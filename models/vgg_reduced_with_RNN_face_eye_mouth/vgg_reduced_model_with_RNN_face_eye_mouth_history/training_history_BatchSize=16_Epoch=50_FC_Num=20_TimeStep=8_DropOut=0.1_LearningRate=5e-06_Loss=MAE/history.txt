Epoch: 1| Step: 0
Training loss: 5.697569847106934
Validation loss: 5.302812973658244

Epoch: 6| Step: 1
Training loss: 4.333301067352295
Validation loss: 5.3010900020599365

Epoch: 6| Step: 2
Training loss: 6.044292449951172
Validation loss: 5.299456040064494

Epoch: 6| Step: 3
Training loss: 5.499641418457031
Validation loss: 5.297831217447917

Epoch: 6| Step: 4
Training loss: 5.735413551330566
Validation loss: 5.296189943949382

Epoch: 6| Step: 5
Training loss: 5.928754806518555
Validation loss: 5.294588009516398

Epoch: 6| Step: 6
Training loss: 5.425355911254883
Validation loss: 5.2929292519887285

Epoch: 6| Step: 7
Training loss: 5.789972305297852
Validation loss: 5.291331768035889

Epoch: 6| Step: 8
Training loss: 4.703056335449219
Validation loss: 5.289722919464111

Epoch: 6| Step: 9
Training loss: 4.45230770111084
Validation loss: 5.287992715835571

Epoch: 6| Step: 10
Training loss: 6.174018859863281
Validation loss: 5.286314328511556

Epoch: 6| Step: 11
Training loss: 5.683956146240234
Validation loss: 5.284538189570109

Epoch: 6| Step: 12
Training loss: 4.5356011390686035
Validation loss: 5.282672484715779

Epoch: 6| Step: 13
Training loss: 5.05138635635376
Validation loss: 5.280844449996948

Epoch: 2| Step: 0
Training loss: 5.986169338226318
Validation loss: 5.278853336970012

Epoch: 6| Step: 1
Training loss: 5.304244041442871
Validation loss: 5.276803255081177

Epoch: 6| Step: 2
Training loss: 5.481390953063965
Validation loss: 5.274703741073608

Epoch: 6| Step: 3
Training loss: 5.329659938812256
Validation loss: 5.272426207860311

Epoch: 6| Step: 4
Training loss: 5.0522260665893555
Validation loss: 5.270199537277222

Epoch: 6| Step: 5
Training loss: 5.556130409240723
Validation loss: 5.267637411753337

Epoch: 6| Step: 6
Training loss: 5.4497222900390625
Validation loss: 5.265119314193726

Epoch: 6| Step: 7
Training loss: 4.561408996582031
Validation loss: 5.262447675069173

Epoch: 6| Step: 8
Training loss: 5.11864709854126
Validation loss: 5.259721517562866

Epoch: 6| Step: 9
Training loss: 5.022924423217773
Validation loss: 5.256822268168132

Epoch: 6| Step: 10
Training loss: 6.336633682250977
Validation loss: 5.25377615292867

Epoch: 6| Step: 11
Training loss: 5.404857635498047
Validation loss: 5.250564098358154

Epoch: 6| Step: 12
Training loss: 4.835326194763184
Validation loss: 5.247062683105469

Epoch: 6| Step: 13
Training loss: 5.208484649658203
Validation loss: 5.243551731109619

Epoch: 3| Step: 0
Training loss: 4.225864887237549
Validation loss: 5.239678780237834

Epoch: 6| Step: 1
Training loss: 5.622578144073486
Validation loss: 5.235958099365234

Epoch: 6| Step: 2
Training loss: 5.426183700561523
Validation loss: 5.23185920715332

Epoch: 6| Step: 3
Training loss: 5.146759033203125
Validation loss: 5.227537631988525

Epoch: 6| Step: 4
Training loss: 4.549315452575684
Validation loss: 5.223329861958821

Epoch: 6| Step: 5
Training loss: 5.88128137588501
Validation loss: 5.218549569447835

Epoch: 6| Step: 6
Training loss: 6.064448356628418
Validation loss: 5.213456551233928

Epoch: 6| Step: 7
Training loss: 5.469653129577637
Validation loss: 5.208632111549377

Epoch: 6| Step: 8
Training loss: 6.285449504852295
Validation loss: 5.203077872594197

Epoch: 6| Step: 9
Training loss: 4.827900409698486
Validation loss: 5.197415033976237

Epoch: 6| Step: 10
Training loss: 5.296214580535889
Validation loss: 5.191572189331055

Epoch: 6| Step: 11
Training loss: 5.967352867126465
Validation loss: 5.185549259185791

Epoch: 6| Step: 12
Training loss: 4.957887172698975
Validation loss: 5.179074287414551

Epoch: 6| Step: 13
Training loss: 4.184816837310791
Validation loss: 5.1725203196207685

Epoch: 4| Step: 0
Training loss: 5.283647060394287
Validation loss: 5.165767192840576

Epoch: 6| Step: 1
Training loss: 4.627589225769043
Validation loss: 5.15897003809611

Epoch: 6| Step: 2
Training loss: 5.697794437408447
Validation loss: 5.151631514231364

Epoch: 6| Step: 3
Training loss: 5.297026634216309
Validation loss: 5.144325613975525

Epoch: 6| Step: 4
Training loss: 6.090359687805176
Validation loss: 5.136725664138794

Epoch: 6| Step: 5
Training loss: 5.58013391494751
Validation loss: 5.128903309504191

Epoch: 6| Step: 6
Training loss: 5.2109479904174805
Validation loss: 5.121074676513672

Epoch: 6| Step: 7
Training loss: 4.848947525024414
Validation loss: 5.112884918848674

Epoch: 6| Step: 8
Training loss: 5.265044212341309
Validation loss: 5.104426781336467

Epoch: 6| Step: 9
Training loss: 4.5201897621154785
Validation loss: 5.096401532491048

Epoch: 6| Step: 10
Training loss: 5.262929916381836
Validation loss: 5.088030099868774

Epoch: 6| Step: 11
Training loss: 5.118466854095459
Validation loss: 5.079650799433391

Epoch: 6| Step: 12
Training loss: 4.643709182739258
Validation loss: 5.071303208669026

Epoch: 6| Step: 13
Training loss: 5.220807075500488
Validation loss: 5.062615633010864

Epoch: 5| Step: 0
Training loss: 4.573899269104004
Validation loss: 5.053881009419759

Epoch: 6| Step: 1
Training loss: 5.5714921951293945
Validation loss: 5.045208772023519

Epoch: 6| Step: 2
Training loss: 4.909101963043213
Validation loss: 5.036394516626994

Epoch: 6| Step: 3
Training loss: 4.365922927856445
Validation loss: 5.0275527238845825

Epoch: 6| Step: 4
Training loss: 6.069977760314941
Validation loss: 5.018328030904134

Epoch: 6| Step: 5
Training loss: 5.915500164031982
Validation loss: 5.0092315673828125

Epoch: 6| Step: 6
Training loss: 4.60116720199585
Validation loss: 5.00003965695699

Epoch: 6| Step: 7
Training loss: 4.366107940673828
Validation loss: 4.991141080856323

Epoch: 6| Step: 8
Training loss: 5.520255088806152
Validation loss: 4.982156117757161

Epoch: 6| Step: 9
Training loss: 5.431568622589111
Validation loss: 4.973327875137329

Epoch: 6| Step: 10
Training loss: 4.311396598815918
Validation loss: 4.964658657709758

Epoch: 6| Step: 11
Training loss: 4.96059513092041
Validation loss: 4.95611556371053

Epoch: 6| Step: 12
Training loss: 5.330101013183594
Validation loss: 4.947571396827698

Epoch: 6| Step: 13
Training loss: 5.1443610191345215
Validation loss: 4.939565062522888

Epoch: 6| Step: 0
Training loss: 6.023745059967041
Validation loss: 4.931588252385457

Epoch: 6| Step: 1
Training loss: 4.515789031982422
Validation loss: 4.923436880111694

Epoch: 6| Step: 2
Training loss: 6.312152862548828
Validation loss: 4.915727933247884

Epoch: 6| Step: 3
Training loss: 4.346812725067139
Validation loss: 4.908343474070231

Epoch: 6| Step: 4
Training loss: 4.641524314880371
Validation loss: 4.9010913372039795

Epoch: 6| Step: 5
Training loss: 4.800500869750977
Validation loss: 4.893854300181071

Epoch: 6| Step: 6
Training loss: 5.076951503753662
Validation loss: 4.886789957682292

Epoch: 6| Step: 7
Training loss: 5.568027496337891
Validation loss: 4.879651467005412

Epoch: 6| Step: 8
Training loss: 5.2208333015441895
Validation loss: 4.872734546661377

Epoch: 6| Step: 9
Training loss: 4.545413017272949
Validation loss: 4.8659855127334595

Epoch: 6| Step: 10
Training loss: 5.239166259765625
Validation loss: 4.858999570210774

Epoch: 6| Step: 11
Training loss: 4.487147331237793
Validation loss: 4.852431138356526

Epoch: 6| Step: 12
Training loss: 3.817936420440674
Validation loss: 4.845532774925232

Epoch: 6| Step: 13
Training loss: 4.963425159454346
Validation loss: 4.838782072067261

Epoch: 7| Step: 0
Training loss: 4.847520351409912
Validation loss: 4.831965883572896

Epoch: 6| Step: 1
Training loss: 4.938297748565674
Validation loss: 4.825222969055176

Epoch: 6| Step: 2
Training loss: 4.580871105194092
Validation loss: 4.818936904271443

Epoch: 6| Step: 3
Training loss: 5.095615863800049
Validation loss: 4.8124635219573975

Epoch: 6| Step: 4
Training loss: 4.597199440002441
Validation loss: 4.806028763453166

Epoch: 6| Step: 5
Training loss: 5.36058235168457
Validation loss: 4.799485603968303

Epoch: 6| Step: 6
Training loss: 5.264693260192871
Validation loss: 4.793381134668986

Epoch: 6| Step: 7
Training loss: 5.272547245025635
Validation loss: 4.78710953394572

Epoch: 6| Step: 8
Training loss: 4.727881908416748
Validation loss: 4.780579725901286

Epoch: 6| Step: 9
Training loss: 4.563068389892578
Validation loss: 4.774384339650472

Epoch: 6| Step: 10
Training loss: 4.2388834953308105
Validation loss: 4.768435875574748

Epoch: 6| Step: 11
Training loss: 5.125340938568115
Validation loss: 4.7624547481536865

Epoch: 6| Step: 12
Training loss: 4.988411903381348
Validation loss: 4.7567243576049805

Epoch: 6| Step: 13
Training loss: 4.728632926940918
Validation loss: 4.751096089680989

Epoch: 8| Step: 0
Training loss: 4.451519966125488
Validation loss: 4.745802720387776

Epoch: 6| Step: 1
Training loss: 4.319876670837402
Validation loss: 4.740142742792766

Epoch: 6| Step: 2
Training loss: 4.8830156326293945
Validation loss: 4.734880367914836

Epoch: 6| Step: 3
Training loss: 4.668398857116699
Validation loss: 4.729674776395162

Epoch: 6| Step: 4
Training loss: 4.002388954162598
Validation loss: 4.723993341128032

Epoch: 6| Step: 5
Training loss: 5.965644836425781
Validation loss: 4.718382120132446

Epoch: 6| Step: 6
Training loss: 4.500901222229004
Validation loss: 4.713090737660726

Epoch: 6| Step: 7
Training loss: 4.31480598449707
Validation loss: 4.707085212071736

Epoch: 6| Step: 8
Training loss: 4.724416732788086
Validation loss: 4.70195198059082

Epoch: 6| Step: 9
Training loss: 4.968933582305908
Validation loss: 4.696102539698283

Epoch: 6| Step: 10
Training loss: 5.150537014007568
Validation loss: 4.690499385197957

Epoch: 6| Step: 11
Training loss: 5.192617893218994
Validation loss: 4.6848413944244385

Epoch: 6| Step: 12
Training loss: 3.984560012817383
Validation loss: 4.6789116859436035

Epoch: 6| Step: 13
Training loss: 6.123763084411621
Validation loss: 4.673392812410991

Epoch: 9| Step: 0
Training loss: 3.2459096908569336
Validation loss: 4.667175054550171

Epoch: 6| Step: 1
Training loss: 3.8221306800842285
Validation loss: 4.660951852798462

Epoch: 6| Step: 2
Training loss: 5.456296443939209
Validation loss: 4.654913107554118

Epoch: 6| Step: 3
Training loss: 5.358515739440918
Validation loss: 4.64857014020284

Epoch: 6| Step: 4
Training loss: 4.541816234588623
Validation loss: 4.642143448193868

Epoch: 6| Step: 5
Training loss: 5.088716506958008
Validation loss: 4.635549783706665

Epoch: 6| Step: 6
Training loss: 4.808300018310547
Validation loss: 4.629343748092651

Epoch: 6| Step: 7
Training loss: 5.931595325469971
Validation loss: 4.622760772705078

Epoch: 6| Step: 8
Training loss: 3.6265134811401367
Validation loss: 4.616237243016561

Epoch: 6| Step: 9
Training loss: 4.714056968688965
Validation loss: 4.609460552533467

Epoch: 6| Step: 10
Training loss: 5.595473766326904
Validation loss: 4.60278840859731

Epoch: 6| Step: 11
Training loss: 5.044157028198242
Validation loss: 4.59652054309845

Epoch: 6| Step: 12
Training loss: 4.097917556762695
Validation loss: 4.590017477671306

Epoch: 6| Step: 13
Training loss: 4.78981351852417
Validation loss: 4.583560466766357

Epoch: 10| Step: 0
Training loss: 5.816489219665527
Validation loss: 4.5771381457646685

Epoch: 6| Step: 1
Training loss: 4.959179878234863
Validation loss: 4.5709885358810425

Epoch: 6| Step: 2
Training loss: 3.4874935150146484
Validation loss: 4.5638482968012495

Epoch: 6| Step: 3
Training loss: 5.314386367797852
Validation loss: 4.5570433139801025

Epoch: 6| Step: 4
Training loss: 5.3774943351745605
Validation loss: 4.550750533739726

Epoch: 6| Step: 5
Training loss: 3.749516725540161
Validation loss: 4.544293165206909

Epoch: 6| Step: 6
Training loss: 4.581456184387207
Validation loss: 4.538153608640035

Epoch: 6| Step: 7
Training loss: 4.616176128387451
Validation loss: 4.531761646270752

Epoch: 6| Step: 8
Training loss: 4.545575141906738
Validation loss: 4.525202035903931

Epoch: 6| Step: 9
Training loss: 4.995704650878906
Validation loss: 4.518963813781738

Epoch: 6| Step: 10
Training loss: 4.271775245666504
Validation loss: 4.512542009353638

Epoch: 6| Step: 11
Training loss: 4.233068466186523
Validation loss: 4.5068559646606445

Epoch: 6| Step: 12
Training loss: 4.516638278961182
Validation loss: 4.500501751899719

Epoch: 6| Step: 13
Training loss: 4.481768608093262
Validation loss: 4.494660019874573

Epoch: 11| Step: 0
Training loss: 4.722275733947754
Validation loss: 4.48872983455658

Epoch: 6| Step: 1
Training loss: 4.443019866943359
Validation loss: 4.482264359792073

Epoch: 6| Step: 2
Training loss: 5.039310455322266
Validation loss: 4.475645502408345

Epoch: 6| Step: 3
Training loss: 4.536264896392822
Validation loss: 4.468943277994792

Epoch: 6| Step: 4
Training loss: 4.8290114402771
Validation loss: 4.462611198425293

Epoch: 6| Step: 5
Training loss: 5.508153915405273
Validation loss: 4.456397930781047

Epoch: 6| Step: 6
Training loss: 4.023380279541016
Validation loss: 4.449771960576375

Epoch: 6| Step: 7
Training loss: 4.064990997314453
Validation loss: 4.443486054738362

Epoch: 6| Step: 8
Training loss: 4.3983001708984375
Validation loss: 4.437489906946818

Epoch: 6| Step: 9
Training loss: 4.300107002258301
Validation loss: 4.431625723838806

Epoch: 6| Step: 10
Training loss: 3.9972541332244873
Validation loss: 4.426015814145406

Epoch: 6| Step: 11
Training loss: 3.7901206016540527
Validation loss: 4.419957796732585

Epoch: 6| Step: 12
Training loss: 4.5158185958862305
Validation loss: 4.414049466451009

Epoch: 6| Step: 13
Training loss: 5.660780906677246
Validation loss: 4.408868590990703

Epoch: 12| Step: 0
Training loss: 4.021785736083984
Validation loss: 4.403799374898274

Epoch: 6| Step: 1
Training loss: 4.44518518447876
Validation loss: 4.397320787111918

Epoch: 6| Step: 2
Training loss: 3.2202200889587402
Validation loss: 4.3915196259816485

Epoch: 6| Step: 3
Training loss: 4.93497371673584
Validation loss: 4.3865446249643965

Epoch: 6| Step: 4
Training loss: 5.359431266784668
Validation loss: 4.381789644559224

Epoch: 6| Step: 5
Training loss: 5.164839267730713
Validation loss: 4.375744899113973

Epoch: 6| Step: 6
Training loss: 4.5217437744140625
Validation loss: 4.369592666625977

Epoch: 6| Step: 7
Training loss: 4.108592987060547
Validation loss: 4.363274772961934

Epoch: 6| Step: 8
Training loss: 3.549927234649658
Validation loss: 4.357767422993978

Epoch: 6| Step: 9
Training loss: 4.823060989379883
Validation loss: 4.352415362993876

Epoch: 6| Step: 10
Training loss: 4.927089214324951
Validation loss: 4.347303549448649

Epoch: 6| Step: 11
Training loss: 5.292016506195068
Validation loss: 4.341098467508952

Epoch: 6| Step: 12
Training loss: 4.64506196975708
Validation loss: 4.335349599520366

Epoch: 6| Step: 13
Training loss: 3.7757511138916016
Validation loss: 4.330202142397563

Epoch: 13| Step: 0
Training loss: 5.287936210632324
Validation loss: 4.324949741363525

Epoch: 6| Step: 1
Training loss: 3.612309694290161
Validation loss: 4.319049557050069

Epoch: 6| Step: 2
Training loss: 4.566197395324707
Validation loss: 4.31358818213145

Epoch: 6| Step: 3
Training loss: 4.386797904968262
Validation loss: 4.30879545211792

Epoch: 6| Step: 4
Training loss: 4.552219390869141
Validation loss: 4.302963097890218

Epoch: 6| Step: 5
Training loss: 4.803493499755859
Validation loss: 4.297993262608846

Epoch: 6| Step: 6
Training loss: 5.363213539123535
Validation loss: 4.292556643486023

Epoch: 6| Step: 7
Training loss: 4.124417304992676
Validation loss: 4.286861220995585

Epoch: 6| Step: 8
Training loss: 3.545626640319824
Validation loss: 4.281725525856018

Epoch: 6| Step: 9
Training loss: 4.07422399520874
Validation loss: 4.276461124420166

Epoch: 6| Step: 10
Training loss: 3.9193363189697266
Validation loss: 4.270903666814168

Epoch: 6| Step: 11
Training loss: 6.035840034484863
Validation loss: 4.266433199246724

Epoch: 6| Step: 12
Training loss: 3.9389896392822266
Validation loss: 4.26071294148763

Epoch: 6| Step: 13
Training loss: 3.5880727767944336
Validation loss: 4.255593021710713

Epoch: 14| Step: 0
Training loss: 5.1498613357543945
Validation loss: 4.250845193862915

Epoch: 6| Step: 1
Training loss: 4.556351661682129
Validation loss: 4.245517770449321

Epoch: 6| Step: 2
Training loss: 4.9172043800354
Validation loss: 4.239926099777222

Epoch: 6| Step: 3
Training loss: 4.027926445007324
Validation loss: 4.234183231989543

Epoch: 6| Step: 4
Training loss: 3.5859522819519043
Validation loss: 4.228366216023763

Epoch: 6| Step: 5
Training loss: 4.856306552886963
Validation loss: 4.223294377326965

Epoch: 6| Step: 6
Training loss: 3.774409055709839
Validation loss: 4.21800156434377

Epoch: 6| Step: 7
Training loss: 4.743892192840576
Validation loss: 4.212375322977702

Epoch: 6| Step: 8
Training loss: 4.270781517028809
Validation loss: 4.206882794698079

Epoch: 6| Step: 9
Training loss: 4.1925811767578125
Validation loss: 4.2024457057317095

Epoch: 6| Step: 10
Training loss: 4.125749111175537
Validation loss: 4.198089122772217

Epoch: 6| Step: 11
Training loss: 3.999272584915161
Validation loss: 4.192702571551005

Epoch: 6| Step: 12
Training loss: 4.3867292404174805
Validation loss: 4.187367836634318

Epoch: 6| Step: 13
Training loss: 4.29340124130249
Validation loss: 4.181930502255757

Epoch: 15| Step: 0
Training loss: 4.479169845581055
Validation loss: 4.177490790685018

Epoch: 6| Step: 1
Training loss: 3.82700514793396
Validation loss: 4.172313292821248

Epoch: 6| Step: 2
Training loss: 3.904155969619751
Validation loss: 4.167154630025228

Epoch: 6| Step: 3
Training loss: 4.003669738769531
Validation loss: 4.163723190625508

Epoch: 6| Step: 4
Training loss: 4.465088844299316
Validation loss: 4.159486611684163

Epoch: 6| Step: 5
Training loss: 5.405627250671387
Validation loss: 4.152323484420776

Epoch: 6| Step: 6
Training loss: 5.1580610275268555
Validation loss: 4.148610790570577

Epoch: 6| Step: 7
Training loss: 3.9168057441711426
Validation loss: 4.1439240376154585

Epoch: 6| Step: 8
Training loss: 4.594827651977539
Validation loss: 4.138947010040283

Epoch: 6| Step: 9
Training loss: 3.998621702194214
Validation loss: 4.133027871449788

Epoch: 6| Step: 10
Training loss: 5.129859924316406
Validation loss: 4.128223260243733

Epoch: 6| Step: 11
Training loss: 3.0871167182922363
Validation loss: 4.122950832049052

Epoch: 6| Step: 12
Training loss: 5.129680156707764
Validation loss: 4.118762095769246

Epoch: 6| Step: 13
Training loss: 2.855316162109375
Validation loss: 4.1135150988896685

Epoch: 16| Step: 0
Training loss: 4.505282402038574
Validation loss: 4.107870936393738

Epoch: 6| Step: 1
Training loss: 4.317378044128418
Validation loss: 4.103322426478068

Epoch: 6| Step: 2
Training loss: 4.315615653991699
Validation loss: 4.09824812412262

Epoch: 6| Step: 3
Training loss: 3.6973416805267334
Validation loss: 4.09290595849355

Epoch: 6| Step: 4
Training loss: 4.572054862976074
Validation loss: 4.088064988454183

Epoch: 6| Step: 5
Training loss: 3.8426952362060547
Validation loss: 4.083106875419617

Epoch: 6| Step: 6
Training loss: 4.184372425079346
Validation loss: 4.0777484973271685

Epoch: 6| Step: 7
Training loss: 3.9740610122680664
Validation loss: 4.072687705357869

Epoch: 6| Step: 8
Training loss: 4.5839314460754395
Validation loss: 4.068001985549927

Epoch: 6| Step: 9
Training loss: 4.761231422424316
Validation loss: 4.062250256538391

Epoch: 6| Step: 10
Training loss: 4.0635881423950195
Validation loss: 4.058571298917134

Epoch: 6| Step: 11
Training loss: 4.818769454956055
Validation loss: 4.052861928939819

Epoch: 6| Step: 12
Training loss: 2.572880268096924
Validation loss: 4.048362731933594

Epoch: 6| Step: 13
Training loss: 4.833165168762207
Validation loss: 4.0434872309366865

Epoch: 17| Step: 0
Training loss: 4.897706031799316
Validation loss: 4.038636287053426

Epoch: 6| Step: 1
Training loss: 4.875916957855225
Validation loss: 4.0342313051223755

Epoch: 6| Step: 2
Training loss: 4.516663551330566
Validation loss: 4.029583175977071

Epoch: 6| Step: 3
Training loss: 3.933854103088379
Validation loss: 4.024923920631409

Epoch: 6| Step: 4
Training loss: 3.9585933685302734
Validation loss: 4.020034750302632

Epoch: 6| Step: 5
Training loss: 3.387256145477295
Validation loss: 4.015685200691223

Epoch: 6| Step: 6
Training loss: 4.502258777618408
Validation loss: 4.010325630505879

Epoch: 6| Step: 7
Training loss: 3.6839699745178223
Validation loss: 4.005688746770223

Epoch: 6| Step: 8
Training loss: 3.3407015800476074
Validation loss: 4.001006007194519

Epoch: 6| Step: 9
Training loss: 4.0065131187438965
Validation loss: 3.9970871607462564

Epoch: 6| Step: 10
Training loss: 3.5263888835906982
Validation loss: 3.991603374481201

Epoch: 6| Step: 11
Training loss: 5.4609055519104
Validation loss: 3.9872713883717856

Epoch: 6| Step: 12
Training loss: 3.6884803771972656
Validation loss: 3.98254930973053

Epoch: 6| Step: 13
Training loss: 4.362565040588379
Validation loss: 3.9777150551478067

Epoch: 18| Step: 0
Training loss: 4.374222278594971
Validation loss: 3.9730844100316367

Epoch: 6| Step: 1
Training loss: 3.397458791732788
Validation loss: 3.96794855594635

Epoch: 6| Step: 2
Training loss: 4.542847156524658
Validation loss: 3.9631675084431968

Epoch: 6| Step: 3
Training loss: 4.519587993621826
Validation loss: 3.958721081415812

Epoch: 6| Step: 4
Training loss: 4.847419738769531
Validation loss: 3.9535546700159707

Epoch: 6| Step: 5
Training loss: 3.97196102142334
Validation loss: 3.949108123779297

Epoch: 6| Step: 6
Training loss: 3.2053940296173096
Validation loss: 3.94444739818573

Epoch: 6| Step: 7
Training loss: 4.274137496948242
Validation loss: 3.940882166226705

Epoch: 6| Step: 8
Training loss: 3.382417678833008
Validation loss: 3.9353718757629395

Epoch: 6| Step: 9
Training loss: 5.159124851226807
Validation loss: 3.9309970140457153

Epoch: 6| Step: 10
Training loss: 4.688297271728516
Validation loss: 3.9256565968195596

Epoch: 6| Step: 11
Training loss: 4.264301776885986
Validation loss: 3.920965631802877

Epoch: 6| Step: 12
Training loss: 3.2981555461883545
Validation loss: 3.916379968325297

Epoch: 6| Step: 13
Training loss: 3.341852903366089
Validation loss: 3.911664923032125

Epoch: 19| Step: 0
Training loss: 4.001410484313965
Validation loss: 3.9071696599324546

Epoch: 6| Step: 1
Training loss: 4.395378112792969
Validation loss: 3.9027180274327598

Epoch: 6| Step: 2
Training loss: 3.577082633972168
Validation loss: 3.898083051045736

Epoch: 6| Step: 3
Training loss: 5.2294416427612305
Validation loss: 3.8938382069269815

Epoch: 6| Step: 4
Training loss: 3.5866575241088867
Validation loss: 3.8892046213150024

Epoch: 6| Step: 5
Training loss: 4.716926574707031
Validation loss: 3.884767691294352

Epoch: 6| Step: 6
Training loss: 4.2130937576293945
Validation loss: 3.8801193634668985

Epoch: 6| Step: 7
Training loss: 4.46952486038208
Validation loss: 3.8756038347880044

Epoch: 6| Step: 8
Training loss: 3.8214447498321533
Validation loss: 3.8712473710378013

Epoch: 6| Step: 9
Training loss: 3.198265790939331
Validation loss: 3.8665446837743125

Epoch: 6| Step: 10
Training loss: 4.7583818435668945
Validation loss: 3.8621784845987954

Epoch: 6| Step: 11
Training loss: 3.98332142829895
Validation loss: 3.857665181159973

Epoch: 6| Step: 12
Training loss: 3.4534566402435303
Validation loss: 3.85370671749115

Epoch: 6| Step: 13
Training loss: 3.0104150772094727
Validation loss: 3.8492500384648642

Epoch: 20| Step: 0
Training loss: 4.818681716918945
Validation loss: 3.8449851274490356

Epoch: 6| Step: 1
Training loss: 3.5794904232025146
Validation loss: 3.840150316556295

Epoch: 6| Step: 2
Training loss: 5.327930450439453
Validation loss: 3.83643647034963

Epoch: 6| Step: 3
Training loss: 3.85849928855896
Validation loss: 3.8313674926757812

Epoch: 6| Step: 4
Training loss: 3.527790069580078
Validation loss: 3.8272945086161294

Epoch: 6| Step: 5
Training loss: 4.515120983123779
Validation loss: 3.822739601135254

Epoch: 6| Step: 6
Training loss: 2.9085984230041504
Validation loss: 3.818671623865763

Epoch: 6| Step: 7
Training loss: 4.353358268737793
Validation loss: 3.8143039544423423

Epoch: 6| Step: 8
Training loss: 4.844665050506592
Validation loss: 3.8098361492156982

Epoch: 6| Step: 9
Training loss: 4.474235534667969
Validation loss: 3.8054789702097573

Epoch: 6| Step: 10
Training loss: 3.166576862335205
Validation loss: 3.801196336746216

Epoch: 6| Step: 11
Training loss: 2.245694160461426
Validation loss: 3.796988566716512

Epoch: 6| Step: 12
Training loss: 3.9099202156066895
Validation loss: 3.7929702599843345

Epoch: 6| Step: 13
Training loss: 4.07301664352417
Validation loss: 3.7886840105056763

Epoch: 21| Step: 0
Training loss: 3.437222957611084
Validation loss: 3.7845619916915894

Epoch: 6| Step: 1
Training loss: 3.7778985500335693
Validation loss: 3.780107537905375

Epoch: 6| Step: 2
Training loss: 3.8845157623291016
Validation loss: 3.7754586140314736

Epoch: 6| Step: 3
Training loss: 3.645658493041992
Validation loss: 3.7712335189183555

Epoch: 6| Step: 4
Training loss: 4.067289352416992
Validation loss: 3.7666762272516885

Epoch: 6| Step: 5
Training loss: 3.8328628540039062
Validation loss: 3.7625237305959067

Epoch: 6| Step: 6
Training loss: 3.662489652633667
Validation loss: 3.7579390605290732

Epoch: 6| Step: 7
Training loss: 3.8583462238311768
Validation loss: 3.753850301106771

Epoch: 6| Step: 8
Training loss: 4.621622562408447
Validation loss: 3.7497532765070596

Epoch: 6| Step: 9
Training loss: 3.310321807861328
Validation loss: 3.745317498842875

Epoch: 6| Step: 10
Training loss: 4.310929775238037
Validation loss: 3.7411548693974814

Epoch: 6| Step: 11
Training loss: 4.605999946594238
Validation loss: 3.737337112426758

Epoch: 6| Step: 12
Training loss: 3.3850512504577637
Validation loss: 3.73287832736969

Epoch: 6| Step: 13
Training loss: 4.4187164306640625
Validation loss: 3.728893836339315

Epoch: 22| Step: 0
Training loss: 2.9195730686187744
Validation loss: 3.724793632825216

Epoch: 6| Step: 1
Training loss: 3.0260584354400635
Validation loss: 3.720955014228821

Epoch: 6| Step: 2
Training loss: 3.525979518890381
Validation loss: 3.7170819441477456

Epoch: 6| Step: 3
Training loss: 4.224771976470947
Validation loss: 3.712830980618795

Epoch: 6| Step: 4
Training loss: 3.9472336769104004
Validation loss: 3.7091144720713296

Epoch: 6| Step: 5
Training loss: 3.2082831859588623
Validation loss: 3.7051033973693848

Epoch: 6| Step: 6
Training loss: 3.906785011291504
Validation loss: 3.700826366742452

Epoch: 6| Step: 7
Training loss: 4.663230895996094
Validation loss: 3.696890195210775

Epoch: 6| Step: 8
Training loss: 3.892883539199829
Validation loss: 3.692727049191793

Epoch: 6| Step: 9
Training loss: 4.19549560546875
Validation loss: 3.688534458478292

Epoch: 6| Step: 10
Training loss: 5.238414287567139
Validation loss: 3.6844451824824014

Epoch: 6| Step: 11
Training loss: 4.05659294128418
Validation loss: 3.6802868048350015

Epoch: 6| Step: 12
Training loss: 3.553157091140747
Validation loss: 3.675887187321981

Epoch: 6| Step: 13
Training loss: 3.677455425262451
Validation loss: 3.671937664349874

Epoch: 23| Step: 0
Training loss: 3.980536937713623
Validation loss: 3.6678707599639893

Epoch: 6| Step: 1
Training loss: 3.0583910942077637
Validation loss: 3.6629201571146646

Epoch: 6| Step: 2
Training loss: 3.6763415336608887
Validation loss: 3.6589924097061157

Epoch: 6| Step: 3
Training loss: 4.306635856628418
Validation loss: 3.6544968287150064

Epoch: 6| Step: 4
Training loss: 3.819305896759033
Validation loss: 3.65029239654541

Epoch: 6| Step: 5
Training loss: 2.8679308891296387
Validation loss: 3.646150827407837

Epoch: 6| Step: 6
Training loss: 4.188629150390625
Validation loss: 3.6418675581614175

Epoch: 6| Step: 7
Training loss: 4.771251678466797
Validation loss: 3.63764226436615

Epoch: 6| Step: 8
Training loss: 4.353085994720459
Validation loss: 3.6333981355031333

Epoch: 6| Step: 9
Training loss: 3.8021044731140137
Validation loss: 3.628638426462809

Epoch: 6| Step: 10
Training loss: 2.947068691253662
Validation loss: 3.6245197455088296

Epoch: 6| Step: 11
Training loss: 3.3173608779907227
Validation loss: 3.62026309967041

Epoch: 6| Step: 12
Training loss: 4.405706405639648
Validation loss: 3.6160691181818643

Epoch: 6| Step: 13
Training loss: 3.764213800430298
Validation loss: 3.6121742328008017

Epoch: 24| Step: 0
Training loss: 3.3255624771118164
Validation loss: 3.6078704992930093

Epoch: 6| Step: 1
Training loss: 4.526708602905273
Validation loss: 3.603590408960978

Epoch: 6| Step: 2
Training loss: 4.601059913635254
Validation loss: 3.5994422833124795

Epoch: 6| Step: 3
Training loss: 2.9672515392303467
Validation loss: 3.594971537590027

Epoch: 6| Step: 4
Training loss: 4.095054626464844
Validation loss: 3.5905460913976035

Epoch: 6| Step: 5
Training loss: 3.417965888977051
Validation loss: 3.5864670276641846

Epoch: 6| Step: 6
Training loss: 3.7342214584350586
Validation loss: 3.5819842418034873

Epoch: 6| Step: 7
Training loss: 4.242804050445557
Validation loss: 3.5778571367263794

Epoch: 6| Step: 8
Training loss: 3.4346587657928467
Validation loss: 3.5736034711201987

Epoch: 6| Step: 9
Training loss: 3.602273941040039
Validation loss: 3.5694262981414795

Epoch: 6| Step: 10
Training loss: 3.6841964721679688
Validation loss: 3.5652764638264975

Epoch: 6| Step: 11
Training loss: 3.509664297103882
Validation loss: 3.5608818531036377

Epoch: 6| Step: 12
Training loss: 2.8959908485412598
Validation loss: 3.5571772257486978

Epoch: 6| Step: 13
Training loss: 4.394311904907227
Validation loss: 3.5529196659723916

Epoch: 25| Step: 0
Training loss: 3.7024385929107666
Validation loss: 3.548944433530172

Epoch: 6| Step: 1
Training loss: 3.5366320610046387
Validation loss: 3.544493635495504

Epoch: 6| Step: 2
Training loss: 3.8052539825439453
Validation loss: 3.540005326271057

Epoch: 6| Step: 3
Training loss: 3.8921027183532715
Validation loss: 3.535661260286967

Epoch: 6| Step: 4
Training loss: 3.1263034343719482
Validation loss: 3.5315088431040444

Epoch: 6| Step: 5
Training loss: 4.191263198852539
Validation loss: 3.527408560117086

Epoch: 6| Step: 6
Training loss: 4.1342082023620605
Validation loss: 3.523023009300232

Epoch: 6| Step: 7
Training loss: 3.28558087348938
Validation loss: 3.518610715866089

Epoch: 6| Step: 8
Training loss: 3.4966940879821777
Validation loss: 3.5143820444742837

Epoch: 6| Step: 9
Training loss: 3.707098960876465
Validation loss: 3.509954333305359

Epoch: 6| Step: 10
Training loss: 2.424665927886963
Validation loss: 3.5056418577829995

Epoch: 6| Step: 11
Training loss: 4.176824569702148
Validation loss: 3.5016302267710366

Epoch: 6| Step: 12
Training loss: 3.556011199951172
Validation loss: 3.4975006580352783

Epoch: 6| Step: 13
Training loss: 4.583520889282227
Validation loss: 3.4934850931167603

Epoch: 26| Step: 0
Training loss: 3.218310832977295
Validation loss: 3.4891396363576255

Epoch: 6| Step: 1
Training loss: 4.126387596130371
Validation loss: 3.4846942822138467

Epoch: 6| Step: 2
Training loss: 2.9085564613342285
Validation loss: 3.480451305707296

Epoch: 6| Step: 3
Training loss: 2.8321690559387207
Validation loss: 3.4762893120447793

Epoch: 6| Step: 4
Training loss: 3.0637431144714355
Validation loss: 3.471812605857849

Epoch: 6| Step: 5
Training loss: 3.881909132003784
Validation loss: 3.4676843881607056

Epoch: 6| Step: 6
Training loss: 3.9432802200317383
Validation loss: 3.4631672700246177

Epoch: 6| Step: 7
Training loss: 3.207207202911377
Validation loss: 3.458820422490438

Epoch: 6| Step: 8
Training loss: 3.720702648162842
Validation loss: 3.454655965169271

Epoch: 6| Step: 9
Training loss: 5.43704080581665
Validation loss: 3.4505708614985147

Epoch: 6| Step: 10
Training loss: 2.476750135421753
Validation loss: 3.446149468421936

Epoch: 6| Step: 11
Training loss: 4.309340476989746
Validation loss: 3.4417818784713745

Epoch: 6| Step: 12
Training loss: 3.084650993347168
Validation loss: 3.437475005785624

Epoch: 6| Step: 13
Training loss: 4.570624351501465
Validation loss: 3.4330299297968545

Epoch: 27| Step: 0
Training loss: 3.6211814880371094
Validation loss: 3.4286278088887534

Epoch: 6| Step: 1
Training loss: 3.4871723651885986
Validation loss: 3.423906842867533

Epoch: 6| Step: 2
Training loss: 3.3467798233032227
Validation loss: 3.418952703475952

Epoch: 6| Step: 3
Training loss: 3.3918747901916504
Validation loss: 3.4146199226379395

Epoch: 6| Step: 4
Training loss: 3.5990335941314697
Validation loss: 3.409929037094116

Epoch: 6| Step: 5
Training loss: 3.5478572845458984
Validation loss: 3.405861814816793

Epoch: 6| Step: 6
Training loss: 2.707724094390869
Validation loss: 3.401522636413574

Epoch: 6| Step: 7
Training loss: 3.8981363773345947
Validation loss: 3.39708411693573

Epoch: 6| Step: 8
Training loss: 4.019207000732422
Validation loss: 3.39275594552358

Epoch: 6| Step: 9
Training loss: 4.118917465209961
Validation loss: 3.388327678044637

Epoch: 6| Step: 10
Training loss: 3.553032875061035
Validation loss: 3.3839698235193887

Epoch: 6| Step: 11
Training loss: 2.9768872261047363
Validation loss: 3.379571239153544

Epoch: 6| Step: 12
Training loss: 3.3304171562194824
Validation loss: 3.3756134112675986

Epoch: 6| Step: 13
Training loss: 4.350006103515625
Validation loss: 3.3712621927261353

Epoch: 28| Step: 0
Training loss: 3.311152458190918
Validation loss: 3.3667995929718018

Epoch: 6| Step: 1
Training loss: 3.6751108169555664
Validation loss: 3.3630162874857583

Epoch: 6| Step: 2
Training loss: 3.895883321762085
Validation loss: 3.358978827794393

Epoch: 6| Step: 3
Training loss: 3.440197467803955
Validation loss: 3.355044364929199

Epoch: 6| Step: 4
Training loss: 2.2894606590270996
Validation loss: 3.3509881099065146

Epoch: 6| Step: 5
Training loss: 3.4383487701416016
Validation loss: 3.346673091252645

Epoch: 6| Step: 6
Training loss: 3.7518997192382812
Validation loss: 3.3428159952163696

Epoch: 6| Step: 7
Training loss: 3.580307722091675
Validation loss: 3.3388317426045737

Epoch: 6| Step: 8
Training loss: 3.9420883655548096
Validation loss: 3.3347201347351074

Epoch: 6| Step: 9
Training loss: 3.4956412315368652
Validation loss: 3.3304762840270996

Epoch: 6| Step: 10
Training loss: 4.3373517990112305
Validation loss: 3.3262592951456704

Epoch: 6| Step: 11
Training loss: 3.044128656387329
Validation loss: 3.322148402531942

Epoch: 6| Step: 12
Training loss: 3.732988119125366
Validation loss: 3.317874471346537

Epoch: 6| Step: 13
Training loss: 3.21779727935791
Validation loss: 3.313709855079651

Epoch: 29| Step: 0
Training loss: 3.093074321746826
Validation loss: 3.309144377708435

Epoch: 6| Step: 1
Training loss: 3.6252901554107666
Validation loss: 3.3048052390416465

Epoch: 6| Step: 2
Training loss: 3.637444496154785
Validation loss: 3.3006308476130166

Epoch: 6| Step: 3
Training loss: 4.297472953796387
Validation loss: 3.296445369720459

Epoch: 6| Step: 4
Training loss: 4.052053451538086
Validation loss: 3.2925694386164346

Epoch: 6| Step: 5
Training loss: 2.816457748413086
Validation loss: 3.288265268007914

Epoch: 6| Step: 6
Training loss: 3.2225840091705322
Validation loss: 3.2842732270558677

Epoch: 6| Step: 7
Training loss: 3.3049325942993164
Validation loss: 3.2801169951756797

Epoch: 6| Step: 8
Training loss: 3.6621577739715576
Validation loss: 3.276247024536133

Epoch: 6| Step: 9
Training loss: 3.643244981765747
Validation loss: 3.272059957186381

Epoch: 6| Step: 10
Training loss: 3.685426712036133
Validation loss: 3.2684603532155356

Epoch: 6| Step: 11
Training loss: 3.9160804748535156
Validation loss: 3.2641855478286743

Epoch: 6| Step: 12
Training loss: 2.6651132106781006
Validation loss: 3.2602901061375937

Epoch: 6| Step: 13
Training loss: 2.815073013305664
Validation loss: 3.2561781803766885

Epoch: 30| Step: 0
Training loss: 3.8074097633361816
Validation loss: 3.2522248029708862

Epoch: 6| Step: 1
Training loss: 3.4011764526367188
Validation loss: 3.2479947805404663

Epoch: 6| Step: 2
Training loss: 2.9033524990081787
Validation loss: 3.2438785632451377

Epoch: 6| Step: 3
Training loss: 3.3423306941986084
Validation loss: 3.240317185719808

Epoch: 6| Step: 4
Training loss: 4.2424726486206055
Validation loss: 3.236495018005371

Epoch: 6| Step: 5
Training loss: 3.3096041679382324
Validation loss: 3.2322271267573037

Epoch: 6| Step: 6
Training loss: 3.2924466133117676
Validation loss: 3.228707790374756

Epoch: 6| Step: 7
Training loss: 3.5142483711242676
Validation loss: 3.2246944904327393

Epoch: 6| Step: 8
Training loss: 3.8155088424682617
Validation loss: 3.2205052375793457

Epoch: 6| Step: 9
Training loss: 3.3528904914855957
Validation loss: 3.2165287335713706

Epoch: 6| Step: 10
Training loss: 3.461993455886841
Validation loss: 3.2124834458033242

Epoch: 6| Step: 11
Training loss: 3.095486879348755
Validation loss: 3.208584507306417

Epoch: 6| Step: 12
Training loss: 3.327465057373047
Validation loss: 3.2045239210128784

Epoch: 6| Step: 13
Training loss: 2.8220055103302
Validation loss: 3.200481573740641

Epoch: 31| Step: 0
Training loss: 3.7598652839660645
Validation loss: 3.1965682903925576

Epoch: 6| Step: 1
Training loss: 3.682568311691284
Validation loss: 3.192282279332479

Epoch: 6| Step: 2
Training loss: 4.181868553161621
Validation loss: 3.1882505416870117

Epoch: 6| Step: 3
Training loss: 3.1619882583618164
Validation loss: 3.1842998266220093

Epoch: 6| Step: 4
Training loss: 3.06343936920166
Validation loss: 3.1800731420516968

Epoch: 6| Step: 5
Training loss: 2.911931276321411
Validation loss: 3.175596276919047

Epoch: 6| Step: 6
Training loss: 3.3385367393493652
Validation loss: 3.171754240989685

Epoch: 6| Step: 7
Training loss: 3.3023838996887207
Validation loss: 3.167752663294474

Epoch: 6| Step: 8
Training loss: 2.94718074798584
Validation loss: 3.163826862970988

Epoch: 6| Step: 9
Training loss: 2.4881176948547363
Validation loss: 3.1597444216410318

Epoch: 6| Step: 10
Training loss: 3.5237841606140137
Validation loss: 3.1561919848124185

Epoch: 6| Step: 11
Training loss: 4.372161388397217
Validation loss: 3.152377645174662

Epoch: 6| Step: 12
Training loss: 2.6423349380493164
Validation loss: 3.1484471559524536

Epoch: 6| Step: 13
Training loss: 3.6085102558135986
Validation loss: 3.1443599859873452

Epoch: 32| Step: 0
Training loss: 3.7995669841766357
Validation loss: 3.140481948852539

Epoch: 6| Step: 1
Training loss: 3.4065098762512207
Validation loss: 3.136793335278829

Epoch: 6| Step: 2
Training loss: 3.5922746658325195
Validation loss: 3.132778207461039

Epoch: 6| Step: 3
Training loss: 3.618650197982788
Validation loss: 3.1287503639856973

Epoch: 6| Step: 4
Training loss: 2.667447566986084
Validation loss: 3.1249465942382812

Epoch: 6| Step: 5
Training loss: 2.888176202774048
Validation loss: 3.121238390604655

Epoch: 6| Step: 6
Training loss: 3.5044784545898438
Validation loss: 3.1173522075017295

Epoch: 6| Step: 7
Training loss: 3.6761059761047363
Validation loss: 3.1139142711957297

Epoch: 6| Step: 8
Training loss: 2.713423252105713
Validation loss: 3.1102381547292075

Epoch: 6| Step: 9
Training loss: 3.4195590019226074
Validation loss: 3.1065210501352944

Epoch: 6| Step: 10
Training loss: 3.22587513923645
Validation loss: 3.10249932607015

Epoch: 6| Step: 11
Training loss: 2.843141555786133
Validation loss: 3.098946293195089

Epoch: 6| Step: 12
Training loss: 3.1235904693603516
Validation loss: 3.095434228579203

Epoch: 6| Step: 13
Training loss: 3.7856454849243164
Validation loss: 3.0921090046564736

Epoch: 33| Step: 0
Training loss: 3.085360288619995
Validation loss: 3.088535745938619

Epoch: 6| Step: 1
Training loss: 2.932821035385132
Validation loss: 3.0852131048838296

Epoch: 6| Step: 2
Training loss: 2.964069128036499
Validation loss: 3.0820589860280356

Epoch: 6| Step: 3
Training loss: 3.413294792175293
Validation loss: 3.078931967417399

Epoch: 6| Step: 4
Training loss: 3.0951426029205322
Validation loss: 3.076115886370341

Epoch: 6| Step: 5
Training loss: 3.195657253265381
Validation loss: 3.073040008544922

Epoch: 6| Step: 6
Training loss: 3.5914058685302734
Validation loss: 3.0697328646977744

Epoch: 6| Step: 7
Training loss: 2.756779670715332
Validation loss: 3.0665477514266968

Epoch: 6| Step: 8
Training loss: 3.6003201007843018
Validation loss: 3.063251336415609

Epoch: 6| Step: 9
Training loss: 3.3804030418395996
Validation loss: 3.0598397254943848

Epoch: 6| Step: 10
Training loss: 3.4606857299804688
Validation loss: 3.0562854210535684

Epoch: 6| Step: 11
Training loss: 3.3348236083984375
Validation loss: 3.052835981051127

Epoch: 6| Step: 12
Training loss: 3.676483631134033
Validation loss: 3.0493551095326743

Epoch: 6| Step: 13
Training loss: 3.0905885696411133
Validation loss: 3.045783519744873

Epoch: 34| Step: 0
Training loss: 3.030378580093384
Validation loss: 3.0419450600941977

Epoch: 6| Step: 1
Training loss: 3.879338264465332
Validation loss: 3.0383267402648926

Epoch: 6| Step: 2
Training loss: 2.9885716438293457
Validation loss: 3.0344335238138833

Epoch: 6| Step: 3
Training loss: 3.054973602294922
Validation loss: 3.030713518460592

Epoch: 6| Step: 4
Training loss: 3.54107403755188
Validation loss: 3.0269283850987754

Epoch: 6| Step: 5
Training loss: 2.9079504013061523
Validation loss: 3.023256858189901

Epoch: 6| Step: 6
Training loss: 3.1632235050201416
Validation loss: 3.0194669167200723

Epoch: 6| Step: 7
Training loss: 3.2235679626464844
Validation loss: 3.0157657464345298

Epoch: 6| Step: 8
Training loss: 3.1554207801818848
Validation loss: 3.0121812423070273

Epoch: 6| Step: 9
Training loss: 3.3684306144714355
Validation loss: 3.0087281465530396

Epoch: 6| Step: 10
Training loss: 2.7386226654052734
Validation loss: 3.005084137121836

Epoch: 6| Step: 11
Training loss: 2.7760519981384277
Validation loss: 3.0014227628707886

Epoch: 6| Step: 12
Training loss: 3.2661826610565186
Validation loss: 2.9978172381718955

Epoch: 6| Step: 13
Training loss: 3.8960955142974854
Validation loss: 2.99459699789683

Epoch: 35| Step: 0
Training loss: 4.225179672241211
Validation loss: 2.9914015531539917

Epoch: 6| Step: 1
Training loss: 3.1551060676574707
Validation loss: 2.9877055883407593

Epoch: 6| Step: 2
Training loss: 3.381763458251953
Validation loss: 2.9843537012736

Epoch: 6| Step: 3
Training loss: 3.3411731719970703
Validation loss: 2.9806171655654907

Epoch: 6| Step: 4
Training loss: 3.0261614322662354
Validation loss: 2.977096756299337

Epoch: 6| Step: 5
Training loss: 2.5241942405700684
Validation loss: 2.9737083117167153

Epoch: 6| Step: 6
Training loss: 2.9434776306152344
Validation loss: 2.9703548749287925

Epoch: 6| Step: 7
Training loss: 4.530759811401367
Validation loss: 2.96664289633433

Epoch: 6| Step: 8
Training loss: 2.664733409881592
Validation loss: 2.9632343451182046

Epoch: 6| Step: 9
Training loss: 2.962833881378174
Validation loss: 2.9597678581873574

Epoch: 6| Step: 10
Training loss: 2.6188666820526123
Validation loss: 2.9565380811691284

Epoch: 6| Step: 11
Training loss: 3.1458497047424316
Validation loss: 2.9534095923105874

Epoch: 6| Step: 12
Training loss: 3.109182834625244
Validation loss: 2.9501578410466514

Epoch: 6| Step: 13
Training loss: 2.7468419075012207
Validation loss: 2.9471128384272256

Epoch: 36| Step: 0
Training loss: 3.8686938285827637
Validation loss: 2.943982203801473

Epoch: 6| Step: 1
Training loss: 2.3338756561279297
Validation loss: 2.9406920274098716

Epoch: 6| Step: 2
Training loss: 3.003877639770508
Validation loss: 2.937471071879069

Epoch: 6| Step: 3
Training loss: 3.0399038791656494
Validation loss: 2.934433102607727

Epoch: 6| Step: 4
Training loss: 2.8770925998687744
Validation loss: 2.931390722592672

Epoch: 6| Step: 5
Training loss: 3.6899020671844482
Validation loss: 2.9284913539886475

Epoch: 6| Step: 6
Training loss: 2.9601094722747803
Validation loss: 2.925354480743408

Epoch: 6| Step: 7
Training loss: 2.6784374713897705
Validation loss: 2.922378897666931

Epoch: 6| Step: 8
Training loss: 3.6255717277526855
Validation loss: 2.919084986050924

Epoch: 6| Step: 9
Training loss: 2.9043309688568115
Validation loss: 2.9160147110621133

Epoch: 6| Step: 10
Training loss: 3.721406936645508
Validation loss: 2.9128673871358237

Epoch: 6| Step: 11
Training loss: 3.43953800201416
Validation loss: 2.909727136294047

Epoch: 6| Step: 12
Training loss: 2.212634563446045
Validation loss: 2.9063849449157715

Epoch: 6| Step: 13
Training loss: 3.442924737930298
Validation loss: 2.903433918952942

Epoch: 37| Step: 0
Training loss: 3.390014410018921
Validation loss: 2.900586644808451

Epoch: 6| Step: 1
Training loss: 3.4082860946655273
Validation loss: 2.897373537222544

Epoch: 6| Step: 2
Training loss: 3.6634488105773926
Validation loss: 2.894141952196757

Epoch: 6| Step: 3
Training loss: 3.1232030391693115
Validation loss: 2.891022562980652

Epoch: 6| Step: 4
Training loss: 3.231808662414551
Validation loss: 2.8879687388738

Epoch: 6| Step: 5
Training loss: 3.1665258407592773
Validation loss: 2.8850797414779663

Epoch: 6| Step: 6
Training loss: 2.3478355407714844
Validation loss: 2.881808082262675

Epoch: 6| Step: 7
Training loss: 2.647874593734741
Validation loss: 2.8788490295410156

Epoch: 6| Step: 8
Training loss: 2.639234781265259
Validation loss: 2.8759144941965737

Epoch: 6| Step: 9
Training loss: 2.4093384742736816
Validation loss: 2.8727510372797647

Epoch: 6| Step: 10
Training loss: 3.5308730602264404
Validation loss: 2.869961698849996

Epoch: 6| Step: 11
Training loss: 3.6591317653656006
Validation loss: 2.867013136545817

Epoch: 6| Step: 12
Training loss: 3.269617795944214
Validation loss: 2.8638071616490683

Epoch: 6| Step: 13
Training loss: 2.7721312046051025
Validation loss: 2.8607786496480307

Epoch: 38| Step: 0
Training loss: 3.1485886573791504
Validation loss: 2.8580089807510376

Epoch: 6| Step: 1
Training loss: 3.0890378952026367
Validation loss: 2.8549114068349204

Epoch: 6| Step: 2
Training loss: 2.8787708282470703
Validation loss: 2.8520161708196006

Epoch: 6| Step: 3
Training loss: 2.6402761936187744
Validation loss: 2.849412759145101

Epoch: 6| Step: 4
Training loss: 3.3151378631591797
Validation loss: 2.8467161655426025

Epoch: 6| Step: 5
Training loss: 2.8026976585388184
Validation loss: 2.844048023223877

Epoch: 6| Step: 6
Training loss: 3.597270965576172
Validation loss: 2.8413769006729126

Epoch: 6| Step: 7
Training loss: 3.2436280250549316
Validation loss: 2.8384387493133545

Epoch: 6| Step: 8
Training loss: 3.262735366821289
Validation loss: 2.835675835609436

Epoch: 6| Step: 9
Training loss: 2.7425971031188965
Validation loss: 2.8327405055363974

Epoch: 6| Step: 10
Training loss: 2.851719379425049
Validation loss: 2.8301936785380044

Epoch: 6| Step: 11
Training loss: 2.65975284576416
Validation loss: 2.827327847480774

Epoch: 6| Step: 12
Training loss: 3.0554304122924805
Validation loss: 2.8244536320368447

Epoch: 6| Step: 13
Training loss: 3.4237775802612305
Validation loss: 2.821518858273824

Epoch: 39| Step: 0
Training loss: 2.6621479988098145
Validation loss: 2.8183302879333496

Epoch: 6| Step: 1
Training loss: 2.785728931427002
Validation loss: 2.8157551288604736

Epoch: 6| Step: 2
Training loss: 3.176326274871826
Validation loss: 2.8131760160128274

Epoch: 6| Step: 3
Training loss: 3.52327823638916
Validation loss: 2.810788949330648

Epoch: 6| Step: 4
Training loss: 2.285928726196289
Validation loss: 2.807958642641703

Epoch: 6| Step: 5
Training loss: 2.9654574394226074
Validation loss: 2.8054208755493164

Epoch: 6| Step: 6
Training loss: 3.1741890907287598
Validation loss: 2.8027984301249185

Epoch: 6| Step: 7
Training loss: 3.7765209674835205
Validation loss: 2.8000274499257407

Epoch: 6| Step: 8
Training loss: 3.4095194339752197
Validation loss: 2.7973324060440063

Epoch: 6| Step: 9
Training loss: 3.188356399536133
Validation loss: 2.7946240504582724

Epoch: 6| Step: 10
Training loss: 3.2041759490966797
Validation loss: 2.7916064659754434

Epoch: 6| Step: 11
Training loss: 2.2310876846313477
Validation loss: 2.7884725530942283

Epoch: 6| Step: 12
Training loss: 3.045557975769043
Validation loss: 2.785989761352539

Epoch: 6| Step: 13
Training loss: 2.7614383697509766
Validation loss: 2.7830477555592856

Epoch: 40| Step: 0
Training loss: 3.6471285820007324
Validation loss: 2.780264695485433

Epoch: 6| Step: 1
Training loss: 2.91568922996521
Validation loss: 2.777525266011556

Epoch: 6| Step: 2
Training loss: 2.835927724838257
Validation loss: 2.7747966845830283

Epoch: 6| Step: 3
Training loss: 2.7668449878692627
Validation loss: 2.772495905558268

Epoch: 6| Step: 4
Training loss: 3.128220796585083
Validation loss: 2.7699023485183716

Epoch: 6| Step: 5
Training loss: 2.9235026836395264
Validation loss: 2.767128070195516

Epoch: 6| Step: 6
Training loss: 3.0887820720672607
Validation loss: 2.7646928230921426

Epoch: 6| Step: 7
Training loss: 3.1886110305786133
Validation loss: 2.7622899214426675

Epoch: 6| Step: 8
Training loss: 2.6376569271087646
Validation loss: 2.759708046913147

Epoch: 6| Step: 9
Training loss: 3.102074384689331
Validation loss: 2.7570501963297525

Epoch: 6| Step: 10
Training loss: 3.301023244857788
Validation loss: 2.7543245553970337

Epoch: 6| Step: 11
Training loss: 2.7466394901275635
Validation loss: 2.751520792643229

Epoch: 6| Step: 12
Training loss: 2.9223616123199463
Validation loss: 2.7486734986305237

Epoch: 6| Step: 13
Training loss: 2.44631290435791
Validation loss: 2.7460285425186157

Epoch: 41| Step: 0
Training loss: 2.3533546924591064
Validation loss: 2.7433252731959024

Epoch: 6| Step: 1
Training loss: 3.321239471435547
Validation loss: 2.7409510612487793

Epoch: 6| Step: 2
Training loss: 2.3520898818969727
Validation loss: 2.7382563749949136

Epoch: 6| Step: 3
Training loss: 2.58835506439209
Validation loss: 2.7357539335886636

Epoch: 6| Step: 4
Training loss: 3.581301689147949
Validation loss: 2.733399589856466

Epoch: 6| Step: 5
Training loss: 3.121128559112549
Validation loss: 2.7307282288869223

Epoch: 6| Step: 6
Training loss: 2.888154983520508
Validation loss: 2.728089968363444

Epoch: 6| Step: 7
Training loss: 3.1608986854553223
Validation loss: 2.725516676902771

Epoch: 6| Step: 8
Training loss: 2.835982322692871
Validation loss: 2.7228962182998657

Epoch: 6| Step: 9
Training loss: 2.997375011444092
Validation loss: 2.7203812996546426

Epoch: 6| Step: 10
Training loss: 2.9033474922180176
Validation loss: 2.717809557914734

Epoch: 6| Step: 11
Training loss: 3.1136224269866943
Validation loss: 2.7150970300038657

Epoch: 6| Step: 12
Training loss: 3.1217551231384277
Validation loss: 2.712480306625366

Epoch: 6| Step: 13
Training loss: 2.7594170570373535
Validation loss: 2.709751089413961

Epoch: 42| Step: 0
Training loss: 3.0339584350585938
Validation loss: 2.7069730361302695

Epoch: 6| Step: 1
Training loss: 3.317857027053833
Validation loss: 2.704542557398478

Epoch: 6| Step: 2
Training loss: 2.5577054023742676
Validation loss: 2.7018011013666787

Epoch: 6| Step: 3
Training loss: 3.0468544960021973
Validation loss: 2.699122945467631

Epoch: 6| Step: 4
Training loss: 2.643247365951538
Validation loss: 2.69625186920166

Epoch: 6| Step: 5
Training loss: 3.0092413425445557
Validation loss: 2.6934292316436768

Epoch: 6| Step: 6
Training loss: 2.970186948776245
Validation loss: 2.690853158632914

Epoch: 6| Step: 7
Training loss: 2.3911290168762207
Validation loss: 2.6881303787231445

Epoch: 6| Step: 8
Training loss: 3.191682815551758
Validation loss: 2.6859048207600913

Epoch: 6| Step: 9
Training loss: 2.7051806449890137
Validation loss: 2.68349552154541

Epoch: 6| Step: 10
Training loss: 2.758967399597168
Validation loss: 2.681289315223694

Epoch: 6| Step: 11
Training loss: 3.2150938510894775
Validation loss: 2.6791763305664062

Epoch: 6| Step: 12
Training loss: 3.6724913120269775
Validation loss: 2.676706592241923

Epoch: 6| Step: 13
Training loss: 2.0319788455963135
Validation loss: 2.6742709477742515

Epoch: 43| Step: 0
Training loss: 3.012511968612671
Validation loss: 2.671432296435038

Epoch: 6| Step: 1
Training loss: 3.809739589691162
Validation loss: 2.6686583360036216

Epoch: 6| Step: 2
Training loss: 2.494093179702759
Validation loss: 2.6660452683766684

Epoch: 6| Step: 3
Training loss: 3.2746334075927734
Validation loss: 2.66330095132192

Epoch: 6| Step: 4
Training loss: 3.4087226390838623
Validation loss: 2.6603556474049888

Epoch: 6| Step: 5
Training loss: 2.1693124771118164
Validation loss: 2.657499353090922

Epoch: 6| Step: 6
Training loss: 2.9925272464752197
Validation loss: 2.6549098889033

Epoch: 6| Step: 7
Training loss: 2.9534263610839844
Validation loss: 2.652162035306295

Epoch: 6| Step: 8
Training loss: 3.040442943572998
Validation loss: 2.649677058060964

Epoch: 6| Step: 9
Training loss: 2.6495680809020996
Validation loss: 2.6469082037607827

Epoch: 6| Step: 10
Training loss: 2.7241382598876953
Validation loss: 2.6441502571105957

Epoch: 6| Step: 11
Training loss: 2.5691044330596924
Validation loss: 2.641355117162069

Epoch: 6| Step: 12
Training loss: 2.8030691146850586
Validation loss: 2.6386619011561074

Epoch: 6| Step: 13
Training loss: 2.1411900520324707
Validation loss: 2.6361429691314697

Epoch: 44| Step: 0
Training loss: 2.968179225921631
Validation loss: 2.6335920890172324

Epoch: 6| Step: 1
Training loss: 2.8106155395507812
Validation loss: 2.631309668223063

Epoch: 6| Step: 2
Training loss: 2.9199886322021484
Validation loss: 2.62883468468984

Epoch: 6| Step: 3
Training loss: 3.160489559173584
Validation loss: 2.6263620456059775

Epoch: 6| Step: 4
Training loss: 2.2536733150482178
Validation loss: 2.6237195332845054

Epoch: 6| Step: 5
Training loss: 3.022128105163574
Validation loss: 2.621126333872477

Epoch: 6| Step: 6
Training loss: 3.503223419189453
Validation loss: 2.6184640328089395

Epoch: 6| Step: 7
Training loss: 2.057739496231079
Validation loss: 2.6157263914744058

Epoch: 6| Step: 8
Training loss: 3.1585612297058105
Validation loss: 2.6129453579584756

Epoch: 6| Step: 9
Training loss: 3.025993824005127
Validation loss: 2.61041792233785

Epoch: 6| Step: 10
Training loss: 3.1040477752685547
Validation loss: 2.607769330342611

Epoch: 6| Step: 11
Training loss: 2.5203380584716797
Validation loss: 2.605257272720337

Epoch: 6| Step: 12
Training loss: 2.8679885864257812
Validation loss: 2.602763215700785

Epoch: 6| Step: 13
Training loss: 2.1286511421203613
Validation loss: 2.6002997557322183

Epoch: 45| Step: 0
Training loss: 2.318023920059204
Validation loss: 2.597692092259725

Epoch: 6| Step: 1
Training loss: 3.1402406692504883
Validation loss: 2.595263421535492

Epoch: 6| Step: 2
Training loss: 2.5173912048339844
Validation loss: 2.592949151992798

Epoch: 6| Step: 3
Training loss: 2.4658355712890625
Validation loss: 2.5906022787094116

Epoch: 6| Step: 4
Training loss: 3.6760904788970947
Validation loss: 2.5881519317626953

Epoch: 6| Step: 5
Training loss: 2.8041489124298096
Validation loss: 2.585857113202413

Epoch: 6| Step: 6
Training loss: 3.0271642208099365
Validation loss: 2.583454966545105

Epoch: 6| Step: 7
Training loss: 2.4448883533477783
Validation loss: 2.5811583598454795

Epoch: 6| Step: 8
Training loss: 2.502168893814087
Validation loss: 2.5788955291112265

Epoch: 6| Step: 9
Training loss: 3.1434693336486816
Validation loss: 2.576823631922404

Epoch: 6| Step: 10
Training loss: 3.1518547534942627
Validation loss: 2.574511011441549

Epoch: 6| Step: 11
Training loss: 2.8983781337738037
Validation loss: 2.572275956471761

Epoch: 6| Step: 12
Training loss: 1.926354169845581
Validation loss: 2.56986137231191

Epoch: 6| Step: 13
Training loss: 2.955293655395508
Validation loss: 2.5674474239349365

Epoch: 46| Step: 0
Training loss: 2.201162815093994
Validation loss: 2.5651899178822837

Epoch: 6| Step: 1
Training loss: 2.9988515377044678
Validation loss: 2.562541047732035

Epoch: 6| Step: 2
Training loss: 3.389456272125244
Validation loss: 2.560629367828369

Epoch: 6| Step: 3
Training loss: 2.540479898452759
Validation loss: 2.557632843653361

Epoch: 6| Step: 4
Training loss: 2.819340705871582
Validation loss: 2.555248816808065

Epoch: 6| Step: 5
Training loss: 2.643892288208008
Validation loss: 2.5529621044794717

Epoch: 6| Step: 6
Training loss: 2.4863133430480957
Validation loss: 2.5513917207717896

Epoch: 6| Step: 7
Training loss: 2.631587028503418
Validation loss: 2.550738533337911

Epoch: 6| Step: 8
Training loss: 3.444887638092041
Validation loss: 2.545087973276774

Epoch: 6| Step: 9
Training loss: 2.846926689147949
Validation loss: 2.5434868335723877

Epoch: 6| Step: 10
Training loss: 2.3212890625
Validation loss: 2.54170294602712

Epoch: 6| Step: 11
Training loss: 2.836768865585327
Validation loss: 2.5400532484054565

Epoch: 6| Step: 12
Training loss: 3.1251349449157715
Validation loss: 2.538003404935201

Epoch: 6| Step: 13
Training loss: 2.1957902908325195
Validation loss: 2.536155660947164

Epoch: 47| Step: 0
Training loss: 3.090557336807251
Validation loss: 2.535603125890096

Epoch: 6| Step: 1
Training loss: 2.5824663639068604
Validation loss: 2.5331779519716897

Epoch: 6| Step: 2
Training loss: 2.613461494445801
Validation loss: 2.530491669972738

Epoch: 6| Step: 3
Training loss: 2.3804516792297363
Validation loss: 2.5275885661443076

Epoch: 6| Step: 4
Training loss: 2.180708885192871
Validation loss: 2.5256394147872925

Epoch: 6| Step: 5
Training loss: 2.6130619049072266
Validation loss: 2.5231704115867615

Epoch: 6| Step: 6
Training loss: 2.9156131744384766
Validation loss: 2.5211355686187744

Epoch: 6| Step: 7
Training loss: 2.6603691577911377
Validation loss: 2.519231915473938

Epoch: 6| Step: 8
Training loss: 3.0452334880828857
Validation loss: 2.5171281894048056

Epoch: 6| Step: 9
Training loss: 3.2274978160858154
Validation loss: 2.514956792195638

Epoch: 6| Step: 10
Training loss: 2.8113772869110107
Validation loss: 2.5126835107803345

Epoch: 6| Step: 11
Training loss: 3.203275680541992
Validation loss: 2.510373870531718

Epoch: 6| Step: 12
Training loss: 2.4159016609191895
Validation loss: 2.5087390343348184

Epoch: 6| Step: 13
Training loss: 2.2690136432647705
Validation loss: 2.5059461990992227

Epoch: 48| Step: 0
Training loss: 2.258805990219116
Validation loss: 2.503576119740804

Epoch: 6| Step: 1
Training loss: 3.211649179458618
Validation loss: 2.501317322254181

Epoch: 6| Step: 2
Training loss: 2.6756417751312256
Validation loss: 2.499041438102722

Epoch: 6| Step: 3
Training loss: 2.543814182281494
Validation loss: 2.4967891375223794

Epoch: 6| Step: 4
Training loss: 2.834796905517578
Validation loss: 2.493993560473124

Epoch: 6| Step: 5
Training loss: 2.235058307647705
Validation loss: 2.4918697675069175

Epoch: 6| Step: 6
Training loss: 2.334827184677124
Validation loss: 2.4893582264582315

Epoch: 6| Step: 7
Training loss: 2.829786777496338
Validation loss: 2.486906806627909

Epoch: 6| Step: 8
Training loss: 2.6222376823425293
Validation loss: 2.4849090576171875

Epoch: 6| Step: 9
Training loss: 2.9004359245300293
Validation loss: 2.4826318422953286

Epoch: 6| Step: 10
Training loss: 3.359720230102539
Validation loss: 2.4805926084518433

Epoch: 6| Step: 11
Training loss: 2.402613639831543
Validation loss: 2.4784621000289917

Epoch: 6| Step: 12
Training loss: 2.968820333480835
Validation loss: 2.4762731790542603

Epoch: 6| Step: 13
Training loss: 2.365147590637207
Validation loss: 2.474043289820353

Epoch: 49| Step: 0
Training loss: 2.8932952880859375
Validation loss: 2.471760352452596

Epoch: 6| Step: 1
Training loss: 2.498371124267578
Validation loss: 2.4699999888738

Epoch: 6| Step: 2
Training loss: 1.9801090955734253
Validation loss: 2.467872937520345

Epoch: 6| Step: 3
Training loss: 3.3191118240356445
Validation loss: 2.4660515785217285

Epoch: 6| Step: 4
Training loss: 2.8687191009521484
Validation loss: 2.463853398958842

Epoch: 6| Step: 5
Training loss: 2.0823476314544678
Validation loss: 2.461714188257853

Epoch: 6| Step: 6
Training loss: 2.9040255546569824
Validation loss: 2.459835728009542

Epoch: 6| Step: 7
Training loss: 2.8116023540496826
Validation loss: 2.4578485091527305

Epoch: 6| Step: 8
Training loss: 3.036442756652832
Validation loss: 2.455721934636434

Epoch: 6| Step: 9
Training loss: 2.7396316528320312
Validation loss: 2.453270196914673

Epoch: 6| Step: 10
Training loss: 2.6528475284576416
Validation loss: 2.451342145601908

Epoch: 6| Step: 11
Training loss: 2.7316691875457764
Validation loss: 2.4489834308624268

Epoch: 6| Step: 12
Training loss: 1.7031069993972778
Validation loss: 2.446722467740377

Epoch: 6| Step: 13
Training loss: 2.8428680896759033
Validation loss: 2.4442837834358215

Epoch: 50| Step: 0
Training loss: 3.43131160736084
Validation loss: 2.4421537121136985

Epoch: 6| Step: 1
Training loss: 2.0848212242126465
Validation loss: 2.439811944961548

Epoch: 6| Step: 2
Training loss: 2.204432487487793
Validation loss: 2.4374477863311768

Epoch: 6| Step: 3
Training loss: 2.6766855716705322
Validation loss: 2.4349615375200906

Epoch: 6| Step: 4
Training loss: 1.8327217102050781
Validation loss: 2.432941416899363

Epoch: 6| Step: 5
Training loss: 2.318927049636841
Validation loss: 2.430838187535604

Epoch: 6| Step: 6
Training loss: 2.5731115341186523
Validation loss: 2.42889932791392

Epoch: 6| Step: 7
Training loss: 3.031324863433838
Validation loss: 2.4267322619756064

Epoch: 6| Step: 8
Training loss: 2.1014018058776855
Validation loss: 2.424152751763662

Epoch: 6| Step: 9
Training loss: 3.3087706565856934
Validation loss: 2.4226220846176147

Epoch: 6| Step: 10
Training loss: 2.8472273349761963
Validation loss: 2.42032124598821

Epoch: 6| Step: 11
Training loss: 2.973188638687134
Validation loss: 2.4183199405670166

Epoch: 6| Step: 12
Training loss: 2.827392578125
Validation loss: 2.4164258241653442

Epoch: 6| Step: 13
Training loss: 2.4007270336151123
Validation loss: 2.4146284262339273

Testing loss: 2.018547805950796
