Epoch: 1| Step: 0
Training loss: 5.230801582336426
Validation loss: 5.2546117305755615

Epoch: 6| Step: 1
Training loss: 4.610622406005859
Validation loss: 5.25338880221049

Epoch: 6| Step: 2
Training loss: 5.984387397766113
Validation loss: 5.252218961715698

Epoch: 6| Step: 3
Training loss: 5.295839309692383
Validation loss: 5.25104284286499

Epoch: 6| Step: 4
Training loss: 5.488499641418457
Validation loss: 5.249902009963989

Epoch: 6| Step: 5
Training loss: 5.451380729675293
Validation loss: 5.248804648717244

Epoch: 6| Step: 6
Training loss: 4.8736891746521
Validation loss: 5.247666200002034

Epoch: 6| Step: 7
Training loss: 5.597475051879883
Validation loss: 5.246583541234334

Epoch: 6| Step: 8
Training loss: 4.034325122833252
Validation loss: 5.245478232701619

Epoch: 6| Step: 9
Training loss: 5.895356178283691
Validation loss: 5.24427588780721

Epoch: 6| Step: 10
Training loss: 5.01875114440918
Validation loss: 5.243169546127319

Epoch: 6| Step: 11
Training loss: 5.443429946899414
Validation loss: 5.241954485575358

Epoch: 6| Step: 12
Training loss: 6.758649826049805
Validation loss: 5.240676800409953

Epoch: 6| Step: 13
Training loss: 4.747930526733398
Validation loss: 5.239377657572429

Epoch: 2| Step: 0
Training loss: 5.8069562911987305
Validation loss: 5.238078594207764

Epoch: 6| Step: 1
Training loss: 5.080560684204102
Validation loss: 5.236658016840617

Epoch: 6| Step: 2
Training loss: 4.45054817199707
Validation loss: 5.235188802083333

Epoch: 6| Step: 3
Training loss: 5.640597343444824
Validation loss: 5.233757654825847

Epoch: 6| Step: 4
Training loss: 4.664234161376953
Validation loss: 5.232101360956828

Epoch: 6| Step: 5
Training loss: 5.593975067138672
Validation loss: 5.2304848829905195

Epoch: 6| Step: 6
Training loss: 6.142273902893066
Validation loss: 5.228729009628296

Epoch: 6| Step: 7
Training loss: 4.773194313049316
Validation loss: 5.226955811182658

Epoch: 6| Step: 8
Training loss: 4.986915111541748
Validation loss: 5.225038846333821

Epoch: 6| Step: 9
Training loss: 5.05573844909668
Validation loss: 5.222979386647542

Epoch: 6| Step: 10
Training loss: 5.256077766418457
Validation loss: 5.220811208089192

Epoch: 6| Step: 11
Training loss: 5.980495929718018
Validation loss: 5.218611876169841

Epoch: 6| Step: 12
Training loss: 4.83820915222168
Validation loss: 5.21611754099528

Epoch: 6| Step: 13
Training loss: 5.8842973709106445
Validation loss: 5.213564316431682

Epoch: 3| Step: 0
Training loss: 3.926072835922241
Validation loss: 5.210892120997111

Epoch: 6| Step: 1
Training loss: 6.454198360443115
Validation loss: 5.208070198694865

Epoch: 6| Step: 2
Training loss: 4.759775161743164
Validation loss: 5.205046892166138

Epoch: 6| Step: 3
Training loss: 4.588837623596191
Validation loss: 5.201884190241496

Epoch: 6| Step: 4
Training loss: 5.038322448730469
Validation loss: 5.1984357833862305

Epoch: 6| Step: 5
Training loss: 5.204844951629639
Validation loss: 5.1949881712595625

Epoch: 6| Step: 6
Training loss: 6.109920024871826
Validation loss: 5.191224495569865

Epoch: 6| Step: 7
Training loss: 5.836164474487305
Validation loss: 5.187354485193889

Epoch: 6| Step: 8
Training loss: 4.684935569763184
Validation loss: 5.1831324100494385

Epoch: 6| Step: 9
Training loss: 5.547076225280762
Validation loss: 5.178629239400228

Epoch: 6| Step: 10
Training loss: 5.288195610046387
Validation loss: 5.173998514811198

Epoch: 6| Step: 11
Training loss: 6.75966739654541
Validation loss: 5.169226169586182

Epoch: 6| Step: 12
Training loss: 4.953917026519775
Validation loss: 5.164141575495402

Epoch: 6| Step: 13
Training loss: 4.461027145385742
Validation loss: 5.158594687779744

Epoch: 4| Step: 0
Training loss: 4.979877471923828
Validation loss: 5.1530998547871905

Epoch: 6| Step: 1
Training loss: 5.065993309020996
Validation loss: 5.147212187449138

Epoch: 6| Step: 2
Training loss: 4.834868431091309
Validation loss: 5.140974044799805

Epoch: 6| Step: 3
Training loss: 4.726828575134277
Validation loss: 5.134720325469971

Epoch: 6| Step: 4
Training loss: 5.458305835723877
Validation loss: 5.127852996190389

Epoch: 6| Step: 5
Training loss: 5.904215335845947
Validation loss: 5.121070226033528

Epoch: 6| Step: 6
Training loss: 5.122128009796143
Validation loss: 5.113947470982869

Epoch: 6| Step: 7
Training loss: 4.960588455200195
Validation loss: 5.106382449467977

Epoch: 6| Step: 8
Training loss: 5.464336395263672
Validation loss: 5.098556200663249

Epoch: 6| Step: 9
Training loss: 5.140429973602295
Validation loss: 5.090635617574056

Epoch: 6| Step: 10
Training loss: 5.858306884765625
Validation loss: 5.082238117853801

Epoch: 6| Step: 11
Training loss: 6.230157852172852
Validation loss: 5.0737727880477905

Epoch: 6| Step: 12
Training loss: 4.709571838378906
Validation loss: 5.065077384312947

Epoch: 6| Step: 13
Training loss: 4.077960014343262
Validation loss: 5.056317488352458

Epoch: 5| Step: 0
Training loss: 4.580169677734375
Validation loss: 5.047182718912761

Epoch: 6| Step: 1
Training loss: 5.1986870765686035
Validation loss: 5.037939389546712

Epoch: 6| Step: 2
Training loss: 5.6760053634643555
Validation loss: 5.028400977452596

Epoch: 6| Step: 3
Training loss: 5.3842291831970215
Validation loss: 5.019069592158

Epoch: 6| Step: 4
Training loss: 5.265374660491943
Validation loss: 5.0094254811604815

Epoch: 6| Step: 5
Training loss: 4.742720603942871
Validation loss: 4.99956742922465

Epoch: 6| Step: 6
Training loss: 5.246579170227051
Validation loss: 4.9894726276397705

Epoch: 6| Step: 7
Training loss: 4.9959025382995605
Validation loss: 4.979419310887654

Epoch: 6| Step: 8
Training loss: 4.891874313354492
Validation loss: 4.9695877234141035

Epoch: 6| Step: 9
Training loss: 4.289090156555176
Validation loss: 4.959172248840332

Epoch: 6| Step: 10
Training loss: 4.098703384399414
Validation loss: 4.94911257425944

Epoch: 6| Step: 11
Training loss: 5.135862350463867
Validation loss: 4.93866244951884

Epoch: 6| Step: 12
Training loss: 5.342451572418213
Validation loss: 4.927630662918091

Epoch: 6| Step: 13
Training loss: 6.046807289123535
Validation loss: 4.917585929234822

Epoch: 6| Step: 0
Training loss: 5.939849853515625
Validation loss: 4.906690200169881

Epoch: 6| Step: 1
Training loss: 5.696685791015625
Validation loss: 4.896567980448405

Epoch: 6| Step: 2
Training loss: 4.7414703369140625
Validation loss: 4.886435906092326

Epoch: 6| Step: 3
Training loss: 5.384474754333496
Validation loss: 4.876439332962036

Epoch: 6| Step: 4
Training loss: 4.283936500549316
Validation loss: 4.8663859367370605

Epoch: 6| Step: 5
Training loss: 3.766268014907837
Validation loss: 4.856672128041585

Epoch: 6| Step: 6
Training loss: 4.936852931976318
Validation loss: 4.847205241521199

Epoch: 6| Step: 7
Training loss: 4.430996417999268
Validation loss: 4.837266604105632

Epoch: 6| Step: 8
Training loss: 4.9547319412231445
Validation loss: 4.827927827835083

Epoch: 6| Step: 9
Training loss: 5.579807758331299
Validation loss: 4.818657159805298

Epoch: 6| Step: 10
Training loss: 4.720920085906982
Validation loss: 4.809251467386882

Epoch: 6| Step: 11
Training loss: 4.796354293823242
Validation loss: 4.799690405527751

Epoch: 6| Step: 12
Training loss: 5.06498908996582
Validation loss: 4.790714422861735

Epoch: 6| Step: 13
Training loss: 4.706043720245361
Validation loss: 4.78112272421519

Epoch: 7| Step: 0
Training loss: 5.049461364746094
Validation loss: 4.771509289741516

Epoch: 6| Step: 1
Training loss: 5.184792518615723
Validation loss: 4.76207160949707

Epoch: 6| Step: 2
Training loss: 4.554337024688721
Validation loss: 4.752044200897217

Epoch: 6| Step: 3
Training loss: 5.131595611572266
Validation loss: 4.742617130279541

Epoch: 6| Step: 4
Training loss: 5.4922709465026855
Validation loss: 4.733056306838989

Epoch: 6| Step: 5
Training loss: 5.384531021118164
Validation loss: 4.723652362823486

Epoch: 6| Step: 6
Training loss: 4.955076217651367
Validation loss: 4.714123924573262

Epoch: 6| Step: 7
Training loss: 5.36878776550293
Validation loss: 4.705422878265381

Epoch: 6| Step: 8
Training loss: 4.939489364624023
Validation loss: 4.696630636850993

Epoch: 6| Step: 9
Training loss: 4.921154975891113
Validation loss: 4.68836251894633

Epoch: 6| Step: 10
Training loss: 3.625004529953003
Validation loss: 4.6805269320805865

Epoch: 6| Step: 11
Training loss: 4.30191707611084
Validation loss: 4.672611236572266

Epoch: 6| Step: 12
Training loss: 4.1036810874938965
Validation loss: 4.6656250556310015

Epoch: 6| Step: 13
Training loss: 4.282898902893066
Validation loss: 4.65909481048584

Epoch: 8| Step: 0
Training loss: 3.9325785636901855
Validation loss: 4.652375221252441

Epoch: 6| Step: 1
Training loss: 5.00103759765625
Validation loss: 4.645545323689778

Epoch: 6| Step: 2
Training loss: 5.1472883224487305
Validation loss: 4.63936448097229

Epoch: 6| Step: 3
Training loss: 4.249013423919678
Validation loss: 4.63293977578481

Epoch: 6| Step: 4
Training loss: 4.181231498718262
Validation loss: 4.6268612543741865

Epoch: 6| Step: 5
Training loss: 5.422133922576904
Validation loss: 4.620896617571513

Epoch: 6| Step: 6
Training loss: 4.747838020324707
Validation loss: 4.614599704742432

Epoch: 6| Step: 7
Training loss: 5.510166645050049
Validation loss: 4.608941435813904

Epoch: 6| Step: 8
Training loss: 4.3931989669799805
Validation loss: 4.602848092714946

Epoch: 6| Step: 9
Training loss: 3.6258273124694824
Validation loss: 4.596457044283549

Epoch: 6| Step: 10
Training loss: 3.8632149696350098
Validation loss: 4.590701659520467

Epoch: 6| Step: 11
Training loss: 5.0119733810424805
Validation loss: 4.584436933199565

Epoch: 6| Step: 12
Training loss: 5.41422700881958
Validation loss: 4.5785683790842695

Epoch: 6| Step: 13
Training loss: 5.450811862945557
Validation loss: 4.5725981791814165

Epoch: 9| Step: 0
Training loss: 4.478140830993652
Validation loss: 4.5667994022369385

Epoch: 6| Step: 1
Training loss: 5.560129642486572
Validation loss: 4.560752431551616

Epoch: 6| Step: 2
Training loss: 4.336154937744141
Validation loss: 4.554885188738505

Epoch: 6| Step: 3
Training loss: 6.355695724487305
Validation loss: 4.548823833465576

Epoch: 6| Step: 4
Training loss: 4.9417724609375
Validation loss: 4.543062130610148

Epoch: 6| Step: 5
Training loss: 3.6143689155578613
Validation loss: 4.536839485168457

Epoch: 6| Step: 6
Training loss: 4.880417823791504
Validation loss: 4.53126585483551

Epoch: 6| Step: 7
Training loss: 4.161691665649414
Validation loss: 4.525416612625122

Epoch: 6| Step: 8
Training loss: 4.223682403564453
Validation loss: 4.520210027694702

Epoch: 6| Step: 9
Training loss: 5.196083068847656
Validation loss: 4.514734109242757

Epoch: 6| Step: 10
Training loss: 5.169544219970703
Validation loss: 4.509508689244588

Epoch: 6| Step: 11
Training loss: 4.302642822265625
Validation loss: 4.504746516545613

Epoch: 6| Step: 12
Training loss: 3.5578014850616455
Validation loss: 4.499646743138631

Epoch: 6| Step: 13
Training loss: 4.087107181549072
Validation loss: 4.494819720586141

Epoch: 10| Step: 0
Training loss: 4.899737358093262
Validation loss: 4.490002353986104

Epoch: 6| Step: 1
Training loss: 4.377215385437012
Validation loss: 4.4846716324488325

Epoch: 6| Step: 2
Training loss: 3.897902011871338
Validation loss: 4.479726791381836

Epoch: 6| Step: 3
Training loss: 4.093852996826172
Validation loss: 4.474822918574016

Epoch: 6| Step: 4
Training loss: 4.876453876495361
Validation loss: 4.469848076502482

Epoch: 6| Step: 5
Training loss: 4.412220001220703
Validation loss: 4.464672048886617

Epoch: 6| Step: 6
Training loss: 5.163041114807129
Validation loss: 4.459347724914551

Epoch: 6| Step: 7
Training loss: 3.4507699012756348
Validation loss: 4.4545298020044966

Epoch: 6| Step: 8
Training loss: 4.277406692504883
Validation loss: 4.449564019838969

Epoch: 6| Step: 9
Training loss: 6.367592811584473
Validation loss: 4.444499254226685

Epoch: 6| Step: 10
Training loss: 4.388759613037109
Validation loss: 4.439209262530009

Epoch: 6| Step: 11
Training loss: 4.465895175933838
Validation loss: 4.434473951657613

Epoch: 6| Step: 12
Training loss: 5.699879169464111
Validation loss: 4.429185589154561

Epoch: 6| Step: 13
Training loss: 3.563354253768921
Validation loss: 4.424013257026672

Epoch: 11| Step: 0
Training loss: 5.05033540725708
Validation loss: 4.418840686480205

Epoch: 6| Step: 1
Training loss: 5.521147727966309
Validation loss: 4.413705786069234

Epoch: 6| Step: 2
Training loss: 4.051791191101074
Validation loss: 4.408464709917705

Epoch: 6| Step: 3
Training loss: 4.175071716308594
Validation loss: 4.403323133786519

Epoch: 6| Step: 4
Training loss: 3.185431957244873
Validation loss: 4.398300528526306

Epoch: 6| Step: 5
Training loss: 5.404836177825928
Validation loss: 4.393188873926799

Epoch: 6| Step: 6
Training loss: 4.380406379699707
Validation loss: 4.388388633728027

Epoch: 6| Step: 7
Training loss: 4.053016662597656
Validation loss: 4.383222063382466

Epoch: 6| Step: 8
Training loss: 4.335979461669922
Validation loss: 4.378321687380473

Epoch: 6| Step: 9
Training loss: 4.591340065002441
Validation loss: 4.373013496398926

Epoch: 6| Step: 10
Training loss: 4.499112129211426
Validation loss: 4.367790063222249

Epoch: 6| Step: 11
Training loss: 4.275392532348633
Validation loss: 4.362845778465271

Epoch: 6| Step: 12
Training loss: 4.167497158050537
Validation loss: 4.357833504676819

Epoch: 6| Step: 13
Training loss: 5.347100257873535
Validation loss: 4.352433800697327

Epoch: 12| Step: 0
Training loss: 5.242950916290283
Validation loss: 4.347652594248454

Epoch: 6| Step: 1
Training loss: 4.3318328857421875
Validation loss: 4.342628121376038

Epoch: 6| Step: 2
Training loss: 3.483360767364502
Validation loss: 4.337426622708638

Epoch: 6| Step: 3
Training loss: 3.614826202392578
Validation loss: 4.331975380579631

Epoch: 6| Step: 4
Training loss: 3.606264591217041
Validation loss: 4.327393054962158

Epoch: 6| Step: 5
Training loss: 6.277009963989258
Validation loss: 4.3229957818984985

Epoch: 6| Step: 6
Training loss: 4.357943534851074
Validation loss: 4.317608078320821

Epoch: 6| Step: 7
Training loss: 4.9166669845581055
Validation loss: 4.31193729241689

Epoch: 6| Step: 8
Training loss: 4.748416423797607
Validation loss: 4.307350754737854

Epoch: 6| Step: 9
Training loss: 4.724347114562988
Validation loss: 4.302188515663147

Epoch: 6| Step: 10
Training loss: 4.340604782104492
Validation loss: 4.29747462272644

Epoch: 6| Step: 11
Training loss: 4.292117118835449
Validation loss: 4.292728066444397

Epoch: 6| Step: 12
Training loss: 4.091891765594482
Validation loss: 4.287408431371053

Epoch: 6| Step: 13
Training loss: 4.110265254974365
Validation loss: 4.282712856928508

Epoch: 13| Step: 0
Training loss: 5.402371406555176
Validation loss: 4.277712066968282

Epoch: 6| Step: 1
Training loss: 4.200202941894531
Validation loss: 4.272674043973287

Epoch: 6| Step: 2
Training loss: 5.514055252075195
Validation loss: 4.2677375475565595

Epoch: 6| Step: 3
Training loss: 3.855985403060913
Validation loss: 4.262609004974365

Epoch: 6| Step: 4
Training loss: 3.05370831489563
Validation loss: 4.257138133049011

Epoch: 6| Step: 5
Training loss: 5.25682258605957
Validation loss: 4.252763907114665

Epoch: 6| Step: 6
Training loss: 4.039280414581299
Validation loss: 4.247290849685669

Epoch: 6| Step: 7
Training loss: 4.5839433670043945
Validation loss: 4.242479165395101

Epoch: 6| Step: 8
Training loss: 4.900565147399902
Validation loss: 4.237056414286296

Epoch: 6| Step: 9
Training loss: 4.053689479827881
Validation loss: 4.232282956441243

Epoch: 6| Step: 10
Training loss: 3.8626108169555664
Validation loss: 4.227011760075887

Epoch: 6| Step: 11
Training loss: 3.4973056316375732
Validation loss: 4.22199010848999

Epoch: 6| Step: 12
Training loss: 3.493628978729248
Validation loss: 4.216847062110901

Epoch: 6| Step: 13
Training loss: 5.506945610046387
Validation loss: 4.211909691492717

Epoch: 14| Step: 0
Training loss: 5.251969337463379
Validation loss: 4.207066694895427

Epoch: 6| Step: 1
Training loss: 4.597161293029785
Validation loss: 4.20160174369812

Epoch: 6| Step: 2
Training loss: 4.2305498123168945
Validation loss: 4.196012179056804

Epoch: 6| Step: 3
Training loss: 3.0514369010925293
Validation loss: 4.191154837608337

Epoch: 6| Step: 4
Training loss: 5.546247959136963
Validation loss: 4.186410665512085

Epoch: 6| Step: 5
Training loss: 4.808469772338867
Validation loss: 4.180916786193848

Epoch: 6| Step: 6
Training loss: 4.6075029373168945
Validation loss: 4.175660212834676

Epoch: 6| Step: 7
Training loss: 4.461888313293457
Validation loss: 4.170397679011027

Epoch: 6| Step: 8
Training loss: 4.631115913391113
Validation loss: 4.165371259053548

Epoch: 6| Step: 9
Training loss: 4.2634501457214355
Validation loss: 4.160002827644348

Epoch: 6| Step: 10
Training loss: 3.9305036067962646
Validation loss: 4.1548726161321

Epoch: 6| Step: 11
Training loss: 2.989168405532837
Validation loss: 4.14961318174998

Epoch: 6| Step: 12
Training loss: 3.8835248947143555
Validation loss: 4.144708037376404

Epoch: 6| Step: 13
Training loss: 4.056942462921143
Validation loss: 4.1401084661483765

Epoch: 15| Step: 0
Training loss: 4.536649227142334
Validation loss: 4.134435613950093

Epoch: 6| Step: 1
Training loss: 4.119658946990967
Validation loss: 4.129713614781697

Epoch: 6| Step: 2
Training loss: 3.9685566425323486
Validation loss: 4.124933997790019

Epoch: 6| Step: 3
Training loss: 4.88203239440918
Validation loss: 4.12033478418986

Epoch: 6| Step: 4
Training loss: 2.726440668106079
Validation loss: 4.1150797208150225

Epoch: 6| Step: 5
Training loss: 4.618762969970703
Validation loss: 4.110510587692261

Epoch: 6| Step: 6
Training loss: 4.753630638122559
Validation loss: 4.105181773503621

Epoch: 6| Step: 7
Training loss: 3.916016101837158
Validation loss: 4.100301345189412

Epoch: 6| Step: 8
Training loss: 5.204777717590332
Validation loss: 4.095582882563273

Epoch: 6| Step: 9
Training loss: 4.386605739593506
Validation loss: 4.090480327606201

Epoch: 6| Step: 10
Training loss: 4.274044990539551
Validation loss: 4.085756023724874

Epoch: 6| Step: 11
Training loss: 3.2831687927246094
Validation loss: 4.080438852310181

Epoch: 6| Step: 12
Training loss: 4.400877952575684
Validation loss: 4.076164881388347

Epoch: 6| Step: 13
Training loss: 4.339267730712891
Validation loss: 4.071975866953532

Epoch: 16| Step: 0
Training loss: 4.392467975616455
Validation loss: 4.066550890604655

Epoch: 6| Step: 1
Training loss: 4.856428146362305
Validation loss: 4.062175909678142

Epoch: 6| Step: 2
Training loss: 4.5653533935546875
Validation loss: 4.058062354723613

Epoch: 6| Step: 3
Training loss: 4.632674217224121
Validation loss: 4.053458213806152

Epoch: 6| Step: 4
Training loss: 4.204600811004639
Validation loss: 4.04871408144633

Epoch: 6| Step: 5
Training loss: 3.3653717041015625
Validation loss: 4.044093171755473

Epoch: 6| Step: 6
Training loss: 4.128625869750977
Validation loss: 4.040080706278483

Epoch: 6| Step: 7
Training loss: 4.474905967712402
Validation loss: 4.034540732701619

Epoch: 6| Step: 8
Training loss: 3.64546275138855
Validation loss: 4.029847264289856

Epoch: 6| Step: 9
Training loss: 3.0255050659179688
Validation loss: 4.025246421496074

Epoch: 6| Step: 10
Training loss: 3.833698272705078
Validation loss: 4.0214459498723345

Epoch: 6| Step: 11
Training loss: 4.422542572021484
Validation loss: 4.017638643582662

Epoch: 6| Step: 12
Training loss: 4.310739994049072
Validation loss: 4.012627720832825

Epoch: 6| Step: 13
Training loss: 4.674300670623779
Validation loss: 4.0082119305928545

Epoch: 17| Step: 0
Training loss: 4.260629653930664
Validation loss: 4.004386226336162

Epoch: 6| Step: 1
Training loss: 4.2509050369262695
Validation loss: 3.9996050198872886

Epoch: 6| Step: 2
Training loss: 4.32130765914917
Validation loss: 3.995963215827942

Epoch: 6| Step: 3
Training loss: 4.698739051818848
Validation loss: 3.991251309712728

Epoch: 6| Step: 4
Training loss: 3.6660187244415283
Validation loss: 3.986881375312805

Epoch: 6| Step: 5
Training loss: 4.0244975090026855
Validation loss: 3.9825069904327393

Epoch: 6| Step: 6
Training loss: 4.291553974151611
Validation loss: 3.9780303239822388

Epoch: 6| Step: 7
Training loss: 3.795151710510254
Validation loss: 3.973967353502909

Epoch: 6| Step: 8
Training loss: 5.44447135925293
Validation loss: 3.9700105587641397

Epoch: 6| Step: 9
Training loss: 3.3738152980804443
Validation loss: 3.965772867202759

Epoch: 6| Step: 10
Training loss: 4.054354667663574
Validation loss: 3.9612565835316977

Epoch: 6| Step: 11
Training loss: 4.4746246337890625
Validation loss: 3.9572089513142905

Epoch: 6| Step: 12
Training loss: 3.937575340270996
Validation loss: 3.952472686767578

Epoch: 6| Step: 13
Training loss: 3.1208853721618652
Validation loss: 3.948353409767151

Epoch: 18| Step: 0
Training loss: 4.466189861297607
Validation loss: 3.944573442141215

Epoch: 6| Step: 1
Training loss: 4.408653736114502
Validation loss: 3.939884583155314

Epoch: 6| Step: 2
Training loss: 4.167865753173828
Validation loss: 3.935989419619242

Epoch: 6| Step: 3
Training loss: 3.860653877258301
Validation loss: 3.931753079096476

Epoch: 6| Step: 4
Training loss: 4.465559959411621
Validation loss: 3.9276190598805747

Epoch: 6| Step: 5
Training loss: 3.176809310913086
Validation loss: 3.924073656400045

Epoch: 6| Step: 6
Training loss: 5.141180992126465
Validation loss: 3.9201740821202598

Epoch: 6| Step: 7
Training loss: 3.766507625579834
Validation loss: 3.9157214562098184

Epoch: 6| Step: 8
Training loss: 4.669754505157471
Validation loss: 3.9121364752451577

Epoch: 6| Step: 9
Training loss: 3.7507057189941406
Validation loss: 3.9085352420806885

Epoch: 6| Step: 10
Training loss: 3.248762845993042
Validation loss: 3.9041500091552734

Epoch: 6| Step: 11
Training loss: 4.192657470703125
Validation loss: 3.9002979596455893

Epoch: 6| Step: 12
Training loss: 3.707000494003296
Validation loss: 3.8964994748433432

Epoch: 6| Step: 13
Training loss: 3.9099087715148926
Validation loss: 3.892027974128723

Epoch: 19| Step: 0
Training loss: 4.20405387878418
Validation loss: 3.888525446256002

Epoch: 6| Step: 1
Training loss: 3.4791879653930664
Validation loss: 3.8848249117533364

Epoch: 6| Step: 2
Training loss: 3.415773391723633
Validation loss: 3.880733370780945

Epoch: 6| Step: 3
Training loss: 4.598688125610352
Validation loss: 3.8763782183329263

Epoch: 6| Step: 4
Training loss: 4.470853805541992
Validation loss: 3.8725435733795166

Epoch: 6| Step: 5
Training loss: 4.518503665924072
Validation loss: 3.8686529397964478

Epoch: 6| Step: 6
Training loss: 3.6246821880340576
Validation loss: 3.864388187726339

Epoch: 6| Step: 7
Training loss: 3.685680866241455
Validation loss: 3.860828439394633

Epoch: 6| Step: 8
Training loss: 4.620985984802246
Validation loss: 3.8570264180501304

Epoch: 6| Step: 9
Training loss: 3.360318899154663
Validation loss: 3.8525557120641074

Epoch: 6| Step: 10
Training loss: 4.941868782043457
Validation loss: 3.848740259806315

Epoch: 6| Step: 11
Training loss: 4.052573204040527
Validation loss: 3.8450826009114585

Epoch: 6| Step: 12
Training loss: 4.460325717926025
Validation loss: 3.840864062309265

Epoch: 6| Step: 13
Training loss: 2.7819035053253174
Validation loss: 3.8371447722117105

Epoch: 20| Step: 0
Training loss: 4.272263526916504
Validation loss: 3.8334943850835166

Epoch: 6| Step: 1
Training loss: 4.553355693817139
Validation loss: 3.82977028687795

Epoch: 6| Step: 2
Training loss: 3.7702300548553467
Validation loss: 3.825333555539449

Epoch: 6| Step: 3
Training loss: 4.158851623535156
Validation loss: 3.821941335995992

Epoch: 6| Step: 4
Training loss: 4.008220195770264
Validation loss: 3.817818800608317

Epoch: 6| Step: 5
Training loss: 3.734525203704834
Validation loss: 3.8140560388565063

Epoch: 6| Step: 6
Training loss: 3.412776470184326
Validation loss: 3.810250441233317

Epoch: 6| Step: 7
Training loss: 4.275144577026367
Validation loss: 3.806805968284607

Epoch: 6| Step: 8
Training loss: 3.451446056365967
Validation loss: 3.80303947130839

Epoch: 6| Step: 9
Training loss: 3.4111104011535645
Validation loss: 3.799779176712036

Epoch: 6| Step: 10
Training loss: 3.7645320892333984
Validation loss: 3.7956753174463906

Epoch: 6| Step: 11
Training loss: 3.766824960708618
Validation loss: 3.792387286822001

Epoch: 6| Step: 12
Training loss: 4.312259674072266
Validation loss: 3.7887538274129233

Epoch: 6| Step: 13
Training loss: 4.61541748046875
Validation loss: 3.7847447395324707

Epoch: 21| Step: 0
Training loss: 3.75431752204895
Validation loss: 3.7812112172444663

Epoch: 6| Step: 1
Training loss: 4.822413444519043
Validation loss: 3.7773355642954507

Epoch: 6| Step: 2
Training loss: 4.907343864440918
Validation loss: 3.7739256223042807

Epoch: 6| Step: 3
Training loss: 4.163881301879883
Validation loss: 3.7701850732167563

Epoch: 6| Step: 4
Training loss: 3.99151349067688
Validation loss: 3.7657864888509116

Epoch: 6| Step: 5
Training loss: 3.603024482727051
Validation loss: 3.761688788731893

Epoch: 6| Step: 6
Training loss: 4.4034013748168945
Validation loss: 3.758172035217285

Epoch: 6| Step: 7
Training loss: 3.0856502056121826
Validation loss: 3.754072626431783

Epoch: 6| Step: 8
Training loss: 4.043561935424805
Validation loss: 3.7503523429234824

Epoch: 6| Step: 9
Training loss: 3.1985182762145996
Validation loss: 3.7468437353769937

Epoch: 6| Step: 10
Training loss: 3.8827414512634277
Validation loss: 3.742967367172241

Epoch: 6| Step: 11
Training loss: 3.6640281677246094
Validation loss: 3.738998015721639

Epoch: 6| Step: 12
Training loss: 4.339189529418945
Validation loss: 3.735162297884623

Epoch: 6| Step: 13
Training loss: 2.9759888648986816
Validation loss: 3.731587052345276

Epoch: 22| Step: 0
Training loss: 3.5419578552246094
Validation loss: 3.7281126976013184

Epoch: 6| Step: 1
Training loss: 4.6782026290893555
Validation loss: 3.7247219483057656

Epoch: 6| Step: 2
Training loss: 3.8672573566436768
Validation loss: 3.721336046854655

Epoch: 6| Step: 3
Training loss: 4.093138694763184
Validation loss: 3.717914859453837

Epoch: 6| Step: 4
Training loss: 4.442503452301025
Validation loss: 3.714675227801005

Epoch: 6| Step: 5
Training loss: 3.1631975173950195
Validation loss: 3.71092681090037

Epoch: 6| Step: 6
Training loss: 2.0415124893188477
Validation loss: 3.707229971885681

Epoch: 6| Step: 7
Training loss: 3.7218501567840576
Validation loss: 3.703798254330953

Epoch: 6| Step: 8
Training loss: 4.294826507568359
Validation loss: 3.700716773668925

Epoch: 6| Step: 9
Training loss: 3.357724666595459
Validation loss: 3.6970269680023193

Epoch: 6| Step: 10
Training loss: 4.732753753662109
Validation loss: 3.6935341358184814

Epoch: 6| Step: 11
Training loss: 4.375677108764648
Validation loss: 3.6900320847829184

Epoch: 6| Step: 12
Training loss: 3.661746025085449
Validation loss: 3.686636130015055

Epoch: 6| Step: 13
Training loss: 4.1501874923706055
Validation loss: 3.6831287940343223

Epoch: 23| Step: 0
Training loss: 3.7734012603759766
Validation loss: 3.6793774366378784

Epoch: 6| Step: 1
Training loss: 4.112618446350098
Validation loss: 3.6756832202275596

Epoch: 6| Step: 2
Training loss: 3.9191534519195557
Validation loss: 3.6723631223042807

Epoch: 6| Step: 3
Training loss: 3.6794533729553223
Validation loss: 3.6685513655344644

Epoch: 6| Step: 4
Training loss: 4.472832679748535
Validation loss: 3.664994160334269

Epoch: 6| Step: 5
Training loss: 3.8938889503479004
Validation loss: 3.6609010299046836

Epoch: 6| Step: 6
Training loss: 3.667142629623413
Validation loss: 3.6574480136235556

Epoch: 6| Step: 7
Training loss: 3.110701560974121
Validation loss: 3.6540174086888633

Epoch: 6| Step: 8
Training loss: 3.6881494522094727
Validation loss: 3.650317072868347

Epoch: 6| Step: 9
Training loss: 4.1739397048950195
Validation loss: 3.646722356478373

Epoch: 6| Step: 10
Training loss: 3.434384822845459
Validation loss: 3.6435642639795938

Epoch: 6| Step: 11
Training loss: 3.6295061111450195
Validation loss: 3.639528195063273

Epoch: 6| Step: 12
Training loss: 4.549271583557129
Validation loss: 3.635799765586853

Epoch: 6| Step: 13
Training loss: 3.332367420196533
Validation loss: 3.6320308446884155

Epoch: 24| Step: 0
Training loss: 2.578319787979126
Validation loss: 3.6281714836756387

Epoch: 6| Step: 1
Training loss: 3.4541544914245605
Validation loss: 3.6241894960403442

Epoch: 6| Step: 2
Training loss: 3.4952540397644043
Validation loss: 3.620556871096293

Epoch: 6| Step: 3
Training loss: 3.7101194858551025
Validation loss: 3.616466005643209

Epoch: 6| Step: 4
Training loss: 3.498201847076416
Validation loss: 3.612492243448893

Epoch: 6| Step: 5
Training loss: 4.074901103973389
Validation loss: 3.6086652278900146

Epoch: 6| Step: 6
Training loss: 3.4776763916015625
Validation loss: 3.604698101679484

Epoch: 6| Step: 7
Training loss: 3.8404488563537598
Validation loss: 3.601288358370463

Epoch: 6| Step: 8
Training loss: 3.639960765838623
Validation loss: 3.5974390506744385

Epoch: 6| Step: 9
Training loss: 3.716677188873291
Validation loss: 3.5935052633285522

Epoch: 6| Step: 10
Training loss: 4.30049991607666
Validation loss: 3.5900431076685586

Epoch: 6| Step: 11
Training loss: 4.216540336608887
Validation loss: 3.5863866011301675

Epoch: 6| Step: 12
Training loss: 4.822661399841309
Validation loss: 3.5824641784032187

Epoch: 6| Step: 13
Training loss: 3.8914990425109863
Validation loss: 3.578618367513021

Epoch: 25| Step: 0
Training loss: 5.12083625793457
Validation loss: 3.5744687716166177

Epoch: 6| Step: 1
Training loss: 2.9951605796813965
Validation loss: 3.570300579071045

Epoch: 6| Step: 2
Training loss: 3.3474860191345215
Validation loss: 3.566126028696696

Epoch: 6| Step: 3
Training loss: 3.3157944679260254
Validation loss: 3.5620439449946084

Epoch: 6| Step: 4
Training loss: 4.232313632965088
Validation loss: 3.5582889318466187

Epoch: 6| Step: 5
Training loss: 4.359728813171387
Validation loss: 3.554563522338867

Epoch: 6| Step: 6
Training loss: 4.2143988609313965
Validation loss: 3.5503611962000527

Epoch: 6| Step: 7
Training loss: 3.567852258682251
Validation loss: 3.5462065935134888

Epoch: 6| Step: 8
Training loss: 3.7589235305786133
Validation loss: 3.5419973929723105

Epoch: 6| Step: 9
Training loss: 3.7607293128967285
Validation loss: 3.537919362386068

Epoch: 6| Step: 10
Training loss: 2.697293996810913
Validation loss: 3.534025033315023

Epoch: 6| Step: 11
Training loss: 3.5083730220794678
Validation loss: 3.530060569445292

Epoch: 6| Step: 12
Training loss: 3.399449586868286
Validation loss: 3.5263312657674155

Epoch: 6| Step: 13
Training loss: 3.716538667678833
Validation loss: 3.52212393283844

Epoch: 26| Step: 0
Training loss: 3.941188335418701
Validation loss: 3.518086592356364

Epoch: 6| Step: 1
Training loss: 3.239332675933838
Validation loss: 3.5140722592671714

Epoch: 6| Step: 2
Training loss: 3.8569679260253906
Validation loss: 3.5102644761403403

Epoch: 6| Step: 3
Training loss: 3.3992719650268555
Validation loss: 3.5064634482065835

Epoch: 6| Step: 4
Training loss: 3.513535499572754
Validation loss: 3.502551794052124

Epoch: 6| Step: 5
Training loss: 4.697741508483887
Validation loss: 3.498505155245463

Epoch: 6| Step: 6
Training loss: 4.709484100341797
Validation loss: 3.4944682916005454

Epoch: 6| Step: 7
Training loss: 3.4872028827667236
Validation loss: 3.4903897047042847

Epoch: 6| Step: 8
Training loss: 3.0303869247436523
Validation loss: 3.486524065335592

Epoch: 6| Step: 9
Training loss: 3.117405891418457
Validation loss: 3.482385754585266

Epoch: 6| Step: 10
Training loss: 3.9384653568267822
Validation loss: 3.478215456008911

Epoch: 6| Step: 11
Training loss: 3.7328670024871826
Validation loss: 3.4741888840993247

Epoch: 6| Step: 12
Training loss: 2.907141923904419
Validation loss: 3.4700663089752197

Epoch: 6| Step: 13
Training loss: 3.6647403240203857
Validation loss: 3.466128349304199

Epoch: 27| Step: 0
Training loss: 3.402636766433716
Validation loss: 3.462138613065084

Epoch: 6| Step: 1
Training loss: 4.49823522567749
Validation loss: 3.458295742670695

Epoch: 6| Step: 2
Training loss: 4.694562911987305
Validation loss: 3.4542019764582315

Epoch: 6| Step: 3
Training loss: 3.283963918685913
Validation loss: 3.4500672419865928

Epoch: 6| Step: 4
Training loss: 2.808633804321289
Validation loss: 3.446097413698832

Epoch: 6| Step: 5
Training loss: 3.5401992797851562
Validation loss: 3.441791534423828

Epoch: 6| Step: 6
Training loss: 2.733750343322754
Validation loss: 3.437645355860392

Epoch: 6| Step: 7
Training loss: 3.4453392028808594
Validation loss: 3.4335236152013144

Epoch: 6| Step: 8
Training loss: 3.434601306915283
Validation loss: 3.4295925299326577

Epoch: 6| Step: 9
Training loss: 3.2986512184143066
Validation loss: 3.425297657648722

Epoch: 6| Step: 10
Training loss: 4.444769382476807
Validation loss: 3.4213178952534995

Epoch: 6| Step: 11
Training loss: 3.530721426010132
Validation loss: 3.4171828826268515

Epoch: 6| Step: 12
Training loss: 3.0660905838012695
Validation loss: 3.413228392601013

Epoch: 6| Step: 13
Training loss: 4.27066707611084
Validation loss: 3.40920627117157

Epoch: 28| Step: 0
Training loss: 3.3684282302856445
Validation loss: 3.4053837060928345

Epoch: 6| Step: 1
Training loss: 3.444455862045288
Validation loss: 3.4019527037938437

Epoch: 6| Step: 2
Training loss: 3.2631101608276367
Validation loss: 3.3986473878224692

Epoch: 6| Step: 3
Training loss: 4.9121856689453125
Validation loss: 3.394136905670166

Epoch: 6| Step: 4
Training loss: 4.602017402648926
Validation loss: 3.389580488204956

Epoch: 6| Step: 5
Training loss: 3.9837825298309326
Validation loss: 3.3853946526845298

Epoch: 6| Step: 6
Training loss: 3.198986053466797
Validation loss: 3.3812976678212485

Epoch: 6| Step: 7
Training loss: 3.193983316421509
Validation loss: 3.3773972193400064

Epoch: 6| Step: 8
Training loss: 2.7637124061584473
Validation loss: 3.37339194615682

Epoch: 6| Step: 9
Training loss: 3.956484317779541
Validation loss: 3.369706670443217

Epoch: 6| Step: 10
Training loss: 3.9823665618896484
Validation loss: 3.365483601888021

Epoch: 6| Step: 11
Training loss: 3.103823661804199
Validation loss: 3.361324191093445

Epoch: 6| Step: 12
Training loss: 3.9537205696105957
Validation loss: 3.357140223185221

Epoch: 6| Step: 13
Training loss: 1.9787884950637817
Validation loss: 3.3532540003458657

Epoch: 29| Step: 0
Training loss: 3.041447639465332
Validation loss: 3.349649349848429

Epoch: 6| Step: 1
Training loss: 3.849416494369507
Validation loss: 3.3455966313680015

Epoch: 6| Step: 2
Training loss: 3.5094704627990723
Validation loss: 3.3417219718297324

Epoch: 6| Step: 3
Training loss: 3.5453133583068848
Validation loss: 3.3378544648488364

Epoch: 6| Step: 4
Training loss: 3.454336643218994
Validation loss: 3.3335975408554077

Epoch: 6| Step: 5
Training loss: 3.8379077911376953
Validation loss: 3.3298079570134482

Epoch: 6| Step: 6
Training loss: 3.0748062133789062
Validation loss: 3.3254741032918296

Epoch: 6| Step: 7
Training loss: 3.841665267944336
Validation loss: 3.321392814318339

Epoch: 6| Step: 8
Training loss: 3.7663955688476562
Validation loss: 3.3174953858057656

Epoch: 6| Step: 9
Training loss: 3.8675119876861572
Validation loss: 3.3138094743092856

Epoch: 6| Step: 10
Training loss: 2.6086440086364746
Validation loss: 3.309874971707662

Epoch: 6| Step: 11
Training loss: 3.9867589473724365
Validation loss: 3.3060160477956138

Epoch: 6| Step: 12
Training loss: 3.0599002838134766
Validation loss: 3.3023186524709067

Epoch: 6| Step: 13
Training loss: 3.5251030921936035
Validation loss: 3.298062245051066

Epoch: 30| Step: 0
Training loss: 2.306919574737549
Validation loss: 3.29459015528361

Epoch: 6| Step: 1
Training loss: 3.285433769226074
Validation loss: 3.2908588647842407

Epoch: 6| Step: 2
Training loss: 2.9087464809417725
Validation loss: 3.287212093671163

Epoch: 6| Step: 3
Training loss: 3.8048629760742188
Validation loss: 3.2834282716115317

Epoch: 6| Step: 4
Training loss: 4.305295944213867
Validation loss: 3.279957095781962

Epoch: 6| Step: 5
Training loss: 3.9920337200164795
Validation loss: 3.2760828336079917

Epoch: 6| Step: 6
Training loss: 4.109562397003174
Validation loss: 3.2723336617151895

Epoch: 6| Step: 7
Training loss: 3.4753336906433105
Validation loss: 3.268216331799825

Epoch: 6| Step: 8
Training loss: 2.5871238708496094
Validation loss: 3.2645837465922036

Epoch: 6| Step: 9
Training loss: 3.7178635597229004
Validation loss: 3.2610454161961875

Epoch: 6| Step: 10
Training loss: 3.4741764068603516
Validation loss: 3.2570823431015015

Epoch: 6| Step: 11
Training loss: 3.4599709510803223
Validation loss: 3.253933310508728

Epoch: 6| Step: 12
Training loss: 3.3494482040405273
Validation loss: 3.249778906504313

Epoch: 6| Step: 13
Training loss: 3.489164352416992
Validation loss: 3.2460711002349854

Epoch: 31| Step: 0
Training loss: 4.447351932525635
Validation loss: 3.242508808771769

Epoch: 6| Step: 1
Training loss: 2.0418834686279297
Validation loss: 3.238036870956421

Epoch: 6| Step: 2
Training loss: 3.470358371734619
Validation loss: 3.2344998121261597

Epoch: 6| Step: 3
Training loss: 2.6260688304901123
Validation loss: 3.2308502991994223

Epoch: 6| Step: 4
Training loss: 2.878418207168579
Validation loss: 3.226964592933655

Epoch: 6| Step: 5
Training loss: 3.5045623779296875
Validation loss: 3.223456382751465

Epoch: 6| Step: 6
Training loss: 3.807685375213623
Validation loss: 3.219907522201538

Epoch: 6| Step: 7
Training loss: 3.577545404434204
Validation loss: 3.215869148572286

Epoch: 6| Step: 8
Training loss: 3.6973257064819336
Validation loss: 3.212190786997477

Epoch: 6| Step: 9
Training loss: 3.5803487300872803
Validation loss: 3.2082237799962363

Epoch: 6| Step: 10
Training loss: 3.117461681365967
Validation loss: 3.2044897079467773

Epoch: 6| Step: 11
Training loss: 3.807734727859497
Validation loss: 3.200670917828878

Epoch: 6| Step: 12
Training loss: 3.621929407119751
Validation loss: 3.196685512860616

Epoch: 6| Step: 13
Training loss: 3.3944296836853027
Validation loss: 3.1927080949147544

Epoch: 32| Step: 0
Training loss: 3.83620285987854
Validation loss: 3.1890210707982383

Epoch: 6| Step: 1
Training loss: 3.458009719848633
Validation loss: 3.185240467389425

Epoch: 6| Step: 2
Training loss: 3.5894615650177
Validation loss: 3.1815672318140664

Epoch: 6| Step: 3
Training loss: 4.03047513961792
Validation loss: 3.178019126256307

Epoch: 6| Step: 4
Training loss: 2.7449588775634766
Validation loss: 3.1742724577585855

Epoch: 6| Step: 5
Training loss: 3.2545483112335205
Validation loss: 3.1702382564544678

Epoch: 6| Step: 6
Training loss: 2.850614070892334
Validation loss: 3.166141907374064

Epoch: 6| Step: 7
Training loss: 4.13963508605957
Validation loss: 3.1625125408172607

Epoch: 6| Step: 8
Training loss: 3.473585605621338
Validation loss: 3.1583180824915567

Epoch: 6| Step: 9
Training loss: 3.666304588317871
Validation loss: 3.1543979247411094

Epoch: 6| Step: 10
Training loss: 2.8153014183044434
Validation loss: 3.150627692540487

Epoch: 6| Step: 11
Training loss: 2.937191963195801
Validation loss: 3.1468859116236367

Epoch: 6| Step: 12
Training loss: 2.910019874572754
Validation loss: 3.142800052960714

Epoch: 6| Step: 13
Training loss: 3.1858232021331787
Validation loss: 3.1390790144602456

Epoch: 33| Step: 0
Training loss: 3.6777396202087402
Validation loss: 3.135384202003479

Epoch: 6| Step: 1
Training loss: 3.547933340072632
Validation loss: 3.131362239519755

Epoch: 6| Step: 2
Training loss: 2.703707695007324
Validation loss: 3.12754495938619

Epoch: 6| Step: 3
Training loss: 3.16202974319458
Validation loss: 3.123708883921305

Epoch: 6| Step: 4
Training loss: 3.195537567138672
Validation loss: 3.1201471090316772

Epoch: 6| Step: 5
Training loss: 3.6328258514404297
Validation loss: 3.1164289712905884

Epoch: 6| Step: 6
Training loss: 3.360673427581787
Validation loss: 3.1129726568857827

Epoch: 6| Step: 7
Training loss: 3.1640617847442627
Validation loss: 3.1095585028330484

Epoch: 6| Step: 8
Training loss: 3.4588499069213867
Validation loss: 3.1055120627085366

Epoch: 6| Step: 9
Training loss: 2.926450490951538
Validation loss: 3.1016925970713296

Epoch: 6| Step: 10
Training loss: 3.8520193099975586
Validation loss: 3.098758419354757

Epoch: 6| Step: 11
Training loss: 3.142510414123535
Validation loss: 3.095386823018392

Epoch: 6| Step: 12
Training loss: 3.2132959365844727
Validation loss: 3.0918354988098145

Epoch: 6| Step: 13
Training loss: 3.1553194522857666
Validation loss: 3.08823823928833

Epoch: 34| Step: 0
Training loss: 3.969511032104492
Validation loss: 3.084863265355428

Epoch: 6| Step: 1
Training loss: 2.811483383178711
Validation loss: 3.081092913945516

Epoch: 6| Step: 2
Training loss: 3.888099431991577
Validation loss: 3.0769498348236084

Epoch: 6| Step: 3
Training loss: 3.3648343086242676
Validation loss: 3.0733643770217896

Epoch: 6| Step: 4
Training loss: 2.4857969284057617
Validation loss: 3.0695979992548623

Epoch: 6| Step: 5
Training loss: 2.6303417682647705
Validation loss: 3.0658233960469565

Epoch: 6| Step: 6
Training loss: 2.7539987564086914
Validation loss: 3.062422235806783

Epoch: 6| Step: 7
Training loss: 3.052767276763916
Validation loss: 3.0588358640670776

Epoch: 6| Step: 8
Training loss: 4.253631591796875
Validation loss: 3.0556693871816

Epoch: 6| Step: 9
Training loss: 2.7908883094787598
Validation loss: 3.051838477452596

Epoch: 6| Step: 10
Training loss: 3.080247163772583
Validation loss: 3.0484939018885293

Epoch: 6| Step: 11
Training loss: 3.712636947631836
Validation loss: 3.0449495712916055

Epoch: 6| Step: 12
Training loss: 4.059667110443115
Validation loss: 3.0413751204808555

Epoch: 6| Step: 13
Training loss: 2.70430588722229
Validation loss: 3.037963310877482

Epoch: 35| Step: 0
Training loss: 2.723484754562378
Validation loss: 3.03438937664032

Epoch: 6| Step: 1
Training loss: 2.687404155731201
Validation loss: 3.0318738222122192

Epoch: 6| Step: 2
Training loss: 4.151634216308594
Validation loss: 3.0296814839045205

Epoch: 6| Step: 3
Training loss: 3.0967025756835938
Validation loss: 3.025554895401001

Epoch: 6| Step: 4
Training loss: 2.6192729473114014
Validation loss: 3.021905461947123

Epoch: 6| Step: 5
Training loss: 2.6382806301116943
Validation loss: 3.0177491903305054

Epoch: 6| Step: 6
Training loss: 3.1453840732574463
Validation loss: 3.015735665957133

Epoch: 6| Step: 7
Training loss: 3.1967716217041016
Validation loss: 3.0119897524515786

Epoch: 6| Step: 8
Training loss: 4.056365966796875
Validation loss: 3.00856880346934

Epoch: 6| Step: 9
Training loss: 3.43746280670166
Validation loss: 3.004756530125936

Epoch: 6| Step: 10
Training loss: 3.3423666954040527
Validation loss: 3.001297195752462

Epoch: 6| Step: 11
Training loss: 2.7109971046447754
Validation loss: 2.9982722202936807

Epoch: 6| Step: 12
Training loss: 3.190938949584961
Validation loss: 2.9955663283665976

Epoch: 6| Step: 13
Training loss: 3.903144359588623
Validation loss: 2.9919110536575317

Epoch: 36| Step: 0
Training loss: 3.5721983909606934
Validation loss: 2.988317608833313

Epoch: 6| Step: 1
Training loss: 2.6450226306915283
Validation loss: 2.9849255084991455

Epoch: 6| Step: 2
Training loss: 2.812729835510254
Validation loss: 2.9824658234914145

Epoch: 6| Step: 3
Training loss: 3.8609626293182373
Validation loss: 2.9785337845484414

Epoch: 6| Step: 4
Training loss: 2.8238396644592285
Validation loss: 2.975329120953878

Epoch: 6| Step: 5
Training loss: 2.9645214080810547
Validation loss: 2.9719872077306113

Epoch: 6| Step: 6
Training loss: 3.1719980239868164
Validation loss: 2.9689655105272927

Epoch: 6| Step: 7
Training loss: 2.9746041297912598
Validation loss: 2.965625445048014

Epoch: 6| Step: 8
Training loss: 3.630985736846924
Validation loss: 2.962633172671

Epoch: 6| Step: 9
Training loss: 3.0490403175354004
Validation loss: 2.9593145847320557

Epoch: 6| Step: 10
Training loss: 3.3293168544769287
Validation loss: 2.9548821449279785

Epoch: 6| Step: 11
Training loss: 3.04368257522583
Validation loss: 2.952015002568563

Epoch: 6| Step: 12
Training loss: 2.864253282546997
Validation loss: 2.948838949203491

Epoch: 6| Step: 13
Training loss: 3.5686378479003906
Validation loss: 2.9456735054651895

Epoch: 37| Step: 0
Training loss: 3.481123924255371
Validation loss: 2.9426178137461343

Epoch: 6| Step: 1
Training loss: 2.62239933013916
Validation loss: 2.93953009446462

Epoch: 6| Step: 2
Training loss: 3.275621175765991
Validation loss: 2.9359485308329263

Epoch: 6| Step: 3
Training loss: 2.3594675064086914
Validation loss: 2.931871215502421

Epoch: 6| Step: 4
Training loss: 2.945434331893921
Validation loss: 2.9298872152964273

Epoch: 6| Step: 5
Training loss: 3.397653102874756
Validation loss: 2.928630789120992

Epoch: 6| Step: 6
Training loss: 3.15948486328125
Validation loss: 2.9247254530588784

Epoch: 6| Step: 7
Training loss: 2.557734489440918
Validation loss: 2.9204264084498086

Epoch: 6| Step: 8
Training loss: 4.115234851837158
Validation loss: 2.918117086092631

Epoch: 6| Step: 9
Training loss: 3.12748122215271
Validation loss: 2.9131346543629966

Epoch: 6| Step: 10
Training loss: 3.3098292350769043
Validation loss: 2.910074512163798

Epoch: 6| Step: 11
Training loss: 3.356265068054199
Validation loss: 2.907322724660238

Epoch: 6| Step: 12
Training loss: 3.443701982498169
Validation loss: 2.9041497707366943

Epoch: 6| Step: 13
Training loss: 2.5812597274780273
Validation loss: 2.9014108180999756

Epoch: 38| Step: 0
Training loss: 2.9943151473999023
Validation loss: 2.8978586196899414

Epoch: 6| Step: 1
Training loss: 3.507627487182617
Validation loss: 2.89483110109965

Epoch: 6| Step: 2
Training loss: 3.2610175609588623
Validation loss: 2.891799211502075

Epoch: 6| Step: 3
Training loss: 3.2436046600341797
Validation loss: 2.8881514072418213

Epoch: 6| Step: 4
Training loss: 2.317391872406006
Validation loss: 2.8845348358154297

Epoch: 6| Step: 5
Training loss: 3.2628843784332275
Validation loss: 2.8814233541488647

Epoch: 6| Step: 6
Training loss: 3.5614068508148193
Validation loss: 2.8795313040415444

Epoch: 6| Step: 7
Training loss: 2.761171340942383
Validation loss: 2.8755099376042685

Epoch: 6| Step: 8
Training loss: 2.7580389976501465
Validation loss: 2.871907631556193

Epoch: 6| Step: 9
Training loss: 2.7435355186462402
Validation loss: 2.868572950363159

Epoch: 6| Step: 10
Training loss: 2.5053927898406982
Validation loss: 2.864619572957357

Epoch: 6| Step: 11
Training loss: 3.132817268371582
Validation loss: 2.8636635541915894

Epoch: 6| Step: 12
Training loss: 3.8516926765441895
Validation loss: 2.858018159866333

Epoch: 6| Step: 13
Training loss: 3.267493486404419
Validation loss: 2.857016603151957

Epoch: 39| Step: 0
Training loss: 2.6832213401794434
Validation loss: 2.853272875150045

Epoch: 6| Step: 1
Training loss: 3.0979971885681152
Validation loss: 2.850006580352783

Epoch: 6| Step: 2
Training loss: 1.9744021892547607
Validation loss: 2.8463770151138306

Epoch: 6| Step: 3
Training loss: 2.96702241897583
Validation loss: 2.8444936672846475

Epoch: 6| Step: 4
Training loss: 3.3054611682891846
Validation loss: 2.841040015220642

Epoch: 6| Step: 5
Training loss: 3.6462290287017822
Validation loss: 2.8432143529256186

Epoch: 6| Step: 6
Training loss: 2.8896305561065674
Validation loss: 2.8446616331736245

Epoch: 6| Step: 7
Training loss: 3.4682698249816895
Validation loss: 2.846483031908671

Epoch: 6| Step: 8
Training loss: 2.8428125381469727
Validation loss: 2.831457535425822

Epoch: 6| Step: 9
Training loss: 3.7650461196899414
Validation loss: 2.828084627787272

Epoch: 6| Step: 10
Training loss: 3.1961073875427246
Validation loss: 2.825974941253662

Epoch: 6| Step: 11
Training loss: 3.0472843647003174
Validation loss: 2.824089606602987

Epoch: 6| Step: 12
Training loss: 2.8268580436706543
Validation loss: 2.8214958906173706

Epoch: 6| Step: 13
Training loss: 2.907094955444336
Validation loss: 2.8173736333847046

Epoch: 40| Step: 0
Training loss: 2.823150157928467
Validation loss: 2.8144656221071878

Epoch: 6| Step: 1
Training loss: 2.707660675048828
Validation loss: 2.8112669785817466

Epoch: 6| Step: 2
Training loss: 3.423886299133301
Validation loss: 2.808623472849528

Epoch: 6| Step: 3
Training loss: 3.0090134143829346
Validation loss: 2.8055965900421143

Epoch: 6| Step: 4
Training loss: 3.415712833404541
Validation loss: 2.802218794822693

Epoch: 6| Step: 5
Training loss: 3.182918071746826
Validation loss: 2.7980474630991616

Epoch: 6| Step: 6
Training loss: 2.9902966022491455
Validation loss: 2.7947412729263306

Epoch: 6| Step: 7
Training loss: 4.41653299331665
Validation loss: 2.790948669115702

Epoch: 6| Step: 8
Training loss: 2.85530161857605
Validation loss: 2.786409636338552

Epoch: 6| Step: 9
Training loss: 2.85980224609375
Validation loss: 2.783316890398661

Epoch: 6| Step: 10
Training loss: 2.9263672828674316
Validation loss: 2.7810474634170532

Epoch: 6| Step: 11
Training loss: 2.46882700920105
Validation loss: 2.781754453976949

Epoch: 6| Step: 12
Training loss: 2.0759034156799316
Validation loss: 2.779901305834452

Epoch: 6| Step: 13
Training loss: 2.8977365493774414
Validation loss: 2.7835214535395303

Epoch: 41| Step: 0
Training loss: 3.3877997398376465
Validation loss: 2.7761332591374717

Epoch: 6| Step: 1
Training loss: 3.3487496376037598
Validation loss: 2.768495559692383

Epoch: 6| Step: 2
Training loss: 2.3325815200805664
Validation loss: 2.76628311475118

Epoch: 6| Step: 3
Training loss: 2.8490705490112305
Validation loss: 2.764513293902079

Epoch: 6| Step: 4
Training loss: 3.499689817428589
Validation loss: 2.7599669694900513

Epoch: 6| Step: 5
Training loss: 3.279712200164795
Validation loss: 2.7581080993016562

Epoch: 6| Step: 6
Training loss: 2.5151476860046387
Validation loss: 2.7543984254201255

Epoch: 6| Step: 7
Training loss: 2.8055176734924316
Validation loss: 2.7477726538976035

Epoch: 6| Step: 8
Training loss: 2.698688507080078
Validation loss: 2.745947281519572

Epoch: 6| Step: 9
Training loss: 2.5812273025512695
Validation loss: 2.7395163774490356

Epoch: 6| Step: 10
Training loss: 2.8828344345092773
Validation loss: 2.739554305871328

Epoch: 6| Step: 11
Training loss: 3.2915968894958496
Validation loss: 2.7375168005625405

Epoch: 6| Step: 12
Training loss: 3.216886043548584
Validation loss: 2.733323057492574

Epoch: 6| Step: 13
Training loss: 2.7039315700531006
Validation loss: 2.73063063621521

Epoch: 42| Step: 0
Training loss: 2.8843741416931152
Validation loss: 2.7271708250045776

Epoch: 6| Step: 1
Training loss: 3.0159010887145996
Validation loss: 2.7273149887720742

Epoch: 6| Step: 2
Training loss: 3.1004178524017334
Validation loss: 2.7222665548324585

Epoch: 6| Step: 3
Training loss: 2.787997245788574
Validation loss: 2.7204115986824036

Epoch: 6| Step: 4
Training loss: 3.0965938568115234
Validation loss: 2.716233193874359

Epoch: 6| Step: 5
Training loss: 2.727564573287964
Validation loss: 2.712639570236206

Epoch: 6| Step: 6
Training loss: 3.1210708618164062
Validation loss: 2.7115424076716104

Epoch: 6| Step: 7
Training loss: 3.32388973236084
Validation loss: 2.709426760673523

Epoch: 6| Step: 8
Training loss: 2.692647933959961
Validation loss: 2.706406593322754

Epoch: 6| Step: 9
Training loss: 3.048069715499878
Validation loss: 2.7047406435012817

Epoch: 6| Step: 10
Training loss: 2.8278801441192627
Validation loss: 2.705183823903402

Epoch: 6| Step: 11
Training loss: 3.657299518585205
Validation loss: 2.6970746914545694

Epoch: 6| Step: 12
Training loss: 2.2149972915649414
Validation loss: 2.6973076264063516

Epoch: 6| Step: 13
Training loss: 2.2550196647644043
Validation loss: 2.6967111825942993

Epoch: 43| Step: 0
Training loss: 2.714688539505005
Validation loss: 2.6868190368016562

Epoch: 6| Step: 1
Training loss: 2.1150803565979004
Validation loss: 2.6838115453720093

Epoch: 6| Step: 2
Training loss: 3.1383492946624756
Validation loss: 2.6823884646097818

Epoch: 6| Step: 3
Training loss: 3.1938090324401855
Validation loss: 2.6821507612864175

Epoch: 6| Step: 4
Training loss: 3.2393546104431152
Validation loss: 2.679193139076233

Epoch: 6| Step: 5
Training loss: 3.4610390663146973
Validation loss: 2.676573117574056

Epoch: 6| Step: 6
Training loss: 2.9611611366271973
Validation loss: 2.6741581757863364

Epoch: 6| Step: 7
Training loss: 2.5030200481414795
Validation loss: 2.6733327507972717

Epoch: 6| Step: 8
Training loss: 3.2411270141601562
Validation loss: 2.669978459676107

Epoch: 6| Step: 9
Training loss: 2.1102707386016846
Validation loss: 2.6673499743143716

Epoch: 6| Step: 10
Training loss: 2.8057260513305664
Validation loss: 2.6638864278793335

Epoch: 6| Step: 11
Training loss: 2.800816059112549
Validation loss: 2.6616816322008767

Epoch: 6| Step: 12
Training loss: 3.074583053588867
Validation loss: 2.6555605928103128

Epoch: 6| Step: 13
Training loss: 2.8485355377197266
Validation loss: 2.653527100880941

Epoch: 44| Step: 0
Training loss: 2.529510736465454
Validation loss: 2.6504263083140054

Epoch: 6| Step: 1
Training loss: 2.5721850395202637
Validation loss: 2.646101395289103

Epoch: 6| Step: 2
Training loss: 3.111298084259033
Validation loss: 2.643884817759196

Epoch: 6| Step: 3
Training loss: 2.825167655944824
Validation loss: 2.6384925842285156

Epoch: 6| Step: 4
Training loss: 3.205958843231201
Validation loss: 2.6396934588750205

Epoch: 6| Step: 5
Training loss: 2.212310314178467
Validation loss: 2.6335755983988443

Epoch: 6| Step: 6
Training loss: 2.0895371437072754
Validation loss: 2.6319526632626853

Epoch: 6| Step: 7
Training loss: 3.2408394813537598
Validation loss: 2.628600835800171

Epoch: 6| Step: 8
Training loss: 2.8290281295776367
Validation loss: 2.626306176185608

Epoch: 6| Step: 9
Training loss: 3.120941400527954
Validation loss: 2.6230048338572183

Epoch: 6| Step: 10
Training loss: 3.7838661670684814
Validation loss: 2.6203743616739907

Epoch: 6| Step: 11
Training loss: 2.7659566402435303
Validation loss: 2.618243137995402

Epoch: 6| Step: 12
Training loss: 2.499911308288574
Validation loss: 2.6155760685602822

Epoch: 6| Step: 13
Training loss: 2.818828821182251
Validation loss: 2.611528992652893

Epoch: 45| Step: 0
Training loss: 2.5337257385253906
Validation loss: 2.6070402463277182

Epoch: 6| Step: 1
Training loss: 2.796065330505371
Validation loss: 2.603963057200114

Epoch: 6| Step: 2
Training loss: 2.455413818359375
Validation loss: 2.6026371717453003

Epoch: 6| Step: 3
Training loss: 2.3501219749450684
Validation loss: 2.5988349517186484

Epoch: 6| Step: 4
Training loss: 2.9342458248138428
Validation loss: 2.597238540649414

Epoch: 6| Step: 5
Training loss: 2.7990732192993164
Validation loss: 2.594246586163839

Epoch: 6| Step: 6
Training loss: 3.0260112285614014
Validation loss: 2.590560475985209

Epoch: 6| Step: 7
Training loss: 3.055896282196045
Validation loss: 2.5866459210713706

Epoch: 6| Step: 8
Training loss: 2.118450164794922
Validation loss: 2.5818082888921103

Epoch: 6| Step: 9
Training loss: 3.0984208583831787
Validation loss: 2.5803091128667197

Epoch: 6| Step: 10
Training loss: 2.3601043224334717
Validation loss: 2.5788566867510476

Epoch: 6| Step: 11
Training loss: 2.941481590270996
Validation loss: 2.578044056892395

Epoch: 6| Step: 12
Training loss: 4.261281490325928
Validation loss: 2.5760483741760254

Epoch: 6| Step: 13
Training loss: 2.3197522163391113
Validation loss: 2.572948614756266

Epoch: 46| Step: 0
Training loss: 2.4795961380004883
Validation loss: 2.570922871430715

Epoch: 6| Step: 1
Training loss: 2.8703112602233887
Validation loss: 2.566260655721029

Epoch: 6| Step: 2
Training loss: 3.00174617767334
Validation loss: 2.5615740219751992

Epoch: 6| Step: 3
Training loss: 2.86392879486084
Validation loss: 2.5574517448743186

Epoch: 6| Step: 4
Training loss: 2.2042293548583984
Validation loss: 2.5502771933873496

Epoch: 6| Step: 5
Training loss: 2.7376954555511475
Validation loss: 2.5516409079233804

Epoch: 6| Step: 6
Training loss: 2.7086710929870605
Validation loss: 2.551529288291931

Epoch: 6| Step: 7
Training loss: 2.875919818878174
Validation loss: 2.545675357182821

Epoch: 6| Step: 8
Training loss: 2.378636598587036
Validation loss: 2.544357339541117

Epoch: 6| Step: 9
Training loss: 3.651670217514038
Validation loss: 2.539888938268026

Epoch: 6| Step: 10
Training loss: 3.036330223083496
Validation loss: 2.5396320819854736

Epoch: 6| Step: 11
Training loss: 2.629443645477295
Validation loss: 2.5349629322687783

Epoch: 6| Step: 12
Training loss: 2.4437968730926514
Validation loss: 2.5372199217478433

Epoch: 6| Step: 13
Training loss: 2.5383572578430176
Validation loss: 2.531511604785919

Epoch: 47| Step: 0
Training loss: 2.565272808074951
Validation loss: 2.5375932256380715

Epoch: 6| Step: 1
Training loss: 2.556450843811035
Validation loss: 2.5369425217310586

Epoch: 6| Step: 2
Training loss: 3.237736940383911
Validation loss: 2.548356374104818

Epoch: 6| Step: 3
Training loss: 2.8163018226623535
Validation loss: 2.533414602279663

Epoch: 6| Step: 4
Training loss: 2.9474308490753174
Validation loss: 2.5144063234329224

Epoch: 6| Step: 5
Training loss: 2.0525777339935303
Validation loss: 2.5117733478546143

Epoch: 6| Step: 6
Training loss: 2.030344247817993
Validation loss: 2.5131179094314575

Epoch: 6| Step: 7
Training loss: 2.684817314147949
Validation loss: 2.5168039401372275

Epoch: 6| Step: 8
Training loss: 2.415745496749878
Validation loss: 2.525639990965525

Epoch: 6| Step: 9
Training loss: 2.7929275035858154
Validation loss: 2.5389049450556436

Epoch: 6| Step: 10
Training loss: 3.037670135498047
Validation loss: 2.5372151533762612

Epoch: 6| Step: 11
Training loss: 3.191891670227051
Validation loss: 2.5163652102152505

Epoch: 6| Step: 12
Training loss: 3.3858184814453125
Validation loss: 2.5111081997553506

Epoch: 6| Step: 13
Training loss: 2.370710849761963
Validation loss: 2.506152947743734

Epoch: 48| Step: 0
Training loss: 2.4653666019439697
Validation loss: 2.5009228388468423

Epoch: 6| Step: 1
Training loss: 2.0733211040496826
Validation loss: 2.495592713356018

Epoch: 6| Step: 2
Training loss: 2.8222415447235107
Validation loss: 2.4923947850863137

Epoch: 6| Step: 3
Training loss: 2.378498077392578
Validation loss: 2.487849394480387

Epoch: 6| Step: 4
Training loss: 2.908231735229492
Validation loss: 2.4862618446350098

Epoch: 6| Step: 5
Training loss: 3.0149388313293457
Validation loss: 2.482830762863159

Epoch: 6| Step: 6
Training loss: 2.6565346717834473
Validation loss: 2.481599529584249

Epoch: 6| Step: 7
Training loss: 3.012974500656128
Validation loss: 2.4802215894063315

Epoch: 6| Step: 8
Training loss: 2.7342066764831543
Validation loss: 2.477740486462911

Epoch: 6| Step: 9
Training loss: 2.6725215911865234
Validation loss: 2.473789930343628

Epoch: 6| Step: 10
Training loss: 3.253654956817627
Validation loss: 2.4723546703656516

Epoch: 6| Step: 11
Training loss: 3.2700822353363037
Validation loss: 2.469391703605652

Epoch: 6| Step: 12
Training loss: 1.733629822731018
Validation loss: 2.4653764168421426

Epoch: 6| Step: 13
Training loss: 2.4005825519561768
Validation loss: 2.46243155002594

Epoch: 49| Step: 0
Training loss: 2.962501049041748
Validation loss: 2.461272716522217

Epoch: 6| Step: 1
Training loss: 2.9719133377075195
Validation loss: 2.4555930693944297

Epoch: 6| Step: 2
Training loss: 2.1583285331726074
Validation loss: 2.4517544507980347

Epoch: 6| Step: 3
Training loss: 3.1118974685668945
Validation loss: 2.4493454893430076

Epoch: 6| Step: 4
Training loss: 1.6005367040634155
Validation loss: 2.448731859525045

Epoch: 6| Step: 5
Training loss: 2.5629422664642334
Validation loss: 2.442900458971659

Epoch: 6| Step: 6
Training loss: 3.2355005741119385
Validation loss: 2.4458595514297485

Epoch: 6| Step: 7
Training loss: 3.035048007965088
Validation loss: 2.4419862429300943

Epoch: 6| Step: 8
Training loss: 2.494325876235962
Validation loss: 2.4387385845184326

Epoch: 6| Step: 9
Training loss: 2.4306483268737793
Validation loss: 2.438344677289327

Epoch: 6| Step: 10
Training loss: 2.111341953277588
Validation loss: 2.4384443362553916

Epoch: 6| Step: 11
Training loss: 2.784213066101074
Validation loss: 2.435030142466227

Epoch: 6| Step: 12
Training loss: 3.301607608795166
Validation loss: 2.4322150548299155

Epoch: 6| Step: 13
Training loss: 2.0064809322357178
Validation loss: 2.425901452700297

Epoch: 50| Step: 0
Training loss: 2.8310327529907227
Validation loss: 2.4196539521217346

Epoch: 6| Step: 1
Training loss: 2.5216481685638428
Validation loss: 2.4251027504603067

Epoch: 6| Step: 2
Training loss: 2.604618549346924
Validation loss: 2.417953530947367

Epoch: 6| Step: 3
Training loss: 2.24712872505188
Validation loss: 2.413711190223694

Epoch: 6| Step: 4
Training loss: 2.5525286197662354
Validation loss: 2.415881554285685

Epoch: 6| Step: 5
Training loss: 2.000391960144043
Validation loss: 2.4124401609102883

Epoch: 6| Step: 6
Training loss: 2.8392457962036133
Validation loss: 2.410659154256185

Epoch: 6| Step: 7
Training loss: 3.1210851669311523
Validation loss: 2.4085519313812256

Epoch: 6| Step: 8
Training loss: 2.865962505340576
Validation loss: 2.4062697092692056

Epoch: 6| Step: 9
Training loss: 2.633573532104492
Validation loss: 2.402233839035034

Epoch: 6| Step: 10
Training loss: 2.6454267501831055
Validation loss: 2.399957855542501

Epoch: 6| Step: 11
Training loss: 2.1729624271392822
Validation loss: 2.396252473195394

Epoch: 6| Step: 12
Training loss: 2.568748950958252
Validation loss: 2.3920632203420005

Epoch: 6| Step: 13
Training loss: 2.6112449169158936
Validation loss: 2.3937666018803916

Epoch: 51| Step: 0
Training loss: 2.8417835235595703
Validation loss: 2.392133414745331

Epoch: 6| Step: 1
Training loss: 2.1288790702819824
Validation loss: 2.3870271841684976

Epoch: 6| Step: 2
Training loss: 2.808488368988037
Validation loss: 2.3838336865107217

Epoch: 6| Step: 3
Training loss: 2.8089537620544434
Validation loss: 2.384077807267507

Epoch: 6| Step: 4
Training loss: 2.5518875122070312
Validation loss: 2.3800563414891562

Epoch: 6| Step: 5
Training loss: 2.3845505714416504
Validation loss: 2.3762893279393515

Epoch: 6| Step: 6
Training loss: 2.2605719566345215
Validation loss: 2.3776829640070596

Epoch: 6| Step: 7
Training loss: 2.89565372467041
Validation loss: 2.373913745085398

Epoch: 6| Step: 8
Training loss: 2.1414051055908203
Validation loss: 2.3714609940846763

Epoch: 6| Step: 9
Training loss: 2.98957896232605
Validation loss: 2.3676382104555764

Epoch: 6| Step: 10
Training loss: 2.5335135459899902
Validation loss: 2.3653666973114014

Epoch: 6| Step: 11
Training loss: 2.2525570392608643
Validation loss: 2.364499807357788

Epoch: 6| Step: 12
Training loss: 2.9435391426086426
Validation loss: 2.360361953576406

Epoch: 6| Step: 13
Training loss: 2.150658130645752
Validation loss: 2.3629921674728394

Epoch: 52| Step: 0
Training loss: 2.510134696960449
Validation loss: 2.357360819975535

Epoch: 6| Step: 1
Training loss: 2.2755417823791504
Validation loss: 2.3618866999944053

Epoch: 6| Step: 2
Training loss: 2.7469234466552734
Validation loss: 2.3611133694648743

Epoch: 6| Step: 3
Training loss: 2.321950912475586
Validation loss: 2.351291557153066

Epoch: 6| Step: 4
Training loss: 2.5087995529174805
Validation loss: 2.354637304941813

Epoch: 6| Step: 5
Training loss: 3.029384136199951
Validation loss: 2.346819281578064

Epoch: 6| Step: 6
Training loss: 2.350391387939453
Validation loss: 2.346480965614319

Epoch: 6| Step: 7
Training loss: 2.755025863647461
Validation loss: 2.3429394563039145

Epoch: 6| Step: 8
Training loss: 2.2805099487304688
Validation loss: 2.3396382331848145

Epoch: 6| Step: 9
Training loss: 3.004243850708008
Validation loss: 2.340482314427694

Epoch: 6| Step: 10
Training loss: 1.8811631202697754
Validation loss: 2.336902896563212

Epoch: 6| Step: 11
Training loss: 2.483135223388672
Validation loss: 2.3341718514760337

Epoch: 6| Step: 12
Training loss: 2.6140663623809814
Validation loss: 2.332645614941915

Epoch: 6| Step: 13
Training loss: 2.4516773223876953
Validation loss: 2.3307116826375327

Epoch: 53| Step: 0
Training loss: 2.527060031890869
Validation loss: 2.330117344856262

Epoch: 6| Step: 1
Training loss: 2.1342804431915283
Validation loss: 2.3307573397954306

Epoch: 6| Step: 2
Training loss: 2.5312576293945312
Validation loss: 2.3248961766560874

Epoch: 6| Step: 3
Training loss: 2.51820707321167
Validation loss: 2.323354204495748

Epoch: 6| Step: 4
Training loss: 2.3214669227600098
Validation loss: 2.3241296211878457

Epoch: 6| Step: 5
Training loss: 2.5911753177642822
Validation loss: 2.3237696488698325

Epoch: 6| Step: 6
Training loss: 2.1660172939300537
Validation loss: 2.326937953631083

Epoch: 6| Step: 7
Training loss: 2.728877544403076
Validation loss: 2.320701758066813

Epoch: 6| Step: 8
Training loss: 2.331178665161133
Validation loss: 2.327588359514872

Epoch: 6| Step: 9
Training loss: 2.07623291015625
Validation loss: 2.327606280644735

Epoch: 6| Step: 10
Training loss: 2.5270442962646484
Validation loss: 2.3189547657966614

Epoch: 6| Step: 11
Training loss: 2.970940351486206
Validation loss: 2.3074355522791543

Epoch: 6| Step: 12
Training loss: 2.4444403648376465
Validation loss: 2.303063213825226

Epoch: 6| Step: 13
Training loss: 2.9530837535858154
Validation loss: 2.3018569350242615

Epoch: 54| Step: 0
Training loss: 3.159574031829834
Validation loss: 2.2982189059257507

Epoch: 6| Step: 1
Training loss: 2.516482353210449
Validation loss: 2.2982051571210227

Epoch: 6| Step: 2
Training loss: 2.400768518447876
Validation loss: 2.2989999651908875

Epoch: 6| Step: 3
Training loss: 2.271914482116699
Validation loss: 2.2981016635894775

Epoch: 6| Step: 4
Training loss: 2.0569090843200684
Validation loss: 2.2933897972106934

Epoch: 6| Step: 5
Training loss: 2.5266928672790527
Validation loss: 2.288985311985016

Epoch: 6| Step: 6
Training loss: 2.520051956176758
Validation loss: 2.286651611328125

Epoch: 6| Step: 7
Training loss: 2.0429654121398926
Validation loss: 2.2831023534139

Epoch: 6| Step: 8
Training loss: 1.9605329036712646
Validation loss: 2.282172938187917

Epoch: 6| Step: 9
Training loss: 1.9490835666656494
Validation loss: 2.282411833604177

Epoch: 6| Step: 10
Training loss: 2.9873275756835938
Validation loss: 2.27726020415624

Epoch: 6| Step: 11
Training loss: 2.9031569957733154
Validation loss: 2.273497760295868

Epoch: 6| Step: 12
Training loss: 2.170473337173462
Validation loss: 2.2744542360305786

Epoch: 6| Step: 13
Training loss: 2.8498647212982178
Validation loss: 2.2709739208221436

Epoch: 55| Step: 0
Training loss: 2.627181053161621
Validation loss: 2.2703717947006226

Epoch: 6| Step: 1
Training loss: 2.184685230255127
Validation loss: 2.264816423257192

Epoch: 6| Step: 2
Training loss: 2.2261996269226074
Validation loss: 2.268417497475942

Epoch: 6| Step: 3
Training loss: 3.0444443225860596
Validation loss: 2.262587289015452

Epoch: 6| Step: 4
Training loss: 2.4588513374328613
Validation loss: 2.258680820465088

Epoch: 6| Step: 5
Training loss: 2.6393399238586426
Validation loss: 2.2568551699320474

Epoch: 6| Step: 6
Training loss: 2.3362579345703125
Validation loss: 2.2548953692118325

Epoch: 6| Step: 7
Training loss: 2.6293811798095703
Validation loss: 2.2558427651723227

Epoch: 6| Step: 8
Training loss: 2.626303195953369
Validation loss: 2.253307501475016

Epoch: 6| Step: 9
Training loss: 2.217931032180786
Validation loss: 2.248217682043711

Epoch: 6| Step: 10
Training loss: 2.4534430503845215
Validation loss: 2.2463534077008567

Epoch: 6| Step: 11
Training loss: 2.2974655628204346
Validation loss: 2.243141293525696

Epoch: 6| Step: 12
Training loss: 2.039318084716797
Validation loss: 2.2415464520454407

Epoch: 6| Step: 13
Training loss: 2.0191431045532227
Validation loss: 2.2441449960072837

Epoch: 56| Step: 0
Training loss: 2.791969060897827
Validation loss: 2.239185849825541

Epoch: 6| Step: 1
Training loss: 3.097508430480957
Validation loss: 2.237276871999105

Epoch: 6| Step: 2
Training loss: 2.5459136962890625
Validation loss: 2.2360899845759072

Epoch: 6| Step: 3
Training loss: 2.118030309677124
Validation loss: 2.2356236378351846

Epoch: 6| Step: 4
Training loss: 1.7236990928649902
Validation loss: 2.2288410464922586

Epoch: 6| Step: 5
Training loss: 2.8646199703216553
Validation loss: 2.2312972942988076

Epoch: 6| Step: 6
Training loss: 1.9136661291122437
Validation loss: 2.230695962905884

Epoch: 6| Step: 7
Training loss: 2.0130929946899414
Validation loss: 2.225876728693644

Epoch: 6| Step: 8
Training loss: 1.3462871313095093
Validation loss: 2.2275015115737915

Epoch: 6| Step: 9
Training loss: 2.7871689796447754
Validation loss: 2.221547484397888

Epoch: 6| Step: 10
Training loss: 2.479095220565796
Validation loss: 2.220959266026815

Epoch: 6| Step: 11
Training loss: 2.938939094543457
Validation loss: 2.221230943997701

Epoch: 6| Step: 12
Training loss: 2.0072712898254395
Validation loss: 2.213455239931742

Epoch: 6| Step: 13
Training loss: 2.700350761413574
Validation loss: 2.2155176798502603

Epoch: 57| Step: 0
Training loss: 2.2088711261749268
Validation loss: 2.2177590131759644

Epoch: 6| Step: 1
Training loss: 2.6778006553649902
Validation loss: 2.214408000310262

Epoch: 6| Step: 2
Training loss: 2.057875633239746
Validation loss: 2.2086608608563743

Epoch: 6| Step: 3
Training loss: 2.169105291366577
Validation loss: 2.2065365513165793

Epoch: 6| Step: 4
Training loss: 2.9141273498535156
Validation loss: 2.2123140494028726

Epoch: 6| Step: 5
Training loss: 2.2378785610198975
Validation loss: 2.207151929537455

Epoch: 6| Step: 6
Training loss: 2.485260486602783
Validation loss: 2.209411640961965

Epoch: 6| Step: 7
Training loss: 2.6406922340393066
Validation loss: 2.2020646731058755

Epoch: 6| Step: 8
Training loss: 1.5896098613739014
Validation loss: 2.2029210329055786

Epoch: 6| Step: 9
Training loss: 2.2260398864746094
Validation loss: 2.2009835839271545

Epoch: 6| Step: 10
Training loss: 2.545591354370117
Validation loss: 2.198810875415802

Epoch: 6| Step: 11
Training loss: 2.678650379180908
Validation loss: 2.199084758758545

Epoch: 6| Step: 12
Training loss: 2.4008872509002686
Validation loss: 2.19479372104009

Epoch: 6| Step: 13
Training loss: 2.20348858833313
Validation loss: 2.191026985645294

Epoch: 58| Step: 0
Training loss: 2.0817441940307617
Validation loss: 2.1904656887054443

Epoch: 6| Step: 1
Training loss: 2.3198208808898926
Validation loss: 2.186372001965841

Epoch: 6| Step: 2
Training loss: 2.7932748794555664
Validation loss: 2.18818062543869

Epoch: 6| Step: 3
Training loss: 1.3667927980422974
Validation loss: 2.1861124833424888

Epoch: 6| Step: 4
Training loss: 2.425372362136841
Validation loss: 2.1930238008499146

Epoch: 6| Step: 5
Training loss: 2.1233692169189453
Validation loss: 2.1879125833511353

Epoch: 6| Step: 6
Training loss: 1.9960849285125732
Validation loss: 2.182882845401764

Epoch: 6| Step: 7
Training loss: 2.595205068588257
Validation loss: 2.1902019381523132

Epoch: 6| Step: 8
Training loss: 3.270658016204834
Validation loss: 2.1876001954078674

Epoch: 6| Step: 9
Training loss: 2.746260643005371
Validation loss: 2.1880874236424765

Epoch: 6| Step: 10
Training loss: 2.4341113567352295
Validation loss: 2.178385853767395

Epoch: 6| Step: 11
Training loss: 1.8247021436691284
Validation loss: 2.1742751399676004

Epoch: 6| Step: 12
Training loss: 2.05000638961792
Validation loss: 2.173952062924703

Epoch: 6| Step: 13
Training loss: 2.737542152404785
Validation loss: 2.1705551147460938

Epoch: 59| Step: 0
Training loss: 1.9095730781555176
Validation loss: 2.1771158377329507

Epoch: 6| Step: 1
Training loss: 2.3801865577697754
Validation loss: 2.172735850016276

Epoch: 6| Step: 2
Training loss: 2.767085075378418
Validation loss: 2.1693158944447837

Epoch: 6| Step: 3
Training loss: 2.2290244102478027
Validation loss: 2.166075885295868

Epoch: 6| Step: 4
Training loss: 2.7692055702209473
Validation loss: 2.165813465913137

Epoch: 6| Step: 5
Training loss: 2.0958619117736816
Validation loss: 2.1679449478785195

Epoch: 6| Step: 6
Training loss: 2.5688529014587402
Validation loss: 2.16497274239858

Epoch: 6| Step: 7
Training loss: 2.363647937774658
Validation loss: 2.1667615373929343

Epoch: 6| Step: 8
Training loss: 2.4378819465637207
Validation loss: 2.1687868436177573

Epoch: 6| Step: 9
Training loss: 2.695619583129883
Validation loss: 2.1597182353337607

Epoch: 6| Step: 10
Training loss: 2.2962217330932617
Validation loss: 2.156929870446523

Epoch: 6| Step: 11
Training loss: 1.5888906717300415
Validation loss: 2.157906472682953

Epoch: 6| Step: 12
Training loss: 1.9905412197113037
Validation loss: 2.160927693049113

Epoch: 6| Step: 13
Training loss: 2.4161314964294434
Validation loss: 2.1613466143608093

Epoch: 60| Step: 0
Training loss: 2.62821626663208
Validation loss: 2.1572279930114746

Epoch: 6| Step: 1
Training loss: 1.9752745628356934
Validation loss: 2.157665272553762

Epoch: 6| Step: 2
Training loss: 2.8721063137054443
Validation loss: 2.164191206296285

Epoch: 6| Step: 3
Training loss: 2.282686233520508
Validation loss: 2.164715051651001

Epoch: 6| Step: 4
Training loss: 2.271495819091797
Validation loss: 2.1685564120610556

Epoch: 6| Step: 5
Training loss: 1.82631254196167
Validation loss: 2.1607947746912637

Epoch: 6| Step: 6
Training loss: 1.9232850074768066
Validation loss: 2.1568660736083984

Epoch: 6| Step: 7
Training loss: 2.5782015323638916
Validation loss: 2.1428873538970947

Epoch: 6| Step: 8
Training loss: 2.7411255836486816
Validation loss: 2.1462111274401345

Epoch: 6| Step: 9
Training loss: 2.4531166553497314
Validation loss: 2.149889608224233

Epoch: 6| Step: 10
Training loss: 2.2630748748779297
Validation loss: 2.148303965727488

Epoch: 6| Step: 11
Training loss: 2.546027421951294
Validation loss: 2.1493263641993203

Epoch: 6| Step: 12
Training loss: 2.2426605224609375
Validation loss: 2.1486132542292276

Epoch: 6| Step: 13
Training loss: 1.724736213684082
Validation loss: 2.14574788014094

Epoch: 61| Step: 0
Training loss: 2.4073665142059326
Validation loss: 2.1484750707944236

Epoch: 6| Step: 1
Training loss: 2.3017141819000244
Validation loss: 2.13681830962499

Epoch: 6| Step: 2
Training loss: 2.1176505088806152
Validation loss: 2.1309964259465537

Epoch: 6| Step: 3
Training loss: 2.504379987716675
Validation loss: 2.1340638796488443

Epoch: 6| Step: 4
Training loss: 2.4580001831054688
Validation loss: 2.138307571411133

Epoch: 6| Step: 5
Training loss: 1.972900152206421
Validation loss: 2.1386618614196777

Epoch: 6| Step: 6
Training loss: 2.4906086921691895
Validation loss: 2.1349835991859436

Epoch: 6| Step: 7
Training loss: 2.0437979698181152
Validation loss: 2.132271965344747

Epoch: 6| Step: 8
Training loss: 2.127692937850952
Validation loss: 2.134132961432139

Epoch: 6| Step: 9
Training loss: 1.8184318542480469
Validation loss: 2.1290587782859802

Epoch: 6| Step: 10
Training loss: 2.2293264865875244
Validation loss: 2.1321386893590293

Epoch: 6| Step: 11
Training loss: 2.864373207092285
Validation loss: 2.1271461844444275

Epoch: 6| Step: 12
Training loss: 2.6214542388916016
Validation loss: 2.135212500890096

Epoch: 6| Step: 13
Training loss: 2.2167115211486816
Validation loss: 2.12833164135615

Epoch: 62| Step: 0
Training loss: 2.5370116233825684
Validation loss: 2.131953159968058

Epoch: 6| Step: 1
Training loss: 1.957771897315979
Validation loss: 2.123355984687805

Epoch: 6| Step: 2
Training loss: 2.4312562942504883
Validation loss: 2.1212276021639505

Epoch: 6| Step: 3
Training loss: 2.0707318782806396
Validation loss: 2.127244849999746

Epoch: 6| Step: 4
Training loss: 2.1749496459960938
Validation loss: 2.118894636631012

Epoch: 6| Step: 5
Training loss: 1.770667314529419
Validation loss: 2.1226505637168884

Epoch: 6| Step: 6
Training loss: 2.1788063049316406
Validation loss: 2.120750069618225

Epoch: 6| Step: 7
Training loss: 2.1254820823669434
Validation loss: 2.120075066884359

Epoch: 6| Step: 8
Training loss: 3.1545610427856445
Validation loss: 2.1139958699544272

Epoch: 6| Step: 9
Training loss: 2.5756564140319824
Validation loss: 2.122063318888346

Epoch: 6| Step: 10
Training loss: 2.5395150184631348
Validation loss: 2.1184352040290833

Epoch: 6| Step: 11
Training loss: 1.7974565029144287
Validation loss: 2.112012187639872

Epoch: 6| Step: 12
Training loss: 2.2451186180114746
Validation loss: 2.1134944558143616

Epoch: 6| Step: 13
Training loss: 2.447622776031494
Validation loss: 2.1129358808199563

Epoch: 63| Step: 0
Training loss: 2.357295036315918
Validation loss: 2.1122359236081443

Epoch: 6| Step: 1
Training loss: 2.8028063774108887
Validation loss: 2.1091116070747375

Epoch: 6| Step: 2
Training loss: 2.754685401916504
Validation loss: 2.11330238978068

Epoch: 6| Step: 3
Training loss: 2.2553110122680664
Validation loss: 2.11379337310791

Epoch: 6| Step: 4
Training loss: 2.373091220855713
Validation loss: 2.1099814971288047

Epoch: 6| Step: 5
Training loss: 1.6484038829803467
Validation loss: 2.104729175567627

Epoch: 6| Step: 6
Training loss: 2.410884380340576
Validation loss: 2.1095520655314126

Epoch: 6| Step: 7
Training loss: 1.3863039016723633
Validation loss: 2.107203245162964

Epoch: 6| Step: 8
Training loss: 2.6717662811279297
Validation loss: 2.1050753196080527

Epoch: 6| Step: 9
Training loss: 1.7239508628845215
Validation loss: 2.110559046268463

Epoch: 6| Step: 10
Training loss: 2.5575366020202637
Validation loss: 2.10803614060084

Epoch: 6| Step: 11
Training loss: 1.9156749248504639
Validation loss: 2.0992904702822366

Epoch: 6| Step: 12
Training loss: 2.7057695388793945
Validation loss: 2.095875322818756

Epoch: 6| Step: 13
Training loss: 2.2191052436828613
Validation loss: 2.0977622270584106

Epoch: 64| Step: 0
Training loss: 1.7424440383911133
Validation loss: 2.101853847503662

Epoch: 6| Step: 1
Training loss: 2.3979249000549316
Validation loss: 2.1123852531115213

Epoch: 6| Step: 2
Training loss: 2.4721813201904297
Validation loss: 2.1128007570902505

Epoch: 6| Step: 3
Training loss: 2.137885808944702
Validation loss: 2.1084993481636047

Epoch: 6| Step: 4
Training loss: 2.553776264190674
Validation loss: 2.1123812596003213

Epoch: 6| Step: 5
Training loss: 1.964827299118042
Validation loss: 2.0997522672017417

Epoch: 6| Step: 6
Training loss: 2.8612313270568848
Validation loss: 2.10273140668869

Epoch: 6| Step: 7
Training loss: 2.082205057144165
Validation loss: 2.102054556210836

Epoch: 6| Step: 8
Training loss: 2.3108396530151367
Validation loss: 2.0968627532323203

Epoch: 6| Step: 9
Training loss: 1.8416659832000732
Validation loss: 2.0948623418807983

Epoch: 6| Step: 10
Training loss: 2.312169075012207
Validation loss: 2.092390457789103

Epoch: 6| Step: 11
Training loss: 2.6616413593292236
Validation loss: 2.09281716744105

Epoch: 6| Step: 12
Training loss: 2.480130195617676
Validation loss: 2.089335799217224

Epoch: 6| Step: 13
Training loss: 1.8875718116760254
Validation loss: 2.0867591500282288

Epoch: 65| Step: 0
Training loss: 2.435636043548584
Validation loss: 2.083775063355764

Epoch: 6| Step: 1
Training loss: 2.3980064392089844
Validation loss: 2.0904648502667746

Epoch: 6| Step: 2
Training loss: 2.5955381393432617
Validation loss: 2.0922104914983115

Epoch: 6| Step: 3
Training loss: 1.6263420581817627
Validation loss: 2.0918589433034263

Epoch: 6| Step: 4
Training loss: 1.7595529556274414
Validation loss: 2.093997895717621

Epoch: 6| Step: 5
Training loss: 2.4546730518341064
Validation loss: 2.0965582529703775

Epoch: 6| Step: 6
Training loss: 2.6389248371124268
Validation loss: 2.094012180964152

Epoch: 6| Step: 7
Training loss: 2.7121074199676514
Validation loss: 2.0857338110605874

Epoch: 6| Step: 8
Training loss: 2.348111391067505
Validation loss: 2.0846922794977822

Epoch: 6| Step: 9
Training loss: 2.1863160133361816
Validation loss: 2.078422963619232

Epoch: 6| Step: 10
Training loss: 1.9773417711257935
Validation loss: 2.0827235778172812

Epoch: 6| Step: 11
Training loss: 1.8858040571212769
Validation loss: 2.0822574496269226

Epoch: 6| Step: 12
Training loss: 2.2968931198120117
Validation loss: 2.07711790005366

Epoch: 6| Step: 13
Training loss: 2.2761006355285645
Validation loss: 2.0793707172075906

Epoch: 66| Step: 0
Training loss: 1.823563814163208
Validation loss: 2.076499323050181

Epoch: 6| Step: 1
Training loss: 2.45241641998291
Validation loss: 2.084353824456533

Epoch: 6| Step: 2
Training loss: 2.6185624599456787
Validation loss: 2.0825201272964478

Epoch: 6| Step: 3
Training loss: 2.4862825870513916
Validation loss: 2.0817152857780457

Epoch: 6| Step: 4
Training loss: 3.0789108276367188
Validation loss: 2.0813617507616677

Epoch: 6| Step: 5
Training loss: 2.083984613418579
Validation loss: 2.079554796218872

Epoch: 6| Step: 6
Training loss: 2.3356575965881348
Validation loss: 2.0776012738545737

Epoch: 6| Step: 7
Training loss: 2.068331480026245
Validation loss: 2.0844167868296304

Epoch: 6| Step: 8
Training loss: 2.1918141841888428
Validation loss: 2.0759841402371726

Epoch: 6| Step: 9
Training loss: 2.3546946048736572
Validation loss: 2.0765121976534524

Epoch: 6| Step: 10
Training loss: 2.5242981910705566
Validation loss: 2.080098509788513

Epoch: 6| Step: 11
Training loss: 1.9324839115142822
Validation loss: 2.0764238834381104

Epoch: 6| Step: 12
Training loss: 1.4193642139434814
Validation loss: 2.075355072816213

Epoch: 6| Step: 13
Training loss: 2.2282462120056152
Validation loss: 2.0707948009173074

Epoch: 67| Step: 0
Training loss: 2.0792627334594727
Validation loss: 2.068042496840159

Epoch: 6| Step: 1
Training loss: 1.691150188446045
Validation loss: 2.0691750049591064

Epoch: 6| Step: 2
Training loss: 2.1750924587249756
Validation loss: 2.0721108118693032

Epoch: 6| Step: 3
Training loss: 2.4109010696411133
Validation loss: 2.0718934337298074

Epoch: 6| Step: 4
Training loss: 2.0098519325256348
Validation loss: 2.066857695579529

Epoch: 6| Step: 5
Training loss: 2.538090229034424
Validation loss: 2.0716410080591836

Epoch: 6| Step: 6
Training loss: 2.0183801651000977
Validation loss: 2.068883001804352

Epoch: 6| Step: 7
Training loss: 2.598789691925049
Validation loss: 2.0675950249036155

Epoch: 6| Step: 8
Training loss: 2.387220859527588
Validation loss: 2.068872312704722

Epoch: 6| Step: 9
Training loss: 1.9616739749908447
Validation loss: 2.071492592493693

Epoch: 6| Step: 10
Training loss: 2.449491024017334
Validation loss: 2.069249153137207

Epoch: 6| Step: 11
Training loss: 1.8183454275131226
Validation loss: 2.0690562029679618

Epoch: 6| Step: 12
Training loss: 2.3479442596435547
Validation loss: 2.071450332800547

Epoch: 6| Step: 13
Training loss: 2.8688204288482666
Validation loss: 2.0679021875063577

Epoch: 68| Step: 0
Training loss: 2.014615535736084
Validation loss: 2.0691097577412925

Epoch: 6| Step: 1
Training loss: 2.287161350250244
Validation loss: 2.0683578054110208

Epoch: 6| Step: 2
Training loss: 1.6972758769989014
Validation loss: 2.0694074034690857

Epoch: 6| Step: 3
Training loss: 2.503843307495117
Validation loss: 2.0686028798421225

Epoch: 6| Step: 4
Training loss: 2.895430088043213
Validation loss: 2.0670690735181174

Epoch: 6| Step: 5
Training loss: 2.4942588806152344
Validation loss: 2.0654640396436057

Epoch: 6| Step: 6
Training loss: 2.5132603645324707
Validation loss: 2.061783254146576

Epoch: 6| Step: 7
Training loss: 1.9436949491500854
Validation loss: 2.0610059102376304

Epoch: 6| Step: 8
Training loss: 2.3307595252990723
Validation loss: 2.0635730822881064

Epoch: 6| Step: 9
Training loss: 2.159287929534912
Validation loss: 2.0572599371274314

Epoch: 6| Step: 10
Training loss: 1.854187250137329
Validation loss: 2.0588717063268027

Epoch: 6| Step: 11
Training loss: 2.7754058837890625
Validation loss: 2.0538983146349588

Epoch: 6| Step: 12
Training loss: 1.4170937538146973
Validation loss: 2.0558086037635803

Epoch: 6| Step: 13
Training loss: 2.4125213623046875
Validation loss: 2.049327830473582

Epoch: 69| Step: 0
Training loss: 2.192246198654175
Validation loss: 2.0575292905171714

Epoch: 6| Step: 1
Training loss: 2.3067679405212402
Validation loss: 2.0591037273406982

Epoch: 6| Step: 2
Training loss: 2.8516485691070557
Validation loss: 2.060968339443207

Epoch: 6| Step: 3
Training loss: 2.5021376609802246
Validation loss: 2.061707297960917

Epoch: 6| Step: 4
Training loss: 2.4041099548339844
Validation loss: 2.0548227628072104

Epoch: 6| Step: 5
Training loss: 1.6588066816329956
Validation loss: 2.052212099234263

Epoch: 6| Step: 6
Training loss: 2.572892665863037
Validation loss: 2.0533753434816995

Epoch: 6| Step: 7
Training loss: 2.0311832427978516
Validation loss: 2.050105075041453

Epoch: 6| Step: 8
Training loss: 2.19766902923584
Validation loss: 2.0495819250742593

Epoch: 6| Step: 9
Training loss: 1.8363457918167114
Validation loss: 2.0582509438196817

Epoch: 6| Step: 10
Training loss: 1.9664794206619263
Validation loss: 2.067029436429342

Epoch: 6| Step: 11
Training loss: 2.1831321716308594
Validation loss: 2.058596611022949

Epoch: 6| Step: 12
Training loss: 2.176546573638916
Validation loss: 2.0753833651542664

Epoch: 6| Step: 13
Training loss: 2.207066774368286
Validation loss: 2.069567640622457

Epoch: 70| Step: 0
Training loss: 2.648632764816284
Validation loss: 2.0614740451176963

Epoch: 6| Step: 1
Training loss: 2.2550854682922363
Validation loss: 2.057971258958181

Epoch: 6| Step: 2
Training loss: 2.3227641582489014
Validation loss: 2.063660720984141

Epoch: 6| Step: 3
Training loss: 2.090331792831421
Validation loss: 2.061420222123464

Epoch: 6| Step: 4
Training loss: 2.0101048946380615
Validation loss: 2.0575746099154153

Epoch: 6| Step: 5
Training loss: 2.244751214981079
Validation loss: 2.078561226526896

Epoch: 6| Step: 6
Training loss: 2.0841801166534424
Validation loss: 2.0625796914100647

Epoch: 6| Step: 7
Training loss: 2.156747341156006
Validation loss: 2.0681403080622354

Epoch: 6| Step: 8
Training loss: 2.7091124057769775
Validation loss: 2.061574161052704

Epoch: 6| Step: 9
Training loss: 1.8894970417022705
Validation loss: 2.04915060599645

Epoch: 6| Step: 10
Training loss: 2.804696559906006
Validation loss: 2.0531612038612366

Epoch: 6| Step: 11
Training loss: 1.972121238708496
Validation loss: 2.042147696018219

Epoch: 6| Step: 12
Training loss: 2.0747017860412598
Validation loss: 2.0478107929229736

Epoch: 6| Step: 13
Training loss: 2.15348219871521
Validation loss: 2.052331586678823

Epoch: 71| Step: 0
Training loss: 2.6746654510498047
Validation loss: 2.052699863910675

Epoch: 6| Step: 1
Training loss: 1.6439459323883057
Validation loss: 2.0543640851974487

Epoch: 6| Step: 2
Training loss: 2.029982328414917
Validation loss: 2.0554178953170776

Epoch: 6| Step: 3
Training loss: 2.961169958114624
Validation loss: 2.055993656317393

Epoch: 6| Step: 4
Training loss: 3.0377700328826904
Validation loss: 2.054615875085195

Epoch: 6| Step: 5
Training loss: 1.9095559120178223
Validation loss: 2.058993478616079

Epoch: 6| Step: 6
Training loss: 2.3311586380004883
Validation loss: 2.0531481504440308

Epoch: 6| Step: 7
Training loss: 1.8356021642684937
Validation loss: 2.05352912346522

Epoch: 6| Step: 8
Training loss: 2.0777909755706787
Validation loss: 2.0539056062698364

Epoch: 6| Step: 9
Training loss: 1.987027645111084
Validation loss: 2.051853974660238

Epoch: 6| Step: 10
Training loss: 2.199275493621826
Validation loss: 2.0504651268323264

Epoch: 6| Step: 11
Training loss: 1.9383145570755005
Validation loss: 2.045527696609497

Epoch: 6| Step: 12
Training loss: 2.344578742980957
Validation loss: 2.048133591810862

Epoch: 6| Step: 13
Training loss: 2.3096768856048584
Validation loss: 2.038069248199463

Epoch: 72| Step: 0
Training loss: 1.6080236434936523
Validation loss: 2.0402971108754477

Epoch: 6| Step: 1
Training loss: 2.1629414558410645
Validation loss: 2.030937612056732

Epoch: 6| Step: 2
Training loss: 2.480457305908203
Validation loss: 2.029605428377787

Epoch: 6| Step: 3
Training loss: 2.5808160305023193
Validation loss: 2.0302260319391885

Epoch: 6| Step: 4
Training loss: 2.2348012924194336
Validation loss: 2.035486340522766

Epoch: 6| Step: 5
Training loss: 2.630213499069214
Validation loss: 2.0317957003911338

Epoch: 6| Step: 6
Training loss: 2.3564515113830566
Validation loss: 2.0381489992141724

Epoch: 6| Step: 7
Training loss: 2.7111358642578125
Validation loss: 2.043163001537323

Epoch: 6| Step: 8
Training loss: 2.225288152694702
Validation loss: 2.0458677609761557

Epoch: 6| Step: 9
Training loss: 1.8129700422286987
Validation loss: 2.042506376902262

Epoch: 6| Step: 10
Training loss: 1.9026732444763184
Validation loss: 2.041804552078247

Epoch: 6| Step: 11
Training loss: 2.1027891635894775
Validation loss: 2.042318284511566

Epoch: 6| Step: 12
Training loss: 1.999991536140442
Validation loss: 2.042159140110016

Epoch: 6| Step: 13
Training loss: 2.1550440788269043
Validation loss: 2.050795078277588

Epoch: 73| Step: 0
Training loss: 2.190139055252075
Validation loss: 2.0456745823224387

Epoch: 6| Step: 1
Training loss: 1.6725153923034668
Validation loss: 2.0402546326319375

Epoch: 6| Step: 2
Training loss: 2.4609293937683105
Validation loss: 2.037925640741984

Epoch: 6| Step: 3
Training loss: 2.6143996715545654
Validation loss: 2.0394383668899536

Epoch: 6| Step: 4
Training loss: 2.0211453437805176
Validation loss: 2.032372613747915

Epoch: 6| Step: 5
Training loss: 2.0769245624542236
Validation loss: 2.0326885183652244

Epoch: 6| Step: 6
Training loss: 2.7238073348999023
Validation loss: 2.035778522491455

Epoch: 6| Step: 7
Training loss: 1.9027931690216064
Validation loss: 2.0305299957593284

Epoch: 6| Step: 8
Training loss: 2.2041215896606445
Validation loss: 2.0276155273119607

Epoch: 6| Step: 9
Training loss: 2.2923693656921387
Validation loss: 2.0369137128194175

Epoch: 6| Step: 10
Training loss: 2.5352625846862793
Validation loss: 2.0396512945493064

Epoch: 6| Step: 11
Training loss: 1.5637905597686768
Validation loss: 2.040010134379069

Epoch: 6| Step: 12
Training loss: 2.2475383281707764
Validation loss: 2.0434970259666443

Epoch: 6| Step: 13
Training loss: 2.5609841346740723
Validation loss: 2.0435887376467385

Epoch: 74| Step: 0
Training loss: 2.3199849128723145
Validation loss: 2.0442842642466226

Epoch: 6| Step: 1
Training loss: 1.8983417749404907
Validation loss: 2.0447245836257935

Epoch: 6| Step: 2
Training loss: 1.7835649251937866
Validation loss: 2.038443704446157

Epoch: 6| Step: 3
Training loss: 2.196181535720825
Validation loss: 2.035995443662008

Epoch: 6| Step: 4
Training loss: 2.52034854888916
Validation loss: 2.0292734702428183

Epoch: 6| Step: 5
Training loss: 2.589020013809204
Validation loss: 2.0340706507364907

Epoch: 6| Step: 6
Training loss: 2.31327486038208
Validation loss: 2.0328193505605063

Epoch: 6| Step: 7
Training loss: 2.135254144668579
Validation loss: 2.04473610719045

Epoch: 6| Step: 8
Training loss: 1.7356311082839966
Validation loss: 2.040912946065267

Epoch: 6| Step: 9
Training loss: 2.030285358428955
Validation loss: 2.051000654697418

Epoch: 6| Step: 10
Training loss: 1.7799232006072998
Validation loss: 2.0383360584576926

Epoch: 6| Step: 11
Training loss: 2.6123228073120117
Validation loss: 2.042702833811442

Epoch: 6| Step: 12
Training loss: 2.3641695976257324
Validation loss: 2.036837120850881

Epoch: 6| Step: 13
Training loss: 3.0075416564941406
Validation loss: 2.0277432998021445

Epoch: 75| Step: 0
Training loss: 1.825229287147522
Validation loss: 2.027295549710592

Epoch: 6| Step: 1
Training loss: 2.8527355194091797
Validation loss: 2.0273534854253135

Epoch: 6| Step: 2
Training loss: 2.189012289047241
Validation loss: 2.035253365834554

Epoch: 6| Step: 3
Training loss: 2.3858089447021484
Validation loss: 2.0300538142522178

Epoch: 6| Step: 4
Training loss: 2.5717477798461914
Validation loss: 2.034147481123606

Epoch: 6| Step: 5
Training loss: 2.4450440406799316
Validation loss: 2.039523720741272

Epoch: 6| Step: 6
Training loss: 1.6560029983520508
Validation loss: 2.042861541112264

Epoch: 6| Step: 7
Training loss: 2.5380563735961914
Validation loss: 2.0447025895118713

Epoch: 6| Step: 8
Training loss: 2.0757834911346436
Validation loss: 2.0384115179379783

Epoch: 6| Step: 9
Training loss: 1.9226164817810059
Validation loss: 2.0400153597195945

Epoch: 6| Step: 10
Training loss: 2.1014204025268555
Validation loss: 2.0399774312973022

Epoch: 6| Step: 11
Training loss: 2.2156436443328857
Validation loss: 2.0446647008260093

Epoch: 6| Step: 12
Training loss: 2.1590018272399902
Validation loss: 2.0438690384229026

Epoch: 6| Step: 13
Training loss: 2.2546498775482178
Validation loss: 2.038246472676595

Epoch: 76| Step: 0
Training loss: 1.4197640419006348
Validation loss: 2.039566079775492

Epoch: 6| Step: 1
Training loss: 2.174365520477295
Validation loss: 2.0324191649754844

Epoch: 6| Step: 2
Training loss: 2.3389675617218018
Validation loss: 2.0313585996627808

Epoch: 6| Step: 3
Training loss: 2.5882554054260254
Validation loss: 2.036061426003774

Epoch: 6| Step: 4
Training loss: 2.1652913093566895
Validation loss: 2.031579156716665

Epoch: 6| Step: 5
Training loss: 2.3245279788970947
Validation loss: 2.02715528011322

Epoch: 6| Step: 6
Training loss: 2.261115074157715
Validation loss: 2.020234763622284

Epoch: 6| Step: 7
Training loss: 1.919020414352417
Validation loss: 2.021060665448507

Epoch: 6| Step: 8
Training loss: 2.487159252166748
Validation loss: 2.0194960236549377

Epoch: 6| Step: 9
Training loss: 2.8479132652282715
Validation loss: 2.01994659503301

Epoch: 6| Step: 10
Training loss: 2.603212833404541
Validation loss: 2.0184735457102456

Epoch: 6| Step: 11
Training loss: 1.7197144031524658
Validation loss: 2.0225832064946494

Epoch: 6| Step: 12
Training loss: 1.7581093311309814
Validation loss: 2.0224198500315347

Epoch: 6| Step: 13
Training loss: 2.154099941253662
Validation loss: 2.02914031346639

Epoch: 77| Step: 0
Training loss: 2.150632381439209
Validation loss: 2.0289593935012817

Epoch: 6| Step: 1
Training loss: 2.4127392768859863
Validation loss: 2.018582820892334

Epoch: 6| Step: 2
Training loss: 2.113603353500366
Validation loss: 2.0310726960500083

Epoch: 6| Step: 3
Training loss: 1.773714542388916
Validation loss: 2.0352383255958557

Epoch: 6| Step: 4
Training loss: 1.9752416610717773
Validation loss: 2.0264998078346252

Epoch: 6| Step: 5
Training loss: 2.3752293586730957
Validation loss: 2.027073403199514

Epoch: 6| Step: 6
Training loss: 1.784773588180542
Validation loss: 2.0261576771736145

Epoch: 6| Step: 7
Training loss: 2.2578539848327637
Validation loss: 2.0238503019014993

Epoch: 6| Step: 8
Training loss: 1.9935111999511719
Validation loss: 2.016707499821981

Epoch: 6| Step: 9
Training loss: 2.2308735847473145
Validation loss: 2.0160439213116965

Epoch: 6| Step: 10
Training loss: 2.2731130123138428
Validation loss: 2.0205798943837485

Epoch: 6| Step: 11
Training loss: 2.4263246059417725
Validation loss: 2.0228809316953025

Epoch: 6| Step: 12
Training loss: 2.0513243675231934
Validation loss: 2.0252286394437156

Epoch: 6| Step: 13
Training loss: 2.730253219604492
Validation loss: 2.0254902839660645

Epoch: 78| Step: 0
Training loss: 2.3086252212524414
Validation loss: 2.0283648570378623

Epoch: 6| Step: 1
Training loss: 1.830155372619629
Validation loss: 2.026847720146179

Epoch: 6| Step: 2
Training loss: 2.2666828632354736
Validation loss: 2.0253308614095054

Epoch: 6| Step: 3
Training loss: 2.694019317626953
Validation loss: 2.0280343294143677

Epoch: 6| Step: 4
Training loss: 2.186832904815674
Validation loss: 2.0238212943077087

Epoch: 6| Step: 5
Training loss: 2.2652533054351807
Validation loss: 2.024980843067169

Epoch: 6| Step: 6
Training loss: 2.8580965995788574
Validation loss: 2.0229488015174866

Epoch: 6| Step: 7
Training loss: 1.978263020515442
Validation loss: 2.0280509988466897

Epoch: 6| Step: 8
Training loss: 2.014134168624878
Validation loss: 2.0225449999173484

Epoch: 6| Step: 9
Training loss: 1.9017348289489746
Validation loss: 2.0239993731180825

Epoch: 6| Step: 10
Training loss: 1.9652714729309082
Validation loss: 2.0247949759165444

Epoch: 6| Step: 11
Training loss: 1.8378822803497314
Validation loss: 2.0202269156773887

Epoch: 6| Step: 12
Training loss: 2.5958526134490967
Validation loss: 2.0132218996683755

Epoch: 6| Step: 13
Training loss: 2.1107232570648193
Validation loss: 2.0166863997777305

Epoch: 79| Step: 0
Training loss: 2.7624149322509766
Validation loss: 2.016896386941274

Epoch: 6| Step: 1
Training loss: 2.078784465789795
Validation loss: 2.016541679700216

Epoch: 6| Step: 2
Training loss: 1.6808191537857056
Validation loss: 2.0223453044891357

Epoch: 6| Step: 3
Training loss: 1.8786754608154297
Validation loss: 2.0375567277272544

Epoch: 6| Step: 4
Training loss: 1.9230468273162842
Validation loss: 2.033840835094452

Epoch: 6| Step: 5
Training loss: 1.7712814807891846
Validation loss: 2.046846350034078

Epoch: 6| Step: 6
Training loss: 2.554307460784912
Validation loss: 2.0490633447964988

Epoch: 6| Step: 7
Training loss: 1.61672842502594
Validation loss: 2.047292689482371

Epoch: 6| Step: 8
Training loss: 2.7237014770507812
Validation loss: 2.046051104863485

Epoch: 6| Step: 9
Training loss: 2.1358258724212646
Validation loss: 2.037216047445933

Epoch: 6| Step: 10
Training loss: 2.527472496032715
Validation loss: 2.024972061316172

Epoch: 6| Step: 11
Training loss: 2.1439085006713867
Validation loss: 2.024660110473633

Epoch: 6| Step: 12
Training loss: 2.353506565093994
Validation loss: 2.02259490887324

Epoch: 6| Step: 13
Training loss: 2.614995002746582
Validation loss: 2.0199349522590637

Epoch: 80| Step: 0
Training loss: 1.4071775674819946
Validation loss: 2.0206433733304343

Epoch: 6| Step: 1
Training loss: 1.766172170639038
Validation loss: 2.0214770833651223

Epoch: 6| Step: 2
Training loss: 2.1868300437927246
Validation loss: 2.0183430115381875

Epoch: 6| Step: 3
Training loss: 2.9962730407714844
Validation loss: 2.017420252164205

Epoch: 6| Step: 4
Training loss: 2.11460542678833
Validation loss: 2.0187485814094543

Epoch: 6| Step: 5
Training loss: 1.6435788869857788
Validation loss: 2.0201048851013184

Epoch: 6| Step: 6
Training loss: 1.750819206237793
Validation loss: 2.019477109114329

Epoch: 6| Step: 7
Training loss: 2.406339645385742
Validation loss: 2.0135937134424844

Epoch: 6| Step: 8
Training loss: 2.7827818393707275
Validation loss: 2.012093464533488

Epoch: 6| Step: 9
Training loss: 2.108672618865967
Validation loss: 2.0209166407585144

Epoch: 6| Step: 10
Training loss: 2.3861122131347656
Validation loss: 2.019834816455841

Epoch: 6| Step: 11
Training loss: 2.0659494400024414
Validation loss: 2.0150296688079834

Epoch: 6| Step: 12
Training loss: 2.8106393814086914
Validation loss: 2.0194985270500183

Epoch: 6| Step: 13
Training loss: 2.1789538860321045
Validation loss: 2.0249080061912537

Epoch: 81| Step: 0
Training loss: 1.2454746961593628
Validation loss: 2.0301560958226523

Epoch: 6| Step: 1
Training loss: 1.8090245723724365
Validation loss: 2.034954309463501

Epoch: 6| Step: 2
Training loss: 2.667232036590576
Validation loss: 2.042288343111674

Epoch: 6| Step: 3
Training loss: 1.973271369934082
Validation loss: 2.04254812002182

Epoch: 6| Step: 4
Training loss: 2.2544949054718018
Validation loss: 2.0392754077911377

Epoch: 6| Step: 5
Training loss: 2.4968783855438232
Validation loss: 2.034423033396403

Epoch: 6| Step: 6
Training loss: 2.4808359146118164
Validation loss: 2.0296323895454407

Epoch: 6| Step: 7
Training loss: 2.5571417808532715
Validation loss: 2.030817727247874

Epoch: 6| Step: 8
Training loss: 2.49113130569458
Validation loss: 2.0276203950246177

Epoch: 6| Step: 9
Training loss: 1.9893003702163696
Validation loss: 2.032339612642924

Epoch: 6| Step: 10
Training loss: 2.0490589141845703
Validation loss: 2.027712643146515

Epoch: 6| Step: 11
Training loss: 2.2647604942321777
Validation loss: 2.024012049039205

Epoch: 6| Step: 12
Training loss: 2.168795585632324
Validation loss: 2.0293137629826865

Epoch: 6| Step: 13
Training loss: 2.221271276473999
Validation loss: 2.026640752951304

Epoch: 82| Step: 0
Training loss: 1.9956953525543213
Validation loss: 2.0212935407956443

Epoch: 6| Step: 1
Training loss: 2.357905387878418
Validation loss: 2.0302512645721436

Epoch: 6| Step: 2
Training loss: 1.9330973625183105
Validation loss: 2.0282782713572183

Epoch: 6| Step: 3
Training loss: 2.4007463455200195
Validation loss: 2.0274141232172647

Epoch: 6| Step: 4
Training loss: 2.078141212463379
Validation loss: 2.025567591190338

Epoch: 6| Step: 5
Training loss: 2.498602867126465
Validation loss: 2.0266645352045694

Epoch: 6| Step: 6
Training loss: 2.493427038192749
Validation loss: 2.029773493607839

Epoch: 6| Step: 7
Training loss: 1.988785982131958
Validation loss: 2.0345085660616555

Epoch: 6| Step: 8
Training loss: 2.0240063667297363
Validation loss: 2.038494825363159

Epoch: 6| Step: 9
Training loss: 2.19648814201355
Validation loss: 2.0395132104555764

Epoch: 6| Step: 10
Training loss: 2.16579270362854
Validation loss: 2.0383198658625283

Epoch: 6| Step: 11
Training loss: 2.4568400382995605
Validation loss: 2.0462885896364846

Epoch: 6| Step: 12
Training loss: 2.22590708732605
Validation loss: 2.037492334842682

Epoch: 6| Step: 13
Training loss: 1.8477585315704346
Validation loss: 2.031638205051422

Epoch: 83| Step: 0
Training loss: 2.8833677768707275
Validation loss: 2.035629391670227

Epoch: 6| Step: 1
Training loss: 2.095914125442505
Validation loss: 2.0291035572687783

Epoch: 6| Step: 2
Training loss: 2.185364246368408
Validation loss: 2.022958993911743

Epoch: 6| Step: 3
Training loss: 1.97335946559906
Validation loss: 2.021391451358795

Epoch: 6| Step: 4
Training loss: 2.2142586708068848
Validation loss: 2.015860100587209

Epoch: 6| Step: 5
Training loss: 3.0176784992218018
Validation loss: 2.0225993394851685

Epoch: 6| Step: 6
Training loss: 2.1113078594207764
Validation loss: 2.018193562825521

Epoch: 6| Step: 7
Training loss: 1.5615489482879639
Validation loss: 2.0220330953598022

Epoch: 6| Step: 8
Training loss: 1.9098279476165771
Validation loss: 2.023015022277832

Epoch: 6| Step: 9
Training loss: 1.9642691612243652
Validation loss: 2.0197889606157937

Epoch: 6| Step: 10
Training loss: 1.92405104637146
Validation loss: 2.019839962323507

Epoch: 6| Step: 11
Training loss: 2.177023410797119
Validation loss: 2.023077070713043

Epoch: 6| Step: 12
Training loss: 2.6286275386810303
Validation loss: 2.0196754336357117

Epoch: 6| Step: 13
Training loss: 1.7818818092346191
Validation loss: 2.016755441824595

Epoch: 84| Step: 0
Training loss: 2.5026121139526367
Validation loss: 2.017862339814504

Epoch: 6| Step: 1
Training loss: 2.7913596630096436
Validation loss: 2.014147380987803

Epoch: 6| Step: 2
Training loss: 1.9320931434631348
Validation loss: 2.0305502812067666

Epoch: 6| Step: 3
Training loss: 2.427619457244873
Validation loss: 2.0377228458722434

Epoch: 6| Step: 4
Training loss: 2.4652204513549805
Validation loss: 2.043559491634369

Epoch: 6| Step: 5
Training loss: 2.646327018737793
Validation loss: 2.0418450435002646

Epoch: 6| Step: 6
Training loss: 1.7142646312713623
Validation loss: 2.0414960781733194

Epoch: 6| Step: 7
Training loss: 1.7799948453903198
Validation loss: 2.0435616970062256

Epoch: 6| Step: 8
Training loss: 2.0257070064544678
Validation loss: 2.046168645222982

Epoch: 6| Step: 9
Training loss: 2.2328035831451416
Validation loss: 2.0329285065333047

Epoch: 6| Step: 10
Training loss: 1.5773147344589233
Validation loss: 2.0343905091285706

Epoch: 6| Step: 11
Training loss: 2.194060802459717
Validation loss: 2.031965653101603

Epoch: 6| Step: 12
Training loss: 2.1447277069091797
Validation loss: 2.0287198623021445

Epoch: 6| Step: 13
Training loss: 2.0656609535217285
Validation loss: 2.0249717235565186

Epoch: 85| Step: 0
Training loss: 2.8337583541870117
Validation loss: 2.0072509249051413

Epoch: 6| Step: 1
Training loss: 2.182845115661621
Validation loss: 2.01842192808787

Epoch: 6| Step: 2
Training loss: 1.7871760129928589
Validation loss: 2.016020735104879

Epoch: 6| Step: 3
Training loss: 2.4458391666412354
Validation loss: 2.012778083483378

Epoch: 6| Step: 4
Training loss: 2.168736696243286
Validation loss: 2.0163450042406716

Epoch: 6| Step: 5
Training loss: 2.449347734451294
Validation loss: 2.0147754748662314

Epoch: 6| Step: 6
Training loss: 2.2867863178253174
Validation loss: 2.009182393550873

Epoch: 6| Step: 7
Training loss: 1.7353672981262207
Validation loss: 2.011108636856079

Epoch: 6| Step: 8
Training loss: 1.721874713897705
Validation loss: 2.015397826830546

Epoch: 6| Step: 9
Training loss: 1.9273805618286133
Validation loss: 2.0121551950772605

Epoch: 6| Step: 10
Training loss: 1.6052883863449097
Validation loss: 2.0129002730051675

Epoch: 6| Step: 11
Training loss: 2.5825796127319336
Validation loss: 2.017929951349894

Epoch: 6| Step: 12
Training loss: 2.6134376525878906
Validation loss: 2.0217546621958413

Epoch: 6| Step: 13
Training loss: 2.16667103767395
Validation loss: 2.021733025709788

Epoch: 86| Step: 0
Training loss: 2.713383913040161
Validation loss: 2.03030933936437

Epoch: 6| Step: 1
Training loss: 1.6680152416229248
Validation loss: 2.0408560037612915

Epoch: 6| Step: 2
Training loss: 2.3609189987182617
Validation loss: 2.037498692671458

Epoch: 6| Step: 3
Training loss: 0.9129241108894348
Validation loss: 2.029698431491852

Epoch: 6| Step: 4
Training loss: 2.3371834754943848
Validation loss: 2.027854402860006

Epoch: 6| Step: 5
Training loss: 1.9428308010101318
Validation loss: 2.0284361044565835

Epoch: 6| Step: 6
Training loss: 1.5698509216308594
Validation loss: 2.0187870264053345

Epoch: 6| Step: 7
Training loss: 1.9649949073791504
Validation loss: 2.023960053920746

Epoch: 6| Step: 8
Training loss: 3.003894090652466
Validation loss: 2.019501507282257

Epoch: 6| Step: 9
Training loss: 2.452922821044922
Validation loss: 2.0204105377197266

Epoch: 6| Step: 10
Training loss: 2.257655143737793
Validation loss: 2.014848450819651

Epoch: 6| Step: 11
Training loss: 2.906467914581299
Validation loss: 2.0157336592674255

Epoch: 6| Step: 12
Training loss: 1.9191503524780273
Validation loss: 2.020458161830902

Epoch: 6| Step: 13
Training loss: 2.3759560585021973
Validation loss: 2.0176786382993064

Epoch: 87| Step: 0
Training loss: 1.9218170642852783
Validation loss: 2.016611317793528

Epoch: 6| Step: 1
Training loss: 1.7136011123657227
Validation loss: 2.013118306795756

Epoch: 6| Step: 2
Training loss: 2.377453327178955
Validation loss: 2.0119707187016806

Epoch: 6| Step: 3
Training loss: 2.537827491760254
Validation loss: 2.008159339427948

Epoch: 6| Step: 4
Training loss: 2.333263635635376
Validation loss: 2.014514406522115

Epoch: 6| Step: 5
Training loss: 2.520387649536133
Validation loss: 2.0098133285840354

Epoch: 6| Step: 6
Training loss: 2.2897989749908447
Validation loss: 2.014999290307363

Epoch: 6| Step: 7
Training loss: 2.1010162830352783
Validation loss: 2.0115052262941995

Epoch: 6| Step: 8
Training loss: 1.9108073711395264
Validation loss: 2.0111839175224304

Epoch: 6| Step: 9
Training loss: 1.9944214820861816
Validation loss: 2.0129940509796143

Epoch: 6| Step: 10
Training loss: 2.116633415222168
Validation loss: 2.0122605760892234

Epoch: 6| Step: 11
Training loss: 2.3771541118621826
Validation loss: 2.0217387080192566

Epoch: 6| Step: 12
Training loss: 2.170694351196289
Validation loss: 2.0237032969792685

Epoch: 6| Step: 13
Training loss: 1.8641105890274048
Validation loss: 2.024973372618357

Epoch: 88| Step: 0
Training loss: 1.3362319469451904
Validation loss: 2.0293036699295044

Epoch: 6| Step: 1
Training loss: 2.1292526721954346
Validation loss: 2.0358996788660684

Epoch: 6| Step: 2
Training loss: 3.197783946990967
Validation loss: 2.0288384358088174

Epoch: 6| Step: 3
Training loss: 1.867266058921814
Validation loss: 2.0400840838750205

Epoch: 6| Step: 4
Training loss: 2.0272512435913086
Validation loss: 2.0355973839759827

Epoch: 6| Step: 5
Training loss: 2.249667167663574
Validation loss: 2.0258466005325317

Epoch: 6| Step: 6
Training loss: 2.495965003967285
Validation loss: 2.0418068170547485

Epoch: 6| Step: 7
Training loss: 1.689499855041504
Validation loss: 2.035455902417501

Epoch: 6| Step: 8
Training loss: 2.5011327266693115
Validation loss: 2.031791885693868

Epoch: 6| Step: 9
Training loss: 2.5901408195495605
Validation loss: 2.0216779311498008

Epoch: 6| Step: 10
Training loss: 1.927931785583496
Validation loss: 2.028207540512085

Epoch: 6| Step: 11
Training loss: 1.5545787811279297
Validation loss: 2.0250091552734375

Epoch: 6| Step: 12
Training loss: 2.294541835784912
Validation loss: 2.023627201716105

Epoch: 6| Step: 13
Training loss: 2.297423839569092
Validation loss: 2.019484599431356

Epoch: 89| Step: 0
Training loss: 2.387847900390625
Validation loss: 2.0175894300142923

Epoch: 6| Step: 1
Training loss: 2.5284218788146973
Validation loss: 2.012039601802826

Epoch: 6| Step: 2
Training loss: 1.8530616760253906
Validation loss: 2.0142366687456765

Epoch: 6| Step: 3
Training loss: 1.7083561420440674
Validation loss: 2.017746071020762

Epoch: 6| Step: 4
Training loss: 2.617685317993164
Validation loss: 2.016611178716024

Epoch: 6| Step: 5
Training loss: 2.1063294410705566
Validation loss: 2.0129683216412864

Epoch: 6| Step: 6
Training loss: 2.8564043045043945
Validation loss: 2.0140744050343833

Epoch: 6| Step: 7
Training loss: 2.6415188312530518
Validation loss: 2.0177029768625894

Epoch: 6| Step: 8
Training loss: 2.31118106842041
Validation loss: 2.0113062461217246

Epoch: 6| Step: 9
Training loss: 1.7032301425933838
Validation loss: 2.011815090974172

Epoch: 6| Step: 10
Training loss: 1.4757397174835205
Validation loss: 2.018342614173889

Epoch: 6| Step: 11
Training loss: 2.127948760986328
Validation loss: 2.015664199988047

Epoch: 6| Step: 12
Training loss: 2.1531500816345215
Validation loss: 2.020864725112915

Epoch: 6| Step: 13
Training loss: 1.7272006273269653
Validation loss: 2.0245272715886435

Epoch: 90| Step: 0
Training loss: 1.8892245292663574
Validation loss: 2.0302937626838684

Epoch: 6| Step: 1
Training loss: 2.0639946460723877
Validation loss: 2.026922265688578

Epoch: 6| Step: 2
Training loss: 2.171802520751953
Validation loss: 2.0366342862447104

Epoch: 6| Step: 3
Training loss: 1.556093692779541
Validation loss: 2.0435614784558616

Epoch: 6| Step: 4
Training loss: 2.072498083114624
Validation loss: 2.037515958150228

Epoch: 6| Step: 5
Training loss: 2.772897243499756
Validation loss: 2.030017832914988

Epoch: 6| Step: 6
Training loss: 2.30202317237854
Validation loss: 2.0263784329096475

Epoch: 6| Step: 7
Training loss: 2.711088180541992
Validation loss: 2.038925270239512

Epoch: 6| Step: 8
Training loss: 3.007328987121582
Validation loss: 2.0209144155184426

Epoch: 6| Step: 9
Training loss: 2.2933688163757324
Validation loss: 2.021038293838501

Epoch: 6| Step: 10
Training loss: 2.032400131225586
Validation loss: 2.01635613044103

Epoch: 6| Step: 11
Training loss: 1.6504759788513184
Validation loss: 2.01226677497228

Epoch: 6| Step: 12
Training loss: 2.02140474319458
Validation loss: 2.0135337511698403

Epoch: 6| Step: 13
Training loss: 1.629560947418213
Validation loss: 2.023494303226471

Epoch: 91| Step: 0
Training loss: 2.025534152984619
Validation loss: 2.025783876578013

Epoch: 6| Step: 1
Training loss: 2.02073335647583
Validation loss: 2.025078515211741

Epoch: 6| Step: 2
Training loss: 2.36470103263855
Validation loss: 2.0233472188313804

Epoch: 6| Step: 3
Training loss: 2.112551212310791
Validation loss: 2.0239944060643515

Epoch: 6| Step: 4
Training loss: 2.570964813232422
Validation loss: 2.0225351254145303

Epoch: 6| Step: 5
Training loss: 2.676124334335327
Validation loss: 2.022454579671224

Epoch: 6| Step: 6
Training loss: 2.3286292552948
Validation loss: 2.021187424659729

Epoch: 6| Step: 7
Training loss: 1.854385256767273
Validation loss: 2.0152493516604104

Epoch: 6| Step: 8
Training loss: 2.4322683811187744
Validation loss: 2.017871618270874

Epoch: 6| Step: 9
Training loss: 1.7700203657150269
Validation loss: 2.0135127902030945

Epoch: 6| Step: 10
Training loss: 1.4827009439468384
Validation loss: 2.0029332041740417

Epoch: 6| Step: 11
Training loss: 2.5776381492614746
Validation loss: 2.010732352733612

Epoch: 6| Step: 12
Training loss: 2.336338996887207
Validation loss: 2.0130494236946106

Epoch: 6| Step: 13
Training loss: 1.9578273296356201
Validation loss: 2.0055532256762185

Epoch: 92| Step: 0
Training loss: 1.6175363063812256
Validation loss: 2.008112688859304

Epoch: 6| Step: 1
Training loss: 2.231321334838867
Validation loss: 2.006347934405009

Epoch: 6| Step: 2
Training loss: 1.8051174879074097
Validation loss: 2.021202007929484

Epoch: 6| Step: 3
Training loss: 2.983135938644409
Validation loss: 2.0332393844922385

Epoch: 6| Step: 4
Training loss: 2.6616368293762207
Validation loss: 2.0335625410079956

Epoch: 6| Step: 5
Training loss: 2.518402576446533
Validation loss: 2.038719872633616

Epoch: 6| Step: 6
Training loss: 1.4646921157836914
Validation loss: 2.035615086555481

Epoch: 6| Step: 7
Training loss: 2.246609687805176
Validation loss: 2.0309377312660217

Epoch: 6| Step: 8
Training loss: 2.2254674434661865
Validation loss: 2.0347753167152405

Epoch: 6| Step: 9
Training loss: 2.275155544281006
Validation loss: 2.0204941431681314

Epoch: 6| Step: 10
Training loss: 2.1348679065704346
Validation loss: 2.0260565479596457

Epoch: 6| Step: 11
Training loss: 2.2762410640716553
Validation loss: 2.0183602571487427

Epoch: 6| Step: 12
Training loss: 1.989173173904419
Validation loss: 2.013944705327352

Epoch: 6| Step: 13
Training loss: 1.8455920219421387
Validation loss: 2.012193024158478

Epoch: 93| Step: 0
Training loss: 2.386305332183838
Validation loss: 2.00843338171641

Epoch: 6| Step: 1
Training loss: 2.2958881855010986
Validation loss: 2.019682824611664

Epoch: 6| Step: 2
Training loss: 1.236907958984375
Validation loss: 2.019757628440857

Epoch: 6| Step: 3
Training loss: 2.3698456287384033
Validation loss: 2.0181663433710733

Epoch: 6| Step: 4
Training loss: 2.245210647583008
Validation loss: 2.0220826268196106

Epoch: 6| Step: 5
Training loss: 2.177126407623291
Validation loss: 2.015681187311808

Epoch: 6| Step: 6
Training loss: 2.250464677810669
Validation loss: 2.022825002670288

Epoch: 6| Step: 7
Training loss: 1.7770326137542725
Validation loss: 2.0167256792386374

Epoch: 6| Step: 8
Training loss: 1.8958308696746826
Validation loss: 2.0152516762415567

Epoch: 6| Step: 9
Training loss: 2.5577878952026367
Validation loss: 2.016412874062856

Epoch: 6| Step: 10
Training loss: 1.9936378002166748
Validation loss: 2.010829269886017

Epoch: 6| Step: 11
Training loss: 2.5691449642181396
Validation loss: 2.021201968193054

Epoch: 6| Step: 12
Training loss: 1.6706463098526
Validation loss: 2.026680827140808

Epoch: 6| Step: 13
Training loss: 2.638908624649048
Validation loss: 2.04025266567866

Epoch: 94| Step: 0
Training loss: 2.73118257522583
Validation loss: 2.04084312915802

Epoch: 6| Step: 1
Training loss: 1.688246488571167
Validation loss: 2.047927141189575

Epoch: 6| Step: 2
Training loss: 2.464010715484619
Validation loss: 2.056240459283193

Epoch: 6| Step: 3
Training loss: 2.0940890312194824
Validation loss: 2.065540631612142

Epoch: 6| Step: 4
Training loss: 2.458275079727173
Validation loss: 2.0687144796053567

Epoch: 6| Step: 5
Training loss: 2.022294282913208
Validation loss: 2.067860027154287

Epoch: 6| Step: 6
Training loss: 2.178380012512207
Validation loss: 2.0585139989852905

Epoch: 6| Step: 7
Training loss: 2.453019618988037
Validation loss: 2.051246623198191

Epoch: 6| Step: 8
Training loss: 1.3637301921844482
Validation loss: 2.05079847574234

Epoch: 6| Step: 9
Training loss: 2.278651237487793
Validation loss: 2.0452115337053933

Epoch: 6| Step: 10
Training loss: 2.2442517280578613
Validation loss: 2.0337289770444236

Epoch: 6| Step: 11
Training loss: 2.492565155029297
Validation loss: 2.0348172982533774

Epoch: 6| Step: 12
Training loss: 2.298771619796753
Validation loss: 2.0227221051851907

Epoch: 6| Step: 13
Training loss: 1.6675161123275757
Validation loss: 2.0195860664049783

Epoch: 95| Step: 0
Training loss: 1.9121184349060059
Validation loss: 2.0225393176078796

Epoch: 6| Step: 1
Training loss: 2.0214309692382812
Validation loss: 2.0221643845240274

Epoch: 6| Step: 2
Training loss: 2.20648193359375
Validation loss: 2.025862912336985

Epoch: 6| Step: 3
Training loss: 2.182136297225952
Validation loss: 2.026519497235616

Epoch: 6| Step: 4
Training loss: 2.3539390563964844
Validation loss: 2.026367207368215

Epoch: 6| Step: 5
Training loss: 2.0958030223846436
Validation loss: 2.026656150817871

Epoch: 6| Step: 6
Training loss: 1.881340742111206
Validation loss: 2.023448348045349

Epoch: 6| Step: 7
Training loss: 2.302936315536499
Validation loss: 2.0211600263913474

Epoch: 6| Step: 8
Training loss: 2.680915355682373
Validation loss: 2.0106961727142334

Epoch: 6| Step: 9
Training loss: 1.7691587209701538
Validation loss: 2.0201549728711448

Epoch: 6| Step: 10
Training loss: 1.816659927368164
Validation loss: 2.0133784413337708

Epoch: 6| Step: 11
Training loss: 2.507984161376953
Validation loss: 2.0151222348213196

Epoch: 6| Step: 12
Training loss: 2.3519198894500732
Validation loss: 2.0161868135134378

Epoch: 6| Step: 13
Training loss: 2.2722575664520264
Validation loss: 2.0107353727022805

Epoch: 96| Step: 0
Training loss: 1.950272798538208
Validation loss: 2.018402934074402

Epoch: 6| Step: 1
Training loss: 2.3229141235351562
Validation loss: 2.017610510190328

Epoch: 6| Step: 2
Training loss: 1.8119016885757446
Validation loss: 2.025841534137726

Epoch: 6| Step: 3
Training loss: 2.3991427421569824
Validation loss: 2.0261943538983664

Epoch: 6| Step: 4
Training loss: 2.330380439758301
Validation loss: 2.027493397394816

Epoch: 6| Step: 5
Training loss: 1.810741901397705
Validation loss: 2.0273744463920593

Epoch: 6| Step: 6
Training loss: 2.1567535400390625
Validation loss: 2.02638832728068

Epoch: 6| Step: 7
Training loss: 2.451512098312378
Validation loss: 2.0259609619776406

Epoch: 6| Step: 8
Training loss: 1.641161561012268
Validation loss: 2.0281289418538413

Epoch: 6| Step: 9
Training loss: 1.5417664051055908
Validation loss: 2.0180442531903586

Epoch: 6| Step: 10
Training loss: 2.0232009887695312
Validation loss: 2.020321508248647

Epoch: 6| Step: 11
Training loss: 2.8535783290863037
Validation loss: 2.020581384499868

Epoch: 6| Step: 12
Training loss: 2.3691458702087402
Validation loss: 2.0294450720151267

Epoch: 6| Step: 13
Training loss: 2.368230104446411
Validation loss: 2.01899653673172

Epoch: 97| Step: 0
Training loss: 2.2329163551330566
Validation loss: 2.018184721469879

Epoch: 6| Step: 1
Training loss: 2.198279619216919
Validation loss: 2.024807115395864

Epoch: 6| Step: 2
Training loss: 1.5703561305999756
Validation loss: 2.0322018464406333

Epoch: 6| Step: 3
Training loss: 2.4027769565582275
Validation loss: 2.0213035146395364

Epoch: 6| Step: 4
Training loss: 2.174436330795288
Validation loss: 2.0155176719029746

Epoch: 6| Step: 5
Training loss: 2.2774879932403564
Validation loss: 2.0198105374972024

Epoch: 6| Step: 6
Training loss: 2.2821502685546875
Validation loss: 2.0187076926231384

Epoch: 6| Step: 7
Training loss: 2.1784098148345947
Validation loss: 2.0262133876482644

Epoch: 6| Step: 8
Training loss: 1.7548648118972778
Validation loss: 2.027690569559733

Epoch: 6| Step: 9
Training loss: 2.646085500717163
Validation loss: 2.030253609021505

Epoch: 6| Step: 10
Training loss: 1.532719373703003
Validation loss: 2.0244500239690146

Epoch: 6| Step: 11
Training loss: 2.1550838947296143
Validation loss: 2.0342716177304587

Epoch: 6| Step: 12
Training loss: 2.8319921493530273
Validation loss: 2.0334139863650003

Epoch: 6| Step: 13
Training loss: 1.603714942932129
Validation loss: 2.038892408212026

Epoch: 98| Step: 0
Training loss: 1.8968138694763184
Validation loss: 2.0253491004308066

Epoch: 6| Step: 1
Training loss: 2.0658106803894043
Validation loss: 2.030943135420481

Epoch: 6| Step: 2
Training loss: 1.7210496664047241
Validation loss: 2.0342344840367637

Epoch: 6| Step: 3
Training loss: 2.100411891937256
Validation loss: 2.0263819893201194

Epoch: 6| Step: 4
Training loss: 2.126889228820801
Validation loss: 2.0218368967374167

Epoch: 6| Step: 5
Training loss: 2.627040386199951
Validation loss: 2.021821081638336

Epoch: 6| Step: 6
Training loss: 1.6929943561553955
Validation loss: 2.0129862427711487

Epoch: 6| Step: 7
Training loss: 2.177077293395996
Validation loss: 2.0199376145998635

Epoch: 6| Step: 8
Training loss: 2.624873161315918
Validation loss: 2.0182146231333413

Epoch: 6| Step: 9
Training loss: 1.892621636390686
Validation loss: 2.01768829425176

Epoch: 6| Step: 10
Training loss: 2.050736427307129
Validation loss: 2.0225091576576233

Epoch: 6| Step: 11
Training loss: 2.320172071456909
Validation loss: 2.0267593264579773

Epoch: 6| Step: 12
Training loss: 2.601651191711426
Validation loss: 2.0208562215169272

Epoch: 6| Step: 13
Training loss: 2.0220508575439453
Validation loss: 2.0209160844484964

Epoch: 99| Step: 0
Training loss: 2.491809368133545
Validation loss: 2.028870940208435

Epoch: 6| Step: 1
Training loss: 2.1513760089874268
Validation loss: 2.0265989303588867

Epoch: 6| Step: 2
Training loss: 2.7088699340820312
Validation loss: 2.037998298803965

Epoch: 6| Step: 3
Training loss: 1.627211332321167
Validation loss: 2.039123555024465

Epoch: 6| Step: 4
Training loss: 1.6289141178131104
Validation loss: 2.038675526777903

Epoch: 6| Step: 5
Training loss: 2.331047296524048
Validation loss: 2.036634882291158

Epoch: 6| Step: 6
Training loss: 2.3803062438964844
Validation loss: 2.0415233373641968

Epoch: 6| Step: 7
Training loss: 2.4966306686401367
Validation loss: 2.0356093645095825

Epoch: 6| Step: 8
Training loss: 1.4165005683898926
Validation loss: 2.0325220823287964

Epoch: 6| Step: 9
Training loss: 2.540530204772949
Validation loss: 2.0374528765678406

Epoch: 6| Step: 10
Training loss: 2.190523147583008
Validation loss: 2.027318278948466

Epoch: 6| Step: 11
Training loss: 2.286231756210327
Validation loss: 2.0388243397076926

Epoch: 6| Step: 12
Training loss: 1.6836847066879272
Validation loss: 2.0258460442225137

Epoch: 6| Step: 13
Training loss: 1.932178258895874
Validation loss: 2.024050752321879

Epoch: 100| Step: 0
Training loss: 2.3395042419433594
Validation loss: 2.023690323034922

Epoch: 6| Step: 1
Training loss: 1.7455061674118042
Validation loss: 2.0305561224619546

Epoch: 6| Step: 2
Training loss: 2.2841832637786865
Validation loss: 2.0291966994603476

Epoch: 6| Step: 3
Training loss: 2.3040413856506348
Validation loss: 2.0258408188819885

Epoch: 6| Step: 4
Training loss: 1.5666985511779785
Validation loss: 2.022570530573527

Epoch: 6| Step: 5
Training loss: 2.6784942150115967
Validation loss: 2.0248448650042215

Epoch: 6| Step: 6
Training loss: 2.450937032699585
Validation loss: 2.027398943901062

Epoch: 6| Step: 7
Training loss: 1.8601293563842773
Validation loss: 2.017140964667002

Epoch: 6| Step: 8
Training loss: 1.913008689880371
Validation loss: 2.0280656615893045

Epoch: 6| Step: 9
Training loss: 1.4781081676483154
Validation loss: 2.026461640993754

Epoch: 6| Step: 10
Training loss: 2.011545181274414
Validation loss: 2.0269192457199097

Epoch: 6| Step: 11
Training loss: 2.1211400032043457
Validation loss: 2.023634990056356

Epoch: 6| Step: 12
Training loss: 1.9941487312316895
Validation loss: 2.0218814611434937

Epoch: 6| Step: 13
Training loss: 3.0752532482147217
Validation loss: 2.010784606138865

Epoch: 101| Step: 0
Training loss: 2.348288059234619
Validation loss: 2.025252878665924

Epoch: 6| Step: 1
Training loss: 2.229351043701172
Validation loss: 2.0201910535494485

Epoch: 6| Step: 2
Training loss: 1.6529946327209473
Validation loss: 2.0188673734664917

Epoch: 6| Step: 3
Training loss: 2.236020565032959
Validation loss: 2.0193890929222107

Epoch: 6| Step: 4
Training loss: 2.8793509006500244
Validation loss: 2.025445818901062

Epoch: 6| Step: 5
Training loss: 2.2274093627929688
Validation loss: 2.030266026655833

Epoch: 6| Step: 6
Training loss: 1.6793862581253052
Validation loss: 2.0303208033243814

Epoch: 6| Step: 7
Training loss: 2.0694665908813477
Validation loss: 2.024514655272166

Epoch: 6| Step: 8
Training loss: 2.833571434020996
Validation loss: 2.027111530303955

Epoch: 6| Step: 9
Training loss: 1.8226724863052368
Validation loss: 2.033293684323629

Epoch: 6| Step: 10
Training loss: 2.5117177963256836
Validation loss: 2.017319977283478

Epoch: 6| Step: 11
Training loss: 1.3447703123092651
Validation loss: 2.031316558519999

Epoch: 6| Step: 12
Training loss: 1.933630108833313
Validation loss: 2.030115862687429

Epoch: 6| Step: 13
Training loss: 1.9695740938186646
Validation loss: 2.0395568013191223

Epoch: 102| Step: 0
Training loss: 1.6794734001159668
Validation loss: 2.0412447452545166

Epoch: 6| Step: 1
Training loss: 1.7539637088775635
Validation loss: 2.030639191468557

Epoch: 6| Step: 2
Training loss: 2.347712278366089
Validation loss: 2.0380954345067344

Epoch: 6| Step: 3
Training loss: 2.161834239959717
Validation loss: 2.0461218555768332

Epoch: 6| Step: 4
Training loss: 2.298318386077881
Validation loss: 2.0266372760136924

Epoch: 6| Step: 5
Training loss: 1.56464421749115
Validation loss: 2.0401652455329895

Epoch: 6| Step: 6
Training loss: 2.0669384002685547
Validation loss: 2.0332192182540894

Epoch: 6| Step: 7
Training loss: 2.373147964477539
Validation loss: 2.0325655341148376

Epoch: 6| Step: 8
Training loss: 2.6842596530914307
Validation loss: 2.0415560603141785

Epoch: 6| Step: 9
Training loss: 2.1740055084228516
Validation loss: 2.030200401941935

Epoch: 6| Step: 10
Training loss: 2.080733299255371
Validation loss: 2.0344543059666953

Epoch: 6| Step: 11
Training loss: 2.534850597381592
Validation loss: 2.0338957707087197

Epoch: 6| Step: 12
Training loss: 1.9981565475463867
Validation loss: 2.038600961367289

Epoch: 6| Step: 13
Training loss: 2.1003334522247314
Validation loss: 2.0470313231150308

Epoch: 103| Step: 0
Training loss: 1.8918286561965942
Validation loss: 2.0471454858779907

Epoch: 6| Step: 1
Training loss: 1.939179539680481
Validation loss: 2.037684957186381

Epoch: 6| Step: 2
Training loss: 1.8952877521514893
Validation loss: 2.0382285515467324

Epoch: 6| Step: 3
Training loss: 1.6145260334014893
Validation loss: 2.0381818612416587

Epoch: 6| Step: 4
Training loss: 2.580000877380371
Validation loss: 2.037016193072001

Epoch: 6| Step: 5
Training loss: 2.412020206451416
Validation loss: 2.0428986152013144

Epoch: 6| Step: 6
Training loss: 2.2541022300720215
Validation loss: 2.0323150952657065

Epoch: 6| Step: 7
Training loss: 1.9390114545822144
Validation loss: 2.031540314356486

Epoch: 6| Step: 8
Training loss: 2.3382222652435303
Validation loss: 2.050080398718516

Epoch: 6| Step: 9
Training loss: 2.315189838409424
Validation loss: 2.0345916152000427

Epoch: 6| Step: 10
Training loss: 1.9179234504699707
Validation loss: 2.0321661233901978

Epoch: 6| Step: 11
Training loss: 2.449831247329712
Validation loss: 2.0252991716066995

Epoch: 6| Step: 12
Training loss: 2.2861533164978027
Validation loss: 2.0303186178207397

Epoch: 6| Step: 13
Training loss: 1.9499913454055786
Validation loss: 2.0291372338930764

Epoch: 104| Step: 0
Training loss: 2.01869797706604
Validation loss: 2.0333968003590903

Epoch: 6| Step: 1
Training loss: 2.1612157821655273
Validation loss: 2.0375689466794333

Epoch: 6| Step: 2
Training loss: 2.3342854976654053
Validation loss: 2.0326499938964844

Epoch: 6| Step: 3
Training loss: 1.880405068397522
Validation loss: 2.034289300441742

Epoch: 6| Step: 4
Training loss: 1.9581513404846191
Validation loss: 2.036217153072357

Epoch: 6| Step: 5
Training loss: 2.1448447704315186
Validation loss: 2.0359763900438943

Epoch: 6| Step: 6
Training loss: 2.5951895713806152
Validation loss: 2.0407219727834067

Epoch: 6| Step: 7
Training loss: 2.9263763427734375
Validation loss: 2.0353542963663735

Epoch: 6| Step: 8
Training loss: 1.9935306310653687
Validation loss: 2.033048391342163

Epoch: 6| Step: 9
Training loss: 2.2336912155151367
Validation loss: 2.034322142601013

Epoch: 6| Step: 10
Training loss: 2.4721791744232178
Validation loss: 2.022544880708059

Epoch: 6| Step: 11
Training loss: 1.7850682735443115
Validation loss: 2.0269768635431924

Epoch: 6| Step: 12
Training loss: 1.3261902332305908
Validation loss: 2.0243006348609924

Epoch: 6| Step: 13
Training loss: 2.146087169647217
Validation loss: 2.0157190362612405

Epoch: 105| Step: 0
Training loss: 2.636586904525757
Validation loss: 2.0117960373560586

Epoch: 6| Step: 1
Training loss: 2.7186970710754395
Validation loss: 2.0123306711514792

Epoch: 6| Step: 2
Training loss: 1.78871750831604
Validation loss: 2.018261671066284

Epoch: 6| Step: 3
Training loss: 2.23110032081604
Validation loss: 2.0226360162099204

Epoch: 6| Step: 4
Training loss: 2.196349620819092
Validation loss: 2.0170697768529258

Epoch: 6| Step: 5
Training loss: 2.048611640930176
Validation loss: 2.015317956606547

Epoch: 6| Step: 6
Training loss: 2.2525272369384766
Validation loss: 2.0232982635498047

Epoch: 6| Step: 7
Training loss: 1.84182608127594
Validation loss: 2.023996194203695

Epoch: 6| Step: 8
Training loss: 2.21551513671875
Validation loss: 2.020416518052419

Epoch: 6| Step: 9
Training loss: 1.7089768648147583
Validation loss: 2.0295862555503845

Epoch: 6| Step: 10
Training loss: 2.1752748489379883
Validation loss: 2.0186471144358316

Epoch: 6| Step: 11
Training loss: 2.1841187477111816
Validation loss: 2.0205570459365845

Epoch: 6| Step: 12
Training loss: 2.061302661895752
Validation loss: 2.0149358908335366

Epoch: 6| Step: 13
Training loss: 1.8581284284591675
Validation loss: 2.010385791460673

Epoch: 106| Step: 0
Training loss: 2.4327776432037354
Validation loss: 2.01446266969045

Epoch: 6| Step: 1
Training loss: 1.6474796533584595
Validation loss: 2.011574705441793

Epoch: 6| Step: 2
Training loss: 2.507540702819824
Validation loss: 2.0116183757781982

Epoch: 6| Step: 3
Training loss: 2.851193904876709
Validation loss: 2.0148698488871255

Epoch: 6| Step: 4
Training loss: 2.2983412742614746
Validation loss: 2.0161316196123757

Epoch: 6| Step: 5
Training loss: 1.876389741897583
Validation loss: 2.021498441696167

Epoch: 6| Step: 6
Training loss: 2.4405081272125244
Validation loss: 2.030633350213369

Epoch: 6| Step: 7
Training loss: 2.3898701667785645
Validation loss: 2.0267629822095237

Epoch: 6| Step: 8
Training loss: 2.0171661376953125
Validation loss: 2.0338003238042197

Epoch: 6| Step: 9
Training loss: 1.7396149635314941
Validation loss: 2.033879280090332

Epoch: 6| Step: 10
Training loss: 1.81936514377594
Validation loss: 2.0367548863093057

Epoch: 6| Step: 11
Training loss: 1.7525722980499268
Validation loss: 2.036628544330597

Epoch: 6| Step: 12
Training loss: 1.8116213083267212
Validation loss: 2.042604704697927

Epoch: 6| Step: 13
Training loss: 2.287243366241455
Validation loss: 2.043414612611135

Epoch: 107| Step: 0
Training loss: 2.161567211151123
Validation loss: 2.0424179633458457

Epoch: 6| Step: 1
Training loss: 1.3782262802124023
Validation loss: 2.0357849995295205

Epoch: 6| Step: 2
Training loss: 2.1329545974731445
Validation loss: 2.0357386072476706

Epoch: 6| Step: 3
Training loss: 1.9087812900543213
Validation loss: 2.0314906438191733

Epoch: 6| Step: 4
Training loss: 2.202500820159912
Validation loss: 2.0337982972462973

Epoch: 6| Step: 5
Training loss: 2.1451120376586914
Validation loss: 2.027260661125183

Epoch: 6| Step: 6
Training loss: 2.2617945671081543
Validation loss: 2.024760901927948

Epoch: 6| Step: 7
Training loss: 2.226226806640625
Validation loss: 2.020988881587982

Epoch: 6| Step: 8
Training loss: 2.593322515487671
Validation loss: 2.0234001676241555

Epoch: 6| Step: 9
Training loss: 2.208563804626465
Validation loss: 2.0299245715141296

Epoch: 6| Step: 10
Training loss: 2.1036012172698975
Validation loss: 2.031015157699585

Epoch: 6| Step: 11
Training loss: 2.2932372093200684
Validation loss: 2.0423580408096313

Epoch: 6| Step: 12
Training loss: 1.806230902671814
Validation loss: 2.041148583094279

Epoch: 6| Step: 13
Training loss: 2.3309433460235596
Validation loss: 2.0338805516560874

Epoch: 108| Step: 0
Training loss: 1.6775816679000854
Validation loss: 2.0371129711469016

Epoch: 6| Step: 1
Training loss: 2.1094141006469727
Validation loss: 2.0416735410690308

Epoch: 6| Step: 2
Training loss: 1.464091420173645
Validation loss: 2.039888580640157

Epoch: 6| Step: 3
Training loss: 2.1355319023132324
Validation loss: 2.039723495642344

Epoch: 6| Step: 4
Training loss: 2.6616358757019043
Validation loss: 2.0224616527557373

Epoch: 6| Step: 5
Training loss: 2.24008846282959
Validation loss: 2.023712933063507

Epoch: 6| Step: 6
Training loss: 2.3574483394622803
Validation loss: 2.0231625040372214

Epoch: 6| Step: 7
Training loss: 2.4188623428344727
Validation loss: 2.0242313742637634

Epoch: 6| Step: 8
Training loss: 2.1126482486724854
Validation loss: 2.0285503268241882

Epoch: 6| Step: 9
Training loss: 1.907120704650879
Validation loss: 2.034790833791097

Epoch: 6| Step: 10
Training loss: 2.401601552963257
Validation loss: 2.0200611352920532

Epoch: 6| Step: 11
Training loss: 2.076688766479492
Validation loss: 2.0231141448020935

Epoch: 6| Step: 12
Training loss: 2.008833885192871
Validation loss: 2.023617168267568

Epoch: 6| Step: 13
Training loss: 2.06229829788208
Validation loss: 2.022877017656962

Epoch: 109| Step: 0
Training loss: 2.5592098236083984
Validation loss: 2.0345491965611777

Epoch: 6| Step: 1
Training loss: 1.9293618202209473
Validation loss: 2.0317660371462503

Epoch: 6| Step: 2
Training loss: 2.8050477504730225
Validation loss: 2.031276524066925

Epoch: 6| Step: 3
Training loss: 1.6968735456466675
Validation loss: 2.0239509542783103

Epoch: 6| Step: 4
Training loss: 2.598651885986328
Validation loss: 2.0301527182261148

Epoch: 6| Step: 5
Training loss: 2.08298921585083
Validation loss: 2.025282899538676

Epoch: 6| Step: 6
Training loss: 2.0111947059631348
Validation loss: 2.024410923322042

Epoch: 6| Step: 7
Training loss: 2.0434179306030273
Validation loss: 2.025259852409363

Epoch: 6| Step: 8
Training loss: 1.5669108629226685
Validation loss: 2.0220575531323752

Epoch: 6| Step: 9
Training loss: 2.113152027130127
Validation loss: 2.0185656348864236

Epoch: 6| Step: 10
Training loss: 1.9473707675933838
Validation loss: 2.016423503557841

Epoch: 6| Step: 11
Training loss: 2.010087490081787
Validation loss: 2.0182655453681946

Epoch: 6| Step: 12
Training loss: 2.2635409832000732
Validation loss: 2.0268638332684836

Epoch: 6| Step: 13
Training loss: 1.9994803667068481
Validation loss: 2.013439158598582

Epoch: 110| Step: 0
Training loss: 1.9651596546173096
Validation loss: 2.018011450767517

Epoch: 6| Step: 1
Training loss: 2.173978328704834
Validation loss: 2.016279319922129

Epoch: 6| Step: 2
Training loss: 2.2942824363708496
Validation loss: 2.022591253121694

Epoch: 6| Step: 3
Training loss: 2.563441753387451
Validation loss: 2.016350487867991

Epoch: 6| Step: 4
Training loss: 2.2903780937194824
Validation loss: 2.0103307962417603

Epoch: 6| Step: 5
Training loss: 1.655306339263916
Validation loss: 2.0129754145940146

Epoch: 6| Step: 6
Training loss: 2.1118955612182617
Validation loss: 2.015299439430237

Epoch: 6| Step: 7
Training loss: 2.1205902099609375
Validation loss: 2.0094953775405884

Epoch: 6| Step: 8
Training loss: 1.6521226167678833
Validation loss: 2.0113943815231323

Epoch: 6| Step: 9
Training loss: 2.7243971824645996
Validation loss: 2.0092697143554688

Epoch: 6| Step: 10
Training loss: 2.348078727722168
Validation loss: 2.008143981297811

Epoch: 6| Step: 11
Training loss: 2.025254726409912
Validation loss: 2.0120429197947183

Epoch: 6| Step: 12
Training loss: 1.9102156162261963
Validation loss: 2.011549234390259

Epoch: 6| Step: 13
Training loss: 1.893090009689331
Validation loss: 2.023064990838369

Epoch: 111| Step: 0
Training loss: 1.2855255603790283
Validation loss: 2.020240227381388

Epoch: 6| Step: 1
Training loss: 1.9676237106323242
Validation loss: 2.018876870473226

Epoch: 6| Step: 2
Training loss: 2.5037598609924316
Validation loss: 2.0334635575612388

Epoch: 6| Step: 3
Training loss: 1.4061260223388672
Validation loss: 2.0376844008763633

Epoch: 6| Step: 4
Training loss: 2.093067169189453
Validation loss: 2.041187504927317

Epoch: 6| Step: 5
Training loss: 2.4673256874084473
Validation loss: 2.056272506713867

Epoch: 6| Step: 6
Training loss: 2.430917739868164
Validation loss: 2.0627654790878296

Epoch: 6| Step: 7
Training loss: 2.3726282119750977
Validation loss: 2.050094723701477

Epoch: 6| Step: 8
Training loss: 2.13382625579834
Validation loss: 2.058108925819397

Epoch: 6| Step: 9
Training loss: 2.974106788635254
Validation loss: 2.053341050942739

Epoch: 6| Step: 10
Training loss: 2.202369451522827
Validation loss: 2.0200477639834085

Epoch: 6| Step: 11
Training loss: 2.3368747234344482
Validation loss: 2.0229205091794333

Epoch: 6| Step: 12
Training loss: 2.099254608154297
Validation loss: 2.0157169500986734

Epoch: 6| Step: 13
Training loss: 1.780841588973999
Validation loss: 2.01785010099411

Epoch: 112| Step: 0
Training loss: 1.5276875495910645
Validation loss: 2.0096022288004556

Epoch: 6| Step: 1
Training loss: 2.1837732791900635
Validation loss: 2.0129045248031616

Epoch: 6| Step: 2
Training loss: 2.394876003265381
Validation loss: 2.014130711555481

Epoch: 6| Step: 3
Training loss: 2.29142689704895
Validation loss: 2.0195985237757363

Epoch: 6| Step: 4
Training loss: 2.5987329483032227
Validation loss: 2.0181413888931274

Epoch: 6| Step: 5
Training loss: 1.893388271331787
Validation loss: 2.022377292315165

Epoch: 6| Step: 6
Training loss: 2.246932029724121
Validation loss: 2.0295676589012146

Epoch: 6| Step: 7
Training loss: 1.770078420639038
Validation loss: 2.0271285573641458

Epoch: 6| Step: 8
Training loss: 2.030147075653076
Validation loss: 2.032053450743357

Epoch: 6| Step: 9
Training loss: 2.1551456451416016
Validation loss: 2.025537848472595

Epoch: 6| Step: 10
Training loss: 1.9084641933441162
Validation loss: 2.0331774950027466

Epoch: 6| Step: 11
Training loss: 2.1772284507751465
Validation loss: 2.0227473378181458

Epoch: 6| Step: 12
Training loss: 3.2182364463806152
Validation loss: 2.0224204063415527

Epoch: 6| Step: 13
Training loss: 2.057990789413452
Validation loss: 2.0186210672060647

Epoch: 113| Step: 0
Training loss: 1.6727615594863892
Validation loss: 2.016375402609507

Epoch: 6| Step: 1
Training loss: 2.4938676357269287
Validation loss: 2.0165146390597024

Epoch: 6| Step: 2
Training loss: 2.16059947013855
Validation loss: 2.012262761592865

Epoch: 6| Step: 3
Training loss: 2.1286535263061523
Validation loss: 2.016235649585724

Epoch: 6| Step: 4
Training loss: 2.579868793487549
Validation loss: 2.007521708806356

Epoch: 6| Step: 5
Training loss: 1.5896097421646118
Validation loss: 2.011140525341034

Epoch: 6| Step: 6
Training loss: 2.3075809478759766
Validation loss: 2.0078587929407754

Epoch: 6| Step: 7
Training loss: 2.482529401779175
Validation loss: 2.0096161166826882

Epoch: 6| Step: 8
Training loss: 2.1200971603393555
Validation loss: 2.002105096975962

Epoch: 6| Step: 9
Training loss: 2.284954071044922
Validation loss: 2.0006290475527444

Epoch: 6| Step: 10
Training loss: 2.142529010772705
Validation loss: 2.0050533612569175

Epoch: 6| Step: 11
Training loss: 2.6083807945251465
Validation loss: 2.0067495703697205

Epoch: 6| Step: 12
Training loss: 1.5510557889938354
Validation loss: 2.0075947443644204

Epoch: 6| Step: 13
Training loss: 1.8008427619934082
Validation loss: 2.000157674153646

Epoch: 114| Step: 0
Training loss: 1.6788594722747803
Validation loss: 2.011468529701233

Epoch: 6| Step: 1
Training loss: 2.241914749145508
Validation loss: 2.0070332884788513

Epoch: 6| Step: 2
Training loss: 2.25449275970459
Validation loss: 2.0099238753318787

Epoch: 6| Step: 3
Training loss: 2.0615780353546143
Validation loss: 2.0151917934417725

Epoch: 6| Step: 4
Training loss: 2.2963733673095703
Validation loss: 2.011427958806356

Epoch: 6| Step: 5
Training loss: 1.9525493383407593
Validation loss: 2.015931725502014

Epoch: 6| Step: 6
Training loss: 2.445020914077759
Validation loss: 2.0226340095202127

Epoch: 6| Step: 7
Training loss: 2.2623441219329834
Validation loss: 2.024582326412201

Epoch: 6| Step: 8
Training loss: 2.3096542358398438
Validation loss: 2.0284010767936707

Epoch: 6| Step: 9
Training loss: 2.012235164642334
Validation loss: 2.020366628964742

Epoch: 6| Step: 10
Training loss: 2.105032444000244
Validation loss: 2.0249674717585244

Epoch: 6| Step: 11
Training loss: 1.5308396816253662
Validation loss: 2.0270132025082908

Epoch: 6| Step: 12
Training loss: 2.480759620666504
Validation loss: 2.029100477695465

Epoch: 6| Step: 13
Training loss: 1.8907732963562012
Validation loss: 2.0248407125473022

Epoch: 115| Step: 0
Training loss: 1.9440969228744507
Validation loss: 2.028467337290446

Epoch: 6| Step: 1
Training loss: 1.5179052352905273
Validation loss: 2.025947411855062

Epoch: 6| Step: 2
Training loss: 2.048513412475586
Validation loss: 2.028693695863088

Epoch: 6| Step: 3
Training loss: 2.036182403564453
Validation loss: 2.0262678265571594

Epoch: 6| Step: 4
Training loss: 2.1856837272644043
Validation loss: 2.0172871152559915

Epoch: 6| Step: 5
Training loss: 1.8847479820251465
Validation loss: 2.0178000728289285

Epoch: 6| Step: 6
Training loss: 1.738649845123291
Validation loss: 2.012949208418528

Epoch: 6| Step: 7
Training loss: 2.1432712078094482
Validation loss: 2.01126366853714

Epoch: 6| Step: 8
Training loss: 1.9911134243011475
Validation loss: 2.020857810974121

Epoch: 6| Step: 9
Training loss: 2.314621925354004
Validation loss: 2.018190006415049

Epoch: 6| Step: 10
Training loss: 2.714071750640869
Validation loss: 2.014961083730062

Epoch: 6| Step: 11
Training loss: 1.8375362157821655
Validation loss: 2.010692576567332

Epoch: 6| Step: 12
Training loss: 2.520106792449951
Validation loss: 2.013201276461283

Epoch: 6| Step: 13
Training loss: 2.5803160667419434
Validation loss: 2.013065199057261

Epoch: 116| Step: 0
Training loss: 2.3289175033569336
Validation loss: 2.0158269008000693

Epoch: 6| Step: 1
Training loss: 2.194998264312744
Validation loss: 2.0122797886530557

Epoch: 6| Step: 2
Training loss: 2.0775203704833984
Validation loss: 2.0110098322232566

Epoch: 6| Step: 3
Training loss: 2.230297565460205
Validation loss: 2.0057347615559897

Epoch: 6| Step: 4
Training loss: 2.1047251224517822
Validation loss: 2.02093372742335

Epoch: 6| Step: 5
Training loss: 1.9833860397338867
Validation loss: 2.0227673252423606

Epoch: 6| Step: 6
Training loss: 2.2738192081451416
Validation loss: 2.0226356983184814

Epoch: 6| Step: 7
Training loss: 2.0643653869628906
Validation loss: 2.0182273586591086

Epoch: 6| Step: 8
Training loss: 1.5988774299621582
Validation loss: 2.021480917930603

Epoch: 6| Step: 9
Training loss: 2.232375383377075
Validation loss: 2.0257583459218345

Epoch: 6| Step: 10
Training loss: 2.0670411586761475
Validation loss: 2.026676138242086

Epoch: 6| Step: 11
Training loss: 1.664019227027893
Validation loss: 2.0266953706741333

Epoch: 6| Step: 12
Training loss: 2.7762019634246826
Validation loss: 2.0298075477282205

Epoch: 6| Step: 13
Training loss: 1.9402289390563965
Validation loss: 2.028310557206472

Epoch: 117| Step: 0
Training loss: 1.708390474319458
Validation loss: 2.0427954395612082

Epoch: 6| Step: 1
Training loss: 1.622909426689148
Validation loss: 2.028175334135691

Epoch: 6| Step: 2
Training loss: 2.678781509399414
Validation loss: 2.044240971406301

Epoch: 6| Step: 3
Training loss: 2.6698198318481445
Validation loss: 2.0307792822519937

Epoch: 6| Step: 4
Training loss: 2.6178500652313232
Validation loss: 2.026432474454244

Epoch: 6| Step: 5
Training loss: 1.8590446710586548
Validation loss: 2.027439018090566

Epoch: 6| Step: 6
Training loss: 2.0827574729919434
Validation loss: 2.0141578118006387

Epoch: 6| Step: 7
Training loss: 2.3336334228515625
Validation loss: 2.03096079826355

Epoch: 6| Step: 8
Training loss: 1.7231746912002563
Validation loss: 2.0254651506741843

Epoch: 6| Step: 9
Training loss: 1.7935442924499512
Validation loss: 2.0345226724942527

Epoch: 6| Step: 10
Training loss: 1.7166996002197266
Validation loss: 2.030727287133535

Epoch: 6| Step: 11
Training loss: 2.11140513420105
Validation loss: 2.0280001759529114

Epoch: 6| Step: 12
Training loss: 2.1167383193969727
Validation loss: 2.0245902140935264

Epoch: 6| Step: 13
Training loss: 2.6167829036712646
Validation loss: 2.0309364000956216

Epoch: 118| Step: 0
Training loss: 2.1247501373291016
Validation loss: 2.0279006958007812

Epoch: 6| Step: 1
Training loss: 2.2387382984161377
Validation loss: 2.0394683281580606

Epoch: 6| Step: 2
Training loss: 2.426994562149048
Validation loss: 2.034186621507009

Epoch: 6| Step: 3
Training loss: 1.9204353094100952
Validation loss: 2.031029542287191

Epoch: 6| Step: 4
Training loss: 1.4771406650543213
Validation loss: 2.032052000363668

Epoch: 6| Step: 5
Training loss: 1.8531744480133057
Validation loss: 2.033037006855011

Epoch: 6| Step: 6
Training loss: 2.027501344680786
Validation loss: 2.028381089369456

Epoch: 6| Step: 7
Training loss: 1.6094603538513184
Validation loss: 2.027748703956604

Epoch: 6| Step: 8
Training loss: 2.9988110065460205
Validation loss: 2.034294923146566

Epoch: 6| Step: 9
Training loss: 2.244882106781006
Validation loss: 2.031610826651255

Epoch: 6| Step: 10
Training loss: 2.365593910217285
Validation loss: 2.031974732875824

Epoch: 6| Step: 11
Training loss: 2.128645181655884
Validation loss: 2.025308152039846

Epoch: 6| Step: 12
Training loss: 1.9729583263397217
Validation loss: 2.030700922012329

Epoch: 6| Step: 13
Training loss: 1.873229742050171
Validation loss: 2.034606158733368

Epoch: 119| Step: 0
Training loss: 2.5524418354034424
Validation loss: 2.0293312072753906

Epoch: 6| Step: 1
Training loss: 1.8841338157653809
Validation loss: 2.026910384496053

Epoch: 6| Step: 2
Training loss: 1.0426113605499268
Validation loss: 2.0203569730122886

Epoch: 6| Step: 3
Training loss: 1.83488929271698
Validation loss: 2.033667186896006

Epoch: 6| Step: 4
Training loss: 1.6647324562072754
Validation loss: 2.0280827283859253

Epoch: 6| Step: 5
Training loss: 1.7464611530303955
Validation loss: 2.034503440062205

Epoch: 6| Step: 6
Training loss: 3.012645721435547
Validation loss: 2.029070496559143

Epoch: 6| Step: 7
Training loss: 1.7331987619400024
Validation loss: 2.0221376419067383

Epoch: 6| Step: 8
Training loss: 2.289485216140747
Validation loss: 2.012374440828959

Epoch: 6| Step: 9
Training loss: 2.48414945602417
Validation loss: 2.017212529977163

Epoch: 6| Step: 10
Training loss: 2.3369388580322266
Validation loss: 2.005311369895935

Epoch: 6| Step: 11
Training loss: 1.7209877967834473
Validation loss: 2.0122608741124473

Epoch: 6| Step: 12
Training loss: 2.545555353164673
Validation loss: 2.0138823986053467

Epoch: 6| Step: 13
Training loss: 2.495133399963379
Validation loss: 2.0207491715749106

Epoch: 120| Step: 0
Training loss: 2.053196907043457
Validation loss: 2.024776041507721

Epoch: 6| Step: 1
Training loss: 2.3079440593719482
Validation loss: 2.028803904851278

Epoch: 6| Step: 2
Training loss: 1.8634121417999268
Validation loss: 2.0242721835772195

Epoch: 6| Step: 3
Training loss: 1.8162448406219482
Validation loss: 2.024898886680603

Epoch: 6| Step: 4
Training loss: 2.4759693145751953
Validation loss: 2.032322367032369

Epoch: 6| Step: 5
Training loss: 2.32515287399292
Validation loss: 2.0262441635131836

Epoch: 6| Step: 6
Training loss: 1.9549124240875244
Validation loss: 2.0352647503217063

Epoch: 6| Step: 7
Training loss: 1.6489416360855103
Validation loss: 2.0393057068188987

Epoch: 6| Step: 8
Training loss: 2.441168785095215
Validation loss: 2.0377882917722068

Epoch: 6| Step: 9
Training loss: 1.8263099193572998
Validation loss: 2.034408390522003

Epoch: 6| Step: 10
Training loss: 2.1224570274353027
Validation loss: 2.031421879927317

Epoch: 6| Step: 11
Training loss: 1.9635581970214844
Validation loss: 2.0287737449010215

Epoch: 6| Step: 12
Training loss: 2.4380264282226562
Validation loss: 2.0436178843180337

Epoch: 6| Step: 13
Training loss: 1.9876458644866943
Validation loss: 2.0255607962608337

Epoch: 121| Step: 0
Training loss: 2.49658203125
Validation loss: 2.017475505669912

Epoch: 6| Step: 1
Training loss: 1.6945245265960693
Validation loss: 2.01487934589386

Epoch: 6| Step: 2
Training loss: 2.0132298469543457
Validation loss: 2.0157090425491333

Epoch: 6| Step: 3
Training loss: 2.542254686355591
Validation loss: 2.0118000706036887

Epoch: 6| Step: 4
Training loss: 2.366894245147705
Validation loss: 2.009543001651764

Epoch: 6| Step: 5
Training loss: 1.9058743715286255
Validation loss: 2.013120969136556

Epoch: 6| Step: 6
Training loss: 2.2490644454956055
Validation loss: 2.0140530665715537

Epoch: 6| Step: 7
Training loss: 1.868513584136963
Validation loss: 2.0055504639943442

Epoch: 6| Step: 8
Training loss: 1.9865304231643677
Validation loss: 2.0062123934427896

Epoch: 6| Step: 9
Training loss: 2.5805163383483887
Validation loss: 2.012451450030009

Epoch: 6| Step: 10
Training loss: 1.7752715349197388
Validation loss: 2.0132110714912415

Epoch: 6| Step: 11
Training loss: 2.088677406311035
Validation loss: 2.0130884051322937

Epoch: 6| Step: 12
Training loss: 1.7096539735794067
Validation loss: 2.0161556601524353

Epoch: 6| Step: 13
Training loss: 2.0245285034179688
Validation loss: 2.0155569513638816

Epoch: 122| Step: 0
Training loss: 2.340275764465332
Validation loss: 2.0271538496017456

Epoch: 6| Step: 1
Training loss: 2.268739700317383
Validation loss: 2.0290104150772095

Epoch: 6| Step: 2
Training loss: 1.8908607959747314
Validation loss: 2.0361794034639993

Epoch: 6| Step: 3
Training loss: 1.6859462261199951
Validation loss: 2.053797642389933

Epoch: 6| Step: 4
Training loss: 2.1736702919006348
Validation loss: 2.056758920351664

Epoch: 6| Step: 5
Training loss: 1.9116806983947754
Validation loss: 2.046467900276184

Epoch: 6| Step: 6
Training loss: 2.382093906402588
Validation loss: 2.058764696121216

Epoch: 6| Step: 7
Training loss: 2.4043800830841064
Validation loss: 2.034778873125712

Epoch: 6| Step: 8
Training loss: 1.5807033777236938
Validation loss: 2.041503667831421

Epoch: 6| Step: 9
Training loss: 2.753927707672119
Validation loss: 2.0351792573928833

Epoch: 6| Step: 10
Training loss: 2.012984037399292
Validation loss: 2.0252188245455423

Epoch: 6| Step: 11
Training loss: 2.1671438217163086
Validation loss: 2.031186600526174

Epoch: 6| Step: 12
Training loss: 2.1875104904174805
Validation loss: 2.015345315138499

Epoch: 6| Step: 13
Training loss: 1.6759687662124634
Validation loss: 2.0124128262201944

Epoch: 123| Step: 0
Training loss: 2.6062777042388916
Validation loss: 2.0207895239194236

Epoch: 6| Step: 1
Training loss: 2.5980112552642822
Validation loss: 2.030162731806437

Epoch: 6| Step: 2
Training loss: 1.6732679605484009
Validation loss: 2.02348393201828

Epoch: 6| Step: 3
Training loss: 2.246903896331787
Validation loss: 2.0223701000213623

Epoch: 6| Step: 4
Training loss: 1.888589859008789
Validation loss: 2.021010398864746

Epoch: 6| Step: 5
Training loss: 2.5583579540252686
Validation loss: 2.022798736890157

Epoch: 6| Step: 6
Training loss: 1.6619796752929688
Validation loss: 2.0282989343007407

Epoch: 6| Step: 7
Training loss: 1.904185175895691
Validation loss: 2.030541181564331

Epoch: 6| Step: 8
Training loss: 1.9067788124084473
Validation loss: 2.02573569615682

Epoch: 6| Step: 9
Training loss: 2.0866193771362305
Validation loss: 2.0390578508377075

Epoch: 6| Step: 10
Training loss: 2.1653900146484375
Validation loss: 2.027497390906016

Epoch: 6| Step: 11
Training loss: 2.063467025756836
Validation loss: 2.0251117944717407

Epoch: 6| Step: 12
Training loss: 1.7917320728302002
Validation loss: 2.0307735204696655

Epoch: 6| Step: 13
Training loss: 1.8750399351119995
Validation loss: 2.0250693559646606

Epoch: 124| Step: 0
Training loss: 2.430960178375244
Validation loss: 2.031660735607147

Epoch: 6| Step: 1
Training loss: 2.0609841346740723
Validation loss: 2.027587334314982

Epoch: 6| Step: 2
Training loss: 2.4741909503936768
Validation loss: 2.018794536590576

Epoch: 6| Step: 3
Training loss: 1.59746515750885
Validation loss: 2.0189887086550393

Epoch: 6| Step: 4
Training loss: 2.280667304992676
Validation loss: 2.021677772204081

Epoch: 6| Step: 5
Training loss: 1.7465033531188965
Validation loss: 2.0234756469726562

Epoch: 6| Step: 6
Training loss: 2.265141010284424
Validation loss: 2.0196520686149597

Epoch: 6| Step: 7
Training loss: 2.5759940147399902
Validation loss: 2.0239752928415933

Epoch: 6| Step: 8
Training loss: 1.525378704071045
Validation loss: 2.0298406879107156

Epoch: 6| Step: 9
Training loss: 1.3938151597976685
Validation loss: 2.0424704551696777

Epoch: 6| Step: 10
Training loss: 1.9476487636566162
Validation loss: 2.0564485987027488

Epoch: 6| Step: 11
Training loss: 2.5319197177886963
Validation loss: 2.0452431639035544

Epoch: 6| Step: 12
Training loss: 2.3944859504699707
Validation loss: 2.0453354716300964

Epoch: 6| Step: 13
Training loss: 1.792372465133667
Validation loss: 2.035124897956848

Epoch: 125| Step: 0
Training loss: 3.107494831085205
Validation loss: 2.038844883441925

Epoch: 6| Step: 1
Training loss: 2.138298273086548
Validation loss: 2.0312918225924173

Epoch: 6| Step: 2
Training loss: 1.9457058906555176
Validation loss: 2.0313960909843445

Epoch: 6| Step: 3
Training loss: 1.8045690059661865
Validation loss: 2.0238258242607117

Epoch: 6| Step: 4
Training loss: 1.8820054531097412
Validation loss: 2.0080785353978476

Epoch: 6| Step: 5
Training loss: 2.260931968688965
Validation loss: 2.0053100983301797

Epoch: 6| Step: 6
Training loss: 1.5638576745986938
Validation loss: 2.0012786189715066

Epoch: 6| Step: 7
Training loss: 2.1382336616516113
Validation loss: 2.004730761051178

Epoch: 6| Step: 8
Training loss: 2.1004371643066406
Validation loss: 2.0113183856010437

Epoch: 6| Step: 9
Training loss: 2.2920846939086914
Validation loss: 2.0056891441345215

Epoch: 6| Step: 10
Training loss: 1.5168914794921875
Validation loss: 2.015691081682841

Epoch: 6| Step: 11
Training loss: 2.2427966594696045
Validation loss: 2.0157297452290854

Epoch: 6| Step: 12
Training loss: 2.823101282119751
Validation loss: 2.026426533857981

Epoch: 6| Step: 13
Training loss: 1.8090126514434814
Validation loss: 2.0276573101679483

Epoch: 126| Step: 0
Training loss: 2.00818133354187
Validation loss: 2.024393081665039

Epoch: 6| Step: 1
Training loss: 2.0813426971435547
Validation loss: 2.0294612646102905

Epoch: 6| Step: 2
Training loss: 2.0927913188934326
Validation loss: 2.0308961272239685

Epoch: 6| Step: 3
Training loss: 2.1548233032226562
Validation loss: 2.042343477408091

Epoch: 6| Step: 4
Training loss: 1.535038948059082
Validation loss: 2.060389757156372

Epoch: 6| Step: 5
Training loss: 2.5635733604431152
Validation loss: 2.0520837704340615

Epoch: 6| Step: 6
Training loss: 2.6553807258605957
Validation loss: 2.0550572276115417

Epoch: 6| Step: 7
Training loss: 1.571761965751648
Validation loss: 2.0404812494913735

Epoch: 6| Step: 8
Training loss: 2.35278058052063
Validation loss: 2.053514281908671

Epoch: 6| Step: 9
Training loss: 2.4181630611419678
Validation loss: 2.0453973015149436

Epoch: 6| Step: 10
Training loss: 1.7828338146209717
Validation loss: 2.0490975181261697

Epoch: 6| Step: 11
Training loss: 1.9228549003601074
Validation loss: 2.041101078192393

Epoch: 6| Step: 12
Training loss: 1.6820111274719238
Validation loss: 2.0488430857658386

Epoch: 6| Step: 13
Training loss: 2.1273579597473145
Validation loss: 2.042504588762919

Epoch: 127| Step: 0
Training loss: 2.171933889389038
Validation loss: 2.032516598701477

Epoch: 6| Step: 1
Training loss: 2.516387462615967
Validation loss: 2.0401187936464944

Epoch: 6| Step: 2
Training loss: 2.1316123008728027
Validation loss: 2.0291281938552856

Epoch: 6| Step: 3
Training loss: 1.6773772239685059
Validation loss: 2.0254034399986267

Epoch: 6| Step: 4
Training loss: 1.7952680587768555
Validation loss: 2.031562924385071

Epoch: 6| Step: 5
Training loss: 1.6545648574829102
Validation loss: 2.023172656695048

Epoch: 6| Step: 6
Training loss: 2.4115052223205566
Validation loss: 2.032906989256541

Epoch: 6| Step: 7
Training loss: 1.7780094146728516
Validation loss: 2.0321632424990335

Epoch: 6| Step: 8
Training loss: 2.606861114501953
Validation loss: 2.02826197942098

Epoch: 6| Step: 9
Training loss: 2.3209848403930664
Validation loss: 2.027587910493215

Epoch: 6| Step: 10
Training loss: 1.9833028316497803
Validation loss: 2.037541230519613

Epoch: 6| Step: 11
Training loss: 2.1336896419525146
Validation loss: 2.045071224371592

Epoch: 6| Step: 12
Training loss: 1.8012335300445557
Validation loss: 2.038828710714976

Epoch: 6| Step: 13
Training loss: 2.2028634548187256
Validation loss: 2.03402711947759

Epoch: 128| Step: 0
Training loss: 1.9841670989990234
Validation loss: 2.0531433622042337

Epoch: 6| Step: 1
Training loss: 1.7851548194885254
Validation loss: 2.0535280307133994

Epoch: 6| Step: 2
Training loss: 2.5733141899108887
Validation loss: 2.0454158385594687

Epoch: 6| Step: 3
Training loss: 1.9750468730926514
Validation loss: 2.042212883631388

Epoch: 6| Step: 4
Training loss: 1.791057825088501
Validation loss: 2.039624253908793

Epoch: 6| Step: 5
Training loss: 2.5647194385528564
Validation loss: 2.0345500310262046

Epoch: 6| Step: 6
Training loss: 2.619013786315918
Validation loss: 2.0326353510220847

Epoch: 6| Step: 7
Training loss: 2.4113078117370605
Validation loss: 2.036182681719462

Epoch: 6| Step: 8
Training loss: 2.0179200172424316
Validation loss: 2.039013604323069

Epoch: 6| Step: 9
Training loss: 2.0105388164520264
Validation loss: 2.0325963497161865

Epoch: 6| Step: 10
Training loss: 1.7726991176605225
Validation loss: 2.0270493626594543

Epoch: 6| Step: 11
Training loss: 1.971637487411499
Validation loss: 2.023174007733663

Epoch: 6| Step: 12
Training loss: 1.5211870670318604
Validation loss: 2.0183671712875366

Epoch: 6| Step: 13
Training loss: 2.0132408142089844
Validation loss: 2.0210843483606973

Epoch: 129| Step: 0
Training loss: 2.0324866771698
Validation loss: 2.0264074206352234

Epoch: 6| Step: 1
Training loss: 2.19862699508667
Validation loss: 2.007243732611338

Epoch: 6| Step: 2
Training loss: 2.283614158630371
Validation loss: 2.0213319460550943

Epoch: 6| Step: 3
Training loss: 1.6683191061019897
Validation loss: 2.035040299097697

Epoch: 6| Step: 4
Training loss: 1.3041253089904785
Validation loss: 2.0242244601249695

Epoch: 6| Step: 5
Training loss: 2.210996150970459
Validation loss: 2.040922482808431

Epoch: 6| Step: 6
Training loss: 2.1498804092407227
Validation loss: 2.0425367951393127

Epoch: 6| Step: 7
Training loss: 2.544902801513672
Validation loss: 2.0472574830055237

Epoch: 6| Step: 8
Training loss: 2.172053575515747
Validation loss: 2.0421817302703857

Epoch: 6| Step: 9
Training loss: 1.844414472579956
Validation loss: 2.0404176115989685

Epoch: 6| Step: 10
Training loss: 1.9991075992584229
Validation loss: 2.035535474618276

Epoch: 6| Step: 11
Training loss: 1.8397681713104248
Validation loss: 2.0240861773490906

Epoch: 6| Step: 12
Training loss: 2.219425678253174
Validation loss: 2.042869726816813

Epoch: 6| Step: 13
Training loss: 2.534158229827881
Validation loss: 2.0360963145891824

Epoch: 130| Step: 0
Training loss: 2.172489643096924
Validation loss: 2.0360319018363953

Epoch: 6| Step: 1
Training loss: 2.2629599571228027
Validation loss: 2.044168253739675

Epoch: 6| Step: 2
Training loss: 2.0114457607269287
Validation loss: 2.055114964644114

Epoch: 6| Step: 3
Training loss: 2.0106873512268066
Validation loss: 2.0469678243001304

Epoch: 6| Step: 4
Training loss: 2.5400314331054688
Validation loss: 2.0518412391344705

Epoch: 6| Step: 5
Training loss: 2.1625964641571045
Validation loss: 2.0476339856783548

Epoch: 6| Step: 6
Training loss: 2.0248076915740967
Validation loss: 2.0462878147761026

Epoch: 6| Step: 7
Training loss: 1.9903008937835693
Validation loss: 2.0390941301981607

Epoch: 6| Step: 8
Training loss: 1.6390018463134766
Validation loss: 2.034708619117737

Epoch: 6| Step: 9
Training loss: 2.2482662200927734
Validation loss: 2.029016375541687

Epoch: 6| Step: 10
Training loss: 1.8110511302947998
Validation loss: 2.024102807044983

Epoch: 6| Step: 11
Training loss: 1.8199958801269531
Validation loss: 2.030602594216665

Epoch: 6| Step: 12
Training loss: 2.4931468963623047
Validation loss: 2.030284881591797

Epoch: 6| Step: 13
Training loss: 1.9233098030090332
Validation loss: 2.0310915311177573

Epoch: 131| Step: 0
Training loss: 1.7792870998382568
Validation loss: 2.0282371640205383

Epoch: 6| Step: 1
Training loss: 1.8930696249008179
Validation loss: 2.029886484146118

Epoch: 6| Step: 2
Training loss: 2.1505870819091797
Validation loss: 2.0316773851712546

Epoch: 6| Step: 3
Training loss: 2.1590070724487305
Validation loss: 2.0306504567464194

Epoch: 6| Step: 4
Training loss: 1.7966067790985107
Validation loss: 2.0318891207377114

Epoch: 6| Step: 5
Training loss: 2.7162017822265625
Validation loss: 2.0305702288945517

Epoch: 6| Step: 6
Training loss: 2.690788745880127
Validation loss: 2.0317981243133545

Epoch: 6| Step: 7
Training loss: 2.3835816383361816
Validation loss: 2.0372623205184937

Epoch: 6| Step: 8
Training loss: 1.7554621696472168
Validation loss: 2.0454458196957908

Epoch: 6| Step: 9
Training loss: 1.9746222496032715
Validation loss: 2.0509002407391868

Epoch: 6| Step: 10
Training loss: 2.008409023284912
Validation loss: 2.056341052055359

Epoch: 6| Step: 11
Training loss: 2.366593360900879
Validation loss: 2.051526685555776

Epoch: 6| Step: 12
Training loss: 2.2497920989990234
Validation loss: 2.0776899258295694

Epoch: 6| Step: 13
Training loss: 1.3788384199142456
Validation loss: 2.0436739921569824

Epoch: 132| Step: 0
Training loss: 2.481555938720703
Validation loss: 2.0433346033096313

Epoch: 6| Step: 1
Training loss: 2.31032657623291
Validation loss: 2.0316150983174643

Epoch: 6| Step: 2
Training loss: 1.3398308753967285
Validation loss: 2.0237406492233276

Epoch: 6| Step: 3
Training loss: 2.294330596923828
Validation loss: 2.027609705924988

Epoch: 6| Step: 4
Training loss: 2.4656519889831543
Validation loss: 2.0164866050084433

Epoch: 6| Step: 5
Training loss: 2.230285882949829
Validation loss: 2.015926698843638

Epoch: 6| Step: 6
Training loss: 1.5709705352783203
Validation loss: 2.0114689469337463

Epoch: 6| Step: 7
Training loss: 2.1407034397125244
Validation loss: 2.0145482619603476

Epoch: 6| Step: 8
Training loss: 2.427076816558838
Validation loss: 2.0060964028040567

Epoch: 6| Step: 9
Training loss: 1.986258625984192
Validation loss: 2.013473868370056

Epoch: 6| Step: 10
Training loss: 2.1438827514648438
Validation loss: 2.018904149532318

Epoch: 6| Step: 11
Training loss: 1.7384812831878662
Validation loss: 2.010729749997457

Epoch: 6| Step: 12
Training loss: 1.8980857133865356
Validation loss: 2.0152029991149902

Epoch: 6| Step: 13
Training loss: 2.096386432647705
Validation loss: 2.0104942123095193

Epoch: 133| Step: 0
Training loss: 1.2721508741378784
Validation loss: 2.0140013297398887

Epoch: 6| Step: 1
Training loss: 1.6761717796325684
Validation loss: 2.0101735989252725

Epoch: 6| Step: 2
Training loss: 2.600106716156006
Validation loss: 2.0140039126078286

Epoch: 6| Step: 3
Training loss: 1.9035050868988037
Validation loss: 2.0134074687957764

Epoch: 6| Step: 4
Training loss: 1.533005952835083
Validation loss: 2.0107609033584595

Epoch: 6| Step: 5
Training loss: 2.345731735229492
Validation loss: 2.027751644452413

Epoch: 6| Step: 6
Training loss: 2.5543301105499268
Validation loss: 2.015327274799347

Epoch: 6| Step: 7
Training loss: 2.468613624572754
Validation loss: 2.0337573091189065

Epoch: 6| Step: 8
Training loss: 2.492645025253296
Validation loss: 2.0254851579666138

Epoch: 6| Step: 9
Training loss: 2.7323131561279297
Validation loss: 2.027183473110199

Epoch: 6| Step: 10
Training loss: 0.931223452091217
Validation loss: 2.0289929707845054

Epoch: 6| Step: 11
Training loss: 2.0832743644714355
Validation loss: 2.041627128918966

Epoch: 6| Step: 12
Training loss: 2.475156784057617
Validation loss: 2.017893671989441

Epoch: 6| Step: 13
Training loss: 1.7709840536117554
Validation loss: 2.026373863220215

Epoch: 134| Step: 0
Training loss: 1.9627892971038818
Validation loss: 2.0238809982935586

Epoch: 6| Step: 1
Training loss: 2.0280697345733643
Validation loss: 2.03301473458608

Epoch: 6| Step: 2
Training loss: 1.6769276857376099
Validation loss: 2.0386801958084106

Epoch: 6| Step: 3
Training loss: 2.783134937286377
Validation loss: 2.036620299021403

Epoch: 6| Step: 4
Training loss: 2.3898162841796875
Validation loss: 2.0278846621513367

Epoch: 6| Step: 5
Training loss: 2.7756152153015137
Validation loss: 2.0303980906804404

Epoch: 6| Step: 6
Training loss: 1.800413727760315
Validation loss: 2.035331686337789

Epoch: 6| Step: 7
Training loss: 1.7623862028121948
Validation loss: 2.0280181765556335

Epoch: 6| Step: 8
Training loss: 2.1853184700012207
Validation loss: 2.031677563985189

Epoch: 6| Step: 9
Training loss: 2.098353147506714
Validation loss: 2.0376760760943093

Epoch: 6| Step: 10
Training loss: 1.498875379562378
Validation loss: 2.0262622435887656

Epoch: 6| Step: 11
Training loss: 2.049309015274048
Validation loss: 2.024822990099589

Epoch: 6| Step: 12
Training loss: 1.4570006132125854
Validation loss: 2.0334415237108865

Epoch: 6| Step: 13
Training loss: 2.1411261558532715
Validation loss: 2.0303810437520347

Epoch: 135| Step: 0
Training loss: 1.9691624641418457
Validation loss: 2.034684499104818

Epoch: 6| Step: 1
Training loss: 1.9048632383346558
Validation loss: 2.03430438041687

Epoch: 6| Step: 2
Training loss: 1.4601280689239502
Validation loss: 2.0333332816759744

Epoch: 6| Step: 3
Training loss: 2.412179470062256
Validation loss: 2.0391299724578857

Epoch: 6| Step: 4
Training loss: 2.190652847290039
Validation loss: 2.038746476173401

Epoch: 6| Step: 5
Training loss: 1.691275715827942
Validation loss: 2.0253706574440002

Epoch: 6| Step: 6
Training loss: 1.8147263526916504
Validation loss: 2.0373430053393045

Epoch: 6| Step: 7
Training loss: 2.594967842102051
Validation loss: 2.0351832509040833

Epoch: 6| Step: 8
Training loss: 2.748746395111084
Validation loss: 2.025157312552134

Epoch: 6| Step: 9
Training loss: 2.1609833240509033
Validation loss: 2.0332329670588174

Epoch: 6| Step: 10
Training loss: 2.102283000946045
Validation loss: 2.0327388644218445

Epoch: 6| Step: 11
Training loss: 1.8700528144836426
Validation loss: 2.0417383313179016

Epoch: 6| Step: 12
Training loss: 2.247217893600464
Validation loss: 2.043624758720398

Epoch: 6| Step: 13
Training loss: 1.755102515220642
Validation loss: 2.0406782229741416

Epoch: 136| Step: 0
Training loss: 2.675773859024048
Validation loss: 2.0444148580233255

Epoch: 6| Step: 1
Training loss: 1.7930480241775513
Validation loss: 2.0425400137901306

Epoch: 6| Step: 2
Training loss: 1.832861304283142
Validation loss: 2.050640046596527

Epoch: 6| Step: 3
Training loss: 1.871927261352539
Validation loss: 2.0681991577148438

Epoch: 6| Step: 4
Training loss: 1.6779481172561646
Validation loss: 2.043920397758484

Epoch: 6| Step: 5
Training loss: 2.48573637008667
Validation loss: 2.0582891702651978

Epoch: 6| Step: 6
Training loss: 2.147183895111084
Validation loss: 2.0465065240859985

Epoch: 6| Step: 7
Training loss: 2.6482036113739014
Validation loss: 2.048187474409739

Epoch: 6| Step: 8
Training loss: 1.5956841707229614
Validation loss: 2.0481265981992087

Epoch: 6| Step: 9
Training loss: 1.877429485321045
Validation loss: 2.052104194959005

Epoch: 6| Step: 10
Training loss: 1.6444064378738403
Validation loss: 2.053561290105184

Epoch: 6| Step: 11
Training loss: 1.9092795848846436
Validation loss: 2.0270869533220925

Epoch: 6| Step: 12
Training loss: 2.31129789352417
Validation loss: 2.047511259714762

Epoch: 6| Step: 13
Training loss: 2.1454715728759766
Validation loss: 2.044074813524882

Epoch: 137| Step: 0
Training loss: 1.814483404159546
Validation loss: 2.056377092997233

Epoch: 6| Step: 1
Training loss: 2.034956932067871
Validation loss: 2.0464223821957908

Epoch: 6| Step: 2
Training loss: 1.9077266454696655
Validation loss: 2.0532508293787637

Epoch: 6| Step: 3
Training loss: 2.096811294555664
Validation loss: 2.046552896499634

Epoch: 6| Step: 4
Training loss: 2.532386302947998
Validation loss: 2.068105240662893

Epoch: 6| Step: 5
Training loss: 1.8030250072479248
Validation loss: 2.0694627364476523

Epoch: 6| Step: 6
Training loss: 1.7207303047180176
Validation loss: 2.0553724567095437

Epoch: 6| Step: 7
Training loss: 1.7447973489761353
Validation loss: 2.0547146598498025

Epoch: 6| Step: 8
Training loss: 1.7231178283691406
Validation loss: 2.055842479070028

Epoch: 6| Step: 9
Training loss: 2.323316812515259
Validation loss: 2.0512044429779053

Epoch: 6| Step: 10
Training loss: 2.360168695449829
Validation loss: 2.0452683766682944

Epoch: 6| Step: 11
Training loss: 1.8967304229736328
Validation loss: 2.044583320617676

Epoch: 6| Step: 12
Training loss: 2.2738747596740723
Validation loss: 2.05075736840566

Epoch: 6| Step: 13
Training loss: 2.4265975952148438
Validation loss: 2.049373964468638

Epoch: 138| Step: 0
Training loss: 2.026846408843994
Validation loss: 2.0486326813697815

Epoch: 6| Step: 1
Training loss: 2.4396069049835205
Validation loss: 2.050956586996714

Epoch: 6| Step: 2
Training loss: 1.88571035861969
Validation loss: 2.051937202612559

Epoch: 6| Step: 3
Training loss: 1.8718018531799316
Validation loss: 2.0501780907313027

Epoch: 6| Step: 4
Training loss: 2.4739651679992676
Validation loss: 2.0366022189458213

Epoch: 6| Step: 5
Training loss: 1.8002740144729614
Validation loss: 2.0407642920811973

Epoch: 6| Step: 6
Training loss: 1.9989820718765259
Validation loss: 2.064689060052236

Epoch: 6| Step: 7
Training loss: 1.7596681118011475
Validation loss: 2.0432205200195312

Epoch: 6| Step: 8
Training loss: 1.767726182937622
Validation loss: 2.0567638874053955

Epoch: 6| Step: 9
Training loss: 2.68455171585083
Validation loss: 2.063547909259796

Epoch: 6| Step: 10
Training loss: 1.919386863708496
Validation loss: 2.083212375640869

Epoch: 6| Step: 11
Training loss: 2.052213191986084
Validation loss: 2.0584487517674765

Epoch: 6| Step: 12
Training loss: 2.388669967651367
Validation loss: 2.0714922746022544

Epoch: 6| Step: 13
Training loss: 1.6927450895309448
Validation loss: 2.060077667236328

Epoch: 139| Step: 0
Training loss: 2.2908568382263184
Validation loss: 2.046099603176117

Epoch: 6| Step: 1
Training loss: 1.5161361694335938
Validation loss: 2.053479492664337

Epoch: 6| Step: 2
Training loss: 2.451292037963867
Validation loss: 2.0521697402000427

Epoch: 6| Step: 3
Training loss: 2.188316822052002
Validation loss: 2.05967245499293

Epoch: 6| Step: 4
Training loss: 1.8383545875549316
Validation loss: 2.052262822786967

Epoch: 6| Step: 5
Training loss: 2.1973438262939453
Validation loss: 2.066425641377767

Epoch: 6| Step: 6
Training loss: 2.176950454711914
Validation loss: 2.059365173180898

Epoch: 6| Step: 7
Training loss: 1.916612982749939
Validation loss: 2.0540546774864197

Epoch: 6| Step: 8
Training loss: 1.9409632682800293
Validation loss: 2.050303637981415

Epoch: 6| Step: 9
Training loss: 2.592756748199463
Validation loss: 2.065782984097799

Epoch: 6| Step: 10
Training loss: 2.0900840759277344
Validation loss: 2.047546108563741

Epoch: 6| Step: 11
Training loss: 2.1016266345977783
Validation loss: 2.051529506842295

Epoch: 6| Step: 12
Training loss: 1.8715860843658447
Validation loss: 2.0445950428644815

Epoch: 6| Step: 13
Training loss: 1.5899670124053955
Validation loss: 2.0428936084111533

Epoch: 140| Step: 0
Training loss: 2.645019769668579
Validation loss: 2.0527270833651223

Epoch: 6| Step: 1
Training loss: 1.7821681499481201
Validation loss: 2.0521612763404846

Epoch: 6| Step: 2
Training loss: 2.617549419403076
Validation loss: 2.052763024965922

Epoch: 6| Step: 3
Training loss: 2.063990354537964
Validation loss: 2.0583206613858542

Epoch: 6| Step: 4
Training loss: 2.5131824016571045
Validation loss: 2.057703673839569

Epoch: 6| Step: 5
Training loss: 2.1451008319854736
Validation loss: 2.0609553456306458

Epoch: 6| Step: 6
Training loss: 1.8779385089874268
Validation loss: 2.072826564311981

Epoch: 6| Step: 7
Training loss: 1.8740246295928955
Validation loss: 2.058297554651896

Epoch: 6| Step: 8
Training loss: 2.1518616676330566
Validation loss: 2.068950057029724

Epoch: 6| Step: 9
Training loss: 2.079254388809204
Validation loss: 2.054904341697693

Epoch: 6| Step: 10
Training loss: 1.8592599630355835
Validation loss: 2.064673741658529

Epoch: 6| Step: 11
Training loss: 2.090451240539551
Validation loss: 2.05952517191569

Epoch: 6| Step: 12
Training loss: 1.6262378692626953
Validation loss: 2.0544500748316445

Epoch: 6| Step: 13
Training loss: 1.2701630592346191
Validation loss: 2.0661089619000754

Epoch: 141| Step: 0
Training loss: 2.7226505279541016
Validation loss: 2.0553338527679443

Epoch: 6| Step: 1
Training loss: 2.577746868133545
Validation loss: 2.0472240447998047

Epoch: 6| Step: 2
Training loss: 1.8402974605560303
Validation loss: 2.063192884127299

Epoch: 6| Step: 3
Training loss: 1.6268818378448486
Validation loss: 2.0563756624857583

Epoch: 6| Step: 4
Training loss: 2.2747952938079834
Validation loss: 2.053812623023987

Epoch: 6| Step: 5
Training loss: 2.1363871097564697
Validation loss: 2.0542874336242676

Epoch: 6| Step: 6
Training loss: 2.1750693321228027
Validation loss: 2.055682122707367

Epoch: 6| Step: 7
Training loss: 1.7385082244873047
Validation loss: 2.0665679375330606

Epoch: 6| Step: 8
Training loss: 1.1846954822540283
Validation loss: 2.062967757383982

Epoch: 6| Step: 9
Training loss: 1.8214677572250366
Validation loss: 2.0707420110702515

Epoch: 6| Step: 10
Training loss: 2.1107990741729736
Validation loss: 2.058395584424337

Epoch: 6| Step: 11
Training loss: 2.316162109375
Validation loss: 2.063419222831726

Epoch: 6| Step: 12
Training loss: 2.3444762229919434
Validation loss: 2.0680839816729226

Epoch: 6| Step: 13
Training loss: 1.5140844583511353
Validation loss: 2.0677011211713157

Epoch: 142| Step: 0
Training loss: 2.1930344104766846
Validation loss: 2.073378622531891

Epoch: 6| Step: 1
Training loss: 1.979997158050537
Validation loss: 2.0742871165275574

Epoch: 6| Step: 2
Training loss: 2.3689098358154297
Validation loss: 2.0796960393587747

Epoch: 6| Step: 3
Training loss: 2.4784669876098633
Validation loss: 2.068382481733958

Epoch: 6| Step: 4
Training loss: 1.8664286136627197
Validation loss: 2.0605569084485373

Epoch: 6| Step: 5
Training loss: 2.112955331802368
Validation loss: 2.083913286526998

Epoch: 6| Step: 6
Training loss: 1.4119904041290283
Validation loss: 2.0800499320030212

Epoch: 6| Step: 7
Training loss: 1.6073143482208252
Validation loss: 2.072890837987264

Epoch: 6| Step: 8
Training loss: 1.79923677444458
Validation loss: 2.0732380747795105

Epoch: 6| Step: 9
Training loss: 1.6759744882583618
Validation loss: 2.0688373843828836

Epoch: 6| Step: 10
Training loss: 1.9227550029754639
Validation loss: 2.0720102787017822

Epoch: 6| Step: 11
Training loss: 2.028416395187378
Validation loss: 2.041700998942057

Epoch: 6| Step: 12
Training loss: 2.9221394062042236
Validation loss: 2.0357481638590493

Epoch: 6| Step: 13
Training loss: 2.1168198585510254
Validation loss: 2.0420456727345786

Epoch: 143| Step: 0
Training loss: 1.9381320476531982
Validation loss: 2.0358707706133523

Epoch: 6| Step: 1
Training loss: 2.105471134185791
Validation loss: 2.016705791155497

Epoch: 6| Step: 2
Training loss: 1.4324021339416504
Validation loss: 2.0202049811681113

Epoch: 6| Step: 3
Training loss: 2.2038023471832275
Validation loss: 2.036222438017527

Epoch: 6| Step: 4
Training loss: 1.6020711660385132
Validation loss: 2.032004257043203

Epoch: 6| Step: 5
Training loss: 2.523458957672119
Validation loss: 2.030016819636027

Epoch: 6| Step: 6
Training loss: 2.2141828536987305
Validation loss: 2.034124215443929

Epoch: 6| Step: 7
Training loss: 1.89823579788208
Validation loss: 2.039229909578959

Epoch: 6| Step: 8
Training loss: 2.0871236324310303
Validation loss: 2.040360609690348

Epoch: 6| Step: 9
Training loss: 2.1974680423736572
Validation loss: 2.052726447582245

Epoch: 6| Step: 10
Training loss: 2.0401206016540527
Validation loss: 2.049081325531006

Epoch: 6| Step: 11
Training loss: 2.364898204803467
Validation loss: 2.061244626839956

Epoch: 6| Step: 12
Training loss: 1.8202881813049316
Validation loss: 2.0535848339398703

Epoch: 6| Step: 13
Training loss: 2.0985476970672607
Validation loss: 2.044530928134918

Epoch: 144| Step: 0
Training loss: 2.163696765899658
Validation loss: 2.0553080638249717

Epoch: 6| Step: 1
Training loss: 2.696523427963257
Validation loss: 2.053649107615153

Epoch: 6| Step: 2
Training loss: 2.134716510772705
Validation loss: 2.0516720612843833

Epoch: 6| Step: 3
Training loss: 1.996577262878418
Validation loss: 2.0535637736320496

Epoch: 6| Step: 4
Training loss: 2.5497283935546875
Validation loss: 2.0540360808372498

Epoch: 6| Step: 5
Training loss: 1.3525707721710205
Validation loss: 2.0645312468210855

Epoch: 6| Step: 6
Training loss: 1.3605129718780518
Validation loss: 2.052510619163513

Epoch: 6| Step: 7
Training loss: 2.430631160736084
Validation loss: 2.0505396525065103

Epoch: 6| Step: 8
Training loss: 2.0615715980529785
Validation loss: 2.0683313409487405

Epoch: 6| Step: 9
Training loss: 1.6038835048675537
Validation loss: 2.070920924345652

Epoch: 6| Step: 10
Training loss: 1.8965983390808105
Validation loss: 2.0768777330716452

Epoch: 6| Step: 11
Training loss: 2.0860354900360107
Validation loss: 2.069740613301595

Epoch: 6| Step: 12
Training loss: 1.9697730541229248
Validation loss: 2.072058081626892

Epoch: 6| Step: 13
Training loss: 2.1779046058654785
Validation loss: 2.05265611410141

Epoch: 145| Step: 0
Training loss: 1.4716224670410156
Validation loss: 2.055667440096537

Epoch: 6| Step: 1
Training loss: 1.920196533203125
Validation loss: 2.057348608970642

Epoch: 6| Step: 2
Training loss: 2.0100364685058594
Validation loss: 2.047648032506307

Epoch: 6| Step: 3
Training loss: 2.548394203186035
Validation loss: 2.0333409309387207

Epoch: 6| Step: 4
Training loss: 2.7810277938842773
Validation loss: 2.0412925680478415

Epoch: 6| Step: 5
Training loss: 2.4978575706481934
Validation loss: 2.0394376715024314

Epoch: 6| Step: 6
Training loss: 1.573228359222412
Validation loss: 2.0501172145207724

Epoch: 6| Step: 7
Training loss: 2.668844223022461
Validation loss: 2.035203297932943

Epoch: 6| Step: 8
Training loss: 1.876201868057251
Validation loss: 2.0485114455223083

Epoch: 6| Step: 9
Training loss: 1.8266792297363281
Validation loss: 2.0539953311284385

Epoch: 6| Step: 10
Training loss: 1.8458936214447021
Validation loss: 2.066115081310272

Epoch: 6| Step: 11
Training loss: 1.7737107276916504
Validation loss: 2.0664649605751038

Epoch: 6| Step: 12
Training loss: 1.7731592655181885
Validation loss: 2.076622645060221

Epoch: 6| Step: 13
Training loss: 1.7305545806884766
Validation loss: 2.0947513977686563

Epoch: 146| Step: 0
Training loss: 2.811396360397339
Validation loss: 2.0989875197410583

Epoch: 6| Step: 1
Training loss: 2.0456395149230957
Validation loss: 2.1027464270591736

Epoch: 6| Step: 2
Training loss: 2.035571813583374
Validation loss: 2.0878299872080484

Epoch: 6| Step: 3
Training loss: 1.987527847290039
Validation loss: 2.0804662108421326

Epoch: 6| Step: 4
Training loss: 2.515862226486206
Validation loss: 2.0776667992273965

Epoch: 6| Step: 5
Training loss: 1.998093605041504
Validation loss: 2.0626207192738852

Epoch: 6| Step: 6
Training loss: 1.6509325504302979
Validation loss: 2.041618545850118

Epoch: 6| Step: 7
Training loss: 2.58301043510437
Validation loss: 2.052936633427938

Epoch: 6| Step: 8
Training loss: 1.5563701391220093
Validation loss: 2.051471769809723

Epoch: 6| Step: 9
Training loss: 1.7863311767578125
Validation loss: 2.053645650545756

Epoch: 6| Step: 10
Training loss: 2.539550542831421
Validation loss: 2.0585645039876304

Epoch: 6| Step: 11
Training loss: 1.7039703130722046
Validation loss: 2.0618894497553506

Epoch: 6| Step: 12
Training loss: 1.7659006118774414
Validation loss: 2.060201406478882

Epoch: 6| Step: 13
Training loss: 2.0506396293640137
Validation loss: 2.0665892362594604

Epoch: 147| Step: 0
Training loss: 2.383497714996338
Validation loss: 2.071662684281667

Epoch: 6| Step: 1
Training loss: 1.6969102621078491
Validation loss: 2.0733577013015747

Epoch: 6| Step: 2
Training loss: 1.7911622524261475
Validation loss: 2.0874078075091043

Epoch: 6| Step: 3
Training loss: 1.9077140092849731
Validation loss: 2.0871236324310303

Epoch: 6| Step: 4
Training loss: 2.3215718269348145
Validation loss: 2.0882208546002707

Epoch: 6| Step: 5
Training loss: 2.010533332824707
Validation loss: 2.0623899698257446

Epoch: 6| Step: 6
Training loss: 1.7005724906921387
Validation loss: 2.068811019261678

Epoch: 6| Step: 7
Training loss: 1.6540225744247437
Validation loss: 2.05813334385554

Epoch: 6| Step: 8
Training loss: 2.307384490966797
Validation loss: 2.061909774939219

Epoch: 6| Step: 9
Training loss: 1.799696922302246
Validation loss: 2.054210364818573

Epoch: 6| Step: 10
Training loss: 2.328747272491455
Validation loss: 2.0723994175593057

Epoch: 6| Step: 11
Training loss: 2.0803332328796387
Validation loss: 2.0684364835421243

Epoch: 6| Step: 12
Training loss: 1.748819351196289
Validation loss: 2.062972108523051

Epoch: 6| Step: 13
Training loss: 2.577275514602661
Validation loss: 2.0569934447606406

Epoch: 148| Step: 0
Training loss: 1.6752687692642212
Validation loss: 2.0664949218432107

Epoch: 6| Step: 1
Training loss: 2.0667319297790527
Validation loss: 2.0625563859939575

Epoch: 6| Step: 2
Training loss: 1.95272696018219
Validation loss: 2.0505547324816384

Epoch: 6| Step: 3
Training loss: 1.3791090250015259
Validation loss: 2.057620902856191

Epoch: 6| Step: 4
Training loss: 1.8236597776412964
Validation loss: 2.065513531366984

Epoch: 6| Step: 5
Training loss: 1.6532795429229736
Validation loss: 2.061537583669027

Epoch: 6| Step: 6
Training loss: 2.3205184936523438
Validation loss: 2.0681938330332437

Epoch: 6| Step: 7
Training loss: 2.865212917327881
Validation loss: 2.0673797130584717

Epoch: 6| Step: 8
Training loss: 1.8259658813476562
Validation loss: 2.0784605741500854

Epoch: 6| Step: 9
Training loss: 2.1167407035827637
Validation loss: 2.0714983542760215

Epoch: 6| Step: 10
Training loss: 2.0227348804473877
Validation loss: 2.0832452376683555

Epoch: 6| Step: 11
Training loss: 2.275982618331909
Validation loss: 2.0847346782684326

Epoch: 6| Step: 12
Training loss: 2.709101676940918
Validation loss: 2.0998896757761636

Epoch: 6| Step: 13
Training loss: 1.8585638999938965
Validation loss: 2.0839126904805503

Epoch: 149| Step: 0
Training loss: 2.653806447982788
Validation loss: 2.0838804244995117

Epoch: 6| Step: 1
Training loss: 2.039306640625
Validation loss: 2.0840657353401184

Epoch: 6| Step: 2
Training loss: 2.313215732574463
Validation loss: 2.0773620009422302

Epoch: 6| Step: 3
Training loss: 2.0491271018981934
Validation loss: 2.0647964676221213

Epoch: 6| Step: 4
Training loss: 2.098112106323242
Validation loss: 2.0607968171437583

Epoch: 6| Step: 5
Training loss: 2.052542209625244
Validation loss: 2.06716787815094

Epoch: 6| Step: 6
Training loss: 1.713902473449707
Validation loss: 2.0559513767560325

Epoch: 6| Step: 7
Training loss: 2.575425148010254
Validation loss: 2.044297715028127

Epoch: 6| Step: 8
Training loss: 1.906477928161621
Validation loss: 2.059935510158539

Epoch: 6| Step: 9
Training loss: 2.0559020042419434
Validation loss: 2.0535478989283242

Epoch: 6| Step: 10
Training loss: 1.427926778793335
Validation loss: 2.0473073522249856

Epoch: 6| Step: 11
Training loss: 2.1922006607055664
Validation loss: 2.049076557159424

Epoch: 6| Step: 12
Training loss: 2.208580493927002
Validation loss: 2.0483714739481607

Epoch: 6| Step: 13
Training loss: 1.2426316738128662
Validation loss: 2.0568955143292746

Epoch: 150| Step: 0
Training loss: 1.7242441177368164
Validation loss: 2.0587334632873535

Epoch: 6| Step: 1
Training loss: 2.239163875579834
Validation loss: 2.056511561075846

Epoch: 6| Step: 2
Training loss: 1.4706743955612183
Validation loss: 2.066522538661957

Epoch: 6| Step: 3
Training loss: 2.185399293899536
Validation loss: 2.0676666498184204

Epoch: 6| Step: 4
Training loss: 1.9645713567733765
Validation loss: 2.07074111700058

Epoch: 6| Step: 5
Training loss: 1.7367236614227295
Validation loss: 2.0740809639294944

Epoch: 6| Step: 6
Training loss: 1.9576802253723145
Validation loss: 2.0718515316645303

Epoch: 6| Step: 7
Training loss: 1.9235095977783203
Validation loss: 2.0845144987106323

Epoch: 6| Step: 8
Training loss: 2.629570722579956
Validation loss: 2.0831879377365112

Epoch: 6| Step: 9
Training loss: 1.9774742126464844
Validation loss: 2.11055459578832

Epoch: 6| Step: 10
Training loss: 1.9412035942077637
Validation loss: 2.0941256483395896

Epoch: 6| Step: 11
Training loss: 1.9372289180755615
Validation loss: 2.0979292591412864

Epoch: 6| Step: 12
Training loss: 2.1174793243408203
Validation loss: 2.099732995033264

Epoch: 6| Step: 13
Training loss: 2.494687795639038
Validation loss: 2.1108784079551697

Epoch: 151| Step: 0
Training loss: 2.175536632537842
Validation loss: 2.0955310066541037

Epoch: 6| Step: 1
Training loss: 2.555771827697754
Validation loss: 2.0988096396128335

Epoch: 6| Step: 2
Training loss: 1.2938703298568726
Validation loss: 2.0817549427350364

Epoch: 6| Step: 3
Training loss: 2.69248628616333
Validation loss: 2.0636968413988748

Epoch: 6| Step: 4
Training loss: 2.139251708984375
Validation loss: 2.0658533175786338

Epoch: 6| Step: 5
Training loss: 1.9390709400177002
Validation loss: 2.0554293394088745

Epoch: 6| Step: 6
Training loss: 1.7743592262268066
Validation loss: 2.0474839011828103

Epoch: 6| Step: 7
Training loss: 2.0408551692962646
Validation loss: 2.046623627344767

Epoch: 6| Step: 8
Training loss: 1.9554122686386108
Validation loss: 2.0519665082295737

Epoch: 6| Step: 9
Training loss: 2.007948160171509
Validation loss: 2.040440400441488

Epoch: 6| Step: 10
Training loss: 1.5567853450775146
Validation loss: 2.0621129274368286

Epoch: 6| Step: 11
Training loss: 2.0911059379577637
Validation loss: 2.0568808714548745

Epoch: 6| Step: 12
Training loss: 2.1326146125793457
Validation loss: 2.0551236073176065

Epoch: 6| Step: 13
Training loss: 2.1172170639038086
Validation loss: 2.0627950628598533

Epoch: 152| Step: 0
Training loss: 1.96778404712677
Validation loss: 2.044722020626068

Epoch: 6| Step: 1
Training loss: 1.817491054534912
Validation loss: 2.0500497817993164

Epoch: 6| Step: 2
Training loss: 2.3515777587890625
Validation loss: 2.054736077785492

Epoch: 6| Step: 3
Training loss: 1.8636713027954102
Validation loss: 2.0608109633127847

Epoch: 6| Step: 4
Training loss: 2.0728759765625
Validation loss: 2.0794111490249634

Epoch: 6| Step: 5
Training loss: 1.3998384475708008
Validation loss: 2.0817970633506775

Epoch: 6| Step: 6
Training loss: 2.185892105102539
Validation loss: 2.0893182357152305

Epoch: 6| Step: 7
Training loss: 1.663069725036621
Validation loss: 2.0847042997678122

Epoch: 6| Step: 8
Training loss: 2.272064685821533
Validation loss: 2.093529542287191

Epoch: 6| Step: 9
Training loss: 1.8780403137207031
Validation loss: 2.0907036860783896

Epoch: 6| Step: 10
Training loss: 1.7256908416748047
Validation loss: 2.0983322858810425

Epoch: 6| Step: 11
Training loss: 2.0350747108459473
Validation loss: 2.0823426445325217

Epoch: 6| Step: 12
Training loss: 2.445404052734375
Validation loss: 2.070497155189514

Epoch: 6| Step: 13
Training loss: 2.6234560012817383
Validation loss: 2.0706619024276733

Epoch: 153| Step: 0
Training loss: 1.613572597503662
Validation loss: 2.079218069712321

Epoch: 6| Step: 1
Training loss: 1.289873719215393
Validation loss: 2.074236750602722

Epoch: 6| Step: 2
Training loss: 1.7439892292022705
Validation loss: 2.0566349426905313

Epoch: 6| Step: 3
Training loss: 2.114205837249756
Validation loss: 2.0769147674242654

Epoch: 6| Step: 4
Training loss: 2.3454368114471436
Validation loss: 2.082395156224569

Epoch: 6| Step: 5
Training loss: 2.345172882080078
Validation loss: 2.073715845743815

Epoch: 6| Step: 6
Training loss: 1.7612292766571045
Validation loss: 2.078619917233785

Epoch: 6| Step: 7
Training loss: 2.4076552391052246
Validation loss: 2.072283983230591

Epoch: 6| Step: 8
Training loss: 2.376159191131592
Validation loss: 2.077376425266266

Epoch: 6| Step: 9
Training loss: 2.2562499046325684
Validation loss: 2.0625080664952598

Epoch: 6| Step: 10
Training loss: 1.549001693725586
Validation loss: 2.077709118525187

Epoch: 6| Step: 11
Training loss: 1.896942377090454
Validation loss: 2.076433459917704

Epoch: 6| Step: 12
Training loss: 2.12762451171875
Validation loss: 2.066828509171804

Epoch: 6| Step: 13
Training loss: 2.1099631786346436
Validation loss: 2.069502353668213

Epoch: 154| Step: 0
Training loss: 2.12967586517334
Validation loss: 2.0844064354896545

Epoch: 6| Step: 1
Training loss: 1.7187049388885498
Validation loss: 2.080609838167826

Epoch: 6| Step: 2
Training loss: 1.7177239656448364
Validation loss: 2.0754265189170837

Epoch: 6| Step: 3
Training loss: 2.2614095211029053
Validation loss: 2.084715406099955

Epoch: 6| Step: 4
Training loss: 2.3845362663269043
Validation loss: 2.0866836309432983

Epoch: 6| Step: 5
Training loss: 1.9319219589233398
Validation loss: 2.0837367177009583

Epoch: 6| Step: 6
Training loss: 2.494673490524292
Validation loss: 2.06194007396698

Epoch: 6| Step: 7
Training loss: 1.6539273262023926
Validation loss: 2.080235540866852

Epoch: 6| Step: 8
Training loss: 2.188924789428711
Validation loss: 2.082554598649343

Epoch: 6| Step: 9
Training loss: 1.6364396810531616
Validation loss: 2.0683691700299582

Epoch: 6| Step: 10
Training loss: 2.272885322570801
Validation loss: 2.07450407743454

Epoch: 6| Step: 11
Training loss: 2.0072317123413086
Validation loss: 2.07206396261851

Epoch: 6| Step: 12
Training loss: 1.7708802223205566
Validation loss: 2.0562015573183694

Epoch: 6| Step: 13
Training loss: 1.7653172016143799
Validation loss: 2.0782056053479514

Epoch: 155| Step: 0
Training loss: 1.850343942642212
Validation loss: 2.0667046109835305

Epoch: 6| Step: 1
Training loss: 3.033388137817383
Validation loss: 2.0654228727022805

Epoch: 6| Step: 2
Training loss: 2.0050621032714844
Validation loss: 2.069323201974233

Epoch: 6| Step: 3
Training loss: 2.190758228302002
Validation loss: 2.0668639739354453

Epoch: 6| Step: 4
Training loss: 2.18558931350708
Validation loss: 2.0634842912356057

Epoch: 6| Step: 5
Training loss: 1.971414566040039
Validation loss: 2.077899932861328

Epoch: 6| Step: 6
Training loss: 1.8075103759765625
Validation loss: 2.079214930534363

Epoch: 6| Step: 7
Training loss: 1.9316824674606323
Validation loss: 2.081207195917765

Epoch: 6| Step: 8
Training loss: 2.4764509201049805
Validation loss: 2.0911249121030173

Epoch: 6| Step: 9
Training loss: 2.2662148475646973
Validation loss: 2.090764840443929

Epoch: 6| Step: 10
Training loss: 1.344501256942749
Validation loss: 2.086914896965027

Epoch: 6| Step: 11
Training loss: 1.8630435466766357
Validation loss: 2.0988977352778115

Epoch: 6| Step: 12
Training loss: 1.6929103136062622
Validation loss: 2.111504316329956

Epoch: 6| Step: 13
Training loss: 1.7054779529571533
Validation loss: 2.1049320697784424

Epoch: 156| Step: 0
Training loss: 2.3523237705230713
Validation loss: 2.1147982478141785

Epoch: 6| Step: 1
Training loss: 2.071697235107422
Validation loss: 2.100937763849894

Epoch: 6| Step: 2
Training loss: 2.1316113471984863
Validation loss: 2.0936765670776367

Epoch: 6| Step: 3
Training loss: 2.1389219760894775
Validation loss: 2.0833083987236023

Epoch: 6| Step: 4
Training loss: 1.7112321853637695
Validation loss: 2.087287127971649

Epoch: 6| Step: 5
Training loss: 2.2372560501098633
Validation loss: 2.0834661523501077

Epoch: 6| Step: 6
Training loss: 1.7785857915878296
Validation loss: 2.0679288506507874

Epoch: 6| Step: 7
Training loss: 2.0423941612243652
Validation loss: 2.0735591053962708

Epoch: 6| Step: 8
Training loss: 1.7733674049377441
Validation loss: 2.071617583433787

Epoch: 6| Step: 9
Training loss: 1.6651229858398438
Validation loss: 2.08615505695343

Epoch: 6| Step: 10
Training loss: 1.9450809955596924
Validation loss: 2.088479002316793

Epoch: 6| Step: 11
Training loss: 2.182156801223755
Validation loss: 2.084197759628296

Epoch: 6| Step: 12
Training loss: 2.305490016937256
Validation loss: 2.0942984223365784

Epoch: 6| Step: 13
Training loss: 1.8225127458572388
Validation loss: 2.0944848457972207

Epoch: 157| Step: 0
Training loss: 1.2851587533950806
Validation loss: 2.088506758213043

Epoch: 6| Step: 1
Training loss: 1.9587253332138062
Validation loss: 2.083681563536326

Epoch: 6| Step: 2
Training loss: 1.7772454023361206
Validation loss: 2.0916597843170166

Epoch: 6| Step: 3
Training loss: 1.9067766666412354
Validation loss: 2.0777421394983926

Epoch: 6| Step: 4
Training loss: 1.5373954772949219
Validation loss: 2.0833047231038413

Epoch: 6| Step: 5
Training loss: 1.9380475282669067
Validation loss: 2.075922727584839

Epoch: 6| Step: 6
Training loss: 1.3448151350021362
Validation loss: 2.0831212798754373

Epoch: 6| Step: 7
Training loss: 2.4191536903381348
Validation loss: 2.089233875274658

Epoch: 6| Step: 8
Training loss: 1.615649700164795
Validation loss: 2.0740298430124917

Epoch: 6| Step: 9
Training loss: 2.805049419403076
Validation loss: 2.08906227350235

Epoch: 6| Step: 10
Training loss: 2.377350091934204
Validation loss: 2.072454273700714

Epoch: 6| Step: 11
Training loss: 2.373582363128662
Validation loss: 2.0863002141316733

Epoch: 6| Step: 12
Training loss: 2.5154104232788086
Validation loss: 2.090646743774414

Epoch: 6| Step: 13
Training loss: 2.0222830772399902
Validation loss: 2.082959751288096

Epoch: 158| Step: 0
Training loss: 2.0933566093444824
Validation loss: 2.091006954511007

Epoch: 6| Step: 1
Training loss: 1.8453397750854492
Validation loss: 2.083819309870402

Epoch: 6| Step: 2
Training loss: 2.4167795181274414
Validation loss: 2.0834940473238626

Epoch: 6| Step: 3
Training loss: 2.3630871772766113
Validation loss: 2.069315950075785

Epoch: 6| Step: 4
Training loss: 1.9570693969726562
Validation loss: 2.0733813047409058

Epoch: 6| Step: 5
Training loss: 1.5950379371643066
Validation loss: 2.0798140168190002

Epoch: 6| Step: 6
Training loss: 2.095151901245117
Validation loss: 2.082585096359253

Epoch: 6| Step: 7
Training loss: 1.7121834754943848
Validation loss: 2.0674069921175637

Epoch: 6| Step: 8
Training loss: 1.8381657600402832
Validation loss: 2.0883625547091165

Epoch: 6| Step: 9
Training loss: 1.8952178955078125
Validation loss: 2.082528293132782

Epoch: 6| Step: 10
Training loss: 2.4773166179656982
Validation loss: 2.0958522955576577

Epoch: 6| Step: 11
Training loss: 1.7119218111038208
Validation loss: 2.0789188941319785

Epoch: 6| Step: 12
Training loss: 2.1059441566467285
Validation loss: 2.0967016418774924

Epoch: 6| Step: 13
Training loss: 1.6705613136291504
Validation loss: 2.0859111547470093

Epoch: 159| Step: 0
Training loss: 1.5793449878692627
Validation loss: 2.10085521141688

Epoch: 6| Step: 1
Training loss: 1.7634570598602295
Validation loss: 2.0948827664057412

Epoch: 6| Step: 2
Training loss: 1.8820827007293701
Validation loss: 2.0970530112584433

Epoch: 6| Step: 3
Training loss: 2.0583972930908203
Validation loss: 2.0975935459136963

Epoch: 6| Step: 4
Training loss: 2.484032154083252
Validation loss: 2.098706841468811

Epoch: 6| Step: 5
Training loss: 2.873812198638916
Validation loss: 2.085426151752472

Epoch: 6| Step: 6
Training loss: 2.4260482788085938
Validation loss: 2.1028720140457153

Epoch: 6| Step: 7
Training loss: 1.616469383239746
Validation loss: 2.077060957749685

Epoch: 6| Step: 8
Training loss: 1.5915324687957764
Validation loss: 2.081894119580587

Epoch: 6| Step: 9
Training loss: 2.2516164779663086
Validation loss: 2.0704104900360107

Epoch: 6| Step: 10
Training loss: 2.576094627380371
Validation loss: 2.0811463991800943

Epoch: 6| Step: 11
Training loss: 1.6596813201904297
Validation loss: 2.065450966358185

Epoch: 6| Step: 12
Training loss: 1.6728951930999756
Validation loss: 2.0809097488721213

Epoch: 6| Step: 13
Training loss: 1.4988465309143066
Validation loss: 2.071623663107554

Epoch: 160| Step: 0
Training loss: 2.2282328605651855
Validation loss: 2.0827337900797525

Epoch: 6| Step: 1
Training loss: 1.964024543762207
Validation loss: 2.083483954270681

Epoch: 6| Step: 2
Training loss: 1.406557321548462
Validation loss: 2.084471801916758

Epoch: 6| Step: 3
Training loss: 1.704950213432312
Validation loss: 2.083072324593862

Epoch: 6| Step: 4
Training loss: 1.758751392364502
Validation loss: 2.0945340991020203

Epoch: 6| Step: 5
Training loss: 2.0931921005249023
Validation loss: 2.0860366821289062

Epoch: 6| Step: 6
Training loss: 2.0996203422546387
Validation loss: 2.084998528162638

Epoch: 6| Step: 7
Training loss: 2.194087266921997
Validation loss: 2.0825746854146323

Epoch: 6| Step: 8
Training loss: 2.641749382019043
Validation loss: 2.0959444443384805

Epoch: 6| Step: 9
Training loss: 2.246448516845703
Validation loss: 2.089264730612437

Epoch: 6| Step: 10
Training loss: 1.4741995334625244
Validation loss: 2.0966915686925254

Epoch: 6| Step: 11
Training loss: 1.8495783805847168
Validation loss: 2.0890328685442605

Epoch: 6| Step: 12
Training loss: 1.8862965106964111
Validation loss: 2.0969409942626953

Epoch: 6| Step: 13
Training loss: 2.3015189170837402
Validation loss: 2.0992202758789062

Epoch: 161| Step: 0
Training loss: 2.2337636947631836
Validation loss: 2.096619645754496

Epoch: 6| Step: 1
Training loss: 1.9599279165267944
Validation loss: 2.090333124001821

Epoch: 6| Step: 2
Training loss: 2.0063633918762207
Validation loss: 2.0880041321118674

Epoch: 6| Step: 3
Training loss: 1.6052217483520508
Validation loss: 2.0751766165097556

Epoch: 6| Step: 4
Training loss: 1.7939374446868896
Validation loss: 2.080526073773702

Epoch: 6| Step: 5
Training loss: 1.8328430652618408
Validation loss: 2.073768377304077

Epoch: 6| Step: 6
Training loss: 2.2558369636535645
Validation loss: 2.0905954440434775

Epoch: 6| Step: 7
Training loss: 2.57149076461792
Validation loss: 2.083655834197998

Epoch: 6| Step: 8
Training loss: 2.744122266769409
Validation loss: 2.101283629735311

Epoch: 6| Step: 9
Training loss: 2.106388807296753
Validation loss: 2.0803611278533936

Epoch: 6| Step: 10
Training loss: 1.323617935180664
Validation loss: 2.0851022402445474

Epoch: 6| Step: 11
Training loss: 1.8226544857025146
Validation loss: 2.0901306668917337

Epoch: 6| Step: 12
Training loss: 1.825738787651062
Validation loss: 2.076520542303721

Epoch: 6| Step: 13
Training loss: 1.883017897605896
Validation loss: 2.0783918301264444

Epoch: 162| Step: 0
Training loss: 2.1176905632019043
Validation loss: 2.0797747373580933

Epoch: 6| Step: 1
Training loss: 2.163827419281006
Validation loss: 2.085022727648417

Epoch: 6| Step: 2
Training loss: 2.30002760887146
Validation loss: 2.0774043599764505

Epoch: 6| Step: 3
Training loss: 1.4957275390625
Validation loss: 2.081145167350769

Epoch: 6| Step: 4
Training loss: 2.0716443061828613
Validation loss: 2.0610723296801248

Epoch: 6| Step: 5
Training loss: 2.421083927154541
Validation loss: 2.0622920989990234

Epoch: 6| Step: 6
Training loss: 1.1540470123291016
Validation loss: 2.062104801336924

Epoch: 6| Step: 7
Training loss: 1.7558437585830688
Validation loss: 2.0582475066184998

Epoch: 6| Step: 8
Training loss: 2.2384352684020996
Validation loss: 2.069619874159495

Epoch: 6| Step: 9
Training loss: 2.0163867473602295
Validation loss: 2.0519750515619912

Epoch: 6| Step: 10
Training loss: 2.3292417526245117
Validation loss: 2.0500019788742065

Epoch: 6| Step: 11
Training loss: 2.318667411804199
Validation loss: 2.0523847142855325

Epoch: 6| Step: 12
Training loss: 1.7232768535614014
Validation loss: 2.0562897523244223

Epoch: 6| Step: 13
Training loss: 1.9262851476669312
Validation loss: 2.062801460425059

Epoch: 163| Step: 0
Training loss: 1.7422080039978027
Validation loss: 2.0640549063682556

Epoch: 6| Step: 1
Training loss: 2.4364590644836426
Validation loss: 2.0745142102241516

Epoch: 6| Step: 2
Training loss: 1.2875146865844727
Validation loss: 2.0521849989891052

Epoch: 6| Step: 3
Training loss: 1.406501293182373
Validation loss: 2.0558404326438904

Epoch: 6| Step: 4
Training loss: 2.1555771827697754
Validation loss: 2.0686551133791604

Epoch: 6| Step: 5
Training loss: 2.0231261253356934
Validation loss: 2.079035838445028

Epoch: 6| Step: 6
Training loss: 1.9359607696533203
Validation loss: 2.081621785958608

Epoch: 6| Step: 7
Training loss: 2.099623203277588
Validation loss: 2.083559254805247

Epoch: 6| Step: 8
Training loss: 2.4977736473083496
Validation loss: 2.0871211290359497

Epoch: 6| Step: 9
Training loss: 1.8028035163879395
Validation loss: 2.0806984504063926

Epoch: 6| Step: 10
Training loss: 2.027350425720215
Validation loss: 2.0838728745778403

Epoch: 6| Step: 11
Training loss: 2.1990201473236084
Validation loss: 2.0797932147979736

Epoch: 6| Step: 12
Training loss: 2.2349984645843506
Validation loss: 2.083798587322235

Epoch: 6| Step: 13
Training loss: 1.9543471336364746
Validation loss: 2.089076578617096

Epoch: 164| Step: 0
Training loss: 1.4416192770004272
Validation loss: 2.079720457394918

Epoch: 6| Step: 1
Training loss: 2.9760279655456543
Validation loss: 2.0766186316808066

Epoch: 6| Step: 2
Training loss: 2.2512426376342773
Validation loss: 2.080260177453359

Epoch: 6| Step: 3
Training loss: 2.0652801990509033
Validation loss: 2.0790260235468545

Epoch: 6| Step: 4
Training loss: 1.862142562866211
Validation loss: 2.084981540838877

Epoch: 6| Step: 5
Training loss: 2.4040284156799316
Validation loss: 2.080510397752126

Epoch: 6| Step: 6
Training loss: 1.8894734382629395
Validation loss: 2.0885913570721946

Epoch: 6| Step: 7
Training loss: 2.149745225906372
Validation loss: 2.084182858467102

Epoch: 6| Step: 8
Training loss: 1.7090789079666138
Validation loss: 2.0900381207466125

Epoch: 6| Step: 9
Training loss: 1.8614730834960938
Validation loss: 2.0992432832717896

Epoch: 6| Step: 10
Training loss: 1.497187614440918
Validation loss: 2.0937681794166565

Epoch: 6| Step: 11
Training loss: 1.677263617515564
Validation loss: 2.0975432991981506

Epoch: 6| Step: 12
Training loss: 1.9339250326156616
Validation loss: 2.0972710053126016

Epoch: 6| Step: 13
Training loss: 1.9932401180267334
Validation loss: 2.0996958017349243

Epoch: 165| Step: 0
Training loss: 2.2846851348876953
Validation loss: 2.08966992298762

Epoch: 6| Step: 1
Training loss: 1.7859227657318115
Validation loss: 2.1083921591440835

Epoch: 6| Step: 2
Training loss: 2.353823661804199
Validation loss: 2.112633983294169

Epoch: 6| Step: 3
Training loss: 1.5038175582885742
Validation loss: 2.115869700908661

Epoch: 6| Step: 4
Training loss: 1.7747292518615723
Validation loss: 2.120327611764272

Epoch: 6| Step: 5
Training loss: 1.9234565496444702
Validation loss: 2.0962345004081726

Epoch: 6| Step: 6
Training loss: 2.1926159858703613
Validation loss: 2.0900721549987793

Epoch: 6| Step: 7
Training loss: 1.9044291973114014
Validation loss: 2.097074031829834

Epoch: 6| Step: 8
Training loss: 1.7882544994354248
Validation loss: 2.083848317464193

Epoch: 6| Step: 9
Training loss: 2.3733348846435547
Validation loss: 2.0881426334381104

Epoch: 6| Step: 10
Training loss: 2.1815662384033203
Validation loss: 2.076452314853668

Epoch: 6| Step: 11
Training loss: 1.9399006366729736
Validation loss: 2.0786238511403403

Epoch: 6| Step: 12
Training loss: 1.7909547090530396
Validation loss: 2.0787094831466675

Epoch: 6| Step: 13
Training loss: 2.2429070472717285
Validation loss: 2.066881696383158

Epoch: 166| Step: 0
Training loss: 2.3108620643615723
Validation loss: 2.0745686690012612

Epoch: 6| Step: 1
Training loss: 2.147975444793701
Validation loss: 2.0712350010871887

Epoch: 6| Step: 2
Training loss: 2.1695823669433594
Validation loss: 2.088805079460144

Epoch: 6| Step: 3
Training loss: 2.364692449569702
Validation loss: 2.0826448798179626

Epoch: 6| Step: 4
Training loss: 1.2796645164489746
Validation loss: 2.091695328553518

Epoch: 6| Step: 5
Training loss: 1.9469330310821533
Validation loss: 2.083772281805674

Epoch: 6| Step: 6
Training loss: 1.7196202278137207
Validation loss: 2.094464441140493

Epoch: 6| Step: 7
Training loss: 1.6394668817520142
Validation loss: 2.0873391230901084

Epoch: 6| Step: 8
Training loss: 2.275601863861084
Validation loss: 2.0815799633661904

Epoch: 6| Step: 9
Training loss: 2.2537875175476074
Validation loss: 2.0833680828412375

Epoch: 6| Step: 10
Training loss: 2.1418991088867188
Validation loss: 2.088068743546804

Epoch: 6| Step: 11
Training loss: 1.8871492147445679
Validation loss: 2.079540769259135

Epoch: 6| Step: 12
Training loss: 1.843310832977295
Validation loss: 2.086624026298523

Epoch: 6| Step: 13
Training loss: 2.2287402153015137
Validation loss: 2.081546902656555

Epoch: 167| Step: 0
Training loss: 2.035809278488159
Validation loss: 2.081786274909973

Epoch: 6| Step: 1
Training loss: 1.712224006652832
Validation loss: 2.067251741886139

Epoch: 6| Step: 2
Training loss: 2.316649913787842
Validation loss: 2.078630030155182

Epoch: 6| Step: 3
Training loss: 1.810333490371704
Validation loss: 2.0777044693628945

Epoch: 6| Step: 4
Training loss: 2.0144405364990234
Validation loss: 2.098679701487223

Epoch: 6| Step: 5
Training loss: 1.9069749116897583
Validation loss: 2.0789852937062583

Epoch: 6| Step: 6
Training loss: 1.935721516609192
Validation loss: 2.084308087825775

Epoch: 6| Step: 7
Training loss: 1.9954732656478882
Validation loss: 2.091329018274943

Epoch: 6| Step: 8
Training loss: 1.9976506233215332
Validation loss: 2.0995176633199057

Epoch: 6| Step: 9
Training loss: 2.4792613983154297
Validation loss: 2.0975067019462585

Epoch: 6| Step: 10
Training loss: 1.2138570547103882
Validation loss: 2.1158270637194314

Epoch: 6| Step: 11
Training loss: 1.6196370124816895
Validation loss: 2.097149988015493

Epoch: 6| Step: 12
Training loss: 2.569551944732666
Validation loss: 2.0925657947858176

Epoch: 6| Step: 13
Training loss: 2.0674848556518555
Validation loss: 2.0817507902781167

Epoch: 168| Step: 0
Training loss: 2.016540288925171
Validation loss: 2.0743155082066855

Epoch: 6| Step: 1
Training loss: 1.8105016946792603
Validation loss: 2.078030010064443

Epoch: 6| Step: 2
Training loss: 2.4312214851379395
Validation loss: 2.088771382967631

Epoch: 6| Step: 3
Training loss: 1.4924979209899902
Validation loss: 2.1041656335194907

Epoch: 6| Step: 4
Training loss: 2.9814915657043457
Validation loss: 2.0889969865481057

Epoch: 6| Step: 5
Training loss: 2.2180023193359375
Validation loss: 2.0831984877586365

Epoch: 6| Step: 6
Training loss: 1.0646456480026245
Validation loss: 2.0840632915496826

Epoch: 6| Step: 7
Training loss: 1.462491750717163
Validation loss: 2.110839227835337

Epoch: 6| Step: 8
Training loss: 2.736927032470703
Validation loss: 2.092115839322408

Epoch: 6| Step: 9
Training loss: 1.7953999042510986
Validation loss: 2.1007710893948874

Epoch: 6| Step: 10
Training loss: 1.780083179473877
Validation loss: 2.0895341833432517

Epoch: 6| Step: 11
Training loss: 1.9578911066055298
Validation loss: 2.0922279755274453

Epoch: 6| Step: 12
Training loss: 1.5938106775283813
Validation loss: 2.087725261847178

Epoch: 6| Step: 13
Training loss: 2.4165866374969482
Validation loss: 2.1002124349276223

Epoch: 169| Step: 0
Training loss: 2.2020044326782227
Validation loss: 2.089589516321818

Epoch: 6| Step: 1
Training loss: 1.9404653310775757
Validation loss: 2.086771627267202

Epoch: 6| Step: 2
Training loss: 1.5445506572723389
Validation loss: 2.0817328294118247

Epoch: 6| Step: 3
Training loss: 1.991947889328003
Validation loss: 2.0894430677096048

Epoch: 6| Step: 4
Training loss: 2.368281364440918
Validation loss: 2.0770566860834756

Epoch: 6| Step: 5
Training loss: 2.1387505531311035
Validation loss: 2.1021731893221536

Epoch: 6| Step: 6
Training loss: 1.6961233615875244
Validation loss: 2.1006446878115335

Epoch: 6| Step: 7
Training loss: 2.182809352874756
Validation loss: 2.097007075945536

Epoch: 6| Step: 8
Training loss: 1.4246437549591064
Validation loss: 2.1052048206329346

Epoch: 6| Step: 9
Training loss: 1.8646025657653809
Validation loss: 2.0717668533325195

Epoch: 6| Step: 10
Training loss: 2.7254955768585205
Validation loss: 2.1122265656789145

Epoch: 6| Step: 11
Training loss: 2.147897481918335
Validation loss: 2.0810504158337912

Epoch: 6| Step: 12
Training loss: 2.000241279602051
Validation loss: 2.1060111125310264

Epoch: 6| Step: 13
Training loss: 1.564474105834961
Validation loss: 2.10235466559728

Epoch: 170| Step: 0
Training loss: 2.1461286544799805
Validation loss: 2.097198784351349

Epoch: 6| Step: 1
Training loss: 1.8472193479537964
Validation loss: 2.095997631549835

Epoch: 6| Step: 2
Training loss: 1.9010024070739746
Validation loss: 2.095439334710439

Epoch: 6| Step: 3
Training loss: 1.7898515462875366
Validation loss: 2.0892439484596252

Epoch: 6| Step: 4
Training loss: 2.1853246688842773
Validation loss: 2.082657297452291

Epoch: 6| Step: 5
Training loss: 2.5417375564575195
Validation loss: 2.090950687726339

Epoch: 6| Step: 6
Training loss: 1.7130866050720215
Validation loss: 2.0809786121050515

Epoch: 6| Step: 7
Training loss: 2.0920021533966064
Validation loss: 2.0914388497670493

Epoch: 6| Step: 8
Training loss: 1.564903736114502
Validation loss: 2.0904990434646606

Epoch: 6| Step: 9
Training loss: 2.130702495574951
Validation loss: 2.092221736907959

Epoch: 6| Step: 10
Training loss: 1.8077222108840942
Validation loss: 2.0918737649917603

Epoch: 6| Step: 11
Training loss: 2.3488874435424805
Validation loss: 2.08514142036438

Epoch: 6| Step: 12
Training loss: 1.6887829303741455
Validation loss: 2.086829662322998

Epoch: 6| Step: 13
Training loss: 1.8316683769226074
Validation loss: 2.0966205398241677

Epoch: 171| Step: 0
Training loss: 1.9963983297348022
Validation loss: 2.0971726179122925

Epoch: 6| Step: 1
Training loss: 1.867342233657837
Validation loss: 2.093258480230967

Epoch: 6| Step: 2
Training loss: 1.958824872970581
Validation loss: 2.0978450179100037

Epoch: 6| Step: 3
Training loss: 2.323535919189453
Validation loss: 2.098028242588043

Epoch: 6| Step: 4
Training loss: 1.8568439483642578
Validation loss: 2.091141720612844

Epoch: 6| Step: 5
Training loss: 2.6463358402252197
Validation loss: 2.0859354734420776

Epoch: 6| Step: 6
Training loss: 2.182065486907959
Validation loss: 2.101754665374756

Epoch: 6| Step: 7
Training loss: 1.3051493167877197
Validation loss: 2.1071112751960754

Epoch: 6| Step: 8
Training loss: 2.1816532611846924
Validation loss: 2.0911590655644736

Epoch: 6| Step: 9
Training loss: 1.8455655574798584
Validation loss: 2.0988797148068747

Epoch: 6| Step: 10
Training loss: 1.5086405277252197
Validation loss: 2.094115138053894

Epoch: 6| Step: 11
Training loss: 1.969810962677002
Validation loss: 2.089030901590983

Epoch: 6| Step: 12
Training loss: 2.0407795906066895
Validation loss: 2.084811548391978

Epoch: 6| Step: 13
Training loss: 2.0788872241973877
Validation loss: 2.066659986972809

Epoch: 172| Step: 0
Training loss: 1.4964377880096436
Validation loss: 2.077544113000234

Epoch: 6| Step: 1
Training loss: 1.7472732067108154
Validation loss: 2.0706071853637695

Epoch: 6| Step: 2
Training loss: 2.3529324531555176
Validation loss: 2.090735077857971

Epoch: 6| Step: 3
Training loss: 2.3310234546661377
Validation loss: 2.0758502086003623

Epoch: 6| Step: 4
Training loss: 2.4211630821228027
Validation loss: 2.0802703499794006

Epoch: 6| Step: 5
Training loss: 1.4815607070922852
Validation loss: 2.083475112915039

Epoch: 6| Step: 6
Training loss: 1.5757524967193604
Validation loss: 2.0804601510365806

Epoch: 6| Step: 7
Training loss: 2.220672369003296
Validation loss: 2.081327497959137

Epoch: 6| Step: 8
Training loss: 1.873561143875122
Validation loss: 2.0721359650293985

Epoch: 6| Step: 9
Training loss: 2.1577110290527344
Validation loss: 2.070929527282715

Epoch: 6| Step: 10
Training loss: 2.5706734657287598
Validation loss: 2.0746075908342996

Epoch: 6| Step: 11
Training loss: 1.9559680223464966
Validation loss: 2.0819934209187827

Epoch: 6| Step: 12
Training loss: 2.0236153602600098
Validation loss: 2.0768609245618186

Epoch: 6| Step: 13
Training loss: 2.1002821922302246
Validation loss: 2.082430680592855

Epoch: 173| Step: 0
Training loss: 1.8750190734863281
Validation loss: 2.0727165937423706

Epoch: 6| Step: 1
Training loss: 1.3146741390228271
Validation loss: 2.091961999734243

Epoch: 6| Step: 2
Training loss: 1.6150636672973633
Validation loss: 2.064558188120524

Epoch: 6| Step: 3
Training loss: 2.270878314971924
Validation loss: 2.0903184016545615

Epoch: 6| Step: 4
Training loss: 1.8375605344772339
Validation loss: 2.084549347559611

Epoch: 6| Step: 5
Training loss: 2.2354021072387695
Validation loss: 2.0860606829325357

Epoch: 6| Step: 6
Training loss: 2.459812879562378
Validation loss: 2.1017536322275796

Epoch: 6| Step: 7
Training loss: 1.961580514907837
Validation loss: 2.095648765563965

Epoch: 6| Step: 8
Training loss: 2.382761001586914
Validation loss: 2.0989909966786704

Epoch: 6| Step: 9
Training loss: 2.3368477821350098
Validation loss: 2.0927542050679526

Epoch: 6| Step: 10
Training loss: 1.942427396774292
Validation loss: 2.0876208345095315

Epoch: 6| Step: 11
Training loss: 1.693365216255188
Validation loss: 2.092191219329834

Epoch: 6| Step: 12
Training loss: 2.245849132537842
Validation loss: 2.0776909589767456

Epoch: 6| Step: 13
Training loss: 1.7575758695602417
Validation loss: 2.091133793195089

Epoch: 174| Step: 0
Training loss: 2.067113161087036
Validation loss: 2.0881218115488687

Epoch: 6| Step: 1
Training loss: 2.159144878387451
Validation loss: 2.0894723931948342

Epoch: 6| Step: 2
Training loss: 1.6711723804473877
Validation loss: 2.085437059402466

Epoch: 6| Step: 3
Training loss: 1.8226854801177979
Validation loss: 2.085840900739034

Epoch: 6| Step: 4
Training loss: 1.5530128479003906
Validation loss: 2.070653736591339

Epoch: 6| Step: 5
Training loss: 1.9746906757354736
Validation loss: 2.0706409017244973

Epoch: 6| Step: 6
Training loss: 1.9651696681976318
Validation loss: 2.0797935326894126

Epoch: 6| Step: 7
Training loss: 1.9957067966461182
Validation loss: 2.0782318115234375

Epoch: 6| Step: 8
Training loss: 1.4109563827514648
Validation loss: 2.091082195440928

Epoch: 6| Step: 9
Training loss: 2.0730695724487305
Validation loss: 2.107046047846476

Epoch: 6| Step: 10
Training loss: 2.6606945991516113
Validation loss: 2.104522466659546

Epoch: 6| Step: 11
Training loss: 1.8806381225585938
Validation loss: 2.0989142258961997

Epoch: 6| Step: 12
Training loss: 2.420950174331665
Validation loss: 2.1342007716496787

Epoch: 6| Step: 13
Training loss: 2.166478157043457
Validation loss: 2.1382559339205423

Epoch: 175| Step: 0
Training loss: 2.374427318572998
Validation loss: 2.1421772638956704

Epoch: 6| Step: 1
Training loss: 1.4266383647918701
Validation loss: 2.123785972595215

Epoch: 6| Step: 2
Training loss: 1.9255057573318481
Validation loss: 2.128061532974243

Epoch: 6| Step: 3
Training loss: 2.0231781005859375
Validation loss: 2.1103275616963706

Epoch: 6| Step: 4
Training loss: 1.850053071975708
Validation loss: 2.1047283013661704

Epoch: 6| Step: 5
Training loss: 2.2688066959381104
Validation loss: 2.085225681463877

Epoch: 6| Step: 6
Training loss: 1.929794430732727
Validation loss: 2.0598755280176797

Epoch: 6| Step: 7
Training loss: 1.8858568668365479
Validation loss: 2.0562318166097007

Epoch: 6| Step: 8
Training loss: 2.2025012969970703
Validation loss: 2.0414483745892844

Epoch: 6| Step: 9
Training loss: 2.3179073333740234
Validation loss: 2.0514328281084695

Epoch: 6| Step: 10
Training loss: 1.9757869243621826
Validation loss: 2.0505515535672507

Epoch: 6| Step: 11
Training loss: 2.395822525024414
Validation loss: 2.051809628804525

Epoch: 6| Step: 12
Training loss: 1.5749537944793701
Validation loss: 2.0353413422902427

Epoch: 6| Step: 13
Training loss: 1.9389660358428955
Validation loss: 2.0339385271072388

Epoch: 176| Step: 0
Training loss: 2.0063600540161133
Validation loss: 2.0530938506126404

Epoch: 6| Step: 1
Training loss: 2.108454942703247
Validation loss: 2.051034172375997

Epoch: 6| Step: 2
Training loss: 1.8268848657608032
Validation loss: 2.0619696180025735

Epoch: 6| Step: 3
Training loss: 1.4303113222122192
Validation loss: 2.065607567628225

Epoch: 6| Step: 4
Training loss: 1.9865679740905762
Validation loss: 2.071524659792582

Epoch: 6| Step: 5
Training loss: 2.125379800796509
Validation loss: 2.0752140879631042

Epoch: 6| Step: 6
Training loss: 2.1844732761383057
Validation loss: 2.0651474793752036

Epoch: 6| Step: 7
Training loss: 2.1546547412872314
Validation loss: 2.0721498926480613

Epoch: 6| Step: 8
Training loss: 1.622887372970581
Validation loss: 2.0718334317207336

Epoch: 6| Step: 9
Training loss: 2.156550407409668
Validation loss: 2.0720229744911194

Epoch: 6| Step: 10
Training loss: 2.471116781234741
Validation loss: 2.0798479119936624

Epoch: 6| Step: 11
Training loss: 2.1771609783172607
Validation loss: 2.0664337277412415

Epoch: 6| Step: 12
Training loss: 2.2382662296295166
Validation loss: 2.084083835283915

Epoch: 6| Step: 13
Training loss: 1.4248018264770508
Validation loss: 2.0884955128033957

Epoch: 177| Step: 0
Training loss: 1.6799468994140625
Validation loss: 2.1023689905802407

Epoch: 6| Step: 1
Training loss: 1.8290133476257324
Validation loss: 2.097085098425547

Epoch: 6| Step: 2
Training loss: 1.667639970779419
Validation loss: 2.09712423880895

Epoch: 6| Step: 3
Training loss: 1.687503695487976
Validation loss: 2.1041391690572104

Epoch: 6| Step: 4
Training loss: 1.9959838390350342
Validation loss: 2.0985097885131836

Epoch: 6| Step: 5
Training loss: 2.272170066833496
Validation loss: 2.084346870581309

Epoch: 6| Step: 6
Training loss: 2.344805955886841
Validation loss: 2.092914263407389

Epoch: 6| Step: 7
Training loss: 1.2659438848495483
Validation loss: 2.0804033676783242

Epoch: 6| Step: 8
Training loss: 1.8993844985961914
Validation loss: 2.071407695611318

Epoch: 6| Step: 9
Training loss: 2.258178949356079
Validation loss: 2.067131280899048

Epoch: 6| Step: 10
Training loss: 2.625854730606079
Validation loss: 2.0738736192385354

Epoch: 6| Step: 11
Training loss: 2.4345250129699707
Validation loss: 2.0632429321606955

Epoch: 6| Step: 12
Training loss: 2.298165798187256
Validation loss: 2.06442654132843

Epoch: 6| Step: 13
Training loss: 1.6375775337219238
Validation loss: 2.0636000831921897

Epoch: 178| Step: 0
Training loss: 2.303898811340332
Validation loss: 2.0622931520144143

Epoch: 6| Step: 1
Training loss: 1.9309064149856567
Validation loss: 2.0645188689231873

Epoch: 6| Step: 2
Training loss: 1.8417950868606567
Validation loss: 2.076543311278025

Epoch: 6| Step: 3
Training loss: 2.3582634925842285
Validation loss: 2.0728394587834678

Epoch: 6| Step: 4
Training loss: 2.011679172515869
Validation loss: 2.067761758963267

Epoch: 6| Step: 5
Training loss: 1.8636010885238647
Validation loss: 2.082656721274058

Epoch: 6| Step: 6
Training loss: 2.3277244567871094
Validation loss: 2.0675640304883323

Epoch: 6| Step: 7
Training loss: 1.603463053703308
Validation loss: 2.0799269676208496

Epoch: 6| Step: 8
Training loss: 1.7917773723602295
Validation loss: 2.0890451669692993

Epoch: 6| Step: 9
Training loss: 2.0247702598571777
Validation loss: 2.089188039302826

Epoch: 6| Step: 10
Training loss: 2.6681060791015625
Validation loss: 2.1067428986231485

Epoch: 6| Step: 11
Training loss: 1.4059219360351562
Validation loss: 2.097907761732737

Epoch: 6| Step: 12
Training loss: 1.945686936378479
Validation loss: 2.103406031926473

Epoch: 6| Step: 13
Training loss: 1.798802137374878
Validation loss: 2.0867530703544617

Epoch: 179| Step: 0
Training loss: 1.6230566501617432
Validation loss: 2.0924032330513

Epoch: 6| Step: 1
Training loss: 1.6486462354660034
Validation loss: 2.0950737595558167

Epoch: 6| Step: 2
Training loss: 2.6836347579956055
Validation loss: 2.1047017176946006

Epoch: 6| Step: 3
Training loss: 1.9063626527786255
Validation loss: 2.097708801428477

Epoch: 6| Step: 4
Training loss: 1.8126819133758545
Validation loss: 2.086248437563578

Epoch: 6| Step: 5
Training loss: 2.0849640369415283
Validation loss: 2.0855698784192405

Epoch: 6| Step: 6
Training loss: 2.917550802230835
Validation loss: 2.088964362939199

Epoch: 6| Step: 7
Training loss: 2.004544258117676
Validation loss: 2.0843507647514343

Epoch: 6| Step: 8
Training loss: 2.02154541015625
Validation loss: 2.092217981815338

Epoch: 6| Step: 9
Training loss: 0.9550526142120361
Validation loss: 2.0948028763135276

Epoch: 6| Step: 10
Training loss: 1.4837260246276855
Validation loss: 2.0946872234344482

Epoch: 6| Step: 11
Training loss: 2.0680313110351562
Validation loss: 2.0988859136899314

Epoch: 6| Step: 12
Training loss: 1.9313932657241821
Validation loss: 2.1047789653142295

Epoch: 6| Step: 13
Training loss: 2.359069585800171
Validation loss: 2.107400417327881

Epoch: 180| Step: 0
Training loss: 1.7163643836975098
Validation loss: 2.1051972111066184

Epoch: 6| Step: 1
Training loss: 2.3814902305603027
Validation loss: 2.099513212839762

Epoch: 6| Step: 2
Training loss: 2.0012385845184326
Validation loss: 2.1268612146377563

Epoch: 6| Step: 3
Training loss: 1.767371654510498
Validation loss: 2.1061758597691855

Epoch: 6| Step: 4
Training loss: 2.3541135787963867
Validation loss: 2.1189277172088623

Epoch: 6| Step: 5
Training loss: 1.0848872661590576
Validation loss: 2.114182452360789

Epoch: 6| Step: 6
Training loss: 1.7988049983978271
Validation loss: 2.1133867502212524

Epoch: 6| Step: 7
Training loss: 2.4367127418518066
Validation loss: 2.125196079413096

Epoch: 6| Step: 8
Training loss: 1.7447901964187622
Validation loss: 2.116138537724813

Epoch: 6| Step: 9
Training loss: 2.5939016342163086
Validation loss: 2.1017507115999856

Epoch: 6| Step: 10
Training loss: 1.4830043315887451
Validation loss: 2.1211470564206443

Epoch: 6| Step: 11
Training loss: 1.849475622177124
Validation loss: 2.1185439427693686

Epoch: 6| Step: 12
Training loss: 2.008925676345825
Validation loss: 2.1265764832496643

Epoch: 6| Step: 13
Training loss: 1.9568285942077637
Validation loss: 2.1050510803858438

Epoch: 181| Step: 0
Training loss: 1.4658823013305664
Validation loss: 2.107389728228251

Epoch: 6| Step: 1
Training loss: 1.5583248138427734
Validation loss: 2.0982788602511087

Epoch: 6| Step: 2
Training loss: 1.7973432540893555
Validation loss: 2.1140121022860208

Epoch: 6| Step: 3
Training loss: 2.261537551879883
Validation loss: 2.1075226068496704

Epoch: 6| Step: 4
Training loss: 1.7120559215545654
Validation loss: 2.106652319431305

Epoch: 6| Step: 5
Training loss: 1.7519346475601196
Validation loss: 2.116754194100698

Epoch: 6| Step: 6
Training loss: 2.3602097034454346
Validation loss: 2.098012844721476

Epoch: 6| Step: 7
Training loss: 2.1815853118896484
Validation loss: 2.095785975456238

Epoch: 6| Step: 8
Training loss: 2.1533331871032715
Validation loss: 2.099542776743571

Epoch: 6| Step: 9
Training loss: 2.1078038215637207
Validation loss: 2.105567137400309

Epoch: 6| Step: 10
Training loss: 2.06419038772583
Validation loss: 2.113041937351227

Epoch: 6| Step: 11
Training loss: 1.905144453048706
Validation loss: 2.117911239465078

Epoch: 6| Step: 12
Training loss: 2.109391212463379
Validation loss: 2.0951417287190757

Epoch: 6| Step: 13
Training loss: 2.1050288677215576
Validation loss: 2.1023685733477273

Epoch: 182| Step: 0
Training loss: 2.034067153930664
Validation loss: 2.0984694163004556

Epoch: 6| Step: 1
Training loss: 1.942583680152893
Validation loss: 2.120383401711782

Epoch: 6| Step: 2
Training loss: 2.3041493892669678
Validation loss: 2.103057106335958

Epoch: 6| Step: 3
Training loss: 1.793029546737671
Validation loss: 2.1211127837498984

Epoch: 6| Step: 4
Training loss: 1.9085501432418823
Validation loss: 2.107589304447174

Epoch: 6| Step: 5
Training loss: 2.0512428283691406
Validation loss: 2.103293518225352

Epoch: 6| Step: 6
Training loss: 1.2781872749328613
Validation loss: 2.1066254377365112

Epoch: 6| Step: 7
Training loss: 1.8293626308441162
Validation loss: 2.096822679042816

Epoch: 6| Step: 8
Training loss: 2.2414755821228027
Validation loss: 2.0960391958554587

Epoch: 6| Step: 9
Training loss: 2.123830556869507
Validation loss: 2.0850174824396768

Epoch: 6| Step: 10
Training loss: 1.9645254611968994
Validation loss: 2.104625384012858

Epoch: 6| Step: 11
Training loss: 2.2383151054382324
Validation loss: 2.0840198198954263

Epoch: 6| Step: 12
Training loss: 1.4808663129806519
Validation loss: 2.0749407013257346

Epoch: 6| Step: 13
Training loss: 2.4526162147521973
Validation loss: 2.0841899116834006

Epoch: 183| Step: 0
Training loss: 2.1732993125915527
Validation loss: 2.091026802857717

Epoch: 6| Step: 1
Training loss: 1.1858527660369873
Validation loss: 2.0914167761802673

Epoch: 6| Step: 2
Training loss: 1.4410583972930908
Validation loss: 2.0863529046376548

Epoch: 6| Step: 3
Training loss: 1.5969462394714355
Validation loss: 2.081500848134359

Epoch: 6| Step: 4
Training loss: 2.4962592124938965
Validation loss: 2.0951565901438394

Epoch: 6| Step: 5
Training loss: 1.7773115634918213
Validation loss: 2.0941572984059653

Epoch: 6| Step: 6
Training loss: 1.7875080108642578
Validation loss: 2.0924565196037292

Epoch: 6| Step: 7
Training loss: 2.6836740970611572
Validation loss: 2.1006062030792236

Epoch: 6| Step: 8
Training loss: 2.0669796466827393
Validation loss: 2.102689246336619

Epoch: 6| Step: 9
Training loss: 1.4196045398712158
Validation loss: 2.1161084373792014

Epoch: 6| Step: 10
Training loss: 2.294102668762207
Validation loss: 2.1344587802886963

Epoch: 6| Step: 11
Training loss: 2.535210371017456
Validation loss: 2.122876524925232

Epoch: 6| Step: 12
Training loss: 1.6392641067504883
Validation loss: 2.1277963121732077

Epoch: 6| Step: 13
Training loss: 2.7986950874328613
Validation loss: 2.1398613452911377

Epoch: 184| Step: 0
Training loss: 2.0777759552001953
Validation loss: 2.133598526318868

Epoch: 6| Step: 1
Training loss: 2.3813562393188477
Validation loss: 2.1271523435910544

Epoch: 6| Step: 2
Training loss: 1.8898134231567383
Validation loss: 2.155195116996765

Epoch: 6| Step: 3
Training loss: 2.23186993598938
Validation loss: 2.1409300764401755

Epoch: 6| Step: 4
Training loss: 1.3060487508773804
Validation loss: 2.149374524752299

Epoch: 6| Step: 5
Training loss: 2.6003007888793945
Validation loss: 2.1237767934799194

Epoch: 6| Step: 6
Training loss: 2.1691911220550537
Validation loss: 2.131150563557943

Epoch: 6| Step: 7
Training loss: 1.4875355958938599
Validation loss: 2.118408958117167

Epoch: 6| Step: 8
Training loss: 2.0784964561462402
Validation loss: 2.1278913219769797

Epoch: 6| Step: 9
Training loss: 1.759207010269165
Validation loss: 2.1226143836975098

Epoch: 6| Step: 10
Training loss: 1.9472167491912842
Validation loss: 2.1255828936894736

Epoch: 6| Step: 11
Training loss: 1.7202858924865723
Validation loss: 2.108448584874471

Epoch: 6| Step: 12
Training loss: 1.8152016401290894
Validation loss: 2.108133534590403

Epoch: 6| Step: 13
Training loss: 1.9609748125076294
Validation loss: 2.114378730456034

Epoch: 185| Step: 0
Training loss: 2.090972900390625
Validation loss: 2.110906442006429

Epoch: 6| Step: 1
Training loss: 2.2111053466796875
Validation loss: 2.1252054373423257

Epoch: 6| Step: 2
Training loss: 2.2502036094665527
Validation loss: 2.1173686385154724

Epoch: 6| Step: 3
Training loss: 2.163341999053955
Validation loss: 2.1232389410336814

Epoch: 6| Step: 4
Training loss: 1.5864676237106323
Validation loss: 2.1211825211842856

Epoch: 6| Step: 5
Training loss: 2.3289732933044434
Validation loss: 2.112426479657491

Epoch: 6| Step: 6
Training loss: 2.2899742126464844
Validation loss: 2.1312796076138816

Epoch: 6| Step: 7
Training loss: 1.3699781894683838
Validation loss: 2.124957025051117

Epoch: 6| Step: 8
Training loss: 1.6644556522369385
Validation loss: 2.1203611493110657

Epoch: 6| Step: 9
Training loss: 2.133413314819336
Validation loss: 2.130330224831899

Epoch: 6| Step: 10
Training loss: 1.2464497089385986
Validation loss: 2.1149049003918967

Epoch: 6| Step: 11
Training loss: 1.5926588773727417
Validation loss: 2.129798253377279

Epoch: 6| Step: 12
Training loss: 1.864095687866211
Validation loss: 2.1101051966349282

Epoch: 6| Step: 13
Training loss: 2.3310956954956055
Validation loss: 2.1145225365956626

Epoch: 186| Step: 0
Training loss: 1.9397079944610596
Validation loss: 2.102119227250417

Epoch: 6| Step: 1
Training loss: 2.319718360900879
Validation loss: 2.117415189743042

Epoch: 6| Step: 2
Training loss: 1.9054515361785889
Validation loss: 2.103979547818502

Epoch: 6| Step: 3
Training loss: 2.3120877742767334
Validation loss: 2.1151406168937683

Epoch: 6| Step: 4
Training loss: 1.7846814393997192
Validation loss: 2.106069564819336

Epoch: 6| Step: 5
Training loss: 2.2213408946990967
Validation loss: 2.1021300752957663

Epoch: 6| Step: 6
Training loss: 1.6663503646850586
Validation loss: 2.0862699349721274

Epoch: 6| Step: 7
Training loss: 2.435507297515869
Validation loss: 2.0953346292177835

Epoch: 6| Step: 8
Training loss: 1.964118242263794
Validation loss: 2.0942073663075766

Epoch: 6| Step: 9
Training loss: 1.8398396968841553
Validation loss: 2.0946728388468423

Epoch: 6| Step: 10
Training loss: 1.8906869888305664
Validation loss: 2.0875399311383567

Epoch: 6| Step: 11
Training loss: 2.0454869270324707
Validation loss: 2.0922609170277915

Epoch: 6| Step: 12
Training loss: 1.3405075073242188
Validation loss: 2.0899683435757956

Epoch: 6| Step: 13
Training loss: 1.900920033454895
Validation loss: 2.1031450231870017

Epoch: 187| Step: 0
Training loss: 1.518791913986206
Validation loss: 2.098967671394348

Epoch: 6| Step: 1
Training loss: 2.3553900718688965
Validation loss: 2.1029739379882812

Epoch: 6| Step: 2
Training loss: 1.556621789932251
Validation loss: 2.1005314787228904

Epoch: 6| Step: 3
Training loss: 2.4069933891296387
Validation loss: 2.0952550967534385

Epoch: 6| Step: 4
Training loss: 1.9044240713119507
Validation loss: 2.111464262008667

Epoch: 6| Step: 5
Training loss: 2.186789035797119
Validation loss: 2.1138182878494263

Epoch: 6| Step: 6
Training loss: 1.8102904558181763
Validation loss: 2.115653475125631

Epoch: 6| Step: 7
Training loss: 1.541698694229126
Validation loss: 2.124571681022644

Epoch: 6| Step: 8
Training loss: 2.7630906105041504
Validation loss: 2.1041133999824524

Epoch: 6| Step: 9
Training loss: 2.0670738220214844
Validation loss: 2.1345344384511313

Epoch: 6| Step: 10
Training loss: 1.9061946868896484
Validation loss: 2.1315184036890664

Epoch: 6| Step: 11
Training loss: 1.4188520908355713
Validation loss: 2.143411656220754

Epoch: 6| Step: 12
Training loss: 1.9412214756011963
Validation loss: 2.149415890375773

Epoch: 6| Step: 13
Training loss: 1.9381306171417236
Validation loss: 2.1382625897725425

Epoch: 188| Step: 0
Training loss: 1.7781672477722168
Validation loss: 2.1312559644381204

Epoch: 6| Step: 1
Training loss: 1.4510843753814697
Validation loss: 2.1035002867380777

Epoch: 6| Step: 2
Training loss: 2.0255441665649414
Validation loss: 2.1226659019788108

Epoch: 6| Step: 3
Training loss: 2.2127671241760254
Validation loss: 2.1119779547055564

Epoch: 6| Step: 4
Training loss: 2.078125
Validation loss: 2.1096293528874717

Epoch: 6| Step: 5
Training loss: 2.0334482192993164
Validation loss: 2.106671909491221

Epoch: 6| Step: 6
Training loss: 1.9409010410308838
Validation loss: 2.089925487836202

Epoch: 6| Step: 7
Training loss: 2.306227922439575
Validation loss: 2.098786413669586

Epoch: 6| Step: 8
Training loss: 1.7537345886230469
Validation loss: 2.092331071694692

Epoch: 6| Step: 9
Training loss: 2.087437629699707
Validation loss: 2.08146725098292

Epoch: 6| Step: 10
Training loss: 2.134188175201416
Validation loss: 2.093381861845652

Epoch: 6| Step: 11
Training loss: 2.262413263320923
Validation loss: 2.085091749827067

Epoch: 6| Step: 12
Training loss: 1.620368242263794
Validation loss: 2.094948927561442

Epoch: 6| Step: 13
Training loss: 1.9297478199005127
Validation loss: 2.0835176706314087

Epoch: 189| Step: 0
Training loss: 1.998042345046997
Validation loss: 2.0977014700571694

Epoch: 6| Step: 1
Training loss: 1.9157514572143555
Validation loss: 2.111175219217936

Epoch: 6| Step: 2
Training loss: 1.6832478046417236
Validation loss: 2.10107292731603

Epoch: 6| Step: 3
Training loss: 1.7025063037872314
Validation loss: 2.109719455242157

Epoch: 6| Step: 4
Training loss: 1.9690048694610596
Validation loss: 2.1045513351758323

Epoch: 6| Step: 5
Training loss: 2.0935096740722656
Validation loss: 2.1026524702707925

Epoch: 6| Step: 6
Training loss: 1.6586401462554932
Validation loss: 2.111193060874939

Epoch: 6| Step: 7
Training loss: 1.8420113325119019
Validation loss: 2.10152937968572

Epoch: 6| Step: 8
Training loss: 2.163435697555542
Validation loss: 2.1017112731933594

Epoch: 6| Step: 9
Training loss: 1.723881483078003
Validation loss: 2.1109357873598733

Epoch: 6| Step: 10
Training loss: 1.7684730291366577
Validation loss: 2.107860823472341

Epoch: 6| Step: 11
Training loss: 2.4314069747924805
Validation loss: 2.1041877071062722

Epoch: 6| Step: 12
Training loss: 1.775579810142517
Validation loss: 2.096246858437856

Epoch: 6| Step: 13
Training loss: 2.534893274307251
Validation loss: 2.1005672415097556

Epoch: 190| Step: 0
Training loss: 1.5986287593841553
Validation loss: 2.0987712939580283

Epoch: 6| Step: 1
Training loss: 1.174131155014038
Validation loss: 2.0963344971338906

Epoch: 6| Step: 2
Training loss: 2.090338706970215
Validation loss: 2.0986960927645364

Epoch: 6| Step: 3
Training loss: 1.8146939277648926
Validation loss: 2.0981644789377847

Epoch: 6| Step: 4
Training loss: 1.7534842491149902
Validation loss: 2.1049715677897134

Epoch: 6| Step: 5
Training loss: 2.3335351943969727
Validation loss: 2.113032102584839

Epoch: 6| Step: 6
Training loss: 2.8086862564086914
Validation loss: 2.0978561838467917

Epoch: 6| Step: 7
Training loss: 2.2350878715515137
Validation loss: 2.104310075441996

Epoch: 6| Step: 8
Training loss: 1.8976309299468994
Validation loss: 2.097643872102102

Epoch: 6| Step: 9
Training loss: 1.8342478275299072
Validation loss: 2.1178977290789285

Epoch: 6| Step: 10
Training loss: 1.6740269660949707
Validation loss: 2.120152990023295

Epoch: 6| Step: 11
Training loss: 1.7878086566925049
Validation loss: 2.1182478070259094

Epoch: 6| Step: 12
Training loss: 1.6352732181549072
Validation loss: 2.1202878952026367

Epoch: 6| Step: 13
Training loss: 2.532270908355713
Validation loss: 2.120829244454702

Epoch: 191| Step: 0
Training loss: 1.5857155323028564
Validation loss: 2.1302085518836975

Epoch: 6| Step: 1
Training loss: 2.449944257736206
Validation loss: 2.1144401828447976

Epoch: 6| Step: 2
Training loss: 2.522193193435669
Validation loss: 2.1194262504577637

Epoch: 6| Step: 3
Training loss: 2.3458988666534424
Validation loss: 2.1170367995897927

Epoch: 6| Step: 4
Training loss: 2.0770797729492188
Validation loss: 2.1402847369511924

Epoch: 6| Step: 5
Training loss: 1.660531997680664
Validation loss: 2.1316436330477395

Epoch: 6| Step: 6
Training loss: 1.7515864372253418
Validation loss: 2.1308158238728843

Epoch: 6| Step: 7
Training loss: 1.8671000003814697
Validation loss: 2.159619987010956

Epoch: 6| Step: 8
Training loss: 1.6970102787017822
Validation loss: 2.147267540295919

Epoch: 6| Step: 9
Training loss: 1.84175705909729
Validation loss: 2.15075292189916

Epoch: 6| Step: 10
Training loss: 1.8631880283355713
Validation loss: 2.1409658590952554

Epoch: 6| Step: 11
Training loss: 2.3960375785827637
Validation loss: 2.139371077219645

Epoch: 6| Step: 12
Training loss: 1.678262710571289
Validation loss: 2.135012606779734

Epoch: 6| Step: 13
Training loss: 1.6407687664031982
Validation loss: 2.1209219694137573

Epoch: 192| Step: 0
Training loss: 1.682605266571045
Validation loss: 2.112700263659159

Epoch: 6| Step: 1
Training loss: 2.381418466567993
Validation loss: 2.1306722362836203

Epoch: 6| Step: 2
Training loss: 1.8408210277557373
Validation loss: 2.107856194178263

Epoch: 6| Step: 3
Training loss: 2.0650129318237305
Validation loss: 2.102514068285624

Epoch: 6| Step: 4
Training loss: 2.597500801086426
Validation loss: 2.1105987429618835

Epoch: 6| Step: 5
Training loss: 1.8490583896636963
Validation loss: 2.110401709874471

Epoch: 6| Step: 6
Training loss: 1.823429822921753
Validation loss: 2.106053610642751

Epoch: 6| Step: 7
Training loss: 1.8966686725616455
Validation loss: 2.1216467221577964

Epoch: 6| Step: 8
Training loss: 1.446169376373291
Validation loss: 2.1094722350438437

Epoch: 6| Step: 9
Training loss: 1.578720211982727
Validation loss: 2.1177212794621787

Epoch: 6| Step: 10
Training loss: 2.2699716091156006
Validation loss: 2.1276463667551675

Epoch: 6| Step: 11
Training loss: 2.05424427986145
Validation loss: 2.1128970185915628

Epoch: 6| Step: 12
Training loss: 1.7457484006881714
Validation loss: 2.1158217589060464

Epoch: 6| Step: 13
Training loss: 1.8125489950180054
Validation loss: 2.1315353910128274

Epoch: 193| Step: 0
Training loss: 1.9695026874542236
Validation loss: 2.146714468797048

Epoch: 6| Step: 1
Training loss: 2.1535661220550537
Validation loss: 2.1416309078534446

Epoch: 6| Step: 2
Training loss: 2.112645387649536
Validation loss: 2.153249899546305

Epoch: 6| Step: 3
Training loss: 2.203441858291626
Validation loss: 2.1348740061124167

Epoch: 6| Step: 4
Training loss: 2.1854584217071533
Validation loss: 2.16264408826828

Epoch: 6| Step: 5
Training loss: 1.6697678565979004
Validation loss: 2.138631065686544

Epoch: 6| Step: 6
Training loss: 1.6760127544403076
Validation loss: 2.1447872718175254

Epoch: 6| Step: 7
Training loss: 1.4605686664581299
Validation loss: 2.1348642905553183

Epoch: 6| Step: 8
Training loss: 2.1046628952026367
Validation loss: 2.140051245689392

Epoch: 6| Step: 9
Training loss: 2.1378843784332275
Validation loss: 2.115557372570038

Epoch: 6| Step: 10
Training loss: 2.057429313659668
Validation loss: 2.119300345579783

Epoch: 6| Step: 11
Training loss: 1.861797571182251
Validation loss: 2.112448732058207

Epoch: 6| Step: 12
Training loss: 1.8330520391464233
Validation loss: 2.1115161776542664

Epoch: 6| Step: 13
Training loss: 1.8483452796936035
Validation loss: 2.109785338242849

Epoch: 194| Step: 0
Training loss: 1.8647242784500122
Validation loss: 2.101139803727468

Epoch: 6| Step: 1
Training loss: 2.061830520629883
Validation loss: 2.0996708075205484

Epoch: 6| Step: 2
Training loss: 1.7697582244873047
Validation loss: 2.105897764364878

Epoch: 6| Step: 3
Training loss: 1.5489646196365356
Validation loss: 2.103423833847046

Epoch: 6| Step: 4
Training loss: 1.306992769241333
Validation loss: 2.1076700091362

Epoch: 6| Step: 5
Training loss: 1.9833297729492188
Validation loss: 2.1130768060684204

Epoch: 6| Step: 6
Training loss: 2.104351282119751
Validation loss: 2.131235659122467

Epoch: 6| Step: 7
Training loss: 2.270526647567749
Validation loss: 2.138471861680349

Epoch: 6| Step: 8
Training loss: 2.240138053894043
Validation loss: 2.1334913969039917

Epoch: 6| Step: 9
Training loss: 1.4439935684204102
Validation loss: 2.1143903732299805

Epoch: 6| Step: 10
Training loss: 2.167870044708252
Validation loss: 2.1426000396410623

Epoch: 6| Step: 11
Training loss: 1.9177184104919434
Validation loss: 2.1464224457740784

Epoch: 6| Step: 12
Training loss: 2.364767551422119
Validation loss: 2.119859834512075

Epoch: 6| Step: 13
Training loss: 2.320706844329834
Validation loss: 2.121251940727234

Epoch: 195| Step: 0
Training loss: 2.0781280994415283
Validation loss: 2.117025593916575

Epoch: 6| Step: 1
Training loss: 1.8005053997039795
Validation loss: 2.1217650969823203

Epoch: 6| Step: 2
Training loss: 1.9784780740737915
Validation loss: 2.1250571409861245

Epoch: 6| Step: 3
Training loss: 2.106907606124878
Validation loss: 2.1263699531555176

Epoch: 6| Step: 4
Training loss: 2.385875701904297
Validation loss: 2.111374874909719

Epoch: 6| Step: 5
Training loss: 1.5826458930969238
Validation loss: 2.1264737447102866

Epoch: 6| Step: 6
Training loss: 1.8814712762832642
Validation loss: 2.1041517853736877

Epoch: 6| Step: 7
Training loss: 1.7173595428466797
Validation loss: 2.1096798380215964

Epoch: 6| Step: 8
Training loss: 1.6226305961608887
Validation loss: 2.1166561444600425

Epoch: 6| Step: 9
Training loss: 2.0472631454467773
Validation loss: 2.1205418705940247

Epoch: 6| Step: 10
Training loss: 1.877453088760376
Validation loss: 2.1288553873697915

Epoch: 6| Step: 11
Training loss: 1.8004810810089111
Validation loss: 2.1263429125150046

Epoch: 6| Step: 12
Training loss: 1.6785391569137573
Validation loss: 2.1497452656428018

Epoch: 6| Step: 13
Training loss: 2.377333164215088
Validation loss: 2.1219149827957153

Epoch: 196| Step: 0
Training loss: 1.2784056663513184
Validation loss: 2.147106945514679

Epoch: 6| Step: 1
Training loss: 1.492221474647522
Validation loss: 2.146988828976949

Epoch: 6| Step: 2
Training loss: 1.9866517782211304
Validation loss: 2.1426681081453958

Epoch: 6| Step: 3
Training loss: 2.173621892929077
Validation loss: 2.141185184319814

Epoch: 6| Step: 4
Training loss: 2.631408214569092
Validation loss: 2.153851052125295

Epoch: 6| Step: 5
Training loss: 2.0191004276275635
Validation loss: 2.142486572265625

Epoch: 6| Step: 6
Training loss: 1.7789764404296875
Validation loss: 2.1420069535573325

Epoch: 6| Step: 7
Training loss: 2.1420998573303223
Validation loss: 2.1285610795021057

Epoch: 6| Step: 8
Training loss: 1.54086172580719
Validation loss: 2.130612055460612

Epoch: 6| Step: 9
Training loss: 1.6896941661834717
Validation loss: 2.122908671696981

Epoch: 6| Step: 10
Training loss: 2.1294360160827637
Validation loss: 2.123239000638326

Epoch: 6| Step: 11
Training loss: 1.7108235359191895
Validation loss: 2.135482589403788

Epoch: 6| Step: 12
Training loss: 2.4925003051757812
Validation loss: 2.117812772591909

Epoch: 6| Step: 13
Training loss: 1.794741153717041
Validation loss: 2.121573487917582

Epoch: 197| Step: 0
Training loss: 1.831265926361084
Validation loss: 2.1212496558825173

Epoch: 6| Step: 1
Training loss: 2.1437745094299316
Validation loss: 2.112818499406179

Epoch: 6| Step: 2
Training loss: 1.9882029294967651
Validation loss: 2.1164506872495017

Epoch: 6| Step: 3
Training loss: 1.925686001777649
Validation loss: 2.13319726785024

Epoch: 6| Step: 4
Training loss: 1.8387055397033691
Validation loss: 2.1406747698783875

Epoch: 6| Step: 5
Training loss: 2.055701732635498
Validation loss: 2.134927729765574

Epoch: 6| Step: 6
Training loss: 2.479700803756714
Validation loss: 2.1403284072875977

Epoch: 6| Step: 7
Training loss: 1.7983969449996948
Validation loss: 2.127354105313619

Epoch: 6| Step: 8
Training loss: 2.2632837295532227
Validation loss: 2.1319372852643332

Epoch: 6| Step: 9
Training loss: 1.8435096740722656
Validation loss: 2.1413224736849465

Epoch: 6| Step: 10
Training loss: 1.7763972282409668
Validation loss: 2.131026486555735

Epoch: 6| Step: 11
Training loss: 2.051823616027832
Validation loss: 2.145412047704061

Epoch: 6| Step: 12
Training loss: 1.4799355268478394
Validation loss: 2.127503514289856

Epoch: 6| Step: 13
Training loss: 1.6113519668579102
Validation loss: 2.12408854564031

Epoch: 198| Step: 0
Training loss: 1.926929235458374
Validation loss: 2.1231185595194497

Epoch: 6| Step: 1
Training loss: 1.6960155963897705
Validation loss: 2.130075693130493

Epoch: 6| Step: 2
Training loss: 2.1258816719055176
Validation loss: 2.125026265780131

Epoch: 6| Step: 3
Training loss: 1.5979723930358887
Validation loss: 2.120099147160848

Epoch: 6| Step: 4
Training loss: 2.104259490966797
Validation loss: 2.128863433996836

Epoch: 6| Step: 5
Training loss: 1.8506951332092285
Validation loss: 2.110624134540558

Epoch: 6| Step: 6
Training loss: 2.6953282356262207
Validation loss: 2.125497063000997

Epoch: 6| Step: 7
Training loss: 1.5350970029830933
Validation loss: 2.1231453021367392

Epoch: 6| Step: 8
Training loss: 2.056628942489624
Validation loss: 2.1243589719136557

Epoch: 6| Step: 9
Training loss: 1.5121879577636719
Validation loss: 2.122757315635681

Epoch: 6| Step: 10
Training loss: 1.5677950382232666
Validation loss: 2.1317343711853027

Epoch: 6| Step: 11
Training loss: 2.476318836212158
Validation loss: 2.1228513518969216

Epoch: 6| Step: 12
Training loss: 2.2133641242980957
Validation loss: 2.1395673950513205

Epoch: 6| Step: 13
Training loss: 1.6229897737503052
Validation loss: 2.1405242482821145

Epoch: 199| Step: 0
Training loss: 1.8421673774719238
Validation loss: 2.1389686465263367

Epoch: 6| Step: 1
Training loss: 1.7069566249847412
Validation loss: 2.137675861517588

Epoch: 6| Step: 2
Training loss: 1.5780987739562988
Validation loss: 2.1231088439623513

Epoch: 6| Step: 3
Training loss: 2.1762351989746094
Validation loss: 2.134632925192515

Epoch: 6| Step: 4
Training loss: 2.121140956878662
Validation loss: 2.126312176386515

Epoch: 6| Step: 5
Training loss: 1.8104026317596436
Validation loss: 2.1103646556536355

Epoch: 6| Step: 6
Training loss: 1.5278764963150024
Validation loss: 2.13064976533254

Epoch: 6| Step: 7
Training loss: 2.75588321685791
Validation loss: 2.128422975540161

Epoch: 6| Step: 8
Training loss: 2.264496326446533
Validation loss: 2.11850905418396

Epoch: 6| Step: 9
Training loss: 1.3804477453231812
Validation loss: 2.1234846711158752

Epoch: 6| Step: 10
Training loss: 2.27280330657959
Validation loss: 2.1123944520950317

Epoch: 6| Step: 11
Training loss: 1.7704100608825684
Validation loss: 2.112803260485331

Epoch: 6| Step: 12
Training loss: 1.401916265487671
Validation loss: 2.1085988879203796

Epoch: 6| Step: 13
Training loss: 2.337239980697632
Validation loss: 2.1155073841412864

Epoch: 200| Step: 0
Training loss: 2.1117191314697266
Validation loss: 2.1221887270609536

Epoch: 6| Step: 1
Training loss: 1.7578390836715698
Validation loss: 2.1139888763427734

Epoch: 6| Step: 2
Training loss: 1.759798526763916
Validation loss: 2.1133434971173606

Epoch: 6| Step: 3
Training loss: 1.6142668724060059
Validation loss: 2.130436599254608

Epoch: 6| Step: 4
Training loss: 2.6835930347442627
Validation loss: 2.1018823186556497

Epoch: 6| Step: 5
Training loss: 2.140923023223877
Validation loss: 2.12371955315272

Epoch: 6| Step: 6
Training loss: 2.4256958961486816
Validation loss: 2.118513365586599

Epoch: 6| Step: 7
Training loss: 1.7301112413406372
Validation loss: 2.120042602221171

Epoch: 6| Step: 8
Training loss: 1.1704480648040771
Validation loss: 2.1262497703234353

Epoch: 6| Step: 9
Training loss: 2.577569007873535
Validation loss: 2.1232456962267556

Epoch: 6| Step: 10
Training loss: 1.480815052986145
Validation loss: 2.1333864529927573

Epoch: 6| Step: 11
Training loss: 2.0537707805633545
Validation loss: 2.133882919947306

Epoch: 6| Step: 12
Training loss: 1.657965898513794
Validation loss: 2.137062390645345

Epoch: 6| Step: 13
Training loss: 1.6265978813171387
Validation loss: 2.141848166783651

Epoch: 201| Step: 0
Training loss: 1.6559008359909058
Validation loss: 2.14220396677653

Epoch: 6| Step: 1
Training loss: 1.5468292236328125
Validation loss: 2.1511072715123496

Epoch: 6| Step: 2
Training loss: 2.1498661041259766
Validation loss: 2.163714269797007

Epoch: 6| Step: 3
Training loss: 1.922529697418213
Validation loss: 2.160577654838562

Epoch: 6| Step: 4
Training loss: 1.972247838973999
Validation loss: 2.173551003138224

Epoch: 6| Step: 5
Training loss: 1.569908857345581
Validation loss: 2.1790937980016074

Epoch: 6| Step: 6
Training loss: 1.5266188383102417
Validation loss: 2.1579457918802896

Epoch: 6| Step: 7
Training loss: 1.2788982391357422
Validation loss: 2.147832711537679

Epoch: 6| Step: 8
Training loss: 2.143587589263916
Validation loss: 2.144944886366526

Epoch: 6| Step: 9
Training loss: 1.613325595855713
Validation loss: 2.1497326691945395

Epoch: 6| Step: 10
Training loss: 2.0965890884399414
Validation loss: 2.1548433899879456

Epoch: 6| Step: 11
Training loss: 2.357250690460205
Validation loss: 2.131795366605123

Epoch: 6| Step: 12
Training loss: 2.1006743907928467
Validation loss: 2.135425547758738

Epoch: 6| Step: 13
Training loss: 2.8537044525146484
Validation loss: 2.1394561926523843

Epoch: 202| Step: 0
Training loss: 1.6189709901809692
Validation loss: 2.1347520550092063

Epoch: 6| Step: 1
Training loss: 1.7990748882293701
Validation loss: 2.136110246181488

Epoch: 6| Step: 2
Training loss: 1.6690129041671753
Validation loss: 2.1503607432047525

Epoch: 6| Step: 3
Training loss: 2.023977518081665
Validation loss: 2.131618618965149

Epoch: 6| Step: 4
Training loss: 2.087657928466797
Validation loss: 2.1259931723276773

Epoch: 6| Step: 5
Training loss: 1.9236961603164673
Validation loss: 2.126848797003428

Epoch: 6| Step: 6
Training loss: 2.122292995452881
Validation loss: 2.1360008915265403

Epoch: 6| Step: 7
Training loss: 2.080832004547119
Validation loss: 2.1094383796056113

Epoch: 6| Step: 8
Training loss: 2.376338481903076
Validation loss: 2.1353562672932944

Epoch: 6| Step: 9
Training loss: 1.8364176750183105
Validation loss: 2.1272355914115906

Epoch: 6| Step: 10
Training loss: 1.9157711267471313
Validation loss: 2.1325851877530417

Epoch: 6| Step: 11
Training loss: 1.8153393268585205
Validation loss: 2.1382580995559692

Epoch: 6| Step: 12
Training loss: 1.9731494188308716
Validation loss: 2.1350682179133096

Epoch: 6| Step: 13
Training loss: 1.5556570291519165
Validation loss: 2.141316294670105

Epoch: 203| Step: 0
Training loss: 1.4314614534378052
Validation loss: 2.136201024055481

Epoch: 6| Step: 1
Training loss: 2.065589189529419
Validation loss: 2.159075438976288

Epoch: 6| Step: 2
Training loss: 1.741335153579712
Validation loss: 2.1562142372131348

Epoch: 6| Step: 3
Training loss: 1.7793235778808594
Validation loss: 2.156409660975138

Epoch: 6| Step: 4
Training loss: 2.339789390563965
Validation loss: 2.1377535263697305

Epoch: 6| Step: 5
Training loss: 2.3970117568969727
Validation loss: 2.1371379494667053

Epoch: 6| Step: 6
Training loss: 1.3377970457077026
Validation loss: 2.1405434211095176

Epoch: 6| Step: 7
Training loss: 1.8591052293777466
Validation loss: 2.127848287423452

Epoch: 6| Step: 8
Training loss: 1.7827072143554688
Validation loss: 2.1337085564931235

Epoch: 6| Step: 9
Training loss: 1.9558590650558472
Validation loss: 2.1202516754468284

Epoch: 6| Step: 10
Training loss: 2.3727922439575195
Validation loss: 2.1107364892959595

Epoch: 6| Step: 11
Training loss: 2.1851491928100586
Validation loss: 2.1178441445032754

Epoch: 6| Step: 12
Training loss: 2.1133108139038086
Validation loss: 2.121427337328593

Epoch: 6| Step: 13
Training loss: 1.6956685781478882
Validation loss: 2.1201090216636658

Epoch: 204| Step: 0
Training loss: 2.0342483520507812
Validation loss: 2.113830864429474

Epoch: 6| Step: 1
Training loss: 2.058957576751709
Validation loss: 2.113384942213694

Epoch: 6| Step: 2
Training loss: 1.244025707244873
Validation loss: 2.1329927245775857

Epoch: 6| Step: 3
Training loss: 2.29148006439209
Validation loss: 2.135833740234375

Epoch: 6| Step: 4
Training loss: 1.3431727886199951
Validation loss: 2.143690844376882

Epoch: 6| Step: 5
Training loss: 2.471965789794922
Validation loss: 2.1465970277786255

Epoch: 6| Step: 6
Training loss: 1.6635147333145142
Validation loss: 2.1327774127324424

Epoch: 6| Step: 7
Training loss: 1.83207106590271
Validation loss: 2.15296479066213

Epoch: 6| Step: 8
Training loss: 1.9350031614303589
Validation loss: 2.144870142141978

Epoch: 6| Step: 9
Training loss: 2.1896169185638428
Validation loss: 2.152654012044271

Epoch: 6| Step: 10
Training loss: 1.8168365955352783
Validation loss: 2.1538361509641013

Epoch: 6| Step: 11
Training loss: 2.239875316619873
Validation loss: 2.1620662609736123

Epoch: 6| Step: 12
Training loss: 2.5276734828948975
Validation loss: 2.156708598136902

Epoch: 6| Step: 13
Training loss: 1.3130964040756226
Validation loss: 2.1565273801485696

Epoch: 205| Step: 0
Training loss: 1.7725374698638916
Validation loss: 2.162169317404429

Epoch: 6| Step: 1
Training loss: 2.43131947517395
Validation loss: 2.1537432074546814

Epoch: 6| Step: 2
Training loss: 1.551046371459961
Validation loss: 2.136307120323181

Epoch: 6| Step: 3
Training loss: 2.031907320022583
Validation loss: 2.1297573248545327

Epoch: 6| Step: 4
Training loss: 1.9393811225891113
Validation loss: 2.1165880958239236

Epoch: 6| Step: 5
Training loss: 1.1392935514450073
Validation loss: 2.131979525089264

Epoch: 6| Step: 6
Training loss: 1.2702174186706543
Validation loss: 2.137233853340149

Epoch: 6| Step: 7
Training loss: 1.9552743434906006
Validation loss: 2.125716745853424

Epoch: 6| Step: 8
Training loss: 1.8291839361190796
Validation loss: 2.137950380643209

Epoch: 6| Step: 9
Training loss: 2.5900540351867676
Validation loss: 2.120769460995992

Epoch: 6| Step: 10
Training loss: 2.0232150554656982
Validation loss: 2.1196357806523642

Epoch: 6| Step: 11
Training loss: 2.544796943664551
Validation loss: 2.1383809049924216

Epoch: 6| Step: 12
Training loss: 1.8409020900726318
Validation loss: 2.1347357630729675

Epoch: 6| Step: 13
Training loss: 2.010763645172119
Validation loss: 2.135940730571747

Epoch: 206| Step: 0
Training loss: 1.5916804075241089
Validation loss: 2.1366776823997498

Epoch: 6| Step: 1
Training loss: 1.62591552734375
Validation loss: 2.126974622408549

Epoch: 6| Step: 2
Training loss: 2.2868025302886963
Validation loss: 2.1073771119117737

Epoch: 6| Step: 3
Training loss: 2.11452317237854
Validation loss: 2.116544167200724

Epoch: 6| Step: 4
Training loss: 1.7100355625152588
Validation loss: 2.1136306325594583

Epoch: 6| Step: 5
Training loss: 1.4490129947662354
Validation loss: 2.1292343537012735

Epoch: 6| Step: 6
Training loss: 2.4882166385650635
Validation loss: 2.1339884996414185

Epoch: 6| Step: 7
Training loss: 1.7924103736877441
Validation loss: 2.127354621887207

Epoch: 6| Step: 8
Training loss: 1.7548015117645264
Validation loss: 2.1158037185668945

Epoch: 6| Step: 9
Training loss: 2.02329683303833
Validation loss: 2.1222798426946006

Epoch: 6| Step: 10
Training loss: 2.018465280532837
Validation loss: 2.146732489267985

Epoch: 6| Step: 11
Training loss: 2.392979145050049
Validation loss: 2.140686511993408

Epoch: 6| Step: 12
Training loss: 1.5664517879486084
Validation loss: 2.1231128176053367

Epoch: 6| Step: 13
Training loss: 2.1989853382110596
Validation loss: 2.1256991227467856

Epoch: 207| Step: 0
Training loss: 2.040989875793457
Validation loss: 2.1362591981887817

Epoch: 6| Step: 1
Training loss: 1.8273882865905762
Validation loss: 2.126250664393107

Epoch: 6| Step: 2
Training loss: 2.115694999694824
Validation loss: 2.1361619432767234

Epoch: 6| Step: 3
Training loss: 1.7539929151535034
Validation loss: 2.1432406504948935

Epoch: 6| Step: 4
Training loss: 1.9843823909759521
Validation loss: 2.138869822025299

Epoch: 6| Step: 5
Training loss: 1.7400051355361938
Validation loss: 2.140568713347117

Epoch: 6| Step: 6
Training loss: 1.9345488548278809
Validation loss: 2.1398137410481772

Epoch: 6| Step: 7
Training loss: 2.0754523277282715
Validation loss: 2.128727157910665

Epoch: 6| Step: 8
Training loss: 2.057579517364502
Validation loss: 2.1377668182055154

Epoch: 6| Step: 9
Training loss: 2.0184438228607178
Validation loss: 2.146088699499766

Epoch: 6| Step: 10
Training loss: 1.8367550373077393
Validation loss: 2.1458398699760437

Epoch: 6| Step: 11
Training loss: 1.3616712093353271
Validation loss: 2.1313517888387046

Epoch: 6| Step: 12
Training loss: 1.992602825164795
Validation loss: 2.1498729983965554

Epoch: 6| Step: 13
Training loss: 1.870837926864624
Validation loss: 2.143651326497396

Epoch: 208| Step: 0
Training loss: 1.9606671333312988
Validation loss: 2.1671969890594482

Epoch: 6| Step: 1
Training loss: 2.2064208984375
Validation loss: 2.161900758743286

Epoch: 6| Step: 2
Training loss: 1.4853605031967163
Validation loss: 2.1537926197052

Epoch: 6| Step: 3
Training loss: 2.3146183490753174
Validation loss: 2.143585483233134

Epoch: 6| Step: 4
Training loss: 1.5998080968856812
Validation loss: 2.151005129019419

Epoch: 6| Step: 5
Training loss: 1.6587146520614624
Validation loss: 2.1445838809013367

Epoch: 6| Step: 6
Training loss: 1.6864677667617798
Validation loss: 2.138068517049154

Epoch: 6| Step: 7
Training loss: 1.3571505546569824
Validation loss: 2.1382736365000405

Epoch: 6| Step: 8
Training loss: 2.5515003204345703
Validation loss: 2.1325867970784507

Epoch: 6| Step: 9
Training loss: 2.7195587158203125
Validation loss: 2.1254743933677673

Epoch: 6| Step: 10
Training loss: 2.1140999794006348
Validation loss: 2.141606628894806

Epoch: 6| Step: 11
Training loss: 1.4989047050476074
Validation loss: 2.142624298731486

Epoch: 6| Step: 12
Training loss: 2.4643688201904297
Validation loss: 2.1416054368019104

Epoch: 6| Step: 13
Training loss: 1.580390214920044
Validation loss: 2.1292502085367837

Epoch: 209| Step: 0
Training loss: 2.590991973876953
Validation loss: 2.1401639779408774

Epoch: 6| Step: 1
Training loss: 1.422783374786377
Validation loss: 2.1341991821924844

Epoch: 6| Step: 2
Training loss: 1.397202730178833
Validation loss: 2.1402124961217246

Epoch: 6| Step: 3
Training loss: 2.2403411865234375
Validation loss: 2.136185963948568

Epoch: 6| Step: 4
Training loss: 1.8742023706436157
Validation loss: 2.1331547101338706

Epoch: 6| Step: 5
Training loss: 1.772708773612976
Validation loss: 2.1453636487325034

Epoch: 6| Step: 6
Training loss: 2.554990768432617
Validation loss: 2.138334552447001

Epoch: 6| Step: 7
Training loss: 1.3894233703613281
Validation loss: 2.13850998878479

Epoch: 6| Step: 8
Training loss: 1.9944877624511719
Validation loss: 2.1422522266705832

Epoch: 6| Step: 9
Training loss: 1.4415526390075684
Validation loss: 2.13121106227239

Epoch: 6| Step: 10
Training loss: 1.9282326698303223
Validation loss: 2.1207688053448996

Epoch: 6| Step: 11
Training loss: 2.089329481124878
Validation loss: 2.11681991815567

Epoch: 6| Step: 12
Training loss: 1.897200345993042
Validation loss: 2.113445301850637

Epoch: 6| Step: 13
Training loss: 2.3428659439086914
Validation loss: 2.1269306341807046

Epoch: 210| Step: 0
Training loss: 2.5830864906311035
Validation loss: 2.1154244343439736

Epoch: 6| Step: 1
Training loss: 1.3022794723510742
Validation loss: 2.116499960422516

Epoch: 6| Step: 2
Training loss: 1.5517346858978271
Validation loss: 2.1327113707860312

Epoch: 6| Step: 3
Training loss: 1.6327980756759644
Validation loss: 2.142876148223877

Epoch: 6| Step: 4
Training loss: 2.4664950370788574
Validation loss: 2.1437111695607505

Epoch: 6| Step: 5
Training loss: 1.727182149887085
Validation loss: 2.1428093910217285

Epoch: 6| Step: 6
Training loss: 1.6091282367706299
Validation loss: 2.162941634654999

Epoch: 6| Step: 7
Training loss: 2.3445727825164795
Validation loss: 2.1584317485491433

Epoch: 6| Step: 8
Training loss: 1.943617343902588
Validation loss: 2.179425617059072

Epoch: 6| Step: 9
Training loss: 2.2429699897766113
Validation loss: 2.1674691438674927

Epoch: 6| Step: 10
Training loss: 1.9037771224975586
Validation loss: 2.179738163948059

Epoch: 6| Step: 11
Training loss: 1.5331226587295532
Validation loss: 2.1790992418924966

Epoch: 6| Step: 12
Training loss: 2.1479063034057617
Validation loss: 2.170745372772217

Epoch: 6| Step: 13
Training loss: 1.700398564338684
Validation loss: 2.1998552878697715

Epoch: 211| Step: 0
Training loss: 1.901814341545105
Validation loss: 2.184092084566752

Epoch: 6| Step: 1
Training loss: 2.5472354888916016
Validation loss: 2.189764757951101

Epoch: 6| Step: 2
Training loss: 1.7534122467041016
Validation loss: 2.1517927050590515

Epoch: 6| Step: 3
Training loss: 2.0126514434814453
Validation loss: 2.1534747878710427

Epoch: 6| Step: 4
Training loss: 2.4001405239105225
Validation loss: 2.154554307460785

Epoch: 6| Step: 5
Training loss: 1.5026612281799316
Validation loss: 2.1300774812698364

Epoch: 6| Step: 6
Training loss: 1.7000170946121216
Validation loss: 2.138354937235514

Epoch: 6| Step: 7
Training loss: 1.8390992879867554
Validation loss: 2.1445359786351523

Epoch: 6| Step: 8
Training loss: 1.870130181312561
Validation loss: 2.139142016569773

Epoch: 6| Step: 9
Training loss: 2.077277660369873
Validation loss: 2.1554671923319497

Epoch: 6| Step: 10
Training loss: 1.7534763813018799
Validation loss: 2.154973646004995

Epoch: 6| Step: 11
Training loss: 1.8725147247314453
Validation loss: 2.1611990531285605

Epoch: 6| Step: 12
Training loss: 1.5561866760253906
Validation loss: 2.1594843665758767

Epoch: 6| Step: 13
Training loss: 1.8921008110046387
Validation loss: 2.1458953221639

Epoch: 212| Step: 0
Training loss: 1.2881181240081787
Validation loss: 2.1203437050183616

Epoch: 6| Step: 1
Training loss: 2.099159002304077
Validation loss: 2.115003009637197

Epoch: 6| Step: 2
Training loss: 2.05576753616333
Validation loss: 2.122594734032949

Epoch: 6| Step: 3
Training loss: 1.9781105518341064
Validation loss: 2.120910028616587

Epoch: 6| Step: 4
Training loss: 1.9261552095413208
Validation loss: 2.1068158547083535

Epoch: 6| Step: 5
Training loss: 2.5972914695739746
Validation loss: 2.120832006136576

Epoch: 6| Step: 6
Training loss: 1.9861953258514404
Validation loss: 2.120209753513336

Epoch: 6| Step: 7
Training loss: 1.9411234855651855
Validation loss: 2.1425514221191406

Epoch: 6| Step: 8
Training loss: 1.7367467880249023
Validation loss: 2.1416690945625305

Epoch: 6| Step: 9
Training loss: 1.7709684371948242
Validation loss: 2.1474244594573975

Epoch: 6| Step: 10
Training loss: 1.840333342552185
Validation loss: 2.1493280132611594

Epoch: 6| Step: 11
Training loss: 1.6412140130996704
Validation loss: 2.162163178126017

Epoch: 6| Step: 12
Training loss: 2.222025156021118
Validation loss: 2.143206834793091

Epoch: 6| Step: 13
Training loss: 1.7733030319213867
Validation loss: 2.146054824193319

Epoch: 213| Step: 0
Training loss: 2.123603343963623
Validation loss: 2.15444282690684

Epoch: 6| Step: 1
Training loss: 1.8376141786575317
Validation loss: 2.141856292883555

Epoch: 6| Step: 2
Training loss: 2.3858697414398193
Validation loss: 2.126834809780121

Epoch: 6| Step: 3
Training loss: 1.8523025512695312
Validation loss: 2.1425302227338157

Epoch: 6| Step: 4
Training loss: 2.0261802673339844
Validation loss: 2.1551500360171

Epoch: 6| Step: 5
Training loss: 1.2806591987609863
Validation loss: 2.155162254969279

Epoch: 6| Step: 6
Training loss: 2.1361241340637207
Validation loss: 2.1548191706339517

Epoch: 6| Step: 7
Training loss: 1.4860985279083252
Validation loss: 2.153093675772349

Epoch: 6| Step: 8
Training loss: 2.041635513305664
Validation loss: 2.1466241081555686

Epoch: 6| Step: 9
Training loss: 1.4711169004440308
Validation loss: 2.16157865524292

Epoch: 6| Step: 10
Training loss: 2.0826973915100098
Validation loss: 2.174296816190084

Epoch: 6| Step: 11
Training loss: 1.4440982341766357
Validation loss: 2.1513702074686685

Epoch: 6| Step: 12
Training loss: 1.7257161140441895
Validation loss: 2.1584090987841287

Epoch: 6| Step: 13
Training loss: 2.452655076980591
Validation loss: 2.185579021771749

Epoch: 214| Step: 0
Training loss: 1.602791428565979
Validation loss: 2.159435431162516

Epoch: 6| Step: 1
Training loss: 1.7043447494506836
Validation loss: 2.1845876773198447

Epoch: 6| Step: 2
Training loss: 2.1288537979125977
Validation loss: 2.1614871819814048

Epoch: 6| Step: 3
Training loss: 1.7143454551696777
Validation loss: 2.1730475425720215

Epoch: 6| Step: 4
Training loss: 1.6381449699401855
Validation loss: 2.176887492338816

Epoch: 6| Step: 5
Training loss: 1.608597993850708
Validation loss: 2.1854167183240256

Epoch: 6| Step: 6
Training loss: 2.3191003799438477
Validation loss: 2.1772860288619995

Epoch: 6| Step: 7
Training loss: 2.3392910957336426
Validation loss: 2.197950621445974

Epoch: 6| Step: 8
Training loss: 1.8685184717178345
Validation loss: 2.1662638187408447

Epoch: 6| Step: 9
Training loss: 2.1496901512145996
Validation loss: 2.1802651484807334

Epoch: 6| Step: 10
Training loss: 2.434441566467285
Validation loss: 2.1793188651402793

Epoch: 6| Step: 11
Training loss: 2.0366642475128174
Validation loss: 2.1801287134488425

Epoch: 6| Step: 12
Training loss: 1.7474185228347778
Validation loss: 2.1723802288373313

Epoch: 6| Step: 13
Training loss: 1.3334417343139648
Validation loss: 2.1468461950620017

Epoch: 215| Step: 0
Training loss: 1.5720524787902832
Validation loss: 2.1390116810798645

Epoch: 6| Step: 1
Training loss: 1.4378494024276733
Validation loss: 2.127083162466685

Epoch: 6| Step: 2
Training loss: 2.640194892883301
Validation loss: 2.1333678364753723

Epoch: 6| Step: 3
Training loss: 2.419736862182617
Validation loss: 2.1325474778811135

Epoch: 6| Step: 4
Training loss: 1.9748400449752808
Validation loss: 2.132739504178365

Epoch: 6| Step: 5
Training loss: 1.7282309532165527
Validation loss: 2.132399320602417

Epoch: 6| Step: 6
Training loss: 1.6795568466186523
Validation loss: 2.131593624750773

Epoch: 6| Step: 7
Training loss: 1.9921711683273315
Validation loss: 2.1346499721209207

Epoch: 6| Step: 8
Training loss: 1.3795135021209717
Validation loss: 2.1250380078951516

Epoch: 6| Step: 9
Training loss: 2.2065582275390625
Validation loss: 2.13747376203537

Epoch: 6| Step: 10
Training loss: 1.8809667825698853
Validation loss: 2.133894224961599

Epoch: 6| Step: 11
Training loss: 1.3098809719085693
Validation loss: 2.117529034614563

Epoch: 6| Step: 12
Training loss: 2.0659055709838867
Validation loss: 2.131718615690867

Epoch: 6| Step: 13
Training loss: 2.168647527694702
Validation loss: 2.1236876845359802

Epoch: 216| Step: 0
Training loss: 2.970438241958618
Validation loss: 2.1305561463038125

Epoch: 6| Step: 1
Training loss: 1.5472228527069092
Validation loss: 2.1358747482299805

Epoch: 6| Step: 2
Training loss: 2.1791863441467285
Validation loss: 2.130575974782308

Epoch: 6| Step: 3
Training loss: 1.568835973739624
Validation loss: 2.1397675474484763

Epoch: 6| Step: 4
Training loss: 1.860639214515686
Validation loss: 2.146822929382324

Epoch: 6| Step: 5
Training loss: 1.4420363903045654
Validation loss: 2.1548035542170205

Epoch: 6| Step: 6
Training loss: 2.1208314895629883
Validation loss: 2.148247500260671

Epoch: 6| Step: 7
Training loss: 2.08317232131958
Validation loss: 2.1414825518925986

Epoch: 6| Step: 8
Training loss: 1.8370344638824463
Validation loss: 2.1606682538986206

Epoch: 6| Step: 9
Training loss: 1.9078878164291382
Validation loss: 2.1501444578170776

Epoch: 6| Step: 10
Training loss: 2.2893199920654297
Validation loss: 2.1579767068227134

Epoch: 6| Step: 11
Training loss: 1.558236837387085
Validation loss: 2.166159709294637

Epoch: 6| Step: 12
Training loss: 1.7247477769851685
Validation loss: 2.157504975795746

Epoch: 6| Step: 13
Training loss: 1.252106785774231
Validation loss: 2.1644233862559

Epoch: 217| Step: 0
Training loss: 1.699291706085205
Validation loss: 2.1517086227734885

Epoch: 6| Step: 1
Training loss: 1.7869277000427246
Validation loss: 2.146692236264547

Epoch: 6| Step: 2
Training loss: 2.046541213989258
Validation loss: 2.1508318980534873

Epoch: 6| Step: 3
Training loss: 1.2590336799621582
Validation loss: 2.1456306179364524

Epoch: 6| Step: 4
Training loss: 1.582263469696045
Validation loss: 2.1295230388641357

Epoch: 6| Step: 5
Training loss: 1.5406467914581299
Validation loss: 2.1380119919776917

Epoch: 6| Step: 6
Training loss: 2.102628707885742
Validation loss: 2.1440608898798623

Epoch: 6| Step: 7
Training loss: 2.133777141571045
Validation loss: 2.1333948572476706

Epoch: 6| Step: 8
Training loss: 2.0925071239471436
Validation loss: 2.1491990089416504

Epoch: 6| Step: 9
Training loss: 2.1374642848968506
Validation loss: 2.1404521465301514

Epoch: 6| Step: 10
Training loss: 2.463574171066284
Validation loss: 2.1436471343040466

Epoch: 6| Step: 11
Training loss: 1.990504503250122
Validation loss: 2.1456922690073648

Epoch: 6| Step: 12
Training loss: 1.9651364088058472
Validation loss: 2.128978212674459

Epoch: 6| Step: 13
Training loss: 1.7922072410583496
Validation loss: 2.149793883164724

Epoch: 218| Step: 0
Training loss: 1.5378751754760742
Validation loss: 2.147561490535736

Epoch: 6| Step: 1
Training loss: 2.3239927291870117
Validation loss: 2.1663978099823

Epoch: 6| Step: 2
Training loss: 1.854414939880371
Validation loss: 2.1617554227511087

Epoch: 6| Step: 3
Training loss: 1.756706953048706
Validation loss: 2.1701773007710776

Epoch: 6| Step: 4
Training loss: 1.7930598258972168
Validation loss: 2.1449366410573325

Epoch: 6| Step: 5
Training loss: 1.697100281715393
Validation loss: 2.158022145430247

Epoch: 6| Step: 6
Training loss: 2.497124195098877
Validation loss: 2.1448697646458945

Epoch: 6| Step: 7
Training loss: 1.3314547538757324
Validation loss: 2.1503121654192605

Epoch: 6| Step: 8
Training loss: 1.550616979598999
Validation loss: 2.157382905483246

Epoch: 6| Step: 9
Training loss: 2.3350486755371094
Validation loss: 2.1711692412694297

Epoch: 6| Step: 10
Training loss: 2.1957318782806396
Validation loss: 2.172025760014852

Epoch: 6| Step: 11
Training loss: 1.466820478439331
Validation loss: 2.1645429730415344

Epoch: 6| Step: 12
Training loss: 1.7653976678848267
Validation loss: 2.143051862716675

Epoch: 6| Step: 13
Training loss: 2.2175564765930176
Validation loss: 2.16651713848114

Epoch: 219| Step: 0
Training loss: 2.607088327407837
Validation loss: 2.1489997506141663

Epoch: 6| Step: 1
Training loss: 1.9867398738861084
Validation loss: 2.149014870325724

Epoch: 6| Step: 2
Training loss: 2.5157997608184814
Validation loss: 2.1345086693763733

Epoch: 6| Step: 3
Training loss: 1.6469876766204834
Validation loss: 2.1478077371915183

Epoch: 6| Step: 4
Training loss: 1.579571008682251
Validation loss: 2.1477176547050476

Epoch: 6| Step: 5
Training loss: 1.455518364906311
Validation loss: 2.150375405947367

Epoch: 6| Step: 6
Training loss: 2.5364389419555664
Validation loss: 2.161019821961721

Epoch: 6| Step: 7
Training loss: 1.6490793228149414
Validation loss: 2.151736776034037

Epoch: 6| Step: 8
Training loss: 2.3474783897399902
Validation loss: 2.1905487775802612

Epoch: 6| Step: 9
Training loss: 1.6558244228363037
Validation loss: 2.165018697579702

Epoch: 6| Step: 10
Training loss: 1.6200095415115356
Validation loss: 2.1702011028925576

Epoch: 6| Step: 11
Training loss: 1.581405520439148
Validation loss: 2.1515219608942666

Epoch: 6| Step: 12
Training loss: 0.9388347268104553
Validation loss: 2.16058079401652

Epoch: 6| Step: 13
Training loss: 1.9528864622116089
Validation loss: 2.1533164978027344

Epoch: 220| Step: 0
Training loss: 1.3486803770065308
Validation loss: 2.160355826218923

Epoch: 6| Step: 1
Training loss: 1.629969835281372
Validation loss: 2.1537323594093323

Epoch: 6| Step: 2
Training loss: 1.8362324237823486
Validation loss: 2.1313202381134033

Epoch: 6| Step: 3
Training loss: 2.254075527191162
Validation loss: 2.1566631197929382

Epoch: 6| Step: 4
Training loss: 1.612973928451538
Validation loss: 2.1473442713419595

Epoch: 6| Step: 5
Training loss: 1.9777941703796387
Validation loss: 2.1402716437975564

Epoch: 6| Step: 6
Training loss: 1.8717514276504517
Validation loss: 2.1438883940378823

Epoch: 6| Step: 7
Training loss: 2.351456642150879
Validation loss: 2.156802217165629

Epoch: 6| Step: 8
Training loss: 2.32631778717041
Validation loss: 2.139745851357778

Epoch: 6| Step: 9
Training loss: 1.8096779584884644
Validation loss: 2.157221039136251

Epoch: 6| Step: 10
Training loss: 2.294989824295044
Validation loss: 2.1499690214792886

Epoch: 6| Step: 11
Training loss: 1.8084750175476074
Validation loss: 2.1501179138819375

Epoch: 6| Step: 12
Training loss: 1.5898672342300415
Validation loss: 2.1504432360331216

Epoch: 6| Step: 13
Training loss: 1.6447657346725464
Validation loss: 2.148335953553518

Epoch: 221| Step: 0
Training loss: 1.5078420639038086
Validation loss: 2.161616047223409

Epoch: 6| Step: 1
Training loss: 2.0988168716430664
Validation loss: 2.1436551213264465

Epoch: 6| Step: 2
Training loss: 1.3853785991668701
Validation loss: 2.150920550028483

Epoch: 6| Step: 3
Training loss: 2.218736410140991
Validation loss: 2.1679680148760476

Epoch: 6| Step: 4
Training loss: 2.5633132457733154
Validation loss: 2.1684632500012717

Epoch: 6| Step: 5
Training loss: 2.1128923892974854
Validation loss: 2.1637612779935202

Epoch: 6| Step: 6
Training loss: 1.6913886070251465
Validation loss: 2.151051163673401

Epoch: 6| Step: 7
Training loss: 2.1553895473480225
Validation loss: 2.1621423959732056

Epoch: 6| Step: 8
Training loss: 1.3282965421676636
Validation loss: 2.154190957546234

Epoch: 6| Step: 9
Training loss: 2.145873546600342
Validation loss: 2.15136190255483

Epoch: 6| Step: 10
Training loss: 1.6154870986938477
Validation loss: 2.170447508494059

Epoch: 6| Step: 11
Training loss: 1.297794222831726
Validation loss: 2.174563944339752

Epoch: 6| Step: 12
Training loss: 2.661109209060669
Validation loss: 2.1554619868596396

Epoch: 6| Step: 13
Training loss: 1.7951029539108276
Validation loss: 2.163551171620687

Epoch: 222| Step: 0
Training loss: 1.9355409145355225
Validation loss: 2.14626673857371

Epoch: 6| Step: 1
Training loss: 2.186223030090332
Validation loss: 2.1508366664250693

Epoch: 6| Step: 2
Training loss: 1.783172607421875
Validation loss: 2.150600870450338

Epoch: 6| Step: 3
Training loss: 1.9136743545532227
Validation loss: 2.134517331918081

Epoch: 6| Step: 4
Training loss: 1.8290529251098633
Validation loss: 2.151266177495321

Epoch: 6| Step: 5
Training loss: 2.08764386177063
Validation loss: 2.1279784440994263

Epoch: 6| Step: 6
Training loss: 2.001248598098755
Validation loss: 2.128405968348185

Epoch: 6| Step: 7
Training loss: 2.530421733856201
Validation loss: 2.1430766383806863

Epoch: 6| Step: 8
Training loss: 1.7385189533233643
Validation loss: 2.11952805519104

Epoch: 6| Step: 9
Training loss: 1.532222032546997
Validation loss: 2.1247439980506897

Epoch: 6| Step: 10
Training loss: 1.8888226747512817
Validation loss: 2.1387946009635925

Epoch: 6| Step: 11
Training loss: 1.922932744026184
Validation loss: 2.1434196631113687

Epoch: 6| Step: 12
Training loss: 1.6227319240570068
Validation loss: 2.144497354825338

Epoch: 6| Step: 13
Training loss: 1.4984829425811768
Validation loss: 2.157225549221039

Epoch: 223| Step: 0
Training loss: 1.9032983779907227
Validation loss: 2.1611299316088357

Epoch: 6| Step: 1
Training loss: 2.361082077026367
Validation loss: 2.146092414855957

Epoch: 6| Step: 2
Training loss: 1.6671910285949707
Validation loss: 2.159955700238546

Epoch: 6| Step: 3
Training loss: 1.5871446132659912
Validation loss: 2.161353131135305

Epoch: 6| Step: 4
Training loss: 1.8673675060272217
Validation loss: 2.1606942812601724

Epoch: 6| Step: 5
Training loss: 2.3609423637390137
Validation loss: 2.157347083091736

Epoch: 6| Step: 6
Training loss: 1.5615756511688232
Validation loss: 2.1756834189097085

Epoch: 6| Step: 7
Training loss: 2.5843160152435303
Validation loss: 2.1577120621999106

Epoch: 6| Step: 8
Training loss: 1.8480998277664185
Validation loss: 2.142858564853668

Epoch: 6| Step: 9
Training loss: 1.9894858598709106
Validation loss: 2.170406142870585

Epoch: 6| Step: 10
Training loss: 1.28477144241333
Validation loss: 2.1658551891644797

Epoch: 6| Step: 11
Training loss: 1.7546603679656982
Validation loss: 2.1590412060419717

Epoch: 6| Step: 12
Training loss: 1.9962759017944336
Validation loss: 2.1589486400286355

Epoch: 6| Step: 13
Training loss: 1.4401495456695557
Validation loss: 2.1435914635658264

Epoch: 224| Step: 0
Training loss: 1.6776349544525146
Validation loss: 2.1458381017049155

Epoch: 6| Step: 1
Training loss: 1.9858591556549072
Validation loss: 2.151650130748749

Epoch: 6| Step: 2
Training loss: 1.8228557109832764
Validation loss: 2.157549500465393

Epoch: 6| Step: 3
Training loss: 2.329402446746826
Validation loss: 2.154742181301117

Epoch: 6| Step: 4
Training loss: 2.1563196182250977
Validation loss: 2.1448216835657754

Epoch: 6| Step: 5
Training loss: 2.187591075897217
Validation loss: 2.1406365434328714

Epoch: 6| Step: 6
Training loss: 1.3484148979187012
Validation loss: 2.1444520950317383

Epoch: 6| Step: 7
Training loss: 1.741182804107666
Validation loss: 2.152223209540049

Epoch: 6| Step: 8
Training loss: 1.639664888381958
Validation loss: 2.149486462275187

Epoch: 6| Step: 9
Training loss: 2.0917410850524902
Validation loss: 2.154492994149526

Epoch: 6| Step: 10
Training loss: 1.5692106485366821
Validation loss: 2.1562934120496116

Epoch: 6| Step: 11
Training loss: 1.8840827941894531
Validation loss: 2.1679172118504844

Epoch: 6| Step: 12
Training loss: 1.6378434896469116
Validation loss: 2.172720491886139

Epoch: 6| Step: 13
Training loss: 2.065753936767578
Validation loss: 2.162079612414042

Epoch: 225| Step: 0
Training loss: 1.51806640625
Validation loss: 2.164499282836914

Epoch: 6| Step: 1
Training loss: 1.8417036533355713
Validation loss: 2.184234698613485

Epoch: 6| Step: 2
Training loss: 1.7986743450164795
Validation loss: 2.170804818471273

Epoch: 6| Step: 3
Training loss: 1.312525987625122
Validation loss: 2.1714634895324707

Epoch: 6| Step: 4
Training loss: 2.301600694656372
Validation loss: 2.150132099787394

Epoch: 6| Step: 5
Training loss: 1.3726222515106201
Validation loss: 2.168246845404307

Epoch: 6| Step: 6
Training loss: 2.538389205932617
Validation loss: 2.170356055100759

Epoch: 6| Step: 7
Training loss: 1.9476191997528076
Validation loss: 2.1754038333892822

Epoch: 6| Step: 8
Training loss: 1.8835258483886719
Validation loss: 2.160667280356089

Epoch: 6| Step: 9
Training loss: 1.9695647954940796
Validation loss: 2.1717889308929443

Epoch: 6| Step: 10
Training loss: 1.6539757251739502
Validation loss: 2.164663334687551

Epoch: 6| Step: 11
Training loss: 1.4979264736175537
Validation loss: 2.1595452030499778

Epoch: 6| Step: 12
Training loss: 1.5890443325042725
Validation loss: 2.1472976009051004

Epoch: 6| Step: 13
Training loss: 2.995887517929077
Validation loss: 2.1361645261446633

Epoch: 226| Step: 0
Training loss: 2.0184214115142822
Validation loss: 2.1304805080095925

Epoch: 6| Step: 1
Training loss: 2.329885244369507
Validation loss: 2.126845419406891

Epoch: 6| Step: 2
Training loss: 1.968913197517395
Validation loss: 2.151573956012726

Epoch: 6| Step: 3
Training loss: 2.3033406734466553
Validation loss: 2.1383830308914185

Epoch: 6| Step: 4
Training loss: 1.5618360042572021
Validation loss: 2.153234601020813

Epoch: 6| Step: 5
Training loss: 2.216360092163086
Validation loss: 2.1657586097717285

Epoch: 6| Step: 6
Training loss: 1.548542857170105
Validation loss: 2.1502069433530173

Epoch: 6| Step: 7
Training loss: 2.401553153991699
Validation loss: 2.1603859464327493

Epoch: 6| Step: 8
Training loss: 1.3146804571151733
Validation loss: 2.154674748579661

Epoch: 6| Step: 9
Training loss: 1.3448244333267212
Validation loss: 2.162337283293406

Epoch: 6| Step: 10
Training loss: 1.6582975387573242
Validation loss: 2.1726237336794534

Epoch: 6| Step: 11
Training loss: 2.057126522064209
Validation loss: 2.15650208791097

Epoch: 6| Step: 12
Training loss: 1.4176218509674072
Validation loss: 2.171194314956665

Epoch: 6| Step: 13
Training loss: 2.022543430328369
Validation loss: 2.160220285256704

Epoch: 227| Step: 0
Training loss: 1.5611704587936401
Validation loss: 2.153249144554138

Epoch: 6| Step: 1
Training loss: 2.2845239639282227
Validation loss: 2.149400055408478

Epoch: 6| Step: 2
Training loss: 2.1140685081481934
Validation loss: 2.1482278307278952

Epoch: 6| Step: 3
Training loss: 2.420915126800537
Validation loss: 2.1371108889579773

Epoch: 6| Step: 4
Training loss: 2.132078170776367
Validation loss: 2.1593423088391623

Epoch: 6| Step: 5
Training loss: 1.6085137128829956
Validation loss: 2.1769631703694663

Epoch: 6| Step: 6
Training loss: 1.4743099212646484
Validation loss: 2.170274496078491

Epoch: 6| Step: 7
Training loss: 2.0224428176879883
Validation loss: 2.162914971510569

Epoch: 6| Step: 8
Training loss: 1.4049955606460571
Validation loss: 2.169808268547058

Epoch: 6| Step: 9
Training loss: 2.57658052444458
Validation loss: 2.17224383354187

Epoch: 6| Step: 10
Training loss: 1.7119383811950684
Validation loss: 2.162362356980642

Epoch: 6| Step: 11
Training loss: 1.5301625728607178
Validation loss: 2.1803625424702964

Epoch: 6| Step: 12
Training loss: 1.502903699874878
Validation loss: 2.1794886191685996

Epoch: 6| Step: 13
Training loss: 2.012753486633301
Validation loss: 2.153548002243042

Epoch: 228| Step: 0
Training loss: 2.2116427421569824
Validation loss: 2.150359034538269

Epoch: 6| Step: 1
Training loss: 1.4783200025558472
Validation loss: 2.1474559903144836

Epoch: 6| Step: 2
Training loss: 2.3767247200012207
Validation loss: 2.162246306737264

Epoch: 6| Step: 3
Training loss: 2.3776683807373047
Validation loss: 2.1621352235476174

Epoch: 6| Step: 4
Training loss: 1.814880609512329
Validation loss: 2.137235184510549

Epoch: 6| Step: 5
Training loss: 2.0396482944488525
Validation loss: 2.131686290105184

Epoch: 6| Step: 6
Training loss: 1.814816951751709
Validation loss: 2.1559940179189048

Epoch: 6| Step: 7
Training loss: 1.5698564052581787
Validation loss: 2.1628815730412803

Epoch: 6| Step: 8
Training loss: 1.3204128742218018
Validation loss: 2.1548967361450195

Epoch: 6| Step: 9
Training loss: 1.6294655799865723
Validation loss: 2.158509135246277

Epoch: 6| Step: 10
Training loss: 2.399081230163574
Validation loss: 2.1600587169329324

Epoch: 6| Step: 11
Training loss: 1.6272237300872803
Validation loss: 2.1430104772249856

Epoch: 6| Step: 12
Training loss: 1.8462779521942139
Validation loss: 2.160481254259745

Epoch: 6| Step: 13
Training loss: 1.987774133682251
Validation loss: 2.176031231880188

Epoch: 229| Step: 0
Training loss: 1.7508931159973145
Validation loss: 2.1873611013094583

Epoch: 6| Step: 1
Training loss: 1.8338066339492798
Validation loss: 2.183639387289683

Epoch: 6| Step: 2
Training loss: 1.9103724956512451
Validation loss: 2.1733515659968057

Epoch: 6| Step: 3
Training loss: 1.6070396900177002
Validation loss: 2.179625948270162

Epoch: 6| Step: 4
Training loss: 1.7780553102493286
Validation loss: 2.159752686818441

Epoch: 6| Step: 5
Training loss: 1.7086198329925537
Validation loss: 2.177779793739319

Epoch: 6| Step: 6
Training loss: 2.460925579071045
Validation loss: 2.1544803579648337

Epoch: 6| Step: 7
Training loss: 2.397113561630249
Validation loss: 2.183768332004547

Epoch: 6| Step: 8
Training loss: 1.915198802947998
Validation loss: 2.1720359325408936

Epoch: 6| Step: 9
Training loss: 1.8076491355895996
Validation loss: 2.1528385877609253

Epoch: 6| Step: 10
Training loss: 1.9815961122512817
Validation loss: 2.1693697373072305

Epoch: 6| Step: 11
Training loss: 1.7073087692260742
Validation loss: 2.1652760108311973

Epoch: 6| Step: 12
Training loss: 1.9387601613998413
Validation loss: 2.165729741255442

Epoch: 6| Step: 13
Training loss: 1.3085510730743408
Validation loss: 2.1465125481287637

Epoch: 230| Step: 0
Training loss: 2.397036552429199
Validation loss: 2.161747694015503

Epoch: 6| Step: 1
Training loss: 1.8154807090759277
Validation loss: 2.156808356444041

Epoch: 6| Step: 2
Training loss: 1.8227224349975586
Validation loss: 2.161028345425924

Epoch: 6| Step: 3
Training loss: 2.4515838623046875
Validation loss: 2.1639888087908425

Epoch: 6| Step: 4
Training loss: 1.7901678085327148
Validation loss: 2.1655445297559104

Epoch: 6| Step: 5
Training loss: 2.583002805709839
Validation loss: 2.1849928895632424

Epoch: 6| Step: 6
Training loss: 1.4806785583496094
Validation loss: 2.1658517122268677

Epoch: 6| Step: 7
Training loss: 1.9948484897613525
Validation loss: 2.185783406098684

Epoch: 6| Step: 8
Training loss: 1.6054778099060059
Validation loss: 2.1877663135528564

Epoch: 6| Step: 9
Training loss: 1.4864288568496704
Validation loss: 2.1589327255884805

Epoch: 6| Step: 10
Training loss: 1.1450103521347046
Validation loss: 2.181175688902537

Epoch: 6| Step: 11
Training loss: 1.487485647201538
Validation loss: 2.1672341227531433

Epoch: 6| Step: 12
Training loss: 1.8588348627090454
Validation loss: 2.165212571620941

Epoch: 6| Step: 13
Training loss: 2.2647430896759033
Validation loss: 2.162398636341095

Epoch: 231| Step: 0
Training loss: 2.196366786956787
Validation loss: 2.1510319113731384

Epoch: 6| Step: 1
Training loss: 1.8256287574768066
Validation loss: 2.156740387280782

Epoch: 6| Step: 2
Training loss: 2.8488986492156982
Validation loss: 2.153139611085256

Epoch: 6| Step: 3
Training loss: 1.4778558015823364
Validation loss: 2.1485917369524636

Epoch: 6| Step: 4
Training loss: 2.4322333335876465
Validation loss: 2.1556841135025024

Epoch: 6| Step: 5
Training loss: 1.5544536113739014
Validation loss: 2.156101624170939

Epoch: 6| Step: 6
Training loss: 1.9352991580963135
Validation loss: 2.174019515514374

Epoch: 6| Step: 7
Training loss: 1.7585209608078003
Validation loss: 2.1590946316719055

Epoch: 6| Step: 8
Training loss: 2.07466721534729
Validation loss: 2.157048682371775

Epoch: 6| Step: 9
Training loss: 1.4907593727111816
Validation loss: 2.1566177010536194

Epoch: 6| Step: 10
Training loss: 1.9897047281265259
Validation loss: 2.1636075576146445

Epoch: 6| Step: 11
Training loss: 1.6422150135040283
Validation loss: 2.161940018335978

Epoch: 6| Step: 12
Training loss: 1.4157108068466187
Validation loss: 2.17216295003891

Epoch: 6| Step: 13
Training loss: 1.7445435523986816
Validation loss: 2.1713966131210327

Epoch: 232| Step: 0
Training loss: 2.2667908668518066
Validation loss: 2.1795953512191772

Epoch: 6| Step: 1
Training loss: 1.7838494777679443
Validation loss: 2.148248831431071

Epoch: 6| Step: 2
Training loss: 1.527846097946167
Validation loss: 2.145950436592102

Epoch: 6| Step: 3
Training loss: 2.509958505630493
Validation loss: 2.156995395819346

Epoch: 6| Step: 4
Training loss: 1.5245550870895386
Validation loss: 2.164164980252584

Epoch: 6| Step: 5
Training loss: 2.1927123069763184
Validation loss: 2.170664072036743

Epoch: 6| Step: 6
Training loss: 1.5827081203460693
Validation loss: 2.171900490919749

Epoch: 6| Step: 7
Training loss: 2.1544041633605957
Validation loss: 2.171208918094635

Epoch: 6| Step: 8
Training loss: 1.7919998168945312
Validation loss: 2.1855787436167398

Epoch: 6| Step: 9
Training loss: 1.8357806205749512
Validation loss: 2.1772207021713257

Epoch: 6| Step: 10
Training loss: 1.9528772830963135
Validation loss: 2.1768616437911987

Epoch: 6| Step: 11
Training loss: 1.669123649597168
Validation loss: 2.1773102283477783

Epoch: 6| Step: 12
Training loss: 1.417372703552246
Validation loss: 2.1661341190338135

Epoch: 6| Step: 13
Training loss: 1.6141999959945679
Validation loss: 2.198355217774709

Epoch: 233| Step: 0
Training loss: 2.6957364082336426
Validation loss: 2.173689305782318

Epoch: 6| Step: 1
Training loss: 1.5738089084625244
Validation loss: 2.1775614619255066

Epoch: 6| Step: 2
Training loss: 1.6740343570709229
Validation loss: 2.180172244707743

Epoch: 6| Step: 3
Training loss: 2.23488187789917
Validation loss: 2.181676506996155

Epoch: 6| Step: 4
Training loss: 2.0964341163635254
Validation loss: 2.160967449347178

Epoch: 6| Step: 5
Training loss: 1.6193344593048096
Validation loss: 2.159716804822286

Epoch: 6| Step: 6
Training loss: 1.6903111934661865
Validation loss: 2.197846313317617

Epoch: 6| Step: 7
Training loss: 2.3272032737731934
Validation loss: 2.1855698029200235

Epoch: 6| Step: 8
Training loss: 2.2115845680236816
Validation loss: 2.1773255864779153

Epoch: 6| Step: 9
Training loss: 1.7124128341674805
Validation loss: 2.171652535597483

Epoch: 6| Step: 10
Training loss: 1.5770366191864014
Validation loss: 2.1317442059516907

Epoch: 6| Step: 11
Training loss: 1.053126335144043
Validation loss: 2.1398311058680215

Epoch: 6| Step: 12
Training loss: 2.214939594268799
Validation loss: 2.140862206617991

Epoch: 6| Step: 13
Training loss: 1.4118447303771973
Validation loss: 2.1586577693621316

Epoch: 234| Step: 0
Training loss: 2.3500242233276367
Validation loss: 2.1568824847539267

Epoch: 6| Step: 1
Training loss: 1.975163459777832
Validation loss: 2.140034337838491

Epoch: 6| Step: 2
Training loss: 1.6669145822525024
Validation loss: 2.1450754006703696

Epoch: 6| Step: 3
Training loss: 2.1247293949127197
Validation loss: 2.151354749997457

Epoch: 6| Step: 4
Training loss: 1.7045214176177979
Validation loss: 2.1459036270777383

Epoch: 6| Step: 5
Training loss: 1.6464762687683105
Validation loss: 2.154577453931173

Epoch: 6| Step: 6
Training loss: 2.021251916885376
Validation loss: 2.1460843880971274

Epoch: 6| Step: 7
Training loss: 1.7932525873184204
Validation loss: 2.160916527112325

Epoch: 6| Step: 8
Training loss: 2.636384963989258
Validation loss: 2.158661723136902

Epoch: 6| Step: 9
Training loss: 1.1322849988937378
Validation loss: 2.148464262485504

Epoch: 6| Step: 10
Training loss: 1.6109586954116821
Validation loss: 2.1471315821011863

Epoch: 6| Step: 11
Training loss: 1.5066003799438477
Validation loss: 2.1504722436269126

Epoch: 6| Step: 12
Training loss: 1.8739190101623535
Validation loss: 2.1372417211532593

Epoch: 6| Step: 13
Training loss: 2.605753183364868
Validation loss: 2.135079562664032

Epoch: 235| Step: 0
Training loss: 2.0349183082580566
Validation loss: 2.1532464623451233

Epoch: 6| Step: 1
Training loss: 1.9011932611465454
Validation loss: 2.1408518155415854

Epoch: 6| Step: 2
Training loss: 1.9955852031707764
Validation loss: 2.153327922026316

Epoch: 6| Step: 3
Training loss: 2.188042163848877
Validation loss: 2.1533162593841553

Epoch: 6| Step: 4
Training loss: 1.3276317119598389
Validation loss: 2.1574281255404153

Epoch: 6| Step: 5
Training loss: 0.7733442783355713
Validation loss: 2.14848659435908

Epoch: 6| Step: 6
Training loss: 2.1115782260894775
Validation loss: 2.1568791468938193

Epoch: 6| Step: 7
Training loss: 1.8106012344360352
Validation loss: 2.1445352435112

Epoch: 6| Step: 8
Training loss: 2.3626222610473633
Validation loss: 2.164692461490631

Epoch: 6| Step: 9
Training loss: 1.9528473615646362
Validation loss: 2.1525542537371316

Epoch: 6| Step: 10
Training loss: 2.139329433441162
Validation loss: 2.1592474778493247

Epoch: 6| Step: 11
Training loss: 1.9896796941757202
Validation loss: 2.1424678762753806

Epoch: 6| Step: 12
Training loss: 1.7568998336791992
Validation loss: 2.1578553120295205

Epoch: 6| Step: 13
Training loss: 1.655362606048584
Validation loss: 2.1672522823015847

Epoch: 236| Step: 0
Training loss: 1.885191798210144
Validation loss: 2.1543387373288474

Epoch: 6| Step: 1
Training loss: 1.8862115144729614
Validation loss: 2.166895111401876

Epoch: 6| Step: 2
Training loss: 1.7681546211242676
Validation loss: 2.165407677491506

Epoch: 6| Step: 3
Training loss: 1.9387975931167603
Validation loss: 2.177202800909678

Epoch: 6| Step: 4
Training loss: 1.7793023586273193
Validation loss: 2.1763397256533303

Epoch: 6| Step: 5
Training loss: 1.8557273149490356
Validation loss: 2.186105807622274

Epoch: 6| Step: 6
Training loss: 1.8200597763061523
Validation loss: 2.188785672187805

Epoch: 6| Step: 7
Training loss: 1.8880250453948975
Validation loss: 2.1812350749969482

Epoch: 6| Step: 8
Training loss: 2.0167088508605957
Validation loss: 2.18283873796463

Epoch: 6| Step: 9
Training loss: 1.9733415842056274
Validation loss: 2.1797024408976235

Epoch: 6| Step: 10
Training loss: 2.1227147579193115
Validation loss: 2.185284733772278

Epoch: 6| Step: 11
Training loss: 2.1437480449676514
Validation loss: 2.183263083299001

Epoch: 6| Step: 12
Training loss: 1.7939872741699219
Validation loss: 2.1659680604934692

Epoch: 6| Step: 13
Training loss: 1.7180407047271729
Validation loss: 2.159385542074839

Epoch: 237| Step: 0
Training loss: 1.823486089706421
Validation loss: 2.1381526788075766

Epoch: 6| Step: 1
Training loss: 1.803678035736084
Validation loss: 2.1505895256996155

Epoch: 6| Step: 2
Training loss: 1.329803228378296
Validation loss: 2.147297739982605

Epoch: 6| Step: 3
Training loss: 2.0236384868621826
Validation loss: 2.157320201396942

Epoch: 6| Step: 4
Training loss: 2.521007537841797
Validation loss: 2.138230840365092

Epoch: 6| Step: 5
Training loss: 1.6611937284469604
Validation loss: 2.1546700994173684

Epoch: 6| Step: 6
Training loss: 1.311044454574585
Validation loss: 2.1490363677342734

Epoch: 6| Step: 7
Training loss: 1.9057087898254395
Validation loss: 2.1637231906255088

Epoch: 6| Step: 8
Training loss: 1.8081741333007812
Validation loss: 2.1680649717648826

Epoch: 6| Step: 9
Training loss: 1.4887073040008545
Validation loss: 2.1462677717208862

Epoch: 6| Step: 10
Training loss: 1.668731927871704
Validation loss: 2.1914615432421365

Epoch: 6| Step: 11
Training loss: 2.73831844329834
Validation loss: 2.1876354614893594

Epoch: 6| Step: 12
Training loss: 1.7587852478027344
Validation loss: 2.1949514349301658

Epoch: 6| Step: 13
Training loss: 2.246699571609497
Validation loss: 2.1891249219576516

Epoch: 238| Step: 0
Training loss: 1.7877609729766846
Validation loss: 2.190015276273092

Epoch: 6| Step: 1
Training loss: 1.7743244171142578
Validation loss: 2.1902852058410645

Epoch: 6| Step: 2
Training loss: 1.6435061693191528
Validation loss: 2.207450211048126

Epoch: 6| Step: 3
Training loss: 1.9445903301239014
Validation loss: 2.1969620188077292

Epoch: 6| Step: 4
Training loss: 2.3110995292663574
Validation loss: 2.20411209265391

Epoch: 6| Step: 5
Training loss: 1.2803242206573486
Validation loss: 2.1913298964500427

Epoch: 6| Step: 6
Training loss: 1.9031779766082764
Validation loss: 2.194752335548401

Epoch: 6| Step: 7
Training loss: 2.4600138664245605
Validation loss: 2.1811785101890564

Epoch: 6| Step: 8
Training loss: 1.9388012886047363
Validation loss: 2.191998839378357

Epoch: 6| Step: 9
Training loss: 1.570148229598999
Validation loss: 2.1822131872177124

Epoch: 6| Step: 10
Training loss: 1.7262998819351196
Validation loss: 2.1680386662483215

Epoch: 6| Step: 11
Training loss: 1.9113247394561768
Validation loss: 2.152446925640106

Epoch: 6| Step: 12
Training loss: 1.85701322555542
Validation loss: 2.164366602897644

Epoch: 6| Step: 13
Training loss: 1.7198572158813477
Validation loss: 2.1511810620625815

Epoch: 239| Step: 0
Training loss: 2.0234971046447754
Validation loss: 2.1711491346359253

Epoch: 6| Step: 1
Training loss: 2.080108165740967
Validation loss: 2.1896517078081765

Epoch: 6| Step: 2
Training loss: 2.037797212600708
Validation loss: 2.1907687187194824

Epoch: 6| Step: 3
Training loss: 1.2207372188568115
Validation loss: 2.1998348236083984

Epoch: 6| Step: 4
Training loss: 1.7380932569503784
Validation loss: 2.2175597151120505

Epoch: 6| Step: 5
Training loss: 1.3129949569702148
Validation loss: 2.199856241544088

Epoch: 6| Step: 6
Training loss: 2.412909984588623
Validation loss: 2.200299104054769

Epoch: 6| Step: 7
Training loss: 2.1040754318237305
Validation loss: 2.201063394546509

Epoch: 6| Step: 8
Training loss: 2.0688059329986572
Validation loss: 2.2168507973353067

Epoch: 6| Step: 9
Training loss: 2.0553152561187744
Validation loss: 2.2087812225023904

Epoch: 6| Step: 10
Training loss: 1.8874198198318481
Validation loss: 2.2004264990488687

Epoch: 6| Step: 11
Training loss: 1.614593744277954
Validation loss: 2.1955344478289285

Epoch: 6| Step: 12
Training loss: 1.8660316467285156
Validation loss: 2.2020121216773987

Epoch: 6| Step: 13
Training loss: 1.0276023149490356
Validation loss: 2.186967213948568

Epoch: 240| Step: 0
Training loss: 1.4141896963119507
Validation loss: 2.204194267590841

Epoch: 6| Step: 1
Training loss: 1.8796948194503784
Validation loss: 2.1637179454167685

Epoch: 6| Step: 2
Training loss: 1.883482575416565
Validation loss: 2.1530109445254006

Epoch: 6| Step: 3
Training loss: 1.6964359283447266
Validation loss: 2.190856715043386

Epoch: 6| Step: 4
Training loss: 1.4120535850524902
Validation loss: 2.1885382930437722

Epoch: 6| Step: 5
Training loss: 1.8428277969360352
Validation loss: 2.18450003862381

Epoch: 6| Step: 6
Training loss: 1.8054814338684082
Validation loss: 2.163397749265035

Epoch: 6| Step: 7
Training loss: 1.812098503112793
Validation loss: 2.1617711385091147

Epoch: 6| Step: 8
Training loss: 3.037350654602051
Validation loss: 2.1721008817354837

Epoch: 6| Step: 9
Training loss: 1.7164967060089111
Validation loss: 2.1728660265604653

Epoch: 6| Step: 10
Training loss: 1.8692271709442139
Validation loss: 2.1608684062957764

Epoch: 6| Step: 11
Training loss: 2.574079990386963
Validation loss: 2.14619247118632

Epoch: 6| Step: 12
Training loss: 1.4800822734832764
Validation loss: 2.1728792587916055

Epoch: 6| Step: 13
Training loss: 1.4194579124450684
Validation loss: 2.1606925328572593

Epoch: 241| Step: 0
Training loss: 1.9434629678726196
Validation loss: 2.175615211327871

Epoch: 6| Step: 1
Training loss: 2.078835964202881
Validation loss: 2.1740139921506247

Epoch: 6| Step: 2
Training loss: 2.6451902389526367
Validation loss: 2.20732973019282

Epoch: 6| Step: 3
Training loss: 2.1537303924560547
Validation loss: 2.1802738110224404

Epoch: 6| Step: 4
Training loss: 1.7507811784744263
Validation loss: 2.162363270918528

Epoch: 6| Step: 5
Training loss: 1.617445707321167
Validation loss: 2.1599841912587485

Epoch: 6| Step: 6
Training loss: 2.157245397567749
Validation loss: 2.165788988272349

Epoch: 6| Step: 7
Training loss: 1.720396637916565
Validation loss: 2.155986706415812

Epoch: 6| Step: 8
Training loss: 1.4616211652755737
Validation loss: 2.169131020704905

Epoch: 6| Step: 9
Training loss: 1.518265962600708
Validation loss: 2.1695444782574973

Epoch: 6| Step: 10
Training loss: 1.7381081581115723
Validation loss: 2.1652375857035318

Epoch: 6| Step: 11
Training loss: 1.8610246181488037
Validation loss: 2.1394246021906533

Epoch: 6| Step: 12
Training loss: 1.915540337562561
Validation loss: 2.154995242754618

Epoch: 6| Step: 13
Training loss: 1.793383002281189
Validation loss: 2.148341397444407

Epoch: 242| Step: 0
Training loss: 1.8158481121063232
Validation loss: 2.137508491675059

Epoch: 6| Step: 1
Training loss: 2.228641986846924
Validation loss: 2.138624588648478

Epoch: 6| Step: 2
Training loss: 2.126974582672119
Validation loss: 2.1267948547999063

Epoch: 6| Step: 3
Training loss: 2.4249980449676514
Validation loss: 2.1355347832043967

Epoch: 6| Step: 4
Training loss: 1.2566150426864624
Validation loss: 2.147229234377543

Epoch: 6| Step: 5
Training loss: 1.8850387334823608
Validation loss: 2.146148602167765

Epoch: 6| Step: 6
Training loss: 2.1446542739868164
Validation loss: 2.148326059182485

Epoch: 6| Step: 7
Training loss: 1.1825287342071533
Validation loss: 2.146960516770681

Epoch: 6| Step: 8
Training loss: 2.3102869987487793
Validation loss: 2.1566692193349204

Epoch: 6| Step: 9
Training loss: 2.033273935317993
Validation loss: 2.1484524607658386

Epoch: 6| Step: 10
Training loss: 1.7348840236663818
Validation loss: 2.1376734177271524

Epoch: 6| Step: 11
Training loss: 1.8705787658691406
Validation loss: 2.1489852468172708

Epoch: 6| Step: 12
Training loss: 1.9043617248535156
Validation loss: 2.152219295501709

Epoch: 6| Step: 13
Training loss: 1.3462936878204346
Validation loss: 2.142848869164785

Epoch: 243| Step: 0
Training loss: 1.9256186485290527
Validation loss: 2.1962722738583884

Epoch: 6| Step: 1
Training loss: 1.5654056072235107
Validation loss: 2.1889376441637673

Epoch: 6| Step: 2
Training loss: 1.8255493640899658
Validation loss: 2.200241963068644

Epoch: 6| Step: 3
Training loss: 1.6846479177474976
Validation loss: 2.210497876008352

Epoch: 6| Step: 4
Training loss: 1.633418321609497
Validation loss: 2.1973345081011453

Epoch: 6| Step: 5
Training loss: 1.6104224920272827
Validation loss: 2.1984618504842124

Epoch: 6| Step: 6
Training loss: 1.9431078433990479
Validation loss: 2.1876996755599976

Epoch: 6| Step: 7
Training loss: 1.7999101877212524
Validation loss: 2.1792667706807456

Epoch: 6| Step: 8
Training loss: 1.3881769180297852
Validation loss: 2.1772075096766152

Epoch: 6| Step: 9
Training loss: 1.460437297821045
Validation loss: 2.1745396852493286

Epoch: 6| Step: 10
Training loss: 1.7142512798309326
Validation loss: 2.1929895679155984

Epoch: 6| Step: 11
Training loss: 2.1299080848693848
Validation loss: 2.1894189914067588

Epoch: 6| Step: 12
Training loss: 2.748673439025879
Validation loss: 2.164992570877075

Epoch: 6| Step: 13
Training loss: 1.9233477115631104
Validation loss: 2.1911232272783914

Epoch: 244| Step: 0
Training loss: 1.463448405265808
Validation loss: 2.184572716554006

Epoch: 6| Step: 1
Training loss: 1.4016883373260498
Validation loss: 2.203282117843628

Epoch: 6| Step: 2
Training loss: 1.7846214771270752
Validation loss: 2.195583939552307

Epoch: 6| Step: 3
Training loss: 1.7782819271087646
Validation loss: 2.212210953235626

Epoch: 6| Step: 4
Training loss: 1.2442128658294678
Validation loss: 2.1988755464553833

Epoch: 6| Step: 5
Training loss: 2.4011881351470947
Validation loss: 2.1864328583081565

Epoch: 6| Step: 6
Training loss: 2.4943289756774902
Validation loss: 2.2063949505488076

Epoch: 6| Step: 7
Training loss: 2.304335832595825
Validation loss: 2.1822619438171387

Epoch: 6| Step: 8
Training loss: 2.319028377532959
Validation loss: 2.206368863582611

Epoch: 6| Step: 9
Training loss: 1.7455055713653564
Validation loss: 2.185244699319204

Epoch: 6| Step: 10
Training loss: 1.6774535179138184
Validation loss: 2.22011137008667

Epoch: 6| Step: 11
Training loss: 1.6779961585998535
Validation loss: 2.2038148045539856

Epoch: 6| Step: 12
Training loss: 1.7420082092285156
Validation loss: 2.2178817987442017

Epoch: 6| Step: 13
Training loss: 1.6682120561599731
Validation loss: 2.1991728146870932

Epoch: 245| Step: 0
Training loss: 1.9395780563354492
Validation loss: 2.209494431813558

Epoch: 6| Step: 1
Training loss: 1.923765778541565
Validation loss: 2.1890289187431335

Epoch: 6| Step: 2
Training loss: 2.128541946411133
Validation loss: 2.192063788572947

Epoch: 6| Step: 3
Training loss: 1.617558240890503
Validation loss: 2.199488619963328

Epoch: 6| Step: 4
Training loss: 1.746113896369934
Validation loss: 2.185785253842672

Epoch: 6| Step: 5
Training loss: 1.7617913484573364
Validation loss: 2.193372368812561

Epoch: 6| Step: 6
Training loss: 1.5617436170578003
Validation loss: 2.1918497681617737

Epoch: 6| Step: 7
Training loss: 1.7381881475448608
Validation loss: 2.180502712726593

Epoch: 6| Step: 8
Training loss: 1.1297225952148438
Validation loss: 2.1730335553487143

Epoch: 6| Step: 9
Training loss: 2.0067625045776367
Validation loss: 2.1745832363764444

Epoch: 6| Step: 10
Training loss: 1.9528318643569946
Validation loss: 2.1749905943870544

Epoch: 6| Step: 11
Training loss: 1.510127305984497
Validation loss: 2.1959718664487204

Epoch: 6| Step: 12
Training loss: 1.6845608949661255
Validation loss: 2.187449872493744

Epoch: 6| Step: 13
Training loss: 2.5289626121520996
Validation loss: 2.194752554098765

Epoch: 246| Step: 0
Training loss: 1.3370754718780518
Validation loss: 2.1906153758366904

Epoch: 6| Step: 1
Training loss: 1.0781137943267822
Validation loss: 2.2201676964759827

Epoch: 6| Step: 2
Training loss: 2.700122356414795
Validation loss: 2.1807480255762735

Epoch: 6| Step: 3
Training loss: 2.1317830085754395
Validation loss: 2.1881078084309897

Epoch: 6| Step: 4
Training loss: 1.974602222442627
Validation loss: 2.2012636264165244

Epoch: 6| Step: 5
Training loss: 2.222712516784668
Validation loss: 2.1792428493499756

Epoch: 6| Step: 6
Training loss: 1.094604730606079
Validation loss: 2.18528151512146

Epoch: 6| Step: 7
Training loss: 2.0496273040771484
Validation loss: 2.1941960652669272

Epoch: 6| Step: 8
Training loss: 1.7298781871795654
Validation loss: 2.190173546473185

Epoch: 6| Step: 9
Training loss: 1.4546761512756348
Validation loss: 2.196393052736918

Epoch: 6| Step: 10
Training loss: 1.777919054031372
Validation loss: 2.1918226877848306

Epoch: 6| Step: 11
Training loss: 1.1766283512115479
Validation loss: 2.202071408430735

Epoch: 6| Step: 12
Training loss: 1.5145652294158936
Validation loss: 2.179946998755137

Epoch: 6| Step: 13
Training loss: 2.827249050140381
Validation loss: 2.16249018907547

Epoch: 247| Step: 0
Training loss: 1.8399691581726074
Validation loss: 2.1483429272969565

Epoch: 6| Step: 1
Training loss: 2.0317940711975098
Validation loss: 2.1869497299194336

Epoch: 6| Step: 2
Training loss: 1.584598422050476
Validation loss: 2.1673235098520913

Epoch: 6| Step: 3
Training loss: 1.9408756494522095
Validation loss: 2.171373705069224

Epoch: 6| Step: 4
Training loss: 1.7220655679702759
Validation loss: 2.1787197987238565

Epoch: 6| Step: 5
Training loss: 2.284547805786133
Validation loss: 2.1747124989827475

Epoch: 6| Step: 6
Training loss: 1.5908091068267822
Validation loss: 2.168717622756958

Epoch: 6| Step: 7
Training loss: 1.6993608474731445
Validation loss: 2.171678086121877

Epoch: 6| Step: 8
Training loss: 1.6119614839553833
Validation loss: 2.181159416834513

Epoch: 6| Step: 9
Training loss: 1.4550085067749023
Validation loss: 2.1608180602391562

Epoch: 6| Step: 10
Training loss: 1.968529462814331
Validation loss: 2.158552606900533

Epoch: 6| Step: 11
Training loss: 2.4463095664978027
Validation loss: 2.1661845445632935

Epoch: 6| Step: 12
Training loss: 1.3751662969589233
Validation loss: 2.1577207247416177

Epoch: 6| Step: 13
Training loss: 1.9237291812896729
Validation loss: 2.1627784371376038

Epoch: 248| Step: 0
Training loss: 2.2208304405212402
Validation loss: 2.1765217582384744

Epoch: 6| Step: 1
Training loss: 1.8828564882278442
Validation loss: 2.180817405382792

Epoch: 6| Step: 2
Training loss: 1.5530650615692139
Validation loss: 2.177050153414408

Epoch: 6| Step: 3
Training loss: 2.1704764366149902
Validation loss: 2.19527260462443

Epoch: 6| Step: 4
Training loss: 1.5113431215286255
Validation loss: 2.1779261032740274

Epoch: 6| Step: 5
Training loss: 1.7620784044265747
Validation loss: 2.173875371615092

Epoch: 6| Step: 6
Training loss: 1.6338778734207153
Validation loss: 2.1749512354532876

Epoch: 6| Step: 7
Training loss: 2.0282058715820312
Validation loss: 2.1830936670303345

Epoch: 6| Step: 8
Training loss: 1.7818557024002075
Validation loss: 2.187480350335439

Epoch: 6| Step: 9
Training loss: 1.987487554550171
Validation loss: 2.1678497791290283

Epoch: 6| Step: 10
Training loss: 2.3166160583496094
Validation loss: 2.1437034209569297

Epoch: 6| Step: 11
Training loss: 1.5122685432434082
Validation loss: 2.1403233408927917

Epoch: 6| Step: 12
Training loss: 1.7698681354522705
Validation loss: 2.1376591126124063

Epoch: 6| Step: 13
Training loss: 2.2044501304626465
Validation loss: 2.1332440177599588

Epoch: 249| Step: 0
Training loss: 1.363263487815857
Validation loss: 2.157246788342794

Epoch: 6| Step: 1
Training loss: 1.382455825805664
Validation loss: 2.146845499674479

Epoch: 6| Step: 2
Training loss: 2.222374439239502
Validation loss: 2.1442110737164817

Epoch: 6| Step: 3
Training loss: 2.2868943214416504
Validation loss: 2.149094065030416

Epoch: 6| Step: 4
Training loss: 1.793884515762329
Validation loss: 2.157534937063853

Epoch: 6| Step: 5
Training loss: 1.8446296453475952
Validation loss: 2.160675664742788

Epoch: 6| Step: 6
Training loss: 2.3380417823791504
Validation loss: 2.1713274121284485

Epoch: 6| Step: 7
Training loss: 1.1288079023361206
Validation loss: 2.157834847768148

Epoch: 6| Step: 8
Training loss: 1.5896259546279907
Validation loss: 2.1915882428487143

Epoch: 6| Step: 9
Training loss: 2.4454708099365234
Validation loss: 2.174172798792521

Epoch: 6| Step: 10
Training loss: 1.5494623184204102
Validation loss: 2.216609458128611

Epoch: 6| Step: 11
Training loss: 1.889159917831421
Validation loss: 2.2551573117574057

Epoch: 6| Step: 12
Training loss: 2.6365420818328857
Validation loss: 2.235903720060984

Epoch: 6| Step: 13
Training loss: 1.3336609601974487
Validation loss: 2.211194713910421

Epoch: 250| Step: 0
Training loss: 1.8862910270690918
Validation loss: 2.2286572655042014

Epoch: 6| Step: 1
Training loss: 1.3868836164474487
Validation loss: 2.1717110872268677

Epoch: 6| Step: 2
Training loss: 2.5326876640319824
Validation loss: 2.203769008318583

Epoch: 6| Step: 3
Training loss: 1.8769320249557495
Validation loss: 2.168032467365265

Epoch: 6| Step: 4
Training loss: 1.2787268161773682
Validation loss: 2.164940516153971

Epoch: 6| Step: 5
Training loss: 1.9352070093154907
Validation loss: 2.174071490764618

Epoch: 6| Step: 6
Training loss: 2.013198137283325
Validation loss: 2.17220409711202

Epoch: 6| Step: 7
Training loss: 1.3615078926086426
Validation loss: 2.178709407647451

Epoch: 6| Step: 8
Training loss: 2.4343972206115723
Validation loss: 2.1918179988861084

Epoch: 6| Step: 9
Training loss: 2.0632877349853516
Validation loss: 2.201813220977783

Epoch: 6| Step: 10
Training loss: 2.0962276458740234
Validation loss: 2.196365237236023

Epoch: 6| Step: 11
Training loss: 1.6728878021240234
Validation loss: 2.2047993739446006

Epoch: 6| Step: 12
Training loss: 1.3980848789215088
Validation loss: 2.2096802592277527

Epoch: 6| Step: 13
Training loss: 1.484266757965088
Validation loss: 2.2063153783480325

Epoch: 251| Step: 0
Training loss: 1.8611172437667847
Validation loss: 2.2262699802716575

Epoch: 6| Step: 1
Training loss: 1.8243367671966553
Validation loss: 2.2396244208017984

Epoch: 6| Step: 2
Training loss: 2.003993511199951
Validation loss: 2.226947784423828

Epoch: 6| Step: 3
Training loss: 1.285475254058838
Validation loss: 2.2240710258483887

Epoch: 6| Step: 4
Training loss: 1.4018878936767578
Validation loss: 2.230286200841268

Epoch: 6| Step: 5
Training loss: 1.6362299919128418
Validation loss: 2.217666208744049

Epoch: 6| Step: 6
Training loss: 1.992757797241211
Validation loss: 2.2387547492980957

Epoch: 6| Step: 7
Training loss: 2.151651620864868
Validation loss: 2.2153056263923645

Epoch: 6| Step: 8
Training loss: 1.8980637788772583
Validation loss: 2.204915404319763

Epoch: 6| Step: 9
Training loss: 2.611252784729004
Validation loss: 2.191053648789724

Epoch: 6| Step: 10
Training loss: 1.3696794509887695
Validation loss: 2.200465420881907

Epoch: 6| Step: 11
Training loss: 1.7501764297485352
Validation loss: 2.1815252701441445

Epoch: 6| Step: 12
Training loss: 1.7365384101867676
Validation loss: 2.1675402323404946

Epoch: 6| Step: 13
Training loss: 1.6561046838760376
Validation loss: 2.169093290964762

Epoch: 252| Step: 0
Training loss: 1.691091775894165
Validation loss: 2.1736478209495544

Epoch: 6| Step: 1
Training loss: 1.476394772529602
Validation loss: 2.185547331968943

Epoch: 6| Step: 2
Training loss: 2.29585337638855
Validation loss: 2.1954888304074607

Epoch: 6| Step: 3
Training loss: 1.6249592304229736
Validation loss: 2.176509519418081

Epoch: 6| Step: 4
Training loss: 2.063957929611206
Validation loss: 2.163528323173523

Epoch: 6| Step: 5
Training loss: 1.858870267868042
Validation loss: 2.179199695587158

Epoch: 6| Step: 6
Training loss: 1.649968147277832
Validation loss: 2.168634514013926

Epoch: 6| Step: 7
Training loss: 2.145707845687866
Validation loss: 2.1609442234039307

Epoch: 6| Step: 8
Training loss: 1.4240468740463257
Validation loss: 2.165847420692444

Epoch: 6| Step: 9
Training loss: 2.5777530670166016
Validation loss: 2.1737255454063416

Epoch: 6| Step: 10
Training loss: 1.6757023334503174
Validation loss: 2.17540309826533

Epoch: 6| Step: 11
Training loss: 1.7142187356948853
Validation loss: 2.159794886906942

Epoch: 6| Step: 12
Training loss: 1.8676261901855469
Validation loss: 2.1598578492800393

Epoch: 6| Step: 13
Training loss: 1.658945083618164
Validation loss: 2.140073776245117

Epoch: 253| Step: 0
Training loss: 1.7829272747039795
Validation loss: 2.1729355454444885

Epoch: 6| Step: 1
Training loss: 2.24885892868042
Validation loss: 2.152627090613047

Epoch: 6| Step: 2
Training loss: 2.09687876701355
Validation loss: 2.173510412375132

Epoch: 6| Step: 3
Training loss: 1.3039233684539795
Validation loss: 2.181242823600769

Epoch: 6| Step: 4
Training loss: 2.5271358489990234
Validation loss: 2.1833900014559426

Epoch: 6| Step: 5
Training loss: 1.5351601839065552
Validation loss: 2.1887704730033875

Epoch: 6| Step: 6
Training loss: 1.7746913433074951
Validation loss: 2.1878290375073752

Epoch: 6| Step: 7
Training loss: 1.6588280200958252
Validation loss: 2.1894233226776123

Epoch: 6| Step: 8
Training loss: 2.2698402404785156
Validation loss: 2.206082542737325

Epoch: 6| Step: 9
Training loss: 1.4886441230773926
Validation loss: 2.187928398450216

Epoch: 6| Step: 10
Training loss: 1.7551467418670654
Validation loss: 2.193176249663035

Epoch: 6| Step: 11
Training loss: 1.720921516418457
Validation loss: 2.2249931494394937

Epoch: 6| Step: 12
Training loss: 1.4579923152923584
Validation loss: 2.1930596431096396

Epoch: 6| Step: 13
Training loss: 1.5927197933197021
Validation loss: 2.1974710623423257

Epoch: 254| Step: 0
Training loss: 1.2794668674468994
Validation loss: 2.2028867403666177

Epoch: 6| Step: 1
Training loss: 1.7833884954452515
Validation loss: 2.1746382117271423

Epoch: 6| Step: 2
Training loss: 1.8712178468704224
Validation loss: 2.1607682506243386

Epoch: 6| Step: 3
Training loss: 2.020817279815674
Validation loss: 2.1606701612472534

Epoch: 6| Step: 4
Training loss: 1.78007972240448
Validation loss: 2.17681090037028

Epoch: 6| Step: 5
Training loss: 1.8732749223709106
Validation loss: 2.16979451974233

Epoch: 6| Step: 6
Training loss: 2.1781020164489746
Validation loss: 2.161171813805898

Epoch: 6| Step: 7
Training loss: 1.8400644063949585
Validation loss: 2.159417470296224

Epoch: 6| Step: 8
Training loss: 1.8708159923553467
Validation loss: 2.177782336870829

Epoch: 6| Step: 9
Training loss: 2.1002697944641113
Validation loss: 2.159582018852234

Epoch: 6| Step: 10
Training loss: 1.5538028478622437
Validation loss: 2.1787964900334678

Epoch: 6| Step: 11
Training loss: 1.6803066730499268
Validation loss: 2.2044265071551004

Epoch: 6| Step: 12
Training loss: 2.1524524688720703
Validation loss: 2.2041415174802146

Epoch: 6| Step: 13
Training loss: 1.373831868171692
Validation loss: 2.203208406766256

Epoch: 255| Step: 0
Training loss: 1.2787569761276245
Validation loss: 2.1967960596084595

Epoch: 6| Step: 1
Training loss: 1.5773353576660156
Validation loss: 2.1846964955329895

Epoch: 6| Step: 2
Training loss: 1.9342221021652222
Validation loss: 2.1902573506037393

Epoch: 6| Step: 3
Training loss: 1.484123706817627
Validation loss: 2.188537081082662

Epoch: 6| Step: 4
Training loss: 1.8410727977752686
Validation loss: 2.1792489290237427

Epoch: 6| Step: 5
Training loss: 1.9632681608200073
Validation loss: 2.1618462403615317

Epoch: 6| Step: 6
Training loss: 1.807795763015747
Validation loss: 2.173320174217224

Epoch: 6| Step: 7
Training loss: 1.9910258054733276
Validation loss: 2.1849395831425986

Epoch: 6| Step: 8
Training loss: 1.9288078546524048
Validation loss: 2.201616803805033

Epoch: 6| Step: 9
Training loss: 2.2762913703918457
Validation loss: 2.1947955886522927

Epoch: 6| Step: 10
Training loss: 1.34165620803833
Validation loss: 2.186784863471985

Epoch: 6| Step: 11
Training loss: 1.7652084827423096
Validation loss: 2.2028951247533164

Epoch: 6| Step: 12
Training loss: 2.5601389408111572
Validation loss: 2.1949004928270974

Epoch: 6| Step: 13
Training loss: 1.5241339206695557
Validation loss: 2.1814675529797873

Epoch: 256| Step: 0
Training loss: 1.9051012992858887
Validation loss: 2.191404342651367

Epoch: 6| Step: 1
Training loss: 1.3244941234588623
Validation loss: 2.1906966964403787

Epoch: 6| Step: 2
Training loss: 2.3481011390686035
Validation loss: 2.190726578235626

Epoch: 6| Step: 3
Training loss: 2.1314496994018555
Validation loss: 2.1699875593185425

Epoch: 6| Step: 4
Training loss: 2.2115516662597656
Validation loss: 2.1919209361076355

Epoch: 6| Step: 5
Training loss: 1.5576722621917725
Validation loss: 2.1939823031425476

Epoch: 6| Step: 6
Training loss: 1.526787281036377
Validation loss: 2.166874667008718

Epoch: 6| Step: 7
Training loss: 1.8342829942703247
Validation loss: 2.1808576782544455

Epoch: 6| Step: 8
Training loss: 2.093956470489502
Validation loss: 2.1731506983439126

Epoch: 6| Step: 9
Training loss: 1.3885409832000732
Validation loss: 2.184482673803965

Epoch: 6| Step: 10
Training loss: 1.4997329711914062
Validation loss: 2.2177820603052774

Epoch: 6| Step: 11
Training loss: 1.8986775875091553
Validation loss: 2.2140788237253823

Epoch: 6| Step: 12
Training loss: 1.6014759540557861
Validation loss: 2.22237761815389

Epoch: 6| Step: 13
Training loss: 1.7222495079040527
Validation loss: 2.2218803564707437

Epoch: 257| Step: 0
Training loss: 1.7978488206863403
Validation loss: 2.2121761639912925

Epoch: 6| Step: 1
Training loss: 2.1948342323303223
Validation loss: 2.207547426223755

Epoch: 6| Step: 2
Training loss: 1.9931676387786865
Validation loss: 2.1696648796399436

Epoch: 6| Step: 3
Training loss: 1.4352383613586426
Validation loss: 2.1789899865786233

Epoch: 6| Step: 4
Training loss: 2.2046737670898438
Validation loss: 2.196571191151937

Epoch: 6| Step: 5
Training loss: 1.9604836702346802
Validation loss: 2.214789569377899

Epoch: 6| Step: 6
Training loss: 1.6677796840667725
Validation loss: 2.178115804990133

Epoch: 6| Step: 7
Training loss: 1.4853928089141846
Validation loss: 2.2084428469340005

Epoch: 6| Step: 8
Training loss: 2.17132568359375
Validation loss: 2.1953697999318442

Epoch: 6| Step: 9
Training loss: 1.9368529319763184
Validation loss: 2.1920831203460693

Epoch: 6| Step: 10
Training loss: 1.618896484375
Validation loss: 2.21035103003184

Epoch: 6| Step: 11
Training loss: 1.5688250064849854
Validation loss: 2.2060813109079995

Epoch: 6| Step: 12
Training loss: 1.556835412979126
Validation loss: 2.180988689263662

Epoch: 6| Step: 13
Training loss: 1.3586649894714355
Validation loss: 2.1963888804117837

Epoch: 258| Step: 0
Training loss: 1.4578388929367065
Validation loss: 2.1855409940083823

Epoch: 6| Step: 1
Training loss: 1.4711359739303589
Validation loss: 2.199389179547628

Epoch: 6| Step: 2
Training loss: 2.08363676071167
Validation loss: 2.2194084922472634

Epoch: 6| Step: 3
Training loss: 1.8052419424057007
Validation loss: 2.202235221862793

Epoch: 6| Step: 4
Training loss: 1.2360683679580688
Validation loss: 2.2081029216448465

Epoch: 6| Step: 5
Training loss: 1.9742403030395508
Validation loss: 2.2014679511388144

Epoch: 6| Step: 6
Training loss: 1.454663872718811
Validation loss: 2.2132887045542398

Epoch: 6| Step: 7
Training loss: 2.3266539573669434
Validation loss: 2.204744497934977

Epoch: 6| Step: 8
Training loss: 1.5058144330978394
Validation loss: 2.187888284524282

Epoch: 6| Step: 9
Training loss: 1.546608805656433
Validation loss: 2.202709992726644

Epoch: 6| Step: 10
Training loss: 1.978295922279358
Validation loss: 2.205894390741984

Epoch: 6| Step: 11
Training loss: 2.0287225246429443
Validation loss: 2.1883970697720847

Epoch: 6| Step: 12
Training loss: 1.9445381164550781
Validation loss: 2.1778781414031982

Epoch: 6| Step: 13
Training loss: 2.20938777923584
Validation loss: 2.1843959291776023

Epoch: 259| Step: 0
Training loss: 2.228543281555176
Validation loss: 2.1790655851364136

Epoch: 6| Step: 1
Training loss: 1.74721360206604
Validation loss: 2.1854978998502097

Epoch: 6| Step: 2
Training loss: 1.490545630455017
Validation loss: 2.191407839457194

Epoch: 6| Step: 3
Training loss: 2.0807862281799316
Validation loss: 2.174641489982605

Epoch: 6| Step: 4
Training loss: 1.4822373390197754
Validation loss: 2.17982025941213

Epoch: 6| Step: 5
Training loss: 1.4812942743301392
Validation loss: 2.204402804374695

Epoch: 6| Step: 6
Training loss: 1.5513783693313599
Validation loss: 2.2035003701845803

Epoch: 6| Step: 7
Training loss: 1.788138508796692
Validation loss: 2.212286372979482

Epoch: 6| Step: 8
Training loss: 2.208066940307617
Validation loss: 2.1801815231641135

Epoch: 6| Step: 9
Training loss: 1.6151190996170044
Validation loss: 2.166833301385244

Epoch: 6| Step: 10
Training loss: 1.322731614112854
Validation loss: 2.1891077160835266

Epoch: 6| Step: 11
Training loss: 1.7953922748565674
Validation loss: 2.205092668533325

Epoch: 6| Step: 12
Training loss: 2.3365440368652344
Validation loss: 2.1918791135152182

Epoch: 6| Step: 13
Training loss: 2.0892767906188965
Validation loss: 2.1923614343007407

Epoch: 260| Step: 0
Training loss: 2.4297518730163574
Validation loss: 2.1983368198076882

Epoch: 6| Step: 1
Training loss: 2.2247352600097656
Validation loss: 2.1906086802482605

Epoch: 6| Step: 2
Training loss: 1.5926246643066406
Validation loss: 2.1998051404953003

Epoch: 6| Step: 3
Training loss: 1.4718846082687378
Validation loss: 2.189184864362081

Epoch: 6| Step: 4
Training loss: 2.17136812210083
Validation loss: 2.194602151711782

Epoch: 6| Step: 5
Training loss: 1.2265923023223877
Validation loss: 2.1897027492523193

Epoch: 6| Step: 6
Training loss: 1.338275671005249
Validation loss: 2.1762376626332602

Epoch: 6| Step: 7
Training loss: 2.0460164546966553
Validation loss: 2.191177010536194

Epoch: 6| Step: 8
Training loss: 1.3880001306533813
Validation loss: 2.1949451764424643

Epoch: 6| Step: 9
Training loss: 1.3082520961761475
Validation loss: 2.1750078399976096

Epoch: 6| Step: 10
Training loss: 1.7303400039672852
Validation loss: 2.197882095972697

Epoch: 6| Step: 11
Training loss: 1.8031446933746338
Validation loss: 2.2144393722216287

Epoch: 6| Step: 12
Training loss: 1.4674077033996582
Validation loss: 2.1892802317937217

Epoch: 6| Step: 13
Training loss: 2.8087263107299805
Validation loss: 2.2190953890482583

Epoch: 261| Step: 0
Training loss: 2.2687244415283203
Validation loss: 2.177750746409098

Epoch: 6| Step: 1
Training loss: 2.0588109493255615
Validation loss: 2.207215110460917

Epoch: 6| Step: 2
Training loss: 1.6931250095367432
Validation loss: 2.206266542275747

Epoch: 6| Step: 3
Training loss: 2.093256950378418
Validation loss: 2.2155640920003257

Epoch: 6| Step: 4
Training loss: 1.4994022846221924
Validation loss: 2.1849192182223

Epoch: 6| Step: 5
Training loss: 2.1085095405578613
Validation loss: 2.1802998383839927

Epoch: 6| Step: 6
Training loss: 1.0700461864471436
Validation loss: 2.2135815223058066

Epoch: 6| Step: 7
Training loss: 2.3255417346954346
Validation loss: 2.205051064491272

Epoch: 6| Step: 8
Training loss: 1.7965972423553467
Validation loss: 2.194766859213511

Epoch: 6| Step: 9
Training loss: 2.074930191040039
Validation loss: 2.228523870309194

Epoch: 6| Step: 10
Training loss: 1.3710613250732422
Validation loss: 2.201963643232981

Epoch: 6| Step: 11
Training loss: 1.3973017930984497
Validation loss: 2.2016036113103232

Epoch: 6| Step: 12
Training loss: 1.449407696723938
Validation loss: 2.221227705478668

Epoch: 6| Step: 13
Training loss: 1.615429401397705
Validation loss: 2.2294439474741616

Epoch: 262| Step: 0
Training loss: 1.7619993686676025
Validation loss: 2.2220473686854043

Epoch: 6| Step: 1
Training loss: 1.8737907409667969
Validation loss: 2.2332953214645386

Epoch: 6| Step: 2
Training loss: 2.1201374530792236
Validation loss: 2.207195222377777

Epoch: 6| Step: 3
Training loss: 2.054865837097168
Validation loss: 2.2147260308265686

Epoch: 6| Step: 4
Training loss: 1.9591968059539795
Validation loss: 2.204453786214193

Epoch: 6| Step: 5
Training loss: 1.8416125774383545
Validation loss: 2.1882872382799783

Epoch: 6| Step: 6
Training loss: 2.0392885208129883
Validation loss: 2.1989855766296387

Epoch: 6| Step: 7
Training loss: 1.655085563659668
Validation loss: 2.2165549993515015

Epoch: 6| Step: 8
Training loss: 1.4267663955688477
Validation loss: 2.2284633119901023

Epoch: 6| Step: 9
Training loss: 1.3502345085144043
Validation loss: 2.2393877108891806

Epoch: 6| Step: 10
Training loss: 1.7134921550750732
Validation loss: 2.25639679034551

Epoch: 6| Step: 11
Training loss: 1.6733813285827637
Validation loss: 2.2541305820147195

Epoch: 6| Step: 12
Training loss: 2.2589945793151855
Validation loss: 2.249452829360962

Epoch: 6| Step: 13
Training loss: 1.4754447937011719
Validation loss: 2.2678476770718894

Epoch: 263| Step: 0
Training loss: 1.940058946609497
Validation loss: 2.254325807094574

Epoch: 6| Step: 1
Training loss: 2.027700185775757
Validation loss: 2.233157436052958

Epoch: 6| Step: 2
Training loss: 2.1677043437957764
Validation loss: 2.24155330657959

Epoch: 6| Step: 3
Training loss: 1.6312448978424072
Validation loss: 2.20388392607371

Epoch: 6| Step: 4
Training loss: 1.7651472091674805
Validation loss: 2.215292513370514

Epoch: 6| Step: 5
Training loss: 2.077097177505493
Validation loss: 2.1908931334813437

Epoch: 6| Step: 6
Training loss: 1.6269922256469727
Validation loss: 2.184125065803528

Epoch: 6| Step: 7
Training loss: 1.5995204448699951
Validation loss: 2.193047205607096

Epoch: 6| Step: 8
Training loss: 1.4724472761154175
Validation loss: 2.1745398243268332

Epoch: 6| Step: 9
Training loss: 1.7570195198059082
Validation loss: 2.1898339788118997

Epoch: 6| Step: 10
Training loss: 1.6134637594223022
Validation loss: 2.190494418144226

Epoch: 6| Step: 11
Training loss: 2.366617202758789
Validation loss: 2.2036035855611167

Epoch: 6| Step: 12
Training loss: 1.938373327255249
Validation loss: 2.1742593248685202

Epoch: 6| Step: 13
Training loss: 1.440332293510437
Validation loss: 2.183467666308085

Epoch: 264| Step: 0
Training loss: 1.1824421882629395
Validation loss: 2.1863699356714883

Epoch: 6| Step: 1
Training loss: 1.9048218727111816
Validation loss: 2.1926175157229104

Epoch: 6| Step: 2
Training loss: 1.562636137008667
Validation loss: 2.1867791215578714

Epoch: 6| Step: 3
Training loss: 1.7812427282333374
Validation loss: 2.187881906827291

Epoch: 6| Step: 4
Training loss: 1.8190137147903442
Validation loss: 2.2058498660723367

Epoch: 6| Step: 5
Training loss: 1.9913853406906128
Validation loss: 2.226605216662089

Epoch: 6| Step: 6
Training loss: 1.6683497428894043
Validation loss: 2.2473782102266946

Epoch: 6| Step: 7
Training loss: 2.302130699157715
Validation loss: 2.252173205216726

Epoch: 6| Step: 8
Training loss: 1.9419461488723755
Validation loss: 2.2586924036343894

Epoch: 6| Step: 9
Training loss: 1.6634284257888794
Validation loss: 2.2569079597791037

Epoch: 6| Step: 10
Training loss: 1.767754077911377
Validation loss: 2.2566157976786294

Epoch: 6| Step: 11
Training loss: 1.8314486742019653
Validation loss: 2.275686343510946

Epoch: 6| Step: 12
Training loss: 1.8009328842163086
Validation loss: 2.2673659722010293

Epoch: 6| Step: 13
Training loss: 1.6558072566986084
Validation loss: 2.243102173010508

Epoch: 265| Step: 0
Training loss: 1.3964505195617676
Validation loss: 2.247817039489746

Epoch: 6| Step: 1
Training loss: 1.827656626701355
Validation loss: 2.237314283847809

Epoch: 6| Step: 2
Training loss: 1.209035038948059
Validation loss: 2.19818776845932

Epoch: 6| Step: 3
Training loss: 1.347428798675537
Validation loss: 2.2137889862060547

Epoch: 6| Step: 4
Training loss: 1.7205123901367188
Validation loss: 2.2131735483805337

Epoch: 6| Step: 5
Training loss: 2.1886157989501953
Validation loss: 2.1986767053604126

Epoch: 6| Step: 6
Training loss: 1.3235621452331543
Validation loss: 2.185041129589081

Epoch: 6| Step: 7
Training loss: 2.5318384170532227
Validation loss: 2.179816464583079

Epoch: 6| Step: 8
Training loss: 2.446427345275879
Validation loss: 2.184530178705851

Epoch: 6| Step: 9
Training loss: 1.8906575441360474
Validation loss: 2.215369621912638

Epoch: 6| Step: 10
Training loss: 2.2529029846191406
Validation loss: 2.2085004846254983

Epoch: 6| Step: 11
Training loss: 1.2997796535491943
Validation loss: 2.1891634861628213

Epoch: 6| Step: 12
Training loss: 1.2006690502166748
Validation loss: 2.194064756234487

Epoch: 6| Step: 13
Training loss: 2.326322555541992
Validation loss: 2.2311335603396096

Epoch: 266| Step: 0
Training loss: 2.6555566787719727
Validation loss: 2.231622099876404

Epoch: 6| Step: 1
Training loss: 2.137038230895996
Validation loss: 2.2373435894648233

Epoch: 6| Step: 2
Training loss: 1.8525819778442383
Validation loss: 2.2335518995920816

Epoch: 6| Step: 3
Training loss: 1.7926815748214722
Validation loss: 2.2376591165860495

Epoch: 6| Step: 4
Training loss: 1.6460676193237305
Validation loss: 2.2245693802833557

Epoch: 6| Step: 5
Training loss: 1.9135351181030273
Validation loss: 2.205869952837626

Epoch: 6| Step: 6
Training loss: 1.1585450172424316
Validation loss: 2.207966764767965

Epoch: 6| Step: 7
Training loss: 1.7384424209594727
Validation loss: 2.216106037298838

Epoch: 6| Step: 8
Training loss: 1.8073612451553345
Validation loss: 2.191619038581848

Epoch: 6| Step: 9
Training loss: 1.8356841802597046
Validation loss: 2.1663416226704917

Epoch: 6| Step: 10
Training loss: 1.4199583530426025
Validation loss: 2.1686763366063437

Epoch: 6| Step: 11
Training loss: 1.9108716249465942
Validation loss: 2.1889057755470276

Epoch: 6| Step: 12
Training loss: 1.5196669101715088
Validation loss: 2.195033371448517

Epoch: 6| Step: 13
Training loss: 1.8846687078475952
Validation loss: 2.197679877281189

Epoch: 267| Step: 0
Training loss: 1.6582181453704834
Validation loss: 2.1798012057940164

Epoch: 6| Step: 1
Training loss: 1.8067853450775146
Validation loss: 2.189527610937754

Epoch: 6| Step: 2
Training loss: 1.4132593870162964
Validation loss: 2.1918142835299173

Epoch: 6| Step: 3
Training loss: 1.3870490789413452
Validation loss: 2.1943244536717734

Epoch: 6| Step: 4
Training loss: 2.0996639728546143
Validation loss: 2.2065503001213074

Epoch: 6| Step: 5
Training loss: 1.9722263813018799
Validation loss: 2.199071705341339

Epoch: 6| Step: 6
Training loss: 1.7573339939117432
Validation loss: 2.2131275733311973

Epoch: 6| Step: 7
Training loss: 1.6686954498291016
Validation loss: 2.217272241910299

Epoch: 6| Step: 8
Training loss: 1.8150570392608643
Validation loss: 2.2224220037460327

Epoch: 6| Step: 9
Training loss: 1.9160308837890625
Validation loss: 2.220475991566976

Epoch: 6| Step: 10
Training loss: 1.4526921510696411
Validation loss: 2.2148016889890036

Epoch: 6| Step: 11
Training loss: 2.1160035133361816
Validation loss: 2.2118491530418396

Epoch: 6| Step: 12
Training loss: 2.106940507888794
Validation loss: 2.2247172196706138

Epoch: 6| Step: 13
Training loss: 1.3226920366287231
Validation loss: 2.21924098332723

Epoch: 268| Step: 0
Training loss: 2.3943614959716797
Validation loss: 2.1993433038393655

Epoch: 6| Step: 1
Training loss: 2.377155303955078
Validation loss: 2.196932832400004

Epoch: 6| Step: 2
Training loss: 2.0094852447509766
Validation loss: 2.207890431086222

Epoch: 6| Step: 3
Training loss: 1.6550335884094238
Validation loss: 2.2008002599080405

Epoch: 6| Step: 4
Training loss: 1.6632336378097534
Validation loss: 2.2208173672358194

Epoch: 6| Step: 5
Training loss: 1.3080670833587646
Validation loss: 2.2193393111228943

Epoch: 6| Step: 6
Training loss: 1.6857950687408447
Validation loss: 2.2223867575327554

Epoch: 6| Step: 7
Training loss: 1.3319263458251953
Validation loss: 2.245560586452484

Epoch: 6| Step: 8
Training loss: 1.5163358449935913
Validation loss: 2.2125572562217712

Epoch: 6| Step: 9
Training loss: 2.0996227264404297
Validation loss: 2.2034395933151245

Epoch: 6| Step: 10
Training loss: 2.2283103466033936
Validation loss: 2.218264917532603

Epoch: 6| Step: 11
Training loss: 0.9000949263572693
Validation loss: 2.192229410012563

Epoch: 6| Step: 12
Training loss: 2.190127372741699
Validation loss: 2.2159276008605957

Epoch: 6| Step: 13
Training loss: 1.1442139148712158
Validation loss: 2.2029152711232505

Epoch: 269| Step: 0
Training loss: 2.2877612113952637
Validation loss: 2.231598158677419

Epoch: 6| Step: 1
Training loss: 2.3105592727661133
Validation loss: 2.2009809017181396

Epoch: 6| Step: 2
Training loss: 1.0992562770843506
Validation loss: 2.2049763401349387

Epoch: 6| Step: 3
Training loss: 2.075143814086914
Validation loss: 2.2226815422376

Epoch: 6| Step: 4
Training loss: 1.559606909751892
Validation loss: 2.2224056323369346

Epoch: 6| Step: 5
Training loss: 1.815024733543396
Validation loss: 2.2353040973345437

Epoch: 6| Step: 6
Training loss: 1.288966417312622
Validation loss: 2.2307629187901816

Epoch: 6| Step: 7
Training loss: 1.6108262538909912
Validation loss: 2.248446782430013

Epoch: 6| Step: 8
Training loss: 2.0608372688293457
Validation loss: 2.2243884007136026

Epoch: 6| Step: 9
Training loss: 1.3690710067749023
Validation loss: 2.2406572699546814

Epoch: 6| Step: 10
Training loss: 1.708909273147583
Validation loss: 2.2367973725001016

Epoch: 6| Step: 11
Training loss: 2.0907983779907227
Validation loss: 2.267797867457072

Epoch: 6| Step: 12
Training loss: 1.6255851984024048
Validation loss: 2.2733633518218994

Epoch: 6| Step: 13
Training loss: 1.6552393436431885
Validation loss: 2.256705860296885

Epoch: 270| Step: 0
Training loss: 1.6412056684494019
Validation loss: 2.2689908146858215

Epoch: 6| Step: 1
Training loss: 1.9420850276947021
Validation loss: 2.2243767579396567

Epoch: 6| Step: 2
Training loss: 1.6805278062820435
Validation loss: 2.2291153271993003

Epoch: 6| Step: 3
Training loss: 1.781224250793457
Validation loss: 2.229593336582184

Epoch: 6| Step: 4
Training loss: 1.9161107540130615
Validation loss: 2.2251038948694863

Epoch: 6| Step: 5
Training loss: 1.173851490020752
Validation loss: 2.2107585867245994

Epoch: 6| Step: 6
Training loss: 1.3258072137832642
Validation loss: 2.228626867135366

Epoch: 6| Step: 7
Training loss: 1.808048963546753
Validation loss: 2.206193765004476

Epoch: 6| Step: 8
Training loss: 1.783556342124939
Validation loss: 2.2083922823270163

Epoch: 6| Step: 9
Training loss: 2.2529759407043457
Validation loss: 2.19951061407725

Epoch: 6| Step: 10
Training loss: 2.101229190826416
Validation loss: 2.2154512206713357

Epoch: 6| Step: 11
Training loss: 2.06858491897583
Validation loss: 2.231582005818685

Epoch: 6| Step: 12
Training loss: 1.1272832155227661
Validation loss: 2.2189762194951377

Epoch: 6| Step: 13
Training loss: 2.018949508666992
Validation loss: 2.2242910464604697

Epoch: 271| Step: 0
Training loss: 1.7116858959197998
Validation loss: 2.2018210093180337

Epoch: 6| Step: 1
Training loss: 1.5617374181747437
Validation loss: 2.228444198767344

Epoch: 6| Step: 2
Training loss: 1.3949042558670044
Validation loss: 2.207066317399343

Epoch: 6| Step: 3
Training loss: 1.1615235805511475
Validation loss: 2.1779306133588157

Epoch: 6| Step: 4
Training loss: 2.103536605834961
Validation loss: 2.20143856604894

Epoch: 6| Step: 5
Training loss: 1.8087258338928223
Validation loss: 2.1763954758644104

Epoch: 6| Step: 6
Training loss: 1.8943910598754883
Validation loss: 2.172674218813578

Epoch: 6| Step: 7
Training loss: 2.1977860927581787
Validation loss: 2.165716012318929

Epoch: 6| Step: 8
Training loss: 1.9068150520324707
Validation loss: 2.169486920038859

Epoch: 6| Step: 9
Training loss: 1.8517616987228394
Validation loss: 2.160232146581014

Epoch: 6| Step: 10
Training loss: 1.845920205116272
Validation loss: 2.138659358024597

Epoch: 6| Step: 11
Training loss: 2.198303461074829
Validation loss: 2.1475940942764282

Epoch: 6| Step: 12
Training loss: 1.442527413368225
Validation loss: 2.1628748377164206

Epoch: 6| Step: 13
Training loss: 1.7193753719329834
Validation loss: 2.161623239517212

Epoch: 272| Step: 0
Training loss: 1.82706618309021
Validation loss: 2.1568562189737954

Epoch: 6| Step: 1
Training loss: 1.8715903759002686
Validation loss: 2.1910491585731506

Epoch: 6| Step: 2
Training loss: 2.0071823596954346
Validation loss: 2.1872620979944863

Epoch: 6| Step: 3
Training loss: 1.8670518398284912
Validation loss: 2.162003537019094

Epoch: 6| Step: 4
Training loss: 1.8241822719573975
Validation loss: 2.20095032453537

Epoch: 6| Step: 5
Training loss: 1.5115835666656494
Validation loss: 2.1854599118232727

Epoch: 6| Step: 6
Training loss: 2.3712151050567627
Validation loss: 2.1782115697860718

Epoch: 6| Step: 7
Training loss: 1.4887797832489014
Validation loss: 2.1898357272148132

Epoch: 6| Step: 8
Training loss: 2.0271501541137695
Validation loss: 2.1780906915664673

Epoch: 6| Step: 9
Training loss: 1.6667449474334717
Validation loss: 2.2077527244885764

Epoch: 6| Step: 10
Training loss: 1.4292582273483276
Validation loss: 2.21049165725708

Epoch: 6| Step: 11
Training loss: 1.6720861196517944
Validation loss: 2.2210933566093445

Epoch: 6| Step: 12
Training loss: 1.6951372623443604
Validation loss: 2.20445982615153

Epoch: 6| Step: 13
Training loss: 1.4508360624313354
Validation loss: 2.218062082926432

Epoch: 273| Step: 0
Training loss: 2.1643142700195312
Validation loss: 2.205400009950002

Epoch: 6| Step: 1
Training loss: 2.3450441360473633
Validation loss: 2.209218601385752

Epoch: 6| Step: 2
Training loss: 1.7031993865966797
Validation loss: 2.209682842095693

Epoch: 6| Step: 3
Training loss: 1.1367491483688354
Validation loss: 2.20603483915329

Epoch: 6| Step: 4
Training loss: 1.812652349472046
Validation loss: 2.199333071708679

Epoch: 6| Step: 5
Training loss: 1.3736557960510254
Validation loss: 2.1833950082461038

Epoch: 6| Step: 6
Training loss: 2.1578683853149414
Validation loss: 2.204659958680471

Epoch: 6| Step: 7
Training loss: 2.0542678833007812
Validation loss: 2.217277725537618

Epoch: 6| Step: 8
Training loss: 1.1543848514556885
Validation loss: 2.2198398311932883

Epoch: 6| Step: 9
Training loss: 1.332602858543396
Validation loss: 2.2185248533884683

Epoch: 6| Step: 10
Training loss: 1.5920228958129883
Validation loss: 2.2276496489842734

Epoch: 6| Step: 11
Training loss: 1.9542303085327148
Validation loss: 2.2023538748423257

Epoch: 6| Step: 12
Training loss: 1.7588132619857788
Validation loss: 2.2071001331011453

Epoch: 6| Step: 13
Training loss: 1.8039525747299194
Validation loss: 2.193276524543762

Epoch: 274| Step: 0
Training loss: 1.5560321807861328
Validation loss: 2.1919392943382263

Epoch: 6| Step: 1
Training loss: 1.8380804061889648
Validation loss: 2.176353633403778

Epoch: 6| Step: 2
Training loss: 1.574507474899292
Validation loss: 2.1967926621437073

Epoch: 6| Step: 3
Training loss: 3.007903575897217
Validation loss: 2.231143355369568

Epoch: 6| Step: 4
Training loss: 1.774724006652832
Validation loss: 2.1810762882232666

Epoch: 6| Step: 5
Training loss: 1.5022807121276855
Validation loss: 2.224983870983124

Epoch: 6| Step: 6
Training loss: 1.7217673063278198
Validation loss: 2.2257239818573

Epoch: 6| Step: 7
Training loss: 1.6749849319458008
Validation loss: 2.234531283378601

Epoch: 6| Step: 8
Training loss: 1.781660795211792
Validation loss: 2.2774415214856467

Epoch: 6| Step: 9
Training loss: 1.225534200668335
Validation loss: 2.2911346753438315

Epoch: 6| Step: 10
Training loss: 2.104356288909912
Validation loss: 2.292971690495809

Epoch: 6| Step: 11
Training loss: 1.3240340948104858
Validation loss: 2.2832388877868652

Epoch: 6| Step: 12
Training loss: 1.9714326858520508
Validation loss: 2.2862077951431274

Epoch: 6| Step: 13
Training loss: 1.878597378730774
Validation loss: 2.293253024419149

Epoch: 275| Step: 0
Training loss: 1.7936129570007324
Validation loss: 2.2565457820892334

Epoch: 6| Step: 1
Training loss: 1.4581975936889648
Validation loss: 2.233648180961609

Epoch: 6| Step: 2
Training loss: 1.3300857543945312
Validation loss: 2.2196911176045737

Epoch: 6| Step: 3
Training loss: 1.5163474082946777
Validation loss: 2.206623613834381

Epoch: 6| Step: 4
Training loss: 1.7058519124984741
Validation loss: 2.1877068082491555

Epoch: 6| Step: 5
Training loss: 1.829217791557312
Validation loss: 2.192976454893748

Epoch: 6| Step: 6
Training loss: 1.2783740758895874
Validation loss: 2.1749675273895264

Epoch: 6| Step: 7
Training loss: 2.0120785236358643
Validation loss: 2.1832812229792276

Epoch: 6| Step: 8
Training loss: 2.579080581665039
Validation loss: 2.187509377797445

Epoch: 6| Step: 9
Training loss: 2.337581157684326
Validation loss: 2.1971208651860556

Epoch: 6| Step: 10
Training loss: 1.7670924663543701
Validation loss: 2.205098589261373

Epoch: 6| Step: 11
Training loss: 2.091918468475342
Validation loss: 2.203926126162211

Epoch: 6| Step: 12
Training loss: 1.9460655450820923
Validation loss: 2.2034777402877808

Epoch: 6| Step: 13
Training loss: 2.3310353755950928
Validation loss: 2.198436220486959

Epoch: 276| Step: 0
Training loss: 2.2463934421539307
Validation loss: 2.1958402593930564

Epoch: 6| Step: 1
Training loss: 1.8192338943481445
Validation loss: 2.1996232668558755

Epoch: 6| Step: 2
Training loss: 1.3635594844818115
Validation loss: 2.2197745045026145

Epoch: 6| Step: 3
Training loss: 1.3196966648101807
Validation loss: 2.2382107774416604

Epoch: 6| Step: 4
Training loss: 2.0185699462890625
Validation loss: 2.213881810506185

Epoch: 6| Step: 5
Training loss: 1.9319255352020264
Validation loss: 2.233141541481018

Epoch: 6| Step: 6
Training loss: 1.4486827850341797
Validation loss: 2.2052273750305176

Epoch: 6| Step: 7
Training loss: 2.21724534034729
Validation loss: 2.1884124080340066

Epoch: 6| Step: 8
Training loss: 1.4789031744003296
Validation loss: 2.2093494733174643

Epoch: 6| Step: 9
Training loss: 2.1708335876464844
Validation loss: 2.179283777872721

Epoch: 6| Step: 10
Training loss: 1.0116653442382812
Validation loss: 2.1865141789118447

Epoch: 6| Step: 11
Training loss: 2.035050392150879
Validation loss: 2.173534393310547

Epoch: 6| Step: 12
Training loss: 1.3296140432357788
Validation loss: 2.194242517153422

Epoch: 6| Step: 13
Training loss: 2.6251726150512695
Validation loss: 2.180655777454376

Epoch: 277| Step: 0
Training loss: 1.6327404975891113
Validation loss: 2.193641265233358

Epoch: 6| Step: 1
Training loss: 1.9761017560958862
Validation loss: 2.1834005316098533

Epoch: 6| Step: 2
Training loss: 2.5875043869018555
Validation loss: 2.1950454314549765

Epoch: 6| Step: 3
Training loss: 1.3040177822113037
Validation loss: 2.214262624581655

Epoch: 6| Step: 4
Training loss: 2.150923252105713
Validation loss: 2.219659368197123

Epoch: 6| Step: 5
Training loss: 1.2318516969680786
Validation loss: 2.215195616086324

Epoch: 6| Step: 6
Training loss: 2.1929802894592285
Validation loss: 2.245210369427999

Epoch: 6| Step: 7
Training loss: 1.9651795625686646
Validation loss: 2.2401385505994162

Epoch: 6| Step: 8
Training loss: 2.111508369445801
Validation loss: 2.2500481605529785

Epoch: 6| Step: 9
Training loss: 1.6518588066101074
Validation loss: 2.2627046704292297

Epoch: 6| Step: 10
Training loss: 0.8406610488891602
Validation loss: 2.2585355838139853

Epoch: 6| Step: 11
Training loss: 1.7938594818115234
Validation loss: 2.240608513355255

Epoch: 6| Step: 12
Training loss: 1.460085391998291
Validation loss: 2.2225571870803833

Epoch: 6| Step: 13
Training loss: 1.7900080680847168
Validation loss: 2.229889969031016

Epoch: 278| Step: 0
Training loss: 1.853613257408142
Validation loss: 2.2318833669026694

Epoch: 6| Step: 1
Training loss: 1.8405195474624634
Validation loss: 2.2536285718282065

Epoch: 6| Step: 2
Training loss: 1.7447023391723633
Validation loss: 2.2361610929171243

Epoch: 6| Step: 3
Training loss: 1.485424518585205
Validation loss: 2.204176346460978

Epoch: 6| Step: 4
Training loss: 1.0287567377090454
Validation loss: 2.2320856849352517

Epoch: 6| Step: 5
Training loss: 1.1216905117034912
Validation loss: 2.2198450764020285

Epoch: 6| Step: 6
Training loss: 1.8267061710357666
Validation loss: 2.2197471459706626

Epoch: 6| Step: 7
Training loss: 1.8646392822265625
Validation loss: 2.21459424495697

Epoch: 6| Step: 8
Training loss: 2.1871161460876465
Validation loss: 2.206861893335978

Epoch: 6| Step: 9
Training loss: 2.2042927742004395
Validation loss: 2.2128151853879294

Epoch: 6| Step: 10
Training loss: 1.6346447467803955
Validation loss: 2.2435773809750876

Epoch: 6| Step: 11
Training loss: 1.9231704473495483
Validation loss: 2.230277200539907

Epoch: 6| Step: 12
Training loss: 1.8123003244400024
Validation loss: 2.2286840081214905

Epoch: 6| Step: 13
Training loss: 1.6424546241760254
Validation loss: 2.2438198725382485

Epoch: 279| Step: 0
Training loss: 1.4405803680419922
Validation loss: 2.220621665318807

Epoch: 6| Step: 1
Training loss: 1.7881697416305542
Validation loss: 2.2360040148099265

Epoch: 6| Step: 2
Training loss: 2.1005921363830566
Validation loss: 2.223106066385905

Epoch: 6| Step: 3
Training loss: 1.8477153778076172
Validation loss: 2.226993997891744

Epoch: 6| Step: 4
Training loss: 1.6746731996536255
Validation loss: 2.2367923061052957

Epoch: 6| Step: 5
Training loss: 2.324312210083008
Validation loss: 2.199121614297231

Epoch: 6| Step: 6
Training loss: 2.271617889404297
Validation loss: 2.2487481435139975

Epoch: 6| Step: 7
Training loss: 1.7263600826263428
Validation loss: 2.2337412436803183

Epoch: 6| Step: 8
Training loss: 1.7737071514129639
Validation loss: 2.2532225847244263

Epoch: 6| Step: 9
Training loss: 1.6887816190719604
Validation loss: 2.2104820609092712

Epoch: 6| Step: 10
Training loss: 1.7336084842681885
Validation loss: 2.20033593972524

Epoch: 6| Step: 11
Training loss: 1.0801117420196533
Validation loss: 2.1891512870788574

Epoch: 6| Step: 12
Training loss: 1.4938160181045532
Validation loss: 2.1798210541407266

Epoch: 6| Step: 13
Training loss: 1.2412314414978027
Validation loss: 2.1891584396362305

Epoch: 280| Step: 0
Training loss: 2.6186442375183105
Validation loss: 2.1910432974497476

Epoch: 6| Step: 1
Training loss: 1.2746515274047852
Validation loss: 2.16888835032781

Epoch: 6| Step: 2
Training loss: 1.5757770538330078
Validation loss: 2.1787339448928833

Epoch: 6| Step: 3
Training loss: 1.7563613653182983
Validation loss: 2.1839129527409873

Epoch: 6| Step: 4
Training loss: 1.6227190494537354
Validation loss: 2.2048397858937583

Epoch: 6| Step: 5
Training loss: 1.8419109582901
Validation loss: 2.208796660105387

Epoch: 6| Step: 6
Training loss: 2.6456429958343506
Validation loss: 2.2260103623072305

Epoch: 6| Step: 7
Training loss: 1.6960608959197998
Validation loss: 2.2190231879552207

Epoch: 6| Step: 8
Training loss: 2.019822835922241
Validation loss: 2.2397149403889975

Epoch: 6| Step: 9
Training loss: 1.102285623550415
Validation loss: 2.229481518268585

Epoch: 6| Step: 10
Training loss: 1.8717255592346191
Validation loss: 2.232565184434255

Epoch: 6| Step: 11
Training loss: 1.9169217348098755
Validation loss: 2.2217456698417664

Epoch: 6| Step: 12
Training loss: 1.4140316247940063
Validation loss: 2.2177709341049194

Epoch: 6| Step: 13
Training loss: 1.3093165159225464
Validation loss: 2.210258106390635

Epoch: 281| Step: 0
Training loss: 1.9013121128082275
Validation loss: 2.196284453074137

Epoch: 6| Step: 1
Training loss: 1.3473055362701416
Validation loss: 2.2195003628730774

Epoch: 6| Step: 2
Training loss: 1.2846200466156006
Validation loss: 2.2158467769622803

Epoch: 6| Step: 3
Training loss: 2.3657660484313965
Validation loss: 2.2231760025024414

Epoch: 6| Step: 4
Training loss: 1.7823176383972168
Validation loss: 2.2036399046579995

Epoch: 6| Step: 5
Training loss: 1.599776268005371
Validation loss: 2.222016473611196

Epoch: 6| Step: 6
Training loss: 1.8548460006713867
Validation loss: 2.2234989007314048

Epoch: 6| Step: 7
Training loss: 1.1529465913772583
Validation loss: 2.2226816415786743

Epoch: 6| Step: 8
Training loss: 1.9817230701446533
Validation loss: 2.198015729586283

Epoch: 6| Step: 9
Training loss: 1.5268754959106445
Validation loss: 2.194361130396525

Epoch: 6| Step: 10
Training loss: 1.6355741024017334
Validation loss: 2.2113508184750876

Epoch: 6| Step: 11
Training loss: 2.0333666801452637
Validation loss: 2.196032166481018

Epoch: 6| Step: 12
Training loss: 1.9619518518447876
Validation loss: 2.2138564586639404

Epoch: 6| Step: 13
Training loss: 1.9122323989868164
Validation loss: 2.202671448389689

Epoch: 282| Step: 0
Training loss: 2.0328357219696045
Validation loss: 2.2232680320739746

Epoch: 6| Step: 1
Training loss: 1.3657888174057007
Validation loss: 2.2253665129343667

Epoch: 6| Step: 2
Training loss: 1.444486141204834
Validation loss: 2.2316854596138

Epoch: 6| Step: 3
Training loss: 1.9979825019836426
Validation loss: 2.22756290435791

Epoch: 6| Step: 4
Training loss: 1.5212392807006836
Validation loss: 2.2358246644337973

Epoch: 6| Step: 5
Training loss: 1.3902692794799805
Validation loss: 2.233919640382131

Epoch: 6| Step: 6
Training loss: 2.263017177581787
Validation loss: 2.2664305567741394

Epoch: 6| Step: 7
Training loss: 1.4902293682098389
Validation loss: 2.255948762098948

Epoch: 6| Step: 8
Training loss: 1.623075008392334
Validation loss: 2.2567111055056253

Epoch: 6| Step: 9
Training loss: 1.6225581169128418
Validation loss: 2.272238870461782

Epoch: 6| Step: 10
Training loss: 2.1954126358032227
Validation loss: 2.277670760949453

Epoch: 6| Step: 11
Training loss: 1.4986670017242432
Validation loss: 2.2756239573160806

Epoch: 6| Step: 12
Training loss: 2.041281223297119
Validation loss: 2.256720781326294

Epoch: 6| Step: 13
Training loss: 1.7188013792037964
Validation loss: 2.2439292867978415

Epoch: 283| Step: 0
Training loss: 1.628136157989502
Validation loss: 2.2423635522524514

Epoch: 6| Step: 1
Training loss: 2.299448251724243
Validation loss: 2.2287004391352334

Epoch: 6| Step: 2
Training loss: 1.816009283065796
Validation loss: 2.237287143866221

Epoch: 6| Step: 3
Training loss: 1.3492085933685303
Validation loss: 2.2497791051864624

Epoch: 6| Step: 4
Training loss: 1.5113335847854614
Validation loss: 2.2515185276667276

Epoch: 6| Step: 5
Training loss: 1.283302664756775
Validation loss: 2.2623703678448996

Epoch: 6| Step: 6
Training loss: 1.6736438274383545
Validation loss: 2.2207315961519876

Epoch: 6| Step: 7
Training loss: 1.8799324035644531
Validation loss: 2.2642021576563516

Epoch: 6| Step: 8
Training loss: 1.5652313232421875
Validation loss: 2.2488630016644797

Epoch: 6| Step: 9
Training loss: 1.7892701625823975
Validation loss: 2.228388031323751

Epoch: 6| Step: 10
Training loss: 2.6367454528808594
Validation loss: 2.22726438442866

Epoch: 6| Step: 11
Training loss: 1.3118680715560913
Validation loss: 2.206769903500875

Epoch: 6| Step: 12
Training loss: 1.573493242263794
Validation loss: 2.191577593485514

Epoch: 6| Step: 13
Training loss: 1.6882797479629517
Validation loss: 2.180668373902639

Epoch: 284| Step: 0
Training loss: 1.2864398956298828
Validation loss: 2.1849282582600913

Epoch: 6| Step: 1
Training loss: 2.0180697441101074
Validation loss: 2.196960469086965

Epoch: 6| Step: 2
Training loss: 2.4371743202209473
Validation loss: 2.1885743538538613

Epoch: 6| Step: 3
Training loss: 1.560078501701355
Validation loss: 2.1840460101763406

Epoch: 6| Step: 4
Training loss: 2.0725083351135254
Validation loss: 2.213454266389211

Epoch: 6| Step: 5
Training loss: 0.815319299697876
Validation loss: 2.1773524483044944

Epoch: 6| Step: 6
Training loss: 1.2773659229278564
Validation loss: 2.2074715296427407

Epoch: 6| Step: 7
Training loss: 1.9896795749664307
Validation loss: 2.186456084251404

Epoch: 6| Step: 8
Training loss: 1.620208740234375
Validation loss: 2.1731587648391724

Epoch: 6| Step: 9
Training loss: 2.0316407680511475
Validation loss: 2.1826632221539817

Epoch: 6| Step: 10
Training loss: 2.130445957183838
Validation loss: 2.19345231850942

Epoch: 6| Step: 11
Training loss: 2.038114547729492
Validation loss: 2.1686758399009705

Epoch: 6| Step: 12
Training loss: 1.787855863571167
Validation loss: 2.173032760620117

Epoch: 6| Step: 13
Training loss: 1.4135349988937378
Validation loss: 2.1977559526761374

Epoch: 285| Step: 0
Training loss: 1.7367559671401978
Validation loss: 2.1762410203615823

Epoch: 6| Step: 1
Training loss: 1.7340502738952637
Validation loss: 2.168150862058004

Epoch: 6| Step: 2
Training loss: 2.1257991790771484
Validation loss: 2.1636223793029785

Epoch: 6| Step: 3
Training loss: 1.5171599388122559
Validation loss: 2.1734439929326377

Epoch: 6| Step: 4
Training loss: 1.3933770656585693
Validation loss: 2.1862376729647317

Epoch: 6| Step: 5
Training loss: 1.2793927192687988
Validation loss: 2.1765578786532083

Epoch: 6| Step: 6
Training loss: 1.8540384769439697
Validation loss: 2.1741881569226584

Epoch: 6| Step: 7
Training loss: 2.3112149238586426
Validation loss: 2.1802034974098206

Epoch: 6| Step: 8
Training loss: 1.8484382629394531
Validation loss: 2.2037665843963623

Epoch: 6| Step: 9
Training loss: 1.7931344509124756
Validation loss: 2.1872875491778054

Epoch: 6| Step: 10
Training loss: 1.8990274667739868
Validation loss: 2.187181234359741

Epoch: 6| Step: 11
Training loss: 1.737473726272583
Validation loss: 2.197827080885569

Epoch: 6| Step: 12
Training loss: 2.0867881774902344
Validation loss: 2.185827990372976

Epoch: 6| Step: 13
Training loss: 1.994248390197754
Validation loss: 2.198802888393402

Epoch: 286| Step: 0
Training loss: 1.6072921752929688
Validation loss: 2.2171092430750527

Epoch: 6| Step: 1
Training loss: 1.7064021825790405
Validation loss: 2.2420661449432373

Epoch: 6| Step: 2
Training loss: 2.4474339485168457
Validation loss: 2.2528912822405496

Epoch: 6| Step: 3
Training loss: 1.9774458408355713
Validation loss: 2.2765899499257407

Epoch: 6| Step: 4
Training loss: 1.5598829984664917
Validation loss: 2.267868399620056

Epoch: 6| Step: 5
Training loss: 1.98307466506958
Validation loss: 2.2559306621551514

Epoch: 6| Step: 6
Training loss: 1.4482688903808594
Validation loss: 2.2003160317738852

Epoch: 6| Step: 7
Training loss: 1.7282419204711914
Validation loss: 2.185963749885559

Epoch: 6| Step: 8
Training loss: 2.1926586627960205
Validation loss: 2.176132321357727

Epoch: 6| Step: 9
Training loss: 2.0678293704986572
Validation loss: 2.169395367304484

Epoch: 6| Step: 10
Training loss: 1.3912540674209595
Validation loss: 2.185706377029419

Epoch: 6| Step: 11
Training loss: 1.6413322687149048
Validation loss: 2.202848037083944

Epoch: 6| Step: 12
Training loss: 1.4306074380874634
Validation loss: 2.1862942377726235

Epoch: 6| Step: 13
Training loss: 1.7153346538543701
Validation loss: 2.186074912548065

Epoch: 287| Step: 0
Training loss: 1.2470295429229736
Validation loss: 2.2006291151046753

Epoch: 6| Step: 1
Training loss: 1.7567110061645508
Validation loss: 2.1992287039756775

Epoch: 6| Step: 2
Training loss: 2.3049447536468506
Validation loss: 2.196080485979716

Epoch: 6| Step: 3
Training loss: 1.7604389190673828
Validation loss: 2.235458334287008

Epoch: 6| Step: 4
Training loss: 1.6646580696105957
Validation loss: 2.2481447060902915

Epoch: 6| Step: 5
Training loss: 1.49069344997406
Validation loss: 2.2417639891306558

Epoch: 6| Step: 6
Training loss: 1.8382644653320312
Validation loss: 2.2385026812553406

Epoch: 6| Step: 7
Training loss: 1.9749295711517334
Validation loss: 2.2547231117884317

Epoch: 6| Step: 8
Training loss: 2.029061794281006
Validation loss: 2.2061047554016113

Epoch: 6| Step: 9
Training loss: 1.8454910516738892
Validation loss: 2.2029154102007547

Epoch: 6| Step: 10
Training loss: 1.4569437503814697
Validation loss: 2.2197214365005493

Epoch: 6| Step: 11
Training loss: 2.0562078952789307
Validation loss: 2.191659172375997

Epoch: 6| Step: 12
Training loss: 1.3657786846160889
Validation loss: 2.1662606398264566

Epoch: 6| Step: 13
Training loss: 1.5885047912597656
Validation loss: 2.1814224322636924

Epoch: 288| Step: 0
Training loss: 1.5192021131515503
Validation loss: 2.2090489268302917

Epoch: 6| Step: 1
Training loss: 2.114056348800659
Validation loss: 2.1835173765818277

Epoch: 6| Step: 2
Training loss: 2.764024257659912
Validation loss: 2.1893775860468545

Epoch: 6| Step: 3
Training loss: 1.8376500606536865
Validation loss: 2.200347363948822

Epoch: 6| Step: 4
Training loss: 1.636063814163208
Validation loss: 2.198221723238627

Epoch: 6| Step: 5
Training loss: 1.283003807067871
Validation loss: 2.183253288269043

Epoch: 6| Step: 6
Training loss: 1.823598861694336
Validation loss: 2.1959910790125527

Epoch: 6| Step: 7
Training loss: 1.94399094581604
Validation loss: 2.2023810545603433

Epoch: 6| Step: 8
Training loss: 1.6044877767562866
Validation loss: 2.2197606960932412

Epoch: 6| Step: 9
Training loss: 2.235844850540161
Validation loss: 2.194438099861145

Epoch: 6| Step: 10
Training loss: 1.3714935779571533
Validation loss: 2.2254799207051597

Epoch: 6| Step: 11
Training loss: 1.180429220199585
Validation loss: 2.2117711504300437

Epoch: 6| Step: 12
Training loss: 0.8560612201690674
Validation loss: 2.2249008814493814

Epoch: 6| Step: 13
Training loss: 1.5428051948547363
Validation loss: 2.2254172563552856

Epoch: 289| Step: 0
Training loss: 1.3488779067993164
Validation loss: 2.25458025932312

Epoch: 6| Step: 1
Training loss: 1.9196863174438477
Validation loss: 2.261516571044922

Epoch: 6| Step: 2
Training loss: 1.6989128589630127
Validation loss: 2.2477516333262124

Epoch: 6| Step: 3
Training loss: 1.6705906391143799
Validation loss: 2.2580966552098594

Epoch: 6| Step: 4
Training loss: 1.5076625347137451
Validation loss: 2.2494165301322937

Epoch: 6| Step: 5
Training loss: 1.2608132362365723
Validation loss: 2.243393878142039

Epoch: 6| Step: 6
Training loss: 2.085303783416748
Validation loss: 2.2504877050717673

Epoch: 6| Step: 7
Training loss: 1.5993086099624634
Validation loss: 2.2280223766962686

Epoch: 6| Step: 8
Training loss: 1.442456841468811
Validation loss: 2.2233096162478128

Epoch: 6| Step: 9
Training loss: 1.6134940385818481
Validation loss: 2.221314013004303

Epoch: 6| Step: 10
Training loss: 2.528230667114258
Validation loss: 2.2098111708958945

Epoch: 6| Step: 11
Training loss: 1.510001301765442
Validation loss: 2.2055741945902505

Epoch: 6| Step: 12
Training loss: 2.239494562149048
Validation loss: 2.2205491860707602

Epoch: 6| Step: 13
Training loss: 1.567932367324829
Validation loss: 2.2144619623819985

Epoch: 290| Step: 0
Training loss: 1.4041907787322998
Validation loss: 2.2030993501345315

Epoch: 6| Step: 1
Training loss: 1.6569020748138428
Validation loss: 2.1944689949353537

Epoch: 6| Step: 2
Training loss: 1.3768208026885986
Validation loss: 2.19757088025411

Epoch: 6| Step: 3
Training loss: 1.5378615856170654
Validation loss: 2.1933640042940774

Epoch: 6| Step: 4
Training loss: 2.661137104034424
Validation loss: 2.1957744359970093

Epoch: 6| Step: 5
Training loss: 1.715055227279663
Validation loss: 2.1777679125467935

Epoch: 6| Step: 6
Training loss: 1.3539763689041138
Validation loss: 2.19113423426946

Epoch: 6| Step: 7
Training loss: 2.4909496307373047
Validation loss: 2.1930005153020224

Epoch: 6| Step: 8
Training loss: 1.4418067932128906
Validation loss: 2.18871142466863

Epoch: 6| Step: 9
Training loss: 1.3851944208145142
Validation loss: 2.1796059012413025

Epoch: 6| Step: 10
Training loss: 2.2528820037841797
Validation loss: 2.1868807474772134

Epoch: 6| Step: 11
Training loss: 1.0470861196517944
Validation loss: 2.188709557056427

Epoch: 6| Step: 12
Training loss: 1.4884452819824219
Validation loss: 2.195990006128947

Epoch: 6| Step: 13
Training loss: 1.772654414176941
Validation loss: 2.2024256785710654

Epoch: 291| Step: 0
Training loss: 1.74611496925354
Validation loss: 2.187364180882772

Epoch: 6| Step: 1
Training loss: 1.741334319114685
Validation loss: 2.1900042494138083

Epoch: 6| Step: 2
Training loss: 2.096219539642334
Validation loss: 2.2067599495251975

Epoch: 6| Step: 3
Training loss: 2.5317325592041016
Validation loss: 2.216758052508036

Epoch: 6| Step: 4
Training loss: 1.286972999572754
Validation loss: 2.190946877002716

Epoch: 6| Step: 5
Training loss: 1.2703709602355957
Validation loss: 2.2150569955507913

Epoch: 6| Step: 6
Training loss: 1.1829476356506348
Validation loss: 2.1961363554000854

Epoch: 6| Step: 7
Training loss: 1.43324613571167
Validation loss: 2.2120631535847983

Epoch: 6| Step: 8
Training loss: 1.4315272569656372
Validation loss: 2.202153960863749

Epoch: 6| Step: 9
Training loss: 0.7557305693626404
Validation loss: 2.238382339477539

Epoch: 6| Step: 10
Training loss: 1.473701000213623
Validation loss: 2.196522275606791

Epoch: 6| Step: 11
Training loss: 2.4263381958007812
Validation loss: 2.201085090637207

Epoch: 6| Step: 12
Training loss: 1.4894627332687378
Validation loss: 2.1952368021011353

Epoch: 6| Step: 13
Training loss: 2.6378440856933594
Validation loss: 2.2310129006703696

Epoch: 292| Step: 0
Training loss: 1.5399104356765747
Validation loss: 2.2190420627593994

Epoch: 6| Step: 1
Training loss: 1.412756085395813
Validation loss: 2.2062381903330484

Epoch: 6| Step: 2
Training loss: 1.7712839841842651
Validation loss: 2.2125773827234902

Epoch: 6| Step: 3
Training loss: 1.5920027494430542
Validation loss: 2.2185224692026773

Epoch: 6| Step: 4
Training loss: 1.5714889764785767
Validation loss: 2.219138960043589

Epoch: 6| Step: 5
Training loss: 1.898765206336975
Validation loss: 2.203668475151062

Epoch: 6| Step: 6
Training loss: 1.6486079692840576
Validation loss: 2.194601615269979

Epoch: 6| Step: 7
Training loss: 2.3543875217437744
Validation loss: 2.192082862059275

Epoch: 6| Step: 8
Training loss: 1.2423334121704102
Validation loss: 2.1825382510821023

Epoch: 6| Step: 9
Training loss: 2.046330451965332
Validation loss: 2.1793163816134133

Epoch: 6| Step: 10
Training loss: 1.2700493335723877
Validation loss: 2.190980394681295

Epoch: 6| Step: 11
Training loss: 1.6071410179138184
Validation loss: 2.1992913484573364

Epoch: 6| Step: 12
Training loss: 1.6778404712677002
Validation loss: 2.1818872888882956

Epoch: 6| Step: 13
Training loss: 1.8952807188034058
Validation loss: 2.18622620900472

Epoch: 293| Step: 0
Training loss: 2.001537322998047
Validation loss: 2.1870807806650796

Epoch: 6| Step: 1
Training loss: 1.2230770587921143
Validation loss: 2.207509160041809

Epoch: 6| Step: 2
Training loss: 1.2497386932373047
Validation loss: 2.182968854904175

Epoch: 6| Step: 3
Training loss: 1.5967715978622437
Validation loss: 2.1748809019724527

Epoch: 6| Step: 4
Training loss: 1.9278854131698608
Validation loss: 2.2199445962905884

Epoch: 6| Step: 5
Training loss: 1.0963542461395264
Validation loss: 2.205000956853231

Epoch: 6| Step: 6
Training loss: 2.249129295349121
Validation loss: 2.2184199889500937

Epoch: 6| Step: 7
Training loss: 1.5078784227371216
Validation loss: 2.2375831604003906

Epoch: 6| Step: 8
Training loss: 2.0821633338928223
Validation loss: 2.2641013463338218

Epoch: 6| Step: 9
Training loss: 1.716725468635559
Validation loss: 2.2778865893681846

Epoch: 6| Step: 10
Training loss: 1.7740033864974976
Validation loss: 2.2776934703191123

Epoch: 6| Step: 11
Training loss: 1.769812822341919
Validation loss: 2.2677324414253235

Epoch: 6| Step: 12
Training loss: 1.4677059650421143
Validation loss: 2.261658271153768

Epoch: 6| Step: 13
Training loss: 1.9048174619674683
Validation loss: 2.234809180100759

Epoch: 294| Step: 0
Training loss: 1.293334722518921
Validation loss: 2.2422096927960715

Epoch: 6| Step: 1
Training loss: 1.9848148822784424
Validation loss: 2.199269413948059

Epoch: 6| Step: 2
Training loss: 1.7733582258224487
Validation loss: 2.1784685452779136

Epoch: 6| Step: 3
Training loss: 1.3715051412582397
Validation loss: 2.225111246109009

Epoch: 6| Step: 4
Training loss: 1.6455278396606445
Validation loss: 2.2058028181393943

Epoch: 6| Step: 5
Training loss: 2.036552667617798
Validation loss: 2.189205606778463

Epoch: 6| Step: 6
Training loss: 1.6263618469238281
Validation loss: 2.1778789361317954

Epoch: 6| Step: 7
Training loss: 1.7073204517364502
Validation loss: 2.1711254318555198

Epoch: 6| Step: 8
Training loss: 1.3269696235656738
Validation loss: 2.159108022848765

Epoch: 6| Step: 9
Training loss: 1.6067715883255005
Validation loss: 2.1711795330047607

Epoch: 6| Step: 10
Training loss: 1.9454610347747803
Validation loss: 2.173264960447947

Epoch: 6| Step: 11
Training loss: 1.9690203666687012
Validation loss: 2.1692154010136924

Epoch: 6| Step: 12
Training loss: 1.7734731435775757
Validation loss: 2.1623313625653586

Epoch: 6| Step: 13
Training loss: 1.7522177696228027
Validation loss: 2.1590049068133035

Epoch: 295| Step: 0
Training loss: 1.5014193058013916
Validation loss: 2.1830520629882812

Epoch: 6| Step: 1
Training loss: 1.668835163116455
Validation loss: 2.1828444401423135

Epoch: 6| Step: 2
Training loss: 1.5177364349365234
Validation loss: 2.2078991731007895

Epoch: 6| Step: 3
Training loss: 1.7839736938476562
Validation loss: 2.2211458683013916

Epoch: 6| Step: 4
Training loss: 1.5542088747024536
Validation loss: 2.195846418539683

Epoch: 6| Step: 5
Training loss: 2.6554927825927734
Validation loss: 2.2079261342684426

Epoch: 6| Step: 6
Training loss: 1.488010287284851
Validation loss: 2.1879175504048667

Epoch: 6| Step: 7
Training loss: 1.5614224672317505
Validation loss: 2.202321390310923

Epoch: 6| Step: 8
Training loss: 1.8526901006698608
Validation loss: 2.190645972887675

Epoch: 6| Step: 9
Training loss: 2.2034990787506104
Validation loss: 2.211988687515259

Epoch: 6| Step: 10
Training loss: 1.9941210746765137
Validation loss: 2.217715303103129

Epoch: 6| Step: 11
Training loss: 1.7656913995742798
Validation loss: 2.195801834265391

Epoch: 6| Step: 12
Training loss: 1.4121522903442383
Validation loss: 2.201392630736033

Epoch: 6| Step: 13
Training loss: 1.3707036972045898
Validation loss: 2.188471953074137

Epoch: 296| Step: 0
Training loss: 1.9801533222198486
Validation loss: 2.2059938510258994

Epoch: 6| Step: 1
Training loss: 1.6166133880615234
Validation loss: 2.2035670280456543

Epoch: 6| Step: 2
Training loss: 1.141724705696106
Validation loss: 2.189311146736145

Epoch: 6| Step: 3
Training loss: 1.593300223350525
Validation loss: 2.225712796052297

Epoch: 6| Step: 4
Training loss: 1.5963221788406372
Validation loss: 2.241045276323954

Epoch: 6| Step: 5
Training loss: 2.4927375316619873
Validation loss: 2.248923659324646

Epoch: 6| Step: 6
Training loss: 2.2575769424438477
Validation loss: 2.2457809448242188

Epoch: 6| Step: 7
Training loss: 2.0621838569641113
Validation loss: 2.2230428059895835

Epoch: 6| Step: 8
Training loss: 1.4946975708007812
Validation loss: 2.20982559521993

Epoch: 6| Step: 9
Training loss: 1.7188084125518799
Validation loss: 2.193197031815847

Epoch: 6| Step: 10
Training loss: 0.9886822700500488
Validation loss: 2.1790425380071006

Epoch: 6| Step: 11
Training loss: 1.4123122692108154
Validation loss: 2.1890301505724588

Epoch: 6| Step: 12
Training loss: 1.7362406253814697
Validation loss: 2.174071172873179

Epoch: 6| Step: 13
Training loss: 2.3363678455352783
Validation loss: 2.1808010737101235

Epoch: 297| Step: 0
Training loss: 2.3459105491638184
Validation loss: 2.186657945315043

Epoch: 6| Step: 1
Training loss: 3.1054248809814453
Validation loss: 2.1946852803230286

Epoch: 6| Step: 2
Training loss: 1.863969087600708
Validation loss: 2.187834640343984

Epoch: 6| Step: 3
Training loss: 1.6995325088500977
Validation loss: 2.186838606993357

Epoch: 6| Step: 4
Training loss: 1.8902952671051025
Validation loss: 2.1496040423711142

Epoch: 6| Step: 5
Training loss: 1.6569061279296875
Validation loss: 2.1609697540601096

Epoch: 6| Step: 6
Training loss: 1.538097620010376
Validation loss: 2.171673913796743

Epoch: 6| Step: 7
Training loss: 1.662466049194336
Validation loss: 2.191985825697581

Epoch: 6| Step: 8
Training loss: 1.5992275476455688
Validation loss: 2.185121695200602

Epoch: 6| Step: 9
Training loss: 1.5207865238189697
Validation loss: 2.160511612892151

Epoch: 6| Step: 10
Training loss: 1.3365918397903442
Validation loss: 2.183365980784098

Epoch: 6| Step: 11
Training loss: 1.9277338981628418
Validation loss: 2.160912573337555

Epoch: 6| Step: 12
Training loss: 0.7098938822746277
Validation loss: 2.1847993532816568

Epoch: 6| Step: 13
Training loss: 1.3424434661865234
Validation loss: 2.2076057394345603

Epoch: 298| Step: 0
Training loss: 1.0133538246154785
Validation loss: 2.1773398717244468

Epoch: 6| Step: 1
Training loss: 1.668409824371338
Validation loss: 2.164298633734385

Epoch: 6| Step: 2
Training loss: 1.5092617273330688
Validation loss: 2.173475682735443

Epoch: 6| Step: 3
Training loss: 1.6200602054595947
Validation loss: 2.202384869257609

Epoch: 6| Step: 4
Training loss: 1.9781779050827026
Validation loss: 2.1876715620358786

Epoch: 6| Step: 5
Training loss: 1.991349220275879
Validation loss: 2.1895075837771096

Epoch: 6| Step: 6
Training loss: 1.8926262855529785
Validation loss: 2.1984169085820517

Epoch: 6| Step: 7
Training loss: 1.6355090141296387
Validation loss: 2.2010160287221274

Epoch: 6| Step: 8
Training loss: 2.1196439266204834
Validation loss: 2.2095136046409607

Epoch: 6| Step: 9
Training loss: 2.057849407196045
Validation loss: 2.183557152748108

Epoch: 6| Step: 10
Training loss: 2.057896137237549
Validation loss: 2.196812152862549

Epoch: 6| Step: 11
Training loss: 1.1936249732971191
Validation loss: 2.2030434608459473

Epoch: 6| Step: 12
Training loss: 1.0446491241455078
Validation loss: 2.2307294607162476

Epoch: 6| Step: 13
Training loss: 1.6127254962921143
Validation loss: 2.2111218571662903

Epoch: 299| Step: 0
Training loss: 2.2927300930023193
Validation loss: 2.189880987008413

Epoch: 6| Step: 1
Training loss: 1.4771397113800049
Validation loss: 2.2024215857187905

Epoch: 6| Step: 2
Training loss: 1.7155400514602661
Validation loss: 2.2071197231610618

Epoch: 6| Step: 3
Training loss: 1.7381452322006226
Validation loss: 2.206478178501129

Epoch: 6| Step: 4
Training loss: 1.273880124092102
Validation loss: 2.2001037200291953

Epoch: 6| Step: 5
Training loss: 1.3846373558044434
Validation loss: 2.185059448083242

Epoch: 6| Step: 6
Training loss: 1.6427838802337646
Validation loss: 2.1994338631629944

Epoch: 6| Step: 7
Training loss: 1.2119946479797363
Validation loss: 2.201141436894735

Epoch: 6| Step: 8
Training loss: 2.206275224685669
Validation loss: 2.247383713722229

Epoch: 6| Step: 9
Training loss: 1.6070082187652588
Validation loss: 2.209382096926371

Epoch: 6| Step: 10
Training loss: 1.9748618602752686
Validation loss: 2.26711905002594

Epoch: 6| Step: 11
Training loss: 1.7460734844207764
Validation loss: 2.239905059337616

Epoch: 6| Step: 12
Training loss: 1.5219193696975708
Validation loss: 2.241376002629598

Epoch: 6| Step: 13
Training loss: 1.7431542873382568
Validation loss: 2.257218658924103

Epoch: 300| Step: 0
Training loss: 1.3880650997161865
Validation loss: 2.2235392133394876

Epoch: 6| Step: 1
Training loss: 1.969623327255249
Validation loss: 2.201765457789103

Epoch: 6| Step: 2
Training loss: 1.0667120218276978
Validation loss: 2.1995598872502646

Epoch: 6| Step: 3
Training loss: 1.9904611110687256
Validation loss: 2.183038850625356

Epoch: 6| Step: 4
Training loss: 1.3407717943191528
Validation loss: 2.149411757787069

Epoch: 6| Step: 5
Training loss: 1.6453578472137451
Validation loss: 2.154405434926351

Epoch: 6| Step: 6
Training loss: 1.6406604051589966
Validation loss: 2.180901805559794

Epoch: 6| Step: 7
Training loss: 1.9302384853363037
Validation loss: 2.1664726734161377

Epoch: 6| Step: 8
Training loss: 2.336942195892334
Validation loss: 2.154588043689728

Epoch: 6| Step: 9
Training loss: 1.4613839387893677
Validation loss: 2.2058297395706177

Epoch: 6| Step: 10
Training loss: 1.5198612213134766
Validation loss: 2.167680025100708

Epoch: 6| Step: 11
Training loss: 1.347501277923584
Validation loss: 2.1829639673233032

Epoch: 6| Step: 12
Training loss: 1.528336763381958
Validation loss: 2.1983259121576944

Epoch: 6| Step: 13
Training loss: 2.166098117828369
Validation loss: 2.183895170688629

Epoch: 301| Step: 0
Training loss: 1.8994168043136597
Validation loss: 2.2046321431795755

Epoch: 6| Step: 1
Training loss: 2.112882375717163
Validation loss: 2.1865034898122153

Epoch: 6| Step: 2
Training loss: 1.267509937286377
Validation loss: 2.2122880617777505

Epoch: 6| Step: 3
Training loss: 1.4317586421966553
Validation loss: 2.2041927576065063

Epoch: 6| Step: 4
Training loss: 1.5945672988891602
Validation loss: 2.1958853602409363

Epoch: 6| Step: 5
Training loss: 1.7830445766448975
Validation loss: 2.2095053593317666

Epoch: 6| Step: 6
Training loss: 1.9686956405639648
Validation loss: 2.2187280654907227

Epoch: 6| Step: 7
Training loss: 1.5296932458877563
Validation loss: 2.2026519775390625

Epoch: 6| Step: 8
Training loss: 1.7868642807006836
Validation loss: 2.209423820177714

Epoch: 6| Step: 9
Training loss: 1.4952996969223022
Validation loss: 2.191971262296041

Epoch: 6| Step: 10
Training loss: 1.2974070310592651
Validation loss: 2.207749903202057

Epoch: 6| Step: 11
Training loss: 1.8870517015457153
Validation loss: 2.2299787600835166

Epoch: 6| Step: 12
Training loss: 2.007503032684326
Validation loss: 2.2194959918657937

Epoch: 6| Step: 13
Training loss: 1.4659851789474487
Validation loss: 2.2533305088678994

Epoch: 302| Step: 0
Training loss: 1.2933841943740845
Validation loss: 2.2790119647979736

Epoch: 6| Step: 1
Training loss: 2.3603506088256836
Validation loss: 2.2382758061091104

Epoch: 6| Step: 2
Training loss: 1.5532748699188232
Validation loss: 2.241910437742869

Epoch: 6| Step: 3
Training loss: 1.5562670230865479
Validation loss: 2.256662130355835

Epoch: 6| Step: 4
Training loss: 1.2983691692352295
Validation loss: 2.2772705952326455

Epoch: 6| Step: 5
Training loss: 1.3181328773498535
Validation loss: 2.243979533513387

Epoch: 6| Step: 6
Training loss: 1.5695059299468994
Validation loss: 2.2257408102353415

Epoch: 6| Step: 7
Training loss: 2.144028663635254
Validation loss: 2.235766371091207

Epoch: 6| Step: 8
Training loss: 1.445303201675415
Validation loss: 2.2372397979100547

Epoch: 6| Step: 9
Training loss: 1.8540278673171997
Validation loss: 2.2385509808858237

Epoch: 6| Step: 10
Training loss: 2.347569465637207
Validation loss: 2.233239690462748

Epoch: 6| Step: 11
Training loss: 0.975164532661438
Validation loss: 2.232080360253652

Epoch: 6| Step: 12
Training loss: 2.0335352420806885
Validation loss: 2.257537583510081

Epoch: 6| Step: 13
Training loss: 2.0099377632141113
Validation loss: 2.2117955485979715

Epoch: 303| Step: 0
Training loss: 1.5876469612121582
Validation loss: 2.218509554862976

Epoch: 6| Step: 1
Training loss: 1.4257904291152954
Validation loss: 2.211039423942566

Epoch: 6| Step: 2
Training loss: 1.2698135375976562
Validation loss: 2.2374616861343384

Epoch: 6| Step: 3
Training loss: 1.7140573263168335
Validation loss: 2.212470054626465

Epoch: 6| Step: 4
Training loss: 2.06561541557312
Validation loss: 2.264268080393473

Epoch: 6| Step: 5
Training loss: 1.3466105461120605
Validation loss: 2.2488285501797995

Epoch: 6| Step: 6
Training loss: 1.3418056964874268
Validation loss: 2.2631206711133323

Epoch: 6| Step: 7
Training loss: 1.8122574090957642
Validation loss: 2.2880768378575644

Epoch: 6| Step: 8
Training loss: 1.8937795162200928
Validation loss: 2.2764610648155212

Epoch: 6| Step: 9
Training loss: 1.4889273643493652
Validation loss: 2.287489374478658

Epoch: 6| Step: 10
Training loss: 2.3415884971618652
Validation loss: 2.31099796295166

Epoch: 6| Step: 11
Training loss: 1.7292710542678833
Validation loss: 2.275136868158976

Epoch: 6| Step: 12
Training loss: 1.0432292222976685
Validation loss: 2.269708275794983

Epoch: 6| Step: 13
Training loss: 2.2695581912994385
Validation loss: 2.2495604356129966

Epoch: 304| Step: 0
Training loss: 2.0865397453308105
Validation loss: 2.2503183086713157

Epoch: 6| Step: 1
Training loss: 1.3548251390457153
Validation loss: 2.2010304927825928

Epoch: 6| Step: 2
Training loss: 1.7425947189331055
Validation loss: 2.240357518196106

Epoch: 6| Step: 3
Training loss: 1.6251227855682373
Validation loss: 2.2141418854395547

Epoch: 6| Step: 4
Training loss: 1.8222990036010742
Validation loss: 2.1883267164230347

Epoch: 6| Step: 5
Training loss: 1.9257899522781372
Validation loss: 2.166457732518514

Epoch: 6| Step: 6
Training loss: 1.1640307903289795
Validation loss: 2.189124266306559

Epoch: 6| Step: 7
Training loss: 1.9629266262054443
Validation loss: 2.1987739404042563

Epoch: 6| Step: 8
Training loss: 2.109445571899414
Validation loss: 2.1972892681757608

Epoch: 6| Step: 9
Training loss: 1.178650975227356
Validation loss: 2.2378969391187034

Epoch: 6| Step: 10
Training loss: 1.5177711248397827
Validation loss: 2.221621811389923

Epoch: 6| Step: 11
Training loss: 1.4780209064483643
Validation loss: 2.22483762105306

Epoch: 6| Step: 12
Training loss: 1.1980774402618408
Validation loss: 2.230048576990763

Epoch: 6| Step: 13
Training loss: 2.023935317993164
Validation loss: 2.2275829315185547

Epoch: 305| Step: 0
Training loss: 1.0935440063476562
Validation loss: 2.272182583808899

Epoch: 6| Step: 1
Training loss: 1.8755924701690674
Validation loss: 2.277569075425466

Epoch: 6| Step: 2
Training loss: 1.284909963607788
Validation loss: 2.2775166034698486

Epoch: 6| Step: 3
Training loss: 2.018564224243164
Validation loss: 2.2411283254623413

Epoch: 6| Step: 4
Training loss: 2.2798948287963867
Validation loss: 2.2070509592692056

Epoch: 6| Step: 5
Training loss: 1.522904396057129
Validation loss: 2.204137841860453

Epoch: 6| Step: 6
Training loss: 1.2924827337265015
Validation loss: 2.204812745253245

Epoch: 6| Step: 7
Training loss: 1.9642457962036133
Validation loss: 2.1750929156939187

Epoch: 6| Step: 8
Training loss: 1.5561760663986206
Validation loss: 2.198119858900706

Epoch: 6| Step: 9
Training loss: 1.2811589241027832
Validation loss: 2.217966596285502

Epoch: 6| Step: 10
Training loss: 2.4786853790283203
Validation loss: 2.1959511240323386

Epoch: 6| Step: 11
Training loss: 1.5718748569488525
Validation loss: 2.203418016433716

Epoch: 6| Step: 12
Training loss: 1.5942785739898682
Validation loss: 2.1936919490496316

Epoch: 6| Step: 13
Training loss: 1.81688392162323
Validation loss: 2.206464250882467

Epoch: 306| Step: 0
Training loss: 1.1354210376739502
Validation loss: 2.1860490838686624

Epoch: 6| Step: 1
Training loss: 2.3185739517211914
Validation loss: 2.200105130672455

Epoch: 6| Step: 2
Training loss: 1.4829001426696777
Validation loss: 2.2416093349456787

Epoch: 6| Step: 3
Training loss: 2.238419771194458
Validation loss: 2.2367292642593384

Epoch: 6| Step: 4
Training loss: 1.4126794338226318
Validation loss: 2.252857208251953

Epoch: 6| Step: 5
Training loss: 1.372722864151001
Validation loss: 2.234815319379171

Epoch: 6| Step: 6
Training loss: 1.722537636756897
Validation loss: 2.225263774394989

Epoch: 6| Step: 7
Training loss: 1.668670415878296
Validation loss: 2.1894180377324424

Epoch: 6| Step: 8
Training loss: 2.310363531112671
Validation loss: 2.2477006316184998

Epoch: 6| Step: 9
Training loss: 1.0858980417251587
Validation loss: 2.2534640034039817

Epoch: 6| Step: 10
Training loss: 1.6200722455978394
Validation loss: 2.2544240156809487

Epoch: 6| Step: 11
Training loss: 1.909555196762085
Validation loss: 2.198706269264221

Epoch: 6| Step: 12
Training loss: 1.1575671434402466
Validation loss: 2.1942015091578164

Epoch: 6| Step: 13
Training loss: 1.1798264980316162
Validation loss: 2.187789022922516

Epoch: 307| Step: 0
Training loss: 1.8185895681381226
Validation loss: 2.2001622517903647

Epoch: 6| Step: 1
Training loss: 0.8699961304664612
Validation loss: 2.1887126167615256

Epoch: 6| Step: 2
Training loss: 1.5027742385864258
Validation loss: 2.1699036161104837

Epoch: 6| Step: 3
Training loss: 1.7405060529708862
Validation loss: 2.191778759161631

Epoch: 6| Step: 4
Training loss: 1.7713431119918823
Validation loss: 2.1764595905939736

Epoch: 6| Step: 5
Training loss: 1.1762739419937134
Validation loss: 2.1888014674186707

Epoch: 6| Step: 6
Training loss: 1.9500725269317627
Validation loss: 2.200552543004354

Epoch: 6| Step: 7
Training loss: 1.6497477293014526
Validation loss: 2.178894340991974

Epoch: 6| Step: 8
Training loss: 2.2559046745300293
Validation loss: 2.199984351793925

Epoch: 6| Step: 9
Training loss: 2.0078518390655518
Validation loss: 2.2545783122380576

Epoch: 6| Step: 10
Training loss: 1.434427261352539
Validation loss: 2.2323655684789023

Epoch: 6| Step: 11
Training loss: 1.9015486240386963
Validation loss: 2.2389577825864158

Epoch: 6| Step: 12
Training loss: 1.2833802700042725
Validation loss: 2.2446122964223227

Epoch: 6| Step: 13
Training loss: 2.026431083679199
Validation loss: 2.235270063082377

Epoch: 308| Step: 0
Training loss: 1.0970262289047241
Validation loss: 2.2419371604919434

Epoch: 6| Step: 1
Training loss: 1.2502936124801636
Validation loss: 2.229324201742808

Epoch: 6| Step: 2
Training loss: 1.8624497652053833
Validation loss: 2.2343826293945312

Epoch: 6| Step: 3
Training loss: 0.9225103855133057
Validation loss: 2.212985356648763

Epoch: 6| Step: 4
Training loss: 1.6159443855285645
Validation loss: 2.2131937543551126

Epoch: 6| Step: 5
Training loss: 2.649528980255127
Validation loss: 2.2184845209121704

Epoch: 6| Step: 6
Training loss: 1.8266664743423462
Validation loss: 2.1969990730285645

Epoch: 6| Step: 7
Training loss: 2.2194745540618896
Validation loss: 2.2435863614082336

Epoch: 6| Step: 8
Training loss: 2.014881134033203
Validation loss: 2.216811498006185

Epoch: 6| Step: 9
Training loss: 1.4982006549835205
Validation loss: 2.2218592166900635

Epoch: 6| Step: 10
Training loss: 1.5192581415176392
Validation loss: 2.2618923584620156

Epoch: 6| Step: 11
Training loss: 1.5108017921447754
Validation loss: 2.252490441004435

Epoch: 6| Step: 12
Training loss: 2.2012853622436523
Validation loss: 2.281842072804769

Epoch: 6| Step: 13
Training loss: 1.7752963304519653
Validation loss: 2.248364965120951

Epoch: 309| Step: 0
Training loss: 1.5477226972579956
Validation loss: 2.2715853452682495

Epoch: 6| Step: 1
Training loss: 1.4223836660385132
Validation loss: 2.2739179929097495

Epoch: 6| Step: 2
Training loss: 2.2937867641448975
Validation loss: 2.2143503030141196

Epoch: 6| Step: 3
Training loss: 1.4602628946304321
Validation loss: 2.156892697016398

Epoch: 6| Step: 4
Training loss: 1.1190295219421387
Validation loss: 2.219783922036489

Epoch: 6| Step: 5
Training loss: 1.2991236448287964
Validation loss: 2.2113887071609497

Epoch: 6| Step: 6
Training loss: 1.2797678709030151
Validation loss: 2.1813772320747375

Epoch: 6| Step: 7
Training loss: 2.0458664894104004
Validation loss: 2.186153074105581

Epoch: 6| Step: 8
Training loss: 1.9848055839538574
Validation loss: 2.2012787659962973

Epoch: 6| Step: 9
Training loss: 1.616268515586853
Validation loss: 2.2232678532600403

Epoch: 6| Step: 10
Training loss: 1.794141411781311
Validation loss: 2.1960801680882773

Epoch: 6| Step: 11
Training loss: 1.8242954015731812
Validation loss: 2.1940676967302957

Epoch: 6| Step: 12
Training loss: 2.1594791412353516
Validation loss: 2.1950997511545816

Epoch: 6| Step: 13
Training loss: 1.9842963218688965
Validation loss: 2.193861265977224

Epoch: 310| Step: 0
Training loss: 1.2060742378234863
Validation loss: 2.2235180735588074

Epoch: 6| Step: 1
Training loss: 1.286057710647583
Validation loss: 2.215916713078817

Epoch: 6| Step: 2
Training loss: 1.3230211734771729
Validation loss: 2.2229188680648804

Epoch: 6| Step: 3
Training loss: 1.8824914693832397
Validation loss: 2.2348773876825967

Epoch: 6| Step: 4
Training loss: 1.4217402935028076
Validation loss: 2.241830905278524

Epoch: 6| Step: 5
Training loss: 2.357074737548828
Validation loss: 2.230348070462545

Epoch: 6| Step: 6
Training loss: 1.5618014335632324
Validation loss: 2.2762686014175415

Epoch: 6| Step: 7
Training loss: 1.6600186824798584
Validation loss: 2.2569209933280945

Epoch: 6| Step: 8
Training loss: 2.2941195964813232
Validation loss: 2.2794992923736572

Epoch: 6| Step: 9
Training loss: 2.0146312713623047
Validation loss: 2.252232809861501

Epoch: 6| Step: 10
Training loss: 1.5757156610488892
Validation loss: 2.2515025536219277

Epoch: 6| Step: 11
Training loss: 1.2378054857254028
Validation loss: 2.243239184220632

Epoch: 6| Step: 12
Training loss: 1.3827635049819946
Validation loss: 2.24593722820282

Epoch: 6| Step: 13
Training loss: 1.4556446075439453
Validation loss: 2.2368231614430747

Epoch: 311| Step: 0
Training loss: 1.1767354011535645
Validation loss: 2.233439346154531

Epoch: 6| Step: 1
Training loss: 1.695554256439209
Validation loss: 2.2394270300865173

Epoch: 6| Step: 2
Training loss: 1.3950629234313965
Validation loss: 2.2398715813954673

Epoch: 6| Step: 3
Training loss: 1.8217878341674805
Validation loss: 2.241132934888204

Epoch: 6| Step: 4
Training loss: 1.189229965209961
Validation loss: 2.2577116092046103

Epoch: 6| Step: 5
Training loss: 1.4136848449707031
Validation loss: 2.2166595458984375

Epoch: 6| Step: 6
Training loss: 1.5117496252059937
Validation loss: 2.213880022366842

Epoch: 6| Step: 7
Training loss: 1.438817024230957
Validation loss: 2.223840673764547

Epoch: 6| Step: 8
Training loss: 2.4561755657196045
Validation loss: 2.2163445949554443

Epoch: 6| Step: 9
Training loss: 1.7499006986618042
Validation loss: 2.2407939434051514

Epoch: 6| Step: 10
Training loss: 1.5393221378326416
Validation loss: 2.2275846799214682

Epoch: 6| Step: 11
Training loss: 1.7400954961776733
Validation loss: 2.192655841509501

Epoch: 6| Step: 12
Training loss: 2.174513578414917
Validation loss: 2.2028000354766846

Epoch: 6| Step: 13
Training loss: 1.7660020589828491
Validation loss: 2.2199689149856567

Epoch: 312| Step: 0
Training loss: 2.1604666709899902
Validation loss: 2.216041306654612

Epoch: 6| Step: 1
Training loss: 1.1589887142181396
Validation loss: 2.2062139312426248

Epoch: 6| Step: 2
Training loss: 1.906343936920166
Validation loss: 2.202662448088328

Epoch: 6| Step: 3
Training loss: 1.900402545928955
Validation loss: 2.192399263381958

Epoch: 6| Step: 4
Training loss: 1.6159336566925049
Validation loss: 2.191145896911621

Epoch: 6| Step: 5
Training loss: 1.6686363220214844
Validation loss: 2.1893251538276672

Epoch: 6| Step: 6
Training loss: 2.189908981323242
Validation loss: 2.203927437464396

Epoch: 6| Step: 7
Training loss: 1.9648981094360352
Validation loss: 2.1800973614056907

Epoch: 6| Step: 8
Training loss: 1.6880096197128296
Validation loss: 2.2223863204320273

Epoch: 6| Step: 9
Training loss: 1.1062930822372437
Validation loss: 2.2125760912895203

Epoch: 6| Step: 10
Training loss: 1.273119330406189
Validation loss: 2.229949414730072

Epoch: 6| Step: 11
Training loss: 1.9619643688201904
Validation loss: 2.2035301129023233

Epoch: 6| Step: 12
Training loss: 1.0284086465835571
Validation loss: 2.203710953394572

Epoch: 6| Step: 13
Training loss: 1.453757643699646
Validation loss: 2.214956263701121

Epoch: 313| Step: 0
Training loss: 1.5947420597076416
Validation loss: 2.2142486770947776

Epoch: 6| Step: 1
Training loss: 1.471718430519104
Validation loss: 2.1755014856656394

Epoch: 6| Step: 2
Training loss: 1.8461170196533203
Validation loss: 2.1950611074765525

Epoch: 6| Step: 3
Training loss: 1.2516478300094604
Validation loss: 2.184971511363983

Epoch: 6| Step: 4
Training loss: 2.063967704772949
Validation loss: 2.2026492754618325

Epoch: 6| Step: 5
Training loss: 1.797597885131836
Validation loss: 2.1839588284492493

Epoch: 6| Step: 6
Training loss: 1.2550511360168457
Validation loss: 2.2034422953923545

Epoch: 6| Step: 7
Training loss: 1.7413915395736694
Validation loss: 2.21409277121226

Epoch: 6| Step: 8
Training loss: 1.6713594198226929
Validation loss: 2.1961230039596558

Epoch: 6| Step: 9
Training loss: 1.7575411796569824
Validation loss: 2.1899508833885193

Epoch: 6| Step: 10
Training loss: 1.585115671157837
Validation loss: 2.232897241910299

Epoch: 6| Step: 11
Training loss: 1.396466612815857
Validation loss: 2.2094346284866333

Epoch: 6| Step: 12
Training loss: 2.191582679748535
Validation loss: 2.2117178241411843

Epoch: 6| Step: 13
Training loss: 1.5456492900848389
Validation loss: 2.222910006841024

Epoch: 314| Step: 0
Training loss: 1.4390640258789062
Validation loss: 2.257535775502523

Epoch: 6| Step: 1
Training loss: 1.577524185180664
Validation loss: 2.221594969431559

Epoch: 6| Step: 2
Training loss: 1.5390294790267944
Validation loss: 2.1991331577301025

Epoch: 6| Step: 3
Training loss: 1.2313933372497559
Validation loss: 2.1918013095855713

Epoch: 6| Step: 4
Training loss: 1.3614048957824707
Validation loss: 2.1563138167063394

Epoch: 6| Step: 5
Training loss: 1.895334243774414
Validation loss: 2.2118996183077493

Epoch: 6| Step: 6
Training loss: 1.413960337638855
Validation loss: 2.184703210989634

Epoch: 6| Step: 7
Training loss: 2.3297977447509766
Validation loss: 2.187344014644623

Epoch: 6| Step: 8
Training loss: 1.6358423233032227
Validation loss: 2.226156234741211

Epoch: 6| Step: 9
Training loss: 1.916365385055542
Validation loss: 2.182878096898397

Epoch: 6| Step: 10
Training loss: 1.4787073135375977
Validation loss: 2.1821306149164834

Epoch: 6| Step: 11
Training loss: 1.8448618650436401
Validation loss: 2.1715837121009827

Epoch: 6| Step: 12
Training loss: 1.2879055738449097
Validation loss: 2.176978349685669

Epoch: 6| Step: 13
Training loss: 2.2512502670288086
Validation loss: 2.2019253174463906

Epoch: 315| Step: 0
Training loss: 1.993767499923706
Validation loss: 2.186050812403361

Epoch: 6| Step: 1
Training loss: 1.4614310264587402
Validation loss: 2.1901918848355613

Epoch: 6| Step: 2
Training loss: 1.242590308189392
Validation loss: 2.2047343651453652

Epoch: 6| Step: 3
Training loss: 1.6753767728805542
Validation loss: 2.2010396917661033

Epoch: 6| Step: 4
Training loss: 1.5372990369796753
Validation loss: 2.204344689846039

Epoch: 6| Step: 5
Training loss: 1.2271220684051514
Validation loss: 2.200211445490519

Epoch: 6| Step: 6
Training loss: 1.6241540908813477
Validation loss: 2.21354478597641

Epoch: 6| Step: 7
Training loss: 2.3284974098205566
Validation loss: 2.212170680363973

Epoch: 6| Step: 8
Training loss: 1.9404557943344116
Validation loss: 2.1863845586776733

Epoch: 6| Step: 9
Training loss: 1.9903557300567627
Validation loss: 2.176907777786255

Epoch: 6| Step: 10
Training loss: 1.1017353534698486
Validation loss: 2.1928977966308594

Epoch: 6| Step: 11
Training loss: 1.137677550315857
Validation loss: 2.2088898420333862

Epoch: 6| Step: 12
Training loss: 1.5182056427001953
Validation loss: 2.1817570527394614

Epoch: 6| Step: 13
Training loss: 1.9060447216033936
Validation loss: 2.212878704071045

Epoch: 316| Step: 0
Training loss: 0.7813076376914978
Validation loss: 2.1990954279899597

Epoch: 6| Step: 1
Training loss: 1.1080436706542969
Validation loss: 2.1939841906229653

Epoch: 6| Step: 2
Training loss: 1.8212640285491943
Validation loss: 2.192961633205414

Epoch: 6| Step: 3
Training loss: 1.6003426313400269
Validation loss: 2.2088303367296853

Epoch: 6| Step: 4
Training loss: 1.983025312423706
Validation loss: 2.1678311030069985

Epoch: 6| Step: 5
Training loss: 1.6171551942825317
Validation loss: 2.1929233074188232

Epoch: 6| Step: 6
Training loss: 2.2480788230895996
Validation loss: 2.2042261560757956

Epoch: 6| Step: 7
Training loss: 1.2324612140655518
Validation loss: 2.1788320342699685

Epoch: 6| Step: 8
Training loss: 1.1423629522323608
Validation loss: 2.1949247121810913

Epoch: 6| Step: 9
Training loss: 0.9406291246414185
Validation loss: 2.2022721767425537

Epoch: 6| Step: 10
Training loss: 1.6819838285446167
Validation loss: 2.1972463528315225

Epoch: 6| Step: 11
Training loss: 1.7886849641799927
Validation loss: 2.2019347548484802

Epoch: 6| Step: 12
Training loss: 1.8648194074630737
Validation loss: 2.223080893357595

Epoch: 6| Step: 13
Training loss: 2.4062232971191406
Validation loss: 2.2347835302352905

Epoch: 317| Step: 0
Training loss: 1.3411262035369873
Validation loss: 2.2058510780334473

Epoch: 6| Step: 1
Training loss: 2.494060516357422
Validation loss: 2.2139896949132285

Epoch: 6| Step: 2
Training loss: 2.2632040977478027
Validation loss: 2.2342573006947837

Epoch: 6| Step: 3
Training loss: 1.4967961311340332
Validation loss: 2.222224752108256

Epoch: 6| Step: 4
Training loss: 1.5117485523223877
Validation loss: 2.2014146645863852

Epoch: 6| Step: 5
Training loss: 1.009390115737915
Validation loss: 2.189091761906942

Epoch: 6| Step: 6
Training loss: 1.8923892974853516
Validation loss: 2.2072311441103616

Epoch: 6| Step: 7
Training loss: 0.9218744039535522
Validation loss: 2.241112470626831

Epoch: 6| Step: 8
Training loss: 1.6577889919281006
Validation loss: 2.2443535923957825

Epoch: 6| Step: 9
Training loss: 1.4954545497894287
Validation loss: 2.2919949491818747

Epoch: 6| Step: 10
Training loss: 1.8575621843338013
Validation loss: 2.340230425198873

Epoch: 6| Step: 11
Training loss: 1.6490983963012695
Validation loss: 2.338395059108734

Epoch: 6| Step: 12
Training loss: 1.8882970809936523
Validation loss: 2.322546203931173

Epoch: 6| Step: 13
Training loss: 2.1292026042938232
Validation loss: 2.268348058064779

Epoch: 318| Step: 0
Training loss: 1.8521023988723755
Validation loss: 2.260149836540222

Epoch: 6| Step: 1
Training loss: 1.4669978618621826
Validation loss: 2.2464231053988137

Epoch: 6| Step: 2
Training loss: 1.700026035308838
Validation loss: 2.248361428578695

Epoch: 6| Step: 3
Training loss: 1.4733452796936035
Validation loss: 2.2165436347325644

Epoch: 6| Step: 4
Training loss: 1.5575658082962036
Validation loss: 2.1869115432103476

Epoch: 6| Step: 5
Training loss: 1.1676969528198242
Validation loss: 2.2247798244158425

Epoch: 6| Step: 6
Training loss: 1.4835278987884521
Validation loss: 2.189292311668396

Epoch: 6| Step: 7
Training loss: 2.1989595890045166
Validation loss: 2.1703677972157798

Epoch: 6| Step: 8
Training loss: 1.8540658950805664
Validation loss: 2.1603840986887612

Epoch: 6| Step: 9
Training loss: 1.870344638824463
Validation loss: 2.184919277826945

Epoch: 6| Step: 10
Training loss: 1.9757351875305176
Validation loss: 2.1510175267855325

Epoch: 6| Step: 11
Training loss: 1.4319546222686768
Validation loss: 2.1115297277768454

Epoch: 6| Step: 12
Training loss: 1.1305408477783203
Validation loss: 2.1395145257314048

Epoch: 6| Step: 13
Training loss: 1.2981152534484863
Validation loss: 2.131632387638092

Epoch: 319| Step: 0
Training loss: 1.7083498239517212
Validation loss: 2.167598764101664

Epoch: 6| Step: 1
Training loss: 2.1719770431518555
Validation loss: 2.19195955991745

Epoch: 6| Step: 2
Training loss: 1.5227175951004028
Validation loss: 2.187692880630493

Epoch: 6| Step: 3
Training loss: 1.773550033569336
Validation loss: 2.192053437232971

Epoch: 6| Step: 4
Training loss: 1.9579520225524902
Validation loss: 2.1987018386522927

Epoch: 6| Step: 5
Training loss: 1.1912362575531006
Validation loss: 2.189456025759379

Epoch: 6| Step: 6
Training loss: 2.044796943664551
Validation loss: 2.190757930278778

Epoch: 6| Step: 7
Training loss: 1.2132906913757324
Validation loss: 2.1890133221944175

Epoch: 6| Step: 8
Training loss: 1.4030697345733643
Validation loss: 2.1876522302627563

Epoch: 6| Step: 9
Training loss: 1.8680238723754883
Validation loss: 2.149665276209513

Epoch: 6| Step: 10
Training loss: 1.581152081489563
Validation loss: 2.1735376119613647

Epoch: 6| Step: 11
Training loss: 2.082528591156006
Validation loss: 2.1671320597330728

Epoch: 6| Step: 12
Training loss: 1.425698161125183
Validation loss: 2.1845311323801675

Epoch: 6| Step: 13
Training loss: 1.6161938905715942
Validation loss: 2.1828975677490234

Epoch: 320| Step: 0
Training loss: 1.3469395637512207
Validation loss: 2.188981215159098

Epoch: 6| Step: 1
Training loss: 1.1382583379745483
Validation loss: 2.171465833981832

Epoch: 6| Step: 2
Training loss: 1.1731083393096924
Validation loss: 2.176932990550995

Epoch: 6| Step: 3
Training loss: 1.5982781648635864
Validation loss: 2.1438291867574057

Epoch: 6| Step: 4
Training loss: 1.8906153440475464
Validation loss: 2.182019511858622

Epoch: 6| Step: 5
Training loss: 1.825685739517212
Validation loss: 2.168768048286438

Epoch: 6| Step: 6
Training loss: 1.7859058380126953
Validation loss: 2.18555357058843

Epoch: 6| Step: 7
Training loss: 1.3787238597869873
Validation loss: 2.165632168451945

Epoch: 6| Step: 8
Training loss: 2.0688600540161133
Validation loss: 2.179839094479879

Epoch: 6| Step: 9
Training loss: 1.5105082988739014
Validation loss: 2.1779375871022544

Epoch: 6| Step: 10
Training loss: 1.9293168783187866
Validation loss: 2.22892435391744

Epoch: 6| Step: 11
Training loss: 2.016747236251831
Validation loss: 2.2367602586746216

Epoch: 6| Step: 12
Training loss: 1.7523062229156494
Validation loss: 2.227652351061503

Epoch: 6| Step: 13
Training loss: 1.6481938362121582
Validation loss: 2.201158901055654

Epoch: 321| Step: 0
Training loss: 1.9043465852737427
Validation loss: 2.2346262534459433

Epoch: 6| Step: 1
Training loss: 1.522081732749939
Validation loss: 2.23566206296285

Epoch: 6| Step: 2
Training loss: 2.2398781776428223
Validation loss: 2.2229365507761636

Epoch: 6| Step: 3
Training loss: 1.8486316204071045
Validation loss: 2.25638610124588

Epoch: 6| Step: 4
Training loss: 1.495383858680725
Validation loss: 2.1911494533220925

Epoch: 6| Step: 5
Training loss: 1.632144570350647
Validation loss: 2.2091397444407144

Epoch: 6| Step: 6
Training loss: 1.8427491188049316
Validation loss: 2.199569284915924

Epoch: 6| Step: 7
Training loss: 1.21693754196167
Validation loss: 2.2382257183392844

Epoch: 6| Step: 8
Training loss: 1.9754889011383057
Validation loss: 2.204893251260122

Epoch: 6| Step: 9
Training loss: 0.9244235754013062
Validation loss: 2.2135605414708457

Epoch: 6| Step: 10
Training loss: 1.6569461822509766
Validation loss: 2.2167877356211343

Epoch: 6| Step: 11
Training loss: 1.0383727550506592
Validation loss: 2.214105506738027

Epoch: 6| Step: 12
Training loss: 1.975158929824829
Validation loss: 2.2185643513997397

Epoch: 6| Step: 13
Training loss: 1.5985040664672852
Validation loss: 2.2239317893981934

Epoch: 322| Step: 0
Training loss: 1.6411259174346924
Validation loss: 2.1996677120526633

Epoch: 6| Step: 1
Training loss: 1.146967887878418
Validation loss: 2.1759093006451926

Epoch: 6| Step: 2
Training loss: 2.5005171298980713
Validation loss: 2.218310296535492

Epoch: 6| Step: 3
Training loss: 1.3915542364120483
Validation loss: 2.203028400739034

Epoch: 6| Step: 4
Training loss: 2.2784409523010254
Validation loss: 2.2204533020655313

Epoch: 6| Step: 5
Training loss: 1.239342212677002
Validation loss: 2.2381585836410522

Epoch: 6| Step: 6
Training loss: 1.3895487785339355
Validation loss: 2.220162590344747

Epoch: 6| Step: 7
Training loss: 1.6284351348876953
Validation loss: 2.213069955507914

Epoch: 6| Step: 8
Training loss: 1.1647140979766846
Validation loss: 2.202220360438029

Epoch: 6| Step: 9
Training loss: 1.5904531478881836
Validation loss: 2.2043801744778952

Epoch: 6| Step: 10
Training loss: 1.143707275390625
Validation loss: 2.1947911977767944

Epoch: 6| Step: 11
Training loss: 1.6512762308120728
Validation loss: 2.1599831183751426

Epoch: 6| Step: 12
Training loss: 1.6211942434310913
Validation loss: 2.1629504760106406

Epoch: 6| Step: 13
Training loss: 1.828323483467102
Validation loss: 2.1908605098724365

Epoch: 323| Step: 0
Training loss: 1.3652079105377197
Validation loss: 2.1997905174891152

Epoch: 6| Step: 1
Training loss: 1.6299725770950317
Validation loss: 2.196898957093557

Epoch: 6| Step: 2
Training loss: 1.7397878170013428
Validation loss: 2.196591933568319

Epoch: 6| Step: 3
Training loss: 1.3447904586791992
Validation loss: 2.2093936602274575

Epoch: 6| Step: 4
Training loss: 1.996232032775879
Validation loss: 2.198441286881765

Epoch: 6| Step: 5
Training loss: 1.5189588069915771
Validation loss: 2.1888526678085327

Epoch: 6| Step: 6
Training loss: 1.8462724685668945
Validation loss: 2.1738614042599997

Epoch: 6| Step: 7
Training loss: 1.7178833484649658
Validation loss: 2.2058768471082053

Epoch: 6| Step: 8
Training loss: 1.430418848991394
Validation loss: 2.205149551232656

Epoch: 6| Step: 9
Training loss: 1.6648836135864258
Validation loss: 2.1720844308535256

Epoch: 6| Step: 10
Training loss: 1.1793168783187866
Validation loss: 2.191845734914144

Epoch: 6| Step: 11
Training loss: 1.9863502979278564
Validation loss: 2.1434083779652915

Epoch: 6| Step: 12
Training loss: 2.0620265007019043
Validation loss: 2.1601699193318686

Epoch: 6| Step: 13
Training loss: 1.3189365863800049
Validation loss: 2.16972678899765

Epoch: 324| Step: 0
Training loss: 1.8552978038787842
Validation loss: 2.1944138010342917

Epoch: 6| Step: 1
Training loss: 1.6427816152572632
Validation loss: 2.1898184418678284

Epoch: 6| Step: 2
Training loss: 1.4036452770233154
Validation loss: 2.20875491698583

Epoch: 6| Step: 3
Training loss: 1.7639861106872559
Validation loss: 2.1855408549308777

Epoch: 6| Step: 4
Training loss: 1.320763111114502
Validation loss: 2.188125729560852

Epoch: 6| Step: 5
Training loss: 2.0217626094818115
Validation loss: 2.1627196868260703

Epoch: 6| Step: 6
Training loss: 2.1216437816619873
Validation loss: 2.1543522278467813

Epoch: 6| Step: 7
Training loss: 1.4458298683166504
Validation loss: 2.205978810787201

Epoch: 6| Step: 8
Training loss: 1.7301068305969238
Validation loss: 2.2627077102661133

Epoch: 6| Step: 9
Training loss: 1.9090931415557861
Validation loss: 2.218520184357961

Epoch: 6| Step: 10
Training loss: 1.326977014541626
Validation loss: 2.246066768964132

Epoch: 6| Step: 11
Training loss: 1.908542275428772
Validation loss: 2.24538246790568

Epoch: 6| Step: 12
Training loss: 1.6587328910827637
Validation loss: 2.2404037714004517

Epoch: 6| Step: 13
Training loss: 1.5091800689697266
Validation loss: 2.1997032165527344

Epoch: 325| Step: 0
Training loss: 1.7981308698654175
Validation loss: 2.1300427317619324

Epoch: 6| Step: 1
Training loss: 0.980562150478363
Validation loss: 2.173489809036255

Epoch: 6| Step: 2
Training loss: 2.108854055404663
Validation loss: 2.155734737714132

Epoch: 6| Step: 3
Training loss: 1.7377614974975586
Validation loss: 2.19184402624766

Epoch: 6| Step: 4
Training loss: 2.1188290119171143
Validation loss: 2.196011165777842

Epoch: 6| Step: 5
Training loss: 1.5664234161376953
Validation loss: 2.1982195377349854

Epoch: 6| Step: 6
Training loss: 1.6621453762054443
Validation loss: 2.202474216620127

Epoch: 6| Step: 7
Training loss: 1.236816167831421
Validation loss: 2.1956050395965576

Epoch: 6| Step: 8
Training loss: 1.9225627183914185
Validation loss: 2.232489069302877

Epoch: 6| Step: 9
Training loss: 1.7586959600448608
Validation loss: 2.1993025143941245

Epoch: 6| Step: 10
Training loss: 1.5450053215026855
Validation loss: 2.230492194493612

Epoch: 6| Step: 11
Training loss: 1.4946684837341309
Validation loss: 2.2558324138323465

Epoch: 6| Step: 12
Training loss: 1.5130133628845215
Validation loss: 2.31592325369517

Epoch: 6| Step: 13
Training loss: 1.6044601202011108
Validation loss: 2.3005733092625937

Epoch: 326| Step: 0
Training loss: 1.3047865629196167
Validation loss: 2.277591089407603

Epoch: 6| Step: 1
Training loss: 1.6233769655227661
Validation loss: 2.259889284769694

Epoch: 6| Step: 2
Training loss: 1.2362022399902344
Validation loss: 2.2623817125956216

Epoch: 6| Step: 3
Training loss: 1.3451998233795166
Validation loss: 2.266686578591665

Epoch: 6| Step: 4
Training loss: 2.3608760833740234
Validation loss: 2.2399240334828696

Epoch: 6| Step: 5
Training loss: 1.5882030725479126
Validation loss: 2.281180659929911

Epoch: 6| Step: 6
Training loss: 0.9267512559890747
Validation loss: 2.259327987829844

Epoch: 6| Step: 7
Training loss: 1.2985379695892334
Validation loss: 2.267296294371287

Epoch: 6| Step: 8
Training loss: 1.6601313352584839
Validation loss: 2.2425336241722107

Epoch: 6| Step: 9
Training loss: 1.668576717376709
Validation loss: 2.2319811979929605

Epoch: 6| Step: 10
Training loss: 1.4771654605865479
Validation loss: 2.236718018849691

Epoch: 6| Step: 11
Training loss: 2.0786333084106445
Validation loss: 2.2339152097702026

Epoch: 6| Step: 12
Training loss: 1.6189337968826294
Validation loss: 2.2407609820365906

Epoch: 6| Step: 13
Training loss: 2.144291400909424
Validation loss: 2.177299698193868

Epoch: 327| Step: 0
Training loss: 1.5894354581832886
Validation loss: 2.21325292189916

Epoch: 6| Step: 1
Training loss: 0.9773467779159546
Validation loss: 2.234526793162028

Epoch: 6| Step: 2
Training loss: 1.4578264951705933
Validation loss: 2.1959972381591797

Epoch: 6| Step: 3
Training loss: 1.2216154336929321
Validation loss: 2.227899889151255

Epoch: 6| Step: 4
Training loss: 1.402571678161621
Validation loss: 2.234599550565084

Epoch: 6| Step: 5
Training loss: 2.4916000366210938
Validation loss: 2.182793378829956

Epoch: 6| Step: 6
Training loss: 1.2183912992477417
Validation loss: 2.2093777457873025

Epoch: 6| Step: 7
Training loss: 1.7221786975860596
Validation loss: 2.1899710496266684

Epoch: 6| Step: 8
Training loss: 1.8796753883361816
Validation loss: 2.2079110940297446

Epoch: 6| Step: 9
Training loss: 1.2907564640045166
Validation loss: 2.203079799811045

Epoch: 6| Step: 10
Training loss: 1.7995452880859375
Validation loss: 2.224835157394409

Epoch: 6| Step: 11
Training loss: 1.8230226039886475
Validation loss: 2.213392456372579

Epoch: 6| Step: 12
Training loss: 1.849064588546753
Validation loss: 2.1831406354904175

Epoch: 6| Step: 13
Training loss: 1.5531268119812012
Validation loss: 2.2150007287661233

Epoch: 328| Step: 0
Training loss: 1.936697006225586
Validation loss: 2.2275437315305076

Epoch: 6| Step: 1
Training loss: 1.2143027782440186
Validation loss: 2.164722998936971

Epoch: 6| Step: 2
Training loss: 1.2681167125701904
Validation loss: 2.1764546235402427

Epoch: 6| Step: 3
Training loss: 1.6650646924972534
Validation loss: 2.161430239677429

Epoch: 6| Step: 4
Training loss: 1.2088799476623535
Validation loss: 2.1678205927213035

Epoch: 6| Step: 5
Training loss: 1.4344508647918701
Validation loss: 2.198566973209381

Epoch: 6| Step: 6
Training loss: 0.8579666614532471
Validation loss: 2.1617418130238852

Epoch: 6| Step: 7
Training loss: 1.4358218908309937
Validation loss: 2.210957626501719

Epoch: 6| Step: 8
Training loss: 1.8818397521972656
Validation loss: 2.1969177524248757

Epoch: 6| Step: 9
Training loss: 1.2636957168579102
Validation loss: 2.1710306803385415

Epoch: 6| Step: 10
Training loss: 1.8972015380859375
Validation loss: 2.2173463503519693

Epoch: 6| Step: 11
Training loss: 2.0367116928100586
Validation loss: 2.1706074277559915

Epoch: 6| Step: 12
Training loss: 1.6905333995819092
Validation loss: 2.223252594470978

Epoch: 6| Step: 13
Training loss: 2.0416359901428223
Validation loss: 2.189618945121765

Epoch: 329| Step: 0
Training loss: 1.4789211750030518
Validation loss: 2.209664225578308

Epoch: 6| Step: 1
Training loss: 1.2630937099456787
Validation loss: 2.22373898824056

Epoch: 6| Step: 2
Training loss: 1.3957339525222778
Validation loss: 2.191502352555593

Epoch: 6| Step: 3
Training loss: 1.8486111164093018
Validation loss: 2.1989447673161826

Epoch: 6| Step: 4
Training loss: 1.3296030759811401
Validation loss: 2.1902564565340676

Epoch: 6| Step: 5
Training loss: 1.6014238595962524
Validation loss: 2.182876547177633

Epoch: 6| Step: 6
Training loss: 1.2391573190689087
Validation loss: 2.1455312768618264

Epoch: 6| Step: 7
Training loss: 1.6406240463256836
Validation loss: 2.1908620397249856

Epoch: 6| Step: 8
Training loss: 1.9661850929260254
Validation loss: 2.2076094150543213

Epoch: 6| Step: 9
Training loss: 1.8314353227615356
Validation loss: 2.184809426466624

Epoch: 6| Step: 10
Training loss: 2.2678442001342773
Validation loss: 2.1703090270360312

Epoch: 6| Step: 11
Training loss: 1.51495361328125
Validation loss: 2.1779746214548745

Epoch: 6| Step: 12
Training loss: 1.171447992324829
Validation loss: 2.1844478845596313

Epoch: 6| Step: 13
Training loss: 1.4862937927246094
Validation loss: 2.187525510787964

Epoch: 330| Step: 0
Training loss: 1.4273244142532349
Validation loss: 2.13454798857371

Epoch: 6| Step: 1
Training loss: 2.251216411590576
Validation loss: 2.171096940835317

Epoch: 6| Step: 2
Training loss: 1.6199357509613037
Validation loss: 2.1584519147872925

Epoch: 6| Step: 3
Training loss: 0.9329699277877808
Validation loss: 2.1544477939605713

Epoch: 6| Step: 4
Training loss: 2.2188568115234375
Validation loss: 2.1667126218477883

Epoch: 6| Step: 5
Training loss: 2.0558462142944336
Validation loss: 2.149055242538452

Epoch: 6| Step: 6
Training loss: 1.2330822944641113
Validation loss: 2.1558898091316223

Epoch: 6| Step: 7
Training loss: 1.4441072940826416
Validation loss: 2.182241221268972

Epoch: 6| Step: 8
Training loss: 1.008362054824829
Validation loss: 2.186229149500529

Epoch: 6| Step: 9
Training loss: 1.6387529373168945
Validation loss: 2.171370267868042

Epoch: 6| Step: 10
Training loss: 1.269234538078308
Validation loss: 2.202241619427999

Epoch: 6| Step: 11
Training loss: 1.6608905792236328
Validation loss: 2.193070669968923

Epoch: 6| Step: 12
Training loss: 1.0992233753204346
Validation loss: 2.2175652782122293

Epoch: 6| Step: 13
Training loss: 1.8615050315856934
Validation loss: 2.178733011086782

Epoch: 331| Step: 0
Training loss: 2.1000285148620605
Validation loss: 2.21731706460317

Epoch: 6| Step: 1
Training loss: 1.5755031108856201
Validation loss: 2.2156150539716086

Epoch: 6| Step: 2
Training loss: 1.8126499652862549
Validation loss: 2.2043704986572266

Epoch: 6| Step: 3
Training loss: 1.4114536046981812
Validation loss: 2.1920721928278604

Epoch: 6| Step: 4
Training loss: 1.4189178943634033
Validation loss: 2.2281919916470847

Epoch: 6| Step: 5
Training loss: 1.6489171981811523
Validation loss: 2.217824379603068

Epoch: 6| Step: 6
Training loss: 2.0509653091430664
Validation loss: 2.1976646979649863

Epoch: 6| Step: 7
Training loss: 1.6872354745864868
Validation loss: 2.228243629137675

Epoch: 6| Step: 8
Training loss: 1.0369430780410767
Validation loss: 2.250710388024648

Epoch: 6| Step: 9
Training loss: 1.417424201965332
Validation loss: 2.2343759139378867

Epoch: 6| Step: 10
Training loss: 1.5787138938903809
Validation loss: 2.2683267990748086

Epoch: 6| Step: 11
Training loss: 1.0713648796081543
Validation loss: 2.2199886639912925

Epoch: 6| Step: 12
Training loss: 1.1394267082214355
Validation loss: 2.303426365057627

Epoch: 6| Step: 13
Training loss: 1.63588285446167
Validation loss: 2.2503249247868857

Epoch: 332| Step: 0
Training loss: 0.9573435187339783
Validation loss: 2.231851498285929

Epoch: 6| Step: 1
Training loss: 0.7731542587280273
Validation loss: 2.2203482389450073

Epoch: 6| Step: 2
Training loss: 1.5359822511672974
Validation loss: 2.2296584447224936

Epoch: 6| Step: 3
Training loss: 2.2770936489105225
Validation loss: 2.2182542085647583

Epoch: 6| Step: 4
Training loss: 2.1015005111694336
Validation loss: 2.250683764616648

Epoch: 6| Step: 5
Training loss: 1.557205080986023
Validation loss: 2.2222605546315513

Epoch: 6| Step: 6
Training loss: 1.073642611503601
Validation loss: 2.2192046443621316

Epoch: 6| Step: 7
Training loss: 1.4120254516601562
Validation loss: 2.223708669344584

Epoch: 6| Step: 8
Training loss: 1.9469974040985107
Validation loss: 2.2153931061426797

Epoch: 6| Step: 9
Training loss: 1.552878737449646
Validation loss: 2.219702939192454

Epoch: 6| Step: 10
Training loss: 1.2999305725097656
Validation loss: 2.212355891863505

Epoch: 6| Step: 11
Training loss: 1.4487152099609375
Validation loss: 2.2141769329706826

Epoch: 6| Step: 12
Training loss: 1.594330906867981
Validation loss: 2.1974963943163552

Epoch: 6| Step: 13
Training loss: 2.3355965614318848
Validation loss: 2.2318150997161865

Epoch: 333| Step: 0
Training loss: 1.6688106060028076
Validation loss: 2.214633802572886

Epoch: 6| Step: 1
Training loss: 1.8171107769012451
Validation loss: 2.2217758099238076

Epoch: 6| Step: 2
Training loss: 1.0169110298156738
Validation loss: 2.2383065025011697

Epoch: 6| Step: 3
Training loss: 1.3355547189712524
Validation loss: 2.18764062722524

Epoch: 6| Step: 4
Training loss: 1.9756330251693726
Validation loss: 2.22420334815979

Epoch: 6| Step: 5
Training loss: 1.625349760055542
Validation loss: 2.205320636431376

Epoch: 6| Step: 6
Training loss: 1.364943504333496
Validation loss: 2.212480624516805

Epoch: 6| Step: 7
Training loss: 1.2717100381851196
Validation loss: 2.2073235511779785

Epoch: 6| Step: 8
Training loss: 1.967576503753662
Validation loss: 2.202976187070211

Epoch: 6| Step: 9
Training loss: 1.9610499143600464
Validation loss: 2.2056018114089966

Epoch: 6| Step: 10
Training loss: 1.3214651346206665
Validation loss: 2.2104164958000183

Epoch: 6| Step: 11
Training loss: 1.558672547340393
Validation loss: 2.2212156653404236

Epoch: 6| Step: 12
Training loss: 1.3404853343963623
Validation loss: 2.252912183602651

Epoch: 6| Step: 13
Training loss: 1.2970318794250488
Validation loss: 2.2503952980041504

Epoch: 334| Step: 0
Training loss: 2.008388042449951
Validation loss: 2.2253350615501404

Epoch: 6| Step: 1
Training loss: 1.4252629280090332
Validation loss: 2.2433277368545532

Epoch: 6| Step: 2
Training loss: 1.3484386205673218
Validation loss: 2.2655428051948547

Epoch: 6| Step: 3
Training loss: 1.2061128616333008
Validation loss: 2.2663851976394653

Epoch: 6| Step: 4
Training loss: 2.1789352893829346
Validation loss: 2.1877202788988748

Epoch: 6| Step: 5
Training loss: 1.4325916767120361
Validation loss: 2.1931504011154175

Epoch: 6| Step: 6
Training loss: 1.3925453424453735
Validation loss: 2.2084548473358154

Epoch: 6| Step: 7
Training loss: 1.353532314300537
Validation loss: 2.2005403439203897

Epoch: 6| Step: 8
Training loss: 1.6339242458343506
Validation loss: 2.214135448137919

Epoch: 6| Step: 9
Training loss: 1.5823872089385986
Validation loss: 2.208146393299103

Epoch: 6| Step: 10
Training loss: 1.5521390438079834
Validation loss: 2.18983926375707

Epoch: 6| Step: 11
Training loss: 1.1633161306381226
Validation loss: 2.231466213862101

Epoch: 6| Step: 12
Training loss: 1.8635083436965942
Validation loss: 2.2131296197573342

Epoch: 6| Step: 13
Training loss: 1.723154902458191
Validation loss: 2.216983179251353

Epoch: 335| Step: 0
Training loss: 1.3103171586990356
Validation loss: 2.2287681897481284

Epoch: 6| Step: 1
Training loss: 1.523112177848816
Validation loss: 2.214280287424723

Epoch: 6| Step: 2
Training loss: 1.4966912269592285
Validation loss: 2.1970146099726358

Epoch: 6| Step: 3
Training loss: 1.5420466661453247
Validation loss: 2.189694364865621

Epoch: 6| Step: 4
Training loss: 1.1184775829315186
Validation loss: 2.2036708990732827

Epoch: 6| Step: 5
Training loss: 1.6278345584869385
Validation loss: 2.2065937916437783

Epoch: 6| Step: 6
Training loss: 1.2879207134246826
Validation loss: 2.174808144569397

Epoch: 6| Step: 7
Training loss: 1.6567764282226562
Validation loss: 2.166939934094747

Epoch: 6| Step: 8
Training loss: 1.8442039489746094
Validation loss: 2.1742977698644004

Epoch: 6| Step: 9
Training loss: 1.5848329067230225
Validation loss: 2.169365564982096

Epoch: 6| Step: 10
Training loss: 1.6675434112548828
Validation loss: 2.218359033266703

Epoch: 6| Step: 11
Training loss: 1.0885217189788818
Validation loss: 2.2331353227297464

Epoch: 6| Step: 12
Training loss: 1.5035426616668701
Validation loss: 2.1869409481684365

Epoch: 6| Step: 13
Training loss: 2.305121421813965
Validation loss: 2.1845697164535522

Epoch: 336| Step: 0
Training loss: 1.5790554285049438
Validation loss: 2.172049323717753

Epoch: 6| Step: 1
Training loss: 1.0010411739349365
Validation loss: 2.1844666798909507

Epoch: 6| Step: 2
Training loss: 1.7612404823303223
Validation loss: 2.1818179289499917

Epoch: 6| Step: 3
Training loss: 1.685183048248291
Validation loss: 2.212666153907776

Epoch: 6| Step: 4
Training loss: 1.4378440380096436
Validation loss: 2.179411470890045

Epoch: 6| Step: 5
Training loss: 1.227500319480896
Validation loss: 2.179247041543325

Epoch: 6| Step: 6
Training loss: 1.3954102993011475
Validation loss: 2.2034480969111123

Epoch: 6| Step: 7
Training loss: 1.347484827041626
Validation loss: 2.140646775563558

Epoch: 6| Step: 8
Training loss: 1.9836220741271973
Validation loss: 2.153339922428131

Epoch: 6| Step: 9
Training loss: 1.2478291988372803
Validation loss: 2.1697481671969094

Epoch: 6| Step: 10
Training loss: 1.7765781879425049
Validation loss: 2.1754551331202188

Epoch: 6| Step: 11
Training loss: 1.8027729988098145
Validation loss: 2.2176459630330405

Epoch: 6| Step: 12
Training loss: 1.2683426141738892
Validation loss: 2.178939680258433

Epoch: 6| Step: 13
Training loss: 1.9025217294692993
Validation loss: 2.1644251346588135

Epoch: 337| Step: 0
Training loss: 1.3811111450195312
Validation loss: 2.2032910188039145

Epoch: 6| Step: 1
Training loss: 2.0269367694854736
Validation loss: 2.21553107102712

Epoch: 6| Step: 2
Training loss: 1.8394675254821777
Validation loss: 2.226436992486318

Epoch: 6| Step: 3
Training loss: 1.1261298656463623
Validation loss: 2.200820525487264

Epoch: 6| Step: 4
Training loss: 1.1643295288085938
Validation loss: 2.234470268090566

Epoch: 6| Step: 5
Training loss: 1.3080636262893677
Validation loss: 2.2093476057052612

Epoch: 6| Step: 6
Training loss: 2.0106844902038574
Validation loss: 2.2208288113276162

Epoch: 6| Step: 7
Training loss: 0.7630921602249146
Validation loss: 2.2451358834902444

Epoch: 6| Step: 8
Training loss: 1.2689623832702637
Validation loss: 2.2399598757425943

Epoch: 6| Step: 9
Training loss: 1.2061100006103516
Validation loss: 2.219620863596598

Epoch: 6| Step: 10
Training loss: 2.1630706787109375
Validation loss: 2.2018547455469766

Epoch: 6| Step: 11
Training loss: 0.9595528244972229
Validation loss: 2.2216567595799765

Epoch: 6| Step: 12
Training loss: 1.432440161705017
Validation loss: 2.2059732476870217

Epoch: 6| Step: 13
Training loss: 2.8299059867858887
Validation loss: 2.2132890025774636

Epoch: 338| Step: 0
Training loss: 1.4437150955200195
Validation loss: 2.227765162785848

Epoch: 6| Step: 1
Training loss: 1.921063780784607
Validation loss: 2.2397592663764954

Epoch: 6| Step: 2
Training loss: 1.3533568382263184
Validation loss: 2.1757673819859824

Epoch: 6| Step: 3
Training loss: 1.031245470046997
Validation loss: 2.1831695834795632

Epoch: 6| Step: 4
Training loss: 1.6674386262893677
Validation loss: 2.1709488232930503

Epoch: 6| Step: 5
Training loss: 0.8299237489700317
Validation loss: 2.148530383904775

Epoch: 6| Step: 6
Training loss: 1.4493076801300049
Validation loss: 2.146024485429128

Epoch: 6| Step: 7
Training loss: 2.093670129776001
Validation loss: 2.1249471306800842

Epoch: 6| Step: 8
Training loss: 1.4572086334228516
Validation loss: 2.1615376075108848

Epoch: 6| Step: 9
Training loss: 1.0729104280471802
Validation loss: 2.1692658265431723

Epoch: 6| Step: 10
Training loss: 1.7505033016204834
Validation loss: 2.1434088945388794

Epoch: 6| Step: 11
Training loss: 1.568246603012085
Validation loss: 2.1688470443089805

Epoch: 6| Step: 12
Training loss: 1.763164758682251
Validation loss: 2.1815098325411477

Epoch: 6| Step: 13
Training loss: 1.5920910835266113
Validation loss: 2.1793657541275024

Epoch: 339| Step: 0
Training loss: 1.0383946895599365
Validation loss: 2.191891392072042

Epoch: 6| Step: 1
Training loss: 1.6381168365478516
Validation loss: 2.192927916844686

Epoch: 6| Step: 2
Training loss: 1.1792926788330078
Validation loss: 2.181750933329264

Epoch: 6| Step: 3
Training loss: 1.1126471757888794
Validation loss: 2.1879828572273254

Epoch: 6| Step: 4
Training loss: 2.7645742893218994
Validation loss: 2.226603945096334

Epoch: 6| Step: 5
Training loss: 1.7832697629928589
Validation loss: 2.2211080392201743

Epoch: 6| Step: 6
Training loss: 1.1971471309661865
Validation loss: 2.2759037812550864

Epoch: 6| Step: 7
Training loss: 1.6676340103149414
Validation loss: 2.2753642201423645

Epoch: 6| Step: 8
Training loss: 1.5668141841888428
Validation loss: 2.2279584805170694

Epoch: 6| Step: 9
Training loss: 1.8996467590332031
Validation loss: 2.21260937054952

Epoch: 6| Step: 10
Training loss: 1.6686060428619385
Validation loss: 2.2208306392033896

Epoch: 6| Step: 11
Training loss: 1.4300798177719116
Validation loss: 2.1416364113489785

Epoch: 6| Step: 12
Training loss: 1.57291579246521
Validation loss: 2.1811368465423584

Epoch: 6| Step: 13
Training loss: 1.444913387298584
Validation loss: 2.202524026234945

Epoch: 340| Step: 0
Training loss: 1.7706243991851807
Validation loss: 2.2067015369733176

Epoch: 6| Step: 1
Training loss: 1.8343791961669922
Validation loss: 2.2266093492507935

Epoch: 6| Step: 2
Training loss: 1.7508721351623535
Validation loss: 2.1848970850308738

Epoch: 6| Step: 3
Training loss: 1.6378651857376099
Validation loss: 2.20240326722463

Epoch: 6| Step: 4
Training loss: 1.1088426113128662
Validation loss: 2.214516262213389

Epoch: 6| Step: 5
Training loss: 1.1188240051269531
Validation loss: 2.190355042616526

Epoch: 6| Step: 6
Training loss: 1.6684958934783936
Validation loss: 2.207478940486908

Epoch: 6| Step: 7
Training loss: 1.5970559120178223
Validation loss: 2.213964104652405

Epoch: 6| Step: 8
Training loss: 1.5837006568908691
Validation loss: 2.1717647314071655

Epoch: 6| Step: 9
Training loss: 1.839016318321228
Validation loss: 2.1800121068954468

Epoch: 6| Step: 10
Training loss: 1.2885187864303589
Validation loss: 2.2001302440961203

Epoch: 6| Step: 11
Training loss: 1.7982598543167114
Validation loss: 2.196643869082133

Epoch: 6| Step: 12
Training loss: 1.5848082304000854
Validation loss: 2.2022969921429953

Epoch: 6| Step: 13
Training loss: 1.1187888383865356
Validation loss: 2.1667546232541404

Epoch: 341| Step: 0
Training loss: 1.3139212131500244
Validation loss: 2.1875842014948526

Epoch: 6| Step: 1
Training loss: 1.2025575637817383
Validation loss: 2.1880736351013184

Epoch: 6| Step: 2
Training loss: 1.4817222356796265
Validation loss: 2.189382572968801

Epoch: 6| Step: 3
Training loss: 1.223830223083496
Validation loss: 2.2225210269292197

Epoch: 6| Step: 4
Training loss: 1.3771324157714844
Validation loss: 2.199326813220978

Epoch: 6| Step: 5
Training loss: 2.185527801513672
Validation loss: 2.190965493520101

Epoch: 6| Step: 6
Training loss: 1.7139756679534912
Validation loss: 2.186000963052114

Epoch: 6| Step: 7
Training loss: 1.6078438758850098
Validation loss: 2.1974745392799377

Epoch: 6| Step: 8
Training loss: 1.5599842071533203
Validation loss: 2.2025985519091287

Epoch: 6| Step: 9
Training loss: 1.8402661085128784
Validation loss: 2.1987646023432412

Epoch: 6| Step: 10
Training loss: 1.2948901653289795
Validation loss: 2.205328385035197

Epoch: 6| Step: 11
Training loss: 1.8214457035064697
Validation loss: 2.1617939869562783

Epoch: 6| Step: 12
Training loss: 1.049708604812622
Validation loss: 2.1850310961405435

Epoch: 6| Step: 13
Training loss: 1.5792886018753052
Validation loss: 2.1769023338953652

Epoch: 342| Step: 0
Training loss: 1.0539101362228394
Validation loss: 2.1978114247322083

Epoch: 6| Step: 1
Training loss: 1.7254525423049927
Validation loss: 2.174425224463145

Epoch: 6| Step: 2
Training loss: 1.1006920337677002
Validation loss: 2.204419036706289

Epoch: 6| Step: 3
Training loss: 1.4238780736923218
Validation loss: 2.1923789381980896

Epoch: 6| Step: 4
Training loss: 1.27033531665802
Validation loss: 2.1477617820103965

Epoch: 6| Step: 5
Training loss: 1.5340287685394287
Validation loss: 2.188041309515635

Epoch: 6| Step: 6
Training loss: 1.8934547901153564
Validation loss: 2.193520963191986

Epoch: 6| Step: 7
Training loss: 1.6631121635437012
Validation loss: 2.2153064807256064

Epoch: 6| Step: 8
Training loss: 1.6826732158660889
Validation loss: 2.1736194094022117

Epoch: 6| Step: 9
Training loss: 1.8811496496200562
Validation loss: 2.203106184800466

Epoch: 6| Step: 10
Training loss: 1.4201993942260742
Validation loss: 2.1927471359570823

Epoch: 6| Step: 11
Training loss: 1.8143696784973145
Validation loss: 2.176359454790751

Epoch: 6| Step: 12
Training loss: 1.3320515155792236
Validation loss: 2.2139777739842734

Epoch: 6| Step: 13
Training loss: 1.3526790142059326
Validation loss: 2.2011082768440247

Epoch: 343| Step: 0
Training loss: 1.7326924800872803
Validation loss: 2.1810245911280313

Epoch: 6| Step: 1
Training loss: 1.2658170461654663
Validation loss: 2.20005202293396

Epoch: 6| Step: 2
Training loss: 1.8848285675048828
Validation loss: 2.1984244187672934

Epoch: 6| Step: 3
Training loss: 0.679497241973877
Validation loss: 2.2175098657608032

Epoch: 6| Step: 4
Training loss: 1.446777582168579
Validation loss: 2.2354360818862915

Epoch: 6| Step: 5
Training loss: 1.2193751335144043
Validation loss: 2.254014035065969

Epoch: 6| Step: 6
Training loss: 1.475561499595642
Validation loss: 2.2211231191953025

Epoch: 6| Step: 7
Training loss: 2.4236223697662354
Validation loss: 2.24652898311615

Epoch: 6| Step: 8
Training loss: 1.3765071630477905
Validation loss: 2.2370555996894836

Epoch: 6| Step: 9
Training loss: 1.6132442951202393
Validation loss: 2.2524354259173074

Epoch: 6| Step: 10
Training loss: 1.1766023635864258
Validation loss: 2.2293654878934226

Epoch: 6| Step: 11
Training loss: 1.0160382986068726
Validation loss: 2.2472859621047974

Epoch: 6| Step: 12
Training loss: 1.9480377435684204
Validation loss: 2.220594863096873

Epoch: 6| Step: 13
Training loss: 1.429260015487671
Validation loss: 2.2403038342793784

Epoch: 344| Step: 0
Training loss: 1.6133517026901245
Validation loss: 2.226858297983805

Epoch: 6| Step: 1
Training loss: 0.8521945476531982
Validation loss: 2.2083421548207602

Epoch: 6| Step: 2
Training loss: 1.2372915744781494
Validation loss: 2.1500843167304993

Epoch: 6| Step: 3
Training loss: 1.5186023712158203
Validation loss: 2.173247734705607

Epoch: 6| Step: 4
Training loss: 1.2511107921600342
Validation loss: 2.15455029408137

Epoch: 6| Step: 5
Training loss: 1.3513908386230469
Validation loss: 2.1689537366231284

Epoch: 6| Step: 6
Training loss: 1.9531912803649902
Validation loss: 2.1954656640688577

Epoch: 6| Step: 7
Training loss: 0.8132989406585693
Validation loss: 2.17193603515625

Epoch: 6| Step: 8
Training loss: 2.151273250579834
Validation loss: 2.1656181613604226

Epoch: 6| Step: 9
Training loss: 1.0194673538208008
Validation loss: 2.175041417280833

Epoch: 6| Step: 10
Training loss: 1.766076683998108
Validation loss: 2.1892725427945456

Epoch: 6| Step: 11
Training loss: 1.7957369089126587
Validation loss: 2.1839473048845925

Epoch: 6| Step: 12
Training loss: 1.7133240699768066
Validation loss: 2.2210971315701804

Epoch: 6| Step: 13
Training loss: 2.6168413162231445
Validation loss: 2.194461981455485

Epoch: 345| Step: 0
Training loss: 2.165700912475586
Validation loss: 2.1812185446421304

Epoch: 6| Step: 1
Training loss: 2.43475341796875
Validation loss: 2.193875471750895

Epoch: 6| Step: 2
Training loss: 1.4556188583374023
Validation loss: 2.2079697052637735

Epoch: 6| Step: 3
Training loss: 1.7079342603683472
Validation loss: 2.217446804046631

Epoch: 6| Step: 4
Training loss: 1.90565025806427
Validation loss: 2.217616319656372

Epoch: 6| Step: 5
Training loss: 0.7665483951568604
Validation loss: 2.2696082393328347

Epoch: 6| Step: 6
Training loss: 1.3396530151367188
Validation loss: 2.265185018380483

Epoch: 6| Step: 7
Training loss: 1.4114596843719482
Validation loss: 2.2216227054595947

Epoch: 6| Step: 8
Training loss: 0.7952960133552551
Validation loss: 2.2432398001352944

Epoch: 6| Step: 9
Training loss: 1.1015591621398926
Validation loss: 2.2510465582211814

Epoch: 6| Step: 10
Training loss: 1.3451441526412964
Validation loss: 2.2500784198443093

Epoch: 6| Step: 11
Training loss: 1.664657711982727
Validation loss: 2.1886684894561768

Epoch: 6| Step: 12
Training loss: 2.1667709350585938
Validation loss: 2.2226752837498984

Epoch: 6| Step: 13
Training loss: 0.7864638566970825
Validation loss: 2.199293037255605

Epoch: 346| Step: 0
Training loss: 2.154452323913574
Validation loss: 2.1596317489941916

Epoch: 6| Step: 1
Training loss: 1.9100223779678345
Validation loss: 2.1849141915639243

Epoch: 6| Step: 2
Training loss: 1.4851161241531372
Validation loss: 2.1522644758224487

Epoch: 6| Step: 3
Training loss: 1.2314354181289673
Validation loss: 2.1752665042877197

Epoch: 6| Step: 4
Training loss: 1.8372769355773926
Validation loss: 2.150453050931295

Epoch: 6| Step: 5
Training loss: 1.763156771659851
Validation loss: 2.1728128592173257

Epoch: 6| Step: 6
Training loss: 1.2512861490249634
Validation loss: 2.14041531085968

Epoch: 6| Step: 7
Training loss: 1.593438982963562
Validation loss: 2.192610243956248

Epoch: 6| Step: 8
Training loss: 1.524561882019043
Validation loss: 2.194584627946218

Epoch: 6| Step: 9
Training loss: 1.1512084007263184
Validation loss: 2.1850601633389792

Epoch: 6| Step: 10
Training loss: 0.8281590938568115
Validation loss: 2.1796859304110208

Epoch: 6| Step: 11
Training loss: 1.2538779973983765
Validation loss: 2.202411433060964

Epoch: 6| Step: 12
Training loss: 1.2297120094299316
Validation loss: 2.2389530738194785

Epoch: 6| Step: 13
Training loss: 1.6073801517486572
Validation loss: 2.2151317795117698

Epoch: 347| Step: 0
Training loss: 1.39357590675354
Validation loss: 2.2395256559054055

Epoch: 6| Step: 1
Training loss: 2.074215888977051
Validation loss: 2.267825166384379

Epoch: 6| Step: 2
Training loss: 1.6807175874710083
Validation loss: 2.273640771706899

Epoch: 6| Step: 3
Training loss: 1.1601526737213135
Validation loss: 2.2807805935541787

Epoch: 6| Step: 4
Training loss: 2.5408756732940674
Validation loss: 2.255141019821167

Epoch: 6| Step: 5
Training loss: 1.6434705257415771
Validation loss: 2.258370598157247

Epoch: 6| Step: 6
Training loss: 1.0364669561386108
Validation loss: 2.2337297399838767

Epoch: 6| Step: 7
Training loss: 2.279984951019287
Validation loss: 2.234479308128357

Epoch: 6| Step: 8
Training loss: 0.7985395789146423
Validation loss: 2.2012552420298257

Epoch: 6| Step: 9
Training loss: 1.339512586593628
Validation loss: 2.1679306626319885

Epoch: 6| Step: 10
Training loss: 0.9536252617835999
Validation loss: 2.1678571502367654

Epoch: 6| Step: 11
Training loss: 0.8657992482185364
Validation loss: 2.1822754542032876

Epoch: 6| Step: 12
Training loss: 1.2701728343963623
Validation loss: 2.1865371465682983

Epoch: 6| Step: 13
Training loss: 1.7042357921600342
Validation loss: 2.221773346265157

Epoch: 348| Step: 0
Training loss: 1.493260383605957
Validation loss: 2.178747912247976

Epoch: 6| Step: 1
Training loss: 1.523951768875122
Validation loss: 2.1698818802833557

Epoch: 6| Step: 2
Training loss: 1.6661964654922485
Validation loss: 2.1750726898511252

Epoch: 6| Step: 3
Training loss: 1.3140907287597656
Validation loss: 2.227352023124695

Epoch: 6| Step: 4
Training loss: 1.4628019332885742
Validation loss: 2.2124520937601724

Epoch: 6| Step: 5
Training loss: 1.202966570854187
Validation loss: 2.1727241476376853

Epoch: 6| Step: 6
Training loss: 1.2181428670883179
Validation loss: 2.166582683722178

Epoch: 6| Step: 7
Training loss: 0.9160044193267822
Validation loss: 2.2017762064933777

Epoch: 6| Step: 8
Training loss: 1.490485668182373
Validation loss: 2.1720051566759744

Epoch: 6| Step: 9
Training loss: 1.9313582181930542
Validation loss: 2.1769753098487854

Epoch: 6| Step: 10
Training loss: 2.18135929107666
Validation loss: 2.1697374184926352

Epoch: 6| Step: 11
Training loss: 1.283155083656311
Validation loss: 2.1744295954704285

Epoch: 6| Step: 12
Training loss: 1.9096356630325317
Validation loss: 2.1920416355133057

Epoch: 6| Step: 13
Training loss: 1.7013065814971924
Validation loss: 2.15625270207723

Epoch: 349| Step: 0
Training loss: 1.5944913625717163
Validation loss: 2.182811677455902

Epoch: 6| Step: 1
Training loss: 1.372542381286621
Validation loss: 2.2054673234621682

Epoch: 6| Step: 2
Training loss: 2.1744415760040283
Validation loss: 2.1486656268437705

Epoch: 6| Step: 3
Training loss: 1.8125189542770386
Validation loss: 2.1625394225120544

Epoch: 6| Step: 4
Training loss: 1.590681552886963
Validation loss: 2.2075953682263694

Epoch: 6| Step: 5
Training loss: 1.8219072818756104
Validation loss: 2.1655918757120767

Epoch: 6| Step: 6
Training loss: 1.9617348909378052
Validation loss: 2.1956489086151123

Epoch: 6| Step: 7
Training loss: 1.644761562347412
Validation loss: 2.1654837131500244

Epoch: 6| Step: 8
Training loss: 1.9119572639465332
Validation loss: 2.15120522181193

Epoch: 6| Step: 9
Training loss: 1.7035824060440063
Validation loss: 2.1388705174128213

Epoch: 6| Step: 10
Training loss: 1.2605161666870117
Validation loss: 2.112752358118693

Epoch: 6| Step: 11
Training loss: 0.8000067472457886
Validation loss: 2.134661058584849

Epoch: 6| Step: 12
Training loss: 1.2943964004516602
Validation loss: 2.1828038692474365

Epoch: 6| Step: 13
Training loss: 0.9627857208251953
Validation loss: 2.195120851198832

Epoch: 350| Step: 0
Training loss: 2.1541590690612793
Validation loss: 2.2049347162246704

Epoch: 6| Step: 1
Training loss: 1.9094845056533813
Validation loss: 2.223365306854248

Epoch: 6| Step: 2
Training loss: 1.5253190994262695
Validation loss: 2.2408437728881836

Epoch: 6| Step: 3
Training loss: 1.3202059268951416
Validation loss: 2.22104541460673

Epoch: 6| Step: 4
Training loss: 1.755364179611206
Validation loss: 2.220452129840851

Epoch: 6| Step: 5
Training loss: 1.1352016925811768
Validation loss: 2.1901561419169107

Epoch: 6| Step: 6
Training loss: 1.274748682975769
Validation loss: 2.201774994532267

Epoch: 6| Step: 7
Training loss: 1.8142130374908447
Validation loss: 2.177772045135498

Epoch: 6| Step: 8
Training loss: 1.1200069189071655
Validation loss: 2.237669587135315

Epoch: 6| Step: 9
Training loss: 1.7189631462097168
Validation loss: 2.2306867837905884

Epoch: 6| Step: 10
Training loss: 1.1727344989776611
Validation loss: 2.218004902203878

Epoch: 6| Step: 11
Training loss: 1.07350492477417
Validation loss: 2.2411350210507712

Epoch: 6| Step: 12
Training loss: 1.6282987594604492
Validation loss: 2.237110733985901

Epoch: 6| Step: 13
Training loss: 2.2677011489868164
Validation loss: 2.2402263879776

Epoch: 351| Step: 0
Training loss: 1.6403923034667969
Validation loss: 2.2627936601638794

Epoch: 6| Step: 1
Training loss: 1.4500898122787476
Validation loss: 2.232338786125183

Epoch: 6| Step: 2
Training loss: 2.286501169204712
Validation loss: 2.2695551911989846

Epoch: 6| Step: 3
Training loss: 0.8847596049308777
Validation loss: 2.241103450457255

Epoch: 6| Step: 4
Training loss: 1.6424970626831055
Validation loss: 2.246672590573629

Epoch: 6| Step: 5
Training loss: 1.8153148889541626
Validation loss: 2.247029741605123

Epoch: 6| Step: 6
Training loss: 1.4938324689865112
Validation loss: 2.2765947580337524

Epoch: 6| Step: 7
Training loss: 1.3671549558639526
Validation loss: 2.2737139463424683

Epoch: 6| Step: 8
Training loss: 0.9382072687149048
Validation loss: 2.2820605834325156

Epoch: 6| Step: 9
Training loss: 1.4640569686889648
Validation loss: 2.229934573173523

Epoch: 6| Step: 10
Training loss: 2.0191853046417236
Validation loss: 2.218245247999827

Epoch: 6| Step: 11
Training loss: 0.8209044337272644
Validation loss: 2.236226280530294

Epoch: 6| Step: 12
Training loss: 0.9539672136306763
Validation loss: 2.2233689626057944

Epoch: 6| Step: 13
Training loss: 1.46901273727417
Validation loss: 2.2447388768196106

Epoch: 352| Step: 0
Training loss: 1.9033100605010986
Validation loss: 2.2234200835227966

Epoch: 6| Step: 1
Training loss: 1.3874943256378174
Validation loss: 2.220639924208323

Epoch: 6| Step: 2
Training loss: 1.3415930271148682
Validation loss: 2.2043938636779785

Epoch: 6| Step: 3
Training loss: 2.298251152038574
Validation loss: 2.1896338065465293

Epoch: 6| Step: 4
Training loss: 0.9853273630142212
Validation loss: 2.2477275133132935

Epoch: 6| Step: 5
Training loss: 1.293017864227295
Validation loss: 2.228239357471466

Epoch: 6| Step: 6
Training loss: 1.0168770551681519
Validation loss: 2.1971362034479776

Epoch: 6| Step: 7
Training loss: 1.8315761089324951
Validation loss: 2.185575465361277

Epoch: 6| Step: 8
Training loss: 1.4970672130584717
Validation loss: 2.2206148505210876

Epoch: 6| Step: 9
Training loss: 1.5509052276611328
Validation loss: 2.246508518854777

Epoch: 6| Step: 10
Training loss: 1.829848051071167
Validation loss: 2.2492469350496926

Epoch: 6| Step: 11
Training loss: 1.8759195804595947
Validation loss: 2.2531845768292746

Epoch: 6| Step: 12
Training loss: 1.5530860424041748
Validation loss: 2.2241714795430503

Epoch: 6| Step: 13
Training loss: 1.2418718338012695
Validation loss: 2.220813035964966

Epoch: 353| Step: 0
Training loss: 1.8708566427230835
Validation loss: 2.223360816637675

Epoch: 6| Step: 1
Training loss: 1.214277744293213
Validation loss: 2.209474345048269

Epoch: 6| Step: 2
Training loss: 1.1461539268493652
Validation loss: 2.2492446303367615

Epoch: 6| Step: 3
Training loss: 1.1109929084777832
Validation loss: 2.2208195130030313

Epoch: 6| Step: 4
Training loss: 1.5995737314224243
Validation loss: 2.2038334210713706

Epoch: 6| Step: 5
Training loss: 1.545588731765747
Validation loss: 2.2211848894755044

Epoch: 6| Step: 6
Training loss: 1.088212013244629
Validation loss: 2.211678127447764

Epoch: 6| Step: 7
Training loss: 1.5922181606292725
Validation loss: 2.2560561696688333

Epoch: 6| Step: 8
Training loss: 1.8699910640716553
Validation loss: 2.2080082098642984

Epoch: 6| Step: 9
Training loss: 1.5184775590896606
Validation loss: 2.2207438349723816

Epoch: 6| Step: 10
Training loss: 2.0344138145446777
Validation loss: 2.220008909702301

Epoch: 6| Step: 11
Training loss: 1.7060141563415527
Validation loss: 2.227149764696757

Epoch: 6| Step: 12
Training loss: 1.5223515033721924
Validation loss: 2.1796151598294577

Epoch: 6| Step: 13
Training loss: 0.9438051581382751
Validation loss: 2.227196673552195

Epoch: 354| Step: 0
Training loss: 1.0730260610580444
Validation loss: 2.1699060996373496

Epoch: 6| Step: 1
Training loss: 1.0596036911010742
Validation loss: 2.205855071544647

Epoch: 6| Step: 2
Training loss: 1.3236143589019775
Validation loss: 2.1930460333824158

Epoch: 6| Step: 3
Training loss: 2.311008930206299
Validation loss: 2.179353634516398

Epoch: 6| Step: 4
Training loss: 1.7440742254257202
Validation loss: 2.2100104888280234

Epoch: 6| Step: 5
Training loss: 1.8912017345428467
Validation loss: 2.2164440552393594

Epoch: 6| Step: 6
Training loss: 2.5922083854675293
Validation loss: 2.2712361017862954

Epoch: 6| Step: 7
Training loss: 1.4912210702896118
Validation loss: 2.275954842567444

Epoch: 6| Step: 8
Training loss: 1.1483359336853027
Validation loss: 2.274779121081034

Epoch: 6| Step: 9
Training loss: 1.4163897037506104
Validation loss: 2.2772006591161094

Epoch: 6| Step: 10
Training loss: 1.8815815448760986
Validation loss: 2.2483174006144204

Epoch: 6| Step: 11
Training loss: 0.970342218875885
Validation loss: 2.2750261425971985

Epoch: 6| Step: 12
Training loss: 1.2581911087036133
Validation loss: 2.2439377307891846

Epoch: 6| Step: 13
Training loss: 1.6888209581375122
Validation loss: 2.2269833286603293

Epoch: 355| Step: 0
Training loss: 1.3291282653808594
Validation loss: 2.256032566229502

Epoch: 6| Step: 1
Training loss: 1.474111557006836
Validation loss: 2.275148948033651

Epoch: 6| Step: 2
Training loss: 2.2254161834716797
Validation loss: 2.2727930545806885

Epoch: 6| Step: 3
Training loss: 1.8755477666854858
Validation loss: 2.2944213350613913

Epoch: 6| Step: 4
Training loss: 1.7181591987609863
Validation loss: 2.268266499042511

Epoch: 6| Step: 5
Training loss: 2.075836181640625
Validation loss: 2.328954339027405

Epoch: 6| Step: 6
Training loss: 0.7407805323600769
Validation loss: 2.2792391379674277

Epoch: 6| Step: 7
Training loss: 1.849530816078186
Validation loss: 2.2748620907465615

Epoch: 6| Step: 8
Training loss: 1.3615866899490356
Validation loss: 2.252951741218567

Epoch: 6| Step: 9
Training loss: 1.777435302734375
Validation loss: 2.2490144968032837

Epoch: 6| Step: 10
Training loss: 1.266160249710083
Validation loss: 2.2425870299339294

Epoch: 6| Step: 11
Training loss: 1.5507514476776123
Validation loss: 2.259069840113322

Epoch: 6| Step: 12
Training loss: 1.170947790145874
Validation loss: 2.257567584514618

Epoch: 6| Step: 13
Training loss: 1.5487396717071533
Validation loss: 2.2408692638079324

Epoch: 356| Step: 0
Training loss: 1.6393600702285767
Validation loss: 2.2389093041419983

Epoch: 6| Step: 1
Training loss: 2.0488436222076416
Validation loss: 2.2157447735468545

Epoch: 6| Step: 2
Training loss: 1.5745328664779663
Validation loss: 2.2332146962483725

Epoch: 6| Step: 3
Training loss: 1.679282784461975
Validation loss: 2.189328134059906

Epoch: 6| Step: 4
Training loss: 1.5261744260787964
Validation loss: 2.17950173219045

Epoch: 6| Step: 5
Training loss: 1.8072171211242676
Validation loss: 2.209498147169749

Epoch: 6| Step: 6
Training loss: 1.1565930843353271
Validation loss: 2.1655704180399575

Epoch: 6| Step: 7
Training loss: 1.4940135478973389
Validation loss: 2.1774285634358725

Epoch: 6| Step: 8
Training loss: 1.5494170188903809
Validation loss: 2.2255419492721558

Epoch: 6| Step: 9
Training loss: 1.4293042421340942
Validation loss: 2.1983031630516052

Epoch: 6| Step: 10
Training loss: 1.9610624313354492
Validation loss: 2.172112305959066

Epoch: 6| Step: 11
Training loss: 1.775693416595459
Validation loss: 2.172522723674774

Epoch: 6| Step: 12
Training loss: 1.3051562309265137
Validation loss: 2.16374272108078

Epoch: 6| Step: 13
Training loss: 1.007745385169983
Validation loss: 2.184032440185547

Epoch: 357| Step: 0
Training loss: 1.1834031343460083
Validation loss: 2.2061374187469482

Epoch: 6| Step: 1
Training loss: 2.2447333335876465
Validation loss: 2.2095787525177

Epoch: 6| Step: 2
Training loss: 1.693872094154358
Validation loss: 2.203241010506948

Epoch: 6| Step: 3
Training loss: 2.0222277641296387
Validation loss: 2.2361135482788086

Epoch: 6| Step: 4
Training loss: 1.662412166595459
Validation loss: 2.216032604376475

Epoch: 6| Step: 5
Training loss: 0.9300501942634583
Validation loss: 2.2407596508661904

Epoch: 6| Step: 6
Training loss: 0.8859502673149109
Validation loss: 2.232003410657247

Epoch: 6| Step: 7
Training loss: 1.7992956638336182
Validation loss: 2.2347474892934165

Epoch: 6| Step: 8
Training loss: 1.0331993103027344
Validation loss: 2.251038591066996

Epoch: 6| Step: 9
Training loss: 1.765073299407959
Validation loss: 2.2797047098477683

Epoch: 6| Step: 10
Training loss: 1.7584511041641235
Validation loss: 2.2608157197634378

Epoch: 6| Step: 11
Training loss: 1.6871488094329834
Validation loss: 2.262255012989044

Epoch: 6| Step: 12
Training loss: 1.4017531871795654
Validation loss: 2.307274023691813

Epoch: 6| Step: 13
Training loss: 1.2624714374542236
Validation loss: 2.3017861247062683

Epoch: 358| Step: 0
Training loss: 1.3799970149993896
Validation loss: 2.3036003708839417

Epoch: 6| Step: 1
Training loss: 1.5851417779922485
Validation loss: 2.317143499851227

Epoch: 6| Step: 2
Training loss: 2.5304388999938965
Validation loss: 2.25540820757548

Epoch: 6| Step: 3
Training loss: 1.5182149410247803
Validation loss: 2.2579339146614075

Epoch: 6| Step: 4
Training loss: 1.4587757587432861
Validation loss: 2.2434850136439004

Epoch: 6| Step: 5
Training loss: 1.3515371084213257
Validation loss: 2.2389492789904275

Epoch: 6| Step: 6
Training loss: 1.964526653289795
Validation loss: 2.244240959485372

Epoch: 6| Step: 7
Training loss: 0.7986807227134705
Validation loss: 2.242370903491974

Epoch: 6| Step: 8
Training loss: 1.6342626810073853
Validation loss: 2.269002914428711

Epoch: 6| Step: 9
Training loss: 1.0074505805969238
Validation loss: 2.256822884082794

Epoch: 6| Step: 10
Training loss: 1.7396587133407593
Validation loss: 2.2498983343442283

Epoch: 6| Step: 11
Training loss: 0.6234257221221924
Validation loss: 2.2560375531514487

Epoch: 6| Step: 12
Training loss: 1.4208588600158691
Validation loss: 2.2640175819396973

Epoch: 6| Step: 13
Training loss: 1.5844788551330566
Validation loss: 2.266399621963501

Epoch: 359| Step: 0
Training loss: 1.28044855594635
Validation loss: 2.250609119733175

Epoch: 6| Step: 1
Training loss: 1.765539288520813
Validation loss: 2.239050288995107

Epoch: 6| Step: 2
Training loss: 0.9841458201408386
Validation loss: 2.2370562156041465

Epoch: 6| Step: 3
Training loss: 2.2293925285339355
Validation loss: 2.2050751050313315

Epoch: 6| Step: 4
Training loss: 1.2981055974960327
Validation loss: 2.204520285129547

Epoch: 6| Step: 5
Training loss: 0.8005582690238953
Validation loss: 2.1787466208140054

Epoch: 6| Step: 6
Training loss: 1.4747982025146484
Validation loss: 2.205276290575663

Epoch: 6| Step: 7
Training loss: 1.6284868717193604
Validation loss: 2.172229746977488

Epoch: 6| Step: 8
Training loss: 1.5416837930679321
Validation loss: 2.185164829095205

Epoch: 6| Step: 9
Training loss: 2.1563541889190674
Validation loss: 2.195375641187032

Epoch: 6| Step: 10
Training loss: 0.9457017779350281
Validation loss: 2.1801092624664307

Epoch: 6| Step: 11
Training loss: 1.008596420288086
Validation loss: 2.1623271107673645

Epoch: 6| Step: 12
Training loss: 1.2323522567749023
Validation loss: 2.175040145715078

Epoch: 6| Step: 13
Training loss: 1.400770664215088
Validation loss: 2.2090286215146384

Epoch: 360| Step: 0
Training loss: 0.9460983872413635
Validation loss: 2.1591465870539346

Epoch: 6| Step: 1
Training loss: 1.8596456050872803
Validation loss: 2.187917470932007

Epoch: 6| Step: 2
Training loss: 1.0883445739746094
Validation loss: 2.190987706184387

Epoch: 6| Step: 3
Training loss: 1.1349278688430786
Validation loss: 2.199391265710195

Epoch: 6| Step: 4
Training loss: 1.1923010349273682
Validation loss: 2.1680440306663513

Epoch: 6| Step: 5
Training loss: 1.2813475131988525
Validation loss: 2.1897170543670654

Epoch: 6| Step: 6
Training loss: 1.9196186065673828
Validation loss: 2.2033965984980264

Epoch: 6| Step: 7
Training loss: 1.650397539138794
Validation loss: 2.1919657985369363

Epoch: 6| Step: 8
Training loss: 1.9679791927337646
Validation loss: 2.190009852250417

Epoch: 6| Step: 9
Training loss: 1.2150837182998657
Validation loss: 2.2548199892044067

Epoch: 6| Step: 10
Training loss: 1.3839305639266968
Validation loss: 2.216538667678833

Epoch: 6| Step: 11
Training loss: 1.8997983932495117
Validation loss: 2.184026916821798

Epoch: 6| Step: 12
Training loss: 1.1947896480560303
Validation loss: 2.189700643221537

Epoch: 6| Step: 13
Training loss: 1.0471609830856323
Validation loss: 2.1976813475290933

Epoch: 361| Step: 0
Training loss: 1.0753717422485352
Validation loss: 2.191075603167216

Epoch: 6| Step: 1
Training loss: 1.0659465789794922
Validation loss: 2.2039830088615417

Epoch: 6| Step: 2
Training loss: 1.350931167602539
Validation loss: 2.216203808784485

Epoch: 6| Step: 3
Training loss: 2.060378074645996
Validation loss: 2.217666725317637

Epoch: 6| Step: 4
Training loss: 1.1811120510101318
Validation loss: 2.185569405555725

Epoch: 6| Step: 5
Training loss: 2.035423755645752
Validation loss: 2.217077116171519

Epoch: 6| Step: 6
Training loss: 1.605093002319336
Validation loss: 2.1837944984436035

Epoch: 6| Step: 7
Training loss: 1.8566970825195312
Validation loss: 2.1980353792508445

Epoch: 6| Step: 8
Training loss: 1.7444111108779907
Validation loss: 2.2179394960403442

Epoch: 6| Step: 9
Training loss: 1.3854387998580933
Validation loss: 2.231060286362966

Epoch: 6| Step: 10
Training loss: 1.2475929260253906
Validation loss: 2.202391425768534

Epoch: 6| Step: 11
Training loss: 1.5853163003921509
Validation loss: 2.1820152203241983

Epoch: 6| Step: 12
Training loss: 1.1661267280578613
Validation loss: 2.258737643559774

Epoch: 6| Step: 13
Training loss: 1.1370735168457031
Validation loss: 2.2348624070485434

Epoch: 362| Step: 0
Training loss: 1.7370712757110596
Validation loss: 2.197727382183075

Epoch: 6| Step: 1
Training loss: 1.7531957626342773
Validation loss: 2.245077967643738

Epoch: 6| Step: 2
Training loss: 1.3261308670043945
Validation loss: 2.225717306137085

Epoch: 6| Step: 3
Training loss: 1.781101107597351
Validation loss: 2.2349337339401245

Epoch: 6| Step: 4
Training loss: 1.0621907711029053
Validation loss: 2.214954694112142

Epoch: 6| Step: 5
Training loss: 1.7537853717803955
Validation loss: 2.2366893887519836

Epoch: 6| Step: 6
Training loss: 1.0800225734710693
Validation loss: 2.2031463781992593

Epoch: 6| Step: 7
Training loss: 1.5737924575805664
Validation loss: 2.2525250713030496

Epoch: 6| Step: 8
Training loss: 1.7924590110778809
Validation loss: 2.249221682548523

Epoch: 6| Step: 9
Training loss: 1.2947864532470703
Validation loss: 2.2426772316296897

Epoch: 6| Step: 10
Training loss: 0.6264870166778564
Validation loss: 2.196778873602549

Epoch: 6| Step: 11
Training loss: 1.5218478441238403
Validation loss: 2.2116445302963257

Epoch: 6| Step: 12
Training loss: 0.8336173295974731
Validation loss: 2.161923070748647

Epoch: 6| Step: 13
Training loss: 2.1415469646453857
Validation loss: 2.150589168071747

Epoch: 363| Step: 0
Training loss: 1.2024331092834473
Validation loss: 2.165634055932363

Epoch: 6| Step: 1
Training loss: 1.8041167259216309
Validation loss: 2.1385210951169333

Epoch: 6| Step: 2
Training loss: 1.0654544830322266
Validation loss: 2.1598939299583435

Epoch: 6| Step: 3
Training loss: 1.0045475959777832
Validation loss: 2.1999190847078958

Epoch: 6| Step: 4
Training loss: 1.3582195043563843
Validation loss: 2.153435210386912

Epoch: 6| Step: 5
Training loss: 2.0206968784332275
Validation loss: 2.1733062267303467

Epoch: 6| Step: 6
Training loss: 1.4311747550964355
Validation loss: 2.155038058757782

Epoch: 6| Step: 7
Training loss: 0.9887682795524597
Validation loss: 2.1771931449572244

Epoch: 6| Step: 8
Training loss: 0.9711002707481384
Validation loss: 2.2006102800369263

Epoch: 6| Step: 9
Training loss: 1.86747407913208
Validation loss: 2.1386083563168845

Epoch: 6| Step: 10
Training loss: 1.3802502155303955
Validation loss: 2.1971424420674643

Epoch: 6| Step: 11
Training loss: 1.958598017692566
Validation loss: 2.200537145137787

Epoch: 6| Step: 12
Training loss: 1.4955151081085205
Validation loss: 2.249998390674591

Epoch: 6| Step: 13
Training loss: 1.498178482055664
Validation loss: 2.210505644480387

Epoch: 364| Step: 0
Training loss: 1.44920015335083
Validation loss: 2.235043923060099

Epoch: 6| Step: 1
Training loss: 1.6644349098205566
Validation loss: 2.2175483306248984

Epoch: 6| Step: 2
Training loss: 1.3070340156555176
Validation loss: 2.2261566122372947

Epoch: 6| Step: 3
Training loss: 1.7050259113311768
Validation loss: 2.2292633255322776

Epoch: 6| Step: 4
Training loss: 1.4376463890075684
Validation loss: 2.186885952949524

Epoch: 6| Step: 5
Training loss: 1.2108304500579834
Validation loss: 2.2333287994066873

Epoch: 6| Step: 6
Training loss: 1.070928931236267
Validation loss: 2.2083683013916016

Epoch: 6| Step: 7
Training loss: 1.757215976715088
Validation loss: 2.2207378149032593

Epoch: 6| Step: 8
Training loss: 1.1457229852676392
Validation loss: 2.1760444243748984

Epoch: 6| Step: 9
Training loss: 1.0489881038665771
Validation loss: 2.1566818356513977

Epoch: 6| Step: 10
Training loss: 1.110122561454773
Validation loss: 2.1228570143381753

Epoch: 6| Step: 11
Training loss: 1.5455681085586548
Validation loss: 2.1308188239733377

Epoch: 6| Step: 12
Training loss: 1.1148090362548828
Validation loss: 2.130921999613444

Epoch: 6| Step: 13
Training loss: 2.0980474948883057
Validation loss: 2.089066445827484

Epoch: 365| Step: 0
Training loss: 1.745544672012329
Validation loss: 2.1166853308677673

Epoch: 6| Step: 1
Training loss: 1.0798261165618896
Validation loss: 2.131318132082621

Epoch: 6| Step: 2
Training loss: 1.2678275108337402
Validation loss: 2.1210590998331704

Epoch: 6| Step: 3
Training loss: 1.0478888750076294
Validation loss: 2.139757990837097

Epoch: 6| Step: 4
Training loss: 1.5845282077789307
Validation loss: 2.150333285331726

Epoch: 6| Step: 5
Training loss: 1.770382046699524
Validation loss: 2.183544377485911

Epoch: 6| Step: 6
Training loss: 1.1216031312942505
Validation loss: 2.184700886408488

Epoch: 6| Step: 7
Training loss: 1.4367408752441406
Validation loss: 2.201140503088633

Epoch: 6| Step: 8
Training loss: 1.0780141353607178
Validation loss: 2.217924118041992

Epoch: 6| Step: 9
Training loss: 1.8213839530944824
Validation loss: 2.170694669087728

Epoch: 6| Step: 10
Training loss: 0.9510721564292908
Validation loss: 2.178991456826528

Epoch: 6| Step: 11
Training loss: 1.9099740982055664
Validation loss: 2.201563239097595

Epoch: 6| Step: 12
Training loss: 1.8790870904922485
Validation loss: 2.2229874531428018

Epoch: 6| Step: 13
Training loss: 1.0135912895202637
Validation loss: 2.226541578769684

Epoch: 366| Step: 0
Training loss: 1.549523115158081
Validation loss: 2.2068264484405518

Epoch: 6| Step: 1
Training loss: 0.9427134990692139
Validation loss: 2.185362716515859

Epoch: 6| Step: 2
Training loss: 1.5405352115631104
Validation loss: 2.230984608332316

Epoch: 6| Step: 3
Training loss: 1.2791804075241089
Validation loss: 2.177121639251709

Epoch: 6| Step: 4
Training loss: 1.192204475402832
Validation loss: 2.1949888467788696

Epoch: 6| Step: 5
Training loss: 1.7506380081176758
Validation loss: 2.1973049640655518

Epoch: 6| Step: 6
Training loss: 0.9507993459701538
Validation loss: 2.1723029414812722

Epoch: 6| Step: 7
Training loss: 1.6107614040374756
Validation loss: 2.179234782854716

Epoch: 6| Step: 8
Training loss: 2.3131699562072754
Validation loss: 2.156842907269796

Epoch: 6| Step: 9
Training loss: 1.4381742477416992
Validation loss: 2.177395840485891

Epoch: 6| Step: 10
Training loss: 0.9715371131896973
Validation loss: 2.117595930894216

Epoch: 6| Step: 11
Training loss: 1.222318172454834
Validation loss: 2.1799248655637107

Epoch: 6| Step: 12
Training loss: 1.2955427169799805
Validation loss: 2.1801786621411643

Epoch: 6| Step: 13
Training loss: 1.5391442775726318
Validation loss: 2.141378323237101

Epoch: 367| Step: 0
Training loss: 1.3326241970062256
Validation loss: 2.1612942218780518

Epoch: 6| Step: 1
Training loss: 1.2842717170715332
Validation loss: 2.1635979811350503

Epoch: 6| Step: 2
Training loss: 1.5023435354232788
Validation loss: 2.143911083539327

Epoch: 6| Step: 3
Training loss: 0.8465623259544373
Validation loss: 2.1939207712809243

Epoch: 6| Step: 4
Training loss: 1.764953851699829
Validation loss: 2.160174787044525

Epoch: 6| Step: 5
Training loss: 0.9522782564163208
Validation loss: 2.18729168176651

Epoch: 6| Step: 6
Training loss: 1.3624508380889893
Validation loss: 2.154715120792389

Epoch: 6| Step: 7
Training loss: 1.0703479051589966
Validation loss: 2.1534397999445596

Epoch: 6| Step: 8
Training loss: 0.9074337482452393
Validation loss: 2.162937879562378

Epoch: 6| Step: 9
Training loss: 1.5226000547409058
Validation loss: 2.179274400075277

Epoch: 6| Step: 10
Training loss: 1.2033460140228271
Validation loss: 2.1892353693644204

Epoch: 6| Step: 11
Training loss: 1.8036956787109375
Validation loss: 2.1575398047765098

Epoch: 6| Step: 12
Training loss: 1.9757670164108276
Validation loss: 2.189718723297119

Epoch: 6| Step: 13
Training loss: 1.7262628078460693
Validation loss: 2.179368873437246

Epoch: 368| Step: 0
Training loss: 1.7543599605560303
Validation loss: 2.198072055975596

Epoch: 6| Step: 1
Training loss: 1.595875859260559
Validation loss: 2.163237730662028

Epoch: 6| Step: 2
Training loss: 1.170910120010376
Validation loss: 2.159024258454641

Epoch: 6| Step: 3
Training loss: 1.384423017501831
Validation loss: 2.176898161570231

Epoch: 6| Step: 4
Training loss: 1.8094630241394043
Validation loss: 2.180413027604421

Epoch: 6| Step: 5
Training loss: 1.1511214971542358
Validation loss: 2.151077151298523

Epoch: 6| Step: 6
Training loss: 0.9379090070724487
Validation loss: 2.171105146408081

Epoch: 6| Step: 7
Training loss: 1.5832724571228027
Validation loss: 2.1789972384770713

Epoch: 6| Step: 8
Training loss: 0.7330788373947144
Validation loss: 2.1860125064849854

Epoch: 6| Step: 9
Training loss: 1.7215856313705444
Validation loss: 2.215944290161133

Epoch: 6| Step: 10
Training loss: 1.3157241344451904
Validation loss: 2.20526393254598

Epoch: 6| Step: 11
Training loss: 0.9412738084793091
Validation loss: 2.217531760533651

Epoch: 6| Step: 12
Training loss: 2.360072135925293
Validation loss: 2.211987614631653

Epoch: 6| Step: 13
Training loss: 1.3986461162567139
Validation loss: 2.2037678360939026

Epoch: 369| Step: 0
Training loss: 1.8538880348205566
Validation loss: 2.2391891876856485

Epoch: 6| Step: 1
Training loss: 1.454828143119812
Validation loss: 2.1615885694821677

Epoch: 6| Step: 2
Training loss: 1.346564531326294
Validation loss: 2.142658054828644

Epoch: 6| Step: 3
Training loss: 1.4096128940582275
Validation loss: 2.146688242753347

Epoch: 6| Step: 4
Training loss: 1.057995319366455
Validation loss: 2.123708168665568

Epoch: 6| Step: 5
Training loss: 1.325232982635498
Validation loss: 2.148440440495809

Epoch: 6| Step: 6
Training loss: 1.623508334159851
Validation loss: 2.108965357144674

Epoch: 6| Step: 7
Training loss: 1.9455369710922241
Validation loss: 2.0788223346074424

Epoch: 6| Step: 8
Training loss: 1.3974840641021729
Validation loss: 2.08277690410614

Epoch: 6| Step: 9
Training loss: 1.116248369216919
Validation loss: 2.048852523167928

Epoch: 6| Step: 10
Training loss: 1.7597817182540894
Validation loss: 2.087716042995453

Epoch: 6| Step: 11
Training loss: 1.762425184249878
Validation loss: 2.0695937871932983

Epoch: 6| Step: 12
Training loss: 0.9337971210479736
Validation loss: 2.1384584506352744

Epoch: 6| Step: 13
Training loss: 1.7913398742675781
Validation loss: 2.1271116932233176

Epoch: 370| Step: 0
Training loss: 0.9878137111663818
Validation loss: 2.1781854828198752

Epoch: 6| Step: 1
Training loss: 1.3814029693603516
Validation loss: 2.183198849360148

Epoch: 6| Step: 2
Training loss: 1.6718014478683472
Validation loss: 2.1853338877360025

Epoch: 6| Step: 3
Training loss: 1.188279390335083
Validation loss: 2.164336323738098

Epoch: 6| Step: 4
Training loss: 1.461394190788269
Validation loss: 2.1685124039649963

Epoch: 6| Step: 5
Training loss: 2.5030274391174316
Validation loss: 2.1790365179379783

Epoch: 6| Step: 6
Training loss: 1.884218454360962
Validation loss: 2.148552179336548

Epoch: 6| Step: 7
Training loss: 1.380121111869812
Validation loss: 2.1825742721557617

Epoch: 6| Step: 8
Training loss: 1.3017008304595947
Validation loss: 2.14205272992452

Epoch: 6| Step: 9
Training loss: 0.7156909704208374
Validation loss: 2.2450260321299234

Epoch: 6| Step: 10
Training loss: 0.9713292717933655
Validation loss: 2.2052607933680215

Epoch: 6| Step: 11
Training loss: 1.477476954460144
Validation loss: 2.174269179503123

Epoch: 6| Step: 12
Training loss: 1.2576823234558105
Validation loss: 2.1515482664108276

Epoch: 6| Step: 13
Training loss: 1.260262131690979
Validation loss: 2.200829267501831

Epoch: 371| Step: 0
Training loss: 1.731045126914978
Validation loss: 2.200123210748037

Epoch: 6| Step: 1
Training loss: 1.3512519598007202
Validation loss: 2.21758238474528

Epoch: 6| Step: 2
Training loss: 1.3091645240783691
Validation loss: 2.2034220894177756

Epoch: 6| Step: 3
Training loss: 1.7042553424835205
Validation loss: 2.18385648727417

Epoch: 6| Step: 4
Training loss: 1.1725139617919922
Validation loss: 2.194714844226837

Epoch: 6| Step: 5
Training loss: 1.1693477630615234
Validation loss: 2.200594703356425

Epoch: 6| Step: 6
Training loss: 1.237222671508789
Validation loss: 2.1852661768595376

Epoch: 6| Step: 7
Training loss: 0.9414123296737671
Validation loss: 2.1906574964523315

Epoch: 6| Step: 8
Training loss: 1.5677664279937744
Validation loss: 2.1956481536229453

Epoch: 6| Step: 9
Training loss: 0.9941074252128601
Validation loss: 2.1848015785217285

Epoch: 6| Step: 10
Training loss: 1.5635151863098145
Validation loss: 2.2099558115005493

Epoch: 6| Step: 11
Training loss: 1.5205692052841187
Validation loss: 2.191864093144735

Epoch: 6| Step: 12
Training loss: 2.3879780769348145
Validation loss: 2.2292463382085166

Epoch: 6| Step: 13
Training loss: 1.3052266836166382
Validation loss: 2.2234373490015664

Epoch: 372| Step: 0
Training loss: 1.548227310180664
Validation loss: 2.211541175842285

Epoch: 6| Step: 1
Training loss: 0.7799843549728394
Validation loss: 2.228590250015259

Epoch: 6| Step: 2
Training loss: 1.9652037620544434
Validation loss: 2.2126576900482178

Epoch: 6| Step: 3
Training loss: 1.3420772552490234
Validation loss: 2.1982908646265664

Epoch: 6| Step: 4
Training loss: 1.6569676399230957
Validation loss: 2.2012865940729776

Epoch: 6| Step: 5
Training loss: 1.1298502683639526
Validation loss: 2.213992695013682

Epoch: 6| Step: 6
Training loss: 1.5962367057800293
Validation loss: 2.188702662785848

Epoch: 6| Step: 7
Training loss: 0.6809090375900269
Validation loss: 2.1924027800559998

Epoch: 6| Step: 8
Training loss: 0.9517797827720642
Validation loss: 2.156586507956187

Epoch: 6| Step: 9
Training loss: 1.5563929080963135
Validation loss: 2.129258672396342

Epoch: 6| Step: 10
Training loss: 1.5060278177261353
Validation loss: 2.171557048956553

Epoch: 6| Step: 11
Training loss: 1.6945966482162476
Validation loss: 2.1444955865542092

Epoch: 6| Step: 12
Training loss: 1.7642199993133545
Validation loss: 2.15792308251063

Epoch: 6| Step: 13
Training loss: 0.9765614867210388
Validation loss: 2.157574236392975

Epoch: 373| Step: 0
Training loss: 0.6294687390327454
Validation loss: 2.1618858774503074

Epoch: 6| Step: 1
Training loss: 1.303696870803833
Validation loss: 2.1533135970433555

Epoch: 6| Step: 2
Training loss: 1.3136169910430908
Validation loss: 2.1243471105893454

Epoch: 6| Step: 3
Training loss: 0.9097530841827393
Validation loss: 2.1323511401812234

Epoch: 6| Step: 4
Training loss: 1.6097345352172852
Validation loss: 2.147490918636322

Epoch: 6| Step: 5
Training loss: 1.5985534191131592
Validation loss: 2.1953943570454917

Epoch: 6| Step: 6
Training loss: 1.643825888633728
Validation loss: 2.19349733988444

Epoch: 6| Step: 7
Training loss: 1.2640149593353271
Validation loss: 2.2052841583887735

Epoch: 6| Step: 8
Training loss: 1.3896467685699463
Validation loss: 2.1361204783121743

Epoch: 6| Step: 9
Training loss: 1.0795174837112427
Validation loss: 2.171475330988566

Epoch: 6| Step: 10
Training loss: 2.1646106243133545
Validation loss: 2.1655803124109902

Epoch: 6| Step: 11
Training loss: 1.9739508628845215
Validation loss: 2.180299997329712

Epoch: 6| Step: 12
Training loss: 1.0834788084030151
Validation loss: 2.207745850086212

Epoch: 6| Step: 13
Training loss: 1.2163957357406616
Validation loss: 2.2099130948384604

Epoch: 374| Step: 0
Training loss: 1.4751732349395752
Validation loss: 2.195329229036967

Epoch: 6| Step: 1
Training loss: 1.2489147186279297
Validation loss: 2.234078327814738

Epoch: 6| Step: 2
Training loss: 0.9976787567138672
Validation loss: 2.174958070119222

Epoch: 6| Step: 3
Training loss: 1.3316898345947266
Validation loss: 2.1724085807800293

Epoch: 6| Step: 4
Training loss: 1.210028886795044
Validation loss: 2.1334505677223206

Epoch: 6| Step: 5
Training loss: 1.3769484758377075
Validation loss: 2.1328744888305664

Epoch: 6| Step: 6
Training loss: 1.374836802482605
Validation loss: 2.1582742730776467

Epoch: 6| Step: 7
Training loss: 1.1990209817886353
Validation loss: 2.1318198442459106

Epoch: 6| Step: 8
Training loss: 1.9311611652374268
Validation loss: 2.111136257648468

Epoch: 6| Step: 9
Training loss: 1.6778171062469482
Validation loss: 2.095668534437815

Epoch: 6| Step: 10
Training loss: 1.8893277645111084
Validation loss: 2.1285290519396463

Epoch: 6| Step: 11
Training loss: 1.2331969738006592
Validation loss: 2.1395914355913797

Epoch: 6| Step: 12
Training loss: 0.9266951084136963
Validation loss: 2.1343734860420227

Epoch: 6| Step: 13
Training loss: 2.210514545440674
Validation loss: 2.1821688612302146

Epoch: 375| Step: 0
Training loss: 1.2048143148422241
Validation loss: 2.1690992514292398

Epoch: 6| Step: 1
Training loss: 1.2565007209777832
Validation loss: 2.181513945261637

Epoch: 6| Step: 2
Training loss: 1.1374561786651611
Validation loss: 2.2117794354756675

Epoch: 6| Step: 3
Training loss: 1.1490907669067383
Validation loss: 2.182038644949595

Epoch: 6| Step: 4
Training loss: 1.6101073026657104
Validation loss: 2.1547533671061196

Epoch: 6| Step: 5
Training loss: 1.8301132917404175
Validation loss: 2.187818765640259

Epoch: 6| Step: 6
Training loss: 1.6788647174835205
Validation loss: 2.15657373269399

Epoch: 6| Step: 7
Training loss: 0.8660737872123718
Validation loss: 2.1710123221079507

Epoch: 6| Step: 8
Training loss: 2.058131694793701
Validation loss: 2.132126490275065

Epoch: 6| Step: 9
Training loss: 0.7117437124252319
Validation loss: 2.138430198033651

Epoch: 6| Step: 10
Training loss: 1.8969608545303345
Validation loss: 2.134200910727183

Epoch: 6| Step: 11
Training loss: 0.5701441764831543
Validation loss: 2.119587461153666

Epoch: 6| Step: 12
Training loss: 1.7224442958831787
Validation loss: 2.1057802637418113

Epoch: 6| Step: 13
Training loss: 1.5290776491165161
Validation loss: 2.1308860977490744

Epoch: 376| Step: 0
Training loss: 1.2890230417251587
Validation loss: 2.1620617111523948

Epoch: 6| Step: 1
Training loss: 1.8159388303756714
Validation loss: 2.2013458808263144

Epoch: 6| Step: 2
Training loss: 1.1495720148086548
Validation loss: 2.180904765923818

Epoch: 6| Step: 3
Training loss: 1.28977370262146
Validation loss: 2.198555072148641

Epoch: 6| Step: 4
Training loss: 0.9318346381187439
Validation loss: 2.2217469215393066

Epoch: 6| Step: 5
Training loss: 1.575026035308838
Validation loss: 2.2307085593541465

Epoch: 6| Step: 6
Training loss: 2.401729106903076
Validation loss: 2.2510134180386863

Epoch: 6| Step: 7
Training loss: 1.2407634258270264
Validation loss: 2.235743304093679

Epoch: 6| Step: 8
Training loss: 0.993394136428833
Validation loss: 2.243380606174469

Epoch: 6| Step: 9
Training loss: 1.4127888679504395
Validation loss: 2.2320542136828103

Epoch: 6| Step: 10
Training loss: 1.5729444026947021
Validation loss: 2.206024169921875

Epoch: 6| Step: 11
Training loss: 1.4299143552780151
Validation loss: 2.2104275623957315

Epoch: 6| Step: 12
Training loss: 1.3914251327514648
Validation loss: 2.2292809089024863

Epoch: 6| Step: 13
Training loss: 1.5170702934265137
Validation loss: 2.202411671479543

Epoch: 377| Step: 0
Training loss: 1.8302503824234009
Validation loss: 2.210732618967692

Epoch: 6| Step: 1
Training loss: 1.3664326667785645
Validation loss: 2.1798043052355447

Epoch: 6| Step: 2
Training loss: 1.4563560485839844
Validation loss: 2.145244777202606

Epoch: 6| Step: 3
Training loss: 1.4801685810089111
Validation loss: 2.1075512369473777

Epoch: 6| Step: 4
Training loss: 0.8661054372787476
Validation loss: 2.137122472127279

Epoch: 6| Step: 5
Training loss: 0.9854577779769897
Validation loss: 2.0649797519048056

Epoch: 6| Step: 6
Training loss: 2.0833263397216797
Validation loss: 2.111674984296163

Epoch: 6| Step: 7
Training loss: 1.9008278846740723
Validation loss: 2.10025292634964

Epoch: 6| Step: 8
Training loss: 1.2316687107086182
Validation loss: 2.1492812236150107

Epoch: 6| Step: 9
Training loss: 1.0701029300689697
Validation loss: 2.134668290615082

Epoch: 6| Step: 10
Training loss: 1.4425708055496216
Validation loss: 2.095573902130127

Epoch: 6| Step: 11
Training loss: 1.1528494358062744
Validation loss: 2.1338067849477134

Epoch: 6| Step: 12
Training loss: 1.6270602941513062
Validation loss: 2.1254153649012246

Epoch: 6| Step: 13
Training loss: 1.2287182807922363
Validation loss: 2.12233837445577

Epoch: 378| Step: 0
Training loss: 2.089263916015625
Validation loss: 2.1848791042963662

Epoch: 6| Step: 1
Training loss: 1.4814701080322266
Validation loss: 2.1829410791397095

Epoch: 6| Step: 2
Training loss: 1.3257904052734375
Validation loss: 2.200597365697225

Epoch: 6| Step: 3
Training loss: 1.7538765668869019
Validation loss: 2.250061591466268

Epoch: 6| Step: 4
Training loss: 1.4753361940383911
Validation loss: 2.229538897673289

Epoch: 6| Step: 5
Training loss: 1.862471580505371
Validation loss: 2.2633559703826904

Epoch: 6| Step: 6
Training loss: 2.107405424118042
Validation loss: 2.250418404738108

Epoch: 6| Step: 7
Training loss: 0.44367629289627075
Validation loss: 2.220901052157084

Epoch: 6| Step: 8
Training loss: 0.8233429789543152
Validation loss: 2.21872212489446

Epoch: 6| Step: 9
Training loss: 1.38384211063385
Validation loss: 2.224655111630758

Epoch: 6| Step: 10
Training loss: 1.2435964345932007
Validation loss: 2.2851669589678445

Epoch: 6| Step: 11
Training loss: 1.7973871231079102
Validation loss: 2.289169430732727

Epoch: 6| Step: 12
Training loss: 1.6956669092178345
Validation loss: 2.274822413921356

Epoch: 6| Step: 13
Training loss: 1.0909934043884277
Validation loss: 2.2830408215522766

Epoch: 379| Step: 0
Training loss: 1.0961766242980957
Validation loss: 2.2487959067026773

Epoch: 6| Step: 1
Training loss: 1.5879451036453247
Validation loss: 2.241822818915049

Epoch: 6| Step: 2
Training loss: 1.3785221576690674
Validation loss: 2.2265618046124778

Epoch: 6| Step: 3
Training loss: 1.0382866859436035
Validation loss: 2.2251756389935813

Epoch: 6| Step: 4
Training loss: 2.001441717147827
Validation loss: 2.140751381715139

Epoch: 6| Step: 5
Training loss: 1.0094385147094727
Validation loss: 2.1783729791641235

Epoch: 6| Step: 6
Training loss: 1.5315814018249512
Validation loss: 2.148365020751953

Epoch: 6| Step: 7
Training loss: 2.72190523147583
Validation loss: 2.1429564555486045

Epoch: 6| Step: 8
Training loss: 0.8813232183456421
Validation loss: 2.164617578188578

Epoch: 6| Step: 9
Training loss: 0.7870210409164429
Validation loss: 2.1446651220321655

Epoch: 6| Step: 10
Training loss: 0.8466641902923584
Validation loss: 2.170502543449402

Epoch: 6| Step: 11
Training loss: 1.5466334819793701
Validation loss: 2.128623366355896

Epoch: 6| Step: 12
Training loss: 1.4339059591293335
Validation loss: 2.100550055503845

Epoch: 6| Step: 13
Training loss: 1.1058340072631836
Validation loss: 2.076869547367096

Epoch: 380| Step: 0
Training loss: 1.1785237789154053
Validation loss: 2.1146289706230164

Epoch: 6| Step: 1
Training loss: 1.4986333847045898
Validation loss: 2.151076157887777

Epoch: 6| Step: 2
Training loss: 1.7579646110534668
Validation loss: 2.1570874055226645

Epoch: 6| Step: 3
Training loss: 1.7353183031082153
Validation loss: 2.1319634715716043

Epoch: 6| Step: 4
Training loss: 1.2325319051742554
Validation loss: 2.159026861190796

Epoch: 6| Step: 5
Training loss: 1.2236846685409546
Validation loss: 2.1647322376569114

Epoch: 6| Step: 6
Training loss: 1.6249873638153076
Validation loss: 2.163737654685974

Epoch: 6| Step: 7
Training loss: 1.343364953994751
Validation loss: 2.1229169170061746

Epoch: 6| Step: 8
Training loss: 0.947490930557251
Validation loss: 2.1444336970647178

Epoch: 6| Step: 9
Training loss: 1.4461044073104858
Validation loss: 2.104083160559336

Epoch: 6| Step: 10
Training loss: 1.1953668594360352
Validation loss: 2.120313346385956

Epoch: 6| Step: 11
Training loss: 1.2120972871780396
Validation loss: 2.0901148120562234

Epoch: 6| Step: 12
Training loss: 1.3933824300765991
Validation loss: 2.1178645491600037

Epoch: 6| Step: 13
Training loss: 1.0137851238250732
Validation loss: 2.1496932903925576

Epoch: 381| Step: 0
Training loss: 0.9350796937942505
Validation loss: 2.188573658466339

Epoch: 6| Step: 1
Training loss: 1.382054090499878
Validation loss: 2.167692542076111

Epoch: 6| Step: 2
Training loss: 1.1056640148162842
Validation loss: 2.2135912775993347

Epoch: 6| Step: 3
Training loss: 1.6514348983764648
Validation loss: 2.239806830883026

Epoch: 6| Step: 4
Training loss: 1.745919942855835
Validation loss: 2.223123788833618

Epoch: 6| Step: 5
Training loss: 0.7250770330429077
Validation loss: 2.2426750858624778

Epoch: 6| Step: 6
Training loss: 0.8106966018676758
Validation loss: 2.234778801600138

Epoch: 6| Step: 7
Training loss: 1.5325431823730469
Validation loss: 2.2171149849891663

Epoch: 6| Step: 8
Training loss: 1.576580286026001
Validation loss: 2.1814945538838706

Epoch: 6| Step: 9
Training loss: 1.4267443418502808
Validation loss: 2.2223488489786782

Epoch: 6| Step: 10
Training loss: 1.1249054670333862
Validation loss: 2.161085367202759

Epoch: 6| Step: 11
Training loss: 0.87367182970047
Validation loss: 2.1869531671206155

Epoch: 6| Step: 12
Training loss: 1.1815850734710693
Validation loss: 2.150622526804606

Epoch: 6| Step: 13
Training loss: 1.8802292346954346
Validation loss: 2.126487930615743

Epoch: 382| Step: 0
Training loss: 1.666363000869751
Validation loss: 2.146066884199778

Epoch: 6| Step: 1
Training loss: 1.4564626216888428
Validation loss: 2.135126272837321

Epoch: 6| Step: 2
Training loss: 1.6302459239959717
Validation loss: 2.1576576034228006

Epoch: 6| Step: 3
Training loss: 1.633337378501892
Validation loss: 2.1122029423713684

Epoch: 6| Step: 4
Training loss: 1.190423607826233
Validation loss: 2.1297584970792136

Epoch: 6| Step: 5
Training loss: 0.9855157732963562
Validation loss: 2.108444253603617

Epoch: 6| Step: 6
Training loss: 1.006125569343567
Validation loss: 2.1649404565493264

Epoch: 6| Step: 7
Training loss: 1.3049776554107666
Validation loss: 2.1570992469787598

Epoch: 6| Step: 8
Training loss: 1.1737043857574463
Validation loss: 2.1153747836748757

Epoch: 6| Step: 9
Training loss: 0.9404418468475342
Validation loss: 2.1995145877202353

Epoch: 6| Step: 10
Training loss: 1.6238216161727905
Validation loss: 2.175971746444702

Epoch: 6| Step: 11
Training loss: 1.4438915252685547
Validation loss: 2.1540094216664634

Epoch: 6| Step: 12
Training loss: 1.2053754329681396
Validation loss: 2.1642146507898965

Epoch: 6| Step: 13
Training loss: 1.147974967956543
Validation loss: 2.1801278591156006

Epoch: 383| Step: 0
Training loss: 1.480820894241333
Validation loss: 2.186334252357483

Epoch: 6| Step: 1
Training loss: 1.2195578813552856
Validation loss: 2.2091238498687744

Epoch: 6| Step: 2
Training loss: 1.0397443771362305
Validation loss: 2.2118568817774453

Epoch: 6| Step: 3
Training loss: 1.625476360321045
Validation loss: 2.211166501045227

Epoch: 6| Step: 4
Training loss: 1.4127728939056396
Validation loss: 2.1621593236923218

Epoch: 6| Step: 5
Training loss: 1.3561381101608276
Validation loss: 2.1804457902908325

Epoch: 6| Step: 6
Training loss: 0.8189603686332703
Validation loss: 2.1798455119132996

Epoch: 6| Step: 7
Training loss: 1.391379475593567
Validation loss: 2.17663981517156

Epoch: 6| Step: 8
Training loss: 1.6829249858856201
Validation loss: 2.175407807032267

Epoch: 6| Step: 9
Training loss: 1.1829981803894043
Validation loss: 2.1760409275690713

Epoch: 6| Step: 10
Training loss: 2.143972873687744
Validation loss: 2.1980795860290527

Epoch: 6| Step: 11
Training loss: 0.8751493692398071
Validation loss: 2.2154512206713357

Epoch: 6| Step: 12
Training loss: 1.012800693511963
Validation loss: 2.1473980148633323

Epoch: 6| Step: 13
Training loss: 0.9154412746429443
Validation loss: 2.127621332804362

Epoch: 384| Step: 0
Training loss: 1.5180110931396484
Validation loss: 2.156087319056193

Epoch: 6| Step: 1
Training loss: 0.6909154057502747
Validation loss: 2.1794363458951316

Epoch: 6| Step: 2
Training loss: 1.2978441715240479
Validation loss: 2.150008499622345

Epoch: 6| Step: 3
Training loss: 1.4992187023162842
Validation loss: 2.173990249633789

Epoch: 6| Step: 4
Training loss: 1.283402442932129
Validation loss: 2.164534608523051

Epoch: 6| Step: 5
Training loss: 1.1416451930999756
Validation loss: 2.1781721711158752

Epoch: 6| Step: 6
Training loss: 1.414929747581482
Validation loss: 2.155927618344625

Epoch: 6| Step: 7
Training loss: 1.1648201942443848
Validation loss: 2.163098414738973

Epoch: 6| Step: 8
Training loss: 1.0809171199798584
Validation loss: 2.1588071982065835

Epoch: 6| Step: 9
Training loss: 1.130889654159546
Validation loss: 2.1724897623062134

Epoch: 6| Step: 10
Training loss: 1.3823802471160889
Validation loss: 2.18497896194458

Epoch: 6| Step: 11
Training loss: 0.9753819704055786
Validation loss: 2.2079612016677856

Epoch: 6| Step: 12
Training loss: 1.4125040769577026
Validation loss: 2.2104180653889975

Epoch: 6| Step: 13
Training loss: 2.078723192214966
Validation loss: 2.1788543661435447

Epoch: 385| Step: 0
Training loss: 1.19784414768219
Validation loss: 2.201904515425364

Epoch: 6| Step: 1
Training loss: 0.9261349439620972
Validation loss: 2.2034127910931907

Epoch: 6| Step: 2
Training loss: 1.430730938911438
Validation loss: 2.2573930819829306

Epoch: 6| Step: 3
Training loss: 1.6353576183319092
Validation loss: 2.256539305051168

Epoch: 6| Step: 4
Training loss: 1.4400756359100342
Validation loss: 2.241761883099874

Epoch: 6| Step: 5
Training loss: 1.568568468093872
Validation loss: 2.2538793484369912

Epoch: 6| Step: 6
Training loss: 1.109834909439087
Validation loss: 2.178084890047709

Epoch: 6| Step: 7
Training loss: 1.4466774463653564
Validation loss: 2.1983207861582437

Epoch: 6| Step: 8
Training loss: 2.243185043334961
Validation loss: 2.209505637486776

Epoch: 6| Step: 9
Training loss: 1.3271249532699585
Validation loss: 2.1940166354179382

Epoch: 6| Step: 10
Training loss: 1.3410379886627197
Validation loss: 2.2031962275505066

Epoch: 6| Step: 11
Training loss: 1.255371332168579
Validation loss: 2.1831858356793723

Epoch: 6| Step: 12
Training loss: 0.8803529143333435
Validation loss: 2.156268000602722

Epoch: 6| Step: 13
Training loss: 1.2565380334854126
Validation loss: 2.1844210426012673

Epoch: 386| Step: 0
Training loss: 0.807565450668335
Validation loss: 2.16147251923879

Epoch: 6| Step: 1
Training loss: 1.317776083946228
Validation loss: 2.1614590883255005

Epoch: 6| Step: 2
Training loss: 1.7069478034973145
Validation loss: 2.1616419752438865

Epoch: 6| Step: 3
Training loss: 1.5708727836608887
Validation loss: 2.2028417388598123

Epoch: 6| Step: 4
Training loss: 1.445320725440979
Validation loss: 2.17302672068278

Epoch: 6| Step: 5
Training loss: 1.4110089540481567
Validation loss: 2.1415889461835227

Epoch: 6| Step: 6
Training loss: 1.0903596878051758
Validation loss: 2.0959961811701455

Epoch: 6| Step: 7
Training loss: 1.0441327095031738
Validation loss: 2.1439008315404258

Epoch: 6| Step: 8
Training loss: 1.5333324670791626
Validation loss: 2.162821809450785

Epoch: 6| Step: 9
Training loss: 1.3283439874649048
Validation loss: 2.123291015625

Epoch: 6| Step: 10
Training loss: 1.2397637367248535
Validation loss: 2.1446839570999146

Epoch: 6| Step: 11
Training loss: 1.456520676612854
Validation loss: 2.139995257059733

Epoch: 6| Step: 12
Training loss: 1.040024995803833
Validation loss: 2.169663667678833

Epoch: 6| Step: 13
Training loss: 1.3008264303207397
Validation loss: 2.173859794934591

Epoch: 387| Step: 0
Training loss: 1.9771300554275513
Validation loss: 2.1794544458389282

Epoch: 6| Step: 1
Training loss: 0.6981918811798096
Validation loss: 2.1850950916608176

Epoch: 6| Step: 2
Training loss: 1.4210947751998901
Validation loss: 2.17943012714386

Epoch: 6| Step: 3
Training loss: 1.2822999954223633
Validation loss: 2.2664197285970054

Epoch: 6| Step: 4
Training loss: 0.8084192276000977
Validation loss: 2.2349599599838257

Epoch: 6| Step: 5
Training loss: 2.0039806365966797
Validation loss: 2.2569085160891214

Epoch: 6| Step: 6
Training loss: 1.4672045707702637
Validation loss: 2.2420907815297446

Epoch: 6| Step: 7
Training loss: 1.644054889678955
Validation loss: 2.2584058046340942

Epoch: 6| Step: 8
Training loss: 1.0834259986877441
Validation loss: 2.2048458059628806

Epoch: 6| Step: 9
Training loss: 1.4149377346038818
Validation loss: 2.2109676202138266

Epoch: 6| Step: 10
Training loss: 1.628217101097107
Validation loss: 2.164590577284495

Epoch: 6| Step: 11
Training loss: 1.4049519300460815
Validation loss: 2.2263377904891968

Epoch: 6| Step: 12
Training loss: 2.1563515663146973
Validation loss: 2.2162641485532126

Epoch: 6| Step: 13
Training loss: 1.306905746459961
Validation loss: 2.140005886554718

Epoch: 388| Step: 0
Training loss: 1.213437795639038
Validation loss: 2.1271029313405356

Epoch: 6| Step: 1
Training loss: 1.4835090637207031
Validation loss: 2.086913824081421

Epoch: 6| Step: 2
Training loss: 0.912399172782898
Validation loss: 2.0619014898935952

Epoch: 6| Step: 3
Training loss: 2.194911241531372
Validation loss: 2.0583504835764566

Epoch: 6| Step: 4
Training loss: 1.392026424407959
Validation loss: 2.1239012082417807

Epoch: 6| Step: 5
Training loss: 1.1363742351531982
Validation loss: 2.0955761075019836

Epoch: 6| Step: 6
Training loss: 1.290442943572998
Validation loss: 2.0923209190368652

Epoch: 6| Step: 7
Training loss: 1.544234037399292
Validation loss: 2.1094356377919516

Epoch: 6| Step: 8
Training loss: 1.4427870512008667
Validation loss: 2.070399363835653

Epoch: 6| Step: 9
Training loss: 1.3227587938308716
Validation loss: 2.08001708984375

Epoch: 6| Step: 10
Training loss: 1.2102612257003784
Validation loss: 2.1272571881612143

Epoch: 6| Step: 11
Training loss: 0.8270795345306396
Validation loss: 2.0893914500872293

Epoch: 6| Step: 12
Training loss: 0.8863818049430847
Validation loss: 2.1472858587900796

Epoch: 6| Step: 13
Training loss: 1.874192714691162
Validation loss: 2.1818912823994956

Epoch: 389| Step: 0
Training loss: 1.8211414813995361
Validation loss: 2.202334741751353

Epoch: 6| Step: 1
Training loss: 1.6821885108947754
Validation loss: 2.243530790011088

Epoch: 6| Step: 2
Training loss: 1.6999906301498413
Validation loss: 2.2163520057996116

Epoch: 6| Step: 3
Training loss: 1.0088865756988525
Validation loss: 2.265848616758982

Epoch: 6| Step: 4
Training loss: 1.234755516052246
Validation loss: 2.262954354286194

Epoch: 6| Step: 5
Training loss: 1.8868584632873535
Validation loss: 2.2673062086105347

Epoch: 6| Step: 6
Training loss: 0.8862260580062866
Validation loss: 2.263944407304128

Epoch: 6| Step: 7
Training loss: 2.2206130027770996
Validation loss: 2.2625263333320618

Epoch: 6| Step: 8
Training loss: 1.3562158346176147
Validation loss: 2.2129828135172525

Epoch: 6| Step: 9
Training loss: 1.603139042854309
Validation loss: 2.2191215356191

Epoch: 6| Step: 10
Training loss: 1.2812535762786865
Validation loss: 2.203455626964569

Epoch: 6| Step: 11
Training loss: 1.3117341995239258
Validation loss: 2.2293253342310586

Epoch: 6| Step: 12
Training loss: 0.9265996813774109
Validation loss: 2.248317817846934

Epoch: 6| Step: 13
Training loss: 0.8953560590744019
Validation loss: 2.2201571067174277

Epoch: 390| Step: 0
Training loss: 1.8560266494750977
Validation loss: 2.2564995884895325

Epoch: 6| Step: 1
Training loss: 1.645709753036499
Validation loss: 2.198416074117025

Epoch: 6| Step: 2
Training loss: 0.8678005337715149
Validation loss: 2.2408116261164346

Epoch: 6| Step: 3
Training loss: 1.3177080154418945
Validation loss: 2.2414662837982178

Epoch: 6| Step: 4
Training loss: 1.3520474433898926
Validation loss: 2.2136047085126243

Epoch: 6| Step: 5
Training loss: 1.3619229793548584
Validation loss: 2.194238523642222

Epoch: 6| Step: 6
Training loss: 0.8235922455787659
Validation loss: 2.249565045038859

Epoch: 6| Step: 7
Training loss: 1.3767664432525635
Validation loss: 2.1962916254997253

Epoch: 6| Step: 8
Training loss: 1.0028886795043945
Validation loss: 2.176699459552765

Epoch: 6| Step: 9
Training loss: 1.0227957963943481
Validation loss: 2.172029276688894

Epoch: 6| Step: 10
Training loss: 1.1673476696014404
Validation loss: 2.1636879245440164

Epoch: 6| Step: 11
Training loss: 2.0787298679351807
Validation loss: 2.1978261272112527

Epoch: 6| Step: 12
Training loss: 1.7214447259902954
Validation loss: 2.214123785495758

Epoch: 6| Step: 13
Training loss: 1.593294382095337
Validation loss: 2.1938143173853555

Epoch: 391| Step: 0
Training loss: 1.478607416152954
Validation loss: 2.195436259110769

Epoch: 6| Step: 1
Training loss: 1.6550326347351074
Validation loss: 2.1758395036061606

Epoch: 6| Step: 2
Training loss: 1.2685513496398926
Validation loss: 2.1811286409695945

Epoch: 6| Step: 3
Training loss: 1.166198968887329
Validation loss: 2.1634884675343833

Epoch: 6| Step: 4
Training loss: 1.2826497554779053
Validation loss: 2.1990275581677756

Epoch: 6| Step: 5
Training loss: 1.3391780853271484
Validation loss: 2.1192498207092285

Epoch: 6| Step: 6
Training loss: 1.4119056463241577
Validation loss: 2.1802058617273965

Epoch: 6| Step: 7
Training loss: 1.224064826965332
Validation loss: 2.155348241329193

Epoch: 6| Step: 8
Training loss: 0.9609307050704956
Validation loss: 2.184273143609365

Epoch: 6| Step: 9
Training loss: 1.0336123704910278
Validation loss: 2.1826513608296714

Epoch: 6| Step: 10
Training loss: 1.3860093355178833
Validation loss: 2.152413268884023

Epoch: 6| Step: 11
Training loss: 1.696063756942749
Validation loss: 2.179103970527649

Epoch: 6| Step: 12
Training loss: 1.5444400310516357
Validation loss: 2.1551010608673096

Epoch: 6| Step: 13
Training loss: 1.2218972444534302
Validation loss: 2.1701629360516868

Epoch: 392| Step: 0
Training loss: 1.0417765378952026
Validation loss: 2.1536141633987427

Epoch: 6| Step: 1
Training loss: 1.3416616916656494
Validation loss: 2.204117794831594

Epoch: 6| Step: 2
Training loss: 1.363016128540039
Validation loss: 2.167683800061544

Epoch: 6| Step: 3
Training loss: 1.2157005071640015
Validation loss: 2.2120503981908164

Epoch: 6| Step: 4
Training loss: 1.3377283811569214
Validation loss: 2.218401829401652

Epoch: 6| Step: 5
Training loss: 1.7817497253417969
Validation loss: 2.1933528184890747

Epoch: 6| Step: 6
Training loss: 1.1388359069824219
Validation loss: 2.208292325337728

Epoch: 6| Step: 7
Training loss: 1.6690144538879395
Validation loss: 2.22732412815094

Epoch: 6| Step: 8
Training loss: 1.3292591571807861
Validation loss: 2.209749937057495

Epoch: 6| Step: 9
Training loss: 1.3030458688735962
Validation loss: 2.239117205142975

Epoch: 6| Step: 10
Training loss: 1.4709196090698242
Validation loss: 2.2133654753367105

Epoch: 6| Step: 11
Training loss: 1.1490110158920288
Validation loss: 2.239043951034546

Epoch: 6| Step: 12
Training loss: 1.5108578205108643
Validation loss: 2.28278911113739

Epoch: 6| Step: 13
Training loss: 0.8289221525192261
Validation loss: 2.242896636327108

Epoch: 393| Step: 0
Training loss: 1.9089398384094238
Validation loss: 2.243232170740763

Epoch: 6| Step: 1
Training loss: 1.106757640838623
Validation loss: 2.2585856517155967

Epoch: 6| Step: 2
Training loss: 1.4417692422866821
Validation loss: 2.2104441126187644

Epoch: 6| Step: 3
Training loss: 1.3156496286392212
Validation loss: 2.214191436767578

Epoch: 6| Step: 4
Training loss: 1.3057081699371338
Validation loss: 2.1964399417241416

Epoch: 6| Step: 5
Training loss: 1.3751804828643799
Validation loss: 2.189386308193207

Epoch: 6| Step: 6
Training loss: 0.6921228170394897
Validation loss: 2.155774931112925

Epoch: 6| Step: 7
Training loss: 1.0085675716400146
Validation loss: 2.2034308115641275

Epoch: 6| Step: 8
Training loss: 1.0658265352249146
Validation loss: 2.1753867665926614

Epoch: 6| Step: 9
Training loss: 1.4734735488891602
Validation loss: 2.1921343406041465

Epoch: 6| Step: 10
Training loss: 1.0493415594100952
Validation loss: 2.209380845228831

Epoch: 6| Step: 11
Training loss: 1.1933975219726562
Validation loss: 2.18392821153005

Epoch: 6| Step: 12
Training loss: 2.4967641830444336
Validation loss: 2.153246839841207

Epoch: 6| Step: 13
Training loss: 0.9811892509460449
Validation loss: 2.158736824989319

Epoch: 394| Step: 0
Training loss: 1.363999366760254
Validation loss: 2.106102168560028

Epoch: 6| Step: 1
Training loss: 1.8651071786880493
Validation loss: 2.1318495074907937

Epoch: 6| Step: 2
Training loss: 1.2153143882751465
Validation loss: 2.1349012653032937

Epoch: 6| Step: 3
Training loss: 1.6276943683624268
Validation loss: 2.1659222642580667

Epoch: 6| Step: 4
Training loss: 1.7316049337387085
Validation loss: 2.13720041513443

Epoch: 6| Step: 5
Training loss: 0.648364782333374
Validation loss: 2.1529862880706787

Epoch: 6| Step: 6
Training loss: 0.6407387852668762
Validation loss: 2.2015733321507773

Epoch: 6| Step: 7
Training loss: 0.6018280386924744
Validation loss: 2.1931715408960977

Epoch: 6| Step: 8
Training loss: 1.3752429485321045
Validation loss: 2.1853727102279663

Epoch: 6| Step: 9
Training loss: 1.4353649616241455
Validation loss: 2.2182789047559104

Epoch: 6| Step: 10
Training loss: 1.3810632228851318
Validation loss: 2.203924020131429

Epoch: 6| Step: 11
Training loss: 0.8431212902069092
Validation loss: 2.2316744923591614

Epoch: 6| Step: 12
Training loss: 2.680598735809326
Validation loss: 2.2437988917032876

Epoch: 6| Step: 13
Training loss: 2.0342354774475098
Validation loss: 2.2509336471557617

Epoch: 395| Step: 0
Training loss: 0.6960946321487427
Validation loss: 2.2186575730641684

Epoch: 6| Step: 1
Training loss: 1.2749131917953491
Validation loss: 2.218139866987864

Epoch: 6| Step: 2
Training loss: 1.595544457435608
Validation loss: 2.2034011483192444

Epoch: 6| Step: 3
Training loss: 1.5963293313980103
Validation loss: 2.271093467871348

Epoch: 6| Step: 4
Training loss: 1.4255609512329102
Validation loss: 2.2320558428764343

Epoch: 6| Step: 5
Training loss: 1.597939372062683
Validation loss: 2.216996908187866

Epoch: 6| Step: 6
Training loss: 0.9390788078308105
Validation loss: 2.2349145809809365

Epoch: 6| Step: 7
Training loss: 1.062530755996704
Validation loss: 2.2056636810302734

Epoch: 6| Step: 8
Training loss: 1.0700103044509888
Validation loss: 2.1738493045171103

Epoch: 6| Step: 9
Training loss: 1.2600468397140503
Validation loss: 2.088616967201233

Epoch: 6| Step: 10
Training loss: 1.2734689712524414
Validation loss: 2.1297682921091714

Epoch: 6| Step: 11
Training loss: 1.5397982597351074
Validation loss: 2.1186404824256897

Epoch: 6| Step: 12
Training loss: 1.9990230798721313
Validation loss: 2.0891308387120566

Epoch: 6| Step: 13
Training loss: 2.157954216003418
Validation loss: 2.1066131790479026

Epoch: 396| Step: 0
Training loss: 1.5488836765289307
Validation loss: 2.1101658940315247

Epoch: 6| Step: 1
Training loss: 1.3809574842453003
Validation loss: 2.088545779387156

Epoch: 6| Step: 2
Training loss: 1.6011606454849243
Validation loss: 2.093824823697408

Epoch: 6| Step: 3
Training loss: 1.364526391029358
Validation loss: 2.064290444056193

Epoch: 6| Step: 4
Training loss: 1.7174956798553467
Validation loss: 2.0635563135147095

Epoch: 6| Step: 5
Training loss: 1.776102900505066
Validation loss: 2.074315627415975

Epoch: 6| Step: 6
Training loss: 0.848781943321228
Validation loss: 2.0423647363980613

Epoch: 6| Step: 7
Training loss: 1.4281933307647705
Validation loss: 2.091588338216146

Epoch: 6| Step: 8
Training loss: 1.1387290954589844
Validation loss: 2.092504700024923

Epoch: 6| Step: 9
Training loss: 1.7325539588928223
Validation loss: 2.0937023957570395

Epoch: 6| Step: 10
Training loss: 1.0756771564483643
Validation loss: 2.0283389886220298

Epoch: 6| Step: 11
Training loss: 1.2000292539596558
Validation loss: 2.150328059991201

Epoch: 6| Step: 12
Training loss: 1.439842939376831
Validation loss: 2.0987452467282615

Epoch: 6| Step: 13
Training loss: 0.7388173341751099
Validation loss: 2.0992944637934365

Epoch: 397| Step: 0
Training loss: 1.582877278327942
Validation loss: 2.172188699245453

Epoch: 6| Step: 1
Training loss: 1.1956801414489746
Validation loss: 2.1382015148798623

Epoch: 6| Step: 2
Training loss: 0.7672407627105713
Validation loss: 2.1453577081362405

Epoch: 6| Step: 3
Training loss: 2.5210375785827637
Validation loss: 2.19651593764623

Epoch: 6| Step: 4
Training loss: 1.3394432067871094
Validation loss: 2.17175555229187

Epoch: 6| Step: 5
Training loss: 1.233077049255371
Validation loss: 2.1414389610290527

Epoch: 6| Step: 6
Training loss: 1.2829521894454956
Validation loss: 2.158002575238546

Epoch: 6| Step: 7
Training loss: 1.5741517543792725
Validation loss: 2.1566079457600913

Epoch: 6| Step: 8
Training loss: 1.154689073562622
Validation loss: 2.1403126319249473

Epoch: 6| Step: 9
Training loss: 1.3610119819641113
Validation loss: 2.188167691230774

Epoch: 6| Step: 10
Training loss: 0.7716153860092163
Validation loss: 2.1947224537531533

Epoch: 6| Step: 11
Training loss: 0.9340802431106567
Validation loss: 2.1554974714914956

Epoch: 6| Step: 12
Training loss: 1.159442663192749
Validation loss: 2.1517966787020364

Epoch: 6| Step: 13
Training loss: 1.2812258005142212
Validation loss: 2.184042453765869

Epoch: 398| Step: 0
Training loss: 1.3833956718444824
Validation loss: 2.1991498867670694

Epoch: 6| Step: 1
Training loss: 1.3741281032562256
Validation loss: 2.145895997683207

Epoch: 6| Step: 2
Training loss: 1.2326858043670654
Validation loss: 2.195927619934082

Epoch: 6| Step: 3
Training loss: 1.4305155277252197
Validation loss: 2.1880985498428345

Epoch: 6| Step: 4
Training loss: 0.7769861221313477
Validation loss: 2.2150850693384805

Epoch: 6| Step: 5
Training loss: 1.2708196640014648
Validation loss: 2.1327994068463645

Epoch: 6| Step: 6
Training loss: 1.2913262844085693
Validation loss: 2.1928726633389792

Epoch: 6| Step: 7
Training loss: 1.0508215427398682
Validation loss: 2.1974048018455505

Epoch: 6| Step: 8
Training loss: 1.0500624179840088
Validation loss: 2.1578406492869058

Epoch: 6| Step: 9
Training loss: 1.0998350381851196
Validation loss: 2.1752275824546814

Epoch: 6| Step: 10
Training loss: 1.39395272731781
Validation loss: 2.1631837487220764

Epoch: 6| Step: 11
Training loss: 1.458775281906128
Validation loss: 2.1511159340540567

Epoch: 6| Step: 12
Training loss: 1.4900152683258057
Validation loss: 2.1611256996790567

Epoch: 6| Step: 13
Training loss: 1.4026938676834106
Validation loss: 2.1033586462338767

Epoch: 399| Step: 0
Training loss: 0.6422770023345947
Validation loss: 2.1347060203552246

Epoch: 6| Step: 1
Training loss: 1.2397150993347168
Validation loss: 2.098722835381826

Epoch: 6| Step: 2
Training loss: 1.2087334394454956
Validation loss: 2.09449694554011

Epoch: 6| Step: 3
Training loss: 0.8554283976554871
Validation loss: 2.1816034515698752

Epoch: 6| Step: 4
Training loss: 1.0543875694274902
Validation loss: 2.1412574847539267

Epoch: 6| Step: 5
Training loss: 1.4859216213226318
Validation loss: 2.104825735092163

Epoch: 6| Step: 6
Training loss: 1.696204662322998
Validation loss: 2.175716280937195

Epoch: 6| Step: 7
Training loss: 0.8606196045875549
Validation loss: 2.153746763865153

Epoch: 6| Step: 8
Training loss: 1.2823206186294556
Validation loss: 2.1534380118052163

Epoch: 6| Step: 9
Training loss: 1.2830374240875244
Validation loss: 2.1505907773971558

Epoch: 6| Step: 10
Training loss: 1.4768280982971191
Validation loss: 2.1661450465520224

Epoch: 6| Step: 11
Training loss: 2.327266216278076
Validation loss: 2.135028898715973

Epoch: 6| Step: 12
Training loss: 0.5463367700576782
Validation loss: 2.1281368335088096

Epoch: 6| Step: 13
Training loss: 1.1737351417541504
Validation loss: 2.141160806020101

Epoch: 400| Step: 0
Training loss: 1.1389501094818115
Validation loss: 2.128458340962728

Epoch: 6| Step: 1
Training loss: 0.9395265579223633
Validation loss: 2.159067451953888

Epoch: 6| Step: 2
Training loss: 0.8676608800888062
Validation loss: 2.1744577487309775

Epoch: 6| Step: 3
Training loss: 1.7560968399047852
Validation loss: 2.1479947566986084

Epoch: 6| Step: 4
Training loss: 0.8520867228507996
Validation loss: 2.1888338724772134

Epoch: 6| Step: 5
Training loss: 1.208168387413025
Validation loss: 2.175987799962362

Epoch: 6| Step: 6
Training loss: 1.88111412525177
Validation loss: 2.1706015268961587

Epoch: 6| Step: 7
Training loss: 0.5332759618759155
Validation loss: 2.1541300813357034

Epoch: 6| Step: 8
Training loss: 1.3258877992630005
Validation loss: 2.1452853878339133

Epoch: 6| Step: 9
Training loss: 1.4157845973968506
Validation loss: 2.1509469747543335

Epoch: 6| Step: 10
Training loss: 1.1473939418792725
Validation loss: 2.1423548062642417

Epoch: 6| Step: 11
Training loss: 0.9687215089797974
Validation loss: 2.137560943762461

Epoch: 6| Step: 12
Training loss: 1.7180548906326294
Validation loss: 2.1684420903523765

Epoch: 6| Step: 13
Training loss: 1.532857894897461
Validation loss: 2.137727459271749

Epoch: 401| Step: 0
Training loss: 1.524057388305664
Validation loss: 2.113049308458964

Epoch: 6| Step: 1
Training loss: 1.5750305652618408
Validation loss: 2.120192309220632

Epoch: 6| Step: 2
Training loss: 1.1951336860656738
Validation loss: 2.203253746032715

Epoch: 6| Step: 3
Training loss: 0.8666963577270508
Validation loss: 2.132344424724579

Epoch: 6| Step: 4
Training loss: 1.2223089933395386
Validation loss: 2.152864634990692

Epoch: 6| Step: 5
Training loss: 0.6925780773162842
Validation loss: 2.138448158899943

Epoch: 6| Step: 6
Training loss: 1.0610522031784058
Validation loss: 2.127829452355703

Epoch: 6| Step: 7
Training loss: 0.9167253375053406
Validation loss: 2.111710866292318

Epoch: 6| Step: 8
Training loss: 1.1836044788360596
Validation loss: 2.1667915980021157

Epoch: 6| Step: 9
Training loss: 1.1087031364440918
Validation loss: 2.2043649554252625

Epoch: 6| Step: 10
Training loss: 1.0074399709701538
Validation loss: 2.1544747948646545

Epoch: 6| Step: 11
Training loss: 1.8238474130630493
Validation loss: 2.1240422129631042

Epoch: 6| Step: 12
Training loss: 1.48806631565094
Validation loss: 2.0903006394704184

Epoch: 6| Step: 13
Training loss: 1.4523999691009521
Validation loss: 2.145371198654175

Epoch: 402| Step: 0
Training loss: 1.026646375656128
Validation loss: 2.1167715390523276

Epoch: 6| Step: 1
Training loss: 1.1342594623565674
Validation loss: 2.0749536752700806

Epoch: 6| Step: 2
Training loss: 1.256808876991272
Validation loss: 2.0820226470629373

Epoch: 6| Step: 3
Training loss: 1.6545817852020264
Validation loss: 2.083288570245107

Epoch: 6| Step: 4
Training loss: 1.2143096923828125
Validation loss: 2.0742095708847046

Epoch: 6| Step: 5
Training loss: 0.9083603620529175
Validation loss: 2.1075714429219565

Epoch: 6| Step: 6
Training loss: 1.379176139831543
Validation loss: 2.099841217199961

Epoch: 6| Step: 7
Training loss: 1.474896788597107
Validation loss: 2.1280797719955444

Epoch: 6| Step: 8
Training loss: 2.1077873706817627
Validation loss: 2.1440465847651162

Epoch: 6| Step: 9
Training loss: 0.8855766654014587
Validation loss: 2.137054959932963

Epoch: 6| Step: 10
Training loss: 1.8559937477111816
Validation loss: 2.1733840107917786

Epoch: 6| Step: 11
Training loss: 1.151383399963379
Validation loss: 2.1273024876912436

Epoch: 6| Step: 12
Training loss: 1.1104702949523926
Validation loss: 2.136139710744222

Epoch: 6| Step: 13
Training loss: 1.2036926746368408
Validation loss: 2.211006005605062

Epoch: 403| Step: 0
Training loss: 1.1419594287872314
Validation loss: 2.1383941968282065

Epoch: 6| Step: 1
Training loss: 0.6673138737678528
Validation loss: 2.1311362187067666

Epoch: 6| Step: 2
Training loss: 1.0000451803207397
Validation loss: 2.1927011013031006

Epoch: 6| Step: 3
Training loss: 1.7794439792633057
Validation loss: 2.2100520730018616

Epoch: 6| Step: 4
Training loss: 1.6395976543426514
Validation loss: 2.1821919679641724

Epoch: 6| Step: 5
Training loss: 1.3371566534042358
Validation loss: 2.1776227951049805

Epoch: 6| Step: 6
Training loss: 1.8353954553604126
Validation loss: 2.223985195159912

Epoch: 6| Step: 7
Training loss: 0.9651632905006409
Validation loss: 2.1777859330177307

Epoch: 6| Step: 8
Training loss: 0.7173575758934021
Validation loss: 2.1808579762776694

Epoch: 6| Step: 9
Training loss: 0.7090921401977539
Validation loss: 2.1082749565442405

Epoch: 6| Step: 10
Training loss: 1.1865284442901611
Validation loss: 2.1066628098487854

Epoch: 6| Step: 11
Training loss: 0.7602948546409607
Validation loss: 2.1299747228622437

Epoch: 6| Step: 12
Training loss: 1.1684372425079346
Validation loss: 2.1051994363466897

Epoch: 6| Step: 13
Training loss: 1.938274621963501
Validation loss: 2.10727459192276

Epoch: 404| Step: 0
Training loss: 2.0357000827789307
Validation loss: 2.10057924191157

Epoch: 6| Step: 1
Training loss: 1.0753121376037598
Validation loss: 2.1336944103240967

Epoch: 6| Step: 2
Training loss: 1.5199851989746094
Validation loss: 2.1433663765589395

Epoch: 6| Step: 3
Training loss: 0.8424636721611023
Validation loss: 2.141005019346873

Epoch: 6| Step: 4
Training loss: 0.9727347493171692
Validation loss: 2.1208515564600625

Epoch: 6| Step: 5
Training loss: 1.27232825756073
Validation loss: 2.1712059378623962

Epoch: 6| Step: 6
Training loss: 1.2228400707244873
Validation loss: 2.1392508347829184

Epoch: 6| Step: 7
Training loss: 1.3537508249282837
Validation loss: 2.147534171740214

Epoch: 6| Step: 8
Training loss: 0.5942500829696655
Validation loss: 2.189501384894053

Epoch: 6| Step: 9
Training loss: 0.8494386672973633
Validation loss: 2.1603904565175376

Epoch: 6| Step: 10
Training loss: 1.0024092197418213
Validation loss: 2.1823270320892334

Epoch: 6| Step: 11
Training loss: 1.9736812114715576
Validation loss: 2.1506195267041526

Epoch: 6| Step: 12
Training loss: 1.0583643913269043
Validation loss: 2.143776615460714

Epoch: 6| Step: 13
Training loss: 1.1371302604675293
Validation loss: 2.141371726989746

Epoch: 405| Step: 0
Training loss: 1.190585970878601
Validation loss: 2.1497403979301453

Epoch: 6| Step: 1
Training loss: 1.2594869136810303
Validation loss: 2.1495396494865417

Epoch: 6| Step: 2
Training loss: 0.5547150373458862
Validation loss: 2.1199453274408975

Epoch: 6| Step: 3
Training loss: 1.040967583656311
Validation loss: 2.1491714914639792

Epoch: 6| Step: 4
Training loss: 1.2392768859863281
Validation loss: 2.1073612173398337

Epoch: 6| Step: 5
Training loss: 1.0697656869888306
Validation loss: 2.1460955142974854

Epoch: 6| Step: 6
Training loss: 1.4171123504638672
Validation loss: 2.1278138558069863

Epoch: 6| Step: 7
Training loss: 1.4394675493240356
Validation loss: 2.1434864600499473

Epoch: 6| Step: 8
Training loss: 1.0135540962219238
Validation loss: 2.0966803232828775

Epoch: 6| Step: 9
Training loss: 1.4133563041687012
Validation loss: 2.1036969820658364

Epoch: 6| Step: 10
Training loss: 1.090599536895752
Validation loss: 2.110167920589447

Epoch: 6| Step: 11
Training loss: 1.0261045694351196
Validation loss: 2.123389959335327

Epoch: 6| Step: 12
Training loss: 1.4232122898101807
Validation loss: 2.086251179377238

Epoch: 6| Step: 13
Training loss: 2.089454412460327
Validation loss: 2.1775980393091836

Epoch: 406| Step: 0
Training loss: 0.7261412143707275
Validation loss: 2.09587025642395

Epoch: 6| Step: 1
Training loss: 1.3753578662872314
Validation loss: 2.105206330617269

Epoch: 6| Step: 2
Training loss: 1.2492589950561523
Validation loss: 2.153624673684438

Epoch: 6| Step: 3
Training loss: 1.0330373048782349
Validation loss: 2.139785349369049

Epoch: 6| Step: 4
Training loss: 0.8816679120063782
Validation loss: 2.1508126854896545

Epoch: 6| Step: 5
Training loss: 1.4472383260726929
Validation loss: 2.2006651759147644

Epoch: 6| Step: 6
Training loss: 0.7297822833061218
Validation loss: 2.1456573406855264

Epoch: 6| Step: 7
Training loss: 1.8855351209640503
Validation loss: 2.155450463294983

Epoch: 6| Step: 8
Training loss: 1.2333228588104248
Validation loss: 2.0922815203666687

Epoch: 6| Step: 9
Training loss: 1.259714126586914
Validation loss: 2.145033836364746

Epoch: 6| Step: 10
Training loss: 1.5120412111282349
Validation loss: 2.1210625966389975

Epoch: 6| Step: 11
Training loss: 1.1324021816253662
Validation loss: 2.052606006463369

Epoch: 6| Step: 12
Training loss: 1.5725677013397217
Validation loss: 2.0688637693723044

Epoch: 6| Step: 13
Training loss: 0.9135463237762451
Validation loss: 2.083812197049459

Epoch: 407| Step: 0
Training loss: 1.4568748474121094
Validation loss: 2.0397114555040994

Epoch: 6| Step: 1
Training loss: 1.326287865638733
Validation loss: 2.1035701433817544

Epoch: 6| Step: 2
Training loss: 0.8431201577186584
Validation loss: 2.028945724169413

Epoch: 6| Step: 3
Training loss: 1.654315710067749
Validation loss: 2.1072646379470825

Epoch: 6| Step: 4
Training loss: 0.9910576343536377
Validation loss: 2.10883895556132

Epoch: 6| Step: 5
Training loss: 1.2138757705688477
Validation loss: 2.1339353124300637

Epoch: 6| Step: 6
Training loss: 2.3117663860321045
Validation loss: 2.1257392366727195

Epoch: 6| Step: 7
Training loss: 0.7527619004249573
Validation loss: 2.1499459544817605

Epoch: 6| Step: 8
Training loss: 0.8392831683158875
Validation loss: 2.1402563055356345

Epoch: 6| Step: 9
Training loss: 1.0277690887451172
Validation loss: 2.1020899017651877

Epoch: 6| Step: 10
Training loss: 1.2988007068634033
Validation loss: 2.1053040623664856

Epoch: 6| Step: 11
Training loss: 1.1584463119506836
Validation loss: 2.1223654747009277

Epoch: 6| Step: 12
Training loss: 1.2889704704284668
Validation loss: 2.1677029530207315

Epoch: 6| Step: 13
Training loss: 1.176386833190918
Validation loss: 2.1092182397842407

Epoch: 408| Step: 0
Training loss: 1.6276230812072754
Validation loss: 2.1308388710021973

Epoch: 6| Step: 1
Training loss: 1.2867478132247925
Validation loss: 2.0821215510368347

Epoch: 6| Step: 2
Training loss: 1.5189510583877563
Validation loss: 2.1256774266560874

Epoch: 6| Step: 3
Training loss: 1.1990394592285156
Validation loss: 2.120030085245768

Epoch: 6| Step: 4
Training loss: 1.0318412780761719
Validation loss: 2.1155194640159607

Epoch: 6| Step: 5
Training loss: 1.4657495021820068
Validation loss: 2.15055114030838

Epoch: 6| Step: 6
Training loss: 1.1934213638305664
Validation loss: 2.2065111001332602

Epoch: 6| Step: 7
Training loss: 1.8129351139068604
Validation loss: 2.2165584762891135

Epoch: 6| Step: 8
Training loss: 1.6738115549087524
Validation loss: 2.213952660560608

Epoch: 6| Step: 9
Training loss: 1.5744385719299316
Validation loss: 2.1542921662330627

Epoch: 6| Step: 10
Training loss: 0.8369499444961548
Validation loss: 2.1645445426305137

Epoch: 6| Step: 11
Training loss: 1.3376811742782593
Validation loss: 2.1663304964701333

Epoch: 6| Step: 12
Training loss: 0.9097445607185364
Validation loss: 2.12038387854894

Epoch: 6| Step: 13
Training loss: 0.7381772994995117
Validation loss: 2.1147339940071106

Epoch: 409| Step: 0
Training loss: 1.0406684875488281
Validation loss: 2.10708487033844

Epoch: 6| Step: 1
Training loss: 1.1668245792388916
Validation loss: 2.1086061199506125

Epoch: 6| Step: 2
Training loss: 0.5899959206581116
Validation loss: 2.1370250582695007

Epoch: 6| Step: 3
Training loss: 1.3616098165512085
Validation loss: 2.079435149828593

Epoch: 6| Step: 4
Training loss: 1.4599896669387817
Validation loss: 2.0952237844467163

Epoch: 6| Step: 5
Training loss: 1.3098533153533936
Validation loss: 2.0694984992345176

Epoch: 6| Step: 6
Training loss: 1.7317065000534058
Validation loss: 2.1053662101427713

Epoch: 6| Step: 7
Training loss: 1.265855073928833
Validation loss: 2.1604046622912088

Epoch: 6| Step: 8
Training loss: 1.3182573318481445
Validation loss: 2.1755278507868447

Epoch: 6| Step: 9
Training loss: 1.2157468795776367
Validation loss: 2.1626702149709067

Epoch: 6| Step: 10
Training loss: 1.6509010791778564
Validation loss: 2.164145827293396

Epoch: 6| Step: 11
Training loss: 1.6452900171279907
Validation loss: 2.121327499548594

Epoch: 6| Step: 12
Training loss: 0.8136833310127258
Validation loss: 2.1551941633224487

Epoch: 6| Step: 13
Training loss: 1.0078078508377075
Validation loss: 2.105176111062368

Epoch: 410| Step: 0
Training loss: 1.0520223379135132
Validation loss: 2.098534047603607

Epoch: 6| Step: 1
Training loss: 1.4189049005508423
Validation loss: 2.148207207520803

Epoch: 6| Step: 2
Training loss: 1.218723177909851
Validation loss: 2.14276389280955

Epoch: 6| Step: 3
Training loss: 1.9122873544692993
Validation loss: 2.0949007670084634

Epoch: 6| Step: 4
Training loss: 1.1860119104385376
Validation loss: 2.128695011138916

Epoch: 6| Step: 5
Training loss: 1.3425312042236328
Validation loss: 2.086029529571533

Epoch: 6| Step: 6
Training loss: 0.7879990339279175
Validation loss: 2.11685973405838

Epoch: 6| Step: 7
Training loss: 2.026883125305176
Validation loss: 2.1221266388893127

Epoch: 6| Step: 8
Training loss: 1.1260660886764526
Validation loss: 2.1147656242052713

Epoch: 6| Step: 9
Training loss: 1.373786211013794
Validation loss: 2.1542528669039407

Epoch: 6| Step: 10
Training loss: 1.205122709274292
Validation loss: 2.106600026289622

Epoch: 6| Step: 11
Training loss: 1.133895993232727
Validation loss: 2.101017475128174

Epoch: 6| Step: 12
Training loss: 1.4775395393371582
Validation loss: 2.1048299074172974

Epoch: 6| Step: 13
Training loss: 0.9357216358184814
Validation loss: 2.0499312480290732

Epoch: 411| Step: 0
Training loss: 1.0055056810379028
Validation loss: 2.0771093567212424

Epoch: 6| Step: 1
Training loss: 0.8348390460014343
Validation loss: 2.09441739320755

Epoch: 6| Step: 2
Training loss: 0.8819612860679626
Validation loss: 2.1365256706873574

Epoch: 6| Step: 3
Training loss: 1.2570064067840576
Validation loss: 2.110272546609243

Epoch: 6| Step: 4
Training loss: 1.6841930150985718
Validation loss: 2.1475985447565713

Epoch: 6| Step: 5
Training loss: 0.7723241448402405
Validation loss: 2.139415204524994

Epoch: 6| Step: 6
Training loss: 0.7196894884109497
Validation loss: 2.153804620107015

Epoch: 6| Step: 7
Training loss: 1.3469802141189575
Validation loss: 2.1995433370272317

Epoch: 6| Step: 8
Training loss: 2.663145065307617
Validation loss: 2.1543757915496826

Epoch: 6| Step: 9
Training loss: 1.474991798400879
Validation loss: 2.2003814776738486

Epoch: 6| Step: 10
Training loss: 0.5212543606758118
Validation loss: 2.1823495427767434

Epoch: 6| Step: 11
Training loss: 1.0766727924346924
Validation loss: 2.1921643018722534

Epoch: 6| Step: 12
Training loss: 1.149702787399292
Validation loss: 2.199107746283213

Epoch: 6| Step: 13
Training loss: 1.4817681312561035
Validation loss: 2.1081622838974

Epoch: 412| Step: 0
Training loss: 0.9070826768875122
Validation loss: 2.108656863371531

Epoch: 6| Step: 1
Training loss: 1.3476192951202393
Validation loss: 2.106040279070536

Epoch: 6| Step: 2
Training loss: 1.5659127235412598
Validation loss: 2.1118611296017966

Epoch: 6| Step: 3
Training loss: 1.3094710111618042
Validation loss: 2.069059371948242

Epoch: 6| Step: 4
Training loss: 0.994281530380249
Validation loss: 2.1099701722462973

Epoch: 6| Step: 5
Training loss: 1.1465388536453247
Validation loss: 2.106430411338806

Epoch: 6| Step: 6
Training loss: 1.3098909854888916
Validation loss: 2.054581622282664

Epoch: 6| Step: 7
Training loss: 0.9354679584503174
Validation loss: 2.1102368434270224

Epoch: 6| Step: 8
Training loss: 0.7236568927764893
Validation loss: 2.1359522541364035

Epoch: 6| Step: 9
Training loss: 1.1554776430130005
Validation loss: 2.163884778817495

Epoch: 6| Step: 10
Training loss: 2.06355357170105
Validation loss: 2.1496031284332275

Epoch: 6| Step: 11
Training loss: 1.099529504776001
Validation loss: 2.1509464184443154

Epoch: 6| Step: 12
Training loss: 1.1372411251068115
Validation loss: 2.0966898600260415

Epoch: 6| Step: 13
Training loss: 1.6275826692581177
Validation loss: 2.1120386918385825

Epoch: 413| Step: 0
Training loss: 1.540650725364685
Validation loss: 2.099605361620585

Epoch: 6| Step: 1
Training loss: 1.0044822692871094
Validation loss: 2.14959317445755

Epoch: 6| Step: 2
Training loss: 1.7332667112350464
Validation loss: 2.1788292725880942

Epoch: 6| Step: 3
Training loss: 1.3982632160186768
Validation loss: 2.1543222069740295

Epoch: 6| Step: 4
Training loss: 1.876410722732544
Validation loss: 2.205295463403066

Epoch: 6| Step: 5
Training loss: 1.6497790813446045
Validation loss: 2.1676650047302246

Epoch: 6| Step: 6
Training loss: 0.8046530485153198
Validation loss: 2.127525885899862

Epoch: 6| Step: 7
Training loss: 0.8528629541397095
Validation loss: 2.173490047454834

Epoch: 6| Step: 8
Training loss: 0.8607195615768433
Validation loss: 2.148561437924703

Epoch: 6| Step: 9
Training loss: 2.2189910411834717
Validation loss: 2.1646236379941306

Epoch: 6| Step: 10
Training loss: 1.0524375438690186
Validation loss: 2.169025739034017

Epoch: 6| Step: 11
Training loss: 1.6183784008026123
Validation loss: 2.1899852951367698

Epoch: 6| Step: 12
Training loss: 1.4299092292785645
Validation loss: 2.188252031803131

Epoch: 6| Step: 13
Training loss: 1.4661293029785156
Validation loss: 2.198054333527883

Epoch: 414| Step: 0
Training loss: 0.9629653096199036
Validation loss: 2.16824464003245

Epoch: 6| Step: 1
Training loss: 1.924497365951538
Validation loss: 2.21022101243337

Epoch: 6| Step: 2
Training loss: 1.0423295497894287
Validation loss: 2.2089625199635825

Epoch: 6| Step: 3
Training loss: 0.8788089752197266
Validation loss: 2.1565317114194236

Epoch: 6| Step: 4
Training loss: 0.9097326397895813
Validation loss: 2.1804407636324563

Epoch: 6| Step: 5
Training loss: 0.6512378454208374
Validation loss: 2.241813858350118

Epoch: 6| Step: 6
Training loss: 1.5520799160003662
Validation loss: 2.2332419554392495

Epoch: 6| Step: 7
Training loss: 1.1618236303329468
Validation loss: 2.2205530405044556

Epoch: 6| Step: 8
Training loss: 1.5682964324951172
Validation loss: 2.190545678138733

Epoch: 6| Step: 9
Training loss: 1.5741517543792725
Validation loss: 2.238569895426432

Epoch: 6| Step: 10
Training loss: 1.3588588237762451
Validation loss: 2.182212313016256

Epoch: 6| Step: 11
Training loss: 1.426326036453247
Validation loss: 2.130319972832998

Epoch: 6| Step: 12
Training loss: 1.3339847326278687
Validation loss: 2.230319698651632

Epoch: 6| Step: 13
Training loss: 0.9413802027702332
Validation loss: 2.1349909901618958

Epoch: 415| Step: 0
Training loss: 0.8539113998413086
Validation loss: 2.140280028184255

Epoch: 6| Step: 1
Training loss: 1.610114336013794
Validation loss: 2.168694535891215

Epoch: 6| Step: 2
Training loss: 0.888486385345459
Validation loss: 2.2158592542012534

Epoch: 6| Step: 3
Training loss: 1.5936639308929443
Validation loss: 2.2123170097668967

Epoch: 6| Step: 4
Training loss: 1.001638412475586
Validation loss: 2.192683140436808

Epoch: 6| Step: 5
Training loss: 1.273193359375
Validation loss: 2.175978740056356

Epoch: 6| Step: 6
Training loss: 0.9918639063835144
Validation loss: 2.1906404892603555

Epoch: 6| Step: 7
Training loss: 1.256612777709961
Validation loss: 2.1837646762530007

Epoch: 6| Step: 8
Training loss: 0.6949107646942139
Validation loss: 2.113740921020508

Epoch: 6| Step: 9
Training loss: 1.5079782009124756
Validation loss: 2.1389246384302774

Epoch: 6| Step: 10
Training loss: 1.9086593389511108
Validation loss: 2.1126470367113748

Epoch: 6| Step: 11
Training loss: 0.919641375541687
Validation loss: 2.106277048587799

Epoch: 6| Step: 12
Training loss: 1.2079007625579834
Validation loss: 2.13506027062734

Epoch: 6| Step: 13
Training loss: 1.5121554136276245
Validation loss: 2.1284878253936768

Epoch: 416| Step: 0
Training loss: 0.7005457282066345
Validation loss: 2.0793599088986716

Epoch: 6| Step: 1
Training loss: 0.9153640270233154
Validation loss: 2.1009446382522583

Epoch: 6| Step: 2
Training loss: 0.7798100709915161
Validation loss: 2.1398894985516868

Epoch: 6| Step: 3
Training loss: 0.7294167280197144
Validation loss: 2.156773567199707

Epoch: 6| Step: 4
Training loss: 1.2186167240142822
Validation loss: 2.1644632617632547

Epoch: 6| Step: 5
Training loss: 2.086360454559326
Validation loss: 2.203432003657023

Epoch: 6| Step: 6
Training loss: 2.1430118083953857
Validation loss: 2.1801607608795166

Epoch: 6| Step: 7
Training loss: 1.5810039043426514
Validation loss: 2.192038973172506

Epoch: 6| Step: 8
Training loss: 1.355322003364563
Validation loss: 2.1615628798802695

Epoch: 6| Step: 9
Training loss: 0.46127986907958984
Validation loss: 2.161446531613668

Epoch: 6| Step: 10
Training loss: 1.2887440919876099
Validation loss: 2.138995110988617

Epoch: 6| Step: 11
Training loss: 1.2923357486724854
Validation loss: 2.137416978677114

Epoch: 6| Step: 12
Training loss: 1.495701551437378
Validation loss: 2.1379416386286416

Epoch: 6| Step: 13
Training loss: 1.6913137435913086
Validation loss: 2.1552535692850747

Epoch: 417| Step: 0
Training loss: 1.259534478187561
Validation loss: 2.121600071589152

Epoch: 6| Step: 1
Training loss: 1.9950706958770752
Validation loss: 2.157992700735728

Epoch: 6| Step: 2
Training loss: 1.0148921012878418
Validation loss: 2.1310030023256936

Epoch: 6| Step: 3
Training loss: 1.1807055473327637
Validation loss: 2.1316187977790833

Epoch: 6| Step: 4
Training loss: 1.6702454090118408
Validation loss: 2.101648290952047

Epoch: 6| Step: 5
Training loss: 0.9351075887680054
Validation loss: 2.100783387819926

Epoch: 6| Step: 6
Training loss: 0.7877635955810547
Validation loss: 2.0709253350893655

Epoch: 6| Step: 7
Training loss: 1.5990256071090698
Validation loss: 2.0709670583407083

Epoch: 6| Step: 8
Training loss: 1.4170894622802734
Validation loss: 2.1173587640126548

Epoch: 6| Step: 9
Training loss: 1.0196739435195923
Validation loss: 2.1494231621424356

Epoch: 6| Step: 10
Training loss: 1.145935297012329
Validation loss: 2.0898154775301614

Epoch: 6| Step: 11
Training loss: 0.9263274073600769
Validation loss: 2.078050673007965

Epoch: 6| Step: 12
Training loss: 1.2311915159225464
Validation loss: 2.138386309146881

Epoch: 6| Step: 13
Training loss: 1.1103084087371826
Validation loss: 2.11711452404658

Epoch: 418| Step: 0
Training loss: 1.5814239978790283
Validation loss: 2.156771977742513

Epoch: 6| Step: 1
Training loss: 1.035412073135376
Validation loss: 2.210311770439148

Epoch: 6| Step: 2
Training loss: 1.6277844905853271
Validation loss: 2.1977893114089966

Epoch: 6| Step: 3
Training loss: 1.8818339109420776
Validation loss: 2.16245307524999

Epoch: 6| Step: 4
Training loss: 0.9800002574920654
Validation loss: 2.156531552473704

Epoch: 6| Step: 5
Training loss: 1.0119885206222534
Validation loss: 2.1101144353548684

Epoch: 6| Step: 6
Training loss: 1.0549381971359253
Validation loss: 2.11687308549881

Epoch: 6| Step: 7
Training loss: 0.8303108215332031
Validation loss: 2.104191223780314

Epoch: 6| Step: 8
Training loss: 1.1757574081420898
Validation loss: 2.0927628676096597

Epoch: 6| Step: 9
Training loss: 1.0300198793411255
Validation loss: 2.11920960744222

Epoch: 6| Step: 10
Training loss: 1.152113914489746
Validation loss: 2.1159174839655557

Epoch: 6| Step: 11
Training loss: 1.3579113483428955
Validation loss: 2.1292644739151

Epoch: 6| Step: 12
Training loss: 1.1418826580047607
Validation loss: 2.114892582098643

Epoch: 6| Step: 13
Training loss: 0.8779098987579346
Validation loss: 2.136829435825348

Epoch: 419| Step: 0
Training loss: 1.7944263219833374
Validation loss: 2.1545865138371787

Epoch: 6| Step: 1
Training loss: 1.248389482498169
Validation loss: 2.1738869547843933

Epoch: 6| Step: 2
Training loss: 0.9497140049934387
Validation loss: 2.1628898978233337

Epoch: 6| Step: 3
Training loss: 1.1146180629730225
Validation loss: 2.12215518951416

Epoch: 6| Step: 4
Training loss: 1.042017936706543
Validation loss: 2.161763389905294

Epoch: 6| Step: 5
Training loss: 0.9963313341140747
Validation loss: 2.1650923689206443

Epoch: 6| Step: 6
Training loss: 1.0692778825759888
Validation loss: 2.222530206044515

Epoch: 6| Step: 7
Training loss: 1.7585417032241821
Validation loss: 2.198274771372477

Epoch: 6| Step: 8
Training loss: 1.3820805549621582
Validation loss: 2.253672162691752

Epoch: 6| Step: 9
Training loss: 1.5586204528808594
Validation loss: 2.2396763960520425

Epoch: 6| Step: 10
Training loss: 1.6842939853668213
Validation loss: 2.2394264737764993

Epoch: 6| Step: 11
Training loss: 0.6619220972061157
Validation loss: 2.2613172928492227

Epoch: 6| Step: 12
Training loss: 0.6453539133071899
Validation loss: 2.2201841870943704

Epoch: 6| Step: 13
Training loss: 1.363492488861084
Validation loss: 2.217643916606903

Epoch: 420| Step: 0
Training loss: 1.2972197532653809
Validation loss: 2.1673855980237327

Epoch: 6| Step: 1
Training loss: 1.37739896774292
Validation loss: 2.1940914193789163

Epoch: 6| Step: 2
Training loss: 1.0779272317886353
Validation loss: 2.178485631942749

Epoch: 6| Step: 3
Training loss: 1.7023345232009888
Validation loss: 2.142811437447866

Epoch: 6| Step: 4
Training loss: 1.0849617719650269
Validation loss: 2.059894323348999

Epoch: 6| Step: 5
Training loss: 0.720569372177124
Validation loss: 2.0637790163358054

Epoch: 6| Step: 6
Training loss: 1.1216199398040771
Validation loss: 2.0621359745661416

Epoch: 6| Step: 7
Training loss: 1.083217740058899
Validation loss: 2.101473609606425

Epoch: 6| Step: 8
Training loss: 1.4072387218475342
Validation loss: 2.0565642515818277

Epoch: 6| Step: 9
Training loss: 1.2675817012786865
Validation loss: 2.0774548053741455

Epoch: 6| Step: 10
Training loss: 1.1760492324829102
Validation loss: 2.0407678882280984

Epoch: 6| Step: 11
Training loss: 1.1650800704956055
Validation loss: 2.0672740936279297

Epoch: 6| Step: 12
Training loss: 1.0926809310913086
Validation loss: 2.084053913752238

Epoch: 6| Step: 13
Training loss: 0.8685815930366516
Validation loss: 2.0564792156219482

Epoch: 421| Step: 0
Training loss: 1.6393194198608398
Validation loss: 2.087948819001516

Epoch: 6| Step: 1
Training loss: 1.6867057085037231
Validation loss: 2.1518589854240417

Epoch: 6| Step: 2
Training loss: 1.2452834844589233
Validation loss: 2.146476149559021

Epoch: 6| Step: 3
Training loss: 1.1966904401779175
Validation loss: 2.1662446657816568

Epoch: 6| Step: 4
Training loss: 1.6124093532562256
Validation loss: 2.144612669944763

Epoch: 6| Step: 5
Training loss: 0.7141457200050354
Validation loss: 2.1505184968312583

Epoch: 6| Step: 6
Training loss: 0.6981291174888611
Validation loss: 2.133290966351827

Epoch: 6| Step: 7
Training loss: 0.9728494882583618
Validation loss: 2.161016861597697

Epoch: 6| Step: 8
Training loss: 1.2726497650146484
Validation loss: 2.1306605537732444

Epoch: 6| Step: 9
Training loss: 1.358428955078125
Validation loss: 2.1469647685686746

Epoch: 6| Step: 10
Training loss: 1.1529479026794434
Validation loss: 2.167047838370005

Epoch: 6| Step: 11
Training loss: 1.3245539665222168
Validation loss: 2.1451985041300454

Epoch: 6| Step: 12
Training loss: 1.2363860607147217
Validation loss: 2.199839433034261

Epoch: 6| Step: 13
Training loss: 0.9502068758010864
Validation loss: 2.1625370581944785

Epoch: 422| Step: 0
Training loss: 1.2751798629760742
Validation loss: 2.15448792775472

Epoch: 6| Step: 1
Training loss: 1.311537504196167
Validation loss: 2.1333724657694497

Epoch: 6| Step: 2
Training loss: 1.398378849029541
Validation loss: 2.128946304321289

Epoch: 6| Step: 3
Training loss: 1.3229057788848877
Validation loss: 2.1211405992507935

Epoch: 6| Step: 4
Training loss: 0.5417252779006958
Validation loss: 2.1673503319422402

Epoch: 6| Step: 5
Training loss: 1.4087042808532715
Validation loss: 2.191461662451426

Epoch: 6| Step: 6
Training loss: 1.0051144361495972
Validation loss: 2.1858246127764382

Epoch: 6| Step: 7
Training loss: 1.9993298053741455
Validation loss: 2.2216683427492776

Epoch: 6| Step: 8
Training loss: 0.9769876003265381
Validation loss: 2.224510431289673

Epoch: 6| Step: 9
Training loss: 1.1753337383270264
Validation loss: 2.2091602285703025

Epoch: 6| Step: 10
Training loss: 1.1096699237823486
Validation loss: 2.2638221383094788

Epoch: 6| Step: 11
Training loss: 1.7029446363449097
Validation loss: 2.1854340632756553

Epoch: 6| Step: 12
Training loss: 1.3228663206100464
Validation loss: 2.1915904879570007

Epoch: 6| Step: 13
Training loss: 1.018341302871704
Validation loss: 2.1785064538319907

Epoch: 423| Step: 0
Training loss: 1.3147166967391968
Validation loss: 2.228037476539612

Epoch: 6| Step: 1
Training loss: 1.5541144609451294
Validation loss: 2.2139077385266623

Epoch: 6| Step: 2
Training loss: 1.1674683094024658
Validation loss: 2.181945482889811

Epoch: 6| Step: 3
Training loss: 0.7825051546096802
Validation loss: 2.202545483907064

Epoch: 6| Step: 4
Training loss: 1.915705919265747
Validation loss: 2.1858203411102295

Epoch: 6| Step: 5
Training loss: 1.6384247541427612
Validation loss: 2.2055206894874573

Epoch: 6| Step: 6
Training loss: 0.9207628965377808
Validation loss: 2.1601816018422446

Epoch: 6| Step: 7
Training loss: 0.6935749650001526
Validation loss: 2.1435731649398804

Epoch: 6| Step: 8
Training loss: 0.7313478589057922
Validation loss: 2.1283284028371177

Epoch: 6| Step: 9
Training loss: 1.372619867324829
Validation loss: 2.1334897677103677

Epoch: 6| Step: 10
Training loss: 1.1147791147232056
Validation loss: 2.063138027985891

Epoch: 6| Step: 11
Training loss: 1.2442069053649902
Validation loss: 2.11063152551651

Epoch: 6| Step: 12
Training loss: 1.0697838068008423
Validation loss: 2.0826870799064636

Epoch: 6| Step: 13
Training loss: 1.6477481126785278
Validation loss: 2.08344433705012

Epoch: 424| Step: 0
Training loss: 1.8140079975128174
Validation loss: 2.0854390064875283

Epoch: 6| Step: 1
Training loss: 1.5568853616714478
Validation loss: 2.1042569875717163

Epoch: 6| Step: 2
Training loss: 1.165631651878357
Validation loss: 2.112603227297465

Epoch: 6| Step: 3
Training loss: 0.8704057335853577
Validation loss: 2.1341528495152793

Epoch: 6| Step: 4
Training loss: 0.4317696988582611
Validation loss: 2.152948538462321

Epoch: 6| Step: 5
Training loss: 1.133601188659668
Validation loss: 2.206604997316996

Epoch: 6| Step: 6
Training loss: 0.8397096991539001
Validation loss: 2.1712910334269204

Epoch: 6| Step: 7
Training loss: 1.1590065956115723
Validation loss: 2.2301450967788696

Epoch: 6| Step: 8
Training loss: 1.4071979522705078
Validation loss: 2.2301708261171975

Epoch: 6| Step: 9
Training loss: 1.0744452476501465
Validation loss: 2.2401028076807656

Epoch: 6| Step: 10
Training loss: 0.5800771713256836
Validation loss: 2.255309820175171

Epoch: 6| Step: 11
Training loss: 1.2274540662765503
Validation loss: 2.2157553831736245

Epoch: 6| Step: 12
Training loss: 1.3590385913848877
Validation loss: 2.2632631063461304

Epoch: 6| Step: 13
Training loss: 1.5322482585906982
Validation loss: 2.248627245426178

Epoch: 425| Step: 0
Training loss: 0.8011313676834106
Validation loss: 2.2401528358459473

Epoch: 6| Step: 1
Training loss: 1.4652390480041504
Validation loss: 2.1379684607187905

Epoch: 6| Step: 2
Training loss: 1.5072166919708252
Validation loss: 2.187883973121643

Epoch: 6| Step: 3
Training loss: 0.9803513288497925
Validation loss: 2.202508350213369

Epoch: 6| Step: 4
Training loss: 1.196643590927124
Validation loss: 2.134680926799774

Epoch: 6| Step: 5
Training loss: 0.7784430980682373
Validation loss: 2.173678398132324

Epoch: 6| Step: 6
Training loss: 0.7569692730903625
Validation loss: 2.148124555746714

Epoch: 6| Step: 7
Training loss: 1.5831255912780762
Validation loss: 2.133590340614319

Epoch: 6| Step: 8
Training loss: 1.490126371383667
Validation loss: 2.176562011241913

Epoch: 6| Step: 9
Training loss: 1.1271989345550537
Validation loss: 2.143373270829519

Epoch: 6| Step: 10
Training loss: 1.1421887874603271
Validation loss: 2.1289443572362265

Epoch: 6| Step: 11
Training loss: 1.4364545345306396
Validation loss: 2.1272926529248557

Epoch: 6| Step: 12
Training loss: 0.8551626801490784
Validation loss: 2.0695061882336936

Epoch: 6| Step: 13
Training loss: 1.2819757461547852
Validation loss: 2.11013263463974

Epoch: 426| Step: 0
Training loss: 0.7265130281448364
Validation loss: 2.1343889037768045

Epoch: 6| Step: 1
Training loss: 0.8363660573959351
Validation loss: 2.073274254798889

Epoch: 6| Step: 2
Training loss: 1.7209299802780151
Validation loss: 2.09235413869222

Epoch: 6| Step: 3
Training loss: 1.2142064571380615
Validation loss: 2.078908324241638

Epoch: 6| Step: 4
Training loss: 1.205258846282959
Validation loss: 2.037961562474569

Epoch: 6| Step: 5
Training loss: 0.9933539628982544
Validation loss: 2.1064319610595703

Epoch: 6| Step: 6
Training loss: 0.8106687068939209
Validation loss: 2.125834127267202

Epoch: 6| Step: 7
Training loss: 0.9191632866859436
Validation loss: 2.1384368936220803

Epoch: 6| Step: 8
Training loss: 1.9912240505218506
Validation loss: 2.1096275250116983

Epoch: 6| Step: 9
Training loss: 2.050581932067871
Validation loss: 2.1307080388069153

Epoch: 6| Step: 10
Training loss: 0.5337142944335938
Validation loss: 2.1357460816701255

Epoch: 6| Step: 11
Training loss: 0.8825160264968872
Validation loss: 2.116822083791097

Epoch: 6| Step: 12
Training loss: 0.9476519823074341
Validation loss: 2.055697719256083

Epoch: 6| Step: 13
Training loss: 0.771864652633667
Validation loss: 2.11264568567276

Epoch: 427| Step: 0
Training loss: 1.169995903968811
Validation loss: 2.1522675355275473

Epoch: 6| Step: 1
Training loss: 1.5514731407165527
Validation loss: 2.1675666173299155

Epoch: 6| Step: 2
Training loss: 1.3540592193603516
Validation loss: 2.1580371459325156

Epoch: 6| Step: 3
Training loss: 1.4787967205047607
Validation loss: 2.186044752597809

Epoch: 6| Step: 4
Training loss: 0.75446617603302
Validation loss: 2.1479533116022744

Epoch: 6| Step: 5
Training loss: 1.12416410446167
Validation loss: 2.1685200333595276

Epoch: 6| Step: 6
Training loss: 0.808221697807312
Validation loss: 2.181108295917511

Epoch: 6| Step: 7
Training loss: 1.4351491928100586
Validation loss: 2.1629136006037393

Epoch: 6| Step: 8
Training loss: 0.9455955028533936
Validation loss: 2.1830614805221558

Epoch: 6| Step: 9
Training loss: 1.8020975589752197
Validation loss: 2.247040311495463

Epoch: 6| Step: 10
Training loss: 1.3148105144500732
Validation loss: 2.2129135926564536

Epoch: 6| Step: 11
Training loss: 1.1920310258865356
Validation loss: 2.155396521091461

Epoch: 6| Step: 12
Training loss: 1.297980785369873
Validation loss: 2.118924836317698

Epoch: 6| Step: 13
Training loss: 0.6964302659034729
Validation loss: 2.1206021904945374

Epoch: 428| Step: 0
Training loss: 1.0584585666656494
Validation loss: 2.073765993118286

Epoch: 6| Step: 1
Training loss: 1.687124490737915
Validation loss: 2.1248005429903665

Epoch: 6| Step: 2
Training loss: 1.3783679008483887
Validation loss: 2.132295389970144

Epoch: 6| Step: 3
Training loss: 1.1485776901245117
Validation loss: 2.086701214313507

Epoch: 6| Step: 4
Training loss: 1.6890029907226562
Validation loss: 2.0849576393763223

Epoch: 6| Step: 5
Training loss: 1.0673426389694214
Validation loss: 2.061250885327657

Epoch: 6| Step: 6
Training loss: 1.0950021743774414
Validation loss: 2.0698429544766745

Epoch: 6| Step: 7
Training loss: 1.0671957731246948
Validation loss: 2.081868588924408

Epoch: 6| Step: 8
Training loss: 0.7087376713752747
Validation loss: 2.1128742496172586

Epoch: 6| Step: 9
Training loss: 0.7522525787353516
Validation loss: 2.135561168193817

Epoch: 6| Step: 10
Training loss: 1.6015470027923584
Validation loss: 2.1524876753489175

Epoch: 6| Step: 11
Training loss: 1.2764763832092285
Validation loss: 2.1599515080451965

Epoch: 6| Step: 12
Training loss: 0.7837697267532349
Validation loss: 2.1648389101028442

Epoch: 6| Step: 13
Training loss: 1.179854393005371
Validation loss: 2.1624640226364136

Epoch: 429| Step: 0
Training loss: 0.5226498246192932
Validation loss: 2.2021440863609314

Epoch: 6| Step: 1
Training loss: 1.5855958461761475
Validation loss: 2.189282258351644

Epoch: 6| Step: 2
Training loss: 0.9559515118598938
Validation loss: 2.1746167739232383

Epoch: 6| Step: 3
Training loss: 1.1860431432724
Validation loss: 2.224521517753601

Epoch: 6| Step: 4
Training loss: 1.0167067050933838
Validation loss: 2.167834222316742

Epoch: 6| Step: 5
Training loss: 1.4201726913452148
Validation loss: 2.1284990310668945

Epoch: 6| Step: 6
Training loss: 0.3595343232154846
Validation loss: 2.1796095768610635

Epoch: 6| Step: 7
Training loss: 1.2269814014434814
Validation loss: 2.215050160884857

Epoch: 6| Step: 8
Training loss: 0.7526803612709045
Validation loss: 2.187698264916738

Epoch: 6| Step: 9
Training loss: 1.3448779582977295
Validation loss: 2.1831766168276467

Epoch: 6| Step: 10
Training loss: 2.028749942779541
Validation loss: 2.1046555240948996

Epoch: 6| Step: 11
Training loss: 1.69344961643219
Validation loss: 2.1446850101153054

Epoch: 6| Step: 12
Training loss: 0.9841228723526001
Validation loss: 2.1273717085520425

Epoch: 6| Step: 13
Training loss: 0.8870797157287598
Validation loss: 2.182584603627523

Epoch: 430| Step: 0
Training loss: 0.975255012512207
Validation loss: 2.1630437771479287

Epoch: 6| Step: 1
Training loss: 1.8747501373291016
Validation loss: 2.163286487261454

Epoch: 6| Step: 2
Training loss: 1.4292960166931152
Validation loss: 2.1463066736857095

Epoch: 6| Step: 3
Training loss: 1.0961580276489258
Validation loss: 2.09065705537796

Epoch: 6| Step: 4
Training loss: 1.3861018419265747
Validation loss: 2.1080411672592163

Epoch: 6| Step: 5
Training loss: 1.1417477130889893
Validation loss: 2.1621756752332053

Epoch: 6| Step: 6
Training loss: 0.7323806285858154
Validation loss: 2.231341024239858

Epoch: 6| Step: 7
Training loss: 1.177908182144165
Validation loss: 2.2093846599260965

Epoch: 6| Step: 8
Training loss: 0.5898528099060059
Validation loss: 2.2257134715716043

Epoch: 6| Step: 9
Training loss: 1.235804796218872
Validation loss: 2.243261158466339

Epoch: 6| Step: 10
Training loss: 0.8873789310455322
Validation loss: 2.191306928793589

Epoch: 6| Step: 11
Training loss: 1.7796168327331543
Validation loss: 2.2223512331644693

Epoch: 6| Step: 12
Training loss: 1.4055359363555908
Validation loss: 2.14165989557902

Epoch: 6| Step: 13
Training loss: 1.3286032676696777
Validation loss: 2.1628280679384866

Epoch: 431| Step: 0
Training loss: 1.2859646081924438
Validation loss: 2.0835158626238504

Epoch: 6| Step: 1
Training loss: 1.1080288887023926
Validation loss: 2.1471731861432395

Epoch: 6| Step: 2
Training loss: 1.1695133447647095
Validation loss: 2.147114634513855

Epoch: 6| Step: 3
Training loss: 1.470124363899231
Validation loss: 2.1372206608454385

Epoch: 6| Step: 4
Training loss: 1.1426745653152466
Validation loss: 2.1683821280797324

Epoch: 6| Step: 5
Training loss: 1.247983694076538
Validation loss: 2.1342772444089255

Epoch: 6| Step: 6
Training loss: 1.1843953132629395
Validation loss: 2.102058470249176

Epoch: 6| Step: 7
Training loss: 1.1087840795516968
Validation loss: 2.102551023165385

Epoch: 6| Step: 8
Training loss: 1.1321327686309814
Validation loss: 2.1292282740275064

Epoch: 6| Step: 9
Training loss: 1.2616190910339355
Validation loss: 2.1135454177856445

Epoch: 6| Step: 10
Training loss: 1.451598048210144
Validation loss: 2.090333620707194

Epoch: 6| Step: 11
Training loss: 1.0211763381958008
Validation loss: 2.129088521003723

Epoch: 6| Step: 12
Training loss: 0.8983504772186279
Validation loss: 2.1439969539642334

Epoch: 6| Step: 13
Training loss: 0.9938493967056274
Validation loss: 2.157146155834198

Epoch: 432| Step: 0
Training loss: 1.6345655918121338
Validation loss: 2.202736973762512

Epoch: 6| Step: 1
Training loss: 0.9069862961769104
Validation loss: 2.1687906781832376

Epoch: 6| Step: 2
Training loss: 0.8406683206558228
Validation loss: 2.165856122970581

Epoch: 6| Step: 3
Training loss: 0.9331521987915039
Validation loss: 2.0950080355008445

Epoch: 6| Step: 4
Training loss: 1.216963291168213
Validation loss: 2.097265680631002

Epoch: 6| Step: 5
Training loss: 1.0312449932098389
Validation loss: 2.106863876183828

Epoch: 6| Step: 6
Training loss: 1.704546332359314
Validation loss: 2.12933756907781

Epoch: 6| Step: 7
Training loss: 1.123429536819458
Validation loss: 2.160621245702108

Epoch: 6| Step: 8
Training loss: 1.1706604957580566
Validation loss: 2.1379924615224204

Epoch: 6| Step: 9
Training loss: 0.833442747592926
Validation loss: 2.1441958944002786

Epoch: 6| Step: 10
Training loss: 1.0742839574813843
Validation loss: 2.1310449043909707

Epoch: 6| Step: 11
Training loss: 1.3247119188308716
Validation loss: 2.10935906569163

Epoch: 6| Step: 12
Training loss: 1.4249441623687744
Validation loss: 2.124137024084727

Epoch: 6| Step: 13
Training loss: 0.9741631746292114
Validation loss: 2.105421304702759

Epoch: 433| Step: 0
Training loss: 1.2951817512512207
Validation loss: 2.169187823931376

Epoch: 6| Step: 1
Training loss: 1.0996222496032715
Validation loss: 2.1280948519706726

Epoch: 6| Step: 2
Training loss: 0.7887760400772095
Validation loss: 2.117170035839081

Epoch: 6| Step: 3
Training loss: 1.4716333150863647
Validation loss: 2.1032124757766724

Epoch: 6| Step: 4
Training loss: 0.771152913570404
Validation loss: 2.112678825855255

Epoch: 6| Step: 5
Training loss: 1.6137311458587646
Validation loss: 2.1120330095291138

Epoch: 6| Step: 6
Training loss: 1.1805205345153809
Validation loss: 2.075539251168569

Epoch: 6| Step: 7
Training loss: 0.6776238679885864
Validation loss: 2.0723533630371094

Epoch: 6| Step: 8
Training loss: 1.0266674757003784
Validation loss: 2.107247849305471

Epoch: 6| Step: 9
Training loss: 0.9040607213973999
Validation loss: 2.1115590731302896

Epoch: 6| Step: 10
Training loss: 0.7725380659103394
Validation loss: 2.191870311896006

Epoch: 6| Step: 11
Training loss: 0.6684445142745972
Validation loss: 2.1603776812553406

Epoch: 6| Step: 12
Training loss: 2.1542248725891113
Validation loss: 2.1305778423945108

Epoch: 6| Step: 13
Training loss: 0.6033694744110107
Validation loss: 2.196197251478831

Epoch: 434| Step: 0
Training loss: 0.9175237417221069
Validation loss: 2.192179560661316

Epoch: 6| Step: 1
Training loss: 0.5953311920166016
Validation loss: 2.192513187726339

Epoch: 6| Step: 2
Training loss: 1.0595910549163818
Validation loss: 2.166211704413096

Epoch: 6| Step: 3
Training loss: 1.5370395183563232
Validation loss: 2.1700150767962136

Epoch: 6| Step: 4
Training loss: 0.9217896461486816
Validation loss: 2.142214775085449

Epoch: 6| Step: 5
Training loss: 0.8046530485153198
Validation loss: 2.1484529972076416

Epoch: 6| Step: 6
Training loss: 1.5707614421844482
Validation loss: 2.0903114080429077

Epoch: 6| Step: 7
Training loss: 1.131274938583374
Validation loss: 2.05280739068985

Epoch: 6| Step: 8
Training loss: 1.3570665121078491
Validation loss: 2.0491317907969155

Epoch: 6| Step: 9
Training loss: 0.6175826787948608
Validation loss: 2.0843683083852134

Epoch: 6| Step: 10
Training loss: 1.1017554998397827
Validation loss: 2.0604650378227234

Epoch: 6| Step: 11
Training loss: 1.2306818962097168
Validation loss: 2.1178576946258545

Epoch: 6| Step: 12
Training loss: 1.3245428800582886
Validation loss: 2.0383980870246887

Epoch: 6| Step: 13
Training loss: 1.7009518146514893
Validation loss: 2.0820619662602744

Epoch: 435| Step: 0
Training loss: 0.6675238609313965
Validation loss: 2.0904794732729592

Epoch: 6| Step: 1
Training loss: 0.8473811149597168
Validation loss: 2.097545325756073

Epoch: 6| Step: 2
Training loss: 1.0333937406539917
Validation loss: 2.169404069582621

Epoch: 6| Step: 3
Training loss: 1.5931158065795898
Validation loss: 2.1554213166236877

Epoch: 6| Step: 4
Training loss: 1.0510571002960205
Validation loss: 2.15057102839152

Epoch: 6| Step: 5
Training loss: 1.4078024625778198
Validation loss: 2.1558759609858194

Epoch: 6| Step: 6
Training loss: 1.1548608541488647
Validation loss: 2.1685954928398132

Epoch: 6| Step: 7
Training loss: 1.0976545810699463
Validation loss: 2.1343422134717307

Epoch: 6| Step: 8
Training loss: 1.3627450466156006
Validation loss: 2.164324859778086

Epoch: 6| Step: 9
Training loss: 1.358271837234497
Validation loss: 2.09576678276062

Epoch: 6| Step: 10
Training loss: 1.5151841640472412
Validation loss: 2.074540833632151

Epoch: 6| Step: 11
Training loss: 0.8891209363937378
Validation loss: 2.055134395758311

Epoch: 6| Step: 12
Training loss: 1.0166395902633667
Validation loss: 2.166039605935415

Epoch: 6| Step: 13
Training loss: 1.8637855052947998
Validation loss: 2.1571445862452188

Epoch: 436| Step: 0
Training loss: 1.1184887886047363
Validation loss: 2.146637221177419

Epoch: 6| Step: 1
Training loss: 1.611835241317749
Validation loss: 2.1829395294189453

Epoch: 6| Step: 2
Training loss: 1.1081006526947021
Validation loss: 2.195245901743571

Epoch: 6| Step: 3
Training loss: 1.03203284740448
Validation loss: 2.2092824379603067

Epoch: 6| Step: 4
Training loss: 1.3664276599884033
Validation loss: 2.1586451729138694

Epoch: 6| Step: 5
Training loss: 0.9175006151199341
Validation loss: 2.2097384333610535

Epoch: 6| Step: 6
Training loss: 1.5228749513626099
Validation loss: 2.22484161456426

Epoch: 6| Step: 7
Training loss: 1.546825885772705
Validation loss: 2.189405600229899

Epoch: 6| Step: 8
Training loss: 1.4003409147262573
Validation loss: 2.2115036249160767

Epoch: 6| Step: 9
Training loss: 0.814711332321167
Validation loss: 2.188837230205536

Epoch: 6| Step: 10
Training loss: 0.660156786441803
Validation loss: 2.1415031949679055

Epoch: 6| Step: 11
Training loss: 0.5822890996932983
Validation loss: 2.130912443002065

Epoch: 6| Step: 12
Training loss: 1.0607045888900757
Validation loss: 2.1010966499646506

Epoch: 6| Step: 13
Training loss: 2.1727747917175293
Validation loss: 2.1327699025472007

Epoch: 437| Step: 0
Training loss: 1.818709135055542
Validation loss: 2.0672972400983176

Epoch: 6| Step: 1
Training loss: 1.0313857793807983
Validation loss: 2.0688111186027527

Epoch: 6| Step: 2
Training loss: 1.4429194927215576
Validation loss: 2.0331888794898987

Epoch: 6| Step: 3
Training loss: 0.9387974739074707
Validation loss: 2.059431811173757

Epoch: 6| Step: 4
Training loss: 0.9227676391601562
Validation loss: 2.059051831563314

Epoch: 6| Step: 5
Training loss: 1.3052096366882324
Validation loss: 2.045447289943695

Epoch: 6| Step: 6
Training loss: 0.8355951309204102
Validation loss: 2.0732809702555337

Epoch: 6| Step: 7
Training loss: 1.17720365524292
Validation loss: 2.0509920716285706

Epoch: 6| Step: 8
Training loss: 1.6813933849334717
Validation loss: 2.10274608929952

Epoch: 6| Step: 9
Training loss: 0.714290976524353
Validation loss: 2.165085713068644

Epoch: 6| Step: 10
Training loss: 0.5373902916908264
Validation loss: 2.1636685331662497

Epoch: 6| Step: 11
Training loss: 1.448431372642517
Validation loss: 2.1988728642463684

Epoch: 6| Step: 12
Training loss: 0.5973533391952515
Validation loss: 2.1606792410214744

Epoch: 6| Step: 13
Training loss: 1.3476572036743164
Validation loss: 2.1815462907155356

Epoch: 438| Step: 0
Training loss: 0.8791483640670776
Validation loss: 2.130584259827932

Epoch: 6| Step: 1
Training loss: 1.4379706382751465
Validation loss: 2.1793681184450784

Epoch: 6| Step: 2
Training loss: 0.7636184692382812
Validation loss: 2.072089731693268

Epoch: 6| Step: 3
Training loss: 1.123009204864502
Validation loss: 2.1547067761421204

Epoch: 6| Step: 4
Training loss: 0.850101113319397
Validation loss: 2.152233282725016

Epoch: 6| Step: 5
Training loss: 0.8784744739532471
Validation loss: 2.136431038379669

Epoch: 6| Step: 6
Training loss: 1.2239346504211426
Validation loss: 2.087833801905314

Epoch: 6| Step: 7
Training loss: 0.8518263697624207
Validation loss: 2.1182796557744346

Epoch: 6| Step: 8
Training loss: 1.0330201387405396
Validation loss: 2.0887792905171714

Epoch: 6| Step: 9
Training loss: 1.0142797231674194
Validation loss: 2.112086375554403

Epoch: 6| Step: 10
Training loss: 1.593166708946228
Validation loss: 2.128636042277018

Epoch: 6| Step: 11
Training loss: 1.024481177330017
Validation loss: 2.108736236890157

Epoch: 6| Step: 12
Training loss: 1.2597898244857788
Validation loss: 2.1477763454119363

Epoch: 6| Step: 13
Training loss: 1.3254694938659668
Validation loss: 2.116778830687205

Epoch: 439| Step: 0
Training loss: 1.2219808101654053
Validation loss: 2.137851675351461

Epoch: 6| Step: 1
Training loss: 1.2437459230422974
Validation loss: 2.128228465716044

Epoch: 6| Step: 2
Training loss: 1.4844017028808594
Validation loss: 2.178763747215271

Epoch: 6| Step: 3
Training loss: 0.5572420358657837
Validation loss: 2.1804987589518228

Epoch: 6| Step: 4
Training loss: 1.0502105951309204
Validation loss: 2.154264668623606

Epoch: 6| Step: 5
Training loss: 0.875471830368042
Validation loss: 2.132840851942698

Epoch: 6| Step: 6
Training loss: 0.816260576248169
Validation loss: 2.136008381843567

Epoch: 6| Step: 7
Training loss: 1.0256757736206055
Validation loss: 2.174506425857544

Epoch: 6| Step: 8
Training loss: 1.315291404724121
Validation loss: 2.158644199371338

Epoch: 6| Step: 9
Training loss: 0.7985398769378662
Validation loss: 2.0974463621775308

Epoch: 6| Step: 10
Training loss: 1.1819158792495728
Validation loss: 2.1219847202301025

Epoch: 6| Step: 11
Training loss: 1.1433472633361816
Validation loss: 2.124889294306437

Epoch: 6| Step: 12
Training loss: 1.205315113067627
Validation loss: 2.0737696488698325

Epoch: 6| Step: 13
Training loss: 1.0256483554840088
Validation loss: 2.1058300137519836

Epoch: 440| Step: 0
Training loss: 1.3890955448150635
Validation loss: 2.173869808514913

Epoch: 6| Step: 1
Training loss: 1.4777953624725342
Validation loss: 2.2013813058535256

Epoch: 6| Step: 2
Training loss: 0.8570827841758728
Validation loss: 2.1650556921958923

Epoch: 6| Step: 3
Training loss: 1.2445859909057617
Validation loss: 2.175819913546244

Epoch: 6| Step: 4
Training loss: 1.2554364204406738
Validation loss: 2.118819534778595

Epoch: 6| Step: 5
Training loss: 0.447299063205719
Validation loss: 2.13574872414271

Epoch: 6| Step: 6
Training loss: 0.842553973197937
Validation loss: 2.152181923389435

Epoch: 6| Step: 7
Training loss: 1.7526755332946777
Validation loss: 2.178334951400757

Epoch: 6| Step: 8
Training loss: 1.3003571033477783
Validation loss: 2.1591761310895285

Epoch: 6| Step: 9
Training loss: 0.7398626804351807
Validation loss: 2.1076746384302774

Epoch: 6| Step: 10
Training loss: 1.0999127626419067
Validation loss: 2.129219174385071

Epoch: 6| Step: 11
Training loss: 1.2787953615188599
Validation loss: 2.135166049003601

Epoch: 6| Step: 12
Training loss: 1.2214889526367188
Validation loss: 2.095421234766642

Epoch: 6| Step: 13
Training loss: 0.7067791223526001
Validation loss: 2.1414791345596313

Epoch: 441| Step: 0
Training loss: 0.6399242877960205
Validation loss: 2.141463498274485

Epoch: 6| Step: 1
Training loss: 1.4754772186279297
Validation loss: 2.114406406879425

Epoch: 6| Step: 2
Training loss: 0.7712472677230835
Validation loss: 2.1395684679349265

Epoch: 6| Step: 3
Training loss: 1.5040168762207031
Validation loss: 2.1616618235905967

Epoch: 6| Step: 4
Training loss: 1.1117429733276367
Validation loss: 2.1108410954475403

Epoch: 6| Step: 5
Training loss: 1.4129127264022827
Validation loss: 2.111564894517263

Epoch: 6| Step: 6
Training loss: 0.6831334233283997
Validation loss: 2.1503127415974936

Epoch: 6| Step: 7
Training loss: 1.4165481328964233
Validation loss: 2.0659521420796714

Epoch: 6| Step: 8
Training loss: 1.0793328285217285
Validation loss: 2.0747817556063333

Epoch: 6| Step: 9
Training loss: 1.3546550273895264
Validation loss: 2.1380438208580017

Epoch: 6| Step: 10
Training loss: 0.87615966796875
Validation loss: 2.125813881556193

Epoch: 6| Step: 11
Training loss: 1.280929684638977
Validation loss: 2.1102482080459595

Epoch: 6| Step: 12
Training loss: 1.0833377838134766
Validation loss: 2.1195615331331887

Epoch: 6| Step: 13
Training loss: 1.031503677368164
Validation loss: 2.066415707270304

Epoch: 442| Step: 0
Training loss: 0.8978040218353271
Validation loss: 2.046649694442749

Epoch: 6| Step: 1
Training loss: 1.2756047248840332
Validation loss: 2.1003348429997764

Epoch: 6| Step: 2
Training loss: 1.1093403100967407
Validation loss: 2.1087443232536316

Epoch: 6| Step: 3
Training loss: 1.4697346687316895
Validation loss: 2.1445091366767883

Epoch: 6| Step: 4
Training loss: 0.5289762020111084
Validation loss: 2.1506678064664206

Epoch: 6| Step: 5
Training loss: 1.206836462020874
Validation loss: 2.191997488339742

Epoch: 6| Step: 6
Training loss: 1.2687116861343384
Validation loss: 2.221908450126648

Epoch: 6| Step: 7
Training loss: 1.2211394309997559
Validation loss: 2.181938350200653

Epoch: 6| Step: 8
Training loss: 1.161428451538086
Validation loss: 2.1193856994311013

Epoch: 6| Step: 9
Training loss: 0.9406038522720337
Validation loss: 2.1660590171813965

Epoch: 6| Step: 10
Training loss: 0.9254404306411743
Validation loss: 2.1438512404759726

Epoch: 6| Step: 11
Training loss: 1.0307155847549438
Validation loss: 2.118653416633606

Epoch: 6| Step: 12
Training loss: 1.5760600566864014
Validation loss: 2.1137415170669556

Epoch: 6| Step: 13
Training loss: 1.0348455905914307
Validation loss: 2.1578909158706665

Epoch: 443| Step: 0
Training loss: 0.7269529104232788
Validation loss: 2.143776059150696

Epoch: 6| Step: 1
Training loss: 0.9472819566726685
Validation loss: 2.0784178574879966

Epoch: 6| Step: 2
Training loss: 1.3302617073059082
Validation loss: 2.0811056892077127

Epoch: 6| Step: 3
Training loss: 0.7818218469619751
Validation loss: 2.1247541507085166

Epoch: 6| Step: 4
Training loss: 1.4808517694473267
Validation loss: 2.116051137447357

Epoch: 6| Step: 5
Training loss: 0.6050068736076355
Validation loss: 2.10648113489151

Epoch: 6| Step: 6
Training loss: 1.6503992080688477
Validation loss: 2.1813933650652566

Epoch: 6| Step: 7
Training loss: 0.9988906383514404
Validation loss: 2.1503199140230813

Epoch: 6| Step: 8
Training loss: 1.6581629514694214
Validation loss: 2.107193191846212

Epoch: 6| Step: 9
Training loss: 1.6397770643234253
Validation loss: 2.1367260416348777

Epoch: 6| Step: 10
Training loss: 0.7905268669128418
Validation loss: 2.1038970152537027

Epoch: 6| Step: 11
Training loss: 1.008455514907837
Validation loss: 2.117935041586558

Epoch: 6| Step: 12
Training loss: 0.537854015827179
Validation loss: 2.1199801762898765

Epoch: 6| Step: 13
Training loss: 1.0178616046905518
Validation loss: 2.1149500012397766

Epoch: 444| Step: 0
Training loss: 1.1250050067901611
Validation loss: 2.1177467505137124

Epoch: 6| Step: 1
Training loss: 0.6692885160446167
Validation loss: 2.1316282947858176

Epoch: 6| Step: 2
Training loss: 1.120505452156067
Validation loss: 2.084570030371348

Epoch: 6| Step: 3
Training loss: 0.8093984127044678
Validation loss: 2.108801484107971

Epoch: 6| Step: 4
Training loss: 0.9523752927780151
Validation loss: 2.1385725935300193

Epoch: 6| Step: 5
Training loss: 0.852156937122345
Validation loss: 2.133146643638611

Epoch: 6| Step: 6
Training loss: 1.6747459173202515
Validation loss: 2.121457556883494

Epoch: 6| Step: 7
Training loss: 1.4760335683822632
Validation loss: 2.162520190080007

Epoch: 6| Step: 8
Training loss: 0.9036720991134644
Validation loss: 2.154986341794332

Epoch: 6| Step: 9
Training loss: 0.7972486019134521
Validation loss: 2.1304150223731995

Epoch: 6| Step: 10
Training loss: 1.6373379230499268
Validation loss: 2.1423879265785217

Epoch: 6| Step: 11
Training loss: 0.7574930191040039
Validation loss: 2.1496647198994956

Epoch: 6| Step: 12
Training loss: 0.934640645980835
Validation loss: 2.1387473742167153

Epoch: 6| Step: 13
Training loss: 1.107238531112671
Validation loss: 2.119782865047455

Epoch: 445| Step: 0
Training loss: 1.2159762382507324
Validation loss: 2.1227468450864158

Epoch: 6| Step: 1
Training loss: 0.5209792256355286
Validation loss: 2.154490311940511

Epoch: 6| Step: 2
Training loss: 1.2208812236785889
Validation loss: 2.162974019845327

Epoch: 6| Step: 3
Training loss: 1.001659631729126
Validation loss: 2.1020485560099282

Epoch: 6| Step: 4
Training loss: 0.9550203084945679
Validation loss: 2.058414101600647

Epoch: 6| Step: 5
Training loss: 1.0679819583892822
Validation loss: 2.1282787720362344

Epoch: 6| Step: 6
Training loss: 1.4202375411987305
Validation loss: 2.123741030693054

Epoch: 6| Step: 7
Training loss: 1.4053449630737305
Validation loss: 2.0940351088841758

Epoch: 6| Step: 8
Training loss: 1.3710747957229614
Validation loss: 2.1201209227244058

Epoch: 6| Step: 9
Training loss: 0.8423311710357666
Validation loss: 2.0979721943537393

Epoch: 6| Step: 10
Training loss: 1.2368892431259155
Validation loss: 2.079729696114858

Epoch: 6| Step: 11
Training loss: 0.5578367710113525
Validation loss: 2.0890814463297525

Epoch: 6| Step: 12
Training loss: 0.8127436637878418
Validation loss: 2.093153635660807

Epoch: 6| Step: 13
Training loss: 0.7042611241340637
Validation loss: 2.118351479371389

Epoch: 446| Step: 0
Training loss: 0.8572089076042175
Validation loss: 2.08126300573349

Epoch: 6| Step: 1
Training loss: 1.0833312273025513
Validation loss: 2.107162872950236

Epoch: 6| Step: 2
Training loss: 0.8131780624389648
Validation loss: 2.1283591190973916

Epoch: 6| Step: 3
Training loss: 1.133933663368225
Validation loss: 2.1390695571899414

Epoch: 6| Step: 4
Training loss: 0.7417051792144775
Validation loss: 2.097290317217509

Epoch: 6| Step: 5
Training loss: 1.3349061012268066
Validation loss: 2.097521126270294

Epoch: 6| Step: 6
Training loss: 1.3232383728027344
Validation loss: 2.110800623893738

Epoch: 6| Step: 7
Training loss: 0.6302320957183838
Validation loss: 2.0874279538790383

Epoch: 6| Step: 8
Training loss: 1.3501029014587402
Validation loss: 2.0659424463907876

Epoch: 6| Step: 9
Training loss: 1.4764184951782227
Validation loss: 2.08051860332489

Epoch: 6| Step: 10
Training loss: 0.817672848701477
Validation loss: 2.090226113796234

Epoch: 6| Step: 11
Training loss: 0.7578715085983276
Validation loss: 2.1314032673835754

Epoch: 6| Step: 12
Training loss: 0.9315740466117859
Validation loss: 2.0728095173835754

Epoch: 6| Step: 13
Training loss: 1.5383220911026
Validation loss: 2.0667259097099304

Epoch: 447| Step: 0
Training loss: 0.6973785758018494
Validation loss: 2.0510806242624917

Epoch: 6| Step: 1
Training loss: 0.7936311960220337
Validation loss: 2.081857363382975

Epoch: 6| Step: 2
Training loss: 0.8832837343215942
Validation loss: 2.1352195541063943

Epoch: 6| Step: 3
Training loss: 0.9345036149024963
Validation loss: 2.117017924785614

Epoch: 6| Step: 4
Training loss: 1.1093201637268066
Validation loss: 2.0648438533147178

Epoch: 6| Step: 5
Training loss: 0.5736546516418457
Validation loss: 2.101301431655884

Epoch: 6| Step: 6
Training loss: 1.1401556730270386
Validation loss: 2.118050138155619

Epoch: 6| Step: 7
Training loss: 0.9077461957931519
Validation loss: 2.0994353890419006

Epoch: 6| Step: 8
Training loss: 1.184927225112915
Validation loss: 2.0973023970921836

Epoch: 6| Step: 9
Training loss: 1.2280325889587402
Validation loss: 2.0770745873451233

Epoch: 6| Step: 10
Training loss: 1.5081839561462402
Validation loss: 2.0939878821372986

Epoch: 6| Step: 11
Training loss: 1.3859919309616089
Validation loss: 2.161724408467611

Epoch: 6| Step: 12
Training loss: 1.3847380876541138
Validation loss: 2.1401840249697366

Epoch: 6| Step: 13
Training loss: 0.9199101328849792
Validation loss: 2.1372753977775574

Epoch: 448| Step: 0
Training loss: 1.1462244987487793
Validation loss: 2.1575785875320435

Epoch: 6| Step: 1
Training loss: 0.8469118475914001
Validation loss: 2.1646659771601358

Epoch: 6| Step: 2
Training loss: 1.286084532737732
Validation loss: 2.1656505266825357

Epoch: 6| Step: 3
Training loss: 1.3781362771987915
Validation loss: 2.135950287183126

Epoch: 6| Step: 4
Training loss: 1.102248191833496
Validation loss: 2.175953527291616

Epoch: 6| Step: 5
Training loss: 0.6561559438705444
Validation loss: 2.129829148451487

Epoch: 6| Step: 6
Training loss: 1.3442472219467163
Validation loss: 2.0832466880480447

Epoch: 6| Step: 7
Training loss: 0.8298507332801819
Validation loss: 2.120768447717031

Epoch: 6| Step: 8
Training loss: 0.6848205924034119
Validation loss: 2.07683527469635

Epoch: 6| Step: 9
Training loss: 1.2190667390823364
Validation loss: 2.146555999914805

Epoch: 6| Step: 10
Training loss: 1.0255882740020752
Validation loss: 2.14436674118042

Epoch: 6| Step: 11
Training loss: 1.0703914165496826
Validation loss: 2.137669841448466

Epoch: 6| Step: 12
Training loss: 1.0502700805664062
Validation loss: 2.1574310660362244

Epoch: 6| Step: 13
Training loss: 0.9565913081169128
Validation loss: 2.122750163078308

Epoch: 449| Step: 0
Training loss: 1.05716073513031
Validation loss: 2.134696662425995

Epoch: 6| Step: 1
Training loss: 0.996208667755127
Validation loss: 2.1259336272875466

Epoch: 6| Step: 2
Training loss: 1.399163842201233
Validation loss: 2.1374955972035727

Epoch: 6| Step: 3
Training loss: 0.7765923142433167
Validation loss: 2.1400606433550515

Epoch: 6| Step: 4
Training loss: 1.103105068206787
Validation loss: 2.0958593487739563

Epoch: 6| Step: 5
Training loss: 0.5178400278091431
Validation loss: 2.159701406955719

Epoch: 6| Step: 6
Training loss: 0.730536937713623
Validation loss: 2.1095402439435325

Epoch: 6| Step: 7
Training loss: 1.2364627122879028
Validation loss: 2.119206666946411

Epoch: 6| Step: 8
Training loss: 1.2004960775375366
Validation loss: 2.1073357264200845

Epoch: 6| Step: 9
Training loss: 1.47654390335083
Validation loss: 2.0755241314570108

Epoch: 6| Step: 10
Training loss: 0.9434618353843689
Validation loss: 2.0395984649658203

Epoch: 6| Step: 11
Training loss: 1.34017014503479
Validation loss: 2.089100440343221

Epoch: 6| Step: 12
Training loss: 0.8308387994766235
Validation loss: 2.0846994320551553

Epoch: 6| Step: 13
Training loss: 1.1586560010910034
Validation loss: 2.084555228551229

Epoch: 450| Step: 0
Training loss: 0.906650722026825
Validation loss: 2.1359147826830545

Epoch: 6| Step: 1
Training loss: 0.7412718534469604
Validation loss: 2.0762560764948526

Epoch: 6| Step: 2
Training loss: 1.2539764642715454
Validation loss: 2.0959795912106833

Epoch: 6| Step: 3
Training loss: 0.6559466123580933
Validation loss: 2.086694876352946

Epoch: 6| Step: 4
Training loss: 0.5926351547241211
Validation loss: 2.060032069683075

Epoch: 6| Step: 5
Training loss: 0.5194781422615051
Validation loss: 2.0747629006703696

Epoch: 6| Step: 6
Training loss: 1.4374679327011108
Validation loss: 2.1291154424349465

Epoch: 6| Step: 7
Training loss: 1.3313682079315186
Validation loss: 2.126273969809214

Epoch: 6| Step: 8
Training loss: 0.6317204833030701
Validation loss: 2.0803462664286294

Epoch: 6| Step: 9
Training loss: 1.634637713432312
Validation loss: 2.081658581892649

Epoch: 6| Step: 10
Training loss: 1.3051422834396362
Validation loss: 2.0816975831985474

Epoch: 6| Step: 11
Training loss: 1.0731451511383057
Validation loss: 2.0655260483423867

Epoch: 6| Step: 12
Training loss: 1.1253211498260498
Validation loss: 2.10339625676473

Epoch: 6| Step: 13
Training loss: 1.7172749042510986
Validation loss: 2.0899842381477356

Testing loss: 1.826681768293861
