Epoch: 1| Step: 0
Training loss: 6.766110444658468
Validation loss: 5.940241679253178

Epoch: 5| Step: 1
Training loss: 5.292437740026392
Validation loss: 5.938658156292651

Epoch: 5| Step: 2
Training loss: 6.225479855101093
Validation loss: 5.937107842863043

Epoch: 5| Step: 3
Training loss: 5.962525962277236
Validation loss: 5.9356729875434775

Epoch: 5| Step: 4
Training loss: 5.627785565160744
Validation loss: 5.934295981070073

Epoch: 5| Step: 5
Training loss: 6.629257561495887
Validation loss: 5.932931487623527

Epoch: 5| Step: 6
Training loss: 5.256706676988038
Validation loss: 5.931689809311198

Epoch: 5| Step: 7
Training loss: 6.228962702479198
Validation loss: 5.9303650332819675

Epoch: 5| Step: 8
Training loss: 6.1535781251785355
Validation loss: 5.928980112078587

Epoch: 5| Step: 9
Training loss: 6.424785613405529
Validation loss: 5.927645687338507

Epoch: 5| Step: 10
Training loss: 5.665886021117692
Validation loss: 5.926104240692836

Epoch: 5| Step: 11
Training loss: 6.526204327633742
Validation loss: 5.924711858071316

Epoch: 2| Step: 0
Training loss: 5.773167584501617
Validation loss: 5.923145174745718

Epoch: 5| Step: 1
Training loss: 5.404297580863705
Validation loss: 5.921608455030777

Epoch: 5| Step: 2
Training loss: 6.348744498061026
Validation loss: 5.919982178205865

Epoch: 5| Step: 3
Training loss: 6.180991709127329
Validation loss: 5.918257682973528

Epoch: 5| Step: 4
Training loss: 6.0657594708135
Validation loss: 5.916475409340243

Epoch: 5| Step: 5
Training loss: 6.916924284155088
Validation loss: 5.91468414708029

Epoch: 5| Step: 6
Training loss: 5.308441766243245
Validation loss: 5.912667362298831

Epoch: 5| Step: 7
Training loss: 6.122030355712844
Validation loss: 5.910719699058639

Epoch: 5| Step: 8
Training loss: 5.97070631951174
Validation loss: 5.908555302487909

Epoch: 5| Step: 9
Training loss: 6.732443689676726
Validation loss: 5.906262264878121

Epoch: 5| Step: 10
Training loss: 5.411397434904068
Validation loss: 5.903955239185296

Epoch: 5| Step: 11
Training loss: 5.3299648654488285
Validation loss: 5.901615726553104

Epoch: 3| Step: 0
Training loss: 6.1201367436509395
Validation loss: 5.898992469397377

Epoch: 5| Step: 1
Training loss: 6.677449026423809
Validation loss: 5.896426944931038

Epoch: 5| Step: 2
Training loss: 6.357033038224063
Validation loss: 5.893575467397259

Epoch: 5| Step: 3
Training loss: 5.535095257581214
Validation loss: 5.890741969396742

Epoch: 5| Step: 4
Training loss: 5.2164381925785515
Validation loss: 5.887687470082927

Epoch: 5| Step: 5
Training loss: 5.781716157832061
Validation loss: 5.884705987293228

Epoch: 5| Step: 6
Training loss: 5.922013817118843
Validation loss: 5.881229635183796

Epoch: 5| Step: 7
Training loss: 6.345603634473228
Validation loss: 5.878006889350473

Epoch: 5| Step: 8
Training loss: 5.639443228815259
Validation loss: 5.87445992496709

Epoch: 5| Step: 9
Training loss: 6.035247900800853
Validation loss: 5.870724529163291

Epoch: 5| Step: 10
Training loss: 6.212883257029583
Validation loss: 5.8666119384199735

Epoch: 5| Step: 11
Training loss: 6.04782026132805
Validation loss: 5.862722608709019

Epoch: 4| Step: 0
Training loss: 6.112188525542822
Validation loss: 5.8583490312708735

Epoch: 5| Step: 1
Training loss: 6.205209684433171
Validation loss: 5.853930535311275

Epoch: 5| Step: 2
Training loss: 5.650221842233726
Validation loss: 5.849162181133864

Epoch: 5| Step: 3
Training loss: 6.475984075874226
Validation loss: 5.844462556966041

Epoch: 5| Step: 4
Training loss: 5.780042367535709
Validation loss: 5.839086708492992

Epoch: 5| Step: 5
Training loss: 5.83898241714467
Validation loss: 5.833812594026525

Epoch: 5| Step: 6
Training loss: 5.866637426361272
Validation loss: 5.828055346416186

Epoch: 5| Step: 7
Training loss: 5.80236063305407
Validation loss: 5.8223453052608996

Epoch: 5| Step: 8
Training loss: 5.324362581455522
Validation loss: 5.816252526001853

Epoch: 5| Step: 9
Training loss: 5.931515217228799
Validation loss: 5.8099717072976

Epoch: 5| Step: 10
Training loss: 6.280100551213301
Validation loss: 5.80353863018675

Epoch: 5| Step: 11
Training loss: 6.323692747581931
Validation loss: 5.797018524065747

Epoch: 5| Step: 0
Training loss: 6.880655909921119
Validation loss: 5.789809651965656

Epoch: 5| Step: 1
Training loss: 5.7954241229940076
Validation loss: 5.782664653458588

Epoch: 5| Step: 2
Training loss: 6.488161309848668
Validation loss: 5.775204523601628

Epoch: 5| Step: 3
Training loss: 5.771431498277238
Validation loss: 5.767280974862634

Epoch: 5| Step: 4
Training loss: 5.713444818205023
Validation loss: 5.759527053799053

Epoch: 5| Step: 5
Training loss: 5.348292154827433
Validation loss: 5.751577630818072

Epoch: 5| Step: 6
Training loss: 5.755556158771917
Validation loss: 5.743522070290729

Epoch: 5| Step: 7
Training loss: 5.869527337509511
Validation loss: 5.735097966021194

Epoch: 5| Step: 8
Training loss: 5.417174838755214
Validation loss: 5.72677519621424

Epoch: 5| Step: 9
Training loss: 6.0185514391572035
Validation loss: 5.718313926649763

Epoch: 5| Step: 10
Training loss: 5.041000490339544
Validation loss: 5.709612607892251

Epoch: 5| Step: 11
Training loss: 6.864670084828196
Validation loss: 5.701158687989702

Epoch: 6| Step: 0
Training loss: 4.675969093775362
Validation loss: 5.692278758247765

Epoch: 5| Step: 1
Training loss: 5.469676260843735
Validation loss: 5.683475866329657

Epoch: 5| Step: 2
Training loss: 5.484886906309008
Validation loss: 5.6745669209483145

Epoch: 5| Step: 3
Training loss: 5.17853055665372
Validation loss: 5.665302325074454

Epoch: 5| Step: 4
Training loss: 5.861293305773786
Validation loss: 5.656788921499969

Epoch: 5| Step: 5
Training loss: 5.721297233574926
Validation loss: 5.647481243816705

Epoch: 5| Step: 6
Training loss: 6.3532118116340435
Validation loss: 5.638425685334093

Epoch: 5| Step: 7
Training loss: 6.382799650480487
Validation loss: 5.628955368755988

Epoch: 5| Step: 8
Training loss: 6.283515483668047
Validation loss: 5.619542929230052

Epoch: 5| Step: 9
Training loss: 5.771548156902219
Validation loss: 5.6099448733644355

Epoch: 5| Step: 10
Training loss: 6.093469231813084
Validation loss: 5.600497830492482

Epoch: 5| Step: 11
Training loss: 4.945084360172598
Validation loss: 5.590762770355264

Epoch: 7| Step: 0
Training loss: 4.8358945089718715
Validation loss: 5.58083648032573

Epoch: 5| Step: 1
Training loss: 5.910887497103795
Validation loss: 5.571561568981856

Epoch: 5| Step: 2
Training loss: 5.852030879222781
Validation loss: 5.5623665768627095

Epoch: 5| Step: 3
Training loss: 5.083786282396998
Validation loss: 5.553053059681723

Epoch: 5| Step: 4
Training loss: 5.221429924799788
Validation loss: 5.543888036420726

Epoch: 5| Step: 5
Training loss: 6.3320149839781825
Validation loss: 5.535280881782904

Epoch: 5| Step: 6
Training loss: 6.00788805930216
Validation loss: 5.5266405788345825

Epoch: 5| Step: 7
Training loss: 5.743597031508353
Validation loss: 5.5181298480263

Epoch: 5| Step: 8
Training loss: 5.905608288655217
Validation loss: 5.508721156277417

Epoch: 5| Step: 9
Training loss: 5.965260389325111
Validation loss: 5.499883939501067

Epoch: 5| Step: 10
Training loss: 5.300417635315603
Validation loss: 5.491017129639201

Epoch: 5| Step: 11
Training loss: 4.822449542741236
Validation loss: 5.482150968176118

Epoch: 8| Step: 0
Training loss: 5.6761394684359825
Validation loss: 5.473743941454784

Epoch: 5| Step: 1
Training loss: 5.750671347526794
Validation loss: 5.464961063633708

Epoch: 5| Step: 2
Training loss: 5.961766816491463
Validation loss: 5.455869434043613

Epoch: 5| Step: 3
Training loss: 4.762312541486316
Validation loss: 5.447170493361052

Epoch: 5| Step: 4
Training loss: 5.700120610082073
Validation loss: 5.43871749752488

Epoch: 5| Step: 5
Training loss: 5.635040646722077
Validation loss: 5.4295269766298775

Epoch: 5| Step: 6
Training loss: 4.858099570738437
Validation loss: 5.42109592494691

Epoch: 5| Step: 7
Training loss: 4.703350074426464
Validation loss: 5.4121632880181725

Epoch: 5| Step: 8
Training loss: 5.672398902930298
Validation loss: 5.403936379829266

Epoch: 5| Step: 9
Training loss: 6.024137899048943
Validation loss: 5.395865667337087

Epoch: 5| Step: 10
Training loss: 6.163525924245606
Validation loss: 5.387184445668538

Epoch: 5| Step: 11
Training loss: 5.0190125431163235
Validation loss: 5.3790454352458

Epoch: 9| Step: 0
Training loss: 5.190426472100368
Validation loss: 5.370638334445003

Epoch: 5| Step: 1
Training loss: 5.847119996704307
Validation loss: 5.362749540603564

Epoch: 5| Step: 2
Training loss: 5.39143414160569
Validation loss: 5.3547463925761765

Epoch: 5| Step: 3
Training loss: 5.0195472093617886
Validation loss: 5.346880495896108

Epoch: 5| Step: 4
Training loss: 5.136661381274225
Validation loss: 5.339194893918898

Epoch: 5| Step: 5
Training loss: 5.330477466489466
Validation loss: 5.3317358659429415

Epoch: 5| Step: 6
Training loss: 5.902037394845635
Validation loss: 5.324664979045985

Epoch: 5| Step: 7
Training loss: 5.269281312120719
Validation loss: 5.316955134459522

Epoch: 5| Step: 8
Training loss: 5.296406863070443
Validation loss: 5.309057661290791

Epoch: 5| Step: 9
Training loss: 6.11334146585759
Validation loss: 5.301427349688062

Epoch: 5| Step: 10
Training loss: 5.241965185417293
Validation loss: 5.294044315904446

Epoch: 5| Step: 11
Training loss: 6.101517485429342
Validation loss: 5.286619011703067

Epoch: 10| Step: 0
Training loss: 6.085622208817849
Validation loss: 5.278727514020497

Epoch: 5| Step: 1
Training loss: 5.389905975597464
Validation loss: 5.270686055815939

Epoch: 5| Step: 2
Training loss: 5.170942239692901
Validation loss: 5.263149649358447

Epoch: 5| Step: 3
Training loss: 5.52693067968444
Validation loss: 5.255436330587268

Epoch: 5| Step: 4
Training loss: 5.626780588403911
Validation loss: 5.247628365058711

Epoch: 5| Step: 5
Training loss: 4.980656591126852
Validation loss: 5.239921879938311

Epoch: 5| Step: 6
Training loss: 5.748594361031707
Validation loss: 5.2333363579581365

Epoch: 5| Step: 7
Training loss: 5.116478324844971
Validation loss: 5.22613687877769

Epoch: 5| Step: 8
Training loss: 5.375312796074257
Validation loss: 5.219777674197254

Epoch: 5| Step: 9
Training loss: 4.645699856926245
Validation loss: 5.213722891489003

Epoch: 5| Step: 10
Training loss: 5.577705089674678
Validation loss: 5.207853022998661

Epoch: 5| Step: 11
Training loss: 3.104693852318772
Validation loss: 5.20244677975765

Epoch: 11| Step: 0
Training loss: 5.7423210284219595
Validation loss: 5.1972973084418825

Epoch: 5| Step: 1
Training loss: 5.784221813248804
Validation loss: 5.1917063117108135

Epoch: 5| Step: 2
Training loss: 4.923616034764295
Validation loss: 5.186172269476334

Epoch: 5| Step: 3
Training loss: 4.9203614829403275
Validation loss: 5.180171708019006

Epoch: 5| Step: 4
Training loss: 5.341689398484604
Validation loss: 5.175235436408227

Epoch: 5| Step: 5
Training loss: 5.711306203898325
Validation loss: 5.169886465111093

Epoch: 5| Step: 6
Training loss: 4.280846792572073
Validation loss: 5.16420482876039

Epoch: 5| Step: 7
Training loss: 5.746463849293775
Validation loss: 5.158600258070862

Epoch: 5| Step: 8
Training loss: 4.97992088745274
Validation loss: 5.153410289509748

Epoch: 5| Step: 9
Training loss: 5.101357986066255
Validation loss: 5.147885414048224

Epoch: 5| Step: 10
Training loss: 5.415669256470838
Validation loss: 5.142468424359974

Epoch: 5| Step: 11
Training loss: 5.6244757513947325
Validation loss: 5.1375031117772485

Epoch: 12| Step: 0
Training loss: 5.527539404112256
Validation loss: 5.132042930196013

Epoch: 5| Step: 1
Training loss: 4.190297345374355
Validation loss: 5.126978151290606

Epoch: 5| Step: 2
Training loss: 5.543162304198613
Validation loss: 5.121561866546231

Epoch: 5| Step: 3
Training loss: 3.9472531823854484
Validation loss: 5.116644165080706

Epoch: 5| Step: 4
Training loss: 5.437126409916557
Validation loss: 5.111725316195765

Epoch: 5| Step: 5
Training loss: 5.896161217440614
Validation loss: 5.107003325507134

Epoch: 5| Step: 6
Training loss: 5.26012733595434
Validation loss: 5.101762745282878

Epoch: 5| Step: 7
Training loss: 6.034601891004091
Validation loss: 5.096598790034668

Epoch: 5| Step: 8
Training loss: 5.589295387694964
Validation loss: 5.090848412245008

Epoch: 5| Step: 9
Training loss: 5.669861323092101
Validation loss: 5.085503195849925

Epoch: 5| Step: 10
Training loss: 4.24455765467238
Validation loss: 5.079519939054661

Epoch: 5| Step: 11
Training loss: 3.2704126042893917
Validation loss: 5.074296292404329

Epoch: 13| Step: 0
Training loss: 5.1398320383616
Validation loss: 5.067760003333878

Epoch: 5| Step: 1
Training loss: 4.444700819144535
Validation loss: 5.061779481139113

Epoch: 5| Step: 2
Training loss: 6.238097186349989
Validation loss: 5.0567596920528635

Epoch: 5| Step: 3
Training loss: 4.904228620156757
Validation loss: 5.051271513638446

Epoch: 5| Step: 4
Training loss: 4.973145849633171
Validation loss: 5.046281470640895

Epoch: 5| Step: 5
Training loss: 5.283104023735511
Validation loss: 5.040691638749632

Epoch: 5| Step: 6
Training loss: 5.244816173608593
Validation loss: 5.03518021732976

Epoch: 5| Step: 7
Training loss: 5.519549219273651
Validation loss: 5.02911039235073

Epoch: 5| Step: 8
Training loss: 5.008079676411716
Validation loss: 5.023890425937409

Epoch: 5| Step: 9
Training loss: 5.129322183308498
Validation loss: 5.0181864241908

Epoch: 5| Step: 10
Training loss: 4.924213156802114
Validation loss: 5.013641202778573

Epoch: 5| Step: 11
Training loss: 4.121361948841001
Validation loss: 5.008269790504438

Epoch: 14| Step: 0
Training loss: 5.71578819413174
Validation loss: 5.003104271449669

Epoch: 5| Step: 1
Training loss: 5.721406246799642
Validation loss: 4.998090916000185

Epoch: 5| Step: 2
Training loss: 5.559414468574765
Validation loss: 4.993337977237011

Epoch: 5| Step: 3
Training loss: 5.626050045763159
Validation loss: 4.987914117433198

Epoch: 5| Step: 4
Training loss: 4.952130238855586
Validation loss: 4.982364021662232

Epoch: 5| Step: 5
Training loss: 4.5156530887561726
Validation loss: 4.976476208444231

Epoch: 5| Step: 6
Training loss: 4.840412392820301
Validation loss: 4.9709748379353105

Epoch: 5| Step: 7
Training loss: 5.187296668054769
Validation loss: 4.966486209219512

Epoch: 5| Step: 8
Training loss: 4.366809698970346
Validation loss: 4.961530931277883

Epoch: 5| Step: 9
Training loss: 4.967931140146009
Validation loss: 4.956017541104121

Epoch: 5| Step: 10
Training loss: 4.560077598982306
Validation loss: 4.950784854447161

Epoch: 5| Step: 11
Training loss: 4.370496775588524
Validation loss: 4.946412737983176

Epoch: 15| Step: 0
Training loss: 4.796226233929769
Validation loss: 4.941389402981513

Epoch: 5| Step: 1
Training loss: 5.865771573592382
Validation loss: 4.936587639707796

Epoch: 5| Step: 2
Training loss: 5.161485822689737
Validation loss: 4.930818858153089

Epoch: 5| Step: 3
Training loss: 5.138485541566569
Validation loss: 4.925326643760247

Epoch: 5| Step: 4
Training loss: 5.225867072626953
Validation loss: 4.92050789713309

Epoch: 5| Step: 5
Training loss: 5.386429278899604
Validation loss: 4.91559371178417

Epoch: 5| Step: 6
Training loss: 4.784447492153695
Validation loss: 4.910266503730181

Epoch: 5| Step: 7
Training loss: 3.5787686098116547
Validation loss: 4.90566333575787

Epoch: 5| Step: 8
Training loss: 5.245473090728485
Validation loss: 4.900794030749594

Epoch: 5| Step: 9
Training loss: 4.790483124007574
Validation loss: 4.895641942713446

Epoch: 5| Step: 10
Training loss: 5.286298517025727
Validation loss: 4.891052974869786

Epoch: 5| Step: 11
Training loss: 4.3459107218673285
Validation loss: 4.885406992996931

Epoch: 16| Step: 0
Training loss: 4.062759860604183
Validation loss: 4.880520539558293

Epoch: 5| Step: 1
Training loss: 5.200083533863208
Validation loss: 4.875396956885986

Epoch: 5| Step: 2
Training loss: 4.902452298972543
Validation loss: 4.871186011571748

Epoch: 5| Step: 3
Training loss: 5.139456294355164
Validation loss: 4.865769948823627

Epoch: 5| Step: 4
Training loss: 5.886880752167006
Validation loss: 4.861641938730011

Epoch: 5| Step: 5
Training loss: 4.679022893058406
Validation loss: 4.855293710652662

Epoch: 5| Step: 6
Training loss: 4.930635146571727
Validation loss: 4.85081967673285

Epoch: 5| Step: 7
Training loss: 4.870802808698039
Validation loss: 4.846840297198437

Epoch: 5| Step: 8
Training loss: 4.920586311326812
Validation loss: 4.840454440706548

Epoch: 5| Step: 9
Training loss: 4.106281000539966
Validation loss: 4.835447891585964

Epoch: 5| Step: 10
Training loss: 5.791109822168123
Validation loss: 4.828826055070146

Epoch: 5| Step: 11
Training loss: 4.815242629865359
Validation loss: 4.82340020817283

Epoch: 17| Step: 0
Training loss: 4.684762180606692
Validation loss: 4.817408020007196

Epoch: 5| Step: 1
Training loss: 5.576839181284166
Validation loss: 4.81265070295313

Epoch: 5| Step: 2
Training loss: 5.036847525243712
Validation loss: 4.808809938175406

Epoch: 5| Step: 3
Training loss: 5.1732765903179425
Validation loss: 4.802609299702251

Epoch: 5| Step: 4
Training loss: 5.696664657518015
Validation loss: 4.796988064472024

Epoch: 5| Step: 5
Training loss: 3.6309573451178725
Validation loss: 4.791740282847713

Epoch: 5| Step: 6
Training loss: 5.237147630295873
Validation loss: 4.786319538327616

Epoch: 5| Step: 7
Training loss: 4.764715589459406
Validation loss: 4.780836183013962

Epoch: 5| Step: 8
Training loss: 4.860177222266277
Validation loss: 4.776430015070159

Epoch: 5| Step: 9
Training loss: 4.960280391397173
Validation loss: 4.770685204728622

Epoch: 5| Step: 10
Training loss: 4.469024222970062
Validation loss: 4.765813438150326

Epoch: 5| Step: 11
Training loss: 2.9870938204528326
Validation loss: 4.759866819061275

Epoch: 18| Step: 0
Training loss: 4.979026866956044
Validation loss: 4.7546491541357225

Epoch: 5| Step: 1
Training loss: 4.670160597790538
Validation loss: 4.749198151552293

Epoch: 5| Step: 2
Training loss: 5.310902792987506
Validation loss: 4.7439798469463845

Epoch: 5| Step: 3
Training loss: 4.07486264049973
Validation loss: 4.739349341293086

Epoch: 5| Step: 4
Training loss: 4.95531080855183
Validation loss: 4.733917189013592

Epoch: 5| Step: 5
Training loss: 5.151751411174559
Validation loss: 4.728634281972767

Epoch: 5| Step: 6
Training loss: 4.349658707132121
Validation loss: 4.723943340890374

Epoch: 5| Step: 7
Training loss: 4.9296404901309465
Validation loss: 4.720198192220465

Epoch: 5| Step: 8
Training loss: 5.857964999619542
Validation loss: 4.713391977817187

Epoch: 5| Step: 9
Training loss: 4.824064158074673
Validation loss: 4.709567231843157

Epoch: 5| Step: 10
Training loss: 3.9592058658981113
Validation loss: 4.705067399285763

Epoch: 5| Step: 11
Training loss: 5.040397715543822
Validation loss: 4.7002337789899995

Epoch: 19| Step: 0
Training loss: 4.095371536708439
Validation loss: 4.693921171302013

Epoch: 5| Step: 1
Training loss: 4.1939679198632165
Validation loss: 4.688512455424711

Epoch: 5| Step: 2
Training loss: 4.667281428216621
Validation loss: 4.683074387872893

Epoch: 5| Step: 3
Training loss: 6.019430170813416
Validation loss: 4.678412117701826

Epoch: 5| Step: 4
Training loss: 4.602292998640668
Validation loss: 4.672597924885605

Epoch: 5| Step: 5
Training loss: 4.972418624342485
Validation loss: 4.667628575144227

Epoch: 5| Step: 6
Training loss: 5.263528559331417
Validation loss: 4.662569745371373

Epoch: 5| Step: 7
Training loss: 4.829738507823698
Validation loss: 4.657533106144469

Epoch: 5| Step: 8
Training loss: 5.022695720954819
Validation loss: 4.652841878167926

Epoch: 5| Step: 9
Training loss: 4.996765998190613
Validation loss: 4.647118662893661

Epoch: 5| Step: 10
Training loss: 3.999141362539369
Validation loss: 4.642243313996851

Epoch: 5| Step: 11
Training loss: 3.127573403305893
Validation loss: 4.637260484636727

Epoch: 20| Step: 0
Training loss: 5.477346410439198
Validation loss: 4.631875263379333

Epoch: 5| Step: 1
Training loss: 4.798905231879512
Validation loss: 4.627582928535987

Epoch: 5| Step: 2
Training loss: 4.409289022211686
Validation loss: 4.622248183207069

Epoch: 5| Step: 3
Training loss: 4.377324603895193
Validation loss: 4.617096213155342

Epoch: 5| Step: 4
Training loss: 4.212914393839416
Validation loss: 4.612130646360276

Epoch: 5| Step: 5
Training loss: 3.8651290192974708
Validation loss: 4.607163298432327

Epoch: 5| Step: 6
Training loss: 5.038794884487704
Validation loss: 4.602069604432106

Epoch: 5| Step: 7
Training loss: 5.1147442058841985
Validation loss: 4.597551511545443

Epoch: 5| Step: 8
Training loss: 5.019885193929189
Validation loss: 4.592820832618121

Epoch: 5| Step: 9
Training loss: 4.8161579448616
Validation loss: 4.58735283971593

Epoch: 5| Step: 10
Training loss: 4.8822001569161815
Validation loss: 4.581761344901866

Epoch: 5| Step: 11
Training loss: 3.8396383484769405
Validation loss: 4.577077952008332

Epoch: 21| Step: 0
Training loss: 4.526574399416962
Validation loss: 4.572423754856424

Epoch: 5| Step: 1
Training loss: 3.865656632561498
Validation loss: 4.567445587233588

Epoch: 5| Step: 2
Training loss: 4.497896762584179
Validation loss: 4.5622964230064404

Epoch: 5| Step: 3
Training loss: 5.478086860728527
Validation loss: 4.557336223566129

Epoch: 5| Step: 4
Training loss: 5.160356400771501
Validation loss: 4.552364029366451

Epoch: 5| Step: 5
Training loss: 4.597392811192056
Validation loss: 4.546692598754636

Epoch: 5| Step: 6
Training loss: 4.753035930373335
Validation loss: 4.541919800356439

Epoch: 5| Step: 7
Training loss: 4.130529223656512
Validation loss: 4.536674908951207

Epoch: 5| Step: 8
Training loss: 5.079153666846038
Validation loss: 4.531433921676772

Epoch: 5| Step: 9
Training loss: 4.479814183945654
Validation loss: 4.52624516821611

Epoch: 5| Step: 10
Training loss: 4.709861417379799
Validation loss: 4.5212187566109225

Epoch: 5| Step: 11
Training loss: 4.249441222314329
Validation loss: 4.5162866673026745

Epoch: 22| Step: 0
Training loss: 5.030410222641553
Validation loss: 4.512010775716688

Epoch: 5| Step: 1
Training loss: 4.273509357971036
Validation loss: 4.505680366733662

Epoch: 5| Step: 2
Training loss: 4.236276122390022
Validation loss: 4.501567567546393

Epoch: 5| Step: 3
Training loss: 4.554254265885356
Validation loss: 4.4958968617944866

Epoch: 5| Step: 4
Training loss: 4.780424358413047
Validation loss: 4.49239773907939

Epoch: 5| Step: 5
Training loss: 4.140270289936452
Validation loss: 4.4861701712773865

Epoch: 5| Step: 6
Training loss: 5.389079792971584
Validation loss: 4.480795828674319

Epoch: 5| Step: 7
Training loss: 3.9590067775790674
Validation loss: 4.475184141309464

Epoch: 5| Step: 8
Training loss: 5.679037988351947
Validation loss: 4.471436162280846

Epoch: 5| Step: 9
Training loss: 3.747354591607485
Validation loss: 4.465448133357699

Epoch: 5| Step: 10
Training loss: 3.9253038713949375
Validation loss: 4.459960068814749

Epoch: 5| Step: 11
Training loss: 6.987146292863138
Validation loss: 4.455256330177909

Epoch: 23| Step: 0
Training loss: 4.385401758212423
Validation loss: 4.450412785390569

Epoch: 5| Step: 1
Training loss: 4.75558705264997
Validation loss: 4.445582564317795

Epoch: 5| Step: 2
Training loss: 3.829848170246585
Validation loss: 4.440719694577102

Epoch: 5| Step: 3
Training loss: 5.197397373024791
Validation loss: 4.435413998587639

Epoch: 5| Step: 4
Training loss: 3.970620262831293
Validation loss: 4.428894640313548

Epoch: 5| Step: 5
Training loss: 3.9627970105841563
Validation loss: 4.424108213157207

Epoch: 5| Step: 6
Training loss: 5.13527301125719
Validation loss: 4.418242374382287

Epoch: 5| Step: 7
Training loss: 4.721354189110188
Validation loss: 4.413404090411139

Epoch: 5| Step: 8
Training loss: 4.291734318369749
Validation loss: 4.40784397107248

Epoch: 5| Step: 9
Training loss: 4.829453763856381
Validation loss: 4.401992914751918

Epoch: 5| Step: 10
Training loss: 4.496115385346512
Validation loss: 4.396717781052237

Epoch: 5| Step: 11
Training loss: 5.6927191294166075
Validation loss: 4.391116588761947

Epoch: 24| Step: 0
Training loss: 4.620117290708887
Validation loss: 4.386206031065094

Epoch: 5| Step: 1
Training loss: 4.589315129133342
Validation loss: 4.380832081887019

Epoch: 5| Step: 2
Training loss: 3.7907995273449315
Validation loss: 4.375794293189456

Epoch: 5| Step: 3
Training loss: 4.5554223751873355
Validation loss: 4.3702880735036365

Epoch: 5| Step: 4
Training loss: 4.6189192930588225
Validation loss: 4.364992476096702

Epoch: 5| Step: 5
Training loss: 5.388858406181684
Validation loss: 4.3597640088431575

Epoch: 5| Step: 6
Training loss: 4.074943382946413
Validation loss: 4.354321539404519

Epoch: 5| Step: 7
Training loss: 4.435669857387972
Validation loss: 4.34896384903183

Epoch: 5| Step: 8
Training loss: 4.3825851082249345
Validation loss: 4.344216392598864

Epoch: 5| Step: 9
Training loss: 3.531436881462545
Validation loss: 4.338584339470837

Epoch: 5| Step: 10
Training loss: 4.974146952889063
Validation loss: 4.3346949357720765

Epoch: 5| Step: 11
Training loss: 5.035515724294696
Validation loss: 4.3287832262271495

Epoch: 25| Step: 0
Training loss: 4.578472241457394
Validation loss: 4.323469869614022

Epoch: 5| Step: 1
Training loss: 4.371168366068903
Validation loss: 4.318321555673804

Epoch: 5| Step: 2
Training loss: 4.362264571081212
Validation loss: 4.313185628116537

Epoch: 5| Step: 3
Training loss: 4.094643764627651
Validation loss: 4.308527185381818

Epoch: 5| Step: 4
Training loss: 4.613429055038565
Validation loss: 4.30337967018594

Epoch: 5| Step: 5
Training loss: 3.2232650644146648
Validation loss: 4.298716854334834

Epoch: 5| Step: 6
Training loss: 4.871509182490359
Validation loss: 4.2935819642022865

Epoch: 5| Step: 7
Training loss: 3.8091813949693014
Validation loss: 4.288676723416448

Epoch: 5| Step: 8
Training loss: 4.643645770827257
Validation loss: 4.284365130931822

Epoch: 5| Step: 9
Training loss: 5.7043154793446185
Validation loss: 4.278991177584201

Epoch: 5| Step: 10
Training loss: 4.18150446962772
Validation loss: 4.272685936225794

Epoch: 5| Step: 11
Training loss: 3.3273608266155335
Validation loss: 4.267998488009137

Epoch: 26| Step: 0
Training loss: 3.851542443770676
Validation loss: 4.264388812383476

Epoch: 5| Step: 1
Training loss: 4.247619635483976
Validation loss: 4.26024273686006

Epoch: 5| Step: 2
Training loss: 4.333538099488315
Validation loss: 4.254292386794333

Epoch: 5| Step: 3
Training loss: 4.723730427362534
Validation loss: 4.2489671293546225

Epoch: 5| Step: 4
Training loss: 3.7040239361675495
Validation loss: 4.243722449444054

Epoch: 5| Step: 5
Training loss: 5.117035795103367
Validation loss: 4.239251419808923

Epoch: 5| Step: 6
Training loss: 3.791200015238182
Validation loss: 4.235024115063295

Epoch: 5| Step: 7
Training loss: 4.5700733611314215
Validation loss: 4.23065308662086

Epoch: 5| Step: 8
Training loss: 4.8851880939860495
Validation loss: 4.225086967619033

Epoch: 5| Step: 9
Training loss: 4.280845233132609
Validation loss: 4.2202303702705

Epoch: 5| Step: 10
Training loss: 4.262233629601464
Validation loss: 4.21462744392597

Epoch: 5| Step: 11
Training loss: 4.68132894574203
Validation loss: 4.209687891533871

Epoch: 27| Step: 0
Training loss: 3.9539640840356958
Validation loss: 4.204735325721213

Epoch: 5| Step: 1
Training loss: 4.45379954800599
Validation loss: 4.1999389125529225

Epoch: 5| Step: 2
Training loss: 3.695012086427818
Validation loss: 4.195438072934715

Epoch: 5| Step: 3
Training loss: 3.699939242714706
Validation loss: 4.190064034310286

Epoch: 5| Step: 4
Training loss: 4.051306224269246
Validation loss: 4.185042889267777

Epoch: 5| Step: 5
Training loss: 4.348856606883175
Validation loss: 4.18048348616406

Epoch: 5| Step: 6
Training loss: 5.275208578460632
Validation loss: 4.17494650557124

Epoch: 5| Step: 7
Training loss: 4.671942566858293
Validation loss: 4.170617722544435

Epoch: 5| Step: 8
Training loss: 4.928803716836527
Validation loss: 4.1649073876231295

Epoch: 5| Step: 9
Training loss: 4.212750499306739
Validation loss: 4.160591300937523

Epoch: 5| Step: 10
Training loss: 4.079912166772003
Validation loss: 4.154807086479784

Epoch: 5| Step: 11
Training loss: 2.8241522268055768
Validation loss: 4.15140518294327

Epoch: 28| Step: 0
Training loss: 4.655810444201308
Validation loss: 4.1459514594701465

Epoch: 5| Step: 1
Training loss: 3.830024465975791
Validation loss: 4.1410034582533095

Epoch: 5| Step: 2
Training loss: 3.873926075432395
Validation loss: 4.136192170591285

Epoch: 5| Step: 3
Training loss: 4.452483763453648
Validation loss: 4.130922194079146

Epoch: 5| Step: 4
Training loss: 3.833655772262319
Validation loss: 4.125974520771191

Epoch: 5| Step: 5
Training loss: 4.65045993950338
Validation loss: 4.121304258059392

Epoch: 5| Step: 6
Training loss: 4.302109294132602
Validation loss: 4.1166707099992506

Epoch: 5| Step: 7
Training loss: 4.390303956373146
Validation loss: 4.112705964532091

Epoch: 5| Step: 8
Training loss: 4.125567541671516
Validation loss: 4.107725394935939

Epoch: 5| Step: 9
Training loss: 4.536080567682182
Validation loss: 4.103220867771509

Epoch: 5| Step: 10
Training loss: 4.307878754846181
Validation loss: 4.096919621142879

Epoch: 5| Step: 11
Training loss: 2.442736551627444
Validation loss: 4.092664244619749

Epoch: 29| Step: 0
Training loss: 4.220227696210398
Validation loss: 4.087765379018478

Epoch: 5| Step: 1
Training loss: 4.738842961539846
Validation loss: 4.082721098265921

Epoch: 5| Step: 2
Training loss: 4.201017964841137
Validation loss: 4.078186668036916

Epoch: 5| Step: 3
Training loss: 4.285700580030052
Validation loss: 4.072380043575193

Epoch: 5| Step: 4
Training loss: 3.63771510586058
Validation loss: 4.068605744851218

Epoch: 5| Step: 5
Training loss: 3.7301725739348104
Validation loss: 4.062663769477656

Epoch: 5| Step: 6
Training loss: 4.096338516596707
Validation loss: 4.058772318451374

Epoch: 5| Step: 7
Training loss: 4.801043659236552
Validation loss: 4.05272447209508

Epoch: 5| Step: 8
Training loss: 4.179045840057366
Validation loss: 4.0480824440336995

Epoch: 5| Step: 9
Training loss: 3.7956463116921095
Validation loss: 4.043297874335035

Epoch: 5| Step: 10
Training loss: 4.201851917880368
Validation loss: 4.03884579675457

Epoch: 5| Step: 11
Training loss: 4.700359152199752
Validation loss: 4.033214844324113

Epoch: 30| Step: 0
Training loss: 4.685054904286262
Validation loss: 4.027713357841415

Epoch: 5| Step: 1
Training loss: 3.506382572163312
Validation loss: 4.022585154497998

Epoch: 5| Step: 2
Training loss: 4.460606764843914
Validation loss: 4.018041375997376

Epoch: 5| Step: 3
Training loss: 4.1709401658457566
Validation loss: 4.012554474140981

Epoch: 5| Step: 4
Training loss: 3.635252430584405
Validation loss: 4.007717986600499

Epoch: 5| Step: 5
Training loss: 3.838212901942732
Validation loss: 4.002861400206978

Epoch: 5| Step: 6
Training loss: 3.451528050469634
Validation loss: 3.9986878070643463

Epoch: 5| Step: 7
Training loss: 3.980133551652414
Validation loss: 3.994392358484235

Epoch: 5| Step: 8
Training loss: 4.8583355248753275
Validation loss: 3.9892042227250157

Epoch: 5| Step: 9
Training loss: 3.8739349378204353
Validation loss: 3.984130203605757

Epoch: 5| Step: 10
Training loss: 4.538666226920059
Validation loss: 3.9788404883600257

Epoch: 5| Step: 11
Training loss: 5.084362717926065
Validation loss: 3.974250296103876

Epoch: 31| Step: 0
Training loss: 4.68862006474957
Validation loss: 3.968811875709524

Epoch: 5| Step: 1
Training loss: 4.184065591826804
Validation loss: 3.963650643867746

Epoch: 5| Step: 2
Training loss: 4.002288878744374
Validation loss: 3.959950310896269

Epoch: 5| Step: 3
Training loss: 3.9911917024937162
Validation loss: 3.9556131234977436

Epoch: 5| Step: 4
Training loss: 3.765523442208698
Validation loss: 3.9495640322970247

Epoch: 5| Step: 5
Training loss: 4.234109905432803
Validation loss: 3.9449207174330487

Epoch: 5| Step: 6
Training loss: 3.777170802578378
Validation loss: 3.9390269654025594

Epoch: 5| Step: 7
Training loss: 4.294629207144136
Validation loss: 3.934226668604014

Epoch: 5| Step: 8
Training loss: 4.055811378968758
Validation loss: 3.9290588664817285

Epoch: 5| Step: 9
Training loss: 3.7245006815468917
Validation loss: 3.924258831127562

Epoch: 5| Step: 10
Training loss: 4.074085090763597
Validation loss: 3.9195645379648916

Epoch: 5| Step: 11
Training loss: 3.9747655739424244
Validation loss: 3.9152274767972752

Epoch: 32| Step: 0
Training loss: 4.448148389344484
Validation loss: 3.910146052054751

Epoch: 5| Step: 1
Training loss: 3.0119207688000853
Validation loss: 3.905274729733652

Epoch: 5| Step: 2
Training loss: 4.544832904962866
Validation loss: 3.9008744139865703

Epoch: 5| Step: 3
Training loss: 3.6597733434733555
Validation loss: 3.896320198698671

Epoch: 5| Step: 4
Training loss: 3.5995473789086057
Validation loss: 3.891955892337762

Epoch: 5| Step: 5
Training loss: 3.5521861906998113
Validation loss: 3.8875815298151997

Epoch: 5| Step: 6
Training loss: 4.424017181735621
Validation loss: 3.8835219125978737

Epoch: 5| Step: 7
Training loss: 4.481554586574973
Validation loss: 3.878185787948948

Epoch: 5| Step: 8
Training loss: 4.179169524709397
Validation loss: 3.873680890043222

Epoch: 5| Step: 9
Training loss: 3.7200242111484654
Validation loss: 3.8688909150622304

Epoch: 5| Step: 10
Training loss: 4.22058766219035
Validation loss: 3.864165680244676

Epoch: 5| Step: 11
Training loss: 4.35677749745767
Validation loss: 3.8603033732989824

Epoch: 33| Step: 0
Training loss: 3.238241933991202
Validation loss: 3.855436191595287

Epoch: 5| Step: 1
Training loss: 4.528341267372531
Validation loss: 3.850432874446414

Epoch: 5| Step: 2
Training loss: 4.289113640263195
Validation loss: 3.845888370038827

Epoch: 5| Step: 3
Training loss: 4.574271705900765
Validation loss: 3.840917189522684

Epoch: 5| Step: 4
Training loss: 3.8404439959540575
Validation loss: 3.835709481542024

Epoch: 5| Step: 5
Training loss: 4.675079165517673
Validation loss: 3.831642916695517

Epoch: 5| Step: 6
Training loss: 3.480095942917612
Validation loss: 3.827113680995228

Epoch: 5| Step: 7
Training loss: 3.2702354484043634
Validation loss: 3.8219484390268845

Epoch: 5| Step: 8
Training loss: 3.5538934177008517
Validation loss: 3.817753710440227

Epoch: 5| Step: 9
Training loss: 3.5048289365286593
Validation loss: 3.8126242153590106

Epoch: 5| Step: 10
Training loss: 4.159661520612519
Validation loss: 3.808365127352852

Epoch: 5| Step: 11
Training loss: 4.6104149631244855
Validation loss: 3.8036342941221277

Epoch: 34| Step: 0
Training loss: 3.965274761055539
Validation loss: 3.799312065830292

Epoch: 5| Step: 1
Training loss: 3.344866414731306
Validation loss: 3.794542362688262

Epoch: 5| Step: 2
Training loss: 4.051914920919144
Validation loss: 3.7900364046940163

Epoch: 5| Step: 3
Training loss: 3.3499789109206763
Validation loss: 3.7855983668828457

Epoch: 5| Step: 4
Training loss: 3.8045050167993684
Validation loss: 3.781200298266418

Epoch: 5| Step: 5
Training loss: 3.8260473724718733
Validation loss: 3.7765706114970565

Epoch: 5| Step: 6
Training loss: 4.283654644463896
Validation loss: 3.7727441670700026

Epoch: 5| Step: 7
Training loss: 4.056582322342226
Validation loss: 3.7679402579608468

Epoch: 5| Step: 8
Training loss: 4.091106230869682
Validation loss: 3.763449371470365

Epoch: 5| Step: 9
Training loss: 3.876491505696587
Validation loss: 3.7590198071059353

Epoch: 5| Step: 10
Training loss: 4.417496417335046
Validation loss: 3.7545872393792283

Epoch: 5| Step: 11
Training loss: 2.7830297369236936
Validation loss: 3.7499780919176806

Epoch: 35| Step: 0
Training loss: 3.4149256821863574
Validation loss: 3.7458652218460964

Epoch: 5| Step: 1
Training loss: 3.525826534468148
Validation loss: 3.7416831986133596

Epoch: 5| Step: 2
Training loss: 4.006431892062725
Validation loss: 3.737713421540532

Epoch: 5| Step: 3
Training loss: 4.12571686960101
Validation loss: 3.733507382786237

Epoch: 5| Step: 4
Training loss: 4.1185437163820415
Validation loss: 3.7293217731519874

Epoch: 5| Step: 5
Training loss: 4.391032678540299
Validation loss: 3.7246275756156533

Epoch: 5| Step: 6
Training loss: 3.87801588275366
Validation loss: 3.7201941862149046

Epoch: 5| Step: 7
Training loss: 3.785099560575875
Validation loss: 3.715732870522589

Epoch: 5| Step: 8
Training loss: 3.5844965680500107
Validation loss: 3.71135975359455

Epoch: 5| Step: 9
Training loss: 3.6604765891285393
Validation loss: 3.7070339190812143

Epoch: 5| Step: 10
Training loss: 3.848343624157953
Validation loss: 3.7029892726227387

Epoch: 5| Step: 11
Training loss: 3.918704997265145
Validation loss: 3.6984971875777446

Epoch: 36| Step: 0
Training loss: 3.4056212518636038
Validation loss: 3.694206023749155

Epoch: 5| Step: 1
Training loss: 4.4056824663591865
Validation loss: 3.6898628143371583

Epoch: 5| Step: 2
Training loss: 3.4024185890699905
Validation loss: 3.6854872248084067

Epoch: 5| Step: 3
Training loss: 3.6773807884411154
Validation loss: 3.6817527153564797

Epoch: 5| Step: 4
Training loss: 4.000992413434247
Validation loss: 3.677918486089974

Epoch: 5| Step: 5
Training loss: 4.5355242334289745
Validation loss: 3.673714035185223

Epoch: 5| Step: 6
Training loss: 4.1455523269473975
Validation loss: 3.669511518668315

Epoch: 5| Step: 7
Training loss: 3.5960586430114083
Validation loss: 3.664348311891227

Epoch: 5| Step: 8
Training loss: 2.800230262007693
Validation loss: 3.66013181197165

Epoch: 5| Step: 9
Training loss: 3.8787803667891616
Validation loss: 3.655583122493133

Epoch: 5| Step: 10
Training loss: 3.6796017128568126
Validation loss: 3.651613743903602

Epoch: 5| Step: 11
Training loss: 4.047842491885193
Validation loss: 3.6472096960513287

Epoch: 37| Step: 0
Training loss: 3.672151985272654
Validation loss: 3.643067055241015

Epoch: 5| Step: 1
Training loss: 3.751116777067239
Validation loss: 3.6389484938543837

Epoch: 5| Step: 2
Training loss: 3.547449544342149
Validation loss: 3.6343005561147113

Epoch: 5| Step: 3
Training loss: 3.5535108693940094
Validation loss: 3.629875696924635

Epoch: 5| Step: 4
Training loss: 4.092981397387526
Validation loss: 3.6256319459821116

Epoch: 5| Step: 5
Training loss: 3.79545975042577
Validation loss: 3.6213041571562847

Epoch: 5| Step: 6
Training loss: 4.056450903197734
Validation loss: 3.61716736910816

Epoch: 5| Step: 7
Training loss: 4.220981036228797
Validation loss: 3.612609850391364

Epoch: 5| Step: 8
Training loss: 3.4971961643526503
Validation loss: 3.6082432281191665

Epoch: 5| Step: 9
Training loss: 3.5692706100810403
Validation loss: 3.603732389772461

Epoch: 5| Step: 10
Training loss: 3.5862013111020414
Validation loss: 3.599282371113817

Epoch: 5| Step: 11
Training loss: 3.322476891063411
Validation loss: 3.595746671546595

Epoch: 38| Step: 0
Training loss: 3.405086353568195
Validation loss: 3.5917390532106506

Epoch: 5| Step: 1
Training loss: 4.034056167355253
Validation loss: 3.587698870251859

Epoch: 5| Step: 2
Training loss: 3.590837973975807
Validation loss: 3.5836041961732783

Epoch: 5| Step: 3
Training loss: 4.459658892121911
Validation loss: 3.579751224025557

Epoch: 5| Step: 4
Training loss: 3.3764066237411
Validation loss: 3.5753659712374444

Epoch: 5| Step: 5
Training loss: 3.682590513858584
Validation loss: 3.5713454407144978

Epoch: 5| Step: 6
Training loss: 3.6532483943987106
Validation loss: 3.566920694250457

Epoch: 5| Step: 7
Training loss: 3.5684682811702646
Validation loss: 3.5633006562541802

Epoch: 5| Step: 8
Training loss: 4.291864976961501
Validation loss: 3.559334486277822

Epoch: 5| Step: 9
Training loss: 3.6259803761678704
Validation loss: 3.554820740826104

Epoch: 5| Step: 10
Training loss: 3.1236793779356
Validation loss: 3.550997216567611

Epoch: 5| Step: 11
Training loss: 2.360241560292274
Validation loss: 3.547471213399823

Epoch: 39| Step: 0
Training loss: 3.734737362698341
Validation loss: 3.543463630699911

Epoch: 5| Step: 1
Training loss: 3.7061698403141086
Validation loss: 3.5397031034458712

Epoch: 5| Step: 2
Training loss: 4.15168408153735
Validation loss: 3.535602823787718

Epoch: 5| Step: 3
Training loss: 4.0409084801829955
Validation loss: 3.5313283298323275

Epoch: 5| Step: 4
Training loss: 3.5409878846989806
Validation loss: 3.5274094596253915

Epoch: 5| Step: 5
Training loss: 4.29879884133597
Validation loss: 3.523719404154737

Epoch: 5| Step: 6
Training loss: 3.4951833551905924
Validation loss: 3.5195259830888466

Epoch: 5| Step: 7
Training loss: 3.2879158250192644
Validation loss: 3.5149989496105607

Epoch: 5| Step: 8
Training loss: 3.1072245306796895
Validation loss: 3.5107255322481756

Epoch: 5| Step: 9
Training loss: 3.555573807775485
Validation loss: 3.5066656094145783

Epoch: 5| Step: 10
Training loss: 3.3629603925148355
Validation loss: 3.5030451198049333

Epoch: 5| Step: 11
Training loss: 2.597136068246815
Validation loss: 3.499155039064282

Epoch: 40| Step: 0
Training loss: 3.1457708154659807
Validation loss: 3.494904834186598

Epoch: 5| Step: 1
Training loss: 4.009578204338829
Validation loss: 3.49108589428604

Epoch: 5| Step: 2
Training loss: 3.610118970944725
Validation loss: 3.487578278122252

Epoch: 5| Step: 3
Training loss: 3.5000997256649145
Validation loss: 3.484197671936757

Epoch: 5| Step: 4
Training loss: 3.5797453963461052
Validation loss: 3.4811535870426624

Epoch: 5| Step: 5
Training loss: 3.646754528105345
Validation loss: 3.47704348433699

Epoch: 5| Step: 6
Training loss: 3.245842989383645
Validation loss: 3.472804595216041

Epoch: 5| Step: 7
Training loss: 3.674843225573568
Validation loss: 3.469197373279882

Epoch: 5| Step: 8
Training loss: 3.226241199669111
Validation loss: 3.4648465999117044

Epoch: 5| Step: 9
Training loss: 3.927324377026952
Validation loss: 3.4608423580183976

Epoch: 5| Step: 10
Training loss: 3.899957456112164
Validation loss: 3.457537638040355

Epoch: 5| Step: 11
Training loss: 4.340412861396143
Validation loss: 3.4532433111253558

Epoch: 41| Step: 0
Training loss: 2.831479101616868
Validation loss: 3.4489295005841294

Epoch: 5| Step: 1
Training loss: 3.388156537273527
Validation loss: 3.4452091931045223

Epoch: 5| Step: 2
Training loss: 3.5635968577684634
Validation loss: 3.4412061883548755

Epoch: 5| Step: 3
Training loss: 2.8331912696976387
Validation loss: 3.4367932778027366

Epoch: 5| Step: 4
Training loss: 3.7974227698523593
Validation loss: 3.433196037905251

Epoch: 5| Step: 5
Training loss: 3.3294299795381583
Validation loss: 3.4290629305547102

Epoch: 5| Step: 6
Training loss: 3.7616126500078035
Validation loss: 3.4254595012064613

Epoch: 5| Step: 7
Training loss: 3.902519947614403
Validation loss: 3.421228710670933

Epoch: 5| Step: 8
Training loss: 4.066784990392417
Validation loss: 3.417601217218842

Epoch: 5| Step: 9
Training loss: 3.81730574097978
Validation loss: 3.4137894166952023

Epoch: 5| Step: 10
Training loss: 3.703974372898702
Validation loss: 3.4092600119197747

Epoch: 5| Step: 11
Training loss: 3.530978302082213
Validation loss: 3.4055780978819756

Epoch: 42| Step: 0
Training loss: 4.019596021480681
Validation loss: 3.400908578057253

Epoch: 5| Step: 1
Training loss: 3.851862340556914
Validation loss: 3.3970216220537788

Epoch: 5| Step: 2
Training loss: 3.786273488286416
Validation loss: 3.393167655701534

Epoch: 5| Step: 3
Training loss: 4.129357550578247
Validation loss: 3.3885693859831516

Epoch: 5| Step: 4
Training loss: 3.7700396101107745
Validation loss: 3.3840354253599574

Epoch: 5| Step: 5
Training loss: 2.867807097881442
Validation loss: 3.379692024490119

Epoch: 5| Step: 6
Training loss: 3.1728329269035673
Validation loss: 3.375918916712742

Epoch: 5| Step: 7
Training loss: 3.6947519147333536
Validation loss: 3.3716540233854593

Epoch: 5| Step: 8
Training loss: 3.26007630803018
Validation loss: 3.3673396537137146

Epoch: 5| Step: 9
Training loss: 2.9964785571210304
Validation loss: 3.3637438908935775

Epoch: 5| Step: 10
Training loss: 2.7124174184577723
Validation loss: 3.359981227852592

Epoch: 5| Step: 11
Training loss: 4.1735374767192495
Validation loss: 3.3561805440865826

Epoch: 43| Step: 0
Training loss: 3.217423545326218
Validation loss: 3.352377637545048

Epoch: 5| Step: 1
Training loss: 3.8997703826995713
Validation loss: 3.3484924589587406

Epoch: 5| Step: 2
Training loss: 3.168985187297279
Validation loss: 3.3456279674193574

Epoch: 5| Step: 3
Training loss: 3.4868275858966027
Validation loss: 3.341687514096598

Epoch: 5| Step: 4
Training loss: 3.2601035133263085
Validation loss: 3.338587968399089

Epoch: 5| Step: 5
Training loss: 3.598217782631101
Validation loss: 3.334649646653698

Epoch: 5| Step: 6
Training loss: 3.025832693705224
Validation loss: 3.331183161252875

Epoch: 5| Step: 7
Training loss: 3.4880852211681748
Validation loss: 3.3276861435747764

Epoch: 5| Step: 8
Training loss: 3.345783791624595
Validation loss: 3.3241924698743768

Epoch: 5| Step: 9
Training loss: 4.525533924953851
Validation loss: 3.320708456926261

Epoch: 5| Step: 10
Training loss: 3.091657142590216
Validation loss: 3.316738583793036

Epoch: 5| Step: 11
Training loss: 2.547400765475002
Validation loss: 3.312968418902324

Epoch: 44| Step: 0
Training loss: 2.7020796149078015
Validation loss: 3.3094728060958167

Epoch: 5| Step: 1
Training loss: 3.106888740308111
Validation loss: 3.3064244592666148

Epoch: 5| Step: 2
Training loss: 4.065417371956184
Validation loss: 3.302969092735045

Epoch: 5| Step: 3
Training loss: 3.7913451564983007
Validation loss: 3.2998304062189434

Epoch: 5| Step: 4
Training loss: 3.277766094797582
Validation loss: 3.2962465877561105

Epoch: 5| Step: 5
Training loss: 3.405890069546068
Validation loss: 3.292327094320846

Epoch: 5| Step: 6
Training loss: 3.193557817085342
Validation loss: 3.28863534094128

Epoch: 5| Step: 7
Training loss: 4.039511561563583
Validation loss: 3.285021911849939

Epoch: 5| Step: 8
Training loss: 3.1117126265572597
Validation loss: 3.2813460805237935

Epoch: 5| Step: 9
Training loss: 3.626904612079633
Validation loss: 3.2777308499529405

Epoch: 5| Step: 10
Training loss: 3.0564153521220736
Validation loss: 3.2741520510698696

Epoch: 5| Step: 11
Training loss: 3.8908168025403325
Validation loss: 3.270579344410562

Epoch: 45| Step: 0
Training loss: 2.9809601904800007
Validation loss: 3.267545777058328

Epoch: 5| Step: 1
Training loss: 3.095607161613961
Validation loss: 3.26440347826462

Epoch: 5| Step: 2
Training loss: 3.253129772582204
Validation loss: 3.2608354845892107

Epoch: 5| Step: 3
Training loss: 3.031923514194059
Validation loss: 3.258423593170166

Epoch: 5| Step: 4
Training loss: 3.8924698343253494
Validation loss: 3.254759439670497

Epoch: 5| Step: 5
Training loss: 3.792008409015973
Validation loss: 3.2522257922533475

Epoch: 5| Step: 6
Training loss: 3.580042695797824
Validation loss: 3.248279654181833

Epoch: 5| Step: 7
Training loss: 3.629546372834847
Validation loss: 3.2449235884217744

Epoch: 5| Step: 8
Training loss: 3.4907831359396484
Validation loss: 3.2412593999222006

Epoch: 5| Step: 9
Training loss: 3.5793849276043135
Validation loss: 3.237919448624226

Epoch: 5| Step: 10
Training loss: 2.821671092628332
Validation loss: 3.234729443354554

Epoch: 5| Step: 11
Training loss: 3.209639609477907
Validation loss: 3.2309795623096695

Epoch: 46| Step: 0
Training loss: 3.2175164683053166
Validation loss: 3.227694413702064

Epoch: 5| Step: 1
Training loss: 3.0529600756796422
Validation loss: 3.224054638107765

Epoch: 5| Step: 2
Training loss: 3.5448302706397725
Validation loss: 3.2201697573181924

Epoch: 5| Step: 3
Training loss: 2.9945043453657005
Validation loss: 3.2171205883901735

Epoch: 5| Step: 4
Training loss: 3.46822910006175
Validation loss: 3.2132614895662615

Epoch: 5| Step: 5
Training loss: 3.0163347268881395
Validation loss: 3.209810970475559

Epoch: 5| Step: 6
Training loss: 3.7903265348896875
Validation loss: 3.2065579014320016

Epoch: 5| Step: 7
Training loss: 3.1816927798441665
Validation loss: 3.2030285580390454

Epoch: 5| Step: 8
Training loss: 3.36994640500157
Validation loss: 3.1996320054682887

Epoch: 5| Step: 9
Training loss: 3.484794420393373
Validation loss: 3.195511489181186

Epoch: 5| Step: 10
Training loss: 3.7057943903566253
Validation loss: 3.192795680201125

Epoch: 5| Step: 11
Training loss: 2.842870555333951
Validation loss: 3.189639850483665

Epoch: 47| Step: 0
Training loss: 2.9301664647540817
Validation loss: 3.1876740750918775

Epoch: 5| Step: 1
Training loss: 2.8044857707037547
Validation loss: 3.1856921997227237

Epoch: 5| Step: 2
Training loss: 3.4536099330735395
Validation loss: 3.1857799239741094

Epoch: 5| Step: 3
Training loss: 4.000190015094327
Validation loss: 3.1768526754396014

Epoch: 5| Step: 4
Training loss: 2.9193464956196644
Validation loss: 3.1740091219424222

Epoch: 5| Step: 5
Training loss: 3.0004187927393953
Validation loss: 3.1723286503189434

Epoch: 5| Step: 6
Training loss: 3.7801514598232835
Validation loss: 3.1721018191764805

Epoch: 5| Step: 7
Training loss: 3.256482774611334
Validation loss: 3.1711505131396205

Epoch: 5| Step: 8
Training loss: 3.789673305713579
Validation loss: 3.1701180645519975

Epoch: 5| Step: 9
Training loss: 3.04899671969389
Validation loss: 3.1665524892969703

Epoch: 5| Step: 10
Training loss: 3.339404839124096
Validation loss: 3.160293657846509

Epoch: 5| Step: 11
Training loss: 2.6992598225495312
Validation loss: 3.155190123065442

Epoch: 48| Step: 0
Training loss: 3.1341128421277276
Validation loss: 3.151108655401405

Epoch: 5| Step: 1
Training loss: 3.3311221099981836
Validation loss: 3.147451266799511

Epoch: 5| Step: 2
Training loss: 2.8658019831758965
Validation loss: 3.1453002431687227

Epoch: 5| Step: 3
Training loss: 3.9284658789389155
Validation loss: 3.1423411259211784

Epoch: 5| Step: 4
Training loss: 3.3806210086211474
Validation loss: 3.140120343961607

Epoch: 5| Step: 5
Training loss: 2.8500822222711495
Validation loss: 3.1360408831174955

Epoch: 5| Step: 6
Training loss: 3.5617460825064438
Validation loss: 3.132830416024873

Epoch: 5| Step: 7
Training loss: 3.2268818473263017
Validation loss: 3.130806709682676

Epoch: 5| Step: 8
Training loss: 3.143501444825207
Validation loss: 3.1274692094427112

Epoch: 5| Step: 9
Training loss: 3.5833451618324634
Validation loss: 3.126337995194487

Epoch: 5| Step: 10
Training loss: 2.9301713467643706
Validation loss: 3.120264400696617

Epoch: 5| Step: 11
Training loss: 2.9127344782013567
Validation loss: 3.1179982615283133

Epoch: 49| Step: 0
Training loss: 3.0838976335074153
Validation loss: 3.113034380957283

Epoch: 5| Step: 1
Training loss: 2.7758031078179126
Validation loss: 3.110259391980013

Epoch: 5| Step: 2
Training loss: 3.216448062590668
Validation loss: 3.1072009136124374

Epoch: 5| Step: 3
Training loss: 3.1728414932800364
Validation loss: 3.1050987966968098

Epoch: 5| Step: 4
Training loss: 3.0845706278592413
Validation loss: 3.1016849202195114

Epoch: 5| Step: 5
Training loss: 3.5464735434112873
Validation loss: 3.0991775093254788

Epoch: 5| Step: 6
Training loss: 3.2246946973967097
Validation loss: 3.095832040631592

Epoch: 5| Step: 7
Training loss: 3.360033263541373
Validation loss: 3.092550488293448

Epoch: 5| Step: 8
Training loss: 3.4529910514708964
Validation loss: 3.0897311685647093

Epoch: 5| Step: 9
Training loss: 3.2352202412131503
Validation loss: 3.0862666216114665

Epoch: 5| Step: 10
Training loss: 3.5383750129888645
Validation loss: 3.083230543141552

Epoch: 5| Step: 11
Training loss: 2.450149578277338
Validation loss: 3.080194323115157

Epoch: 50| Step: 0
Training loss: 3.16029868730295
Validation loss: 3.0776348143260046

Epoch: 5| Step: 1
Training loss: 3.3225345850307693
Validation loss: 3.0750860487779135

Epoch: 5| Step: 2
Training loss: 3.1922427030281737
Validation loss: 3.072158788984631

Epoch: 5| Step: 3
Training loss: 3.110708899459693
Validation loss: 3.069721673055963

Epoch: 5| Step: 4
Training loss: 3.109889309007995
Validation loss: 3.0681263499057203

Epoch: 5| Step: 5
Training loss: 3.2545709011309434
Validation loss: 3.0650584731454322

Epoch: 5| Step: 6
Training loss: 3.624316973299827
Validation loss: 3.0621729111676728

Epoch: 5| Step: 7
Training loss: 2.9386000501117198
Validation loss: 3.0586194832646174

Epoch: 5| Step: 8
Training loss: 3.1634576666796903
Validation loss: 3.0553768937782966

Epoch: 5| Step: 9
Training loss: 3.063757502010877
Validation loss: 3.0521424106613178

Epoch: 5| Step: 10
Training loss: 3.5163215455805608
Validation loss: 3.05050761175631

Epoch: 5| Step: 11
Training loss: 1.5955906131444364
Validation loss: 3.0483885144094875

Epoch: 51| Step: 0
Training loss: 2.9928172273051836
Validation loss: 3.0460984047293778

Epoch: 5| Step: 1
Training loss: 2.6088963600707356
Validation loss: 3.043966587593205

Epoch: 5| Step: 2
Training loss: 3.383611501023124
Validation loss: 3.0421815571386506

Epoch: 5| Step: 3
Training loss: 2.8832765944820635
Validation loss: 3.0392766352430325

Epoch: 5| Step: 4
Training loss: 3.247120829024336
Validation loss: 3.037084381883824

Epoch: 5| Step: 5
Training loss: 2.961397402030654
Validation loss: 3.0341787249241614

Epoch: 5| Step: 6
Training loss: 3.629383856445774
Validation loss: 3.0316955789491464

Epoch: 5| Step: 7
Training loss: 3.194403558736644
Validation loss: 3.0284913609418065

Epoch: 5| Step: 8
Training loss: 2.993916064536422
Validation loss: 3.025578824012482

Epoch: 5| Step: 9
Training loss: 3.576554532623416
Validation loss: 3.02315659248943

Epoch: 5| Step: 10
Training loss: 3.125268543149032
Validation loss: 3.0201432207127694

Epoch: 5| Step: 11
Training loss: 3.9794770896952865
Validation loss: 3.017159932776271

Epoch: 52| Step: 0
Training loss: 2.808865381509999
Validation loss: 3.015800395206667

Epoch: 5| Step: 1
Training loss: 2.919393699617141
Validation loss: 3.0122018699542004

Epoch: 5| Step: 2
Training loss: 3.2041825200264524
Validation loss: 3.0099550122007237

Epoch: 5| Step: 3
Training loss: 3.262834004226348
Validation loss: 3.0079345215986457

Epoch: 5| Step: 4
Training loss: 2.4690199112921665
Validation loss: 3.004703275441088

Epoch: 5| Step: 5
Training loss: 3.233533224501124
Validation loss: 3.003605530315582

Epoch: 5| Step: 6
Training loss: 3.1050513796770853
Validation loss: 2.9999828172562513

Epoch: 5| Step: 7
Training loss: 2.980447311624241
Validation loss: 2.9981251328450864

Epoch: 5| Step: 8
Training loss: 3.5775392544323528
Validation loss: 2.9954792770257277

Epoch: 5| Step: 9
Training loss: 2.8792126517113
Validation loss: 2.99287180300869

Epoch: 5| Step: 10
Training loss: 3.647832326097417
Validation loss: 2.9900580615208066

Epoch: 5| Step: 11
Training loss: 4.415450426499212
Validation loss: 2.987174649924449

Epoch: 53| Step: 0
Training loss: 3.0731829166909215
Validation loss: 2.9861727021886226

Epoch: 5| Step: 1
Training loss: 3.026353952354893
Validation loss: 2.9828265268892884

Epoch: 5| Step: 2
Training loss: 2.9583529261267087
Validation loss: 2.9781356285628733

Epoch: 5| Step: 3
Training loss: 3.51267101373824
Validation loss: 2.975722210172311

Epoch: 5| Step: 4
Training loss: 3.4223104400191064
Validation loss: 2.9733163215238925

Epoch: 5| Step: 5
Training loss: 3.0978351170970555
Validation loss: 2.9707451524171415

Epoch: 5| Step: 6
Training loss: 3.5677251142492366
Validation loss: 2.96787629237453

Epoch: 5| Step: 7
Training loss: 3.2562850920970026
Validation loss: 2.965345361199002

Epoch: 5| Step: 8
Training loss: 2.9580489187573824
Validation loss: 2.9615923644677316

Epoch: 5| Step: 9
Training loss: 2.5624374754186077
Validation loss: 2.9594597462943857

Epoch: 5| Step: 10
Training loss: 2.637260776898066
Validation loss: 2.956546866395724

Epoch: 5| Step: 11
Training loss: 3.21072795397645
Validation loss: 2.954005824868028

Epoch: 54| Step: 0
Training loss: 3.5760369350906895
Validation loss: 2.952164683884581

Epoch: 5| Step: 1
Training loss: 2.688418031963668
Validation loss: 2.949493065343856

Epoch: 5| Step: 2
Training loss: 3.4665113218665398
Validation loss: 2.948878045012646

Epoch: 5| Step: 3
Training loss: 2.53089111044455
Validation loss: 2.9453514561998597

Epoch: 5| Step: 4
Training loss: 3.1339314809683994
Validation loss: 2.942880491548998

Epoch: 5| Step: 5
Training loss: 2.8558072203959983
Validation loss: 2.940233027852892

Epoch: 5| Step: 6
Training loss: 2.920534693478745
Validation loss: 2.9387144932886344

Epoch: 5| Step: 7
Training loss: 2.784342300445659
Validation loss: 2.935659846748142

Epoch: 5| Step: 8
Training loss: 3.3153399403353663
Validation loss: 2.9360455672951136

Epoch: 5| Step: 9
Training loss: 3.6322189010159427
Validation loss: 2.9306717503569817

Epoch: 5| Step: 10
Training loss: 2.942307778613059
Validation loss: 2.929185290207315

Epoch: 5| Step: 11
Training loss: 2.0985718048586532
Validation loss: 2.9272186184681526

Epoch: 55| Step: 0
Training loss: 3.3617045996862602
Validation loss: 2.9250301352739068

Epoch: 5| Step: 1
Training loss: 3.086676014281167
Validation loss: 2.9227342549124726

Epoch: 5| Step: 2
Training loss: 2.834685246186301
Validation loss: 2.9209695490873933

Epoch: 5| Step: 3
Training loss: 3.3303504631124516
Validation loss: 2.9186099844546614

Epoch: 5| Step: 4
Training loss: 2.8632749216548414
Validation loss: 2.916576439733466

Epoch: 5| Step: 5
Training loss: 2.63053428720078
Validation loss: 2.9143911249689687

Epoch: 5| Step: 6
Training loss: 2.754753685825263
Validation loss: 2.91267832931833

Epoch: 5| Step: 7
Training loss: 3.3637591475493855
Validation loss: 2.910379402087738

Epoch: 5| Step: 8
Training loss: 2.5863433242855947
Validation loss: 2.908711792214466

Epoch: 5| Step: 9
Training loss: 3.0829160940684726
Validation loss: 2.906349296650968

Epoch: 5| Step: 10
Training loss: 3.44774640326554
Validation loss: 2.9044590254640745

Epoch: 5| Step: 11
Training loss: 3.5412133020181975
Validation loss: 2.9027225731483255

Epoch: 56| Step: 0
Training loss: 2.872771518978902
Validation loss: 2.8986934984092545

Epoch: 5| Step: 1
Training loss: 3.2921174782872993
Validation loss: 2.8975262816144802

Epoch: 5| Step: 2
Training loss: 3.274303968008247
Validation loss: 2.895062326230889

Epoch: 5| Step: 3
Training loss: 3.0410869690471047
Validation loss: 2.892895341368119

Epoch: 5| Step: 4
Training loss: 3.0361304566873297
Validation loss: 2.8902054662659773

Epoch: 5| Step: 5
Training loss: 3.011048476149166
Validation loss: 2.888308633143635

Epoch: 5| Step: 6
Training loss: 2.9518751294880907
Validation loss: 2.8863404421419405

Epoch: 5| Step: 7
Training loss: 3.261940077165214
Validation loss: 2.88379837725313

Epoch: 5| Step: 8
Training loss: 2.880529807684938
Validation loss: 2.8808243019856983

Epoch: 5| Step: 9
Training loss: 2.9783238283534725
Validation loss: 2.8792314867616478

Epoch: 5| Step: 10
Training loss: 2.675768241015366
Validation loss: 2.875179931289906

Epoch: 5| Step: 11
Training loss: 3.0116319854152453
Validation loss: 2.8739223741137017

Epoch: 57| Step: 0
Training loss: 2.8595042381888884
Validation loss: 2.873453404968728

Epoch: 5| Step: 1
Training loss: 3.3528414333494894
Validation loss: 2.8772269103797363

Epoch: 5| Step: 2
Training loss: 2.7954468730530824
Validation loss: 2.87977918126028

Epoch: 5| Step: 3
Training loss: 2.5935474914179766
Validation loss: 2.9110337711562857

Epoch: 5| Step: 4
Training loss: 3.3802110919833375
Validation loss: 2.927197261824026

Epoch: 5| Step: 5
Training loss: 3.007538859813142
Validation loss: 2.9025072040627267

Epoch: 5| Step: 6
Training loss: 2.827392483259891
Validation loss: 2.8790336487530523

Epoch: 5| Step: 7
Training loss: 2.97005538349339
Validation loss: 2.8592837411183174

Epoch: 5| Step: 8
Training loss: 2.9069414854351048
Validation loss: 2.859017448791677

Epoch: 5| Step: 9
Training loss: 2.882861790843005
Validation loss: 2.8602846154509334

Epoch: 5| Step: 10
Training loss: 3.4623777953248536
Validation loss: 2.860382687690294

Epoch: 5| Step: 11
Training loss: 2.983517828267798
Validation loss: 2.859618614325047

Epoch: 58| Step: 0
Training loss: 2.57840371214824
Validation loss: 2.856974040164401

Epoch: 5| Step: 1
Training loss: 2.2630973659578095
Validation loss: 2.8515791278511085

Epoch: 5| Step: 2
Training loss: 2.567156584745665
Validation loss: 2.8521978567540094

Epoch: 5| Step: 3
Training loss: 3.174018323627888
Validation loss: 2.854827008582016

Epoch: 5| Step: 4
Training loss: 3.415338552736693
Validation loss: 2.8739681396280203

Epoch: 5| Step: 5
Training loss: 3.437013210161365
Validation loss: 2.861340064673744

Epoch: 5| Step: 6
Training loss: 2.8773926439980997
Validation loss: 2.8460208712809085

Epoch: 5| Step: 7
Training loss: 3.209917412286673
Validation loss: 2.8560179092302507

Epoch: 5| Step: 8
Training loss: 3.211291811066879
Validation loss: 2.8565095986633957

Epoch: 5| Step: 9
Training loss: 2.957791954972724
Validation loss: 2.837083541176155

Epoch: 5| Step: 10
Training loss: 3.030542979421686
Validation loss: 2.833706401124407

Epoch: 5| Step: 11
Training loss: 2.93985605108043
Validation loss: 2.8325945940633233

Epoch: 59| Step: 0
Training loss: 3.0617195224785325
Validation loss: 2.830597918619466

Epoch: 5| Step: 1
Training loss: 2.868452993405752
Validation loss: 2.830764322258521

Epoch: 5| Step: 2
Training loss: 3.0011959870866938
Validation loss: 2.8278338140147508

Epoch: 5| Step: 3
Training loss: 3.306705517027903
Validation loss: 2.826416525261743

Epoch: 5| Step: 4
Training loss: 2.6152586248525638
Validation loss: 2.8228755551449574

Epoch: 5| Step: 5
Training loss: 3.3009506994689737
Validation loss: 2.8205774945344717

Epoch: 5| Step: 6
Training loss: 2.1891453685772406
Validation loss: 2.8182431816317055

Epoch: 5| Step: 7
Training loss: 2.682250640456626
Validation loss: 2.8159918160520556

Epoch: 5| Step: 8
Training loss: 2.9394729157348713
Validation loss: 2.8128395970501527

Epoch: 5| Step: 9
Training loss: 3.4423467972406767
Validation loss: 2.8100944792938782

Epoch: 5| Step: 10
Training loss: 3.0322916659677643
Validation loss: 2.808904200034656

Epoch: 5| Step: 11
Training loss: 2.390851377851438
Validation loss: 2.8074394581144464

Epoch: 60| Step: 0
Training loss: 3.4275119285459397
Validation loss: 2.804902365130502

Epoch: 5| Step: 1
Training loss: 2.993271593959539
Validation loss: 2.8040008696184247

Epoch: 5| Step: 2
Training loss: 2.972796603484826
Validation loss: 2.803102904579632

Epoch: 5| Step: 3
Training loss: 2.646708506422411
Validation loss: 2.800466270593957

Epoch: 5| Step: 4
Training loss: 3.213070349029112
Validation loss: 2.796541503118112

Epoch: 5| Step: 5
Training loss: 2.9404275793437313
Validation loss: 2.7986917438097656

Epoch: 5| Step: 6
Training loss: 3.496962182643092
Validation loss: 2.794079120146961

Epoch: 5| Step: 7
Training loss: 2.796237126927422
Validation loss: 2.7916316639902616

Epoch: 5| Step: 8
Training loss: 2.3647946390749364
Validation loss: 2.788778523895284

Epoch: 5| Step: 9
Training loss: 2.3786635000966183
Validation loss: 2.787564257236094

Epoch: 5| Step: 10
Training loss: 2.6089305384941737
Validation loss: 2.786440345967547

Epoch: 5| Step: 11
Training loss: 3.8295358977238436
Validation loss: 2.7852196991600797

Epoch: 61| Step: 0
Training loss: 2.4607381104121315
Validation loss: 2.782793191981673

Epoch: 5| Step: 1
Training loss: 2.879230206713585
Validation loss: 2.7840275485956707

Epoch: 5| Step: 2
Training loss: 2.9520973960812515
Validation loss: 2.7829959975239076

Epoch: 5| Step: 3
Training loss: 3.036174117451826
Validation loss: 2.784773024008165

Epoch: 5| Step: 4
Training loss: 2.7563796170783195
Validation loss: 2.7826761311198145

Epoch: 5| Step: 5
Training loss: 2.6444286512478508
Validation loss: 2.7793766241724374

Epoch: 5| Step: 6
Training loss: 3.230038006443777
Validation loss: 2.775725779116463

Epoch: 5| Step: 7
Training loss: 2.823814014859183
Validation loss: 2.7704786286348178

Epoch: 5| Step: 8
Training loss: 3.327854629065089
Validation loss: 2.765836201162787

Epoch: 5| Step: 9
Training loss: 2.898782632437636
Validation loss: 2.7677875619923213

Epoch: 5| Step: 10
Training loss: 2.9662664364931253
Validation loss: 2.767193261601319

Epoch: 5| Step: 11
Training loss: 2.8508442013230546
Validation loss: 2.7675127206996475

Epoch: 62| Step: 0
Training loss: 3.2359064134755906
Validation loss: 2.7663557376754886

Epoch: 5| Step: 1
Training loss: 2.8167495835719465
Validation loss: 2.7680900313878234

Epoch: 5| Step: 2
Training loss: 3.0263162948992064
Validation loss: 2.762849093512961

Epoch: 5| Step: 3
Training loss: 2.8621444214770313
Validation loss: 2.7602192874134146

Epoch: 5| Step: 4
Training loss: 2.946888307316852
Validation loss: 2.758658145285097

Epoch: 5| Step: 5
Training loss: 2.734506571192823
Validation loss: 2.7566183204535935

Epoch: 5| Step: 6
Training loss: 2.736121965656814
Validation loss: 2.7568322115350568

Epoch: 5| Step: 7
Training loss: 2.947634158846619
Validation loss: 2.7542936156347424

Epoch: 5| Step: 8
Training loss: 2.8334740061526027
Validation loss: 2.751784395956861

Epoch: 5| Step: 9
Training loss: 2.87223981962177
Validation loss: 2.7483634775388968

Epoch: 5| Step: 10
Training loss: 2.8781482210993214
Validation loss: 2.7462697268914655

Epoch: 5| Step: 11
Training loss: 2.6840510749107387
Validation loss: 2.7440308536462252

Epoch: 63| Step: 0
Training loss: 3.0005711965379467
Validation loss: 2.7415527920616487

Epoch: 5| Step: 1
Training loss: 3.094020330775313
Validation loss: 2.741154304900582

Epoch: 5| Step: 2
Training loss: 3.1418014524436693
Validation loss: 2.739133135473628

Epoch: 5| Step: 3
Training loss: 2.8016300803871883
Validation loss: 2.7365959158063844

Epoch: 5| Step: 4
Training loss: 3.2550852678560025
Validation loss: 2.7361793849762024

Epoch: 5| Step: 5
Training loss: 2.47398632368349
Validation loss: 2.7367018690141274

Epoch: 5| Step: 6
Training loss: 2.811011704742479
Validation loss: 2.736492804600708

Epoch: 5| Step: 7
Training loss: 2.5821967136846995
Validation loss: 2.733553735833196

Epoch: 5| Step: 8
Training loss: 3.015194244453765
Validation loss: 2.7321826465616956

Epoch: 5| Step: 9
Training loss: 2.7994218876619597
Validation loss: 2.7292725904065067

Epoch: 5| Step: 10
Training loss: 2.58454954579619
Validation loss: 2.730683376043048

Epoch: 5| Step: 11
Training loss: 2.549779534626752
Validation loss: 2.7300808384970487

Epoch: 64| Step: 0
Training loss: 2.641996129266299
Validation loss: 2.7251906746757166

Epoch: 5| Step: 1
Training loss: 3.0091335813791145
Validation loss: 2.7237307172001963

Epoch: 5| Step: 2
Training loss: 2.5093501715661004
Validation loss: 2.7220021925827917

Epoch: 5| Step: 3
Training loss: 3.301562263138524
Validation loss: 2.7219762039494477

Epoch: 5| Step: 4
Training loss: 3.3260503042228184
Validation loss: 2.7223484699066987

Epoch: 5| Step: 5
Training loss: 2.7719865469007474
Validation loss: 2.7208110735879893

Epoch: 5| Step: 6
Training loss: 2.7308867084159463
Validation loss: 2.7203081167829573

Epoch: 5| Step: 7
Training loss: 2.7229124630051853
Validation loss: 2.7181265836061854

Epoch: 5| Step: 8
Training loss: 3.0393453824300276
Validation loss: 2.7154969671376796

Epoch: 5| Step: 9
Training loss: 2.5004111905497006
Validation loss: 2.7115293803941367

Epoch: 5| Step: 10
Training loss: 2.768516882044567
Validation loss: 2.711435380375176

Epoch: 5| Step: 11
Training loss: 2.911935966133496
Validation loss: 2.709952836124809

Epoch: 65| Step: 0
Training loss: 2.6504329039898833
Validation loss: 2.709062827729222

Epoch: 5| Step: 1
Training loss: 2.698297677451496
Validation loss: 2.7086311702309134

Epoch: 5| Step: 2
Training loss: 2.841671362133752
Validation loss: 2.7060602748578675

Epoch: 5| Step: 3
Training loss: 2.8950964083785107
Validation loss: 2.704817262413005

Epoch: 5| Step: 4
Training loss: 3.205081546835087
Validation loss: 2.70135705937841

Epoch: 5| Step: 5
Training loss: 2.5699298423067236
Validation loss: 2.6996709405275126

Epoch: 5| Step: 6
Training loss: 2.7942736585068917
Validation loss: 2.7017660639039907

Epoch: 5| Step: 7
Training loss: 2.12581181446381
Validation loss: 2.698349793964937

Epoch: 5| Step: 8
Training loss: 3.2106278541675524
Validation loss: 2.6980571612054365

Epoch: 5| Step: 9
Training loss: 3.1028707133094
Validation loss: 2.697834876500992

Epoch: 5| Step: 10
Training loss: 3.036313262318088
Validation loss: 2.6949054207893677

Epoch: 5| Step: 11
Training loss: 2.325388381677536
Validation loss: 2.6932573527376773

Epoch: 66| Step: 0
Training loss: 2.730987281297577
Validation loss: 2.6890634823785704

Epoch: 5| Step: 1
Training loss: 2.741885785407059
Validation loss: 2.6898594412898564

Epoch: 5| Step: 2
Training loss: 3.105521262822519
Validation loss: 2.6907155738321733

Epoch: 5| Step: 3
Training loss: 2.5570391642316608
Validation loss: 2.6889835225635212

Epoch: 5| Step: 4
Training loss: 3.007894618907409
Validation loss: 2.6880381695895994

Epoch: 5| Step: 5
Training loss: 2.9584818699758135
Validation loss: 2.6881866649811963

Epoch: 5| Step: 6
Training loss: 2.7006782527547304
Validation loss: 2.6849234376383087

Epoch: 5| Step: 7
Training loss: 2.926497286483938
Validation loss: 2.6868178884442773

Epoch: 5| Step: 8
Training loss: 3.131500045325644
Validation loss: 2.68284359163913

Epoch: 5| Step: 9
Training loss: 2.348232712639695
Validation loss: 2.681512153958099

Epoch: 5| Step: 10
Training loss: 2.5552439419027326
Validation loss: 2.6854177584965284

Epoch: 5| Step: 11
Training loss: 3.462662174544605
Validation loss: 2.6901353401576324

Epoch: 67| Step: 0
Training loss: 3.1222074619938343
Validation loss: 2.7115654012082677

Epoch: 5| Step: 1
Training loss: 2.822775824342448
Validation loss: 2.7292034835855814

Epoch: 5| Step: 2
Training loss: 3.4001777490265983
Validation loss: 2.7221185818284845

Epoch: 5| Step: 3
Training loss: 2.818861992550262
Validation loss: 2.7075980410990086

Epoch: 5| Step: 4
Training loss: 2.659732196635331
Validation loss: 2.703108348317391

Epoch: 5| Step: 5
Training loss: 2.6253420289055276
Validation loss: 2.6997101626714652

Epoch: 5| Step: 6
Training loss: 2.481802225998467
Validation loss: 2.698412346441961

Epoch: 5| Step: 7
Training loss: 3.0925321397522114
Validation loss: 2.6971095189823595

Epoch: 5| Step: 8
Training loss: 2.5034554443173396
Validation loss: 2.6994308484038125

Epoch: 5| Step: 9
Training loss: 2.7033730982886963
Validation loss: 2.6990428155073256

Epoch: 5| Step: 10
Training loss: 3.1703094978750723
Validation loss: 2.6987345767762068

Epoch: 5| Step: 11
Training loss: 1.7929359715609103
Validation loss: 2.696607954728425

Epoch: 68| Step: 0
Training loss: 3.188378007425924
Validation loss: 2.6966348104241744

Epoch: 5| Step: 1
Training loss: 2.4386193077462486
Validation loss: 2.6983589241914485

Epoch: 5| Step: 2
Training loss: 3.0801697731292066
Validation loss: 2.6958986870411983

Epoch: 5| Step: 3
Training loss: 2.7317642391235553
Validation loss: 2.6921779742361123

Epoch: 5| Step: 4
Training loss: 2.7873931077382412
Validation loss: 2.6872945566534208

Epoch: 5| Step: 5
Training loss: 2.721724888618196
Validation loss: 2.683984834399587

Epoch: 5| Step: 6
Training loss: 2.8578964329528063
Validation loss: 2.680703225512726

Epoch: 5| Step: 7
Training loss: 2.5124998405798107
Validation loss: 2.675989232948502

Epoch: 5| Step: 8
Training loss: 2.937273057328117
Validation loss: 2.674930179136325

Epoch: 5| Step: 9
Training loss: 3.0672624886858824
Validation loss: 2.671933335230723

Epoch: 5| Step: 10
Training loss: 2.7277299627743385
Validation loss: 2.666739925977614

Epoch: 5| Step: 11
Training loss: 2.4614260234049423
Validation loss: 2.668489047059388

Epoch: 69| Step: 0
Training loss: 2.9672974898053903
Validation loss: 2.6668392301892823

Epoch: 5| Step: 1
Training loss: 2.698799862632901
Validation loss: 2.662462602421365

Epoch: 5| Step: 2
Training loss: 2.226870331482299
Validation loss: 2.663613125813839

Epoch: 5| Step: 3
Training loss: 2.5627897145319287
Validation loss: 2.662398335929182

Epoch: 5| Step: 4
Training loss: 2.786389178312164
Validation loss: 2.663206087728284

Epoch: 5| Step: 5
Training loss: 2.495432400435408
Validation loss: 2.659422797144469

Epoch: 5| Step: 6
Training loss: 2.8367125237684703
Validation loss: 2.6595036606646003

Epoch: 5| Step: 7
Training loss: 2.691085021139878
Validation loss: 2.6601224011150277

Epoch: 5| Step: 8
Training loss: 3.2713546499466455
Validation loss: 2.6644929983640355

Epoch: 5| Step: 9
Training loss: 2.7663647368191886
Validation loss: 2.66396418862716

Epoch: 5| Step: 10
Training loss: 3.227314341883685
Validation loss: 2.65714928606826

Epoch: 5| Step: 11
Training loss: 3.214039735616089
Validation loss: 2.6545895454187556

Epoch: 70| Step: 0
Training loss: 2.4433716698206855
Validation loss: 2.651844886005235

Epoch: 5| Step: 1
Training loss: 3.1628141224576845
Validation loss: 2.6517874687278318

Epoch: 5| Step: 2
Training loss: 3.285549725386277
Validation loss: 2.654462867619613

Epoch: 5| Step: 3
Training loss: 2.6915297348418052
Validation loss: 2.6516150370997678

Epoch: 5| Step: 4
Training loss: 2.545726868379857
Validation loss: 2.6507009363454443

Epoch: 5| Step: 5
Training loss: 2.7095567336505604
Validation loss: 2.652256349482226

Epoch: 5| Step: 6
Training loss: 2.7017019417883947
Validation loss: 2.6517254947340336

Epoch: 5| Step: 7
Training loss: 2.6032745867884834
Validation loss: 2.6506046591993693

Epoch: 5| Step: 8
Training loss: 2.8116621676870492
Validation loss: 2.6502544056035604

Epoch: 5| Step: 9
Training loss: 2.736690565307693
Validation loss: 2.646485204567492

Epoch: 5| Step: 10
Training loss: 2.8662244130326324
Validation loss: 2.646945469326156

Epoch: 5| Step: 11
Training loss: 2.76279265635768
Validation loss: 2.642962228359348

Epoch: 71| Step: 0
Training loss: 2.6400960358578334
Validation loss: 2.6402433409249135

Epoch: 5| Step: 1
Training loss: 3.1834144588605366
Validation loss: 2.641837923072372

Epoch: 5| Step: 2
Training loss: 2.3267669813324026
Validation loss: 2.640165488385782

Epoch: 5| Step: 3
Training loss: 2.234554470297177
Validation loss: 2.639847112290167

Epoch: 5| Step: 4
Training loss: 2.973210888324304
Validation loss: 2.6396153455347156

Epoch: 5| Step: 5
Training loss: 3.001185818597213
Validation loss: 2.6368718119334744

Epoch: 5| Step: 6
Training loss: 2.79381363900773
Validation loss: 2.635125906865992

Epoch: 5| Step: 7
Training loss: 2.3929488910743975
Validation loss: 2.6374098787986267

Epoch: 5| Step: 8
Training loss: 2.74681392250249
Validation loss: 2.633313170086246

Epoch: 5| Step: 9
Training loss: 3.2266219089756154
Validation loss: 2.633595075807829

Epoch: 5| Step: 10
Training loss: 2.769855173642276
Validation loss: 2.634370405163723

Epoch: 5| Step: 11
Training loss: 2.489046706672176
Validation loss: 2.6317254981635574

Epoch: 72| Step: 0
Training loss: 2.6395034665552677
Validation loss: 2.6373453332951358

Epoch: 5| Step: 1
Training loss: 2.7550082119024886
Validation loss: 2.6411032535162557

Epoch: 5| Step: 2
Training loss: 3.09217995001289
Validation loss: 2.6390981718083837

Epoch: 5| Step: 3
Training loss: 2.7725284429799038
Validation loss: 2.6402427539635105

Epoch: 5| Step: 4
Training loss: 2.774905909412301
Validation loss: 2.63143995298598

Epoch: 5| Step: 5
Training loss: 1.9829522987665007
Validation loss: 2.6260303299349093

Epoch: 5| Step: 6
Training loss: 2.6363857935031167
Validation loss: 2.622441914875495

Epoch: 5| Step: 7
Training loss: 2.657091433822952
Validation loss: 2.619274237456012

Epoch: 5| Step: 8
Training loss: 2.8120472013709223
Validation loss: 2.6198190544825377

Epoch: 5| Step: 9
Training loss: 2.937103407039837
Validation loss: 2.6225073120504967

Epoch: 5| Step: 10
Training loss: 3.117663354333593
Validation loss: 2.618956530703402

Epoch: 5| Step: 11
Training loss: 2.8349922223127404
Validation loss: 2.6192424317253282

Epoch: 73| Step: 0
Training loss: 2.4391147449086046
Validation loss: 2.618587248637606

Epoch: 5| Step: 1
Training loss: 2.5479831274123708
Validation loss: 2.6186619415287513

Epoch: 5| Step: 2
Training loss: 2.6774934288820473
Validation loss: 2.61759422899583

Epoch: 5| Step: 3
Training loss: 2.81227305874225
Validation loss: 2.6197692511163937

Epoch: 5| Step: 4
Training loss: 3.046653543885042
Validation loss: 2.6169677224567174

Epoch: 5| Step: 5
Training loss: 3.0901750659422818
Validation loss: 2.6158252226209684

Epoch: 5| Step: 6
Training loss: 2.8385130901239783
Validation loss: 2.6142499541453224

Epoch: 5| Step: 7
Training loss: 2.5945465519335253
Validation loss: 2.613333465404248

Epoch: 5| Step: 8
Training loss: 2.598266529874507
Validation loss: 2.6113926706680193

Epoch: 5| Step: 9
Training loss: 2.451372334463713
Validation loss: 2.6097559279655793

Epoch: 5| Step: 10
Training loss: 2.9885130948154304
Validation loss: 2.6077564915363616

Epoch: 5| Step: 11
Training loss: 2.9368028828107193
Validation loss: 2.6085504991926016

Epoch: 74| Step: 0
Training loss: 2.5541343906804785
Validation loss: 2.610528709907431

Epoch: 5| Step: 1
Training loss: 2.290089347628885
Validation loss: 2.617746101852768

Epoch: 5| Step: 2
Training loss: 3.215856047430894
Validation loss: 2.608395569691569

Epoch: 5| Step: 3
Training loss: 3.1769434830366716
Validation loss: 2.6065021450096832

Epoch: 5| Step: 4
Training loss: 2.7460275916083785
Validation loss: 2.60205575965543

Epoch: 5| Step: 5
Training loss: 2.606031823116929
Validation loss: 2.601746313037559

Epoch: 5| Step: 6
Training loss: 2.4566136719445355
Validation loss: 2.60228435135926

Epoch: 5| Step: 7
Training loss: 2.655328388774896
Validation loss: 2.60476017991489

Epoch: 5| Step: 8
Training loss: 2.761578546874349
Validation loss: 2.6052220698170783

Epoch: 5| Step: 9
Training loss: 2.7839769003885384
Validation loss: 2.6076714556969165

Epoch: 5| Step: 10
Training loss: 2.702179054166764
Validation loss: 2.6043702096866803

Epoch: 5| Step: 11
Training loss: 3.119811366321012
Validation loss: 2.6007122678079475

Epoch: 75| Step: 0
Training loss: 2.896111472697914
Validation loss: 2.5973957476103706

Epoch: 5| Step: 1
Training loss: 2.1488278675894
Validation loss: 2.5998336882463127

Epoch: 5| Step: 2
Training loss: 2.746384237669669
Validation loss: 2.599638092547317

Epoch: 5| Step: 3
Training loss: 2.7788617456286593
Validation loss: 2.5984565439021474

Epoch: 5| Step: 4
Training loss: 2.8233773018732213
Validation loss: 2.595791890062017

Epoch: 5| Step: 5
Training loss: 2.6502764683583733
Validation loss: 2.597483674629268

Epoch: 5| Step: 6
Training loss: 2.638289191607134
Validation loss: 2.598192481812627

Epoch: 5| Step: 7
Training loss: 2.8164265667609785
Validation loss: 2.5984915592567144

Epoch: 5| Step: 8
Training loss: 2.961705573718547
Validation loss: 2.596934607900835

Epoch: 5| Step: 9
Training loss: 2.7033442590244205
Validation loss: 2.594970959615436

Epoch: 5| Step: 10
Training loss: 2.7818730545808483
Validation loss: 2.5928824402429407

Epoch: 5| Step: 11
Training loss: 2.898555948556809
Validation loss: 2.5917011004692325

Epoch: 76| Step: 0
Training loss: 2.9608946623509063
Validation loss: 2.5888272491870175

Epoch: 5| Step: 1
Training loss: 2.8412749869795677
Validation loss: 2.591265944312077

Epoch: 5| Step: 2
Training loss: 2.7920710901757526
Validation loss: 2.588915586169045

Epoch: 5| Step: 3
Training loss: 2.458138269562723
Validation loss: 2.587360405496568

Epoch: 5| Step: 4
Training loss: 2.286701325616374
Validation loss: 2.5845754172842303

Epoch: 5| Step: 5
Training loss: 2.790504403408003
Validation loss: 2.5840594491507347

Epoch: 5| Step: 6
Training loss: 2.368827428030388
Validation loss: 2.5858628146017124

Epoch: 5| Step: 7
Training loss: 3.1100274556410765
Validation loss: 2.5832481344591556

Epoch: 5| Step: 8
Training loss: 2.8922215357199264
Validation loss: 2.5807673929092703

Epoch: 5| Step: 9
Training loss: 2.559446981719662
Validation loss: 2.581628280335388

Epoch: 5| Step: 10
Training loss: 2.631180254449054
Validation loss: 2.582134173597925

Epoch: 5| Step: 11
Training loss: 3.0192785712518004
Validation loss: 2.5799679382498155

Epoch: 77| Step: 0
Training loss: 3.1831720927148095
Validation loss: 2.585089172710434

Epoch: 5| Step: 1
Training loss: 2.4900290969312895
Validation loss: 2.5846175083465637

Epoch: 5| Step: 2
Training loss: 2.425987148914437
Validation loss: 2.5854107799560353

Epoch: 5| Step: 3
Training loss: 2.672670390992945
Validation loss: 2.5892404512386045

Epoch: 5| Step: 4
Training loss: 2.4795525728665013
Validation loss: 2.584664918104995

Epoch: 5| Step: 5
Training loss: 2.638046721431515
Validation loss: 2.580324017350907

Epoch: 5| Step: 6
Training loss: 2.8528065097364435
Validation loss: 2.581531274262895

Epoch: 5| Step: 7
Training loss: 2.6178166330757313
Validation loss: 2.5760719409114397

Epoch: 5| Step: 8
Training loss: 2.5599096277795983
Validation loss: 2.5739401906350663

Epoch: 5| Step: 9
Training loss: 3.0648032110617116
Validation loss: 2.572964873743893

Epoch: 5| Step: 10
Training loss: 2.578192785123324
Validation loss: 2.5745813464591127

Epoch: 5| Step: 11
Training loss: 3.2901783407277403
Validation loss: 2.5735225131506048

Epoch: 78| Step: 0
Training loss: 2.781042627040137
Validation loss: 2.571863674542137

Epoch: 5| Step: 1
Training loss: 2.493303294315364
Validation loss: 2.569687269667675

Epoch: 5| Step: 2
Training loss: 2.819236148433175
Validation loss: 2.5642926799538137

Epoch: 5| Step: 3
Training loss: 2.5398753581666114
Validation loss: 2.569803916140152

Epoch: 5| Step: 4
Training loss: 2.928729498315643
Validation loss: 2.578105159644647

Epoch: 5| Step: 5
Training loss: 2.804296949816739
Validation loss: 2.575831601197734

Epoch: 5| Step: 6
Training loss: 2.990277749113902
Validation loss: 2.581316257885673

Epoch: 5| Step: 7
Training loss: 2.619601010816644
Validation loss: 2.5900079513057084

Epoch: 5| Step: 8
Training loss: 2.9216592474446283
Validation loss: 2.5924023685384956

Epoch: 5| Step: 9
Training loss: 2.258791701286018
Validation loss: 2.5679604572270174

Epoch: 5| Step: 10
Training loss: 2.5202094532948176
Validation loss: 2.5650277076337606

Epoch: 5| Step: 11
Training loss: 2.4183321727466844
Validation loss: 2.5657336022719908

Epoch: 79| Step: 0
Training loss: 2.740893631996051
Validation loss: 2.565924109038106

Epoch: 5| Step: 1
Training loss: 2.831058224547204
Validation loss: 2.5666985889613

Epoch: 5| Step: 2
Training loss: 2.5578449114387096
Validation loss: 2.569326213459176

Epoch: 5| Step: 3
Training loss: 2.7300339599565184
Validation loss: 2.5706366611899147

Epoch: 5| Step: 4
Training loss: 2.743826873328038
Validation loss: 2.5723506765707387

Epoch: 5| Step: 5
Training loss: 3.0334857678800247
Validation loss: 2.5722270934690687

Epoch: 5| Step: 6
Training loss: 2.079644816223556
Validation loss: 2.575030564000237

Epoch: 5| Step: 7
Training loss: 2.6408332877993215
Validation loss: 2.5764916187574243

Epoch: 5| Step: 8
Training loss: 2.3363905247307253
Validation loss: 2.576082260350855

Epoch: 5| Step: 9
Training loss: 2.9544807026843447
Validation loss: 2.5745701836985218

Epoch: 5| Step: 10
Training loss: 3.0138955963419525
Validation loss: 2.567241832663574

Epoch: 5| Step: 11
Training loss: 2.1891033291327564
Validation loss: 2.5662081219563135

Epoch: 80| Step: 0
Training loss: 2.579746175892359
Validation loss: 2.564540233038134

Epoch: 5| Step: 1
Training loss: 3.304395008896015
Validation loss: 2.561716320412459

Epoch: 5| Step: 2
Training loss: 2.717187454372798
Validation loss: 2.5582265459340787

Epoch: 5| Step: 3
Training loss: 2.3878296110301203
Validation loss: 2.5584453665922755

Epoch: 5| Step: 4
Training loss: 2.873418289958387
Validation loss: 2.556570671412604

Epoch: 5| Step: 5
Training loss: 2.432007494601196
Validation loss: 2.5558056731997754

Epoch: 5| Step: 6
Training loss: 2.6312812857682064
Validation loss: 2.5537830583297088

Epoch: 5| Step: 7
Training loss: 2.5611534302259127
Validation loss: 2.553229862022287

Epoch: 5| Step: 8
Training loss: 2.469790275720285
Validation loss: 2.5505628020063993

Epoch: 5| Step: 9
Training loss: 2.6101090546548362
Validation loss: 2.546841139461045

Epoch: 5| Step: 10
Training loss: 2.6164285498802404
Validation loss: 2.5453176476114487

Epoch: 5| Step: 11
Training loss: 3.405477453694573
Validation loss: 2.546693417057461

Epoch: 81| Step: 0
Training loss: 2.4230998233788963
Validation loss: 2.5475362180718943

Epoch: 5| Step: 1
Training loss: 2.392035373706865
Validation loss: 2.548153710327138

Epoch: 5| Step: 2
Training loss: 2.943520240969405
Validation loss: 2.5539254890402616

Epoch: 5| Step: 3
Training loss: 2.751452842489909
Validation loss: 2.546656304703681

Epoch: 5| Step: 4
Training loss: 2.597575663987319
Validation loss: 2.547902007436391

Epoch: 5| Step: 5
Training loss: 2.5241152204642323
Validation loss: 2.5423401789663296

Epoch: 5| Step: 6
Training loss: 2.922563604310475
Validation loss: 2.5479433241286893

Epoch: 5| Step: 7
Training loss: 3.1151746786012247
Validation loss: 2.5435769271395814

Epoch: 5| Step: 8
Training loss: 1.6650535963212825
Validation loss: 2.542745858779879

Epoch: 5| Step: 9
Training loss: 2.734072772080997
Validation loss: 2.541951039826709

Epoch: 5| Step: 10
Training loss: 2.9011334736312513
Validation loss: 2.5403143667435626

Epoch: 5| Step: 11
Training loss: 2.8761332393125185
Validation loss: 2.541051220772819

Epoch: 82| Step: 0
Training loss: 2.317642370992677
Validation loss: 2.539748563755622

Epoch: 5| Step: 1
Training loss: 2.4174815042886846
Validation loss: 2.5417015289563087

Epoch: 5| Step: 2
Training loss: 2.9980650065616214
Validation loss: 2.541692969441461

Epoch: 5| Step: 3
Training loss: 2.6242141455575583
Validation loss: 2.540446333724219

Epoch: 5| Step: 4
Training loss: 2.461473291593527
Validation loss: 2.540541709982945

Epoch: 5| Step: 5
Training loss: 2.8005056844203082
Validation loss: 2.5385816735042432

Epoch: 5| Step: 6
Training loss: 2.2728511932574675
Validation loss: 2.535672699960179

Epoch: 5| Step: 7
Training loss: 2.680168442343409
Validation loss: 2.5405218381062613

Epoch: 5| Step: 8
Training loss: 2.9783155030106587
Validation loss: 2.537708269538959

Epoch: 5| Step: 9
Training loss: 2.8086813540318754
Validation loss: 2.53689769696814

Epoch: 5| Step: 10
Training loss: 2.760255331446983
Validation loss: 2.5339753820131246

Epoch: 5| Step: 11
Training loss: 3.240276757182134
Validation loss: 2.5337727871117797

Epoch: 83| Step: 0
Training loss: 2.373199382638007
Validation loss: 2.5388412418306996

Epoch: 5| Step: 1
Training loss: 2.7067220932432776
Validation loss: 2.5331281828842664

Epoch: 5| Step: 2
Training loss: 2.954454233855432
Validation loss: 2.5337212198683963

Epoch: 5| Step: 3
Training loss: 3.184150132315452
Validation loss: 2.5328545096426

Epoch: 5| Step: 4
Training loss: 2.5405689641537177
Validation loss: 2.5367494738501715

Epoch: 5| Step: 5
Training loss: 2.454352199447566
Validation loss: 2.5331425126470646

Epoch: 5| Step: 6
Training loss: 2.579464928344411
Validation loss: 2.532089616117916

Epoch: 5| Step: 7
Training loss: 2.439716016471555
Validation loss: 2.530834016644919

Epoch: 5| Step: 8
Training loss: 2.883672818464362
Validation loss: 2.532211595935582

Epoch: 5| Step: 9
Training loss: 2.3574629355760286
Validation loss: 2.5345117565782163

Epoch: 5| Step: 10
Training loss: 2.5190200168712336
Validation loss: 2.5323714766380347

Epoch: 5| Step: 11
Training loss: 2.928345070042662
Validation loss: 2.5318397670847252

Epoch: 84| Step: 0
Training loss: 2.335066310749685
Validation loss: 2.5345245577471016

Epoch: 5| Step: 1
Training loss: 2.8356528231235525
Validation loss: 2.546454002830054

Epoch: 5| Step: 2
Training loss: 2.8583463892809986
Validation loss: 2.5523316256092414

Epoch: 5| Step: 3
Training loss: 2.328830074586033
Validation loss: 2.543176465748492

Epoch: 5| Step: 4
Training loss: 2.867548698936338
Validation loss: 2.545828715526765

Epoch: 5| Step: 5
Training loss: 2.810210419239604
Validation loss: 2.5410638482582923

Epoch: 5| Step: 6
Training loss: 2.558877943722909
Validation loss: 2.5281823961605747

Epoch: 5| Step: 7
Training loss: 2.735276079208859
Validation loss: 2.5276611065983463

Epoch: 5| Step: 8
Training loss: 3.0594001184509736
Validation loss: 2.5256722773351634

Epoch: 5| Step: 9
Training loss: 2.591799266730716
Validation loss: 2.52888119692723

Epoch: 5| Step: 10
Training loss: 2.531801799393055
Validation loss: 2.5304647098802264

Epoch: 5| Step: 11
Training loss: 2.0222541559699887
Validation loss: 2.533119308116412

Epoch: 85| Step: 0
Training loss: 2.5823741690897797
Validation loss: 2.5350507803413627

Epoch: 5| Step: 1
Training loss: 2.7392161211455197
Validation loss: 2.536251476137632

Epoch: 5| Step: 2
Training loss: 2.3654131896563637
Validation loss: 2.538376309520907

Epoch: 5| Step: 3
Training loss: 2.894738317334105
Validation loss: 2.5339963205941074

Epoch: 5| Step: 4
Training loss: 2.022755158011037
Validation loss: 2.539085767590455

Epoch: 5| Step: 5
Training loss: 3.1097631164318327
Validation loss: 2.5352446154225117

Epoch: 5| Step: 6
Training loss: 2.4844576264082696
Validation loss: 2.528806405644398

Epoch: 5| Step: 7
Training loss: 2.71952563216482
Validation loss: 2.529289502853588

Epoch: 5| Step: 8
Training loss: 2.6312116968986903
Validation loss: 2.52810838974446

Epoch: 5| Step: 9
Training loss: 2.7130312351069636
Validation loss: 2.5277447232564296

Epoch: 5| Step: 10
Training loss: 2.8594348671904717
Validation loss: 2.530688678841264

Epoch: 5| Step: 11
Training loss: 2.986249245299814
Validation loss: 2.5254253848251143

Epoch: 86| Step: 0
Training loss: 2.5200229845058444
Validation loss: 2.5264225243346177

Epoch: 5| Step: 1
Training loss: 2.9883433217103157
Validation loss: 2.526545288901763

Epoch: 5| Step: 2
Training loss: 2.5055113124770925
Validation loss: 2.5253196995475227

Epoch: 5| Step: 3
Training loss: 2.8959950646627113
Validation loss: 2.5235353653613197

Epoch: 5| Step: 4
Training loss: 2.496982088048424
Validation loss: 2.521802120345297

Epoch: 5| Step: 5
Training loss: 2.647218406766117
Validation loss: 2.5195402672579172

Epoch: 5| Step: 6
Training loss: 2.669760240798257
Validation loss: 2.5229502897492244

Epoch: 5| Step: 7
Training loss: 2.82793236176513
Validation loss: 2.517827414517819

Epoch: 5| Step: 8
Training loss: 2.483929480185905
Validation loss: 2.521488578747575

Epoch: 5| Step: 9
Training loss: 2.189075011953447
Validation loss: 2.5165347829476854

Epoch: 5| Step: 10
Training loss: 2.9354440514988496
Validation loss: 2.5186826001182134

Epoch: 5| Step: 11
Training loss: 1.4237108221516386
Validation loss: 2.5139397688599843

Epoch: 87| Step: 0
Training loss: 2.4460880889875805
Validation loss: 2.515039924838085

Epoch: 5| Step: 1
Training loss: 3.0393751910250977
Validation loss: 2.5214921324256254

Epoch: 5| Step: 2
Training loss: 3.1032015603754144
Validation loss: 2.518344676627366

Epoch: 5| Step: 3
Training loss: 2.598125857017436
Validation loss: 2.5177940274102624

Epoch: 5| Step: 4
Training loss: 2.812019815779387
Validation loss: 2.5163191751761547

Epoch: 5| Step: 5
Training loss: 2.3776387062084816
Validation loss: 2.514823841285965

Epoch: 5| Step: 6
Training loss: 2.2806760510130117
Validation loss: 2.5179807954035143

Epoch: 5| Step: 7
Training loss: 3.065832232549134
Validation loss: 2.519160465685445

Epoch: 5| Step: 8
Training loss: 2.229139690295361
Validation loss: 2.520233612339507

Epoch: 5| Step: 9
Training loss: 2.002807196819768
Validation loss: 2.512900051449324

Epoch: 5| Step: 10
Training loss: 2.780375653964882
Validation loss: 2.51702711469332

Epoch: 5| Step: 11
Training loss: 2.8295429531948457
Validation loss: 2.5180226069999234

Epoch: 88| Step: 0
Training loss: 3.138500804784944
Validation loss: 2.513457013688838

Epoch: 5| Step: 1
Training loss: 2.412840104712835
Validation loss: 2.5128498210269505

Epoch: 5| Step: 2
Training loss: 2.706455714488021
Validation loss: 2.517968336218345

Epoch: 5| Step: 3
Training loss: 2.4321161134632687
Validation loss: 2.514470251986176

Epoch: 5| Step: 4
Training loss: 2.4217543048932613
Validation loss: 2.5127411220549183

Epoch: 5| Step: 5
Training loss: 2.592557885931718
Validation loss: 2.5106665591097928

Epoch: 5| Step: 6
Training loss: 2.423363505057139
Validation loss: 2.515680754776235

Epoch: 5| Step: 7
Training loss: 3.233915287094955
Validation loss: 2.515611423432102

Epoch: 5| Step: 8
Training loss: 2.896577058056505
Validation loss: 2.5130545473884403

Epoch: 5| Step: 9
Training loss: 2.343603816241914
Validation loss: 2.515838590285613

Epoch: 5| Step: 10
Training loss: 2.204014050897579
Validation loss: 2.5160083123313886

Epoch: 5| Step: 11
Training loss: 2.448886197768108
Validation loss: 2.5115609126829397

Epoch: 89| Step: 0
Training loss: 2.971477179470304
Validation loss: 2.517686149542576

Epoch: 5| Step: 1
Training loss: 2.3128097945270816
Validation loss: 2.5097351389021685

Epoch: 5| Step: 2
Training loss: 1.996384093785726
Validation loss: 2.5178344572392217

Epoch: 5| Step: 3
Training loss: 3.0318569873407637
Validation loss: 2.51656357609841

Epoch: 5| Step: 4
Training loss: 2.957952842063095
Validation loss: 2.508603689181362

Epoch: 5| Step: 5
Training loss: 2.7288238853695344
Validation loss: 2.5064296573988374

Epoch: 5| Step: 6
Training loss: 2.4491570326529213
Validation loss: 2.510853058068297

Epoch: 5| Step: 7
Training loss: 2.2026832083495838
Validation loss: 2.5093805356596066

Epoch: 5| Step: 8
Training loss: 2.7511786622604584
Validation loss: 2.50915860010618

Epoch: 5| Step: 9
Training loss: 2.371578663444052
Validation loss: 2.5071526884435578

Epoch: 5| Step: 10
Training loss: 2.7220255095150527
Validation loss: 2.5058464511806653

Epoch: 5| Step: 11
Training loss: 3.234213414970357
Validation loss: 2.5063510292536377

Epoch: 90| Step: 0
Training loss: 2.73380879670777
Validation loss: 2.512354432660667

Epoch: 5| Step: 1
Training loss: 2.471536922363483
Validation loss: 2.5104720490758567

Epoch: 5| Step: 2
Training loss: 2.070372497840829
Validation loss: 2.506229441694003

Epoch: 5| Step: 3
Training loss: 2.1578757749833537
Validation loss: 2.507950787875931

Epoch: 5| Step: 4
Training loss: 2.861539927901089
Validation loss: 2.5041022776948885

Epoch: 5| Step: 5
Training loss: 2.5990438096866337
Validation loss: 2.503921933256439

Epoch: 5| Step: 6
Training loss: 2.5532413787651422
Validation loss: 2.5056636948966466

Epoch: 5| Step: 7
Training loss: 2.95395079677259
Validation loss: 2.5050354175544776

Epoch: 5| Step: 8
Training loss: 1.9796757963417182
Validation loss: 2.503997245638778

Epoch: 5| Step: 9
Training loss: 3.195796267722653
Validation loss: 2.5038200359607994

Epoch: 5| Step: 10
Training loss: 2.7918589701298018
Validation loss: 2.5018951325913275

Epoch: 5| Step: 11
Training loss: 3.248307887982886
Validation loss: 2.5074256685775693

Epoch: 91| Step: 0
Training loss: 2.2877181861090223
Validation loss: 2.5026160142970744

Epoch: 5| Step: 1
Training loss: 3.0121139089010747
Validation loss: 2.5028920929271155

Epoch: 5| Step: 2
Training loss: 2.368576397736941
Validation loss: 2.5092119766493277

Epoch: 5| Step: 3
Training loss: 2.787468377177734
Validation loss: 2.5086554737589846

Epoch: 5| Step: 4
Training loss: 2.8691628950590777
Validation loss: 2.5048966177497354

Epoch: 5| Step: 5
Training loss: 2.1342827616430604
Validation loss: 2.502541922682734

Epoch: 5| Step: 6
Training loss: 2.924421210774841
Validation loss: 2.503236297152369

Epoch: 5| Step: 7
Training loss: 2.679404641395234
Validation loss: 2.5057449770608162

Epoch: 5| Step: 8
Training loss: 2.4941677728309135
Validation loss: 2.5021759874963503

Epoch: 5| Step: 9
Training loss: 2.7581550018041137
Validation loss: 2.5062785146205746

Epoch: 5| Step: 10
Training loss: 2.598307454794115
Validation loss: 2.506054881262393

Epoch: 5| Step: 11
Training loss: 1.2202095193430003
Validation loss: 2.50125823941479

Epoch: 92| Step: 0
Training loss: 2.799299840580345
Validation loss: 2.502169895236439

Epoch: 5| Step: 1
Training loss: 2.8209580292931418
Validation loss: 2.504739925084157

Epoch: 5| Step: 2
Training loss: 1.980020084760889
Validation loss: 2.5038971050252163

Epoch: 5| Step: 3
Training loss: 3.11953119497206
Validation loss: 2.5000036199861384

Epoch: 5| Step: 4
Training loss: 2.586018079902482
Validation loss: 2.5049770325110967

Epoch: 5| Step: 5
Training loss: 2.54032664594115
Validation loss: 2.5048772562720116

Epoch: 5| Step: 6
Training loss: 2.9570635008974433
Validation loss: 2.501648812172051

Epoch: 5| Step: 7
Training loss: 2.7031783611344835
Validation loss: 2.5060549763994056

Epoch: 5| Step: 8
Training loss: 2.3736615676035853
Validation loss: 2.5059263320028937

Epoch: 5| Step: 9
Training loss: 2.352432444916952
Validation loss: 2.5039238495190843

Epoch: 5| Step: 10
Training loss: 2.346068087858891
Validation loss: 2.5019043226046076

Epoch: 5| Step: 11
Training loss: 1.812665734441774
Validation loss: 2.504921685921659

Epoch: 93| Step: 0
Training loss: 2.6685693827131427
Validation loss: 2.5035780931173788

Epoch: 5| Step: 1
Training loss: 2.435581626124123
Validation loss: 2.5070275834182456

Epoch: 5| Step: 2
Training loss: 2.4348123845506917
Validation loss: 2.5074434533720735

Epoch: 5| Step: 3
Training loss: 2.8441681606833864
Validation loss: 2.5132368650460926

Epoch: 5| Step: 4
Training loss: 2.2126713616341553
Validation loss: 2.505059034904432

Epoch: 5| Step: 5
Training loss: 2.8890615823268724
Validation loss: 2.509995323584609

Epoch: 5| Step: 6
Training loss: 2.672859412095708
Validation loss: 2.5125531421880374

Epoch: 5| Step: 7
Training loss: 2.707628676860587
Validation loss: 2.5142369360160646

Epoch: 5| Step: 8
Training loss: 2.9125720756027746
Validation loss: 2.5159173996918085

Epoch: 5| Step: 9
Training loss: 2.1382379518417234
Validation loss: 2.4967016754340032

Epoch: 5| Step: 10
Training loss: 2.9386448354008228
Validation loss: 2.504805730138093

Epoch: 5| Step: 11
Training loss: 1.9516777474892097
Validation loss: 2.498855316839476

Epoch: 94| Step: 0
Training loss: 2.6477006545498143
Validation loss: 2.4999199556411114

Epoch: 5| Step: 1
Training loss: 2.637208613349484
Validation loss: 2.5007717848613247

Epoch: 5| Step: 2
Training loss: 1.9647845340853178
Validation loss: 2.503338801555359

Epoch: 5| Step: 3
Training loss: 2.511258808460424
Validation loss: 2.498980091589121

Epoch: 5| Step: 4
Training loss: 2.376194201942564
Validation loss: 2.4986770984179314

Epoch: 5| Step: 5
Training loss: 3.00308069361177
Validation loss: 2.4973870927951407

Epoch: 5| Step: 6
Training loss: 3.2969123151213218
Validation loss: 2.501072935496493

Epoch: 5| Step: 7
Training loss: 2.552874373761229
Validation loss: 2.4979147241079516

Epoch: 5| Step: 8
Training loss: 2.8351107987108364
Validation loss: 2.497292616258893

Epoch: 5| Step: 9
Training loss: 2.583991202808912
Validation loss: 2.4978909974506616

Epoch: 5| Step: 10
Training loss: 2.347525543788918
Validation loss: 2.4996326415047254

Epoch: 5| Step: 11
Training loss: 1.4165290690898864
Validation loss: 2.4952630186420035

Epoch: 95| Step: 0
Training loss: 2.7948200199273336
Validation loss: 2.5015411037695183

Epoch: 5| Step: 1
Training loss: 2.4872205260962628
Validation loss: 2.4945432875132036

Epoch: 5| Step: 2
Training loss: 2.6047553554179266
Validation loss: 2.492888460666546

Epoch: 5| Step: 3
Training loss: 2.8467167061808283
Validation loss: 2.4975189891967724

Epoch: 5| Step: 4
Training loss: 2.6212152717265367
Validation loss: 2.4967513036663704

Epoch: 5| Step: 5
Training loss: 2.8629328371325165
Validation loss: 2.4978806015562967

Epoch: 5| Step: 6
Training loss: 2.1184156170862902
Validation loss: 2.496543010066262

Epoch: 5| Step: 7
Training loss: 1.9442699656845215
Validation loss: 2.4942010340971237

Epoch: 5| Step: 8
Training loss: 2.5519525195999395
Validation loss: 2.4978205598462275

Epoch: 5| Step: 9
Training loss: 3.1651708851462876
Validation loss: 2.497567431799999

Epoch: 5| Step: 10
Training loss: 2.6341808170597045
Validation loss: 2.496439930167995

Epoch: 5| Step: 11
Training loss: 2.179992107587054
Validation loss: 2.49580731885171

Epoch: 96| Step: 0
Training loss: 2.654151985531082
Validation loss: 2.4960133634626245

Epoch: 5| Step: 1
Training loss: 2.583690023921111
Validation loss: 2.4968849802593582

Epoch: 5| Step: 2
Training loss: 2.230353945368011
Validation loss: 2.4937578712664217

Epoch: 5| Step: 3
Training loss: 2.620609790222005
Validation loss: 2.4967808461808456

Epoch: 5| Step: 4
Training loss: 2.430054173905688
Validation loss: 2.494795515871098

Epoch: 5| Step: 5
Training loss: 2.679283445274286
Validation loss: 2.496455103229516

Epoch: 5| Step: 6
Training loss: 2.5437394013055172
Validation loss: 2.4920052289328765

Epoch: 5| Step: 7
Training loss: 2.815072642010746
Validation loss: 2.496726439937835

Epoch: 5| Step: 8
Training loss: 2.6073282403599505
Validation loss: 2.494703320483295

Epoch: 5| Step: 9
Training loss: 2.732413760235225
Validation loss: 2.4939849773085565

Epoch: 5| Step: 10
Training loss: 2.9559238632989375
Validation loss: 2.4960631884563043

Epoch: 5| Step: 11
Training loss: 1.584154677261235
Validation loss: 2.4984265422441583

Epoch: 97| Step: 0
Training loss: 2.9855373176282978
Validation loss: 2.4900046727571983

Epoch: 5| Step: 1
Training loss: 3.1672934530910086
Validation loss: 2.493477080125395

Epoch: 5| Step: 2
Training loss: 2.6077307357449553
Validation loss: 2.492031989432638

Epoch: 5| Step: 3
Training loss: 2.4722322459023633
Validation loss: 2.4911971321755244

Epoch: 5| Step: 4
Training loss: 2.565858268587722
Validation loss: 2.490135723478694

Epoch: 5| Step: 5
Training loss: 2.3060573838596925
Validation loss: 2.4914588062209266

Epoch: 5| Step: 6
Training loss: 2.9493154345699906
Validation loss: 2.488820854377802

Epoch: 5| Step: 7
Training loss: 2.571688205614785
Validation loss: 2.4832937418792045

Epoch: 5| Step: 8
Training loss: 2.032468694279225
Validation loss: 2.4776102731685725

Epoch: 5| Step: 9
Training loss: 2.7183186857607327
Validation loss: 2.497973504876704

Epoch: 5| Step: 10
Training loss: 1.8399617993494282
Validation loss: 2.4932244912741126

Epoch: 5| Step: 11
Training loss: 2.253222171629802
Validation loss: 2.5037252407338446

Epoch: 98| Step: 0
Training loss: 2.4027759194290335
Validation loss: 2.509607453068575

Epoch: 5| Step: 1
Training loss: 2.7425635968383006
Validation loss: 2.5175577759197796

Epoch: 5| Step: 2
Training loss: 2.9533912498300583
Validation loss: 2.524689414024454

Epoch: 5| Step: 3
Training loss: 2.492633552455104
Validation loss: 2.4984650867013505

Epoch: 5| Step: 4
Training loss: 2.314443853818456
Validation loss: 2.5003917705014986

Epoch: 5| Step: 5
Training loss: 2.652311659156703
Validation loss: 2.4939232604309844

Epoch: 5| Step: 6
Training loss: 2.6365277708614103
Validation loss: 2.488666067504334

Epoch: 5| Step: 7
Training loss: 2.1145419663265037
Validation loss: 2.493153387899292

Epoch: 5| Step: 8
Training loss: 2.330119667418338
Validation loss: 2.491562488912674

Epoch: 5| Step: 9
Training loss: 3.0929055650948554
Validation loss: 2.491609795398711

Epoch: 5| Step: 10
Training loss: 3.144249035035827
Validation loss: 2.492673820472417

Epoch: 5| Step: 11
Training loss: 1.8459521574720676
Validation loss: 2.4960642908911996

Epoch: 99| Step: 0
Training loss: 2.2679399962249995
Validation loss: 2.504903922881266

Epoch: 5| Step: 1
Training loss: 2.699045355122809
Validation loss: 2.510542096108276

Epoch: 5| Step: 2
Training loss: 2.6431138087063006
Validation loss: 2.5155337022914535

Epoch: 5| Step: 3
Training loss: 2.42243626151465
Validation loss: 2.5220646740798593

Epoch: 5| Step: 4
Training loss: 2.7861472743501725
Validation loss: 2.5193734565628563

Epoch: 5| Step: 5
Training loss: 2.8343309628263134
Validation loss: 2.5213149230735588

Epoch: 5| Step: 6
Training loss: 2.3787589191985186
Validation loss: 2.5214321368435533

Epoch: 5| Step: 7
Training loss: 2.766135561955169
Validation loss: 2.525468565959279

Epoch: 5| Step: 8
Training loss: 2.8253231606431592
Validation loss: 2.51819990996467

Epoch: 5| Step: 9
Training loss: 2.5662915162055695
Validation loss: 2.5146704772180906

Epoch: 5| Step: 10
Training loss: 2.5972153827307456
Validation loss: 2.511542761507052

Epoch: 5| Step: 11
Training loss: 3.3588787333297465
Validation loss: 2.50495876224379

Epoch: 100| Step: 0
Training loss: 2.6117597635502388
Validation loss: 2.5005177359127115

Epoch: 5| Step: 1
Training loss: 2.63538033883811
Validation loss: 2.50110547737554

Epoch: 5| Step: 2
Training loss: 2.4167727962297554
Validation loss: 2.494522730614363

Epoch: 5| Step: 3
Training loss: 2.53777386169369
Validation loss: 2.4912821880276654

Epoch: 5| Step: 4
Training loss: 2.834374535675179
Validation loss: 2.490608568189176

Epoch: 5| Step: 5
Training loss: 2.868220753770253
Validation loss: 2.491671342324385

Epoch: 5| Step: 6
Training loss: 1.943222332440289
Validation loss: 2.4870101141210763

Epoch: 5| Step: 7
Training loss: 2.727550076340545
Validation loss: 2.4835183208059384

Epoch: 5| Step: 8
Training loss: 2.657074654417284
Validation loss: 2.490077473802499

Epoch: 5| Step: 9
Training loss: 2.8422213627337816
Validation loss: 2.4864886267779283

Epoch: 5| Step: 10
Training loss: 2.5072884175419934
Validation loss: 2.482152016270941

Epoch: 5| Step: 11
Training loss: 2.0750669767302115
Validation loss: 2.4833123835590984

Epoch: 101| Step: 0
Training loss: 2.6021355808246525
Validation loss: 2.4834319790079995

Epoch: 5| Step: 1
Training loss: 2.641958498153053
Validation loss: 2.4819943920100833

Epoch: 5| Step: 2
Training loss: 2.5524544478488753
Validation loss: 2.4803811125404844

Epoch: 5| Step: 3
Training loss: 2.7207164449153485
Validation loss: 2.478328183709006

Epoch: 5| Step: 4
Training loss: 2.693045107492403
Validation loss: 2.4833116394947283

Epoch: 5| Step: 5
Training loss: 2.518472422409613
Validation loss: 2.4875230437478155

Epoch: 5| Step: 6
Training loss: 2.227843120448528
Validation loss: 2.482208290786243

Epoch: 5| Step: 7
Training loss: 2.6952435913122974
Validation loss: 2.494261923648143

Epoch: 5| Step: 8
Training loss: 2.796885399825724
Validation loss: 2.493819906932789

Epoch: 5| Step: 9
Training loss: 2.6163221152655565
Validation loss: 2.4868732163527603

Epoch: 5| Step: 10
Training loss: 2.3964153301611444
Validation loss: 2.4881383235012193

Epoch: 5| Step: 11
Training loss: 3.288778333552764
Validation loss: 2.4774698987826542

Epoch: 102| Step: 0
Training loss: 2.347486645352826
Validation loss: 2.485076305483039

Epoch: 5| Step: 1
Training loss: 2.4667587941810267
Validation loss: 2.485927041009991

Epoch: 5| Step: 2
Training loss: 2.496628395096211
Validation loss: 2.487533161447081

Epoch: 5| Step: 3
Training loss: 2.584484049146554
Validation loss: 2.4872378283030407

Epoch: 5| Step: 4
Training loss: 2.9600089436473276
Validation loss: 2.486061759159346

Epoch: 5| Step: 5
Training loss: 2.569533209656443
Validation loss: 2.487049378740447

Epoch: 5| Step: 6
Training loss: 2.6397342420964436
Validation loss: 2.488546831379243

Epoch: 5| Step: 7
Training loss: 2.5747506919094674
Validation loss: 2.485364860693948

Epoch: 5| Step: 8
Training loss: 2.019489929839015
Validation loss: 2.490311649095943

Epoch: 5| Step: 9
Training loss: 2.8475891021640014
Validation loss: 2.489919090507626

Epoch: 5| Step: 10
Training loss: 2.702501346330193
Validation loss: 2.488189643678734

Epoch: 5| Step: 11
Training loss: 3.088515351790739
Validation loss: 2.486335029202904

Epoch: 103| Step: 0
Training loss: 2.3382905571800445
Validation loss: 2.4879685529316564

Epoch: 5| Step: 1
Training loss: 2.4872940476620196
Validation loss: 2.480806470893614

Epoch: 5| Step: 2
Training loss: 2.612842289162024
Validation loss: 2.4834349431194784

Epoch: 5| Step: 3
Training loss: 2.2937859763668444
Validation loss: 2.480829936486395

Epoch: 5| Step: 4
Training loss: 2.572051135644966
Validation loss: 2.489082271372082

Epoch: 5| Step: 5
Training loss: 2.6107463773566946
Validation loss: 2.488755895996263

Epoch: 5| Step: 6
Training loss: 2.572743851473164
Validation loss: 2.482546483315684

Epoch: 5| Step: 7
Training loss: 2.8370470130744274
Validation loss: 2.48271728886826

Epoch: 5| Step: 8
Training loss: 2.3975053895764438
Validation loss: 2.481032520215081

Epoch: 5| Step: 9
Training loss: 2.801065044842231
Validation loss: 2.482394510674091

Epoch: 5| Step: 10
Training loss: 2.7303885910645267
Validation loss: 2.4767408657725056

Epoch: 5| Step: 11
Training loss: 2.535832342857379
Validation loss: 2.4828569584701725

Epoch: 104| Step: 0
Training loss: 2.377601202927769
Validation loss: 2.4770265098408837

Epoch: 5| Step: 1
Training loss: 1.9467782622622927
Validation loss: 2.4842061479236324

Epoch: 5| Step: 2
Training loss: 2.732920930346035
Validation loss: 2.4893150158397033

Epoch: 5| Step: 3
Training loss: 2.7026876636035153
Validation loss: 2.49838394543425

Epoch: 5| Step: 4
Training loss: 2.8522316343558964
Validation loss: 2.502514710880095

Epoch: 5| Step: 5
Training loss: 2.7801163323850746
Validation loss: 2.4891729389026933

Epoch: 5| Step: 6
Training loss: 3.080241603540482
Validation loss: 2.479264122519378

Epoch: 5| Step: 7
Training loss: 2.1340273796048344
Validation loss: 2.4796349232834

Epoch: 5| Step: 8
Training loss: 2.0818870737853157
Validation loss: 2.4829865680490797

Epoch: 5| Step: 9
Training loss: 2.7417311764193806
Validation loss: 2.4857539542561033

Epoch: 5| Step: 10
Training loss: 3.0703375041225014
Validation loss: 2.4853448034568064

Epoch: 5| Step: 11
Training loss: 2.4380557087016923
Validation loss: 2.4824967231741666

Epoch: 105| Step: 0
Training loss: 2.566185231903515
Validation loss: 2.4877237786382014

Epoch: 5| Step: 1
Training loss: 2.1578613010553496
Validation loss: 2.483592599950706

Epoch: 5| Step: 2
Training loss: 2.3684129218469447
Validation loss: 2.48435581647716

Epoch: 5| Step: 3
Training loss: 2.66189137697612
Validation loss: 2.4837717567467497

Epoch: 5| Step: 4
Training loss: 2.454815713215974
Validation loss: 2.4830049619826107

Epoch: 5| Step: 5
Training loss: 2.8782351991512614
Validation loss: 2.4847340354356673

Epoch: 5| Step: 6
Training loss: 2.44745559137753
Validation loss: 2.484573520270193

Epoch: 5| Step: 7
Training loss: 2.959369334746178
Validation loss: 2.4817362433014756

Epoch: 5| Step: 8
Training loss: 2.801767683626738
Validation loss: 2.4832633668422073

Epoch: 5| Step: 9
Training loss: 2.8031605253658305
Validation loss: 2.4800379101101453

Epoch: 5| Step: 10
Training loss: 2.4813466358344107
Validation loss: 2.4813722581955067

Epoch: 5| Step: 11
Training loss: 2.1364062985674317
Validation loss: 2.4906670527336217

Epoch: 106| Step: 0
Training loss: 1.868938183957758
Validation loss: 2.4798991072356404

Epoch: 5| Step: 1
Training loss: 2.8262289867944386
Validation loss: 2.4782684740029395

Epoch: 5| Step: 2
Training loss: 2.62134042593901
Validation loss: 2.478225145886009

Epoch: 5| Step: 3
Training loss: 2.851592264934552
Validation loss: 2.4755947436414965

Epoch: 5| Step: 4
Training loss: 2.4134089995828676
Validation loss: 2.483227302754008

Epoch: 5| Step: 5
Training loss: 2.2635469574975438
Validation loss: 2.4830465903817758

Epoch: 5| Step: 6
Training loss: 2.5486588111268773
Validation loss: 2.476796063982931

Epoch: 5| Step: 7
Training loss: 2.4598601389878545
Validation loss: 2.476185421962523

Epoch: 5| Step: 8
Training loss: 2.795435188547855
Validation loss: 2.4770587239488076

Epoch: 5| Step: 9
Training loss: 2.654687758653975
Validation loss: 2.478610121877265

Epoch: 5| Step: 10
Training loss: 3.1152683555160836
Validation loss: 2.4740950268911264

Epoch: 5| Step: 11
Training loss: 1.4631286345986283
Validation loss: 2.4724147411518387

Epoch: 107| Step: 0
Training loss: 2.4101434889692053
Validation loss: 2.4745573797586875

Epoch: 5| Step: 1
Training loss: 2.398893729193188
Validation loss: 2.4757645140676376

Epoch: 5| Step: 2
Training loss: 2.744593073243338
Validation loss: 2.481104263234382

Epoch: 5| Step: 3
Training loss: 2.417329423285112
Validation loss: 2.4738082652838598

Epoch: 5| Step: 4
Training loss: 2.6086661466712866
Validation loss: 2.4805529402414934

Epoch: 5| Step: 5
Training loss: 2.888567547980841
Validation loss: 2.476989909774584

Epoch: 5| Step: 6
Training loss: 2.526090756493179
Validation loss: 2.4751654995868924

Epoch: 5| Step: 7
Training loss: 2.684457609351019
Validation loss: 2.47146609541599

Epoch: 5| Step: 8
Training loss: 2.4433849403513643
Validation loss: 2.4784923178616776

Epoch: 5| Step: 9
Training loss: 2.7566076137517013
Validation loss: 2.476499835484083

Epoch: 5| Step: 10
Training loss: 2.5037315176759187
Validation loss: 2.4719799496908514

Epoch: 5| Step: 11
Training loss: 1.2046618863362597
Validation loss: 2.4747642583030705

Epoch: 108| Step: 0
Training loss: 2.519757874225311
Validation loss: 2.4732869384977834

Epoch: 5| Step: 1
Training loss: 2.5444761809637644
Validation loss: 2.4730640454766486

Epoch: 5| Step: 2
Training loss: 2.9744413732925206
Validation loss: 2.4736868070203086

Epoch: 5| Step: 3
Training loss: 2.0816617999339373
Validation loss: 2.469647304821314

Epoch: 5| Step: 4
Training loss: 2.5480325326803928
Validation loss: 2.479967650412745

Epoch: 5| Step: 5
Training loss: 2.465627603082286
Validation loss: 2.4796545579753686

Epoch: 5| Step: 6
Training loss: 2.7401245704233936
Validation loss: 2.4785233846452277

Epoch: 5| Step: 7
Training loss: 2.504533376729116
Validation loss: 2.467826896021026

Epoch: 5| Step: 8
Training loss: 2.8764256798625025
Validation loss: 2.4694356710572283

Epoch: 5| Step: 9
Training loss: 2.5435067587736993
Validation loss: 2.474269788444711

Epoch: 5| Step: 10
Training loss: 2.4182173149765496
Validation loss: 2.4824296424438064

Epoch: 5| Step: 11
Training loss: 2.2657635876592144
Validation loss: 2.48205184679828

Epoch: 109| Step: 0
Training loss: 2.4984376794028917
Validation loss: 2.4823429146130933

Epoch: 5| Step: 1
Training loss: 2.767847321312702
Validation loss: 2.4877532247027214

Epoch: 5| Step: 2
Training loss: 2.3070774940534866
Validation loss: 2.482133910181636

Epoch: 5| Step: 3
Training loss: 2.3283948293914554
Validation loss: 2.4888710987665332

Epoch: 5| Step: 4
Training loss: 2.643426345962206
Validation loss: 2.4882826872481623

Epoch: 5| Step: 5
Training loss: 2.7311184919109444
Validation loss: 2.489849237316873

Epoch: 5| Step: 6
Training loss: 2.3659099492907747
Validation loss: 2.489996948891421

Epoch: 5| Step: 7
Training loss: 2.9135993814508576
Validation loss: 2.489653683443888

Epoch: 5| Step: 8
Training loss: 2.6286491279639352
Validation loss: 2.491414682751437

Epoch: 5| Step: 9
Training loss: 2.8133182606888423
Validation loss: 2.4905345222251922

Epoch: 5| Step: 10
Training loss: 2.4916103735170894
Validation loss: 2.4896767703815037

Epoch: 5| Step: 11
Training loss: 3.2730674807651887
Validation loss: 2.4935968453997823

Epoch: 110| Step: 0
Training loss: 2.515275445191947
Validation loss: 2.4900781440345887

Epoch: 5| Step: 1
Training loss: 2.620556385425728
Validation loss: 2.491796211688702

Epoch: 5| Step: 2
Training loss: 2.6589072007666643
Validation loss: 2.4900044493399296

Epoch: 5| Step: 3
Training loss: 2.546672789614575
Validation loss: 2.4907624127410126

Epoch: 5| Step: 4
Training loss: 2.0549276813488424
Validation loss: 2.4890724872389542

Epoch: 5| Step: 5
Training loss: 2.3406096718952165
Validation loss: 2.488096205349828

Epoch: 5| Step: 6
Training loss: 3.345652814265263
Validation loss: 2.4862251709915655

Epoch: 5| Step: 7
Training loss: 2.39127545452379
Validation loss: 2.4853689017000145

Epoch: 5| Step: 8
Training loss: 2.5781632854046497
Validation loss: 2.4840672100388965

Epoch: 5| Step: 9
Training loss: 2.827698733414351
Validation loss: 2.4854700446225895

Epoch: 5| Step: 10
Training loss: 2.7059600604282417
Validation loss: 2.480881403842901

Epoch: 5| Step: 11
Training loss: 2.063776141624386
Validation loss: 2.4805034284595533

Epoch: 111| Step: 0
Training loss: 2.7554415704453663
Validation loss: 2.477633684832646

Epoch: 5| Step: 1
Training loss: 2.4321946336449716
Validation loss: 2.4861215014628324

Epoch: 5| Step: 2
Training loss: 3.0079925879529172
Validation loss: 2.4802036454114917

Epoch: 5| Step: 3
Training loss: 2.77357899479511
Validation loss: 2.4781651330482575

Epoch: 5| Step: 4
Training loss: 2.593422742673627
Validation loss: 2.47432179374433

Epoch: 5| Step: 5
Training loss: 2.6775995689421377
Validation loss: 2.474732445855726

Epoch: 5| Step: 6
Training loss: 2.6079404622402413
Validation loss: 2.4795526529947263

Epoch: 5| Step: 7
Training loss: 2.4544994610031883
Validation loss: 2.4746445028837156

Epoch: 5| Step: 8
Training loss: 2.3189909282867136
Validation loss: 2.4691895001162805

Epoch: 5| Step: 9
Training loss: 2.660301977526856
Validation loss: 2.467737358382026

Epoch: 5| Step: 10
Training loss: 1.9923520487727011
Validation loss: 2.47044394318536

Epoch: 5| Step: 11
Training loss: 2.5158232616700165
Validation loss: 2.4680852115657146

Epoch: 112| Step: 0
Training loss: 2.552754735537108
Validation loss: 2.4681259766936816

Epoch: 5| Step: 1
Training loss: 2.3591545962024107
Validation loss: 2.4665086204784923

Epoch: 5| Step: 2
Training loss: 2.9379541573580252
Validation loss: 2.4685887312224892

Epoch: 5| Step: 3
Training loss: 2.969778745996223
Validation loss: 2.4662795401516933

Epoch: 5| Step: 4
Training loss: 2.7109185034006607
Validation loss: 2.4687266248087294

Epoch: 5| Step: 5
Training loss: 2.1237472880830564
Validation loss: 2.482775003011236

Epoch: 5| Step: 6
Training loss: 2.5074634725053295
Validation loss: 2.4734836317022917

Epoch: 5| Step: 7
Training loss: 2.437580009516695
Validation loss: 2.471817259952075

Epoch: 5| Step: 8
Training loss: 2.490202684387814
Validation loss: 2.4743825662511205

Epoch: 5| Step: 9
Training loss: 2.7285982855343147
Validation loss: 2.468851377119899

Epoch: 5| Step: 10
Training loss: 2.725356920298253
Validation loss: 2.4661782828871193

Epoch: 5| Step: 11
Training loss: 1.6068728356363504
Validation loss: 2.469488118080739

Epoch: 113| Step: 0
Training loss: 2.6721455398029264
Validation loss: 2.4785599300030903

Epoch: 5| Step: 1
Training loss: 2.6697982837616334
Validation loss: 2.478465815996312

Epoch: 5| Step: 2
Training loss: 2.46449289378997
Validation loss: 2.480374299901929

Epoch: 5| Step: 3
Training loss: 2.675065216267708
Validation loss: 2.4845462156273315

Epoch: 5| Step: 4
Training loss: 2.675127960424468
Validation loss: 2.481240256167865

Epoch: 5| Step: 5
Training loss: 1.7355520017807042
Validation loss: 2.4841796510295864

Epoch: 5| Step: 6
Training loss: 2.488835582938119
Validation loss: 2.486294558633878

Epoch: 5| Step: 7
Training loss: 2.9584348061221823
Validation loss: 2.48137683816468

Epoch: 5| Step: 8
Training loss: 2.905077297738386
Validation loss: 2.4794668061363483

Epoch: 5| Step: 9
Training loss: 2.8948572466874305
Validation loss: 2.4799423820713984

Epoch: 5| Step: 10
Training loss: 2.2193324439422364
Validation loss: 2.477008659054279

Epoch: 5| Step: 11
Training loss: 1.4955298254877232
Validation loss: 2.480085123989259

Epoch: 114| Step: 0
Training loss: 2.3536345519096358
Validation loss: 2.4812079542170498

Epoch: 5| Step: 1
Training loss: 2.1091717657446845
Validation loss: 2.4782163510957202

Epoch: 5| Step: 2
Training loss: 2.699150029368964
Validation loss: 2.4733318713557435

Epoch: 5| Step: 3
Training loss: 2.4860490640845456
Validation loss: 2.471620838073098

Epoch: 5| Step: 4
Training loss: 2.4194889250894227
Validation loss: 2.4743239778386092

Epoch: 5| Step: 5
Training loss: 2.793781039686393
Validation loss: 2.4771277808417147

Epoch: 5| Step: 6
Training loss: 2.9814579473303358
Validation loss: 2.4764046844356167

Epoch: 5| Step: 7
Training loss: 2.316272442251429
Validation loss: 2.47406136281489

Epoch: 5| Step: 8
Training loss: 2.5173265850871096
Validation loss: 2.473420401196991

Epoch: 5| Step: 9
Training loss: 2.6578094392699434
Validation loss: 2.47909379632961

Epoch: 5| Step: 10
Training loss: 2.7704992068953413
Validation loss: 2.473150066383346

Epoch: 5| Step: 11
Training loss: 2.743558100982517
Validation loss: 2.469434458175204

Epoch: 115| Step: 0
Training loss: 2.444375733170854
Validation loss: 2.47128445266032

Epoch: 5| Step: 1
Training loss: 2.422896237559198
Validation loss: 2.470730763558458

Epoch: 5| Step: 2
Training loss: 2.1592569807513278
Validation loss: 2.4734760389861963

Epoch: 5| Step: 3
Training loss: 2.4469714889892007
Validation loss: 2.4647816258746347

Epoch: 5| Step: 4
Training loss: 3.0128002476153726
Validation loss: 2.4649850650667635

Epoch: 5| Step: 5
Training loss: 2.220981925969822
Validation loss: 2.4693424222254

Epoch: 5| Step: 6
Training loss: 2.3594576587471137
Validation loss: 2.464998823749811

Epoch: 5| Step: 7
Training loss: 2.479787177213985
Validation loss: 2.469874274906109

Epoch: 5| Step: 8
Training loss: 3.4243251441964837
Validation loss: 2.462186236167571

Epoch: 5| Step: 9
Training loss: 2.424050713584604
Validation loss: 2.4711098156564657

Epoch: 5| Step: 10
Training loss: 2.596098881870539
Validation loss: 2.4689419828684733

Epoch: 5| Step: 11
Training loss: 2.4132092396917617
Validation loss: 2.464647798160001

Epoch: 116| Step: 0
Training loss: 2.3753977994554845
Validation loss: 2.4710513466368647

Epoch: 5| Step: 1
Training loss: 2.7232824669908062
Validation loss: 2.472639777845303

Epoch: 5| Step: 2
Training loss: 2.571689132704374
Validation loss: 2.4797518677941452

Epoch: 5| Step: 3
Training loss: 1.9448806712361302
Validation loss: 2.478212045886178

Epoch: 5| Step: 4
Training loss: 3.072016507650766
Validation loss: 2.472496280648083

Epoch: 5| Step: 5
Training loss: 2.6705018915520737
Validation loss: 2.4821348987358975

Epoch: 5| Step: 6
Training loss: 2.426876490433103
Validation loss: 2.481097684808622

Epoch: 5| Step: 7
Training loss: 2.1664728175768366
Validation loss: 2.4808745405225836

Epoch: 5| Step: 8
Training loss: 2.435384957591427
Validation loss: 2.4730991892849157

Epoch: 5| Step: 9
Training loss: 2.943497885499651
Validation loss: 2.4731152165273778

Epoch: 5| Step: 10
Training loss: 2.6317524119978764
Validation loss: 2.4755396490641375

Epoch: 5| Step: 11
Training loss: 3.010704809916378
Validation loss: 2.477403391690862

Epoch: 117| Step: 0
Training loss: 2.958933612652449
Validation loss: 2.4810706742422353

Epoch: 5| Step: 1
Training loss: 2.547699964347726
Validation loss: 2.4813733951816497

Epoch: 5| Step: 2
Training loss: 2.406983796233537
Validation loss: 2.476578605110117

Epoch: 5| Step: 3
Training loss: 2.559826176970798
Validation loss: 2.474059652294971

Epoch: 5| Step: 4
Training loss: 2.5461047359298603
Validation loss: 2.482330408619728

Epoch: 5| Step: 5
Training loss: 2.521051182016623
Validation loss: 2.476730513464236

Epoch: 5| Step: 6
Training loss: 2.3776180493944254
Validation loss: 2.478587741468978

Epoch: 5| Step: 7
Training loss: 2.6166435017947363
Validation loss: 2.4779826684191226

Epoch: 5| Step: 8
Training loss: 2.814750618602272
Validation loss: 2.477713653302996

Epoch: 5| Step: 9
Training loss: 2.7524877046592846
Validation loss: 2.4760845697901614

Epoch: 5| Step: 10
Training loss: 2.442309403260046
Validation loss: 2.4753336901440592

Epoch: 5| Step: 11
Training loss: 1.620145589385239
Validation loss: 2.4764990532707216

Epoch: 118| Step: 0
Training loss: 2.7008964745723634
Validation loss: 2.480109786044181

Epoch: 5| Step: 1
Training loss: 2.3020739202752853
Validation loss: 2.4781595249344637

Epoch: 5| Step: 2
Training loss: 3.1804228361184785
Validation loss: 2.4751479343874805

Epoch: 5| Step: 3
Training loss: 2.592205460976522
Validation loss: 2.4745093096839756

Epoch: 5| Step: 4
Training loss: 2.3153592553079396
Validation loss: 2.4722292884506603

Epoch: 5| Step: 5
Training loss: 2.394008361578722
Validation loss: 2.4778201763579264

Epoch: 5| Step: 6
Training loss: 2.555947742453296
Validation loss: 2.471292180743469

Epoch: 5| Step: 7
Training loss: 2.533717518670245
Validation loss: 2.4743632068948793

Epoch: 5| Step: 8
Training loss: 2.2998125663346993
Validation loss: 2.4746249147492767

Epoch: 5| Step: 9
Training loss: 2.631024667691649
Validation loss: 2.4764910305553154

Epoch: 5| Step: 10
Training loss: 2.7702279445354416
Validation loss: 2.47812061253304

Epoch: 5| Step: 11
Training loss: 2.549935310141609
Validation loss: 2.479294750901286

Epoch: 119| Step: 0
Training loss: 2.957998301559074
Validation loss: 2.4740739025762104

Epoch: 5| Step: 1
Training loss: 2.7423474735210607
Validation loss: 2.467987405517887

Epoch: 5| Step: 2
Training loss: 2.6972230193842677
Validation loss: 2.4684727549302083

Epoch: 5| Step: 3
Training loss: 2.659517768945374
Validation loss: 2.471434055614188

Epoch: 5| Step: 4
Training loss: 2.4054600793843917
Validation loss: 2.4786737590471666

Epoch: 5| Step: 5
Training loss: 2.4640204600809943
Validation loss: 2.4805251027511845

Epoch: 5| Step: 6
Training loss: 2.1691957043250176
Validation loss: 2.4723268623983126

Epoch: 5| Step: 7
Training loss: 2.4938333750771973
Validation loss: 2.4773760561409004

Epoch: 5| Step: 8
Training loss: 2.190582827870916
Validation loss: 2.480389987766409

Epoch: 5| Step: 9
Training loss: 2.6401699057726677
Validation loss: 2.4642991332333124

Epoch: 5| Step: 10
Training loss: 2.756317684527593
Validation loss: 2.4742839291122594

Epoch: 5| Step: 11
Training loss: 2.696989914091301
Validation loss: 2.4688523870877277

Epoch: 120| Step: 0
Training loss: 2.367060289647359
Validation loss: 2.46756147393418

Epoch: 5| Step: 1
Training loss: 2.669047147480927
Validation loss: 2.4745960792238515

Epoch: 5| Step: 2
Training loss: 2.340271670229445
Validation loss: 2.4936919818270207

Epoch: 5| Step: 3
Training loss: 2.620374873766145
Validation loss: 2.47154807618674

Epoch: 5| Step: 4
Training loss: 2.768114510449784
Validation loss: 2.4775473143816438

Epoch: 5| Step: 5
Training loss: 2.0589571492727825
Validation loss: 2.469126129469939

Epoch: 5| Step: 6
Training loss: 2.8426976195446025
Validation loss: 2.474986207486906

Epoch: 5| Step: 7
Training loss: 2.6629826211279877
Validation loss: 2.4713684874837534

Epoch: 5| Step: 8
Training loss: 3.221610122581779
Validation loss: 2.474817230639993

Epoch: 5| Step: 9
Training loss: 2.4812750519609645
Validation loss: 2.470481301704587

Epoch: 5| Step: 10
Training loss: 2.369602092384481
Validation loss: 2.4745828997955313

Epoch: 5| Step: 11
Training loss: 0.8129669461586798
Validation loss: 2.471202139538104

Epoch: 121| Step: 0
Training loss: 2.3805595378132702
Validation loss: 2.4756470601839617

Epoch: 5| Step: 1
Training loss: 2.4548011447525275
Validation loss: 2.4736055236347294

Epoch: 5| Step: 2
Training loss: 2.2793598444199206
Validation loss: 2.4706118842002853

Epoch: 5| Step: 3
Training loss: 2.633910541611263
Validation loss: 2.4677432981380827

Epoch: 5| Step: 4
Training loss: 2.560091421908892
Validation loss: 2.473712508720819

Epoch: 5| Step: 5
Training loss: 3.1190849781745635
Validation loss: 2.4668496982761106

Epoch: 5| Step: 6
Training loss: 2.539983494322005
Validation loss: 2.464961108090465

Epoch: 5| Step: 7
Training loss: 2.6470467395755977
Validation loss: 2.4695824173402725

Epoch: 5| Step: 8
Training loss: 2.575876908844408
Validation loss: 2.4711176065971157

Epoch: 5| Step: 9
Training loss: 2.3006384502454007
Validation loss: 2.4722582440008183

Epoch: 5| Step: 10
Training loss: 2.697051352595118
Validation loss: 2.472071316812709

Epoch: 5| Step: 11
Training loss: 2.512557629735668
Validation loss: 2.4711962442753337

Epoch: 122| Step: 0
Training loss: 2.352202268239632
Validation loss: 2.4681167514689273

Epoch: 5| Step: 1
Training loss: 2.2123421564210264
Validation loss: 2.4692533599572144

Epoch: 5| Step: 2
Training loss: 2.324223571259443
Validation loss: 2.471014746513501

Epoch: 5| Step: 3
Training loss: 2.6940701040026336
Validation loss: 2.4745206628808893

Epoch: 5| Step: 4
Training loss: 2.078842154069925
Validation loss: 2.4787427969959515

Epoch: 5| Step: 5
Training loss: 2.493458390933054
Validation loss: 2.474725657809291

Epoch: 5| Step: 6
Training loss: 2.753336183240153
Validation loss: 2.4749268546678946

Epoch: 5| Step: 7
Training loss: 2.8965345855497127
Validation loss: 2.481093340555633

Epoch: 5| Step: 8
Training loss: 2.9991531766344486
Validation loss: 2.475845168847353

Epoch: 5| Step: 9
Training loss: 3.0411489037308064
Validation loss: 2.4763054899878996

Epoch: 5| Step: 10
Training loss: 2.350594051839962
Validation loss: 2.474775421665581

Epoch: 5| Step: 11
Training loss: 2.006970537038785
Validation loss: 2.4759091780066322

Epoch: 123| Step: 0
Training loss: 2.2119924232463517
Validation loss: 2.4713094216179456

Epoch: 5| Step: 1
Training loss: 2.566247758079326
Validation loss: 2.473960315636627

Epoch: 5| Step: 2
Training loss: 3.1031219636070553
Validation loss: 2.4743636164058493

Epoch: 5| Step: 3
Training loss: 2.5515115110274853
Validation loss: 2.4711032508251773

Epoch: 5| Step: 4
Training loss: 2.5591137539622957
Validation loss: 2.470972971698779

Epoch: 5| Step: 5
Training loss: 2.336292558816134
Validation loss: 2.4711918886459716

Epoch: 5| Step: 6
Training loss: 2.3784462870895506
Validation loss: 2.4743134508076263

Epoch: 5| Step: 7
Training loss: 2.694104086843994
Validation loss: 2.468572463319606

Epoch: 5| Step: 8
Training loss: 2.6954203266192267
Validation loss: 2.472708303296355

Epoch: 5| Step: 9
Training loss: 2.702444178227922
Validation loss: 2.46930089268589

Epoch: 5| Step: 10
Training loss: 2.395639583106356
Validation loss: 2.4732395386091106

Epoch: 5| Step: 11
Training loss: 2.033900365821689
Validation loss: 2.47552971308939

Epoch: 124| Step: 0
Training loss: 3.0168056252300914
Validation loss: 2.4711247985220735

Epoch: 5| Step: 1
Training loss: 2.4706710873663944
Validation loss: 2.4699819283718782

Epoch: 5| Step: 2
Training loss: 2.8216316329424513
Validation loss: 2.467898640527885

Epoch: 5| Step: 3
Training loss: 2.909101010706009
Validation loss: 2.4637463943600864

Epoch: 5| Step: 4
Training loss: 2.725983741347931
Validation loss: 2.463262664502193

Epoch: 5| Step: 5
Training loss: 2.4292255710725152
Validation loss: 2.463066278335376

Epoch: 5| Step: 6
Training loss: 2.5096181863307634
Validation loss: 2.4590538101957358

Epoch: 5| Step: 7
Training loss: 2.592503811310162
Validation loss: 2.4651392030647385

Epoch: 5| Step: 8
Training loss: 2.5361140106879105
Validation loss: 2.4617796894885307

Epoch: 5| Step: 9
Training loss: 1.9791446751493735
Validation loss: 2.474613995586639

Epoch: 5| Step: 10
Training loss: 2.1801493712531124
Validation loss: 2.4738951999572767

Epoch: 5| Step: 11
Training loss: 2.2484949164253574
Validation loss: 2.469337369361275

Epoch: 125| Step: 0
Training loss: 2.356550534456614
Validation loss: 2.471681564452927

Epoch: 5| Step: 1
Training loss: 2.585974378985517
Validation loss: 2.476228436744103

Epoch: 5| Step: 2
Training loss: 2.6381142321386966
Validation loss: 2.4751911598455085

Epoch: 5| Step: 3
Training loss: 2.712683475459495
Validation loss: 2.470778291988739

Epoch: 5| Step: 4
Training loss: 2.6011526340518283
Validation loss: 2.4746520558856298

Epoch: 5| Step: 5
Training loss: 2.5083457878876607
Validation loss: 2.477433509768464

Epoch: 5| Step: 6
Training loss: 2.639735416245261
Validation loss: 2.47378693371702

Epoch: 5| Step: 7
Training loss: 1.996678813436728
Validation loss: 2.4748267740901766

Epoch: 5| Step: 8
Training loss: 2.5590163951973173
Validation loss: 2.474971522944479

Epoch: 5| Step: 9
Training loss: 2.572474164916452
Validation loss: 2.4755130634203315

Epoch: 5| Step: 10
Training loss: 2.6056012487392697
Validation loss: 2.469763125401247

Epoch: 5| Step: 11
Training loss: 3.869812723601372
Validation loss: 2.4764971117759766

Epoch: 126| Step: 0
Training loss: 2.454161018231233
Validation loss: 2.47354553928124

Epoch: 5| Step: 1
Training loss: 2.6452504114118773
Validation loss: 2.474690773941651

Epoch: 5| Step: 2
Training loss: 2.391153713427431
Validation loss: 2.475796971301786

Epoch: 5| Step: 3
Training loss: 2.6477618860787113
Validation loss: 2.4738928548613695

Epoch: 5| Step: 4
Training loss: 3.0032763074851374
Validation loss: 2.4724841788685423

Epoch: 5| Step: 5
Training loss: 2.798693869991802
Validation loss: 2.4778429926808445

Epoch: 5| Step: 6
Training loss: 2.93508925839964
Validation loss: 2.477968845522577

Epoch: 5| Step: 7
Training loss: 2.4507361765721383
Validation loss: 2.4753098513853877

Epoch: 5| Step: 8
Training loss: 2.493178980566414
Validation loss: 2.485302885786727

Epoch: 5| Step: 9
Training loss: 2.2494702245297984
Validation loss: 2.47298691935537

Epoch: 5| Step: 10
Training loss: 2.2330323566871937
Validation loss: 2.4781326026046244

Epoch: 5| Step: 11
Training loss: 2.2082258114340227
Validation loss: 2.47184223558435

Epoch: 127| Step: 0
Training loss: 2.547529171672757
Validation loss: 2.474076568722842

Epoch: 5| Step: 1
Training loss: 2.0963139563706377
Validation loss: 2.4693331572922745

Epoch: 5| Step: 2
Training loss: 2.906396185367012
Validation loss: 2.4710228674136814

Epoch: 5| Step: 3
Training loss: 2.431714356311892
Validation loss: 2.471777934223449

Epoch: 5| Step: 4
Training loss: 3.0143330232630694
Validation loss: 2.4703210588049966

Epoch: 5| Step: 5
Training loss: 2.4766963116329284
Validation loss: 2.4699844058827694

Epoch: 5| Step: 6
Training loss: 2.0722407735903827
Validation loss: 2.4724774609892592

Epoch: 5| Step: 7
Training loss: 3.1078559577093707
Validation loss: 2.4681951084324134

Epoch: 5| Step: 8
Training loss: 2.4106003709147634
Validation loss: 2.470235767817536

Epoch: 5| Step: 9
Training loss: 2.7159823657714792
Validation loss: 2.4687533640134403

Epoch: 5| Step: 10
Training loss: 2.3659876435860885
Validation loss: 2.4754189298878715

Epoch: 5| Step: 11
Training loss: 2.1773681332660426
Validation loss: 2.46968754538571

Epoch: 128| Step: 0
Training loss: 2.4814366652372946
Validation loss: 2.4732511868313516

Epoch: 5| Step: 1
Training loss: 2.92661769507356
Validation loss: 2.471225491313612

Epoch: 5| Step: 2
Training loss: 2.5355434033939126
Validation loss: 2.470570380021024

Epoch: 5| Step: 3
Training loss: 2.52275439957789
Validation loss: 2.469405646520589

Epoch: 5| Step: 4
Training loss: 2.694413364095686
Validation loss: 2.473174982363587

Epoch: 5| Step: 5
Training loss: 3.009941477159124
Validation loss: 2.468458754023046

Epoch: 5| Step: 6
Training loss: 2.448764205198188
Validation loss: 2.4710308475791956

Epoch: 5| Step: 7
Training loss: 1.9518490705377134
Validation loss: 2.471314158918067

Epoch: 5| Step: 8
Training loss: 1.9576136166082243
Validation loss: 2.464453991333378

Epoch: 5| Step: 9
Training loss: 2.4018440036922692
Validation loss: 2.4743262823771737

Epoch: 5| Step: 10
Training loss: 3.0233375079355014
Validation loss: 2.4733472223247484

Epoch: 5| Step: 11
Training loss: 2.2855349495902133
Validation loss: 2.4689952108875692

Epoch: 129| Step: 0
Training loss: 2.4441108066519552
Validation loss: 2.4702483310202883

Epoch: 5| Step: 1
Training loss: 2.5634902343385417
Validation loss: 2.460779978236912

Epoch: 5| Step: 2
Training loss: 2.99493680298223
Validation loss: 2.467631517220834

Epoch: 5| Step: 3
Training loss: 3.184720940933232
Validation loss: 2.4624330366295535

Epoch: 5| Step: 4
Training loss: 2.023355607544383
Validation loss: 2.4587041540159214

Epoch: 5| Step: 5
Training loss: 2.3685509308679595
Validation loss: 2.457869170033334

Epoch: 5| Step: 6
Training loss: 2.257223402210732
Validation loss: 2.4670227422577

Epoch: 5| Step: 7
Training loss: 2.4951304694790815
Validation loss: 2.461631438897087

Epoch: 5| Step: 8
Training loss: 2.370598378352553
Validation loss: 2.463845882759613

Epoch: 5| Step: 9
Training loss: 2.8083361851105137
Validation loss: 2.466080131313497

Epoch: 5| Step: 10
Training loss: 2.513960293434268
Validation loss: 2.464499863194329

Epoch: 5| Step: 11
Training loss: 2.25577831040088
Validation loss: 2.463456962263708

Epoch: 130| Step: 0
Training loss: 2.39469344070536
Validation loss: 2.465954302178347

Epoch: 5| Step: 1
Training loss: 2.696749539070518
Validation loss: 2.473679518130075

Epoch: 5| Step: 2
Training loss: 2.635849285175956
Validation loss: 2.467825962117043

Epoch: 5| Step: 3
Training loss: 3.030154630032794
Validation loss: 2.467875973788217

Epoch: 5| Step: 4
Training loss: 2.217187035461764
Validation loss: 2.469237764275615

Epoch: 5| Step: 5
Training loss: 2.5857462740261536
Validation loss: 2.471068122852291

Epoch: 5| Step: 6
Training loss: 2.8915740233723226
Validation loss: 2.4729711965790355

Epoch: 5| Step: 7
Training loss: 2.0113022456427667
Validation loss: 2.4689137307932434

Epoch: 5| Step: 8
Training loss: 2.7819002227222542
Validation loss: 2.4648602097692716

Epoch: 5| Step: 9
Training loss: 2.279061822612604
Validation loss: 2.4637546057475004

Epoch: 5| Step: 10
Training loss: 2.4929402807912004
Validation loss: 2.4668381607736607

Epoch: 5| Step: 11
Training loss: 1.7228787855837255
Validation loss: 2.466750715623752

Epoch: 131| Step: 0
Training loss: 2.7018071308211034
Validation loss: 2.4676377933822993

Epoch: 5| Step: 1
Training loss: 2.0743064502631405
Validation loss: 2.4648474599061707

Epoch: 5| Step: 2
Training loss: 2.9915160379415036
Validation loss: 2.4675599521509057

Epoch: 5| Step: 3
Training loss: 2.451221188964844
Validation loss: 2.465489233974535

Epoch: 5| Step: 4
Training loss: 2.5070778789802226
Validation loss: 2.4638766181353056

Epoch: 5| Step: 5
Training loss: 2.41563319985798
Validation loss: 2.472154949168264

Epoch: 5| Step: 6
Training loss: 2.310017361431192
Validation loss: 2.4764221464512537

Epoch: 5| Step: 7
Training loss: 2.7257342897865278
Validation loss: 2.472505744664481

Epoch: 5| Step: 8
Training loss: 2.6263688469367574
Validation loss: 2.474301357915844

Epoch: 5| Step: 9
Training loss: 2.0475623454568397
Validation loss: 2.4746520398282494

Epoch: 5| Step: 10
Training loss: 2.7033834168498068
Validation loss: 2.476539226627201

Epoch: 5| Step: 11
Training loss: 3.7683918392111253
Validation loss: 2.4778867203723727

Epoch: 132| Step: 0
Training loss: 2.622604275967683
Validation loss: 2.465121576497713

Epoch: 5| Step: 1
Training loss: 2.8320947258511406
Validation loss: 2.4730825353033867

Epoch: 5| Step: 2
Training loss: 2.2963073444214617
Validation loss: 2.467371213554498

Epoch: 5| Step: 3
Training loss: 2.568309339608864
Validation loss: 2.4666615074228337

Epoch: 5| Step: 4
Training loss: 2.0703537271101493
Validation loss: 2.4676070726476227

Epoch: 5| Step: 5
Training loss: 2.647604302070881
Validation loss: 2.4822186362573992

Epoch: 5| Step: 6
Training loss: 2.2713416227714367
Validation loss: 2.4782234703084973

Epoch: 5| Step: 7
Training loss: 2.9812717780831255
Validation loss: 2.4747198813316933

Epoch: 5| Step: 8
Training loss: 2.4329543153837947
Validation loss: 2.4718439898372333

Epoch: 5| Step: 9
Training loss: 2.9256438565558236
Validation loss: 2.4712389258209093

Epoch: 5| Step: 10
Training loss: 2.211405458565401
Validation loss: 2.4743879480610125

Epoch: 5| Step: 11
Training loss: 2.950499805847999
Validation loss: 2.4733799924288067

Epoch: 133| Step: 0
Training loss: 2.8061456741617494
Validation loss: 2.4727311607612252

Epoch: 5| Step: 1
Training loss: 2.655634999605396
Validation loss: 2.4755511620641597

Epoch: 5| Step: 2
Training loss: 2.343525583331448
Validation loss: 2.468611222402563

Epoch: 5| Step: 3
Training loss: 2.1457558281490567
Validation loss: 2.4768398863627845

Epoch: 5| Step: 4
Training loss: 2.43905414039797
Validation loss: 2.4741750013271657

Epoch: 5| Step: 5
Training loss: 2.696014931962859
Validation loss: 2.4741602376899525

Epoch: 5| Step: 6
Training loss: 2.4990823015060806
Validation loss: 2.4725950252592557

Epoch: 5| Step: 7
Training loss: 2.6722099585019317
Validation loss: 2.4698852150226687

Epoch: 5| Step: 8
Training loss: 3.0949223926779195
Validation loss: 2.4730441234675546

Epoch: 5| Step: 9
Training loss: 2.2634415200753533
Validation loss: 2.4709093975261993

Epoch: 5| Step: 10
Training loss: 2.231221354324718
Validation loss: 2.475563016104438

Epoch: 5| Step: 11
Training loss: 2.544572034725051
Validation loss: 2.477031158002581

Epoch: 134| Step: 0
Training loss: 3.198248002141661
Validation loss: 2.467859425447402

Epoch: 5| Step: 1
Training loss: 2.4587870572453396
Validation loss: 2.475524167225077

Epoch: 5| Step: 2
Training loss: 2.5221519384333715
Validation loss: 2.4736074995273576

Epoch: 5| Step: 3
Training loss: 2.165402875245524
Validation loss: 2.468704752366567

Epoch: 5| Step: 4
Training loss: 3.090571765036183
Validation loss: 2.4591531329513465

Epoch: 5| Step: 5
Training loss: 2.0673154622650167
Validation loss: 2.4692553071474843

Epoch: 5| Step: 6
Training loss: 2.243801267245406
Validation loss: 2.4671415650446424

Epoch: 5| Step: 7
Training loss: 2.329292670192886
Validation loss: 2.4651460396725535

Epoch: 5| Step: 8
Training loss: 2.5631165111729532
Validation loss: 2.46501902638689

Epoch: 5| Step: 9
Training loss: 2.0626494613592383
Validation loss: 2.464420054474797

Epoch: 5| Step: 10
Training loss: 2.7234547564714333
Validation loss: 2.4673680288354616

Epoch: 5| Step: 11
Training loss: 3.3398194786216027
Validation loss: 2.456107774164565

Epoch: 135| Step: 0
Training loss: 2.4296342163130946
Validation loss: 2.455805009066529

Epoch: 5| Step: 1
Training loss: 2.605555405669851
Validation loss: 2.4598785746012912

Epoch: 5| Step: 2
Training loss: 3.0221225136159995
Validation loss: 2.474636014510444

Epoch: 5| Step: 3
Training loss: 2.551799483311207
Validation loss: 2.465465980981284

Epoch: 5| Step: 4
Training loss: 2.286241479089208
Validation loss: 2.4696649875811074

Epoch: 5| Step: 5
Training loss: 2.580655699658411
Validation loss: 2.4633209352757706

Epoch: 5| Step: 6
Training loss: 2.6260462900978756
Validation loss: 2.4688562136951524

Epoch: 5| Step: 7
Training loss: 2.401759130783569
Validation loss: 2.4615417344187334

Epoch: 5| Step: 8
Training loss: 2.263424455814993
Validation loss: 2.4623009633537163

Epoch: 5| Step: 9
Training loss: 2.6961063708593325
Validation loss: 2.4722463861694215

Epoch: 5| Step: 10
Training loss: 2.6248043532349663
Validation loss: 2.4646397550051926

Epoch: 5| Step: 11
Training loss: 1.2485189246598405
Validation loss: 2.4747374676332714

Epoch: 136| Step: 0
Training loss: 1.9726723849703687
Validation loss: 2.4735018633631167

Epoch: 5| Step: 1
Training loss: 2.426428175706838
Validation loss: 2.468064402092906

Epoch: 5| Step: 2
Training loss: 3.068856318665678
Validation loss: 2.467922321433109

Epoch: 5| Step: 3
Training loss: 2.584362460824421
Validation loss: 2.4659784831567344

Epoch: 5| Step: 4
Training loss: 2.6090787616624582
Validation loss: 2.462078592869659

Epoch: 5| Step: 5
Training loss: 2.6756603352869512
Validation loss: 2.470061521188699

Epoch: 5| Step: 6
Training loss: 2.536018119277966
Validation loss: 2.4742719203903922

Epoch: 5| Step: 7
Training loss: 2.733319149523274
Validation loss: 2.466408685669508

Epoch: 5| Step: 8
Training loss: 2.4302997369714374
Validation loss: 2.468337877697811

Epoch: 5| Step: 9
Training loss: 2.149331534507194
Validation loss: 2.4709350818818234

Epoch: 5| Step: 10
Training loss: 2.539001088500118
Validation loss: 2.463152277351063

Epoch: 5| Step: 11
Training loss: 2.524454484686041
Validation loss: 2.468950440522912

Epoch: 137| Step: 0
Training loss: 2.3527679902040406
Validation loss: 2.462871118841892

Epoch: 5| Step: 1
Training loss: 2.493301286219442
Validation loss: 2.4665369464190645

Epoch: 5| Step: 2
Training loss: 2.781890966729114
Validation loss: 2.469217437239768

Epoch: 5| Step: 3
Training loss: 2.8807660207331898
Validation loss: 2.472251232175841

Epoch: 5| Step: 4
Training loss: 1.9403138186105777
Validation loss: 2.4682404277925905

Epoch: 5| Step: 5
Training loss: 2.632223635057176
Validation loss: 2.469279968742611

Epoch: 5| Step: 6
Training loss: 2.5286201661703136
Validation loss: 2.46621869686863

Epoch: 5| Step: 7
Training loss: 2.562017162703264
Validation loss: 2.470339549055487

Epoch: 5| Step: 8
Training loss: 1.9256116935569858
Validation loss: 2.464866521199148

Epoch: 5| Step: 9
Training loss: 2.5847178000029047
Validation loss: 2.4590891441304055

Epoch: 5| Step: 10
Training loss: 3.015683188395863
Validation loss: 2.4650382314332564

Epoch: 5| Step: 11
Training loss: 2.1688799068889435
Validation loss: 2.4628246721053144

Epoch: 138| Step: 0
Training loss: 2.3757780707907865
Validation loss: 2.453348647692642

Epoch: 5| Step: 1
Training loss: 2.096372413950735
Validation loss: 2.4604917758380953

Epoch: 5| Step: 2
Training loss: 2.8069302828196254
Validation loss: 2.464894233263207

Epoch: 5| Step: 3
Training loss: 2.459873320566501
Validation loss: 2.459863864487142

Epoch: 5| Step: 4
Training loss: 2.8480503976413205
Validation loss: 2.46916801197257

Epoch: 5| Step: 5
Training loss: 2.6049237689324927
Validation loss: 2.4675817904561623

Epoch: 5| Step: 6
Training loss: 2.2968727163705696
Validation loss: 2.467015039054596

Epoch: 5| Step: 7
Training loss: 2.396673392479611
Validation loss: 2.459791788704452

Epoch: 5| Step: 8
Training loss: 3.561125105183825
Validation loss: 2.457614689922481

Epoch: 5| Step: 9
Training loss: 2.17733440746196
Validation loss: 2.466659288352379

Epoch: 5| Step: 10
Training loss: 1.9369445127536438
Validation loss: 2.466514851166156

Epoch: 5| Step: 11
Training loss: 2.2227285470584777
Validation loss: 2.46722754682912

Epoch: 139| Step: 0
Training loss: 2.9707368325873653
Validation loss: 2.470090932478555

Epoch: 5| Step: 1
Training loss: 2.2123365525040284
Validation loss: 2.465502679592449

Epoch: 5| Step: 2
Training loss: 2.38227913312085
Validation loss: 2.465465150944895

Epoch: 5| Step: 3
Training loss: 2.0939887750465025
Validation loss: 2.4723100585609137

Epoch: 5| Step: 4
Training loss: 2.8410489176238314
Validation loss: 2.4729871724293893

Epoch: 5| Step: 5
Training loss: 2.8216814855587127
Validation loss: 2.467353864637029

Epoch: 5| Step: 6
Training loss: 2.632021006798903
Validation loss: 2.477888472350536

Epoch: 5| Step: 7
Training loss: 2.5090191276432385
Validation loss: 2.4760064625006066

Epoch: 5| Step: 8
Training loss: 2.5254689829176677
Validation loss: 2.4751384142501625

Epoch: 5| Step: 9
Training loss: 2.3116291571528023
Validation loss: 2.481022884518718

Epoch: 5| Step: 10
Training loss: 2.468393710537966
Validation loss: 2.4771698649194853

Epoch: 5| Step: 11
Training loss: 2.408248665805203
Validation loss: 2.4708619922328934

Epoch: 140| Step: 0
Training loss: 2.6932317248462416
Validation loss: 2.4654549366392597

Epoch: 5| Step: 1
Training loss: 2.3351937325137677
Validation loss: 2.4592370470804688

Epoch: 5| Step: 2
Training loss: 3.000464085604743
Validation loss: 2.4682063296800987

Epoch: 5| Step: 3
Training loss: 2.2986507687664277
Validation loss: 2.4829365146554445

Epoch: 5| Step: 4
Training loss: 2.4783784484177436
Validation loss: 2.481417056656797

Epoch: 5| Step: 5
Training loss: 2.829462399052401
Validation loss: 2.47400191151569

Epoch: 5| Step: 6
Training loss: 2.5125886588324904
Validation loss: 2.476556436990563

Epoch: 5| Step: 7
Training loss: 2.669103780341704
Validation loss: 2.4678817421329424

Epoch: 5| Step: 8
Training loss: 2.429086298019298
Validation loss: 2.469812647358883

Epoch: 5| Step: 9
Training loss: 2.485107313943687
Validation loss: 2.463831589449568

Epoch: 5| Step: 10
Training loss: 2.466762273671123
Validation loss: 2.460190378038985

Epoch: 5| Step: 11
Training loss: 1.5297491542404238
Validation loss: 2.4636357002511744

Epoch: 141| Step: 0
Training loss: 2.2743314578172393
Validation loss: 2.4647973081925985

Epoch: 5| Step: 1
Training loss: 2.699304250861822
Validation loss: 2.4705342432335753

Epoch: 5| Step: 2
Training loss: 2.1413126488387686
Validation loss: 2.468882963567529

Epoch: 5| Step: 3
Training loss: 2.902290189718615
Validation loss: 2.4687781875546353

Epoch: 5| Step: 4
Training loss: 2.6479755550132085
Validation loss: 2.4715208044975276

Epoch: 5| Step: 5
Training loss: 2.719041304493102
Validation loss: 2.470169946690189

Epoch: 5| Step: 6
Training loss: 2.398872261529619
Validation loss: 2.4725613166539664

Epoch: 5| Step: 7
Training loss: 2.8201239779118676
Validation loss: 2.4784252930861914

Epoch: 5| Step: 8
Training loss: 3.1608145161424046
Validation loss: 2.4717548207720577

Epoch: 5| Step: 9
Training loss: 2.1065785273491295
Validation loss: 2.4735100001949153

Epoch: 5| Step: 10
Training loss: 1.6031666235325752
Validation loss: 2.4762564107948957

Epoch: 5| Step: 11
Training loss: 2.811308460026358
Validation loss: 2.4658367657505944

Epoch: 142| Step: 0
Training loss: 2.154998084153742
Validation loss: 2.463857970520996

Epoch: 5| Step: 1
Training loss: 2.188913488115364
Validation loss: 2.4670091800941547

Epoch: 5| Step: 2
Training loss: 2.6957145943844725
Validation loss: 2.456082523256464

Epoch: 5| Step: 3
Training loss: 2.417109668072894
Validation loss: 2.4606437992252763

Epoch: 5| Step: 4
Training loss: 2.960062264998981
Validation loss: 2.4639941533200456

Epoch: 5| Step: 5
Training loss: 2.254951115858636
Validation loss: 2.4634898115081207

Epoch: 5| Step: 6
Training loss: 2.6064932437518653
Validation loss: 2.462281694595108

Epoch: 5| Step: 7
Training loss: 2.8304652863412083
Validation loss: 2.4662515133561294

Epoch: 5| Step: 8
Training loss: 3.0284928829618996
Validation loss: 2.465670125183338

Epoch: 5| Step: 9
Training loss: 2.3385100727170225
Validation loss: 2.460862779239831

Epoch: 5| Step: 10
Training loss: 2.4248398875440436
Validation loss: 2.4689632878940375

Epoch: 5| Step: 11
Training loss: 1.3905642635497673
Validation loss: 2.4683728754940413

Epoch: 143| Step: 0
Training loss: 2.6797197968341164
Validation loss: 2.4635470244421307

Epoch: 5| Step: 1
Training loss: 1.4532925909059415
Validation loss: 2.465127605168564

Epoch: 5| Step: 2
Training loss: 2.232081162826264
Validation loss: 2.465109660157746

Epoch: 5| Step: 3
Training loss: 2.6519227627802806
Validation loss: 2.46242785662782

Epoch: 5| Step: 4
Training loss: 1.8567890810147858
Validation loss: 2.4610443576440773

Epoch: 5| Step: 5
Training loss: 2.713614952772032
Validation loss: 2.4661430646215496

Epoch: 5| Step: 6
Training loss: 2.748590021200829
Validation loss: 2.459517074061687

Epoch: 5| Step: 7
Training loss: 3.0463702443981737
Validation loss: 2.4583573474896485

Epoch: 5| Step: 8
Training loss: 2.053664268148407
Validation loss: 2.461932902381935

Epoch: 5| Step: 9
Training loss: 2.6379708037130882
Validation loss: 2.4743454733989325

Epoch: 5| Step: 10
Training loss: 3.072159306359275
Validation loss: 2.4643195270406313

Epoch: 5| Step: 11
Training loss: 3.401522934858324
Validation loss: 2.4611544276303636

Epoch: 144| Step: 0
Training loss: 2.365220968395892
Validation loss: 2.461559459262591

Epoch: 5| Step: 1
Training loss: 2.7038923287990824
Validation loss: 2.467616565480011

Epoch: 5| Step: 2
Training loss: 2.8503465542151143
Validation loss: 2.4752849849877636

Epoch: 5| Step: 3
Training loss: 2.7075693275543626
Validation loss: 2.4794183063755733

Epoch: 5| Step: 4
Training loss: 2.565614435915275
Validation loss: 2.477817658571238

Epoch: 5| Step: 5
Training loss: 2.2614328470526193
Validation loss: 2.482046823809942

Epoch: 5| Step: 6
Training loss: 2.5202500375195775
Validation loss: 2.4794083218378375

Epoch: 5| Step: 7
Training loss: 2.18884236156674
Validation loss: 2.482906187261249

Epoch: 5| Step: 8
Training loss: 2.5170325848997797
Validation loss: 2.488377288290464

Epoch: 5| Step: 9
Training loss: 2.7015004651176735
Validation loss: 2.4852935044777715

Epoch: 5| Step: 10
Training loss: 2.99769917313956
Validation loss: 2.4921730842292984

Epoch: 5| Step: 11
Training loss: 1.6785685516031301
Validation loss: 2.4905649840855086

Epoch: 145| Step: 0
Training loss: 2.8054463414588215
Validation loss: 2.4884617339292388

Epoch: 5| Step: 1
Training loss: 2.6161318343771036
Validation loss: 2.488527194992744

Epoch: 5| Step: 2
Training loss: 2.3250720597452057
Validation loss: 2.487002356988659

Epoch: 5| Step: 3
Training loss: 2.039948019038632
Validation loss: 2.4809965438213926

Epoch: 5| Step: 4
Training loss: 2.659987927459626
Validation loss: 2.4781587793229534

Epoch: 5| Step: 5
Training loss: 2.873520511923708
Validation loss: 2.4717878732224277

Epoch: 5| Step: 6
Training loss: 3.169622363632543
Validation loss: 2.475648460626933

Epoch: 5| Step: 7
Training loss: 2.4415426719697266
Validation loss: 2.47065539006094

Epoch: 5| Step: 8
Training loss: 2.4166117914042387
Validation loss: 2.4695322712750625

Epoch: 5| Step: 9
Training loss: 2.5699456135676404
Validation loss: 2.4699752439063953

Epoch: 5| Step: 10
Training loss: 2.0911680784898943
Validation loss: 2.4740527961498575

Epoch: 5| Step: 11
Training loss: 3.296240578306329
Validation loss: 2.4717167962427453

Epoch: 146| Step: 0
Training loss: 2.6239973605712548
Validation loss: 2.4734969595636027

Epoch: 5| Step: 1
Training loss: 2.94232511922778
Validation loss: 2.473372646404505

Epoch: 5| Step: 2
Training loss: 2.3770357742923487
Validation loss: 2.467143936690666

Epoch: 5| Step: 3
Training loss: 2.6006006977437397
Validation loss: 2.4634681325076806

Epoch: 5| Step: 4
Training loss: 2.870631672531469
Validation loss: 2.460599910448944

Epoch: 5| Step: 5
Training loss: 2.4585489943569985
Validation loss: 2.4622058607213217

Epoch: 5| Step: 6
Training loss: 2.714378437810377
Validation loss: 2.4609986353147963

Epoch: 5| Step: 7
Training loss: 2.4411571161947947
Validation loss: 2.465010305380542

Epoch: 5| Step: 8
Training loss: 2.058983203161721
Validation loss: 2.4629800222146527

Epoch: 5| Step: 9
Training loss: 2.20048689656169
Validation loss: 2.469147509349191

Epoch: 5| Step: 10
Training loss: 2.7046918792953605
Validation loss: 2.4672419452840475

Epoch: 5| Step: 11
Training loss: 2.669885083986638
Validation loss: 2.4637201512033555

Epoch: 147| Step: 0
Training loss: 2.654883448310865
Validation loss: 2.468062631065842

Epoch: 5| Step: 1
Training loss: 2.3965535173336088
Validation loss: 2.467925501411576

Epoch: 5| Step: 2
Training loss: 2.5833425726776613
Validation loss: 2.4689550556056705

Epoch: 5| Step: 3
Training loss: 2.427622711977247
Validation loss: 2.4747668675077352

Epoch: 5| Step: 4
Training loss: 2.7520041532097017
Validation loss: 2.4725071870649877

Epoch: 5| Step: 5
Training loss: 2.426013781817381
Validation loss: 2.4732527573288428

Epoch: 5| Step: 6
Training loss: 2.300988698004031
Validation loss: 2.4737366158700174

Epoch: 5| Step: 7
Training loss: 2.8504497708570833
Validation loss: 2.468428454001217

Epoch: 5| Step: 8
Training loss: 2.0232409525378747
Validation loss: 2.472639038604568

Epoch: 5| Step: 9
Training loss: 2.609202304995915
Validation loss: 2.4699358204754556

Epoch: 5| Step: 10
Training loss: 2.712985977024124
Validation loss: 2.470720800203369

Epoch: 5| Step: 11
Training loss: 3.2538647780689227
Validation loss: 2.466706194485735

Epoch: 148| Step: 0
Training loss: 2.707960621546081
Validation loss: 2.468279266546591

Epoch: 5| Step: 1
Training loss: 2.6305267644817425
Validation loss: 2.4711191623702473

Epoch: 5| Step: 2
Training loss: 2.5448644460315637
Validation loss: 2.4665592347948344

Epoch: 5| Step: 3
Training loss: 1.908706645460717
Validation loss: 2.468641787785004

Epoch: 5| Step: 4
Training loss: 3.166342133071237
Validation loss: 2.4692461666046395

Epoch: 5| Step: 5
Training loss: 2.2600537432129117
Validation loss: 2.4664196371303837

Epoch: 5| Step: 6
Training loss: 1.7865729855891457
Validation loss: 2.46276745045766

Epoch: 5| Step: 7
Training loss: 2.4811233257561147
Validation loss: 2.465414546402387

Epoch: 5| Step: 8
Training loss: 3.0800482458819456
Validation loss: 2.465814317752614

Epoch: 5| Step: 9
Training loss: 2.720193238686976
Validation loss: 2.462357717766876

Epoch: 5| Step: 10
Training loss: 2.223368069817289
Validation loss: 2.4609342867714226

Epoch: 5| Step: 11
Training loss: 2.653116869155772
Validation loss: 2.4622461180026147

Epoch: 149| Step: 0
Training loss: 2.4047146146855503
Validation loss: 2.4620202362033052

Epoch: 5| Step: 1
Training loss: 2.6987591364583525
Validation loss: 2.465278526688105

Epoch: 5| Step: 2
Training loss: 2.5334690869080774
Validation loss: 2.463995338642213

Epoch: 5| Step: 3
Training loss: 2.8647362315669898
Validation loss: 2.464655994452368

Epoch: 5| Step: 4
Training loss: 2.3494246894633504
Validation loss: 2.4693389061411075

Epoch: 5| Step: 5
Training loss: 2.325356905215477
Validation loss: 2.4643163020971595

Epoch: 5| Step: 6
Training loss: 2.7366578082530992
Validation loss: 2.4674645268158804

Epoch: 5| Step: 7
Training loss: 2.3248757852167095
Validation loss: 2.470608132688622

Epoch: 5| Step: 8
Training loss: 2.7702504073067744
Validation loss: 2.4708169822945236

Epoch: 5| Step: 9
Training loss: 2.594141735231185
Validation loss: 2.4653561316979578

Epoch: 5| Step: 10
Training loss: 2.023221037491117
Validation loss: 2.46706844958228

Epoch: 5| Step: 11
Training loss: 3.2522257006166506
Validation loss: 2.4604598939238467

Epoch: 150| Step: 0
Training loss: 2.188340597767719
Validation loss: 2.4572488337706875

Epoch: 5| Step: 1
Training loss: 2.784878196586741
Validation loss: 2.461089275866976

Epoch: 5| Step: 2
Training loss: 3.0906239138332268
Validation loss: 2.4556501314478067

Epoch: 5| Step: 3
Training loss: 2.508055297886851
Validation loss: 2.4586410141337254

Epoch: 5| Step: 4
Training loss: 2.7673715367606757
Validation loss: 2.464729677231772

Epoch: 5| Step: 5
Training loss: 2.948399552513982
Validation loss: 2.4641346523579837

Epoch: 5| Step: 6
Training loss: 2.019085183676724
Validation loss: 2.4610671478513573

Epoch: 5| Step: 7
Training loss: 2.667993324803319
Validation loss: 2.4619218058743653

Epoch: 5| Step: 8
Training loss: 2.280045910088614
Validation loss: 2.4646515446368302

Epoch: 5| Step: 9
Training loss: 2.104551210925493
Validation loss: 2.4583664719454745

Epoch: 5| Step: 10
Training loss: 2.3788823970607313
Validation loss: 2.4640453917772804

Epoch: 5| Step: 11
Training loss: 2.3058568024851183
Validation loss: 2.464287418509026

Epoch: 151| Step: 0
Training loss: 2.352391701940889
Validation loss: 2.469538904645031

Epoch: 5| Step: 1
Training loss: 2.9107018285780657
Validation loss: 2.466560644425128

Epoch: 5| Step: 2
Training loss: 2.5750619899361955
Validation loss: 2.473975281239064

Epoch: 5| Step: 3
Training loss: 2.0056186669030653
Validation loss: 2.4743686730577825

Epoch: 5| Step: 4
Training loss: 2.450595693765697
Validation loss: 2.470000879658222

Epoch: 5| Step: 5
Training loss: 2.4990366033137947
Validation loss: 2.468171546866125

Epoch: 5| Step: 6
Training loss: 2.1784071357831523
Validation loss: 2.470567312013425

Epoch: 5| Step: 7
Training loss: 2.73176519916391
Validation loss: 2.477179048409178

Epoch: 5| Step: 8
Training loss: 2.707410028993391
Validation loss: 2.470420847412199

Epoch: 5| Step: 9
Training loss: 2.843117109024861
Validation loss: 2.471884041925186

Epoch: 5| Step: 10
Training loss: 2.4506122330184907
Validation loss: 2.467324932056342

Epoch: 5| Step: 11
Training loss: 2.3231431539881737
Validation loss: 2.4667992832215373

Epoch: 152| Step: 0
Training loss: 2.367622260025491
Validation loss: 2.469986018676673

Epoch: 5| Step: 1
Training loss: 2.4231605317406126
Validation loss: 2.466341622518561

Epoch: 5| Step: 2
Training loss: 2.8237974662557033
Validation loss: 2.464337888982098

Epoch: 5| Step: 3
Training loss: 2.629781092827197
Validation loss: 2.4604117099239367

Epoch: 5| Step: 4
Training loss: 2.9139224266770394
Validation loss: 2.461481627602814

Epoch: 5| Step: 5
Training loss: 2.7619520032221825
Validation loss: 2.4528113000589546

Epoch: 5| Step: 6
Training loss: 2.1871488016768015
Validation loss: 2.462672926548181

Epoch: 5| Step: 7
Training loss: 2.0015946230071346
Validation loss: 2.4616075118345435

Epoch: 5| Step: 8
Training loss: 2.3461194077955123
Validation loss: 2.4614299543835094

Epoch: 5| Step: 9
Training loss: 2.5478446378427364
Validation loss: 2.46486818973538

Epoch: 5| Step: 10
Training loss: 2.452292914712837
Validation loss: 2.4618505973862246

Epoch: 5| Step: 11
Training loss: 3.0547340174886815
Validation loss: 2.458734509229063

Epoch: 153| Step: 0
Training loss: 2.6918314250521775
Validation loss: 2.4699219967871584

Epoch: 5| Step: 1
Training loss: 2.7873885744002873
Validation loss: 2.4632393783912816

Epoch: 5| Step: 2
Training loss: 2.2689504487573138
Validation loss: 2.460823879949349

Epoch: 5| Step: 3
Training loss: 2.346641079842629
Validation loss: 2.460457879210392

Epoch: 5| Step: 4
Training loss: 2.6153554396922294
Validation loss: 2.453966656443063

Epoch: 5| Step: 5
Training loss: 2.5735431994541664
Validation loss: 2.461106967641482

Epoch: 5| Step: 6
Training loss: 2.3747412892025332
Validation loss: 2.4680897799661414

Epoch: 5| Step: 7
Training loss: 2.9114038852429616
Validation loss: 2.4680502821418075

Epoch: 5| Step: 8
Training loss: 2.4590356653271277
Validation loss: 2.4687984357178805

Epoch: 5| Step: 9
Training loss: 2.160169384107619
Validation loss: 2.4652946732767425

Epoch: 5| Step: 10
Training loss: 2.754688254717087
Validation loss: 2.469590249302642

Epoch: 5| Step: 11
Training loss: 2.2275745969327048
Validation loss: 2.469682734573055

Epoch: 154| Step: 0
Training loss: 2.674402836964318
Validation loss: 2.4757402019602814

Epoch: 5| Step: 1
Training loss: 2.8939027090953617
Validation loss: 2.4784820770806912

Epoch: 5| Step: 2
Training loss: 2.548428021009301
Validation loss: 2.4683882894994222

Epoch: 5| Step: 3
Training loss: 2.485777453072502
Validation loss: 2.4758414894640755

Epoch: 5| Step: 4
Training loss: 2.8203939072121824
Validation loss: 2.4712924701692605

Epoch: 5| Step: 5
Training loss: 2.6845275053994313
Validation loss: 2.471028837464366

Epoch: 5| Step: 6
Training loss: 2.5874255183460413
Validation loss: 2.465573258817995

Epoch: 5| Step: 7
Training loss: 2.3436539693868323
Validation loss: 2.4714269731179384

Epoch: 5| Step: 8
Training loss: 1.7053246248921134
Validation loss: 2.473592431298169

Epoch: 5| Step: 9
Training loss: 2.615718417852292
Validation loss: 2.4657868456693928

Epoch: 5| Step: 10
Training loss: 2.273598681631921
Validation loss: 2.470699082121224

Epoch: 5| Step: 11
Training loss: 2.445821008429161
Validation loss: 2.4695104160252654

Epoch: 155| Step: 0
Training loss: 2.3310769842749104
Validation loss: 2.4586522951480116

Epoch: 5| Step: 1
Training loss: 1.9367987686621286
Validation loss: 2.4647149295666275

Epoch: 5| Step: 2
Training loss: 3.007339876372314
Validation loss: 2.472640400575098

Epoch: 5| Step: 3
Training loss: 2.371847771248312
Validation loss: 2.4712893990383002

Epoch: 5| Step: 4
Training loss: 2.7405073882283335
Validation loss: 2.4757235416689736

Epoch: 5| Step: 5
Training loss: 2.440534903100288
Validation loss: 2.470986906096191

Epoch: 5| Step: 6
Training loss: 2.788346655525567
Validation loss: 2.4652143140393785

Epoch: 5| Step: 7
Training loss: 1.9588146497504624
Validation loss: 2.4667607513948098

Epoch: 5| Step: 8
Training loss: 2.456647542760871
Validation loss: 2.4637423803868717

Epoch: 5| Step: 9
Training loss: 2.7364863500381857
Validation loss: 2.471403631285433

Epoch: 5| Step: 10
Training loss: 2.578905854316133
Validation loss: 2.4598653122812775

Epoch: 5| Step: 11
Training loss: 3.5438157386670124
Validation loss: 2.467229998920921

Epoch: 156| Step: 0
Training loss: 2.9342576658537642
Validation loss: 2.4669892796586437

Epoch: 5| Step: 1
Training loss: 2.5180603938597748
Validation loss: 2.466672836330362

Epoch: 5| Step: 2
Training loss: 2.3560239728993557
Validation loss: 2.474644801953324

Epoch: 5| Step: 3
Training loss: 2.454106322897542
Validation loss: 2.475352070713692

Epoch: 5| Step: 4
Training loss: 2.733019509171533
Validation loss: 2.4747728084557856

Epoch: 5| Step: 5
Training loss: 2.675190792231707
Validation loss: 2.4669603468289547

Epoch: 5| Step: 6
Training loss: 2.5470680210479686
Validation loss: 2.476115083040678

Epoch: 5| Step: 7
Training loss: 2.2603966731111624
Validation loss: 2.476823281598391

Epoch: 5| Step: 8
Training loss: 2.474023040460663
Validation loss: 2.4727413771500877

Epoch: 5| Step: 9
Training loss: 2.30305945873818
Validation loss: 2.4627134404087663

Epoch: 5| Step: 10
Training loss: 2.5330033058057584
Validation loss: 2.4639164288076087

Epoch: 5| Step: 11
Training loss: 1.5548087988072323
Validation loss: 2.4531997377709907

Epoch: 157| Step: 0
Training loss: 2.2158550664900667
Validation loss: 2.4619948805007676

Epoch: 5| Step: 1
Training loss: 2.479421223199233
Validation loss: 2.461796714510972

Epoch: 5| Step: 2
Training loss: 2.589270987257394
Validation loss: 2.46868190590992

Epoch: 5| Step: 3
Training loss: 2.167043677565377
Validation loss: 2.455638614143323

Epoch: 5| Step: 4
Training loss: 3.234380159972862
Validation loss: 2.467215044746829

Epoch: 5| Step: 5
Training loss: 2.6192831730294333
Validation loss: 2.45371803680035

Epoch: 5| Step: 6
Training loss: 1.9236497825410843
Validation loss: 2.4609888162258042

Epoch: 5| Step: 7
Training loss: 2.8354898735273197
Validation loss: 2.466669852076441

Epoch: 5| Step: 8
Training loss: 2.6396350697959705
Validation loss: 2.4684782562709633

Epoch: 5| Step: 9
Training loss: 2.584780431309839
Validation loss: 2.4699522503331375

Epoch: 5| Step: 10
Training loss: 2.534525976611197
Validation loss: 2.4703187384658336

Epoch: 5| Step: 11
Training loss: 2.428954575071092
Validation loss: 2.4749295760902044

Epoch: 158| Step: 0
Training loss: 1.9628477480935818
Validation loss: 2.477088202548448

Epoch: 5| Step: 1
Training loss: 2.676981368640222
Validation loss: 2.4802655354557253

Epoch: 5| Step: 2
Training loss: 2.5585589923390573
Validation loss: 2.474617544319781

Epoch: 5| Step: 3
Training loss: 2.3814721511984125
Validation loss: 2.4716898680434207

Epoch: 5| Step: 4
Training loss: 2.882303332512099
Validation loss: 2.476193132744052

Epoch: 5| Step: 5
Training loss: 2.3012129114779096
Validation loss: 2.4727546346896943

Epoch: 5| Step: 6
Training loss: 2.5911089768336417
Validation loss: 2.4754845372086085

Epoch: 5| Step: 7
Training loss: 2.270492691481907
Validation loss: 2.470837945488865

Epoch: 5| Step: 8
Training loss: 2.9372026008861467
Validation loss: 2.469299943247197

Epoch: 5| Step: 9
Training loss: 2.2450649393115722
Validation loss: 2.472360658579573

Epoch: 5| Step: 10
Training loss: 2.6954557076708534
Validation loss: 2.463837875290632

Epoch: 5| Step: 11
Training loss: 2.4275035794484143
Validation loss: 2.461680983198509

Epoch: 159| Step: 0
Training loss: 2.032777300096676
Validation loss: 2.46876323873455

Epoch: 5| Step: 1
Training loss: 2.455117843658675
Validation loss: 2.4683909295909503

Epoch: 5| Step: 2
Training loss: 2.3835048982807177
Validation loss: 2.46023294768025

Epoch: 5| Step: 3
Training loss: 2.5767207164778876
Validation loss: 2.4606512115105637

Epoch: 5| Step: 4
Training loss: 2.8355959852153885
Validation loss: 2.45828852909014

Epoch: 5| Step: 5
Training loss: 2.598564826566278
Validation loss: 2.459278500161099

Epoch: 5| Step: 6
Training loss: 2.7408518785371396
Validation loss: 2.4527223868132015

Epoch: 5| Step: 7
Training loss: 2.1011448555078025
Validation loss: 2.459761121427813

Epoch: 5| Step: 8
Training loss: 2.5920435795946926
Validation loss: 2.4538877823912104

Epoch: 5| Step: 9
Training loss: 2.586651383712033
Validation loss: 2.4591589035785066

Epoch: 5| Step: 10
Training loss: 2.409379781478313
Validation loss: 2.4601771961401435

Epoch: 5| Step: 11
Training loss: 3.0319269741795916
Validation loss: 2.461735946060921

Epoch: 160| Step: 0
Training loss: 2.408605240340639
Validation loss: 2.4650198847837212

Epoch: 5| Step: 1
Training loss: 2.306548734509364
Validation loss: 2.4661192780098524

Epoch: 5| Step: 2
Training loss: 2.8908767178196713
Validation loss: 2.468647435629071

Epoch: 5| Step: 3
Training loss: 2.455693449297988
Validation loss: 2.4648532897474427

Epoch: 5| Step: 4
Training loss: 2.1622769808568374
Validation loss: 2.4604780626079377

Epoch: 5| Step: 5
Training loss: 2.0684462863143622
Validation loss: 2.4645212066206477

Epoch: 5| Step: 6
Training loss: 2.3398028897139227
Validation loss: 2.457475950492723

Epoch: 5| Step: 7
Training loss: 2.8624551161532974
Validation loss: 2.464566452460844

Epoch: 5| Step: 8
Training loss: 2.6862257664627154
Validation loss: 2.4594109861785918

Epoch: 5| Step: 9
Training loss: 2.3687275827600196
Validation loss: 2.4617401428810437

Epoch: 5| Step: 10
Training loss: 2.8061669148335153
Validation loss: 2.458412857439687

Epoch: 5| Step: 11
Training loss: 2.7107687246240055
Validation loss: 2.458807585655541

Epoch: 161| Step: 0
Training loss: 2.221444978158385
Validation loss: 2.4672107444990496

Epoch: 5| Step: 1
Training loss: 2.924524421828628
Validation loss: 2.4686833424965147

Epoch: 5| Step: 2
Training loss: 2.1782169098255575
Validation loss: 2.472328971910721

Epoch: 5| Step: 3
Training loss: 2.410696899512836
Validation loss: 2.4691739261592147

Epoch: 5| Step: 4
Training loss: 2.817422754807855
Validation loss: 2.4757289626961048

Epoch: 5| Step: 5
Training loss: 2.589224578812187
Validation loss: 2.472303239754529

Epoch: 5| Step: 6
Training loss: 1.9950133981469926
Validation loss: 2.476643598093114

Epoch: 5| Step: 7
Training loss: 2.7336999550395706
Validation loss: 2.476137636245559

Epoch: 5| Step: 8
Training loss: 2.6907745638758134
Validation loss: 2.4741581056480357

Epoch: 5| Step: 9
Training loss: 2.2886131288196707
Validation loss: 2.4683818180436115

Epoch: 5| Step: 10
Training loss: 2.7809882737357965
Validation loss: 2.4674269957984944

Epoch: 5| Step: 11
Training loss: 1.5140337898988803
Validation loss: 2.4597019141467147

Epoch: 162| Step: 0
Training loss: 3.137258062875315
Validation loss: 2.4570958624805996

Epoch: 5| Step: 1
Training loss: 2.2180685151906
Validation loss: 2.4564608633046525

Epoch: 5| Step: 2
Training loss: 2.7491674029798427
Validation loss: 2.4593139762852982

Epoch: 5| Step: 3
Training loss: 2.399437115146687
Validation loss: 2.460060774839409

Epoch: 5| Step: 4
Training loss: 2.3738917726562248
Validation loss: 2.4588213546644044

Epoch: 5| Step: 5
Training loss: 2.3714241413528114
Validation loss: 2.4542380438065847

Epoch: 5| Step: 6
Training loss: 2.37260939093658
Validation loss: 2.4635602346826775

Epoch: 5| Step: 7
Training loss: 1.9613706558682191
Validation loss: 2.4603642436834776

Epoch: 5| Step: 8
Training loss: 1.7125873014375548
Validation loss: 2.4580848872725842

Epoch: 5| Step: 9
Training loss: 2.9475036080090002
Validation loss: 2.4523325853112876

Epoch: 5| Step: 10
Training loss: 3.0213161389612724
Validation loss: 2.4587480826920682

Epoch: 5| Step: 11
Training loss: 2.7418447427012738
Validation loss: 2.4613190733563513

Epoch: 163| Step: 0
Training loss: 2.2434912954815784
Validation loss: 2.458370484594025

Epoch: 5| Step: 1
Training loss: 2.512351233789541
Validation loss: 2.465002616038814

Epoch: 5| Step: 2
Training loss: 2.9673362176395894
Validation loss: 2.4693322641878956

Epoch: 5| Step: 3
Training loss: 2.580967116845882
Validation loss: 2.4678214858137353

Epoch: 5| Step: 4
Training loss: 2.273915034214055
Validation loss: 2.4671798211482137

Epoch: 5| Step: 5
Training loss: 3.0305993079797506
Validation loss: 2.4748617844890184

Epoch: 5| Step: 6
Training loss: 2.6414286276572616
Validation loss: 2.4596837599234016

Epoch: 5| Step: 7
Training loss: 2.2628966642378523
Validation loss: 2.4697189763340925

Epoch: 5| Step: 8
Training loss: 1.9092345715216943
Validation loss: 2.463487875890838

Epoch: 5| Step: 9
Training loss: 2.6074091650263727
Validation loss: 2.47504363230254

Epoch: 5| Step: 10
Training loss: 2.3346876800581975
Validation loss: 2.4625407572179543

Epoch: 5| Step: 11
Training loss: 2.200441281537886
Validation loss: 2.466699509197973

Epoch: 164| Step: 0
Training loss: 2.1810147746135327
Validation loss: 2.4633599322482747

Epoch: 5| Step: 1
Training loss: 2.9095199401350484
Validation loss: 2.456382136070748

Epoch: 5| Step: 2
Training loss: 2.360056999617355
Validation loss: 2.460813920889336

Epoch: 5| Step: 3
Training loss: 2.536222401220155
Validation loss: 2.472275329464716

Epoch: 5| Step: 4
Training loss: 2.7783378184861487
Validation loss: 2.472849054437967

Epoch: 5| Step: 5
Training loss: 2.5208963643750675
Validation loss: 2.4635411411040202

Epoch: 5| Step: 6
Training loss: 2.670316007108489
Validation loss: 2.46853278206439

Epoch: 5| Step: 7
Training loss: 2.369828868755611
Validation loss: 2.4705116489282197

Epoch: 5| Step: 8
Training loss: 2.5499167036027863
Validation loss: 2.465419264809165

Epoch: 5| Step: 9
Training loss: 2.1874433237635516
Validation loss: 2.4761352611778924

Epoch: 5| Step: 10
Training loss: 2.6197896746304914
Validation loss: 2.467821441533716

Epoch: 5| Step: 11
Training loss: 3.057295444536014
Validation loss: 2.467212802015542

Epoch: 165| Step: 0
Training loss: 2.7424826612593836
Validation loss: 2.4775188777523867

Epoch: 5| Step: 1
Training loss: 2.095346667575109
Validation loss: 2.4757461766858007

Epoch: 5| Step: 2
Training loss: 2.4415564406927763
Validation loss: 2.4745466248932138

Epoch: 5| Step: 3
Training loss: 1.9568920580919418
Validation loss: 2.475372521946913

Epoch: 5| Step: 4
Training loss: 2.554717830746219
Validation loss: 2.4840915606215295

Epoch: 5| Step: 5
Training loss: 2.9686513783989064
Validation loss: 2.478973482656692

Epoch: 5| Step: 6
Training loss: 2.5424526646051473
Validation loss: 2.475011699019503

Epoch: 5| Step: 7
Training loss: 2.3595462762167125
Validation loss: 2.4766372805756394

Epoch: 5| Step: 8
Training loss: 2.692991811168302
Validation loss: 2.4796231728414497

Epoch: 5| Step: 9
Training loss: 2.994668355421007
Validation loss: 2.471692146903891

Epoch: 5| Step: 10
Training loss: 2.1775325938258816
Validation loss: 2.469730021719561

Epoch: 5| Step: 11
Training loss: 2.8101269353250147
Validation loss: 2.47048893378293

Epoch: 166| Step: 0
Training loss: 2.225294963701683
Validation loss: 2.463215257232709

Epoch: 5| Step: 1
Training loss: 2.303462954276902
Validation loss: 2.469808283256152

Epoch: 5| Step: 2
Training loss: 2.141361416191157
Validation loss: 2.4625123651390934

Epoch: 5| Step: 3
Training loss: 2.534859238728742
Validation loss: 2.4569584603739774

Epoch: 5| Step: 4
Training loss: 2.6002426694449965
Validation loss: 2.4525339341870125

Epoch: 5| Step: 5
Training loss: 2.3106739979822275
Validation loss: 2.4552137873031596

Epoch: 5| Step: 6
Training loss: 2.445977361316984
Validation loss: 2.463413317175054

Epoch: 5| Step: 7
Training loss: 2.6290511704924784
Validation loss: 2.455892496081344

Epoch: 5| Step: 8
Training loss: 3.098345493445321
Validation loss: 2.464965422338141

Epoch: 5| Step: 9
Training loss: 2.403924685442543
Validation loss: 2.4651305671104056

Epoch: 5| Step: 10
Training loss: 2.751765724661907
Validation loss: 2.4641694538559524

Epoch: 5| Step: 11
Training loss: 2.9539267445690447
Validation loss: 2.4697506039757684

Epoch: 167| Step: 0
Training loss: 2.3244762117773226
Validation loss: 2.467169473013269

Epoch: 5| Step: 1
Training loss: 2.2660941854904064
Validation loss: 2.4619106084387545

Epoch: 5| Step: 2
Training loss: 1.7392116157098223
Validation loss: 2.4744902403710896

Epoch: 5| Step: 3
Training loss: 2.3720490041241367
Validation loss: 2.470222327854481

Epoch: 5| Step: 4
Training loss: 2.692738063704697
Validation loss: 2.4718754616860314

Epoch: 5| Step: 5
Training loss: 3.2157589245962774
Validation loss: 2.4733460173855724

Epoch: 5| Step: 6
Training loss: 2.0840206411221773
Validation loss: 2.465496232796486

Epoch: 5| Step: 7
Training loss: 3.003687499654559
Validation loss: 2.469395995627304

Epoch: 5| Step: 8
Training loss: 2.5417409062617318
Validation loss: 2.46942329078237

Epoch: 5| Step: 9
Training loss: 2.612057249525474
Validation loss: 2.4570670880815726

Epoch: 5| Step: 10
Training loss: 2.284275609057713
Validation loss: 2.4617987200581273

Epoch: 5| Step: 11
Training loss: 2.656185732793309
Validation loss: 2.460400344111872

Epoch: 168| Step: 0
Training loss: 2.7184298096576636
Validation loss: 2.461061101160891

Epoch: 5| Step: 1
Training loss: 2.4306152142665893
Validation loss: 2.4627652601482377

Epoch: 5| Step: 2
Training loss: 2.71886926148264
Validation loss: 2.4693977777667526

Epoch: 5| Step: 3
Training loss: 2.1514019852922273
Validation loss: 2.465014339454319

Epoch: 5| Step: 4
Training loss: 2.5246376986289296
Validation loss: 2.462307749342097

Epoch: 5| Step: 5
Training loss: 2.668260415975348
Validation loss: 2.459982263771204

Epoch: 5| Step: 6
Training loss: 2.133771184850737
Validation loss: 2.4612747687880225

Epoch: 5| Step: 7
Training loss: 2.391909484853917
Validation loss: 2.4618980914612574

Epoch: 5| Step: 8
Training loss: 2.8086444282469274
Validation loss: 2.4721641512871515

Epoch: 5| Step: 9
Training loss: 3.0415684584000062
Validation loss: 2.4834674561100574

Epoch: 5| Step: 10
Training loss: 2.051901317082565
Validation loss: 2.4881446916685257

Epoch: 5| Step: 11
Training loss: 2.2816972686000896
Validation loss: 2.4887605062850864

Epoch: 169| Step: 0
Training loss: 2.7005422083058717
Validation loss: 2.4879716134561467

Epoch: 5| Step: 1
Training loss: 2.48044606596419
Validation loss: 2.4971452825334595

Epoch: 5| Step: 2
Training loss: 2.5677044747860736
Validation loss: 2.485141300083297

Epoch: 5| Step: 3
Training loss: 2.30881784451965
Validation loss: 2.4880828279263745

Epoch: 5| Step: 4
Training loss: 2.882676201469657
Validation loss: 2.492499990613115

Epoch: 5| Step: 5
Training loss: 2.798342357149129
Validation loss: 2.482768453019655

Epoch: 5| Step: 6
Training loss: 2.4037385194596523
Validation loss: 2.4861223565693225

Epoch: 5| Step: 7
Training loss: 2.238988102317776
Validation loss: 2.487910619866898

Epoch: 5| Step: 8
Training loss: 2.6377197174107008
Validation loss: 2.4762842040032114

Epoch: 5| Step: 9
Training loss: 2.3929873494102
Validation loss: 2.4809610994562528

Epoch: 5| Step: 10
Training loss: 2.355372589830804
Validation loss: 2.4762545132391294

Epoch: 5| Step: 11
Training loss: 2.563659405681621
Validation loss: 2.467714490892214

Epoch: 170| Step: 0
Training loss: 2.393892834737036
Validation loss: 2.4610115201606293

Epoch: 5| Step: 1
Training loss: 2.984250370638865
Validation loss: 2.4551216188400415

Epoch: 5| Step: 2
Training loss: 2.5153215118637284
Validation loss: 2.4667408529823196

Epoch: 5| Step: 3
Training loss: 2.529359747499214
Validation loss: 2.4628655686743794

Epoch: 5| Step: 4
Training loss: 2.672995349164999
Validation loss: 2.475500157742979

Epoch: 5| Step: 5
Training loss: 2.877998778384694
Validation loss: 2.482516835435097

Epoch: 5| Step: 6
Training loss: 1.68388077486464
Validation loss: 2.4794434598602195

Epoch: 5| Step: 7
Training loss: 2.6403461737962446
Validation loss: 2.4795428813386113

Epoch: 5| Step: 8
Training loss: 2.747978334310932
Validation loss: 2.464556423877671

Epoch: 5| Step: 9
Training loss: 2.0994769671185787
Validation loss: 2.4494611102041666

Epoch: 5| Step: 10
Training loss: 2.310382904915954
Validation loss: 2.4503530768532835

Epoch: 5| Step: 11
Training loss: 2.5450241759225536
Validation loss: 2.4715196870954435

Epoch: 171| Step: 0
Training loss: 2.2867922412361024
Validation loss: 2.4613052053090216

Epoch: 5| Step: 1
Training loss: 2.3591207405164663
Validation loss: 2.4700168023265103

Epoch: 5| Step: 2
Training loss: 2.6998783967220046
Validation loss: 2.4732686751282142

Epoch: 5| Step: 3
Training loss: 2.7623731385527734
Validation loss: 2.4738718051167283

Epoch: 5| Step: 4
Training loss: 2.4497483455100744
Validation loss: 2.4649395044975178

Epoch: 5| Step: 5
Training loss: 2.1713057396321958
Validation loss: 2.4757963493659534

Epoch: 5| Step: 6
Training loss: 2.337280091737806
Validation loss: 2.4694447686591245

Epoch: 5| Step: 7
Training loss: 2.4691465035253746
Validation loss: 2.4697010083709823

Epoch: 5| Step: 8
Training loss: 2.865538910515902
Validation loss: 2.460030104858702

Epoch: 5| Step: 9
Training loss: 2.9219903770147324
Validation loss: 2.461363950241719

Epoch: 5| Step: 10
Training loss: 2.1503314184202886
Validation loss: 2.4506035620859095

Epoch: 5| Step: 11
Training loss: 2.8361051315492003
Validation loss: 2.4622993818364955

Epoch: 172| Step: 0
Training loss: 2.593643094353001
Validation loss: 2.4495489779033193

Epoch: 5| Step: 1
Training loss: 2.3970360653312115
Validation loss: 2.4587977901385356

Epoch: 5| Step: 2
Training loss: 2.5177394912889803
Validation loss: 2.4547612105321854

Epoch: 5| Step: 3
Training loss: 2.731671550002358
Validation loss: 2.460459506323791

Epoch: 5| Step: 4
Training loss: 2.7178348447967378
Validation loss: 2.454074827595823

Epoch: 5| Step: 5
Training loss: 2.2479168467363975
Validation loss: 2.4538049261805814

Epoch: 5| Step: 6
Training loss: 2.9207786094193615
Validation loss: 2.4558053933560515

Epoch: 5| Step: 7
Training loss: 2.194174148985317
Validation loss: 2.459002219275018

Epoch: 5| Step: 8
Training loss: 2.50123489398198
Validation loss: 2.459983063351342

Epoch: 5| Step: 9
Training loss: 2.0821853781043376
Validation loss: 2.456555569628493

Epoch: 5| Step: 10
Training loss: 2.5301976783332307
Validation loss: 2.457999446522749

Epoch: 5| Step: 11
Training loss: 1.8599383358321706
Validation loss: 2.461719037645832

Epoch: 173| Step: 0
Training loss: 2.0357730684899926
Validation loss: 2.465435587767571

Epoch: 5| Step: 1
Training loss: 2.1152556780220544
Validation loss: 2.4572360868638046

Epoch: 5| Step: 2
Training loss: 2.6873471416206014
Validation loss: 2.4575627878536763

Epoch: 5| Step: 3
Training loss: 2.561813634736355
Validation loss: 2.462601336380516

Epoch: 5| Step: 4
Training loss: 2.268486583539719
Validation loss: 2.4543633099407014

Epoch: 5| Step: 5
Training loss: 2.681445910003393
Validation loss: 2.4527142397475346

Epoch: 5| Step: 6
Training loss: 2.4734584477321366
Validation loss: 2.4534324809656214

Epoch: 5| Step: 7
Training loss: 2.6478431057160075
Validation loss: 2.459132150941893

Epoch: 5| Step: 8
Training loss: 2.762907255368884
Validation loss: 2.4620616827728523

Epoch: 5| Step: 9
Training loss: 2.6626337868474006
Validation loss: 2.4533162295567656

Epoch: 5| Step: 10
Training loss: 2.3343594429284154
Validation loss: 2.458671232751532

Epoch: 5| Step: 11
Training loss: 2.7511299586159748
Validation loss: 2.455695140248253

Epoch: 174| Step: 0
Training loss: 2.7653337745568054
Validation loss: 2.4570379737232355

Epoch: 5| Step: 1
Training loss: 2.8988324741936955
Validation loss: 2.4544800621945995

Epoch: 5| Step: 2
Training loss: 2.1073229945958087
Validation loss: 2.459008052874536

Epoch: 5| Step: 3
Training loss: 2.4809856206684024
Validation loss: 2.4600008761525856

Epoch: 5| Step: 4
Training loss: 2.2725553603610544
Validation loss: 2.45701711718321

Epoch: 5| Step: 5
Training loss: 2.357466879780905
Validation loss: 2.4724347244835085

Epoch: 5| Step: 6
Training loss: 2.097602602025796
Validation loss: 2.4651212742578106

Epoch: 5| Step: 7
Training loss: 2.3854987339967093
Validation loss: 2.4597518931015605

Epoch: 5| Step: 8
Training loss: 3.024316783075895
Validation loss: 2.46369064369873

Epoch: 5| Step: 9
Training loss: 2.795243709223118
Validation loss: 2.4651570632345523

Epoch: 5| Step: 10
Training loss: 2.2585445919908755
Validation loss: 2.4615842584940806

Epoch: 5| Step: 11
Training loss: 1.6131123969359096
Validation loss: 2.460545443029613

Epoch: 175| Step: 0
Training loss: 2.3713803063173864
Validation loss: 2.4590960965317916

Epoch: 5| Step: 1
Training loss: 2.000956187556405
Validation loss: 2.45791746248046

Epoch: 5| Step: 2
Training loss: 2.476725094629288
Validation loss: 2.454245710206425

Epoch: 5| Step: 3
Training loss: 2.8503676327957845
Validation loss: 2.4641440114190463

Epoch: 5| Step: 4
Training loss: 2.2133147598352876
Validation loss: 2.452000666067262

Epoch: 5| Step: 5
Training loss: 2.485864540626311
Validation loss: 2.4532023415653783

Epoch: 5| Step: 6
Training loss: 2.27344326791982
Validation loss: 2.455325231303467

Epoch: 5| Step: 7
Training loss: 2.7269585876453846
Validation loss: 2.462460033783071

Epoch: 5| Step: 8
Training loss: 3.113017340259189
Validation loss: 2.4707223682885533

Epoch: 5| Step: 9
Training loss: 1.8158466092249208
Validation loss: 2.4696608524975754

Epoch: 5| Step: 10
Training loss: 2.8523864391834253
Validation loss: 2.4704903773609557

Epoch: 5| Step: 11
Training loss: 2.2422021739094093
Validation loss: 2.4669926058049305

Epoch: 176| Step: 0
Training loss: 2.259755707424758
Validation loss: 2.4704697248663505

Epoch: 5| Step: 1
Training loss: 2.3664813609401714
Validation loss: 2.473665771586079

Epoch: 5| Step: 2
Training loss: 2.494508625027076
Validation loss: 2.472509700214835

Epoch: 5| Step: 3
Training loss: 2.85959778631746
Validation loss: 2.4762728428448977

Epoch: 5| Step: 4
Training loss: 2.4637012282159625
Validation loss: 2.472345325593467

Epoch: 5| Step: 5
Training loss: 2.433689954396085
Validation loss: 2.46745345921091

Epoch: 5| Step: 6
Training loss: 2.526619148445025
Validation loss: 2.469346758990664

Epoch: 5| Step: 7
Training loss: 2.508559071299055
Validation loss: 2.462100784421533

Epoch: 5| Step: 8
Training loss: 2.6505690917253535
Validation loss: 2.46487140186596

Epoch: 5| Step: 9
Training loss: 2.2030665613093876
Validation loss: 2.458390806356044

Epoch: 5| Step: 10
Training loss: 2.6566935449418776
Validation loss: 2.46182600663596

Epoch: 5| Step: 11
Training loss: 1.8040699087836947
Validation loss: 2.4655788371378335

Epoch: 177| Step: 0
Training loss: 2.9397734914185425
Validation loss: 2.460943361305644

Epoch: 5| Step: 1
Training loss: 2.4027640122427862
Validation loss: 2.466640702048676

Epoch: 5| Step: 2
Training loss: 2.5906060709336534
Validation loss: 2.45838708872671

Epoch: 5| Step: 3
Training loss: 1.8755240026050144
Validation loss: 2.457778412747641

Epoch: 5| Step: 4
Training loss: 2.776635359976482
Validation loss: 2.4559905168304166

Epoch: 5| Step: 5
Training loss: 2.3869749640313267
Validation loss: 2.4615058605907723

Epoch: 5| Step: 6
Training loss: 2.715857359116704
Validation loss: 2.4611865326354394

Epoch: 5| Step: 7
Training loss: 2.3034964894623418
Validation loss: 2.460213416412458

Epoch: 5| Step: 8
Training loss: 2.2774318985539983
Validation loss: 2.4513031092312354

Epoch: 5| Step: 9
Training loss: 2.9294837168709624
Validation loss: 2.463526894415559

Epoch: 5| Step: 10
Training loss: 2.1527738331857726
Validation loss: 2.4641514998517384

Epoch: 5| Step: 11
Training loss: 0.737447318118986
Validation loss: 2.466851043307788

Epoch: 178| Step: 0
Training loss: 2.7798099861798353
Validation loss: 2.4663327370177295

Epoch: 5| Step: 1
Training loss: 1.9626235096935942
Validation loss: 2.4598112203366256

Epoch: 5| Step: 2
Training loss: 2.362662645826657
Validation loss: 2.461802476923754

Epoch: 5| Step: 3
Training loss: 2.632972055914951
Validation loss: 2.466863357964921

Epoch: 5| Step: 4
Training loss: 2.1754897519893635
Validation loss: 2.4648224013059448

Epoch: 5| Step: 5
Training loss: 2.6523106703570463
Validation loss: 2.464888308807982

Epoch: 5| Step: 6
Training loss: 2.3451983236620157
Validation loss: 2.46376481097405

Epoch: 5| Step: 7
Training loss: 2.8012225070814507
Validation loss: 2.4634960256358274

Epoch: 5| Step: 8
Training loss: 2.705345080041678
Validation loss: 2.4653654317242233

Epoch: 5| Step: 9
Training loss: 2.6065188555098575
Validation loss: 2.463198479962569

Epoch: 5| Step: 10
Training loss: 1.9037667656584176
Validation loss: 2.4648997425907644

Epoch: 5| Step: 11
Training loss: 3.206038327136143
Validation loss: 2.4662281910169996

Epoch: 179| Step: 0
Training loss: 2.139092335238654
Validation loss: 2.4646977997546053

Epoch: 5| Step: 1
Training loss: 2.5272707331632702
Validation loss: 2.461711112038496

Epoch: 5| Step: 2
Training loss: 2.842943852780254
Validation loss: 2.4712881609373047

Epoch: 5| Step: 3
Training loss: 2.735098955501742
Validation loss: 2.471186501885611

Epoch: 5| Step: 4
Training loss: 2.823994016873341
Validation loss: 2.4710501124367914

Epoch: 5| Step: 5
Training loss: 2.559909348372947
Validation loss: 2.464016609836975

Epoch: 5| Step: 6
Training loss: 2.6285637778413684
Validation loss: 2.463776415285395

Epoch: 5| Step: 7
Training loss: 2.1814837967146055
Validation loss: 2.46720775284285

Epoch: 5| Step: 8
Training loss: 2.495185125512212
Validation loss: 2.4655090981669323

Epoch: 5| Step: 9
Training loss: 2.5931555744758272
Validation loss: 2.46941797257538

Epoch: 5| Step: 10
Training loss: 1.7684577565668553
Validation loss: 2.4682862655068054

Epoch: 5| Step: 11
Training loss: 1.0410820973771997
Validation loss: 2.459833977545042

Epoch: 180| Step: 0
Training loss: 2.7358662054074174
Validation loss: 2.460185881785822

Epoch: 5| Step: 1
Training loss: 2.2071999814510863
Validation loss: 2.4721309350931944

Epoch: 5| Step: 2
Training loss: 2.087271388892952
Validation loss: 2.4749995352844163

Epoch: 5| Step: 3
Training loss: 2.043222911188872
Validation loss: 2.470890059203261

Epoch: 5| Step: 4
Training loss: 2.934724023636578
Validation loss: 2.4724646640215826

Epoch: 5| Step: 5
Training loss: 2.7506571764755305
Validation loss: 2.4621942611119283

Epoch: 5| Step: 6
Training loss: 2.676733674445389
Validation loss: 2.4630556467238693

Epoch: 5| Step: 7
Training loss: 2.5351758112689087
Validation loss: 2.4647305115463487

Epoch: 5| Step: 8
Training loss: 2.590616654588535
Validation loss: 2.4631814726949313

Epoch: 5| Step: 9
Training loss: 2.131039843447694
Validation loss: 2.4668771061720363

Epoch: 5| Step: 10
Training loss: 2.5397033821586614
Validation loss: 2.466410534411626

Epoch: 5| Step: 11
Training loss: 1.5973417909989485
Validation loss: 2.4643710207538176

Epoch: 181| Step: 0
Training loss: 2.7794880804584143
Validation loss: 2.4674754896946713

Epoch: 5| Step: 1
Training loss: 2.38145593268361
Validation loss: 2.461028598935957

Epoch: 5| Step: 2
Training loss: 2.4965918197753294
Validation loss: 2.462769677068556

Epoch: 5| Step: 3
Training loss: 2.5994193382361557
Validation loss: 2.466636128950749

Epoch: 5| Step: 4
Training loss: 2.4209646175151454
Validation loss: 2.4655077806078083

Epoch: 5| Step: 5
Training loss: 1.9397778196034872
Validation loss: 2.4667027874076095

Epoch: 5| Step: 6
Training loss: 2.518155075503383
Validation loss: 2.4658641526759766

Epoch: 5| Step: 7
Training loss: 2.1779410636220917
Validation loss: 2.462936923272277

Epoch: 5| Step: 8
Training loss: 1.9847136080944765
Validation loss: 2.471027301735534

Epoch: 5| Step: 9
Training loss: 2.884027157987638
Validation loss: 2.4720065371644

Epoch: 5| Step: 10
Training loss: 2.9203738676086197
Validation loss: 2.464541747730428

Epoch: 5| Step: 11
Training loss: 1.7635226941726434
Validation loss: 2.469138509223111

Epoch: 182| Step: 0
Training loss: 2.19308086743309
Validation loss: 2.4617482318281043

Epoch: 5| Step: 1
Training loss: 2.375597426915096
Validation loss: 2.4754579128490546

Epoch: 5| Step: 2
Training loss: 2.0924205829676334
Validation loss: 2.4648492271979126

Epoch: 5| Step: 3
Training loss: 3.0087667165370293
Validation loss: 2.4659946735035283

Epoch: 5| Step: 4
Training loss: 2.31099022733569
Validation loss: 2.4674818669032605

Epoch: 5| Step: 5
Training loss: 2.387100114337809
Validation loss: 2.468007438785506

Epoch: 5| Step: 6
Training loss: 2.494079923675248
Validation loss: 2.4700999934822487

Epoch: 5| Step: 7
Training loss: 2.796572620946013
Validation loss: 2.4786348467029797

Epoch: 5| Step: 8
Training loss: 2.3013849939704594
Validation loss: 2.4742736347785246

Epoch: 5| Step: 9
Training loss: 2.764153557846854
Validation loss: 2.482731629501597

Epoch: 5| Step: 10
Training loss: 2.3935422363953487
Validation loss: 2.469121261236706

Epoch: 5| Step: 11
Training loss: 2.5167642229215823
Validation loss: 2.4773104848786693

Epoch: 183| Step: 0
Training loss: 1.8744933397485621
Validation loss: 2.4760930913116797

Epoch: 5| Step: 1
Training loss: 2.5311191666310884
Validation loss: 2.4825750744375705

Epoch: 5| Step: 2
Training loss: 2.4142774961465507
Validation loss: 2.4868617617604776

Epoch: 5| Step: 3
Training loss: 2.32107736844317
Validation loss: 2.4834205085432655

Epoch: 5| Step: 4
Training loss: 2.1670227736265293
Validation loss: 2.47959854601005

Epoch: 5| Step: 5
Training loss: 2.8337178436864447
Validation loss: 2.4753055973066695

Epoch: 5| Step: 6
Training loss: 2.2702007520862444
Validation loss: 2.4817428080259645

Epoch: 5| Step: 7
Training loss: 2.8905136499351505
Validation loss: 2.481126318650814

Epoch: 5| Step: 8
Training loss: 2.549229943183364
Validation loss: 2.47754805616752

Epoch: 5| Step: 9
Training loss: 2.5460905961716236
Validation loss: 2.4776617633015445

Epoch: 5| Step: 10
Training loss: 2.3913667812037684
Validation loss: 2.4733879649892674

Epoch: 5| Step: 11
Training loss: 3.96652111032173
Validation loss: 2.4848231545185087

Epoch: 184| Step: 0
Training loss: 1.9822488643524154
Validation loss: 2.477015304486835

Epoch: 5| Step: 1
Training loss: 2.7872655727188556
Validation loss: 2.476831319280853

Epoch: 5| Step: 2
Training loss: 2.1889640268617425
Validation loss: 2.470931304728323

Epoch: 5| Step: 3
Training loss: 2.2972658823834027
Validation loss: 2.4758271209585785

Epoch: 5| Step: 4
Training loss: 2.7541720214730137
Validation loss: 2.477514170360106

Epoch: 5| Step: 5
Training loss: 2.848383890339075
Validation loss: 2.4865308720385126

Epoch: 5| Step: 6
Training loss: 2.6002728355746614
Validation loss: 2.4831056210958447

Epoch: 5| Step: 7
Training loss: 2.913766472637756
Validation loss: 2.4787697407521043

Epoch: 5| Step: 8
Training loss: 2.4409992824867506
Validation loss: 2.4731261222232037

Epoch: 5| Step: 9
Training loss: 1.798592915518624
Validation loss: 2.476401639702158

Epoch: 5| Step: 10
Training loss: 2.759832922674465
Validation loss: 2.4768027380619104

Epoch: 5| Step: 11
Training loss: 2.125669261782237
Validation loss: 2.4694762992437282

Epoch: 185| Step: 0
Training loss: 2.308896427354366
Validation loss: 2.479079098049841

Epoch: 5| Step: 1
Training loss: 2.869817790185423
Validation loss: 2.481092663892501

Epoch: 5| Step: 2
Training loss: 2.2975885230144337
Validation loss: 2.4739636765807154

Epoch: 5| Step: 3
Training loss: 2.793147666909173
Validation loss: 2.4694945866374254

Epoch: 5| Step: 4
Training loss: 2.866521191417347
Validation loss: 2.475374857614682

Epoch: 5| Step: 5
Training loss: 2.657343381355813
Validation loss: 2.4781803458448555

Epoch: 5| Step: 6
Training loss: 1.990438194432654
Validation loss: 2.474283985321452

Epoch: 5| Step: 7
Training loss: 2.316617650490044
Validation loss: 2.478179660369073

Epoch: 5| Step: 8
Training loss: 2.1272777243127945
Validation loss: 2.4724033863205928

Epoch: 5| Step: 9
Training loss: 2.519864129838972
Validation loss: 2.4712482780761844

Epoch: 5| Step: 10
Training loss: 2.6806619279363084
Validation loss: 2.4680069678425642

Epoch: 5| Step: 11
Training loss: 1.7595321720582595
Validation loss: 2.459154668016246

Epoch: 186| Step: 0
Training loss: 2.4167212008757755
Validation loss: 2.466385356761012

Epoch: 5| Step: 1
Training loss: 2.5975774996874152
Validation loss: 2.459983014891947

Epoch: 5| Step: 2
Training loss: 2.9945102371445933
Validation loss: 2.470663504100648

Epoch: 5| Step: 3
Training loss: 2.333147302659432
Validation loss: 2.4630360168410648

Epoch: 5| Step: 4
Training loss: 1.7175807096571623
Validation loss: 2.469978320693296

Epoch: 5| Step: 5
Training loss: 2.6231601261734645
Validation loss: 2.4626404173588354

Epoch: 5| Step: 6
Training loss: 2.78866121199504
Validation loss: 2.4756316351952123

Epoch: 5| Step: 7
Training loss: 2.4915809969596414
Validation loss: 2.4604469335138766

Epoch: 5| Step: 8
Training loss: 2.265709290087482
Validation loss: 2.4708784480958976

Epoch: 5| Step: 9
Training loss: 2.4990512001132257
Validation loss: 2.4621045650350664

Epoch: 5| Step: 10
Training loss: 2.3894041846206995
Validation loss: 2.4678124204695746

Epoch: 5| Step: 11
Training loss: 2.5291824373846
Validation loss: 2.4705950284890315

Epoch: 187| Step: 0
Training loss: 2.199165845000863
Validation loss: 2.4745570385262714

Epoch: 5| Step: 1
Training loss: 3.2908833372429447
Validation loss: 2.4809941533847644

Epoch: 5| Step: 2
Training loss: 1.7959438399134442
Validation loss: 2.4711567177128333

Epoch: 5| Step: 3
Training loss: 2.5829347077320284
Validation loss: 2.4758874592941593

Epoch: 5| Step: 4
Training loss: 2.724852017225447
Validation loss: 2.466615852968819

Epoch: 5| Step: 5
Training loss: 2.303075608198758
Validation loss: 2.4740900439621596

Epoch: 5| Step: 6
Training loss: 2.6716058606680475
Validation loss: 2.474258847639948

Epoch: 5| Step: 7
Training loss: 2.3081833011423427
Validation loss: 2.472023443530364

Epoch: 5| Step: 8
Training loss: 2.2925989739904344
Validation loss: 2.474346449005477

Epoch: 5| Step: 9
Training loss: 2.346069612229621
Validation loss: 2.4793172892059667

Epoch: 5| Step: 10
Training loss: 2.2900990297319033
Validation loss: 2.4815374720330166

Epoch: 5| Step: 11
Training loss: 2.8214146370569533
Validation loss: 2.4769550016466577

Epoch: 188| Step: 0
Training loss: 2.2626784533521684
Validation loss: 2.4829842335401042

Epoch: 5| Step: 1
Training loss: 2.6015336318605256
Validation loss: 2.4811044554218475

Epoch: 5| Step: 2
Training loss: 2.3681133209770113
Validation loss: 2.483557400632924

Epoch: 5| Step: 3
Training loss: 2.5645922051489856
Validation loss: 2.481766554971205

Epoch: 5| Step: 4
Training loss: 2.373142921796011
Validation loss: 2.4854768672749894

Epoch: 5| Step: 5
Training loss: 2.198688124609608
Validation loss: 2.482768465023321

Epoch: 5| Step: 6
Training loss: 2.806753433710643
Validation loss: 2.482249660405988

Epoch: 5| Step: 7
Training loss: 2.4629073720993366
Validation loss: 2.4788385916797138

Epoch: 5| Step: 8
Training loss: 2.7189099494975117
Validation loss: 2.4770097860118097

Epoch: 5| Step: 9
Training loss: 2.381963059402354
Validation loss: 2.4774967761873636

Epoch: 5| Step: 10
Training loss: 2.461241494430949
Validation loss: 2.479151614862051

Epoch: 5| Step: 11
Training loss: 2.5023164507674673
Validation loss: 2.477542374483009

Epoch: 189| Step: 0
Training loss: 2.239393773299665
Validation loss: 2.4720879514863148

Epoch: 5| Step: 1
Training loss: 2.2683294531765426
Validation loss: 2.472084979797189

Epoch: 5| Step: 2
Training loss: 1.9950245720442399
Validation loss: 2.477082050591584

Epoch: 5| Step: 3
Training loss: 2.7006286383765232
Validation loss: 2.470597863248133

Epoch: 5| Step: 4
Training loss: 2.3377577410086254
Validation loss: 2.466997224550267

Epoch: 5| Step: 5
Training loss: 2.2470409220630643
Validation loss: 2.4793809643189597

Epoch: 5| Step: 6
Training loss: 3.260117554680646
Validation loss: 2.4993475976681747

Epoch: 5| Step: 7
Training loss: 2.4144565297738287
Validation loss: 2.4820416527228826

Epoch: 5| Step: 8
Training loss: 2.7040205337546075
Validation loss: 2.4840177803014925

Epoch: 5| Step: 9
Training loss: 2.773163086116153
Validation loss: 2.4636473253320417

Epoch: 5| Step: 10
Training loss: 2.3722003698521257
Validation loss: 2.47355190084028

Epoch: 5| Step: 11
Training loss: 1.4427437714815912
Validation loss: 2.4746942663648195

Epoch: 190| Step: 0
Training loss: 2.2120911516789223
Validation loss: 2.48232049182244

Epoch: 5| Step: 1
Training loss: 2.496703453998298
Validation loss: 2.4940052438834805

Epoch: 5| Step: 2
Training loss: 2.6569243528762234
Validation loss: 2.477463992370737

Epoch: 5| Step: 3
Training loss: 2.1296517562945305
Validation loss: 2.483345190175658

Epoch: 5| Step: 4
Training loss: 2.8508269733119014
Validation loss: 2.4788547020397678

Epoch: 5| Step: 5
Training loss: 2.5429805632286095
Validation loss: 2.480562091182525

Epoch: 5| Step: 6
Training loss: 2.4893042648728207
Validation loss: 2.4884784805964717

Epoch: 5| Step: 7
Training loss: 2.5761575300787594
Validation loss: 2.480893136312657

Epoch: 5| Step: 8
Training loss: 2.6113571587648297
Validation loss: 2.4847226769307302

Epoch: 5| Step: 9
Training loss: 2.7848439516355197
Validation loss: 2.4776360464353897

Epoch: 5| Step: 10
Training loss: 2.483334977407573
Validation loss: 2.47838185147003

Epoch: 5| Step: 11
Training loss: 3.1566794830298406
Validation loss: 2.4844454869281596

Epoch: 191| Step: 0
Training loss: 2.3496592984877034
Validation loss: 2.478003999947775

Epoch: 5| Step: 1
Training loss: 2.4365172728191054
Validation loss: 2.477486643564333

Epoch: 5| Step: 2
Training loss: 3.0644540586160147
Validation loss: 2.487123422616461

Epoch: 5| Step: 3
Training loss: 2.2358986521291104
Validation loss: 2.4755274939425704

Epoch: 5| Step: 4
Training loss: 2.853336984002223
Validation loss: 2.481612915319892

Epoch: 5| Step: 5
Training loss: 2.6392891117459754
Validation loss: 2.473291537455669

Epoch: 5| Step: 6
Training loss: 2.9196419572141368
Validation loss: 2.4762930337374995

Epoch: 5| Step: 7
Training loss: 2.935690951793277
Validation loss: 2.4683221293325412

Epoch: 5| Step: 8
Training loss: 2.4230334064921704
Validation loss: 2.472777168326511

Epoch: 5| Step: 9
Training loss: 2.2215589553390473
Validation loss: 2.4741495332952312

Epoch: 5| Step: 10
Training loss: 1.9622988895464633
Validation loss: 2.4666756192143677

Epoch: 5| Step: 11
Training loss: 0.8344080829133769
Validation loss: 2.46914617763837

Epoch: 192| Step: 0
Training loss: 2.8367496725176173
Validation loss: 2.4710589729343924

Epoch: 5| Step: 1
Training loss: 2.210052097276116
Validation loss: 2.476513012733573

Epoch: 5| Step: 2
Training loss: 2.4242536123696716
Validation loss: 2.4794881369162156

Epoch: 5| Step: 3
Training loss: 2.7362474406488753
Validation loss: 2.4707182872442677

Epoch: 5| Step: 4
Training loss: 2.704084016764357
Validation loss: 2.469573257895145

Epoch: 5| Step: 5
Training loss: 2.854121651027641
Validation loss: 2.481889132828741

Epoch: 5| Step: 6
Training loss: 1.8468633970874024
Validation loss: 2.480535226967379

Epoch: 5| Step: 7
Training loss: 2.397428020554322
Validation loss: 2.4681614846322777

Epoch: 5| Step: 8
Training loss: 2.487601530217094
Validation loss: 2.469246307414315

Epoch: 5| Step: 9
Training loss: 2.3349662471185972
Validation loss: 2.4801394266497514

Epoch: 5| Step: 10
Training loss: 2.5124318962925742
Validation loss: 2.47731662022815

Epoch: 5| Step: 11
Training loss: 1.7829056791516882
Validation loss: 2.4647563751581414

Epoch: 193| Step: 0
Training loss: 2.4939367200506397
Validation loss: 2.488316653971419

Epoch: 5| Step: 1
Training loss: 2.6350079446922563
Validation loss: 2.477420253207991

Epoch: 5| Step: 2
Training loss: 2.750371734463248
Validation loss: 2.4714620839317494

Epoch: 5| Step: 3
Training loss: 1.8964191272326993
Validation loss: 2.473277865070203

Epoch: 5| Step: 4
Training loss: 2.182043081129255
Validation loss: 2.4743749783008377

Epoch: 5| Step: 5
Training loss: 2.472306213190386
Validation loss: 2.4745556816251413

Epoch: 5| Step: 6
Training loss: 2.893572485074358
Validation loss: 2.469240168105009

Epoch: 5| Step: 7
Training loss: 1.826644102024479
Validation loss: 2.4680166442931717

Epoch: 5| Step: 8
Training loss: 2.299192855020304
Validation loss: 2.469320150924983

Epoch: 5| Step: 9
Training loss: 2.650496591067465
Validation loss: 2.475927819114285

Epoch: 5| Step: 10
Training loss: 2.8007290674346894
Validation loss: 2.475676513459512

Epoch: 5| Step: 11
Training loss: 1.487735838586622
Validation loss: 2.465236973014393

Epoch: 194| Step: 0
Training loss: 2.1489481371145978
Validation loss: 2.4805905169538485

Epoch: 5| Step: 1
Training loss: 2.3054906447846837
Validation loss: 2.4815638490218532

Epoch: 5| Step: 2
Training loss: 2.5868359989932213
Validation loss: 2.4781430572903766

Epoch: 5| Step: 3
Training loss: 2.352787142508149
Validation loss: 2.468618490040134

Epoch: 5| Step: 4
Training loss: 2.7474821007851027
Validation loss: 2.47907021813085

Epoch: 5| Step: 5
Training loss: 2.704933046933161
Validation loss: 2.4794166876972263

Epoch: 5| Step: 6
Training loss: 2.279391119282583
Validation loss: 2.4797200432164086

Epoch: 5| Step: 7
Training loss: 2.8582177660594326
Validation loss: 2.4795386625674274

Epoch: 5| Step: 8
Training loss: 1.9029323912621599
Validation loss: 2.4822496483998138

Epoch: 5| Step: 9
Training loss: 2.4605740717819957
Validation loss: 2.474659606857325

Epoch: 5| Step: 10
Training loss: 2.524989639865281
Validation loss: 2.4837492308657843

Epoch: 5| Step: 11
Training loss: 2.808530167455491
Validation loss: 2.4707059797388604

Epoch: 195| Step: 0
Training loss: 2.6047722887908336
Validation loss: 2.4840956996769576

Epoch: 5| Step: 1
Training loss: 2.5291741418701847
Validation loss: 2.486300515987736

Epoch: 5| Step: 2
Training loss: 2.7768734561933903
Validation loss: 2.478989031115095

Epoch: 5| Step: 3
Training loss: 2.5078625064986046
Validation loss: 2.481902445571994

Epoch: 5| Step: 4
Training loss: 2.628188875671768
Validation loss: 2.4759684952411916

Epoch: 5| Step: 5
Training loss: 2.3818727735210214
Validation loss: 2.4815738489057786

Epoch: 5| Step: 6
Training loss: 2.167148524279737
Validation loss: 2.485283103854402

Epoch: 5| Step: 7
Training loss: 2.226862944025107
Validation loss: 2.4812336941174467

Epoch: 5| Step: 8
Training loss: 2.300239019828123
Validation loss: 2.478880728866659

Epoch: 5| Step: 9
Training loss: 2.7604493241207706
Validation loss: 2.474211622958031

Epoch: 5| Step: 10
Training loss: 2.200689498185861
Validation loss: 2.4792059740321677

Epoch: 5| Step: 11
Training loss: 1.6005729037039866
Validation loss: 2.4684496024817415

Epoch: 196| Step: 0
Training loss: 3.0360049677570697
Validation loss: 2.4791744549946837

Epoch: 5| Step: 1
Training loss: 2.55409807877501
Validation loss: 2.472011234951568

Epoch: 5| Step: 2
Training loss: 2.745725170160424
Validation loss: 2.4814142822983705

Epoch: 5| Step: 3
Training loss: 1.8305221881954423
Validation loss: 2.4734436838342218

Epoch: 5| Step: 4
Training loss: 2.637769068873461
Validation loss: 2.4744313574200167

Epoch: 5| Step: 5
Training loss: 2.914455847489011
Validation loss: 2.48461529431366

Epoch: 5| Step: 6
Training loss: 2.0660074638830115
Validation loss: 2.475841633911068

Epoch: 5| Step: 7
Training loss: 2.17629467369998
Validation loss: 2.4729769128682513

Epoch: 5| Step: 8
Training loss: 2.134345206056922
Validation loss: 2.4752861368099563

Epoch: 5| Step: 9
Training loss: 2.349354160111883
Validation loss: 2.4815536329258867

Epoch: 5| Step: 10
Training loss: 2.3303132494137064
Validation loss: 2.474876156592024

Epoch: 5| Step: 11
Training loss: 2.2632308411835984
Validation loss: 2.4761712961657087

Epoch: 197| Step: 0
Training loss: 2.1945324798287205
Validation loss: 2.481836161332388

Epoch: 5| Step: 1
Training loss: 2.439907547809529
Validation loss: 2.484752440421344

Epoch: 5| Step: 2
Training loss: 2.1817019325050206
Validation loss: 2.4829633808964133

Epoch: 5| Step: 3
Training loss: 2.262397835463928
Validation loss: 2.4827468183186765

Epoch: 5| Step: 4
Training loss: 2.48405627239453
Validation loss: 2.4825473396535793

Epoch: 5| Step: 5
Training loss: 2.553997541577284
Validation loss: 2.4779160107186837

Epoch: 5| Step: 6
Training loss: 2.334897425356942
Validation loss: 2.4755149796026967

Epoch: 5| Step: 7
Training loss: 2.6391600207417865
Validation loss: 2.476099594769529

Epoch: 5| Step: 8
Training loss: 1.9704468090677079
Validation loss: 2.4705972239197687

Epoch: 5| Step: 9
Training loss: 2.9156986991832583
Validation loss: 2.4797462232078753

Epoch: 5| Step: 10
Training loss: 2.9950472957589516
Validation loss: 2.481636617473047

Epoch: 5| Step: 11
Training loss: 0.6862883728360859
Validation loss: 2.4749147848429125

Epoch: 198| Step: 0
Training loss: 2.517240207151087
Validation loss: 2.479123390979418

Epoch: 5| Step: 1
Training loss: 2.574195965910646
Validation loss: 2.4761005616609397

Epoch: 5| Step: 2
Training loss: 2.1696598090440817
Validation loss: 2.4701241519745643

Epoch: 5| Step: 3
Training loss: 2.5486056760567743
Validation loss: 2.473929299970554

Epoch: 5| Step: 4
Training loss: 2.2048776567560857
Validation loss: 2.4742435986871376

Epoch: 5| Step: 5
Training loss: 2.9543843485517054
Validation loss: 2.4756423773216265

Epoch: 5| Step: 6
Training loss: 2.1080229770776238
Validation loss: 2.477995232435109

Epoch: 5| Step: 7
Training loss: 2.554770838693468
Validation loss: 2.473395222607604

Epoch: 5| Step: 8
Training loss: 2.2339240199242303
Validation loss: 2.483084481420259

Epoch: 5| Step: 9
Training loss: 2.5146484375
Validation loss: 2.4824407273163698

Epoch: 5| Step: 10
Training loss: 2.6173612166869407
Validation loss: 2.4779864448467053

Epoch: 5| Step: 11
Training loss: 2.0981092478888366
Validation loss: 2.470909172382354

Epoch: 199| Step: 0
Training loss: 2.324968694660714
Validation loss: 2.4761464665024957

Epoch: 5| Step: 1
Training loss: 2.4204546301170526
Validation loss: 2.4815570676524996

Epoch: 5| Step: 2
Training loss: 3.1791280868275904
Validation loss: 2.476565692951699

Epoch: 5| Step: 3
Training loss: 2.5015845045829126
Validation loss: 2.480989678817549

Epoch: 5| Step: 4
Training loss: 3.0766949890034416
Validation loss: 2.4831325615192372

Epoch: 5| Step: 5
Training loss: 1.9201150915301093
Validation loss: 2.4791482489299783

Epoch: 5| Step: 6
Training loss: 2.397319321810321
Validation loss: 2.4771855610467375

Epoch: 5| Step: 7
Training loss: 2.1642275310071346
Validation loss: 2.4790599156218

Epoch: 5| Step: 8
Training loss: 1.761205289664416
Validation loss: 2.487236294594282

Epoch: 5| Step: 9
Training loss: 2.9535076559499354
Validation loss: 2.491442853121036

Epoch: 5| Step: 10
Training loss: 1.8138180905685741
Validation loss: 2.4919433394425496

Epoch: 5| Step: 11
Training loss: 3.099050739524124
Validation loss: 2.480691015743197

Epoch: 200| Step: 0
Training loss: 1.9968930788370955
Validation loss: 2.490828686772906

Epoch: 5| Step: 1
Training loss: 2.440111961610137
Validation loss: 2.4846590667442396

Epoch: 5| Step: 2
Training loss: 2.4417392351044644
Validation loss: 2.494165076382639

Epoch: 5| Step: 3
Training loss: 2.223219332577114
Validation loss: 2.4847873529472615

Epoch: 5| Step: 4
Training loss: 2.367018489028927
Validation loss: 2.4798259873509467

Epoch: 5| Step: 5
Training loss: 2.539752572991913
Validation loss: 2.4809879030027306

Epoch: 5| Step: 6
Training loss: 2.246890144137941
Validation loss: 2.478062866156775

Epoch: 5| Step: 7
Training loss: 2.7263321656268413
Validation loss: 2.484629911864365

Epoch: 5| Step: 8
Training loss: 2.7629994143783274
Validation loss: 2.4837110699893765

Epoch: 5| Step: 9
Training loss: 2.3749578371822846
Validation loss: 2.4852601439844557

Epoch: 5| Step: 10
Training loss: 2.7483975336531508
Validation loss: 2.483675784355862

Epoch: 5| Step: 11
Training loss: 2.8784646429236407
Validation loss: 2.4738420091017845

Epoch: 201| Step: 0
Training loss: 2.3270454720126756
Validation loss: 2.476916808286395

Epoch: 5| Step: 1
Training loss: 2.194722269340377
Validation loss: 2.474030111509702

Epoch: 5| Step: 2
Training loss: 2.5578705442596985
Validation loss: 2.476405915967059

Epoch: 5| Step: 3
Training loss: 2.6882642502096177
Validation loss: 2.4774175786301735

Epoch: 5| Step: 4
Training loss: 2.8398763242844653
Validation loss: 2.4768275731786

Epoch: 5| Step: 5
Training loss: 2.1714549584685643
Validation loss: 2.4788560245273605

Epoch: 5| Step: 6
Training loss: 1.91275384502351
Validation loss: 2.4788536801170538

Epoch: 5| Step: 7
Training loss: 2.8144395710117767
Validation loss: 2.4803798629573888

Epoch: 5| Step: 8
Training loss: 2.226612077127603
Validation loss: 2.4815987863911273

Epoch: 5| Step: 9
Training loss: 2.685852432901108
Validation loss: 2.478544591279004

Epoch: 5| Step: 10
Training loss: 2.3497343846628276
Validation loss: 2.480015742869811

Epoch: 5| Step: 11
Training loss: 2.461737414948778
Validation loss: 2.488595600323486

Epoch: 202| Step: 0
Training loss: 2.453152018598721
Validation loss: 2.485025060925162

Epoch: 5| Step: 1
Training loss: 2.4355161369727343
Validation loss: 2.483038102725892

Epoch: 5| Step: 2
Training loss: 2.54896749648887
Validation loss: 2.4864712953862234

Epoch: 5| Step: 3
Training loss: 3.2246836070915124
Validation loss: 2.479094569709966

Epoch: 5| Step: 4
Training loss: 2.9252955360764274
Validation loss: 2.482009081030583

Epoch: 5| Step: 5
Training loss: 2.353937008438685
Validation loss: 2.4856308655849073

Epoch: 5| Step: 6
Training loss: 2.2086023730611313
Validation loss: 2.4853136380742735

Epoch: 5| Step: 7
Training loss: 1.987543115208171
Validation loss: 2.487402964061942

Epoch: 5| Step: 8
Training loss: 2.0315809713831574
Validation loss: 2.481190493852632

Epoch: 5| Step: 9
Training loss: 2.3783618824062205
Validation loss: 2.4844501591955592

Epoch: 5| Step: 10
Training loss: 2.3155535564649905
Validation loss: 2.4918883571644694

Epoch: 5| Step: 11
Training loss: 1.448811517549819
Validation loss: 2.495217859634807

Epoch: 203| Step: 0
Training loss: 2.737495255139563
Validation loss: 2.4914356520632306

Epoch: 5| Step: 1
Training loss: 2.5726301417226405
Validation loss: 2.4901757606140467

Epoch: 5| Step: 2
Training loss: 2.1278131601010735
Validation loss: 2.4973718299282344

Epoch: 5| Step: 3
Training loss: 2.307020035046977
Validation loss: 2.4840390400081267

Epoch: 5| Step: 4
Training loss: 2.9004286021819223
Validation loss: 2.49329512247047

Epoch: 5| Step: 5
Training loss: 2.5803099650106858
Validation loss: 2.4893142615974386

Epoch: 5| Step: 6
Training loss: 2.2810354262514663
Validation loss: 2.4923744330858093

Epoch: 5| Step: 7
Training loss: 2.181908136016196
Validation loss: 2.4813436692283255

Epoch: 5| Step: 8
Training loss: 2.4388216788093127
Validation loss: 2.4834441394428346

Epoch: 5| Step: 9
Training loss: 2.8747417499819625
Validation loss: 2.479943014984804

Epoch: 5| Step: 10
Training loss: 1.8453486349393862
Validation loss: 2.479670831295365

Epoch: 5| Step: 11
Training loss: 0.5170829275387328
Validation loss: 2.473237698988306

Epoch: 204| Step: 0
Training loss: 2.647193188778832
Validation loss: 2.478372688470541

Epoch: 5| Step: 1
Training loss: 2.3966738898743647
Validation loss: 2.4789154876495187

Epoch: 5| Step: 2
Training loss: 2.5514493712781285
Validation loss: 2.475324170721161

Epoch: 5| Step: 3
Training loss: 2.4252963602723168
Validation loss: 2.4797307676319504

Epoch: 5| Step: 4
Training loss: 2.853587646411007
Validation loss: 2.4788695960145697

Epoch: 5| Step: 5
Training loss: 2.3911345693004016
Validation loss: 2.4767282392396135

Epoch: 5| Step: 6
Training loss: 2.5849164808346563
Validation loss: 2.4827802886057717

Epoch: 5| Step: 7
Training loss: 1.9881471240177655
Validation loss: 2.4873555875516846

Epoch: 5| Step: 8
Training loss: 1.9924693188764082
Validation loss: 2.4842587229870605

Epoch: 5| Step: 9
Training loss: 2.553656040279917
Validation loss: 2.4837835795528065

Epoch: 5| Step: 10
Training loss: 2.389862437578895
Validation loss: 2.4891421187782172

Epoch: 5| Step: 11
Training loss: 1.6602855676885901
Validation loss: 2.479165807825362

Epoch: 205| Step: 0
Training loss: 2.795473653413663
Validation loss: 2.4903789902127778

Epoch: 5| Step: 1
Training loss: 2.642973899103348
Validation loss: 2.4896440591681612

Epoch: 5| Step: 2
Training loss: 2.0905109231841847
Validation loss: 2.4815529724009933

Epoch: 5| Step: 3
Training loss: 2.219881977861883
Validation loss: 2.4808360791492823

Epoch: 5| Step: 4
Training loss: 2.290354705725633
Validation loss: 2.4808170824946325

Epoch: 5| Step: 5
Training loss: 2.648738697670572
Validation loss: 2.4812521270691588

Epoch: 5| Step: 6
Training loss: 2.5822462029947606
Validation loss: 2.480426235285183

Epoch: 5| Step: 7
Training loss: 3.1454727943079472
Validation loss: 2.481351972513622

Epoch: 5| Step: 8
Training loss: 2.4880339351375897
Validation loss: 2.484598677540525

Epoch: 5| Step: 9
Training loss: 1.9491368584258382
Validation loss: 2.479530072758519

Epoch: 5| Step: 10
Training loss: 2.012308275082032
Validation loss: 2.4826266176562193

Epoch: 5| Step: 11
Training loss: 2.1808711294014236
Validation loss: 2.4849064936209655

Epoch: 206| Step: 0
Training loss: 2.245878577499101
Validation loss: 2.4850498858253913

Epoch: 5| Step: 1
Training loss: 2.4757377141589703
Validation loss: 2.4911851651064736

Epoch: 5| Step: 2
Training loss: 2.671187016659899
Validation loss: 2.483806457082662

Epoch: 5| Step: 3
Training loss: 2.2486307428278063
Validation loss: 2.485759741060078

Epoch: 5| Step: 4
Training loss: 2.4869362925616927
Validation loss: 2.4869442676006224

Epoch: 5| Step: 5
Training loss: 2.652277770085543
Validation loss: 2.4808717855788665

Epoch: 5| Step: 6
Training loss: 2.1999121431667645
Validation loss: 2.4805315505360546

Epoch: 5| Step: 7
Training loss: 2.0534003689999025
Validation loss: 2.4855184023154195

Epoch: 5| Step: 8
Training loss: 2.2330618247302576
Validation loss: 2.4810618174671513

Epoch: 5| Step: 9
Training loss: 2.6645910907679164
Validation loss: 2.4831751479154596

Epoch: 5| Step: 10
Training loss: 2.7985999898844685
Validation loss: 2.4960804174283053

Epoch: 5| Step: 11
Training loss: 2.052989882112108
Validation loss: 2.490567299522664

Epoch: 207| Step: 0
Training loss: 2.438021579593728
Validation loss: 2.4916742368304567

Epoch: 5| Step: 1
Training loss: 2.4326649174550234
Validation loss: 2.4983903550818614

Epoch: 5| Step: 2
Training loss: 1.9889951971733522
Validation loss: 2.4948494625099817

Epoch: 5| Step: 3
Training loss: 3.1117415886801525
Validation loss: 2.491352363897644

Epoch: 5| Step: 4
Training loss: 2.4333979985602383
Validation loss: 2.4955506029829557

Epoch: 5| Step: 5
Training loss: 2.771220263853716
Validation loss: 2.486204093802098

Epoch: 5| Step: 6
Training loss: 2.209222242801937
Validation loss: 2.4871552662974037

Epoch: 5| Step: 7
Training loss: 2.5546301972381666
Validation loss: 2.4883527441049114

Epoch: 5| Step: 8
Training loss: 2.3259560126936707
Validation loss: 2.4950656435147134

Epoch: 5| Step: 9
Training loss: 1.6383326910308065
Validation loss: 2.4899660172818168

Epoch: 5| Step: 10
Training loss: 2.639576269158894
Validation loss: 2.5002619367706846

Epoch: 5| Step: 11
Training loss: 2.4420064691868726
Validation loss: 2.4937985991520306

Epoch: 208| Step: 0
Training loss: 2.0707468404942677
Validation loss: 2.502213757588673

Epoch: 5| Step: 1
Training loss: 2.1003421232282453
Validation loss: 2.4956137444872626

Epoch: 5| Step: 2
Training loss: 2.1361475988390595
Validation loss: 2.4856823614246624

Epoch: 5| Step: 3
Training loss: 2.3277952229471532
Validation loss: 2.4843000684590253

Epoch: 5| Step: 4
Training loss: 2.611525511717634
Validation loss: 2.485740694111663

Epoch: 5| Step: 5
Training loss: 2.2807114893078735
Validation loss: 2.4790186771065224

Epoch: 5| Step: 6
Training loss: 2.7698645559310524
Validation loss: 2.485927918162123

Epoch: 5| Step: 7
Training loss: 3.1043126287429
Validation loss: 2.482871054232365

Epoch: 5| Step: 8
Training loss: 2.3089539429245605
Validation loss: 2.484689304775113

Epoch: 5| Step: 9
Training loss: 2.4179811739255737
Validation loss: 2.483092566847334

Epoch: 5| Step: 10
Training loss: 2.565347438578513
Validation loss: 2.4902118716750286

Epoch: 5| Step: 11
Training loss: 3.3981822652448628
Validation loss: 2.4938724924341042

Epoch: 209| Step: 0
Training loss: 3.0944145336642186
Validation loss: 2.485627652305062

Epoch: 5| Step: 1
Training loss: 2.408897825653059
Validation loss: 2.490099507587933

Epoch: 5| Step: 2
Training loss: 2.7941687933548427
Validation loss: 2.49829787285048

Epoch: 5| Step: 3
Training loss: 2.4194421177164425
Validation loss: 2.4786668896139776

Epoch: 5| Step: 4
Training loss: 2.4084675466589385
Validation loss: 2.499986739918193

Epoch: 5| Step: 5
Training loss: 2.6831011590758154
Validation loss: 2.487841373131185

Epoch: 5| Step: 6
Training loss: 2.2628221735584857
Validation loss: 2.493247071002599

Epoch: 5| Step: 7
Training loss: 2.343053383616725
Validation loss: 2.492454131879953

Epoch: 5| Step: 8
Training loss: 2.3332027898328698
Validation loss: 2.496409002781953

Epoch: 5| Step: 9
Training loss: 2.084987123847557
Validation loss: 2.4898778243776043

Epoch: 5| Step: 10
Training loss: 1.9062808925439283
Validation loss: 2.484072772822364

Epoch: 5| Step: 11
Training loss: 2.4145377965873056
Validation loss: 2.4903558080648187

Epoch: 210| Step: 0
Training loss: 2.4679646268872353
Validation loss: 2.487491859729425

Epoch: 5| Step: 1
Training loss: 2.4160126645217312
Validation loss: 2.4936649244260147

Epoch: 5| Step: 2
Training loss: 1.8776646435468978
Validation loss: 2.4869565406821956

Epoch: 5| Step: 3
Training loss: 2.775470515046957
Validation loss: 2.482711799072636

Epoch: 5| Step: 4
Training loss: 2.6290609645805016
Validation loss: 2.4864590778410975

Epoch: 5| Step: 5
Training loss: 2.4558162626569144
Validation loss: 2.48771405505106

Epoch: 5| Step: 6
Training loss: 2.6942131122330353
Validation loss: 2.4964793130847887

Epoch: 5| Step: 7
Training loss: 2.0994185959836855
Validation loss: 2.5002793752018193

Epoch: 5| Step: 8
Training loss: 2.0001594956697017
Validation loss: 2.4885116402619056

Epoch: 5| Step: 9
Training loss: 2.4248404774845618
Validation loss: 2.501722326659124

Epoch: 5| Step: 10
Training loss: 2.604479554771107
Validation loss: 2.4917382101379206

Epoch: 5| Step: 11
Training loss: 3.3446229169616473
Validation loss: 2.488237609161194

Epoch: 211| Step: 0
Training loss: 2.119220953618652
Validation loss: 2.48473222231631

Epoch: 5| Step: 1
Training loss: 2.5132256669813455
Validation loss: 2.4897173535546715

Epoch: 5| Step: 2
Training loss: 2.984784482654979
Validation loss: 2.485076501360826

Epoch: 5| Step: 3
Training loss: 2.4748417505092073
Validation loss: 2.4756472407568824

Epoch: 5| Step: 4
Training loss: 2.319816150944322
Validation loss: 2.4825114292305535

Epoch: 5| Step: 5
Training loss: 2.193153052336777
Validation loss: 2.4859689361675392

Epoch: 5| Step: 6
Training loss: 2.477609695793004
Validation loss: 2.4864846075678355

Epoch: 5| Step: 7
Training loss: 2.3542365904919644
Validation loss: 2.490150986814868

Epoch: 5| Step: 8
Training loss: 2.4789731780982853
Validation loss: 2.481400066164894

Epoch: 5| Step: 9
Training loss: 2.559267750264029
Validation loss: 2.4921898358532393

Epoch: 5| Step: 10
Training loss: 2.3104161332740087
Validation loss: 2.493660151903447

Epoch: 5| Step: 11
Training loss: 1.4655704577612765
Validation loss: 2.493125631332796

Epoch: 212| Step: 0
Training loss: 2.896905128956051
Validation loss: 2.4918841872003252

Epoch: 5| Step: 1
Training loss: 2.304331399594623
Validation loss: 2.4994871487695054

Epoch: 5| Step: 2
Training loss: 2.291221459809825
Validation loss: 2.498799174716877

Epoch: 5| Step: 3
Training loss: 2.043129092282701
Validation loss: 2.4959670379426857

Epoch: 5| Step: 4
Training loss: 2.2987919288449756
Validation loss: 2.493907940515068

Epoch: 5| Step: 5
Training loss: 1.8806813949085777
Validation loss: 2.497196361914447

Epoch: 5| Step: 6
Training loss: 2.747989439753824
Validation loss: 2.5032553002696853

Epoch: 5| Step: 7
Training loss: 2.159182448020906
Validation loss: 2.5079203470556637

Epoch: 5| Step: 8
Training loss: 2.538761062335016
Validation loss: 2.493580097252182

Epoch: 5| Step: 9
Training loss: 2.694784272995636
Validation loss: 2.4995557151837606

Epoch: 5| Step: 10
Training loss: 2.5707986945771446
Validation loss: 2.5100052299862967

Epoch: 5| Step: 11
Training loss: 2.57534631048467
Validation loss: 2.4972788385878726

Epoch: 213| Step: 0
Training loss: 2.9639781949969675
Validation loss: 2.494040379392875

Epoch: 5| Step: 1
Training loss: 1.6858037264466947
Validation loss: 2.4940830264887652

Epoch: 5| Step: 2
Training loss: 2.3561319458222765
Validation loss: 2.487700625656511

Epoch: 5| Step: 3
Training loss: 2.403578030231619
Validation loss: 2.4953617501141085

Epoch: 5| Step: 4
Training loss: 2.039378174648684
Validation loss: 2.4855323151197917

Epoch: 5| Step: 5
Training loss: 3.0595185695233655
Validation loss: 2.4818937318572587

Epoch: 5| Step: 6
Training loss: 2.404048854204527
Validation loss: 2.485796136071578

Epoch: 5| Step: 7
Training loss: 2.5170296485133745
Validation loss: 2.4835598046022036

Epoch: 5| Step: 8
Training loss: 1.9816949723737742
Validation loss: 2.480393688437873

Epoch: 5| Step: 9
Training loss: 2.700988454376706
Validation loss: 2.4852703168638666

Epoch: 5| Step: 10
Training loss: 2.4373139530485393
Validation loss: 2.4928557039262698

Epoch: 5| Step: 11
Training loss: 1.6201435291616075
Validation loss: 2.4881016193828684

Epoch: 214| Step: 0
Training loss: 1.7715165409755425
Validation loss: 2.4945933529285327

Epoch: 5| Step: 1
Training loss: 2.260072626280406
Validation loss: 2.501259252183824

Epoch: 5| Step: 2
Training loss: 2.348810251873105
Validation loss: 2.4948182685299187

Epoch: 5| Step: 3
Training loss: 2.403992225317038
Validation loss: 2.50698934099802

Epoch: 5| Step: 4
Training loss: 2.623267737525413
Validation loss: 2.522366200872378

Epoch: 5| Step: 5
Training loss: 2.8897223635567384
Validation loss: 2.5189828359613

Epoch: 5| Step: 6
Training loss: 2.552471821598611
Validation loss: 2.5115182103397995

Epoch: 5| Step: 7
Training loss: 3.015695679780112
Validation loss: 2.5045675197015993

Epoch: 5| Step: 8
Training loss: 2.4631507246120736
Validation loss: 2.5062649429142185

Epoch: 5| Step: 9
Training loss: 1.9335089154369625
Validation loss: 2.5028594611579913

Epoch: 5| Step: 10
Training loss: 1.8240449810379489
Validation loss: 2.497985131219227

Epoch: 5| Step: 11
Training loss: 4.158060238928908
Validation loss: 2.4991824998976258

Epoch: 215| Step: 0
Training loss: 2.9361163187918127
Validation loss: 2.4944998876470064

Epoch: 5| Step: 1
Training loss: 2.0979948143544944
Validation loss: 2.504287008376066

Epoch: 5| Step: 2
Training loss: 1.949983924408209
Validation loss: 2.5012261721549836

Epoch: 5| Step: 3
Training loss: 2.088714009037104
Validation loss: 2.4988425038885933

Epoch: 5| Step: 4
Training loss: 2.553435599252033
Validation loss: 2.5019893400423587

Epoch: 5| Step: 5
Training loss: 2.8383634085488874
Validation loss: 2.492791779223071

Epoch: 5| Step: 6
Training loss: 2.4237615313361403
Validation loss: 2.5016530810192044

Epoch: 5| Step: 7
Training loss: 2.4177835667804217
Validation loss: 2.5044632052717217

Epoch: 5| Step: 8
Training loss: 2.9523064018687384
Validation loss: 2.4994065335316273

Epoch: 5| Step: 9
Training loss: 2.104526967338766
Validation loss: 2.4874381209429353

Epoch: 5| Step: 10
Training loss: 2.4081443166861476
Validation loss: 2.489744154605234

Epoch: 5| Step: 11
Training loss: 1.7758017086087425
Validation loss: 2.4891340709612884

Epoch: 216| Step: 0
Training loss: 2.6562966735329594
Validation loss: 2.490176745975842

Epoch: 5| Step: 1
Training loss: 2.1921358304993626
Validation loss: 2.4793791212415153

Epoch: 5| Step: 2
Training loss: 2.5449696534151833
Validation loss: 2.4823848542525075

Epoch: 5| Step: 3
Training loss: 2.553855363835405
Validation loss: 2.487771218017292

Epoch: 5| Step: 4
Training loss: 2.196540570477287
Validation loss: 2.493995353592432

Epoch: 5| Step: 5
Training loss: 2.447771292624144
Validation loss: 2.494908452867652

Epoch: 5| Step: 6
Training loss: 2.984893114741817
Validation loss: 2.49043839958996

Epoch: 5| Step: 7
Training loss: 2.095439855245357
Validation loss: 2.502072889532251

Epoch: 5| Step: 8
Training loss: 2.492240881273423
Validation loss: 2.498272179530984

Epoch: 5| Step: 9
Training loss: 2.2706325570570596
Validation loss: 2.5022760719328097

Epoch: 5| Step: 10
Training loss: 2.3067815028621634
Validation loss: 2.4951372418278894

Epoch: 5| Step: 11
Training loss: 2.7636254620108893
Validation loss: 2.5066840622768383

Epoch: 217| Step: 0
Training loss: 2.144796608660876
Validation loss: 2.4956322821983696

Epoch: 5| Step: 1
Training loss: 2.555899143157389
Validation loss: 2.4871773978648584

Epoch: 5| Step: 2
Training loss: 2.6996653031484175
Validation loss: 2.4871064052021836

Epoch: 5| Step: 3
Training loss: 1.8895041556069112
Validation loss: 2.497693547604847

Epoch: 5| Step: 4
Training loss: 3.1950137271496666
Validation loss: 2.50081459920142

Epoch: 5| Step: 5
Training loss: 2.4943305580272916
Validation loss: 2.5007505959011755

Epoch: 5| Step: 6
Training loss: 2.0427058034281713
Validation loss: 2.5086744615656054

Epoch: 5| Step: 7
Training loss: 2.490992627359978
Validation loss: 2.505014698901677

Epoch: 5| Step: 8
Training loss: 2.808859524732662
Validation loss: 2.4983902517005787

Epoch: 5| Step: 9
Training loss: 2.4662182537806263
Validation loss: 2.5017955769138025

Epoch: 5| Step: 10
Training loss: 2.3778116749142777
Validation loss: 2.4989788433556788

Epoch: 5| Step: 11
Training loss: 2.5754786000326373
Validation loss: 2.4974169857865003

Epoch: 218| Step: 0
Training loss: 2.070914472478121
Validation loss: 2.4882318800215946

Epoch: 5| Step: 1
Training loss: 2.592156989600385
Validation loss: 2.4914717927104486

Epoch: 5| Step: 2
Training loss: 2.101839182058206
Validation loss: 2.4845751475838465

Epoch: 5| Step: 3
Training loss: 2.9062757593469475
Validation loss: 2.492566654856661

Epoch: 5| Step: 4
Training loss: 2.9017964356612116
Validation loss: 2.4943690243952665

Epoch: 5| Step: 5
Training loss: 2.467498558685593
Validation loss: 2.494129843055006

Epoch: 5| Step: 6
Training loss: 2.213237523146195
Validation loss: 2.4912826186828188

Epoch: 5| Step: 7
Training loss: 2.816355626766346
Validation loss: 2.48732007205011

Epoch: 5| Step: 8
Training loss: 2.5690812985514677
Validation loss: 2.4962693950082357

Epoch: 5| Step: 9
Training loss: 2.380586178183393
Validation loss: 2.497794943148494

Epoch: 5| Step: 10
Training loss: 1.4444915914584582
Validation loss: 2.4916938723372795

Epoch: 5| Step: 11
Training loss: 1.4752868308799885
Validation loss: 2.4974087359135217

Epoch: 219| Step: 0
Training loss: 2.4271962435631047
Validation loss: 2.5080306135577546

Epoch: 5| Step: 1
Training loss: 2.4053086260050347
Validation loss: 2.513999322856497

Epoch: 5| Step: 2
Training loss: 2.6781861128004834
Validation loss: 2.5127762861630685

Epoch: 5| Step: 3
Training loss: 2.091003438456922
Validation loss: 2.5075179191435906

Epoch: 5| Step: 4
Training loss: 2.4650351666153054
Validation loss: 2.4883447436381743

Epoch: 5| Step: 5
Training loss: 2.509863944298651
Validation loss: 2.492775611484951

Epoch: 5| Step: 6
Training loss: 2.687213438857994
Validation loss: 2.5084627205776147

Epoch: 5| Step: 7
Training loss: 2.847305925167533
Validation loss: 2.4999611454169566

Epoch: 5| Step: 8
Training loss: 1.7585775787274305
Validation loss: 2.5047948116636096

Epoch: 5| Step: 9
Training loss: 2.5585135177961926
Validation loss: 2.500026523926221

Epoch: 5| Step: 10
Training loss: 2.607276575276227
Validation loss: 2.4976499678129347

Epoch: 5| Step: 11
Training loss: 1.3382322000666274
Validation loss: 2.4943419165899665

Epoch: 220| Step: 0
Training loss: 2.549605234293836
Validation loss: 2.487485601712574

Epoch: 5| Step: 1
Training loss: 2.5528056361694187
Validation loss: 2.496409313171931

Epoch: 5| Step: 2
Training loss: 2.6491637907905563
Validation loss: 2.4948680696090304

Epoch: 5| Step: 3
Training loss: 2.602474659879739
Validation loss: 2.498603291564386

Epoch: 5| Step: 4
Training loss: 2.6009540934722586
Validation loss: 2.495056191412381

Epoch: 5| Step: 5
Training loss: 2.470439188131754
Validation loss: 2.491595298538135

Epoch: 5| Step: 6
Training loss: 2.062996428885538
Validation loss: 2.4920179454880356

Epoch: 5| Step: 7
Training loss: 2.1181316452394885
Validation loss: 2.493860024341137

Epoch: 5| Step: 8
Training loss: 2.032226327862192
Validation loss: 2.498395770664607

Epoch: 5| Step: 9
Training loss: 2.7469151273710626
Validation loss: 2.4964539830604116

Epoch: 5| Step: 10
Training loss: 2.4684519527488855
Validation loss: 2.5073598173858893

Epoch: 5| Step: 11
Training loss: 2.765997048046112
Validation loss: 2.5117773936116166

Epoch: 221| Step: 0
Training loss: 2.7849743370366773
Validation loss: 2.4979755072282472

Epoch: 5| Step: 1
Training loss: 2.362613703499345
Validation loss: 2.4951625633219594

Epoch: 5| Step: 2
Training loss: 2.2688600791939466
Validation loss: 2.493581702752652

Epoch: 5| Step: 3
Training loss: 2.35873384163906
Validation loss: 2.4876692382072187

Epoch: 5| Step: 4
Training loss: 2.259527907730774
Validation loss: 2.484144847933587

Epoch: 5| Step: 5
Training loss: 2.66430349742166
Validation loss: 2.4956663558798082

Epoch: 5| Step: 6
Training loss: 2.3297046192545685
Validation loss: 2.491253652970309

Epoch: 5| Step: 7
Training loss: 2.4094064990011956
Validation loss: 2.4937327267232603

Epoch: 5| Step: 8
Training loss: 2.3572706728708526
Validation loss: 2.4989425131289207

Epoch: 5| Step: 9
Training loss: 2.0898315429330983
Validation loss: 2.4982224105232285

Epoch: 5| Step: 10
Training loss: 3.0440344456291486
Validation loss: 2.4912381491576188

Epoch: 5| Step: 11
Training loss: 1.9399422665490165
Validation loss: 2.4998004038924266

Epoch: 222| Step: 0
Training loss: 2.3688537977520925
Validation loss: 2.4855979292695705

Epoch: 5| Step: 1
Training loss: 2.3297871026610104
Validation loss: 2.4894812428652133

Epoch: 5| Step: 2
Training loss: 2.2806353851525163
Validation loss: 2.4965298211542244

Epoch: 5| Step: 3
Training loss: 2.6031444425188823
Validation loss: 2.4909142297945084

Epoch: 5| Step: 4
Training loss: 2.0536626428284945
Validation loss: 2.489465372863614

Epoch: 5| Step: 5
Training loss: 3.08199442755649
Validation loss: 2.4941376756029805

Epoch: 5| Step: 6
Training loss: 2.5972420957443014
Validation loss: 2.505718055758082

Epoch: 5| Step: 7
Training loss: 2.471002348018381
Validation loss: 2.500842274401235

Epoch: 5| Step: 8
Training loss: 2.6429031747321963
Validation loss: 2.4977161644892836

Epoch: 5| Step: 9
Training loss: 2.1046529403148693
Validation loss: 2.4999680000482423

Epoch: 5| Step: 10
Training loss: 2.158297023197743
Validation loss: 2.4979942580689793

Epoch: 5| Step: 11
Training loss: 1.9679116780303114
Validation loss: 2.4958668278806675

Epoch: 223| Step: 0
Training loss: 2.2575871444222577
Validation loss: 2.508824660149012

Epoch: 5| Step: 1
Training loss: 2.3410655606559914
Validation loss: 2.4941359051664977

Epoch: 5| Step: 2
Training loss: 2.5584024372356415
Validation loss: 2.501564632989092

Epoch: 5| Step: 3
Training loss: 2.292036812684714
Validation loss: 2.4931126175964464

Epoch: 5| Step: 4
Training loss: 2.8002436293468307
Validation loss: 2.4987295379678685

Epoch: 5| Step: 5
Training loss: 1.8711047719738323
Validation loss: 2.5043717902257927

Epoch: 5| Step: 6
Training loss: 2.8024192712677123
Validation loss: 2.492495179989515

Epoch: 5| Step: 7
Training loss: 2.0002226705573367
Validation loss: 2.510624300546939

Epoch: 5| Step: 8
Training loss: 2.0665975384789763
Validation loss: 2.5027153884884363

Epoch: 5| Step: 9
Training loss: 2.6540374516803404
Validation loss: 2.5030973876623928

Epoch: 5| Step: 10
Training loss: 2.6220995000994205
Validation loss: 2.5016432884715742

Epoch: 5| Step: 11
Training loss: 3.242840878017921
Validation loss: 2.5032168950529106

Epoch: 224| Step: 0
Training loss: 2.25599454664694
Validation loss: 2.4950882444052978

Epoch: 5| Step: 1
Training loss: 2.245166992059857
Validation loss: 2.5046734480087873

Epoch: 5| Step: 2
Training loss: 2.5334148803770224
Validation loss: 2.5039370173380573

Epoch: 5| Step: 3
Training loss: 2.7496870036167547
Validation loss: 2.4937722360484837

Epoch: 5| Step: 4
Training loss: 1.9766824557728242
Validation loss: 2.499983509327224

Epoch: 5| Step: 5
Training loss: 2.3590453467059387
Validation loss: 2.5153936078291785

Epoch: 5| Step: 6
Training loss: 2.3324182850547026
Validation loss: 2.504771731208291

Epoch: 5| Step: 7
Training loss: 2.120213559568349
Validation loss: 2.516740741071175

Epoch: 5| Step: 8
Training loss: 1.9937358748076117
Validation loss: 2.508931398592146

Epoch: 5| Step: 9
Training loss: 2.7984541372276417
Validation loss: 2.5221812385699094

Epoch: 5| Step: 10
Training loss: 3.1152908559241133
Validation loss: 2.5093695777083895

Epoch: 5| Step: 11
Training loss: 2.0747197295114757
Validation loss: 2.505894738748344

Epoch: 225| Step: 0
Training loss: 2.3316129632000147
Validation loss: 2.4987624284143526

Epoch: 5| Step: 1
Training loss: 2.161249418771554
Validation loss: 2.5128900773945047

Epoch: 5| Step: 2
Training loss: 2.5618357844258375
Validation loss: 2.505399071509883

Epoch: 5| Step: 3
Training loss: 2.502177529913662
Validation loss: 2.4977812696661963

Epoch: 5| Step: 4
Training loss: 2.091610284883823
Validation loss: 2.509824237064869

Epoch: 5| Step: 5
Training loss: 2.4387785663818486
Validation loss: 2.502628065637538

Epoch: 5| Step: 6
Training loss: 2.360550745371124
Validation loss: 2.507231235977734

Epoch: 5| Step: 7
Training loss: 2.5176017055783286
Validation loss: 2.5094853621965023

Epoch: 5| Step: 8
Training loss: 2.487276697918685
Validation loss: 2.5047034245851605

Epoch: 5| Step: 9
Training loss: 2.7532080231877343
Validation loss: 2.513399913177485

Epoch: 5| Step: 10
Training loss: 2.32353054083529
Validation loss: 2.504901916153446

Epoch: 5| Step: 11
Training loss: 2.343105787115524
Validation loss: 2.5017546258106416

Epoch: 226| Step: 0
Training loss: 2.4590349866341312
Validation loss: 2.4998318695117314

Epoch: 5| Step: 1
Training loss: 2.00945965483277
Validation loss: 2.4981958634658032

Epoch: 5| Step: 2
Training loss: 2.571301301955298
Validation loss: 2.4927375270208936

Epoch: 5| Step: 3
Training loss: 2.2498459233405237
Validation loss: 2.492579143368329

Epoch: 5| Step: 4
Training loss: 2.8378479462766366
Validation loss: 2.4995268175230847

Epoch: 5| Step: 5
Training loss: 2.190488898692575
Validation loss: 2.492124215880119

Epoch: 5| Step: 6
Training loss: 2.270634447073401
Validation loss: 2.492787602799902

Epoch: 5| Step: 7
Training loss: 2.902459410548718
Validation loss: 2.4901705824715648

Epoch: 5| Step: 8
Training loss: 2.1040712718930914
Validation loss: 2.4941515980804994

Epoch: 5| Step: 9
Training loss: 2.2423828252588516
Validation loss: 2.4971568610158736

Epoch: 5| Step: 10
Training loss: 2.472675052227832
Validation loss: 2.5027933211331423

Epoch: 5| Step: 11
Training loss: 3.1135400834414013
Validation loss: 2.50772134173524

Epoch: 227| Step: 0
Training loss: 2.239453180360685
Validation loss: 2.4988979374174387

Epoch: 5| Step: 1
Training loss: 2.54493780123806
Validation loss: 2.4982697221200256

Epoch: 5| Step: 2
Training loss: 3.0985818757139416
Validation loss: 2.5031444007480466

Epoch: 5| Step: 3
Training loss: 2.2786509719064085
Validation loss: 2.5105907582955225

Epoch: 5| Step: 4
Training loss: 2.110558523950478
Validation loss: 2.503199937439269

Epoch: 5| Step: 5
Training loss: 2.3712557339837743
Validation loss: 2.4969111036126166

Epoch: 5| Step: 6
Training loss: 2.3568281359933447
Validation loss: 2.5004842805696956

Epoch: 5| Step: 7
Training loss: 2.124946481367363
Validation loss: 2.501233059064619

Epoch: 5| Step: 8
Training loss: 2.685316041215808
Validation loss: 2.50418545122977

Epoch: 5| Step: 9
Training loss: 2.6115932515465414
Validation loss: 2.5014389982916794

Epoch: 5| Step: 10
Training loss: 2.2509785749380917
Validation loss: 2.5096205851284283

Epoch: 5| Step: 11
Training loss: 2.153219885873853
Validation loss: 2.505202966844253

Epoch: 228| Step: 0
Training loss: 2.125626752090517
Validation loss: 2.5057482041882144

Epoch: 5| Step: 1
Training loss: 2.5752951147351086
Validation loss: 2.5158488448482874

Epoch: 5| Step: 2
Training loss: 2.2937155032357293
Validation loss: 2.5078963466741544

Epoch: 5| Step: 3
Training loss: 3.1626350102612033
Validation loss: 2.5212815683576433

Epoch: 5| Step: 4
Training loss: 2.13045855282958
Validation loss: 2.5111519711458294

Epoch: 5| Step: 5
Training loss: 2.389244528722371
Validation loss: 2.5124843967010175

Epoch: 5| Step: 6
Training loss: 2.1088339782889123
Validation loss: 2.496352718094718

Epoch: 5| Step: 7
Training loss: 2.4742534474817828
Validation loss: 2.5097341612193116

Epoch: 5| Step: 8
Training loss: 2.990349665835486
Validation loss: 2.499599325337998

Epoch: 5| Step: 9
Training loss: 2.0463337655885923
Validation loss: 2.5073278043895266

Epoch: 5| Step: 10
Training loss: 2.1178514628930363
Validation loss: 2.4943207407145835

Epoch: 5| Step: 11
Training loss: 0.6369773947898277
Validation loss: 2.4874871073121954

Epoch: 229| Step: 0
Training loss: 2.1839158259089935
Validation loss: 2.4969449609178387

Epoch: 5| Step: 1
Training loss: 2.366292752919023
Validation loss: 2.4906374297236713

Epoch: 5| Step: 2
Training loss: 2.8646015698401524
Validation loss: 2.495111816559726

Epoch: 5| Step: 3
Training loss: 2.0193539215092886
Validation loss: 2.4891490650629566

Epoch: 5| Step: 4
Training loss: 2.5651191723896165
Validation loss: 2.495073387523004

Epoch: 5| Step: 5
Training loss: 2.3250497053842363
Validation loss: 2.4939829418789006

Epoch: 5| Step: 6
Training loss: 2.9264308070885185
Validation loss: 2.503117917797342

Epoch: 5| Step: 7
Training loss: 2.1280845246127993
Validation loss: 2.50919607703529

Epoch: 5| Step: 8
Training loss: 2.1298384838922084
Validation loss: 2.5059395804767033

Epoch: 5| Step: 9
Training loss: 2.2135869518958398
Validation loss: 2.5136789491243174

Epoch: 5| Step: 10
Training loss: 2.6345779431278036
Validation loss: 2.5088568559858815

Epoch: 5| Step: 11
Training loss: 1.9313322771934402
Validation loss: 2.5099127581621343

Epoch: 230| Step: 0
Training loss: 2.300488801513955
Validation loss: 2.5083275817623503

Epoch: 5| Step: 1
Training loss: 2.541421211355775
Validation loss: 2.511479213558711

Epoch: 5| Step: 2
Training loss: 2.165798771479585
Validation loss: 2.5036130942821626

Epoch: 5| Step: 3
Training loss: 2.190706246647492
Validation loss: 2.505709575517549

Epoch: 5| Step: 4
Training loss: 1.8901075805846268
Validation loss: 2.5110807582498653

Epoch: 5| Step: 5
Training loss: 2.7883899209010683
Validation loss: 2.5060125885386193

Epoch: 5| Step: 6
Training loss: 2.5400250767048163
Validation loss: 2.5088071742034495

Epoch: 5| Step: 7
Training loss: 2.717624036525315
Validation loss: 2.5045320559007775

Epoch: 5| Step: 8
Training loss: 2.22111363839803
Validation loss: 2.5122503941101906

Epoch: 5| Step: 9
Training loss: 2.859367995957098
Validation loss: 2.503941264430914

Epoch: 5| Step: 10
Training loss: 1.9513792857533017
Validation loss: 2.515933785925999

Epoch: 5| Step: 11
Training loss: 2.6939467356060005
Validation loss: 2.507054900773739

Epoch: 231| Step: 0
Training loss: 2.8038457175730764
Validation loss: 2.499989382403397

Epoch: 5| Step: 1
Training loss: 2.812323925016891
Validation loss: 2.5074591184663975

Epoch: 5| Step: 2
Training loss: 2.2728436405561436
Validation loss: 2.5125557872721482

Epoch: 5| Step: 3
Training loss: 2.3412907222825488
Validation loss: 2.5056435305489897

Epoch: 5| Step: 4
Training loss: 2.2771732011275185
Validation loss: 2.5041505175708223

Epoch: 5| Step: 5
Training loss: 2.453751890907589
Validation loss: 2.500901846344949

Epoch: 5| Step: 6
Training loss: 1.92836849214664
Validation loss: 2.5107358054286815

Epoch: 5| Step: 7
Training loss: 2.2996286507069668
Validation loss: 2.5121794891577682

Epoch: 5| Step: 8
Training loss: 2.3835418085361018
Validation loss: 2.51115245377731

Epoch: 5| Step: 9
Training loss: 2.0552718923349578
Validation loss: 2.515818317954394

Epoch: 5| Step: 10
Training loss: 2.5196782032301765
Validation loss: 2.5165154439026667

Epoch: 5| Step: 11
Training loss: 3.1977137564402853
Validation loss: 2.509950223830651

Epoch: 232| Step: 0
Training loss: 2.575999638119074
Validation loss: 2.5169450364884405

Epoch: 5| Step: 1
Training loss: 2.646218960111025
Validation loss: 2.520146305211954

Epoch: 5| Step: 2
Training loss: 2.6978720191197123
Validation loss: 2.5152134213100807

Epoch: 5| Step: 3
Training loss: 2.059293508581544
Validation loss: 2.5192775983064357

Epoch: 5| Step: 4
Training loss: 1.8969662463694794
Validation loss: 2.517675517753113

Epoch: 5| Step: 5
Training loss: 2.028896905512511
Validation loss: 2.5103818856727877

Epoch: 5| Step: 6
Training loss: 1.987170195656408
Validation loss: 2.5160416718068372

Epoch: 5| Step: 7
Training loss: 2.556295373042936
Validation loss: 2.5026002752225525

Epoch: 5| Step: 8
Training loss: 2.449071852371799
Validation loss: 2.5037283554004945

Epoch: 5| Step: 9
Training loss: 2.187482997283252
Validation loss: 2.4926288696218726

Epoch: 5| Step: 10
Training loss: 2.798186522134039
Validation loss: 2.4977228244296747

Epoch: 5| Step: 11
Training loss: 4.168144930232613
Validation loss: 2.493518820542255

Epoch: 233| Step: 0
Training loss: 2.7029365958999256
Validation loss: 2.4927481496021864

Epoch: 5| Step: 1
Training loss: 1.9383712163401043
Validation loss: 2.4896519716662238

Epoch: 5| Step: 2
Training loss: 2.4099484049549025
Validation loss: 2.4968687435385277

Epoch: 5| Step: 3
Training loss: 2.5950199373394436
Validation loss: 2.4895857780370054

Epoch: 5| Step: 4
Training loss: 2.722082003617401
Validation loss: 2.4875834558055887

Epoch: 5| Step: 5
Training loss: 2.343303892277158
Validation loss: 2.50085974850846

Epoch: 5| Step: 6
Training loss: 2.4628598410174667
Validation loss: 2.4923521483751374

Epoch: 5| Step: 7
Training loss: 1.9035779642582338
Validation loss: 2.501736296272021

Epoch: 5| Step: 8
Training loss: 2.247526080327098
Validation loss: 2.4953857476414574

Epoch: 5| Step: 9
Training loss: 2.303206870126233
Validation loss: 2.497046291378502

Epoch: 5| Step: 10
Training loss: 2.692239707046487
Validation loss: 2.502296239596605

Epoch: 5| Step: 11
Training loss: 2.7155692249536076
Validation loss: 2.5041189395991985

Epoch: 234| Step: 0
Training loss: 2.085031605579313
Validation loss: 2.51592192072371

Epoch: 5| Step: 1
Training loss: 2.5479477571434472
Validation loss: 2.5087422977462954

Epoch: 5| Step: 2
Training loss: 2.940281464214974
Validation loss: 2.5181656520109357

Epoch: 5| Step: 3
Training loss: 2.7001659978065145
Validation loss: 2.5167806233780268

Epoch: 5| Step: 4
Training loss: 2.2320183550308954
Validation loss: 2.519798079365937

Epoch: 5| Step: 5
Training loss: 1.6831369864642205
Validation loss: 2.5338449716482834

Epoch: 5| Step: 6
Training loss: 2.995624848717364
Validation loss: 2.510997156377307

Epoch: 5| Step: 7
Training loss: 2.2460907778512946
Validation loss: 2.5169108759158756

Epoch: 5| Step: 8
Training loss: 2.177741710154407
Validation loss: 2.5218878476659787

Epoch: 5| Step: 9
Training loss: 2.3141982569980626
Validation loss: 2.5139069426282283

Epoch: 5| Step: 10
Training loss: 2.2494893024272464
Validation loss: 2.516601388813092

Epoch: 5| Step: 11
Training loss: 1.672027580928101
Validation loss: 2.5113758784560263

Epoch: 235| Step: 0
Training loss: 3.0538873819747625
Validation loss: 2.506972341537827

Epoch: 5| Step: 1
Training loss: 2.671211026326443
Validation loss: 2.5068982558311808

Epoch: 5| Step: 2
Training loss: 2.319946465696726
Validation loss: 2.5022318851248326

Epoch: 5| Step: 3
Training loss: 2.1092792630545634
Validation loss: 2.5118495655947286

Epoch: 5| Step: 4
Training loss: 2.354943262700469
Validation loss: 2.508986403327703

Epoch: 5| Step: 5
Training loss: 2.0879678167734856
Validation loss: 2.498633134223112

Epoch: 5| Step: 6
Training loss: 2.1251480948509984
Validation loss: 2.5025058307573427

Epoch: 5| Step: 7
Training loss: 2.50283862129495
Validation loss: 2.496242001408787

Epoch: 5| Step: 8
Training loss: 2.1451757466626886
Validation loss: 2.498498950780669

Epoch: 5| Step: 9
Training loss: 2.714804406189733
Validation loss: 2.490205492837003

Epoch: 5| Step: 10
Training loss: 2.2146817371782714
Validation loss: 2.4994927726216836

Epoch: 5| Step: 11
Training loss: 2.0155421986687
Validation loss: 2.491174398284125

Epoch: 236| Step: 0
Training loss: 2.5831067590925523
Validation loss: 2.497323594359553

Epoch: 5| Step: 1
Training loss: 2.518689581286003
Validation loss: 2.5071274603109694

Epoch: 5| Step: 2
Training loss: 2.198071683747391
Validation loss: 2.5220213736118247

Epoch: 5| Step: 3
Training loss: 2.035536014906383
Validation loss: 2.511068272740989

Epoch: 5| Step: 4
Training loss: 2.6510547770017996
Validation loss: 2.520190978111224

Epoch: 5| Step: 5
Training loss: 2.327107149398999
Validation loss: 2.5328314044489284

Epoch: 5| Step: 6
Training loss: 2.6686382654460643
Validation loss: 2.5218593792311417

Epoch: 5| Step: 7
Training loss: 2.4035875527592703
Validation loss: 2.528053144825617

Epoch: 5| Step: 8
Training loss: 2.616871464564976
Validation loss: 2.5159579623363975

Epoch: 5| Step: 9
Training loss: 2.3630233750060947
Validation loss: 2.5288202138553864

Epoch: 5| Step: 10
Training loss: 1.9520778442870177
Validation loss: 2.5167869230195294

Epoch: 5| Step: 11
Training loss: 2.0747400695511646
Validation loss: 2.5202156103453284

Epoch: 237| Step: 0
Training loss: 2.5018656445113185
Validation loss: 2.5189046824865096

Epoch: 5| Step: 1
Training loss: 2.9575325504423904
Validation loss: 2.5103638921759526

Epoch: 5| Step: 2
Training loss: 1.775983755411139
Validation loss: 2.5197853374257155

Epoch: 5| Step: 3
Training loss: 2.4723973432468913
Validation loss: 2.527051599234649

Epoch: 5| Step: 4
Training loss: 2.4828462515590077
Validation loss: 2.524241117730346

Epoch: 5| Step: 5
Training loss: 2.3365993008809185
Validation loss: 2.5294864932039767

Epoch: 5| Step: 6
Training loss: 1.990774992796823
Validation loss: 2.5294581299268746

Epoch: 5| Step: 7
Training loss: 2.971566400239563
Validation loss: 2.5269759950749346

Epoch: 5| Step: 8
Training loss: 1.8330632213089186
Validation loss: 2.514155367314943

Epoch: 5| Step: 9
Training loss: 2.7211323089452386
Validation loss: 2.507031288356985

Epoch: 5| Step: 10
Training loss: 2.0743307022371464
Validation loss: 2.4987205211471064

Epoch: 5| Step: 11
Training loss: 2.3743686840819853
Validation loss: 2.497128530337608

Epoch: 238| Step: 0
Training loss: 2.4673318773561004
Validation loss: 2.4907876032229037

Epoch: 5| Step: 1
Training loss: 2.587280109294824
Validation loss: 2.4999330114290648

Epoch: 5| Step: 2
Training loss: 2.52386404867131
Validation loss: 2.5054157842658555

Epoch: 5| Step: 3
Training loss: 2.314648017242705
Validation loss: 2.511138125121226

Epoch: 5| Step: 4
Training loss: 2.079859189255693
Validation loss: 2.517115603493057

Epoch: 5| Step: 5
Training loss: 2.516872594210335
Validation loss: 2.513041043900305

Epoch: 5| Step: 6
Training loss: 2.3481748392168345
Validation loss: 2.5117328934100724

Epoch: 5| Step: 7
Training loss: 2.6367623332624834
Validation loss: 2.5062796997631724

Epoch: 5| Step: 8
Training loss: 2.5816682453614495
Validation loss: 2.500487419137705

Epoch: 5| Step: 9
Training loss: 2.352924750775617
Validation loss: 2.5068556840904255

Epoch: 5| Step: 10
Training loss: 3.1728375858129367
Validation loss: 2.4928240585935897

Epoch: 5| Step: 11
Training loss: 2.1723867129165892
Validation loss: 2.5020983413375353

Epoch: 239| Step: 0
Training loss: 2.233366411827665
Validation loss: 2.5012282453789103

Epoch: 5| Step: 1
Training loss: 2.5151820770243885
Validation loss: 2.504811349980907

Epoch: 5| Step: 2
Training loss: 2.7047727997814346
Validation loss: 2.4957443056377553

Epoch: 5| Step: 3
Training loss: 2.5044997727357257
Validation loss: 2.5180788728401566

Epoch: 5| Step: 4
Training loss: 2.4765564349849334
Validation loss: 2.5064306680782655

Epoch: 5| Step: 5
Training loss: 3.027295394019045
Validation loss: 2.4952098214608274

Epoch: 5| Step: 6
Training loss: 2.2254782730581217
Validation loss: 2.500627971298765

Epoch: 5| Step: 7
Training loss: 1.991783310521754
Validation loss: 2.49251684964325

Epoch: 5| Step: 8
Training loss: 2.296790504198897
Validation loss: 2.486380273632177

Epoch: 5| Step: 9
Training loss: 2.6105203456235597
Validation loss: 2.497159182275343

Epoch: 5| Step: 10
Training loss: 2.362591704349781
Validation loss: 2.5193921624957634

Epoch: 5| Step: 11
Training loss: 2.876326213624355
Validation loss: 2.5170806874732428

Epoch: 240| Step: 0
Training loss: 2.2700279860934987
Validation loss: 2.531421274897558

Epoch: 5| Step: 1
Training loss: 2.4204924544240636
Validation loss: 2.537435943753375

Epoch: 5| Step: 2
Training loss: 2.372231425769511
Validation loss: 2.5388303249529707

Epoch: 5| Step: 3
Training loss: 2.8167651578699
Validation loss: 2.536721555980262

Epoch: 5| Step: 4
Training loss: 2.0647930922772906
Validation loss: 2.5340993017090594

Epoch: 5| Step: 5
Training loss: 1.9594791050074547
Validation loss: 2.5304804208974527

Epoch: 5| Step: 6
Training loss: 2.5258461997840205
Validation loss: 2.5138786722880706

Epoch: 5| Step: 7
Training loss: 2.587259836154427
Validation loss: 2.5123917274805847

Epoch: 5| Step: 8
Training loss: 2.497952385637213
Validation loss: 2.5158159645528086

Epoch: 5| Step: 9
Training loss: 2.2210099436929385
Validation loss: 2.5105206631584602

Epoch: 5| Step: 10
Training loss: 2.895949290490222
Validation loss: 2.5077572476805794

Epoch: 5| Step: 11
Training loss: 2.4406967719120445
Validation loss: 2.507829624485956

Epoch: 241| Step: 0
Training loss: 1.5307147589238355
Validation loss: 2.5042270329943515

Epoch: 5| Step: 1
Training loss: 2.480966977522008
Validation loss: 2.5003846905691574

Epoch: 5| Step: 2
Training loss: 2.7183215801266374
Validation loss: 2.505672599509728

Epoch: 5| Step: 3
Training loss: 2.5979592053423954
Validation loss: 2.492555078964771

Epoch: 5| Step: 4
Training loss: 2.1067239562023117
Validation loss: 2.4993320367466674

Epoch: 5| Step: 5
Training loss: 2.538327248562462
Validation loss: 2.500187606527475

Epoch: 5| Step: 6
Training loss: 2.597171319427595
Validation loss: 2.4986053470853498

Epoch: 5| Step: 7
Training loss: 3.133556857827506
Validation loss: 2.5007193444393696

Epoch: 5| Step: 8
Training loss: 2.028660693785497
Validation loss: 2.500214587379858

Epoch: 5| Step: 9
Training loss: 2.7414897672248983
Validation loss: 2.499905167211511

Epoch: 5| Step: 10
Training loss: 1.810952742926338
Validation loss: 2.5102286420083932

Epoch: 5| Step: 11
Training loss: 1.9191339686406612
Validation loss: 2.510074292707092

Epoch: 242| Step: 0
Training loss: 2.2479410287446107
Validation loss: 2.5120274703567302

Epoch: 5| Step: 1
Training loss: 2.123735500418667
Validation loss: 2.5101239850285495

Epoch: 5| Step: 2
Training loss: 2.2282748949048417
Validation loss: 2.5130819454899127

Epoch: 5| Step: 3
Training loss: 2.1826921215464488
Validation loss: 2.508054616615303

Epoch: 5| Step: 4
Training loss: 2.8442659014887446
Validation loss: 2.5196556908288144

Epoch: 5| Step: 5
Training loss: 2.722867369162973
Validation loss: 2.511408808971576

Epoch: 5| Step: 6
Training loss: 2.3486136263184627
Validation loss: 2.505844189505429

Epoch: 5| Step: 7
Training loss: 2.392586694818836
Validation loss: 2.516100568027952

Epoch: 5| Step: 8
Training loss: 2.9335542516169997
Validation loss: 2.513201321987179

Epoch: 5| Step: 9
Training loss: 2.1814670749848974
Validation loss: 2.5109180738500374

Epoch: 5| Step: 10
Training loss: 2.0362488491741226
Validation loss: 2.515567316851129

Epoch: 5| Step: 11
Training loss: 1.8277785796241328
Validation loss: 2.5111439048567794

Epoch: 243| Step: 0
Training loss: 1.7411568505428048
Validation loss: 2.518401858310335

Epoch: 5| Step: 1
Training loss: 2.7651019275220547
Validation loss: 2.501268962830802

Epoch: 5| Step: 2
Training loss: 2.469315669284256
Validation loss: 2.5066859784094677

Epoch: 5| Step: 3
Training loss: 2.021786520671373
Validation loss: 2.5074463613661258

Epoch: 5| Step: 4
Training loss: 2.2397999030386297
Validation loss: 2.497410148020039

Epoch: 5| Step: 5
Training loss: 2.147471706750225
Validation loss: 2.495863301400276

Epoch: 5| Step: 6
Training loss: 2.031075103272717
Validation loss: 2.503164728097842

Epoch: 5| Step: 7
Training loss: 2.842048890779856
Validation loss: 2.492412461319035

Epoch: 5| Step: 8
Training loss: 2.365996914330322
Validation loss: 2.5017780577223903

Epoch: 5| Step: 9
Training loss: 2.436314123179813
Validation loss: 2.503169280099862

Epoch: 5| Step: 10
Training loss: 2.9015300529116046
Validation loss: 2.503273446058384

Epoch: 5| Step: 11
Training loss: 3.5190207124855553
Validation loss: 2.5129277753977104

Epoch: 244| Step: 0
Training loss: 2.7072261503442347
Validation loss: 2.521036578620568

Epoch: 5| Step: 1
Training loss: 2.2514894641728826
Validation loss: 2.5245090410183098

Epoch: 5| Step: 2
Training loss: 2.681622843395161
Validation loss: 2.530865012039601

Epoch: 5| Step: 3
Training loss: 2.8434694591939356
Validation loss: 2.5433051164702527

Epoch: 5| Step: 4
Training loss: 2.0965508473382783
Validation loss: 2.5370398813645796

Epoch: 5| Step: 5
Training loss: 2.3867200486199924
Validation loss: 2.548483611655847

Epoch: 5| Step: 6
Training loss: 2.3963434975401845
Validation loss: 2.5662634629349963

Epoch: 5| Step: 7
Training loss: 1.7589780207177588
Validation loss: 2.562594830688905

Epoch: 5| Step: 8
Training loss: 3.0844651971400427
Validation loss: 2.5576550380279697

Epoch: 5| Step: 9
Training loss: 1.9661025154108156
Validation loss: 2.542290385641215

Epoch: 5| Step: 10
Training loss: 2.555631317407007
Validation loss: 2.531988895559895

Epoch: 5| Step: 11
Training loss: 2.539815656024932
Validation loss: 2.511914966882566

Epoch: 245| Step: 0
Training loss: 2.728168353493318
Validation loss: 2.520440809306937

Epoch: 5| Step: 1
Training loss: 2.7597852356599333
Validation loss: 2.5199938209018944

Epoch: 5| Step: 2
Training loss: 2.335182297511238
Validation loss: 2.5251799513016473

Epoch: 5| Step: 3
Training loss: 2.2132503422532506
Validation loss: 2.5078003983091746

Epoch: 5| Step: 4
Training loss: 2.430386163773118
Validation loss: 2.499151141377208

Epoch: 5| Step: 5
Training loss: 2.3213207995371974
Validation loss: 2.5133378627742187

Epoch: 5| Step: 6
Training loss: 2.1803837146257927
Validation loss: 2.5124118020818265

Epoch: 5| Step: 7
Training loss: 2.8457430049324675
Validation loss: 2.5216545896551907

Epoch: 5| Step: 8
Training loss: 2.5644419685115283
Validation loss: 2.5322316742578304

Epoch: 5| Step: 9
Training loss: 2.4358231082701214
Validation loss: 2.553167020933627

Epoch: 5| Step: 10
Training loss: 3.0946245594975825
Validation loss: 2.53034831497822

Epoch: 5| Step: 11
Training loss: 2.4824860307160233
Validation loss: 2.52036671352552

Epoch: 246| Step: 0
Training loss: 2.4491190669507192
Validation loss: 2.5373713529638793

Epoch: 5| Step: 1
Training loss: 2.862371823302134
Validation loss: 2.5001562467068505

Epoch: 5| Step: 2
Training loss: 2.6732775481468942
Validation loss: 2.505336240066167

Epoch: 5| Step: 3
Training loss: 2.433924375457873
Validation loss: 2.516042785229447

Epoch: 5| Step: 4
Training loss: 2.48278959538606
Validation loss: 2.4983111080973504

Epoch: 5| Step: 5
Training loss: 2.0598838860462303
Validation loss: 2.4962829096303705

Epoch: 5| Step: 6
Training loss: 2.7061963576006662
Validation loss: 2.505792578750707

Epoch: 5| Step: 7
Training loss: 2.4468090608756747
Validation loss: 2.50371292883526

Epoch: 5| Step: 8
Training loss: 2.5899173962002386
Validation loss: 2.500327021350004

Epoch: 5| Step: 9
Training loss: 2.330115983884075
Validation loss: 2.5046266064110156

Epoch: 5| Step: 10
Training loss: 2.7492392094493936
Validation loss: 2.513433568131586

Epoch: 5| Step: 11
Training loss: 2.7218420926720577
Validation loss: 2.5085474682228055

Epoch: 247| Step: 0
Training loss: 2.6136817340154623
Validation loss: 2.5130180372048008

Epoch: 5| Step: 1
Training loss: 2.6674632631040613
Validation loss: 2.528005667574732

Epoch: 5| Step: 2
Training loss: 2.726309515903792
Validation loss: 2.5240831011829217

Epoch: 5| Step: 3
Training loss: 2.4535064400712194
Validation loss: 2.5235430731798716

Epoch: 5| Step: 4
Training loss: 2.3291477286763693
Validation loss: 2.5361432082754263

Epoch: 5| Step: 5
Training loss: 2.29166178847285
Validation loss: 2.515718142441724

Epoch: 5| Step: 6
Training loss: 2.2093025335921115
Validation loss: 2.527440575813906

Epoch: 5| Step: 7
Training loss: 2.4852981291837146
Validation loss: 2.5189531831218326

Epoch: 5| Step: 8
Training loss: 2.345509085145431
Validation loss: 2.5117238797639203

Epoch: 5| Step: 9
Training loss: 2.0988683058092557
Validation loss: 2.5024715365945243

Epoch: 5| Step: 10
Training loss: 2.8296508045229025
Validation loss: 2.5124019684337004

Epoch: 5| Step: 11
Training loss: 2.5577125487842163
Validation loss: 2.511410861922751

Epoch: 248| Step: 0
Training loss: 2.1425694454159885
Validation loss: 2.506676950578401

Epoch: 5| Step: 1
Training loss: 2.989374417084213
Validation loss: 2.4921823379957417

Epoch: 5| Step: 2
Training loss: 2.1844314851675053
Validation loss: 2.4892693897575215

Epoch: 5| Step: 3
Training loss: 2.60821160061853
Validation loss: 2.485249235573589

Epoch: 5| Step: 4
Training loss: 1.9594573859944175
Validation loss: 2.479328187654918

Epoch: 5| Step: 5
Training loss: 1.8176372335641524
Validation loss: 2.475856441689342

Epoch: 5| Step: 6
Training loss: 2.396072066202423
Validation loss: 2.478563380902327

Epoch: 5| Step: 7
Training loss: 2.4464083522561744
Validation loss: 2.486546848662235

Epoch: 5| Step: 8
Training loss: 2.880359132945267
Validation loss: 2.4705649336012425

Epoch: 5| Step: 9
Training loss: 2.423637487151991
Validation loss: 2.474274678667672

Epoch: 5| Step: 10
Training loss: 2.4890126062290814
Validation loss: 2.475340592906737

Epoch: 5| Step: 11
Training loss: 3.306984394047045
Validation loss: 2.4711934202525567

Epoch: 249| Step: 0
Training loss: 2.346956221677287
Validation loss: 2.4738204850725842

Epoch: 5| Step: 1
Training loss: 2.116706033275507
Validation loss: 2.4705375364599744

Epoch: 5| Step: 2
Training loss: 2.2996840135537804
Validation loss: 2.4745689776183446

Epoch: 5| Step: 3
Training loss: 2.463432669832652
Validation loss: 2.479581142420937

Epoch: 5| Step: 4
Training loss: 2.175201283929915
Validation loss: 2.48067873969528

Epoch: 5| Step: 5
Training loss: 2.687516766872888
Validation loss: 2.4850052088216614

Epoch: 5| Step: 6
Training loss: 2.7514628074387986
Validation loss: 2.4785493387986013

Epoch: 5| Step: 7
Training loss: 2.2417378788902522
Validation loss: 2.4920060939795947

Epoch: 5| Step: 8
Training loss: 1.9289127910591175
Validation loss: 2.489159772799736

Epoch: 5| Step: 9
Training loss: 3.0104556669637086
Validation loss: 2.487432405936805

Epoch: 5| Step: 10
Training loss: 2.5293786937779967
Validation loss: 2.5000912331782374

Epoch: 5| Step: 11
Training loss: 1.817799417423403
Validation loss: 2.5026348772390867

Epoch: 250| Step: 0
Training loss: 2.0647563729650305
Validation loss: 2.491569753397306

Epoch: 5| Step: 1
Training loss: 2.360289743708465
Validation loss: 2.501529138530441

Epoch: 5| Step: 2
Training loss: 2.6114091996109114
Validation loss: 2.4934435103951538

Epoch: 5| Step: 3
Training loss: 1.9685699743885994
Validation loss: 2.5058950539098235

Epoch: 5| Step: 4
Training loss: 2.0500999844987198
Validation loss: 2.503594607728609

Epoch: 5| Step: 5
Training loss: 2.670154575345366
Validation loss: 2.4992609004395137

Epoch: 5| Step: 6
Training loss: 2.9673529299098433
Validation loss: 2.5005893052450476

Epoch: 5| Step: 7
Training loss: 2.4928172879306376
Validation loss: 2.5037792608043454

Epoch: 5| Step: 8
Training loss: 2.3160305393952862
Validation loss: 2.5026547085795245

Epoch: 5| Step: 9
Training loss: 2.1089144733825695
Validation loss: 2.5121966293510103

Epoch: 5| Step: 10
Training loss: 2.7691443513362746
Validation loss: 2.511660071399976

Epoch: 5| Step: 11
Training loss: 1.0257097020295385
Validation loss: 2.5179285476857083

Epoch: 251| Step: 0
Training loss: 1.6241081431325932
Validation loss: 2.5105906000202998

Epoch: 5| Step: 1
Training loss: 2.8809709326917288
Validation loss: 2.5200011532266187

Epoch: 5| Step: 2
Training loss: 2.7530583801176354
Validation loss: 2.5130166141033166

Epoch: 5| Step: 3
Training loss: 1.9842196426251413
Validation loss: 2.510687676254309

Epoch: 5| Step: 4
Training loss: 2.335461928524244
Validation loss: 2.517066526752049

Epoch: 5| Step: 5
Training loss: 2.1494873810828308
Validation loss: 2.509600682163541

Epoch: 5| Step: 6
Training loss: 2.011668143515478
Validation loss: 2.5161612118884262

Epoch: 5| Step: 7
Training loss: 2.7558858479526687
Validation loss: 2.514395877537477

Epoch: 5| Step: 8
Training loss: 2.683928311966781
Validation loss: 2.504561863614021

Epoch: 5| Step: 9
Training loss: 2.483835413653969
Validation loss: 2.5218460765190005

Epoch: 5| Step: 10
Training loss: 2.1868094307924464
Validation loss: 2.5136654924629314

Epoch: 5| Step: 11
Training loss: 2.503163339080756
Validation loss: 2.508687117383589

Epoch: 252| Step: 0
Training loss: 2.3772294472385527
Validation loss: 2.516178990211873

Epoch: 5| Step: 1
Training loss: 2.926499567612864
Validation loss: 2.5164134959799815

Epoch: 5| Step: 2
Training loss: 2.1221880539989013
Validation loss: 2.509511473140571

Epoch: 5| Step: 3
Training loss: 2.54493958122318
Validation loss: 2.506753648458217

Epoch: 5| Step: 4
Training loss: 2.2783454275566
Validation loss: 2.509720362788247

Epoch: 5| Step: 5
Training loss: 2.571169724757493
Validation loss: 2.503059448339515

Epoch: 5| Step: 6
Training loss: 2.136870272492554
Validation loss: 2.500672615485903

Epoch: 5| Step: 7
Training loss: 2.5049355425127318
Validation loss: 2.5059000290952245

Epoch: 5| Step: 8
Training loss: 2.4159018413422206
Validation loss: 2.5082055137443486

Epoch: 5| Step: 9
Training loss: 2.2429797537336755
Validation loss: 2.512546258630236

Epoch: 5| Step: 10
Training loss: 2.009244534304576
Validation loss: 2.503115659609801

Epoch: 5| Step: 11
Training loss: 1.9866714405902792
Validation loss: 2.509568436492006

Epoch: 253| Step: 0
Training loss: 2.5233038993875767
Validation loss: 2.5100315017483816

Epoch: 5| Step: 1
Training loss: 2.1718879534657556
Validation loss: 2.500988768707045

Epoch: 5| Step: 2
Training loss: 2.393219481162534
Validation loss: 2.5105229344702193

Epoch: 5| Step: 3
Training loss: 2.2424302451555604
Validation loss: 2.50074279399661

Epoch: 5| Step: 4
Training loss: 2.567692218185728
Validation loss: 2.503944541491567

Epoch: 5| Step: 5
Training loss: 1.6979698765692077
Validation loss: 2.507296413030967

Epoch: 5| Step: 6
Training loss: 2.1515064861067748
Validation loss: 2.516846012968145

Epoch: 5| Step: 7
Training loss: 2.4821969327299565
Validation loss: 2.5135226873563155

Epoch: 5| Step: 8
Training loss: 2.8533949725305634
Validation loss: 2.515980128777353

Epoch: 5| Step: 9
Training loss: 2.230993740208084
Validation loss: 2.5170365395437986

Epoch: 5| Step: 10
Training loss: 2.832753140752881
Validation loss: 2.5167374767253223

Epoch: 5| Step: 11
Training loss: 1.0617202814917786
Validation loss: 2.519440369852153

Epoch: 254| Step: 0
Training loss: 2.194189143989932
Validation loss: 2.5274073235575347

Epoch: 5| Step: 1
Training loss: 2.314007963353123
Validation loss: 2.5313779029399432

Epoch: 5| Step: 2
Training loss: 2.280750899390282
Validation loss: 2.5302116320732373

Epoch: 5| Step: 3
Training loss: 2.43437718598215
Validation loss: 2.5344864989690157

Epoch: 5| Step: 4
Training loss: 2.4980239688160113
Validation loss: 2.52004852504912

Epoch: 5| Step: 5
Training loss: 2.1180244846531715
Validation loss: 2.5298087290696567

Epoch: 5| Step: 6
Training loss: 2.5391385580555452
Validation loss: 2.5109073481226103

Epoch: 5| Step: 7
Training loss: 2.485604419848463
Validation loss: 2.5215884974399367

Epoch: 5| Step: 8
Training loss: 2.8559942218604526
Validation loss: 2.526696359536255

Epoch: 5| Step: 9
Training loss: 2.221905895077375
Validation loss: 2.522872026858644

Epoch: 5| Step: 10
Training loss: 2.1608553370855903
Validation loss: 2.521498849730211

Epoch: 5| Step: 11
Training loss: 1.893778606236507
Validation loss: 2.5272077733152765

Epoch: 255| Step: 0
Training loss: 2.2089637600234466
Validation loss: 2.5202357329951237

Epoch: 5| Step: 1
Training loss: 2.2433013807555824
Validation loss: 2.517910631791106

Epoch: 5| Step: 2
Training loss: 2.67082988086146
Validation loss: 2.5126755801732106

Epoch: 5| Step: 3
Training loss: 2.836904481750173
Validation loss: 2.5037405323212045

Epoch: 5| Step: 4
Training loss: 1.7448038888379835
Validation loss: 2.50677039181227

Epoch: 5| Step: 5
Training loss: 1.6583779538284211
Validation loss: 2.5185404956225983

Epoch: 5| Step: 6
Training loss: 2.562413190906454
Validation loss: 2.5013994670909954

Epoch: 5| Step: 7
Training loss: 2.365694689511551
Validation loss: 2.51211002954684

Epoch: 5| Step: 8
Training loss: 2.7154190880920406
Validation loss: 2.500262477129456

Epoch: 5| Step: 9
Training loss: 2.5640025502041945
Validation loss: 2.5137271257526694

Epoch: 5| Step: 10
Training loss: 2.45008204575782
Validation loss: 2.506437806237837

Epoch: 5| Step: 11
Training loss: 1.6574952824267977
Validation loss: 2.518888958425829

Epoch: 256| Step: 0
Training loss: 2.577356674841844
Validation loss: 2.5055814862994663

Epoch: 5| Step: 1
Training loss: 2.025490797870857
Validation loss: 2.5052483542901047

Epoch: 5| Step: 2
Training loss: 2.739348156097085
Validation loss: 2.5012784113136988

Epoch: 5| Step: 3
Training loss: 2.2905099087850354
Validation loss: 2.4875056017520265

Epoch: 5| Step: 4
Training loss: 1.9686566285289635
Validation loss: 2.4931147613213147

Epoch: 5| Step: 5
Training loss: 2.4104665497739948
Validation loss: 2.4812757606033893

Epoch: 5| Step: 6
Training loss: 2.456607169470775
Validation loss: 2.48924319818077

Epoch: 5| Step: 7
Training loss: 2.6649990728781057
Validation loss: 2.4841264144520276

Epoch: 5| Step: 8
Training loss: 2.510890129891144
Validation loss: 2.482138572792415

Epoch: 5| Step: 9
Training loss: 2.356852819095088
Validation loss: 2.485755297051596

Epoch: 5| Step: 10
Training loss: 2.375970642107554
Validation loss: 2.480542607847366

Epoch: 5| Step: 11
Training loss: 1.1876826396831248
Validation loss: 2.4804308991034816

Epoch: 257| Step: 0
Training loss: 2.0289769292190036
Validation loss: 2.4936919718677837

Epoch: 5| Step: 1
Training loss: 2.737098514605568
Validation loss: 2.491516353757651

Epoch: 5| Step: 2
Training loss: 2.749923444896113
Validation loss: 2.504815446866134

Epoch: 5| Step: 3
Training loss: 2.5681429811703667
Validation loss: 2.4881344546818998

Epoch: 5| Step: 4
Training loss: 1.7926087527091088
Validation loss: 2.505508969218762

Epoch: 5| Step: 5
Training loss: 1.9896752767305739
Validation loss: 2.509079249789308

Epoch: 5| Step: 6
Training loss: 1.981299713184958
Validation loss: 2.5094375732398553

Epoch: 5| Step: 7
Training loss: 2.81504418482414
Validation loss: 2.5130264196514966

Epoch: 5| Step: 8
Training loss: 2.399188691338793
Validation loss: 2.51826290961417

Epoch: 5| Step: 9
Training loss: 2.637732552495353
Validation loss: 2.508881591579403

Epoch: 5| Step: 10
Training loss: 2.553782451496273
Validation loss: 2.5044112626095303

Epoch: 5| Step: 11
Training loss: 1.0186153112201863
Validation loss: 2.500638312072585

Epoch: 258| Step: 0
Training loss: 2.0798409626755583
Validation loss: 2.5107057623914604

Epoch: 5| Step: 1
Training loss: 2.310248335498499
Validation loss: 2.506742516542706

Epoch: 5| Step: 2
Training loss: 2.6185444061494008
Validation loss: 2.5112410269514114

Epoch: 5| Step: 3
Training loss: 2.411721881831057
Validation loss: 2.5116862981666523

Epoch: 5| Step: 4
Training loss: 2.3123058546894493
Validation loss: 2.510686236005015

Epoch: 5| Step: 5
Training loss: 2.207538269678958
Validation loss: 2.507241343484649

Epoch: 5| Step: 6
Training loss: 2.658192900134174
Validation loss: 2.5147794048684675

Epoch: 5| Step: 7
Training loss: 2.5941863095178785
Validation loss: 2.5101082811581623

Epoch: 5| Step: 8
Training loss: 2.099955004255439
Validation loss: 2.519370286319316

Epoch: 5| Step: 9
Training loss: 2.6912168483224876
Validation loss: 2.5114361933825746

Epoch: 5| Step: 10
Training loss: 2.226679534513255
Validation loss: 2.521359141869625

Epoch: 5| Step: 11
Training loss: 2.263667662043103
Validation loss: 2.5100153283015914

Epoch: 259| Step: 0
Training loss: 2.2149734593646255
Validation loss: 2.514124223209445

Epoch: 5| Step: 1
Training loss: 2.2752395252271267
Validation loss: 2.516354457066013

Epoch: 5| Step: 2
Training loss: 1.6546294003121422
Validation loss: 2.514236758214663

Epoch: 5| Step: 3
Training loss: 2.5423305665821334
Validation loss: 2.511197887973033

Epoch: 5| Step: 4
Training loss: 2.516083859124139
Validation loss: 2.4977500088931968

Epoch: 5| Step: 5
Training loss: 2.4321684605327314
Validation loss: 2.5146301308369843

Epoch: 5| Step: 6
Training loss: 2.454834554967145
Validation loss: 2.5187333117485156

Epoch: 5| Step: 7
Training loss: 2.342702504364628
Validation loss: 2.5184274291001914

Epoch: 5| Step: 8
Training loss: 2.844783050363893
Validation loss: 2.5180925505122125

Epoch: 5| Step: 9
Training loss: 2.8417227089763553
Validation loss: 2.5167000765719636

Epoch: 5| Step: 10
Training loss: 1.8665925039590676
Validation loss: 2.5155692913766163

Epoch: 5| Step: 11
Training loss: 1.4197620160184967
Validation loss: 2.5262754876110813

Epoch: 260| Step: 0
Training loss: 2.9819497045091437
Validation loss: 2.521252200633652

Epoch: 5| Step: 1
Training loss: 2.0767912062054683
Validation loss: 2.530899945924185

Epoch: 5| Step: 2
Training loss: 1.9656059349117956
Validation loss: 2.5207398032079564

Epoch: 5| Step: 3
Training loss: 2.172555391507591
Validation loss: 2.527769299566865

Epoch: 5| Step: 4
Training loss: 3.0298568827755776
Validation loss: 2.5285684408070663

Epoch: 5| Step: 5
Training loss: 2.193882377955952
Validation loss: 2.539042964762339

Epoch: 5| Step: 6
Training loss: 2.2358723138441285
Validation loss: 2.5376235112070833

Epoch: 5| Step: 7
Training loss: 2.335670481446471
Validation loss: 2.524763807889112

Epoch: 5| Step: 8
Training loss: 2.1787605091920486
Validation loss: 2.533475717560815

Epoch: 5| Step: 9
Training loss: 2.388383500166162
Validation loss: 2.533982270084419

Epoch: 5| Step: 10
Training loss: 2.2061986382317094
Validation loss: 2.537561667527646

Epoch: 5| Step: 11
Training loss: 1.8254054128716015
Validation loss: 2.5339477197693023

Epoch: 261| Step: 0
Training loss: 1.7821018792002665
Validation loss: 2.5332516538373095

Epoch: 5| Step: 1
Training loss: 1.967578478826961
Validation loss: 2.534191077175528

Epoch: 5| Step: 2
Training loss: 2.444574799337186
Validation loss: 2.5216748840083003

Epoch: 5| Step: 3
Training loss: 2.649075771603196
Validation loss: 2.5167283290346725

Epoch: 5| Step: 4
Training loss: 2.6342598307312897
Validation loss: 2.516530041954482

Epoch: 5| Step: 5
Training loss: 2.2238954867223995
Validation loss: 2.519099631784135

Epoch: 5| Step: 6
Training loss: 2.1397326760574074
Validation loss: 2.5079395780917975

Epoch: 5| Step: 7
Training loss: 1.5933342933784902
Validation loss: 2.5076857838846607

Epoch: 5| Step: 8
Training loss: 3.138819085154258
Validation loss: 2.51429212496351

Epoch: 5| Step: 9
Training loss: 2.5615622502599438
Validation loss: 2.498845513327887

Epoch: 5| Step: 10
Training loss: 2.5044597900598955
Validation loss: 2.4957245925359763

Epoch: 5| Step: 11
Training loss: 1.4551207260961712
Validation loss: 2.513295937668059

Epoch: 262| Step: 0
Training loss: 2.316870605859739
Validation loss: 2.518753219457293

Epoch: 5| Step: 1
Training loss: 1.9700781565619792
Validation loss: 2.5003808327524686

Epoch: 5| Step: 2
Training loss: 2.1590948825781364
Validation loss: 2.4998076484114833

Epoch: 5| Step: 3
Training loss: 3.1424359466652687
Validation loss: 2.527852663100019

Epoch: 5| Step: 4
Training loss: 1.9284395823747948
Validation loss: 2.531125972205243

Epoch: 5| Step: 5
Training loss: 1.8609498351078253
Validation loss: 2.5146714806349655

Epoch: 5| Step: 6
Training loss: 2.0926411667471547
Validation loss: 2.5151746516575457

Epoch: 5| Step: 7
Training loss: 2.4417583730442174
Validation loss: 2.5240020396034937

Epoch: 5| Step: 8
Training loss: 2.2784314445275964
Validation loss: 2.525194263224453

Epoch: 5| Step: 9
Training loss: 2.599257906133529
Validation loss: 2.5287556819188812

Epoch: 5| Step: 10
Training loss: 2.7915982385096614
Validation loss: 2.525188216663334

Epoch: 5| Step: 11
Training loss: 2.1518096538087113
Validation loss: 2.52118460648422

Epoch: 263| Step: 0
Training loss: 2.259159834497417
Validation loss: 2.5323968024157386

Epoch: 5| Step: 1
Training loss: 2.659401852464314
Validation loss: 2.5387835579261226

Epoch: 5| Step: 2
Training loss: 2.4370016909136756
Validation loss: 2.533924432442174

Epoch: 5| Step: 3
Training loss: 2.2963498092498127
Validation loss: 2.536709376816056

Epoch: 5| Step: 4
Training loss: 1.9114552081201213
Validation loss: 2.5358329343988726

Epoch: 5| Step: 5
Training loss: 2.1259323767370835
Validation loss: 2.519149010024645

Epoch: 5| Step: 6
Training loss: 2.2487269084735084
Validation loss: 2.5310092152171912

Epoch: 5| Step: 7
Training loss: 2.4249930706121803
Validation loss: 2.5268501731337927

Epoch: 5| Step: 8
Training loss: 2.36189277151649
Validation loss: 2.530420646276998

Epoch: 5| Step: 9
Training loss: 2.8201960066726297
Validation loss: 2.5324838323475602

Epoch: 5| Step: 10
Training loss: 2.2055148966789266
Validation loss: 2.5220261476105605

Epoch: 5| Step: 11
Training loss: 2.283004817394466
Validation loss: 2.5385986765232222

Epoch: 264| Step: 0
Training loss: 2.3037339128914716
Validation loss: 2.528860927014984

Epoch: 5| Step: 1
Training loss: 2.572083022834796
Validation loss: 2.5211303880076534

Epoch: 5| Step: 2
Training loss: 2.025000362631683
Validation loss: 2.515619420110544

Epoch: 5| Step: 3
Training loss: 1.7985405541928416
Validation loss: 2.504792467734985

Epoch: 5| Step: 4
Training loss: 2.5902357078138065
Validation loss: 2.5078998601954203

Epoch: 5| Step: 5
Training loss: 2.187369533462883
Validation loss: 2.516421695390618

Epoch: 5| Step: 6
Training loss: 2.3315594833348374
Validation loss: 2.512181357600708

Epoch: 5| Step: 7
Training loss: 2.7851457207736194
Validation loss: 2.516742387057744

Epoch: 5| Step: 8
Training loss: 2.0089705278163046
Validation loss: 2.5234818863089807

Epoch: 5| Step: 9
Training loss: 2.4013340262426675
Validation loss: 2.532560005600542

Epoch: 5| Step: 10
Training loss: 2.706078035383985
Validation loss: 2.5272826394225523

Epoch: 5| Step: 11
Training loss: 2.210655383116145
Validation loss: 2.5321276677665234

Epoch: 265| Step: 0
Training loss: 2.6585017813604304
Validation loss: 2.5432669898809053

Epoch: 5| Step: 1
Training loss: 2.726150262924346
Validation loss: 2.547270905941069

Epoch: 5| Step: 2
Training loss: 2.4700809223031195
Validation loss: 2.558206162931687

Epoch: 5| Step: 3
Training loss: 2.0680960828938906
Validation loss: 2.5436935290442597

Epoch: 5| Step: 4
Training loss: 1.9254585289739963
Validation loss: 2.548808220289905

Epoch: 5| Step: 5
Training loss: 2.0411950429513444
Validation loss: 2.543299612933745

Epoch: 5| Step: 6
Training loss: 2.5196622119549112
Validation loss: 2.553870604211761

Epoch: 5| Step: 7
Training loss: 2.2439325964965233
Validation loss: 2.526266211266263

Epoch: 5| Step: 8
Training loss: 2.534699526704068
Validation loss: 2.5184098579621264

Epoch: 5| Step: 9
Training loss: 2.2920104953731952
Validation loss: 2.52396459753183

Epoch: 5| Step: 10
Training loss: 2.3741298888618143
Validation loss: 2.5134290268141104

Epoch: 5| Step: 11
Training loss: 1.3670137131455926
Validation loss: 2.502200771268166

Epoch: 266| Step: 0
Training loss: 2.186238606392173
Validation loss: 2.513729222257798

Epoch: 5| Step: 1
Training loss: 2.066282099147364
Validation loss: 2.510317649445044

Epoch: 5| Step: 2
Training loss: 2.260095939794144
Validation loss: 2.5109784531829145

Epoch: 5| Step: 3
Training loss: 3.076519697597763
Validation loss: 2.514506365765665

Epoch: 5| Step: 4
Training loss: 2.250310134706339
Validation loss: 2.514745511153474

Epoch: 5| Step: 5
Training loss: 3.0319458467584446
Validation loss: 2.5145954963518444

Epoch: 5| Step: 6
Training loss: 2.2401562571520586
Validation loss: 2.521384928914309

Epoch: 5| Step: 7
Training loss: 1.8946687943385985
Validation loss: 2.520389251107926

Epoch: 5| Step: 8
Training loss: 1.7808891064638148
Validation loss: 2.527683083946213

Epoch: 5| Step: 9
Training loss: 2.2880570739149912
Validation loss: 2.508362548336929

Epoch: 5| Step: 10
Training loss: 2.557647390285586
Validation loss: 2.52394220208211

Epoch: 5| Step: 11
Training loss: 2.121698957059174
Validation loss: 2.5383743683905995

Epoch: 267| Step: 0
Training loss: 2.049733037545992
Validation loss: 2.5285637184479137

Epoch: 5| Step: 1
Training loss: 2.301521635502061
Validation loss: 2.5168502659068195

Epoch: 5| Step: 2
Training loss: 2.085897495300495
Validation loss: 2.542124071289269

Epoch: 5| Step: 3
Training loss: 2.0766814531480557
Validation loss: 2.5242867157897844

Epoch: 5| Step: 4
Training loss: 2.389771652007064
Validation loss: 2.5321125907666064

Epoch: 5| Step: 5
Training loss: 2.397349555075603
Validation loss: 2.5314641006408634

Epoch: 5| Step: 6
Training loss: 2.377741185418721
Validation loss: 2.534639361665977

Epoch: 5| Step: 7
Training loss: 2.163887540169087
Validation loss: 2.5349653159382775

Epoch: 5| Step: 8
Training loss: 2.7212812544745515
Validation loss: 2.5271524300894925

Epoch: 5| Step: 9
Training loss: 2.2877758172518656
Validation loss: 2.5306958977448457

Epoch: 5| Step: 10
Training loss: 2.5294264830149333
Validation loss: 2.5404288699125135

Epoch: 5| Step: 11
Training loss: 3.442745991480206
Validation loss: 2.5435648589121365

Epoch: 268| Step: 0
Training loss: 1.6105349166244816
Validation loss: 2.523480784042025

Epoch: 5| Step: 1
Training loss: 2.2839818822339204
Validation loss: 2.5275126169382203

Epoch: 5| Step: 2
Training loss: 2.273373527544417
Validation loss: 2.5187841406780955

Epoch: 5| Step: 3
Training loss: 2.267110718913018
Validation loss: 2.5020755675325304

Epoch: 5| Step: 4
Training loss: 2.3631859121717573
Validation loss: 2.5010376008834956

Epoch: 5| Step: 5
Training loss: 2.5051292253615376
Validation loss: 2.5037192613565633

Epoch: 5| Step: 6
Training loss: 2.526396631423898
Validation loss: 2.5007871223149567

Epoch: 5| Step: 7
Training loss: 2.0041325313122296
Validation loss: 2.5007822601020773

Epoch: 5| Step: 8
Training loss: 2.3513477518872397
Validation loss: 2.508597471950593

Epoch: 5| Step: 9
Training loss: 2.7563578197470946
Validation loss: 2.5111705128312054

Epoch: 5| Step: 10
Training loss: 2.7484065554526635
Validation loss: 2.512246194675704

Epoch: 5| Step: 11
Training loss: 1.8798121055087427
Validation loss: 2.5079335255797464

Epoch: 269| Step: 0
Training loss: 2.308919764185735
Validation loss: 2.519085180731563

Epoch: 5| Step: 1
Training loss: 1.8255692573977873
Validation loss: 2.531129194445908

Epoch: 5| Step: 2
Training loss: 2.017923035733353
Validation loss: 2.509667943099987

Epoch: 5| Step: 3
Training loss: 3.0569775672915607
Validation loss: 2.5259531588959607

Epoch: 5| Step: 4
Training loss: 2.5803351898692615
Validation loss: 2.515397482114255

Epoch: 5| Step: 5
Training loss: 1.829582806856964
Validation loss: 2.531183410679156

Epoch: 5| Step: 6
Training loss: 2.3433483542570905
Validation loss: 2.531144905263374

Epoch: 5| Step: 7
Training loss: 2.424630351257791
Validation loss: 2.5330136085350015

Epoch: 5| Step: 8
Training loss: 2.2449380306195583
Validation loss: 2.53993412413614

Epoch: 5| Step: 9
Training loss: 2.1473308140430913
Validation loss: 2.534580829601775

Epoch: 5| Step: 10
Training loss: 2.466346633185785
Validation loss: 2.522995972167862

Epoch: 5| Step: 11
Training loss: 2.7634542965920437
Validation loss: 2.530219708246068

Epoch: 270| Step: 0
Training loss: 2.124838093592242
Validation loss: 2.508898037624624

Epoch: 5| Step: 1
Training loss: 2.601152175757692
Validation loss: 2.5374237836782454

Epoch: 5| Step: 2
Training loss: 2.6737380643045854
Validation loss: 2.5247641777478806

Epoch: 5| Step: 3
Training loss: 1.5774960161452007
Validation loss: 2.5286689401049474

Epoch: 5| Step: 4
Training loss: 2.3491529114875203
Validation loss: 2.5186956276716215

Epoch: 5| Step: 5
Training loss: 2.102143955270238
Validation loss: 2.5400902531388594

Epoch: 5| Step: 6
Training loss: 2.347000716051237
Validation loss: 2.532036509984591

Epoch: 5| Step: 7
Training loss: 2.086481487763382
Validation loss: 2.5191146663906285

Epoch: 5| Step: 8
Training loss: 2.6114389628566994
Validation loss: 2.5221000725365914

Epoch: 5| Step: 9
Training loss: 2.507557888712957
Validation loss: 2.527007611742294

Epoch: 5| Step: 10
Training loss: 2.5105676460504918
Validation loss: 2.527202847939171

Epoch: 5| Step: 11
Training loss: 1.9936310568221263
Validation loss: 2.5189798269179624

Epoch: 271| Step: 0
Training loss: 2.2550862362225295
Validation loss: 2.525245322059463

Epoch: 5| Step: 1
Training loss: 2.445869552976655
Validation loss: 2.5366021114908235

Epoch: 5| Step: 2
Training loss: 2.425038689373532
Validation loss: 2.5205928488113187

Epoch: 5| Step: 3
Training loss: 2.4459676139228366
Validation loss: 2.5298602994915833

Epoch: 5| Step: 4
Training loss: 2.6890231407250815
Validation loss: 2.53220298864982

Epoch: 5| Step: 5
Training loss: 1.4482672927748563
Validation loss: 2.5461669163795455

Epoch: 5| Step: 6
Training loss: 2.316922469618828
Validation loss: 2.5263718943041473

Epoch: 5| Step: 7
Training loss: 2.0093550044795716
Validation loss: 2.520954465451586

Epoch: 5| Step: 8
Training loss: 2.585020334838928
Validation loss: 2.5282300429807427

Epoch: 5| Step: 9
Training loss: 2.321551984084597
Validation loss: 2.5238669652980517

Epoch: 5| Step: 10
Training loss: 2.3708508035544633
Validation loss: 2.536190153249052

Epoch: 5| Step: 11
Training loss: 2.9104046401965715
Validation loss: 2.5237158433839526

Epoch: 272| Step: 0
Training loss: 2.0808191260098647
Validation loss: 2.530952279121169

Epoch: 5| Step: 1
Training loss: 2.8937962637513155
Validation loss: 2.521807345806799

Epoch: 5| Step: 2
Training loss: 2.325368491063766
Validation loss: 2.5276751686644743

Epoch: 5| Step: 3
Training loss: 1.8412837975450191
Validation loss: 2.521174499712725

Epoch: 5| Step: 4
Training loss: 2.842789875639523
Validation loss: 2.5236219569010325

Epoch: 5| Step: 5
Training loss: 2.166704128626209
Validation loss: 2.5213349423893407

Epoch: 5| Step: 6
Training loss: 2.0912766152447952
Validation loss: 2.521736851390138

Epoch: 5| Step: 7
Training loss: 3.103524382706728
Validation loss: 2.5276851904916953

Epoch: 5| Step: 8
Training loss: 2.0812014416594518
Validation loss: 2.5420903467684868

Epoch: 5| Step: 9
Training loss: 1.8716264257184203
Validation loss: 2.536230959613209

Epoch: 5| Step: 10
Training loss: 1.9197149155484963
Validation loss: 2.546956140984781

Epoch: 5| Step: 11
Training loss: 2.193952037060991
Validation loss: 2.5466009160257688

Epoch: 273| Step: 0
Training loss: 1.8844174710828452
Validation loss: 2.5353036611340163

Epoch: 5| Step: 1
Training loss: 2.353635058399807
Validation loss: 2.549110605461639

Epoch: 5| Step: 2
Training loss: 1.7366706844925242
Validation loss: 2.5417805252733574

Epoch: 5| Step: 3
Training loss: 2.6363156158833285
Validation loss: 2.5364432533541748

Epoch: 5| Step: 4
Training loss: 2.5171340302104896
Validation loss: 2.5339234052857798

Epoch: 5| Step: 5
Training loss: 1.7077487162329856
Validation loss: 2.5488193633609786

Epoch: 5| Step: 6
Training loss: 2.4031592992906927
Validation loss: 2.5392723505402888

Epoch: 5| Step: 7
Training loss: 2.7142357014945886
Validation loss: 2.525755692382286

Epoch: 5| Step: 8
Training loss: 2.864750712735432
Validation loss: 2.5169088945489717

Epoch: 5| Step: 9
Training loss: 2.0585410529382404
Validation loss: 2.515361969585715

Epoch: 5| Step: 10
Training loss: 2.5152758243449522
Validation loss: 2.5294439795881596

Epoch: 5| Step: 11
Training loss: 2.1742012135617124
Validation loss: 2.5301359024663554

Epoch: 274| Step: 0
Training loss: 2.807121984181651
Validation loss: 2.5336222384020886

Epoch: 5| Step: 1
Training loss: 2.581693179899653
Validation loss: 2.535617749137437

Epoch: 5| Step: 2
Training loss: 2.5368483058881157
Validation loss: 2.5205319489785754

Epoch: 5| Step: 3
Training loss: 1.9639014227342912
Validation loss: 2.536334609839976

Epoch: 5| Step: 4
Training loss: 2.3453585381916464
Validation loss: 2.52675987468257

Epoch: 5| Step: 5
Training loss: 2.348786194803117
Validation loss: 2.5281478491003258

Epoch: 5| Step: 6
Training loss: 2.5397447813776313
Validation loss: 2.529706928099244

Epoch: 5| Step: 7
Training loss: 2.138338636102838
Validation loss: 2.5273028669632427

Epoch: 5| Step: 8
Training loss: 1.825895596581102
Validation loss: 2.5301893429588596

Epoch: 5| Step: 9
Training loss: 2.058394999745089
Validation loss: 2.5440917067527784

Epoch: 5| Step: 10
Training loss: 2.33756038975352
Validation loss: 2.5183021050942087

Epoch: 5| Step: 11
Training loss: 2.0904998604994085
Validation loss: 2.529304325677019

Epoch: 275| Step: 0
Training loss: 2.170524561541154
Validation loss: 2.5318586339886955

Epoch: 5| Step: 1
Training loss: 2.2792431090354204
Validation loss: 2.5185130149033452

Epoch: 5| Step: 2
Training loss: 2.9421303150456217
Validation loss: 2.5305735975518666

Epoch: 5| Step: 3
Training loss: 2.4864642876845555
Validation loss: 2.5485956351503

Epoch: 5| Step: 4
Training loss: 2.266981363422671
Validation loss: 2.551416303437406

Epoch: 5| Step: 5
Training loss: 2.1410642298578884
Validation loss: 2.5534536471564597

Epoch: 5| Step: 6
Training loss: 2.595185307848743
Validation loss: 2.5419505395944624

Epoch: 5| Step: 7
Training loss: 2.5904789716658234
Validation loss: 2.5505822762760193

Epoch: 5| Step: 8
Training loss: 2.1696491499265163
Validation loss: 2.545706039941366

Epoch: 5| Step: 9
Training loss: 1.7368474983819098
Validation loss: 2.5278014486436535

Epoch: 5| Step: 10
Training loss: 1.7921354065086268
Validation loss: 2.5186733115853066

Epoch: 5| Step: 11
Training loss: 2.523584698142452
Validation loss: 2.5159125904105277

Epoch: 276| Step: 0
Training loss: 2.0687842144398547
Validation loss: 2.5171317372380075

Epoch: 5| Step: 1
Training loss: 1.8472281155536052
Validation loss: 2.52936562306022

Epoch: 5| Step: 2
Training loss: 2.2347439548006536
Validation loss: 2.5311765463889437

Epoch: 5| Step: 3
Training loss: 2.049320536335039
Validation loss: 2.52516194129562

Epoch: 5| Step: 4
Training loss: 2.525436507160055
Validation loss: 2.5360466951406933

Epoch: 5| Step: 5
Training loss: 2.871772281108984
Validation loss: 2.521721739840975

Epoch: 5| Step: 6
Training loss: 2.967222121741306
Validation loss: 2.5486611809750905

Epoch: 5| Step: 7
Training loss: 1.8710973178136652
Validation loss: 2.5328697704858674

Epoch: 5| Step: 8
Training loss: 2.093963953729926
Validation loss: 2.5243156881244184

Epoch: 5| Step: 9
Training loss: 2.227846330976304
Validation loss: 2.5241852706441046

Epoch: 5| Step: 10
Training loss: 2.092237922909823
Validation loss: 2.504803513132414

Epoch: 5| Step: 11
Training loss: 3.3761145552774785
Validation loss: 2.5353251059577806

Epoch: 277| Step: 0
Training loss: 1.9017763642887815
Validation loss: 2.53374866502498

Epoch: 5| Step: 1
Training loss: 2.1044618254770353
Validation loss: 2.5264917516701444

Epoch: 5| Step: 2
Training loss: 2.1235628317027047
Validation loss: 2.5128238356992862

Epoch: 5| Step: 3
Training loss: 2.7029653513074585
Validation loss: 2.515450015409105

Epoch: 5| Step: 4
Training loss: 2.390697104170744
Validation loss: 2.499549523139909

Epoch: 5| Step: 5
Training loss: 2.674625074547495
Validation loss: 2.5037628386675084

Epoch: 5| Step: 6
Training loss: 2.333536604701057
Validation loss: 2.4951916011058084

Epoch: 5| Step: 7
Training loss: 2.4505775977494677
Validation loss: 2.4966395084442947

Epoch: 5| Step: 8
Training loss: 2.222953682626734
Validation loss: 2.4995160309911544

Epoch: 5| Step: 9
Training loss: 2.491252951153712
Validation loss: 2.503384151370457

Epoch: 5| Step: 10
Training loss: 2.3199832567071184
Validation loss: 2.5039622934846872

Epoch: 5| Step: 11
Training loss: 3.003094190108037
Validation loss: 2.4931376010413437

Epoch: 278| Step: 0
Training loss: 2.6564357019473146
Validation loss: 2.514407323246593

Epoch: 5| Step: 1
Training loss: 1.7810354940185722
Validation loss: 2.50543704082715

Epoch: 5| Step: 2
Training loss: 2.573929302978654
Validation loss: 2.525131243735027

Epoch: 5| Step: 3
Training loss: 2.1694113390886716
Validation loss: 2.5064979427407077

Epoch: 5| Step: 4
Training loss: 2.562862928787677
Validation loss: 2.520279150858664

Epoch: 5| Step: 5
Training loss: 1.775195825547119
Validation loss: 2.525509490490285

Epoch: 5| Step: 6
Training loss: 2.5526690894303274
Validation loss: 2.5232281396268443

Epoch: 5| Step: 7
Training loss: 1.7468460817621911
Validation loss: 2.5061393813267103

Epoch: 5| Step: 8
Training loss: 2.7086229805239705
Validation loss: 2.5102878606103007

Epoch: 5| Step: 9
Training loss: 2.3368797825787055
Validation loss: 2.5188535247017763

Epoch: 5| Step: 10
Training loss: 2.6843356643654634
Validation loss: 2.5086593069711483

Epoch: 5| Step: 11
Training loss: 2.34311921850322
Validation loss: 2.5180846129740497

Epoch: 279| Step: 0
Training loss: 1.991204352038215
Validation loss: 2.5206398154032286

Epoch: 5| Step: 1
Training loss: 2.146679634189336
Validation loss: 2.5298082382169143

Epoch: 5| Step: 2
Training loss: 1.8833805984147516
Validation loss: 2.5200350590378817

Epoch: 5| Step: 3
Training loss: 2.707836917474345
Validation loss: 2.5273168052404413

Epoch: 5| Step: 4
Training loss: 2.2994496972574296
Validation loss: 2.529312553995403

Epoch: 5| Step: 5
Training loss: 2.2487415397107453
Validation loss: 2.5231210000327167

Epoch: 5| Step: 6
Training loss: 2.1579404092786154
Validation loss: 2.523861765749242

Epoch: 5| Step: 7
Training loss: 2.113545681526754
Validation loss: 2.52242646567311

Epoch: 5| Step: 8
Training loss: 2.5945968164775977
Validation loss: 2.514938083004062

Epoch: 5| Step: 9
Training loss: 2.6187463473565384
Validation loss: 2.521130068840204

Epoch: 5| Step: 10
Training loss: 2.5338488765294103
Validation loss: 2.525381915792153

Epoch: 5| Step: 11
Training loss: 2.521301310163238
Validation loss: 2.523319450270517

Epoch: 280| Step: 0
Training loss: 2.280693090733844
Validation loss: 2.51631795725717

Epoch: 5| Step: 1
Training loss: 2.765141676572127
Validation loss: 2.517968521646822

Epoch: 5| Step: 2
Training loss: 2.0607892657714184
Validation loss: 2.5164474501301957

Epoch: 5| Step: 3
Training loss: 2.5829874135241293
Validation loss: 2.523939911358827

Epoch: 5| Step: 4
Training loss: 2.1871042166020724
Validation loss: 2.5272756741301046

Epoch: 5| Step: 5
Training loss: 2.225112282137991
Validation loss: 2.5370884229555

Epoch: 5| Step: 6
Training loss: 2.2722628465713846
Validation loss: 2.5314780277790727

Epoch: 5| Step: 7
Training loss: 2.6576819655238295
Validation loss: 2.5238087974414056

Epoch: 5| Step: 8
Training loss: 2.700062864066255
Validation loss: 2.5142868819075357

Epoch: 5| Step: 9
Training loss: 1.4767545544896528
Validation loss: 2.522917580755327

Epoch: 5| Step: 10
Training loss: 1.8418990720710424
Validation loss: 2.5274384533425276

Epoch: 5| Step: 11
Training loss: 1.9292037913606908
Validation loss: 2.5196963115709803

Epoch: 281| Step: 0
Training loss: 2.556295186508476
Validation loss: 2.5418826126123455

Epoch: 5| Step: 1
Training loss: 2.930926007745405
Validation loss: 2.5402290676983843

Epoch: 5| Step: 2
Training loss: 2.2544471448708023
Validation loss: 2.5432817703005615

Epoch: 5| Step: 3
Training loss: 2.3781850438802676
Validation loss: 2.5455836940579513

Epoch: 5| Step: 4
Training loss: 2.0100121231093078
Validation loss: 2.5632175355864066

Epoch: 5| Step: 5
Training loss: 1.5526043147671729
Validation loss: 2.542514324848052

Epoch: 5| Step: 6
Training loss: 2.626894766574128
Validation loss: 2.5671101035092856

Epoch: 5| Step: 7
Training loss: 1.8430138104190938
Validation loss: 2.5553291868131742

Epoch: 5| Step: 8
Training loss: 2.1280838524065575
Validation loss: 2.543214335890841

Epoch: 5| Step: 9
Training loss: 2.5660469813992672
Validation loss: 2.547644914205881

Epoch: 5| Step: 10
Training loss: 2.3810526368059826
Validation loss: 2.535939182414909

Epoch: 5| Step: 11
Training loss: 0.9224500640544904
Validation loss: 2.5301686869740254

Epoch: 282| Step: 0
Training loss: 1.9800932940264977
Validation loss: 2.5324142392390705

Epoch: 5| Step: 1
Training loss: 2.4533013930349323
Validation loss: 2.5059807763606763

Epoch: 5| Step: 2
Training loss: 2.377811574646209
Validation loss: 2.5086030080587425

Epoch: 5| Step: 3
Training loss: 1.6354005735864947
Validation loss: 2.5039779724227764

Epoch: 5| Step: 4
Training loss: 2.4070640276961797
Validation loss: 2.512142056736144

Epoch: 5| Step: 5
Training loss: 2.220834102475413
Validation loss: 2.520842155462123

Epoch: 5| Step: 6
Training loss: 2.792195417139989
Validation loss: 2.5100189358223672

Epoch: 5| Step: 7
Training loss: 2.4275517045868216
Validation loss: 2.5090365527216867

Epoch: 5| Step: 8
Training loss: 2.1964566653201683
Validation loss: 2.5211237544388405

Epoch: 5| Step: 9
Training loss: 2.1523017671509503
Validation loss: 2.519263459792173

Epoch: 5| Step: 10
Training loss: 2.4910638362770774
Validation loss: 2.515616999390321

Epoch: 5| Step: 11
Training loss: 2.5656105329173036
Validation loss: 2.5417497939185414

Epoch: 283| Step: 0
Training loss: 2.4404621221334026
Validation loss: 2.5323186470978536

Epoch: 5| Step: 1
Training loss: 2.4639322133957893
Validation loss: 2.5240331247992915

Epoch: 5| Step: 2
Training loss: 2.124727568273138
Validation loss: 2.5192807923260028

Epoch: 5| Step: 3
Training loss: 2.3735730753406212
Validation loss: 2.5256811507378085

Epoch: 5| Step: 4
Training loss: 3.148095048402582
Validation loss: 2.5344698211266414

Epoch: 5| Step: 5
Training loss: 2.2045578862405497
Validation loss: 2.53346462855878

Epoch: 5| Step: 6
Training loss: 2.372278561643983
Validation loss: 2.55074357009327

Epoch: 5| Step: 7
Training loss: 1.9043432611537974
Validation loss: 2.54878836999049

Epoch: 5| Step: 8
Training loss: 2.137142048807188
Validation loss: 2.546974679443364

Epoch: 5| Step: 9
Training loss: 1.9636019656149932
Validation loss: 2.5344867459021674

Epoch: 5| Step: 10
Training loss: 2.0037258728821232
Validation loss: 2.5507520408184767

Epoch: 5| Step: 11
Training loss: 1.5664827323373405
Validation loss: 2.5547646910411785

Epoch: 284| Step: 0
Training loss: 2.434346335245981
Validation loss: 2.543827843470851

Epoch: 5| Step: 1
Training loss: 2.390727122001798
Validation loss: 2.5437692065064508

Epoch: 5| Step: 2
Training loss: 1.992777957554078
Validation loss: 2.5521450671040924

Epoch: 5| Step: 3
Training loss: 2.5839616770190736
Validation loss: 2.5402703449413284

Epoch: 5| Step: 4
Training loss: 1.9326516062103767
Validation loss: 2.556856410996262

Epoch: 5| Step: 5
Training loss: 2.242144115706148
Validation loss: 2.5340119842331466

Epoch: 5| Step: 6
Training loss: 2.6533508635984964
Validation loss: 2.5132744313626714

Epoch: 5| Step: 7
Training loss: 2.0771017208324927
Validation loss: 2.5199743112952686

Epoch: 5| Step: 8
Training loss: 1.862378043463819
Validation loss: 2.5096489351014113

Epoch: 5| Step: 9
Training loss: 2.6173736050610845
Validation loss: 2.4988605366172627

Epoch: 5| Step: 10
Training loss: 2.2815378085917604
Validation loss: 2.5161313204911693

Epoch: 5| Step: 11
Training loss: 3.5574548701562247
Validation loss: 2.49303328254146

Epoch: 285| Step: 0
Training loss: 2.2265009285963218
Validation loss: 2.499945608183127

Epoch: 5| Step: 1
Training loss: 1.5299134941827977
Validation loss: 2.513708719508639

Epoch: 5| Step: 2
Training loss: 2.1197288435141024
Validation loss: 2.51245831269938

Epoch: 5| Step: 3
Training loss: 2.466724675587567
Validation loss: 2.5145031775336077

Epoch: 5| Step: 4
Training loss: 2.1836829534063122
Validation loss: 2.523131849046403

Epoch: 5| Step: 5
Training loss: 2.7038070612021383
Validation loss: 2.5157843553131305

Epoch: 5| Step: 6
Training loss: 2.344143541992488
Validation loss: 2.525198810921259

Epoch: 5| Step: 7
Training loss: 3.2503711781918856
Validation loss: 2.5294082165419005

Epoch: 5| Step: 8
Training loss: 2.107621658089967
Validation loss: 2.52736921263205

Epoch: 5| Step: 9
Training loss: 1.9305938569011778
Validation loss: 2.5358238281703254

Epoch: 5| Step: 10
Training loss: 2.3597426980591973
Validation loss: 2.525625062127676

Epoch: 5| Step: 11
Training loss: 1.6525739504935855
Validation loss: 2.517610812610034

Epoch: 286| Step: 0
Training loss: 2.362647408221068
Validation loss: 2.5238919552586547

Epoch: 5| Step: 1
Training loss: 2.8598829141405027
Validation loss: 2.5413468477577625

Epoch: 5| Step: 2
Training loss: 2.1408515309111897
Validation loss: 2.52779297174934

Epoch: 5| Step: 3
Training loss: 2.5504909192424474
Validation loss: 2.5379021130235717

Epoch: 5| Step: 4
Training loss: 1.96964661299307
Validation loss: 2.531601167188974

Epoch: 5| Step: 5
Training loss: 2.1693480356926083
Validation loss: 2.5331709523193493

Epoch: 5| Step: 6
Training loss: 1.965668219013883
Validation loss: 2.5327861896696047

Epoch: 5| Step: 7
Training loss: 2.5873320815291305
Validation loss: 2.537206086549049

Epoch: 5| Step: 8
Training loss: 2.433067203582934
Validation loss: 2.5371634712746234

Epoch: 5| Step: 9
Training loss: 2.1474516115077167
Validation loss: 2.5429111167521707

Epoch: 5| Step: 10
Training loss: 1.884331308241077
Validation loss: 2.5289708657701446

Epoch: 5| Step: 11
Training loss: 2.4491432093115333
Validation loss: 2.540866117308661

Epoch: 287| Step: 0
Training loss: 2.3483261193660323
Validation loss: 2.521174499712725

Epoch: 5| Step: 1
Training loss: 2.1650342171235812
Validation loss: 2.5074530449854495

Epoch: 5| Step: 2
Training loss: 1.9656905364981336
Validation loss: 2.512482467197969

Epoch: 5| Step: 3
Training loss: 2.4842065718076576
Validation loss: 2.516746194137662

Epoch: 5| Step: 4
Training loss: 2.169371115269723
Validation loss: 2.521429808381036

Epoch: 5| Step: 5
Training loss: 2.7925393367991793
Validation loss: 2.530504925492719

Epoch: 5| Step: 6
Training loss: 2.6692965374461073
Validation loss: 2.523540014462048

Epoch: 5| Step: 7
Training loss: 2.632975677957419
Validation loss: 2.531067303944175

Epoch: 5| Step: 8
Training loss: 2.158296581333438
Validation loss: 2.5220536648891576

Epoch: 5| Step: 9
Training loss: 2.075900845138721
Validation loss: 2.5301690364114

Epoch: 5| Step: 10
Training loss: 1.8075006530887168
Validation loss: 2.533960578673039

Epoch: 5| Step: 11
Training loss: 2.403845241839896
Validation loss: 2.533456468622111

Epoch: 288| Step: 0
Training loss: 2.1687228154394282
Validation loss: 2.5251195397737907

Epoch: 5| Step: 1
Training loss: 1.7283622371913878
Validation loss: 2.52514166906658

Epoch: 5| Step: 2
Training loss: 1.9518212201138876
Validation loss: 2.5365833875676445

Epoch: 5| Step: 3
Training loss: 2.127280974538862
Validation loss: 2.5377457397934253

Epoch: 5| Step: 4
Training loss: 2.1822621442911596
Validation loss: 2.524439997389167

Epoch: 5| Step: 5
Training loss: 1.9900571914582401
Validation loss: 2.529331143219485

Epoch: 5| Step: 6
Training loss: 3.0224623573805225
Validation loss: 2.5214400047458305

Epoch: 5| Step: 7
Training loss: 2.395990670607909
Validation loss: 2.513676615455898

Epoch: 5| Step: 8
Training loss: 2.698137654762379
Validation loss: 2.530925667160426

Epoch: 5| Step: 9
Training loss: 2.36163969169436
Validation loss: 2.5436437036298196

Epoch: 5| Step: 10
Training loss: 2.139498449001833
Validation loss: 2.5447827269659573

Epoch: 5| Step: 11
Training loss: 2.3440740742745385
Validation loss: 2.5424684969070293

Epoch: 289| Step: 0
Training loss: 2.3890997315543845
Validation loss: 2.5488303348926302

Epoch: 5| Step: 1
Training loss: 2.000696776132469
Validation loss: 2.562665513361105

Epoch: 5| Step: 2
Training loss: 2.2998834746324013
Validation loss: 2.5655132232181006

Epoch: 5| Step: 3
Training loss: 2.222978565196809
Validation loss: 2.5831095242200166

Epoch: 5| Step: 4
Training loss: 2.2073262515440746
Validation loss: 2.5712154468198394

Epoch: 5| Step: 5
Training loss: 2.44237656499101
Validation loss: 2.5629939169278826

Epoch: 5| Step: 6
Training loss: 1.8344955950580404
Validation loss: 2.5726682463241803

Epoch: 5| Step: 7
Training loss: 2.1443879404458603
Validation loss: 2.5941180117482707

Epoch: 5| Step: 8
Training loss: 2.504786867680051
Validation loss: 2.599408324177

Epoch: 5| Step: 9
Training loss: 2.850395402751409
Validation loss: 2.5931448019759116

Epoch: 5| Step: 10
Training loss: 2.2234273689130353
Validation loss: 2.581491842016757

Epoch: 5| Step: 11
Training loss: 1.63458929170522
Validation loss: 2.5753945813736143

Epoch: 290| Step: 0
Training loss: 2.2186810120079077
Validation loss: 2.591097026473914

Epoch: 5| Step: 1
Training loss: 1.518964961031421
Validation loss: 2.5972312522216687

Epoch: 5| Step: 2
Training loss: 2.3162611197026117
Validation loss: 2.583210958894574

Epoch: 5| Step: 3
Training loss: 1.6963159781930148
Validation loss: 2.565230763727478

Epoch: 5| Step: 4
Training loss: 1.961139805301371
Validation loss: 2.5582890375218743

Epoch: 5| Step: 5
Training loss: 2.688223541802181
Validation loss: 2.5584636897841087

Epoch: 5| Step: 6
Training loss: 2.0515528217444743
Validation loss: 2.536833691614273

Epoch: 5| Step: 7
Training loss: 2.736808086726316
Validation loss: 2.5341672961961725

Epoch: 5| Step: 8
Training loss: 2.8274457758688345
Validation loss: 2.530979196952554

Epoch: 5| Step: 9
Training loss: 2.262577506576648
Validation loss: 2.503888453967352

Epoch: 5| Step: 10
Training loss: 2.0915723265185227
Validation loss: 2.520367832920518

Epoch: 5| Step: 11
Training loss: 3.277700484346898
Validation loss: 2.5141859025464837

Epoch: 291| Step: 0
Training loss: 2.310106533781118
Validation loss: 2.5145154563530916

Epoch: 5| Step: 1
Training loss: 2.3365440984442407
Validation loss: 2.5031725740455952

Epoch: 5| Step: 2
Training loss: 2.063798206859201
Validation loss: 2.511730991015311

Epoch: 5| Step: 3
Training loss: 2.5975668526087974
Validation loss: 2.5083565681327675

Epoch: 5| Step: 4
Training loss: 2.2609201975004187
Validation loss: 2.506884715219074

Epoch: 5| Step: 5
Training loss: 2.415507060301816
Validation loss: 2.527972320579898

Epoch: 5| Step: 6
Training loss: 1.8484502461397827
Validation loss: 2.515246777504647

Epoch: 5| Step: 7
Training loss: 2.506103884273749
Validation loss: 2.5265230421493583

Epoch: 5| Step: 8
Training loss: 2.760903676575502
Validation loss: 2.50702177438028

Epoch: 5| Step: 9
Training loss: 1.7610758688990877
Validation loss: 2.5297319978126924

Epoch: 5| Step: 10
Training loss: 1.9780287298848822
Validation loss: 2.5269452959640035

Epoch: 5| Step: 11
Training loss: 1.8875969842916183
Validation loss: 2.5482661225687018

Epoch: 292| Step: 0
Training loss: 2.1137728586432867
Validation loss: 2.5700884086527687

Epoch: 5| Step: 1
Training loss: 2.2733548598328386
Validation loss: 2.5749863178235346

Epoch: 5| Step: 2
Training loss: 2.301589072722164
Validation loss: 2.5861038354274384

Epoch: 5| Step: 3
Training loss: 2.4990344090163124
Validation loss: 2.5858133176737246

Epoch: 5| Step: 4
Training loss: 3.064445967267772
Validation loss: 2.579998934404266

Epoch: 5| Step: 5
Training loss: 2.3684757365779157
Validation loss: 2.5770208672426307

Epoch: 5| Step: 6
Training loss: 2.400449921237962
Validation loss: 2.569463514280148

Epoch: 5| Step: 7
Training loss: 2.064690784643998
Validation loss: 2.5653167029822024

Epoch: 5| Step: 8
Training loss: 2.0926638390719554
Validation loss: 2.5489366218401943

Epoch: 5| Step: 9
Training loss: 1.704032166387851
Validation loss: 2.5128295324904517

Epoch: 5| Step: 10
Training loss: 2.002507664240768
Validation loss: 2.5115639068826137

Epoch: 5| Step: 11
Training loss: 2.20054811238793
Validation loss: 2.5062813367652366

Epoch: 293| Step: 0
Training loss: 2.5866714772772874
Validation loss: 2.496030103243144

Epoch: 5| Step: 1
Training loss: 2.276266952526935
Validation loss: 2.505935774818147

Epoch: 5| Step: 2
Training loss: 2.1850404263385808
Validation loss: 2.5005614286079396

Epoch: 5| Step: 3
Training loss: 2.531901711290303
Validation loss: 2.500336254871426

Epoch: 5| Step: 4
Training loss: 2.3935247051301984
Validation loss: 2.4879056366579233

Epoch: 5| Step: 5
Training loss: 1.5033034664804552
Validation loss: 2.4917353914557974

Epoch: 5| Step: 6
Training loss: 3.004254661960862
Validation loss: 2.4893545992704342

Epoch: 5| Step: 7
Training loss: 2.0432660851087565
Validation loss: 2.5057821997802288

Epoch: 5| Step: 8
Training loss: 2.6654190681577496
Validation loss: 2.5161900211582076

Epoch: 5| Step: 9
Training loss: 1.6915063277804747
Validation loss: 2.535364586215051

Epoch: 5| Step: 10
Training loss: 2.1430305274572663
Validation loss: 2.5260193945043756

Epoch: 5| Step: 11
Training loss: 2.3962704688179515
Validation loss: 2.5247900637924188

Epoch: 294| Step: 0
Training loss: 2.3106604811792337
Validation loss: 2.5340606916318213

Epoch: 5| Step: 1
Training loss: 2.436937022607384
Validation loss: 2.5214100971308016

Epoch: 5| Step: 2
Training loss: 1.922761542061791
Validation loss: 2.5570464583163273

Epoch: 5| Step: 3
Training loss: 2.5472776878620027
Validation loss: 2.5335820056142375

Epoch: 5| Step: 4
Training loss: 2.297867126023048
Validation loss: 2.532851528845209

Epoch: 5| Step: 5
Training loss: 1.7356533116637045
Validation loss: 2.53802015379055

Epoch: 5| Step: 6
Training loss: 1.828672669366897
Validation loss: 2.500090716623447

Epoch: 5| Step: 7
Training loss: 2.2433397475892978
Validation loss: 2.537141078783192

Epoch: 5| Step: 8
Training loss: 2.5975510654808622
Validation loss: 2.5145872554311266

Epoch: 5| Step: 9
Training loss: 2.282410731330029
Validation loss: 2.5453880548630554

Epoch: 5| Step: 10
Training loss: 2.065374509827389
Validation loss: 2.5238651310905347

Epoch: 5| Step: 11
Training loss: 4.146105324466838
Validation loss: 2.5239411413436663

Epoch: 295| Step: 0
Training loss: 2.2294818144401156
Validation loss: 2.525476181339375

Epoch: 5| Step: 1
Training loss: 2.092559248109392
Validation loss: 2.5268654781026596

Epoch: 5| Step: 2
Training loss: 2.836903809415637
Validation loss: 2.5296538819028394

Epoch: 5| Step: 3
Training loss: 1.7598694020281234
Validation loss: 2.5394097565114078

Epoch: 5| Step: 4
Training loss: 2.170003839656404
Validation loss: 2.5393666168407507

Epoch: 5| Step: 5
Training loss: 2.5151024506711104
Validation loss: 2.547562063800718

Epoch: 5| Step: 6
Training loss: 2.8514216976153905
Validation loss: 2.54684829892943

Epoch: 5| Step: 7
Training loss: 2.304847116923671
Validation loss: 2.546022131943531

Epoch: 5| Step: 8
Training loss: 2.659224426812175
Validation loss: 2.5457472069173135

Epoch: 5| Step: 9
Training loss: 1.1396211361005226
Validation loss: 2.524721608221718

Epoch: 5| Step: 10
Training loss: 1.8038062383882016
Validation loss: 2.5338010256383976

Epoch: 5| Step: 11
Training loss: 1.6572681392563748
Validation loss: 2.5210422174486604

Epoch: 296| Step: 0
Training loss: 2.390807899010948
Validation loss: 2.5289501134136168

Epoch: 5| Step: 1
Training loss: 1.958137610644788
Validation loss: 2.518990810105947

Epoch: 5| Step: 2
Training loss: 2.1200065285204284
Validation loss: 2.5212440720946954

Epoch: 5| Step: 3
Training loss: 2.0579271196263496
Validation loss: 2.519029804966069

Epoch: 5| Step: 4
Training loss: 1.609373888922743
Validation loss: 2.518370802222112

Epoch: 5| Step: 5
Training loss: 2.5596373781036355
Validation loss: 2.5145784633739967

Epoch: 5| Step: 6
Training loss: 2.2550533555648062
Validation loss: 2.530947047027682

Epoch: 5| Step: 7
Training loss: 2.2955356767258785
Validation loss: 2.5319569055867093

Epoch: 5| Step: 8
Training loss: 2.115362978871274
Validation loss: 2.5336612158791434

Epoch: 5| Step: 9
Training loss: 2.339608360512206
Validation loss: 2.5411823246368535

Epoch: 5| Step: 10
Training loss: 2.82524290812829
Validation loss: 2.560108534292895

Epoch: 5| Step: 11
Training loss: 3.0168416627599237
Validation loss: 2.547609710814187

Epoch: 297| Step: 0
Training loss: 2.4142367105678186
Validation loss: 2.5636091371193324

Epoch: 5| Step: 1
Training loss: 1.9224458792500843
Validation loss: 2.540365708254916

Epoch: 5| Step: 2
Training loss: 2.4335445686869277
Validation loss: 2.563710465674295

Epoch: 5| Step: 3
Training loss: 2.049115999869312
Validation loss: 2.554570054398407

Epoch: 5| Step: 4
Training loss: 2.0090098095165905
Validation loss: 2.536687058639604

Epoch: 5| Step: 5
Training loss: 2.3961597275582287
Validation loss: 2.546270302598101

Epoch: 5| Step: 6
Training loss: 2.755643256220623
Validation loss: 2.522994704316688

Epoch: 5| Step: 7
Training loss: 2.145804605631206
Validation loss: 2.525366955867738

Epoch: 5| Step: 8
Training loss: 2.5630924191342452
Validation loss: 2.515312868502857

Epoch: 5| Step: 9
Training loss: 1.9439463280148432
Validation loss: 2.5044843310894556

Epoch: 5| Step: 10
Training loss: 2.1690144534299978
Validation loss: 2.5071100833806197

Epoch: 5| Step: 11
Training loss: 3.1820582893734386
Validation loss: 2.5025089846534527

Epoch: 298| Step: 0
Training loss: 1.8615351078514937
Validation loss: 2.52151785113478

Epoch: 5| Step: 1
Training loss: 2.5434797626137953
Validation loss: 2.5283580947632434

Epoch: 5| Step: 2
Training loss: 1.7778097694551684
Validation loss: 2.523353681559975

Epoch: 5| Step: 3
Training loss: 2.1113811983818485
Validation loss: 2.543230432971892

Epoch: 5| Step: 4
Training loss: 2.262973048880277
Validation loss: 2.5254287441491243

Epoch: 5| Step: 5
Training loss: 2.915865670070553
Validation loss: 2.5495570712839193

Epoch: 5| Step: 6
Training loss: 1.9592751679852596
Validation loss: 2.518244952704976

Epoch: 5| Step: 7
Training loss: 2.284013406964718
Validation loss: 2.5308321344960825

Epoch: 5| Step: 8
Training loss: 2.8854075591199524
Validation loss: 2.5294309366996006

Epoch: 5| Step: 9
Training loss: 2.0122195314955396
Validation loss: 2.5408781006112697

Epoch: 5| Step: 10
Training loss: 2.382629987887269
Validation loss: 2.5254846778107267

Epoch: 5| Step: 11
Training loss: 2.2445083994088972
Validation loss: 2.5416979409987994

Epoch: 299| Step: 0
Training loss: 2.058981466246048
Validation loss: 2.5245017296567367

Epoch: 5| Step: 1
Training loss: 2.6111234186662498
Validation loss: 2.5176482939331555

Epoch: 5| Step: 2
Training loss: 2.6744305619550106
Validation loss: 2.5181560538617833

Epoch: 5| Step: 3
Training loss: 2.319173205639796
Validation loss: 2.51944605956843

Epoch: 5| Step: 4
Training loss: 1.8764783117767392
Validation loss: 2.523918987748906

Epoch: 5| Step: 5
Training loss: 2.366777541916934
Validation loss: 2.534078971610739

Epoch: 5| Step: 6
Training loss: 2.4594157039856004
Validation loss: 2.539965280304303

Epoch: 5| Step: 7
Training loss: 2.1068776358625003
Validation loss: 2.5090140279836652

Epoch: 5| Step: 8
Training loss: 2.246593015163461
Validation loss: 2.524825136814977

Epoch: 5| Step: 9
Training loss: 2.405828860201331
Validation loss: 2.5232031588401767

Epoch: 5| Step: 10
Training loss: 2.4451429411873113
Validation loss: 2.5250087566349793

Epoch: 5| Step: 11
Training loss: 1.7553859662313285
Validation loss: 2.521011485485589

Epoch: 300| Step: 0
Training loss: 2.747217851752531
Validation loss: 2.504936165145391

Epoch: 5| Step: 1
Training loss: 2.636085535945263
Validation loss: 2.495493403250815

Epoch: 5| Step: 2
Training loss: 2.409566797917312
Validation loss: 2.4981769829123768

Epoch: 5| Step: 3
Training loss: 2.282655570336731
Validation loss: 2.498213753732174

Epoch: 5| Step: 4
Training loss: 2.471015566645226
Validation loss: 2.5191918432820213

Epoch: 5| Step: 5
Training loss: 2.1906512858817693
Validation loss: 2.5213819345574904

Epoch: 5| Step: 6
Training loss: 1.9655878618428384
Validation loss: 2.5340107199335

Epoch: 5| Step: 7
Training loss: 2.056851483989829
Validation loss: 2.5304805543739426

Epoch: 5| Step: 8
Training loss: 2.027136055187879
Validation loss: 2.5123215540815234

Epoch: 5| Step: 9
Training loss: 2.3391246677818995
Validation loss: 2.501404169247662

Epoch: 5| Step: 10
Training loss: 2.4451321178851613
Validation loss: 2.4945766592586915

Epoch: 5| Step: 11
Training loss: 1.5262519075348953
Validation loss: 2.507085106432567

Epoch: 301| Step: 0
Training loss: 1.7531894501995544
Validation loss: 2.5135827669929824

Epoch: 5| Step: 1
Training loss: 2.5647394582626775
Validation loss: 2.4966201227222884

Epoch: 5| Step: 2
Training loss: 2.403973381783731
Validation loss: 2.4954435987277708

Epoch: 5| Step: 3
Training loss: 2.344625284151712
Validation loss: 2.4935824278170418

Epoch: 5| Step: 4
Training loss: 2.744824915376308
Validation loss: 2.495033221937807

Epoch: 5| Step: 5
Training loss: 2.719014297442149
Validation loss: 2.5006734695892052

Epoch: 5| Step: 6
Training loss: 1.7791090697614758
Validation loss: 2.500766882894381

Epoch: 5| Step: 7
Training loss: 2.5831444168745534
Validation loss: 2.505458646126859

Epoch: 5| Step: 8
Training loss: 2.142528495109448
Validation loss: 2.509266203235571

Epoch: 5| Step: 9
Training loss: 2.004958443532067
Validation loss: 2.5108412519427787

Epoch: 5| Step: 10
Training loss: 2.5022815783563592
Validation loss: 2.509500777028656

Epoch: 5| Step: 11
Training loss: 1.6599163285965002
Validation loss: 2.5323036104645302

Epoch: 302| Step: 0
Training loss: 1.9448823261702843
Validation loss: 2.5285042167526828

Epoch: 5| Step: 1
Training loss: 3.01058063698509
Validation loss: 2.560924592372538

Epoch: 5| Step: 2
Training loss: 2.930689281849587
Validation loss: 2.558190066885336

Epoch: 5| Step: 3
Training loss: 2.4037616298193845
Validation loss: 2.5729113255701472

Epoch: 5| Step: 4
Training loss: 1.9140794402949335
Validation loss: 2.5734155315425777

Epoch: 5| Step: 5
Training loss: 1.460654409795605
Validation loss: 2.5758919186585274

Epoch: 5| Step: 6
Training loss: 2.623753842246053
Validation loss: 2.577667843138833

Epoch: 5| Step: 7
Training loss: 2.0376207655239083
Validation loss: 2.5686996292596045

Epoch: 5| Step: 8
Training loss: 1.8498013647511005
Validation loss: 2.578453216467849

Epoch: 5| Step: 9
Training loss: 2.4182293432562787
Validation loss: 2.5659911673062545

Epoch: 5| Step: 10
Training loss: 1.768599308994999
Validation loss: 2.5684220725796463

Epoch: 5| Step: 11
Training loss: 2.3933162126840832
Validation loss: 2.57391570974638

Epoch: 303| Step: 0
Training loss: 2.3331962499767913
Validation loss: 2.5545509644088162

Epoch: 5| Step: 1
Training loss: 1.8975526607880655
Validation loss: 2.57000590295893

Epoch: 5| Step: 2
Training loss: 2.3770619526558234
Validation loss: 2.550154857826387

Epoch: 5| Step: 3
Training loss: 1.5925966465247026
Validation loss: 2.5640010159203337

Epoch: 5| Step: 4
Training loss: 2.711765305831899
Validation loss: 2.5401717829248436

Epoch: 5| Step: 5
Training loss: 2.2763558759371465
Validation loss: 2.552272105858323

Epoch: 5| Step: 6
Training loss: 2.2684874243418176
Validation loss: 2.5479502816580797

Epoch: 5| Step: 7
Training loss: 1.8486801439645315
Validation loss: 2.5553072450831116

Epoch: 5| Step: 8
Training loss: 2.4350312275225567
Validation loss: 2.5647626129835785

Epoch: 5| Step: 9
Training loss: 2.412360125029688
Validation loss: 2.5553853815082417

Epoch: 5| Step: 10
Training loss: 2.2923283633145464
Validation loss: 2.5518932051129544

Epoch: 5| Step: 11
Training loss: 2.665487763962991
Validation loss: 2.55900712301809

Epoch: 304| Step: 0
Training loss: 2.0543746419963753
Validation loss: 2.5634544424888897

Epoch: 5| Step: 1
Training loss: 1.9885609847806152
Validation loss: 2.574098822540531

Epoch: 5| Step: 2
Training loss: 2.4836661809131417
Validation loss: 2.578360853099697

Epoch: 5| Step: 3
Training loss: 1.9022172263053598
Validation loss: 2.5799855887764607

Epoch: 5| Step: 4
Training loss: 2.5302038974547707
Validation loss: 2.5847376434070664

Epoch: 5| Step: 5
Training loss: 2.269408861231765
Validation loss: 2.581871701080448

Epoch: 5| Step: 6
Training loss: 2.6012595060395705
Validation loss: 2.5880610917286133

Epoch: 5| Step: 7
Training loss: 2.5112005147050547
Validation loss: 2.548242778967568

Epoch: 5| Step: 8
Training loss: 2.0525065984399182
Validation loss: 2.565555445029881

Epoch: 5| Step: 9
Training loss: 1.790147477366783
Validation loss: 2.55940048661543

Epoch: 5| Step: 10
Training loss: 1.9090527426426134
Validation loss: 2.5535934936670204

Epoch: 5| Step: 11
Training loss: 3.4438794674222866
Validation loss: 2.5469156078697592

Epoch: 305| Step: 0
Training loss: 2.551793316821506
Validation loss: 2.5392366867960825

Epoch: 5| Step: 1
Training loss: 2.559461886057145
Validation loss: 2.530126053289065

Epoch: 5| Step: 2
Training loss: 1.9030305535193526
Validation loss: 2.530393706800205

Epoch: 5| Step: 3
Training loss: 2.649754109760678
Validation loss: 2.547115665602711

Epoch: 5| Step: 4
Training loss: 2.148832416651493
Validation loss: 2.5293157942566324

Epoch: 5| Step: 5
Training loss: 2.472939425339348
Validation loss: 2.5427527309064635

Epoch: 5| Step: 6
Training loss: 2.3018180959039443
Validation loss: 2.552520396636511

Epoch: 5| Step: 7
Training loss: 1.6911627261586233
Validation loss: 2.553312357327909

Epoch: 5| Step: 8
Training loss: 2.361259263819651
Validation loss: 2.5528223265304155

Epoch: 5| Step: 9
Training loss: 1.9848094074215445
Validation loss: 2.5476932966293018

Epoch: 5| Step: 10
Training loss: 1.6520682030747016
Validation loss: 2.5633090533068565

Epoch: 5| Step: 11
Training loss: 2.6023844202414317
Validation loss: 2.5366341427469545

Epoch: 306| Step: 0
Training loss: 1.804156997455062
Validation loss: 2.5565078580424565

Epoch: 5| Step: 1
Training loss: 2.664392087354996
Validation loss: 2.579310830333824

Epoch: 5| Step: 2
Training loss: 2.029235897671746
Validation loss: 2.555365092469631

Epoch: 5| Step: 3
Training loss: 2.266449035219642
Validation loss: 2.5459154072615315

Epoch: 5| Step: 4
Training loss: 2.481065381001615
Validation loss: 2.5468709122638624

Epoch: 5| Step: 5
Training loss: 2.1845778429756773
Validation loss: 2.5394232586571976

Epoch: 5| Step: 6
Training loss: 2.248714291605538
Validation loss: 2.5410177869540767

Epoch: 5| Step: 7
Training loss: 2.9270091924180903
Validation loss: 2.5340210460088937

Epoch: 5| Step: 8
Training loss: 2.1519190097444447
Validation loss: 2.54755893253522

Epoch: 5| Step: 9
Training loss: 2.269498683676093
Validation loss: 2.5507163856908877

Epoch: 5| Step: 10
Training loss: 1.7865781901406061
Validation loss: 2.5491455893774266

Epoch: 5| Step: 11
Training loss: 1.640106046434692
Validation loss: 2.5463245553718745

Epoch: 307| Step: 0
Training loss: 1.6272438403229985
Validation loss: 2.5536941284637904

Epoch: 5| Step: 1
Training loss: 2.2506843162035928
Validation loss: 2.5490928112973164

Epoch: 5| Step: 2
Training loss: 2.8236736863805993
Validation loss: 2.5542849924538706

Epoch: 5| Step: 3
Training loss: 2.077123529726954
Validation loss: 2.550350645521922

Epoch: 5| Step: 4
Training loss: 2.0730779639386143
Validation loss: 2.5102434230452726

Epoch: 5| Step: 5
Training loss: 2.792833359644584
Validation loss: 2.503928947643413

Epoch: 5| Step: 6
Training loss: 2.2498552487753285
Validation loss: 2.4990995454397718

Epoch: 5| Step: 7
Training loss: 1.8613429834467283
Validation loss: 2.498096202117764

Epoch: 5| Step: 8
Training loss: 2.4249644601321587
Validation loss: 2.497859123596954

Epoch: 5| Step: 9
Training loss: 1.8595679687895508
Validation loss: 2.5126817873133507

Epoch: 5| Step: 10
Training loss: 2.3794279481704566
Validation loss: 2.5276344462311067

Epoch: 5| Step: 11
Training loss: 1.842536268149037
Validation loss: 2.520233095971419

Epoch: 308| Step: 0
Training loss: 2.580171454890799
Validation loss: 2.531869145404416

Epoch: 5| Step: 1
Training loss: 2.4455890925652395
Validation loss: 2.549173402358558

Epoch: 5| Step: 2
Training loss: 1.718891068651499
Validation loss: 2.555545145741514

Epoch: 5| Step: 3
Training loss: 2.1333496758709236
Validation loss: 2.5730465548596055

Epoch: 5| Step: 4
Training loss: 2.289501057038289
Validation loss: 2.5680400964202748

Epoch: 5| Step: 5
Training loss: 2.1282871851128724
Validation loss: 2.559084387563858

Epoch: 5| Step: 6
Training loss: 2.707747195469465
Validation loss: 2.578981700318539

Epoch: 5| Step: 7
Training loss: 1.8983137930293348
Validation loss: 2.568980883689429

Epoch: 5| Step: 8
Training loss: 2.466074302358345
Validation loss: 2.549970691799208

Epoch: 5| Step: 9
Training loss: 2.085641675681808
Validation loss: 2.580915874780588

Epoch: 5| Step: 10
Training loss: 1.9737635158199263
Validation loss: 2.586756934634249

Epoch: 5| Step: 11
Training loss: 1.7193467231402655
Validation loss: 2.559240221659791

Epoch: 309| Step: 0
Training loss: 1.9330300482374598
Validation loss: 2.5609136920510442

Epoch: 5| Step: 1
Training loss: 2.5430275343327993
Validation loss: 2.5420106722765015

Epoch: 5| Step: 2
Training loss: 2.0500512558646826
Validation loss: 2.55751369675256

Epoch: 5| Step: 3
Training loss: 2.2312782007994416
Validation loss: 2.5403200624997604

Epoch: 5| Step: 4
Training loss: 1.8079545475470598
Validation loss: 2.51729583144044

Epoch: 5| Step: 5
Training loss: 2.026381306426716
Validation loss: 2.4981738613244016

Epoch: 5| Step: 6
Training loss: 1.9783843317933143
Validation loss: 2.5132412723187465

Epoch: 5| Step: 7
Training loss: 2.411610070570449
Validation loss: 2.5234230600107277

Epoch: 5| Step: 8
Training loss: 2.3513341647086183
Validation loss: 2.5171613602294265

Epoch: 5| Step: 9
Training loss: 2.3059056053328737
Validation loss: 2.512401003650709

Epoch: 5| Step: 10
Training loss: 2.8816282739797328
Validation loss: 2.526448295086587

Epoch: 5| Step: 11
Training loss: 1.5613087499970602
Validation loss: 2.5311945096750614

Epoch: 310| Step: 0
Training loss: 1.8449168634679776
Validation loss: 2.5276416168697975

Epoch: 5| Step: 1
Training loss: 2.571252343784538
Validation loss: 2.554076453187573

Epoch: 5| Step: 2
Training loss: 2.4148313415267784
Validation loss: 2.5358973489161603

Epoch: 5| Step: 3
Training loss: 2.340660907790791
Validation loss: 2.557121746428827

Epoch: 5| Step: 4
Training loss: 2.34512360057969
Validation loss: 2.570379258267669

Epoch: 5| Step: 5
Training loss: 2.555426814342507
Validation loss: 2.583856992304146

Epoch: 5| Step: 6
Training loss: 1.920000728567303
Validation loss: 2.5744425898680494

Epoch: 5| Step: 7
Training loss: 2.3716088227299497
Validation loss: 2.574994114680802

Epoch: 5| Step: 8
Training loss: 1.6953703699035354
Validation loss: 2.5733873822184905

Epoch: 5| Step: 9
Training loss: 1.9819117599153036
Validation loss: 2.565884899600203

Epoch: 5| Step: 10
Training loss: 2.2856739990055943
Validation loss: 2.564472551894466

Epoch: 5| Step: 11
Training loss: 1.7922597908798714
Validation loss: 2.5448257572567545

Epoch: 311| Step: 0
Training loss: 2.041471264369962
Validation loss: 2.556103048787452

Epoch: 5| Step: 1
Training loss: 2.5522130712631945
Validation loss: 2.5583616428072222

Epoch: 5| Step: 2
Training loss: 1.815468100828302
Validation loss: 2.58321215873495

Epoch: 5| Step: 3
Training loss: 1.9922408152907192
Validation loss: 2.5663120595058757

Epoch: 5| Step: 4
Training loss: 2.3375795646630664
Validation loss: 2.554251630737943

Epoch: 5| Step: 5
Training loss: 1.622939049987135
Validation loss: 2.5467981549236995

Epoch: 5| Step: 6
Training loss: 2.5329363821468984
Validation loss: 2.5543459548275798

Epoch: 5| Step: 7
Training loss: 1.692912569684983
Validation loss: 2.5315644104275465

Epoch: 5| Step: 8
Training loss: 2.015280287490054
Validation loss: 2.5237136469265384

Epoch: 5| Step: 9
Training loss: 2.8236963994653816
Validation loss: 2.5376304970307437

Epoch: 5| Step: 10
Training loss: 2.5557961581022104
Validation loss: 2.5347466101119123

Epoch: 5| Step: 11
Training loss: 1.9983716534823783
Validation loss: 2.5264876663427365

Epoch: 312| Step: 0
Training loss: 2.089834280972999
Validation loss: 2.532467188388797

Epoch: 5| Step: 1
Training loss: 2.7067801398965754
Validation loss: 2.5407550080941386

Epoch: 5| Step: 2
Training loss: 2.100047306254571
Validation loss: 2.5550453487584597

Epoch: 5| Step: 3
Training loss: 1.5698975731306357
Validation loss: 2.5373154562129754

Epoch: 5| Step: 4
Training loss: 2.558320148777822
Validation loss: 2.5440052184057897

Epoch: 5| Step: 5
Training loss: 2.2148638796690525
Validation loss: 2.520549329937733

Epoch: 5| Step: 6
Training loss: 2.7226191207565162
Validation loss: 2.5543696743398066

Epoch: 5| Step: 7
Training loss: 1.9137715021142643
Validation loss: 2.5448946869637967

Epoch: 5| Step: 8
Training loss: 1.7981283709322426
Validation loss: 2.5678235480179303

Epoch: 5| Step: 9
Training loss: 2.2818132515135225
Validation loss: 2.534742720330905

Epoch: 5| Step: 10
Training loss: 2.062936216521262
Validation loss: 2.582450430619901

Epoch: 5| Step: 11
Training loss: 1.3656102701261303
Validation loss: 2.563508242456776

Epoch: 313| Step: 0
Training loss: 2.357302633460327
Validation loss: 2.5664565353847615

Epoch: 5| Step: 1
Training loss: 1.8646802468571948
Validation loss: 2.5788729074120287

Epoch: 5| Step: 2
Training loss: 2.2456107242171868
Validation loss: 2.5958640357498517

Epoch: 5| Step: 3
Training loss: 2.5419600166339698
Validation loss: 2.5845245350355595

Epoch: 5| Step: 4
Training loss: 2.305071472251457
Validation loss: 2.576584997593622

Epoch: 5| Step: 5
Training loss: 1.6883713627128822
Validation loss: 2.55152617750071

Epoch: 5| Step: 6
Training loss: 2.3475351921263043
Validation loss: 2.555316878629894

Epoch: 5| Step: 7
Training loss: 1.6730195878017127
Validation loss: 2.5590469153171878

Epoch: 5| Step: 8
Training loss: 2.5497311917907397
Validation loss: 2.555018105147253

Epoch: 5| Step: 9
Training loss: 2.332928304487078
Validation loss: 2.5722291442246075

Epoch: 5| Step: 10
Training loss: 2.011137824762194
Validation loss: 2.5534817652961608

Epoch: 5| Step: 11
Training loss: 2.105769148365337
Validation loss: 2.5578755115599927

Epoch: 314| Step: 0
Training loss: 2.1907002608884314
Validation loss: 2.5611584726130014

Epoch: 5| Step: 1
Training loss: 1.5290166176640774
Validation loss: 2.552523623004415

Epoch: 5| Step: 2
Training loss: 2.6990799819894233
Validation loss: 2.552155016197312

Epoch: 5| Step: 3
Training loss: 2.2554287586161688
Validation loss: 2.554901629309797

Epoch: 5| Step: 4
Training loss: 2.1693027550469295
Validation loss: 2.554346367072172

Epoch: 5| Step: 5
Training loss: 2.3319247171934423
Validation loss: 2.554481260819444

Epoch: 5| Step: 6
Training loss: 2.4327312673973176
Validation loss: 2.5670696312748627

Epoch: 5| Step: 7
Training loss: 1.8679534745559025
Validation loss: 2.5452808586575264

Epoch: 5| Step: 8
Training loss: 1.9183847632696285
Validation loss: 2.5377757837108526

Epoch: 5| Step: 9
Training loss: 1.972124749522566
Validation loss: 2.5468642462754962

Epoch: 5| Step: 10
Training loss: 2.4032471981653285
Validation loss: 2.528906111805114

Epoch: 5| Step: 11
Training loss: 2.06446074716249
Validation loss: 2.5448699110517286

Epoch: 315| Step: 0
Training loss: 2.1007567495419
Validation loss: 2.527425360799118

Epoch: 5| Step: 1
Training loss: 2.2311653612683506
Validation loss: 2.5223939428664366

Epoch: 5| Step: 2
Training loss: 2.0765929346889695
Validation loss: 2.510995051656729

Epoch: 5| Step: 3
Training loss: 2.56370385897074
Validation loss: 2.5135399211482787

Epoch: 5| Step: 4
Training loss: 2.332480229235693
Validation loss: 2.5088301007240634

Epoch: 5| Step: 5
Training loss: 2.320212930411765
Validation loss: 2.4987195610207564

Epoch: 5| Step: 6
Training loss: 2.1932307789063685
Validation loss: 2.502973873895932

Epoch: 5| Step: 7
Training loss: 2.262025380802518
Validation loss: 2.513007023959521

Epoch: 5| Step: 8
Training loss: 2.3111392992493265
Validation loss: 2.518202194074676

Epoch: 5| Step: 9
Training loss: 2.007922692744684
Validation loss: 2.5415845464249522

Epoch: 5| Step: 10
Training loss: 1.8712067062272435
Validation loss: 2.5395196278201557

Epoch: 5| Step: 11
Training loss: 1.105826060643221
Validation loss: 2.57153465951586

Epoch: 316| Step: 0
Training loss: 2.1330365073812705
Validation loss: 2.5713666978303675

Epoch: 5| Step: 1
Training loss: 1.925528364619938
Validation loss: 2.6089140433483897

Epoch: 5| Step: 2
Training loss: 2.162573898023002
Validation loss: 2.587992939395992

Epoch: 5| Step: 3
Training loss: 1.9348536230508644
Validation loss: 2.6070001534968092

Epoch: 5| Step: 4
Training loss: 2.4102472569426583
Validation loss: 2.6166615237551967

Epoch: 5| Step: 5
Training loss: 2.0326315069880923
Validation loss: 2.584761280034832

Epoch: 5| Step: 6
Training loss: 1.8808402340747876
Validation loss: 2.555448160270297

Epoch: 5| Step: 7
Training loss: 3.2019557400467393
Validation loss: 2.5474340628749874

Epoch: 5| Step: 8
Training loss: 1.8607162638748653
Validation loss: 2.529334623037927

Epoch: 5| Step: 9
Training loss: 2.5099882865723635
Validation loss: 2.5235025143589094

Epoch: 5| Step: 10
Training loss: 1.9239027909249555
Validation loss: 2.5339499269577233

Epoch: 5| Step: 11
Training loss: 0.6725978511399384
Validation loss: 2.5479914123746257

Epoch: 317| Step: 0
Training loss: 2.3032877146412334
Validation loss: 2.5741720701856408

Epoch: 5| Step: 1
Training loss: 2.0214572480818767
Validation loss: 2.558263354529999

Epoch: 5| Step: 2
Training loss: 2.3131875742890404
Validation loss: 2.5534392407450697

Epoch: 5| Step: 3
Training loss: 1.9685793605908022
Validation loss: 2.562938551863337

Epoch: 5| Step: 4
Training loss: 2.0966553528949965
Validation loss: 2.566036327377463

Epoch: 5| Step: 5
Training loss: 2.2988139162621106
Validation loss: 2.5551134584595845

Epoch: 5| Step: 6
Training loss: 2.0168050224616927
Validation loss: 2.546647180614601

Epoch: 5| Step: 7
Training loss: 2.4029647396705798
Validation loss: 2.5409354828402058

Epoch: 5| Step: 8
Training loss: 2.286428661342178
Validation loss: 2.5117137942505035

Epoch: 5| Step: 9
Training loss: 2.5628768829828483
Validation loss: 2.5293718520825847

Epoch: 5| Step: 10
Training loss: 1.9427556772744305
Validation loss: 2.5682845188154184

Epoch: 5| Step: 11
Training loss: 1.217366827509916
Validation loss: 2.576462820579792

Epoch: 318| Step: 0
Training loss: 2.060268929343512
Validation loss: 2.606336907478448

Epoch: 5| Step: 1
Training loss: 2.508547095973054
Validation loss: 2.6036536639689047

Epoch: 5| Step: 2
Training loss: 2.3009277711595515
Validation loss: 2.588902311447745

Epoch: 5| Step: 3
Training loss: 2.402562077223419
Validation loss: 2.6076651356123

Epoch: 5| Step: 4
Training loss: 2.246357300264782
Validation loss: 2.5892993514010354

Epoch: 5| Step: 5
Training loss: 2.053258130360169
Validation loss: 2.5887135666709176

Epoch: 5| Step: 6
Training loss: 1.6206077490615547
Validation loss: 2.5899446754487196

Epoch: 5| Step: 7
Training loss: 1.6540233831863065
Validation loss: 2.5825165308435256

Epoch: 5| Step: 8
Training loss: 1.9690956538898994
Validation loss: 2.570200317624688

Epoch: 5| Step: 9
Training loss: 2.3900450956806667
Validation loss: 2.5753113970379804

Epoch: 5| Step: 10
Training loss: 2.4968401967321774
Validation loss: 2.5629489164308463

Epoch: 5| Step: 11
Training loss: 1.9914348302431262
Validation loss: 2.514543853856496

Epoch: 319| Step: 0
Training loss: 3.148749627101584
Validation loss: 2.535680431609137

Epoch: 5| Step: 1
Training loss: 1.765070735389303
Validation loss: 2.5260979767386074

Epoch: 5| Step: 2
Training loss: 1.6657759750106644
Validation loss: 2.5451835893958883

Epoch: 5| Step: 3
Training loss: 1.6381589248096016
Validation loss: 2.548193549309447

Epoch: 5| Step: 4
Training loss: 2.0029375437894434
Validation loss: 2.5509990620563396

Epoch: 5| Step: 5
Training loss: 2.332767849473791
Validation loss: 2.591445592413505

Epoch: 5| Step: 6
Training loss: 1.527922849799549
Validation loss: 2.6001111813762074

Epoch: 5| Step: 7
Training loss: 2.583943038690533
Validation loss: 2.589095474091508

Epoch: 5| Step: 8
Training loss: 2.1517788514376623
Validation loss: 2.585300090404502

Epoch: 5| Step: 9
Training loss: 2.587532220169921
Validation loss: 2.5801854694838564

Epoch: 5| Step: 10
Training loss: 2.2460974651803514
Validation loss: 2.5711053052650477

Epoch: 5| Step: 11
Training loss: 1.7269112765477765
Validation loss: 2.546351416036195

Epoch: 320| Step: 0
Training loss: 2.078695577435499
Validation loss: 2.5399057328135393

Epoch: 5| Step: 1
Training loss: 2.06235249309766
Validation loss: 2.546436338346597

Epoch: 5| Step: 2
Training loss: 1.963486492754563
Validation loss: 2.5638380937709613

Epoch: 5| Step: 3
Training loss: 1.831782407473682
Validation loss: 2.5814858734453145

Epoch: 5| Step: 4
Training loss: 1.5133142848783574
Validation loss: 2.5832842942679863

Epoch: 5| Step: 5
Training loss: 2.297918173638752
Validation loss: 2.5567945526777986

Epoch: 5| Step: 6
Training loss: 2.432852005928734
Validation loss: 2.5700141865033213

Epoch: 5| Step: 7
Training loss: 2.6132255970227787
Validation loss: 2.5529261475425344

Epoch: 5| Step: 8
Training loss: 1.9577944061344348
Validation loss: 2.5240000205087836

Epoch: 5| Step: 9
Training loss: 2.1830071222570933
Validation loss: 2.5244066524827273

Epoch: 5| Step: 10
Training loss: 2.6461400332371845
Validation loss: 2.5042431148997895

Epoch: 5| Step: 11
Training loss: 2.9549942155965354
Validation loss: 2.5063367167475072

Epoch: 321| Step: 0
Training loss: 2.6611650657449104
Validation loss: 2.505075190780494

Epoch: 5| Step: 1
Training loss: 2.619776023580414
Validation loss: 2.491804565857953

Epoch: 5| Step: 2
Training loss: 2.281890152249041
Validation loss: 2.531795319344153

Epoch: 5| Step: 3
Training loss: 1.719057367757859
Validation loss: 2.519199584106937

Epoch: 5| Step: 4
Training loss: 1.6245953716345047
Validation loss: 2.5170179700287

Epoch: 5| Step: 5
Training loss: 2.0487920505195185
Validation loss: 2.5312624448305487

Epoch: 5| Step: 6
Training loss: 2.217613573918215
Validation loss: 2.5249045942556285

Epoch: 5| Step: 7
Training loss: 2.4693636554060605
Validation loss: 2.5255876165837803

Epoch: 5| Step: 8
Training loss: 2.549085067718337
Validation loss: 2.52266074903112

Epoch: 5| Step: 9
Training loss: 1.8106746690209983
Validation loss: 2.538774131636422

Epoch: 5| Step: 10
Training loss: 1.7614421754257998
Validation loss: 2.546933834589923

Epoch: 5| Step: 11
Training loss: 1.1562358236732564
Validation loss: 2.539241937018916

Epoch: 322| Step: 0
Training loss: 2.7326071119473765
Validation loss: 2.5578143614410918

Epoch: 5| Step: 1
Training loss: 2.115711556358634
Validation loss: 2.541062640244595

Epoch: 5| Step: 2
Training loss: 2.3055834047200734
Validation loss: 2.5687838166200625

Epoch: 5| Step: 3
Training loss: 1.8553359455967966
Validation loss: 2.5570676683473703

Epoch: 5| Step: 4
Training loss: 1.7828216980438596
Validation loss: 2.540245586497425

Epoch: 5| Step: 5
Training loss: 2.2844733888909237
Validation loss: 2.5717957612288282

Epoch: 5| Step: 6
Training loss: 1.8358358801455963
Validation loss: 2.555347991083577

Epoch: 5| Step: 7
Training loss: 2.321510185651517
Validation loss: 2.552224148868274

Epoch: 5| Step: 8
Training loss: 2.1505310955127652
Validation loss: 2.5602407885972016

Epoch: 5| Step: 9
Training loss: 2.47166193876974
Validation loss: 2.557965239770847

Epoch: 5| Step: 10
Training loss: 2.1006262299642735
Validation loss: 2.5720099628892297

Epoch: 5| Step: 11
Training loss: 2.0541164054163854
Validation loss: 2.5788132336534892

Epoch: 323| Step: 0
Training loss: 2.2933225602443996
Validation loss: 2.5959745848317284

Epoch: 5| Step: 1
Training loss: 2.3859797206058424
Validation loss: 2.592838468053398

Epoch: 5| Step: 2
Training loss: 2.0099926700743067
Validation loss: 2.5947350006674594

Epoch: 5| Step: 3
Training loss: 1.8957466552817555
Validation loss: 2.5882855326360614

Epoch: 5| Step: 4
Training loss: 2.031985809862346
Validation loss: 2.5849704067324355

Epoch: 5| Step: 5
Training loss: 2.247122089663143
Validation loss: 2.574483276112836

Epoch: 5| Step: 6
Training loss: 2.0388157720849724
Validation loss: 2.574754098767892

Epoch: 5| Step: 7
Training loss: 2.5858939821206084
Validation loss: 2.553562352056057

Epoch: 5| Step: 8
Training loss: 2.5003807731569014
Validation loss: 2.5613391154002403

Epoch: 5| Step: 9
Training loss: 2.130106008694489
Validation loss: 2.5353347997579245

Epoch: 5| Step: 10
Training loss: 2.0244006364876785
Validation loss: 2.5393056547670785

Epoch: 5| Step: 11
Training loss: 1.7330801314259416
Validation loss: 2.5547268210212954

Epoch: 324| Step: 0
Training loss: 1.9788142710385295
Validation loss: 2.5619879323384547

Epoch: 5| Step: 1
Training loss: 2.2880424856829653
Validation loss: 2.5661053648082297

Epoch: 5| Step: 2
Training loss: 1.7471149368514884
Validation loss: 2.577222346259955

Epoch: 5| Step: 3
Training loss: 1.9148844297112009
Validation loss: 2.580271133954281

Epoch: 5| Step: 4
Training loss: 2.3238222441131566
Validation loss: 2.564631668697202

Epoch: 5| Step: 5
Training loss: 2.4854590971640507
Validation loss: 2.5887150632833045

Epoch: 5| Step: 6
Training loss: 2.208839310555097
Validation loss: 2.590194501950102

Epoch: 5| Step: 7
Training loss: 2.15077066138308
Validation loss: 2.5776627636765697

Epoch: 5| Step: 8
Training loss: 2.7414498491752886
Validation loss: 2.5683779368920407

Epoch: 5| Step: 9
Training loss: 2.203893324615645
Validation loss: 2.557394924267501

Epoch: 5| Step: 10
Training loss: 1.892637395570385
Validation loss: 2.5396242195282532

Epoch: 5| Step: 11
Training loss: 1.7672980155082807
Validation loss: 2.5505340986093175

Epoch: 325| Step: 0
Training loss: 2.463562452512211
Validation loss: 2.5459982137049493

Epoch: 5| Step: 1
Training loss: 2.3132115893067535
Validation loss: 2.589409939051953

Epoch: 5| Step: 2
Training loss: 2.3887329592813082
Validation loss: 2.61521758154144

Epoch: 5| Step: 3
Training loss: 2.4038200494375874
Validation loss: 2.6364736259395736

Epoch: 5| Step: 4
Training loss: 2.4181154665706037
Validation loss: 2.613908218266601

Epoch: 5| Step: 5
Training loss: 2.5069901018103264
Validation loss: 2.6149760834042097

Epoch: 5| Step: 6
Training loss: 2.287891700435657
Validation loss: 2.607374939990191

Epoch: 5| Step: 7
Training loss: 1.929166345067612
Validation loss: 2.5857272912645275

Epoch: 5| Step: 8
Training loss: 2.0318704684490645
Validation loss: 2.5426548667911297

Epoch: 5| Step: 9
Training loss: 1.5648766562267746
Validation loss: 2.5332535930107243

Epoch: 5| Step: 10
Training loss: 2.0146522244571776
Validation loss: 2.4993223185741273

Epoch: 5| Step: 11
Training loss: 2.2655253421306463
Validation loss: 2.495663147560017

Epoch: 326| Step: 0
Training loss: 2.5014891004307764
Validation loss: 2.4851372467149107

Epoch: 5| Step: 1
Training loss: 1.7242790069905636
Validation loss: 2.506134057791798

Epoch: 5| Step: 2
Training loss: 2.517240775436668
Validation loss: 2.5101155018637917

Epoch: 5| Step: 3
Training loss: 2.413171992818798
Validation loss: 2.489121052320122

Epoch: 5| Step: 4
Training loss: 1.5949835397953227
Validation loss: 2.5047288794063163

Epoch: 5| Step: 5
Training loss: 2.213513386863622
Validation loss: 2.4986857695066433

Epoch: 5| Step: 6
Training loss: 2.050371517848913
Validation loss: 2.5096885263596613

Epoch: 5| Step: 7
Training loss: 1.9576326158211124
Validation loss: 2.50452363510794

Epoch: 5| Step: 8
Training loss: 2.796206090630971
Validation loss: 2.491757589986249

Epoch: 5| Step: 9
Training loss: 1.9368360058434204
Validation loss: 2.50907382163232

Epoch: 5| Step: 10
Training loss: 2.5476329588329887
Validation loss: 2.522950636248876

Epoch: 5| Step: 11
Training loss: 1.225238498514674
Validation loss: 2.536313114800417

Epoch: 327| Step: 0
Training loss: 1.9293804464952253
Validation loss: 2.5348550689117864

Epoch: 5| Step: 1
Training loss: 2.35692565297049
Validation loss: 2.5678785504967108

Epoch: 5| Step: 2
Training loss: 2.329723142457427
Validation loss: 2.5492272776988023

Epoch: 5| Step: 3
Training loss: 2.2304890593290567
Validation loss: 2.544354867214436

Epoch: 5| Step: 4
Training loss: 2.4568884099974273
Validation loss: 2.5262823888120267

Epoch: 5| Step: 5
Training loss: 2.419850641638474
Validation loss: 2.5229188565203495

Epoch: 5| Step: 6
Training loss: 1.5405088493095473
Validation loss: 2.521004091080566

Epoch: 5| Step: 7
Training loss: 2.1855565838772844
Validation loss: 2.5573670103598207

Epoch: 5| Step: 8
Training loss: 2.2780996020331172
Validation loss: 2.5349823628074764

Epoch: 5| Step: 9
Training loss: 2.5250973748797314
Validation loss: 2.538389177298795

Epoch: 5| Step: 10
Training loss: 1.46080326544803
Validation loss: 2.519012894647781

Epoch: 5| Step: 11
Training loss: 1.86155681666233
Validation loss: 2.5203366000368685

Epoch: 328| Step: 0
Training loss: 1.7815697366286134
Validation loss: 2.5166059283533344

Epoch: 5| Step: 1
Training loss: 2.516182689571849
Validation loss: 2.5309072074014596

Epoch: 5| Step: 2
Training loss: 2.3176873252573764
Validation loss: 2.522661501179122

Epoch: 5| Step: 3
Training loss: 2.239322653096608
Validation loss: 2.537917226086646

Epoch: 5| Step: 4
Training loss: 1.9652580294685853
Validation loss: 2.5336507040564933

Epoch: 5| Step: 5
Training loss: 2.1382154282462587
Validation loss: 2.530135191803461

Epoch: 5| Step: 6
Training loss: 1.8246995182102153
Validation loss: 2.516254618735701

Epoch: 5| Step: 7
Training loss: 2.0546901688358976
Validation loss: 2.528768571152804

Epoch: 5| Step: 8
Training loss: 1.8096571364677352
Validation loss: 2.5496755854867525

Epoch: 5| Step: 9
Training loss: 2.383818667242426
Validation loss: 2.5305647413045427

Epoch: 5| Step: 10
Training loss: 2.1172540520487257
Validation loss: 2.532367934304141

Epoch: 5| Step: 11
Training loss: 3.3062275934451644
Validation loss: 2.5502863039156902

Epoch: 329| Step: 0
Training loss: 1.9519967444345812
Validation loss: 2.528939805914483

Epoch: 5| Step: 1
Training loss: 1.43064256463157
Validation loss: 2.514880877865908

Epoch: 5| Step: 2
Training loss: 2.7265710693924254
Validation loss: 2.5341508553787446

Epoch: 5| Step: 3
Training loss: 2.3369257950956523
Validation loss: 2.5410638130734355

Epoch: 5| Step: 4
Training loss: 2.08228201724767
Validation loss: 2.54456955956337

Epoch: 5| Step: 5
Training loss: 2.468191832204852
Validation loss: 2.543574345559172

Epoch: 5| Step: 6
Training loss: 1.956172061622922
Validation loss: 2.536242114857461

Epoch: 5| Step: 7
Training loss: 1.7555559381988903
Validation loss: 2.5663277330005068

Epoch: 5| Step: 8
Training loss: 2.2526096468879024
Validation loss: 2.565957617097986

Epoch: 5| Step: 9
Training loss: 1.730714113221858
Validation loss: 2.575152245745977

Epoch: 5| Step: 10
Training loss: 2.324356100688188
Validation loss: 2.5279744033063354

Epoch: 5| Step: 11
Training loss: 2.2616594007015056
Validation loss: 2.53287700670555

Epoch: 330| Step: 0
Training loss: 1.342396520252969
Validation loss: 2.526503476798356

Epoch: 5| Step: 1
Training loss: 2.4309281986920235
Validation loss: 2.5010137092227813

Epoch: 5| Step: 2
Training loss: 1.733802288452321
Validation loss: 2.498454713076234

Epoch: 5| Step: 3
Training loss: 2.344682228339715
Validation loss: 2.5114553539860216

Epoch: 5| Step: 4
Training loss: 1.9007663335814609
Validation loss: 2.5045963274725973

Epoch: 5| Step: 5
Training loss: 2.3772199194201797
Validation loss: 2.5122741314595833

Epoch: 5| Step: 6
Training loss: 1.9261292303745539
Validation loss: 2.5276977314751985

Epoch: 5| Step: 7
Training loss: 1.991634336977954
Validation loss: 2.531942139489241

Epoch: 5| Step: 8
Training loss: 2.3512439195147694
Validation loss: 2.5429227622659845

Epoch: 5| Step: 9
Training loss: 2.0112389446023453
Validation loss: 2.5580065997500627

Epoch: 5| Step: 10
Training loss: 2.4832382000445308
Validation loss: 2.570783759359948

Epoch: 5| Step: 11
Training loss: 2.6426382121425323
Validation loss: 2.5825455307801253

Epoch: 331| Step: 0
Training loss: 1.9763649702318882
Validation loss: 2.59943699808579

Epoch: 5| Step: 1
Training loss: 1.8359871715562892
Validation loss: 2.577927290916798

Epoch: 5| Step: 2
Training loss: 2.5832926429087064
Validation loss: 2.5707327509781823

Epoch: 5| Step: 3
Training loss: 1.567191595374525
Validation loss: 2.532431707324377

Epoch: 5| Step: 4
Training loss: 2.0367528469917513
Validation loss: 2.543394901724907

Epoch: 5| Step: 5
Training loss: 1.603564169888843
Validation loss: 2.5541170321294064

Epoch: 5| Step: 6
Training loss: 2.313720071971035
Validation loss: 2.51509020434088

Epoch: 5| Step: 7
Training loss: 2.0054067009903385
Validation loss: 2.5290905567597175

Epoch: 5| Step: 8
Training loss: 2.764395488996859
Validation loss: 2.5265798224879776

Epoch: 5| Step: 9
Training loss: 2.3705743412445313
Validation loss: 2.5356508153676782

Epoch: 5| Step: 10
Training loss: 1.9911065853028198
Validation loss: 2.557441463602285

Epoch: 5| Step: 11
Training loss: 2.2419454729730113
Validation loss: 2.541056959835915

Epoch: 332| Step: 0
Training loss: 2.053116810867955
Validation loss: 2.5796584298867877

Epoch: 5| Step: 1
Training loss: 2.4285114545389033
Validation loss: 2.609972887202854

Epoch: 5| Step: 2
Training loss: 1.7119847406571829
Validation loss: 2.6164797988506385

Epoch: 5| Step: 3
Training loss: 1.9484020043316006
Validation loss: 2.6475515843746162

Epoch: 5| Step: 4
Training loss: 2.30731103571791
Validation loss: 2.665058956442415

Epoch: 5| Step: 5
Training loss: 2.677277752141039
Validation loss: 2.6287257305892697

Epoch: 5| Step: 6
Training loss: 2.0741624267747314
Validation loss: 2.6240426543042847

Epoch: 5| Step: 7
Training loss: 1.9249074938456865
Validation loss: 2.581164762430438

Epoch: 5| Step: 8
Training loss: 2.256227563973672
Validation loss: 2.5370583826451294

Epoch: 5| Step: 9
Training loss: 1.9964222497740052
Validation loss: 2.5207026949573312

Epoch: 5| Step: 10
Training loss: 1.7817219560690167
Validation loss: 2.499935498994991

Epoch: 5| Step: 11
Training loss: 2.1219830132972137
Validation loss: 2.49390465823275

Epoch: 333| Step: 0
Training loss: 2.2257514413355275
Validation loss: 2.487678362970902

Epoch: 5| Step: 1
Training loss: 2.347615830363882
Validation loss: 2.469992654849983

Epoch: 5| Step: 2
Training loss: 1.9717081643211944
Validation loss: 2.4736935677981933

Epoch: 5| Step: 3
Training loss: 2.35790110649731
Validation loss: 2.474557881570978

Epoch: 5| Step: 4
Training loss: 2.5280814413460595
Validation loss: 2.4638466831018846

Epoch: 5| Step: 5
Training loss: 1.87313527524139
Validation loss: 2.4960696279427785

Epoch: 5| Step: 6
Training loss: 2.6974138554773064
Validation loss: 2.4792861201788954

Epoch: 5| Step: 7
Training loss: 1.912548914763786
Validation loss: 2.498448577945365

Epoch: 5| Step: 8
Training loss: 1.603406858298266
Validation loss: 2.4996029737243224

Epoch: 5| Step: 9
Training loss: 1.693355784692885
Validation loss: 2.5495351344281976

Epoch: 5| Step: 10
Training loss: 2.196681128856111
Validation loss: 2.562668108659455

Epoch: 5| Step: 11
Training loss: 1.5368474521471753
Validation loss: 2.5830912220208817

Epoch: 334| Step: 0
Training loss: 2.1460709177975246
Validation loss: 2.6035402854367744

Epoch: 5| Step: 1
Training loss: 2.6700771596382062
Validation loss: 2.5839447533608615

Epoch: 5| Step: 2
Training loss: 2.1266377813396526
Validation loss: 2.5825837275733394

Epoch: 5| Step: 3
Training loss: 1.8252917121914312
Validation loss: 2.577131538485077

Epoch: 5| Step: 4
Training loss: 2.337656874670936
Validation loss: 2.535472280027697

Epoch: 5| Step: 5
Training loss: 1.5991531485336887
Validation loss: 2.532159178916486

Epoch: 5| Step: 6
Training loss: 2.261179383684584
Validation loss: 2.535199710138394

Epoch: 5| Step: 7
Training loss: 1.9662241400141578
Validation loss: 2.519195301615807

Epoch: 5| Step: 8
Training loss: 2.3841686954465215
Validation loss: 2.521799309660998

Epoch: 5| Step: 9
Training loss: 1.898751440895242
Validation loss: 2.5062005199073023

Epoch: 5| Step: 10
Training loss: 2.0475816744396247
Validation loss: 2.5169547537150807

Epoch: 5| Step: 11
Training loss: 1.745312338805981
Validation loss: 2.53375654565072

Epoch: 335| Step: 0
Training loss: 1.8763509334123463
Validation loss: 2.5646492465918076

Epoch: 5| Step: 1
Training loss: 1.9128430900252889
Validation loss: 2.5382072260254027

Epoch: 5| Step: 2
Training loss: 1.8227453387447659
Validation loss: 2.552363739698255

Epoch: 5| Step: 3
Training loss: 2.266641112725816
Validation loss: 2.5683991635797825

Epoch: 5| Step: 4
Training loss: 2.02369281822318
Validation loss: 2.5397179799194722

Epoch: 5| Step: 5
Training loss: 1.895200819481656
Validation loss: 2.5423287730478883

Epoch: 5| Step: 6
Training loss: 2.4862698220776096
Validation loss: 2.5562252973064

Epoch: 5| Step: 7
Training loss: 2.1626802843388724
Validation loss: 2.5559513725939387

Epoch: 5| Step: 8
Training loss: 2.168980707655249
Validation loss: 2.5710784636554735

Epoch: 5| Step: 9
Training loss: 2.0925421575859384
Validation loss: 2.550757041454083

Epoch: 5| Step: 10
Training loss: 2.0556860988278496
Validation loss: 2.57227092366794

Epoch: 5| Step: 11
Training loss: 2.3975001190153695
Validation loss: 2.550887077905241

Epoch: 336| Step: 0
Training loss: 1.657637320996609
Validation loss: 2.5515907993059375

Epoch: 5| Step: 1
Training loss: 2.011286124218561
Validation loss: 2.558451221951591

Epoch: 5| Step: 2
Training loss: 1.5659998035844898
Validation loss: 2.554590108650202

Epoch: 5| Step: 3
Training loss: 2.069954895228403
Validation loss: 2.5446783785145315

Epoch: 5| Step: 4
Training loss: 1.7709145770416106
Validation loss: 2.5618437802926084

Epoch: 5| Step: 5
Training loss: 1.7975414864497044
Validation loss: 2.553894919386552

Epoch: 5| Step: 6
Training loss: 2.516586783280235
Validation loss: 2.538021785976754

Epoch: 5| Step: 7
Training loss: 2.309517870704832
Validation loss: 2.541397488259692

Epoch: 5| Step: 8
Training loss: 1.8913649695144759
Validation loss: 2.5625142042805313

Epoch: 5| Step: 9
Training loss: 2.435041508252297
Validation loss: 2.55969617937551

Epoch: 5| Step: 10
Training loss: 2.683772585044889
Validation loss: 2.557659613456614

Epoch: 5| Step: 11
Training loss: 2.5692433275665265
Validation loss: 2.5527011564662323

Epoch: 337| Step: 0
Training loss: 2.111874378268604
Validation loss: 2.561362576229958

Epoch: 5| Step: 1
Training loss: 1.9776024777640713
Validation loss: 2.5944523990131594

Epoch: 5| Step: 2
Training loss: 1.8715581456985815
Validation loss: 2.5840800780135447

Epoch: 5| Step: 3
Training loss: 2.461459731140472
Validation loss: 2.5843159719212263

Epoch: 5| Step: 4
Training loss: 2.315089142403413
Validation loss: 2.5966998679687316

Epoch: 5| Step: 5
Training loss: 2.385785758658615
Validation loss: 2.5920456951552193

Epoch: 5| Step: 6
Training loss: 1.9800338719100572
Validation loss: 2.5716260666731676

Epoch: 5| Step: 7
Training loss: 1.9418104890704107
Validation loss: 2.5740110229591098

Epoch: 5| Step: 8
Training loss: 2.2182885348264945
Validation loss: 2.598498360415635

Epoch: 5| Step: 9
Training loss: 1.852275598399314
Validation loss: 2.595870648621556

Epoch: 5| Step: 10
Training loss: 1.9774951166992079
Validation loss: 2.5750779458010764

Epoch: 5| Step: 11
Training loss: 1.0557512923062704
Validation loss: 2.558326019955929

Epoch: 338| Step: 0
Training loss: 1.9857695477745891
Validation loss: 2.590132757126641

Epoch: 5| Step: 1
Training loss: 2.254855215664549
Validation loss: 2.5617221101267855

Epoch: 5| Step: 2
Training loss: 1.961743557680844
Validation loss: 2.55486932937645

Epoch: 5| Step: 3
Training loss: 1.8358292568032812
Validation loss: 2.53439031471677

Epoch: 5| Step: 4
Training loss: 2.1374616429863806
Validation loss: 2.553825318477908

Epoch: 5| Step: 5
Training loss: 1.9656153352678734
Validation loss: 2.5566293333934462

Epoch: 5| Step: 6
Training loss: 2.30717391035802
Validation loss: 2.5695507849490724

Epoch: 5| Step: 7
Training loss: 1.682798689109921
Validation loss: 2.573862910820822

Epoch: 5| Step: 8
Training loss: 1.711168108165611
Validation loss: 2.5618462852971415

Epoch: 5| Step: 9
Training loss: 2.5638972869033827
Validation loss: 2.560012554070243

Epoch: 5| Step: 10
Training loss: 2.459894837403417
Validation loss: 2.565135172674289

Epoch: 5| Step: 11
Training loss: 1.7612710117361912
Validation loss: 2.5542906317775804

Epoch: 339| Step: 0
Training loss: 1.4857560810168142
Validation loss: 2.527902222080648

Epoch: 5| Step: 1
Training loss: 2.0828861392397005
Validation loss: 2.537459093149372

Epoch: 5| Step: 2
Training loss: 2.450341753576441
Validation loss: 2.538712685769561

Epoch: 5| Step: 3
Training loss: 1.6828978620465387
Validation loss: 2.5324483064049534

Epoch: 5| Step: 4
Training loss: 2.2606677312928127
Validation loss: 2.5344792007116625

Epoch: 5| Step: 5
Training loss: 2.1249077720823455
Validation loss: 2.555848727796088

Epoch: 5| Step: 6
Training loss: 2.24006387449202
Validation loss: 2.516756154884054

Epoch: 5| Step: 7
Training loss: 2.072061512464818
Validation loss: 2.555808988705433

Epoch: 5| Step: 8
Training loss: 2.5713523917796994
Validation loss: 2.5971096754479857

Epoch: 5| Step: 9
Training loss: 2.099263007404115
Validation loss: 2.6014935901515712

Epoch: 5| Step: 10
Training loss: 1.791438694430119
Validation loss: 2.6015486158395698

Epoch: 5| Step: 11
Training loss: 1.4637712545179244
Validation loss: 2.62188404825837

Epoch: 340| Step: 0
Training loss: 2.3723784584612333
Validation loss: 2.6313564639930083

Epoch: 5| Step: 1
Training loss: 2.2010830554118783
Validation loss: 2.580263141290734

Epoch: 5| Step: 2
Training loss: 2.3322105658263474
Validation loss: 2.5651459524298024

Epoch: 5| Step: 3
Training loss: 1.857188437761856
Validation loss: 2.542030235510889

Epoch: 5| Step: 4
Training loss: 2.0531648861336245
Validation loss: 2.5520489469793675

Epoch: 5| Step: 5
Training loss: 1.7305441811958107
Validation loss: 2.531292016265407

Epoch: 5| Step: 6
Training loss: 2.4725229911390967
Validation loss: 2.501174468095174

Epoch: 5| Step: 7
Training loss: 2.1508050254230984
Validation loss: 2.5315958226391206

Epoch: 5| Step: 8
Training loss: 1.428721116942974
Validation loss: 2.534550387220482

Epoch: 5| Step: 9
Training loss: 2.241116789791335
Validation loss: 2.5706035522659385

Epoch: 5| Step: 10
Training loss: 2.1187051773956527
Validation loss: 2.5695800162683087

Epoch: 5| Step: 11
Training loss: 0.816647434656926
Validation loss: 2.581434718643243

Epoch: 341| Step: 0
Training loss: 2.009830395958828
Validation loss: 2.5758286238542656

Epoch: 5| Step: 1
Training loss: 2.062085890378797
Validation loss: 2.5641388595248147

Epoch: 5| Step: 2
Training loss: 2.081550929219619
Validation loss: 2.54742020932202

Epoch: 5| Step: 3
Training loss: 2.2716096956642957
Validation loss: 2.572117014545516

Epoch: 5| Step: 4
Training loss: 2.520056759936812
Validation loss: 2.5581510786958916

Epoch: 5| Step: 5
Training loss: 1.6737997793782067
Validation loss: 2.5447919280064673

Epoch: 5| Step: 6
Training loss: 1.9949614715680029
Validation loss: 2.543826869128073

Epoch: 5| Step: 7
Training loss: 2.275609188470178
Validation loss: 2.561245653916124

Epoch: 5| Step: 8
Training loss: 1.7810295370095464
Validation loss: 2.559891862112686

Epoch: 5| Step: 9
Training loss: 1.983792136789824
Validation loss: 2.5521779483980604

Epoch: 5| Step: 10
Training loss: 2.331813271716943
Validation loss: 2.5272818021734027

Epoch: 5| Step: 11
Training loss: 0.9315567458677918
Validation loss: 2.5194846688629475

Epoch: 342| Step: 0
Training loss: 2.1797848478065562
Validation loss: 2.5091104961072292

Epoch: 5| Step: 1
Training loss: 1.885249985831847
Validation loss: 2.4999633905591288

Epoch: 5| Step: 2
Training loss: 2.519345772000438
Validation loss: 2.517854539737174

Epoch: 5| Step: 3
Training loss: 1.9978836306113636
Validation loss: 2.531442878187683

Epoch: 5| Step: 4
Training loss: 1.7862885805078594
Validation loss: 2.5019852702934324

Epoch: 5| Step: 5
Training loss: 2.0900269615223
Validation loss: 2.527818732459706

Epoch: 5| Step: 6
Training loss: 2.178484622378355
Validation loss: 2.560481152344503

Epoch: 5| Step: 7
Training loss: 2.3393177084362478
Validation loss: 2.575449154084261

Epoch: 5| Step: 8
Training loss: 1.8054687658464272
Validation loss: 2.599296778402124

Epoch: 5| Step: 9
Training loss: 2.0439425129878104
Validation loss: 2.6018603959087194

Epoch: 5| Step: 10
Training loss: 2.0094734179657583
Validation loss: 2.625393913625315

Epoch: 5| Step: 11
Training loss: 0.977342766899267
Validation loss: 2.62915008834916

Epoch: 343| Step: 0
Training loss: 1.9038174226159414
Validation loss: 2.6068820046808088

Epoch: 5| Step: 1
Training loss: 1.5849883899203334
Validation loss: 2.577075029671772

Epoch: 5| Step: 2
Training loss: 2.185496475415867
Validation loss: 2.5523772647814678

Epoch: 5| Step: 3
Training loss: 2.0681500351452002
Validation loss: 2.504648432880091

Epoch: 5| Step: 4
Training loss: 2.2760893047826456
Validation loss: 2.516251851204502

Epoch: 5| Step: 5
Training loss: 2.7405280936669367
Validation loss: 2.5128094236692453

Epoch: 5| Step: 6
Training loss: 2.272015208623246
Validation loss: 2.5122125060204406

Epoch: 5| Step: 7
Training loss: 1.6976991369778789
Validation loss: 2.5041263739464474

Epoch: 5| Step: 8
Training loss: 2.141942308056802
Validation loss: 2.5030012037419365

Epoch: 5| Step: 9
Training loss: 1.275443340339548
Validation loss: 2.5187528171633984

Epoch: 5| Step: 10
Training loss: 2.0990935503724772
Validation loss: 2.491232993161495

Epoch: 5| Step: 11
Training loss: 3.864586280897033
Validation loss: 2.522643299922111

Epoch: 344| Step: 0
Training loss: 2.0016720458166732
Validation loss: 2.510553472334267

Epoch: 5| Step: 1
Training loss: 2.2665208821070015
Validation loss: 2.547368495224851

Epoch: 5| Step: 2
Training loss: 1.9161284838305157
Validation loss: 2.5737104324046283

Epoch: 5| Step: 3
Training loss: 2.482915005449419
Validation loss: 2.5931494871760754

Epoch: 5| Step: 4
Training loss: 1.6518857785702088
Validation loss: 2.6009089094713667

Epoch: 5| Step: 5
Training loss: 2.032886491465428
Validation loss: 2.62409842994099

Epoch: 5| Step: 6
Training loss: 2.4533819562129517
Validation loss: 2.5849402195900426

Epoch: 5| Step: 7
Training loss: 2.2214744925845116
Validation loss: 2.560552981612089

Epoch: 5| Step: 8
Training loss: 2.1774824467158433
Validation loss: 2.550017066661594

Epoch: 5| Step: 9
Training loss: 1.9592623299506058
Validation loss: 2.5194490128533795

Epoch: 5| Step: 10
Training loss: 1.9809295298844338
Validation loss: 2.539014043101062

Epoch: 5| Step: 11
Training loss: 2.059390874636511
Validation loss: 2.5366173909086553

Epoch: 345| Step: 0
Training loss: 2.0273851452902947
Validation loss: 2.5252393503652173

Epoch: 5| Step: 1
Training loss: 1.5502871247429222
Validation loss: 2.5242161646784163

Epoch: 5| Step: 2
Training loss: 2.471621810735853
Validation loss: 2.5234733122340374

Epoch: 5| Step: 3
Training loss: 1.5530624714781183
Validation loss: 2.52557560006521

Epoch: 5| Step: 4
Training loss: 1.871406481257846
Validation loss: 2.5526916842793437

Epoch: 5| Step: 5
Training loss: 1.7830309079626185
Validation loss: 2.5291947176025555

Epoch: 5| Step: 6
Training loss: 1.8354094699656465
Validation loss: 2.5344613743749473

Epoch: 5| Step: 7
Training loss: 2.395384395388841
Validation loss: 2.5550663440648336

Epoch: 5| Step: 8
Training loss: 2.524376378617426
Validation loss: 2.5675364830795253

Epoch: 5| Step: 9
Training loss: 2.2907771956400946
Validation loss: 2.5644116675538147

Epoch: 5| Step: 10
Training loss: 2.607807625228321
Validation loss: 2.612943656947042

Epoch: 5| Step: 11
Training loss: 1.917932949003953
Validation loss: 2.6192138267185148

Epoch: 346| Step: 0
Training loss: 1.4698107521049006
Validation loss: 2.6282654009981963

Epoch: 5| Step: 1
Training loss: 1.5689473457375487
Validation loss: 2.613181910125879

Epoch: 5| Step: 2
Training loss: 2.4501510378933764
Validation loss: 2.5893187760370466

Epoch: 5| Step: 3
Training loss: 2.6121351069373366
Validation loss: 2.5475538593310194

Epoch: 5| Step: 4
Training loss: 2.229983515828195
Validation loss: 2.5221165525209823

Epoch: 5| Step: 5
Training loss: 2.234501761728763
Validation loss: 2.5339168698954593

Epoch: 5| Step: 6
Training loss: 1.7596680744327138
Validation loss: 2.5030584978150716

Epoch: 5| Step: 7
Training loss: 1.6666858036214156
Validation loss: 2.5155372564837077

Epoch: 5| Step: 8
Training loss: 1.9968005457505984
Validation loss: 2.5116948412859275

Epoch: 5| Step: 9
Training loss: 2.2641439924718214
Validation loss: 2.5077327030277368

Epoch: 5| Step: 10
Training loss: 2.3181218039212137
Validation loss: 2.5128713507327944

Epoch: 5| Step: 11
Training loss: 2.4954732920723743
Validation loss: 2.5117596612567747

Epoch: 347| Step: 0
Training loss: 2.403412272690799
Validation loss: 2.521275096731208

Epoch: 5| Step: 1
Training loss: 1.737094705638533
Validation loss: 2.4929250425027694

Epoch: 5| Step: 2
Training loss: 1.98584860806094
Validation loss: 2.505151503480767

Epoch: 5| Step: 3
Training loss: 2.082812536630251
Validation loss: 2.508305910083076

Epoch: 5| Step: 4
Training loss: 1.9497897548308158
Validation loss: 2.5232792028137365

Epoch: 5| Step: 5
Training loss: 2.430208009364737
Validation loss: 2.5087239242260417

Epoch: 5| Step: 6
Training loss: 1.589092180093051
Validation loss: 2.541372224814699

Epoch: 5| Step: 7
Training loss: 2.1563478530573423
Validation loss: 2.5355369975535718

Epoch: 5| Step: 8
Training loss: 2.3253053321107586
Validation loss: 2.555484752319203

Epoch: 5| Step: 9
Training loss: 2.216816449183955
Validation loss: 2.5724655880802856

Epoch: 5| Step: 10
Training loss: 1.7422025534488383
Validation loss: 2.589304220042628

Epoch: 5| Step: 11
Training loss: 2.625120886789324
Validation loss: 2.5951653835575277

Epoch: 348| Step: 0
Training loss: 1.6889554564145384
Validation loss: 2.60030663069891

Epoch: 5| Step: 1
Training loss: 1.573058048319441
Validation loss: 2.5948947463865903

Epoch: 5| Step: 2
Training loss: 1.6500326095595395
Validation loss: 2.576269900346745

Epoch: 5| Step: 3
Training loss: 1.9892203580750794
Validation loss: 2.569721555945368

Epoch: 5| Step: 4
Training loss: 3.049012046021975
Validation loss: 2.564817768251555

Epoch: 5| Step: 5
Training loss: 1.8286563720515339
Validation loss: 2.543242701996307

Epoch: 5| Step: 6
Training loss: 2.002328113698763
Validation loss: 2.529853975466471

Epoch: 5| Step: 7
Training loss: 1.727049814902896
Validation loss: 2.5066530631293134

Epoch: 5| Step: 8
Training loss: 2.7559310936196395
Validation loss: 2.523302741925622

Epoch: 5| Step: 9
Training loss: 1.8528999616543143
Validation loss: 2.5201097952801232

Epoch: 5| Step: 10
Training loss: 2.1350964065690894
Validation loss: 2.517203426172574

Epoch: 5| Step: 11
Training loss: 0.5593068566186284
Validation loss: 2.5192135356711964

Epoch: 349| Step: 0
Training loss: 1.5600365865525225
Validation loss: 2.510846723756514

Epoch: 5| Step: 1
Training loss: 1.8297866703199626
Validation loss: 2.527608673816946

Epoch: 5| Step: 2
Training loss: 2.2983148953161807
Validation loss: 2.5104141248529213

Epoch: 5| Step: 3
Training loss: 2.486826904322653
Validation loss: 2.531166899459057

Epoch: 5| Step: 4
Training loss: 1.740578083385394
Validation loss: 2.514276229817416

Epoch: 5| Step: 5
Training loss: 2.483077952248652
Validation loss: 2.5175665595452625

Epoch: 5| Step: 6
Training loss: 1.9109605215437293
Validation loss: 2.526585779218468

Epoch: 5| Step: 7
Training loss: 1.6506204478942432
Validation loss: 2.5391807372122024

Epoch: 5| Step: 8
Training loss: 1.856145410127886
Validation loss: 2.5826303745927333

Epoch: 5| Step: 9
Training loss: 1.674190023641286
Validation loss: 2.6235554898636813

Epoch: 5| Step: 10
Training loss: 2.7805263992425546
Validation loss: 2.5868976036153972

Epoch: 5| Step: 11
Training loss: 1.921293837593817
Validation loss: 2.6277263425179997

Epoch: 350| Step: 0
Training loss: 2.3254551267721464
Validation loss: 2.582366983090639

Epoch: 5| Step: 1
Training loss: 2.1696746438112693
Validation loss: 2.5262606529144613

Epoch: 5| Step: 2
Training loss: 2.0171448647671646
Validation loss: 2.541782307469487

Epoch: 5| Step: 3
Training loss: 2.3337986572946963
Validation loss: 2.5274623703474375

Epoch: 5| Step: 4
Training loss: 1.290549651525769
Validation loss: 2.535481497223843

Epoch: 5| Step: 5
Training loss: 1.8050110762195528
Validation loss: 2.5366984742606187

Epoch: 5| Step: 6
Training loss: 1.4915400993028545
Validation loss: 2.5503061542417234

Epoch: 5| Step: 7
Training loss: 2.5672872532080664
Validation loss: 2.5436119559194754

Epoch: 5| Step: 8
Training loss: 2.304056993004765
Validation loss: 2.542888028709004

Epoch: 5| Step: 9
Training loss: 1.751980002036556
Validation loss: 2.5783355800285572

Epoch: 5| Step: 10
Training loss: 2.3881732610534754
Validation loss: 2.55616326437545

Epoch: 5| Step: 11
Training loss: 1.3757513767618885
Validation loss: 2.574825765214861

Epoch: 351| Step: 0
Training loss: 2.38175455590136
Validation loss: 2.550110744895152

Epoch: 5| Step: 1
Training loss: 1.5933836721637822
Validation loss: 2.547041214743891

Epoch: 5| Step: 2
Training loss: 2.0277861184191055
Validation loss: 2.5218352436396856

Epoch: 5| Step: 3
Training loss: 2.3543813039332226
Validation loss: 2.5007999809157138

Epoch: 5| Step: 4
Training loss: 1.9374770501531096
Validation loss: 2.5346001052761404

Epoch: 5| Step: 5
Training loss: 2.1604037979414663
Validation loss: 2.522301436858237

Epoch: 5| Step: 6
Training loss: 1.682030609315005
Validation loss: 2.5062792082659757

Epoch: 5| Step: 7
Training loss: 1.8855900201786675
Validation loss: 2.536188363206335

Epoch: 5| Step: 8
Training loss: 2.3030804737191692
Validation loss: 2.5125182833567785

Epoch: 5| Step: 9
Training loss: 2.452162049444498
Validation loss: 2.518951581961105

Epoch: 5| Step: 10
Training loss: 1.3717813968225168
Validation loss: 2.5365356940052686

Epoch: 5| Step: 11
Training loss: 1.6877725169222817
Validation loss: 2.541907241775636

Epoch: 352| Step: 0
Training loss: 1.9480286292335953
Validation loss: 2.570359091447569

Epoch: 5| Step: 1
Training loss: 1.4097352812881985
Validation loss: 2.5421022813140124

Epoch: 5| Step: 2
Training loss: 2.2837345754585887
Validation loss: 2.564807775320478

Epoch: 5| Step: 3
Training loss: 2.2043235170145907
Validation loss: 2.601244287437217

Epoch: 5| Step: 4
Training loss: 2.13828021081879
Validation loss: 2.575123274423277

Epoch: 5| Step: 5
Training loss: 2.2141506180225297
Validation loss: 2.5889248030333483

Epoch: 5| Step: 6
Training loss: 2.1954827836538167
Validation loss: 2.5997461616875888

Epoch: 5| Step: 7
Training loss: 1.746660861571083
Validation loss: 2.588967053609567

Epoch: 5| Step: 8
Training loss: 1.7232487842373452
Validation loss: 2.610217778747001

Epoch: 5| Step: 9
Training loss: 2.1002309899220735
Validation loss: 2.633452178339575

Epoch: 5| Step: 10
Training loss: 2.2212034817591904
Validation loss: 2.5774938870544664

Epoch: 5| Step: 11
Training loss: 1.8511729414084157
Validation loss: 2.538245651701526

Epoch: 353| Step: 0
Training loss: 1.3520985681334805
Validation loss: 2.543161766747099

Epoch: 5| Step: 1
Training loss: 2.391467077010684
Validation loss: 2.5401878562679023

Epoch: 5| Step: 2
Training loss: 2.036109627790664
Validation loss: 2.52044225974786

Epoch: 5| Step: 3
Training loss: 1.697894051368053
Validation loss: 2.5263341019976515

Epoch: 5| Step: 4
Training loss: 2.411446842526
Validation loss: 2.5058579795478706

Epoch: 5| Step: 5
Training loss: 1.8672876051878782
Validation loss: 2.554261349939849

Epoch: 5| Step: 6
Training loss: 2.0181880298647004
Validation loss: 2.5594602481368023

Epoch: 5| Step: 7
Training loss: 2.5271481846609447
Validation loss: 2.5876858612240365

Epoch: 5| Step: 8
Training loss: 2.006688140847177
Validation loss: 2.562885879522286

Epoch: 5| Step: 9
Training loss: 2.150431314719201
Validation loss: 2.5832356208862057

Epoch: 5| Step: 10
Training loss: 1.9270279197630071
Validation loss: 2.598687218315524

Epoch: 5| Step: 11
Training loss: 0.15323092047515138
Validation loss: 2.56465271722401

Epoch: 354| Step: 0
Training loss: 2.0104319781048114
Validation loss: 2.585808611497671

Epoch: 5| Step: 1
Training loss: 1.750855236881781
Validation loss: 2.5830957100905394

Epoch: 5| Step: 2
Training loss: 2.2622696859409777
Validation loss: 2.5632267983483867

Epoch: 5| Step: 3
Training loss: 1.973876273698283
Validation loss: 2.5815180827870723

Epoch: 5| Step: 4
Training loss: 2.0776479073031577
Validation loss: 2.5799862241007574

Epoch: 5| Step: 5
Training loss: 2.126440793940494
Validation loss: 2.5716627066572073

Epoch: 5| Step: 6
Training loss: 1.5403005974174857
Validation loss: 2.572928785123098

Epoch: 5| Step: 7
Training loss: 2.58143486487823
Validation loss: 2.5828017962096066

Epoch: 5| Step: 8
Training loss: 1.8911574063323002
Validation loss: 2.544821252441395

Epoch: 5| Step: 9
Training loss: 1.3754157391513924
Validation loss: 2.5391065075312866

Epoch: 5| Step: 10
Training loss: 1.9154104663393634
Validation loss: 2.584779047718567

Epoch: 5| Step: 11
Training loss: 3.0015486852436184
Validation loss: 2.531705112908283

Epoch: 355| Step: 0
Training loss: 1.935347006878374
Validation loss: 2.515106724332066

Epoch: 5| Step: 1
Training loss: 2.3915782349439088
Validation loss: 2.5189284162853625

Epoch: 5| Step: 2
Training loss: 2.1143727189834562
Validation loss: 2.515187464351291

Epoch: 5| Step: 3
Training loss: 1.391702384642652
Validation loss: 2.5228803765647694

Epoch: 5| Step: 4
Training loss: 2.027883939126904
Validation loss: 2.5394141281396987

Epoch: 5| Step: 5
Training loss: 1.9598250558200765
Validation loss: 2.5364153634464977

Epoch: 5| Step: 6
Training loss: 1.701661627398037
Validation loss: 2.549033395191775

Epoch: 5| Step: 7
Training loss: 2.7110115502877257
Validation loss: 2.5372926970304195

Epoch: 5| Step: 8
Training loss: 2.1693457277213923
Validation loss: 2.561004213740775

Epoch: 5| Step: 9
Training loss: 2.1087825366971478
Validation loss: 2.544300424071197

Epoch: 5| Step: 10
Training loss: 1.8189481279926267
Validation loss: 2.5771440778422945

Epoch: 5| Step: 11
Training loss: 1.1469011994989142
Validation loss: 2.570895773306089

Epoch: 356| Step: 0
Training loss: 2.1448149502123246
Validation loss: 2.5047866733436424

Epoch: 5| Step: 1
Training loss: 2.112190571531728
Validation loss: 2.5300860731274786

Epoch: 5| Step: 2
Training loss: 2.070591745797537
Validation loss: 2.5049199131925426

Epoch: 5| Step: 3
Training loss: 1.82083947408355
Validation loss: 2.522266080613174

Epoch: 5| Step: 4
Training loss: 1.7290166613612759
Validation loss: 2.5047501021359566

Epoch: 5| Step: 5
Training loss: 1.7330815071181567
Validation loss: 2.4876442118236177

Epoch: 5| Step: 6
Training loss: 1.9164553885180342
Validation loss: 2.4945076732355638

Epoch: 5| Step: 7
Training loss: 1.9490747188339852
Validation loss: 2.505684271403438

Epoch: 5| Step: 8
Training loss: 1.5545964046607972
Validation loss: 2.499301483002824

Epoch: 5| Step: 9
Training loss: 2.734877709090335
Validation loss: 2.520590172749395

Epoch: 5| Step: 10
Training loss: 2.1831150246694517
Validation loss: 2.4880939415139354

Epoch: 5| Step: 11
Training loss: 0.7699840007705133
Validation loss: 2.496380371130249

Epoch: 357| Step: 0
Training loss: 2.3735887450395894
Validation loss: 2.52917939727026

Epoch: 5| Step: 1
Training loss: 2.1537531895539175
Validation loss: 2.50581470428873

Epoch: 5| Step: 2
Training loss: 2.910369414644764
Validation loss: 2.5092973878417086

Epoch: 5| Step: 3
Training loss: 2.0230910545897665
Validation loss: 2.492191868761273

Epoch: 5| Step: 4
Training loss: 1.5083748356850755
Validation loss: 2.4750631348427605

Epoch: 5| Step: 5
Training loss: 1.7091218555192458
Validation loss: 2.504988453839076

Epoch: 5| Step: 6
Training loss: 1.8265499274455028
Validation loss: 2.510879459434306

Epoch: 5| Step: 7
Training loss: 1.3228859735167302
Validation loss: 2.468899774635646

Epoch: 5| Step: 8
Training loss: 2.0814101561363696
Validation loss: 2.505573741067859

Epoch: 5| Step: 9
Training loss: 1.844270277162382
Validation loss: 2.5081130468605095

Epoch: 5| Step: 10
Training loss: 1.8414060273006467
Validation loss: 2.503990735291545

Epoch: 5| Step: 11
Training loss: 2.700690788627756
Validation loss: 2.5241595200791878

Epoch: 358| Step: 0
Training loss: 2.1463195348727475
Validation loss: 2.590780737888939

Epoch: 5| Step: 1
Training loss: 1.4733677771729377
Validation loss: 2.628768769930492

Epoch: 5| Step: 2
Training loss: 1.794450666904323
Validation loss: 2.6688821847714808

Epoch: 5| Step: 3
Training loss: 2.4322672699079813
Validation loss: 2.6147945111063486

Epoch: 5| Step: 4
Training loss: 2.3972794411633904
Validation loss: 2.6355525133807536

Epoch: 5| Step: 5
Training loss: 1.3332139299493027
Validation loss: 2.633374981359704

Epoch: 5| Step: 6
Training loss: 1.9339028467828154
Validation loss: 2.6389146491237847

Epoch: 5| Step: 7
Training loss: 1.653990373737963
Validation loss: 2.5920517620520105

Epoch: 5| Step: 8
Training loss: 2.3060054825174183
Validation loss: 2.5819753197380093

Epoch: 5| Step: 9
Training loss: 2.4333317647780843
Validation loss: 2.565886705705964

Epoch: 5| Step: 10
Training loss: 2.1707117272385563
Validation loss: 2.5109012691350268

Epoch: 5| Step: 11
Training loss: 1.5539375681763392
Validation loss: 2.536685210204885

Epoch: 359| Step: 0
Training loss: 1.948763195920534
Validation loss: 2.5524873543468725

Epoch: 5| Step: 1
Training loss: 2.106310957301043
Validation loss: 2.5490778619208956

Epoch: 5| Step: 2
Training loss: 1.5889981807268603
Validation loss: 2.5733358541062055

Epoch: 5| Step: 3
Training loss: 2.248713867507906
Validation loss: 2.549211623766119

Epoch: 5| Step: 4
Training loss: 1.7799002904503702
Validation loss: 2.555295018434917

Epoch: 5| Step: 5
Training loss: 1.7086415671803246
Validation loss: 2.5564496945552886

Epoch: 5| Step: 6
Training loss: 2.3735079847144855
Validation loss: 2.591198942065104

Epoch: 5| Step: 7
Training loss: 1.249442453018606
Validation loss: 2.5792478678548663

Epoch: 5| Step: 8
Training loss: 2.1769580227016276
Validation loss: 2.5715525784642783

Epoch: 5| Step: 9
Training loss: 2.2348596007350348
Validation loss: 2.5282316186189493

Epoch: 5| Step: 10
Training loss: 2.288740324190564
Validation loss: 2.5505994427213854

Epoch: 5| Step: 11
Training loss: 1.3329420359944786
Validation loss: 2.525865549980998

Epoch: 360| Step: 0
Training loss: 2.6650444301888045
Validation loss: 2.5488401566144727

Epoch: 5| Step: 1
Training loss: 1.9571125066947694
Validation loss: 2.5281817281713925

Epoch: 5| Step: 2
Training loss: 1.6956589867700589
Validation loss: 2.5801533320610326

Epoch: 5| Step: 3
Training loss: 2.390627892187027
Validation loss: 2.5566787114620184

Epoch: 5| Step: 4
Training loss: 1.5894135964072837
Validation loss: 2.5532857294122913

Epoch: 5| Step: 5
Training loss: 1.9123111731366949
Validation loss: 2.5502815438655615

Epoch: 5| Step: 6
Training loss: 2.0768398814370457
Validation loss: 2.562769716691269

Epoch: 5| Step: 7
Training loss: 1.647188698933367
Validation loss: 2.546130014843893

Epoch: 5| Step: 8
Training loss: 1.6003081084662119
Validation loss: 2.549307864509169

Epoch: 5| Step: 9
Training loss: 2.1980480377807035
Validation loss: 2.5455731182960113

Epoch: 5| Step: 10
Training loss: 1.9368699802999576
Validation loss: 2.5271990114065193

Epoch: 5| Step: 11
Training loss: 2.0980527705491663
Validation loss: 2.532273464354532

Epoch: 361| Step: 0
Training loss: 1.7707933383987824
Validation loss: 2.545732222285366

Epoch: 5| Step: 1
Training loss: 2.486323522187413
Validation loss: 2.532288542358111

Epoch: 5| Step: 2
Training loss: 1.6852347393264508
Validation loss: 2.5179248035465034

Epoch: 5| Step: 3
Training loss: 1.8070815419522515
Validation loss: 2.5091290508988795

Epoch: 5| Step: 4
Training loss: 2.099660927782797
Validation loss: 2.5169454272306093

Epoch: 5| Step: 5
Training loss: 2.309761591081534
Validation loss: 2.5204259658879886

Epoch: 5| Step: 6
Training loss: 1.7502484826379832
Validation loss: 2.496682333962855

Epoch: 5| Step: 7
Training loss: 2.049115999869312
Validation loss: 2.51456692955484

Epoch: 5| Step: 8
Training loss: 1.6377595128013271
Validation loss: 2.5579881684278454

Epoch: 5| Step: 9
Training loss: 1.9311091942674619
Validation loss: 2.5419723621347106

Epoch: 5| Step: 10
Training loss: 2.213757983838961
Validation loss: 2.5672668144494417

Epoch: 5| Step: 11
Training loss: 1.2591473148776753
Validation loss: 2.553861194709893

Epoch: 362| Step: 0
Training loss: 1.7030607438871301
Validation loss: 2.569011606382754

Epoch: 5| Step: 1
Training loss: 2.300863941306354
Validation loss: 2.5838524901780575

Epoch: 5| Step: 2
Training loss: 1.6119131424981092
Validation loss: 2.594265821403947

Epoch: 5| Step: 3
Training loss: 1.4428896830179427
Validation loss: 2.5848080338009374

Epoch: 5| Step: 4
Training loss: 2.0598499728634527
Validation loss: 2.6039809707555714

Epoch: 5| Step: 5
Training loss: 1.7930343050805126
Validation loss: 2.569059454940812

Epoch: 5| Step: 6
Training loss: 1.6427181152491144
Validation loss: 2.5472689208900654

Epoch: 5| Step: 7
Training loss: 2.2867057046625674
Validation loss: 2.494567910170028

Epoch: 5| Step: 8
Training loss: 2.300734825507861
Validation loss: 2.5163470667413206

Epoch: 5| Step: 9
Training loss: 1.7776799481349557
Validation loss: 2.542272817269904

Epoch: 5| Step: 10
Training loss: 2.485128804174915
Validation loss: 2.5142937962593863

Epoch: 5| Step: 11
Training loss: 3.074639530298141
Validation loss: 2.5353290438236673

Epoch: 363| Step: 0
Training loss: 1.3365365631605133
Validation loss: 2.5051401661714414

Epoch: 5| Step: 1
Training loss: 2.406459254294185
Validation loss: 2.502465415281167

Epoch: 5| Step: 2
Training loss: 1.8928110394685553
Validation loss: 2.525576437879979

Epoch: 5| Step: 3
Training loss: 2.0190563713468404
Validation loss: 2.5459279208761814

Epoch: 5| Step: 4
Training loss: 2.5425156806454754
Validation loss: 2.598310647247194

Epoch: 5| Step: 5
Training loss: 1.5688013805470868
Validation loss: 2.5853949454965615

Epoch: 5| Step: 6
Training loss: 1.953893586567289
Validation loss: 2.5654595349969935

Epoch: 5| Step: 7
Training loss: 1.7593771519486867
Validation loss: 2.556638017754601

Epoch: 5| Step: 8
Training loss: 2.3862666874137712
Validation loss: 2.567920271126997

Epoch: 5| Step: 9
Training loss: 1.8237979901949959
Validation loss: 2.5529399614893706

Epoch: 5| Step: 10
Training loss: 1.9615766236029382
Validation loss: 2.500084887493912

Epoch: 5| Step: 11
Training loss: 3.3084460228881998
Validation loss: 2.5193710473358535

Epoch: 364| Step: 0
Training loss: 2.3090838381687
Validation loss: 2.4963773507603517

Epoch: 5| Step: 1
Training loss: 2.2181346201103596
Validation loss: 2.495699832022658

Epoch: 5| Step: 2
Training loss: 2.134627020996481
Validation loss: 2.4795539590844258

Epoch: 5| Step: 3
Training loss: 1.7491168109585151
Validation loss: 2.500630009264872

Epoch: 5| Step: 4
Training loss: 1.5712066685688502
Validation loss: 2.492538997373131

Epoch: 5| Step: 5
Training loss: 2.4437543395801464
Validation loss: 2.4945594995469924

Epoch: 5| Step: 6
Training loss: 1.340153472068481
Validation loss: 2.4929728929657973

Epoch: 5| Step: 7
Training loss: 2.309549253339507
Validation loss: 2.5230590804267896

Epoch: 5| Step: 8
Training loss: 2.1737787698659274
Validation loss: 2.493898832569333

Epoch: 5| Step: 9
Training loss: 1.7238631054103652
Validation loss: 2.535261699597482

Epoch: 5| Step: 10
Training loss: 1.7630837981917964
Validation loss: 2.5182090306126255

Epoch: 5| Step: 11
Training loss: 1.5313203756547837
Validation loss: 2.5543271976282593

Epoch: 365| Step: 0
Training loss: 1.9314801619081483
Validation loss: 2.5007576589078404

Epoch: 5| Step: 1
Training loss: 1.812348655432913
Validation loss: 2.498533975385842

Epoch: 5| Step: 2
Training loss: 1.6496602806856182
Validation loss: 2.4872398333062935

Epoch: 5| Step: 3
Training loss: 1.773524345254513
Validation loss: 2.475013780154132

Epoch: 5| Step: 4
Training loss: 2.1865662898114913
Validation loss: 2.4751327471021294

Epoch: 5| Step: 5
Training loss: 2.269142839874274
Validation loss: 2.4959919510262263

Epoch: 5| Step: 6
Training loss: 1.944453099398046
Validation loss: 2.499996854859599

Epoch: 5| Step: 7
Training loss: 1.6863778233135858
Validation loss: 2.473501118355709

Epoch: 5| Step: 8
Training loss: 2.453741785736249
Validation loss: 2.4760796871537405

Epoch: 5| Step: 9
Training loss: 2.296531392041343
Validation loss: 2.488775809987798

Epoch: 5| Step: 10
Training loss: 2.4339361302028824
Validation loss: 2.5172256171641565

Epoch: 5| Step: 11
Training loss: 1.2958765437699362
Validation loss: 2.539801536012898

Epoch: 366| Step: 0
Training loss: 2.6172220256293137
Validation loss: 2.5427452180576364

Epoch: 5| Step: 1
Training loss: 1.5508325986264289
Validation loss: 2.5839623228993354

Epoch: 5| Step: 2
Training loss: 1.724806017265546
Validation loss: 2.576788114467241

Epoch: 5| Step: 3
Training loss: 2.0525333150002196
Validation loss: 2.621363508931796

Epoch: 5| Step: 4
Training loss: 2.430058883298931
Validation loss: 2.6220009262404367

Epoch: 5| Step: 5
Training loss: 2.341695266313676
Validation loss: 2.593969159652997

Epoch: 5| Step: 6
Training loss: 1.4595279523597628
Validation loss: 2.57553836648114

Epoch: 5| Step: 7
Training loss: 2.148351716149606
Validation loss: 2.5598022518858596

Epoch: 5| Step: 8
Training loss: 1.8455411971172462
Validation loss: 2.5661077108016768

Epoch: 5| Step: 9
Training loss: 1.8668349184548834
Validation loss: 2.523821719811491

Epoch: 5| Step: 10
Training loss: 1.7630645956884128
Validation loss: 2.5273139712089177

Epoch: 5| Step: 11
Training loss: 2.5722978802789727
Validation loss: 2.5192802402735275

Epoch: 367| Step: 0
Training loss: 1.4802317568030576
Validation loss: 2.506580902033328

Epoch: 5| Step: 1
Training loss: 2.20353824716799
Validation loss: 2.5219154806878525

Epoch: 5| Step: 2
Training loss: 2.2168526932331054
Validation loss: 2.5643364017106562

Epoch: 5| Step: 3
Training loss: 2.7477807713922626
Validation loss: 2.564704477892247

Epoch: 5| Step: 4
Training loss: 1.7636868802569736
Validation loss: 2.597934667825216

Epoch: 5| Step: 5
Training loss: 1.7474313003723134
Validation loss: 2.616710520688655

Epoch: 5| Step: 6
Training loss: 1.6214055140724215
Validation loss: 2.621731464032246

Epoch: 5| Step: 7
Training loss: 2.1812323014817436
Validation loss: 2.61983910600447

Epoch: 5| Step: 8
Training loss: 2.012333511194981
Validation loss: 2.5833235414893685

Epoch: 5| Step: 9
Training loss: 2.095963517905284
Validation loss: 2.5529410471456866

Epoch: 5| Step: 10
Training loss: 1.849867032401826
Validation loss: 2.50850406115343

Epoch: 5| Step: 11
Training loss: 1.738252652393799
Validation loss: 2.5144469857616265

Epoch: 368| Step: 0
Training loss: 2.510652734148882
Validation loss: 2.506986099618001

Epoch: 5| Step: 1
Training loss: 1.6402426864584236
Validation loss: 2.519546408201056

Epoch: 5| Step: 2
Training loss: 2.3264071892418685
Validation loss: 2.5004648173872055

Epoch: 5| Step: 3
Training loss: 2.271046643052369
Validation loss: 2.5044967462916206

Epoch: 5| Step: 4
Training loss: 1.8679170978700796
Validation loss: 2.51291056310357

Epoch: 5| Step: 5
Training loss: 1.7437261108074624
Validation loss: 2.5024650381569624

Epoch: 5| Step: 6
Training loss: 2.402689094842404
Validation loss: 2.5344588540626085

Epoch: 5| Step: 7
Training loss: 2.065501023812411
Validation loss: 2.517829604273643

Epoch: 5| Step: 8
Training loss: 1.816310035044155
Validation loss: 2.5673921685757515

Epoch: 5| Step: 9
Training loss: 1.6205146950323517
Validation loss: 2.5882251067500808

Epoch: 5| Step: 10
Training loss: 1.8298969647319037
Validation loss: 2.5979000502980094

Epoch: 5| Step: 11
Training loss: 2.337142582459322
Validation loss: 2.5643981323388902

Epoch: 369| Step: 0
Training loss: 1.744239932455058
Validation loss: 2.521287106165431

Epoch: 5| Step: 1
Training loss: 2.0850924376710047
Validation loss: 2.485227562509676

Epoch: 5| Step: 2
Training loss: 1.9397173468172684
Validation loss: 2.47721216483293

Epoch: 5| Step: 3
Training loss: 1.9013298199493205
Validation loss: 2.497838711310928

Epoch: 5| Step: 4
Training loss: 1.7984213104977627
Validation loss: 2.461235581364333

Epoch: 5| Step: 5
Training loss: 2.4058653288685665
Validation loss: 2.4876567530004055

Epoch: 5| Step: 6
Training loss: 2.2878125003334797
Validation loss: 2.519234845373179

Epoch: 5| Step: 7
Training loss: 1.8694196949127124
Validation loss: 2.4678465240246905

Epoch: 5| Step: 8
Training loss: 2.1924458857853635
Validation loss: 2.4979276114142634

Epoch: 5| Step: 9
Training loss: 1.7980459627210916
Validation loss: 2.476087606889471

Epoch: 5| Step: 10
Training loss: 2.5266579312129065
Validation loss: 2.4870461433272912

Epoch: 5| Step: 11
Training loss: 0.9986082763761331
Validation loss: 2.5063846599523405

Epoch: 370| Step: 0
Training loss: 2.4005437791229385
Validation loss: 2.5015286421286453

Epoch: 5| Step: 1
Training loss: 1.9751444317120324
Validation loss: 2.5141132622259272

Epoch: 5| Step: 2
Training loss: 1.775573989581233
Validation loss: 2.5198790357018632

Epoch: 5| Step: 3
Training loss: 2.2387924808835984
Validation loss: 2.518545118444141

Epoch: 5| Step: 4
Training loss: 1.9945553339973292
Validation loss: 2.5319687329195273

Epoch: 5| Step: 5
Training loss: 1.596508107896832
Validation loss: 2.543357940440632

Epoch: 5| Step: 6
Training loss: 2.1021980544191505
Validation loss: 2.522930369876741

Epoch: 5| Step: 7
Training loss: 2.1651953200758514
Validation loss: 2.510856721754138

Epoch: 5| Step: 8
Training loss: 1.567121461368779
Validation loss: 2.514147176318243

Epoch: 5| Step: 9
Training loss: 2.0366752359404567
Validation loss: 2.4966492887863234

Epoch: 5| Step: 10
Training loss: 1.8119881005728022
Validation loss: 2.4853226195962805

Epoch: 5| Step: 11
Training loss: 3.180989366808007
Validation loss: 2.47968653562896

Epoch: 371| Step: 0
Training loss: 1.7799460339669961
Validation loss: 2.462514132089615

Epoch: 5| Step: 1
Training loss: 1.8647080562654623
Validation loss: 2.5047890767683723

Epoch: 5| Step: 2
Training loss: 1.6062946654763086
Validation loss: 2.491275744141662

Epoch: 5| Step: 3
Training loss: 2.647102221899875
Validation loss: 2.497804273527132

Epoch: 5| Step: 4
Training loss: 2.2187762191727676
Validation loss: 2.498169248524839

Epoch: 5| Step: 5
Training loss: 2.1019625938782145
Validation loss: 2.5056087282318034

Epoch: 5| Step: 6
Training loss: 2.0174582963719714
Validation loss: 2.5587945602082676

Epoch: 5| Step: 7
Training loss: 1.6944226861123042
Validation loss: 2.5906400573501487

Epoch: 5| Step: 8
Training loss: 2.262094627863237
Validation loss: 2.5948257781463577

Epoch: 5| Step: 9
Training loss: 1.9128681426920922
Validation loss: 2.5925320749435294

Epoch: 5| Step: 10
Training loss: 1.7453239502014664
Validation loss: 2.579122982107123

Epoch: 5| Step: 11
Training loss: 1.3132262264345982
Validation loss: 2.5727069913445826

Epoch: 372| Step: 0
Training loss: 1.9439829990287196
Validation loss: 2.561023868503187

Epoch: 5| Step: 1
Training loss: 1.39612247072466
Validation loss: 2.5685350597328696

Epoch: 5| Step: 2
Training loss: 1.3825246651434178
Validation loss: 2.5571553037896892

Epoch: 5| Step: 3
Training loss: 2.3260266365172697
Validation loss: 2.569023624675586

Epoch: 5| Step: 4
Training loss: 2.4124845514148747
Validation loss: 2.572862795730417

Epoch: 5| Step: 5
Training loss: 1.5085957128590044
Validation loss: 2.608363577989317

Epoch: 5| Step: 6
Training loss: 2.2534489159406634
Validation loss: 2.5736382910058415

Epoch: 5| Step: 7
Training loss: 1.6971168584561593
Validation loss: 2.545337275194613

Epoch: 5| Step: 8
Training loss: 2.3805930886066458
Validation loss: 2.580030746467736

Epoch: 5| Step: 9
Training loss: 1.7612576103181399
Validation loss: 2.5536571159064274

Epoch: 5| Step: 10
Training loss: 2.0516672890623724
Validation loss: 2.5802152232906015

Epoch: 5| Step: 11
Training loss: 1.9107115392830722
Validation loss: 2.553483595736444

Epoch: 373| Step: 0
Training loss: 2.0945030110898277
Validation loss: 2.546516837931178

Epoch: 5| Step: 1
Training loss: 1.7312617497785647
Validation loss: 2.558169714658584

Epoch: 5| Step: 2
Training loss: 2.3512143102246084
Validation loss: 2.5499567955383666

Epoch: 5| Step: 3
Training loss: 1.6185649221066094
Validation loss: 2.542892978396825

Epoch: 5| Step: 4
Training loss: 1.87149553225955
Validation loss: 2.585225398119826

Epoch: 5| Step: 5
Training loss: 2.126604596351285
Validation loss: 2.590591955491864

Epoch: 5| Step: 6
Training loss: 1.0806903449136855
Validation loss: 2.6139832120743995

Epoch: 5| Step: 7
Training loss: 1.812499605376102
Validation loss: 2.619533910388773

Epoch: 5| Step: 8
Training loss: 2.302984507195144
Validation loss: 2.5757004829805177

Epoch: 5| Step: 9
Training loss: 1.5832922160515102
Validation loss: 2.5881531396309647

Epoch: 5| Step: 10
Training loss: 2.481545714621946
Validation loss: 2.5438898296492845

Epoch: 5| Step: 11
Training loss: 1.415282929377507
Validation loss: 2.5498064991518303

Epoch: 374| Step: 0
Training loss: 2.588156862779012
Validation loss: 2.527328919608437

Epoch: 5| Step: 1
Training loss: 1.6933872524197513
Validation loss: 2.4964887040897104

Epoch: 5| Step: 2
Training loss: 2.652577003705943
Validation loss: 2.519043568177709

Epoch: 5| Step: 3
Training loss: 1.521610749349922
Validation loss: 2.5139084284522415

Epoch: 5| Step: 4
Training loss: 1.9285882452075176
Validation loss: 2.5536155707189443

Epoch: 5| Step: 5
Training loss: 1.9267248971624629
Validation loss: 2.5220614441970497

Epoch: 5| Step: 6
Training loss: 1.532552204331939
Validation loss: 2.5544357467402308

Epoch: 5| Step: 7
Training loss: 2.2377931285627533
Validation loss: 2.4914137576893127

Epoch: 5| Step: 8
Training loss: 1.4155480606021082
Validation loss: 2.5283384002003184

Epoch: 5| Step: 9
Training loss: 2.0934655295176965
Validation loss: 2.523754930559103

Epoch: 5| Step: 10
Training loss: 1.4764752236059504
Validation loss: 2.5183438166832066

Epoch: 5| Step: 11
Training loss: 0.5047738051655736
Validation loss: 2.4977844732767474

Epoch: 375| Step: 0
Training loss: 1.2517845766393896
Validation loss: 2.5277976444590866

Epoch: 5| Step: 1
Training loss: 1.5050431351167353
Validation loss: 2.5215835276009138

Epoch: 5| Step: 2
Training loss: 1.9354238769375043
Validation loss: 2.5217230713627616

Epoch: 5| Step: 3
Training loss: 1.630067041223663
Validation loss: 2.5184958447251744

Epoch: 5| Step: 4
Training loss: 2.1574741150683456
Validation loss: 2.51714801690274

Epoch: 5| Step: 5
Training loss: 1.7401543629894591
Validation loss: 2.530652937310537

Epoch: 5| Step: 6
Training loss: 2.065504717534961
Validation loss: 2.512230511979775

Epoch: 5| Step: 7
Training loss: 2.611469364840368
Validation loss: 2.523456352958681

Epoch: 5| Step: 8
Training loss: 2.5395146832928837
Validation loss: 2.5101544446371777

Epoch: 5| Step: 9
Training loss: 1.6946489995810359
Validation loss: 2.5327254732035276

Epoch: 5| Step: 10
Training loss: 1.6642896470328057
Validation loss: 2.547172263804263

Epoch: 5| Step: 11
Training loss: 2.206969349761095
Validation loss: 2.5844923785367815

Epoch: 376| Step: 0
Training loss: 2.1106311589931446
Validation loss: 2.5618234493370284

Epoch: 5| Step: 1
Training loss: 2.122842254183061
Validation loss: 2.5521353262191844

Epoch: 5| Step: 2
Training loss: 1.8273710342594867
Validation loss: 2.553001644713991

Epoch: 5| Step: 3
Training loss: 1.5577869286920651
Validation loss: 2.594809844174007

Epoch: 5| Step: 4
Training loss: 2.058897397775778
Validation loss: 2.5887189276092357

Epoch: 5| Step: 5
Training loss: 1.7090065567756887
Validation loss: 2.5987669021242725

Epoch: 5| Step: 6
Training loss: 1.923583844936892
Validation loss: 2.5534343893103553

Epoch: 5| Step: 7
Training loss: 1.7286266571418751
Validation loss: 2.550613787276743

Epoch: 5| Step: 8
Training loss: 1.9146523325887392
Validation loss: 2.581216607635988

Epoch: 5| Step: 9
Training loss: 2.3042115835418664
Validation loss: 2.559724878997537

Epoch: 5| Step: 10
Training loss: 1.9231119904622032
Validation loss: 2.538538161692641

Epoch: 5| Step: 11
Training loss: 0.6807025696029683
Validation loss: 2.529892192285131

Epoch: 377| Step: 0
Training loss: 1.832029558193182
Validation loss: 2.536141042165975

Epoch: 5| Step: 1
Training loss: 1.7605941803346872
Validation loss: 2.5443227965021253

Epoch: 5| Step: 2
Training loss: 2.14760826059999
Validation loss: 2.5403648479441325

Epoch: 5| Step: 3
Training loss: 1.8906988334425787
Validation loss: 2.5542593625430277

Epoch: 5| Step: 4
Training loss: 1.9001716887552098
Validation loss: 2.5687476344534694

Epoch: 5| Step: 5
Training loss: 1.9006875601059101
Validation loss: 2.602126842152336

Epoch: 5| Step: 6
Training loss: 1.9063406750735026
Validation loss: 2.5618277924118527

Epoch: 5| Step: 7
Training loss: 1.6237895565486
Validation loss: 2.5882296166229155

Epoch: 5| Step: 8
Training loss: 2.1761870904601808
Validation loss: 2.5967395283495334

Epoch: 5| Step: 9
Training loss: 1.7566745041389487
Validation loss: 2.5797011364476865

Epoch: 5| Step: 10
Training loss: 2.050930286623214
Validation loss: 2.6085754700071906

Epoch: 5| Step: 11
Training loss: 1.7625737790296403
Validation loss: 2.5460889516002743

Epoch: 378| Step: 0
Training loss: 2.3072819993022526
Validation loss: 2.495456389321593

Epoch: 5| Step: 1
Training loss: 1.780653468848739
Validation loss: 2.4681171418914416

Epoch: 5| Step: 2
Training loss: 1.7369422127044578
Validation loss: 2.462806835357627

Epoch: 5| Step: 3
Training loss: 1.2238221383579986
Validation loss: 2.4611734791800006

Epoch: 5| Step: 4
Training loss: 2.6161616350279355
Validation loss: 2.4303458937785734

Epoch: 5| Step: 5
Training loss: 2.194576262151295
Validation loss: 2.4388396013628992

Epoch: 5| Step: 6
Training loss: 1.6922213592382378
Validation loss: 2.45087950483886

Epoch: 5| Step: 7
Training loss: 1.9190130246084687
Validation loss: 2.4405697867204372

Epoch: 5| Step: 8
Training loss: 1.5575248858329724
Validation loss: 2.450627949258952

Epoch: 5| Step: 9
Training loss: 2.207389653905146
Validation loss: 2.46911183051626

Epoch: 5| Step: 10
Training loss: 2.0809699067667107
Validation loss: 2.5178978526815863

Epoch: 5| Step: 11
Training loss: 1.6442665013846398
Validation loss: 2.5842005917219693

Epoch: 379| Step: 0
Training loss: 2.344553796900655
Validation loss: 2.6025719311936606

Epoch: 5| Step: 1
Training loss: 1.944833351782315
Validation loss: 2.6084438764184124

Epoch: 5| Step: 2
Training loss: 1.4463828582537013
Validation loss: 2.6455982559381956

Epoch: 5| Step: 3
Training loss: 2.0055614870546687
Validation loss: 2.610300193211718

Epoch: 5| Step: 4
Training loss: 1.8549584259145373
Validation loss: 2.5971499262713347

Epoch: 5| Step: 5
Training loss: 1.8306420759066901
Validation loss: 2.5854098923681765

Epoch: 5| Step: 6
Training loss: 1.8920692413192846
Validation loss: 2.610275615667653

Epoch: 5| Step: 7
Training loss: 1.8694222456338492
Validation loss: 2.591548157452977

Epoch: 5| Step: 8
Training loss: 2.519643287237675
Validation loss: 2.556872336716416

Epoch: 5| Step: 9
Training loss: 1.3073774464138743
Validation loss: 2.564772846234572

Epoch: 5| Step: 10
Training loss: 1.5258401557579555
Validation loss: 2.560625817551163

Epoch: 5| Step: 11
Training loss: 1.7534843906026532
Validation loss: 2.5536126413871783

Epoch: 380| Step: 0
Training loss: 1.9441811822359436
Validation loss: 2.5404731587810985

Epoch: 5| Step: 1
Training loss: 1.8847071188903521
Validation loss: 2.578089896839719

Epoch: 5| Step: 2
Training loss: 2.3140082724513205
Validation loss: 2.5471344213064837

Epoch: 5| Step: 3
Training loss: 1.717648586747814
Validation loss: 2.5520440403514955

Epoch: 5| Step: 4
Training loss: 1.6148949927332525
Validation loss: 2.538973899664837

Epoch: 5| Step: 5
Training loss: 2.03647352702399
Validation loss: 2.5210858420858844

Epoch: 5| Step: 6
Training loss: 1.482686819492456
Validation loss: 2.521004014240112

Epoch: 5| Step: 7
Training loss: 2.3777113044613474
Validation loss: 2.513954089450855

Epoch: 5| Step: 8
Training loss: 1.5030645219528402
Validation loss: 2.5498512874510335

Epoch: 5| Step: 9
Training loss: 2.2141666622063756
Validation loss: 2.5335817056597603

Epoch: 5| Step: 10
Training loss: 2.079135964370152
Validation loss: 2.587848429785723

Epoch: 5| Step: 11
Training loss: 1.1212700362950991
Validation loss: 2.5809759694995367

Epoch: 381| Step: 0
Training loss: 1.7855375120676498
Validation loss: 2.5881677443201805

Epoch: 5| Step: 1
Training loss: 2.124353871567321
Validation loss: 2.6088820275415587

Epoch: 5| Step: 2
Training loss: 2.146479043441968
Validation loss: 2.617959750289118

Epoch: 5| Step: 3
Training loss: 2.2904667111359154
Validation loss: 2.6325243179970794

Epoch: 5| Step: 4
Training loss: 1.7243989533118795
Validation loss: 2.6295943547610583

Epoch: 5| Step: 5
Training loss: 1.6652549089154098
Validation loss: 2.665688222826317

Epoch: 5| Step: 6
Training loss: 1.791933180333846
Validation loss: 2.6213755638501888

Epoch: 5| Step: 7
Training loss: 1.7100217275744936
Validation loss: 2.6497230598003245

Epoch: 5| Step: 8
Training loss: 1.683632693094776
Validation loss: 2.6186236526308795

Epoch: 5| Step: 9
Training loss: 1.5986603284179377
Validation loss: 2.598156579194085

Epoch: 5| Step: 10
Training loss: 2.487001386346803
Validation loss: 2.5958157972495615

Epoch: 5| Step: 11
Training loss: 2.4896918450067793
Validation loss: 2.586152189779632

Epoch: 382| Step: 0
Training loss: 2.128334682626478
Validation loss: 2.547683287220405

Epoch: 5| Step: 1
Training loss: 2.4634787381437113
Validation loss: 2.5405747082163948

Epoch: 5| Step: 2
Training loss: 1.5259839026375766
Validation loss: 2.535673416906577

Epoch: 5| Step: 3
Training loss: 1.5081960555915968
Validation loss: 2.512045020887299

Epoch: 5| Step: 4
Training loss: 1.8363806656374917
Validation loss: 2.5097167132765823

Epoch: 5| Step: 5
Training loss: 1.7893533928273104
Validation loss: 2.541160460128539

Epoch: 5| Step: 6
Training loss: 2.4100909602937497
Validation loss: 2.5239014095783547

Epoch: 5| Step: 7
Training loss: 2.2210849779232884
Validation loss: 2.550675370967581

Epoch: 5| Step: 8
Training loss: 1.9330348584642973
Validation loss: 2.5347419208185027

Epoch: 5| Step: 9
Training loss: 1.6276603343173022
Validation loss: 2.55669205829747

Epoch: 5| Step: 10
Training loss: 1.4951332136275717
Validation loss: 2.570857565150962

Epoch: 5| Step: 11
Training loss: 2.1483137615289936
Validation loss: 2.5981832787073227

Epoch: 383| Step: 0
Training loss: 2.4490542318524104
Validation loss: 2.5571332339889423

Epoch: 5| Step: 1
Training loss: 1.5038701833388317
Validation loss: 2.5262298015785514

Epoch: 5| Step: 2
Training loss: 1.9494498503839455
Validation loss: 2.5249776047635644

Epoch: 5| Step: 3
Training loss: 2.0260574876286874
Validation loss: 2.491013935214758

Epoch: 5| Step: 4
Training loss: 2.078926792208143
Validation loss: 2.5250479280530946

Epoch: 5| Step: 5
Training loss: 1.662146096098472
Validation loss: 2.5292709545638576

Epoch: 5| Step: 6
Training loss: 1.33981776976907
Validation loss: 2.526271362610745

Epoch: 5| Step: 7
Training loss: 1.8143189609558017
Validation loss: 2.497842938944702

Epoch: 5| Step: 8
Training loss: 1.7013485244149509
Validation loss: 2.509281021613307

Epoch: 5| Step: 9
Training loss: 1.7014653930417956
Validation loss: 2.495306612253459

Epoch: 5| Step: 10
Training loss: 2.301705917789787
Validation loss: 2.498649602001816

Epoch: 5| Step: 11
Training loss: 2.9145520491939987
Validation loss: 2.5062919475250873

Epoch: 384| Step: 0
Training loss: 1.5739394477335638
Validation loss: 2.507732134568195

Epoch: 5| Step: 1
Training loss: 1.8633754234587296
Validation loss: 2.5858780430530466

Epoch: 5| Step: 2
Training loss: 1.6207375744118706
Validation loss: 2.6346262675108223

Epoch: 5| Step: 3
Training loss: 1.750382177310812
Validation loss: 2.6836432721243577

Epoch: 5| Step: 4
Training loss: 1.786117261648918
Validation loss: 2.689247106835154

Epoch: 5| Step: 5
Training loss: 2.1435432312122673
Validation loss: 2.6644946854325346

Epoch: 5| Step: 6
Training loss: 2.557636856638524
Validation loss: 2.635891752179587

Epoch: 5| Step: 7
Training loss: 2.1539653893101316
Validation loss: 2.54108023262037

Epoch: 5| Step: 8
Training loss: 1.7313151818960408
Validation loss: 2.5377451565268836

Epoch: 5| Step: 9
Training loss: 2.1523272449670587
Validation loss: 2.5140488032475066

Epoch: 5| Step: 10
Training loss: 2.0101046410646846
Validation loss: 2.5317211301364266

Epoch: 5| Step: 11
Training loss: 0.8307264959756778
Validation loss: 2.5262328413101085

Epoch: 385| Step: 0
Training loss: 2.284546234350972
Validation loss: 2.5289772293206543

Epoch: 5| Step: 1
Training loss: 1.8485563315779279
Validation loss: 2.5120154720189825

Epoch: 5| Step: 2
Training loss: 1.8398134913456914
Validation loss: 2.518833639477389

Epoch: 5| Step: 3
Training loss: 2.002511355097624
Validation loss: 2.4822071902016676

Epoch: 5| Step: 4
Training loss: 2.1635078242640713
Validation loss: 2.5310816375249816

Epoch: 5| Step: 5
Training loss: 1.9827178884408727
Validation loss: 2.5114847472700608

Epoch: 5| Step: 6
Training loss: 1.556107146052915
Validation loss: 2.5129249666471503

Epoch: 5| Step: 7
Training loss: 2.0332159065775604
Validation loss: 2.513756865927211

Epoch: 5| Step: 8
Training loss: 1.8686572559014023
Validation loss: 2.5195721999987963

Epoch: 5| Step: 9
Training loss: 1.2258373473771842
Validation loss: 2.5029264170486014

Epoch: 5| Step: 10
Training loss: 1.7567491494031904
Validation loss: 2.5483558928620273

Epoch: 5| Step: 11
Training loss: 1.4289986874071825
Validation loss: 2.5404485782806536

Epoch: 386| Step: 0
Training loss: 1.6057643200638025
Validation loss: 2.56696627006691

Epoch: 5| Step: 1
Training loss: 1.6009441391529664
Validation loss: 2.5690700809583604

Epoch: 5| Step: 2
Training loss: 1.6600754662100676
Validation loss: 2.5358153291247616

Epoch: 5| Step: 3
Training loss: 2.3687481158004955
Validation loss: 2.5294657293683662

Epoch: 5| Step: 4
Training loss: 2.296068530026941
Validation loss: 2.5477547364596256

Epoch: 5| Step: 5
Training loss: 2.200170280629076
Validation loss: 2.5456319010243202

Epoch: 5| Step: 6
Training loss: 2.074927027694605
Validation loss: 2.5365349655533653

Epoch: 5| Step: 7
Training loss: 1.4023135721258928
Validation loss: 2.555885963198645

Epoch: 5| Step: 8
Training loss: 1.7081377646300435
Validation loss: 2.5255417568362493

Epoch: 5| Step: 9
Training loss: 2.223428441214856
Validation loss: 2.5310113248817885

Epoch: 5| Step: 10
Training loss: 1.543698681430114
Validation loss: 2.4979548950600092

Epoch: 5| Step: 11
Training loss: 0.9981977195739684
Validation loss: 2.5065516731863196

Epoch: 387| Step: 0
Training loss: 1.5588926253421662
Validation loss: 2.4986272579590483

Epoch: 5| Step: 1
Training loss: 1.9037190504557748
Validation loss: 2.51794694675463

Epoch: 5| Step: 2
Training loss: 1.7966386059048327
Validation loss: 2.4902160584019235

Epoch: 5| Step: 3
Training loss: 2.0258467187390874
Validation loss: 2.535646435292288

Epoch: 5| Step: 4
Training loss: 1.8396106094406106
Validation loss: 2.5294539315693036

Epoch: 5| Step: 5
Training loss: 2.1167142557316234
Validation loss: 2.54953608905551

Epoch: 5| Step: 6
Training loss: 1.586383174419195
Validation loss: 2.5526220525086285

Epoch: 5| Step: 7
Training loss: 1.9024497126024968
Validation loss: 2.5230101626077226

Epoch: 5| Step: 8
Training loss: 1.264512550388258
Validation loss: 2.51026658576415

Epoch: 5| Step: 9
Training loss: 2.1525535412020997
Validation loss: 2.5348638670607704

Epoch: 5| Step: 10
Training loss: 2.08522312918897
Validation loss: 2.528878160379017

Epoch: 5| Step: 11
Training loss: 0.8380078498272377
Validation loss: 2.5274943287726375

Epoch: 388| Step: 0
Training loss: 1.1805506699903536
Validation loss: 2.531081519779577

Epoch: 5| Step: 1
Training loss: 1.9251830620853392
Validation loss: 2.5640524410505345

Epoch: 5| Step: 2
Training loss: 2.044511784893429
Validation loss: 2.554840623814289

Epoch: 5| Step: 3
Training loss: 1.5776328650864029
Validation loss: 2.5252269446957

Epoch: 5| Step: 4
Training loss: 1.3460424075793505
Validation loss: 2.5378003137674288

Epoch: 5| Step: 5
Training loss: 2.378863855745247
Validation loss: 2.525850998017418

Epoch: 5| Step: 6
Training loss: 1.9975489856504751
Validation loss: 2.5326696857255495

Epoch: 5| Step: 7
Training loss: 2.0519911330628253
Validation loss: 2.536847871220414

Epoch: 5| Step: 8
Training loss: 1.2446833075228416
Validation loss: 2.539136390588998

Epoch: 5| Step: 9
Training loss: 2.062785966873295
Validation loss: 2.510953799568514

Epoch: 5| Step: 10
Training loss: 2.2159055287436997
Validation loss: 2.5623464189421656

Epoch: 5| Step: 11
Training loss: 1.4308039574041287
Validation loss: 2.557959550294152

Epoch: 389| Step: 0
Training loss: 1.3417272202626547
Validation loss: 2.554240966409026

Epoch: 5| Step: 1
Training loss: 2.493690444120403
Validation loss: 2.526676443641144

Epoch: 5| Step: 2
Training loss: 2.0411878011259357
Validation loss: 2.579641362468321

Epoch: 5| Step: 3
Training loss: 1.781379226547858
Validation loss: 2.5389722172262643

Epoch: 5| Step: 4
Training loss: 1.363456736640301
Validation loss: 2.5358596202199495

Epoch: 5| Step: 5
Training loss: 1.746146659988177
Validation loss: 2.5076467235434228

Epoch: 5| Step: 6
Training loss: 1.9592337939229911
Validation loss: 2.4967327663060748

Epoch: 5| Step: 7
Training loss: 1.6776758967589778
Validation loss: 2.496798476032031

Epoch: 5| Step: 8
Training loss: 2.074964141535865
Validation loss: 2.519153150630946

Epoch: 5| Step: 9
Training loss: 1.8285447641327395
Validation loss: 2.497733793704548

Epoch: 5| Step: 10
Training loss: 1.6431843005391482
Validation loss: 2.5002776945380862

Epoch: 5| Step: 11
Training loss: 2.532117812605259
Validation loss: 2.5123421472335195

Epoch: 390| Step: 0
Training loss: 1.7886596625953135
Validation loss: 2.5325974971095726

Epoch: 5| Step: 1
Training loss: 1.521245621837124
Validation loss: 2.5725991919374516

Epoch: 5| Step: 2
Training loss: 2.391228693115897
Validation loss: 2.630798960300976

Epoch: 5| Step: 3
Training loss: 1.5760524472886726
Validation loss: 2.6612531666268735

Epoch: 5| Step: 4
Training loss: 1.5693729303696513
Validation loss: 2.673110193058889

Epoch: 5| Step: 5
Training loss: 2.0926221400337597
Validation loss: 2.6946099918400126

Epoch: 5| Step: 6
Training loss: 1.4029289448473383
Validation loss: 2.686842390674316

Epoch: 5| Step: 7
Training loss: 1.2980232670554568
Validation loss: 2.6421061092137585

Epoch: 5| Step: 8
Training loss: 2.5262549765800673
Validation loss: 2.6255869284943905

Epoch: 5| Step: 9
Training loss: 2.0579318696247184
Validation loss: 2.5537438861576436

Epoch: 5| Step: 10
Training loss: 1.599844257404207
Validation loss: 2.5097714633106847

Epoch: 5| Step: 11
Training loss: 2.579896630278974
Validation loss: 2.516044423776009

Epoch: 391| Step: 0
Training loss: 2.1776424097734113
Validation loss: 2.4756741058479586

Epoch: 5| Step: 1
Training loss: 2.0804192061905042
Validation loss: 2.468977861310829

Epoch: 5| Step: 2
Training loss: 2.152442334473763
Validation loss: 2.4719315200497607

Epoch: 5| Step: 3
Training loss: 2.048792399630438
Validation loss: 2.5031664623838075

Epoch: 5| Step: 4
Training loss: 1.3094957573681036
Validation loss: 2.4954626591965803

Epoch: 5| Step: 5
Training loss: 2.0425708740712643
Validation loss: 2.480554896583365

Epoch: 5| Step: 6
Training loss: 1.4928564998601856
Validation loss: 2.4904937628994888

Epoch: 5| Step: 7
Training loss: 2.0327497374384658
Validation loss: 2.4881918435475447

Epoch: 5| Step: 8
Training loss: 1.651566270663343
Validation loss: 2.5117918313381282

Epoch: 5| Step: 9
Training loss: 2.1212495356723906
Validation loss: 2.5289015256004603

Epoch: 5| Step: 10
Training loss: 1.922763030037174
Validation loss: 2.5467853257320043

Epoch: 5| Step: 11
Training loss: 0.8881980890618985
Validation loss: 2.572281497799178

Epoch: 392| Step: 0
Training loss: 1.8235679625556729
Validation loss: 2.5985429708362924

Epoch: 5| Step: 1
Training loss: 2.114428760410036
Validation loss: 2.59586421944096

Epoch: 5| Step: 2
Training loss: 1.9042924929837404
Validation loss: 2.613287100336343

Epoch: 5| Step: 3
Training loss: 2.0196188459454296
Validation loss: 2.5891869173791684

Epoch: 5| Step: 4
Training loss: 1.4489128838803467
Validation loss: 2.60572223488308

Epoch: 5| Step: 5
Training loss: 1.9549812346238322
Validation loss: 2.5659352242385323

Epoch: 5| Step: 6
Training loss: 2.1587088014065303
Validation loss: 2.582733601255257

Epoch: 5| Step: 7
Training loss: 2.013478400244093
Validation loss: 2.540749530313119

Epoch: 5| Step: 8
Training loss: 1.6840285870352392
Validation loss: 2.529637026896872

Epoch: 5| Step: 9
Training loss: 1.4269463782016538
Validation loss: 2.5387489399108727

Epoch: 5| Step: 10
Training loss: 1.5735804776005178
Validation loss: 2.5295598898563534

Epoch: 5| Step: 11
Training loss: 1.815753450298222
Validation loss: 2.5200003805740514

Epoch: 393| Step: 0
Training loss: 1.7637146599227969
Validation loss: 2.4996535100834403

Epoch: 5| Step: 1
Training loss: 1.551271836636625
Validation loss: 2.489362546608848

Epoch: 5| Step: 2
Training loss: 1.4457670579537556
Validation loss: 2.4796396066182522

Epoch: 5| Step: 3
Training loss: 1.9846533632653731
Validation loss: 2.4958023832521783

Epoch: 5| Step: 4
Training loss: 2.486426508081494
Validation loss: 2.5090293190126047

Epoch: 5| Step: 5
Training loss: 1.943395014297106
Validation loss: 2.502162478897414

Epoch: 5| Step: 6
Training loss: 2.1876205411124143
Validation loss: 2.5037438493216007

Epoch: 5| Step: 7
Training loss: 1.70736188327156
Validation loss: 2.5068428288122213

Epoch: 5| Step: 8
Training loss: 0.9299835887609442
Validation loss: 2.56010011198758

Epoch: 5| Step: 9
Training loss: 1.8374343289428035
Validation loss: 2.5407021769257763

Epoch: 5| Step: 10
Training loss: 1.617980909831404
Validation loss: 2.5540196968181403

Epoch: 5| Step: 11
Training loss: 3.382788959800095
Validation loss: 2.6031162177857823

Epoch: 394| Step: 0
Training loss: 2.1936506721637277
Validation loss: 2.5853076140781295

Epoch: 5| Step: 1
Training loss: 1.1419974131078865
Validation loss: 2.5992086719332463

Epoch: 5| Step: 2
Training loss: 1.897508558774199
Validation loss: 2.5929414454048607

Epoch: 5| Step: 3
Training loss: 1.8780367102158075
Validation loss: 2.621636949810516

Epoch: 5| Step: 4
Training loss: 1.69315548981637
Validation loss: 2.612580274264265

Epoch: 5| Step: 5
Training loss: 1.4753948620651283
Validation loss: 2.59182215670856

Epoch: 5| Step: 6
Training loss: 2.1276897909676906
Validation loss: 2.541201855156046

Epoch: 5| Step: 7
Training loss: 2.2041966422433825
Validation loss: 2.5323840807161253

Epoch: 5| Step: 8
Training loss: 2.1308726896854293
Validation loss: 2.5636879291891024

Epoch: 5| Step: 9
Training loss: 1.8417202396569652
Validation loss: 2.5408074569562644

Epoch: 5| Step: 10
Training loss: 1.5930804173729087
Validation loss: 2.4896827076720207

Epoch: 5| Step: 11
Training loss: 1.5112572096028725
Validation loss: 2.5255983822345134

Epoch: 395| Step: 0
Training loss: 2.0355396458759683
Validation loss: 2.51494394880747

Epoch: 5| Step: 1
Training loss: 1.7594505307397077
Validation loss: 2.536363832304754

Epoch: 5| Step: 2
Training loss: 1.3014242055265484
Validation loss: 2.542363697894576

Epoch: 5| Step: 3
Training loss: 1.4337660350750958
Validation loss: 2.5403479095386263

Epoch: 5| Step: 4
Training loss: 1.5454557439218046
Validation loss: 2.5422611297029682

Epoch: 5| Step: 5
Training loss: 1.8891003348550697
Validation loss: 2.550248807568211

Epoch: 5| Step: 6
Training loss: 1.5454034452609027
Validation loss: 2.5562226080262387

Epoch: 5| Step: 7
Training loss: 1.2864108469406128
Validation loss: 2.5623782718247448

Epoch: 5| Step: 8
Training loss: 3.0535758647073825
Validation loss: 2.5743836083345037

Epoch: 5| Step: 9
Training loss: 1.9535242511854012
Validation loss: 2.5639389502688275

Epoch: 5| Step: 10
Training loss: 1.6431854613024044
Validation loss: 2.5660137416340825

Epoch: 5| Step: 11
Training loss: 1.3748052198991858
Validation loss: 2.5947698250464764

Epoch: 396| Step: 0
Training loss: 2.1994598419137836
Validation loss: 2.573335359974872

Epoch: 5| Step: 1
Training loss: 1.3145815374218037
Validation loss: 2.5458895018937415

Epoch: 5| Step: 2
Training loss: 1.6663343654603173
Validation loss: 2.560273668741312

Epoch: 5| Step: 3
Training loss: 1.8568321599547735
Validation loss: 2.579076086763713

Epoch: 5| Step: 4
Training loss: 1.6717469353514405
Validation loss: 2.591210723268908

Epoch: 5| Step: 5
Training loss: 1.5464745205427692
Validation loss: 2.592134964870262

Epoch: 5| Step: 6
Training loss: 1.6628885202392276
Validation loss: 2.5691527675059254

Epoch: 5| Step: 7
Training loss: 2.183076582316299
Validation loss: 2.5420437725869407

Epoch: 5| Step: 8
Training loss: 1.6832355728970223
Validation loss: 2.5396796801761843

Epoch: 5| Step: 9
Training loss: 2.0697899500841825
Validation loss: 2.516854051114872

Epoch: 5| Step: 10
Training loss: 1.8980384689870327
Validation loss: 2.523822097680592

Epoch: 5| Step: 11
Training loss: 1.2847398819726328
Validation loss: 2.4898606602110775

Epoch: 397| Step: 0
Training loss: 1.587365846146864
Validation loss: 2.479546499139522

Epoch: 5| Step: 1
Training loss: 2.265310120899047
Validation loss: 2.4870890381727864

Epoch: 5| Step: 2
Training loss: 1.6855852779111231
Validation loss: 2.474852652610901

Epoch: 5| Step: 3
Training loss: 1.5602958391347899
Validation loss: 2.4854547925094237

Epoch: 5| Step: 4
Training loss: 1.3366720845801567
Validation loss: 2.512617853035487

Epoch: 5| Step: 5
Training loss: 1.5790182928000525
Validation loss: 2.496564391912136

Epoch: 5| Step: 6
Training loss: 1.7788584532282787
Validation loss: 2.5593486303229382

Epoch: 5| Step: 7
Training loss: 1.7224366616838407
Validation loss: 2.558458044127207

Epoch: 5| Step: 8
Training loss: 2.539939470696305
Validation loss: 2.5599987336617556

Epoch: 5| Step: 9
Training loss: 1.650746685195176
Validation loss: 2.549544631979932

Epoch: 5| Step: 10
Training loss: 1.5136867596294372
Validation loss: 2.5637232527941007

Epoch: 5| Step: 11
Training loss: 2.1541220074370915
Validation loss: 2.5561504161187414

Epoch: 398| Step: 0
Training loss: 2.1253556346624682
Validation loss: 2.512933946336191

Epoch: 5| Step: 1
Training loss: 1.797817348007543
Validation loss: 2.47188063796502

Epoch: 5| Step: 2
Training loss: 1.5364892816390072
Validation loss: 2.4791675869488543

Epoch: 5| Step: 3
Training loss: 1.776396446553288
Validation loss: 2.4886659158182156

Epoch: 5| Step: 4
Training loss: 2.0147416892499783
Validation loss: 2.5118295458240145

Epoch: 5| Step: 5
Training loss: 2.059938863569273
Validation loss: 2.4852101064021137

Epoch: 5| Step: 6
Training loss: 1.678226136866299
Validation loss: 2.4498200436434994

Epoch: 5| Step: 7
Training loss: 2.211815865128499
Validation loss: 2.45743519869303

Epoch: 5| Step: 8
Training loss: 2.0601802843331645
Validation loss: 2.5092056144403636

Epoch: 5| Step: 9
Training loss: 2.173385314534298
Validation loss: 2.51365520528084

Epoch: 5| Step: 10
Training loss: 2.34417029109186
Validation loss: 2.5016049716829913

Epoch: 5| Step: 11
Training loss: 0.9757986514614425
Validation loss: 2.5442111198006163

Epoch: 399| Step: 0
Training loss: 1.4218821263396708
Validation loss: 2.5162195999638746

Epoch: 5| Step: 1
Training loss: 2.2140226911090153
Validation loss: 2.557737196410172

Epoch: 5| Step: 2
Training loss: 1.9832853794979055
Validation loss: 2.5479563697243903

Epoch: 5| Step: 3
Training loss: 1.8453307406874913
Validation loss: 2.5804455880736623

Epoch: 5| Step: 4
Training loss: 2.054351431047301
Validation loss: 2.569567057258676

Epoch: 5| Step: 5
Training loss: 1.637960686562372
Validation loss: 2.6109397521390703

Epoch: 5| Step: 6
Training loss: 2.8111343459055775
Validation loss: 2.652537590213516

Epoch: 5| Step: 7
Training loss: 1.982774103753348
Validation loss: 2.684328381241275

Epoch: 5| Step: 8
Training loss: 1.8336993921287532
Validation loss: 2.6480452360508364

Epoch: 5| Step: 9
Training loss: 1.2550020272591924
Validation loss: 2.610463043089139

Epoch: 5| Step: 10
Training loss: 1.8049994525221738
Validation loss: 2.5767839585273635

Epoch: 5| Step: 11
Training loss: 2.2609149248937745
Validation loss: 2.5257967105875676

Epoch: 400| Step: 0
Training loss: 1.1140035862479707
Validation loss: 2.562598164546743

Epoch: 5| Step: 1
Training loss: 1.3835173712337088
Validation loss: 2.5616785512215

Epoch: 5| Step: 2
Training loss: 2.09872948950628
Validation loss: 2.5591079622286994

Epoch: 5| Step: 3
Training loss: 1.3264648832927644
Validation loss: 2.5771105764599422

Epoch: 5| Step: 4
Training loss: 2.7841235971035796
Validation loss: 2.5726235038649548

Epoch: 5| Step: 5
Training loss: 2.4307754877282934
Validation loss: 2.575995062486066

Epoch: 5| Step: 6
Training loss: 1.9053067234246428
Validation loss: 2.575396108869796

Epoch: 5| Step: 7
Training loss: 1.9921568625095138
Validation loss: 2.5591160054369655

Epoch: 5| Step: 8
Training loss: 1.563222641730348
Validation loss: 2.5499423031419304

Epoch: 5| Step: 9
Training loss: 1.1658515239620706
Validation loss: 2.5208727101857695

Epoch: 5| Step: 10
Training loss: 1.9517311310430774
Validation loss: 2.556798387540753

Epoch: 5| Step: 11
Training loss: 2.7564761460446885
Validation loss: 2.5457149703381576

Testing loss: 2.0492387240311425
