Epoch: 1| Step: 0
Training loss: 6.123419284820557
Validation loss: 5.339906553427379

Epoch: 5| Step: 1
Training loss: 5.5669426918029785
Validation loss: 5.338420609633128

Epoch: 5| Step: 2
Training loss: 5.355820655822754
Validation loss: 5.337054987748464

Epoch: 5| Step: 3
Training loss: 4.899048805236816
Validation loss: 5.335712571938832

Epoch: 5| Step: 4
Training loss: 4.553140163421631
Validation loss: 5.334224760532379

Epoch: 5| Step: 5
Training loss: 5.271129608154297
Validation loss: 5.332838416099548

Epoch: 5| Step: 6
Training loss: 4.855064392089844
Validation loss: 5.331419209639232

Epoch: 5| Step: 7
Training loss: 6.183719158172607
Validation loss: 5.329948385556539

Epoch: 5| Step: 8
Training loss: 6.022083282470703
Validation loss: 5.328456322352092

Epoch: 5| Step: 9
Training loss: 4.770402908325195
Validation loss: 5.326922555764516

Epoch: 5| Step: 10
Training loss: 5.927399635314941
Validation loss: 5.3254077434539795

Epoch: 5| Step: 11
Training loss: 4.838592529296875
Validation loss: 5.323796550432841

Epoch: 2| Step: 0
Training loss: 5.4254961013793945
Validation loss: 5.322154621283214

Epoch: 5| Step: 1
Training loss: 6.242948055267334
Validation loss: 5.320401390393575

Epoch: 5| Step: 2
Training loss: 4.6341400146484375
Validation loss: 5.31870832045873

Epoch: 5| Step: 3
Training loss: 5.300588607788086
Validation loss: 5.3168773253758745

Epoch: 5| Step: 4
Training loss: 4.642974376678467
Validation loss: 5.315012176831563

Epoch: 5| Step: 5
Training loss: 6.176273345947266
Validation loss: 5.312948703765869

Epoch: 5| Step: 6
Training loss: 5.399846076965332
Validation loss: 5.310807744661967

Epoch: 5| Step: 7
Training loss: 6.329163551330566
Validation loss: 5.308614730834961

Epoch: 5| Step: 8
Training loss: 4.885308742523193
Validation loss: 5.306324481964111

Epoch: 5| Step: 9
Training loss: 4.135743618011475
Validation loss: 5.303959846496582

Epoch: 5| Step: 10
Training loss: 6.089446067810059
Validation loss: 5.301443735758464

Epoch: 5| Step: 11
Training loss: 5.037552356719971
Validation loss: 5.29867559671402

Epoch: 3| Step: 0
Training loss: 4.94159460067749
Validation loss: 5.2958207329114275

Epoch: 5| Step: 1
Training loss: 4.635838985443115
Validation loss: 5.292938768863678

Epoch: 5| Step: 2
Training loss: 4.560433387756348
Validation loss: 5.289620916048686

Epoch: 5| Step: 3
Training loss: 4.809037685394287
Validation loss: 5.2863331238428755

Epoch: 5| Step: 4
Training loss: 5.241097927093506
Validation loss: 5.282965123653412

Epoch: 5| Step: 5
Training loss: 4.85839319229126
Validation loss: 5.279198884963989

Epoch: 5| Step: 6
Training loss: 6.215449810028076
Validation loss: 5.275257150332133

Epoch: 5| Step: 7
Training loss: 5.652436256408691
Validation loss: 5.271113932132721

Epoch: 5| Step: 8
Training loss: 6.234269618988037
Validation loss: 5.266803344090779

Epoch: 5| Step: 9
Training loss: 5.646045684814453
Validation loss: 5.262191534042358

Epoch: 5| Step: 10
Training loss: 5.90162992477417
Validation loss: 5.257364769776662

Epoch: 5| Step: 11
Training loss: 5.928046226501465
Validation loss: 5.2519392768541975

Epoch: 4| Step: 0
Training loss: 3.7818896770477295
Validation loss: 5.246423681577046

Epoch: 5| Step: 1
Training loss: 5.638976573944092
Validation loss: 5.240528643131256

Epoch: 5| Step: 2
Training loss: 4.724841117858887
Validation loss: 5.2346619963645935

Epoch: 5| Step: 3
Training loss: 5.826048851013184
Validation loss: 5.2280041972796125

Epoch: 5| Step: 4
Training loss: 5.754805088043213
Validation loss: 5.221213936805725

Epoch: 5| Step: 5
Training loss: 3.9864449501037598
Validation loss: 5.213972230752309

Epoch: 5| Step: 6
Training loss: 5.185647010803223
Validation loss: 5.206168333689372

Epoch: 5| Step: 7
Training loss: 6.361172199249268
Validation loss: 5.198585828145345

Epoch: 5| Step: 8
Training loss: 4.997937202453613
Validation loss: 5.190123438835144

Epoch: 5| Step: 9
Training loss: 5.705833435058594
Validation loss: 5.181271513303121

Epoch: 5| Step: 10
Training loss: 6.185492515563965
Validation loss: 5.172152956326802

Epoch: 5| Step: 11
Training loss: 4.975625038146973
Validation loss: 5.162855327129364

Epoch: 5| Step: 0
Training loss: 5.500100612640381
Validation loss: 5.152852515379588

Epoch: 5| Step: 1
Training loss: 5.762170791625977
Validation loss: 5.143204867839813

Epoch: 5| Step: 2
Training loss: 5.835421085357666
Validation loss: 5.132871528466542

Epoch: 5| Step: 3
Training loss: 5.414031505584717
Validation loss: 5.1223442157109575

Epoch: 5| Step: 4
Training loss: 4.565539360046387
Validation loss: 5.111983259518941

Epoch: 5| Step: 5
Training loss: 5.272177696228027
Validation loss: 5.101469993591309

Epoch: 5| Step: 6
Training loss: 4.605447292327881
Validation loss: 5.090391496817271

Epoch: 5| Step: 7
Training loss: 5.767611503601074
Validation loss: 5.080026030540466

Epoch: 5| Step: 8
Training loss: 4.988923072814941
Validation loss: 5.069442510604858

Epoch: 5| Step: 9
Training loss: 5.002440452575684
Validation loss: 5.0586113929748535

Epoch: 5| Step: 10
Training loss: 4.498188495635986
Validation loss: 5.048550705115001

Epoch: 5| Step: 11
Training loss: 3.7702090740203857
Validation loss: 5.038017193476359

Epoch: 6| Step: 0
Training loss: 5.482949733734131
Validation loss: 5.027830282847087

Epoch: 5| Step: 1
Training loss: 4.900190353393555
Validation loss: 5.017552495002747

Epoch: 5| Step: 2
Training loss: 4.755837917327881
Validation loss: 5.007069756587346

Epoch: 5| Step: 3
Training loss: 5.139100551605225
Validation loss: 4.997360706329346

Epoch: 5| Step: 4
Training loss: 5.820577144622803
Validation loss: 4.987417121728261

Epoch: 5| Step: 5
Training loss: 4.529694557189941
Validation loss: 4.978082935015361

Epoch: 5| Step: 6
Training loss: 4.3459367752075195
Validation loss: 4.968039830525716

Epoch: 5| Step: 7
Training loss: 5.179656982421875
Validation loss: 4.9587927261988325

Epoch: 5| Step: 8
Training loss: 5.922039031982422
Validation loss: 4.949357767899831

Epoch: 5| Step: 9
Training loss: 5.1486287117004395
Validation loss: 4.939778705437978

Epoch: 5| Step: 10
Training loss: 4.72173547744751
Validation loss: 4.930805206298828

Epoch: 5| Step: 11
Training loss: 3.674797534942627
Validation loss: 4.921741247177124

Epoch: 7| Step: 0
Training loss: 4.1347503662109375
Validation loss: 4.9130513270696

Epoch: 5| Step: 1
Training loss: 5.15629243850708
Validation loss: 4.905174930890401

Epoch: 5| Step: 2
Training loss: 5.16061544418335
Validation loss: 4.896813293298085

Epoch: 5| Step: 3
Training loss: 4.012052059173584
Validation loss: 4.8882923523585005

Epoch: 5| Step: 4
Training loss: 5.6333417892456055
Validation loss: 4.879483858744304

Epoch: 5| Step: 5
Training loss: 5.387705326080322
Validation loss: 4.8713099757830305

Epoch: 5| Step: 6
Training loss: 4.8211164474487305
Validation loss: 4.862797538439433

Epoch: 5| Step: 7
Training loss: 4.131746768951416
Validation loss: 4.854565481344859

Epoch: 5| Step: 8
Training loss: 5.329506874084473
Validation loss: 4.846497515837352

Epoch: 5| Step: 9
Training loss: 5.851199626922607
Validation loss: 4.83800611893336

Epoch: 5| Step: 10
Training loss: 4.851315021514893
Validation loss: 4.829921046892802

Epoch: 5| Step: 11
Training loss: 5.188987731933594
Validation loss: 4.821649491786957

Epoch: 8| Step: 0
Training loss: 4.447451591491699
Validation loss: 4.813761154810588

Epoch: 5| Step: 1
Training loss: 6.100494384765625
Validation loss: 4.805460969607036

Epoch: 5| Step: 2
Training loss: 4.56082820892334
Validation loss: 4.797533293565114

Epoch: 5| Step: 3
Training loss: 5.771766662597656
Validation loss: 4.789965550104777

Epoch: 5| Step: 4
Training loss: 4.2949347496032715
Validation loss: 4.782234758138657

Epoch: 5| Step: 5
Training loss: 4.410393714904785
Validation loss: 4.77481331427892

Epoch: 5| Step: 6
Training loss: 5.366305351257324
Validation loss: 4.766538600126903

Epoch: 5| Step: 7
Training loss: 4.974451541900635
Validation loss: 4.7589790026346845

Epoch: 5| Step: 8
Training loss: 3.317925214767456
Validation loss: 4.751260002454122

Epoch: 5| Step: 9
Training loss: 5.531564235687256
Validation loss: 4.743640383084615

Epoch: 5| Step: 10
Training loss: 4.6480937004089355
Validation loss: 4.735836644967397

Epoch: 5| Step: 11
Training loss: 5.209295749664307
Validation loss: 4.728502849737803

Epoch: 9| Step: 0
Training loss: 5.0741868019104
Validation loss: 4.721243580182393

Epoch: 5| Step: 1
Training loss: 4.656006813049316
Validation loss: 4.714444677035014

Epoch: 5| Step: 2
Training loss: 4.396605968475342
Validation loss: 4.70712810754776

Epoch: 5| Step: 3
Training loss: 4.362298011779785
Validation loss: 4.700360635916392

Epoch: 5| Step: 4
Training loss: 4.294892311096191
Validation loss: 4.693613926569621

Epoch: 5| Step: 5
Training loss: 5.3615498542785645
Validation loss: 4.687399605909984

Epoch: 5| Step: 6
Training loss: 5.822136878967285
Validation loss: 4.680757363637288

Epoch: 5| Step: 7
Training loss: 4.241488456726074
Validation loss: 4.674188146988551

Epoch: 5| Step: 8
Training loss: 4.150612831115723
Validation loss: 4.667669157187144

Epoch: 5| Step: 9
Training loss: 5.31747579574585
Validation loss: 4.661008834838867

Epoch: 5| Step: 10
Training loss: 4.896191596984863
Validation loss: 4.654318382342656

Epoch: 5| Step: 11
Training loss: 4.897045135498047
Validation loss: 4.647230366865794

Epoch: 10| Step: 0
Training loss: 5.448394775390625
Validation loss: 4.640368541081746

Epoch: 5| Step: 1
Training loss: 3.9170594215393066
Validation loss: 4.632555266221364

Epoch: 5| Step: 2
Training loss: 5.143285751342773
Validation loss: 4.62484735250473

Epoch: 5| Step: 3
Training loss: 4.266181468963623
Validation loss: 4.617454866568248

Epoch: 5| Step: 4
Training loss: 5.391884803771973
Validation loss: 4.609762668609619

Epoch: 5| Step: 5
Training loss: 3.979837417602539
Validation loss: 4.601909637451172

Epoch: 5| Step: 6
Training loss: 5.626978874206543
Validation loss: 4.594301720460256

Epoch: 5| Step: 7
Training loss: 3.919384717941284
Validation loss: 4.586241940657298

Epoch: 5| Step: 8
Training loss: 5.082701206207275
Validation loss: 4.578387538592021

Epoch: 5| Step: 9
Training loss: 4.0609636306762695
Validation loss: 4.570380508899689

Epoch: 5| Step: 10
Training loss: 4.78917932510376
Validation loss: 4.562788685162862

Epoch: 5| Step: 11
Training loss: 5.091091156005859
Validation loss: 4.554932256539662

Epoch: 11| Step: 0
Training loss: 4.892369747161865
Validation loss: 4.546511034170787

Epoch: 5| Step: 1
Training loss: 3.8960890769958496
Validation loss: 4.538891593615214

Epoch: 5| Step: 2
Training loss: 4.863870620727539
Validation loss: 4.531167447566986

Epoch: 5| Step: 3
Training loss: 4.210779666900635
Validation loss: 4.523713956276576

Epoch: 5| Step: 4
Training loss: 4.782469749450684
Validation loss: 4.515785098075867

Epoch: 5| Step: 5
Training loss: 3.986234188079834
Validation loss: 4.507803241411845

Epoch: 5| Step: 6
Training loss: 4.910225868225098
Validation loss: 4.5002331137657166

Epoch: 5| Step: 7
Training loss: 5.659405708312988
Validation loss: 4.492264628410339

Epoch: 5| Step: 8
Training loss: 4.1351518630981445
Validation loss: 4.484338363011678

Epoch: 5| Step: 9
Training loss: 3.6013152599334717
Validation loss: 4.476070602734883

Epoch: 5| Step: 10
Training loss: 5.979915142059326
Validation loss: 4.468696077664693

Epoch: 5| Step: 11
Training loss: 3.627135753631592
Validation loss: 4.460952023665111

Epoch: 12| Step: 0
Training loss: 5.021190643310547
Validation loss: 4.453511754671733

Epoch: 5| Step: 1
Training loss: 4.339982032775879
Validation loss: 4.445348521073659

Epoch: 5| Step: 2
Training loss: 4.042171478271484
Validation loss: 4.438572575648625

Epoch: 5| Step: 3
Training loss: 5.214090347290039
Validation loss: 4.431202471256256

Epoch: 5| Step: 4
Training loss: 4.2724432945251465
Validation loss: 4.424525539080302

Epoch: 5| Step: 5
Training loss: 4.609847545623779
Validation loss: 4.416906277338664

Epoch: 5| Step: 6
Training loss: 3.838886260986328
Validation loss: 4.410494069258372

Epoch: 5| Step: 7
Training loss: 4.963837146759033
Validation loss: 4.403998772303264

Epoch: 5| Step: 8
Training loss: 4.0475640296936035
Validation loss: 4.398036688566208

Epoch: 5| Step: 9
Training loss: 4.41463565826416
Validation loss: 4.3914652069409685

Epoch: 5| Step: 10
Training loss: 4.997016906738281
Validation loss: 4.385285864273707

Epoch: 5| Step: 11
Training loss: 4.909188747406006
Validation loss: 4.378720949093501

Epoch: 13| Step: 0
Training loss: 5.009949207305908
Validation loss: 4.372403800487518

Epoch: 5| Step: 1
Training loss: 5.196837425231934
Validation loss: 4.366198678811391

Epoch: 5| Step: 2
Training loss: 3.1935808658599854
Validation loss: 4.3598432540893555

Epoch: 5| Step: 3
Training loss: 4.003022193908691
Validation loss: 4.353521982828776

Epoch: 5| Step: 4
Training loss: 4.585926532745361
Validation loss: 4.346816331148148

Epoch: 5| Step: 5
Training loss: 4.445633888244629
Validation loss: 4.340085128943126

Epoch: 5| Step: 6
Training loss: 4.916741371154785
Validation loss: 4.3334418932596845

Epoch: 5| Step: 7
Training loss: 4.479035377502441
Validation loss: 4.32651533683141

Epoch: 5| Step: 8
Training loss: 4.234902381896973
Validation loss: 4.320370674133301

Epoch: 5| Step: 9
Training loss: 3.6179611682891846
Validation loss: 4.314431289831798

Epoch: 5| Step: 10
Training loss: 5.1909074783325195
Validation loss: 4.30795282125473

Epoch: 5| Step: 11
Training loss: 5.501124382019043
Validation loss: 4.301894495884578

Epoch: 14| Step: 0
Training loss: 4.326967239379883
Validation loss: 4.296276907126109

Epoch: 5| Step: 1
Training loss: 4.872591972351074
Validation loss: 4.290459771951039

Epoch: 5| Step: 2
Training loss: 3.822300672531128
Validation loss: 4.283925473690033

Epoch: 5| Step: 3
Training loss: 3.7405669689178467
Validation loss: 4.27864087621371

Epoch: 5| Step: 4
Training loss: 4.075582027435303
Validation loss: 4.2735721071561175

Epoch: 5| Step: 5
Training loss: 4.245888710021973
Validation loss: 4.2683848937352495

Epoch: 5| Step: 6
Training loss: 4.762595176696777
Validation loss: 4.262404610713323

Epoch: 5| Step: 7
Training loss: 4.705935001373291
Validation loss: 4.2562186022599535

Epoch: 5| Step: 8
Training loss: 5.146435737609863
Validation loss: 4.249983261028926

Epoch: 5| Step: 9
Training loss: 4.446581840515137
Validation loss: 4.244480391343434

Epoch: 5| Step: 10
Training loss: 3.932974338531494
Validation loss: 4.238594233989716

Epoch: 5| Step: 11
Training loss: 5.639225006103516
Validation loss: 4.23412028948466

Epoch: 15| Step: 0
Training loss: 4.782943248748779
Validation loss: 4.228585292895635

Epoch: 5| Step: 1
Training loss: 4.316689491271973
Validation loss: 4.222095866998036

Epoch: 5| Step: 2
Training loss: 3.871691942214966
Validation loss: 4.215694785118103

Epoch: 5| Step: 3
Training loss: 4.796469688415527
Validation loss: 4.210653950770696

Epoch: 5| Step: 4
Training loss: 3.964536190032959
Validation loss: 4.205558975537618

Epoch: 5| Step: 5
Training loss: 4.226210594177246
Validation loss: 4.200317581494649

Epoch: 5| Step: 6
Training loss: 3.502871036529541
Validation loss: 4.1946768164634705

Epoch: 5| Step: 7
Training loss: 4.825464725494385
Validation loss: 4.189414471387863

Epoch: 5| Step: 8
Training loss: 4.89454984664917
Validation loss: 4.183176875114441

Epoch: 5| Step: 9
Training loss: 4.276741981506348
Validation loss: 4.177298804124196

Epoch: 5| Step: 10
Training loss: 3.9746031761169434
Validation loss: 4.172240446011226

Epoch: 5| Step: 11
Training loss: 5.396206378936768
Validation loss: 4.166645685831706

Epoch: 16| Step: 0
Training loss: 4.267856597900391
Validation loss: 4.161393910646439

Epoch: 5| Step: 1
Training loss: 4.167792320251465
Validation loss: 4.155856152375539

Epoch: 5| Step: 2
Training loss: 4.996542453765869
Validation loss: 4.150341361761093

Epoch: 5| Step: 3
Training loss: 4.247959136962891
Validation loss: 4.145318239927292

Epoch: 5| Step: 4
Training loss: 3.9768989086151123
Validation loss: 4.139912148316701

Epoch: 5| Step: 5
Training loss: 3.937494993209839
Validation loss: 4.134265472491582

Epoch: 5| Step: 6
Training loss: 3.9380810260772705
Validation loss: 4.1294253170490265

Epoch: 5| Step: 7
Training loss: 4.534224987030029
Validation loss: 4.125211000442505

Epoch: 5| Step: 8
Training loss: 4.017218589782715
Validation loss: 4.1200970113277435

Epoch: 5| Step: 9
Training loss: 4.306258201599121
Validation loss: 4.115286598602931

Epoch: 5| Step: 10
Training loss: 4.490020275115967
Validation loss: 4.109849691390991

Epoch: 5| Step: 11
Training loss: 4.862100124359131
Validation loss: 4.1045446793238325

Epoch: 17| Step: 0
Training loss: 3.471280336380005
Validation loss: 4.099618881940842

Epoch: 5| Step: 1
Training loss: 3.1153063774108887
Validation loss: 4.094029873609543

Epoch: 5| Step: 2
Training loss: 3.6938655376434326
Validation loss: 4.088927318652471

Epoch: 5| Step: 3
Training loss: 4.631134033203125
Validation loss: 4.084145198265712

Epoch: 5| Step: 4
Training loss: 5.083314418792725
Validation loss: 4.07931254307429

Epoch: 5| Step: 5
Training loss: 4.447986125946045
Validation loss: 4.074474036693573

Epoch: 5| Step: 6
Training loss: 4.8734540939331055
Validation loss: 4.069771657387416

Epoch: 5| Step: 7
Training loss: 4.011264801025391
Validation loss: 4.064978649218877

Epoch: 5| Step: 8
Training loss: 3.9103195667266846
Validation loss: 4.059831400712331

Epoch: 5| Step: 9
Training loss: 4.3850932121276855
Validation loss: 4.0542942980925245

Epoch: 5| Step: 10
Training loss: 4.655754089355469
Validation loss: 4.049819181362788

Epoch: 5| Step: 11
Training loss: 4.645012378692627
Validation loss: 4.045966068903605

Epoch: 18| Step: 0
Training loss: 4.287515640258789
Validation loss: 4.040640711784363

Epoch: 5| Step: 1
Training loss: 4.514975070953369
Validation loss: 4.036268174648285

Epoch: 5| Step: 2
Training loss: 4.859193325042725
Validation loss: 4.0305450558662415

Epoch: 5| Step: 3
Training loss: 3.62357759475708
Validation loss: 4.026235957940419

Epoch: 5| Step: 4
Training loss: 3.5593857765197754
Validation loss: 4.021841029326121

Epoch: 5| Step: 5
Training loss: 4.131707191467285
Validation loss: 4.016651272773743

Epoch: 5| Step: 6
Training loss: 3.764153242111206
Validation loss: 4.011613686879476

Epoch: 5| Step: 7
Training loss: 4.716350555419922
Validation loss: 4.00700443983078

Epoch: 5| Step: 8
Training loss: 4.3729095458984375
Validation loss: 4.001912593841553

Epoch: 5| Step: 9
Training loss: 2.882747173309326
Validation loss: 3.99798576037089

Epoch: 5| Step: 10
Training loss: 4.910275936126709
Validation loss: 3.993435730536779

Epoch: 5| Step: 11
Training loss: 4.900169372558594
Validation loss: 3.988746722539266

Epoch: 19| Step: 0
Training loss: 4.117137432098389
Validation loss: 3.9845868746439614

Epoch: 5| Step: 1
Training loss: 4.529377460479736
Validation loss: 3.9799285531044006

Epoch: 5| Step: 2
Training loss: 3.5593178272247314
Validation loss: 3.9757569432258606

Epoch: 5| Step: 3
Training loss: 3.893620729446411
Validation loss: 3.9723600248495736

Epoch: 5| Step: 4
Training loss: 3.8017477989196777
Validation loss: 3.9672097166379294

Epoch: 5| Step: 5
Training loss: 3.8897366523742676
Validation loss: 3.963224768638611

Epoch: 5| Step: 6
Training loss: 3.8650031089782715
Validation loss: 3.9583062628904977

Epoch: 5| Step: 7
Training loss: 4.5271897315979
Validation loss: 3.953904857238134

Epoch: 5| Step: 8
Training loss: 4.3192291259765625
Validation loss: 3.9498600165049234

Epoch: 5| Step: 9
Training loss: 4.538060188293457
Validation loss: 3.9456640481948853

Epoch: 5| Step: 10
Training loss: 3.7722091674804688
Validation loss: 3.941528687874476

Epoch: 5| Step: 11
Training loss: 6.039029121398926
Validation loss: 3.936897655328115

Epoch: 20| Step: 0
Training loss: 4.545784950256348
Validation loss: 3.9320271015167236

Epoch: 5| Step: 1
Training loss: 4.002364158630371
Validation loss: 3.9282968242963157

Epoch: 5| Step: 2
Training loss: 4.671927452087402
Validation loss: 3.9241468608379364

Epoch: 5| Step: 3
Training loss: 3.34846568107605
Validation loss: 3.91974468032519

Epoch: 5| Step: 4
Training loss: 4.127380847930908
Validation loss: 3.9149496058622995

Epoch: 5| Step: 5
Training loss: 3.8531651496887207
Validation loss: 3.91020205616951

Epoch: 5| Step: 6
Training loss: 4.106601715087891
Validation loss: 3.905900011459986

Epoch: 5| Step: 7
Training loss: 4.101780414581299
Validation loss: 3.9016013145446777

Epoch: 5| Step: 8
Training loss: 4.121657848358154
Validation loss: 3.896832436323166

Epoch: 5| Step: 9
Training loss: 4.323369026184082
Validation loss: 3.8931451737880707

Epoch: 5| Step: 10
Training loss: 3.466431140899658
Validation loss: 3.88843568166097

Epoch: 5| Step: 11
Training loss: 4.040227890014648
Validation loss: 3.884454300006231

Epoch: 21| Step: 0
Training loss: 4.224663734436035
Validation loss: 3.8798426588376365

Epoch: 5| Step: 1
Training loss: 4.320195198059082
Validation loss: 3.8762880067030587

Epoch: 5| Step: 2
Training loss: 4.136740684509277
Validation loss: 3.8724170128504434

Epoch: 5| Step: 3
Training loss: 4.8566575050354
Validation loss: 3.867568920056025

Epoch: 5| Step: 4
Training loss: 3.3309664726257324
Validation loss: 3.8629555900891623

Epoch: 5| Step: 5
Training loss: 4.061737537384033
Validation loss: 3.8586865961551666

Epoch: 5| Step: 6
Training loss: 3.6391987800598145
Validation loss: 3.854717950026194

Epoch: 5| Step: 7
Training loss: 4.2316131591796875
Validation loss: 3.850928564866384

Epoch: 5| Step: 8
Training loss: 3.2226364612579346
Validation loss: 3.8464188079039254

Epoch: 5| Step: 9
Training loss: 4.084717750549316
Validation loss: 3.842898507912954

Epoch: 5| Step: 10
Training loss: 4.013364791870117
Validation loss: 3.8384723166624704

Epoch: 5| Step: 11
Training loss: 4.017345428466797
Validation loss: 3.834094097216924

Epoch: 22| Step: 0
Training loss: 4.540763854980469
Validation loss: 3.8296736776828766

Epoch: 5| Step: 1
Training loss: 3.818950653076172
Validation loss: 3.826050947109858

Epoch: 5| Step: 2
Training loss: 4.577963352203369
Validation loss: 3.8213560978571572

Epoch: 5| Step: 3
Training loss: 4.17302942276001
Validation loss: 3.816858301560084

Epoch: 5| Step: 4
Training loss: 4.4730143547058105
Validation loss: 3.8128042618433633

Epoch: 5| Step: 5
Training loss: 4.147814750671387
Validation loss: 3.808644970258077

Epoch: 5| Step: 6
Training loss: 3.8673901557922363
Validation loss: 3.8043708006540933

Epoch: 5| Step: 7
Training loss: 3.0142886638641357
Validation loss: 3.800122340520223

Epoch: 5| Step: 8
Training loss: 3.5290348529815674
Validation loss: 3.7959819535414376

Epoch: 5| Step: 9
Training loss: 3.806546449661255
Validation loss: 3.7915605306625366

Epoch: 5| Step: 10
Training loss: 3.6366660594940186
Validation loss: 3.787994146347046

Epoch: 5| Step: 11
Training loss: 4.062176704406738
Validation loss: 3.784263720115026

Epoch: 23| Step: 0
Training loss: 4.424042701721191
Validation loss: 3.7786820828914642

Epoch: 5| Step: 1
Training loss: 2.6858363151550293
Validation loss: 3.775443742672602

Epoch: 5| Step: 2
Training loss: 3.498398542404175
Validation loss: 3.7700954973697662

Epoch: 5| Step: 3
Training loss: 3.9589123725891113
Validation loss: 3.7668544352054596

Epoch: 5| Step: 4
Training loss: 3.613798141479492
Validation loss: 3.7622537116209664

Epoch: 5| Step: 5
Training loss: 4.275048732757568
Validation loss: 3.758184274037679

Epoch: 5| Step: 6
Training loss: 3.672947406768799
Validation loss: 3.7540950576464334

Epoch: 5| Step: 7
Training loss: 3.573014736175537
Validation loss: 3.7498796383539834

Epoch: 5| Step: 8
Training loss: 4.92138147354126
Validation loss: 3.746052384376526

Epoch: 5| Step: 9
Training loss: 4.492023944854736
Validation loss: 3.741988033056259

Epoch: 5| Step: 10
Training loss: 3.652625322341919
Validation loss: 3.7380531628926597

Epoch: 5| Step: 11
Training loss: 5.515225410461426
Validation loss: 3.7340465088685355

Epoch: 24| Step: 0
Training loss: 3.960789442062378
Validation loss: 3.729530781507492

Epoch: 5| Step: 1
Training loss: 4.389128684997559
Validation loss: 3.725781669219335

Epoch: 5| Step: 2
Training loss: 3.556809186935425
Validation loss: 3.7222749292850494

Epoch: 5| Step: 3
Training loss: 3.614107131958008
Validation loss: 3.717255820830663

Epoch: 5| Step: 4
Training loss: 4.303285598754883
Validation loss: 3.7126040359338126

Epoch: 5| Step: 5
Training loss: 3.778669834136963
Validation loss: 3.7089002629121146

Epoch: 5| Step: 6
Training loss: 4.174623966217041
Validation loss: 3.704318364461263

Epoch: 5| Step: 7
Training loss: 3.3037586212158203
Validation loss: 3.7003234028816223

Epoch: 5| Step: 8
Training loss: 4.08607816696167
Validation loss: 3.697251965602239

Epoch: 5| Step: 9
Training loss: 4.310036659240723
Validation loss: 3.6933420399824777

Epoch: 5| Step: 10
Training loss: 3.051961898803711
Validation loss: 3.689339190721512

Epoch: 5| Step: 11
Training loss: 4.131613254547119
Validation loss: 3.6849977374076843

Epoch: 25| Step: 0
Training loss: 4.206135272979736
Validation loss: 3.6805700759092965

Epoch: 5| Step: 1
Training loss: 4.6783223152160645
Validation loss: 3.676679720481237

Epoch: 5| Step: 2
Training loss: 2.753469705581665
Validation loss: 3.6730888883272805

Epoch: 5| Step: 3
Training loss: 3.608755111694336
Validation loss: 3.6688519616921744

Epoch: 5| Step: 4
Training loss: 2.970776081085205
Validation loss: 3.6649897197882333

Epoch: 5| Step: 5
Training loss: 4.360465049743652
Validation loss: 3.660638908545176

Epoch: 5| Step: 6
Training loss: 4.100862979888916
Validation loss: 3.656747510035833

Epoch: 5| Step: 7
Training loss: 3.3388900756835938
Validation loss: 3.6530325412750244

Epoch: 5| Step: 8
Training loss: 3.9299652576446533
Validation loss: 3.648282527923584

Epoch: 5| Step: 9
Training loss: 4.053591728210449
Validation loss: 3.644619196653366

Epoch: 5| Step: 10
Training loss: 4.058420658111572
Validation loss: 3.6404031217098236

Epoch: 5| Step: 11
Training loss: 3.736206293106079
Validation loss: 3.6365247070789337

Epoch: 26| Step: 0
Training loss: 2.714094638824463
Validation loss: 3.6318387190500894

Epoch: 5| Step: 1
Training loss: 4.337216377258301
Validation loss: 3.6273424923419952

Epoch: 5| Step: 2
Training loss: 4.012661933898926
Validation loss: 3.623620460430781

Epoch: 5| Step: 3
Training loss: 3.9794812202453613
Validation loss: 3.61965282758077

Epoch: 5| Step: 4
Training loss: 4.4314398765563965
Validation loss: 3.6154370307922363

Epoch: 5| Step: 5
Training loss: 3.2919793128967285
Validation loss: 3.610247621933619

Epoch: 5| Step: 6
Training loss: 3.094583511352539
Validation loss: 3.605775614579519

Epoch: 5| Step: 7
Training loss: 3.9131240844726562
Validation loss: 3.601666271686554

Epoch: 5| Step: 8
Training loss: 3.9865200519561768
Validation loss: 3.5970928172270455

Epoch: 5| Step: 9
Training loss: 3.808035373687744
Validation loss: 3.592092216014862

Epoch: 5| Step: 10
Training loss: 3.922187089920044
Validation loss: 3.5869606037934623

Epoch: 5| Step: 11
Training loss: 3.8218464851379395
Validation loss: 3.5819758574167886

Epoch: 27| Step: 0
Training loss: 4.12200927734375
Validation loss: 3.5779728392759957

Epoch: 5| Step: 1
Training loss: 3.350430727005005
Validation loss: 3.5725300014019012

Epoch: 5| Step: 2
Training loss: 3.456714630126953
Validation loss: 3.567843586206436

Epoch: 5| Step: 3
Training loss: 3.4860587120056152
Validation loss: 3.5629378656546273

Epoch: 5| Step: 4
Training loss: 4.471495151519775
Validation loss: 3.5581813057263694

Epoch: 5| Step: 5
Training loss: 4.064407825469971
Validation loss: 3.5534790058930716

Epoch: 5| Step: 6
Training loss: 3.476332426071167
Validation loss: 3.5495410760243735

Epoch: 5| Step: 7
Training loss: 3.956202983856201
Validation loss: 3.5445873041947684

Epoch: 5| Step: 8
Training loss: 3.4330310821533203
Validation loss: 3.5395994583765664

Epoch: 5| Step: 9
Training loss: 3.630646228790283
Validation loss: 3.534503777821859

Epoch: 5| Step: 10
Training loss: 3.315647840499878
Validation loss: 3.5316319863001504

Epoch: 5| Step: 11
Training loss: 4.485966682434082
Validation loss: 3.5276323159535727

Epoch: 28| Step: 0
Training loss: 4.141671657562256
Validation loss: 3.523696502049764

Epoch: 5| Step: 1
Training loss: 4.684945106506348
Validation loss: 3.5280965169270835

Epoch: 5| Step: 2
Training loss: 3.7528884410858154
Validation loss: 3.5177544554074607

Epoch: 5| Step: 3
Training loss: 3.955728054046631
Validation loss: 3.5111625492572784

Epoch: 5| Step: 4
Training loss: 3.2856640815734863
Validation loss: 3.5075506468613944

Epoch: 5| Step: 5
Training loss: 4.161406517028809
Validation loss: 3.506180922190348

Epoch: 5| Step: 6
Training loss: 3.420799732208252
Validation loss: 3.501058886448542

Epoch: 5| Step: 7
Training loss: 3.3890233039855957
Validation loss: 3.493808368841807

Epoch: 5| Step: 8
Training loss: 2.9156715869903564
Validation loss: 3.4881791869799295

Epoch: 5| Step: 9
Training loss: 4.092114448547363
Validation loss: 3.483016381661097

Epoch: 5| Step: 10
Training loss: 2.917210340499878
Validation loss: 3.4796698490778604

Epoch: 5| Step: 11
Training loss: 2.0708370208740234
Validation loss: 3.475436190764109

Epoch: 29| Step: 0
Training loss: 3.430973768234253
Validation loss: 3.471520036458969

Epoch: 5| Step: 1
Training loss: 3.3337903022766113
Validation loss: 3.4655472139517465

Epoch: 5| Step: 2
Training loss: 3.7917113304138184
Validation loss: 3.4606546759605408

Epoch: 5| Step: 3
Training loss: 4.444642543792725
Validation loss: 3.45613224307696

Epoch: 5| Step: 4
Training loss: 4.510450839996338
Validation loss: 3.450919032096863

Epoch: 5| Step: 5
Training loss: 3.3291707038879395
Validation loss: 3.4462835490703583

Epoch: 5| Step: 6
Training loss: 3.043665647506714
Validation loss: 3.442406843105952

Epoch: 5| Step: 7
Training loss: 3.6850974559783936
Validation loss: 3.437173624833425

Epoch: 5| Step: 8
Training loss: 3.629380464553833
Validation loss: 3.4331152538458505

Epoch: 5| Step: 9
Training loss: 2.920168399810791
Validation loss: 3.428632507721583

Epoch: 5| Step: 10
Training loss: 3.2699122428894043
Validation loss: 3.4237199227015176

Epoch: 5| Step: 11
Training loss: 5.392762660980225
Validation loss: 3.420492649078369

Epoch: 30| Step: 0
Training loss: 3.4168972969055176
Validation loss: 3.415550877650579

Epoch: 5| Step: 1
Training loss: 4.248852252960205
Validation loss: 3.41115794579188

Epoch: 5| Step: 2
Training loss: 3.902599811553955
Validation loss: 3.4079834818840027

Epoch: 5| Step: 3
Training loss: 3.9884026050567627
Validation loss: 3.4029790461063385

Epoch: 5| Step: 4
Training loss: 2.7408156394958496
Validation loss: 3.398289034763972

Epoch: 5| Step: 5
Training loss: 2.809842348098755
Validation loss: 3.3938070833683014

Epoch: 5| Step: 6
Training loss: 3.869838237762451
Validation loss: 3.389477660258611

Epoch: 5| Step: 7
Training loss: 4.275921821594238
Validation loss: 3.3857300182183585

Epoch: 5| Step: 8
Training loss: 3.169020414352417
Validation loss: 3.381404091914495

Epoch: 5| Step: 9
Training loss: 3.242771863937378
Validation loss: 3.377445330222448

Epoch: 5| Step: 10
Training loss: 3.4079246520996094
Validation loss: 3.3727268179257712

Epoch: 5| Step: 11
Training loss: 4.119261741638184
Validation loss: 3.368509213129679

Epoch: 31| Step: 0
Training loss: 2.9232912063598633
Validation loss: 3.3641327818234763

Epoch: 5| Step: 1
Training loss: 3.5572609901428223
Validation loss: 3.359518200159073

Epoch: 5| Step: 2
Training loss: 2.8823916912078857
Validation loss: 3.355009208122889

Epoch: 5| Step: 3
Training loss: 2.9158213138580322
Validation loss: 3.3515675961971283

Epoch: 5| Step: 4
Training loss: 3.277733325958252
Validation loss: 3.3473094205061593

Epoch: 5| Step: 5
Training loss: 3.9841461181640625
Validation loss: 3.342965692281723

Epoch: 5| Step: 6
Training loss: 3.268894910812378
Validation loss: 3.338752418756485

Epoch: 5| Step: 7
Training loss: 4.0988874435424805
Validation loss: 3.334137578805288

Epoch: 5| Step: 8
Training loss: 3.816687822341919
Validation loss: 3.330364316701889

Epoch: 5| Step: 9
Training loss: 4.530478477478027
Validation loss: 3.3261904219786325

Epoch: 5| Step: 10
Training loss: 3.3026256561279297
Validation loss: 3.322387049595515

Epoch: 5| Step: 11
Training loss: 4.036443710327148
Validation loss: 3.317636489868164

Epoch: 32| Step: 0
Training loss: 4.135165691375732
Validation loss: 3.313841382662455

Epoch: 5| Step: 1
Training loss: 3.534517288208008
Validation loss: 3.3096646666526794

Epoch: 5| Step: 2
Training loss: 3.0789947509765625
Validation loss: 3.3057945370674133

Epoch: 5| Step: 3
Training loss: 3.531703233718872
Validation loss: 3.3014835119247437

Epoch: 5| Step: 4
Training loss: 4.127684593200684
Validation loss: 3.29775998989741

Epoch: 5| Step: 5
Training loss: 3.6655113697052
Validation loss: 3.293905198574066

Epoch: 5| Step: 6
Training loss: 3.629814624786377
Validation loss: 3.290025512377421

Epoch: 5| Step: 7
Training loss: 2.983696937561035
Validation loss: 3.2861613432566323

Epoch: 5| Step: 8
Training loss: 2.969874620437622
Validation loss: 3.282506803671519

Epoch: 5| Step: 9
Training loss: 3.769770860671997
Validation loss: 3.2790348629156747

Epoch: 5| Step: 10
Training loss: 3.082141160964966
Validation loss: 3.2751376231511435

Epoch: 5| Step: 11
Training loss: 1.7895878553390503
Validation loss: 3.2709477146466575

Epoch: 33| Step: 0
Training loss: 3.6440258026123047
Validation loss: 3.268014828364054

Epoch: 5| Step: 1
Training loss: 4.005358695983887
Validation loss: 3.264236807823181

Epoch: 5| Step: 2
Training loss: 3.4705169200897217
Validation loss: 3.260387033224106

Epoch: 5| Step: 3
Training loss: 3.1551811695098877
Validation loss: 3.256384571393331

Epoch: 5| Step: 4
Training loss: 3.879518985748291
Validation loss: 3.2528282006581626

Epoch: 5| Step: 5
Training loss: 3.0232372283935547
Validation loss: 3.2489043871561685

Epoch: 5| Step: 6
Training loss: 3.489865779876709
Validation loss: 3.244806299606959

Epoch: 5| Step: 7
Training loss: 3.4139657020568848
Validation loss: 3.2410829166571298

Epoch: 5| Step: 8
Training loss: 3.1934638023376465
Validation loss: 3.2376264929771423

Epoch: 5| Step: 9
Training loss: 3.3206005096435547
Validation loss: 3.2337275246779122

Epoch: 5| Step: 10
Training loss: 2.677276849746704
Validation loss: 3.230873147646586

Epoch: 5| Step: 11
Training loss: 5.616321086883545
Validation loss: 3.2268594404061637

Epoch: 34| Step: 0
Training loss: 3.3588173389434814
Validation loss: 3.22281613945961

Epoch: 5| Step: 1
Training loss: 3.297849178314209
Validation loss: 3.2188300093015036

Epoch: 5| Step: 2
Training loss: 3.4170823097229004
Validation loss: 3.2151348988215127

Epoch: 5| Step: 3
Training loss: 2.962421417236328
Validation loss: 3.210857778787613

Epoch: 5| Step: 4
Training loss: 3.2489306926727295
Validation loss: 3.2072947919368744

Epoch: 5| Step: 5
Training loss: 4.006314754486084
Validation loss: 3.203282654285431

Epoch: 5| Step: 6
Training loss: 3.933349609375
Validation loss: 3.1997962991396585

Epoch: 5| Step: 7
Training loss: 2.965170383453369
Validation loss: 3.1956994434197745

Epoch: 5| Step: 8
Training loss: 3.344818115234375
Validation loss: 3.192059963941574

Epoch: 5| Step: 9
Training loss: 3.253002643585205
Validation loss: 3.1880743404229483

Epoch: 5| Step: 10
Training loss: 3.6926474571228027
Validation loss: 3.184248467286428

Epoch: 5| Step: 11
Training loss: 2.1965506076812744
Validation loss: 3.1806334356466928

Epoch: 35| Step: 0
Training loss: 3.243788242340088
Validation loss: 3.177082598209381

Epoch: 5| Step: 1
Training loss: 3.241576671600342
Validation loss: 3.1739234924316406

Epoch: 5| Step: 2
Training loss: 3.1517956256866455
Validation loss: 3.1705362101395926

Epoch: 5| Step: 3
Training loss: 3.1556904315948486
Validation loss: 3.167593310276667

Epoch: 5| Step: 4
Training loss: 3.0007567405700684
Validation loss: 3.1642108658949533

Epoch: 5| Step: 5
Training loss: 3.271237850189209
Validation loss: 3.1604034205277762

Epoch: 5| Step: 6
Training loss: 4.106823444366455
Validation loss: 3.1567977567513785

Epoch: 5| Step: 7
Training loss: 2.8799543380737305
Validation loss: 3.1534877717494965

Epoch: 5| Step: 8
Training loss: 3.8742423057556152
Validation loss: 3.149735470612844

Epoch: 5| Step: 9
Training loss: 3.474862575531006
Validation loss: 3.1464164753754935

Epoch: 5| Step: 10
Training loss: 3.559116840362549
Validation loss: 3.142540156841278

Epoch: 5| Step: 11
Training loss: 2.4768500328063965
Validation loss: 3.138772497574488

Epoch: 36| Step: 0
Training loss: 3.1598715782165527
Validation loss: 3.1352266470591226

Epoch: 5| Step: 1
Training loss: 2.5824151039123535
Validation loss: 3.1324623624483743

Epoch: 5| Step: 2
Training loss: 3.452063798904419
Validation loss: 3.128842751185099

Epoch: 5| Step: 3
Training loss: 3.3781981468200684
Validation loss: 3.1258291999499

Epoch: 5| Step: 4
Training loss: 3.5000596046447754
Validation loss: 3.122712920109431

Epoch: 5| Step: 5
Training loss: 4.323368072509766
Validation loss: 3.119363953669866

Epoch: 5| Step: 6
Training loss: 3.326690673828125
Validation loss: 3.115538547436396

Epoch: 5| Step: 7
Training loss: 2.847954034805298
Validation loss: 3.1121122936407724

Epoch: 5| Step: 8
Training loss: 3.080944538116455
Validation loss: 3.1089958945910134

Epoch: 5| Step: 9
Training loss: 3.5357024669647217
Validation loss: 3.1055973768234253

Epoch: 5| Step: 10
Training loss: 2.9571776390075684
Validation loss: 3.1020385523637137

Epoch: 5| Step: 11
Training loss: 4.394471168518066
Validation loss: 3.0984886387983956

Epoch: 37| Step: 0
Training loss: 2.9569897651672363
Validation loss: 3.0947332084178925

Epoch: 5| Step: 1
Training loss: 4.308470726013184
Validation loss: 3.091210146745046

Epoch: 5| Step: 2
Training loss: 3.544426679611206
Validation loss: 3.088064799706141

Epoch: 5| Step: 3
Training loss: 3.398345947265625
Validation loss: 3.0845465461413064

Epoch: 5| Step: 4
Training loss: 3.840745210647583
Validation loss: 3.081322193145752

Epoch: 5| Step: 5
Training loss: 2.554640293121338
Validation loss: 3.077802369991938

Epoch: 5| Step: 6
Training loss: 3.49212646484375
Validation loss: 3.0740288694699607

Epoch: 5| Step: 7
Training loss: 2.2416045665740967
Validation loss: 3.0708181063334146

Epoch: 5| Step: 8
Training loss: 3.2444567680358887
Validation loss: 3.0669234494368234

Epoch: 5| Step: 9
Training loss: 3.3852295875549316
Validation loss: 3.063492784897486

Epoch: 5| Step: 10
Training loss: 2.8959693908691406
Validation loss: 3.060112019379934

Epoch: 5| Step: 11
Training loss: 3.700589656829834
Validation loss: 3.0566402077674866

Epoch: 38| Step: 0
Training loss: 4.487767696380615
Validation loss: 3.0537369350592294

Epoch: 5| Step: 1
Training loss: 2.736609935760498
Validation loss: 3.0509050488471985

Epoch: 5| Step: 2
Training loss: 3.4938488006591797
Validation loss: 3.0475957890351615

Epoch: 5| Step: 3
Training loss: 2.934445858001709
Validation loss: 3.0446336766084037

Epoch: 5| Step: 4
Training loss: 2.4671096801757812
Validation loss: 3.0416537622610726

Epoch: 5| Step: 5
Training loss: 3.448822021484375
Validation loss: 3.0384766161441803

Epoch: 5| Step: 6
Training loss: 3.188732624053955
Validation loss: 3.0354001422723136

Epoch: 5| Step: 7
Training loss: 2.7542355060577393
Validation loss: 3.0321564376354218

Epoch: 5| Step: 8
Training loss: 3.0216598510742188
Validation loss: 3.0289492507775626

Epoch: 5| Step: 9
Training loss: 3.57393217086792
Validation loss: 3.026296705007553

Epoch: 5| Step: 10
Training loss: 3.3569045066833496
Validation loss: 3.0230522950490317

Epoch: 5| Step: 11
Training loss: 3.5870304107666016
Validation loss: 3.020498434702555

Epoch: 39| Step: 0
Training loss: 3.48675799369812
Validation loss: 3.016744246085485

Epoch: 5| Step: 1
Training loss: 2.7435944080352783
Validation loss: 3.012784351905187

Epoch: 5| Step: 2
Training loss: 3.6122188568115234
Validation loss: 3.009263813495636

Epoch: 5| Step: 3
Training loss: 2.9525914192199707
Validation loss: 3.005608022212982

Epoch: 5| Step: 4
Training loss: 4.265181541442871
Validation loss: 3.0025011698404946

Epoch: 5| Step: 5
Training loss: 3.092741012573242
Validation loss: 2.998548130194346

Epoch: 5| Step: 6
Training loss: 2.8015713691711426
Validation loss: 2.9946665664513907

Epoch: 5| Step: 7
Training loss: 3.4103260040283203
Validation loss: 2.991096278031667

Epoch: 5| Step: 8
Training loss: 2.2548248767852783
Validation loss: 2.9878945847352347

Epoch: 5| Step: 9
Training loss: 2.6144933700561523
Validation loss: 2.9840163389841714

Epoch: 5| Step: 10
Training loss: 3.9268481731414795
Validation loss: 2.981191714604696

Epoch: 5| Step: 11
Training loss: 3.209566354751587
Validation loss: 2.9785065750281015

Epoch: 40| Step: 0
Training loss: 2.9040637016296387
Validation loss: 2.9757489363352456

Epoch: 5| Step: 1
Training loss: 2.626727819442749
Validation loss: 2.9722518622875214

Epoch: 5| Step: 2
Training loss: 2.977445363998413
Validation loss: 2.9692849814891815

Epoch: 5| Step: 3
Training loss: 3.671581983566284
Validation loss: 2.96580171585083

Epoch: 5| Step: 4
Training loss: 3.2444472312927246
Validation loss: 2.962778409322103

Epoch: 5| Step: 5
Training loss: 3.0679104328155518
Validation loss: 2.959817796945572

Epoch: 5| Step: 6
Training loss: 2.8226687908172607
Validation loss: 2.956594039996465

Epoch: 5| Step: 7
Training loss: 3.484126329421997
Validation loss: 2.9530763824780784

Epoch: 5| Step: 8
Training loss: 3.257672071456909
Validation loss: 2.9503329594930015

Epoch: 5| Step: 9
Training loss: 3.2980589866638184
Validation loss: 2.9470817943414054

Epoch: 5| Step: 10
Training loss: 2.977710008621216
Validation loss: 2.9438647429148355

Epoch: 5| Step: 11
Training loss: 5.274074554443359
Validation loss: 2.9410332838694253

Epoch: 41| Step: 0
Training loss: 2.5804576873779297
Validation loss: 2.9373186429341636

Epoch: 5| Step: 1
Training loss: 2.99284029006958
Validation loss: 2.9342521031697593

Epoch: 5| Step: 2
Training loss: 3.1524558067321777
Validation loss: 2.9314404129981995

Epoch: 5| Step: 3
Training loss: 3.4608845710754395
Validation loss: 2.928115874528885

Epoch: 5| Step: 4
Training loss: 3.337132215499878
Validation loss: 2.925538738568624

Epoch: 5| Step: 5
Training loss: 2.944455623626709
Validation loss: 2.922699103752772

Epoch: 5| Step: 6
Training loss: 3.4204323291778564
Validation loss: 2.919803500175476

Epoch: 5| Step: 7
Training loss: 3.7586700916290283
Validation loss: 2.916567881902059

Epoch: 5| Step: 8
Training loss: 3.1137919425964355
Validation loss: 2.9136062065760293

Epoch: 5| Step: 9
Training loss: 2.7567660808563232
Validation loss: 2.910541852315267

Epoch: 5| Step: 10
Training loss: 2.9492485523223877
Validation loss: 2.907105972369512

Epoch: 5| Step: 11
Training loss: 2.6489856243133545
Validation loss: 2.9037547210852304

Epoch: 42| Step: 0
Training loss: 3.0315208435058594
Validation loss: 2.9014262557029724

Epoch: 5| Step: 1
Training loss: 2.870880603790283
Validation loss: 2.898477832476298

Epoch: 5| Step: 2
Training loss: 3.391101121902466
Validation loss: 2.895440141359965

Epoch: 5| Step: 3
Training loss: 2.5297672748565674
Validation loss: 2.892711659272512

Epoch: 5| Step: 4
Training loss: 2.825597047805786
Validation loss: 2.889737755060196

Epoch: 5| Step: 5
Training loss: 3.340183973312378
Validation loss: 2.8868886530399323

Epoch: 5| Step: 6
Training loss: 3.093055248260498
Validation loss: 2.8834659357865653

Epoch: 5| Step: 7
Training loss: 2.7387077808380127
Validation loss: 2.880249778429667

Epoch: 5| Step: 8
Training loss: 2.8872852325439453
Validation loss: 2.877739508946737

Epoch: 5| Step: 9
Training loss: 3.571284532546997
Validation loss: 2.87456813454628

Epoch: 5| Step: 10
Training loss: 3.764141798019409
Validation loss: 2.8716415067513785

Epoch: 5| Step: 11
Training loss: 3.0263431072235107
Validation loss: 2.8687611122926078

Epoch: 43| Step: 0
Training loss: 3.8479599952697754
Validation loss: 2.8658847709496817

Epoch: 5| Step: 1
Training loss: 2.765305995941162
Validation loss: 2.8624347845713296

Epoch: 5| Step: 2
Training loss: 2.943337917327881
Validation loss: 2.8591804603735604

Epoch: 5| Step: 3
Training loss: 3.015857219696045
Validation loss: 2.8553450405597687

Epoch: 5| Step: 4
Training loss: 3.0694422721862793
Validation loss: 2.85246350367864

Epoch: 5| Step: 5
Training loss: 2.7193117141723633
Validation loss: 2.8492897053559623

Epoch: 5| Step: 6
Training loss: 2.8846962451934814
Validation loss: 2.8467310269673667

Epoch: 5| Step: 7
Training loss: 3.4649391174316406
Validation loss: 2.843910038471222

Epoch: 5| Step: 8
Training loss: 3.1433475017547607
Validation loss: 2.840907553831736

Epoch: 5| Step: 9
Training loss: 3.2346510887145996
Validation loss: 2.838563323020935

Epoch: 5| Step: 10
Training loss: 2.5230414867401123
Validation loss: 2.8356593549251556

Epoch: 5| Step: 11
Training loss: 3.4198501110076904
Validation loss: 2.832701096932093

Epoch: 44| Step: 0
Training loss: 2.570401668548584
Validation loss: 2.8300111393133798

Epoch: 5| Step: 1
Training loss: 2.83398699760437
Validation loss: 2.828571617603302

Epoch: 5| Step: 2
Training loss: 2.917736768722534
Validation loss: 2.825835347175598

Epoch: 5| Step: 3
Training loss: 2.8361382484436035
Validation loss: 2.8229626019795737

Epoch: 5| Step: 4
Training loss: 3.806382656097412
Validation loss: 2.821480671564738

Epoch: 5| Step: 5
Training loss: 2.864899158477783
Validation loss: 2.8178293704986572

Epoch: 5| Step: 6
Training loss: 2.868495225906372
Validation loss: 2.814902832110723

Epoch: 5| Step: 7
Training loss: 3.1256630420684814
Validation loss: 2.8132871886094413

Epoch: 5| Step: 8
Training loss: 3.4890735149383545
Validation loss: 2.810889105002085

Epoch: 5| Step: 9
Training loss: 3.039741039276123
Validation loss: 2.808954348166784

Epoch: 5| Step: 10
Training loss: 2.9808833599090576
Validation loss: 2.805721233288447

Epoch: 5| Step: 11
Training loss: 3.0096564292907715
Validation loss: 2.8032577534516654

Epoch: 45| Step: 0
Training loss: 3.107571840286255
Validation loss: 2.800355782111486

Epoch: 5| Step: 1
Training loss: 2.6460909843444824
Validation loss: 2.797524114449819

Epoch: 5| Step: 2
Training loss: 3.1344940662384033
Validation loss: 2.7948260505994162

Epoch: 5| Step: 3
Training loss: 3.2569992542266846
Validation loss: 2.7919694582621255

Epoch: 5| Step: 4
Training loss: 2.7511401176452637
Validation loss: 2.7893859644730887

Epoch: 5| Step: 5
Training loss: 3.0770981311798096
Validation loss: 2.7869881888230643

Epoch: 5| Step: 6
Training loss: 2.993447780609131
Validation loss: 2.78427591919899

Epoch: 5| Step: 7
Training loss: 3.027353286743164
Validation loss: 2.7814859251181283

Epoch: 5| Step: 8
Training loss: 2.9896864891052246
Validation loss: 2.7787203888098397

Epoch: 5| Step: 9
Training loss: 3.090256690979004
Validation loss: 2.775815029939016

Epoch: 5| Step: 10
Training loss: 3.0435376167297363
Validation loss: 2.77297975619634

Epoch: 5| Step: 11
Training loss: 2.3888492584228516
Validation loss: 2.7706108589967093

Epoch: 46| Step: 0
Training loss: 3.5117721557617188
Validation loss: 2.7682016690572104

Epoch: 5| Step: 1
Training loss: 2.557739734649658
Validation loss: 2.7663365304470062

Epoch: 5| Step: 2
Training loss: 2.6181952953338623
Validation loss: 2.7644292215506234

Epoch: 5| Step: 3
Training loss: 3.300748348236084
Validation loss: 2.762122948964437

Epoch: 5| Step: 4
Training loss: 3.604398012161255
Validation loss: 2.7597783903280892

Epoch: 5| Step: 5
Training loss: 2.752821445465088
Validation loss: 2.757155100504557

Epoch: 5| Step: 6
Training loss: 3.1365466117858887
Validation loss: 2.7551326553026834

Epoch: 5| Step: 7
Training loss: 3.0458273887634277
Validation loss: 2.753172884384791

Epoch: 5| Step: 8
Training loss: 2.5007882118225098
Validation loss: 2.7505374948183694

Epoch: 5| Step: 9
Training loss: 2.9279823303222656
Validation loss: 2.747678359349569

Epoch: 5| Step: 10
Training loss: 2.7089788913726807
Validation loss: 2.7448132832845054

Epoch: 5| Step: 11
Training loss: 2.8952369689941406
Validation loss: 2.7419168651103973

Epoch: 47| Step: 0
Training loss: 2.949315071105957
Validation loss: 2.741035540898641

Epoch: 5| Step: 1
Training loss: 3.15378475189209
Validation loss: 2.741658866405487

Epoch: 5| Step: 2
Training loss: 3.1034958362579346
Validation loss: 2.7343891064325967

Epoch: 5| Step: 3
Training loss: 2.2258493900299072
Validation loss: 2.7316462198893228

Epoch: 5| Step: 4
Training loss: 3.083887815475464
Validation loss: 2.729761093854904

Epoch: 5| Step: 5
Training loss: 2.8551836013793945
Validation loss: 2.727051089207331

Epoch: 5| Step: 6
Training loss: 2.7444374561309814
Validation loss: 2.7248066862424216

Epoch: 5| Step: 7
Training loss: 2.8981332778930664
Validation loss: 2.723236749569575

Epoch: 5| Step: 8
Training loss: 3.075108766555786
Validation loss: 2.7206809322039285

Epoch: 5| Step: 9
Training loss: 2.8566243648529053
Validation loss: 2.71867843468984

Epoch: 5| Step: 10
Training loss: 3.1796841621398926
Validation loss: 2.715975726644198

Epoch: 5| Step: 11
Training loss: 3.855781316757202
Validation loss: 2.713692252834638

Epoch: 48| Step: 0
Training loss: 3.48041033744812
Validation loss: 2.71018393834432

Epoch: 5| Step: 1
Training loss: 2.2450625896453857
Validation loss: 2.708887388308843

Epoch: 5| Step: 2
Training loss: 2.845972776412964
Validation loss: 2.7050043841203055

Epoch: 5| Step: 3
Training loss: 2.288684844970703
Validation loss: 2.703612804412842

Epoch: 5| Step: 4
Training loss: 3.265176773071289
Validation loss: 2.7171810567379

Epoch: 5| Step: 5
Training loss: 3.06382417678833
Validation loss: 2.7026631583770118

Epoch: 5| Step: 6
Training loss: 2.794605255126953
Validation loss: 2.6922416985034943

Epoch: 5| Step: 7
Training loss: 3.568953037261963
Validation loss: 2.6893302500247955

Epoch: 5| Step: 8
Training loss: 2.8871798515319824
Validation loss: 2.692540486653646

Epoch: 5| Step: 9
Training loss: 2.7110908031463623
Validation loss: 2.697706123193105

Epoch: 5| Step: 10
Training loss: 2.502103805541992
Validation loss: 2.691327234109243

Epoch: 5| Step: 11
Training loss: 4.64809513092041
Validation loss: 2.6883574426174164

Epoch: 49| Step: 0
Training loss: 3.2394022941589355
Validation loss: 2.6814072728157043

Epoch: 5| Step: 1
Training loss: 2.6048684120178223
Validation loss: 2.676395227511724

Epoch: 5| Step: 2
Training loss: 2.5528836250305176
Validation loss: 2.6725450456142426

Epoch: 5| Step: 3
Training loss: 3.0184874534606934
Validation loss: 2.669806415836016

Epoch: 5| Step: 4
Training loss: 3.2172393798828125
Validation loss: 2.666013310352961

Epoch: 5| Step: 5
Training loss: 3.297466993331909
Validation loss: 2.6648980478445687

Epoch: 5| Step: 6
Training loss: 2.556013822555542
Validation loss: 2.6612148582935333

Epoch: 5| Step: 7
Training loss: 3.108743190765381
Validation loss: 2.6558982729911804

Epoch: 5| Step: 8
Training loss: 2.317011833190918
Validation loss: 2.652224878470103

Epoch: 5| Step: 9
Training loss: 2.9329581260681152
Validation loss: 2.6512508442004523

Epoch: 5| Step: 10
Training loss: 2.6551127433776855
Validation loss: 2.6473737756411233

Epoch: 5| Step: 11
Training loss: 3.270672559738159
Validation loss: 2.644799441099167

Epoch: 50| Step: 0
Training loss: 2.9329349994659424
Validation loss: 2.643087645371755

Epoch: 5| Step: 1
Training loss: 2.591341495513916
Validation loss: 2.640516847372055

Epoch: 5| Step: 2
Training loss: 2.432656764984131
Validation loss: 2.6362549165884652

Epoch: 5| Step: 3
Training loss: 2.5491230487823486
Validation loss: 2.6320278644561768

Epoch: 5| Step: 4
Training loss: 2.9938220977783203
Validation loss: 2.6283886233965554

Epoch: 5| Step: 5
Training loss: 3.0769379138946533
Validation loss: 2.6260979572931924

Epoch: 5| Step: 6
Training loss: 2.7016472816467285
Validation loss: 2.624804566303889

Epoch: 5| Step: 7
Training loss: 3.298309326171875
Validation loss: 2.623782306909561

Epoch: 5| Step: 8
Training loss: 2.8492119312286377
Validation loss: 2.623020569483439

Epoch: 5| Step: 9
Training loss: 3.0171074867248535
Validation loss: 2.617993474006653

Epoch: 5| Step: 10
Training loss: 2.786684513092041
Validation loss: 2.615652402242025

Epoch: 5| Step: 11
Training loss: 2.4932587146759033
Validation loss: 2.6461829344431558

Epoch: 51| Step: 0
Training loss: 3.3501758575439453
Validation loss: 2.607935816049576

Epoch: 5| Step: 1
Training loss: 2.435258388519287
Validation loss: 2.6067975560824075

Epoch: 5| Step: 2
Training loss: 2.903637647628784
Validation loss: 2.6015457262595496

Epoch: 5| Step: 3
Training loss: 2.8531575202941895
Validation loss: 2.6006012658278146

Epoch: 5| Step: 4
Training loss: 2.9993698596954346
Validation loss: 2.599743922551473

Epoch: 5| Step: 5
Training loss: 2.5969607830047607
Validation loss: 2.5933425227801004

Epoch: 5| Step: 6
Training loss: 2.8996243476867676
Validation loss: 2.591666022936503

Epoch: 5| Step: 7
Training loss: 2.572793483734131
Validation loss: 2.5887076556682587

Epoch: 5| Step: 8
Training loss: 2.9892499446868896
Validation loss: 2.584095150232315

Epoch: 5| Step: 9
Training loss: 2.9041733741760254
Validation loss: 2.5799000759919486

Epoch: 5| Step: 10
Training loss: 2.3903286457061768
Validation loss: 2.575024644533793

Epoch: 5| Step: 11
Training loss: 2.264902353286743
Validation loss: 2.575616732239723

Epoch: 52| Step: 0
Training loss: 3.0600783824920654
Validation loss: 2.5783775250116983

Epoch: 5| Step: 1
Training loss: 3.175544261932373
Validation loss: 2.5709442496299744

Epoch: 5| Step: 2
Training loss: 2.7610697746276855
Validation loss: 2.5667944848537445

Epoch: 5| Step: 3
Training loss: 2.8473427295684814
Validation loss: 2.565952330827713

Epoch: 5| Step: 4
Training loss: 3.0651354789733887
Validation loss: 2.562811106443405

Epoch: 5| Step: 5
Training loss: 3.0097239017486572
Validation loss: 2.561652421951294

Epoch: 5| Step: 6
Training loss: 2.233656406402588
Validation loss: 2.5569573044776917

Epoch: 5| Step: 7
Training loss: 2.7339279651641846
Validation loss: 2.559569150209427

Epoch: 5| Step: 8
Training loss: 2.8234777450561523
Validation loss: 2.5556687911351523

Epoch: 5| Step: 9
Training loss: 2.191775321960449
Validation loss: 2.5505953828493753

Epoch: 5| Step: 10
Training loss: 2.7689521312713623
Validation loss: 2.550704131523768

Epoch: 5| Step: 11
Training loss: 1.2269320487976074
Validation loss: 2.542627880970637

Epoch: 53| Step: 0
Training loss: 2.5479817390441895
Validation loss: 2.5426337122917175

Epoch: 5| Step: 1
Training loss: 3.2835135459899902
Validation loss: 2.538336470723152

Epoch: 5| Step: 2
Training loss: 3.069585084915161
Validation loss: 2.5370625853538513

Epoch: 5| Step: 3
Training loss: 2.5873970985412598
Validation loss: 2.534826328357061

Epoch: 5| Step: 4
Training loss: 2.9060466289520264
Validation loss: 2.5340345203876495

Epoch: 5| Step: 5
Training loss: 2.8733534812927246
Validation loss: 2.5283314088980355

Epoch: 5| Step: 6
Training loss: 2.4669859409332275
Validation loss: 2.5263599356015525

Epoch: 5| Step: 7
Training loss: 2.6401612758636475
Validation loss: 2.5211848517258963

Epoch: 5| Step: 8
Training loss: 2.402010440826416
Validation loss: 2.523422052462896

Epoch: 5| Step: 9
Training loss: 2.7621185779571533
Validation loss: 2.5188086877266564

Epoch: 5| Step: 10
Training loss: 2.43337345123291
Validation loss: 2.5143451392650604

Epoch: 5| Step: 11
Training loss: 2.6151299476623535
Validation loss: 2.5114583571751914

Epoch: 54| Step: 0
Training loss: 3.162891149520874
Validation loss: 2.507317006587982

Epoch: 5| Step: 1
Training loss: 3.2776882648468018
Validation loss: 2.5056202113628387

Epoch: 5| Step: 2
Training loss: 1.9514200687408447
Validation loss: 2.5053549905618033

Epoch: 5| Step: 3
Training loss: 2.4245500564575195
Validation loss: 2.503789742787679

Epoch: 5| Step: 4
Training loss: 2.2742111682891846
Validation loss: 2.5001261830329895

Epoch: 5| Step: 5
Training loss: 2.9229726791381836
Validation loss: 2.4980142613252005

Epoch: 5| Step: 6
Training loss: 2.7328872680664062
Validation loss: 2.491871694723765

Epoch: 5| Step: 7
Training loss: 2.531378746032715
Validation loss: 2.4966308772563934

Epoch: 5| Step: 8
Training loss: 2.6660003662109375
Validation loss: 2.4903675665458045

Epoch: 5| Step: 9
Training loss: 2.797868013381958
Validation loss: 2.487641920646032

Epoch: 5| Step: 10
Training loss: 2.7622387409210205
Validation loss: 2.484201659758886

Epoch: 5| Step: 11
Training loss: 3.0661890506744385
Validation loss: 2.479582260052363

Epoch: 55| Step: 0
Training loss: 2.809755563735962
Validation loss: 2.4789418081442514

Epoch: 5| Step: 1
Training loss: 2.903520107269287
Validation loss: 2.480707402030627

Epoch: 5| Step: 2
Training loss: 1.8821109533309937
Validation loss: 2.4780457516511283

Epoch: 5| Step: 3
Training loss: 2.5910019874572754
Validation loss: 2.4790999641021094

Epoch: 5| Step: 4
Training loss: 3.0871987342834473
Validation loss: 2.471891780694326

Epoch: 5| Step: 5
Training loss: 2.2579143047332764
Validation loss: 2.4669045507907867

Epoch: 5| Step: 6
Training loss: 2.9206607341766357
Validation loss: 2.4665295084317527

Epoch: 5| Step: 7
Training loss: 2.7405240535736084
Validation loss: 2.459557036558787

Epoch: 5| Step: 8
Training loss: 2.9105043411254883
Validation loss: 2.4584463834762573

Epoch: 5| Step: 9
Training loss: 2.6044411659240723
Validation loss: 2.4614135175943375

Epoch: 5| Step: 10
Training loss: 2.498157501220703
Validation loss: 2.4588409662246704

Epoch: 5| Step: 11
Training loss: 2.5976405143737793
Validation loss: 2.4545771181583405

Epoch: 56| Step: 0
Training loss: 2.5310144424438477
Validation loss: 2.452547828356425

Epoch: 5| Step: 1
Training loss: 2.6373794078826904
Validation loss: 2.4506584803263345

Epoch: 5| Step: 2
Training loss: 2.662968158721924
Validation loss: 2.4426239679257074

Epoch: 5| Step: 3
Training loss: 2.950113534927368
Validation loss: 2.447422911723455

Epoch: 5| Step: 4
Training loss: 2.6294267177581787
Validation loss: 2.4450030525525412

Epoch: 5| Step: 5
Training loss: 2.2121734619140625
Validation loss: 2.4474658767382302

Epoch: 5| Step: 6
Training loss: 2.64543080329895
Validation loss: 2.437414973974228

Epoch: 5| Step: 7
Training loss: 2.4699957370758057
Validation loss: 2.4366128742694855

Epoch: 5| Step: 8
Training loss: 2.9398746490478516
Validation loss: 2.435771589477857

Epoch: 5| Step: 9
Training loss: 2.355846881866455
Validation loss: 2.4321428636709848

Epoch: 5| Step: 10
Training loss: 2.774965524673462
Validation loss: 2.4315629800160727

Epoch: 5| Step: 11
Training loss: 2.798569679260254
Validation loss: 2.4284620682398477

Epoch: 57| Step: 0
Training loss: 2.671949863433838
Validation loss: 2.4197609225908914

Epoch: 5| Step: 1
Training loss: 2.9060964584350586
Validation loss: 2.4218515853087106

Epoch: 5| Step: 2
Training loss: 2.4013237953186035
Validation loss: 2.4198442300160727

Epoch: 5| Step: 3
Training loss: 2.6760966777801514
Validation loss: 2.4188090761502585

Epoch: 5| Step: 4
Training loss: 2.724439859390259
Validation loss: 2.419205496708552

Epoch: 5| Step: 5
Training loss: 2.5296082496643066
Validation loss: 2.4108647604783378

Epoch: 5| Step: 6
Training loss: 2.9827582836151123
Validation loss: 2.4118483463923135

Epoch: 5| Step: 7
Training loss: 2.3783812522888184
Validation loss: 2.4056424697240195

Epoch: 5| Step: 8
Training loss: 2.8876678943634033
Validation loss: 2.403377046187719

Epoch: 5| Step: 9
Training loss: 2.552945613861084
Validation loss: 2.4029296239217124

Epoch: 5| Step: 10
Training loss: 1.852110505104065
Validation loss: 2.396140848596891

Epoch: 5| Step: 11
Training loss: 2.2953639030456543
Validation loss: 2.397781560818354

Epoch: 58| Step: 0
Training loss: 2.2827019691467285
Validation loss: 2.3946325878302255

Epoch: 5| Step: 1
Training loss: 2.6074233055114746
Validation loss: 2.3920735021432242

Epoch: 5| Step: 2
Training loss: 2.3133580684661865
Validation loss: 2.393452003598213

Epoch: 5| Step: 3
Training loss: 3.4406063556671143
Validation loss: 2.395081947247187

Epoch: 5| Step: 4
Training loss: 2.5191826820373535
Validation loss: 2.3966217637062073

Epoch: 5| Step: 5
Training loss: 2.1641077995300293
Validation loss: 2.401963929335276

Epoch: 5| Step: 6
Training loss: 2.6682872772216797
Validation loss: 2.3874107003211975

Epoch: 5| Step: 7
Training loss: 2.2976231575012207
Validation loss: 2.3803600470225015

Epoch: 5| Step: 8
Training loss: 3.0248465538024902
Validation loss: 2.384452154239019

Epoch: 5| Step: 9
Training loss: 2.406069278717041
Validation loss: 2.3834522465864816

Epoch: 5| Step: 10
Training loss: 2.4187021255493164
Validation loss: 2.3702927380800247

Epoch: 5| Step: 11
Training loss: 2.545935869216919
Validation loss: 2.374614636103312

Epoch: 59| Step: 0
Training loss: 2.567575693130493
Validation loss: 2.3811960170666375

Epoch: 5| Step: 1
Training loss: 2.6296684741973877
Validation loss: 2.4021629293759665

Epoch: 5| Step: 2
Training loss: 2.8941707611083984
Validation loss: 2.4030489325523376

Epoch: 5| Step: 3
Training loss: 2.3521065711975098
Validation loss: 2.388446887334188

Epoch: 5| Step: 4
Training loss: 2.936783790588379
Validation loss: 2.373711774746577

Epoch: 5| Step: 5
Training loss: 2.4380574226379395
Validation loss: 2.36214912434419

Epoch: 5| Step: 6
Training loss: 2.503554105758667
Validation loss: 2.3574022402366004

Epoch: 5| Step: 7
Training loss: 2.4145710468292236
Validation loss: 2.3512075940767923

Epoch: 5| Step: 8
Training loss: 2.5683748722076416
Validation loss: 2.35586287577947

Epoch: 5| Step: 9
Training loss: 2.5388200283050537
Validation loss: 2.3556976914405823

Epoch: 5| Step: 10
Training loss: 2.398022413253784
Validation loss: 2.352603574593862

Epoch: 5| Step: 11
Training loss: 1.192923903465271
Validation loss: 2.363302300373713

Epoch: 60| Step: 0
Training loss: 2.7275121212005615
Validation loss: 2.3591990868250527

Epoch: 5| Step: 1
Training loss: 2.9173455238342285
Validation loss: 2.35867307583491

Epoch: 5| Step: 2
Training loss: 1.9988152980804443
Validation loss: 2.3465664188067117

Epoch: 5| Step: 3
Training loss: 2.812451124191284
Validation loss: 2.342398146788279

Epoch: 5| Step: 4
Training loss: 2.8194081783294678
Validation loss: 2.3387462298075357

Epoch: 5| Step: 5
Training loss: 2.6493468284606934
Validation loss: 2.3309643864631653

Epoch: 5| Step: 6
Training loss: 2.127747058868408
Validation loss: 2.3330369889736176

Epoch: 5| Step: 7
Training loss: 2.7597532272338867
Validation loss: 2.3356957137584686

Epoch: 5| Step: 8
Training loss: 2.355205535888672
Validation loss: 2.3343665599823

Epoch: 5| Step: 9
Training loss: 2.727118968963623
Validation loss: 2.332892343401909

Epoch: 5| Step: 10
Training loss: 2.011378049850464
Validation loss: 2.328238050142924

Epoch: 5| Step: 11
Training loss: 1.039412498474121
Validation loss: 2.3256573379039764

Epoch: 61| Step: 0
Training loss: 2.6103217601776123
Validation loss: 2.324860543012619

Epoch: 5| Step: 1
Training loss: 2.2511844635009766
Validation loss: 2.314223219950994

Epoch: 5| Step: 2
Training loss: 2.8443450927734375
Validation loss: 2.317042807737986

Epoch: 5| Step: 3
Training loss: 2.2659263610839844
Validation loss: 2.3170078694820404

Epoch: 5| Step: 4
Training loss: 2.1494853496551514
Validation loss: 2.3157692154248557

Epoch: 5| Step: 5
Training loss: 2.2465293407440186
Validation loss: 2.3196574449539185

Epoch: 5| Step: 6
Training loss: 2.7382161617279053
Validation loss: 2.323821470141411

Epoch: 5| Step: 7
Training loss: 2.221806049346924
Validation loss: 2.315315226713816

Epoch: 5| Step: 8
Training loss: 2.8254477977752686
Validation loss: 2.3086934636036553

Epoch: 5| Step: 9
Training loss: 2.1965725421905518
Validation loss: 2.2990766068299613

Epoch: 5| Step: 10
Training loss: 2.744105100631714
Validation loss: 2.2936147153377533

Epoch: 5| Step: 11
Training loss: 2.6471667289733887
Validation loss: 2.289781073729197

Epoch: 62| Step: 0
Training loss: 2.79935359954834
Validation loss: 2.2953297893206277

Epoch: 5| Step: 1
Training loss: 2.593201160430908
Validation loss: 2.295715093612671

Epoch: 5| Step: 2
Training loss: 2.7447285652160645
Validation loss: 2.2910519440968833

Epoch: 5| Step: 3
Training loss: 2.108811378479004
Validation loss: 2.2902315159638724

Epoch: 5| Step: 4
Training loss: 2.694103956222534
Validation loss: 2.2950953344504037

Epoch: 5| Step: 5
Training loss: 2.487330436706543
Validation loss: 2.287336821357409

Epoch: 5| Step: 6
Training loss: 2.178211212158203
Validation loss: 2.286416898171107

Epoch: 5| Step: 7
Training loss: 2.617070436477661
Validation loss: 2.284281939268112

Epoch: 5| Step: 8
Training loss: 2.1440930366516113
Validation loss: 2.275539437929789

Epoch: 5| Step: 9
Training loss: 2.7019190788269043
Validation loss: 2.2683268984158835

Epoch: 5| Step: 10
Training loss: 2.05952787399292
Validation loss: 2.267873922983805

Epoch: 5| Step: 11
Training loss: 1.4238133430480957
Validation loss: 2.2682814995447793

Epoch: 63| Step: 0
Training loss: 2.280977249145508
Validation loss: 2.2784449656804404

Epoch: 5| Step: 1
Training loss: 2.7481465339660645
Validation loss: 2.2932004233201346

Epoch: 5| Step: 2
Training loss: 2.3297441005706787
Validation loss: 2.2832922438780465

Epoch: 5| Step: 3
Training loss: 2.2822086811065674
Validation loss: 2.2670004218816757

Epoch: 5| Step: 4
Training loss: 2.6247851848602295
Validation loss: 2.2583667188882828

Epoch: 5| Step: 5
Training loss: 2.801004648208618
Validation loss: 2.2527360220750174

Epoch: 5| Step: 6
Training loss: 2.4762299060821533
Validation loss: 2.249972090125084

Epoch: 5| Step: 7
Training loss: 2.053488254547119
Validation loss: 2.2531991998354592

Epoch: 5| Step: 8
Training loss: 2.691244602203369
Validation loss: 2.252650037407875

Epoch: 5| Step: 9
Training loss: 2.449388027191162
Validation loss: 2.258472661177317

Epoch: 5| Step: 10
Training loss: 2.0809550285339355
Validation loss: 2.256811241308848

Epoch: 5| Step: 11
Training loss: 2.4596962928771973
Validation loss: 2.2587285935878754

Epoch: 64| Step: 0
Training loss: 2.9659104347229004
Validation loss: 2.2566234866778054

Epoch: 5| Step: 1
Training loss: 1.828116774559021
Validation loss: 2.2534450789292655

Epoch: 5| Step: 2
Training loss: 3.036221981048584
Validation loss: 2.250454386075338

Epoch: 5| Step: 3
Training loss: 2.528918981552124
Validation loss: 2.2453138877948127

Epoch: 5| Step: 4
Training loss: 2.5430634021759033
Validation loss: 2.2359667470057807

Epoch: 5| Step: 5
Training loss: 2.192725658416748
Validation loss: 2.2289419571558633

Epoch: 5| Step: 6
Training loss: 2.580233335494995
Validation loss: 2.223747039834658

Epoch: 5| Step: 7
Training loss: 2.2054810523986816
Validation loss: 2.222638080517451

Epoch: 5| Step: 8
Training loss: 2.026170015335083
Validation loss: 2.2226436336835227

Epoch: 5| Step: 9
Training loss: 2.48884654045105
Validation loss: 2.2218760599692664

Epoch: 5| Step: 10
Training loss: 1.8967097997665405
Validation loss: 2.2222032894690833

Epoch: 5| Step: 11
Training loss: 2.8043036460876465
Validation loss: 2.213779995838801

Epoch: 65| Step: 0
Training loss: 2.2356021404266357
Validation loss: 2.205665558576584

Epoch: 5| Step: 1
Training loss: 2.695598840713501
Validation loss: 2.210526575644811

Epoch: 5| Step: 2
Training loss: 2.5146918296813965
Validation loss: 2.210595021645228

Epoch: 5| Step: 3
Training loss: 2.620950698852539
Validation loss: 2.210213914513588

Epoch: 5| Step: 4
Training loss: 2.0921530723571777
Validation loss: 2.211377660433451

Epoch: 5| Step: 5
Training loss: 2.6004462242126465
Validation loss: 2.2100532998641333

Epoch: 5| Step: 6
Training loss: 2.852348804473877
Validation loss: 2.2078768610954285

Epoch: 5| Step: 7
Training loss: 2.050355911254883
Validation loss: 2.2013131231069565

Epoch: 5| Step: 8
Training loss: 2.2855987548828125
Validation loss: 2.2065541545550027

Epoch: 5| Step: 9
Training loss: 2.3088572025299072
Validation loss: 2.2017760972181954

Epoch: 5| Step: 10
Training loss: 2.0099565982818604
Validation loss: 2.1959213266770043

Epoch: 5| Step: 11
Training loss: 0.8562492728233337
Validation loss: 2.1812909146149955

Epoch: 66| Step: 0
Training loss: 2.2039265632629395
Validation loss: 2.1881256252527237

Epoch: 5| Step: 1
Training loss: 1.851137399673462
Validation loss: 2.183682153622309

Epoch: 5| Step: 2
Training loss: 2.2268991470336914
Validation loss: 2.1927483826875687

Epoch: 5| Step: 3
Training loss: 2.6455235481262207
Validation loss: 2.1889882385730743

Epoch: 5| Step: 4
Training loss: 2.724968433380127
Validation loss: 2.1733098328113556

Epoch: 5| Step: 5
Training loss: 2.9595119953155518
Validation loss: 2.179846172531446

Epoch: 5| Step: 6
Training loss: 2.3917174339294434
Validation loss: 2.1796654413143792

Epoch: 5| Step: 7
Training loss: 2.23492169380188
Validation loss: 2.177577336629232

Epoch: 5| Step: 8
Training loss: 1.918677568435669
Validation loss: 2.1737764875094094

Epoch: 5| Step: 9
Training loss: 2.4001212120056152
Validation loss: 2.1745724081993103

Epoch: 5| Step: 10
Training loss: 1.9543516635894775
Validation loss: 2.171627695361773

Epoch: 5| Step: 11
Training loss: 3.5194854736328125
Validation loss: 2.172048052151998

Epoch: 67| Step: 0
Training loss: 2.049625873565674
Validation loss: 2.1732640663782754

Epoch: 5| Step: 1
Training loss: 2.1409528255462646
Validation loss: 2.176183760166168

Epoch: 5| Step: 2
Training loss: 2.376948595046997
Validation loss: 2.1703715225060782

Epoch: 5| Step: 3
Training loss: 2.551858901977539
Validation loss: 2.1677601039409637

Epoch: 5| Step: 4
Training loss: 2.246274948120117
Validation loss: 2.169426441192627

Epoch: 5| Step: 5
Training loss: 2.1511902809143066
Validation loss: 2.1637047827243805

Epoch: 5| Step: 6
Training loss: 2.174651622772217
Validation loss: 2.1631818612416587

Epoch: 5| Step: 7
Training loss: 2.421443223953247
Validation loss: 2.1640481650829315

Epoch: 5| Step: 8
Training loss: 3.172896146774292
Validation loss: 2.1596237272024155

Epoch: 5| Step: 9
Training loss: 2.058051347732544
Validation loss: 2.156798228621483

Epoch: 5| Step: 10
Training loss: 2.161262273788452
Validation loss: 2.15751447280248

Epoch: 5| Step: 11
Training loss: 2.689119338989258
Validation loss: 2.153456707795461

Epoch: 68| Step: 0
Training loss: 2.717186689376831
Validation loss: 2.1510280718406043

Epoch: 5| Step: 1
Training loss: 2.4286680221557617
Validation loss: 2.1487659960985184

Epoch: 5| Step: 2
Training loss: 1.4606940746307373
Validation loss: 2.156067803502083

Epoch: 5| Step: 3
Training loss: 2.7382214069366455
Validation loss: 2.159507488210996

Epoch: 5| Step: 4
Training loss: 2.7882180213928223
Validation loss: 2.167387237151464

Epoch: 5| Step: 5
Training loss: 1.9352035522460938
Validation loss: 2.18103755513827

Epoch: 5| Step: 6
Training loss: 1.7374026775360107
Validation loss: 2.175506671269735

Epoch: 5| Step: 7
Training loss: 2.4260501861572266
Validation loss: 2.16566031674544

Epoch: 5| Step: 8
Training loss: 3.024322509765625
Validation loss: 2.1450367271900177

Epoch: 5| Step: 9
Training loss: 2.4560725688934326
Validation loss: 2.139825458327929

Epoch: 5| Step: 10
Training loss: 1.986484169960022
Validation loss: 2.154514253139496

Epoch: 5| Step: 11
Training loss: 1.539808988571167
Validation loss: 2.1609899948040643

Epoch: 69| Step: 0
Training loss: 2.318821668624878
Validation loss: 2.173163652420044

Epoch: 5| Step: 1
Training loss: 2.3373830318450928
Validation loss: 2.1922576328118644

Epoch: 5| Step: 2
Training loss: 1.8920787572860718
Validation loss: 2.201222062110901

Epoch: 5| Step: 3
Training loss: 2.9142563343048096
Validation loss: 2.1942407141129174

Epoch: 5| Step: 4
Training loss: 2.2768852710723877
Validation loss: 2.187743494908015

Epoch: 5| Step: 5
Training loss: 2.4869940280914307
Validation loss: 2.16882332166036

Epoch: 5| Step: 6
Training loss: 2.1547577381134033
Validation loss: 2.1635102331638336

Epoch: 5| Step: 7
Training loss: 2.0052480697631836
Validation loss: 2.149140328168869

Epoch: 5| Step: 8
Training loss: 2.4999728202819824
Validation loss: 2.143650099635124

Epoch: 5| Step: 9
Training loss: 2.3382649421691895
Validation loss: 2.140369897087415

Epoch: 5| Step: 10
Training loss: 2.26656436920166
Validation loss: 2.126556172966957

Epoch: 5| Step: 11
Training loss: 2.881119728088379
Validation loss: 2.1282023787498474

Epoch: 70| Step: 0
Training loss: 2.3687984943389893
Validation loss: 2.124090443054835

Epoch: 5| Step: 1
Training loss: 2.2331557273864746
Validation loss: 2.1265249451001487

Epoch: 5| Step: 2
Training loss: 2.290391206741333
Validation loss: 2.1281075328588486

Epoch: 5| Step: 3
Training loss: 1.7738888263702393
Validation loss: 2.129886875549952

Epoch: 5| Step: 4
Training loss: 1.9454009532928467
Validation loss: 2.1311492174863815

Epoch: 5| Step: 5
Training loss: 2.6583399772644043
Validation loss: 2.1352063169082007

Epoch: 5| Step: 6
Training loss: 2.248169183731079
Validation loss: 2.1290604074796042

Epoch: 5| Step: 7
Training loss: 2.5067126750946045
Validation loss: 2.1363228311141333

Epoch: 5| Step: 8
Training loss: 2.483646869659424
Validation loss: 2.138527731100718

Epoch: 5| Step: 9
Training loss: 2.323681116104126
Validation loss: 2.127338702479998

Epoch: 5| Step: 10
Training loss: 2.478921890258789
Validation loss: 2.124486953020096

Epoch: 5| Step: 11
Training loss: 1.5619195699691772
Validation loss: 2.12040243546168

Epoch: 71| Step: 0
Training loss: 2.3220109939575195
Validation loss: 2.1196141143639884

Epoch: 5| Step: 1
Training loss: 2.267925262451172
Validation loss: 2.1178100307782493

Epoch: 5| Step: 2
Training loss: 2.0458245277404785
Validation loss: 2.1192076106866202

Epoch: 5| Step: 3
Training loss: 2.746875524520874
Validation loss: 2.1206661512454352

Epoch: 5| Step: 4
Training loss: 2.2157082557678223
Validation loss: 2.1247888058423996

Epoch: 5| Step: 5
Training loss: 2.7109897136688232
Validation loss: 2.1224035968383155

Epoch: 5| Step: 6
Training loss: 2.394287586212158
Validation loss: 2.1254718949397406

Epoch: 5| Step: 7
Training loss: 1.741206169128418
Validation loss: 2.1241762141386666

Epoch: 5| Step: 8
Training loss: 1.7041571140289307
Validation loss: 2.124009609222412

Epoch: 5| Step: 9
Training loss: 2.4951908588409424
Validation loss: 2.1209489504496255

Epoch: 5| Step: 10
Training loss: 2.587581157684326
Validation loss: 2.1198297341664634

Epoch: 5| Step: 11
Training loss: 2.260756254196167
Validation loss: 2.111180325349172

Epoch: 72| Step: 0
Training loss: 2.603431224822998
Validation loss: 2.1123502949873605

Epoch: 5| Step: 1
Training loss: 2.351174831390381
Validation loss: 2.1086756785710654

Epoch: 5| Step: 2
Training loss: 1.8400617837905884
Validation loss: 2.1105631987253823

Epoch: 5| Step: 3
Training loss: 2.2559332847595215
Validation loss: 2.1115130533774695

Epoch: 5| Step: 4
Training loss: 2.292426824569702
Validation loss: 2.1094537725051246

Epoch: 5| Step: 5
Training loss: 2.105067729949951
Validation loss: 2.1080058415730796

Epoch: 5| Step: 6
Training loss: 2.2684147357940674
Validation loss: 2.097788671652476

Epoch: 5| Step: 7
Training loss: 2.21197772026062
Validation loss: 2.100742926200231

Epoch: 5| Step: 8
Training loss: 2.3417115211486816
Validation loss: 2.1079367846250534

Epoch: 5| Step: 9
Training loss: 2.4334664344787598
Validation loss: 2.101020316282908

Epoch: 5| Step: 10
Training loss: 2.415926456451416
Validation loss: 2.097669040163358

Epoch: 5| Step: 11
Training loss: 1.7306063175201416
Validation loss: 2.0945399701595306

Epoch: 73| Step: 0
Training loss: 2.5201687812805176
Validation loss: 2.090942546725273

Epoch: 5| Step: 1
Training loss: 2.321368455886841
Validation loss: 2.101533422867457

Epoch: 5| Step: 2
Training loss: 2.9258382320404053
Validation loss: 2.103287195165952

Epoch: 5| Step: 3
Training loss: 2.0066561698913574
Validation loss: 2.102955455581347

Epoch: 5| Step: 4
Training loss: 2.0814054012298584
Validation loss: 2.113772009809812

Epoch: 5| Step: 5
Training loss: 1.8862712383270264
Validation loss: 2.121820236245791

Epoch: 5| Step: 6
Training loss: 2.557563543319702
Validation loss: 2.115308851003647

Epoch: 5| Step: 7
Training loss: 2.4492592811584473
Validation loss: 2.1133458415667215

Epoch: 5| Step: 8
Training loss: 2.337355375289917
Validation loss: 2.1098255266745887

Epoch: 5| Step: 9
Training loss: 1.933855414390564
Validation loss: 2.1139528254667916

Epoch: 5| Step: 10
Training loss: 2.1316046714782715
Validation loss: 2.101496174931526

Epoch: 5| Step: 11
Training loss: 1.4427261352539062
Validation loss: 2.101245587070783

Epoch: 74| Step: 0
Training loss: 2.39678955078125
Validation loss: 2.091850300629934

Epoch: 5| Step: 1
Training loss: 1.9615623950958252
Validation loss: 2.0917766988277435

Epoch: 5| Step: 2
Training loss: 2.521883010864258
Validation loss: 2.0883393784364066

Epoch: 5| Step: 3
Training loss: 2.1903600692749023
Validation loss: 2.090747574965159

Epoch: 5| Step: 4
Training loss: 2.2513587474823
Validation loss: 2.0828733990589776

Epoch: 5| Step: 5
Training loss: 1.9711780548095703
Validation loss: 2.086953356862068

Epoch: 5| Step: 6
Training loss: 2.5856871604919434
Validation loss: 2.0889924317598343

Epoch: 5| Step: 7
Training loss: 1.8848726749420166
Validation loss: 2.0979432264963784

Epoch: 5| Step: 8
Training loss: 2.1376850605010986
Validation loss: 2.0956426759560904

Epoch: 5| Step: 9
Training loss: 2.314424991607666
Validation loss: 2.0956896295150123

Epoch: 5| Step: 10
Training loss: 2.4168808460235596
Validation loss: 2.093343814214071

Epoch: 5| Step: 11
Training loss: 3.408674478530884
Validation loss: 2.0883144537607827

Epoch: 75| Step: 0
Training loss: 2.2852559089660645
Validation loss: 2.0785390188296637

Epoch: 5| Step: 1
Training loss: 2.3725197315216064
Validation loss: 2.0797722736994424

Epoch: 5| Step: 2
Training loss: 2.2599451541900635
Validation loss: 2.082713633775711

Epoch: 5| Step: 3
Training loss: 2.3457465171813965
Validation loss: 2.0830890933672586

Epoch: 5| Step: 4
Training loss: 2.31941294670105
Validation loss: 2.082039033373197

Epoch: 5| Step: 5
Training loss: 2.847060441970825
Validation loss: 2.0830458303292594

Epoch: 5| Step: 6
Training loss: 2.6361403465270996
Validation loss: 2.084608649214109

Epoch: 5| Step: 7
Training loss: 1.9044212102890015
Validation loss: 2.0865691155195236

Epoch: 5| Step: 8
Training loss: 1.8788087368011475
Validation loss: 2.0880399495363235

Epoch: 5| Step: 9
Training loss: 1.8601815700531006
Validation loss: 2.0820839603741965

Epoch: 5| Step: 10
Training loss: 2.071930408477783
Validation loss: 2.0806268006563187

Epoch: 5| Step: 11
Training loss: 2.2133727073669434
Validation loss: 2.0781565507253013

Epoch: 76| Step: 0
Training loss: 2.2059669494628906
Validation loss: 2.0732984046141305

Epoch: 5| Step: 1
Training loss: 2.0415635108947754
Validation loss: 2.0638271818558374

Epoch: 5| Step: 2
Training loss: 2.701610803604126
Validation loss: 2.0631266633669534

Epoch: 5| Step: 3
Training loss: 2.6109137535095215
Validation loss: 2.0588959753513336

Epoch: 5| Step: 4
Training loss: 2.149613618850708
Validation loss: 2.0670042087634406

Epoch: 5| Step: 5
Training loss: 2.374661684036255
Validation loss: 2.0700453519821167

Epoch: 5| Step: 6
Training loss: 2.0194573402404785
Validation loss: 2.064324523011843

Epoch: 5| Step: 7
Training loss: 2.2453196048736572
Validation loss: 2.0726828227440515

Epoch: 5| Step: 8
Training loss: 2.058480978012085
Validation loss: 2.076382343967756

Epoch: 5| Step: 9
Training loss: 1.747693657875061
Validation loss: 2.0612174967924752

Epoch: 5| Step: 10
Training loss: 2.545086622238159
Validation loss: 2.0711874465147653

Epoch: 5| Step: 11
Training loss: 2.0036301612854004
Validation loss: 2.07792821029822

Epoch: 77| Step: 0
Training loss: 2.5165858268737793
Validation loss: 2.066640983025233

Epoch: 5| Step: 1
Training loss: 1.973283052444458
Validation loss: 2.060964991648992

Epoch: 5| Step: 2
Training loss: 2.4107377529144287
Validation loss: 2.062888582547506

Epoch: 5| Step: 3
Training loss: 2.267228126525879
Validation loss: 2.058704858024915

Epoch: 5| Step: 4
Training loss: 2.398211717605591
Validation loss: 2.0499154527982077

Epoch: 5| Step: 5
Training loss: 2.3471226692199707
Validation loss: 2.0459900200366974

Epoch: 5| Step: 6
Training loss: 2.0193095207214355
Validation loss: 2.0525351464748383

Epoch: 5| Step: 7
Training loss: 2.051008701324463
Validation loss: 2.0500974158445993

Epoch: 5| Step: 8
Training loss: 2.244889736175537
Validation loss: 2.0553350349267325

Epoch: 5| Step: 9
Training loss: 2.3496789932250977
Validation loss: 2.054100548227628

Epoch: 5| Step: 10
Training loss: 2.0161287784576416
Validation loss: 2.0522900819778442

Epoch: 5| Step: 11
Training loss: 1.7413321733474731
Validation loss: 2.0541513512531915

Epoch: 78| Step: 0
Training loss: 1.9305340051651
Validation loss: 2.0522256245215735

Epoch: 5| Step: 1
Training loss: 2.375708818435669
Validation loss: 2.053876648346583

Epoch: 5| Step: 2
Training loss: 2.372615098953247
Validation loss: 2.049769252538681

Epoch: 5| Step: 3
Training loss: 2.230393886566162
Validation loss: 2.0520091205835342

Epoch: 5| Step: 4
Training loss: 2.390058994293213
Validation loss: 2.0468399624029794

Epoch: 5| Step: 5
Training loss: 2.5697686672210693
Validation loss: 2.041000078121821

Epoch: 5| Step: 6
Training loss: 2.552807569503784
Validation loss: 2.042124847571055

Epoch: 5| Step: 7
Training loss: 2.1859912872314453
Validation loss: 2.051625912388166

Epoch: 5| Step: 8
Training loss: 2.237886428833008
Validation loss: 2.05576462050279

Epoch: 5| Step: 9
Training loss: 1.7080224752426147
Validation loss: 2.0520222187042236

Epoch: 5| Step: 10
Training loss: 1.909131646156311
Validation loss: 2.049340079228083

Epoch: 5| Step: 11
Training loss: 1.5554277896881104
Validation loss: 2.047659287850062

Epoch: 79| Step: 0
Training loss: 2.032782793045044
Validation loss: 2.057034487525622

Epoch: 5| Step: 1
Training loss: 2.3645429611206055
Validation loss: 2.0521481235822043

Epoch: 5| Step: 2
Training loss: 1.8413556814193726
Validation loss: 2.0522812604904175

Epoch: 5| Step: 3
Training loss: 2.4416377544403076
Validation loss: 2.0520060112078986

Epoch: 5| Step: 4
Training loss: 2.152930736541748
Validation loss: 2.0446350127458572

Epoch: 5| Step: 5
Training loss: 2.606527328491211
Validation loss: 2.048740645249685

Epoch: 5| Step: 6
Training loss: 2.205216646194458
Validation loss: 2.048618664344152

Epoch: 5| Step: 7
Training loss: 2.1603379249572754
Validation loss: 2.0499935249487558

Epoch: 5| Step: 8
Training loss: 2.3001227378845215
Validation loss: 2.0497254927953086

Epoch: 5| Step: 9
Training loss: 2.039278268814087
Validation loss: 2.046046813329061

Epoch: 5| Step: 10
Training loss: 2.1827378273010254
Validation loss: 2.0485130151112876

Epoch: 5| Step: 11
Training loss: 3.3368401527404785
Validation loss: 2.0400140831867852

Epoch: 80| Step: 0
Training loss: 1.2078348398208618
Validation loss: 2.0400219609340033

Epoch: 5| Step: 1
Training loss: 2.0959506034851074
Validation loss: 2.040060634414355

Epoch: 5| Step: 2
Training loss: 2.5513815879821777
Validation loss: 2.04908853272597

Epoch: 5| Step: 3
Training loss: 2.088209629058838
Validation loss: 2.047028034925461

Epoch: 5| Step: 4
Training loss: 2.7772388458251953
Validation loss: 2.0521024962266288

Epoch: 5| Step: 5
Training loss: 2.569974422454834
Validation loss: 2.0519721607367196

Epoch: 5| Step: 6
Training loss: 2.2515869140625
Validation loss: 2.050428772966067

Epoch: 5| Step: 7
Training loss: 1.966043472290039
Validation loss: 2.048993652065595

Epoch: 5| Step: 8
Training loss: 2.582846164703369
Validation loss: 2.043406143784523

Epoch: 5| Step: 9
Training loss: 1.661960244178772
Validation loss: 2.0435235649347305

Epoch: 5| Step: 10
Training loss: 2.497394323348999
Validation loss: 2.05701544880867

Epoch: 5| Step: 11
Training loss: 2.746406078338623
Validation loss: 2.0551525255044303

Epoch: 81| Step: 0
Training loss: 2.4824931621551514
Validation loss: 2.060008853673935

Epoch: 5| Step: 1
Training loss: 2.3607888221740723
Validation loss: 2.0495961556831994

Epoch: 5| Step: 2
Training loss: 2.4347190856933594
Validation loss: 2.0428374260663986

Epoch: 5| Step: 3
Training loss: 2.2500357627868652
Validation loss: 2.045752838253975

Epoch: 5| Step: 4
Training loss: 2.0252532958984375
Validation loss: 2.0396137783924737

Epoch: 5| Step: 5
Training loss: 1.976051688194275
Validation loss: 2.0404921720425286

Epoch: 5| Step: 6
Training loss: 2.161144256591797
Validation loss: 2.037208909789721

Epoch: 5| Step: 7
Training loss: 2.414391279220581
Validation loss: 2.0322494308153787

Epoch: 5| Step: 8
Training loss: 2.0355334281921387
Validation loss: 2.0304285138845444

Epoch: 5| Step: 9
Training loss: 1.56862473487854
Validation loss: 2.042341560125351

Epoch: 5| Step: 10
Training loss: 2.4756908416748047
Validation loss: 2.046651060382525

Epoch: 5| Step: 11
Training loss: 2.565708637237549
Validation loss: 2.036947856346766

Epoch: 82| Step: 0
Training loss: 2.063138961791992
Validation loss: 2.0298843334118524

Epoch: 5| Step: 1
Training loss: 2.2321226596832275
Validation loss: 2.034512927134832

Epoch: 5| Step: 2
Training loss: 2.3149781227111816
Validation loss: 2.025247206290563

Epoch: 5| Step: 3
Training loss: 2.4358673095703125
Validation loss: 2.0290685445070267

Epoch: 5| Step: 4
Training loss: 1.9989824295043945
Validation loss: 2.023768832286199

Epoch: 5| Step: 5
Training loss: 2.401870012283325
Validation loss: 2.0261632055044174

Epoch: 5| Step: 6
Training loss: 1.928053855895996
Validation loss: 2.025814116001129

Epoch: 5| Step: 7
Training loss: 2.266641616821289
Validation loss: 2.032120664914449

Epoch: 5| Step: 8
Training loss: 2.201612949371338
Validation loss: 2.0325183272361755

Epoch: 5| Step: 9
Training loss: 2.086693286895752
Validation loss: 2.0346751610438027

Epoch: 5| Step: 10
Training loss: 2.605154275894165
Validation loss: 2.036204367876053

Epoch: 5| Step: 11
Training loss: 0.4300079345703125
Validation loss: 2.0329315761725106

Epoch: 83| Step: 0
Training loss: 2.440128803253174
Validation loss: 2.0333690494298935

Epoch: 5| Step: 1
Training loss: 2.272707462310791
Validation loss: 2.039445087313652

Epoch: 5| Step: 2
Training loss: 2.042996883392334
Validation loss: 2.0392877956231437

Epoch: 5| Step: 3
Training loss: 2.0138189792633057
Validation loss: 2.0439818849166236

Epoch: 5| Step: 4
Training loss: 2.2272560596466064
Validation loss: 2.0431040972471237

Epoch: 5| Step: 5
Training loss: 1.9524269104003906
Validation loss: 2.042245785395304

Epoch: 5| Step: 6
Training loss: 2.1927056312561035
Validation loss: 2.026251961787542

Epoch: 5| Step: 7
Training loss: 2.2114453315734863
Validation loss: 2.024510403474172

Epoch: 5| Step: 8
Training loss: 2.5133607387542725
Validation loss: 2.0278590073188147

Epoch: 5| Step: 9
Training loss: 2.22428560256958
Validation loss: 2.0288304835557938

Epoch: 5| Step: 10
Training loss: 2.459430456161499
Validation loss: 2.033949246009191

Epoch: 5| Step: 11
Training loss: 0.6844770908355713
Validation loss: 2.03021639585495

Epoch: 84| Step: 0
Training loss: 2.3527328968048096
Validation loss: 2.034997155268987

Epoch: 5| Step: 1
Training loss: 2.391918420791626
Validation loss: 2.0264521539211273

Epoch: 5| Step: 2
Training loss: 2.636854648590088
Validation loss: 2.026364912589391

Epoch: 5| Step: 3
Training loss: 1.9483391046524048
Validation loss: 2.0300704886515937

Epoch: 5| Step: 4
Training loss: 2.250326633453369
Validation loss: 2.03342812259992

Epoch: 5| Step: 5
Training loss: 2.3135199546813965
Validation loss: 2.026134207844734

Epoch: 5| Step: 6
Training loss: 2.1354804039001465
Validation loss: 2.0282619496186576

Epoch: 5| Step: 7
Training loss: 2.308088779449463
Validation loss: 2.0245934426784515

Epoch: 5| Step: 8
Training loss: 1.7914825677871704
Validation loss: 2.028575619061788

Epoch: 5| Step: 9
Training loss: 1.9695909023284912
Validation loss: 2.031656185785929

Epoch: 5| Step: 10
Training loss: 2.0385799407958984
Validation loss: 2.025474414229393

Epoch: 5| Step: 11
Training loss: 1.6264539957046509
Validation loss: 2.0530956188837686

Epoch: 85| Step: 0
Training loss: 2.360851764678955
Validation loss: 2.0381766259670258

Epoch: 5| Step: 1
Training loss: 2.136025905609131
Validation loss: 2.035043478012085

Epoch: 5| Step: 2
Training loss: 1.6856215000152588
Validation loss: 2.03448623418808

Epoch: 5| Step: 3
Training loss: 2.2549586296081543
Validation loss: 2.04691419005394

Epoch: 5| Step: 4
Training loss: 1.8747316598892212
Validation loss: 2.0259395887454352

Epoch: 5| Step: 5
Training loss: 2.4815969467163086
Validation loss: 2.037743255496025

Epoch: 5| Step: 6
Training loss: 2.16949462890625
Validation loss: 2.029877250393232

Epoch: 5| Step: 7
Training loss: 1.998573660850525
Validation loss: 2.0285240759452186

Epoch: 5| Step: 8
Training loss: 1.7985365390777588
Validation loss: 2.0320419718821845

Epoch: 5| Step: 9
Training loss: 2.654585123062134
Validation loss: 2.0341835021972656

Epoch: 5| Step: 10
Training loss: 2.5977160930633545
Validation loss: 2.033398389816284

Epoch: 5| Step: 11
Training loss: 1.8196748495101929
Validation loss: 2.030019844571749

Epoch: 86| Step: 0
Training loss: 2.4575324058532715
Validation loss: 2.031088431676229

Epoch: 5| Step: 1
Training loss: 2.192570447921753
Validation loss: 2.026906723777453

Epoch: 5| Step: 2
Training loss: 2.520369529724121
Validation loss: 2.0305064817269645

Epoch: 5| Step: 3
Training loss: 2.5317187309265137
Validation loss: 2.0399374216794968

Epoch: 5| Step: 4
Training loss: 2.04750657081604
Validation loss: 2.0416815082232156

Epoch: 5| Step: 5
Training loss: 1.4879848957061768
Validation loss: 2.043132116397222

Epoch: 5| Step: 6
Training loss: 1.8694223165512085
Validation loss: 2.0440283020337424

Epoch: 5| Step: 7
Training loss: 2.5521419048309326
Validation loss: 2.044551302989324

Epoch: 5| Step: 8
Training loss: 2.405489444732666
Validation loss: 2.037762224674225

Epoch: 5| Step: 9
Training loss: 2.127333164215088
Validation loss: 2.026047314206759

Epoch: 5| Step: 10
Training loss: 2.196828603744507
Validation loss: 2.0230141977469125

Epoch: 5| Step: 11
Training loss: 1.7735395431518555
Validation loss: 2.0298080841700235

Epoch: 87| Step: 0
Training loss: 2.137651205062866
Validation loss: 2.0264416436354318

Epoch: 5| Step: 1
Training loss: 2.1619954109191895
Validation loss: 2.021454950173696

Epoch: 5| Step: 2
Training loss: 2.1514968872070312
Validation loss: 2.019404153029124

Epoch: 5| Step: 3
Training loss: 2.002707004547119
Validation loss: 2.0206125428279242

Epoch: 5| Step: 4
Training loss: 2.6678450107574463
Validation loss: 2.0233214795589447

Epoch: 5| Step: 5
Training loss: 2.7486186027526855
Validation loss: 2.019619216521581

Epoch: 5| Step: 6
Training loss: 2.404794216156006
Validation loss: 2.0296725978453956

Epoch: 5| Step: 7
Training loss: 1.8454320430755615
Validation loss: 2.019197091460228

Epoch: 5| Step: 8
Training loss: 2.051835298538208
Validation loss: 2.031003604332606

Epoch: 5| Step: 9
Training loss: 2.332253932952881
Validation loss: 2.0243734071652093

Epoch: 5| Step: 10
Training loss: 1.515161156654358
Validation loss: 2.0238219797611237

Epoch: 5| Step: 11
Training loss: 2.0375585556030273
Validation loss: 2.0248451282580695

Epoch: 88| Step: 0
Training loss: 2.2960991859436035
Validation loss: 2.030349001288414

Epoch: 5| Step: 1
Training loss: 2.0249602794647217
Validation loss: 2.0366527686516442

Epoch: 5| Step: 2
Training loss: 2.036991834640503
Validation loss: 2.0409533182779946

Epoch: 5| Step: 3
Training loss: 2.548593521118164
Validation loss: 2.0333230594793954

Epoch: 5| Step: 4
Training loss: 2.3294856548309326
Validation loss: 2.030404175321261

Epoch: 5| Step: 5
Training loss: 2.5763099193573
Validation loss: 2.0284671833117804

Epoch: 5| Step: 6
Training loss: 2.1001458168029785
Validation loss: 2.0187531610329947

Epoch: 5| Step: 7
Training loss: 2.649031400680542
Validation loss: 2.02494948108991

Epoch: 5| Step: 8
Training loss: 1.70639169216156
Validation loss: 2.0298445324103036

Epoch: 5| Step: 9
Training loss: 2.0302977561950684
Validation loss: 2.02146577835083

Epoch: 5| Step: 10
Training loss: 1.8157999515533447
Validation loss: 2.026827096939087

Epoch: 5| Step: 11
Training loss: 1.115438461303711
Validation loss: 2.030177687605222

Epoch: 89| Step: 0
Training loss: 2.05775785446167
Validation loss: 2.0287439823150635

Epoch: 5| Step: 1
Training loss: 2.091691017150879
Validation loss: 2.013028840223948

Epoch: 5| Step: 2
Training loss: 3.1648693084716797
Validation loss: 2.0230979720751443

Epoch: 5| Step: 3
Training loss: 2.3267714977264404
Validation loss: 2.027021199464798

Epoch: 5| Step: 4
Training loss: 1.9745365381240845
Validation loss: 2.03215000530084

Epoch: 5| Step: 5
Training loss: 2.012807846069336
Validation loss: 2.032082661986351

Epoch: 5| Step: 6
Training loss: 1.8869667053222656
Validation loss: 2.0288905451695123

Epoch: 5| Step: 7
Training loss: 2.3845152854919434
Validation loss: 2.0235246121883392

Epoch: 5| Step: 8
Training loss: 2.047015905380249
Validation loss: 2.014325658480326

Epoch: 5| Step: 9
Training loss: 1.7499364614486694
Validation loss: 2.0166929264863334

Epoch: 5| Step: 10
Training loss: 2.3827366828918457
Validation loss: 2.0196296870708466

Epoch: 5| Step: 11
Training loss: 2.1572060585021973
Validation loss: 2.0133533428112664

Epoch: 90| Step: 0
Training loss: 1.9166767597198486
Validation loss: 2.0248487840096154

Epoch: 5| Step: 1
Training loss: 2.2779860496520996
Validation loss: 2.02017550667127

Epoch: 5| Step: 2
Training loss: 2.227949380874634
Validation loss: 2.0234460482994714

Epoch: 5| Step: 3
Training loss: 2.3591370582580566
Validation loss: 2.029467925429344

Epoch: 5| Step: 4
Training loss: 2.3008534908294678
Validation loss: 2.0273060301939645

Epoch: 5| Step: 5
Training loss: 2.0804879665374756
Validation loss: 2.0326371788978577

Epoch: 5| Step: 6
Training loss: 2.5776968002319336
Validation loss: 2.0203718741734824

Epoch: 5| Step: 7
Training loss: 2.219684600830078
Validation loss: 2.021810919046402

Epoch: 5| Step: 8
Training loss: 2.126163959503174
Validation loss: 2.0186899503072104

Epoch: 5| Step: 9
Training loss: 1.630871057510376
Validation loss: 2.0199959526459375

Epoch: 5| Step: 10
Training loss: 2.307633638381958
Validation loss: 2.02497731645902

Epoch: 5| Step: 11
Training loss: 2.40092134475708
Validation loss: 2.0166801114877067

Epoch: 91| Step: 0
Training loss: 1.8667967319488525
Validation loss: 2.021337702870369

Epoch: 5| Step: 1
Training loss: 1.9109992980957031
Validation loss: 2.022307207187017

Epoch: 5| Step: 2
Training loss: 2.0353312492370605
Validation loss: 2.0275819351275763

Epoch: 5| Step: 3
Training loss: 3.1092867851257324
Validation loss: 2.0257861763238907

Epoch: 5| Step: 4
Training loss: 1.9742345809936523
Validation loss: 2.029264137148857

Epoch: 5| Step: 5
Training loss: 1.8311312198638916
Validation loss: 2.031224916378657

Epoch: 5| Step: 6
Training loss: 2.2351748943328857
Validation loss: 2.028989533583323

Epoch: 5| Step: 7
Training loss: 1.6409046649932861
Validation loss: 2.0424839655558267

Epoch: 5| Step: 8
Training loss: 2.2481415271759033
Validation loss: 2.0371815214554467

Epoch: 5| Step: 9
Training loss: 2.410996675491333
Validation loss: 2.0420277416706085

Epoch: 5| Step: 10
Training loss: 2.6444783210754395
Validation loss: 2.0349652419487634

Epoch: 5| Step: 11
Training loss: 1.4424599409103394
Validation loss: 2.0332053899765015

Epoch: 92| Step: 0
Training loss: 2.27964448928833
Validation loss: 2.026674514015516

Epoch: 5| Step: 1
Training loss: 2.4615676403045654
Validation loss: 2.0226617604494095

Epoch: 5| Step: 2
Training loss: 2.1500072479248047
Validation loss: 2.027442216873169

Epoch: 5| Step: 3
Training loss: 1.8362048864364624
Validation loss: 2.015815148750941

Epoch: 5| Step: 4
Training loss: 2.1035046577453613
Validation loss: 2.025992751121521

Epoch: 5| Step: 5
Training loss: 2.0229194164276123
Validation loss: 2.013541509707769

Epoch: 5| Step: 6
Training loss: 2.1704764366149902
Validation loss: 2.0189666698376336

Epoch: 5| Step: 7
Training loss: 2.078781843185425
Validation loss: 2.0203446994225183

Epoch: 5| Step: 8
Training loss: 1.8054271936416626
Validation loss: 2.0163738081852594

Epoch: 5| Step: 9
Training loss: 2.632053852081299
Validation loss: 2.0164977610111237

Epoch: 5| Step: 10
Training loss: 2.210766077041626
Validation loss: 2.015433743596077

Epoch: 5| Step: 11
Training loss: 2.399384021759033
Validation loss: 2.017370248834292

Epoch: 93| Step: 0
Training loss: 2.1625657081604004
Validation loss: 2.020384465654691

Epoch: 5| Step: 1
Training loss: 2.0773956775665283
Validation loss: 2.0221983095010123

Epoch: 5| Step: 2
Training loss: 1.9088900089263916
Validation loss: 2.03342571357886

Epoch: 5| Step: 3
Training loss: 2.0409247875213623
Validation loss: 2.040885974963506

Epoch: 5| Step: 4
Training loss: 2.766380786895752
Validation loss: 2.0308655351400375

Epoch: 5| Step: 5
Training loss: 1.5270271301269531
Validation loss: 2.025733490784963

Epoch: 5| Step: 6
Training loss: 2.506885528564453
Validation loss: 2.0246155063311257

Epoch: 5| Step: 7
Training loss: 1.5935308933258057
Validation loss: 2.032764032483101

Epoch: 5| Step: 8
Training loss: 1.932620644569397
Validation loss: 2.029542957743009

Epoch: 5| Step: 9
Training loss: 2.5181143283843994
Validation loss: 2.0306154737869897

Epoch: 5| Step: 10
Training loss: 2.63508939743042
Validation loss: 2.0288120061159134

Epoch: 5| Step: 11
Training loss: 3.2120473384857178
Validation loss: 2.0281346241633096

Epoch: 94| Step: 0
Training loss: 1.5556025505065918
Validation loss: 2.0259660184383392

Epoch: 5| Step: 1
Training loss: 1.890851616859436
Validation loss: 2.0259624967972436

Epoch: 5| Step: 2
Training loss: 2.2477569580078125
Validation loss: 2.0256245086590448

Epoch: 5| Step: 3
Training loss: 2.1904497146606445
Validation loss: 2.024175157149633

Epoch: 5| Step: 4
Training loss: 1.7532100677490234
Validation loss: 2.0238850762446723

Epoch: 5| Step: 5
Training loss: 2.432476282119751
Validation loss: 2.022562329967817

Epoch: 5| Step: 6
Training loss: 2.107024669647217
Validation loss: 2.0183893193801246

Epoch: 5| Step: 7
Training loss: 2.188370704650879
Validation loss: 2.0229173451662064

Epoch: 5| Step: 8
Training loss: 2.385861396789551
Validation loss: 2.0264386186997094

Epoch: 5| Step: 9
Training loss: 2.3982129096984863
Validation loss: 2.0336456348498664

Epoch: 5| Step: 10
Training loss: 2.3855156898498535
Validation loss: 2.0443782210350037

Epoch: 5| Step: 11
Training loss: 2.484720230102539
Validation loss: 2.044104114174843

Epoch: 95| Step: 0
Training loss: 2.3729782104492188
Validation loss: 2.022319177786509

Epoch: 5| Step: 1
Training loss: 2.3492257595062256
Validation loss: 2.018215591708819

Epoch: 5| Step: 2
Training loss: 2.1705214977264404
Validation loss: 2.026677370071411

Epoch: 5| Step: 3
Training loss: 1.817838430404663
Validation loss: 2.032971665263176

Epoch: 5| Step: 4
Training loss: 2.686272382736206
Validation loss: 2.031580130259196

Epoch: 5| Step: 5
Training loss: 2.021461009979248
Validation loss: 2.041271761059761

Epoch: 5| Step: 6
Training loss: 1.6498998403549194
Validation loss: 2.0258319973945618

Epoch: 5| Step: 7
Training loss: 2.1700711250305176
Validation loss: 2.0253766079743705

Epoch: 5| Step: 8
Training loss: 2.258563280105591
Validation loss: 2.022671197851499

Epoch: 5| Step: 9
Training loss: 2.0034193992614746
Validation loss: 2.0136851320664086

Epoch: 5| Step: 10
Training loss: 2.5466690063476562
Validation loss: 2.0202123820781708

Epoch: 5| Step: 11
Training loss: 0.15214502811431885
Validation loss: 2.0191399653752646

Epoch: 96| Step: 0
Training loss: 2.2077584266662598
Validation loss: 2.0297997246185937

Epoch: 5| Step: 1
Training loss: 2.3626577854156494
Validation loss: 2.035934790968895

Epoch: 5| Step: 2
Training loss: 2.8275465965270996
Validation loss: 2.032604689399401

Epoch: 5| Step: 3
Training loss: 2.044309139251709
Validation loss: 2.0280165622631707

Epoch: 5| Step: 4
Training loss: 1.6262582540512085
Validation loss: 2.034958307941755

Epoch: 5| Step: 5
Training loss: 2.1711883544921875
Validation loss: 2.024020473162333

Epoch: 5| Step: 6
Training loss: 1.5986759662628174
Validation loss: 2.0232729266087213

Epoch: 5| Step: 7
Training loss: 1.9742809534072876
Validation loss: 2.0236076513926187

Epoch: 5| Step: 8
Training loss: 2.116647720336914
Validation loss: 2.016507402062416

Epoch: 5| Step: 9
Training loss: 2.499744176864624
Validation loss: 2.029085487127304

Epoch: 5| Step: 10
Training loss: 2.0899531841278076
Validation loss: 2.0204513470331826

Epoch: 5| Step: 11
Training loss: 2.5125787258148193
Validation loss: 2.0321003595987954

Epoch: 97| Step: 0
Training loss: 2.5306901931762695
Validation loss: 2.0180067668358483

Epoch: 5| Step: 1
Training loss: 2.2689430713653564
Validation loss: 2.0231737792491913

Epoch: 5| Step: 2
Training loss: 2.2616043090820312
Validation loss: 2.023702690998713

Epoch: 5| Step: 3
Training loss: 2.3843982219696045
Validation loss: 2.0244586964448295

Epoch: 5| Step: 4
Training loss: 2.653197765350342
Validation loss: 2.028532460331917

Epoch: 5| Step: 5
Training loss: 1.6477792263031006
Validation loss: 2.0186170240243277

Epoch: 5| Step: 6
Training loss: 2.5315353870391846
Validation loss: 2.0097910513480506

Epoch: 5| Step: 7
Training loss: 2.3476643562316895
Validation loss: 2.01876799762249

Epoch: 5| Step: 8
Training loss: 1.993841528892517
Validation loss: 2.010717342297236

Epoch: 5| Step: 9
Training loss: 1.7712876796722412
Validation loss: 2.018131415049235

Epoch: 5| Step: 10
Training loss: 1.8585017919540405
Validation loss: 2.0117936382691064

Epoch: 5| Step: 11
Training loss: 0.6336079835891724
Validation loss: 2.0134661396344504

Epoch: 98| Step: 0
Training loss: 2.43910551071167
Validation loss: 2.0099280923604965

Epoch: 5| Step: 1
Training loss: 2.2237188816070557
Validation loss: 2.002968043088913

Epoch: 5| Step: 2
Training loss: 1.971225380897522
Validation loss: 2.0082443356513977

Epoch: 5| Step: 3
Training loss: 1.9330793619155884
Validation loss: 2.00969360768795

Epoch: 5| Step: 4
Training loss: 2.0723719596862793
Validation loss: 2.002340023716291

Epoch: 5| Step: 5
Training loss: 1.771935224533081
Validation loss: 2.0102859189112983

Epoch: 5| Step: 6
Training loss: 2.0385642051696777
Validation loss: 2.0102285544077554

Epoch: 5| Step: 7
Training loss: 2.718604564666748
Validation loss: 2.008991693456968

Epoch: 5| Step: 8
Training loss: 2.222625970840454
Validation loss: 2.009490191936493

Epoch: 5| Step: 9
Training loss: 2.236525058746338
Validation loss: 2.013796259959539

Epoch: 5| Step: 10
Training loss: 2.0791046619415283
Validation loss: 2.0172122468551

Epoch: 5| Step: 11
Training loss: 2.164926052093506
Validation loss: 2.0307629307111106

Epoch: 99| Step: 0
Training loss: 2.0498900413513184
Validation loss: 2.02706611653169

Epoch: 5| Step: 1
Training loss: 2.8499855995178223
Validation loss: 2.0202586352825165

Epoch: 5| Step: 2
Training loss: 2.345432996749878
Validation loss: 2.019904057184855

Epoch: 5| Step: 3
Training loss: 2.2340033054351807
Validation loss: 2.020267461736997

Epoch: 5| Step: 4
Training loss: 2.03859281539917
Validation loss: 2.0128870606422424

Epoch: 5| Step: 5
Training loss: 1.6375339031219482
Validation loss: 2.017112612724304

Epoch: 5| Step: 6
Training loss: 2.329151153564453
Validation loss: 2.008792911966642

Epoch: 5| Step: 7
Training loss: 2.171316623687744
Validation loss: 2.005848467350006

Epoch: 5| Step: 8
Training loss: 2.765031337738037
Validation loss: 2.0054934521516166

Epoch: 5| Step: 9
Training loss: 1.6813316345214844
Validation loss: 2.018564055363337

Epoch: 5| Step: 10
Training loss: 1.6058037281036377
Validation loss: 2.018841659029325

Epoch: 5| Step: 11
Training loss: 1.7326589822769165
Validation loss: 2.026657228668531

Epoch: 100| Step: 0
Training loss: 2.690385103225708
Validation loss: 2.0249908566474915

Epoch: 5| Step: 1
Training loss: 1.7283378839492798
Validation loss: 2.0285576035579047

Epoch: 5| Step: 2
Training loss: 2.1467461585998535
Validation loss: 2.02945110698541

Epoch: 5| Step: 3
Training loss: 2.108396053314209
Validation loss: 2.030172804991404

Epoch: 5| Step: 4
Training loss: 1.7958341836929321
Validation loss: 2.0465975552797318

Epoch: 5| Step: 5
Training loss: 2.130394697189331
Validation loss: 2.033357247710228

Epoch: 5| Step: 6
Training loss: 2.2735562324523926
Validation loss: 2.0375754634539285

Epoch: 5| Step: 7
Training loss: 2.0764553546905518
Validation loss: 2.0415127128362656

Epoch: 5| Step: 8
Training loss: 1.8224480152130127
Validation loss: 2.036620408296585

Epoch: 5| Step: 9
Training loss: 2.6461784839630127
Validation loss: 2.019010623296102

Epoch: 5| Step: 10
Training loss: 2.179215431213379
Validation loss: 2.02106940249602

Epoch: 5| Step: 11
Training loss: 2.3840584754943848
Validation loss: 2.0141618798176446

Epoch: 101| Step: 0
Training loss: 2.152057647705078
Validation loss: 2.0056660572687783

Epoch: 5| Step: 1
Training loss: 2.535214900970459
Validation loss: 2.0177914748589196

Epoch: 5| Step: 2
Training loss: 2.3565635681152344
Validation loss: 2.0208865056435266

Epoch: 5| Step: 3
Training loss: 2.3328771591186523
Validation loss: 2.0215514600276947

Epoch: 5| Step: 4
Training loss: 1.3975425958633423
Validation loss: 2.0281914323568344

Epoch: 5| Step: 5
Training loss: 1.9522778987884521
Validation loss: 2.0279183834791183

Epoch: 5| Step: 6
Training loss: 2.4158570766448975
Validation loss: 2.0300568441549935

Epoch: 5| Step: 7
Training loss: 2.0927696228027344
Validation loss: 2.023097182313601

Epoch: 5| Step: 8
Training loss: 2.3082756996154785
Validation loss: 2.024489253759384

Epoch: 5| Step: 9
Training loss: 1.6087110042572021
Validation loss: 2.021922374765078

Epoch: 5| Step: 10
Training loss: 2.7340519428253174
Validation loss: 2.0214999864498773

Epoch: 5| Step: 11
Training loss: 1.980172872543335
Validation loss: 2.0113640328248343

Epoch: 102| Step: 0
Training loss: 2.6527843475341797
Validation loss: 2.01275501648585

Epoch: 5| Step: 1
Training loss: 1.998676061630249
Validation loss: 2.0198478996753693

Epoch: 5| Step: 2
Training loss: 1.7375164031982422
Validation loss: 2.011287108063698

Epoch: 5| Step: 3
Training loss: 1.5336647033691406
Validation loss: 2.0129310389359794

Epoch: 5| Step: 4
Training loss: 2.419992685317993
Validation loss: 2.0104366640249887

Epoch: 5| Step: 5
Training loss: 2.483518362045288
Validation loss: 2.0184514969587326

Epoch: 5| Step: 6
Training loss: 2.0336906909942627
Validation loss: 2.019144207239151

Epoch: 5| Step: 7
Training loss: 1.9278240203857422
Validation loss: 2.015807494521141

Epoch: 5| Step: 8
Training loss: 2.3235650062561035
Validation loss: 2.018640940388044

Epoch: 5| Step: 9
Training loss: 1.8495762348175049
Validation loss: 2.028525412082672

Epoch: 5| Step: 10
Training loss: 2.378206729888916
Validation loss: 2.016883820295334

Epoch: 5| Step: 11
Training loss: 3.628209114074707
Validation loss: 2.0279416193564734

Epoch: 103| Step: 0
Training loss: 2.1577367782592773
Validation loss: 2.0232634594043097

Epoch: 5| Step: 1
Training loss: 2.1613845825195312
Validation loss: 2.0263181080420813

Epoch: 5| Step: 2
Training loss: 2.2857069969177246
Validation loss: 2.026024783651034

Epoch: 5| Step: 3
Training loss: 2.3570868968963623
Validation loss: 2.0150320132573447

Epoch: 5| Step: 4
Training loss: 2.5701916217803955
Validation loss: 2.017050395409266

Epoch: 5| Step: 5
Training loss: 2.299288272857666
Validation loss: 2.012455999851227

Epoch: 5| Step: 6
Training loss: 1.8726985454559326
Validation loss: 2.017701730132103

Epoch: 5| Step: 7
Training loss: 2.39300274848938
Validation loss: 2.005028416713079

Epoch: 5| Step: 8
Training loss: 2.3088831901550293
Validation loss: 2.008329982558886

Epoch: 5| Step: 9
Training loss: 1.5473097562789917
Validation loss: 2.007334644595782

Epoch: 5| Step: 10
Training loss: 1.662755012512207
Validation loss: 2.009569838643074

Epoch: 5| Step: 11
Training loss: 2.0558364391326904
Validation loss: 2.004256457090378

Epoch: 104| Step: 0
Training loss: 1.9566376209259033
Validation loss: 2.007198616862297

Epoch: 5| Step: 1
Training loss: 2.3235039710998535
Validation loss: 2.0052067637443542

Epoch: 5| Step: 2
Training loss: 2.575167655944824
Validation loss: 2.013124773899714

Epoch: 5| Step: 3
Training loss: 2.3946094512939453
Validation loss: 2.0031775484482446

Epoch: 5| Step: 4
Training loss: 2.249479293823242
Validation loss: 2.0133349100748696

Epoch: 5| Step: 5
Training loss: 2.3612115383148193
Validation loss: 2.011302128434181

Epoch: 5| Step: 6
Training loss: 1.685133934020996
Validation loss: 2.0112446943918862

Epoch: 5| Step: 7
Training loss: 2.2231767177581787
Validation loss: 2.0265694161256156

Epoch: 5| Step: 8
Training loss: 2.213594675064087
Validation loss: 2.0183226068814597

Epoch: 5| Step: 9
Training loss: 1.6630914211273193
Validation loss: 2.0143878012895584

Epoch: 5| Step: 10
Training loss: 1.8318815231323242
Validation loss: 2.013692984978358

Epoch: 5| Step: 11
Training loss: 2.579155206680298
Validation loss: 2.013869270682335

Epoch: 105| Step: 0
Training loss: 2.183957576751709
Validation loss: 2.011249542236328

Epoch: 5| Step: 1
Training loss: 2.934420585632324
Validation loss: 2.0095575551191964

Epoch: 5| Step: 2
Training loss: 1.9002344608306885
Validation loss: 2.0097929189602532

Epoch: 5| Step: 3
Training loss: 2.1922545433044434
Validation loss: 2.0137313256661096

Epoch: 5| Step: 4
Training loss: 1.743334174156189
Validation loss: 2.0186255276203156

Epoch: 5| Step: 5
Training loss: 1.8594434261322021
Validation loss: 2.034019942084948

Epoch: 5| Step: 6
Training loss: 2.57676100730896
Validation loss: 2.025126561522484

Epoch: 5| Step: 7
Training loss: 2.1788086891174316
Validation loss: 2.022188643614451

Epoch: 5| Step: 8
Training loss: 1.6477930545806885
Validation loss: 2.0335174898306527

Epoch: 5| Step: 9
Training loss: 2.343104124069214
Validation loss: 2.0311235884825387

Epoch: 5| Step: 10
Training loss: 1.8521209955215454
Validation loss: 2.030946056048075

Epoch: 5| Step: 11
Training loss: 3.1991868019104004
Validation loss: 2.032440890868505

Epoch: 106| Step: 0
Training loss: 1.7355308532714844
Validation loss: 2.018057808279991

Epoch: 5| Step: 1
Training loss: 2.2530574798583984
Validation loss: 2.0102557937304177

Epoch: 5| Step: 2
Training loss: 2.0110034942626953
Validation loss: 2.0160008470217385

Epoch: 5| Step: 3
Training loss: 2.5599446296691895
Validation loss: 2.013654410839081

Epoch: 5| Step: 4
Training loss: 2.0255684852600098
Validation loss: 2.0145831257104874

Epoch: 5| Step: 5
Training loss: 1.267744779586792
Validation loss: 2.0251635909080505

Epoch: 5| Step: 6
Training loss: 2.6487796306610107
Validation loss: 2.015095333258311

Epoch: 5| Step: 7
Training loss: 1.8873937129974365
Validation loss: 2.0148509244124093

Epoch: 5| Step: 8
Training loss: 2.1592392921447754
Validation loss: 2.019810368617376

Epoch: 5| Step: 9
Training loss: 2.5915210247039795
Validation loss: 2.011788229147593

Epoch: 5| Step: 10
Training loss: 2.2036640644073486
Validation loss: 2.010790834824244

Epoch: 5| Step: 11
Training loss: 2.9305906295776367
Validation loss: 2.006839861472448

Epoch: 107| Step: 0
Training loss: 1.7988941669464111
Validation loss: 2.0107387950023017

Epoch: 5| Step: 1
Training loss: 2.413125514984131
Validation loss: 2.0074848979711533

Epoch: 5| Step: 2
Training loss: 1.8249375820159912
Validation loss: 2.0094942450523376

Epoch: 5| Step: 3
Training loss: 1.8810245990753174
Validation loss: 2.0128312359253564

Epoch: 5| Step: 4
Training loss: 2.599562406539917
Validation loss: 2.0196278790632882

Epoch: 5| Step: 5
Training loss: 2.5820114612579346
Validation loss: 2.024451360106468

Epoch: 5| Step: 6
Training loss: 2.4543731212615967
Validation loss: 2.0140384087959924

Epoch: 5| Step: 7
Training loss: 1.5457732677459717
Validation loss: 2.0153495023647943

Epoch: 5| Step: 8
Training loss: 2.2292442321777344
Validation loss: 2.0194025337696075

Epoch: 5| Step: 9
Training loss: 1.7633216381072998
Validation loss: 2.0195792665084205

Epoch: 5| Step: 10
Training loss: 2.268141984939575
Validation loss: 2.018221358458201

Epoch: 5| Step: 11
Training loss: 2.3290958404541016
Validation loss: 2.014303276936213

Epoch: 108| Step: 0
Training loss: 2.28363037109375
Validation loss: 2.0175831019878387

Epoch: 5| Step: 1
Training loss: 2.1658458709716797
Validation loss: 2.024927278359731

Epoch: 5| Step: 2
Training loss: 2.5604805946350098
Validation loss: 2.035281226038933

Epoch: 5| Step: 3
Training loss: 2.1843879222869873
Validation loss: 2.032216265797615

Epoch: 5| Step: 4
Training loss: 1.7150039672851562
Validation loss: 2.0367774864037833

Epoch: 5| Step: 5
Training loss: 2.3829028606414795
Validation loss: 2.0469213972489038

Epoch: 5| Step: 6
Training loss: 1.7678954601287842
Validation loss: 2.0543242841959

Epoch: 5| Step: 7
Training loss: 2.2466142177581787
Validation loss: 2.0435170183579126

Epoch: 5| Step: 8
Training loss: 1.9265308380126953
Validation loss: 2.0158545027176538

Epoch: 5| Step: 9
Training loss: 1.9688403606414795
Validation loss: 2.0023905634880066

Epoch: 5| Step: 10
Training loss: 2.4924519062042236
Validation loss: 1.9982851793368657

Epoch: 5| Step: 11
Training loss: 1.0617276430130005
Validation loss: 1.9915131330490112

Epoch: 109| Step: 0
Training loss: 2.2875022888183594
Validation loss: 1.9961412052313487

Epoch: 5| Step: 1
Training loss: 2.542999505996704
Validation loss: 2.002215266227722

Epoch: 5| Step: 2
Training loss: 1.997136116027832
Validation loss: 2.015229339400927

Epoch: 5| Step: 3
Training loss: 1.7473726272583008
Validation loss: 2.0163177450497947

Epoch: 5| Step: 4
Training loss: 2.0587170124053955
Validation loss: 2.016692395011584

Epoch: 5| Step: 5
Training loss: 1.9163395166397095
Validation loss: 2.0214142352342606

Epoch: 5| Step: 6
Training loss: 2.2376930713653564
Validation loss: 2.017201751470566

Epoch: 5| Step: 7
Training loss: 2.2082114219665527
Validation loss: 2.019357298811277

Epoch: 5| Step: 8
Training loss: 2.746142625808716
Validation loss: 2.0088566492001214

Epoch: 5| Step: 9
Training loss: 2.0733041763305664
Validation loss: 2.00332901875178

Epoch: 5| Step: 10
Training loss: 2.151824712753296
Validation loss: 2.0028315037488937

Epoch: 5| Step: 11
Training loss: 1.9762011766433716
Validation loss: 1.9989237387975056

Epoch: 110| Step: 0
Training loss: 1.643280029296875
Validation loss: 1.9961136728525162

Epoch: 5| Step: 1
Training loss: 2.151505947113037
Validation loss: 1.9981802105903625

Epoch: 5| Step: 2
Training loss: 2.2519431114196777
Validation loss: 1.9921423842509587

Epoch: 5| Step: 3
Training loss: 2.186354160308838
Validation loss: 2.002728193998337

Epoch: 5| Step: 4
Training loss: 2.049428939819336
Validation loss: 2.0028162598609924

Epoch: 5| Step: 5
Training loss: 2.479147434234619
Validation loss: 2.0040086855491004

Epoch: 5| Step: 6
Training loss: 2.4776997566223145
Validation loss: 2.010971873998642

Epoch: 5| Step: 7
Training loss: 1.9169254302978516
Validation loss: 1.999461089571317

Epoch: 5| Step: 8
Training loss: 1.9419081211090088
Validation loss: 2.016213908791542

Epoch: 5| Step: 9
Training loss: 2.0513923168182373
Validation loss: 2.023740460475286

Epoch: 5| Step: 10
Training loss: 2.3635406494140625
Validation loss: 2.028811161716779

Epoch: 5| Step: 11
Training loss: 2.7698137760162354
Validation loss: 2.0270497500896454

Epoch: 111| Step: 0
Training loss: 2.205491542816162
Validation loss: 2.03227399289608

Epoch: 5| Step: 1
Training loss: 1.6651290655136108
Validation loss: 2.027227888504664

Epoch: 5| Step: 2
Training loss: 2.419276714324951
Validation loss: 2.034752741456032

Epoch: 5| Step: 3
Training loss: 2.563406467437744
Validation loss: 2.0242593387762704

Epoch: 5| Step: 4
Training loss: 2.2226099967956543
Validation loss: 2.0214955657720566

Epoch: 5| Step: 5
Training loss: 2.0825023651123047
Validation loss: 2.0260637998580933

Epoch: 5| Step: 6
Training loss: 1.8953335285186768
Validation loss: 2.017063230276108

Epoch: 5| Step: 7
Training loss: 2.2054085731506348
Validation loss: 2.0201879690090814

Epoch: 5| Step: 8
Training loss: 2.3927369117736816
Validation loss: 2.0108073949813843

Epoch: 5| Step: 9
Training loss: 2.0179712772369385
Validation loss: 2.01018292705218

Epoch: 5| Step: 10
Training loss: 1.9209206104278564
Validation loss: 2.008528853456179

Epoch: 5| Step: 11
Training loss: 2.3237853050231934
Validation loss: 2.011951982975006

Epoch: 112| Step: 0
Training loss: 1.777614951133728
Validation loss: 2.003409579396248

Epoch: 5| Step: 1
Training loss: 1.7382646799087524
Validation loss: 2.011217618981997

Epoch: 5| Step: 2
Training loss: 2.1777424812316895
Validation loss: 2.013324578603109

Epoch: 5| Step: 3
Training loss: 2.024937868118286
Validation loss: 2.013853818178177

Epoch: 5| Step: 4
Training loss: 2.5871689319610596
Validation loss: 2.03063428401947

Epoch: 5| Step: 5
Training loss: 2.0814757347106934
Validation loss: 2.0191679944594703

Epoch: 5| Step: 6
Training loss: 2.356721878051758
Validation loss: 2.0354175170262656

Epoch: 5| Step: 7
Training loss: 2.6345725059509277
Validation loss: 2.0259981403748193

Epoch: 5| Step: 8
Training loss: 1.5646743774414062
Validation loss: 2.0200724651416144

Epoch: 5| Step: 9
Training loss: 2.160609483718872
Validation loss: 2.0226779778798423

Epoch: 5| Step: 10
Training loss: 2.2550711631774902
Validation loss: 2.0231996824344

Epoch: 5| Step: 11
Training loss: 2.355806827545166
Validation loss: 2.0220303585131965

Epoch: 113| Step: 0
Training loss: 1.704890251159668
Validation loss: 2.003375048438708

Epoch: 5| Step: 1
Training loss: 2.2978732585906982
Validation loss: 2.0215743829806647

Epoch: 5| Step: 2
Training loss: 2.7441513538360596
Validation loss: 2.025640885035197

Epoch: 5| Step: 3
Training loss: 1.9345004558563232
Validation loss: 2.018544847766558

Epoch: 5| Step: 4
Training loss: 2.114149570465088
Validation loss: 2.0177499602238336

Epoch: 5| Step: 5
Training loss: 2.3938636779785156
Validation loss: 2.0217367808024087

Epoch: 5| Step: 6
Training loss: 2.126028537750244
Validation loss: 2.02080962061882

Epoch: 5| Step: 7
Training loss: 2.1174397468566895
Validation loss: 2.009993980328242

Epoch: 5| Step: 8
Training loss: 2.2220308780670166
Validation loss: 2.0059488713741302

Epoch: 5| Step: 9
Training loss: 2.331786870956421
Validation loss: 2.002875184019407

Epoch: 5| Step: 10
Training loss: 2.0210094451904297
Validation loss: 2.0046385129292807

Epoch: 5| Step: 11
Training loss: 1.1918143033981323
Validation loss: 2.007362042864164

Epoch: 114| Step: 0
Training loss: 1.7815757989883423
Validation loss: 2.0185542851686478

Epoch: 5| Step: 1
Training loss: 2.4264869689941406
Validation loss: 2.0200680842002234

Epoch: 5| Step: 2
Training loss: 2.207498073577881
Validation loss: 2.020828644434611

Epoch: 5| Step: 3
Training loss: 2.074195146560669
Validation loss: 2.0188159147898355

Epoch: 5| Step: 4
Training loss: 2.4987998008728027
Validation loss: 2.029576321442922

Epoch: 5| Step: 5
Training loss: 1.8110719919204712
Validation loss: 2.0173075745503106

Epoch: 5| Step: 6
Training loss: 1.9590476751327515
Validation loss: 2.01681221028169

Epoch: 5| Step: 7
Training loss: 2.0120575428009033
Validation loss: 2.021748219927152

Epoch: 5| Step: 8
Training loss: 2.3378474712371826
Validation loss: 2.0321383078893027

Epoch: 5| Step: 9
Training loss: 2.6140449047088623
Validation loss: 2.022674227754275

Epoch: 5| Step: 10
Training loss: 1.7996419668197632
Validation loss: 2.019099324941635

Epoch: 5| Step: 11
Training loss: 1.99660325050354
Validation loss: 2.0240286886692047

Epoch: 115| Step: 0
Training loss: 2.1989076137542725
Validation loss: 2.0168604105710983

Epoch: 5| Step: 1
Training loss: 2.333887815475464
Validation loss: 2.024832641084989

Epoch: 5| Step: 2
Training loss: 2.022125244140625
Validation loss: 2.0251301725705466

Epoch: 5| Step: 3
Training loss: 2.3187763690948486
Validation loss: 2.017870048681895

Epoch: 5| Step: 4
Training loss: 1.8755899667739868
Validation loss: 2.0442956735690436

Epoch: 5| Step: 5
Training loss: 2.061351776123047
Validation loss: 2.0233828723430634

Epoch: 5| Step: 6
Training loss: 2.1558327674865723
Validation loss: 2.0257610380649567

Epoch: 5| Step: 7
Training loss: 2.5505778789520264
Validation loss: 2.0339246342579522

Epoch: 5| Step: 8
Training loss: 1.7362420558929443
Validation loss: 2.0416186352570853

Epoch: 5| Step: 9
Training loss: 2.1120822429656982
Validation loss: 2.034041921297709

Epoch: 5| Step: 10
Training loss: 2.070202112197876
Validation loss: 2.0284162213404975

Epoch: 5| Step: 11
Training loss: 2.127627372741699
Validation loss: 2.0211557745933533

Epoch: 116| Step: 0
Training loss: 1.830389380455017
Validation loss: 2.018652930855751

Epoch: 5| Step: 1
Training loss: 1.8751375675201416
Validation loss: 2.0102842152118683

Epoch: 5| Step: 2
Training loss: 2.801429271697998
Validation loss: 2.008157953619957

Epoch: 5| Step: 3
Training loss: 2.2138965129852295
Validation loss: 2.0115114897489548

Epoch: 5| Step: 4
Training loss: 1.7861915826797485
Validation loss: 2.004312386115392

Epoch: 5| Step: 5
Training loss: 2.502964496612549
Validation loss: 2.00969260931015

Epoch: 5| Step: 6
Training loss: 1.8460941314697266
Validation loss: 2.0052965929110846

Epoch: 5| Step: 7
Training loss: 2.359286069869995
Validation loss: 2.0089814215898514

Epoch: 5| Step: 8
Training loss: 2.0698816776275635
Validation loss: 2.0024644434452057

Epoch: 5| Step: 9
Training loss: 1.9078458547592163
Validation loss: 2.0105759849150977

Epoch: 5| Step: 10
Training loss: 2.0611064434051514
Validation loss: 2.0108044197161994

Epoch: 5| Step: 11
Training loss: 2.829555034637451
Validation loss: 2.0182102719942727

Epoch: 117| Step: 0
Training loss: 1.7859855890274048
Validation loss: 2.0194339752197266

Epoch: 5| Step: 1
Training loss: 1.9846338033676147
Validation loss: 2.0352497895558677

Epoch: 5| Step: 2
Training loss: 2.3842735290527344
Validation loss: 2.047893315553665

Epoch: 5| Step: 3
Training loss: 2.0355100631713867
Validation loss: 2.0435718297958374

Epoch: 5| Step: 4
Training loss: 2.447568893432617
Validation loss: 2.042287692427635

Epoch: 5| Step: 5
Training loss: 2.3555917739868164
Validation loss: 2.0518159916003547

Epoch: 5| Step: 6
Training loss: 2.0946102142333984
Validation loss: 2.0366209596395493

Epoch: 5| Step: 7
Training loss: 2.363784074783325
Validation loss: 2.0327455749114356

Epoch: 5| Step: 8
Training loss: 1.9059345722198486
Validation loss: 2.020764003197352

Epoch: 5| Step: 9
Training loss: 2.360173225402832
Validation loss: 2.014830231666565

Epoch: 5| Step: 10
Training loss: 1.7572686672210693
Validation loss: 2.0083471139272056

Epoch: 5| Step: 11
Training loss: 2.5299196243286133
Validation loss: 2.0138712575038276

Epoch: 118| Step: 0
Training loss: 3.0252346992492676
Validation loss: 2.0229676365852356

Epoch: 5| Step: 1
Training loss: 2.285149574279785
Validation loss: 2.0233613153298697

Epoch: 5| Step: 2
Training loss: 2.7261300086975098
Validation loss: 2.03402841091156

Epoch: 5| Step: 3
Training loss: 2.1177096366882324
Validation loss: 2.029280732075373

Epoch: 5| Step: 4
Training loss: 2.0141777992248535
Validation loss: 2.0329922338326774

Epoch: 5| Step: 5
Training loss: 1.732438325881958
Validation loss: 2.031139021118482

Epoch: 5| Step: 6
Training loss: 2.0602431297302246
Validation loss: 2.031226764122645

Epoch: 5| Step: 7
Training loss: 1.7244186401367188
Validation loss: 2.0225569754838943

Epoch: 5| Step: 8
Training loss: 2.068840742111206
Validation loss: 2.020287329951922

Epoch: 5| Step: 9
Training loss: 2.1313018798828125
Validation loss: 2.009392554561297

Epoch: 5| Step: 10
Training loss: 1.9813181161880493
Validation loss: 2.005103891094526

Epoch: 5| Step: 11
Training loss: 2.081516742706299
Validation loss: 2.0008314351240792

Epoch: 119| Step: 0
Training loss: 2.3974668979644775
Validation loss: 2.0087961107492447

Epoch: 5| Step: 1
Training loss: 1.995356559753418
Validation loss: 2.0035462975502014

Epoch: 5| Step: 2
Training loss: 2.5888469219207764
Validation loss: 2.0195495635271072

Epoch: 5| Step: 3
Training loss: 2.32352876663208
Validation loss: 2.018478492895762

Epoch: 5| Step: 4
Training loss: 1.9237228631973267
Validation loss: 2.0144105652968087

Epoch: 5| Step: 5
Training loss: 1.889257788658142
Validation loss: 2.0203454196453094

Epoch: 5| Step: 6
Training loss: 1.7258838415145874
Validation loss: 2.0316118200620017

Epoch: 5| Step: 7
Training loss: 2.446448564529419
Validation loss: 2.031673709551493

Epoch: 5| Step: 8
Training loss: 2.1699023246765137
Validation loss: 2.0366463909546533

Epoch: 5| Step: 9
Training loss: 1.8640739917755127
Validation loss: 2.048882474501928

Epoch: 5| Step: 10
Training loss: 2.1268677711486816
Validation loss: 2.062712902824084

Epoch: 5| Step: 11
Training loss: 1.8569260835647583
Validation loss: 2.0383880734443665

Epoch: 120| Step: 0
Training loss: 2.1532721519470215
Validation loss: 2.0336949129899344

Epoch: 5| Step: 1
Training loss: 2.6013176441192627
Validation loss: 2.020075038075447

Epoch: 5| Step: 2
Training loss: 2.081892490386963
Validation loss: 2.031481852134069

Epoch: 5| Step: 3
Training loss: 1.7543694972991943
Validation loss: 2.0199150145053864

Epoch: 5| Step: 4
Training loss: 2.2425618171691895
Validation loss: 2.022468388080597

Epoch: 5| Step: 5
Training loss: 2.1649327278137207
Validation loss: 2.0335673739512763

Epoch: 5| Step: 6
Training loss: 1.4334139823913574
Validation loss: 2.04179285466671

Epoch: 5| Step: 7
Training loss: 2.65995717048645
Validation loss: 2.045169457793236

Epoch: 5| Step: 8
Training loss: 2.432544231414795
Validation loss: 2.042995115121206

Epoch: 5| Step: 9
Training loss: 2.0471644401550293
Validation loss: 2.0405638267596564

Epoch: 5| Step: 10
Training loss: 2.264464855194092
Validation loss: 2.0401285340388617

Epoch: 5| Step: 11
Training loss: 2.495190143585205
Validation loss: 2.0465501248836517

Epoch: 121| Step: 0
Training loss: 2.6335413455963135
Validation loss: 2.0463674465815225

Epoch: 5| Step: 1
Training loss: 2.3309974670410156
Validation loss: 2.0467558999856315

Epoch: 5| Step: 2
Training loss: 2.242682695388794
Validation loss: 2.0432288497686386

Epoch: 5| Step: 3
Training loss: 1.802619218826294
Validation loss: 2.0417647312084832

Epoch: 5| Step: 4
Training loss: 2.376455545425415
Validation loss: 2.0245384673277536

Epoch: 5| Step: 5
Training loss: 2.0636231899261475
Validation loss: 2.028359279036522

Epoch: 5| Step: 6
Training loss: 2.1364450454711914
Validation loss: 2.0266861965258918

Epoch: 5| Step: 7
Training loss: 1.9082695245742798
Validation loss: 2.023351083199183

Epoch: 5| Step: 8
Training loss: 2.657414674758911
Validation loss: 2.017411842942238

Epoch: 5| Step: 9
Training loss: 1.9592946767807007
Validation loss: 2.0113243559996286

Epoch: 5| Step: 10
Training loss: 2.0188238620758057
Validation loss: 2.0091232607762017

Epoch: 5| Step: 11
Training loss: 1.653082251548767
Validation loss: 2.0093031227588654

Epoch: 122| Step: 0
Training loss: 2.04638934135437
Validation loss: 2.004338006178538

Epoch: 5| Step: 1
Training loss: 1.9508508443832397
Validation loss: 2.0133827129999795

Epoch: 5| Step: 2
Training loss: 2.4802298545837402
Validation loss: 2.019932816425959

Epoch: 5| Step: 3
Training loss: 2.188941240310669
Validation loss: 2.015176852544149

Epoch: 5| Step: 4
Training loss: 2.330125331878662
Validation loss: 2.018835191925367

Epoch: 5| Step: 5
Training loss: 2.4016780853271484
Validation loss: 2.019421324133873

Epoch: 5| Step: 6
Training loss: 2.216283082962036
Validation loss: 2.0239837219317756

Epoch: 5| Step: 7
Training loss: 1.9476054906845093
Validation loss: 2.0230597406625748

Epoch: 5| Step: 8
Training loss: 2.100109100341797
Validation loss: 2.0205322206020355

Epoch: 5| Step: 9
Training loss: 2.1532516479492188
Validation loss: 2.0149070471525192

Epoch: 5| Step: 10
Training loss: 1.4942188262939453
Validation loss: 2.025553142031034

Epoch: 5| Step: 11
Training loss: 2.667346239089966
Validation loss: 2.0121514201164246

Epoch: 123| Step: 0
Training loss: 2.0960376262664795
Validation loss: 2.0224331816037497

Epoch: 5| Step: 1
Training loss: 2.6378097534179688
Validation loss: 2.0098318507273993

Epoch: 5| Step: 2
Training loss: 2.5322632789611816
Validation loss: 2.01404661933581

Epoch: 5| Step: 3
Training loss: 1.8497722148895264
Validation loss: 2.014939561486244

Epoch: 5| Step: 4
Training loss: 1.469346284866333
Validation loss: 2.008554975191752

Epoch: 5| Step: 5
Training loss: 2.3909430503845215
Validation loss: 2.011754885315895

Epoch: 5| Step: 6
Training loss: 2.0643374919891357
Validation loss: 2.0144313871860504

Epoch: 5| Step: 7
Training loss: 2.170478105545044
Validation loss: 2.003509745001793

Epoch: 5| Step: 8
Training loss: 1.9937998056411743
Validation loss: 2.0060495734214783

Epoch: 5| Step: 9
Training loss: 2.0224947929382324
Validation loss: 2.008772596716881

Epoch: 5| Step: 10
Training loss: 2.0419840812683105
Validation loss: 2.0100847830375037

Epoch: 5| Step: 11
Training loss: 2.0085134506225586
Validation loss: 2.010839839776357

Epoch: 124| Step: 0
Training loss: 2.3463425636291504
Validation loss: 2.0030350983142853

Epoch: 5| Step: 1
Training loss: 1.938340187072754
Validation loss: 2.026080479224523

Epoch: 5| Step: 2
Training loss: 2.7105355262756348
Validation loss: 2.0182914584875107

Epoch: 5| Step: 3
Training loss: 1.8583097457885742
Validation loss: 2.0210485557715097

Epoch: 5| Step: 4
Training loss: 2.0100131034851074
Validation loss: 2.0204563637574515

Epoch: 5| Step: 5
Training loss: 2.2903785705566406
Validation loss: 2.0201757500569024

Epoch: 5| Step: 6
Training loss: 1.9254592657089233
Validation loss: 2.0199541250864663

Epoch: 5| Step: 7
Training loss: 1.8533546924591064
Validation loss: 2.0272518396377563

Epoch: 5| Step: 8
Training loss: 2.1010711193084717
Validation loss: 2.0269659906625748

Epoch: 5| Step: 9
Training loss: 2.288940906524658
Validation loss: 2.0227463245391846

Epoch: 5| Step: 10
Training loss: 1.8583641052246094
Validation loss: 2.0242430915435157

Epoch: 5| Step: 11
Training loss: 2.0781593322753906
Validation loss: 2.0203284521897635

Epoch: 125| Step: 0
Training loss: 1.990612268447876
Validation loss: 2.0207387854655585

Epoch: 5| Step: 1
Training loss: 2.3291232585906982
Validation loss: 2.0181680669387183

Epoch: 5| Step: 2
Training loss: 1.810609221458435
Validation loss: 2.016508623957634

Epoch: 5| Step: 3
Training loss: 2.060490846633911
Validation loss: 2.0156953185796738

Epoch: 5| Step: 4
Training loss: 2.1402981281280518
Validation loss: 2.0153986463944116

Epoch: 5| Step: 5
Training loss: 2.3786520957946777
Validation loss: 2.0164057513078055

Epoch: 5| Step: 6
Training loss: 1.5842056274414062
Validation loss: 2.0225863605737686

Epoch: 5| Step: 7
Training loss: 2.5709245204925537
Validation loss: 2.015771026412646

Epoch: 5| Step: 8
Training loss: 1.9145543575286865
Validation loss: 2.0158875485261283

Epoch: 5| Step: 9
Training loss: 2.3845677375793457
Validation loss: 2.0120986302693686

Epoch: 5| Step: 10
Training loss: 1.9012187719345093
Validation loss: 2.0269544422626495

Epoch: 5| Step: 11
Training loss: 3.1114959716796875
Validation loss: 2.0136230687300363

Epoch: 126| Step: 0
Training loss: 2.2119572162628174
Validation loss: 2.023678590854009

Epoch: 5| Step: 1
Training loss: 2.535088300704956
Validation loss: 2.0270739098389945

Epoch: 5| Step: 2
Training loss: 2.632225751876831
Validation loss: 2.01880536476771

Epoch: 5| Step: 3
Training loss: 2.2642791271209717
Validation loss: 2.0318060914675393

Epoch: 5| Step: 4
Training loss: 1.6604912281036377
Validation loss: 2.0283428182204566

Epoch: 5| Step: 5
Training loss: 1.51156747341156
Validation loss: 2.0279863278071084

Epoch: 5| Step: 6
Training loss: 1.6119816303253174
Validation loss: 2.0365552504857383

Epoch: 5| Step: 7
Training loss: 2.500077247619629
Validation loss: 2.031122088432312

Epoch: 5| Step: 8
Training loss: 2.5432302951812744
Validation loss: 2.0257406681776047

Epoch: 5| Step: 9
Training loss: 1.7087342739105225
Validation loss: 2.0142683933178582

Epoch: 5| Step: 10
Training loss: 1.8868443965911865
Validation loss: 2.0163892755905786

Epoch: 5| Step: 11
Training loss: 2.7385215759277344
Validation loss: 2.0157412389914193

Epoch: 127| Step: 0
Training loss: 2.4503908157348633
Validation loss: 2.024385084708532

Epoch: 5| Step: 1
Training loss: 2.2123255729675293
Validation loss: 2.018920734524727

Epoch: 5| Step: 2
Training loss: 1.9109554290771484
Validation loss: 2.019003748893738

Epoch: 5| Step: 3
Training loss: 2.4756920337677
Validation loss: 2.015840247273445

Epoch: 5| Step: 4
Training loss: 2.102632999420166
Validation loss: 2.018356293439865

Epoch: 5| Step: 5
Training loss: 2.208883285522461
Validation loss: 2.0183135420084

Epoch: 5| Step: 6
Training loss: 1.8030223846435547
Validation loss: 2.012621372938156

Epoch: 5| Step: 7
Training loss: 2.1265077590942383
Validation loss: 2.020003249247869

Epoch: 5| Step: 8
Training loss: 2.130549669265747
Validation loss: 2.0233920911947885

Epoch: 5| Step: 9
Training loss: 1.741132378578186
Validation loss: 2.015387381116549

Epoch: 5| Step: 10
Training loss: 1.9834715127944946
Validation loss: 2.014566197991371

Epoch: 5| Step: 11
Training loss: 1.9721342325210571
Validation loss: 2.02132211625576

Epoch: 128| Step: 0
Training loss: 2.2969961166381836
Validation loss: 2.0289434691270194

Epoch: 5| Step: 1
Training loss: 2.0689876079559326
Validation loss: 2.0125421583652496

Epoch: 5| Step: 2
Training loss: 1.7882664203643799
Validation loss: 2.01234603424867

Epoch: 5| Step: 3
Training loss: 1.7387418746948242
Validation loss: 2.0089215487241745

Epoch: 5| Step: 4
Training loss: 2.364367961883545
Validation loss: 1.9990234275658925

Epoch: 5| Step: 5
Training loss: 2.1210718154907227
Validation loss: 2.0024172166983285

Epoch: 5| Step: 6
Training loss: 2.601901054382324
Validation loss: 2.0043995479742684

Epoch: 5| Step: 7
Training loss: 2.1645281314849854
Validation loss: 2.0163101057211557

Epoch: 5| Step: 8
Training loss: 1.6650638580322266
Validation loss: 2.016945386926333

Epoch: 5| Step: 9
Training loss: 2.6046526432037354
Validation loss: 2.0156909773747125

Epoch: 5| Step: 10
Training loss: 2.1208927631378174
Validation loss: 2.020759309331576

Epoch: 5| Step: 11
Training loss: 0.8454413414001465
Validation loss: 2.022357021768888

Epoch: 129| Step: 0
Training loss: 1.9836461544036865
Validation loss: 2.0295850137869516

Epoch: 5| Step: 1
Training loss: 1.7728859186172485
Validation loss: 2.0291393051544824

Epoch: 5| Step: 2
Training loss: 1.8277368545532227
Validation loss: 2.027775456508001

Epoch: 5| Step: 3
Training loss: 1.9037662744522095
Validation loss: 2.011311342318853

Epoch: 5| Step: 4
Training loss: 1.9908841848373413
Validation loss: 2.0199426263570786

Epoch: 5| Step: 5
Training loss: 2.476559638977051
Validation loss: 2.027802069981893

Epoch: 5| Step: 6
Training loss: 2.329357147216797
Validation loss: 2.0265585631132126

Epoch: 5| Step: 7
Training loss: 2.5174858570098877
Validation loss: 2.0249690959850946

Epoch: 5| Step: 8
Training loss: 2.1623926162719727
Validation loss: 2.017748882373174

Epoch: 5| Step: 9
Training loss: 2.256456136703491
Validation loss: 2.0130768169959388

Epoch: 5| Step: 10
Training loss: 2.029236316680908
Validation loss: 2.016829897960027

Epoch: 5| Step: 11
Training loss: 2.257129192352295
Validation loss: 2.0133243749539056

Epoch: 130| Step: 0
Training loss: 1.9239921569824219
Validation loss: 2.0189644743998847

Epoch: 5| Step: 1
Training loss: 2.3271806240081787
Validation loss: 2.0158634334802628

Epoch: 5| Step: 2
Training loss: 2.1455118656158447
Validation loss: 2.013539418578148

Epoch: 5| Step: 3
Training loss: 2.077446460723877
Validation loss: 2.019927442073822

Epoch: 5| Step: 4
Training loss: 1.803710699081421
Validation loss: 2.023540506760279

Epoch: 5| Step: 5
Training loss: 2.1899092197418213
Validation loss: 2.0254206508398056

Epoch: 5| Step: 6
Training loss: 2.3150434494018555
Validation loss: 2.027168189485868

Epoch: 5| Step: 7
Training loss: 2.4462368488311768
Validation loss: 2.031575088699659

Epoch: 5| Step: 8
Training loss: 2.0047435760498047
Validation loss: 2.022588938474655

Epoch: 5| Step: 9
Training loss: 2.3247361183166504
Validation loss: 2.041583001613617

Epoch: 5| Step: 10
Training loss: 1.8630634546279907
Validation loss: 2.0370471676190696

Epoch: 5| Step: 11
Training loss: 1.7293294668197632
Validation loss: 2.0276150157054267

Epoch: 131| Step: 0
Training loss: 1.8904978036880493
Validation loss: 2.0313145369291306

Epoch: 5| Step: 1
Training loss: 2.617851734161377
Validation loss: 2.0359899948040643

Epoch: 5| Step: 2
Training loss: 1.481268048286438
Validation loss: 2.0268699129422507

Epoch: 5| Step: 3
Training loss: 1.8895466327667236
Validation loss: 2.0228423923254013

Epoch: 5| Step: 4
Training loss: 1.6226218938827515
Validation loss: 2.0288904358943305

Epoch: 5| Step: 5
Training loss: 2.0152878761291504
Validation loss: 2.026840185125669

Epoch: 5| Step: 6
Training loss: 2.13987398147583
Validation loss: 2.0256105760733285

Epoch: 5| Step: 7
Training loss: 2.9633948802948
Validation loss: 2.0258730302254357

Epoch: 5| Step: 8
Training loss: 2.345912218093872
Validation loss: 2.027461439371109

Epoch: 5| Step: 9
Training loss: 2.060112714767456
Validation loss: 2.0288647611935935

Epoch: 5| Step: 10
Training loss: 1.9889976978302002
Validation loss: 2.0258402675390244

Epoch: 5| Step: 11
Training loss: 2.5986037254333496
Validation loss: 2.027818356951078

Epoch: 132| Step: 0
Training loss: 1.908097505569458
Validation loss: 2.0246370236078897

Epoch: 5| Step: 1
Training loss: 1.8622567653656006
Validation loss: 2.023094897468885

Epoch: 5| Step: 2
Training loss: 2.333173990249634
Validation loss: 2.0369311968485513

Epoch: 5| Step: 3
Training loss: 2.586763858795166
Validation loss: 2.0212355107069016

Epoch: 5| Step: 4
Training loss: 1.4771721363067627
Validation loss: 2.021753599246343

Epoch: 5| Step: 5
Training loss: 2.2569096088409424
Validation loss: 2.0355419317881265

Epoch: 5| Step: 6
Training loss: 2.049734592437744
Validation loss: 2.0322242428859076

Epoch: 5| Step: 7
Training loss: 2.5572004318237305
Validation loss: 2.0178670585155487

Epoch: 5| Step: 8
Training loss: 1.8233897686004639
Validation loss: 2.0337001383304596

Epoch: 5| Step: 9
Training loss: 1.8396368026733398
Validation loss: 2.0260389099518457

Epoch: 5| Step: 10
Training loss: 1.9913842678070068
Validation loss: 2.0309566408395767

Epoch: 5| Step: 11
Training loss: 4.072811126708984
Validation loss: 2.027399241924286

Epoch: 133| Step: 0
Training loss: 1.9744784832000732
Validation loss: 2.0353186825911203

Epoch: 5| Step: 1
Training loss: 2.2164947986602783
Validation loss: 2.030733476082484

Epoch: 5| Step: 2
Training loss: 2.2267863750457764
Validation loss: 2.035671894749006

Epoch: 5| Step: 3
Training loss: 1.952967882156372
Validation loss: 2.0295406728982925

Epoch: 5| Step: 4
Training loss: 1.411987066268921
Validation loss: 2.0325936625401178

Epoch: 5| Step: 5
Training loss: 2.1196048259735107
Validation loss: 2.0260013292233148

Epoch: 5| Step: 6
Training loss: 2.268733024597168
Validation loss: 2.028791348139445

Epoch: 5| Step: 7
Training loss: 1.9639396667480469
Validation loss: 2.02327860891819

Epoch: 5| Step: 8
Training loss: 2.4601237773895264
Validation loss: 2.027393082777659

Epoch: 5| Step: 9
Training loss: 1.7651245594024658
Validation loss: 2.0328506777683892

Epoch: 5| Step: 10
Training loss: 2.5375146865844727
Validation loss: 2.029653718074163

Epoch: 5| Step: 11
Training loss: 2.677987575531006
Validation loss: 2.0337339093287787

Epoch: 134| Step: 0
Training loss: 2.137598752975464
Validation loss: 2.0327904323736825

Epoch: 5| Step: 1
Training loss: 1.9974006414413452
Validation loss: 2.03314071893692

Epoch: 5| Step: 2
Training loss: 2.160975217819214
Validation loss: 2.0369293789068856

Epoch: 5| Step: 3
Training loss: 2.0616097450256348
Validation loss: 2.03210320075353

Epoch: 5| Step: 4
Training loss: 2.7434616088867188
Validation loss: 2.0243335316578546

Epoch: 5| Step: 5
Training loss: 1.7709734439849854
Validation loss: 2.029580439130465

Epoch: 5| Step: 6
Training loss: 2.496392250061035
Validation loss: 2.0427335699399314

Epoch: 5| Step: 7
Training loss: 1.8096109628677368
Validation loss: 2.0410470267136893

Epoch: 5| Step: 8
Training loss: 2.1125271320343018
Validation loss: 2.039072265227636

Epoch: 5| Step: 9
Training loss: 1.9306083917617798
Validation loss: 2.028736174106598

Epoch: 5| Step: 10
Training loss: 1.8908054828643799
Validation loss: 2.0412536511818566

Epoch: 5| Step: 11
Training loss: 1.8807506561279297
Validation loss: 2.035239517688751

Epoch: 135| Step: 0
Training loss: 1.855228066444397
Validation loss: 2.033991644779841

Epoch: 5| Step: 1
Training loss: 2.3574259281158447
Validation loss: 2.026665205756823

Epoch: 5| Step: 2
Training loss: 2.110363006591797
Validation loss: 2.0321571677923203

Epoch: 5| Step: 3
Training loss: 2.291588306427002
Validation loss: 2.039135659734408

Epoch: 5| Step: 4
Training loss: 2.0528221130371094
Validation loss: 2.0426783512036004

Epoch: 5| Step: 5
Training loss: 1.7135474681854248
Validation loss: 2.0492258171240487

Epoch: 5| Step: 6
Training loss: 2.0300469398498535
Validation loss: 2.063961391647657

Epoch: 5| Step: 7
Training loss: 2.0399303436279297
Validation loss: 2.0311675866444907

Epoch: 5| Step: 8
Training loss: 2.519923686981201
Validation loss: 2.027393495043119

Epoch: 5| Step: 9
Training loss: 2.239713191986084
Validation loss: 2.0208962708711624

Epoch: 5| Step: 10
Training loss: 2.2273876667022705
Validation loss: 2.009722093741099

Epoch: 5| Step: 11
Training loss: 1.488553524017334
Validation loss: 2.01562728981177

Epoch: 136| Step: 0
Training loss: 2.514735698699951
Validation loss: 2.016061286131541

Epoch: 5| Step: 1
Training loss: 1.6886348724365234
Validation loss: 2.022966668009758

Epoch: 5| Step: 2
Training loss: 2.296234369277954
Validation loss: 2.0260396351416907

Epoch: 5| Step: 3
Training loss: 2.164170265197754
Validation loss: 2.0227382828791938

Epoch: 5| Step: 4
Training loss: 2.5885252952575684
Validation loss: 2.0282563269138336

Epoch: 5| Step: 5
Training loss: 2.1528449058532715
Validation loss: 2.023854742447535

Epoch: 5| Step: 6
Training loss: 2.4736812114715576
Validation loss: 2.0280809750159583

Epoch: 5| Step: 7
Training loss: 2.0376532077789307
Validation loss: 2.0291791558265686

Epoch: 5| Step: 8
Training loss: 1.7596399784088135
Validation loss: 2.015175074338913

Epoch: 5| Step: 9
Training loss: 2.267442226409912
Validation loss: 2.004665717482567

Epoch: 5| Step: 10
Training loss: 1.699928641319275
Validation loss: 2.0100188851356506

Epoch: 5| Step: 11
Training loss: 0.9469931125640869
Validation loss: 2.0025130261977515

Epoch: 137| Step: 0
Training loss: 2.285698175430298
Validation loss: 1.9942367672920227

Epoch: 5| Step: 1
Training loss: 1.6888339519500732
Validation loss: 1.9902699838081996

Epoch: 5| Step: 2
Training loss: 2.0269789695739746
Validation loss: 1.9868104408184688

Epoch: 5| Step: 3
Training loss: 2.206777334213257
Validation loss: 1.9945351034402847

Epoch: 5| Step: 4
Training loss: 1.9788528680801392
Validation loss: 2.0002482483784356

Epoch: 5| Step: 5
Training loss: 2.0208969116210938
Validation loss: 2.004451110959053

Epoch: 5| Step: 6
Training loss: 1.8384405374526978
Validation loss: 2.007318382461866

Epoch: 5| Step: 7
Training loss: 2.272834539413452
Validation loss: 2.002617374062538

Epoch: 5| Step: 8
Training loss: 2.6421456336975098
Validation loss: 2.005526920159658

Epoch: 5| Step: 9
Training loss: 2.147660493850708
Validation loss: 1.9974344422419865

Epoch: 5| Step: 10
Training loss: 2.084895610809326
Validation loss: 2.007340649763743

Epoch: 5| Step: 11
Training loss: 2.7099575996398926
Validation loss: 1.9956292410691578

Epoch: 138| Step: 0
Training loss: 1.6558959484100342
Validation loss: 2.0059996843338013

Epoch: 5| Step: 1
Training loss: 1.758960485458374
Validation loss: 2.016413609186808

Epoch: 5| Step: 2
Training loss: 2.255627393722534
Validation loss: 2.0183492501576743

Epoch: 5| Step: 3
Training loss: 2.2385330200195312
Validation loss: 2.017400562763214

Epoch: 5| Step: 4
Training loss: 1.986919641494751
Validation loss: 2.0211183428764343

Epoch: 5| Step: 5
Training loss: 2.1973166465759277
Validation loss: 2.028401126464208

Epoch: 5| Step: 6
Training loss: 1.792422890663147
Validation loss: 2.022970899939537

Epoch: 5| Step: 7
Training loss: 2.002781391143799
Validation loss: 2.017312303185463

Epoch: 5| Step: 8
Training loss: 2.1527373790740967
Validation loss: 2.0186087787151337

Epoch: 5| Step: 9
Training loss: 2.1682984828948975
Validation loss: 2.025158996383349

Epoch: 5| Step: 10
Training loss: 2.4642999172210693
Validation loss: 2.039655645688375

Epoch: 5| Step: 11
Training loss: 2.8646910190582275
Validation loss: 2.0374628454446793

Epoch: 139| Step: 0
Training loss: 2.1556177139282227
Validation loss: 2.0243496745824814

Epoch: 5| Step: 1
Training loss: 2.269221782684326
Validation loss: 2.0338965207338333

Epoch: 5| Step: 2
Training loss: 2.7857139110565186
Validation loss: 2.038060953219732

Epoch: 5| Step: 3
Training loss: 2.4830482006073
Validation loss: 2.03638186554114

Epoch: 5| Step: 4
Training loss: 1.4962602853775024
Validation loss: 2.0352445393800735

Epoch: 5| Step: 5
Training loss: 1.7298349142074585
Validation loss: 2.0442048559586206

Epoch: 5| Step: 6
Training loss: 2.460057020187378
Validation loss: 2.047719811399778

Epoch: 5| Step: 7
Training loss: 1.7781455516815186
Validation loss: 2.0322517305612564

Epoch: 5| Step: 8
Training loss: 2.7157657146453857
Validation loss: 2.0480038474003472

Epoch: 5| Step: 9
Training loss: 1.451964020729065
Validation loss: 2.044044946630796

Epoch: 5| Step: 10
Training loss: 2.0493407249450684
Validation loss: 2.0358462035655975

Epoch: 5| Step: 11
Training loss: 0.5345445275306702
Validation loss: 2.0281254847844443

Epoch: 140| Step: 0
Training loss: 2.670497179031372
Validation loss: 2.0339794009923935

Epoch: 5| Step: 1
Training loss: 2.127509593963623
Validation loss: 2.0305485129356384

Epoch: 5| Step: 2
Training loss: 1.1747820377349854
Validation loss: 2.0450971325238547

Epoch: 5| Step: 3
Training loss: 2.605292797088623
Validation loss: 2.036067376534144

Epoch: 5| Step: 4
Training loss: 1.5627524852752686
Validation loss: 2.03565576672554

Epoch: 5| Step: 5
Training loss: 2.4703755378723145
Validation loss: 2.0283433347940445

Epoch: 5| Step: 6
Training loss: 2.2658066749572754
Validation loss: 2.02694670855999

Epoch: 5| Step: 7
Training loss: 1.9669933319091797
Validation loss: 2.0317310293515525

Epoch: 5| Step: 8
Training loss: 2.617588996887207
Validation loss: 2.0333743691444397

Epoch: 5| Step: 9
Training loss: 1.6056249141693115
Validation loss: 2.0254900058110556

Epoch: 5| Step: 10
Training loss: 2.1086106300354004
Validation loss: 2.027673304080963

Epoch: 5| Step: 11
Training loss: 2.161909580230713
Validation loss: 2.0294508089621863

Epoch: 141| Step: 0
Training loss: 2.269960403442383
Validation loss: 2.0242377519607544

Epoch: 5| Step: 1
Training loss: 2.1248974800109863
Validation loss: 2.0285944640636444

Epoch: 5| Step: 2
Training loss: 2.197509527206421
Validation loss: 2.0266122619311013

Epoch: 5| Step: 3
Training loss: 1.6480985879898071
Validation loss: 2.0258252869049707

Epoch: 5| Step: 4
Training loss: 2.164865493774414
Validation loss: 2.0274883608023324

Epoch: 5| Step: 5
Training loss: 2.171292781829834
Validation loss: 2.0308470924695334

Epoch: 5| Step: 6
Training loss: 2.1488518714904785
Validation loss: 2.025019332766533

Epoch: 5| Step: 7
Training loss: 2.1330485343933105
Validation loss: 2.029776001969973

Epoch: 5| Step: 8
Training loss: 1.9139182567596436
Validation loss: 2.0274888227383294

Epoch: 5| Step: 9
Training loss: 2.0406408309936523
Validation loss: 2.0350902328888574

Epoch: 5| Step: 10
Training loss: 2.4473824501037598
Validation loss: 2.0203380286693573

Epoch: 5| Step: 11
Training loss: 1.7988572120666504
Validation loss: 2.0309015760819116

Epoch: 142| Step: 0
Training loss: 1.7429249286651611
Validation loss: 2.0345810800790787

Epoch: 5| Step: 1
Training loss: 1.803924322128296
Validation loss: 2.0230178435643515

Epoch: 5| Step: 2
Training loss: 2.563413619995117
Validation loss: 2.0330523004134498

Epoch: 5| Step: 3
Training loss: 2.2858669757843018
Validation loss: 2.0477526038885117

Epoch: 5| Step: 4
Training loss: 2.044055938720703
Validation loss: 2.040331467986107

Epoch: 5| Step: 5
Training loss: 2.209885358810425
Validation loss: 2.0332953532536826

Epoch: 5| Step: 6
Training loss: 1.8462880849838257
Validation loss: 2.040187035997709

Epoch: 5| Step: 7
Training loss: 1.9484455585479736
Validation loss: 2.0385254323482513

Epoch: 5| Step: 8
Training loss: 1.9590381383895874
Validation loss: 2.035238047440847

Epoch: 5| Step: 9
Training loss: 2.14996075630188
Validation loss: 2.033269147078196

Epoch: 5| Step: 10
Training loss: 2.670825958251953
Validation loss: 2.035814548532168

Epoch: 5| Step: 11
Training loss: 1.7693415880203247
Validation loss: 2.038334369659424

Epoch: 143| Step: 0
Training loss: 1.7604888677597046
Validation loss: 2.0378279934326806

Epoch: 5| Step: 1
Training loss: 2.2334117889404297
Validation loss: 2.0394162038962045

Epoch: 5| Step: 2
Training loss: 2.183633804321289
Validation loss: 2.0403697987397513

Epoch: 5| Step: 3
Training loss: 2.0339150428771973
Validation loss: 2.0391815652449927

Epoch: 5| Step: 4
Training loss: 1.8254992961883545
Validation loss: 2.032726844151815

Epoch: 5| Step: 5
Training loss: 2.4262681007385254
Validation loss: 2.0464939773082733

Epoch: 5| Step: 6
Training loss: 1.5890939235687256
Validation loss: 2.042301664749781

Epoch: 5| Step: 7
Training loss: 1.720747709274292
Validation loss: 2.033127541343371

Epoch: 5| Step: 8
Training loss: 2.5736138820648193
Validation loss: 2.0395729591449103

Epoch: 5| Step: 9
Training loss: 2.4698643684387207
Validation loss: 2.024642994006475

Epoch: 5| Step: 10
Training loss: 1.8047192096710205
Validation loss: 2.0413906822601953

Epoch: 5| Step: 11
Training loss: 2.7732021808624268
Validation loss: 2.0447647919257483

Epoch: 144| Step: 0
Training loss: 2.139296770095825
Validation loss: 2.035535295804342

Epoch: 5| Step: 1
Training loss: 1.7790250778198242
Validation loss: 2.047086626291275

Epoch: 5| Step: 2
Training loss: 1.394778847694397
Validation loss: 2.0349847078323364

Epoch: 5| Step: 3
Training loss: 1.8376858234405518
Validation loss: 2.04065511127313

Epoch: 5| Step: 4
Training loss: 1.8698772192001343
Validation loss: 2.0307504137357077

Epoch: 5| Step: 5
Training loss: 2.151480197906494
Validation loss: 2.027727320790291

Epoch: 5| Step: 6
Training loss: 2.3515877723693848
Validation loss: 2.0305073956648507

Epoch: 5| Step: 7
Training loss: 2.3942973613739014
Validation loss: 2.0183326452970505

Epoch: 5| Step: 8
Training loss: 2.1172549724578857
Validation loss: 2.0312791963418326

Epoch: 5| Step: 9
Training loss: 2.1787331104278564
Validation loss: 2.022464618086815

Epoch: 5| Step: 10
Training loss: 2.668354034423828
Validation loss: 2.0207438866297402

Epoch: 5| Step: 11
Training loss: 1.803533911705017
Validation loss: 2.0305769393841424

Epoch: 145| Step: 0
Training loss: 2.5458221435546875
Validation loss: 2.0274380097786584

Epoch: 5| Step: 1
Training loss: 2.3119330406188965
Validation loss: 2.0280992289384208

Epoch: 5| Step: 2
Training loss: 1.9243417978286743
Validation loss: 2.0262147088845572

Epoch: 5| Step: 3
Training loss: 2.3691201210021973
Validation loss: 2.034187669555346

Epoch: 5| Step: 4
Training loss: 2.331911563873291
Validation loss: 2.0344582398732505

Epoch: 5| Step: 5
Training loss: 1.9786392450332642
Validation loss: 2.0429601867993674

Epoch: 5| Step: 6
Training loss: 1.5488309860229492
Validation loss: 2.0367075155178704

Epoch: 5| Step: 7
Training loss: 2.098602771759033
Validation loss: 2.03494102259477

Epoch: 5| Step: 8
Training loss: 1.873164415359497
Validation loss: 2.031393532951673

Epoch: 5| Step: 9
Training loss: 1.4938075542449951
Validation loss: 2.0316765109697976

Epoch: 5| Step: 10
Training loss: 2.4218876361846924
Validation loss: 2.0245638489723206

Epoch: 5| Step: 11
Training loss: 1.4685556888580322
Validation loss: 2.031957228978475

Epoch: 146| Step: 0
Training loss: 1.5439141988754272
Validation loss: 2.0354326516389847

Epoch: 5| Step: 1
Training loss: 1.9549427032470703
Validation loss: 2.0253241757551828

Epoch: 5| Step: 2
Training loss: 2.3782172203063965
Validation loss: 2.0176714062690735

Epoch: 5| Step: 3
Training loss: 1.8691002130508423
Validation loss: 2.038093164563179

Epoch: 5| Step: 4
Training loss: 2.3365302085876465
Validation loss: 2.032369911670685

Epoch: 5| Step: 5
Training loss: 2.381298542022705
Validation loss: 2.023407459259033

Epoch: 5| Step: 6
Training loss: 2.146172046661377
Validation loss: 2.021441712975502

Epoch: 5| Step: 7
Training loss: 2.5275368690490723
Validation loss: 2.0223191579182944

Epoch: 5| Step: 8
Training loss: 2.2619452476501465
Validation loss: 2.026930476228396

Epoch: 5| Step: 9
Training loss: 1.5115153789520264
Validation loss: 2.0178463955720267

Epoch: 5| Step: 10
Training loss: 1.861040711402893
Validation loss: 2.0260589321454368

Epoch: 5| Step: 11
Training loss: 1.0561330318450928
Validation loss: 2.0304159969091415

Epoch: 147| Step: 0
Training loss: 1.7997452020645142
Validation loss: 2.028011908133825

Epoch: 5| Step: 1
Training loss: 2.4265995025634766
Validation loss: 2.0197341591119766

Epoch: 5| Step: 2
Training loss: 1.8630523681640625
Validation loss: 2.0174072881539664

Epoch: 5| Step: 3
Training loss: 2.515984058380127
Validation loss: 2.0340231458346048

Epoch: 5| Step: 4
Training loss: 1.6726255416870117
Validation loss: 2.0363154858350754

Epoch: 5| Step: 5
Training loss: 2.026505947113037
Validation loss: 2.0363354831933975

Epoch: 5| Step: 6
Training loss: 2.3044824600219727
Validation loss: 2.032675643761953

Epoch: 5| Step: 7
Training loss: 2.1368420124053955
Validation loss: 2.0286316325267157

Epoch: 5| Step: 8
Training loss: 1.9929468631744385
Validation loss: 2.022462675968806

Epoch: 5| Step: 9
Training loss: 1.8212368488311768
Validation loss: 2.0217303782701492

Epoch: 5| Step: 10
Training loss: 2.0857019424438477
Validation loss: 2.0205268363157907

Epoch: 5| Step: 11
Training loss: 2.0918993949890137
Validation loss: 2.0351741115252175

Epoch: 148| Step: 0
Training loss: 1.6471736431121826
Validation loss: 2.025929187734922

Epoch: 5| Step: 1
Training loss: 1.6425421237945557
Validation loss: 2.0222671379645667

Epoch: 5| Step: 2
Training loss: 2.73130464553833
Validation loss: 2.0315593779087067

Epoch: 5| Step: 3
Training loss: 1.864372968673706
Validation loss: 2.0388058573007584

Epoch: 5| Step: 4
Training loss: 2.351766586303711
Validation loss: 2.038147062063217

Epoch: 5| Step: 5
Training loss: 1.9974056482315063
Validation loss: 2.049006720383962

Epoch: 5| Step: 6
Training loss: 2.207958698272705
Validation loss: 2.05585282544295

Epoch: 5| Step: 7
Training loss: 2.178737163543701
Validation loss: 2.0288398216168084

Epoch: 5| Step: 8
Training loss: 2.1549596786499023
Validation loss: 2.032561014095942

Epoch: 5| Step: 9
Training loss: 2.3064372539520264
Validation loss: 2.0345820585886636

Epoch: 5| Step: 10
Training loss: 1.7751739025115967
Validation loss: 2.0364007353782654

Epoch: 5| Step: 11
Training loss: 2.3561787605285645
Validation loss: 2.0361269811789193

Epoch: 149| Step: 0
Training loss: 1.8516372442245483
Validation loss: 2.0244700014591217

Epoch: 5| Step: 1
Training loss: 2.0911078453063965
Validation loss: 2.024986763795217

Epoch: 5| Step: 2
Training loss: 2.8049063682556152
Validation loss: 2.026743397116661

Epoch: 5| Step: 3
Training loss: 2.007406234741211
Validation loss: 2.0465401957432428

Epoch: 5| Step: 4
Training loss: 1.7856223583221436
Validation loss: 2.0399983674287796

Epoch: 5| Step: 5
Training loss: 1.7126476764678955
Validation loss: 2.044203797976176

Epoch: 5| Step: 6
Training loss: 2.417428493499756
Validation loss: 2.0414977967739105

Epoch: 5| Step: 7
Training loss: 2.348402261734009
Validation loss: 2.034326876203219

Epoch: 5| Step: 8
Training loss: 2.449070930480957
Validation loss: 2.025688568751017

Epoch: 5| Step: 9
Training loss: 2.058696746826172
Validation loss: 2.029436926047007

Epoch: 5| Step: 10
Training loss: 2.013698101043701
Validation loss: 2.031592989961306

Epoch: 5| Step: 11
Training loss: 1.5859630107879639
Validation loss: 2.0225030730168023

Epoch: 150| Step: 0
Training loss: 2.4308109283447266
Validation loss: 2.032765656709671

Epoch: 5| Step: 1
Training loss: 2.09963059425354
Validation loss: 2.0289295812447867

Epoch: 5| Step: 2
Training loss: 1.7929798364639282
Validation loss: 2.036641319592794

Epoch: 5| Step: 3
Training loss: 2.2156150341033936
Validation loss: 2.0392041156689324

Epoch: 5| Step: 4
Training loss: 2.29378080368042
Validation loss: 2.03145702679952

Epoch: 5| Step: 5
Training loss: 2.1077003479003906
Validation loss: 2.0328975717226663

Epoch: 5| Step: 6
Training loss: 2.13564133644104
Validation loss: 2.0400375028451285

Epoch: 5| Step: 7
Training loss: 1.9781608581542969
Validation loss: 2.0431741774082184

Epoch: 5| Step: 8
Training loss: 2.1478095054626465
Validation loss: 2.0416691650946936

Epoch: 5| Step: 9
Training loss: 2.004828929901123
Validation loss: 2.0520252088705697

Epoch: 5| Step: 10
Training loss: 1.6454111337661743
Validation loss: 2.042791177829107

Epoch: 5| Step: 11
Training loss: 1.8113601207733154
Validation loss: 2.037078246474266

Epoch: 151| Step: 0
Training loss: 2.3462560176849365
Validation loss: 2.0351643363634744

Epoch: 5| Step: 1
Training loss: 2.0755136013031006
Validation loss: 2.0259292274713516

Epoch: 5| Step: 2
Training loss: 2.0164833068847656
Validation loss: 2.028600588440895

Epoch: 5| Step: 3
Training loss: 1.626835584640503
Validation loss: 2.014393930633863

Epoch: 5| Step: 4
Training loss: 2.195060968399048
Validation loss: 2.0214037001132965

Epoch: 5| Step: 5
Training loss: 2.190580368041992
Validation loss: 2.014965131878853

Epoch: 5| Step: 6
Training loss: 2.5995452404022217
Validation loss: 2.0240179051955542

Epoch: 5| Step: 7
Training loss: 1.7359142303466797
Validation loss: 2.022693410515785

Epoch: 5| Step: 8
Training loss: 2.1723854541778564
Validation loss: 2.0246226688226066

Epoch: 5| Step: 9
Training loss: 2.1372506618499756
Validation loss: 2.026348133881887

Epoch: 5| Step: 10
Training loss: 1.980401635169983
Validation loss: 2.0324355214834213

Epoch: 5| Step: 11
Training loss: 1.1793195009231567
Validation loss: 2.0192880829175315

Epoch: 152| Step: 0
Training loss: 2.1056392192840576
Validation loss: 2.0330522110064826

Epoch: 5| Step: 1
Training loss: 2.4069504737854004
Validation loss: 2.028506318728129

Epoch: 5| Step: 2
Training loss: 2.5756423473358154
Validation loss: 2.0311408638954163

Epoch: 5| Step: 3
Training loss: 1.6065247058868408
Validation loss: 2.039513498544693

Epoch: 5| Step: 4
Training loss: 2.008794069290161
Validation loss: 2.038428783416748

Epoch: 5| Step: 5
Training loss: 1.649450659751892
Validation loss: 2.0352121790250144

Epoch: 5| Step: 6
Training loss: 2.034801959991455
Validation loss: 2.0335993667443595

Epoch: 5| Step: 7
Training loss: 1.8354108333587646
Validation loss: 2.03371628622214

Epoch: 5| Step: 8
Training loss: 2.275782823562622
Validation loss: 2.02849280834198

Epoch: 5| Step: 9
Training loss: 2.5947422981262207
Validation loss: 2.034029871225357

Epoch: 5| Step: 10
Training loss: 1.5265429019927979
Validation loss: 2.0385650942722955

Epoch: 5| Step: 11
Training loss: 2.2489101886749268
Validation loss: 2.031735271215439

Epoch: 153| Step: 0
Training loss: 1.6983855962753296
Validation loss: 2.0412206848462424

Epoch: 5| Step: 1
Training loss: 2.1577324867248535
Validation loss: 2.045683830976486

Epoch: 5| Step: 2
Training loss: 2.511444568634033
Validation loss: 2.042697290579478

Epoch: 5| Step: 3
Training loss: 2.0105762481689453
Validation loss: 2.0381560971339545

Epoch: 5| Step: 4
Training loss: 1.8309587240219116
Validation loss: 2.046870688597361

Epoch: 5| Step: 5
Training loss: 1.7500110864639282
Validation loss: 2.040957768758138

Epoch: 5| Step: 6
Training loss: 2.0610241889953613
Validation loss: 2.039086530605952

Epoch: 5| Step: 7
Training loss: 2.1453464031219482
Validation loss: 2.026291420062383

Epoch: 5| Step: 8
Training loss: 2.1735081672668457
Validation loss: 2.040950467189153

Epoch: 5| Step: 9
Training loss: 2.240816593170166
Validation loss: 2.040945822993914

Epoch: 5| Step: 10
Training loss: 2.3539557456970215
Validation loss: 2.045501043399175

Epoch: 5| Step: 11
Training loss: 0.9722369909286499
Validation loss: 2.0270181397596994

Epoch: 154| Step: 0
Training loss: 2.562044620513916
Validation loss: 2.042818913857142

Epoch: 5| Step: 1
Training loss: 2.030247926712036
Validation loss: 2.038145288825035

Epoch: 5| Step: 2
Training loss: 1.7691673040390015
Validation loss: 2.0244782666365304

Epoch: 5| Step: 3
Training loss: 1.6097818613052368
Validation loss: 2.0300167153278985

Epoch: 5| Step: 4
Training loss: 2.0048890113830566
Validation loss: 2.031707525253296

Epoch: 5| Step: 5
Training loss: 2.3142788410186768
Validation loss: 2.041424651940664

Epoch: 5| Step: 6
Training loss: 2.6437344551086426
Validation loss: 2.043558498223623

Epoch: 5| Step: 7
Training loss: 2.175666570663452
Validation loss: 2.0447427878777185

Epoch: 5| Step: 8
Training loss: 1.598105788230896
Validation loss: 2.0390317887067795

Epoch: 5| Step: 9
Training loss: 2.150010585784912
Validation loss: 2.054396758476893

Epoch: 5| Step: 10
Training loss: 1.8274425268173218
Validation loss: 2.039606144030889

Epoch: 5| Step: 11
Training loss: 2.2473998069763184
Validation loss: 2.046754797299703

Epoch: 155| Step: 0
Training loss: 2.3022899627685547
Validation loss: 2.0396588146686554

Epoch: 5| Step: 1
Training loss: 2.10500431060791
Validation loss: 2.0365291088819504

Epoch: 5| Step: 2
Training loss: 2.2432162761688232
Validation loss: 2.0364353358745575

Epoch: 5| Step: 3
Training loss: 1.9225189685821533
Validation loss: 2.043394992748896

Epoch: 5| Step: 4
Training loss: 1.8069607019424438
Validation loss: 2.038959264755249

Epoch: 5| Step: 5
Training loss: 2.1902332305908203
Validation loss: 2.0446863571802774

Epoch: 5| Step: 6
Training loss: 2.3227696418762207
Validation loss: 2.0405704577763877

Epoch: 5| Step: 7
Training loss: 1.853875756263733
Validation loss: 2.0405699064334235

Epoch: 5| Step: 8
Training loss: 1.9752063751220703
Validation loss: 2.034969240427017

Epoch: 5| Step: 9
Training loss: 1.3400156497955322
Validation loss: 2.0340370684862137

Epoch: 5| Step: 10
Training loss: 2.195957899093628
Validation loss: 2.0272049804528556

Epoch: 5| Step: 11
Training loss: 2.9218132495880127
Validation loss: 2.0323923925558725

Epoch: 156| Step: 0
Training loss: 2.3774585723876953
Validation loss: 2.0394765635331473

Epoch: 5| Step: 1
Training loss: 2.463897228240967
Validation loss: 2.0390151043732962

Epoch: 5| Step: 2
Training loss: 1.685201644897461
Validation loss: 2.0403116196393967

Epoch: 5| Step: 3
Training loss: 1.5525805950164795
Validation loss: 2.0402338256438575

Epoch: 5| Step: 4
Training loss: 1.6542689800262451
Validation loss: 2.0361897150675454

Epoch: 5| Step: 5
Training loss: 2.519047975540161
Validation loss: 2.0434731443723044

Epoch: 5| Step: 6
Training loss: 1.7284505367279053
Validation loss: 2.038597052296003

Epoch: 5| Step: 7
Training loss: 2.084315776824951
Validation loss: 2.046094218889872

Epoch: 5| Step: 8
Training loss: 1.966679334640503
Validation loss: 2.046332190434138

Epoch: 5| Step: 9
Training loss: 1.956761360168457
Validation loss: 2.044951577981313

Epoch: 5| Step: 10
Training loss: 2.3412392139434814
Validation loss: 2.051398992538452

Epoch: 5| Step: 11
Training loss: 3.2771778106689453
Validation loss: 2.060152212778727

Epoch: 157| Step: 0
Training loss: 2.251824140548706
Validation loss: 2.059439649184545

Epoch: 5| Step: 1
Training loss: 1.2481012344360352
Validation loss: 2.043916404247284

Epoch: 5| Step: 2
Training loss: 1.7982772588729858
Validation loss: 2.0589624494314194

Epoch: 5| Step: 3
Training loss: 1.8114118576049805
Validation loss: 2.0486443837483725

Epoch: 5| Step: 4
Training loss: 2.2474613189697266
Validation loss: 2.059032157063484

Epoch: 5| Step: 5
Training loss: 2.3809494972229004
Validation loss: 2.057220737139384

Epoch: 5| Step: 6
Training loss: 2.121258020401001
Validation loss: 2.04451385140419

Epoch: 5| Step: 7
Training loss: 1.7472732067108154
Validation loss: 2.0605491548776627

Epoch: 5| Step: 8
Training loss: 2.6108803749084473
Validation loss: 2.0613757173220315

Epoch: 5| Step: 9
Training loss: 2.5233445167541504
Validation loss: 2.055846338470777

Epoch: 5| Step: 10
Training loss: 1.9860531091690063
Validation loss: 2.0527268946170807

Epoch: 5| Step: 11
Training loss: 0.8422937393188477
Validation loss: 2.053031956156095

Epoch: 158| Step: 0
Training loss: 2.36603045463562
Validation loss: 2.0503912965456643

Epoch: 5| Step: 1
Training loss: 1.7590566873550415
Validation loss: 2.0731283773978553

Epoch: 5| Step: 2
Training loss: 2.5199623107910156
Validation loss: 2.1282059103250504

Epoch: 5| Step: 3
Training loss: 2.2522034645080566
Validation loss: 2.157371550798416

Epoch: 5| Step: 4
Training loss: 1.9121536016464233
Validation loss: 2.1320843249559402

Epoch: 5| Step: 5
Training loss: 1.9082494974136353
Validation loss: 2.1054245432217917

Epoch: 5| Step: 6
Training loss: 1.759981393814087
Validation loss: 2.074774985512098

Epoch: 5| Step: 7
Training loss: 2.7719035148620605
Validation loss: 2.0604630758364997

Epoch: 5| Step: 8
Training loss: 2.086610794067383
Validation loss: 2.0382961531480155

Epoch: 5| Step: 9
Training loss: 2.27938175201416
Validation loss: 2.032778029640516

Epoch: 5| Step: 10
Training loss: 1.679731011390686
Validation loss: 2.0331066300471625

Epoch: 5| Step: 11
Training loss: 1.9347236156463623
Validation loss: 2.0467450569073358

Epoch: 159| Step: 0
Training loss: 2.2256596088409424
Validation loss: 2.0484252721071243

Epoch: 5| Step: 1
Training loss: 2.1615195274353027
Validation loss: 2.0545311917861304

Epoch: 5| Step: 2
Training loss: 2.0168144702911377
Validation loss: 2.0699707865715027

Epoch: 5| Step: 3
Training loss: 2.0430800914764404
Validation loss: 2.0758595863978067

Epoch: 5| Step: 4
Training loss: 1.5725247859954834
Validation loss: 2.0710252473751702

Epoch: 5| Step: 5
Training loss: 2.10737681388855
Validation loss: 2.0800443589687347

Epoch: 5| Step: 6
Training loss: 2.6763901710510254
Validation loss: 2.078023225069046

Epoch: 5| Step: 7
Training loss: 1.986797571182251
Validation loss: 2.072942545016607

Epoch: 5| Step: 8
Training loss: 2.0396957397460938
Validation loss: 2.0813771734635034

Epoch: 5| Step: 9
Training loss: 2.715604543685913
Validation loss: 2.085167442758878

Epoch: 5| Step: 10
Training loss: 2.5211901664733887
Validation loss: 2.0765393525362015

Epoch: 5| Step: 11
Training loss: 2.2375216484069824
Validation loss: 2.0669840027888617

Epoch: 160| Step: 0
Training loss: 2.6819963455200195
Validation loss: 2.057973951101303

Epoch: 5| Step: 1
Training loss: 2.428144931793213
Validation loss: 2.0614525079727173

Epoch: 5| Step: 2
Training loss: 2.0802721977233887
Validation loss: 2.0523713678121567

Epoch: 5| Step: 3
Training loss: 1.7131456136703491
Validation loss: 2.0463639895121255

Epoch: 5| Step: 4
Training loss: 2.3109993934631348
Validation loss: 2.0387354095776877

Epoch: 5| Step: 5
Training loss: 1.7598451375961304
Validation loss: 2.03025949994723

Epoch: 5| Step: 6
Training loss: 1.7216625213623047
Validation loss: 2.023569345474243

Epoch: 5| Step: 7
Training loss: 2.376932144165039
Validation loss: 2.02296548585097

Epoch: 5| Step: 8
Training loss: 2.3321585655212402
Validation loss: 2.0206064035495124

Epoch: 5| Step: 9
Training loss: 1.8906056880950928
Validation loss: 2.011429031689962

Epoch: 5| Step: 10
Training loss: 2.419381618499756
Validation loss: 2.0055016577243805

Epoch: 5| Step: 11
Training loss: 1.6348226070404053
Validation loss: 2.007289081811905

Epoch: 161| Step: 0
Training loss: 2.005847692489624
Validation loss: 2.006875768303871

Epoch: 5| Step: 1
Training loss: 2.7839221954345703
Validation loss: 2.017450839281082

Epoch: 5| Step: 2
Training loss: 1.4502570629119873
Validation loss: 2.012788956363996

Epoch: 5| Step: 3
Training loss: 2.2722785472869873
Validation loss: 2.05217116077741

Epoch: 5| Step: 4
Training loss: 1.5254768133163452
Validation loss: 2.0583527286847434

Epoch: 5| Step: 5
Training loss: 1.9513671398162842
Validation loss: 2.059145932396253

Epoch: 5| Step: 6
Training loss: 2.409636974334717
Validation loss: 2.0449845790863037

Epoch: 5| Step: 7
Training loss: 1.9782123565673828
Validation loss: 2.0553902635971704

Epoch: 5| Step: 8
Training loss: 1.664099931716919
Validation loss: 2.0424802899360657

Epoch: 5| Step: 9
Training loss: 2.448472499847412
Validation loss: 2.0597667197386422

Epoch: 5| Step: 10
Training loss: 2.1497676372528076
Validation loss: 2.051265353957812

Epoch: 5| Step: 11
Training loss: 1.9437148571014404
Validation loss: 2.063965087135633

Epoch: 162| Step: 0
Training loss: 2.1786696910858154
Validation loss: 2.0612053026755652

Epoch: 5| Step: 1
Training loss: 2.327784776687622
Validation loss: 2.0562154352664948

Epoch: 5| Step: 2
Training loss: 1.8126548528671265
Validation loss: 2.069058428208033

Epoch: 5| Step: 3
Training loss: 2.1543362140655518
Validation loss: 2.078402762611707

Epoch: 5| Step: 4
Training loss: 1.8096116781234741
Validation loss: 2.0695436050494513

Epoch: 5| Step: 5
Training loss: 2.004578113555908
Validation loss: 2.0693155278762183

Epoch: 5| Step: 6
Training loss: 2.0934672355651855
Validation loss: 2.077478210131327

Epoch: 5| Step: 7
Training loss: 2.0466573238372803
Validation loss: 2.0566804806391397

Epoch: 5| Step: 8
Training loss: 1.5729647874832153
Validation loss: 2.0508160640796027

Epoch: 5| Step: 9
Training loss: 2.3738484382629395
Validation loss: 2.050882786512375

Epoch: 5| Step: 10
Training loss: 2.1258511543273926
Validation loss: 2.0416685541470847

Epoch: 5| Step: 11
Training loss: 2.7130396366119385
Validation loss: 2.049836347500483

Epoch: 163| Step: 0
Training loss: 1.9353927373886108
Validation loss: 2.064015656709671

Epoch: 5| Step: 1
Training loss: 2.7313408851623535
Validation loss: 2.049563671151797

Epoch: 5| Step: 2
Training loss: 2.320159435272217
Validation loss: 2.045004293322563

Epoch: 5| Step: 3
Training loss: 2.1182198524475098
Validation loss: 2.0352637569109597

Epoch: 5| Step: 4
Training loss: 1.9147546291351318
Validation loss: 2.048199633757273

Epoch: 5| Step: 5
Training loss: 2.468149185180664
Validation loss: 2.045966694752375

Epoch: 5| Step: 6
Training loss: 1.7624788284301758
Validation loss: 2.0458920697371163

Epoch: 5| Step: 7
Training loss: 2.016191005706787
Validation loss: 2.0446192771196365

Epoch: 5| Step: 8
Training loss: 2.587209939956665
Validation loss: 2.050087591012319

Epoch: 5| Step: 9
Training loss: 1.2532843351364136
Validation loss: 2.0454125305016837

Epoch: 5| Step: 10
Training loss: 2.149888277053833
Validation loss: 2.0532463689645133

Epoch: 5| Step: 11
Training loss: 1.6237393617630005
Validation loss: 2.052260642250379

Epoch: 164| Step: 0
Training loss: 1.8904078006744385
Validation loss: 2.0588041245937347

Epoch: 5| Step: 1
Training loss: 2.4392027854919434
Validation loss: 2.057035634915034

Epoch: 5| Step: 2
Training loss: 2.4590582847595215
Validation loss: 2.062548945347468

Epoch: 5| Step: 3
Training loss: 1.6124532222747803
Validation loss: 2.0614254722992578

Epoch: 5| Step: 4
Training loss: 2.434390068054199
Validation loss: 2.062818467617035

Epoch: 5| Step: 5
Training loss: 2.0080959796905518
Validation loss: 2.072217360138893

Epoch: 5| Step: 6
Training loss: 2.1434099674224854
Validation loss: 2.0721080849568048

Epoch: 5| Step: 7
Training loss: 1.8206344842910767
Validation loss: 2.0803645054499307

Epoch: 5| Step: 8
Training loss: 2.0576157569885254
Validation loss: 2.072380910317103

Epoch: 5| Step: 9
Training loss: 1.7721446752548218
Validation loss: 2.055041790008545

Epoch: 5| Step: 10
Training loss: 2.217254400253296
Validation loss: 2.059431274731954

Epoch: 5| Step: 11
Training loss: 3.0608139038085938
Validation loss: 2.05519492427508

Epoch: 165| Step: 0
Training loss: 2.206818103790283
Validation loss: 2.059975172082583

Epoch: 5| Step: 1
Training loss: 1.9410775899887085
Validation loss: 2.055001715819041

Epoch: 5| Step: 2
Training loss: 1.9191160202026367
Validation loss: 2.054159884651502

Epoch: 5| Step: 3
Training loss: 1.944230079650879
Validation loss: 2.0438104619582496

Epoch: 5| Step: 4
Training loss: 2.01124906539917
Validation loss: 2.037776152292887

Epoch: 5| Step: 5
Training loss: 1.7849595546722412
Validation loss: 2.04132117331028

Epoch: 5| Step: 6
Training loss: 2.315545082092285
Validation loss: 2.0415351887543998

Epoch: 5| Step: 7
Training loss: 1.9717426300048828
Validation loss: 2.030422771970431

Epoch: 5| Step: 8
Training loss: 2.0721192359924316
Validation loss: 2.029771625995636

Epoch: 5| Step: 9
Training loss: 2.290269613265991
Validation loss: 2.0370047887166343

Epoch: 5| Step: 10
Training loss: 2.0563042163848877
Validation loss: 2.0374414970477424

Epoch: 5| Step: 11
Training loss: 2.05560302734375
Validation loss: 2.036911760767301

Epoch: 166| Step: 0
Training loss: 1.7635996341705322
Validation loss: 2.04267847041289

Epoch: 5| Step: 1
Training loss: 1.5005347728729248
Validation loss: 2.0404802014430365

Epoch: 5| Step: 2
Training loss: 2.7685725688934326
Validation loss: 2.035420839985212

Epoch: 5| Step: 3
Training loss: 2.0278677940368652
Validation loss: 2.0530939598878226

Epoch: 5| Step: 4
Training loss: 2.234400510787964
Validation loss: 2.04996819794178

Epoch: 5| Step: 5
Training loss: 2.030770778656006
Validation loss: 2.0585827430089316

Epoch: 5| Step: 6
Training loss: 1.5153844356536865
Validation loss: 2.0480860571066537

Epoch: 5| Step: 7
Training loss: 2.145265579223633
Validation loss: 2.0496863226095834

Epoch: 5| Step: 8
Training loss: 2.2934653759002686
Validation loss: 2.0517990440130234

Epoch: 5| Step: 9
Training loss: 2.119232654571533
Validation loss: 2.0572765469551086

Epoch: 5| Step: 10
Training loss: 1.7429176568984985
Validation loss: 2.060896649956703

Epoch: 5| Step: 11
Training loss: 2.8926448822021484
Validation loss: 2.0653759042421975

Epoch: 167| Step: 0
Training loss: 2.3874597549438477
Validation loss: 2.052753373980522

Epoch: 5| Step: 1
Training loss: 1.6421339511871338
Validation loss: 2.0527135829130807

Epoch: 5| Step: 2
Training loss: 1.623999834060669
Validation loss: 2.0620753467082977

Epoch: 5| Step: 3
Training loss: 2.015813112258911
Validation loss: 2.06098572909832

Epoch: 5| Step: 4
Training loss: 2.24931001663208
Validation loss: 2.053960308432579

Epoch: 5| Step: 5
Training loss: 1.8127237558364868
Validation loss: 2.057711571455002

Epoch: 5| Step: 6
Training loss: 1.4350240230560303
Validation loss: 2.0549041281143823

Epoch: 5| Step: 7
Training loss: 2.407336711883545
Validation loss: 2.0682446310917535

Epoch: 5| Step: 8
Training loss: 2.2614333629608154
Validation loss: 2.052942077318827

Epoch: 5| Step: 9
Training loss: 2.465909481048584
Validation loss: 2.0543854981660843

Epoch: 5| Step: 10
Training loss: 1.9930236339569092
Validation loss: 2.0811485052108765

Epoch: 5| Step: 11
Training loss: 2.8275139331817627
Validation loss: 2.058264354864756

Epoch: 168| Step: 0
Training loss: 1.7092344760894775
Validation loss: 2.0543410181999207

Epoch: 5| Step: 1
Training loss: 1.896935224533081
Validation loss: 2.053898811340332

Epoch: 5| Step: 2
Training loss: 1.8681408166885376
Validation loss: 2.053436184922854

Epoch: 5| Step: 3
Training loss: 1.7595897912979126
Validation loss: 2.0542400926351547

Epoch: 5| Step: 4
Training loss: 1.9756799936294556
Validation loss: 2.057756414016088

Epoch: 5| Step: 5
Training loss: 2.3027968406677246
Validation loss: 2.054659550388654

Epoch: 5| Step: 6
Training loss: 2.105536937713623
Validation loss: 2.0513880054155984

Epoch: 5| Step: 7
Training loss: 2.3814961910247803
Validation loss: 2.062409187356631

Epoch: 5| Step: 8
Training loss: 2.2686574459075928
Validation loss: 2.0487176130215325

Epoch: 5| Step: 9
Training loss: 2.0693938732147217
Validation loss: 2.0491845508416495

Epoch: 5| Step: 10
Training loss: 2.0898969173431396
Validation loss: 2.053993841012319

Epoch: 5| Step: 11
Training loss: 1.8230997323989868
Validation loss: 2.0489948391914368

Epoch: 169| Step: 0
Training loss: 1.8619791269302368
Validation loss: 2.052520458896955

Epoch: 5| Step: 1
Training loss: 1.8455644845962524
Validation loss: 2.0561516086260476

Epoch: 5| Step: 2
Training loss: 1.8734595775604248
Validation loss: 2.041822145382563

Epoch: 5| Step: 3
Training loss: 2.0368361473083496
Validation loss: 2.0479384064674377

Epoch: 5| Step: 4
Training loss: 2.190321445465088
Validation loss: 2.0505701849857965

Epoch: 5| Step: 5
Training loss: 1.9143282175064087
Validation loss: 2.05398361881574

Epoch: 5| Step: 6
Training loss: 2.6516356468200684
Validation loss: 2.054630031188329

Epoch: 5| Step: 7
Training loss: 2.2008957862854004
Validation loss: 2.0606447209914527

Epoch: 5| Step: 8
Training loss: 2.417081117630005
Validation loss: 2.0633596827586493

Epoch: 5| Step: 9
Training loss: 1.8407046794891357
Validation loss: 2.0492394467194877

Epoch: 5| Step: 10
Training loss: 1.674361228942871
Validation loss: 2.059199114640554

Epoch: 5| Step: 11
Training loss: 1.1967346668243408
Validation loss: 2.0505445152521133

Epoch: 170| Step: 0
Training loss: 1.7985455989837646
Validation loss: 2.0506256967782974

Epoch: 5| Step: 1
Training loss: 1.8676326274871826
Validation loss: 2.059834733605385

Epoch: 5| Step: 2
Training loss: 2.624774932861328
Validation loss: 2.051747669776281

Epoch: 5| Step: 3
Training loss: 2.2078659534454346
Validation loss: 2.05905744433403

Epoch: 5| Step: 4
Training loss: 2.428325653076172
Validation loss: 2.0685489724079766

Epoch: 5| Step: 5
Training loss: 2.2457268238067627
Validation loss: 2.059986943999926

Epoch: 5| Step: 6
Training loss: 1.8673114776611328
Validation loss: 2.0559278776248298

Epoch: 5| Step: 7
Training loss: 1.758235216140747
Validation loss: 2.0473146438598633

Epoch: 5| Step: 8
Training loss: 2.061028480529785
Validation loss: 2.0477284590403237

Epoch: 5| Step: 9
Training loss: 1.7166407108306885
Validation loss: 2.0437963008880615

Epoch: 5| Step: 10
Training loss: 1.813030481338501
Validation loss: 2.0467844704786935

Epoch: 5| Step: 11
Training loss: 1.5151257514953613
Validation loss: 2.040248359243075

Epoch: 171| Step: 0
Training loss: 2.6200222969055176
Validation loss: 2.0402493874231973

Epoch: 5| Step: 1
Training loss: 1.83542001247406
Validation loss: 2.0513873795668283

Epoch: 5| Step: 2
Training loss: 1.8583539724349976
Validation loss: 2.0340759307146072

Epoch: 5| Step: 3
Training loss: 1.5689818859100342
Validation loss: 2.0423481861750283

Epoch: 5| Step: 4
Training loss: 2.0467498302459717
Validation loss: 2.0519844740629196

Epoch: 5| Step: 5
Training loss: 2.223599433898926
Validation loss: 2.0541497568289437

Epoch: 5| Step: 6
Training loss: 1.5606218576431274
Validation loss: 2.047729323307673

Epoch: 5| Step: 7
Training loss: 2.3718433380126953
Validation loss: 2.0516772170861564

Epoch: 5| Step: 8
Training loss: 2.203669548034668
Validation loss: 2.0514810333649316

Epoch: 5| Step: 9
Training loss: 2.2799272537231445
Validation loss: 2.055147096514702

Epoch: 5| Step: 10
Training loss: 1.6335262060165405
Validation loss: 2.0494665106137595

Epoch: 5| Step: 11
Training loss: 2.228985548019409
Validation loss: 2.0577632983525596

Epoch: 172| Step: 0
Training loss: 2.028423547744751
Validation loss: 2.0632598300774894

Epoch: 5| Step: 1
Training loss: 1.986413598060608
Validation loss: 2.055459221204122

Epoch: 5| Step: 2
Training loss: 1.7539198398590088
Validation loss: 2.0712230056524277

Epoch: 5| Step: 3
Training loss: 2.347451686859131
Validation loss: 2.06854784488678

Epoch: 5| Step: 4
Training loss: 1.686225175857544
Validation loss: 2.059008772174517

Epoch: 5| Step: 5
Training loss: 2.1978373527526855
Validation loss: 2.0522680332263312

Epoch: 5| Step: 6
Training loss: 1.8094825744628906
Validation loss: 2.051514451702436

Epoch: 5| Step: 7
Training loss: 2.2051868438720703
Validation loss: 2.0544453263282776

Epoch: 5| Step: 8
Training loss: 2.063969373703003
Validation loss: 2.0600689152876535

Epoch: 5| Step: 9
Training loss: 2.3841195106506348
Validation loss: 2.0583543380101523

Epoch: 5| Step: 10
Training loss: 2.0601978302001953
Validation loss: 2.0647462954123816

Epoch: 5| Step: 11
Training loss: 0.7325208187103271
Validation loss: 2.0546554078658423

Epoch: 173| Step: 0
Training loss: 2.339118242263794
Validation loss: 2.057362119356791

Epoch: 5| Step: 1
Training loss: 1.8758697509765625
Validation loss: 2.055706555644671

Epoch: 5| Step: 2
Training loss: 2.3242154121398926
Validation loss: 2.0414040138324103

Epoch: 5| Step: 3
Training loss: 1.6242036819458008
Validation loss: 2.0479393104712167

Epoch: 5| Step: 4
Training loss: 2.247955322265625
Validation loss: 2.045586109161377

Epoch: 5| Step: 5
Training loss: 1.6693923473358154
Validation loss: 2.0466289768616357

Epoch: 5| Step: 6
Training loss: 2.202312707901001
Validation loss: 2.053798963626226

Epoch: 5| Step: 7
Training loss: 1.8416551351547241
Validation loss: 2.0478831926981607

Epoch: 5| Step: 8
Training loss: 2.253737688064575
Validation loss: 2.0450558414061866

Epoch: 5| Step: 9
Training loss: 2.089179515838623
Validation loss: 2.059359441200892

Epoch: 5| Step: 10
Training loss: 1.9714679718017578
Validation loss: 2.0560115625460944

Epoch: 5| Step: 11
Training loss: 2.3970203399658203
Validation loss: 2.0611939082543054

Epoch: 174| Step: 0
Training loss: 1.933126449584961
Validation loss: 2.0715765158335366

Epoch: 5| Step: 1
Training loss: 1.9982655048370361
Validation loss: 2.0634839236736298

Epoch: 5| Step: 2
Training loss: 1.7886375188827515
Validation loss: 2.0782026251157126

Epoch: 5| Step: 3
Training loss: 2.1648995876312256
Validation loss: 2.0804660667975745

Epoch: 5| Step: 4
Training loss: 1.9807536602020264
Validation loss: 2.0926337440808616

Epoch: 5| Step: 5
Training loss: 2.281540632247925
Validation loss: 2.0886375109354653

Epoch: 5| Step: 6
Training loss: 2.2136988639831543
Validation loss: 2.085348511735598

Epoch: 5| Step: 7
Training loss: 2.028029441833496
Validation loss: 2.0938625981410346

Epoch: 5| Step: 8
Training loss: 1.6095796823501587
Validation loss: 2.0799251397450766

Epoch: 5| Step: 9
Training loss: 2.3610382080078125
Validation loss: 2.0614153842131295

Epoch: 5| Step: 10
Training loss: 1.8680737018585205
Validation loss: 2.0763702938954034

Epoch: 5| Step: 11
Training loss: 2.0153236389160156
Validation loss: 2.0709685683250427

Epoch: 175| Step: 0
Training loss: 2.117161273956299
Validation loss: 2.0515725513299308

Epoch: 5| Step: 1
Training loss: 2.531813383102417
Validation loss: 2.047546918193499

Epoch: 5| Step: 2
Training loss: 1.9604803323745728
Validation loss: 2.053455129265785

Epoch: 5| Step: 3
Training loss: 2.42057728767395
Validation loss: 2.04541244606177

Epoch: 5| Step: 4
Training loss: 1.9472839832305908
Validation loss: 2.0473166157801947

Epoch: 5| Step: 5
Training loss: 1.5930331945419312
Validation loss: 2.0552354951699576

Epoch: 5| Step: 6
Training loss: 1.8051528930664062
Validation loss: 2.072228873769442

Epoch: 5| Step: 7
Training loss: 2.202746868133545
Validation loss: 2.078263665239016

Epoch: 5| Step: 8
Training loss: 2.1169917583465576
Validation loss: 2.0955113073190055

Epoch: 5| Step: 9
Training loss: 1.8746511936187744
Validation loss: 2.093214690685272

Epoch: 5| Step: 10
Training loss: 1.8621619939804077
Validation loss: 2.092061847448349

Epoch: 5| Step: 11
Training loss: 2.0681779384613037
Validation loss: 2.092779884735743

Epoch: 176| Step: 0
Training loss: 1.9619401693344116
Validation loss: 2.079131136337916

Epoch: 5| Step: 1
Training loss: 2.254291534423828
Validation loss: 2.091318299372991

Epoch: 5| Step: 2
Training loss: 1.7996368408203125
Validation loss: 2.0900807827711105

Epoch: 5| Step: 3
Training loss: 1.4766693115234375
Validation loss: 2.0871595789988837

Epoch: 5| Step: 4
Training loss: 1.9384605884552002
Validation loss: 2.083299239476522

Epoch: 5| Step: 5
Training loss: 2.295518636703491
Validation loss: 2.0957321226596832

Epoch: 5| Step: 6
Training loss: 2.3102898597717285
Validation loss: 2.083039845029513

Epoch: 5| Step: 7
Training loss: 1.9181381464004517
Validation loss: 2.1009228080511093

Epoch: 5| Step: 8
Training loss: 1.9530584812164307
Validation loss: 2.086902141571045

Epoch: 5| Step: 9
Training loss: 1.4960215091705322
Validation loss: 2.075875530640284

Epoch: 5| Step: 10
Training loss: 2.4861106872558594
Validation loss: 2.0622418373823166

Epoch: 5| Step: 11
Training loss: 2.335088014602661
Validation loss: 2.0561522394418716

Epoch: 177| Step: 0
Training loss: 1.3002952337265015
Validation loss: 2.0559684336185455

Epoch: 5| Step: 1
Training loss: 2.197028636932373
Validation loss: 2.0480680664380393

Epoch: 5| Step: 2
Training loss: 2.4630682468414307
Validation loss: 2.0439505030711493

Epoch: 5| Step: 3
Training loss: 2.2738265991210938
Validation loss: 2.034547636906306

Epoch: 5| Step: 4
Training loss: 1.8119537830352783
Validation loss: 2.0476656357447305

Epoch: 5| Step: 5
Training loss: 2.079469680786133
Validation loss: 2.04683680832386

Epoch: 5| Step: 6
Training loss: 1.8033937215805054
Validation loss: 2.041950528820356

Epoch: 5| Step: 7
Training loss: 2.269040584564209
Validation loss: 2.0269939402739205

Epoch: 5| Step: 8
Training loss: 2.222012996673584
Validation loss: 2.0321557323137918

Epoch: 5| Step: 9
Training loss: 2.5982136726379395
Validation loss: 2.039240747690201

Epoch: 5| Step: 10
Training loss: 1.5643357038497925
Validation loss: 2.046287933985392

Epoch: 5| Step: 11
Training loss: 2.131549119949341
Validation loss: 2.046769912044207

Epoch: 178| Step: 0
Training loss: 1.8191354274749756
Validation loss: 2.044833188255628

Epoch: 5| Step: 1
Training loss: 1.8964134454727173
Validation loss: 2.0670280158519745

Epoch: 5| Step: 2
Training loss: 1.956493616104126
Validation loss: 2.0759581526120505

Epoch: 5| Step: 3
Training loss: 1.9733692407608032
Validation loss: 2.076836278041204

Epoch: 5| Step: 4
Training loss: 2.064788579940796
Validation loss: 2.071440746386846

Epoch: 5| Step: 5
Training loss: 2.05617094039917
Validation loss: 2.0815504093964896

Epoch: 5| Step: 6
Training loss: 2.423391819000244
Validation loss: 2.0748015691836676

Epoch: 5| Step: 7
Training loss: 1.7586129903793335
Validation loss: 2.0892593612273536

Epoch: 5| Step: 8
Training loss: 2.438734531402588
Validation loss: 2.082661971449852

Epoch: 5| Step: 9
Training loss: 1.9347209930419922
Validation loss: 2.087332839767138

Epoch: 5| Step: 10
Training loss: 2.085556745529175
Validation loss: 2.0888329644997916

Epoch: 5| Step: 11
Training loss: 1.5875332355499268
Validation loss: 2.0976144472757974

Epoch: 179| Step: 0
Training loss: 2.0330615043640137
Validation loss: 2.097028687596321

Epoch: 5| Step: 1
Training loss: 1.5610878467559814
Validation loss: 2.0937493294477463

Epoch: 5| Step: 2
Training loss: 2.0745508670806885
Validation loss: 2.1048623075087867

Epoch: 5| Step: 3
Training loss: 2.5086560249328613
Validation loss: 2.1155662834644318

Epoch: 5| Step: 4
Training loss: 1.9901468753814697
Validation loss: 2.1276832471291223

Epoch: 5| Step: 5
Training loss: 2.1295084953308105
Validation loss: 2.0980475495258966

Epoch: 5| Step: 6
Training loss: 2.1185717582702637
Validation loss: 2.1016019533077874

Epoch: 5| Step: 7
Training loss: 1.9784618616104126
Validation loss: 2.1031992932160697

Epoch: 5| Step: 8
Training loss: 2.354857921600342
Validation loss: 2.086019739508629

Epoch: 5| Step: 9
Training loss: 2.3166117668151855
Validation loss: 2.083865980307261

Epoch: 5| Step: 10
Training loss: 1.3543968200683594
Validation loss: 2.0728843410809836

Epoch: 5| Step: 11
Training loss: 2.4151806831359863
Validation loss: 2.0592760195334754

Epoch: 180| Step: 0
Training loss: 2.0594825744628906
Validation loss: 2.0619302739699683

Epoch: 5| Step: 1
Training loss: 1.8807613849639893
Validation loss: 2.0580311318238578

Epoch: 5| Step: 2
Training loss: 1.9180183410644531
Validation loss: 2.06132780512174

Epoch: 5| Step: 3
Training loss: 2.0226049423217773
Validation loss: 2.060345490773519

Epoch: 5| Step: 4
Training loss: 2.517711877822876
Validation loss: 2.053168868025144

Epoch: 5| Step: 5
Training loss: 1.6107702255249023
Validation loss: 2.0526418735583625

Epoch: 5| Step: 6
Training loss: 2.3846042156219482
Validation loss: 2.0499068846305213

Epoch: 5| Step: 7
Training loss: 2.4710655212402344
Validation loss: 2.057813376188278

Epoch: 5| Step: 8
Training loss: 1.9296633005142212
Validation loss: 2.0592581182718277

Epoch: 5| Step: 9
Training loss: 2.0645909309387207
Validation loss: 2.060601601998011

Epoch: 5| Step: 10
Training loss: 1.7762343883514404
Validation loss: 2.0660898139079413

Epoch: 5| Step: 11
Training loss: 2.0413384437561035
Validation loss: 2.083858792980512

Epoch: 181| Step: 0
Training loss: 2.5291225910186768
Validation loss: 2.0851717243591943

Epoch: 5| Step: 1
Training loss: 1.4565832614898682
Validation loss: 2.093049024542173

Epoch: 5| Step: 2
Training loss: 2.0562996864318848
Validation loss: 2.0958934972683587

Epoch: 5| Step: 3
Training loss: 1.7701385021209717
Validation loss: 2.0954716950654984

Epoch: 5| Step: 4
Training loss: 2.034571886062622
Validation loss: 2.0992249250411987

Epoch: 5| Step: 5
Training loss: 2.0379910469055176
Validation loss: 2.105604792634646

Epoch: 5| Step: 6
Training loss: 2.2150583267211914
Validation loss: 2.100954075654348

Epoch: 5| Step: 7
Training loss: 1.8194541931152344
Validation loss: 2.117890606323878

Epoch: 5| Step: 8
Training loss: 2.109743356704712
Validation loss: 2.103795737028122

Epoch: 5| Step: 9
Training loss: 2.33848237991333
Validation loss: 2.0871071070432663

Epoch: 5| Step: 10
Training loss: 1.997804045677185
Validation loss: 2.100605974594752

Epoch: 5| Step: 11
Training loss: 2.029806613922119
Validation loss: 2.1042157113552094

Epoch: 182| Step: 0
Training loss: 1.7914661169052124
Validation loss: 2.1008796840906143

Epoch: 5| Step: 1
Training loss: 2.051048994064331
Validation loss: 2.0906710823376975

Epoch: 5| Step: 2
Training loss: 1.887976050376892
Validation loss: 2.0845458010832467

Epoch: 5| Step: 3
Training loss: 2.069157361984253
Validation loss: 2.073441276947657

Epoch: 5| Step: 4
Training loss: 1.785430908203125
Validation loss: 2.081635276476542

Epoch: 5| Step: 5
Training loss: 1.9882169961929321
Validation loss: 2.061349868774414

Epoch: 5| Step: 6
Training loss: 2.5371336936950684
Validation loss: 2.063333367307981

Epoch: 5| Step: 7
Training loss: 1.7074317932128906
Validation loss: 2.0632642259200416

Epoch: 5| Step: 8
Training loss: 2.3671956062316895
Validation loss: 2.0758406668901443

Epoch: 5| Step: 9
Training loss: 2.136845827102661
Validation loss: 2.076118975877762

Epoch: 5| Step: 10
Training loss: 1.6960914134979248
Validation loss: 2.0844088395436606

Epoch: 5| Step: 11
Training loss: 2.1197760105133057
Validation loss: 2.075684408346812

Epoch: 183| Step: 0
Training loss: 1.6193269491195679
Validation loss: 2.0844934235016503

Epoch: 5| Step: 1
Training loss: 2.0898776054382324
Validation loss: 2.088909844557444

Epoch: 5| Step: 2
Training loss: 1.8435615301132202
Validation loss: 2.0825976530710855

Epoch: 5| Step: 3
Training loss: 2.1574244499206543
Validation loss: 2.0861287663380303

Epoch: 5| Step: 4
Training loss: 2.1190345287323
Validation loss: 2.0811353772878647

Epoch: 5| Step: 5
Training loss: 1.537376046180725
Validation loss: 2.083834936221441

Epoch: 5| Step: 6
Training loss: 2.3444759845733643
Validation loss: 2.0894822776317596

Epoch: 5| Step: 7
Training loss: 1.635263204574585
Validation loss: 2.0740142365296683

Epoch: 5| Step: 8
Training loss: 2.6730127334594727
Validation loss: 2.076066017150879

Epoch: 5| Step: 9
Training loss: 2.0241434574127197
Validation loss: 2.0734239568312964

Epoch: 5| Step: 10
Training loss: 1.820439100265503
Validation loss: 2.07541257639726

Epoch: 5| Step: 11
Training loss: 2.3734071254730225
Validation loss: 2.0731505006551743

Epoch: 184| Step: 0
Training loss: 1.4504919052124023
Validation loss: 2.06847474972407

Epoch: 5| Step: 1
Training loss: 1.709381103515625
Validation loss: 2.065378561615944

Epoch: 5| Step: 2
Training loss: 2.4615864753723145
Validation loss: 2.0689999212821326

Epoch: 5| Step: 3
Training loss: 2.2529311180114746
Validation loss: 2.063239569465319

Epoch: 5| Step: 4
Training loss: 1.9496097564697266
Validation loss: 2.0778907040754953

Epoch: 5| Step: 5
Training loss: 2.7280311584472656
Validation loss: 2.078882267077764

Epoch: 5| Step: 6
Training loss: 1.9222255945205688
Validation loss: 2.0779530654350915

Epoch: 5| Step: 7
Training loss: 1.785287618637085
Validation loss: 2.0784971515337625

Epoch: 5| Step: 8
Training loss: 1.6769577264785767
Validation loss: 2.0828378200531006

Epoch: 5| Step: 9
Training loss: 1.836169958114624
Validation loss: 2.0806617190440497

Epoch: 5| Step: 10
Training loss: 2.0793423652648926
Validation loss: 2.0904119362433753

Epoch: 5| Step: 11
Training loss: 2.91371488571167
Validation loss: 2.0847866038481393

Epoch: 185| Step: 0
Training loss: 1.7644493579864502
Validation loss: 2.078138142824173

Epoch: 5| Step: 1
Training loss: 1.680719017982483
Validation loss: 2.0948579063018165

Epoch: 5| Step: 2
Training loss: 2.0714643001556396
Validation loss: 2.0922075460354486

Epoch: 5| Step: 3
Training loss: 1.8886048793792725
Validation loss: 2.0901630918184915

Epoch: 5| Step: 4
Training loss: 2.634352922439575
Validation loss: 2.072090655565262

Epoch: 5| Step: 5
Training loss: 2.2988617420196533
Validation loss: 2.0866770992676416

Epoch: 5| Step: 6
Training loss: 1.3028485774993896
Validation loss: 2.078131745258967

Epoch: 5| Step: 7
Training loss: 1.9579055309295654
Validation loss: 2.0832850436369577

Epoch: 5| Step: 8
Training loss: 1.8157844543457031
Validation loss: 2.0736319621404014

Epoch: 5| Step: 9
Training loss: 2.046938896179199
Validation loss: 2.07340440650781

Epoch: 5| Step: 10
Training loss: 2.327148914337158
Validation loss: 2.0726112723350525

Epoch: 5| Step: 11
Training loss: 1.7698856592178345
Validation loss: 2.072132339080175

Epoch: 186| Step: 0
Training loss: 1.9162147045135498
Validation loss: 2.0628484090169272

Epoch: 5| Step: 1
Training loss: 2.0075912475585938
Validation loss: 2.0556873629490533

Epoch: 5| Step: 2
Training loss: 1.6434564590454102
Validation loss: 2.051927755276362

Epoch: 5| Step: 3
Training loss: 2.034668445587158
Validation loss: 2.0520128856102624

Epoch: 5| Step: 4
Training loss: 2.665748119354248
Validation loss: 2.0564680844545364

Epoch: 5| Step: 5
Training loss: 2.1708476543426514
Validation loss: 2.049403354525566

Epoch: 5| Step: 6
Training loss: 2.4749691486358643
Validation loss: 2.060173516472181

Epoch: 5| Step: 7
Training loss: 1.8655273914337158
Validation loss: 2.0589245160420737

Epoch: 5| Step: 8
Training loss: 1.6734501123428345
Validation loss: 2.0490740835666656

Epoch: 5| Step: 9
Training loss: 1.960209846496582
Validation loss: 2.0510005156199136

Epoch: 5| Step: 10
Training loss: 1.9667991399765015
Validation loss: 2.055368199944496

Epoch: 5| Step: 11
Training loss: 2.8338184356689453
Validation loss: 2.060350547234217

Epoch: 187| Step: 0
Training loss: 1.7253963947296143
Validation loss: 2.0507619033257165

Epoch: 5| Step: 1
Training loss: 2.3105826377868652
Validation loss: 2.0599648108085

Epoch: 5| Step: 2
Training loss: 2.2776906490325928
Validation loss: 2.0594977686802545

Epoch: 5| Step: 3
Training loss: 1.4827110767364502
Validation loss: 2.065658320983251

Epoch: 5| Step: 4
Training loss: 2.0642237663269043
Validation loss: 2.068958063920339

Epoch: 5| Step: 5
Training loss: 2.0889365673065186
Validation loss: 2.076893463730812

Epoch: 5| Step: 6
Training loss: 1.6446573734283447
Validation loss: 2.0832936267058053

Epoch: 5| Step: 7
Training loss: 1.8476543426513672
Validation loss: 2.0924390256404877

Epoch: 5| Step: 8
Training loss: 1.612176537513733
Validation loss: 2.0855414271354675

Epoch: 5| Step: 9
Training loss: 2.943974018096924
Validation loss: 2.0959545870622

Epoch: 5| Step: 10
Training loss: 1.8315871953964233
Validation loss: 2.0759080797433853

Epoch: 5| Step: 11
Training loss: 3.1303224563598633
Validation loss: 2.0741388499736786

Epoch: 188| Step: 0
Training loss: 2.0043606758117676
Validation loss: 2.0722656498352685

Epoch: 5| Step: 1
Training loss: 1.970102310180664
Validation loss: 2.068843444188436

Epoch: 5| Step: 2
Training loss: 1.4337924718856812
Validation loss: 2.0727841556072235

Epoch: 5| Step: 3
Training loss: 2.070065975189209
Validation loss: 2.059357980887095

Epoch: 5| Step: 4
Training loss: 2.063764810562134
Validation loss: 2.065670763452848

Epoch: 5| Step: 5
Training loss: 2.366328716278076
Validation loss: 2.064233566323916

Epoch: 5| Step: 6
Training loss: 1.7633155584335327
Validation loss: 2.069461072484652

Epoch: 5| Step: 7
Training loss: 1.9932548999786377
Validation loss: 2.074772596359253

Epoch: 5| Step: 8
Training loss: 2.3775415420532227
Validation loss: 2.086408024032911

Epoch: 5| Step: 9
Training loss: 1.5862928628921509
Validation loss: 2.0790966699520745

Epoch: 5| Step: 10
Training loss: 2.385042667388916
Validation loss: 2.0776268939177194

Epoch: 5| Step: 11
Training loss: 2.0698304176330566
Validation loss: 2.0767538100481033

Epoch: 189| Step: 0
Training loss: 1.5495051145553589
Validation loss: 2.0977256695429483

Epoch: 5| Step: 1
Training loss: 2.3382232189178467
Validation loss: 2.0902002453804016

Epoch: 5| Step: 2
Training loss: 2.055427074432373
Validation loss: 2.0862560868263245

Epoch: 5| Step: 3
Training loss: 1.7756164073944092
Validation loss: 2.083984007438024

Epoch: 5| Step: 4
Training loss: 2.2961173057556152
Validation loss: 2.0598835349082947

Epoch: 5| Step: 5
Training loss: 2.065842866897583
Validation loss: 2.053981681664785

Epoch: 5| Step: 6
Training loss: 1.5379359722137451
Validation loss: 2.047955413659414

Epoch: 5| Step: 7
Training loss: 2.4486489295959473
Validation loss: 2.0494114557902017

Epoch: 5| Step: 8
Training loss: 1.9330673217773438
Validation loss: 2.0521492759386697

Epoch: 5| Step: 9
Training loss: 1.7969852685928345
Validation loss: 2.0522991766532264

Epoch: 5| Step: 10
Training loss: 2.0328214168548584
Validation loss: 2.0541213005781174

Epoch: 5| Step: 11
Training loss: 2.5866830348968506
Validation loss: 2.0596664448579154

Epoch: 190| Step: 0
Training loss: 2.195160388946533
Validation loss: 2.0482688695192337

Epoch: 5| Step: 1
Training loss: 1.5641072988510132
Validation loss: 2.0611043572425842

Epoch: 5| Step: 2
Training loss: 1.7444343566894531
Validation loss: 2.0538075218598046

Epoch: 5| Step: 3
Training loss: 1.8105144500732422
Validation loss: 2.0534021804730096

Epoch: 5| Step: 4
Training loss: 2.851931095123291
Validation loss: 2.068956901629766

Epoch: 5| Step: 5
Training loss: 2.7841796875
Validation loss: 2.077527716755867

Epoch: 5| Step: 6
Training loss: 1.7607734203338623
Validation loss: 2.0831682880719504

Epoch: 5| Step: 7
Training loss: 1.31382155418396
Validation loss: 2.091227541367213

Epoch: 5| Step: 8
Training loss: 2.138245105743408
Validation loss: 2.0934745371341705

Epoch: 5| Step: 9
Training loss: 1.4694511890411377
Validation loss: 2.0870124797026315

Epoch: 5| Step: 10
Training loss: 2.095111608505249
Validation loss: 2.0907114446163177

Epoch: 5| Step: 11
Training loss: 2.681633949279785
Validation loss: 2.086680601040522

Epoch: 191| Step: 0
Training loss: 1.7746899127960205
Validation loss: 2.0877695629994073

Epoch: 5| Step: 1
Training loss: 2.2096076011657715
Validation loss: 2.059286748369535

Epoch: 5| Step: 2
Training loss: 2.2461748123168945
Validation loss: 2.062415877978007

Epoch: 5| Step: 3
Training loss: 1.7981150150299072
Validation loss: 2.0583379914363227

Epoch: 5| Step: 4
Training loss: 2.3769829273223877
Validation loss: 2.057043100396792

Epoch: 5| Step: 5
Training loss: 1.832198143005371
Validation loss: 2.0583585798740387

Epoch: 5| Step: 6
Training loss: 1.990805983543396
Validation loss: 2.0641130159298577

Epoch: 5| Step: 7
Training loss: 2.368192672729492
Validation loss: 2.0641930103302

Epoch: 5| Step: 8
Training loss: 1.8145908117294312
Validation loss: 2.06376584370931

Epoch: 5| Step: 9
Training loss: 2.367265224456787
Validation loss: 2.061356469988823

Epoch: 5| Step: 10
Training loss: 1.745880126953125
Validation loss: 2.0568025608857474

Epoch: 5| Step: 11
Training loss: 2.628533363342285
Validation loss: 2.057360624273618

Epoch: 192| Step: 0
Training loss: 2.1039700508117676
Validation loss: 2.065250645081202

Epoch: 5| Step: 1
Training loss: 2.1204493045806885
Validation loss: 2.0591213007767997

Epoch: 5| Step: 2
Training loss: 2.1236672401428223
Validation loss: 2.0747246891260147

Epoch: 5| Step: 3
Training loss: 2.046966552734375
Validation loss: 2.0848539769649506

Epoch: 5| Step: 4
Training loss: 1.7580831050872803
Validation loss: 2.0884034484624863

Epoch: 5| Step: 5
Training loss: 2.048370122909546
Validation loss: 2.0878249605496726

Epoch: 5| Step: 6
Training loss: 2.0388376712799072
Validation loss: 2.095431754986445

Epoch: 5| Step: 7
Training loss: 1.6512773036956787
Validation loss: 2.1009286791086197

Epoch: 5| Step: 8
Training loss: 2.5215671062469482
Validation loss: 2.1087548484404883

Epoch: 5| Step: 9
Training loss: 1.825514554977417
Validation loss: 2.1194068094094596

Epoch: 5| Step: 10
Training loss: 1.7674837112426758
Validation loss: 2.1293307741483054

Epoch: 5| Step: 11
Training loss: 2.2354254722595215
Validation loss: 2.1098527709643045

Epoch: 193| Step: 0
Training loss: 1.8692766427993774
Validation loss: 2.1058005591233573

Epoch: 5| Step: 1
Training loss: 1.8701164722442627
Validation loss: 2.1009912192821503

Epoch: 5| Step: 2
Training loss: 1.8864272832870483
Validation loss: 2.094212700923284

Epoch: 5| Step: 3
Training loss: 1.662294626235962
Validation loss: 2.1066258549690247

Epoch: 5| Step: 4
Training loss: 2.3719067573547363
Validation loss: 2.095777968565623

Epoch: 5| Step: 5
Training loss: 2.2192256450653076
Validation loss: 2.0870935221513114

Epoch: 5| Step: 6
Training loss: 2.31001877784729
Validation loss: 2.0936715453863144

Epoch: 5| Step: 7
Training loss: 0.9090606570243835
Validation loss: 2.078437919418017

Epoch: 5| Step: 8
Training loss: 2.346980333328247
Validation loss: 2.073491175969442

Epoch: 5| Step: 9
Training loss: 2.010733127593994
Validation loss: 2.080797240138054

Epoch: 5| Step: 10
Training loss: 2.1657917499542236
Validation loss: 2.069481780131658

Epoch: 5| Step: 11
Training loss: 2.8114445209503174
Validation loss: 2.085089777906736

Epoch: 194| Step: 0
Training loss: 2.0134236812591553
Validation loss: 2.0914847751458487

Epoch: 5| Step: 1
Training loss: 1.651882529258728
Validation loss: 2.10077857474486

Epoch: 5| Step: 2
Training loss: 2.0784382820129395
Validation loss: 2.1080073714256287

Epoch: 5| Step: 3
Training loss: 2.0028340816497803
Validation loss: 2.102273106575012

Epoch: 5| Step: 4
Training loss: 1.5350747108459473
Validation loss: 2.103329673409462

Epoch: 5| Step: 5
Training loss: 2.05171275138855
Validation loss: 2.1024186561505

Epoch: 5| Step: 6
Training loss: 2.5676779747009277
Validation loss: 2.1066471139589944

Epoch: 5| Step: 7
Training loss: 1.8458826541900635
Validation loss: 2.1056943386793137

Epoch: 5| Step: 8
Training loss: 2.3160593509674072
Validation loss: 2.0888334264357886

Epoch: 5| Step: 9
Training loss: 1.6400495767593384
Validation loss: 2.099222665031751

Epoch: 5| Step: 10
Training loss: 2.2420334815979004
Validation loss: 2.0924624452988305

Epoch: 5| Step: 11
Training loss: 0.8851933479309082
Validation loss: 2.0865042209625244

Epoch: 195| Step: 0
Training loss: 2.1319570541381836
Validation loss: 2.0794381300608316

Epoch: 5| Step: 1
Training loss: 1.7791767120361328
Validation loss: 2.068832571307818

Epoch: 5| Step: 2
Training loss: 2.0057663917541504
Validation loss: 2.086414118607839

Epoch: 5| Step: 3
Training loss: 2.5960116386413574
Validation loss: 2.0743475556373596

Epoch: 5| Step: 4
Training loss: 1.5460447072982788
Validation loss: 2.068727597594261

Epoch: 5| Step: 5
Training loss: 2.0991835594177246
Validation loss: 2.061935489376386

Epoch: 5| Step: 6
Training loss: 2.183548927307129
Validation loss: 2.084211771686872

Epoch: 5| Step: 7
Training loss: 2.0587639808654785
Validation loss: 2.071499288082123

Epoch: 5| Step: 8
Training loss: 1.8665109872817993
Validation loss: 2.068356583515803

Epoch: 5| Step: 9
Training loss: 1.6515343189239502
Validation loss: 2.081157917777697

Epoch: 5| Step: 10
Training loss: 1.9807965755462646
Validation loss: 2.084598476688067

Epoch: 5| Step: 11
Training loss: 1.6174418926239014
Validation loss: 2.0912460486094155

Epoch: 196| Step: 0
Training loss: 2.4968972206115723
Validation loss: 2.0994063864151635

Epoch: 5| Step: 1
Training loss: 1.8832679986953735
Validation loss: 2.108611593643824

Epoch: 5| Step: 2
Training loss: 1.8805999755859375
Validation loss: 2.1020892560482025

Epoch: 5| Step: 3
Training loss: 1.4377917051315308
Validation loss: 2.104608674844106

Epoch: 5| Step: 4
Training loss: 2.661102294921875
Validation loss: 2.113948126633962

Epoch: 5| Step: 5
Training loss: 1.887110948562622
Validation loss: 2.102901061375936

Epoch: 5| Step: 6
Training loss: 2.1226184368133545
Validation loss: 2.097181722521782

Epoch: 5| Step: 7
Training loss: 1.6043701171875
Validation loss: 2.1023546208937964

Epoch: 5| Step: 8
Training loss: 1.9350477457046509
Validation loss: 2.097075432538986

Epoch: 5| Step: 9
Training loss: 1.7857805490493774
Validation loss: 2.0899683137734733

Epoch: 5| Step: 10
Training loss: 2.144498825073242
Validation loss: 2.072778284549713

Epoch: 5| Step: 11
Training loss: 2.72353458404541
Validation loss: 2.0695178161064782

Epoch: 197| Step: 0
Training loss: 2.4923548698425293
Validation loss: 2.0748515725135803

Epoch: 5| Step: 1
Training loss: 1.9997107982635498
Validation loss: 2.056372086207072

Epoch: 5| Step: 2
Training loss: 2.001594066619873
Validation loss: 2.071209798256556

Epoch: 5| Step: 3
Training loss: 1.9979922771453857
Validation loss: 2.064674804608027

Epoch: 5| Step: 4
Training loss: 1.5978002548217773
Validation loss: 2.0604561467965445

Epoch: 5| Step: 5
Training loss: 2.022890329360962
Validation loss: 2.0653805832068124

Epoch: 5| Step: 6
Training loss: 2.1894214153289795
Validation loss: 2.061643977959951

Epoch: 5| Step: 7
Training loss: 2.2595832347869873
Validation loss: 2.063847636183103

Epoch: 5| Step: 8
Training loss: 1.8791685104370117
Validation loss: 2.0544865975777307

Epoch: 5| Step: 9
Training loss: 2.0283477306365967
Validation loss: 2.058013300100962

Epoch: 5| Step: 10
Training loss: 2.070190906524658
Validation loss: 2.068269227941831

Epoch: 5| Step: 11
Training loss: 2.3460023403167725
Validation loss: 2.073312217990557

Epoch: 198| Step: 0
Training loss: 2.1361327171325684
Validation loss: 2.0566044797499976

Epoch: 5| Step: 1
Training loss: 2.1216373443603516
Validation loss: 2.0609906713167825

Epoch: 5| Step: 2
Training loss: 2.4781453609466553
Validation loss: 2.062059963742892

Epoch: 5| Step: 3
Training loss: 2.0777249336242676
Validation loss: 2.06448765595754

Epoch: 5| Step: 4
Training loss: 1.6232306957244873
Validation loss: 2.087328314781189

Epoch: 5| Step: 5
Training loss: 1.9869039058685303
Validation loss: 2.0731261372566223

Epoch: 5| Step: 6
Training loss: 1.9175872802734375
Validation loss: 2.0813125669956207

Epoch: 5| Step: 7
Training loss: 1.5359739065170288
Validation loss: 2.0651958088080087

Epoch: 5| Step: 8
Training loss: 1.4884495735168457
Validation loss: 2.0559017211198807

Epoch: 5| Step: 9
Training loss: 2.5586352348327637
Validation loss: 2.0667948375145593

Epoch: 5| Step: 10
Training loss: 2.3121631145477295
Validation loss: 2.0722389618555703

Epoch: 5| Step: 11
Training loss: 1.5171178579330444
Validation loss: 2.0867884755134583

Epoch: 199| Step: 0
Training loss: 1.5626565217971802
Validation loss: 2.073746139804522

Epoch: 5| Step: 1
Training loss: 1.8994581699371338
Validation loss: 2.069132720430692

Epoch: 5| Step: 2
Training loss: 2.2039103507995605
Validation loss: 2.058972199757894

Epoch: 5| Step: 3
Training loss: 1.9317772388458252
Validation loss: 2.0682630290587745

Epoch: 5| Step: 4
Training loss: 2.4854962825775146
Validation loss: 2.0697788298130035

Epoch: 5| Step: 5
Training loss: 1.9557491540908813
Validation loss: 2.083947092294693

Epoch: 5| Step: 6
Training loss: 2.0977046489715576
Validation loss: 2.076665242513021

Epoch: 5| Step: 7
Training loss: 2.254209041595459
Validation loss: 2.0743916680415473

Epoch: 5| Step: 8
Training loss: 1.9998966455459595
Validation loss: 2.0739105492830276

Epoch: 5| Step: 9
Training loss: 2.135413646697998
Validation loss: 2.0781856874624887

Epoch: 5| Step: 10
Training loss: 1.9293485879898071
Validation loss: 2.0678407102823257

Epoch: 5| Step: 11
Training loss: 2.1557207107543945
Validation loss: 2.0745691706736884

Epoch: 200| Step: 0
Training loss: 1.8803659677505493
Validation loss: 2.078926424185435

Epoch: 5| Step: 1
Training loss: 2.41041898727417
Validation loss: 2.098255679011345

Epoch: 5| Step: 2
Training loss: 2.295073986053467
Validation loss: 2.0923197319110236

Epoch: 5| Step: 3
Training loss: 2.1455800533294678
Validation loss: 2.104809323946635

Epoch: 5| Step: 4
Training loss: 1.792629599571228
Validation loss: 2.1081430912017822

Epoch: 5| Step: 5
Training loss: 1.6179298162460327
Validation loss: 2.1072514851888022

Epoch: 5| Step: 6
Training loss: 1.6084213256835938
Validation loss: 2.096755862236023

Epoch: 5| Step: 7
Training loss: 2.006378650665283
Validation loss: 2.1168378392855325

Epoch: 5| Step: 8
Training loss: 1.6734880208969116
Validation loss: 2.1036862333615622

Epoch: 5| Step: 9
Training loss: 2.490217924118042
Validation loss: 2.0870878398418427

Epoch: 5| Step: 10
Training loss: 1.9889171123504639
Validation loss: 2.0849103778600693

Epoch: 5| Step: 11
Training loss: 2.7321090698242188
Validation loss: 2.0662001222372055

Epoch: 201| Step: 0
Training loss: 1.5373328924179077
Validation loss: 2.0714299976825714

Epoch: 5| Step: 1
Training loss: 2.238605499267578
Validation loss: 2.080268606543541

Epoch: 5| Step: 2
Training loss: 2.4899814128875732
Validation loss: 2.069298267364502

Epoch: 5| Step: 3
Training loss: 1.6986262798309326
Validation loss: 2.072479863961538

Epoch: 5| Step: 4
Training loss: 2.089783191680908
Validation loss: 2.0702474315961203

Epoch: 5| Step: 5
Training loss: 1.5747525691986084
Validation loss: 2.064901888370514

Epoch: 5| Step: 6
Training loss: 2.1084182262420654
Validation loss: 2.064262638489405

Epoch: 5| Step: 7
Training loss: 1.998598337173462
Validation loss: 2.058406616250674

Epoch: 5| Step: 8
Training loss: 2.248993396759033
Validation loss: 2.068549012144407

Epoch: 5| Step: 9
Training loss: 2.0344300270080566
Validation loss: 2.0688137064377465

Epoch: 5| Step: 10
Training loss: 1.9228605031967163
Validation loss: 2.0687728971242905

Epoch: 5| Step: 11
Training loss: 2.0672802925109863
Validation loss: 2.083988775809606

Epoch: 202| Step: 0
Training loss: 1.700331449508667
Validation loss: 2.071990375717481

Epoch: 5| Step: 1
Training loss: 1.8227564096450806
Validation loss: 2.064023161927859

Epoch: 5| Step: 2
Training loss: 2.228693723678589
Validation loss: 2.072445293267568

Epoch: 5| Step: 3
Training loss: 2.252923011779785
Validation loss: 2.081490228573481

Epoch: 5| Step: 4
Training loss: 2.2297496795654297
Validation loss: 2.0723573366800943

Epoch: 5| Step: 5
Training loss: 1.5438158512115479
Validation loss: 2.0815084079901376

Epoch: 5| Step: 6
Training loss: 2.256089448928833
Validation loss: 2.1080814550320306

Epoch: 5| Step: 7
Training loss: 1.8113048076629639
Validation loss: 2.086106469233831

Epoch: 5| Step: 8
Training loss: 2.1116690635681152
Validation loss: 2.0974687387545905

Epoch: 5| Step: 9
Training loss: 2.0040645599365234
Validation loss: 2.1020953257878623

Epoch: 5| Step: 10
Training loss: 1.728798270225525
Validation loss: 2.114037871360779

Epoch: 5| Step: 11
Training loss: 2.246623992919922
Validation loss: 2.117458383242289

Epoch: 203| Step: 0
Training loss: 2.0273237228393555
Validation loss: 2.108594169219335

Epoch: 5| Step: 1
Training loss: 1.736564040184021
Validation loss: 2.102460578083992

Epoch: 5| Step: 2
Training loss: 1.5886554718017578
Validation loss: 2.1033809880415597

Epoch: 5| Step: 3
Training loss: 2.169966459274292
Validation loss: 2.096882993976275

Epoch: 5| Step: 4
Training loss: 1.9230722188949585
Validation loss: 2.0992915431658425

Epoch: 5| Step: 5
Training loss: 1.9895159006118774
Validation loss: 2.092254022757212

Epoch: 5| Step: 6
Training loss: 2.110327959060669
Validation loss: 2.099348043402036

Epoch: 5| Step: 7
Training loss: 2.3921074867248535
Validation loss: 2.0998307317495346

Epoch: 5| Step: 8
Training loss: 1.7673635482788086
Validation loss: 2.09453321993351

Epoch: 5| Step: 9
Training loss: 1.7475208044052124
Validation loss: 2.0814358393351235

Epoch: 5| Step: 10
Training loss: 2.324674606323242
Validation loss: 2.1057880173126855

Epoch: 5| Step: 11
Training loss: 1.440111517906189
Validation loss: 2.104581226905187

Epoch: 204| Step: 0
Training loss: 1.8447002172470093
Validation loss: 2.102524926265081

Epoch: 5| Step: 1
Training loss: 2.032252788543701
Validation loss: 2.117127070824305

Epoch: 5| Step: 2
Training loss: 2.798646926879883
Validation loss: 2.110414430499077

Epoch: 5| Step: 3
Training loss: 1.8549461364746094
Validation loss: 2.105126773317655

Epoch: 5| Step: 4
Training loss: 2.482194185256958
Validation loss: 2.1093295514583588

Epoch: 5| Step: 5
Training loss: 2.198390245437622
Validation loss: 2.0815131068229675

Epoch: 5| Step: 6
Training loss: 1.9395259618759155
Validation loss: 2.088461478551229

Epoch: 5| Step: 7
Training loss: 1.9576553106307983
Validation loss: 2.0784795184930167

Epoch: 5| Step: 8
Training loss: 1.4653433561325073
Validation loss: 2.0867568999528885

Epoch: 5| Step: 9
Training loss: 1.4213978052139282
Validation loss: 2.0836956004301705

Epoch: 5| Step: 10
Training loss: 1.67538583278656
Validation loss: 2.0900201201438904

Epoch: 5| Step: 11
Training loss: 1.6679482460021973
Validation loss: 2.0879067480564117

Epoch: 205| Step: 0
Training loss: 1.7945029735565186
Validation loss: 2.0990612457195916

Epoch: 5| Step: 1
Training loss: 2.017646551132202
Validation loss: 2.0969572315613427

Epoch: 5| Step: 2
Training loss: 1.9552522897720337
Validation loss: 2.1116215934356055

Epoch: 5| Step: 3
Training loss: 2.170452356338501
Validation loss: 2.105324402451515

Epoch: 5| Step: 4
Training loss: 1.6446549892425537
Validation loss: 2.1228998601436615

Epoch: 5| Step: 5
Training loss: 1.6382694244384766
Validation loss: 2.1149827539920807

Epoch: 5| Step: 6
Training loss: 2.4198477268218994
Validation loss: 2.127256984512011

Epoch: 5| Step: 7
Training loss: 2.0850682258605957
Validation loss: 2.102792759736379

Epoch: 5| Step: 8
Training loss: 1.8909156322479248
Validation loss: 2.107683559258779

Epoch: 5| Step: 9
Training loss: 1.5332705974578857
Validation loss: 2.1014143178860345

Epoch: 5| Step: 10
Training loss: 2.164477825164795
Validation loss: 2.0851370841264725

Epoch: 5| Step: 11
Training loss: 4.2975897789001465
Validation loss: 2.084743097424507

Epoch: 206| Step: 0
Training loss: 1.627807855606079
Validation loss: 2.0785381694634757

Epoch: 5| Step: 1
Training loss: 2.220550060272217
Validation loss: 2.084697504838308

Epoch: 5| Step: 2
Training loss: 1.848595380783081
Validation loss: 2.089025914669037

Epoch: 5| Step: 3
Training loss: 2.028860092163086
Validation loss: 2.084840774536133

Epoch: 5| Step: 4
Training loss: 2.0878090858459473
Validation loss: 2.0762350956598916

Epoch: 5| Step: 5
Training loss: 1.8264697790145874
Validation loss: 2.079378366470337

Epoch: 5| Step: 6
Training loss: 1.9295215606689453
Validation loss: 2.075014501810074

Epoch: 5| Step: 7
Training loss: 2.125763416290283
Validation loss: 2.0781241953372955

Epoch: 5| Step: 8
Training loss: 2.464951276779175
Validation loss: 2.079757735133171

Epoch: 5| Step: 9
Training loss: 2.1361024379730225
Validation loss: 2.077981323003769

Epoch: 5| Step: 10
Training loss: 1.7294706106185913
Validation loss: 2.0755925873915353

Epoch: 5| Step: 11
Training loss: 1.3421460390090942
Validation loss: 2.0904119511445365

Epoch: 207| Step: 0
Training loss: 2.039555788040161
Validation loss: 2.0879129568735757

Epoch: 5| Step: 1
Training loss: 2.2063827514648438
Validation loss: 2.0961967408657074

Epoch: 5| Step: 2
Training loss: 1.97685968875885
Validation loss: 2.096470276514689

Epoch: 5| Step: 3
Training loss: 2.52081036567688
Validation loss: 2.1058114618062973

Epoch: 5| Step: 4
Training loss: 1.6501951217651367
Validation loss: 2.1105002810557685

Epoch: 5| Step: 5
Training loss: 2.267618417739868
Validation loss: 2.1095965802669525

Epoch: 5| Step: 6
Training loss: 1.901846170425415
Validation loss: 2.0996271669864655

Epoch: 5| Step: 7
Training loss: 1.797899842262268
Validation loss: 2.1127500434716544

Epoch: 5| Step: 8
Training loss: 1.783601999282837
Validation loss: 2.094266956051191

Epoch: 5| Step: 9
Training loss: 1.681707739830017
Validation loss: 2.0918027609586716

Epoch: 5| Step: 10
Training loss: 1.8872807025909424
Validation loss: 2.0915161222219467

Epoch: 5| Step: 11
Training loss: 2.417811155319214
Validation loss: 2.089685241381327

Epoch: 208| Step: 0
Training loss: 1.8255386352539062
Validation loss: 2.091333955526352

Epoch: 5| Step: 1
Training loss: 1.9571613073349
Validation loss: 2.0725200225909552

Epoch: 5| Step: 2
Training loss: 1.7896525859832764
Validation loss: 2.089429130156835

Epoch: 5| Step: 3
Training loss: 2.4073173999786377
Validation loss: 2.080142358938853

Epoch: 5| Step: 4
Training loss: 1.1767382621765137
Validation loss: 2.085070843497912

Epoch: 5| Step: 5
Training loss: 1.9382884502410889
Validation loss: 2.0730693141619363

Epoch: 5| Step: 6
Training loss: 1.6971899271011353
Validation loss: 2.090535248319308

Epoch: 5| Step: 7
Training loss: 2.057734489440918
Validation loss: 2.0872227400541306

Epoch: 5| Step: 8
Training loss: 2.241687059402466
Validation loss: 2.0923498769601188

Epoch: 5| Step: 9
Training loss: 2.1179962158203125
Validation loss: 2.09351846575737

Epoch: 5| Step: 10
Training loss: 2.484898328781128
Validation loss: 2.1065785586833954

Epoch: 5| Step: 11
Training loss: 1.2345153093338013
Validation loss: 2.094218065341314

Epoch: 209| Step: 0
Training loss: 2.2877683639526367
Validation loss: 2.1088689863681793

Epoch: 5| Step: 1
Training loss: 1.8301585912704468
Validation loss: 2.0878482908010483

Epoch: 5| Step: 2
Training loss: 1.9412645101547241
Validation loss: 2.0930228531360626

Epoch: 5| Step: 3
Training loss: 2.3776211738586426
Validation loss: 2.0945986409982047

Epoch: 5| Step: 4
Training loss: 2.0055384635925293
Validation loss: 2.078098480900129

Epoch: 5| Step: 5
Training loss: 1.3864185810089111
Validation loss: 2.0922976036866507

Epoch: 5| Step: 6
Training loss: 1.5842828750610352
Validation loss: 2.084290380279223

Epoch: 5| Step: 7
Training loss: 1.850946068763733
Validation loss: 2.076101611057917

Epoch: 5| Step: 8
Training loss: 2.2017829418182373
Validation loss: 2.078966051340103

Epoch: 5| Step: 9
Training loss: 2.0258965492248535
Validation loss: 2.07674710949262

Epoch: 5| Step: 10
Training loss: 2.329817056655884
Validation loss: 2.0863092790047326

Epoch: 5| Step: 11
Training loss: 1.179883360862732
Validation loss: 2.0950084726015725

Epoch: 210| Step: 0
Training loss: 1.8720579147338867
Validation loss: 2.0927373319864273

Epoch: 5| Step: 1
Training loss: 2.1142513751983643
Validation loss: 2.0910265346368155

Epoch: 5| Step: 2
Training loss: 2.1795761585235596
Validation loss: 2.1083420515060425

Epoch: 5| Step: 3
Training loss: 1.9455833435058594
Validation loss: 2.11068332195282

Epoch: 5| Step: 4
Training loss: 1.6859651803970337
Validation loss: 2.1157118529081345

Epoch: 5| Step: 5
Training loss: 1.9236986637115479
Validation loss: 2.114113469918569

Epoch: 5| Step: 6
Training loss: 2.2009294033050537
Validation loss: 2.1164293438196182

Epoch: 5| Step: 7
Training loss: 2.0594286918640137
Validation loss: 2.1082304368416467

Epoch: 5| Step: 8
Training loss: 1.607783317565918
Validation loss: 2.106916159391403

Epoch: 5| Step: 9
Training loss: 2.015150308609009
Validation loss: 2.097372184197108

Epoch: 5| Step: 10
Training loss: 1.8185923099517822
Validation loss: 2.1065857311089835

Epoch: 5| Step: 11
Training loss: 2.367093086242676
Validation loss: 2.115467141071955

Epoch: 211| Step: 0
Training loss: 2.1186647415161133
Validation loss: 2.126090263326963

Epoch: 5| Step: 1
Training loss: 2.3241190910339355
Validation loss: 2.124733497699102

Epoch: 5| Step: 2
Training loss: 2.1190314292907715
Validation loss: 2.1188183277845383

Epoch: 5| Step: 3
Training loss: 1.9862823486328125
Validation loss: 2.1241538574298224

Epoch: 5| Step: 4
Training loss: 1.830182671546936
Validation loss: 2.132266173760096

Epoch: 5| Step: 5
Training loss: 2.2687172889709473
Validation loss: 2.113518089056015

Epoch: 5| Step: 6
Training loss: 1.8607349395751953
Validation loss: 2.1118028511603675

Epoch: 5| Step: 7
Training loss: 1.3606154918670654
Validation loss: 2.0970919529596963

Epoch: 5| Step: 8
Training loss: 2.0648562908172607
Validation loss: 2.0931138594945273

Epoch: 5| Step: 9
Training loss: 1.7354257106781006
Validation loss: 2.079970598220825

Epoch: 5| Step: 10
Training loss: 1.920125961303711
Validation loss: 2.076032817363739

Epoch: 5| Step: 11
Training loss: 2.2695326805114746
Validation loss: 2.0756525695323944

Epoch: 212| Step: 0
Training loss: 2.3163609504699707
Validation loss: 2.0737909028927484

Epoch: 5| Step: 1
Training loss: 1.5622552633285522
Validation loss: 2.0770260294278464

Epoch: 5| Step: 2
Training loss: 1.7983471155166626
Validation loss: 2.0765100518862405

Epoch: 5| Step: 3
Training loss: 2.1807446479797363
Validation loss: 2.080944245060285

Epoch: 5| Step: 4
Training loss: 1.7964296340942383
Validation loss: 2.0756810108820596

Epoch: 5| Step: 5
Training loss: 1.7951316833496094
Validation loss: 2.0885851830244064

Epoch: 5| Step: 6
Training loss: 2.212721109390259
Validation loss: 2.0963850071032843

Epoch: 5| Step: 7
Training loss: 2.0044102668762207
Validation loss: 2.0993816951910653

Epoch: 5| Step: 8
Training loss: 1.8839895725250244
Validation loss: 2.1304612855116525

Epoch: 5| Step: 9
Training loss: 2.445162773132324
Validation loss: 2.120205879211426

Epoch: 5| Step: 10
Training loss: 1.9200525283813477
Validation loss: 2.135299429297447

Epoch: 5| Step: 11
Training loss: 1.816774606704712
Validation loss: 2.137046068906784

Epoch: 213| Step: 0
Training loss: 1.9855209589004517
Validation loss: 2.129401753346125

Epoch: 5| Step: 1
Training loss: 2.0181429386138916
Validation loss: 2.118952304124832

Epoch: 5| Step: 2
Training loss: 2.2633044719696045
Validation loss: 2.1050564646720886

Epoch: 5| Step: 3
Training loss: 1.7083864212036133
Validation loss: 2.098971967895826

Epoch: 5| Step: 4
Training loss: 2.1181485652923584
Validation loss: 2.087078481912613

Epoch: 5| Step: 5
Training loss: 1.9469053745269775
Validation loss: 2.090975413719813

Epoch: 5| Step: 6
Training loss: 2.147502899169922
Validation loss: 2.097885474562645

Epoch: 5| Step: 7
Training loss: 2.3830318450927734
Validation loss: 2.088720584909121

Epoch: 5| Step: 8
Training loss: 1.657513976097107
Validation loss: 2.083807036280632

Epoch: 5| Step: 9
Training loss: 1.7592527866363525
Validation loss: 2.0955431361993155

Epoch: 5| Step: 10
Training loss: 1.8035976886749268
Validation loss: 2.0950661102930703

Epoch: 5| Step: 11
Training loss: 2.0479745864868164
Validation loss: 2.107296645641327

Epoch: 214| Step: 0
Training loss: 2.029496192932129
Validation loss: 2.093973865111669

Epoch: 5| Step: 1
Training loss: 1.9907268285751343
Validation loss: 2.0974815587202706

Epoch: 5| Step: 2
Training loss: 1.295668363571167
Validation loss: 2.0951541860898337

Epoch: 5| Step: 3
Training loss: 2.1862149238586426
Validation loss: 2.1005783677101135

Epoch: 5| Step: 4
Training loss: 1.8424888849258423
Validation loss: 2.0986320078372955

Epoch: 5| Step: 5
Training loss: 2.0622477531433105
Validation loss: 2.097861329714457

Epoch: 5| Step: 6
Training loss: 2.200063705444336
Validation loss: 2.1105849544207254

Epoch: 5| Step: 7
Training loss: 1.5277431011199951
Validation loss: 2.12134949862957

Epoch: 5| Step: 8
Training loss: 1.6100623607635498
Validation loss: 2.1109062135219574

Epoch: 5| Step: 9
Training loss: 2.204603433609009
Validation loss: 2.108807161450386

Epoch: 5| Step: 10
Training loss: 2.1970741748809814
Validation loss: 2.0955066035191217

Epoch: 5| Step: 11
Training loss: 3.7735393047332764
Validation loss: 2.1008900503317514

Epoch: 215| Step: 0
Training loss: 1.6957870721817017
Validation loss: 2.086808438102404

Epoch: 5| Step: 1
Training loss: 1.9487216472625732
Validation loss: 2.097256451845169

Epoch: 5| Step: 2
Training loss: 1.4811322689056396
Validation loss: 2.103162497282028

Epoch: 5| Step: 3
Training loss: 1.711647391319275
Validation loss: 2.108288273215294

Epoch: 5| Step: 4
Training loss: 2.1289520263671875
Validation loss: 2.0971637964248657

Epoch: 5| Step: 5
Training loss: 1.9029957056045532
Validation loss: 2.100986118117968

Epoch: 5| Step: 6
Training loss: 1.6369683742523193
Validation loss: 2.094778746366501

Epoch: 5| Step: 7
Training loss: 2.3980369567871094
Validation loss: 2.1026313106218972

Epoch: 5| Step: 8
Training loss: 1.757541298866272
Validation loss: 2.1058312008778253

Epoch: 5| Step: 9
Training loss: 2.1165459156036377
Validation loss: 2.099072188138962

Epoch: 5| Step: 10
Training loss: 2.4804491996765137
Validation loss: 2.107059513529142

Epoch: 5| Step: 11
Training loss: 2.441073417663574
Validation loss: 2.104434629281362

Epoch: 216| Step: 0
Training loss: 1.4420095682144165
Validation loss: 2.1148703346649804

Epoch: 5| Step: 1
Training loss: 1.784886360168457
Validation loss: 2.131061608592669

Epoch: 5| Step: 2
Training loss: 2.2973458766937256
Validation loss: 2.1626903414726257

Epoch: 5| Step: 3
Training loss: 1.6945483684539795
Validation loss: 2.150344322125117

Epoch: 5| Step: 4
Training loss: 1.7243903875350952
Validation loss: 2.1483571032683053

Epoch: 5| Step: 5
Training loss: 2.5234527587890625
Validation loss: 2.1395749350388846

Epoch: 5| Step: 6
Training loss: 2.018890142440796
Validation loss: 2.1390275359153748

Epoch: 5| Step: 7
Training loss: 2.183858871459961
Validation loss: 2.1145984729131064

Epoch: 5| Step: 8
Training loss: 2.0537540912628174
Validation loss: 2.098550498485565

Epoch: 5| Step: 9
Training loss: 2.0139565467834473
Validation loss: 2.1037642657756805

Epoch: 5| Step: 10
Training loss: 2.0005571842193604
Validation loss: 2.101846625407537

Epoch: 5| Step: 11
Training loss: 1.6236222982406616
Validation loss: 2.084894875685374

Epoch: 217| Step: 0
Training loss: 1.9697574377059937
Validation loss: 2.0790254871050515

Epoch: 5| Step: 1
Training loss: 1.9237394332885742
Validation loss: 2.084325904647509

Epoch: 5| Step: 2
Training loss: 1.7653108835220337
Validation loss: 2.092901185154915

Epoch: 5| Step: 3
Training loss: 2.0339436531066895
Validation loss: 2.084934631983439

Epoch: 5| Step: 4
Training loss: 1.6822712421417236
Validation loss: 2.0949873626232147

Epoch: 5| Step: 5
Training loss: 2.34151029586792
Validation loss: 2.092898060878118

Epoch: 5| Step: 6
Training loss: 2.45034122467041
Validation loss: 2.103442043066025

Epoch: 5| Step: 7
Training loss: 1.5916303396224976
Validation loss: 2.0877685894568763

Epoch: 5| Step: 8
Training loss: 1.5879526138305664
Validation loss: 2.101926699280739

Epoch: 5| Step: 9
Training loss: 1.7112281322479248
Validation loss: 2.0975441336631775

Epoch: 5| Step: 10
Training loss: 2.570805072784424
Validation loss: 2.1145820717016854

Epoch: 5| Step: 11
Training loss: 1.7321364879608154
Validation loss: 2.1240383932987847

Epoch: 218| Step: 0
Training loss: 1.9209556579589844
Validation loss: 2.11690454185009

Epoch: 5| Step: 1
Training loss: 1.826732873916626
Validation loss: 2.134778380393982

Epoch: 5| Step: 2
Training loss: 2.5217700004577637
Validation loss: 2.129382779200872

Epoch: 5| Step: 3
Training loss: 2.375950813293457
Validation loss: 2.1343377232551575

Epoch: 5| Step: 4
Training loss: 1.7446956634521484
Validation loss: 2.1360037128130593

Epoch: 5| Step: 5
Training loss: 2.0789849758148193
Validation loss: 2.1376597930987677

Epoch: 5| Step: 6
Training loss: 1.648688554763794
Validation loss: 2.15526682138443

Epoch: 5| Step: 7
Training loss: 1.9360380172729492
Validation loss: 2.132098843653997

Epoch: 5| Step: 8
Training loss: 1.7060943841934204
Validation loss: 2.127083972096443

Epoch: 5| Step: 9
Training loss: 1.7615110874176025
Validation loss: 2.119079733888308

Epoch: 5| Step: 10
Training loss: 1.9563624858856201
Validation loss: 2.125138739744822

Epoch: 5| Step: 11
Training loss: 2.7859067916870117
Validation loss: 2.097893387079239

Epoch: 219| Step: 0
Training loss: 2.3042943477630615
Validation loss: 2.1041618287563324

Epoch: 5| Step: 1
Training loss: 1.7590099573135376
Validation loss: 2.1107558657725654

Epoch: 5| Step: 2
Training loss: 1.6741605997085571
Validation loss: 2.114177385965983

Epoch: 5| Step: 3
Training loss: 1.7386680841445923
Validation loss: 2.0976416766643524

Epoch: 5| Step: 4
Training loss: 1.9722360372543335
Validation loss: 2.099235122402509

Epoch: 5| Step: 5
Training loss: 1.8140987157821655
Validation loss: 2.1161204973856607

Epoch: 5| Step: 6
Training loss: 1.4813220500946045
Validation loss: 2.107598344484965

Epoch: 5| Step: 7
Training loss: 2.1055543422698975
Validation loss: 2.1149972677230835

Epoch: 5| Step: 8
Training loss: 1.8093045949935913
Validation loss: 2.1008205910523734

Epoch: 5| Step: 9
Training loss: 2.1228389739990234
Validation loss: 2.1105756064256034

Epoch: 5| Step: 10
Training loss: 2.2471835613250732
Validation loss: 2.107748677333196

Epoch: 5| Step: 11
Training loss: 2.084092378616333
Validation loss: 2.1108322739601135

Epoch: 220| Step: 0
Training loss: 2.276956558227539
Validation loss: 2.1093135525782905

Epoch: 5| Step: 1
Training loss: 1.4069240093231201
Validation loss: 2.113293985525767

Epoch: 5| Step: 2
Training loss: 1.9549458026885986
Validation loss: 2.104802722732226

Epoch: 5| Step: 3
Training loss: 2.068066120147705
Validation loss: 2.092579106489817

Epoch: 5| Step: 4
Training loss: 1.7383136749267578
Validation loss: 2.089945058027903

Epoch: 5| Step: 5
Training loss: 2.0400431156158447
Validation loss: 2.0807507832845054

Epoch: 5| Step: 6
Training loss: 1.2377856969833374
Validation loss: 2.087129677335421

Epoch: 5| Step: 7
Training loss: 2.2280805110931396
Validation loss: 2.0849070648352304

Epoch: 5| Step: 8
Training loss: 2.388467311859131
Validation loss: 2.071093628803889

Epoch: 5| Step: 9
Training loss: 2.228886127471924
Validation loss: 2.077509636680285

Epoch: 5| Step: 10
Training loss: 1.7826404571533203
Validation loss: 2.0808067421118417

Epoch: 5| Step: 11
Training loss: 3.223397731781006
Validation loss: 2.0842995593945184

Epoch: 221| Step: 0
Training loss: 2.068856716156006
Validation loss: 2.0751307606697083

Epoch: 5| Step: 1
Training loss: 2.499009847640991
Validation loss: 2.073864991466204

Epoch: 5| Step: 2
Training loss: 2.016352653503418
Validation loss: 2.074481541911761

Epoch: 5| Step: 3
Training loss: 1.3030582666397095
Validation loss: 2.070375546813011

Epoch: 5| Step: 4
Training loss: 2.32666015625
Validation loss: 2.081464355190595

Epoch: 5| Step: 5
Training loss: 1.3143880367279053
Validation loss: 2.085377852121989

Epoch: 5| Step: 6
Training loss: 2.0312705039978027
Validation loss: 2.102040867010752

Epoch: 5| Step: 7
Training loss: 1.57900869846344
Validation loss: 2.0883006006479263

Epoch: 5| Step: 8
Training loss: 1.7888768911361694
Validation loss: 2.102795660495758

Epoch: 5| Step: 9
Training loss: 1.9971542358398438
Validation loss: 2.090709298849106

Epoch: 5| Step: 10
Training loss: 2.251807928085327
Validation loss: 2.1049456149339676

Epoch: 5| Step: 11
Training loss: 2.3396477699279785
Validation loss: 2.114274243513743

Epoch: 222| Step: 0
Training loss: 2.59997296333313
Validation loss: 2.1261406441529593

Epoch: 5| Step: 1
Training loss: 1.3706022500991821
Validation loss: 2.126023252805074

Epoch: 5| Step: 2
Training loss: 1.7068008184432983
Validation loss: 2.1321146289507547

Epoch: 5| Step: 3
Training loss: 1.482239007949829
Validation loss: 2.1236310501893363

Epoch: 5| Step: 4
Training loss: 2.2067904472351074
Validation loss: 2.1357176452875137

Epoch: 5| Step: 5
Training loss: 2.2317092418670654
Validation loss: 2.1331676095724106

Epoch: 5| Step: 6
Training loss: 1.5364940166473389
Validation loss: 2.128683497508367

Epoch: 5| Step: 7
Training loss: 2.335561752319336
Validation loss: 2.1272657811641693

Epoch: 5| Step: 8
Training loss: 1.8060684204101562
Validation loss: 2.120130027333895

Epoch: 5| Step: 9
Training loss: 2.0789225101470947
Validation loss: 2.112366517384847

Epoch: 5| Step: 10
Training loss: 1.508702039718628
Validation loss: 2.110796650250753

Epoch: 5| Step: 11
Training loss: 2.559067726135254
Validation loss: 2.1162163466215134

Epoch: 223| Step: 0
Training loss: 1.9899559020996094
Validation loss: 2.0938406685988107

Epoch: 5| Step: 1
Training loss: 1.8214191198349
Validation loss: 2.1024178663889566

Epoch: 5| Step: 2
Training loss: 1.4241939783096313
Validation loss: 2.0920169403155646

Epoch: 5| Step: 3
Training loss: 1.849744439125061
Validation loss: 2.1000764866669974

Epoch: 5| Step: 4
Training loss: 1.9814954996109009
Validation loss: 2.1012035459280014

Epoch: 5| Step: 5
Training loss: 1.99383544921875
Validation loss: 2.09984697898229

Epoch: 5| Step: 6
Training loss: 2.9049766063690186
Validation loss: 2.105976566672325

Epoch: 5| Step: 7
Training loss: 1.8663219213485718
Validation loss: 2.118062987923622

Epoch: 5| Step: 8
Training loss: 1.2879122495651245
Validation loss: 2.10622904698054

Epoch: 5| Step: 9
Training loss: 2.070114850997925
Validation loss: 2.116080125172933

Epoch: 5| Step: 10
Training loss: 2.1041178703308105
Validation loss: 2.114141588409742

Epoch: 5| Step: 11
Training loss: 1.0017549991607666
Validation loss: 2.122519532839457

Epoch: 224| Step: 0
Training loss: 1.9072777032852173
Validation loss: 2.136286829908689

Epoch: 5| Step: 1
Training loss: 2.2483973503112793
Validation loss: 2.138353258371353

Epoch: 5| Step: 2
Training loss: 1.8214725255966187
Validation loss: 2.1236369212468467

Epoch: 5| Step: 3
Training loss: 1.7347667217254639
Validation loss: 2.1361721207698188

Epoch: 5| Step: 4
Training loss: 2.535310983657837
Validation loss: 2.1252549091974893

Epoch: 5| Step: 5
Training loss: 1.4625493288040161
Validation loss: 2.1312866707642875

Epoch: 5| Step: 6
Training loss: 2.2483439445495605
Validation loss: 2.121244798103968

Epoch: 5| Step: 7
Training loss: 1.6796287298202515
Validation loss: 2.1179733723402023

Epoch: 5| Step: 8
Training loss: 1.6208751201629639
Validation loss: 2.098923936486244

Epoch: 5| Step: 9
Training loss: 1.8377125263214111
Validation loss: 2.100812296072642

Epoch: 5| Step: 10
Training loss: 2.3706789016723633
Validation loss: 2.0995434125264487

Epoch: 5| Step: 11
Training loss: 1.1063528060913086
Validation loss: 2.0970798333485923

Epoch: 225| Step: 0
Training loss: 1.6751148700714111
Validation loss: 2.114495664834976

Epoch: 5| Step: 1
Training loss: 1.5701282024383545
Validation loss: 2.1016474763552346

Epoch: 5| Step: 2
Training loss: 2.064710855484009
Validation loss: 2.1088318775097528

Epoch: 5| Step: 3
Training loss: 1.7663536071777344
Validation loss: 2.105493903160095

Epoch: 5| Step: 4
Training loss: 1.8703844547271729
Validation loss: 2.105887840191523

Epoch: 5| Step: 5
Training loss: 1.5456500053405762
Validation loss: 2.108842601378759

Epoch: 5| Step: 6
Training loss: 1.894052505493164
Validation loss: 2.1109097450971603

Epoch: 5| Step: 7
Training loss: 1.7492929697036743
Validation loss: 2.105972722172737

Epoch: 5| Step: 8
Training loss: 2.525359630584717
Validation loss: 2.103012209137281

Epoch: 5| Step: 9
Training loss: 2.571948289871216
Validation loss: 2.1213675687710443

Epoch: 5| Step: 10
Training loss: 1.668712854385376
Validation loss: 2.1091353793938956

Epoch: 5| Step: 11
Training loss: 2.0178351402282715
Validation loss: 2.1245494335889816

Epoch: 226| Step: 0
Training loss: 1.861819863319397
Validation loss: 2.1203742573658624

Epoch: 5| Step: 1
Training loss: 1.819101333618164
Validation loss: 2.117921610673269

Epoch: 5| Step: 2
Training loss: 1.887494444847107
Validation loss: 2.146530563632647

Epoch: 5| Step: 3
Training loss: 1.6801326274871826
Validation loss: 2.1294954667488732

Epoch: 5| Step: 4
Training loss: 1.4299997091293335
Validation loss: 2.139038955171903

Epoch: 5| Step: 5
Training loss: 1.4910681247711182
Validation loss: 2.1343894600868225

Epoch: 5| Step: 6
Training loss: 1.893857717514038
Validation loss: 2.1193924198547998

Epoch: 5| Step: 7
Training loss: 1.7004013061523438
Validation loss: 2.1209940711657205

Epoch: 5| Step: 8
Training loss: 2.152344226837158
Validation loss: 2.1134022970994315

Epoch: 5| Step: 9
Training loss: 2.7982699871063232
Validation loss: 2.1145069052775702

Epoch: 5| Step: 10
Training loss: 2.1011128425598145
Validation loss: 2.116068055232366

Epoch: 5| Step: 11
Training loss: 2.7915985584259033
Validation loss: 2.124611427386602

Epoch: 227| Step: 0
Training loss: 1.9450442790985107
Validation loss: 2.115621800223986

Epoch: 5| Step: 1
Training loss: 2.2615745067596436
Validation loss: 2.1166221847136817

Epoch: 5| Step: 2
Training loss: 1.5889179706573486
Validation loss: 2.123034010330836

Epoch: 5| Step: 3
Training loss: 2.2559454441070557
Validation loss: 2.136595825354258

Epoch: 5| Step: 4
Training loss: 1.8421214818954468
Validation loss: 2.1175210575262704

Epoch: 5| Step: 5
Training loss: 1.952765703201294
Validation loss: 2.1222062706947327

Epoch: 5| Step: 6
Training loss: 1.5155651569366455
Validation loss: 2.1248969485362372

Epoch: 5| Step: 7
Training loss: 1.9069312810897827
Validation loss: 2.1232126355171204

Epoch: 5| Step: 8
Training loss: 2.00011944770813
Validation loss: 2.1447441379229226

Epoch: 5| Step: 9
Training loss: 1.6679404973983765
Validation loss: 2.136781563361486

Epoch: 5| Step: 10
Training loss: 1.809350609779358
Validation loss: 2.1524177441994348

Epoch: 5| Step: 11
Training loss: 1.853278636932373
Validation loss: 2.143526862064997

Epoch: 228| Step: 0
Training loss: 1.9530357122421265
Validation loss: 2.1627921164035797

Epoch: 5| Step: 1
Training loss: 2.155940055847168
Validation loss: 2.1521513362725577

Epoch: 5| Step: 2
Training loss: 2.3057169914245605
Validation loss: 2.165614902973175

Epoch: 5| Step: 3
Training loss: 1.7733409404754639
Validation loss: 2.143823872009913

Epoch: 5| Step: 4
Training loss: 2.213040828704834
Validation loss: 2.1358958929777145

Epoch: 5| Step: 5
Training loss: 1.9124422073364258
Validation loss: 2.138079563776652

Epoch: 5| Step: 6
Training loss: 2.238097667694092
Validation loss: 2.127179135878881

Epoch: 5| Step: 7
Training loss: 1.9083656072616577
Validation loss: 2.106581375002861

Epoch: 5| Step: 8
Training loss: 1.0430597066879272
Validation loss: 2.1007032692432404

Epoch: 5| Step: 9
Training loss: 1.9038082361221313
Validation loss: 2.1117399483919144

Epoch: 5| Step: 10
Training loss: 2.146000385284424
Validation loss: 2.1002209136883416

Epoch: 5| Step: 11
Training loss: 2.8040924072265625
Validation loss: 2.094572832187017

Epoch: 229| Step: 0
Training loss: 2.4643306732177734
Validation loss: 2.1049084762732186

Epoch: 5| Step: 1
Training loss: 1.576032042503357
Validation loss: 2.083607186873754

Epoch: 5| Step: 2
Training loss: 1.8963258266448975
Validation loss: 2.085102006793022

Epoch: 5| Step: 3
Training loss: 2.16058611869812
Validation loss: 2.0876117448012033

Epoch: 5| Step: 4
Training loss: 2.200226306915283
Validation loss: 2.0896076560020447

Epoch: 5| Step: 5
Training loss: 1.8526077270507812
Validation loss: 2.0970896830161414

Epoch: 5| Step: 6
Training loss: 1.8086721897125244
Validation loss: 2.0956839124361673

Epoch: 5| Step: 7
Training loss: 1.7645467519760132
Validation loss: 2.1085460583368936

Epoch: 5| Step: 8
Training loss: 2.012622356414795
Validation loss: 2.0972304542859397

Epoch: 5| Step: 9
Training loss: 2.1341164112091064
Validation loss: 2.10443522532781

Epoch: 5| Step: 10
Training loss: 1.719983696937561
Validation loss: 2.124311715364456

Epoch: 5| Step: 11
Training loss: 0.855791449546814
Validation loss: 2.1282613625129065

Epoch: 230| Step: 0
Training loss: 2.102781057357788
Validation loss: 2.125466669599215

Epoch: 5| Step: 1
Training loss: 1.5979275703430176
Validation loss: 2.1413599948088327

Epoch: 5| Step: 2
Training loss: 1.9631938934326172
Validation loss: 2.14659920334816

Epoch: 5| Step: 3
Training loss: 2.0903191566467285
Validation loss: 2.142365872859955

Epoch: 5| Step: 4
Training loss: 2.6163887977600098
Validation loss: 2.150513634085655

Epoch: 5| Step: 5
Training loss: 2.1798291206359863
Validation loss: 2.1492127726475396

Epoch: 5| Step: 6
Training loss: 2.1644515991210938
Validation loss: 2.145886758963267

Epoch: 5| Step: 7
Training loss: 1.8086055517196655
Validation loss: 2.1534996231396994

Epoch: 5| Step: 8
Training loss: 1.2847890853881836
Validation loss: 2.138545344273249

Epoch: 5| Step: 9
Training loss: 1.4440057277679443
Validation loss: 2.134246895710627

Epoch: 5| Step: 10
Training loss: 1.8347123861312866
Validation loss: 2.1295717457930246

Epoch: 5| Step: 11
Training loss: 2.8483588695526123
Validation loss: 2.115508625904719

Epoch: 231| Step: 0
Training loss: 1.1679366827011108
Validation loss: 2.1129909257094064

Epoch: 5| Step: 1
Training loss: 2.0478711128234863
Validation loss: 2.113560378551483

Epoch: 5| Step: 2
Training loss: 1.5467193126678467
Validation loss: 2.0911137759685516

Epoch: 5| Step: 3
Training loss: 1.8103303909301758
Validation loss: 2.0993997206290564

Epoch: 5| Step: 4
Training loss: 1.7617251873016357
Validation loss: 2.1076761136452355

Epoch: 5| Step: 5
Training loss: 1.6167428493499756
Validation loss: 2.1091156154870987

Epoch: 5| Step: 6
Training loss: 1.7898101806640625
Validation loss: 2.1264388163884482

Epoch: 5| Step: 7
Training loss: 2.559744119644165
Validation loss: 2.1124869187672934

Epoch: 5| Step: 8
Training loss: 1.930681586265564
Validation loss: 2.109035005172094

Epoch: 5| Step: 9
Training loss: 2.094805955886841
Validation loss: 2.114030738671621

Epoch: 5| Step: 10
Training loss: 2.4817066192626953
Validation loss: 2.125942458709081

Epoch: 5| Step: 11
Training loss: 1.704714059829712
Validation loss: 2.147894779841105

Epoch: 232| Step: 0
Training loss: 2.2741477489471436
Validation loss: 2.1411715149879456

Epoch: 5| Step: 1
Training loss: 1.894156813621521
Validation loss: 2.149881492058436

Epoch: 5| Step: 2
Training loss: 2.125694751739502
Validation loss: 2.144267519315084

Epoch: 5| Step: 3
Training loss: 1.8666168451309204
Validation loss: 2.145496820410093

Epoch: 5| Step: 4
Training loss: 2.1066410541534424
Validation loss: 2.161477987964948

Epoch: 5| Step: 5
Training loss: 1.9015138149261475
Validation loss: 2.144398366411527

Epoch: 5| Step: 6
Training loss: 1.9684641361236572
Validation loss: 2.1371761163075766

Epoch: 5| Step: 7
Training loss: 2.0488839149475098
Validation loss: 2.14277653892835

Epoch: 5| Step: 8
Training loss: 1.73932683467865
Validation loss: 2.1296182175477347

Epoch: 5| Step: 9
Training loss: 1.9565290212631226
Validation loss: 2.130450189113617

Epoch: 5| Step: 10
Training loss: 1.3689091205596924
Validation loss: 2.1403054197629294

Epoch: 5| Step: 11
Training loss: 0.641933798789978
Validation loss: 2.127853994568189

Epoch: 233| Step: 0
Training loss: 1.94431471824646
Validation loss: 2.1354266504446664

Epoch: 5| Step: 1
Training loss: 1.7818056344985962
Validation loss: 2.1487722049156823

Epoch: 5| Step: 2
Training loss: 1.6998023986816406
Validation loss: 2.1333866665760675

Epoch: 5| Step: 3
Training loss: 1.5480339527130127
Validation loss: 2.117440144220988

Epoch: 5| Step: 4
Training loss: 1.6051183938980103
Validation loss: 2.1457352936267853

Epoch: 5| Step: 5
Training loss: 1.9417924880981445
Validation loss: 2.1265898446242013

Epoch: 5| Step: 6
Training loss: 1.5410704612731934
Validation loss: 2.1306915978590646

Epoch: 5| Step: 7
Training loss: 1.9572126865386963
Validation loss: 2.1093282798926034

Epoch: 5| Step: 8
Training loss: 2.5938961505889893
Validation loss: 2.130830705165863

Epoch: 5| Step: 9
Training loss: 1.7458080053329468
Validation loss: 2.133756637573242

Epoch: 5| Step: 10
Training loss: 2.221973180770874
Validation loss: 2.1325565179189048

Epoch: 5| Step: 11
Training loss: 3.3958964347839355
Validation loss: 2.114469160636266

Epoch: 234| Step: 0
Training loss: 1.7486340999603271
Validation loss: 2.097811515132586

Epoch: 5| Step: 1
Training loss: 1.8659969568252563
Validation loss: 2.1012503504753113

Epoch: 5| Step: 2
Training loss: 2.026597499847412
Validation loss: 2.0958345333735147

Epoch: 5| Step: 3
Training loss: 1.4911521673202515
Validation loss: 2.091206803917885

Epoch: 5| Step: 4
Training loss: 1.4942982196807861
Validation loss: 2.0967715233564377

Epoch: 5| Step: 5
Training loss: 1.7140436172485352
Validation loss: 2.079136773943901

Epoch: 5| Step: 6
Training loss: 2.4286274909973145
Validation loss: 2.071266084909439

Epoch: 5| Step: 7
Training loss: 1.961822509765625
Validation loss: 2.106472611427307

Epoch: 5| Step: 8
Training loss: 2.00732421875
Validation loss: 2.0952871441841125

Epoch: 5| Step: 9
Training loss: 2.261869192123413
Validation loss: 2.1033803274234137

Epoch: 5| Step: 10
Training loss: 1.403943419456482
Validation loss: 2.0999765594800315

Epoch: 5| Step: 11
Training loss: 3.0507030487060547
Validation loss: 2.1182814687490463

Epoch: 235| Step: 0
Training loss: 2.1459827423095703
Validation loss: 2.1174055536588035

Epoch: 5| Step: 1
Training loss: 1.9596869945526123
Validation loss: 2.1108999053637185

Epoch: 5| Step: 2
Training loss: 2.4980125427246094
Validation loss: 2.1135391741991043

Epoch: 5| Step: 3
Training loss: 2.589221239089966
Validation loss: 2.1265727430582047

Epoch: 5| Step: 4
Training loss: 1.9743473529815674
Validation loss: 2.110204671820005

Epoch: 5| Step: 5
Training loss: 1.683127760887146
Validation loss: 2.119525005420049

Epoch: 5| Step: 6
Training loss: 1.5199224948883057
Validation loss: 2.1129623552163443

Epoch: 5| Step: 7
Training loss: 1.4844627380371094
Validation loss: 2.1084188719590506

Epoch: 5| Step: 8
Training loss: 1.9071903228759766
Validation loss: 2.0871736109256744

Epoch: 5| Step: 9
Training loss: 2.5583043098449707
Validation loss: 2.083012039462725

Epoch: 5| Step: 10
Training loss: 1.465671181678772
Validation loss: 2.0852334598700204

Epoch: 5| Step: 11
Training loss: 1.1874229907989502
Validation loss: 2.0815124809741974

Epoch: 236| Step: 0
Training loss: 1.5315465927124023
Validation loss: 2.0910058865944543

Epoch: 5| Step: 1
Training loss: 1.8685266971588135
Validation loss: 2.087509905298551

Epoch: 5| Step: 2
Training loss: 1.7788454294204712
Validation loss: 2.0937724312146506

Epoch: 5| Step: 3
Training loss: 2.8244106769561768
Validation loss: 2.0920328001181283

Epoch: 5| Step: 4
Training loss: 2.159209966659546
Validation loss: 2.08898696800073

Epoch: 5| Step: 5
Training loss: 2.0848708152770996
Validation loss: 2.1047822535037994

Epoch: 5| Step: 6
Training loss: 2.110079288482666
Validation loss: 2.094583029548327

Epoch: 5| Step: 7
Training loss: 1.3358150720596313
Validation loss: 2.099078526099523

Epoch: 5| Step: 8
Training loss: 2.084991931915283
Validation loss: 2.11336342493693

Epoch: 5| Step: 9
Training loss: 1.9397001266479492
Validation loss: 2.1213584542274475

Epoch: 5| Step: 10
Training loss: 1.8898417949676514
Validation loss: 2.12626946469148

Epoch: 5| Step: 11
Training loss: 0.9727274179458618
Validation loss: 2.140103538831075

Epoch: 237| Step: 0
Training loss: 1.966038465499878
Validation loss: 2.147742971777916

Epoch: 5| Step: 1
Training loss: 1.6548230648040771
Validation loss: 2.135248308380445

Epoch: 5| Step: 2
Training loss: 1.4179751873016357
Validation loss: 2.1300249099731445

Epoch: 5| Step: 3
Training loss: 1.8030369281768799
Validation loss: 2.1240971932808557

Epoch: 5| Step: 4
Training loss: 2.2976696491241455
Validation loss: 2.1329267770051956

Epoch: 5| Step: 5
Training loss: 1.9286760091781616
Validation loss: 2.1356180359919867

Epoch: 5| Step: 6
Training loss: 1.8872846364974976
Validation loss: 2.1082808723052344

Epoch: 5| Step: 7
Training loss: 1.6950504779815674
Validation loss: 2.1255728602409363

Epoch: 5| Step: 8
Training loss: 2.4278039932250977
Validation loss: 2.1133629232645035

Epoch: 5| Step: 9
Training loss: 2.0699868202209473
Validation loss: 2.1199495097001395

Epoch: 5| Step: 10
Training loss: 1.7070910930633545
Validation loss: 2.124224469065666

Epoch: 5| Step: 11
Training loss: 2.51739501953125
Validation loss: 2.1295052617788315

Epoch: 238| Step: 0
Training loss: 1.613053560256958
Validation loss: 2.1266869654258094

Epoch: 5| Step: 1
Training loss: 2.328232526779175
Validation loss: 2.1185536285241446

Epoch: 5| Step: 2
Training loss: 2.215165853500366
Validation loss: 2.132677594820658

Epoch: 5| Step: 3
Training loss: 1.534134864807129
Validation loss: 2.1261414736509323

Epoch: 5| Step: 4
Training loss: 2.1505115032196045
Validation loss: 2.1364580343166986

Epoch: 5| Step: 5
Training loss: 1.3871132135391235
Validation loss: 2.1300644675890603

Epoch: 5| Step: 6
Training loss: 1.9343839883804321
Validation loss: 2.1342784563700357

Epoch: 5| Step: 7
Training loss: 1.920901894569397
Validation loss: 2.13999738295873

Epoch: 5| Step: 8
Training loss: 1.92242431640625
Validation loss: 2.1168584724267325

Epoch: 5| Step: 9
Training loss: 2.032008171081543
Validation loss: 2.1442366441090903

Epoch: 5| Step: 10
Training loss: 1.864967942237854
Validation loss: 2.1244014898935952

Epoch: 5| Step: 11
Training loss: 1.9156702756881714
Validation loss: 2.135050892829895

Epoch: 239| Step: 0
Training loss: 1.792028784751892
Validation loss: 2.125907614827156

Epoch: 5| Step: 1
Training loss: 1.9694570302963257
Validation loss: 2.1133167445659637

Epoch: 5| Step: 2
Training loss: 2.1623501777648926
Validation loss: 2.1334842493136725

Epoch: 5| Step: 3
Training loss: 2.281874656677246
Validation loss: 2.1444600025812783

Epoch: 5| Step: 4
Training loss: 2.1659772396087646
Validation loss: 2.1244376252094903

Epoch: 5| Step: 5
Training loss: 1.825621247291565
Validation loss: 2.1400746007760367

Epoch: 5| Step: 6
Training loss: 2.1779255867004395
Validation loss: 2.130483423670133

Epoch: 5| Step: 7
Training loss: 1.5431066751480103
Validation loss: 2.1345303605000177

Epoch: 5| Step: 8
Training loss: 1.3705172538757324
Validation loss: 2.147391989827156

Epoch: 5| Step: 9
Training loss: 2.2914130687713623
Validation loss: 2.140471617380778

Epoch: 5| Step: 10
Training loss: 1.204730749130249
Validation loss: 2.134387418627739

Epoch: 5| Step: 11
Training loss: 1.2857797145843506
Validation loss: 2.1476820607980094

Epoch: 240| Step: 0
Training loss: 1.9427833557128906
Validation loss: 2.1476219842831292

Epoch: 5| Step: 1
Training loss: 2.2070529460906982
Validation loss: 2.163363183538119

Epoch: 5| Step: 2
Training loss: 1.195450782775879
Validation loss: 2.1271014511585236

Epoch: 5| Step: 3
Training loss: 2.1693031787872314
Validation loss: 2.118916466832161

Epoch: 5| Step: 4
Training loss: 2.1964879035949707
Validation loss: 2.112933153907458

Epoch: 5| Step: 5
Training loss: 1.4683432579040527
Validation loss: 2.117812623580297

Epoch: 5| Step: 6
Training loss: 2.0968689918518066
Validation loss: 2.1300792346398034

Epoch: 5| Step: 7
Training loss: 1.379539132118225
Validation loss: 2.124895289540291

Epoch: 5| Step: 8
Training loss: 1.8398809432983398
Validation loss: 2.130854974190394

Epoch: 5| Step: 9
Training loss: 1.783146619796753
Validation loss: 2.134494513273239

Epoch: 5| Step: 10
Training loss: 2.4180960655212402
Validation loss: 2.1283102681239447

Epoch: 5| Step: 11
Training loss: 2.233600616455078
Validation loss: 2.118231783310572

Epoch: 241| Step: 0
Training loss: 1.2368495464324951
Validation loss: 2.1370102763175964

Epoch: 5| Step: 1
Training loss: 1.8624099493026733
Validation loss: 2.1362860600153604

Epoch: 5| Step: 2
Training loss: 1.7806164026260376
Validation loss: 2.133334497610728

Epoch: 5| Step: 3
Training loss: 1.6546649932861328
Validation loss: 2.118788331747055

Epoch: 5| Step: 4
Training loss: 1.677120566368103
Validation loss: 2.1283608774344125

Epoch: 5| Step: 5
Training loss: 2.5141749382019043
Validation loss: 2.138130302230517

Epoch: 5| Step: 6
Training loss: 2.0385594367980957
Validation loss: 2.1335686842600503

Epoch: 5| Step: 7
Training loss: 1.9276745319366455
Validation loss: 2.154913147290548

Epoch: 5| Step: 8
Training loss: 1.822251558303833
Validation loss: 2.147724370161692

Epoch: 5| Step: 9
Training loss: 1.6027323007583618
Validation loss: 2.1410669088363647

Epoch: 5| Step: 10
Training loss: 2.2909655570983887
Validation loss: 2.149444575111071

Epoch: 5| Step: 11
Training loss: 2.072011947631836
Validation loss: 2.1448545157909393

Epoch: 242| Step: 0
Training loss: 1.5004122257232666
Validation loss: 2.1521834482749305

Epoch: 5| Step: 1
Training loss: 2.144751787185669
Validation loss: 2.1188404013713202

Epoch: 5| Step: 2
Training loss: 1.9110825061798096
Validation loss: 2.119193896651268

Epoch: 5| Step: 3
Training loss: 1.7376598119735718
Validation loss: 2.113051394621531

Epoch: 5| Step: 4
Training loss: 1.2910182476043701
Validation loss: 2.1266430467367172

Epoch: 5| Step: 5
Training loss: 2.046584367752075
Validation loss: 2.107018858194351

Epoch: 5| Step: 6
Training loss: 2.3788461685180664
Validation loss: 2.118518297870954

Epoch: 5| Step: 7
Training loss: 2.096860885620117
Validation loss: 2.130721628665924

Epoch: 5| Step: 8
Training loss: 2.2112183570861816
Validation loss: 2.130141794681549

Epoch: 5| Step: 9
Training loss: 1.8590091466903687
Validation loss: 2.136384144425392

Epoch: 5| Step: 10
Training loss: 1.9364343881607056
Validation loss: 2.1418435176213584

Epoch: 5| Step: 11
Training loss: 1.0443625450134277
Validation loss: 2.1461154172817865

Epoch: 243| Step: 0
Training loss: 1.9119338989257812
Validation loss: 2.149023617307345

Epoch: 5| Step: 1
Training loss: 1.8863093852996826
Validation loss: 2.146703779697418

Epoch: 5| Step: 2
Training loss: 1.7785024642944336
Validation loss: 2.152599493662516

Epoch: 5| Step: 3
Training loss: 1.4330427646636963
Validation loss: 2.135117302338282

Epoch: 5| Step: 4
Training loss: 1.2873214483261108
Validation loss: 2.1336931586265564

Epoch: 5| Step: 5
Training loss: 1.8357025384902954
Validation loss: 2.1399240493774414

Epoch: 5| Step: 6
Training loss: 2.2507660388946533
Validation loss: 2.139566491047541

Epoch: 5| Step: 7
Training loss: 2.256857395172119
Validation loss: 2.126060297091802

Epoch: 5| Step: 8
Training loss: 2.044931173324585
Validation loss: 2.134938289721807

Epoch: 5| Step: 9
Training loss: 1.6277602910995483
Validation loss: 2.12376015384992

Epoch: 5| Step: 10
Training loss: 2.036524534225464
Validation loss: 2.1300673286120095

Epoch: 5| Step: 11
Training loss: 2.0204577445983887
Validation loss: 2.139016995827357

Epoch: 244| Step: 0
Training loss: 1.6096904277801514
Validation loss: 2.165580670038859

Epoch: 5| Step: 1
Training loss: 1.475712537765503
Validation loss: 2.1336857875188193

Epoch: 5| Step: 2
Training loss: 1.6866190433502197
Validation loss: 2.1678065756956735

Epoch: 5| Step: 3
Training loss: 1.9548852443695068
Validation loss: 2.1438983231782913

Epoch: 5| Step: 4
Training loss: 1.6850436925888062
Validation loss: 2.1537056813637414

Epoch: 5| Step: 5
Training loss: 2.0707035064697266
Validation loss: 2.141271010041237

Epoch: 5| Step: 6
Training loss: 1.6224076747894287
Validation loss: 2.1508896201848984

Epoch: 5| Step: 7
Training loss: 1.444969892501831
Validation loss: 2.1416167616844177

Epoch: 5| Step: 8
Training loss: 2.466850757598877
Validation loss: 2.1433255026737847

Epoch: 5| Step: 9
Training loss: 1.7686821222305298
Validation loss: 2.1344613979260125

Epoch: 5| Step: 10
Training loss: 2.566704511642456
Validation loss: 2.126219153404236

Epoch: 5| Step: 11
Training loss: 1.8897613286972046
Validation loss: 2.136499911546707

Epoch: 245| Step: 0
Training loss: 1.2649345397949219
Validation loss: 2.136440649628639

Epoch: 5| Step: 1
Training loss: 2.4561524391174316
Validation loss: 2.143994296590487

Epoch: 5| Step: 2
Training loss: 1.9970786571502686
Validation loss: 2.13510433336099

Epoch: 5| Step: 3
Training loss: 1.7213783264160156
Validation loss: 2.1198298037052155

Epoch: 5| Step: 4
Training loss: 2.0447702407836914
Validation loss: 2.1300552437702813

Epoch: 5| Step: 5
Training loss: 2.223879337310791
Validation loss: 2.1315393646558127

Epoch: 5| Step: 6
Training loss: 1.539090633392334
Validation loss: 2.125766098499298

Epoch: 5| Step: 7
Training loss: 2.0280063152313232
Validation loss: 2.1193422178427377

Epoch: 5| Step: 8
Training loss: 1.9988073110580444
Validation loss: 2.138888120651245

Epoch: 5| Step: 9
Training loss: 1.4562689065933228
Validation loss: 2.121019338568052

Epoch: 5| Step: 10
Training loss: 1.9000415802001953
Validation loss: 2.120539978146553

Epoch: 5| Step: 11
Training loss: 1.2414734363555908
Validation loss: 2.1283492147922516

Epoch: 246| Step: 0
Training loss: 1.4799163341522217
Validation loss: 2.1241736114025116

Epoch: 5| Step: 1
Training loss: 1.7876369953155518
Validation loss: 2.11690982679526

Epoch: 5| Step: 2
Training loss: 1.6737511157989502
Validation loss: 2.1030196646849313

Epoch: 5| Step: 3
Training loss: 2.2834315299987793
Validation loss: 2.1049521416425705

Epoch: 5| Step: 4
Training loss: 2.699716091156006
Validation loss: 2.096814672152201

Epoch: 5| Step: 5
Training loss: 1.8318698406219482
Validation loss: 2.099051217238108

Epoch: 5| Step: 6
Training loss: 1.6247053146362305
Validation loss: 2.1053908665974936

Epoch: 5| Step: 7
Training loss: 2.0704827308654785
Validation loss: 2.1015073458353677

Epoch: 5| Step: 8
Training loss: 2.233548402786255
Validation loss: 2.1181011497974396

Epoch: 5| Step: 9
Training loss: 1.4843227863311768
Validation loss: 2.1287592500448227

Epoch: 5| Step: 10
Training loss: 1.7237398624420166
Validation loss: 2.1062384446461997

Epoch: 5| Step: 11
Training loss: 1.4705919027328491
Validation loss: 2.128004560867945

Epoch: 247| Step: 0
Training loss: 1.4035367965698242
Validation loss: 2.1377274096012115

Epoch: 5| Step: 1
Training loss: 2.396106004714966
Validation loss: 2.127307047446569

Epoch: 5| Step: 2
Training loss: 1.8627420663833618
Validation loss: 2.1226277301708856

Epoch: 5| Step: 3
Training loss: 2.007760524749756
Validation loss: 2.1291899184385934

Epoch: 5| Step: 4
Training loss: 1.7153069972991943
Validation loss: 2.114775617917379

Epoch: 5| Step: 5
Training loss: 1.9955812692642212
Validation loss: 2.135014295578003

Epoch: 5| Step: 6
Training loss: 1.7374099493026733
Validation loss: 2.1272672414779663

Epoch: 5| Step: 7
Training loss: 2.00998854637146
Validation loss: 2.1173240890105567

Epoch: 5| Step: 8
Training loss: 1.9362643957138062
Validation loss: 2.105451355377833

Epoch: 5| Step: 9
Training loss: 1.894296646118164
Validation loss: 2.1073781798283258

Epoch: 5| Step: 10
Training loss: 1.6584373712539673
Validation loss: 2.1058093706766763

Epoch: 5| Step: 11
Training loss: 1.958634853363037
Validation loss: 2.1200184424718223

Epoch: 248| Step: 0
Training loss: 1.580055832862854
Validation loss: 2.1303208470344543

Epoch: 5| Step: 1
Training loss: 1.4709423780441284
Validation loss: 2.1015621622403464

Epoch: 5| Step: 2
Training loss: 1.6856842041015625
Validation loss: 2.1350016792615256

Epoch: 5| Step: 3
Training loss: 2.3158130645751953
Validation loss: 2.156187797586123

Epoch: 5| Step: 4
Training loss: 2.0977537631988525
Validation loss: 2.144553691148758

Epoch: 5| Step: 5
Training loss: 1.7317968606948853
Validation loss: 2.182385355234146

Epoch: 5| Step: 6
Training loss: 2.2824158668518066
Validation loss: 2.1849972108999887

Epoch: 5| Step: 7
Training loss: 1.9990675449371338
Validation loss: 2.155663306514422

Epoch: 5| Step: 8
Training loss: 2.388094902038574
Validation loss: 2.163580814997355

Epoch: 5| Step: 9
Training loss: 1.6311734914779663
Validation loss: 2.1557244459788003

Epoch: 5| Step: 10
Training loss: 1.5467151403427124
Validation loss: 2.1509369760751724

Epoch: 5| Step: 11
Training loss: 1.5682897567749023
Validation loss: 2.1394962668418884

Epoch: 249| Step: 0
Training loss: 2.6288228034973145
Validation loss: 2.146456241607666

Epoch: 5| Step: 1
Training loss: 1.8983770608901978
Validation loss: 2.144802530606588

Epoch: 5| Step: 2
Training loss: 1.6543474197387695
Validation loss: 2.1320781211058297

Epoch: 5| Step: 3
Training loss: 2.041487693786621
Validation loss: 2.135740632812182

Epoch: 5| Step: 4
Training loss: 1.7441215515136719
Validation loss: 2.1053290168444314

Epoch: 5| Step: 5
Training loss: 1.7256273031234741
Validation loss: 2.1192087282737098

Epoch: 5| Step: 6
Training loss: 1.7714895009994507
Validation loss: 2.1200255950291953

Epoch: 5| Step: 7
Training loss: 2.113421678543091
Validation loss: 2.12946284810702

Epoch: 5| Step: 8
Training loss: 1.7266643047332764
Validation loss: 2.11382287244002

Epoch: 5| Step: 9
Training loss: 0.9842005968093872
Validation loss: 2.1316670775413513

Epoch: 5| Step: 10
Training loss: 1.8469436168670654
Validation loss: 2.1238882640997567

Epoch: 5| Step: 11
Training loss: 3.0607593059539795
Validation loss: 2.124600683649381

Epoch: 250| Step: 0
Training loss: 1.6710516214370728
Validation loss: 2.123816668987274

Epoch: 5| Step: 1
Training loss: 1.9952446222305298
Validation loss: 2.120108629266421

Epoch: 5| Step: 2
Training loss: 1.7952148914337158
Validation loss: 2.1205969403187432

Epoch: 5| Step: 3
Training loss: 2.3132882118225098
Validation loss: 2.116375724474589

Epoch: 5| Step: 4
Training loss: 1.8218475580215454
Validation loss: 2.125782678524653

Epoch: 5| Step: 5
Training loss: 1.6288257837295532
Validation loss: 2.1357865035533905

Epoch: 5| Step: 6
Training loss: 1.7505886554718018
Validation loss: 2.1364431232213974

Epoch: 5| Step: 7
Training loss: 2.543401002883911
Validation loss: 2.1209569176038108

Epoch: 5| Step: 8
Training loss: 1.6132690906524658
Validation loss: 2.1241354048252106

Epoch: 5| Step: 9
Training loss: 1.3253682851791382
Validation loss: 2.1316580971082053

Epoch: 5| Step: 10
Training loss: 1.637793779373169
Validation loss: 2.1378543128569922

Epoch: 5| Step: 11
Training loss: 1.7751243114471436
Validation loss: 2.1297972251971564

Epoch: 251| Step: 0
Training loss: 1.670631766319275
Validation loss: 2.1221904903650284

Epoch: 5| Step: 1
Training loss: 2.2093234062194824
Validation loss: 2.1166368424892426

Epoch: 5| Step: 2
Training loss: 1.9492416381835938
Validation loss: 2.1242048740386963

Epoch: 5| Step: 3
Training loss: 2.0297586917877197
Validation loss: 2.1380058427651725

Epoch: 5| Step: 4
Training loss: 1.5339006185531616
Validation loss: 2.1530895034472146

Epoch: 5| Step: 5
Training loss: 1.9364248514175415
Validation loss: 2.134542087713877

Epoch: 5| Step: 6
Training loss: 1.6962082386016846
Validation loss: 2.154413715004921

Epoch: 5| Step: 7
Training loss: 1.4381190538406372
Validation loss: 2.1380706826845803

Epoch: 5| Step: 8
Training loss: 1.9782657623291016
Validation loss: 2.138558099667231

Epoch: 5| Step: 9
Training loss: 1.805214285850525
Validation loss: 2.166344945629438

Epoch: 5| Step: 10
Training loss: 1.9253206253051758
Validation loss: 2.1661960581938424

Epoch: 5| Step: 11
Training loss: 1.1081790924072266
Validation loss: 2.170930936932564

Epoch: 252| Step: 0
Training loss: 2.285804271697998
Validation loss: 2.162410090366999

Epoch: 5| Step: 1
Training loss: 2.2879624366760254
Validation loss: 2.1688675036032996

Epoch: 5| Step: 2
Training loss: 1.482659935951233
Validation loss: 2.16084594031175

Epoch: 5| Step: 3
Training loss: 2.052060127258301
Validation loss: 2.1592031170924506

Epoch: 5| Step: 4
Training loss: 1.6008743047714233
Validation loss: 2.164792309204737

Epoch: 5| Step: 5
Training loss: 1.8323453664779663
Validation loss: 2.1743661016225815

Epoch: 5| Step: 6
Training loss: 1.8166182041168213
Validation loss: 2.211199184258779

Epoch: 5| Step: 7
Training loss: 1.5325241088867188
Validation loss: 2.1552370687325797

Epoch: 5| Step: 8
Training loss: 1.5917607545852661
Validation loss: 2.184605598449707

Epoch: 5| Step: 9
Training loss: 1.8459266424179077
Validation loss: 2.1840419421593347

Epoch: 5| Step: 10
Training loss: 1.68781316280365
Validation loss: 2.1750721285740533

Epoch: 5| Step: 11
Training loss: 1.7142341136932373
Validation loss: 2.158367504676183

Epoch: 253| Step: 0
Training loss: 1.7221587896347046
Validation loss: 2.152165492375692

Epoch: 5| Step: 1
Training loss: 1.6400467157363892
Validation loss: 2.138447026411692

Epoch: 5| Step: 2
Training loss: 1.5986381769180298
Validation loss: 2.1347407599290213

Epoch: 5| Step: 3
Training loss: 1.5284276008605957
Validation loss: 2.119877909620603

Epoch: 5| Step: 4
Training loss: 2.4688003063201904
Validation loss: 2.1293522119522095

Epoch: 5| Step: 5
Training loss: 1.830182671546936
Validation loss: 2.128332018852234

Epoch: 5| Step: 6
Training loss: 1.9277175664901733
Validation loss: 2.1268399208784103

Epoch: 5| Step: 7
Training loss: 1.7589771747589111
Validation loss: 2.1222418944040933

Epoch: 5| Step: 8
Training loss: 1.9793989658355713
Validation loss: 2.1237718562285104

Epoch: 5| Step: 9
Training loss: 1.601345419883728
Validation loss: 2.140999565521876

Epoch: 5| Step: 10
Training loss: 2.0215091705322266
Validation loss: 2.125860338409742

Epoch: 5| Step: 11
Training loss: 2.046947479248047
Validation loss: 2.131689558426539

Epoch: 254| Step: 0
Training loss: 2.232149600982666
Validation loss: 2.1428578396638236

Epoch: 5| Step: 1
Training loss: 1.7035871744155884
Validation loss: 2.1575738191604614

Epoch: 5| Step: 2
Training loss: 2.0107154846191406
Validation loss: 2.1784896602233252

Epoch: 5| Step: 3
Training loss: 2.207235097885132
Validation loss: 2.1634937673807144

Epoch: 5| Step: 4
Training loss: 2.2279467582702637
Validation loss: 2.174376130104065

Epoch: 5| Step: 5
Training loss: 1.9566713571548462
Validation loss: 2.1633428633213043

Epoch: 5| Step: 6
Training loss: 1.5653507709503174
Validation loss: 2.1462155481179557

Epoch: 5| Step: 7
Training loss: 2.051628351211548
Validation loss: 2.129230245947838

Epoch: 5| Step: 8
Training loss: 1.5792381763458252
Validation loss: 2.1209814250469208

Epoch: 5| Step: 9
Training loss: 1.711798071861267
Validation loss: 2.1370600710312524

Epoch: 5| Step: 10
Training loss: 1.4699878692626953
Validation loss: 2.1459132929642997

Epoch: 5| Step: 11
Training loss: 1.3260626792907715
Validation loss: 2.1496051301558814

Epoch: 255| Step: 0
Training loss: 1.9048141241073608
Validation loss: 2.153454174598058

Epoch: 5| Step: 1
Training loss: 2.081885814666748
Validation loss: 2.156832128763199

Epoch: 5| Step: 2
Training loss: 1.216639757156372
Validation loss: 2.1590582032998404

Epoch: 5| Step: 3
Training loss: 1.9607124328613281
Validation loss: 2.1770301163196564

Epoch: 5| Step: 4
Training loss: 1.8158950805664062
Validation loss: 2.1942316591739655

Epoch: 5| Step: 5
Training loss: 2.087688446044922
Validation loss: 2.1876917580763497

Epoch: 5| Step: 6
Training loss: 1.9639307260513306
Validation loss: 2.197677637139956

Epoch: 5| Step: 7
Training loss: 2.1855530738830566
Validation loss: 2.1804209848244986

Epoch: 5| Step: 8
Training loss: 2.165623188018799
Validation loss: 2.179462254047394

Epoch: 5| Step: 9
Training loss: 1.193865180015564
Validation loss: 2.1835956225792565

Epoch: 5| Step: 10
Training loss: 1.5612605810165405
Validation loss: 2.153475041190783

Epoch: 5| Step: 11
Training loss: 1.0480564832687378
Validation loss: 2.166038895646731

Epoch: 256| Step: 0
Training loss: 2.1546661853790283
Validation loss: 2.143895208835602

Epoch: 5| Step: 1
Training loss: 1.771154761314392
Validation loss: 2.1410639733076096

Epoch: 5| Step: 2
Training loss: 1.9358257055282593
Validation loss: 2.1407372653484344

Epoch: 5| Step: 3
Training loss: 1.572021245956421
Validation loss: 2.144328316052755

Epoch: 5| Step: 4
Training loss: 1.3577148914337158
Validation loss: 2.1515206346909204

Epoch: 5| Step: 5
Training loss: 1.4656436443328857
Validation loss: 2.1538773626089096

Epoch: 5| Step: 6
Training loss: 2.1389522552490234
Validation loss: 2.1621334801117578

Epoch: 5| Step: 7
Training loss: 1.7630456686019897
Validation loss: 2.169229949514071

Epoch: 5| Step: 8
Training loss: 1.7837470769882202
Validation loss: 2.150330359737078

Epoch: 5| Step: 9
Training loss: 1.939647912979126
Validation loss: 2.159796714782715

Epoch: 5| Step: 10
Training loss: 1.8976142406463623
Validation loss: 2.1606196661790213

Epoch: 5| Step: 11
Training loss: 1.7282309532165527
Validation loss: 2.170362710952759

Epoch: 257| Step: 0
Training loss: 1.607682466506958
Validation loss: 2.164046217997869

Epoch: 5| Step: 1
Training loss: 2.163179874420166
Validation loss: 2.1310605704784393

Epoch: 5| Step: 2
Training loss: 2.1660311222076416
Validation loss: 2.155666306614876

Epoch: 5| Step: 3
Training loss: 2.142183780670166
Validation loss: 2.159074435631434

Epoch: 5| Step: 4
Training loss: 2.175729274749756
Validation loss: 2.1706418792406716

Epoch: 5| Step: 5
Training loss: 2.130563259124756
Validation loss: 2.1600330968697867

Epoch: 5| Step: 6
Training loss: 1.325920820236206
Validation loss: 2.1792887349923453

Epoch: 5| Step: 7
Training loss: 1.076715111732483
Validation loss: 2.200144370396932

Epoch: 5| Step: 8
Training loss: 1.7727543115615845
Validation loss: 2.188332587480545

Epoch: 5| Step: 9
Training loss: 1.5407871007919312
Validation loss: 2.1942833065986633

Epoch: 5| Step: 10
Training loss: 1.3397115468978882
Validation loss: 2.155926858385404

Epoch: 5| Step: 11
Training loss: 3.421795129776001
Validation loss: 2.1703801850477853

Epoch: 258| Step: 0
Training loss: 1.5223054885864258
Validation loss: 2.1939394772052765

Epoch: 5| Step: 1
Training loss: 1.8000503778457642
Validation loss: 2.1646770586570105

Epoch: 5| Step: 2
Training loss: 1.7529842853546143
Validation loss: 2.1665906508763633

Epoch: 5| Step: 3
Training loss: 2.00807523727417
Validation loss: 2.1688146690527597

Epoch: 5| Step: 4
Training loss: 1.9131065607070923
Validation loss: 2.14349635442098

Epoch: 5| Step: 5
Training loss: 1.8628418445587158
Validation loss: 2.1485897501309714

Epoch: 5| Step: 6
Training loss: 1.31729257106781
Validation loss: 2.159335787097613

Epoch: 5| Step: 7
Training loss: 1.2279843091964722
Validation loss: 2.1556066125631332

Epoch: 5| Step: 8
Training loss: 2.030916213989258
Validation loss: 2.1415439546108246

Epoch: 5| Step: 9
Training loss: 2.067634105682373
Validation loss: 2.119559740026792

Epoch: 5| Step: 10
Training loss: 2.1931560039520264
Validation loss: 2.144943152864774

Epoch: 5| Step: 11
Training loss: 1.8673641681671143
Validation loss: 2.1368434031804404

Epoch: 259| Step: 0
Training loss: 1.4818722009658813
Validation loss: 2.140842874844869

Epoch: 5| Step: 1
Training loss: 1.7493168115615845
Validation loss: 2.162120282649994

Epoch: 5| Step: 2
Training loss: 1.3749200105667114
Validation loss: 2.166398376226425

Epoch: 5| Step: 3
Training loss: 1.8836456537246704
Validation loss: 2.1769669353961945

Epoch: 5| Step: 4
Training loss: 1.9377353191375732
Validation loss: 2.188059056798617

Epoch: 5| Step: 5
Training loss: 1.8143666982650757
Validation loss: 2.1887791752815247

Epoch: 5| Step: 6
Training loss: 1.394011378288269
Validation loss: 2.1698251167933145

Epoch: 5| Step: 7
Training loss: 1.8154289722442627
Validation loss: 2.1862036883831024

Epoch: 5| Step: 8
Training loss: 2.0380897521972656
Validation loss: 2.1719357719024024

Epoch: 5| Step: 9
Training loss: 1.7254846096038818
Validation loss: 2.18458820382754

Epoch: 5| Step: 10
Training loss: 2.7481014728546143
Validation loss: 2.161142408847809

Epoch: 5| Step: 11
Training loss: 0.5404903292655945
Validation loss: 2.1431231002012887

Epoch: 260| Step: 0
Training loss: 1.6329708099365234
Validation loss: 2.1642863353093467

Epoch: 5| Step: 1
Training loss: 1.6661899089813232
Validation loss: 2.1532028118769326

Epoch: 5| Step: 2
Training loss: 1.475804090499878
Validation loss: 2.1417326182127

Epoch: 5| Step: 3
Training loss: 1.2504833936691284
Validation loss: 2.1615997950236

Epoch: 5| Step: 4
Training loss: 1.6030540466308594
Validation loss: 2.1422560711701712

Epoch: 5| Step: 5
Training loss: 2.9383411407470703
Validation loss: 2.1531480501095452

Epoch: 5| Step: 6
Training loss: 2.0571398735046387
Validation loss: 2.1636684189240136

Epoch: 5| Step: 7
Training loss: 1.9466049671173096
Validation loss: 2.1758243292570114

Epoch: 5| Step: 8
Training loss: 1.7178045511245728
Validation loss: 2.167115737994512

Epoch: 5| Step: 9
Training loss: 1.4571099281311035
Validation loss: 2.1482837249835334

Epoch: 5| Step: 10
Training loss: 2.1188807487487793
Validation loss: 2.1689895341793695

Epoch: 5| Step: 11
Training loss: 0.8834629654884338
Validation loss: 2.1669372767210007

Epoch: 261| Step: 0
Training loss: 1.9642843008041382
Validation loss: 2.1805204848448434

Epoch: 5| Step: 1
Training loss: 1.5644034147262573
Validation loss: 2.168974980711937

Epoch: 5| Step: 2
Training loss: 2.368980884552002
Validation loss: 2.1828840474287667

Epoch: 5| Step: 3
Training loss: 1.8689134120941162
Validation loss: 2.176170771320661

Epoch: 5| Step: 4
Training loss: 1.6016162633895874
Validation loss: 2.1766866942246756

Epoch: 5| Step: 5
Training loss: 1.485894799232483
Validation loss: 2.1786866883436837

Epoch: 5| Step: 6
Training loss: 1.4447605609893799
Validation loss: 2.1655573646227517

Epoch: 5| Step: 7
Training loss: 1.9087018966674805
Validation loss: 2.168789734443029

Epoch: 5| Step: 8
Training loss: 2.1409103870391846
Validation loss: 2.151472588380178

Epoch: 5| Step: 9
Training loss: 2.0688862800598145
Validation loss: 2.1622517903645835

Epoch: 5| Step: 10
Training loss: 1.735731840133667
Validation loss: 2.1591623375813165

Epoch: 5| Step: 11
Training loss: 1.5651240348815918
Validation loss: 2.1448835929234824

Epoch: 262| Step: 0
Training loss: 1.7558119297027588
Validation loss: 2.1567823588848114

Epoch: 5| Step: 1
Training loss: 2.158205509185791
Validation loss: 2.1509724259376526

Epoch: 5| Step: 2
Training loss: 1.3071377277374268
Validation loss: 2.1559750735759735

Epoch: 5| Step: 3
Training loss: 2.4601869583129883
Validation loss: 2.1691942711671195

Epoch: 5| Step: 4
Training loss: 1.2513164281845093
Validation loss: 2.1609874616066613

Epoch: 5| Step: 5
Training loss: 1.9027099609375
Validation loss: 2.1579775661230087

Epoch: 5| Step: 6
Training loss: 1.7430334091186523
Validation loss: 2.1679305732250214

Epoch: 5| Step: 7
Training loss: 1.5711352825164795
Validation loss: 2.1793546130259833

Epoch: 5| Step: 8
Training loss: 2.4712090492248535
Validation loss: 2.1861925025780997

Epoch: 5| Step: 9
Training loss: 1.7053064107894897
Validation loss: 2.1965546111265817

Epoch: 5| Step: 10
Training loss: 1.737924575805664
Validation loss: 2.1942970752716064

Epoch: 5| Step: 11
Training loss: 0.7933030128479004
Validation loss: 2.1786789000034332

Epoch: 263| Step: 0
Training loss: 2.02569842338562
Validation loss: 2.1759675641854606

Epoch: 5| Step: 1
Training loss: 1.3507109880447388
Validation loss: 2.184773658712705

Epoch: 5| Step: 2
Training loss: 1.7003662586212158
Validation loss: 2.191533307234446

Epoch: 5| Step: 3
Training loss: 1.8824657201766968
Validation loss: 2.1696738799413047

Epoch: 5| Step: 4
Training loss: 1.8462871313095093
Validation loss: 2.1614489207665124

Epoch: 5| Step: 5
Training loss: 1.903432846069336
Validation loss: 2.1633774240811667

Epoch: 5| Step: 6
Training loss: 2.164163112640381
Validation loss: 2.164202476541201

Epoch: 5| Step: 7
Training loss: 1.5114431381225586
Validation loss: 2.1517189095417657

Epoch: 5| Step: 8
Training loss: 1.5947389602661133
Validation loss: 2.147162308295568

Epoch: 5| Step: 9
Training loss: 1.6523908376693726
Validation loss: 2.1448851575454078

Epoch: 5| Step: 10
Training loss: 1.7825120687484741
Validation loss: 2.161568745970726

Epoch: 5| Step: 11
Training loss: 2.4643497467041016
Validation loss: 2.1521049439907074

Epoch: 264| Step: 0
Training loss: 1.608591079711914
Validation loss: 2.159941554069519

Epoch: 5| Step: 1
Training loss: 1.6959329843521118
Validation loss: 2.1594871828953424

Epoch: 5| Step: 2
Training loss: 1.577331304550171
Validation loss: 2.1590355783700943

Epoch: 5| Step: 3
Training loss: 1.3615368604660034
Validation loss: 2.161941960453987

Epoch: 5| Step: 4
Training loss: 1.165036916732788
Validation loss: 2.155099183320999

Epoch: 5| Step: 5
Training loss: 1.883826494216919
Validation loss: 2.162519628802935

Epoch: 5| Step: 6
Training loss: 1.5666286945343018
Validation loss: 2.166362831989924

Epoch: 5| Step: 7
Training loss: 2.3009684085845947
Validation loss: 2.161587913831075

Epoch: 5| Step: 8
Training loss: 2.1167900562286377
Validation loss: 2.177362705270449

Epoch: 5| Step: 9
Training loss: 2.2287685871124268
Validation loss: 2.1876033941904702

Epoch: 5| Step: 10
Training loss: 2.0099291801452637
Validation loss: 2.168744683265686

Epoch: 5| Step: 11
Training loss: 2.4381327629089355
Validation loss: 2.181602547566096

Epoch: 265| Step: 0
Training loss: 1.728671669960022
Validation loss: 2.1569625486930213

Epoch: 5| Step: 1
Training loss: 1.608742117881775
Validation loss: 2.1872379581133523

Epoch: 5| Step: 2
Training loss: 1.6779693365097046
Validation loss: 2.147928386926651

Epoch: 5| Step: 3
Training loss: 1.157371163368225
Validation loss: 2.172861317793528

Epoch: 5| Step: 4
Training loss: 1.6369473934173584
Validation loss: 2.152262012163798

Epoch: 5| Step: 5
Training loss: 1.6637048721313477
Validation loss: 2.143434231479963

Epoch: 5| Step: 6
Training loss: 1.40036940574646
Validation loss: 2.1381386816501617

Epoch: 5| Step: 7
Training loss: 1.5047595500946045
Validation loss: 2.131522829333941

Epoch: 5| Step: 8
Training loss: 2.5908939838409424
Validation loss: 2.1374426931142807

Epoch: 5| Step: 9
Training loss: 2.5149266719818115
Validation loss: 2.146413346131643

Epoch: 5| Step: 10
Training loss: 2.3433163166046143
Validation loss: 2.1434672127167382

Epoch: 5| Step: 11
Training loss: 2.4012937545776367
Validation loss: 2.1403920451800027

Epoch: 266| Step: 0
Training loss: 1.7560113668441772
Validation loss: 2.1448308726151786

Epoch: 5| Step: 1
Training loss: 2.241685390472412
Validation loss: 2.1573206782341003

Epoch: 5| Step: 2
Training loss: 1.6488450765609741
Validation loss: 2.164654662211736

Epoch: 5| Step: 3
Training loss: 1.8234338760375977
Validation loss: 2.155476614832878

Epoch: 5| Step: 4
Training loss: 1.8593708276748657
Validation loss: 2.155650168657303

Epoch: 5| Step: 5
Training loss: 1.5761464834213257
Validation loss: 2.1723988751570382

Epoch: 5| Step: 6
Training loss: 2.201612949371338
Validation loss: 2.151368041833242

Epoch: 5| Step: 7
Training loss: 0.9514118432998657
Validation loss: 2.1576252778371177

Epoch: 5| Step: 8
Training loss: 1.7722902297973633
Validation loss: 2.1534216701984406

Epoch: 5| Step: 9
Training loss: 2.3548026084899902
Validation loss: 2.167062853773435

Epoch: 5| Step: 10
Training loss: 1.9242385625839233
Validation loss: 2.1717794934908548

Epoch: 5| Step: 11
Training loss: 1.2345235347747803
Validation loss: 2.175983647505442

Epoch: 267| Step: 0
Training loss: 1.909401535987854
Validation loss: 2.1501986334721246

Epoch: 5| Step: 1
Training loss: 2.283151149749756
Validation loss: 2.155388683080673

Epoch: 5| Step: 2
Training loss: 1.4803369045257568
Validation loss: 2.141270950436592

Epoch: 5| Step: 3
Training loss: 1.401497483253479
Validation loss: 2.147581314047178

Epoch: 5| Step: 4
Training loss: 1.7166789770126343
Validation loss: 2.119904716809591

Epoch: 5| Step: 5
Training loss: 2.089430093765259
Validation loss: 2.146044999361038

Epoch: 5| Step: 6
Training loss: 1.7316615581512451
Validation loss: 2.1411356578270593

Epoch: 5| Step: 7
Training loss: 1.6859798431396484
Validation loss: 2.120121717453003

Epoch: 5| Step: 8
Training loss: 1.47176194190979
Validation loss: 2.137109398841858

Epoch: 5| Step: 9
Training loss: 1.6104154586791992
Validation loss: 2.1352715343236923

Epoch: 5| Step: 10
Training loss: 2.3211419582366943
Validation loss: 2.13458418349425

Epoch: 5| Step: 11
Training loss: 1.209563970565796
Validation loss: 2.1384408871332803

Epoch: 268| Step: 0
Training loss: 1.6017940044403076
Validation loss: 2.1468793153762817

Epoch: 5| Step: 1
Training loss: 1.8804088830947876
Validation loss: 2.1447567542394004

Epoch: 5| Step: 2
Training loss: 1.6534630060195923
Validation loss: 2.1525229016939798

Epoch: 5| Step: 3
Training loss: 1.900520920753479
Validation loss: 2.150508160392443

Epoch: 5| Step: 4
Training loss: 1.5887880325317383
Validation loss: 2.1460366547107697

Epoch: 5| Step: 5
Training loss: 1.7242546081542969
Validation loss: 2.1508308897415795

Epoch: 5| Step: 6
Training loss: 1.3949017524719238
Validation loss: 2.1458237816890082

Epoch: 5| Step: 7
Training loss: 2.0543630123138428
Validation loss: 2.1424072980880737

Epoch: 5| Step: 8
Training loss: 1.9795879125595093
Validation loss: 2.160257418950399

Epoch: 5| Step: 9
Training loss: 1.64170241355896
Validation loss: 2.173202400406202

Epoch: 5| Step: 10
Training loss: 2.0114762783050537
Validation loss: 2.192654237151146

Epoch: 5| Step: 11
Training loss: 1.8658850193023682
Validation loss: 2.2009160071611404

Epoch: 269| Step: 0
Training loss: 1.3154418468475342
Validation loss: 2.204346348841985

Epoch: 5| Step: 1
Training loss: 1.5950896739959717
Validation loss: 2.2076948285102844

Epoch: 5| Step: 2
Training loss: 1.4669784307479858
Validation loss: 2.203804463148117

Epoch: 5| Step: 3
Training loss: 2.6589787006378174
Validation loss: 2.1912543326616287

Epoch: 5| Step: 4
Training loss: 1.740121841430664
Validation loss: 2.1815172682205834

Epoch: 5| Step: 5
Training loss: 1.9296674728393555
Validation loss: 2.1654643515745797

Epoch: 5| Step: 6
Training loss: 1.5917409658432007
Validation loss: 2.174657166004181

Epoch: 5| Step: 7
Training loss: 1.6752763986587524
Validation loss: 2.1792151480913162

Epoch: 5| Step: 8
Training loss: 1.5721813440322876
Validation loss: 2.1750596165657043

Epoch: 5| Step: 9
Training loss: 1.96222722530365
Validation loss: 2.182554970184962

Epoch: 5| Step: 10
Training loss: 1.9304430484771729
Validation loss: 2.156793554623922

Epoch: 5| Step: 11
Training loss: 1.7614463567733765
Validation loss: 2.185719539721807

Epoch: 270| Step: 0
Training loss: 1.5551700592041016
Validation loss: 2.1753525833288827

Epoch: 5| Step: 1
Training loss: 1.5734889507293701
Validation loss: 2.157232036193212

Epoch: 5| Step: 2
Training loss: 1.8987241983413696
Validation loss: 2.146707703669866

Epoch: 5| Step: 3
Training loss: 1.703545331954956
Validation loss: 2.1778934448957443

Epoch: 5| Step: 4
Training loss: 1.8884265422821045
Validation loss: 2.1281474431355796

Epoch: 5| Step: 5
Training loss: 1.846799612045288
Validation loss: 2.160387525955836

Epoch: 5| Step: 6
Training loss: 1.5946409702301025
Validation loss: 2.1935814321041107

Epoch: 5| Step: 7
Training loss: 2.0085785388946533
Validation loss: 2.1587888846794763

Epoch: 5| Step: 8
Training loss: 1.426105260848999
Validation loss: 2.1945871859788895

Epoch: 5| Step: 9
Training loss: 2.293215274810791
Validation loss: 2.176048621535301

Epoch: 5| Step: 10
Training loss: 1.8207496404647827
Validation loss: 2.1755588253339133

Epoch: 5| Step: 11
Training loss: 1.3758571147918701
Validation loss: 2.1843829254309335

Epoch: 271| Step: 0
Training loss: 1.8603217601776123
Validation loss: 2.16094841559728

Epoch: 5| Step: 1
Training loss: 2.244213819503784
Validation loss: 2.164668083190918

Epoch: 5| Step: 2
Training loss: 2.0593204498291016
Validation loss: 2.1466034799814224

Epoch: 5| Step: 3
Training loss: 2.2479095458984375
Validation loss: 2.1733571191628775

Epoch: 5| Step: 4
Training loss: 1.3778445720672607
Validation loss: 2.1645462264617286

Epoch: 5| Step: 5
Training loss: 1.5097681283950806
Validation loss: 2.1545664966106415

Epoch: 5| Step: 6
Training loss: 1.3275861740112305
Validation loss: 2.1657531609137854

Epoch: 5| Step: 7
Training loss: 1.6577857732772827
Validation loss: 2.168042595187823

Epoch: 5| Step: 8
Training loss: 1.8050177097320557
Validation loss: 2.1636277784903846

Epoch: 5| Step: 9
Training loss: 1.5056053400039673
Validation loss: 2.182616263628006

Epoch: 5| Step: 10
Training loss: 2.0608367919921875
Validation loss: 2.1862513522307077

Epoch: 5| Step: 11
Training loss: 2.562021255493164
Validation loss: 2.1870616525411606

Epoch: 272| Step: 0
Training loss: 1.2192533016204834
Validation loss: 2.1936994741360345

Epoch: 5| Step: 1
Training loss: 1.568153738975525
Validation loss: 2.1966797411441803

Epoch: 5| Step: 2
Training loss: 1.8992435932159424
Validation loss: 2.189453129967054

Epoch: 5| Step: 3
Training loss: 2.0906448364257812
Validation loss: 2.2011585036913552

Epoch: 5| Step: 4
Training loss: 1.6864433288574219
Validation loss: 2.1986445635557175

Epoch: 5| Step: 5
Training loss: 2.221416711807251
Validation loss: 2.1955747604370117

Epoch: 5| Step: 6
Training loss: 1.7683559656143188
Validation loss: 2.2084891895453134

Epoch: 5| Step: 7
Training loss: 1.6241413354873657
Validation loss: 2.184904138247172

Epoch: 5| Step: 8
Training loss: 1.523138403892517
Validation loss: 2.167095790306727

Epoch: 5| Step: 9
Training loss: 2.1858038902282715
Validation loss: 2.1737368553876877

Epoch: 5| Step: 10
Training loss: 1.7762982845306396
Validation loss: 2.1859340568383536

Epoch: 5| Step: 11
Training loss: 0.7782137393951416
Validation loss: 2.171644185980161

Epoch: 273| Step: 0
Training loss: 2.2976510524749756
Validation loss: 2.1842839370171228

Epoch: 5| Step: 1
Training loss: 1.7134374380111694
Validation loss: 2.168448507785797

Epoch: 5| Step: 2
Training loss: 1.7756763696670532
Validation loss: 2.1820760617653527

Epoch: 5| Step: 3
Training loss: 1.347352385520935
Validation loss: 2.203066070874532

Epoch: 5| Step: 4
Training loss: 2.163137435913086
Validation loss: 2.165982057650884

Epoch: 5| Step: 5
Training loss: 1.461248755455017
Validation loss: 2.177000562349955

Epoch: 5| Step: 6
Training loss: 1.6150901317596436
Validation loss: 2.1803498615821204

Epoch: 5| Step: 7
Training loss: 1.24240243434906
Validation loss: 2.1813122928142548

Epoch: 5| Step: 8
Training loss: 1.0623162984848022
Validation loss: 2.1671889324982962

Epoch: 5| Step: 9
Training loss: 2.1128344535827637
Validation loss: 2.1761815349260965

Epoch: 5| Step: 10
Training loss: 2.026487350463867
Validation loss: 2.164932201306025

Epoch: 5| Step: 11
Training loss: 2.3287901878356934
Validation loss: 2.162420998016993

Epoch: 274| Step: 0
Training loss: 1.3119456768035889
Validation loss: 2.181057035923004

Epoch: 5| Step: 1
Training loss: 2.0984373092651367
Validation loss: 2.187160164117813

Epoch: 5| Step: 2
Training loss: 1.4058372974395752
Validation loss: 2.1766282320022583

Epoch: 5| Step: 3
Training loss: 1.5505403280258179
Validation loss: 2.1989534248908362

Epoch: 5| Step: 4
Training loss: 1.9134200811386108
Validation loss: 2.1922622323036194

Epoch: 5| Step: 5
Training loss: 1.4721457958221436
Validation loss: 2.1860571602980294

Epoch: 5| Step: 6
Training loss: 1.2505818605422974
Validation loss: 2.2041401962439218

Epoch: 5| Step: 7
Training loss: 2.0411200523376465
Validation loss: 2.176197429498037

Epoch: 5| Step: 8
Training loss: 1.7157694101333618
Validation loss: 2.1827192852894464

Epoch: 5| Step: 9
Training loss: 2.1262331008911133
Validation loss: 2.1476218551397324

Epoch: 5| Step: 10
Training loss: 2.20361328125
Validation loss: 2.157208854953448

Epoch: 5| Step: 11
Training loss: 1.583920955657959
Validation loss: 2.1582562178373337

Epoch: 275| Step: 0
Training loss: 2.4897708892822266
Validation loss: 2.1673659682273865

Epoch: 5| Step: 1
Training loss: 2.33776593208313
Validation loss: 2.157767946521441

Epoch: 5| Step: 2
Training loss: 1.5574182271957397
Validation loss: 2.149359146753947

Epoch: 5| Step: 3
Training loss: 1.5628268718719482
Validation loss: 2.1441427717606225

Epoch: 5| Step: 4
Training loss: 2.247135877609253
Validation loss: 2.132962077856064

Epoch: 5| Step: 5
Training loss: 1.7012125253677368
Validation loss: 2.1447320580482483

Epoch: 5| Step: 6
Training loss: 1.621255874633789
Validation loss: 2.143095831076304

Epoch: 5| Step: 7
Training loss: 1.1290191411972046
Validation loss: 2.1433982451756797

Epoch: 5| Step: 8
Training loss: 1.557477355003357
Validation loss: 2.13486410677433

Epoch: 5| Step: 9
Training loss: 1.4456298351287842
Validation loss: 2.131791109840075

Epoch: 5| Step: 10
Training loss: 2.0180249214172363
Validation loss: 2.123467688759168

Epoch: 5| Step: 11
Training loss: 1.1956247091293335
Validation loss: 2.146932621796926

Epoch: 276| Step: 0
Training loss: 1.649082899093628
Validation loss: 2.1366442441940308

Epoch: 5| Step: 1
Training loss: 1.4491510391235352
Validation loss: 2.118547956148783

Epoch: 5| Step: 2
Training loss: 2.4145140647888184
Validation loss: 2.144098083178202

Epoch: 5| Step: 3
Training loss: 2.1473941802978516
Validation loss: 2.1377473970254264

Epoch: 5| Step: 4
Training loss: 1.4435752630233765
Validation loss: 2.144674768050512

Epoch: 5| Step: 5
Training loss: 2.090407609939575
Validation loss: 2.1495115607976913

Epoch: 5| Step: 6
Training loss: 1.8197221755981445
Validation loss: 2.130394155780474

Epoch: 5| Step: 7
Training loss: 1.482656478881836
Validation loss: 2.14299975335598

Epoch: 5| Step: 8
Training loss: 1.4968030452728271
Validation loss: 2.131664608915647

Epoch: 5| Step: 9
Training loss: 2.0813262462615967
Validation loss: 2.146428724129995

Epoch: 5| Step: 10
Training loss: 1.455235242843628
Validation loss: 2.1506481965382895

Epoch: 5| Step: 11
Training loss: 1.90366530418396
Validation loss: 2.138130009174347

Epoch: 277| Step: 0
Training loss: 1.9210691452026367
Validation loss: 2.1563520431518555

Epoch: 5| Step: 1
Training loss: 1.6142873764038086
Validation loss: 2.1438367068767548

Epoch: 5| Step: 2
Training loss: 1.1760104894638062
Validation loss: 2.142247741421064

Epoch: 5| Step: 3
Training loss: 1.2519069910049438
Validation loss: 2.165014003713926

Epoch: 5| Step: 4
Training loss: 2.3246335983276367
Validation loss: 2.1386189063390098

Epoch: 5| Step: 5
Training loss: 1.832373857498169
Validation loss: 2.151764010389646

Epoch: 5| Step: 6
Training loss: 1.8651081323623657
Validation loss: 2.140908191601435

Epoch: 5| Step: 7
Training loss: 1.227803349494934
Validation loss: 2.1605766465266547

Epoch: 5| Step: 8
Training loss: 2.3810250759124756
Validation loss: 2.1629527608553567

Epoch: 5| Step: 9
Training loss: 1.8171489238739014
Validation loss: 2.1650774081548056

Epoch: 5| Step: 10
Training loss: 1.9299484491348267
Validation loss: 2.172376145919164

Epoch: 5| Step: 11
Training loss: 1.0771251916885376
Validation loss: 2.166199187437693

Epoch: 278| Step: 0
Training loss: 1.8674242496490479
Validation loss: 2.160574202736219

Epoch: 5| Step: 1
Training loss: 1.7494242191314697
Validation loss: 2.162438581387202

Epoch: 5| Step: 2
Training loss: 1.802514672279358
Validation loss: 2.15196659664313

Epoch: 5| Step: 3
Training loss: 1.6011978387832642
Validation loss: 2.1668683141469955

Epoch: 5| Step: 4
Training loss: 1.3578736782073975
Validation loss: 2.1536587526400885

Epoch: 5| Step: 5
Training loss: 2.0195798873901367
Validation loss: 2.174012924234072

Epoch: 5| Step: 6
Training loss: 1.7069848775863647
Validation loss: 2.1785858372847238

Epoch: 5| Step: 7
Training loss: 1.4356588125228882
Validation loss: 2.209904223680496

Epoch: 5| Step: 8
Training loss: 1.5034687519073486
Validation loss: 2.2161103834708533

Epoch: 5| Step: 9
Training loss: 2.204315662384033
Validation loss: 2.210844412446022

Epoch: 5| Step: 10
Training loss: 1.7953475713729858
Validation loss: 2.18588754038016

Epoch: 5| Step: 11
Training loss: 2.471412181854248
Validation loss: 2.1976820627848306

Epoch: 279| Step: 0
Training loss: 1.7520462274551392
Validation loss: 2.1707803110281625

Epoch: 5| Step: 1
Training loss: 1.637437105178833
Validation loss: 2.1667968382438025

Epoch: 5| Step: 2
Training loss: 2.064652919769287
Validation loss: 2.1571871091922126

Epoch: 5| Step: 3
Training loss: 1.6945081949234009
Validation loss: 2.1608076989650726

Epoch: 5| Step: 4
Training loss: 1.5722843408584595
Validation loss: 2.1503305534521737

Epoch: 5| Step: 5
Training loss: 1.4270145893096924
Validation loss: 2.1513369381427765

Epoch: 5| Step: 6
Training loss: 1.749922513961792
Validation loss: 2.1880757808685303

Epoch: 5| Step: 7
Training loss: 2.2947497367858887
Validation loss: 2.157226632038752

Epoch: 5| Step: 8
Training loss: 1.688993215560913
Validation loss: 2.166644424200058

Epoch: 5| Step: 9
Training loss: 1.3634408712387085
Validation loss: 2.165400425593058

Epoch: 5| Step: 10
Training loss: 1.6725660562515259
Validation loss: 2.1630854258934655

Epoch: 5| Step: 11
Training loss: 1.6909313201904297
Validation loss: 2.185354769229889

Epoch: 280| Step: 0
Training loss: 1.9754632711410522
Validation loss: 2.167667935291926

Epoch: 5| Step: 1
Training loss: 1.5422660112380981
Validation loss: 2.1751179645458856

Epoch: 5| Step: 2
Training loss: 1.6335738897323608
Validation loss: 2.1670308113098145

Epoch: 5| Step: 3
Training loss: 1.5234168767929077
Validation loss: 2.170901745557785

Epoch: 5| Step: 4
Training loss: 1.748727798461914
Validation loss: 2.1694452315568924

Epoch: 5| Step: 5
Training loss: 1.7095940113067627
Validation loss: 2.1686837524175644

Epoch: 5| Step: 6
Training loss: 2.260524272918701
Validation loss: 2.17319655418396

Epoch: 5| Step: 7
Training loss: 1.6082448959350586
Validation loss: 2.1608749081691108

Epoch: 5| Step: 8
Training loss: 1.6578435897827148
Validation loss: 2.188398132721583

Epoch: 5| Step: 9
Training loss: 1.6208460330963135
Validation loss: 2.1821976552406945

Epoch: 5| Step: 10
Training loss: 1.6363369226455688
Validation loss: 2.1952260931332908

Epoch: 5| Step: 11
Training loss: 1.3121211528778076
Validation loss: 2.1788989702860513

Epoch: 281| Step: 0
Training loss: 1.4136834144592285
Validation loss: 2.1988243559996286

Epoch: 5| Step: 1
Training loss: 2.0771682262420654
Validation loss: 2.1903139650821686

Epoch: 5| Step: 2
Training loss: 1.218327283859253
Validation loss: 2.1687555611133575

Epoch: 5| Step: 3
Training loss: 1.4081377983093262
Validation loss: 2.2167558670043945

Epoch: 5| Step: 4
Training loss: 1.5803238153457642
Validation loss: 2.180341054995855

Epoch: 5| Step: 5
Training loss: 1.559037208557129
Validation loss: 2.1764041433731713

Epoch: 5| Step: 6
Training loss: 1.6937748193740845
Validation loss: 2.168181007107099

Epoch: 5| Step: 7
Training loss: 1.6998631954193115
Validation loss: 2.1692704459031424

Epoch: 5| Step: 8
Training loss: 1.7371402978897095
Validation loss: 2.1668294817209244

Epoch: 5| Step: 9
Training loss: 2.1925711631774902
Validation loss: 2.1628543039162955

Epoch: 5| Step: 10
Training loss: 2.0944018363952637
Validation loss: 2.1816944976647696

Epoch: 5| Step: 11
Training loss: 3.225836753845215
Validation loss: 2.17162032922109

Epoch: 282| Step: 0
Training loss: 2.690742254257202
Validation loss: 2.1642163395881653

Epoch: 5| Step: 1
Training loss: 1.9070230722427368
Validation loss: 2.1321443766355515

Epoch: 5| Step: 2
Training loss: 1.5063203573226929
Validation loss: 2.14070192972819

Epoch: 5| Step: 3
Training loss: 1.579857587814331
Validation loss: 2.1344368308782578

Epoch: 5| Step: 4
Training loss: 2.2268319129943848
Validation loss: 2.14243691166242

Epoch: 5| Step: 5
Training loss: 1.276270866394043
Validation loss: 2.139896889527639

Epoch: 5| Step: 6
Training loss: 1.723520040512085
Validation loss: 2.123008812467257

Epoch: 5| Step: 7
Training loss: 1.9579572677612305
Validation loss: 2.130247419079145

Epoch: 5| Step: 8
Training loss: 1.4146034717559814
Validation loss: 2.132075160741806

Epoch: 5| Step: 9
Training loss: 1.6230262517929077
Validation loss: 2.1441980451345444

Epoch: 5| Step: 10
Training loss: 1.2641570568084717
Validation loss: 2.1086736619472504

Epoch: 5| Step: 11
Training loss: 1.172959327697754
Validation loss: 2.1426588892936707

Epoch: 283| Step: 0
Training loss: 1.8594777584075928
Validation loss: 2.1811567644278207

Epoch: 5| Step: 1
Training loss: 2.969371795654297
Validation loss: 2.1759484012921653

Epoch: 5| Step: 2
Training loss: 1.4089906215667725
Validation loss: 2.15325395266215

Epoch: 5| Step: 3
Training loss: 1.9621047973632812
Validation loss: 2.1799554775158563

Epoch: 5| Step: 4
Training loss: 1.0789542198181152
Validation loss: 2.1781899432341256

Epoch: 5| Step: 5
Training loss: 1.6618707180023193
Validation loss: 2.167919417222341

Epoch: 5| Step: 6
Training loss: 1.744268774986267
Validation loss: 2.1653000315030417

Epoch: 5| Step: 7
Training loss: 2.3375461101531982
Validation loss: 2.1606557965278625

Epoch: 5| Step: 8
Training loss: 1.467262625694275
Validation loss: 2.1570577969153724

Epoch: 5| Step: 9
Training loss: 1.7675864696502686
Validation loss: 2.1536458482344947

Epoch: 5| Step: 10
Training loss: 1.6038143634796143
Validation loss: 2.160096431771914

Epoch: 5| Step: 11
Training loss: 2.00727915763855
Validation loss: 2.149108052253723

Epoch: 284| Step: 0
Training loss: 1.7814960479736328
Validation loss: 2.157754590113958

Epoch: 5| Step: 1
Training loss: 1.783263921737671
Validation loss: 2.1701428294181824

Epoch: 5| Step: 2
Training loss: 1.7788646221160889
Validation loss: 2.1835790425539017

Epoch: 5| Step: 3
Training loss: 1.485782504081726
Validation loss: 2.2069408297538757

Epoch: 5| Step: 4
Training loss: 2.128674268722534
Validation loss: 2.218462054928144

Epoch: 5| Step: 5
Training loss: 1.8840059041976929
Validation loss: 2.2215988437334695

Epoch: 5| Step: 6
Training loss: 1.0991735458374023
Validation loss: 2.2271220733722052

Epoch: 5| Step: 7
Training loss: 2.064535140991211
Validation loss: 2.2187297443548837

Epoch: 5| Step: 8
Training loss: 1.4761947393417358
Validation loss: 2.243069658676783

Epoch: 5| Step: 9
Training loss: 2.050638198852539
Validation loss: 2.2330825328826904

Epoch: 5| Step: 10
Training loss: 1.5900264978408813
Validation loss: 2.2331827779610953

Epoch: 5| Step: 11
Training loss: 1.1043493747711182
Validation loss: 2.23348505795002

Epoch: 285| Step: 0
Training loss: 1.3764722347259521
Validation loss: 2.2276065945625305

Epoch: 5| Step: 1
Training loss: 1.7406688928604126
Validation loss: 2.2313421865304313

Epoch: 5| Step: 2
Training loss: 1.9388339519500732
Validation loss: 2.176989590128263

Epoch: 5| Step: 3
Training loss: 1.7852916717529297
Validation loss: 2.202698936065038

Epoch: 5| Step: 4
Training loss: 1.5355908870697021
Validation loss: 2.2148157358169556

Epoch: 5| Step: 5
Training loss: 2.072319507598877
Validation loss: 2.204699397087097

Epoch: 5| Step: 6
Training loss: 1.6183239221572876
Validation loss: 2.2001945773760476

Epoch: 5| Step: 7
Training loss: 1.9317820072174072
Validation loss: 2.2108597258726754

Epoch: 5| Step: 8
Training loss: 2.102363348007202
Validation loss: 2.2119764586289725

Epoch: 5| Step: 9
Training loss: 1.3610546588897705
Validation loss: 2.196063141028086

Epoch: 5| Step: 10
Training loss: 1.6865081787109375
Validation loss: 2.201712965965271

Epoch: 5| Step: 11
Training loss: 1.4841333627700806
Validation loss: 2.2028936545054116

Epoch: 286| Step: 0
Training loss: 2.3257510662078857
Validation loss: 2.198344886302948

Epoch: 5| Step: 1
Training loss: 1.920025110244751
Validation loss: 2.2128885289033255

Epoch: 5| Step: 2
Training loss: 1.8836486339569092
Validation loss: 2.2046974102656045

Epoch: 5| Step: 3
Training loss: 1.3940681219100952
Validation loss: 2.1859467774629593

Epoch: 5| Step: 4
Training loss: 1.600383996963501
Validation loss: 2.185827746987343

Epoch: 5| Step: 5
Training loss: 1.7936903238296509
Validation loss: 2.1974137226740518

Epoch: 5| Step: 6
Training loss: 1.666778802871704
Validation loss: 2.2096685469150543

Epoch: 5| Step: 7
Training loss: 1.155186414718628
Validation loss: 2.2012369136015573

Epoch: 5| Step: 8
Training loss: 1.505640983581543
Validation loss: 2.204427649577459

Epoch: 5| Step: 9
Training loss: 1.6944507360458374
Validation loss: 2.1823734839757285

Epoch: 5| Step: 10
Training loss: 2.047132968902588
Validation loss: 2.2033642580111823

Epoch: 5| Step: 11
Training loss: 1.107900857925415
Validation loss: 2.199067915479342

Epoch: 287| Step: 0
Training loss: 1.7778863906860352
Validation loss: 2.2076382289330163

Epoch: 5| Step: 1
Training loss: 1.5702416896820068
Validation loss: 2.2059391091267266

Epoch: 5| Step: 2
Training loss: 1.9102312326431274
Validation loss: 2.2263218263785043

Epoch: 5| Step: 3
Training loss: 1.5996562242507935
Validation loss: 2.2473062574863434

Epoch: 5| Step: 4
Training loss: 1.6902446746826172
Validation loss: 2.2427522440751395

Epoch: 5| Step: 5
Training loss: 1.481369137763977
Validation loss: 2.2436393052339554

Epoch: 5| Step: 6
Training loss: 2.517136812210083
Validation loss: 2.2512961626052856

Epoch: 5| Step: 7
Training loss: 1.368883490562439
Validation loss: 2.249559665719668

Epoch: 5| Step: 8
Training loss: 1.8305555582046509
Validation loss: 2.1870326548814774

Epoch: 5| Step: 9
Training loss: 1.6031529903411865
Validation loss: 2.1969307909409204

Epoch: 5| Step: 10
Training loss: 1.7049936056137085
Validation loss: 2.1962672571341195

Epoch: 5| Step: 11
Training loss: 2.0729236602783203
Validation loss: 2.174762636423111

Epoch: 288| Step: 0
Training loss: 1.8663276433944702
Validation loss: 2.169521992405256

Epoch: 5| Step: 1
Training loss: 1.6137897968292236
Validation loss: 2.1582181056340537

Epoch: 5| Step: 2
Training loss: 1.6918575763702393
Validation loss: 2.1669427206118903

Epoch: 5| Step: 3
Training loss: 1.7143466472625732
Validation loss: 2.162791430950165

Epoch: 5| Step: 4
Training loss: 1.2256262302398682
Validation loss: 2.1648134887218475

Epoch: 5| Step: 5
Training loss: 1.7910743951797485
Validation loss: 2.1344681481520333

Epoch: 5| Step: 6
Training loss: 2.0942928791046143
Validation loss: 2.1540980637073517

Epoch: 5| Step: 7
Training loss: 1.644273042678833
Validation loss: 2.1590349773565927

Epoch: 5| Step: 8
Training loss: 1.8599128723144531
Validation loss: 2.153288503487905

Epoch: 5| Step: 9
Training loss: 1.986751914024353
Validation loss: 2.137649784485499

Epoch: 5| Step: 10
Training loss: 1.449330449104309
Validation loss: 2.162889694174131

Epoch: 5| Step: 11
Training loss: 1.8936830759048462
Validation loss: 2.1481167872746787

Epoch: 289| Step: 0
Training loss: 1.7864692211151123
Validation loss: 2.170170267422994

Epoch: 5| Step: 1
Training loss: 1.3075145483016968
Validation loss: 2.176613748073578

Epoch: 5| Step: 2
Training loss: 1.5747259855270386
Validation loss: 2.1719439029693604

Epoch: 5| Step: 3
Training loss: 1.7758945226669312
Validation loss: 2.2080846379200616

Epoch: 5| Step: 4
Training loss: 1.2277939319610596
Validation loss: 2.1803867369890213

Epoch: 5| Step: 5
Training loss: 2.096360445022583
Validation loss: 2.165099397301674

Epoch: 5| Step: 6
Training loss: 1.8375126123428345
Validation loss: 2.175030047694842

Epoch: 5| Step: 7
Training loss: 1.7460525035858154
Validation loss: 2.1719929774602256

Epoch: 5| Step: 8
Training loss: 1.8022358417510986
Validation loss: 2.166204502185186

Epoch: 5| Step: 9
Training loss: 1.9468576908111572
Validation loss: 2.179706891377767

Epoch: 5| Step: 10
Training loss: 2.1538517475128174
Validation loss: 2.1677879641453424

Epoch: 5| Step: 11
Training loss: 1.6653728485107422
Validation loss: 2.161735008160273

Epoch: 290| Step: 0
Training loss: 2.1179511547088623
Validation loss: 2.166634907325109

Epoch: 5| Step: 1
Training loss: 1.5951731204986572
Validation loss: 2.17180867989858

Epoch: 5| Step: 2
Training loss: 1.8639390468597412
Validation loss: 2.169459323088328

Epoch: 5| Step: 3
Training loss: 1.8503040075302124
Validation loss: 2.1471326053142548

Epoch: 5| Step: 4
Training loss: 1.8341224193572998
Validation loss: 2.1413625379403434

Epoch: 5| Step: 5
Training loss: 1.8098560571670532
Validation loss: 2.1532390962044397

Epoch: 5| Step: 6
Training loss: 1.4477194547653198
Validation loss: 2.1551730930805206

Epoch: 5| Step: 7
Training loss: 1.525813341140747
Validation loss: 2.176748106877009

Epoch: 5| Step: 8
Training loss: 1.242384672164917
Validation loss: 2.1713278690973916

Epoch: 5| Step: 9
Training loss: 1.7303909063339233
Validation loss: 2.1710604975620904

Epoch: 5| Step: 10
Training loss: 1.7252025604248047
Validation loss: 2.169246877233187

Epoch: 5| Step: 11
Training loss: 1.375455617904663
Validation loss: 2.1666001925865808

Epoch: 291| Step: 0
Training loss: 1.6025489568710327
Validation loss: 2.1875865509112677

Epoch: 5| Step: 1
Training loss: 2.15828537940979
Validation loss: 2.1804981430371604

Epoch: 5| Step: 2
Training loss: 1.4961426258087158
Validation loss: 2.1648520628611245

Epoch: 5| Step: 3
Training loss: 1.39986252784729
Validation loss: 2.186008264621099

Epoch: 5| Step: 4
Training loss: 1.8725115060806274
Validation loss: 2.168092201153437

Epoch: 5| Step: 5
Training loss: 1.772957444190979
Validation loss: 2.1746858954429626

Epoch: 5| Step: 6
Training loss: 1.9160096645355225
Validation loss: 2.16151092449824

Epoch: 5| Step: 7
Training loss: 1.741987943649292
Validation loss: 2.1967036426067352

Epoch: 5| Step: 8
Training loss: 1.6639204025268555
Validation loss: 2.1945280333360038

Epoch: 5| Step: 9
Training loss: 1.2993204593658447
Validation loss: 2.174997886021932

Epoch: 5| Step: 10
Training loss: 1.6232330799102783
Validation loss: 2.199776162703832

Epoch: 5| Step: 11
Training loss: 1.5368256568908691
Validation loss: 2.1854992657899857

Epoch: 292| Step: 0
Training loss: 1.4344112873077393
Validation loss: 2.2005755603313446

Epoch: 5| Step: 1
Training loss: 1.3417457342147827
Validation loss: 2.1985338230927787

Epoch: 5| Step: 2
Training loss: 1.876155138015747
Validation loss: 2.1681977858146033

Epoch: 5| Step: 3
Training loss: 1.4876835346221924
Validation loss: 2.1555004914601645

Epoch: 5| Step: 4
Training loss: 2.3219943046569824
Validation loss: 2.1831079175074897

Epoch: 5| Step: 5
Training loss: 1.9762840270996094
Validation loss: 2.1675221423308053

Epoch: 5| Step: 6
Training loss: 1.5331608057022095
Validation loss: 2.1827728847662606

Epoch: 5| Step: 7
Training loss: 1.6011184453964233
Validation loss: 2.1839444239934287

Epoch: 5| Step: 8
Training loss: 2.082845687866211
Validation loss: 2.211972172061602

Epoch: 5| Step: 9
Training loss: 1.7928041219711304
Validation loss: 2.202178825934728

Epoch: 5| Step: 10
Training loss: 1.5540552139282227
Validation loss: 2.194968913992246

Epoch: 5| Step: 11
Training loss: 1.401659607887268
Validation loss: 2.2027204483747482

Epoch: 293| Step: 0
Training loss: 1.8270280361175537
Validation loss: 2.2052790274222693

Epoch: 5| Step: 1
Training loss: 1.6521265506744385
Validation loss: 2.187497769792875

Epoch: 5| Step: 2
Training loss: 1.8265225887298584
Validation loss: 2.16983363032341

Epoch: 5| Step: 3
Training loss: 1.7199032306671143
Validation loss: 2.180325229962667

Epoch: 5| Step: 4
Training loss: 1.6672289371490479
Validation loss: 2.204689770936966

Epoch: 5| Step: 5
Training loss: 1.4436662197113037
Validation loss: 2.177045524120331

Epoch: 5| Step: 6
Training loss: 1.6624915599822998
Validation loss: 2.171283404032389

Epoch: 5| Step: 7
Training loss: 2.1726558208465576
Validation loss: 2.2041364709536233

Epoch: 5| Step: 8
Training loss: 1.3442795276641846
Validation loss: 2.1830820937951407

Epoch: 5| Step: 9
Training loss: 1.780299186706543
Validation loss: 2.2014277229706445

Epoch: 5| Step: 10
Training loss: 1.6213182210922241
Validation loss: 2.1944682002067566

Epoch: 5| Step: 11
Training loss: 1.434893012046814
Validation loss: 2.185650492707888

Epoch: 294| Step: 0
Training loss: 1.4844251871109009
Validation loss: 2.173470144470533

Epoch: 5| Step: 1
Training loss: 1.4045932292938232
Validation loss: 2.187726154923439

Epoch: 5| Step: 2
Training loss: 1.6359150409698486
Validation loss: 2.2034756541252136

Epoch: 5| Step: 3
Training loss: 1.663558006286621
Validation loss: 2.1923817892869315

Epoch: 5| Step: 4
Training loss: 1.2311066389083862
Validation loss: 2.195414404074351

Epoch: 5| Step: 5
Training loss: 1.8473390340805054
Validation loss: 2.2146200438340506

Epoch: 5| Step: 6
Training loss: 1.4105041027069092
Validation loss: 2.1962065547704697

Epoch: 5| Step: 7
Training loss: 1.8927141427993774
Validation loss: 2.1913787623246512

Epoch: 5| Step: 8
Training loss: 1.4225764274597168
Validation loss: 2.1987185577551522

Epoch: 5| Step: 9
Training loss: 2.2227160930633545
Validation loss: 2.1749251186847687

Epoch: 5| Step: 10
Training loss: 1.9964401721954346
Validation loss: 2.151287997762362

Epoch: 5| Step: 11
Training loss: 2.8569092750549316
Validation loss: 2.191023046771685

Epoch: 295| Step: 0
Training loss: 1.331258773803711
Validation loss: 2.174831658601761

Epoch: 5| Step: 1
Training loss: 1.5836751461029053
Validation loss: 2.172520528237025

Epoch: 5| Step: 2
Training loss: 1.4833823442459106
Validation loss: 2.1719118456045785

Epoch: 5| Step: 3
Training loss: 1.744593620300293
Validation loss: 2.183353006839752

Epoch: 5| Step: 4
Training loss: 1.4191694259643555
Validation loss: 2.2008025348186493

Epoch: 5| Step: 5
Training loss: 1.688320517539978
Validation loss: 2.2062658170859017

Epoch: 5| Step: 6
Training loss: 1.6309163570404053
Validation loss: 2.2278874218463898

Epoch: 5| Step: 7
Training loss: 1.768986463546753
Validation loss: 2.223451261719068

Epoch: 5| Step: 8
Training loss: 2.2142333984375
Validation loss: 2.2300988286733627

Epoch: 5| Step: 9
Training loss: 1.9215419292449951
Validation loss: 2.2047631442546844

Epoch: 5| Step: 10
Training loss: 1.8574012517929077
Validation loss: 2.220033645629883

Epoch: 5| Step: 11
Training loss: 1.247499704360962
Validation loss: 2.230603223045667

Epoch: 296| Step: 0
Training loss: 1.752110481262207
Validation loss: 2.234489073355993

Epoch: 5| Step: 1
Training loss: 1.4374840259552002
Validation loss: 2.228561153014501

Epoch: 5| Step: 2
Training loss: 1.5566860437393188
Validation loss: 2.2641086975733438

Epoch: 5| Step: 3
Training loss: 1.5543044805526733
Validation loss: 2.250872532526652

Epoch: 5| Step: 4
Training loss: 1.9396030902862549
Validation loss: 2.201386342446009

Epoch: 5| Step: 5
Training loss: 1.5050454139709473
Validation loss: 2.21018585562706

Epoch: 5| Step: 6
Training loss: 1.81049382686615
Validation loss: 2.2240099708239236

Epoch: 5| Step: 7
Training loss: 1.798313856124878
Validation loss: 2.2065974374612174

Epoch: 5| Step: 8
Training loss: 1.7563049793243408
Validation loss: 2.189620559414228

Epoch: 5| Step: 9
Training loss: 1.8708431720733643
Validation loss: 2.21471099058787

Epoch: 5| Step: 10
Training loss: 1.6320759057998657
Validation loss: 2.2145991921424866

Epoch: 5| Step: 11
Training loss: 2.241241455078125
Validation loss: 2.206339637438456

Epoch: 297| Step: 0
Training loss: 1.3849594593048096
Validation loss: 2.2060626447200775

Epoch: 5| Step: 1
Training loss: 1.9451825618743896
Validation loss: 2.1797815461953483

Epoch: 5| Step: 2
Training loss: 1.486902117729187
Validation loss: 2.2171915769577026

Epoch: 5| Step: 3
Training loss: 1.5071182250976562
Validation loss: 2.1876244097948074

Epoch: 5| Step: 4
Training loss: 1.2171123027801514
Validation loss: 2.214453846216202

Epoch: 5| Step: 5
Training loss: 1.5930335521697998
Validation loss: 2.2039182682832084

Epoch: 5| Step: 6
Training loss: 1.7835605144500732
Validation loss: 2.226476098100344

Epoch: 5| Step: 7
Training loss: 1.7213557958602905
Validation loss: 2.215086057782173

Epoch: 5| Step: 8
Training loss: 1.6639823913574219
Validation loss: 2.2236107140779495

Epoch: 5| Step: 9
Training loss: 1.9233970642089844
Validation loss: 2.2281293670336404

Epoch: 5| Step: 10
Training loss: 1.6980394124984741
Validation loss: 2.225272128979365

Epoch: 5| Step: 11
Training loss: 1.3555430173873901
Validation loss: 2.2306225498517356

Epoch: 298| Step: 0
Training loss: 1.6913011074066162
Validation loss: 2.2146856437126794

Epoch: 5| Step: 1
Training loss: 1.6170170307159424
Validation loss: 2.211367050806681

Epoch: 5| Step: 2
Training loss: 1.0662000179290771
Validation loss: 2.2159894158442817

Epoch: 5| Step: 3
Training loss: 1.1496572494506836
Validation loss: 2.1811333100001016

Epoch: 5| Step: 4
Training loss: 2.359145402908325
Validation loss: 2.195653423666954

Epoch: 5| Step: 5
Training loss: 2.020183563232422
Validation loss: 2.2087397476037345

Epoch: 5| Step: 6
Training loss: 2.0028343200683594
Validation loss: 2.194883813460668

Epoch: 5| Step: 7
Training loss: 1.5816304683685303
Validation loss: 2.1769752502441406

Epoch: 5| Step: 8
Training loss: 1.8749275207519531
Validation loss: 2.185796116789182

Epoch: 5| Step: 9
Training loss: 1.243843913078308
Validation loss: 2.1894843926032386

Epoch: 5| Step: 10
Training loss: 1.2881373167037964
Validation loss: 2.171653484304746

Epoch: 5| Step: 11
Training loss: 1.9120762348175049
Validation loss: 2.1839379916588464

Epoch: 299| Step: 0
Training loss: 1.3635189533233643
Validation loss: 2.173140898346901

Epoch: 5| Step: 1
Training loss: 1.7840182781219482
Validation loss: 2.1852708905935287

Epoch: 5| Step: 2
Training loss: 1.906469702720642
Validation loss: 2.1807659417390823

Epoch: 5| Step: 3
Training loss: 1.6749870777130127
Validation loss: 2.175401876370112

Epoch: 5| Step: 4
Training loss: 1.4688693284988403
Validation loss: 2.2048578510681787

Epoch: 5| Step: 5
Training loss: 1.930124282836914
Validation loss: 2.206813911596934

Epoch: 5| Step: 6
Training loss: 1.8921114206314087
Validation loss: 2.210823714733124

Epoch: 5| Step: 7
Training loss: 1.5126063823699951
Validation loss: 2.1713815877834954

Epoch: 5| Step: 8
Training loss: 1.3008320331573486
Validation loss: 2.1870688994725547

Epoch: 5| Step: 9
Training loss: 1.7756881713867188
Validation loss: 2.2084762950738273

Epoch: 5| Step: 10
Training loss: 1.8938357830047607
Validation loss: 2.1843133171399436

Epoch: 5| Step: 11
Training loss: 1.0152720212936401
Validation loss: 2.205175439516703

Epoch: 300| Step: 0
Training loss: 1.541476845741272
Validation loss: 2.178214048345884

Epoch: 5| Step: 1
Training loss: 2.0647785663604736
Validation loss: 2.1827599505583444

Epoch: 5| Step: 2
Training loss: 1.4272793531417847
Validation loss: 2.200945590933164

Epoch: 5| Step: 3
Training loss: 1.4754536151885986
Validation loss: 2.188025097052256

Epoch: 5| Step: 4
Training loss: 1.5608361959457397
Validation loss: 2.172471816341082

Epoch: 5| Step: 5
Training loss: 1.9832782745361328
Validation loss: 2.169272060195605

Epoch: 5| Step: 6
Training loss: 1.7811546325683594
Validation loss: 2.1743554174900055

Epoch: 5| Step: 7
Training loss: 0.9751693606376648
Validation loss: 2.1750046660502753

Epoch: 5| Step: 8
Training loss: 1.8057811260223389
Validation loss: 2.211818436781565

Epoch: 5| Step: 9
Training loss: 1.918503999710083
Validation loss: 2.1959747026364007

Epoch: 5| Step: 10
Training loss: 1.484442949295044
Validation loss: 2.1909643014272056

Epoch: 5| Step: 11
Training loss: 1.9875625371932983
Validation loss: 2.1702364534139633

Epoch: 301| Step: 0
Training loss: 1.777259111404419
Validation loss: 2.179874320824941

Epoch: 5| Step: 1
Training loss: 1.548051118850708
Validation loss: 2.182225892941157

Epoch: 5| Step: 2
Training loss: 2.1958305835723877
Validation loss: 2.168634141484896

Epoch: 5| Step: 3
Training loss: 1.1236474514007568
Validation loss: 2.1621475418408713

Epoch: 5| Step: 4
Training loss: 1.5374383926391602
Validation loss: 2.171253581841787

Epoch: 5| Step: 5
Training loss: 2.221649408340454
Validation loss: 2.1588546683390937

Epoch: 5| Step: 6
Training loss: 1.4949544668197632
Validation loss: 2.1614934553702674

Epoch: 5| Step: 7
Training loss: 1.2403827905654907
Validation loss: 2.1764428665240607

Epoch: 5| Step: 8
Training loss: 1.7489410638809204
Validation loss: 2.173988918463389

Epoch: 5| Step: 9
Training loss: 1.8565824031829834
Validation loss: 2.229595532019933

Epoch: 5| Step: 10
Training loss: 1.57546067237854
Validation loss: 2.209634313980738

Epoch: 5| Step: 11
Training loss: 1.0076684951782227
Validation loss: 2.217842400074005

Epoch: 302| Step: 0
Training loss: 1.9673728942871094
Validation loss: 2.2182928025722504

Epoch: 5| Step: 1
Training loss: 1.4274694919586182
Validation loss: 2.204765275120735

Epoch: 5| Step: 2
Training loss: 1.4051414728164673
Validation loss: 2.2068584312995276

Epoch: 5| Step: 3
Training loss: 1.5787708759307861
Validation loss: 2.192222222685814

Epoch: 5| Step: 4
Training loss: 1.3323506116867065
Validation loss: 2.184367428223292

Epoch: 5| Step: 5
Training loss: 1.7749354839324951
Validation loss: 2.1740047285954156

Epoch: 5| Step: 6
Training loss: 1.897387146949768
Validation loss: 2.1742005000511804

Epoch: 5| Step: 7
Training loss: 1.244145393371582
Validation loss: 2.176123480002085

Epoch: 5| Step: 8
Training loss: 1.954636812210083
Validation loss: 2.177247221271197

Epoch: 5| Step: 9
Training loss: 2.139850378036499
Validation loss: 2.1769054532051086

Epoch: 5| Step: 10
Training loss: 1.3525235652923584
Validation loss: 2.168740456302961

Epoch: 5| Step: 11
Training loss: 1.758682131767273
Validation loss: 2.1941009958585105

Epoch: 303| Step: 0
Training loss: 1.9114631414413452
Validation loss: 2.192620332042376

Epoch: 5| Step: 1
Training loss: 0.6596503853797913
Validation loss: 2.2016094426314035

Epoch: 5| Step: 2
Training loss: 2.109642505645752
Validation loss: 2.2066458811362586

Epoch: 5| Step: 3
Training loss: 1.885278344154358
Validation loss: 2.22749026119709

Epoch: 5| Step: 4
Training loss: 2.014219284057617
Validation loss: 2.219142109155655

Epoch: 5| Step: 5
Training loss: 1.8019863367080688
Validation loss: 2.2286929140488305

Epoch: 5| Step: 6
Training loss: 1.8376070261001587
Validation loss: 2.2407349894444146

Epoch: 5| Step: 7
Training loss: 1.430830717086792
Validation loss: 2.2288961112499237

Epoch: 5| Step: 8
Training loss: 1.544569492340088
Validation loss: 2.251850724220276

Epoch: 5| Step: 9
Training loss: 1.8872079849243164
Validation loss: 2.2377636283636093

Epoch: 5| Step: 10
Training loss: 1.1957414150238037
Validation loss: 2.258342057466507

Epoch: 5| Step: 11
Training loss: 1.0998305082321167
Validation loss: 2.219813754161199

Epoch: 304| Step: 0
Training loss: 1.7070258855819702
Validation loss: 2.2319371551275253

Epoch: 5| Step: 1
Training loss: 1.2564069032669067
Validation loss: 2.2251266787449517

Epoch: 5| Step: 2
Training loss: 1.4494799375534058
Validation loss: 2.235533515612284

Epoch: 5| Step: 3
Training loss: 1.9841734170913696
Validation loss: 2.2393513917922974

Epoch: 5| Step: 4
Training loss: 1.5648114681243896
Validation loss: 2.2191779414812722

Epoch: 5| Step: 5
Training loss: 1.6547731161117554
Validation loss: 2.2348327338695526

Epoch: 5| Step: 6
Training loss: 1.8040117025375366
Validation loss: 2.2227569272120795

Epoch: 5| Step: 7
Training loss: 1.5030183792114258
Validation loss: 2.2025520404179892

Epoch: 5| Step: 8
Training loss: 1.976506233215332
Validation loss: 2.2247289369503656

Epoch: 5| Step: 9
Training loss: 1.8920990228652954
Validation loss: 2.2085057695706687

Epoch: 5| Step: 10
Training loss: 1.2561635971069336
Validation loss: 2.2116421461105347

Epoch: 5| Step: 11
Training loss: 1.5627069473266602
Validation loss: 2.200583597024282

Epoch: 305| Step: 0
Training loss: 2.2425403594970703
Validation loss: 2.1786660154660544

Epoch: 5| Step: 1
Training loss: 1.8355928659439087
Validation loss: 2.182414491971334

Epoch: 5| Step: 2
Training loss: 1.9636768102645874
Validation loss: 2.1799110422531762

Epoch: 5| Step: 3
Training loss: 1.6524288654327393
Validation loss: 2.1810038735469184

Epoch: 5| Step: 4
Training loss: 1.4475970268249512
Validation loss: 2.198732912540436

Epoch: 5| Step: 5
Training loss: 1.5813530683517456
Validation loss: 2.204956447084745

Epoch: 5| Step: 6
Training loss: 0.8847416639328003
Validation loss: 2.1869042416413627

Epoch: 5| Step: 7
Training loss: 1.2609363794326782
Validation loss: 2.207615375518799

Epoch: 5| Step: 8
Training loss: 1.5347745418548584
Validation loss: 2.2061623434225717

Epoch: 5| Step: 9
Training loss: 1.2020337581634521
Validation loss: 2.1751764019330344

Epoch: 5| Step: 10
Training loss: 2.0905776023864746
Validation loss: 2.195235292116801

Epoch: 5| Step: 11
Training loss: 2.4594004154205322
Validation loss: 2.167539725701014

Epoch: 306| Step: 0
Training loss: 1.9662328958511353
Validation loss: 2.2107840875784555

Epoch: 5| Step: 1
Training loss: 1.801217794418335
Validation loss: 2.1618009010950723

Epoch: 5| Step: 2
Training loss: 2.2800471782684326
Validation loss: 2.1793982088565826

Epoch: 5| Step: 3
Training loss: 1.5547164678573608
Validation loss: 2.1737919747829437

Epoch: 5| Step: 4
Training loss: 1.1565213203430176
Validation loss: 2.1869610647360482

Epoch: 5| Step: 5
Training loss: 1.173218011856079
Validation loss: 2.1613225638866425

Epoch: 5| Step: 6
Training loss: 1.1971008777618408
Validation loss: 2.164153536160787

Epoch: 5| Step: 7
Training loss: 1.8460056781768799
Validation loss: 2.155112365881602

Epoch: 5| Step: 8
Training loss: 1.8798563480377197
Validation loss: 2.1538579016923904

Epoch: 5| Step: 9
Training loss: 1.3051303625106812
Validation loss: 2.1553870290517807

Epoch: 5| Step: 10
Training loss: 1.5622671842575073
Validation loss: 2.1674775381882987

Epoch: 5| Step: 11
Training loss: 1.1300947666168213
Validation loss: 2.154566099246343

Epoch: 307| Step: 0
Training loss: 1.4721109867095947
Validation loss: 2.148942619562149

Epoch: 5| Step: 1
Training loss: 1.38899827003479
Validation loss: 2.1458901862303414

Epoch: 5| Step: 2
Training loss: 2.235919237136841
Validation loss: 2.177834078669548

Epoch: 5| Step: 3
Training loss: 2.0822503566741943
Validation loss: 2.1662270774443946

Epoch: 5| Step: 4
Training loss: 1.6752742528915405
Validation loss: 2.1819433669249215

Epoch: 5| Step: 5
Training loss: 1.3799768686294556
Validation loss: 2.1741182108720145

Epoch: 5| Step: 6
Training loss: 1.5024279356002808
Validation loss: 2.183658167719841

Epoch: 5| Step: 7
Training loss: 1.4710791110992432
Validation loss: 2.1940943698088327

Epoch: 5| Step: 8
Training loss: 1.3960236310958862
Validation loss: 2.205933690071106

Epoch: 5| Step: 9
Training loss: 1.243640661239624
Validation loss: 2.1984642247358956

Epoch: 5| Step: 10
Training loss: 1.7936184406280518
Validation loss: 2.2089434762795768

Epoch: 5| Step: 11
Training loss: 0.6973391175270081
Validation loss: 2.205676426490148

Epoch: 308| Step: 0
Training loss: 2.4604299068450928
Validation loss: 2.2027719666560492

Epoch: 5| Step: 1
Training loss: 1.6785424947738647
Validation loss: 2.2034247666597366

Epoch: 5| Step: 2
Training loss: 0.9778223037719727
Validation loss: 2.2121371825536094

Epoch: 5| Step: 3
Training loss: 1.4129447937011719
Validation loss: 2.199743707974752

Epoch: 5| Step: 4
Training loss: 1.591970682144165
Validation loss: 2.1942296028137207

Epoch: 5| Step: 5
Training loss: 1.9367835521697998
Validation loss: 2.174686630566915

Epoch: 5| Step: 6
Training loss: 1.4868651628494263
Validation loss: 2.186281055212021

Epoch: 5| Step: 7
Training loss: 1.2333320379257202
Validation loss: 2.1700239926576614

Epoch: 5| Step: 8
Training loss: 1.6079295873641968
Validation loss: 2.1873460014661155

Epoch: 5| Step: 9
Training loss: 1.366969108581543
Validation loss: 2.1837944785753884

Epoch: 5| Step: 10
Training loss: 2.1640095710754395
Validation loss: 2.163250063856443

Epoch: 5| Step: 11
Training loss: 1.1615993976593018
Validation loss: 2.1641466319561005

Epoch: 309| Step: 0
Training loss: 1.974176049232483
Validation loss: 2.157347400983175

Epoch: 5| Step: 1
Training loss: 2.46821928024292
Validation loss: 2.1616609394550323

Epoch: 5| Step: 2
Training loss: 0.9243555068969727
Validation loss: 2.1720362404982247

Epoch: 5| Step: 3
Training loss: 1.530550241470337
Validation loss: 2.1626120706399283

Epoch: 5| Step: 4
Training loss: 2.1809229850769043
Validation loss: 2.1397988200187683

Epoch: 5| Step: 5
Training loss: 1.308946967124939
Validation loss: 2.1420354743798575

Epoch: 5| Step: 6
Training loss: 1.523276686668396
Validation loss: 2.1572893261909485

Epoch: 5| Step: 7
Training loss: 1.1691733598709106
Validation loss: 2.163716966907183

Epoch: 5| Step: 8
Training loss: 1.7076209783554077
Validation loss: 2.196243936816851

Epoch: 5| Step: 9
Training loss: 1.8574737310409546
Validation loss: 2.176901400089264

Epoch: 5| Step: 10
Training loss: 1.4146978855133057
Validation loss: 2.1709759334723153

Epoch: 5| Step: 11
Training loss: 1.6304353475570679
Validation loss: 2.193286289771398

Epoch: 310| Step: 0
Training loss: 1.8561607599258423
Validation loss: 2.191324154535929

Epoch: 5| Step: 1
Training loss: 1.042182207107544
Validation loss: 2.2013683517773948

Epoch: 5| Step: 2
Training loss: 1.8404624462127686
Validation loss: 2.205421174565951

Epoch: 5| Step: 3
Training loss: 1.6592460870742798
Validation loss: 2.1764545341332755

Epoch: 5| Step: 4
Training loss: 1.8891332149505615
Validation loss: 2.211821436882019

Epoch: 5| Step: 5
Training loss: 1.6661208868026733
Validation loss: 2.1910655995210013

Epoch: 5| Step: 6
Training loss: 1.7639625072479248
Validation loss: 2.169667308529218

Epoch: 5| Step: 7
Training loss: 2.0611088275909424
Validation loss: 2.1822236478328705

Epoch: 5| Step: 8
Training loss: 1.6745134592056274
Validation loss: 2.155273507038752

Epoch: 5| Step: 9
Training loss: 1.3827944993972778
Validation loss: 2.1568628003199897

Epoch: 5| Step: 10
Training loss: 0.9847957491874695
Validation loss: 2.1699980398019156

Epoch: 5| Step: 11
Training loss: 0.9849547147750854
Validation loss: 2.175612206260363

Epoch: 311| Step: 0
Training loss: 1.6764190196990967
Validation loss: 2.1786087850729623

Epoch: 5| Step: 1
Training loss: 1.356195092201233
Validation loss: 2.2177204688390098

Epoch: 5| Step: 2
Training loss: 1.434698462486267
Validation loss: 2.2321827660004296

Epoch: 5| Step: 3
Training loss: 1.8628997802734375
Validation loss: 2.2156572192907333

Epoch: 5| Step: 4
Training loss: 1.632333755493164
Validation loss: 2.2193219860394797

Epoch: 5| Step: 5
Training loss: 1.2692182064056396
Validation loss: 2.214604248603185

Epoch: 5| Step: 6
Training loss: 1.4476200342178345
Validation loss: 2.2124778578678765

Epoch: 5| Step: 7
Training loss: 2.258732557296753
Validation loss: 2.207992066939672

Epoch: 5| Step: 8
Training loss: 1.3810231685638428
Validation loss: 2.213489184776942

Epoch: 5| Step: 9
Training loss: 1.892486572265625
Validation loss: 2.1693868885437646

Epoch: 5| Step: 10
Training loss: 2.217266798019409
Validation loss: 2.176370124022166

Epoch: 5| Step: 11
Training loss: 1.3921897411346436
Validation loss: 2.160549392302831

Epoch: 312| Step: 0
Training loss: 1.5325124263763428
Validation loss: 2.15784353017807

Epoch: 5| Step: 1
Training loss: 1.4759480953216553
Validation loss: 2.175972724954287

Epoch: 5| Step: 2
Training loss: 1.7534592151641846
Validation loss: 2.1772484531005225

Epoch: 5| Step: 3
Training loss: 1.4644062519073486
Validation loss: 2.192939430475235

Epoch: 5| Step: 4
Training loss: 1.5475103855133057
Validation loss: 2.1768325567245483

Epoch: 5| Step: 5
Training loss: 1.9949655532836914
Validation loss: 2.196334878603617

Epoch: 5| Step: 6
Training loss: 1.3629835844039917
Validation loss: 2.169647455215454

Epoch: 5| Step: 7
Training loss: 1.3261219263076782
Validation loss: 2.188728133837382

Epoch: 5| Step: 8
Training loss: 1.7081667184829712
Validation loss: 2.210743402441343

Epoch: 5| Step: 9
Training loss: 1.9418449401855469
Validation loss: 2.21037395298481

Epoch: 5| Step: 10
Training loss: 1.8368995189666748
Validation loss: 2.214399809638659

Epoch: 5| Step: 11
Training loss: 1.1385881900787354
Validation loss: 2.240316500266393

Epoch: 313| Step: 0
Training loss: 1.6319373846054077
Validation loss: 2.238795797030131

Epoch: 5| Step: 1
Training loss: 1.573445200920105
Validation loss: 2.2516830066839852

Epoch: 5| Step: 2
Training loss: 1.9503593444824219
Validation loss: 2.2444077332814536

Epoch: 5| Step: 3
Training loss: 1.5530022382736206
Validation loss: 2.2521031498908997

Epoch: 5| Step: 4
Training loss: 2.069441318511963
Validation loss: 2.2417737493912377

Epoch: 5| Step: 5
Training loss: 1.766340970993042
Validation loss: 2.272576332092285

Epoch: 5| Step: 6
Training loss: 1.4868109226226807
Validation loss: 2.236510048309962

Epoch: 5| Step: 7
Training loss: 2.0003161430358887
Validation loss: 2.227296933531761

Epoch: 5| Step: 8
Training loss: 1.3574788570404053
Validation loss: 2.188316618402799

Epoch: 5| Step: 9
Training loss: 1.3302515745162964
Validation loss: 2.225398783882459

Epoch: 5| Step: 10
Training loss: 1.3313212394714355
Validation loss: 2.2149060865243277

Epoch: 5| Step: 11
Training loss: 2.9834794998168945
Validation loss: 2.183827449878057

Epoch: 314| Step: 0
Training loss: 1.8568280935287476
Validation loss: 2.1723629037539163

Epoch: 5| Step: 1
Training loss: 1.215344786643982
Validation loss: 2.2061820179224014

Epoch: 5| Step: 2
Training loss: 1.8840357065200806
Validation loss: 2.1789391189813614

Epoch: 5| Step: 3
Training loss: 1.6308667659759521
Validation loss: 2.1453073670466742

Epoch: 5| Step: 4
Training loss: 1.4084229469299316
Validation loss: 2.1654412895441055

Epoch: 5| Step: 5
Training loss: 1.5893452167510986
Validation loss: 2.1839001029729843

Epoch: 5| Step: 6
Training loss: 1.3352582454681396
Validation loss: 2.1508749624093375

Epoch: 5| Step: 7
Training loss: 1.5323636531829834
Validation loss: 2.157662789026896

Epoch: 5| Step: 8
Training loss: 1.6130857467651367
Validation loss: 2.177621285120646

Epoch: 5| Step: 9
Training loss: 1.9830825328826904
Validation loss: 2.16700908044974

Epoch: 5| Step: 10
Training loss: 1.8337032794952393
Validation loss: 2.1501498768726983

Epoch: 5| Step: 11
Training loss: 2.0710718631744385
Validation loss: 2.1711386690537133

Epoch: 315| Step: 0
Training loss: 1.4793226718902588
Validation loss: 2.1532091995080314

Epoch: 5| Step: 1
Training loss: 1.265114665031433
Validation loss: 2.1661522885163627

Epoch: 5| Step: 2
Training loss: 2.1127398014068604
Validation loss: 2.176892807086309

Epoch: 5| Step: 3
Training loss: 1.394903302192688
Validation loss: 2.1796828707059226

Epoch: 5| Step: 4
Training loss: 1.8193203210830688
Validation loss: 2.18611149986585

Epoch: 5| Step: 5
Training loss: 1.980607032775879
Validation loss: 2.1985004792610803

Epoch: 5| Step: 6
Training loss: 1.415898084640503
Validation loss: 2.1962831715742746

Epoch: 5| Step: 7
Training loss: 1.4468443393707275
Validation loss: 2.187694251537323

Epoch: 5| Step: 8
Training loss: 1.3545032739639282
Validation loss: 2.2068246404329934

Epoch: 5| Step: 9
Training loss: 1.872043251991272
Validation loss: 2.2249829073747

Epoch: 5| Step: 10
Training loss: 1.5092861652374268
Validation loss: 2.243302802244822

Epoch: 5| Step: 11
Training loss: 2.374131679534912
Validation loss: 2.2037910918394723

Epoch: 316| Step: 0
Training loss: 1.7713741064071655
Validation loss: 2.2510935415824256

Epoch: 5| Step: 1
Training loss: 1.5077823400497437
Validation loss: 2.236928110321363

Epoch: 5| Step: 2
Training loss: 1.5071474313735962
Validation loss: 2.2091462314128876

Epoch: 5| Step: 3
Training loss: 1.7881650924682617
Validation loss: 2.2316038608551025

Epoch: 5| Step: 4
Training loss: 1.593648076057434
Validation loss: 2.2055802990992865

Epoch: 5| Step: 5
Training loss: 1.7738878726959229
Validation loss: 2.1952892541885376

Epoch: 5| Step: 6
Training loss: 0.7982221841812134
Validation loss: 2.1916462580362954

Epoch: 5| Step: 7
Training loss: 1.8897802829742432
Validation loss: 2.1662546197573342

Epoch: 5| Step: 8
Training loss: 1.9628016948699951
Validation loss: 2.16346882780393

Epoch: 5| Step: 9
Training loss: 1.4860926866531372
Validation loss: 2.165606732169787

Epoch: 5| Step: 10
Training loss: 1.155038833618164
Validation loss: 2.182003597418467

Epoch: 5| Step: 11
Training loss: 3.2297215461730957
Validation loss: 2.1797957768042884

Epoch: 317| Step: 0
Training loss: 2.3424766063690186
Validation loss: 2.180767069260279

Epoch: 5| Step: 1
Training loss: 1.817887306213379
Validation loss: 2.160450811187426

Epoch: 5| Step: 2
Training loss: 1.1653048992156982
Validation loss: 2.1659207989772162

Epoch: 5| Step: 3
Training loss: 1.0989784002304077
Validation loss: 2.163756092389425

Epoch: 5| Step: 4
Training loss: 1.349344253540039
Validation loss: 2.1607263733943305

Epoch: 5| Step: 5
Training loss: 1.7806236743927002
Validation loss: 2.180567115545273

Epoch: 5| Step: 6
Training loss: 1.5262864828109741
Validation loss: 2.1678928832213082

Epoch: 5| Step: 7
Training loss: 1.5744022130966187
Validation loss: 2.2246916592121124

Epoch: 5| Step: 8
Training loss: 2.5402915477752686
Validation loss: 2.21108670035998

Epoch: 5| Step: 9
Training loss: 1.525299310684204
Validation loss: 2.2163145393133163

Epoch: 5| Step: 10
Training loss: 2.259787082672119
Validation loss: 2.2188679625590644

Epoch: 5| Step: 11
Training loss: 1.6924293041229248
Validation loss: 2.1969592769940696

Epoch: 318| Step: 0
Training loss: 2.0606813430786133
Validation loss: 2.190470968683561

Epoch: 5| Step: 1
Training loss: 1.3471304178237915
Validation loss: 2.1932142476240792

Epoch: 5| Step: 2
Training loss: 1.4249870777130127
Validation loss: 2.17350401977698

Epoch: 5| Step: 3
Training loss: 1.4235481023788452
Validation loss: 2.1526983877023063

Epoch: 5| Step: 4
Training loss: 2.083489418029785
Validation loss: 2.166076958179474

Epoch: 5| Step: 5
Training loss: 1.2074730396270752
Validation loss: 2.158034230271975

Epoch: 5| Step: 6
Training loss: 1.2900290489196777
Validation loss: 2.1494693408409753

Epoch: 5| Step: 7
Training loss: 2.137331247329712
Validation loss: 2.177748034397761

Epoch: 5| Step: 8
Training loss: 1.1300233602523804
Validation loss: 2.175586630900701

Epoch: 5| Step: 9
Training loss: 2.477973461151123
Validation loss: 2.1673660775025687

Epoch: 5| Step: 10
Training loss: 1.6051288843154907
Validation loss: 2.1740490843852363

Epoch: 5| Step: 11
Training loss: 1.0354031324386597
Validation loss: 2.2211475720008216

Epoch: 319| Step: 0
Training loss: 1.1223905086517334
Validation loss: 2.192718734343847

Epoch: 5| Step: 1
Training loss: 1.175430417060852
Validation loss: 2.179587776462237

Epoch: 5| Step: 2
Training loss: 1.1949827671051025
Validation loss: 2.216533193985621

Epoch: 5| Step: 3
Training loss: 1.539870023727417
Validation loss: 2.1942833165327706

Epoch: 5| Step: 4
Training loss: 2.4410204887390137
Validation loss: 2.2073069314161935

Epoch: 5| Step: 5
Training loss: 1.7694790363311768
Validation loss: 2.21042171617349

Epoch: 5| Step: 6
Training loss: 1.1698641777038574
Validation loss: 2.212726836403211

Epoch: 5| Step: 7
Training loss: 1.8903992176055908
Validation loss: 2.195349082350731

Epoch: 5| Step: 8
Training loss: 1.571919560432434
Validation loss: 2.2133301397164664

Epoch: 5| Step: 9
Training loss: 1.7834182977676392
Validation loss: 2.2035867224136987

Epoch: 5| Step: 10
Training loss: 2.1929447650909424
Validation loss: 2.2100145469109216

Epoch: 5| Step: 11
Training loss: 1.169350028038025
Validation loss: 2.2221690764029822

Epoch: 320| Step: 0
Training loss: 1.742780089378357
Validation loss: 2.2240579575300217

Epoch: 5| Step: 1
Training loss: 1.279736042022705
Validation loss: 2.2149939437707267

Epoch: 5| Step: 2
Training loss: 1.813714623451233
Validation loss: 2.2232027451197305

Epoch: 5| Step: 3
Training loss: 1.2771543264389038
Validation loss: 2.2429684350887933

Epoch: 5| Step: 4
Training loss: 2.441469192504883
Validation loss: 2.222619970639547

Epoch: 5| Step: 5
Training loss: 1.5612386465072632
Validation loss: 2.227015713850657

Epoch: 5| Step: 6
Training loss: 1.4580185413360596
Validation loss: 2.2369047552347183

Epoch: 5| Step: 7
Training loss: 1.592281699180603
Validation loss: 2.261310428380966

Epoch: 5| Step: 8
Training loss: 1.4162018299102783
Validation loss: 2.2527714471022287

Epoch: 5| Step: 9
Training loss: 1.588539719581604
Validation loss: 2.247666597366333

Epoch: 5| Step: 10
Training loss: 1.4135010242462158
Validation loss: 2.253823166092237

Epoch: 5| Step: 11
Training loss: 0.7678004503250122
Validation loss: 2.259424244364103

Epoch: 321| Step: 0
Training loss: 1.6409695148468018
Validation loss: 2.2701694667339325

Epoch: 5| Step: 1
Training loss: 1.7845265865325928
Validation loss: 2.2806521405776343

Epoch: 5| Step: 2
Training loss: 1.3770763874053955
Validation loss: 2.24864033361276

Epoch: 5| Step: 3
Training loss: 1.7741470336914062
Validation loss: 2.248126193881035

Epoch: 5| Step: 4
Training loss: 1.4720755815505981
Validation loss: 2.2540707141160965

Epoch: 5| Step: 5
Training loss: 1.8142998218536377
Validation loss: 2.2428057392438254

Epoch: 5| Step: 6
Training loss: 1.2609407901763916
Validation loss: 2.2305954545736313

Epoch: 5| Step: 7
Training loss: 0.9453733563423157
Validation loss: 2.21854704618454

Epoch: 5| Step: 8
Training loss: 1.772592306137085
Validation loss: 2.2198244482278824

Epoch: 5| Step: 9
Training loss: 1.6773128509521484
Validation loss: 2.2028037011623383

Epoch: 5| Step: 10
Training loss: 1.6996486186981201
Validation loss: 2.2264737437168756

Epoch: 5| Step: 11
Training loss: 1.5353201627731323
Validation loss: 2.1973896622657776

Epoch: 322| Step: 0
Training loss: 1.6181201934814453
Validation loss: 2.1939134101072946

Epoch: 5| Step: 1
Training loss: 2.3934199810028076
Validation loss: 2.1628108074267707

Epoch: 5| Step: 2
Training loss: 1.506718635559082
Validation loss: 2.179862474401792

Epoch: 5| Step: 3
Training loss: 1.2104991674423218
Validation loss: 2.1875022798776627

Epoch: 5| Step: 4
Training loss: 1.5799190998077393
Validation loss: 2.1720639715592065

Epoch: 5| Step: 5
Training loss: 1.4284477233886719
Validation loss: 2.172153025865555

Epoch: 5| Step: 6
Training loss: 1.383970022201538
Validation loss: 2.1757307996352515

Epoch: 5| Step: 7
Training loss: 2.139761447906494
Validation loss: 2.201951245466868

Epoch: 5| Step: 8
Training loss: 1.3558645248413086
Validation loss: 2.1897348165512085

Epoch: 5| Step: 9
Training loss: 0.9869810342788696
Validation loss: 2.1862247238556543

Epoch: 5| Step: 10
Training loss: 1.6289126873016357
Validation loss: 2.2193569242954254

Epoch: 5| Step: 11
Training loss: 1.1056636571884155
Validation loss: 2.217022478580475

Epoch: 323| Step: 0
Training loss: 1.5126280784606934
Validation loss: 2.239968885978063

Epoch: 5| Step: 1
Training loss: 1.850701928138733
Validation loss: 2.204734593629837

Epoch: 5| Step: 2
Training loss: 1.0614376068115234
Validation loss: 2.2189564953247705

Epoch: 5| Step: 3
Training loss: 1.4898993968963623
Validation loss: 2.2327618400255838

Epoch: 5| Step: 4
Training loss: 1.4536335468292236
Validation loss: 2.2133532812198005

Epoch: 5| Step: 5
Training loss: 1.8740440607070923
Validation loss: 2.2453819513320923

Epoch: 5| Step: 6
Training loss: 1.3387887477874756
Validation loss: 2.209346796075503

Epoch: 5| Step: 7
Training loss: 1.1811925172805786
Validation loss: 2.2313052167495093

Epoch: 5| Step: 8
Training loss: 1.6223417520523071
Validation loss: 2.226946214834849

Epoch: 5| Step: 9
Training loss: 2.0629451274871826
Validation loss: 2.2150719861189523

Epoch: 5| Step: 10
Training loss: 2.1659648418426514
Validation loss: 2.223090410232544

Epoch: 5| Step: 11
Training loss: 1.3840153217315674
Validation loss: 2.2004645566145578

Epoch: 324| Step: 0
Training loss: 1.3395342826843262
Validation loss: 2.2136426071325936

Epoch: 5| Step: 1
Training loss: 1.8182176351547241
Validation loss: 2.2098698168992996

Epoch: 5| Step: 2
Training loss: 1.4788602590560913
Validation loss: 2.19783062239488

Epoch: 5| Step: 3
Training loss: 1.7359797954559326
Validation loss: 2.1976308276255927

Epoch: 5| Step: 4
Training loss: 1.5022187232971191
Validation loss: 2.1975928445657096

Epoch: 5| Step: 5
Training loss: 1.1174864768981934
Validation loss: 2.2170569052298865

Epoch: 5| Step: 6
Training loss: 1.7027690410614014
Validation loss: 2.2166119118531546

Epoch: 5| Step: 7
Training loss: 1.3639856576919556
Validation loss: 2.1966800888379416

Epoch: 5| Step: 8
Training loss: 1.647046685218811
Validation loss: 2.213663955529531

Epoch: 5| Step: 9
Training loss: 1.6617090702056885
Validation loss: 2.206234872341156

Epoch: 5| Step: 10
Training loss: 1.561906099319458
Validation loss: 2.202632173895836

Epoch: 5| Step: 11
Training loss: 1.4459311962127686
Validation loss: 2.204304317633311

Epoch: 325| Step: 0
Training loss: 1.3985579013824463
Validation loss: 2.200923209389051

Epoch: 5| Step: 1
Training loss: 1.6242306232452393
Validation loss: 2.179641996820768

Epoch: 5| Step: 2
Training loss: 1.4501855373382568
Validation loss: 2.2189573844273887

Epoch: 5| Step: 3
Training loss: 1.7060788869857788
Validation loss: 2.2218025227387748

Epoch: 5| Step: 4
Training loss: 1.7977546453475952
Validation loss: 2.219989389181137

Epoch: 5| Step: 5
Training loss: 1.9095577001571655
Validation loss: 2.1846892734368644

Epoch: 5| Step: 6
Training loss: 1.0417107343673706
Validation loss: 2.201313982407252

Epoch: 5| Step: 7
Training loss: 2.220369815826416
Validation loss: 2.1823884646097818

Epoch: 5| Step: 8
Training loss: 1.749541997909546
Validation loss: 2.188552737236023

Epoch: 5| Step: 9
Training loss: 1.4290887117385864
Validation loss: 2.1936196784178414

Epoch: 5| Step: 10
Training loss: 1.4678786993026733
Validation loss: 2.227703496813774

Epoch: 5| Step: 11
Training loss: 1.3891520500183105
Validation loss: 2.217099606990814

Epoch: 326| Step: 0
Training loss: 2.0457749366760254
Validation loss: 2.207385947306951

Epoch: 5| Step: 1
Training loss: 1.5560057163238525
Validation loss: 2.2205260694026947

Epoch: 5| Step: 2
Training loss: 2.1534650325775146
Validation loss: 2.2038213262955346

Epoch: 5| Step: 3
Training loss: 0.9006360173225403
Validation loss: 2.218858301639557

Epoch: 5| Step: 4
Training loss: 1.4973987340927124
Validation loss: 2.200583537419637

Epoch: 5| Step: 5
Training loss: 1.9038410186767578
Validation loss: 2.211588109532992

Epoch: 5| Step: 6
Training loss: 1.5180492401123047
Validation loss: 2.223884334166845

Epoch: 5| Step: 7
Training loss: 1.3446954488754272
Validation loss: 2.224992329875628

Epoch: 5| Step: 8
Training loss: 2.055535316467285
Validation loss: 2.2126754969358444

Epoch: 5| Step: 9
Training loss: 1.363335132598877
Validation loss: 2.2036307801802955

Epoch: 5| Step: 10
Training loss: 1.34706711769104
Validation loss: 2.195563569664955

Epoch: 5| Step: 11
Training loss: 1.5988526344299316
Validation loss: 2.201595882574717

Epoch: 327| Step: 0
Training loss: 1.2151011228561401
Validation loss: 2.206766833861669

Epoch: 5| Step: 1
Training loss: 1.6390825510025024
Validation loss: 2.1737467100222907

Epoch: 5| Step: 2
Training loss: 1.4506962299346924
Validation loss: 2.191469262043635

Epoch: 5| Step: 3
Training loss: 2.2376961708068848
Validation loss: 2.1928555369377136

Epoch: 5| Step: 4
Training loss: 1.3129135370254517
Validation loss: 2.2023944705724716

Epoch: 5| Step: 5
Training loss: 1.7844336032867432
Validation loss: 2.205114394426346

Epoch: 5| Step: 6
Training loss: 1.6736526489257812
Validation loss: 2.207582503557205

Epoch: 5| Step: 7
Training loss: 0.940142810344696
Validation loss: 2.1995158592859902

Epoch: 5| Step: 8
Training loss: 1.6714929342269897
Validation loss: 2.1755299319823584

Epoch: 5| Step: 9
Training loss: 1.3217716217041016
Validation loss: 2.199466715256373

Epoch: 5| Step: 10
Training loss: 1.7107932567596436
Validation loss: 2.1986775348583856

Epoch: 5| Step: 11
Training loss: 1.829470157623291
Validation loss: 2.1954612036546073

Epoch: 328| Step: 0
Training loss: 2.2554688453674316
Validation loss: 2.1916069984436035

Epoch: 5| Step: 1
Training loss: 1.5270628929138184
Validation loss: 2.1905132234096527

Epoch: 5| Step: 2
Training loss: 1.913940668106079
Validation loss: 2.2084278662999473

Epoch: 5| Step: 3
Training loss: 2.045653820037842
Validation loss: 2.199935793876648

Epoch: 5| Step: 4
Training loss: 1.3694746494293213
Validation loss: 2.251435806353887

Epoch: 5| Step: 5
Training loss: 1.9988136291503906
Validation loss: 2.222982555627823

Epoch: 5| Step: 6
Training loss: 0.7822224497795105
Validation loss: 2.21034004787604

Epoch: 5| Step: 7
Training loss: 1.3235194683074951
Validation loss: 2.2171359409888587

Epoch: 5| Step: 8
Training loss: 0.9564323425292969
Validation loss: 2.224227170149485

Epoch: 5| Step: 9
Training loss: 1.7145545482635498
Validation loss: 2.1764179368813834

Epoch: 5| Step: 10
Training loss: 1.8487142324447632
Validation loss: 2.211014280716578

Epoch: 5| Step: 11
Training loss: 0.6617131233215332
Validation loss: 2.189717893799146

Epoch: 329| Step: 0
Training loss: 1.2448899745941162
Validation loss: 2.222558915615082

Epoch: 5| Step: 1
Training loss: 1.6584579944610596
Validation loss: 2.2235214561223984

Epoch: 5| Step: 2
Training loss: 1.4768255949020386
Validation loss: 2.2285014390945435

Epoch: 5| Step: 3
Training loss: 1.6981022357940674
Validation loss: 2.2540687024593353

Epoch: 5| Step: 4
Training loss: 1.4555201530456543
Validation loss: 2.2822219034036

Epoch: 5| Step: 5
Training loss: 1.9065536260604858
Validation loss: 2.27028755346934

Epoch: 5| Step: 6
Training loss: 2.1042392253875732
Validation loss: 2.2639442483584085

Epoch: 5| Step: 7
Training loss: 1.329350233078003
Validation loss: 2.2351266344388327

Epoch: 5| Step: 8
Training loss: 1.5132139921188354
Validation loss: 2.2416259745756784

Epoch: 5| Step: 9
Training loss: 1.504706859588623
Validation loss: 2.2675422628720603

Epoch: 5| Step: 10
Training loss: 1.4919793605804443
Validation loss: 2.2622104535500207

Epoch: 5| Step: 11
Training loss: 2.4941463470458984
Validation loss: 2.242657259106636

Epoch: 330| Step: 0
Training loss: 1.092851996421814
Validation loss: 2.2655018170674643

Epoch: 5| Step: 1
Training loss: 2.0795254707336426
Validation loss: 2.2519206454356513

Epoch: 5| Step: 2
Training loss: 1.9582188129425049
Validation loss: 2.244899501403173

Epoch: 5| Step: 3
Training loss: 1.4912151098251343
Validation loss: 2.2356659173965454

Epoch: 5| Step: 4
Training loss: 2.1123135089874268
Validation loss: 2.236225018898646

Epoch: 5| Step: 5
Training loss: 1.5262305736541748
Validation loss: 2.2420849998792014

Epoch: 5| Step: 6
Training loss: 1.545743465423584
Validation loss: 2.2272226909796395

Epoch: 5| Step: 7
Training loss: 1.7404245138168335
Validation loss: 2.2232293834288916

Epoch: 5| Step: 8
Training loss: 0.8440953493118286
Validation loss: 2.2309489150842032

Epoch: 5| Step: 9
Training loss: 1.304840326309204
Validation loss: 2.2029982606569924

Epoch: 5| Step: 10
Training loss: 1.4107649326324463
Validation loss: 2.1942693293094635

Epoch: 5| Step: 11
Training loss: 1.745370864868164
Validation loss: 2.187087739507357

Epoch: 331| Step: 0
Training loss: 1.250497817993164
Validation loss: 2.1998339196046195

Epoch: 5| Step: 1
Training loss: 1.3961790800094604
Validation loss: 2.180693174401919

Epoch: 5| Step: 2
Training loss: 2.2235898971557617
Validation loss: 2.174038290977478

Epoch: 5| Step: 3
Training loss: 1.6352144479751587
Validation loss: 2.216985046863556

Epoch: 5| Step: 4
Training loss: 2.2276012897491455
Validation loss: 2.196789006392161

Epoch: 5| Step: 5
Training loss: 1.7291758060455322
Validation loss: 2.2181200285752616

Epoch: 5| Step: 6
Training loss: 1.4492058753967285
Validation loss: 2.2141185949246087

Epoch: 5| Step: 7
Training loss: 1.0817368030548096
Validation loss: 2.2214441994825997

Epoch: 5| Step: 8
Training loss: 1.1441644430160522
Validation loss: 2.2252996961275735

Epoch: 5| Step: 9
Training loss: 0.9611799120903015
Validation loss: 2.198370714982351

Epoch: 5| Step: 10
Training loss: 1.3322943449020386
Validation loss: 2.1771644949913025

Epoch: 5| Step: 11
Training loss: 1.96680748462677
Validation loss: 2.191046789288521

Epoch: 332| Step: 0
Training loss: 1.5581872463226318
Validation loss: 2.201458513736725

Epoch: 5| Step: 1
Training loss: 1.4326441287994385
Validation loss: 2.227017343044281

Epoch: 5| Step: 2
Training loss: 1.9346215724945068
Validation loss: 2.220420425136884

Epoch: 5| Step: 3
Training loss: 1.8341888189315796
Validation loss: 2.201472212870916

Epoch: 5| Step: 4
Training loss: 1.541226863861084
Validation loss: 2.201101372639338

Epoch: 5| Step: 5
Training loss: 1.3166420459747314
Validation loss: 2.2207939525445304

Epoch: 5| Step: 6
Training loss: 1.3510593175888062
Validation loss: 2.2066445698340735

Epoch: 5| Step: 7
Training loss: 1.5879676342010498
Validation loss: 2.212012161811193

Epoch: 5| Step: 8
Training loss: 1.4323420524597168
Validation loss: 2.2257232815027237

Epoch: 5| Step: 9
Training loss: 1.2666069269180298
Validation loss: 2.219413553675016

Epoch: 5| Step: 10
Training loss: 1.254986047744751
Validation loss: 2.2379226088523865

Epoch: 5| Step: 11
Training loss: 1.304260492324829
Validation loss: 2.21063569188118

Epoch: 333| Step: 0
Training loss: 2.0733819007873535
Validation loss: 2.2166278014580407

Epoch: 5| Step: 1
Training loss: 1.5020984411239624
Validation loss: 2.213720371325811

Epoch: 5| Step: 2
Training loss: 1.3194596767425537
Validation loss: 2.197258085012436

Epoch: 5| Step: 3
Training loss: 1.144057035446167
Validation loss: 2.232127765814463

Epoch: 5| Step: 4
Training loss: 1.3504879474639893
Validation loss: 2.1698614110549292

Epoch: 5| Step: 5
Training loss: 2.0907444953918457
Validation loss: 2.2010800540447235

Epoch: 5| Step: 6
Training loss: 1.4145386219024658
Validation loss: 2.2426551580429077

Epoch: 5| Step: 7
Training loss: 1.578518271446228
Validation loss: 2.210310007135073

Epoch: 5| Step: 8
Training loss: 1.1386048793792725
Validation loss: 2.221460372209549

Epoch: 5| Step: 9
Training loss: 1.4167845249176025
Validation loss: 2.2084554731845856

Epoch: 5| Step: 10
Training loss: 1.508859634399414
Validation loss: 2.2041242669026055

Epoch: 5| Step: 11
Training loss: 2.6147327423095703
Validation loss: 2.216075678666433

Epoch: 334| Step: 0
Training loss: 1.5915439128875732
Validation loss: 2.2602411806583405

Epoch: 5| Step: 1
Training loss: 1.1667749881744385
Validation loss: 2.218803415695826

Epoch: 5| Step: 2
Training loss: 1.460675835609436
Validation loss: 2.1752804021040597

Epoch: 5| Step: 3
Training loss: 1.4119675159454346
Validation loss: 2.1855015655358634

Epoch: 5| Step: 4
Training loss: 1.7140600681304932
Validation loss: 2.142393007874489

Epoch: 5| Step: 5
Training loss: 1.8044240474700928
Validation loss: 2.1505989929040275

Epoch: 5| Step: 6
Training loss: 1.1516530513763428
Validation loss: 2.158297896385193

Epoch: 5| Step: 7
Training loss: 1.8460607528686523
Validation loss: 2.163100545605024

Epoch: 5| Step: 8
Training loss: 1.735242247581482
Validation loss: 2.14819265405337

Epoch: 5| Step: 9
Training loss: 1.973467469215393
Validation loss: 2.158766975005468

Epoch: 5| Step: 10
Training loss: 1.3966652154922485
Validation loss: 2.1800835529963174

Epoch: 5| Step: 11
Training loss: 2.0606298446655273
Validation loss: 2.2026443680127463

Epoch: 335| Step: 0
Training loss: 1.3729726076126099
Validation loss: 2.255407676100731

Epoch: 5| Step: 1
Training loss: 1.2428920269012451
Validation loss: 2.2730819384256997

Epoch: 5| Step: 2
Training loss: 1.5167204141616821
Validation loss: 2.2449690153201423

Epoch: 5| Step: 3
Training loss: 1.7559900283813477
Validation loss: 2.2574256310860314

Epoch: 5| Step: 4
Training loss: 1.061973214149475
Validation loss: 2.289425710837046

Epoch: 5| Step: 5
Training loss: 1.2375314235687256
Validation loss: 2.2743153423070908

Epoch: 5| Step: 6
Training loss: 1.5932905673980713
Validation loss: 2.2595238437255225

Epoch: 5| Step: 7
Training loss: 2.1723642349243164
Validation loss: 2.2861330856879554

Epoch: 5| Step: 8
Training loss: 1.7473020553588867
Validation loss: 2.2595451970895133

Epoch: 5| Step: 9
Training loss: 1.6935882568359375
Validation loss: 2.263815959294637

Epoch: 5| Step: 10
Training loss: 2.161721706390381
Validation loss: 2.2425111134847007

Epoch: 5| Step: 11
Training loss: 1.7742011547088623
Validation loss: 2.241191878914833

Epoch: 336| Step: 0
Training loss: 1.6573822498321533
Validation loss: 2.2450110763311386

Epoch: 5| Step: 1
Training loss: 1.5341960191726685
Validation loss: 2.2308067083358765

Epoch: 5| Step: 2
Training loss: 1.6302502155303955
Validation loss: 2.252759416898092

Epoch: 5| Step: 3
Training loss: 1.3669685125350952
Validation loss: 2.2555010368426642

Epoch: 5| Step: 4
Training loss: 1.3164206743240356
Validation loss: 2.2400061885515847

Epoch: 5| Step: 5
Training loss: 1.4517754316329956
Validation loss: 2.2454882661501565

Epoch: 5| Step: 6
Training loss: 2.3274152278900146
Validation loss: 2.2082432210445404

Epoch: 5| Step: 7
Training loss: 1.7487399578094482
Validation loss: 2.202359219392141

Epoch: 5| Step: 8
Training loss: 1.446794867515564
Validation loss: 2.2213261127471924

Epoch: 5| Step: 9
Training loss: 1.349027395248413
Validation loss: 2.2296887089808783

Epoch: 5| Step: 10
Training loss: 1.2648990154266357
Validation loss: 2.2158476561307907

Epoch: 5| Step: 11
Training loss: 1.3818455934524536
Validation loss: 2.2038312554359436

Epoch: 337| Step: 0
Training loss: 1.5870611667633057
Validation loss: 2.2160329073667526

Epoch: 5| Step: 1
Training loss: 2.218170642852783
Validation loss: 2.1999718248844147

Epoch: 5| Step: 2
Training loss: 1.2054550647735596
Validation loss: 2.209256629149119

Epoch: 5| Step: 3
Training loss: 1.8364537954330444
Validation loss: 2.2028612544139228

Epoch: 5| Step: 4
Training loss: 1.467374324798584
Validation loss: 2.194656883676847

Epoch: 5| Step: 5
Training loss: 1.652199387550354
Validation loss: 2.1825930972894034

Epoch: 5| Step: 6
Training loss: 1.3223655223846436
Validation loss: 2.2141248136758804

Epoch: 5| Step: 7
Training loss: 1.3248636722564697
Validation loss: 2.215397854646047

Epoch: 5| Step: 8
Training loss: 1.3366796970367432
Validation loss: 2.191673239072164

Epoch: 5| Step: 9
Training loss: 1.7128770351409912
Validation loss: 2.1907098094622293

Epoch: 5| Step: 10
Training loss: 1.8193410634994507
Validation loss: 2.1872445543607077

Epoch: 5| Step: 11
Training loss: 1.6691439151763916
Validation loss: 2.1814005374908447

Epoch: 338| Step: 0
Training loss: 2.214171886444092
Validation loss: 2.195093055566152

Epoch: 5| Step: 1
Training loss: 1.1969208717346191
Validation loss: 2.2347736159960427

Epoch: 5| Step: 2
Training loss: 1.3462051153182983
Validation loss: 2.224719742933909

Epoch: 5| Step: 3
Training loss: 1.7295029163360596
Validation loss: 2.258610794941584

Epoch: 5| Step: 4
Training loss: 1.2822178602218628
Validation loss: 2.240849862496058

Epoch: 5| Step: 5
Training loss: 1.2921956777572632
Validation loss: 2.256763607263565

Epoch: 5| Step: 6
Training loss: 1.1485764980316162
Validation loss: 2.2537432461977005

Epoch: 5| Step: 7
Training loss: 1.4910407066345215
Validation loss: 2.2445428470770517

Epoch: 5| Step: 8
Training loss: 0.9859297871589661
Validation loss: 2.242309103409449

Epoch: 5| Step: 9
Training loss: 2.161747694015503
Validation loss: 2.2948500712712607

Epoch: 5| Step: 10
Training loss: 1.792742133140564
Validation loss: 2.27945784231027

Epoch: 5| Step: 11
Training loss: 1.952279806137085
Validation loss: 2.248005380233129

Epoch: 339| Step: 0
Training loss: 1.7021968364715576
Validation loss: 2.285839925209681

Epoch: 5| Step: 1
Training loss: 0.8517977595329285
Validation loss: 2.2475308378537497

Epoch: 5| Step: 2
Training loss: 1.9098975658416748
Validation loss: 2.2210235943396888

Epoch: 5| Step: 3
Training loss: 2.047985553741455
Validation loss: 2.2639347116152444

Epoch: 5| Step: 4
Training loss: 2.1975789070129395
Validation loss: 2.2486901779969535

Epoch: 5| Step: 5
Training loss: 1.118309736251831
Validation loss: 2.2416025747855506

Epoch: 5| Step: 6
Training loss: 0.9295269846916199
Validation loss: 2.203819751739502

Epoch: 5| Step: 7
Training loss: 1.5055263042449951
Validation loss: 2.2274895509084067

Epoch: 5| Step: 8
Training loss: 1.4460577964782715
Validation loss: 2.2219188809394836

Epoch: 5| Step: 9
Training loss: 1.7718654870986938
Validation loss: 2.2343817551930747

Epoch: 5| Step: 10
Training loss: 1.2681485414505005
Validation loss: 2.2462039589881897

Epoch: 5| Step: 11
Training loss: 2.159951686859131
Validation loss: 2.215048318107923

Epoch: 340| Step: 0
Training loss: 2.3358383178710938
Validation loss: 2.226920112967491

Epoch: 5| Step: 1
Training loss: 1.857316255569458
Validation loss: 2.2412930776675544

Epoch: 5| Step: 2
Training loss: 1.7242629528045654
Validation loss: 2.2100348273913064

Epoch: 5| Step: 3
Training loss: 1.8467658758163452
Validation loss: 2.2096356749534607

Epoch: 5| Step: 4
Training loss: 1.3503812551498413
Validation loss: 2.1765991151332855

Epoch: 5| Step: 5
Training loss: 1.1134719848632812
Validation loss: 2.1827807128429413

Epoch: 5| Step: 6
Training loss: 1.351209282875061
Validation loss: 2.171954254309336

Epoch: 5| Step: 7
Training loss: 1.5034271478652954
Validation loss: 2.1639511386553445

Epoch: 5| Step: 8
Training loss: 1.3823020458221436
Validation loss: 2.176454166571299

Epoch: 5| Step: 9
Training loss: 0.9609874486923218
Validation loss: 2.210500051577886

Epoch: 5| Step: 10
Training loss: 1.1735514402389526
Validation loss: 2.211090366045634

Epoch: 5| Step: 11
Training loss: 3.0330822467803955
Validation loss: 2.218071460723877

Epoch: 341| Step: 0
Training loss: 1.3755954504013062
Validation loss: 2.204177896181742

Epoch: 5| Step: 1
Training loss: 1.5369904041290283
Validation loss: 2.1962543030579886

Epoch: 5| Step: 2
Training loss: 1.5567958354949951
Validation loss: 2.1935945401589074

Epoch: 5| Step: 3
Training loss: 1.582666039466858
Validation loss: 2.172599052389463

Epoch: 5| Step: 4
Training loss: 0.9865869283676147
Validation loss: 2.179242650667826

Epoch: 5| Step: 5
Training loss: 1.4297764301300049
Validation loss: 2.163667211929957

Epoch: 5| Step: 6
Training loss: 1.1959140300750732
Validation loss: 2.1689637253681817

Epoch: 5| Step: 7
Training loss: 1.8450149297714233
Validation loss: 2.2000877261161804

Epoch: 5| Step: 8
Training loss: 1.3502048254013062
Validation loss: 2.1734862873951593

Epoch: 5| Step: 9
Training loss: 1.7086248397827148
Validation loss: 2.1702740689118705

Epoch: 5| Step: 10
Training loss: 2.0084688663482666
Validation loss: 2.1807536582152047

Epoch: 5| Step: 11
Training loss: 1.8687019348144531
Validation loss: 2.156908243894577

Epoch: 342| Step: 0
Training loss: 1.56821608543396
Validation loss: 2.182610655824343

Epoch: 5| Step: 1
Training loss: 1.0919572114944458
Validation loss: 2.1833320558071136

Epoch: 5| Step: 2
Training loss: 1.0958068370819092
Validation loss: 2.1791128118832908

Epoch: 5| Step: 3
Training loss: 1.497381567955017
Validation loss: 2.2043295403321586

Epoch: 5| Step: 4
Training loss: 1.9505341053009033
Validation loss: 2.186643143494924

Epoch: 5| Step: 5
Training loss: 1.7503745555877686
Validation loss: 2.227113053202629

Epoch: 5| Step: 6
Training loss: 1.5181078910827637
Validation loss: 2.187199537952741

Epoch: 5| Step: 7
Training loss: 1.455930471420288
Validation loss: 2.214945539832115

Epoch: 5| Step: 8
Training loss: 1.0573318004608154
Validation loss: 2.23539491991202

Epoch: 5| Step: 9
Training loss: 1.5434261560440063
Validation loss: 2.2267541686693826

Epoch: 5| Step: 10
Training loss: 1.6316745281219482
Validation loss: 2.22535174091657

Epoch: 5| Step: 11
Training loss: 2.5806989669799805
Validation loss: 2.192582686742147

Epoch: 343| Step: 0
Training loss: 1.1680587530136108
Validation loss: 2.2151976923147836

Epoch: 5| Step: 1
Training loss: 1.0587332248687744
Validation loss: 2.197258015473684

Epoch: 5| Step: 2
Training loss: 2.0006346702575684
Validation loss: 2.2159068087736764

Epoch: 5| Step: 3
Training loss: 1.2533762454986572
Validation loss: 2.216496924559275

Epoch: 5| Step: 4
Training loss: 1.82956862449646
Validation loss: 2.1858504315217337

Epoch: 5| Step: 5
Training loss: 1.6514310836791992
Validation loss: 2.17704638838768

Epoch: 5| Step: 6
Training loss: 1.9240297079086304
Validation loss: 2.195017993450165

Epoch: 5| Step: 7
Training loss: 1.7896935939788818
Validation loss: 2.1937503715356192

Epoch: 5| Step: 8
Training loss: 1.6718883514404297
Validation loss: 2.166963259379069

Epoch: 5| Step: 9
Training loss: 1.1758248805999756
Validation loss: 2.170037771264712

Epoch: 5| Step: 10
Training loss: 1.226080298423767
Validation loss: 2.1611306071281433

Epoch: 5| Step: 11
Training loss: 1.0710515975952148
Validation loss: 2.145720819632212

Epoch: 344| Step: 0
Training loss: 1.26779305934906
Validation loss: 2.142078330119451

Epoch: 5| Step: 1
Training loss: 0.9866946339607239
Validation loss: 2.166555384794871

Epoch: 5| Step: 2
Training loss: 1.6660339832305908
Validation loss: 2.1666574676831565

Epoch: 5| Step: 3
Training loss: 1.5802185535430908
Validation loss: 2.1676478882630668

Epoch: 5| Step: 4
Training loss: 1.4791820049285889
Validation loss: 2.1709926774104438

Epoch: 5| Step: 5
Training loss: 1.0452247858047485
Validation loss: 2.164228936036428

Epoch: 5| Step: 6
Training loss: 1.4656944274902344
Validation loss: 2.1691390722990036

Epoch: 5| Step: 7
Training loss: 1.4580191373825073
Validation loss: 2.1519052932659783

Epoch: 5| Step: 8
Training loss: 1.3048194646835327
Validation loss: 2.1598441352446875

Epoch: 5| Step: 9
Training loss: 1.8728420734405518
Validation loss: 2.216524342695872

Epoch: 5| Step: 10
Training loss: 1.5345338582992554
Validation loss: 2.225078289707502

Epoch: 5| Step: 11
Training loss: 2.435392379760742
Validation loss: 2.1813058803478875

Epoch: 345| Step: 0
Training loss: 1.9441163539886475
Validation loss: 2.225163077314695

Epoch: 5| Step: 1
Training loss: 1.1816003322601318
Validation loss: 2.2129147946834564

Epoch: 5| Step: 2
Training loss: 1.1141945123672485
Validation loss: 2.2186514834562936

Epoch: 5| Step: 3
Training loss: 1.6764596700668335
Validation loss: 2.216270476579666

Epoch: 5| Step: 4
Training loss: 0.9602658152580261
Validation loss: 2.211378365755081

Epoch: 5| Step: 5
Training loss: 0.9031651616096497
Validation loss: 2.20677383740743

Epoch: 5| Step: 6
Training loss: 1.8702704906463623
Validation loss: 2.2097137570381165

Epoch: 5| Step: 7
Training loss: 0.9041517376899719
Validation loss: 2.199573283394178

Epoch: 5| Step: 8
Training loss: 1.9523929357528687
Validation loss: 2.222243974606196

Epoch: 5| Step: 9
Training loss: 1.6875883340835571
Validation loss: 2.196946461995443

Epoch: 5| Step: 10
Training loss: 1.8211126327514648
Validation loss: 2.184668938318888

Epoch: 5| Step: 11
Training loss: 0.9796174764633179
Validation loss: 2.1776862343152366

Epoch: 346| Step: 0
Training loss: 1.0362608432769775
Validation loss: 2.1908725996812186

Epoch: 5| Step: 1
Training loss: 1.3383255004882812
Validation loss: 2.2284353574117026

Epoch: 5| Step: 2
Training loss: 1.3259321451187134
Validation loss: 2.1747765441735587

Epoch: 5| Step: 3
Training loss: 0.8427175283432007
Validation loss: 2.2116405119498572

Epoch: 5| Step: 4
Training loss: 1.8761993646621704
Validation loss: 2.226553906997045

Epoch: 5| Step: 5
Training loss: 1.4371099472045898
Validation loss: 2.204863573114077

Epoch: 5| Step: 6
Training loss: 1.8659734725952148
Validation loss: 2.2267379661401114

Epoch: 5| Step: 7
Training loss: 1.7160627841949463
Validation loss: 2.221088925997416

Epoch: 5| Step: 8
Training loss: 1.9796638488769531
Validation loss: 2.2000877410173416

Epoch: 5| Step: 9
Training loss: 1.079127550125122
Validation loss: 2.2267231941223145

Epoch: 5| Step: 10
Training loss: 1.128760576248169
Validation loss: 2.199764276544253

Epoch: 5| Step: 11
Training loss: 1.5145015716552734
Validation loss: 2.2443975855906806

Epoch: 347| Step: 0
Training loss: 2.1197476387023926
Validation loss: 2.2077823877334595

Epoch: 5| Step: 1
Training loss: 0.8498497009277344
Validation loss: 2.2364224394162497

Epoch: 5| Step: 2
Training loss: 0.966254711151123
Validation loss: 2.2177507976690927

Epoch: 5| Step: 3
Training loss: 2.2163093090057373
Validation loss: 2.237299144268036

Epoch: 5| Step: 4
Training loss: 1.2991098165512085
Validation loss: 2.229114602009455

Epoch: 5| Step: 5
Training loss: 1.436061978340149
Validation loss: 2.2381240129470825

Epoch: 5| Step: 6
Training loss: 1.3871164321899414
Validation loss: 2.2225582847992578

Epoch: 5| Step: 7
Training loss: 1.651236891746521
Validation loss: 2.236497223377228

Epoch: 5| Step: 8
Training loss: 1.2688976526260376
Validation loss: 2.2239196648200354

Epoch: 5| Step: 9
Training loss: 1.4641945362091064
Validation loss: 2.2052002598841987

Epoch: 5| Step: 10
Training loss: 1.1124470233917236
Validation loss: 2.219230279326439

Epoch: 5| Step: 11
Training loss: 0.9838249683380127
Validation loss: 2.226528654495875

Epoch: 348| Step: 0
Training loss: 1.5127474069595337
Validation loss: 2.2363146295150123

Epoch: 5| Step: 1
Training loss: 1.1892361640930176
Validation loss: 2.219907154639562

Epoch: 5| Step: 2
Training loss: 1.9488728046417236
Validation loss: 2.2120273411273956

Epoch: 5| Step: 3
Training loss: 1.2267414331436157
Validation loss: 2.2116874059041343

Epoch: 5| Step: 4
Training loss: 1.1973741054534912
Validation loss: 2.2000969499349594

Epoch: 5| Step: 5
Training loss: 1.8200347423553467
Validation loss: 2.190960799654325

Epoch: 5| Step: 6
Training loss: 1.0721174478530884
Validation loss: 2.212429568171501

Epoch: 5| Step: 7
Training loss: 1.1916640996932983
Validation loss: 2.2289529740810394

Epoch: 5| Step: 8
Training loss: 1.8132158517837524
Validation loss: 2.1945627133051553

Epoch: 5| Step: 9
Training loss: 1.7617114782333374
Validation loss: 2.206161767244339

Epoch: 5| Step: 10
Training loss: 1.2746167182922363
Validation loss: 2.185871442159017

Epoch: 5| Step: 11
Training loss: 0.910297155380249
Validation loss: 2.2174627681573233

Epoch: 349| Step: 0
Training loss: 1.8193172216415405
Validation loss: 2.212409108877182

Epoch: 5| Step: 1
Training loss: 2.2223429679870605
Validation loss: 2.2076593538125358

Epoch: 5| Step: 2
Training loss: 1.128440499305725
Validation loss: 2.204379985729853

Epoch: 5| Step: 3
Training loss: 1.2853965759277344
Validation loss: 2.177094062169393

Epoch: 5| Step: 4
Training loss: 1.096081018447876
Validation loss: 2.1925718983014426

Epoch: 5| Step: 5
Training loss: 1.4422471523284912
Validation loss: 2.1805205245812735

Epoch: 5| Step: 6
Training loss: 1.7332226037979126
Validation loss: 2.1638702899217606

Epoch: 5| Step: 7
Training loss: 0.7874536514282227
Validation loss: 2.1857830286026

Epoch: 5| Step: 8
Training loss: 1.42069411277771
Validation loss: 2.1704649925231934

Epoch: 5| Step: 9
Training loss: 1.741929054260254
Validation loss: 2.171432226896286

Epoch: 5| Step: 10
Training loss: 1.3520257472991943
Validation loss: 2.172238275408745

Epoch: 5| Step: 11
Training loss: 0.3330279588699341
Validation loss: 2.1725813895463943

Epoch: 350| Step: 0
Training loss: 1.2056012153625488
Validation loss: 2.1772828052441278

Epoch: 5| Step: 1
Training loss: 1.1704477071762085
Validation loss: 2.1832073777914047

Epoch: 5| Step: 2
Training loss: 1.5529162883758545
Validation loss: 2.185863176981608

Epoch: 5| Step: 3
Training loss: 1.4027971029281616
Validation loss: 2.192491297920545

Epoch: 5| Step: 4
Training loss: 1.189301609992981
Validation loss: 2.168945401906967

Epoch: 5| Step: 5
Training loss: 2.0952651500701904
Validation loss: 2.192373643318812

Epoch: 5| Step: 6
Training loss: 1.9471639394760132
Validation loss: 2.2002840638160706

Epoch: 5| Step: 7
Training loss: 1.114192247390747
Validation loss: 2.1750852167606354

Epoch: 5| Step: 8
Training loss: 0.9327224493026733
Validation loss: 2.205023636420568

Epoch: 5| Step: 9
Training loss: 1.6910498142242432
Validation loss: 2.1782510578632355

Epoch: 5| Step: 10
Training loss: 1.6615091562271118
Validation loss: 2.194529781738917

Epoch: 5| Step: 11
Training loss: 0.3082016706466675
Validation loss: 2.191820591688156

Epoch: 351| Step: 0
Training loss: 1.2498266696929932
Validation loss: 2.198301707704862

Epoch: 5| Step: 1
Training loss: 1.5288934707641602
Validation loss: 2.2087116887172065

Epoch: 5| Step: 2
Training loss: 0.9560649991035461
Validation loss: 2.2137605597575507

Epoch: 5| Step: 3
Training loss: 1.4647290706634521
Validation loss: 2.1964172472556434

Epoch: 5| Step: 4
Training loss: 1.160852313041687
Validation loss: 2.2001244773467383

Epoch: 5| Step: 5
Training loss: 1.7029571533203125
Validation loss: 2.1881249248981476

Epoch: 5| Step: 6
Training loss: 2.1714489459991455
Validation loss: 2.203425402442614

Epoch: 5| Step: 7
Training loss: 1.5301192998886108
Validation loss: 2.1794143319129944

Epoch: 5| Step: 8
Training loss: 1.4586728811264038
Validation loss: 2.174068902929624

Epoch: 5| Step: 9
Training loss: 1.1918132305145264
Validation loss: 2.186426187554995

Epoch: 5| Step: 10
Training loss: 1.7799885272979736
Validation loss: 2.1888310611248016

Epoch: 5| Step: 11
Training loss: 0.8840107917785645
Validation loss: 2.1942396263281503

Epoch: 352| Step: 0
Training loss: 0.8104217648506165
Validation loss: 2.1811474661032357

Epoch: 5| Step: 1
Training loss: 1.7392698526382446
Validation loss: 2.1965109209219613

Epoch: 5| Step: 2
Training loss: 1.076245665550232
Validation loss: 2.1920384963353476

Epoch: 5| Step: 3
Training loss: 1.4965578317642212
Validation loss: 2.1794534424940744

Epoch: 5| Step: 4
Training loss: 0.6833648681640625
Validation loss: 2.1704804599285126

Epoch: 5| Step: 5
Training loss: 1.665639877319336
Validation loss: 2.2036973237991333

Epoch: 5| Step: 6
Training loss: 1.0495208501815796
Validation loss: 2.17328479886055

Epoch: 5| Step: 7
Training loss: 2.144625425338745
Validation loss: 2.2018105536699295

Epoch: 5| Step: 8
Training loss: 1.6085197925567627
Validation loss: 2.215373476346334

Epoch: 5| Step: 9
Training loss: 1.153150200843811
Validation loss: 2.214976047476133

Epoch: 5| Step: 10
Training loss: 2.1210765838623047
Validation loss: 2.193540871143341

Epoch: 5| Step: 11
Training loss: 1.152000069618225
Validation loss: 2.216296931107839

Epoch: 353| Step: 0
Training loss: 1.039697289466858
Validation loss: 2.201235050956408

Epoch: 5| Step: 1
Training loss: 1.5641857385635376
Validation loss: 2.229171246290207

Epoch: 5| Step: 2
Training loss: 1.7087997198104858
Validation loss: 2.200444449981054

Epoch: 5| Step: 3
Training loss: 1.3575799465179443
Validation loss: 2.2234611809253693

Epoch: 5| Step: 4
Training loss: 1.813765287399292
Validation loss: 2.21449547012647

Epoch: 5| Step: 5
Training loss: 0.9452213048934937
Validation loss: 2.1971940646568933

Epoch: 5| Step: 6
Training loss: 1.6636970043182373
Validation loss: 2.1872509320576987

Epoch: 5| Step: 7
Training loss: 0.9971973299980164
Validation loss: 2.21693084637324

Epoch: 5| Step: 8
Training loss: 0.8569223284721375
Validation loss: 2.2050412048896155

Epoch: 5| Step: 9
Training loss: 1.6399219036102295
Validation loss: 2.1877970844507217

Epoch: 5| Step: 10
Training loss: 1.7888972759246826
Validation loss: 2.2036290168762207

Epoch: 5| Step: 11
Training loss: 0.6315679550170898
Validation loss: 2.1854497293631234

Epoch: 354| Step: 0
Training loss: 1.1741596460342407
Validation loss: 2.2109583665927253

Epoch: 5| Step: 1
Training loss: 1.695793867111206
Validation loss: 2.22360423207283

Epoch: 5| Step: 2
Training loss: 0.981132984161377
Validation loss: 2.2325974901517234

Epoch: 5| Step: 3
Training loss: 1.5443847179412842
Validation loss: 2.2084277470906577

Epoch: 5| Step: 4
Training loss: 1.2213287353515625
Validation loss: 2.187721093495687

Epoch: 5| Step: 5
Training loss: 1.3799965381622314
Validation loss: 2.2436234851678214

Epoch: 5| Step: 6
Training loss: 1.7154823541641235
Validation loss: 2.250970666607221

Epoch: 5| Step: 7
Training loss: 1.3601971864700317
Validation loss: 2.253768747051557

Epoch: 5| Step: 8
Training loss: 1.271578073501587
Validation loss: 2.2348200976848602

Epoch: 5| Step: 9
Training loss: 1.4480944871902466
Validation loss: 2.253389855225881

Epoch: 5| Step: 10
Training loss: 1.4363739490509033
Validation loss: 2.26005549232165

Epoch: 5| Step: 11
Training loss: 1.069926381111145
Validation loss: 2.2426425019900003

Epoch: 355| Step: 0
Training loss: 1.128753423690796
Validation loss: 2.266133298476537

Epoch: 5| Step: 1
Training loss: 1.5423896312713623
Validation loss: 2.2714649637540183

Epoch: 5| Step: 2
Training loss: 1.3894842863082886
Validation loss: 2.2577595114707947

Epoch: 5| Step: 3
Training loss: 1.2600034475326538
Validation loss: 2.2557103633880615

Epoch: 5| Step: 4
Training loss: 1.6039352416992188
Validation loss: 2.226565877596537

Epoch: 5| Step: 5
Training loss: 1.4155583381652832
Validation loss: 2.211764266093572

Epoch: 5| Step: 6
Training loss: 0.9966694712638855
Validation loss: 2.181478336453438

Epoch: 5| Step: 7
Training loss: 1.3933851718902588
Validation loss: 2.1640721609195075

Epoch: 5| Step: 8
Training loss: 1.1636637449264526
Validation loss: 2.202619711558024

Epoch: 5| Step: 9
Training loss: 2.2301437854766846
Validation loss: 2.1955856531858444

Epoch: 5| Step: 10
Training loss: 1.4248278141021729
Validation loss: 2.2016376753648124

Epoch: 5| Step: 11
Training loss: 1.2768317461013794
Validation loss: 2.195852607488632

Epoch: 356| Step: 0
Training loss: 1.2211377620697021
Validation loss: 2.1920694361130395

Epoch: 5| Step: 1
Training loss: 1.390823245048523
Validation loss: 2.1749822944402695

Epoch: 5| Step: 2
Training loss: 1.794995665550232
Validation loss: 2.1881549110015235

Epoch: 5| Step: 3
Training loss: 1.7017320394515991
Validation loss: 2.2087094336748123

Epoch: 5| Step: 4
Training loss: 0.9889998435974121
Validation loss: 2.2095071574052176

Epoch: 5| Step: 5
Training loss: 0.9670273065567017
Validation loss: 2.206957827011744

Epoch: 5| Step: 6
Training loss: 1.1053848266601562
Validation loss: 2.202288140853246

Epoch: 5| Step: 7
Training loss: 1.3254295587539673
Validation loss: 2.224774797757467

Epoch: 5| Step: 8
Training loss: 1.207235336303711
Validation loss: 2.2486508886019387

Epoch: 5| Step: 9
Training loss: 1.330928921699524
Validation loss: 2.240286479393641

Epoch: 5| Step: 10
Training loss: 1.8612287044525146
Validation loss: 2.2411001374324164

Epoch: 5| Step: 11
Training loss: 1.133286952972412
Validation loss: 2.232388620575269

Epoch: 357| Step: 0
Training loss: 1.2244588136672974
Validation loss: 2.237746665875117

Epoch: 5| Step: 1
Training loss: 1.4900152683258057
Validation loss: 2.249101296067238

Epoch: 5| Step: 2
Training loss: 0.9492460489273071
Validation loss: 2.2608308444420495

Epoch: 5| Step: 3
Training loss: 1.6767469644546509
Validation loss: 2.235984375079473

Epoch: 5| Step: 4
Training loss: 1.9428808689117432
Validation loss: 2.199886679649353

Epoch: 5| Step: 5
Training loss: 1.2397840023040771
Validation loss: 2.189813310901324

Epoch: 5| Step: 6
Training loss: 1.5685580968856812
Validation loss: 2.2396463255087533

Epoch: 5| Step: 7
Training loss: 1.4964401721954346
Validation loss: 2.248629922668139

Epoch: 5| Step: 8
Training loss: 1.275244116783142
Validation loss: 2.231519271930059

Epoch: 5| Step: 9
Training loss: 0.7901620268821716
Validation loss: 2.227253700296084

Epoch: 5| Step: 10
Training loss: 1.7433583736419678
Validation loss: 2.2177993655204773

Epoch: 5| Step: 11
Training loss: 1.1760679483413696
Validation loss: 2.2335132708152137

Epoch: 358| Step: 0
Training loss: 0.7205451726913452
Validation loss: 2.2464348574479422

Epoch: 5| Step: 1
Training loss: 1.6690670251846313
Validation loss: 2.2461436639229455

Epoch: 5| Step: 2
Training loss: 1.2277244329452515
Validation loss: 2.2314475228389106

Epoch: 5| Step: 3
Training loss: 2.0691487789154053
Validation loss: 2.262855112552643

Epoch: 5| Step: 4
Training loss: 1.3534893989562988
Validation loss: 2.229773079355558

Epoch: 5| Step: 5
Training loss: 1.0635892152786255
Validation loss: 2.2181575248638787

Epoch: 5| Step: 6
Training loss: 1.8513038158416748
Validation loss: 2.264961918195089

Epoch: 5| Step: 7
Training loss: 1.272254228591919
Validation loss: 2.2428775131702423

Epoch: 5| Step: 8
Training loss: 1.24519944190979
Validation loss: 2.189270575841268

Epoch: 5| Step: 9
Training loss: 0.9917110204696655
Validation loss: 2.219460686047872

Epoch: 5| Step: 10
Training loss: 1.4589898586273193
Validation loss: 2.210102086265882

Epoch: 5| Step: 11
Training loss: 1.0896596908569336
Validation loss: 2.22113728026549

Epoch: 359| Step: 0
Training loss: 1.1332632303237915
Validation loss: 2.1744697193304696

Epoch: 5| Step: 1
Training loss: 1.4473750591278076
Validation loss: 2.1869237571954727

Epoch: 5| Step: 2
Training loss: 1.472493290901184
Validation loss: 2.1933555801709494

Epoch: 5| Step: 3
Training loss: 1.2484314441680908
Validation loss: 2.191165511806806

Epoch: 5| Step: 4
Training loss: 1.6864573955535889
Validation loss: 2.169795195261637

Epoch: 5| Step: 5
Training loss: 1.0097047090530396
Validation loss: 2.1670543452103934

Epoch: 5| Step: 6
Training loss: 0.7974606156349182
Validation loss: 2.1740342378616333

Epoch: 5| Step: 7
Training loss: 1.5425703525543213
Validation loss: 2.161724934975306

Epoch: 5| Step: 8
Training loss: 1.6088203191757202
Validation loss: 2.2135386069615683

Epoch: 5| Step: 9
Training loss: 1.7759336233139038
Validation loss: 2.193538616100947

Epoch: 5| Step: 10
Training loss: 1.2679122686386108
Validation loss: 2.2476525406042733

Epoch: 5| Step: 11
Training loss: 1.602146029472351
Validation loss: 2.272241229812304

Epoch: 360| Step: 0
Training loss: 1.4179151058197021
Validation loss: 2.2746971944967904

Epoch: 5| Step: 1
Training loss: 1.1609535217285156
Validation loss: 2.243857736388842

Epoch: 5| Step: 2
Training loss: 1.9788944721221924
Validation loss: 2.275398616989454

Epoch: 5| Step: 3
Training loss: 1.8729121685028076
Validation loss: 2.253620902697245

Epoch: 5| Step: 4
Training loss: 1.5881059169769287
Validation loss: 2.251628190279007

Epoch: 5| Step: 5
Training loss: 1.6197624206542969
Validation loss: 2.2621298929055533

Epoch: 5| Step: 6
Training loss: 1.5950556993484497
Validation loss: 2.278831258416176

Epoch: 5| Step: 7
Training loss: 1.24668288230896
Validation loss: 2.2838585575421653

Epoch: 5| Step: 8
Training loss: 0.9489251971244812
Validation loss: 2.2493299146493277

Epoch: 5| Step: 9
Training loss: 1.2589222192764282
Validation loss: 2.274102638165156

Epoch: 5| Step: 10
Training loss: 1.4135710000991821
Validation loss: 2.281592230002085

Epoch: 5| Step: 11
Training loss: 0.5479098558425903
Validation loss: 2.2310300519069037

Epoch: 361| Step: 0
Training loss: 0.8913262486457825
Validation loss: 2.2074736952781677

Epoch: 5| Step: 1
Training loss: 0.9960775375366211
Validation loss: 2.2149485051631927

Epoch: 5| Step: 2
Training loss: 1.1890347003936768
Validation loss: 2.189367492993673

Epoch: 5| Step: 3
Training loss: 1.8038578033447266
Validation loss: 2.2170314490795135

Epoch: 5| Step: 4
Training loss: 1.3442432880401611
Validation loss: 2.206801344950994

Epoch: 5| Step: 5
Training loss: 1.0879720449447632
Validation loss: 2.240160425504049

Epoch: 5| Step: 6
Training loss: 1.3854924440383911
Validation loss: 2.2377491941054664

Epoch: 5| Step: 7
Training loss: 2.162821054458618
Validation loss: 2.218208978573481

Epoch: 5| Step: 8
Training loss: 2.380383014678955
Validation loss: 2.2236354649066925

Epoch: 5| Step: 9
Training loss: 0.9427621960639954
Validation loss: 2.1808999478816986

Epoch: 5| Step: 10
Training loss: 1.05446195602417
Validation loss: 2.216596951087316

Epoch: 5| Step: 11
Training loss: 1.134509801864624
Validation loss: 2.2044659753640494

Epoch: 362| Step: 0
Training loss: 2.0640947818756104
Validation loss: 2.2397381067276

Epoch: 5| Step: 1
Training loss: 1.946942925453186
Validation loss: 2.188437526424726

Epoch: 5| Step: 2
Training loss: 1.339650273323059
Validation loss: 2.252248893181483

Epoch: 5| Step: 3
Training loss: 1.171216368675232
Validation loss: 2.2270992596944175

Epoch: 5| Step: 4
Training loss: 0.9991170763969421
Validation loss: 2.235401153564453

Epoch: 5| Step: 5
Training loss: 1.5150426626205444
Validation loss: 2.244158089160919

Epoch: 5| Step: 6
Training loss: 1.4932689666748047
Validation loss: 2.268109917640686

Epoch: 5| Step: 7
Training loss: 0.893210768699646
Validation loss: 2.2478502839803696

Epoch: 5| Step: 8
Training loss: 1.2680829763412476
Validation loss: 2.2826817681392035

Epoch: 5| Step: 9
Training loss: 1.397091269493103
Validation loss: 2.2851963192224503

Epoch: 5| Step: 10
Training loss: 1.551238775253296
Validation loss: 2.284858852624893

Epoch: 5| Step: 11
Training loss: 1.043626070022583
Validation loss: 2.2636321236689887

Epoch: 363| Step: 0
Training loss: 1.4541599750518799
Validation loss: 2.292071064313253

Epoch: 5| Step: 1
Training loss: 1.6611979007720947
Validation loss: 2.292953913410505

Epoch: 5| Step: 2
Training loss: 1.0522725582122803
Validation loss: 2.2577881713708243

Epoch: 5| Step: 3
Training loss: 1.1163241863250732
Validation loss: 2.2647271851698556

Epoch: 5| Step: 4
Training loss: 1.693929672241211
Validation loss: 2.25039508442084

Epoch: 5| Step: 5
Training loss: 1.641360878944397
Validation loss: 2.214380537470182

Epoch: 5| Step: 6
Training loss: 1.7931272983551025
Validation loss: 2.1813031683365502

Epoch: 5| Step: 7
Training loss: 1.6710102558135986
Validation loss: 2.14340112109979

Epoch: 5| Step: 8
Training loss: 1.8694308996200562
Validation loss: 2.177009344100952

Epoch: 5| Step: 9
Training loss: 1.2207450866699219
Validation loss: 2.1895326326290765

Epoch: 5| Step: 10
Training loss: 1.3045469522476196
Validation loss: 2.194367160399755

Epoch: 5| Step: 11
Training loss: 0.8993661999702454
Validation loss: 2.216677630941073

Epoch: 364| Step: 0
Training loss: 0.9355584979057312
Validation loss: 2.172609051068624

Epoch: 5| Step: 1
Training loss: 1.5724166631698608
Validation loss: 2.1508871018886566

Epoch: 5| Step: 2
Training loss: 1.6762332916259766
Validation loss: 2.186335727572441

Epoch: 5| Step: 3
Training loss: 1.2874996662139893
Validation loss: 2.2295120110114417

Epoch: 5| Step: 4
Training loss: 1.3577067852020264
Validation loss: 2.202736794948578

Epoch: 5| Step: 5
Training loss: 1.154964804649353
Validation loss: 2.251896763841311

Epoch: 5| Step: 6
Training loss: 1.1744611263275146
Validation loss: 2.2337992588678994

Epoch: 5| Step: 7
Training loss: 2.257000207901001
Validation loss: 2.2283105552196503

Epoch: 5| Step: 8
Training loss: 0.812427818775177
Validation loss: 2.2187140186627707

Epoch: 5| Step: 9
Training loss: 1.2626303434371948
Validation loss: 2.227918187777201

Epoch: 5| Step: 10
Training loss: 1.9431648254394531
Validation loss: 2.214690695206324

Epoch: 5| Step: 11
Training loss: 2.023820161819458
Validation loss: 2.2147973676522574

Epoch: 365| Step: 0
Training loss: 1.2052299976348877
Validation loss: 2.2406572004159293

Epoch: 5| Step: 1
Training loss: 1.3264795541763306
Validation loss: 2.2155530899763107

Epoch: 5| Step: 2
Training loss: 1.7421668767929077
Validation loss: 2.214616338411967

Epoch: 5| Step: 3
Training loss: 1.8707587718963623
Validation loss: 2.226672192414602

Epoch: 5| Step: 4
Training loss: 1.5855915546417236
Validation loss: 2.2360973159472146

Epoch: 5| Step: 5
Training loss: 1.2184804677963257
Validation loss: 2.220973844329516

Epoch: 5| Step: 6
Training loss: 1.5432521104812622
Validation loss: 2.2135699689388275

Epoch: 5| Step: 7
Training loss: 1.53976309299469
Validation loss: 2.2187370657920837

Epoch: 5| Step: 8
Training loss: 0.9850720167160034
Validation loss: 2.2432927091916404

Epoch: 5| Step: 9
Training loss: 1.4983265399932861
Validation loss: 2.2043947180112204

Epoch: 5| Step: 10
Training loss: 1.3868504762649536
Validation loss: 2.2242999970912933

Epoch: 5| Step: 11
Training loss: 1.9921540021896362
Validation loss: 2.2349257270495095

Epoch: 366| Step: 0
Training loss: 1.621025800704956
Validation loss: 2.2182227770487466

Epoch: 5| Step: 1
Training loss: 1.2978955507278442
Validation loss: 2.183282862106959

Epoch: 5| Step: 2
Training loss: 2.0239410400390625
Validation loss: 2.1652791500091553

Epoch: 5| Step: 3
Training loss: 1.5400689840316772
Validation loss: 2.2221179952224097

Epoch: 5| Step: 4
Training loss: 1.1290647983551025
Validation loss: 2.1972156912088394

Epoch: 5| Step: 5
Training loss: 1.814173698425293
Validation loss: 2.248291169603666

Epoch: 5| Step: 6
Training loss: 1.6286405324935913
Validation loss: 2.2599595487117767

Epoch: 5| Step: 7
Training loss: 1.2386592626571655
Validation loss: 2.2208558917045593

Epoch: 5| Step: 8
Training loss: 1.500387191772461
Validation loss: 2.1964553594589233

Epoch: 5| Step: 9
Training loss: 1.6311194896697998
Validation loss: 2.1950374792019525

Epoch: 5| Step: 10
Training loss: 1.1309744119644165
Validation loss: 2.1739871253569922

Epoch: 5| Step: 11
Training loss: 1.2582042217254639
Validation loss: 2.1946317106485367

Epoch: 367| Step: 0
Training loss: 1.4950898885726929
Validation loss: 2.211587126056353

Epoch: 5| Step: 1
Training loss: 1.628556251525879
Validation loss: 2.21151202917099

Epoch: 5| Step: 2
Training loss: 1.683648705482483
Validation loss: 2.196110427379608

Epoch: 5| Step: 3
Training loss: 1.3026903867721558
Validation loss: 2.1953808615605035

Epoch: 5| Step: 4
Training loss: 1.7272552251815796
Validation loss: 2.2233187158902488

Epoch: 5| Step: 5
Training loss: 1.4022718667984009
Validation loss: 2.2337651451428733

Epoch: 5| Step: 6
Training loss: 1.1432385444641113
Validation loss: 2.210426698128382

Epoch: 5| Step: 7
Training loss: 1.367035150527954
Validation loss: 2.2223462661107383

Epoch: 5| Step: 8
Training loss: 1.48561692237854
Validation loss: 2.252924789985021

Epoch: 5| Step: 9
Training loss: 1.4111692905426025
Validation loss: 2.24353755513827

Epoch: 5| Step: 10
Training loss: 1.6537965536117554
Validation loss: 2.2286917914946875

Epoch: 5| Step: 11
Training loss: 0.7008016109466553
Validation loss: 2.2547300656636557

Epoch: 368| Step: 0
Training loss: 1.5480647087097168
Validation loss: 2.240636318922043

Epoch: 5| Step: 1
Training loss: 1.5600597858428955
Validation loss: 2.2576561669508615

Epoch: 5| Step: 2
Training loss: 1.5185234546661377
Validation loss: 2.2498045762379966

Epoch: 5| Step: 3
Training loss: 1.6283226013183594
Validation loss: 2.250464325149854

Epoch: 5| Step: 4
Training loss: 1.8476731777191162
Validation loss: 2.2662082513173423

Epoch: 5| Step: 5
Training loss: 0.7083587646484375
Validation loss: 2.3065758695205054

Epoch: 5| Step: 6
Training loss: 2.020535945892334
Validation loss: 2.2708175828059516

Epoch: 5| Step: 7
Training loss: 0.9838557243347168
Validation loss: 2.2639289100964866

Epoch: 5| Step: 8
Training loss: 1.4072792530059814
Validation loss: 2.2475228955348334

Epoch: 5| Step: 9
Training loss: 0.8894914388656616
Validation loss: 2.2625523060560226

Epoch: 5| Step: 10
Training loss: 1.1399261951446533
Validation loss: 2.234791894753774

Epoch: 5| Step: 11
Training loss: 1.2107988595962524
Validation loss: 2.2279707292715707

Epoch: 369| Step: 0
Training loss: 1.4202289581298828
Validation loss: 2.1942361146211624

Epoch: 5| Step: 1
Training loss: 0.9061176180839539
Validation loss: 2.2102833290894828

Epoch: 5| Step: 2
Training loss: 1.1327954530715942
Validation loss: 2.2128287305434546

Epoch: 5| Step: 3
Training loss: 2.11727237701416
Validation loss: 2.2215503652890525

Epoch: 5| Step: 4
Training loss: 1.223209023475647
Validation loss: 2.1915436287721

Epoch: 5| Step: 5
Training loss: 1.3231514692306519
Validation loss: 2.183820992708206

Epoch: 5| Step: 6
Training loss: 1.449683427810669
Validation loss: 2.2305771509806314

Epoch: 5| Step: 7
Training loss: 1.404151439666748
Validation loss: 2.178839549422264

Epoch: 5| Step: 8
Training loss: 1.5017434358596802
Validation loss: 2.1838199297587075

Epoch: 5| Step: 9
Training loss: 1.2026870250701904
Validation loss: 2.219073603550593

Epoch: 5| Step: 10
Training loss: 1.4606266021728516
Validation loss: 2.2265207221110663

Epoch: 5| Step: 11
Training loss: 1.2762582302093506
Validation loss: 2.2371040085951486

Epoch: 370| Step: 0
Training loss: 1.0730266571044922
Validation loss: 2.2423993249734244

Epoch: 5| Step: 1
Training loss: 1.9646803140640259
Validation loss: 2.247440362970034

Epoch: 5| Step: 2
Training loss: 1.5037060976028442
Validation loss: 2.2407184739907584

Epoch: 5| Step: 3
Training loss: 1.0032837390899658
Validation loss: 2.2441568871339164

Epoch: 5| Step: 4
Training loss: 1.332643747329712
Validation loss: 2.242956966161728

Epoch: 5| Step: 5
Training loss: 1.7461172342300415
Validation loss: 2.198157638311386

Epoch: 5| Step: 6
Training loss: 1.3279063701629639
Validation loss: 2.2116323908170066

Epoch: 5| Step: 7
Training loss: 1.6394062042236328
Validation loss: 2.2250099877516427

Epoch: 5| Step: 8
Training loss: 0.9508846402168274
Validation loss: 2.210540294647217

Epoch: 5| Step: 9
Training loss: 1.0203189849853516
Validation loss: 2.2142176181077957

Epoch: 5| Step: 10
Training loss: 1.570725917816162
Validation loss: 2.2149998346964517

Epoch: 5| Step: 11
Training loss: 0.536769688129425
Validation loss: 2.1872947365045547

Epoch: 371| Step: 0
Training loss: 1.8120777606964111
Validation loss: 2.2019284864266715

Epoch: 5| Step: 1
Training loss: 1.3748302459716797
Validation loss: 2.2141381800174713

Epoch: 5| Step: 2
Training loss: 1.011563777923584
Validation loss: 2.2233350773652396

Epoch: 5| Step: 3
Training loss: 1.0894070863723755
Validation loss: 2.2532961865266166

Epoch: 5| Step: 4
Training loss: 1.37180495262146
Validation loss: 2.269333988428116

Epoch: 5| Step: 5
Training loss: 1.1553417444229126
Validation loss: 2.219102511803309

Epoch: 5| Step: 6
Training loss: 1.6241943836212158
Validation loss: 2.199976841608683

Epoch: 5| Step: 7
Training loss: 1.039971113204956
Validation loss: 2.1901178310314813

Epoch: 5| Step: 8
Training loss: 1.3052572011947632
Validation loss: 2.2008725901444754

Epoch: 5| Step: 9
Training loss: 1.3435919284820557
Validation loss: 2.218648682037989

Epoch: 5| Step: 10
Training loss: 1.0273538827896118
Validation loss: 2.193166176478068

Epoch: 5| Step: 11
Training loss: 1.5685701370239258
Validation loss: 2.212606370449066

Epoch: 372| Step: 0
Training loss: 1.4686005115509033
Validation loss: 2.187865734100342

Epoch: 5| Step: 1
Training loss: 1.3405441045761108
Validation loss: 2.2030351211627326

Epoch: 5| Step: 2
Training loss: 1.6479294300079346
Validation loss: 2.209966724117597

Epoch: 5| Step: 3
Training loss: 1.0321046113967896
Validation loss: 2.194013218084971

Epoch: 5| Step: 4
Training loss: 1.5234792232513428
Validation loss: 2.175142069657644

Epoch: 5| Step: 5
Training loss: 1.0232919454574585
Validation loss: 2.1709810545047126

Epoch: 5| Step: 6
Training loss: 0.7263405323028564
Validation loss: 2.1849592526753745

Epoch: 5| Step: 7
Training loss: 0.8446363210678101
Validation loss: 2.1576001048088074

Epoch: 5| Step: 8
Training loss: 1.9657083749771118
Validation loss: 2.1826683978239694

Epoch: 5| Step: 9
Training loss: 1.1600478887557983
Validation loss: 2.1732732305924096

Epoch: 5| Step: 10
Training loss: 1.6725887060165405
Validation loss: 2.187433660030365

Epoch: 5| Step: 11
Training loss: 2.385234832763672
Validation loss: 2.1920916736125946

Epoch: 373| Step: 0
Training loss: 1.3567521572113037
Validation loss: 2.184612527489662

Epoch: 5| Step: 1
Training loss: 1.971792459487915
Validation loss: 2.175554951032003

Epoch: 5| Step: 2
Training loss: 1.1857678890228271
Validation loss: 2.1933245013157525

Epoch: 5| Step: 3
Training loss: 1.4609802961349487
Validation loss: 2.1742131263017654

Epoch: 5| Step: 4
Training loss: 0.9970796704292297
Validation loss: 2.2201056828101478

Epoch: 5| Step: 5
Training loss: 1.345575213432312
Validation loss: 2.2221903602282205

Epoch: 5| Step: 6
Training loss: 0.6401345133781433
Validation loss: 2.19659490386645

Epoch: 5| Step: 7
Training loss: 1.622799277305603
Validation loss: 2.224340091149012

Epoch: 5| Step: 8
Training loss: 1.363166332244873
Validation loss: 2.2010964900255203

Epoch: 5| Step: 9
Training loss: 0.9927177429199219
Validation loss: 2.2135986934105554

Epoch: 5| Step: 10
Training loss: 1.2780163288116455
Validation loss: 2.2302999943494797

Epoch: 5| Step: 11
Training loss: 1.6747075319290161
Validation loss: 2.202938715616862

Epoch: 374| Step: 0
Training loss: 1.6872551441192627
Validation loss: 2.21744013329347

Epoch: 5| Step: 1
Training loss: 1.3142585754394531
Validation loss: 2.2380754500627518

Epoch: 5| Step: 2
Training loss: 1.309687614440918
Validation loss: 2.22692363957564

Epoch: 5| Step: 3
Training loss: 0.878332257270813
Validation loss: 2.216182842850685

Epoch: 5| Step: 4
Training loss: 1.2174108028411865
Validation loss: 2.2256518453359604

Epoch: 5| Step: 5
Training loss: 1.105541706085205
Validation loss: 2.2323335905869803

Epoch: 5| Step: 6
Training loss: 1.3241573572158813
Validation loss: 2.204277142882347

Epoch: 5| Step: 7
Training loss: 1.0066030025482178
Validation loss: 2.22089975575606

Epoch: 5| Step: 8
Training loss: 1.4600732326507568
Validation loss: 2.269082854191462

Epoch: 5| Step: 9
Training loss: 1.7275054454803467
Validation loss: 2.2369563033183417

Epoch: 5| Step: 10
Training loss: 0.8797404170036316
Validation loss: 2.218743175268173

Epoch: 5| Step: 11
Training loss: 1.6731035709381104
Validation loss: 2.2443220913410187

Epoch: 375| Step: 0
Training loss: 1.125526785850525
Validation loss: 2.2565090358257294

Epoch: 5| Step: 1
Training loss: 1.0750830173492432
Validation loss: 2.2041848252216973

Epoch: 5| Step: 2
Training loss: 1.460420846939087
Validation loss: 2.2202208091815314

Epoch: 5| Step: 3
Training loss: 0.9726412892341614
Validation loss: 2.214421113332113

Epoch: 5| Step: 4
Training loss: 2.1580440998077393
Validation loss: 2.230433444182078

Epoch: 5| Step: 5
Training loss: 1.412227988243103
Validation loss: 2.207846701145172

Epoch: 5| Step: 6
Training loss: 1.0161545276641846
Validation loss: 2.2201703687508902

Epoch: 5| Step: 7
Training loss: 1.1104531288146973
Validation loss: 2.2001427859067917

Epoch: 5| Step: 8
Training loss: 0.9090322256088257
Validation loss: 2.22086031238238

Epoch: 5| Step: 9
Training loss: 1.7781318426132202
Validation loss: 2.226840724547704

Epoch: 5| Step: 10
Training loss: 0.9542346000671387
Validation loss: 2.224696154395739

Epoch: 5| Step: 11
Training loss: 1.0266308784484863
Validation loss: 2.222956677277883

Epoch: 376| Step: 0
Training loss: 1.4210988283157349
Validation loss: 2.242225393652916

Epoch: 5| Step: 1
Training loss: 1.4455296993255615
Validation loss: 2.2126512825489044

Epoch: 5| Step: 2
Training loss: 1.3573696613311768
Validation loss: 2.23428808649381

Epoch: 5| Step: 3
Training loss: 1.1278152465820312
Validation loss: 2.200006718436877

Epoch: 5| Step: 4
Training loss: 1.3540802001953125
Validation loss: 2.2170926282803216

Epoch: 5| Step: 5
Training loss: 1.1686785221099854
Validation loss: 2.1978901078303656

Epoch: 5| Step: 6
Training loss: 1.0712698698043823
Validation loss: 2.19500100115935

Epoch: 5| Step: 7
Training loss: 1.1448150873184204
Validation loss: 2.201059261957804

Epoch: 5| Step: 8
Training loss: 1.3979041576385498
Validation loss: 2.203302785754204

Epoch: 5| Step: 9
Training loss: 0.9321504831314087
Validation loss: 2.17561241487662

Epoch: 5| Step: 10
Training loss: 1.7616933584213257
Validation loss: 2.197845940788587

Epoch: 5| Step: 11
Training loss: 0.28228509426116943
Validation loss: 2.1880058149496713

Epoch: 377| Step: 0
Training loss: 1.1441036462783813
Validation loss: 2.2310018042723336

Epoch: 5| Step: 1
Training loss: 1.366217017173767
Validation loss: 2.281275009115537

Epoch: 5| Step: 2
Training loss: 1.5577149391174316
Validation loss: 2.2664850850900016

Epoch: 5| Step: 3
Training loss: 1.3629376888275146
Validation loss: 2.2765872478485107

Epoch: 5| Step: 4
Training loss: 1.2759554386138916
Validation loss: 2.272364621361097

Epoch: 5| Step: 5
Training loss: 1.817582368850708
Validation loss: 2.279034768541654

Epoch: 5| Step: 6
Training loss: 1.1012485027313232
Validation loss: 2.275180588165919

Epoch: 5| Step: 7
Training loss: 1.2510303258895874
Validation loss: 2.2894923786322274

Epoch: 5| Step: 8
Training loss: 1.4156615734100342
Validation loss: 2.296385476986567

Epoch: 5| Step: 9
Training loss: 1.6337693929672241
Validation loss: 2.2844790518283844

Epoch: 5| Step: 10
Training loss: 1.3401339054107666
Validation loss: 2.264586235086123

Epoch: 5| Step: 11
Training loss: 0.7183412313461304
Validation loss: 2.2446099470059075

Epoch: 378| Step: 0
Training loss: 2.0242083072662354
Validation loss: 2.2267113824685416

Epoch: 5| Step: 1
Training loss: 1.6801698207855225
Validation loss: 2.1888425747553506

Epoch: 5| Step: 2
Training loss: 1.6979278326034546
Validation loss: 2.192677289247513

Epoch: 5| Step: 3
Training loss: 1.2272365093231201
Validation loss: 2.2419343839089074

Epoch: 5| Step: 4
Training loss: 0.9796470403671265
Validation loss: 2.2170935521523156

Epoch: 5| Step: 5
Training loss: 1.7484452724456787
Validation loss: 2.226515829563141

Epoch: 5| Step: 6
Training loss: 0.9909127354621887
Validation loss: 2.200986703236898

Epoch: 5| Step: 7
Training loss: 1.1927273273468018
Validation loss: 2.195429583390554

Epoch: 5| Step: 8
Training loss: 0.8223126530647278
Validation loss: 2.1794811338186264

Epoch: 5| Step: 9
Training loss: 1.6999547481536865
Validation loss: 2.157780721783638

Epoch: 5| Step: 10
Training loss: 1.039016842842102
Validation loss: 2.176469494899114

Epoch: 5| Step: 11
Training loss: 0.38999924063682556
Validation loss: 2.160616318384806

Epoch: 379| Step: 0
Training loss: 1.068691372871399
Validation loss: 2.162871499856313

Epoch: 5| Step: 1
Training loss: 1.4628818035125732
Validation loss: 2.169909343123436

Epoch: 5| Step: 2
Training loss: 0.9123117327690125
Validation loss: 2.165703604618708

Epoch: 5| Step: 3
Training loss: 1.1138302087783813
Validation loss: 2.164362425605456

Epoch: 5| Step: 4
Training loss: 1.555097222328186
Validation loss: 2.1833017816146216

Epoch: 5| Step: 5
Training loss: 0.8368986248970032
Validation loss: 2.1793248454729715

Epoch: 5| Step: 6
Training loss: 0.9892109632492065
Validation loss: 2.1705788175264993

Epoch: 5| Step: 7
Training loss: 1.0836732387542725
Validation loss: 2.1998193164666495

Epoch: 5| Step: 8
Training loss: 1.3620277643203735
Validation loss: 2.1941487987836203

Epoch: 5| Step: 9
Training loss: 1.401188611984253
Validation loss: 2.164589285850525

Epoch: 5| Step: 10
Training loss: 2.1724343299865723
Validation loss: 2.1987822453180947

Epoch: 5| Step: 11
Training loss: 0.9632136821746826
Validation loss: 2.1816465109586716

Epoch: 380| Step: 0
Training loss: 1.80440354347229
Validation loss: 2.204579070210457

Epoch: 5| Step: 1
Training loss: 1.109405517578125
Validation loss: 2.169996127486229

Epoch: 5| Step: 2
Training loss: 1.656206727027893
Validation loss: 2.1694483111302056

Epoch: 5| Step: 3
Training loss: 0.9845408201217651
Validation loss: 2.1929243355989456

Epoch: 5| Step: 4
Training loss: 1.6983789205551147
Validation loss: 2.2088701327641806

Epoch: 5| Step: 5
Training loss: 1.6836421489715576
Validation loss: 2.212622289856275

Epoch: 5| Step: 6
Training loss: 0.861960232257843
Validation loss: 2.19302728275458

Epoch: 5| Step: 7
Training loss: 0.9781202077865601
Validation loss: 2.2119597693284354

Epoch: 5| Step: 8
Training loss: 1.113170862197876
Validation loss: 2.2500385542710624

Epoch: 5| Step: 9
Training loss: 0.658930242061615
Validation loss: 2.222833037376404

Epoch: 5| Step: 10
Training loss: 1.5207504034042358
Validation loss: 2.227420841654142

Epoch: 5| Step: 11
Training loss: 0.8140326142311096
Validation loss: 2.1958552648623786

Epoch: 381| Step: 0
Training loss: 0.9379832148551941
Validation loss: 2.2359039386113486

Epoch: 5| Step: 1
Training loss: 0.861175537109375
Validation loss: 2.194253837068876

Epoch: 5| Step: 2
Training loss: 1.580971121788025
Validation loss: 2.226726084947586

Epoch: 5| Step: 3
Training loss: 1.523297905921936
Validation loss: 2.1479453394810357

Epoch: 5| Step: 4
Training loss: 1.3997423648834229
Validation loss: 2.143167942762375

Epoch: 5| Step: 5
Training loss: 1.252657413482666
Validation loss: 2.1431814481814704

Epoch: 5| Step: 6
Training loss: 1.4034245014190674
Validation loss: 2.151118293404579

Epoch: 5| Step: 7
Training loss: 1.2603107690811157
Validation loss: 2.1510419994592667

Epoch: 5| Step: 8
Training loss: 0.9407953023910522
Validation loss: 2.15273546675841

Epoch: 5| Step: 9
Training loss: 1.0913232564926147
Validation loss: 2.119804158806801

Epoch: 5| Step: 10
Training loss: 2.048344135284424
Validation loss: 2.175095265110334

Epoch: 5| Step: 11
Training loss: 0.6499664783477783
Validation loss: 2.2055863738059998

Epoch: 382| Step: 0
Training loss: 2.1078312397003174
Validation loss: 2.1892653008302054

Epoch: 5| Step: 1
Training loss: 1.408182144165039
Validation loss: 2.213604678710302

Epoch: 5| Step: 2
Training loss: 1.4009839296340942
Validation loss: 2.1998389661312103

Epoch: 5| Step: 3
Training loss: 1.140515685081482
Validation loss: 2.237058093150457

Epoch: 5| Step: 4
Training loss: 0.7026941180229187
Validation loss: 2.230853348970413

Epoch: 5| Step: 5
Training loss: 1.1394747495651245
Validation loss: 2.2755620380242667

Epoch: 5| Step: 6
Training loss: 0.9552233815193176
Validation loss: 2.2958651731411615

Epoch: 5| Step: 7
Training loss: 1.1787478923797607
Validation loss: 2.2551266650358834

Epoch: 5| Step: 8
Training loss: 1.628692388534546
Validation loss: 2.2413349598646164

Epoch: 5| Step: 9
Training loss: 1.1126749515533447
Validation loss: 2.25602695842584

Epoch: 5| Step: 10
Training loss: 1.3702621459960938
Validation loss: 2.2749601950248084

Epoch: 5| Step: 11
Training loss: 0.8984265327453613
Validation loss: 2.2470251619815826

Epoch: 383| Step: 0
Training loss: 1.1295057535171509
Validation loss: 2.243626763423284

Epoch: 5| Step: 1
Training loss: 0.7692626118659973
Validation loss: 2.2372817595799765

Epoch: 5| Step: 2
Training loss: 0.7884902954101562
Validation loss: 2.220176781217257

Epoch: 5| Step: 3
Training loss: 1.5073293447494507
Validation loss: 2.25118879477183

Epoch: 5| Step: 4
Training loss: 1.4023497104644775
Validation loss: 2.2072875052690506

Epoch: 5| Step: 5
Training loss: 0.9313637018203735
Validation loss: 2.21593347688516

Epoch: 5| Step: 6
Training loss: 0.8161279559135437
Validation loss: 2.188726236422857

Epoch: 5| Step: 7
Training loss: 1.5406193733215332
Validation loss: 2.1721681704123816

Epoch: 5| Step: 8
Training loss: 1.5349438190460205
Validation loss: 2.2047367990016937

Epoch: 5| Step: 9
Training loss: 1.7029368877410889
Validation loss: 2.1891677180926004

Epoch: 5| Step: 10
Training loss: 1.4631139039993286
Validation loss: 2.160418023665746

Epoch: 5| Step: 11
Training loss: 1.0339096784591675
Validation loss: 2.1660044391949973

Epoch: 384| Step: 0
Training loss: 1.5422290563583374
Validation loss: 2.1251875261465707

Epoch: 5| Step: 1
Training loss: 0.9333075284957886
Validation loss: 2.134804824988047

Epoch: 5| Step: 2
Training loss: 1.2025796175003052
Validation loss: 2.1719782650470734

Epoch: 5| Step: 3
Training loss: 1.3760855197906494
Validation loss: 2.158546711007754

Epoch: 5| Step: 4
Training loss: 1.272979974746704
Validation loss: 2.1272767086823783

Epoch: 5| Step: 5
Training loss: 1.093121886253357
Validation loss: 2.1738949616750083

Epoch: 5| Step: 6
Training loss: 1.414940595626831
Validation loss: 2.1729991187651954

Epoch: 5| Step: 7
Training loss: 0.8703978657722473
Validation loss: 2.1430397232373557

Epoch: 5| Step: 8
Training loss: 1.0897927284240723
Validation loss: 2.167093982299169

Epoch: 5| Step: 9
Training loss: 1.4784818887710571
Validation loss: 2.1890442073345184

Epoch: 5| Step: 10
Training loss: 1.519335389137268
Validation loss: 2.2207632263501487

Epoch: 5| Step: 11
Training loss: 1.3534822463989258
Validation loss: 2.236442675193151

Epoch: 385| Step: 0
Training loss: 0.9345229268074036
Validation loss: 2.200793370604515

Epoch: 5| Step: 1
Training loss: 1.0480949878692627
Validation loss: 2.2645570983489356

Epoch: 5| Step: 2
Training loss: 1.6262611150741577
Validation loss: 2.2355661739905677

Epoch: 5| Step: 3
Training loss: 1.6137430667877197
Validation loss: 2.219254901011785

Epoch: 5| Step: 4
Training loss: 1.0024278163909912
Validation loss: 2.2063157061735788

Epoch: 5| Step: 5
Training loss: 1.0802115201950073
Validation loss: 2.2186011721690497

Epoch: 5| Step: 6
Training loss: 1.1822162866592407
Validation loss: 2.2470857997735343

Epoch: 5| Step: 7
Training loss: 0.8208176493644714
Validation loss: 2.2258408715327582

Epoch: 5| Step: 8
Training loss: 1.83001708984375
Validation loss: 2.199392115076383

Epoch: 5| Step: 9
Training loss: 1.3021535873413086
Validation loss: 2.199235806862513

Epoch: 5| Step: 10
Training loss: 1.1858537197113037
Validation loss: 2.1953411599000296

Epoch: 5| Step: 11
Training loss: 0.5813437104225159
Validation loss: 2.204976628224055

Epoch: 386| Step: 0
Training loss: 1.1086859703063965
Validation loss: 2.2006240487098694

Epoch: 5| Step: 1
Training loss: 1.7219955921173096
Validation loss: 2.2062046229839325

Epoch: 5| Step: 2
Training loss: 0.9930661916732788
Validation loss: 2.1924801766872406

Epoch: 5| Step: 3
Training loss: 1.3192943334579468
Validation loss: 2.235791653394699

Epoch: 5| Step: 4
Training loss: 1.2760646343231201
Validation loss: 2.2176047960917153

Epoch: 5| Step: 5
Training loss: 0.904875636100769
Validation loss: 2.2618521402279534

Epoch: 5| Step: 6
Training loss: 1.4919792413711548
Validation loss: 2.233089422186216

Epoch: 5| Step: 7
Training loss: 0.6957225799560547
Validation loss: 2.228485052784284

Epoch: 5| Step: 8
Training loss: 1.3468654155731201
Validation loss: 2.2182906369368234

Epoch: 5| Step: 9
Training loss: 1.1958926916122437
Validation loss: 2.1758377254009247

Epoch: 5| Step: 10
Training loss: 1.1889607906341553
Validation loss: 2.2077093422412872

Epoch: 5| Step: 11
Training loss: 3.4791135787963867
Validation loss: 2.260066876808802

Epoch: 387| Step: 0
Training loss: 1.6976518630981445
Validation loss: 2.2788486828406653

Epoch: 5| Step: 1
Training loss: 1.7102779150009155
Validation loss: 2.3510948618253074

Epoch: 5| Step: 2
Training loss: 0.9512770771980286
Validation loss: 2.34012363354365

Epoch: 5| Step: 3
Training loss: 1.2338449954986572
Validation loss: 2.2608254651228585

Epoch: 5| Step: 4
Training loss: 1.354964017868042
Validation loss: 2.2313386698563895

Epoch: 5| Step: 5
Training loss: 0.8261713981628418
Validation loss: 2.1803891013065972

Epoch: 5| Step: 6
Training loss: 1.402470350265503
Validation loss: 2.257976879676183

Epoch: 5| Step: 7
Training loss: 1.7166544198989868
Validation loss: 2.2444020013014474

Epoch: 5| Step: 8
Training loss: 2.573514461517334
Validation loss: 2.2865690092245736

Epoch: 5| Step: 9
Training loss: 1.4211699962615967
Validation loss: 2.2963297019402185

Epoch: 5| Step: 10
Training loss: 2.0196940898895264
Validation loss: 2.2820445696512857

Epoch: 5| Step: 11
Training loss: 1.765933871269226
Validation loss: 2.30500528216362

Epoch: 388| Step: 0
Training loss: 2.1898868083953857
Validation loss: 2.294447918732961

Epoch: 5| Step: 1
Training loss: 1.4104981422424316
Validation loss: 2.3069790800412497

Epoch: 5| Step: 2
Training loss: 1.5047193765640259
Validation loss: 2.302086427807808

Epoch: 5| Step: 3
Training loss: 1.0264312028884888
Validation loss: 2.231182316939036

Epoch: 5| Step: 4
Training loss: 1.8109238147735596
Validation loss: 2.220684011777242

Epoch: 5| Step: 5
Training loss: 1.0544521808624268
Validation loss: 2.187157849470774

Epoch: 5| Step: 6
Training loss: 0.8502517938613892
Validation loss: 2.1970086097717285

Epoch: 5| Step: 7
Training loss: 0.9693706631660461
Validation loss: 2.1866281926631927

Epoch: 5| Step: 8
Training loss: 1.297167420387268
Validation loss: 2.160228967666626

Epoch: 5| Step: 9
Training loss: 1.5716544389724731
Validation loss: 2.1900715430577598

Epoch: 5| Step: 10
Training loss: 1.5770304203033447
Validation loss: 2.1935857236385345

Epoch: 5| Step: 11
Training loss: 1.8733646869659424
Validation loss: 2.1725369691848755

Epoch: 389| Step: 0
Training loss: 1.186073899269104
Validation loss: 2.1671061317125955

Epoch: 5| Step: 1
Training loss: 1.2694119215011597
Validation loss: 2.183939998348554

Epoch: 5| Step: 2
Training loss: 1.1118601560592651
Validation loss: 2.187632674972216

Epoch: 5| Step: 3
Training loss: 1.0217241048812866
Validation loss: 2.2042095363140106

Epoch: 5| Step: 4
Training loss: 1.264028787612915
Validation loss: 2.2020204911629357

Epoch: 5| Step: 5
Training loss: 0.9321130514144897
Validation loss: 2.1846444606781006

Epoch: 5| Step: 6
Training loss: 1.1096208095550537
Validation loss: 2.207940553625425

Epoch: 5| Step: 7
Training loss: 1.577392816543579
Validation loss: 2.18952739238739

Epoch: 5| Step: 8
Training loss: 1.2414381504058838
Validation loss: 2.2180453836917877

Epoch: 5| Step: 9
Training loss: 1.6179660558700562
Validation loss: 2.155136376619339

Epoch: 5| Step: 10
Training loss: 1.6673612594604492
Validation loss: 2.1662868609031043

Epoch: 5| Step: 11
Training loss: 1.7091610431671143
Validation loss: 2.159545456369718

Epoch: 390| Step: 0
Training loss: 1.4960744380950928
Validation loss: 2.14783405760924

Epoch: 5| Step: 1
Training loss: 1.171623945236206
Validation loss: 2.182965805133184

Epoch: 5| Step: 2
Training loss: 1.5348008871078491
Validation loss: 2.192818577090899

Epoch: 5| Step: 3
Training loss: 1.1576998233795166
Validation loss: 2.1704619775215783

Epoch: 5| Step: 4
Training loss: 1.6400721073150635
Validation loss: 2.1477412482102713

Epoch: 5| Step: 5
Training loss: 1.2640631198883057
Validation loss: 2.162290687362353

Epoch: 5| Step: 6
Training loss: 1.5420464277267456
Validation loss: 2.216440260410309

Epoch: 5| Step: 7
Training loss: 0.679356575012207
Validation loss: 2.171663542588552

Epoch: 5| Step: 8
Training loss: 0.7648183107376099
Validation loss: 2.195156469941139

Epoch: 5| Step: 9
Training loss: 1.295806646347046
Validation loss: 2.1968240489562354

Epoch: 5| Step: 10
Training loss: 0.8721113204956055
Validation loss: 2.2334912021954856

Epoch: 5| Step: 11
Training loss: 0.6467589139938354
Validation loss: 2.2135452230771384

Epoch: 391| Step: 0
Training loss: 2.169334888458252
Validation loss: 2.2620506982008615

Epoch: 5| Step: 1
Training loss: 1.62764573097229
Validation loss: 2.21942130724589

Epoch: 5| Step: 2
Training loss: 2.0237979888916016
Validation loss: 2.2083319971958795

Epoch: 5| Step: 3
Training loss: 1.5238306522369385
Validation loss: 2.208587795495987

Epoch: 5| Step: 4
Training loss: 0.8212334513664246
Validation loss: 2.1662493497133255

Epoch: 5| Step: 5
Training loss: 0.7189723253250122
Validation loss: 2.2204425930976868

Epoch: 5| Step: 6
Training loss: 1.1560879945755005
Validation loss: 2.1884775857130685

Epoch: 5| Step: 7
Training loss: 1.0147950649261475
Validation loss: 2.2056219975153604

Epoch: 5| Step: 8
Training loss: 1.1272995471954346
Validation loss: 2.2111273954312005

Epoch: 5| Step: 9
Training loss: 1.0524861812591553
Validation loss: 2.2310929149389267

Epoch: 5| Step: 10
Training loss: 1.0234676599502563
Validation loss: 2.186682641506195

Epoch: 5| Step: 11
Training loss: 1.6758596897125244
Validation loss: 2.1868586440881095

Epoch: 392| Step: 0
Training loss: 1.2119497060775757
Validation loss: 2.2265188644329705

Epoch: 5| Step: 1
Training loss: 1.408306360244751
Validation loss: 2.2460757990678153

Epoch: 5| Step: 2
Training loss: 1.0515004396438599
Validation loss: 2.2690917005141578

Epoch: 5| Step: 3
Training loss: 1.4033098220825195
Validation loss: 2.2206468929847083

Epoch: 5| Step: 4
Training loss: 1.238181471824646
Validation loss: 2.2442025244235992

Epoch: 5| Step: 5
Training loss: 1.6007459163665771
Validation loss: 2.2022371192773185

Epoch: 5| Step: 6
Training loss: 0.9386838674545288
Validation loss: 2.2232438921928406

Epoch: 5| Step: 7
Training loss: 1.1355984210968018
Validation loss: 2.197457363208135

Epoch: 5| Step: 8
Training loss: 1.0377525091171265
Validation loss: 2.189550911386808

Epoch: 5| Step: 9
Training loss: 0.8981014490127563
Validation loss: 2.1636228958765664

Epoch: 5| Step: 10
Training loss: 1.670149803161621
Validation loss: 2.205878729621569

Epoch: 5| Step: 11
Training loss: 2.4226527214050293
Validation loss: 2.1902238180239997

Epoch: 393| Step: 0
Training loss: 1.115653395652771
Validation loss: 2.207399864991506

Epoch: 5| Step: 1
Training loss: 1.5626065731048584
Validation loss: 2.191416636109352

Epoch: 5| Step: 2
Training loss: 1.5501983165740967
Validation loss: 2.231590837240219

Epoch: 5| Step: 3
Training loss: 1.2128204107284546
Validation loss: 2.2255560954411826

Epoch: 5| Step: 4
Training loss: 1.6425034999847412
Validation loss: 2.2204708456993103

Epoch: 5| Step: 5
Training loss: 1.0669628381729126
Validation loss: 2.2222242752710977

Epoch: 5| Step: 6
Training loss: 1.4989246129989624
Validation loss: 2.2145401934782663

Epoch: 5| Step: 7
Training loss: 0.8600245714187622
Validation loss: 2.238427663842837

Epoch: 5| Step: 8
Training loss: 1.019148349761963
Validation loss: 2.2289222925901413

Epoch: 5| Step: 9
Training loss: 1.3934104442596436
Validation loss: 2.240652600924174

Epoch: 5| Step: 10
Training loss: 1.1184132099151611
Validation loss: 2.2392624417940774

Epoch: 5| Step: 11
Training loss: 1.4629175662994385
Validation loss: 2.2216362953186035

Epoch: 394| Step: 0
Training loss: 1.5277459621429443
Validation loss: 2.2671429912249246

Epoch: 5| Step: 1
Training loss: 1.1801888942718506
Validation loss: 2.237686107556025

Epoch: 5| Step: 2
Training loss: 0.7872266173362732
Validation loss: 2.2033929526805878

Epoch: 5| Step: 3
Training loss: 0.7746305465698242
Validation loss: 2.2450575282176337

Epoch: 5| Step: 4
Training loss: 1.4699190855026245
Validation loss: 2.2279599408308663

Epoch: 5| Step: 5
Training loss: 1.583102822303772
Validation loss: 2.265695492426554

Epoch: 5| Step: 6
Training loss: 1.3262814283370972
Validation loss: 2.238032420476278

Epoch: 5| Step: 7
Training loss: 1.2182178497314453
Validation loss: 2.220396434267362

Epoch: 5| Step: 8
Training loss: 1.5991477966308594
Validation loss: 2.1980897982915244

Epoch: 5| Step: 9
Training loss: 1.4032589197158813
Validation loss: 2.205522909760475

Epoch: 5| Step: 10
Training loss: 1.1138533353805542
Validation loss: 2.2101044952869415

Epoch: 5| Step: 11
Training loss: 2.418501853942871
Validation loss: 2.1739531457424164

Epoch: 395| Step: 0
Training loss: 0.8401540517807007
Validation loss: 2.1764320184787116

Epoch: 5| Step: 1
Training loss: 1.0718785524368286
Validation loss: 2.1543808380762735

Epoch: 5| Step: 2
Training loss: 1.301555871963501
Validation loss: 2.169226730863253

Epoch: 5| Step: 3
Training loss: 1.527409553527832
Validation loss: 2.1770093788703284

Epoch: 5| Step: 4
Training loss: 1.7523313760757446
Validation loss: 2.1428846021493277

Epoch: 5| Step: 5
Training loss: 1.5805180072784424
Validation loss: 2.158599615097046

Epoch: 5| Step: 6
Training loss: 1.3426563739776611
Validation loss: 2.153001363078753

Epoch: 5| Step: 7
Training loss: 1.410519003868103
Validation loss: 2.166593278447787

Epoch: 5| Step: 8
Training loss: 0.875016987323761
Validation loss: 2.1581893960634866

Epoch: 5| Step: 9
Training loss: 0.6957641839981079
Validation loss: 2.197742020090421

Epoch: 5| Step: 10
Training loss: 1.469734787940979
Validation loss: 2.1800816108783088

Epoch: 5| Step: 11
Training loss: 0.8016017079353333
Validation loss: 2.1723889062801995

Epoch: 396| Step: 0
Training loss: 0.7527691721916199
Validation loss: 2.192503253618876

Epoch: 5| Step: 1
Training loss: 1.5072758197784424
Validation loss: 2.230516731739044

Epoch: 5| Step: 2
Training loss: 1.6533238887786865
Validation loss: 2.226059466600418

Epoch: 5| Step: 3
Training loss: 1.2160345315933228
Validation loss: 2.227405697107315

Epoch: 5| Step: 4
Training loss: 1.2669166326522827
Validation loss: 2.2335611085096994

Epoch: 5| Step: 5
Training loss: 1.0823891162872314
Validation loss: 2.204991857210795

Epoch: 5| Step: 6
Training loss: 1.0716969966888428
Validation loss: 2.2142811715602875

Epoch: 5| Step: 7
Training loss: 1.2147529125213623
Validation loss: 2.190236190954844

Epoch: 5| Step: 8
Training loss: 1.0839723348617554
Validation loss: 2.180412838856379

Epoch: 5| Step: 9
Training loss: 1.1388908624649048
Validation loss: 2.2051632006963096

Epoch: 5| Step: 10
Training loss: 1.7062203884124756
Validation loss: 2.172936255733172

Epoch: 5| Step: 11
Training loss: 1.2772889137268066
Validation loss: 2.1979107161362967

Epoch: 397| Step: 0
Training loss: 1.3033651113510132
Validation loss: 2.174270103375117

Epoch: 5| Step: 1
Training loss: 1.1232854127883911
Validation loss: 2.2061568945646286

Epoch: 5| Step: 2
Training loss: 1.1857699155807495
Validation loss: 2.214426005880038

Epoch: 5| Step: 3
Training loss: 1.6627782583236694
Validation loss: 2.228692481915156

Epoch: 5| Step: 4
Training loss: 1.2361650466918945
Validation loss: 2.226763198773066

Epoch: 5| Step: 5
Training loss: 1.111186146736145
Validation loss: 2.2172655363877616

Epoch: 5| Step: 6
Training loss: 0.8282880783081055
Validation loss: 2.215840627749761

Epoch: 5| Step: 7
Training loss: 1.5555263757705688
Validation loss: 2.169422169526418

Epoch: 5| Step: 8
Training loss: 1.7522462606430054
Validation loss: 2.2006196876366935

Epoch: 5| Step: 9
Training loss: 1.1225727796554565
Validation loss: 2.164397398630778

Epoch: 5| Step: 10
Training loss: 0.8180678486824036
Validation loss: 2.1878386040528617

Epoch: 5| Step: 11
Training loss: 1.2948765754699707
Validation loss: 2.179584970076879

Epoch: 398| Step: 0
Training loss: 1.6709816455841064
Validation loss: 2.1767249951759973

Epoch: 5| Step: 1
Training loss: 1.3427515029907227
Validation loss: 2.1684048622846603

Epoch: 5| Step: 2
Training loss: 1.2380670309066772
Validation loss: 2.1348683536052704

Epoch: 5| Step: 3
Training loss: 1.0277092456817627
Validation loss: 2.1716818809509277

Epoch: 5| Step: 4
Training loss: 0.8584826588630676
Validation loss: 2.1756543020407357

Epoch: 5| Step: 5
Training loss: 1.2832978963851929
Validation loss: 2.1891383081674576

Epoch: 5| Step: 6
Training loss: 1.692848801612854
Validation loss: 2.17559090256691

Epoch: 5| Step: 7
Training loss: 0.9295679330825806
Validation loss: 2.165004218618075

Epoch: 5| Step: 8
Training loss: 1.1553640365600586
Validation loss: 2.1941298643747964

Epoch: 5| Step: 9
Training loss: 1.1467071771621704
Validation loss: 2.185556968053182

Epoch: 5| Step: 10
Training loss: 0.967647910118103
Validation loss: 2.1851001729567847

Epoch: 5| Step: 11
Training loss: 0.42302191257476807
Validation loss: 2.1675658027331033

Epoch: 399| Step: 0
Training loss: 0.7992778420448303
Validation loss: 2.1548830469449363

Epoch: 5| Step: 1
Training loss: 1.549057126045227
Validation loss: 2.195029765367508

Epoch: 5| Step: 2
Training loss: 1.3726059198379517
Validation loss: 2.1953532099723816

Epoch: 5| Step: 3
Training loss: 1.4163004159927368
Validation loss: 2.1686135679483414

Epoch: 5| Step: 4
Training loss: 0.814038097858429
Validation loss: 2.231870397925377

Epoch: 5| Step: 5
Training loss: 1.6763534545898438
Validation loss: 2.233373681704203

Epoch: 5| Step: 6
Training loss: 0.8975849151611328
Validation loss: 2.2052700519561768

Epoch: 5| Step: 7
Training loss: 1.586915373802185
Validation loss: 2.1746224711338678

Epoch: 5| Step: 8
Training loss: 1.235396146774292
Validation loss: 2.2127169569333396

Epoch: 5| Step: 9
Training loss: 0.8723305463790894
Validation loss: 2.195076033473015

Epoch: 5| Step: 10
Training loss: 1.6309057474136353
Validation loss: 2.1612741549809775

Epoch: 5| Step: 11
Training loss: 0.9004755616188049
Validation loss: 2.20578341682752

Epoch: 400| Step: 0
Training loss: 1.790114402770996
Validation loss: 2.22182098031044

Epoch: 5| Step: 1
Training loss: 1.1649714708328247
Validation loss: 2.1883108963569007

Epoch: 5| Step: 2
Training loss: 1.131408452987671
Validation loss: 2.2082326660553613

Epoch: 5| Step: 3
Training loss: 1.510613203048706
Validation loss: 2.2091258466243744

Epoch: 5| Step: 4
Training loss: 1.8313026428222656
Validation loss: 2.220708300669988

Epoch: 5| Step: 5
Training loss: 0.7712658643722534
Validation loss: 2.1915010660886765

Epoch: 5| Step: 6
Training loss: 0.6790167093276978
Validation loss: 2.176807150244713

Epoch: 5| Step: 7
Training loss: 1.0455615520477295
Validation loss: 2.1543932954470315

Epoch: 5| Step: 8
Training loss: 1.050824522972107
Validation loss: 2.1950919230779014

Epoch: 5| Step: 9
Training loss: 1.0752063989639282
Validation loss: 2.169374326864878

Epoch: 5| Step: 10
Training loss: 1.047521710395813
Validation loss: 2.16074700653553

Epoch: 5| Step: 11
Training loss: 0.7271902561187744
Validation loss: 2.1495739618937173

Epoch: 401| Step: 0
Training loss: 1.2931495904922485
Validation loss: 2.169401377439499

Epoch: 5| Step: 1
Training loss: 1.330066442489624
Validation loss: 2.1816403716802597

Epoch: 5| Step: 2
Training loss: 2.4599721431732178
Validation loss: 2.173809895912806

Epoch: 5| Step: 3
Training loss: 1.775132179260254
Validation loss: 2.1889644960562387

Epoch: 5| Step: 4
Training loss: 0.7951921224594116
Validation loss: 2.1937200079361596

Epoch: 5| Step: 5
Training loss: 0.7457584142684937
Validation loss: 2.1691144009431205

Epoch: 5| Step: 6
Training loss: 1.098984718322754
Validation loss: 2.1939854125181832

Epoch: 5| Step: 7
Training loss: 1.033936619758606
Validation loss: 2.183521260817846

Epoch: 5| Step: 8
Training loss: 1.5124881267547607
Validation loss: 2.1783252159754434

Epoch: 5| Step: 9
Training loss: 1.165799856185913
Validation loss: 2.228492165605227

Epoch: 5| Step: 10
Training loss: 0.6816768646240234
Validation loss: 2.22818856438001

Epoch: 5| Step: 11
Training loss: 0.9834986925125122
Validation loss: 2.241484373807907

Epoch: 402| Step: 0
Training loss: 1.6490371227264404
Validation loss: 2.24188394844532

Epoch: 5| Step: 1
Training loss: 0.7678905725479126
Validation loss: 2.2183457215627036

Epoch: 5| Step: 2
Training loss: 0.8061705827713013
Validation loss: 2.2210425635178885

Epoch: 5| Step: 3
Training loss: 0.750058650970459
Validation loss: 2.187268858154615

Epoch: 5| Step: 4
Training loss: 1.4329197406768799
Validation loss: 2.2152886589368186

Epoch: 5| Step: 5
Training loss: 0.6679077744483948
Validation loss: 2.2274727523326874

Epoch: 5| Step: 6
Training loss: 1.1815952062606812
Validation loss: 2.231235921382904

Epoch: 5| Step: 7
Training loss: 1.6904102563858032
Validation loss: 2.250069330135981

Epoch: 5| Step: 8
Training loss: 1.5125668048858643
Validation loss: 2.2400512198607125

Epoch: 5| Step: 9
Training loss: 1.7840509414672852
Validation loss: 2.2033039033412933

Epoch: 5| Step: 10
Training loss: 1.051588773727417
Validation loss: 2.2040821065505347

Epoch: 5| Step: 11
Training loss: 0.6643049716949463
Validation loss: 2.188812732696533

Epoch: 403| Step: 0
Training loss: 1.0752217769622803
Validation loss: 2.205812911192576

Epoch: 5| Step: 1
Training loss: 1.738358497619629
Validation loss: 2.208504562576612

Epoch: 5| Step: 2
Training loss: 1.3248831033706665
Validation loss: 2.204824904600779

Epoch: 5| Step: 3
Training loss: 1.5311760902404785
Validation loss: 2.2050793766975403

Epoch: 5| Step: 4
Training loss: 1.499319076538086
Validation loss: 2.211672673622767

Epoch: 5| Step: 5
Training loss: 0.7625693082809448
Validation loss: 2.203738878170649

Epoch: 5| Step: 6
Training loss: 1.237565279006958
Validation loss: 2.1747571726640067

Epoch: 5| Step: 7
Training loss: 1.299144983291626
Validation loss: 2.2068501661221185

Epoch: 5| Step: 8
Training loss: 1.3245899677276611
Validation loss: 2.215290163954099

Epoch: 5| Step: 9
Training loss: 1.09403657913208
Validation loss: 2.222730368375778

Epoch: 5| Step: 10
Training loss: 0.7815563082695007
Validation loss: 2.2405362327893577

Epoch: 5| Step: 11
Training loss: 2.926027774810791
Validation loss: 2.258338510990143

Epoch: 404| Step: 0
Training loss: 1.020260214805603
Validation loss: 2.2290230294068656

Epoch: 5| Step: 1
Training loss: 1.3745946884155273
Validation loss: 2.2640800923109055

Epoch: 5| Step: 2
Training loss: 1.3774912357330322
Validation loss: 2.226570785045624

Epoch: 5| Step: 3
Training loss: 1.3536067008972168
Validation loss: 2.2340731769800186

Epoch: 5| Step: 4
Training loss: 1.1399030685424805
Validation loss: 2.1890392849842706

Epoch: 5| Step: 5
Training loss: 1.109804630279541
Validation loss: 2.1521412382523217

Epoch: 5| Step: 6
Training loss: 1.0424047708511353
Validation loss: 2.1735446552435556

Epoch: 5| Step: 7
Training loss: 0.8316375017166138
Validation loss: 2.1256073117256165

Epoch: 5| Step: 8
Training loss: 1.0023654699325562
Validation loss: 2.1572440365950265

Epoch: 5| Step: 9
Training loss: 1.9066423177719116
Validation loss: 2.094761992494265

Epoch: 5| Step: 10
Training loss: 2.1177029609680176
Validation loss: 2.141597737868627

Epoch: 5| Step: 11
Training loss: 1.7589765787124634
Validation loss: 2.1121996144453683

Epoch: 405| Step: 0
Training loss: 1.7685232162475586
Validation loss: 2.102155630787214

Epoch: 5| Step: 1
Training loss: 1.1358451843261719
Validation loss: 2.132829720775286

Epoch: 5| Step: 2
Training loss: 0.721234917640686
Validation loss: 2.1792836288611093

Epoch: 5| Step: 3
Training loss: 1.611850380897522
Validation loss: 2.1547180811564126

Epoch: 5| Step: 4
Training loss: 0.9648289680480957
Validation loss: 2.1916429648796716

Epoch: 5| Step: 5
Training loss: 1.500096082687378
Validation loss: 2.1749044905106225

Epoch: 5| Step: 6
Training loss: 0.5925987362861633
Validation loss: 2.1696147123972573

Epoch: 5| Step: 7
Training loss: 1.4482344388961792
Validation loss: 2.1864179521799088

Epoch: 5| Step: 8
Training loss: 1.1585344076156616
Validation loss: 2.209445998072624

Epoch: 5| Step: 9
Training loss: 1.4582366943359375
Validation loss: 2.1819766561190286

Epoch: 5| Step: 10
Training loss: 1.0145543813705444
Validation loss: 2.1845484226942062

Epoch: 5| Step: 11
Training loss: 1.0433392524719238
Validation loss: 2.203039969007174

Epoch: 406| Step: 0
Training loss: 1.1667290925979614
Validation loss: 2.1995669851700463

Epoch: 5| Step: 1
Training loss: 0.5223101377487183
Validation loss: 2.1609081824620566

Epoch: 5| Step: 2
Training loss: 1.790185570716858
Validation loss: 2.239065776268641

Epoch: 5| Step: 3
Training loss: 1.326991081237793
Validation loss: 2.1869092682997384

Epoch: 5| Step: 4
Training loss: 1.5167728662490845
Validation loss: 2.22162198026975

Epoch: 5| Step: 5
Training loss: 1.8954436779022217
Validation loss: 2.211356242497762

Epoch: 5| Step: 6
Training loss: 1.1937358379364014
Validation loss: 2.1818737238645554

Epoch: 5| Step: 7
Training loss: 1.1643069982528687
Validation loss: 2.1715370217959085

Epoch: 5| Step: 8
Training loss: 1.1341516971588135
Validation loss: 2.1432630817095437

Epoch: 5| Step: 9
Training loss: 1.1497527360916138
Validation loss: 2.167780707279841

Epoch: 5| Step: 10
Training loss: 0.6478890180587769
Validation loss: 2.149617855747541

Epoch: 5| Step: 11
Training loss: 0.8614240288734436
Validation loss: 2.146811922391256

Epoch: 407| Step: 0
Training loss: 1.3270022869110107
Validation loss: 2.1284002363681793

Epoch: 5| Step: 1
Training loss: 0.8105586767196655
Validation loss: 2.1128928562005362

Epoch: 5| Step: 2
Training loss: 1.2478601932525635
Validation loss: 2.1627087692419686

Epoch: 5| Step: 3
Training loss: 1.3693640232086182
Validation loss: 2.141821950674057

Epoch: 5| Step: 4
Training loss: 1.1577074527740479
Validation loss: 2.1441905945539474

Epoch: 5| Step: 5
Training loss: 1.0424175262451172
Validation loss: 2.119348406791687

Epoch: 5| Step: 6
Training loss: 1.4717485904693604
Validation loss: 2.121840243538221

Epoch: 5| Step: 7
Training loss: 0.9635032415390015
Validation loss: 2.1546923170487084

Epoch: 5| Step: 8
Training loss: 1.3879932165145874
Validation loss: 2.1418861895799637

Epoch: 5| Step: 9
Training loss: 1.281524896621704
Validation loss: 2.170340125759443

Epoch: 5| Step: 10
Training loss: 1.190855622291565
Validation loss: 2.2207037011782327

Epoch: 5| Step: 11
Training loss: 0.825210690498352
Validation loss: 2.2029732366402945

Epoch: 408| Step: 0
Training loss: 1.5505362749099731
Validation loss: 2.216874822974205

Epoch: 5| Step: 1
Training loss: 0.8944321870803833
Validation loss: 2.224333316087723

Epoch: 5| Step: 2
Training loss: 1.6156505346298218
Validation loss: 2.205990289648374

Epoch: 5| Step: 3
Training loss: 1.1380786895751953
Validation loss: 2.195372993747393

Epoch: 5| Step: 4
Training loss: 0.8670557141304016
Validation loss: 2.2104128003120422

Epoch: 5| Step: 5
Training loss: 1.1154029369354248
Validation loss: 2.1911189208428064

Epoch: 5| Step: 6
Training loss: 1.5440435409545898
Validation loss: 2.204902788003286

Epoch: 5| Step: 7
Training loss: 1.0546602010726929
Validation loss: 2.198478549718857

Epoch: 5| Step: 8
Training loss: 0.8394063711166382
Validation loss: 2.2018659810225167

Epoch: 5| Step: 9
Training loss: 1.3002103567123413
Validation loss: 2.2152512669563293

Epoch: 5| Step: 10
Training loss: 1.0005767345428467
Validation loss: 2.226525366306305

Epoch: 5| Step: 11
Training loss: 1.1180378198623657
Validation loss: 2.2145169178644815

Epoch: 409| Step: 0
Training loss: 0.6095999479293823
Validation loss: 2.188762585322062

Epoch: 5| Step: 1
Training loss: 1.1215310096740723
Validation loss: 2.1670829951763153

Epoch: 5| Step: 2
Training loss: 1.10403573513031
Validation loss: 2.1938325564066568

Epoch: 5| Step: 3
Training loss: 1.051639199256897
Validation loss: 2.2007713317871094

Epoch: 5| Step: 4
Training loss: 1.1240062713623047
Validation loss: 2.176280160744985

Epoch: 5| Step: 5
Training loss: 0.9684670567512512
Validation loss: 2.1814991583426795

Epoch: 5| Step: 6
Training loss: 1.1037532091140747
Validation loss: 2.1603720287481942

Epoch: 5| Step: 7
Training loss: 1.0071619749069214
Validation loss: 2.245986839135488

Epoch: 5| Step: 8
Training loss: 1.8251148462295532
Validation loss: 2.201155294974645

Epoch: 5| Step: 9
Training loss: 1.5616000890731812
Validation loss: 2.2131715019543967

Epoch: 5| Step: 10
Training loss: 1.3602651357650757
Validation loss: 2.2283978164196014

Epoch: 5| Step: 11
Training loss: 0.5266286134719849
Validation loss: 2.217042247454325

Epoch: 410| Step: 0
Training loss: 0.8717215657234192
Validation loss: 2.2078897754351297

Epoch: 5| Step: 1
Training loss: 1.0386877059936523
Validation loss: 2.2481435239315033

Epoch: 5| Step: 2
Training loss: 1.2858664989471436
Validation loss: 2.2327286998430886

Epoch: 5| Step: 3
Training loss: 1.4577785730361938
Validation loss: 2.2187744031349816

Epoch: 5| Step: 4
Training loss: 1.315880537033081
Validation loss: 2.1883263190587363

Epoch: 5| Step: 5
Training loss: 1.1462501287460327
Validation loss: 2.1730737586816153

Epoch: 5| Step: 6
Training loss: 1.5169782638549805
Validation loss: 2.142137333750725

Epoch: 5| Step: 7
Training loss: 1.2867168188095093
Validation loss: 2.1690093825260797

Epoch: 5| Step: 8
Training loss: 1.0309031009674072
Validation loss: 2.1501527627309165

Epoch: 5| Step: 9
Training loss: 0.9010213017463684
Validation loss: 2.1655009984970093

Epoch: 5| Step: 10
Training loss: 1.2597711086273193
Validation loss: 2.164336313803991

Epoch: 5| Step: 11
Training loss: 0.8145309090614319
Validation loss: 2.1760327219963074

Epoch: 411| Step: 0
Training loss: 1.1214375495910645
Validation loss: 2.1806724965572357

Epoch: 5| Step: 1
Training loss: 1.2259540557861328
Validation loss: 2.1432028859853745

Epoch: 5| Step: 2
Training loss: 0.8772643208503723
Validation loss: 2.1979387750228248

Epoch: 5| Step: 3
Training loss: 0.8721103668212891
Validation loss: 2.1540231307347617

Epoch: 5| Step: 4
Training loss: 1.6297394037246704
Validation loss: 2.20187047123909

Epoch: 5| Step: 5
Training loss: 1.2653496265411377
Validation loss: 2.2553599725166955

Epoch: 5| Step: 6
Training loss: 0.8760161399841309
Validation loss: 2.2214422027269998

Epoch: 5| Step: 7
Training loss: 1.0266666412353516
Validation loss: 2.197562575340271

Epoch: 5| Step: 8
Training loss: 1.4837268590927124
Validation loss: 2.193691591421763

Epoch: 5| Step: 9
Training loss: 0.8447582125663757
Validation loss: 2.214772582054138

Epoch: 5| Step: 10
Training loss: 1.5159640312194824
Validation loss: 2.2191599011421204

Epoch: 5| Step: 11
Training loss: 2.331817150115967
Validation loss: 2.2276838223139444

Epoch: 412| Step: 0
Training loss: 1.3049747943878174
Validation loss: 2.241520802179972

Epoch: 5| Step: 1
Training loss: 0.7818757891654968
Validation loss: 2.287757416566213

Epoch: 5| Step: 2
Training loss: 0.991956353187561
Validation loss: 2.300311436255773

Epoch: 5| Step: 3
Training loss: 1.2142263650894165
Validation loss: 2.323629637559255

Epoch: 5| Step: 4
Training loss: 1.209047555923462
Validation loss: 2.3486862778663635

Epoch: 5| Step: 5
Training loss: 1.566582441329956
Validation loss: 2.2410284181435904

Epoch: 5| Step: 6
Training loss: 1.3494832515716553
Validation loss: 2.2546271085739136

Epoch: 5| Step: 7
Training loss: 0.8939633369445801
Validation loss: 2.2649377286434174

Epoch: 5| Step: 8
Training loss: 1.8050708770751953
Validation loss: 2.2301581303278604

Epoch: 5| Step: 9
Training loss: 2.005300521850586
Validation loss: 2.2253280729055405

Epoch: 5| Step: 10
Training loss: 0.9167081713676453
Validation loss: 2.265554462869962

Epoch: 5| Step: 11
Training loss: 2.1150777339935303
Validation loss: 2.217573051651319

Epoch: 413| Step: 0
Training loss: 2.2341666221618652
Validation loss: 2.1963186313708625

Epoch: 5| Step: 1
Training loss: 1.0740256309509277
Validation loss: 2.2103783090909324

Epoch: 5| Step: 2
Training loss: 0.7611331939697266
Validation loss: 2.2204664995272956

Epoch: 5| Step: 3
Training loss: 1.4555760622024536
Validation loss: 2.2215412259101868

Epoch: 5| Step: 4
Training loss: 0.9728442430496216
Validation loss: 2.1677918831507363

Epoch: 5| Step: 5
Training loss: 1.3025652170181274
Validation loss: 2.150794913371404

Epoch: 5| Step: 6
Training loss: 1.601388692855835
Validation loss: 2.1301520615816116

Epoch: 5| Step: 7
Training loss: 1.0076913833618164
Validation loss: 2.166754355033239

Epoch: 5| Step: 8
Training loss: 1.4308665990829468
Validation loss: 2.1838393608729043

Epoch: 5| Step: 9
Training loss: 0.9625797271728516
Validation loss: 2.18346706032753

Epoch: 5| Step: 10
Training loss: 1.095423936843872
Validation loss: 2.154917299747467

Epoch: 5| Step: 11
Training loss: 1.1707452535629272
Validation loss: 2.1163548032442727

Epoch: 414| Step: 0
Training loss: 1.424842357635498
Validation loss: 2.148478771249453

Epoch: 5| Step: 1
Training loss: 2.0840067863464355
Validation loss: 2.158595934510231

Epoch: 5| Step: 2
Training loss: 1.1621161699295044
Validation loss: 2.1863802323738732

Epoch: 5| Step: 3
Training loss: 1.0451202392578125
Validation loss: 2.233974725008011

Epoch: 5| Step: 4
Training loss: 0.8593236804008484
Validation loss: 2.2177881648143134

Epoch: 5| Step: 5
Training loss: 0.9767690896987915
Validation loss: 2.2238592008749642

Epoch: 5| Step: 6
Training loss: 1.3013213872909546
Validation loss: 2.2236303289731345

Epoch: 5| Step: 7
Training loss: 1.1062383651733398
Validation loss: 2.230831424395243

Epoch: 5| Step: 8
Training loss: 0.9289194345474243
Validation loss: 2.1874859780073166

Epoch: 5| Step: 9
Training loss: 1.0596742630004883
Validation loss: 2.2454304297765098

Epoch: 5| Step: 10
Training loss: 1.0481575727462769
Validation loss: 2.1921602139870324

Epoch: 5| Step: 11
Training loss: 1.0957571268081665
Validation loss: 2.1813498934110007

Epoch: 415| Step: 0
Training loss: 1.2593309879302979
Validation loss: 2.1877006689707437

Epoch: 5| Step: 1
Training loss: 1.5006023645401
Validation loss: 2.1955339908599854

Epoch: 5| Step: 2
Training loss: 1.1246204376220703
Validation loss: 2.230581690867742

Epoch: 5| Step: 3
Training loss: 0.8356574773788452
Validation loss: 2.1995886663595834

Epoch: 5| Step: 4
Training loss: 0.6363732814788818
Validation loss: 2.192360291878382

Epoch: 5| Step: 5
Training loss: 1.2800185680389404
Validation loss: 2.219326744476954

Epoch: 5| Step: 6
Training loss: 0.6811956167221069
Validation loss: 2.2324442118406296

Epoch: 5| Step: 7
Training loss: 1.179577350616455
Validation loss: 2.2105635503927865

Epoch: 5| Step: 8
Training loss: 1.8749300241470337
Validation loss: 2.2553276121616364

Epoch: 5| Step: 9
Training loss: 1.2189397811889648
Validation loss: 2.224019691348076

Epoch: 5| Step: 10
Training loss: 1.2229857444763184
Validation loss: 2.189670652151108

Epoch: 5| Step: 11
Training loss: 1.8364458084106445
Validation loss: 2.2547818620999656

Epoch: 416| Step: 0
Training loss: 0.9629778861999512
Validation loss: 2.2695205907026925

Epoch: 5| Step: 1
Training loss: 1.3028390407562256
Validation loss: 2.258864924311638

Epoch: 5| Step: 2
Training loss: 0.9090608358383179
Validation loss: 2.2785725593566895

Epoch: 5| Step: 3
Training loss: 1.4260733127593994
Validation loss: 2.248625655968984

Epoch: 5| Step: 4
Training loss: 1.6759437322616577
Validation loss: 2.2540507117907205

Epoch: 5| Step: 5
Training loss: 1.0375244617462158
Validation loss: 2.2363403737545013

Epoch: 5| Step: 6
Training loss: 1.1371982097625732
Validation loss: 2.267687514424324

Epoch: 5| Step: 7
Training loss: 1.0869338512420654
Validation loss: 2.227578947941462

Epoch: 5| Step: 8
Training loss: 1.2600017786026
Validation loss: 2.2183191080888114

Epoch: 5| Step: 9
Training loss: 1.026177167892456
Validation loss: 2.2069694101810455

Epoch: 5| Step: 10
Training loss: 0.775593638420105
Validation loss: 2.178777967890104

Epoch: 5| Step: 11
Training loss: 2.5413851737976074
Validation loss: 2.20113867521286

Epoch: 417| Step: 0
Training loss: 1.1311745643615723
Validation loss: 2.219135751326879

Epoch: 5| Step: 1
Training loss: 1.2687734365463257
Validation loss: 2.196909914414088

Epoch: 5| Step: 2
Training loss: 0.5900659561157227
Validation loss: 2.2220662236213684

Epoch: 5| Step: 3
Training loss: 0.859592080116272
Validation loss: 2.1885470698277154

Epoch: 5| Step: 4
Training loss: 1.3739069700241089
Validation loss: 2.209108352661133

Epoch: 5| Step: 5
Training loss: 0.8866122364997864
Validation loss: 2.206003025174141

Epoch: 5| Step: 6
Training loss: 1.192175269126892
Validation loss: 2.2053077121575675

Epoch: 5| Step: 7
Training loss: 0.6401538252830505
Validation loss: 2.2371270606915155

Epoch: 5| Step: 8
Training loss: 1.7079051733016968
Validation loss: 2.1921747823556266

Epoch: 5| Step: 9
Training loss: 1.257793664932251
Validation loss: 2.208285649617513

Epoch: 5| Step: 10
Training loss: 1.4832514524459839
Validation loss: 2.205633913477262

Epoch: 5| Step: 11
Training loss: 0.7108609080314636
Validation loss: 2.207300146420797

Epoch: 418| Step: 0
Training loss: 1.3410975933074951
Validation loss: 2.248120372494062

Epoch: 5| Step: 1
Training loss: 0.6721323728561401
Validation loss: 2.205273379882177

Epoch: 5| Step: 2
Training loss: 0.7178266644477844
Validation loss: 2.212461849053701

Epoch: 5| Step: 3
Training loss: 1.435235857963562
Validation loss: 2.1927720655997596

Epoch: 5| Step: 4
Training loss: 1.4999088048934937
Validation loss: 2.215049594640732

Epoch: 5| Step: 5
Training loss: 1.4580934047698975
Validation loss: 2.2683663368225098

Epoch: 5| Step: 6
Training loss: 1.469395399093628
Validation loss: 2.21395576496919

Epoch: 5| Step: 7
Training loss: 1.6481822729110718
Validation loss: 2.2022207528352737

Epoch: 5| Step: 8
Training loss: 1.4157030582427979
Validation loss: 2.2129282106955848

Epoch: 5| Step: 9
Training loss: 0.6003342866897583
Validation loss: 2.2079036037127175

Epoch: 5| Step: 10
Training loss: 0.9555901288986206
Validation loss: 2.174814671278

Epoch: 5| Step: 11
Training loss: 0.8824886083602905
Validation loss: 2.1793177723884583

Epoch: 419| Step: 0
Training loss: 1.3195481300354004
Validation loss: 2.192002460360527

Epoch: 5| Step: 1
Training loss: 1.2180697917938232
Validation loss: 2.2080761392911277

Epoch: 5| Step: 2
Training loss: 1.1044542789459229
Validation loss: 2.220823884010315

Epoch: 5| Step: 3
Training loss: 1.0518295764923096
Validation loss: 2.2256550391515098

Epoch: 5| Step: 4
Training loss: 0.9846404790878296
Validation loss: 2.2037079334259033

Epoch: 5| Step: 5
Training loss: 0.9849902987480164
Validation loss: 2.223421171307564

Epoch: 5| Step: 6
Training loss: 1.0500277280807495
Validation loss: 2.188747609655062

Epoch: 5| Step: 7
Training loss: 0.9561500549316406
Validation loss: 2.1817113210757575

Epoch: 5| Step: 8
Training loss: 1.4087812900543213
Validation loss: 2.2136187007029853

Epoch: 5| Step: 9
Training loss: 1.425933599472046
Validation loss: 2.1963413010040918

Epoch: 5| Step: 10
Training loss: 1.1186493635177612
Validation loss: 2.2006700138250985

Epoch: 5| Step: 11
Training loss: 1.9884486198425293
Validation loss: 2.2326003313064575

Epoch: 420| Step: 0
Training loss: 1.0221539735794067
Validation loss: 2.228869875272115

Epoch: 5| Step: 1
Training loss: 0.9534837007522583
Validation loss: 2.256499409675598

Epoch: 5| Step: 2
Training loss: 1.5621552467346191
Validation loss: 2.2066141019264855

Epoch: 5| Step: 3
Training loss: 0.7081387042999268
Validation loss: 2.2430156668027244

Epoch: 5| Step: 4
Training loss: 1.5623780488967896
Validation loss: 2.2307524383068085

Epoch: 5| Step: 5
Training loss: 0.7856433987617493
Validation loss: 2.185093273719152

Epoch: 5| Step: 6
Training loss: 1.1684411764144897
Validation loss: 2.251362313826879

Epoch: 5| Step: 7
Training loss: 1.5276000499725342
Validation loss: 2.19485180079937

Epoch: 5| Step: 8
Training loss: 1.192589521408081
Validation loss: 2.174205332994461

Epoch: 5| Step: 9
Training loss: 0.7503013014793396
Validation loss: 2.2218815883000693

Epoch: 5| Step: 10
Training loss: 1.2943439483642578
Validation loss: 2.181506191690763

Epoch: 5| Step: 11
Training loss: 2.0618767738342285
Validation loss: 2.2179128179947534

Epoch: 421| Step: 0
Training loss: 0.589065432548523
Validation loss: 2.268671860297521

Epoch: 5| Step: 1
Training loss: 1.4859662055969238
Validation loss: 2.25746883948644

Epoch: 5| Step: 2
Training loss: 2.1617937088012695
Validation loss: 2.2427829752365747

Epoch: 5| Step: 3
Training loss: 1.4056209325790405
Validation loss: 2.2476550738016763

Epoch: 5| Step: 4
Training loss: 0.8347910046577454
Validation loss: 2.182500049471855

Epoch: 5| Step: 5
Training loss: 1.0720123052597046
Validation loss: 2.2540858387947083

Epoch: 5| Step: 6
Training loss: 0.7385426759719849
Validation loss: 2.2309855620066323

Epoch: 5| Step: 7
Training loss: 0.5652350187301636
Validation loss: 2.211286028226217

Epoch: 5| Step: 8
Training loss: 1.2496616840362549
Validation loss: 2.2237986028194427

Epoch: 5| Step: 9
Training loss: 1.1379430294036865
Validation loss: 2.203622728586197

Epoch: 5| Step: 10
Training loss: 1.1536099910736084
Validation loss: 2.2096827824910483

Epoch: 5| Step: 11
Training loss: 0.7940987348556519
Validation loss: 2.1837443709373474

Epoch: 422| Step: 0
Training loss: 0.7617533802986145
Validation loss: 2.204241822163264

Epoch: 5| Step: 1
Training loss: 1.0097389221191406
Validation loss: 2.247390960653623

Epoch: 5| Step: 2
Training loss: 0.9658750295639038
Validation loss: 2.2370485663414

Epoch: 5| Step: 3
Training loss: 0.8590927124023438
Validation loss: 2.1953246792157493

Epoch: 5| Step: 4
Training loss: 0.6690555214881897
Validation loss: 2.1796264201402664

Epoch: 5| Step: 5
Training loss: 1.1841156482696533
Validation loss: 2.200563167532285

Epoch: 5| Step: 6
Training loss: 1.2438545227050781
Validation loss: 2.238049015402794

Epoch: 5| Step: 7
Training loss: 1.1796995401382446
Validation loss: 2.2072948018709817

Epoch: 5| Step: 8
Training loss: 2.4039833545684814
Validation loss: 2.2414635519186654

Epoch: 5| Step: 9
Training loss: 0.9556806683540344
Validation loss: 2.2098237375418344

Epoch: 5| Step: 10
Training loss: 1.058525800704956
Validation loss: 2.216821620861689

Epoch: 5| Step: 11
Training loss: 1.1931726932525635
Validation loss: 2.236593320965767

Epoch: 423| Step: 0
Training loss: 0.9850437045097351
Validation loss: 2.212978626290957

Epoch: 5| Step: 1
Training loss: 1.306020975112915
Validation loss: 2.195158993204435

Epoch: 5| Step: 2
Training loss: 1.2289073467254639
Validation loss: 2.2112577656904855

Epoch: 5| Step: 3
Training loss: 0.8639111518859863
Validation loss: 2.2127101520697274

Epoch: 5| Step: 4
Training loss: 1.2728328704833984
Validation loss: 2.222700218359629

Epoch: 5| Step: 5
Training loss: 1.2487938404083252
Validation loss: 2.213520497083664

Epoch: 5| Step: 6
Training loss: 1.2933034896850586
Validation loss: 2.2092925111452737

Epoch: 5| Step: 7
Training loss: 1.2358083724975586
Validation loss: 2.186062087615331

Epoch: 5| Step: 8
Training loss: 1.1927735805511475
Validation loss: 2.2224013855059943

Epoch: 5| Step: 9
Training loss: 0.7659907341003418
Validation loss: 2.246589551369349

Epoch: 5| Step: 10
Training loss: 1.426405429840088
Validation loss: 2.2094596227010093

Epoch: 5| Step: 11
Training loss: 0.5123992562294006
Validation loss: 2.1887444853782654

Epoch: 424| Step: 0
Training loss: 1.29905366897583
Validation loss: 2.1842604279518127

Epoch: 5| Step: 1
Training loss: 0.8967006802558899
Validation loss: 2.2135847558577857

Epoch: 5| Step: 2
Training loss: 0.5631388425827026
Validation loss: 2.240113615989685

Epoch: 5| Step: 3
Training loss: 2.1695504188537598
Validation loss: 2.211074392000834

Epoch: 5| Step: 4
Training loss: 1.0721745491027832
Validation loss: 2.184535652399063

Epoch: 5| Step: 5
Training loss: 1.3065919876098633
Validation loss: 2.2154135207335153

Epoch: 5| Step: 6
Training loss: 0.9078966975212097
Validation loss: 2.252084900935491

Epoch: 5| Step: 7
Training loss: 1.2157410383224487
Validation loss: 2.242931385835012

Epoch: 5| Step: 8
Training loss: 1.0131340026855469
Validation loss: 2.2209920982519784

Epoch: 5| Step: 9
Training loss: 0.9725719690322876
Validation loss: 2.221907824277878

Epoch: 5| Step: 10
Training loss: 1.030359148979187
Validation loss: 2.1930085321267447

Epoch: 5| Step: 11
Training loss: 0.7329747080802917
Validation loss: 2.1886600901683173

Epoch: 425| Step: 0
Training loss: 1.2060658931732178
Validation loss: 2.195299123724302

Epoch: 5| Step: 1
Training loss: 1.0033835172653198
Validation loss: 2.1650626361370087

Epoch: 5| Step: 2
Training loss: 0.7739831805229187
Validation loss: 2.193317080537478

Epoch: 5| Step: 3
Training loss: 1.3896751403808594
Validation loss: 2.167960156997045

Epoch: 5| Step: 4
Training loss: 0.9969886541366577
Validation loss: 2.1531337102254233

Epoch: 5| Step: 5
Training loss: 0.8660128712654114
Validation loss: 2.1532211303710938

Epoch: 5| Step: 6
Training loss: 1.7051719427108765
Validation loss: 2.147265781958898

Epoch: 5| Step: 7
Training loss: 0.9400955438613892
Validation loss: 2.1894806722799935

Epoch: 5| Step: 8
Training loss: 1.1413538455963135
Validation loss: 2.180860390265783

Epoch: 5| Step: 9
Training loss: 0.8383652567863464
Validation loss: 2.2129463454087577

Epoch: 5| Step: 10
Training loss: 1.4841668605804443
Validation loss: 2.185596456130346

Epoch: 5| Step: 11
Training loss: 2.1993889808654785
Validation loss: 2.2248023450374603

Epoch: 426| Step: 0
Training loss: 1.3337208032608032
Validation loss: 2.21179860830307

Epoch: 5| Step: 1
Training loss: 1.1671499013900757
Validation loss: 2.1780219972133636

Epoch: 5| Step: 2
Training loss: 0.5590160489082336
Validation loss: 2.187729597091675

Epoch: 5| Step: 3
Training loss: 0.9890016317367554
Validation loss: 2.1660604824622474

Epoch: 5| Step: 4
Training loss: 1.1757197380065918
Validation loss: 2.1712616980075836

Epoch: 5| Step: 5
Training loss: 0.4572471082210541
Validation loss: 2.2050780753294625

Epoch: 5| Step: 6
Training loss: 1.511394739151001
Validation loss: 2.158232589562734

Epoch: 5| Step: 7
Training loss: 1.3551304340362549
Validation loss: 2.1533940186103186

Epoch: 5| Step: 8
Training loss: 0.7865053415298462
Validation loss: 2.165851573149363

Epoch: 5| Step: 9
Training loss: 1.5105632543563843
Validation loss: 2.1455495754877725

Epoch: 5| Step: 10
Training loss: 1.062088966369629
Validation loss: 2.1731367707252502

Epoch: 5| Step: 11
Training loss: 1.2413955926895142
Validation loss: 2.204402173558871

Epoch: 427| Step: 0
Training loss: 1.8011016845703125
Validation loss: 2.17674387494723

Epoch: 5| Step: 1
Training loss: 1.286138892173767
Validation loss: 2.2014936407407126

Epoch: 5| Step: 2
Training loss: 1.1282727718353271
Validation loss: 2.192161872982979

Epoch: 5| Step: 3
Training loss: 1.0238878726959229
Validation loss: 2.1986897587776184

Epoch: 5| Step: 4
Training loss: 0.852350115776062
Validation loss: 2.1736512730518975

Epoch: 5| Step: 5
Training loss: 0.7473801374435425
Validation loss: 2.1858688394228616

Epoch: 5| Step: 6
Training loss: 1.4320987462997437
Validation loss: 2.1700378159681954

Epoch: 5| Step: 7
Training loss: 1.419645071029663
Validation loss: 2.200952505071958

Epoch: 5| Step: 8
Training loss: 1.3985522985458374
Validation loss: 2.2070654531319938

Epoch: 5| Step: 9
Training loss: 1.1525689363479614
Validation loss: 2.2249791771173477

Epoch: 5| Step: 10
Training loss: 0.8594107627868652
Validation loss: 2.203569749991099

Epoch: 5| Step: 11
Training loss: 0.7581585645675659
Validation loss: 2.1720178574323654

Epoch: 428| Step: 0
Training loss: 1.2136679887771606
Validation loss: 2.1970423559347787

Epoch: 5| Step: 1
Training loss: 0.9945430755615234
Validation loss: 2.192464937766393

Epoch: 5| Step: 2
Training loss: 1.3684115409851074
Validation loss: 2.19987516105175

Epoch: 5| Step: 3
Training loss: 1.3012754917144775
Validation loss: 2.2137874215841293

Epoch: 5| Step: 4
Training loss: 1.6441948413848877
Validation loss: 2.1815174718697867

Epoch: 5| Step: 5
Training loss: 1.3518879413604736
Validation loss: 2.1764436215162277

Epoch: 5| Step: 6
Training loss: 1.1977119445800781
Validation loss: 2.1644662419954934

Epoch: 5| Step: 7
Training loss: 0.7656167149543762
Validation loss: 2.2130907475948334

Epoch: 5| Step: 8
Training loss: 0.8874751329421997
Validation loss: 2.197280248006185

Epoch: 5| Step: 9
Training loss: 1.0585078001022339
Validation loss: 2.2119816641012826

Epoch: 5| Step: 10
Training loss: 0.7118414044380188
Validation loss: 2.1772743264834085

Epoch: 5| Step: 11
Training loss: 0.8536293506622314
Validation loss: 2.2428395648797355

Epoch: 429| Step: 0
Training loss: 0.9018037915229797
Validation loss: 2.1888949324687323

Epoch: 5| Step: 1
Training loss: 1.695590615272522
Validation loss: 2.2036338249842324

Epoch: 5| Step: 2
Training loss: 1.3242011070251465
Validation loss: 2.167285164197286

Epoch: 5| Step: 3
Training loss: 1.14182710647583
Validation loss: 2.182613417506218

Epoch: 5| Step: 4
Training loss: 1.0637469291687012
Validation loss: 2.1501189172267914

Epoch: 5| Step: 5
Training loss: 1.0680577754974365
Validation loss: 2.1834651629130044

Epoch: 5| Step: 6
Training loss: 1.401021957397461
Validation loss: 2.1531314154465995

Epoch: 5| Step: 7
Training loss: 1.090540885925293
Validation loss: 2.165554255247116

Epoch: 5| Step: 8
Training loss: 0.7974454760551453
Validation loss: 2.2091000328461328

Epoch: 5| Step: 9
Training loss: 0.771244466304779
Validation loss: 2.1892912288506827

Epoch: 5| Step: 10
Training loss: 1.1807194948196411
Validation loss: 2.1807916462421417

Epoch: 5| Step: 11
Training loss: 0.5048466324806213
Validation loss: 2.199654678503672

Epoch: 430| Step: 0
Training loss: 1.457955002784729
Validation loss: 2.237293004989624

Epoch: 5| Step: 1
Training loss: 1.0168046951293945
Validation loss: 2.234115704894066

Epoch: 5| Step: 2
Training loss: 0.7810032367706299
Validation loss: 2.180582116047541

Epoch: 5| Step: 3
Training loss: 0.7739537358283997
Validation loss: 2.239653006196022

Epoch: 5| Step: 4
Training loss: 1.1584692001342773
Validation loss: 2.213967129588127

Epoch: 5| Step: 5
Training loss: 1.1933014392852783
Validation loss: 2.1885899156332016

Epoch: 5| Step: 6
Training loss: 1.2206250429153442
Validation loss: 2.1951968471209207

Epoch: 5| Step: 7
Training loss: 1.3316353559494019
Validation loss: 2.1767521699269614

Epoch: 5| Step: 8
Training loss: 0.8603113293647766
Validation loss: 2.2068184316158295

Epoch: 5| Step: 9
Training loss: 1.1900140047073364
Validation loss: 2.1772727916638055

Epoch: 5| Step: 10
Training loss: 1.060468077659607
Validation loss: 2.1916756878296533

Epoch: 5| Step: 11
Training loss: 1.924434781074524
Validation loss: 2.194661279519399

Epoch: 431| Step: 0
Training loss: 0.4841609597206116
Validation loss: 2.2243827283382416

Epoch: 5| Step: 1
Training loss: 0.7717755436897278
Validation loss: 2.248397712906202

Epoch: 5| Step: 2
Training loss: 1.1632283926010132
Validation loss: 2.183810124794642

Epoch: 5| Step: 3
Training loss: 1.5383102893829346
Validation loss: 2.1815049946308136

Epoch: 5| Step: 4
Training loss: 0.7363417744636536
Validation loss: 2.1754713157812753

Epoch: 5| Step: 5
Training loss: 1.6139713525772095
Validation loss: 2.236565957466761

Epoch: 5| Step: 6
Training loss: 0.6368692517280579
Validation loss: 2.1886054327090583

Epoch: 5| Step: 7
Training loss: 1.0964508056640625
Validation loss: 2.236512541770935

Epoch: 5| Step: 8
Training loss: 1.4911941289901733
Validation loss: 2.1855744222799935

Epoch: 5| Step: 9
Training loss: 1.0280207395553589
Validation loss: 2.210705911119779

Epoch: 5| Step: 10
Training loss: 0.9327666163444519
Validation loss: 2.2353082299232483

Epoch: 5| Step: 11
Training loss: 2.439457893371582
Validation loss: 2.183831219871839

Epoch: 432| Step: 0
Training loss: 0.5741356015205383
Validation loss: 2.2236468295256295

Epoch: 5| Step: 1
Training loss: 1.6333402395248413
Validation loss: 2.1803804834683738

Epoch: 5| Step: 2
Training loss: 1.2157280445098877
Validation loss: 2.1910244524478912

Epoch: 5| Step: 3
Training loss: 1.3632162809371948
Validation loss: 2.1933686584234238

Epoch: 5| Step: 4
Training loss: 1.2509130239486694
Validation loss: 2.171531250079473

Epoch: 5| Step: 5
Training loss: 0.9529849886894226
Validation loss: 2.190909077723821

Epoch: 5| Step: 6
Training loss: 0.9348945617675781
Validation loss: 2.1607930014530816

Epoch: 5| Step: 7
Training loss: 0.9260099530220032
Validation loss: 2.1538937389850616

Epoch: 5| Step: 8
Training loss: 0.859714150428772
Validation loss: 2.1338281631469727

Epoch: 5| Step: 9
Training loss: 1.1042283773422241
Validation loss: 2.161344756682714

Epoch: 5| Step: 10
Training loss: 1.1261732578277588
Validation loss: 2.217944949865341

Epoch: 5| Step: 11
Training loss: 1.2159173488616943
Validation loss: 2.2090906898180642

Epoch: 433| Step: 0
Training loss: 1.1738522052764893
Validation loss: 2.166236996650696

Epoch: 5| Step: 1
Training loss: 0.682283878326416
Validation loss: 2.2433239916960397

Epoch: 5| Step: 2
Training loss: 1.3868123292922974
Validation loss: 2.1937540223201117

Epoch: 5| Step: 3
Training loss: 1.3213554620742798
Validation loss: 2.208752373854319

Epoch: 5| Step: 4
Training loss: 1.2976315021514893
Validation loss: 2.2081883351008096

Epoch: 5| Step: 5
Training loss: 1.5074583292007446
Validation loss: 2.1996229539314904

Epoch: 5| Step: 6
Training loss: 0.8702760934829712
Validation loss: 2.233475769559542

Epoch: 5| Step: 7
Training loss: 1.1628843545913696
Validation loss: 2.2319071888923645

Epoch: 5| Step: 8
Training loss: 0.6015574336051941
Validation loss: 2.1847276836633682

Epoch: 5| Step: 9
Training loss: 0.6745193004608154
Validation loss: 2.1892847269773483

Epoch: 5| Step: 10
Training loss: 1.152428388595581
Validation loss: 2.239805062611898

Epoch: 5| Step: 11
Training loss: 1.5296380519866943
Validation loss: 2.200982302427292

Epoch: 434| Step: 0
Training loss: 1.1437453031539917
Validation loss: 2.174370909730593

Epoch: 5| Step: 1
Training loss: 1.3204511404037476
Validation loss: 2.2028240064779916

Epoch: 5| Step: 2
Training loss: 1.5246845483779907
Validation loss: 2.2251150210698447

Epoch: 5| Step: 3
Training loss: 0.8970168232917786
Validation loss: 2.2008055299520493

Epoch: 5| Step: 4
Training loss: 1.3250653743743896
Validation loss: 2.184090256690979

Epoch: 5| Step: 5
Training loss: 0.8985784649848938
Validation loss: 2.199579839905103

Epoch: 5| Step: 6
Training loss: 1.0231059789657593
Validation loss: 2.19867250820001

Epoch: 5| Step: 7
Training loss: 1.0932918787002563
Validation loss: 2.221202780803045

Epoch: 5| Step: 8
Training loss: 0.6113379001617432
Validation loss: 2.220081945260366

Epoch: 5| Step: 9
Training loss: 0.8856900930404663
Validation loss: 2.2125386397043862

Epoch: 5| Step: 10
Training loss: 0.9241026639938354
Validation loss: 2.210374434789022

Epoch: 5| Step: 11
Training loss: 1.6127616167068481
Validation loss: 2.2025174448887506

Epoch: 435| Step: 0
Training loss: 1.0694868564605713
Validation loss: 2.174584577480952

Epoch: 5| Step: 1
Training loss: 0.49200350046157837
Validation loss: 2.1635307520627975

Epoch: 5| Step: 2
Training loss: 1.2970880270004272
Validation loss: 2.1819665928681693

Epoch: 5| Step: 3
Training loss: 1.2866064310073853
Validation loss: 2.1867277522881827

Epoch: 5| Step: 4
Training loss: 1.2991093397140503
Validation loss: 2.1478035052617392

Epoch: 5| Step: 5
Training loss: 0.9443355798721313
Validation loss: 2.1639275004466376

Epoch: 5| Step: 6
Training loss: 0.8031817674636841
Validation loss: 2.139609898130099

Epoch: 5| Step: 7
Training loss: 0.709747314453125
Validation loss: 2.1758959045012793

Epoch: 5| Step: 8
Training loss: 1.5110929012298584
Validation loss: 2.154948885242144

Epoch: 5| Step: 9
Training loss: 0.9607120752334595
Validation loss: 2.17960054675738

Epoch: 5| Step: 10
Training loss: 1.053208827972412
Validation loss: 2.1986812154452005

Epoch: 5| Step: 11
Training loss: 1.1661008596420288
Validation loss: 2.215330272912979

Epoch: 436| Step: 0
Training loss: 1.4709646701812744
Validation loss: 2.175398126244545

Epoch: 5| Step: 1
Training loss: 1.2336915731430054
Validation loss: 2.211256260673205

Epoch: 5| Step: 2
Training loss: 0.6875906586647034
Validation loss: 2.217498262723287

Epoch: 5| Step: 3
Training loss: 1.0052802562713623
Validation loss: 2.1939470569292703

Epoch: 5| Step: 4
Training loss: 0.9281005859375
Validation loss: 2.2226439863443375

Epoch: 5| Step: 5
Training loss: 0.9604355692863464
Validation loss: 2.1900333762168884

Epoch: 5| Step: 6
Training loss: 1.2350128889083862
Validation loss: 2.207920476794243

Epoch: 5| Step: 7
Training loss: 1.1022353172302246
Validation loss: 2.161863406499227

Epoch: 5| Step: 8
Training loss: 0.9705950617790222
Validation loss: 2.177537366747856

Epoch: 5| Step: 9
Training loss: 1.0247993469238281
Validation loss: 2.164107382297516

Epoch: 5| Step: 10
Training loss: 1.5135042667388916
Validation loss: 2.1964858869711557

Epoch: 5| Step: 11
Training loss: 0.3116454482078552
Validation loss: 2.1606550167004266

Epoch: 437| Step: 0
Training loss: 1.1248199939727783
Validation loss: 2.1999008109172187

Epoch: 5| Step: 1
Training loss: 1.2167859077453613
Validation loss: 2.2233108977476754

Epoch: 5| Step: 2
Training loss: 0.8691450953483582
Validation loss: 2.1880083978176117

Epoch: 5| Step: 3
Training loss: 1.7281177043914795
Validation loss: 2.2032325118780136

Epoch: 5| Step: 4
Training loss: 0.9363449811935425
Validation loss: 2.2021630903085074

Epoch: 5| Step: 5
Training loss: 1.1412941217422485
Validation loss: 2.2131971567869186

Epoch: 5| Step: 6
Training loss: 1.345341682434082
Validation loss: 2.228054463863373

Epoch: 5| Step: 7
Training loss: 1.0119050741195679
Validation loss: 2.2111126681168876

Epoch: 5| Step: 8
Training loss: 0.8101969957351685
Validation loss: 2.181601251165072

Epoch: 5| Step: 9
Training loss: 0.9553079605102539
Validation loss: 2.163383980592092

Epoch: 5| Step: 10
Training loss: 1.548671841621399
Validation loss: 2.152102808157603

Epoch: 5| Step: 11
Training loss: 0.7530800104141235
Validation loss: 2.148212338487307

Epoch: 438| Step: 0
Training loss: 1.5122212171554565
Validation loss: 2.131901661554972

Epoch: 5| Step: 1
Training loss: 1.1450501680374146
Validation loss: 2.153873160481453

Epoch: 5| Step: 2
Training loss: 1.641964316368103
Validation loss: 2.203700363636017

Epoch: 5| Step: 3
Training loss: 1.2844409942626953
Validation loss: 2.1811768213907876

Epoch: 5| Step: 4
Training loss: 1.4119555950164795
Validation loss: 2.2175801595052085

Epoch: 5| Step: 5
Training loss: 0.7712821960449219
Validation loss: 2.251788521806399

Epoch: 5| Step: 6
Training loss: 1.120850682258606
Validation loss: 2.2004178166389465

Epoch: 5| Step: 7
Training loss: 0.675316333770752
Validation loss: 2.2102464785178504

Epoch: 5| Step: 8
Training loss: 0.927486777305603
Validation loss: 2.2097283204396567

Epoch: 5| Step: 9
Training loss: 0.8627193570137024
Validation loss: 2.2183331002791724

Epoch: 5| Step: 10
Training loss: 0.7369022369384766
Validation loss: 2.1934368213017783

Epoch: 5| Step: 11
Training loss: 1.1098649501800537
Validation loss: 2.222536643346151

Epoch: 439| Step: 0
Training loss: 1.1663800477981567
Validation loss: 2.2459776947895684

Epoch: 5| Step: 1
Training loss: 1.0791562795639038
Validation loss: 2.2086314757665

Epoch: 5| Step: 2
Training loss: 1.1566176414489746
Validation loss: 2.197105755408605

Epoch: 5| Step: 3
Training loss: 1.2281733751296997
Validation loss: 2.1723422904809317

Epoch: 5| Step: 4
Training loss: 0.9223079681396484
Validation loss: 2.1569053679704666

Epoch: 5| Step: 5
Training loss: 0.6970669031143188
Validation loss: 2.1405794272820153

Epoch: 5| Step: 6
Training loss: 1.5691494941711426
Validation loss: 2.148495694001516

Epoch: 5| Step: 7
Training loss: 1.2304019927978516
Validation loss: 2.13067989051342

Epoch: 5| Step: 8
Training loss: 1.1017833948135376
Validation loss: 2.1669870913028717

Epoch: 5| Step: 9
Training loss: 0.9569419622421265
Validation loss: 2.1820921500523887

Epoch: 5| Step: 10
Training loss: 1.0515004396438599
Validation loss: 2.162098526954651

Epoch: 5| Step: 11
Training loss: 0.7106820344924927
Validation loss: 2.1866487115621567

Epoch: 440| Step: 0
Training loss: 1.4237035512924194
Validation loss: 2.151912267009417

Epoch: 5| Step: 1
Training loss: 0.9457270503044128
Validation loss: 2.1504311909278235

Epoch: 5| Step: 2
Training loss: 0.8976327180862427
Validation loss: 2.2180813401937485

Epoch: 5| Step: 3
Training loss: 1.0293829441070557
Validation loss: 2.178942675391833

Epoch: 5| Step: 4
Training loss: 0.7227600812911987
Validation loss: 2.2214686473210654

Epoch: 5| Step: 5
Training loss: 0.8473227620124817
Validation loss: 2.1677220364411673

Epoch: 5| Step: 6
Training loss: 1.3320006132125854
Validation loss: 2.170230726401011

Epoch: 5| Step: 7
Training loss: 0.8516449928283691
Validation loss: 2.18934757510821

Epoch: 5| Step: 8
Training loss: 1.2884232997894287
Validation loss: 2.210071345170339

Epoch: 5| Step: 9
Training loss: 1.2218117713928223
Validation loss: 2.19869656364123

Epoch: 5| Step: 10
Training loss: 0.8041653633117676
Validation loss: 2.1862744291623435

Epoch: 5| Step: 11
Training loss: 0.7138053178787231
Validation loss: 2.2016894469658532

Epoch: 441| Step: 0
Training loss: 1.5058257579803467
Validation loss: 2.2140489518642426

Epoch: 5| Step: 1
Training loss: 1.7626731395721436
Validation loss: 2.215460633238157

Epoch: 5| Step: 2
Training loss: 0.6570359468460083
Validation loss: 2.17715784907341

Epoch: 5| Step: 3
Training loss: 0.716064453125
Validation loss: 2.1712923794984818

Epoch: 5| Step: 4
Training loss: 0.9568697214126587
Validation loss: 2.165928135315577

Epoch: 5| Step: 5
Training loss: 0.791777491569519
Validation loss: 2.2042112201452255

Epoch: 5| Step: 6
Training loss: 0.7244109511375427
Validation loss: 2.1780433555444083

Epoch: 5| Step: 7
Training loss: 0.8370726704597473
Validation loss: 2.1907979051272073

Epoch: 5| Step: 8
Training loss: 1.3555986881256104
Validation loss: 2.1659064491589866

Epoch: 5| Step: 9
Training loss: 0.9493514895439148
Validation loss: 2.177806317806244

Epoch: 5| Step: 10
Training loss: 1.1083109378814697
Validation loss: 2.1768352637688317

Epoch: 5| Step: 11
Training loss: 0.35067957639694214
Validation loss: 2.166399593154589

Epoch: 442| Step: 0
Training loss: 1.5926153659820557
Validation loss: 2.202703202764193

Epoch: 5| Step: 1
Training loss: 0.9075077176094055
Validation loss: 2.160508339603742

Epoch: 5| Step: 2
Training loss: 0.7481358647346497
Validation loss: 2.1850528717041016

Epoch: 5| Step: 3
Training loss: 1.3884251117706299
Validation loss: 2.2155158867438636

Epoch: 5| Step: 4
Training loss: 1.3835910558700562
Validation loss: 2.169460659225782

Epoch: 5| Step: 5
Training loss: 1.203337550163269
Validation loss: 2.1992689420779548

Epoch: 5| Step: 6
Training loss: 1.1206310987472534
Validation loss: 2.217158541083336

Epoch: 5| Step: 7
Training loss: 1.1705116033554077
Validation loss: 2.1875606377919516

Epoch: 5| Step: 8
Training loss: 0.8580588102340698
Validation loss: 2.184664338827133

Epoch: 5| Step: 9
Training loss: 0.836574375629425
Validation loss: 2.178519368171692

Epoch: 5| Step: 10
Training loss: 0.7690327167510986
Validation loss: 2.2259732683499656

Epoch: 5| Step: 11
Training loss: 0.13762617111206055
Validation loss: 2.1440310974915824

Epoch: 443| Step: 0
Training loss: 1.411907434463501
Validation loss: 2.186963756879171

Epoch: 5| Step: 1
Training loss: 0.9053398966789246
Validation loss: 2.196269780397415

Epoch: 5| Step: 2
Training loss: 1.2354605197906494
Validation loss: 2.1948751707871756

Epoch: 5| Step: 3
Training loss: 0.6500107049942017
Validation loss: 2.1654321054617562

Epoch: 5| Step: 4
Training loss: 1.2065236568450928
Validation loss: 2.2328211615482965

Epoch: 5| Step: 5
Training loss: 1.3133176565170288
Validation loss: 2.2176968157291412

Epoch: 5| Step: 6
Training loss: 0.6966968774795532
Validation loss: 2.183758636315664

Epoch: 5| Step: 7
Training loss: 1.237121820449829
Validation loss: 2.23367769519488

Epoch: 5| Step: 8
Training loss: 0.9100081324577332
Validation loss: 2.2239454885323844

Epoch: 5| Step: 9
Training loss: 1.0351897478103638
Validation loss: 2.2168398946523666

Epoch: 5| Step: 10
Training loss: 0.951156497001648
Validation loss: 2.262375752131144

Epoch: 5| Step: 11
Training loss: 0.7584129571914673
Validation loss: 2.2803226510683694

Epoch: 444| Step: 0
Training loss: 1.0928428173065186
Validation loss: 2.2474931478500366

Epoch: 5| Step: 1
Training loss: 1.1264228820800781
Validation loss: 2.268886516491572

Epoch: 5| Step: 2
Training loss: 1.2035735845565796
Validation loss: 2.222690458099047

Epoch: 5| Step: 3
Training loss: 1.2467122077941895
Validation loss: 2.2375061015288034

Epoch: 5| Step: 4
Training loss: 1.1022980213165283
Validation loss: 2.2549574623505273

Epoch: 5| Step: 5
Training loss: 0.8077972531318665
Validation loss: 2.225500931342443

Epoch: 5| Step: 6
Training loss: 0.7621872425079346
Validation loss: 2.222544809182485

Epoch: 5| Step: 7
Training loss: 1.0893027782440186
Validation loss: 2.2008050034443536

Epoch: 5| Step: 8
Training loss: 0.7696276307106018
Validation loss: 2.2277181247870126

Epoch: 5| Step: 9
Training loss: 0.894308865070343
Validation loss: 2.2103670487801232

Epoch: 5| Step: 10
Training loss: 1.1421350240707397
Validation loss: 2.2068422536055246

Epoch: 5| Step: 11
Training loss: 2.3641273975372314
Validation loss: 2.196535070737203

Epoch: 445| Step: 0
Training loss: 0.6926581263542175
Validation loss: 2.1897994677225747

Epoch: 5| Step: 1
Training loss: 1.1968992948532104
Validation loss: 2.21455088754495

Epoch: 5| Step: 2
Training loss: 1.0683168172836304
Validation loss: 2.19485737880071

Epoch: 5| Step: 3
Training loss: 1.1301686763763428
Validation loss: 2.1647703101237616

Epoch: 5| Step: 4
Training loss: 0.7236566543579102
Validation loss: 2.193535933891932

Epoch: 5| Step: 5
Training loss: 1.8022207021713257
Validation loss: 2.1904324293136597

Epoch: 5| Step: 6
Training loss: 1.131620168685913
Validation loss: 2.1222178041934967

Epoch: 5| Step: 7
Training loss: 1.081945538520813
Validation loss: 2.125684226552645

Epoch: 5| Step: 8
Training loss: 0.9891376495361328
Validation loss: 2.1440988034009933

Epoch: 5| Step: 9
Training loss: 0.8030321002006531
Validation loss: 2.1198309610287347

Epoch: 5| Step: 10
Training loss: 0.9786397814750671
Validation loss: 2.1110198944807053

Epoch: 5| Step: 11
Training loss: 2.0753798484802246
Validation loss: 2.1391391307115555

Epoch: 446| Step: 0
Training loss: 1.145566701889038
Validation loss: 2.150462364157041

Epoch: 5| Step: 1
Training loss: 1.140946626663208
Validation loss: 2.1151909132798514

Epoch: 5| Step: 2
Training loss: 0.6957792043685913
Validation loss: 2.1344897051652274

Epoch: 5| Step: 3
Training loss: 1.611106514930725
Validation loss: 2.1196926285823188

Epoch: 5| Step: 4
Training loss: 1.1103613376617432
Validation loss: 2.114189694325129

Epoch: 5| Step: 5
Training loss: 1.1935542821884155
Validation loss: 2.1153196593125663

Epoch: 5| Step: 6
Training loss: 0.5661776661872864
Validation loss: 2.0868176172176995

Epoch: 5| Step: 7
Training loss: 1.1347118616104126
Validation loss: 2.1125487883885703

Epoch: 5| Step: 8
Training loss: 0.547024667263031
Validation loss: 2.119156430164973

Epoch: 5| Step: 9
Training loss: 1.3057739734649658
Validation loss: 2.120292291045189

Epoch: 5| Step: 10
Training loss: 1.0042411088943481
Validation loss: 2.1865451633930206

Epoch: 5| Step: 11
Training loss: 1.2340110540390015
Validation loss: 2.100052615006765

Epoch: 447| Step: 0
Training loss: 0.895173192024231
Validation loss: 2.169761300086975

Epoch: 5| Step: 1
Training loss: 0.790263295173645
Validation loss: 2.2059475481510162

Epoch: 5| Step: 2
Training loss: 0.7399371862411499
Validation loss: 2.1730101505915322

Epoch: 5| Step: 3
Training loss: 1.5867395401000977
Validation loss: 2.154668534795443

Epoch: 5| Step: 4
Training loss: 0.8347444534301758
Validation loss: 2.1854289869467416

Epoch: 5| Step: 5
Training loss: 1.21071457862854
Validation loss: 2.1804371376832328

Epoch: 5| Step: 6
Training loss: 0.9671021699905396
Validation loss: 2.1480004092057547

Epoch: 5| Step: 7
Training loss: 0.8816477060317993
Validation loss: 2.1882571975390115

Epoch: 5| Step: 8
Training loss: 0.8306652903556824
Validation loss: 2.1435434073209763

Epoch: 5| Step: 9
Training loss: 1.6120401620864868
Validation loss: 2.1902252584695816

Epoch: 5| Step: 10
Training loss: 1.0535948276519775
Validation loss: 2.1989949444929757

Epoch: 5| Step: 11
Training loss: 1.0527217388153076
Validation loss: 2.16689425210158

Epoch: 448| Step: 0
Training loss: 0.9440746307373047
Validation loss: 2.179869761069616

Epoch: 5| Step: 1
Training loss: 0.94514000415802
Validation loss: 2.1912280966838202

Epoch: 5| Step: 2
Training loss: 0.9824811816215515
Validation loss: 2.1467252473036447

Epoch: 5| Step: 3
Training loss: 0.8185895681381226
Validation loss: 2.1789990166823068

Epoch: 5| Step: 4
Training loss: 1.0574499368667603
Validation loss: 2.1741340160369873

Epoch: 5| Step: 5
Training loss: 0.8696109652519226
Validation loss: 2.1911945740381875

Epoch: 5| Step: 6
Training loss: 1.4232935905456543
Validation loss: 2.146451771259308

Epoch: 5| Step: 7
Training loss: 1.2231531143188477
Validation loss: 2.1545767287413278

Epoch: 5| Step: 8
Training loss: 1.1487393379211426
Validation loss: 2.176416421929995

Epoch: 5| Step: 9
Training loss: 1.0002442598342896
Validation loss: 2.144514411687851

Epoch: 5| Step: 10
Training loss: 0.9824792146682739
Validation loss: 2.1633710116147995

Epoch: 5| Step: 11
Training loss: 0.5486520528793335
Validation loss: 2.176436801751455

Epoch: 449| Step: 0
Training loss: 0.6340084075927734
Validation loss: 2.140302682916323

Epoch: 5| Step: 1
Training loss: 0.8467701077461243
Validation loss: 2.1658421059449515

Epoch: 5| Step: 2
Training loss: 1.109918475151062
Validation loss: 2.1647390027840934

Epoch: 5| Step: 3
Training loss: 1.2171525955200195
Validation loss: 2.164951130747795

Epoch: 5| Step: 4
Training loss: 0.8011242151260376
Validation loss: 2.148915355404218

Epoch: 5| Step: 5
Training loss: 2.032702684402466
Validation loss: 2.1680720845858255

Epoch: 5| Step: 6
Training loss: 1.037358283996582
Validation loss: 2.151081070303917

Epoch: 5| Step: 7
Training loss: 0.5622652173042297
Validation loss: 2.1357787350813546

Epoch: 5| Step: 8
Training loss: 1.4951567649841309
Validation loss: 2.157340332865715

Epoch: 5| Step: 9
Training loss: 0.6658049821853638
Validation loss: 2.150263180335363

Epoch: 5| Step: 10
Training loss: 1.011063814163208
Validation loss: 2.13090972105662

Epoch: 5| Step: 11
Training loss: 0.31226152181625366
Validation loss: 2.179737389087677

Epoch: 450| Step: 0
Training loss: 0.5836163759231567
Validation loss: 2.1939420302708945

Epoch: 5| Step: 1
Training loss: 1.0600380897521973
Validation loss: 2.135987808307012

Epoch: 5| Step: 2
Training loss: 1.4194355010986328
Validation loss: 2.1746667623519897

Epoch: 5| Step: 3
Training loss: 1.151491403579712
Validation loss: 2.167204404870669

Epoch: 5| Step: 4
Training loss: 1.1727323532104492
Validation loss: 2.1812160114447274

Epoch: 5| Step: 5
Training loss: 1.100614309310913
Validation loss: 2.1698046972354255

Epoch: 5| Step: 6
Training loss: 1.4127438068389893
Validation loss: 2.194202537337939

Epoch: 5| Step: 7
Training loss: 0.9401769638061523
Validation loss: 2.1106605529785156

Epoch: 5| Step: 8
Training loss: 0.996303379535675
Validation loss: 2.2030674318472543

Epoch: 5| Step: 9
Training loss: 0.6653273701667786
Validation loss: 2.1986627727746964

Epoch: 5| Step: 10
Training loss: 0.9830320477485657
Validation loss: 2.1792713900407157

Epoch: 5| Step: 11
Training loss: 0.6481199860572815
Validation loss: 2.1695366899172464

Epoch: 451| Step: 0
Training loss: 0.9072445631027222
Validation loss: 2.1150302489598594

Epoch: 5| Step: 1
Training loss: 0.9110969305038452
Validation loss: 2.1613259613513947

Epoch: 5| Step: 2
Training loss: 1.370300531387329
Validation loss: 2.1722892622152963

Epoch: 5| Step: 3
Training loss: 0.557925820350647
Validation loss: 2.129423846801122

Epoch: 5| Step: 4
Training loss: 1.3665168285369873
Validation loss: 2.1613157242536545

Epoch: 5| Step: 5
Training loss: 1.2174136638641357
Validation loss: 2.125651960571607

Epoch: 5| Step: 6
Training loss: 1.164280652999878
Validation loss: 2.109076807896296

Epoch: 5| Step: 7
Training loss: 1.213768720626831
Validation loss: 2.1029270738363266

Epoch: 5| Step: 8
Training loss: 1.1335914134979248
Validation loss: 2.129482557376226

Epoch: 5| Step: 9
Training loss: 0.7581897377967834
Validation loss: 2.176510473092397

Epoch: 5| Step: 10
Training loss: 0.5954464673995972
Validation loss: 2.1903113226095834

Epoch: 5| Step: 11
Training loss: 0.451967716217041
Validation loss: 2.1768049796422324

Epoch: 452| Step: 0
Training loss: 0.8219736218452454
Validation loss: 2.1714053799708686

Epoch: 5| Step: 1
Training loss: 0.6549748182296753
Validation loss: 2.1451948086420694

Epoch: 5| Step: 2
Training loss: 0.8558432459831238
Validation loss: 2.133219172557195

Epoch: 5| Step: 3
Training loss: 1.3099135160446167
Validation loss: 2.1699751764535904

Epoch: 5| Step: 4
Training loss: 1.2039610147476196
Validation loss: 2.175286278128624

Epoch: 5| Step: 5
Training loss: 1.4548511505126953
Validation loss: 2.218596031268438

Epoch: 5| Step: 6
Training loss: 0.7268690466880798
Validation loss: 2.2017448941866555

Epoch: 5| Step: 7
Training loss: 0.7135598659515381
Validation loss: 2.1610896786053977

Epoch: 5| Step: 8
Training loss: 0.7537387609481812
Validation loss: 2.2138100465138755

Epoch: 5| Step: 9
Training loss: 0.9119293093681335
Validation loss: 2.1844431459903717

Epoch: 5| Step: 10
Training loss: 1.4468294382095337
Validation loss: 2.1820594370365143

Epoch: 5| Step: 11
Training loss: 0.896925151348114
Validation loss: 2.2129800071318946

Epoch: 453| Step: 0
Training loss: 0.7950023412704468
Validation loss: 2.1551635762055716

Epoch: 5| Step: 1
Training loss: 1.28232741355896
Validation loss: 2.171965459982554

Epoch: 5| Step: 2
Training loss: 0.9248159527778625
Validation loss: 2.1534328162670135

Epoch: 5| Step: 3
Training loss: 1.4125704765319824
Validation loss: 2.1646355390548706

Epoch: 5| Step: 4
Training loss: 1.0552496910095215
Validation loss: 2.1801006694634757

Epoch: 5| Step: 5
Training loss: 0.8053730130195618
Validation loss: 2.164132922887802

Epoch: 5| Step: 6
Training loss: 0.9810826182365417
Validation loss: 2.1984040240446725

Epoch: 5| Step: 7
Training loss: 0.973859965801239
Validation loss: 2.1666529228289924

Epoch: 5| Step: 8
Training loss: 0.6148937940597534
Validation loss: 2.1751229614019394

Epoch: 5| Step: 9
Training loss: 1.0827314853668213
Validation loss: 2.199532558520635

Epoch: 5| Step: 10
Training loss: 0.8434616327285767
Validation loss: 2.185579299926758

Epoch: 5| Step: 11
Training loss: 0.7171642780303955
Validation loss: 2.1660953909158707

Epoch: 454| Step: 0
Training loss: 1.6309782266616821
Validation loss: 2.1650620251893997

Epoch: 5| Step: 1
Training loss: 1.2011080980300903
Validation loss: 2.1922869185606637

Epoch: 5| Step: 2
Training loss: 0.5526461005210876
Validation loss: 2.164622570077578

Epoch: 5| Step: 3
Training loss: 0.6086118221282959
Validation loss: 2.1454959412415824

Epoch: 5| Step: 4
Training loss: 0.8642433881759644
Validation loss: 2.1627177596092224

Epoch: 5| Step: 5
Training loss: 1.2374495267868042
Validation loss: 2.1744352926810584

Epoch: 5| Step: 6
Training loss: 1.275482177734375
Validation loss: 2.1456792602936425

Epoch: 5| Step: 7
Training loss: 1.135284185409546
Validation loss: 2.1465013722578683

Epoch: 5| Step: 8
Training loss: 0.6775108575820923
Validation loss: 2.1445986131827035

Epoch: 5| Step: 9
Training loss: 0.6922982931137085
Validation loss: 2.1452566385269165

Epoch: 5| Step: 10
Training loss: 1.2518231868743896
Validation loss: 2.12107086678346

Epoch: 5| Step: 11
Training loss: 1.6163188219070435
Validation loss: 2.0955355366071067

Epoch: 455| Step: 0
Training loss: 1.4434208869934082
Validation loss: 2.1401824951171875

Epoch: 5| Step: 1
Training loss: 1.1238903999328613
Validation loss: 2.2153135389089584

Epoch: 5| Step: 2
Training loss: 1.1910682916641235
Validation loss: 2.1915467778841653

Epoch: 5| Step: 3
Training loss: 1.276320457458496
Validation loss: 2.2212209602197013

Epoch: 5| Step: 4
Training loss: 1.226135492324829
Validation loss: 2.199433838327726

Epoch: 5| Step: 5
Training loss: 0.6227013468742371
Validation loss: 2.20567853252093

Epoch: 5| Step: 6
Training loss: 1.027971863746643
Validation loss: 2.1245124687751136

Epoch: 5| Step: 7
Training loss: 0.6599539518356323
Validation loss: 2.1511303236087165

Epoch: 5| Step: 8
Training loss: 0.5141037702560425
Validation loss: 2.1472592651844025

Epoch: 5| Step: 9
Training loss: 1.0706067085266113
Validation loss: 2.118525038162867

Epoch: 5| Step: 10
Training loss: 1.0060265064239502
Validation loss: 2.147808253765106

Epoch: 5| Step: 11
Training loss: 1.163738489151001
Validation loss: 2.1534916857878366

Epoch: 456| Step: 0
Training loss: 0.8667024374008179
Validation loss: 2.1733874628941217

Epoch: 5| Step: 1
Training loss: 1.0383538007736206
Validation loss: 2.1457295517126718

Epoch: 5| Step: 2
Training loss: 1.1541310548782349
Validation loss: 2.169088472922643

Epoch: 5| Step: 3
Training loss: 1.2500064373016357
Validation loss: 2.15445842842261

Epoch: 5| Step: 4
Training loss: 0.6526576280593872
Validation loss: 2.1860408733288446

Epoch: 5| Step: 5
Training loss: 1.236863374710083
Validation loss: 2.146392529209455

Epoch: 5| Step: 6
Training loss: 0.9777253866195679
Validation loss: 2.207432975371679

Epoch: 5| Step: 7
Training loss: 1.2247141599655151
Validation loss: 2.1837348143259683

Epoch: 5| Step: 8
Training loss: 1.075088381767273
Validation loss: 2.2639781634012857

Epoch: 5| Step: 9
Training loss: 0.7388032078742981
Validation loss: 2.1903442392746606

Epoch: 5| Step: 10
Training loss: 0.8853429555892944
Validation loss: 2.1471134026845298

Epoch: 5| Step: 11
Training loss: 0.27252471446990967
Validation loss: 2.1834620187679925

Epoch: 457| Step: 0
Training loss: 0.7728837132453918
Validation loss: 2.1915769477685294

Epoch: 5| Step: 1
Training loss: 1.4624444246292114
Validation loss: 2.1694044967492423

Epoch: 5| Step: 2
Training loss: 0.9406176805496216
Validation loss: 2.151897748311361

Epoch: 5| Step: 3
Training loss: 1.086912751197815
Validation loss: 2.1732407907644906

Epoch: 5| Step: 4
Training loss: 0.8481060266494751
Validation loss: 2.2024607261021933

Epoch: 5| Step: 5
Training loss: 1.4258619546890259
Validation loss: 2.1204309463500977

Epoch: 5| Step: 6
Training loss: 0.782187283039093
Validation loss: 2.15370611846447

Epoch: 5| Step: 7
Training loss: 1.312522292137146
Validation loss: 2.191144128640493

Epoch: 5| Step: 8
Training loss: 1.1987775564193726
Validation loss: 2.1987709552049637

Epoch: 5| Step: 9
Training loss: 0.8149450421333313
Validation loss: 2.1888674845298133

Epoch: 5| Step: 10
Training loss: 0.7240946888923645
Validation loss: 2.1700446705023446

Epoch: 5| Step: 11
Training loss: 0.8028257489204407
Validation loss: 2.153683473666509

Epoch: 458| Step: 0
Training loss: 1.6173185110092163
Validation loss: 2.1537234584490457

Epoch: 5| Step: 1
Training loss: 0.828391432762146
Validation loss: 2.143200993537903

Epoch: 5| Step: 2
Training loss: 0.8326253890991211
Validation loss: 2.123992661635081

Epoch: 5| Step: 3
Training loss: 0.9908174276351929
Validation loss: 2.185933902859688

Epoch: 5| Step: 4
Training loss: 1.1743404865264893
Validation loss: 2.1666735212008157

Epoch: 5| Step: 5
Training loss: 0.9286853075027466
Validation loss: 2.140045687556267

Epoch: 5| Step: 6
Training loss: 1.2586379051208496
Validation loss: 2.112058545152346

Epoch: 5| Step: 7
Training loss: 0.8385491371154785
Validation loss: 2.1243586937586465

Epoch: 5| Step: 8
Training loss: 0.5340763330459595
Validation loss: 2.153836876153946

Epoch: 5| Step: 9
Training loss: 1.058619737625122
Validation loss: 2.1473081757624946

Epoch: 5| Step: 10
Training loss: 0.8159674406051636
Validation loss: 2.1582867403825126

Epoch: 5| Step: 11
Training loss: 2.316439628601074
Validation loss: 2.183587923645973

Epoch: 459| Step: 0
Training loss: 1.0907176733016968
Validation loss: 2.225727284948031

Epoch: 5| Step: 1
Training loss: 0.8658223152160645
Validation loss: 2.204805145661036

Epoch: 5| Step: 2
Training loss: 1.1107757091522217
Validation loss: 2.1890384604533515

Epoch: 5| Step: 3
Training loss: 1.327438473701477
Validation loss: 2.2053262442350388

Epoch: 5| Step: 4
Training loss: 0.8488026857376099
Validation loss: 2.2305938651164374

Epoch: 5| Step: 5
Training loss: 1.6666892766952515
Validation loss: 2.148730993270874

Epoch: 5| Step: 6
Training loss: 0.4970165193080902
Validation loss: 2.1485681235790253

Epoch: 5| Step: 7
Training loss: 0.8779963254928589
Validation loss: 2.1690269708633423

Epoch: 5| Step: 8
Training loss: 0.9675183296203613
Validation loss: 2.179785360892614

Epoch: 5| Step: 9
Training loss: 1.549115777015686
Validation loss: 2.2039470771948495

Epoch: 5| Step: 10
Training loss: 0.6030139327049255
Validation loss: 2.1745141396919885

Epoch: 5| Step: 11
Training loss: 1.18622624874115
Validation loss: 2.2027307947476706

Epoch: 460| Step: 0
Training loss: 1.420880675315857
Validation loss: 2.213606903950373

Epoch: 5| Step: 1
Training loss: 1.3559764623641968
Validation loss: 2.180565267801285

Epoch: 5| Step: 2
Training loss: 1.1569976806640625
Validation loss: 2.189836005369822

Epoch: 5| Step: 3
Training loss: 0.8749868273735046
Validation loss: 2.1740598579247794

Epoch: 5| Step: 4
Training loss: 0.793996274471283
Validation loss: 2.159225175778071

Epoch: 5| Step: 5
Training loss: 0.7867091298103333
Validation loss: 2.170883908867836

Epoch: 5| Step: 6
Training loss: 0.7307245135307312
Validation loss: 2.1336043775081635

Epoch: 5| Step: 7
Training loss: 1.2342792749404907
Validation loss: 2.172278513511022

Epoch: 5| Step: 8
Training loss: 0.8394495844841003
Validation loss: 2.1777574171622596

Epoch: 5| Step: 9
Training loss: 1.028712511062622
Validation loss: 2.1489853461583457

Epoch: 5| Step: 10
Training loss: 0.7584863901138306
Validation loss: 2.189037263393402

Epoch: 5| Step: 11
Training loss: 0.5562622547149658
Validation loss: 2.153632511695226

Epoch: 461| Step: 0
Training loss: 0.9459024667739868
Validation loss: 2.201607048511505

Epoch: 5| Step: 1
Training loss: 1.1038789749145508
Validation loss: 2.178727706273397

Epoch: 5| Step: 2
Training loss: 0.6651387214660645
Validation loss: 2.1641861498355865

Epoch: 5| Step: 3
Training loss: 0.8915765881538391
Validation loss: 2.1999445855617523

Epoch: 5| Step: 4
Training loss: 0.5566256642341614
Validation loss: 2.1648758302132287

Epoch: 5| Step: 5
Training loss: 0.871322512626648
Validation loss: 2.201256220539411

Epoch: 5| Step: 6
Training loss: 0.9996360540390015
Validation loss: 2.146246001124382

Epoch: 5| Step: 7
Training loss: 1.2136930227279663
Validation loss: 2.14900441467762

Epoch: 5| Step: 8
Training loss: 1.4063262939453125
Validation loss: 2.1514369000991187

Epoch: 5| Step: 9
Training loss: 0.9939438104629517
Validation loss: 2.1759491662184396

Epoch: 5| Step: 10
Training loss: 0.9479263424873352
Validation loss: 2.1011028538147607

Epoch: 5| Step: 11
Training loss: 0.3430659770965576
Validation loss: 2.1434300194183984

Epoch: 462| Step: 0
Training loss: 0.7925002574920654
Validation loss: 2.157559702793757

Epoch: 5| Step: 1
Training loss: 1.3125005960464478
Validation loss: 2.1183985620737076

Epoch: 5| Step: 2
Training loss: 1.038222312927246
Validation loss: 2.082536439100901

Epoch: 5| Step: 3
Training loss: 1.2174333333969116
Validation loss: 2.1505055030186973

Epoch: 5| Step: 4
Training loss: 0.6081222891807556
Validation loss: 2.1287660747766495

Epoch: 5| Step: 5
Training loss: 0.7650026679039001
Validation loss: 2.1620274732510247

Epoch: 5| Step: 6
Training loss: 0.9179018139839172
Validation loss: 2.185725505153338

Epoch: 5| Step: 7
Training loss: 1.3116978406906128
Validation loss: 2.211812525987625

Epoch: 5| Step: 8
Training loss: 1.2284592390060425
Validation loss: 2.184866319100062

Epoch: 5| Step: 9
Training loss: 1.119570255279541
Validation loss: 2.1895526895920434

Epoch: 5| Step: 10
Training loss: 1.0410301685333252
Validation loss: 2.208830157915751

Epoch: 5| Step: 11
Training loss: 1.3688923120498657
Validation loss: 2.1834951986869178

Epoch: 463| Step: 0
Training loss: 1.3885310888290405
Validation loss: 2.138721227645874

Epoch: 5| Step: 1
Training loss: 1.428359866142273
Validation loss: 2.1636685878038406

Epoch: 5| Step: 2
Training loss: 0.7523621916770935
Validation loss: 2.1311621169249215

Epoch: 5| Step: 3
Training loss: 0.7242367267608643
Validation loss: 2.1792805592219033

Epoch: 5| Step: 4
Training loss: 0.69024658203125
Validation loss: 2.147693788011869

Epoch: 5| Step: 5
Training loss: 0.8637199401855469
Validation loss: 2.1817405124505362

Epoch: 5| Step: 6
Training loss: 1.4155311584472656
Validation loss: 2.1950743099053702

Epoch: 5| Step: 7
Training loss: 1.0660834312438965
Validation loss: 2.1359394739071527

Epoch: 5| Step: 8
Training loss: 0.6104984283447266
Validation loss: 2.1237321893374124

Epoch: 5| Step: 9
Training loss: 0.5188324451446533
Validation loss: 2.144804229338964

Epoch: 5| Step: 10
Training loss: 0.9568955302238464
Validation loss: 2.1273847917715707

Epoch: 5| Step: 11
Training loss: 0.4409743547439575
Validation loss: 2.076403016845385

Epoch: 464| Step: 0
Training loss: 1.035785436630249
Validation loss: 2.1292541374762854

Epoch: 5| Step: 1
Training loss: 1.0905033349990845
Validation loss: 2.1292221546173096

Epoch: 5| Step: 2
Training loss: 1.061001181602478
Validation loss: 2.111870065331459

Epoch: 5| Step: 3
Training loss: 0.723069965839386
Validation loss: 2.1224874009688697

Epoch: 5| Step: 4
Training loss: 0.9770013093948364
Validation loss: 2.129005735119184

Epoch: 5| Step: 5
Training loss: 0.7583420276641846
Validation loss: 2.0768225391705832

Epoch: 5| Step: 6
Training loss: 0.9240196943283081
Validation loss: 2.1078000962734222

Epoch: 5| Step: 7
Training loss: 0.9876002073287964
Validation loss: 2.055480659008026

Epoch: 5| Step: 8
Training loss: 1.2518842220306396
Validation loss: 2.1103653609752655

Epoch: 5| Step: 9
Training loss: 0.8834463357925415
Validation loss: 2.107831686735153

Epoch: 5| Step: 10
Training loss: 1.164827585220337
Validation loss: 2.1349817464749017

Epoch: 5| Step: 11
Training loss: 0.8231961727142334
Validation loss: 2.1123634775479636

Epoch: 465| Step: 0
Training loss: 0.9602373242378235
Validation loss: 2.1492601186037064

Epoch: 5| Step: 1
Training loss: 0.9062756299972534
Validation loss: 2.1565620054801307

Epoch: 5| Step: 2
Training loss: 1.3291808366775513
Validation loss: 2.141697660088539

Epoch: 5| Step: 3
Training loss: 1.1373751163482666
Validation loss: 2.164662629365921

Epoch: 5| Step: 4
Training loss: 0.7522883415222168
Validation loss: 2.136425276597341

Epoch: 5| Step: 5
Training loss: 0.9771144986152649
Validation loss: 2.1686810553073883

Epoch: 5| Step: 6
Training loss: 1.0388991832733154
Validation loss: 2.1715695361296334

Epoch: 5| Step: 7
Training loss: 0.6805518865585327
Validation loss: 2.152785857518514

Epoch: 5| Step: 8
Training loss: 0.7956911325454712
Validation loss: 2.1132281919320426

Epoch: 5| Step: 9
Training loss: 0.9780870676040649
Validation loss: 2.1881995598475137

Epoch: 5| Step: 10
Training loss: 1.1470258235931396
Validation loss: 2.1767228047053018

Epoch: 5| Step: 11
Training loss: 1.1056928634643555
Validation loss: 2.1268538385629654

Epoch: 466| Step: 0
Training loss: 0.5639553070068359
Validation loss: 2.1632055044174194

Epoch: 5| Step: 1
Training loss: 0.8967064023017883
Validation loss: 2.171219746271769

Epoch: 5| Step: 2
Training loss: 1.0583418607711792
Validation loss: 2.1474153051773706

Epoch: 5| Step: 3
Training loss: 0.9378963708877563
Validation loss: 2.1907665580511093

Epoch: 5| Step: 4
Training loss: 0.6548962593078613
Validation loss: 2.226329023639361

Epoch: 5| Step: 5
Training loss: 0.861303985118866
Validation loss: 2.1831753005584082

Epoch: 5| Step: 6
Training loss: 1.4873322248458862
Validation loss: 2.186505307753881

Epoch: 5| Step: 7
Training loss: 0.8677226901054382
Validation loss: 2.1318229039510093

Epoch: 5| Step: 8
Training loss: 1.4285659790039062
Validation loss: 2.17794398466746

Epoch: 5| Step: 9
Training loss: 1.105908989906311
Validation loss: 2.201862355073293

Epoch: 5| Step: 10
Training loss: 1.0230767726898193
Validation loss: 2.206102649370829

Epoch: 5| Step: 11
Training loss: 0.5237874984741211
Validation loss: 2.186381404598554

Epoch: 467| Step: 0
Training loss: 1.1617166996002197
Validation loss: 2.1838031907876334

Epoch: 5| Step: 1
Training loss: 1.2610365152359009
Validation loss: 2.165724034110705

Epoch: 5| Step: 2
Training loss: 0.772138774394989
Validation loss: 2.181765466928482

Epoch: 5| Step: 3
Training loss: 0.89789879322052
Validation loss: 2.169811174273491

Epoch: 5| Step: 4
Training loss: 1.0849878787994385
Validation loss: 2.136375958720843

Epoch: 5| Step: 5
Training loss: 1.1223657131195068
Validation loss: 2.16874523460865

Epoch: 5| Step: 6
Training loss: 0.6966441869735718
Validation loss: 2.1875390807787576

Epoch: 5| Step: 7
Training loss: 0.6399604082107544
Validation loss: 2.236431469519933

Epoch: 5| Step: 8
Training loss: 0.8816565275192261
Validation loss: 2.1950973520676293

Epoch: 5| Step: 9
Training loss: 1.299863338470459
Validation loss: 2.155192732810974

Epoch: 5| Step: 10
Training loss: 1.1026073694229126
Validation loss: 2.1693853040536246

Epoch: 5| Step: 11
Training loss: 0.4868892431259155
Validation loss: 2.1630129665136337

Epoch: 468| Step: 0
Training loss: 0.9982892274856567
Validation loss: 2.175822595755259

Epoch: 5| Step: 1
Training loss: 0.97322016954422
Validation loss: 2.182277167836825

Epoch: 5| Step: 2
Training loss: 1.358001470565796
Validation loss: 2.221429631114006

Epoch: 5| Step: 3
Training loss: 0.9088819622993469
Validation loss: 2.172623117764791

Epoch: 5| Step: 4
Training loss: 1.5774521827697754
Validation loss: 2.1522572338581085

Epoch: 5| Step: 5
Training loss: 1.0686070919036865
Validation loss: 2.1746682226657867

Epoch: 5| Step: 6
Training loss: 0.7623227834701538
Validation loss: 2.201311389605204

Epoch: 5| Step: 7
Training loss: 0.7738315463066101
Validation loss: 2.1843897501627603

Epoch: 5| Step: 8
Training loss: 0.8973719477653503
Validation loss: 2.181800345579783

Epoch: 5| Step: 9
Training loss: 1.286125898361206
Validation loss: 2.1472924947738647

Epoch: 5| Step: 10
Training loss: 0.7977417707443237
Validation loss: 2.180480122566223

Epoch: 5| Step: 11
Training loss: 0.7218879461288452
Validation loss: 2.141718859473864

Epoch: 469| Step: 0
Training loss: 0.9583556056022644
Validation loss: 2.1776518325010934

Epoch: 5| Step: 1
Training loss: 1.012689232826233
Validation loss: 2.1578138321638107

Epoch: 5| Step: 2
Training loss: 1.1086183786392212
Validation loss: 2.1356043418248496

Epoch: 5| Step: 3
Training loss: 0.9454372525215149
Validation loss: 2.1277783513069153

Epoch: 5| Step: 4
Training loss: 0.9363871812820435
Validation loss: 2.1287448555231094

Epoch: 5| Step: 5
Training loss: 1.0097997188568115
Validation loss: 2.157307287057241

Epoch: 5| Step: 6
Training loss: 1.3396230936050415
Validation loss: 2.111568277080854

Epoch: 5| Step: 7
Training loss: 1.1396782398223877
Validation loss: 2.127270817756653

Epoch: 5| Step: 8
Training loss: 0.9176580309867859
Validation loss: 2.117673466602961

Epoch: 5| Step: 9
Training loss: 0.8549009561538696
Validation loss: 2.1423782805601754

Epoch: 5| Step: 10
Training loss: 0.5672864317893982
Validation loss: 2.1478758106629052

Epoch: 5| Step: 11
Training loss: 1.8910441398620605
Validation loss: 2.195211092631022

Epoch: 470| Step: 0
Training loss: 1.5725061893463135
Validation loss: 2.187949558099111

Epoch: 5| Step: 1
Training loss: 0.9526082873344421
Validation loss: 2.1582544843355813

Epoch: 5| Step: 2
Training loss: 1.1970291137695312
Validation loss: 2.2015760193268457

Epoch: 5| Step: 3
Training loss: 1.2163569927215576
Validation loss: 2.2157191733519235

Epoch: 5| Step: 4
Training loss: 1.0380436182022095
Validation loss: 2.2027977208296456

Epoch: 5| Step: 5
Training loss: 0.6005139350891113
Validation loss: 2.2163559645414352

Epoch: 5| Step: 6
Training loss: 0.8944481015205383
Validation loss: 2.201872835556666

Epoch: 5| Step: 7
Training loss: 0.6586014032363892
Validation loss: 2.150760675470034

Epoch: 5| Step: 8
Training loss: 0.5906986594200134
Validation loss: 2.1477254231770835

Epoch: 5| Step: 9
Training loss: 0.9545454978942871
Validation loss: 2.1895891626675925

Epoch: 5| Step: 10
Training loss: 1.3569873571395874
Validation loss: 2.127606744567553

Epoch: 5| Step: 11
Training loss: 0.5855839252471924
Validation loss: 2.1391049921512604

Epoch: 471| Step: 0
Training loss: 1.3327560424804688
Validation loss: 2.164475664496422

Epoch: 5| Step: 1
Training loss: 0.9828804135322571
Validation loss: 2.1732158809900284

Epoch: 5| Step: 2
Training loss: 0.6056028604507446
Validation loss: 2.1659073531627655

Epoch: 5| Step: 3
Training loss: 1.2485545873641968
Validation loss: 2.143364275495211

Epoch: 5| Step: 4
Training loss: 0.5516060590744019
Validation loss: 2.1255936374266944

Epoch: 5| Step: 5
Training loss: 0.8706251978874207
Validation loss: 2.175634572903315

Epoch: 5| Step: 6
Training loss: 0.7783532738685608
Validation loss: 2.142808655897776

Epoch: 5| Step: 7
Training loss: 1.1324524879455566
Validation loss: 2.1526425580183663

Epoch: 5| Step: 8
Training loss: 1.111840009689331
Validation loss: 2.199265251557032

Epoch: 5| Step: 9
Training loss: 0.778312087059021
Validation loss: 2.2175880670547485

Epoch: 5| Step: 10
Training loss: 1.1179449558258057
Validation loss: 2.1603449086348214

Epoch: 5| Step: 11
Training loss: 0.5101358294487
Validation loss: 2.1991383681694665

Epoch: 472| Step: 0
Training loss: 1.0493431091308594
Validation loss: 2.229484274983406

Epoch: 5| Step: 1
Training loss: 1.019416332244873
Validation loss: 2.1943415105342865

Epoch: 5| Step: 2
Training loss: 0.7334010601043701
Validation loss: 2.218211809794108

Epoch: 5| Step: 3
Training loss: 0.8933364152908325
Validation loss: 2.1930656085411706

Epoch: 5| Step: 4
Training loss: 1.0918679237365723
Validation loss: 2.174848268429438

Epoch: 5| Step: 5
Training loss: 1.025125503540039
Validation loss: 2.1755684117476144

Epoch: 5| Step: 6
Training loss: 0.5298899412155151
Validation loss: 2.164199302593867

Epoch: 5| Step: 7
Training loss: 1.9187310934066772
Validation loss: 2.193679799636205

Epoch: 5| Step: 8
Training loss: 1.0311429500579834
Validation loss: 2.2082038770119348

Epoch: 5| Step: 9
Training loss: 0.5619620084762573
Validation loss: 2.1584558486938477

Epoch: 5| Step: 10
Training loss: 0.5623643398284912
Validation loss: 2.1800985435644784

Epoch: 5| Step: 11
Training loss: 0.6045792102813721
Validation loss: 2.2049062500397363

Epoch: 473| Step: 0
Training loss: 0.6570894122123718
Validation loss: 2.159931888182958

Epoch: 5| Step: 1
Training loss: 0.6127110719680786
Validation loss: 2.134635791182518

Epoch: 5| Step: 2
Training loss: 0.7333583831787109
Validation loss: 2.1772645910580954

Epoch: 5| Step: 3
Training loss: 1.2040022611618042
Validation loss: 2.2225968092679977

Epoch: 5| Step: 4
Training loss: 1.3164446353912354
Validation loss: 2.1644881069660187

Epoch: 5| Step: 5
Training loss: 1.3073996305465698
Validation loss: 2.166557023922602

Epoch: 5| Step: 6
Training loss: 1.1531598567962646
Validation loss: 2.176428178946177

Epoch: 5| Step: 7
Training loss: 0.8112514615058899
Validation loss: 2.182312165697416

Epoch: 5| Step: 8
Training loss: 0.47994598746299744
Validation loss: 2.188996990521749

Epoch: 5| Step: 9
Training loss: 1.3664734363555908
Validation loss: 2.1779601524273553

Epoch: 5| Step: 10
Training loss: 0.8429058194160461
Validation loss: 2.248261645436287

Epoch: 5| Step: 11
Training loss: 0.5268251895904541
Validation loss: 2.200928126772245

Epoch: 474| Step: 0
Training loss: 1.4947079420089722
Validation loss: 2.2494889398415885

Epoch: 5| Step: 1
Training loss: 0.6534594893455505
Validation loss: 2.2316244641939798

Epoch: 5| Step: 2
Training loss: 1.1891130208969116
Validation loss: 2.2080680628617606

Epoch: 5| Step: 3
Training loss: 0.6709169149398804
Validation loss: 2.1610978543758392

Epoch: 5| Step: 4
Training loss: 1.1760753393173218
Validation loss: 2.16561329861482

Epoch: 5| Step: 5
Training loss: 0.9529587030410767
Validation loss: 2.1489116549491882

Epoch: 5| Step: 6
Training loss: 0.9972925186157227
Validation loss: 2.0867964078982673

Epoch: 5| Step: 7
Training loss: 0.8861900568008423
Validation loss: 2.0715625435113907

Epoch: 5| Step: 8
Training loss: 1.153740406036377
Validation loss: 2.1059199621280036

Epoch: 5| Step: 9
Training loss: 0.6884843111038208
Validation loss: 2.0820452074209848

Epoch: 5| Step: 10
Training loss: 0.9494756460189819
Validation loss: 2.131807655096054

Epoch: 5| Step: 11
Training loss: 0.3402005434036255
Validation loss: 2.1182308147350946

Epoch: 475| Step: 0
Training loss: 0.7184367775917053
Validation loss: 2.1393474340438843

Epoch: 5| Step: 1
Training loss: 0.5429633855819702
Validation loss: 2.1230887472629547

Epoch: 5| Step: 2
Training loss: 1.27657949924469
Validation loss: 2.1868466337521872

Epoch: 5| Step: 3
Training loss: 1.1332752704620361
Validation loss: 2.177735616763433

Epoch: 5| Step: 4
Training loss: 0.8623450994491577
Validation loss: 2.1408164898554483

Epoch: 5| Step: 5
Training loss: 1.1581662893295288
Validation loss: 2.1477497667074203

Epoch: 5| Step: 6
Training loss: 0.8230827450752258
Validation loss: 2.130417058865229

Epoch: 5| Step: 7
Training loss: 1.3000423908233643
Validation loss: 2.1600141872962317

Epoch: 5| Step: 8
Training loss: 0.5592591166496277
Validation loss: 2.178625469406446

Epoch: 5| Step: 9
Training loss: 0.7634512782096863
Validation loss: 2.209681198000908

Epoch: 5| Step: 10
Training loss: 0.8975183367729187
Validation loss: 2.165923903385798

Epoch: 5| Step: 11
Training loss: 0.35702693462371826
Validation loss: 2.1823397874832153

Epoch: 476| Step: 0
Training loss: 1.0659136772155762
Validation loss: 2.1966869235038757

Epoch: 5| Step: 1
Training loss: 0.8972078561782837
Validation loss: 2.186895747979482

Epoch: 5| Step: 2
Training loss: 0.6048120260238647
Validation loss: 2.2132833153009415

Epoch: 5| Step: 3
Training loss: 0.7391291260719299
Validation loss: 2.2058497915665307

Epoch: 5| Step: 4
Training loss: 0.912525475025177
Validation loss: 2.183298980196317

Epoch: 5| Step: 5
Training loss: 0.6975773572921753
Validation loss: 2.111662824948629

Epoch: 5| Step: 6
Training loss: 0.7013351917266846
Validation loss: 2.2155031263828278

Epoch: 5| Step: 7
Training loss: 1.6034603118896484
Validation loss: 2.1657571345567703

Epoch: 5| Step: 8
Training loss: 0.8004541397094727
Validation loss: 2.207437048355738

Epoch: 5| Step: 9
Training loss: 0.9028263092041016
Validation loss: 2.17607914408048

Epoch: 5| Step: 10
Training loss: 1.0902560949325562
Validation loss: 2.1694872031609216

Epoch: 5| Step: 11
Training loss: 0.6292575001716614
Validation loss: 2.1462826281785965

Epoch: 477| Step: 0
Training loss: 0.5055633783340454
Validation loss: 2.1645885010560355

Epoch: 5| Step: 1
Training loss: 1.4015324115753174
Validation loss: 2.205165058374405

Epoch: 5| Step: 2
Training loss: 0.798133909702301
Validation loss: 2.16933407386144

Epoch: 5| Step: 3
Training loss: 0.8194150924682617
Validation loss: 2.1751139611005783

Epoch: 5| Step: 4
Training loss: 1.4297773838043213
Validation loss: 2.142265493671099

Epoch: 5| Step: 5
Training loss: 1.0478017330169678
Validation loss: 2.047072947025299

Epoch: 5| Step: 6
Training loss: 0.8697250485420227
Validation loss: 2.0707971453666687

Epoch: 5| Step: 7
Training loss: 1.4514695405960083
Validation loss: 2.1054830700159073

Epoch: 5| Step: 8
Training loss: 0.9439601898193359
Validation loss: 2.092124422391256

Epoch: 5| Step: 9
Training loss: 1.0004377365112305
Validation loss: 2.0658950954675674

Epoch: 5| Step: 10
Training loss: 1.3075592517852783
Validation loss: 2.0849289894104004

Epoch: 5| Step: 11
Training loss: 0.8800193071365356
Validation loss: 2.0751817921797433

Epoch: 478| Step: 0
Training loss: 0.754762589931488
Validation loss: 2.0812232395013175

Epoch: 5| Step: 1
Training loss: 0.9120807647705078
Validation loss: 2.045439660549164

Epoch: 5| Step: 2
Training loss: 1.0426757335662842
Validation loss: 2.0771620720624924

Epoch: 5| Step: 3
Training loss: 1.1375463008880615
Validation loss: 2.112652356425921

Epoch: 5| Step: 4
Training loss: 0.9133630990982056
Validation loss: 2.1426787227392197

Epoch: 5| Step: 5
Training loss: 0.9941642880439758
Validation loss: 2.151934027671814

Epoch: 5| Step: 6
Training loss: 0.6965337991714478
Validation loss: 2.1359837452570596

Epoch: 5| Step: 7
Training loss: 0.5733169913291931
Validation loss: 2.1754605174064636

Epoch: 5| Step: 8
Training loss: 1.0749647617340088
Validation loss: 2.153299495577812

Epoch: 5| Step: 9
Training loss: 1.0873771905899048
Validation loss: 2.1388032138347626

Epoch: 5| Step: 10
Training loss: 1.3339626789093018
Validation loss: 2.2193611015876136

Epoch: 5| Step: 11
Training loss: 0.8951448798179626
Validation loss: 2.2031586120525994

Epoch: 479| Step: 0
Training loss: 0.9599359631538391
Validation loss: 2.1734479467074075

Epoch: 5| Step: 1
Training loss: 0.9036765098571777
Validation loss: 2.200371061762174

Epoch: 5| Step: 2
Training loss: 1.1072829961776733
Validation loss: 2.161098142464956

Epoch: 5| Step: 3
Training loss: 1.1953761577606201
Validation loss: 2.199415331085523

Epoch: 5| Step: 4
Training loss: 0.9814637303352356
Validation loss: 2.144137293100357

Epoch: 5| Step: 5
Training loss: 0.6309307813644409
Validation loss: 2.1404200891653695

Epoch: 5| Step: 6
Training loss: 0.8890663385391235
Validation loss: 2.15148933728536

Epoch: 5| Step: 7
Training loss: 0.773100733757019
Validation loss: 2.174464742342631

Epoch: 5| Step: 8
Training loss: 0.8529542088508606
Validation loss: 2.117402270436287

Epoch: 5| Step: 9
Training loss: 0.8782945871353149
Validation loss: 2.07914732893308

Epoch: 5| Step: 10
Training loss: 0.6563212871551514
Validation loss: 2.0873580823342004

Epoch: 5| Step: 11
Training loss: 2.37955904006958
Validation loss: 2.1333665748437247

Epoch: 480| Step: 0
Training loss: 0.7312421798706055
Validation loss: 2.076240986585617

Epoch: 5| Step: 1
Training loss: 0.7043263912200928
Validation loss: 2.085650106271108

Epoch: 5| Step: 2
Training loss: 0.9318825006484985
Validation loss: 2.095783288280169

Epoch: 5| Step: 3
Training loss: 1.024930715560913
Validation loss: 2.097707321246465

Epoch: 5| Step: 4
Training loss: 0.6240350604057312
Validation loss: 2.1282423535982766

Epoch: 5| Step: 5
Training loss: 0.9392646551132202
Validation loss: 2.050741031765938

Epoch: 5| Step: 6
Training loss: 1.1604321002960205
Validation loss: 2.08065598209699

Epoch: 5| Step: 7
Training loss: 0.6914840936660767
Validation loss: 2.1069659094015756

Epoch: 5| Step: 8
Training loss: 1.6532843112945557
Validation loss: 2.1228579680124917

Epoch: 5| Step: 9
Training loss: 0.8183808326721191
Validation loss: 2.126003051797549

Epoch: 5| Step: 10
Training loss: 0.8226677775382996
Validation loss: 2.1367656787236533

Epoch: 5| Step: 11
Training loss: 0.7742903232574463
Validation loss: 2.1350972801446915

Epoch: 481| Step: 0
Training loss: 0.6809217929840088
Validation loss: 2.1579956809679666

Epoch: 5| Step: 1
Training loss: 1.1575597524642944
Validation loss: 2.1365222930908203

Epoch: 5| Step: 2
Training loss: 1.3726155757904053
Validation loss: 2.137904942035675

Epoch: 5| Step: 3
Training loss: 0.7217543125152588
Validation loss: 2.171396632989248

Epoch: 5| Step: 4
Training loss: 0.97356778383255
Validation loss: 2.1337739626566568

Epoch: 5| Step: 5
Training loss: 1.3115280866622925
Validation loss: 2.0945869982242584

Epoch: 5| Step: 6
Training loss: 0.8224460482597351
Validation loss: 2.1096850434939065

Epoch: 5| Step: 7
Training loss: 0.5092364549636841
Validation loss: 2.1614787628253302

Epoch: 5| Step: 8
Training loss: 1.0033057928085327
Validation loss: 2.162701368331909

Epoch: 5| Step: 9
Training loss: 0.9491226077079773
Validation loss: 2.1834791600704193

Epoch: 5| Step: 10
Training loss: 0.8528226613998413
Validation loss: 2.152199367682139

Epoch: 5| Step: 11
Training loss: 1.1581478118896484
Validation loss: 2.180802881717682

Epoch: 482| Step: 0
Training loss: 0.5912072062492371
Validation loss: 2.1950918088356652

Epoch: 5| Step: 1
Training loss: 1.375514268875122
Validation loss: 2.1934614926576614

Epoch: 5| Step: 2
Training loss: 1.105547308921814
Validation loss: 2.205703556537628

Epoch: 5| Step: 3
Training loss: 0.6807933449745178
Validation loss: 2.20209664106369

Epoch: 5| Step: 4
Training loss: 0.668592095375061
Validation loss: 2.166513999303182

Epoch: 5| Step: 5
Training loss: 0.6190244555473328
Validation loss: 2.1640130827824273

Epoch: 5| Step: 6
Training loss: 0.8542518615722656
Validation loss: 2.1183914095163345

Epoch: 5| Step: 7
Training loss: 0.9161497354507446
Validation loss: 2.1303841372330985

Epoch: 5| Step: 8
Training loss: 0.632047712802887
Validation loss: 2.0956923315922418

Epoch: 5| Step: 9
Training loss: 1.0628859996795654
Validation loss: 2.159019112586975

Epoch: 5| Step: 10
Training loss: 0.900922954082489
Validation loss: 2.1669221967458725

Epoch: 5| Step: 11
Training loss: 1.5056061744689941
Validation loss: 2.1108686476945877

Epoch: 483| Step: 0
Training loss: 0.5438281297683716
Validation loss: 2.1182041267553964

Epoch: 5| Step: 1
Training loss: 0.8553982973098755
Validation loss: 2.1197386731704078

Epoch: 5| Step: 2
Training loss: 0.7579545974731445
Validation loss: 2.1313099563121796

Epoch: 5| Step: 3
Training loss: 0.7853982448577881
Validation loss: 2.186153839031855

Epoch: 5| Step: 4
Training loss: 0.9993710517883301
Validation loss: 2.2272930393616357

Epoch: 5| Step: 5
Training loss: 1.2665215730667114
Validation loss: 2.1912552962700524

Epoch: 5| Step: 6
Training loss: 1.124219536781311
Validation loss: 2.169786145289739

Epoch: 5| Step: 7
Training loss: 0.7276290655136108
Validation loss: 2.120849922299385

Epoch: 5| Step: 8
Training loss: 1.172103762626648
Validation loss: 2.117228776216507

Epoch: 5| Step: 9
Training loss: 1.0493173599243164
Validation loss: 2.164154574275017

Epoch: 5| Step: 10
Training loss: 0.8020332455635071
Validation loss: 2.1409142216046653

Epoch: 5| Step: 11
Training loss: 0.4862457811832428
Validation loss: 2.0983013908068338

Epoch: 484| Step: 0
Training loss: 1.127813458442688
Validation loss: 2.137932524085045

Epoch: 5| Step: 1
Training loss: 0.91997891664505
Validation loss: 2.0609252552191415

Epoch: 5| Step: 2
Training loss: 0.7837730646133423
Validation loss: 2.0676183501879373

Epoch: 5| Step: 3
Training loss: 0.7799188494682312
Validation loss: 2.1146883318821588

Epoch: 5| Step: 4
Training loss: 0.9240827560424805
Validation loss: 2.1677134931087494

Epoch: 5| Step: 5
Training loss: 0.9968466758728027
Validation loss: 2.222328553597132

Epoch: 5| Step: 6
Training loss: 0.8356364965438843
Validation loss: 2.1908603062232337

Epoch: 5| Step: 7
Training loss: 1.4372532367706299
Validation loss: 2.2419913162787757

Epoch: 5| Step: 8
Training loss: 1.0067299604415894
Validation loss: 2.1776637931664786

Epoch: 5| Step: 9
Training loss: 0.8615075945854187
Validation loss: 2.0981898456811905

Epoch: 5| Step: 10
Training loss: 0.8524672389030457
Validation loss: 2.1020180583000183

Epoch: 5| Step: 11
Training loss: 1.3680131435394287
Validation loss: 2.1201003789901733

Epoch: 485| Step: 0
Training loss: 0.6113871335983276
Validation loss: 2.1513398985068

Epoch: 5| Step: 1
Training loss: 1.1851348876953125
Validation loss: 2.171089599529902

Epoch: 5| Step: 2
Training loss: 0.935390830039978
Validation loss: 2.151400645573934

Epoch: 5| Step: 3
Training loss: 1.0811370611190796
Validation loss: 2.1458949893712997

Epoch: 5| Step: 4
Training loss: 0.9923144578933716
Validation loss: 2.1442183454831443

Epoch: 5| Step: 5
Training loss: 0.8461767435073853
Validation loss: 2.129111632704735

Epoch: 5| Step: 6
Training loss: 0.8473377227783203
Validation loss: 2.135342170794805

Epoch: 5| Step: 7
Training loss: 0.7084983587265015
Validation loss: 2.061238999168078

Epoch: 5| Step: 8
Training loss: 1.2450551986694336
Validation loss: 2.103886902332306

Epoch: 5| Step: 9
Training loss: 0.8007218241691589
Validation loss: 2.085437764724096

Epoch: 5| Step: 10
Training loss: 0.9951372146606445
Validation loss: 2.1269887189070382

Epoch: 5| Step: 11
Training loss: 0.7043361067771912
Validation loss: 2.0944289167722068

Epoch: 486| Step: 0
Training loss: 0.7650457620620728
Validation loss: 2.17632823685805

Epoch: 5| Step: 1
Training loss: 0.6547127366065979
Validation loss: 2.140403444568316

Epoch: 5| Step: 2
Training loss: 1.000023603439331
Validation loss: 2.18293305238088

Epoch: 5| Step: 3
Training loss: 0.8580076098442078
Validation loss: 2.2151835014422736

Epoch: 5| Step: 4
Training loss: 1.0785455703735352
Validation loss: 2.1525798241297402

Epoch: 5| Step: 5
Training loss: 1.341929316520691
Validation loss: 2.094308535257975

Epoch: 5| Step: 6
Training loss: 0.7604699730873108
Validation loss: 2.09761950870355

Epoch: 5| Step: 7
Training loss: 1.0097894668579102
Validation loss: 2.113336975375811

Epoch: 5| Step: 8
Training loss: 0.6629691123962402
Validation loss: 2.1626156866550446

Epoch: 5| Step: 9
Training loss: 0.7495698928833008
Validation loss: 2.1938272615273795

Epoch: 5| Step: 10
Training loss: 1.4415414333343506
Validation loss: 2.154544234275818

Epoch: 5| Step: 11
Training loss: 0.4970839023590088
Validation loss: 2.162438601255417

Epoch: 487| Step: 0
Training loss: 1.1193643808364868
Validation loss: 2.173251206676165

Epoch: 5| Step: 1
Training loss: 0.888566792011261
Validation loss: 2.196760361393293

Epoch: 5| Step: 2
Training loss: 0.3530326187610626
Validation loss: 2.1972648799419403

Epoch: 5| Step: 3
Training loss: 0.8679794073104858
Validation loss: 2.1382032384475074

Epoch: 5| Step: 4
Training loss: 1.5104634761810303
Validation loss: 2.1559770703315735

Epoch: 5| Step: 5
Training loss: 0.9074877500534058
Validation loss: 2.1587674568096795

Epoch: 5| Step: 6
Training loss: 0.7403141260147095
Validation loss: 2.1441367814938226

Epoch: 5| Step: 7
Training loss: 0.9594119787216187
Validation loss: 2.115863929192225

Epoch: 5| Step: 8
Training loss: 1.04694402217865
Validation loss: 2.12056972583135

Epoch: 5| Step: 9
Training loss: 0.6584345698356628
Validation loss: 2.105413541197777

Epoch: 5| Step: 10
Training loss: 0.7004464268684387
Validation loss: 2.102938344081243

Epoch: 5| Step: 11
Training loss: 0.46395590901374817
Validation loss: 2.1082675606012344

Epoch: 488| Step: 0
Training loss: 0.47290998697280884
Validation loss: 2.104837184151014

Epoch: 5| Step: 1
Training loss: 0.7824541926383972
Validation loss: 2.105516791343689

Epoch: 5| Step: 2
Training loss: 0.6460483074188232
Validation loss: 2.1406394044558206

Epoch: 5| Step: 3
Training loss: 0.8726919293403625
Validation loss: 2.1220851093530655

Epoch: 5| Step: 4
Training loss: 1.0320520401000977
Validation loss: 2.1193850487470627

Epoch: 5| Step: 5
Training loss: 0.529541015625
Validation loss: 2.162493964036306

Epoch: 5| Step: 6
Training loss: 1.0883821249008179
Validation loss: 2.138645107547442

Epoch: 5| Step: 7
Training loss: 0.6160898208618164
Validation loss: 2.1259645372629166

Epoch: 5| Step: 8
Training loss: 0.7345816493034363
Validation loss: 2.143000473578771

Epoch: 5| Step: 9
Training loss: 1.361573576927185
Validation loss: 2.1432744761308036

Epoch: 5| Step: 10
Training loss: 0.867774486541748
Validation loss: 2.1624853909015656

Epoch: 5| Step: 11
Training loss: 3.1627843379974365
Validation loss: 2.175445646047592

Epoch: 489| Step: 0
Training loss: 0.9881450533866882
Validation loss: 2.1369084467490516

Epoch: 5| Step: 1
Training loss: 1.0067857503890991
Validation loss: 2.1423790554205575

Epoch: 5| Step: 2
Training loss: 1.1686021089553833
Validation loss: 2.1392869651317596

Epoch: 5| Step: 3
Training loss: 0.9705959558486938
Validation loss: 2.141776288549105

Epoch: 5| Step: 4
Training loss: 0.8652762174606323
Validation loss: 2.142393171787262

Epoch: 5| Step: 5
Training loss: 0.7766287326812744
Validation loss: 2.1152462164560952

Epoch: 5| Step: 6
Training loss: 0.6190448999404907
Validation loss: 2.142637610435486

Epoch: 5| Step: 7
Training loss: 0.7133117318153381
Validation loss: 2.0840095380942025

Epoch: 5| Step: 8
Training loss: 0.787767231464386
Validation loss: 2.148109888037046

Epoch: 5| Step: 9
Training loss: 1.0144522190093994
Validation loss: 2.178914094964663

Epoch: 5| Step: 10
Training loss: 0.6225137114524841
Validation loss: 2.1623061348994574

Epoch: 5| Step: 11
Training loss: 1.3472208976745605
Validation loss: 2.164228225747744

Epoch: 490| Step: 0
Training loss: 0.6507377028465271
Validation loss: 2.1334891617298126

Epoch: 5| Step: 1
Training loss: 0.601021945476532
Validation loss: 2.121867979566256

Epoch: 5| Step: 2
Training loss: 1.0178887844085693
Validation loss: 2.2078245679537454

Epoch: 5| Step: 3
Training loss: 0.8920434713363647
Validation loss: 2.2296238591273627

Epoch: 5| Step: 4
Training loss: 1.1074342727661133
Validation loss: 2.2144833902517953

Epoch: 5| Step: 5
Training loss: 1.1671454906463623
Validation loss: 2.1867234210173288

Epoch: 5| Step: 6
Training loss: 0.8257894515991211
Validation loss: 2.1893442968527475

Epoch: 5| Step: 7
Training loss: 0.912662148475647
Validation loss: 2.2098456968863807

Epoch: 5| Step: 8
Training loss: 0.5324873328208923
Validation loss: 2.175656666358312

Epoch: 5| Step: 9
Training loss: 0.7228965759277344
Validation loss: 2.1390565782785416

Epoch: 5| Step: 10
Training loss: 0.998897910118103
Validation loss: 2.1174208919207254

Epoch: 5| Step: 11
Training loss: 1.4257951974868774
Validation loss: 2.1323274622360864

Epoch: 491| Step: 0
Training loss: 0.6418471336364746
Validation loss: 2.1557614356279373

Epoch: 5| Step: 1
Training loss: 0.45501384139060974
Validation loss: 2.1559940725564957

Epoch: 5| Step: 2
Training loss: 1.0613043308258057
Validation loss: 2.128014862537384

Epoch: 5| Step: 3
Training loss: 0.8985840678215027
Validation loss: 2.1127939174572625

Epoch: 5| Step: 4
Training loss: 0.5869644284248352
Validation loss: 2.105894073843956

Epoch: 5| Step: 5
Training loss: 1.1027594804763794
Validation loss: 2.1106928239266076

Epoch: 5| Step: 6
Training loss: 1.5172168016433716
Validation loss: 2.1277118821938834

Epoch: 5| Step: 7
Training loss: 0.6582947373390198
Validation loss: 2.078721816341082

Epoch: 5| Step: 8
Training loss: 0.8326808214187622
Validation loss: 2.1213088432947793

Epoch: 5| Step: 9
Training loss: 0.8767527341842651
Validation loss: 2.1243463357289634

Epoch: 5| Step: 10
Training loss: 0.8282915353775024
Validation loss: 2.1054262270530066

Epoch: 5| Step: 11
Training loss: 1.3724253177642822
Validation loss: 2.108667626976967

Epoch: 492| Step: 0
Training loss: 1.02535879611969
Validation loss: 2.0916463236014047

Epoch: 5| Step: 1
Training loss: 0.7237647175788879
Validation loss: 2.0937810043493905

Epoch: 5| Step: 2
Training loss: 0.6805492639541626
Validation loss: 2.1054734140634537

Epoch: 5| Step: 3
Training loss: 0.883797287940979
Validation loss: 2.0884672552347183

Epoch: 5| Step: 4
Training loss: 0.7915200591087341
Validation loss: 2.0914815763632455

Epoch: 5| Step: 5
Training loss: 0.6417971849441528
Validation loss: 2.1012023190657296

Epoch: 5| Step: 6
Training loss: 0.6617043018341064
Validation loss: 2.1062183479468026

Epoch: 5| Step: 7
Training loss: 1.240175485610962
Validation loss: 2.0738871097564697

Epoch: 5| Step: 8
Training loss: 0.8489965200424194
Validation loss: 2.053039809068044

Epoch: 5| Step: 9
Training loss: 1.0884162187576294
Validation loss: 2.084418758749962

Epoch: 5| Step: 10
Training loss: 0.8856180310249329
Validation loss: 2.143597573041916

Epoch: 5| Step: 11
Training loss: 0.4554392099380493
Validation loss: 2.114344904820124

Epoch: 493| Step: 0
Training loss: 0.8978906869888306
Validation loss: 2.1353911260763803

Epoch: 5| Step: 1
Training loss: 0.6151909828186035
Validation loss: 2.1203089555104575

Epoch: 5| Step: 2
Training loss: 1.1508934497833252
Validation loss: 2.128940840562185

Epoch: 5| Step: 3
Training loss: 1.2787750959396362
Validation loss: 2.152195299665133

Epoch: 5| Step: 4
Training loss: 0.4150882661342621
Validation loss: 2.1271513303120932

Epoch: 5| Step: 5
Training loss: 0.6482046842575073
Validation loss: 2.125774318973223

Epoch: 5| Step: 6
Training loss: 1.1023625135421753
Validation loss: 2.1536688754955926

Epoch: 5| Step: 7
Training loss: 0.7477421760559082
Validation loss: 2.1478994637727737

Epoch: 5| Step: 8
Training loss: 0.9119208455085754
Validation loss: 2.0837311247984567

Epoch: 5| Step: 9
Training loss: 0.9156044721603394
Validation loss: 2.105560769637426

Epoch: 5| Step: 10
Training loss: 0.8181123733520508
Validation loss: 2.1152507960796356

Epoch: 5| Step: 11
Training loss: 0.1610160917043686
Validation loss: 2.0861089477936425

Epoch: 494| Step: 0
Training loss: 0.9801890254020691
Validation loss: 2.079597776134809

Epoch: 5| Step: 1
Training loss: 0.902797520160675
Validation loss: 2.0794136623541513

Epoch: 5| Step: 2
Training loss: 1.1567497253417969
Validation loss: 2.0640091548363366

Epoch: 5| Step: 3
Training loss: 0.7253671884536743
Validation loss: 2.0270451505978904

Epoch: 5| Step: 4
Training loss: 0.822428822517395
Validation loss: 2.083708574374517

Epoch: 5| Step: 5
Training loss: 0.5419527292251587
Validation loss: 2.0771841406822205

Epoch: 5| Step: 6
Training loss: 0.9721634984016418
Validation loss: 2.100016454855601

Epoch: 5| Step: 7
Training loss: 0.48725587129592896
Validation loss: 2.0907711585362754

Epoch: 5| Step: 8
Training loss: 0.42750120162963867
Validation loss: 2.1103479911883674

Epoch: 5| Step: 9
Training loss: 1.0165644884109497
Validation loss: 2.103560984134674

Epoch: 5| Step: 10
Training loss: 1.2385454177856445
Validation loss: 2.133708188931147

Epoch: 5| Step: 11
Training loss: 0.2925635576248169
Validation loss: 2.1438539624214172

Epoch: 495| Step: 0
Training loss: 1.1887791156768799
Validation loss: 2.1538449923197427

Epoch: 5| Step: 1
Training loss: 1.2180263996124268
Validation loss: 2.2202370862166085

Epoch: 5| Step: 2
Training loss: 0.5540025234222412
Validation loss: 2.2516090969244638

Epoch: 5| Step: 3
Training loss: 1.0096063613891602
Validation loss: 2.2504341850678125

Epoch: 5| Step: 4
Training loss: 0.6409027576446533
Validation loss: 2.2062686582406363

Epoch: 5| Step: 5
Training loss: 0.7378429174423218
Validation loss: 2.1187985787789025

Epoch: 5| Step: 6
Training loss: 0.871342658996582
Validation loss: 2.1130371193091073

Epoch: 5| Step: 7
Training loss: 0.9514952898025513
Validation loss: 2.197097639242808

Epoch: 5| Step: 8
Training loss: 0.8663519620895386
Validation loss: 2.1526089310646057

Epoch: 5| Step: 9
Training loss: 0.8099520802497864
Validation loss: 2.144972195227941

Epoch: 5| Step: 10
Training loss: 1.0031108856201172
Validation loss: 2.1861740897099176

Epoch: 5| Step: 11
Training loss: 0.10249936580657959
Validation loss: 2.130111907919248

Epoch: 496| Step: 0
Training loss: 0.7685842514038086
Validation loss: 2.180960769454638

Epoch: 5| Step: 1
Training loss: 0.8840912580490112
Validation loss: 2.1789067337910333

Epoch: 5| Step: 2
Training loss: 0.9925004839897156
Validation loss: 2.180336579680443

Epoch: 5| Step: 3
Training loss: 1.3235714435577393
Validation loss: 2.173324391245842

Epoch: 5| Step: 4
Training loss: 0.6904116272926331
Validation loss: 2.1837853292624154

Epoch: 5| Step: 5
Training loss: 0.8165991902351379
Validation loss: 2.163803353905678

Epoch: 5| Step: 6
Training loss: 1.0054523944854736
Validation loss: 2.1670902570088706

Epoch: 5| Step: 7
Training loss: 0.52996426820755
Validation loss: 2.159663384159406

Epoch: 5| Step: 8
Training loss: 0.8212277293205261
Validation loss: 2.099593664209048

Epoch: 5| Step: 9
Training loss: 0.6690421104431152
Validation loss: 2.094096750020981

Epoch: 5| Step: 10
Training loss: 0.6479554772377014
Validation loss: 2.113888626297315

Epoch: 5| Step: 11
Training loss: 2.355030059814453
Validation loss: 2.079323803385099

Epoch: 497| Step: 0
Training loss: 0.9019725918769836
Validation loss: 2.1075962831576667

Epoch: 5| Step: 1
Training loss: 0.6840429306030273
Validation loss: 2.0931922048330307

Epoch: 5| Step: 2
Training loss: 0.8184221982955933
Validation loss: 2.0739883879820504

Epoch: 5| Step: 3
Training loss: 1.1908552646636963
Validation loss: 2.09470305343469

Epoch: 5| Step: 4
Training loss: 0.7540252804756165
Validation loss: 2.083071753382683

Epoch: 5| Step: 5
Training loss: 0.9774196743965149
Validation loss: 2.0232661366462708

Epoch: 5| Step: 6
Training loss: 0.7986283302307129
Validation loss: 2.0278119842211404

Epoch: 5| Step: 7
Training loss: 0.6520501375198364
Validation loss: 2.0482404828071594

Epoch: 5| Step: 8
Training loss: 1.0426219701766968
Validation loss: 2.061052516102791

Epoch: 5| Step: 9
Training loss: 1.1837141513824463
Validation loss: 2.059414952993393

Epoch: 5| Step: 10
Training loss: 0.5467283725738525
Validation loss: 2.0979657669862113

Epoch: 5| Step: 11
Training loss: 0.331800639629364
Validation loss: 2.133685494462649

Epoch: 498| Step: 0
Training loss: 0.6753222942352295
Validation loss: 2.1120110948880515

Epoch: 5| Step: 1
Training loss: 0.74470055103302
Validation loss: 2.1133538633584976

Epoch: 5| Step: 2
Training loss: 0.620217502117157
Validation loss: 2.11707711716493

Epoch: 5| Step: 3
Training loss: 1.1793943643569946
Validation loss: 2.0985230654478073

Epoch: 5| Step: 4
Training loss: 0.7737734913825989
Validation loss: 2.0972766081492105

Epoch: 5| Step: 5
Training loss: 0.5985265970230103
Validation loss: 2.128400514523188

Epoch: 5| Step: 6
Training loss: 0.8482936024665833
Validation loss: 2.0850230902433395

Epoch: 5| Step: 7
Training loss: 0.8877156972885132
Validation loss: 2.1668737530708313

Epoch: 5| Step: 8
Training loss: 0.707103431224823
Validation loss: 2.09932870666186

Epoch: 5| Step: 9
Training loss: 0.8997983932495117
Validation loss: 2.0993395894765854

Epoch: 5| Step: 10
Training loss: 1.0115330219268799
Validation loss: 2.120927393436432

Epoch: 5| Step: 11
Training loss: 0.6777483820915222
Validation loss: 2.122263083855311

Epoch: 499| Step: 0
Training loss: 1.0338444709777832
Validation loss: 2.1117106477419534

Epoch: 5| Step: 1
Training loss: 0.7729978561401367
Validation loss: 2.117310553789139

Epoch: 5| Step: 2
Training loss: 0.5435735583305359
Validation loss: 2.110980749130249

Epoch: 5| Step: 3
Training loss: 0.863882839679718
Validation loss: 2.174846430619558

Epoch: 5| Step: 4
Training loss: 1.0158352851867676
Validation loss: 2.1191479861736298

Epoch: 5| Step: 5
Training loss: 0.5942410230636597
Validation loss: 2.1514507879813514

Epoch: 5| Step: 6
Training loss: 0.5661525726318359
Validation loss: 2.1067600498596826

Epoch: 5| Step: 7
Training loss: 1.1965610980987549
Validation loss: 2.1296961655219397

Epoch: 5| Step: 8
Training loss: 0.5348199605941772
Validation loss: 2.1223500867684684

Epoch: 5| Step: 9
Training loss: 1.0516035556793213
Validation loss: 2.106693059206009

Epoch: 5| Step: 10
Training loss: 0.8630579710006714
Validation loss: 2.119186500708262

Epoch: 5| Step: 11
Training loss: 0.10535573959350586
Validation loss: 2.1304534624020257

Epoch: 500| Step: 0
Training loss: 0.5957659482955933
Validation loss: 2.0795989284912744

Epoch: 5| Step: 1
Training loss: 1.000279426574707
Validation loss: 2.1076229164997735

Epoch: 5| Step: 2
Training loss: 0.7142059206962585
Validation loss: 2.0931791563828788

Epoch: 5| Step: 3
Training loss: 0.4518349766731262
Validation loss: 2.115528474251429

Epoch: 5| Step: 4
Training loss: 1.0222364664077759
Validation loss: 2.0805051724116006

Epoch: 5| Step: 5
Training loss: 0.7544547319412231
Validation loss: 2.072395473718643

Epoch: 5| Step: 6
Training loss: 0.766101598739624
Validation loss: 2.0599724700053534

Epoch: 5| Step: 7
Training loss: 0.5525935888290405
Validation loss: 2.1241843899091086

Epoch: 5| Step: 8
Training loss: 0.7345808744430542
Validation loss: 2.0752210865418115

Epoch: 5| Step: 9
Training loss: 0.8565350770950317
Validation loss: 2.093272333343824

Epoch: 5| Step: 10
Training loss: 1.2488012313842773
Validation loss: 2.1044028798739114

Epoch: 5| Step: 11
Training loss: 1.6576015949249268
Validation loss: 2.11033803721269

Testing loss: 1.8897953265004879
