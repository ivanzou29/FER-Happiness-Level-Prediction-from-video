Epoch: 1| Step: 0
Training loss: 5.463204498602875
Validation loss: 5.963179480425047

Epoch: 5| Step: 1
Training loss: 6.680324805123859
Validation loss: 5.961700270659999

Epoch: 5| Step: 2
Training loss: 5.381944650082601
Validation loss: 5.960195699376125

Epoch: 5| Step: 3
Training loss: 5.993487002079156
Validation loss: 5.9587050857702435

Epoch: 5| Step: 4
Training loss: 5.967904715076508
Validation loss: 5.957190299490462

Epoch: 5| Step: 5
Training loss: 7.00431854004722
Validation loss: 5.955572217689443

Epoch: 5| Step: 6
Training loss: 6.803094653375989
Validation loss: 5.953940668570966

Epoch: 5| Step: 7
Training loss: 5.023110956046842
Validation loss: 5.952276127618844

Epoch: 5| Step: 8
Training loss: 5.588217956705037
Validation loss: 5.950532877859089

Epoch: 5| Step: 9
Training loss: 6.302118810968923
Validation loss: 5.948793505847348

Epoch: 5| Step: 10
Training loss: 6.223852470061593
Validation loss: 5.947015292072579

Epoch: 5| Step: 11
Training loss: 6.193477941056031
Validation loss: 5.945216709055358

Epoch: 2| Step: 0
Training loss: 6.319709211492429
Validation loss: 5.943188816430909

Epoch: 5| Step: 1
Training loss: 6.05741023709948
Validation loss: 5.9412294955508065

Epoch: 5| Step: 2
Training loss: 5.7623870772346475
Validation loss: 5.9391084868120885

Epoch: 5| Step: 3
Training loss: 6.095960010908032
Validation loss: 5.936918156541243

Epoch: 5| Step: 4
Training loss: 5.390477805961407
Validation loss: 5.934561300006698

Epoch: 5| Step: 5
Training loss: 6.4484692790212215
Validation loss: 5.932147059186632

Epoch: 5| Step: 6
Training loss: 6.324162050008335
Validation loss: 5.929574006225435

Epoch: 5| Step: 7
Training loss: 6.658093980569932
Validation loss: 5.92687758863538

Epoch: 5| Step: 8
Training loss: 5.4467979824029085
Validation loss: 5.924068524448365

Epoch: 5| Step: 9
Training loss: 5.536294996328949
Validation loss: 5.921148975324661

Epoch: 5| Step: 10
Training loss: 6.347758412639408
Validation loss: 5.918067352178519

Epoch: 5| Step: 11
Training loss: 5.9535552742922215
Validation loss: 5.914685813210378

Epoch: 3| Step: 0
Training loss: 5.694934052712647
Validation loss: 5.911301230697104

Epoch: 5| Step: 1
Training loss: 6.347607872411803
Validation loss: 5.907565500200582

Epoch: 5| Step: 2
Training loss: 6.305858782154002
Validation loss: 5.903864249177247

Epoch: 5| Step: 3
Training loss: 5.985764464185266
Validation loss: 5.899666233374315

Epoch: 5| Step: 4
Training loss: 6.456211192632037
Validation loss: 5.895567583580767

Epoch: 5| Step: 5
Training loss: 6.2434807918885795
Validation loss: 5.890869364910455

Epoch: 5| Step: 6
Training loss: 6.6398422677482465
Validation loss: 5.886274834466599

Epoch: 5| Step: 7
Training loss: 6.346600272742301
Validation loss: 5.881142611034966

Epoch: 5| Step: 8
Training loss: 5.1729921361810725
Validation loss: 5.87601715102613

Epoch: 5| Step: 9
Training loss: 4.536846624575475
Validation loss: 5.870426277937791

Epoch: 5| Step: 10
Training loss: 5.707510153268078
Validation loss: 5.864946793382352

Epoch: 5| Step: 11
Training loss: 7.314029109872913
Validation loss: 5.858818427884654

Epoch: 4| Step: 0
Training loss: 6.812595471754328
Validation loss: 5.852769843421357

Epoch: 5| Step: 1
Training loss: 5.627428166504219
Validation loss: 5.846434243608897

Epoch: 5| Step: 2
Training loss: 5.618882816090059
Validation loss: 5.839606742344713

Epoch: 5| Step: 3
Training loss: 6.921954083475289
Validation loss: 5.832693503121695

Epoch: 5| Step: 4
Training loss: 6.0973578312226895
Validation loss: 5.825217918827502

Epoch: 5| Step: 5
Training loss: 4.939162348721821
Validation loss: 5.817638737174875

Epoch: 5| Step: 6
Training loss: 4.9283011976442905
Validation loss: 5.80945728333334

Epoch: 5| Step: 7
Training loss: 6.366805850333418
Validation loss: 5.801766681990762

Epoch: 5| Step: 8
Training loss: 6.359454780096927
Validation loss: 5.79370519956121

Epoch: 5| Step: 9
Training loss: 5.88806744410408
Validation loss: 5.785133851167022

Epoch: 5| Step: 10
Training loss: 5.44049112767654
Validation loss: 5.776448663441661

Epoch: 5| Step: 11
Training loss: 5.229859365756951
Validation loss: 5.76704999066801

Epoch: 5| Step: 0
Training loss: 5.980292060379778
Validation loss: 5.7573836713405475

Epoch: 5| Step: 1
Training loss: 6.63080472179244
Validation loss: 5.747994909506349

Epoch: 5| Step: 2
Training loss: 6.471144375896075
Validation loss: 5.738068814085845

Epoch: 5| Step: 3
Training loss: 6.093303018462539
Validation loss: 5.727638417645369

Epoch: 5| Step: 4
Training loss: 4.557670650164522
Validation loss: 5.7169991542043075

Epoch: 5| Step: 5
Training loss: 5.653832356242976
Validation loss: 5.706057619303775

Epoch: 5| Step: 6
Training loss: 6.100999481366218
Validation loss: 5.695432148022419

Epoch: 5| Step: 7
Training loss: 5.073871039736905
Validation loss: 5.684576666611667

Epoch: 5| Step: 8
Training loss: 5.8704494952781365
Validation loss: 5.673181675793885

Epoch: 5| Step: 9
Training loss: 6.153890554561361
Validation loss: 5.661621950014309

Epoch: 5| Step: 10
Training loss: 5.119635961525002
Validation loss: 5.650119852803452

Epoch: 5| Step: 11
Training loss: 5.807232510617519
Validation loss: 5.638280210335887

Epoch: 6| Step: 0
Training loss: 6.032581241723006
Validation loss: 5.627031997715782

Epoch: 5| Step: 1
Training loss: 6.136125075715473
Validation loss: 5.615338052428288

Epoch: 5| Step: 2
Training loss: 6.453961999290145
Validation loss: 5.60378557868831

Epoch: 5| Step: 3
Training loss: 4.858892189891465
Validation loss: 5.592351308809015

Epoch: 5| Step: 4
Training loss: 5.766727166418927
Validation loss: 5.580774598701405

Epoch: 5| Step: 5
Training loss: 6.3415806260289544
Validation loss: 5.569778516658881

Epoch: 5| Step: 6
Training loss: 4.787909961806735
Validation loss: 5.558303493017407

Epoch: 5| Step: 7
Training loss: 5.315298801754113
Validation loss: 5.547159615678439

Epoch: 5| Step: 8
Training loss: 5.252528898512783
Validation loss: 5.535631861563832

Epoch: 5| Step: 9
Training loss: 5.469008957317562
Validation loss: 5.5252060349771535

Epoch: 5| Step: 10
Training loss: 5.893855577577036
Validation loss: 5.514025433715637

Epoch: 5| Step: 11
Training loss: 5.646178325327361
Validation loss: 5.503370422748159

Epoch: 7| Step: 0
Training loss: 5.0933485750566145
Validation loss: 5.492895074432644

Epoch: 5| Step: 1
Training loss: 5.371876363437872
Validation loss: 5.482859787112423

Epoch: 5| Step: 2
Training loss: 6.541858289629316
Validation loss: 5.4722983265709155

Epoch: 5| Step: 3
Training loss: 5.673828461166083
Validation loss: 5.462378555973054

Epoch: 5| Step: 4
Training loss: 5.929096257785163
Validation loss: 5.453082662889876

Epoch: 5| Step: 5
Training loss: 5.332070956239522
Validation loss: 5.443492335262995

Epoch: 5| Step: 6
Training loss: 5.563581211578308
Validation loss: 5.434283602389981

Epoch: 5| Step: 7
Training loss: 5.174283760373152
Validation loss: 5.425793260744595

Epoch: 5| Step: 8
Training loss: 5.105535622051531
Validation loss: 5.417994192256657

Epoch: 5| Step: 9
Training loss: 6.191902212982431
Validation loss: 5.409905669541061

Epoch: 5| Step: 10
Training loss: 5.366582800326367
Validation loss: 5.402499983912722

Epoch: 5| Step: 11
Training loss: 3.807952419961472
Validation loss: 5.395714146047654

Epoch: 8| Step: 0
Training loss: 5.6430844680221135
Validation loss: 5.38934852856374

Epoch: 5| Step: 1
Training loss: 5.373149819533632
Validation loss: 5.383599395889232

Epoch: 5| Step: 2
Training loss: 5.820497978378533
Validation loss: 5.377345645284773

Epoch: 5| Step: 3
Training loss: 5.787221762640557
Validation loss: 5.3713414138568085

Epoch: 5| Step: 4
Training loss: 4.5254178101929465
Validation loss: 5.365600684526877

Epoch: 5| Step: 5
Training loss: 5.4657893422775885
Validation loss: 5.360148975475056

Epoch: 5| Step: 6
Training loss: 6.183009512237383
Validation loss: 5.354169885161901

Epoch: 5| Step: 7
Training loss: 4.8815900813579285
Validation loss: 5.348887058316823

Epoch: 5| Step: 8
Training loss: 5.879778927130984
Validation loss: 5.342817370137015

Epoch: 5| Step: 9
Training loss: 5.631409955901867
Validation loss: 5.338034996241962

Epoch: 5| Step: 10
Training loss: 5.244988001836067
Validation loss: 5.33271531408517

Epoch: 5| Step: 11
Training loss: 3.558829441074919
Validation loss: 5.326950368861631

Epoch: 9| Step: 0
Training loss: 6.214117270255392
Validation loss: 5.322052740569939

Epoch: 5| Step: 1
Training loss: 5.157149912591961
Validation loss: 5.316366920073455

Epoch: 5| Step: 2
Training loss: 4.880827135435241
Validation loss: 5.3110850450686575

Epoch: 5| Step: 3
Training loss: 5.462277140315858
Validation loss: 5.3057513736230035

Epoch: 5| Step: 4
Training loss: 6.211583901602745
Validation loss: 5.300294902982143

Epoch: 5| Step: 5
Training loss: 5.519214704741178
Validation loss: 5.294695905767198

Epoch: 5| Step: 6
Training loss: 4.9939328576746895
Validation loss: 5.288843688495656

Epoch: 5| Step: 7
Training loss: 5.2763276946803055
Validation loss: 5.283670920147306

Epoch: 5| Step: 8
Training loss: 5.121966138567668
Validation loss: 5.278677635555011

Epoch: 5| Step: 9
Training loss: 5.7341098983978585
Validation loss: 5.274311202398306

Epoch: 5| Step: 10
Training loss: 5.248488980784936
Validation loss: 5.269715928257755

Epoch: 5| Step: 11
Training loss: 2.849627279705145
Validation loss: 5.264988205133639

Epoch: 10| Step: 0
Training loss: 5.707777826980301
Validation loss: 5.2606557458111505

Epoch: 5| Step: 1
Training loss: 5.863259779899065
Validation loss: 5.25565286601822

Epoch: 5| Step: 2
Training loss: 5.397372150329305
Validation loss: 5.250921675598762

Epoch: 5| Step: 3
Training loss: 5.523980315000029
Validation loss: 5.246104187622443

Epoch: 5| Step: 4
Training loss: 5.104609982707937
Validation loss: 5.2412307101088125

Epoch: 5| Step: 5
Training loss: 5.903795812244507
Validation loss: 5.236317311225604

Epoch: 5| Step: 6
Training loss: 5.478560362172509
Validation loss: 5.231445456818083

Epoch: 5| Step: 7
Training loss: 4.524991257801357
Validation loss: 5.226397258463378

Epoch: 5| Step: 8
Training loss: 5.516348729186903
Validation loss: 5.221614378979757

Epoch: 5| Step: 9
Training loss: 5.261022350328337
Validation loss: 5.21669247512202

Epoch: 5| Step: 10
Training loss: 4.631237463477254
Validation loss: 5.211933450684829

Epoch: 5| Step: 11
Training loss: 4.6730935029124865
Validation loss: 5.206903240960787

Epoch: 11| Step: 0
Training loss: 5.361157890910732
Validation loss: 5.202210751725955

Epoch: 5| Step: 1
Training loss: 5.903508271537305
Validation loss: 5.19740193735507

Epoch: 5| Step: 2
Training loss: 4.9788180858372755
Validation loss: 5.1927038541549395

Epoch: 5| Step: 3
Training loss: 4.955753050395953
Validation loss: 5.187556369888865

Epoch: 5| Step: 4
Training loss: 5.131943999367733
Validation loss: 5.182991228538184

Epoch: 5| Step: 5
Training loss: 5.4340188294141685
Validation loss: 5.177920539240367

Epoch: 5| Step: 6
Training loss: 4.5695211654658765
Validation loss: 5.1732004086550845

Epoch: 5| Step: 7
Training loss: 4.496526437151237
Validation loss: 5.168197576791556

Epoch: 5| Step: 8
Training loss: 5.079142588849638
Validation loss: 5.163661770029528

Epoch: 5| Step: 9
Training loss: 5.799720415414234
Validation loss: 5.1585442650375315

Epoch: 5| Step: 10
Training loss: 6.333883796996707
Validation loss: 5.154089719814219

Epoch: 5| Step: 11
Training loss: 5.2251505633841955
Validation loss: 5.148597919316979

Epoch: 12| Step: 0
Training loss: 4.874576256749024
Validation loss: 5.143880599732878

Epoch: 5| Step: 1
Training loss: 5.300736991455801
Validation loss: 5.139038080621564

Epoch: 5| Step: 2
Training loss: 5.394144252897704
Validation loss: 5.134359520462981

Epoch: 5| Step: 3
Training loss: 4.8689126375626
Validation loss: 5.130010830196675

Epoch: 5| Step: 4
Training loss: 4.969142490455884
Validation loss: 5.1251317914439225

Epoch: 5| Step: 5
Training loss: 4.729643922270442
Validation loss: 5.120250043661747

Epoch: 5| Step: 6
Training loss: 5.333894263015832
Validation loss: 5.115767606636236

Epoch: 5| Step: 7
Training loss: 5.687740781948199
Validation loss: 5.111103990222744

Epoch: 5| Step: 8
Training loss: 5.239614295741591
Validation loss: 5.105917924707693

Epoch: 5| Step: 9
Training loss: 6.291802040647908
Validation loss: 5.101192607000607

Epoch: 5| Step: 10
Training loss: 4.983271653081759
Validation loss: 5.096269300479005

Epoch: 5| Step: 11
Training loss: 4.239300442691954
Validation loss: 5.091400111516031

Epoch: 13| Step: 0
Training loss: 4.815857545855934
Validation loss: 5.0864392026778065

Epoch: 5| Step: 1
Training loss: 5.612694398363751
Validation loss: 5.081747490371598

Epoch: 5| Step: 2
Training loss: 6.012601335270328
Validation loss: 5.07676034441852

Epoch: 5| Step: 3
Training loss: 4.902788435384365
Validation loss: 5.0716637533511495

Epoch: 5| Step: 4
Training loss: 5.258716069160315
Validation loss: 5.066929366909899

Epoch: 5| Step: 5
Training loss: 5.129081217562512
Validation loss: 5.0621889199334715

Epoch: 5| Step: 6
Training loss: 5.2515067708475645
Validation loss: 5.057281685323979

Epoch: 5| Step: 7
Training loss: 5.126324366207074
Validation loss: 5.052236482586458

Epoch: 5| Step: 8
Training loss: 5.199091083612897
Validation loss: 5.04750760958789

Epoch: 5| Step: 9
Training loss: 5.094033075435692
Validation loss: 5.042462422753045

Epoch: 5| Step: 10
Training loss: 4.69129139476131
Validation loss: 5.037452081621196

Epoch: 5| Step: 11
Training loss: 4.300334633514591
Validation loss: 5.032577971226941

Epoch: 14| Step: 0
Training loss: 5.225980398381492
Validation loss: 5.028297387221057

Epoch: 5| Step: 1
Training loss: 4.941016381606196
Validation loss: 5.022958292631078

Epoch: 5| Step: 2
Training loss: 4.793098479041001
Validation loss: 5.0184235732293905

Epoch: 5| Step: 3
Training loss: 5.940107234924496
Validation loss: 5.01360101158114

Epoch: 5| Step: 4
Training loss: 4.4006502537977275
Validation loss: 5.0083877066497395

Epoch: 5| Step: 5
Training loss: 4.808129840601948
Validation loss: 5.004060812832941

Epoch: 5| Step: 6
Training loss: 5.7724925753288385
Validation loss: 4.998960271655968

Epoch: 5| Step: 7
Training loss: 4.639894781235089
Validation loss: 4.994511691597698

Epoch: 5| Step: 8
Training loss: 5.674712172952
Validation loss: 4.989600739684302

Epoch: 5| Step: 9
Training loss: 4.934767147859042
Validation loss: 4.984250353108638

Epoch: 5| Step: 10
Training loss: 4.952748185033294
Validation loss: 4.978994512840609

Epoch: 5| Step: 11
Training loss: 5.556399997535921
Validation loss: 4.9742635530092025

Epoch: 15| Step: 0
Training loss: 4.640783442094761
Validation loss: 4.9696370178778935

Epoch: 5| Step: 1
Training loss: 4.116738571795136
Validation loss: 4.965042482445974

Epoch: 5| Step: 2
Training loss: 5.578665570905103
Validation loss: 4.959602644947195

Epoch: 5| Step: 3
Training loss: 4.159643179189031
Validation loss: 4.954540551816579

Epoch: 5| Step: 4
Training loss: 5.6284923308626
Validation loss: 4.950016373950836

Epoch: 5| Step: 5
Training loss: 5.639864799015299
Validation loss: 4.945621731909416

Epoch: 5| Step: 6
Training loss: 6.058102930332395
Validation loss: 4.940607260137949

Epoch: 5| Step: 7
Training loss: 4.613969381692969
Validation loss: 4.935349410524573

Epoch: 5| Step: 8
Training loss: 5.073451312310367
Validation loss: 4.930083922393415

Epoch: 5| Step: 9
Training loss: 4.241489865878337
Validation loss: 4.92466242741902

Epoch: 5| Step: 10
Training loss: 5.298850262290194
Validation loss: 4.920765722500998

Epoch: 5| Step: 11
Training loss: 6.185010621193576
Validation loss: 4.915005575715657

Epoch: 16| Step: 0
Training loss: 5.121866896729404
Validation loss: 4.9099744359974045

Epoch: 5| Step: 1
Training loss: 5.190883590071993
Validation loss: 4.905109831876199

Epoch: 5| Step: 2
Training loss: 4.680832253165605
Validation loss: 4.900513812782539

Epoch: 5| Step: 3
Training loss: 6.111380869758807
Validation loss: 4.895480628869999

Epoch: 5| Step: 4
Training loss: 5.2990422949023595
Validation loss: 4.890667144301304

Epoch: 5| Step: 5
Training loss: 4.869290652146176
Validation loss: 4.885321161384512

Epoch: 5| Step: 6
Training loss: 4.274548485541955
Validation loss: 4.880048012992343

Epoch: 5| Step: 7
Training loss: 4.716493382769864
Validation loss: 4.875525837439853

Epoch: 5| Step: 8
Training loss: 5.080720490552989
Validation loss: 4.870059505447675

Epoch: 5| Step: 9
Training loss: 4.851034482765353
Validation loss: 4.865202097235027

Epoch: 5| Step: 10
Training loss: 4.9512572030985575
Validation loss: 4.861215992961704

Epoch: 5| Step: 11
Training loss: 3.653042160413268
Validation loss: 4.856541444272029

Epoch: 17| Step: 0
Training loss: 5.198832806393001
Validation loss: 4.852104013458161

Epoch: 5| Step: 1
Training loss: 4.866268652922585
Validation loss: 4.846552105987853

Epoch: 5| Step: 2
Training loss: 4.485863202741035
Validation loss: 4.8414781800752476

Epoch: 5| Step: 3
Training loss: 4.2089936647954325
Validation loss: 4.837311417537015

Epoch: 5| Step: 4
Training loss: 5.3669833348518186
Validation loss: 4.832152331969967

Epoch: 5| Step: 5
Training loss: 5.174080830641961
Validation loss: 4.827616050585688

Epoch: 5| Step: 6
Training loss: 4.163068871101835
Validation loss: 4.8224281437123055

Epoch: 5| Step: 7
Training loss: 5.630047038611882
Validation loss: 4.817894847111938

Epoch: 5| Step: 8
Training loss: 4.5719769438448425
Validation loss: 4.8129332376311025

Epoch: 5| Step: 9
Training loss: 5.6378753807799
Validation loss: 4.808402864668563

Epoch: 5| Step: 10
Training loss: 4.692749745831537
Validation loss: 4.803829589999698

Epoch: 5| Step: 11
Training loss: 5.873799627516161
Validation loss: 4.798928656823379

Epoch: 18| Step: 0
Training loss: 4.443640530253249
Validation loss: 4.793239205545512

Epoch: 5| Step: 1
Training loss: 4.5459675620751465
Validation loss: 4.788709825615914

Epoch: 5| Step: 2
Training loss: 5.265352055298425
Validation loss: 4.78434212123305

Epoch: 5| Step: 3
Training loss: 4.876645519621849
Validation loss: 4.778774751038164

Epoch: 5| Step: 4
Training loss: 4.776398834329579
Validation loss: 4.774234694754579

Epoch: 5| Step: 5
Training loss: 5.350248790909988
Validation loss: 4.769624393104557

Epoch: 5| Step: 6
Training loss: 5.553421326879304
Validation loss: 4.764318877124003

Epoch: 5| Step: 7
Training loss: 5.081390551585672
Validation loss: 4.7588159163899615

Epoch: 5| Step: 8
Training loss: 4.758036390526989
Validation loss: 4.753299077759016

Epoch: 5| Step: 9
Training loss: 4.625387020929577
Validation loss: 4.7497219874353105

Epoch: 5| Step: 10
Training loss: 4.710949241408461
Validation loss: 4.744249602534942

Epoch: 5| Step: 11
Training loss: 3.3146086405122253
Validation loss: 4.739147839782428

Epoch: 19| Step: 0
Training loss: 4.806644593151552
Validation loss: 4.734337792916549

Epoch: 5| Step: 1
Training loss: 4.721609701685309
Validation loss: 4.729362797416175

Epoch: 5| Step: 2
Training loss: 4.498055143758683
Validation loss: 4.723708942844272

Epoch: 5| Step: 3
Training loss: 5.482199908670154
Validation loss: 4.71901985053697

Epoch: 5| Step: 4
Training loss: 5.305223036238288
Validation loss: 4.714443291969338

Epoch: 5| Step: 5
Training loss: 3.9924462042368942
Validation loss: 4.709461771792761

Epoch: 5| Step: 6
Training loss: 5.053592144588122
Validation loss: 4.7047182005901815

Epoch: 5| Step: 7
Training loss: 5.248449550749972
Validation loss: 4.699554866821015

Epoch: 5| Step: 8
Training loss: 4.596499911006718
Validation loss: 4.694224167470543

Epoch: 5| Step: 9
Training loss: 5.2527041056148
Validation loss: 4.689595148429522

Epoch: 5| Step: 10
Training loss: 3.955755873642906
Validation loss: 4.684848764666219

Epoch: 5| Step: 11
Training loss: 4.895487260423397
Validation loss: 4.680392713697993

Epoch: 20| Step: 0
Training loss: 5.4078477912904175
Validation loss: 4.675027555496686

Epoch: 5| Step: 1
Training loss: 4.911077954586487
Validation loss: 4.669948508137362

Epoch: 5| Step: 2
Training loss: 4.979980636313913
Validation loss: 4.664686969504816

Epoch: 5| Step: 3
Training loss: 4.180799446863312
Validation loss: 4.659552152094357

Epoch: 5| Step: 4
Training loss: 4.783967884963823
Validation loss: 4.654947179691995

Epoch: 5| Step: 5
Training loss: 5.063205246015734
Validation loss: 4.649553757964412

Epoch: 5| Step: 6
Training loss: 3.7365314210979212
Validation loss: 4.644202723111878

Epoch: 5| Step: 7
Training loss: 4.826435077302907
Validation loss: 4.639780432230592

Epoch: 5| Step: 8
Training loss: 4.394334413994525
Validation loss: 4.6346015156293765

Epoch: 5| Step: 9
Training loss: 4.889783110382008
Validation loss: 4.629126366211826

Epoch: 5| Step: 10
Training loss: 5.512239708669695
Validation loss: 4.623972692751633

Epoch: 5| Step: 11
Training loss: 1.7496982041753886
Validation loss: 4.6187380937243026

Epoch: 21| Step: 0
Training loss: 4.936146224615034
Validation loss: 4.615070948732171

Epoch: 5| Step: 1
Training loss: 4.9108771596873675
Validation loss: 4.609880503721403

Epoch: 5| Step: 2
Training loss: 4.975166831741636
Validation loss: 4.604792223014476

Epoch: 5| Step: 3
Training loss: 5.406069890368224
Validation loss: 4.600140855539981

Epoch: 5| Step: 4
Training loss: 5.014898800194904
Validation loss: 4.595396572858517

Epoch: 5| Step: 5
Training loss: 4.930641335948565
Validation loss: 4.589273373490218

Epoch: 5| Step: 6
Training loss: 4.279094292543404
Validation loss: 4.583839322105736

Epoch: 5| Step: 7
Training loss: 4.106628660628914
Validation loss: 4.579043802840913

Epoch: 5| Step: 8
Training loss: 4.6395469980425785
Validation loss: 4.574012236978686

Epoch: 5| Step: 9
Training loss: 4.18109688927556
Validation loss: 4.568188417695338

Epoch: 5| Step: 10
Training loss: 4.280486101371909
Validation loss: 4.563427134161202

Epoch: 5| Step: 11
Training loss: 5.002026719367813
Validation loss: 4.5575214945651945

Epoch: 22| Step: 0
Training loss: 4.879690408110324
Validation loss: 4.552539578523601

Epoch: 5| Step: 1
Training loss: 4.808702630329565
Validation loss: 4.5468215327489325

Epoch: 5| Step: 2
Training loss: 3.93579779267578
Validation loss: 4.541444447823392

Epoch: 5| Step: 3
Training loss: 4.292530207497134
Validation loss: 4.536583254554416

Epoch: 5| Step: 4
Training loss: 4.761158335177161
Validation loss: 4.531374111887402

Epoch: 5| Step: 5
Training loss: 3.7331451561596167
Validation loss: 4.5250629234505375

Epoch: 5| Step: 6
Training loss: 4.956269911429009
Validation loss: 4.519549687116334

Epoch: 5| Step: 7
Training loss: 4.818879889928228
Validation loss: 4.513808213841633

Epoch: 5| Step: 8
Training loss: 5.147146060108156
Validation loss: 4.507764731186571

Epoch: 5| Step: 9
Training loss: 4.656748700157751
Validation loss: 4.503351142600079

Epoch: 5| Step: 10
Training loss: 4.766194093838051
Validation loss: 4.497974187009931

Epoch: 5| Step: 11
Training loss: 5.664573993607351
Validation loss: 4.4917394973049785

Epoch: 23| Step: 0
Training loss: 4.128933504965627
Validation loss: 4.486513308095344

Epoch: 5| Step: 1
Training loss: 5.216012567984762
Validation loss: 4.482635789918243

Epoch: 5| Step: 2
Training loss: 4.980720543573862
Validation loss: 4.478291193843459

Epoch: 5| Step: 3
Training loss: 4.1341220677425685
Validation loss: 4.4731404537985595

Epoch: 5| Step: 4
Training loss: 3.9547406540052528
Validation loss: 4.46816687347261

Epoch: 5| Step: 5
Training loss: 4.884025825813364
Validation loss: 4.462361925056652

Epoch: 5| Step: 6
Training loss: 4.117887433833593
Validation loss: 4.457001953741953

Epoch: 5| Step: 7
Training loss: 4.52029990053712
Validation loss: 4.451096216473539

Epoch: 5| Step: 8
Training loss: 4.998824172045596
Validation loss: 4.444354731263594

Epoch: 5| Step: 9
Training loss: 4.323808300797562
Validation loss: 4.437965243311885

Epoch: 5| Step: 10
Training loss: 4.894345754166549
Validation loss: 4.431499422350437

Epoch: 5| Step: 11
Training loss: 5.147798582498317
Validation loss: 4.424362884604049

Epoch: 24| Step: 0
Training loss: 4.579503603691735
Validation loss: 4.418306539603694

Epoch: 5| Step: 1
Training loss: 4.52521191517008
Validation loss: 4.412171657078195

Epoch: 5| Step: 2
Training loss: 4.736544574628881
Validation loss: 4.406416075983321

Epoch: 5| Step: 3
Training loss: 4.772857680747858
Validation loss: 4.402530100956204

Epoch: 5| Step: 4
Training loss: 4.898653989932942
Validation loss: 4.395768425750024

Epoch: 5| Step: 5
Training loss: 4.2294199199047045
Validation loss: 4.389051922588158

Epoch: 5| Step: 6
Training loss: 4.717497804739259
Validation loss: 4.382304633051637

Epoch: 5| Step: 7
Training loss: 3.9591517890570884
Validation loss: 4.376836990524776

Epoch: 5| Step: 8
Training loss: 4.514847738036827
Validation loss: 4.371793039320297

Epoch: 5| Step: 9
Training loss: 4.462433305343473
Validation loss: 4.365998599341846

Epoch: 5| Step: 10
Training loss: 4.312296102375224
Validation loss: 4.361006159272102

Epoch: 5| Step: 11
Training loss: 4.113907667608428
Validation loss: 4.355482544470869

Epoch: 25| Step: 0
Training loss: 3.440361635139828
Validation loss: 4.349715095814527

Epoch: 5| Step: 1
Training loss: 4.458115949708455
Validation loss: 4.343784652315598

Epoch: 5| Step: 2
Training loss: 4.470066330180775
Validation loss: 4.338402390581955

Epoch: 5| Step: 3
Training loss: 4.440454922988827
Validation loss: 4.332154896252594

Epoch: 5| Step: 4
Training loss: 4.40060409387066
Validation loss: 4.326157913587329

Epoch: 5| Step: 5
Training loss: 4.659313039284533
Validation loss: 4.3205438957767175

Epoch: 5| Step: 6
Training loss: 4.457931975840446
Validation loss: 4.3142407446908235

Epoch: 5| Step: 7
Training loss: 4.893439412400742
Validation loss: 4.308417553266038

Epoch: 5| Step: 8
Training loss: 3.6223454457043625
Validation loss: 4.3045758407705295

Epoch: 5| Step: 9
Training loss: 5.181786021447654
Validation loss: 4.29773862540551

Epoch: 5| Step: 10
Training loss: 4.624452300762897
Validation loss: 4.2907499596610705

Epoch: 5| Step: 11
Training loss: 4.527204509762925
Validation loss: 4.285564986156395

Epoch: 26| Step: 0
Training loss: 4.503919378097736
Validation loss: 4.278955633735049

Epoch: 5| Step: 1
Training loss: 4.680779280379588
Validation loss: 4.273341352739908

Epoch: 5| Step: 2
Training loss: 4.902279553240026
Validation loss: 4.268052762171983

Epoch: 5| Step: 3
Training loss: 4.338417567401246
Validation loss: 4.260974127837374

Epoch: 5| Step: 4
Training loss: 3.624904631313851
Validation loss: 4.25440331092599

Epoch: 5| Step: 5
Training loss: 4.021956265568838
Validation loss: 4.248002765762677

Epoch: 5| Step: 6
Training loss: 4.232463785412016
Validation loss: 4.241697256144084

Epoch: 5| Step: 7
Training loss: 4.436639621765876
Validation loss: 4.235196628599731

Epoch: 5| Step: 8
Training loss: 4.8817072967960495
Validation loss: 4.228583848504197

Epoch: 5| Step: 9
Training loss: 4.0059850739054825
Validation loss: 4.224045437041315

Epoch: 5| Step: 10
Training loss: 4.024761567250633
Validation loss: 4.215714730867076

Epoch: 5| Step: 11
Training loss: 5.812339862545408
Validation loss: 4.2101397162621454

Epoch: 27| Step: 0
Training loss: 4.034265144678565
Validation loss: 4.203557069071524

Epoch: 5| Step: 1
Training loss: 4.64909232520093
Validation loss: 4.1976051009854505

Epoch: 5| Step: 2
Training loss: 4.129021966877157
Validation loss: 4.192257873156811

Epoch: 5| Step: 3
Training loss: 3.2490381137893656
Validation loss: 4.185461449593184

Epoch: 5| Step: 4
Training loss: 4.068147929424837
Validation loss: 4.179659653805581

Epoch: 5| Step: 5
Training loss: 4.455429177039102
Validation loss: 4.173647462358955

Epoch: 5| Step: 6
Training loss: 4.574763290868771
Validation loss: 4.167182583657602

Epoch: 5| Step: 7
Training loss: 4.613054675320899
Validation loss: 4.160850827494651

Epoch: 5| Step: 8
Training loss: 4.750138732490376
Validation loss: 4.154947808278735

Epoch: 5| Step: 9
Training loss: 3.5581053012320702
Validation loss: 4.148859547364753

Epoch: 5| Step: 10
Training loss: 4.8429576594888335
Validation loss: 4.143657615019174

Epoch: 5| Step: 11
Training loss: 4.8085977165397935
Validation loss: 4.136238404057237

Epoch: 28| Step: 0
Training loss: 4.312789464993666
Validation loss: 4.13040957575933

Epoch: 5| Step: 1
Training loss: 3.4367368371153253
Validation loss: 4.123862793732642

Epoch: 5| Step: 2
Training loss: 4.275214849059078
Validation loss: 4.118438260480965

Epoch: 5| Step: 3
Training loss: 4.469545093575616
Validation loss: 4.112462284954865

Epoch: 5| Step: 4
Training loss: 3.9329849272050446
Validation loss: 4.106885080758135

Epoch: 5| Step: 5
Training loss: 4.950071145519337
Validation loss: 4.100281956909752

Epoch: 5| Step: 6
Training loss: 4.080557963421997
Validation loss: 4.094899921187963

Epoch: 5| Step: 7
Training loss: 4.880867972181304
Validation loss: 4.088426078895704

Epoch: 5| Step: 8
Training loss: 3.671457339943287
Validation loss: 4.082447932390781

Epoch: 5| Step: 9
Training loss: 3.808147384700476
Validation loss: 4.076382806886421

Epoch: 5| Step: 10
Training loss: 4.507031986357519
Validation loss: 4.070758792672394

Epoch: 5| Step: 11
Training loss: 3.937710347687803
Validation loss: 4.064037403780605

Epoch: 29| Step: 0
Training loss: 4.127231110121232
Validation loss: 4.058763502314095

Epoch: 5| Step: 1
Training loss: 3.7896275049913433
Validation loss: 4.051980175022533

Epoch: 5| Step: 2
Training loss: 3.9990059094167147
Validation loss: 4.045223385097083

Epoch: 5| Step: 3
Training loss: 4.8106543234295325
Validation loss: 4.040445102188889

Epoch: 5| Step: 4
Training loss: 4.208922518034441
Validation loss: 4.034876746966385

Epoch: 5| Step: 5
Training loss: 3.279157716253362
Validation loss: 4.028539465905788

Epoch: 5| Step: 6
Training loss: 4.507050395256399
Validation loss: 4.0232082758422365

Epoch: 5| Step: 7
Training loss: 4.86591607842003
Validation loss: 4.0166863005040865

Epoch: 5| Step: 8
Training loss: 4.254474080056896
Validation loss: 4.010956500822881

Epoch: 5| Step: 9
Training loss: 3.9625792101334745
Validation loss: 4.00475198388943

Epoch: 5| Step: 10
Training loss: 3.718843346714452
Validation loss: 3.998759211380256

Epoch: 5| Step: 11
Training loss: 4.044297741638523
Validation loss: 3.9931047782996925

Epoch: 30| Step: 0
Training loss: 4.104238106094547
Validation loss: 3.987487469875695

Epoch: 5| Step: 1
Training loss: 4.288045571540535
Validation loss: 3.981371881005714

Epoch: 5| Step: 2
Training loss: 4.180090426694355
Validation loss: 3.9757087005774236

Epoch: 5| Step: 3
Training loss: 3.3808685426020273
Validation loss: 3.969323885218206

Epoch: 5| Step: 4
Training loss: 3.735975744417838
Validation loss: 3.9640394575777265

Epoch: 5| Step: 5
Training loss: 4.644735551580543
Validation loss: 3.9596005502721425

Epoch: 5| Step: 6
Training loss: 4.429838201526013
Validation loss: 3.9531684089056487

Epoch: 5| Step: 7
Training loss: 3.007316568287172
Validation loss: 3.946703705200386

Epoch: 5| Step: 8
Training loss: 3.863351973608522
Validation loss: 3.9414604594116724

Epoch: 5| Step: 9
Training loss: 4.584231733646169
Validation loss: 3.9363473183909496

Epoch: 5| Step: 10
Training loss: 4.630195998127844
Validation loss: 3.931283170542949

Epoch: 5| Step: 11
Training loss: 2.956169053112669
Validation loss: 3.9255231832576785

Epoch: 31| Step: 0
Training loss: 4.247850210964945
Validation loss: 3.9194864748143012

Epoch: 5| Step: 1
Training loss: 4.561983680251054
Validation loss: 3.913931559531702

Epoch: 5| Step: 2
Training loss: 4.483859893243357
Validation loss: 3.9090855339579895

Epoch: 5| Step: 3
Training loss: 4.1378304894059665
Validation loss: 3.903221451703009

Epoch: 5| Step: 4
Training loss: 3.858794133879595
Validation loss: 3.898977539126625

Epoch: 5| Step: 5
Training loss: 3.7922888165029622
Validation loss: 3.892722908539197

Epoch: 5| Step: 6
Training loss: 3.480133759788975
Validation loss: 3.8864947128263205

Epoch: 5| Step: 7
Training loss: 3.7147334871665114
Validation loss: 3.8811718284282226

Epoch: 5| Step: 8
Training loss: 3.9888015392754954
Validation loss: 3.875955955967678

Epoch: 5| Step: 9
Training loss: 3.371520049722189
Validation loss: 3.8710842498139213

Epoch: 5| Step: 10
Training loss: 4.42935163243889
Validation loss: 3.8663395937892417

Epoch: 5| Step: 11
Training loss: 4.157708163208447
Validation loss: 3.861212469313528

Epoch: 32| Step: 0
Training loss: 4.2189568362924765
Validation loss: 3.8554833723342994

Epoch: 5| Step: 1
Training loss: 4.3534391729351505
Validation loss: 3.850343249447717

Epoch: 5| Step: 2
Training loss: 3.6620393222466445
Validation loss: 3.8442776428969974

Epoch: 5| Step: 3
Training loss: 4.024894494989997
Validation loss: 3.8390504128091556

Epoch: 5| Step: 4
Training loss: 3.2377961719205426
Validation loss: 3.833643541361892

Epoch: 5| Step: 5
Training loss: 4.097143732098571
Validation loss: 3.8289807459567236

Epoch: 5| Step: 6
Training loss: 3.7906665670784228
Validation loss: 3.824567613285045

Epoch: 5| Step: 7
Training loss: 3.6038133451707863
Validation loss: 3.8188531008432305

Epoch: 5| Step: 8
Training loss: 3.3309746662460302
Validation loss: 3.8133244170293628

Epoch: 5| Step: 9
Training loss: 4.334600899000193
Validation loss: 3.8077081155955192

Epoch: 5| Step: 10
Training loss: 4.539370501732806
Validation loss: 3.803297192226031

Epoch: 5| Step: 11
Training loss: 4.72317883145724
Validation loss: 3.7987056238449255

Epoch: 33| Step: 0
Training loss: 4.483772051214354
Validation loss: 3.793395563502354

Epoch: 5| Step: 1
Training loss: 4.366509400270583
Validation loss: 3.7874657009321693

Epoch: 5| Step: 2
Training loss: 4.483454486859679
Validation loss: 3.7818719651867743

Epoch: 5| Step: 3
Training loss: 3.9489766545710507
Validation loss: 3.776125133074243

Epoch: 5| Step: 4
Training loss: 3.1343737586067455
Validation loss: 3.770866544939054

Epoch: 5| Step: 5
Training loss: 4.000084399286597
Validation loss: 3.766324043022987

Epoch: 5| Step: 6
Training loss: 4.247916440167062
Validation loss: 3.760972056846199

Epoch: 5| Step: 7
Training loss: 3.2761574599882586
Validation loss: 3.754799087311915

Epoch: 5| Step: 8
Training loss: 3.586896115825985
Validation loss: 3.749244380692946

Epoch: 5| Step: 9
Training loss: 3.648240666113701
Validation loss: 3.7444871540790725

Epoch: 5| Step: 10
Training loss: 3.307383634635213
Validation loss: 3.7399548989736786

Epoch: 5| Step: 11
Training loss: 4.493438175083839
Validation loss: 3.7346371355188688

Epoch: 34| Step: 0
Training loss: 3.7226197440087656
Validation loss: 3.729582809515257

Epoch: 5| Step: 1
Training loss: 3.6603654701909494
Validation loss: 3.725338642250607

Epoch: 5| Step: 2
Training loss: 4.336595090196727
Validation loss: 3.71972797794704

Epoch: 5| Step: 3
Training loss: 3.7857860753740553
Validation loss: 3.7143870065225335

Epoch: 5| Step: 4
Training loss: 3.8534549915243725
Validation loss: 3.709381162643134

Epoch: 5| Step: 5
Training loss: 4.034918956297229
Validation loss: 3.70442387782418

Epoch: 5| Step: 6
Training loss: 3.185665126081558
Validation loss: 3.6982934231529367

Epoch: 5| Step: 7
Training loss: 3.9069553806480197
Validation loss: 3.6943680226318127

Epoch: 5| Step: 8
Training loss: 4.340163911809331
Validation loss: 3.689164394903306

Epoch: 5| Step: 9
Training loss: 3.7738297221104684
Validation loss: 3.6839805985111407

Epoch: 5| Step: 10
Training loss: 3.6634172143840655
Validation loss: 3.679108214355046

Epoch: 5| Step: 11
Training loss: 2.939138726437912
Validation loss: 3.673795362938576

Epoch: 35| Step: 0
Training loss: 3.7845603387180207
Validation loss: 3.6694401453111563

Epoch: 5| Step: 1
Training loss: 3.913669711141981
Validation loss: 3.664582688008234

Epoch: 5| Step: 2
Training loss: 4.368963163793775
Validation loss: 3.6595149989919826

Epoch: 5| Step: 3
Training loss: 3.8887315915100267
Validation loss: 3.654508246475096

Epoch: 5| Step: 4
Training loss: 3.930778822082505
Validation loss: 3.6491749553901345

Epoch: 5| Step: 5
Training loss: 3.59793908149586
Validation loss: 3.644534510004208

Epoch: 5| Step: 6
Training loss: 3.9382290846342447
Validation loss: 3.6393292949622897

Epoch: 5| Step: 7
Training loss: 2.901516248327181
Validation loss: 3.6346512219113

Epoch: 5| Step: 8
Training loss: 3.8838937892515193
Validation loss: 3.629428925803088

Epoch: 5| Step: 9
Training loss: 3.6490059844679097
Validation loss: 3.624708827152474

Epoch: 5| Step: 10
Training loss: 3.8066918578597613
Validation loss: 3.6192996653544154

Epoch: 5| Step: 11
Training loss: 2.4160375324264445
Validation loss: 3.615011550793412

Epoch: 36| Step: 0
Training loss: 3.361162570597972
Validation loss: 3.610599574309385

Epoch: 5| Step: 1
Training loss: 3.700585504548848
Validation loss: 3.606279788233072

Epoch: 5| Step: 2
Training loss: 4.239614250701469
Validation loss: 3.6018095283442424

Epoch: 5| Step: 3
Training loss: 3.4162960471753325
Validation loss: 3.597088244646292

Epoch: 5| Step: 4
Training loss: 3.748630909543361
Validation loss: 3.5926197430770723

Epoch: 5| Step: 5
Training loss: 3.701199574228475
Validation loss: 3.5878157783499747

Epoch: 5| Step: 6
Training loss: 2.975888794277394
Validation loss: 3.5833719282881074

Epoch: 5| Step: 7
Training loss: 3.443835575542844
Validation loss: 3.5788793254584244

Epoch: 5| Step: 8
Training loss: 4.043539550587822
Validation loss: 3.574746423344564

Epoch: 5| Step: 9
Training loss: 4.162941500873783
Validation loss: 3.569809909562819

Epoch: 5| Step: 10
Training loss: 3.9466497289019205
Validation loss: 3.565262972311372

Epoch: 5| Step: 11
Training loss: 3.8615696647709083
Validation loss: 3.560551908248494

Epoch: 37| Step: 0
Training loss: 4.3408847937069615
Validation loss: 3.555852331666963

Epoch: 5| Step: 1
Training loss: 3.4671470443751495
Validation loss: 3.5512737887985644

Epoch: 5| Step: 2
Training loss: 4.125450803225507
Validation loss: 3.546557732955154

Epoch: 5| Step: 3
Training loss: 3.7577116193335947
Validation loss: 3.5417884450433292

Epoch: 5| Step: 4
Training loss: 3.178103040471163
Validation loss: 3.5369242369213194

Epoch: 5| Step: 5
Training loss: 3.083540436946099
Validation loss: 3.5318809215716755

Epoch: 5| Step: 6
Training loss: 3.8954212698380695
Validation loss: 3.527416815692764

Epoch: 5| Step: 7
Training loss: 3.6636248166508776
Validation loss: 3.5226871737568612

Epoch: 5| Step: 8
Training loss: 2.987242434583453
Validation loss: 3.5182270226047323

Epoch: 5| Step: 9
Training loss: 3.9288312157281187
Validation loss: 3.5132549746085515

Epoch: 5| Step: 10
Training loss: 3.5541837565885848
Validation loss: 3.5088340104513036

Epoch: 5| Step: 11
Training loss: 4.360631399370035
Validation loss: 3.5045678156704687

Epoch: 38| Step: 0
Training loss: 3.3462241458000905
Validation loss: 3.4995760320281546

Epoch: 5| Step: 1
Training loss: 3.5352835785080594
Validation loss: 3.4956340636762144

Epoch: 5| Step: 2
Training loss: 3.9693858921320233
Validation loss: 3.4907084582263233

Epoch: 5| Step: 3
Training loss: 3.5619953534258224
Validation loss: 3.4859996680109813

Epoch: 5| Step: 4
Training loss: 3.4372804051396693
Validation loss: 3.481508601301347

Epoch: 5| Step: 5
Training loss: 3.8688715803180487
Validation loss: 3.476516694756549

Epoch: 5| Step: 6
Training loss: 3.3742327347801475
Validation loss: 3.471753237947152

Epoch: 5| Step: 7
Training loss: 3.568002567085061
Validation loss: 3.4673474600843437

Epoch: 5| Step: 8
Training loss: 3.669108025986679
Validation loss: 3.4628132199900388

Epoch: 5| Step: 9
Training loss: 3.32346573043333
Validation loss: 3.4587815848322525

Epoch: 5| Step: 10
Training loss: 3.954911020775433
Validation loss: 3.4541682742996676

Epoch: 5| Step: 11
Training loss: 4.020013333578439
Validation loss: 3.449888412771838

Epoch: 39| Step: 0
Training loss: 3.6364246417476966
Validation loss: 3.4452405995588866

Epoch: 5| Step: 1
Training loss: 3.624913707889946
Validation loss: 3.440842991205065

Epoch: 5| Step: 2
Training loss: 3.10413905052514
Validation loss: 3.4361989767061627

Epoch: 5| Step: 3
Training loss: 3.9432724314415424
Validation loss: 3.431344728951449

Epoch: 5| Step: 4
Training loss: 3.5550548992397975
Validation loss: 3.426903947040851

Epoch: 5| Step: 5
Training loss: 3.964808391544923
Validation loss: 3.422570226174997

Epoch: 5| Step: 6
Training loss: 3.161726779423258
Validation loss: 3.4182751676265837

Epoch: 5| Step: 7
Training loss: 3.3004712201848623
Validation loss: 3.413629954017705

Epoch: 5| Step: 8
Training loss: 3.474328855841824
Validation loss: 3.4091918560456707

Epoch: 5| Step: 9
Training loss: 3.9259293106019193
Validation loss: 3.4049564378484685

Epoch: 5| Step: 10
Training loss: 3.1928438756319037
Validation loss: 3.4004996638496756

Epoch: 5| Step: 11
Training loss: 4.289665916256848
Validation loss: 3.396337750578547

Epoch: 40| Step: 0
Training loss: 3.530454833038514
Validation loss: 3.3919609883298514

Epoch: 5| Step: 1
Training loss: 3.6365072514611048
Validation loss: 3.3876494610460957

Epoch: 5| Step: 2
Training loss: 3.671991744113193
Validation loss: 3.383370365956463

Epoch: 5| Step: 3
Training loss: 3.668375628474668
Validation loss: 3.3790329514344006

Epoch: 5| Step: 4
Training loss: 3.2038549568406895
Validation loss: 3.374527951183421

Epoch: 5| Step: 5
Training loss: 2.875418259423484
Validation loss: 3.370042957603755

Epoch: 5| Step: 6
Training loss: 3.7948114258325663
Validation loss: 3.3658789786517653

Epoch: 5| Step: 7
Training loss: 4.116092891063832
Validation loss: 3.361707117413841

Epoch: 5| Step: 8
Training loss: 3.435230407539043
Validation loss: 3.357535729614628

Epoch: 5| Step: 9
Training loss: 3.521471511216452
Validation loss: 3.3534486675446797

Epoch: 5| Step: 10
Training loss: 3.0169170556733884
Validation loss: 3.3498518400973705

Epoch: 5| Step: 11
Training loss: 3.363114373899757
Validation loss: 3.3453164397728288

Epoch: 41| Step: 0
Training loss: 3.268534263362391
Validation loss: 3.3415941436647767

Epoch: 5| Step: 1
Training loss: 3.472019476163532
Validation loss: 3.3375308708068094

Epoch: 5| Step: 2
Training loss: 3.150854957450537
Validation loss: 3.3330769658843353

Epoch: 5| Step: 3
Training loss: 4.013352756854567
Validation loss: 3.3293058064730454

Epoch: 5| Step: 4
Training loss: 3.5723980378001716
Validation loss: 3.3255496231700916

Epoch: 5| Step: 5
Training loss: 3.8043518544999113
Validation loss: 3.321088462364135

Epoch: 5| Step: 6
Training loss: 2.8275901330803515
Validation loss: 3.3169154842214135

Epoch: 5| Step: 7
Training loss: 3.659841094397771
Validation loss: 3.31286249636476

Epoch: 5| Step: 8
Training loss: 3.8515771087926547
Validation loss: 3.308772079664077

Epoch: 5| Step: 9
Training loss: 3.1640227138702275
Validation loss: 3.3044646648673233

Epoch: 5| Step: 10
Training loss: 3.1741352014909117
Validation loss: 3.300618202651771

Epoch: 5| Step: 11
Training loss: 3.0703653034979124
Validation loss: 3.2968762173281285

Epoch: 42| Step: 0
Training loss: 3.499119375341897
Validation loss: 3.292955832193966

Epoch: 5| Step: 1
Training loss: 2.6267020747255816
Validation loss: 3.289032320562192

Epoch: 5| Step: 2
Training loss: 3.6511152679962477
Validation loss: 3.285298553420745

Epoch: 5| Step: 3
Training loss: 2.8994555060822176
Validation loss: 3.2811408130704995

Epoch: 5| Step: 4
Training loss: 3.479803670409399
Validation loss: 3.277924611597715

Epoch: 5| Step: 5
Training loss: 3.600236429292076
Validation loss: 3.2742078568108886

Epoch: 5| Step: 6
Training loss: 3.6151576103580174
Validation loss: 3.270265376028975

Epoch: 5| Step: 7
Training loss: 3.7802625895930637
Validation loss: 3.2665797363525235

Epoch: 5| Step: 8
Training loss: 3.5196495247971473
Validation loss: 3.2625806450163637

Epoch: 5| Step: 9
Training loss: 2.9928683708960966
Validation loss: 3.2585937545119092

Epoch: 5| Step: 10
Training loss: 3.5153337824263113
Validation loss: 3.254917532583721

Epoch: 5| Step: 11
Training loss: 4.1744084470219684
Validation loss: 3.250915392316131

Epoch: 43| Step: 0
Training loss: 3.330696652601433
Validation loss: 3.246802150580951

Epoch: 5| Step: 1
Training loss: 2.841800734264991
Validation loss: 3.242797913597102

Epoch: 5| Step: 2
Training loss: 3.412268964051959
Validation loss: 3.238850726405717

Epoch: 5| Step: 3
Training loss: 3.775713185021075
Validation loss: 3.235146779047499

Epoch: 5| Step: 4
Training loss: 2.7161794326961917
Validation loss: 3.2310770700543374

Epoch: 5| Step: 5
Training loss: 3.5405705420000344
Validation loss: 3.2272946448412205

Epoch: 5| Step: 6
Training loss: 3.855944881393499
Validation loss: 3.2236281222255685

Epoch: 5| Step: 7
Training loss: 3.0929495035927927
Validation loss: 3.219741190293876

Epoch: 5| Step: 8
Training loss: 3.6088173175342986
Validation loss: 3.216004963413919

Epoch: 5| Step: 9
Training loss: 3.5402275003726147
Validation loss: 3.2114765491313375

Epoch: 5| Step: 10
Training loss: 3.1507916984507824
Validation loss: 3.207984290189162

Epoch: 5| Step: 11
Training loss: 3.233571712974558
Validation loss: 3.2042265881878595

Epoch: 44| Step: 0
Training loss: 3.286178375427072
Validation loss: 3.200473382575833

Epoch: 5| Step: 1
Training loss: 3.435884408163314
Validation loss: 3.196752247173617

Epoch: 5| Step: 2
Training loss: 3.146119127912451
Validation loss: 3.1928880567304727

Epoch: 5| Step: 3
Training loss: 3.355272351735592
Validation loss: 3.18899530666748

Epoch: 5| Step: 4
Training loss: 3.447054813844485
Validation loss: 3.1853857383615383

Epoch: 5| Step: 5
Training loss: 3.291554139221809
Validation loss: 3.1814732516332027

Epoch: 5| Step: 6
Training loss: 2.8929562627371936
Validation loss: 3.1779097727688335

Epoch: 5| Step: 7
Training loss: 3.3326660124057046
Validation loss: 3.174197507050637

Epoch: 5| Step: 8
Training loss: 3.1354295259298612
Validation loss: 3.170621921962169

Epoch: 5| Step: 9
Training loss: 3.55941987314984
Validation loss: 3.1669281090342962

Epoch: 5| Step: 10
Training loss: 3.8019767990166944
Validation loss: 3.163591203792646

Epoch: 5| Step: 11
Training loss: 2.0675300758323774
Validation loss: 3.160138683796814

Epoch: 45| Step: 0
Training loss: 3.469984092785875
Validation loss: 3.159352345295776

Epoch: 5| Step: 1
Training loss: 3.378381236307121
Validation loss: 3.1541098240996854

Epoch: 5| Step: 2
Training loss: 2.6159684259976554
Validation loss: 3.149832328996324

Epoch: 5| Step: 3
Training loss: 3.008200246415484
Validation loss: 3.147038738305651

Epoch: 5| Step: 4
Training loss: 2.8139940320231602
Validation loss: 3.144103365074788

Epoch: 5| Step: 5
Training loss: 3.639558169200238
Validation loss: 3.140797298759762

Epoch: 5| Step: 6
Training loss: 3.4024450766610213
Validation loss: 3.138049019756859

Epoch: 5| Step: 7
Training loss: 2.9459894753117264
Validation loss: 3.1348756448011477

Epoch: 5| Step: 8
Training loss: 3.2118868944104104
Validation loss: 3.131532015762337

Epoch: 5| Step: 9
Training loss: 3.2418200916636115
Validation loss: 3.128606889098255

Epoch: 5| Step: 10
Training loss: 4.012076743550973
Validation loss: 3.1254256499005026

Epoch: 5| Step: 11
Training loss: 3.8569809132846244
Validation loss: 3.1221599229909387

Epoch: 46| Step: 0
Training loss: 3.0726696022843467
Validation loss: 3.1184710486809615

Epoch: 5| Step: 1
Training loss: 3.5965424676427244
Validation loss: 3.11514768728982

Epoch: 5| Step: 2
Training loss: 3.4539390743605383
Validation loss: 3.111363948943851

Epoch: 5| Step: 3
Training loss: 2.8489128448555614
Validation loss: 3.107573915698604

Epoch: 5| Step: 4
Training loss: 2.9613548930741778
Validation loss: 3.104314158389803

Epoch: 5| Step: 5
Training loss: 3.4832838599480533
Validation loss: 3.100996925168777

Epoch: 5| Step: 6
Training loss: 3.267007343537362
Validation loss: 3.0979026898443127

Epoch: 5| Step: 7
Training loss: 2.8413669536265695
Validation loss: 3.0945746160914913

Epoch: 5| Step: 8
Training loss: 3.7292422210597906
Validation loss: 3.0915000581876546

Epoch: 5| Step: 9
Training loss: 3.248306713618236
Validation loss: 3.0878443946731537

Epoch: 5| Step: 10
Training loss: 3.016645663980395
Validation loss: 3.0838713734954264

Epoch: 5| Step: 11
Training loss: 3.338978152175903
Validation loss: 3.080746829878969

Epoch: 47| Step: 0
Training loss: 3.1911967662849405
Validation loss: 3.0782775389284915

Epoch: 5| Step: 1
Training loss: 3.284359866033906
Validation loss: 3.075523306479282

Epoch: 5| Step: 2
Training loss: 3.738391200952932
Validation loss: 3.0721934755280333

Epoch: 5| Step: 3
Training loss: 3.1867200607817083
Validation loss: 3.0694701452363575

Epoch: 5| Step: 4
Training loss: 3.2273740325149722
Validation loss: 3.0661591869694385

Epoch: 5| Step: 5
Training loss: 3.3386101123064114
Validation loss: 3.062579303155837

Epoch: 5| Step: 6
Training loss: 2.9204540367382403
Validation loss: 3.0594259715680434

Epoch: 5| Step: 7
Training loss: 3.412096098866917
Validation loss: 3.055612682521351

Epoch: 5| Step: 8
Training loss: 3.14300386284528
Validation loss: 3.0518637091001835

Epoch: 5| Step: 9
Training loss: 3.2525288939896897
Validation loss: 3.047596837800847

Epoch: 5| Step: 10
Training loss: 2.4902476830220386
Validation loss: 3.0444809205089154

Epoch: 5| Step: 11
Training loss: 2.797958079069707
Validation loss: 3.0417058998782687

Epoch: 48| Step: 0
Training loss: 3.6092502853183115
Validation loss: 3.039510483072473

Epoch: 5| Step: 1
Training loss: 2.8635060637143255
Validation loss: 3.035546427047527

Epoch: 5| Step: 2
Training loss: 3.242893077874503
Validation loss: 3.0319185011398337

Epoch: 5| Step: 3
Training loss: 3.0566410930011623
Validation loss: 3.0290071343534906

Epoch: 5| Step: 4
Training loss: 3.1241972845989903
Validation loss: 3.0257948951534996

Epoch: 5| Step: 5
Training loss: 3.058147217564399
Validation loss: 3.023266415351371

Epoch: 5| Step: 6
Training loss: 2.9742448248996554
Validation loss: 3.019818347016069

Epoch: 5| Step: 7
Training loss: 2.492974518781519
Validation loss: 3.017299384912552

Epoch: 5| Step: 8
Training loss: 3.6630104360220894
Validation loss: 3.0149812752504417

Epoch: 5| Step: 9
Training loss: 3.657613777064945
Validation loss: 3.011922596037349

Epoch: 5| Step: 10
Training loss: 2.877997949966644
Validation loss: 3.009024850499732

Epoch: 5| Step: 11
Training loss: 3.1289234708581186
Validation loss: 3.0058787285155057

Epoch: 49| Step: 0
Training loss: 3.0399137349186525
Validation loss: 3.0030481429888676

Epoch: 5| Step: 1
Training loss: 2.76553448027843
Validation loss: 2.999785452032064

Epoch: 5| Step: 2
Training loss: 2.4995971355087905
Validation loss: 2.9969356502883575

Epoch: 5| Step: 3
Training loss: 3.434044227950695
Validation loss: 2.994827818721444

Epoch: 5| Step: 4
Training loss: 3.0605702451046155
Validation loss: 2.9920330455945368

Epoch: 5| Step: 5
Training loss: 2.9096122079554854
Validation loss: 2.9883188847850106

Epoch: 5| Step: 6
Training loss: 3.49827533191022
Validation loss: 2.9860216860478737

Epoch: 5| Step: 7
Training loss: 3.5985179287547444
Validation loss: 2.982996524058529

Epoch: 5| Step: 8
Training loss: 3.195062081893452
Validation loss: 2.9806040061968044

Epoch: 5| Step: 9
Training loss: 3.185014241664312
Validation loss: 2.9773872481082897

Epoch: 5| Step: 10
Training loss: 3.0765206275519965
Validation loss: 2.9750118137840977

Epoch: 5| Step: 11
Training loss: 3.1099386806514544
Validation loss: 2.973915378151221

Epoch: 50| Step: 0
Training loss: 3.1048733890292297
Validation loss: 2.9702563596741447

Epoch: 5| Step: 1
Training loss: 2.68520825279919
Validation loss: 2.9682111384914216

Epoch: 5| Step: 2
Training loss: 2.7951814436322246
Validation loss: 2.965264847930981

Epoch: 5| Step: 3
Training loss: 2.770707799223729
Validation loss: 2.9628798791182973

Epoch: 5| Step: 4
Training loss: 3.401429431224194
Validation loss: 2.958763713603437

Epoch: 5| Step: 5
Training loss: 3.0250838969552833
Validation loss: 2.956572153927569

Epoch: 5| Step: 6
Training loss: 3.14184273412773
Validation loss: 2.9531660329400133

Epoch: 5| Step: 7
Training loss: 3.325989373800859
Validation loss: 2.951301479291853

Epoch: 5| Step: 8
Training loss: 3.4268705230466576
Validation loss: 2.9486663840031633

Epoch: 5| Step: 9
Training loss: 3.478475048893047
Validation loss: 2.9446488028111046

Epoch: 5| Step: 10
Training loss: 2.7783349866429266
Validation loss: 2.942818642408297

Epoch: 5| Step: 11
Training loss: 3.1116042843739273
Validation loss: 2.9435011625575433

Epoch: 51| Step: 0
Training loss: 3.4129379829787676
Validation loss: 2.9461168056123044

Epoch: 5| Step: 1
Training loss: 2.360849791134033
Validation loss: 2.9455952799508003

Epoch: 5| Step: 2
Training loss: 2.7823966587888935
Validation loss: 2.942426922376052

Epoch: 5| Step: 3
Training loss: 3.395102221336311
Validation loss: 2.9366921470596066

Epoch: 5| Step: 4
Training loss: 3.174435488760521
Validation loss: 2.9308263133582013

Epoch: 5| Step: 5
Training loss: 2.982845054037176
Validation loss: 2.9252652917413404

Epoch: 5| Step: 6
Training loss: 3.3121952420520393
Validation loss: 2.9198990020366415

Epoch: 5| Step: 7
Training loss: 3.1449374676963315
Validation loss: 2.917966932017872

Epoch: 5| Step: 8
Training loss: 3.6442541280794916
Validation loss: 2.9169329907668784

Epoch: 5| Step: 9
Training loss: 2.6232282017731285
Validation loss: 2.9138264291984766

Epoch: 5| Step: 10
Training loss: 2.8649957163514075
Validation loss: 2.9107143677642657

Epoch: 5| Step: 11
Training loss: 2.1314679613275955
Validation loss: 2.9095009938679928

Epoch: 52| Step: 0
Training loss: 2.7632050352449378
Validation loss: 2.906368772752731

Epoch: 5| Step: 1
Training loss: 3.0286643415012904
Validation loss: 2.9068230744172774

Epoch: 5| Step: 2
Training loss: 3.6741554483536745
Validation loss: 2.9031422245320853

Epoch: 5| Step: 3
Training loss: 2.68569459820984
Validation loss: 2.8985802854342753

Epoch: 5| Step: 4
Training loss: 3.296301913961068
Validation loss: 2.8961374800064386

Epoch: 5| Step: 5
Training loss: 2.8803074815641634
Validation loss: 2.898881612583334

Epoch: 5| Step: 6
Training loss: 3.316574469839213
Validation loss: 2.8973145344544617

Epoch: 5| Step: 7
Training loss: 3.016105653080952
Validation loss: 2.8964780917606467

Epoch: 5| Step: 8
Training loss: 3.2345212451840344
Validation loss: 2.895006666724831

Epoch: 5| Step: 9
Training loss: 3.202986998027574
Validation loss: 2.8903508511696034

Epoch: 5| Step: 10
Training loss: 2.1266440595224436
Validation loss: 2.8872930276408173

Epoch: 5| Step: 11
Training loss: 2.947376610629815
Validation loss: 2.8831021922320446

Epoch: 53| Step: 0
Training loss: 2.8808459679243112
Validation loss: 2.880246458209405

Epoch: 5| Step: 1
Training loss: 3.0912426893469425
Validation loss: 2.8792483412497782

Epoch: 5| Step: 2
Training loss: 3.624394201762958
Validation loss: 2.8761262070000915

Epoch: 5| Step: 3
Training loss: 3.0939537520697185
Validation loss: 2.873575292937353

Epoch: 5| Step: 4
Training loss: 3.4130670767987463
Validation loss: 2.8715131215484258

Epoch: 5| Step: 5
Training loss: 2.704778000470618
Validation loss: 2.8714010787795243

Epoch: 5| Step: 6
Training loss: 2.8480865613877024
Validation loss: 2.8663654690816203

Epoch: 5| Step: 7
Training loss: 2.6821635292828327
Validation loss: 2.862235113656473

Epoch: 5| Step: 8
Training loss: 2.8887128124212147
Validation loss: 2.864624745618701

Epoch: 5| Step: 9
Training loss: 2.470165571153799
Validation loss: 2.860942813764881

Epoch: 5| Step: 10
Training loss: 3.3243663499565064
Validation loss: 2.8580959634858196

Epoch: 5| Step: 11
Training loss: 2.640730274517158
Validation loss: 2.856141734279878

Epoch: 54| Step: 0
Training loss: 2.4922553265469043
Validation loss: 2.8550548018592243

Epoch: 5| Step: 1
Training loss: 2.856585867268414
Validation loss: 2.851470175864114

Epoch: 5| Step: 2
Training loss: 2.8348331034948795
Validation loss: 2.8480273625464902

Epoch: 5| Step: 3
Training loss: 3.0116565267465703
Validation loss: 2.8445483823150477

Epoch: 5| Step: 4
Training loss: 3.096022262729769
Validation loss: 2.8412073876379353

Epoch: 5| Step: 5
Training loss: 2.904995391106684
Validation loss: 2.8389633717059133

Epoch: 5| Step: 6
Training loss: 2.726246462981017
Validation loss: 2.8399754510745323

Epoch: 5| Step: 7
Training loss: 3.673614739117977
Validation loss: 2.846228455713417

Epoch: 5| Step: 8
Training loss: 2.7431537197484355
Validation loss: 2.835577571506726

Epoch: 5| Step: 9
Training loss: 3.225542327465943
Validation loss: 2.8311900816718087

Epoch: 5| Step: 10
Training loss: 3.308212240262637
Validation loss: 2.8284461610087073

Epoch: 5| Step: 11
Training loss: 2.146845112999302
Validation loss: 2.8273013937185043

Epoch: 55| Step: 0
Training loss: 2.887972712940002
Validation loss: 2.82653652282553

Epoch: 5| Step: 1
Training loss: 2.859924930574316
Validation loss: 2.828488373990616

Epoch: 5| Step: 2
Training loss: 3.180400496640441
Validation loss: 2.834053022945272

Epoch: 5| Step: 3
Training loss: 3.039099999517599
Validation loss: 2.8337505988165415

Epoch: 5| Step: 4
Training loss: 2.9350033153404733
Validation loss: 2.8322503612425036

Epoch: 5| Step: 5
Training loss: 3.054158743049644
Validation loss: 2.8322741980865698

Epoch: 5| Step: 6
Training loss: 2.8801626209864675
Validation loss: 2.8298143817239225

Epoch: 5| Step: 7
Training loss: 3.2019491875337964
Validation loss: 2.8266357448936366

Epoch: 5| Step: 8
Training loss: 2.788754486258201
Validation loss: 2.821821744126911

Epoch: 5| Step: 9
Training loss: 2.6591474998338853
Validation loss: 2.8151299295766896

Epoch: 5| Step: 10
Training loss: 3.0879859016867472
Validation loss: 2.812776647313192

Epoch: 5| Step: 11
Training loss: 3.154465728114064
Validation loss: 2.80694620180733

Epoch: 56| Step: 0
Training loss: 3.1947068664089158
Validation loss: 2.803143415387015

Epoch: 5| Step: 1
Training loss: 3.3474011318429375
Validation loss: 2.802019974135227

Epoch: 5| Step: 2
Training loss: 2.9775722122724204
Validation loss: 2.799247332295793

Epoch: 5| Step: 3
Training loss: 3.224169566558325
Validation loss: 2.798499575007569

Epoch: 5| Step: 4
Training loss: 2.6686230774476347
Validation loss: 2.794671798099458

Epoch: 5| Step: 5
Training loss: 2.8160414545465
Validation loss: 2.7945047489794113

Epoch: 5| Step: 6
Training loss: 2.5843832179611157
Validation loss: 2.795490582904159

Epoch: 5| Step: 7
Training loss: 2.966133008242046
Validation loss: 2.7967260239348812

Epoch: 5| Step: 8
Training loss: 2.3711792177888062
Validation loss: 2.8005725848483105

Epoch: 5| Step: 9
Training loss: 3.485585365993484
Validation loss: 2.7958368971262324

Epoch: 5| Step: 10
Training loss: 2.5841607850307273
Validation loss: 2.7844427763413897

Epoch: 5| Step: 11
Training loss: 2.021952669753762
Validation loss: 2.779009130598802

Epoch: 57| Step: 0
Training loss: 3.046437080408472
Validation loss: 2.780556617342399

Epoch: 5| Step: 1
Training loss: 3.0354022659103284
Validation loss: 2.7816198760265323

Epoch: 5| Step: 2
Training loss: 2.400778854671814
Validation loss: 2.782047525279898

Epoch: 5| Step: 3
Training loss: 3.1421801005029266
Validation loss: 2.77866582437252

Epoch: 5| Step: 4
Training loss: 3.2898696307756636
Validation loss: 2.778740804682481

Epoch: 5| Step: 5
Training loss: 2.8407739849909337
Validation loss: 2.7786051322055907

Epoch: 5| Step: 6
Training loss: 3.129803741932183
Validation loss: 2.7767756865230826

Epoch: 5| Step: 7
Training loss: 2.9036280792560265
Validation loss: 2.7721953749126453

Epoch: 5| Step: 8
Training loss: 2.8279484646322186
Validation loss: 2.7714953002284224

Epoch: 5| Step: 9
Training loss: 3.011900662520448
Validation loss: 2.7671398389213087

Epoch: 5| Step: 10
Training loss: 2.424433777763631
Validation loss: 2.765831571432642

Epoch: 5| Step: 11
Training loss: 2.494235641115459
Validation loss: 2.763366315684721

Epoch: 58| Step: 0
Training loss: 2.586032923294866
Validation loss: 2.761074381272086

Epoch: 5| Step: 1
Training loss: 2.5767419052818514
Validation loss: 2.757965015232136

Epoch: 5| Step: 2
Training loss: 2.811580762050196
Validation loss: 2.757092447629494

Epoch: 5| Step: 3
Training loss: 2.727589498532296
Validation loss: 2.7551750128208883

Epoch: 5| Step: 4
Training loss: 3.1839904912394483
Validation loss: 2.7491850295604583

Epoch: 5| Step: 5
Training loss: 2.7891655910897515
Validation loss: 2.7497402487526807

Epoch: 5| Step: 6
Training loss: 3.026964599493108
Validation loss: 2.7469739195249048

Epoch: 5| Step: 7
Training loss: 3.4950428326210066
Validation loss: 2.744253845413246

Epoch: 5| Step: 8
Training loss: 2.9594107443434328
Validation loss: 2.7462428827067655

Epoch: 5| Step: 9
Training loss: 2.921169420207458
Validation loss: 2.7403940130287987

Epoch: 5| Step: 10
Training loss: 2.2969171429355546
Validation loss: 2.7391973351677663

Epoch: 5| Step: 11
Training loss: 4.093499794804973
Validation loss: 2.7368008234565577

Epoch: 59| Step: 0
Training loss: 2.7752659747529314
Validation loss: 2.7357080280212704

Epoch: 5| Step: 1
Training loss: 3.021734502262011
Validation loss: 2.733976229699905

Epoch: 5| Step: 2
Training loss: 3.3200524082413576
Validation loss: 2.7327713287317317

Epoch: 5| Step: 3
Training loss: 2.60057163556901
Validation loss: 2.7313298189734017

Epoch: 5| Step: 4
Training loss: 3.0036659094969305
Validation loss: 2.7305566667147247

Epoch: 5| Step: 5
Training loss: 2.7448001598441496
Validation loss: 2.727819497305646

Epoch: 5| Step: 6
Training loss: 2.611110726710442
Validation loss: 2.7246394986363978

Epoch: 5| Step: 7
Training loss: 2.7749447447628244
Validation loss: 2.7243373065046548

Epoch: 5| Step: 8
Training loss: 2.8609429734915723
Validation loss: 2.722188222493319

Epoch: 5| Step: 9
Training loss: 2.5697462391533095
Validation loss: 2.7226174423392866

Epoch: 5| Step: 10
Training loss: 3.2288910450774653
Validation loss: 2.7203985163750755

Epoch: 5| Step: 11
Training loss: 2.549987295530498
Validation loss: 2.7224811222156373

Epoch: 60| Step: 0
Training loss: 3.1240599171928407
Validation loss: 2.7188216269400933

Epoch: 5| Step: 1
Training loss: 2.781656214163196
Validation loss: 2.716888788178187

Epoch: 5| Step: 2
Training loss: 3.031610369153478
Validation loss: 2.713472835280384

Epoch: 5| Step: 3
Training loss: 2.4387637065930474
Validation loss: 2.7102700143694447

Epoch: 5| Step: 4
Training loss: 2.797782537597507
Validation loss: 2.7083996410077895

Epoch: 5| Step: 5
Training loss: 2.6308960773991936
Validation loss: 2.7057183161136438

Epoch: 5| Step: 6
Training loss: 3.06468792046853
Validation loss: 2.7061296643291786

Epoch: 5| Step: 7
Training loss: 2.689622883366779
Validation loss: 2.7048172697584976

Epoch: 5| Step: 8
Training loss: 3.3512023874590784
Validation loss: 2.7026687817737782

Epoch: 5| Step: 9
Training loss: 2.723862587368706
Validation loss: 2.702227875415357

Epoch: 5| Step: 10
Training loss: 2.68836978765447
Validation loss: 2.7023226295006837

Epoch: 5| Step: 11
Training loss: 2.022903666534714
Validation loss: 2.699480598876699

Epoch: 61| Step: 0
Training loss: 2.5915420510444247
Validation loss: 2.6999693662765862

Epoch: 5| Step: 1
Training loss: 2.655649364105597
Validation loss: 2.696124882289406

Epoch: 5| Step: 2
Training loss: 2.9851177150192876
Validation loss: 2.6935111545492045

Epoch: 5| Step: 3
Training loss: 2.8209125588437396
Validation loss: 2.6914081619617627

Epoch: 5| Step: 4
Training loss: 2.8537310154099997
Validation loss: 2.6902201400726597

Epoch: 5| Step: 5
Training loss: 2.6416445236802293
Validation loss: 2.692123262211328

Epoch: 5| Step: 6
Training loss: 3.0140335548320163
Validation loss: 2.6980176094249666

Epoch: 5| Step: 7
Training loss: 2.7409266863666057
Validation loss: 2.6878446535409943

Epoch: 5| Step: 8
Training loss: 3.1559614295101364
Validation loss: 2.6833950526285113

Epoch: 5| Step: 9
Training loss: 2.8800594758144347
Validation loss: 2.681015060227176

Epoch: 5| Step: 10
Training loss: 2.6880714341276617
Validation loss: 2.6802747136798923

Epoch: 5| Step: 11
Training loss: 3.1150718144302254
Validation loss: 2.67871012162101

Epoch: 62| Step: 0
Training loss: 2.8216628965505466
Validation loss: 2.6806618019377044

Epoch: 5| Step: 1
Training loss: 3.0760284874816
Validation loss: 2.679394326887403

Epoch: 5| Step: 2
Training loss: 2.920555265489228
Validation loss: 2.677237785772197

Epoch: 5| Step: 3
Training loss: 2.8590054299248617
Validation loss: 2.6721771842701814

Epoch: 5| Step: 4
Training loss: 2.8250309157578775
Validation loss: 2.674270998174768

Epoch: 5| Step: 5
Training loss: 2.9357999386721203
Validation loss: 2.678126730486186

Epoch: 5| Step: 6
Training loss: 2.6302759646542864
Validation loss: 2.6855634802102637

Epoch: 5| Step: 7
Training loss: 3.4369209495423836
Validation loss: 2.6981457363860817

Epoch: 5| Step: 8
Training loss: 2.3867415256943163
Validation loss: 2.667081015900261

Epoch: 5| Step: 9
Training loss: 2.298490825270473
Validation loss: 2.670017730919522

Epoch: 5| Step: 10
Training loss: 2.5665660326496904
Validation loss: 2.6772868725972683

Epoch: 5| Step: 11
Training loss: 3.2938108261253833
Validation loss: 2.68889422439693

Epoch: 63| Step: 0
Training loss: 2.857773295738986
Validation loss: 2.699571938784806

Epoch: 5| Step: 1
Training loss: 2.810086974158922
Validation loss: 2.7021340297530396

Epoch: 5| Step: 2
Training loss: 2.7227473195852374
Validation loss: 2.708190820074434

Epoch: 5| Step: 3
Training loss: 3.208473318109412
Validation loss: 2.7065273511338392

Epoch: 5| Step: 4
Training loss: 2.63519541498977
Validation loss: 2.700072705944155

Epoch: 5| Step: 5
Training loss: 3.0482240477991533
Validation loss: 2.6962268955276554

Epoch: 5| Step: 6
Training loss: 2.3609595630354567
Validation loss: 2.6847989200203872

Epoch: 5| Step: 7
Training loss: 2.78344956762538
Validation loss: 2.676234512735663

Epoch: 5| Step: 8
Training loss: 2.884299124962725
Validation loss: 2.6683958278662847

Epoch: 5| Step: 9
Training loss: 3.238430558134356
Validation loss: 2.6635938140773057

Epoch: 5| Step: 10
Training loss: 2.5593870840381223
Validation loss: 2.6623240753043267

Epoch: 5| Step: 11
Training loss: 1.8399051728899103
Validation loss: 2.657246526147558

Epoch: 64| Step: 0
Training loss: 2.6983074852701088
Validation loss: 2.6571773555806777

Epoch: 5| Step: 1
Training loss: 2.7257216941513462
Validation loss: 2.6539697658397285

Epoch: 5| Step: 2
Training loss: 2.2568107943617806
Validation loss: 2.6544268877769173

Epoch: 5| Step: 3
Training loss: 3.36222824643538
Validation loss: 2.6592967717057796

Epoch: 5| Step: 4
Training loss: 2.935105666901774
Validation loss: 2.6492030332356524

Epoch: 5| Step: 5
Training loss: 2.963213606891329
Validation loss: 2.654673250492045

Epoch: 5| Step: 6
Training loss: 3.0003083388501635
Validation loss: 2.6492108179076967

Epoch: 5| Step: 7
Training loss: 2.6617245973299437
Validation loss: 2.6461290146721272

Epoch: 5| Step: 8
Training loss: 2.3636035541778195
Validation loss: 2.644254962081319

Epoch: 5| Step: 9
Training loss: 2.72693795403628
Validation loss: 2.643220295758074

Epoch: 5| Step: 10
Training loss: 2.9238126317329156
Validation loss: 2.64057899374828

Epoch: 5| Step: 11
Training loss: 2.0514627541366934
Validation loss: 2.6399215724402603

Epoch: 65| Step: 0
Training loss: 2.471968086505796
Validation loss: 2.6373125137717346

Epoch: 5| Step: 1
Training loss: 2.6287239544313272
Validation loss: 2.6368764043700113

Epoch: 5| Step: 2
Training loss: 3.239122233228761
Validation loss: 2.6348367751656823

Epoch: 5| Step: 3
Training loss: 2.5262762111566803
Validation loss: 2.63329666545746

Epoch: 5| Step: 4
Training loss: 2.8159486607889312
Validation loss: 2.6325280689579786

Epoch: 5| Step: 5
Training loss: 2.5100764338189547
Validation loss: 2.628539321935456

Epoch: 5| Step: 6
Training loss: 2.6458474606915274
Validation loss: 2.6294494604278293

Epoch: 5| Step: 7
Training loss: 3.266912763109848
Validation loss: 2.6281175757691475

Epoch: 5| Step: 8
Training loss: 2.591895026135813
Validation loss: 2.6277467041875653

Epoch: 5| Step: 9
Training loss: 2.7466141057154956
Validation loss: 2.6277435588378473

Epoch: 5| Step: 10
Training loss: 2.6929538302538094
Validation loss: 2.6236741562643813

Epoch: 5| Step: 11
Training loss: 3.684329981767483
Validation loss: 2.624121560601178

Epoch: 66| Step: 0
Training loss: 2.992278812300009
Validation loss: 2.621528074055389

Epoch: 5| Step: 1
Training loss: 2.7861186928697164
Validation loss: 2.621192736966604

Epoch: 5| Step: 2
Training loss: 3.2154392140568344
Validation loss: 2.623385496762004

Epoch: 5| Step: 3
Training loss: 2.436754259325921
Validation loss: 2.620561317302683

Epoch: 5| Step: 4
Training loss: 2.695041985688992
Validation loss: 2.6188921183501157

Epoch: 5| Step: 5
Training loss: 2.731853870527443
Validation loss: 2.6177910104171387

Epoch: 5| Step: 6
Training loss: 3.2783853287509586
Validation loss: 2.6121235684267408

Epoch: 5| Step: 7
Training loss: 2.272271450455615
Validation loss: 2.613845988456568

Epoch: 5| Step: 8
Training loss: 2.6582459075646536
Validation loss: 2.614572849227332

Epoch: 5| Step: 9
Training loss: 2.611491915032063
Validation loss: 2.6229076447961694

Epoch: 5| Step: 10
Training loss: 2.275676660200167
Validation loss: 2.630000294430309

Epoch: 5| Step: 11
Training loss: 3.5687236297221046
Validation loss: 2.6282341576464674

Epoch: 67| Step: 0
Training loss: 2.439309451145899
Validation loss: 2.628631925133532

Epoch: 5| Step: 1
Training loss: 2.717642898522387
Validation loss: 2.619968386858546

Epoch: 5| Step: 2
Training loss: 2.928484290684123
Validation loss: 2.6090492494439848

Epoch: 5| Step: 3
Training loss: 2.7306967273109315
Validation loss: 2.6081008350987576

Epoch: 5| Step: 4
Training loss: 2.9009743664992027
Validation loss: 2.6049590901501887

Epoch: 5| Step: 5
Training loss: 2.7799818598203436
Validation loss: 2.605415374193878

Epoch: 5| Step: 6
Training loss: 3.081405982350259
Validation loss: 2.60996703705002

Epoch: 5| Step: 7
Training loss: 3.0197430100895777
Validation loss: 2.6080997343139933

Epoch: 5| Step: 8
Training loss: 2.748657765976938
Validation loss: 2.6084836438676327

Epoch: 5| Step: 9
Training loss: 2.496081332801176
Validation loss: 2.6073336392259168

Epoch: 5| Step: 10
Training loss: 2.5652290326755987
Validation loss: 2.6059652615100872

Epoch: 5| Step: 11
Training loss: 1.7279200675543929
Validation loss: 2.6023241327699784

Epoch: 68| Step: 0
Training loss: 2.8449191530134237
Validation loss: 2.600465144065309

Epoch: 5| Step: 1
Training loss: 2.971690759252707
Validation loss: 2.5957831950930395

Epoch: 5| Step: 2
Training loss: 2.9933321284891377
Validation loss: 2.593056923214861

Epoch: 5| Step: 3
Training loss: 3.1172079979550045
Validation loss: 2.59304315824791

Epoch: 5| Step: 4
Training loss: 3.162163510722126
Validation loss: 2.5923742107883907

Epoch: 5| Step: 5
Training loss: 2.3671548671172724
Validation loss: 2.5961166867561074

Epoch: 5| Step: 6
Training loss: 2.2513262760472332
Validation loss: 2.595475645409233

Epoch: 5| Step: 7
Training loss: 2.400342153955283
Validation loss: 2.5967961773345953

Epoch: 5| Step: 8
Training loss: 2.4372983995844546
Validation loss: 2.59555493791233

Epoch: 5| Step: 9
Training loss: 2.622989702205244
Validation loss: 2.593592841967527

Epoch: 5| Step: 10
Training loss: 2.8079174431839724
Validation loss: 2.593883947567584

Epoch: 5| Step: 11
Training loss: 1.887337845664299
Validation loss: 2.587506443513228

Epoch: 69| Step: 0
Training loss: 2.2798109349280113
Validation loss: 2.5879644496152436

Epoch: 5| Step: 1
Training loss: 2.636060935015121
Validation loss: 2.5928631342562567

Epoch: 5| Step: 2
Training loss: 2.386614258721774
Validation loss: 2.594354268046875

Epoch: 5| Step: 3
Training loss: 2.9859685188570673
Validation loss: 2.59691024814498

Epoch: 5| Step: 4
Training loss: 2.7438794429197926
Validation loss: 2.5960719428044343

Epoch: 5| Step: 5
Training loss: 2.7208003939338092
Validation loss: 2.5992528077120443

Epoch: 5| Step: 6
Training loss: 2.314209074520814
Validation loss: 2.5958581384929933

Epoch: 5| Step: 7
Training loss: 2.4624001652187717
Validation loss: 2.591602267347326

Epoch: 5| Step: 8
Training loss: 2.808407157886002
Validation loss: 2.5909410034703213

Epoch: 5| Step: 9
Training loss: 3.2375409392489525
Validation loss: 2.585519870252601

Epoch: 5| Step: 10
Training loss: 2.9707512785791557
Validation loss: 2.5836415312080034

Epoch: 5| Step: 11
Training loss: 3.9691142718530217
Validation loss: 2.584415272034143

Epoch: 70| Step: 0
Training loss: 2.4459091287422052
Validation loss: 2.5802813903995574

Epoch: 5| Step: 1
Training loss: 2.7954829497208844
Validation loss: 2.580433888613245

Epoch: 5| Step: 2
Training loss: 2.3313039287639574
Validation loss: 2.579319679043517

Epoch: 5| Step: 3
Training loss: 2.6193386973015995
Validation loss: 2.578005026906136

Epoch: 5| Step: 4
Training loss: 2.89807324035638
Validation loss: 2.5759047957135266

Epoch: 5| Step: 5
Training loss: 2.7291509807417387
Validation loss: 2.5740611559220734

Epoch: 5| Step: 6
Training loss: 2.758208767785617
Validation loss: 2.573018447829364

Epoch: 5| Step: 7
Training loss: 2.8469808481347387
Validation loss: 2.571819308216025

Epoch: 5| Step: 8
Training loss: 2.954134491035486
Validation loss: 2.5741239500365802

Epoch: 5| Step: 9
Training loss: 2.6908397770490744
Validation loss: 2.576603835657055

Epoch: 5| Step: 10
Training loss: 2.568028882015774
Validation loss: 2.5785162850351986

Epoch: 5| Step: 11
Training loss: 3.111715384866292
Validation loss: 2.57598503385786

Epoch: 71| Step: 0
Training loss: 2.7562852472313573
Validation loss: 2.5746896532064145

Epoch: 5| Step: 1
Training loss: 2.62162727576959
Validation loss: 2.5719420766136887

Epoch: 5| Step: 2
Training loss: 2.8062518759128614
Validation loss: 2.5680853403779285

Epoch: 5| Step: 3
Training loss: 2.5658906044122447
Validation loss: 2.5692415334867587

Epoch: 5| Step: 4
Training loss: 3.0092874452841367
Validation loss: 2.5735246709571578

Epoch: 5| Step: 5
Training loss: 2.931925902696275
Validation loss: 2.576777073068622

Epoch: 5| Step: 6
Training loss: 2.3003285712359727
Validation loss: 2.583706441720344

Epoch: 5| Step: 7
Training loss: 2.7856372134407605
Validation loss: 2.583029130488343

Epoch: 5| Step: 8
Training loss: 2.7963496732447735
Validation loss: 2.5832579599172516

Epoch: 5| Step: 9
Training loss: 2.6419643639493735
Validation loss: 2.5812866283770552

Epoch: 5| Step: 10
Training loss: 2.6804888447403292
Validation loss: 2.5804841585745426

Epoch: 5| Step: 11
Training loss: 2.901424216085861
Validation loss: 2.579967195107628

Epoch: 72| Step: 0
Training loss: 2.5463319913372295
Validation loss: 2.5789093558388965

Epoch: 5| Step: 1
Training loss: 2.11882355598893
Validation loss: 2.575440351863517

Epoch: 5| Step: 2
Training loss: 2.5145685098037847
Validation loss: 2.5723710749355684

Epoch: 5| Step: 3
Training loss: 2.8111259494820433
Validation loss: 2.5687173456125922

Epoch: 5| Step: 4
Training loss: 2.5260715024044766
Validation loss: 2.5667463993614366

Epoch: 5| Step: 5
Training loss: 2.870367879649988
Validation loss: 2.5633451378450895

Epoch: 5| Step: 6
Training loss: 3.162700896987597
Validation loss: 2.564963703214736

Epoch: 5| Step: 7
Training loss: 2.7959735632425637
Validation loss: 2.570177335576692

Epoch: 5| Step: 8
Training loss: 2.8442892045468167
Validation loss: 2.570359524313135

Epoch: 5| Step: 9
Training loss: 2.613078886445005
Validation loss: 2.5690734257473657

Epoch: 5| Step: 10
Training loss: 2.915596647625578
Validation loss: 2.570133415561517

Epoch: 5| Step: 11
Training loss: 2.2781452319341766
Validation loss: 2.567483487192186

Epoch: 73| Step: 0
Training loss: 2.6505620756193253
Validation loss: 2.570962160943592

Epoch: 5| Step: 1
Training loss: 2.794500611105016
Validation loss: 2.5792129879634818

Epoch: 5| Step: 2
Training loss: 2.707163885921356
Validation loss: 2.57799347436043

Epoch: 5| Step: 3
Training loss: 2.73214805381701
Validation loss: 2.5653032035223924

Epoch: 5| Step: 4
Training loss: 2.337393112594708
Validation loss: 2.562950311806966

Epoch: 5| Step: 5
Training loss: 2.377828319355059
Validation loss: 2.5585390352023825

Epoch: 5| Step: 6
Training loss: 2.7824435298429933
Validation loss: 2.555450181729358

Epoch: 5| Step: 7
Training loss: 2.591683357242266
Validation loss: 2.5589167966087825

Epoch: 5| Step: 8
Training loss: 2.948812252097464
Validation loss: 2.554790490861581

Epoch: 5| Step: 9
Training loss: 2.956755813005893
Validation loss: 2.5505008377860787

Epoch: 5| Step: 10
Training loss: 2.661034437688557
Validation loss: 2.5519070480082027

Epoch: 5| Step: 11
Training loss: 2.600055704987273
Validation loss: 2.5546471595495563

Epoch: 74| Step: 0
Training loss: 2.2408444306465407
Validation loss: 2.553148371800776

Epoch: 5| Step: 1
Training loss: 2.5267118109072944
Validation loss: 2.5556477988452864

Epoch: 5| Step: 2
Training loss: 2.6585326316370472
Validation loss: 2.556784843105451

Epoch: 5| Step: 3
Training loss: 2.8383738243573333
Validation loss: 2.5572351668280664

Epoch: 5| Step: 4
Training loss: 2.7431073941725934
Validation loss: 2.563558852070838

Epoch: 5| Step: 5
Training loss: 3.041979804097989
Validation loss: 2.563821920715637

Epoch: 5| Step: 6
Training loss: 2.6701588612705027
Validation loss: 2.5594913063435736

Epoch: 5| Step: 7
Training loss: 2.722308581359945
Validation loss: 2.5556665385779325

Epoch: 5| Step: 8
Training loss: 2.8811425642062147
Validation loss: 2.5529613554488066

Epoch: 5| Step: 9
Training loss: 2.736376917837638
Validation loss: 2.5482237624290276

Epoch: 5| Step: 10
Training loss: 2.4195303119070064
Validation loss: 2.5485117553957224

Epoch: 5| Step: 11
Training loss: 2.754135836507092
Validation loss: 2.5447404845112573

Epoch: 75| Step: 0
Training loss: 2.544485457292025
Validation loss: 2.544093932473951

Epoch: 5| Step: 1
Training loss: 2.554813860180122
Validation loss: 2.5498078939280613

Epoch: 5| Step: 2
Training loss: 2.8672483682018295
Validation loss: 2.555610171255053

Epoch: 5| Step: 3
Training loss: 3.0314957037380452
Validation loss: 2.5531459244081147

Epoch: 5| Step: 4
Training loss: 2.737996085170402
Validation loss: 2.5571860597847196

Epoch: 5| Step: 5
Training loss: 3.0126992693956995
Validation loss: 2.564340322143662

Epoch: 5| Step: 6
Training loss: 2.3032730158495696
Validation loss: 2.5497358165036905

Epoch: 5| Step: 7
Training loss: 2.436651130953767
Validation loss: 2.5484024374440604

Epoch: 5| Step: 8
Training loss: 2.325863552719536
Validation loss: 2.5407427505164026

Epoch: 5| Step: 9
Training loss: 2.764628085186479
Validation loss: 2.535963975067362

Epoch: 5| Step: 10
Training loss: 2.831070183102643
Validation loss: 2.5400653052132394

Epoch: 5| Step: 11
Training loss: 2.534683912385441
Validation loss: 2.5443340529230873

Epoch: 76| Step: 0
Training loss: 2.667210573120076
Validation loss: 2.5447883365987716

Epoch: 5| Step: 1
Training loss: 2.7715742702838515
Validation loss: 2.5445273682273153

Epoch: 5| Step: 2
Training loss: 2.7679232084063092
Validation loss: 2.5446321405935617

Epoch: 5| Step: 3
Training loss: 2.266922151902364
Validation loss: 2.54644413679422

Epoch: 5| Step: 4
Training loss: 3.1764960241234323
Validation loss: 2.543691947362061

Epoch: 5| Step: 5
Training loss: 3.0104749909309176
Validation loss: 2.5446127379060246

Epoch: 5| Step: 6
Training loss: 2.9254345758503244
Validation loss: 2.542408562606717

Epoch: 5| Step: 7
Training loss: 2.1773500659359644
Validation loss: 2.5417218371693604

Epoch: 5| Step: 8
Training loss: 2.443131616895239
Validation loss: 2.5407298242794556

Epoch: 5| Step: 9
Training loss: 2.6318328574309433
Validation loss: 2.537995486906261

Epoch: 5| Step: 10
Training loss: 2.4746407835787934
Validation loss: 2.5354113065986326

Epoch: 5| Step: 11
Training loss: 2.514576948316338
Validation loss: 2.5335232452265743

Epoch: 77| Step: 0
Training loss: 2.472252305046625
Validation loss: 2.533628805919606

Epoch: 5| Step: 1
Training loss: 2.4579957848831673
Validation loss: 2.5338711844196578

Epoch: 5| Step: 2
Training loss: 2.132785447616324
Validation loss: 2.534267651863259

Epoch: 5| Step: 3
Training loss: 2.6450678000747327
Validation loss: 2.5346253186402987

Epoch: 5| Step: 4
Training loss: 2.804965459709544
Validation loss: 2.537345853674256

Epoch: 5| Step: 5
Training loss: 2.424799181301642
Validation loss: 2.537160237120385

Epoch: 5| Step: 6
Training loss: 2.8464847033351157
Validation loss: 2.541728137528884

Epoch: 5| Step: 7
Training loss: 2.477392496804137
Validation loss: 2.534323439444013

Epoch: 5| Step: 8
Training loss: 2.65687517774999
Validation loss: 2.52790430093506

Epoch: 5| Step: 9
Training loss: 3.238400962098548
Validation loss: 2.5303765976102133

Epoch: 5| Step: 10
Training loss: 2.986483163844599
Validation loss: 2.5280106110347607

Epoch: 5| Step: 11
Training loss: 2.8077452416449717
Validation loss: 2.5297259660246345

Epoch: 78| Step: 0
Training loss: 2.773475582237445
Validation loss: 2.5275666238347063

Epoch: 5| Step: 1
Training loss: 2.79857051326648
Validation loss: 2.5273804541570377

Epoch: 5| Step: 2
Training loss: 2.429116528507808
Validation loss: 2.5277053558597014

Epoch: 5| Step: 3
Training loss: 2.5302447925096048
Validation loss: 2.5247051708177346

Epoch: 5| Step: 4
Training loss: 2.713389933633904
Validation loss: 2.527930256997917

Epoch: 5| Step: 5
Training loss: 2.7244835390408206
Validation loss: 2.5258482606657116

Epoch: 5| Step: 6
Training loss: 2.5508921016423236
Validation loss: 2.5299537581400724

Epoch: 5| Step: 7
Training loss: 3.1174229124276995
Validation loss: 2.526457712315935

Epoch: 5| Step: 8
Training loss: 2.6372434192980014
Validation loss: 2.523889888843513

Epoch: 5| Step: 9
Training loss: 2.3551759047527385
Validation loss: 2.52404405057612

Epoch: 5| Step: 10
Training loss: 2.6310449660781914
Validation loss: 2.5227067595987918

Epoch: 5| Step: 11
Training loss: 1.9320457966986113
Validation loss: 2.5225504761942656

Epoch: 79| Step: 0
Training loss: 2.813732809508256
Validation loss: 2.5247806737873306

Epoch: 5| Step: 1
Training loss: 2.617835121307504
Validation loss: 2.5240692513140113

Epoch: 5| Step: 2
Training loss: 2.3272713753983516
Validation loss: 2.527395465052478

Epoch: 5| Step: 3
Training loss: 2.8426259932026663
Validation loss: 2.521362301732518

Epoch: 5| Step: 4
Training loss: 2.8870135867806974
Validation loss: 2.5225528233129255

Epoch: 5| Step: 5
Training loss: 2.7317944365949343
Validation loss: 2.5189685163533193

Epoch: 5| Step: 6
Training loss: 2.4291779698348286
Validation loss: 2.519546906967209

Epoch: 5| Step: 7
Training loss: 2.6051598041157606
Validation loss: 2.5207672123604934

Epoch: 5| Step: 8
Training loss: 2.6553943826756066
Validation loss: 2.5214044354859673

Epoch: 5| Step: 9
Training loss: 2.479547092089777
Validation loss: 2.523936672067887

Epoch: 5| Step: 10
Training loss: 2.629426403082717
Validation loss: 2.5190395496431717

Epoch: 5| Step: 11
Training loss: 3.012183721250888
Validation loss: 2.5184911468682976

Epoch: 80| Step: 0
Training loss: 2.3683599709559284
Validation loss: 2.5217571628083464

Epoch: 5| Step: 1
Training loss: 3.1952404209951752
Validation loss: 2.5212171054888737

Epoch: 5| Step: 2
Training loss: 2.6107481124741065
Validation loss: 2.5170823371841875

Epoch: 5| Step: 3
Training loss: 2.5161094436009206
Validation loss: 2.519372048880583

Epoch: 5| Step: 4
Training loss: 2.6077178444205997
Validation loss: 2.5160508831925408

Epoch: 5| Step: 5
Training loss: 2.800997546155754
Validation loss: 2.518774613906203

Epoch: 5| Step: 6
Training loss: 2.639545106999918
Validation loss: 2.5196241494728193

Epoch: 5| Step: 7
Training loss: 2.187401687592679
Validation loss: 2.5139108271077713

Epoch: 5| Step: 8
Training loss: 2.8762240913746115
Validation loss: 2.513538444987031

Epoch: 5| Step: 9
Training loss: 2.7088479555705827
Validation loss: 2.5117577193318663

Epoch: 5| Step: 10
Training loss: 2.5247945531979736
Validation loss: 2.5158530264234567

Epoch: 5| Step: 11
Training loss: 2.4983171521104555
Validation loss: 2.513076363906973

Epoch: 81| Step: 0
Training loss: 3.002090361615826
Validation loss: 2.5123895013528204

Epoch: 5| Step: 1
Training loss: 2.3618876233738932
Validation loss: 2.5146797923877013

Epoch: 5| Step: 2
Training loss: 2.4093204081444966
Validation loss: 2.509849240187931

Epoch: 5| Step: 3
Training loss: 2.795947640399445
Validation loss: 2.5112465018499153

Epoch: 5| Step: 4
Training loss: 2.418992622291697
Validation loss: 2.514649318460353

Epoch: 5| Step: 5
Training loss: 2.9500933228295203
Validation loss: 2.5145962035053366

Epoch: 5| Step: 6
Training loss: 2.814413987681126
Validation loss: 2.511912661236322

Epoch: 5| Step: 7
Training loss: 2.679947998908835
Validation loss: 2.5121194372547517

Epoch: 5| Step: 8
Training loss: 2.46734163697907
Validation loss: 2.5060552380261716

Epoch: 5| Step: 9
Training loss: 2.5423803630276955
Validation loss: 2.5059610030551576

Epoch: 5| Step: 10
Training loss: 2.5467394459229475
Validation loss: 2.509565103439232

Epoch: 5| Step: 11
Training loss: 1.48925717213101
Validation loss: 2.5075440426511793

Epoch: 82| Step: 0
Training loss: 3.2870275585851783
Validation loss: 2.5095257893122827

Epoch: 5| Step: 1
Training loss: 2.572191009945468
Validation loss: 2.510534767812964

Epoch: 5| Step: 2
Training loss: 2.4612944813317705
Validation loss: 2.5104099144323775

Epoch: 5| Step: 3
Training loss: 2.8424480098643383
Validation loss: 2.5085230540662833

Epoch: 5| Step: 4
Training loss: 3.059123454989388
Validation loss: 2.510809220030376

Epoch: 5| Step: 5
Training loss: 2.47351840206817
Validation loss: 2.509721344434731

Epoch: 5| Step: 6
Training loss: 2.1986983176398227
Validation loss: 2.5123821151812065

Epoch: 5| Step: 7
Training loss: 2.381313164942059
Validation loss: 2.511454111952987

Epoch: 5| Step: 8
Training loss: 2.80644268912119
Validation loss: 2.510326183371551

Epoch: 5| Step: 9
Training loss: 1.8941550599042025
Validation loss: 2.5080036197458275

Epoch: 5| Step: 10
Training loss: 2.7233812196117504
Validation loss: 2.5074446617351343

Epoch: 5| Step: 11
Training loss: 2.2335156475447286
Validation loss: 2.5060950723646127

Epoch: 83| Step: 0
Training loss: 2.2461382256126514
Validation loss: 2.507099355230436

Epoch: 5| Step: 1
Training loss: 2.310786050266225
Validation loss: 2.505765675799642

Epoch: 5| Step: 2
Training loss: 2.8016887136390305
Validation loss: 2.511132515481527

Epoch: 5| Step: 3
Training loss: 2.6890507149756737
Validation loss: 2.5046301721146738

Epoch: 5| Step: 4
Training loss: 2.577754046022127
Validation loss: 2.5038988685598293

Epoch: 5| Step: 5
Training loss: 2.9427487170843953
Validation loss: 2.5079028864938953

Epoch: 5| Step: 6
Training loss: 2.7617089083872557
Validation loss: 2.5081309614467933

Epoch: 5| Step: 7
Training loss: 2.6537775537944386
Validation loss: 2.506552564918896

Epoch: 5| Step: 8
Training loss: 2.937953183543163
Validation loss: 2.506989871981633

Epoch: 5| Step: 9
Training loss: 2.2880191443182563
Validation loss: 2.5069141303918663

Epoch: 5| Step: 10
Training loss: 2.547049487169005
Validation loss: 2.506222293031529

Epoch: 5| Step: 11
Training loss: 2.5774551908666217
Validation loss: 2.503833561406073

Epoch: 84| Step: 0
Training loss: 2.7396617244823323
Validation loss: 2.50216026351993

Epoch: 5| Step: 1
Training loss: 2.965766933891561
Validation loss: 2.508372560196484

Epoch: 5| Step: 2
Training loss: 2.2575129009904744
Validation loss: 2.499924336718936

Epoch: 5| Step: 3
Training loss: 2.732498658678122
Validation loss: 2.499678471870014

Epoch: 5| Step: 4
Training loss: 2.4273973079060807
Validation loss: 2.5024935346927006

Epoch: 5| Step: 5
Training loss: 2.9879614565404764
Validation loss: 2.5011891080227002

Epoch: 5| Step: 6
Training loss: 2.4012810069936297
Validation loss: 2.4997012436693167

Epoch: 5| Step: 7
Training loss: 2.6552567363969986
Validation loss: 2.500168882069919

Epoch: 5| Step: 8
Training loss: 2.7572485155265367
Validation loss: 2.5018827302883038

Epoch: 5| Step: 9
Training loss: 1.9067779185220692
Validation loss: 2.5017581598700196

Epoch: 5| Step: 10
Training loss: 2.393858573981116
Validation loss: 2.4971287332264276

Epoch: 5| Step: 11
Training loss: 4.215623389286896
Validation loss: 2.503613911671162

Epoch: 85| Step: 0
Training loss: 3.0612922934075195
Validation loss: 2.4991765613260393

Epoch: 5| Step: 1
Training loss: 3.002193126131188
Validation loss: 2.498582899273513

Epoch: 5| Step: 2
Training loss: 2.5154631189422734
Validation loss: 2.4951074071245802

Epoch: 5| Step: 3
Training loss: 2.329599412855661
Validation loss: 2.4991703723177436

Epoch: 5| Step: 4
Training loss: 2.703534398470524
Validation loss: 2.500556871858599

Epoch: 5| Step: 5
Training loss: 2.495166110699428
Validation loss: 2.4974048615664692

Epoch: 5| Step: 6
Training loss: 2.481558684934713
Validation loss: 2.4966255182708705

Epoch: 5| Step: 7
Training loss: 2.639616463284427
Validation loss: 2.4968871446170118

Epoch: 5| Step: 8
Training loss: 2.9320512924912
Validation loss: 2.501775857887782

Epoch: 5| Step: 9
Training loss: 2.1421717047022066
Validation loss: 2.4921971024953073

Epoch: 5| Step: 10
Training loss: 2.379732235984572
Validation loss: 2.498652259816381

Epoch: 5| Step: 11
Training loss: 2.23438759113312
Validation loss: 2.4981990168383477

Epoch: 86| Step: 0
Training loss: 2.3680089148598475
Validation loss: 2.5001367809706667

Epoch: 5| Step: 1
Training loss: 2.3990955754681207
Validation loss: 2.496609204260871

Epoch: 5| Step: 2
Training loss: 2.2789802233250915
Validation loss: 2.497903540870811

Epoch: 5| Step: 3
Training loss: 2.9656752876544323
Validation loss: 2.494305263931372

Epoch: 5| Step: 4
Training loss: 2.6070354275302723
Validation loss: 2.497869396292707

Epoch: 5| Step: 5
Training loss: 3.024678766518025
Validation loss: 2.4944571282039054

Epoch: 5| Step: 6
Training loss: 2.722113447113753
Validation loss: 2.496048582142959

Epoch: 5| Step: 7
Training loss: 2.491778205577988
Validation loss: 2.4966372404180914

Epoch: 5| Step: 8
Training loss: 2.669265275654783
Validation loss: 2.494816281562908

Epoch: 5| Step: 9
Training loss: 2.3796152145217406
Validation loss: 2.4893454686790895

Epoch: 5| Step: 10
Training loss: 2.5311038128118075
Validation loss: 2.490032424217745

Epoch: 5| Step: 11
Training loss: 3.2588178880861016
Validation loss: 2.495360699122234

Epoch: 87| Step: 0
Training loss: 2.4815086287610364
Validation loss: 2.489941041911001

Epoch: 5| Step: 1
Training loss: 2.533213948481841
Validation loss: 2.490035899112882

Epoch: 5| Step: 2
Training loss: 2.4508277195521706
Validation loss: 2.490040483094572

Epoch: 5| Step: 3
Training loss: 2.3255554971250936
Validation loss: 2.491864860162579

Epoch: 5| Step: 4
Training loss: 2.7396879188291
Validation loss: 2.490983845742983

Epoch: 5| Step: 5
Training loss: 2.747964973015472
Validation loss: 2.491627669162131

Epoch: 5| Step: 6
Training loss: 2.776371309463173
Validation loss: 2.4879034924375283

Epoch: 5| Step: 7
Training loss: 2.745237387865549
Validation loss: 2.493078401426045

Epoch: 5| Step: 8
Training loss: 2.85533148022055
Validation loss: 2.487653863803206

Epoch: 5| Step: 9
Training loss: 2.724904340412374
Validation loss: 2.490429679841287

Epoch: 5| Step: 10
Training loss: 2.4986353010423
Validation loss: 2.4917171915432625

Epoch: 5| Step: 11
Training loss: 1.5530726802003638
Validation loss: 2.4957195990562

Epoch: 88| Step: 0
Training loss: 2.4858606083245647
Validation loss: 2.485240957300921

Epoch: 5| Step: 1
Training loss: 3.0174387482982064
Validation loss: 2.4836558874692285

Epoch: 5| Step: 2
Training loss: 2.344546576872178
Validation loss: 2.489503134282985

Epoch: 5| Step: 3
Training loss: 2.568711544593634
Validation loss: 2.492626526209259

Epoch: 5| Step: 4
Training loss: 2.754255297028752
Validation loss: 2.485747579964033

Epoch: 5| Step: 5
Training loss: 2.7720878648360143
Validation loss: 2.4911850095860375

Epoch: 5| Step: 6
Training loss: 2.760583366302918
Validation loss: 2.489618912978623

Epoch: 5| Step: 7
Training loss: 2.776561685968815
Validation loss: 2.4975372303595624

Epoch: 5| Step: 8
Training loss: 2.4271265006967644
Validation loss: 2.4963697540562735

Epoch: 5| Step: 9
Training loss: 2.355297480946915
Validation loss: 2.491932779207888

Epoch: 5| Step: 10
Training loss: 2.5213056599984336
Validation loss: 2.4956756743137802

Epoch: 5| Step: 11
Training loss: 1.1909023532570948
Validation loss: 2.4961008142441994

Epoch: 89| Step: 0
Training loss: 2.936711306916446
Validation loss: 2.492952777393369

Epoch: 5| Step: 1
Training loss: 2.6645620107108297
Validation loss: 2.4928761350969

Epoch: 5| Step: 2
Training loss: 2.5886071936886355
Validation loss: 2.4920903548676594

Epoch: 5| Step: 3
Training loss: 2.5514747880201734
Validation loss: 2.4903720912376732

Epoch: 5| Step: 4
Training loss: 2.650204769356331
Validation loss: 2.4916618813327354

Epoch: 5| Step: 5
Training loss: 2.8135715562592614
Validation loss: 2.4822163150335803

Epoch: 5| Step: 6
Training loss: 2.6168507829105447
Validation loss: 2.4926274906752615

Epoch: 5| Step: 7
Training loss: 2.7753542012476196
Validation loss: 2.483541084779933

Epoch: 5| Step: 8
Training loss: 2.6718787477701236
Validation loss: 2.4920556203932662

Epoch: 5| Step: 9
Training loss: 2.321071616176074
Validation loss: 2.4902740754596824

Epoch: 5| Step: 10
Training loss: 2.002557906933974
Validation loss: 2.4938222651579443

Epoch: 5| Step: 11
Training loss: 2.078281597461217
Validation loss: 2.478357092053609

Epoch: 90| Step: 0
Training loss: 2.326740442033603
Validation loss: 2.484119230175994

Epoch: 5| Step: 1
Training loss: 2.4822623428958392
Validation loss: 2.486079696785938

Epoch: 5| Step: 2
Training loss: 2.5998454341427886
Validation loss: 2.4838811715475724

Epoch: 5| Step: 3
Training loss: 2.6060830554506005
Validation loss: 2.48270742163215

Epoch: 5| Step: 4
Training loss: 2.3730063854891985
Validation loss: 2.486090689462176

Epoch: 5| Step: 5
Training loss: 2.1921703074209997
Validation loss: 2.4861633573816397

Epoch: 5| Step: 6
Training loss: 2.653253548139822
Validation loss: 2.4793591958841956

Epoch: 5| Step: 7
Training loss: 2.564918214412451
Validation loss: 2.4846982085916336

Epoch: 5| Step: 8
Training loss: 3.217561965499818
Validation loss: 2.4837706248581024

Epoch: 5| Step: 9
Training loss: 2.8784273699088416
Validation loss: 2.486699642164312

Epoch: 5| Step: 10
Training loss: 2.5765607307571434
Validation loss: 2.4893443712499908

Epoch: 5| Step: 11
Training loss: 1.8939576843996888
Validation loss: 2.484823134528942

Epoch: 91| Step: 0
Training loss: 2.456996511144028
Validation loss: 2.487974474334408

Epoch: 5| Step: 1
Training loss: 2.3275934418995785
Validation loss: 2.486047351822879

Epoch: 5| Step: 2
Training loss: 2.691277266956476
Validation loss: 2.487151244170422

Epoch: 5| Step: 3
Training loss: 2.399154208081267
Validation loss: 2.4862454728509964

Epoch: 5| Step: 4
Training loss: 2.625535910261095
Validation loss: 2.4871846511926115

Epoch: 5| Step: 5
Training loss: 2.4717626418319685
Validation loss: 2.4878506110654013

Epoch: 5| Step: 6
Training loss: 2.8357019247778785
Validation loss: 2.489041494251736

Epoch: 5| Step: 7
Training loss: 2.9859207703796935
Validation loss: 2.4878281640435476

Epoch: 5| Step: 8
Training loss: 1.9387726449535516
Validation loss: 2.4882215954842426

Epoch: 5| Step: 9
Training loss: 2.82929252003755
Validation loss: 2.4834942566065576

Epoch: 5| Step: 10
Training loss: 3.0045284425529033
Validation loss: 2.483630634652752

Epoch: 5| Step: 11
Training loss: 1.7227051051125692
Validation loss: 2.482577191247919

Epoch: 92| Step: 0
Training loss: 2.0659206807806885
Validation loss: 2.4787783452188092

Epoch: 5| Step: 1
Training loss: 2.5067316976525658
Validation loss: 2.468545201011684

Epoch: 5| Step: 2
Training loss: 2.9633783832926093
Validation loss: 2.4867424790695076

Epoch: 5| Step: 3
Training loss: 2.5599140982818693
Validation loss: 2.4829194065298026

Epoch: 5| Step: 4
Training loss: 2.2771980147408883
Validation loss: 2.474416105515595

Epoch: 5| Step: 5
Training loss: 2.9300380649632847
Validation loss: 2.4799394979069986

Epoch: 5| Step: 6
Training loss: 2.283055048595945
Validation loss: 2.479858675847252

Epoch: 5| Step: 7
Training loss: 2.631920366224622
Validation loss: 2.4819527619731336

Epoch: 5| Step: 8
Training loss: 2.7396375314744694
Validation loss: 2.482968630081848

Epoch: 5| Step: 9
Training loss: 2.2985604259156847
Validation loss: 2.482186307017138

Epoch: 5| Step: 10
Training loss: 3.100612542946876
Validation loss: 2.485143858418915

Epoch: 5| Step: 11
Training loss: 3.0800539740254806
Validation loss: 2.4834087980141524

Epoch: 93| Step: 0
Training loss: 1.8443054397066774
Validation loss: 2.4864547908988386

Epoch: 5| Step: 1
Training loss: 2.490398566125101
Validation loss: 2.488023434172393

Epoch: 5| Step: 2
Training loss: 2.375705212747056
Validation loss: 2.4897717932605223

Epoch: 5| Step: 3
Training loss: 3.077086607548843
Validation loss: 2.4847692380752044

Epoch: 5| Step: 4
Training loss: 2.7676833946435853
Validation loss: 2.487394417386233

Epoch: 5| Step: 5
Training loss: 2.4663311661416323
Validation loss: 2.486408201388007

Epoch: 5| Step: 6
Training loss: 2.8818516564401024
Validation loss: 2.4879574886949505

Epoch: 5| Step: 7
Training loss: 2.8691351405559393
Validation loss: 2.4790056414094384

Epoch: 5| Step: 8
Training loss: 2.7670492179692623
Validation loss: 2.4845215736192574

Epoch: 5| Step: 9
Training loss: 2.328704966561686
Validation loss: 2.4791571405906274

Epoch: 5| Step: 10
Training loss: 2.6419811490791987
Validation loss: 2.4775386655429017

Epoch: 5| Step: 11
Training loss: 2.2812100759696743
Validation loss: 2.4812344868492913

Epoch: 94| Step: 0
Training loss: 2.198716751723396
Validation loss: 2.483550224710785

Epoch: 5| Step: 1
Training loss: 2.6938577015315923
Validation loss: 2.4764681255598076

Epoch: 5| Step: 2
Training loss: 2.591087169398472
Validation loss: 2.471687163149871

Epoch: 5| Step: 3
Training loss: 2.9777606945433486
Validation loss: 2.467630724144773

Epoch: 5| Step: 4
Training loss: 2.5323968808719055
Validation loss: 2.471983152580308

Epoch: 5| Step: 5
Training loss: 2.269366942874407
Validation loss: 2.4782209970257463

Epoch: 5| Step: 6
Training loss: 2.5450428182301286
Validation loss: 2.468724685249432

Epoch: 5| Step: 7
Training loss: 2.527115353105998
Validation loss: 2.4740161420526308

Epoch: 5| Step: 8
Training loss: 2.0818587870497627
Validation loss: 2.4793105297394766

Epoch: 5| Step: 9
Training loss: 2.746385192599383
Validation loss: 2.4741102085008326

Epoch: 5| Step: 10
Training loss: 3.1684705381536156
Validation loss: 2.4740515935619767

Epoch: 5| Step: 11
Training loss: 2.096203974364693
Validation loss: 2.4800010340314165

Epoch: 95| Step: 0
Training loss: 2.5540711945638153
Validation loss: 2.479686900192666

Epoch: 5| Step: 1
Training loss: 2.7123001587553106
Validation loss: 2.48228155260244

Epoch: 5| Step: 2
Training loss: 3.221006176757575
Validation loss: 2.4842695177825393

Epoch: 5| Step: 3
Training loss: 2.413105302684336
Validation loss: 2.479421667934407

Epoch: 5| Step: 4
Training loss: 2.1958026813874647
Validation loss: 2.4830691346391593

Epoch: 5| Step: 5
Training loss: 2.8512056310296243
Validation loss: 2.4832408843550833

Epoch: 5| Step: 6
Training loss: 2.2474234981904293
Validation loss: 2.4793285763119552

Epoch: 5| Step: 7
Training loss: 2.6828535855523743
Validation loss: 2.4830531396396642

Epoch: 5| Step: 8
Training loss: 2.0399890416916873
Validation loss: 2.480764140164811

Epoch: 5| Step: 9
Training loss: 2.5712695905192255
Validation loss: 2.487393211264212

Epoch: 5| Step: 10
Training loss: 2.8112774205004865
Validation loss: 2.4793559664627214

Epoch: 5| Step: 11
Training loss: 1.9786538982369248
Validation loss: 2.474552891545035

Epoch: 96| Step: 0
Training loss: 2.9822455193540858
Validation loss: 2.4781305782067724

Epoch: 5| Step: 1
Training loss: 2.3907613279079665
Validation loss: 2.4743484423732087

Epoch: 5| Step: 2
Training loss: 2.039320655353533
Validation loss: 2.4731398556995536

Epoch: 5| Step: 3
Training loss: 2.1427729612799693
Validation loss: 2.469231317173508

Epoch: 5| Step: 4
Training loss: 3.0663151235464445
Validation loss: 2.4761732940822214

Epoch: 5| Step: 5
Training loss: 2.1302418849948532
Validation loss: 2.4714826517635196

Epoch: 5| Step: 6
Training loss: 2.7241436303877102
Validation loss: 2.474389375312623

Epoch: 5| Step: 7
Training loss: 2.481106797705386
Validation loss: 2.4749036863320097

Epoch: 5| Step: 8
Training loss: 2.5878866634698454
Validation loss: 2.477906833969355

Epoch: 5| Step: 9
Training loss: 2.493927733701214
Validation loss: 2.47401971172019

Epoch: 5| Step: 10
Training loss: 3.0526640841835606
Validation loss: 2.4775561035275895

Epoch: 5| Step: 11
Training loss: 2.7963739724232592
Validation loss: 2.47485475997038

Epoch: 97| Step: 0
Training loss: 2.6793227767749026
Validation loss: 2.4743444536287176

Epoch: 5| Step: 1
Training loss: 2.5820834202192127
Validation loss: 2.4800247916461675

Epoch: 5| Step: 2
Training loss: 2.7505326188758423
Validation loss: 2.4711693365336003

Epoch: 5| Step: 3
Training loss: 2.556751036099468
Validation loss: 2.472533991856106

Epoch: 5| Step: 4
Training loss: 2.476233812536317
Validation loss: 2.4732031355526662

Epoch: 5| Step: 5
Training loss: 2.655158323463264
Validation loss: 2.4787939029165043

Epoch: 5| Step: 6
Training loss: 2.387343804008463
Validation loss: 2.4774013666971384

Epoch: 5| Step: 7
Training loss: 2.87636202186633
Validation loss: 2.481937027950789

Epoch: 5| Step: 8
Training loss: 2.747500410696039
Validation loss: 2.478532639272983

Epoch: 5| Step: 9
Training loss: 2.3906855357365657
Validation loss: 2.4754647109266332

Epoch: 5| Step: 10
Training loss: 2.1413246737685507
Validation loss: 2.476160425947121

Epoch: 5| Step: 11
Training loss: 3.060247877714987
Validation loss: 2.4640753747913737

Epoch: 98| Step: 0
Training loss: 2.370077452701793
Validation loss: 2.4685893268047785

Epoch: 5| Step: 1
Training loss: 2.3173023568392397
Validation loss: 2.471081841635395

Epoch: 5| Step: 2
Training loss: 1.7816790013946453
Validation loss: 2.4761545384771977

Epoch: 5| Step: 3
Training loss: 2.537789457000711
Validation loss: 2.4809498758356128

Epoch: 5| Step: 4
Training loss: 2.881351090186587
Validation loss: 2.481273370435756

Epoch: 5| Step: 5
Training loss: 2.599324498090708
Validation loss: 2.4863264428967353

Epoch: 5| Step: 6
Training loss: 2.3536989765846204
Validation loss: 2.4955646549122465

Epoch: 5| Step: 7
Training loss: 3.1832564286400986
Validation loss: 2.492154486904903

Epoch: 5| Step: 8
Training loss: 2.8982711703138415
Validation loss: 2.49615978497876

Epoch: 5| Step: 9
Training loss: 2.500680640072869
Validation loss: 2.4849898499167047

Epoch: 5| Step: 10
Training loss: 2.9015796831368896
Validation loss: 2.4760863310674934

Epoch: 5| Step: 11
Training loss: 2.1290131988259597
Validation loss: 2.46909226889851

Epoch: 99| Step: 0
Training loss: 2.821660530667995
Validation loss: 2.473858228297822

Epoch: 5| Step: 1
Training loss: 2.881584422796869
Validation loss: 2.474485844371802

Epoch: 5| Step: 2
Training loss: 1.8111472507815791
Validation loss: 2.4792426054941927

Epoch: 5| Step: 3
Training loss: 2.539831802025592
Validation loss: 2.4906039294121776

Epoch: 5| Step: 4
Training loss: 2.443612284572668
Validation loss: 2.4957829790868225

Epoch: 5| Step: 5
Training loss: 2.9140641363308073
Validation loss: 2.5023433947714273

Epoch: 5| Step: 6
Training loss: 2.662544780229259
Validation loss: 2.5066340362317976

Epoch: 5| Step: 7
Training loss: 2.9876408308345606
Validation loss: 2.5098829546269017

Epoch: 5| Step: 8
Training loss: 2.5907251575651586
Validation loss: 2.506023283682316

Epoch: 5| Step: 9
Training loss: 2.675642513938706
Validation loss: 2.509491951316492

Epoch: 5| Step: 10
Training loss: 2.4276705401276772
Validation loss: 2.50122181123008

Epoch: 5| Step: 11
Training loss: 1.5491326551036617
Validation loss: 2.503274743740147

Epoch: 100| Step: 0
Training loss: 2.7585940887960887
Validation loss: 2.499946498298363

Epoch: 5| Step: 1
Training loss: 2.7205176033469898
Validation loss: 2.492778883298442

Epoch: 5| Step: 2
Training loss: 2.707944773653215
Validation loss: 2.4952528347461356

Epoch: 5| Step: 3
Training loss: 1.557974173555813
Validation loss: 2.4899941561654595

Epoch: 5| Step: 4
Training loss: 1.9715863943110745
Validation loss: 2.4851468644599004

Epoch: 5| Step: 5
Training loss: 2.5655935269282737
Validation loss: 2.4869172466352265

Epoch: 5| Step: 6
Training loss: 2.6793923618616384
Validation loss: 2.4774364249191017

Epoch: 5| Step: 7
Training loss: 2.4987183146450067
Validation loss: 2.477970401003185

Epoch: 5| Step: 8
Training loss: 3.371058529065355
Validation loss: 2.473658976596592

Epoch: 5| Step: 9
Training loss: 2.361435249618517
Validation loss: 2.471607765368146

Epoch: 5| Step: 10
Training loss: 3.13976355737626
Validation loss: 2.4694449697996235

Epoch: 5| Step: 11
Training loss: 1.1814893893727176
Validation loss: 2.4652296430219676

Testing loss: 2.0388896598336954
