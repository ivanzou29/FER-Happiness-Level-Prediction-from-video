Epoch: 1| Step: 0
Training loss: 5.6019254643998435
Validation loss: 5.834712528490195

Epoch: 6| Step: 1
Training loss: 6.709912542691328
Validation loss: 5.833362724593459

Epoch: 6| Step: 2
Training loss: 6.663799750278845
Validation loss: 5.832144625209664

Epoch: 6| Step: 3
Training loss: 5.316454324497922
Validation loss: 5.830926952838073

Epoch: 6| Step: 4
Training loss: 5.423285133289867
Validation loss: 5.829695475516703

Epoch: 6| Step: 5
Training loss: 7.044678474707822
Validation loss: 5.828511624982221

Epoch: 6| Step: 6
Training loss: 4.958990144369428
Validation loss: 5.827215865256359

Epoch: 6| Step: 7
Training loss: 5.8226590540295815
Validation loss: 5.826017624316462

Epoch: 6| Step: 8
Training loss: 6.3570948456593745
Validation loss: 5.8247591309961235

Epoch: 6| Step: 9
Training loss: 6.318592719319446
Validation loss: 5.823419984778029

Epoch: 6| Step: 10
Training loss: 5.829958711612078
Validation loss: 5.8220819774671515

Epoch: 6| Step: 11
Training loss: 5.852839454084912
Validation loss: 5.820601529107154

Epoch: 6| Step: 12
Training loss: 5.241725759168078
Validation loss: 5.819179839453859

Epoch: 6| Step: 13
Training loss: 5.65380047610529
Validation loss: 5.81767272482971

Epoch: 2| Step: 0
Training loss: 4.877793709785165
Validation loss: 5.816128763651083

Epoch: 6| Step: 1
Training loss: 5.511141329771345
Validation loss: 5.814600329190323

Epoch: 6| Step: 2
Training loss: 6.18851223767234
Validation loss: 5.812933245957361

Epoch: 6| Step: 3
Training loss: 6.106539251061591
Validation loss: 5.811255892710065

Epoch: 6| Step: 4
Training loss: 6.122723526151213
Validation loss: 5.809394909443426

Epoch: 6| Step: 5
Training loss: 6.020280894066076
Validation loss: 5.80756006917816

Epoch: 6| Step: 6
Training loss: 6.271232854170739
Validation loss: 5.805434276930378

Epoch: 6| Step: 7
Training loss: 6.315898320448032
Validation loss: 5.803487976368508

Epoch: 6| Step: 8
Training loss: 5.085640472317314
Validation loss: 5.8013864186554915

Epoch: 6| Step: 9
Training loss: 5.843281936259887
Validation loss: 5.799110906791242

Epoch: 6| Step: 10
Training loss: 6.253126659326367
Validation loss: 5.796736750706432

Epoch: 6| Step: 11
Training loss: 6.118284943064621
Validation loss: 5.794247095866639

Epoch: 6| Step: 12
Training loss: 6.0721883538827495
Validation loss: 5.791698602089782

Epoch: 6| Step: 13
Training loss: 5.8822496203156085
Validation loss: 5.7889132735718505

Epoch: 3| Step: 0
Training loss: 5.5376160620244
Validation loss: 5.785943100792886

Epoch: 6| Step: 1
Training loss: 5.226317258820378
Validation loss: 5.782971484968912

Epoch: 6| Step: 2
Training loss: 6.128741931353678
Validation loss: 5.779778920557782

Epoch: 6| Step: 3
Training loss: 6.11092331722977
Validation loss: 5.776502787486307

Epoch: 6| Step: 4
Training loss: 5.123020813410646
Validation loss: 5.772865525175962

Epoch: 6| Step: 5
Training loss: 6.52052470523965
Validation loss: 5.769083145567799

Epoch: 6| Step: 6
Training loss: 5.64806148390764
Validation loss: 5.765046818662485

Epoch: 6| Step: 7
Training loss: 6.374636471425038
Validation loss: 5.760919596105624

Epoch: 6| Step: 8
Training loss: 6.455518080222689
Validation loss: 5.756381211940873

Epoch: 6| Step: 9
Training loss: 5.956558639039198
Validation loss: 5.751801139580875

Epoch: 6| Step: 10
Training loss: 6.337493667749857
Validation loss: 5.74695296339234

Epoch: 6| Step: 11
Training loss: 4.878772938405874
Validation loss: 5.741779892482808

Epoch: 6| Step: 12
Training loss: 5.477884043362847
Validation loss: 5.736587804281433

Epoch: 6| Step: 13
Training loss: 6.1893763924124965
Validation loss: 5.731065312983596

Epoch: 4| Step: 0
Training loss: 5.307988663547027
Validation loss: 5.725423646713535

Epoch: 6| Step: 1
Training loss: 6.230547425541662
Validation loss: 5.71938321858587

Epoch: 6| Step: 2
Training loss: 5.793614707116078
Validation loss: 5.713355794808307

Epoch: 6| Step: 3
Training loss: 6.188584974319655
Validation loss: 5.70706492158851

Epoch: 6| Step: 4
Training loss: 5.834786297726483
Validation loss: 5.700712263210832

Epoch: 6| Step: 5
Training loss: 4.534160862919947
Validation loss: 5.694168987693335

Epoch: 6| Step: 6
Training loss: 5.1170521958495625
Validation loss: 5.687244395566338

Epoch: 6| Step: 7
Training loss: 5.542076248674152
Validation loss: 5.6806552487521875

Epoch: 6| Step: 8
Training loss: 5.802317899371862
Validation loss: 5.6733559600761385

Epoch: 6| Step: 9
Training loss: 6.528510144140732
Validation loss: 5.666852312225962

Epoch: 6| Step: 10
Training loss: 6.534572504562392
Validation loss: 5.659318516640903

Epoch: 6| Step: 11
Training loss: 6.315413907245052
Validation loss: 5.651828196647214

Epoch: 6| Step: 12
Training loss: 5.979092091306851
Validation loss: 5.64462214730012

Epoch: 6| Step: 13
Training loss: 5.072638261846283
Validation loss: 5.637093746324092

Epoch: 5| Step: 0
Training loss: 6.022648978665023
Validation loss: 5.629384373714616

Epoch: 6| Step: 1
Training loss: 6.315438068384921
Validation loss: 5.621517502092889

Epoch: 6| Step: 2
Training loss: 6.088253731251166
Validation loss: 5.61401356747334

Epoch: 6| Step: 3
Training loss: 5.37541782618154
Validation loss: 5.606263214061733

Epoch: 6| Step: 4
Training loss: 5.246425319938836
Validation loss: 5.59865362240122

Epoch: 6| Step: 5
Training loss: 5.107457352290742
Validation loss: 5.591025600079308

Epoch: 6| Step: 6
Training loss: 5.574555780477778
Validation loss: 5.583202313076782

Epoch: 6| Step: 7
Training loss: 5.8638322890213646
Validation loss: 5.57580834588331

Epoch: 6| Step: 8
Training loss: 6.1605859968203305
Validation loss: 5.568455140784343

Epoch: 6| Step: 9
Training loss: 5.39242178784608
Validation loss: 5.560677419098618

Epoch: 6| Step: 10
Training loss: 5.480909681901546
Validation loss: 5.553024765652796

Epoch: 6| Step: 11
Training loss: 5.480508424883118
Validation loss: 5.5454561666532705

Epoch: 6| Step: 12
Training loss: 5.748394617624267
Validation loss: 5.538043661533005

Epoch: 6| Step: 13
Training loss: 5.757702850995467
Validation loss: 5.530591160389098

Epoch: 6| Step: 0
Training loss: 4.481591613602614
Validation loss: 5.523115538080742

Epoch: 6| Step: 1
Training loss: 5.71733300836287
Validation loss: 5.51602753493251

Epoch: 6| Step: 2
Training loss: 5.893106681527434
Validation loss: 5.508836929608337

Epoch: 6| Step: 3
Training loss: 4.798237858615552
Validation loss: 5.50143757730394

Epoch: 6| Step: 4
Training loss: 6.2487770409942325
Validation loss: 5.494462664790083

Epoch: 6| Step: 5
Training loss: 5.941954537899861
Validation loss: 5.486927507178752

Epoch: 6| Step: 6
Training loss: 6.222259604629362
Validation loss: 5.479863672440244

Epoch: 6| Step: 7
Training loss: 5.499344353176962
Validation loss: 5.4726116678698755

Epoch: 6| Step: 8
Training loss: 4.579856779366232
Validation loss: 5.465515051859659

Epoch: 6| Step: 9
Training loss: 5.341725283741013
Validation loss: 5.458232043930508

Epoch: 6| Step: 10
Training loss: 5.559832329726137
Validation loss: 5.451411520012641

Epoch: 6| Step: 11
Training loss: 5.873814239962474
Validation loss: 5.44457176712702

Epoch: 6| Step: 12
Training loss: 5.554266504571832
Validation loss: 5.4376254012457

Epoch: 6| Step: 13
Training loss: 6.2274305631180695
Validation loss: 5.430754968744026

Epoch: 7| Step: 0
Training loss: 5.443153686798258
Validation loss: 5.424110647922156

Epoch: 6| Step: 1
Training loss: 5.45881037289773
Validation loss: 5.416956008617016

Epoch: 6| Step: 2
Training loss: 6.385248062704035
Validation loss: 5.410581701927326

Epoch: 6| Step: 3
Training loss: 5.805346609408528
Validation loss: 5.403338785908086

Epoch: 6| Step: 4
Training loss: 5.558541421650652
Validation loss: 5.396656793432568

Epoch: 6| Step: 5
Training loss: 5.39037802310131
Validation loss: 5.3899769269063675

Epoch: 6| Step: 6
Training loss: 6.188592679422895
Validation loss: 5.383235477388769

Epoch: 6| Step: 7
Training loss: 5.626329731065873
Validation loss: 5.375873583397211

Epoch: 6| Step: 8
Training loss: 4.846431457570075
Validation loss: 5.368741169198012

Epoch: 6| Step: 9
Training loss: 5.4212508927991685
Validation loss: 5.361770761696994

Epoch: 6| Step: 10
Training loss: 4.992036963448247
Validation loss: 5.355196080777835

Epoch: 6| Step: 11
Training loss: 5.334443672153811
Validation loss: 5.348289182929883

Epoch: 6| Step: 12
Training loss: 5.144059445608697
Validation loss: 5.342017028474868

Epoch: 6| Step: 13
Training loss: 5.228448866659168
Validation loss: 5.335859812910554

Epoch: 8| Step: 0
Training loss: 5.4795625879622465
Validation loss: 5.329913930669188

Epoch: 6| Step: 1
Training loss: 5.23312335635863
Validation loss: 5.323894234290514

Epoch: 6| Step: 2
Training loss: 5.428421509615808
Validation loss: 5.318029241440609

Epoch: 6| Step: 3
Training loss: 5.714114452247931
Validation loss: 5.3120540955347515

Epoch: 6| Step: 4
Training loss: 5.386823203641913
Validation loss: 5.306268275768258

Epoch: 6| Step: 5
Training loss: 5.89499524453629
Validation loss: 5.300049017433603

Epoch: 6| Step: 6
Training loss: 5.717583208967303
Validation loss: 5.29426671028133

Epoch: 6| Step: 7
Training loss: 5.939248239231696
Validation loss: 5.287466600100673

Epoch: 6| Step: 8
Training loss: 5.861069091035575
Validation loss: 5.281068486512231

Epoch: 6| Step: 9
Training loss: 5.64406322400039
Validation loss: 5.274532854267713

Epoch: 6| Step: 10
Training loss: 5.030296093092303
Validation loss: 5.268088167434181

Epoch: 6| Step: 11
Training loss: 5.107831902757389
Validation loss: 5.2616041700107195

Epoch: 6| Step: 12
Training loss: 4.290745806122044
Validation loss: 5.255573614132919

Epoch: 6| Step: 13
Training loss: 4.799344002084222
Validation loss: 5.248944766852316

Epoch: 9| Step: 0
Training loss: 4.732558100082269
Validation loss: 5.243270587792266

Epoch: 6| Step: 1
Training loss: 5.634579110322996
Validation loss: 5.237100770190713

Epoch: 6| Step: 2
Training loss: 4.349010109355278
Validation loss: 5.2309209102543255

Epoch: 6| Step: 3
Training loss: 5.475022560665383
Validation loss: 5.22489190119088

Epoch: 6| Step: 4
Training loss: 5.749500418811879
Validation loss: 5.218624090628869

Epoch: 6| Step: 5
Training loss: 5.156184525507595
Validation loss: 5.212424977690417

Epoch: 6| Step: 6
Training loss: 4.901535976777139
Validation loss: 5.205989305091255

Epoch: 6| Step: 7
Training loss: 5.9704887693571225
Validation loss: 5.1998739691891425

Epoch: 6| Step: 8
Training loss: 6.3836276445526545
Validation loss: 5.193241083128091

Epoch: 6| Step: 9
Training loss: 5.6141272685781685
Validation loss: 5.186695082389705

Epoch: 6| Step: 10
Training loss: 5.712996460023942
Validation loss: 5.180593680797442

Epoch: 6| Step: 11
Training loss: 4.521496186539648
Validation loss: 5.173982926334522

Epoch: 6| Step: 12
Training loss: 4.338250280565446
Validation loss: 5.167605601897132

Epoch: 6| Step: 13
Training loss: 5.520740589826355
Validation loss: 5.161629508137968

Epoch: 10| Step: 0
Training loss: 6.487753555546771
Validation loss: 5.155820115790107

Epoch: 6| Step: 1
Training loss: 5.965250477292294
Validation loss: 5.149672781168993

Epoch: 6| Step: 2
Training loss: 4.638966479131621
Validation loss: 5.143612257456204

Epoch: 6| Step: 3
Training loss: 5.445790952572555
Validation loss: 5.1377297454474835

Epoch: 6| Step: 4
Training loss: 5.538094117130488
Validation loss: 5.132556090199402

Epoch: 6| Step: 5
Training loss: 4.30099988445751
Validation loss: 5.126585211253491

Epoch: 6| Step: 6
Training loss: 4.84107296707395
Validation loss: 5.1209517827107085

Epoch: 6| Step: 7
Training loss: 3.6848841295180006
Validation loss: 5.1159068128436616

Epoch: 6| Step: 8
Training loss: 5.945788571198814
Validation loss: 5.1110474068822676

Epoch: 6| Step: 9
Training loss: 5.4693964112945626
Validation loss: 5.105585962305762

Epoch: 6| Step: 10
Training loss: 5.493347305971418
Validation loss: 5.100535766035396

Epoch: 6| Step: 11
Training loss: 5.483541311167382
Validation loss: 5.095132246263413

Epoch: 6| Step: 12
Training loss: 4.86752136946789
Validation loss: 5.089388924861152

Epoch: 6| Step: 13
Training loss: 4.555602830677725
Validation loss: 5.084046121037433

Epoch: 11| Step: 0
Training loss: 4.094589263848576
Validation loss: 5.079290449946188

Epoch: 6| Step: 1
Training loss: 5.505974732185469
Validation loss: 5.074410325041844

Epoch: 6| Step: 2
Training loss: 5.783201475958056
Validation loss: 5.069306244846178

Epoch: 6| Step: 3
Training loss: 4.832337156217209
Validation loss: 5.064489374056785

Epoch: 6| Step: 4
Training loss: 4.594986729649423
Validation loss: 5.059008426435795

Epoch: 6| Step: 5
Training loss: 5.720676785425024
Validation loss: 5.053832212212347

Epoch: 6| Step: 6
Training loss: 4.269757068522088
Validation loss: 5.04805937767473

Epoch: 6| Step: 7
Training loss: 5.716510938890358
Validation loss: 5.043143232199713

Epoch: 6| Step: 8
Training loss: 5.364230344942648
Validation loss: 5.0381623166397285

Epoch: 6| Step: 9
Training loss: 5.479421786133238
Validation loss: 5.0331160281600456

Epoch: 6| Step: 10
Training loss: 5.801315868671992
Validation loss: 5.027457567184804

Epoch: 6| Step: 11
Training loss: 5.596033748958491
Validation loss: 5.021632509483617

Epoch: 6| Step: 12
Training loss: 4.496391545035811
Validation loss: 5.0166591318946265

Epoch: 6| Step: 13
Training loss: 4.633795957087863
Validation loss: 5.012165766200994

Epoch: 12| Step: 0
Training loss: 4.649180941074628
Validation loss: 5.006255591711255

Epoch: 6| Step: 1
Training loss: 5.0839581131669
Validation loss: 5.000683515241548

Epoch: 6| Step: 2
Training loss: 4.802207343871686
Validation loss: 4.9959502349911995

Epoch: 6| Step: 3
Training loss: 5.406212779010689
Validation loss: 4.991458463492753

Epoch: 6| Step: 4
Training loss: 4.194371975798321
Validation loss: 4.986315884483605

Epoch: 6| Step: 5
Training loss: 5.96744926619648
Validation loss: 4.981063555934053

Epoch: 6| Step: 6
Training loss: 4.7862379198377685
Validation loss: 4.975429819220278

Epoch: 6| Step: 7
Training loss: 5.254243135110095
Validation loss: 4.9702932652222485

Epoch: 6| Step: 8
Training loss: 4.993798415387368
Validation loss: 4.966186853995201

Epoch: 6| Step: 9
Training loss: 4.768787772852737
Validation loss: 4.960975178252586

Epoch: 6| Step: 10
Training loss: 5.278056064876027
Validation loss: 4.954972493197671

Epoch: 6| Step: 11
Training loss: 5.229142674040244
Validation loss: 4.950803643953975

Epoch: 6| Step: 12
Training loss: 5.712658582360167
Validation loss: 4.945972207788934

Epoch: 6| Step: 13
Training loss: 4.981226198529632
Validation loss: 4.940593635576952

Epoch: 13| Step: 0
Training loss: 4.828063766930676
Validation loss: 4.935507102557481

Epoch: 6| Step: 1
Training loss: 4.8017362633299765
Validation loss: 4.930170228016849

Epoch: 6| Step: 2
Training loss: 4.788165906206815
Validation loss: 4.925618777316937

Epoch: 6| Step: 3
Training loss: 5.136753653636169
Validation loss: 4.9212202655932975

Epoch: 6| Step: 4
Training loss: 4.965951575360771
Validation loss: 4.915646700478728

Epoch: 6| Step: 5
Training loss: 4.651294093385632
Validation loss: 4.910782196764342

Epoch: 6| Step: 6
Training loss: 5.1048042781422724
Validation loss: 4.9061359951113115

Epoch: 6| Step: 7
Training loss: 5.292803344394314
Validation loss: 4.901233773380171

Epoch: 6| Step: 8
Training loss: 5.191879997136209
Validation loss: 4.896291908810022

Epoch: 6| Step: 9
Training loss: 5.468817138259756
Validation loss: 4.89156749284714

Epoch: 6| Step: 10
Training loss: 5.227020289239939
Validation loss: 4.886051692508589

Epoch: 6| Step: 11
Training loss: 4.841708435998974
Validation loss: 4.881405982318734

Epoch: 6| Step: 12
Training loss: 5.46470413956765
Validation loss: 4.877230826647156

Epoch: 6| Step: 13
Training loss: 4.534066844014995
Validation loss: 4.872125071334261

Epoch: 14| Step: 0
Training loss: 4.877690477586867
Validation loss: 4.8670575087299

Epoch: 6| Step: 1
Training loss: 5.670851601994687
Validation loss: 4.86232665471288

Epoch: 6| Step: 2
Training loss: 5.605539184553128
Validation loss: 4.857627071826453

Epoch: 6| Step: 3
Training loss: 5.1692127394274445
Validation loss: 4.853002689717431

Epoch: 6| Step: 4
Training loss: 5.281522303677064
Validation loss: 4.848029430451151

Epoch: 6| Step: 5
Training loss: 5.028266733091168
Validation loss: 4.84217697360698

Epoch: 6| Step: 6
Training loss: 4.348184421534104
Validation loss: 4.837249692869511

Epoch: 6| Step: 7
Training loss: 3.7550632626909928
Validation loss: 4.83379813403857

Epoch: 6| Step: 8
Training loss: 4.127055956258513
Validation loss: 4.8287305400738365

Epoch: 6| Step: 9
Training loss: 4.5609609019772615
Validation loss: 4.822603148231844

Epoch: 6| Step: 10
Training loss: 5.53276515402866
Validation loss: 4.817651262374874

Epoch: 6| Step: 11
Training loss: 5.1552363468605575
Validation loss: 4.8134609105294315

Epoch: 6| Step: 12
Training loss: 4.753257838894058
Validation loss: 4.808402691125483

Epoch: 6| Step: 13
Training loss: 5.186464137329279
Validation loss: 4.803879915509451

Epoch: 15| Step: 0
Training loss: 5.144322512019053
Validation loss: 4.799180627135656

Epoch: 6| Step: 1
Training loss: 3.9197005973061225
Validation loss: 4.792761083372171

Epoch: 6| Step: 2
Training loss: 4.790630637686262
Validation loss: 4.78843323896906

Epoch: 6| Step: 3
Training loss: 5.104064608221798
Validation loss: 4.7844214797798905

Epoch: 6| Step: 4
Training loss: 5.6077395634493055
Validation loss: 4.7798346791215565

Epoch: 6| Step: 5
Training loss: 4.800897260091402
Validation loss: 4.774966447189709

Epoch: 6| Step: 6
Training loss: 4.626461725963659
Validation loss: 4.769664982267672

Epoch: 6| Step: 7
Training loss: 4.556348860810183
Validation loss: 4.766193560261028

Epoch: 6| Step: 8
Training loss: 4.44298547533998
Validation loss: 4.760465269724048

Epoch: 6| Step: 9
Training loss: 5.270378163502893
Validation loss: 4.755715695821185

Epoch: 6| Step: 10
Training loss: 5.663618988562651
Validation loss: 4.750439472949553

Epoch: 6| Step: 11
Training loss: 4.50394817508132
Validation loss: 4.746927137425487

Epoch: 6| Step: 12
Training loss: 4.27727730756044
Validation loss: 4.743436293852836

Epoch: 6| Step: 13
Training loss: 5.4493137802533615
Validation loss: 4.738021168354625

Epoch: 16| Step: 0
Training loss: 5.052951992378344
Validation loss: 4.731765817049258

Epoch: 6| Step: 1
Training loss: 4.776238900885306
Validation loss: 4.728537759961487

Epoch: 6| Step: 2
Training loss: 5.351794874060799
Validation loss: 4.724736035759562

Epoch: 6| Step: 3
Training loss: 5.245918140326798
Validation loss: 4.718451719982881

Epoch: 6| Step: 4
Training loss: 5.586559938550868
Validation loss: 4.712032631550066

Epoch: 6| Step: 5
Training loss: 4.7941928783283485
Validation loss: 4.707049585836953

Epoch: 6| Step: 6
Training loss: 5.138750192414403
Validation loss: 4.701488560806915

Epoch: 6| Step: 7
Training loss: 5.3075092883754245
Validation loss: 4.695717894052766

Epoch: 6| Step: 8
Training loss: 4.749325352994228
Validation loss: 4.69024694699518

Epoch: 6| Step: 9
Training loss: 4.311028713299708
Validation loss: 4.683441931708728

Epoch: 6| Step: 10
Training loss: 3.8657909607475243
Validation loss: 4.679106967688993

Epoch: 6| Step: 11
Training loss: 4.369484394653684
Validation loss: 4.673790818504038

Epoch: 6| Step: 12
Training loss: 4.096826227452106
Validation loss: 4.668379157205867

Epoch: 6| Step: 13
Training loss: 4.586003629607317
Validation loss: 4.662849374998614

Epoch: 17| Step: 0
Training loss: 5.483614181391361
Validation loss: 4.6571615978084555

Epoch: 6| Step: 1
Training loss: 4.986736634999456
Validation loss: 4.652605888013081

Epoch: 6| Step: 2
Training loss: 4.8943494563580305
Validation loss: 4.646943693801268

Epoch: 6| Step: 3
Training loss: 4.776830088838396
Validation loss: 4.640836939911626

Epoch: 6| Step: 4
Training loss: 4.900836460575446
Validation loss: 4.636436841622516

Epoch: 6| Step: 5
Training loss: 4.799841544396894
Validation loss: 4.630293935092459

Epoch: 6| Step: 6
Training loss: 4.345470060463738
Validation loss: 4.625189356321296

Epoch: 6| Step: 7
Training loss: 5.282919715711781
Validation loss: 4.619958965565155

Epoch: 6| Step: 8
Training loss: 4.905188962074969
Validation loss: 4.614832691260962

Epoch: 6| Step: 9
Training loss: 3.73556359181727
Validation loss: 4.609443655418694

Epoch: 6| Step: 10
Training loss: 4.1049850861328405
Validation loss: 4.60428737752566

Epoch: 6| Step: 11
Training loss: 4.907197702806928
Validation loss: 4.59923269534223

Epoch: 6| Step: 12
Training loss: 4.533870807276086
Validation loss: 4.594158958863596

Epoch: 6| Step: 13
Training loss: 4.594162695375735
Validation loss: 4.5892430208604775

Epoch: 18| Step: 0
Training loss: 4.284441572766992
Validation loss: 4.583799384726401

Epoch: 6| Step: 1
Training loss: 3.5646388008146683
Validation loss: 4.578880586212151

Epoch: 6| Step: 2
Training loss: 4.313248279171214
Validation loss: 4.575044118255069

Epoch: 6| Step: 3
Training loss: 4.877311745299847
Validation loss: 4.569742698688226

Epoch: 6| Step: 4
Training loss: 4.690435278891369
Validation loss: 4.565030341268641

Epoch: 6| Step: 5
Training loss: 4.116468218345839
Validation loss: 4.560440365012494

Epoch: 6| Step: 6
Training loss: 5.516134352034698
Validation loss: 4.55543893119479

Epoch: 6| Step: 7
Training loss: 5.0273012575904295
Validation loss: 4.550440383391512

Epoch: 6| Step: 8
Training loss: 4.999821468980636
Validation loss: 4.544532460839968

Epoch: 6| Step: 9
Training loss: 5.294883150967306
Validation loss: 4.540709450083647

Epoch: 6| Step: 10
Training loss: 4.600311368272651
Validation loss: 4.535328820422916

Epoch: 6| Step: 11
Training loss: 4.454580825283058
Validation loss: 4.530323714366323

Epoch: 6| Step: 12
Training loss: 5.157791369700261
Validation loss: 4.525780263828543

Epoch: 6| Step: 13
Training loss: 4.222719712534788
Validation loss: 4.520306335297333

Epoch: 19| Step: 0
Training loss: 4.963414044122118
Validation loss: 4.514051504221872

Epoch: 6| Step: 1
Training loss: 4.145475030236988
Validation loss: 4.509236182007924

Epoch: 6| Step: 2
Training loss: 4.232435845183451
Validation loss: 4.505060211863123

Epoch: 6| Step: 3
Training loss: 4.166969186608948
Validation loss: 4.499699723856998

Epoch: 6| Step: 4
Training loss: 4.239076826252054
Validation loss: 4.495019947441969

Epoch: 6| Step: 5
Training loss: 4.841309948034669
Validation loss: 4.48934168803298

Epoch: 6| Step: 6
Training loss: 5.49900271303922
Validation loss: 4.484369045346656

Epoch: 6| Step: 7
Training loss: 4.460239656449948
Validation loss: 4.479623472591988

Epoch: 6| Step: 8
Training loss: 4.640413940973273
Validation loss: 4.474643813152932

Epoch: 6| Step: 9
Training loss: 5.090450411730489
Validation loss: 4.470697507664484

Epoch: 6| Step: 10
Training loss: 4.261066390334339
Validation loss: 4.463983443426605

Epoch: 6| Step: 11
Training loss: 4.210917117152663
Validation loss: 4.458952542855697

Epoch: 6| Step: 12
Training loss: 4.6620433021213445
Validation loss: 4.453983014528148

Epoch: 6| Step: 13
Training loss: 4.890200270469783
Validation loss: 4.449712291089172

Epoch: 20| Step: 0
Training loss: 4.679403407878199
Validation loss: 4.444961435660616

Epoch: 6| Step: 1
Training loss: 5.184362358827453
Validation loss: 4.439633622131559

Epoch: 6| Step: 2
Training loss: 3.666149334102664
Validation loss: 4.433821752121959

Epoch: 6| Step: 3
Training loss: 4.0969509976086655
Validation loss: 4.429605455216235

Epoch: 6| Step: 4
Training loss: 5.688914699462778
Validation loss: 4.423989876434902

Epoch: 6| Step: 5
Training loss: 4.876774782732348
Validation loss: 4.419143282282765

Epoch: 6| Step: 6
Training loss: 3.5942869365784498
Validation loss: 4.415214923769785

Epoch: 6| Step: 7
Training loss: 4.8641743893104845
Validation loss: 4.414634428978257

Epoch: 6| Step: 8
Training loss: 4.4351207103451005
Validation loss: 4.405185579914833

Epoch: 6| Step: 9
Training loss: 4.607736276828542
Validation loss: 4.39946023491309

Epoch: 6| Step: 10
Training loss: 4.689859025540465
Validation loss: 4.396333072453423

Epoch: 6| Step: 11
Training loss: 4.3465652673591695
Validation loss: 4.392393939164042

Epoch: 6| Step: 12
Training loss: 4.092040658758132
Validation loss: 4.386948898496634

Epoch: 6| Step: 13
Training loss: 4.3282754920107855
Validation loss: 4.381158508709576

Epoch: 21| Step: 0
Training loss: 4.660746815969342
Validation loss: 4.376560949969695

Epoch: 6| Step: 1
Training loss: 5.132485668164222
Validation loss: 4.372010544808699

Epoch: 6| Step: 2
Training loss: 4.3640112065661745
Validation loss: 4.367067375191557

Epoch: 6| Step: 3
Training loss: 4.769790779819588
Validation loss: 4.362010473641926

Epoch: 6| Step: 4
Training loss: 4.279148003457937
Validation loss: 4.35735599702274

Epoch: 6| Step: 5
Training loss: 4.438769091879571
Validation loss: 4.351336287823058

Epoch: 6| Step: 6
Training loss: 4.5053056592479885
Validation loss: 4.3462969039274615

Epoch: 6| Step: 7
Training loss: 4.67906773304938
Validation loss: 4.341426676281726

Epoch: 6| Step: 8
Training loss: 3.550500302588586
Validation loss: 4.3363055282062195

Epoch: 6| Step: 9
Training loss: 4.355305621594783
Validation loss: 4.332199345667675

Epoch: 6| Step: 10
Training loss: 4.793518681521713
Validation loss: 4.3276620151303105

Epoch: 6| Step: 11
Training loss: 3.8827002526374677
Validation loss: 4.32341906221128

Epoch: 6| Step: 12
Training loss: 4.849599935804346
Validation loss: 4.318004430811301

Epoch: 6| Step: 13
Training loss: 4.151288505818997
Validation loss: 4.313614153105179

Epoch: 22| Step: 0
Training loss: 4.104199533605245
Validation loss: 4.308643035283998

Epoch: 6| Step: 1
Training loss: 4.069909015360238
Validation loss: 4.303679988164944

Epoch: 6| Step: 2
Training loss: 4.727144971535058
Validation loss: 4.298985151548166

Epoch: 6| Step: 3
Training loss: 4.726022938598808
Validation loss: 4.295279540741154

Epoch: 6| Step: 4
Training loss: 3.8275193338634663
Validation loss: 4.290500920801405

Epoch: 6| Step: 5
Training loss: 3.841375470382395
Validation loss: 4.285681628299598

Epoch: 6| Step: 6
Training loss: 5.59624523579299
Validation loss: 4.28127828992421

Epoch: 6| Step: 7
Training loss: 3.6745025972862475
Validation loss: 4.276756806071584

Epoch: 6| Step: 8
Training loss: 3.523189290644197
Validation loss: 4.274188490021232

Epoch: 6| Step: 9
Training loss: 3.6976559972450658
Validation loss: 4.271062885101031

Epoch: 6| Step: 10
Training loss: 4.892104245077178
Validation loss: 4.268523520497919

Epoch: 6| Step: 11
Training loss: 4.885900976363528
Validation loss: 4.262257757229913

Epoch: 6| Step: 12
Training loss: 4.775686180782239
Validation loss: 4.25743714524182

Epoch: 6| Step: 13
Training loss: 4.826116545362724
Validation loss: 4.251358899549356

Epoch: 23| Step: 0
Training loss: 4.288503252545662
Validation loss: 4.246659237412482

Epoch: 6| Step: 1
Training loss: 4.330264447530529
Validation loss: 4.2421157109583305

Epoch: 6| Step: 2
Training loss: 3.8294586972416083
Validation loss: 4.238110310612916

Epoch: 6| Step: 3
Training loss: 3.8554775311371
Validation loss: 4.233944879249044

Epoch: 6| Step: 4
Training loss: 4.960676051181494
Validation loss: 4.228107257062398

Epoch: 6| Step: 5
Training loss: 4.248903918574453
Validation loss: 4.222563971664827

Epoch: 6| Step: 6
Training loss: 4.495935723968662
Validation loss: 4.217202927235062

Epoch: 6| Step: 7
Training loss: 4.197134066473008
Validation loss: 4.212571543643495

Epoch: 6| Step: 8
Training loss: 4.293693335546543
Validation loss: 4.208653837532379

Epoch: 6| Step: 9
Training loss: 4.424916868991478
Validation loss: 4.204562219184863

Epoch: 6| Step: 10
Training loss: 4.29625261827777
Validation loss: 4.200083864979329

Epoch: 6| Step: 11
Training loss: 4.399235546287972
Validation loss: 4.1942045713020955

Epoch: 6| Step: 12
Training loss: 4.2095974575242385
Validation loss: 4.1893573646301325

Epoch: 6| Step: 13
Training loss: 4.882862695054499
Validation loss: 4.184660693883672

Epoch: 24| Step: 0
Training loss: 4.413819216885271
Validation loss: 4.180120503941231

Epoch: 6| Step: 1
Training loss: 4.716151248192237
Validation loss: 4.1757116308971804

Epoch: 6| Step: 2
Training loss: 4.418821756732607
Validation loss: 4.1710943475096345

Epoch: 6| Step: 3
Training loss: 4.447387425593826
Validation loss: 4.166429105980069

Epoch: 6| Step: 4
Training loss: 4.3586278569113865
Validation loss: 4.161176854219621

Epoch: 6| Step: 5
Training loss: 3.7550348179164263
Validation loss: 4.15685824195697

Epoch: 6| Step: 6
Training loss: 4.2002533245892035
Validation loss: 4.1529079375748275

Epoch: 6| Step: 7
Training loss: 4.870907165820551
Validation loss: 4.148307304949478

Epoch: 6| Step: 8
Training loss: 2.8875432263065886
Validation loss: 4.143149320199479

Epoch: 6| Step: 9
Training loss: 3.8288290816561195
Validation loss: 4.138726870603613

Epoch: 6| Step: 10
Training loss: 4.448474048053014
Validation loss: 4.134506868588691

Epoch: 6| Step: 11
Training loss: 4.406216668618391
Validation loss: 4.1300453965260635

Epoch: 6| Step: 12
Training loss: 3.984844703663732
Validation loss: 4.125739638168008

Epoch: 6| Step: 13
Training loss: 4.817878788862369
Validation loss: 4.120967589461575

Epoch: 25| Step: 0
Training loss: 4.763850047277855
Validation loss: 4.116161201632105

Epoch: 6| Step: 1
Training loss: 4.684828340200784
Validation loss: 4.111648201583348

Epoch: 6| Step: 2
Training loss: 4.065362244778983
Validation loss: 4.107205938956556

Epoch: 6| Step: 3
Training loss: 4.406072085420735
Validation loss: 4.102536156754803

Epoch: 6| Step: 4
Training loss: 4.404591999189175
Validation loss: 4.098010634233967

Epoch: 6| Step: 5
Training loss: 4.704911105119849
Validation loss: 4.093416506163541

Epoch: 6| Step: 6
Training loss: 4.208131212473252
Validation loss: 4.088515529022576

Epoch: 6| Step: 7
Training loss: 3.8590370678926664
Validation loss: 4.08334758652256

Epoch: 6| Step: 8
Training loss: 3.8823563674326853
Validation loss: 4.078767474978118

Epoch: 6| Step: 9
Training loss: 2.6145517314404345
Validation loss: 4.074572364040009

Epoch: 6| Step: 10
Training loss: 4.601790469469719
Validation loss: 4.069914092360868

Epoch: 6| Step: 11
Training loss: 4.404535271056356
Validation loss: 4.065656931910806

Epoch: 6| Step: 12
Training loss: 3.730391800171677
Validation loss: 4.061582138837035

Epoch: 6| Step: 13
Training loss: 4.268672539160392
Validation loss: 4.057157377959656

Epoch: 26| Step: 0
Training loss: 3.026388615707456
Validation loss: 4.052243083298953

Epoch: 6| Step: 1
Training loss: 4.640498817860474
Validation loss: 4.047937300402554

Epoch: 6| Step: 2
Training loss: 3.7337778803139168
Validation loss: 4.043723235319337

Epoch: 6| Step: 3
Training loss: 4.050880835549627
Validation loss: 4.039752106914108

Epoch: 6| Step: 4
Training loss: 4.870199333983607
Validation loss: 4.0353054377256905

Epoch: 6| Step: 5
Training loss: 4.815500488255876
Validation loss: 4.031000686545768

Epoch: 6| Step: 6
Training loss: 5.394160871891088
Validation loss: 4.026444303539087

Epoch: 6| Step: 7
Training loss: 4.610983564663156
Validation loss: 4.021922002012346

Epoch: 6| Step: 8
Training loss: 3.968380648029038
Validation loss: 4.017001300870118

Epoch: 6| Step: 9
Training loss: 4.248644668786323
Validation loss: 4.012370372670871

Epoch: 6| Step: 10
Training loss: 2.7593260331955523
Validation loss: 4.007529463759841

Epoch: 6| Step: 11
Training loss: 3.998747629568596
Validation loss: 4.003057900471181

Epoch: 6| Step: 12
Training loss: 3.3933493923963907
Validation loss: 3.998406649181449

Epoch: 6| Step: 13
Training loss: 3.8377042535855055
Validation loss: 3.9942019481972344

Epoch: 27| Step: 0
Training loss: 4.401667816342992
Validation loss: 3.989937941658967

Epoch: 6| Step: 1
Training loss: 4.335204136319818
Validation loss: 3.98593920751655

Epoch: 6| Step: 2
Training loss: 4.50445971434036
Validation loss: 3.980588542419697

Epoch: 6| Step: 3
Training loss: 4.156634090717071
Validation loss: 3.975709375226647

Epoch: 6| Step: 4
Training loss: 3.8621213461936446
Validation loss: 3.971317351957522

Epoch: 6| Step: 5
Training loss: 4.457835279554267
Validation loss: 3.9667779223015764

Epoch: 6| Step: 6
Training loss: 3.8182240025555605
Validation loss: 3.961828649470096

Epoch: 6| Step: 7
Training loss: 3.587779384460541
Validation loss: 3.9571054997057113

Epoch: 6| Step: 8
Training loss: 4.494288740904516
Validation loss: 3.952978058547998

Epoch: 6| Step: 9
Training loss: 3.1570788513235017
Validation loss: 3.948194180332828

Epoch: 6| Step: 10
Training loss: 3.8708335873727266
Validation loss: 3.9439317761105173

Epoch: 6| Step: 11
Training loss: 4.284249918396597
Validation loss: 3.9392351434731765

Epoch: 6| Step: 12
Training loss: 3.902601201115575
Validation loss: 3.93506779306544

Epoch: 6| Step: 13
Training loss: 4.246599519958311
Validation loss: 3.9306867477994443

Epoch: 28| Step: 0
Training loss: 4.17896117557438
Validation loss: 3.925914573619698

Epoch: 6| Step: 1
Training loss: 4.701084239160328
Validation loss: 3.9212618446029337

Epoch: 6| Step: 2
Training loss: 4.052738140058492
Validation loss: 3.9168449253071818

Epoch: 6| Step: 3
Training loss: 4.207396198336376
Validation loss: 3.911859294524416

Epoch: 6| Step: 4
Training loss: 4.142315213692681
Validation loss: 3.9075479207646455

Epoch: 6| Step: 5
Training loss: 3.6339957330455093
Validation loss: 3.9026814958333875

Epoch: 6| Step: 6
Training loss: 4.47993914426615
Validation loss: 3.8983343871399128

Epoch: 6| Step: 7
Training loss: 3.8589149849595055
Validation loss: 3.893704157233366

Epoch: 6| Step: 8
Training loss: 3.9303593146614713
Validation loss: 3.8890420126665908

Epoch: 6| Step: 9
Training loss: 3.876126033469984
Validation loss: 3.8843082077491315

Epoch: 6| Step: 10
Training loss: 3.4575586638642157
Validation loss: 3.879786211986456

Epoch: 6| Step: 11
Training loss: 3.2946467530644354
Validation loss: 3.875145263410201

Epoch: 6| Step: 12
Training loss: 4.317718223618736
Validation loss: 3.870824943727751

Epoch: 6| Step: 13
Training loss: 4.079911933023259
Validation loss: 3.8666440228643246

Epoch: 29| Step: 0
Training loss: 3.768864041907301
Validation loss: 3.8618565456535743

Epoch: 6| Step: 1
Training loss: 4.423573737167077
Validation loss: 3.8579130505456543

Epoch: 6| Step: 2
Training loss: 3.6974163881124507
Validation loss: 3.8533124372274306

Epoch: 6| Step: 3
Training loss: 3.7577014676700164
Validation loss: 3.8485097593626745

Epoch: 6| Step: 4
Training loss: 4.026448073443238
Validation loss: 3.8438703109810035

Epoch: 6| Step: 5
Training loss: 4.49990569121825
Validation loss: 3.8393099398603794

Epoch: 6| Step: 6
Training loss: 4.058385085468495
Validation loss: 3.8345857246775856

Epoch: 6| Step: 7
Training loss: 3.5874235776410677
Validation loss: 3.828372039089967

Epoch: 6| Step: 8
Training loss: 3.99816184724159
Validation loss: 3.8230729586522596

Epoch: 6| Step: 9
Training loss: 3.735242288025818
Validation loss: 3.817899434648428

Epoch: 6| Step: 10
Training loss: 3.65214817115052
Validation loss: 3.8128078107135686

Epoch: 6| Step: 11
Training loss: 3.8020456529953632
Validation loss: 3.8091357244919095

Epoch: 6| Step: 12
Training loss: 3.979075538963214
Validation loss: 3.802653516403812

Epoch: 6| Step: 13
Training loss: 4.392073965759584
Validation loss: 3.798534684668642

Epoch: 30| Step: 0
Training loss: 4.004037250143549
Validation loss: 3.794382310572379

Epoch: 6| Step: 1
Training loss: 3.510933284307104
Validation loss: 3.7894647234026237

Epoch: 6| Step: 2
Training loss: 3.0226440965807946
Validation loss: 3.7851579716655226

Epoch: 6| Step: 3
Training loss: 3.95366945399957
Validation loss: 3.780493311136429

Epoch: 6| Step: 4
Training loss: 4.5246727925226295
Validation loss: 3.776723374841377

Epoch: 6| Step: 5
Training loss: 3.8938433346652497
Validation loss: 3.77122501144585

Epoch: 6| Step: 6
Training loss: 3.582106860911366
Validation loss: 3.7665810960710275

Epoch: 6| Step: 7
Training loss: 4.435960959452761
Validation loss: 3.762741567771425

Epoch: 6| Step: 8
Training loss: 3.832061487481046
Validation loss: 3.758927484535256

Epoch: 6| Step: 9
Training loss: 3.5393140421351394
Validation loss: 3.7540865566048423

Epoch: 6| Step: 10
Training loss: 4.003503219044833
Validation loss: 3.749701509252164

Epoch: 6| Step: 11
Training loss: 4.15355577839615
Validation loss: 3.7453450239326576

Epoch: 6| Step: 12
Training loss: 4.043437897372387
Validation loss: 3.7401426245953866

Epoch: 6| Step: 13
Training loss: 3.846009125554392
Validation loss: 3.7354040071549846

Epoch: 31| Step: 0
Training loss: 3.5905662697818728
Validation loss: 3.7309528456146364

Epoch: 6| Step: 1
Training loss: 4.3004146908247725
Validation loss: 3.7262964480240597

Epoch: 6| Step: 2
Training loss: 4.103263923518667
Validation loss: 3.721263346043203

Epoch: 6| Step: 3
Training loss: 3.9428743288009174
Validation loss: 3.716589912055362

Epoch: 6| Step: 4
Training loss: 4.013727712126811
Validation loss: 3.7120214545600043

Epoch: 6| Step: 5
Training loss: 4.181521346748744
Validation loss: 3.707429039812599

Epoch: 6| Step: 6
Training loss: 2.8763320159160504
Validation loss: 3.702461580278493

Epoch: 6| Step: 7
Training loss: 3.482504440929158
Validation loss: 3.697961461328694

Epoch: 6| Step: 8
Training loss: 3.9461736664565286
Validation loss: 3.6940568722248894

Epoch: 6| Step: 9
Training loss: 3.877218780256113
Validation loss: 3.6891000907605993

Epoch: 6| Step: 10
Training loss: 4.018969853440223
Validation loss: 3.6849052869408143

Epoch: 6| Step: 11
Training loss: 4.114719179381614
Validation loss: 3.6799005553381656

Epoch: 6| Step: 12
Training loss: 3.2919440977464953
Validation loss: 3.6757967952300916

Epoch: 6| Step: 13
Training loss: 3.7415488062408624
Validation loss: 3.6713447350243635

Epoch: 32| Step: 0
Training loss: 3.4824514510802387
Validation loss: 3.6669257823825383

Epoch: 6| Step: 1
Training loss: 4.297738505208905
Validation loss: 3.662868259043383

Epoch: 6| Step: 2
Training loss: 4.153593203730379
Validation loss: 3.6586041275692907

Epoch: 6| Step: 3
Training loss: 3.668026729690186
Validation loss: 3.654004312096167

Epoch: 6| Step: 4
Training loss: 3.5789654007182823
Validation loss: 3.649588643587821

Epoch: 6| Step: 5
Training loss: 3.8878373419798407
Validation loss: 3.645562116434935

Epoch: 6| Step: 6
Training loss: 3.6925863327440385
Validation loss: 3.6410545565038013

Epoch: 6| Step: 7
Training loss: 3.7352664154919593
Validation loss: 3.636458101093187

Epoch: 6| Step: 8
Training loss: 3.8522713339719457
Validation loss: 3.632107617757022

Epoch: 6| Step: 9
Training loss: 3.750053151071896
Validation loss: 3.6278252608414676

Epoch: 6| Step: 10
Training loss: 3.8436104353711555
Validation loss: 3.6232668142403894

Epoch: 6| Step: 11
Training loss: 3.5995698989798215
Validation loss: 3.619351359787342

Epoch: 6| Step: 12
Training loss: 3.9641038025661652
Validation loss: 3.614579602916599

Epoch: 6| Step: 13
Training loss: 3.247397628004633
Validation loss: 3.6106797759519162

Epoch: 33| Step: 0
Training loss: 4.347869017845166
Validation loss: 3.6061235014503885

Epoch: 6| Step: 1
Training loss: 3.686471957422013
Validation loss: 3.601912784160902

Epoch: 6| Step: 2
Training loss: 4.1580801928164615
Validation loss: 3.5976730605846505

Epoch: 6| Step: 3
Training loss: 3.4740465296921843
Validation loss: 3.593276791584803

Epoch: 6| Step: 4
Training loss: 3.406539204770392
Validation loss: 3.5890600810902935

Epoch: 6| Step: 5
Training loss: 3.9202922651757706
Validation loss: 3.584534569414188

Epoch: 6| Step: 6
Training loss: 3.860324140586895
Validation loss: 3.579900087493214

Epoch: 6| Step: 7
Training loss: 3.169888329930718
Validation loss: 3.575870875565482

Epoch: 6| Step: 8
Training loss: 2.8315265916198444
Validation loss: 3.5717892364769828

Epoch: 6| Step: 9
Training loss: 3.76773050414377
Validation loss: 3.5673571040141496

Epoch: 6| Step: 10
Training loss: 3.9624338427294674
Validation loss: 3.563532941655719

Epoch: 6| Step: 11
Training loss: 3.6313426335874404
Validation loss: 3.5591383795364764

Epoch: 6| Step: 12
Training loss: 3.5446212262745855
Validation loss: 3.5550834463191667

Epoch: 6| Step: 13
Training loss: 4.009029211176249
Validation loss: 3.55104126098905

Epoch: 34| Step: 0
Training loss: 2.9553453283028506
Validation loss: 3.546985551676878

Epoch: 6| Step: 1
Training loss: 3.438510815515631
Validation loss: 3.543532220516607

Epoch: 6| Step: 2
Training loss: 3.67508508492929
Validation loss: 3.5396722600916464

Epoch: 6| Step: 3
Training loss: 3.7121508090526696
Validation loss: 3.5352226012239845

Epoch: 6| Step: 4
Training loss: 3.4259610797655538
Validation loss: 3.531259609873251

Epoch: 6| Step: 5
Training loss: 3.5951665325615427
Validation loss: 3.527231275892299

Epoch: 6| Step: 6
Training loss: 3.927174426303137
Validation loss: 3.523125904681586

Epoch: 6| Step: 7
Training loss: 3.8263872211604206
Validation loss: 3.5193042632536256

Epoch: 6| Step: 8
Training loss: 3.091238832989617
Validation loss: 3.515487193479665

Epoch: 6| Step: 9
Training loss: 4.089063684786201
Validation loss: 3.5113853378351036

Epoch: 6| Step: 10
Training loss: 4.097659508310191
Validation loss: 3.507305672216063

Epoch: 6| Step: 11
Training loss: 3.3688956262822525
Validation loss: 3.5027180063497596

Epoch: 6| Step: 12
Training loss: 4.20145834172679
Validation loss: 3.4992049540379555

Epoch: 6| Step: 13
Training loss: 3.5700646111975343
Validation loss: 3.494772663244816

Epoch: 35| Step: 0
Training loss: 3.4785349533169496
Validation loss: 3.490507286315899

Epoch: 6| Step: 1
Training loss: 3.3666041459677096
Validation loss: 3.48609959185463

Epoch: 6| Step: 2
Training loss: 4.11104280111478
Validation loss: 3.4820575619825296

Epoch: 6| Step: 3
Training loss: 3.217491570545409
Validation loss: 3.4775592189548536

Epoch: 6| Step: 4
Training loss: 4.225874021516441
Validation loss: 3.4735767816488305

Epoch: 6| Step: 5
Training loss: 3.5411999712856237
Validation loss: 3.4688973381207853

Epoch: 6| Step: 6
Training loss: 3.291310464120337
Validation loss: 3.4651925571914055

Epoch: 6| Step: 7
Training loss: 4.458233817347583
Validation loss: 3.460957202037248

Epoch: 6| Step: 8
Training loss: 3.177965302332546
Validation loss: 3.4565904699098136

Epoch: 6| Step: 9
Training loss: 2.8331084629655896
Validation loss: 3.45235713056354

Epoch: 6| Step: 10
Training loss: 3.5425033179505183
Validation loss: 3.448205357631007

Epoch: 6| Step: 11
Training loss: 3.7270407699676396
Validation loss: 3.4443315766071416

Epoch: 6| Step: 12
Training loss: 3.707319113806725
Validation loss: 3.4404436281347506

Epoch: 6| Step: 13
Training loss: 3.418722573123245
Validation loss: 3.4363903682232295

Epoch: 36| Step: 0
Training loss: 3.7443731690467428
Validation loss: 3.4325603250683825

Epoch: 6| Step: 1
Training loss: 3.776324887232382
Validation loss: 3.4281397450308773

Epoch: 6| Step: 2
Training loss: 4.031221138311169
Validation loss: 3.424139402913366

Epoch: 6| Step: 3
Training loss: 3.9727914012623837
Validation loss: 3.4201917761485774

Epoch: 6| Step: 4
Training loss: 3.6109836180914074
Validation loss: 3.415906534694102

Epoch: 6| Step: 5
Training loss: 2.8940768689621765
Validation loss: 3.411811418194199

Epoch: 6| Step: 6
Training loss: 3.8567015001795015
Validation loss: 3.408168625679767

Epoch: 6| Step: 7
Training loss: 3.11534427460928
Validation loss: 3.404002156634606

Epoch: 6| Step: 8
Training loss: 3.5738822736941946
Validation loss: 3.4005798602705806

Epoch: 6| Step: 9
Training loss: 3.4902983127537563
Validation loss: 3.3961506950753058

Epoch: 6| Step: 10
Training loss: 3.262155834767496
Validation loss: 3.3924844216813894

Epoch: 6| Step: 11
Training loss: 3.319468096901987
Validation loss: 3.388641011356807

Epoch: 6| Step: 12
Training loss: 3.4241048436646495
Validation loss: 3.385180976684048

Epoch: 6| Step: 13
Training loss: 3.3866573622968725
Validation loss: 3.380766428215779

Epoch: 37| Step: 0
Training loss: 3.45688738335002
Validation loss: 3.3769402048670205

Epoch: 6| Step: 1
Training loss: 3.3222808389018197
Validation loss: 3.3730968007050546

Epoch: 6| Step: 2
Training loss: 3.888186261114949
Validation loss: 3.3696663473057864

Epoch: 6| Step: 3
Training loss: 2.953459705579697
Validation loss: 3.3656577096599327

Epoch: 6| Step: 4
Training loss: 3.2033125659641257
Validation loss: 3.36199238856065

Epoch: 6| Step: 5
Training loss: 3.2336373340280478
Validation loss: 3.3580423003397644

Epoch: 6| Step: 6
Training loss: 3.3727487190441514
Validation loss: 3.35411691727479

Epoch: 6| Step: 7
Training loss: 3.515524765281163
Validation loss: 3.3502853556699472

Epoch: 6| Step: 8
Training loss: 4.031549250414846
Validation loss: 3.346994602453938

Epoch: 6| Step: 9
Training loss: 3.44067291863912
Validation loss: 3.3428386028452595

Epoch: 6| Step: 10
Training loss: 3.743879027523391
Validation loss: 3.339328635425377

Epoch: 6| Step: 11
Training loss: 3.5614593056588837
Validation loss: 3.3357659682187784

Epoch: 6| Step: 12
Training loss: 3.591769261381075
Validation loss: 3.331716626225106

Epoch: 6| Step: 13
Training loss: 3.4235582087523824
Validation loss: 3.3279084088883866

Epoch: 38| Step: 0
Training loss: 3.752721943045011
Validation loss: 3.324542772793324

Epoch: 6| Step: 1
Training loss: 2.7416119528492913
Validation loss: 3.3206690697785417

Epoch: 6| Step: 2
Training loss: 3.818429057468391
Validation loss: 3.316910057306699

Epoch: 6| Step: 3
Training loss: 3.742198713122553
Validation loss: 3.313103914690905

Epoch: 6| Step: 4
Training loss: 3.812499249567677
Validation loss: 3.309431754331913

Epoch: 6| Step: 5
Training loss: 3.535465930842006
Validation loss: 3.305487665891488

Epoch: 6| Step: 6
Training loss: 3.8266612465805676
Validation loss: 3.3015982013775447

Epoch: 6| Step: 7
Training loss: 3.393184135569548
Validation loss: 3.2978107757501194

Epoch: 6| Step: 8
Training loss: 3.2336439697907773
Validation loss: 3.2939912860857787

Epoch: 6| Step: 9
Training loss: 2.9627423988034263
Validation loss: 3.2900576381021196

Epoch: 6| Step: 10
Training loss: 3.468885264465711
Validation loss: 3.286489801916166

Epoch: 6| Step: 11
Training loss: 3.2773798325635877
Validation loss: 3.2827543897174563

Epoch: 6| Step: 12
Training loss: 3.0594979967714533
Validation loss: 3.2792297925935996

Epoch: 6| Step: 13
Training loss: 3.3059095643696197
Validation loss: 3.27524556168762

Epoch: 39| Step: 0
Training loss: 3.186996719420905
Validation loss: 3.2718033698644415

Epoch: 6| Step: 1
Training loss: 3.377979658672008
Validation loss: 3.268010559471188

Epoch: 6| Step: 2
Training loss: 4.237325956208146
Validation loss: 3.264441974032461

Epoch: 6| Step: 3
Training loss: 3.376042946628201
Validation loss: 3.2606089883617995

Epoch: 6| Step: 4
Training loss: 2.775125511011651
Validation loss: 3.2566911824402416

Epoch: 6| Step: 5
Training loss: 3.138422407147973
Validation loss: 3.25322631717251

Epoch: 6| Step: 6
Training loss: 3.2735438363732396
Validation loss: 3.2494994291536012

Epoch: 6| Step: 7
Training loss: 3.3881751144353656
Validation loss: 3.245954465421749

Epoch: 6| Step: 8
Training loss: 3.8653972142302915
Validation loss: 3.2420544455316205

Epoch: 6| Step: 9
Training loss: 2.6222941667130604
Validation loss: 3.238181830131265

Epoch: 6| Step: 10
Training loss: 3.329074491355539
Validation loss: 3.2344330000783206

Epoch: 6| Step: 11
Training loss: 3.540513303363503
Validation loss: 3.2309887493287532

Epoch: 6| Step: 12
Training loss: 3.7699897763950947
Validation loss: 3.227888141324012

Epoch: 6| Step: 13
Training loss: 3.2387624274972033
Validation loss: 3.223960831270909

Epoch: 40| Step: 0
Training loss: 3.1634662584435045
Validation loss: 3.2204421080090544

Epoch: 6| Step: 1
Training loss: 3.4640040191820893
Validation loss: 3.2167081436553326

Epoch: 6| Step: 2
Training loss: 2.778252432853782
Validation loss: 3.2134255625783674

Epoch: 6| Step: 3
Training loss: 3.5296057189680647
Validation loss: 3.2101601358085206

Epoch: 6| Step: 4
Training loss: 3.4971679401166016
Validation loss: 3.2066688100473244

Epoch: 6| Step: 5
Training loss: 3.35122743012036
Validation loss: 3.203379005347358

Epoch: 6| Step: 6
Training loss: 3.2460812638429384
Validation loss: 3.1996460669209053

Epoch: 6| Step: 7
Training loss: 3.586457657331539
Validation loss: 3.1966002713237187

Epoch: 6| Step: 8
Training loss: 3.5412612383792395
Validation loss: 3.1928376528928473

Epoch: 6| Step: 9
Training loss: 3.6013146437219197
Validation loss: 3.189361066359834

Epoch: 6| Step: 10
Training loss: 3.3374494570216084
Validation loss: 3.185571249052534

Epoch: 6| Step: 11
Training loss: 3.5518260128006722
Validation loss: 3.1818294824259175

Epoch: 6| Step: 12
Training loss: 3.4601236940886313
Validation loss: 3.1781340982462565

Epoch: 6| Step: 13
Training loss: 2.425410587906299
Validation loss: 3.174322101983206

Epoch: 41| Step: 0
Training loss: 3.292333575585075
Validation loss: 3.171603913146596

Epoch: 6| Step: 1
Training loss: 3.280915161486959
Validation loss: 3.1676431873517408

Epoch: 6| Step: 2
Training loss: 3.6213090456071804
Validation loss: 3.1644047555937793

Epoch: 6| Step: 3
Training loss: 3.7429604896704274
Validation loss: 3.1610046429872027

Epoch: 6| Step: 4
Training loss: 2.978229046151886
Validation loss: 3.157856950756903

Epoch: 6| Step: 5
Training loss: 3.4109027128590688
Validation loss: 3.1539633244857708

Epoch: 6| Step: 6
Training loss: 3.3994139222296007
Validation loss: 3.1504154476315946

Epoch: 6| Step: 7
Training loss: 2.778909791649767
Validation loss: 3.1469608627268024

Epoch: 6| Step: 8
Training loss: 2.8240770908564268
Validation loss: 3.1437093667652194

Epoch: 6| Step: 9
Training loss: 3.4191051403301893
Validation loss: 3.1406175350777397

Epoch: 6| Step: 10
Training loss: 3.01527062740344
Validation loss: 3.1376948945810685

Epoch: 6| Step: 11
Training loss: 3.3623981446222255
Validation loss: 3.134442926991191

Epoch: 6| Step: 12
Training loss: 3.669497105498679
Validation loss: 3.1312528740926155

Epoch: 6| Step: 13
Training loss: 3.112798291968488
Validation loss: 3.127816266383376

Epoch: 42| Step: 0
Training loss: 3.7497908215991878
Validation loss: 3.1250214893873762

Epoch: 6| Step: 1
Training loss: 3.236029160480175
Validation loss: 3.1215196684120388

Epoch: 6| Step: 2
Training loss: 3.5165496288427747
Validation loss: 3.1180681531878673

Epoch: 6| Step: 3
Training loss: 3.9554549878321965
Validation loss: 3.115071788917857

Epoch: 6| Step: 4
Training loss: 3.348359825240876
Validation loss: 3.1116475501866927

Epoch: 6| Step: 5
Training loss: 3.3555560028491307
Validation loss: 3.1080931892048174

Epoch: 6| Step: 6
Training loss: 2.679676734302126
Validation loss: 3.1047099020024467

Epoch: 6| Step: 7
Training loss: 3.40170825230699
Validation loss: 3.1016101208929787

Epoch: 6| Step: 8
Training loss: 2.2064321599438146
Validation loss: 3.098340760998974

Epoch: 6| Step: 9
Training loss: 3.065996315154507
Validation loss: 3.0950727364451893

Epoch: 6| Step: 10
Training loss: 3.1951855025667895
Validation loss: 3.092286775372622

Epoch: 6| Step: 11
Training loss: 3.010519182160244
Validation loss: 3.089372074023685

Epoch: 6| Step: 12
Training loss: 3.1301730254980575
Validation loss: 3.0861705708109666

Epoch: 6| Step: 13
Training loss: 3.2420954312040506
Validation loss: 3.083130576366282

Epoch: 43| Step: 0
Training loss: 2.732411666098468
Validation loss: 3.079959600212549

Epoch: 6| Step: 1
Training loss: 2.917560186214767
Validation loss: 3.0773707981087903

Epoch: 6| Step: 2
Training loss: 2.3832612162351805
Validation loss: 3.074538618587093

Epoch: 6| Step: 3
Training loss: 2.6688985921690587
Validation loss: 3.0718932478845553

Epoch: 6| Step: 4
Training loss: 3.1580827887073495
Validation loss: 3.068965134133521

Epoch: 6| Step: 5
Training loss: 3.522993038589655
Validation loss: 3.0661299595206737

Epoch: 6| Step: 6
Training loss: 2.8709670265932425
Validation loss: 3.0635645307258184

Epoch: 6| Step: 7
Training loss: 3.3423464672631655
Validation loss: 3.060903029014874

Epoch: 6| Step: 8
Training loss: 2.566846742959786
Validation loss: 3.0582311162748903

Epoch: 6| Step: 9
Training loss: 3.7607447233664524
Validation loss: 3.05572715816862

Epoch: 6| Step: 10
Training loss: 3.0531207893834513
Validation loss: 3.0530796616414673

Epoch: 6| Step: 11
Training loss: 3.6093216268713393
Validation loss: 3.050461156824863

Epoch: 6| Step: 12
Training loss: 3.750234723692383
Validation loss: 3.047664311866166

Epoch: 6| Step: 13
Training loss: 3.970909192113529
Validation loss: 3.0447299285869414

Epoch: 44| Step: 0
Training loss: 2.7280376127564243
Validation loss: 3.0412692154354257

Epoch: 6| Step: 1
Training loss: 2.997876687453757
Validation loss: 3.038144009610526

Epoch: 6| Step: 2
Training loss: 3.3837436865644457
Validation loss: 3.0349138147517447

Epoch: 6| Step: 3
Training loss: 3.7182869502693654
Validation loss: 3.0320972163183226

Epoch: 6| Step: 4
Training loss: 3.320171469890906
Validation loss: 3.028709435006969

Epoch: 6| Step: 5
Training loss: 3.3404547595332406
Validation loss: 3.025381273354118

Epoch: 6| Step: 6
Training loss: 2.8639787810514568
Validation loss: 3.0222102392495147

Epoch: 6| Step: 7
Training loss: 3.184554889902474
Validation loss: 3.0191216497375692

Epoch: 6| Step: 8
Training loss: 2.892032095239017
Validation loss: 3.015814595694376

Epoch: 6| Step: 9
Training loss: 2.777450881372612
Validation loss: 3.012538813107497

Epoch: 6| Step: 10
Training loss: 3.695321790752063
Validation loss: 3.010056805248897

Epoch: 6| Step: 11
Training loss: 3.1595272763284195
Validation loss: 3.0070058822718075

Epoch: 6| Step: 12
Training loss: 3.1756623305686906
Validation loss: 3.0042284464909867

Epoch: 6| Step: 13
Training loss: 2.8662109375
Validation loss: 3.0013488148039036

Epoch: 45| Step: 0
Training loss: 3.1849378872598324
Validation loss: 2.9988296663155207

Epoch: 6| Step: 1
Training loss: 2.9126634281786847
Validation loss: 2.9959050019188966

Epoch: 6| Step: 2
Training loss: 3.6922434669802056
Validation loss: 2.993236095729543

Epoch: 6| Step: 3
Training loss: 3.394949128973492
Validation loss: 2.9906846962939593

Epoch: 6| Step: 4
Training loss: 3.1775245902057634
Validation loss: 2.9878817023155153

Epoch: 6| Step: 5
Training loss: 3.5417553759666234
Validation loss: 2.984854907583577

Epoch: 6| Step: 6
Training loss: 2.862197400219752
Validation loss: 2.9821646662105796

Epoch: 6| Step: 7
Training loss: 2.7568125005922384
Validation loss: 2.979134317146854

Epoch: 6| Step: 8
Training loss: 2.9193419221814283
Validation loss: 2.9763844621199866

Epoch: 6| Step: 9
Training loss: 3.586827651763406
Validation loss: 2.973436584846702

Epoch: 6| Step: 10
Training loss: 3.389928227567882
Validation loss: 2.970670380120322

Epoch: 6| Step: 11
Training loss: 2.734613288305747
Validation loss: 2.9679817276406752

Epoch: 6| Step: 12
Training loss: 2.628829342764362
Validation loss: 2.9653507246524033

Epoch: 6| Step: 13
Training loss: 2.6880553802791174
Validation loss: 2.9627926935395528

Epoch: 46| Step: 0
Training loss: 3.4985994534064595
Validation loss: 2.960341931302852

Epoch: 6| Step: 1
Training loss: 2.98034827712573
Validation loss: 2.9576470738717893

Epoch: 6| Step: 2
Training loss: 3.124051674956394
Validation loss: 2.955015139382314

Epoch: 6| Step: 3
Training loss: 3.443138630456235
Validation loss: 2.952324747046454

Epoch: 6| Step: 4
Training loss: 3.0653963989511435
Validation loss: 2.9498299274881488

Epoch: 6| Step: 5
Training loss: 3.6795107400153992
Validation loss: 2.9474349060722345

Epoch: 6| Step: 6
Training loss: 3.2468845400335065
Validation loss: 2.9445895818011847

Epoch: 6| Step: 7
Training loss: 3.1336044870562123
Validation loss: 2.941810880661524

Epoch: 6| Step: 8
Training loss: 2.372250923451636
Validation loss: 2.9386794651036072

Epoch: 6| Step: 9
Training loss: 3.2750039369981705
Validation loss: 2.9361984128874075

Epoch: 6| Step: 10
Training loss: 2.6070292087875027
Validation loss: 2.9337817528459245

Epoch: 6| Step: 11
Training loss: 2.5980343651029445
Validation loss: 2.931468249494369

Epoch: 6| Step: 12
Training loss: 3.184469240720151
Validation loss: 2.9288411999215858

Epoch: 6| Step: 13
Training loss: 2.7331359671846567
Validation loss: 2.926298210401972

Epoch: 47| Step: 0
Training loss: 3.2028436304582515
Validation loss: 2.924310841844086

Epoch: 6| Step: 1
Training loss: 2.5500619058013454
Validation loss: 2.92204409295317

Epoch: 6| Step: 2
Training loss: 2.6794956683568576
Validation loss: 2.9197911193897954

Epoch: 6| Step: 3
Training loss: 2.7679021910767867
Validation loss: 2.9174495781575933

Epoch: 6| Step: 4
Training loss: 3.0078275605852656
Validation loss: 2.9153715437135443

Epoch: 6| Step: 5
Training loss: 2.8191930181670144
Validation loss: 2.913253508251844

Epoch: 6| Step: 6
Training loss: 3.003067355838222
Validation loss: 2.910942432278577

Epoch: 6| Step: 7
Training loss: 2.6790186989969285
Validation loss: 2.908450821267789

Epoch: 6| Step: 8
Training loss: 3.4995885334656776
Validation loss: 2.906250656291929

Epoch: 6| Step: 9
Training loss: 3.3227182805423916
Validation loss: 2.904111807116671

Epoch: 6| Step: 10
Training loss: 3.280870397499046
Validation loss: 2.901357682626709

Epoch: 6| Step: 11
Training loss: 3.1052215285832907
Validation loss: 2.8988465382965676

Epoch: 6| Step: 12
Training loss: 3.4614834666977927
Validation loss: 2.896654826675232

Epoch: 6| Step: 13
Training loss: 3.163806292674752
Validation loss: 2.8944255553874116

Epoch: 48| Step: 0
Training loss: 3.2795590357816775
Validation loss: 2.891998913024761

Epoch: 6| Step: 1
Training loss: 3.127239492957563
Validation loss: 2.8898666761811866

Epoch: 6| Step: 2
Training loss: 3.280001157434771
Validation loss: 2.8875008411048446

Epoch: 6| Step: 3
Training loss: 3.9476067548042537
Validation loss: 2.884912527136715

Epoch: 6| Step: 4
Training loss: 3.003902440260913
Validation loss: 2.8823014437821337

Epoch: 6| Step: 5
Training loss: 3.01797946865816
Validation loss: 2.880158840717657

Epoch: 6| Step: 6
Training loss: 2.285453059817495
Validation loss: 2.877636170820626

Epoch: 6| Step: 7
Training loss: 2.6299624992278825
Validation loss: 2.8754403288510297

Epoch: 6| Step: 8
Training loss: 3.014659351444044
Validation loss: 2.873201955157884

Epoch: 6| Step: 9
Training loss: 2.926946308734389
Validation loss: 2.871100545516157

Epoch: 6| Step: 10
Training loss: 3.1121888583521518
Validation loss: 2.8689429152482564

Epoch: 6| Step: 11
Training loss: 2.847350304263244
Validation loss: 2.8669474515983437

Epoch: 6| Step: 12
Training loss: 2.699797152917351
Validation loss: 2.8648948407582626

Epoch: 6| Step: 13
Training loss: 2.817620680897647
Validation loss: 2.863039569447607

Epoch: 49| Step: 0
Training loss: 3.011654151787763
Validation loss: 2.860633309188131

Epoch: 6| Step: 1
Training loss: 3.0187911573806963
Validation loss: 2.8587193805771154

Epoch: 6| Step: 2
Training loss: 2.984384906213107
Validation loss: 2.8569264307249047

Epoch: 6| Step: 3
Training loss: 2.308849649721066
Validation loss: 2.856025707584194

Epoch: 6| Step: 4
Training loss: 2.779783569528464
Validation loss: 2.853259691984514

Epoch: 6| Step: 5
Training loss: 2.7952485709985497
Validation loss: 2.8511030410517932

Epoch: 6| Step: 6
Training loss: 2.9267561832661464
Validation loss: 2.8482745022294202

Epoch: 6| Step: 7
Training loss: 2.747374408270775
Validation loss: 2.848631278076735

Epoch: 6| Step: 8
Training loss: 3.490373998239015
Validation loss: 2.844184465021984

Epoch: 6| Step: 9
Training loss: 3.547568366888653
Validation loss: 2.8426107562968186

Epoch: 6| Step: 10
Training loss: 3.1526163165349232
Validation loss: 2.840322392078832

Epoch: 6| Step: 11
Training loss: 3.283099280081785
Validation loss: 2.8385679517923017

Epoch: 6| Step: 12
Training loss: 2.4913786050740665
Validation loss: 2.8368606255948663

Epoch: 6| Step: 13
Training loss: 3.0751674017271027
Validation loss: 2.8345312129457847

Epoch: 50| Step: 0
Training loss: 3.2508508595497205
Validation loss: 2.833046524640711

Epoch: 6| Step: 1
Training loss: 3.386197059868087
Validation loss: 2.8310199905169413

Epoch: 6| Step: 2
Training loss: 2.841414614002503
Validation loss: 2.829010995019389

Epoch: 6| Step: 3
Training loss: 2.0774314698301892
Validation loss: 2.826790046705787

Epoch: 6| Step: 4
Training loss: 2.9040367969462055
Validation loss: 2.8246998568405

Epoch: 6| Step: 5
Training loss: 2.3810815746587606
Validation loss: 2.8232895204896997

Epoch: 6| Step: 6
Training loss: 2.7205835933676026
Validation loss: 2.8213519913189264

Epoch: 6| Step: 7
Training loss: 3.6438068679899787
Validation loss: 2.8188868588804596

Epoch: 6| Step: 8
Training loss: 3.173434771297602
Validation loss: 2.8170443943693213

Epoch: 6| Step: 9
Training loss: 3.2705420751135263
Validation loss: 2.81499061508376

Epoch: 6| Step: 10
Training loss: 3.0855259874455214
Validation loss: 2.812960113753408

Epoch: 6| Step: 11
Training loss: 3.0863067792302274
Validation loss: 2.8111100612315085

Epoch: 6| Step: 12
Training loss: 2.8304565260957752
Validation loss: 2.8087934936745964

Epoch: 6| Step: 13
Training loss: 2.4249577744730515
Validation loss: 2.806296267053715

Epoch: 51| Step: 0
Training loss: 3.072561900894213
Validation loss: 2.8045806156006052

Epoch: 6| Step: 1
Training loss: 2.9372289004930483
Validation loss: 2.803456099003463

Epoch: 6| Step: 2
Training loss: 2.4397601872772947
Validation loss: 2.8009763655895106

Epoch: 6| Step: 3
Training loss: 2.674581484275219
Validation loss: 2.7986487335335064

Epoch: 6| Step: 4
Training loss: 2.3568882247323133
Validation loss: 2.7968368243519293

Epoch: 6| Step: 5
Training loss: 3.217401462756301
Validation loss: 2.795765093573713

Epoch: 6| Step: 6
Training loss: 3.0801446940135087
Validation loss: 2.796198033074605

Epoch: 6| Step: 7
Training loss: 2.8880953880893765
Validation loss: 2.7929770302816506

Epoch: 6| Step: 8
Training loss: 3.285699497805661
Validation loss: 2.7953486904177636

Epoch: 6| Step: 9
Training loss: 2.882335096077328
Validation loss: 2.7880056820624093

Epoch: 6| Step: 10
Training loss: 2.893900072725458
Validation loss: 2.7872823524751915

Epoch: 6| Step: 11
Training loss: 3.0553258828822747
Validation loss: 2.7857263667272014

Epoch: 6| Step: 12
Training loss: 3.169519912515155
Validation loss: 2.7842359194857784

Epoch: 6| Step: 13
Training loss: 2.9836135611884
Validation loss: 2.7836132510324134

Epoch: 52| Step: 0
Training loss: 2.6685053228561437
Validation loss: 2.780984930201319

Epoch: 6| Step: 1
Training loss: 2.7081148695255544
Validation loss: 2.780360933424859

Epoch: 6| Step: 2
Training loss: 2.818604181751356
Validation loss: 2.7771318357505175

Epoch: 6| Step: 3
Training loss: 2.5370409620780108
Validation loss: 2.774983708445522

Epoch: 6| Step: 4
Training loss: 3.503776148121135
Validation loss: 2.775364824891443

Epoch: 6| Step: 5
Training loss: 2.730247215703406
Validation loss: 2.772354989279777

Epoch: 6| Step: 6
Training loss: 2.4576632561693836
Validation loss: 2.7693481815238843

Epoch: 6| Step: 7
Training loss: 3.0136645966576077
Validation loss: 2.7682336978869286

Epoch: 6| Step: 8
Training loss: 3.1599860410744154
Validation loss: 2.7664344019850255

Epoch: 6| Step: 9
Training loss: 2.6778771872246865
Validation loss: 2.765548503845115

Epoch: 6| Step: 10
Training loss: 3.0748295062181206
Validation loss: 2.764103487097957

Epoch: 6| Step: 11
Training loss: 2.9133132912348687
Validation loss: 2.762306478174724

Epoch: 6| Step: 12
Training loss: 3.0263930273783926
Validation loss: 2.760680971747728

Epoch: 6| Step: 13
Training loss: 3.285991911680236
Validation loss: 2.7596381523135802

Epoch: 53| Step: 0
Training loss: 3.2365682785632313
Validation loss: 2.757955372741379

Epoch: 6| Step: 1
Training loss: 2.7321000581126347
Validation loss: 2.764623888221836

Epoch: 6| Step: 2
Training loss: 2.8971187748234573
Validation loss: 2.8047296207421026

Epoch: 6| Step: 3
Training loss: 2.9455747614088543
Validation loss: 2.8083299593428843

Epoch: 6| Step: 4
Training loss: 3.14191983229107
Validation loss: 2.8062140119095718

Epoch: 6| Step: 5
Training loss: 3.2548205498189047
Validation loss: 2.8027567048462605

Epoch: 6| Step: 6
Training loss: 3.3843911520166565
Validation loss: 2.795426432244284

Epoch: 6| Step: 7
Training loss: 2.8914806852162296
Validation loss: 2.7924107703350893

Epoch: 6| Step: 8
Training loss: 2.7459761918627144
Validation loss: 2.7857572202319902

Epoch: 6| Step: 9
Training loss: 2.5561203044643213
Validation loss: 2.762524146985694

Epoch: 6| Step: 10
Training loss: 2.5803272436034215
Validation loss: 2.75684699284797

Epoch: 6| Step: 11
Training loss: 2.928587195722822
Validation loss: 2.761346729910401

Epoch: 6| Step: 12
Training loss: 2.657282101444349
Validation loss: 2.7733303998586227

Epoch: 6| Step: 13
Training loss: 2.898651690936014
Validation loss: 2.7726009199637933

Epoch: 54| Step: 0
Training loss: 2.9225773094792227
Validation loss: 2.7545557288815563

Epoch: 6| Step: 1
Training loss: 2.8584276307977103
Validation loss: 2.7417694816519838

Epoch: 6| Step: 2
Training loss: 2.7900489750873962
Validation loss: 2.7333900784983314

Epoch: 6| Step: 3
Training loss: 3.3072886229173166
Validation loss: 2.729615463357335

Epoch: 6| Step: 4
Training loss: 2.3987144285489683
Validation loss: 2.733590149638598

Epoch: 6| Step: 5
Training loss: 2.4131000661957382
Validation loss: 2.741610532454574

Epoch: 6| Step: 6
Training loss: 3.529429548817128
Validation loss: 2.7675037504157545

Epoch: 6| Step: 7
Training loss: 2.2208315259438245
Validation loss: 2.735035974450778

Epoch: 6| Step: 8
Training loss: 3.1595435756908707
Validation loss: 2.7234788451974876

Epoch: 6| Step: 9
Training loss: 2.677765715990913
Validation loss: 2.7219835980164326

Epoch: 6| Step: 10
Training loss: 3.001203613431195
Validation loss: 2.7254280710693717

Epoch: 6| Step: 11
Training loss: 3.1024517639000706
Validation loss: 2.728389211869696

Epoch: 6| Step: 12
Training loss: 2.8776571185503252
Validation loss: 2.7352077124442373

Epoch: 6| Step: 13
Training loss: 2.7698547432612943
Validation loss: 2.733804494288192

Epoch: 55| Step: 0
Training loss: 3.2791232528300878
Validation loss: 2.7285209406311934

Epoch: 6| Step: 1
Training loss: 2.471605508535988
Validation loss: 2.7328847402654293

Epoch: 6| Step: 2
Training loss: 2.339623442453513
Validation loss: 2.72785519740175

Epoch: 6| Step: 3
Training loss: 3.2427960295827334
Validation loss: 2.719191562851538

Epoch: 6| Step: 4
Training loss: 2.647250199100603
Validation loss: 2.7115484862862855

Epoch: 6| Step: 5
Training loss: 2.7480886926566837
Validation loss: 2.707130389946332

Epoch: 6| Step: 6
Training loss: 2.74350535142758
Validation loss: 2.704372412187599

Epoch: 6| Step: 7
Training loss: 2.818123176389685
Validation loss: 2.706285940141608

Epoch: 6| Step: 8
Training loss: 2.927084944284523
Validation loss: 2.706523706398696

Epoch: 6| Step: 9
Training loss: 3.0636099536128905
Validation loss: 2.7082737744947365

Epoch: 6| Step: 10
Training loss: 2.4859146049974936
Validation loss: 2.7071308449776916

Epoch: 6| Step: 11
Training loss: 3.0410737979643847
Validation loss: 2.7028773640887493

Epoch: 6| Step: 12
Training loss: 2.7628464183833104
Validation loss: 2.6958596968700603

Epoch: 6| Step: 13
Training loss: 3.099709983303409
Validation loss: 2.693981133005769

Epoch: 56| Step: 0
Training loss: 2.4389990085351108
Validation loss: 2.6930271798599126

Epoch: 6| Step: 1
Training loss: 3.3870015977709875
Validation loss: 2.6917097255541997

Epoch: 6| Step: 2
Training loss: 3.328502508253333
Validation loss: 2.6903522644164646

Epoch: 6| Step: 3
Training loss: 2.718226239846715
Validation loss: 2.6902720327277136

Epoch: 6| Step: 4
Training loss: 3.115304325478369
Validation loss: 2.690530473006382

Epoch: 6| Step: 5
Training loss: 2.414656383955217
Validation loss: 2.689492425975405

Epoch: 6| Step: 6
Training loss: 2.6763081498222836
Validation loss: 2.689350762470426

Epoch: 6| Step: 7
Training loss: 2.5206078883053022
Validation loss: 2.687207967579159

Epoch: 6| Step: 8
Training loss: 2.3803312797151124
Validation loss: 2.6851463953288155

Epoch: 6| Step: 9
Training loss: 3.086594600975957
Validation loss: 2.682774433035508

Epoch: 6| Step: 10
Training loss: 3.0614162785273304
Validation loss: 2.680378757064234

Epoch: 6| Step: 11
Training loss: 2.8972685479710885
Validation loss: 2.679034302696328

Epoch: 6| Step: 12
Training loss: 2.5233868573188403
Validation loss: 2.677418258635016

Epoch: 6| Step: 13
Training loss: 2.74890782602699
Validation loss: 2.67626614597373

Epoch: 57| Step: 0
Training loss: 2.7766615489837756
Validation loss: 2.67352480453191

Epoch: 6| Step: 1
Training loss: 3.2939237429344925
Validation loss: 2.67451067456806

Epoch: 6| Step: 2
Training loss: 3.1119916631003455
Validation loss: 2.6729569205872714

Epoch: 6| Step: 3
Training loss: 2.723752035251398
Validation loss: 2.6698351801554643

Epoch: 6| Step: 4
Training loss: 2.7220454796573024
Validation loss: 2.668148483395823

Epoch: 6| Step: 5
Training loss: 2.6057114152127663
Validation loss: 2.667262716039138

Epoch: 6| Step: 6
Training loss: 2.28738081157748
Validation loss: 2.6650214832434824

Epoch: 6| Step: 7
Training loss: 3.0701696153934486
Validation loss: 2.6645299775421374

Epoch: 6| Step: 8
Training loss: 2.686955064040766
Validation loss: 2.662250383523023

Epoch: 6| Step: 9
Training loss: 2.2375631994773406
Validation loss: 2.6632139881339247

Epoch: 6| Step: 10
Training loss: 3.287181325341489
Validation loss: 2.6626703795838704

Epoch: 6| Step: 11
Training loss: 3.0113355736709018
Validation loss: 2.6593625550627

Epoch: 6| Step: 12
Training loss: 2.6701188590350267
Validation loss: 2.657430244480097

Epoch: 6| Step: 13
Training loss: 2.5490280131450294
Validation loss: 2.659222454353351

Epoch: 58| Step: 0
Training loss: 2.9888133653586966
Validation loss: 2.6558708967559377

Epoch: 6| Step: 1
Training loss: 3.374662170456396
Validation loss: 2.6549206567511967

Epoch: 6| Step: 2
Training loss: 2.4513901328376972
Validation loss: 2.653905619345234

Epoch: 6| Step: 3
Training loss: 2.201008530845904
Validation loss: 2.648343755062556

Epoch: 6| Step: 4
Training loss: 2.7699762801934735
Validation loss: 2.6497696908400985

Epoch: 6| Step: 5
Training loss: 2.7146914652095804
Validation loss: 2.6519699619830264

Epoch: 6| Step: 6
Training loss: 2.6150343507220977
Validation loss: 2.6458532728109674

Epoch: 6| Step: 7
Training loss: 2.762378921271935
Validation loss: 2.645413513117625

Epoch: 6| Step: 8
Training loss: 3.294851975075465
Validation loss: 2.651050774958964

Epoch: 6| Step: 9
Training loss: 3.239692481717768
Validation loss: 2.6462002347129796

Epoch: 6| Step: 10
Training loss: 2.885311707792253
Validation loss: 2.64205474068808

Epoch: 6| Step: 11
Training loss: 2.6217063949623953
Validation loss: 2.6424245326857556

Epoch: 6| Step: 12
Training loss: 2.6300113616813983
Validation loss: 2.6434235800417825

Epoch: 6| Step: 13
Training loss: 2.159487298234317
Validation loss: 2.6417646789017817

Epoch: 59| Step: 0
Training loss: 2.4918458519066355
Validation loss: 2.642005544480987

Epoch: 6| Step: 1
Training loss: 3.2079260596508474
Validation loss: 2.6448130304876725

Epoch: 6| Step: 2
Training loss: 2.5365757428723894
Validation loss: 2.643759122190978

Epoch: 6| Step: 3
Training loss: 2.1710181432780296
Validation loss: 2.643207453496036

Epoch: 6| Step: 4
Training loss: 2.47524787355175
Validation loss: 2.6414256791223227

Epoch: 6| Step: 5
Training loss: 2.801098665901382
Validation loss: 2.6431506040326274

Epoch: 6| Step: 6
Training loss: 3.4077324397404465
Validation loss: 2.641674232070952

Epoch: 6| Step: 7
Training loss: 2.729751601883109
Validation loss: 2.6406451493497074

Epoch: 6| Step: 8
Training loss: 2.826034025825682
Validation loss: 2.639266904447673

Epoch: 6| Step: 9
Training loss: 2.4532123720196393
Validation loss: 2.637729208148327

Epoch: 6| Step: 10
Training loss: 2.7978727809241226
Validation loss: 2.636138309592582

Epoch: 6| Step: 11
Training loss: 2.359586390442181
Validation loss: 2.6318632654058156

Epoch: 6| Step: 12
Training loss: 3.3748592771226567
Validation loss: 2.6305775877345354

Epoch: 6| Step: 13
Training loss: 2.90468300854447
Validation loss: 2.630386585704313

Epoch: 60| Step: 0
Training loss: 2.8544098316570707
Validation loss: 2.628636157826323

Epoch: 6| Step: 1
Training loss: 2.639709675170634
Validation loss: 2.626015164096432

Epoch: 6| Step: 2
Training loss: 2.691874293142792
Validation loss: 2.6278814365470415

Epoch: 6| Step: 3
Training loss: 2.995615138852057
Validation loss: 2.6280961926030924

Epoch: 6| Step: 4
Training loss: 3.1684934132239495
Validation loss: 2.6249384797168442

Epoch: 6| Step: 5
Training loss: 2.7556442079417547
Validation loss: 2.62577785592738

Epoch: 6| Step: 6
Training loss: 2.548611476065471
Validation loss: 2.6217172168272733

Epoch: 6| Step: 7
Training loss: 3.1220622177424775
Validation loss: 2.621044948709138

Epoch: 6| Step: 8
Training loss: 2.801826399092973
Validation loss: 2.6212082680075692

Epoch: 6| Step: 9
Training loss: 2.573840563580934
Validation loss: 2.619192571881076

Epoch: 6| Step: 10
Training loss: 2.3764451298269282
Validation loss: 2.6182484009061975

Epoch: 6| Step: 11
Training loss: 2.5698793736213768
Validation loss: 2.618586212960114

Epoch: 6| Step: 12
Training loss: 2.367753266561158
Validation loss: 2.6193174889890267

Epoch: 6| Step: 13
Training loss: 3.009524484884958
Validation loss: 2.616018552352728

Epoch: 61| Step: 0
Training loss: 2.6881519680093966
Validation loss: 2.614353296462038

Epoch: 6| Step: 1
Training loss: 1.9640366582149151
Validation loss: 2.615231381738197

Epoch: 6| Step: 2
Training loss: 3.3015889821613027
Validation loss: 2.6134182333860387

Epoch: 6| Step: 3
Training loss: 2.772617616489087
Validation loss: 2.6132429849040304

Epoch: 6| Step: 4
Training loss: 2.828700897424442
Validation loss: 2.6109118551855017

Epoch: 6| Step: 5
Training loss: 2.713697979330504
Validation loss: 2.6111728771380402

Epoch: 6| Step: 6
Training loss: 3.082269038127736
Validation loss: 2.608666268531047

Epoch: 6| Step: 7
Training loss: 3.1498717266789216
Validation loss: 2.609848619068379

Epoch: 6| Step: 8
Training loss: 2.82417704655629
Validation loss: 2.610917478736135

Epoch: 6| Step: 9
Training loss: 2.707168993947735
Validation loss: 2.6081800789543563

Epoch: 6| Step: 10
Training loss: 2.6823839684070743
Validation loss: 2.6059269309204094

Epoch: 6| Step: 11
Training loss: 2.1875118800249393
Validation loss: 2.6052458447106366

Epoch: 6| Step: 12
Training loss: 2.274985294504112
Validation loss: 2.6024152486525027

Epoch: 6| Step: 13
Training loss: 2.9754183114501385
Validation loss: 2.599178470520763

Epoch: 62| Step: 0
Training loss: 2.8319719821384512
Validation loss: 2.5994520973340576

Epoch: 6| Step: 1
Training loss: 2.6324551393575506
Validation loss: 2.6009602503522724

Epoch: 6| Step: 2
Training loss: 2.77415065998728
Validation loss: 2.6006878364817445

Epoch: 6| Step: 3
Training loss: 2.77398573064125
Validation loss: 2.5999797936412374

Epoch: 6| Step: 4
Training loss: 2.8815129356643325
Validation loss: 2.600167405412278

Epoch: 6| Step: 5
Training loss: 2.813938027551494
Validation loss: 2.6008962822552135

Epoch: 6| Step: 6
Training loss: 3.0566577849957617
Validation loss: 2.599276144183084

Epoch: 6| Step: 7
Training loss: 2.162024684994459
Validation loss: 2.599170367829514

Epoch: 6| Step: 8
Training loss: 3.35877367892222
Validation loss: 2.59760630471154

Epoch: 6| Step: 9
Training loss: 2.300578757735634
Validation loss: 2.5956000658505274

Epoch: 6| Step: 10
Training loss: 2.857264505930129
Validation loss: 2.595530148022367

Epoch: 6| Step: 11
Training loss: 2.3941108371887525
Validation loss: 2.59366590677618

Epoch: 6| Step: 12
Training loss: 2.6269235375308684
Validation loss: 2.59321581077367

Epoch: 6| Step: 13
Training loss: 2.587037742713964
Validation loss: 2.592546758423191

Epoch: 63| Step: 0
Training loss: 2.82804558573973
Validation loss: 2.591974976243194

Epoch: 6| Step: 1
Training loss: 3.135508150474869
Validation loss: 2.5909476250729138

Epoch: 6| Step: 2
Training loss: 2.8840961028024354
Validation loss: 2.593945430762027

Epoch: 6| Step: 3
Training loss: 2.4123302775555993
Validation loss: 2.5867892703596955

Epoch: 6| Step: 4
Training loss: 2.546788688086457
Validation loss: 2.5944095676845214

Epoch: 6| Step: 5
Training loss: 2.6380496134918747
Validation loss: 2.6037442793030143

Epoch: 6| Step: 6
Training loss: 2.0491097168560466
Validation loss: 2.6073522741812742

Epoch: 6| Step: 7
Training loss: 2.259093030374193
Validation loss: 2.6092406978803817

Epoch: 6| Step: 8
Training loss: 3.1635554908213415
Validation loss: 2.589326970941497

Epoch: 6| Step: 9
Training loss: 2.5192539742656015
Validation loss: 2.587695888653875

Epoch: 6| Step: 10
Training loss: 2.9648678744695394
Validation loss: 2.5813710440640976

Epoch: 6| Step: 11
Training loss: 2.655730073196387
Validation loss: 2.583255533359451

Epoch: 6| Step: 12
Training loss: 3.1020859437568156
Validation loss: 2.5840256030041573

Epoch: 6| Step: 13
Training loss: 2.8263776238977467
Validation loss: 2.5863846683241287

Epoch: 64| Step: 0
Training loss: 2.522994531069894
Validation loss: 2.5871901460226963

Epoch: 6| Step: 1
Training loss: 2.674739885607189
Validation loss: 2.5858481892109735

Epoch: 6| Step: 2
Training loss: 2.455987608583236
Validation loss: 2.5838195332996867

Epoch: 6| Step: 3
Training loss: 3.024490212604858
Validation loss: 2.5851181284158327

Epoch: 6| Step: 4
Training loss: 2.958716855687429
Validation loss: 2.5814356345359206

Epoch: 6| Step: 5
Training loss: 2.41422821760034
Validation loss: 2.584247863053215

Epoch: 6| Step: 6
Training loss: 2.165904449003777
Validation loss: 2.5855891827721353

Epoch: 6| Step: 7
Training loss: 3.284369448177099
Validation loss: 2.5842271970884587

Epoch: 6| Step: 8
Training loss: 2.953431774533851
Validation loss: 2.5777038384343927

Epoch: 6| Step: 9
Training loss: 2.886602458753684
Validation loss: 2.577856246349525

Epoch: 6| Step: 10
Training loss: 3.072858768930643
Validation loss: 2.5763637653461418

Epoch: 6| Step: 11
Training loss: 2.542627642792987
Validation loss: 2.574195224961265

Epoch: 6| Step: 12
Training loss: 2.5962673059216392
Validation loss: 2.5749764067917713

Epoch: 6| Step: 13
Training loss: 2.220520924631717
Validation loss: 2.5764094337907792

Epoch: 65| Step: 0
Training loss: 1.8258835835276308
Validation loss: 2.578685784279229

Epoch: 6| Step: 1
Training loss: 3.0478370125914322
Validation loss: 2.581488263184473

Epoch: 6| Step: 2
Training loss: 2.8517180099933634
Validation loss: 2.5844998853430927

Epoch: 6| Step: 3
Training loss: 3.0006037740308247
Validation loss: 2.5844980403543154

Epoch: 6| Step: 4
Training loss: 2.6079566435749744
Validation loss: 2.578931246989499

Epoch: 6| Step: 5
Training loss: 3.228534382271207
Validation loss: 2.5748617925250405

Epoch: 6| Step: 6
Training loss: 2.5769090038926987
Validation loss: 2.5738104736229244

Epoch: 6| Step: 7
Training loss: 2.9349514883474033
Validation loss: 2.5692777705619276

Epoch: 6| Step: 8
Training loss: 2.7539954204867536
Validation loss: 2.570249778963991

Epoch: 6| Step: 9
Training loss: 2.5335370316510217
Validation loss: 2.5645923910799655

Epoch: 6| Step: 10
Training loss: 3.1736440751923363
Validation loss: 2.567052843923809

Epoch: 6| Step: 11
Training loss: 2.418069618598564
Validation loss: 2.565635127900578

Epoch: 6| Step: 12
Training loss: 2.2632994193156613
Validation loss: 2.564670666824975

Epoch: 6| Step: 13
Training loss: 2.3358262459788848
Validation loss: 2.561920682039613

Epoch: 66| Step: 0
Training loss: 2.745964123201879
Validation loss: 2.561963304280679

Epoch: 6| Step: 1
Training loss: 2.942739156826032
Validation loss: 2.5592954183090098

Epoch: 6| Step: 2
Training loss: 2.819660565800314
Validation loss: 2.5597595199247483

Epoch: 6| Step: 3
Training loss: 2.2157363842082387
Validation loss: 2.5573619721505927

Epoch: 6| Step: 4
Training loss: 2.884932237487144
Validation loss: 2.559710775667032

Epoch: 6| Step: 5
Training loss: 2.1554905756543263
Validation loss: 2.557497398248358

Epoch: 6| Step: 6
Training loss: 2.583607064378066
Validation loss: 2.5557205802276224

Epoch: 6| Step: 7
Training loss: 3.187170273425416
Validation loss: 2.555967766462518

Epoch: 6| Step: 8
Training loss: 2.779970196077048
Validation loss: 2.5566914171846964

Epoch: 6| Step: 9
Training loss: 2.484140349048981
Validation loss: 2.5581569153122694

Epoch: 6| Step: 10
Training loss: 2.278859702109947
Validation loss: 2.5537337487528826

Epoch: 6| Step: 11
Training loss: 2.643399378114627
Validation loss: 2.5549715527756782

Epoch: 6| Step: 12
Training loss: 2.778847932243844
Validation loss: 2.5528058073930744

Epoch: 6| Step: 13
Training loss: 2.9803541968893588
Validation loss: 2.5541825879478726

Epoch: 67| Step: 0
Training loss: 2.6813822466908093
Validation loss: 2.552158172963307

Epoch: 6| Step: 1
Training loss: 2.2701719761708805
Validation loss: 2.5511043824887274

Epoch: 6| Step: 2
Training loss: 2.5123688848644927
Validation loss: 2.5480080952827655

Epoch: 6| Step: 3
Training loss: 2.515091454452795
Validation loss: 2.553301311678908

Epoch: 6| Step: 4
Training loss: 2.4183644108141418
Validation loss: 2.5481237770759417

Epoch: 6| Step: 5
Training loss: 3.403447249246822
Validation loss: 2.551491078274395

Epoch: 6| Step: 6
Training loss: 3.0238437428950116
Validation loss: 2.5478476010992743

Epoch: 6| Step: 7
Training loss: 2.259991923798841
Validation loss: 2.5486397275320014

Epoch: 6| Step: 8
Training loss: 2.7579980198864815
Validation loss: 2.5492057822565286

Epoch: 6| Step: 9
Training loss: 2.919459522602389
Validation loss: 2.555193198701306

Epoch: 6| Step: 10
Training loss: 2.844515519280693
Validation loss: 2.5558225732938995

Epoch: 6| Step: 11
Training loss: 2.547955055810574
Validation loss: 2.5560915604839334

Epoch: 6| Step: 12
Training loss: 2.8608516361470775
Validation loss: 2.5579037577996258

Epoch: 6| Step: 13
Training loss: 2.443446413192953
Validation loss: 2.5593449312523457

Epoch: 68| Step: 0
Training loss: 2.7190639270760752
Validation loss: 2.557055885234343

Epoch: 6| Step: 1
Training loss: 3.030035817907157
Validation loss: 2.5565490006828457

Epoch: 6| Step: 2
Training loss: 2.391682708721878
Validation loss: 2.555139857381713

Epoch: 6| Step: 3
Training loss: 2.533096393580861
Validation loss: 2.55097092239235

Epoch: 6| Step: 4
Training loss: 2.924274295867387
Validation loss: 2.5505273136624993

Epoch: 6| Step: 5
Training loss: 2.305581233125453
Validation loss: 2.546177103418946

Epoch: 6| Step: 6
Training loss: 2.6047438223549806
Validation loss: 2.5426771833758743

Epoch: 6| Step: 7
Training loss: 3.0913636222717282
Validation loss: 2.5429386697719707

Epoch: 6| Step: 8
Training loss: 2.440470719192876
Validation loss: 2.5427422879233714

Epoch: 6| Step: 9
Training loss: 2.833721209137074
Validation loss: 2.5506781050433402

Epoch: 6| Step: 10
Training loss: 2.874886551982109
Validation loss: 2.5595270449384517

Epoch: 6| Step: 11
Training loss: 2.3870078253615765
Validation loss: 2.5558461430637713

Epoch: 6| Step: 12
Training loss: 2.863127200782195
Validation loss: 2.5468644217991114

Epoch: 6| Step: 13
Training loss: 2.621391995740204
Validation loss: 2.5361779989516777

Epoch: 69| Step: 0
Training loss: 2.7478782097759935
Validation loss: 2.538866201784461

Epoch: 6| Step: 1
Training loss: 2.607875187362096
Validation loss: 2.5387859956865055

Epoch: 6| Step: 2
Training loss: 2.9243985462484083
Validation loss: 2.542785356650285

Epoch: 6| Step: 3
Training loss: 2.7323969198400273
Validation loss: 2.5437516952121593

Epoch: 6| Step: 4
Training loss: 2.5492091803878187
Validation loss: 2.5466549238047396

Epoch: 6| Step: 5
Training loss: 2.6521604584184733
Validation loss: 2.5474993168733557

Epoch: 6| Step: 6
Training loss: 2.408197382837335
Validation loss: 2.5529843562845094

Epoch: 6| Step: 7
Training loss: 2.563147672354328
Validation loss: 2.5525505624334452

Epoch: 6| Step: 8
Training loss: 2.8850586780418572
Validation loss: 2.5577749247617447

Epoch: 6| Step: 9
Training loss: 3.1405595611283394
Validation loss: 2.553943303989714

Epoch: 6| Step: 10
Training loss: 2.225840026357917
Validation loss: 2.5524011582713153

Epoch: 6| Step: 11
Training loss: 2.710974965125212
Validation loss: 2.5516387136943575

Epoch: 6| Step: 12
Training loss: 2.225737408801733
Validation loss: 2.549668743708054

Epoch: 6| Step: 13
Training loss: 2.976934775153392
Validation loss: 2.5484027298068384

Epoch: 70| Step: 0
Training loss: 2.9398377227113173
Validation loss: 2.54470256681189

Epoch: 6| Step: 1
Training loss: 1.8631452914684274
Validation loss: 2.5432951327571907

Epoch: 6| Step: 2
Training loss: 2.8306718181192485
Validation loss: 2.539786258149685

Epoch: 6| Step: 3
Training loss: 2.8934266406130593
Validation loss: 2.538090704766288

Epoch: 6| Step: 4
Training loss: 2.36560549608301
Validation loss: 2.5366419204184925

Epoch: 6| Step: 5
Training loss: 3.143022675304075
Validation loss: 2.5361213120748265

Epoch: 6| Step: 6
Training loss: 2.604809450293604
Validation loss: 2.53488653048163

Epoch: 6| Step: 7
Training loss: 2.4566855862155097
Validation loss: 2.528700356856509

Epoch: 6| Step: 8
Training loss: 2.81427945958605
Validation loss: 2.5250428784698626

Epoch: 6| Step: 9
Training loss: 2.906880136082208
Validation loss: 2.52962259480694

Epoch: 6| Step: 10
Training loss: 2.382858526066754
Validation loss: 2.521258552144641

Epoch: 6| Step: 11
Training loss: 2.3813136655451665
Validation loss: 2.524863738610343

Epoch: 6| Step: 12
Training loss: 2.7799907791204324
Validation loss: 2.5246386429962526

Epoch: 6| Step: 13
Training loss: 2.629548355745963
Validation loss: 2.529884488103673

Epoch: 71| Step: 0
Training loss: 2.112284031950846
Validation loss: 2.5237970716027016

Epoch: 6| Step: 1
Training loss: 2.734323555598653
Validation loss: 2.5255572192045856

Epoch: 6| Step: 2
Training loss: 2.414676328968676
Validation loss: 2.526092675601821

Epoch: 6| Step: 3
Training loss: 2.617898144249419
Validation loss: 2.524256412937848

Epoch: 6| Step: 4
Training loss: 2.8051759937309537
Validation loss: 2.520775176919603

Epoch: 6| Step: 5
Training loss: 2.900949546314736
Validation loss: 2.5219895349056536

Epoch: 6| Step: 6
Training loss: 2.091681640186389
Validation loss: 2.5230170845524778

Epoch: 6| Step: 7
Training loss: 2.7675934591252154
Validation loss: 2.517861250964533

Epoch: 6| Step: 8
Training loss: 2.6628304146642052
Validation loss: 2.5220351992764223

Epoch: 6| Step: 9
Training loss: 2.4055035907319726
Validation loss: 2.521942814037703

Epoch: 6| Step: 10
Training loss: 2.788439085285643
Validation loss: 2.5207228570695173

Epoch: 6| Step: 11
Training loss: 2.9918380015268826
Validation loss: 2.5155912756386996

Epoch: 6| Step: 12
Training loss: 2.854337329820571
Validation loss: 2.522652077654187

Epoch: 6| Step: 13
Training loss: 2.7627981793106153
Validation loss: 2.5230837515942266

Epoch: 72| Step: 0
Training loss: 3.203829952913778
Validation loss: 2.521369220321234

Epoch: 6| Step: 1
Training loss: 2.625528373220603
Validation loss: 2.5216220903795366

Epoch: 6| Step: 2
Training loss: 2.984357424379693
Validation loss: 2.5211325118492813

Epoch: 6| Step: 3
Training loss: 2.5962668467651424
Validation loss: 2.517914971702401

Epoch: 6| Step: 4
Training loss: 2.289535942200393
Validation loss: 2.5160932717149818

Epoch: 6| Step: 5
Training loss: 2.462261897160316
Validation loss: 2.5170887860438693

Epoch: 6| Step: 6
Training loss: 3.0249098709172895
Validation loss: 2.5165972834826915

Epoch: 6| Step: 7
Training loss: 2.6544960065169625
Validation loss: 2.5148326818628113

Epoch: 6| Step: 8
Training loss: 2.2389750046282555
Validation loss: 2.5127958496792013

Epoch: 6| Step: 9
Training loss: 2.7427313719024635
Validation loss: 2.5188889742012086

Epoch: 6| Step: 10
Training loss: 2.207703290588412
Validation loss: 2.5154484436124163

Epoch: 6| Step: 11
Training loss: 2.751128138712193
Validation loss: 2.520751279225848

Epoch: 6| Step: 12
Training loss: 2.2793998008573304
Validation loss: 2.5171967487098206

Epoch: 6| Step: 13
Training loss: 2.7798375175525853
Validation loss: 2.510898121823925

Epoch: 73| Step: 0
Training loss: 3.0689079042042473
Validation loss: 2.513568187394016

Epoch: 6| Step: 1
Training loss: 2.8672483682018295
Validation loss: 2.513792962292504

Epoch: 6| Step: 2
Training loss: 2.6606762079602917
Validation loss: 2.5110134718581802

Epoch: 6| Step: 3
Training loss: 2.8111119553870876
Validation loss: 2.512330182031726

Epoch: 6| Step: 4
Training loss: 2.140262099641905
Validation loss: 2.511537346585202

Epoch: 6| Step: 5
Training loss: 2.441583489660184
Validation loss: 2.503755720655432

Epoch: 6| Step: 6
Training loss: 2.65364934729486
Validation loss: 2.5062249091232944

Epoch: 6| Step: 7
Training loss: 2.557177342321609
Validation loss: 2.5093155552595436

Epoch: 6| Step: 8
Training loss: 2.966257755801498
Validation loss: 2.506868305500114

Epoch: 6| Step: 9
Training loss: 3.0340993801228584
Validation loss: 2.507404076264998

Epoch: 6| Step: 10
Training loss: 2.676224675991898
Validation loss: 2.509668711016937

Epoch: 6| Step: 11
Training loss: 2.355120125397792
Validation loss: 2.515214337619008

Epoch: 6| Step: 12
Training loss: 2.407357691661758
Validation loss: 2.5203902325405663

Epoch: 6| Step: 13
Training loss: 2.1910168306861206
Validation loss: 2.5246314736654867

Epoch: 74| Step: 0
Training loss: 2.510601263791109
Validation loss: 2.524763107518104

Epoch: 6| Step: 1
Training loss: 2.4149883186263166
Validation loss: 2.5218778185570656

Epoch: 6| Step: 2
Training loss: 2.0494515313333634
Validation loss: 2.5209530310678256

Epoch: 6| Step: 3
Training loss: 2.857874742500665
Validation loss: 2.519852429009926

Epoch: 6| Step: 4
Training loss: 2.3243929244743007
Validation loss: 2.516531518334672

Epoch: 6| Step: 5
Training loss: 2.8467976095858742
Validation loss: 2.5110029957807996

Epoch: 6| Step: 6
Training loss: 2.494249405725383
Validation loss: 2.5036308307699477

Epoch: 6| Step: 7
Training loss: 2.988726414452205
Validation loss: 2.5131568410697236

Epoch: 6| Step: 8
Training loss: 2.4718037321327815
Validation loss: 2.5255230453165796

Epoch: 6| Step: 9
Training loss: 3.079763837900759
Validation loss: 2.5309029643461876

Epoch: 6| Step: 10
Training loss: 2.7962057495708548
Validation loss: 2.5120131031907476

Epoch: 6| Step: 11
Training loss: 2.8790518362845057
Validation loss: 2.498807861284128

Epoch: 6| Step: 12
Training loss: 2.6363611953747967
Validation loss: 2.5067018800740977

Epoch: 6| Step: 13
Training loss: 2.787704521853001
Validation loss: 2.5108591114556296

Epoch: 75| Step: 0
Training loss: 2.9403917404559055
Validation loss: 2.517032284946487

Epoch: 6| Step: 1
Training loss: 2.8744715329305195
Validation loss: 2.5315143305903876

Epoch: 6| Step: 2
Training loss: 2.518620573367559
Validation loss: 2.5534822379817155

Epoch: 6| Step: 3
Training loss: 2.083417534716074
Validation loss: 2.5732256334461203

Epoch: 6| Step: 4
Training loss: 2.8385969150777752
Validation loss: 2.5870982289716142

Epoch: 6| Step: 5
Training loss: 2.691327053726401
Validation loss: 2.582263884113445

Epoch: 6| Step: 6
Training loss: 2.4013391891032483
Validation loss: 2.565704404567848

Epoch: 6| Step: 7
Training loss: 2.997882890720892
Validation loss: 2.5505722840468508

Epoch: 6| Step: 8
Training loss: 2.3565045004287115
Validation loss: 2.536487372909048

Epoch: 6| Step: 9
Training loss: 2.7973760230689257
Validation loss: 2.532866695576502

Epoch: 6| Step: 10
Training loss: 2.409485264492632
Validation loss: 2.522331625350744

Epoch: 6| Step: 11
Training loss: 2.7513148892284107
Validation loss: 2.505828627300844

Epoch: 6| Step: 12
Training loss: 2.737381856798872
Validation loss: 2.5073281173898607

Epoch: 6| Step: 13
Training loss: 2.7377992823490382
Validation loss: 2.4985652144224786

Epoch: 76| Step: 0
Training loss: 2.993636375612384
Validation loss: 2.504399798982648

Epoch: 6| Step: 1
Training loss: 2.893172013170065
Validation loss: 2.5047427965558047

Epoch: 6| Step: 2
Training loss: 2.1539611831539434
Validation loss: 2.5015871731782138

Epoch: 6| Step: 3
Training loss: 2.429011407234101
Validation loss: 2.5067540804183426

Epoch: 6| Step: 4
Training loss: 2.840448831901464
Validation loss: 2.501110418397655

Epoch: 6| Step: 5
Training loss: 2.6753282149559254
Validation loss: 2.5028722317149135

Epoch: 6| Step: 6
Training loss: 3.147074136806852
Validation loss: 2.501060785307624

Epoch: 6| Step: 7
Training loss: 2.7810666313158703
Validation loss: 2.50097091417967

Epoch: 6| Step: 8
Training loss: 2.3420593267365395
Validation loss: 2.4928922224836176

Epoch: 6| Step: 9
Training loss: 2.6353284999488817
Validation loss: 2.502445010795168

Epoch: 6| Step: 10
Training loss: 2.464691302486527
Validation loss: 2.5021852638219073

Epoch: 6| Step: 11
Training loss: 2.036267348860148
Validation loss: 2.500716631220434

Epoch: 6| Step: 12
Training loss: 2.6976801548883835
Validation loss: 2.5035526781796813

Epoch: 6| Step: 13
Training loss: 2.668771648095838
Validation loss: 2.5018150416557634

Epoch: 77| Step: 0
Training loss: 1.9589031959516578
Validation loss: 2.50553817851076

Epoch: 6| Step: 1
Training loss: 2.9156376976399048
Validation loss: 2.503349730348623

Epoch: 6| Step: 2
Training loss: 2.6557426416883536
Validation loss: 2.4978841251886905

Epoch: 6| Step: 3
Training loss: 2.7196895685881697
Validation loss: 2.500364054557716

Epoch: 6| Step: 4
Training loss: 2.919726882598735
Validation loss: 2.4939029732730376

Epoch: 6| Step: 5
Training loss: 2.427535008218314
Validation loss: 2.494149148558548

Epoch: 6| Step: 6
Training loss: 2.2959147411758956
Validation loss: 2.4948288364601354

Epoch: 6| Step: 7
Training loss: 2.603436594033281
Validation loss: 2.498211188898563

Epoch: 6| Step: 8
Training loss: 2.19174512667118
Validation loss: 2.4936810266426077

Epoch: 6| Step: 9
Training loss: 2.6265962379553525
Validation loss: 2.4942944428707285

Epoch: 6| Step: 10
Training loss: 2.537998763051795
Validation loss: 2.495343719968684

Epoch: 6| Step: 11
Training loss: 3.0452366263115733
Validation loss: 2.498503857197207

Epoch: 6| Step: 12
Training loss: 2.7713314172797623
Validation loss: 2.4925976358955424

Epoch: 6| Step: 13
Training loss: 2.866135905906754
Validation loss: 2.4957648962590784

Epoch: 78| Step: 0
Training loss: 2.8016767998700662
Validation loss: 2.4959989319782743

Epoch: 6| Step: 1
Training loss: 3.0162147380160444
Validation loss: 2.49375547314444

Epoch: 6| Step: 2
Training loss: 2.4764869269263388
Validation loss: 2.492407140350766

Epoch: 6| Step: 3
Training loss: 2.6069242195379547
Validation loss: 2.492827147029971

Epoch: 6| Step: 4
Training loss: 2.1565349224755646
Validation loss: 2.4932472901448945

Epoch: 6| Step: 5
Training loss: 2.352866486107219
Validation loss: 2.4981321668740786

Epoch: 6| Step: 6
Training loss: 2.6221840604692037
Validation loss: 2.4959103512436727

Epoch: 6| Step: 7
Training loss: 2.353293456675389
Validation loss: 2.4890388680817126

Epoch: 6| Step: 8
Training loss: 2.6086157876380813
Validation loss: 2.4900114789950956

Epoch: 6| Step: 9
Training loss: 2.9111989860602088
Validation loss: 2.4846412627969645

Epoch: 6| Step: 10
Training loss: 2.4383999068097473
Validation loss: 2.4850125084657506

Epoch: 6| Step: 11
Training loss: 2.445219287984824
Validation loss: 2.4902261890950017

Epoch: 6| Step: 12
Training loss: 3.2827913569587017
Validation loss: 2.496472285724947

Epoch: 6| Step: 13
Training loss: 2.425083717395536
Validation loss: 2.4847269828537075

Epoch: 79| Step: 0
Training loss: 2.712117490738433
Validation loss: 2.489038245463489

Epoch: 6| Step: 1
Training loss: 2.1495911985804192
Validation loss: 2.487984967520583

Epoch: 6| Step: 2
Training loss: 2.1480933451269437
Validation loss: 2.4876254428690423

Epoch: 6| Step: 3
Training loss: 2.552543276906575
Validation loss: 2.4860561768508393

Epoch: 6| Step: 4
Training loss: 2.796860167394765
Validation loss: 2.4912652648162075

Epoch: 6| Step: 5
Training loss: 1.8499546715621755
Validation loss: 2.4920388618876155

Epoch: 6| Step: 6
Training loss: 2.7074795086226997
Validation loss: 2.4831801126135993

Epoch: 6| Step: 7
Training loss: 2.5360058975632502
Validation loss: 2.49088804354864

Epoch: 6| Step: 8
Training loss: 2.8301040721938553
Validation loss: 2.491444061269892

Epoch: 6| Step: 9
Training loss: 2.847075812651184
Validation loss: 2.4878790753468274

Epoch: 6| Step: 10
Training loss: 2.7967681011890515
Validation loss: 2.4914306798921224

Epoch: 6| Step: 11
Training loss: 2.484667490889516
Validation loss: 2.4914067240160636

Epoch: 6| Step: 12
Training loss: 2.553449978450714
Validation loss: 2.4900047764866375

Epoch: 6| Step: 13
Training loss: 3.2520085510479317
Validation loss: 2.4895941815213085

Epoch: 80| Step: 0
Training loss: 2.5822788875787337
Validation loss: 2.4921260495317976

Epoch: 6| Step: 1
Training loss: 3.143007200547799
Validation loss: 2.4878944723169703

Epoch: 6| Step: 2
Training loss: 2.2291546640043274
Validation loss: 2.4862500997817896

Epoch: 6| Step: 3
Training loss: 2.6324910043995646
Validation loss: 2.482706609364008

Epoch: 6| Step: 4
Training loss: 2.703503003454048
Validation loss: 2.489922334156842

Epoch: 6| Step: 5
Training loss: 2.557185919932605
Validation loss: 2.486158726293647

Epoch: 6| Step: 6
Training loss: 2.8885850461299536
Validation loss: 2.489101480329245

Epoch: 6| Step: 7
Training loss: 2.490790761986064
Validation loss: 2.488632935843212

Epoch: 6| Step: 8
Training loss: 2.6189581048621595
Validation loss: 2.4856851909672417

Epoch: 6| Step: 9
Training loss: 2.208998729817693
Validation loss: 2.4840987269817303

Epoch: 6| Step: 10
Training loss: 2.384046891461759
Validation loss: 2.482098349982121

Epoch: 6| Step: 11
Training loss: 2.3141186178693562
Validation loss: 2.4869058062267233

Epoch: 6| Step: 12
Training loss: 2.8101106454915232
Validation loss: 2.4831296250512844

Epoch: 6| Step: 13
Training loss: 2.716456531128421
Validation loss: 2.4808803747464907

Epoch: 81| Step: 0
Training loss: 2.486772256336075
Validation loss: 2.4789888147196937

Epoch: 6| Step: 1
Training loss: 2.797066879083894
Validation loss: 2.483752126604823

Epoch: 6| Step: 2
Training loss: 2.739745092995161
Validation loss: 2.4831160548436526

Epoch: 6| Step: 3
Training loss: 3.305867879379496
Validation loss: 2.48648121160991

Epoch: 6| Step: 4
Training loss: 2.3290352290082317
Validation loss: 2.4878604678854144

Epoch: 6| Step: 5
Training loss: 2.2882918274577357
Validation loss: 2.4905978068514933

Epoch: 6| Step: 6
Training loss: 2.2106278812647435
Validation loss: 2.4879256652642034

Epoch: 6| Step: 7
Training loss: 2.4034183238852536
Validation loss: 2.490358548527868

Epoch: 6| Step: 8
Training loss: 2.976506430430734
Validation loss: 2.486205580199325

Epoch: 6| Step: 9
Training loss: 2.913405929929578
Validation loss: 2.480553140481265

Epoch: 6| Step: 10
Training loss: 2.199049948249525
Validation loss: 2.4815847214320077

Epoch: 6| Step: 11
Training loss: 2.600941260226372
Validation loss: 2.480566628595034

Epoch: 6| Step: 12
Training loss: 2.3941415093075338
Validation loss: 2.480543737204168

Epoch: 6| Step: 13
Training loss: 2.6131740485357406
Validation loss: 2.476380198093734

Epoch: 82| Step: 0
Training loss: 2.8646238751865947
Validation loss: 2.476304980506423

Epoch: 6| Step: 1
Training loss: 2.29508206721491
Validation loss: 2.4889972800350693

Epoch: 6| Step: 2
Training loss: 2.922002779364651
Validation loss: 2.4790931070992457

Epoch: 6| Step: 3
Training loss: 2.2625152292318615
Validation loss: 2.4838481000454364

Epoch: 6| Step: 4
Training loss: 2.476744251020064
Validation loss: 2.4835042647178

Epoch: 6| Step: 5
Training loss: 2.538982214025137
Validation loss: 2.4808912823458718

Epoch: 6| Step: 6
Training loss: 3.226544470194026
Validation loss: 2.4793732233844863

Epoch: 6| Step: 7
Training loss: 2.16874777054466
Validation loss: 2.476150590755283

Epoch: 6| Step: 8
Training loss: 2.1312709729010106
Validation loss: 2.4763063605189988

Epoch: 6| Step: 9
Training loss: 2.6150105546552296
Validation loss: 2.4775625750777115

Epoch: 6| Step: 10
Training loss: 2.8394106780020483
Validation loss: 2.481364987877431

Epoch: 6| Step: 11
Training loss: 3.026114449252233
Validation loss: 2.481018077667626

Epoch: 6| Step: 12
Training loss: 2.296483635809011
Validation loss: 2.4783930225876225

Epoch: 6| Step: 13
Training loss: 2.406301126308516
Validation loss: 2.482303131328899

Epoch: 83| Step: 0
Training loss: 2.66930082474894
Validation loss: 2.481861738612861

Epoch: 6| Step: 1
Training loss: 2.3313430972085287
Validation loss: 2.4801975051876357

Epoch: 6| Step: 2
Training loss: 2.166589906751078
Validation loss: 2.4871676601592063

Epoch: 6| Step: 3
Training loss: 2.2796154698476347
Validation loss: 2.4882303948348206

Epoch: 6| Step: 4
Training loss: 2.866424874894775
Validation loss: 2.4893233723498187

Epoch: 6| Step: 5
Training loss: 3.297322464358007
Validation loss: 2.488334539412734

Epoch: 6| Step: 6
Training loss: 2.655732945999795
Validation loss: 2.4853763281806778

Epoch: 6| Step: 7
Training loss: 3.111884862941995
Validation loss: 2.4841909760270333

Epoch: 6| Step: 8
Training loss: 2.1814862011357876
Validation loss: 2.480842037597838

Epoch: 6| Step: 9
Training loss: 2.671421391759423
Validation loss: 2.483172799581778

Epoch: 6| Step: 10
Training loss: 2.1731559214505403
Validation loss: 2.4797359956174807

Epoch: 6| Step: 11
Training loss: 2.133193879735276
Validation loss: 2.475110387427596

Epoch: 6| Step: 12
Training loss: 2.9134835084782624
Validation loss: 2.4771691831743516

Epoch: 6| Step: 13
Training loss: 2.5049517229799956
Validation loss: 2.473680345410157

Epoch: 84| Step: 0
Training loss: 2.3921452095584166
Validation loss: 2.4697794317175457

Epoch: 6| Step: 1
Training loss: 2.682983951055674
Validation loss: 2.476700787940281

Epoch: 6| Step: 2
Training loss: 2.4518297019428372
Validation loss: 2.478402931050217

Epoch: 6| Step: 3
Training loss: 2.4589754548339
Validation loss: 2.482523662202105

Epoch: 6| Step: 4
Training loss: 2.656389748880108
Validation loss: 2.4787974737189673

Epoch: 6| Step: 5
Training loss: 2.430617470331121
Validation loss: 2.472535237368826

Epoch: 6| Step: 6
Training loss: 2.4919944377488075
Validation loss: 2.4758660653937055

Epoch: 6| Step: 7
Training loss: 3.17638358659797
Validation loss: 2.474189038143945

Epoch: 6| Step: 8
Training loss: 2.4219326873799996
Validation loss: 2.4750732693599917

Epoch: 6| Step: 9
Training loss: 2.513653379430061
Validation loss: 2.473127379488176

Epoch: 6| Step: 10
Training loss: 1.782351237077589
Validation loss: 2.473007908342743

Epoch: 6| Step: 11
Training loss: 2.799893503207395
Validation loss: 2.4755666758372947

Epoch: 6| Step: 12
Training loss: 3.0646466886366976
Validation loss: 2.478314843749097

Epoch: 6| Step: 13
Training loss: 2.8253441727547184
Validation loss: 2.4757218322974834

Epoch: 85| Step: 0
Training loss: 2.114881773185154
Validation loss: 2.4750889948376473

Epoch: 6| Step: 1
Training loss: 2.149328761334128
Validation loss: 2.475167492295004

Epoch: 6| Step: 2
Training loss: 2.613790465324
Validation loss: 2.4738978221252386

Epoch: 6| Step: 3
Training loss: 2.909744622734313
Validation loss: 2.4743714533086107

Epoch: 6| Step: 4
Training loss: 2.4197624591231146
Validation loss: 2.477123193016432

Epoch: 6| Step: 5
Training loss: 2.5244405069939857
Validation loss: 2.4745506032755498

Epoch: 6| Step: 6
Training loss: 2.17469308375801
Validation loss: 2.474705751183727

Epoch: 6| Step: 7
Training loss: 2.6498225818478858
Validation loss: 2.469400811021457

Epoch: 6| Step: 8
Training loss: 2.5977516099449223
Validation loss: 2.4708936776119947

Epoch: 6| Step: 9
Training loss: 2.7478126149485007
Validation loss: 2.468725405542378

Epoch: 6| Step: 10
Training loss: 2.512338612245926
Validation loss: 2.4705763230183533

Epoch: 6| Step: 11
Training loss: 2.7733484388209053
Validation loss: 2.47228771353948

Epoch: 6| Step: 12
Training loss: 2.7739568519564455
Validation loss: 2.470539989287529

Epoch: 6| Step: 13
Training loss: 3.2206182890869672
Validation loss: 2.4757668935035095

Epoch: 86| Step: 0
Training loss: 2.902953873139426
Validation loss: 2.4733550503986357

Epoch: 6| Step: 1
Training loss: 2.7939613552492926
Validation loss: 2.472563409895401

Epoch: 6| Step: 2
Training loss: 3.026614075370441
Validation loss: 2.4758342390166836

Epoch: 6| Step: 3
Training loss: 1.7979553955197456
Validation loss: 2.4754760477027937

Epoch: 6| Step: 4
Training loss: 2.0134405082740554
Validation loss: 2.4799598071599642

Epoch: 6| Step: 5
Training loss: 3.2173953863178544
Validation loss: 2.474067626680555

Epoch: 6| Step: 6
Training loss: 2.5378937364100906
Validation loss: 2.4756426461751455

Epoch: 6| Step: 7
Training loss: 2.4631199438802556
Validation loss: 2.476414247842846

Epoch: 6| Step: 8
Training loss: 2.8065677386478045
Validation loss: 2.4711505550095048

Epoch: 6| Step: 9
Training loss: 2.7151162429288305
Validation loss: 2.4817053728520273

Epoch: 6| Step: 10
Training loss: 2.463788225176439
Validation loss: 2.4774852361409185

Epoch: 6| Step: 11
Training loss: 1.9741915629620415
Validation loss: 2.478843625176589

Epoch: 6| Step: 12
Training loss: 2.7444580763333706
Validation loss: 2.470354532571484

Epoch: 6| Step: 13
Training loss: 2.450182273468195
Validation loss: 2.4658957935023196

Epoch: 87| Step: 0
Training loss: 2.8468778407127706
Validation loss: 2.468750273628059

Epoch: 6| Step: 1
Training loss: 2.554513161219712
Validation loss: 2.473000597366403

Epoch: 6| Step: 2
Training loss: 2.6170411937300826
Validation loss: 2.471406465117049

Epoch: 6| Step: 3
Training loss: 2.618375867097099
Validation loss: 2.475762511808699

Epoch: 6| Step: 4
Training loss: 2.103576942619815
Validation loss: 2.471839114900027

Epoch: 6| Step: 5
Training loss: 2.469312676155219
Validation loss: 2.473391808678001

Epoch: 6| Step: 6
Training loss: 2.1919777952726305
Validation loss: 2.4728849525207033

Epoch: 6| Step: 7
Training loss: 2.4925250838231396
Validation loss: 2.4750813287801128

Epoch: 6| Step: 8
Training loss: 3.058917382901984
Validation loss: 2.4798019193689296

Epoch: 6| Step: 9
Training loss: 2.6669052037204293
Validation loss: 2.4761148844479943

Epoch: 6| Step: 10
Training loss: 2.804034313764683
Validation loss: 2.472801095778828

Epoch: 6| Step: 11
Training loss: 2.3922403899063664
Validation loss: 2.467531007895904

Epoch: 6| Step: 12
Training loss: 2.1117215138543233
Validation loss: 2.473611286650484

Epoch: 6| Step: 13
Training loss: 3.046292136757521
Validation loss: 2.4725789986626276

Epoch: 88| Step: 0
Training loss: 3.443278086152302
Validation loss: 2.4757189030900726

Epoch: 6| Step: 1
Training loss: 2.2130536308081763
Validation loss: 2.4690999776910996

Epoch: 6| Step: 2
Training loss: 2.503615340117318
Validation loss: 2.46682748098508

Epoch: 6| Step: 3
Training loss: 2.39613316083449
Validation loss: 2.4668579738336396

Epoch: 6| Step: 4
Training loss: 2.791634535723199
Validation loss: 2.4648041437335326

Epoch: 6| Step: 5
Training loss: 2.1506089213179584
Validation loss: 2.467106187385252

Epoch: 6| Step: 6
Training loss: 2.491251898428447
Validation loss: 2.4705946103115273

Epoch: 6| Step: 7
Training loss: 2.7292923255315773
Validation loss: 2.4712835260926815

Epoch: 6| Step: 8
Training loss: 2.8659628765632794
Validation loss: 2.4691362521456677

Epoch: 6| Step: 9
Training loss: 2.6228631722891182
Validation loss: 2.4772396345263994

Epoch: 6| Step: 10
Training loss: 2.453911819135922
Validation loss: 2.471759860656254

Epoch: 6| Step: 11
Training loss: 2.7237550113766678
Validation loss: 2.4707307072684292

Epoch: 6| Step: 12
Training loss: 2.3967758536193315
Validation loss: 2.4670400049156247

Epoch: 6| Step: 13
Training loss: 2.1356229604924004
Validation loss: 2.4702478363755493

Epoch: 89| Step: 0
Training loss: 2.4203399715748466
Validation loss: 2.469968808784147

Epoch: 6| Step: 1
Training loss: 2.4947821524696803
Validation loss: 2.4719855115439167

Epoch: 6| Step: 2
Training loss: 2.2787378143637604
Validation loss: 2.4703720976725894

Epoch: 6| Step: 3
Training loss: 2.768602481812986
Validation loss: 2.475059044901083

Epoch: 6| Step: 4
Training loss: 3.2570492515880853
Validation loss: 2.4699424085196418

Epoch: 6| Step: 5
Training loss: 2.069830842040152
Validation loss: 2.4664047142928665

Epoch: 6| Step: 6
Training loss: 2.645147389882628
Validation loss: 2.4659363369980665

Epoch: 6| Step: 7
Training loss: 2.2191099492769575
Validation loss: 2.4640784992608933

Epoch: 6| Step: 8
Training loss: 2.576315134734475
Validation loss: 2.465800757000117

Epoch: 6| Step: 9
Training loss: 2.8804970309734355
Validation loss: 2.4641690466822754

Epoch: 6| Step: 10
Training loss: 2.6139608505924827
Validation loss: 2.4695793883312165

Epoch: 6| Step: 11
Training loss: 1.9860837292802924
Validation loss: 2.463362420451938

Epoch: 6| Step: 12
Training loss: 3.0988947159250477
Validation loss: 2.4566885219423074

Epoch: 6| Step: 13
Training loss: 2.5428157356038157
Validation loss: 2.464873477456267

Epoch: 90| Step: 0
Training loss: 2.575247528623064
Validation loss: 2.4653241978485174

Epoch: 6| Step: 1
Training loss: 2.8714345301584587
Validation loss: 2.457487257067116

Epoch: 6| Step: 2
Training loss: 2.15966725117626
Validation loss: 2.471670475539061

Epoch: 6| Step: 3
Training loss: 2.6500363545353274
Validation loss: 2.4639310199796287

Epoch: 6| Step: 4
Training loss: 2.544938363338759
Validation loss: 2.470084622332515

Epoch: 6| Step: 5
Training loss: 2.720302445482388
Validation loss: 2.466030183931725

Epoch: 6| Step: 6
Training loss: 2.477674553473908
Validation loss: 2.4706845168467164

Epoch: 6| Step: 7
Training loss: 2.5883409101183306
Validation loss: 2.4655546280649663

Epoch: 6| Step: 8
Training loss: 2.346835838834335
Validation loss: 2.472426441475413

Epoch: 6| Step: 9
Training loss: 2.852174458094087
Validation loss: 2.4702726569633158

Epoch: 6| Step: 10
Training loss: 2.3815900825091534
Validation loss: 2.480720855637032

Epoch: 6| Step: 11
Training loss: 2.769638597482141
Validation loss: 2.4727194377746144

Epoch: 6| Step: 12
Training loss: 2.873052683914505
Validation loss: 2.4697753772710582

Epoch: 6| Step: 13
Training loss: 2.0802309078646535
Validation loss: 2.473166462837727

Epoch: 91| Step: 0
Training loss: 2.694526181723633
Validation loss: 2.4681111245478933

Epoch: 6| Step: 1
Training loss: 2.109980856460581
Validation loss: 2.4717110288098167

Epoch: 6| Step: 2
Training loss: 3.040697143577032
Validation loss: 2.4762369738176324

Epoch: 6| Step: 3
Training loss: 2.8221420313822247
Validation loss: 2.4682953814315534

Epoch: 6| Step: 4
Training loss: 2.2327250544280313
Validation loss: 2.4697553945447006

Epoch: 6| Step: 5
Training loss: 2.45668286884543
Validation loss: 2.4736673980435597

Epoch: 6| Step: 6
Training loss: 1.85691253706343
Validation loss: 2.4709184997530524

Epoch: 6| Step: 7
Training loss: 2.496785194968613
Validation loss: 2.4686329085512306

Epoch: 6| Step: 8
Training loss: 2.7538987179916945
Validation loss: 2.4654311554765447

Epoch: 6| Step: 9
Training loss: 2.887180895326593
Validation loss: 2.46781477134355

Epoch: 6| Step: 10
Training loss: 2.5340167336818418
Validation loss: 2.4603425613686447

Epoch: 6| Step: 11
Training loss: 2.7927471366405276
Validation loss: 2.4665128011226307

Epoch: 6| Step: 12
Training loss: 2.1094580739934794
Validation loss: 2.4641434147623267

Epoch: 6| Step: 13
Training loss: 2.836392789081773
Validation loss: 2.4670658080755214

Epoch: 92| Step: 0
Training loss: 2.671847962359772
Validation loss: 2.4688307994384093

Epoch: 6| Step: 1
Training loss: 2.8499118992088075
Validation loss: 2.4687114422841296

Epoch: 6| Step: 2
Training loss: 2.7839786131793716
Validation loss: 2.4679688453171145

Epoch: 6| Step: 3
Training loss: 2.676658675853667
Validation loss: 2.4635029333401826

Epoch: 6| Step: 4
Training loss: 2.8946910407353452
Validation loss: 2.4637072603623933

Epoch: 6| Step: 5
Training loss: 2.7506856930448063
Validation loss: 2.4689809473877764

Epoch: 6| Step: 6
Training loss: 2.374487570644355
Validation loss: 2.468545398201205

Epoch: 6| Step: 7
Training loss: 2.2197658738407458
Validation loss: 2.4649817926328943

Epoch: 6| Step: 8
Training loss: 2.5061843673217283
Validation loss: 2.469528067583839

Epoch: 6| Step: 9
Training loss: 2.1294642285909355
Validation loss: 2.4692093144249623

Epoch: 6| Step: 10
Training loss: 2.0551917324049844
Validation loss: 2.4728351224991507

Epoch: 6| Step: 11
Training loss: 3.143564547155631
Validation loss: 2.4724375872678723

Epoch: 6| Step: 12
Training loss: 1.7695447234931314
Validation loss: 2.471644575758115

Epoch: 6| Step: 13
Training loss: 3.0049020136187794
Validation loss: 2.479007448698925

Epoch: 93| Step: 0
Training loss: 2.6727257874248203
Validation loss: 2.4786253479743428

Epoch: 6| Step: 1
Training loss: 3.1674688394002835
Validation loss: 2.4763195187398184

Epoch: 6| Step: 2
Training loss: 2.797564117951378
Validation loss: 2.4677830826621547

Epoch: 6| Step: 3
Training loss: 2.8521811454353583
Validation loss: 2.471930230026432

Epoch: 6| Step: 4
Training loss: 2.3955255283053645
Validation loss: 2.4650367463773026

Epoch: 6| Step: 5
Training loss: 2.360526201939458
Validation loss: 2.467439746423781

Epoch: 6| Step: 6
Training loss: 2.4497768611889326
Validation loss: 2.463551266566169

Epoch: 6| Step: 7
Training loss: 2.2351810095281377
Validation loss: 2.4693469038175726

Epoch: 6| Step: 8
Training loss: 2.7297446146133786
Validation loss: 2.467605937370058

Epoch: 6| Step: 9
Training loss: 2.6321875852158882
Validation loss: 2.466238474624805

Epoch: 6| Step: 10
Training loss: 2.298118202960908
Validation loss: 2.4686132304618162

Epoch: 6| Step: 11
Training loss: 2.363848556650636
Validation loss: 2.4640553418081517

Epoch: 6| Step: 12
Training loss: 2.524413118048663
Validation loss: 2.4656567409133894

Epoch: 6| Step: 13
Training loss: 2.7540968808688313
Validation loss: 2.4606155265617344

Epoch: 94| Step: 0
Training loss: 2.5775722026609498
Validation loss: 2.4672433464714834

Epoch: 6| Step: 1
Training loss: 2.4651774378551057
Validation loss: 2.4679906457901994

Epoch: 6| Step: 2
Training loss: 2.4041120270636047
Validation loss: 2.473588089928324

Epoch: 6| Step: 3
Training loss: 2.523623244119311
Validation loss: 2.4763109418343037

Epoch: 6| Step: 4
Training loss: 2.6119164065994678
Validation loss: 2.478157404350602

Epoch: 6| Step: 5
Training loss: 2.8935393617232505
Validation loss: 2.477875097950396

Epoch: 6| Step: 6
Training loss: 2.9608759810767795
Validation loss: 2.4814716704518895

Epoch: 6| Step: 7
Training loss: 2.790031798943774
Validation loss: 2.473287500816237

Epoch: 6| Step: 8
Training loss: 2.7600938908183563
Validation loss: 2.477010772600544

Epoch: 6| Step: 9
Training loss: 2.8766895802787236
Validation loss: 2.470937299122514

Epoch: 6| Step: 10
Training loss: 1.9519671861204322
Validation loss: 2.4723304827223105

Epoch: 6| Step: 11
Training loss: 2.0795347551732895
Validation loss: 2.465364815215769

Epoch: 6| Step: 12
Training loss: 2.5719383222680565
Validation loss: 2.4668004671958124

Epoch: 6| Step: 13
Training loss: 2.4489237776546267
Validation loss: 2.468110625449843

Epoch: 95| Step: 0
Training loss: 2.1148101860345108
Validation loss: 2.468746338209825

Epoch: 6| Step: 1
Training loss: 2.5731565747143343
Validation loss: 2.4668075227041992

Epoch: 6| Step: 2
Training loss: 2.5312727938909085
Validation loss: 2.468284031798255

Epoch: 6| Step: 3
Training loss: 2.4861455402322683
Validation loss: 2.458583468842079

Epoch: 6| Step: 4
Training loss: 2.411799879720653
Validation loss: 2.461645486706544

Epoch: 6| Step: 5
Training loss: 2.28997347154202
Validation loss: 2.4663006023327108

Epoch: 6| Step: 6
Training loss: 3.041769278550414
Validation loss: 2.4685258401434265

Epoch: 6| Step: 7
Training loss: 3.187954739315142
Validation loss: 2.469087810984505

Epoch: 6| Step: 8
Training loss: 2.409661586950136
Validation loss: 2.453216858782028

Epoch: 6| Step: 9
Training loss: 2.313480169471386
Validation loss: 2.4666114590455086

Epoch: 6| Step: 10
Training loss: 3.2049326192405467
Validation loss: 2.463722042284455

Epoch: 6| Step: 11
Training loss: 2.461451110527902
Validation loss: 2.4673938003819185

Epoch: 6| Step: 12
Training loss: 2.4687780064792944
Validation loss: 2.459762712654311

Epoch: 6| Step: 13
Training loss: 2.0783692409999754
Validation loss: 2.4608383481674

Epoch: 96| Step: 0
Training loss: 2.7312123346241277
Validation loss: 2.466581913634721

Epoch: 6| Step: 1
Training loss: 2.8106949842077293
Validation loss: 2.4650455156499795

Epoch: 6| Step: 2
Training loss: 2.924638716075521
Validation loss: 2.4685680145274964

Epoch: 6| Step: 3
Training loss: 2.5509350950806184
Validation loss: 2.475114962929399

Epoch: 6| Step: 4
Training loss: 2.253789254098992
Validation loss: 2.480721864777003

Epoch: 6| Step: 5
Training loss: 2.3206466280101172
Validation loss: 2.4765791706924047

Epoch: 6| Step: 6
Training loss: 2.3977513030630035
Validation loss: 2.4800883484557223

Epoch: 6| Step: 7
Training loss: 3.078786401320503
Validation loss: 2.481503264395894

Epoch: 6| Step: 8
Training loss: 2.5268473071275195
Validation loss: 2.4833599072086354

Epoch: 6| Step: 9
Training loss: 2.7335945105408523
Validation loss: 2.4804005691088844

Epoch: 6| Step: 10
Training loss: 2.9926188583798576
Validation loss: 2.47565381761494

Epoch: 6| Step: 11
Training loss: 2.2116691537980575
Validation loss: 2.4722139064301305

Epoch: 6| Step: 12
Training loss: 2.6573945216350023
Validation loss: 2.4708916432628474

Epoch: 6| Step: 13
Training loss: 1.8613363227783797
Validation loss: 2.4702835631440125

Epoch: 97| Step: 0
Training loss: 2.375241417912183
Validation loss: 2.4712289202956357

Epoch: 6| Step: 1
Training loss: 2.6358361695626416
Validation loss: 2.4631792625884525

Epoch: 6| Step: 2
Training loss: 2.6043653081791858
Validation loss: 2.4672190591099477

Epoch: 6| Step: 3
Training loss: 3.546393676902251
Validation loss: 2.4595285247360468

Epoch: 6| Step: 4
Training loss: 1.7828204275986375
Validation loss: 2.4664295735553843

Epoch: 6| Step: 5
Training loss: 2.549061591319027
Validation loss: 2.4603575653893652

Epoch: 6| Step: 6
Training loss: 2.3558417130941844
Validation loss: 2.469225527842514

Epoch: 6| Step: 7
Training loss: 2.0581327497635846
Validation loss: 2.4528830747106154

Epoch: 6| Step: 8
Training loss: 2.7282809113546587
Validation loss: 2.46280040974048

Epoch: 6| Step: 9
Training loss: 2.217830951168327
Validation loss: 2.459356746904755

Epoch: 6| Step: 10
Training loss: 2.478636345655144
Validation loss: 2.4638264325481

Epoch: 6| Step: 11
Training loss: 2.6805351851704478
Validation loss: 2.4597324307105

Epoch: 6| Step: 12
Training loss: 3.049458196075463
Validation loss: 2.4594677850653444

Epoch: 6| Step: 13
Training loss: 2.358156205210203
Validation loss: 2.4626289004751993

Epoch: 98| Step: 0
Training loss: 2.5243861065908533
Validation loss: 2.464398681955099

Epoch: 6| Step: 1
Training loss: 2.567510219356773
Validation loss: 2.46406043775654

Epoch: 6| Step: 2
Training loss: 2.5462900437814517
Validation loss: 2.4674760855456666

Epoch: 6| Step: 3
Training loss: 2.5121900908229855
Validation loss: 2.4712294026842843

Epoch: 6| Step: 4
Training loss: 2.407590220376069
Validation loss: 2.4766930386288837

Epoch: 6| Step: 5
Training loss: 2.8014449818818914
Validation loss: 2.4807578411496713

Epoch: 6| Step: 6
Training loss: 2.22042278576957
Validation loss: 2.481739285493032

Epoch: 6| Step: 7
Training loss: 2.204577677240099
Validation loss: 2.4793355921620215

Epoch: 6| Step: 8
Training loss: 2.391128985567813
Validation loss: 2.4807452510803794

Epoch: 6| Step: 9
Training loss: 2.836236270688058
Validation loss: 2.4793467469621415

Epoch: 6| Step: 10
Training loss: 2.8148041505592993
Validation loss: 2.4825740340386284

Epoch: 6| Step: 11
Training loss: 2.4021843585969807
Validation loss: 2.4816858064243474

Epoch: 6| Step: 12
Training loss: 2.994248917643713
Validation loss: 2.483189929964906

Epoch: 6| Step: 13
Training loss: 2.8364067425042094
Validation loss: 2.479625664757078

Epoch: 99| Step: 0
Training loss: 2.7972480056350557
Validation loss: 2.478370063020436

Epoch: 6| Step: 1
Training loss: 2.4808984579504436
Validation loss: 2.470767950883693

Epoch: 6| Step: 2
Training loss: 3.0087828817183353
Validation loss: 2.4716871149199444

Epoch: 6| Step: 3
Training loss: 2.3658677252508835
Validation loss: 2.4731298779489395

Epoch: 6| Step: 4
Training loss: 2.770664085630525
Validation loss: 2.4731305206394025

Epoch: 6| Step: 5
Training loss: 2.414642758059223
Validation loss: 2.4718155639550226

Epoch: 6| Step: 6
Training loss: 2.419423098883015
Validation loss: 2.470370923452693

Epoch: 6| Step: 7
Training loss: 2.5437137198145554
Validation loss: 2.467677048216075

Epoch: 6| Step: 8
Training loss: 2.411291118012183
Validation loss: 2.46515641846533

Epoch: 6| Step: 9
Training loss: 2.221384338197855
Validation loss: 2.4627178715403186

Epoch: 6| Step: 10
Training loss: 1.9188976019832253
Validation loss: 2.460503773085413

Epoch: 6| Step: 11
Training loss: 2.170790037674025
Validation loss: 2.459790886077882

Epoch: 6| Step: 12
Training loss: 3.272674253063173
Validation loss: 2.456844167050889

Epoch: 6| Step: 13
Training loss: 2.819655323337506
Validation loss: 2.465487888199931

Epoch: 100| Step: 0
Training loss: 3.0641484397807397
Validation loss: 2.469803323856314

Epoch: 6| Step: 1
Training loss: 2.584830147864758
Validation loss: 2.4683656836001124

Epoch: 6| Step: 2
Training loss: 2.6167188537965735
Validation loss: 2.467661637819429

Epoch: 6| Step: 3
Training loss: 2.578562289056858
Validation loss: 2.474722113245414

Epoch: 6| Step: 4
Training loss: 2.319550565727191
Validation loss: 2.4647161467863867

Epoch: 6| Step: 5
Training loss: 2.768604720805615
Validation loss: 2.4580403870000453

Epoch: 6| Step: 6
Training loss: 2.9335695308899563
Validation loss: 2.456523913640235

Epoch: 6| Step: 7
Training loss: 2.5658988741410123
Validation loss: 2.4555561709966605

Epoch: 6| Step: 8
Training loss: 2.9558373967771847
Validation loss: 2.458045883399175

Epoch: 6| Step: 9
Training loss: 2.232777164251699
Validation loss: 2.4697986580695974

Epoch: 6| Step: 10
Training loss: 2.6507092300556554
Validation loss: 2.461036583253041

Epoch: 6| Step: 11
Training loss: 2.09837786376016
Validation loss: 2.464011042091266

Epoch: 6| Step: 12
Training loss: 2.224809565591944
Validation loss: 2.464216036499276

Epoch: 6| Step: 13
Training loss: 2.3166931900957737
Validation loss: 2.4669988996990107

Epoch: 101| Step: 0
Training loss: 2.627982670289939
Validation loss: 2.470177209741756

Epoch: 6| Step: 1
Training loss: 3.1321329725935665
Validation loss: 2.4624667305804757

Epoch: 6| Step: 2
Training loss: 2.5215352449966377
Validation loss: 2.4595204143520957

Epoch: 6| Step: 3
Training loss: 2.27214753039318
Validation loss: 2.4599147548482234

Epoch: 6| Step: 4
Training loss: 2.0099996684439465
Validation loss: 2.4580098170970834

Epoch: 6| Step: 5
Training loss: 2.8888930622298914
Validation loss: 2.4530465261295356

Epoch: 6| Step: 6
Training loss: 2.2985570029824087
Validation loss: 2.457914645430264

Epoch: 6| Step: 7
Training loss: 1.8910504327481004
Validation loss: 2.4552745593826573

Epoch: 6| Step: 8
Training loss: 2.2295301503488796
Validation loss: 2.453236619876117

Epoch: 6| Step: 9
Training loss: 2.538759935398091
Validation loss: 2.451935676227801

Epoch: 6| Step: 10
Training loss: 2.34298500291988
Validation loss: 2.4602408255572805

Epoch: 6| Step: 11
Training loss: 3.1597304086730507
Validation loss: 2.460810759979414

Epoch: 6| Step: 12
Training loss: 2.9663788009309924
Validation loss: 2.470667090674623

Epoch: 6| Step: 13
Training loss: 2.837660757207959
Validation loss: 2.472766956102928

Epoch: 102| Step: 0
Training loss: 2.3959845011469354
Validation loss: 2.4760710412127116

Epoch: 6| Step: 1
Training loss: 2.7830205703561797
Validation loss: 2.475684041243196

Epoch: 6| Step: 2
Training loss: 2.334941945303877
Validation loss: 2.4747820048546765

Epoch: 6| Step: 3
Training loss: 1.8886212536439317
Validation loss: 2.4807425921008295

Epoch: 6| Step: 4
Training loss: 2.844198003000747
Validation loss: 2.4815439852417884

Epoch: 6| Step: 5
Training loss: 2.123591124287601
Validation loss: 2.482968906143885

Epoch: 6| Step: 6
Training loss: 2.076141328488245
Validation loss: 2.4778775996422415

Epoch: 6| Step: 7
Training loss: 2.6806129214440935
Validation loss: 2.477985699183116

Epoch: 6| Step: 8
Training loss: 2.603696389014939
Validation loss: 2.4754143589610234

Epoch: 6| Step: 9
Training loss: 3.251963975676342
Validation loss: 2.4681694700244186

Epoch: 6| Step: 10
Training loss: 2.223345014588164
Validation loss: 2.4664105706614574

Epoch: 6| Step: 11
Training loss: 3.3053487201879834
Validation loss: 2.4700569041514604

Epoch: 6| Step: 12
Training loss: 2.5655142570877114
Validation loss: 2.466195470893811

Epoch: 6| Step: 13
Training loss: 2.5940467021329203
Validation loss: 2.4603172691309005

Epoch: 103| Step: 0
Training loss: 2.7980780544777866
Validation loss: 2.459614813041655

Epoch: 6| Step: 1
Training loss: 2.3871033104289063
Validation loss: 2.4656053143429775

Epoch: 6| Step: 2
Training loss: 2.6964030395425036
Validation loss: 2.459634627743795

Epoch: 6| Step: 3
Training loss: 2.6531138137923045
Validation loss: 2.457331798226299

Epoch: 6| Step: 4
Training loss: 2.790331298135928
Validation loss: 2.4542704376232907

Epoch: 6| Step: 5
Training loss: 2.4014505850453287
Validation loss: 2.4525027933730232

Epoch: 6| Step: 6
Training loss: 3.0046711159991912
Validation loss: 2.4567438148520826

Epoch: 6| Step: 7
Training loss: 2.0957261054920138
Validation loss: 2.455590679407521

Epoch: 6| Step: 8
Training loss: 2.698106992235989
Validation loss: 2.4591568251847753

Epoch: 6| Step: 9
Training loss: 2.0817283424340256
Validation loss: 2.461543449601597

Epoch: 6| Step: 10
Training loss: 3.1948114949048363
Validation loss: 2.459611711174118

Epoch: 6| Step: 11
Training loss: 2.428734301066253
Validation loss: 2.4582826372080984

Epoch: 6| Step: 12
Training loss: 2.251899870799474
Validation loss: 2.4559076000988282

Epoch: 6| Step: 13
Training loss: 2.2635957245940883
Validation loss: 2.456061401762484

Epoch: 104| Step: 0
Training loss: 3.1234259646700293
Validation loss: 2.457449840474859

Epoch: 6| Step: 1
Training loss: 2.403851688672076
Validation loss: 2.459306335783258

Epoch: 6| Step: 2
Training loss: 2.2943849105849528
Validation loss: 2.4716844461958667

Epoch: 6| Step: 3
Training loss: 2.523896639126713
Validation loss: 2.4713177103797883

Epoch: 6| Step: 4
Training loss: 1.9315590373552702
Validation loss: 2.470801969418125

Epoch: 6| Step: 5
Training loss: 2.425834618317676
Validation loss: 2.469410916479742

Epoch: 6| Step: 6
Training loss: 2.7332535542111103
Validation loss: 2.465541847544842

Epoch: 6| Step: 7
Training loss: 2.2017498729883798
Validation loss: 2.467184383172129

Epoch: 6| Step: 8
Training loss: 2.871006555595607
Validation loss: 2.4730969077041096

Epoch: 6| Step: 9
Training loss: 2.199693320313124
Validation loss: 2.468317839062794

Epoch: 6| Step: 10
Training loss: 2.81967832245676
Validation loss: 2.474332091892566

Epoch: 6| Step: 11
Training loss: 2.930433498771582
Validation loss: 2.4637162279110725

Epoch: 6| Step: 12
Training loss: 2.440019918892025
Validation loss: 2.4665319884967456

Epoch: 6| Step: 13
Training loss: 2.681801276454925
Validation loss: 2.4615798354110505

Epoch: 105| Step: 0
Training loss: 2.4837094741072314
Validation loss: 2.4585284355028865

Epoch: 6| Step: 1
Training loss: 2.421232568996156
Validation loss: 2.4645502446700522

Epoch: 6| Step: 2
Training loss: 2.612608225647821
Validation loss: 2.4603773983355475

Epoch: 6| Step: 3
Training loss: 3.0042516462675963
Validation loss: 2.4598027837599057

Epoch: 6| Step: 4
Training loss: 2.81963139390768
Validation loss: 2.465986338650539

Epoch: 6| Step: 5
Training loss: 3.1108486957989934
Validation loss: 2.4598903466677102

Epoch: 6| Step: 6
Training loss: 1.9432356445182717
Validation loss: 2.4613727971757218

Epoch: 6| Step: 7
Training loss: 2.449676908870887
Validation loss: 2.4639148926775363

Epoch: 6| Step: 8
Training loss: 2.3481385914518604
Validation loss: 2.459994019188369

Epoch: 6| Step: 9
Training loss: 2.6642541900312593
Validation loss: 2.456022313171943

Epoch: 6| Step: 10
Training loss: 1.8022283006987088
Validation loss: 2.4605916098067686

Epoch: 6| Step: 11
Training loss: 2.3039447169360443
Validation loss: 2.457674848869456

Epoch: 6| Step: 12
Training loss: 2.6986949981130834
Validation loss: 2.453939169122781

Epoch: 6| Step: 13
Training loss: 2.7027407687315974
Validation loss: 2.461426620720365

Epoch: 106| Step: 0
Training loss: 2.3846489505203943
Validation loss: 2.462568568067348

Epoch: 6| Step: 1
Training loss: 2.543326122762009
Validation loss: 2.457158686290123

Epoch: 6| Step: 2
Training loss: 2.2898400974667537
Validation loss: 2.46154783239285

Epoch: 6| Step: 3
Training loss: 2.420134281815082
Validation loss: 2.4570595032604436

Epoch: 6| Step: 4
Training loss: 2.9359314971748773
Validation loss: 2.4513238178390444

Epoch: 6| Step: 5
Training loss: 2.798469813345074
Validation loss: 2.4510287745880177

Epoch: 6| Step: 6
Training loss: 2.557029280762303
Validation loss: 2.4520213242184905

Epoch: 6| Step: 7
Training loss: 2.1275939816651745
Validation loss: 2.454997293764735

Epoch: 6| Step: 8
Training loss: 2.0949275562807546
Validation loss: 2.4582712251824157

Epoch: 6| Step: 9
Training loss: 2.5616792434386957
Validation loss: 2.4615743307601208

Epoch: 6| Step: 10
Training loss: 2.6513085571325927
Validation loss: 2.4591104496840974

Epoch: 6| Step: 11
Training loss: 2.715504956857073
Validation loss: 2.457041584229683

Epoch: 6| Step: 12
Training loss: 3.260239536401704
Validation loss: 2.4498359839365387

Epoch: 6| Step: 13
Training loss: 2.1064903597553415
Validation loss: 2.460345516958004

Epoch: 107| Step: 0
Training loss: 2.739659200761277
Validation loss: 2.46415966151195

Epoch: 6| Step: 1
Training loss: 1.7399144419100716
Validation loss: 2.4678826719904605

Epoch: 6| Step: 2
Training loss: 3.1484906592034396
Validation loss: 2.463129413674669

Epoch: 6| Step: 3
Training loss: 3.1027520730701186
Validation loss: 2.46535993149629

Epoch: 6| Step: 4
Training loss: 2.0937747099827457
Validation loss: 2.461406344202252

Epoch: 6| Step: 5
Training loss: 2.1653706146602776
Validation loss: 2.4558773272504237

Epoch: 6| Step: 6
Training loss: 2.375767834671615
Validation loss: 2.4633302550840783

Epoch: 6| Step: 7
Training loss: 2.0284262176326844
Validation loss: 2.4518611268185766

Epoch: 6| Step: 8
Training loss: 2.4901627593868847
Validation loss: 2.4538453617697185

Epoch: 6| Step: 9
Training loss: 2.7200989281671566
Validation loss: 2.457779859749294

Epoch: 6| Step: 10
Training loss: 2.3844915758985197
Validation loss: 2.452234920676629

Epoch: 6| Step: 11
Training loss: 2.803877434591764
Validation loss: 2.4583499121241625

Epoch: 6| Step: 12
Training loss: 2.6038405150577955
Validation loss: 2.451594740017612

Epoch: 6| Step: 13
Training loss: 3.000979263696718
Validation loss: 2.450623713140094

Epoch: 108| Step: 0
Training loss: 2.76723937422704
Validation loss: 2.4473299554364907

Epoch: 6| Step: 1
Training loss: 2.449369143016419
Validation loss: 2.4494209591401126

Epoch: 6| Step: 2
Training loss: 2.5695469420554975
Validation loss: 2.464060873169363

Epoch: 6| Step: 3
Training loss: 1.9241955401453066
Validation loss: 2.446054461835904

Epoch: 6| Step: 4
Training loss: 2.1850253685497694
Validation loss: 2.4495391717226136

Epoch: 6| Step: 5
Training loss: 2.5714700521423426
Validation loss: 2.4607184418562706

Epoch: 6| Step: 6
Training loss: 3.098778539405373
Validation loss: 2.4627077547530978

Epoch: 6| Step: 7
Training loss: 2.481578188314448
Validation loss: 2.461683727335282

Epoch: 6| Step: 8
Training loss: 2.4798432289840693
Validation loss: 2.4641116062996784

Epoch: 6| Step: 9
Training loss: 2.7915864524894105
Validation loss: 2.4692218506648405

Epoch: 6| Step: 10
Training loss: 1.9171962697420017
Validation loss: 2.4711676079318248

Epoch: 6| Step: 11
Training loss: 2.5634931175060673
Validation loss: 2.467420839884142

Epoch: 6| Step: 12
Training loss: 2.5244231292148593
Validation loss: 2.461791488781836

Epoch: 6| Step: 13
Training loss: 2.921739218101737
Validation loss: 2.4705960256812562

Epoch: 109| Step: 0
Training loss: 3.1224053864999726
Validation loss: 2.4616494738323413

Epoch: 6| Step: 1
Training loss: 2.5946618740760212
Validation loss: 2.462545493233353

Epoch: 6| Step: 2
Training loss: 2.479589591830631
Validation loss: 2.462065923421259

Epoch: 6| Step: 3
Training loss: 2.4343495672461994
Validation loss: 2.45082037483775

Epoch: 6| Step: 4
Training loss: 2.250920001661951
Validation loss: 2.4487763268387965

Epoch: 6| Step: 5
Training loss: 2.7534773255843827
Validation loss: 2.435771655427335

Epoch: 6| Step: 6
Training loss: 2.3367385766486897
Validation loss: 2.448088016329666

Epoch: 6| Step: 7
Training loss: 2.8282541487906223
Validation loss: 2.459384666465883

Epoch: 6| Step: 8
Training loss: 2.4582334164072
Validation loss: 2.454806810276364

Epoch: 6| Step: 9
Training loss: 2.883689354174932
Validation loss: 2.446493073038419

Epoch: 6| Step: 10
Training loss: 2.6285532562741305
Validation loss: 2.45133976861612

Epoch: 6| Step: 11
Training loss: 2.7223006991884193
Validation loss: 2.4576477991508923

Epoch: 6| Step: 12
Training loss: 2.0059425760190974
Validation loss: 2.4581980641105488

Epoch: 6| Step: 13
Training loss: 2.0714465220382956
Validation loss: 2.465964182065304

Epoch: 110| Step: 0
Training loss: 2.944225970946042
Validation loss: 2.4678339646966085

Epoch: 6| Step: 1
Training loss: 2.3840464914384207
Validation loss: 2.4690939748129312

Epoch: 6| Step: 2
Training loss: 2.2089610617138478
Validation loss: 2.4688350807691424

Epoch: 6| Step: 3
Training loss: 2.5044470335480558
Validation loss: 2.4697796569643775

Epoch: 6| Step: 4
Training loss: 2.4231886715674236
Validation loss: 2.4598682320978207

Epoch: 6| Step: 5
Training loss: 2.2288076759359554
Validation loss: 2.4693064324120013

Epoch: 6| Step: 6
Training loss: 2.12900939131601
Validation loss: 2.4593227841409613

Epoch: 6| Step: 7
Training loss: 2.8379517855161076
Validation loss: 2.459308597842904

Epoch: 6| Step: 8
Training loss: 2.8770283717035037
Validation loss: 2.4580355372259004

Epoch: 6| Step: 9
Training loss: 2.6060239552050435
Validation loss: 2.4571796042933096

Epoch: 6| Step: 10
Training loss: 2.2812399668015666
Validation loss: 2.457819001224987

Epoch: 6| Step: 11
Training loss: 2.701437186163797
Validation loss: 2.457410644609076

Epoch: 6| Step: 12
Training loss: 2.5291650921870636
Validation loss: 2.4587142589940534

Epoch: 6| Step: 13
Training loss: 2.868215766313425
Validation loss: 2.4646520928029463

Epoch: 111| Step: 0
Training loss: 2.9053922638515
Validation loss: 2.462726745880856

Epoch: 6| Step: 1
Training loss: 1.9957364055481621
Validation loss: 2.463079305626818

Epoch: 6| Step: 2
Training loss: 2.612952150341051
Validation loss: 2.462359160060314

Epoch: 6| Step: 3
Training loss: 2.093767308405604
Validation loss: 2.4577934566729294

Epoch: 6| Step: 4
Training loss: 2.279159424076975
Validation loss: 2.455285742576158

Epoch: 6| Step: 5
Training loss: 2.390259359484453
Validation loss: 2.460306310695566

Epoch: 6| Step: 6
Training loss: 3.152780873600079
Validation loss: 2.452787825622753

Epoch: 6| Step: 7
Training loss: 2.625238680206384
Validation loss: 2.4578128737901848

Epoch: 6| Step: 8
Training loss: 2.4233401880950036
Validation loss: 2.449556342651767

Epoch: 6| Step: 9
Training loss: 2.646868755959236
Validation loss: 2.4536815667969876

Epoch: 6| Step: 10
Training loss: 2.478447326248193
Validation loss: 2.4523122781607816

Epoch: 6| Step: 11
Training loss: 2.8377424228981427
Validation loss: 2.460084781555547

Epoch: 6| Step: 12
Training loss: 2.629365107266309
Validation loss: 2.458842884747017

Epoch: 6| Step: 13
Training loss: 2.337508983900788
Validation loss: 2.4526262687507567

Epoch: 112| Step: 0
Training loss: 2.939281816021414
Validation loss: 2.4573753774975016

Epoch: 6| Step: 1
Training loss: 2.487695166824503
Validation loss: 2.4650291538384446

Epoch: 6| Step: 2
Training loss: 2.2960635458097594
Validation loss: 2.4623268686225788

Epoch: 6| Step: 3
Training loss: 2.131368406703828
Validation loss: 2.465907395842638

Epoch: 6| Step: 4
Training loss: 2.4910660375955733
Validation loss: 2.466104224450512

Epoch: 6| Step: 5
Training loss: 2.7651230523595043
Validation loss: 2.470360049828234

Epoch: 6| Step: 6
Training loss: 1.9315584201890006
Validation loss: 2.4637878139077123

Epoch: 6| Step: 7
Training loss: 2.7093944720456205
Validation loss: 2.4693645887284936

Epoch: 6| Step: 8
Training loss: 3.4621235556765604
Validation loss: 2.458540832253892

Epoch: 6| Step: 9
Training loss: 2.55203024880351
Validation loss: 2.45888807751048

Epoch: 6| Step: 10
Training loss: 2.2957734041878926
Validation loss: 2.4592253365192045

Epoch: 6| Step: 11
Training loss: 2.2677039769460396
Validation loss: 2.4537169112910346

Epoch: 6| Step: 12
Training loss: 2.181060577299908
Validation loss: 2.458410008630221

Epoch: 6| Step: 13
Training loss: 2.54078883244609
Validation loss: 2.457991217929908

Epoch: 113| Step: 0
Training loss: 2.688165005756724
Validation loss: 2.4508347561894914

Epoch: 6| Step: 1
Training loss: 3.0353491683782625
Validation loss: 2.4563258401229535

Epoch: 6| Step: 2
Training loss: 2.236036309938641
Validation loss: 2.4613226372220174

Epoch: 6| Step: 3
Training loss: 2.407862333639785
Validation loss: 2.455512260062039

Epoch: 6| Step: 4
Training loss: 2.461692088862588
Validation loss: 2.456702343264583

Epoch: 6| Step: 5
Training loss: 2.5085470009305557
Validation loss: 2.459291454610431

Epoch: 6| Step: 6
Training loss: 2.4382970436022258
Validation loss: 2.4521427820389365

Epoch: 6| Step: 7
Training loss: 1.9932523985393413
Validation loss: 2.458096837667183

Epoch: 6| Step: 8
Training loss: 2.0605209565905485
Validation loss: 2.4616649783633813

Epoch: 6| Step: 9
Training loss: 2.8658267749897317
Validation loss: 2.44564599311281

Epoch: 6| Step: 10
Training loss: 2.232230698083272
Validation loss: 2.4546555686798572

Epoch: 6| Step: 11
Training loss: 2.350693247381745
Validation loss: 2.4556066995600485

Epoch: 6| Step: 12
Training loss: 2.8416102816747975
Validation loss: 2.4603901249301585

Epoch: 6| Step: 13
Training loss: 3.0112625746347654
Validation loss: 2.461498604239353

Epoch: 114| Step: 0
Training loss: 2.518309398952265
Validation loss: 2.4543919703284884

Epoch: 6| Step: 1
Training loss: 2.673259354167866
Validation loss: 2.4622403525935113

Epoch: 6| Step: 2
Training loss: 2.2785059480872
Validation loss: 2.4605445507729176

Epoch: 6| Step: 3
Training loss: 2.8065094621839646
Validation loss: 2.4615838387858133

Epoch: 6| Step: 4
Training loss: 2.8155966771063508
Validation loss: 2.45888158105135

Epoch: 6| Step: 5
Training loss: 2.06253606591336
Validation loss: 2.4541381881779976

Epoch: 6| Step: 6
Training loss: 2.5853789034495227
Validation loss: 2.45262137586759

Epoch: 6| Step: 7
Training loss: 2.73351322217904
Validation loss: 2.452206222924855

Epoch: 6| Step: 8
Training loss: 2.141099863216935
Validation loss: 2.4470095367276983

Epoch: 6| Step: 9
Training loss: 2.6877647092109975
Validation loss: 2.44335228430809

Epoch: 6| Step: 10
Training loss: 2.84240690939461
Validation loss: 2.4502970275403375

Epoch: 6| Step: 11
Training loss: 2.6220082991386495
Validation loss: 2.4501822896859395

Epoch: 6| Step: 12
Training loss: 2.0754600015019498
Validation loss: 2.4601896491902426

Epoch: 6| Step: 13
Training loss: 2.3354701974968544
Validation loss: 2.4541087516682403

Epoch: 115| Step: 0
Training loss: 2.763729501938946
Validation loss: 2.4516167995516907

Epoch: 6| Step: 1
Training loss: 2.433979132494655
Validation loss: 2.4469030649029966

Epoch: 6| Step: 2
Training loss: 2.7977994105087074
Validation loss: 2.45231668555184

Epoch: 6| Step: 3
Training loss: 2.440086068839775
Validation loss: 2.457348065755227

Epoch: 6| Step: 4
Training loss: 2.6753917549833814
Validation loss: 2.4520649168435154

Epoch: 6| Step: 5
Training loss: 2.097961744514259
Validation loss: 2.461922794474342

Epoch: 6| Step: 6
Training loss: 2.1296645187738874
Validation loss: 2.4571740574416268

Epoch: 6| Step: 7
Training loss: 2.7813485803170974
Validation loss: 2.4557000674603295

Epoch: 6| Step: 8
Training loss: 2.7147007746749012
Validation loss: 2.452712799883003

Epoch: 6| Step: 9
Training loss: 2.6368294247605784
Validation loss: 2.4518873490213733

Epoch: 6| Step: 10
Training loss: 2.9987529705966294
Validation loss: 2.451853331412494

Epoch: 6| Step: 11
Training loss: 2.322607376195189
Validation loss: 2.45982321080684

Epoch: 6| Step: 12
Training loss: 2.346546183585403
Validation loss: 2.4569081173009364

Epoch: 6| Step: 13
Training loss: 2.0232233943116107
Validation loss: 2.452099612129861

Epoch: 116| Step: 0
Training loss: 2.7164904094535878
Validation loss: 2.449276864124391

Epoch: 6| Step: 1
Training loss: 2.7064282294735813
Validation loss: 2.4471280119398493

Epoch: 6| Step: 2
Training loss: 2.2238944146457755
Validation loss: 2.4480600247441577

Epoch: 6| Step: 3
Training loss: 2.188305515752642
Validation loss: 2.4608791768262437

Epoch: 6| Step: 4
Training loss: 2.3728581859782856
Validation loss: 2.4505067690460236

Epoch: 6| Step: 5
Training loss: 2.390541523990659
Validation loss: 2.444257173324598

Epoch: 6| Step: 6
Training loss: 2.33559912843082
Validation loss: 2.4490333012364665

Epoch: 6| Step: 7
Training loss: 2.628756151831553
Validation loss: 2.457054570688297

Epoch: 6| Step: 8
Training loss: 2.1935952417284486
Validation loss: 2.4608029041116266

Epoch: 6| Step: 9
Training loss: 2.884852403537788
Validation loss: 2.4688553123706987

Epoch: 6| Step: 10
Training loss: 2.606482907506827
Validation loss: 2.479138435609078

Epoch: 6| Step: 11
Training loss: 2.745275774445764
Validation loss: 2.4810163479196814

Epoch: 6| Step: 12
Training loss: 2.432846419943817
Validation loss: 2.490832463665586

Epoch: 6| Step: 13
Training loss: 2.8353835896943482
Validation loss: 2.4829883184292627

Epoch: 117| Step: 0
Training loss: 2.0974727955305457
Validation loss: 2.4783061534962045

Epoch: 6| Step: 1
Training loss: 2.7799702818400447
Validation loss: 2.4899747745609857

Epoch: 6| Step: 2
Training loss: 2.9746834338080532
Validation loss: 2.488860186224956

Epoch: 6| Step: 3
Training loss: 2.3654349609800023
Validation loss: 2.4827799124926795

Epoch: 6| Step: 4
Training loss: 2.099407012413737
Validation loss: 2.480253852085818

Epoch: 6| Step: 5
Training loss: 2.7067900931430575
Validation loss: 2.4796066187660144

Epoch: 6| Step: 6
Training loss: 2.62104317492656
Validation loss: 2.481269719119952

Epoch: 6| Step: 7
Training loss: 2.211309287148167
Validation loss: 2.477881640831426

Epoch: 6| Step: 8
Training loss: 2.496867983620803
Validation loss: 2.4777717726634214

Epoch: 6| Step: 9
Training loss: 2.315493836594239
Validation loss: 2.4793207831257007

Epoch: 6| Step: 10
Training loss: 2.4977183420471434
Validation loss: 2.456275714613478

Epoch: 6| Step: 11
Training loss: 3.1019359142833367
Validation loss: 2.467863881554958

Epoch: 6| Step: 12
Training loss: 2.410779875413044
Validation loss: 2.4514469716794944

Epoch: 6| Step: 13
Training loss: 2.786630120136621
Validation loss: 2.4580447679544632

Epoch: 118| Step: 0
Training loss: 3.002738338669818
Validation loss: 2.4568607289344486

Epoch: 6| Step: 1
Training loss: 2.270439137066235
Validation loss: 2.459748286573401

Epoch: 6| Step: 2
Training loss: 1.8249936796105037
Validation loss: 2.4614442979625295

Epoch: 6| Step: 3
Training loss: 2.800238180248135
Validation loss: 2.4527422855478673

Epoch: 6| Step: 4
Training loss: 2.0256587617079727
Validation loss: 2.453613912857506

Epoch: 6| Step: 5
Training loss: 3.0407587725704035
Validation loss: 2.44413033246948

Epoch: 6| Step: 6
Training loss: 2.170559162049782
Validation loss: 2.452003700585967

Epoch: 6| Step: 7
Training loss: 2.4498356433157418
Validation loss: 2.4525234189407614

Epoch: 6| Step: 8
Training loss: 2.6840643990603548
Validation loss: 2.4535688901716113

Epoch: 6| Step: 9
Training loss: 2.793294991599565
Validation loss: 2.4483777903741863

Epoch: 6| Step: 10
Training loss: 2.9943046549777277
Validation loss: 2.4565321471480734

Epoch: 6| Step: 11
Training loss: 2.4571653490209404
Validation loss: 2.4494818262735625

Epoch: 6| Step: 12
Training loss: 2.4805429522611973
Validation loss: 2.4555626519802116

Epoch: 6| Step: 13
Training loss: 2.1021108372845148
Validation loss: 2.461808743734108

Epoch: 119| Step: 0
Training loss: 2.6870307512699334
Validation loss: 2.4603437888269517

Epoch: 6| Step: 1
Training loss: 2.212139759801476
Validation loss: 2.461648618295771

Epoch: 6| Step: 2
Training loss: 2.5340004565412415
Validation loss: 2.4636577285837067

Epoch: 6| Step: 3
Training loss: 2.052096629866173
Validation loss: 2.4625739575428813

Epoch: 6| Step: 4
Training loss: 3.014656820677929
Validation loss: 2.4720668642708645

Epoch: 6| Step: 5
Training loss: 2.683722480451602
Validation loss: 2.475748845044118

Epoch: 6| Step: 6
Training loss: 2.308232571253778
Validation loss: 2.470082707970172

Epoch: 6| Step: 7
Training loss: 3.2399694738009663
Validation loss: 2.4732922965841397

Epoch: 6| Step: 8
Training loss: 2.6475898038710164
Validation loss: 2.472962258573984

Epoch: 6| Step: 9
Training loss: 1.9501681108635922
Validation loss: 2.462108305294824

Epoch: 6| Step: 10
Training loss: 2.6402262550270903
Validation loss: 2.4779039955445943

Epoch: 6| Step: 11
Training loss: 2.6531007835262512
Validation loss: 2.469382707987214

Epoch: 6| Step: 12
Training loss: 2.3971304547232446
Validation loss: 2.4762264870135953

Epoch: 6| Step: 13
Training loss: 2.1062456442224757
Validation loss: 2.4684669960153762

Epoch: 120| Step: 0
Training loss: 2.355597902113268
Validation loss: 2.4705561135523055

Epoch: 6| Step: 1
Training loss: 2.662720462465121
Validation loss: 2.4722561866651214

Epoch: 6| Step: 2
Training loss: 2.6274498905880717
Validation loss: 2.480604609575997

Epoch: 6| Step: 3
Training loss: 2.820524508889973
Validation loss: 2.484727366668207

Epoch: 6| Step: 4
Training loss: 2.167872191332243
Validation loss: 2.473094851066086

Epoch: 6| Step: 5
Training loss: 2.193903678010653
Validation loss: 2.476642739713908

Epoch: 6| Step: 6
Training loss: 2.9029734199297876
Validation loss: 2.475363520375087

Epoch: 6| Step: 7
Training loss: 2.300348678364483
Validation loss: 2.4716373250569728

Epoch: 6| Step: 8
Training loss: 2.3342417810464307
Validation loss: 2.463836899554969

Epoch: 6| Step: 9
Training loss: 2.803685936572179
Validation loss: 2.4672078172661713

Epoch: 6| Step: 10
Training loss: 2.4853477253162914
Validation loss: 2.4441044903986566

Epoch: 6| Step: 11
Training loss: 2.3248592744302914
Validation loss: 2.452044724965597

Epoch: 6| Step: 12
Training loss: 2.6305860392992755
Validation loss: 2.4565560872498473

Epoch: 6| Step: 13
Training loss: 2.5836025425911577
Validation loss: 2.4531370757953797

Epoch: 121| Step: 0
Training loss: 2.74150794322484
Validation loss: 2.4558749649493903

Epoch: 6| Step: 1
Training loss: 2.811911203423088
Validation loss: 2.4437565835146993

Epoch: 6| Step: 2
Training loss: 1.8957046493061949
Validation loss: 2.4500023472054586

Epoch: 6| Step: 3
Training loss: 2.1640258124922096
Validation loss: 2.4446541953285847

Epoch: 6| Step: 4
Training loss: 2.416223244161226
Validation loss: 2.4537542714467038

Epoch: 6| Step: 5
Training loss: 2.840803695110817
Validation loss: 2.4557820243985518

Epoch: 6| Step: 6
Training loss: 2.815269971135269
Validation loss: 2.448039183019445

Epoch: 6| Step: 7
Training loss: 2.5443255061688848
Validation loss: 2.4524599862601537

Epoch: 6| Step: 8
Training loss: 2.572771189253844
Validation loss: 2.450716865528028

Epoch: 6| Step: 9
Training loss: 2.335901572675219
Validation loss: 2.4571187418697416

Epoch: 6| Step: 10
Training loss: 2.3648808385979665
Validation loss: 2.459459666402812

Epoch: 6| Step: 11
Training loss: 2.8398981522041558
Validation loss: 2.453595207489403

Epoch: 6| Step: 12
Training loss: 2.649790550447842
Validation loss: 2.4594890307917083

Epoch: 6| Step: 13
Training loss: 2.306736956207152
Validation loss: 2.4561738750642506

Epoch: 122| Step: 0
Training loss: 2.4628594537951103
Validation loss: 2.454342825309321

Epoch: 6| Step: 1
Training loss: 2.3729530347315144
Validation loss: 2.453620091265943

Epoch: 6| Step: 2
Training loss: 1.7607298653288326
Validation loss: 2.4502165575400023

Epoch: 6| Step: 3
Training loss: 2.2606463220427644
Validation loss: 2.455468566810374

Epoch: 6| Step: 4
Training loss: 2.5114857994253783
Validation loss: 2.4552043517162314

Epoch: 6| Step: 5
Training loss: 2.4390374250179985
Validation loss: 2.4522671586595712

Epoch: 6| Step: 6
Training loss: 2.8062998777854866
Validation loss: 2.4444484707649865

Epoch: 6| Step: 7
Training loss: 2.584541981479179
Validation loss: 2.448632275028357

Epoch: 6| Step: 8
Training loss: 2.812612573701912
Validation loss: 2.4535955556858693

Epoch: 6| Step: 9
Training loss: 2.489089331569079
Validation loss: 2.460165930194209

Epoch: 6| Step: 10
Training loss: 2.5884825752825735
Validation loss: 2.4526091193144226

Epoch: 6| Step: 11
Training loss: 2.7968238527533473
Validation loss: 2.4528147831342126

Epoch: 6| Step: 12
Training loss: 2.340708271984908
Validation loss: 2.4527422693470498

Epoch: 6| Step: 13
Training loss: 2.98974908420202
Validation loss: 2.4565997773341777

Epoch: 123| Step: 0
Training loss: 2.426769503713035
Validation loss: 2.4592149306753055

Epoch: 6| Step: 1
Training loss: 2.3301092307228024
Validation loss: 2.459526634469668

Epoch: 6| Step: 2
Training loss: 2.2909269584025047
Validation loss: 2.46400513163926

Epoch: 6| Step: 3
Training loss: 2.7783808964725822
Validation loss: 2.457618550196109

Epoch: 6| Step: 4
Training loss: 2.215263744005524
Validation loss: 2.453076145471262

Epoch: 6| Step: 5
Training loss: 2.753931356545573
Validation loss: 2.4505586259760657

Epoch: 6| Step: 6
Training loss: 2.9228611878078232
Validation loss: 2.4590569713441663

Epoch: 6| Step: 7
Training loss: 2.212557249891042
Validation loss: 2.451942450387863

Epoch: 6| Step: 8
Training loss: 2.089117818940228
Validation loss: 2.445834558108628

Epoch: 6| Step: 9
Training loss: 2.440564405639095
Validation loss: 2.4487180061061227

Epoch: 6| Step: 10
Training loss: 2.903883760337987
Validation loss: 2.447046885618176

Epoch: 6| Step: 11
Training loss: 2.8511173266591427
Validation loss: 2.444469448766076

Epoch: 6| Step: 12
Training loss: 2.317934609558046
Validation loss: 2.448956894857248

Epoch: 6| Step: 13
Training loss: 2.7593649150106794
Validation loss: 2.446555361082581

Epoch: 124| Step: 0
Training loss: 2.8464361227276895
Validation loss: 2.4406329504478648

Epoch: 6| Step: 1
Training loss: 2.522338060789575
Validation loss: 2.4446115189830278

Epoch: 6| Step: 2
Training loss: 2.7220798139453533
Validation loss: 2.4438582332152277

Epoch: 6| Step: 3
Training loss: 2.3766130691555487
Validation loss: 2.448872145728037

Epoch: 6| Step: 4
Training loss: 2.4545625981461083
Validation loss: 2.4517336339727502

Epoch: 6| Step: 5
Training loss: 2.9820485259213516
Validation loss: 2.4518779411495997

Epoch: 6| Step: 6
Training loss: 2.530188820770102
Validation loss: 2.447379882613313

Epoch: 6| Step: 7
Training loss: 2.7022371984089117
Validation loss: 2.451190842026966

Epoch: 6| Step: 8
Training loss: 2.2518596381627725
Validation loss: 2.4545910578964323

Epoch: 6| Step: 9
Training loss: 2.3755073005565692
Validation loss: 2.4535359971762998

Epoch: 6| Step: 10
Training loss: 2.5922379280138137
Validation loss: 2.457783465124007

Epoch: 6| Step: 11
Training loss: 2.1696203590585625
Validation loss: 2.462206833068705

Epoch: 6| Step: 12
Training loss: 2.4012944108469285
Validation loss: 2.4662602581694415

Epoch: 6| Step: 13
Training loss: 2.274679467393664
Validation loss: 2.460880129513775

Epoch: 125| Step: 0
Training loss: 3.0427954334267393
Validation loss: 2.456875155796721

Epoch: 6| Step: 1
Training loss: 2.3066606771064273
Validation loss: 2.4637503236524942

Epoch: 6| Step: 2
Training loss: 2.4955215395206323
Validation loss: 2.452857389654512

Epoch: 6| Step: 3
Training loss: 3.011727141332749
Validation loss: 2.458631114920241

Epoch: 6| Step: 4
Training loss: 2.3980473999480205
Validation loss: 2.454450374799688

Epoch: 6| Step: 5
Training loss: 2.5865803176028384
Validation loss: 2.461212611084765

Epoch: 6| Step: 6
Training loss: 2.1656030342782575
Validation loss: 2.4472710806503435

Epoch: 6| Step: 7
Training loss: 2.520845576064801
Validation loss: 2.4581906767580026

Epoch: 6| Step: 8
Training loss: 2.101300531672697
Validation loss: 2.4561545905946907

Epoch: 6| Step: 9
Training loss: 2.3662767326348235
Validation loss: 2.4674989451799387

Epoch: 6| Step: 10
Training loss: 1.7936397452147446
Validation loss: 2.4583253267664293

Epoch: 6| Step: 11
Training loss: 2.5850385964793805
Validation loss: 2.4643443912130905

Epoch: 6| Step: 12
Training loss: 3.2020182860863167
Validation loss: 2.4656833804543363

Epoch: 6| Step: 13
Training loss: 2.506304801665212
Validation loss: 2.4584417049853178

Epoch: 126| Step: 0
Training loss: 2.4537701578424804
Validation loss: 2.4611326432942597

Epoch: 6| Step: 1
Training loss: 2.99700683049215
Validation loss: 2.4492740087445712

Epoch: 6| Step: 2
Training loss: 2.501860498504961
Validation loss: 2.450086781528331

Epoch: 6| Step: 3
Training loss: 2.7711763862740266
Validation loss: 2.463827472799617

Epoch: 6| Step: 4
Training loss: 2.336444506276193
Validation loss: 2.460596180008162

Epoch: 6| Step: 5
Training loss: 2.8625040912182484
Validation loss: 2.457810513349483

Epoch: 6| Step: 6
Training loss: 2.6977035752516505
Validation loss: 2.459540205580677

Epoch: 6| Step: 7
Training loss: 2.6090226535127994
Validation loss: 2.456529664157948

Epoch: 6| Step: 8
Training loss: 2.746990464423439
Validation loss: 2.4518857040644852

Epoch: 6| Step: 9
Training loss: 2.3508062318873435
Validation loss: 2.4578384343076647

Epoch: 6| Step: 10
Training loss: 2.570929456136947
Validation loss: 2.453791056150412

Epoch: 6| Step: 11
Training loss: 2.316154685038202
Validation loss: 2.4569333880271387

Epoch: 6| Step: 12
Training loss: 2.249327983105139
Validation loss: 2.453372108664438

Epoch: 6| Step: 13
Training loss: 1.6195742184155375
Validation loss: 2.4518045812006646

Epoch: 127| Step: 0
Training loss: 3.0032056529699664
Validation loss: 2.448893661867457

Epoch: 6| Step: 1
Training loss: 2.098030497377487
Validation loss: 2.4607380861898687

Epoch: 6| Step: 2
Training loss: 2.5105332681213843
Validation loss: 2.4615200422970283

Epoch: 6| Step: 3
Training loss: 2.2486952071329096
Validation loss: 2.4736772933075106

Epoch: 6| Step: 4
Training loss: 2.878240003576574
Validation loss: 2.4900793488561064

Epoch: 6| Step: 5
Training loss: 2.589778847550024
Validation loss: 2.4812597100030245

Epoch: 6| Step: 6
Training loss: 2.2567501538759323
Validation loss: 2.465960540309336

Epoch: 6| Step: 7
Training loss: 2.2574984322137976
Validation loss: 2.455313287648842

Epoch: 6| Step: 8
Training loss: 2.4592671856641806
Validation loss: 2.448499964485482

Epoch: 6| Step: 9
Training loss: 2.039007076518682
Validation loss: 2.4500444187627126

Epoch: 6| Step: 10
Training loss: 2.3998843125435294
Validation loss: 2.4577733765285434

Epoch: 6| Step: 11
Training loss: 2.878970679878165
Validation loss: 2.4626024215234015

Epoch: 6| Step: 12
Training loss: 2.9274014518432394
Validation loss: 2.468790335667735

Epoch: 6| Step: 13
Training loss: 2.8965340916796913
Validation loss: 2.4769418387804363

Epoch: 128| Step: 0
Training loss: 2.5059093253315146
Validation loss: 2.47599720244283

Epoch: 6| Step: 1
Training loss: 2.484546199633896
Validation loss: 2.4808814478898196

Epoch: 6| Step: 2
Training loss: 2.3443016928812925
Validation loss: 2.4784337223870563

Epoch: 6| Step: 3
Training loss: 2.6848220790398485
Validation loss: 2.4800585950830616

Epoch: 6| Step: 4
Training loss: 2.9543080054414816
Validation loss: 2.4745134446945403

Epoch: 6| Step: 5
Training loss: 2.04759029091532
Validation loss: 2.477319531506313

Epoch: 6| Step: 6
Training loss: 1.9132723053006195
Validation loss: 2.4705699940071715

Epoch: 6| Step: 7
Training loss: 2.813621975372721
Validation loss: 2.475843002144667

Epoch: 6| Step: 8
Training loss: 2.9014454166287997
Validation loss: 2.4699609900880546

Epoch: 6| Step: 9
Training loss: 2.5727750813888264
Validation loss: 2.4666903954301085

Epoch: 6| Step: 10
Training loss: 2.3641995245938623
Validation loss: 2.4670106901368367

Epoch: 6| Step: 11
Training loss: 2.494912693430244
Validation loss: 2.464013461098913

Epoch: 6| Step: 12
Training loss: 2.691856579138526
Validation loss: 2.461634639108935

Epoch: 6| Step: 13
Training loss: 2.6813175148455435
Validation loss: 2.4533974886967953

Epoch: 129| Step: 0
Training loss: 2.444728696315828
Validation loss: 2.4575330487677944

Epoch: 6| Step: 1
Training loss: 2.576185942200031
Validation loss: 2.452841805150042

Epoch: 6| Step: 2
Training loss: 2.3407712190434893
Validation loss: 2.4583358980154677

Epoch: 6| Step: 3
Training loss: 2.655322283133844
Validation loss: 2.459941036582529

Epoch: 6| Step: 4
Training loss: 2.525653350451952
Validation loss: 2.4504705755665643

Epoch: 6| Step: 5
Training loss: 2.4836280707585554
Validation loss: 2.449062847426072

Epoch: 6| Step: 6
Training loss: 2.627596161713267
Validation loss: 2.4567764708083843

Epoch: 6| Step: 7
Training loss: 2.2688952817192685
Validation loss: 2.4493527089323233

Epoch: 6| Step: 8
Training loss: 2.137263979903676
Validation loss: 2.452876473247578

Epoch: 6| Step: 9
Training loss: 2.7785188788335016
Validation loss: 2.454382086357402

Epoch: 6| Step: 10
Training loss: 2.94327610356245
Validation loss: 2.4543346006473143

Epoch: 6| Step: 11
Training loss: 2.1293561827441465
Validation loss: 2.4556799540168215

Epoch: 6| Step: 12
Training loss: 2.6788239714234767
Validation loss: 2.455646943663985

Epoch: 6| Step: 13
Training loss: 2.573470381692869
Validation loss: 2.4518013478993472

Epoch: 130| Step: 0
Training loss: 2.7846115028988185
Validation loss: 2.456704882691583

Epoch: 6| Step: 1
Training loss: 2.2615979414383673
Validation loss: 2.450100607655276

Epoch: 6| Step: 2
Training loss: 2.350362477855965
Validation loss: 2.450935431395269

Epoch: 6| Step: 3
Training loss: 2.2284987212466927
Validation loss: 2.4448902224578086

Epoch: 6| Step: 4
Training loss: 2.615244220831914
Validation loss: 2.4518394179286074

Epoch: 6| Step: 5
Training loss: 2.921733342781021
Validation loss: 2.454193012331453

Epoch: 6| Step: 6
Training loss: 2.47987889763267
Validation loss: 2.4576080890426364

Epoch: 6| Step: 7
Training loss: 2.4194215221854503
Validation loss: 2.4536310633683995

Epoch: 6| Step: 8
Training loss: 2.362637115213336
Validation loss: 2.4475080893139003

Epoch: 6| Step: 9
Training loss: 1.8275031964108424
Validation loss: 2.453961466666258

Epoch: 6| Step: 10
Training loss: 2.8873901412344254
Validation loss: 2.4559490122980137

Epoch: 6| Step: 11
Training loss: 2.7277311864509506
Validation loss: 2.4617668974411315

Epoch: 6| Step: 12
Training loss: 2.617259101457591
Validation loss: 2.4636727285436577

Epoch: 6| Step: 13
Training loss: 2.627798677522196
Validation loss: 2.4610679470790258

Epoch: 131| Step: 0
Training loss: 2.545972605723447
Validation loss: 2.461604533546694

Epoch: 6| Step: 1
Training loss: 2.7427166811280803
Validation loss: 2.460893660866345

Epoch: 6| Step: 2
Training loss: 2.1301831257143995
Validation loss: 2.456297974769124

Epoch: 6| Step: 3
Training loss: 2.7579333573354194
Validation loss: 2.464679823400319

Epoch: 6| Step: 4
Training loss: 2.5587437709477223
Validation loss: 2.462415059879008

Epoch: 6| Step: 5
Training loss: 2.9824509734787092
Validation loss: 2.4617294409755917

Epoch: 6| Step: 6
Training loss: 2.415388909531869
Validation loss: 2.455367494866813

Epoch: 6| Step: 7
Training loss: 1.8280164898351916
Validation loss: 2.460887040524145

Epoch: 6| Step: 8
Training loss: 2.662982083944002
Validation loss: 2.4674424680517157

Epoch: 6| Step: 9
Training loss: 2.6932383642197597
Validation loss: 2.4755857047558036

Epoch: 6| Step: 10
Training loss: 2.4997518416263556
Validation loss: 2.4745936946477483

Epoch: 6| Step: 11
Training loss: 2.1937137089958054
Validation loss: 2.4698082631450617

Epoch: 6| Step: 12
Training loss: 2.690148047021312
Validation loss: 2.474191455230788

Epoch: 6| Step: 13
Training loss: 2.39278857492814
Validation loss: 2.4729307161964216

Epoch: 132| Step: 0
Training loss: 2.580106771167147
Validation loss: 2.4739130250228496

Epoch: 6| Step: 1
Training loss: 2.313871853101568
Validation loss: 2.4693236026678616

Epoch: 6| Step: 2
Training loss: 2.5889372699220723
Validation loss: 2.470822136667581

Epoch: 6| Step: 3
Training loss: 2.4941744641522963
Validation loss: 2.4660375961403753

Epoch: 6| Step: 4
Training loss: 2.474369461966819
Validation loss: 2.4606010893316514

Epoch: 6| Step: 5
Training loss: 2.637737614201707
Validation loss: 2.46478542252823

Epoch: 6| Step: 6
Training loss: 2.294879279857364
Validation loss: 2.461465316764707

Epoch: 6| Step: 7
Training loss: 1.9615531046279095
Validation loss: 2.466226527428942

Epoch: 6| Step: 8
Training loss: 2.3928513476010806
Validation loss: 2.4611190163815735

Epoch: 6| Step: 9
Training loss: 2.4466580232611355
Validation loss: 2.4732991086471854

Epoch: 6| Step: 10
Training loss: 2.377934700649233
Validation loss: 2.4572097074697057

Epoch: 6| Step: 11
Training loss: 2.6674561126731042
Validation loss: 2.463125170824093

Epoch: 6| Step: 12
Training loss: 3.1576148377569813
Validation loss: 2.4509497634338997

Epoch: 6| Step: 13
Training loss: 2.664526487872007
Validation loss: 2.4542631679747817

Epoch: 133| Step: 0
Training loss: 2.460568354940276
Validation loss: 2.4596177856610404

Epoch: 6| Step: 1
Training loss: 3.1657842778676724
Validation loss: 2.4553680693808517

Epoch: 6| Step: 2
Training loss: 2.165799542063528
Validation loss: 2.461896388630903

Epoch: 6| Step: 3
Training loss: 2.626452543645092
Validation loss: 2.452706829802763

Epoch: 6| Step: 4
Training loss: 2.883889428758441
Validation loss: 2.455091178493146

Epoch: 6| Step: 5
Training loss: 2.875980707499135
Validation loss: 2.4613440445239485

Epoch: 6| Step: 6
Training loss: 2.2537665100677744
Validation loss: 2.45270675689803

Epoch: 6| Step: 7
Training loss: 1.8771957256555412
Validation loss: 2.4623670835817815

Epoch: 6| Step: 8
Training loss: 2.4136498354689473
Validation loss: 2.4617358653527717

Epoch: 6| Step: 9
Training loss: 2.379177435089523
Validation loss: 2.4552091747137372

Epoch: 6| Step: 10
Training loss: 2.464326202660207
Validation loss: 2.4521354493658465

Epoch: 6| Step: 11
Training loss: 2.2776008578600004
Validation loss: 2.440340636583681

Epoch: 6| Step: 12
Training loss: 2.393733179416771
Validation loss: 2.4497395295888293

Epoch: 6| Step: 13
Training loss: 2.5464477180643157
Validation loss: 2.457105561685718

Epoch: 134| Step: 0
Training loss: 2.3633318935043763
Validation loss: 2.457933996923767

Epoch: 6| Step: 1
Training loss: 2.4664346001548108
Validation loss: 2.445590083705467

Epoch: 6| Step: 2
Training loss: 2.872083760541025
Validation loss: 2.454131403887202

Epoch: 6| Step: 3
Training loss: 2.780718291816851
Validation loss: 2.456742245931912

Epoch: 6| Step: 4
Training loss: 2.4799094703517177
Validation loss: 2.4458258986698556

Epoch: 6| Step: 5
Training loss: 2.297974926465647
Validation loss: 2.456943269821221

Epoch: 6| Step: 6
Training loss: 2.514802217688659
Validation loss: 2.4559248802105786

Epoch: 6| Step: 7
Training loss: 1.9402778155212228
Validation loss: 2.460987926148175

Epoch: 6| Step: 8
Training loss: 2.5845931785584986
Validation loss: 2.45628103700916

Epoch: 6| Step: 9
Training loss: 2.7772962778060926
Validation loss: 2.463726566357442

Epoch: 6| Step: 10
Training loss: 2.209665532413609
Validation loss: 2.465353170027116

Epoch: 6| Step: 11
Training loss: 1.9067082088897755
Validation loss: 2.4676550034288565

Epoch: 6| Step: 12
Training loss: 2.7481327653488443
Validation loss: 2.4708748377058254

Epoch: 6| Step: 13
Training loss: 2.8531690278682955
Validation loss: 2.4699720906985885

Epoch: 135| Step: 0
Training loss: 2.8009992485385857
Validation loss: 2.475689707129251

Epoch: 6| Step: 1
Training loss: 3.101819236756818
Validation loss: 2.460592772544324

Epoch: 6| Step: 2
Training loss: 1.7518736482112158
Validation loss: 2.459608867792106

Epoch: 6| Step: 3
Training loss: 2.8627782694728587
Validation loss: 2.457184358727643

Epoch: 6| Step: 4
Training loss: 2.1920075976943165
Validation loss: 2.4596623583654798

Epoch: 6| Step: 5
Training loss: 3.1028943793429242
Validation loss: 2.4569604294379537

Epoch: 6| Step: 6
Training loss: 2.4761454234024534
Validation loss: 2.4575202912081164

Epoch: 6| Step: 7
Training loss: 2.248070101116714
Validation loss: 2.457047373966909

Epoch: 6| Step: 8
Training loss: 2.562480740358501
Validation loss: 2.4457523409437663

Epoch: 6| Step: 9
Training loss: 2.507290889886203
Validation loss: 2.451029828377109

Epoch: 6| Step: 10
Training loss: 1.8776521363570025
Validation loss: 2.446563360149359

Epoch: 6| Step: 11
Training loss: 2.53626329323569
Validation loss: 2.450584554029582

Epoch: 6| Step: 12
Training loss: 2.488529306740057
Validation loss: 2.4550937438646057

Epoch: 6| Step: 13
Training loss: 2.2255284099835255
Validation loss: 2.4436039750096876

Epoch: 136| Step: 0
Training loss: 2.6628406217227454
Validation loss: 2.447361795291952

Epoch: 6| Step: 1
Training loss: 2.273975741194111
Validation loss: 2.45076231352803

Epoch: 6| Step: 2
Training loss: 2.1915526859635395
Validation loss: 2.4518155371172856

Epoch: 6| Step: 3
Training loss: 2.14739632086448
Validation loss: 2.4564923704766355

Epoch: 6| Step: 4
Training loss: 2.654509568832893
Validation loss: 2.464540183774402

Epoch: 6| Step: 5
Training loss: 2.9535485019476035
Validation loss: 2.4584233272912206

Epoch: 6| Step: 6
Training loss: 2.400322685801157
Validation loss: 2.477536616601715

Epoch: 6| Step: 7
Training loss: 2.437354645918995
Validation loss: 2.474235524493184

Epoch: 6| Step: 8
Training loss: 2.363719451884423
Validation loss: 2.478326099345004

Epoch: 6| Step: 9
Training loss: 2.6720489088424895
Validation loss: 2.4812856215218932

Epoch: 6| Step: 10
Training loss: 2.4053466884844226
Validation loss: 2.4598974219957905

Epoch: 6| Step: 11
Training loss: 2.8451196076202208
Validation loss: 2.461778688725074

Epoch: 6| Step: 12
Training loss: 2.906392247810389
Validation loss: 2.4613108033922466

Epoch: 6| Step: 13
Training loss: 1.9654341127409687
Validation loss: 2.463153467111445

Epoch: 137| Step: 0
Training loss: 2.5299088492578106
Validation loss: 2.45974986973087

Epoch: 6| Step: 1
Training loss: 3.002019996866189
Validation loss: 2.458193869325558

Epoch: 6| Step: 2
Training loss: 2.658209582789731
Validation loss: 2.4753486634961326

Epoch: 6| Step: 3
Training loss: 2.804006084664092
Validation loss: 2.4785006988372547

Epoch: 6| Step: 4
Training loss: 2.1614588971118116
Validation loss: 2.4721841868738137

Epoch: 6| Step: 5
Training loss: 2.216325751837224
Validation loss: 2.471359628095846

Epoch: 6| Step: 6
Training loss: 2.1876808091779427
Validation loss: 2.4728779304210775

Epoch: 6| Step: 7
Training loss: 2.370793884521238
Validation loss: 2.4683212197637805

Epoch: 6| Step: 8
Training loss: 2.4963795195375256
Validation loss: 2.467591460522404

Epoch: 6| Step: 9
Training loss: 2.557568992810286
Validation loss: 2.4605817345899643

Epoch: 6| Step: 10
Training loss: 2.0372224302730704
Validation loss: 2.4680841570086436

Epoch: 6| Step: 11
Training loss: 2.668036039740972
Validation loss: 2.4681994794122906

Epoch: 6| Step: 12
Training loss: 2.5941772109112606
Validation loss: 2.4624038848579644

Epoch: 6| Step: 13
Training loss: 2.6663306640498456
Validation loss: 2.4554409911135844

Epoch: 138| Step: 0
Training loss: 2.0813489873217192
Validation loss: 2.4672320161571766

Epoch: 6| Step: 1
Training loss: 2.3717261387045006
Validation loss: 2.4563191508491413

Epoch: 6| Step: 2
Training loss: 2.2317827032271373
Validation loss: 2.463910312504495

Epoch: 6| Step: 3
Training loss: 2.512810026560651
Validation loss: 2.459689466704814

Epoch: 6| Step: 4
Training loss: 2.4032929320870218
Validation loss: 2.458296029298153

Epoch: 6| Step: 5
Training loss: 2.647838423498603
Validation loss: 2.4512245446127907

Epoch: 6| Step: 6
Training loss: 2.654999562064097
Validation loss: 2.457222256415257

Epoch: 6| Step: 7
Training loss: 2.3710666007635357
Validation loss: 2.4574838291229915

Epoch: 6| Step: 8
Training loss: 2.829030266134334
Validation loss: 2.4623590632350467

Epoch: 6| Step: 9
Training loss: 2.4876150440085647
Validation loss: 2.4702171440789926

Epoch: 6| Step: 10
Training loss: 2.694793297337433
Validation loss: 2.465604234550779

Epoch: 6| Step: 11
Training loss: 2.125261851614348
Validation loss: 2.4623849154462056

Epoch: 6| Step: 12
Training loss: 3.0341067666044292
Validation loss: 2.462469651346652

Epoch: 6| Step: 13
Training loss: 2.466718199767251
Validation loss: 2.4702214230069446

Epoch: 139| Step: 0
Training loss: 1.843833016288505
Validation loss: 2.462800724366192

Epoch: 6| Step: 1
Training loss: 2.267040152727152
Validation loss: 2.476656971121388

Epoch: 6| Step: 2
Training loss: 2.0157808938472237
Validation loss: 2.4550177203313854

Epoch: 6| Step: 3
Training loss: 2.5846901273662177
Validation loss: 2.4564212432003223

Epoch: 6| Step: 4
Training loss: 2.4255720899158835
Validation loss: 2.4589095948887336

Epoch: 6| Step: 5
Training loss: 2.650183898015068
Validation loss: 2.462060621600891

Epoch: 6| Step: 6
Training loss: 2.9974685160786616
Validation loss: 2.4722508825886313

Epoch: 6| Step: 7
Training loss: 2.867639157843889
Validation loss: 2.460691732416234

Epoch: 6| Step: 8
Training loss: 1.9158990262607538
Validation loss: 2.4694648383773714

Epoch: 6| Step: 9
Training loss: 3.0169619428025354
Validation loss: 2.4666531345494564

Epoch: 6| Step: 10
Training loss: 2.0840983194306624
Validation loss: 2.465050399992374

Epoch: 6| Step: 11
Training loss: 2.6833451557096435
Validation loss: 2.457615753014148

Epoch: 6| Step: 12
Training loss: 2.421564685260822
Validation loss: 2.4689352553510093

Epoch: 6| Step: 13
Training loss: 2.6648202305149806
Validation loss: 2.467250851668801

Epoch: 140| Step: 0
Training loss: 2.595587022422249
Validation loss: 2.4577004108224196

Epoch: 6| Step: 1
Training loss: 2.645120980393057
Validation loss: 2.4576467643679396

Epoch: 6| Step: 2
Training loss: 2.137987948934137
Validation loss: 2.467607000183113

Epoch: 6| Step: 3
Training loss: 2.3051868996799487
Validation loss: 2.462168616703261

Epoch: 6| Step: 4
Training loss: 2.3068345236295515
Validation loss: 2.4648548011108864

Epoch: 6| Step: 5
Training loss: 2.6172010734547744
Validation loss: 2.4642174071565353

Epoch: 6| Step: 6
Training loss: 2.5468229510833766
Validation loss: 2.4574528480525957

Epoch: 6| Step: 7
Training loss: 2.7204098950807793
Validation loss: 2.4665828641196397

Epoch: 6| Step: 8
Training loss: 1.6565210372551555
Validation loss: 2.460850628323682

Epoch: 6| Step: 9
Training loss: 3.0216909484673176
Validation loss: 2.451534119849598

Epoch: 6| Step: 10
Training loss: 2.5839978460651314
Validation loss: 2.4608033966179494

Epoch: 6| Step: 11
Training loss: 3.1822907010257504
Validation loss: 2.445204792352198

Epoch: 6| Step: 12
Training loss: 2.200785592006832
Validation loss: 2.463574759413631

Epoch: 6| Step: 13
Training loss: 1.9855720333807214
Validation loss: 2.472476842236302

Epoch: 141| Step: 0
Training loss: 2.654793553201384
Validation loss: 2.465498138632298

Epoch: 6| Step: 1
Training loss: 1.9990123455893423
Validation loss: 2.461175574034192

Epoch: 6| Step: 2
Training loss: 2.443622431632781
Validation loss: 2.4679823378039645

Epoch: 6| Step: 3
Training loss: 2.2698549968771453
Validation loss: 2.4635057641626417

Epoch: 6| Step: 4
Training loss: 2.529846273132012
Validation loss: 2.4652828061286853

Epoch: 6| Step: 5
Training loss: 2.203771618040858
Validation loss: 2.4608230806424123

Epoch: 6| Step: 6
Training loss: 2.7704503265537634
Validation loss: 2.456807670670226

Epoch: 6| Step: 7
Training loss: 1.8910076920520833
Validation loss: 2.463580646703842

Epoch: 6| Step: 8
Training loss: 2.9289787554167437
Validation loss: 2.4576465380091106

Epoch: 6| Step: 9
Training loss: 2.5871410507896373
Validation loss: 2.4571305958889735

Epoch: 6| Step: 10
Training loss: 2.567414943396791
Validation loss: 2.451619935846996

Epoch: 6| Step: 11
Training loss: 3.109815556739022
Validation loss: 2.45432227169782

Epoch: 6| Step: 12
Training loss: 2.1236900331002766
Validation loss: 2.4460366002695246

Epoch: 6| Step: 13
Training loss: 2.5159518580417317
Validation loss: 2.450776419585679

Epoch: 142| Step: 0
Training loss: 2.7073611544216245
Validation loss: 2.448920856958726

Epoch: 6| Step: 1
Training loss: 3.081838159350631
Validation loss: 2.452491484072149

Epoch: 6| Step: 2
Training loss: 3.2986591447154914
Validation loss: 2.4602073272445457

Epoch: 6| Step: 3
Training loss: 2.290809355390924
Validation loss: 2.482377831013049

Epoch: 6| Step: 4
Training loss: 1.8126148319042055
Validation loss: 2.4856521394709317

Epoch: 6| Step: 5
Training loss: 2.545485790482025
Validation loss: 2.4845031129445583

Epoch: 6| Step: 6
Training loss: 2.57703270169856
Validation loss: 2.4787268983191155

Epoch: 6| Step: 7
Training loss: 2.391611830540177
Validation loss: 2.4875357971938334

Epoch: 6| Step: 8
Training loss: 2.200168330081719
Validation loss: 2.4932270174088282

Epoch: 6| Step: 9
Training loss: 1.933421055952117
Validation loss: 2.4901614030107027

Epoch: 6| Step: 10
Training loss: 2.8022949724974566
Validation loss: 2.475285599025445

Epoch: 6| Step: 11
Training loss: 2.9548760929367877
Validation loss: 2.4706295118058303

Epoch: 6| Step: 12
Training loss: 2.4211720092375573
Validation loss: 2.4792317747868373

Epoch: 6| Step: 13
Training loss: 2.005030266588034
Validation loss: 2.463071384396517

Epoch: 143| Step: 0
Training loss: 2.159143689984301
Validation loss: 2.451769573801668

Epoch: 6| Step: 1
Training loss: 2.49572378649468
Validation loss: 2.4561942756679933

Epoch: 6| Step: 2
Training loss: 2.7126475280864084
Validation loss: 2.4429201523635964

Epoch: 6| Step: 3
Training loss: 1.369247410591913
Validation loss: 2.4482626866569257

Epoch: 6| Step: 4
Training loss: 2.7135110122403785
Validation loss: 2.451528203629922

Epoch: 6| Step: 5
Training loss: 1.6070293628642602
Validation loss: 2.4658566835446747

Epoch: 6| Step: 6
Training loss: 2.917335288294126
Validation loss: 2.4720717990369763

Epoch: 6| Step: 7
Training loss: 2.446732861128404
Validation loss: 2.4614999279802503

Epoch: 6| Step: 8
Training loss: 2.928177345158122
Validation loss: 2.4547158689456134

Epoch: 6| Step: 9
Training loss: 2.2455891714149594
Validation loss: 2.455145196395544

Epoch: 6| Step: 10
Training loss: 2.410989824321828
Validation loss: 2.4483703165872788

Epoch: 6| Step: 11
Training loss: 3.0055320913543153
Validation loss: 2.45492406749677

Epoch: 6| Step: 12
Training loss: 2.9967385683638037
Validation loss: 2.4582517631920404

Epoch: 6| Step: 13
Training loss: 2.6764844429850996
Validation loss: 2.4676387233317425

Epoch: 144| Step: 0
Training loss: 2.9755163882584204
Validation loss: 2.4683941773825997

Epoch: 6| Step: 1
Training loss: 2.3442612154060667
Validation loss: 2.4553196155272956

Epoch: 6| Step: 2
Training loss: 2.737782213827079
Validation loss: 2.4538156626474756

Epoch: 6| Step: 3
Training loss: 2.805782688712163
Validation loss: 2.457986844963171

Epoch: 6| Step: 4
Training loss: 2.246623578813953
Validation loss: 2.4448355472648378

Epoch: 6| Step: 5
Training loss: 2.82007967761951
Validation loss: 2.4446529843741835

Epoch: 6| Step: 6
Training loss: 2.8837500394201916
Validation loss: 2.4423351748403017

Epoch: 6| Step: 7
Training loss: 2.2097756935660335
Validation loss: 2.441072698568824

Epoch: 6| Step: 8
Training loss: 1.8495248132728874
Validation loss: 2.4608648380269886

Epoch: 6| Step: 9
Training loss: 2.6195114521810954
Validation loss: 2.450309838924902

Epoch: 6| Step: 10
Training loss: 2.3438096102445494
Validation loss: 2.438306740176649

Epoch: 6| Step: 11
Training loss: 1.832597917384099
Validation loss: 2.447330962108328

Epoch: 6| Step: 12
Training loss: 2.8887963361667754
Validation loss: 2.4428630663266944

Epoch: 6| Step: 13
Training loss: 2.214963879430682
Validation loss: 2.4466179480063444

Epoch: 145| Step: 0
Training loss: 2.68609333928815
Validation loss: 2.452568720050185

Epoch: 6| Step: 1
Training loss: 2.7536049535978315
Validation loss: 2.456443000568528

Epoch: 6| Step: 2
Training loss: 2.2484067998278707
Validation loss: 2.460115269141649

Epoch: 6| Step: 3
Training loss: 2.4881816945902866
Validation loss: 2.4585785554897774

Epoch: 6| Step: 4
Training loss: 2.6754294505277048
Validation loss: 2.464719742014748

Epoch: 6| Step: 5
Training loss: 1.9988676680425104
Validation loss: 2.4526929697639788

Epoch: 6| Step: 6
Training loss: 1.933487274629175
Validation loss: 2.465559438874106

Epoch: 6| Step: 7
Training loss: 2.7684567711686134
Validation loss: 2.452106402042054

Epoch: 6| Step: 8
Training loss: 2.5304778063271387
Validation loss: 2.4557186273461262

Epoch: 6| Step: 9
Training loss: 2.356772901558715
Validation loss: 2.4475271740276057

Epoch: 6| Step: 10
Training loss: 2.2041004807955917
Validation loss: 2.452410899743086

Epoch: 6| Step: 11
Training loss: 2.564637385980682
Validation loss: 2.4638158526007445

Epoch: 6| Step: 12
Training loss: 2.3866410313016244
Validation loss: 2.4632530016397998

Epoch: 6| Step: 13
Training loss: 3.0992673746520354
Validation loss: 2.4535984627195555

Epoch: 146| Step: 0
Training loss: 2.6825603066639827
Validation loss: 2.462617274620698

Epoch: 6| Step: 1
Training loss: 2.8854718438299902
Validation loss: 2.4475639873786603

Epoch: 6| Step: 2
Training loss: 2.468316148710564
Validation loss: 2.4655387370173094

Epoch: 6| Step: 3
Training loss: 3.042808283638087
Validation loss: 2.475126441782659

Epoch: 6| Step: 4
Training loss: 2.16432315069228
Validation loss: 2.4765195471792327

Epoch: 6| Step: 5
Training loss: 2.569378065563499
Validation loss: 2.468893553990465

Epoch: 6| Step: 6
Training loss: 2.3878586664468426
Validation loss: 2.480016872466538

Epoch: 6| Step: 7
Training loss: 2.38091395051913
Validation loss: 2.4848262289119116

Epoch: 6| Step: 8
Training loss: 2.420056158470325
Validation loss: 2.486599052633238

Epoch: 6| Step: 9
Training loss: 1.982207548836044
Validation loss: 2.4842149694951314

Epoch: 6| Step: 10
Training loss: 2.1724680358501876
Validation loss: 2.479749087566602

Epoch: 6| Step: 11
Training loss: 2.4000185250521007
Validation loss: 2.470399378021562

Epoch: 6| Step: 12
Training loss: 3.0348687348738888
Validation loss: 2.4815086127480233

Epoch: 6| Step: 13
Training loss: 2.2416647059019605
Validation loss: 2.472794346621631

Epoch: 147| Step: 0
Training loss: 2.166610154613135
Validation loss: 2.467057335906712

Epoch: 6| Step: 1
Training loss: 2.1111544415003607
Validation loss: 2.4740954123549956

Epoch: 6| Step: 2
Training loss: 2.22845956395853
Validation loss: 2.458047605062845

Epoch: 6| Step: 3
Training loss: 2.345060465344253
Validation loss: 2.463081306096429

Epoch: 6| Step: 4
Training loss: 2.42212473904532
Validation loss: 2.464007107167088

Epoch: 6| Step: 5
Training loss: 3.0156805003697023
Validation loss: 2.479079915513709

Epoch: 6| Step: 6
Training loss: 3.134478271243549
Validation loss: 2.470822152749851

Epoch: 6| Step: 7
Training loss: 2.3663723489493513
Validation loss: 2.4721157131992455

Epoch: 6| Step: 8
Training loss: 2.9100831707476926
Validation loss: 2.457291614057587

Epoch: 6| Step: 9
Training loss: 2.0181608586390665
Validation loss: 2.458268347921119

Epoch: 6| Step: 10
Training loss: 2.158203125
Validation loss: 2.459206027503725

Epoch: 6| Step: 11
Training loss: 2.245737913389442
Validation loss: 2.4511751253428193

Epoch: 6| Step: 12
Training loss: 2.747340476878018
Validation loss: 2.4529399761554505

Epoch: 6| Step: 13
Training loss: 2.694017447451228
Validation loss: 2.463170115630332

Epoch: 148| Step: 0
Training loss: 1.9815544448060751
Validation loss: 2.4674327088275705

Epoch: 6| Step: 1
Training loss: 1.9729123997331646
Validation loss: 2.461921793769057

Epoch: 6| Step: 2
Training loss: 3.187975380547588
Validation loss: 2.462994526167154

Epoch: 6| Step: 3
Training loss: 2.577884454776147
Validation loss: 2.4673907243983315

Epoch: 6| Step: 4
Training loss: 2.461230257574114
Validation loss: 2.4583090252940667

Epoch: 6| Step: 5
Training loss: 2.9688894138729114
Validation loss: 2.4486563897329616

Epoch: 6| Step: 6
Training loss: 2.3345270395876065
Validation loss: 2.457465913186275

Epoch: 6| Step: 7
Training loss: 2.434465328788388
Validation loss: 2.458778718161029

Epoch: 6| Step: 8
Training loss: 2.410933556247534
Validation loss: 2.462769648832561

Epoch: 6| Step: 9
Training loss: 2.568311474719676
Validation loss: 2.459601290809217

Epoch: 6| Step: 10
Training loss: 2.4385246666260425
Validation loss: 2.4603537861290428

Epoch: 6| Step: 11
Training loss: 2.624611417074384
Validation loss: 2.472828919788335

Epoch: 6| Step: 12
Training loss: 1.7178587249870934
Validation loss: 2.4552692833576195

Epoch: 6| Step: 13
Training loss: 2.6038585531431258
Validation loss: 2.471328346645482

Epoch: 149| Step: 0
Training loss: 2.2369832640948237
Validation loss: 2.4615290823858644

Epoch: 6| Step: 1
Training loss: 2.0088752279314126
Validation loss: 2.47012841095512

Epoch: 6| Step: 2
Training loss: 2.7305658456895863
Validation loss: 2.4666550193546004

Epoch: 6| Step: 3
Training loss: 2.409681375421798
Validation loss: 2.467603199819171

Epoch: 6| Step: 4
Training loss: 2.6134892539136767
Validation loss: 2.473383309981017

Epoch: 6| Step: 5
Training loss: 1.9862419417297645
Validation loss: 2.475288889943757

Epoch: 6| Step: 6
Training loss: 2.715580023951715
Validation loss: 2.4721585817992007

Epoch: 6| Step: 7
Training loss: 2.6373801073060776
Validation loss: 2.47482027531569

Epoch: 6| Step: 8
Training loss: 2.304387891012729
Validation loss: 2.4701466854776633

Epoch: 6| Step: 9
Training loss: 2.239055506288689
Validation loss: 2.4673899513756754

Epoch: 6| Step: 10
Training loss: 2.252651771233496
Validation loss: 2.4679547409202613

Epoch: 6| Step: 11
Training loss: 3.2788431695519655
Validation loss: 2.4657881469642997

Epoch: 6| Step: 12
Training loss: 2.498373933309109
Validation loss: 2.470511182483718

Epoch: 6| Step: 13
Training loss: 2.7255259295055745
Validation loss: 2.476499001123155

Epoch: 150| Step: 0
Training loss: 2.7534211292847397
Validation loss: 2.4755152785671415

Epoch: 6| Step: 1
Training loss: 2.753927547291319
Validation loss: 2.4673590624805204

Epoch: 6| Step: 2
Training loss: 2.324374563940776
Validation loss: 2.485076853141302

Epoch: 6| Step: 3
Training loss: 2.1333373824716926
Validation loss: 2.4728106168799795

Epoch: 6| Step: 4
Training loss: 3.0229810424371784
Validation loss: 2.4757287018771583

Epoch: 6| Step: 5
Training loss: 2.2735453052457264
Validation loss: 2.4819139971007287

Epoch: 6| Step: 6
Training loss: 2.6099391487306565
Validation loss: 2.4850748783729846

Epoch: 6| Step: 7
Training loss: 2.38168608509616
Validation loss: 2.470829389760911

Epoch: 6| Step: 8
Training loss: 2.7710000086013094
Validation loss: 2.4810729564983225

Epoch: 6| Step: 9
Training loss: 2.4151865493404925
Validation loss: 2.4702236911574773

Epoch: 6| Step: 10
Training loss: 2.6581432103139377
Validation loss: 2.469545002985207

Epoch: 6| Step: 11
Training loss: 2.016561246381199
Validation loss: 2.4651246794919044

Epoch: 6| Step: 12
Training loss: 2.3202820849753207
Validation loss: 2.4644245611423874

Epoch: 6| Step: 13
Training loss: 2.1961079849764324
Validation loss: 2.464745101929519

Epoch: 151| Step: 0
Training loss: 1.7164306944476853
Validation loss: 2.4631863607336046

Epoch: 6| Step: 1
Training loss: 2.298339791882435
Validation loss: 2.4708226191356473

Epoch: 6| Step: 2
Training loss: 2.7279958373230975
Validation loss: 2.457061856336455

Epoch: 6| Step: 3
Training loss: 2.5502671195350195
Validation loss: 2.4635146275999595

Epoch: 6| Step: 4
Training loss: 2.296047658545284
Validation loss: 2.461472000125026

Epoch: 6| Step: 5
Training loss: 2.455603835358633
Validation loss: 2.466389134834717

Epoch: 6| Step: 6
Training loss: 2.648517348624618
Validation loss: 2.4743572087558445

Epoch: 6| Step: 7
Training loss: 2.0917207363886043
Validation loss: 2.4708698844672092

Epoch: 6| Step: 8
Training loss: 2.2883570498658856
Validation loss: 2.4611427181195817

Epoch: 6| Step: 9
Training loss: 2.928323901412211
Validation loss: 2.473783560485541

Epoch: 6| Step: 10
Training loss: 2.2706703570849807
Validation loss: 2.4634190879042404

Epoch: 6| Step: 11
Training loss: 2.288092710490669
Validation loss: 2.4680940344072173

Epoch: 6| Step: 12
Training loss: 2.5338613909271746
Validation loss: 2.4759887929322777

Epoch: 6| Step: 13
Training loss: 3.087965364172991
Validation loss: 2.4713734236443634

Epoch: 152| Step: 0
Training loss: 2.16380986140245
Validation loss: 2.475279370348566

Epoch: 6| Step: 1
Training loss: 2.3198232423928435
Validation loss: 2.4648180041855263

Epoch: 6| Step: 2
Training loss: 2.872284809548079
Validation loss: 2.4648243882697938

Epoch: 6| Step: 3
Training loss: 2.6027196195282345
Validation loss: 2.4718783713348715

Epoch: 6| Step: 4
Training loss: 2.152293237553824
Validation loss: 2.4761064913850697

Epoch: 6| Step: 5
Training loss: 2.848441812299602
Validation loss: 2.465027799752624

Epoch: 6| Step: 6
Training loss: 3.046167849128389
Validation loss: 2.4666060139527826

Epoch: 6| Step: 7
Training loss: 2.3674289089272484
Validation loss: 2.462184424600344

Epoch: 6| Step: 8
Training loss: 2.0424906825923497
Validation loss: 2.4628472885284087

Epoch: 6| Step: 9
Training loss: 2.109332161927571
Validation loss: 2.4617407320494498

Epoch: 6| Step: 10
Training loss: 2.571304454532833
Validation loss: 2.4694589329330157

Epoch: 6| Step: 11
Training loss: 2.2815030101360834
Validation loss: 2.456333160286843

Epoch: 6| Step: 12
Training loss: 2.814775013038065
Validation loss: 2.473450864979471

Epoch: 6| Step: 13
Training loss: 2.0090905066724756
Validation loss: 2.472912783621032

Epoch: 153| Step: 0
Training loss: 2.155014568731003
Validation loss: 2.4696058729273895

Epoch: 6| Step: 1
Training loss: 2.3522773745980508
Validation loss: 2.4734558130495237

Epoch: 6| Step: 2
Training loss: 2.8342069700120254
Validation loss: 2.48115929630767

Epoch: 6| Step: 3
Training loss: 2.9589742226001574
Validation loss: 2.516448476524533

Epoch: 6| Step: 4
Training loss: 2.6726794900025923
Validation loss: 2.5218211726447852

Epoch: 6| Step: 5
Training loss: 2.329757015999968
Validation loss: 2.5053073654639255

Epoch: 6| Step: 6
Training loss: 2.2839687294030253
Validation loss: 2.488179682360956

Epoch: 6| Step: 7
Training loss: 2.4443472520213563
Validation loss: 2.483227446771375

Epoch: 6| Step: 8
Training loss: 1.8582229892261581
Validation loss: 2.4917460402367335

Epoch: 6| Step: 9
Training loss: 2.479265248451681
Validation loss: 2.490214125607009

Epoch: 6| Step: 10
Training loss: 2.192105812296356
Validation loss: 2.4806528578789697

Epoch: 6| Step: 11
Training loss: 2.44626489197141
Validation loss: 2.491394905486365

Epoch: 6| Step: 12
Training loss: 3.203212234425689
Validation loss: 2.481805828497544

Epoch: 6| Step: 13
Training loss: 2.6046026754955327
Validation loss: 2.4827002072412707

Epoch: 154| Step: 0
Training loss: 2.290729839845309
Validation loss: 2.4847990909620195

Epoch: 6| Step: 1
Training loss: 2.370387366463516
Validation loss: 2.4832003553574182

Epoch: 6| Step: 2
Training loss: 2.2930554661120834
Validation loss: 2.4756951482937386

Epoch: 6| Step: 3
Training loss: 1.6759427221794077
Validation loss: 2.4605326809019257

Epoch: 6| Step: 4
Training loss: 2.679439789024529
Validation loss: 2.4637848543836753

Epoch: 6| Step: 5
Training loss: 2.1094319653766354
Validation loss: 2.450112892975337

Epoch: 6| Step: 6
Training loss: 2.7652879067714498
Validation loss: 2.457076039434169

Epoch: 6| Step: 7
Training loss: 2.7049606352813402
Validation loss: 2.4480498149183187

Epoch: 6| Step: 8
Training loss: 2.045228135457782
Validation loss: 2.4651331583028666

Epoch: 6| Step: 9
Training loss: 2.799580208780943
Validation loss: 2.455440602721277

Epoch: 6| Step: 10
Training loss: 2.9776311442899224
Validation loss: 2.461617947920442

Epoch: 6| Step: 11
Training loss: 3.0107241322844933
Validation loss: 2.473336397933432

Epoch: 6| Step: 12
Training loss: 2.785368538105219
Validation loss: 2.466823035086611

Epoch: 6| Step: 13
Training loss: 2.114503517586341
Validation loss: 2.4677880098923803

Epoch: 155| Step: 0
Training loss: 2.2122851466799998
Validation loss: 2.4750912424730513

Epoch: 6| Step: 1
Training loss: 2.6670396563825296
Validation loss: 2.4646827576662056

Epoch: 6| Step: 2
Training loss: 2.503284680706026
Validation loss: 2.4834930485904025

Epoch: 6| Step: 3
Training loss: 1.763038699023408
Validation loss: 2.4641504214382044

Epoch: 6| Step: 4
Training loss: 2.0463875925530526
Validation loss: 2.468804564054106

Epoch: 6| Step: 5
Training loss: 2.3826273861881075
Validation loss: 2.4704869272482846

Epoch: 6| Step: 6
Training loss: 2.5966115586093563
Validation loss: 2.46328934606562

Epoch: 6| Step: 7
Training loss: 2.6417122131977964
Validation loss: 2.4783054159456634

Epoch: 6| Step: 8
Training loss: 2.594014073912383
Validation loss: 2.4739069294190212

Epoch: 6| Step: 9
Training loss: 3.1306373103366782
Validation loss: 2.47067256702529

Epoch: 6| Step: 10
Training loss: 2.6491334614008175
Validation loss: 2.468316873147376

Epoch: 6| Step: 11
Training loss: 2.341399680107097
Validation loss: 2.4569406821212105

Epoch: 6| Step: 12
Training loss: 2.2486204580555578
Validation loss: 2.4706897117039555

Epoch: 6| Step: 13
Training loss: 2.8513247038049383
Validation loss: 2.4814416854573675

Epoch: 156| Step: 0
Training loss: 2.5793300702207578
Validation loss: 2.473324958970458

Epoch: 6| Step: 1
Training loss: 2.9063597627646987
Validation loss: 2.46701605380097

Epoch: 6| Step: 2
Training loss: 2.462927410386471
Validation loss: 2.4777407726333744

Epoch: 6| Step: 3
Training loss: 2.0088885203410873
Validation loss: 2.4839373029054124

Epoch: 6| Step: 4
Training loss: 2.808816320012377
Validation loss: 2.4819479068911505

Epoch: 6| Step: 5
Training loss: 2.143855643380244
Validation loss: 2.471186485805712

Epoch: 6| Step: 6
Training loss: 2.2421598532430993
Validation loss: 2.473009852576769

Epoch: 6| Step: 7
Training loss: 2.349643063323537
Validation loss: 2.4615728133468497

Epoch: 6| Step: 8
Training loss: 2.783929455663582
Validation loss: 2.4728264290581112

Epoch: 6| Step: 9
Training loss: 2.821479281268116
Validation loss: 2.467858427149394

Epoch: 6| Step: 10
Training loss: 2.378931906676095
Validation loss: 2.463334916991403

Epoch: 6| Step: 11
Training loss: 1.9726344947748393
Validation loss: 2.4673424019643875

Epoch: 6| Step: 12
Training loss: 2.409603506847378
Validation loss: 2.4678362350414176

Epoch: 6| Step: 13
Training loss: 2.5331588894195742
Validation loss: 2.4675387698770104

Epoch: 157| Step: 0
Training loss: 2.764543483497711
Validation loss: 2.4615084434915655

Epoch: 6| Step: 1
Training loss: 2.14115565050368
Validation loss: 2.463317463023158

Epoch: 6| Step: 2
Training loss: 2.395857327106133
Validation loss: 2.45763188931485

Epoch: 6| Step: 3
Training loss: 2.882786696403827
Validation loss: 2.4686128280452633

Epoch: 6| Step: 4
Training loss: 2.683360260380127
Validation loss: 2.462300120146957

Epoch: 6| Step: 5
Training loss: 2.4358269255905447
Validation loss: 2.4659706034670394

Epoch: 6| Step: 6
Training loss: 1.807200807894779
Validation loss: 2.473785977968568

Epoch: 6| Step: 7
Training loss: 2.3934521880784314
Validation loss: 2.472068664577558

Epoch: 6| Step: 8
Training loss: 2.204953780608923
Validation loss: 2.4726636262756534

Epoch: 6| Step: 9
Training loss: 2.7202068240407495
Validation loss: 2.473765112040582

Epoch: 6| Step: 10
Training loss: 1.84806345027311
Validation loss: 2.475013609569392

Epoch: 6| Step: 11
Training loss: 2.8556213755593998
Validation loss: 2.479309291637216

Epoch: 6| Step: 12
Training loss: 2.3926464833984653
Validation loss: 2.479991700763557

Epoch: 6| Step: 13
Training loss: 2.842372350988702
Validation loss: 2.4786523451094684

Epoch: 158| Step: 0
Training loss: 1.917247939769888
Validation loss: 2.4785955449759745

Epoch: 6| Step: 1
Training loss: 2.2000577962392747
Validation loss: 2.4705874369479295

Epoch: 6| Step: 2
Training loss: 2.502678294809053
Validation loss: 2.4741907967555368

Epoch: 6| Step: 3
Training loss: 2.006296260692559
Validation loss: 2.4820104418618696

Epoch: 6| Step: 4
Training loss: 2.735248709464006
Validation loss: 2.4857911845909535

Epoch: 6| Step: 5
Training loss: 1.9004251882736598
Validation loss: 2.4817406304607417

Epoch: 6| Step: 6
Training loss: 2.4755522294919134
Validation loss: 2.469118798953102

Epoch: 6| Step: 7
Training loss: 2.8558903707732703
Validation loss: 2.480980143057449

Epoch: 6| Step: 8
Training loss: 2.7470652786680683
Validation loss: 2.4823766384610138

Epoch: 6| Step: 9
Training loss: 2.9518193986846777
Validation loss: 2.476562163055108

Epoch: 6| Step: 10
Training loss: 1.9767894991470356
Validation loss: 2.4808425982038207

Epoch: 6| Step: 11
Training loss: 2.7770532383662907
Validation loss: 2.4828042236855974

Epoch: 6| Step: 12
Training loss: 2.95498372675357
Validation loss: 2.4798989750425386

Epoch: 6| Step: 13
Training loss: 2.0743141511576475
Validation loss: 2.4875311167446466

Epoch: 159| Step: 0
Training loss: 2.2687591972900267
Validation loss: 2.481184728422125

Epoch: 6| Step: 1
Training loss: 2.328555483349728
Validation loss: 2.481816748040575

Epoch: 6| Step: 2
Training loss: 2.9778289103348556
Validation loss: 2.481715444218247

Epoch: 6| Step: 3
Training loss: 2.7089845510206323
Validation loss: 2.4728171731612316

Epoch: 6| Step: 4
Training loss: 2.177983537455853
Validation loss: 2.4662183182297954

Epoch: 6| Step: 5
Training loss: 2.7815525019009257
Validation loss: 2.469858331208293

Epoch: 6| Step: 6
Training loss: 2.538686495596651
Validation loss: 2.4624807534538777

Epoch: 6| Step: 7
Training loss: 2.305246266016901
Validation loss: 2.4712477655421567

Epoch: 6| Step: 8
Training loss: 2.825427628956103
Validation loss: 2.4672259523641786

Epoch: 6| Step: 9
Training loss: 1.7065361928737084
Validation loss: 2.4646207504033324

Epoch: 6| Step: 10
Training loss: 2.342245305565079
Validation loss: 2.461039683324685

Epoch: 6| Step: 11
Training loss: 1.6460625050335407
Validation loss: 2.4614423930238147

Epoch: 6| Step: 12
Training loss: 2.419320414308498
Validation loss: 2.456734134436902

Epoch: 6| Step: 13
Training loss: 3.0186761629856123
Validation loss: 2.454182828019905

Epoch: 160| Step: 0
Training loss: 2.198390554050214
Validation loss: 2.461886300749198

Epoch: 6| Step: 1
Training loss: 2.423723462939757
Validation loss: 2.4555980988547907

Epoch: 6| Step: 2
Training loss: 2.2082836817311864
Validation loss: 2.4546522177223142

Epoch: 6| Step: 3
Training loss: 2.6558141014121763
Validation loss: 2.4569843168481382

Epoch: 6| Step: 4
Training loss: 2.747351150993042
Validation loss: 2.455689306869451

Epoch: 6| Step: 5
Training loss: 2.6613003459305378
Validation loss: 2.4486877255117983

Epoch: 6| Step: 6
Training loss: 2.465298618234532
Validation loss: 2.4607725380805823

Epoch: 6| Step: 7
Training loss: 2.2264059446742763
Validation loss: 2.4639065064387307

Epoch: 6| Step: 8
Training loss: 2.620818486093293
Validation loss: 2.458284819388279

Epoch: 6| Step: 9
Training loss: 2.642807639700435
Validation loss: 2.4535018323698807

Epoch: 6| Step: 10
Training loss: 2.441205362828912
Validation loss: 2.4743374155968367

Epoch: 6| Step: 11
Training loss: 2.4330657337181636
Validation loss: 2.456624719640342

Epoch: 6| Step: 12
Training loss: 2.074705939540634
Validation loss: 2.4737864759215893

Epoch: 6| Step: 13
Training loss: 2.499295516890612
Validation loss: 2.483220837965811

Epoch: 161| Step: 0
Training loss: 2.631217314818427
Validation loss: 2.4753247205370545

Epoch: 6| Step: 1
Training loss: 2.230237638188031
Validation loss: 2.492792899045269

Epoch: 6| Step: 2
Training loss: 2.2222001021661804
Validation loss: 2.4830820489857848

Epoch: 6| Step: 3
Training loss: 2.5157665899958515
Validation loss: 2.4696366050007197

Epoch: 6| Step: 4
Training loss: 1.4517137791506727
Validation loss: 2.4873843889830374

Epoch: 6| Step: 5
Training loss: 2.533451206409705
Validation loss: 2.4792332333088236

Epoch: 6| Step: 6
Training loss: 2.386364699854758
Validation loss: 2.475040533716454

Epoch: 6| Step: 7
Training loss: 2.2689581194963835
Validation loss: 2.4679758894349053

Epoch: 6| Step: 8
Training loss: 2.7065357013393547
Validation loss: 2.4748862577562156

Epoch: 6| Step: 9
Training loss: 2.321215829428261
Validation loss: 2.48051849075066

Epoch: 6| Step: 10
Training loss: 2.9445545627787495
Validation loss: 2.4677631160075917

Epoch: 6| Step: 11
Training loss: 2.2514188319584103
Validation loss: 2.4681709350834784

Epoch: 6| Step: 12
Training loss: 2.296853824440016
Validation loss: 2.4676933441630093

Epoch: 6| Step: 13
Training loss: 3.0114346975117905
Validation loss: 2.469901013752535

Epoch: 162| Step: 0
Training loss: 1.6877283718851903
Validation loss: 2.473195455616196

Epoch: 6| Step: 1
Training loss: 2.0862949936519306
Validation loss: 2.4759080024004336

Epoch: 6| Step: 2
Training loss: 2.2727697905984954
Validation loss: 2.4760558034204148

Epoch: 6| Step: 3
Training loss: 2.457346303175287
Validation loss: 2.4697912008370086

Epoch: 6| Step: 4
Training loss: 2.6667331051497376
Validation loss: 2.479124747384052

Epoch: 6| Step: 5
Training loss: 2.4099916374093113
Validation loss: 2.4809484783851787

Epoch: 6| Step: 6
Training loss: 2.1722539118379136
Validation loss: 2.48958118922781

Epoch: 6| Step: 7
Training loss: 2.672788318893497
Validation loss: 2.478637612148779

Epoch: 6| Step: 8
Training loss: 3.185227275746071
Validation loss: 2.483228566906168

Epoch: 6| Step: 9
Training loss: 2.540454001965455
Validation loss: 2.48650352097101

Epoch: 6| Step: 10
Training loss: 2.5936328907461923
Validation loss: 2.500480653333659

Epoch: 6| Step: 11
Training loss: 2.4066988043431317
Validation loss: 2.4975658010190487

Epoch: 6| Step: 12
Training loss: 2.10347731474805
Validation loss: 2.5019150233984453

Epoch: 6| Step: 13
Training loss: 2.713521555840084
Validation loss: 2.4921278991269067

Epoch: 163| Step: 0
Training loss: 2.4083762744740413
Validation loss: 2.489168050012331

Epoch: 6| Step: 1
Training loss: 2.208347488453921
Validation loss: 2.489730532669183

Epoch: 6| Step: 2
Training loss: 2.8581823978295535
Validation loss: 2.487639659366793

Epoch: 6| Step: 3
Training loss: 2.2828424199811366
Validation loss: 2.4883218439564687

Epoch: 6| Step: 4
Training loss: 2.5453758274019513
Validation loss: 2.4841818304557766

Epoch: 6| Step: 5
Training loss: 2.69030562043792
Validation loss: 2.4801576274082215

Epoch: 6| Step: 6
Training loss: 2.1938430375153084
Validation loss: 2.4745467654012763

Epoch: 6| Step: 7
Training loss: 2.2207468208033427
Validation loss: 2.4730475720211933

Epoch: 6| Step: 8
Training loss: 2.687460876889789
Validation loss: 2.476554766300934

Epoch: 6| Step: 9
Training loss: 2.6198718524489695
Validation loss: 2.475961911194564

Epoch: 6| Step: 10
Training loss: 2.186532705882824
Validation loss: 2.464079482964025

Epoch: 6| Step: 11
Training loss: 2.5928966543226437
Validation loss: 2.4780833230797334

Epoch: 6| Step: 12
Training loss: 2.426899478699502
Validation loss: 2.4850717203394175

Epoch: 6| Step: 13
Training loss: 2.172484826845973
Validation loss: 2.5050562906952

Epoch: 164| Step: 0
Training loss: 2.640415702515853
Validation loss: 2.494771863079645

Epoch: 6| Step: 1
Training loss: 2.289015108731104
Validation loss: 2.490979945450847

Epoch: 6| Step: 2
Training loss: 2.5237600397946625
Validation loss: 2.502870493255984

Epoch: 6| Step: 3
Training loss: 2.032915225061384
Validation loss: 2.5139920164935945

Epoch: 6| Step: 4
Training loss: 2.819104303054906
Validation loss: 2.490589781687269

Epoch: 6| Step: 5
Training loss: 2.6489923396736
Validation loss: 2.4834142142657365

Epoch: 6| Step: 6
Training loss: 2.599908159541278
Validation loss: 2.469627932480539

Epoch: 6| Step: 7
Training loss: 1.9672966088297508
Validation loss: 2.478240847355154

Epoch: 6| Step: 8
Training loss: 2.547718119169798
Validation loss: 2.471391270918049

Epoch: 6| Step: 9
Training loss: 2.073223442751166
Validation loss: 2.4779655421275324

Epoch: 6| Step: 10
Training loss: 2.2847114325683764
Validation loss: 2.4660608477720793

Epoch: 6| Step: 11
Training loss: 2.715427868253994
Validation loss: 2.473086769104788

Epoch: 6| Step: 12
Training loss: 2.7420762085678345
Validation loss: 2.4721802649586806

Epoch: 6| Step: 13
Training loss: 2.087864931838814
Validation loss: 2.4823666338072807

Epoch: 165| Step: 0
Training loss: 2.1876301318017393
Validation loss: 2.4748369818281253

Epoch: 6| Step: 1
Training loss: 2.303239373895895
Validation loss: 2.470416202897918

Epoch: 6| Step: 2
Training loss: 2.4265695663909304
Validation loss: 2.478600562934624

Epoch: 6| Step: 3
Training loss: 1.7953942209739524
Validation loss: 2.4695913112617287

Epoch: 6| Step: 4
Training loss: 2.3463571924549256
Validation loss: 2.4851857268060225

Epoch: 6| Step: 5
Training loss: 1.6746526443376286
Validation loss: 2.477837203424634

Epoch: 6| Step: 6
Training loss: 2.5789493052191585
Validation loss: 2.47562036734872

Epoch: 6| Step: 7
Training loss: 2.8774261189379455
Validation loss: 2.482581957065744

Epoch: 6| Step: 8
Training loss: 2.6744513332227333
Validation loss: 2.4833535387723438

Epoch: 6| Step: 9
Training loss: 2.520143135940628
Validation loss: 2.471648820061109

Epoch: 6| Step: 10
Training loss: 2.441377538893678
Validation loss: 2.478403107414079

Epoch: 6| Step: 11
Training loss: 2.7730856228969425
Validation loss: 2.484511717547277

Epoch: 6| Step: 12
Training loss: 2.5218710746876396
Validation loss: 2.4821504433997212

Epoch: 6| Step: 13
Training loss: 2.9724862129013605
Validation loss: 2.485039564133709

Epoch: 166| Step: 0
Training loss: 2.016667296144161
Validation loss: 2.489199051401018

Epoch: 6| Step: 1
Training loss: 2.550736197618505
Validation loss: 2.492344244449383

Epoch: 6| Step: 2
Training loss: 2.081702344154467
Validation loss: 2.4814819189116606

Epoch: 6| Step: 3
Training loss: 2.6284375162547557
Validation loss: 2.4863191111506873

Epoch: 6| Step: 4
Training loss: 2.2148284642467457
Validation loss: 2.4841706293845047

Epoch: 6| Step: 5
Training loss: 2.1266019056538568
Validation loss: 2.484118882258954

Epoch: 6| Step: 6
Training loss: 2.9755300097816737
Validation loss: 2.485360595846591

Epoch: 6| Step: 7
Training loss: 2.394434368420156
Validation loss: 2.4784883217576534

Epoch: 6| Step: 8
Training loss: 2.6598624404674527
Validation loss: 2.4983677780986775

Epoch: 6| Step: 9
Training loss: 2.267271509066613
Validation loss: 2.487282321421493

Epoch: 6| Step: 10
Training loss: 2.7728284570051462
Validation loss: 2.5072692726401997

Epoch: 6| Step: 11
Training loss: 2.5590844069733536
Validation loss: 2.5139250451210713

Epoch: 6| Step: 12
Training loss: 2.7729534747639684
Validation loss: 2.506532193704438

Epoch: 6| Step: 13
Training loss: 2.056794453344652
Validation loss: 2.484613067288676

Epoch: 167| Step: 0
Training loss: 2.355402349292108
Validation loss: 2.4816862707685265

Epoch: 6| Step: 1
Training loss: 2.217500361600586
Validation loss: 2.4693325176364684

Epoch: 6| Step: 2
Training loss: 2.6534172660964574
Validation loss: 2.467288538365978

Epoch: 6| Step: 3
Training loss: 2.6545196282542554
Validation loss: 2.4597598371376557

Epoch: 6| Step: 4
Training loss: 2.428707501662477
Validation loss: 2.4664786791263698

Epoch: 6| Step: 5
Training loss: 2.2949858701183694
Validation loss: 2.4546101927648905

Epoch: 6| Step: 6
Training loss: 2.660027096115581
Validation loss: 2.4657048385322633

Epoch: 6| Step: 7
Training loss: 2.4093700839337613
Validation loss: 2.4619796322528313

Epoch: 6| Step: 8
Training loss: 2.507251902635929
Validation loss: 2.476469244740518

Epoch: 6| Step: 9
Training loss: 1.9496657598585443
Validation loss: 2.4717965542401927

Epoch: 6| Step: 10
Training loss: 2.6011091874086674
Validation loss: 2.4725135894648793

Epoch: 6| Step: 11
Training loss: 2.540195247625097
Validation loss: 2.4906629884152887

Epoch: 6| Step: 12
Training loss: 2.4073776971445473
Validation loss: 2.4794944151179354

Epoch: 6| Step: 13
Training loss: 2.515991373808466
Validation loss: 2.4889152992593804

Epoch: 168| Step: 0
Training loss: 2.6395535975956386
Validation loss: 2.509394161773528

Epoch: 6| Step: 1
Training loss: 2.6638448408151514
Validation loss: 2.5187088602522554

Epoch: 6| Step: 2
Training loss: 2.580546218951905
Validation loss: 2.515743244938306

Epoch: 6| Step: 3
Training loss: 2.431657881464873
Validation loss: 2.525777560450743

Epoch: 6| Step: 4
Training loss: 2.331047527939885
Validation loss: 2.4971718845190285

Epoch: 6| Step: 5
Training loss: 2.230344110804451
Validation loss: 2.4924416885773786

Epoch: 6| Step: 6
Training loss: 2.2789005042766424
Validation loss: 2.474938302282561

Epoch: 6| Step: 7
Training loss: 2.3657302651612673
Validation loss: 2.4802181327548265

Epoch: 6| Step: 8
Training loss: 2.3188122352823477
Validation loss: 2.485379557773526

Epoch: 6| Step: 9
Training loss: 2.2752701232174517
Validation loss: 2.485267998490297

Epoch: 6| Step: 10
Training loss: 2.434213525707844
Validation loss: 2.463564388070899

Epoch: 6| Step: 11
Training loss: 2.655421767418204
Validation loss: 2.4839687615072004

Epoch: 6| Step: 12
Training loss: 2.8634158072919167
Validation loss: 2.4758469262825833

Epoch: 6| Step: 13
Training loss: 2.325980203388493
Validation loss: 2.477748550742546

Epoch: 169| Step: 0
Training loss: 2.3304813416639907
Validation loss: 2.466092212151799

Epoch: 6| Step: 1
Training loss: 2.008105186177064
Validation loss: 2.4745494149803857

Epoch: 6| Step: 2
Training loss: 2.445572811810896
Validation loss: 2.490188434650792

Epoch: 6| Step: 3
Training loss: 2.472338422504214
Validation loss: 2.498564148874398

Epoch: 6| Step: 4
Training loss: 2.571075048062774
Validation loss: 2.4886530863325547

Epoch: 6| Step: 5
Training loss: 2.405103831597584
Validation loss: 2.4980125951813394

Epoch: 6| Step: 6
Training loss: 2.011600231642301
Validation loss: 2.49464050238505

Epoch: 6| Step: 7
Training loss: 2.5414916640105005
Validation loss: 2.47953455997584

Epoch: 6| Step: 8
Training loss: 2.4248846242927913
Validation loss: 2.488963274705115

Epoch: 6| Step: 9
Training loss: 2.9199839301516284
Validation loss: 2.471842040667286

Epoch: 6| Step: 10
Training loss: 2.090535215265959
Validation loss: 2.4754439915799797

Epoch: 6| Step: 11
Training loss: 2.898817834294832
Validation loss: 2.484394889128143

Epoch: 6| Step: 12
Training loss: 2.5499391436327397
Validation loss: 2.4803043020608855

Epoch: 6| Step: 13
Training loss: 2.2016677907074054
Validation loss: 2.4990021780624554

Epoch: 170| Step: 0
Training loss: 2.2123837542842115
Validation loss: 2.499294753735991

Epoch: 6| Step: 1
Training loss: 2.3785843153726787
Validation loss: 2.4859208709652942

Epoch: 6| Step: 2
Training loss: 2.545661215783281
Validation loss: 2.4891487497766804

Epoch: 6| Step: 3
Training loss: 2.6770353399543954
Validation loss: 2.4986585355871997

Epoch: 6| Step: 4
Training loss: 2.2388344392342345
Validation loss: 2.5064657126399372

Epoch: 6| Step: 5
Training loss: 2.5122047061001145
Validation loss: 2.507035686726348

Epoch: 6| Step: 6
Training loss: 1.702136181400404
Validation loss: 2.504873008783203

Epoch: 6| Step: 7
Training loss: 2.591529907183527
Validation loss: 2.5106972554737848

Epoch: 6| Step: 8
Training loss: 2.469554432051456
Validation loss: 2.503098792590971

Epoch: 6| Step: 9
Training loss: 2.434048189255087
Validation loss: 2.4665052936795386

Epoch: 6| Step: 10
Training loss: 2.7289648102713717
Validation loss: 2.4731802322406744

Epoch: 6| Step: 11
Training loss: 2.3089041719042003
Validation loss: 2.465465300029121

Epoch: 6| Step: 12
Training loss: 2.726633502724323
Validation loss: 2.4734795893519794

Epoch: 6| Step: 13
Training loss: 2.3114922879581576
Validation loss: 2.4660203224369828

Epoch: 171| Step: 0
Training loss: 3.0412432928987387
Validation loss: 2.470075677904134

Epoch: 6| Step: 1
Training loss: 3.1159668638257307
Validation loss: 2.470107192391804

Epoch: 6| Step: 2
Training loss: 2.340287155399218
Validation loss: 2.47089087133546

Epoch: 6| Step: 3
Training loss: 2.278325963411873
Validation loss: 2.480188893628242

Epoch: 6| Step: 4
Training loss: 1.506998029929065
Validation loss: 2.473442703855289

Epoch: 6| Step: 5
Training loss: 2.1926932677946724
Validation loss: 2.4715380638741933

Epoch: 6| Step: 6
Training loss: 3.0136794697733205
Validation loss: 2.475834600135208

Epoch: 6| Step: 7
Training loss: 2.2637262214410225
Validation loss: 2.482782649314306

Epoch: 6| Step: 8
Training loss: 1.9922451833713901
Validation loss: 2.4836660849185246

Epoch: 6| Step: 9
Training loss: 1.9959322571047275
Validation loss: 2.4858593774808697

Epoch: 6| Step: 10
Training loss: 2.831300417554336
Validation loss: 2.4775135929621404

Epoch: 6| Step: 11
Training loss: 2.5011273703189514
Validation loss: 2.4834342310930224

Epoch: 6| Step: 12
Training loss: 2.583371367225819
Validation loss: 2.4815182045243147

Epoch: 6| Step: 13
Training loss: 2.2713313358672442
Validation loss: 2.502696958813617

Epoch: 172| Step: 0
Training loss: 1.9198545675034266
Validation loss: 2.4916281396275157

Epoch: 6| Step: 1
Training loss: 2.5187726911937816
Validation loss: 2.4822899247863863

Epoch: 6| Step: 2
Training loss: 2.157398747160118
Validation loss: 2.4870457878310215

Epoch: 6| Step: 3
Training loss: 2.8834509000531945
Validation loss: 2.4760375725104207

Epoch: 6| Step: 4
Training loss: 2.513724515492662
Validation loss: 2.4863977894458986

Epoch: 6| Step: 5
Training loss: 2.082307893792554
Validation loss: 2.4761628270679736

Epoch: 6| Step: 6
Training loss: 3.1378791914296706
Validation loss: 2.4650040870101297

Epoch: 6| Step: 7
Training loss: 2.2683867360746524
Validation loss: 2.473945703306919

Epoch: 6| Step: 8
Training loss: 2.454779971764849
Validation loss: 2.4807392763813745

Epoch: 6| Step: 9
Training loss: 2.806492641638456
Validation loss: 2.482416456583284

Epoch: 6| Step: 10
Training loss: 2.5389359193207284
Validation loss: 2.4784792312984227

Epoch: 6| Step: 11
Training loss: 2.684481589140686
Validation loss: 2.4801679133411727

Epoch: 6| Step: 12
Training loss: 1.4738732932353205
Validation loss: 2.4878195150080242

Epoch: 6| Step: 13
Training loss: 2.305465928854488
Validation loss: 2.4862475905319616

Epoch: 173| Step: 0
Training loss: 2.5313411743321246
Validation loss: 2.483038936889917

Epoch: 6| Step: 1
Training loss: 2.024047288364852
Validation loss: 2.4839217214315887

Epoch: 6| Step: 2
Training loss: 2.4610978331637035
Validation loss: 2.485561551339441

Epoch: 6| Step: 3
Training loss: 2.2414426197652695
Validation loss: 2.4807118534496055

Epoch: 6| Step: 4
Training loss: 2.5562153485101726
Validation loss: 2.489286434287892

Epoch: 6| Step: 5
Training loss: 2.614359680174669
Validation loss: 2.480728768564839

Epoch: 6| Step: 6
Training loss: 2.791122402447068
Validation loss: 2.476692043891503

Epoch: 6| Step: 7
Training loss: 2.7511082930166135
Validation loss: 2.473600989517427

Epoch: 6| Step: 8
Training loss: 2.47642059400964
Validation loss: 2.4789854726105403

Epoch: 6| Step: 9
Training loss: 1.9499130082900318
Validation loss: 2.488824742087556

Epoch: 6| Step: 10
Training loss: 2.844904403287178
Validation loss: 2.4676356637564973

Epoch: 6| Step: 11
Training loss: 2.345903653253454
Validation loss: 2.4822300062206453

Epoch: 6| Step: 12
Training loss: 1.7238832286444423
Validation loss: 2.4997140164516214

Epoch: 6| Step: 13
Training loss: 2.36560237173246
Validation loss: 2.5056234849808035

Epoch: 174| Step: 0
Training loss: 2.4518787109595848
Validation loss: 2.49451800752146

Epoch: 6| Step: 1
Training loss: 2.1273197527150796
Validation loss: 2.498775388872687

Epoch: 6| Step: 2
Training loss: 2.608625658450774
Validation loss: 2.5119774004472384

Epoch: 6| Step: 3
Training loss: 2.3589028397587457
Validation loss: 2.5055105908647777

Epoch: 6| Step: 4
Training loss: 2.2584637293408205
Validation loss: 2.489339111564903

Epoch: 6| Step: 5
Training loss: 2.4532247146458714
Validation loss: 2.4887662102583135

Epoch: 6| Step: 6
Training loss: 3.018502399407609
Validation loss: 2.478838928315174

Epoch: 6| Step: 7
Training loss: 2.1845296038269515
Validation loss: 2.48995663758327

Epoch: 6| Step: 8
Training loss: 2.476706996998376
Validation loss: 2.4796554153119774

Epoch: 6| Step: 9
Training loss: 2.309205982594461
Validation loss: 2.484030301794824

Epoch: 6| Step: 10
Training loss: 2.5504073472131368
Validation loss: 2.5024164124768102

Epoch: 6| Step: 11
Training loss: 2.32645453618233
Validation loss: 2.4854570027926286

Epoch: 6| Step: 12
Training loss: 2.420988843675487
Validation loss: 2.490167019999029

Epoch: 6| Step: 13
Training loss: 2.4726357120185263
Validation loss: 2.4985038731012965

Epoch: 175| Step: 0
Training loss: 2.2533248072054723
Validation loss: 2.4843497764858418

Epoch: 6| Step: 1
Training loss: 2.6100098528621216
Validation loss: 2.489327794025771

Epoch: 6| Step: 2
Training loss: 1.780021779430747
Validation loss: 2.4914206956468736

Epoch: 6| Step: 3
Training loss: 2.2315735227117357
Validation loss: 2.4796420824922984

Epoch: 6| Step: 4
Training loss: 2.407037581324337
Validation loss: 2.483530416818099

Epoch: 6| Step: 5
Training loss: 2.586548148255158
Validation loss: 2.468586783506433

Epoch: 6| Step: 6
Training loss: 2.4176902795523243
Validation loss: 2.489002779914506

Epoch: 6| Step: 7
Training loss: 2.7709803912688353
Validation loss: 2.5037941592672905

Epoch: 6| Step: 8
Training loss: 2.418795886331438
Validation loss: 2.5132335882437467

Epoch: 6| Step: 9
Training loss: 2.3558659005205183
Validation loss: 2.560548721727937

Epoch: 6| Step: 10
Training loss: 2.7941903810512057
Validation loss: 2.5723348157841426

Epoch: 6| Step: 11
Training loss: 2.3576490139513644
Validation loss: 2.5638593154235787

Epoch: 6| Step: 12
Training loss: 2.6572278186440434
Validation loss: 2.532330019644867

Epoch: 6| Step: 13
Training loss: 2.543740057398605
Validation loss: 2.504406558165539

Epoch: 176| Step: 0
Training loss: 2.4664971417948527
Validation loss: 2.4940047937824845

Epoch: 6| Step: 1
Training loss: 2.871639277732922
Validation loss: 2.4843815577518438

Epoch: 6| Step: 2
Training loss: 1.7935914265258426
Validation loss: 2.4815336409612363

Epoch: 6| Step: 3
Training loss: 2.51441604281122
Validation loss: 2.484339107997906

Epoch: 6| Step: 4
Training loss: 2.849841792751552
Validation loss: 2.4970904108162864

Epoch: 6| Step: 5
Training loss: 1.7169634463729944
Validation loss: 2.4870742273720525

Epoch: 6| Step: 6
Training loss: 3.213436296034872
Validation loss: 2.4864097116353907

Epoch: 6| Step: 7
Training loss: 2.0176471354969148
Validation loss: 2.5141869219616364

Epoch: 6| Step: 8
Training loss: 2.7410870813887596
Validation loss: 2.5167662754514644

Epoch: 6| Step: 9
Training loss: 1.9328974539389945
Validation loss: 2.486515378730469

Epoch: 6| Step: 10
Training loss: 2.372579746815432
Validation loss: 2.5068238192063403

Epoch: 6| Step: 11
Training loss: 2.2454234308860697
Validation loss: 2.499103854417069

Epoch: 6| Step: 12
Training loss: 2.3669951206506705
Validation loss: 2.510325122815604

Epoch: 6| Step: 13
Training loss: 2.3127474265858967
Validation loss: 2.505560460923443

Epoch: 177| Step: 0
Training loss: 2.5009338542087516
Validation loss: 2.512091451296331

Epoch: 6| Step: 1
Training loss: 2.377491798266395
Validation loss: 2.500898422297537

Epoch: 6| Step: 2
Training loss: 2.403760637963015
Validation loss: 2.501543013913572

Epoch: 6| Step: 3
Training loss: 2.3015062002843942
Validation loss: 2.4951059757983587

Epoch: 6| Step: 4
Training loss: 2.6790478891134226
Validation loss: 2.498680927059161

Epoch: 6| Step: 5
Training loss: 3.0300803533292373
Validation loss: 2.522311058617907

Epoch: 6| Step: 6
Training loss: 1.7434020320760146
Validation loss: 2.496541476105266

Epoch: 6| Step: 7
Training loss: 2.3212423291796025
Validation loss: 2.5058065851388944

Epoch: 6| Step: 8
Training loss: 2.354505351412288
Validation loss: 2.4986020789255003

Epoch: 6| Step: 9
Training loss: 2.2643634309191483
Validation loss: 2.5152733598493953

Epoch: 6| Step: 10
Training loss: 3.027459202687625
Validation loss: 2.5162767312401355

Epoch: 6| Step: 11
Training loss: 2.5643919496582748
Validation loss: 2.4997564674016806

Epoch: 6| Step: 12
Training loss: 2.1661776455408766
Validation loss: 2.497902530718191

Epoch: 6| Step: 13
Training loss: 2.0623679841302165
Validation loss: 2.516000131315441

Epoch: 178| Step: 0
Training loss: 3.1529076129845013
Validation loss: 2.5094207883008885

Epoch: 6| Step: 1
Training loss: 2.2108378573228906
Validation loss: 2.5139030581426836

Epoch: 6| Step: 2
Training loss: 2.543706315248933
Validation loss: 2.5133851151313658

Epoch: 6| Step: 3
Training loss: 2.8440752786580434
Validation loss: 2.519985723783028

Epoch: 6| Step: 4
Training loss: 2.392135741149162
Validation loss: 2.5108095286401775

Epoch: 6| Step: 5
Training loss: 2.586084920593718
Validation loss: 2.5058414877820283

Epoch: 6| Step: 6
Training loss: 2.2868952467679717
Validation loss: 2.514817291812658

Epoch: 6| Step: 7
Training loss: 2.3045511496345092
Validation loss: 2.500640516880527

Epoch: 6| Step: 8
Training loss: 2.2743640597699595
Validation loss: 2.4879900463984543

Epoch: 6| Step: 9
Training loss: 2.2649973032684776
Validation loss: 2.489460823737131

Epoch: 6| Step: 10
Training loss: 2.5331956897117656
Validation loss: 2.499124166931391

Epoch: 6| Step: 11
Training loss: 2.1947520344949956
Validation loss: 2.491334775256498

Epoch: 6| Step: 12
Training loss: 1.6397122705245095
Validation loss: 2.4964788912845863

Epoch: 6| Step: 13
Training loss: 2.3652448583066605
Validation loss: 2.492709433054147

Epoch: 179| Step: 0
Training loss: 3.1704350853425614
Validation loss: 2.4867338422372613

Epoch: 6| Step: 1
Training loss: 2.3783401291698234
Validation loss: 2.4780009090723643

Epoch: 6| Step: 2
Training loss: 2.543178098531605
Validation loss: 2.4738487513850993

Epoch: 6| Step: 3
Training loss: 2.3480474111264154
Validation loss: 2.5047036268603904

Epoch: 6| Step: 4
Training loss: 1.877729971626377
Validation loss: 2.502179086225661

Epoch: 6| Step: 5
Training loss: 2.939075777793472
Validation loss: 2.507455073442562

Epoch: 6| Step: 6
Training loss: 2.2788788478329836
Validation loss: 2.5089369141660245

Epoch: 6| Step: 7
Training loss: 2.71826720061588
Validation loss: 2.4919071019840238

Epoch: 6| Step: 8
Training loss: 1.6185868700229058
Validation loss: 2.5100288144265

Epoch: 6| Step: 9
Training loss: 2.4272061645686023
Validation loss: 2.501454343568347

Epoch: 6| Step: 10
Training loss: 2.483190866091732
Validation loss: 2.499406410319443

Epoch: 6| Step: 11
Training loss: 2.15348018822592
Validation loss: 2.4933429140359062

Epoch: 6| Step: 12
Training loss: 2.5319133878239954
Validation loss: 2.4726512199780575

Epoch: 6| Step: 13
Training loss: 1.9281824706182218
Validation loss: 2.470536466865557

Epoch: 180| Step: 0
Training loss: 1.9421229430783968
Validation loss: 2.4871409471761754

Epoch: 6| Step: 1
Training loss: 2.341585711327615
Validation loss: 2.4847463973961137

Epoch: 6| Step: 2
Training loss: 2.786754005408033
Validation loss: 2.47233503122397

Epoch: 6| Step: 3
Training loss: 2.3399766174191483
Validation loss: 2.4897086352707354

Epoch: 6| Step: 4
Training loss: 2.5254142270382975
Validation loss: 2.4872038148940114

Epoch: 6| Step: 5
Training loss: 2.184569766812348
Validation loss: 2.48453508417123

Epoch: 6| Step: 6
Training loss: 2.876190270869291
Validation loss: 2.4773774997157005

Epoch: 6| Step: 7
Training loss: 2.414503730030066
Validation loss: 2.490520896634534

Epoch: 6| Step: 8
Training loss: 2.4635583878340155
Validation loss: 2.4802888659834395

Epoch: 6| Step: 9
Training loss: 2.1174533578539028
Validation loss: 2.4744539962277394

Epoch: 6| Step: 10
Training loss: 2.812312819292101
Validation loss: 2.472315390637423

Epoch: 6| Step: 11
Training loss: 1.9389243889005607
Validation loss: 2.4931313253191614

Epoch: 6| Step: 12
Training loss: 2.2003864555786654
Validation loss: 2.481101544580933

Epoch: 6| Step: 13
Training loss: 2.7855740483934817
Validation loss: 2.4927753165831588

Epoch: 181| Step: 0
Training loss: 1.6127979949494038
Validation loss: 2.4877410733516405

Epoch: 6| Step: 1
Training loss: 2.6360632865845437
Validation loss: 2.489250517323518

Epoch: 6| Step: 2
Training loss: 2.2407776124872965
Validation loss: 2.488830857035579

Epoch: 6| Step: 3
Training loss: 2.700975919885219
Validation loss: 2.48586537184377

Epoch: 6| Step: 4
Training loss: 2.7936799964412296
Validation loss: 2.490058914685113

Epoch: 6| Step: 5
Training loss: 1.8963113817855581
Validation loss: 2.493137525334313

Epoch: 6| Step: 6
Training loss: 2.736488702433939
Validation loss: 2.49549458157295

Epoch: 6| Step: 7
Training loss: 1.6599304763758533
Validation loss: 2.494627201868464

Epoch: 6| Step: 8
Training loss: 2.618100408500965
Validation loss: 2.4921363020115397

Epoch: 6| Step: 9
Training loss: 1.9857409124069194
Validation loss: 2.4985007558977603

Epoch: 6| Step: 10
Training loss: 2.5738769674826716
Validation loss: 2.507624602285183

Epoch: 6| Step: 11
Training loss: 2.3472847287534924
Validation loss: 2.496427104820103

Epoch: 6| Step: 12
Training loss: 2.4299875546360385
Validation loss: 2.504687444790407

Epoch: 6| Step: 13
Training loss: 3.010564006292895
Validation loss: 2.491240653380811

Epoch: 182| Step: 0
Training loss: 1.971703146142641
Validation loss: 2.5048419475630235

Epoch: 6| Step: 1
Training loss: 2.4556292732339458
Validation loss: 2.536253266135805

Epoch: 6| Step: 2
Training loss: 2.5592602043816663
Validation loss: 2.567380668878174

Epoch: 6| Step: 3
Training loss: 2.7646449017274723
Validation loss: 2.581443207955357

Epoch: 6| Step: 4
Training loss: 1.932052830607587
Validation loss: 2.612701899196606

Epoch: 6| Step: 5
Training loss: 2.431399217748269
Validation loss: 2.637477451005097

Epoch: 6| Step: 6
Training loss: 2.3299408046422996
Validation loss: 2.6325638650825556

Epoch: 6| Step: 7
Training loss: 2.500674538211066
Validation loss: 2.5649885948725726

Epoch: 6| Step: 8
Training loss: 2.7511643632371627
Validation loss: 2.529149035204328

Epoch: 6| Step: 9
Training loss: 2.325131123444641
Validation loss: 2.498209192700659

Epoch: 6| Step: 10
Training loss: 2.4800205096042776
Validation loss: 2.4762791773389603

Epoch: 6| Step: 11
Training loss: 2.1847043292598247
Validation loss: 2.4879991500215213

Epoch: 6| Step: 12
Training loss: 2.8884615663596622
Validation loss: 2.49196486639613

Epoch: 6| Step: 13
Training loss: 2.245993119349008
Validation loss: 2.495273700142541

Epoch: 183| Step: 0
Training loss: 2.3188633358960042
Validation loss: 2.495297921460011

Epoch: 6| Step: 1
Training loss: 2.9887087048749357
Validation loss: 2.4962125937954798

Epoch: 6| Step: 2
Training loss: 2.034966106648044
Validation loss: 2.4984218543642114

Epoch: 6| Step: 3
Training loss: 2.9117360173136375
Validation loss: 2.505587707049159

Epoch: 6| Step: 4
Training loss: 2.6445435110960225
Validation loss: 2.5053341385202432

Epoch: 6| Step: 5
Training loss: 1.9225561904136512
Validation loss: 2.4964595520666824

Epoch: 6| Step: 6
Training loss: 3.3854469806585508
Validation loss: 2.4994943584264773

Epoch: 6| Step: 7
Training loss: 2.3299667958525485
Validation loss: 2.4892971534059605

Epoch: 6| Step: 8
Training loss: 2.184818477117516
Validation loss: 2.482762947332241

Epoch: 6| Step: 9
Training loss: 2.4426479264349763
Validation loss: 2.480657455194859

Epoch: 6| Step: 10
Training loss: 2.1558565527166027
Validation loss: 2.4799957224850013

Epoch: 6| Step: 11
Training loss: 2.1121249887444193
Validation loss: 2.473278399274697

Epoch: 6| Step: 12
Training loss: 2.679293856610051
Validation loss: 2.481011278790288

Epoch: 6| Step: 13
Training loss: 2.2522366321297
Validation loss: 2.4877511921607818

Epoch: 184| Step: 0
Training loss: 1.7095877840989995
Validation loss: 2.479262379527082

Epoch: 6| Step: 1
Training loss: 2.0908516708224676
Validation loss: 2.488172000740373

Epoch: 6| Step: 2
Training loss: 2.2549461464890186
Validation loss: 2.4955141273082857

Epoch: 6| Step: 3
Training loss: 2.391446439946811
Validation loss: 2.4921011914781253

Epoch: 6| Step: 4
Training loss: 2.6802622009233055
Validation loss: 2.5056279968335144

Epoch: 6| Step: 5
Training loss: 2.201345604418528
Validation loss: 2.499834953264175

Epoch: 6| Step: 6
Training loss: 2.4417307401545676
Validation loss: 2.4997894118941812

Epoch: 6| Step: 7
Training loss: 2.78821548722116
Validation loss: 2.4917160752244754

Epoch: 6| Step: 8
Training loss: 2.464593502828771
Validation loss: 2.4917260582861505

Epoch: 6| Step: 9
Training loss: 2.613224319727421
Validation loss: 2.4832937258777026

Epoch: 6| Step: 10
Training loss: 2.7724872519335033
Validation loss: 2.492314629416413

Epoch: 6| Step: 11
Training loss: 2.648703232658817
Validation loss: 2.50521967694311

Epoch: 6| Step: 12
Training loss: 2.1526516730450997
Validation loss: 2.486779590740887

Epoch: 6| Step: 13
Training loss: 2.310462672810615
Validation loss: 2.4887902554153163

Epoch: 185| Step: 0
Training loss: 2.9610117397210893
Validation loss: 2.4952596226876014

Epoch: 6| Step: 1
Training loss: 2.854695477654596
Validation loss: 2.5010851571208783

Epoch: 6| Step: 2
Training loss: 1.810374756896067
Validation loss: 2.4968087809426915

Epoch: 6| Step: 3
Training loss: 2.0371861502790245
Validation loss: 2.488598398610767

Epoch: 6| Step: 4
Training loss: 2.4832333034705645
Validation loss: 2.501173554586275

Epoch: 6| Step: 5
Training loss: 2.9052066365744604
Validation loss: 2.480891154209887

Epoch: 6| Step: 6
Training loss: 2.0315653629514587
Validation loss: 2.5028798999713966

Epoch: 6| Step: 7
Training loss: 2.715017628761792
Validation loss: 2.4824770029161045

Epoch: 6| Step: 8
Training loss: 2.295776935122366
Validation loss: 2.4980943808016463

Epoch: 6| Step: 9
Training loss: 2.059990483234237
Validation loss: 2.5012688595684964

Epoch: 6| Step: 10
Training loss: 2.4745078242901446
Validation loss: 2.5024880267506893

Epoch: 6| Step: 11
Training loss: 2.317588774494115
Validation loss: 2.5006534040433768

Epoch: 6| Step: 12
Training loss: 2.032200517537934
Validation loss: 2.497978998911905

Epoch: 6| Step: 13
Training loss: 2.3153577107183168
Validation loss: 2.51803247787562

Epoch: 186| Step: 0
Training loss: 2.3429415516484653
Validation loss: 2.4959761821219715

Epoch: 6| Step: 1
Training loss: 2.7073186196167933
Validation loss: 2.495610731150802

Epoch: 6| Step: 2
Training loss: 2.656355193803986
Validation loss: 2.5058039051793655

Epoch: 6| Step: 3
Training loss: 1.79449052577628
Validation loss: 2.5158273366743122

Epoch: 6| Step: 4
Training loss: 2.4124469968675606
Validation loss: 2.5227141234169492

Epoch: 6| Step: 5
Training loss: 2.610421707461017
Validation loss: 2.5114248448885217

Epoch: 6| Step: 6
Training loss: 2.8150327510520814
Validation loss: 2.5396508263957096

Epoch: 6| Step: 7
Training loss: 2.5677423584536228
Validation loss: 2.539726663435138

Epoch: 6| Step: 8
Training loss: 2.233171258805465
Validation loss: 2.525354946166681

Epoch: 6| Step: 9
Training loss: 2.1198016142240745
Validation loss: 2.510708729914101

Epoch: 6| Step: 10
Training loss: 1.9444160080904267
Validation loss: 2.510087816113095

Epoch: 6| Step: 11
Training loss: 2.2267920660163663
Validation loss: 2.487477043339854

Epoch: 6| Step: 12
Training loss: 2.231160445780279
Validation loss: 2.5039525417069726

Epoch: 6| Step: 13
Training loss: 2.5398596817967234
Validation loss: 2.4904673867509413

Epoch: 187| Step: 0
Training loss: 2.597264310481037
Validation loss: 2.4944062117705403

Epoch: 6| Step: 1
Training loss: 1.608957403132415
Validation loss: 2.504863569893397

Epoch: 6| Step: 2
Training loss: 2.0772641342073377
Validation loss: 2.4977573349262445

Epoch: 6| Step: 3
Training loss: 2.0484671188296555
Validation loss: 2.4873694840892493

Epoch: 6| Step: 4
Training loss: 2.1833112667026637
Validation loss: 2.4967264996206286

Epoch: 6| Step: 5
Training loss: 3.1351600280024114
Validation loss: 2.488587939946059

Epoch: 6| Step: 6
Training loss: 1.7196615402865965
Validation loss: 2.493862119622459

Epoch: 6| Step: 7
Training loss: 2.623209024446489
Validation loss: 2.482873362840914

Epoch: 6| Step: 8
Training loss: 2.39746312531723
Validation loss: 2.484751322972533

Epoch: 6| Step: 9
Training loss: 2.5548006085195754
Validation loss: 2.472230638592094

Epoch: 6| Step: 10
Training loss: 2.367403631132164
Validation loss: 2.47563070423548

Epoch: 6| Step: 11
Training loss: 2.109596749411933
Validation loss: 2.4804043578753436

Epoch: 6| Step: 12
Training loss: 2.7971523722775262
Validation loss: 2.4918696122039092

Epoch: 6| Step: 13
Training loss: 2.9111298641380574
Validation loss: 2.497646400098934

Epoch: 188| Step: 0
Training loss: 2.2878908667646494
Validation loss: 2.5210591259763624

Epoch: 6| Step: 1
Training loss: 2.680920731393895
Validation loss: 2.5748719161933527

Epoch: 6| Step: 2
Training loss: 2.4985085807074294
Validation loss: 2.5946925874954476

Epoch: 6| Step: 3
Training loss: 2.2731872630618835
Validation loss: 2.5529993294798303

Epoch: 6| Step: 4
Training loss: 2.4902483532083175
Validation loss: 2.5595735726741444

Epoch: 6| Step: 5
Training loss: 2.9272426322044796
Validation loss: 2.5225905501890304

Epoch: 6| Step: 6
Training loss: 2.191666259572193
Validation loss: 2.5104190831680593

Epoch: 6| Step: 7
Training loss: 2.695896958824216
Validation loss: 2.484978752429166

Epoch: 6| Step: 8
Training loss: 2.82669368374107
Validation loss: 2.4640776606939787

Epoch: 6| Step: 9
Training loss: 1.9857589821524098
Validation loss: 2.4984544983667885

Epoch: 6| Step: 10
Training loss: 2.068467955940681
Validation loss: 2.494263018913611

Epoch: 6| Step: 11
Training loss: 2.3138978187334787
Validation loss: 2.4986379409809367

Epoch: 6| Step: 12
Training loss: 2.7394167386495183
Validation loss: 2.492095371564439

Epoch: 6| Step: 13
Training loss: 1.8971864950459834
Validation loss: 2.5057014619739704

Epoch: 189| Step: 0
Training loss: 2.674497510827932
Validation loss: 2.4878025522693235

Epoch: 6| Step: 1
Training loss: 1.6353335106314744
Validation loss: 2.5043938648492974

Epoch: 6| Step: 2
Training loss: 2.694504945825146
Validation loss: 2.4930972966838296

Epoch: 6| Step: 3
Training loss: 2.2478056910016737
Validation loss: 2.494456694114341

Epoch: 6| Step: 4
Training loss: 2.059486036534401
Validation loss: 2.4884288510511556

Epoch: 6| Step: 5
Training loss: 2.253667914683002
Validation loss: 2.498862134749637

Epoch: 6| Step: 6
Training loss: 2.2209279291309842
Validation loss: 2.4874650463926415

Epoch: 6| Step: 7
Training loss: 2.5331598306101792
Validation loss: 2.479997645218049

Epoch: 6| Step: 8
Training loss: 2.5322341889407425
Validation loss: 2.4848321777923754

Epoch: 6| Step: 9
Training loss: 2.853297043091252
Validation loss: 2.4908818379343383

Epoch: 6| Step: 10
Training loss: 2.6667976545905736
Validation loss: 2.494033321262029

Epoch: 6| Step: 11
Training loss: 1.752546433229548
Validation loss: 2.4923683666899428

Epoch: 6| Step: 12
Training loss: 2.4813667173823406
Validation loss: 2.4981622617079005

Epoch: 6| Step: 13
Training loss: 2.6175522279675136
Validation loss: 2.4999854405297075

Epoch: 190| Step: 0
Training loss: 2.4629347673978357
Validation loss: 2.4929811017304164

Epoch: 6| Step: 1
Training loss: 1.2776367131517283
Validation loss: 2.5000249464061954

Epoch: 6| Step: 2
Training loss: 2.1825910801360844
Validation loss: 2.495279926683816

Epoch: 6| Step: 3
Training loss: 2.356968542977494
Validation loss: 2.5105394409886337

Epoch: 6| Step: 4
Training loss: 2.0092254298237275
Validation loss: 2.5014422548023605

Epoch: 6| Step: 5
Training loss: 2.1534219523206146
Validation loss: 2.5144121235543766

Epoch: 6| Step: 6
Training loss: 2.9429488272279927
Validation loss: 2.5156177417974233

Epoch: 6| Step: 7
Training loss: 2.7414642858354865
Validation loss: 2.507640290017096

Epoch: 6| Step: 8
Training loss: 3.1419776546720533
Validation loss: 2.515267009022793

Epoch: 6| Step: 9
Training loss: 2.725015545721945
Validation loss: 2.517092866892684

Epoch: 6| Step: 10
Training loss: 2.470923517220657
Validation loss: 2.5433782119924424

Epoch: 6| Step: 11
Training loss: 2.315695539421974
Validation loss: 2.527856962363374

Epoch: 6| Step: 12
Training loss: 1.620997708704351
Validation loss: 2.5228760274758266

Epoch: 6| Step: 13
Training loss: 2.5262059948093007
Validation loss: 2.5113978598702986

Epoch: 191| Step: 0
Training loss: 2.6623209073720933
Validation loss: 2.4734592027930997

Epoch: 6| Step: 1
Training loss: 2.0139079505924475
Validation loss: 2.498649924040829

Epoch: 6| Step: 2
Training loss: 1.7225507154597604
Validation loss: 2.4837954502973973

Epoch: 6| Step: 3
Training loss: 2.479167542871486
Validation loss: 2.4874962926482365

Epoch: 6| Step: 4
Training loss: 2.9153065007659493
Validation loss: 2.468500156878293

Epoch: 6| Step: 5
Training loss: 1.8785344190127387
Validation loss: 2.4839290962481173

Epoch: 6| Step: 6
Training loss: 2.8601796836695375
Validation loss: 2.4775483007563275

Epoch: 6| Step: 7
Training loss: 2.0844199843463835
Validation loss: 2.4794807528972953

Epoch: 6| Step: 8
Training loss: 1.8459064997286174
Validation loss: 2.486319063204593

Epoch: 6| Step: 9
Training loss: 2.601696663911045
Validation loss: 2.482067339951664

Epoch: 6| Step: 10
Training loss: 1.977333732588649
Validation loss: 2.5023085187658363

Epoch: 6| Step: 11
Training loss: 2.3134246214884726
Validation loss: 2.4880670428335327

Epoch: 6| Step: 12
Training loss: 2.9910615640245783
Validation loss: 2.4882837731684453

Epoch: 6| Step: 13
Training loss: 2.5055415724284025
Validation loss: 2.483419254489244

Epoch: 192| Step: 0
Training loss: 2.3741574047582352
Validation loss: 2.496842838568797

Epoch: 6| Step: 1
Training loss: 2.6936755530741805
Validation loss: 2.5017451553010646

Epoch: 6| Step: 2
Training loss: 2.0394469150930163
Validation loss: 2.503196302232625

Epoch: 6| Step: 3
Training loss: 2.219596486406816
Validation loss: 2.512522804574291

Epoch: 6| Step: 4
Training loss: 2.850198665186389
Validation loss: 2.508866212538889

Epoch: 6| Step: 5
Training loss: 2.127513745058442
Validation loss: 2.5135764474645352

Epoch: 6| Step: 6
Training loss: 2.6596924857880695
Validation loss: 2.5375057045006484

Epoch: 6| Step: 7
Training loss: 2.105509515201372
Validation loss: 2.521565202342891

Epoch: 6| Step: 8
Training loss: 2.908195254774441
Validation loss: 2.517249362847605

Epoch: 6| Step: 9
Training loss: 1.9102712023261952
Validation loss: 2.5256611698049367

Epoch: 6| Step: 10
Training loss: 1.9680768027632223
Validation loss: 2.5174828060741117

Epoch: 6| Step: 11
Training loss: 2.2418995316766175
Validation loss: 2.5123184065726063

Epoch: 6| Step: 12
Training loss: 2.332043518340845
Validation loss: 2.5004515796349867

Epoch: 6| Step: 13
Training loss: 2.661970911602211
Validation loss: 2.4933059717740775

Epoch: 193| Step: 0
Training loss: 1.9060747034738115
Validation loss: 2.491500042178318

Epoch: 6| Step: 1
Training loss: 2.77995055628107
Validation loss: 2.49389851190849

Epoch: 6| Step: 2
Training loss: 2.4904104372503695
Validation loss: 2.500152916999914

Epoch: 6| Step: 3
Training loss: 1.7418807918697297
Validation loss: 2.495292809682801

Epoch: 6| Step: 4
Training loss: 2.1617742345904465
Validation loss: 2.4884063513591297

Epoch: 6| Step: 5
Training loss: 2.3223206535216963
Validation loss: 2.4892752122875765

Epoch: 6| Step: 6
Training loss: 2.7268053181689704
Validation loss: 2.4952983514221025

Epoch: 6| Step: 7
Training loss: 2.516061401424561
Validation loss: 2.4801162268977865

Epoch: 6| Step: 8
Training loss: 2.680014543066848
Validation loss: 2.486600850408693

Epoch: 6| Step: 9
Training loss: 1.6410914166806285
Validation loss: 2.5062927680040863

Epoch: 6| Step: 10
Training loss: 2.8635473609073028
Validation loss: 2.4904928953330723

Epoch: 6| Step: 11
Training loss: 2.2471281373277465
Validation loss: 2.4904336687511472

Epoch: 6| Step: 12
Training loss: 2.4508660479033986
Validation loss: 2.4955910349068793

Epoch: 6| Step: 13
Training loss: 2.720010048903808
Validation loss: 2.49457630881786

Epoch: 194| Step: 0
Training loss: 2.486148608994615
Validation loss: 2.4970154112866187

Epoch: 6| Step: 1
Training loss: 1.7429218198715415
Validation loss: 2.487989575245126

Epoch: 6| Step: 2
Training loss: 3.134512347390711
Validation loss: 2.508698375305691

Epoch: 6| Step: 3
Training loss: 1.8520163450652687
Validation loss: 2.494180948344224

Epoch: 6| Step: 4
Training loss: 2.248450169318838
Validation loss: 2.507123858535506

Epoch: 6| Step: 5
Training loss: 2.653062770729273
Validation loss: 2.5038099265453657

Epoch: 6| Step: 6
Training loss: 2.2586515247050594
Validation loss: 2.507535719130609

Epoch: 6| Step: 7
Training loss: 2.0099957541046085
Validation loss: 2.502628788081006

Epoch: 6| Step: 8
Training loss: 2.510534407728788
Validation loss: 2.483901436573836

Epoch: 6| Step: 9
Training loss: 2.3204197714313275
Validation loss: 2.4927635045421437

Epoch: 6| Step: 10
Training loss: 1.9760386862268997
Validation loss: 2.4952658174145483

Epoch: 6| Step: 11
Training loss: 2.189254384204482
Validation loss: 2.502286294735461

Epoch: 6| Step: 12
Training loss: 2.902172057873795
Validation loss: 2.5024469718561075

Epoch: 6| Step: 13
Training loss: 2.422422088850391
Validation loss: 2.504757312508503

Epoch: 195| Step: 0
Training loss: 2.8787555215163954
Validation loss: 2.511925166276841

Epoch: 6| Step: 1
Training loss: 2.5572366391313155
Validation loss: 2.509382522970778

Epoch: 6| Step: 2
Training loss: 2.380123234291157
Validation loss: 2.51994141386948

Epoch: 6| Step: 3
Training loss: 1.9819855007715255
Validation loss: 2.509624092277323

Epoch: 6| Step: 4
Training loss: 2.374278711915572
Validation loss: 2.508241832580825

Epoch: 6| Step: 5
Training loss: 1.913711204210321
Validation loss: 2.4922158649229518

Epoch: 6| Step: 6
Training loss: 1.8567482481907513
Validation loss: 2.4709439649039413

Epoch: 6| Step: 7
Training loss: 2.511763553012153
Validation loss: 2.4839524443569205

Epoch: 6| Step: 8
Training loss: 2.452966478413427
Validation loss: 2.5019476138830226

Epoch: 6| Step: 9
Training loss: 2.8785885515214216
Validation loss: 2.4819528380213334

Epoch: 6| Step: 10
Training loss: 2.4692623717340014
Validation loss: 2.488259419695292

Epoch: 6| Step: 11
Training loss: 2.306543256108015
Validation loss: 2.487749586890729

Epoch: 6| Step: 12
Training loss: 2.5545842794394704
Validation loss: 2.4845373712417125

Epoch: 6| Step: 13
Training loss: 2.0057319518923253
Validation loss: 2.4894668732754375

Epoch: 196| Step: 0
Training loss: 2.4412420843243146
Validation loss: 2.4891535469129162

Epoch: 6| Step: 1
Training loss: 1.8734061778602293
Validation loss: 2.508501506841211

Epoch: 6| Step: 2
Training loss: 2.414854246997264
Validation loss: 2.4965921381007123

Epoch: 6| Step: 3
Training loss: 2.5075061646649086
Validation loss: 2.510267044821514

Epoch: 6| Step: 4
Training loss: 2.4779666806768073
Validation loss: 2.5263988334129626

Epoch: 6| Step: 5
Training loss: 2.9446230620262743
Validation loss: 2.55802409501418

Epoch: 6| Step: 6
Training loss: 2.1172281521768883
Validation loss: 2.540971822554142

Epoch: 6| Step: 7
Training loss: 2.21415621734822
Validation loss: 2.5416763388861385

Epoch: 6| Step: 8
Training loss: 2.3595213181554597
Validation loss: 2.513683865431391

Epoch: 6| Step: 9
Training loss: 2.145243542056782
Validation loss: 2.53189662633138

Epoch: 6| Step: 10
Training loss: 2.0817133390612144
Validation loss: 2.504090380233942

Epoch: 6| Step: 11
Training loss: 2.805891538295184
Validation loss: 2.5019366472005893

Epoch: 6| Step: 12
Training loss: 2.222616346165305
Validation loss: 2.5093148268234433

Epoch: 6| Step: 13
Training loss: 2.552316107482027
Validation loss: 2.4970024576069374

Epoch: 197| Step: 0
Training loss: 2.6635493793955223
Validation loss: 2.4998993217541097

Epoch: 6| Step: 1
Training loss: 2.5726281955462453
Validation loss: 2.5026537876720787

Epoch: 6| Step: 2
Training loss: 1.95714028182273
Validation loss: 2.512849702427252

Epoch: 6| Step: 3
Training loss: 2.4562469831841267
Validation loss: 2.504949192805979

Epoch: 6| Step: 4
Training loss: 2.5702599980983845
Validation loss: 2.4999817847541976

Epoch: 6| Step: 5
Training loss: 2.054895658790992
Validation loss: 2.507700346184785

Epoch: 6| Step: 6
Training loss: 2.576247207662299
Validation loss: 2.5059836939803586

Epoch: 6| Step: 7
Training loss: 2.2876570100524445
Validation loss: 2.510904634043412

Epoch: 6| Step: 8
Training loss: 2.893033235898978
Validation loss: 2.511693753621893

Epoch: 6| Step: 9
Training loss: 2.0386046849332717
Validation loss: 2.5106191487521508

Epoch: 6| Step: 10
Training loss: 2.7197273514642033
Validation loss: 2.5029790771469456

Epoch: 6| Step: 11
Training loss: 2.524745731959431
Validation loss: 2.5378882563676193

Epoch: 6| Step: 12
Training loss: 2.4119229511082065
Validation loss: 2.5198700906177858

Epoch: 6| Step: 13
Training loss: 2.031515485580126
Validation loss: 2.499792869252419

Epoch: 198| Step: 0
Training loss: 2.080078010379985
Validation loss: 2.5204011741090984

Epoch: 6| Step: 1
Training loss: 2.241814240014314
Validation loss: 2.5177820407703773

Epoch: 6| Step: 2
Training loss: 1.8417743507537068
Validation loss: 2.5213317115717286

Epoch: 6| Step: 3
Training loss: 2.5773769333742114
Validation loss: 2.5241538370519425

Epoch: 6| Step: 4
Training loss: 2.66279424196629
Validation loss: 2.4885593101245402

Epoch: 6| Step: 5
Training loss: 3.2061277131970396
Validation loss: 2.4901746954654325

Epoch: 6| Step: 6
Training loss: 2.407173673037134
Validation loss: 2.4929719844212554

Epoch: 6| Step: 7
Training loss: 3.021292149569743
Validation loss: 2.4917588617710664

Epoch: 6| Step: 8
Training loss: 2.155172216875791
Validation loss: 2.4939264590390984

Epoch: 6| Step: 9
Training loss: 2.482239483151271
Validation loss: 2.5008224406053343

Epoch: 6| Step: 10
Training loss: 1.7974456544388235
Validation loss: 2.488068847533674

Epoch: 6| Step: 11
Training loss: 2.604712151935353
Validation loss: 2.502181595379703

Epoch: 6| Step: 12
Training loss: 2.4650062471198413
Validation loss: 2.4926437390815197

Epoch: 6| Step: 13
Training loss: 2.2259160759829504
Validation loss: 2.490582051658711

Epoch: 199| Step: 0
Training loss: 1.9146814085283066
Validation loss: 2.511659565134858

Epoch: 6| Step: 1
Training loss: 2.2327251612117003
Validation loss: 2.5186144203063416

Epoch: 6| Step: 2
Training loss: 2.2354661104743014
Validation loss: 2.5288378599714623

Epoch: 6| Step: 3
Training loss: 2.201185305942831
Validation loss: 2.520237305747858

Epoch: 6| Step: 4
Training loss: 2.3184708501790317
Validation loss: 2.506685045112372

Epoch: 6| Step: 5
Training loss: 2.9342276019206563
Validation loss: 2.5254005221482476

Epoch: 6| Step: 6
Training loss: 2.3527370827178093
Validation loss: 2.5289399866103324

Epoch: 6| Step: 7
Training loss: 2.4387249925075216
Validation loss: 2.5083435225253403

Epoch: 6| Step: 8
Training loss: 2.038959135161467
Validation loss: 2.521162111474386

Epoch: 6| Step: 9
Training loss: 2.3080021185642083
Validation loss: 2.500365119338754

Epoch: 6| Step: 10
Training loss: 2.604375012010758
Validation loss: 2.501030423479231

Epoch: 6| Step: 11
Training loss: 1.7946312869416787
Validation loss: 2.4899525521569483

Epoch: 6| Step: 12
Training loss: 3.0512166707720167
Validation loss: 2.4938872947280823

Epoch: 6| Step: 13
Training loss: 2.4234641491170574
Validation loss: 2.493346085498791

Epoch: 200| Step: 0
Training loss: 1.6396416032931573
Validation loss: 2.494401305259174

Epoch: 6| Step: 1
Training loss: 2.6355111528629953
Validation loss: 2.5005852491083904

Epoch: 6| Step: 2
Training loss: 2.153740791216982
Validation loss: 2.506400688378769

Epoch: 6| Step: 3
Training loss: 1.5908279559266194
Validation loss: 2.4932855640474543

Epoch: 6| Step: 4
Training loss: 3.2745641986252108
Validation loss: 2.4804120395215032

Epoch: 6| Step: 5
Training loss: 2.2665986172428085
Validation loss: 2.5057965154536266

Epoch: 6| Step: 6
Training loss: 2.4499789918271313
Validation loss: 2.4976520479827364

Epoch: 6| Step: 7
Training loss: 2.5648446870000954
Validation loss: 2.4996879382871695

Epoch: 6| Step: 8
Training loss: 2.6916973250053426
Validation loss: 2.5065260743812217

Epoch: 6| Step: 9
Training loss: 2.4160471045278915
Validation loss: 2.5153639284749096

Epoch: 6| Step: 10
Training loss: 2.023525869435551
Validation loss: 2.525749037529633

Epoch: 6| Step: 11
Training loss: 2.4347221978982985
Validation loss: 2.5214102271475483

Epoch: 6| Step: 12
Training loss: 2.3749016189276055
Validation loss: 2.53315699135079

Epoch: 6| Step: 13
Training loss: 2.1257503531109245
Validation loss: 2.537600474881781

Epoch: 201| Step: 0
Training loss: 2.0446002929597733
Validation loss: 2.515045897050495

Epoch: 6| Step: 1
Training loss: 2.5304803502334257
Validation loss: 2.534173337013358

Epoch: 6| Step: 2
Training loss: 2.60772205010789
Validation loss: 2.5370573293483347

Epoch: 6| Step: 3
Training loss: 2.723402055256924
Validation loss: 2.524810708696523

Epoch: 6| Step: 4
Training loss: 2.8312957018938345
Validation loss: 2.5122687813819224

Epoch: 6| Step: 5
Training loss: 2.6730322757574796
Validation loss: 2.512132245758824

Epoch: 6| Step: 6
Training loss: 2.246095342220903
Validation loss: 2.517713702417998

Epoch: 6| Step: 7
Training loss: 2.772595602851798
Validation loss: 2.5176877554538004

Epoch: 6| Step: 8
Training loss: 2.4188203313493792
Validation loss: 2.505392465678086

Epoch: 6| Step: 9
Training loss: 1.785517349282791
Validation loss: 2.5070388567175

Epoch: 6| Step: 10
Training loss: 2.3628714213991717
Validation loss: 2.5089377219015976

Epoch: 6| Step: 11
Training loss: 1.474500316098536
Validation loss: 2.4965668470225713

Epoch: 6| Step: 12
Training loss: 1.9906570839205178
Validation loss: 2.5135224205784215

Epoch: 6| Step: 13
Training loss: 2.370967553691007
Validation loss: 2.519153261047021

Epoch: 202| Step: 0
Training loss: 2.1152607501385403
Validation loss: 2.525898696681282

Epoch: 6| Step: 1
Training loss: 2.9146407221028854
Validation loss: 2.524460694345352

Epoch: 6| Step: 2
Training loss: 2.7929268360327457
Validation loss: 2.5265907136611427

Epoch: 6| Step: 3
Training loss: 2.129964974701939
Validation loss: 2.5014979801915787

Epoch: 6| Step: 4
Training loss: 1.720185460693206
Validation loss: 2.5061918827462732

Epoch: 6| Step: 5
Training loss: 2.195012408071566
Validation loss: 2.485557962277268

Epoch: 6| Step: 6
Training loss: 3.2020519413068023
Validation loss: 2.484150514517092

Epoch: 6| Step: 7
Training loss: 2.2580914704520327
Validation loss: 2.505023137872148

Epoch: 6| Step: 8
Training loss: 2.2169031327782616
Validation loss: 2.507219777320064

Epoch: 6| Step: 9
Training loss: 1.8965925506006225
Validation loss: 2.521790312298744

Epoch: 6| Step: 10
Training loss: 2.4094064990011956
Validation loss: 2.4995350564308194

Epoch: 6| Step: 11
Training loss: 2.823059688384379
Validation loss: 2.5182997421794693

Epoch: 6| Step: 12
Training loss: 1.8443796408170552
Validation loss: 2.528351006702806

Epoch: 6| Step: 13
Training loss: 2.2148413817916133
Validation loss: 2.5368249903640847

Epoch: 203| Step: 0
Training loss: 2.6399157773657236
Validation loss: 2.519213452861122

Epoch: 6| Step: 1
Training loss: 2.137315405297878
Validation loss: 2.530116341495482

Epoch: 6| Step: 2
Training loss: 2.233748127958413
Validation loss: 2.5557824917481424

Epoch: 6| Step: 3
Training loss: 2.633309156170045
Validation loss: 2.5567556053749945

Epoch: 6| Step: 4
Training loss: 3.000433254746141
Validation loss: 2.53856155540075

Epoch: 6| Step: 5
Training loss: 2.2439702087981543
Validation loss: 2.5465229469791897

Epoch: 6| Step: 6
Training loss: 2.6423738545865048
Validation loss: 2.52678040913579

Epoch: 6| Step: 7
Training loss: 1.8866328186305845
Validation loss: 2.5187942570410105

Epoch: 6| Step: 8
Training loss: 2.568195804855548
Validation loss: 2.515714039618798

Epoch: 6| Step: 9
Training loss: 1.938679612909263
Validation loss: 2.5124741877151973

Epoch: 6| Step: 10
Training loss: 2.215022650058233
Validation loss: 2.5137475315298756

Epoch: 6| Step: 11
Training loss: 1.7053109236212391
Validation loss: 2.5113246009269097

Epoch: 6| Step: 12
Training loss: 1.7164747263567015
Validation loss: 2.5014670359154945

Epoch: 6| Step: 13
Training loss: 2.758088441179005
Validation loss: 2.5019702935603774

Epoch: 204| Step: 0
Training loss: 2.585452123537674
Validation loss: 2.491975111566133

Epoch: 6| Step: 1
Training loss: 1.953076049191265
Validation loss: 2.4920498960448274

Epoch: 6| Step: 2
Training loss: 2.3893070951487125
Validation loss: 2.5003367197250883

Epoch: 6| Step: 3
Training loss: 2.7250897384006323
Validation loss: 2.505145214234711

Epoch: 6| Step: 4
Training loss: 1.9480072109237776
Validation loss: 2.521515057862431

Epoch: 6| Step: 5
Training loss: 2.648751569372111
Validation loss: 2.5154425513407097

Epoch: 6| Step: 6
Training loss: 2.509441666531057
Validation loss: 2.5058840807169838

Epoch: 6| Step: 7
Training loss: 1.8823936914668176
Validation loss: 2.494064819809007

Epoch: 6| Step: 8
Training loss: 2.8611174730479134
Validation loss: 2.504048264592862

Epoch: 6| Step: 9
Training loss: 1.4270705155216972
Validation loss: 2.517357508046579

Epoch: 6| Step: 10
Training loss: 3.150264389810482
Validation loss: 2.5066049427522374

Epoch: 6| Step: 11
Training loss: 2.4347356134967497
Validation loss: 2.53351475218714

Epoch: 6| Step: 12
Training loss: 1.7675338823882911
Validation loss: 2.5303330428536595

Epoch: 6| Step: 13
Training loss: 2.0954494127208063
Validation loss: 2.5380127443565277

Epoch: 205| Step: 0
Training loss: 2.51385170175529
Validation loss: 2.5412174020613203

Epoch: 6| Step: 1
Training loss: 2.129262239982429
Validation loss: 2.540549022106241

Epoch: 6| Step: 2
Training loss: 2.1011472383931658
Validation loss: 2.514325408433851

Epoch: 6| Step: 3
Training loss: 3.0715813963119913
Validation loss: 2.538142799678869

Epoch: 6| Step: 4
Training loss: 2.5804602941316195
Validation loss: 2.535425125856061

Epoch: 6| Step: 5
Training loss: 2.536330881121683
Validation loss: 2.503479332516244

Epoch: 6| Step: 6
Training loss: 2.517033721564565
Validation loss: 2.5151170174265194

Epoch: 6| Step: 7
Training loss: 2.276359332253982
Validation loss: 2.529278493689241

Epoch: 6| Step: 8
Training loss: 2.4925601883855504
Validation loss: 2.5123217201560046

Epoch: 6| Step: 9
Training loss: 2.0782182715573017
Validation loss: 2.499079439430884

Epoch: 6| Step: 10
Training loss: 1.9795537335877946
Validation loss: 2.498925661671435

Epoch: 6| Step: 11
Training loss: 2.5335066355438998
Validation loss: 2.4938105895315212

Epoch: 6| Step: 12
Training loss: 2.1072888266040963
Validation loss: 2.493196161733156

Epoch: 6| Step: 13
Training loss: 1.9673781686601353
Validation loss: 2.5025585116146174

Epoch: 206| Step: 0
Training loss: 2.6118722261777867
Validation loss: 2.4924515571337813

Epoch: 6| Step: 1
Training loss: 2.7316827217392095
Validation loss: 2.505531121050475

Epoch: 6| Step: 2
Training loss: 2.6021112086745197
Validation loss: 2.5109664082915413

Epoch: 6| Step: 3
Training loss: 2.2192734651535773
Validation loss: 2.508786195659571

Epoch: 6| Step: 4
Training loss: 1.3869216555586446
Validation loss: 2.513955409280456

Epoch: 6| Step: 5
Training loss: 2.9015435287520956
Validation loss: 2.501445956099597

Epoch: 6| Step: 6
Training loss: 2.0878024675904467
Validation loss: 2.512237226368383

Epoch: 6| Step: 7
Training loss: 2.1168377013703417
Validation loss: 2.5058741064870063

Epoch: 6| Step: 8
Training loss: 2.2349045132714647
Validation loss: 2.5018930738172522

Epoch: 6| Step: 9
Training loss: 2.277244500276175
Validation loss: 2.54412709158405

Epoch: 6| Step: 10
Training loss: 2.2110623705213404
Validation loss: 2.5406915691142613

Epoch: 6| Step: 11
Training loss: 2.012578984007862
Validation loss: 2.58258831653576

Epoch: 6| Step: 12
Training loss: 3.1254021957978537
Validation loss: 2.563775946679415

Epoch: 6| Step: 13
Training loss: 2.462451287576866
Validation loss: 2.511398698459223

Epoch: 207| Step: 0
Training loss: 1.9657386273895998
Validation loss: 2.516062838596993

Epoch: 6| Step: 1
Training loss: 2.3597789696459914
Validation loss: 2.4891831357002654

Epoch: 6| Step: 2
Training loss: 2.175342673130933
Validation loss: 2.4939927246723856

Epoch: 6| Step: 3
Training loss: 2.2194376135211598
Validation loss: 2.4939553777755634

Epoch: 6| Step: 4
Training loss: 2.154807230034371
Validation loss: 2.5007983045742286

Epoch: 6| Step: 5
Training loss: 1.9822602304788064
Validation loss: 2.5032869665200725

Epoch: 6| Step: 6
Training loss: 2.916111775248368
Validation loss: 2.502230428098199

Epoch: 6| Step: 7
Training loss: 3.0309647888031224
Validation loss: 2.4936538894476232

Epoch: 6| Step: 8
Training loss: 2.589780688776695
Validation loss: 2.4969264448879396

Epoch: 6| Step: 9
Training loss: 2.596614313181389
Validation loss: 2.4927500186617033

Epoch: 6| Step: 10
Training loss: 2.122684339015245
Validation loss: 2.4996920872849

Epoch: 6| Step: 11
Training loss: 2.5522742582773765
Validation loss: 2.5192855833477608

Epoch: 6| Step: 12
Training loss: 2.543974927850649
Validation loss: 2.500880269206845

Epoch: 6| Step: 13
Training loss: 2.4083421207606452
Validation loss: 2.5010765300981

Epoch: 208| Step: 0
Training loss: 3.0354625886067272
Validation loss: 2.4905126957161645

Epoch: 6| Step: 1
Training loss: 2.4810125280553654
Validation loss: 2.4968357087864517

Epoch: 6| Step: 2
Training loss: 2.3785598577858647
Validation loss: 2.487453832149983

Epoch: 6| Step: 3
Training loss: 2.153942587417631
Validation loss: 2.4784530178827295

Epoch: 6| Step: 4
Training loss: 2.308240731191685
Validation loss: 2.47418998570651

Epoch: 6| Step: 5
Training loss: 2.634274040269592
Validation loss: 2.474073681735623

Epoch: 6| Step: 6
Training loss: 1.6412109781755766
Validation loss: 2.473795398901477

Epoch: 6| Step: 7
Training loss: 2.278296034348784
Validation loss: 2.4610402484414906

Epoch: 6| Step: 8
Training loss: 2.3953672757389737
Validation loss: 2.4881879548489083

Epoch: 6| Step: 9
Training loss: 2.121354622719467
Validation loss: 2.484175300169382

Epoch: 6| Step: 10
Training loss: 2.152121087549693
Validation loss: 2.4800504236581404

Epoch: 6| Step: 11
Training loss: 2.3897391279851026
Validation loss: 2.4983155774873973

Epoch: 6| Step: 12
Training loss: 2.3339707888922043
Validation loss: 2.499508332542515

Epoch: 6| Step: 13
Training loss: 2.6785603368620334
Validation loss: 2.4826620022306183

Epoch: 209| Step: 0
Training loss: 2.379802265768674
Validation loss: 2.495684570778507

Epoch: 6| Step: 1
Training loss: 2.5042730053894804
Validation loss: 2.4874127128276817

Epoch: 6| Step: 2
Training loss: 3.042061470920482
Validation loss: 2.492638653744272

Epoch: 6| Step: 3
Training loss: 2.006198100431827
Validation loss: 2.4852238450525745

Epoch: 6| Step: 4
Training loss: 1.409494810234873
Validation loss: 2.500428202832963

Epoch: 6| Step: 5
Training loss: 2.303279847693982
Validation loss: 2.500776535867119

Epoch: 6| Step: 6
Training loss: 1.78136704712837
Validation loss: 2.485556331610337

Epoch: 6| Step: 7
Training loss: 2.4630296321546905
Validation loss: 2.5024118392562236

Epoch: 6| Step: 8
Training loss: 2.8005352258031597
Validation loss: 2.496599013919071

Epoch: 6| Step: 9
Training loss: 2.526000808437819
Validation loss: 2.498283941668409

Epoch: 6| Step: 10
Training loss: 2.720598403656944
Validation loss: 2.518798989828423

Epoch: 6| Step: 11
Training loss: 2.316491162446898
Validation loss: 2.5197368528079434

Epoch: 6| Step: 12
Training loss: 2.3905512979154175
Validation loss: 2.5192854256187944

Epoch: 6| Step: 13
Training loss: 2.1751629209337358
Validation loss: 2.5251294773255295

Epoch: 210| Step: 0
Training loss: 2.050546977876338
Validation loss: 2.512754472969377

Epoch: 6| Step: 1
Training loss: 2.282051886099887
Validation loss: 2.5064600291286165

Epoch: 6| Step: 2
Training loss: 1.7779374357228797
Validation loss: 2.5007423570256755

Epoch: 6| Step: 3
Training loss: 2.6044779070193425
Validation loss: 2.5106463241526233

Epoch: 6| Step: 4
Training loss: 2.373010504801021
Validation loss: 2.5071935632644973

Epoch: 6| Step: 5
Training loss: 2.4726165237971864
Validation loss: 2.5044128096001432

Epoch: 6| Step: 6
Training loss: 2.571568144688824
Validation loss: 2.4977060601982455

Epoch: 6| Step: 7
Training loss: 2.664610238693759
Validation loss: 2.5007508421930824

Epoch: 6| Step: 8
Training loss: 2.2682219255917953
Validation loss: 2.4830496909794473

Epoch: 6| Step: 9
Training loss: 1.6087966916911949
Validation loss: 2.495525217753172

Epoch: 6| Step: 10
Training loss: 2.6485874729960903
Validation loss: 2.5073110806059957

Epoch: 6| Step: 11
Training loss: 1.7771451398946971
Validation loss: 2.5096000250621677

Epoch: 6| Step: 12
Training loss: 2.976169990832354
Validation loss: 2.5098312032916716

Epoch: 6| Step: 13
Training loss: 2.2964306875209384
Validation loss: 2.539452625527514

Epoch: 211| Step: 0
Training loss: 2.9754064522705765
Validation loss: 2.5518374629533427

Epoch: 6| Step: 1
Training loss: 1.728327336805211
Validation loss: 2.5438048848097634

Epoch: 6| Step: 2
Training loss: 2.296895033560858
Validation loss: 2.5326446254790658

Epoch: 6| Step: 3
Training loss: 2.7969558959855148
Validation loss: 2.524598483463942

Epoch: 6| Step: 4
Training loss: 1.7949821785809852
Validation loss: 2.5224399858688367

Epoch: 6| Step: 5
Training loss: 1.9720115287900286
Validation loss: 2.506210441308868

Epoch: 6| Step: 6
Training loss: 2.2423304070312375
Validation loss: 2.5015171533779665

Epoch: 6| Step: 7
Training loss: 3.126083948971631
Validation loss: 2.5151921407312696

Epoch: 6| Step: 8
Training loss: 2.0688923121249982
Validation loss: 2.5150614989935103

Epoch: 6| Step: 9
Training loss: 2.7004494187057606
Validation loss: 2.5016544748458602

Epoch: 6| Step: 10
Training loss: 1.9186032987795494
Validation loss: 2.5049234070936945

Epoch: 6| Step: 11
Training loss: 2.611224586870806
Validation loss: 2.506001976595924

Epoch: 6| Step: 12
Training loss: 2.176201880732094
Validation loss: 2.5192762300029874

Epoch: 6| Step: 13
Training loss: 2.303414410196063
Validation loss: 2.519748364933701

Epoch: 212| Step: 0
Training loss: 2.2447827568378926
Validation loss: 2.5049799275054077

Epoch: 6| Step: 1
Training loss: 2.17259917775802
Validation loss: 2.5156732716480183

Epoch: 6| Step: 2
Training loss: 2.1016798022124665
Validation loss: 2.5048634905748446

Epoch: 6| Step: 3
Training loss: 2.6772704498168283
Validation loss: 2.5204367259959426

Epoch: 6| Step: 4
Training loss: 2.1756116160589563
Validation loss: 2.516355530872068

Epoch: 6| Step: 5
Training loss: 2.5243834620969325
Validation loss: 2.540341177551802

Epoch: 6| Step: 6
Training loss: 2.3908483862134324
Validation loss: 2.5183688693397417

Epoch: 6| Step: 7
Training loss: 2.1705199480983293
Validation loss: 2.5073713506808373

Epoch: 6| Step: 8
Training loss: 2.3563751956453345
Validation loss: 2.548607281974482

Epoch: 6| Step: 9
Training loss: 2.017834539081888
Validation loss: 2.541300392858378

Epoch: 6| Step: 10
Training loss: 2.022066926174963
Validation loss: 2.5455983088300913

Epoch: 6| Step: 11
Training loss: 2.905243073633346
Validation loss: 2.5567322771174235

Epoch: 6| Step: 12
Training loss: 1.5977598124098176
Validation loss: 2.557862730160275

Epoch: 6| Step: 13
Training loss: 2.747181054468874
Validation loss: 2.5452474062413404

Epoch: 213| Step: 0
Training loss: 3.1192017742127476
Validation loss: 2.5658552022383803

Epoch: 6| Step: 1
Training loss: 2.217152087282988
Validation loss: 2.53072298317014

Epoch: 6| Step: 2
Training loss: 1.7338178272360052
Validation loss: 2.5094727737425346

Epoch: 6| Step: 3
Training loss: 2.4474749768607684
Validation loss: 2.5250975322456575

Epoch: 6| Step: 4
Training loss: 2.7110551704131596
Validation loss: 2.5267216321113217

Epoch: 6| Step: 5
Training loss: 2.5718296756203767
Validation loss: 2.5062034095245167

Epoch: 6| Step: 6
Training loss: 1.758999029882531
Validation loss: 2.5091446678576514

Epoch: 6| Step: 7
Training loss: 1.695540733619813
Validation loss: 2.499860982208623

Epoch: 6| Step: 8
Training loss: 2.661854564537252
Validation loss: 2.500275525169044

Epoch: 6| Step: 9
Training loss: 2.822345962172974
Validation loss: 2.5070991808852336

Epoch: 6| Step: 10
Training loss: 2.235932134359281
Validation loss: 2.5096708168498423

Epoch: 6| Step: 11
Training loss: 2.2995561793482584
Validation loss: 2.5157270391079125

Epoch: 6| Step: 12
Training loss: 2.359834739911849
Validation loss: 2.518965152357593

Epoch: 6| Step: 13
Training loss: 2.585812568527906
Validation loss: 2.5152968198534187

Epoch: 214| Step: 0
Training loss: 1.7676297849408704
Validation loss: 2.519398010042838

Epoch: 6| Step: 1
Training loss: 2.7505494349145394
Validation loss: 2.5150010182130242

Epoch: 6| Step: 2
Training loss: 1.392887033064955
Validation loss: 2.506880859479743

Epoch: 6| Step: 3
Training loss: 3.3602115033202744
Validation loss: 2.517911184143868

Epoch: 6| Step: 4
Training loss: 2.117645326781967
Validation loss: 2.527275780260551

Epoch: 6| Step: 5
Training loss: 2.051742008952702
Validation loss: 2.488967281930117

Epoch: 6| Step: 6
Training loss: 2.4515749170634393
Validation loss: 2.516361057807751

Epoch: 6| Step: 7
Training loss: 2.3818181198723685
Validation loss: 2.5165656248444552

Epoch: 6| Step: 8
Training loss: 2.584759677363
Validation loss: 2.5143122594611795

Epoch: 6| Step: 9
Training loss: 2.6685060376189593
Validation loss: 2.5034206036451576

Epoch: 6| Step: 10
Training loss: 2.670607238181961
Validation loss: 2.5005462288171114

Epoch: 6| Step: 11
Training loss: 2.195717553615753
Validation loss: 2.4934220878423403

Epoch: 6| Step: 12
Training loss: 2.1233240137938703
Validation loss: 2.507843556117738

Epoch: 6| Step: 13
Training loss: 2.26639854116881
Validation loss: 2.50072458416131

Epoch: 215| Step: 0
Training loss: 1.6773689769167965
Validation loss: 2.509168185163191

Epoch: 6| Step: 1
Training loss: 2.369632981126081
Validation loss: 2.504459298205544

Epoch: 6| Step: 2
Training loss: 1.948137797759398
Validation loss: 2.4952064493216852

Epoch: 6| Step: 3
Training loss: 2.562191083942563
Validation loss: 2.4983934644707464

Epoch: 6| Step: 4
Training loss: 2.3120954004952328
Validation loss: 2.499161579686154

Epoch: 6| Step: 5
Training loss: 2.442281971847433
Validation loss: 2.5040213190974936

Epoch: 6| Step: 6
Training loss: 2.9400377066134022
Validation loss: 2.515310074264008

Epoch: 6| Step: 7
Training loss: 2.899647421614865
Validation loss: 2.501222216343643

Epoch: 6| Step: 8
Training loss: 2.578128699097725
Validation loss: 2.5217671727003914

Epoch: 6| Step: 9
Training loss: 1.7940754186540218
Validation loss: 2.5234809454454306

Epoch: 6| Step: 10
Training loss: 2.9929851534520147
Validation loss: 2.512589275614934

Epoch: 6| Step: 11
Training loss: 1.7118734647612357
Validation loss: 2.5100754839728823

Epoch: 6| Step: 12
Training loss: 1.7338121892863412
Validation loss: 2.531711928678946

Epoch: 6| Step: 13
Training loss: 2.070720819477903
Validation loss: 2.5192553465244094

Epoch: 216| Step: 0
Training loss: 2.2123800902551363
Validation loss: 2.547364053402521

Epoch: 6| Step: 1
Training loss: 1.8164787031920828
Validation loss: 2.5276721896195453

Epoch: 6| Step: 2
Training loss: 2.347373297931394
Validation loss: 2.5267948928427524

Epoch: 6| Step: 3
Training loss: 2.172638573655227
Validation loss: 2.5140240710766877

Epoch: 6| Step: 4
Training loss: 3.09745966899684
Validation loss: 2.51595457457314

Epoch: 6| Step: 5
Training loss: 2.2053865769442482
Validation loss: 2.5113086988653355

Epoch: 6| Step: 6
Training loss: 2.3332963895143712
Validation loss: 2.519115151440045

Epoch: 6| Step: 7
Training loss: 2.5351223936009695
Validation loss: 2.50248556554025

Epoch: 6| Step: 8
Training loss: 2.830001292952926
Validation loss: 2.5077885500832826

Epoch: 6| Step: 9
Training loss: 2.3685792161878254
Validation loss: 2.486211629667044

Epoch: 6| Step: 10
Training loss: 2.2929685420437513
Validation loss: 2.5323270382300995

Epoch: 6| Step: 11
Training loss: 2.238458596438623
Validation loss: 2.5024054399092197

Epoch: 6| Step: 12
Training loss: 2.4868965068614823
Validation loss: 2.529507252941854

Epoch: 6| Step: 13
Training loss: 1.2368250807779102
Validation loss: 2.5090594177569243

Epoch: 217| Step: 0
Training loss: 1.8145161957552771
Validation loss: 2.527615256959544

Epoch: 6| Step: 1
Training loss: 2.235144316005748
Validation loss: 2.514669232822591

Epoch: 6| Step: 2
Training loss: 2.684566760069494
Validation loss: 2.50448538221918

Epoch: 6| Step: 3
Training loss: 1.5498696057016328
Validation loss: 2.5153583282594085

Epoch: 6| Step: 4
Training loss: 2.488890760379421
Validation loss: 2.5000891987464446

Epoch: 6| Step: 5
Training loss: 2.587954745667899
Validation loss: 2.515438602089213

Epoch: 6| Step: 6
Training loss: 2.624604513257794
Validation loss: 2.5061229746552844

Epoch: 6| Step: 7
Training loss: 2.604096332871821
Validation loss: 2.5184968466179507

Epoch: 6| Step: 8
Training loss: 2.41423345164197
Validation loss: 2.5355206008793383

Epoch: 6| Step: 9
Training loss: 2.5130543339263705
Validation loss: 2.5256129317202585

Epoch: 6| Step: 10
Training loss: 2.3441308284352034
Validation loss: 2.5558793362694994

Epoch: 6| Step: 11
Training loss: 2.3846450512746857
Validation loss: 2.5860402681303953

Epoch: 6| Step: 12
Training loss: 2.5880093759605693
Validation loss: 2.5962417766971604

Epoch: 6| Step: 13
Training loss: 1.9760133485536249
Validation loss: 2.536410091706414

Epoch: 218| Step: 0
Training loss: 2.374364466712845
Validation loss: 2.5178075290804625

Epoch: 6| Step: 1
Training loss: 2.660957831833152
Validation loss: 2.511824507239441

Epoch: 6| Step: 2
Training loss: 2.348928605009242
Validation loss: 2.5237574891144123

Epoch: 6| Step: 3
Training loss: 2.419724721936351
Validation loss: 2.523530200558596

Epoch: 6| Step: 4
Training loss: 2.355286649683846
Validation loss: 2.5353785154365958

Epoch: 6| Step: 5
Training loss: 2.634205435548329
Validation loss: 2.5397509927668525

Epoch: 6| Step: 6
Training loss: 2.36410129916164
Validation loss: 2.5087986925256334

Epoch: 6| Step: 7
Training loss: 2.14918410766593
Validation loss: 2.503605721897474

Epoch: 6| Step: 8
Training loss: 2.11370360266568
Validation loss: 2.5030533741050696

Epoch: 6| Step: 9
Training loss: 2.0447910562113703
Validation loss: 2.511284426270733

Epoch: 6| Step: 10
Training loss: 2.22412457764203
Validation loss: 2.516431588336785

Epoch: 6| Step: 11
Training loss: 2.698053707535552
Validation loss: 2.511242257222274

Epoch: 6| Step: 12
Training loss: 2.6821898407110876
Validation loss: 2.5283396673364162

Epoch: 6| Step: 13
Training loss: 2.648450373165386
Validation loss: 2.52806278398973

Epoch: 219| Step: 0
Training loss: 2.4805963918930174
Validation loss: 2.5553672422834217

Epoch: 6| Step: 1
Training loss: 2.0933598396826083
Validation loss: 2.5572470345781544

Epoch: 6| Step: 2
Training loss: 1.5898007098846252
Validation loss: 2.5276734158231604

Epoch: 6| Step: 3
Training loss: 2.8580007116745314
Validation loss: 2.520175427633031

Epoch: 6| Step: 4
Training loss: 2.561105488265074
Validation loss: 2.5080335921674797

Epoch: 6| Step: 5
Training loss: 1.9960769085257601
Validation loss: 2.508509934081583

Epoch: 6| Step: 6
Training loss: 2.5569428453976295
Validation loss: 2.5111476155903207

Epoch: 6| Step: 7
Training loss: 2.1241082957186808
Validation loss: 2.5103443552157767

Epoch: 6| Step: 8
Training loss: 2.5549748343704595
Validation loss: 2.492445897465663

Epoch: 6| Step: 9
Training loss: 2.0452533150918706
Validation loss: 2.499671882713822

Epoch: 6| Step: 10
Training loss: 2.719248671125666
Validation loss: 2.5100581967115634

Epoch: 6| Step: 11
Training loss: 2.7437736944683135
Validation loss: 2.513184178764058

Epoch: 6| Step: 12
Training loss: 2.2312235982919666
Validation loss: 2.531112745668916

Epoch: 6| Step: 13
Training loss: 2.0189265926822113
Validation loss: 2.5369870198195557

Epoch: 220| Step: 0
Training loss: 1.9317209132589008
Validation loss: 2.536713061900527

Epoch: 6| Step: 1
Training loss: 2.666275671268857
Validation loss: 2.553836256833855

Epoch: 6| Step: 2
Training loss: 2.6813732661298153
Validation loss: 2.5438479043051356

Epoch: 6| Step: 3
Training loss: 2.0798797082962914
Validation loss: 2.5342290796306584

Epoch: 6| Step: 4
Training loss: 1.7303423350984368
Validation loss: 2.503179991360539

Epoch: 6| Step: 5
Training loss: 2.777554060086259
Validation loss: 2.5216600360350365

Epoch: 6| Step: 6
Training loss: 1.9352099513217114
Validation loss: 2.5249605100206414

Epoch: 6| Step: 7
Training loss: 2.278194733063935
Validation loss: 2.512747008800893

Epoch: 6| Step: 8
Training loss: 2.3624548610028255
Validation loss: 2.5287911517065984

Epoch: 6| Step: 9
Training loss: 2.64822143753625
Validation loss: 2.5382908670734987

Epoch: 6| Step: 10
Training loss: 2.265621422074222
Validation loss: 2.5251021902726194

Epoch: 6| Step: 11
Training loss: 2.50790129412264
Validation loss: 2.523861513840473

Epoch: 6| Step: 12
Training loss: 2.8769551139249745
Validation loss: 2.5224055019405767

Epoch: 6| Step: 13
Training loss: 2.250929322646928
Validation loss: 2.5133038824246396

Epoch: 221| Step: 0
Training loss: 1.8836536981764802
Validation loss: 2.509928965912217

Epoch: 6| Step: 1
Training loss: 1.8322311324861726
Validation loss: 2.5176211664916783

Epoch: 6| Step: 2
Training loss: 2.6536267061202428
Validation loss: 2.5233078284551502

Epoch: 6| Step: 3
Training loss: 2.3458556825195425
Validation loss: 2.5319426103107365

Epoch: 6| Step: 4
Training loss: 2.387799956168077
Validation loss: 2.545429264057621

Epoch: 6| Step: 5
Training loss: 2.689650096896954
Validation loss: 2.538902661109742

Epoch: 6| Step: 6
Training loss: 2.655826130875093
Validation loss: 2.571097527525051

Epoch: 6| Step: 7
Training loss: 1.6636715281930183
Validation loss: 2.598464358266089

Epoch: 6| Step: 8
Training loss: 2.293425064562589
Validation loss: 2.5818124313856226

Epoch: 6| Step: 9
Training loss: 1.768661992879406
Validation loss: 2.568132475099928

Epoch: 6| Step: 10
Training loss: 2.4523274285343595
Validation loss: 2.5287810321235678

Epoch: 6| Step: 11
Training loss: 2.5821843412089818
Validation loss: 2.5185439114625434

Epoch: 6| Step: 12
Training loss: 2.5794594749998505
Validation loss: 2.5113266262568765

Epoch: 6| Step: 13
Training loss: 2.3005689124680453
Validation loss: 2.5129946508015437

Epoch: 222| Step: 0
Training loss: 1.8157695351618215
Validation loss: 2.5046567620294877

Epoch: 6| Step: 1
Training loss: 2.2102522040715233
Validation loss: 2.5156169046149306

Epoch: 6| Step: 2
Training loss: 2.8400029238833566
Validation loss: 2.527985025184478

Epoch: 6| Step: 3
Training loss: 2.8872647936917044
Validation loss: 2.5256709872279277

Epoch: 6| Step: 4
Training loss: 2.896102581725895
Validation loss: 2.537331892185868

Epoch: 6| Step: 5
Training loss: 1.6221896592156875
Validation loss: 2.52560190259628

Epoch: 6| Step: 6
Training loss: 2.497656009448544
Validation loss: 2.538645266950929

Epoch: 6| Step: 7
Training loss: 2.1617797490024326
Validation loss: 2.523159031418386

Epoch: 6| Step: 8
Training loss: 2.5553567458879165
Validation loss: 2.511262550670755

Epoch: 6| Step: 9
Training loss: 2.4361500058270456
Validation loss: 2.5143892321277455

Epoch: 6| Step: 10
Training loss: 1.8503059598152891
Validation loss: 2.5089580894224506

Epoch: 6| Step: 11
Training loss: 2.75083529184436
Validation loss: 2.513221975126966

Epoch: 6| Step: 12
Training loss: 2.2093352318277684
Validation loss: 2.49943367583545

Epoch: 6| Step: 13
Training loss: 2.3859006787689623
Validation loss: 2.5022086162683754

Epoch: 223| Step: 0
Training loss: 2.577076554244512
Validation loss: 2.5191538289010436

Epoch: 6| Step: 1
Training loss: 1.7788997336742818
Validation loss: 2.5378145564753276

Epoch: 6| Step: 2
Training loss: 2.2390842561802837
Validation loss: 2.601854256431109

Epoch: 6| Step: 3
Training loss: 2.5334365254851186
Validation loss: 2.592624067564545

Epoch: 6| Step: 4
Training loss: 2.7260176761918924
Validation loss: 2.644551354561458

Epoch: 6| Step: 5
Training loss: 2.0420248794310347
Validation loss: 2.607823411215112

Epoch: 6| Step: 6
Training loss: 2.1467118424742386
Validation loss: 2.612356055399356

Epoch: 6| Step: 7
Training loss: 2.3085643166151932
Validation loss: 2.5352824081277006

Epoch: 6| Step: 8
Training loss: 2.198438705953716
Validation loss: 2.5382110185222646

Epoch: 6| Step: 9
Training loss: 2.2229062762698373
Validation loss: 2.4997144694987066

Epoch: 6| Step: 10
Training loss: 2.535944035980583
Validation loss: 2.504108668738434

Epoch: 6| Step: 11
Training loss: 2.4118588954588542
Validation loss: 2.5221688592151263

Epoch: 6| Step: 12
Training loss: 3.0381736730440747
Validation loss: 2.530245216533209

Epoch: 6| Step: 13
Training loss: 2.9779277083702516
Validation loss: 2.546921914883556

Epoch: 224| Step: 0
Training loss: 2.1557696263480395
Validation loss: 2.5299355975662796

Epoch: 6| Step: 1
Training loss: 2.215749081256465
Validation loss: 2.5481120656639358

Epoch: 6| Step: 2
Training loss: 2.7265595269391922
Validation loss: 2.556336923254582

Epoch: 6| Step: 3
Training loss: 2.4174325869292432
Validation loss: 2.5428381132839477

Epoch: 6| Step: 4
Training loss: 2.4516686654185382
Validation loss: 2.5223655352813226

Epoch: 6| Step: 5
Training loss: 2.4609971780958433
Validation loss: 2.5245204684215437

Epoch: 6| Step: 6
Training loss: 3.457704019547074
Validation loss: 2.520931767415041

Epoch: 6| Step: 7
Training loss: 2.270905858086214
Validation loss: 2.51505923968016

Epoch: 6| Step: 8
Training loss: 1.8487729978130434
Validation loss: 2.5193155989903047

Epoch: 6| Step: 9
Training loss: 1.8508907338870824
Validation loss: 2.5356044128249184

Epoch: 6| Step: 10
Training loss: 2.1076060471829337
Validation loss: 2.564505792267272

Epoch: 6| Step: 11
Training loss: 2.6265125458259946
Validation loss: 2.5799854540106804

Epoch: 6| Step: 12
Training loss: 2.9472282513472807
Validation loss: 2.59152800586682

Epoch: 6| Step: 13
Training loss: 2.381972368062471
Validation loss: 2.5526241949032924

Epoch: 225| Step: 0
Training loss: 1.9150274841487696
Validation loss: 2.5455462650292526

Epoch: 6| Step: 1
Training loss: 1.7511168049839696
Validation loss: 2.510928395984147

Epoch: 6| Step: 2
Training loss: 2.2661042857469327
Validation loss: 2.5122223423873393

Epoch: 6| Step: 3
Training loss: 2.050823102251512
Validation loss: 2.5085997331235665

Epoch: 6| Step: 4
Training loss: 3.0330404126210198
Validation loss: 2.509067352172402

Epoch: 6| Step: 5
Training loss: 1.9869148040653106
Validation loss: 2.5130629198308845

Epoch: 6| Step: 6
Training loss: 2.922713052441868
Validation loss: 2.5209964878048226

Epoch: 6| Step: 7
Training loss: 2.180921417233875
Validation loss: 2.5327189386443907

Epoch: 6| Step: 8
Training loss: 2.46058579611075
Validation loss: 2.52873128215596

Epoch: 6| Step: 9
Training loss: 2.8758896819432276
Validation loss: 2.5153200110766742

Epoch: 6| Step: 10
Training loss: 2.718841463501689
Validation loss: 2.5270108962363147

Epoch: 6| Step: 11
Training loss: 2.339502784200676
Validation loss: 2.510007553215871

Epoch: 6| Step: 12
Training loss: 2.3596735885345437
Validation loss: 2.5253341994997425

Epoch: 6| Step: 13
Training loss: 1.6222568981102181
Validation loss: 2.50572713660094

Epoch: 226| Step: 0
Training loss: 2.425084503903775
Validation loss: 2.520607604542095

Epoch: 6| Step: 1
Training loss: 1.758224371235285
Validation loss: 2.514547824266518

Epoch: 6| Step: 2
Training loss: 1.3116706771175306
Validation loss: 2.498040178144325

Epoch: 6| Step: 3
Training loss: 2.1506516023657345
Validation loss: 2.517532999301624

Epoch: 6| Step: 4
Training loss: 2.0606968251126356
Validation loss: 2.507796543977707

Epoch: 6| Step: 5
Training loss: 3.0869268835248618
Validation loss: 2.509152142742298

Epoch: 6| Step: 6
Training loss: 2.225109710560255
Validation loss: 2.5245595352688963

Epoch: 6| Step: 7
Training loss: 2.2844052376683246
Validation loss: 2.511856067437735

Epoch: 6| Step: 8
Training loss: 2.457085395058715
Validation loss: 2.516165546920914

Epoch: 6| Step: 9
Training loss: 2.0963552407840482
Validation loss: 2.5187060362557854

Epoch: 6| Step: 10
Training loss: 2.834233047648656
Validation loss: 2.5159209178055435

Epoch: 6| Step: 11
Training loss: 2.3407403568622063
Validation loss: 2.5384731528191344

Epoch: 6| Step: 12
Training loss: 1.9779054203467763
Validation loss: 2.521021849043659

Epoch: 6| Step: 13
Training loss: 2.772547533403474
Validation loss: 2.526056479708836

Epoch: 227| Step: 0
Training loss: 2.7789842613408724
Validation loss: 2.5185830552376

Epoch: 6| Step: 1
Training loss: 2.0608972043717526
Validation loss: 2.549888481868096

Epoch: 6| Step: 2
Training loss: 1.9124791661542673
Validation loss: 2.533534130077593

Epoch: 6| Step: 3
Training loss: 2.6135403400618977
Validation loss: 2.5509022581286245

Epoch: 6| Step: 4
Training loss: 2.38991780510823
Validation loss: 2.562785830489799

Epoch: 6| Step: 5
Training loss: 2.8189444565783273
Validation loss: 2.5701812355047964

Epoch: 6| Step: 6
Training loss: 3.024621697092458
Validation loss: 2.529429899863659

Epoch: 6| Step: 7
Training loss: 2.5317113950326244
Validation loss: 2.5372980334956403

Epoch: 6| Step: 8
Training loss: 2.396232262169144
Validation loss: 2.518812706973703

Epoch: 6| Step: 9
Training loss: 1.978154683304701
Validation loss: 2.5208259508849777

Epoch: 6| Step: 10
Training loss: 1.895584411488415
Validation loss: 2.519336213835602

Epoch: 6| Step: 11
Training loss: 2.0128533284192653
Validation loss: 2.520628744813543

Epoch: 6| Step: 12
Training loss: 2.0101225510999754
Validation loss: 2.5265898407962877

Epoch: 6| Step: 13
Training loss: 1.8992137185472997
Validation loss: 2.4995661359058565

Epoch: 228| Step: 0
Training loss: 3.008553708388761
Validation loss: 2.4995524641639335

Epoch: 6| Step: 1
Training loss: 2.2349172081003332
Validation loss: 2.49139675562427

Epoch: 6| Step: 2
Training loss: 1.764313539900033
Validation loss: 2.4987156111803186

Epoch: 6| Step: 3
Training loss: 1.7518747369587075
Validation loss: 2.516006061764982

Epoch: 6| Step: 4
Training loss: 2.7060137180846215
Validation loss: 2.5090438022471933

Epoch: 6| Step: 5
Training loss: 1.6902534485550305
Validation loss: 2.511038854800983

Epoch: 6| Step: 6
Training loss: 2.314612789521712
Validation loss: 2.536386090659125

Epoch: 6| Step: 7
Training loss: 2.5856730622676416
Validation loss: 2.5330819302177576

Epoch: 6| Step: 8
Training loss: 1.9868107062272315
Validation loss: 2.549964536470135

Epoch: 6| Step: 9
Training loss: 2.762777813366959
Validation loss: 2.5105452656289415

Epoch: 6| Step: 10
Training loss: 2.45712129703834
Validation loss: 2.515274133954029

Epoch: 6| Step: 11
Training loss: 1.7967355425247558
Validation loss: 2.548878277788226

Epoch: 6| Step: 12
Training loss: 2.590221901007703
Validation loss: 2.5348183083865754

Epoch: 6| Step: 13
Training loss: 2.1825824504366613
Validation loss: 2.551508770057915

Epoch: 229| Step: 0
Training loss: 2.4909879374539363
Validation loss: 2.5392685087700646

Epoch: 6| Step: 1
Training loss: 1.9170714724872386
Validation loss: 2.584534609323716

Epoch: 6| Step: 2
Training loss: 2.3084940880759035
Validation loss: 2.564562548985201

Epoch: 6| Step: 3
Training loss: 2.1562369525901675
Validation loss: 2.5708150169507324

Epoch: 6| Step: 4
Training loss: 2.2895694731089473
Validation loss: 2.5692954171983784

Epoch: 6| Step: 5
Training loss: 2.60797575021949
Validation loss: 2.5657280539206835

Epoch: 6| Step: 6
Training loss: 2.2730633929265895
Validation loss: 2.513787508747453

Epoch: 6| Step: 7
Training loss: 1.6898296664246757
Validation loss: 2.5071550975247687

Epoch: 6| Step: 8
Training loss: 2.1919155786922473
Validation loss: 2.5205942912823995

Epoch: 6| Step: 9
Training loss: 2.3934002892241004
Validation loss: 2.5123940643195084

Epoch: 6| Step: 10
Training loss: 2.4446135183104607
Validation loss: 2.5154115732455367

Epoch: 6| Step: 11
Training loss: 2.8702848164194723
Validation loss: 2.5036947763123107

Epoch: 6| Step: 12
Training loss: 1.7494326761815733
Validation loss: 2.5224429632165046

Epoch: 6| Step: 13
Training loss: 2.6027799856239198
Validation loss: 2.497255877622925

Epoch: 230| Step: 0
Training loss: 2.511193014270196
Validation loss: 2.5138335868789627

Epoch: 6| Step: 1
Training loss: 1.970069564133311
Validation loss: 2.506266084462444

Epoch: 6| Step: 2
Training loss: 2.0723876917173327
Validation loss: 2.503861115951936

Epoch: 6| Step: 3
Training loss: 2.0993756683157754
Validation loss: 2.505239924008946

Epoch: 6| Step: 4
Training loss: 1.4821715212625604
Validation loss: 2.50746695890048

Epoch: 6| Step: 5
Training loss: 2.2202857706499923
Validation loss: 2.5150501866070063

Epoch: 6| Step: 6
Training loss: 2.8986026686008417
Validation loss: 2.500652148699977

Epoch: 6| Step: 7
Training loss: 1.7267567106773505
Validation loss: 2.5013115462535054

Epoch: 6| Step: 8
Training loss: 2.241380499781285
Validation loss: 2.506027965270884

Epoch: 6| Step: 9
Training loss: 3.106095160879251
Validation loss: 2.5048833994527007

Epoch: 6| Step: 10
Training loss: 2.481985514516311
Validation loss: 2.5083512532638577

Epoch: 6| Step: 11
Training loss: 2.651056305870502
Validation loss: 2.5015644344312027

Epoch: 6| Step: 12
Training loss: 2.7548899956426647
Validation loss: 2.51908265686615

Epoch: 6| Step: 13
Training loss: 2.145474808256333
Validation loss: 2.507957810799967

Epoch: 231| Step: 0
Training loss: 2.556365695564312
Validation loss: 2.484884677644175

Epoch: 6| Step: 1
Training loss: 1.6313442948371535
Validation loss: 2.5160945193544135

Epoch: 6| Step: 2
Training loss: 2.444561827856355
Validation loss: 2.53119018860783

Epoch: 6| Step: 3
Training loss: 2.250372749817807
Validation loss: 2.526876368044611

Epoch: 6| Step: 4
Training loss: 2.3804327415895297
Validation loss: 2.5174146805832995

Epoch: 6| Step: 5
Training loss: 1.6866282577941187
Validation loss: 2.5360334903509294

Epoch: 6| Step: 6
Training loss: 2.042094931806613
Validation loss: 2.5254562538550736

Epoch: 6| Step: 7
Training loss: 1.7835592726902065
Validation loss: 2.5306197743712433

Epoch: 6| Step: 8
Training loss: 2.27665896450246
Validation loss: 2.526581395223465

Epoch: 6| Step: 9
Training loss: 3.0267043490591825
Validation loss: 2.52986543566427

Epoch: 6| Step: 10
Training loss: 2.5628003200301577
Validation loss: 2.5035094741775095

Epoch: 6| Step: 11
Training loss: 2.35955122737967
Validation loss: 2.537700502964841

Epoch: 6| Step: 12
Training loss: 2.224258247777811
Validation loss: 2.5152456025115266

Epoch: 6| Step: 13
Training loss: 2.3745614701019995
Validation loss: 2.519120948364874

Epoch: 232| Step: 0
Training loss: 2.0745801018222827
Validation loss: 2.533214215146752

Epoch: 6| Step: 1
Training loss: 2.13443780809428
Validation loss: 2.5254883045365526

Epoch: 6| Step: 2
Training loss: 1.717869342254202
Validation loss: 2.5258576683332934

Epoch: 6| Step: 3
Training loss: 2.8461302133717084
Validation loss: 2.5205291743200333

Epoch: 6| Step: 4
Training loss: 2.3784632278111437
Validation loss: 2.5323349154341335

Epoch: 6| Step: 5
Training loss: 2.343889257744397
Validation loss: 2.5221431628994337

Epoch: 6| Step: 6
Training loss: 2.3703916914905956
Validation loss: 2.512524275401496

Epoch: 6| Step: 7
Training loss: 1.9166577864178587
Validation loss: 2.5273178861808927

Epoch: 6| Step: 8
Training loss: 2.3295580658497284
Validation loss: 2.5292479992713717

Epoch: 6| Step: 9
Training loss: 2.3260834210263153
Validation loss: 2.53362343427968

Epoch: 6| Step: 10
Training loss: 2.1146619309223604
Validation loss: 2.515648598886059

Epoch: 6| Step: 11
Training loss: 2.8663428619021727
Validation loss: 2.5266226870434165

Epoch: 6| Step: 12
Training loss: 2.417875272703409
Validation loss: 2.5134193750050704

Epoch: 6| Step: 13
Training loss: 1.9186485934719608
Validation loss: 2.5304316465463197

Epoch: 233| Step: 0
Training loss: 2.0421140790377503
Validation loss: 2.5432852036891336

Epoch: 6| Step: 1
Training loss: 2.362116553458271
Validation loss: 2.559208764471453

Epoch: 6| Step: 2
Training loss: 2.931342956760837
Validation loss: 2.547223494388545

Epoch: 6| Step: 3
Training loss: 1.7960791110603274
Validation loss: 2.5572706533735357

Epoch: 6| Step: 4
Training loss: 2.5306637874013416
Validation loss: 2.5430915205189195

Epoch: 6| Step: 5
Training loss: 2.139097239377331
Validation loss: 2.5600047794933207

Epoch: 6| Step: 6
Training loss: 2.354942958975197
Validation loss: 2.5486127701516312

Epoch: 6| Step: 7
Training loss: 2.0394304316262213
Validation loss: 2.5361714811220675

Epoch: 6| Step: 8
Training loss: 2.5913206006381664
Validation loss: 2.5059683130122643

Epoch: 6| Step: 9
Training loss: 1.8750286735885333
Validation loss: 2.506847707009708

Epoch: 6| Step: 10
Training loss: 2.2396585377922595
Validation loss: 2.4980909847195747

Epoch: 6| Step: 11
Training loss: 2.578777068934934
Validation loss: 2.495942048988513

Epoch: 6| Step: 12
Training loss: 1.8406152747630782
Validation loss: 2.4977426669297245

Epoch: 6| Step: 13
Training loss: 2.4733795024267713
Validation loss: 2.5040174470472416

Epoch: 234| Step: 0
Training loss: 2.2202844820664156
Validation loss: 2.4969351737768983

Epoch: 6| Step: 1
Training loss: 2.284320802476195
Validation loss: 2.5087605919366474

Epoch: 6| Step: 2
Training loss: 2.2954006523514963
Validation loss: 2.5020652029210133

Epoch: 6| Step: 3
Training loss: 2.169584534773382
Validation loss: 2.5113546958961916

Epoch: 6| Step: 4
Training loss: 1.9611129378303376
Validation loss: 2.4911253847280803

Epoch: 6| Step: 5
Training loss: 2.621123767118079
Validation loss: 2.4714816468900405

Epoch: 6| Step: 6
Training loss: 2.97233381289654
Validation loss: 2.502185105014997

Epoch: 6| Step: 7
Training loss: 2.1920521918021185
Validation loss: 2.532163839645915

Epoch: 6| Step: 8
Training loss: 2.2161118848077885
Validation loss: 2.5291822017169525

Epoch: 6| Step: 9
Training loss: 2.2202714888068957
Validation loss: 2.5360720664764442

Epoch: 6| Step: 10
Training loss: 2.883440316334175
Validation loss: 2.539145146516506

Epoch: 6| Step: 11
Training loss: 2.0029836095938265
Validation loss: 2.5105832204269696

Epoch: 6| Step: 12
Training loss: 1.9765542373182965
Validation loss: 2.5144999102829306

Epoch: 6| Step: 13
Training loss: 2.256321292501114
Validation loss: 2.5058203020466348

Epoch: 235| Step: 0
Training loss: 2.253199633501085
Validation loss: 2.5221554045245402

Epoch: 6| Step: 1
Training loss: 2.605703820829602
Validation loss: 2.517367705120936

Epoch: 6| Step: 2
Training loss: 1.4942180139782546
Validation loss: 2.529000935369429

Epoch: 6| Step: 3
Training loss: 3.0650670717253163
Validation loss: 2.512789579566134

Epoch: 6| Step: 4
Training loss: 2.568896799464001
Validation loss: 2.532751642649554

Epoch: 6| Step: 5
Training loss: 1.7848489108641765
Validation loss: 2.5807648446817915

Epoch: 6| Step: 6
Training loss: 2.46732385704298
Validation loss: 2.555338101073144

Epoch: 6| Step: 7
Training loss: 2.1444803311777205
Validation loss: 2.5520441532371296

Epoch: 6| Step: 8
Training loss: 2.5270041188914854
Validation loss: 2.5550306441652304

Epoch: 6| Step: 9
Training loss: 2.437379687347749
Validation loss: 2.5596763591782383

Epoch: 6| Step: 10
Training loss: 1.9844585611366468
Validation loss: 2.541284318733812

Epoch: 6| Step: 11
Training loss: 2.33452816298592
Validation loss: 2.541536786455777

Epoch: 6| Step: 12
Training loss: 2.1305973161066545
Validation loss: 2.552655647618516

Epoch: 6| Step: 13
Training loss: 1.8830928989412845
Validation loss: 2.5472570105515575

Epoch: 236| Step: 0
Training loss: 1.7990969644425592
Validation loss: 2.541420773561313

Epoch: 6| Step: 1
Training loss: 2.8151026233782965
Validation loss: 2.5162039617731793

Epoch: 6| Step: 2
Training loss: 2.672160886226704
Validation loss: 2.5151272393834665

Epoch: 6| Step: 3
Training loss: 2.293960486792617
Validation loss: 2.522242464870309

Epoch: 6| Step: 4
Training loss: 2.64697801553887
Validation loss: 2.5182728466097197

Epoch: 6| Step: 5
Training loss: 1.9932751248492757
Validation loss: 2.528502083387592

Epoch: 6| Step: 6
Training loss: 1.9469855287873228
Validation loss: 2.521094321830187

Epoch: 6| Step: 7
Training loss: 1.4168651479169045
Validation loss: 2.514762209198125

Epoch: 6| Step: 8
Training loss: 1.9271233700554036
Validation loss: 2.5144062683629134

Epoch: 6| Step: 9
Training loss: 1.6818106074713277
Validation loss: 2.5192913483347033

Epoch: 6| Step: 10
Training loss: 2.920879500419221
Validation loss: 2.5260152651531187

Epoch: 6| Step: 11
Training loss: 2.6205290002613855
Validation loss: 2.533393242926523

Epoch: 6| Step: 12
Training loss: 2.5569701656291337
Validation loss: 2.525182500545072

Epoch: 6| Step: 13
Training loss: 1.9001305961900394
Validation loss: 2.5829348769584173

Epoch: 237| Step: 0
Training loss: 2.15948553175075
Validation loss: 2.5770200885566537

Epoch: 6| Step: 1
Training loss: 2.1560391309156026
Validation loss: 2.6186275335186098

Epoch: 6| Step: 2
Training loss: 1.8118472403708805
Validation loss: 2.6195211757515873

Epoch: 6| Step: 3
Training loss: 2.094133256594363
Validation loss: 2.5752478063655686

Epoch: 6| Step: 4
Training loss: 1.8633419642763187
Validation loss: 2.595048204193559

Epoch: 6| Step: 5
Training loss: 2.322693293712649
Validation loss: 2.5591492493944683

Epoch: 6| Step: 6
Training loss: 1.8141198647799055
Validation loss: 2.5533006891682075

Epoch: 6| Step: 7
Training loss: 2.765956535510898
Validation loss: 2.5093470361655035

Epoch: 6| Step: 8
Training loss: 3.2400901536996716
Validation loss: 2.5214431014697882

Epoch: 6| Step: 9
Training loss: 1.6515329955613531
Validation loss: 2.5265749470017456

Epoch: 6| Step: 10
Training loss: 2.11922781628663
Validation loss: 2.5322008505547

Epoch: 6| Step: 11
Training loss: 2.859259097559208
Validation loss: 2.522951360747994

Epoch: 6| Step: 12
Training loss: 2.6428808925548357
Validation loss: 2.526435920911819

Epoch: 6| Step: 13
Training loss: 2.004788150773039
Validation loss: 2.51230998419895

Epoch: 238| Step: 0
Training loss: 2.9595167631617745
Validation loss: 2.523848493271764

Epoch: 6| Step: 1
Training loss: 2.778035138181911
Validation loss: 2.5117516562450475

Epoch: 6| Step: 2
Training loss: 1.8795907088399773
Validation loss: 2.501975089936395

Epoch: 6| Step: 3
Training loss: 2.0241032392610947
Validation loss: 2.5171350247521214

Epoch: 6| Step: 4
Training loss: 2.3468597127160016
Validation loss: 2.52626122113705

Epoch: 6| Step: 5
Training loss: 1.7583845097957247
Validation loss: 2.5021935455883186

Epoch: 6| Step: 6
Training loss: 1.9240981478887038
Validation loss: 2.5375643335214284

Epoch: 6| Step: 7
Training loss: 2.021053603709556
Validation loss: 2.586600995491875

Epoch: 6| Step: 8
Training loss: 2.485305995560918
Validation loss: 2.5566874228542193

Epoch: 6| Step: 9
Training loss: 1.8195774411553833
Validation loss: 2.5813891929800423

Epoch: 6| Step: 10
Training loss: 3.0967271140132047
Validation loss: 2.5376209255274924

Epoch: 6| Step: 11
Training loss: 1.6413274805123175
Validation loss: 2.5390192272704786

Epoch: 6| Step: 12
Training loss: 2.652328468694473
Validation loss: 2.515334513381464

Epoch: 6| Step: 13
Training loss: 3.0482274892822576
Validation loss: 2.5045520665737566

Epoch: 239| Step: 0
Training loss: 2.0882440166243814
Validation loss: 2.527170842587801

Epoch: 6| Step: 1
Training loss: 1.9671366908486019
Validation loss: 2.5103571609050395

Epoch: 6| Step: 2
Training loss: 2.4281597670099835
Validation loss: 2.5006557717146563

Epoch: 6| Step: 3
Training loss: 2.4610217852009937
Validation loss: 2.507137346345742

Epoch: 6| Step: 4
Training loss: 2.219223509215825
Validation loss: 2.4966906498986616

Epoch: 6| Step: 5
Training loss: 2.6406045946766143
Validation loss: 2.5058111363062023

Epoch: 6| Step: 6
Training loss: 2.388096288544877
Validation loss: 2.509942422816889

Epoch: 6| Step: 7
Training loss: 2.3323108499092156
Validation loss: 2.5020793214925154

Epoch: 6| Step: 8
Training loss: 2.2062652068654174
Validation loss: 2.5053441148999314

Epoch: 6| Step: 9
Training loss: 2.686153340613136
Validation loss: 2.512265119755315

Epoch: 6| Step: 10
Training loss: 2.380203569826219
Validation loss: 2.501641132199854

Epoch: 6| Step: 11
Training loss: 2.2478512994585604
Validation loss: 2.5253907194085925

Epoch: 6| Step: 12
Training loss: 2.403670774077646
Validation loss: 2.52359438192976

Epoch: 6| Step: 13
Training loss: 1.9594975994394233
Validation loss: 2.52502969088582

Epoch: 240| Step: 0
Training loss: 2.1616518110217258
Validation loss: 2.5370807602041796

Epoch: 6| Step: 1
Training loss: 2.0162881159623605
Validation loss: 2.514907165846471

Epoch: 6| Step: 2
Training loss: 2.027744848892654
Validation loss: 2.5379058942334973

Epoch: 6| Step: 3
Training loss: 2.2551708144898592
Validation loss: 2.53261916881578

Epoch: 6| Step: 4
Training loss: 2.142130635492472
Validation loss: 2.5331593913879407

Epoch: 6| Step: 5
Training loss: 2.5624091899877337
Validation loss: 2.528524037710616

Epoch: 6| Step: 6
Training loss: 2.4765547983910214
Validation loss: 2.548845445518057

Epoch: 6| Step: 7
Training loss: 2.1744170098167843
Validation loss: 2.5366007760304763

Epoch: 6| Step: 8
Training loss: 1.628706007251352
Validation loss: 2.55350039837776

Epoch: 6| Step: 9
Training loss: 2.424442825017696
Validation loss: 2.54092786296768

Epoch: 6| Step: 10
Training loss: 2.048437788648316
Validation loss: 2.563323160092621

Epoch: 6| Step: 11
Training loss: 2.743742933676968
Validation loss: 2.5505476762385904

Epoch: 6| Step: 12
Training loss: 2.319119644519908
Validation loss: 2.536161343983595

Epoch: 6| Step: 13
Training loss: 2.444921882801266
Validation loss: 2.5218073851996077

Epoch: 241| Step: 0
Training loss: 1.8997721435043486
Validation loss: 2.519911216453506

Epoch: 6| Step: 1
Training loss: 1.758926377768805
Validation loss: 2.5180269388278353

Epoch: 6| Step: 2
Training loss: 1.94522119024377
Validation loss: 2.534328707684974

Epoch: 6| Step: 3
Training loss: 2.1806389157612998
Validation loss: 2.552434326221214

Epoch: 6| Step: 4
Training loss: 2.201554299874666
Validation loss: 2.538840369264779

Epoch: 6| Step: 5
Training loss: 1.8058570936066056
Validation loss: 2.5221562552916446

Epoch: 6| Step: 6
Training loss: 3.132801997673715
Validation loss: 2.547807830790048

Epoch: 6| Step: 7
Training loss: 2.495640004545447
Validation loss: 2.558888751779165

Epoch: 6| Step: 8
Training loss: 2.569987082244826
Validation loss: 2.5395819890616167

Epoch: 6| Step: 9
Training loss: 2.3026063995131913
Validation loss: 2.5472702468575084

Epoch: 6| Step: 10
Training loss: 1.6187949921824838
Validation loss: 2.5188058996820764

Epoch: 6| Step: 11
Training loss: 2.600279803992546
Validation loss: 2.5061716750820606

Epoch: 6| Step: 12
Training loss: 2.5963438002603567
Validation loss: 2.507146158553897

Epoch: 6| Step: 13
Training loss: 2.478578823717753
Validation loss: 2.5243597244917506

Epoch: 242| Step: 0
Training loss: 2.618838117113901
Validation loss: 2.53461690768116

Epoch: 6| Step: 1
Training loss: 2.4847936697332114
Validation loss: 2.536765553213305

Epoch: 6| Step: 2
Training loss: 2.1124265849883
Validation loss: 2.5396847710654034

Epoch: 6| Step: 3
Training loss: 2.4401547573603124
Validation loss: 2.5477548651319553

Epoch: 6| Step: 4
Training loss: 1.7679164499460567
Validation loss: 2.527442556785584

Epoch: 6| Step: 5
Training loss: 2.381288435017541
Validation loss: 2.5045979973056967

Epoch: 6| Step: 6
Training loss: 2.5844375547428564
Validation loss: 2.5097299219503713

Epoch: 6| Step: 7
Training loss: 2.389860342566112
Validation loss: 2.5288730261294368

Epoch: 6| Step: 8
Training loss: 2.406491750487837
Validation loss: 2.5448315775913084

Epoch: 6| Step: 9
Training loss: 2.1110535901024456
Validation loss: 2.5399456346756217

Epoch: 6| Step: 10
Training loss: 1.9606178296693453
Validation loss: 2.56241478817071

Epoch: 6| Step: 11
Training loss: 2.8424407963555076
Validation loss: 2.565616309971715

Epoch: 6| Step: 12
Training loss: 1.4216733517029363
Validation loss: 2.5706854088843323

Epoch: 6| Step: 13
Training loss: 2.2557832779372853
Validation loss: 2.5731388078513215

Epoch: 243| Step: 0
Training loss: 2.4180218963451994
Validation loss: 2.5884003527091686

Epoch: 6| Step: 1
Training loss: 2.984504417289626
Validation loss: 2.588206683358156

Epoch: 6| Step: 2
Training loss: 1.9743113608880047
Validation loss: 2.5768459191178326

Epoch: 6| Step: 3
Training loss: 2.17587701939421
Validation loss: 2.573770425180342

Epoch: 6| Step: 4
Training loss: 2.287438138531808
Validation loss: 2.5418507920991438

Epoch: 6| Step: 5
Training loss: 2.8297569666592297
Validation loss: 2.5370712062048635

Epoch: 6| Step: 6
Training loss: 1.9815877127205235
Validation loss: 2.517600805921762

Epoch: 6| Step: 7
Training loss: 1.9274797667592984
Validation loss: 2.52433850527642

Epoch: 6| Step: 8
Training loss: 1.7091643320430667
Validation loss: 2.514815869729348

Epoch: 6| Step: 9
Training loss: 3.2147896114347163
Validation loss: 2.5067058113859755

Epoch: 6| Step: 10
Training loss: 2.0787731106517726
Validation loss: 2.5250367410586496

Epoch: 6| Step: 11
Training loss: 1.970650134399679
Validation loss: 2.5279403367597184

Epoch: 6| Step: 12
Training loss: 2.1296131325357663
Validation loss: 2.5406235654607134

Epoch: 6| Step: 13
Training loss: 1.945496332146004
Validation loss: 2.5500075221729905

Epoch: 244| Step: 0
Training loss: 2.0895160739022094
Validation loss: 2.532718279696315

Epoch: 6| Step: 1
Training loss: 1.7170236413891078
Validation loss: 2.5489076643380413

Epoch: 6| Step: 2
Training loss: 1.9570434935409489
Validation loss: 2.5301599706553595

Epoch: 6| Step: 3
Training loss: 2.6909882728890997
Validation loss: 2.5485161640337437

Epoch: 6| Step: 4
Training loss: 1.9922880259563727
Validation loss: 2.5470238234523217

Epoch: 6| Step: 5
Training loss: 2.5424244381639336
Validation loss: 2.5799907676275304

Epoch: 6| Step: 6
Training loss: 2.081045751315281
Validation loss: 2.5392440496241466

Epoch: 6| Step: 7
Training loss: 2.1056812865608387
Validation loss: 2.5416033585798874

Epoch: 6| Step: 8
Training loss: 2.7230234869911727
Validation loss: 2.514382223216406

Epoch: 6| Step: 9
Training loss: 2.3469578470573897
Validation loss: 2.5297068691945497

Epoch: 6| Step: 10
Training loss: 2.35494518629295
Validation loss: 2.508656289505039

Epoch: 6| Step: 11
Training loss: 2.208289403898327
Validation loss: 2.5223288447949823

Epoch: 6| Step: 12
Training loss: 2.703005573082082
Validation loss: 2.5097166697357385

Epoch: 6| Step: 13
Training loss: 2.0586317373748404
Validation loss: 2.5317605214136862

Epoch: 245| Step: 0
Training loss: 2.8329645552648057
Validation loss: 2.506353458923246

Epoch: 6| Step: 1
Training loss: 2.4004688917518915
Validation loss: 2.528666178303571

Epoch: 6| Step: 2
Training loss: 1.6068328482738552
Validation loss: 2.520246947213096

Epoch: 6| Step: 3
Training loss: 2.059029636164215
Validation loss: 2.5301106090265484

Epoch: 6| Step: 4
Training loss: 2.358994105837429
Validation loss: 2.496847461776156

Epoch: 6| Step: 5
Training loss: 2.0785795015937687
Validation loss: 2.51916075355508

Epoch: 6| Step: 6
Training loss: 2.8533523585971663
Validation loss: 2.5264290083340386

Epoch: 6| Step: 7
Training loss: 1.5840561705850595
Validation loss: 2.523439287277549

Epoch: 6| Step: 8
Training loss: 1.9049566290015831
Validation loss: 2.5289512368656326

Epoch: 6| Step: 9
Training loss: 2.0816634033926844
Validation loss: 2.5201634129012818

Epoch: 6| Step: 10
Training loss: 2.7195628913106056
Validation loss: 2.507117201775156

Epoch: 6| Step: 11
Training loss: 2.4922426032309484
Validation loss: 2.5374673850683567

Epoch: 6| Step: 12
Training loss: 2.329867229526279
Validation loss: 2.5243425350521025

Epoch: 6| Step: 13
Training loss: 2.171467585051849
Validation loss: 2.5528955270091096

Epoch: 246| Step: 0
Training loss: 1.8960249528007447
Validation loss: 2.5671012398020396

Epoch: 6| Step: 1
Training loss: 2.1408624447746027
Validation loss: 2.544220678224914

Epoch: 6| Step: 2
Training loss: 1.9393277929709247
Validation loss: 2.5514114170075484

Epoch: 6| Step: 3
Training loss: 2.3598976819439406
Validation loss: 2.5488919421862906

Epoch: 6| Step: 4
Training loss: 2.147674314021203
Validation loss: 2.512657128666728

Epoch: 6| Step: 5
Training loss: 2.86454264294017
Validation loss: 2.539248556509431

Epoch: 6| Step: 6
Training loss: 2.6046900007193585
Validation loss: 2.5405140019279773

Epoch: 6| Step: 7
Training loss: 2.150072176409325
Validation loss: 2.5417295875473824

Epoch: 6| Step: 8
Training loss: 1.9779523704857704
Validation loss: 2.5180062027971717

Epoch: 6| Step: 9
Training loss: 1.7415099601274593
Validation loss: 2.544725677429962

Epoch: 6| Step: 10
Training loss: 2.293189484923439
Validation loss: 2.5525365517863925

Epoch: 6| Step: 11
Training loss: 2.2919037667355413
Validation loss: 2.516433538497961

Epoch: 6| Step: 12
Training loss: 2.199760952880311
Validation loss: 2.543219316192514

Epoch: 6| Step: 13
Training loss: 2.6735084403885576
Validation loss: 2.5476762724222866

Epoch: 247| Step: 0
Training loss: 2.338846799885046
Validation loss: 2.5504287857875387

Epoch: 6| Step: 1
Training loss: 1.8398099276598578
Validation loss: 2.5260437457413656

Epoch: 6| Step: 2
Training loss: 2.6157782105269325
Validation loss: 2.528098652517291

Epoch: 6| Step: 3
Training loss: 2.4184264210566635
Validation loss: 2.54242563380858

Epoch: 6| Step: 4
Training loss: 1.7148798980031212
Validation loss: 2.5409351036064542

Epoch: 6| Step: 5
Training loss: 2.584384048243116
Validation loss: 2.5339667101517227

Epoch: 6| Step: 6
Training loss: 2.10283318999077
Validation loss: 2.5350926748336278

Epoch: 6| Step: 7
Training loss: 1.5751580022850011
Validation loss: 2.542105587337342

Epoch: 6| Step: 8
Training loss: 2.2395910455142163
Validation loss: 2.5264885235149634

Epoch: 6| Step: 9
Training loss: 2.03832854292466
Validation loss: 2.539412520320236

Epoch: 6| Step: 10
Training loss: 2.1691882303606924
Validation loss: 2.552422642371584

Epoch: 6| Step: 11
Training loss: 3.026469442800969
Validation loss: 2.549258437195058

Epoch: 6| Step: 12
Training loss: 2.014765356520083
Validation loss: 2.5585761149723245

Epoch: 6| Step: 13
Training loss: 2.3986547912182115
Validation loss: 2.629633825022177

Epoch: 248| Step: 0
Training loss: 2.792605332425993
Validation loss: 2.587476765870778

Epoch: 6| Step: 1
Training loss: 2.4883435299922705
Validation loss: 2.5367256091618122

Epoch: 6| Step: 2
Training loss: 2.4986519039834807
Validation loss: 2.515295619212061

Epoch: 6| Step: 3
Training loss: 1.8054773493074636
Validation loss: 2.5129265775776584

Epoch: 6| Step: 4
Training loss: 2.660499853049914
Validation loss: 2.4957492612541956

Epoch: 6| Step: 5
Training loss: 1.8877715970100903
Validation loss: 2.516847806899998

Epoch: 6| Step: 6
Training loss: 1.935461017386555
Validation loss: 2.521578266218845

Epoch: 6| Step: 7
Training loss: 1.3513547263554364
Validation loss: 2.5083450433282426

Epoch: 6| Step: 8
Training loss: 2.8213957082755656
Validation loss: 2.5130921006185805

Epoch: 6| Step: 9
Training loss: 2.451309406935957
Validation loss: 2.5355938189473566

Epoch: 6| Step: 10
Training loss: 2.2820712139909918
Validation loss: 2.5360087963086073

Epoch: 6| Step: 11
Training loss: 1.8598606533233273
Validation loss: 2.548063753571087

Epoch: 6| Step: 12
Training loss: 1.9880881824699967
Validation loss: 2.5474730649503123

Epoch: 6| Step: 13
Training loss: 2.193478289783481
Validation loss: 2.538096881063484

Epoch: 249| Step: 0
Training loss: 1.4871357992844183
Validation loss: 2.5146438075149526

Epoch: 6| Step: 1
Training loss: 2.49454427513213
Validation loss: 2.520815310663368

Epoch: 6| Step: 2
Training loss: 1.7993174662903932
Validation loss: 2.52142036055336

Epoch: 6| Step: 3
Training loss: 2.0500959141320956
Validation loss: 2.508457065352472

Epoch: 6| Step: 4
Training loss: 2.3299646469839557
Validation loss: 2.5201535424882477

Epoch: 6| Step: 5
Training loss: 1.478505788389917
Validation loss: 2.5272308434447677

Epoch: 6| Step: 6
Training loss: 1.8071421653922861
Validation loss: 2.5198555198002373

Epoch: 6| Step: 7
Training loss: 2.079128969369325
Validation loss: 2.522903149602975

Epoch: 6| Step: 8
Training loss: 3.0871792769551827
Validation loss: 2.5205089318323344

Epoch: 6| Step: 9
Training loss: 3.149004182388179
Validation loss: 2.5305168126091764

Epoch: 6| Step: 10
Training loss: 2.6546606357735234
Validation loss: 2.5190037059244315

Epoch: 6| Step: 11
Training loss: 2.134253158554487
Validation loss: 2.536766563554687

Epoch: 6| Step: 12
Training loss: 2.0798385553794483
Validation loss: 2.5326231697258788

Epoch: 6| Step: 13
Training loss: 2.136988537369842
Validation loss: 2.5989680369673143

Epoch: 250| Step: 0
Training loss: 2.4815761707305493
Validation loss: 2.6030345490407845

Epoch: 6| Step: 1
Training loss: 2.2144683573588058
Validation loss: 2.6769453723156365

Epoch: 6| Step: 2
Training loss: 2.0356236248814006
Validation loss: 2.6601290484366635

Epoch: 6| Step: 3
Training loss: 1.2572772859869228
Validation loss: 2.642631009576646

Epoch: 6| Step: 4
Training loss: 2.331148782532181
Validation loss: 2.629999289687802

Epoch: 6| Step: 5
Training loss: 2.5368765943719103
Validation loss: 2.594170854121708

Epoch: 6| Step: 6
Training loss: 2.686354725794617
Validation loss: 2.51709225910711

Epoch: 6| Step: 7
Training loss: 2.394929090497408
Validation loss: 2.523579407472226

Epoch: 6| Step: 8
Training loss: 2.2188400465194813
Validation loss: 2.492178882037881

Epoch: 6| Step: 9
Training loss: 2.1225104615006467
Validation loss: 2.5304284194915394

Epoch: 6| Step: 10
Training loss: 2.627856743692215
Validation loss: 2.5076683216896596

Epoch: 6| Step: 11
Training loss: 2.7164002711109876
Validation loss: 2.5248500386013086

Epoch: 6| Step: 12
Training loss: 2.124470588708537
Validation loss: 2.540442395969725

Epoch: 6| Step: 13
Training loss: 1.6675558896971554
Validation loss: 2.4968600263532523

Epoch: 251| Step: 0
Training loss: 2.0663927506869437
Validation loss: 2.5029800217481815

Epoch: 6| Step: 1
Training loss: 2.1454728079828236
Validation loss: 2.5090692684645934

Epoch: 6| Step: 2
Training loss: 1.9811762462089233
Validation loss: 2.4878873168904154

Epoch: 6| Step: 3
Training loss: 2.24947615989301
Validation loss: 2.512171362897705

Epoch: 6| Step: 4
Training loss: 2.3794749414864333
Validation loss: 2.5252210142645293

Epoch: 6| Step: 5
Training loss: 1.8835034507393777
Validation loss: 2.555313811293879

Epoch: 6| Step: 6
Training loss: 2.34372568753666
Validation loss: 2.536885036997814

Epoch: 6| Step: 7
Training loss: 2.8783690573797096
Validation loss: 2.533141226344356

Epoch: 6| Step: 8
Training loss: 2.432951375516963
Validation loss: 2.52004923855649

Epoch: 6| Step: 9
Training loss: 2.0676043377787052
Validation loss: 2.516605194132598

Epoch: 6| Step: 10
Training loss: 2.1872102818049974
Validation loss: 2.5175313262101633

Epoch: 6| Step: 11
Training loss: 2.679437297562192
Validation loss: 2.507981671958404

Epoch: 6| Step: 12
Training loss: 2.026009828240524
Validation loss: 2.510460561682498

Epoch: 6| Step: 13
Training loss: 2.027018555889815
Validation loss: 2.507707698608869

Epoch: 252| Step: 0
Training loss: 1.8312177661753863
Validation loss: 2.510450566064248

Epoch: 6| Step: 1
Training loss: 2.3751843029589224
Validation loss: 2.532986190711068

Epoch: 6| Step: 2
Training loss: 2.6471830114516384
Validation loss: 2.5484959099626816

Epoch: 6| Step: 3
Training loss: 2.1492219359839844
Validation loss: 2.605715273394931

Epoch: 6| Step: 4
Training loss: 1.9110250233080341
Validation loss: 2.555597623418934

Epoch: 6| Step: 5
Training loss: 2.2546144427374695
Validation loss: 2.553371304257909

Epoch: 6| Step: 6
Training loss: 2.2471333361843087
Validation loss: 2.5541787919404397

Epoch: 6| Step: 7
Training loss: 2.146488595807383
Validation loss: 2.516011684228869

Epoch: 6| Step: 8
Training loss: 2.436476663817077
Validation loss: 2.5368865250272963

Epoch: 6| Step: 9
Training loss: 1.7611257565862453
Validation loss: 2.5234280833097165

Epoch: 6| Step: 10
Training loss: 2.179276403675248
Validation loss: 2.532365309914041

Epoch: 6| Step: 11
Training loss: 2.5795096638205113
Validation loss: 2.53876726830509

Epoch: 6| Step: 12
Training loss: 1.974091927093313
Validation loss: 2.536856012416624

Epoch: 6| Step: 13
Training loss: 2.610589390119816
Validation loss: 2.5257567621914787

Epoch: 253| Step: 0
Training loss: 2.323541007080459
Validation loss: 2.5243021189441635

Epoch: 6| Step: 1
Training loss: 2.1378152046024796
Validation loss: 2.543821239801673

Epoch: 6| Step: 2
Training loss: 2.4712735569264814
Validation loss: 2.5413615924372146

Epoch: 6| Step: 3
Training loss: 1.9188276492631913
Validation loss: 2.5535053625081003

Epoch: 6| Step: 4
Training loss: 2.430708299711702
Validation loss: 2.569399222127791

Epoch: 6| Step: 5
Training loss: 2.0865681012958133
Validation loss: 2.545057635176188

Epoch: 6| Step: 6
Training loss: 2.416602813490998
Validation loss: 2.5270143242135523

Epoch: 6| Step: 7
Training loss: 2.2962970655307826
Validation loss: 2.4885800200730053

Epoch: 6| Step: 8
Training loss: 1.3111894967782067
Validation loss: 2.487661383296313

Epoch: 6| Step: 9
Training loss: 2.882995103464722
Validation loss: 2.5138901993857585

Epoch: 6| Step: 10
Training loss: 3.2070520658200827
Validation loss: 2.5118375743170125

Epoch: 6| Step: 11
Training loss: 2.471563353828363
Validation loss: 2.5119426305176726

Epoch: 6| Step: 12
Training loss: 2.20155960635123
Validation loss: 2.517414175475463

Epoch: 6| Step: 13
Training loss: 1.8783196626090692
Validation loss: 2.4928194558200114

Epoch: 254| Step: 0
Training loss: 1.9623096422338102
Validation loss: 2.4980412121018363

Epoch: 6| Step: 1
Training loss: 2.513077956952093
Validation loss: 2.46844573902404

Epoch: 6| Step: 2
Training loss: 2.5593042682939284
Validation loss: 2.4903790281082228

Epoch: 6| Step: 3
Training loss: 2.5252696846947322
Validation loss: 2.48427820716894

Epoch: 6| Step: 4
Training loss: 1.9559426087499998
Validation loss: 2.475739014236096

Epoch: 6| Step: 5
Training loss: 2.251989332902217
Validation loss: 2.4886186930851326

Epoch: 6| Step: 6
Training loss: 2.0163640286482525
Validation loss: 2.5321693870012423

Epoch: 6| Step: 7
Training loss: 1.6341105143178507
Validation loss: 2.5078888720076904

Epoch: 6| Step: 8
Training loss: 2.725948931455668
Validation loss: 2.5022135630524214

Epoch: 6| Step: 9
Training loss: 1.9283293604940352
Validation loss: 2.47385665416907

Epoch: 6| Step: 10
Training loss: 2.319209906115237
Validation loss: 2.498764734267684

Epoch: 6| Step: 11
Training loss: 2.51377516314234
Validation loss: 2.4855650444751536

Epoch: 6| Step: 12
Training loss: 1.7524994303529606
Validation loss: 2.506057029772379

Epoch: 6| Step: 13
Training loss: 2.9280570007049795
Validation loss: 2.506936559080601

Epoch: 255| Step: 0
Training loss: 2.490339496862094
Validation loss: 2.500848244768038

Epoch: 6| Step: 1
Training loss: 1.8272178551083764
Validation loss: 2.514470959174891

Epoch: 6| Step: 2
Training loss: 2.2453637570534664
Validation loss: 2.52917731553611

Epoch: 6| Step: 3
Training loss: 2.6023436510537827
Validation loss: 2.4910897415251068

Epoch: 6| Step: 4
Training loss: 2.4073309514003913
Validation loss: 2.5052024830665935

Epoch: 6| Step: 5
Training loss: 2.1874546591283184
Validation loss: 2.508191390050434

Epoch: 6| Step: 6
Training loss: 2.4828595991810745
Validation loss: 2.4851233356962035

Epoch: 6| Step: 7
Training loss: 2.516525297004798
Validation loss: 2.4869057662810707

Epoch: 6| Step: 8
Training loss: 2.0259212141016416
Validation loss: 2.5131359067406818

Epoch: 6| Step: 9
Training loss: 2.4834370311958867
Validation loss: 2.4840704773258793

Epoch: 6| Step: 10
Training loss: 2.150180733647154
Validation loss: 2.477883132221008

Epoch: 6| Step: 11
Training loss: 1.8100390334161953
Validation loss: 2.518466253208409

Epoch: 6| Step: 12
Training loss: 2.1489481371145978
Validation loss: 2.5118212800088466

Epoch: 6| Step: 13
Training loss: 2.051894229237588
Validation loss: 2.518134340527884

Epoch: 256| Step: 0
Training loss: 2.472599263913092
Validation loss: 2.534890770787914

Epoch: 6| Step: 1
Training loss: 2.714294905037485
Validation loss: 2.5360715964215816

Epoch: 6| Step: 2
Training loss: 2.1574847238293784
Validation loss: 2.5630326066460243

Epoch: 6| Step: 3
Training loss: 1.9096994926564224
Validation loss: 2.6120179396262038

Epoch: 6| Step: 4
Training loss: 1.7817107826007266
Validation loss: 2.6574658920812273

Epoch: 6| Step: 5
Training loss: 2.0990042732707774
Validation loss: 2.608859652798221

Epoch: 6| Step: 6
Training loss: 2.2156277031068226
Validation loss: 2.6201840682563105

Epoch: 6| Step: 7
Training loss: 2.856517760833379
Validation loss: 2.557546604188043

Epoch: 6| Step: 8
Training loss: 1.888537870621763
Validation loss: 2.5204481324485015

Epoch: 6| Step: 9
Training loss: 2.2094252304129687
Validation loss: 2.515617939246084

Epoch: 6| Step: 10
Training loss: 1.900138312876919
Validation loss: 2.517078603626294

Epoch: 6| Step: 11
Training loss: 2.5898608729284067
Validation loss: 2.5127727063216136

Epoch: 6| Step: 12
Training loss: 1.7962727076316933
Validation loss: 2.5391961478247587

Epoch: 6| Step: 13
Training loss: 2.438414866591612
Validation loss: 2.5144693314553166

Epoch: 257| Step: 0
Training loss: 2.4005122949292907
Validation loss: 2.5356384665131833

Epoch: 6| Step: 1
Training loss: 1.4784867600076175
Validation loss: 2.518072828918713

Epoch: 6| Step: 2
Training loss: 2.5454667767627184
Validation loss: 2.5288043511018667

Epoch: 6| Step: 3
Training loss: 2.60037066678489
Validation loss: 2.505027817364197

Epoch: 6| Step: 4
Training loss: 2.413316629977231
Validation loss: 2.4964421705183133

Epoch: 6| Step: 5
Training loss: 2.58889628897261
Validation loss: 2.497911757293874

Epoch: 6| Step: 6
Training loss: 2.6116587986570963
Validation loss: 2.5216293391784457

Epoch: 6| Step: 7
Training loss: 1.8784348497259407
Validation loss: 2.5312609103246335

Epoch: 6| Step: 8
Training loss: 2.3079406537404172
Validation loss: 2.536141453452722

Epoch: 6| Step: 9
Training loss: 2.445750236940923
Validation loss: 2.537142343480665

Epoch: 6| Step: 10
Training loss: 2.4435558895668854
Validation loss: 2.540090906263578

Epoch: 6| Step: 11
Training loss: 1.9601671141790522
Validation loss: 2.5615041550029174

Epoch: 6| Step: 12
Training loss: 1.9016108736328334
Validation loss: 2.5473667598342566

Epoch: 6| Step: 13
Training loss: 2.3436553935984
Validation loss: 2.517860556564413

Epoch: 258| Step: 0
Training loss: 1.8137200294295173
Validation loss: 2.528725515119151

Epoch: 6| Step: 1
Training loss: 2.2754922606726984
Validation loss: 2.5285870080005584

Epoch: 6| Step: 2
Training loss: 2.5763366044992293
Validation loss: 2.5041167061170313

Epoch: 6| Step: 3
Training loss: 1.9850236928760565
Validation loss: 2.538577905040661

Epoch: 6| Step: 4
Training loss: 2.0738768789740307
Validation loss: 2.5347658237788955

Epoch: 6| Step: 5
Training loss: 2.3070031897791923
Validation loss: 2.5313842800613813

Epoch: 6| Step: 6
Training loss: 1.983210665117634
Validation loss: 2.514142264868447

Epoch: 6| Step: 7
Training loss: 2.213898526017441
Validation loss: 2.53372529745332

Epoch: 6| Step: 8
Training loss: 2.350544756792885
Validation loss: 2.557699203389986

Epoch: 6| Step: 9
Training loss: 2.2530283151905333
Validation loss: 2.547639665702707

Epoch: 6| Step: 10
Training loss: 1.8637671646770737
Validation loss: 2.527599072223599

Epoch: 6| Step: 11
Training loss: 2.562221232812269
Validation loss: 2.562408848823833

Epoch: 6| Step: 12
Training loss: 2.7646809491476287
Validation loss: 2.592220560192228

Epoch: 6| Step: 13
Training loss: 1.9685378187372546
Validation loss: 2.5765565513170494

Epoch: 259| Step: 0
Training loss: 1.9881175635209845
Validation loss: 2.5565333799245527

Epoch: 6| Step: 1
Training loss: 1.6387043200657936
Validation loss: 2.518744167829124

Epoch: 6| Step: 2
Training loss: 2.1181028294802973
Validation loss: 2.532725512426521

Epoch: 6| Step: 3
Training loss: 1.943419305078596
Validation loss: 2.5289002332123793

Epoch: 6| Step: 4
Training loss: 2.709030668032268
Validation loss: 2.5235732665018045

Epoch: 6| Step: 5
Training loss: 2.86777085026998
Validation loss: 2.5172929466635994

Epoch: 6| Step: 6
Training loss: 1.8022574706275292
Validation loss: 2.5374932393953307

Epoch: 6| Step: 7
Training loss: 1.7063963383670657
Validation loss: 2.5270016501093857

Epoch: 6| Step: 8
Training loss: 2.4866869263765414
Validation loss: 2.5380472197642847

Epoch: 6| Step: 9
Training loss: 2.038816824542329
Validation loss: 2.531349274372216

Epoch: 6| Step: 10
Training loss: 2.971183020800102
Validation loss: 2.5235091003401013

Epoch: 6| Step: 11
Training loss: 2.0172983956086044
Validation loss: 2.53758999895119

Epoch: 6| Step: 12
Training loss: 1.9137257805306451
Validation loss: 2.517550471992234

Epoch: 6| Step: 13
Training loss: 2.6209893241353437
Validation loss: 2.538145461148323

Epoch: 260| Step: 0
Training loss: 2.754383927710156
Validation loss: 2.537671190196761

Epoch: 6| Step: 1
Training loss: 2.547644563266184
Validation loss: 2.5458899623318607

Epoch: 6| Step: 2
Training loss: 1.3955411700138676
Validation loss: 2.5446829382369778

Epoch: 6| Step: 3
Training loss: 2.073940797275329
Validation loss: 2.5490219802507377

Epoch: 6| Step: 4
Training loss: 2.036247327040574
Validation loss: 2.6072896364280083

Epoch: 6| Step: 5
Training loss: 2.827671752354311
Validation loss: 2.6097202263008388

Epoch: 6| Step: 6
Training loss: 2.4929764315045397
Validation loss: 2.5657361538126326

Epoch: 6| Step: 7
Training loss: 2.1505524923467614
Validation loss: 2.578278076559537

Epoch: 6| Step: 8
Training loss: 1.869161288825825
Validation loss: 2.593109595663

Epoch: 6| Step: 9
Training loss: 1.926219526640248
Validation loss: 2.5915368991103875

Epoch: 6| Step: 10
Training loss: 2.0230027840143077
Validation loss: 2.5438913760627

Epoch: 6| Step: 11
Training loss: 2.5995088553537378
Validation loss: 2.547378615063307

Epoch: 6| Step: 12
Training loss: 2.3112907340884035
Validation loss: 2.574021960441694

Epoch: 6| Step: 13
Training loss: 1.564696179962615
Validation loss: 2.551429747884965

Epoch: 261| Step: 0
Training loss: 1.8166564112849182
Validation loss: 2.5840759876222306

Epoch: 6| Step: 1
Training loss: 2.541173908015748
Validation loss: 2.5145086492800695

Epoch: 6| Step: 2
Training loss: 2.3531127078278606
Validation loss: 2.5387058105329325

Epoch: 6| Step: 3
Training loss: 1.6934884098085476
Validation loss: 2.5749454890657106

Epoch: 6| Step: 4
Training loss: 1.9487512673893221
Validation loss: 2.530320016325986

Epoch: 6| Step: 5
Training loss: 2.4101768257833216
Validation loss: 2.5622374004627795

Epoch: 6| Step: 6
Training loss: 2.451043089868792
Validation loss: 2.5542063750955153

Epoch: 6| Step: 7
Training loss: 1.368253194450108
Validation loss: 2.5534501340693043

Epoch: 6| Step: 8
Training loss: 2.5910216539744986
Validation loss: 2.5268581106568315

Epoch: 6| Step: 9
Training loss: 2.676070639004398
Validation loss: 2.5450380405663267

Epoch: 6| Step: 10
Training loss: 2.213909941312195
Validation loss: 2.557431333085538

Epoch: 6| Step: 11
Training loss: 2.090647206095865
Validation loss: 2.5641962655381647

Epoch: 6| Step: 12
Training loss: 2.3034255888810393
Validation loss: 2.5720725019597572

Epoch: 6| Step: 13
Training loss: 1.864254487375898
Validation loss: 2.607100433843041

Epoch: 262| Step: 0
Training loss: 2.6831912609265114
Validation loss: 2.604154851250865

Epoch: 6| Step: 1
Training loss: 2.230230048078515
Validation loss: 2.557521822660086

Epoch: 6| Step: 2
Training loss: 2.217528745858438
Validation loss: 2.542772909613119

Epoch: 6| Step: 3
Training loss: 1.8128016648332874
Validation loss: 2.5483289597671064

Epoch: 6| Step: 4
Training loss: 2.0730013678289043
Validation loss: 2.568587105714965

Epoch: 6| Step: 5
Training loss: 1.4921879793336108
Validation loss: 2.5658826288995153

Epoch: 6| Step: 6
Training loss: 2.5000304220255933
Validation loss: 2.5362934526331276

Epoch: 6| Step: 7
Training loss: 1.9679224000494981
Validation loss: 2.5518173442465315

Epoch: 6| Step: 8
Training loss: 2.007762863792465
Validation loss: 2.5338356250007434

Epoch: 6| Step: 9
Training loss: 1.8254767252499609
Validation loss: 2.537432933102726

Epoch: 6| Step: 10
Training loss: 2.9156246140327484
Validation loss: 2.511305961485373

Epoch: 6| Step: 11
Training loss: 2.2397852133907894
Validation loss: 2.5263218255695934

Epoch: 6| Step: 12
Training loss: 2.0858618333215455
Validation loss: 2.5656073733431684

Epoch: 6| Step: 13
Training loss: 2.745751480325819
Validation loss: 2.538829037619134

Epoch: 263| Step: 0
Training loss: 1.5910442047212117
Validation loss: 2.524723949387247

Epoch: 6| Step: 1
Training loss: 1.9642617063169867
Validation loss: 2.558137840439462

Epoch: 6| Step: 2
Training loss: 2.2026074389991677
Validation loss: 2.5675004071486365

Epoch: 6| Step: 3
Training loss: 2.077161981693618
Validation loss: 2.575493025878714

Epoch: 6| Step: 4
Training loss: 2.7414397608615917
Validation loss: 2.5567953608358196

Epoch: 6| Step: 5
Training loss: 2.243534547455198
Validation loss: 2.5540908910101487

Epoch: 6| Step: 6
Training loss: 2.1555234265418237
Validation loss: 2.5683426657013495

Epoch: 6| Step: 7
Training loss: 2.102537361566021
Validation loss: 2.554889791491898

Epoch: 6| Step: 8
Training loss: 1.8120939523411048
Validation loss: 2.57326623083822

Epoch: 6| Step: 9
Training loss: 2.0582471986527078
Validation loss: 2.581312917415155

Epoch: 6| Step: 10
Training loss: 2.228237659661134
Validation loss: 2.5315256557366292

Epoch: 6| Step: 11
Training loss: 1.945662011303979
Validation loss: 2.542192191112014

Epoch: 6| Step: 12
Training loss: 3.0738618248466394
Validation loss: 2.5378807486902235

Epoch: 6| Step: 13
Training loss: 2.4505083257428266
Validation loss: 2.5395956878319876

Epoch: 264| Step: 0
Training loss: 1.8905832585542577
Validation loss: 2.5714340932095494

Epoch: 6| Step: 1
Training loss: 1.8995148541300726
Validation loss: 2.5610590969696463

Epoch: 6| Step: 2
Training loss: 2.3682832605310997
Validation loss: 2.5492554288160822

Epoch: 6| Step: 3
Training loss: 2.066637686044271
Validation loss: 2.557114205868413

Epoch: 6| Step: 4
Training loss: 2.7815006443196424
Validation loss: 2.53701073325331

Epoch: 6| Step: 5
Training loss: 1.7811065749934745
Validation loss: 2.560869613160404

Epoch: 6| Step: 6
Training loss: 2.3250929783103484
Validation loss: 2.5675930335186927

Epoch: 6| Step: 7
Training loss: 2.611522225104423
Validation loss: 2.5741317803795534

Epoch: 6| Step: 8
Training loss: 2.1153166553277853
Validation loss: 2.563461867517405

Epoch: 6| Step: 9
Training loss: 1.9551201967329517
Validation loss: 2.554507965716605

Epoch: 6| Step: 10
Training loss: 1.8202663956071272
Validation loss: 2.5612580538452874

Epoch: 6| Step: 11
Training loss: 2.118851911856381
Validation loss: 2.546862448132873

Epoch: 6| Step: 12
Training loss: 2.155505950374438
Validation loss: 2.5273714845246977

Epoch: 6| Step: 13
Training loss: 2.73111919028723
Validation loss: 2.5659509000349714

Epoch: 265| Step: 0
Training loss: 2.506439498624715
Validation loss: 2.511718227926292

Epoch: 6| Step: 1
Training loss: 1.5231199275868779
Validation loss: 2.494181051899978

Epoch: 6| Step: 2
Training loss: 1.8308930918276993
Validation loss: 2.525239865709612

Epoch: 6| Step: 3
Training loss: 2.1376036323276657
Validation loss: 2.5040591268144983

Epoch: 6| Step: 4
Training loss: 2.472230606445878
Validation loss: 2.533037057186599

Epoch: 6| Step: 5
Training loss: 2.551088743968357
Validation loss: 2.5197602397151626

Epoch: 6| Step: 6
Training loss: 1.8856840277799756
Validation loss: 2.5393785641872344

Epoch: 6| Step: 7
Training loss: 1.9407412581703287
Validation loss: 2.5680198609414964

Epoch: 6| Step: 8
Training loss: 2.129540697105233
Validation loss: 2.5471640268784834

Epoch: 6| Step: 9
Training loss: 2.295413947411648
Validation loss: 2.5646886937686455

Epoch: 6| Step: 10
Training loss: 2.287070178731166
Validation loss: 2.5538572931989507

Epoch: 6| Step: 11
Training loss: 2.0909317179348927
Validation loss: 2.5412950921612207

Epoch: 6| Step: 12
Training loss: 2.534375933213068
Validation loss: 2.551833383166486

Epoch: 6| Step: 13
Training loss: 2.3418980720550198
Validation loss: 2.5287983799553984

Epoch: 266| Step: 0
Training loss: 1.4510451989314603
Validation loss: 2.5205552812136642

Epoch: 6| Step: 1
Training loss: 1.3034517752122459
Validation loss: 2.5437593183417073

Epoch: 6| Step: 2
Training loss: 2.814956101232784
Validation loss: 2.5715941351870315

Epoch: 6| Step: 3
Training loss: 2.183839623763461
Validation loss: 2.5550233890386096

Epoch: 6| Step: 4
Training loss: 1.59809731362133
Validation loss: 2.535956195316594

Epoch: 6| Step: 5
Training loss: 2.7156578105880285
Validation loss: 2.5694582678162408

Epoch: 6| Step: 6
Training loss: 2.4702242541732446
Validation loss: 2.568621232640905

Epoch: 6| Step: 7
Training loss: 2.5981406312370887
Validation loss: 2.543166153409877

Epoch: 6| Step: 8
Training loss: 1.9894890554836029
Validation loss: 2.526695856283904

Epoch: 6| Step: 9
Training loss: 2.1730086846281216
Validation loss: 2.543385008199082

Epoch: 6| Step: 10
Training loss: 2.173391238281753
Validation loss: 2.537466249726943

Epoch: 6| Step: 11
Training loss: 2.3015284725452614
Validation loss: 2.538678998106103

Epoch: 6| Step: 12
Training loss: 1.883918405762392
Validation loss: 2.584161107945996

Epoch: 6| Step: 13
Training loss: 2.4470594704420003
Validation loss: 2.5807899958078244

Epoch: 267| Step: 0
Training loss: 2.102306815581013
Validation loss: 2.5595635437442295

Epoch: 6| Step: 1
Training loss: 1.7266198748553439
Validation loss: 2.5377938098905832

Epoch: 6| Step: 2
Training loss: 2.0360721569952305
Validation loss: 2.5251265110137053

Epoch: 6| Step: 3
Training loss: 2.23798521524136
Validation loss: 2.5548860120883297

Epoch: 6| Step: 4
Training loss: 2.581295214388638
Validation loss: 2.5152678937160173

Epoch: 6| Step: 5
Training loss: 1.9513937028830788
Validation loss: 2.5380218877437244

Epoch: 6| Step: 6
Training loss: 2.1538875740910273
Validation loss: 2.5119751067223994

Epoch: 6| Step: 7
Training loss: 1.7675178981236308
Validation loss: 2.5157191099014007

Epoch: 6| Step: 8
Training loss: 2.8557031955311456
Validation loss: 2.54100201989416

Epoch: 6| Step: 9
Training loss: 1.9798975615541443
Validation loss: 2.5284330446786067

Epoch: 6| Step: 10
Training loss: 2.277901164127077
Validation loss: 2.5103201207845007

Epoch: 6| Step: 11
Training loss: 1.9442777524372479
Validation loss: 2.5305484694395526

Epoch: 6| Step: 12
Training loss: 2.351841704056619
Validation loss: 2.5477972564621805

Epoch: 6| Step: 13
Training loss: 2.0443898030709886
Validation loss: 2.580254956099997

Epoch: 268| Step: 0
Training loss: 2.5792453065714684
Validation loss: 2.5718839686172856

Epoch: 6| Step: 1
Training loss: 2.075144300843614
Validation loss: 2.549740932119955

Epoch: 6| Step: 2
Training loss: 2.325090312229177
Validation loss: 2.5760683121301318

Epoch: 6| Step: 3
Training loss: 1.851175581668154
Validation loss: 2.574882333036119

Epoch: 6| Step: 4
Training loss: 1.6502805413545116
Validation loss: 2.5863130571419712

Epoch: 6| Step: 5
Training loss: 2.376995051820553
Validation loss: 2.5859628005773296

Epoch: 6| Step: 6
Training loss: 2.310144926371734
Validation loss: 2.5801988602794044

Epoch: 6| Step: 7
Training loss: 2.4247075405932295
Validation loss: 2.567585574008264

Epoch: 6| Step: 8
Training loss: 2.0438425445602078
Validation loss: 2.5759639275268187

Epoch: 6| Step: 9
Training loss: 2.572760161506084
Validation loss: 2.5481558857177258

Epoch: 6| Step: 10
Training loss: 1.7698312803987506
Validation loss: 2.5403984897891942

Epoch: 6| Step: 11
Training loss: 1.7649616582018108
Validation loss: 2.5324455859911907

Epoch: 6| Step: 12
Training loss: 2.6266317291485817
Validation loss: 2.5495540983250087

Epoch: 6| Step: 13
Training loss: 1.6786108070322898
Validation loss: 2.549510473748156

Epoch: 269| Step: 0
Training loss: 1.7091791183685203
Validation loss: 2.535456846781317

Epoch: 6| Step: 1
Training loss: 1.4773069251043616
Validation loss: 2.5472861116144427

Epoch: 6| Step: 2
Training loss: 2.8568986686171742
Validation loss: 2.5277475685950783

Epoch: 6| Step: 3
Training loss: 2.6323081419207397
Validation loss: 2.523803109688247

Epoch: 6| Step: 4
Training loss: 1.9876155075960684
Validation loss: 2.546903660774838

Epoch: 6| Step: 5
Training loss: 2.300403194746181
Validation loss: 2.582990521070825

Epoch: 6| Step: 6
Training loss: 2.3784772614536287
Validation loss: 2.56730212750716

Epoch: 6| Step: 7
Training loss: 1.9690321462786262
Validation loss: 2.5680890578051536

Epoch: 6| Step: 8
Training loss: 2.126002355794956
Validation loss: 2.5532784887811357

Epoch: 6| Step: 9
Training loss: 2.5319054779199583
Validation loss: 2.542011571109987

Epoch: 6| Step: 10
Training loss: 2.6565541710323073
Validation loss: 2.5162963761087465

Epoch: 6| Step: 11
Training loss: 1.7495694311973098
Validation loss: 2.505157483404996

Epoch: 6| Step: 12
Training loss: 2.280412912289594
Validation loss: 2.4981507694053215

Epoch: 6| Step: 13
Training loss: 2.1058821405033954
Validation loss: 2.521415664205497

Epoch: 270| Step: 0
Training loss: 1.8956466694696013
Validation loss: 2.5374217361131786

Epoch: 6| Step: 1
Training loss: 2.025106676847495
Validation loss: 2.507451650420233

Epoch: 6| Step: 2
Training loss: 2.150822983186874
Validation loss: 2.534247040879488

Epoch: 6| Step: 3
Training loss: 2.043681908269362
Validation loss: 2.5214751716443837

Epoch: 6| Step: 4
Training loss: 1.6597243521378318
Validation loss: 2.5178974699780166

Epoch: 6| Step: 5
Training loss: 2.0535042840631053
Validation loss: 2.5231330459588652

Epoch: 6| Step: 6
Training loss: 1.8805287546902325
Validation loss: 2.5112574318319645

Epoch: 6| Step: 7
Training loss: 2.6847214640628194
Validation loss: 2.5463321239827943

Epoch: 6| Step: 8
Training loss: 2.355777245811829
Validation loss: 2.5088563293570196

Epoch: 6| Step: 9
Training loss: 2.3304431817969697
Validation loss: 2.5458766486129685

Epoch: 6| Step: 10
Training loss: 2.9274485259576037
Validation loss: 2.579525992692202

Epoch: 6| Step: 11
Training loss: 1.5900214468511213
Validation loss: 2.583558708532351

Epoch: 6| Step: 12
Training loss: 1.9217130391176946
Validation loss: 2.574027147432008

Epoch: 6| Step: 13
Training loss: 2.6341997334923932
Validation loss: 2.5805393666294663

Epoch: 271| Step: 0
Training loss: 2.24571816662807
Validation loss: 2.5933280662917886

Epoch: 6| Step: 1
Training loss: 2.1466519791039413
Validation loss: 2.59511659615056

Epoch: 6| Step: 2
Training loss: 2.7570542111606744
Validation loss: 2.577990233627003

Epoch: 6| Step: 3
Training loss: 2.2758850346376134
Validation loss: 2.575457848272764

Epoch: 6| Step: 4
Training loss: 2.4244849139731715
Validation loss: 2.5897995459311645

Epoch: 6| Step: 5
Training loss: 2.1600191648833986
Validation loss: 2.5734873896728927

Epoch: 6| Step: 6
Training loss: 1.6594307784136577
Validation loss: 2.561721877452651

Epoch: 6| Step: 7
Training loss: 2.184195174645252
Validation loss: 2.568319349859426

Epoch: 6| Step: 8
Training loss: 1.9773192634407764
Validation loss: 2.578328889433227

Epoch: 6| Step: 9
Training loss: 1.5047430707547302
Validation loss: 2.567456437471531

Epoch: 6| Step: 10
Training loss: 2.6501151653672474
Validation loss: 2.541676041841153

Epoch: 6| Step: 11
Training loss: 2.1264735330082227
Validation loss: 2.538581513060944

Epoch: 6| Step: 12
Training loss: 1.9699220347588795
Validation loss: 2.5543236740751385

Epoch: 6| Step: 13
Training loss: 1.6021135824230743
Validation loss: 2.5336322171010917

Epoch: 272| Step: 0
Training loss: 1.910049217049368
Validation loss: 2.5344328629504433

Epoch: 6| Step: 1
Training loss: 2.122740385643645
Validation loss: 2.542919902654651

Epoch: 6| Step: 2
Training loss: 2.924269730136029
Validation loss: 2.553354566907449

Epoch: 6| Step: 3
Training loss: 1.3671264634812974
Validation loss: 2.5528647387800696

Epoch: 6| Step: 4
Training loss: 2.5377619302796335
Validation loss: 2.578600521738693

Epoch: 6| Step: 5
Training loss: 2.1397624261840456
Validation loss: 2.5444372949772784

Epoch: 6| Step: 6
Training loss: 2.2712548124339
Validation loss: 2.5878706330300902

Epoch: 6| Step: 7
Training loss: 2.0667557015262497
Validation loss: 2.5992862339124336

Epoch: 6| Step: 8
Training loss: 2.3723782574658245
Validation loss: 2.5827978999530434

Epoch: 6| Step: 9
Training loss: 2.0302809531186052
Validation loss: 2.5604092822629276

Epoch: 6| Step: 10
Training loss: 1.85509504871597
Validation loss: 2.594955133725236

Epoch: 6| Step: 11
Training loss: 2.2556606717141583
Validation loss: 2.606487496316837

Epoch: 6| Step: 12
Training loss: 2.321641329562938
Validation loss: 2.570976666226781

Epoch: 6| Step: 13
Training loss: 2.2416287566693667
Validation loss: 2.5915742197342513

Epoch: 273| Step: 0
Training loss: 1.3333112993009193
Validation loss: 2.564247543411638

Epoch: 6| Step: 1
Training loss: 2.2913948129029693
Validation loss: 2.5569469014914072

Epoch: 6| Step: 2
Training loss: 2.271606127164799
Validation loss: 2.5708807304584185

Epoch: 6| Step: 3
Training loss: 2.3534260712993067
Validation loss: 2.558172526156902

Epoch: 6| Step: 4
Training loss: 1.6110084170282035
Validation loss: 2.5478593293229164

Epoch: 6| Step: 5
Training loss: 1.8717806198450486
Validation loss: 2.516377243763847

Epoch: 6| Step: 6
Training loss: 2.1248365227142765
Validation loss: 2.533129869204294

Epoch: 6| Step: 7
Training loss: 2.6124633969019717
Validation loss: 2.5205848718525132

Epoch: 6| Step: 8
Training loss: 2.5172483525654856
Validation loss: 2.557538897857739

Epoch: 6| Step: 9
Training loss: 2.798882131860739
Validation loss: 2.5101312868199033

Epoch: 6| Step: 10
Training loss: 2.2644724051625524
Validation loss: 2.5574527904668973

Epoch: 6| Step: 11
Training loss: 1.8520668083400587
Validation loss: 2.536767072641277

Epoch: 6| Step: 12
Training loss: 2.2462162415648295
Validation loss: 2.6007958887401945

Epoch: 6| Step: 13
Training loss: 2.493756030847432
Validation loss: 2.60533505487076

Epoch: 274| Step: 0
Training loss: 2.660759990369082
Validation loss: 2.6015594604596624

Epoch: 6| Step: 1
Training loss: 2.0152490546173767
Validation loss: 2.5647450823459246

Epoch: 6| Step: 2
Training loss: 2.021419505677169
Validation loss: 2.5895943653447637

Epoch: 6| Step: 3
Training loss: 1.8575637715047386
Validation loss: 2.5951180890703007

Epoch: 6| Step: 4
Training loss: 2.450065600237081
Validation loss: 2.5548144978756686

Epoch: 6| Step: 5
Training loss: 1.8007143219200792
Validation loss: 2.55083014931574

Epoch: 6| Step: 6
Training loss: 2.045623513188275
Validation loss: 2.565531945099513

Epoch: 6| Step: 7
Training loss: 1.5158018028722688
Validation loss: 2.553312423469376

Epoch: 6| Step: 8
Training loss: 2.090132591750732
Validation loss: 2.546765658599986

Epoch: 6| Step: 9
Training loss: 2.558148480756574
Validation loss: 2.540464935328025

Epoch: 6| Step: 10
Training loss: 1.421933937947227
Validation loss: 2.5527118194447516

Epoch: 6| Step: 11
Training loss: 2.494341741353067
Validation loss: 2.5815035328343074

Epoch: 6| Step: 12
Training loss: 2.4196032298155594
Validation loss: 2.565933060049678

Epoch: 6| Step: 13
Training loss: 2.3061651116025184
Validation loss: 2.6036749846099654

Epoch: 275| Step: 0
Training loss: 2.6300314865838326
Validation loss: 2.584765396244984

Epoch: 6| Step: 1
Training loss: 1.9106217579662805
Validation loss: 2.6021159349959118

Epoch: 6| Step: 2
Training loss: 1.3906643465454946
Validation loss: 2.560381036504822

Epoch: 6| Step: 3
Training loss: 1.6524669700472587
Validation loss: 2.5790170686770075

Epoch: 6| Step: 4
Training loss: 2.889977294938282
Validation loss: 2.597665160505649

Epoch: 6| Step: 5
Training loss: 1.5563786955172136
Validation loss: 2.5293676967843752

Epoch: 6| Step: 6
Training loss: 2.445355399733515
Validation loss: 2.569508930347901

Epoch: 6| Step: 7
Training loss: 1.7608796212569051
Validation loss: 2.554469076884732

Epoch: 6| Step: 8
Training loss: 2.1705505943561674
Validation loss: 2.541824122278407

Epoch: 6| Step: 9
Training loss: 2.665245621260669
Validation loss: 2.580644828786111

Epoch: 6| Step: 10
Training loss: 1.81783587892715
Validation loss: 2.567931985045504

Epoch: 6| Step: 11
Training loss: 1.7329325133058724
Validation loss: 2.540978734664678

Epoch: 6| Step: 12
Training loss: 1.9701024814033012
Validation loss: 2.554798819851208

Epoch: 6| Step: 13
Training loss: 2.6278986594113065
Validation loss: 2.5588655206133484

Epoch: 276| Step: 0
Training loss: 2.1087573242060307
Validation loss: 2.586471502480772

Epoch: 6| Step: 1
Training loss: 2.1729740134035764
Validation loss: 2.515603454371211

Epoch: 6| Step: 2
Training loss: 1.7446603374495158
Validation loss: 2.5542003855468325

Epoch: 6| Step: 3
Training loss: 1.9777235759792138
Validation loss: 2.5637446536401

Epoch: 6| Step: 4
Training loss: 1.8731534130040395
Validation loss: 2.5596509152067815

Epoch: 6| Step: 5
Training loss: 2.2611601935372474
Validation loss: 2.551658351053267

Epoch: 6| Step: 6
Training loss: 2.925305968363809
Validation loss: 2.534936269376614

Epoch: 6| Step: 7
Training loss: 1.9271261536935655
Validation loss: 2.5362938521448166

Epoch: 6| Step: 8
Training loss: 2.5453773260789254
Validation loss: 2.564181342229129

Epoch: 6| Step: 9
Training loss: 2.082684899189684
Validation loss: 2.5810774264402645

Epoch: 6| Step: 10
Training loss: 1.8356832774662049
Validation loss: 2.584191200396579

Epoch: 6| Step: 11
Training loss: 2.271868291999747
Validation loss: 2.5672137317334998

Epoch: 6| Step: 12
Training loss: 1.784797816112521
Validation loss: 2.543348308467483

Epoch: 6| Step: 13
Training loss: 1.9787042646490425
Validation loss: 2.5236640726103943

Epoch: 277| Step: 0
Training loss: 1.668410803221702
Validation loss: 2.569787680121954

Epoch: 6| Step: 1
Training loss: 2.590536309761433
Validation loss: 2.5616801896624586

Epoch: 6| Step: 2
Training loss: 2.2073871696901843
Validation loss: 2.543272032576018

Epoch: 6| Step: 3
Training loss: 2.861058807717993
Validation loss: 2.548837853190247

Epoch: 6| Step: 4
Training loss: 2.3155940209503134
Validation loss: 2.5232752697646

Epoch: 6| Step: 5
Training loss: 1.6917512819272056
Validation loss: 2.541180569384683

Epoch: 6| Step: 6
Training loss: 2.4248560125332297
Validation loss: 2.56340449737494

Epoch: 6| Step: 7
Training loss: 1.6215105738828808
Validation loss: 2.5533090774871385

Epoch: 6| Step: 8
Training loss: 1.950296780425554
Validation loss: 2.5524013139538515

Epoch: 6| Step: 9
Training loss: 2.2263160970772375
Validation loss: 2.5424584473921894

Epoch: 6| Step: 10
Training loss: 1.7287139606373974
Validation loss: 2.518505697968312

Epoch: 6| Step: 11
Training loss: 2.3546384040559136
Validation loss: 2.53732269932992

Epoch: 6| Step: 12
Training loss: 2.374733960158645
Validation loss: 2.5316088543741535

Epoch: 6| Step: 13
Training loss: 1.815100021758927
Validation loss: 2.5821475158153917

Epoch: 278| Step: 0
Training loss: 2.4735543546948553
Validation loss: 2.5759717021428403

Epoch: 6| Step: 1
Training loss: 1.9919136008671918
Validation loss: 2.6133999723903925

Epoch: 6| Step: 2
Training loss: 1.9877435522981224
Validation loss: 2.6327691833977602

Epoch: 6| Step: 3
Training loss: 2.168229700828069
Validation loss: 2.639816687148762

Epoch: 6| Step: 4
Training loss: 1.75669574443245
Validation loss: 2.6100996613992975

Epoch: 6| Step: 5
Training loss: 2.095399349270292
Validation loss: 2.5841572329601066

Epoch: 6| Step: 6
Training loss: 1.925050794253316
Validation loss: 2.54667985788727

Epoch: 6| Step: 7
Training loss: 2.4023699503144447
Validation loss: 2.549122277212434

Epoch: 6| Step: 8
Training loss: 3.1340965626537556
Validation loss: 2.5518174999646854

Epoch: 6| Step: 9
Training loss: 2.642345703008784
Validation loss: 2.5629561878825102

Epoch: 6| Step: 10
Training loss: 1.577844802607377
Validation loss: 2.549351071707345

Epoch: 6| Step: 11
Training loss: 1.7704379219951283
Validation loss: 2.5379159617753135

Epoch: 6| Step: 12
Training loss: 2.239964782403936
Validation loss: 2.548488301001396

Epoch: 6| Step: 13
Training loss: 1.3446047082901693
Validation loss: 2.5496151621274445

Epoch: 279| Step: 0
Training loss: 2.640064067063192
Validation loss: 2.5612104008649466

Epoch: 6| Step: 1
Training loss: 2.59038868230052
Validation loss: 2.556124392954474

Epoch: 6| Step: 2
Training loss: 2.2355546304933838
Validation loss: 2.5049833380423574

Epoch: 6| Step: 3
Training loss: 2.4311392516185695
Validation loss: 2.516778259034822

Epoch: 6| Step: 4
Training loss: 1.7190898905979806
Validation loss: 2.5527054060965866

Epoch: 6| Step: 5
Training loss: 2.048987077887296
Validation loss: 2.61837173922624

Epoch: 6| Step: 6
Training loss: 2.2367344915999947
Validation loss: 2.6297155441085307

Epoch: 6| Step: 7
Training loss: 2.288248900513378
Validation loss: 2.6036639275061693

Epoch: 6| Step: 8
Training loss: 2.024928659194961
Validation loss: 2.5395818404166444

Epoch: 6| Step: 9
Training loss: 2.032180103685674
Validation loss: 2.5321720939806887

Epoch: 6| Step: 10
Training loss: 2.1070707946166904
Validation loss: 2.520710608487361

Epoch: 6| Step: 11
Training loss: 1.833122725382921
Validation loss: 2.5377831625208573

Epoch: 6| Step: 12
Training loss: 1.8543887558990322
Validation loss: 2.5592597075326644

Epoch: 6| Step: 13
Training loss: 2.833006465981238
Validation loss: 2.5494599749135336

Epoch: 280| Step: 0
Training loss: 2.337316099878391
Validation loss: 2.5627902339542823

Epoch: 6| Step: 1
Training loss: 2.298601085824095
Validation loss: 2.5628513855099175

Epoch: 6| Step: 2
Training loss: 1.763457664416371
Validation loss: 2.552356803929941

Epoch: 6| Step: 3
Training loss: 2.4584961422387037
Validation loss: 2.566899810044466

Epoch: 6| Step: 4
Training loss: 1.5879444521405988
Validation loss: 2.6035704782234923

Epoch: 6| Step: 5
Training loss: 2.1814021541135395
Validation loss: 2.5775773362583516

Epoch: 6| Step: 6
Training loss: 1.995071896091705
Validation loss: 2.5501980156153903

Epoch: 6| Step: 7
Training loss: 1.4159503790194545
Validation loss: 2.5607703814810363

Epoch: 6| Step: 8
Training loss: 2.437349070253355
Validation loss: 2.560280668424816

Epoch: 6| Step: 9
Training loss: 2.4252908551902155
Validation loss: 2.58513881800056

Epoch: 6| Step: 10
Training loss: 2.1941140592792694
Validation loss: 2.6242964573785708

Epoch: 6| Step: 11
Training loss: 2.007560743883198
Validation loss: 2.5967154651638436

Epoch: 6| Step: 12
Training loss: 2.4873126433851462
Validation loss: 2.619528320505029

Epoch: 6| Step: 13
Training loss: 1.9369189098559454
Validation loss: 2.6223099109522834

Epoch: 281| Step: 0
Training loss: 2.3434742065924494
Validation loss: 2.6209020113374

Epoch: 6| Step: 1
Training loss: 2.5221735856701937
Validation loss: 2.5937732710809334

Epoch: 6| Step: 2
Training loss: 1.9771162018959736
Validation loss: 2.552945335289058

Epoch: 6| Step: 3
Training loss: 2.033031914471288
Validation loss: 2.547954198062316

Epoch: 6| Step: 4
Training loss: 2.250656773820411
Validation loss: 2.5537435827362898

Epoch: 6| Step: 5
Training loss: 1.8706474010733438
Validation loss: 2.5532271228974204

Epoch: 6| Step: 6
Training loss: 2.4661908949562257
Validation loss: 2.5565885417578507

Epoch: 6| Step: 7
Training loss: 2.0140656346192394
Validation loss: 2.5469289512614686

Epoch: 6| Step: 8
Training loss: 1.903876343289905
Validation loss: 2.5528422310733396

Epoch: 6| Step: 9
Training loss: 2.253771482038388
Validation loss: 2.571904223906805

Epoch: 6| Step: 10
Training loss: 2.4085781179806145
Validation loss: 2.581031532679276

Epoch: 6| Step: 11
Training loss: 2.0173596155799784
Validation loss: 2.617250902916715

Epoch: 6| Step: 12
Training loss: 2.104277038197468
Validation loss: 2.6552060637695702

Epoch: 6| Step: 13
Training loss: 2.2961890824844438
Validation loss: 2.6421660792563215

Epoch: 282| Step: 0
Training loss: 1.947609950378691
Validation loss: 2.591924737508724

Epoch: 6| Step: 1
Training loss: 2.2112733835177534
Validation loss: 2.6374523432736474

Epoch: 6| Step: 2
Training loss: 2.277819523260808
Validation loss: 2.5882271640207057

Epoch: 6| Step: 3
Training loss: 2.2169462582170345
Validation loss: 2.5568882351407423

Epoch: 6| Step: 4
Training loss: 2.0685701920197785
Validation loss: 2.5683510203642634

Epoch: 6| Step: 5
Training loss: 2.0683081947456836
Validation loss: 2.5765478377024316

Epoch: 6| Step: 6
Training loss: 1.9547921351687318
Validation loss: 2.5420310014674627

Epoch: 6| Step: 7
Training loss: 2.3187480751708236
Validation loss: 2.559129366733816

Epoch: 6| Step: 8
Training loss: 2.1179478254871142
Validation loss: 2.54227654899594

Epoch: 6| Step: 9
Training loss: 2.0982662855389203
Validation loss: 2.528005553615683

Epoch: 6| Step: 10
Training loss: 2.0393587679133693
Validation loss: 2.5475336639006905

Epoch: 6| Step: 11
Training loss: 2.571970488952959
Validation loss: 2.535974951291451

Epoch: 6| Step: 12
Training loss: 2.1343129228581836
Validation loss: 2.5560868345633017

Epoch: 6| Step: 13
Training loss: 2.3901744742134197
Validation loss: 2.5411383804198446

Epoch: 283| Step: 0
Training loss: 1.6177163848709337
Validation loss: 2.563315765666248

Epoch: 6| Step: 1
Training loss: 1.5588619603723646
Validation loss: 2.5345308838366973

Epoch: 6| Step: 2
Training loss: 2.2056388851516733
Validation loss: 2.5628161506702805

Epoch: 6| Step: 3
Training loss: 1.9290093222511993
Validation loss: 2.5873249476953086

Epoch: 6| Step: 4
Training loss: 2.69850840516802
Validation loss: 2.584019451907651

Epoch: 6| Step: 5
Training loss: 2.2201043951559183
Validation loss: 2.6151438766976596

Epoch: 6| Step: 6
Training loss: 1.9842891524360717
Validation loss: 2.578635040077752

Epoch: 6| Step: 7
Training loss: 2.1619120906704015
Validation loss: 2.605026077877048

Epoch: 6| Step: 8
Training loss: 1.3287299181047756
Validation loss: 2.5757686134516673

Epoch: 6| Step: 9
Training loss: 2.4106231187808644
Validation loss: 2.5711027899627346

Epoch: 6| Step: 10
Training loss: 1.984877034757854
Validation loss: 2.54539754252062

Epoch: 6| Step: 11
Training loss: 2.055106232767592
Validation loss: 2.580704756594688

Epoch: 6| Step: 12
Training loss: 2.799779992315663
Validation loss: 2.539516326253963

Epoch: 6| Step: 13
Training loss: 2.0635726913541093
Validation loss: 2.549957313678972

Epoch: 284| Step: 0
Training loss: 1.9900285578839938
Validation loss: 2.5497898435945867

Epoch: 6| Step: 1
Training loss: 1.8770124443913916
Validation loss: 2.547673464937917

Epoch: 6| Step: 2
Training loss: 2.231436016973254
Validation loss: 2.5420456171252104

Epoch: 6| Step: 3
Training loss: 2.7934930055939367
Validation loss: 2.546976894844495

Epoch: 6| Step: 4
Training loss: 2.090112059294945
Validation loss: 2.5554353200805044

Epoch: 6| Step: 5
Training loss: 2.029507050630963
Validation loss: 2.5660019802443648

Epoch: 6| Step: 6
Training loss: 1.8544453257926938
Validation loss: 2.5949984843372778

Epoch: 6| Step: 7
Training loss: 1.8425765101620017
Validation loss: 2.5649915847987295

Epoch: 6| Step: 8
Training loss: 1.4547708686187955
Validation loss: 2.5767409954314044

Epoch: 6| Step: 9
Training loss: 1.8703671121551424
Validation loss: 2.5620185120574126

Epoch: 6| Step: 10
Training loss: 2.8577125594411514
Validation loss: 2.584214080880751

Epoch: 6| Step: 11
Training loss: 1.660406906054569
Validation loss: 2.5016526322942183

Epoch: 6| Step: 12
Training loss: 2.3526677674034846
Validation loss: 2.5563841619004237

Epoch: 6| Step: 13
Training loss: 2.303855823522517
Validation loss: 2.5254736874622647

Epoch: 285| Step: 0
Training loss: 2.0703394474219126
Validation loss: 2.5385221248642074

Epoch: 6| Step: 1
Training loss: 1.9947322375124281
Validation loss: 2.5744078995517268

Epoch: 6| Step: 2
Training loss: 1.4041970844917147
Validation loss: 2.569599303885667

Epoch: 6| Step: 3
Training loss: 2.743843209110692
Validation loss: 2.506818263317654

Epoch: 6| Step: 4
Training loss: 2.6036696506506423
Validation loss: 2.54594214738052

Epoch: 6| Step: 5
Training loss: 1.9248224003101158
Validation loss: 2.5714785357192693

Epoch: 6| Step: 6
Training loss: 1.9505960800535158
Validation loss: 2.5385052896073472

Epoch: 6| Step: 7
Training loss: 2.84317580913327
Validation loss: 2.5817160209566383

Epoch: 6| Step: 8
Training loss: 1.6084599532388413
Validation loss: 2.5956085471055794

Epoch: 6| Step: 9
Training loss: 2.338480913920772
Validation loss: 2.6111149725874174

Epoch: 6| Step: 10
Training loss: 1.8462828356509629
Validation loss: 2.6524474957513275

Epoch: 6| Step: 11
Training loss: 2.6243432449560005
Validation loss: 2.621816960792312

Epoch: 6| Step: 12
Training loss: 1.1050235134747275
Validation loss: 2.6214587681819053

Epoch: 6| Step: 13
Training loss: 2.416331092511727
Validation loss: 2.5772016316684767

Epoch: 286| Step: 0
Training loss: 2.195377769721724
Validation loss: 2.5200003805740514

Epoch: 6| Step: 1
Training loss: 1.6641814140133757
Validation loss: 2.5228732868962362

Epoch: 6| Step: 2
Training loss: 1.9684054360788867
Validation loss: 2.5876061778620403

Epoch: 6| Step: 3
Training loss: 2.364658024038189
Validation loss: 2.6192857065396105

Epoch: 6| Step: 4
Training loss: 3.0316759577086776
Validation loss: 2.606932999288774

Epoch: 6| Step: 5
Training loss: 2.1650780453611556
Validation loss: 2.611515028015676

Epoch: 6| Step: 6
Training loss: 2.283484318421479
Validation loss: 2.591897670737768

Epoch: 6| Step: 7
Training loss: 2.2019657845883533
Validation loss: 2.578169296346495

Epoch: 6| Step: 8
Training loss: 2.4346059589247564
Validation loss: 2.5724871247281076

Epoch: 6| Step: 9
Training loss: 2.6306824713166312
Validation loss: 2.5676596806516283

Epoch: 6| Step: 10
Training loss: 2.3893154771292275
Validation loss: 2.584563213784404

Epoch: 6| Step: 11
Training loss: 2.3425892307869978
Validation loss: 2.6623336984817154

Epoch: 6| Step: 12
Training loss: 2.48637242663546
Validation loss: 2.7324459864707116

Epoch: 6| Step: 13
Training loss: 2.2273234890618734
Validation loss: 2.6405561464501073

Epoch: 287| Step: 0
Training loss: 2.3697962722454102
Validation loss: 2.6020122211920893

Epoch: 6| Step: 1
Training loss: 2.085484830623269
Validation loss: 2.5078325914507036

Epoch: 6| Step: 2
Training loss: 2.2856584567676888
Validation loss: 2.4923341442879092

Epoch: 6| Step: 3
Training loss: 2.0367375123125906
Validation loss: 2.514259220358877

Epoch: 6| Step: 4
Training loss: 2.516016106382649
Validation loss: 2.5117494414151627

Epoch: 6| Step: 5
Training loss: 1.9115700199714531
Validation loss: 2.5100117484801827

Epoch: 6| Step: 6
Training loss: 3.413115695283365
Validation loss: 2.4918591911886687

Epoch: 6| Step: 7
Training loss: 1.8591518749068692
Validation loss: 2.5157146398397017

Epoch: 6| Step: 8
Training loss: 2.2350652735521113
Validation loss: 2.53204835460064

Epoch: 6| Step: 9
Training loss: 2.0588934606007405
Validation loss: 2.5250318625929413

Epoch: 6| Step: 10
Training loss: 2.3290391189873643
Validation loss: 2.5309811987046067

Epoch: 6| Step: 11
Training loss: 2.779591097776326
Validation loss: 2.51685328539024

Epoch: 6| Step: 12
Training loss: 1.8351365310434509
Validation loss: 2.527894759411502

Epoch: 6| Step: 13
Training loss: 1.7530505295438323
Validation loss: 2.528770771076444

Epoch: 288| Step: 0
Training loss: 1.3941204844500596
Validation loss: 2.4999553676435826

Epoch: 6| Step: 1
Training loss: 2.375630746707524
Validation loss: 2.482191689916887

Epoch: 6| Step: 2
Training loss: 2.1030923599952547
Validation loss: 2.51966287431744

Epoch: 6| Step: 3
Training loss: 2.502169716577567
Validation loss: 2.5128126911412636

Epoch: 6| Step: 4
Training loss: 2.748263764650834
Validation loss: 2.5253471652031125

Epoch: 6| Step: 5
Training loss: 2.1044696426069094
Validation loss: 2.562623168342275

Epoch: 6| Step: 6
Training loss: 2.7309101932136906
Validation loss: 2.5293226086106446

Epoch: 6| Step: 7
Training loss: 2.1584366477875156
Validation loss: 2.54668595874263

Epoch: 6| Step: 8
Training loss: 1.614214684844333
Validation loss: 2.4824930896643647

Epoch: 6| Step: 9
Training loss: 1.194730230390959
Validation loss: 2.534807068494834

Epoch: 6| Step: 10
Training loss: 2.447267183758482
Validation loss: 2.5623696146722543

Epoch: 6| Step: 11
Training loss: 2.2516003321606908
Validation loss: 2.533788373719603

Epoch: 6| Step: 12
Training loss: 2.5270742187167903
Validation loss: 2.5335457520354874

Epoch: 6| Step: 13
Training loss: 2.166534994477057
Validation loss: 2.5626188111092576

Epoch: 289| Step: 0
Training loss: 2.000027894779225
Validation loss: 2.5157976742828994

Epoch: 6| Step: 1
Training loss: 2.3777643479159094
Validation loss: 2.5175250284313924

Epoch: 6| Step: 2
Training loss: 1.837803513249215
Validation loss: 2.5541079735870538

Epoch: 6| Step: 3
Training loss: 2.052135899317484
Validation loss: 2.556954967038077

Epoch: 6| Step: 4
Training loss: 1.8471757130834883
Validation loss: 2.5475805510569307

Epoch: 6| Step: 5
Training loss: 1.5268880256912318
Validation loss: 2.502863055178346

Epoch: 6| Step: 6
Training loss: 2.480125199203287
Validation loss: 2.5070226817956924

Epoch: 6| Step: 7
Training loss: 1.3823683720540259
Validation loss: 2.5368130936469866

Epoch: 6| Step: 8
Training loss: 2.151912916094843
Validation loss: 2.528865483831119

Epoch: 6| Step: 9
Training loss: 1.8124978953382176
Validation loss: 2.5188906621662652

Epoch: 6| Step: 10
Training loss: 2.7846485761341446
Validation loss: 2.5292279679621843

Epoch: 6| Step: 11
Training loss: 2.4266407007707604
Validation loss: 2.52194141172865

Epoch: 6| Step: 12
Training loss: 2.5929580766412785
Validation loss: 2.5195679969966407

Epoch: 6| Step: 13
Training loss: 1.9452702161490751
Validation loss: 2.5289641054622165

Epoch: 290| Step: 0
Training loss: 1.93859045044855
Validation loss: 2.545777940745825

Epoch: 6| Step: 1
Training loss: 2.128294018546856
Validation loss: 2.514136448561508

Epoch: 6| Step: 2
Training loss: 1.7667643154196415
Validation loss: 2.5182826849462008

Epoch: 6| Step: 3
Training loss: 1.8165032473681335
Validation loss: 2.5220344666362684

Epoch: 6| Step: 4
Training loss: 1.768007409671429
Validation loss: 2.546921665255601

Epoch: 6| Step: 5
Training loss: 1.5664226883099428
Validation loss: 2.5189861644401765

Epoch: 6| Step: 6
Training loss: 2.4182801177122073
Validation loss: 2.527262517850969

Epoch: 6| Step: 7
Training loss: 2.0620549039588925
Validation loss: 2.5016029305400544

Epoch: 6| Step: 8
Training loss: 2.657291701758093
Validation loss: 2.509762759275074

Epoch: 6| Step: 9
Training loss: 2.8475678355616045
Validation loss: 2.5177098750997633

Epoch: 6| Step: 10
Training loss: 1.6438542148058362
Validation loss: 2.532492077794037

Epoch: 6| Step: 11
Training loss: 1.8384238431385358
Validation loss: 2.5525470519952096

Epoch: 6| Step: 12
Training loss: 1.9175712966097993
Validation loss: 2.5322423959696283

Epoch: 6| Step: 13
Training loss: 2.6513452462259717
Validation loss: 2.55185561169713

Epoch: 291| Step: 0
Training loss: 1.785907078281129
Validation loss: 2.5747203502217695

Epoch: 6| Step: 1
Training loss: 2.134359169226899
Validation loss: 2.6240251335514304

Epoch: 6| Step: 2
Training loss: 2.479139269081697
Validation loss: 2.6482735342096824

Epoch: 6| Step: 3
Training loss: 2.2564246324073443
Validation loss: 2.621812413968689

Epoch: 6| Step: 4
Training loss: 1.757893064560021
Validation loss: 2.5354743017407513

Epoch: 6| Step: 5
Training loss: 1.7493712794464333
Validation loss: 2.5168558825377882

Epoch: 6| Step: 6
Training loss: 2.0865788420373876
Validation loss: 2.505789331858146

Epoch: 6| Step: 7
Training loss: 2.358667027439818
Validation loss: 2.5256167863955974

Epoch: 6| Step: 8
Training loss: 2.041759359111053
Validation loss: 2.51025977904167

Epoch: 6| Step: 9
Training loss: 1.776422215595584
Validation loss: 2.5088713758523955

Epoch: 6| Step: 10
Training loss: 2.352498726758298
Validation loss: 2.572908236738184

Epoch: 6| Step: 11
Training loss: 1.9891652838077967
Validation loss: 2.5743392429892347

Epoch: 6| Step: 12
Training loss: 2.677671335759606
Validation loss: 2.5652168184642625

Epoch: 6| Step: 13
Training loss: 2.187054725014612
Validation loss: 2.573492515978008

Epoch: 292| Step: 0
Training loss: 2.6389418434942304
Validation loss: 2.5705572319048198

Epoch: 6| Step: 1
Training loss: 2.2085446190674123
Validation loss: 2.5807251736134966

Epoch: 6| Step: 2
Training loss: 1.6558543038476177
Validation loss: 2.5572504686402464

Epoch: 6| Step: 3
Training loss: 1.5498805276910756
Validation loss: 2.60605393243208

Epoch: 6| Step: 4
Training loss: 2.203543332471275
Validation loss: 2.6307998193590465

Epoch: 6| Step: 5
Training loss: 2.2176343235073386
Validation loss: 2.6415452952335934

Epoch: 6| Step: 6
Training loss: 2.18112561764813
Validation loss: 2.6316841492204066

Epoch: 6| Step: 7
Training loss: 2.0947703821538473
Validation loss: 2.612226972047847

Epoch: 6| Step: 8
Training loss: 2.241005615935466
Validation loss: 2.597186802867921

Epoch: 6| Step: 9
Training loss: 2.294574337880411
Validation loss: 2.5804902680520323

Epoch: 6| Step: 10
Training loss: 1.8504608997789491
Validation loss: 2.576984993475101

Epoch: 6| Step: 11
Training loss: 1.7249664939169422
Validation loss: 2.5620473446388656

Epoch: 6| Step: 12
Training loss: 2.21887357125906
Validation loss: 2.5762775082317266

Epoch: 6| Step: 13
Training loss: 2.004174762902459
Validation loss: 2.559508803102895

Epoch: 293| Step: 0
Training loss: 1.4386862131357705
Validation loss: 2.5373048146663604

Epoch: 6| Step: 1
Training loss: 2.5584699062048415
Validation loss: 2.5396504039424794

Epoch: 6| Step: 2
Training loss: 1.2132305461362252
Validation loss: 2.538707688800906

Epoch: 6| Step: 3
Training loss: 1.9755226385334783
Validation loss: 2.549511027047749

Epoch: 6| Step: 4
Training loss: 1.7877042186894054
Validation loss: 2.5483645664352714

Epoch: 6| Step: 5
Training loss: 2.544130215359241
Validation loss: 2.5274394202463766

Epoch: 6| Step: 6
Training loss: 2.3705040388477214
Validation loss: 2.5378344808659277

Epoch: 6| Step: 7
Training loss: 2.0285050845666603
Validation loss: 2.533497648389744

Epoch: 6| Step: 8
Training loss: 1.9105800790344591
Validation loss: 2.5719301801086987

Epoch: 6| Step: 9
Training loss: 1.8147546622340833
Validation loss: 2.529748950358756

Epoch: 6| Step: 10
Training loss: 2.201366290736276
Validation loss: 2.5412515603539334

Epoch: 6| Step: 11
Training loss: 3.114351976322181
Validation loss: 2.5330664941729766

Epoch: 6| Step: 12
Training loss: 2.3050192384061803
Validation loss: 2.6035836037539197

Epoch: 6| Step: 13
Training loss: 2.316584614002741
Validation loss: 2.658360200305726

Epoch: 294| Step: 0
Training loss: 2.122818444113269
Validation loss: 2.6828036415340426

Epoch: 6| Step: 1
Training loss: 2.2433766258940806
Validation loss: 2.681164970917042

Epoch: 6| Step: 2
Training loss: 1.6412869525825682
Validation loss: 2.6152234351432875

Epoch: 6| Step: 3
Training loss: 3.022295280193706
Validation loss: 2.569644365752364

Epoch: 6| Step: 4
Training loss: 1.9019421539334942
Validation loss: 2.5365916588513158

Epoch: 6| Step: 5
Training loss: 2.4095830251143937
Validation loss: 2.5436812504781168

Epoch: 6| Step: 6
Training loss: 2.4279686836975705
Validation loss: 2.50389020560565

Epoch: 6| Step: 7
Training loss: 2.3591076023582294
Validation loss: 2.528578600528225

Epoch: 6| Step: 8
Training loss: 1.5671791966409443
Validation loss: 2.5481627627467236

Epoch: 6| Step: 9
Training loss: 1.8374667677177297
Validation loss: 2.5441865676049895

Epoch: 6| Step: 10
Training loss: 2.279865837834628
Validation loss: 2.5456482911068803

Epoch: 6| Step: 11
Training loss: 1.2643164946539986
Validation loss: 2.5196020229759437

Epoch: 6| Step: 12
Training loss: 1.8874425032997242
Validation loss: 2.543711923350193

Epoch: 6| Step: 13
Training loss: 1.9644946779842625
Validation loss: 2.610769907885833

Epoch: 295| Step: 0
Training loss: 1.8860528058925048
Validation loss: 2.646421372155205

Epoch: 6| Step: 1
Training loss: 2.220981603924973
Validation loss: 2.8283807487836796

Epoch: 6| Step: 2
Training loss: 2.387830809198624
Validation loss: 2.809756643520556

Epoch: 6| Step: 3
Training loss: 2.7227012597718794
Validation loss: 2.8840819392140062

Epoch: 6| Step: 4
Training loss: 1.6126506764593094
Validation loss: 2.8308901818509375

Epoch: 6| Step: 5
Training loss: 2.0612069903085843
Validation loss: 2.724612029335251

Epoch: 6| Step: 6
Training loss: 2.5042808121633313
Validation loss: 2.6544385530237786

Epoch: 6| Step: 7
Training loss: 2.148268703418784
Validation loss: 2.571927661750585

Epoch: 6| Step: 8
Training loss: 2.3534513979177136
Validation loss: 2.5470328408849756

Epoch: 6| Step: 9
Training loss: 1.7779464873423574
Validation loss: 2.555247254249524

Epoch: 6| Step: 10
Training loss: 2.067535034399475
Validation loss: 2.536103716636742

Epoch: 6| Step: 11
Training loss: 2.0258248285857547
Validation loss: 2.5550884900380746

Epoch: 6| Step: 12
Training loss: 2.3022278154927913
Validation loss: 2.590222100439871

Epoch: 6| Step: 13
Training loss: 2.6568529230141453
Validation loss: 2.598780353901597

Epoch: 296| Step: 0
Training loss: 2.0577595882811095
Validation loss: 2.580689012591677

Epoch: 6| Step: 1
Training loss: 2.605277859445044
Validation loss: 2.537702930021806

Epoch: 6| Step: 2
Training loss: 2.1850275508444326
Validation loss: 2.540943298170588

Epoch: 6| Step: 3
Training loss: 1.9335258703165756
Validation loss: 2.5233918334482097

Epoch: 6| Step: 4
Training loss: 2.1562235733845387
Validation loss: 2.558968630595583

Epoch: 6| Step: 5
Training loss: 1.6473080349863949
Validation loss: 2.549697949715002

Epoch: 6| Step: 6
Training loss: 2.827441222425671
Validation loss: 2.5855580615270246

Epoch: 6| Step: 7
Training loss: 2.509589020567818
Validation loss: 2.6297299595270576

Epoch: 6| Step: 8
Training loss: 2.1764589962855276
Validation loss: 2.619020766991693

Epoch: 6| Step: 9
Training loss: 2.070929669212409
Validation loss: 2.6820381316324413

Epoch: 6| Step: 10
Training loss: 2.325741668046569
Validation loss: 2.6683621728527167

Epoch: 6| Step: 11
Training loss: 1.7759842252718088
Validation loss: 2.6263785299895597

Epoch: 6| Step: 12
Training loss: 2.015416807319658
Validation loss: 2.6421968946810623

Epoch: 6| Step: 13
Training loss: 1.595975780188561
Validation loss: 2.613849405167733

Epoch: 297| Step: 0
Training loss: 2.5523428233565046
Validation loss: 2.5987565771976557

Epoch: 6| Step: 1
Training loss: 2.22437947653577
Validation loss: 2.5785536284512274

Epoch: 6| Step: 2
Training loss: 1.7221996714370054
Validation loss: 2.5662807238424774

Epoch: 6| Step: 3
Training loss: 2.5016824782869564
Validation loss: 2.5565763562087342

Epoch: 6| Step: 4
Training loss: 2.1323612839727093
Validation loss: 2.575064852431805

Epoch: 6| Step: 5
Training loss: 2.018794207487494
Validation loss: 2.5673115690050574

Epoch: 6| Step: 6
Training loss: 1.884273547830784
Validation loss: 2.5666122624795196

Epoch: 6| Step: 7
Training loss: 2.167325090965072
Validation loss: 2.5641069568388555

Epoch: 6| Step: 8
Training loss: 2.25263441355837
Validation loss: 2.5946873575870817

Epoch: 6| Step: 9
Training loss: 2.2685456491291105
Validation loss: 2.6148840033513276

Epoch: 6| Step: 10
Training loss: 2.1888288548859745
Validation loss: 2.599684976175377

Epoch: 6| Step: 11
Training loss: 1.5856655996475548
Validation loss: 2.630863521037414

Epoch: 6| Step: 12
Training loss: 2.1609262815061516
Validation loss: 2.619651636485438

Epoch: 6| Step: 13
Training loss: 1.8917524270714734
Validation loss: 2.614927904947733

Epoch: 298| Step: 0
Training loss: 1.8875082508437344
Validation loss: 2.586150315239449

Epoch: 6| Step: 1
Training loss: 1.8952338420147443
Validation loss: 2.6026728249171494

Epoch: 6| Step: 2
Training loss: 2.121812224548029
Validation loss: 2.586935451981241

Epoch: 6| Step: 3
Training loss: 2.0038558031540057
Validation loss: 2.5778831907986093

Epoch: 6| Step: 4
Training loss: 2.1590962076806575
Validation loss: 2.551476368771196

Epoch: 6| Step: 5
Training loss: 2.381296144373789
Validation loss: 2.548515555946194

Epoch: 6| Step: 6
Training loss: 2.0136515101116195
Validation loss: 2.575717148404064

Epoch: 6| Step: 7
Training loss: 1.9337733329839837
Validation loss: 2.5932890394329458

Epoch: 6| Step: 8
Training loss: 2.6380989587832007
Validation loss: 2.564514825702825

Epoch: 6| Step: 9
Training loss: 1.1969796814719749
Validation loss: 2.606089718629508

Epoch: 6| Step: 10
Training loss: 1.9131450088985
Validation loss: 2.645970939201763

Epoch: 6| Step: 11
Training loss: 2.94999941163138
Validation loss: 2.6268712897240105

Epoch: 6| Step: 12
Training loss: 2.137158113320249
Validation loss: 2.650716500616239

Epoch: 6| Step: 13
Training loss: 1.6586556148625942
Validation loss: 2.573530229520267

Epoch: 299| Step: 0
Training loss: 2.5969439225398006
Validation loss: 2.565763070669504

Epoch: 6| Step: 1
Training loss: 2.204705070787863
Validation loss: 2.534480274677812

Epoch: 6| Step: 2
Training loss: 2.8081096714806186
Validation loss: 2.5182623139454656

Epoch: 6| Step: 3
Training loss: 2.1978404196098498
Validation loss: 2.5075999691788

Epoch: 6| Step: 4
Training loss: 2.1617461108705087
Validation loss: 2.493773709967642

Epoch: 6| Step: 5
Training loss: 2.2009924990687795
Validation loss: 2.5269586740447494

Epoch: 6| Step: 6
Training loss: 1.7085916122332447
Validation loss: 2.491932767248367

Epoch: 6| Step: 7
Training loss: 2.2529593185903614
Validation loss: 2.511228759812514

Epoch: 6| Step: 8
Training loss: 2.0468663805132206
Validation loss: 2.528003942469951

Epoch: 6| Step: 9
Training loss: 1.3746222063719378
Validation loss: 2.5145820050893173

Epoch: 6| Step: 10
Training loss: 1.754825003069279
Validation loss: 2.5104952809119077

Epoch: 6| Step: 11
Training loss: 2.26038644187397
Validation loss: 2.5307660523248154

Epoch: 6| Step: 12
Training loss: 1.7933249524900357
Validation loss: 2.5287912931290557

Epoch: 6| Step: 13
Training loss: 2.2288930374433136
Validation loss: 2.5734454446873403

Epoch: 300| Step: 0
Training loss: 1.774403044561968
Validation loss: 2.530163739877927

Epoch: 6| Step: 1
Training loss: 1.8388219373000605
Validation loss: 2.5769561738262228

Epoch: 6| Step: 2
Training loss: 1.670175276598036
Validation loss: 2.5444979818431936

Epoch: 6| Step: 3
Training loss: 2.484089193158706
Validation loss: 2.5707418359541943

Epoch: 6| Step: 4
Training loss: 2.5193566550152595
Validation loss: 2.5596217994794745

Epoch: 6| Step: 5
Training loss: 2.2102638539360213
Validation loss: 2.588776074445022

Epoch: 6| Step: 6
Training loss: 1.8283769482835448
Validation loss: 2.545735937233593

Epoch: 6| Step: 7
Training loss: 2.424006354874442
Validation loss: 2.555690339123051

Epoch: 6| Step: 8
Training loss: 2.2846885789470295
Validation loss: 2.5617797816371333

Epoch: 6| Step: 9
Training loss: 1.8276414802360832
Validation loss: 2.5093199733783194

Epoch: 6| Step: 10
Training loss: 1.410800733728545
Validation loss: 2.553490968059688

Epoch: 6| Step: 11
Training loss: 2.3421298721685457
Validation loss: 2.5437218429419217

Epoch: 6| Step: 12
Training loss: 2.3594132982391955
Validation loss: 2.5822596215745848

Epoch: 6| Step: 13
Training loss: 1.908580668494747
Validation loss: 2.560324031891242

Epoch: 301| Step: 0
Training loss: 1.8022345183648523
Validation loss: 2.5798014189938274

Epoch: 6| Step: 1
Training loss: 2.3441597135377195
Validation loss: 2.6330196702837902

Epoch: 6| Step: 2
Training loss: 2.178293089763659
Validation loss: 2.598835658743824

Epoch: 6| Step: 3
Training loss: 2.65520537535746
Validation loss: 2.5914256547031322

Epoch: 6| Step: 4
Training loss: 1.7243592717060738
Validation loss: 2.5800116985509245

Epoch: 6| Step: 5
Training loss: 1.8919609961168957
Validation loss: 2.602169649531645

Epoch: 6| Step: 6
Training loss: 2.846659084134273
Validation loss: 2.533289468431507

Epoch: 6| Step: 7
Training loss: 1.9595794838730918
Validation loss: 2.5918092782462336

Epoch: 6| Step: 8
Training loss: 2.239373118862647
Validation loss: 2.5739206113460775

Epoch: 6| Step: 9
Training loss: 1.6188737858754545
Validation loss: 2.593237569662162

Epoch: 6| Step: 10
Training loss: 2.372952632838016
Validation loss: 2.542887806031425

Epoch: 6| Step: 11
Training loss: 2.351300500614384
Validation loss: 2.5350471241901653

Epoch: 6| Step: 12
Training loss: 1.6193533873799735
Validation loss: 2.557088425608274

Epoch: 6| Step: 13
Training loss: 1.576615092796314
Validation loss: 2.532671109551173

Epoch: 302| Step: 0
Training loss: 1.8457626090985044
Validation loss: 2.5428547557745107

Epoch: 6| Step: 1
Training loss: 1.8440311023629545
Validation loss: 2.531511081370678

Epoch: 6| Step: 2
Training loss: 2.2304585952661244
Validation loss: 2.5812436901935985

Epoch: 6| Step: 3
Training loss: 2.0609000965394366
Validation loss: 2.5924153705101434

Epoch: 6| Step: 4
Training loss: 1.8588413787114049
Validation loss: 2.5895682025773255

Epoch: 6| Step: 5
Training loss: 1.8396733360982938
Validation loss: 2.5639548010003756

Epoch: 6| Step: 6
Training loss: 2.086972097929587
Validation loss: 2.5646261993056845

Epoch: 6| Step: 7
Training loss: 2.724555558524288
Validation loss: 2.5673969201181235

Epoch: 6| Step: 8
Training loss: 1.8678220045905123
Validation loss: 2.5740538232170906

Epoch: 6| Step: 9
Training loss: 1.8026435143086263
Validation loss: 2.578571735556166

Epoch: 6| Step: 10
Training loss: 2.055015856827865
Validation loss: 2.613873941507369

Epoch: 6| Step: 11
Training loss: 2.1751944882484744
Validation loss: 2.5419573591584146

Epoch: 6| Step: 12
Training loss: 2.216100588440136
Validation loss: 2.5587813213986315

Epoch: 6| Step: 13
Training loss: 2.284966354957143
Validation loss: 2.561996581086958

Epoch: 303| Step: 0
Training loss: 1.9614619431451477
Validation loss: 2.5571022248395185

Epoch: 6| Step: 1
Training loss: 2.3033269454639296
Validation loss: 2.601445772990938

Epoch: 6| Step: 2
Training loss: 1.983503435624736
Validation loss: 2.558365642289749

Epoch: 6| Step: 3
Training loss: 1.9260097159222813
Validation loss: 2.5817195763860115

Epoch: 6| Step: 4
Training loss: 1.8190938775246874
Validation loss: 2.5891462473273377

Epoch: 6| Step: 5
Training loss: 2.9040632327107687
Validation loss: 2.5669523806720407

Epoch: 6| Step: 6
Training loss: 1.9729542724290878
Validation loss: 2.5920856758584976

Epoch: 6| Step: 7
Training loss: 1.363838672080358
Validation loss: 2.5574411683884075

Epoch: 6| Step: 8
Training loss: 1.8423318096191628
Validation loss: 2.5391682685927957

Epoch: 6| Step: 9
Training loss: 2.105456860000924
Validation loss: 2.52703997099663

Epoch: 6| Step: 10
Training loss: 1.666913451361661
Validation loss: 2.5191573306646893

Epoch: 6| Step: 11
Training loss: 2.1521693884257926
Validation loss: 2.5491096818516983

Epoch: 6| Step: 12
Training loss: 1.712149691427982
Validation loss: 2.556723449313542

Epoch: 6| Step: 13
Training loss: 3.1571188759956392
Validation loss: 2.559048600085526

Epoch: 304| Step: 0
Training loss: 2.214649333191679
Validation loss: 2.5740647836736565

Epoch: 6| Step: 1
Training loss: 2.072571411006903
Validation loss: 2.5829620914943767

Epoch: 6| Step: 2
Training loss: 1.6793942927454475
Validation loss: 2.5638753642543706

Epoch: 6| Step: 3
Training loss: 1.9144703955923073
Validation loss: 2.5770608266239803

Epoch: 6| Step: 4
Training loss: 3.0347167964821815
Validation loss: 2.561597215368285

Epoch: 6| Step: 5
Training loss: 1.7907616155413564
Validation loss: 2.5871241556089335

Epoch: 6| Step: 6
Training loss: 1.996609973781909
Validation loss: 2.6453771473255

Epoch: 6| Step: 7
Training loss: 1.9060941538656686
Validation loss: 2.7067256899992462

Epoch: 6| Step: 8
Training loss: 2.5288660573608435
Validation loss: 2.7241303272299375

Epoch: 6| Step: 9
Training loss: 2.5050759283805957
Validation loss: 2.639124562520154

Epoch: 6| Step: 10
Training loss: 1.95208498921794
Validation loss: 2.609005168967672

Epoch: 6| Step: 11
Training loss: 1.9383495068169188
Validation loss: 2.586432886837059

Epoch: 6| Step: 12
Training loss: 1.8132886814949638
Validation loss: 2.603050203687509

Epoch: 6| Step: 13
Training loss: 2.0527222956947164
Validation loss: 2.571493833902003

Epoch: 305| Step: 0
Training loss: 1.8779246091650004
Validation loss: 2.5569632345855218

Epoch: 6| Step: 1
Training loss: 1.8701291076439621
Validation loss: 2.564156051438552

Epoch: 6| Step: 2
Training loss: 2.467517593460206
Validation loss: 2.5771435497488624

Epoch: 6| Step: 3
Training loss: 2.1999459563466432
Validation loss: 2.5746556067170743

Epoch: 6| Step: 4
Training loss: 2.1950379332303833
Validation loss: 2.539028813065292

Epoch: 6| Step: 5
Training loss: 2.1876371068221117
Validation loss: 2.5712030910477717

Epoch: 6| Step: 6
Training loss: 1.8147426411203231
Validation loss: 2.6218158392432174

Epoch: 6| Step: 7
Training loss: 2.226049210126987
Validation loss: 2.623028590142625

Epoch: 6| Step: 8
Training loss: 2.1782489801529468
Validation loss: 2.6546378235999173

Epoch: 6| Step: 9
Training loss: 2.150802365000898
Validation loss: 2.6483439051051203

Epoch: 6| Step: 10
Training loss: 2.7268751779434246
Validation loss: 2.6893904343230934

Epoch: 6| Step: 11
Training loss: 2.544107724092258
Validation loss: 2.652082067960291

Epoch: 6| Step: 12
Training loss: 1.3747061935718172
Validation loss: 2.617212840095182

Epoch: 6| Step: 13
Training loss: 1.519350801162993
Validation loss: 2.5858903402309674

Epoch: 306| Step: 0
Training loss: 1.9139761769038859
Validation loss: 2.5660698610713033

Epoch: 6| Step: 1
Training loss: 2.0603107045861733
Validation loss: 2.560941284127239

Epoch: 6| Step: 2
Training loss: 2.2412881675827596
Validation loss: 2.5413111505814516

Epoch: 6| Step: 3
Training loss: 2.1335608877572674
Validation loss: 2.531482293415826

Epoch: 6| Step: 4
Training loss: 2.101313012498462
Validation loss: 2.54164608702119

Epoch: 6| Step: 5
Training loss: 1.6915791975938277
Validation loss: 2.5815701979592527

Epoch: 6| Step: 6
Training loss: 1.892382600839213
Validation loss: 2.567122686012549

Epoch: 6| Step: 7
Training loss: 2.0910029823723444
Validation loss: 2.596274422836956

Epoch: 6| Step: 8
Training loss: 1.8982093579761885
Validation loss: 2.6297488173137538

Epoch: 6| Step: 9
Training loss: 2.7997227667754503
Validation loss: 2.568567520429393

Epoch: 6| Step: 10
Training loss: 2.081210262618019
Validation loss: 2.5644115978247854

Epoch: 6| Step: 11
Training loss: 1.8152971060256615
Validation loss: 2.5580745568215666

Epoch: 6| Step: 12
Training loss: 1.4457722525469705
Validation loss: 2.5549679601244257

Epoch: 6| Step: 13
Training loss: 2.3109550470249562
Validation loss: 2.549939735797522

Epoch: 307| Step: 0
Training loss: 1.5693693602539234
Validation loss: 2.58663327171785

Epoch: 6| Step: 1
Training loss: 2.21221886696788
Validation loss: 2.581371428902486

Epoch: 6| Step: 2
Training loss: 2.394523085413793
Validation loss: 2.607062268551306

Epoch: 6| Step: 3
Training loss: 2.276969761181505
Validation loss: 2.5785468324751952

Epoch: 6| Step: 4
Training loss: 1.9800801093339337
Validation loss: 2.5638910565195485

Epoch: 6| Step: 5
Training loss: 2.324636623740167
Validation loss: 2.573455388636778

Epoch: 6| Step: 6
Training loss: 1.622914296231316
Validation loss: 2.628766385382743

Epoch: 6| Step: 7
Training loss: 1.502245017708896
Validation loss: 2.6481996352543775

Epoch: 6| Step: 8
Training loss: 1.7825347550308988
Validation loss: 2.6309006085240796

Epoch: 6| Step: 9
Training loss: 2.386373391895253
Validation loss: 2.619661124423267

Epoch: 6| Step: 10
Training loss: 1.8539217312082426
Validation loss: 2.587799661825085

Epoch: 6| Step: 11
Training loss: 2.154942544582774
Validation loss: 2.5698090497931325

Epoch: 6| Step: 12
Training loss: 2.607802505428299
Validation loss: 2.5903935297198166

Epoch: 6| Step: 13
Training loss: 1.9133436449063241
Validation loss: 2.563372285205489

Epoch: 308| Step: 0
Training loss: 2.3091146071958053
Validation loss: 2.554033621537598

Epoch: 6| Step: 1
Training loss: 2.730028807379793
Validation loss: 2.5880228874908258

Epoch: 6| Step: 2
Training loss: 1.6508651141606294
Validation loss: 2.565801834783667

Epoch: 6| Step: 3
Training loss: 1.9289917714846703
Validation loss: 2.543863868507952

Epoch: 6| Step: 4
Training loss: 1.6594025460523347
Validation loss: 2.5761666306294546

Epoch: 6| Step: 5
Training loss: 1.670199972275085
Validation loss: 2.5667896187632846

Epoch: 6| Step: 6
Training loss: 2.435129529104529
Validation loss: 2.582128410415772

Epoch: 6| Step: 7
Training loss: 1.8734349394741807
Validation loss: 2.583739915251986

Epoch: 6| Step: 8
Training loss: 2.4556879152707967
Validation loss: 2.614024058148817

Epoch: 6| Step: 9
Training loss: 1.5191878296003543
Validation loss: 2.6422972791873267

Epoch: 6| Step: 10
Training loss: 1.5076755599853857
Validation loss: 2.695621918687505

Epoch: 6| Step: 11
Training loss: 2.243926965221962
Validation loss: 2.676507469809613

Epoch: 6| Step: 12
Training loss: 2.2070835343641013
Validation loss: 2.6280506058489195

Epoch: 6| Step: 13
Training loss: 1.9073249412591113
Validation loss: 2.6293506142842795

Epoch: 309| Step: 0
Training loss: 1.610251178932321
Validation loss: 2.549264750103129

Epoch: 6| Step: 1
Training loss: 1.2151965643979215
Validation loss: 2.581438497660515

Epoch: 6| Step: 2
Training loss: 2.4834176384186937
Validation loss: 2.5781644413560927

Epoch: 6| Step: 3
Training loss: 2.4580258538148985
Validation loss: 2.6086947073969307

Epoch: 6| Step: 4
Training loss: 1.0754915222656718
Validation loss: 2.5988826906335896

Epoch: 6| Step: 5
Training loss: 2.555497254061357
Validation loss: 2.599104872695993

Epoch: 6| Step: 6
Training loss: 2.249492588048808
Validation loss: 2.585889249199739

Epoch: 6| Step: 7
Training loss: 2.6125680722945854
Validation loss: 2.597567495106158

Epoch: 6| Step: 8
Training loss: 2.5732849001732623
Validation loss: 2.5870679553002844

Epoch: 6| Step: 9
Training loss: 2.2371830934261867
Validation loss: 2.616286605722251

Epoch: 6| Step: 10
Training loss: 1.711191863917822
Validation loss: 2.602040641155494

Epoch: 6| Step: 11
Training loss: 2.000289180830062
Validation loss: 2.627967761427939

Epoch: 6| Step: 12
Training loss: 2.2626967876694586
Validation loss: 2.7139348180323193

Epoch: 6| Step: 13
Training loss: 1.8666824232299282
Validation loss: 2.6992619276848746

Epoch: 310| Step: 0
Training loss: 1.96161472739032
Validation loss: 2.689039957209509

Epoch: 6| Step: 1
Training loss: 1.453116386141934
Validation loss: 2.671787952098215

Epoch: 6| Step: 2
Training loss: 2.6077708721552546
Validation loss: 2.616065032296473

Epoch: 6| Step: 3
Training loss: 1.954409367741336
Validation loss: 2.563183181686505

Epoch: 6| Step: 4
Training loss: 2.016143495569341
Validation loss: 2.556835620769279

Epoch: 6| Step: 5
Training loss: 2.7887340533913294
Validation loss: 2.5212235477127165

Epoch: 6| Step: 6
Training loss: 1.9354741980710892
Validation loss: 2.569601716277411

Epoch: 6| Step: 7
Training loss: 1.491246510938862
Validation loss: 2.5942249858986277

Epoch: 6| Step: 8
Training loss: 2.083114943183912
Validation loss: 2.5400601661995363

Epoch: 6| Step: 9
Training loss: 2.099886882096876
Validation loss: 2.5938261243074585

Epoch: 6| Step: 10
Training loss: 2.078532243564343
Validation loss: 2.5470366865450735

Epoch: 6| Step: 11
Training loss: 1.5622660652515226
Validation loss: 2.5533447469882824

Epoch: 6| Step: 12
Training loss: 2.203181489260833
Validation loss: 2.559551015288959

Epoch: 6| Step: 13
Training loss: 2.0037895302493385
Validation loss: 2.585833091203107

Epoch: 311| Step: 0
Training loss: 2.364114207870255
Validation loss: 2.554319613815846

Epoch: 6| Step: 1
Training loss: 1.0311401771097146
Validation loss: 2.5708375373282495

Epoch: 6| Step: 2
Training loss: 1.7604464315873884
Validation loss: 2.5790422291438415

Epoch: 6| Step: 3
Training loss: 2.3035886052062624
Validation loss: 2.56588530031188

Epoch: 6| Step: 4
Training loss: 1.789246662106398
Validation loss: 2.578199142777103

Epoch: 6| Step: 5
Training loss: 1.4887813018403584
Validation loss: 2.5719833199799145

Epoch: 6| Step: 6
Training loss: 2.0700245782987077
Validation loss: 2.5642774046684695

Epoch: 6| Step: 7
Training loss: 1.777693024575397
Validation loss: 2.5938869731232668

Epoch: 6| Step: 8
Training loss: 2.33063254271535
Validation loss: 2.610229900363465

Epoch: 6| Step: 9
Training loss: 2.447790480804074
Validation loss: 2.634337876655258

Epoch: 6| Step: 10
Training loss: 2.030593296412901
Validation loss: 2.625001407804566

Epoch: 6| Step: 11
Training loss: 2.0941371275152663
Validation loss: 2.5581507020142706

Epoch: 6| Step: 12
Training loss: 2.1750009120193847
Validation loss: 2.5774757723775004

Epoch: 6| Step: 13
Training loss: 2.122427786058044
Validation loss: 2.578268104974213

Epoch: 312| Step: 0
Training loss: 2.5299493721280286
Validation loss: 2.561761656666802

Epoch: 6| Step: 1
Training loss: 2.016206169621651
Validation loss: 2.5649308405891595

Epoch: 6| Step: 2
Training loss: 1.6737381010651073
Validation loss: 2.600571299411566

Epoch: 6| Step: 3
Training loss: 1.8344104665937584
Validation loss: 2.567595757317929

Epoch: 6| Step: 4
Training loss: 1.633059834268863
Validation loss: 2.5799265414384074

Epoch: 6| Step: 5
Training loss: 2.271065959622605
Validation loss: 2.575780924182949

Epoch: 6| Step: 6
Training loss: 1.602444438476967
Validation loss: 2.588818116396302

Epoch: 6| Step: 7
Training loss: 2.370041741112223
Validation loss: 2.5802814134996135

Epoch: 6| Step: 8
Training loss: 1.9190611049670012
Validation loss: 2.595160571846977

Epoch: 6| Step: 9
Training loss: 2.2379316286581097
Validation loss: 2.6429923917709233

Epoch: 6| Step: 10
Training loss: 1.7048708865145943
Validation loss: 2.6614614487920294

Epoch: 6| Step: 11
Training loss: 2.375083721090678
Validation loss: 2.5644621121359723

Epoch: 6| Step: 12
Training loss: 2.388904825300343
Validation loss: 2.566805548646722

Epoch: 6| Step: 13
Training loss: 1.1566122879324137
Validation loss: 2.5566884719494043

Epoch: 313| Step: 0
Training loss: 1.4528325104396937
Validation loss: 2.592953586486142

Epoch: 6| Step: 1
Training loss: 1.9641126482137035
Validation loss: 2.5665480188920897

Epoch: 6| Step: 2
Training loss: 2.0286155636397707
Validation loss: 2.5838772652307473

Epoch: 6| Step: 3
Training loss: 2.2238929137376333
Validation loss: 2.5473476977581853

Epoch: 6| Step: 4
Training loss: 2.7012870581969755
Validation loss: 2.531946141469162

Epoch: 6| Step: 5
Training loss: 1.1370687568562436
Validation loss: 2.5925352017039964

Epoch: 6| Step: 6
Training loss: 2.5585120268138897
Validation loss: 2.5939851677234516

Epoch: 6| Step: 7
Training loss: 2.114148651194647
Validation loss: 2.643010448307665

Epoch: 6| Step: 8
Training loss: 2.0789449121205297
Validation loss: 2.6258005253679153

Epoch: 6| Step: 9
Training loss: 2.091300898432462
Validation loss: 2.6082744295174307

Epoch: 6| Step: 10
Training loss: 2.046165751107632
Validation loss: 2.543636595676446

Epoch: 6| Step: 11
Training loss: 1.6935093867151891
Validation loss: 2.6266870073153776

Epoch: 6| Step: 12
Training loss: 1.8323846081758226
Validation loss: 2.6079582129457894

Epoch: 6| Step: 13
Training loss: 1.9938782940666897
Validation loss: 2.5921039950314775

Epoch: 314| Step: 0
Training loss: 2.109883790996848
Validation loss: 2.555873770413094

Epoch: 6| Step: 1
Training loss: 1.5478967702142232
Validation loss: 2.6100636713682666

Epoch: 6| Step: 2
Training loss: 2.673459302767612
Validation loss: 2.5841459923927657

Epoch: 6| Step: 3
Training loss: 1.9737146540853727
Validation loss: 2.5878875694016945

Epoch: 6| Step: 4
Training loss: 1.6180120015683561
Validation loss: 2.5961610702493836

Epoch: 6| Step: 5
Training loss: 1.7640285870491197
Validation loss: 2.6000147311698076

Epoch: 6| Step: 6
Training loss: 1.713872612838635
Validation loss: 2.606675127516509

Epoch: 6| Step: 7
Training loss: 2.1746939608234968
Validation loss: 2.567870969954282

Epoch: 6| Step: 8
Training loss: 1.600016894847363
Validation loss: 2.5583020381276653

Epoch: 6| Step: 9
Training loss: 1.7720025933291916
Validation loss: 2.5905254650129526

Epoch: 6| Step: 10
Training loss: 2.0684515884779495
Validation loss: 2.5507702985434015

Epoch: 6| Step: 11
Training loss: 2.4450812184704604
Validation loss: 2.567390535714697

Epoch: 6| Step: 12
Training loss: 2.0371290372373245
Validation loss: 2.600614067457427

Epoch: 6| Step: 13
Training loss: 1.7447352917421979
Validation loss: 2.6182975882023323

Epoch: 315| Step: 0
Training loss: 1.7981169016327208
Validation loss: 2.597577423199937

Epoch: 6| Step: 1
Training loss: 1.4454405031999815
Validation loss: 2.5402093106982346

Epoch: 6| Step: 2
Training loss: 2.0984656905086494
Validation loss: 2.5782532631150548

Epoch: 6| Step: 3
Training loss: 1.6301722740922182
Validation loss: 2.5425003956482164

Epoch: 6| Step: 4
Training loss: 2.2722796346079424
Validation loss: 2.5135654287615474

Epoch: 6| Step: 5
Training loss: 1.7644100904336613
Validation loss: 2.570952763763863

Epoch: 6| Step: 6
Training loss: 2.0168358765960606
Validation loss: 2.553206283663719

Epoch: 6| Step: 7
Training loss: 2.1945577932879905
Validation loss: 2.558240482703918

Epoch: 6| Step: 8
Training loss: 2.159410344454264
Validation loss: 2.522318053373899

Epoch: 6| Step: 9
Training loss: 1.9978795731979104
Validation loss: 2.556317321835969

Epoch: 6| Step: 10
Training loss: 1.4913884764821719
Validation loss: 2.583132087395673

Epoch: 6| Step: 11
Training loss: 1.9003575038866043
Validation loss: 2.6074529181643387

Epoch: 6| Step: 12
Training loss: 2.338293616061103
Validation loss: 2.6547587228927427

Epoch: 6| Step: 13
Training loss: 2.5215942453430076
Validation loss: 2.668677411368997

Epoch: 316| Step: 0
Training loss: 1.7697081487960897
Validation loss: 2.7692228216362205

Epoch: 6| Step: 1
Training loss: 2.5059195055626535
Validation loss: 2.730539520176056

Epoch: 6| Step: 2
Training loss: 2.4188445789860165
Validation loss: 2.7172409488158595

Epoch: 6| Step: 3
Training loss: 1.984003167345995
Validation loss: 2.7026582583218373

Epoch: 6| Step: 4
Training loss: 1.9699982818363655
Validation loss: 2.5598921803279877

Epoch: 6| Step: 5
Training loss: 1.399957353078601
Validation loss: 2.5906619950902066

Epoch: 6| Step: 6
Training loss: 2.21535360936634
Validation loss: 2.525716738433054

Epoch: 6| Step: 7
Training loss: 2.198213228825526
Validation loss: 2.531645488847156

Epoch: 6| Step: 8
Training loss: 1.846068653867586
Validation loss: 2.5575246659447672

Epoch: 6| Step: 9
Training loss: 1.6657375447968241
Validation loss: 2.556902097615783

Epoch: 6| Step: 10
Training loss: 1.8169050290697126
Validation loss: 2.5252236421455327

Epoch: 6| Step: 11
Training loss: 2.1644383734100723
Validation loss: 2.538446424030962

Epoch: 6| Step: 12
Training loss: 1.8880367374846483
Validation loss: 2.553962721365134

Epoch: 6| Step: 13
Training loss: 2.6094046950792085
Validation loss: 2.531630640491396

Epoch: 317| Step: 0
Training loss: 2.1309504502620817
Validation loss: 2.525880038933875

Epoch: 6| Step: 1
Training loss: 2.3714011180063337
Validation loss: 2.5301503748175627

Epoch: 6| Step: 2
Training loss: 2.541043397955448
Validation loss: 2.5135772458048407

Epoch: 6| Step: 3
Training loss: 2.4536685219994223
Validation loss: 2.5949164529139184

Epoch: 6| Step: 4
Training loss: 2.155803468328033
Validation loss: 2.5612964129582814

Epoch: 6| Step: 5
Training loss: 1.7003344150807247
Validation loss: 2.503304364036363

Epoch: 6| Step: 6
Training loss: 1.8087342045007961
Validation loss: 2.571366863954712

Epoch: 6| Step: 7
Training loss: 2.3024157691153113
Validation loss: 2.5561266081983076

Epoch: 6| Step: 8
Training loss: 2.099284813213716
Validation loss: 2.6125473869929814

Epoch: 6| Step: 9
Training loss: 1.467258507713498
Validation loss: 2.5591114869582134

Epoch: 6| Step: 10
Training loss: 1.7839069961929865
Validation loss: 2.584277554711798

Epoch: 6| Step: 11
Training loss: 2.0422303595857567
Validation loss: 2.573926832890676

Epoch: 6| Step: 12
Training loss: 2.0254367687004957
Validation loss: 2.584844875096016

Epoch: 6| Step: 13
Training loss: 2.101777700304045
Validation loss: 2.545154247668388

Epoch: 318| Step: 0
Training loss: 1.8212297608894554
Validation loss: 2.5568780402680877

Epoch: 6| Step: 1
Training loss: 2.3103712439192545
Validation loss: 2.563533807024532

Epoch: 6| Step: 2
Training loss: 1.4131674700179577
Validation loss: 2.5957927396568956

Epoch: 6| Step: 3
Training loss: 2.2324471860236716
Validation loss: 2.596676274976799

Epoch: 6| Step: 4
Training loss: 2.1979011667678314
Validation loss: 2.6327664364672465

Epoch: 6| Step: 5
Training loss: 2.03647352702399
Validation loss: 2.6350018372067847

Epoch: 6| Step: 6
Training loss: 1.8298842613433532
Validation loss: 2.616301482426621

Epoch: 6| Step: 7
Training loss: 2.6495863861611895
Validation loss: 2.577085034784379

Epoch: 6| Step: 8
Training loss: 2.029953763087583
Validation loss: 2.6269866903398924

Epoch: 6| Step: 9
Training loss: 1.9777073616655803
Validation loss: 2.5502862532769055

Epoch: 6| Step: 10
Training loss: 1.8758312290179282
Validation loss: 2.5589751835293413

Epoch: 6| Step: 11
Training loss: 2.112078255532952
Validation loss: 2.5793014539421573

Epoch: 6| Step: 12
Training loss: 1.3285698089721583
Validation loss: 2.5326135518411332

Epoch: 6| Step: 13
Training loss: 1.8092698878720788
Validation loss: 2.5492609935350243

Epoch: 319| Step: 0
Training loss: 1.4588598481621151
Validation loss: 2.586817796124905

Epoch: 6| Step: 1
Training loss: 1.6493354990957025
Validation loss: 2.577990626676934

Epoch: 6| Step: 2
Training loss: 2.125372236971895
Validation loss: 2.5642267782434183

Epoch: 6| Step: 3
Training loss: 2.0789117686167238
Validation loss: 2.563787617536852

Epoch: 6| Step: 4
Training loss: 1.4516076810804386
Validation loss: 2.645774019632793

Epoch: 6| Step: 5
Training loss: 1.9245011909542626
Validation loss: 2.599662201285201

Epoch: 6| Step: 6
Training loss: 1.7855411840734963
Validation loss: 2.6108268155786627

Epoch: 6| Step: 7
Training loss: 2.4111072018245445
Validation loss: 2.5627793415679596

Epoch: 6| Step: 8
Training loss: 1.8319139910751874
Validation loss: 2.5518121354688024

Epoch: 6| Step: 9
Training loss: 2.15817893174364
Validation loss: 2.5481338354360963

Epoch: 6| Step: 10
Training loss: 1.8755709732445451
Validation loss: 2.5647202774121824

Epoch: 6| Step: 11
Training loss: 2.307404962403102
Validation loss: 2.5874973751675228

Epoch: 6| Step: 12
Training loss: 2.683994313292299
Validation loss: 2.5862978773446934

Epoch: 6| Step: 13
Training loss: 2.1309743932351752
Validation loss: 2.5849299316698824

Epoch: 320| Step: 0
Training loss: 1.732799880151225
Validation loss: 2.59478428146759

Epoch: 6| Step: 1
Training loss: 2.1020671706496667
Validation loss: 2.5553623128704577

Epoch: 6| Step: 2
Training loss: 2.023964478199875
Validation loss: 2.5907855577338927

Epoch: 6| Step: 3
Training loss: 1.60198998677414
Validation loss: 2.5367421351103765

Epoch: 6| Step: 4
Training loss: 2.0781879845733044
Validation loss: 2.5773713831072076

Epoch: 6| Step: 5
Training loss: 2.029363607240118
Validation loss: 2.5282815395155693

Epoch: 6| Step: 6
Training loss: 1.881840625196873
Validation loss: 2.5819618881381445

Epoch: 6| Step: 7
Training loss: 1.4927685789563008
Validation loss: 2.5914830638536452

Epoch: 6| Step: 8
Training loss: 1.713394978127991
Validation loss: 2.5627935287951176

Epoch: 6| Step: 9
Training loss: 2.8528248958128213
Validation loss: 2.5551866827222622

Epoch: 6| Step: 10
Training loss: 1.8044048269599242
Validation loss: 2.5703883599524024

Epoch: 6| Step: 11
Training loss: 1.8426367421436936
Validation loss: 2.5911027352025204

Epoch: 6| Step: 12
Training loss: 2.2326999601241715
Validation loss: 2.6171332510265004

Epoch: 6| Step: 13
Training loss: 1.852316401105569
Validation loss: 2.669710081602491

Epoch: 321| Step: 0
Training loss: 1.878725927507058
Validation loss: 2.632903039962086

Epoch: 6| Step: 1
Training loss: 2.2136744081675555
Validation loss: 2.677304705262849

Epoch: 6| Step: 2
Training loss: 1.7637908320901416
Validation loss: 2.598155221843609

Epoch: 6| Step: 3
Training loss: 1.885923609014773
Validation loss: 2.5861796009333324

Epoch: 6| Step: 4
Training loss: 1.9535146706008029
Validation loss: 2.5405004801623035

Epoch: 6| Step: 5
Training loss: 1.8119104676263924
Validation loss: 2.5550263906261836

Epoch: 6| Step: 6
Training loss: 2.2118461547936796
Validation loss: 2.537740744835342

Epoch: 6| Step: 7
Training loss: 1.8982203481049604
Validation loss: 2.5355584482396964

Epoch: 6| Step: 8
Training loss: 1.9361864374808575
Validation loss: 2.5765711484832927

Epoch: 6| Step: 9
Training loss: 2.2972692034569775
Validation loss: 2.6114836983855736

Epoch: 6| Step: 10
Training loss: 1.708099729181441
Validation loss: 2.612420640315026

Epoch: 6| Step: 11
Training loss: 2.318210047449687
Validation loss: 2.626632198125333

Epoch: 6| Step: 12
Training loss: 1.4448328820446168
Validation loss: 2.6187241631130855

Epoch: 6| Step: 13
Training loss: 2.1752098333054426
Validation loss: 2.6344128432144505

Epoch: 322| Step: 0
Training loss: 2.4850428421349386
Validation loss: 2.6444789293411066

Epoch: 6| Step: 1
Training loss: 1.9740462740698834
Validation loss: 2.6428622337179357

Epoch: 6| Step: 2
Training loss: 2.3241327862910475
Validation loss: 2.6824278614811954

Epoch: 6| Step: 3
Training loss: 2.305822060845489
Validation loss: 2.6443380175361932

Epoch: 6| Step: 4
Training loss: 1.6173529793666974
Validation loss: 2.585041363383347

Epoch: 6| Step: 5
Training loss: 2.09349844261168
Validation loss: 2.559362134020042

Epoch: 6| Step: 6
Training loss: 2.0549841837030707
Validation loss: 2.5628328882485647

Epoch: 6| Step: 7
Training loss: 1.7093208374145934
Validation loss: 2.5432011761291333

Epoch: 6| Step: 8
Training loss: 1.7213790899445183
Validation loss: 2.5368684336622813

Epoch: 6| Step: 9
Training loss: 1.6704039474590473
Validation loss: 2.572432520073723

Epoch: 6| Step: 10
Training loss: 1.796847401282617
Validation loss: 2.550313995389559

Epoch: 6| Step: 11
Training loss: 2.085496034232928
Validation loss: 2.5596301670831125

Epoch: 6| Step: 12
Training loss: 2.198299561425029
Validation loss: 2.576103951862837

Epoch: 6| Step: 13
Training loss: 1.1318902832886766
Validation loss: 2.5944842176454195

Epoch: 323| Step: 0
Training loss: 1.0792330700587163
Validation loss: 2.5982745130372344

Epoch: 6| Step: 1
Training loss: 2.116303093791161
Validation loss: 2.590710801198068

Epoch: 6| Step: 2
Training loss: 2.296088674461152
Validation loss: 2.6376525280375582

Epoch: 6| Step: 3
Training loss: 1.8015119348660569
Validation loss: 2.6392734386823036

Epoch: 6| Step: 4
Training loss: 2.1650591046236296
Validation loss: 2.631760806944019

Epoch: 6| Step: 5
Training loss: 1.6287103988037244
Validation loss: 2.5958749730019286

Epoch: 6| Step: 6
Training loss: 2.430344667519793
Validation loss: 2.598312608596662

Epoch: 6| Step: 7
Training loss: 1.8965248551453477
Validation loss: 2.6150549251800768

Epoch: 6| Step: 8
Training loss: 2.1780134218991627
Validation loss: 2.6290943065263854

Epoch: 6| Step: 9
Training loss: 1.8405757670788536
Validation loss: 2.596845319557654

Epoch: 6| Step: 10
Training loss: 1.702352296020849
Validation loss: 2.571045729417535

Epoch: 6| Step: 11
Training loss: 1.4815886999556191
Validation loss: 2.568518138856846

Epoch: 6| Step: 12
Training loss: 2.414949618301704
Validation loss: 2.562467466318421

Epoch: 6| Step: 13
Training loss: 1.8150930600439947
Validation loss: 2.5966526014300464

Epoch: 324| Step: 0
Training loss: 2.332732077743435
Validation loss: 2.5827375360723

Epoch: 6| Step: 1
Training loss: 1.7200928730619804
Validation loss: 2.579913880835496

Epoch: 6| Step: 2
Training loss: 1.80640979838759
Validation loss: 2.5416910503864596

Epoch: 6| Step: 3
Training loss: 2.04082509296831
Validation loss: 2.60373930412607

Epoch: 6| Step: 4
Training loss: 1.7081931762266025
Validation loss: 2.5844023912570386

Epoch: 6| Step: 5
Training loss: 2.0875982752526623
Validation loss: 2.621849864404261

Epoch: 6| Step: 6
Training loss: 2.0288508405085444
Validation loss: 2.6360738384727953

Epoch: 6| Step: 7
Training loss: 1.54207591046362
Validation loss: 2.639459507021646

Epoch: 6| Step: 8
Training loss: 2.2030859328248837
Validation loss: 2.6203536890045855

Epoch: 6| Step: 9
Training loss: 2.080353424050231
Validation loss: 2.6243943166570762

Epoch: 6| Step: 10
Training loss: 2.213475364739264
Validation loss: 2.704952026806732

Epoch: 6| Step: 11
Training loss: 1.9158923063732891
Validation loss: 2.6459336950135777

Epoch: 6| Step: 12
Training loss: 2.0240786210572925
Validation loss: 2.686712179113992

Epoch: 6| Step: 13
Training loss: 1.7803771574155558
Validation loss: 2.6161594934022703

Epoch: 325| Step: 0
Training loss: 1.5548198394424286
Validation loss: 2.5412833649158317

Epoch: 6| Step: 1
Training loss: 2.0861887119769342
Validation loss: 2.5375851524484894

Epoch: 6| Step: 2
Training loss: 2.5922790400809608
Validation loss: 2.514675079500858

Epoch: 6| Step: 3
Training loss: 1.5393296992535908
Validation loss: 2.568162801784166

Epoch: 6| Step: 4
Training loss: 1.388361041642403
Validation loss: 2.533117147264561

Epoch: 6| Step: 5
Training loss: 1.9032785363111824
Validation loss: 2.533162120839191

Epoch: 6| Step: 6
Training loss: 2.876612335552487
Validation loss: 2.540178931859813

Epoch: 6| Step: 7
Training loss: 1.393432782942185
Validation loss: 2.5115715209145826

Epoch: 6| Step: 8
Training loss: 1.8641017171055065
Validation loss: 2.5827446748843985

Epoch: 6| Step: 9
Training loss: 2.1101486482734004
Validation loss: 2.5845076419690036

Epoch: 6| Step: 10
Training loss: 1.9903309268011569
Validation loss: 2.5389802264064216

Epoch: 6| Step: 11
Training loss: 1.309537268441465
Validation loss: 2.54783271459936

Epoch: 6| Step: 12
Training loss: 1.953322865953923
Validation loss: 2.5486787988565376

Epoch: 6| Step: 13
Training loss: 1.9290078390940075
Validation loss: 2.5943645377404976

Epoch: 326| Step: 0
Training loss: 2.1020271326522524
Validation loss: 2.5801495704124724

Epoch: 6| Step: 1
Training loss: 1.728947506846305
Validation loss: 2.6538687859721604

Epoch: 6| Step: 2
Training loss: 2.295436798116369
Validation loss: 2.5829244464384393

Epoch: 6| Step: 3
Training loss: 1.8795652126193358
Validation loss: 2.6316084933922834

Epoch: 6| Step: 4
Training loss: 1.5596537033268467
Validation loss: 2.618182275090515

Epoch: 6| Step: 5
Training loss: 1.6530033896123584
Validation loss: 2.5898924027557926

Epoch: 6| Step: 6
Training loss: 1.703129479638604
Validation loss: 2.5667775048644654

Epoch: 6| Step: 7
Training loss: 1.2608350369445493
Validation loss: 2.524521113769219

Epoch: 6| Step: 8
Training loss: 1.741771083725533
Validation loss: 2.5525043581415696

Epoch: 6| Step: 9
Training loss: 1.8769250524289196
Validation loss: 2.519279416137822

Epoch: 6| Step: 10
Training loss: 2.396328872075131
Validation loss: 2.555161427314729

Epoch: 6| Step: 11
Training loss: 2.2064323760561173
Validation loss: 2.531417432985237

Epoch: 6| Step: 12
Training loss: 1.874008552368907
Validation loss: 2.5432089805908653

Epoch: 6| Step: 13
Training loss: 2.6198707604018363
Validation loss: 2.594226165327713

Epoch: 327| Step: 0
Training loss: 1.6341319616439813
Validation loss: 2.689391424265006

Epoch: 6| Step: 1
Training loss: 2.679915437930004
Validation loss: 2.7143715207619783

Epoch: 6| Step: 2
Training loss: 2.2498211259735634
Validation loss: 2.7119745768159067

Epoch: 6| Step: 3
Training loss: 2.5573932656010117
Validation loss: 2.6028055881202827

Epoch: 6| Step: 4
Training loss: 1.7326140528317167
Validation loss: 2.5872235284059824

Epoch: 6| Step: 5
Training loss: 2.2784729868409492
Validation loss: 2.5223243706931577

Epoch: 6| Step: 6
Training loss: 1.5670364139710289
Validation loss: 2.5561924972222307

Epoch: 6| Step: 7
Training loss: 1.6808340018855317
Validation loss: 2.5558797327197027

Epoch: 6| Step: 8
Training loss: 1.2950453663394887
Validation loss: 2.5407791985533077

Epoch: 6| Step: 9
Training loss: 1.3943772858755268
Validation loss: 2.5137216542810012

Epoch: 6| Step: 10
Training loss: 2.287446998023847
Validation loss: 2.543791864786397

Epoch: 6| Step: 11
Training loss: 2.0214795393586487
Validation loss: 2.5366388187517352

Epoch: 6| Step: 12
Training loss: 1.9706013769493609
Validation loss: 2.5425206193366043

Epoch: 6| Step: 13
Training loss: 1.7730801260066467
Validation loss: 2.5563905971074234

Epoch: 328| Step: 0
Training loss: 2.233824121817641
Validation loss: 2.6130166901090575

Epoch: 6| Step: 1
Training loss: 1.967508196880323
Validation loss: 2.649147441162669

Epoch: 6| Step: 2
Training loss: 2.2156383562425246
Validation loss: 2.6059740940483884

Epoch: 6| Step: 3
Training loss: 1.510974079624222
Validation loss: 2.589410867469481

Epoch: 6| Step: 4
Training loss: 1.4294661053444868
Validation loss: 2.562601738747653

Epoch: 6| Step: 5
Training loss: 2.3145083392675567
Validation loss: 2.5588047086218273

Epoch: 6| Step: 6
Training loss: 1.8825880367975716
Validation loss: 2.557348656003167

Epoch: 6| Step: 7
Training loss: 2.7469493243997625
Validation loss: 2.5507749252669325

Epoch: 6| Step: 8
Training loss: 2.040087095346152
Validation loss: 2.549848244707876

Epoch: 6| Step: 9
Training loss: 2.6427019066307063
Validation loss: 2.560559693437038

Epoch: 6| Step: 10
Training loss: 1.3113925439615364
Validation loss: 2.565205440684325

Epoch: 6| Step: 11
Training loss: 2.0883829590831904
Validation loss: 2.566311769183388

Epoch: 6| Step: 12
Training loss: 1.4552740797165071
Validation loss: 2.6028521818800963

Epoch: 6| Step: 13
Training loss: 1.9325496436253051
Validation loss: 2.620286842907543

Epoch: 329| Step: 0
Training loss: 1.8986467787691306
Validation loss: 2.7204056445043716

Epoch: 6| Step: 1
Training loss: 2.315097484142727
Validation loss: 2.7849094304688085

Epoch: 6| Step: 2
Training loss: 2.0866900168911093
Validation loss: 2.7157565770905796

Epoch: 6| Step: 3
Training loss: 2.164591920729765
Validation loss: 2.6233174366047236

Epoch: 6| Step: 4
Training loss: 1.6430165616278636
Validation loss: 2.57783876621878

Epoch: 6| Step: 5
Training loss: 2.0817544549166183
Validation loss: 2.5482176535600645

Epoch: 6| Step: 6
Training loss: 2.507245721674723
Validation loss: 2.5595742247084754

Epoch: 6| Step: 7
Training loss: 2.3505977032838064
Validation loss: 2.624822020173654

Epoch: 6| Step: 8
Training loss: 2.223655757525997
Validation loss: 2.5862231754652965

Epoch: 6| Step: 9
Training loss: 2.700430613193678
Validation loss: 2.5732172482830458

Epoch: 6| Step: 10
Training loss: 2.126293013382625
Validation loss: 2.575912705486884

Epoch: 6| Step: 11
Training loss: 1.9124525500625746
Validation loss: 2.5339009802408836

Epoch: 6| Step: 12
Training loss: 1.9580684509781112
Validation loss: 2.49211963174502

Epoch: 6| Step: 13
Training loss: 1.9171613248423283
Validation loss: 2.575534428379652

Epoch: 330| Step: 0
Training loss: 2.5280266477411693
Validation loss: 2.5978347143377287

Epoch: 6| Step: 1
Training loss: 2.0542880638210685
Validation loss: 2.609053540558806

Epoch: 6| Step: 2
Training loss: 1.88209767048242
Validation loss: 2.574207350262343

Epoch: 6| Step: 3
Training loss: 2.28790170446406
Validation loss: 2.56847393906897

Epoch: 6| Step: 4
Training loss: 2.1394509764544396
Validation loss: 2.564445888783147

Epoch: 6| Step: 5
Training loss: 1.8225450046042713
Validation loss: 2.531131992807493

Epoch: 6| Step: 6
Training loss: 1.5470671871516373
Validation loss: 2.5332986367091586

Epoch: 6| Step: 7
Training loss: 2.426534784457182
Validation loss: 2.5143342902731143

Epoch: 6| Step: 8
Training loss: 1.854039591460134
Validation loss: 2.489859112158628

Epoch: 6| Step: 9
Training loss: 1.6544458891895943
Validation loss: 2.542319062933111

Epoch: 6| Step: 10
Training loss: 1.778837879661303
Validation loss: 2.4826888354300527

Epoch: 6| Step: 11
Training loss: 1.773444356358924
Validation loss: 2.5000770398031675

Epoch: 6| Step: 12
Training loss: 1.9769459831140448
Validation loss: 2.5570799875281542

Epoch: 6| Step: 13
Training loss: 1.7924685642779234
Validation loss: 2.5292508821957527

Epoch: 331| Step: 0
Training loss: 1.8376025502140283
Validation loss: 2.559991772012601

Epoch: 6| Step: 1
Training loss: 1.5561223908466164
Validation loss: 2.5938146345672193

Epoch: 6| Step: 2
Training loss: 2.167598328433507
Validation loss: 2.658851217529176

Epoch: 6| Step: 3
Training loss: 2.4966129246603397
Validation loss: 2.6570964287414283

Epoch: 6| Step: 4
Training loss: 2.56960177813358
Validation loss: 2.6226579875408103

Epoch: 6| Step: 5
Training loss: 1.963936992753364
Validation loss: 2.6969225511303905

Epoch: 6| Step: 6
Training loss: 1.8393721897468007
Validation loss: 2.674408200717524

Epoch: 6| Step: 7
Training loss: 1.7520203508388303
Validation loss: 2.6633683434820346

Epoch: 6| Step: 8
Training loss: 1.5945172426542091
Validation loss: 2.584101906138926

Epoch: 6| Step: 9
Training loss: 1.813692424131111
Validation loss: 2.5492352117937718

Epoch: 6| Step: 10
Training loss: 1.8088994272509833
Validation loss: 2.5758819532624053

Epoch: 6| Step: 11
Training loss: 1.858064333800765
Validation loss: 2.55585674627986

Epoch: 6| Step: 12
Training loss: 1.6002019546130686
Validation loss: 2.584527490830394

Epoch: 6| Step: 13
Training loss: 2.0261197373385804
Validation loss: 2.602387000741554

Epoch: 332| Step: 0
Training loss: 2.305104880605132
Validation loss: 2.5702869448797276

Epoch: 6| Step: 1
Training loss: 1.8098560649061268
Validation loss: 2.630136852740921

Epoch: 6| Step: 2
Training loss: 2.473002959376507
Validation loss: 2.6268779758070746

Epoch: 6| Step: 3
Training loss: 2.41748801337883
Validation loss: 2.7635578253300346

Epoch: 6| Step: 4
Training loss: 2.01763567330045
Validation loss: 2.6822798768805987

Epoch: 6| Step: 5
Training loss: 1.373133693245624
Validation loss: 2.6615933995522685

Epoch: 6| Step: 6
Training loss: 1.9975399146072699
Validation loss: 2.622313661370689

Epoch: 6| Step: 7
Training loss: 1.8845861161682558
Validation loss: 2.612305615386323

Epoch: 6| Step: 8
Training loss: 2.2496031305193656
Validation loss: 2.5941757710614977

Epoch: 6| Step: 9
Training loss: 2.218683698496338
Validation loss: 2.610569419765394

Epoch: 6| Step: 10
Training loss: 1.5532396178292283
Validation loss: 2.6140896203123374

Epoch: 6| Step: 11
Training loss: 1.1774938030849273
Validation loss: 2.5874361150106635

Epoch: 6| Step: 12
Training loss: 1.8684538054723763
Validation loss: 2.5844097561019415

Epoch: 6| Step: 13
Training loss: 1.6533611222721034
Validation loss: 2.5701118862471293

Epoch: 333| Step: 0
Training loss: 1.5894576970051288
Validation loss: 2.5689254311014347

Epoch: 6| Step: 1
Training loss: 1.860207507545965
Validation loss: 2.6307439479036265

Epoch: 6| Step: 2
Training loss: 2.0372781363611154
Validation loss: 2.598669679521889

Epoch: 6| Step: 3
Training loss: 2.127631633554791
Validation loss: 2.5681685112066

Epoch: 6| Step: 4
Training loss: 2.0893144454191566
Validation loss: 2.565357351959283

Epoch: 6| Step: 5
Training loss: 1.8100055761936344
Validation loss: 2.5674760931400753

Epoch: 6| Step: 6
Training loss: 1.9854044609321748
Validation loss: 2.6090890381261787

Epoch: 6| Step: 7
Training loss: 1.3545466647919513
Validation loss: 2.563963433427967

Epoch: 6| Step: 8
Training loss: 1.941425899045435
Validation loss: 2.5816657826779426

Epoch: 6| Step: 9
Training loss: 2.2281561251441917
Validation loss: 2.586309661668737

Epoch: 6| Step: 10
Training loss: 1.8761795148628413
Validation loss: 2.612938303889544

Epoch: 6| Step: 11
Training loss: 2.098055156946393
Validation loss: 2.592651831773845

Epoch: 6| Step: 12
Training loss: 2.138794276249056
Validation loss: 2.585640712583025

Epoch: 6| Step: 13
Training loss: 1.5411502987185761
Validation loss: 2.6037811578872447

Epoch: 334| Step: 0
Training loss: 1.690491744058798
Validation loss: 2.5708666574141206

Epoch: 6| Step: 1
Training loss: 1.5776640719348023
Validation loss: 2.591450510690708

Epoch: 6| Step: 2
Training loss: 2.332612289555165
Validation loss: 2.5602973372171327

Epoch: 6| Step: 3
Training loss: 1.9928956811326264
Validation loss: 2.6081221079587498

Epoch: 6| Step: 4
Training loss: 1.8173162990330554
Validation loss: 2.656380070512331

Epoch: 6| Step: 5
Training loss: 2.039095121977734
Validation loss: 2.6685348066633456

Epoch: 6| Step: 6
Training loss: 2.247786068473876
Validation loss: 2.6628145294784598

Epoch: 6| Step: 7
Training loss: 1.9092696615028175
Validation loss: 2.6947401240644107

Epoch: 6| Step: 8
Training loss: 1.6540499055845275
Validation loss: 2.6472693148459627

Epoch: 6| Step: 9
Training loss: 1.4836441650181265
Validation loss: 2.613784992379664

Epoch: 6| Step: 10
Training loss: 1.6889357640149822
Validation loss: 2.5885312996752026

Epoch: 6| Step: 11
Training loss: 1.758764119582987
Validation loss: 2.621583698566087

Epoch: 6| Step: 12
Training loss: 1.7159300819504792
Validation loss: 2.5948434769154094

Epoch: 6| Step: 13
Training loss: 2.251345126415509
Validation loss: 2.576035733851784

Epoch: 335| Step: 0
Training loss: 2.508317557841866
Validation loss: 2.5817522830282598

Epoch: 6| Step: 1
Training loss: 2.5925105247173565
Validation loss: 2.5829417229257734

Epoch: 6| Step: 2
Training loss: 1.0750367535362952
Validation loss: 2.578357439448335

Epoch: 6| Step: 3
Training loss: 1.0601308438680106
Validation loss: 2.5735410069223126

Epoch: 6| Step: 4
Training loss: 2.1743770978960804
Validation loss: 2.622559593767264

Epoch: 6| Step: 5
Training loss: 2.1807572122402332
Validation loss: 2.6691966175213597

Epoch: 6| Step: 6
Training loss: 1.7955325875699144
Validation loss: 2.7078724738022686

Epoch: 6| Step: 7
Training loss: 1.6713713841092843
Validation loss: 2.695154570592035

Epoch: 6| Step: 8
Training loss: 1.286292596969885
Validation loss: 2.705524063536309

Epoch: 6| Step: 9
Training loss: 2.0034964516105864
Validation loss: 2.6318417050705976

Epoch: 6| Step: 10
Training loss: 1.31518044832784
Validation loss: 2.557172105613795

Epoch: 6| Step: 11
Training loss: 2.161212462876425
Validation loss: 2.5590100597617655

Epoch: 6| Step: 12
Training loss: 1.92591978120367
Validation loss: 2.5732699214784693

Epoch: 6| Step: 13
Training loss: 2.2722170985422396
Validation loss: 2.5549854878600096

Epoch: 336| Step: 0
Training loss: 2.4246556224317994
Validation loss: 2.5154851712683444

Epoch: 6| Step: 1
Training loss: 1.7463818340193737
Validation loss: 2.493825535598261

Epoch: 6| Step: 2
Training loss: 2.1396136714142653
Validation loss: 2.535429247718091

Epoch: 6| Step: 3
Training loss: 1.7987978391137693
Validation loss: 2.539489318968399

Epoch: 6| Step: 4
Training loss: 1.4061107142663185
Validation loss: 2.562101503726411

Epoch: 6| Step: 5
Training loss: 1.69979027969161
Validation loss: 2.4951709838562124

Epoch: 6| Step: 6
Training loss: 1.76583401953465
Validation loss: 2.5144502175238106

Epoch: 6| Step: 7
Training loss: 2.1488824556989257
Validation loss: 2.5516031137828863

Epoch: 6| Step: 8
Training loss: 1.8637423474610773
Validation loss: 2.54869585534432

Epoch: 6| Step: 9
Training loss: 2.1619310589790035
Validation loss: 2.556821252840298

Epoch: 6| Step: 10
Training loss: 1.9377579055918193
Validation loss: 2.5672967257165182

Epoch: 6| Step: 11
Training loss: 1.7912525615154726
Validation loss: 2.620903239406992

Epoch: 6| Step: 12
Training loss: 2.011780139764162
Validation loss: 2.634085297559232

Epoch: 6| Step: 13
Training loss: 2.5200069008081805
Validation loss: 2.6443677933409226

Epoch: 337| Step: 0
Training loss: 1.7007119819578362
Validation loss: 2.66374106159975

Epoch: 6| Step: 1
Training loss: 1.9759683432186104
Validation loss: 2.7252747446781043

Epoch: 6| Step: 2
Training loss: 2.271380145764034
Validation loss: 2.723201644177245

Epoch: 6| Step: 3
Training loss: 1.6875508618637107
Validation loss: 2.6312153062624795

Epoch: 6| Step: 4
Training loss: 1.5995200182278269
Validation loss: 2.6627782446428445

Epoch: 6| Step: 5
Training loss: 2.2485958592342206
Validation loss: 2.5853604674603203

Epoch: 6| Step: 6
Training loss: 1.6965361367448824
Validation loss: 2.6216747930424633

Epoch: 6| Step: 7
Training loss: 2.3227850587338357
Validation loss: 2.5674179150201106

Epoch: 6| Step: 8
Training loss: 1.8042311318430952
Validation loss: 2.515338194236369

Epoch: 6| Step: 9
Training loss: 1.5912373501378971
Validation loss: 2.5424605416956036

Epoch: 6| Step: 10
Training loss: 1.8391317945987593
Validation loss: 2.5770596547582163

Epoch: 6| Step: 11
Training loss: 2.0586828107587922
Validation loss: 2.608077299533665

Epoch: 6| Step: 12
Training loss: 1.7482414265207888
Validation loss: 2.6427288966318003

Epoch: 6| Step: 13
Training loss: 1.6900941195039945
Validation loss: 2.6014603603348316

Epoch: 338| Step: 0
Training loss: 1.7952447544792067
Validation loss: 2.590437823360498

Epoch: 6| Step: 1
Training loss: 1.7151887933229748
Validation loss: 2.59698299393039

Epoch: 6| Step: 2
Training loss: 1.830372138410542
Validation loss: 2.545328009776521

Epoch: 6| Step: 3
Training loss: 2.343954865720887
Validation loss: 2.564534256003545

Epoch: 6| Step: 4
Training loss: 1.7778455088879068
Validation loss: 2.5902496372724966

Epoch: 6| Step: 5
Training loss: 1.7320422043580845
Validation loss: 2.595492516846054

Epoch: 6| Step: 6
Training loss: 2.110766820551182
Validation loss: 2.602060035578871

Epoch: 6| Step: 7
Training loss: 1.5028117370920828
Validation loss: 2.6379253273508785

Epoch: 6| Step: 8
Training loss: 1.9890726908792047
Validation loss: 2.6581722708991875

Epoch: 6| Step: 9
Training loss: 1.5251614719641868
Validation loss: 2.6681891704487763

Epoch: 6| Step: 10
Training loss: 1.5947055569986388
Validation loss: 2.6585234842086436

Epoch: 6| Step: 11
Training loss: 2.2727080023555484
Validation loss: 2.6421582738281475

Epoch: 6| Step: 12
Training loss: 2.806519911259955
Validation loss: 2.678516736456166

Epoch: 6| Step: 13
Training loss: 1.665654240507218
Validation loss: 2.669003079018711

Epoch: 339| Step: 0
Training loss: 1.3412115383410717
Validation loss: 2.5983620662295435

Epoch: 6| Step: 1
Training loss: 2.012312303402979
Validation loss: 2.5782747321526833

Epoch: 6| Step: 2
Training loss: 1.9733147154823305
Validation loss: 2.6142296621531016

Epoch: 6| Step: 3
Training loss: 2.673054752564017
Validation loss: 2.564383241195632

Epoch: 6| Step: 4
Training loss: 1.4209465936319865
Validation loss: 2.557619455828589

Epoch: 6| Step: 5
Training loss: 2.0048468986523966
Validation loss: 2.556257343048517

Epoch: 6| Step: 6
Training loss: 1.3695601447757164
Validation loss: 2.5759420690064436

Epoch: 6| Step: 7
Training loss: 1.5099308767349915
Validation loss: 2.540128216223211

Epoch: 6| Step: 8
Training loss: 1.9770282905186842
Validation loss: 2.579151912353253

Epoch: 6| Step: 9
Training loss: 2.1937224035891116
Validation loss: 2.577221505961568

Epoch: 6| Step: 10
Training loss: 2.024130095141942
Validation loss: 2.592392792332

Epoch: 6| Step: 11
Training loss: 1.9208263234350538
Validation loss: 2.556415327426088

Epoch: 6| Step: 12
Training loss: 1.6245004913244798
Validation loss: 2.569803977991454

Epoch: 6| Step: 13
Training loss: 2.2388587193419194
Validation loss: 2.6020527054200993

Epoch: 340| Step: 0
Training loss: 1.8443187547598532
Validation loss: 2.5984508704451086

Epoch: 6| Step: 1
Training loss: 2.377821801967427
Validation loss: 2.6681601296068633

Epoch: 6| Step: 2
Training loss: 1.5452028735148675
Validation loss: 2.635881787495052

Epoch: 6| Step: 3
Training loss: 0.7959605186917119
Validation loss: 2.657434491115388

Epoch: 6| Step: 4
Training loss: 2.0887345552358556
Validation loss: 2.633727822954966

Epoch: 6| Step: 5
Training loss: 2.3519594991661257
Validation loss: 2.6694307356910345

Epoch: 6| Step: 6
Training loss: 1.41950153493983
Validation loss: 2.6494889249347597

Epoch: 6| Step: 7
Training loss: 1.562842369717115
Validation loss: 2.610658432790041

Epoch: 6| Step: 8
Training loss: 2.2361490102943127
Validation loss: 2.633776012063476

Epoch: 6| Step: 9
Training loss: 2.104557441708746
Validation loss: 2.6016458797744466

Epoch: 6| Step: 10
Training loss: 1.7349004550926865
Validation loss: 2.6112212237910097

Epoch: 6| Step: 11
Training loss: 2.105517668146935
Validation loss: 2.6066407289661715

Epoch: 6| Step: 12
Training loss: 1.868913180266091
Validation loss: 2.603827528169414

Epoch: 6| Step: 13
Training loss: 1.8869721615652784
Validation loss: 2.553538757315922

Epoch: 341| Step: 0
Training loss: 2.157081333174456
Validation loss: 2.5719662093547777

Epoch: 6| Step: 1
Training loss: 1.8583120946426008
Validation loss: 2.5688687862457025

Epoch: 6| Step: 2
Training loss: 1.9489285973612027
Validation loss: 2.614588556373111

Epoch: 6| Step: 3
Training loss: 1.895764702473428
Validation loss: 2.6057780404888957

Epoch: 6| Step: 4
Training loss: 2.2865791259928594
Validation loss: 2.612640986676595

Epoch: 6| Step: 5
Training loss: 1.5142018823862122
Validation loss: 2.547025087142904

Epoch: 6| Step: 6
Training loss: 2.22443146031863
Validation loss: 2.5896889020332083

Epoch: 6| Step: 7
Training loss: 1.5486789549757292
Validation loss: 2.634225317223538

Epoch: 6| Step: 8
Training loss: 1.322978921862193
Validation loss: 2.5817188375958957

Epoch: 6| Step: 9
Training loss: 1.9769558119439974
Validation loss: 2.581522081027383

Epoch: 6| Step: 10
Training loss: 2.0092584175711004
Validation loss: 2.5673198264177874

Epoch: 6| Step: 11
Training loss: 1.9529761906201393
Validation loss: 2.6025561171707063

Epoch: 6| Step: 12
Training loss: 1.7221128683682543
Validation loss: 2.609000668353688

Epoch: 6| Step: 13
Training loss: 1.7377879610817495
Validation loss: 2.544969887620892

Epoch: 342| Step: 0
Training loss: 2.5713947649655977
Validation loss: 2.5720649318468363

Epoch: 6| Step: 1
Training loss: 2.078776780791509
Validation loss: 2.597205835745169

Epoch: 6| Step: 2
Training loss: 1.823381055989613
Validation loss: 2.628371435125888

Epoch: 6| Step: 3
Training loss: 1.9034436940912982
Validation loss: 2.6572757909388516

Epoch: 6| Step: 4
Training loss: 1.7157238763273666
Validation loss: 2.5988846477288923

Epoch: 6| Step: 5
Training loss: 1.7940253840535647
Validation loss: 2.574577287279043

Epoch: 6| Step: 6
Training loss: 1.5813319791870581
Validation loss: 2.5699147435530163

Epoch: 6| Step: 7
Training loss: 2.415612275755065
Validation loss: 2.5575477539208156

Epoch: 6| Step: 8
Training loss: 2.210877326712627
Validation loss: 2.5612722882848917

Epoch: 6| Step: 9
Training loss: 1.4149455479904787
Validation loss: 2.590292437673566

Epoch: 6| Step: 10
Training loss: 1.8314783364070992
Validation loss: 2.556905376732856

Epoch: 6| Step: 11
Training loss: 1.4841212808708115
Validation loss: 2.5390717804567977

Epoch: 6| Step: 12
Training loss: 1.166771418546322
Validation loss: 2.531323019787656

Epoch: 6| Step: 13
Training loss: 1.3911371038237503
Validation loss: 2.5781734269343053

Epoch: 343| Step: 0
Training loss: 2.011957187781059
Validation loss: 2.5846601790900285

Epoch: 6| Step: 1
Training loss: 1.295067136047911
Validation loss: 2.608134403097542

Epoch: 6| Step: 2
Training loss: 2.515553443791357
Validation loss: 2.5636883438064197

Epoch: 6| Step: 3
Training loss: 1.5679436271566922
Validation loss: 2.5974290332517134

Epoch: 6| Step: 4
Training loss: 1.6686581475628057
Validation loss: 2.6540997347534305

Epoch: 6| Step: 5
Training loss: 1.6300495626953377
Validation loss: 2.5559189809854406

Epoch: 6| Step: 6
Training loss: 1.927242011333401
Validation loss: 2.56680560282983

Epoch: 6| Step: 7
Training loss: 1.2398608028054003
Validation loss: 2.5714327333431775

Epoch: 6| Step: 8
Training loss: 2.414043340020547
Validation loss: 2.593354972570925

Epoch: 6| Step: 9
Training loss: 1.7487526944448506
Validation loss: 2.60860981638758

Epoch: 6| Step: 10
Training loss: 1.5773780490269294
Validation loss: 2.626583045880627

Epoch: 6| Step: 11
Training loss: 1.5151759790121702
Validation loss: 2.6751296983453643

Epoch: 6| Step: 12
Training loss: 2.0740151745453517
Validation loss: 2.6730596135945417

Epoch: 6| Step: 13
Training loss: 2.4569155812896755
Validation loss: 2.6922594701025555

Epoch: 344| Step: 0
Training loss: 1.818693824765721
Validation loss: 2.6620595194532166

Epoch: 6| Step: 1
Training loss: 2.166972383302925
Validation loss: 2.6577050505964697

Epoch: 6| Step: 2
Training loss: 1.6139606218414935
Validation loss: 2.694953887228825

Epoch: 6| Step: 3
Training loss: 2.0491716153319204
Validation loss: 2.634006067449079

Epoch: 6| Step: 4
Training loss: 1.6857020371894953
Validation loss: 2.6063326309485473

Epoch: 6| Step: 5
Training loss: 2.0522786804269564
Validation loss: 2.56308384578656

Epoch: 6| Step: 6
Training loss: 1.6531742975567993
Validation loss: 2.5548180907427236

Epoch: 6| Step: 7
Training loss: 1.2214504060331302
Validation loss: 2.6011074764149003

Epoch: 6| Step: 8
Training loss: 2.244625347965284
Validation loss: 2.6022978880250065

Epoch: 6| Step: 9
Training loss: 1.0962335998978703
Validation loss: 2.6017855070375684

Epoch: 6| Step: 10
Training loss: 1.8333858858148036
Validation loss: 2.5403378457689754

Epoch: 6| Step: 11
Training loss: 1.9646267173833853
Validation loss: 2.6158581750165557

Epoch: 6| Step: 12
Training loss: 1.4273552554313589
Validation loss: 2.642309896535612

Epoch: 6| Step: 13
Training loss: 2.332177239070495
Validation loss: 2.5904474336383045

Epoch: 345| Step: 0
Training loss: 2.3767091724648424
Validation loss: 2.581027052566974

Epoch: 6| Step: 1
Training loss: 1.6841187687398058
Validation loss: 2.6073601076046535

Epoch: 6| Step: 2
Training loss: 1.4815796883581127
Validation loss: 2.5525202837719387

Epoch: 6| Step: 3
Training loss: 1.3611101060764124
Validation loss: 2.5807331417500934

Epoch: 6| Step: 4
Training loss: 2.289524487429658
Validation loss: 2.5757685054625363

Epoch: 6| Step: 5
Training loss: 1.4223792051975084
Validation loss: 2.6316576650206653

Epoch: 6| Step: 6
Training loss: 1.8185314584632657
Validation loss: 2.560811734946877

Epoch: 6| Step: 7
Training loss: 1.5637199979567595
Validation loss: 2.6147589656205503

Epoch: 6| Step: 8
Training loss: 2.084674924578941
Validation loss: 2.5932195956075312

Epoch: 6| Step: 9
Training loss: 1.2264300232312215
Validation loss: 2.555383235597233

Epoch: 6| Step: 10
Training loss: 2.1621435588281215
Validation loss: 2.56370603666611

Epoch: 6| Step: 11
Training loss: 1.8837061617078195
Validation loss: 2.5438760680905173

Epoch: 6| Step: 12
Training loss: 1.2425202697697024
Validation loss: 2.605118376714103

Epoch: 6| Step: 13
Training loss: 2.621712033250511
Validation loss: 2.578593910807642

Epoch: 346| Step: 0
Training loss: 1.7584991470304476
Validation loss: 2.5693845532857615

Epoch: 6| Step: 1
Training loss: 1.631676164403957
Validation loss: 2.581928237653045

Epoch: 6| Step: 2
Training loss: 1.8768892942246935
Validation loss: 2.6197470224468353

Epoch: 6| Step: 3
Training loss: 2.422658485920848
Validation loss: 2.6333038294221804

Epoch: 6| Step: 4
Training loss: 1.3565897854352529
Validation loss: 2.622761150069391

Epoch: 6| Step: 5
Training loss: 1.6842729300463637
Validation loss: 2.6422273638496745

Epoch: 6| Step: 6
Training loss: 2.183171922478146
Validation loss: 2.706916634177717

Epoch: 6| Step: 7
Training loss: 1.803008318056203
Validation loss: 2.6671241700591466

Epoch: 6| Step: 8
Training loss: 2.229593776772762
Validation loss: 2.633229631080125

Epoch: 6| Step: 9
Training loss: 1.5915981800597188
Validation loss: 2.5902343731590967

Epoch: 6| Step: 10
Training loss: 1.678852956289005
Validation loss: 2.5742699671557467

Epoch: 6| Step: 11
Training loss: 2.117230629569637
Validation loss: 2.5375568170560032

Epoch: 6| Step: 12
Training loss: 1.9469168301859991
Validation loss: 2.5594242834889656

Epoch: 6| Step: 13
Training loss: 1.9832945758441316
Validation loss: 2.609804220931953

Epoch: 347| Step: 0
Training loss: 2.1728396023196113
Validation loss: 2.5935363221913352

Epoch: 6| Step: 1
Training loss: 2.269356016659061
Validation loss: 2.5824548832588903

Epoch: 6| Step: 2
Training loss: 1.7620486608187815
Validation loss: 2.599675461186801

Epoch: 6| Step: 3
Training loss: 1.5672112201633694
Validation loss: 2.6446945838693616

Epoch: 6| Step: 4
Training loss: 1.5432518807922995
Validation loss: 2.701801262581084

Epoch: 6| Step: 5
Training loss: 2.0590375099859877
Validation loss: 2.7547785394301907

Epoch: 6| Step: 6
Training loss: 2.138991129139415
Validation loss: 2.777529725019574

Epoch: 6| Step: 7
Training loss: 2.323123962549897
Validation loss: 2.683366968603577

Epoch: 6| Step: 8
Training loss: 1.3501814914494275
Validation loss: 2.660355054957937

Epoch: 6| Step: 9
Training loss: 1.4030117048644004
Validation loss: 2.6079179270503023

Epoch: 6| Step: 10
Training loss: 1.3977949914788756
Validation loss: 2.5587101490052597

Epoch: 6| Step: 11
Training loss: 2.501948741518896
Validation loss: 2.5568098610122867

Epoch: 6| Step: 12
Training loss: 1.4643017389171622
Validation loss: 2.5644370952801525

Epoch: 6| Step: 13
Training loss: 1.5085613387511487
Validation loss: 2.588232145986453

Epoch: 348| Step: 0
Training loss: 1.8186119551558186
Validation loss: 2.583214839145572

Epoch: 6| Step: 1
Training loss: 1.9879785693297245
Validation loss: 2.5782530088145426

Epoch: 6| Step: 2
Training loss: 2.150848478519877
Validation loss: 2.6295385634732975

Epoch: 6| Step: 3
Training loss: 1.1189878669060531
Validation loss: 2.6070430790022474

Epoch: 6| Step: 4
Training loss: 1.9132820873951821
Validation loss: 2.575333210764991

Epoch: 6| Step: 5
Training loss: 1.6191152241627527
Validation loss: 2.6041413776441362

Epoch: 6| Step: 6
Training loss: 2.103445577916237
Validation loss: 2.6321856075930565

Epoch: 6| Step: 7
Training loss: 1.993576104404222
Validation loss: 2.6708802868251333

Epoch: 6| Step: 8
Training loss: 1.9517305202555242
Validation loss: 2.6705843985521676

Epoch: 6| Step: 9
Training loss: 2.034520494734239
Validation loss: 2.647896695505658

Epoch: 6| Step: 10
Training loss: 1.8564170582410673
Validation loss: 2.6038415222638234

Epoch: 6| Step: 11
Training loss: 1.263279424983342
Validation loss: 2.6359990397477127

Epoch: 6| Step: 12
Training loss: 2.4300809584581016
Validation loss: 2.6510792387952296

Epoch: 6| Step: 13
Training loss: 2.186482656148831
Validation loss: 2.5925517704060836

Epoch: 349| Step: 0
Training loss: 1.74512415512564
Validation loss: 2.587955344488488

Epoch: 6| Step: 1
Training loss: 1.428469446493067
Validation loss: 2.597282302442602

Epoch: 6| Step: 2
Training loss: 2.1188290696595433
Validation loss: 2.6261531855080675

Epoch: 6| Step: 3
Training loss: 1.5149625923398125
Validation loss: 2.599546122671119

Epoch: 6| Step: 4
Training loss: 1.7633192147024437
Validation loss: 2.579607958985465

Epoch: 6| Step: 5
Training loss: 2.268601139954344
Validation loss: 2.56393163898417

Epoch: 6| Step: 6
Training loss: 1.9193211155951178
Validation loss: 2.5586125419256627

Epoch: 6| Step: 7
Training loss: 1.4932825354610193
Validation loss: 2.6135956518548253

Epoch: 6| Step: 8
Training loss: 1.4331521333703667
Validation loss: 2.660611539876397

Epoch: 6| Step: 9
Training loss: 1.7189900317344107
Validation loss: 2.640481331733561

Epoch: 6| Step: 10
Training loss: 2.1565234245869522
Validation loss: 2.6689088653521265

Epoch: 6| Step: 11
Training loss: 1.8844539088085515
Validation loss: 2.6806999644207106

Epoch: 6| Step: 12
Training loss: 2.297206828742196
Validation loss: 2.6687430156107146

Epoch: 6| Step: 13
Training loss: 1.304641265963646
Validation loss: 2.6239005768585377

Epoch: 350| Step: 0
Training loss: 1.9720866070119816
Validation loss: 2.583139909660776

Epoch: 6| Step: 1
Training loss: 2.031587660674319
Validation loss: 2.566856511224913

Epoch: 6| Step: 2
Training loss: 2.162882899965887
Validation loss: 2.5767372480778703

Epoch: 6| Step: 3
Training loss: 1.6763016041799488
Validation loss: 2.625635297283347

Epoch: 6| Step: 4
Training loss: 1.0180601417110917
Validation loss: 2.589468582160128

Epoch: 6| Step: 5
Training loss: 1.7587836401568275
Validation loss: 2.5818051822591923

Epoch: 6| Step: 6
Training loss: 1.6324048423197983
Validation loss: 2.560342035118956

Epoch: 6| Step: 7
Training loss: 1.552993925462229
Validation loss: 2.554799714185548

Epoch: 6| Step: 8
Training loss: 2.025793875976007
Validation loss: 2.6002994407714333

Epoch: 6| Step: 9
Training loss: 2.100008365069486
Validation loss: 2.5940507308471785

Epoch: 6| Step: 10
Training loss: 1.9440061173558627
Validation loss: 2.6655921161825056

Epoch: 6| Step: 11
Training loss: 1.9391044618306672
Validation loss: 2.656092291245362

Epoch: 6| Step: 12
Training loss: 1.9064960008324658
Validation loss: 2.732375716500538

Epoch: 6| Step: 13
Training loss: 1.7043798181223009
Validation loss: 2.7954214144151024

Epoch: 351| Step: 0
Training loss: 1.2456700672011032
Validation loss: 2.7274864839101807

Epoch: 6| Step: 1
Training loss: 1.824126933562444
Validation loss: 2.6832417900945305

Epoch: 6| Step: 2
Training loss: 1.3761625577084444
Validation loss: 2.650900011955874

Epoch: 6| Step: 3
Training loss: 2.1976602293236835
Validation loss: 2.5936301483285087

Epoch: 6| Step: 4
Training loss: 1.4589326535291371
Validation loss: 2.5832643243329825

Epoch: 6| Step: 5
Training loss: 1.6287259155272737
Validation loss: 2.6162448381062275

Epoch: 6| Step: 6
Training loss: 1.0735455432251586
Validation loss: 2.533498275766287

Epoch: 6| Step: 7
Training loss: 2.2373576497236867
Validation loss: 2.58109867185001

Epoch: 6| Step: 8
Training loss: 1.5990065112813385
Validation loss: 2.5835093674108154

Epoch: 6| Step: 9
Training loss: 2.2421855860047364
Validation loss: 2.57913339333546

Epoch: 6| Step: 10
Training loss: 2.595354801685284
Validation loss: 2.5524995399571826

Epoch: 6| Step: 11
Training loss: 1.523733726458376
Validation loss: 2.5467695280675526

Epoch: 6| Step: 12
Training loss: 1.9251391595850156
Validation loss: 2.592676162571224

Epoch: 6| Step: 13
Training loss: 1.5242826807173475
Validation loss: 2.6053738402810156

Epoch: 352| Step: 0
Training loss: 2.2894245160887405
Validation loss: 2.6543047345559456

Epoch: 6| Step: 1
Training loss: 1.9561582891154783
Validation loss: 2.611531415438385

Epoch: 6| Step: 2
Training loss: 1.6751461648508472
Validation loss: 2.6141229556021313

Epoch: 6| Step: 3
Training loss: 1.890836467423692
Validation loss: 2.543646507751016

Epoch: 6| Step: 4
Training loss: 1.2489202604411171
Validation loss: 2.598461024548143

Epoch: 6| Step: 5
Training loss: 2.3161779487384315
Validation loss: 2.5728165199053468

Epoch: 6| Step: 6
Training loss: 1.3727909028603278
Validation loss: 2.571606357738361

Epoch: 6| Step: 7
Training loss: 2.1103549517701845
Validation loss: 2.5393621962300643

Epoch: 6| Step: 8
Training loss: 1.6997475689111632
Validation loss: 2.5833722901226954

Epoch: 6| Step: 9
Training loss: 1.5060290922518675
Validation loss: 2.5651050135164106

Epoch: 6| Step: 10
Training loss: 2.139755629375089
Validation loss: 2.60915449204392

Epoch: 6| Step: 11
Training loss: 1.7253405359246576
Validation loss: 2.578693851174628

Epoch: 6| Step: 12
Training loss: 1.3156151814218962
Validation loss: 2.603457824874345

Epoch: 6| Step: 13
Training loss: 1.7968253087346173
Validation loss: 2.590738378849952

Epoch: 353| Step: 0
Training loss: 1.5488784608682982
Validation loss: 2.6160030436648785

Epoch: 6| Step: 1
Training loss: 1.508775867787167
Validation loss: 2.5903269229302834

Epoch: 6| Step: 2
Training loss: 1.773781091956563
Validation loss: 2.6191809658477845

Epoch: 6| Step: 3
Training loss: 1.674884689689079
Validation loss: 2.642097777218018

Epoch: 6| Step: 4
Training loss: 1.9574332975908046
Validation loss: 2.7243695845188762

Epoch: 6| Step: 5
Training loss: 1.9183241753755917
Validation loss: 2.710643001101111

Epoch: 6| Step: 6
Training loss: 2.1471320607791644
Validation loss: 2.6871051941905804

Epoch: 6| Step: 7
Training loss: 1.5243459487154996
Validation loss: 2.6193945389685376

Epoch: 6| Step: 8
Training loss: 1.971618318854415
Validation loss: 2.6205200537724784

Epoch: 6| Step: 9
Training loss: 1.6004871759207773
Validation loss: 2.6032491110179814

Epoch: 6| Step: 10
Training loss: 2.3654335498817654
Validation loss: 2.6471313586612837

Epoch: 6| Step: 11
Training loss: 2.2030270602053044
Validation loss: 2.6397697974996035

Epoch: 6| Step: 12
Training loss: 1.3016611966267693
Validation loss: 2.6428604069190076

Epoch: 6| Step: 13
Training loss: 1.9214042148981036
Validation loss: 2.6322131885040583

Epoch: 354| Step: 0
Training loss: 1.153988869717505
Validation loss: 2.6412108935692507

Epoch: 6| Step: 1
Training loss: 2.0657868060799083
Validation loss: 2.6280001344172708

Epoch: 6| Step: 2
Training loss: 1.8660839442826185
Validation loss: 2.648278350699451

Epoch: 6| Step: 3
Training loss: 2.108957998241878
Validation loss: 2.6686323391589215

Epoch: 6| Step: 4
Training loss: 1.0921065926770503
Validation loss: 2.68986779522681

Epoch: 6| Step: 5
Training loss: 1.6480569987902713
Validation loss: 2.6734730661487447

Epoch: 6| Step: 6
Training loss: 2.0331344079856253
Validation loss: 2.672620464829884

Epoch: 6| Step: 7
Training loss: 1.1683319445686593
Validation loss: 2.646399269753217

Epoch: 6| Step: 8
Training loss: 1.5200380397102362
Validation loss: 2.655159651673049

Epoch: 6| Step: 9
Training loss: 1.2157838379317978
Validation loss: 2.62606826117089

Epoch: 6| Step: 10
Training loss: 2.114072415370202
Validation loss: 2.6146157909876186

Epoch: 6| Step: 11
Training loss: 2.532291716043798
Validation loss: 2.628983245674338

Epoch: 6| Step: 12
Training loss: 1.4155504185985763
Validation loss: 2.6103830579424376

Epoch: 6| Step: 13
Training loss: 1.9927369799817332
Validation loss: 2.667510649121475

Epoch: 355| Step: 0
Training loss: 1.825624108397551
Validation loss: 2.717273135642774

Epoch: 6| Step: 1
Training loss: 2.3305542835853004
Validation loss: 2.6692802367005988

Epoch: 6| Step: 2
Training loss: 2.098352412631209
Validation loss: 2.6840713497988187

Epoch: 6| Step: 3
Training loss: 1.5685288657151921
Validation loss: 2.6474479094301664

Epoch: 6| Step: 4
Training loss: 1.3858747035855699
Validation loss: 2.557506347678204

Epoch: 6| Step: 5
Training loss: 1.887523218984715
Validation loss: 2.564914000508968

Epoch: 6| Step: 6
Training loss: 1.6483115921026685
Validation loss: 2.6115495525588592

Epoch: 6| Step: 7
Training loss: 1.2037476748942166
Validation loss: 2.653139604544011

Epoch: 6| Step: 8
Training loss: 1.8754297399782074
Validation loss: 2.601465049652092

Epoch: 6| Step: 9
Training loss: 1.8487658404947735
Validation loss: 2.5764852376118035

Epoch: 6| Step: 10
Training loss: 2.2770975022312876
Validation loss: 2.541326098737329

Epoch: 6| Step: 11
Training loss: 2.01655308847612
Validation loss: 2.584767310222822

Epoch: 6| Step: 12
Training loss: 1.507115969098438
Validation loss: 2.659998862474241

Epoch: 6| Step: 13
Training loss: 1.574591429259635
Validation loss: 2.6199779456911463

Epoch: 356| Step: 0
Training loss: 2.102769016105957
Validation loss: 2.5972037243878505

Epoch: 6| Step: 1
Training loss: 1.4004861753844384
Validation loss: 2.5853777046147046

Epoch: 6| Step: 2
Training loss: 1.4337943038148309
Validation loss: 2.569181431090571

Epoch: 6| Step: 3
Training loss: 2.1125338038160772
Validation loss: 2.566837470039796

Epoch: 6| Step: 4
Training loss: 1.7558379209096706
Validation loss: 2.5684560701953845

Epoch: 6| Step: 5
Training loss: 1.6582903979444599
Validation loss: 2.5733416176779556

Epoch: 6| Step: 6
Training loss: 2.3122859546473853
Validation loss: 2.5797325131890507

Epoch: 6| Step: 7
Training loss: 1.6620356434696502
Validation loss: 2.561795362649477

Epoch: 6| Step: 8
Training loss: 2.540173284672152
Validation loss: 2.5884569539280857

Epoch: 6| Step: 9
Training loss: 1.323571466108155
Validation loss: 2.5899634546968895

Epoch: 6| Step: 10
Training loss: 1.5547612618435493
Validation loss: 2.5770420921272

Epoch: 6| Step: 11
Training loss: 1.7348679537915546
Validation loss: 2.6622508760770183

Epoch: 6| Step: 12
Training loss: 1.5563289086126515
Validation loss: 2.604694974080396

Epoch: 6| Step: 13
Training loss: 1.3596055284785575
Validation loss: 2.614246290958377

Epoch: 357| Step: 0
Training loss: 1.774803274294103
Validation loss: 2.6130730318408024

Epoch: 6| Step: 1
Training loss: 1.7599246750231587
Validation loss: 2.640175700289403

Epoch: 6| Step: 2
Training loss: 1.7244050368222852
Validation loss: 2.5568018027786032

Epoch: 6| Step: 3
Training loss: 1.5854132777147336
Validation loss: 2.5882268876710155

Epoch: 6| Step: 4
Training loss: 1.085420993398486
Validation loss: 2.614188864892069

Epoch: 6| Step: 5
Training loss: 2.259500051074229
Validation loss: 2.6231699952756555

Epoch: 6| Step: 6
Training loss: 2.1478287267828193
Validation loss: 2.6306945854899344

Epoch: 6| Step: 7
Training loss: 1.41763242826205
Validation loss: 2.5868557224629116

Epoch: 6| Step: 8
Training loss: 1.7747630404412265
Validation loss: 2.571937024468292

Epoch: 6| Step: 9
Training loss: 1.5518443885884412
Validation loss: 2.6430726454420554

Epoch: 6| Step: 10
Training loss: 1.7198533418141335
Validation loss: 2.613756624101211

Epoch: 6| Step: 11
Training loss: 1.2579748392484846
Validation loss: 2.58778049066699

Epoch: 6| Step: 12
Training loss: 2.519983437347479
Validation loss: 2.6141054291666945

Epoch: 6| Step: 13
Training loss: 1.7727626239035017
Validation loss: 2.6139530521516927

Epoch: 358| Step: 0
Training loss: 1.4996930444085916
Validation loss: 2.731932131960344

Epoch: 6| Step: 1
Training loss: 1.759381217335748
Validation loss: 2.7037169409224147

Epoch: 6| Step: 2
Training loss: 3.02954588505494
Validation loss: 2.7776824987813225

Epoch: 6| Step: 3
Training loss: 1.6598328757897187
Validation loss: 2.7632245783539404

Epoch: 6| Step: 4
Training loss: 1.5838604936240248
Validation loss: 2.7235218425332626

Epoch: 6| Step: 5
Training loss: 1.9604531104024263
Validation loss: 2.7290210587968144

Epoch: 6| Step: 6
Training loss: 1.4252485560430102
Validation loss: 2.632992165733608

Epoch: 6| Step: 7
Training loss: 1.7057101027804147
Validation loss: 2.607583022644422

Epoch: 6| Step: 8
Training loss: 1.720215259544372
Validation loss: 2.6084797098039583

Epoch: 6| Step: 9
Training loss: 1.4552057607086895
Validation loss: 2.5677916930455433

Epoch: 6| Step: 10
Training loss: 1.9895664700364342
Validation loss: 2.5936301330077316

Epoch: 6| Step: 11
Training loss: 2.000594646744381
Validation loss: 2.6164297041131745

Epoch: 6| Step: 12
Training loss: 1.3592267887392149
Validation loss: 2.601661397678954

Epoch: 6| Step: 13
Training loss: 1.5549612139804783
Validation loss: 2.6158800797560717

Epoch: 359| Step: 0
Training loss: 1.2053035481965895
Validation loss: 2.6201899373024267

Epoch: 6| Step: 1
Training loss: 2.172497337699637
Validation loss: 2.6177852118896956

Epoch: 6| Step: 2
Training loss: 1.6040484232073982
Validation loss: 2.636620760380186

Epoch: 6| Step: 3
Training loss: 1.4307812118738563
Validation loss: 2.6700294619921876

Epoch: 6| Step: 4
Training loss: 2.128258058754751
Validation loss: 2.731426982252134

Epoch: 6| Step: 5
Training loss: 1.9225258074195237
Validation loss: 2.6754356291005417

Epoch: 6| Step: 6
Training loss: 1.7786348788443966
Validation loss: 2.6334919566856163

Epoch: 6| Step: 7
Training loss: 1.7837909845082647
Validation loss: 2.5861043732151643

Epoch: 6| Step: 8
Training loss: 1.7113327893557326
Validation loss: 2.5582115140194785

Epoch: 6| Step: 9
Training loss: 1.7367235383565343
Validation loss: 2.563444025711173

Epoch: 6| Step: 10
Training loss: 1.9980537958854965
Validation loss: 2.6123462519205995

Epoch: 6| Step: 11
Training loss: 2.1901085695153673
Validation loss: 2.6235360347259524

Epoch: 6| Step: 12
Training loss: 1.75216431976764
Validation loss: 2.5917147039109456

Epoch: 6| Step: 13
Training loss: 1.8186940214056635
Validation loss: 2.624928064723051

Epoch: 360| Step: 0
Training loss: 1.8356415205651415
Validation loss: 2.647163497293009

Epoch: 6| Step: 1
Training loss: 1.8072820071384588
Validation loss: 2.6831555256268587

Epoch: 6| Step: 2
Training loss: 1.3360336001448252
Validation loss: 2.7273090437195466

Epoch: 6| Step: 3
Training loss: 2.0743752975440666
Validation loss: 2.7621522065988002

Epoch: 6| Step: 4
Training loss: 2.336666746080572
Validation loss: 2.7911589621061723

Epoch: 6| Step: 5
Training loss: 2.302948686949868
Validation loss: 2.8174562300311927

Epoch: 6| Step: 6
Training loss: 1.3054062924833787
Validation loss: 2.7383088216150844

Epoch: 6| Step: 7
Training loss: 1.7578915048434882
Validation loss: 2.6924292876658074

Epoch: 6| Step: 8
Training loss: 1.901158772523938
Validation loss: 2.6283695226639967

Epoch: 6| Step: 9
Training loss: 1.2448520512745191
Validation loss: 2.6051079129878225

Epoch: 6| Step: 10
Training loss: 1.8736660344687694
Validation loss: 2.6277847505234555

Epoch: 6| Step: 11
Training loss: 1.9652204815974932
Validation loss: 2.6392109863957205

Epoch: 6| Step: 12
Training loss: 0.9670439433357128
Validation loss: 2.63357775817319

Epoch: 6| Step: 13
Training loss: 1.55746227677954
Validation loss: 2.5790473598151538

Epoch: 361| Step: 0
Training loss: 1.456999995737593
Validation loss: 2.6823694063544266

Epoch: 6| Step: 1
Training loss: 2.2589418959049627
Validation loss: 2.6111139910143217

Epoch: 6| Step: 2
Training loss: 2.5174460128556526
Validation loss: 2.6585113025353513

Epoch: 6| Step: 3
Training loss: 1.632973402938514
Validation loss: 2.663933073089981

Epoch: 6| Step: 4
Training loss: 2.323774433140916
Validation loss: 2.795044170114787

Epoch: 6| Step: 5
Training loss: 1.396577418502233
Validation loss: 2.7514217487289847

Epoch: 6| Step: 6
Training loss: 1.790847354418062
Validation loss: 2.7550920679455424

Epoch: 6| Step: 7
Training loss: 1.6581259126513315
Validation loss: 2.682065066546554

Epoch: 6| Step: 8
Training loss: 1.5294430249998139
Validation loss: 2.6623200864703107

Epoch: 6| Step: 9
Training loss: 1.5944933186364467
Validation loss: 2.6353086567534088

Epoch: 6| Step: 10
Training loss: 1.817989192859183
Validation loss: 2.610283973124212

Epoch: 6| Step: 11
Training loss: 2.065154823429146
Validation loss: 2.5916331205210614

Epoch: 6| Step: 12
Training loss: 1.3088411922800993
Validation loss: 2.5908129045284922

Epoch: 6| Step: 13
Training loss: 1.7649203219273315
Validation loss: 2.6346786480896958

Epoch: 362| Step: 0
Training loss: 1.6486558814728853
Validation loss: 2.5890039201370096

Epoch: 6| Step: 1
Training loss: 1.301203845228863
Validation loss: 2.573496028726371

Epoch: 6| Step: 2
Training loss: 1.1910212660843882
Validation loss: 2.581441376175051

Epoch: 6| Step: 3
Training loss: 1.4382407726122468
Validation loss: 2.5865091343188755

Epoch: 6| Step: 4
Training loss: 1.7969516903641125
Validation loss: 2.5574203945684104

Epoch: 6| Step: 5
Training loss: 1.7190658279162054
Validation loss: 2.5636162536343923

Epoch: 6| Step: 6
Training loss: 2.1806179234790863
Validation loss: 2.5801498168256476

Epoch: 6| Step: 7
Training loss: 1.8176660250428214
Validation loss: 2.652065226894359

Epoch: 6| Step: 8
Training loss: 1.6650993448123395
Validation loss: 2.7349483361208495

Epoch: 6| Step: 9
Training loss: 2.3593383179901464
Validation loss: 2.706620853612632

Epoch: 6| Step: 10
Training loss: 1.876359827943046
Validation loss: 2.7337199125769485

Epoch: 6| Step: 11
Training loss: 1.4153345614293347
Validation loss: 2.6324976007366687

Epoch: 6| Step: 12
Training loss: 1.8385323226158143
Validation loss: 2.62858611335636

Epoch: 6| Step: 13
Training loss: 1.5248802200554499
Validation loss: 2.6404078016171937

Epoch: 363| Step: 0
Training loss: 1.6912578843659691
Validation loss: 2.642960089657034

Epoch: 6| Step: 1
Training loss: 1.3844659693604164
Validation loss: 2.6499679704445906

Epoch: 6| Step: 2
Training loss: 1.4350683128232895
Validation loss: 2.638657282542575

Epoch: 6| Step: 3
Training loss: 1.7978949927492993
Validation loss: 2.6636017730061563

Epoch: 6| Step: 4
Training loss: 1.6346861388139375
Validation loss: 2.662513857045776

Epoch: 6| Step: 5
Training loss: 2.0968129542533145
Validation loss: 2.7082705576052546

Epoch: 6| Step: 6
Training loss: 1.9228913635815401
Validation loss: 2.6618601401765836

Epoch: 6| Step: 7
Training loss: 1.3127324942891068
Validation loss: 2.67587281601807

Epoch: 6| Step: 8
Training loss: 2.0753806213218224
Validation loss: 2.73138914299426

Epoch: 6| Step: 9
Training loss: 1.1989916856746317
Validation loss: 2.6692179207868545

Epoch: 6| Step: 10
Training loss: 2.7086971821056194
Validation loss: 2.6975222167902353

Epoch: 6| Step: 11
Training loss: 1.8233819712835553
Validation loss: 2.646577780413668

Epoch: 6| Step: 12
Training loss: 1.6914093510905464
Validation loss: 2.6087700757465297

Epoch: 6| Step: 13
Training loss: 1.7567514565699163
Validation loss: 2.6288650758871666

Epoch: 364| Step: 0
Training loss: 2.067385926242046
Validation loss: 2.5933735279345007

Epoch: 6| Step: 1
Training loss: 1.9792595958643335
Validation loss: 2.5996831037506585

Epoch: 6| Step: 2
Training loss: 1.8227512902221383
Validation loss: 2.6216342328978093

Epoch: 6| Step: 3
Training loss: 1.588967796661951
Validation loss: 2.609544790382158

Epoch: 6| Step: 4
Training loss: 1.3902268857826559
Validation loss: 2.615655403158004

Epoch: 6| Step: 5
Training loss: 1.2420542903466245
Validation loss: 2.6831962368774414

Epoch: 6| Step: 6
Training loss: 1.1166059674424167
Validation loss: 2.6740394956434295

Epoch: 6| Step: 7
Training loss: 2.2465089629805517
Validation loss: 2.6549342318648788

Epoch: 6| Step: 8
Training loss: 1.6727421018259783
Validation loss: 2.6812914171554625

Epoch: 6| Step: 9
Training loss: 1.8474398399541339
Validation loss: 2.70158870309978

Epoch: 6| Step: 10
Training loss: 2.217751936680233
Validation loss: 2.687774762442842

Epoch: 6| Step: 11
Training loss: 1.4072929753152263
Validation loss: 2.6817598772495015

Epoch: 6| Step: 12
Training loss: 1.6471024300108084
Validation loss: 2.726600850736417

Epoch: 6| Step: 13
Training loss: 1.5079427079819812
Validation loss: 2.6647860979046816

Epoch: 365| Step: 0
Training loss: 1.5685977208368158
Validation loss: 2.657582192045586

Epoch: 6| Step: 1
Training loss: 1.2437767083448912
Validation loss: 2.660796817951513

Epoch: 6| Step: 2
Training loss: 1.2366544705600973
Validation loss: 2.64711616735532

Epoch: 6| Step: 3
Training loss: 1.918742223966169
Validation loss: 2.618651812646591

Epoch: 6| Step: 4
Training loss: 1.5848724848238913
Validation loss: 2.61250301951062

Epoch: 6| Step: 5
Training loss: 1.8534567113101625
Validation loss: 2.608858510447429

Epoch: 6| Step: 6
Training loss: 2.3866849856321823
Validation loss: 2.5734002023204825

Epoch: 6| Step: 7
Training loss: 2.0782686341633196
Validation loss: 2.594830146380699

Epoch: 6| Step: 8
Training loss: 2.056134428817259
Validation loss: 2.563789740914232

Epoch: 6| Step: 9
Training loss: 1.3196140224950168
Validation loss: 2.6325799101619434

Epoch: 6| Step: 10
Training loss: 1.2874622006098928
Validation loss: 2.6332945641750114

Epoch: 6| Step: 11
Training loss: 1.8667960933820162
Validation loss: 2.727056915722547

Epoch: 6| Step: 12
Training loss: 2.020364084197411
Validation loss: 2.7577031359722395

Epoch: 6| Step: 13
Training loss: 1.9408499152770626
Validation loss: 2.768531837795184

Epoch: 366| Step: 0
Training loss: 1.5512620771431311
Validation loss: 2.7055856901035913

Epoch: 6| Step: 1
Training loss: 1.2854114963091585
Validation loss: 2.6082876684885736

Epoch: 6| Step: 2
Training loss: 1.94217450236531
Validation loss: 2.5865529721465466

Epoch: 6| Step: 3
Training loss: 0.8824631328824786
Validation loss: 2.5999526043998045

Epoch: 6| Step: 4
Training loss: 1.5971390836151023
Validation loss: 2.5771157341053326

Epoch: 6| Step: 5
Training loss: 2.0805255534045095
Validation loss: 2.5955737033609463

Epoch: 6| Step: 6
Training loss: 1.8020549911592902
Validation loss: 2.586934707000486

Epoch: 6| Step: 7
Training loss: 2.0401264790988365
Validation loss: 2.599319896635222

Epoch: 6| Step: 8
Training loss: 1.867143638446814
Validation loss: 2.6025433987026103

Epoch: 6| Step: 9
Training loss: 1.7604429780998974
Validation loss: 2.633877803753505

Epoch: 6| Step: 10
Training loss: 1.5256382622742075
Validation loss: 2.618193050813582

Epoch: 6| Step: 11
Training loss: 1.663747265109158
Validation loss: 2.6491690931482075

Epoch: 6| Step: 12
Training loss: 2.3859328554079506
Validation loss: 2.635784761759404

Epoch: 6| Step: 13
Training loss: 1.929728457367563
Validation loss: 2.6359089377799894

Epoch: 367| Step: 0
Training loss: 1.457109791783893
Validation loss: 2.6044951168196877

Epoch: 6| Step: 1
Training loss: 1.8424361121852044
Validation loss: 2.6463506047786014

Epoch: 6| Step: 2
Training loss: 1.5176423008922892
Validation loss: 2.598410406562092

Epoch: 6| Step: 3
Training loss: 1.3223363499624239
Validation loss: 2.6347769210795735

Epoch: 6| Step: 4
Training loss: 1.771302538774336
Validation loss: 2.624661363224094

Epoch: 6| Step: 5
Training loss: 0.9675285268121621
Validation loss: 2.626114971787602

Epoch: 6| Step: 6
Training loss: 2.138547125535462
Validation loss: 2.6240357489912847

Epoch: 6| Step: 7
Training loss: 1.8642899124315386
Validation loss: 2.6212017796971083

Epoch: 6| Step: 8
Training loss: 1.9318181063402131
Validation loss: 2.604820952556064

Epoch: 6| Step: 9
Training loss: 1.793696835358044
Validation loss: 2.6084507049461516

Epoch: 6| Step: 10
Training loss: 2.293104437431496
Validation loss: 2.636488629883845

Epoch: 6| Step: 11
Training loss: 1.4550859899116304
Validation loss: 2.665329245125118

Epoch: 6| Step: 12
Training loss: 1.630115819221422
Validation loss: 2.677260149350035

Epoch: 6| Step: 13
Training loss: 1.6913674154074205
Validation loss: 2.7345207684127497

Epoch: 368| Step: 0
Training loss: 1.4876308672101477
Validation loss: 2.695514439191233

Epoch: 6| Step: 1
Training loss: 1.7485106806572028
Validation loss: 2.6113142014605195

Epoch: 6| Step: 2
Training loss: 1.6124359946152769
Validation loss: 2.591754022783972

Epoch: 6| Step: 3
Training loss: 2.0452511002290845
Validation loss: 2.6574538251825364

Epoch: 6| Step: 4
Training loss: 1.5328799544957914
Validation loss: 2.579087649867222

Epoch: 6| Step: 5
Training loss: 1.8963465851720644
Validation loss: 2.671002801486876

Epoch: 6| Step: 6
Training loss: 2.0229007200430362
Validation loss: 2.649070244056633

Epoch: 6| Step: 7
Training loss: 1.7865945376715904
Validation loss: 2.6449684371459194

Epoch: 6| Step: 8
Training loss: 1.5104740351162935
Validation loss: 2.701794541298035

Epoch: 6| Step: 9
Training loss: 1.464062454402764
Validation loss: 2.6512237416354485

Epoch: 6| Step: 10
Training loss: 2.174911900632459
Validation loss: 2.6794766119745193

Epoch: 6| Step: 11
Training loss: 1.123528365703621
Validation loss: 2.6805884771570945

Epoch: 6| Step: 12
Training loss: 1.3030192965808154
Validation loss: 2.6756107767937887

Epoch: 6| Step: 13
Training loss: 1.5392836203733167
Validation loss: 2.6275556173587336

Epoch: 369| Step: 0
Training loss: 1.6518846960862064
Validation loss: 2.650313306677234

Epoch: 6| Step: 1
Training loss: 2.3375642655457924
Validation loss: 2.6416396800526982

Epoch: 6| Step: 2
Training loss: 1.9260561980845552
Validation loss: 2.6279324092446887

Epoch: 6| Step: 3
Training loss: 1.6762253677413048
Validation loss: 2.6976394854600163

Epoch: 6| Step: 4
Training loss: 0.9952578159802491
Validation loss: 2.5813803417435075

Epoch: 6| Step: 5
Training loss: 1.6017857837874434
Validation loss: 2.650438301259197

Epoch: 6| Step: 6
Training loss: 2.381289235990781
Validation loss: 2.625540927375452

Epoch: 6| Step: 7
Training loss: 1.636287951164084
Validation loss: 2.6262055308205228

Epoch: 6| Step: 8
Training loss: 1.270667122566272
Validation loss: 2.601625397831613

Epoch: 6| Step: 9
Training loss: 1.2852411213130166
Validation loss: 2.657419590479646

Epoch: 6| Step: 10
Training loss: 1.833524636200107
Validation loss: 2.6077321071586894

Epoch: 6| Step: 11
Training loss: 1.489254530606015
Validation loss: 2.6198088314841486

Epoch: 6| Step: 12
Training loss: 1.679777772828557
Validation loss: 2.6405479299520476

Epoch: 6| Step: 13
Training loss: 1.545305631215381
Validation loss: 2.6005008276280592

Epoch: 370| Step: 0
Training loss: 1.9139868896497751
Validation loss: 2.6762252550615893

Epoch: 6| Step: 1
Training loss: 1.9538166499957301
Validation loss: 2.711619589064202

Epoch: 6| Step: 2
Training loss: 1.1170402376445934
Validation loss: 2.6821294099687005

Epoch: 6| Step: 3
Training loss: 2.171572218173431
Validation loss: 2.741635186344128

Epoch: 6| Step: 4
Training loss: 1.4637919400898716
Validation loss: 2.734817556262216

Epoch: 6| Step: 5
Training loss: 1.7824557055176906
Validation loss: 2.728913926416742

Epoch: 6| Step: 6
Training loss: 1.5319582799703861
Validation loss: 2.732436722921186

Epoch: 6| Step: 7
Training loss: 1.0393339103793373
Validation loss: 2.6607933233852883

Epoch: 6| Step: 8
Training loss: 1.5551106246162398
Validation loss: 2.6570703174770167

Epoch: 6| Step: 9
Training loss: 1.5836734490083086
Validation loss: 2.6808988837743173

Epoch: 6| Step: 10
Training loss: 1.3324465286089993
Validation loss: 2.6240350296868025

Epoch: 6| Step: 11
Training loss: 1.5886035177561446
Validation loss: 2.6181585000460577

Epoch: 6| Step: 12
Training loss: 1.9029395954289559
Validation loss: 2.6642938328870946

Epoch: 6| Step: 13
Training loss: 2.150879959296706
Validation loss: 2.6463935639401166

Epoch: 371| Step: 0
Training loss: 1.3970741573767735
Validation loss: 2.6726184279177843

Epoch: 6| Step: 1
Training loss: 2.0538473405947233
Validation loss: 2.670124886195904

Epoch: 6| Step: 2
Training loss: 1.9554961193088152
Validation loss: 2.6446085720882366

Epoch: 6| Step: 3
Training loss: 0.9230075926297931
Validation loss: 2.7063219426483855

Epoch: 6| Step: 4
Training loss: 1.7738775975986074
Validation loss: 2.74115907053524

Epoch: 6| Step: 5
Training loss: 1.7935172511500215
Validation loss: 2.7868402284738756

Epoch: 6| Step: 6
Training loss: 1.6853408422338025
Validation loss: 2.6995954899299037

Epoch: 6| Step: 7
Training loss: 1.7890268513821783
Validation loss: 2.7038220368675483

Epoch: 6| Step: 8
Training loss: 1.1482736898877497
Validation loss: 2.6716670053885996

Epoch: 6| Step: 9
Training loss: 1.9686394312251698
Validation loss: 2.661825932288379

Epoch: 6| Step: 10
Training loss: 1.7808885709591298
Validation loss: 2.6407057920958805

Epoch: 6| Step: 11
Training loss: 1.84408779605956
Validation loss: 2.6151858594257917

Epoch: 6| Step: 12
Training loss: 1.762930780887867
Validation loss: 2.5915560654798324

Epoch: 6| Step: 13
Training loss: 1.9824648096104995
Validation loss: 2.6077792833520115

Epoch: 372| Step: 0
Training loss: 1.8457431042090418
Validation loss: 2.586874808309689

Epoch: 6| Step: 1
Training loss: 1.6036562747580296
Validation loss: 2.6166950882342066

Epoch: 6| Step: 2
Training loss: 1.5872145148267327
Validation loss: 2.597841582224019

Epoch: 6| Step: 3
Training loss: 1.1084345740254675
Validation loss: 2.6691483235351683

Epoch: 6| Step: 4
Training loss: 1.677486094887603
Validation loss: 2.641631993408169

Epoch: 6| Step: 5
Training loss: 1.731262713774673
Validation loss: 2.7271029456831957

Epoch: 6| Step: 6
Training loss: 2.2806385213629343
Validation loss: 2.6795107724826877

Epoch: 6| Step: 7
Training loss: 1.7036160102487816
Validation loss: 2.7153768843840504

Epoch: 6| Step: 8
Training loss: 1.436619945321069
Validation loss: 2.7188325043652486

Epoch: 6| Step: 9
Training loss: 0.9749399362305363
Validation loss: 2.612551371968233

Epoch: 6| Step: 10
Training loss: 1.744471878428625
Validation loss: 2.657624199633416

Epoch: 6| Step: 11
Training loss: 1.8442485587854016
Validation loss: 2.6267583800858962

Epoch: 6| Step: 12
Training loss: 1.7431838945387959
Validation loss: 2.6867861132261903

Epoch: 6| Step: 13
Training loss: 2.5167013199633024
Validation loss: 2.7012637277442915

Epoch: 373| Step: 0
Training loss: 1.5678210635119598
Validation loss: 2.662831802468322

Epoch: 6| Step: 1
Training loss: 2.548013631535691
Validation loss: 2.677650292669597

Epoch: 6| Step: 2
Training loss: 2.299748498185666
Validation loss: 2.6314754241524456

Epoch: 6| Step: 3
Training loss: 2.1561117819009863
Validation loss: 2.6820389613148015

Epoch: 6| Step: 4
Training loss: 1.48896177257402
Validation loss: 2.7933334574854904

Epoch: 6| Step: 5
Training loss: 2.0276560754122603
Validation loss: 2.88158058923407

Epoch: 6| Step: 6
Training loss: 1.878221859076678
Validation loss: 2.862944218401154

Epoch: 6| Step: 7
Training loss: 1.5982642474208513
Validation loss: 2.801581445343756

Epoch: 6| Step: 8
Training loss: 1.5308548553703776
Validation loss: 2.730847231965661

Epoch: 6| Step: 9
Training loss: 1.3173718632270612
Validation loss: 2.650203989682745

Epoch: 6| Step: 10
Training loss: 1.8132351009441043
Validation loss: 2.6393082324565045

Epoch: 6| Step: 11
Training loss: 1.1978926393614753
Validation loss: 2.649107421647721

Epoch: 6| Step: 12
Training loss: 1.4473895844824187
Validation loss: 2.683314161251913

Epoch: 6| Step: 13
Training loss: 2.0523749852644277
Validation loss: 2.674160743683837

Epoch: 374| Step: 0
Training loss: 1.0029110261393723
Validation loss: 2.6618150943494845

Epoch: 6| Step: 1
Training loss: 2.081201556217595
Validation loss: 2.665541863645041

Epoch: 6| Step: 2
Training loss: 1.684613054258492
Validation loss: 2.636701825876434

Epoch: 6| Step: 3
Training loss: 2.128423737607604
Validation loss: 2.620849226543065

Epoch: 6| Step: 4
Training loss: 1.1806063578776151
Validation loss: 2.6076154582233344

Epoch: 6| Step: 5
Training loss: 2.0782640453659256
Validation loss: 2.7210968090576477

Epoch: 6| Step: 6
Training loss: 1.8466814949918442
Validation loss: 2.7834865135787568

Epoch: 6| Step: 7
Training loss: 2.6951407999828465
Validation loss: 2.8053141312751846

Epoch: 6| Step: 8
Training loss: 1.744836410024677
Validation loss: 2.8005143397088466

Epoch: 6| Step: 9
Training loss: 1.6361571010623306
Validation loss: 2.7454253496117746

Epoch: 6| Step: 10
Training loss: 2.1742948594857894
Validation loss: 2.6548748121662804

Epoch: 6| Step: 11
Training loss: 1.6765342745578122
Validation loss: 2.617077019480443

Epoch: 6| Step: 12
Training loss: 1.357572742009581
Validation loss: 2.6853525320305636

Epoch: 6| Step: 13
Training loss: 1.3092117444506661
Validation loss: 2.633667079885753

Epoch: 375| Step: 0
Training loss: 1.3346855141766278
Validation loss: 2.6147843596445215

Epoch: 6| Step: 1
Training loss: 1.5537259756303983
Validation loss: 2.674725504781709

Epoch: 6| Step: 2
Training loss: 1.6124892241835014
Validation loss: 2.7127081725228868

Epoch: 6| Step: 3
Training loss: 1.1772817877631367
Validation loss: 2.656613433508775

Epoch: 6| Step: 4
Training loss: 1.9271192873788263
Validation loss: 2.617247137652299

Epoch: 6| Step: 5
Training loss: 3.0584369097917907
Validation loss: 2.6391672026675126

Epoch: 6| Step: 6
Training loss: 1.647793974169096
Validation loss: 2.654862808327666

Epoch: 6| Step: 7
Training loss: 1.3501912034583476
Validation loss: 2.6575071015476905

Epoch: 6| Step: 8
Training loss: 1.7137081757164299
Validation loss: 2.641095444947033

Epoch: 6| Step: 9
Training loss: 1.9018873728670278
Validation loss: 2.6045742453469116

Epoch: 6| Step: 10
Training loss: 1.6393256718918177
Validation loss: 2.58993003858734

Epoch: 6| Step: 11
Training loss: 1.731924508143282
Validation loss: 2.586473545783038

Epoch: 6| Step: 12
Training loss: 1.6318605559231036
Validation loss: 2.5255997943131745

Epoch: 6| Step: 13
Training loss: 1.586794842276474
Validation loss: 2.540496499478419

Epoch: 376| Step: 0
Training loss: 1.7841874379791978
Validation loss: 2.524807970216953

Epoch: 6| Step: 1
Training loss: 2.2956727702724025
Validation loss: 2.543000400266167

Epoch: 6| Step: 2
Training loss: 1.739649818962065
Validation loss: 2.559231278293165

Epoch: 6| Step: 3
Training loss: 1.7847369012422767
Validation loss: 2.5667713356556834

Epoch: 6| Step: 4
Training loss: 1.3323049403949325
Validation loss: 2.6045627496231782

Epoch: 6| Step: 5
Training loss: 1.4688178513458123
Validation loss: 2.556147066078701

Epoch: 6| Step: 6
Training loss: 1.5437428524454189
Validation loss: 2.6112854563447128

Epoch: 6| Step: 7
Training loss: 2.037556292920534
Validation loss: 2.6615044178615195

Epoch: 6| Step: 8
Training loss: 2.0720322861383713
Validation loss: 2.679125431231916

Epoch: 6| Step: 9
Training loss: 1.8891861539872439
Validation loss: 2.687488748098077

Epoch: 6| Step: 10
Training loss: 1.711419651602789
Validation loss: 2.6739774615370537

Epoch: 6| Step: 11
Training loss: 1.9275431591303107
Validation loss: 2.683044273689846

Epoch: 6| Step: 12
Training loss: 1.1395134408684529
Validation loss: 2.6829309288135965

Epoch: 6| Step: 13
Training loss: 1.466390622055193
Validation loss: 2.7051356487378047

Epoch: 377| Step: 0
Training loss: 2.078041591261105
Validation loss: 2.674941877523941

Epoch: 6| Step: 1
Training loss: 1.5532684751130532
Validation loss: 2.718901516722611

Epoch: 6| Step: 2
Training loss: 1.4036714012445413
Validation loss: 2.673387066149708

Epoch: 6| Step: 3
Training loss: 1.290761948678899
Validation loss: 2.698553155078306

Epoch: 6| Step: 4
Training loss: 1.6606309638384689
Validation loss: 2.66304232248407

Epoch: 6| Step: 5
Training loss: 2.070364091338315
Validation loss: 2.715931246001976

Epoch: 6| Step: 6
Training loss: 1.4841979874924571
Validation loss: 2.760287462965469

Epoch: 6| Step: 7
Training loss: 1.25048828125
Validation loss: 2.7517648871221194

Epoch: 6| Step: 8
Training loss: 1.2834887600366833
Validation loss: 2.6787386179017783

Epoch: 6| Step: 9
Training loss: 2.0329960287930664
Validation loss: 2.6681158975633728

Epoch: 6| Step: 10
Training loss: 1.7819800637539627
Validation loss: 2.670102853508438

Epoch: 6| Step: 11
Training loss: 1.9151974796831508
Validation loss: 2.726331990726226

Epoch: 6| Step: 12
Training loss: 1.2295823552743832
Validation loss: 2.6348977363329715

Epoch: 6| Step: 13
Training loss: 1.9030601202267652
Validation loss: 2.6304914089247005

Epoch: 378| Step: 0
Training loss: 1.4966600904907885
Validation loss: 2.6564420294069993

Epoch: 6| Step: 1
Training loss: 1.93378720327245
Validation loss: 2.6322047950007055

Epoch: 6| Step: 2
Training loss: 1.7750599703261845
Validation loss: 2.6997748104424577

Epoch: 6| Step: 3
Training loss: 1.8898858761517663
Validation loss: 2.656162454994994

Epoch: 6| Step: 4
Training loss: 1.31352947369613
Validation loss: 2.6946335384264706

Epoch: 6| Step: 5
Training loss: 2.0398778929349466
Validation loss: 2.714965641935391

Epoch: 6| Step: 6
Training loss: 1.8964971351390696
Validation loss: 2.7244652202941793

Epoch: 6| Step: 7
Training loss: 1.5381753756238385
Validation loss: 2.6452450636447002

Epoch: 6| Step: 8
Training loss: 1.4335117576497476
Validation loss: 2.654372535358911

Epoch: 6| Step: 9
Training loss: 1.4105426121670823
Validation loss: 2.574645636535696

Epoch: 6| Step: 10
Training loss: 1.9825636639180184
Validation loss: 2.593948050295188

Epoch: 6| Step: 11
Training loss: 1.2614219481777715
Validation loss: 2.5716445393165595

Epoch: 6| Step: 12
Training loss: 2.015003907079198
Validation loss: 2.595073178606412

Epoch: 6| Step: 13
Training loss: 2.367081139318462
Validation loss: 2.660253940306546

Epoch: 379| Step: 0
Training loss: 2.22926749836222
Validation loss: 2.62188478330864

Epoch: 6| Step: 1
Training loss: 2.230183544730899
Validation loss: 2.6079071698186267

Epoch: 6| Step: 2
Training loss: 2.050985271659504
Validation loss: 2.616138699796686

Epoch: 6| Step: 3
Training loss: 1.7086326367942029
Validation loss: 2.5985289826138738

Epoch: 6| Step: 4
Training loss: 1.1750881648974185
Validation loss: 2.599600952654502

Epoch: 6| Step: 5
Training loss: 1.3919801859514236
Validation loss: 2.702853282877033

Epoch: 6| Step: 6
Training loss: 1.4746434087804727
Validation loss: 2.703021097115714

Epoch: 6| Step: 7
Training loss: 1.3497544471510605
Validation loss: 2.7740093805704107

Epoch: 6| Step: 8
Training loss: 1.9038991972581722
Validation loss: 2.7134603145263654

Epoch: 6| Step: 9
Training loss: 1.84683854636735
Validation loss: 2.6961588318629124

Epoch: 6| Step: 10
Training loss: 1.1725893513647048
Validation loss: 2.6758316295178397

Epoch: 6| Step: 11
Training loss: 1.7862553458003676
Validation loss: 2.6477513282433254

Epoch: 6| Step: 12
Training loss: 1.5507229042127495
Validation loss: 2.616657624765636

Epoch: 6| Step: 13
Training loss: 2.6610786978442795
Validation loss: 2.6210440239166615

Epoch: 380| Step: 0
Training loss: 1.716521048928202
Validation loss: 2.6156861966903207

Epoch: 6| Step: 1
Training loss: 1.8420624202751164
Validation loss: 2.603175933571626

Epoch: 6| Step: 2
Training loss: 1.4984914823639424
Validation loss: 2.6099625495133574

Epoch: 6| Step: 3
Training loss: 1.638018908800249
Validation loss: 2.6374228434553983

Epoch: 6| Step: 4
Training loss: 1.4927883037149816
Validation loss: 2.6755222315849903

Epoch: 6| Step: 5
Training loss: 1.3930287534891321
Validation loss: 2.6043075421694035

Epoch: 6| Step: 6
Training loss: 1.315540062706451
Validation loss: 2.6352104186721994

Epoch: 6| Step: 7
Training loss: 2.046541725573994
Validation loss: 2.697344794229071

Epoch: 6| Step: 8
Training loss: 1.605041298498345
Validation loss: 2.70048873622339

Epoch: 6| Step: 9
Training loss: 1.4980732145816333
Validation loss: 2.6574547522572414

Epoch: 6| Step: 10
Training loss: 1.3647794606833372
Validation loss: 2.7328973901271123

Epoch: 6| Step: 11
Training loss: 2.3494017549712964
Validation loss: 2.7306415901544505

Epoch: 6| Step: 12
Training loss: 1.4985112908962286
Validation loss: 2.749950885334114

Epoch: 6| Step: 13
Training loss: 1.6709122782612758
Validation loss: 2.69589922872092

Epoch: 381| Step: 0
Training loss: 1.5073731726187651
Validation loss: 2.717909116530313

Epoch: 6| Step: 1
Training loss: 0.8597737514279915
Validation loss: 2.5957510785643096

Epoch: 6| Step: 2
Training loss: 0.8941612644571567
Validation loss: 2.622924188285468

Epoch: 6| Step: 3
Training loss: 1.4743747549796618
Validation loss: 2.5933743093713417

Epoch: 6| Step: 4
Training loss: 1.5823401632237233
Validation loss: 2.63651051393676

Epoch: 6| Step: 5
Training loss: 2.5576179332520868
Validation loss: 2.586528714334072

Epoch: 6| Step: 6
Training loss: 1.5574744467070354
Validation loss: 2.5714813481192866

Epoch: 6| Step: 7
Training loss: 1.9489934940180615
Validation loss: 2.608725202290551

Epoch: 6| Step: 8
Training loss: 1.5574527091597101
Validation loss: 2.622789239148887

Epoch: 6| Step: 9
Training loss: 1.735282591746305
Validation loss: 2.6156292503987806

Epoch: 6| Step: 10
Training loss: 1.7800906239703413
Validation loss: 2.6596477468791138

Epoch: 6| Step: 11
Training loss: 1.7230639332108746
Validation loss: 2.676424952393106

Epoch: 6| Step: 12
Training loss: 1.1074038980091254
Validation loss: 2.5870006868867534

Epoch: 6| Step: 13
Training loss: 1.6611767313969246
Validation loss: 2.672277498323416

Epoch: 382| Step: 0
Training loss: 1.7822317797440759
Validation loss: 2.595980853016507

Epoch: 6| Step: 1
Training loss: 1.4736773039899767
Validation loss: 2.62057637065296

Epoch: 6| Step: 2
Training loss: 1.8417411464055309
Validation loss: 2.623163458798464

Epoch: 6| Step: 3
Training loss: 2.0221835341729313
Validation loss: 2.6898502748269717

Epoch: 6| Step: 4
Training loss: 1.6785005145761056
Validation loss: 2.593224560320496

Epoch: 6| Step: 5
Training loss: 1.3249879476610886
Validation loss: 2.6842970946689984

Epoch: 6| Step: 6
Training loss: 1.5290186447443839
Validation loss: 2.708072317212426

Epoch: 6| Step: 7
Training loss: 1.2092588048507522
Validation loss: 2.7378801676987288

Epoch: 6| Step: 8
Training loss: 1.8333851705794288
Validation loss: 2.796066849380106

Epoch: 6| Step: 9
Training loss: 2.0521001153508207
Validation loss: 2.7699273475869424

Epoch: 6| Step: 10
Training loss: 1.4804274419894692
Validation loss: 2.7409301947456943

Epoch: 6| Step: 11
Training loss: 1.7587647973843206
Validation loss: 2.7571969790762143

Epoch: 6| Step: 12
Training loss: 2.1917777605027218
Validation loss: 2.689035228507469

Epoch: 6| Step: 13
Training loss: 1.441848645641163
Validation loss: 2.622021036851255

Epoch: 383| Step: 0
Training loss: 1.8151572907024434
Validation loss: 2.6176381572440506

Epoch: 6| Step: 1
Training loss: 1.8487740939764576
Validation loss: 2.5874939351770947

Epoch: 6| Step: 2
Training loss: 1.1891889106436175
Validation loss: 2.579967957502201

Epoch: 6| Step: 3
Training loss: 1.461220698523776
Validation loss: 2.60965567352764

Epoch: 6| Step: 4
Training loss: 1.9443784255975793
Validation loss: 2.588490527215201

Epoch: 6| Step: 5
Training loss: 1.6488461824000842
Validation loss: 2.6211743557962888

Epoch: 6| Step: 6
Training loss: 1.2958560295611452
Validation loss: 2.682118876302056

Epoch: 6| Step: 7
Training loss: 1.6584046941128594
Validation loss: 2.7270608572231603

Epoch: 6| Step: 8
Training loss: 2.1054381755809994
Validation loss: 2.779502533992649

Epoch: 6| Step: 9
Training loss: 1.6777219405507273
Validation loss: 2.7921620802388443

Epoch: 6| Step: 10
Training loss: 1.8652665859456947
Validation loss: 2.7191991909964512

Epoch: 6| Step: 11
Training loss: 1.7867342529158057
Validation loss: 2.675004030385056

Epoch: 6| Step: 12
Training loss: 1.7002056894966209
Validation loss: 2.672214256000695

Epoch: 6| Step: 13
Training loss: 1.4750256487669167
Validation loss: 2.6603996624822637

Epoch: 384| Step: 0
Training loss: 1.7843710343138124
Validation loss: 2.6674050759155

Epoch: 6| Step: 1
Training loss: 2.1202486437611157
Validation loss: 2.6459402878737857

Epoch: 6| Step: 2
Training loss: 1.48820731712791
Validation loss: 2.6573368317401913

Epoch: 6| Step: 3
Training loss: 1.4974018483801288
Validation loss: 2.597084529363768

Epoch: 6| Step: 4
Training loss: 1.6783951156568777
Validation loss: 2.6549737893802536

Epoch: 6| Step: 5
Training loss: 1.8449264264621035
Validation loss: 2.6181040662953237

Epoch: 6| Step: 6
Training loss: 2.2354417935180133
Validation loss: 2.6317731879308273

Epoch: 6| Step: 7
Training loss: 1.2541086859412383
Validation loss: 2.6816765434821375

Epoch: 6| Step: 8
Training loss: 1.5574765898290737
Validation loss: 2.757911687549554

Epoch: 6| Step: 9
Training loss: 1.6591575580668143
Validation loss: 2.683779114563949

Epoch: 6| Step: 10
Training loss: 1.3826026110656044
Validation loss: 2.7152743869336464

Epoch: 6| Step: 11
Training loss: 0.9401600293639368
Validation loss: 2.713263225852529

Epoch: 6| Step: 12
Training loss: 1.6273862484324102
Validation loss: 2.7538626304400493

Epoch: 6| Step: 13
Training loss: 1.3653995266675651
Validation loss: 2.739281254541702

Epoch: 385| Step: 0
Training loss: 1.5159675761557587
Validation loss: 2.676346916309964

Epoch: 6| Step: 1
Training loss: 1.8140327286885356
Validation loss: 2.6672704331045627

Epoch: 6| Step: 2
Training loss: 1.521411507150704
Validation loss: 2.7639433926224792

Epoch: 6| Step: 3
Training loss: 1.5673693504824922
Validation loss: 2.739490758881332

Epoch: 6| Step: 4
Training loss: 2.0094248906374386
Validation loss: 2.792303686387668

Epoch: 6| Step: 5
Training loss: 2.1410679045754653
Validation loss: 2.7200349570113036

Epoch: 6| Step: 6
Training loss: 1.310694087894861
Validation loss: 2.7042065994143423

Epoch: 6| Step: 7
Training loss: 1.7666485275680888
Validation loss: 2.6822272777544844

Epoch: 6| Step: 8
Training loss: 1.1966499874064782
Validation loss: 2.6252287204946687

Epoch: 6| Step: 9
Training loss: 1.78888185080466
Validation loss: 2.579141281652141

Epoch: 6| Step: 10
Training loss: 1.8919779452798637
Validation loss: 2.5767248570984735

Epoch: 6| Step: 11
Training loss: 2.031711232565233
Validation loss: 2.572393237988824

Epoch: 6| Step: 12
Training loss: 1.8182502164763206
Validation loss: 2.5581285048839106

Epoch: 6| Step: 13
Training loss: 1.2731713326908771
Validation loss: 2.587454490138543

Epoch: 386| Step: 0
Training loss: 1.1731633034876625
Validation loss: 2.5882033364278803

Epoch: 6| Step: 1
Training loss: 1.9478170060011253
Validation loss: 2.58607329658381

Epoch: 6| Step: 2
Training loss: 1.494612635437
Validation loss: 2.633248946692809

Epoch: 6| Step: 3
Training loss: 1.1964142153921777
Validation loss: 2.596001471334392

Epoch: 6| Step: 4
Training loss: 1.3519012379492
Validation loss: 2.6342049980894484

Epoch: 6| Step: 5
Training loss: 1.6322816414718944
Validation loss: 2.6189229345160974

Epoch: 6| Step: 6
Training loss: 1.284560416173203
Validation loss: 2.6426980272652734

Epoch: 6| Step: 7
Training loss: 1.6171693662649533
Validation loss: 2.650275523779362

Epoch: 6| Step: 8
Training loss: 1.9662255344699737
Validation loss: 2.6475927605496903

Epoch: 6| Step: 9
Training loss: 1.930213454998514
Validation loss: 2.654700302144047

Epoch: 6| Step: 10
Training loss: 1.9661016665586317
Validation loss: 2.711178654361771

Epoch: 6| Step: 11
Training loss: 1.6003239005780907
Validation loss: 2.7385968268173992

Epoch: 6| Step: 12
Training loss: 2.263315957816859
Validation loss: 2.7894981321884824

Epoch: 6| Step: 13
Training loss: 1.4664883346223714
Validation loss: 2.6492654112150147

Epoch: 387| Step: 0
Training loss: 1.6721822866245557
Validation loss: 2.6854736022201053

Epoch: 6| Step: 1
Training loss: 1.3933542878721397
Validation loss: 2.6840620303274796

Epoch: 6| Step: 2
Training loss: 1.0834358545845946
Validation loss: 2.6753127975829085

Epoch: 6| Step: 3
Training loss: 2.415521964457953
Validation loss: 2.6603712684942025

Epoch: 6| Step: 4
Training loss: 2.164168923305451
Validation loss: 2.709996421971135

Epoch: 6| Step: 5
Training loss: 1.401399852624523
Validation loss: 2.65312393841462

Epoch: 6| Step: 6
Training loss: 1.225458073120221
Validation loss: 2.6321622836086287

Epoch: 6| Step: 7
Training loss: 2.415427109285183
Validation loss: 2.614486378446341

Epoch: 6| Step: 8
Training loss: 1.1378031274356597
Validation loss: 2.665668529231111

Epoch: 6| Step: 9
Training loss: 1.2716108924280407
Validation loss: 2.6771228406393086

Epoch: 6| Step: 10
Training loss: 1.9786493796564226
Validation loss: 2.71819931240953

Epoch: 6| Step: 11
Training loss: 1.9067847330489294
Validation loss: 2.7123679895111015

Epoch: 6| Step: 12
Training loss: 1.5587825039409076
Validation loss: 2.6517213101354344

Epoch: 6| Step: 13
Training loss: 1.9699668151461587
Validation loss: 2.63528460647958

Epoch: 388| Step: 0
Training loss: 1.6601385138069125
Validation loss: 2.6080820150434096

Epoch: 6| Step: 1
Training loss: 1.5133371290643847
Validation loss: 2.5757180586161765

Epoch: 6| Step: 2
Training loss: 1.7948546620134636
Validation loss: 2.60375438224044

Epoch: 6| Step: 3
Training loss: 1.417985059576055
Validation loss: 2.6144774720746162

Epoch: 6| Step: 4
Training loss: 1.1956361320045175
Validation loss: 2.640511858320152

Epoch: 6| Step: 5
Training loss: 1.9605369614743633
Validation loss: 2.642136993015703

Epoch: 6| Step: 6
Training loss: 1.7072283109492963
Validation loss: 2.621689722534123

Epoch: 6| Step: 7
Training loss: 1.4042348198052355
Validation loss: 2.619312437198262

Epoch: 6| Step: 8
Training loss: 1.4991012900945875
Validation loss: 2.6425473741695584

Epoch: 6| Step: 9
Training loss: 2.241102853466769
Validation loss: 2.692613438914682

Epoch: 6| Step: 10
Training loss: 1.8674571588752378
Validation loss: 2.739688469980993

Epoch: 6| Step: 11
Training loss: 1.5655452806959702
Validation loss: 2.6968918895229406

Epoch: 6| Step: 12
Training loss: 1.3468753044676824
Validation loss: 2.7661976625479103

Epoch: 6| Step: 13
Training loss: 1.7624256551226762
Validation loss: 2.685411262556093

Epoch: 389| Step: 0
Training loss: 1.364419107043106
Validation loss: 2.6969422209352865

Epoch: 6| Step: 1
Training loss: 2.372377051493013
Validation loss: 2.6574010262490853

Epoch: 6| Step: 2
Training loss: 2.1294538161210905
Validation loss: 2.6310850488904833

Epoch: 6| Step: 3
Training loss: 1.2822846677678499
Validation loss: 2.7450857686538557

Epoch: 6| Step: 4
Training loss: 2.075278720750258
Validation loss: 2.702263358498252

Epoch: 6| Step: 5
Training loss: 1.5841469263849866
Validation loss: 2.736606058277421

Epoch: 6| Step: 6
Training loss: 2.0329854740612734
Validation loss: 2.7203833690383057

Epoch: 6| Step: 7
Training loss: 1.9367594995862731
Validation loss: 2.6836237787734953

Epoch: 6| Step: 8
Training loss: 1.0788053494395409
Validation loss: 2.7594479906531135

Epoch: 6| Step: 9
Training loss: 1.4456727274904806
Validation loss: 2.751399825466637

Epoch: 6| Step: 10
Training loss: 1.714254638696753
Validation loss: 2.838621860502918

Epoch: 6| Step: 11
Training loss: 1.9303166525995104
Validation loss: 2.755693336493729

Epoch: 6| Step: 12
Training loss: 1.7753138761644311
Validation loss: 2.7092482170879864

Epoch: 6| Step: 13
Training loss: 1.4622281335352405
Validation loss: 2.6194271316868627

Epoch: 390| Step: 0
Training loss: 1.4156714290727115
Validation loss: 2.627590967050044

Epoch: 6| Step: 1
Training loss: 1.1358156057491755
Validation loss: 2.6139445316064545

Epoch: 6| Step: 2
Training loss: 1.4425147944704884
Validation loss: 2.6470606102656897

Epoch: 6| Step: 3
Training loss: 1.479602570397505
Validation loss: 2.6329029795930867

Epoch: 6| Step: 4
Training loss: 2.0526858250532425
Validation loss: 2.661292977369034

Epoch: 6| Step: 5
Training loss: 1.6230662651143202
Validation loss: 2.619234755206834

Epoch: 6| Step: 6
Training loss: 1.7294941863915962
Validation loss: 2.668217689737188

Epoch: 6| Step: 7
Training loss: 0.8775981748170747
Validation loss: 2.611003938351265

Epoch: 6| Step: 8
Training loss: 1.4958982813060941
Validation loss: 2.657726326363446

Epoch: 6| Step: 9
Training loss: 1.7103291305215769
Validation loss: 2.6284387332446375

Epoch: 6| Step: 10
Training loss: 1.8421602669370059
Validation loss: 2.6803053652390543

Epoch: 6| Step: 11
Training loss: 1.5831654944890234
Validation loss: 2.7782925086482235

Epoch: 6| Step: 12
Training loss: 2.0314830939725272
Validation loss: 2.794094827920977

Epoch: 6| Step: 13
Training loss: 1.646979170514096
Validation loss: 2.7575984075653257

Epoch: 391| Step: 0
Training loss: 1.4842529246677487
Validation loss: 2.6935773046237017

Epoch: 6| Step: 1
Training loss: 1.5762341946710188
Validation loss: 2.685738659108459

Epoch: 6| Step: 2
Training loss: 1.3161989043082392
Validation loss: 2.6272452909283595

Epoch: 6| Step: 3
Training loss: 1.3510526014996762
Validation loss: 2.640422971321739

Epoch: 6| Step: 4
Training loss: 1.3059724430722912
Validation loss: 2.612799553983751

Epoch: 6| Step: 5
Training loss: 1.9986914884151172
Validation loss: 2.6225257747899957

Epoch: 6| Step: 6
Training loss: 1.5714400309603103
Validation loss: 2.649893061561464

Epoch: 6| Step: 7
Training loss: 1.6978029864427515
Validation loss: 2.6707014663287185

Epoch: 6| Step: 8
Training loss: 1.791503972791461
Validation loss: 2.6555860549801564

Epoch: 6| Step: 9
Training loss: 1.3353717342123597
Validation loss: 2.611120755491189

Epoch: 6| Step: 10
Training loss: 1.675409876080672
Validation loss: 2.6510433704143415

Epoch: 6| Step: 11
Training loss: 1.2498111582208646
Validation loss: 2.6156329344367424

Epoch: 6| Step: 12
Training loss: 1.4935089172158373
Validation loss: 2.6613051836376345

Epoch: 6| Step: 13
Training loss: 2.275369459061964
Validation loss: 2.6732829884793192

Epoch: 392| Step: 0
Training loss: 2.405822815069927
Validation loss: 2.7077279270096484

Epoch: 6| Step: 1
Training loss: 1.6595521074454578
Validation loss: 2.6940406784096003

Epoch: 6| Step: 2
Training loss: 1.4589770213481847
Validation loss: 2.665234648135963

Epoch: 6| Step: 3
Training loss: 1.8842844294454102
Validation loss: 2.6001871882203593

Epoch: 6| Step: 4
Training loss: 1.5132734795776075
Validation loss: 2.6258900662314995

Epoch: 6| Step: 5
Training loss: 1.8575157037535812
Validation loss: 2.6493365956881356

Epoch: 6| Step: 6
Training loss: 1.2739167511028888
Validation loss: 2.6989751283532124

Epoch: 6| Step: 7
Training loss: 1.675807997127745
Validation loss: 2.7711738912535218

Epoch: 6| Step: 8
Training loss: 1.3124614437434614
Validation loss: 2.738236322184031

Epoch: 6| Step: 9
Training loss: 1.501742939820196
Validation loss: 2.6996649793299397

Epoch: 6| Step: 10
Training loss: 1.6768599019773163
Validation loss: 2.7806004326465974

Epoch: 6| Step: 11
Training loss: 1.4593642632622477
Validation loss: 2.758780290707847

Epoch: 6| Step: 12
Training loss: 1.0325771808179804
Validation loss: 2.6662881155340368

Epoch: 6| Step: 13
Training loss: 1.7345271688155048
Validation loss: 2.664529381017653

Epoch: 393| Step: 0
Training loss: 2.0868824165169038
Validation loss: 2.7375707643324554

Epoch: 6| Step: 1
Training loss: 1.314118522692668
Validation loss: 2.6477428714393425

Epoch: 6| Step: 2
Training loss: 1.5862112325826399
Validation loss: 2.620963232180089

Epoch: 6| Step: 3
Training loss: 1.526096937547864
Validation loss: 2.6207230708989924

Epoch: 6| Step: 4
Training loss: 1.5992829265678496
Validation loss: 2.6878271125615343

Epoch: 6| Step: 5
Training loss: 1.3113438191410793
Validation loss: 2.6666339832528263

Epoch: 6| Step: 6
Training loss: 1.5517535104565916
Validation loss: 2.707388842782103

Epoch: 6| Step: 7
Training loss: 1.548702586066318
Validation loss: 2.6700216487240227

Epoch: 6| Step: 8
Training loss: 1.3602850487653877
Validation loss: 2.764985896115378

Epoch: 6| Step: 9
Training loss: 1.357754717300809
Validation loss: 2.745236331213782

Epoch: 6| Step: 10
Training loss: 1.956431161700409
Validation loss: 2.763488073269082

Epoch: 6| Step: 11
Training loss: 1.4717585815262442
Validation loss: 2.7698163817011863

Epoch: 6| Step: 12
Training loss: 1.4894934495959222
Validation loss: 2.713616768547571

Epoch: 6| Step: 13
Training loss: 1.5302735933012843
Validation loss: 2.655849897881392

Epoch: 394| Step: 0
Training loss: 1.5613916662369782
Validation loss: 2.7212695435625465

Epoch: 6| Step: 1
Training loss: 0.8815946703060864
Validation loss: 2.756429741636453

Epoch: 6| Step: 2
Training loss: 1.9927255539682605
Validation loss: 2.7195824119769307

Epoch: 6| Step: 3
Training loss: 1.495608896120175
Validation loss: 2.7508816461751358

Epoch: 6| Step: 4
Training loss: 2.4372736507860413
Validation loss: 2.7244352187050085

Epoch: 6| Step: 5
Training loss: 1.4490632747527143
Validation loss: 2.7383453463219096

Epoch: 6| Step: 6
Training loss: 1.554229899015828
Validation loss: 2.7262556601116805

Epoch: 6| Step: 7
Training loss: 1.7030375746940236
Validation loss: 2.7405230768173214

Epoch: 6| Step: 8
Training loss: 1.314430452012388
Validation loss: 2.708401581320026

Epoch: 6| Step: 9
Training loss: 1.4426956818871708
Validation loss: 2.75415241412824

Epoch: 6| Step: 10
Training loss: 1.1942049767222638
Validation loss: 2.716799595472892

Epoch: 6| Step: 11
Training loss: 1.0216018871744001
Validation loss: 2.6822555218579103

Epoch: 6| Step: 12
Training loss: 1.5516982742324557
Validation loss: 2.629957120374193

Epoch: 6| Step: 13
Training loss: 1.7118621139347772
Validation loss: 2.6227964810526445

Epoch: 395| Step: 0
Training loss: 1.2525910702640006
Validation loss: 2.598942473114077

Epoch: 6| Step: 1
Training loss: 1.2526817165592021
Validation loss: 2.623673792776263

Epoch: 6| Step: 2
Training loss: 1.9693925807970802
Validation loss: 2.6566522480690256

Epoch: 6| Step: 3
Training loss: 1.3019459410342464
Validation loss: 2.64852996634748

Epoch: 6| Step: 4
Training loss: 1.6500782687957125
Validation loss: 2.633468289679486

Epoch: 6| Step: 5
Training loss: 1.4264785524635228
Validation loss: 2.6382445566571917

Epoch: 6| Step: 6
Training loss: 1.6318534699462106
Validation loss: 2.6411367970014075

Epoch: 6| Step: 7
Training loss: 1.7520962829957991
Validation loss: 2.655494612451594

Epoch: 6| Step: 8
Training loss: 1.2777610353856486
Validation loss: 2.6885883286358423

Epoch: 6| Step: 9
Training loss: 1.9592331246295087
Validation loss: 2.7403047334643107

Epoch: 6| Step: 10
Training loss: 1.1268186703872223
Validation loss: 2.7334026824093214

Epoch: 6| Step: 11
Training loss: 1.7907409790186763
Validation loss: 2.684176112050497

Epoch: 6| Step: 12
Training loss: 1.326049799068872
Validation loss: 2.655685260053398

Epoch: 6| Step: 13
Training loss: 1.5754098480058214
Validation loss: 2.637603867400503

Epoch: 396| Step: 0
Training loss: 1.576491917825072
Validation loss: 2.7095451480482717

Epoch: 6| Step: 1
Training loss: 1.2656383749172717
Validation loss: 2.6691302279524756

Epoch: 6| Step: 2
Training loss: 1.1966679187243898
Validation loss: 2.7265960122920907

Epoch: 6| Step: 3
Training loss: 1.794726870697955
Validation loss: 2.6518622117157875

Epoch: 6| Step: 4
Training loss: 1.565239907300867
Validation loss: 2.657183150395143

Epoch: 6| Step: 5
Training loss: 1.25285490174069
Validation loss: 2.648383020911567

Epoch: 6| Step: 6
Training loss: 1.4713920205797326
Validation loss: 2.672808612315333

Epoch: 6| Step: 7
Training loss: 1.6294835666180172
Validation loss: 2.64994578515982

Epoch: 6| Step: 8
Training loss: 1.3957454407002716
Validation loss: 2.690281323301646

Epoch: 6| Step: 9
Training loss: 1.8471264714766118
Validation loss: 2.7490846960222464

Epoch: 6| Step: 10
Training loss: 1.8439770574900884
Validation loss: 2.767820345433302

Epoch: 6| Step: 11
Training loss: 1.4368030683076887
Validation loss: 2.6940841603253705

Epoch: 6| Step: 12
Training loss: 2.0153319862950947
Validation loss: 2.686891035830862

Epoch: 6| Step: 13
Training loss: 1.4496676425844301
Validation loss: 2.6654870185752997

Epoch: 397| Step: 0
Training loss: 1.2239773471518753
Validation loss: 2.695544703704502

Epoch: 6| Step: 1
Training loss: 1.1829679238363497
Validation loss: 2.651898151434202

Epoch: 6| Step: 2
Training loss: 1.2165907291769635
Validation loss: 2.6934164998776464

Epoch: 6| Step: 3
Training loss: 1.4313789742674208
Validation loss: 2.6613401522342013

Epoch: 6| Step: 4
Training loss: 1.759457102836671
Validation loss: 2.5946411761963937

Epoch: 6| Step: 5
Training loss: 1.9494836661629742
Validation loss: 2.551405747958473

Epoch: 6| Step: 6
Training loss: 1.1702711192252313
Validation loss: 2.6616758691879046

Epoch: 6| Step: 7
Training loss: 2.4768065323319655
Validation loss: 2.637417381884922

Epoch: 6| Step: 8
Training loss: 1.429156512269776
Validation loss: 2.6501695188847614

Epoch: 6| Step: 9
Training loss: 1.3251243353033184
Validation loss: 2.6269469382817094

Epoch: 6| Step: 10
Training loss: 1.484621047658751
Validation loss: 2.679830556596855

Epoch: 6| Step: 11
Training loss: 1.512747953913775
Validation loss: 2.655986630715863

Epoch: 6| Step: 12
Training loss: 1.5956331235362806
Validation loss: 2.674329348004601

Epoch: 6| Step: 13
Training loss: 1.5775106008327633
Validation loss: 2.6879689007163496

Epoch: 398| Step: 0
Training loss: 1.0884171860382132
Validation loss: 2.676223874202888

Epoch: 6| Step: 1
Training loss: 1.2367060416671756
Validation loss: 2.6670013207812686

Epoch: 6| Step: 2
Training loss: 1.346082215970971
Validation loss: 2.642160574852723

Epoch: 6| Step: 3
Training loss: 1.7202187937924773
Validation loss: 2.67344476641989

Epoch: 6| Step: 4
Training loss: 1.526385228495229
Validation loss: 2.6453774777893067

Epoch: 6| Step: 5
Training loss: 1.4707773704076434
Validation loss: 2.6790049492739376

Epoch: 6| Step: 6
Training loss: 1.4641100050344718
Validation loss: 2.642640121796583

Epoch: 6| Step: 7
Training loss: 1.3659994140221607
Validation loss: 2.699539673382463

Epoch: 6| Step: 8
Training loss: 1.4775024328841109
Validation loss: 2.662713702226551

Epoch: 6| Step: 9
Training loss: 1.4038898583815445
Validation loss: 2.6799182848073237

Epoch: 6| Step: 10
Training loss: 1.026508702649566
Validation loss: 2.6711284345480117

Epoch: 6| Step: 11
Training loss: 1.5461656890062292
Validation loss: 2.6225966698957746

Epoch: 6| Step: 12
Training loss: 1.8585718167242697
Validation loss: 2.602161907376975

Epoch: 6| Step: 13
Training loss: 2.36103691533016
Validation loss: 2.6551659559836738

Epoch: 399| Step: 0
Training loss: 1.1316235847493792
Validation loss: 2.6159855905849545

Epoch: 6| Step: 1
Training loss: 1.1063020079720625
Validation loss: 2.6273563647489624

Epoch: 6| Step: 2
Training loss: 1.7775913611002123
Validation loss: 2.618377415046993

Epoch: 6| Step: 3
Training loss: 1.2894199684870158
Validation loss: 2.6476167890696547

Epoch: 6| Step: 4
Training loss: 1.4577289782247929
Validation loss: 2.684080151080803

Epoch: 6| Step: 5
Training loss: 1.1202353670389997
Validation loss: 2.7306282313409165

Epoch: 6| Step: 6
Training loss: 1.6944912094514037
Validation loss: 2.6819584068498132

Epoch: 6| Step: 7
Training loss: 1.0685705781653498
Validation loss: 2.7257028734815196

Epoch: 6| Step: 8
Training loss: 1.3607397135020391
Validation loss: 2.759845463416146

Epoch: 6| Step: 9
Training loss: 2.3971741172626824
Validation loss: 2.7356779064314614

Epoch: 6| Step: 10
Training loss: 2.1319548171374727
Validation loss: 2.6966553075132285

Epoch: 6| Step: 11
Training loss: 1.2921081629317903
Validation loss: 2.7021108352881154

Epoch: 6| Step: 12
Training loss: 1.799254194035584
Validation loss: 2.7238531341564394

Epoch: 6| Step: 13
Training loss: 1.4739908095737109
Validation loss: 2.7306697918795173

Epoch: 400| Step: 0
Training loss: 1.6460622153500086
Validation loss: 2.73307880015086

Epoch: 6| Step: 1
Training loss: 1.2549418988399867
Validation loss: 2.7188824296173135

Epoch: 6| Step: 2
Training loss: 1.6537586403964863
Validation loss: 2.736740397096267

Epoch: 6| Step: 3
Training loss: 1.49012525966435
Validation loss: 2.6981301585285027

Epoch: 6| Step: 4
Training loss: 1.292076609787869
Validation loss: 2.702439502388278

Epoch: 6| Step: 5
Training loss: 1.4688313238477249
Validation loss: 2.636789384060657

Epoch: 6| Step: 6
Training loss: 1.6868517301579127
Validation loss: 2.5870962936790236

Epoch: 6| Step: 7
Training loss: 1.5264238870527047
Validation loss: 2.6371786587714574

Epoch: 6| Step: 8
Training loss: 1.3387494748468018
Validation loss: 2.712639998706687

Epoch: 6| Step: 9
Training loss: 1.1615677284531511
Validation loss: 2.66095360575394

Epoch: 6| Step: 10
Training loss: 1.0982779917476666
Validation loss: 2.65787209741692

Epoch: 6| Step: 11
Training loss: 1.871900539828963
Validation loss: 2.6466232882707525

Epoch: 6| Step: 12
Training loss: 1.2823872055215046
Validation loss: 2.64011420250979

Epoch: 6| Step: 13
Training loss: 1.9160334190607855
Validation loss: 2.654389294420494

Epoch: 401| Step: 0
Training loss: 1.587173356220206
Validation loss: 2.6401997812616687

Epoch: 6| Step: 1
Training loss: 1.4875512122306207
Validation loss: 2.7073178710686956

Epoch: 6| Step: 2
Training loss: 1.8147492757339387
Validation loss: 2.7200138618312364

Epoch: 6| Step: 3
Training loss: 1.4284629371863447
Validation loss: 2.71840171483154

Epoch: 6| Step: 4
Training loss: 1.9482461035361647
Validation loss: 2.652802552667294

Epoch: 6| Step: 5
Training loss: 1.3072199656161752
Validation loss: 2.6618161094751107

Epoch: 6| Step: 6
Training loss: 0.9356816459535318
Validation loss: 2.600043295230829

Epoch: 6| Step: 7
Training loss: 1.697546265186528
Validation loss: 2.6973419952077506

Epoch: 6| Step: 8
Training loss: 1.7710249703626975
Validation loss: 2.6912374162062305

Epoch: 6| Step: 9
Training loss: 1.971032530037633
Validation loss: 2.7082455596394435

Epoch: 6| Step: 10
Training loss: 1.723133393033037
Validation loss: 2.676316932091879

Epoch: 6| Step: 11
Training loss: 1.2497168220195516
Validation loss: 2.7128789950460908

Epoch: 6| Step: 12
Training loss: 1.613923764613437
Validation loss: 2.7713427875994694

Epoch: 6| Step: 13
Training loss: 1.946798102022041
Validation loss: 2.7933706710189434

Epoch: 402| Step: 0
Training loss: 1.6821330874630545
Validation loss: 2.7939850992025232

Epoch: 6| Step: 1
Training loss: 1.3425258116842491
Validation loss: 2.7862143911850445

Epoch: 6| Step: 2
Training loss: 1.5637155001194176
Validation loss: 2.681558295178737

Epoch: 6| Step: 3
Training loss: 0.9281184957257097
Validation loss: 2.7080164259342445

Epoch: 6| Step: 4
Training loss: 1.5690504477895988
Validation loss: 2.675278412659266

Epoch: 6| Step: 5
Training loss: 1.504374641700515
Validation loss: 2.69190263530716

Epoch: 6| Step: 6
Training loss: 2.070208622467685
Validation loss: 2.7033196234051635

Epoch: 6| Step: 7
Training loss: 2.077327603969255
Validation loss: 2.706473949583962

Epoch: 6| Step: 8
Training loss: 1.463984855620427
Validation loss: 2.722668553328662

Epoch: 6| Step: 9
Training loss: 1.640508302443777
Validation loss: 2.7612911254804304

Epoch: 6| Step: 10
Training loss: 1.7235310035442422
Validation loss: 2.702649892460742

Epoch: 6| Step: 11
Training loss: 1.3294724753386606
Validation loss: 2.7065404435105336

Epoch: 6| Step: 12
Training loss: 2.1647574620583603
Validation loss: 2.6622913547484544

Epoch: 6| Step: 13
Training loss: 1.4218397869738268
Validation loss: 2.759139162427881

Epoch: 403| Step: 0
Training loss: 1.2939407060649137
Validation loss: 2.7347879225166034

Epoch: 6| Step: 1
Training loss: 1.118115073384402
Validation loss: 2.7595459674477083

Epoch: 6| Step: 2
Training loss: 2.29043631615716
Validation loss: 2.698953088254456

Epoch: 6| Step: 3
Training loss: 1.7157287399528929
Validation loss: 2.66178184877127

Epoch: 6| Step: 4
Training loss: 1.7834785307246241
Validation loss: 2.645706524150472

Epoch: 6| Step: 5
Training loss: 1.414196787827903
Validation loss: 2.651627366593753

Epoch: 6| Step: 6
Training loss: 1.1397914192052085
Validation loss: 2.6884338619389805

Epoch: 6| Step: 7
Training loss: 1.7531181212917566
Validation loss: 2.6748745832425236

Epoch: 6| Step: 8
Training loss: 1.2747660066894289
Validation loss: 2.6934120517934037

Epoch: 6| Step: 9
Training loss: 0.8994850023025498
Validation loss: 2.7060984462621884

Epoch: 6| Step: 10
Training loss: 1.2445810637290005
Validation loss: 2.647232907000026

Epoch: 6| Step: 11
Training loss: 1.614191569718982
Validation loss: 2.6547102860013023

Epoch: 6| Step: 12
Training loss: 1.2602536224755105
Validation loss: 2.684913388530024

Epoch: 6| Step: 13
Training loss: 1.4520165101943832
Validation loss: 2.6736815741915696

Epoch: 404| Step: 0
Training loss: 1.0585881194355562
Validation loss: 2.6233764501984402

Epoch: 6| Step: 1
Training loss: 1.3041942829137225
Validation loss: 2.6645480819967164

Epoch: 6| Step: 2
Training loss: 1.604544417587012
Validation loss: 2.655525467736309

Epoch: 6| Step: 3
Training loss: 2.068748257454775
Validation loss: 2.7035274757243473

Epoch: 6| Step: 4
Training loss: 2.029613481189491
Validation loss: 2.6437007589842296

Epoch: 6| Step: 5
Training loss: 1.1543789235757302
Validation loss: 2.695249031535906

Epoch: 6| Step: 6
Training loss: 1.346012384454058
Validation loss: 2.7506366628538133

Epoch: 6| Step: 7
Training loss: 1.512389672409104
Validation loss: 2.8016365763424895

Epoch: 6| Step: 8
Training loss: 1.7614205863001717
Validation loss: 2.7980457604669793

Epoch: 6| Step: 9
Training loss: 1.5437837790063873
Validation loss: 2.800317716170436

Epoch: 6| Step: 10
Training loss: 1.666439454167699
Validation loss: 2.7920637749781663

Epoch: 6| Step: 11
Training loss: 1.2932833378180306
Validation loss: 2.635893365218776

Epoch: 6| Step: 12
Training loss: 1.5955350266702975
Validation loss: 2.658979352544027

Epoch: 6| Step: 13
Training loss: 1.3262885467939054
Validation loss: 2.6371202704746484

Epoch: 405| Step: 0
Training loss: 1.7066922407668008
Validation loss: 2.5706113971968922

Epoch: 6| Step: 1
Training loss: 2.3438702361737085
Validation loss: 2.620114647210864

Epoch: 6| Step: 2
Training loss: 1.5470092406930849
Validation loss: 2.5651308526266265

Epoch: 6| Step: 3
Training loss: 1.4095290207705151
Validation loss: 2.611450162026994

Epoch: 6| Step: 4
Training loss: 1.362824284170838
Validation loss: 2.6234673763995144

Epoch: 6| Step: 5
Training loss: 1.3010966059027056
Validation loss: 2.78301281730121

Epoch: 6| Step: 6
Training loss: 1.996104977570552
Validation loss: 2.764545869513539

Epoch: 6| Step: 7
Training loss: 1.458092678740327
Validation loss: 2.815133775995863

Epoch: 6| Step: 8
Training loss: 1.515689179939458
Validation loss: 2.657003737077919

Epoch: 6| Step: 9
Training loss: 1.5677027485727932
Validation loss: 2.6774299906753405

Epoch: 6| Step: 10
Training loss: 0.9223173664189788
Validation loss: 2.725050061317256

Epoch: 6| Step: 11
Training loss: 1.5753350855096109
Validation loss: 2.7510581003892534

Epoch: 6| Step: 12
Training loss: 1.4762371855332224
Validation loss: 2.716205736464664

Epoch: 6| Step: 13
Training loss: 1.3376283708805652
Validation loss: 2.7365905795592154

Epoch: 406| Step: 0
Training loss: 2.081317714929885
Validation loss: 2.771204533964674

Epoch: 6| Step: 1
Training loss: 1.3275034628210505
Validation loss: 2.676790872077671

Epoch: 6| Step: 2
Training loss: 1.4007746596854174
Validation loss: 2.684739010532455

Epoch: 6| Step: 3
Training loss: 1.1492322390637972
Validation loss: 2.685519457128032

Epoch: 6| Step: 4
Training loss: 1.438661686418155
Validation loss: 2.7952883320434077

Epoch: 6| Step: 5
Training loss: 1.6444716635304304
Validation loss: 2.8034998682415644

Epoch: 6| Step: 6
Training loss: 2.5719779048463027
Validation loss: 2.9404649853791636

Epoch: 6| Step: 7
Training loss: 1.24225649851978
Validation loss: 2.8905818764159092

Epoch: 6| Step: 8
Training loss: 1.738926868342192
Validation loss: 2.821515616579726

Epoch: 6| Step: 9
Training loss: 1.4613933973869835
Validation loss: 2.7374086826369877

Epoch: 6| Step: 10
Training loss: 1.663198470622025
Validation loss: 2.75149479612505

Epoch: 6| Step: 11
Training loss: 1.37108227325592
Validation loss: 2.6317657291481886

Epoch: 6| Step: 12
Training loss: 1.18736763266625
Validation loss: 2.6455543150674807

Epoch: 6| Step: 13
Training loss: 1.2590657973938666
Validation loss: 2.691855877956792

Epoch: 407| Step: 0
Training loss: 1.5712977113361257
Validation loss: 2.720021122448381

Epoch: 6| Step: 1
Training loss: 1.318634230607889
Validation loss: 2.743141899413182

Epoch: 6| Step: 2
Training loss: 1.0006693149834884
Validation loss: 2.6942318284044116

Epoch: 6| Step: 3
Training loss: 1.6602770952111248
Validation loss: 2.6799697356626604

Epoch: 6| Step: 4
Training loss: 1.396202688551127
Validation loss: 2.717463009689864

Epoch: 6| Step: 5
Training loss: 1.227608932898031
Validation loss: 2.7129413773009827

Epoch: 6| Step: 6
Training loss: 1.4321281570968463
Validation loss: 2.739862889481434

Epoch: 6| Step: 7
Training loss: 1.323214620042637
Validation loss: 2.7309305931033356

Epoch: 6| Step: 8
Training loss: 1.4554836041055454
Validation loss: 2.6618126162470648

Epoch: 6| Step: 9
Training loss: 1.5988553124788056
Validation loss: 2.7162070384799577

Epoch: 6| Step: 10
Training loss: 1.8928878105640488
Validation loss: 2.6406290479399526

Epoch: 6| Step: 11
Training loss: 2.2098340627245823
Validation loss: 2.645700396304467

Epoch: 6| Step: 12
Training loss: 1.6809907337502923
Validation loss: 2.6189071775016406

Epoch: 6| Step: 13
Training loss: 0.9974625700426906
Validation loss: 2.598612704385006

Epoch: 408| Step: 0
Training loss: 0.9779762715618601
Validation loss: 2.646725952083389

Epoch: 6| Step: 1
Training loss: 1.5935471349519212
Validation loss: 2.6937055579677085

Epoch: 6| Step: 2
Training loss: 1.1766228689484248
Validation loss: 2.623750919283118

Epoch: 6| Step: 3
Training loss: 1.2945057932641924
Validation loss: 2.6178312658085336

Epoch: 6| Step: 4
Training loss: 2.064232878543885
Validation loss: 2.628444561182162

Epoch: 6| Step: 5
Training loss: 1.5528753252653194
Validation loss: 2.654000141024017

Epoch: 6| Step: 6
Training loss: 1.4848741194164221
Validation loss: 2.6949845119071374

Epoch: 6| Step: 7
Training loss: 1.499357642279613
Validation loss: 2.686550919080102

Epoch: 6| Step: 8
Training loss: 1.194536443365969
Validation loss: 2.6906278136885136

Epoch: 6| Step: 9
Training loss: 1.7334016010094373
Validation loss: 2.6907384714854703

Epoch: 6| Step: 10
Training loss: 1.5067333253248265
Validation loss: 2.6945166845786077

Epoch: 6| Step: 11
Training loss: 1.783635666731054
Validation loss: 2.7424582033499023

Epoch: 6| Step: 12
Training loss: 1.4854064570107728
Validation loss: 2.79025130665752

Epoch: 6| Step: 13
Training loss: 1.7441445892049714
Validation loss: 2.835339289573383

Epoch: 409| Step: 0
Training loss: 1.5412951700563438
Validation loss: 2.7802785112526514

Epoch: 6| Step: 1
Training loss: 1.5232725396466333
Validation loss: 2.806445655430706

Epoch: 6| Step: 2
Training loss: 2.0279276747437764
Validation loss: 2.7292726996016157

Epoch: 6| Step: 3
Training loss: 1.4460425929949696
Validation loss: 2.68299217089045

Epoch: 6| Step: 4
Training loss: 0.9979715337515882
Validation loss: 2.744869402388466

Epoch: 6| Step: 5
Training loss: 1.5131745339707408
Validation loss: 2.786736780437506

Epoch: 6| Step: 6
Training loss: 1.534620740056369
Validation loss: 2.725846729492496

Epoch: 6| Step: 7
Training loss: 1.5583609882831566
Validation loss: 2.716385803643069

Epoch: 6| Step: 8
Training loss: 1.1618394041226114
Validation loss: 2.6683957236257476

Epoch: 6| Step: 9
Training loss: 1.3563335639067164
Validation loss: 2.753436903040871

Epoch: 6| Step: 10
Training loss: 1.4002237260393648
Validation loss: 2.667061796319417

Epoch: 6| Step: 11
Training loss: 1.4119956154066313
Validation loss: 2.654652013872685

Epoch: 6| Step: 12
Training loss: 1.1200675387965493
Validation loss: 2.6075235068412823

Epoch: 6| Step: 13
Training loss: 1.4690814354476918
Validation loss: 2.705637181578387

Epoch: 410| Step: 0
Training loss: 1.399845458765325
Validation loss: 2.6867418328680475

Epoch: 6| Step: 1
Training loss: 0.8708295892029603
Validation loss: 2.6666338491407284

Epoch: 6| Step: 2
Training loss: 1.927466964339624
Validation loss: 2.692140033500523

Epoch: 6| Step: 3
Training loss: 1.6772372094242503
Validation loss: 2.725611348650466

Epoch: 6| Step: 4
Training loss: 1.3788038869583326
Validation loss: 2.743880977994665

Epoch: 6| Step: 5
Training loss: 1.6957552986405295
Validation loss: 2.759412450885472

Epoch: 6| Step: 6
Training loss: 1.25606012000628
Validation loss: 2.7975266477095766

Epoch: 6| Step: 7
Training loss: 1.8268629102799538
Validation loss: 2.7553537879628873

Epoch: 6| Step: 8
Training loss: 1.6193863667273576
Validation loss: 2.7289947329421778

Epoch: 6| Step: 9
Training loss: 1.126506115141219
Validation loss: 2.636935754959011

Epoch: 6| Step: 10
Training loss: 1.390587066818812
Validation loss: 2.6673284444607632

Epoch: 6| Step: 11
Training loss: 1.6975754080920993
Validation loss: 2.7490675819335255

Epoch: 6| Step: 12
Training loss: 1.2873063117694057
Validation loss: 2.7039807091613586

Epoch: 6| Step: 13
Training loss: 1.9486842215681826
Validation loss: 2.7399111552812503

Epoch: 411| Step: 0
Training loss: 1.3517442261346961
Validation loss: 2.7176887955017515

Epoch: 6| Step: 1
Training loss: 1.5723611553858448
Validation loss: 2.715447140609932

Epoch: 6| Step: 2
Training loss: 1.6167489161985464
Validation loss: 2.7051270408201384

Epoch: 6| Step: 3
Training loss: 1.0317768716162057
Validation loss: 2.7294586598129023

Epoch: 6| Step: 4
Training loss: 1.2103991880922185
Validation loss: 2.887453012510731

Epoch: 6| Step: 5
Training loss: 2.013084170458318
Validation loss: 2.9218575380180916

Epoch: 6| Step: 6
Training loss: 1.2932964727877627
Validation loss: 2.845962969860529

Epoch: 6| Step: 7
Training loss: 1.7160310914306278
Validation loss: 2.7512324057026136

Epoch: 6| Step: 8
Training loss: 1.300966175211404
Validation loss: 2.7460589924435457

Epoch: 6| Step: 9
Training loss: 1.3725362726362274
Validation loss: 2.749410190332498

Epoch: 6| Step: 10
Training loss: 1.9599917133311826
Validation loss: 2.7692056095883633

Epoch: 6| Step: 11
Training loss: 1.493964929161394
Validation loss: 2.6537503018216575

Epoch: 6| Step: 12
Training loss: 2.123653434008449
Validation loss: 2.7932057953657643

Epoch: 6| Step: 13
Training loss: 1.5245258845017584
Validation loss: 2.729870783026588

Epoch: 412| Step: 0
Training loss: 1.4204563147793934
Validation loss: 2.6799526695086007

Epoch: 6| Step: 1
Training loss: 1.299590702914548
Validation loss: 2.731264928781314

Epoch: 6| Step: 2
Training loss: 1.4472854757041556
Validation loss: 2.7903146933639085

Epoch: 6| Step: 3
Training loss: 1.7910094349461938
Validation loss: 2.8263507427002272

Epoch: 6| Step: 4
Training loss: 1.2727991856347625
Validation loss: 2.762069989161287

Epoch: 6| Step: 5
Training loss: 1.1222754441179281
Validation loss: 2.7228998980970203

Epoch: 6| Step: 6
Training loss: 1.4228946257746389
Validation loss: 2.742240854524939

Epoch: 6| Step: 7
Training loss: 1.4922125849188137
Validation loss: 2.676662149706585

Epoch: 6| Step: 8
Training loss: 1.1402930730417786
Validation loss: 2.742299917150166

Epoch: 6| Step: 9
Training loss: 1.9545650209008028
Validation loss: 2.744854578290093

Epoch: 6| Step: 10
Training loss: 1.6877453237159983
Validation loss: 2.7228652239033266

Epoch: 6| Step: 11
Training loss: 1.1158183317669328
Validation loss: 2.7090857903259744

Epoch: 6| Step: 12
Training loss: 2.3886508145343543
Validation loss: 2.709431687186975

Epoch: 6| Step: 13
Training loss: 0.9888935830746604
Validation loss: 2.7440586426277767

Epoch: 413| Step: 0
Training loss: 1.2863305938354117
Validation loss: 2.74656642067323

Epoch: 6| Step: 1
Training loss: 1.5638333544329497
Validation loss: 2.761728519636443

Epoch: 6| Step: 2
Training loss: 1.2577797073923083
Validation loss: 2.791748662475109

Epoch: 6| Step: 3
Training loss: 1.5963248602296485
Validation loss: 2.8293424623805308

Epoch: 6| Step: 4
Training loss: 1.3890794888155857
Validation loss: 2.752058515838684

Epoch: 6| Step: 5
Training loss: 2.2156769868807302
Validation loss: 2.7341798476560593

Epoch: 6| Step: 6
Training loss: 1.414479821097276
Validation loss: 2.666611660946341

Epoch: 6| Step: 7
Training loss: 1.4951539436870291
Validation loss: 2.699966923193186

Epoch: 6| Step: 8
Training loss: 0.8967203399011316
Validation loss: 2.7283346834763917

Epoch: 6| Step: 9
Training loss: 0.920686149197901
Validation loss: 2.7164464377633255

Epoch: 6| Step: 10
Training loss: 1.5540363731006033
Validation loss: 2.7319218703203925

Epoch: 6| Step: 11
Training loss: 1.4684498256986795
Validation loss: 2.746184809239021

Epoch: 6| Step: 12
Training loss: 1.303626537091286
Validation loss: 2.7376700175774316

Epoch: 6| Step: 13
Training loss: 1.2643890939738776
Validation loss: 2.764257462898009

Epoch: 414| Step: 0
Training loss: 1.3796799086019518
Validation loss: 2.7785038767301287

Epoch: 6| Step: 1
Training loss: 1.1865170074414246
Validation loss: 2.711785629943853

Epoch: 6| Step: 2
Training loss: 1.4660789063413813
Validation loss: 2.731774639542761

Epoch: 6| Step: 3
Training loss: 1.2507913945279292
Validation loss: 2.683521475228187

Epoch: 6| Step: 4
Training loss: 1.4664656548313455
Validation loss: 2.7079545171835147

Epoch: 6| Step: 5
Training loss: 1.557512716299593
Validation loss: 2.7881752547673537

Epoch: 6| Step: 6
Training loss: 1.183167484687436
Validation loss: 2.7461048920044973

Epoch: 6| Step: 7
Training loss: 1.3874666158423072
Validation loss: 2.752240799685583

Epoch: 6| Step: 8
Training loss: 1.2539998907852734
Validation loss: 2.8049998414962642

Epoch: 6| Step: 9
Training loss: 2.1720217648323685
Validation loss: 2.8290550430892316

Epoch: 6| Step: 10
Training loss: 1.0176609466880118
Validation loss: 2.780494473023853

Epoch: 6| Step: 11
Training loss: 1.573438124291941
Validation loss: 2.8082841995272725

Epoch: 6| Step: 12
Training loss: 1.164216613808529
Validation loss: 2.786250237986442

Epoch: 6| Step: 13
Training loss: 1.6277854228500197
Validation loss: 2.696656257949596

Epoch: 415| Step: 0
Training loss: 0.9711791316312055
Validation loss: 2.7593331039663944

Epoch: 6| Step: 1
Training loss: 1.477583275011844
Validation loss: 2.7175064458364093

Epoch: 6| Step: 2
Training loss: 1.3697248183886213
Validation loss: 2.713550579815441

Epoch: 6| Step: 3
Training loss: 1.2014862889600109
Validation loss: 2.691068232201097

Epoch: 6| Step: 4
Training loss: 2.457352512625605
Validation loss: 2.6701081440487626

Epoch: 6| Step: 5
Training loss: 1.6050664021668979
Validation loss: 2.765126874931894

Epoch: 6| Step: 6
Training loss: 1.486190248127251
Validation loss: 2.80337283918173

Epoch: 6| Step: 7
Training loss: 1.6149662261124116
Validation loss: 2.832632740206627

Epoch: 6| Step: 8
Training loss: 1.1825880555802388
Validation loss: 2.8500493742475057

Epoch: 6| Step: 9
Training loss: 1.7400287202679092
Validation loss: 2.810918052256896

Epoch: 6| Step: 10
Training loss: 0.8835409754095512
Validation loss: 2.6572297925834834

Epoch: 6| Step: 11
Training loss: 1.3782701619135456
Validation loss: 2.6614476307593424

Epoch: 6| Step: 12
Training loss: 0.6927963334788239
Validation loss: 2.7101596005681956

Epoch: 6| Step: 13
Training loss: 1.5091963826200607
Validation loss: 2.6645310512858735

Epoch: 416| Step: 0
Training loss: 1.651497482131577
Validation loss: 2.7545270576281413

Epoch: 6| Step: 1
Training loss: 1.3885833669106662
Validation loss: 2.8101042539685603

Epoch: 6| Step: 2
Training loss: 1.0089022045813552
Validation loss: 2.7610383515287817

Epoch: 6| Step: 3
Training loss: 1.579782804940259
Validation loss: 2.6689089100180534

Epoch: 6| Step: 4
Training loss: 1.3201114117681851
Validation loss: 2.7010078886082383

Epoch: 6| Step: 5
Training loss: 1.5619341016244517
Validation loss: 2.754642801107859

Epoch: 6| Step: 6
Training loss: 1.6596522385204462
Validation loss: 2.7504875950152443

Epoch: 6| Step: 7
Training loss: 1.550740277496171
Validation loss: 2.72405841320181

Epoch: 6| Step: 8
Training loss: 2.3499960513791938
Validation loss: 2.7047019577594913

Epoch: 6| Step: 9
Training loss: 1.1183785445222276
Validation loss: 2.7053738098494424

Epoch: 6| Step: 10
Training loss: 0.8814265081156706
Validation loss: 2.6715464101781268

Epoch: 6| Step: 11
Training loss: 1.4060709521432186
Validation loss: 2.686395847106126

Epoch: 6| Step: 12
Training loss: 1.2378689052305014
Validation loss: 2.7076431030656347

Epoch: 6| Step: 13
Training loss: 0.9798842431815099
Validation loss: 2.6987953129931355

Epoch: 417| Step: 0
Training loss: 1.3636845645188471
Validation loss: 2.659704751692438

Epoch: 6| Step: 1
Training loss: 1.3242741125906334
Validation loss: 2.682765916298823

Epoch: 6| Step: 2
Training loss: 2.2718643041303843
Validation loss: 2.730928897968525

Epoch: 6| Step: 3
Training loss: 1.074182350235572
Validation loss: 2.7151579823671095

Epoch: 6| Step: 4
Training loss: 1.1933426426590106
Validation loss: 2.723751947718253

Epoch: 6| Step: 5
Training loss: 1.6542279838260336
Validation loss: 2.6769376311871307

Epoch: 6| Step: 6
Training loss: 1.216033843259669
Validation loss: 2.7632211558032598

Epoch: 6| Step: 7
Training loss: 1.2006889551018975
Validation loss: 2.686276711907582

Epoch: 6| Step: 8
Training loss: 1.199129579689413
Validation loss: 2.7209785068293497

Epoch: 6| Step: 9
Training loss: 1.269311786168868
Validation loss: 2.668758091255447

Epoch: 6| Step: 10
Training loss: 1.14081927173569
Validation loss: 2.6887838416908583

Epoch: 6| Step: 11
Training loss: 1.131339700841284
Validation loss: 2.7251002663647315

Epoch: 6| Step: 12
Training loss: 1.4319675795598594
Validation loss: 2.7469204363285606

Epoch: 6| Step: 13
Training loss: 1.9973144978885904
Validation loss: 2.6756305067383974

Epoch: 418| Step: 0
Training loss: 0.953968925197894
Validation loss: 2.6602122580541407

Epoch: 6| Step: 1
Training loss: 1.3922549778333337
Validation loss: 2.742463028298368

Epoch: 6| Step: 2
Training loss: 1.2223718574468707
Validation loss: 2.706008989674893

Epoch: 6| Step: 3
Training loss: 1.1036181376956016
Validation loss: 2.724894890814159

Epoch: 6| Step: 4
Training loss: 1.3171650315582335
Validation loss: 2.705119519886719

Epoch: 6| Step: 5
Training loss: 1.3645971991535837
Validation loss: 2.7662124297286526

Epoch: 6| Step: 6
Training loss: 1.9097705287796267
Validation loss: 2.6875471510188587

Epoch: 6| Step: 7
Training loss: 1.2386726699388662
Validation loss: 2.6713288327123577

Epoch: 6| Step: 8
Training loss: 2.039744763582327
Validation loss: 2.7096658265318263

Epoch: 6| Step: 9
Training loss: 1.3810012938695726
Validation loss: 2.6829630236869755

Epoch: 6| Step: 10
Training loss: 1.2508078825460394
Validation loss: 2.697085231574271

Epoch: 6| Step: 11
Training loss: 1.2717803282498767
Validation loss: 2.6573001057425887

Epoch: 6| Step: 12
Training loss: 1.468221041614162
Validation loss: 2.773033972383846

Epoch: 6| Step: 13
Training loss: 1.095701656238571
Validation loss: 2.6875981453414295

Epoch: 419| Step: 0
Training loss: 1.2385332109928908
Validation loss: 2.7143500375415996

Epoch: 6| Step: 1
Training loss: 1.3972172874597797
Validation loss: 2.6915164181216036

Epoch: 6| Step: 2
Training loss: 1.537630450909598
Validation loss: 2.743012017227793

Epoch: 6| Step: 3
Training loss: 1.1533116300742194
Validation loss: 2.7964513305070144

Epoch: 6| Step: 4
Training loss: 1.4252853576310571
Validation loss: 2.7681322532381354

Epoch: 6| Step: 5
Training loss: 1.2592790477159856
Validation loss: 2.711210429499476

Epoch: 6| Step: 6
Training loss: 1.167741325971777
Validation loss: 2.72290843523606

Epoch: 6| Step: 7
Training loss: 1.9238245930130966
Validation loss: 2.7414698372618913

Epoch: 6| Step: 8
Training loss: 1.526571795807163
Validation loss: 2.80720124013534

Epoch: 6| Step: 9
Training loss: 1.7438848463853318
Validation loss: 2.74922821023059

Epoch: 6| Step: 10
Training loss: 1.3145212323029138
Validation loss: 2.7509825280643594

Epoch: 6| Step: 11
Training loss: 1.2367501404875734
Validation loss: 2.6939562642607235

Epoch: 6| Step: 12
Training loss: 0.9325955852782823
Validation loss: 2.681196983186714

Epoch: 6| Step: 13
Training loss: 1.3823567733246034
Validation loss: 2.6466933126893895

Epoch: 420| Step: 0
Training loss: 2.0405153674458605
Validation loss: 2.737690671902465

Epoch: 6| Step: 1
Training loss: 1.4766199009955105
Validation loss: 2.678589368790387

Epoch: 6| Step: 2
Training loss: 1.2961472457137773
Validation loss: 2.6538422611350487

Epoch: 6| Step: 3
Training loss: 1.5291854018779576
Validation loss: 2.725923567183867

Epoch: 6| Step: 4
Training loss: 1.2280309354756123
Validation loss: 2.7326261758946186

Epoch: 6| Step: 5
Training loss: 1.1575007504157977
Validation loss: 2.7959774004851035

Epoch: 6| Step: 6
Training loss: 1.6346009603355889
Validation loss: 2.776321888439038

Epoch: 6| Step: 7
Training loss: 0.876600878686223
Validation loss: 2.7817394525990746

Epoch: 6| Step: 8
Training loss: 1.4589620688085232
Validation loss: 2.7436974870179394

Epoch: 6| Step: 9
Training loss: 1.154865673395411
Validation loss: 2.7784082131763537

Epoch: 6| Step: 10
Training loss: 1.443683262723381
Validation loss: 2.7595467738266466

Epoch: 6| Step: 11
Training loss: 1.5835240985324266
Validation loss: 2.7570764785995774

Epoch: 6| Step: 12
Training loss: 0.8938246355704678
Validation loss: 2.7716725926002317

Epoch: 6| Step: 13
Training loss: 1.5990906038362378
Validation loss: 2.7846219057155923

Epoch: 421| Step: 0
Training loss: 0.9546450703833635
Validation loss: 2.7451769264657413

Epoch: 6| Step: 1
Training loss: 1.1202907012138124
Validation loss: 2.756564382902675

Epoch: 6| Step: 2
Training loss: 1.0033531000929765
Validation loss: 2.724041681613093

Epoch: 6| Step: 3
Training loss: 2.2133708813174895
Validation loss: 2.7446080724901254

Epoch: 6| Step: 4
Training loss: 1.1898653665884595
Validation loss: 2.7185992202749065

Epoch: 6| Step: 5
Training loss: 1.332032458173366
Validation loss: 2.645754374930405

Epoch: 6| Step: 6
Training loss: 1.645444421650826
Validation loss: 2.721050210188781

Epoch: 6| Step: 7
Training loss: 1.7348960574892514
Validation loss: 2.686054743052942

Epoch: 6| Step: 8
Training loss: 1.9419257775608778
Validation loss: 2.6545966968270864

Epoch: 6| Step: 9
Training loss: 1.4447995487026553
Validation loss: 2.775143151700616

Epoch: 6| Step: 10
Training loss: 1.2866562087534983
Validation loss: 2.762834955567253

Epoch: 6| Step: 11
Training loss: 1.6640905816659313
Validation loss: 2.760160748596585

Epoch: 6| Step: 12
Training loss: 1.7171091049668292
Validation loss: 2.8565136710570442

Epoch: 6| Step: 13
Training loss: 1.931347337757375
Validation loss: 2.889233283356945

Epoch: 422| Step: 0
Training loss: 1.7928843758869903
Validation loss: 2.956168139065604

Epoch: 6| Step: 1
Training loss: 1.6855560691467812
Validation loss: 2.7813586953172007

Epoch: 6| Step: 2
Training loss: 1.319586288903342
Validation loss: 2.766102521515738

Epoch: 6| Step: 3
Training loss: 0.9528085151906825
Validation loss: 2.7081547653800984

Epoch: 6| Step: 4
Training loss: 1.679063903024195
Validation loss: 2.719784316996931

Epoch: 6| Step: 5
Training loss: 1.226232350618076
Validation loss: 2.7231717891786964

Epoch: 6| Step: 6
Training loss: 1.3281476187182408
Validation loss: 2.664733190749093

Epoch: 6| Step: 7
Training loss: 1.7825449870720427
Validation loss: 2.681590243480053

Epoch: 6| Step: 8
Training loss: 1.0114186552510689
Validation loss: 2.7104731591739433

Epoch: 6| Step: 9
Training loss: 1.290278375737481
Validation loss: 2.691980176172484

Epoch: 6| Step: 10
Training loss: 1.2216072823392976
Validation loss: 2.710661339962247

Epoch: 6| Step: 11
Training loss: 1.086660734337916
Validation loss: 2.6365801287345767

Epoch: 6| Step: 12
Training loss: 1.5368635860855437
Validation loss: 2.716053352476145

Epoch: 6| Step: 13
Training loss: 2.160332615638821
Validation loss: 2.695097629993944

Epoch: 423| Step: 0
Training loss: 1.9106785970800326
Validation loss: 2.672874501689372

Epoch: 6| Step: 1
Training loss: 1.5255891131064119
Validation loss: 2.685606592612555

Epoch: 6| Step: 2
Training loss: 1.1984697419645103
Validation loss: 2.735980944648923

Epoch: 6| Step: 3
Training loss: 1.3164976184503243
Validation loss: 2.6671687090673073

Epoch: 6| Step: 4
Training loss: 1.064281540786592
Validation loss: 2.6673309323361147

Epoch: 6| Step: 5
Training loss: 1.4341409662675106
Validation loss: 2.755352850562982

Epoch: 6| Step: 6
Training loss: 0.923985893214075
Validation loss: 2.7117872417991324

Epoch: 6| Step: 7
Training loss: 1.3305145309555022
Validation loss: 2.772753248742093

Epoch: 6| Step: 8
Training loss: 0.9997161521991149
Validation loss: 2.722561747490312

Epoch: 6| Step: 9
Training loss: 1.9425646513167298
Validation loss: 2.7208107121234564

Epoch: 6| Step: 10
Training loss: 0.6984771973254125
Validation loss: 2.691761157696994

Epoch: 6| Step: 11
Training loss: 1.5624296553989458
Validation loss: 2.7372194300246466

Epoch: 6| Step: 12
Training loss: 0.8426613318716057
Validation loss: 2.764932477493339

Epoch: 6| Step: 13
Training loss: 1.3782958497866793
Validation loss: 2.7144611189629315

Epoch: 424| Step: 0
Training loss: 1.4146590686837344
Validation loss: 2.735795079185652

Epoch: 6| Step: 1
Training loss: 0.7422013933989495
Validation loss: 2.6485769559590233

Epoch: 6| Step: 2
Training loss: 1.303054381362132
Validation loss: 2.7258151905719825

Epoch: 6| Step: 3
Training loss: 1.3521687024658882
Validation loss: 2.712856262296997

Epoch: 6| Step: 4
Training loss: 1.285931338994226
Validation loss: 2.7289633687329613

Epoch: 6| Step: 5
Training loss: 1.3393269868576605
Validation loss: 2.72388938588009

Epoch: 6| Step: 6
Training loss: 1.0995234020495712
Validation loss: 2.725474084800318

Epoch: 6| Step: 7
Training loss: 0.9855596891546121
Validation loss: 2.750400340677077

Epoch: 6| Step: 8
Training loss: 1.7353657135308644
Validation loss: 2.720851670495983

Epoch: 6| Step: 9
Training loss: 1.0178255157528613
Validation loss: 2.7122979465357906

Epoch: 6| Step: 10
Training loss: 2.107808979956174
Validation loss: 2.6575335972822236

Epoch: 6| Step: 11
Training loss: 1.305818627052939
Validation loss: 2.6890899627246663

Epoch: 6| Step: 12
Training loss: 1.3627044419361036
Validation loss: 2.731073708158707

Epoch: 6| Step: 13
Training loss: 1.5135726403963399
Validation loss: 2.7930884560138947

Epoch: 425| Step: 0
Training loss: 1.4302122060006044
Validation loss: 2.7351082245628247

Epoch: 6| Step: 1
Training loss: 1.1869709442554666
Validation loss: 2.7351575476432597

Epoch: 6| Step: 2
Training loss: 1.2016991923229585
Validation loss: 2.683495635895592

Epoch: 6| Step: 3
Training loss: 0.8931506634943222
Validation loss: 2.7253904109643283

Epoch: 6| Step: 4
Training loss: 1.4459442407612912
Validation loss: 2.7604024970692613

Epoch: 6| Step: 5
Training loss: 1.3533214963824378
Validation loss: 2.813386989175253

Epoch: 6| Step: 6
Training loss: 1.1885604640712373
Validation loss: 2.7945733571721707

Epoch: 6| Step: 7
Training loss: 1.4069391045694462
Validation loss: 2.766200047136908

Epoch: 6| Step: 8
Training loss: 0.916529497085035
Validation loss: 2.73404374795537

Epoch: 6| Step: 9
Training loss: 1.3100162802114121
Validation loss: 2.7239032445604465

Epoch: 6| Step: 10
Training loss: 2.1891218440134876
Validation loss: 2.7260449491215555

Epoch: 6| Step: 11
Training loss: 1.6362474441216939
Validation loss: 2.747868940407939

Epoch: 6| Step: 12
Training loss: 1.2080949953855746
Validation loss: 2.675528929756741

Epoch: 6| Step: 13
Training loss: 1.2053053284664894
Validation loss: 2.719836401647587

Epoch: 426| Step: 0
Training loss: 1.4324877055707417
Validation loss: 2.6649930043036254

Epoch: 6| Step: 1
Training loss: 1.2330015243062964
Validation loss: 2.720139773087375

Epoch: 6| Step: 2
Training loss: 1.2377104300944743
Validation loss: 2.713914407523143

Epoch: 6| Step: 3
Training loss: 1.6802974569290423
Validation loss: 2.7384357635540137

Epoch: 6| Step: 4
Training loss: 1.273056909522195
Validation loss: 2.743442418520274

Epoch: 6| Step: 5
Training loss: 2.1423170544425423
Validation loss: 2.6895368235669257

Epoch: 6| Step: 6
Training loss: 0.9703073903807726
Validation loss: 2.7743701351724956

Epoch: 6| Step: 7
Training loss: 1.1551509479456237
Validation loss: 2.7334568334994533

Epoch: 6| Step: 8
Training loss: 1.8660215304646388
Validation loss: 2.7378393987623015

Epoch: 6| Step: 9
Training loss: 1.2499292353626692
Validation loss: 2.7340772920848515

Epoch: 6| Step: 10
Training loss: 1.0387235963589512
Validation loss: 2.7008084640919456

Epoch: 6| Step: 11
Training loss: 0.9752544340078342
Validation loss: 2.763160354490468

Epoch: 6| Step: 12
Training loss: 1.0774136836623145
Validation loss: 2.7968987405291523

Epoch: 6| Step: 13
Training loss: 1.3776978987863902
Validation loss: 2.7934746272997564

Epoch: 427| Step: 0
Training loss: 0.948660007123924
Validation loss: 2.746588107632167

Epoch: 6| Step: 1
Training loss: 1.4521763483993897
Validation loss: 2.7840138821630287

Epoch: 6| Step: 2
Training loss: 1.698481678322342
Validation loss: 2.7706106904338195

Epoch: 6| Step: 3
Training loss: 1.2144976549153401
Validation loss: 2.7893215454504676

Epoch: 6| Step: 4
Training loss: 1.9757142791318543
Validation loss: 2.772207254124327

Epoch: 6| Step: 5
Training loss: 1.266349208519068
Validation loss: 2.794300919388879

Epoch: 6| Step: 6
Training loss: 1.1189486087558087
Validation loss: 2.7360615787659226

Epoch: 6| Step: 7
Training loss: 1.2695970254144513
Validation loss: 2.7491542642742814

Epoch: 6| Step: 8
Training loss: 1.5125265008795836
Validation loss: 2.7102687718131

Epoch: 6| Step: 9
Training loss: 1.0462100066240072
Validation loss: 2.817408679158049

Epoch: 6| Step: 10
Training loss: 1.536490367835627
Validation loss: 2.7589748767853295

Epoch: 6| Step: 11
Training loss: 1.4298704270033697
Validation loss: 2.7601613892371435

Epoch: 6| Step: 12
Training loss: 1.1307032449364163
Validation loss: 2.75962790010331

Epoch: 6| Step: 13
Training loss: 0.9762167356638762
Validation loss: 2.8014374074756963

Epoch: 428| Step: 0
Training loss: 1.8921722512296189
Validation loss: 2.7406927093876

Epoch: 6| Step: 1
Training loss: 1.6908636125711436
Validation loss: 2.7872654016418053

Epoch: 6| Step: 2
Training loss: 1.4244885580902806
Validation loss: 2.810485146387864

Epoch: 6| Step: 3
Training loss: 1.1979877229707878
Validation loss: 2.932205637092741

Epoch: 6| Step: 4
Training loss: 2.1700028508251115
Validation loss: 2.7815699304026373

Epoch: 6| Step: 5
Training loss: 1.4106888967095335
Validation loss: 2.813830068232263

Epoch: 6| Step: 6
Training loss: 1.2013015801096332
Validation loss: 2.7607562929829195

Epoch: 6| Step: 7
Training loss: 1.3378703540463646
Validation loss: 2.741323583136869

Epoch: 6| Step: 8
Training loss: 0.8929342148077509
Validation loss: 2.6990948955497847

Epoch: 6| Step: 9
Training loss: 1.3296907507815223
Validation loss: 2.6909552400661574

Epoch: 6| Step: 10
Training loss: 1.3075732906799422
Validation loss: 2.6980085811398404

Epoch: 6| Step: 11
Training loss: 1.3028608772590604
Validation loss: 2.6526563981688267

Epoch: 6| Step: 12
Training loss: 1.1070843002110284
Validation loss: 2.6612911930841023

Epoch: 6| Step: 13
Training loss: 1.421281963381508
Validation loss: 2.708746839403234

Epoch: 429| Step: 0
Training loss: 1.377621579075207
Validation loss: 2.591629632356088

Epoch: 6| Step: 1
Training loss: 1.4379769238993345
Validation loss: 2.6146566727726235

Epoch: 6| Step: 2
Training loss: 1.2595190945488206
Validation loss: 2.6416403720000323

Epoch: 6| Step: 3
Training loss: 1.02861976429544
Validation loss: 2.6432425111831535

Epoch: 6| Step: 4
Training loss: 1.4190731739213152
Validation loss: 2.64399887428606

Epoch: 6| Step: 5
Training loss: 1.2436777448512657
Validation loss: 2.6268712745971063

Epoch: 6| Step: 6
Training loss: 1.4004894524980285
Validation loss: 2.623399261565513

Epoch: 6| Step: 7
Training loss: 1.189495367793989
Validation loss: 2.7104829669166923

Epoch: 6| Step: 8
Training loss: 1.3487578823647663
Validation loss: 2.71611705166181

Epoch: 6| Step: 9
Training loss: 1.0066293084452547
Validation loss: 2.7068351465399263

Epoch: 6| Step: 10
Training loss: 2.2214887666935557
Validation loss: 2.7359627900260977

Epoch: 6| Step: 11
Training loss: 0.7710296836141062
Validation loss: 2.7717178816277612

Epoch: 6| Step: 12
Training loss: 1.4133355395431813
Validation loss: 2.7882201759815834

Epoch: 6| Step: 13
Training loss: 1.6269161224736877
Validation loss: 2.756212600719544

Epoch: 430| Step: 0
Training loss: 1.585880447639327
Validation loss: 2.7019985549399586

Epoch: 6| Step: 1
Training loss: 1.12074869940106
Validation loss: 2.6347849595152497

Epoch: 6| Step: 2
Training loss: 1.3003999534998838
Validation loss: 2.676825697756056

Epoch: 6| Step: 3
Training loss: 0.9544217715390945
Validation loss: 2.7649492921830054

Epoch: 6| Step: 4
Training loss: 1.4689621467777076
Validation loss: 2.680740727785769

Epoch: 6| Step: 5
Training loss: 1.1877947491707193
Validation loss: 2.7147602461818745

Epoch: 6| Step: 6
Training loss: 1.1901720001232257
Validation loss: 2.6930607184529527

Epoch: 6| Step: 7
Training loss: 0.9644660673821984
Validation loss: 2.70618163001171

Epoch: 6| Step: 8
Training loss: 1.5021541545254702
Validation loss: 2.679895746945743

Epoch: 6| Step: 9
Training loss: 1.007648306785883
Validation loss: 2.7829995242598295

Epoch: 6| Step: 10
Training loss: 1.365868417096484
Validation loss: 2.8232303083854493

Epoch: 6| Step: 11
Training loss: 1.274053412960115
Validation loss: 2.816763606086829

Epoch: 6| Step: 12
Training loss: 1.4971569456750051
Validation loss: 2.7732949950093064

Epoch: 6| Step: 13
Training loss: 2.05507966567016
Validation loss: 2.832626189080554

Epoch: 431| Step: 0
Training loss: 1.1408242352115672
Validation loss: 2.7912828599129074

Epoch: 6| Step: 1
Training loss: 1.1219411697637938
Validation loss: 2.7537121715651565

Epoch: 6| Step: 2
Training loss: 1.0455040566590545
Validation loss: 2.75886766889995

Epoch: 6| Step: 3
Training loss: 1.4132286690398315
Validation loss: 2.7836869953564203

Epoch: 6| Step: 4
Training loss: 1.4901034996389446
Validation loss: 2.754675690497063

Epoch: 6| Step: 5
Training loss: 1.684035453473019
Validation loss: 2.738579777776098

Epoch: 6| Step: 6
Training loss: 2.310661203453149
Validation loss: 2.7699604284762813

Epoch: 6| Step: 7
Training loss: 1.2298378432002008
Validation loss: 2.784385599500787

Epoch: 6| Step: 8
Training loss: 1.8831658249464427
Validation loss: 2.9391147828576787

Epoch: 6| Step: 9
Training loss: 1.8911430973112682
Validation loss: 2.888232847961603

Epoch: 6| Step: 10
Training loss: 1.1061650432141577
Validation loss: 2.7288524407965253

Epoch: 6| Step: 11
Training loss: 1.4793365094456066
Validation loss: 2.7239356152454492

Epoch: 6| Step: 12
Training loss: 1.1060132414489054
Validation loss: 2.7025019491766793

Epoch: 6| Step: 13
Training loss: 1.49497764927924
Validation loss: 2.653888924607367

Epoch: 432| Step: 0
Training loss: 1.7635903577247238
Validation loss: 2.746353954650612

Epoch: 6| Step: 1
Training loss: 1.092905099690976
Validation loss: 2.7270369822791363

Epoch: 6| Step: 2
Training loss: 1.2222690151871027
Validation loss: 2.7544316793839045

Epoch: 6| Step: 3
Training loss: 1.648406909821507
Validation loss: 2.788174798710706

Epoch: 6| Step: 4
Training loss: 1.6610306176309693
Validation loss: 2.772129004479848

Epoch: 6| Step: 5
Training loss: 1.4045615762485082
Validation loss: 2.791599761578696

Epoch: 6| Step: 6
Training loss: 0.956278664651721
Validation loss: 2.8469259810951377

Epoch: 6| Step: 7
Training loss: 1.1000001798976404
Validation loss: 2.8138230073084074

Epoch: 6| Step: 8
Training loss: 1.3054484814954381
Validation loss: 2.7912785037234302

Epoch: 6| Step: 9
Training loss: 1.3279596562404654
Validation loss: 2.7873146713983656

Epoch: 6| Step: 10
Training loss: 1.7350173310615264
Validation loss: 2.7799572887158446

Epoch: 6| Step: 11
Training loss: 1.3411688299583933
Validation loss: 2.782452255598003

Epoch: 6| Step: 12
Training loss: 1.1708222810669318
Validation loss: 2.708112918003064

Epoch: 6| Step: 13
Training loss: 1.7501474045934462
Validation loss: 2.7063846522332913

Epoch: 433| Step: 0
Training loss: 1.8262239662941506
Validation loss: 2.667176083743501

Epoch: 6| Step: 1
Training loss: 1.0467452922575784
Validation loss: 2.7179970703520904

Epoch: 6| Step: 2
Training loss: 0.9072490972670528
Validation loss: 2.6993221809676253

Epoch: 6| Step: 3
Training loss: 1.189601243792296
Validation loss: 2.6825352431628082

Epoch: 6| Step: 4
Training loss: 1.4994201334067294
Validation loss: 2.70459433956568

Epoch: 6| Step: 5
Training loss: 1.5858730058757482
Validation loss: 2.6676669380603815

Epoch: 6| Step: 6
Training loss: 1.1666088544054714
Validation loss: 2.713467094778111

Epoch: 6| Step: 7
Training loss: 1.0918834563235187
Validation loss: 2.7240697036839885

Epoch: 6| Step: 8
Training loss: 0.9988567254212746
Validation loss: 2.7089707920400428

Epoch: 6| Step: 9
Training loss: 1.0059636034249502
Validation loss: 2.732483142150457

Epoch: 6| Step: 10
Training loss: 0.8561612466075336
Validation loss: 2.7003106845078078

Epoch: 6| Step: 11
Training loss: 2.0612706074977116
Validation loss: 2.7191750059039874

Epoch: 6| Step: 12
Training loss: 1.014964079385688
Validation loss: 2.6927191600667983

Epoch: 6| Step: 13
Training loss: 1.9798929856020084
Validation loss: 2.792301672743207

Epoch: 434| Step: 0
Training loss: 1.8698118274278333
Validation loss: 2.744481198862256

Epoch: 6| Step: 1
Training loss: 1.1725044086105005
Validation loss: 2.782456982632252

Epoch: 6| Step: 2
Training loss: 1.1493335264604794
Validation loss: 2.729243791863921

Epoch: 6| Step: 3
Training loss: 1.6085945385064393
Validation loss: 2.777649295272657

Epoch: 6| Step: 4
Training loss: 1.3375568948213588
Validation loss: 2.8236847333498596

Epoch: 6| Step: 5
Training loss: 1.7105189120561008
Validation loss: 2.7341789683962716

Epoch: 6| Step: 6
Training loss: 1.3823540568794837
Validation loss: 2.763164941958792

Epoch: 6| Step: 7
Training loss: 0.9152426315111036
Validation loss: 2.6719624391640706

Epoch: 6| Step: 8
Training loss: 1.280137905276687
Validation loss: 2.7308701205188837

Epoch: 6| Step: 9
Training loss: 1.0561097904121033
Validation loss: 2.7508746114609712

Epoch: 6| Step: 10
Training loss: 1.011746380402896
Validation loss: 2.6974057974406986

Epoch: 6| Step: 11
Training loss: 1.1518105000461936
Validation loss: 2.7139571464264427

Epoch: 6| Step: 12
Training loss: 0.998973170234251
Validation loss: 2.709491662986362

Epoch: 6| Step: 13
Training loss: 1.8196146531929507
Validation loss: 2.7693615903122932

Epoch: 435| Step: 0
Training loss: 0.9184816266933723
Validation loss: 2.7510426307646685

Epoch: 6| Step: 1
Training loss: 0.9691636217703073
Validation loss: 2.7136763736337413

Epoch: 6| Step: 2
Training loss: 1.149193547307669
Validation loss: 2.7206656039668298

Epoch: 6| Step: 3
Training loss: 1.1811596104184283
Validation loss: 2.75680612963945

Epoch: 6| Step: 4
Training loss: 0.9754510887511046
Validation loss: 2.7515310013813217

Epoch: 6| Step: 5
Training loss: 1.1853080395816522
Validation loss: 2.790126551261254

Epoch: 6| Step: 6
Training loss: 1.2647906249248395
Validation loss: 2.790543391909417

Epoch: 6| Step: 7
Training loss: 1.2584788766693986
Validation loss: 2.836740623508156

Epoch: 6| Step: 8
Training loss: 1.1813205758461505
Validation loss: 2.7957240743271026

Epoch: 6| Step: 9
Training loss: 1.1994596854364488
Validation loss: 2.8249231623437225

Epoch: 6| Step: 10
Training loss: 1.454628525469642
Validation loss: 2.8056594595432642

Epoch: 6| Step: 11
Training loss: 1.6581487028898783
Validation loss: 2.8406370682384825

Epoch: 6| Step: 12
Training loss: 1.0866514644456542
Validation loss: 2.830028069270459

Epoch: 6| Step: 13
Training loss: 1.9051699470948078
Validation loss: 2.7536004440023354

Epoch: 436| Step: 0
Training loss: 1.1750657448738777
Validation loss: 2.8134194319403085

Epoch: 6| Step: 1
Training loss: 1.2100960545994341
Validation loss: 2.7247293571205646

Epoch: 6| Step: 2
Training loss: 0.9132006241686406
Validation loss: 2.765483198823058

Epoch: 6| Step: 3
Training loss: 1.3987662499023361
Validation loss: 2.679091369634731

Epoch: 6| Step: 4
Training loss: 1.2532935145745476
Validation loss: 2.660166258193285

Epoch: 6| Step: 5
Training loss: 0.6729897854017068
Validation loss: 2.7194484383572464

Epoch: 6| Step: 6
Training loss: 1.0085409917410868
Validation loss: 2.734679766428146

Epoch: 6| Step: 7
Training loss: 1.5309542934838298
Validation loss: 2.697169407834802

Epoch: 6| Step: 8
Training loss: 1.4397309447966837
Validation loss: 2.6983335950999363

Epoch: 6| Step: 9
Training loss: 1.8457544067363274
Validation loss: 2.803566059411704

Epoch: 6| Step: 10
Training loss: 1.1576702056220702
Validation loss: 2.7846033119018854

Epoch: 6| Step: 11
Training loss: 1.1771169787074178
Validation loss: 2.850958327298474

Epoch: 6| Step: 12
Training loss: 1.4389988092996788
Validation loss: 2.7799330747447892

Epoch: 6| Step: 13
Training loss: 1.3693298557349387
Validation loss: 2.7746851733902864

Epoch: 437| Step: 0
Training loss: 1.3608101032950628
Validation loss: 2.8147619476417156

Epoch: 6| Step: 1
Training loss: 1.3646774356611564
Validation loss: 2.7986837466531873

Epoch: 6| Step: 2
Training loss: 1.876545459882758
Validation loss: 2.795383119410736

Epoch: 6| Step: 3
Training loss: 0.9926677052422191
Validation loss: 2.748863332093881

Epoch: 6| Step: 4
Training loss: 1.0390849863931988
Validation loss: 2.7256569219275626

Epoch: 6| Step: 5
Training loss: 1.1775775760762484
Validation loss: 2.769756098176117

Epoch: 6| Step: 6
Training loss: 1.4992836195213821
Validation loss: 2.7448278252224414

Epoch: 6| Step: 7
Training loss: 1.7840824695778514
Validation loss: 2.815069931814892

Epoch: 6| Step: 8
Training loss: 1.35632842228312
Validation loss: 2.8381064871743087

Epoch: 6| Step: 9
Training loss: 1.2817780871795084
Validation loss: 2.7732884469969554

Epoch: 6| Step: 10
Training loss: 1.3615770591253369
Validation loss: 2.8537805579174798

Epoch: 6| Step: 11
Training loss: 0.9925790149455038
Validation loss: 2.7374069116752597

Epoch: 6| Step: 12
Training loss: 0.9989549421319823
Validation loss: 2.7636943910577934

Epoch: 6| Step: 13
Training loss: 0.8596502730179708
Validation loss: 2.752302751787113

Epoch: 438| Step: 0
Training loss: 0.7138858902303782
Validation loss: 2.792113785499136

Epoch: 6| Step: 1
Training loss: 1.8278882778175642
Validation loss: 2.7922958310314483

Epoch: 6| Step: 2
Training loss: 1.1553401460195416
Validation loss: 2.762408784076723

Epoch: 6| Step: 3
Training loss: 1.5660729565001679
Validation loss: 2.7060589753025996

Epoch: 6| Step: 4
Training loss: 0.8342891377478642
Validation loss: 2.7139048171663265

Epoch: 6| Step: 5
Training loss: 1.2060127776119056
Validation loss: 2.7430172468211786

Epoch: 6| Step: 6
Training loss: 0.8363623920745226
Validation loss: 2.708792491040316

Epoch: 6| Step: 7
Training loss: 1.4040696088864364
Validation loss: 2.7027256988608137

Epoch: 6| Step: 8
Training loss: 1.462848657635045
Validation loss: 2.7884883200542365

Epoch: 6| Step: 9
Training loss: 1.6989131258016097
Validation loss: 2.7279410971363354

Epoch: 6| Step: 10
Training loss: 1.0839921830729486
Validation loss: 2.820457602701786

Epoch: 6| Step: 11
Training loss: 1.3785271920561746
Validation loss: 2.7533640081930604

Epoch: 6| Step: 12
Training loss: 1.3193269019166909
Validation loss: 2.77217283114653

Epoch: 6| Step: 13
Training loss: 0.9713562393507266
Validation loss: 2.737488636010677

Epoch: 439| Step: 0
Training loss: 1.3408389829931888
Validation loss: 2.796445305633911

Epoch: 6| Step: 1
Training loss: 1.271470967821259
Validation loss: 2.878531111935562

Epoch: 6| Step: 2
Training loss: 1.8169424270595096
Validation loss: 2.849373507657239

Epoch: 6| Step: 3
Training loss: 1.3700413591170244
Validation loss: 2.8937867614739967

Epoch: 6| Step: 4
Training loss: 1.374262828889855
Validation loss: 2.890963629055842

Epoch: 6| Step: 5
Training loss: 1.649049618142803
Validation loss: 2.9236370900002386

Epoch: 6| Step: 6
Training loss: 1.0690351228573305
Validation loss: 2.8093251287201415

Epoch: 6| Step: 7
Training loss: 1.1841165628018882
Validation loss: 2.7914657283225406

Epoch: 6| Step: 8
Training loss: 0.9683922137700983
Validation loss: 2.7592714105201503

Epoch: 6| Step: 9
Training loss: 1.7106263038817047
Validation loss: 2.769466297157396

Epoch: 6| Step: 10
Training loss: 1.4006268290108175
Validation loss: 2.7532202405040263

Epoch: 6| Step: 11
Training loss: 0.890476749864164
Validation loss: 2.7919848009340686

Epoch: 6| Step: 12
Training loss: 1.2144739501973716
Validation loss: 2.7026904938449983

Epoch: 6| Step: 13
Training loss: 1.5714462514601089
Validation loss: 2.7251113192251033

Epoch: 440| Step: 0
Training loss: 1.0504573620654563
Validation loss: 2.7809058558680575

Epoch: 6| Step: 1
Training loss: 1.2793570234995295
Validation loss: 2.7556505960008404

Epoch: 6| Step: 2
Training loss: 1.945195267296944
Validation loss: 2.7263786596424913

Epoch: 6| Step: 3
Training loss: 1.158446879733537
Validation loss: 2.8253641650571537

Epoch: 6| Step: 4
Training loss: 0.9256226608998933
Validation loss: 2.788523218499768

Epoch: 6| Step: 5
Training loss: 1.1580744602726927
Validation loss: 2.780910928466866

Epoch: 6| Step: 6
Training loss: 1.3824779299721375
Validation loss: 2.801526143053896

Epoch: 6| Step: 7
Training loss: 1.3502051091676812
Validation loss: 2.780602097500216

Epoch: 6| Step: 8
Training loss: 1.074231511820501
Validation loss: 2.715585730721989

Epoch: 6| Step: 9
Training loss: 1.0228010921617152
Validation loss: 2.7969878474082797

Epoch: 6| Step: 10
Training loss: 1.295567508347563
Validation loss: 2.860219195042395

Epoch: 6| Step: 11
Training loss: 1.4564567026289146
Validation loss: 2.729448075867838

Epoch: 6| Step: 12
Training loss: 1.1389524660482093
Validation loss: 2.7559420588773893

Epoch: 6| Step: 13
Training loss: 1.124035739914213
Validation loss: 2.736573096924174

Epoch: 441| Step: 0
Training loss: 1.0347702746288634
Validation loss: 2.697796378283224

Epoch: 6| Step: 1
Training loss: 2.097089921877909
Validation loss: 2.722721327118416

Epoch: 6| Step: 2
Training loss: 0.934291339560898
Validation loss: 2.7330840923679967

Epoch: 6| Step: 3
Training loss: 1.2548799151079149
Validation loss: 2.73502926219789

Epoch: 6| Step: 4
Training loss: 1.3039015727019259
Validation loss: 2.663933818912477

Epoch: 6| Step: 5
Training loss: 0.9280415879603227
Validation loss: 2.6443897474288396

Epoch: 6| Step: 6
Training loss: 1.4449857600213327
Validation loss: 2.7225873766032076

Epoch: 6| Step: 7
Training loss: 1.4316768459510336
Validation loss: 2.667578501572617

Epoch: 6| Step: 8
Training loss: 1.5446172093121397
Validation loss: 2.728951079223071

Epoch: 6| Step: 9
Training loss: 1.4406693391741305
Validation loss: 2.7643762272806107

Epoch: 6| Step: 10
Training loss: 1.0433498072212295
Validation loss: 2.736406425464887

Epoch: 6| Step: 11
Training loss: 1.0385946496873806
Validation loss: 2.7939453125

Epoch: 6| Step: 12
Training loss: 0.9518524805462162
Validation loss: 2.810606014998259

Epoch: 6| Step: 13
Training loss: 0.7971907719298613
Validation loss: 2.781655928459796

Epoch: 442| Step: 0
Training loss: 1.6938587055302272
Validation loss: 2.8007268541233135

Epoch: 6| Step: 1
Training loss: 1.1505345511953402
Validation loss: 2.8058999078970364

Epoch: 6| Step: 2
Training loss: 1.3111961791536195
Validation loss: 2.814203622327016

Epoch: 6| Step: 3
Training loss: 1.0184531522416003
Validation loss: 2.842372413898803

Epoch: 6| Step: 4
Training loss: 1.1728907950999634
Validation loss: 2.7998759474975903

Epoch: 6| Step: 5
Training loss: 1.4428839823345678
Validation loss: 2.8611599018870764

Epoch: 6| Step: 6
Training loss: 1.411014496486173
Validation loss: 2.8142391196712095

Epoch: 6| Step: 7
Training loss: 1.0061953085495596
Validation loss: 2.828312005311227

Epoch: 6| Step: 8
Training loss: 1.3303628356314383
Validation loss: 2.7839683364185652

Epoch: 6| Step: 9
Training loss: 1.8320848013853406
Validation loss: 2.8140756361402532

Epoch: 6| Step: 10
Training loss: 0.9821158021445442
Validation loss: 2.824674591520007

Epoch: 6| Step: 11
Training loss: 0.8452938930980889
Validation loss: 2.7715794961640237

Epoch: 6| Step: 12
Training loss: 1.049649220864848
Validation loss: 2.7737165713605916

Epoch: 6| Step: 13
Training loss: 1.2765401009470352
Validation loss: 2.712017888412444

Epoch: 443| Step: 0
Training loss: 1.357217194199189
Validation loss: 2.8179442870415476

Epoch: 6| Step: 1
Training loss: 1.287119470304918
Validation loss: 2.7446466995166507

Epoch: 6| Step: 2
Training loss: 1.0516990425599526
Validation loss: 2.7912486650663317

Epoch: 6| Step: 3
Training loss: 1.3700339196175801
Validation loss: 2.8431502188302527

Epoch: 6| Step: 4
Training loss: 1.2338293777021785
Validation loss: 2.834646626515872

Epoch: 6| Step: 5
Training loss: 1.3905979968245974
Validation loss: 2.874493692569533

Epoch: 6| Step: 6
Training loss: 1.1368520861681568
Validation loss: 2.8632688292216173

Epoch: 6| Step: 7
Training loss: 1.27125282347299
Validation loss: 2.899616738457837

Epoch: 6| Step: 8
Training loss: 0.9557199954113437
Validation loss: 2.8289636313423476

Epoch: 6| Step: 9
Training loss: 1.7972464136142794
Validation loss: 2.814804432898146

Epoch: 6| Step: 10
Training loss: 1.236724548904598
Validation loss: 2.78030122154189

Epoch: 6| Step: 11
Training loss: 1.206481610925936
Validation loss: 2.876811935437457

Epoch: 6| Step: 12
Training loss: 1.2200173855152527
Validation loss: 2.7902644654631503

Epoch: 6| Step: 13
Training loss: 1.443867223695401
Validation loss: 2.803991516523094

Epoch: 444| Step: 0
Training loss: 0.9542658809792504
Validation loss: 2.8079437083681755

Epoch: 6| Step: 1
Training loss: 1.1816640299851486
Validation loss: 2.7514057323443697

Epoch: 6| Step: 2
Training loss: 0.9000588424308444
Validation loss: 2.780260245699773

Epoch: 6| Step: 3
Training loss: 1.2649618224463157
Validation loss: 2.690646348042261

Epoch: 6| Step: 4
Training loss: 1.0527504546400694
Validation loss: 2.7253219055636357

Epoch: 6| Step: 5
Training loss: 0.8442506364543799
Validation loss: 2.7303127740888447

Epoch: 6| Step: 6
Training loss: 1.8929757880482685
Validation loss: 2.707548472803312

Epoch: 6| Step: 7
Training loss: 1.6013782674380759
Validation loss: 2.7610543624074464

Epoch: 6| Step: 8
Training loss: 0.8312166192945906
Validation loss: 2.7851978243613558

Epoch: 6| Step: 9
Training loss: 1.2712608879320766
Validation loss: 2.8294953315931384

Epoch: 6| Step: 10
Training loss: 1.1363528996740653
Validation loss: 2.819953169963673

Epoch: 6| Step: 11
Training loss: 1.4034156209479962
Validation loss: 2.883098798283111

Epoch: 6| Step: 12
Training loss: 1.291987758637534
Validation loss: 2.8847539441339904

Epoch: 6| Step: 13
Training loss: 1.4982496221380524
Validation loss: 2.8274673203014102

Epoch: 445| Step: 0
Training loss: 0.9462285923016489
Validation loss: 2.841280734982216

Epoch: 6| Step: 1
Training loss: 0.9546256212325134
Validation loss: 2.8546167608139617

Epoch: 6| Step: 2
Training loss: 1.23677071939898
Validation loss: 2.828534428587072

Epoch: 6| Step: 3
Training loss: 1.1774519396650325
Validation loss: 2.834992446575385

Epoch: 6| Step: 4
Training loss: 1.3076488670517203
Validation loss: 2.7925454412466797

Epoch: 6| Step: 5
Training loss: 1.2457017431433912
Validation loss: 2.6895101850999614

Epoch: 6| Step: 6
Training loss: 1.9890874940510985
Validation loss: 2.7560428059985753

Epoch: 6| Step: 7
Training loss: 1.3801542691372355
Validation loss: 2.7628412407056606

Epoch: 6| Step: 8
Training loss: 1.2680976167582887
Validation loss: 2.7412837786317605

Epoch: 6| Step: 9
Training loss: 1.5271187931261574
Validation loss: 2.731777534197846

Epoch: 6| Step: 10
Training loss: 0.8001089856297691
Validation loss: 2.677750134578214

Epoch: 6| Step: 11
Training loss: 1.2302412519107104
Validation loss: 2.7724232569748843

Epoch: 6| Step: 12
Training loss: 1.1309355873161304
Validation loss: 2.768643529723494

Epoch: 6| Step: 13
Training loss: 1.4075698592633565
Validation loss: 2.779586859073575

Epoch: 446| Step: 0
Training loss: 1.1688360355961889
Validation loss: 2.7612336491241263

Epoch: 6| Step: 1
Training loss: 1.2538026190504794
Validation loss: 2.724842888272169

Epoch: 6| Step: 2
Training loss: 1.3307244835140988
Validation loss: 2.735824382483436

Epoch: 6| Step: 3
Training loss: 1.0630265221575155
Validation loss: 2.7526679679720942

Epoch: 6| Step: 4
Training loss: 1.410062242581547
Validation loss: 2.8127157905588445

Epoch: 6| Step: 5
Training loss: 1.3562720389267502
Validation loss: 2.7542123322348893

Epoch: 6| Step: 6
Training loss: 2.113565986334202
Validation loss: 2.7993132052649186

Epoch: 6| Step: 7
Training loss: 1.069591641445212
Validation loss: 2.9002051708386056

Epoch: 6| Step: 8
Training loss: 1.4187463567073608
Validation loss: 2.898765840123851

Epoch: 6| Step: 9
Training loss: 1.408302758616686
Validation loss: 2.9120052326700336

Epoch: 6| Step: 10
Training loss: 1.6273819998111465
Validation loss: 2.8887607783456666

Epoch: 6| Step: 11
Training loss: 1.4315876658221396
Validation loss: 2.8166442996233636

Epoch: 6| Step: 12
Training loss: 1.0877899178098207
Validation loss: 2.73349910694715

Epoch: 6| Step: 13
Training loss: 1.3608016497039663
Validation loss: 2.7581259717722744

Epoch: 447| Step: 0
Training loss: 1.223322580136082
Validation loss: 2.822246490730444

Epoch: 6| Step: 1
Training loss: 1.1290482164498843
Validation loss: 2.8515238302038757

Epoch: 6| Step: 2
Training loss: 0.9491333157745169
Validation loss: 2.866862889345984

Epoch: 6| Step: 3
Training loss: 1.1038670343235402
Validation loss: 2.8516546225799733

Epoch: 6| Step: 4
Training loss: 1.9451415205122111
Validation loss: 2.901382485624042

Epoch: 6| Step: 5
Training loss: 1.006133462543043
Validation loss: 2.8194557924673864

Epoch: 6| Step: 6
Training loss: 1.3209614259399898
Validation loss: 2.790776357501058

Epoch: 6| Step: 7
Training loss: 0.8317016521834191
Validation loss: 2.7993811349190465

Epoch: 6| Step: 8
Training loss: 1.3093612925101041
Validation loss: 2.774286102706278

Epoch: 6| Step: 9
Training loss: 1.7401786820975687
Validation loss: 2.904337304865807

Epoch: 6| Step: 10
Training loss: 1.363200931314477
Validation loss: 2.953969091382408

Epoch: 6| Step: 11
Training loss: 1.9391240112483152
Validation loss: 2.810215785371844

Epoch: 6| Step: 12
Training loss: 0.7277566264462494
Validation loss: 2.833173401376566

Epoch: 6| Step: 13
Training loss: 1.561402660324901
Validation loss: 2.7397667904384084

Epoch: 448| Step: 0
Training loss: 1.1220752526714846
Validation loss: 2.792778296746201

Epoch: 6| Step: 1
Training loss: 1.077277251052284
Validation loss: 2.8220831753760627

Epoch: 6| Step: 2
Training loss: 1.718140511385496
Validation loss: 2.788423367027393

Epoch: 6| Step: 3
Training loss: 1.065725255819873
Validation loss: 2.8011828870108686

Epoch: 6| Step: 4
Training loss: 1.1498998556899835
Validation loss: 2.805926744269303

Epoch: 6| Step: 5
Training loss: 1.2290572532621353
Validation loss: 2.8863104435564177

Epoch: 6| Step: 6
Training loss: 1.0040579952040392
Validation loss: 2.950311400255019

Epoch: 6| Step: 7
Training loss: 1.4774611226242018
Validation loss: 2.8734150816343837

Epoch: 6| Step: 8
Training loss: 1.0539896599047047
Validation loss: 2.8693733856677452

Epoch: 6| Step: 9
Training loss: 1.3084612878969897
Validation loss: 2.830891936441145

Epoch: 6| Step: 10
Training loss: 1.0994506504559838
Validation loss: 2.804331864077033

Epoch: 6| Step: 11
Training loss: 1.8167140248743192
Validation loss: 2.8924328073990937

Epoch: 6| Step: 12
Training loss: 1.034194557147881
Validation loss: 2.7962205288044064

Epoch: 6| Step: 13
Training loss: 1.303745729360782
Validation loss: 2.7887985147302627

Epoch: 449| Step: 0
Training loss: 1.153006773473028
Validation loss: 2.774406242426721

Epoch: 6| Step: 1
Training loss: 1.8829655881827787
Validation loss: 2.761663210614777

Epoch: 6| Step: 2
Training loss: 1.4504502814055178
Validation loss: 2.7554402869693826

Epoch: 6| Step: 3
Training loss: 1.174607917624896
Validation loss: 2.7454080752108387

Epoch: 6| Step: 4
Training loss: 1.3939766088080283
Validation loss: 2.706512709766245

Epoch: 6| Step: 5
Training loss: 1.0310143866289116
Validation loss: 2.6795688599179934

Epoch: 6| Step: 6
Training loss: 1.0637532864619588
Validation loss: 2.761757166486033

Epoch: 6| Step: 7
Training loss: 1.4648391113207804
Validation loss: 2.6782203713717085

Epoch: 6| Step: 8
Training loss: 1.0975140245275816
Validation loss: 2.7130031136685764

Epoch: 6| Step: 9
Training loss: 0.7174190139256509
Validation loss: 2.7413616331522324

Epoch: 6| Step: 10
Training loss: 1.146255184315779
Validation loss: 2.731186990134762

Epoch: 6| Step: 11
Training loss: 0.8596632734051528
Validation loss: 2.7498466709047102

Epoch: 6| Step: 12
Training loss: 1.4838133703131005
Validation loss: 2.7588580547696893

Epoch: 6| Step: 13
Training loss: 1.1700298788053933
Validation loss: 2.7999237109758637

Epoch: 450| Step: 0
Training loss: 1.720997121681054
Validation loss: 2.8644821334071264

Epoch: 6| Step: 1
Training loss: 1.445098861163615
Validation loss: 2.8452339213185422

Epoch: 6| Step: 2
Training loss: 0.7888858333007607
Validation loss: 2.819881501379753

Epoch: 6| Step: 3
Training loss: 1.128466140861101
Validation loss: 2.833475268305664

Epoch: 6| Step: 4
Training loss: 1.6612671489992927
Validation loss: 2.8382918548315867

Epoch: 6| Step: 5
Training loss: 1.1188242200388134
Validation loss: 2.8260113596506784

Epoch: 6| Step: 6
Training loss: 1.4170890159833225
Validation loss: 2.8794973414464504

Epoch: 6| Step: 7
Training loss: 1.0017642908450228
Validation loss: 2.853937673548016

Epoch: 6| Step: 8
Training loss: 1.4440977198010931
Validation loss: 2.8327858105997983

Epoch: 6| Step: 9
Training loss: 1.1709635432502914
Validation loss: 2.8101953600785925

Epoch: 6| Step: 10
Training loss: 0.6381984904505403
Validation loss: 2.7747304705299065

Epoch: 6| Step: 11
Training loss: 1.0691758406124852
Validation loss: 2.800682587528477

Epoch: 6| Step: 12
Training loss: 0.9322702771224759
Validation loss: 2.7650950583224523

Epoch: 6| Step: 13
Training loss: 1.4773112018616783
Validation loss: 2.7843163406695064

Testing loss: 2.389599437753906
