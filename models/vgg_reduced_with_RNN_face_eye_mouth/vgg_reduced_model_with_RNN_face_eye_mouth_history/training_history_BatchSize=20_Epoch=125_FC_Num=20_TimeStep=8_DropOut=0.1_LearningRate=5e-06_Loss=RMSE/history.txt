Epoch: 1| Step: 0
Training loss: 5.614586239768593
Validation loss: 5.848650606325464

Epoch: 5| Step: 1
Training loss: 6.354667402038233
Validation loss: 5.846766055635044

Epoch: 5| Step: 2
Training loss: 6.327606858127754
Validation loss: 5.844629109397971

Epoch: 5| Step: 3
Training loss: 6.262807007838549
Validation loss: 5.842678617838365

Epoch: 5| Step: 4
Training loss: 5.096459726972953
Validation loss: 5.840570220499879

Epoch: 5| Step: 5
Training loss: 6.298668542067603
Validation loss: 5.838665455286586

Epoch: 5| Step: 6
Training loss: 5.920455077954576
Validation loss: 5.836583664752535

Epoch: 5| Step: 7
Training loss: 4.8180195255984435
Validation loss: 5.834599768448765

Epoch: 5| Step: 8
Training loss: 6.390972995376894
Validation loss: 5.832830825233234

Epoch: 5| Step: 9
Training loss: 5.5759016462542785
Validation loss: 5.830921133021035

Epoch: 5| Step: 10
Training loss: 6.315103730401617
Validation loss: 5.829048322231141

Epoch: 5| Step: 11
Training loss: 7.212898822514297
Validation loss: 5.8270661702163

Epoch: 2| Step: 0
Training loss: 4.901091956091066
Validation loss: 5.824975124737148

Epoch: 5| Step: 1
Training loss: 5.89345913408972
Validation loss: 5.822930974607228

Epoch: 5| Step: 2
Training loss: 6.207334228956942
Validation loss: 5.820783782926484

Epoch: 5| Step: 3
Training loss: 5.717075790727619
Validation loss: 5.818430592490672

Epoch: 5| Step: 4
Training loss: 6.360293010463832
Validation loss: 5.816129440029905

Epoch: 5| Step: 5
Training loss: 6.509728414141323
Validation loss: 5.8136379673011795

Epoch: 5| Step: 6
Training loss: 6.241106648738486
Validation loss: 5.811015100072961

Epoch: 5| Step: 7
Training loss: 5.594126939060924
Validation loss: 5.8081929372770436

Epoch: 5| Step: 8
Training loss: 5.873555756657334
Validation loss: 5.805277353320567

Epoch: 5| Step: 9
Training loss: 5.574183677129938
Validation loss: 5.80217743756761

Epoch: 5| Step: 10
Training loss: 6.251409142903115
Validation loss: 5.798844577812649

Epoch: 5| Step: 11
Training loss: 5.504593404918005
Validation loss: 5.7954545110021405

Epoch: 3| Step: 0
Training loss: 5.33031877119133
Validation loss: 5.7919514629497595

Epoch: 5| Step: 1
Training loss: 5.992008609414123
Validation loss: 5.788152914108653

Epoch: 5| Step: 2
Training loss: 5.626327697041134
Validation loss: 5.78413991781862

Epoch: 5| Step: 3
Training loss: 6.171536593273927
Validation loss: 5.78011785883127

Epoch: 5| Step: 4
Training loss: 6.311757261184962
Validation loss: 5.775825904643644

Epoch: 5| Step: 5
Training loss: 6.193480712702918
Validation loss: 5.770993015912381

Epoch: 5| Step: 6
Training loss: 5.82125719839564
Validation loss: 5.766186687674027

Epoch: 5| Step: 7
Training loss: 6.307024100876197
Validation loss: 5.761427622191213

Epoch: 5| Step: 8
Training loss: 6.004118459571105
Validation loss: 5.756227541702645

Epoch: 5| Step: 9
Training loss: 5.5203463741486525
Validation loss: 5.750542912214669

Epoch: 5| Step: 10
Training loss: 5.230448328936984
Validation loss: 5.745098139270755

Epoch: 5| Step: 11
Training loss: 6.42590383859129
Validation loss: 5.739377569074588

Epoch: 4| Step: 0
Training loss: 5.534267141453216
Validation loss: 5.733500782144068

Epoch: 5| Step: 1
Training loss: 4.960480340033354
Validation loss: 5.727523806292288

Epoch: 5| Step: 2
Training loss: 6.1624913213641666
Validation loss: 5.721109824041032

Epoch: 5| Step: 3
Training loss: 6.281685733390057
Validation loss: 5.714357895622313

Epoch: 5| Step: 4
Training loss: 5.686897665134387
Validation loss: 5.708098513467517

Epoch: 5| Step: 5
Training loss: 6.103195616610952
Validation loss: 5.701344132747866

Epoch: 5| Step: 6
Training loss: 6.382658602891467
Validation loss: 5.6942372783203865

Epoch: 5| Step: 7
Training loss: 6.165331962415902
Validation loss: 5.68721525296897

Epoch: 5| Step: 8
Training loss: 5.860108678024813
Validation loss: 5.680196495283998

Epoch: 5| Step: 9
Training loss: 5.088710046778608
Validation loss: 5.67261070195002

Epoch: 5| Step: 10
Training loss: 5.8071986808231975
Validation loss: 5.665257140707015

Epoch: 5| Step: 11
Training loss: 4.505669942444633
Validation loss: 5.657915105611835

Epoch: 5| Step: 0
Training loss: 6.394156900026633
Validation loss: 5.650827959886292

Epoch: 5| Step: 1
Training loss: 6.006564364110742
Validation loss: 5.643557475746629

Epoch: 5| Step: 2
Training loss: 5.958359226979721
Validation loss: 5.636161743192745

Epoch: 5| Step: 3
Training loss: 5.840688627742471
Validation loss: 5.628760408960441

Epoch: 5| Step: 4
Training loss: 6.4579209062701155
Validation loss: 5.621014553605233

Epoch: 5| Step: 5
Training loss: 6.037328315647408
Validation loss: 5.613064033696259

Epoch: 5| Step: 6
Training loss: 5.13690199144408
Validation loss: 5.605598460611798

Epoch: 5| Step: 7
Training loss: 6.398976434873198
Validation loss: 5.597699417405681

Epoch: 5| Step: 8
Training loss: 4.092266017631016
Validation loss: 5.589658686579841

Epoch: 5| Step: 9
Training loss: 4.434940083302194
Validation loss: 5.581706239365069

Epoch: 5| Step: 10
Training loss: 5.800305115139284
Validation loss: 5.574138880484723

Epoch: 5| Step: 11
Training loss: 5.466732328687369
Validation loss: 5.566539797603026

Epoch: 6| Step: 0
Training loss: 6.20754593671255
Validation loss: 5.55884950844268

Epoch: 5| Step: 1
Training loss: 4.73937402060417
Validation loss: 5.551345420692459

Epoch: 5| Step: 2
Training loss: 5.658331556511864
Validation loss: 5.543670129612791

Epoch: 5| Step: 3
Training loss: 6.072982063617472
Validation loss: 5.536376438151218

Epoch: 5| Step: 4
Training loss: 5.228722461005054
Validation loss: 5.5291211616734435

Epoch: 5| Step: 5
Training loss: 6.067689542509352
Validation loss: 5.521939604661398

Epoch: 5| Step: 6
Training loss: 5.353882936710514
Validation loss: 5.515129535383861

Epoch: 5| Step: 7
Training loss: 5.1664606894176455
Validation loss: 5.508205484569609

Epoch: 5| Step: 8
Training loss: 5.397776583943698
Validation loss: 5.50126889792521

Epoch: 5| Step: 9
Training loss: 6.034861061753449
Validation loss: 5.495163206824438

Epoch: 5| Step: 10
Training loss: 5.848884489205306
Validation loss: 5.48853173459247

Epoch: 5| Step: 11
Training loss: 6.124364703181721
Validation loss: 5.481900380492302

Epoch: 7| Step: 0
Training loss: 5.3820839265639595
Validation loss: 5.475463321538211

Epoch: 5| Step: 1
Training loss: 5.160523464353927
Validation loss: 5.469125375126329

Epoch: 5| Step: 2
Training loss: 5.4432654672111305
Validation loss: 5.463187195000868

Epoch: 5| Step: 3
Training loss: 5.0522972245180755
Validation loss: 5.457594736616403

Epoch: 5| Step: 4
Training loss: 6.024251247116019
Validation loss: 5.451780260889641

Epoch: 5| Step: 5
Training loss: 6.05499936192806
Validation loss: 5.446549868368309

Epoch: 5| Step: 6
Training loss: 5.451377260664128
Validation loss: 5.440813998570061

Epoch: 5| Step: 7
Training loss: 5.4953204968665155
Validation loss: 5.435769130829209

Epoch: 5| Step: 8
Training loss: 6.1173299916553985
Validation loss: 5.430476596493486

Epoch: 5| Step: 9
Training loss: 5.174626934960203
Validation loss: 5.425463768550704

Epoch: 5| Step: 10
Training loss: 5.806262535516945
Validation loss: 5.420756522398524

Epoch: 5| Step: 11
Training loss: 5.436395993459737
Validation loss: 5.415632195604595

Epoch: 8| Step: 0
Training loss: 5.274533487093406
Validation loss: 5.410920281290565

Epoch: 5| Step: 1
Training loss: 5.486525241764192
Validation loss: 5.406224847929847

Epoch: 5| Step: 2
Training loss: 5.792278266650398
Validation loss: 5.401683436945127

Epoch: 5| Step: 3
Training loss: 5.665369595947947
Validation loss: 5.397116521994752

Epoch: 5| Step: 4
Training loss: 6.053650364801209
Validation loss: 5.392352423572549

Epoch: 5| Step: 5
Training loss: 5.380682846469127
Validation loss: 5.3873623174671215

Epoch: 5| Step: 6
Training loss: 4.838052068549197
Validation loss: 5.382838267138725

Epoch: 5| Step: 7
Training loss: 5.132618893204604
Validation loss: 5.378184979148841

Epoch: 5| Step: 8
Training loss: 5.799674044690633
Validation loss: 5.373361981108871

Epoch: 5| Step: 9
Training loss: 5.489839011022396
Validation loss: 5.368713221277833

Epoch: 5| Step: 10
Training loss: 5.756256680065342
Validation loss: 5.364582308673452

Epoch: 5| Step: 11
Training loss: 4.654273516123717
Validation loss: 5.35966440500061

Epoch: 9| Step: 0
Training loss: 5.053570065216543
Validation loss: 5.355248637537154

Epoch: 5| Step: 1
Training loss: 5.204713870931954
Validation loss: 5.3504235533736395

Epoch: 5| Step: 2
Training loss: 6.31893049486042
Validation loss: 5.3461745192169055

Epoch: 5| Step: 3
Training loss: 5.635412962436928
Validation loss: 5.341283731030442

Epoch: 5| Step: 4
Training loss: 4.6264625505024
Validation loss: 5.3367566010146374

Epoch: 5| Step: 5
Training loss: 5.216759033522899
Validation loss: 5.332286138346

Epoch: 5| Step: 6
Training loss: 5.755973698283552
Validation loss: 5.327612567919476

Epoch: 5| Step: 7
Training loss: 5.446250101421741
Validation loss: 5.3229251072686665

Epoch: 5| Step: 8
Training loss: 5.717704635714364
Validation loss: 5.318522835231125

Epoch: 5| Step: 9
Training loss: 5.882957750530871
Validation loss: 5.314036023848771

Epoch: 5| Step: 10
Training loss: 5.013140957536685
Validation loss: 5.309114185054499

Epoch: 5| Step: 11
Training loss: 5.099152303817694
Validation loss: 5.304657948654628

Epoch: 10| Step: 0
Training loss: 5.171712175554845
Validation loss: 5.2996482003612435

Epoch: 5| Step: 1
Training loss: 5.332215827849209
Validation loss: 5.295298188806373

Epoch: 5| Step: 2
Training loss: 5.616776452656471
Validation loss: 5.290367975843392

Epoch: 5| Step: 3
Training loss: 5.815585722219256
Validation loss: 5.285321097987884

Epoch: 5| Step: 4
Training loss: 5.363043149815431
Validation loss: 5.280834572910145

Epoch: 5| Step: 5
Training loss: 5.379198430699126
Validation loss: 5.276074734804158

Epoch: 5| Step: 6
Training loss: 5.600761068943363
Validation loss: 5.27139948893992

Epoch: 5| Step: 7
Training loss: 5.577540604782546
Validation loss: 5.266760200965629

Epoch: 5| Step: 8
Training loss: 5.181654980780151
Validation loss: 5.262103509653084

Epoch: 5| Step: 9
Training loss: 4.668300115722958
Validation loss: 5.256825604335024

Epoch: 5| Step: 10
Training loss: 5.304806332949633
Validation loss: 5.252492108817984

Epoch: 5| Step: 11
Training loss: 6.746139552717991
Validation loss: 5.247830692065051

Epoch: 11| Step: 0
Training loss: 5.192673275241588
Validation loss: 5.243102045533786

Epoch: 5| Step: 1
Training loss: 5.5341311779625775
Validation loss: 5.238453535318518

Epoch: 5| Step: 2
Training loss: 5.0976592432941406
Validation loss: 5.234156939011569

Epoch: 5| Step: 3
Training loss: 5.192112170719635
Validation loss: 5.229407691213572

Epoch: 5| Step: 4
Training loss: 6.13032331550602
Validation loss: 5.224118028394959

Epoch: 5| Step: 5
Training loss: 5.583011655887911
Validation loss: 5.219741696608478

Epoch: 5| Step: 6
Training loss: 5.659577629046976
Validation loss: 5.215455422026451

Epoch: 5| Step: 7
Training loss: 4.787535083134244
Validation loss: 5.211093677199228

Epoch: 5| Step: 8
Training loss: 4.4268240579714
Validation loss: 5.206606749134083

Epoch: 5| Step: 9
Training loss: 5.449431209455882
Validation loss: 5.202506531701058

Epoch: 5| Step: 10
Training loss: 5.60654439674135
Validation loss: 5.198306688903122

Epoch: 5| Step: 11
Training loss: 4.971255840157082
Validation loss: 5.1936709456504

Epoch: 12| Step: 0
Training loss: 4.738408652257225
Validation loss: 5.189630576456847

Epoch: 5| Step: 1
Training loss: 4.955522312077512
Validation loss: 5.185391752194172

Epoch: 5| Step: 2
Training loss: 5.2568474574054065
Validation loss: 5.18146247044661

Epoch: 5| Step: 3
Training loss: 5.927468589593304
Validation loss: 5.177052413981141

Epoch: 5| Step: 4
Training loss: 5.5095797253511085
Validation loss: 5.172851170731945

Epoch: 5| Step: 5
Training loss: 5.561528324597282
Validation loss: 5.169132116139656

Epoch: 5| Step: 6
Training loss: 4.687221264499154
Validation loss: 5.164641993677948

Epoch: 5| Step: 7
Training loss: 5.601841194742865
Validation loss: 5.160492964257406

Epoch: 5| Step: 8
Training loss: 5.3938551803005135
Validation loss: 5.156359207075746

Epoch: 5| Step: 9
Training loss: 5.5356555355487895
Validation loss: 5.152395530133929

Epoch: 5| Step: 10
Training loss: 5.335137101961721
Validation loss: 5.148239239978959

Epoch: 5| Step: 11
Training loss: 2.5410356102992413
Validation loss: 5.143925172736161

Epoch: 13| Step: 0
Training loss: 5.867710867344599
Validation loss: 5.140217008314227

Epoch: 5| Step: 1
Training loss: 5.271506265295879
Validation loss: 5.136155439657417

Epoch: 5| Step: 2
Training loss: 5.961771935370809
Validation loss: 5.131766659323158

Epoch: 5| Step: 3
Training loss: 5.231718659002329
Validation loss: 5.1272726292433894

Epoch: 5| Step: 4
Training loss: 5.225363555379537
Validation loss: 5.123125663962978

Epoch: 5| Step: 5
Training loss: 5.410467366110896
Validation loss: 5.118212508416492

Epoch: 5| Step: 6
Training loss: 4.791728187940089
Validation loss: 5.113593355954863

Epoch: 5| Step: 7
Training loss: 3.865776405669103
Validation loss: 5.108644509081549

Epoch: 5| Step: 8
Training loss: 5.2484553653359605
Validation loss: 5.103910839390751

Epoch: 5| Step: 9
Training loss: 5.3359164102118
Validation loss: 5.099266972875591

Epoch: 5| Step: 10
Training loss: 4.975617467239403
Validation loss: 5.094138405624385

Epoch: 5| Step: 11
Training loss: 6.140342337045491
Validation loss: 5.089773494287306

Epoch: 14| Step: 0
Training loss: 5.429349381052769
Validation loss: 5.085107191588299

Epoch: 5| Step: 1
Training loss: 5.184768693081383
Validation loss: 5.0804962021368905

Epoch: 5| Step: 2
Training loss: 4.145454785622281
Validation loss: 5.075786674300506

Epoch: 5| Step: 3
Training loss: 5.847879022038374
Validation loss: 5.0714916862382795

Epoch: 5| Step: 4
Training loss: 6.1382250573148625
Validation loss: 5.066113552010136

Epoch: 5| Step: 5
Training loss: 4.80151004086062
Validation loss: 5.062312126598188

Epoch: 5| Step: 6
Training loss: 4.700450859359131
Validation loss: 5.057780455970073

Epoch: 5| Step: 7
Training loss: 5.1141021978723895
Validation loss: 5.053452173264059

Epoch: 5| Step: 8
Training loss: 5.153384620506701
Validation loss: 5.048421317755139

Epoch: 5| Step: 9
Training loss: 5.530670135620805
Validation loss: 5.044147270027116

Epoch: 5| Step: 10
Training loss: 4.769020546854287
Validation loss: 5.039306784531669

Epoch: 5| Step: 11
Training loss: 4.901869452280147
Validation loss: 5.034782985744437

Epoch: 15| Step: 0
Training loss: 5.576005634562247
Validation loss: 5.030752445678794

Epoch: 5| Step: 1
Training loss: 4.703943935332662
Validation loss: 5.026154443401249

Epoch: 5| Step: 2
Training loss: 4.934318579845865
Validation loss: 5.021659073522689

Epoch: 5| Step: 3
Training loss: 4.199092249184708
Validation loss: 5.017092283175604

Epoch: 5| Step: 4
Training loss: 5.484416733281386
Validation loss: 5.013259765743831

Epoch: 5| Step: 5
Training loss: 5.100742338420369
Validation loss: 5.009109170499421

Epoch: 5| Step: 6
Training loss: 5.2718139861985005
Validation loss: 5.004260695582781

Epoch: 5| Step: 7
Training loss: 5.770129256098175
Validation loss: 4.99979672018719

Epoch: 5| Step: 8
Training loss: 5.017216985349166
Validation loss: 4.995466378325469

Epoch: 5| Step: 9
Training loss: 4.878066834439619
Validation loss: 4.991539011083444

Epoch: 5| Step: 10
Training loss: 5.681368026934244
Validation loss: 4.9861268539439925

Epoch: 5| Step: 11
Training loss: 2.8673207098759796
Validation loss: 4.982475748023847

Epoch: 16| Step: 0
Training loss: 5.10793981898142
Validation loss: 4.978433022924392

Epoch: 5| Step: 1
Training loss: 5.363055063966864
Validation loss: 4.974366722184721

Epoch: 5| Step: 2
Training loss: 4.187663516367851
Validation loss: 4.9693079141368095

Epoch: 5| Step: 3
Training loss: 4.4561673663638235
Validation loss: 4.965665151546971

Epoch: 5| Step: 4
Training loss: 5.336924337392899
Validation loss: 4.961630040487297

Epoch: 5| Step: 5
Training loss: 5.626228198433186
Validation loss: 4.956914044120079

Epoch: 5| Step: 6
Training loss: 4.779066597052451
Validation loss: 4.952169227844822

Epoch: 5| Step: 7
Training loss: 5.48612804598012
Validation loss: 4.948230149895829

Epoch: 5| Step: 8
Training loss: 5.578891391624854
Validation loss: 4.943904593936531

Epoch: 5| Step: 9
Training loss: 5.074521520448901
Validation loss: 4.939372114183652

Epoch: 5| Step: 10
Training loss: 4.917416833233438
Validation loss: 4.934984918627357

Epoch: 5| Step: 11
Training loss: 3.8859274820736243
Validation loss: 4.930902644672721

Epoch: 17| Step: 0
Training loss: 4.900989020048279
Validation loss: 4.926746319246071

Epoch: 5| Step: 1
Training loss: 4.437744778611403
Validation loss: 4.922290949931276

Epoch: 5| Step: 2
Training loss: 3.953908850113685
Validation loss: 4.917357099945932

Epoch: 5| Step: 3
Training loss: 4.709319942484128
Validation loss: 4.912584940828763

Epoch: 5| Step: 4
Training loss: 6.016119602231938
Validation loss: 4.908732480700361

Epoch: 5| Step: 5
Training loss: 5.426326276677612
Validation loss: 4.904575280749578

Epoch: 5| Step: 6
Training loss: 4.334937067862026
Validation loss: 4.899336323264869

Epoch: 5| Step: 7
Training loss: 4.7265265849616895
Validation loss: 4.894619375918684

Epoch: 5| Step: 8
Training loss: 4.715369422008284
Validation loss: 4.889692670620674

Epoch: 5| Step: 9
Training loss: 5.829587696604482
Validation loss: 4.8849346950699

Epoch: 5| Step: 10
Training loss: 5.706653914095691
Validation loss: 4.880811365651385

Epoch: 5| Step: 11
Training loss: 5.565075396003904
Validation loss: 4.875908412415073

Epoch: 18| Step: 0
Training loss: 5.160255864327577
Validation loss: 4.87126847448085

Epoch: 5| Step: 1
Training loss: 5.257526089489717
Validation loss: 4.867071575909005

Epoch: 5| Step: 2
Training loss: 4.622640471812687
Validation loss: 4.861678661941483

Epoch: 5| Step: 3
Training loss: 5.474329777633261
Validation loss: 4.8568213275265215

Epoch: 5| Step: 4
Training loss: 5.610658291631571
Validation loss: 4.852257728418119

Epoch: 5| Step: 5
Training loss: 4.827146363069805
Validation loss: 4.847799769840392

Epoch: 5| Step: 6
Training loss: 5.005116324583018
Validation loss: 4.842735807828151

Epoch: 5| Step: 7
Training loss: 4.588639511237172
Validation loss: 4.837524621984626

Epoch: 5| Step: 8
Training loss: 4.401588950654904
Validation loss: 4.833240313566614

Epoch: 5| Step: 9
Training loss: 5.4389623670557805
Validation loss: 4.828886504956569

Epoch: 5| Step: 10
Training loss: 4.5487356671985175
Validation loss: 4.823734076859922

Epoch: 5| Step: 11
Training loss: 2.3289871155712887
Validation loss: 4.818966636950161

Epoch: 19| Step: 0
Training loss: 4.401632500289244
Validation loss: 4.814399476490729

Epoch: 5| Step: 1
Training loss: 5.26425886685261
Validation loss: 4.810482857459279

Epoch: 5| Step: 2
Training loss: 4.91809091575331
Validation loss: 4.8054598965369735

Epoch: 5| Step: 3
Training loss: 5.021964086989833
Validation loss: 4.80127019334867

Epoch: 5| Step: 4
Training loss: 5.236002836898373
Validation loss: 4.796992148295313

Epoch: 5| Step: 5
Training loss: 4.551716223025242
Validation loss: 4.791467093029524

Epoch: 5| Step: 6
Training loss: 4.994616853149561
Validation loss: 4.786615349065928

Epoch: 5| Step: 7
Training loss: 5.672852487115822
Validation loss: 4.781245487186072

Epoch: 5| Step: 8
Training loss: 4.1346203143750655
Validation loss: 4.775982866441803

Epoch: 5| Step: 9
Training loss: 4.437457447116615
Validation loss: 4.770590291502749

Epoch: 5| Step: 10
Training loss: 5.24778664571599
Validation loss: 4.7649693689499255

Epoch: 5| Step: 11
Training loss: 4.897362306615252
Validation loss: 4.759244522707419

Epoch: 20| Step: 0
Training loss: 4.932882926759585
Validation loss: 4.754326556517964

Epoch: 5| Step: 1
Training loss: 4.483856490194373
Validation loss: 4.749426999582818

Epoch: 5| Step: 2
Training loss: 4.973987242396628
Validation loss: 4.744762209798393

Epoch: 5| Step: 3
Training loss: 4.795105250439553
Validation loss: 4.739442767339938

Epoch: 5| Step: 4
Training loss: 4.975891355475333
Validation loss: 4.7337168875060724

Epoch: 5| Step: 5
Training loss: 4.559425049390094
Validation loss: 4.728280739279396

Epoch: 5| Step: 6
Training loss: 5.112138193474399
Validation loss: 4.723793504973422

Epoch: 5| Step: 7
Training loss: 4.96980399223062
Validation loss: 4.718083239810308

Epoch: 5| Step: 8
Training loss: 5.526180379446697
Validation loss: 4.713427432311108

Epoch: 5| Step: 9
Training loss: 4.471237024080998
Validation loss: 4.708612672852048

Epoch: 5| Step: 10
Training loss: 4.572068305892859
Validation loss: 4.703003443502087

Epoch: 5| Step: 11
Training loss: 4.581949660931741
Validation loss: 4.698033903002595

Epoch: 21| Step: 0
Training loss: 4.210491772560169
Validation loss: 4.692900280796696

Epoch: 5| Step: 1
Training loss: 4.849331500987505
Validation loss: 4.688169355285612

Epoch: 5| Step: 2
Training loss: 5.337877046726235
Validation loss: 4.683450687653153

Epoch: 5| Step: 3
Training loss: 4.298717200976893
Validation loss: 4.677955404540112

Epoch: 5| Step: 4
Training loss: 5.108243391148555
Validation loss: 4.6731912211107485

Epoch: 5| Step: 5
Training loss: 4.665780164894092
Validation loss: 4.667525836782488

Epoch: 5| Step: 6
Training loss: 4.923892428179875
Validation loss: 4.6632067706312155

Epoch: 5| Step: 7
Training loss: 5.093445002312006
Validation loss: 4.65812751927255

Epoch: 5| Step: 8
Training loss: 5.099289766111984
Validation loss: 4.653325897245468

Epoch: 5| Step: 9
Training loss: 4.688143876676873
Validation loss: 4.648172318617492

Epoch: 5| Step: 10
Training loss: 4.233418148923256
Validation loss: 4.642850352987977

Epoch: 5| Step: 11
Training loss: 5.22759461297661
Validation loss: 4.638272850676257

Epoch: 22| Step: 0
Training loss: 4.1815484868410575
Validation loss: 4.631964517473952

Epoch: 5| Step: 1
Training loss: 5.120823530783193
Validation loss: 4.627147433772869

Epoch: 5| Step: 2
Training loss: 5.377698176734514
Validation loss: 4.6223766516345695

Epoch: 5| Step: 3
Training loss: 4.853293977584845
Validation loss: 4.616894471174925

Epoch: 5| Step: 4
Training loss: 5.108996829348685
Validation loss: 4.611918636580334

Epoch: 5| Step: 5
Training loss: 5.004889195880075
Validation loss: 4.606320432644669

Epoch: 5| Step: 6
Training loss: 4.42201841950775
Validation loss: 4.600779217912671

Epoch: 5| Step: 7
Training loss: 4.219957419085705
Validation loss: 4.595978652556476

Epoch: 5| Step: 8
Training loss: 5.003091238028261
Validation loss: 4.590415090077212

Epoch: 5| Step: 9
Training loss: 4.42959750721527
Validation loss: 4.584859284779572

Epoch: 5| Step: 10
Training loss: 3.993187825688953
Validation loss: 4.579410541740639

Epoch: 5| Step: 11
Training loss: 5.392413298821107
Validation loss: 4.574135523038119

Epoch: 23| Step: 0
Training loss: 5.219304951839646
Validation loss: 4.568710846391795

Epoch: 5| Step: 1
Training loss: 4.496636299123134
Validation loss: 4.563588887747992

Epoch: 5| Step: 2
Training loss: 4.1625815901907695
Validation loss: 4.55819566607134

Epoch: 5| Step: 3
Training loss: 3.91763745444717
Validation loss: 4.5524552438495665

Epoch: 5| Step: 4
Training loss: 5.209530664783005
Validation loss: 4.547778989018817

Epoch: 5| Step: 5
Training loss: 4.86359146538221
Validation loss: 4.542417869504214

Epoch: 5| Step: 6
Training loss: 5.261586256277757
Validation loss: 4.536518953475283

Epoch: 5| Step: 7
Training loss: 4.7849549543119965
Validation loss: 4.530518865245103

Epoch: 5| Step: 8
Training loss: 3.8971877302216074
Validation loss: 4.525010621074204

Epoch: 5| Step: 9
Training loss: 4.3172276332451895
Validation loss: 4.520241785095175

Epoch: 5| Step: 10
Training loss: 4.887502630286717
Validation loss: 4.515239325116196

Epoch: 5| Step: 11
Training loss: 5.065122702073519
Validation loss: 4.509521186981018

Epoch: 24| Step: 0
Training loss: 4.1745471183337335
Validation loss: 4.50576958954747

Epoch: 5| Step: 1
Training loss: 4.43091750518379
Validation loss: 4.503568091246686

Epoch: 5| Step: 2
Training loss: 4.5792920184254085
Validation loss: 4.500468883104939

Epoch: 5| Step: 3
Training loss: 4.8531102462121805
Validation loss: 4.494068696132907

Epoch: 5| Step: 4
Training loss: 4.915251037768288
Validation loss: 4.486851339646685

Epoch: 5| Step: 5
Training loss: 4.065115688127625
Validation loss: 4.479722430622228

Epoch: 5| Step: 6
Training loss: 4.422565096327017
Validation loss: 4.474587067318539

Epoch: 5| Step: 7
Training loss: 5.650042251834031
Validation loss: 4.469498000421079

Epoch: 5| Step: 8
Training loss: 4.566912881566964
Validation loss: 4.46439197086856

Epoch: 5| Step: 9
Training loss: 4.074189958626098
Validation loss: 4.458327305275713

Epoch: 5| Step: 10
Training loss: 4.641453729992483
Validation loss: 4.452862295689352

Epoch: 5| Step: 11
Training loss: 5.106211018034151
Validation loss: 4.445789403200821

Epoch: 25| Step: 0
Training loss: 4.3923579695551735
Validation loss: 4.43971848439518

Epoch: 5| Step: 1
Training loss: 4.954562102059974
Validation loss: 4.434811525407758

Epoch: 5| Step: 2
Training loss: 4.726804213215136
Validation loss: 4.429892497670681

Epoch: 5| Step: 3
Training loss: 4.205771368265758
Validation loss: 4.424754127668774

Epoch: 5| Step: 4
Training loss: 4.676669209362452
Validation loss: 4.419054981086186

Epoch: 5| Step: 5
Training loss: 3.5530923135641292
Validation loss: 4.413407264171393

Epoch: 5| Step: 6
Training loss: 5.189091082238355
Validation loss: 4.407945888249463

Epoch: 5| Step: 7
Training loss: 4.361921981512592
Validation loss: 4.4024543060077415

Epoch: 5| Step: 8
Training loss: 4.527898561911794
Validation loss: 4.39671929035599

Epoch: 5| Step: 9
Training loss: 4.074555102442095
Validation loss: 4.3912609676010925

Epoch: 5| Step: 10
Training loss: 4.940207403053101
Validation loss: 4.385193493647146

Epoch: 5| Step: 11
Training loss: 5.106994821115964
Validation loss: 4.3799100525574906

Epoch: 26| Step: 0
Training loss: 4.851681423726119
Validation loss: 4.37378398253729

Epoch: 5| Step: 1
Training loss: 4.651063014113535
Validation loss: 4.367668093565644

Epoch: 5| Step: 2
Training loss: 3.7551447862529423
Validation loss: 4.363276568996249

Epoch: 5| Step: 3
Training loss: 4.586402674514946
Validation loss: 4.35641533525556

Epoch: 5| Step: 4
Training loss: 4.045326908891874
Validation loss: 4.351033953123384

Epoch: 5| Step: 5
Training loss: 4.228079419619892
Validation loss: 4.346095154185059

Epoch: 5| Step: 6
Training loss: 5.055683963435093
Validation loss: 4.3411814004150076

Epoch: 5| Step: 7
Training loss: 4.308878829530731
Validation loss: 4.336053909709449

Epoch: 5| Step: 8
Training loss: 4.622855436731287
Validation loss: 4.329974315352757

Epoch: 5| Step: 9
Training loss: 4.323563688950599
Validation loss: 4.3236867961691905

Epoch: 5| Step: 10
Training loss: 4.675636027924436
Validation loss: 4.3181852377188985

Epoch: 5| Step: 11
Training loss: 4.33779125280146
Validation loss: 4.312573966714223

Epoch: 27| Step: 0
Training loss: 4.4635752346893875
Validation loss: 4.307231144631725

Epoch: 5| Step: 1
Training loss: 4.50837479229736
Validation loss: 4.301467900749225

Epoch: 5| Step: 2
Training loss: 4.818289309001108
Validation loss: 4.297803715996665

Epoch: 5| Step: 3
Training loss: 4.359868284913203
Validation loss: 4.290166350335417

Epoch: 5| Step: 4
Training loss: 4.626240331994762
Validation loss: 4.284359093063137

Epoch: 5| Step: 5
Training loss: 4.09820105001127
Validation loss: 4.279020457507777

Epoch: 5| Step: 6
Training loss: 3.9150591588331185
Validation loss: 4.273690029681944

Epoch: 5| Step: 7
Training loss: 3.9867693718999146
Validation loss: 4.267606891968678

Epoch: 5| Step: 8
Training loss: 4.551864560571108
Validation loss: 4.262114406532961

Epoch: 5| Step: 9
Training loss: 4.669522002301785
Validation loss: 4.256186881323231

Epoch: 5| Step: 10
Training loss: 4.505696399983927
Validation loss: 4.2508772991733315

Epoch: 5| Step: 11
Training loss: 3.879534006942451
Validation loss: 4.245976305767173

Epoch: 28| Step: 0
Training loss: 4.043459124473027
Validation loss: 4.240845469715225

Epoch: 5| Step: 1
Training loss: 4.798801097553112
Validation loss: 4.234539765440351

Epoch: 5| Step: 2
Training loss: 4.136598868069335
Validation loss: 4.229968233049358

Epoch: 5| Step: 3
Training loss: 4.938162264290423
Validation loss: 4.224660176186143

Epoch: 5| Step: 4
Training loss: 4.561586471445501
Validation loss: 4.219909146093222

Epoch: 5| Step: 5
Training loss: 3.697179213943334
Validation loss: 4.2143079000478645

Epoch: 5| Step: 6
Training loss: 4.000390510570255
Validation loss: 4.207971324395064

Epoch: 5| Step: 7
Training loss: 3.927333483161809
Validation loss: 4.202403965097998

Epoch: 5| Step: 8
Training loss: 4.238264373886332
Validation loss: 4.196934661668402

Epoch: 5| Step: 9
Training loss: 4.492696345161678
Validation loss: 4.1918028791654365

Epoch: 5| Step: 10
Training loss: 4.755549752498267
Validation loss: 4.18615442928747

Epoch: 5| Step: 11
Training loss: 4.467476189736144
Validation loss: 4.181235923230206

Epoch: 29| Step: 0
Training loss: 3.8713611622050945
Validation loss: 4.176249364551997

Epoch: 5| Step: 1
Training loss: 4.350967448725417
Validation loss: 4.169918844682008

Epoch: 5| Step: 2
Training loss: 4.505446211280758
Validation loss: 4.164144862292656

Epoch: 5| Step: 3
Training loss: 3.9732661946489363
Validation loss: 4.15971064083898

Epoch: 5| Step: 4
Training loss: 3.7095408813099584
Validation loss: 4.154950849515509

Epoch: 5| Step: 5
Training loss: 4.635498914810463
Validation loss: 4.149731785559732

Epoch: 5| Step: 6
Training loss: 3.687600085953044
Validation loss: 4.144133112147866

Epoch: 5| Step: 7
Training loss: 4.52153499566696
Validation loss: 4.138241702171605

Epoch: 5| Step: 8
Training loss: 4.3181884400531425
Validation loss: 4.132364480746025

Epoch: 5| Step: 9
Training loss: 4.286576347843191
Validation loss: 4.12662629619001

Epoch: 5| Step: 10
Training loss: 5.037098015206268
Validation loss: 4.121878102465029

Epoch: 5| Step: 11
Training loss: 4.165495262787099
Validation loss: 4.116816934103014

Epoch: 30| Step: 0
Training loss: 4.749436395235512
Validation loss: 4.1098210101200765

Epoch: 5| Step: 1
Training loss: 3.394312808752981
Validation loss: 4.10457977726669

Epoch: 5| Step: 2
Training loss: 4.0881136465680425
Validation loss: 4.099502365802073

Epoch: 5| Step: 3
Training loss: 4.410966229455013
Validation loss: 4.093668002600807

Epoch: 5| Step: 4
Training loss: 4.514139637299567
Validation loss: 4.088321031906235

Epoch: 5| Step: 5
Training loss: 4.170060009421655
Validation loss: 4.082437464018421

Epoch: 5| Step: 6
Training loss: 3.7492519904203423
Validation loss: 4.07624974501616

Epoch: 5| Step: 7
Training loss: 4.372110120819161
Validation loss: 4.069824453078128

Epoch: 5| Step: 8
Training loss: 4.507057801114049
Validation loss: 4.065141234960989

Epoch: 5| Step: 9
Training loss: 4.264336583549982
Validation loss: 4.059124125930782

Epoch: 5| Step: 10
Training loss: 4.1366675700622935
Validation loss: 4.054154402050091

Epoch: 5| Step: 11
Training loss: 3.2840321689475163
Validation loss: 4.049082368829095

Epoch: 31| Step: 0
Training loss: 4.899827191166633
Validation loss: 4.0447546413055555

Epoch: 5| Step: 1
Training loss: 3.532061593293061
Validation loss: 4.038602432621632

Epoch: 5| Step: 2
Training loss: 4.386451339383945
Validation loss: 4.033209824575751

Epoch: 5| Step: 3
Training loss: 3.979063914838099
Validation loss: 4.027630681972948

Epoch: 5| Step: 4
Training loss: 3.358607856630354
Validation loss: 4.022635657151031

Epoch: 5| Step: 5
Training loss: 4.471065961480459
Validation loss: 4.016437166366206

Epoch: 5| Step: 6
Training loss: 4.776866024956712
Validation loss: 4.011849041896552

Epoch: 5| Step: 7
Training loss: 3.839894664034912
Validation loss: 4.005646882108775

Epoch: 5| Step: 8
Training loss: 3.47086771337022
Validation loss: 4.000467864132327

Epoch: 5| Step: 9
Training loss: 4.6339338466909314
Validation loss: 3.9947608124272134

Epoch: 5| Step: 10
Training loss: 4.038265304548709
Validation loss: 3.9887226843070454

Epoch: 5| Step: 11
Training loss: 3.6689498612977522
Validation loss: 3.9827684741494567

Epoch: 32| Step: 0
Training loss: 4.047682044663635
Validation loss: 3.9810781414840366

Epoch: 5| Step: 1
Training loss: 4.1409179583862725
Validation loss: 3.9730859684723416

Epoch: 5| Step: 2
Training loss: 4.097272914996732
Validation loss: 3.967829239534486

Epoch: 5| Step: 3
Training loss: 4.428650319148261
Validation loss: 3.9639779183728323

Epoch: 5| Step: 4
Training loss: 3.580537873678164
Validation loss: 3.9584852122565892

Epoch: 5| Step: 5
Training loss: 4.236720262654165
Validation loss: 3.952818792091187

Epoch: 5| Step: 6
Training loss: 4.261188813293664
Validation loss: 3.947347130202157

Epoch: 5| Step: 7
Training loss: 4.140155808838595
Validation loss: 3.9415841240469787

Epoch: 5| Step: 8
Training loss: 4.073879560650096
Validation loss: 3.935870120875235

Epoch: 5| Step: 9
Training loss: 3.6483316344885592
Validation loss: 3.928284619026211

Epoch: 5| Step: 10
Training loss: 4.190079762648725
Validation loss: 3.923839988709549

Epoch: 5| Step: 11
Training loss: 4.254109359390093
Validation loss: 3.9192839849342214

Epoch: 33| Step: 0
Training loss: 3.9573370767337472
Validation loss: 3.9145199019223003

Epoch: 5| Step: 1
Training loss: 4.383598162020481
Validation loss: 3.907172742576406

Epoch: 5| Step: 2
Training loss: 4.31122935276059
Validation loss: 3.9023584996257505

Epoch: 5| Step: 3
Training loss: 3.2881957155623773
Validation loss: 3.897616930103345

Epoch: 5| Step: 4
Training loss: 3.8393334547350726
Validation loss: 3.8939358923529386

Epoch: 5| Step: 5
Training loss: 4.288002425136165
Validation loss: 3.889780685752276

Epoch: 5| Step: 6
Training loss: 3.575585409397664
Validation loss: 3.8839057851748313

Epoch: 5| Step: 7
Training loss: 3.4339772987748445
Validation loss: 3.8769367976769704

Epoch: 5| Step: 8
Training loss: 4.343415830643074
Validation loss: 3.8701262485585137

Epoch: 5| Step: 9
Training loss: 4.3882837535599055
Validation loss: 3.8632448231336483

Epoch: 5| Step: 10
Training loss: 4.182996463257062
Validation loss: 3.8565479173789767

Epoch: 5| Step: 11
Training loss: 4.195810526407352
Validation loss: 3.850204052822707

Epoch: 34| Step: 0
Training loss: 4.52977860337088
Validation loss: 3.8451998077583007

Epoch: 5| Step: 1
Training loss: 3.7977155845980652
Validation loss: 3.8386913962214124

Epoch: 5| Step: 2
Training loss: 3.7737657866222003
Validation loss: 3.8328991709739513

Epoch: 5| Step: 3
Training loss: 4.440280741502106
Validation loss: 3.827104523291543

Epoch: 5| Step: 4
Training loss: 3.921161723531046
Validation loss: 3.8218472134320067

Epoch: 5| Step: 5
Training loss: 3.362672544682463
Validation loss: 3.815766535036356

Epoch: 5| Step: 6
Training loss: 4.191840583929582
Validation loss: 3.8106758099772846

Epoch: 5| Step: 7
Training loss: 4.28924971486332
Validation loss: 3.804288301406988

Epoch: 5| Step: 8
Training loss: 3.769490770508042
Validation loss: 3.799033264531315

Epoch: 5| Step: 9
Training loss: 3.8326317241847723
Validation loss: 3.792861329327718

Epoch: 5| Step: 10
Training loss: 3.4307115976638456
Validation loss: 3.7873841491455758

Epoch: 5| Step: 11
Training loss: 3.6969235801568217
Validation loss: 3.7820302457754926

Epoch: 35| Step: 0
Training loss: 3.768538744621628
Validation loss: 3.7760796836605452

Epoch: 5| Step: 1
Training loss: 4.3944895831358
Validation loss: 3.7709585119865263

Epoch: 5| Step: 2
Training loss: 3.8962684973093165
Validation loss: 3.7649967993933324

Epoch: 5| Step: 3
Training loss: 3.551103130393144
Validation loss: 3.75942930360441

Epoch: 5| Step: 4
Training loss: 4.040676716697021
Validation loss: 3.753999918636727

Epoch: 5| Step: 5
Training loss: 3.367939380507964
Validation loss: 3.748612486261247

Epoch: 5| Step: 6
Training loss: 3.4962649170301945
Validation loss: 3.743193107032503

Epoch: 5| Step: 7
Training loss: 3.747488579608599
Validation loss: 3.737322358467663

Epoch: 5| Step: 8
Training loss: 3.9771176533378054
Validation loss: 3.732033478287225

Epoch: 5| Step: 9
Training loss: 4.409141295340882
Validation loss: 3.726670978707996

Epoch: 5| Step: 10
Training loss: 3.9789047687616894
Validation loss: 3.7209108469892653

Epoch: 5| Step: 11
Training loss: 3.637887342876083
Validation loss: 3.716121086282361

Epoch: 36| Step: 0
Training loss: 3.6178514435626
Validation loss: 3.71059727230103

Epoch: 5| Step: 1
Training loss: 3.531232580631469
Validation loss: 3.7056987097268883

Epoch: 5| Step: 2
Training loss: 4.51031435291752
Validation loss: 3.7001467611228973

Epoch: 5| Step: 3
Training loss: 4.025439902961354
Validation loss: 3.6954851600790475

Epoch: 5| Step: 4
Training loss: 3.9254932506689353
Validation loss: 3.689821627758747

Epoch: 5| Step: 5
Training loss: 3.743961558788568
Validation loss: 3.6841890535678954

Epoch: 5| Step: 6
Training loss: 3.1604593742232665
Validation loss: 3.678431194549446

Epoch: 5| Step: 7
Training loss: 3.426287310291712
Validation loss: 3.6739279128263544

Epoch: 5| Step: 8
Training loss: 4.503717158798936
Validation loss: 3.6681600080032735

Epoch: 5| Step: 9
Training loss: 3.531139810919105
Validation loss: 3.6637458311968483

Epoch: 5| Step: 10
Training loss: 4.040528494382389
Validation loss: 3.6576459453195937

Epoch: 5| Step: 11
Training loss: 2.435919224619747
Validation loss: 3.6526694195094085

Epoch: 37| Step: 0
Training loss: 3.8885157739182734
Validation loss: 3.647390543485222

Epoch: 5| Step: 1
Training loss: 3.772349830707547
Validation loss: 3.64219083934507

Epoch: 5| Step: 2
Training loss: 4.255746210562352
Validation loss: 3.637585502178929

Epoch: 5| Step: 3
Training loss: 3.5475936363287874
Validation loss: 3.632358415998788

Epoch: 5| Step: 4
Training loss: 3.81502099407614
Validation loss: 3.627339627528349

Epoch: 5| Step: 5
Training loss: 3.899366738184843
Validation loss: 3.6215542223070423

Epoch: 5| Step: 6
Training loss: 3.892846756167573
Validation loss: 3.616843919248596

Epoch: 5| Step: 7
Training loss: 3.0466090942162936
Validation loss: 3.6116445460182676

Epoch: 5| Step: 8
Training loss: 3.2319447698312014
Validation loss: 3.606709435923886

Epoch: 5| Step: 9
Training loss: 4.047644582502244
Validation loss: 3.602101658689365

Epoch: 5| Step: 10
Training loss: 3.510288647469009
Validation loss: 3.5969329780702686

Epoch: 5| Step: 11
Training loss: 4.947767760060603
Validation loss: 3.5921434819844644

Epoch: 38| Step: 0
Training loss: 3.228966064785163
Validation loss: 3.586590914455129

Epoch: 5| Step: 1
Training loss: 3.6837286332840478
Validation loss: 3.5820105415835557

Epoch: 5| Step: 2
Training loss: 2.8216798801492025
Validation loss: 3.576693902491184

Epoch: 5| Step: 3
Training loss: 3.7926587214792087
Validation loss: 3.5723528718383495

Epoch: 5| Step: 4
Training loss: 4.2200545942924235
Validation loss: 3.567827607919996

Epoch: 5| Step: 5
Training loss: 3.8865226964529547
Validation loss: 3.5621783462675864

Epoch: 5| Step: 6
Training loss: 4.155999886007004
Validation loss: 3.557739763908287

Epoch: 5| Step: 7
Training loss: 3.7744486778813737
Validation loss: 3.551958589050751

Epoch: 5| Step: 8
Training loss: 3.888647227877378
Validation loss: 3.5468558032262747

Epoch: 5| Step: 9
Training loss: 3.6444144112685666
Validation loss: 3.5417976841347683

Epoch: 5| Step: 10
Training loss: 3.476997811142038
Validation loss: 3.5373213795923544

Epoch: 5| Step: 11
Training loss: 3.1389764662896744
Validation loss: 3.5318176015909417

Epoch: 39| Step: 0
Training loss: 3.725182107659905
Validation loss: 3.527265545726891

Epoch: 5| Step: 1
Training loss: 3.4974028624432965
Validation loss: 3.522441579470997

Epoch: 5| Step: 2
Training loss: 3.370267729269526
Validation loss: 3.516951744372572

Epoch: 5| Step: 3
Training loss: 3.97869767758946
Validation loss: 3.511821271498149

Epoch: 5| Step: 4
Training loss: 3.4887096317133044
Validation loss: 3.5069871085732833

Epoch: 5| Step: 5
Training loss: 4.3826934743892485
Validation loss: 3.5022589058391675

Epoch: 5| Step: 6
Training loss: 3.811212290936693
Validation loss: 3.497122757003648

Epoch: 5| Step: 7
Training loss: 3.4515298464514
Validation loss: 3.4914382142113

Epoch: 5| Step: 8
Training loss: 3.0292971898170373
Validation loss: 3.4865419979369667

Epoch: 5| Step: 9
Training loss: 3.1683192876443926
Validation loss: 3.4817402775787745

Epoch: 5| Step: 10
Training loss: 3.748055780588039
Validation loss: 3.47624543419348

Epoch: 5| Step: 11
Training loss: 4.518358505405921
Validation loss: 3.471759739063296

Epoch: 40| Step: 0
Training loss: 3.782755276271989
Validation loss: 3.46724331985473

Epoch: 5| Step: 1
Training loss: 3.3138124277169503
Validation loss: 3.4617680284325396

Epoch: 5| Step: 2
Training loss: 4.104493465418847
Validation loss: 3.4558080430888065

Epoch: 5| Step: 3
Training loss: 3.792601892740825
Validation loss: 3.451759099880043

Epoch: 5| Step: 4
Training loss: 4.025206774974278
Validation loss: 3.4451141473326468

Epoch: 5| Step: 5
Training loss: 3.2665771848399054
Validation loss: 3.4405503466155873

Epoch: 5| Step: 6
Training loss: 3.4143046766758967
Validation loss: 3.4356070710750055

Epoch: 5| Step: 7
Training loss: 3.4878733226625944
Validation loss: 3.4310329871234178

Epoch: 5| Step: 8
Training loss: 3.129141237957303
Validation loss: 3.426135663584996

Epoch: 5| Step: 9
Training loss: 3.9953681831522503
Validation loss: 3.421437408244531

Epoch: 5| Step: 10
Training loss: 3.0814887706794005
Validation loss: 3.415751344299089

Epoch: 5| Step: 11
Training loss: 2.3583551691165456
Validation loss: 3.411774969573152

Epoch: 41| Step: 0
Training loss: 3.6282056906283993
Validation loss: 3.407527007595102

Epoch: 5| Step: 1
Training loss: 3.626585252025652
Validation loss: 3.4034701036631168

Epoch: 5| Step: 2
Training loss: 4.244289825667844
Validation loss: 3.398893163541237

Epoch: 5| Step: 3
Training loss: 2.802002197754874
Validation loss: 3.3945792209058276

Epoch: 5| Step: 4
Training loss: 3.853109486247788
Validation loss: 3.389910849793401

Epoch: 5| Step: 5
Training loss: 3.7495313987409205
Validation loss: 3.384982117371347

Epoch: 5| Step: 6
Training loss: 3.743503920375625
Validation loss: 3.380938162676211

Epoch: 5| Step: 7
Training loss: 3.250145542113749
Validation loss: 3.3766340726827666

Epoch: 5| Step: 8
Training loss: 3.395156574487133
Validation loss: 3.371761958619992

Epoch: 5| Step: 9
Training loss: 3.2269653364411544
Validation loss: 3.3672422683403878

Epoch: 5| Step: 10
Training loss: 3.335567838033582
Validation loss: 3.3629853003561854

Epoch: 5| Step: 11
Training loss: 1.5640015063363941
Validation loss: 3.3581756491278645

Epoch: 42| Step: 0
Training loss: 4.200063732208626
Validation loss: 3.3543668809610887

Epoch: 5| Step: 1
Training loss: 2.736589243680745
Validation loss: 3.351598251851596

Epoch: 5| Step: 2
Training loss: 3.3513516446456846
Validation loss: 3.347354084445231

Epoch: 5| Step: 3
Training loss: 3.6477703652635967
Validation loss: 3.3431792975420285

Epoch: 5| Step: 4
Training loss: 3.95646568542047
Validation loss: 3.339080110514495

Epoch: 5| Step: 5
Training loss: 2.8760569744170184
Validation loss: 3.335232010153138

Epoch: 5| Step: 6
Training loss: 3.011178488953118
Validation loss: 3.3314611879721827

Epoch: 5| Step: 7
Training loss: 3.620491907830079
Validation loss: 3.327313134592293

Epoch: 5| Step: 8
Training loss: 3.8090614696779515
Validation loss: 3.3235167118037046

Epoch: 5| Step: 9
Training loss: 2.842257097345289
Validation loss: 3.3202922207082146

Epoch: 5| Step: 10
Training loss: 3.7055652159476447
Validation loss: 3.315572315532149

Epoch: 5| Step: 11
Training loss: 4.052643306582229
Validation loss: 3.31218589637032

Epoch: 43| Step: 0
Training loss: 2.5890659182611713
Validation loss: 3.3087547470248952

Epoch: 5| Step: 1
Training loss: 3.0998328932975774
Validation loss: 3.3057573779565037

Epoch: 5| Step: 2
Training loss: 3.8311374566877827
Validation loss: 3.3040151310374886

Epoch: 5| Step: 3
Training loss: 3.8719714235086724
Validation loss: 3.300806584909937

Epoch: 5| Step: 4
Training loss: 3.343719197068985
Validation loss: 3.2969163105622843

Epoch: 5| Step: 5
Training loss: 3.4859690761803166
Validation loss: 3.2924189231099033

Epoch: 5| Step: 6
Training loss: 3.6438793650150147
Validation loss: 3.2868190795102947

Epoch: 5| Step: 7
Training loss: 2.917991301054927
Validation loss: 3.2820676117968013

Epoch: 5| Step: 8
Training loss: 3.741247262083837
Validation loss: 3.2777828699860825

Epoch: 5| Step: 9
Training loss: 3.42219521056355
Validation loss: 3.2737182217619334

Epoch: 5| Step: 10
Training loss: 3.501752414685379
Validation loss: 3.270592696860591

Epoch: 5| Step: 11
Training loss: 3.6614852332713776
Validation loss: 3.267136186111328

Epoch: 44| Step: 0
Training loss: 3.5736120824363216
Validation loss: 3.2636578611129723

Epoch: 5| Step: 1
Training loss: 3.479415991219448
Validation loss: 3.258543034770649

Epoch: 5| Step: 2
Training loss: 2.4990902198970444
Validation loss: 3.255248276529026

Epoch: 5| Step: 3
Training loss: 3.739708575150045
Validation loss: 3.251576371463515

Epoch: 5| Step: 4
Training loss: 3.562970849760789
Validation loss: 3.2477472334918414

Epoch: 5| Step: 5
Training loss: 3.3063907066936387
Validation loss: 3.243550264680881

Epoch: 5| Step: 6
Training loss: 3.5635173750317706
Validation loss: 3.2404700452788275

Epoch: 5| Step: 7
Training loss: 3.6318120419689834
Validation loss: 3.236785690569302

Epoch: 5| Step: 8
Training loss: 3.243461193244797
Validation loss: 3.2320131471806364

Epoch: 5| Step: 9
Training loss: 3.4254118177550303
Validation loss: 3.2288219678111623

Epoch: 5| Step: 10
Training loss: 3.144107538902975
Validation loss: 3.22611177389015

Epoch: 5| Step: 11
Training loss: 2.723837641320946
Validation loss: 3.2214479435331294

Epoch: 45| Step: 0
Training loss: 3.3108156348317976
Validation loss: 3.217925259255434

Epoch: 5| Step: 1
Training loss: 3.0902600881996527
Validation loss: 3.214537842767167

Epoch: 5| Step: 2
Training loss: 3.176978454526392
Validation loss: 3.211384336097691

Epoch: 5| Step: 3
Training loss: 3.2727946012006237
Validation loss: 3.207747738310354

Epoch: 5| Step: 4
Training loss: 2.906484614920998
Validation loss: 3.2040068800281247

Epoch: 5| Step: 5
Training loss: 3.6037253548807855
Validation loss: 3.2009718318281

Epoch: 5| Step: 6
Training loss: 3.0760157760493354
Validation loss: 3.197053287440653

Epoch: 5| Step: 7
Training loss: 3.722931634538074
Validation loss: 3.193910286421544

Epoch: 5| Step: 8
Training loss: 3.9624328800136515
Validation loss: 3.1904751039091725

Epoch: 5| Step: 9
Training loss: 3.3168441788855314
Validation loss: 3.186444768578516

Epoch: 5| Step: 10
Training loss: 3.21752995451149
Validation loss: 3.1830686982655445

Epoch: 5| Step: 11
Training loss: 3.0052073107915467
Validation loss: 3.17904160396491

Epoch: 46| Step: 0
Training loss: 3.035406664480793
Validation loss: 3.175484800246408

Epoch: 5| Step: 1
Training loss: 2.7472726128352494
Validation loss: 3.1718607997733015

Epoch: 5| Step: 2
Training loss: 3.7526524382042696
Validation loss: 3.1718811135319265

Epoch: 5| Step: 3
Training loss: 3.062188580307749
Validation loss: 3.1657699404915935

Epoch: 5| Step: 4
Training loss: 3.6687289131767296
Validation loss: 3.1623996336720492

Epoch: 5| Step: 5
Training loss: 3.805066475607103
Validation loss: 3.158263907931853

Epoch: 5| Step: 6
Training loss: 3.358778363850932
Validation loss: 3.1550763091336798

Epoch: 5| Step: 7
Training loss: 3.412962013799978
Validation loss: 3.152118118574918

Epoch: 5| Step: 8
Training loss: 2.8371656716628153
Validation loss: 3.148008981575972

Epoch: 5| Step: 9
Training loss: 3.063300359034459
Validation loss: 3.145052078111038

Epoch: 5| Step: 10
Training loss: 3.4381014211096126
Validation loss: 3.1418705205440873

Epoch: 5| Step: 11
Training loss: 2.7596719756978634
Validation loss: 3.1391355769004625

Epoch: 47| Step: 0
Training loss: 2.8537799731036895
Validation loss: 3.135628900072484

Epoch: 5| Step: 1
Training loss: 3.3130538765268414
Validation loss: 3.1325383466721246

Epoch: 5| Step: 2
Training loss: 3.4568185514545977
Validation loss: 3.1291343361360684

Epoch: 5| Step: 3
Training loss: 2.9459376797322463
Validation loss: 3.1257570748386265

Epoch: 5| Step: 4
Training loss: 3.558291174276301
Validation loss: 3.1223064130885922

Epoch: 5| Step: 5
Training loss: 3.5260103225253983
Validation loss: 3.118388487173322

Epoch: 5| Step: 6
Training loss: 3.25484237851798
Validation loss: 3.1148005519295663

Epoch: 5| Step: 7
Training loss: 3.420459471952208
Validation loss: 3.111403303720789

Epoch: 5| Step: 8
Training loss: 3.1877169067780766
Validation loss: 3.10760076180955

Epoch: 5| Step: 9
Training loss: 2.8623504999425706
Validation loss: 3.1051202958423807

Epoch: 5| Step: 10
Training loss: 3.4241269857620678
Validation loss: 3.1012858340278946

Epoch: 5| Step: 11
Training loss: 2.971527727537211
Validation loss: 3.098787092505182

Epoch: 48| Step: 0
Training loss: 2.912462055794106
Validation loss: 3.0959809412279258

Epoch: 5| Step: 1
Training loss: 3.1964019932597103
Validation loss: 3.093538309169498

Epoch: 5| Step: 2
Training loss: 3.107051268607326
Validation loss: 3.090610420287804

Epoch: 5| Step: 3
Training loss: 2.805118368306618
Validation loss: 3.088270166867595

Epoch: 5| Step: 4
Training loss: 3.270704052226893
Validation loss: 3.0847924534554987

Epoch: 5| Step: 5
Training loss: 3.2630872585216095
Validation loss: 3.0819146859899003

Epoch: 5| Step: 6
Training loss: 3.23587944682316
Validation loss: 3.078054972721825

Epoch: 5| Step: 7
Training loss: 3.1151856995609464
Validation loss: 3.0749230359688116

Epoch: 5| Step: 8
Training loss: 3.2051664964393756
Validation loss: 3.0714038594942625

Epoch: 5| Step: 9
Training loss: 3.1253178244141946
Validation loss: 3.06859220758174

Epoch: 5| Step: 10
Training loss: 3.9352558340741024
Validation loss: 3.065527943647371

Epoch: 5| Step: 11
Training loss: 3.7763772889863603
Validation loss: 3.0616714790564608

Epoch: 49| Step: 0
Training loss: 3.1696181513170782
Validation loss: 3.059601631901205

Epoch: 5| Step: 1
Training loss: 3.438868025013032
Validation loss: 3.055837036061564

Epoch: 5| Step: 2
Training loss: 3.245733394887959
Validation loss: 3.05425658768021

Epoch: 5| Step: 3
Training loss: 3.6110223090835674
Validation loss: 3.048638206951442

Epoch: 5| Step: 4
Training loss: 2.9507384976094397
Validation loss: 3.045846560110726

Epoch: 5| Step: 5
Training loss: 3.152569277045284
Validation loss: 3.0420319172411414

Epoch: 5| Step: 6
Training loss: 3.395637709398812
Validation loss: 3.0396551422219718

Epoch: 5| Step: 7
Training loss: 2.78771333091962
Validation loss: 3.0374349634248676

Epoch: 5| Step: 8
Training loss: 2.9624362665072943
Validation loss: 3.0346512343665712

Epoch: 5| Step: 9
Training loss: 3.432571623541835
Validation loss: 3.031533237870893

Epoch: 5| Step: 10
Training loss: 2.762288036240955
Validation loss: 3.0286178631309624

Epoch: 5| Step: 11
Training loss: 3.3026213262826385
Validation loss: 3.0253049223885426

Epoch: 50| Step: 0
Training loss: 3.192782045958221
Validation loss: 3.0224322012098614

Epoch: 5| Step: 1
Training loss: 3.4212800645326102
Validation loss: 3.0192438163994075

Epoch: 5| Step: 2
Training loss: 3.1305081461404565
Validation loss: 3.016798924125131

Epoch: 5| Step: 3
Training loss: 2.762428375972697
Validation loss: 3.0135923067319763

Epoch: 5| Step: 4
Training loss: 2.7957616540065042
Validation loss: 3.0099331831618366

Epoch: 5| Step: 5
Training loss: 2.906481333724016
Validation loss: 3.0079934135954187

Epoch: 5| Step: 6
Training loss: 3.181329326727306
Validation loss: 3.0047468142871456

Epoch: 5| Step: 7
Training loss: 3.5283930201130267
Validation loss: 3.0015577437710483

Epoch: 5| Step: 8
Training loss: 2.8189090184864773
Validation loss: 3.0001258625013225

Epoch: 5| Step: 9
Training loss: 3.4749615015326127
Validation loss: 2.99606662756204

Epoch: 5| Step: 10
Training loss: 3.3240925174328595
Validation loss: 2.9941101338094143

Epoch: 5| Step: 11
Training loss: 3.0122088912930916
Validation loss: 2.990403934441202

Epoch: 51| Step: 0
Training loss: 3.325750085650175
Validation loss: 2.9888277705130926

Epoch: 5| Step: 1
Training loss: 3.192758598160138
Validation loss: 2.985240511190465

Epoch: 5| Step: 2
Training loss: 2.7864596833317896
Validation loss: 2.984156186135928

Epoch: 5| Step: 3
Training loss: 3.242114109909206
Validation loss: 2.983768594590924

Epoch: 5| Step: 4
Training loss: 3.0892588065351343
Validation loss: 2.977064178855431

Epoch: 5| Step: 5
Training loss: 2.9431646392738666
Validation loss: 2.9751755460936757

Epoch: 5| Step: 6
Training loss: 3.0518582795962583
Validation loss: 2.97259998978433

Epoch: 5| Step: 7
Training loss: 3.0612383988122835
Validation loss: 2.9704820332046147

Epoch: 5| Step: 8
Training loss: 3.1489196862463302
Validation loss: 2.9706316389034693

Epoch: 5| Step: 9
Training loss: 3.185963877615026
Validation loss: 2.969359278481039

Epoch: 5| Step: 10
Training loss: 3.35671082357426
Validation loss: 2.9680404383981913

Epoch: 5| Step: 11
Training loss: 2.3517994301906295
Validation loss: 2.9648571290529766

Epoch: 52| Step: 0
Training loss: 3.4147146898333784
Validation loss: 2.963133119514207

Epoch: 5| Step: 1
Training loss: 2.5672801023697116
Validation loss: 2.9598551762437904

Epoch: 5| Step: 2
Training loss: 3.4037935691395735
Validation loss: 2.9570470294674154

Epoch: 5| Step: 3
Training loss: 3.476437821456417
Validation loss: 2.9541876224981554

Epoch: 5| Step: 4
Training loss: 3.1164914073388044
Validation loss: 2.950846231849473

Epoch: 5| Step: 5
Training loss: 3.0838557307716083
Validation loss: 2.946095528640419

Epoch: 5| Step: 6
Training loss: 2.7384616503966894
Validation loss: 2.9449934107777445

Epoch: 5| Step: 7
Training loss: 3.548052084117956
Validation loss: 2.941481300129431

Epoch: 5| Step: 8
Training loss: 2.9381255437464597
Validation loss: 2.9390446409703297

Epoch: 5| Step: 9
Training loss: 2.4287233064748364
Validation loss: 2.935333751827744

Epoch: 5| Step: 10
Training loss: 2.9636052576805922
Validation loss: 2.933393824605644

Epoch: 5| Step: 11
Training loss: 3.48938749912052
Validation loss: 2.930955888624255

Epoch: 53| Step: 0
Training loss: 2.822888410551163
Validation loss: 2.9280533772668664

Epoch: 5| Step: 1
Training loss: 2.762731040165323
Validation loss: 2.9255173669846255

Epoch: 5| Step: 2
Training loss: 2.8227163621470743
Validation loss: 2.9232420043986034

Epoch: 5| Step: 3
Training loss: 2.850164368557612
Validation loss: 2.920895815293013

Epoch: 5| Step: 4
Training loss: 2.978307337747986
Validation loss: 2.918242591901013

Epoch: 5| Step: 5
Training loss: 2.9438442142255754
Validation loss: 2.9163382833541798

Epoch: 5| Step: 6
Training loss: 2.9222457568917566
Validation loss: 2.9145971221997575

Epoch: 5| Step: 7
Training loss: 3.549505527069135
Validation loss: 2.913403505566645

Epoch: 5| Step: 8
Training loss: 3.445006895459808
Validation loss: 2.910569692851705

Epoch: 5| Step: 9
Training loss: 3.369281728249932
Validation loss: 2.9084950119774966

Epoch: 5| Step: 10
Training loss: 2.9391609528279354
Validation loss: 2.9057547820738194

Epoch: 5| Step: 11
Training loss: 3.59354632256554
Validation loss: 2.903598474820562

Epoch: 54| Step: 0
Training loss: 2.749744490110813
Validation loss: 2.9008807417902234

Epoch: 5| Step: 1
Training loss: 3.214570526341465
Validation loss: 2.898689235095876

Epoch: 5| Step: 2
Training loss: 3.7892101141107752
Validation loss: 2.896036354788012

Epoch: 5| Step: 3
Training loss: 3.1810640172048057
Validation loss: 2.8937024376944764

Epoch: 5| Step: 4
Training loss: 2.874784046852918
Validation loss: 2.8903698885954583

Epoch: 5| Step: 5
Training loss: 2.951382238841824
Validation loss: 2.887955310836151

Epoch: 5| Step: 6
Training loss: 2.32925275075991
Validation loss: 2.8860326217399117

Epoch: 5| Step: 7
Training loss: 3.0236575024426355
Validation loss: 2.88264184324323

Epoch: 5| Step: 8
Training loss: 2.7161506416275802
Validation loss: 2.8805763717699526

Epoch: 5| Step: 9
Training loss: 3.128781129237917
Validation loss: 2.878801403439768

Epoch: 5| Step: 10
Training loss: 3.1266103028813785
Validation loss: 2.877314168318977

Epoch: 5| Step: 11
Training loss: 3.2283209564911783
Validation loss: 2.8738782221454855

Epoch: 55| Step: 0
Training loss: 3.3152581014601075
Validation loss: 2.871247524027351

Epoch: 5| Step: 1
Training loss: 3.4428173207601325
Validation loss: 2.869774187776723

Epoch: 5| Step: 2
Training loss: 2.3181378484489703
Validation loss: 2.866799615024509

Epoch: 5| Step: 3
Training loss: 2.7139762096051046
Validation loss: 2.8661175566954884

Epoch: 5| Step: 4
Training loss: 3.353277021305608
Validation loss: 2.8654413094366245

Epoch: 5| Step: 5
Training loss: 2.6472175061278502
Validation loss: 2.8635409013218216

Epoch: 5| Step: 6
Training loss: 3.2169710446834214
Validation loss: 2.8624272376117608

Epoch: 5| Step: 7
Training loss: 3.2231323630304507
Validation loss: 2.8606289752612817

Epoch: 5| Step: 8
Training loss: 2.7893316742756555
Validation loss: 2.8582082462929628

Epoch: 5| Step: 9
Training loss: 2.557612060448517
Validation loss: 2.856554627677014

Epoch: 5| Step: 10
Training loss: 3.0330652523699975
Validation loss: 2.85425723876552

Epoch: 5| Step: 11
Training loss: 3.9689316595359014
Validation loss: 2.852412333204207

Epoch: 56| Step: 0
Training loss: 2.779754751077018
Validation loss: 2.848420478824351

Epoch: 5| Step: 1
Training loss: 3.1896997976603276
Validation loss: 2.8455260463227012

Epoch: 5| Step: 2
Training loss: 2.9658770664124448
Validation loss: 2.8427613779116

Epoch: 5| Step: 3
Training loss: 3.155243968206162
Validation loss: 2.8401238444574872

Epoch: 5| Step: 4
Training loss: 3.0049783408198447
Validation loss: 2.8378967859175495

Epoch: 5| Step: 5
Training loss: 2.7629033721970626
Validation loss: 2.836374650230463

Epoch: 5| Step: 6
Training loss: 2.801818655529458
Validation loss: 2.840243822520232

Epoch: 5| Step: 7
Training loss: 3.379236176540613
Validation loss: 2.8327098761217644

Epoch: 5| Step: 8
Training loss: 2.99365548958253
Validation loss: 2.8289379054541195

Epoch: 5| Step: 9
Training loss: 2.8159224984926503
Validation loss: 2.827375266946607

Epoch: 5| Step: 10
Training loss: 2.6535288616801
Validation loss: 2.8264496760557827

Epoch: 5| Step: 11
Training loss: 3.7418115861067687
Validation loss: 2.823099293496403

Epoch: 57| Step: 0
Training loss: 3.3691264718905627
Validation loss: 2.8213495125021226

Epoch: 5| Step: 1
Training loss: 2.7987918358930557
Validation loss: 2.8212577736223086

Epoch: 5| Step: 2
Training loss: 3.121353157731166
Validation loss: 2.8185776211625884

Epoch: 5| Step: 3
Training loss: 2.4181446510634546
Validation loss: 2.8177101090590733

Epoch: 5| Step: 4
Training loss: 3.0134661759433583
Validation loss: 2.816454780714261

Epoch: 5| Step: 5
Training loss: 2.692184800707349
Validation loss: 2.8150304678210487

Epoch: 5| Step: 6
Training loss: 2.6613700438982706
Validation loss: 2.813186551115443

Epoch: 5| Step: 7
Training loss: 3.052405400040481
Validation loss: 2.810450739803623

Epoch: 5| Step: 8
Training loss: 3.262864986187878
Validation loss: 2.808764099274715

Epoch: 5| Step: 9
Training loss: 3.1381751986744915
Validation loss: 2.8062349724030926

Epoch: 5| Step: 10
Training loss: 2.698890677138664
Validation loss: 2.8037006940912543

Epoch: 5| Step: 11
Training loss: 3.5740239658331348
Validation loss: 2.8021120344107837

Epoch: 58| Step: 0
Training loss: 2.9873075606802137
Validation loss: 2.79820616884353

Epoch: 5| Step: 1
Training loss: 2.9164978160120785
Validation loss: 2.7961700730318295

Epoch: 5| Step: 2
Training loss: 2.894891343260093
Validation loss: 2.7941406707927214

Epoch: 5| Step: 3
Training loss: 2.434935174036018
Validation loss: 2.7918403782579073

Epoch: 5| Step: 4
Training loss: 3.443147770724475
Validation loss: 2.7897061763682522

Epoch: 5| Step: 5
Training loss: 2.977659328755558
Validation loss: 2.788883791201603

Epoch: 5| Step: 6
Training loss: 2.7610091143453857
Validation loss: 2.785820013832782

Epoch: 5| Step: 7
Training loss: 2.5517640725083472
Validation loss: 2.7846186093539895

Epoch: 5| Step: 8
Training loss: 2.8024081262915526
Validation loss: 2.782448731738697

Epoch: 5| Step: 9
Training loss: 3.0595492725397695
Validation loss: 2.7823489086261612

Epoch: 5| Step: 10
Training loss: 3.1416701670120397
Validation loss: 2.780063854840361

Epoch: 5| Step: 11
Training loss: 3.5660340030266378
Validation loss: 2.7780654548983406

Epoch: 59| Step: 0
Training loss: 2.990694076712936
Validation loss: 2.7773362350541038

Epoch: 5| Step: 1
Training loss: 3.0005745337607945
Validation loss: 2.7746402800876617

Epoch: 5| Step: 2
Training loss: 2.4827435973049043
Validation loss: 2.773375185414191

Epoch: 5| Step: 3
Training loss: 2.6267246756788327
Validation loss: 2.7714333183419275

Epoch: 5| Step: 4
Training loss: 3.1692506052383598
Validation loss: 2.7700780266916873

Epoch: 5| Step: 5
Training loss: 2.9960587361464484
Validation loss: 2.7683431841724584

Epoch: 5| Step: 6
Training loss: 3.353493016677213
Validation loss: 2.7665877238083594

Epoch: 5| Step: 7
Training loss: 2.4703597602932006
Validation loss: 2.765351721988788

Epoch: 5| Step: 8
Training loss: 3.0798133828241054
Validation loss: 2.764292343816298

Epoch: 5| Step: 9
Training loss: 2.959082513069352
Validation loss: 2.763116169158738

Epoch: 5| Step: 10
Training loss: 2.874486130940237
Validation loss: 2.761464187709877

Epoch: 5| Step: 11
Training loss: 2.1476422311846366
Validation loss: 2.758687180519885

Epoch: 60| Step: 0
Training loss: 3.2897190335779825
Validation loss: 2.7577047281937417

Epoch: 5| Step: 1
Training loss: 3.5838553174140872
Validation loss: 2.7554741654875965

Epoch: 5| Step: 2
Training loss: 2.560370607223061
Validation loss: 2.7541622574944533

Epoch: 5| Step: 3
Training loss: 2.669984204249145
Validation loss: 2.752386480918831

Epoch: 5| Step: 4
Training loss: 2.6052754800881304
Validation loss: 2.7508556161983573

Epoch: 5| Step: 5
Training loss: 2.7421875
Validation loss: 2.7478041985676076

Epoch: 5| Step: 6
Training loss: 2.853181896498938
Validation loss: 2.74620538867177

Epoch: 5| Step: 7
Training loss: 3.1584963217142152
Validation loss: 2.7454805589394113

Epoch: 5| Step: 8
Training loss: 2.356580177871126
Validation loss: 2.742513711478338

Epoch: 5| Step: 9
Training loss: 3.0062635520582015
Validation loss: 2.7415276265083244

Epoch: 5| Step: 10
Training loss: 2.4344355564640976
Validation loss: 2.740156905370002

Epoch: 5| Step: 11
Training loss: 4.025027181403271
Validation loss: 2.737987203223987

Epoch: 61| Step: 0
Training loss: 3.1341028005930274
Validation loss: 2.7368974658351513

Epoch: 5| Step: 1
Training loss: 2.7262057095532577
Validation loss: 2.7345743415468076

Epoch: 5| Step: 2
Training loss: 2.5509669658356833
Validation loss: 2.733886126457832

Epoch: 5| Step: 3
Training loss: 3.150081839330912
Validation loss: 2.7314608785662853

Epoch: 5| Step: 4
Training loss: 2.6559431908633253
Validation loss: 2.730512088400773

Epoch: 5| Step: 5
Training loss: 3.175030120947028
Validation loss: 2.7282604880114896

Epoch: 5| Step: 6
Training loss: 2.960299380343929
Validation loss: 2.7277033331044933

Epoch: 5| Step: 7
Training loss: 2.950058409549034
Validation loss: 2.7242077092715595

Epoch: 5| Step: 8
Training loss: 2.7997163799238516
Validation loss: 2.723862747839619

Epoch: 5| Step: 9
Training loss: 2.6964712112505533
Validation loss: 2.722592495829054

Epoch: 5| Step: 10
Training loss: 2.3349269352331343
Validation loss: 2.7211179067945155

Epoch: 5| Step: 11
Training loss: 4.164438084023349
Validation loss: 2.7215528984453816

Epoch: 62| Step: 0
Training loss: 3.1268828251291096
Validation loss: 2.71993941016943

Epoch: 5| Step: 1
Training loss: 2.259438110989672
Validation loss: 2.71769388740144

Epoch: 5| Step: 2
Training loss: 3.1288174010578818
Validation loss: 2.7165804497274153

Epoch: 5| Step: 3
Training loss: 3.2416818247410473
Validation loss: 2.7148738136730937

Epoch: 5| Step: 4
Training loss: 2.4673422167574377
Validation loss: 2.7131133604880153

Epoch: 5| Step: 5
Training loss: 3.237229124542339
Validation loss: 2.7153498664960307

Epoch: 5| Step: 6
Training loss: 2.294997089857862
Validation loss: 2.711385750333379

Epoch: 5| Step: 7
Training loss: 3.0445110834289277
Validation loss: 2.7106310536548093

Epoch: 5| Step: 8
Training loss: 3.002230768512365
Validation loss: 2.71334715650663

Epoch: 5| Step: 9
Training loss: 2.609103068727295
Validation loss: 2.711920172602385

Epoch: 5| Step: 10
Training loss: 2.5680918274976947
Validation loss: 2.7039388045326262

Epoch: 5| Step: 11
Training loss: 3.56052464380402
Validation loss: 2.7019521524551564

Epoch: 63| Step: 0
Training loss: 2.3666324783148207
Validation loss: 2.702709474764536

Epoch: 5| Step: 1
Training loss: 2.594652869025486
Validation loss: 2.702075111231553

Epoch: 5| Step: 2
Training loss: 2.295980473930456
Validation loss: 2.7006403247634165

Epoch: 5| Step: 3
Training loss: 3.0402757434267924
Validation loss: 2.6987138157194943

Epoch: 5| Step: 4
Training loss: 2.8484669226101436
Validation loss: 2.697909523918879

Epoch: 5| Step: 5
Training loss: 3.0213727973600744
Validation loss: 2.6974779211678053

Epoch: 5| Step: 6
Training loss: 2.8614377778690576
Validation loss: 2.6960132885694095

Epoch: 5| Step: 7
Training loss: 2.6027838328845325
Validation loss: 2.6967402891990497

Epoch: 5| Step: 8
Training loss: 3.3376679053200626
Validation loss: 2.6956759663855365

Epoch: 5| Step: 9
Training loss: 3.1088449611049276
Validation loss: 2.695753328697661

Epoch: 5| Step: 10
Training loss: 3.1401998507322846
Validation loss: 2.6948995412068912

Epoch: 5| Step: 11
Training loss: 1.397622878143744
Validation loss: 2.6910085582672667

Epoch: 64| Step: 0
Training loss: 2.5863797365727543
Validation loss: 2.689718975297964

Epoch: 5| Step: 1
Training loss: 2.844604196218182
Validation loss: 2.6889812098851826

Epoch: 5| Step: 2
Training loss: 3.0998121266194367
Validation loss: 2.686838807971965

Epoch: 5| Step: 3
Training loss: 3.180359115716248
Validation loss: 2.6841723925535264

Epoch: 5| Step: 4
Training loss: 2.9405492012721943
Validation loss: 2.6829996390698514

Epoch: 5| Step: 5
Training loss: 2.4504027600005394
Validation loss: 2.6825662021816576

Epoch: 5| Step: 6
Training loss: 2.841042204079145
Validation loss: 2.67799665899498

Epoch: 5| Step: 7
Training loss: 2.571339596238379
Validation loss: 2.677742277059992

Epoch: 5| Step: 8
Training loss: 3.1334740755924035
Validation loss: 2.6777022953648495

Epoch: 5| Step: 9
Training loss: 2.479161099553202
Validation loss: 2.674106316854815

Epoch: 5| Step: 10
Training loss: 2.950018323421146
Validation loss: 2.6754978633164654

Epoch: 5| Step: 11
Training loss: 1.9661462914337904
Validation loss: 2.6752626942203084

Epoch: 65| Step: 0
Training loss: 2.9613421724723703
Validation loss: 2.673258573786094

Epoch: 5| Step: 1
Training loss: 2.7466380636645584
Validation loss: 2.6731697016764437

Epoch: 5| Step: 2
Training loss: 2.8299291767653503
Validation loss: 2.6716475399230633

Epoch: 5| Step: 3
Training loss: 3.083724143202441
Validation loss: 2.6715164985106825

Epoch: 5| Step: 4
Training loss: 3.235670484488786
Validation loss: 2.670486818311659

Epoch: 5| Step: 5
Training loss: 2.423027699474745
Validation loss: 2.668929839644774

Epoch: 5| Step: 6
Training loss: 2.3403960580740777
Validation loss: 2.66854757915597

Epoch: 5| Step: 7
Training loss: 2.728996960748341
Validation loss: 2.667591803727872

Epoch: 5| Step: 8
Training loss: 2.708917310306756
Validation loss: 2.666238516967483

Epoch: 5| Step: 9
Training loss: 2.405511321595214
Validation loss: 2.6651700869313597

Epoch: 5| Step: 10
Training loss: 3.2676274489141903
Validation loss: 2.6631033057166493

Epoch: 5| Step: 11
Training loss: 2.6677891236543743
Validation loss: 2.6627572144331326

Epoch: 66| Step: 0
Training loss: 3.101031587067713
Validation loss: 2.6646495183539733

Epoch: 5| Step: 1
Training loss: 2.9724316706395615
Validation loss: 2.659929475907052

Epoch: 5| Step: 2
Training loss: 2.557158508770438
Validation loss: 2.6598182422402568

Epoch: 5| Step: 3
Training loss: 2.8458676680080326
Validation loss: 2.6582390275708

Epoch: 5| Step: 4
Training loss: 2.8607662964309775
Validation loss: 2.6587288902029353

Epoch: 5| Step: 5
Training loss: 3.392492948790428
Validation loss: 2.6577195291257683

Epoch: 5| Step: 6
Training loss: 2.9617685243876206
Validation loss: 2.6545317571413007

Epoch: 5| Step: 7
Training loss: 2.2775500876386627
Validation loss: 2.6543297015909446

Epoch: 5| Step: 8
Training loss: 2.6380497038687096
Validation loss: 2.6556870892524187

Epoch: 5| Step: 9
Training loss: 2.1277638581265794
Validation loss: 2.655676499332238

Epoch: 5| Step: 10
Training loss: 2.5010448179869926
Validation loss: 2.6541488377877065

Epoch: 5| Step: 11
Training loss: 3.978019282636134
Validation loss: 2.6553705554751312

Epoch: 67| Step: 0
Training loss: 3.1833001685953066
Validation loss: 2.655203624395418

Epoch: 5| Step: 1
Training loss: 2.694186918224047
Validation loss: 2.654218031138202

Epoch: 5| Step: 2
Training loss: 2.956930463678307
Validation loss: 2.6535692300618097

Epoch: 5| Step: 3
Training loss: 2.8872162386358555
Validation loss: 2.6517886188088116

Epoch: 5| Step: 4
Training loss: 2.423788287060556
Validation loss: 2.648828445732331

Epoch: 5| Step: 5
Training loss: 3.1113926461157586
Validation loss: 2.646705695137971

Epoch: 5| Step: 6
Training loss: 2.6726752973255246
Validation loss: 2.644763457388355

Epoch: 5| Step: 7
Training loss: 2.7314132781293208
Validation loss: 2.641385606551379

Epoch: 5| Step: 8
Training loss: 3.099154135451421
Validation loss: 2.6400657490468515

Epoch: 5| Step: 9
Training loss: 2.406574276958598
Validation loss: 2.636376248944117

Epoch: 5| Step: 10
Training loss: 2.5457972955312216
Validation loss: 2.637995782239288

Epoch: 5| Step: 11
Training loss: 1.5600614210410608
Validation loss: 2.6373062006844736

Epoch: 68| Step: 0
Training loss: 3.177079164262548
Validation loss: 2.6373392123889516

Epoch: 5| Step: 1
Training loss: 2.7218794077017447
Validation loss: 2.6428565728924602

Epoch: 5| Step: 2
Training loss: 2.974787946564657
Validation loss: 2.6582044161854865

Epoch: 5| Step: 3
Training loss: 2.405520043564941
Validation loss: 2.6454756837951914

Epoch: 5| Step: 4
Training loss: 2.7820136061389835
Validation loss: 2.634302557163764

Epoch: 5| Step: 5
Training loss: 2.793548310443326
Validation loss: 2.6308285740420727

Epoch: 5| Step: 6
Training loss: 2.267124390200253
Validation loss: 2.6335267589448823

Epoch: 5| Step: 7
Training loss: 2.479907547550306
Validation loss: 2.6347757598025985

Epoch: 5| Step: 8
Training loss: 3.0659608553921354
Validation loss: 2.6343334494889237

Epoch: 5| Step: 9
Training loss: 3.158414344117696
Validation loss: 2.635612689079882

Epoch: 5| Step: 10
Training loss: 2.6202242868823493
Validation loss: 2.6359095144001654

Epoch: 5| Step: 11
Training loss: 2.5495371566791007
Validation loss: 2.6339286792653502

Epoch: 69| Step: 0
Training loss: 2.735206085335098
Validation loss: 2.6358161530511173

Epoch: 5| Step: 1
Training loss: 3.1483648022004016
Validation loss: 2.6335500972498087

Epoch: 5| Step: 2
Training loss: 2.7484003963427424
Validation loss: 2.6323730600079007

Epoch: 5| Step: 3
Training loss: 2.923455611498547
Validation loss: 2.6300334016143845

Epoch: 5| Step: 4
Training loss: 2.8293218451196895
Validation loss: 2.6285808072715096

Epoch: 5| Step: 5
Training loss: 2.897738884071301
Validation loss: 2.627237146237525

Epoch: 5| Step: 6
Training loss: 2.897929761479015
Validation loss: 2.625503434997154

Epoch: 5| Step: 7
Training loss: 2.7874729103859024
Validation loss: 2.622587806218408

Epoch: 5| Step: 8
Training loss: 2.1284170166069503
Validation loss: 2.620186835960574

Epoch: 5| Step: 9
Training loss: 2.1853015206267226
Validation loss: 2.618614122997506

Epoch: 5| Step: 10
Training loss: 2.8162172971029693
Validation loss: 2.6174839022741665

Epoch: 5| Step: 11
Training loss: 3.379001929190865
Validation loss: 2.6157728822590736

Epoch: 70| Step: 0
Training loss: 2.744662045935515
Validation loss: 2.6178787571150997

Epoch: 5| Step: 1
Training loss: 2.649080541634107
Validation loss: 2.6115630640231133

Epoch: 5| Step: 2
Training loss: 2.7503192889651307
Validation loss: 2.6140919650450916

Epoch: 5| Step: 3
Training loss: 2.903450714991099
Validation loss: 2.6117681200612335

Epoch: 5| Step: 4
Training loss: 2.781394954718679
Validation loss: 2.6114880767962494

Epoch: 5| Step: 5
Training loss: 3.180005106891874
Validation loss: 2.615873168086226

Epoch: 5| Step: 6
Training loss: 3.062656009359366
Validation loss: 2.6079529220292423

Epoch: 5| Step: 7
Training loss: 2.5473090427993985
Validation loss: 2.6116698028940806

Epoch: 5| Step: 8
Training loss: 2.3990257113479414
Validation loss: 2.6089527488985227

Epoch: 5| Step: 9
Training loss: 2.7134792054663945
Validation loss: 2.610780763668099

Epoch: 5| Step: 10
Training loss: 2.598180915794262
Validation loss: 2.6101291845768673

Epoch: 5| Step: 11
Training loss: 1.7895273995530834
Validation loss: 2.6109325268110406

Epoch: 71| Step: 0
Training loss: 2.799100874543749
Validation loss: 2.6104053130718596

Epoch: 5| Step: 1
Training loss: 2.8908755632008134
Validation loss: 2.609231419524824

Epoch: 5| Step: 2
Training loss: 3.055516903565358
Validation loss: 2.6079089868187344

Epoch: 5| Step: 3
Training loss: 2.7660196313719925
Validation loss: 2.606340566535895

Epoch: 5| Step: 4
Training loss: 2.7638028278935107
Validation loss: 2.603858522621936

Epoch: 5| Step: 5
Training loss: 3.1054190001911253
Validation loss: 2.603484389892085

Epoch: 5| Step: 6
Training loss: 2.467830148580415
Validation loss: 2.6027354134737855

Epoch: 5| Step: 7
Training loss: 2.4042801163040526
Validation loss: 2.6006156718184505

Epoch: 5| Step: 8
Training loss: 2.6134908959839738
Validation loss: 2.5997831351974274

Epoch: 5| Step: 9
Training loss: 2.5651965026243926
Validation loss: 2.5993831850427327

Epoch: 5| Step: 10
Training loss: 2.7930395157392085
Validation loss: 2.5986045005352247

Epoch: 5| Step: 11
Training loss: 1.9826780257080292
Validation loss: 2.5984782589062907

Epoch: 72| Step: 0
Training loss: 2.421239363411152
Validation loss: 2.5924327370266105

Epoch: 5| Step: 1
Training loss: 2.6765590010763214
Validation loss: 2.596327427937148

Epoch: 5| Step: 2
Training loss: 2.896654922701518
Validation loss: 2.59695705095984

Epoch: 5| Step: 3
Training loss: 2.3959244973349914
Validation loss: 2.5991914080202276

Epoch: 5| Step: 4
Training loss: 3.051811093284884
Validation loss: 2.6058395518415876

Epoch: 5| Step: 5
Training loss: 2.3814262985688086
Validation loss: 2.6127765360100224

Epoch: 5| Step: 6
Training loss: 2.96602851204727
Validation loss: 2.6023708687564784

Epoch: 5| Step: 7
Training loss: 3.0332485571392276
Validation loss: 2.5898234547337187

Epoch: 5| Step: 8
Training loss: 2.9954263473469633
Validation loss: 2.589758862484646

Epoch: 5| Step: 9
Training loss: 2.6335554121831777
Validation loss: 2.589737266165767

Epoch: 5| Step: 10
Training loss: 2.563642572749604
Validation loss: 2.5924181103809074

Epoch: 5| Step: 11
Training loss: 2.4541775334565052
Validation loss: 2.592175246951879

Epoch: 73| Step: 0
Training loss: 2.585957230322672
Validation loss: 2.5912644491729786

Epoch: 5| Step: 1
Training loss: 2.721830004594992
Validation loss: 2.5945485927052325

Epoch: 5| Step: 2
Training loss: 2.7157549968548147
Validation loss: 2.596069130257979

Epoch: 5| Step: 3
Training loss: 2.622947798936308
Validation loss: 2.5951197159690405

Epoch: 5| Step: 4
Training loss: 2.7719341663122856
Validation loss: 2.5956893281400144

Epoch: 5| Step: 5
Training loss: 2.784406435325583
Validation loss: 2.5953671343413727

Epoch: 5| Step: 6
Training loss: 3.09581957095661
Validation loss: 2.5925356423623374

Epoch: 5| Step: 7
Training loss: 2.831717722407976
Validation loss: 2.5899829012013025

Epoch: 5| Step: 8
Training loss: 2.92932907963778
Validation loss: 2.5882705582323906

Epoch: 5| Step: 9
Training loss: 2.3409176815376997
Validation loss: 2.5835669505457064

Epoch: 5| Step: 10
Training loss: 2.6669136072103976
Validation loss: 2.5825336985068152

Epoch: 5| Step: 11
Training loss: 2.0950035783468564
Validation loss: 2.58050166313208

Epoch: 74| Step: 0
Training loss: 2.733293068596987
Validation loss: 2.5781713693475474

Epoch: 5| Step: 1
Training loss: 2.7949029374030854
Validation loss: 2.5778114552040434

Epoch: 5| Step: 2
Training loss: 2.7795525846713836
Validation loss: 2.5775715320551287

Epoch: 5| Step: 3
Training loss: 2.6322037080702567
Validation loss: 2.5760814929500193

Epoch: 5| Step: 4
Training loss: 2.6335508856259824
Validation loss: 2.575106998646404

Epoch: 5| Step: 5
Training loss: 2.866516367350717
Validation loss: 2.5741075483045566

Epoch: 5| Step: 6
Training loss: 2.0441584141105014
Validation loss: 2.576917161160995

Epoch: 5| Step: 7
Training loss: 2.473847932192634
Validation loss: 2.5786170894433598

Epoch: 5| Step: 8
Training loss: 2.7133606736245217
Validation loss: 2.5825405916973376

Epoch: 5| Step: 9
Training loss: 3.097957947555812
Validation loss: 2.586629588622939

Epoch: 5| Step: 10
Training loss: 2.9258677898896206
Validation loss: 2.586552430611417

Epoch: 5| Step: 11
Training loss: 3.0650007975392137
Validation loss: 2.576407908823275

Epoch: 75| Step: 0
Training loss: 2.9663014805084464
Validation loss: 2.569220190027901

Epoch: 5| Step: 1
Training loss: 2.3265898078458456
Validation loss: 2.5690783017845775

Epoch: 5| Step: 2
Training loss: 2.8910060322136824
Validation loss: 2.5698888481721114

Epoch: 5| Step: 3
Training loss: 2.5441217811574233
Validation loss: 2.574138449080663

Epoch: 5| Step: 4
Training loss: 2.7274680833496325
Validation loss: 2.5746471683346486

Epoch: 5| Step: 5
Training loss: 2.3252479133920603
Validation loss: 2.5759710349768103

Epoch: 5| Step: 6
Training loss: 3.2015816296536075
Validation loss: 2.5753147607228772

Epoch: 5| Step: 7
Training loss: 2.247728896997361
Validation loss: 2.5776234109935707

Epoch: 5| Step: 8
Training loss: 2.9998402552989405
Validation loss: 2.578751362707629

Epoch: 5| Step: 9
Training loss: 2.5989623493375054
Validation loss: 2.579591103040253

Epoch: 5| Step: 10
Training loss: 2.8607777974395776
Validation loss: 2.577189173538493

Epoch: 5| Step: 11
Training loss: 2.362755280281022
Validation loss: 2.5735882038458677

Epoch: 76| Step: 0
Training loss: 2.89807077231647
Validation loss: 2.5727224405367184

Epoch: 5| Step: 1
Training loss: 2.576776695254564
Validation loss: 2.568695135373734

Epoch: 5| Step: 2
Training loss: 2.924696921272156
Validation loss: 2.568672259748488

Epoch: 5| Step: 3
Training loss: 2.5116293314298064
Validation loss: 2.560707527589263

Epoch: 5| Step: 4
Training loss: 2.7163735011147847
Validation loss: 2.558699037360862

Epoch: 5| Step: 5
Training loss: 2.622180878139077
Validation loss: 2.5576205356144364

Epoch: 5| Step: 6
Training loss: 2.6480393912275315
Validation loss: 2.5571661890534134

Epoch: 5| Step: 7
Training loss: 2.1108232965643636
Validation loss: 2.5560199595178483

Epoch: 5| Step: 8
Training loss: 3.3205659657390796
Validation loss: 2.5554408713421375

Epoch: 5| Step: 9
Training loss: 2.7546785610874003
Validation loss: 2.5538666054694406

Epoch: 5| Step: 10
Training loss: 2.4321279749766087
Validation loss: 2.5517553832388935

Epoch: 5| Step: 11
Training loss: 2.4628366075683163
Validation loss: 2.5517869400948925

Epoch: 77| Step: 0
Training loss: 2.725110823451324
Validation loss: 2.5553211705615606

Epoch: 5| Step: 1
Training loss: 2.693311661815639
Validation loss: 2.5718992219002943

Epoch: 5| Step: 2
Training loss: 2.5122848988023323
Validation loss: 2.58436856497748

Epoch: 5| Step: 3
Training loss: 2.3528365932390765
Validation loss: 2.579467705078278

Epoch: 5| Step: 4
Training loss: 2.903945501399373
Validation loss: 2.5724025294995605

Epoch: 5| Step: 5
Training loss: 2.2442933936116476
Validation loss: 2.5588499916415812

Epoch: 5| Step: 6
Training loss: 2.9478560981773727
Validation loss: 2.554907070916013

Epoch: 5| Step: 7
Training loss: 2.748030390686611
Validation loss: 2.549350724899236

Epoch: 5| Step: 8
Training loss: 2.8380011834322914
Validation loss: 2.5536044524671366

Epoch: 5| Step: 9
Training loss: 2.6931273517434597
Validation loss: 2.555452389782812

Epoch: 5| Step: 10
Training loss: 3.012348509972282
Validation loss: 2.5555182301057595

Epoch: 5| Step: 11
Training loss: 2.666608293212318
Validation loss: 2.560720255995466

Epoch: 78| Step: 0
Training loss: 2.899528853192464
Validation loss: 2.5592048245322907

Epoch: 5| Step: 1
Training loss: 2.2849361998417836
Validation loss: 2.561935308310695

Epoch: 5| Step: 2
Training loss: 2.0156782276311342
Validation loss: 2.5628570835077875

Epoch: 5| Step: 3
Training loss: 2.710551385563782
Validation loss: 2.56337533902333

Epoch: 5| Step: 4
Training loss: 2.8195207070829746
Validation loss: 2.561005520959772

Epoch: 5| Step: 5
Training loss: 2.7585157843078205
Validation loss: 2.5606286535096556

Epoch: 5| Step: 6
Training loss: 2.590567417218061
Validation loss: 2.5540464804429464

Epoch: 5| Step: 7
Training loss: 2.699905948413674
Validation loss: 2.5504905803792894

Epoch: 5| Step: 8
Training loss: 2.778727040747252
Validation loss: 2.5489035252980754

Epoch: 5| Step: 9
Training loss: 2.580764990954736
Validation loss: 2.549644922018702

Epoch: 5| Step: 10
Training loss: 3.175623590701413
Validation loss: 2.550429077918031

Epoch: 5| Step: 11
Training loss: 3.213670889772093
Validation loss: 2.5484411128502082

Epoch: 79| Step: 0
Training loss: 2.627585727008179
Validation loss: 2.5457915554479174

Epoch: 5| Step: 1
Training loss: 2.4890127978059096
Validation loss: 2.5461859365752306

Epoch: 5| Step: 2
Training loss: 2.8247445488946448
Validation loss: 2.54479378616759

Epoch: 5| Step: 3
Training loss: 2.4100602933060835
Validation loss: 2.5451288536767906

Epoch: 5| Step: 4
Training loss: 2.9832648164634876
Validation loss: 2.540629489264407

Epoch: 5| Step: 5
Training loss: 2.949878179330154
Validation loss: 2.5415995985052025

Epoch: 5| Step: 6
Training loss: 2.6658646649110103
Validation loss: 2.5393799998992863

Epoch: 5| Step: 7
Training loss: 2.639400943354896
Validation loss: 2.538644910853977

Epoch: 5| Step: 8
Training loss: 2.8032569743615445
Validation loss: 2.5389270179010737

Epoch: 5| Step: 9
Training loss: 2.2790187218145235
Validation loss: 2.5368167433370323

Epoch: 5| Step: 10
Training loss: 2.5945908435937257
Validation loss: 2.5373545100716886

Epoch: 5| Step: 11
Training loss: 3.0920331410436885
Validation loss: 2.540485046179289

Epoch: 80| Step: 0
Training loss: 3.0284061265957276
Validation loss: 2.539880489731742

Epoch: 5| Step: 1
Training loss: 2.762408784076723
Validation loss: 2.5351200542011414

Epoch: 5| Step: 2
Training loss: 2.852364038140837
Validation loss: 2.5347561513177292

Epoch: 5| Step: 3
Training loss: 2.9792730850384253
Validation loss: 2.5349376840913886

Epoch: 5| Step: 4
Training loss: 2.585756232140459
Validation loss: 2.5338751323861066

Epoch: 5| Step: 5
Training loss: 2.3369250809393396
Validation loss: 2.5309950931752203

Epoch: 5| Step: 6
Training loss: 2.380316155215373
Validation loss: 2.5322365074683293

Epoch: 5| Step: 7
Training loss: 2.6459469407889604
Validation loss: 2.5322872477756633

Epoch: 5| Step: 8
Training loss: 2.550333775386125
Validation loss: 2.528819620673477

Epoch: 5| Step: 9
Training loss: 2.488278088051121
Validation loss: 2.528866344125657

Epoch: 5| Step: 10
Training loss: 2.369216100083326
Validation loss: 2.529148662058948

Epoch: 5| Step: 11
Training loss: 3.4784391331602436
Validation loss: 2.5299361158806795

Epoch: 81| Step: 0
Training loss: 3.027986007980613
Validation loss: 2.528861535900374

Epoch: 5| Step: 1
Training loss: 2.9084047922648155
Validation loss: 2.529901887269132

Epoch: 5| Step: 2
Training loss: 2.989865510142186
Validation loss: 2.5276154652616865

Epoch: 5| Step: 3
Training loss: 2.691653568326497
Validation loss: 2.5294336151904835

Epoch: 5| Step: 4
Training loss: 2.4637324855419958
Validation loss: 2.5259230923433478

Epoch: 5| Step: 5
Training loss: 2.92147318479188
Validation loss: 2.5265012355808723

Epoch: 5| Step: 6
Training loss: 2.3357475484210264
Validation loss: 2.5251588845387265

Epoch: 5| Step: 7
Training loss: 2.2561546495742286
Validation loss: 2.524067370024449

Epoch: 5| Step: 8
Training loss: 2.176032717844481
Validation loss: 2.525253543934231

Epoch: 5| Step: 9
Training loss: 2.551903377079012
Validation loss: 2.5230158088371244

Epoch: 5| Step: 10
Training loss: 2.6688917135809014
Validation loss: 2.5248961351768693

Epoch: 5| Step: 11
Training loss: 2.956724203840819
Validation loss: 2.5218817537856237

Epoch: 82| Step: 0
Training loss: 3.029756473033546
Validation loss: 2.521993454203933

Epoch: 5| Step: 1
Training loss: 2.3911785407388937
Validation loss: 2.5193485913366884

Epoch: 5| Step: 2
Training loss: 2.4747594774301542
Validation loss: 2.5241541794507607

Epoch: 5| Step: 3
Training loss: 2.603325323889505
Validation loss: 2.519593948254421

Epoch: 5| Step: 4
Training loss: 2.997993274917847
Validation loss: 2.5220360126643007

Epoch: 5| Step: 5
Training loss: 2.682197307420738
Validation loss: 2.522842900126768

Epoch: 5| Step: 6
Training loss: 3.016753464884976
Validation loss: 2.5211341470879054

Epoch: 5| Step: 7
Training loss: 2.629119546974834
Validation loss: 2.5203486494170657

Epoch: 5| Step: 8
Training loss: 2.4415742129722724
Validation loss: 2.5201829328694667

Epoch: 5| Step: 9
Training loss: 2.229556991297017
Validation loss: 2.518798339070681

Epoch: 5| Step: 10
Training loss: 2.5356076254565565
Validation loss: 2.525226085128264

Epoch: 5| Step: 11
Training loss: 2.9342914670971925
Validation loss: 2.5221844879927704

Epoch: 83| Step: 0
Training loss: 2.2389120707588317
Validation loss: 2.518970393563518

Epoch: 5| Step: 1
Training loss: 2.5688071437150675
Validation loss: 2.5275153013923943

Epoch: 5| Step: 2
Training loss: 2.963286985014141
Validation loss: 2.5200183328587378

Epoch: 5| Step: 3
Training loss: 2.684297116873934
Validation loss: 2.5236420130256274

Epoch: 5| Step: 4
Training loss: 2.5211770530061908
Validation loss: 2.517415300129492

Epoch: 5| Step: 5
Training loss: 2.5884951939750973
Validation loss: 2.5169782690904317

Epoch: 5| Step: 6
Training loss: 3.005446576085508
Validation loss: 2.519402221214658

Epoch: 5| Step: 7
Training loss: 2.5425956675067454
Validation loss: 2.5187045335412894

Epoch: 5| Step: 8
Training loss: 2.8135767253191823
Validation loss: 2.519975963054036

Epoch: 5| Step: 9
Training loss: 2.2256935967337794
Validation loss: 2.517428247426176

Epoch: 5| Step: 10
Training loss: 2.8378329917689595
Validation loss: 2.521559135260476

Epoch: 5| Step: 11
Training loss: 3.2966088644063936
Validation loss: 2.5211628837709217

Epoch: 84| Step: 0
Training loss: 2.596503485260227
Validation loss: 2.5230319087900726

Epoch: 5| Step: 1
Training loss: 1.961957385134079
Validation loss: 2.523035109868987

Epoch: 5| Step: 2
Training loss: 2.71482644933224
Validation loss: 2.5211945162032876

Epoch: 5| Step: 3
Training loss: 2.6802219936607368
Validation loss: 2.5186080857929998

Epoch: 5| Step: 4
Training loss: 2.6779328320707143
Validation loss: 2.518664985402066

Epoch: 5| Step: 5
Training loss: 2.869993743889666
Validation loss: 2.5168768846005727

Epoch: 5| Step: 6
Training loss: 2.4925809448015803
Validation loss: 2.516961341041942

Epoch: 5| Step: 7
Training loss: 2.89567858239043
Validation loss: 2.518234319329866

Epoch: 5| Step: 8
Training loss: 2.5951566443821106
Validation loss: 2.513071663825038

Epoch: 5| Step: 9
Training loss: 3.028015613450144
Validation loss: 2.511295668593553

Epoch: 5| Step: 10
Training loss: 2.5073777056582016
Validation loss: 2.5155603033240688

Epoch: 5| Step: 11
Training loss: 2.574668462946598
Validation loss: 2.515699839614071

Epoch: 85| Step: 0
Training loss: 3.3210201451794146
Validation loss: 2.5171181490638936

Epoch: 5| Step: 1
Training loss: 2.888754739662551
Validation loss: 2.5164801405841772

Epoch: 5| Step: 2
Training loss: 2.67280669448206
Validation loss: 2.515920001753956

Epoch: 5| Step: 3
Training loss: 2.744393442257462
Validation loss: 2.520051690497405

Epoch: 5| Step: 4
Training loss: 2.5984104983176417
Validation loss: 2.5190182382890796

Epoch: 5| Step: 5
Training loss: 2.345587556836429
Validation loss: 2.5215777264882777

Epoch: 5| Step: 6
Training loss: 1.9183969427588683
Validation loss: 2.5194111640168626

Epoch: 5| Step: 7
Training loss: 2.318712909741155
Validation loss: 2.519343725515226

Epoch: 5| Step: 8
Training loss: 2.796662732812284
Validation loss: 2.5213524754127254

Epoch: 5| Step: 9
Training loss: 2.608063876662805
Validation loss: 2.5173533842180134

Epoch: 5| Step: 10
Training loss: 2.6313014009579185
Validation loss: 2.5176113808119602

Epoch: 5| Step: 11
Training loss: 2.951529096875819
Validation loss: 2.516424814080958

Epoch: 86| Step: 0
Training loss: 2.7321312990487296
Validation loss: 2.5094611550976924

Epoch: 5| Step: 1
Training loss: 2.807762394342858
Validation loss: 2.5061303039595626

Epoch: 5| Step: 2
Training loss: 2.6455309737646604
Validation loss: 2.5083052645239685

Epoch: 5| Step: 3
Training loss: 2.2010396191620107
Validation loss: 2.5059889781932276

Epoch: 5| Step: 4
Training loss: 2.755777272624233
Validation loss: 2.5060173652856075

Epoch: 5| Step: 5
Training loss: 2.4787712957301333
Validation loss: 2.5164339609010935

Epoch: 5| Step: 6
Training loss: 2.7477005101105396
Validation loss: 2.5120903203043152

Epoch: 5| Step: 7
Training loss: 2.4886626665396756
Validation loss: 2.5150644258282413

Epoch: 5| Step: 8
Training loss: 2.877987843247241
Validation loss: 2.514153877685594

Epoch: 5| Step: 9
Training loss: 2.8368449795267647
Validation loss: 2.509462552504841

Epoch: 5| Step: 10
Training loss: 2.554538920803594
Validation loss: 2.503858767181735

Epoch: 5| Step: 11
Training loss: 2.436958839792092
Validation loss: 2.5072931482754175

Epoch: 87| Step: 0
Training loss: 2.7719089647897945
Validation loss: 2.505031545088896

Epoch: 5| Step: 1
Training loss: 2.617618172354447
Validation loss: 2.5055055118183733

Epoch: 5| Step: 2
Training loss: 2.028451253221121
Validation loss: 2.5123495137520844

Epoch: 5| Step: 3
Training loss: 3.014487254508264
Validation loss: 2.513353064256807

Epoch: 5| Step: 4
Training loss: 2.562208484722379
Validation loss: 2.5178598897823

Epoch: 5| Step: 5
Training loss: 2.8501874560897
Validation loss: 2.518779407862781

Epoch: 5| Step: 6
Training loss: 2.4117234635623683
Validation loss: 2.5167655294359896

Epoch: 5| Step: 7
Training loss: 2.598540145672542
Validation loss: 2.51609842019776

Epoch: 5| Step: 8
Training loss: 2.844666888642047
Validation loss: 2.5125576257818856

Epoch: 5| Step: 9
Training loss: 2.745403696889188
Validation loss: 2.515756325226006

Epoch: 5| Step: 10
Training loss: 2.385854411598903
Validation loss: 2.51590238743852

Epoch: 5| Step: 11
Training loss: 3.062629852656028
Validation loss: 2.5095398560144786

Epoch: 88| Step: 0
Training loss: 2.6533433157127626
Validation loss: 2.5147003859798995

Epoch: 5| Step: 1
Training loss: 2.711693298343492
Validation loss: 2.513854005623093

Epoch: 5| Step: 2
Training loss: 2.088665153930649
Validation loss: 2.5115818996929313

Epoch: 5| Step: 3
Training loss: 2.0386914613553646
Validation loss: 2.5115474446732913

Epoch: 5| Step: 4
Training loss: 2.664765296033926
Validation loss: 2.51333060982436

Epoch: 5| Step: 5
Training loss: 3.1107999517361575
Validation loss: 2.511358588279129

Epoch: 5| Step: 6
Training loss: 2.6628982819151505
Validation loss: 2.505510567075357

Epoch: 5| Step: 7
Training loss: 2.815221783453829
Validation loss: 2.5075048018232358

Epoch: 5| Step: 8
Training loss: 2.4321120942596766
Validation loss: 2.5053694323624245

Epoch: 5| Step: 9
Training loss: 2.4171624387639103
Validation loss: 2.5094784148028286

Epoch: 5| Step: 10
Training loss: 3.049403935956013
Validation loss: 2.508968574038239

Epoch: 5| Step: 11
Training loss: 3.232103370118195
Validation loss: 2.5029839192167387

Epoch: 89| Step: 0
Training loss: 2.7664341147095937
Validation loss: 2.5014202593731336

Epoch: 5| Step: 1
Training loss: 2.49189914482136
Validation loss: 2.500711995303669

Epoch: 5| Step: 2
Training loss: 2.071286299945117
Validation loss: 2.50384780093495

Epoch: 5| Step: 3
Training loss: 2.317851910090853
Validation loss: 2.496796438917244

Epoch: 5| Step: 4
Training loss: 2.90070856580178
Validation loss: 2.496497004753632

Epoch: 5| Step: 5
Training loss: 3.0321963691129596
Validation loss: 2.496065051053605

Epoch: 5| Step: 6
Training loss: 2.8751748073342416
Validation loss: 2.498372362698069

Epoch: 5| Step: 7
Training loss: 2.5457054214268164
Validation loss: 2.4989917231867023

Epoch: 5| Step: 8
Training loss: 2.1872270686318465
Validation loss: 2.4983740168099215

Epoch: 5| Step: 9
Training loss: 2.838497131184937
Validation loss: 2.5020791309161527

Epoch: 5| Step: 10
Training loss: 2.6424705782346827
Validation loss: 2.5010103925735363

Epoch: 5| Step: 11
Training loss: 2.5295926543392726
Validation loss: 2.4979849641916005

Epoch: 90| Step: 0
Training loss: 2.6325050423511347
Validation loss: 2.4994443911813176

Epoch: 5| Step: 1
Training loss: 2.7266387491576882
Validation loss: 2.503441170811298

Epoch: 5| Step: 2
Training loss: 2.9038039547870502
Validation loss: 2.5022579685371036

Epoch: 5| Step: 3
Training loss: 2.418196906201115
Validation loss: 2.5035619871001535

Epoch: 5| Step: 4
Training loss: 2.7352755562226703
Validation loss: 2.5038580490606765

Epoch: 5| Step: 5
Training loss: 2.687363465855247
Validation loss: 2.512751915070916

Epoch: 5| Step: 6
Training loss: 2.96085423979038
Validation loss: 2.5109122738127874

Epoch: 5| Step: 7
Training loss: 2.357926182821777
Validation loss: 2.5079225692282394

Epoch: 5| Step: 8
Training loss: 2.5475674489444606
Validation loss: 2.497987580956465

Epoch: 5| Step: 9
Training loss: 2.6945950202773
Validation loss: 2.5004926315356184

Epoch: 5| Step: 10
Training loss: 2.218861214442837
Validation loss: 2.499036134243118

Epoch: 5| Step: 11
Training loss: 1.7702786717629664
Validation loss: 2.499947424176822

Epoch: 91| Step: 0
Training loss: 2.4051609299521948
Validation loss: 2.5003266717151322

Epoch: 5| Step: 1
Training loss: 3.32984571792568
Validation loss: 2.5018176822098677

Epoch: 5| Step: 2
Training loss: 2.672900622094975
Validation loss: 2.5031594934837167

Epoch: 5| Step: 3
Training loss: 2.811073874133546
Validation loss: 2.503616724915729

Epoch: 5| Step: 4
Training loss: 2.6065200446210794
Validation loss: 2.503747134576035

Epoch: 5| Step: 5
Training loss: 2.1120231677142924
Validation loss: 2.5018184962147063

Epoch: 5| Step: 6
Training loss: 2.83917371146811
Validation loss: 2.500323238933793

Epoch: 5| Step: 7
Training loss: 2.1656436583580807
Validation loss: 2.4998427381326085

Epoch: 5| Step: 8
Training loss: 2.4803582114272587
Validation loss: 2.501943548036779

Epoch: 5| Step: 9
Training loss: 2.4739291754894954
Validation loss: 2.4993924793542552

Epoch: 5| Step: 10
Training loss: 2.62015030961174
Validation loss: 2.499406076454138

Epoch: 5| Step: 11
Training loss: 3.416740292631988
Validation loss: 2.4975201466752996

Epoch: 92| Step: 0
Training loss: 3.252490776453567
Validation loss: 2.492549969533518

Epoch: 5| Step: 1
Training loss: 2.819884883343655
Validation loss: 2.492746001576831

Epoch: 5| Step: 2
Training loss: 2.593869401872135
Validation loss: 2.492508093324337

Epoch: 5| Step: 3
Training loss: 2.767061194666518
Validation loss: 2.4910875601668563

Epoch: 5| Step: 4
Training loss: 2.5613342983211598
Validation loss: 2.492446160520945

Epoch: 5| Step: 5
Training loss: 2.231965052471226
Validation loss: 2.492363029684261

Epoch: 5| Step: 6
Training loss: 2.124630839875368
Validation loss: 2.493286185605046

Epoch: 5| Step: 7
Training loss: 2.243446236027628
Validation loss: 2.493443418761044

Epoch: 5| Step: 8
Training loss: 2.4834943446077116
Validation loss: 2.491795599726265

Epoch: 5| Step: 9
Training loss: 2.714838568593302
Validation loss: 2.4939981020058815

Epoch: 5| Step: 10
Training loss: 2.7289650723691823
Validation loss: 2.4946527037546655

Epoch: 5| Step: 11
Training loss: 2.420678809306833
Validation loss: 2.497135277376573

Epoch: 93| Step: 0
Training loss: 2.6142872697198722
Validation loss: 2.4951225265774273

Epoch: 5| Step: 1
Training loss: 2.63420796979145
Validation loss: 2.4926794278139646

Epoch: 5| Step: 2
Training loss: 2.6877923850761682
Validation loss: 2.4858619990173567

Epoch: 5| Step: 3
Training loss: 2.6517683930448306
Validation loss: 2.4912497570881817

Epoch: 5| Step: 4
Training loss: 2.5814114056017305
Validation loss: 2.494337330556599

Epoch: 5| Step: 5
Training loss: 2.491998360371548
Validation loss: 2.49255209381471

Epoch: 5| Step: 6
Training loss: 2.9609906435905304
Validation loss: 2.4913002037046725

Epoch: 5| Step: 7
Training loss: 2.2676733820027626
Validation loss: 2.4925749865162787

Epoch: 5| Step: 8
Training loss: 2.1183070076968122
Validation loss: 2.4920964797408325

Epoch: 5| Step: 9
Training loss: 1.9620998630676643
Validation loss: 2.487045124770427

Epoch: 5| Step: 10
Training loss: 3.2496563656409854
Validation loss: 2.488786862603455

Epoch: 5| Step: 11
Training loss: 3.3700498376890957
Validation loss: 2.487997213508

Epoch: 94| Step: 0
Training loss: 2.2723148890809917
Validation loss: 2.488834728763831

Epoch: 5| Step: 1
Training loss: 2.5040566909515096
Validation loss: 2.4903518190302454

Epoch: 5| Step: 2
Training loss: 2.742499613592352
Validation loss: 2.4954534514318927

Epoch: 5| Step: 3
Training loss: 2.532627531495177
Validation loss: 2.49545690683568

Epoch: 5| Step: 4
Training loss: 2.9515425059912066
Validation loss: 2.4961454399061984

Epoch: 5| Step: 5
Training loss: 2.976828095208531
Validation loss: 2.4974278291171528

Epoch: 5| Step: 6
Training loss: 2.8009580505836125
Validation loss: 2.4954181925047663

Epoch: 5| Step: 7
Training loss: 1.8480791249159418
Validation loss: 2.4953651061192885

Epoch: 5| Step: 8
Training loss: 2.5158755728515847
Validation loss: 2.496080493046077

Epoch: 5| Step: 9
Training loss: 2.5549661560205927
Validation loss: 2.5002584999272344

Epoch: 5| Step: 10
Training loss: 2.7761449359248576
Validation loss: 2.497450792478918

Epoch: 5| Step: 11
Training loss: 3.145276321377405
Validation loss: 2.4968399779052235

Epoch: 95| Step: 0
Training loss: 2.17003405372866
Validation loss: 2.4952828408908907

Epoch: 5| Step: 1
Training loss: 2.5336957818635133
Validation loss: 2.492497583309674

Epoch: 5| Step: 2
Training loss: 2.882681825565612
Validation loss: 2.4892775548643664

Epoch: 5| Step: 3
Training loss: 2.1173165482609235
Validation loss: 2.4905823029448464

Epoch: 5| Step: 4
Training loss: 3.086883940605567
Validation loss: 2.4858853329680186

Epoch: 5| Step: 5
Training loss: 2.5777312006889646
Validation loss: 2.488343078867162

Epoch: 5| Step: 6
Training loss: 2.130003480147263
Validation loss: 2.483785593343831

Epoch: 5| Step: 7
Training loss: 3.1000376299143153
Validation loss: 2.490222574841834

Epoch: 5| Step: 8
Training loss: 2.211433921052722
Validation loss: 2.4855323151197917

Epoch: 5| Step: 9
Training loss: 3.0703177803906567
Validation loss: 2.4885491706497618

Epoch: 5| Step: 10
Training loss: 2.697572772128937
Validation loss: 2.488573625076471

Epoch: 5| Step: 11
Training loss: 2.2310348834461475
Validation loss: 2.490334454688302

Epoch: 96| Step: 0
Training loss: 2.7656103446270417
Validation loss: 2.4866432495672224

Epoch: 5| Step: 1
Training loss: 2.5535021723941
Validation loss: 2.489948837764504

Epoch: 5| Step: 2
Training loss: 2.764280951683473
Validation loss: 2.4908220901588605

Epoch: 5| Step: 3
Training loss: 2.3149008788604695
Validation loss: 2.4883997583040203

Epoch: 5| Step: 4
Training loss: 2.8356647623026667
Validation loss: 2.4894432576461463

Epoch: 5| Step: 5
Training loss: 3.0297264124165135
Validation loss: 2.4900364177535317

Epoch: 5| Step: 6
Training loss: 2.238317892097542
Validation loss: 2.490213906197791

Epoch: 5| Step: 7
Training loss: 2.622351172836227
Validation loss: 2.48841700240974

Epoch: 5| Step: 8
Training loss: 2.5711093583353337
Validation loss: 2.4918927184770547

Epoch: 5| Step: 9
Training loss: 2.518557243449411
Validation loss: 2.4938963808074295

Epoch: 5| Step: 10
Training loss: 2.644044546759109
Validation loss: 2.4943623634654872

Epoch: 5| Step: 11
Training loss: 2.367718728262665
Validation loss: 2.4853849937124077

Epoch: 97| Step: 0
Training loss: 2.662755382629461
Validation loss: 2.484646700351097

Epoch: 5| Step: 1
Training loss: 2.3083097279944917
Validation loss: 2.4845476190509075

Epoch: 5| Step: 2
Training loss: 2.4309176063336575
Validation loss: 2.4863799300269327

Epoch: 5| Step: 3
Training loss: 2.566867920387672
Validation loss: 2.484643037999769

Epoch: 5| Step: 4
Training loss: 2.7543725018092857
Validation loss: 2.4867945590914298

Epoch: 5| Step: 5
Training loss: 2.80291334903302
Validation loss: 2.4841471513593514

Epoch: 5| Step: 6
Training loss: 2.575365288758943
Validation loss: 2.4879532083274567

Epoch: 5| Step: 7
Training loss: 2.533612973272307
Validation loss: 2.4862655707693713

Epoch: 5| Step: 8
Training loss: 2.892899891370965
Validation loss: 2.4840474022695105

Epoch: 5| Step: 9
Training loss: 2.6290791016841997
Validation loss: 2.484907041316654

Epoch: 5| Step: 10
Training loss: 2.5909303712959577
Validation loss: 2.486811480769132

Epoch: 5| Step: 11
Training loss: 1.5334392390096507
Validation loss: 2.4844822890429046

Epoch: 98| Step: 0
Training loss: 3.022317210587124
Validation loss: 2.487407696671139

Epoch: 5| Step: 1
Training loss: 2.644880128101992
Validation loss: 2.4830985838922564

Epoch: 5| Step: 2
Training loss: 2.4035682100854654
Validation loss: 2.482702776095002

Epoch: 5| Step: 3
Training loss: 2.8858362069603536
Validation loss: 2.4793661635670676

Epoch: 5| Step: 4
Training loss: 2.563479166665344
Validation loss: 2.4851102021040616

Epoch: 5| Step: 5
Training loss: 2.4531795228378113
Validation loss: 2.487967570688165

Epoch: 5| Step: 6
Training loss: 2.532891388875922
Validation loss: 2.4924321069529207

Epoch: 5| Step: 7
Training loss: 2.9941116401279704
Validation loss: 2.48593922920095

Epoch: 5| Step: 8
Training loss: 2.3309012635412976
Validation loss: 2.4786990964301756

Epoch: 5| Step: 9
Training loss: 2.691745243952983
Validation loss: 2.482939779429357

Epoch: 5| Step: 10
Training loss: 1.9669257295101246
Validation loss: 2.4818327890343475

Epoch: 5| Step: 11
Training loss: 1.9474292560112625
Validation loss: 2.486929202285221

Epoch: 99| Step: 0
Training loss: 2.3150783289929002
Validation loss: 2.483788015090359

Epoch: 5| Step: 1
Training loss: 2.5602349295703872
Validation loss: 2.4873864577688467

Epoch: 5| Step: 2
Training loss: 2.6350110210499476
Validation loss: 2.4895053329911208

Epoch: 5| Step: 3
Training loss: 2.7500081495684463
Validation loss: 2.4918429496266095

Epoch: 5| Step: 4
Training loss: 3.1493615245133357
Validation loss: 2.497933105550404

Epoch: 5| Step: 5
Training loss: 2.7542328769345126
Validation loss: 2.5010577666180054

Epoch: 5| Step: 6
Training loss: 2.5428754610684634
Validation loss: 2.5084615998302278

Epoch: 5| Step: 7
Training loss: 2.0640697863188127
Validation loss: 2.5083700017899715

Epoch: 5| Step: 8
Training loss: 2.4999948501533873
Validation loss: 2.510611246938834

Epoch: 5| Step: 9
Training loss: 2.810410040943507
Validation loss: 2.5061461358178736

Epoch: 5| Step: 10
Training loss: 2.475163398512251
Validation loss: 2.498458086795376

Epoch: 5| Step: 11
Training loss: 3.054086299184057
Validation loss: 2.4933186338836255

Epoch: 100| Step: 0
Training loss: 2.6600654575353597
Validation loss: 2.4895973497791575

Epoch: 5| Step: 1
Training loss: 2.4593187609280713
Validation loss: 2.4887359459207326

Epoch: 5| Step: 2
Training loss: 2.9056289173279515
Validation loss: 2.484822998599886

Epoch: 5| Step: 3
Training loss: 2.3923092562575774
Validation loss: 2.482814482649501

Epoch: 5| Step: 4
Training loss: 2.428974108209734
Validation loss: 2.4831055010754848

Epoch: 5| Step: 5
Training loss: 3.0078595838948705
Validation loss: 2.4763002908649163

Epoch: 5| Step: 6
Training loss: 2.7829606870834613
Validation loss: 2.480130786850356

Epoch: 5| Step: 7
Training loss: 2.565560629777097
Validation loss: 2.4801626061575743

Epoch: 5| Step: 8
Training loss: 2.1406626454405355
Validation loss: 2.481904322799137

Epoch: 5| Step: 9
Training loss: 2.371200131790322
Validation loss: 2.4770285832669807

Epoch: 5| Step: 10
Training loss: 2.898009893333339
Validation loss: 2.480893068240467

Epoch: 5| Step: 11
Training loss: 2.0473855815958464
Validation loss: 2.481309118615551

Epoch: 101| Step: 0
Training loss: 2.2422371569727253
Validation loss: 2.4816618005125433

Epoch: 5| Step: 1
Training loss: 2.764234462669876
Validation loss: 2.481925356451816

Epoch: 5| Step: 2
Training loss: 1.6887019786317796
Validation loss: 2.479101498065185

Epoch: 5| Step: 3
Training loss: 2.3163635352894003
Validation loss: 2.47920074292547

Epoch: 5| Step: 4
Training loss: 2.765844045466771
Validation loss: 2.4755793323717152

Epoch: 5| Step: 5
Training loss: 2.5650944485294707
Validation loss: 2.484114227364213

Epoch: 5| Step: 6
Training loss: 3.0392040229539785
Validation loss: 2.482435945220378

Epoch: 5| Step: 7
Training loss: 3.0482442273492247
Validation loss: 2.483163438229526

Epoch: 5| Step: 8
Training loss: 2.693935053370319
Validation loss: 2.4768781932098243

Epoch: 5| Step: 9
Training loss: 2.727187557769037
Validation loss: 2.479490653006625

Epoch: 5| Step: 10
Training loss: 2.5582135332949814
Validation loss: 2.4775356703191083

Epoch: 5| Step: 11
Training loss: 1.3497034418251417
Validation loss: 2.4830812768473693

Epoch: 102| Step: 0
Training loss: 2.253323008477899
Validation loss: 2.480815416676495

Epoch: 5| Step: 1
Training loss: 2.4771591093655636
Validation loss: 2.4753561561580097

Epoch: 5| Step: 2
Training loss: 2.878736141567357
Validation loss: 2.4772532890563106

Epoch: 5| Step: 3
Training loss: 2.719011228442113
Validation loss: 2.4753502687817863

Epoch: 5| Step: 4
Training loss: 2.248285275966755
Validation loss: 2.4806838135087816

Epoch: 5| Step: 5
Training loss: 2.456700919890339
Validation loss: 2.478835714246176

Epoch: 5| Step: 6
Training loss: 2.6262224166707075
Validation loss: 2.4831085135847712

Epoch: 5| Step: 7
Training loss: 2.8222372403416913
Validation loss: 2.4782842473498854

Epoch: 5| Step: 8
Training loss: 2.7100837528476367
Validation loss: 2.4811379999143104

Epoch: 5| Step: 9
Training loss: 2.516533728955797
Validation loss: 2.477366871376534

Epoch: 5| Step: 10
Training loss: 2.5537960818740815
Validation loss: 2.4847555568814728

Epoch: 5| Step: 11
Training loss: 3.0189416860057796
Validation loss: 2.4791405914174884

Epoch: 103| Step: 0
Training loss: 2.4873668002403644
Validation loss: 2.4770978736022915

Epoch: 5| Step: 1
Training loss: 3.1069539675118767
Validation loss: 2.4732383296008322

Epoch: 5| Step: 2
Training loss: 2.331261180206571
Validation loss: 2.4761589275021003

Epoch: 5| Step: 3
Training loss: 2.714509748592076
Validation loss: 2.476228204060296

Epoch: 5| Step: 4
Training loss: 2.297667801201147
Validation loss: 2.476971360882292

Epoch: 5| Step: 5
Training loss: 2.680476303334547
Validation loss: 2.476734747046133

Epoch: 5| Step: 6
Training loss: 2.996099638653356
Validation loss: 2.47691262915988

Epoch: 5| Step: 7
Training loss: 2.1414448080171695
Validation loss: 2.4816123228632394

Epoch: 5| Step: 8
Training loss: 2.404561230453185
Validation loss: 2.4796387492761776

Epoch: 5| Step: 9
Training loss: 2.572809276321636
Validation loss: 2.4849265184162292

Epoch: 5| Step: 10
Training loss: 2.6952955162508387
Validation loss: 2.4880134122973545

Epoch: 5| Step: 11
Training loss: 1.3822987350976899
Validation loss: 2.4790321775763733

Epoch: 104| Step: 0
Training loss: 2.5459626792935257
Validation loss: 2.483973724619151

Epoch: 5| Step: 1
Training loss: 2.5185895239205696
Validation loss: 2.4854231248906515

Epoch: 5| Step: 2
Training loss: 2.1110583335012483
Validation loss: 2.484208063398982

Epoch: 5| Step: 3
Training loss: 2.410081364536331
Validation loss: 2.484207855456009

Epoch: 5| Step: 4
Training loss: 2.944049108904206
Validation loss: 2.484276391717505

Epoch: 5| Step: 5
Training loss: 2.2369901918103294
Validation loss: 2.479596466720262

Epoch: 5| Step: 6
Training loss: 2.4121072993095827
Validation loss: 2.4789457276145592

Epoch: 5| Step: 7
Training loss: 2.450284248522928
Validation loss: 2.486394812884979

Epoch: 5| Step: 8
Training loss: 3.250764170085883
Validation loss: 2.4857266266116627

Epoch: 5| Step: 9
Training loss: 2.8115976369539872
Validation loss: 2.4802680066996965

Epoch: 5| Step: 10
Training loss: 2.6696591474725913
Validation loss: 2.4827702015530018

Epoch: 5| Step: 11
Training loss: 1.7799239325610898
Validation loss: 2.480440739350847

Epoch: 105| Step: 0
Training loss: 2.81553096635387
Validation loss: 2.4862842221315766

Epoch: 5| Step: 1
Training loss: 2.316239606707374
Validation loss: 2.4775807105646037

Epoch: 5| Step: 2
Training loss: 2.816589942052688
Validation loss: 2.4757731610791267

Epoch: 5| Step: 3
Training loss: 2.2025813520910744
Validation loss: 2.481529589706483

Epoch: 5| Step: 4
Training loss: 2.543014315007969
Validation loss: 2.4779429915279407

Epoch: 5| Step: 5
Training loss: 2.811289887236484
Validation loss: 2.4779849655461406

Epoch: 5| Step: 6
Training loss: 2.8316850542710488
Validation loss: 2.4775184046077405

Epoch: 5| Step: 7
Training loss: 2.0268925806083544
Validation loss: 2.480867849367636

Epoch: 5| Step: 8
Training loss: 2.720857351605042
Validation loss: 2.4788287731253447

Epoch: 5| Step: 9
Training loss: 2.4575919525856644
Validation loss: 2.476962316993623

Epoch: 5| Step: 10
Training loss: 2.721841129131652
Validation loss: 2.472778437821067

Epoch: 5| Step: 11
Training loss: 2.4558609205374293
Validation loss: 2.4752521357564183

Epoch: 106| Step: 0
Training loss: 2.5229555974886706
Validation loss: 2.4699432390624265

Epoch: 5| Step: 1
Training loss: 2.7167439568725222
Validation loss: 2.472909264578878

Epoch: 5| Step: 2
Training loss: 2.6435946407617616
Validation loss: 2.4745115177001855

Epoch: 5| Step: 3
Training loss: 2.938472667931118
Validation loss: 2.4737351782022063

Epoch: 5| Step: 4
Training loss: 2.772095433429559
Validation loss: 2.4681480716107718

Epoch: 5| Step: 5
Training loss: 2.26128967115398
Validation loss: 2.476940679706903

Epoch: 5| Step: 6
Training loss: 2.377301155383186
Validation loss: 2.470507020668966

Epoch: 5| Step: 7
Training loss: 2.446354945470112
Validation loss: 2.4713587236647134

Epoch: 5| Step: 8
Training loss: 2.699286850596012
Validation loss: 2.4702360654101456

Epoch: 5| Step: 9
Training loss: 2.83597566773343
Validation loss: 2.468427109829061

Epoch: 5| Step: 10
Training loss: 2.191221069562768
Validation loss: 2.4704776826918633

Epoch: 5| Step: 11
Training loss: 2.6023264270252855
Validation loss: 2.4711106035958523

Epoch: 107| Step: 0
Training loss: 2.9994598538191592
Validation loss: 2.472230345257857

Epoch: 5| Step: 1
Training loss: 2.599627442444024
Validation loss: 2.473327127879019

Epoch: 5| Step: 2
Training loss: 2.116708060733407
Validation loss: 2.4717148228578014

Epoch: 5| Step: 3
Training loss: 1.9763918113135848
Validation loss: 2.4762215244209935

Epoch: 5| Step: 4
Training loss: 2.7506921070652552
Validation loss: 2.475765890368935

Epoch: 5| Step: 5
Training loss: 2.636490423418431
Validation loss: 2.473981778217789

Epoch: 5| Step: 6
Training loss: 2.456428004990411
Validation loss: 2.4750485531061504

Epoch: 5| Step: 7
Training loss: 2.405438967672484
Validation loss: 2.472563747385217

Epoch: 5| Step: 8
Training loss: 2.659337033853596
Validation loss: 2.4697673407592418

Epoch: 5| Step: 9
Training loss: 2.8617162239465546
Validation loss: 2.472117670190334

Epoch: 5| Step: 10
Training loss: 2.6234809476561565
Validation loss: 2.4764634241930192

Epoch: 5| Step: 11
Training loss: 2.7877168374335386
Validation loss: 2.474860455853022

Epoch: 108| Step: 0
Training loss: 2.8877529413318754
Validation loss: 2.4774933478609014

Epoch: 5| Step: 1
Training loss: 2.093265989925226
Validation loss: 2.4681204061432425

Epoch: 5| Step: 2
Training loss: 2.868097062281364
Validation loss: 2.469964847153675

Epoch: 5| Step: 3
Training loss: 2.5840025516946197
Validation loss: 2.4650464868772497

Epoch: 5| Step: 4
Training loss: 2.414199578303715
Validation loss: 2.467736152716479

Epoch: 5| Step: 5
Training loss: 2.808224458781897
Validation loss: 2.474530643052694

Epoch: 5| Step: 6
Training loss: 2.8930188963002967
Validation loss: 2.4630960453935073

Epoch: 5| Step: 7
Training loss: 2.294171877115053
Validation loss: 2.4682140613637578

Epoch: 5| Step: 8
Training loss: 2.7827794016819394
Validation loss: 2.4619021911617334

Epoch: 5| Step: 9
Training loss: 2.066235598348378
Validation loss: 2.4690728922029237

Epoch: 5| Step: 10
Training loss: 2.3990287921699482
Validation loss: 2.4695976870292213

Epoch: 5| Step: 11
Training loss: 3.0381664533990844
Validation loss: 2.472401329105672

Epoch: 109| Step: 0
Training loss: 2.466009042901183
Validation loss: 2.472011359529207

Epoch: 5| Step: 1
Training loss: 2.753622703293962
Validation loss: 2.477480163796341

Epoch: 5| Step: 2
Training loss: 2.3826332900398057
Validation loss: 2.4885708427289037

Epoch: 5| Step: 3
Training loss: 2.2925592475980983
Validation loss: 2.481432633841095

Epoch: 5| Step: 4
Training loss: 2.478246266884341
Validation loss: 2.48335355477346

Epoch: 5| Step: 5
Training loss: 2.62352329679585
Validation loss: 2.483223166251618

Epoch: 5| Step: 6
Training loss: 2.3679980410554875
Validation loss: 2.4862320395195407

Epoch: 5| Step: 7
Training loss: 2.9284061325423796
Validation loss: 2.4876975548153992

Epoch: 5| Step: 8
Training loss: 2.610358869354719
Validation loss: 2.476845353076077

Epoch: 5| Step: 9
Training loss: 2.907804668073648
Validation loss: 2.483570280441169

Epoch: 5| Step: 10
Training loss: 2.6398254628717917
Validation loss: 2.4776072419453343

Epoch: 5| Step: 11
Training loss: 2.794511446350757
Validation loss: 2.475774039822455

Epoch: 110| Step: 0
Training loss: 2.543354995388642
Validation loss: 2.475932962847652

Epoch: 5| Step: 1
Training loss: 2.634301282545886
Validation loss: 2.476438693733564

Epoch: 5| Step: 2
Training loss: 2.5446225368673163
Validation loss: 2.4733742770711604

Epoch: 5| Step: 3
Training loss: 2.519312649492141
Validation loss: 2.4761829225729306

Epoch: 5| Step: 4
Training loss: 2.289293297078561
Validation loss: 2.4726230002403

Epoch: 5| Step: 5
Training loss: 2.695898904450079
Validation loss: 2.4726118191247095

Epoch: 5| Step: 6
Training loss: 2.4542889597484474
Validation loss: 2.4705698975036987

Epoch: 5| Step: 7
Training loss: 2.86018501857032
Validation loss: 2.4625671501008295

Epoch: 5| Step: 8
Training loss: 2.3421668236896953
Validation loss: 2.462497852295457

Epoch: 5| Step: 9
Training loss: 2.4312222162929364
Validation loss: 2.4717993233176867

Epoch: 5| Step: 10
Training loss: 2.909851795630523
Validation loss: 2.4826300548997993

Epoch: 5| Step: 11
Training loss: 2.11992195597533
Validation loss: 2.4832391601559407

Epoch: 111| Step: 0
Training loss: 2.6984571605290855
Validation loss: 2.4753235265936264

Epoch: 5| Step: 1
Training loss: 2.5909957970099624
Validation loss: 2.47268640581156

Epoch: 5| Step: 2
Training loss: 2.5894404078533984
Validation loss: 2.471953124826391

Epoch: 5| Step: 3
Training loss: 2.7669259152877435
Validation loss: 2.468749468839564

Epoch: 5| Step: 4
Training loss: 1.8697070755237435
Validation loss: 2.47239605547562

Epoch: 5| Step: 5
Training loss: 2.374757955163341
Validation loss: 2.4763407001191515

Epoch: 5| Step: 6
Training loss: 2.4297299887324417
Validation loss: 2.4826553158931675

Epoch: 5| Step: 7
Training loss: 2.197780647106674
Validation loss: 2.4767562838530788

Epoch: 5| Step: 8
Training loss: 2.6681026129141943
Validation loss: 2.473108749406954

Epoch: 5| Step: 9
Training loss: 2.9922585740375727
Validation loss: 2.4718300241010884

Epoch: 5| Step: 10
Training loss: 2.8150918673876837
Validation loss: 2.475535475638568

Epoch: 5| Step: 11
Training loss: 2.2905183400383953
Validation loss: 2.4674017439710085

Epoch: 112| Step: 0
Training loss: 2.5324513916291376
Validation loss: 2.479941340567974

Epoch: 5| Step: 1
Training loss: 2.380228010523378
Validation loss: 2.480691193946675

Epoch: 5| Step: 2
Training loss: 2.167978867515806
Validation loss: 2.4751291067955217

Epoch: 5| Step: 3
Training loss: 2.567827037571895
Validation loss: 2.4749973477725065

Epoch: 5| Step: 4
Training loss: 2.2084745565878605
Validation loss: 2.4747496748054183

Epoch: 5| Step: 5
Training loss: 2.7420096923912807
Validation loss: 2.47397305266703

Epoch: 5| Step: 6
Training loss: 2.743569485020294
Validation loss: 2.473419352930956

Epoch: 5| Step: 7
Training loss: 2.6577931129246344
Validation loss: 2.473349236580094

Epoch: 5| Step: 8
Training loss: 2.549662930519471
Validation loss: 2.470267366724474

Epoch: 5| Step: 9
Training loss: 2.7218558449843084
Validation loss: 2.4747439545826264

Epoch: 5| Step: 10
Training loss: 2.682113839091008
Validation loss: 2.472499113227369

Epoch: 5| Step: 11
Training loss: 3.261208792470353
Validation loss: 2.473021851359133

Epoch: 113| Step: 0
Training loss: 2.7271058161551642
Validation loss: 2.4754063447695227

Epoch: 5| Step: 1
Training loss: 2.536776596457736
Validation loss: 2.478081420909715

Epoch: 5| Step: 2
Training loss: 2.448747361373064
Validation loss: 2.4767106269637598

Epoch: 5| Step: 3
Training loss: 2.7305796413797347
Validation loss: 2.4765801414078026

Epoch: 5| Step: 4
Training loss: 2.622996246690061
Validation loss: 2.479239011291337

Epoch: 5| Step: 5
Training loss: 2.359476655702733
Validation loss: 2.492536817283205

Epoch: 5| Step: 6
Training loss: 2.892894287140023
Validation loss: 2.4950052473883275

Epoch: 5| Step: 7
Training loss: 2.2073003284187784
Validation loss: 2.5024729914959183

Epoch: 5| Step: 8
Training loss: 2.4040465732068212
Validation loss: 2.5035877431869547

Epoch: 5| Step: 9
Training loss: 2.671753908503049
Validation loss: 2.508274610176313

Epoch: 5| Step: 10
Training loss: 2.9155300832265016
Validation loss: 2.4985807284329806

Epoch: 5| Step: 11
Training loss: 2.606682947730743
Validation loss: 2.499449661397632

Epoch: 114| Step: 0
Training loss: 2.5256777052181434
Validation loss: 2.507200976608188

Epoch: 5| Step: 1
Training loss: 2.662985933760173
Validation loss: 2.5075248165049904

Epoch: 5| Step: 2
Training loss: 3.008843896571091
Validation loss: 2.5148306554062527

Epoch: 5| Step: 3
Training loss: 2.799493001267899
Validation loss: 2.5131291591771463

Epoch: 5| Step: 4
Training loss: 2.6953413367456496
Validation loss: 2.5046042621446567

Epoch: 5| Step: 5
Training loss: 2.672616153116304
Validation loss: 2.5056794860921783

Epoch: 5| Step: 6
Training loss: 2.4218744093371254
Validation loss: 2.4947249351182967

Epoch: 5| Step: 7
Training loss: 2.314143653492372
Validation loss: 2.4923395291857227

Epoch: 5| Step: 8
Training loss: 2.236472898902836
Validation loss: 2.4831428311284878

Epoch: 5| Step: 9
Training loss: 2.7732010861495766
Validation loss: 2.4816143204023327

Epoch: 5| Step: 10
Training loss: 2.6510157455845866
Validation loss: 2.4755542439595772

Epoch: 5| Step: 11
Training loss: 1.7879345932417923
Validation loss: 2.4758818339841593

Epoch: 115| Step: 0
Training loss: 2.194584084211252
Validation loss: 2.4741043623273256

Epoch: 5| Step: 1
Training loss: 2.2897020299363793
Validation loss: 2.4715921564075773

Epoch: 5| Step: 2
Training loss: 2.8095630994378644
Validation loss: 2.4604029806619407

Epoch: 5| Step: 3
Training loss: 2.426901443498495
Validation loss: 2.464362744907083

Epoch: 5| Step: 4
Training loss: 2.6864761353921414
Validation loss: 2.4644282575711016

Epoch: 5| Step: 5
Training loss: 2.5291021205787474
Validation loss: 2.4649664983800563

Epoch: 5| Step: 6
Training loss: 2.6045957186431954
Validation loss: 2.4590406706821915

Epoch: 5| Step: 7
Training loss: 2.610343342263993
Validation loss: 2.464660536964109

Epoch: 5| Step: 8
Training loss: 2.721160872072656
Validation loss: 2.460186515743883

Epoch: 5| Step: 9
Training loss: 2.63524291379204
Validation loss: 2.4604938288795184

Epoch: 5| Step: 10
Training loss: 2.7969277659292398
Validation loss: 2.463401449029142

Epoch: 5| Step: 11
Training loss: 1.682452104632136
Validation loss: 2.467938796897418

Epoch: 116| Step: 0
Training loss: 2.518407952721919
Validation loss: 2.4660413062647075

Epoch: 5| Step: 1
Training loss: 2.589556786014152
Validation loss: 2.4727514086949336

Epoch: 5| Step: 2
Training loss: 1.9573908492602028
Validation loss: 2.4727319160442693

Epoch: 5| Step: 3
Training loss: 2.759922074447963
Validation loss: 2.4674955049755325

Epoch: 5| Step: 4
Training loss: 3.0766130016050943
Validation loss: 2.4640457304337726

Epoch: 5| Step: 5
Training loss: 2.588555523370283
Validation loss: 2.4694574807064567

Epoch: 5| Step: 6
Training loss: 2.601040166249197
Validation loss: 2.468931102950698

Epoch: 5| Step: 7
Training loss: 2.8858570263211565
Validation loss: 2.4653571471271416

Epoch: 5| Step: 8
Training loss: 2.3457037348432803
Validation loss: 2.469633141627807

Epoch: 5| Step: 9
Training loss: 2.340364885328412
Validation loss: 2.477490649303519

Epoch: 5| Step: 10
Training loss: 2.2655704886357104
Validation loss: 2.4784907065948323

Epoch: 5| Step: 11
Training loss: 2.277399759274533
Validation loss: 2.4791869488589042

Epoch: 117| Step: 0
Training loss: 2.1435778223409874
Validation loss: 2.4748309326546436

Epoch: 5| Step: 1
Training loss: 2.563018002140616
Validation loss: 2.47207584168005

Epoch: 5| Step: 2
Training loss: 2.5882134232642473
Validation loss: 2.4705634116575035

Epoch: 5| Step: 3
Training loss: 2.50174671188204
Validation loss: 2.4752062825573127

Epoch: 5| Step: 4
Training loss: 2.2031126630721736
Validation loss: 2.4723550955614075

Epoch: 5| Step: 5
Training loss: 2.6268320502419304
Validation loss: 2.467644218480388

Epoch: 5| Step: 6
Training loss: 2.6935364109691924
Validation loss: 2.460880755219368

Epoch: 5| Step: 7
Training loss: 2.1316317129761475
Validation loss: 2.471093614602163

Epoch: 5| Step: 8
Training loss: 3.247577351154765
Validation loss: 2.463513946108413

Epoch: 5| Step: 9
Training loss: 2.441600187609604
Validation loss: 2.4664505619567096

Epoch: 5| Step: 10
Training loss: 2.5340443010861007
Validation loss: 2.472024046322357

Epoch: 5| Step: 11
Training loss: 3.564040804491315
Validation loss: 2.471366582155278

Epoch: 118| Step: 0
Training loss: 2.8760944439444756
Validation loss: 2.4738535380336897

Epoch: 5| Step: 1
Training loss: 2.4242109293047793
Validation loss: 2.4731953310982013

Epoch: 5| Step: 2
Training loss: 2.2618747584903334
Validation loss: 2.477811793080543

Epoch: 5| Step: 3
Training loss: 2.2498301335957342
Validation loss: 2.479609058616119

Epoch: 5| Step: 4
Training loss: 3.0091408706808744
Validation loss: 2.475100325307475

Epoch: 5| Step: 5
Training loss: 2.2966551383531497
Validation loss: 2.478648409381534

Epoch: 5| Step: 6
Training loss: 2.472444015964539
Validation loss: 2.480916308778477

Epoch: 5| Step: 7
Training loss: 2.0612034045540164
Validation loss: 2.4832242383824927

Epoch: 5| Step: 8
Training loss: 2.8794806022646444
Validation loss: 2.4856666470137543

Epoch: 5| Step: 9
Training loss: 2.6774515771983975
Validation loss: 2.485783719386024

Epoch: 5| Step: 10
Training loss: 2.75782590003716
Validation loss: 2.483449875627282

Epoch: 5| Step: 11
Training loss: 3.7783923739978045
Validation loss: 2.4817139551316987

Epoch: 119| Step: 0
Training loss: 2.05598646521659
Validation loss: 2.4750566246478205

Epoch: 5| Step: 1
Training loss: 3.1105951570133588
Validation loss: 2.477373742409536

Epoch: 5| Step: 2
Training loss: 2.1591175196344756
Validation loss: 2.474391924691089

Epoch: 5| Step: 3
Training loss: 2.6733280268717143
Validation loss: 2.470733421250505

Epoch: 5| Step: 4
Training loss: 2.4110677470083792
Validation loss: 2.4689013559485136

Epoch: 5| Step: 5
Training loss: 2.459166261764936
Validation loss: 2.4672889289195483

Epoch: 5| Step: 6
Training loss: 2.8331364020928764
Validation loss: 2.4614468022282363

Epoch: 5| Step: 7
Training loss: 2.825559010518773
Validation loss: 2.4650119617293154

Epoch: 5| Step: 8
Training loss: 2.126273951409571
Validation loss: 2.4604186545505833

Epoch: 5| Step: 9
Training loss: 2.8597595289811752
Validation loss: 2.4604812602824535

Epoch: 5| Step: 10
Training loss: 2.5141039686653355
Validation loss: 2.464597426739917

Epoch: 5| Step: 11
Training loss: 1.8923380003596029
Validation loss: 2.4642398455137338

Epoch: 120| Step: 0
Training loss: 2.6353618832248067
Validation loss: 2.4700111716901976

Epoch: 5| Step: 1
Training loss: 3.257011626164572
Validation loss: 2.471254468674865

Epoch: 5| Step: 2
Training loss: 2.636752206095616
Validation loss: 2.4669494823329012

Epoch: 5| Step: 3
Training loss: 2.839065885987937
Validation loss: 2.47149909947455

Epoch: 5| Step: 4
Training loss: 2.202547471122661
Validation loss: 2.476067221743302

Epoch: 5| Step: 5
Training loss: 2.586810100190155
Validation loss: 2.4705820287648548

Epoch: 5| Step: 6
Training loss: 2.224920691459017
Validation loss: 2.4577930767361322

Epoch: 5| Step: 7
Training loss: 1.9603609856195385
Validation loss: 2.4597814357395427

Epoch: 5| Step: 8
Training loss: 2.4879157787554176
Validation loss: 2.459093353547189

Epoch: 5| Step: 9
Training loss: 2.8876393338229085
Validation loss: 2.455699905647282

Epoch: 5| Step: 10
Training loss: 2.411643090527213
Validation loss: 2.461298666796272

Epoch: 5| Step: 11
Training loss: 2.062799836530045
Validation loss: 2.4663120617914824

Epoch: 121| Step: 0
Training loss: 2.262704163502326
Validation loss: 2.4654378200274887

Epoch: 5| Step: 1
Training loss: 2.5183005942491468
Validation loss: 2.4657401637783893

Epoch: 5| Step: 2
Training loss: 2.033267266602033
Validation loss: 2.4652568150615584

Epoch: 5| Step: 3
Training loss: 2.7686532892770024
Validation loss: 2.464545867218098

Epoch: 5| Step: 4
Training loss: 2.31554212743649
Validation loss: 2.4649800959628854

Epoch: 5| Step: 5
Training loss: 3.010243570351781
Validation loss: 2.4628613858727206

Epoch: 5| Step: 6
Training loss: 2.523039417341461
Validation loss: 2.4640565593537405

Epoch: 5| Step: 7
Training loss: 2.435914135050709
Validation loss: 2.4689932192331683

Epoch: 5| Step: 8
Training loss: 2.929674804659993
Validation loss: 2.464049050474421

Epoch: 5| Step: 9
Training loss: 2.5705185085862774
Validation loss: 2.4717090473820185

Epoch: 5| Step: 10
Training loss: 2.4872627030099133
Validation loss: 2.4688147282866906

Epoch: 5| Step: 11
Training loss: 3.0704212120941543
Validation loss: 2.470190943526742

Epoch: 122| Step: 0
Training loss: 2.545241317549868
Validation loss: 2.475391299529724

Epoch: 5| Step: 1
Training loss: 2.223869971158522
Validation loss: 2.468866691567779

Epoch: 5| Step: 2
Training loss: 2.6028285339718984
Validation loss: 2.469007329768202

Epoch: 5| Step: 3
Training loss: 2.522106658241168
Validation loss: 2.4735099359357364

Epoch: 5| Step: 4
Training loss: 2.882980879334851
Validation loss: 2.474843063099104

Epoch: 5| Step: 5
Training loss: 2.1443295687980384
Validation loss: 2.481145611223847

Epoch: 5| Step: 6
Training loss: 2.559410931494523
Validation loss: 2.475901743190796

Epoch: 5| Step: 7
Training loss: 2.3048148427147024
Validation loss: 2.4819219502529832

Epoch: 5| Step: 8
Training loss: 2.5998663427771005
Validation loss: 2.476586198342393

Epoch: 5| Step: 9
Training loss: 2.641533509116467
Validation loss: 2.474055632970037

Epoch: 5| Step: 10
Training loss: 2.802283316546321
Validation loss: 2.4731843614399187

Epoch: 5| Step: 11
Training loss: 3.1904056245744687
Validation loss: 2.4702959572038887

Epoch: 123| Step: 0
Training loss: 2.2611475406037567
Validation loss: 2.4689068120736852

Epoch: 5| Step: 1
Training loss: 2.7155101369922496
Validation loss: 2.4712883659475775

Epoch: 5| Step: 2
Training loss: 2.555973767416097
Validation loss: 2.4672247424222915

Epoch: 5| Step: 3
Training loss: 2.59883052126867
Validation loss: 2.4687653673876744

Epoch: 5| Step: 4
Training loss: 2.5045029142046373
Validation loss: 2.4649935967489234

Epoch: 5| Step: 5
Training loss: 2.5667210680493144
Validation loss: 2.471960374601236

Epoch: 5| Step: 6
Training loss: 2.9140788632667256
Validation loss: 2.46976378103469

Epoch: 5| Step: 7
Training loss: 2.7408438757182085
Validation loss: 2.4757902102490323

Epoch: 5| Step: 8
Training loss: 2.364353611300048
Validation loss: 2.465734583809094

Epoch: 5| Step: 9
Training loss: 2.6741148723160335
Validation loss: 2.47592701264654

Epoch: 5| Step: 10
Training loss: 1.975171108318216
Validation loss: 2.472356532022696

Epoch: 5| Step: 11
Training loss: 3.1569775035637826
Validation loss: 2.469642892156558

Epoch: 124| Step: 0
Training loss: 2.261026279733715
Validation loss: 2.46688062173818

Epoch: 5| Step: 1
Training loss: 2.7183737658922675
Validation loss: 2.468701764532867

Epoch: 5| Step: 2
Training loss: 2.6718452853508037
Validation loss: 2.472606222521454

Epoch: 5| Step: 3
Training loss: 2.398011011233593
Validation loss: 2.4759350973734944

Epoch: 5| Step: 4
Training loss: 2.8741397399909276
Validation loss: 2.4738943004686984

Epoch: 5| Step: 5
Training loss: 2.811022561160879
Validation loss: 2.480654820148989

Epoch: 5| Step: 6
Training loss: 2.446107290371189
Validation loss: 2.4713265658982184

Epoch: 5| Step: 7
Training loss: 2.4837982659912936
Validation loss: 2.4717509383662204

Epoch: 5| Step: 8
Training loss: 2.328918526612959
Validation loss: 2.4720187296919116

Epoch: 5| Step: 9
Training loss: 2.562085187878953
Validation loss: 2.4767055570437826

Epoch: 5| Step: 10
Training loss: 2.57080796866576
Validation loss: 2.473638246140986

Epoch: 5| Step: 11
Training loss: 2.14928738516702
Validation loss: 2.4661817229149205

Epoch: 125| Step: 0
Training loss: 2.3014725325041563
Validation loss: 2.46539751009848

Epoch: 5| Step: 1
Training loss: 2.5576704150090848
Validation loss: 2.4677061940531853

Epoch: 5| Step: 2
Training loss: 2.6007111677156423
Validation loss: 2.4635323785737153

Epoch: 5| Step: 3
Training loss: 2.1326387774802376
Validation loss: 2.464948298297032

Epoch: 5| Step: 4
Training loss: 2.322933476363004
Validation loss: 2.4617543454322184

Epoch: 5| Step: 5
Training loss: 2.5704718543283143
Validation loss: 2.452716837981955

Epoch: 5| Step: 6
Training loss: 2.733930802368837
Validation loss: 2.4604579195854273

Epoch: 5| Step: 7
Training loss: 2.797476251005353
Validation loss: 2.4542983057589756

Epoch: 5| Step: 8
Training loss: 2.846620222095454
Validation loss: 2.466752862122359

Epoch: 5| Step: 9
Training loss: 2.716557726011664
Validation loss: 2.4599539592745407

Epoch: 5| Step: 10
Training loss: 2.354810936014303
Validation loss: 2.471298122005006

Epoch: 5| Step: 11
Training loss: 1.7217754439081174
Validation loss: 2.470307832440433

Testing loss: 2.02099126839796
