Epoch: 1| Step: 0
Training loss: 6.631976790512942
Validation loss: 5.938581950339837

Epoch: 5| Step: 1
Training loss: 5.776087089706239
Validation loss: 5.937095387375375

Epoch: 5| Step: 2
Training loss: 5.721016856688304
Validation loss: 5.935655963376844

Epoch: 5| Step: 3
Training loss: 6.515465164968497
Validation loss: 5.934229261106312

Epoch: 5| Step: 4
Training loss: 6.907153040331349
Validation loss: 5.932757950147628

Epoch: 5| Step: 5
Training loss: 5.881818993962189
Validation loss: 5.931196842417663

Epoch: 5| Step: 6
Training loss: 4.605203687240833
Validation loss: 5.929647727836278

Epoch: 5| Step: 7
Training loss: 5.697734636912795
Validation loss: 5.928079989484786

Epoch: 5| Step: 8
Training loss: 5.897269713145235
Validation loss: 5.926386682188969

Epoch: 5| Step: 9
Training loss: 6.340343443897362
Validation loss: 5.9247039171004126

Epoch: 5| Step: 10
Training loss: 5.697750705159408
Validation loss: 5.92291402969901

Epoch: 5| Step: 11
Training loss: 8.271490601015957
Validation loss: 5.921157565311761

Epoch: 2| Step: 0
Training loss: 5.31293422943883
Validation loss: 5.919230230359711

Epoch: 5| Step: 1
Training loss: 6.810072440099613
Validation loss: 5.917282007572576

Epoch: 5| Step: 2
Training loss: 5.360158434846425
Validation loss: 5.915376168761068

Epoch: 5| Step: 3
Training loss: 6.599997503106772
Validation loss: 5.91336322851412

Epoch: 5| Step: 4
Training loss: 6.339931597897222
Validation loss: 5.911288041898345

Epoch: 5| Step: 5
Training loss: 5.157908409911818
Validation loss: 5.909124115759461

Epoch: 5| Step: 6
Training loss: 5.565438169655977
Validation loss: 5.906877904814632

Epoch: 5| Step: 7
Training loss: 5.584980489206685
Validation loss: 5.904635328089446

Epoch: 5| Step: 8
Training loss: 5.802510198463375
Validation loss: 5.902195091908519

Epoch: 5| Step: 9
Training loss: 6.540961095902151
Validation loss: 5.899693046817906

Epoch: 5| Step: 10
Training loss: 6.540734518257875
Validation loss: 5.896991058916405

Epoch: 5| Step: 11
Training loss: 7.5454196197938215
Validation loss: 5.894224407888152

Epoch: 3| Step: 0
Training loss: 6.281089059466456
Validation loss: 5.891393258937435

Epoch: 5| Step: 1
Training loss: 6.088239320199193
Validation loss: 5.888344813300671

Epoch: 5| Step: 2
Training loss: 6.212606030793169
Validation loss: 5.885057498021158

Epoch: 5| Step: 3
Training loss: 6.671499344481567
Validation loss: 5.881790214156915

Epoch: 5| Step: 4
Training loss: 5.693773100855306
Validation loss: 5.87835863843244

Epoch: 5| Step: 5
Training loss: 5.750126712895592
Validation loss: 5.87472981988272

Epoch: 5| Step: 6
Training loss: 5.808997955316652
Validation loss: 5.8708361215722435

Epoch: 5| Step: 7
Training loss: 5.016361741000857
Validation loss: 5.866947343553045

Epoch: 5| Step: 8
Training loss: 5.2895269598504155
Validation loss: 5.862938959244108

Epoch: 5| Step: 9
Training loss: 6.7753433309462086
Validation loss: 5.858687283317454

Epoch: 5| Step: 10
Training loss: 5.99875755161733
Validation loss: 5.85412040592618

Epoch: 5| Step: 11
Training loss: 6.299921477297728
Validation loss: 5.849487785727235

Epoch: 4| Step: 0
Training loss: 5.862666067931233
Validation loss: 5.844490038410275

Epoch: 5| Step: 1
Training loss: 6.0675223085978045
Validation loss: 5.839279552410359

Epoch: 5| Step: 2
Training loss: 6.305510929227962
Validation loss: 5.833842591354057

Epoch: 5| Step: 3
Training loss: 5.579786891901267
Validation loss: 5.828187834781923

Epoch: 5| Step: 4
Training loss: 6.121538079158689
Validation loss: 5.822262615214597

Epoch: 5| Step: 5
Training loss: 6.294525844178205
Validation loss: 5.815589370905372

Epoch: 5| Step: 6
Training loss: 5.628734959280042
Validation loss: 5.809302363113444

Epoch: 5| Step: 7
Training loss: 5.759872916727044
Validation loss: 5.802286383079583

Epoch: 5| Step: 8
Training loss: 5.631925600362417
Validation loss: 5.795303549870622

Epoch: 5| Step: 9
Training loss: 5.417211456289869
Validation loss: 5.7878740251602645

Epoch: 5| Step: 10
Training loss: 6.475867442347734
Validation loss: 5.779923020392522

Epoch: 5| Step: 11
Training loss: 5.817185676978125
Validation loss: 5.771721529404757

Epoch: 5| Step: 0
Training loss: 5.713725566657382
Validation loss: 5.763250080645057

Epoch: 5| Step: 1
Training loss: 5.857039247985402
Validation loss: 5.754799532863596

Epoch: 5| Step: 2
Training loss: 4.850753151530694
Validation loss: 5.7459836560734

Epoch: 5| Step: 3
Training loss: 5.553348685736041
Validation loss: 5.736663077765404

Epoch: 5| Step: 4
Training loss: 5.624605292141202
Validation loss: 5.727180145803461

Epoch: 5| Step: 5
Training loss: 6.407224106581034
Validation loss: 5.717336775353152

Epoch: 5| Step: 6
Training loss: 6.203150213464187
Validation loss: 5.707300004455785

Epoch: 5| Step: 7
Training loss: 6.001537126101659
Validation loss: 5.696984344398415

Epoch: 5| Step: 8
Training loss: 6.423582866251483
Validation loss: 5.686357201704568

Epoch: 5| Step: 9
Training loss: 5.218006378006171
Validation loss: 5.675756312204155

Epoch: 5| Step: 10
Training loss: 6.089734128463335
Validation loss: 5.664752751527333

Epoch: 5| Step: 11
Training loss: 5.697766103853224
Validation loss: 5.653680509311273

Epoch: 6| Step: 0
Training loss: 5.575777815542063
Validation loss: 5.643089291526523

Epoch: 5| Step: 1
Training loss: 6.369325693033411
Validation loss: 5.631917218342281

Epoch: 5| Step: 2
Training loss: 5.522890487411234
Validation loss: 5.620815076673459

Epoch: 5| Step: 3
Training loss: 5.79483925992256
Validation loss: 5.609809809048711

Epoch: 5| Step: 4
Training loss: 5.251746477549457
Validation loss: 5.598525702743172

Epoch: 5| Step: 5
Training loss: 5.802368851033797
Validation loss: 5.587343656954058

Epoch: 5| Step: 6
Training loss: 4.955233248581903
Validation loss: 5.576423007812677

Epoch: 5| Step: 7
Training loss: 5.946306303478249
Validation loss: 5.565507033145811

Epoch: 5| Step: 8
Training loss: 5.890792722869189
Validation loss: 5.554698745565928

Epoch: 5| Step: 9
Training loss: 6.102494602099402
Validation loss: 5.543607768599949

Epoch: 5| Step: 10
Training loss: 5.467365547414288
Validation loss: 5.533340583455648

Epoch: 5| Step: 11
Training loss: 5.340529157159129
Validation loss: 5.522583682817944

Epoch: 7| Step: 0
Training loss: 5.144846565472188
Validation loss: 5.512193356128492

Epoch: 5| Step: 1
Training loss: 5.363661583780911
Validation loss: 5.501671443179435

Epoch: 5| Step: 2
Training loss: 5.814449516605364
Validation loss: 5.491763732102506

Epoch: 5| Step: 3
Training loss: 5.157315785626365
Validation loss: 5.481664032850892

Epoch: 5| Step: 4
Training loss: 6.46317334679284
Validation loss: 5.471973137853268

Epoch: 5| Step: 5
Training loss: 5.037872694441612
Validation loss: 5.461888344663978

Epoch: 5| Step: 6
Training loss: 5.78870072566449
Validation loss: 5.452329743409184

Epoch: 5| Step: 7
Training loss: 6.714711665640271
Validation loss: 5.442350847346727

Epoch: 5| Step: 8
Training loss: 5.119209367682758
Validation loss: 5.432723406431528

Epoch: 5| Step: 9
Training loss: 5.146248660398971
Validation loss: 5.4231289852676205

Epoch: 5| Step: 10
Training loss: 5.410226406923274
Validation loss: 5.414179835073294

Epoch: 5| Step: 11
Training loss: 5.18509829892422
Validation loss: 5.405063079903471

Epoch: 8| Step: 0
Training loss: 5.507885568553444
Validation loss: 5.396149065164881

Epoch: 5| Step: 1
Training loss: 5.19292708394974
Validation loss: 5.38777342483809

Epoch: 5| Step: 2
Training loss: 5.8927626234789
Validation loss: 5.379307410804397

Epoch: 5| Step: 3
Training loss: 4.951878339638018
Validation loss: 5.371201437130697

Epoch: 5| Step: 4
Training loss: 5.429234679296969
Validation loss: 5.3632381481004785

Epoch: 5| Step: 5
Training loss: 5.843247988756379
Validation loss: 5.355938253451809

Epoch: 5| Step: 6
Training loss: 4.21447175287268
Validation loss: 5.348493838795937

Epoch: 5| Step: 7
Training loss: 5.59219713873724
Validation loss: 5.341558196543053

Epoch: 5| Step: 8
Training loss: 5.877695642068498
Validation loss: 5.334924537496807

Epoch: 5| Step: 9
Training loss: 5.512552329440007
Validation loss: 5.328479177089641

Epoch: 5| Step: 10
Training loss: 5.802879329117639
Validation loss: 5.322224158262584

Epoch: 5| Step: 11
Training loss: 6.410349357713622
Validation loss: 5.315343148370804

Epoch: 9| Step: 0
Training loss: 4.765053236384778
Validation loss: 5.308939035773254

Epoch: 5| Step: 1
Training loss: 5.5806010758627
Validation loss: 5.302860497835886

Epoch: 5| Step: 2
Training loss: 5.307600567045045
Validation loss: 5.29627667764045

Epoch: 5| Step: 3
Training loss: 4.673550614671932
Validation loss: 5.290469847775849

Epoch: 5| Step: 4
Training loss: 5.2482613000482345
Validation loss: 5.284619672763064

Epoch: 5| Step: 5
Training loss: 6.3754038963275566
Validation loss: 5.278795345267306

Epoch: 5| Step: 6
Training loss: 5.421148861677638
Validation loss: 5.272631962793208

Epoch: 5| Step: 7
Training loss: 5.425489820174613
Validation loss: 5.266890025784552

Epoch: 5| Step: 8
Training loss: 4.96264907267091
Validation loss: 5.261556629004612

Epoch: 5| Step: 9
Training loss: 5.350867812461409
Validation loss: 5.255647709616315

Epoch: 5| Step: 10
Training loss: 5.925539518491551
Validation loss: 5.249925764255344

Epoch: 5| Step: 11
Training loss: 6.111409894786931
Validation loss: 5.244847463735895

Epoch: 10| Step: 0
Training loss: 5.4618221325012115
Validation loss: 5.2392435159574084

Epoch: 5| Step: 1
Training loss: 4.537842263168201
Validation loss: 5.234040753524766

Epoch: 5| Step: 2
Training loss: 4.944655243645974
Validation loss: 5.228510339235758

Epoch: 5| Step: 3
Training loss: 5.6087702263096935
Validation loss: 5.223371526659244

Epoch: 5| Step: 4
Training loss: 5.6779728837072865
Validation loss: 5.21810963217694

Epoch: 5| Step: 5
Training loss: 5.414736575044443
Validation loss: 5.212560466717523

Epoch: 5| Step: 6
Training loss: 5.56083911573987
Validation loss: 5.207529618875993

Epoch: 5| Step: 7
Training loss: 5.842546798133405
Validation loss: 5.2024365829813854

Epoch: 5| Step: 8
Training loss: 5.1845043678997405
Validation loss: 5.197009979042728

Epoch: 5| Step: 9
Training loss: 5.2993696521687506
Validation loss: 5.191889701857041

Epoch: 5| Step: 10
Training loss: 4.991517883189265
Validation loss: 5.186670926496004

Epoch: 5| Step: 11
Training loss: 5.50263636432645
Validation loss: 5.181986364320428

Epoch: 11| Step: 0
Training loss: 6.220553802662301
Validation loss: 5.177040125502175

Epoch: 5| Step: 1
Training loss: 5.929094649320055
Validation loss: 5.172149819931407

Epoch: 5| Step: 2
Training loss: 5.5643667453369146
Validation loss: 5.167044612945645

Epoch: 5| Step: 3
Training loss: 5.5676345273137615
Validation loss: 5.161767854722089

Epoch: 5| Step: 4
Training loss: 4.995987999149566
Validation loss: 5.156818327745876

Epoch: 5| Step: 5
Training loss: 5.177732533123965
Validation loss: 5.151928225273993

Epoch: 5| Step: 6
Training loss: 3.8654841823725477
Validation loss: 5.147019356434703

Epoch: 5| Step: 7
Training loss: 5.366940688409485
Validation loss: 5.142218021196763

Epoch: 5| Step: 8
Training loss: 4.719882046147024
Validation loss: 5.138168319954471

Epoch: 5| Step: 9
Training loss: 5.212965449128136
Validation loss: 5.133752877050621

Epoch: 5| Step: 10
Training loss: 5.084886199067852
Validation loss: 5.128871812048698

Epoch: 5| Step: 11
Training loss: 5.138507998444027
Validation loss: 5.124417946490481

Epoch: 12| Step: 0
Training loss: 5.864826565492841
Validation loss: 5.119716153472424

Epoch: 5| Step: 1
Training loss: 5.8910303760549025
Validation loss: 5.115344869423568

Epoch: 5| Step: 2
Training loss: 4.385426984157189
Validation loss: 5.110877124410719

Epoch: 5| Step: 3
Training loss: 5.955936118598665
Validation loss: 5.106149524461265

Epoch: 5| Step: 4
Training loss: 5.476763102602782
Validation loss: 5.1016718495884845

Epoch: 5| Step: 5
Training loss: 4.981521411427413
Validation loss: 5.096916337959497

Epoch: 5| Step: 6
Training loss: 4.600286076813636
Validation loss: 5.092067581080392

Epoch: 5| Step: 7
Training loss: 5.057739091351641
Validation loss: 5.087788234859252

Epoch: 5| Step: 8
Training loss: 5.055520980958938
Validation loss: 5.082955481864188

Epoch: 5| Step: 9
Training loss: 5.17647880028262
Validation loss: 5.078244291029247

Epoch: 5| Step: 10
Training loss: 4.928174060100798
Validation loss: 5.073934435985563

Epoch: 5| Step: 11
Training loss: 4.10181012087349
Validation loss: 5.069309419491439

Epoch: 13| Step: 0
Training loss: 5.251879582682849
Validation loss: 5.064733714961459

Epoch: 5| Step: 1
Training loss: 4.316053612574929
Validation loss: 5.059792999725202

Epoch: 5| Step: 2
Training loss: 5.831745403870646
Validation loss: 5.055428955160446

Epoch: 5| Step: 3
Training loss: 5.16738946022246
Validation loss: 5.050753635410661

Epoch: 5| Step: 4
Training loss: 6.0163186998564315
Validation loss: 5.046268997578693

Epoch: 5| Step: 5
Training loss: 4.896632785320678
Validation loss: 5.041508769355504

Epoch: 5| Step: 6
Training loss: 4.6797804273953725
Validation loss: 5.036685448002885

Epoch: 5| Step: 7
Training loss: 4.97913814946179
Validation loss: 5.0325407974754865

Epoch: 5| Step: 8
Training loss: 5.244136260473044
Validation loss: 5.027492043798555

Epoch: 5| Step: 9
Training loss: 5.10345545374498
Validation loss: 5.023176282356933

Epoch: 5| Step: 10
Training loss: 5.274410175052956
Validation loss: 5.018706130948067

Epoch: 5| Step: 11
Training loss: 4.313248721378203
Validation loss: 5.014196539070234

Epoch: 14| Step: 0
Training loss: 5.263007263236567
Validation loss: 5.009978850885398

Epoch: 5| Step: 1
Training loss: 5.038395327381089
Validation loss: 5.004932489908436

Epoch: 5| Step: 2
Training loss: 4.611817621137016
Validation loss: 5.000278965797215

Epoch: 5| Step: 3
Training loss: 5.054750515811795
Validation loss: 4.995291408112064

Epoch: 5| Step: 4
Training loss: 4.861393254887132
Validation loss: 4.991086397636825

Epoch: 5| Step: 5
Training loss: 5.657040366913659
Validation loss: 4.9862309810122385

Epoch: 5| Step: 6
Training loss: 5.0017014469580205
Validation loss: 4.981432796747473

Epoch: 5| Step: 7
Training loss: 5.116053704606984
Validation loss: 4.976835913061729

Epoch: 5| Step: 8
Training loss: 5.1819100653184655
Validation loss: 4.972097241069924

Epoch: 5| Step: 9
Training loss: 5.476332111383042
Validation loss: 4.967735498852269

Epoch: 5| Step: 10
Training loss: 4.728914542626547
Validation loss: 4.963203509387574

Epoch: 5| Step: 11
Training loss: 5.722349607825415
Validation loss: 4.9589939345209695

Epoch: 15| Step: 0
Training loss: 5.554160563910819
Validation loss: 4.953406782187587

Epoch: 5| Step: 1
Training loss: 5.017353461177968
Validation loss: 4.948466198838686

Epoch: 5| Step: 2
Training loss: 5.374286338091675
Validation loss: 4.94343666308636

Epoch: 5| Step: 3
Training loss: 5.178029250904032
Validation loss: 4.9386022359527475

Epoch: 5| Step: 4
Training loss: 5.374390501019282
Validation loss: 4.9339006398472485

Epoch: 5| Step: 5
Training loss: 4.8428353707410485
Validation loss: 4.9293816295753485

Epoch: 5| Step: 6
Training loss: 5.1074657547708755
Validation loss: 4.924643578517366

Epoch: 5| Step: 7
Training loss: 4.175573188587055
Validation loss: 4.919753902284171

Epoch: 5| Step: 8
Training loss: 5.183449876135411
Validation loss: 4.915331071819401

Epoch: 5| Step: 9
Training loss: 4.78946712707459
Validation loss: 4.910472000882793

Epoch: 5| Step: 10
Training loss: 4.832080985748483
Validation loss: 4.90537975068738

Epoch: 5| Step: 11
Training loss: 5.223598398097749
Validation loss: 4.901555749549875

Epoch: 16| Step: 0
Training loss: 4.589950131745884
Validation loss: 4.896123993815034

Epoch: 5| Step: 1
Training loss: 5.2373737911777525
Validation loss: 4.892144053601401

Epoch: 5| Step: 2
Training loss: 4.886346767791601
Validation loss: 4.886958079038649

Epoch: 5| Step: 3
Training loss: 5.261992245641234
Validation loss: 4.882430067217515

Epoch: 5| Step: 4
Training loss: 5.1577495821882895
Validation loss: 4.8776411743172225

Epoch: 5| Step: 5
Training loss: 4.449318419990394
Validation loss: 4.87281164137949

Epoch: 5| Step: 6
Training loss: 4.659719518643976
Validation loss: 4.86790403885191

Epoch: 5| Step: 7
Training loss: 5.525331423386007
Validation loss: 4.8635053835776585

Epoch: 5| Step: 8
Training loss: 4.990499052728904
Validation loss: 4.858426270269417

Epoch: 5| Step: 9
Training loss: 5.117955646664076
Validation loss: 4.853966838450953

Epoch: 5| Step: 10
Training loss: 4.963029555500794
Validation loss: 4.8491659751656035

Epoch: 5| Step: 11
Training loss: 5.159330430465048
Validation loss: 4.845219895667988

Epoch: 17| Step: 0
Training loss: 4.848150014514033
Validation loss: 4.840566216364923

Epoch: 5| Step: 1
Training loss: 5.139991790824301
Validation loss: 4.8352976937088785

Epoch: 5| Step: 2
Training loss: 5.388298085305184
Validation loss: 4.830130916542968

Epoch: 5| Step: 3
Training loss: 5.307763355421773
Validation loss: 4.82621283663682

Epoch: 5| Step: 4
Training loss: 4.878099678750946
Validation loss: 4.821397392400883

Epoch: 5| Step: 5
Training loss: 3.987951969374027
Validation loss: 4.817038604649212

Epoch: 5| Step: 6
Training loss: 5.252166845839732
Validation loss: 4.812343545327411

Epoch: 5| Step: 7
Training loss: 4.666300327817494
Validation loss: 4.807313460951226

Epoch: 5| Step: 8
Training loss: 4.913893267654319
Validation loss: 4.802783181365364

Epoch: 5| Step: 9
Training loss: 4.95325322993025
Validation loss: 4.798729131265204

Epoch: 5| Step: 10
Training loss: 4.8998225199417895
Validation loss: 4.793829664673347

Epoch: 5| Step: 11
Training loss: 4.9049245416745695
Validation loss: 4.789538718147551

Epoch: 18| Step: 0
Training loss: 4.646053953306627
Validation loss: 4.78507510992272

Epoch: 5| Step: 1
Training loss: 5.3078655897196825
Validation loss: 4.780719569750344

Epoch: 5| Step: 2
Training loss: 5.092973521207402
Validation loss: 4.776546558357268

Epoch: 5| Step: 3
Training loss: 4.825953714464156
Validation loss: 4.772136221586804

Epoch: 5| Step: 4
Training loss: 4.7789516534748495
Validation loss: 4.76716132909609

Epoch: 5| Step: 5
Training loss: 5.0481939806658245
Validation loss: 4.763055919798162

Epoch: 5| Step: 6
Training loss: 4.290984510014636
Validation loss: 4.7584704866479095

Epoch: 5| Step: 7
Training loss: 5.069983520180067
Validation loss: 4.753759402261524

Epoch: 5| Step: 8
Training loss: 4.830237262971827
Validation loss: 4.749338815079948

Epoch: 5| Step: 9
Training loss: 5.294921154555466
Validation loss: 4.744740309648444

Epoch: 5| Step: 10
Training loss: 4.505345031193245
Validation loss: 4.740763870045966

Epoch: 5| Step: 11
Training loss: 4.820707580104395
Validation loss: 4.735873548578703

Epoch: 19| Step: 0
Training loss: 4.405044498976585
Validation loss: 4.731392268095761

Epoch: 5| Step: 1
Training loss: 5.496010807498706
Validation loss: 4.7270302028816875

Epoch: 5| Step: 2
Training loss: 4.962014293202637
Validation loss: 4.722680053146111

Epoch: 5| Step: 3
Training loss: 4.688028534655911
Validation loss: 4.717949182459586

Epoch: 5| Step: 4
Training loss: 5.337203270840681
Validation loss: 4.713458768280719

Epoch: 5| Step: 5
Training loss: 5.2102015488898035
Validation loss: 4.708792759696366

Epoch: 5| Step: 6
Training loss: 4.697700692884419
Validation loss: 4.704260138885827

Epoch: 5| Step: 7
Training loss: 5.234179683855974
Validation loss: 4.699622834743634

Epoch: 5| Step: 8
Training loss: 5.033008149781461
Validation loss: 4.694924810888785

Epoch: 5| Step: 9
Training loss: 3.8004568026185135
Validation loss: 4.689926231633767

Epoch: 5| Step: 10
Training loss: 4.411179618933372
Validation loss: 4.685715127849614

Epoch: 5| Step: 11
Training loss: 2.629454148944021
Validation loss: 4.680983273250339

Epoch: 20| Step: 0
Training loss: 4.462906651708094
Validation loss: 4.676178616003794

Epoch: 5| Step: 1
Training loss: 4.754960531718757
Validation loss: 4.672205127632377

Epoch: 5| Step: 2
Training loss: 4.2097904716778585
Validation loss: 4.6681648245136875

Epoch: 5| Step: 3
Training loss: 4.458549755702213
Validation loss: 4.663259418982014

Epoch: 5| Step: 4
Training loss: 5.011876116427949
Validation loss: 4.658603013932667

Epoch: 5| Step: 5
Training loss: 4.604811449198112
Validation loss: 4.654236992031758

Epoch: 5| Step: 6
Training loss: 5.0136174732878285
Validation loss: 4.6502185219858925

Epoch: 5| Step: 7
Training loss: 4.618832987244993
Validation loss: 4.645769301288263

Epoch: 5| Step: 8
Training loss: 5.397297762341446
Validation loss: 4.641607255515501

Epoch: 5| Step: 9
Training loss: 5.482293497450451
Validation loss: 4.636843166808502

Epoch: 5| Step: 10
Training loss: 4.276863468326875
Validation loss: 4.6322967002000075

Epoch: 5| Step: 11
Training loss: 5.283819532837096
Validation loss: 4.628001948576847

Epoch: 21| Step: 0
Training loss: 4.428595837292887
Validation loss: 4.624143478194256

Epoch: 5| Step: 1
Training loss: 5.093239226212498
Validation loss: 4.619308217014543

Epoch: 5| Step: 2
Training loss: 4.823944355809799
Validation loss: 4.613906404546329

Epoch: 5| Step: 3
Training loss: 4.717003707615793
Validation loss: 4.610184980875145

Epoch: 5| Step: 4
Training loss: 4.846743735252058
Validation loss: 4.605031129398396

Epoch: 5| Step: 5
Training loss: 5.41939608936168
Validation loss: 4.600173783820486

Epoch: 5| Step: 6
Training loss: 4.281060430408975
Validation loss: 4.595853795236301

Epoch: 5| Step: 7
Training loss: 4.597791075046298
Validation loss: 4.59134638869917

Epoch: 5| Step: 8
Training loss: 4.467913782802511
Validation loss: 4.587043156687706

Epoch: 5| Step: 9
Training loss: 3.730799667300797
Validation loss: 4.582475428774636

Epoch: 5| Step: 10
Training loss: 5.173524345791188
Validation loss: 4.578071203338866

Epoch: 5| Step: 11
Training loss: 5.633501537151809
Validation loss: 4.57370146821657

Epoch: 22| Step: 0
Training loss: 5.002289247968066
Validation loss: 4.569420551957752

Epoch: 5| Step: 1
Training loss: 4.547669226636592
Validation loss: 4.565020217892519

Epoch: 5| Step: 2
Training loss: 4.285759326153183
Validation loss: 4.560583156139142

Epoch: 5| Step: 3
Training loss: 5.431432385998363
Validation loss: 4.555953393534222

Epoch: 5| Step: 4
Training loss: 5.187770238984205
Validation loss: 4.551152711041654

Epoch: 5| Step: 5
Training loss: 5.383137420459265
Validation loss: 4.54663395543138

Epoch: 5| Step: 6
Training loss: 4.275810405813715
Validation loss: 4.542234834368176

Epoch: 5| Step: 7
Training loss: 4.23748394898382
Validation loss: 4.537568661228943

Epoch: 5| Step: 8
Training loss: 3.9600821931574224
Validation loss: 4.532980121615248

Epoch: 5| Step: 9
Training loss: 4.630039871406663
Validation loss: 4.528434404816076

Epoch: 5| Step: 10
Training loss: 4.2795404515485576
Validation loss: 4.523921521193915

Epoch: 5| Step: 11
Training loss: 4.300047878619824
Validation loss: 4.519988814666434

Epoch: 23| Step: 0
Training loss: 4.846646925419442
Validation loss: 4.516059199030776

Epoch: 5| Step: 1
Training loss: 4.591771952027216
Validation loss: 4.511701452268879

Epoch: 5| Step: 2
Training loss: 4.76902794584156
Validation loss: 4.507445445507249

Epoch: 5| Step: 3
Training loss: 5.408205064722928
Validation loss: 4.502875041002709

Epoch: 5| Step: 4
Training loss: 4.64456246047125
Validation loss: 4.498297007059414

Epoch: 5| Step: 5
Training loss: 4.097371836084048
Validation loss: 4.494260867865915

Epoch: 5| Step: 6
Training loss: 4.451286498565282
Validation loss: 4.489962562540895

Epoch: 5| Step: 7
Training loss: 4.439270740795497
Validation loss: 4.485651665233983

Epoch: 5| Step: 8
Training loss: 4.320582017545427
Validation loss: 4.481570475605148

Epoch: 5| Step: 9
Training loss: 4.721171181091297
Validation loss: 4.477044377513245

Epoch: 5| Step: 10
Training loss: 4.373204762111811
Validation loss: 4.472752030636674

Epoch: 5| Step: 11
Training loss: 4.946934438554393
Validation loss: 4.468549168126459

Epoch: 24| Step: 0
Training loss: 4.275057804542265
Validation loss: 4.464401672673812

Epoch: 5| Step: 1
Training loss: 4.275437913740304
Validation loss: 4.460084752373786

Epoch: 5| Step: 2
Training loss: 4.909616857990116
Validation loss: 4.45583024422176

Epoch: 5| Step: 3
Training loss: 4.831869802653515
Validation loss: 4.451712539374137

Epoch: 5| Step: 4
Training loss: 4.592611574033481
Validation loss: 4.4473192214249195

Epoch: 5| Step: 5
Training loss: 4.281864317097086
Validation loss: 4.443240942861346

Epoch: 5| Step: 6
Training loss: 3.426499120819322
Validation loss: 4.438876793627014

Epoch: 5| Step: 7
Training loss: 5.615348504274947
Validation loss: 4.4347104899782925

Epoch: 5| Step: 8
Training loss: 4.262933909237436
Validation loss: 4.4305779819591935

Epoch: 5| Step: 9
Training loss: 4.586290180220556
Validation loss: 4.426671893878421

Epoch: 5| Step: 10
Training loss: 4.655225807556056
Validation loss: 4.422262401707118

Epoch: 5| Step: 11
Training loss: 5.693696722960126
Validation loss: 4.417605645154772

Epoch: 25| Step: 0
Training loss: 4.813643678785188
Validation loss: 4.413409330490671

Epoch: 5| Step: 1
Training loss: 4.2668984995879775
Validation loss: 4.409159076539705

Epoch: 5| Step: 2
Training loss: 4.32065860955393
Validation loss: 4.404828290887057

Epoch: 5| Step: 3
Training loss: 4.483196887997208
Validation loss: 4.400091642812559

Epoch: 5| Step: 4
Training loss: 4.678476422092996
Validation loss: 4.395700238760614

Epoch: 5| Step: 5
Training loss: 4.838513700351712
Validation loss: 4.3913051716427685

Epoch: 5| Step: 6
Training loss: 4.340426923435706
Validation loss: 4.3867996221953165

Epoch: 5| Step: 7
Training loss: 4.299018020283318
Validation loss: 4.3823303301953676

Epoch: 5| Step: 8
Training loss: 5.256522713389238
Validation loss: 4.378123975486372

Epoch: 5| Step: 9
Training loss: 4.42904222420646
Validation loss: 4.373502874800038

Epoch: 5| Step: 10
Training loss: 4.046238911837144
Validation loss: 4.368903471834631

Epoch: 5| Step: 11
Training loss: 3.558325211979504
Validation loss: 4.364722104776039

Epoch: 26| Step: 0
Training loss: 4.1001060006930246
Validation loss: 4.360558238725607

Epoch: 5| Step: 1
Training loss: 4.821044866239571
Validation loss: 4.356277012205363

Epoch: 5| Step: 2
Training loss: 4.581088308106484
Validation loss: 4.352054524756235

Epoch: 5| Step: 3
Training loss: 4.039945701385305
Validation loss: 4.347878943101282

Epoch: 5| Step: 4
Training loss: 4.8846683972980705
Validation loss: 4.343463101506323

Epoch: 5| Step: 5
Training loss: 4.680671703030745
Validation loss: 4.339377450599365

Epoch: 5| Step: 6
Training loss: 4.054511799616267
Validation loss: 4.3348865919447395

Epoch: 5| Step: 7
Training loss: 4.581418255764576
Validation loss: 4.330782124036327

Epoch: 5| Step: 8
Training loss: 4.787293448113413
Validation loss: 4.326486490834935

Epoch: 5| Step: 9
Training loss: 4.4373222637848455
Validation loss: 4.3221803965025325

Epoch: 5| Step: 10
Training loss: 3.799316876897622
Validation loss: 4.317960369023062

Epoch: 5| Step: 11
Training loss: 5.533299298162614
Validation loss: 4.313537486680096

Epoch: 27| Step: 0
Training loss: 4.827551353967694
Validation loss: 4.309224174539714

Epoch: 5| Step: 1
Training loss: 4.584680648215115
Validation loss: 4.304841552857874

Epoch: 5| Step: 2
Training loss: 3.6748973339038855
Validation loss: 4.300393221308025

Epoch: 5| Step: 3
Training loss: 4.529838394751888
Validation loss: 4.296267957867201

Epoch: 5| Step: 4
Training loss: 4.886360624929392
Validation loss: 4.291889377790449

Epoch: 5| Step: 5
Training loss: 4.646359583496567
Validation loss: 4.287546905691036

Epoch: 5| Step: 6
Training loss: 4.0669524222696385
Validation loss: 4.283052083750256

Epoch: 5| Step: 7
Training loss: 4.163378575254558
Validation loss: 4.27875031405407

Epoch: 5| Step: 8
Training loss: 4.617200719101212
Validation loss: 4.2744054447790525

Epoch: 5| Step: 9
Training loss: 4.24606657326572
Validation loss: 4.270192580499791

Epoch: 5| Step: 10
Training loss: 4.299391353025417
Validation loss: 4.265769914114793

Epoch: 5| Step: 11
Training loss: 3.92590222528156
Validation loss: 4.261279686380236

Epoch: 28| Step: 0
Training loss: 4.425812279238094
Validation loss: 4.256951289908689

Epoch: 5| Step: 1
Training loss: 3.986276928107052
Validation loss: 4.252527504498796

Epoch: 5| Step: 2
Training loss: 4.7766132685216
Validation loss: 4.248328375715554

Epoch: 5| Step: 3
Training loss: 3.5524660651930433
Validation loss: 4.2439549969172585

Epoch: 5| Step: 4
Training loss: 3.8580035657139464
Validation loss: 4.239559373467652

Epoch: 5| Step: 5
Training loss: 4.548759777690697
Validation loss: 4.235144921720238

Epoch: 5| Step: 6
Training loss: 4.03952289370171
Validation loss: 4.2311089789416805

Epoch: 5| Step: 7
Training loss: 3.691413096265146
Validation loss: 4.226629528141719

Epoch: 5| Step: 8
Training loss: 5.359768955887748
Validation loss: 4.222506896608667

Epoch: 5| Step: 9
Training loss: 4.443251415240655
Validation loss: 4.218134446624564

Epoch: 5| Step: 10
Training loss: 5.198695224511003
Validation loss: 4.213926355116728

Epoch: 5| Step: 11
Training loss: 2.7678716123000564
Validation loss: 4.209465519782113

Epoch: 29| Step: 0
Training loss: 4.032448050914629
Validation loss: 4.205264335273917

Epoch: 5| Step: 1
Training loss: 4.625411144230729
Validation loss: 4.200976341351955

Epoch: 5| Step: 2
Training loss: 4.3463151342225155
Validation loss: 4.196726271322456

Epoch: 5| Step: 3
Training loss: 3.958275978609798
Validation loss: 4.192510619941474

Epoch: 5| Step: 4
Training loss: 4.417180133458551
Validation loss: 4.188268553013629

Epoch: 5| Step: 5
Training loss: 3.9848249592742073
Validation loss: 4.184049935851599

Epoch: 5| Step: 6
Training loss: 4.478588025472347
Validation loss: 4.179653402884614

Epoch: 5| Step: 7
Training loss: 4.679559314226737
Validation loss: 4.175364345939279

Epoch: 5| Step: 8
Training loss: 4.515159081310538
Validation loss: 4.171097491292972

Epoch: 5| Step: 9
Training loss: 4.077266208067032
Validation loss: 4.1666761620731245

Epoch: 5| Step: 10
Training loss: 4.272544307222306
Validation loss: 4.162128154271312

Epoch: 5| Step: 11
Training loss: 4.304362262271065
Validation loss: 4.1577215864030155

Epoch: 30| Step: 0
Training loss: 3.777948246332304
Validation loss: 4.153221819849129

Epoch: 5| Step: 1
Training loss: 4.201027272252813
Validation loss: 4.1489055534732575

Epoch: 5| Step: 2
Training loss: 4.185235849021949
Validation loss: 4.144599379477779

Epoch: 5| Step: 3
Training loss: 4.708954806652295
Validation loss: 4.140155621681291

Epoch: 5| Step: 4
Training loss: 3.549321880853272
Validation loss: 4.1355929381167496

Epoch: 5| Step: 5
Training loss: 3.854336434139368
Validation loss: 4.1311315857137805

Epoch: 5| Step: 6
Training loss: 4.768843367676243
Validation loss: 4.126745220868453

Epoch: 5| Step: 7
Training loss: 3.984842190746862
Validation loss: 4.122330543577786

Epoch: 5| Step: 8
Training loss: 3.959113368759098
Validation loss: 4.117944781675662

Epoch: 5| Step: 9
Training loss: 4.546924289292017
Validation loss: 4.11314038273651

Epoch: 5| Step: 10
Training loss: 4.664988261348106
Validation loss: 4.108983165011745

Epoch: 5| Step: 11
Training loss: 6.184589356441744
Validation loss: 4.104153069927071

Epoch: 31| Step: 0
Training loss: 3.807829200103792
Validation loss: 4.09879244315604

Epoch: 5| Step: 1
Training loss: 3.7976583292880286
Validation loss: 4.094155405563396

Epoch: 5| Step: 2
Training loss: 4.562686028019373
Validation loss: 4.08955824376768

Epoch: 5| Step: 3
Training loss: 4.218188891360054
Validation loss: 4.0849711075815085

Epoch: 5| Step: 4
Training loss: 4.593754774856681
Validation loss: 4.080182648922748

Epoch: 5| Step: 5
Training loss: 3.1130475156339528
Validation loss: 4.075338003264371

Epoch: 5| Step: 6
Training loss: 4.887818917798956
Validation loss: 4.0705539682997625

Epoch: 5| Step: 7
Training loss: 3.4297565983304854
Validation loss: 4.065837755630214

Epoch: 5| Step: 8
Training loss: 4.321389807264905
Validation loss: 4.0610543393113945

Epoch: 5| Step: 9
Training loss: 4.482405492549039
Validation loss: 4.056395899064401

Epoch: 5| Step: 10
Training loss: 4.810678112425231
Validation loss: 4.05156276206121

Epoch: 5| Step: 11
Training loss: 3.4294475219466665
Validation loss: 4.046708067957666

Epoch: 32| Step: 0
Training loss: 4.081826119995431
Validation loss: 4.041850772413632

Epoch: 5| Step: 1
Training loss: 4.097342509140166
Validation loss: 4.037350152052674

Epoch: 5| Step: 2
Training loss: 3.4623921181298196
Validation loss: 4.032731284311911

Epoch: 5| Step: 3
Training loss: 3.9863808762509825
Validation loss: 4.027990669711627

Epoch: 5| Step: 4
Training loss: 4.502246507861793
Validation loss: 4.02323272579025

Epoch: 5| Step: 5
Training loss: 4.299047080620495
Validation loss: 4.018480050377655

Epoch: 5| Step: 6
Training loss: 4.1987606490676725
Validation loss: 4.013849917482575

Epoch: 5| Step: 7
Training loss: 3.925305329127899
Validation loss: 4.008656349107208

Epoch: 5| Step: 8
Training loss: 3.9133841103720575
Validation loss: 4.003146429150947

Epoch: 5| Step: 9
Training loss: 4.761445160439123
Validation loss: 3.997998432213185

Epoch: 5| Step: 10
Training loss: 4.177351767776811
Validation loss: 3.993192522583935

Epoch: 5| Step: 11
Training loss: 4.697532801653164
Validation loss: 3.988643469133547

Epoch: 33| Step: 0
Training loss: 4.092379508041965
Validation loss: 3.9837672499351138

Epoch: 5| Step: 1
Training loss: 3.832287701066124
Validation loss: 3.9791746921691384

Epoch: 5| Step: 2
Training loss: 3.9980828936304986
Validation loss: 3.9744633678265076

Epoch: 5| Step: 3
Training loss: 3.5626227374433213
Validation loss: 3.9698233016685567

Epoch: 5| Step: 4
Training loss: 3.947057598659258
Validation loss: 3.9654110958285633

Epoch: 5| Step: 5
Training loss: 3.9748139199901376
Validation loss: 3.9610783829673775

Epoch: 5| Step: 6
Training loss: 3.6097250764515953
Validation loss: 3.9567213624378357

Epoch: 5| Step: 7
Training loss: 4.402270312234079
Validation loss: 3.952370970009505

Epoch: 5| Step: 8
Training loss: 4.523405032131967
Validation loss: 3.9479373220072818

Epoch: 5| Step: 9
Training loss: 4.6219369178735805
Validation loss: 3.9434481354628037

Epoch: 5| Step: 10
Training loss: 4.141758025995536
Validation loss: 3.938647370465722

Epoch: 5| Step: 11
Training loss: 4.912385445149714
Validation loss: 3.9338573934423215

Epoch: 34| Step: 0
Training loss: 3.8122392158743517
Validation loss: 3.929159509416994

Epoch: 5| Step: 1
Training loss: 4.087064452691455
Validation loss: 3.924270526459104

Epoch: 5| Step: 2
Training loss: 3.9146084890053032
Validation loss: 3.9194510366722475

Epoch: 5| Step: 3
Training loss: 4.137052556763314
Validation loss: 3.9148105355770055

Epoch: 5| Step: 4
Training loss: 3.2308659338189836
Validation loss: 3.9103815786785607

Epoch: 5| Step: 5
Training loss: 4.369907576153195
Validation loss: 3.9057729251721627

Epoch: 5| Step: 6
Training loss: 4.1940063489175525
Validation loss: 3.9010273721362596

Epoch: 5| Step: 7
Training loss: 4.139037781724748
Validation loss: 3.8963952534744495

Epoch: 5| Step: 8
Training loss: 4.1318039700148965
Validation loss: 3.891751913870093

Epoch: 5| Step: 9
Training loss: 3.917951589529655
Validation loss: 3.887472895520609

Epoch: 5| Step: 10
Training loss: 4.338629249644309
Validation loss: 3.882661792227634

Epoch: 5| Step: 11
Training loss: 4.234882619913256
Validation loss: 3.8780750358533163

Epoch: 35| Step: 0
Training loss: 4.5620380324501335
Validation loss: 3.8735551909324473

Epoch: 5| Step: 1
Training loss: 3.899010503394241
Validation loss: 3.8689729621167914

Epoch: 5| Step: 2
Training loss: 3.7969717005593595
Validation loss: 3.8643380504546347

Epoch: 5| Step: 3
Training loss: 4.252047550412822
Validation loss: 3.8597611968961534

Epoch: 5| Step: 4
Training loss: 3.319125477155913
Validation loss: 3.855326914344333

Epoch: 5| Step: 5
Training loss: 4.251653910435455
Validation loss: 3.8508591490089827

Epoch: 5| Step: 6
Training loss: 4.020151162792775
Validation loss: 3.8464534577106333

Epoch: 5| Step: 7
Training loss: 3.540654984134264
Validation loss: 3.8420685447593317

Epoch: 5| Step: 8
Training loss: 4.314855623272072
Validation loss: 3.8377972385217047

Epoch: 5| Step: 9
Training loss: 3.518425940435245
Validation loss: 3.8334081563005054

Epoch: 5| Step: 10
Training loss: 4.387561312950777
Validation loss: 3.8288453001847884

Epoch: 5| Step: 11
Training loss: 2.650436232307259
Validation loss: 3.8244159921675958

Epoch: 36| Step: 0
Training loss: 3.5521996144403367
Validation loss: 3.820102449244975

Epoch: 5| Step: 1
Training loss: 4.517975825555371
Validation loss: 3.815885067678127

Epoch: 5| Step: 2
Training loss: 4.437017925027642
Validation loss: 3.811614965678401

Epoch: 5| Step: 3
Training loss: 3.647896638761159
Validation loss: 3.80733127634272

Epoch: 5| Step: 4
Training loss: 4.320596806309901
Validation loss: 3.8026253858196397

Epoch: 5| Step: 5
Training loss: 3.6303860344030996
Validation loss: 3.798302171609177

Epoch: 5| Step: 6
Training loss: 4.470212470345151
Validation loss: 3.793690412117286

Epoch: 5| Step: 7
Training loss: 4.050496840907684
Validation loss: 3.7891246253095336

Epoch: 5| Step: 8
Training loss: 3.271565705612176
Validation loss: 3.7845949505435144

Epoch: 5| Step: 9
Training loss: 3.762887046398044
Validation loss: 3.7802092798770923

Epoch: 5| Step: 10
Training loss: 3.4993921842049245
Validation loss: 3.77577447230902

Epoch: 5| Step: 11
Training loss: 3.2234675825289814
Validation loss: 3.7715338149436346

Epoch: 37| Step: 0
Training loss: 3.696742226803306
Validation loss: 3.767562557680708

Epoch: 5| Step: 1
Training loss: 3.7383391596056676
Validation loss: 3.7635614484190913

Epoch: 5| Step: 2
Training loss: 3.3748981319171505
Validation loss: 3.759515287974396

Epoch: 5| Step: 3
Training loss: 3.915536568656127
Validation loss: 3.7556480259643625

Epoch: 5| Step: 4
Training loss: 3.732266393404341
Validation loss: 3.751449506149772

Epoch: 5| Step: 5
Training loss: 4.143696807934188
Validation loss: 3.747586103870593

Epoch: 5| Step: 6
Training loss: 3.818008820425149
Validation loss: 3.7434306830596142

Epoch: 5| Step: 7
Training loss: 3.550208990903121
Validation loss: 3.7394267698505734

Epoch: 5| Step: 8
Training loss: 4.076350618984644
Validation loss: 3.7353963426220385

Epoch: 5| Step: 9
Training loss: 4.692349786076543
Validation loss: 3.7312658180740716

Epoch: 5| Step: 10
Training loss: 3.731909029474387
Validation loss: 3.7267930114810084

Epoch: 5| Step: 11
Training loss: 4.2664704655199825
Validation loss: 3.7225441583901118

Epoch: 38| Step: 0
Training loss: 4.467341914782137
Validation loss: 3.7180363908046647

Epoch: 5| Step: 1
Training loss: 4.881707101439328
Validation loss: 3.713488674276152

Epoch: 5| Step: 2
Training loss: 3.234357308601978
Validation loss: 3.7091450267227053

Epoch: 5| Step: 3
Training loss: 4.083955652472527
Validation loss: 3.704201934712352

Epoch: 5| Step: 4
Training loss: 3.4650935241055674
Validation loss: 3.6997544660376525

Epoch: 5| Step: 5
Training loss: 3.7621361490017193
Validation loss: 3.6951713239331236

Epoch: 5| Step: 6
Training loss: 3.7857004252794404
Validation loss: 3.690736524860193

Epoch: 5| Step: 7
Training loss: 3.8231838178015596
Validation loss: 3.686153543201394

Epoch: 5| Step: 8
Training loss: 3.0881906516858164
Validation loss: 3.6818246972489854

Epoch: 5| Step: 9
Training loss: 2.9496420045001925
Validation loss: 3.6775184928589857

Epoch: 5| Step: 10
Training loss: 4.241193061174334
Validation loss: 3.6735365442801937

Epoch: 5| Step: 11
Training loss: 3.438832111605491
Validation loss: 3.6693335320896363

Epoch: 39| Step: 0
Training loss: 4.179451566793174
Validation loss: 3.6649931218593186

Epoch: 5| Step: 1
Training loss: 4.097578515260044
Validation loss: 3.660824063723023

Epoch: 5| Step: 2
Training loss: 3.410206308248716
Validation loss: 3.6565980175051536

Epoch: 5| Step: 3
Training loss: 3.4591940456021537
Validation loss: 3.6523520022484344

Epoch: 5| Step: 4
Training loss: 3.892676980485519
Validation loss: 3.6480794454552226

Epoch: 5| Step: 5
Training loss: 4.708421531908922
Validation loss: 3.643841001095108

Epoch: 5| Step: 6
Training loss: 3.479671297005664
Validation loss: 3.6393961872329412

Epoch: 5| Step: 7
Training loss: 3.5497064925809965
Validation loss: 3.635037791376202

Epoch: 5| Step: 8
Training loss: 3.504697372279759
Validation loss: 3.6308132563372926

Epoch: 5| Step: 9
Training loss: 3.150734491850236
Validation loss: 3.6266294686575415

Epoch: 5| Step: 10
Training loss: 4.039644948257631
Validation loss: 3.622564604845453

Epoch: 5| Step: 11
Training loss: 2.991411790820231
Validation loss: 3.618553002748763

Epoch: 40| Step: 0
Training loss: 3.3710312290516105
Validation loss: 3.6143766979917378

Epoch: 5| Step: 1
Training loss: 3.777199964341003
Validation loss: 3.610375891732405

Epoch: 5| Step: 2
Training loss: 3.4802572098311972
Validation loss: 3.6065284546572656

Epoch: 5| Step: 3
Training loss: 4.5868453470808355
Validation loss: 3.602792161719841

Epoch: 5| Step: 4
Training loss: 3.2490568993430164
Validation loss: 3.598708080124006

Epoch: 5| Step: 5
Training loss: 3.6685186101933516
Validation loss: 3.5942968919899556

Epoch: 5| Step: 6
Training loss: 4.065757736396665
Validation loss: 3.590479836269945

Epoch: 5| Step: 7
Training loss: 3.8966927761859775
Validation loss: 3.586245150309639

Epoch: 5| Step: 8
Training loss: 3.9839249899057227
Validation loss: 3.5821793642417297

Epoch: 5| Step: 9
Training loss: 3.1605488423666785
Validation loss: 3.5779428838279688

Epoch: 5| Step: 10
Training loss: 3.5978441883084273
Validation loss: 3.5738453543200426

Epoch: 5| Step: 11
Training loss: 3.6407499496563687
Validation loss: 3.5696749128326637

Epoch: 41| Step: 0
Training loss: 4.051145678821629
Validation loss: 3.565621486420256

Epoch: 5| Step: 1
Training loss: 3.7825596330559694
Validation loss: 3.5614179339836665

Epoch: 5| Step: 2
Training loss: 3.861109664209279
Validation loss: 3.5573465427766338

Epoch: 5| Step: 3
Training loss: 3.880389004113143
Validation loss: 3.5532460570367523

Epoch: 5| Step: 4
Training loss: 3.349763970102298
Validation loss: 3.5490728618272054

Epoch: 5| Step: 5
Training loss: 3.285967822984791
Validation loss: 3.5450541489989136

Epoch: 5| Step: 6
Training loss: 3.5292805268627316
Validation loss: 3.5410565112489323

Epoch: 5| Step: 7
Training loss: 4.30105620431264
Validation loss: 3.5370401326168364

Epoch: 5| Step: 8
Training loss: 3.6680418094594263
Validation loss: 3.5329226243138745

Epoch: 5| Step: 9
Training loss: 3.496422437848665
Validation loss: 3.5287917816646988

Epoch: 5| Step: 10
Training loss: 3.287280689655291
Validation loss: 3.5246844090668215

Epoch: 5| Step: 11
Training loss: 3.066146548019299
Validation loss: 3.5205471309982914

Epoch: 42| Step: 0
Training loss: 3.9607672720601563
Validation loss: 3.5166854332849518

Epoch: 5| Step: 1
Training loss: 3.712298270245216
Validation loss: 3.512680572628727

Epoch: 5| Step: 2
Training loss: 3.423863220905407
Validation loss: 3.5087740627342985

Epoch: 5| Step: 3
Training loss: 3.5609649563409196
Validation loss: 3.504838834259734

Epoch: 5| Step: 4
Training loss: 3.791212970013236
Validation loss: 3.500938738091451

Epoch: 5| Step: 5
Training loss: 3.4311834387933
Validation loss: 3.4968974150529295

Epoch: 5| Step: 6
Training loss: 3.5826874675802305
Validation loss: 3.4929666922869016

Epoch: 5| Step: 7
Training loss: 4.749366517238218
Validation loss: 3.488907715410177

Epoch: 5| Step: 8
Training loss: 3.267681149844014
Validation loss: 3.484648415824641

Epoch: 5| Step: 9
Training loss: 3.3288238221540696
Validation loss: 3.4806359932702406

Epoch: 5| Step: 10
Training loss: 3.2262683946808584
Validation loss: 3.476408588560032

Epoch: 5| Step: 11
Training loss: 1.6221354251587417
Validation loss: 3.472427051648557

Epoch: 43| Step: 0
Training loss: 3.7286047627588093
Validation loss: 3.4690719603996647

Epoch: 5| Step: 1
Training loss: 3.20572597690468
Validation loss: 3.4654824672749522

Epoch: 5| Step: 2
Training loss: 3.113432723779412
Validation loss: 3.4620228279076635

Epoch: 5| Step: 3
Training loss: 3.7016262449908393
Validation loss: 3.4584637448797295

Epoch: 5| Step: 4
Training loss: 3.2765479411764504
Validation loss: 3.455031609388322

Epoch: 5| Step: 5
Training loss: 3.633234340007424
Validation loss: 3.4515344630412663

Epoch: 5| Step: 6
Training loss: 3.4121434734629923
Validation loss: 3.4480789248193253

Epoch: 5| Step: 7
Training loss: 3.864766297374939
Validation loss: 3.444569502546218

Epoch: 5| Step: 8
Training loss: 3.156100581192094
Validation loss: 3.440964836825236

Epoch: 5| Step: 9
Training loss: 4.111288459205922
Validation loss: 3.4375122590279896

Epoch: 5| Step: 10
Training loss: 3.8675919138288184
Validation loss: 3.4339093846936897

Epoch: 5| Step: 11
Training loss: 4.712151973430306
Validation loss: 3.4301118349244097

Epoch: 44| Step: 0
Training loss: 3.6392346784873575
Validation loss: 3.4261715013153493

Epoch: 5| Step: 1
Training loss: 3.7328222390419468
Validation loss: 3.4223373135618216

Epoch: 5| Step: 2
Training loss: 3.4717397091769953
Validation loss: 3.41830625775044

Epoch: 5| Step: 3
Training loss: 3.1947700021310004
Validation loss: 3.4144497032775365

Epoch: 5| Step: 4
Training loss: 3.516804679464502
Validation loss: 3.4105349137847925

Epoch: 5| Step: 5
Training loss: 3.494030766815124
Validation loss: 3.406692890223696

Epoch: 5| Step: 6
Training loss: 2.9658780310587938
Validation loss: 3.4029503860724293

Epoch: 5| Step: 7
Training loss: 4.125080685837896
Validation loss: 3.399330308352367

Epoch: 5| Step: 8
Training loss: 3.623586050050638
Validation loss: 3.3953048298692505

Epoch: 5| Step: 9
Training loss: 3.2329217714378453
Validation loss: 3.3914118848389307

Epoch: 5| Step: 10
Training loss: 3.6776210546634767
Validation loss: 3.387594289511408

Epoch: 5| Step: 11
Training loss: 4.424222181676887
Validation loss: 3.3837568038422963

Epoch: 45| Step: 0
Training loss: 3.1216945714428066
Validation loss: 3.380009265713905

Epoch: 5| Step: 1
Training loss: 4.352411649575256
Validation loss: 3.3764595066634278

Epoch: 5| Step: 2
Training loss: 3.289188192326273
Validation loss: 3.3724930365066146

Epoch: 5| Step: 3
Training loss: 3.5675377278247704
Validation loss: 3.3687075306156333

Epoch: 5| Step: 4
Training loss: 4.150747457087054
Validation loss: 3.3648968758163362

Epoch: 5| Step: 5
Training loss: 3.5045336923850527
Validation loss: 3.3610536151798844

Epoch: 5| Step: 6
Training loss: 2.7013630499389905
Validation loss: 3.3573033413795983

Epoch: 5| Step: 7
Training loss: 3.0643793684360117
Validation loss: 3.3535102513899173

Epoch: 5| Step: 8
Training loss: 2.9292976628653595
Validation loss: 3.3498834496003926

Epoch: 5| Step: 9
Training loss: 3.6423706322856564
Validation loss: 3.3462487388459317

Epoch: 5| Step: 10
Training loss: 3.8355175650836784
Validation loss: 3.3427904392158885

Epoch: 5| Step: 11
Training loss: 3.426565500267653
Validation loss: 3.3390894493499483

Epoch: 46| Step: 0
Training loss: 3.024240943947479
Validation loss: 3.335440462413938

Epoch: 5| Step: 1
Training loss: 3.5897271238026236
Validation loss: 3.3320217691445384

Epoch: 5| Step: 2
Training loss: 3.2151641129866917
Validation loss: 3.32858876085047

Epoch: 5| Step: 3
Training loss: 3.6269086877157966
Validation loss: 3.325192982228901

Epoch: 5| Step: 4
Training loss: 3.134180089152152
Validation loss: 3.321760028130628

Epoch: 5| Step: 5
Training loss: 3.654727455759035
Validation loss: 3.3183216663872708

Epoch: 5| Step: 6
Training loss: 3.5485756447834795
Validation loss: 3.314694889012775

Epoch: 5| Step: 7
Training loss: 3.2114802363602855
Validation loss: 3.310997640253469

Epoch: 5| Step: 8
Training loss: 3.726079689594742
Validation loss: 3.3074215520550214

Epoch: 5| Step: 9
Training loss: 3.6002241117866998
Validation loss: 3.303792839903141

Epoch: 5| Step: 10
Training loss: 3.2775835170041816
Validation loss: 3.300102895519692

Epoch: 5| Step: 11
Training loss: 4.851333096742766
Validation loss: 3.2965768736544225

Epoch: 47| Step: 0
Training loss: 3.81245559916672
Validation loss: 3.2926745360604097

Epoch: 5| Step: 1
Training loss: 3.207378261809956
Validation loss: 3.2887658463389564

Epoch: 5| Step: 2
Training loss: 3.501220762708863
Validation loss: 3.284749311658483

Epoch: 5| Step: 3
Training loss: 3.50186243913186
Validation loss: 3.280731711250639

Epoch: 5| Step: 4
Training loss: 3.1810476782114865
Validation loss: 3.277022029588665

Epoch: 5| Step: 5
Training loss: 3.1660056846504965
Validation loss: 3.2732513787549715

Epoch: 5| Step: 6
Training loss: 3.3363408508165273
Validation loss: 3.269602943038487

Epoch: 5| Step: 7
Training loss: 3.6214969414657663
Validation loss: 3.265992592621365

Epoch: 5| Step: 8
Training loss: 3.66203346275487
Validation loss: 3.2623191844288675

Epoch: 5| Step: 9
Training loss: 3.2093261239584043
Validation loss: 3.2586808362439172

Epoch: 5| Step: 10
Training loss: 3.1914672098676116
Validation loss: 3.2548610268012634

Epoch: 5| Step: 11
Training loss: 3.863274708309363
Validation loss: 3.251191189908809

Epoch: 48| Step: 0
Training loss: 3.559143894854804
Validation loss: 3.2473145510186403

Epoch: 5| Step: 1
Training loss: 3.1212376643721185
Validation loss: 3.24327650050454

Epoch: 5| Step: 2
Training loss: 2.6643853760995326
Validation loss: 3.239811086877125

Epoch: 5| Step: 3
Training loss: 3.4737279416180433
Validation loss: 3.236775366008458

Epoch: 5| Step: 4
Training loss: 3.5702605462833055
Validation loss: 3.2327612569074735

Epoch: 5| Step: 5
Training loss: 3.699401528697882
Validation loss: 3.2293404727224764

Epoch: 5| Step: 6
Training loss: 3.729492059644211
Validation loss: 3.2255196598707263

Epoch: 5| Step: 7
Training loss: 2.4259896058365444
Validation loss: 3.2218846547586137

Epoch: 5| Step: 8
Training loss: 3.7017533864582703
Validation loss: 3.218489975904415

Epoch: 5| Step: 9
Training loss: 3.434183358702113
Validation loss: 3.2150783831729806

Epoch: 5| Step: 10
Training loss: 3.42246579160794
Validation loss: 3.2115624957288653

Epoch: 5| Step: 11
Training loss: 3.3425316418082356
Validation loss: 3.2080838469731905

Epoch: 49| Step: 0
Training loss: 3.1555245953893203
Validation loss: 3.204974203615921

Epoch: 5| Step: 1
Training loss: 3.4070076755966823
Validation loss: 3.2020154380342785

Epoch: 5| Step: 2
Training loss: 2.5528343081888254
Validation loss: 3.198922621389875

Epoch: 5| Step: 3
Training loss: 3.6568619957645234
Validation loss: 3.1959200516979123

Epoch: 5| Step: 4
Training loss: 3.5083004754370952
Validation loss: 3.1925072640376446

Epoch: 5| Step: 5
Training loss: 3.39862046023307
Validation loss: 3.1894306089405005

Epoch: 5| Step: 6
Training loss: 3.904453077908025
Validation loss: 3.1858989085251266

Epoch: 5| Step: 7
Training loss: 3.286701288124742
Validation loss: 3.182495470695539

Epoch: 5| Step: 8
Training loss: 2.9475472873715707
Validation loss: 3.178894862700453

Epoch: 5| Step: 9
Training loss: 3.220053991966849
Validation loss: 3.175933665316706

Epoch: 5| Step: 10
Training loss: 3.556478397161656
Validation loss: 3.1726093475699955

Epoch: 5| Step: 11
Training loss: 2.521257244018376
Validation loss: 3.169405005234059

Epoch: 50| Step: 0
Training loss: 3.167523335142824
Validation loss: 3.1669812621317246

Epoch: 5| Step: 1
Training loss: 2.436326159974456
Validation loss: 3.164062396390937

Epoch: 5| Step: 2
Training loss: 3.5332225590261546
Validation loss: 3.16160696058416

Epoch: 5| Step: 3
Training loss: 3.544121971993651
Validation loss: 3.1585739506243966

Epoch: 5| Step: 4
Training loss: 3.6477352013686795
Validation loss: 3.15574819522671

Epoch: 5| Step: 5
Training loss: 3.069340908860912
Validation loss: 3.1530705606369045

Epoch: 5| Step: 6
Training loss: 2.834530988646648
Validation loss: 3.15008025622182

Epoch: 5| Step: 7
Training loss: 3.005910138054137
Validation loss: 3.1475344104971468

Epoch: 5| Step: 8
Training loss: 3.33304729823886
Validation loss: 3.1449920948436625

Epoch: 5| Step: 9
Training loss: 3.70804780582363
Validation loss: 3.142146512192138

Epoch: 5| Step: 10
Training loss: 3.5683584395951837
Validation loss: 3.139511043692586

Epoch: 5| Step: 11
Training loss: 3.979668563959477
Validation loss: 3.1366296409532364

Epoch: 51| Step: 0
Training loss: 3.4369203945837987
Validation loss: 3.1336905564101323

Epoch: 5| Step: 1
Training loss: 3.6764710576674218
Validation loss: 3.130340152362048

Epoch: 5| Step: 2
Training loss: 2.6600448428224692
Validation loss: 3.127132644916821

Epoch: 5| Step: 3
Training loss: 3.039583058626312
Validation loss: 3.1240130137438276

Epoch: 5| Step: 4
Training loss: 3.319020601149455
Validation loss: 3.120835463459899

Epoch: 5| Step: 5
Training loss: 3.358992727841327
Validation loss: 3.1179517798558147

Epoch: 5| Step: 6
Training loss: 3.3614092677960237
Validation loss: 3.1153862289360834

Epoch: 5| Step: 7
Training loss: 3.064131632972802
Validation loss: 3.1123790223383567

Epoch: 5| Step: 8
Training loss: 3.656718819059989
Validation loss: 3.109339459853519

Epoch: 5| Step: 9
Training loss: 2.5773862762966733
Validation loss: 3.106351369512403

Epoch: 5| Step: 10
Training loss: 3.501338566535279
Validation loss: 3.103505801358769

Epoch: 5| Step: 11
Training loss: 3.274986465076695
Validation loss: 3.1008507450793528

Epoch: 52| Step: 0
Training loss: 2.990344722612862
Validation loss: 3.0974121061677717

Epoch: 5| Step: 1
Training loss: 3.487170684470348
Validation loss: 3.0947164702077865

Epoch: 5| Step: 2
Training loss: 3.360244993179005
Validation loss: 3.091262909435111

Epoch: 5| Step: 3
Training loss: 3.3094004398625296
Validation loss: 3.088175667771273

Epoch: 5| Step: 4
Training loss: 3.3661513006484753
Validation loss: 3.085348779720114

Epoch: 5| Step: 5
Training loss: 2.8067087524895187
Validation loss: 3.0816253923492662

Epoch: 5| Step: 6
Training loss: 3.4080231977040394
Validation loss: 3.0787891116893005

Epoch: 5| Step: 7
Training loss: 3.226175575979382
Validation loss: 3.0756879024149417

Epoch: 5| Step: 8
Training loss: 3.562082768150645
Validation loss: 3.073016786830083

Epoch: 5| Step: 9
Training loss: 2.714906277382463
Validation loss: 3.0699718891455574

Epoch: 5| Step: 10
Training loss: 3.390620499708995
Validation loss: 3.0673541051797906

Epoch: 5| Step: 11
Training loss: 1.3882857374677975
Validation loss: 3.064310466427361

Epoch: 53| Step: 0
Training loss: 3.838358998535148
Validation loss: 3.0613986811754184

Epoch: 5| Step: 1
Training loss: 2.9813829372364804
Validation loss: 3.0592719731243294

Epoch: 5| Step: 2
Training loss: 3.764528486861742
Validation loss: 3.056080854060928

Epoch: 5| Step: 3
Training loss: 3.343668143438039
Validation loss: 3.053508387883956

Epoch: 5| Step: 4
Training loss: 3.278066053124162
Validation loss: 3.050447055748822

Epoch: 5| Step: 5
Training loss: 3.3339936714958993
Validation loss: 3.0479438928277682

Epoch: 5| Step: 6
Training loss: 2.1904659327766387
Validation loss: 3.0451397820899975

Epoch: 5| Step: 7
Training loss: 2.3685165048627743
Validation loss: 3.041785330395533

Epoch: 5| Step: 8
Training loss: 3.402334500113
Validation loss: 3.0395840521731627

Epoch: 5| Step: 9
Training loss: 3.205283577405355
Validation loss: 3.037088742037865

Epoch: 5| Step: 10
Training loss: 3.031546037513446
Validation loss: 3.0343006585885433

Epoch: 5| Step: 11
Training loss: 3.046526297153538
Validation loss: 3.0315226763227874

Epoch: 54| Step: 0
Training loss: 3.9971812568587763
Validation loss: 3.0293865440636125

Epoch: 5| Step: 1
Training loss: 2.9447641039218375
Validation loss: 3.0269762796496096

Epoch: 5| Step: 2
Training loss: 3.51603201311486
Validation loss: 3.024527820537194

Epoch: 5| Step: 3
Training loss: 3.110611866069994
Validation loss: 3.0219871005778733

Epoch: 5| Step: 4
Training loss: 3.0547858415076474
Validation loss: 3.0196102505408806

Epoch: 5| Step: 5
Training loss: 3.181781650928003
Validation loss: 3.017022874562942

Epoch: 5| Step: 6
Training loss: 2.9188873193364966
Validation loss: 3.0148602736535044

Epoch: 5| Step: 7
Training loss: 2.5163587364962425
Validation loss: 3.0123193375376056

Epoch: 5| Step: 8
Training loss: 2.9545747942234675
Validation loss: 3.0098315179548516

Epoch: 5| Step: 9
Training loss: 2.943802261698541
Validation loss: 3.007585052874126

Epoch: 5| Step: 10
Training loss: 3.3124730810835024
Validation loss: 3.005168588376587

Epoch: 5| Step: 11
Training loss: 3.566850515481758
Validation loss: 3.003001618803123

Epoch: 55| Step: 0
Training loss: 3.6182253442431738
Validation loss: 3.0005994767354496

Epoch: 5| Step: 1
Training loss: 3.1632904994732334
Validation loss: 2.997648363829615

Epoch: 5| Step: 2
Training loss: 2.812344949475019
Validation loss: 2.9953031495660913

Epoch: 5| Step: 3
Training loss: 3.1339284379064014
Validation loss: 2.9931532029353707

Epoch: 5| Step: 4
Training loss: 2.9580219982533733
Validation loss: 2.990300857798212

Epoch: 5| Step: 5
Training loss: 3.5372360939821803
Validation loss: 2.9884267900383974

Epoch: 5| Step: 6
Training loss: 3.2989924713446634
Validation loss: 2.9856147953705787

Epoch: 5| Step: 7
Training loss: 3.224980814085675
Validation loss: 2.983323549453491

Epoch: 5| Step: 8
Training loss: 2.917127046127246
Validation loss: 2.980913154931071

Epoch: 5| Step: 9
Training loss: 2.5892937307750463
Validation loss: 2.9780221532386655

Epoch: 5| Step: 10
Training loss: 2.964210171155503
Validation loss: 2.975875882097644

Epoch: 5| Step: 11
Training loss: 3.475969791250358
Validation loss: 2.9741483261338835

Epoch: 56| Step: 0
Training loss: 3.0716150835507663
Validation loss: 2.9712259642180228

Epoch: 5| Step: 1
Training loss: 2.7651902196478604
Validation loss: 2.9681795810338047

Epoch: 5| Step: 2
Training loss: 3.2357130738168576
Validation loss: 2.9661624172284067

Epoch: 5| Step: 3
Training loss: 3.2871243164303174
Validation loss: 2.963756526115008

Epoch: 5| Step: 4
Training loss: 3.5932202819516794
Validation loss: 2.961288196526173

Epoch: 5| Step: 5
Training loss: 3.377161817130905
Validation loss: 2.95902076757564

Epoch: 5| Step: 6
Training loss: 3.040485274582999
Validation loss: 2.95616978905477

Epoch: 5| Step: 7
Training loss: 2.409475270521395
Validation loss: 2.9537213310414163

Epoch: 5| Step: 8
Training loss: 2.7036687050571344
Validation loss: 2.9512478010575234

Epoch: 5| Step: 9
Training loss: 2.756958394264868
Validation loss: 2.948739318952288

Epoch: 5| Step: 10
Training loss: 3.1971931426000633
Validation loss: 2.9464308001081836

Epoch: 5| Step: 11
Training loss: 4.935791879059395
Validation loss: 2.944349824736632

Epoch: 57| Step: 0
Training loss: 3.2709475130857446
Validation loss: 2.941623347065204

Epoch: 5| Step: 1
Training loss: 3.4313399172815404
Validation loss: 2.9391334300698704

Epoch: 5| Step: 2
Training loss: 3.230292060568181
Validation loss: 2.9412934179056065

Epoch: 5| Step: 3
Training loss: 3.390377756412515
Validation loss: 2.9345320425643027

Epoch: 5| Step: 4
Training loss: 2.610598614180114
Validation loss: 2.9317785235288465

Epoch: 5| Step: 5
Training loss: 3.083072616964221
Validation loss: 2.9296540389799217

Epoch: 5| Step: 6
Training loss: 2.6969461548790505
Validation loss: 2.9277487379743534

Epoch: 5| Step: 7
Training loss: 3.3886556927297335
Validation loss: 2.9262792335797947

Epoch: 5| Step: 8
Training loss: 2.9549821130821172
Validation loss: 2.924683022237342

Epoch: 5| Step: 9
Training loss: 2.8409153151010473
Validation loss: 2.9210333572460683

Epoch: 5| Step: 10
Training loss: 2.8231332468280175
Validation loss: 2.9194454012743294

Epoch: 5| Step: 11
Training loss: 2.7834830588388306
Validation loss: 2.9169698432753655

Epoch: 58| Step: 0
Training loss: 3.15800321626892
Validation loss: 2.91425515459315

Epoch: 5| Step: 1
Training loss: 2.8715783365501863
Validation loss: 2.9115321412168256

Epoch: 5| Step: 2
Training loss: 2.8800922575055066
Validation loss: 2.9089886876998

Epoch: 5| Step: 3
Training loss: 3.201635246883904
Validation loss: 2.905719428357516

Epoch: 5| Step: 4
Training loss: 3.1328963651395476
Validation loss: 2.904076279465511

Epoch: 5| Step: 5
Training loss: 3.01206420025536
Validation loss: 2.902375352429879

Epoch: 5| Step: 6
Training loss: 3.315142171581462
Validation loss: 2.9000000559050454

Epoch: 5| Step: 7
Training loss: 3.317846913140823
Validation loss: 2.8982722191585335

Epoch: 5| Step: 8
Training loss: 2.7931636288819064
Validation loss: 2.8963189381130365

Epoch: 5| Step: 9
Training loss: 2.4723513446858285
Validation loss: 2.89431720376374

Epoch: 5| Step: 10
Training loss: 3.3199507213290413
Validation loss: 2.892422071081388

Epoch: 5| Step: 11
Training loss: 2.513550275989959
Validation loss: 2.890643482320998

Epoch: 59| Step: 0
Training loss: 3.00111543263948
Validation loss: 2.888322184427987

Epoch: 5| Step: 1
Training loss: 2.699061873606938
Validation loss: 2.886326533933335

Epoch: 5| Step: 2
Training loss: 2.9805530621163765
Validation loss: 2.8841707808255714

Epoch: 5| Step: 3
Training loss: 3.092235001579388
Validation loss: 2.882227827154888

Epoch: 5| Step: 4
Training loss: 2.6183530119656853
Validation loss: 2.8801653285664615

Epoch: 5| Step: 5
Training loss: 3.176202237048952
Validation loss: 2.878237238962126

Epoch: 5| Step: 6
Training loss: 3.1873448652026792
Validation loss: 2.8763460000816874

Epoch: 5| Step: 7
Training loss: 3.1197033053936525
Validation loss: 2.8743372097905717

Epoch: 5| Step: 8
Training loss: 3.177697160968328
Validation loss: 2.872364622737941

Epoch: 5| Step: 9
Training loss: 3.045936948698508
Validation loss: 2.8700372979656943

Epoch: 5| Step: 10
Training loss: 3.1127789904710657
Validation loss: 2.867794426511249

Epoch: 5| Step: 11
Training loss: 2.717176749508141
Validation loss: 2.866158275564533

Epoch: 60| Step: 0
Training loss: 2.6205521093557977
Validation loss: 2.863723443178889

Epoch: 5| Step: 1
Training loss: 3.2008440037153645
Validation loss: 2.8618946647260013

Epoch: 5| Step: 2
Training loss: 2.9687209278490174
Validation loss: 2.85960577987146

Epoch: 5| Step: 3
Training loss: 3.310022399227267
Validation loss: 2.8571850149842084

Epoch: 5| Step: 4
Training loss: 2.3183520733944096
Validation loss: 2.8552470749559298

Epoch: 5| Step: 5
Training loss: 2.9499695081266437
Validation loss: 2.8530669367642068

Epoch: 5| Step: 6
Training loss: 3.3121824292236695
Validation loss: 2.8512639660223553

Epoch: 5| Step: 7
Training loss: 3.0483987763730127
Validation loss: 2.8489041413354985

Epoch: 5| Step: 8
Training loss: 3.077652018655945
Validation loss: 2.847994605930137

Epoch: 5| Step: 9
Training loss: 3.0485296989196797
Validation loss: 2.8451645829620276

Epoch: 5| Step: 10
Training loss: 2.9034876667731027
Validation loss: 2.843270194968922

Epoch: 5| Step: 11
Training loss: 3.260874235730351
Validation loss: 2.841984001369666

Epoch: 61| Step: 0
Training loss: 2.9435751569460296
Validation loss: 2.8407083530597705

Epoch: 5| Step: 1
Training loss: 2.8826176440540157
Validation loss: 2.8391964545076154

Epoch: 5| Step: 2
Training loss: 2.6538199585054496
Validation loss: 2.8373564155873345

Epoch: 5| Step: 3
Training loss: 3.3141528630290917
Validation loss: 2.835379984466782

Epoch: 5| Step: 4
Training loss: 2.811203551835241
Validation loss: 2.833999917679801

Epoch: 5| Step: 5
Training loss: 2.6360222242631193
Validation loss: 2.831499222515461

Epoch: 5| Step: 6
Training loss: 2.88253625719571
Validation loss: 2.829719950789879

Epoch: 5| Step: 7
Training loss: 3.0569404430633784
Validation loss: 2.8271812775263245

Epoch: 5| Step: 8
Training loss: 2.734683558901812
Validation loss: 2.8258485501471293

Epoch: 5| Step: 9
Training loss: 3.046974376133793
Validation loss: 2.8243745274581

Epoch: 5| Step: 10
Training loss: 3.354052207999938
Validation loss: 2.822162496933117

Epoch: 5| Step: 11
Training loss: 4.212797132930512
Validation loss: 2.821039167855267

Epoch: 62| Step: 0
Training loss: 2.7233582827087837
Validation loss: 2.8182643452266873

Epoch: 5| Step: 1
Training loss: 3.252514233451739
Validation loss: 2.8165326030604234

Epoch: 5| Step: 2
Training loss: 2.495476253823794
Validation loss: 2.8154612457944856

Epoch: 5| Step: 3
Training loss: 2.8312389449352153
Validation loss: 2.813353663272382

Epoch: 5| Step: 4
Training loss: 2.8626107007072603
Validation loss: 2.811858450162635

Epoch: 5| Step: 5
Training loss: 3.070262025219251
Validation loss: 2.810008849568986

Epoch: 5| Step: 6
Training loss: 2.545292087423904
Validation loss: 2.808312675690633

Epoch: 5| Step: 7
Training loss: 3.32370202680142
Validation loss: 2.806388657846443

Epoch: 5| Step: 8
Training loss: 2.7550989043938046
Validation loss: 2.8045980568510993

Epoch: 5| Step: 9
Training loss: 2.6834837600844925
Validation loss: 2.8035131774696063

Epoch: 5| Step: 10
Training loss: 3.659425188171594
Validation loss: 2.800971648529341

Epoch: 5| Step: 11
Training loss: 3.15806512289322
Validation loss: 2.8043216760727794

Epoch: 63| Step: 0
Training loss: 2.6537229297782776
Validation loss: 2.8029798801129617

Epoch: 5| Step: 1
Training loss: 3.0463855839400233
Validation loss: 2.7973397861496596

Epoch: 5| Step: 2
Training loss: 3.0857278100731578
Validation loss: 2.79886597179407

Epoch: 5| Step: 3
Training loss: 3.048135350053152
Validation loss: 2.7930421228263373

Epoch: 5| Step: 4
Training loss: 2.7254052097126595
Validation loss: 2.792674865911038

Epoch: 5| Step: 5
Training loss: 2.943094323873897
Validation loss: 2.7919273444544075

Epoch: 5| Step: 6
Training loss: 3.1721218370126545
Validation loss: 2.792264846985655

Epoch: 5| Step: 7
Training loss: 2.91436569641055
Validation loss: 2.7915320197889395

Epoch: 5| Step: 8
Training loss: 3.019689637208751
Validation loss: 2.7910593437399474

Epoch: 5| Step: 9
Training loss: 2.740996969071737
Validation loss: 2.787643584586173

Epoch: 5| Step: 10
Training loss: 2.707293168865363
Validation loss: 2.784270867663563

Epoch: 5| Step: 11
Training loss: 3.641931913188759
Validation loss: 2.7813804503004818

Epoch: 64| Step: 0
Training loss: 2.815436546801608
Validation loss: 2.7773313919987106

Epoch: 5| Step: 1
Training loss: 3.1983264242246374
Validation loss: 2.778405610235005

Epoch: 5| Step: 2
Training loss: 2.7109703039993374
Validation loss: 2.787811932124178

Epoch: 5| Step: 3
Training loss: 2.8221757392693165
Validation loss: 2.788881198037407

Epoch: 5| Step: 4
Training loss: 2.6355789094422364
Validation loss: 2.7681635791739834

Epoch: 5| Step: 5
Training loss: 3.440498431491037
Validation loss: 2.765590638775201

Epoch: 5| Step: 6
Training loss: 2.499161102688981
Validation loss: 2.764381046315865

Epoch: 5| Step: 7
Training loss: 2.654151985531082
Validation loss: 2.7640137909111813

Epoch: 5| Step: 8
Training loss: 2.753325965292665
Validation loss: 2.7624335436357557

Epoch: 5| Step: 9
Training loss: 3.4868591758969303
Validation loss: 2.761899331612878

Epoch: 5| Step: 10
Training loss: 2.738415506638741
Validation loss: 2.7604889926192313

Epoch: 5| Step: 11
Training loss: 3.3096669876058007
Validation loss: 2.761178135959186

Epoch: 65| Step: 0
Training loss: 3.0228081573073387
Validation loss: 2.7591861153307633

Epoch: 5| Step: 1
Training loss: 2.5676131059941163
Validation loss: 2.7581470744026686

Epoch: 5| Step: 2
Training loss: 2.7982433530765527
Validation loss: 2.756435587279814

Epoch: 5| Step: 3
Training loss: 3.195071782602683
Validation loss: 2.756640818446641

Epoch: 5| Step: 4
Training loss: 2.9996760511333824
Validation loss: 2.7533848334276674

Epoch: 5| Step: 5
Training loss: 3.060527243974214
Validation loss: 2.749707368973364

Epoch: 5| Step: 6
Training loss: 2.830688831892423
Validation loss: 2.749330728181233

Epoch: 5| Step: 7
Training loss: 2.884478989335334
Validation loss: 2.746122180109647

Epoch: 5| Step: 8
Training loss: 2.9321343948351
Validation loss: 2.7454062768432044

Epoch: 5| Step: 9
Training loss: 2.795224859101581
Validation loss: 2.744099768066341

Epoch: 5| Step: 10
Training loss: 2.794860199381739
Validation loss: 2.741401570605037

Epoch: 5| Step: 11
Training loss: 2.354387987474185
Validation loss: 2.7393166456970643

Epoch: 66| Step: 0
Training loss: 2.499050532287662
Validation loss: 2.7370288794757816

Epoch: 5| Step: 1
Training loss: 2.997620592658333
Validation loss: 2.737361468695757

Epoch: 5| Step: 2
Training loss: 2.9471552823736404
Validation loss: 2.7534890618650505

Epoch: 5| Step: 3
Training loss: 2.497138674758397
Validation loss: 2.7346970068838585

Epoch: 5| Step: 4
Training loss: 3.1641627166324207
Validation loss: 2.734131680516366

Epoch: 5| Step: 5
Training loss: 3.036206312937123
Validation loss: 2.733950340356014

Epoch: 5| Step: 6
Training loss: 2.6892039198098305
Validation loss: 2.7337533116912898

Epoch: 5| Step: 7
Training loss: 3.0186840610924093
Validation loss: 2.7337694896380604

Epoch: 5| Step: 8
Training loss: 2.7735876768044725
Validation loss: 2.734643318090505

Epoch: 5| Step: 9
Training loss: 3.0536045974548927
Validation loss: 2.7315077653495545

Epoch: 5| Step: 10
Training loss: 2.6007590213007896
Validation loss: 2.7313776427237824

Epoch: 5| Step: 11
Training loss: 3.909470596181435
Validation loss: 2.729433830424439

Epoch: 67| Step: 0
Training loss: 2.7117985394124275
Validation loss: 2.7261786933096164

Epoch: 5| Step: 1
Training loss: 3.105588514789646
Validation loss: 2.7237710481133575

Epoch: 5| Step: 2
Training loss: 2.844508813917801
Validation loss: 2.7221669505848713

Epoch: 5| Step: 3
Training loss: 2.6227600895265155
Validation loss: 2.7214363645462987

Epoch: 5| Step: 4
Training loss: 3.0083078744362286
Validation loss: 2.722894407316101

Epoch: 5| Step: 5
Training loss: 3.0788341034627877
Validation loss: 2.7211474849693627

Epoch: 5| Step: 6
Training loss: 2.766101774509937
Validation loss: 2.718097349002689

Epoch: 5| Step: 7
Training loss: 2.728238090976425
Validation loss: 2.714217284303215

Epoch: 5| Step: 8
Training loss: 2.389448088122552
Validation loss: 2.7164595883866802

Epoch: 5| Step: 9
Training loss: 2.948948727808465
Validation loss: 2.711359524376741

Epoch: 5| Step: 10
Training loss: 3.2044512724425216
Validation loss: 2.709708731431051

Epoch: 5| Step: 11
Training loss: 2.724214433601533
Validation loss: 2.7073003094838413

Epoch: 68| Step: 0
Training loss: 2.946544116508318
Validation loss: 2.7056786927455705

Epoch: 5| Step: 1
Training loss: 3.1984917603005405
Validation loss: 2.7077977360027394

Epoch: 5| Step: 2
Training loss: 2.6872734151734448
Validation loss: 2.7080225741780466

Epoch: 5| Step: 3
Training loss: 2.855306263278372
Validation loss: 2.7028680212509464

Epoch: 5| Step: 4
Training loss: 3.32039493234071
Validation loss: 2.699517921249546

Epoch: 5| Step: 5
Training loss: 2.668750921959461
Validation loss: 2.6999642446293275

Epoch: 5| Step: 6
Training loss: 2.5647801744876353
Validation loss: 2.702290180046981

Epoch: 5| Step: 7
Training loss: 3.2536423153667666
Validation loss: 2.7022294341515343

Epoch: 5| Step: 8
Training loss: 2.876137881458255
Validation loss: 2.702062140602017

Epoch: 5| Step: 9
Training loss: 2.2633486131012805
Validation loss: 2.699407634392105

Epoch: 5| Step: 10
Training loss: 2.650346995973577
Validation loss: 2.6969396646054573

Epoch: 5| Step: 11
Training loss: 2.0038898311187743
Validation loss: 2.6969719905806175

Epoch: 69| Step: 0
Training loss: 2.7866609208566424
Validation loss: 2.695765953804012

Epoch: 5| Step: 1
Training loss: 3.2023113426845056
Validation loss: 2.693629575163226

Epoch: 5| Step: 2
Training loss: 2.486939072743457
Validation loss: 2.691959820619935

Epoch: 5| Step: 3
Training loss: 3.0823992955448345
Validation loss: 2.6895387590193027

Epoch: 5| Step: 4
Training loss: 2.8576826913926356
Validation loss: 2.687462957999279

Epoch: 5| Step: 5
Training loss: 2.958187063836714
Validation loss: 2.6872865680843665

Epoch: 5| Step: 6
Training loss: 2.7135688258085335
Validation loss: 2.6862418830196297

Epoch: 5| Step: 7
Training loss: 2.918637853914433
Validation loss: 2.6846097774664615

Epoch: 5| Step: 8
Training loss: 2.8663746359769466
Validation loss: 2.681737002951277

Epoch: 5| Step: 9
Training loss: 2.7855821794758238
Validation loss: 2.680195618436335

Epoch: 5| Step: 10
Training loss: 2.533093381694268
Validation loss: 2.680713675803595

Epoch: 5| Step: 11
Training loss: 1.6270219987485175
Validation loss: 2.6781084284942955

Epoch: 70| Step: 0
Training loss: 2.812043725196063
Validation loss: 2.703872672813695

Epoch: 5| Step: 1
Training loss: 2.601463980427402
Validation loss: 2.7600948050129372

Epoch: 5| Step: 2
Training loss: 2.671293675052682
Validation loss: 2.785015618053911

Epoch: 5| Step: 3
Training loss: 3.4010628217162857
Validation loss: 2.7293726003764567

Epoch: 5| Step: 4
Training loss: 2.8338886352604096
Validation loss: 2.6835994544563206

Epoch: 5| Step: 5
Training loss: 2.9367777159612043
Validation loss: 2.6723796375363547

Epoch: 5| Step: 6
Training loss: 2.977500947812792
Validation loss: 2.678766309142919

Epoch: 5| Step: 7
Training loss: 2.441481444154528
Validation loss: 2.685451747249846

Epoch: 5| Step: 8
Training loss: 3.064740509698116
Validation loss: 2.697838857012304

Epoch: 5| Step: 9
Training loss: 2.914567100874167
Validation loss: 2.7036481215138393

Epoch: 5| Step: 10
Training loss: 2.7420791648048986
Validation loss: 2.7011766081994018

Epoch: 5| Step: 11
Training loss: 1.352643589428935
Validation loss: 2.692498065454277

Epoch: 71| Step: 0
Training loss: 2.996740159550425
Validation loss: 2.6913691953222303

Epoch: 5| Step: 1
Training loss: 3.0710468530288715
Validation loss: 2.6859636757821397

Epoch: 5| Step: 2
Training loss: 2.7968287970280294
Validation loss: 2.6808020643648454

Epoch: 5| Step: 3
Training loss: 3.0596516656515838
Validation loss: 2.6779205791748897

Epoch: 5| Step: 4
Training loss: 2.7689861842699717
Validation loss: 2.6743648149261197

Epoch: 5| Step: 5
Training loss: 2.8524750385980937
Validation loss: 2.6707528752860767

Epoch: 5| Step: 6
Training loss: 2.614400444372039
Validation loss: 2.667009027428612

Epoch: 5| Step: 7
Training loss: 2.51115095445462
Validation loss: 2.665205910560638

Epoch: 5| Step: 8
Training loss: 2.637100666784985
Validation loss: 2.6641097414185357

Epoch: 5| Step: 9
Training loss: 2.469881209015022
Validation loss: 2.6616794596344513

Epoch: 5| Step: 10
Training loss: 3.1098439232033126
Validation loss: 2.6609927452625963

Epoch: 5| Step: 11
Training loss: 2.553444562917859
Validation loss: 2.660412350807682

Epoch: 72| Step: 0
Training loss: 2.65005182899318
Validation loss: 2.65815849930085

Epoch: 5| Step: 1
Training loss: 2.3428979978089544
Validation loss: 2.6605994872444962

Epoch: 5| Step: 2
Training loss: 3.1964003522864854
Validation loss: 2.6654983186303256

Epoch: 5| Step: 3
Training loss: 2.3762945361431234
Validation loss: 2.655047103179035

Epoch: 5| Step: 4
Training loss: 3.0276219000243136
Validation loss: 2.657229699120475

Epoch: 5| Step: 5
Training loss: 2.686240677424639
Validation loss: 2.656017491505421

Epoch: 5| Step: 6
Training loss: 2.950258185516321
Validation loss: 2.6569492952949827

Epoch: 5| Step: 7
Training loss: 2.9255426408877283
Validation loss: 2.6529296767156096

Epoch: 5| Step: 8
Training loss: 2.6989702698298728
Validation loss: 2.652165604958671

Epoch: 5| Step: 9
Training loss: 2.6474609375
Validation loss: 2.6522210963134105

Epoch: 5| Step: 10
Training loss: 3.0247352042832234
Validation loss: 2.6521491240087016

Epoch: 5| Step: 11
Training loss: 3.2235325217283193
Validation loss: 2.6492848761437373

Epoch: 73| Step: 0
Training loss: 3.0138690164577917
Validation loss: 2.648920335895901

Epoch: 5| Step: 1
Training loss: 3.0317500380393922
Validation loss: 2.6490582214155314

Epoch: 5| Step: 2
Training loss: 2.5185275185440834
Validation loss: 2.6470446604669773

Epoch: 5| Step: 3
Training loss: 2.225385281069424
Validation loss: 2.6460526718376527

Epoch: 5| Step: 4
Training loss: 3.0660967822541765
Validation loss: 2.6461249713916026

Epoch: 5| Step: 5
Training loss: 2.398837674334213
Validation loss: 2.6463834511069373

Epoch: 5| Step: 6
Training loss: 3.252518338409026
Validation loss: 2.644505626980695

Epoch: 5| Step: 7
Training loss: 2.7558116192265505
Validation loss: 2.6402553848925914

Epoch: 5| Step: 8
Training loss: 3.149033255805183
Validation loss: 2.637420466731981

Epoch: 5| Step: 9
Training loss: 2.0839214512085453
Validation loss: 2.6346665503498086

Epoch: 5| Step: 10
Training loss: 2.7865260796318165
Validation loss: 2.6389241995596184

Epoch: 5| Step: 11
Training loss: 3.0235225064257074
Validation loss: 2.6354503792778945

Epoch: 74| Step: 0
Training loss: 3.1638952140383916
Validation loss: 2.6320048111127132

Epoch: 5| Step: 1
Training loss: 1.853850034045491
Validation loss: 2.6304525708904856

Epoch: 5| Step: 2
Training loss: 2.5615512673323795
Validation loss: 2.63113874213799

Epoch: 5| Step: 3
Training loss: 2.8218281654366315
Validation loss: 2.6313306824795064

Epoch: 5| Step: 4
Training loss: 2.984943435618634
Validation loss: 2.6312965156388195

Epoch: 5| Step: 5
Training loss: 3.1145850004023723
Validation loss: 2.629878124748025

Epoch: 5| Step: 6
Training loss: 2.7252125718384876
Validation loss: 2.6270703711455883

Epoch: 5| Step: 7
Training loss: 2.616852787307114
Validation loss: 2.627873403456077

Epoch: 5| Step: 8
Training loss: 2.8115314087352266
Validation loss: 2.629710115640349

Epoch: 5| Step: 9
Training loss: 2.951618435977381
Validation loss: 2.6275237568604894

Epoch: 5| Step: 10
Training loss: 2.6277454188287606
Validation loss: 2.628345170779554

Epoch: 5| Step: 11
Training loss: 2.7595863581030344
Validation loss: 2.627260566882078

Epoch: 75| Step: 0
Training loss: 3.4285204037775032
Validation loss: 2.62695412712598

Epoch: 5| Step: 1
Training loss: 2.39876849844729
Validation loss: 2.625926126866088

Epoch: 5| Step: 2
Training loss: 2.2723401754346306
Validation loss: 2.622831663845504

Epoch: 5| Step: 3
Training loss: 3.131417056441392
Validation loss: 2.620943155145766

Epoch: 5| Step: 4
Training loss: 2.79684107243083
Validation loss: 2.6192504192251347

Epoch: 5| Step: 5
Training loss: 2.786946666862857
Validation loss: 2.618513547590716

Epoch: 5| Step: 6
Training loss: 2.758860532121815
Validation loss: 2.6189413428676556

Epoch: 5| Step: 7
Training loss: 2.806954320527079
Validation loss: 2.6190972188282333

Epoch: 5| Step: 8
Training loss: 2.8857811836409146
Validation loss: 2.616292665768239

Epoch: 5| Step: 9
Training loss: 2.312386381090249
Validation loss: 2.6158285721861825

Epoch: 5| Step: 10
Training loss: 2.6520515921452024
Validation loss: 2.6143438158600496

Epoch: 5| Step: 11
Training loss: 2.2075365416460575
Validation loss: 2.612637842152775

Epoch: 76| Step: 0
Training loss: 2.6354233109663086
Validation loss: 2.6112697331346544

Epoch: 5| Step: 1
Training loss: 2.7837133749653864
Validation loss: 2.611573870861859

Epoch: 5| Step: 2
Training loss: 2.5030277038028643
Validation loss: 2.607703097795001

Epoch: 5| Step: 3
Training loss: 2.715096924318018
Validation loss: 2.608811447063894

Epoch: 5| Step: 4
Training loss: 2.8021859832075497
Validation loss: 2.607293309388892

Epoch: 5| Step: 5
Training loss: 2.625487327752872
Validation loss: 2.6038126450546355

Epoch: 5| Step: 6
Training loss: 2.7597621693626633
Validation loss: 2.6127527840164855

Epoch: 5| Step: 7
Training loss: 2.4103453823177596
Validation loss: 2.6593325138246975

Epoch: 5| Step: 8
Training loss: 3.0960552219916995
Validation loss: 2.71095666502995

Epoch: 5| Step: 9
Training loss: 2.8545053842600354
Validation loss: 2.662816622388813

Epoch: 5| Step: 10
Training loss: 3.203467969443428
Validation loss: 2.639026150284644

Epoch: 5| Step: 11
Training loss: 1.9509445837021506
Validation loss: 2.624658554819252

Epoch: 77| Step: 0
Training loss: 2.486537735726898
Validation loss: 2.6246602504602707

Epoch: 5| Step: 1
Training loss: 3.1820674303200294
Validation loss: 2.6270000240861755

Epoch: 5| Step: 2
Training loss: 2.5517673426558547
Validation loss: 2.623932947023642

Epoch: 5| Step: 3
Training loss: 2.7882932141646686
Validation loss: 2.6203991632417316

Epoch: 5| Step: 4
Training loss: 2.3052427495865775
Validation loss: 2.623367820149122

Epoch: 5| Step: 5
Training loss: 2.784774347474373
Validation loss: 2.6199907842745813

Epoch: 5| Step: 6
Training loss: 2.9188791511927277
Validation loss: 2.615990842470469

Epoch: 5| Step: 7
Training loss: 2.8101631628974344
Validation loss: 2.6110056923210445

Epoch: 5| Step: 8
Training loss: 2.7856835164477305
Validation loss: 2.601731460018207

Epoch: 5| Step: 9
Training loss: 2.970861547335227
Validation loss: 2.6000650084450214

Epoch: 5| Step: 10
Training loss: 2.7781364071657944
Validation loss: 2.595437006803056

Epoch: 5| Step: 11
Training loss: 1.6362333101334998
Validation loss: 2.591044665842472

Epoch: 78| Step: 0
Training loss: 2.829868853869829
Validation loss: 2.5936200519166297

Epoch: 5| Step: 1
Training loss: 2.4953261554800608
Validation loss: 2.5901247220221246

Epoch: 5| Step: 2
Training loss: 2.834424837088557
Validation loss: 2.5932472653334258

Epoch: 5| Step: 3
Training loss: 2.957651373116423
Validation loss: 2.591285737572223

Epoch: 5| Step: 4
Training loss: 2.877799619823359
Validation loss: 2.5928673218936775

Epoch: 5| Step: 5
Training loss: 2.8172671289345543
Validation loss: 2.59056674997624

Epoch: 5| Step: 6
Training loss: 2.495639240272987
Validation loss: 2.5901134728339246

Epoch: 5| Step: 7
Training loss: 2.881536764905567
Validation loss: 2.584991205103342

Epoch: 5| Step: 8
Training loss: 2.57064863517315
Validation loss: 2.5820341817172627

Epoch: 5| Step: 9
Training loss: 2.8282944433550385
Validation loss: 2.5909908702014204

Epoch: 5| Step: 10
Training loss: 2.277871752818854
Validation loss: 2.5949425311330927

Epoch: 5| Step: 11
Training loss: 2.9959236106658036
Validation loss: 2.5990642775740147

Epoch: 79| Step: 0
Training loss: 2.6366731766894866
Validation loss: 2.5933823842049106

Epoch: 5| Step: 1
Training loss: 2.7321402872965717
Validation loss: 2.580279438444082

Epoch: 5| Step: 2
Training loss: 2.8983878159698877
Validation loss: 2.581607654969177

Epoch: 5| Step: 3
Training loss: 2.646191029637133
Validation loss: 2.579483290933981

Epoch: 5| Step: 4
Training loss: 3.1442869482448375
Validation loss: 2.5803507531605994

Epoch: 5| Step: 5
Training loss: 2.5618379249319
Validation loss: 2.5818504774224476

Epoch: 5| Step: 6
Training loss: 2.3849972574150264
Validation loss: 2.5798232871720352

Epoch: 5| Step: 7
Training loss: 2.394786628185767
Validation loss: 2.580248237756118

Epoch: 5| Step: 8
Training loss: 2.5197385717451297
Validation loss: 2.580366320207951

Epoch: 5| Step: 9
Training loss: 2.9864312722335358
Validation loss: 2.5770596971612627

Epoch: 5| Step: 10
Training loss: 2.7312680276585657
Validation loss: 2.57824519484113

Epoch: 5| Step: 11
Training loss: 3.220274036664554
Validation loss: 2.580484932365497

Epoch: 80| Step: 0
Training loss: 2.723087227423451
Validation loss: 2.578275951628726

Epoch: 5| Step: 1
Training loss: 2.2523965787695954
Validation loss: 2.5789524484475783

Epoch: 5| Step: 2
Training loss: 2.760733292372697
Validation loss: 2.575857907343277

Epoch: 5| Step: 3
Training loss: 2.8651739632882305
Validation loss: 2.584060233404214

Epoch: 5| Step: 4
Training loss: 2.7489631605569698
Validation loss: 2.5796176943315627

Epoch: 5| Step: 5
Training loss: 2.6565758000449144
Validation loss: 2.5933273576232034

Epoch: 5| Step: 6
Training loss: 2.8652500185965244
Validation loss: 2.585384916827321

Epoch: 5| Step: 7
Training loss: 2.5139350664406646
Validation loss: 2.596337877309825

Epoch: 5| Step: 8
Training loss: 3.1026412663662533
Validation loss: 2.5866243040062735

Epoch: 5| Step: 9
Training loss: 2.556971377782813
Validation loss: 2.578210162673182

Epoch: 5| Step: 10
Training loss: 2.6212500171725046
Validation loss: 2.5752087369589893

Epoch: 5| Step: 11
Training loss: 3.3837683474744717
Validation loss: 2.5753418667709744

Epoch: 81| Step: 0
Training loss: 2.604584001797257
Validation loss: 2.5685837486900494

Epoch: 5| Step: 1
Training loss: 2.775222075228124
Validation loss: 2.5689092204674586

Epoch: 5| Step: 2
Training loss: 2.825734682677623
Validation loss: 2.571119156770565

Epoch: 5| Step: 3
Training loss: 2.8704070846597767
Validation loss: 2.572854158411811

Epoch: 5| Step: 4
Training loss: 2.1892908667435087
Validation loss: 2.574713104277539

Epoch: 5| Step: 5
Training loss: 2.6278943952886133
Validation loss: 2.5763698614594035

Epoch: 5| Step: 6
Training loss: 2.8427702505027654
Validation loss: 2.576265797555048

Epoch: 5| Step: 7
Training loss: 2.804233694952288
Validation loss: 2.5735369036402496

Epoch: 5| Step: 8
Training loss: 2.5106912887440958
Validation loss: 2.5738656164061284

Epoch: 5| Step: 9
Training loss: 2.6959490480503963
Validation loss: 2.571260634903959

Epoch: 5| Step: 10
Training loss: 2.9555591058191886
Validation loss: 2.565944937900908

Epoch: 5| Step: 11
Training loss: 2.6288911952229594
Validation loss: 2.565571839482275

Epoch: 82| Step: 0
Training loss: 2.7298810378204865
Validation loss: 2.562399331108061

Epoch: 5| Step: 1
Training loss: 3.03096117039712
Validation loss: 2.5661558496491237

Epoch: 5| Step: 2
Training loss: 2.6468967693564087
Validation loss: 2.5633663248246545

Epoch: 5| Step: 3
Training loss: 2.9132820291024535
Validation loss: 2.5604590025759886

Epoch: 5| Step: 4
Training loss: 2.1397882761455014
Validation loss: 2.5587198163295803

Epoch: 5| Step: 5
Training loss: 2.515667174560339
Validation loss: 2.557840231479268

Epoch: 5| Step: 6
Training loss: 2.825153117123543
Validation loss: 2.555035842493554

Epoch: 5| Step: 7
Training loss: 2.9583432551114615
Validation loss: 2.5627551610801222

Epoch: 5| Step: 8
Training loss: 2.7000959767837873
Validation loss: 2.5605856792847113

Epoch: 5| Step: 9
Training loss: 2.6156556158427464
Validation loss: 2.561604145507776

Epoch: 5| Step: 10
Training loss: 2.529997810242199
Validation loss: 2.5574611379766443

Epoch: 5| Step: 11
Training loss: 2.2339106790893988
Validation loss: 2.5611852746731336

Epoch: 83| Step: 0
Training loss: 2.764626446646246
Validation loss: 2.5577459352687373

Epoch: 5| Step: 1
Training loss: 2.7635943182856617
Validation loss: 2.5536317383913185

Epoch: 5| Step: 2
Training loss: 2.6510084608555267
Validation loss: 2.5506737390890577

Epoch: 5| Step: 3
Training loss: 2.797454092076907
Validation loss: 2.5579201508062455

Epoch: 5| Step: 4
Training loss: 2.514301117549506
Validation loss: 2.5601017242762287

Epoch: 5| Step: 5
Training loss: 2.666331379395621
Validation loss: 2.561491457639776

Epoch: 5| Step: 6
Training loss: 2.694052846926896
Validation loss: 2.5638438786938647

Epoch: 5| Step: 7
Training loss: 2.414643745445575
Validation loss: 2.567768217449841

Epoch: 5| Step: 8
Training loss: 2.8486142319735994
Validation loss: 2.5682167313372095

Epoch: 5| Step: 9
Training loss: 2.7082090691644702
Validation loss: 2.5707873956006377

Epoch: 5| Step: 10
Training loss: 2.834295128282611
Validation loss: 2.5684021611390793

Epoch: 5| Step: 11
Training loss: 2.643861761954831
Validation loss: 2.5677167545410065

Epoch: 84| Step: 0
Training loss: 2.9888380940535773
Validation loss: 2.562790896799073

Epoch: 5| Step: 1
Training loss: 2.153610493663315
Validation loss: 2.5636082322955556

Epoch: 5| Step: 2
Training loss: 2.344958489707425
Validation loss: 2.5626398102681684

Epoch: 5| Step: 3
Training loss: 2.852717753464688
Validation loss: 2.56058764625289

Epoch: 5| Step: 4
Training loss: 2.6381960199046843
Validation loss: 2.5559498917770185

Epoch: 5| Step: 5
Training loss: 2.436234659270933
Validation loss: 2.552984138378732

Epoch: 5| Step: 6
Training loss: 2.479087144447162
Validation loss: 2.547569390868955

Epoch: 5| Step: 7
Training loss: 3.0673238948396846
Validation loss: 2.5472045326404444

Epoch: 5| Step: 8
Training loss: 2.6129671144631477
Validation loss: 2.546437891015912

Epoch: 5| Step: 9
Training loss: 2.806812724423008
Validation loss: 2.5445822710936894

Epoch: 5| Step: 10
Training loss: 2.9521658818331775
Validation loss: 2.5406657590642587

Epoch: 5| Step: 11
Training loss: 2.6946693427053554
Validation loss: 2.5379559732049883

Epoch: 85| Step: 0
Training loss: 2.810781504875798
Validation loss: 2.542891587640999

Epoch: 5| Step: 1
Training loss: 2.8490743572778756
Validation loss: 2.5450691498665887

Epoch: 5| Step: 2
Training loss: 2.8333168216298996
Validation loss: 2.538746928631546

Epoch: 5| Step: 3
Training loss: 2.299557527191224
Validation loss: 2.538112255203148

Epoch: 5| Step: 4
Training loss: 2.9444052515680355
Validation loss: 2.5399234779162536

Epoch: 5| Step: 5
Training loss: 2.54557701689381
Validation loss: 2.534957196101884

Epoch: 5| Step: 6
Training loss: 2.688700829078035
Validation loss: 2.5325026258070285

Epoch: 5| Step: 7
Training loss: 3.1499748168423065
Validation loss: 2.5359337412394405

Epoch: 5| Step: 8
Training loss: 2.03727076358398
Validation loss: 2.534422985395605

Epoch: 5| Step: 9
Training loss: 2.3553845341495596
Validation loss: 2.537949481469721

Epoch: 5| Step: 10
Training loss: 2.73201994704062
Validation loss: 2.5362140778124806

Epoch: 5| Step: 11
Training loss: 2.1833358366663123
Validation loss: 2.5378537239992

Epoch: 86| Step: 0
Training loss: 2.523679361474284
Validation loss: 2.536798275538187

Epoch: 5| Step: 1
Training loss: 2.861994143103492
Validation loss: 2.5398617156625503

Epoch: 5| Step: 2
Training loss: 2.453221604698657
Validation loss: 2.536187685574955

Epoch: 5| Step: 3
Training loss: 2.2472909937540155
Validation loss: 2.5347949506756606

Epoch: 5| Step: 4
Training loss: 3.148884251705618
Validation loss: 2.5367103382280893

Epoch: 5| Step: 5
Training loss: 2.518928301915648
Validation loss: 2.5298389929024063

Epoch: 5| Step: 6
Training loss: 2.745300265150864
Validation loss: 2.5336078368548254

Epoch: 5| Step: 7
Training loss: 2.6804343203293315
Validation loss: 2.5299483747706026

Epoch: 5| Step: 8
Training loss: 2.7573961154325186
Validation loss: 2.5338272447452894

Epoch: 5| Step: 9
Training loss: 2.457221916818347
Validation loss: 2.526801423064584

Epoch: 5| Step: 10
Training loss: 2.80781291776982
Validation loss: 2.5273831544739487

Epoch: 5| Step: 11
Training loss: 2.59622937932134
Validation loss: 2.5248848393116945

Epoch: 87| Step: 0
Training loss: 2.7546364107116763
Validation loss: 2.530285054804306

Epoch: 5| Step: 1
Training loss: 2.6459563119097247
Validation loss: 2.5342522269606054

Epoch: 5| Step: 2
Training loss: 2.1005463252817207
Validation loss: 2.531429908387118

Epoch: 5| Step: 3
Training loss: 2.7161892637228955
Validation loss: 2.5334207857455104

Epoch: 5| Step: 4
Training loss: 2.467561169980188
Validation loss: 2.527977605986095

Epoch: 5| Step: 5
Training loss: 3.1215486923005575
Validation loss: 2.5290972342431894

Epoch: 5| Step: 6
Training loss: 2.5833396193725235
Validation loss: 2.5273519453950573

Epoch: 5| Step: 7
Training loss: 2.3546213931781903
Validation loss: 2.527401172235208

Epoch: 5| Step: 8
Training loss: 2.913528679846164
Validation loss: 2.5269881857696603

Epoch: 5| Step: 9
Training loss: 2.503234678001528
Validation loss: 2.5334786897815422

Epoch: 5| Step: 10
Training loss: 2.8504977812143633
Validation loss: 2.53254182449002

Epoch: 5| Step: 11
Training loss: 3.2794859004112356
Validation loss: 2.529294149232866

Epoch: 88| Step: 0
Training loss: 2.4719444564146995
Validation loss: 2.529020591384525

Epoch: 5| Step: 1
Training loss: 2.85666181738259
Validation loss: 2.5296058691880106

Epoch: 5| Step: 2
Training loss: 2.6759361055213033
Validation loss: 2.5344771507677124

Epoch: 5| Step: 3
Training loss: 2.8495528154727974
Validation loss: 2.5302592367551355

Epoch: 5| Step: 4
Training loss: 2.6759896524397475
Validation loss: 2.5238654302317656

Epoch: 5| Step: 5
Training loss: 2.7484376110360977
Validation loss: 2.526878160752578

Epoch: 5| Step: 6
Training loss: 2.676774290382746
Validation loss: 2.527195481476866

Epoch: 5| Step: 7
Training loss: 2.281835402534603
Validation loss: 2.525480016555677

Epoch: 5| Step: 8
Training loss: 2.514588420855399
Validation loss: 2.52821859305166

Epoch: 5| Step: 9
Training loss: 2.8397310803926055
Validation loss: 2.5220941721718324

Epoch: 5| Step: 10
Training loss: 2.4942211117225748
Validation loss: 2.5248436253032978

Epoch: 5| Step: 11
Training loss: 2.8371760918683795
Validation loss: 2.515795202401162

Epoch: 89| Step: 0
Training loss: 2.6867322490471706
Validation loss: 2.527504803313066

Epoch: 5| Step: 1
Training loss: 2.612238335167842
Validation loss: 2.522882414274755

Epoch: 5| Step: 2
Training loss: 2.4225847742386235
Validation loss: 2.514257327777863

Epoch: 5| Step: 3
Training loss: 2.9453382415051346
Validation loss: 2.516629569357067

Epoch: 5| Step: 4
Training loss: 2.5829984899111067
Validation loss: 2.510054290438909

Epoch: 5| Step: 5
Training loss: 2.7759924067742445
Validation loss: 2.5202971957570393

Epoch: 5| Step: 6
Training loss: 2.314692720654784
Validation loss: 2.5199218092436304

Epoch: 5| Step: 7
Training loss: 2.6019761498404206
Validation loss: 2.520519127981096

Epoch: 5| Step: 8
Training loss: 3.1418620088459317
Validation loss: 2.519821213392221

Epoch: 5| Step: 9
Training loss: 2.3755833762601295
Validation loss: 2.5205461808794203

Epoch: 5| Step: 10
Training loss: 2.600236342765504
Validation loss: 2.5202753510864007

Epoch: 5| Step: 11
Training loss: 2.841461937950994
Validation loss: 2.519509777204304

Epoch: 90| Step: 0
Training loss: 2.3422069301906285
Validation loss: 2.51633910790584

Epoch: 5| Step: 1
Training loss: 2.848520323134633
Validation loss: 2.516801701064029

Epoch: 5| Step: 2
Training loss: 2.7531815244866986
Validation loss: 2.517864166653855

Epoch: 5| Step: 3
Training loss: 2.2340409889524913
Validation loss: 2.5145505897225306

Epoch: 5| Step: 4
Training loss: 2.5108431273162917
Validation loss: 2.5270204922021695

Epoch: 5| Step: 5
Training loss: 2.8768394225027945
Validation loss: 2.52174441107014

Epoch: 5| Step: 6
Training loss: 3.018603973331868
Validation loss: 2.518760512009007

Epoch: 5| Step: 7
Training loss: 2.484234691952374
Validation loss: 2.5169470454551073

Epoch: 5| Step: 8
Training loss: 2.4873951722106433
Validation loss: 2.52153019034881

Epoch: 5| Step: 9
Training loss: 2.773520283068
Validation loss: 2.5223824309999188

Epoch: 5| Step: 10
Training loss: 2.7654374053608137
Validation loss: 2.5209196065426327

Epoch: 5| Step: 11
Training loss: 2.728602130149385
Validation loss: 2.5244600765282215

Epoch: 91| Step: 0
Training loss: 2.2576222059054007
Validation loss: 2.5207402012437923

Epoch: 5| Step: 1
Training loss: 3.1683880661342716
Validation loss: 2.520080159643145

Epoch: 5| Step: 2
Training loss: 2.567895187378055
Validation loss: 2.5191942802839744

Epoch: 5| Step: 3
Training loss: 2.940343738365236
Validation loss: 2.52543498484867

Epoch: 5| Step: 4
Training loss: 2.9575539936931583
Validation loss: 2.523192028629104

Epoch: 5| Step: 5
Training loss: 2.5342768714807034
Validation loss: 2.5183033476945593

Epoch: 5| Step: 6
Training loss: 2.5414697122609673
Validation loss: 2.5181701847862885

Epoch: 5| Step: 7
Training loss: 2.345646205595842
Validation loss: 2.517897497595802

Epoch: 5| Step: 8
Training loss: 2.574492143344504
Validation loss: 2.517934075113916

Epoch: 5| Step: 9
Training loss: 2.805563277264367
Validation loss: 2.518707566578288

Epoch: 5| Step: 10
Training loss: 2.465398614157693
Validation loss: 2.517719826115072

Epoch: 5| Step: 11
Training loss: 1.687765241899633
Validation loss: 2.509649279479176

Epoch: 92| Step: 0
Training loss: 2.5975035199461836
Validation loss: 2.515710232951312

Epoch: 5| Step: 1
Training loss: 2.727508992740621
Validation loss: 2.513409648062557

Epoch: 5| Step: 2
Training loss: 2.9795882097973503
Validation loss: 2.5124532200205025

Epoch: 5| Step: 3
Training loss: 2.6686133392149265
Validation loss: 2.512561456994628

Epoch: 5| Step: 4
Training loss: 2.122895825863691
Validation loss: 2.5082759092312057

Epoch: 5| Step: 5
Training loss: 2.786222149592944
Validation loss: 2.509616009202185

Epoch: 5| Step: 6
Training loss: 2.7104899891800582
Validation loss: 2.516952709232657

Epoch: 5| Step: 7
Training loss: 2.6937635310778014
Validation loss: 2.5139466209409598

Epoch: 5| Step: 8
Training loss: 2.3510398917697826
Validation loss: 2.514525471368988

Epoch: 5| Step: 9
Training loss: 2.7055714732316973
Validation loss: 2.5097945551806684

Epoch: 5| Step: 10
Training loss: 2.660312552768559
Validation loss: 2.5136498620947356

Epoch: 5| Step: 11
Training loss: 2.5654727161111257
Validation loss: 2.5065074269991134

Epoch: 93| Step: 0
Training loss: 2.5216958853303546
Validation loss: 2.503092970466555

Epoch: 5| Step: 1
Training loss: 2.6783499980408862
Validation loss: 2.5051486166156853

Epoch: 5| Step: 2
Training loss: 2.4531281100696845
Validation loss: 2.5025799551965955

Epoch: 5| Step: 3
Training loss: 2.518112185159903
Validation loss: 2.5018097128899712

Epoch: 5| Step: 4
Training loss: 2.4119434129710147
Validation loss: 2.501124796557605

Epoch: 5| Step: 5
Training loss: 2.6298006755299115
Validation loss: 2.4987213123068437

Epoch: 5| Step: 6
Training loss: 2.5998561635945583
Validation loss: 2.4992313912157322

Epoch: 5| Step: 7
Training loss: 2.71947688766452
Validation loss: 2.503986783847676

Epoch: 5| Step: 8
Training loss: 2.8304396793937374
Validation loss: 2.501239989643696

Epoch: 5| Step: 9
Training loss: 2.5390472881154893
Validation loss: 2.500668738250498

Epoch: 5| Step: 10
Training loss: 2.7988258250001454
Validation loss: 2.501008672680639

Epoch: 5| Step: 11
Training loss: 3.2011134832990513
Validation loss: 2.503503192710631

Epoch: 94| Step: 0
Training loss: 2.3321280659014807
Validation loss: 2.504306806799406

Epoch: 5| Step: 1
Training loss: 2.341342350594109
Validation loss: 2.505644208511408

Epoch: 5| Step: 2
Training loss: 2.7407821140469535
Validation loss: 2.5081246479857064

Epoch: 5| Step: 3
Training loss: 3.0195118260715
Validation loss: 2.506166296121622

Epoch: 5| Step: 4
Training loss: 2.5511356592418735
Validation loss: 2.513364929728726

Epoch: 5| Step: 5
Training loss: 2.9416986854546914
Validation loss: 2.5147641804054475

Epoch: 5| Step: 6
Training loss: 2.847004631432644
Validation loss: 2.5146715319909365

Epoch: 5| Step: 7
Training loss: 2.7647066477391373
Validation loss: 2.5145184272811005

Epoch: 5| Step: 8
Training loss: 2.0638543508431355
Validation loss: 2.513169980276297

Epoch: 5| Step: 9
Training loss: 2.803696311133914
Validation loss: 2.5146870157683727

Epoch: 5| Step: 10
Training loss: 2.4468451136375258
Validation loss: 2.51156602694786

Epoch: 5| Step: 11
Training loss: 2.569247967422185
Validation loss: 2.5066011262143357

Epoch: 95| Step: 0
Training loss: 2.975474241267973
Validation loss: 2.504329956991319

Epoch: 5| Step: 1
Training loss: 2.1201910693958337
Validation loss: 2.503932704775866

Epoch: 5| Step: 2
Training loss: 2.7764613041337443
Validation loss: 2.5020977914494624

Epoch: 5| Step: 3
Training loss: 2.531358033688727
Validation loss: 2.504222014815742

Epoch: 5| Step: 4
Training loss: 2.536947455169166
Validation loss: 2.4978224947095584

Epoch: 5| Step: 5
Training loss: 2.7004251392641447
Validation loss: 2.5016901938708496

Epoch: 5| Step: 6
Training loss: 2.327029898726411
Validation loss: 2.500891653633175

Epoch: 5| Step: 7
Training loss: 2.154939999906782
Validation loss: 2.5004348615092327

Epoch: 5| Step: 8
Training loss: 2.9247957207187256
Validation loss: 2.4970862177129804

Epoch: 5| Step: 9
Training loss: 3.0957106725558625
Validation loss: 2.4930504846358965

Epoch: 5| Step: 10
Training loss: 2.6999833918873066
Validation loss: 2.494091681685016

Epoch: 5| Step: 11
Training loss: 1.8346580429974158
Validation loss: 2.4957807819287443

Epoch: 96| Step: 0
Training loss: 2.4688845247725495
Validation loss: 2.49478417928338

Epoch: 5| Step: 1
Training loss: 2.645106738988907
Validation loss: 2.49126218241871

Epoch: 5| Step: 2
Training loss: 2.4662180604331088
Validation loss: 2.4899973757792564

Epoch: 5| Step: 3
Training loss: 2.594746961071963
Validation loss: 2.497470426323893

Epoch: 5| Step: 4
Training loss: 2.3982724807084854
Validation loss: 2.496859083415367

Epoch: 5| Step: 5
Training loss: 3.130845820063842
Validation loss: 2.4931288030720817

Epoch: 5| Step: 6
Training loss: 2.197531125452553
Validation loss: 2.4973583211988646

Epoch: 5| Step: 7
Training loss: 2.7402949309506357
Validation loss: 2.4908587741307686

Epoch: 5| Step: 8
Training loss: 2.247494468130532
Validation loss: 2.49436822986377

Epoch: 5| Step: 9
Training loss: 2.6574208988679673
Validation loss: 2.4901250678113924

Epoch: 5| Step: 10
Training loss: 3.092618793250505
Validation loss: 2.4942313117794472

Epoch: 5| Step: 11
Training loss: 2.769097943971886
Validation loss: 2.4919432198478435

Epoch: 97| Step: 0
Training loss: 2.145529703923649
Validation loss: 2.4867765147676466

Epoch: 5| Step: 1
Training loss: 2.7997311122395816
Validation loss: 2.498413587928523

Epoch: 5| Step: 2
Training loss: 2.6142615516701406
Validation loss: 2.5142582365330157

Epoch: 5| Step: 3
Training loss: 2.723969196324664
Validation loss: 2.5078087882928526

Epoch: 5| Step: 4
Training loss: 2.5059972354968045
Validation loss: 2.5017603120700267

Epoch: 5| Step: 5
Training loss: 2.507124857048034
Validation loss: 2.5037647471165814

Epoch: 5| Step: 6
Training loss: 2.1203158868412637
Validation loss: 2.5001870522458116

Epoch: 5| Step: 7
Training loss: 2.8558003745743408
Validation loss: 2.4945905852596026

Epoch: 5| Step: 8
Training loss: 2.6573277699166167
Validation loss: 2.4930842668609126

Epoch: 5| Step: 9
Training loss: 2.8987155174319845
Validation loss: 2.4863884442312587

Epoch: 5| Step: 10
Training loss: 2.7579310232310283
Validation loss: 2.489650072349769

Epoch: 5| Step: 11
Training loss: 2.8563938964389646
Validation loss: 2.4848229906040595

Epoch: 98| Step: 0
Training loss: 2.4243429099917053
Validation loss: 2.490526602559132

Epoch: 5| Step: 1
Training loss: 2.2601209408968512
Validation loss: 2.4921251167613296

Epoch: 5| Step: 2
Training loss: 2.9555384547791324
Validation loss: 2.488019225788349

Epoch: 5| Step: 3
Training loss: 2.6451485616286163
Validation loss: 2.4888318469213133

Epoch: 5| Step: 4
Training loss: 2.5682485346211132
Validation loss: 2.484643841638459

Epoch: 5| Step: 5
Training loss: 2.747744068415968
Validation loss: 2.4900945866064115

Epoch: 5| Step: 6
Training loss: 2.496048952276751
Validation loss: 2.4981771220913678

Epoch: 5| Step: 7
Training loss: 2.630406488690645
Validation loss: 2.495000401779071

Epoch: 5| Step: 8
Training loss: 2.3087932674730127
Validation loss: 2.4921788939962206

Epoch: 5| Step: 9
Training loss: 2.660629432034716
Validation loss: 2.494178459021921

Epoch: 5| Step: 10
Training loss: 2.8389852661309454
Validation loss: 2.4925356933604137

Epoch: 5| Step: 11
Training loss: 3.0764245307949225
Validation loss: 2.4972930279767795

Epoch: 99| Step: 0
Training loss: 2.2224706696333185
Validation loss: 2.4876910896641795

Epoch: 5| Step: 1
Training loss: 2.8403335002064494
Validation loss: 2.488839871766736

Epoch: 5| Step: 2
Training loss: 2.736510048154829
Validation loss: 2.4916960372171904

Epoch: 5| Step: 3
Training loss: 2.3841730954740115
Validation loss: 2.4946511666402382

Epoch: 5| Step: 4
Training loss: 2.301018953592621
Validation loss: 2.4930047754968045

Epoch: 5| Step: 5
Training loss: 2.6060738154077216
Validation loss: 2.493766218864072

Epoch: 5| Step: 6
Training loss: 2.753324926177237
Validation loss: 2.495562736211552

Epoch: 5| Step: 7
Training loss: 2.890872429233018
Validation loss: 2.48365448154187

Epoch: 5| Step: 8
Training loss: 2.3120267229086795
Validation loss: 2.4861116437420074

Epoch: 5| Step: 9
Training loss: 2.9964691682881477
Validation loss: 2.488998808667511

Epoch: 5| Step: 10
Training loss: 2.6348581036286043
Validation loss: 2.4956033550291563

Epoch: 5| Step: 11
Training loss: 2.1594187355304917
Validation loss: 2.4946596287221667

Epoch: 100| Step: 0
Training loss: 2.970869412053745
Validation loss: 2.489896416762935

Epoch: 5| Step: 1
Training loss: 2.571226844368068
Validation loss: 2.4893640011905105

Epoch: 5| Step: 2
Training loss: 2.700763707411569
Validation loss: 2.4896955378371417

Epoch: 5| Step: 3
Training loss: 2.260140561821741
Validation loss: 2.492603510432585

Epoch: 5| Step: 4
Training loss: 2.318093828581559
Validation loss: 2.491485421075233

Epoch: 5| Step: 5
Training loss: 2.208393156093059
Validation loss: 2.4892758907171975

Epoch: 5| Step: 6
Training loss: 2.6127308720691613
Validation loss: 2.4895446659953198

Epoch: 5| Step: 7
Training loss: 2.8260107409684148
Validation loss: 2.4839777638890834

Epoch: 5| Step: 8
Training loss: 2.5726194840719567
Validation loss: 2.48339117311372

Epoch: 5| Step: 9
Training loss: 2.9520285856832276
Validation loss: 2.486798753569016

Epoch: 5| Step: 10
Training loss: 2.4311787729690413
Validation loss: 2.4820535918340805

Epoch: 5| Step: 11
Training loss: 2.9300658935324124
Validation loss: 2.477418500898713

Epoch: 101| Step: 0
Training loss: 2.442913109194825
Validation loss: 2.4875390120023795

Epoch: 5| Step: 1
Training loss: 2.248518774115811
Validation loss: 2.47987112219943

Epoch: 5| Step: 2
Training loss: 2.623533293274162
Validation loss: 2.4846612177626923

Epoch: 5| Step: 3
Training loss: 2.1694133172900343
Validation loss: 2.4855680020461755

Epoch: 5| Step: 4
Training loss: 2.701741211663061
Validation loss: 2.4850884178967263

Epoch: 5| Step: 5
Training loss: 2.569972795572535
Validation loss: 2.4863848323902813

Epoch: 5| Step: 6
Training loss: 2.1332493149584058
Validation loss: 2.4870499778905697

Epoch: 5| Step: 7
Training loss: 2.472344112129814
Validation loss: 2.485377439352948

Epoch: 5| Step: 8
Training loss: 3.07882372676097
Validation loss: 2.4815213390575277

Epoch: 5| Step: 9
Training loss: 3.0445872007284263
Validation loss: 2.486027238154426

Epoch: 5| Step: 10
Training loss: 2.8358092055712834
Validation loss: 2.4869816139302356

Epoch: 5| Step: 11
Training loss: 3.114474614690143
Validation loss: 2.4839209495541894

Epoch: 102| Step: 0
Training loss: 2.905467594615258
Validation loss: 2.4876453818835436

Epoch: 5| Step: 1
Training loss: 2.4366375302070025
Validation loss: 2.484302595670936

Epoch: 5| Step: 2
Training loss: 2.580596848581674
Validation loss: 2.4858917188954486

Epoch: 5| Step: 3
Training loss: 2.295878706781977
Validation loss: 2.4819820423589594

Epoch: 5| Step: 4
Training loss: 2.570104897877943
Validation loss: 2.4878468436215497

Epoch: 5| Step: 5
Training loss: 2.775655713666251
Validation loss: 2.485641096896047

Epoch: 5| Step: 6
Training loss: 2.4541252672452445
Validation loss: 2.483152368584977

Epoch: 5| Step: 7
Training loss: 2.7838624835745054
Validation loss: 2.490457322855344

Epoch: 5| Step: 8
Training loss: 2.903320969454181
Validation loss: 2.477123726391661

Epoch: 5| Step: 9
Training loss: 2.498499992500383
Validation loss: 2.481018482076115

Epoch: 5| Step: 10
Training loss: 2.3318995657439445
Validation loss: 2.4866861233981283

Epoch: 5| Step: 11
Training loss: 3.428906188811873
Validation loss: 2.4862545429058454

Epoch: 103| Step: 0
Training loss: 2.2263610748734513
Validation loss: 2.4886105896858304

Epoch: 5| Step: 1
Training loss: 2.7664204978198916
Validation loss: 2.485131238603453

Epoch: 5| Step: 2
Training loss: 2.4782562721378563
Validation loss: 2.4851624582391585

Epoch: 5| Step: 3
Training loss: 2.6076118771479897
Validation loss: 2.4886614091395938

Epoch: 5| Step: 4
Training loss: 2.497076614127266
Validation loss: 2.495598689710525

Epoch: 5| Step: 5
Training loss: 2.4057243070176875
Validation loss: 2.487757521387092

Epoch: 5| Step: 6
Training loss: 2.5068857732677814
Validation loss: 2.49448181543013

Epoch: 5| Step: 7
Training loss: 2.6597829324307924
Validation loss: 2.4986217355304947

Epoch: 5| Step: 8
Training loss: 2.9742568490323955
Validation loss: 2.504497246071633

Epoch: 5| Step: 9
Training loss: 2.812479824417652
Validation loss: 2.4954836780911376

Epoch: 5| Step: 10
Training loss: 2.548163339730172
Validation loss: 2.4903251960498736

Epoch: 5| Step: 11
Training loss: 3.506174907458191
Validation loss: 2.4828965588362673

Epoch: 104| Step: 0
Training loss: 2.890371610515679
Validation loss: 2.4886128670231273

Epoch: 5| Step: 1
Training loss: 2.5550565773808107
Validation loss: 2.4898134002894587

Epoch: 5| Step: 2
Training loss: 2.7428038684178477
Validation loss: 2.4949298427492983

Epoch: 5| Step: 3
Training loss: 3.1103015841746027
Validation loss: 2.504161946635524

Epoch: 5| Step: 4
Training loss: 2.6009754515196715
Validation loss: 2.5120014132477495

Epoch: 5| Step: 5
Training loss: 2.3012779748843877
Validation loss: 2.5195435043155237

Epoch: 5| Step: 6
Training loss: 2.261360522216214
Validation loss: 2.520749667384456

Epoch: 5| Step: 7
Training loss: 2.832319826353458
Validation loss: 2.5282448838034224

Epoch: 5| Step: 8
Training loss: 2.9210437265353533
Validation loss: 2.5199406727361873

Epoch: 5| Step: 9
Training loss: 2.26721998174365
Validation loss: 2.520775271501054

Epoch: 5| Step: 10
Training loss: 2.2082009785653707
Validation loss: 2.5175788194780204

Epoch: 5| Step: 11
Training loss: 2.798256133489363
Validation loss: 2.511490621139033

Epoch: 105| Step: 0
Training loss: 2.5567355564522978
Validation loss: 2.5153060971582724

Epoch: 5| Step: 1
Training loss: 2.238816654953203
Validation loss: 2.508771231808078

Epoch: 5| Step: 2
Training loss: 2.6680193291668832
Validation loss: 2.507296987532414

Epoch: 5| Step: 3
Training loss: 2.4673857963747494
Validation loss: 2.507256601741111

Epoch: 5| Step: 4
Training loss: 2.7700367023777015
Validation loss: 2.499875780834208

Epoch: 5| Step: 5
Training loss: 2.5173668369505795
Validation loss: 2.496762380658214

Epoch: 5| Step: 6
Training loss: 2.8785348805376114
Validation loss: 2.492707902711947

Epoch: 5| Step: 7
Training loss: 2.6503853175897945
Validation loss: 2.492342307326085

Epoch: 5| Step: 8
Training loss: 2.784617496295944
Validation loss: 2.4868417685270456

Epoch: 5| Step: 9
Training loss: 2.8173000488818523
Validation loss: 2.484983349737293

Epoch: 5| Step: 10
Training loss: 2.5664453605098756
Validation loss: 2.4861644362361024

Epoch: 5| Step: 11
Training loss: 2.0795748822725773
Validation loss: 2.4838671015149814

Epoch: 106| Step: 0
Training loss: 2.8861878026817025
Validation loss: 2.4820125711610914

Epoch: 5| Step: 1
Training loss: 1.922284958697035
Validation loss: 2.4827118630936464

Epoch: 5| Step: 2
Training loss: 2.822878528820637
Validation loss: 2.481552944378721

Epoch: 5| Step: 3
Training loss: 2.665270221172269
Validation loss: 2.47962512791373

Epoch: 5| Step: 4
Training loss: 2.7021424376514522
Validation loss: 2.483589424032736

Epoch: 5| Step: 5
Training loss: 2.315000573934727
Validation loss: 2.4789789887456397

Epoch: 5| Step: 6
Training loss: 2.5433803055384923
Validation loss: 2.482185494578467

Epoch: 5| Step: 7
Training loss: 2.4447853568317615
Validation loss: 2.4797110574264716

Epoch: 5| Step: 8
Training loss: 2.5994259420632635
Validation loss: 2.479768525057573

Epoch: 5| Step: 9
Training loss: 2.7032578275823513
Validation loss: 2.4764381040504944

Epoch: 5| Step: 10
Training loss: 2.7060695773058865
Validation loss: 2.477346330342813

Epoch: 5| Step: 11
Training loss: 3.4686188544148444
Validation loss: 2.4764732721823295

Epoch: 107| Step: 0
Training loss: 2.9468763333233663
Validation loss: 2.47654810759878

Epoch: 5| Step: 1
Training loss: 2.9371308439707775
Validation loss: 2.4766520254357824

Epoch: 5| Step: 2
Training loss: 2.212984788445045
Validation loss: 2.4746834880084845

Epoch: 5| Step: 3
Training loss: 2.1389815432914574
Validation loss: 2.4832632268273476

Epoch: 5| Step: 4
Training loss: 2.358636904836911
Validation loss: 2.4799957304963924

Epoch: 5| Step: 5
Training loss: 2.432205906621516
Validation loss: 2.482434644648745

Epoch: 5| Step: 6
Training loss: 2.5209784557930583
Validation loss: 2.482978188211887

Epoch: 5| Step: 7
Training loss: 2.780698571564066
Validation loss: 2.481072231782143

Epoch: 5| Step: 8
Training loss: 2.269667708320993
Validation loss: 2.4813249086656004

Epoch: 5| Step: 9
Training loss: 2.7236102278666534
Validation loss: 2.480049013684058

Epoch: 5| Step: 10
Training loss: 2.9471855380209813
Validation loss: 2.4755472836056853

Epoch: 5| Step: 11
Training loss: 3.240365640235971
Validation loss: 2.475498885631214

Epoch: 108| Step: 0
Training loss: 2.1075178094475673
Validation loss: 2.4785625512440643

Epoch: 5| Step: 1
Training loss: 2.275115347652354
Validation loss: 2.4744429378042683

Epoch: 5| Step: 2
Training loss: 2.4336459673182507
Validation loss: 2.480398184105465

Epoch: 5| Step: 3
Training loss: 2.503086473642341
Validation loss: 2.478719562129464

Epoch: 5| Step: 4
Training loss: 2.914629597236485
Validation loss: 2.4818485497351115

Epoch: 5| Step: 5
Training loss: 2.6829309880569094
Validation loss: 2.479327997333151

Epoch: 5| Step: 6
Training loss: 2.3582218206706216
Validation loss: 2.480616635697484

Epoch: 5| Step: 7
Training loss: 2.7283618312956044
Validation loss: 2.479749948876621

Epoch: 5| Step: 8
Training loss: 2.5707250571260896
Validation loss: 2.4808049852658494

Epoch: 5| Step: 9
Training loss: 3.2225414278787063
Validation loss: 2.4810941853833075

Epoch: 5| Step: 10
Training loss: 2.5370770482447846
Validation loss: 2.4795635103452445

Epoch: 5| Step: 11
Training loss: 2.3755702287862914
Validation loss: 2.477951298190456

Epoch: 109| Step: 0
Training loss: 2.0754094558628338
Validation loss: 2.4750851738527757

Epoch: 5| Step: 1
Training loss: 2.7016281658286965
Validation loss: 2.473863725693691

Epoch: 5| Step: 2
Training loss: 3.057287178274539
Validation loss: 2.4746543400469623

Epoch: 5| Step: 3
Training loss: 2.664534988342537
Validation loss: 2.4696752810128673

Epoch: 5| Step: 4
Training loss: 3.209583154630716
Validation loss: 2.4677936013206465

Epoch: 5| Step: 5
Training loss: 2.9443137501755237
Validation loss: 2.472338016675899

Epoch: 5| Step: 6
Training loss: 2.068116142228618
Validation loss: 2.468430277083839

Epoch: 5| Step: 7
Training loss: 2.2805667010628796
Validation loss: 2.471811593227514

Epoch: 5| Step: 8
Training loss: 2.799948766784609
Validation loss: 2.460468219235299

Epoch: 5| Step: 9
Training loss: 2.068685792231972
Validation loss: 2.464564691012493

Epoch: 5| Step: 10
Training loss: 2.0659434155362315
Validation loss: 2.4696141472941786

Epoch: 5| Step: 11
Training loss: 2.837482126322509
Validation loss: 2.4700978116856844

Epoch: 110| Step: 0
Training loss: 1.8681015267401782
Validation loss: 2.4640766568322494

Epoch: 5| Step: 1
Training loss: 2.4295745528975146
Validation loss: 2.46838057043513

Epoch: 5| Step: 2
Training loss: 2.925419417086914
Validation loss: 2.4674626184728394

Epoch: 5| Step: 3
Training loss: 2.3533869664651887
Validation loss: 2.467054392384978

Epoch: 5| Step: 4
Training loss: 2.4149000572864563
Validation loss: 2.469740017227925

Epoch: 5| Step: 5
Training loss: 2.6858188782706476
Validation loss: 2.4741676456179236

Epoch: 5| Step: 6
Training loss: 2.5318437044859845
Validation loss: 2.4768598400084865

Epoch: 5| Step: 7
Training loss: 3.023368262944716
Validation loss: 2.467648083192985

Epoch: 5| Step: 8
Training loss: 2.3809332769626588
Validation loss: 2.4762754865654157

Epoch: 5| Step: 9
Training loss: 2.420593808832787
Validation loss: 2.4796345707308887

Epoch: 5| Step: 10
Training loss: 2.9802489193380843
Validation loss: 2.4782452807874567

Epoch: 5| Step: 11
Training loss: 3.0909451186788437
Validation loss: 2.4666776429449766

Epoch: 111| Step: 0
Training loss: 2.407464649737123
Validation loss: 2.4768775635240066

Epoch: 5| Step: 1
Training loss: 2.5096825968148586
Validation loss: 2.4602892753596386

Epoch: 5| Step: 2
Training loss: 2.5884838647868214
Validation loss: 2.4741380980917183

Epoch: 5| Step: 3
Training loss: 2.983967538549668
Validation loss: 2.4751231426211944

Epoch: 5| Step: 4
Training loss: 2.778985977208852
Validation loss: 2.479117883207629

Epoch: 5| Step: 5
Training loss: 2.449847127076488
Validation loss: 2.4754436946134564

Epoch: 5| Step: 6
Training loss: 2.7524232591399955
Validation loss: 2.4748625792618717

Epoch: 5| Step: 7
Training loss: 2.1743378431495746
Validation loss: 2.4708455121371156

Epoch: 5| Step: 8
Training loss: 2.3089735619116416
Validation loss: 2.4712914973768823

Epoch: 5| Step: 9
Training loss: 2.7537725754347973
Validation loss: 2.472101841423345

Epoch: 5| Step: 10
Training loss: 2.642088715766831
Validation loss: 2.475874150319677

Epoch: 5| Step: 11
Training loss: 2.5874432101444578
Validation loss: 2.480575855575983

Epoch: 112| Step: 0
Training loss: 2.7061080789685015
Validation loss: 2.4807841663616155

Epoch: 5| Step: 1
Training loss: 2.4470929863538706
Validation loss: 2.4825586200770644

Epoch: 5| Step: 2
Training loss: 2.438252161812584
Validation loss: 2.4797722587049242

Epoch: 5| Step: 3
Training loss: 2.4458660437645654
Validation loss: 2.481042878596984

Epoch: 5| Step: 4
Training loss: 2.3787343631777684
Validation loss: 2.4787363686044896

Epoch: 5| Step: 5
Training loss: 2.872185365926983
Validation loss: 2.4788661796055496

Epoch: 5| Step: 6
Training loss: 3.0331900768895945
Validation loss: 2.4715333571488203

Epoch: 5| Step: 7
Training loss: 2.377630784441782
Validation loss: 2.4697027339768747

Epoch: 5| Step: 8
Training loss: 2.382933566660572
Validation loss: 2.465184548380729

Epoch: 5| Step: 9
Training loss: 2.8237174236821487
Validation loss: 2.4593208815983365

Epoch: 5| Step: 10
Training loss: 2.5892944674038567
Validation loss: 2.4697863017366775

Epoch: 5| Step: 11
Training loss: 2.6238834186161024
Validation loss: 2.4715049960246502

Epoch: 113| Step: 0
Training loss: 3.0695184743784782
Validation loss: 2.474201272112383

Epoch: 5| Step: 1
Training loss: 2.611983223503413
Validation loss: 2.4842454888516965

Epoch: 5| Step: 2
Training loss: 3.0727085538748486
Validation loss: 2.481939033233668

Epoch: 5| Step: 3
Training loss: 2.4267221490400086
Validation loss: 2.4876182028068015

Epoch: 5| Step: 4
Training loss: 2.473707605338882
Validation loss: 2.4931207581626884

Epoch: 5| Step: 5
Training loss: 2.0263290659064737
Validation loss: 2.4946982433265044

Epoch: 5| Step: 6
Training loss: 2.6933916849324264
Validation loss: 2.5011594547326963

Epoch: 5| Step: 7
Training loss: 2.6327358879918834
Validation loss: 2.5092551656053326

Epoch: 5| Step: 8
Training loss: 2.6758278501587696
Validation loss: 2.5083783185817814

Epoch: 5| Step: 9
Training loss: 2.5362427063033812
Validation loss: 2.5070964785330525

Epoch: 5| Step: 10
Training loss: 2.5340615188007756
Validation loss: 2.5105905248395652

Epoch: 5| Step: 11
Training loss: 1.2451395907910967
Validation loss: 2.502884091306625

Epoch: 114| Step: 0
Training loss: 2.6604691152000526
Validation loss: 2.505121988300821

Epoch: 5| Step: 1
Training loss: 2.8631198728291074
Validation loss: 2.5025545737876653

Epoch: 5| Step: 2
Training loss: 2.667836220885935
Validation loss: 2.4958041544966814

Epoch: 5| Step: 3
Training loss: 2.5165083382762257
Validation loss: 2.493981627412682

Epoch: 5| Step: 4
Training loss: 2.420162259801919
Validation loss: 2.493745944371188

Epoch: 5| Step: 5
Training loss: 2.6239562002922696
Validation loss: 2.4890329132907874

Epoch: 5| Step: 6
Training loss: 2.480836567678533
Validation loss: 2.4775660594431117

Epoch: 5| Step: 7
Training loss: 2.7834256695566304
Validation loss: 2.4782720415539816

Epoch: 5| Step: 8
Training loss: 2.9504765335802148
Validation loss: 2.476086298971335

Epoch: 5| Step: 9
Training loss: 2.3075768930966767
Validation loss: 2.472635772282806

Epoch: 5| Step: 10
Training loss: 2.482148426280973
Validation loss: 2.4697508976045266

Epoch: 5| Step: 11
Training loss: 1.4841546146018432
Validation loss: 2.467217202920792

Epoch: 115| Step: 0
Training loss: 2.6803837975359994
Validation loss: 2.4776530186347254

Epoch: 5| Step: 1
Training loss: 2.3425759999130555
Validation loss: 2.4693548250319597

Epoch: 5| Step: 2
Training loss: 2.3823119591461817
Validation loss: 2.4805632565734674

Epoch: 5| Step: 3
Training loss: 2.9531220935625577
Validation loss: 2.470086645281025

Epoch: 5| Step: 4
Training loss: 2.9047883983240648
Validation loss: 2.4733697023656784

Epoch: 5| Step: 5
Training loss: 2.68973678832679
Validation loss: 2.4662269805856063

Epoch: 5| Step: 6
Training loss: 2.3914100504872713
Validation loss: 2.4696224940386178

Epoch: 5| Step: 7
Training loss: 1.9850139640489894
Validation loss: 2.463342260687382

Epoch: 5| Step: 8
Training loss: 2.79994033681791
Validation loss: 2.4671787742571576

Epoch: 5| Step: 9
Training loss: 1.7214358065622144
Validation loss: 2.471999918453386

Epoch: 5| Step: 10
Training loss: 2.8896999219180026
Validation loss: 2.46277742178643

Epoch: 5| Step: 11
Training loss: 3.7589574009540865
Validation loss: 2.4733929613818173

Epoch: 116| Step: 0
Training loss: 2.730749025817714
Validation loss: 2.473722305415901

Epoch: 5| Step: 1
Training loss: 2.360303481357617
Validation loss: 2.483933083599127

Epoch: 5| Step: 2
Training loss: 2.091846340816272
Validation loss: 2.482402270199896

Epoch: 5| Step: 3
Training loss: 2.6300661155599867
Validation loss: 2.468281991273542

Epoch: 5| Step: 4
Training loss: 2.5118924521366504
Validation loss: 2.476715359949308

Epoch: 5| Step: 5
Training loss: 2.7544168201904635
Validation loss: 2.4759559730997136

Epoch: 5| Step: 6
Training loss: 2.510449790472253
Validation loss: 2.4819236793697788

Epoch: 5| Step: 7
Training loss: 2.543061754251654
Validation loss: 2.48006562489031

Epoch: 5| Step: 8
Training loss: 2.619821981832296
Validation loss: 2.4801716143439947

Epoch: 5| Step: 9
Training loss: 2.7970004772830976
Validation loss: 2.478663615204176

Epoch: 5| Step: 10
Training loss: 2.8138332173985887
Validation loss: 2.4802778556038003

Epoch: 5| Step: 11
Training loss: 2.4960460867233842
Validation loss: 2.478784889723324

Epoch: 117| Step: 0
Training loss: 2.2499541172011703
Validation loss: 2.47927657987002

Epoch: 5| Step: 1
Training loss: 2.4371449138522157
Validation loss: 2.475843353230879

Epoch: 5| Step: 2
Training loss: 2.620085156927771
Validation loss: 2.4774325233480767

Epoch: 5| Step: 3
Training loss: 2.6669905783705325
Validation loss: 2.4813450584491603

Epoch: 5| Step: 4
Training loss: 2.1778458228909803
Validation loss: 2.474982169597632

Epoch: 5| Step: 5
Training loss: 2.944049432837071
Validation loss: 2.4726409750934155

Epoch: 5| Step: 6
Training loss: 2.2100354838219674
Validation loss: 2.4711126900259734

Epoch: 5| Step: 7
Training loss: 2.962137990474005
Validation loss: 2.4691532948398276

Epoch: 5| Step: 8
Training loss: 2.79879422110702
Validation loss: 2.4640903278618675

Epoch: 5| Step: 9
Training loss: 2.5166019414532115
Validation loss: 2.466183819557146

Epoch: 5| Step: 10
Training loss: 2.6765002099230744
Validation loss: 2.4643250658711944

Epoch: 5| Step: 11
Training loss: 2.2229674109757007
Validation loss: 2.471272338916725

Epoch: 118| Step: 0
Training loss: 2.764435593184393
Validation loss: 2.4747325863532383

Epoch: 5| Step: 1
Training loss: 2.614308518839589
Validation loss: 2.4746873136278578

Epoch: 5| Step: 2
Training loss: 2.791439123037526
Validation loss: 2.464732321242213

Epoch: 5| Step: 3
Training loss: 3.0846655433421346
Validation loss: 2.4679832676235813

Epoch: 5| Step: 4
Training loss: 2.3380966159512018
Validation loss: 2.468704951555352

Epoch: 5| Step: 5
Training loss: 2.177562046502838
Validation loss: 2.4671779810355616

Epoch: 5| Step: 6
Training loss: 2.484575851286718
Validation loss: 2.470807160007829

Epoch: 5| Step: 7
Training loss: 2.5232407815035947
Validation loss: 2.4713556003599897

Epoch: 5| Step: 8
Training loss: 2.925926459545332
Validation loss: 2.474399291777877

Epoch: 5| Step: 9
Training loss: 2.2182915442256697
Validation loss: 2.47173704042867

Epoch: 5| Step: 10
Training loss: 2.609644162121163
Validation loss: 2.475976736308398

Epoch: 5| Step: 11
Training loss: 1.246757450155698
Validation loss: 2.475912560379033

Epoch: 119| Step: 0
Training loss: 2.8364881080823308
Validation loss: 2.475681966691022

Epoch: 5| Step: 1
Training loss: 2.3049988617139143
Validation loss: 2.4714480718224765

Epoch: 5| Step: 2
Training loss: 2.35357296189234
Validation loss: 2.4773096387606532

Epoch: 5| Step: 3
Training loss: 2.6045053694126485
Validation loss: 2.4813217258415894

Epoch: 5| Step: 4
Training loss: 2.783108379692173
Validation loss: 2.4723599333186153

Epoch: 5| Step: 5
Training loss: 2.674782403669955
Validation loss: 2.4710138821586924

Epoch: 5| Step: 6
Training loss: 2.333759427902066
Validation loss: 2.477181727254779

Epoch: 5| Step: 7
Training loss: 2.757958600115965
Validation loss: 2.4717171941348344

Epoch: 5| Step: 8
Training loss: 2.4829878863355264
Validation loss: 2.4728770627002885

Epoch: 5| Step: 9
Training loss: 2.901483215662128
Validation loss: 2.474537317219947

Epoch: 5| Step: 10
Training loss: 2.112554795496924
Validation loss: 2.467108981860297

Epoch: 5| Step: 11
Training loss: 2.8507229339832185
Validation loss: 2.4713377206708715

Epoch: 120| Step: 0
Training loss: 2.727393955368524
Validation loss: 2.468424099524692

Epoch: 5| Step: 1
Training loss: 2.431648468862851
Validation loss: 2.470313538807074

Epoch: 5| Step: 2
Training loss: 2.563368301285375
Validation loss: 2.473305261980459

Epoch: 5| Step: 3
Training loss: 2.3153452509910095
Validation loss: 2.48478712106494

Epoch: 5| Step: 4
Training loss: 2.4666242501332087
Validation loss: 2.502527659844816

Epoch: 5| Step: 5
Training loss: 2.081003934043528
Validation loss: 2.4998711632273567

Epoch: 5| Step: 6
Training loss: 2.7508529727407676
Validation loss: 2.5036106183060878

Epoch: 5| Step: 7
Training loss: 2.7413035649929607
Validation loss: 2.4903646277975793

Epoch: 5| Step: 8
Training loss: 2.935768266300242
Validation loss: 2.4708610333427985

Epoch: 5| Step: 9
Training loss: 3.110907248977887
Validation loss: 2.4605514284083605

Epoch: 5| Step: 10
Training loss: 2.164124305476005
Validation loss: 2.4585540209060235

Epoch: 5| Step: 11
Training loss: 2.7890047126147537
Validation loss: 2.475930222466853

Epoch: 121| Step: 0
Training loss: 2.865729935949286
Validation loss: 2.4711978341685876

Epoch: 5| Step: 1
Training loss: 2.4873484924796467
Validation loss: 2.4774801457524087

Epoch: 5| Step: 2
Training loss: 2.1448863140292223
Validation loss: 2.4778738591309026

Epoch: 5| Step: 3
Training loss: 2.8992346312679755
Validation loss: 2.477596672730536

Epoch: 5| Step: 4
Training loss: 2.517583901788611
Validation loss: 2.4818767206126333

Epoch: 5| Step: 5
Training loss: 2.761316078538584
Validation loss: 2.483267981327511

Epoch: 5| Step: 6
Training loss: 2.5016719949027224
Validation loss: 2.486366081896993

Epoch: 5| Step: 7
Training loss: 1.8924143496927017
Validation loss: 2.487680147986404

Epoch: 5| Step: 8
Training loss: 2.649238487806845
Validation loss: 2.4862010950329436

Epoch: 5| Step: 9
Training loss: 2.5294105533696105
Validation loss: 2.487648021504768

Epoch: 5| Step: 10
Training loss: 2.8061764306023185
Validation loss: 2.4891058265697126

Epoch: 5| Step: 11
Training loss: 3.966126784013607
Validation loss: 2.488328375337656

Epoch: 122| Step: 0
Training loss: 2.4777782837430533
Validation loss: 2.4828442830187463

Epoch: 5| Step: 1
Training loss: 2.49775766901193
Validation loss: 2.474730651501087

Epoch: 5| Step: 2
Training loss: 2.609498529308436
Validation loss: 2.4733337189394744

Epoch: 5| Step: 3
Training loss: 2.4337340386430086
Validation loss: 2.4703762195017114

Epoch: 5| Step: 4
Training loss: 2.716572031662413
Validation loss: 2.471314775952247

Epoch: 5| Step: 5
Training loss: 2.517347326715957
Validation loss: 2.468959944284624

Epoch: 5| Step: 6
Training loss: 2.967340395715977
Validation loss: 2.468425053324736

Epoch: 5| Step: 7
Training loss: 2.533959528008962
Validation loss: 2.464655414042101

Epoch: 5| Step: 8
Training loss: 2.9477723067200468
Validation loss: 2.460437190955141

Epoch: 5| Step: 9
Training loss: 2.2722962126723267
Validation loss: 2.462969212761802

Epoch: 5| Step: 10
Training loss: 2.195757837704796
Validation loss: 2.464445485999949

Epoch: 5| Step: 11
Training loss: 2.820194146798189
Validation loss: 2.4585583080108577

Epoch: 123| Step: 0
Training loss: 2.6723509247527457
Validation loss: 2.4743226750105443

Epoch: 5| Step: 1
Training loss: 2.3209633476325013
Validation loss: 2.4731457041530205

Epoch: 5| Step: 2
Training loss: 2.665646616232053
Validation loss: 2.474785537290386

Epoch: 5| Step: 3
Training loss: 2.581128953954242
Validation loss: 2.470747043385136

Epoch: 5| Step: 4
Training loss: 2.4246531641579545
Validation loss: 2.466371774981302

Epoch: 5| Step: 5
Training loss: 2.780629978291228
Validation loss: 2.4678461416101953

Epoch: 5| Step: 6
Training loss: 2.629922248213192
Validation loss: 2.464942122086858

Epoch: 5| Step: 7
Training loss: 2.160523533423453
Validation loss: 2.4515297718347475

Epoch: 5| Step: 8
Training loss: 2.906396185367012
Validation loss: 2.4647307392698434

Epoch: 5| Step: 9
Training loss: 2.8746783864461234
Validation loss: 2.4617819250634927

Epoch: 5| Step: 10
Training loss: 2.4934843987924777
Validation loss: 2.4627292992647325

Epoch: 5| Step: 11
Training loss: 0.8829991641229668
Validation loss: 2.469601090113524

Epoch: 124| Step: 0
Training loss: 1.7467843893773531
Validation loss: 2.465043827083815

Epoch: 5| Step: 1
Training loss: 2.7671747553061783
Validation loss: 2.4634760000390097

Epoch: 5| Step: 2
Training loss: 2.7098106658786456
Validation loss: 2.466082048782947

Epoch: 5| Step: 3
Training loss: 2.2774746106404384
Validation loss: 2.466208529992939

Epoch: 5| Step: 4
Training loss: 2.2421475184262
Validation loss: 2.471453293211552

Epoch: 5| Step: 5
Training loss: 2.57219722022513
Validation loss: 2.464132197185961

Epoch: 5| Step: 6
Training loss: 2.6364613951372995
Validation loss: 2.4625208368081424

Epoch: 5| Step: 7
Training loss: 2.8548281012258565
Validation loss: 2.4680131464458124

Epoch: 5| Step: 8
Training loss: 2.863833094523166
Validation loss: 2.4625017028970526

Epoch: 5| Step: 9
Training loss: 2.6551975633640494
Validation loss: 2.4672061402460455

Epoch: 5| Step: 10
Training loss: 2.76432123002971
Validation loss: 2.4732146594293347

Epoch: 5| Step: 11
Training loss: 2.179933267499428
Validation loss: 2.467733866177196

Epoch: 125| Step: 0
Training loss: 2.6761452977146027
Validation loss: 2.473824107226425

Epoch: 5| Step: 1
Training loss: 2.0664427092423963
Validation loss: 2.468966048078421

Epoch: 5| Step: 2
Training loss: 1.9632295989571458
Validation loss: 2.4687357350834636

Epoch: 5| Step: 3
Training loss: 2.788221643889761
Validation loss: 2.470282561804208

Epoch: 5| Step: 4
Training loss: 2.7301814592579876
Validation loss: 2.4767424902105963

Epoch: 5| Step: 5
Training loss: 2.672634440681259
Validation loss: 2.473479569270739

Epoch: 5| Step: 6
Training loss: 2.6543138516116866
Validation loss: 2.474132958657194

Epoch: 5| Step: 7
Training loss: 3.182378806228606
Validation loss: 2.4702189095398257

Epoch: 5| Step: 8
Training loss: 2.1726077373730317
Validation loss: 2.473801627299058

Epoch: 5| Step: 9
Training loss: 2.4859940153803337
Validation loss: 2.4724834154740885

Epoch: 5| Step: 10
Training loss: 2.663231325674729
Validation loss: 2.4710142238803976

Epoch: 5| Step: 11
Training loss: 2.789783972166777
Validation loss: 2.465032490689613

Epoch: 126| Step: 0
Training loss: 2.722063084792774
Validation loss: 2.4679285243999645

Epoch: 5| Step: 1
Training loss: 2.895200664832826
Validation loss: 2.467336004264088

Epoch: 5| Step: 2
Training loss: 2.5760110222124553
Validation loss: 2.466212429180013

Epoch: 5| Step: 3
Training loss: 2.433395941029049
Validation loss: 2.4684102955418687

Epoch: 5| Step: 4
Training loss: 2.2087302900815504
Validation loss: 2.4628621724174518

Epoch: 5| Step: 5
Training loss: 2.6553034273890255
Validation loss: 2.465200866848671

Epoch: 5| Step: 6
Training loss: 2.49065378284934
Validation loss: 2.4618970665350712

Epoch: 5| Step: 7
Training loss: 2.7230409982475856
Validation loss: 2.469044205079953

Epoch: 5| Step: 8
Training loss: 2.635371653859714
Validation loss: 2.4641923159452435

Epoch: 5| Step: 9
Training loss: 2.193514810762996
Validation loss: 2.4664300125776975

Epoch: 5| Step: 10
Training loss: 2.6749718994375926
Validation loss: 2.4594903091646367

Epoch: 5| Step: 11
Training loss: 2.167325861006338
Validation loss: 2.462433452158815

Epoch: 127| Step: 0
Training loss: 3.043031429874349
Validation loss: 2.4634048163138638

Epoch: 5| Step: 1
Training loss: 2.575036620833345
Validation loss: 2.46245251801827

Epoch: 5| Step: 2
Training loss: 2.260507420653187
Validation loss: 2.458204586623282

Epoch: 5| Step: 3
Training loss: 2.2486062501484754
Validation loss: 2.4621385055659366

Epoch: 5| Step: 4
Training loss: 2.403338069919922
Validation loss: 2.466901356630621

Epoch: 5| Step: 5
Training loss: 2.769167856068279
Validation loss: 2.4623995439335866

Epoch: 5| Step: 6
Training loss: 2.533238983488735
Validation loss: 2.4673814279796025

Epoch: 5| Step: 7
Training loss: 2.2996752012048085
Validation loss: 2.466387990940944

Epoch: 5| Step: 8
Training loss: 2.766308112829039
Validation loss: 2.4721972424665535

Epoch: 5| Step: 9
Training loss: 2.4059877128826397
Validation loss: 2.4622997409055456

Epoch: 5| Step: 10
Training loss: 2.8432316569685256
Validation loss: 2.4629379215483898

Epoch: 5| Step: 11
Training loss: 2.1588680572124246
Validation loss: 2.4567972909779003

Epoch: 128| Step: 0
Training loss: 2.7081654031971936
Validation loss: 2.4631328337618283

Epoch: 5| Step: 1
Training loss: 3.1250495906709754
Validation loss: 2.4641942631033356

Epoch: 5| Step: 2
Training loss: 2.592384806384847
Validation loss: 2.4641053130938384

Epoch: 5| Step: 3
Training loss: 2.30774478180231
Validation loss: 2.461689356841587

Epoch: 5| Step: 4
Training loss: 2.8252388574677374
Validation loss: 2.4676602892038577

Epoch: 5| Step: 5
Training loss: 2.483655333497946
Validation loss: 2.45709083699161

Epoch: 5| Step: 6
Training loss: 2.7400733209809927
Validation loss: 2.467741776466934

Epoch: 5| Step: 7
Training loss: 2.629592511189204
Validation loss: 2.469454652683865

Epoch: 5| Step: 8
Training loss: 2.10609474855104
Validation loss: 2.4754536469856454

Epoch: 5| Step: 9
Training loss: 2.4737317004883486
Validation loss: 2.4710365643368335

Epoch: 5| Step: 10
Training loss: 2.1486038421045413
Validation loss: 2.473438836147761

Epoch: 5| Step: 11
Training loss: 1.7981828656795342
Validation loss: 2.4746099932197376

Epoch: 129| Step: 0
Training loss: 2.6547741548563897
Validation loss: 2.473027193951899

Epoch: 5| Step: 1
Training loss: 2.010344812034778
Validation loss: 2.4747068631329543

Epoch: 5| Step: 2
Training loss: 2.2150182369333913
Validation loss: 2.470621725357347

Epoch: 5| Step: 3
Training loss: 2.5206486552873844
Validation loss: 2.4726228515876394

Epoch: 5| Step: 4
Training loss: 2.9488607631448183
Validation loss: 2.4780305027432656

Epoch: 5| Step: 5
Training loss: 2.4676988512669924
Validation loss: 2.4677408143516235

Epoch: 5| Step: 6
Training loss: 2.665517907266567
Validation loss: 2.4612471410935903

Epoch: 5| Step: 7
Training loss: 2.57613652156608
Validation loss: 2.4569890999627915

Epoch: 5| Step: 8
Training loss: 2.669421313006208
Validation loss: 2.4584931359372724

Epoch: 5| Step: 9
Training loss: 2.386848708390288
Validation loss: 2.451647287089473

Epoch: 5| Step: 10
Training loss: 2.5549027005236553
Validation loss: 2.4677511480140226

Epoch: 5| Step: 11
Training loss: 3.950453507669691
Validation loss: 2.47448048886988

Epoch: 130| Step: 0
Training loss: 2.6456577713358516
Validation loss: 2.50992008431561

Epoch: 5| Step: 1
Training loss: 2.8321487718072675
Validation loss: 2.497686603207782

Epoch: 5| Step: 2
Training loss: 2.578973249127326
Validation loss: 2.5031933178668933

Epoch: 5| Step: 3
Training loss: 2.3835584129632346
Validation loss: 2.4813640750826877

Epoch: 5| Step: 4
Training loss: 2.4165119472392234
Validation loss: 2.4571262213905807

Epoch: 5| Step: 5
Training loss: 1.9522289814823277
Validation loss: 2.455316769197797

Epoch: 5| Step: 6
Training loss: 2.605239880988677
Validation loss: 2.455881594757661

Epoch: 5| Step: 7
Training loss: 2.838410447380338
Validation loss: 2.4571404000738126

Epoch: 5| Step: 8
Training loss: 2.397614875404154
Validation loss: 2.4612297611169716

Epoch: 5| Step: 9
Training loss: 2.9412480244627877
Validation loss: 2.46922492839051

Epoch: 5| Step: 10
Training loss: 2.6553149204303725
Validation loss: 2.4671554284712007

Epoch: 5| Step: 11
Training loss: 3.3380097646416154
Validation loss: 2.466634497856967

Epoch: 131| Step: 0
Training loss: 2.6963131139139165
Validation loss: 2.467783726745096

Epoch: 5| Step: 1
Training loss: 2.621986021253392
Validation loss: 2.4709848517222843

Epoch: 5| Step: 2
Training loss: 2.639603185742117
Validation loss: 2.4692249847148653

Epoch: 5| Step: 3
Training loss: 2.4402982837459777
Validation loss: 2.4650293754893267

Epoch: 5| Step: 4
Training loss: 2.4209278838908532
Validation loss: 2.4705838261325876

Epoch: 5| Step: 5
Training loss: 2.664167743293259
Validation loss: 2.466775100221272

Epoch: 5| Step: 6
Training loss: 2.67771469765632
Validation loss: 2.468313307306351

Epoch: 5| Step: 7
Training loss: 2.959042065753614
Validation loss: 2.4653237102748657

Epoch: 5| Step: 8
Training loss: 2.352321666967346
Validation loss: 2.45934415633925

Epoch: 5| Step: 9
Training loss: 2.145250877167696
Validation loss: 2.46198432899764

Epoch: 5| Step: 10
Training loss: 2.243453781423804
Validation loss: 2.455670524266451

Epoch: 5| Step: 11
Training loss: 3.522124931992058
Validation loss: 2.455180289186959

Epoch: 132| Step: 0
Training loss: 2.71665882936373
Validation loss: 2.457091407059663

Epoch: 5| Step: 1
Training loss: 2.9350377578516174
Validation loss: 2.454924767559297

Epoch: 5| Step: 2
Training loss: 2.1691308558357583
Validation loss: 2.45633831269851

Epoch: 5| Step: 3
Training loss: 2.51609371391637
Validation loss: 2.4493946537528135

Epoch: 5| Step: 4
Training loss: 2.5244665734383798
Validation loss: 2.4565313909282196

Epoch: 5| Step: 5
Training loss: 2.129226744439361
Validation loss: 2.4491412623557736

Epoch: 5| Step: 6
Training loss: 2.9889465788135086
Validation loss: 2.4568411344673433

Epoch: 5| Step: 7
Training loss: 2.6485412037218716
Validation loss: 2.4581196511607524

Epoch: 5| Step: 8
Training loss: 2.392582708860405
Validation loss: 2.4580237966913714

Epoch: 5| Step: 9
Training loss: 2.3709366823363185
Validation loss: 2.448255188172876

Epoch: 5| Step: 10
Training loss: 2.692900266515258
Validation loss: 2.446304761845104

Epoch: 5| Step: 11
Training loss: 1.8262259898608089
Validation loss: 2.456837689447894

Epoch: 133| Step: 0
Training loss: 2.7038388053993705
Validation loss: 2.4558499786227936

Epoch: 5| Step: 1
Training loss: 2.440991468671731
Validation loss: 2.457170257113275

Epoch: 5| Step: 2
Training loss: 1.869359879504303
Validation loss: 2.455319429413456

Epoch: 5| Step: 3
Training loss: 2.9879823622483004
Validation loss: 2.460000908458614

Epoch: 5| Step: 4
Training loss: 2.770767000785891
Validation loss: 2.460585618469822

Epoch: 5| Step: 5
Training loss: 2.7267616876897467
Validation loss: 2.46174683356602

Epoch: 5| Step: 6
Training loss: 2.6272009750352785
Validation loss: 2.462788413596809

Epoch: 5| Step: 7
Training loss: 2.0431147390103854
Validation loss: 2.4590701006711564

Epoch: 5| Step: 8
Training loss: 2.23323616936207
Validation loss: 2.4583099062390645

Epoch: 5| Step: 9
Training loss: 2.61171594563116
Validation loss: 2.4518543645888413

Epoch: 5| Step: 10
Training loss: 2.946140810303082
Validation loss: 2.4538659436659205

Epoch: 5| Step: 11
Training loss: 2.4437519980810247
Validation loss: 2.455845415769311

Epoch: 134| Step: 0
Training loss: 2.3406409432411888
Validation loss: 2.4504903020520925

Epoch: 5| Step: 1
Training loss: 2.3503830698965538
Validation loss: 2.4408828459128924

Epoch: 5| Step: 2
Training loss: 2.630893993079125
Validation loss: 2.4528715889634896

Epoch: 5| Step: 3
Training loss: 3.0147881013667575
Validation loss: 2.4551803964107926

Epoch: 5| Step: 4
Training loss: 2.561264112218625
Validation loss: 2.4496689564685585

Epoch: 5| Step: 5
Training loss: 2.661037304765477
Validation loss: 2.44989188971054

Epoch: 5| Step: 6
Training loss: 3.084071577891569
Validation loss: 2.456061005378823

Epoch: 5| Step: 7
Training loss: 2.1555668951284668
Validation loss: 2.4531025652659357

Epoch: 5| Step: 8
Training loss: 2.5801175827023983
Validation loss: 2.4552425389152055

Epoch: 5| Step: 9
Training loss: 1.9552275060392115
Validation loss: 2.4537022492583045

Epoch: 5| Step: 10
Training loss: 2.360661844133164
Validation loss: 2.4522911849580606

Epoch: 5| Step: 11
Training loss: 3.2865717284423126
Validation loss: 2.4632704359003306

Epoch: 135| Step: 0
Training loss: 2.428044883162352
Validation loss: 2.4577968963108336

Epoch: 5| Step: 1
Training loss: 2.7242553918516816
Validation loss: 2.4573458059334694

Epoch: 5| Step: 2
Training loss: 2.4571409943880895
Validation loss: 2.4560757605152337

Epoch: 5| Step: 3
Training loss: 2.683973971199455
Validation loss: 2.454615587572887

Epoch: 5| Step: 4
Training loss: 2.3696993855265465
Validation loss: 2.4580122197823613

Epoch: 5| Step: 5
Training loss: 2.473278672401762
Validation loss: 2.4572588679210923

Epoch: 5| Step: 6
Training loss: 2.384541468977411
Validation loss: 2.456416196110421

Epoch: 5| Step: 7
Training loss: 2.2958821337083277
Validation loss: 2.4605757795647634

Epoch: 5| Step: 8
Training loss: 2.629165432582592
Validation loss: 2.458921529155163

Epoch: 5| Step: 9
Training loss: 2.9860090805089383
Validation loss: 2.45327768032902

Epoch: 5| Step: 10
Training loss: 2.474246702286256
Validation loss: 2.4593040979579173

Epoch: 5| Step: 11
Training loss: 2.995239295124614
Validation loss: 2.454805110620586

Epoch: 136| Step: 0
Training loss: 2.566742618064561
Validation loss: 2.4631570323560625

Epoch: 5| Step: 1
Training loss: 2.6670191849718314
Validation loss: 2.4600354029788063

Epoch: 5| Step: 2
Training loss: 3.0998213562713413
Validation loss: 2.457709800448369

Epoch: 5| Step: 3
Training loss: 2.6733846582288288
Validation loss: 2.4615173302639035

Epoch: 5| Step: 4
Training loss: 2.014376941458642
Validation loss: 2.457890269929959

Epoch: 5| Step: 5
Training loss: 2.4530505515300365
Validation loss: 2.457178811886693

Epoch: 5| Step: 6
Training loss: 2.117635419134177
Validation loss: 2.4544410840081228

Epoch: 5| Step: 7
Training loss: 2.112908688350061
Validation loss: 2.460942868827332

Epoch: 5| Step: 8
Training loss: 2.6318200841649144
Validation loss: 2.4598290586134812

Epoch: 5| Step: 9
Training loss: 2.740886238200713
Validation loss: 2.4543472472680277

Epoch: 5| Step: 10
Training loss: 2.8637351890124347
Validation loss: 2.4670844797630935

Epoch: 5| Step: 11
Training loss: 2.225058814139391
Validation loss: 2.4586755236924187

Epoch: 137| Step: 0
Training loss: 2.4617570753634093
Validation loss: 2.454536732350157

Epoch: 5| Step: 1
Training loss: 2.634052471359483
Validation loss: 2.4548512113432404

Epoch: 5| Step: 2
Training loss: 2.6984416102392967
Validation loss: 2.4563667114329175

Epoch: 5| Step: 3
Training loss: 2.930096976592469
Validation loss: 2.4561765485074973

Epoch: 5| Step: 4
Training loss: 2.7987040926808735
Validation loss: 2.457320280718363

Epoch: 5| Step: 5
Training loss: 2.616111055740799
Validation loss: 2.461148893773369

Epoch: 5| Step: 6
Training loss: 2.627992831250869
Validation loss: 2.458003882110852

Epoch: 5| Step: 7
Training loss: 1.9511247692206997
Validation loss: 2.4564496975932624

Epoch: 5| Step: 8
Training loss: 2.608598422228801
Validation loss: 2.4598911745467618

Epoch: 5| Step: 9
Training loss: 2.5382904287391272
Validation loss: 2.4617835916550583

Epoch: 5| Step: 10
Training loss: 2.1192952042555944
Validation loss: 2.458389218282462

Epoch: 5| Step: 11
Training loss: 1.8865433447514468
Validation loss: 2.458030598529396

Epoch: 138| Step: 0
Training loss: 2.748227501892928
Validation loss: 2.459756347742144

Epoch: 5| Step: 1
Training loss: 2.594856302034941
Validation loss: 2.4577432438784674

Epoch: 5| Step: 2
Training loss: 2.8651676391235403
Validation loss: 2.4540711175963277

Epoch: 5| Step: 3
Training loss: 2.1769114765678332
Validation loss: 2.4561226018233557

Epoch: 5| Step: 4
Training loss: 2.5337412313376384
Validation loss: 2.45138077979207

Epoch: 5| Step: 5
Training loss: 2.6254044175832183
Validation loss: 2.453688983919735

Epoch: 5| Step: 6
Training loss: 2.5410378621540914
Validation loss: 2.455393412598751

Epoch: 5| Step: 7
Training loss: 2.4426420700314644
Validation loss: 2.449495148868537

Epoch: 5| Step: 8
Training loss: 1.8705335188500636
Validation loss: 2.4555713094471576

Epoch: 5| Step: 9
Training loss: 2.3473448586513683
Validation loss: 2.445419908384808

Epoch: 5| Step: 10
Training loss: 2.879264985175626
Validation loss: 2.4529514291834866

Epoch: 5| Step: 11
Training loss: 3.612061396705396
Validation loss: 2.451851313678607

Epoch: 139| Step: 0
Training loss: 2.874809922278932
Validation loss: 2.451935793722363

Epoch: 5| Step: 1
Training loss: 2.094395779899618
Validation loss: 2.465584171683967

Epoch: 5| Step: 2
Training loss: 2.918363041518661
Validation loss: 2.4669938339813

Epoch: 5| Step: 3
Training loss: 2.5612006265806606
Validation loss: 2.4699612233622674

Epoch: 5| Step: 4
Training loss: 2.413379757822782
Validation loss: 2.4779086220149216

Epoch: 5| Step: 5
Training loss: 2.8661004690168372
Validation loss: 2.478200681540146

Epoch: 5| Step: 6
Training loss: 3.014543566719415
Validation loss: 2.4772432597011504

Epoch: 5| Step: 7
Training loss: 2.342169063157089
Validation loss: 2.4780414469400602

Epoch: 5| Step: 8
Training loss: 2.2075152651301124
Validation loss: 2.4788699987698095

Epoch: 5| Step: 9
Training loss: 2.1061585947006685
Validation loss: 2.4785650682740723

Epoch: 5| Step: 10
Training loss: 2.6160083448819393
Validation loss: 2.4757848013935355

Epoch: 5| Step: 11
Training loss: 3.167938796723762
Validation loss: 2.4787309581623465

Epoch: 140| Step: 0
Training loss: 2.7404999933909204
Validation loss: 2.4748532105595853

Epoch: 5| Step: 1
Training loss: 2.554061766353284
Validation loss: 2.4769434751186186

Epoch: 5| Step: 2
Training loss: 2.771945863869441
Validation loss: 2.4754847840077985

Epoch: 5| Step: 3
Training loss: 2.485365951886145
Validation loss: 2.4745362072017993

Epoch: 5| Step: 4
Training loss: 2.5400498568530248
Validation loss: 2.470973506401572

Epoch: 5| Step: 5
Training loss: 2.330457197692045
Validation loss: 2.46619640944334

Epoch: 5| Step: 6
Training loss: 2.700608774713368
Validation loss: 2.464112747218683

Epoch: 5| Step: 7
Training loss: 2.6564318426382636
Validation loss: 2.464023282245564

Epoch: 5| Step: 8
Training loss: 2.174517334624013
Validation loss: 2.457999608184415

Epoch: 5| Step: 9
Training loss: 2.8076822343008465
Validation loss: 2.460242303413514

Epoch: 5| Step: 10
Training loss: 2.215733478941212
Validation loss: 2.4551493923431607

Epoch: 5| Step: 11
Training loss: 2.806650139162719
Validation loss: 2.455363635100001

Epoch: 141| Step: 0
Training loss: 2.477604884324696
Validation loss: 2.454768308737592

Epoch: 5| Step: 1
Training loss: 2.3752656085416226
Validation loss: 2.4531635516269774

Epoch: 5| Step: 2
Training loss: 2.530894878578242
Validation loss: 2.457440223477797

Epoch: 5| Step: 3
Training loss: 2.76259528983945
Validation loss: 2.4562207792127775

Epoch: 5| Step: 4
Training loss: 2.3894936870420516
Validation loss: 2.455530287347458

Epoch: 5| Step: 5
Training loss: 2.438780814894636
Validation loss: 2.468002588471416

Epoch: 5| Step: 6
Training loss: 2.374879733604309
Validation loss: 2.461551940748099

Epoch: 5| Step: 7
Training loss: 2.6179616210257586
Validation loss: 2.457119760703109

Epoch: 5| Step: 8
Training loss: 2.7833945760632552
Validation loss: 2.453588146378307

Epoch: 5| Step: 9
Training loss: 2.7801182190712175
Validation loss: 2.460926047808123

Epoch: 5| Step: 10
Training loss: 2.584833376179417
Validation loss: 2.4640090020596386

Epoch: 5| Step: 11
Training loss: 2.689833315680323
Validation loss: 2.467016923583244

Epoch: 142| Step: 0
Training loss: 2.292652946703251
Validation loss: 2.4664816877774522

Epoch: 5| Step: 1
Training loss: 2.8448609917173147
Validation loss: 2.4657667419858957

Epoch: 5| Step: 2
Training loss: 2.3154698452469744
Validation loss: 2.4591649185895337

Epoch: 5| Step: 3
Training loss: 2.459066012408237
Validation loss: 2.4654387266306688

Epoch: 5| Step: 4
Training loss: 2.609742464243415
Validation loss: 2.460933206948063

Epoch: 5| Step: 5
Training loss: 2.738419163342266
Validation loss: 2.458601724122592

Epoch: 5| Step: 6
Training loss: 2.1956483848709865
Validation loss: 2.4566724239262063

Epoch: 5| Step: 7
Training loss: 2.7978868412370055
Validation loss: 2.461341243503702

Epoch: 5| Step: 8
Training loss: 2.6789791850398825
Validation loss: 2.4552640437356446

Epoch: 5| Step: 9
Training loss: 2.7169503580668275
Validation loss: 2.4595866133676463

Epoch: 5| Step: 10
Training loss: 2.3386391419030983
Validation loss: 2.452908079109519

Epoch: 5| Step: 11
Training loss: 2.0852801826724825
Validation loss: 2.45265623339682

Epoch: 143| Step: 0
Training loss: 2.321660122484494
Validation loss: 2.454992603885208

Epoch: 5| Step: 1
Training loss: 2.1824912357045108
Validation loss: 2.4699085068520663

Epoch: 5| Step: 2
Training loss: 1.9303858184600229
Validation loss: 2.4780809378505

Epoch: 5| Step: 3
Training loss: 2.1731921256984514
Validation loss: 2.4856940832234486

Epoch: 5| Step: 4
Training loss: 2.93422662686902
Validation loss: 2.4747757106840065

Epoch: 5| Step: 5
Training loss: 2.7232791401557646
Validation loss: 2.4921055763356232

Epoch: 5| Step: 6
Training loss: 2.88311683268272
Validation loss: 2.4751853964947195

Epoch: 5| Step: 7
Training loss: 2.5818295767968586
Validation loss: 2.46300035031092

Epoch: 5| Step: 8
Training loss: 2.6995214356053414
Validation loss: 2.459626824663677

Epoch: 5| Step: 9
Training loss: 2.46127733578669
Validation loss: 2.45602094198596

Epoch: 5| Step: 10
Training loss: 2.957257321382122
Validation loss: 2.4651086405967306

Epoch: 5| Step: 11
Training loss: 3.035188456282233
Validation loss: 2.4667283363516046

Epoch: 144| Step: 0
Training loss: 2.975230642402078
Validation loss: 2.4658676858008626

Epoch: 5| Step: 1
Training loss: 2.3921201929431914
Validation loss: 2.4653493782773475

Epoch: 5| Step: 2
Training loss: 2.354860243001398
Validation loss: 2.464293731405908

Epoch: 5| Step: 3
Training loss: 3.0362925323359318
Validation loss: 2.4660388731327676

Epoch: 5| Step: 4
Training loss: 2.955085063555552
Validation loss: 2.4679660035130455

Epoch: 5| Step: 5
Training loss: 2.431197503707272
Validation loss: 2.4655111732203947

Epoch: 5| Step: 6
Training loss: 1.9986575508804725
Validation loss: 2.4640354134847393

Epoch: 5| Step: 7
Training loss: 2.340704401398554
Validation loss: 2.4687956552267627

Epoch: 5| Step: 8
Training loss: 2.428518326763818
Validation loss: 2.468505549500782

Epoch: 5| Step: 9
Training loss: 2.7524857990338583
Validation loss: 2.463011000311047

Epoch: 5| Step: 10
Training loss: 2.5244863119798806
Validation loss: 2.4627010606280204

Epoch: 5| Step: 11
Training loss: 2.041771970355814
Validation loss: 2.4634618900815526

Epoch: 145| Step: 0
Training loss: 2.483363683459628
Validation loss: 2.463676914000057

Epoch: 5| Step: 1
Training loss: 2.4209177401912996
Validation loss: 2.464465953168517

Epoch: 5| Step: 2
Training loss: 2.271565508849003
Validation loss: 2.4635242370139436

Epoch: 5| Step: 3
Training loss: 3.41796875
Validation loss: 2.460556105673962

Epoch: 5| Step: 4
Training loss: 2.448919493966114
Validation loss: 2.46364386765243

Epoch: 5| Step: 5
Training loss: 2.698737050423379
Validation loss: 2.463729538047923

Epoch: 5| Step: 6
Training loss: 2.709103186325267
Validation loss: 2.462675512258801

Epoch: 5| Step: 7
Training loss: 2.31333650460516
Validation loss: 2.4595687329428007

Epoch: 5| Step: 8
Training loss: 2.56788831677113
Validation loss: 2.4628077106601096

Epoch: 5| Step: 9
Training loss: 2.351038066391955
Validation loss: 2.4595400117081896

Epoch: 5| Step: 10
Training loss: 2.481506226807929
Validation loss: 2.4620778867715436

Epoch: 5| Step: 11
Training loss: 1.4157237205861868
Validation loss: 2.4559586270445326

Epoch: 146| Step: 0
Training loss: 2.534609413830121
Validation loss: 2.461214778558365

Epoch: 5| Step: 1
Training loss: 2.8950860319382943
Validation loss: 2.4613522255835636

Epoch: 5| Step: 2
Training loss: 2.031976071216835
Validation loss: 2.459613221719475

Epoch: 5| Step: 3
Training loss: 2.7431029614779843
Validation loss: 2.4592565780235756

Epoch: 5| Step: 4
Training loss: 2.5380980552627714
Validation loss: 2.461871423065823

Epoch: 5| Step: 5
Training loss: 2.6609383888265543
Validation loss: 2.454629100847096

Epoch: 5| Step: 6
Training loss: 2.4922056765476457
Validation loss: 2.4559210981740414

Epoch: 5| Step: 7
Training loss: 2.267890271265614
Validation loss: 2.4536713398759047

Epoch: 5| Step: 8
Training loss: 2.796038539839154
Validation loss: 2.455240236694668

Epoch: 5| Step: 9
Training loss: 2.798134461592031
Validation loss: 2.4553735029823254

Epoch: 5| Step: 10
Training loss: 2.1327349191046827
Validation loss: 2.4597123340853333

Epoch: 5| Step: 11
Training loss: 1.6450254010497458
Validation loss: 2.4539858204691813

Epoch: 147| Step: 0
Training loss: 3.0771949253668693
Validation loss: 2.4615620784283756

Epoch: 5| Step: 1
Training loss: 2.7574276750197977
Validation loss: 2.4551537946411486

Epoch: 5| Step: 2
Training loss: 2.8534481137205407
Validation loss: 2.4625271481826396

Epoch: 5| Step: 3
Training loss: 2.3095886874929716
Validation loss: 2.4668423448863703

Epoch: 5| Step: 4
Training loss: 2.2436135040673886
Validation loss: 2.4603505802134915

Epoch: 5| Step: 5
Training loss: 1.9981545636493048
Validation loss: 2.4630439260853154

Epoch: 5| Step: 6
Training loss: 2.618187738842965
Validation loss: 2.4627265583098987

Epoch: 5| Step: 7
Training loss: 2.672929433037431
Validation loss: 2.4608874442040576

Epoch: 5| Step: 8
Training loss: 2.214248065804219
Validation loss: 2.4565252360178627

Epoch: 5| Step: 9
Training loss: 2.3962991234047903
Validation loss: 2.4506390766367674

Epoch: 5| Step: 10
Training loss: 2.5880684269698557
Validation loss: 2.4586498466228046

Epoch: 5| Step: 11
Training loss: 3.0437411893681836
Validation loss: 2.461563402135139

Epoch: 148| Step: 0
Training loss: 2.718333683805211
Validation loss: 2.4615471503567865

Epoch: 5| Step: 1
Training loss: 2.2860894278508326
Validation loss: 2.469634384581014

Epoch: 5| Step: 2
Training loss: 2.8800490451981164
Validation loss: 2.477393138388783

Epoch: 5| Step: 3
Training loss: 2.712799927614572
Validation loss: 2.462140155777158

Epoch: 5| Step: 4
Training loss: 2.5070828240814462
Validation loss: 2.4692564094817913

Epoch: 5| Step: 5
Training loss: 1.8421558018255304
Validation loss: 2.466183309998729

Epoch: 5| Step: 6
Training loss: 2.192490144748787
Validation loss: 2.4634059373968573

Epoch: 5| Step: 7
Training loss: 2.4941799127864477
Validation loss: 2.4575729460317635

Epoch: 5| Step: 8
Training loss: 2.4960503850522007
Validation loss: 2.4604094771415546

Epoch: 5| Step: 9
Training loss: 2.9328571720613033
Validation loss: 2.465412124740064

Epoch: 5| Step: 10
Training loss: 2.595007626002284
Validation loss: 2.462092428317024

Epoch: 5| Step: 11
Training loss: 3.210446062557859
Validation loss: 2.460544877799165

Epoch: 149| Step: 0
Training loss: 3.1212967865064623
Validation loss: 2.463824311723879

Epoch: 5| Step: 1
Training loss: 2.0421660325104813
Validation loss: 2.4654167907695044

Epoch: 5| Step: 2
Training loss: 3.0689629071064566
Validation loss: 2.465555719966357

Epoch: 5| Step: 3
Training loss: 2.6838922459537424
Validation loss: 2.4726441088273416

Epoch: 5| Step: 4
Training loss: 2.754355276308534
Validation loss: 2.4715716336999116

Epoch: 5| Step: 5
Training loss: 2.5504716623957213
Validation loss: 2.4699123157350624

Epoch: 5| Step: 6
Training loss: 1.9369294341649543
Validation loss: 2.4640980442396714

Epoch: 5| Step: 7
Training loss: 2.217861158684569
Validation loss: 2.450620530979006

Epoch: 5| Step: 8
Training loss: 2.472340158323582
Validation loss: 2.4534765688131888

Epoch: 5| Step: 9
Training loss: 2.655832055814412
Validation loss: 2.45148108812979

Epoch: 5| Step: 10
Training loss: 1.967331935679552
Validation loss: 2.4446511598142386

Epoch: 5| Step: 11
Training loss: 2.8875237402001956
Validation loss: 2.4548382010882897

Epoch: 150| Step: 0
Training loss: 2.0204322915139437
Validation loss: 2.4513986834677697

Epoch: 5| Step: 1
Training loss: 2.0967249445657057
Validation loss: 2.4465809742458284

Epoch: 5| Step: 2
Training loss: 2.3928784489445634
Validation loss: 2.454035555559938

Epoch: 5| Step: 3
Training loss: 2.1018110504086405
Validation loss: 2.450385380135312

Epoch: 5| Step: 4
Training loss: 2.4091949276853795
Validation loss: 2.4503522011559746

Epoch: 5| Step: 5
Training loss: 2.39252939602801
Validation loss: 2.4596403911830396

Epoch: 5| Step: 6
Training loss: 2.911572740157461
Validation loss: 2.4529359627231426

Epoch: 5| Step: 7
Training loss: 2.4112773742229354
Validation loss: 2.4570605463768915

Epoch: 5| Step: 8
Training loss: 3.2183400606005734
Validation loss: 2.4460354184286763

Epoch: 5| Step: 9
Training loss: 2.7472135992614484
Validation loss: 2.4476041222297806

Epoch: 5| Step: 10
Training loss: 2.8113394144034825
Validation loss: 2.447584346101068

Epoch: 5| Step: 11
Training loss: 3.1005454906318564
Validation loss: 2.459984670587399

Epoch: 151| Step: 0
Training loss: 2.945947067748598
Validation loss: 2.458159546986403

Epoch: 5| Step: 1
Training loss: 2.756074611766706
Validation loss: 2.465154734004942

Epoch: 5| Step: 2
Training loss: 2.2398317302784507
Validation loss: 2.4597896825752734

Epoch: 5| Step: 3
Training loss: 2.383716449311405
Validation loss: 2.4605982026829243

Epoch: 5| Step: 4
Training loss: 2.156503966481952
Validation loss: 2.475141861892653

Epoch: 5| Step: 5
Training loss: 2.43467215804323
Validation loss: 2.4690342389425317

Epoch: 5| Step: 6
Training loss: 2.8931525649749603
Validation loss: 2.4762209748042245

Epoch: 5| Step: 7
Training loss: 2.6234467770365306
Validation loss: 2.4737946238644466

Epoch: 5| Step: 8
Training loss: 2.407720240484598
Validation loss: 2.4701097341246916

Epoch: 5| Step: 9
Training loss: 2.410436777763467
Validation loss: 2.472043564647648

Epoch: 5| Step: 10
Training loss: 2.8092548722329034
Validation loss: 2.475534348009875

Epoch: 5| Step: 11
Training loss: 2.332106392574713
Validation loss: 2.474520566531488

Epoch: 152| Step: 0
Training loss: 2.3082957841961345
Validation loss: 2.4658882479232265

Epoch: 5| Step: 1
Training loss: 2.647216245233763
Validation loss: 2.4670126149365683

Epoch: 5| Step: 2
Training loss: 2.493560699697068
Validation loss: 2.4564896367167175

Epoch: 5| Step: 3
Training loss: 2.6601110782233
Validation loss: 2.4595763382986426

Epoch: 5| Step: 4
Training loss: 2.8888810129139797
Validation loss: 2.4562430580662284

Epoch: 5| Step: 5
Training loss: 2.9842658697017757
Validation loss: 2.4565605719490478

Epoch: 5| Step: 6
Training loss: 1.988271836893699
Validation loss: 2.4640849497660784

Epoch: 5| Step: 7
Training loss: 2.013057759395784
Validation loss: 2.4586845661591465

Epoch: 5| Step: 8
Training loss: 2.1847654416653555
Validation loss: 2.4573615033644045

Epoch: 5| Step: 9
Training loss: 2.857574396241279
Validation loss: 2.4557445090102172

Epoch: 5| Step: 10
Training loss: 2.578197316398168
Validation loss: 2.4543753270258377

Epoch: 5| Step: 11
Training loss: 2.598580332286683
Validation loss: 2.4573177580979757

Epoch: 153| Step: 0
Training loss: 2.703369658759574
Validation loss: 2.460836414501441

Epoch: 5| Step: 1
Training loss: 2.464709101413358
Validation loss: 2.4715187103730636

Epoch: 5| Step: 2
Training loss: 2.3391016322998937
Validation loss: 2.4586073505844452

Epoch: 5| Step: 3
Training loss: 1.7639597914388492
Validation loss: 2.478309484496187

Epoch: 5| Step: 4
Training loss: 2.0438271464215028
Validation loss: 2.502577688584527

Epoch: 5| Step: 5
Training loss: 2.9230135571024785
Validation loss: 2.5159015542992726

Epoch: 5| Step: 6
Training loss: 2.5973218659605375
Validation loss: 2.496745558253257

Epoch: 5| Step: 7
Training loss: 2.9860081223660355
Validation loss: 2.467119394674597

Epoch: 5| Step: 8
Training loss: 2.6662311396980214
Validation loss: 2.460776046220037

Epoch: 5| Step: 9
Training loss: 2.5545280010117097
Validation loss: 2.460113443935206

Epoch: 5| Step: 10
Training loss: 2.8961407797827787
Validation loss: 2.4667454721990394

Epoch: 5| Step: 11
Training loss: 2.4234485067662384
Validation loss: 2.465766161837085

Epoch: 154| Step: 0
Training loss: 2.383426074466651
Validation loss: 2.470982467681539

Epoch: 5| Step: 1
Training loss: 2.686125647860455
Validation loss: 2.471664892881104

Epoch: 5| Step: 2
Training loss: 2.3206986128527713
Validation loss: 2.478139142801433

Epoch: 5| Step: 3
Training loss: 2.2806849367728885
Validation loss: 2.480176701211156

Epoch: 5| Step: 4
Training loss: 2.8876687268919077
Validation loss: 2.4787764676281334

Epoch: 5| Step: 5
Training loss: 2.7648722168296906
Validation loss: 2.4893064877008872

Epoch: 5| Step: 6
Training loss: 2.7190476177910052
Validation loss: 2.4858527996500137

Epoch: 5| Step: 7
Training loss: 2.6305254049519102
Validation loss: 2.484455345262136

Epoch: 5| Step: 8
Training loss: 2.380462287916596
Validation loss: 2.481066806413967

Epoch: 5| Step: 9
Training loss: 2.9253825793344763
Validation loss: 2.471521248644619

Epoch: 5| Step: 10
Training loss: 2.4110799098400952
Validation loss: 2.477987924146387

Epoch: 5| Step: 11
Training loss: 2.379083736419599
Validation loss: 2.4736442138955295

Epoch: 155| Step: 0
Training loss: 2.5962316751361434
Validation loss: 2.472073599340076

Epoch: 5| Step: 1
Training loss: 2.5843858933132724
Validation loss: 2.4678178790022858

Epoch: 5| Step: 2
Training loss: 2.548226682361859
Validation loss: 2.469526486672274

Epoch: 5| Step: 3
Training loss: 2.392294705789942
Validation loss: 2.464298613207159

Epoch: 5| Step: 4
Training loss: 2.6859767944231097
Validation loss: 2.4616997542435803

Epoch: 5| Step: 5
Training loss: 2.3874035241571967
Validation loss: 2.465049473096459

Epoch: 5| Step: 6
Training loss: 2.472659914035101
Validation loss: 2.4623442973372245

Epoch: 5| Step: 7
Training loss: 2.719941502951852
Validation loss: 2.459189166327299

Epoch: 5| Step: 8
Training loss: 2.5180650333432606
Validation loss: 2.4621367625543504

Epoch: 5| Step: 9
Training loss: 2.8017644499856025
Validation loss: 2.4589021894735703

Epoch: 5| Step: 10
Training loss: 2.3622148614200342
Validation loss: 2.4667797032652357

Epoch: 5| Step: 11
Training loss: 2.7246650279934426
Validation loss: 2.4605652663867867

Epoch: 156| Step: 0
Training loss: 2.601381862658274
Validation loss: 2.4653268573394658

Epoch: 5| Step: 1
Training loss: 2.217020892280969
Validation loss: 2.455847697197112

Epoch: 5| Step: 2
Training loss: 2.451209419844433
Validation loss: 2.454464427282773

Epoch: 5| Step: 3
Training loss: 1.9888206005212585
Validation loss: 2.4573967302497626

Epoch: 5| Step: 4
Training loss: 2.853841962698545
Validation loss: 2.4594716262739493

Epoch: 5| Step: 5
Training loss: 2.5304626370550776
Validation loss: 2.4562025466813076

Epoch: 5| Step: 6
Training loss: 3.158050023828459
Validation loss: 2.4547898298529325

Epoch: 5| Step: 7
Training loss: 2.567003990482309
Validation loss: 2.460713516618573

Epoch: 5| Step: 8
Training loss: 2.3821826540134405
Validation loss: 2.457969397475927

Epoch: 5| Step: 9
Training loss: 2.528727275088182
Validation loss: 2.4535466659891

Epoch: 5| Step: 10
Training loss: 2.310406433119496
Validation loss: 2.46059825920475

Epoch: 5| Step: 11
Training loss: 2.63375565928832
Validation loss: 2.4717817281687378

Epoch: 157| Step: 0
Training loss: 2.195147090667117
Validation loss: 2.4961157505775184

Epoch: 5| Step: 1
Training loss: 2.969078929146209
Validation loss: 2.5134484330829245

Epoch: 5| Step: 2
Training loss: 2.2370752410922305
Validation loss: 2.543614143005353

Epoch: 5| Step: 3
Training loss: 2.3803329824673427
Validation loss: 2.522792243540704

Epoch: 5| Step: 4
Training loss: 2.6145886627588757
Validation loss: 2.5045444272356057

Epoch: 5| Step: 5
Training loss: 2.6604783455537926
Validation loss: 2.4953710935716504

Epoch: 5| Step: 6
Training loss: 2.604185689220888
Validation loss: 2.4886539804867795

Epoch: 5| Step: 7
Training loss: 2.9093778452464942
Validation loss: 2.4843680583608965

Epoch: 5| Step: 8
Training loss: 2.4571568103723616
Validation loss: 2.486150111408133

Epoch: 5| Step: 9
Training loss: 2.624177622266981
Validation loss: 2.4844122190106703

Epoch: 5| Step: 10
Training loss: 2.592453782084389
Validation loss: 2.4894915002514457

Epoch: 5| Step: 11
Training loss: 3.757446017407365
Validation loss: 2.4771195155314643

Epoch: 158| Step: 0
Training loss: 2.7867334723183963
Validation loss: 2.485307390561186

Epoch: 5| Step: 1
Training loss: 3.049423482219807
Validation loss: 2.48492496728992

Epoch: 5| Step: 2
Training loss: 2.4051257392862735
Validation loss: 2.4802495944711036

Epoch: 5| Step: 3
Training loss: 2.4790569462792718
Validation loss: 2.4811679365294443

Epoch: 5| Step: 4
Training loss: 2.597589890629135
Validation loss: 2.484150622489976

Epoch: 5| Step: 5
Training loss: 2.396140822429238
Validation loss: 2.4820368978748095

Epoch: 5| Step: 6
Training loss: 2.7672213672394186
Validation loss: 2.4803376370918855

Epoch: 5| Step: 7
Training loss: 2.7560877607349603
Validation loss: 2.478304085147392

Epoch: 5| Step: 8
Training loss: 2.5630391181821217
Validation loss: 2.479860162041929

Epoch: 5| Step: 9
Training loss: 2.1425001187586
Validation loss: 2.4782560196019063

Epoch: 5| Step: 10
Training loss: 2.2228413858391067
Validation loss: 2.4711735052729082

Epoch: 5| Step: 11
Training loss: 2.265786526940003
Validation loss: 2.4649380818496436

Epoch: 159| Step: 0
Training loss: 2.9539976092246887
Validation loss: 2.478125743697489

Epoch: 5| Step: 1
Training loss: 2.6044590493415836
Validation loss: 2.471003485755772

Epoch: 5| Step: 2
Training loss: 2.284087102154441
Validation loss: 2.46906740828078

Epoch: 5| Step: 3
Training loss: 1.9714872314480805
Validation loss: 2.474460279172771

Epoch: 5| Step: 4
Training loss: 2.6079772129233496
Validation loss: 2.474641879499767

Epoch: 5| Step: 5
Training loss: 2.257206290942005
Validation loss: 2.470044086599535

Epoch: 5| Step: 6
Training loss: 2.516349830219975
Validation loss: 2.4625608832034662

Epoch: 5| Step: 7
Training loss: 2.993956199983058
Validation loss: 2.465370863439106

Epoch: 5| Step: 8
Training loss: 2.987807451971454
Validation loss: 2.463906833018757

Epoch: 5| Step: 9
Training loss: 2.274462491769175
Validation loss: 2.4680563157339885

Epoch: 5| Step: 10
Training loss: 2.241816898780967
Validation loss: 2.4616083229936176

Epoch: 5| Step: 11
Training loss: 2.97182506114185
Validation loss: 2.464272164290423

Epoch: 160| Step: 0
Training loss: 2.3021879445698614
Validation loss: 2.4639209686509926

Epoch: 5| Step: 1
Training loss: 2.401676736669808
Validation loss: 2.4522846102583986

Epoch: 5| Step: 2
Training loss: 2.9490729087491485
Validation loss: 2.4551321229582923

Epoch: 5| Step: 3
Training loss: 2.4717938936722477
Validation loss: 2.463606957880276

Epoch: 5| Step: 4
Training loss: 3.0312916860958543
Validation loss: 2.4597784168738106

Epoch: 5| Step: 5
Training loss: 2.3128131963664122
Validation loss: 2.458784919953655

Epoch: 5| Step: 6
Training loss: 2.5049952193650484
Validation loss: 2.4587169741190436

Epoch: 5| Step: 7
Training loss: 2.7414417611336375
Validation loss: 2.4639004586526467

Epoch: 5| Step: 8
Training loss: 2.323936637618699
Validation loss: 2.456647829868231

Epoch: 5| Step: 9
Training loss: 2.4743387244394204
Validation loss: 2.457240254984305

Epoch: 5| Step: 10
Training loss: 2.443620675413854
Validation loss: 2.461283712910157

Epoch: 5| Step: 11
Training loss: 1.8239579923125826
Validation loss: 2.4538844243127205

Epoch: 161| Step: 0
Training loss: 2.112005331596234
Validation loss: 2.45525852492481

Epoch: 5| Step: 1
Training loss: 2.8902125708732886
Validation loss: 2.4536034953616523

Epoch: 5| Step: 2
Training loss: 2.6887523483344142
Validation loss: 2.4554396216258523

Epoch: 5| Step: 3
Training loss: 2.126547194067748
Validation loss: 2.4549374010233063

Epoch: 5| Step: 4
Training loss: 2.4022368616655347
Validation loss: 2.45457073705322

Epoch: 5| Step: 5
Training loss: 2.7259171823472315
Validation loss: 2.450030357146817

Epoch: 5| Step: 6
Training loss: 2.4515072293004767
Validation loss: 2.453410773832403

Epoch: 5| Step: 7
Training loss: 2.431036277340259
Validation loss: 2.4488131944318146

Epoch: 5| Step: 8
Training loss: 2.275860416228393
Validation loss: 2.4480142303395493

Epoch: 5| Step: 9
Training loss: 3.0755917731794353
Validation loss: 2.4501218251347123

Epoch: 5| Step: 10
Training loss: 2.3739847723802714
Validation loss: 2.4434264387547215

Epoch: 5| Step: 11
Training loss: 2.9342547407278543
Validation loss: 2.450953366696265

Epoch: 162| Step: 0
Training loss: 1.8089935322272142
Validation loss: 2.4515720278909545

Epoch: 5| Step: 1
Training loss: 2.3764312848366336
Validation loss: 2.459650823498776

Epoch: 5| Step: 2
Training loss: 2.5535469892401284
Validation loss: 2.4615633335284035

Epoch: 5| Step: 3
Training loss: 2.4026116942800413
Validation loss: 2.463054928806112

Epoch: 5| Step: 4
Training loss: 2.916884132634152
Validation loss: 2.4546331924527363

Epoch: 5| Step: 5
Training loss: 2.5449119444717034
Validation loss: 2.4604752969391273

Epoch: 5| Step: 6
Training loss: 2.4836565814330793
Validation loss: 2.4579538332589763

Epoch: 5| Step: 7
Training loss: 2.1998396381540517
Validation loss: 2.457711809330536

Epoch: 5| Step: 8
Training loss: 2.691041520296322
Validation loss: 2.4553148332063377

Epoch: 5| Step: 9
Training loss: 2.8837283780759426
Validation loss: 2.455032951123486

Epoch: 5| Step: 10
Training loss: 2.476966800841445
Validation loss: 2.4572835569313924

Epoch: 5| Step: 11
Training loss: 3.7398868249915154
Validation loss: 2.4519609900986468

Epoch: 163| Step: 0
Training loss: 2.733531276777236
Validation loss: 2.4539468243116898

Epoch: 5| Step: 1
Training loss: 2.5847425206411283
Validation loss: 2.449604050761241

Epoch: 5| Step: 2
Training loss: 2.978709490360936
Validation loss: 2.452097027420875

Epoch: 5| Step: 3
Training loss: 2.122221982111537
Validation loss: 2.4593781915148747

Epoch: 5| Step: 4
Training loss: 2.785604946380115
Validation loss: 2.4617505138385445

Epoch: 5| Step: 5
Training loss: 2.1648880798801082
Validation loss: 2.4612202234696583

Epoch: 5| Step: 6
Training loss: 2.7361683223657627
Validation loss: 2.47244313603767

Epoch: 5| Step: 7
Training loss: 2.278959404577537
Validation loss: 2.473555190049049

Epoch: 5| Step: 8
Training loss: 2.4946100305577477
Validation loss: 2.473977736681422

Epoch: 5| Step: 9
Training loss: 2.656528054437994
Validation loss: 2.4664449191513396

Epoch: 5| Step: 10
Training loss: 2.516128584409726
Validation loss: 2.4727393141901852

Epoch: 5| Step: 11
Training loss: 1.7874243953694902
Validation loss: 2.4601285866467855

Epoch: 164| Step: 0
Training loss: 2.448923582941675
Validation loss: 2.4603847791224203

Epoch: 5| Step: 1
Training loss: 2.4224936402732427
Validation loss: 2.4640877758883426

Epoch: 5| Step: 2
Training loss: 2.726591356010001
Validation loss: 2.461909446323601

Epoch: 5| Step: 3
Training loss: 2.459698949706499
Validation loss: 2.4545413502504734

Epoch: 5| Step: 4
Training loss: 2.5719981130471434
Validation loss: 2.461996127310196

Epoch: 5| Step: 5
Training loss: 2.318391666332086
Validation loss: 2.4505406188706615

Epoch: 5| Step: 6
Training loss: 2.502804232462358
Validation loss: 2.4548846127831276

Epoch: 5| Step: 7
Training loss: 2.402192000891929
Validation loss: 2.4512024450738856

Epoch: 5| Step: 8
Training loss: 3.025695430800301
Validation loss: 2.4517659474279463

Epoch: 5| Step: 9
Training loss: 2.1951406825695643
Validation loss: 2.4517227303646845

Epoch: 5| Step: 10
Training loss: 2.749589109068349
Validation loss: 2.4561377529610673

Epoch: 5| Step: 11
Training loss: 2.368872316770497
Validation loss: 2.455190606930594

Epoch: 165| Step: 0
Training loss: 2.3146217510103555
Validation loss: 2.45549012224503

Epoch: 5| Step: 1
Training loss: 2.9877723410103627
Validation loss: 2.4504338018277383

Epoch: 5| Step: 2
Training loss: 2.5415897878891363
Validation loss: 2.4542896964209895

Epoch: 5| Step: 3
Training loss: 2.3820601479393586
Validation loss: 2.4522246917734165

Epoch: 5| Step: 4
Training loss: 1.9955661024033453
Validation loss: 2.4476789007306703

Epoch: 5| Step: 5
Training loss: 2.5255640476332233
Validation loss: 2.4490709924414746

Epoch: 5| Step: 6
Training loss: 2.3991278732712704
Validation loss: 2.4536600076202166

Epoch: 5| Step: 7
Training loss: 2.388976282793225
Validation loss: 2.4523501255632665

Epoch: 5| Step: 8
Training loss: 2.7963423408196193
Validation loss: 2.4595658814331682

Epoch: 5| Step: 9
Training loss: 2.516752760300847
Validation loss: 2.452759849196125

Epoch: 5| Step: 10
Training loss: 2.861699228014477
Validation loss: 2.452560303115499

Epoch: 5| Step: 11
Training loss: 0.9844882839352379
Validation loss: 2.455080006552425

Epoch: 166| Step: 0
Training loss: 2.7784940802700047
Validation loss: 2.4503924018265173

Epoch: 5| Step: 1
Training loss: 2.110305128950354
Validation loss: 2.4520249380603603

Epoch: 5| Step: 2
Training loss: 2.892185758964225
Validation loss: 2.448518940038368

Epoch: 5| Step: 3
Training loss: 3.1990416760748324
Validation loss: 2.45029197594434

Epoch: 5| Step: 4
Training loss: 2.4445659241208952
Validation loss: 2.456046371496442

Epoch: 5| Step: 5
Training loss: 2.5618514193854653
Validation loss: 2.4491832229657775

Epoch: 5| Step: 6
Training loss: 2.0792079771087724
Validation loss: 2.4538207009167445

Epoch: 5| Step: 7
Training loss: 2.389925386868252
Validation loss: 2.4477781838279005

Epoch: 5| Step: 8
Training loss: 2.1508970296661256
Validation loss: 2.454336478722169

Epoch: 5| Step: 9
Training loss: 2.4286147322119844
Validation loss: 2.447427450493898

Epoch: 5| Step: 10
Training loss: 2.4458188638686957
Validation loss: 2.457312187302113

Epoch: 5| Step: 11
Training loss: 2.3360812037737473
Validation loss: 2.453158228541846

Epoch: 167| Step: 0
Training loss: 2.786054340678783
Validation loss: 2.459245756244065

Epoch: 5| Step: 1
Training loss: 2.414085610288349
Validation loss: 2.463675664009006

Epoch: 5| Step: 2
Training loss: 2.5626055067718485
Validation loss: 2.470654807039221

Epoch: 5| Step: 3
Training loss: 2.3911185160340644
Validation loss: 2.4654536593444147

Epoch: 5| Step: 4
Training loss: 2.717618158573891
Validation loss: 2.4671457647490334

Epoch: 5| Step: 5
Training loss: 1.887394564885888
Validation loss: 2.468623540351538

Epoch: 5| Step: 6
Training loss: 2.27894862897019
Validation loss: 2.4722668068386175

Epoch: 5| Step: 7
Training loss: 2.6869674864754995
Validation loss: 2.472677004758682

Epoch: 5| Step: 8
Training loss: 2.5181635019971456
Validation loss: 2.4628458364368573

Epoch: 5| Step: 9
Training loss: 2.8869369486314618
Validation loss: 2.4629431892128157

Epoch: 5| Step: 10
Training loss: 2.804459841528593
Validation loss: 2.461641152515912

Epoch: 5| Step: 11
Training loss: 2.7619896395721697
Validation loss: 2.458994365709212

Epoch: 168| Step: 0
Training loss: 2.132274294286891
Validation loss: 2.451647100696853

Epoch: 5| Step: 1
Training loss: 2.778899667735826
Validation loss: 2.4530069642715198

Epoch: 5| Step: 2
Training loss: 2.559544603552687
Validation loss: 2.4610694365480787

Epoch: 5| Step: 3
Training loss: 2.2264265052355383
Validation loss: 2.4663171289095263

Epoch: 5| Step: 4
Training loss: 2.811319739332012
Validation loss: 2.4818871154976163

Epoch: 5| Step: 5
Training loss: 2.8047674906170244
Validation loss: 2.4774310216626274

Epoch: 5| Step: 6
Training loss: 2.1619238907424085
Validation loss: 2.4590810403768457

Epoch: 5| Step: 7
Training loss: 2.189424376762646
Validation loss: 2.467773087278461

Epoch: 5| Step: 8
Training loss: 2.838881464693631
Validation loss: 2.4669681226861155

Epoch: 5| Step: 9
Training loss: 2.2698125615645512
Validation loss: 2.472415367956291

Epoch: 5| Step: 10
Training loss: 2.7033848279320254
Validation loss: 2.4616215557449506

Epoch: 5| Step: 11
Training loss: 3.268983273178348
Validation loss: 2.466426802476961

Epoch: 169| Step: 0
Training loss: 2.7387643515812803
Validation loss: 2.458593744019964

Epoch: 5| Step: 1
Training loss: 2.150976837388183
Validation loss: 2.4500625349355074

Epoch: 5| Step: 2
Training loss: 2.7409802683941513
Validation loss: 2.459271039304464

Epoch: 5| Step: 3
Training loss: 2.3365372618225053
Validation loss: 2.4643248965621476

Epoch: 5| Step: 4
Training loss: 1.9166597145065052
Validation loss: 2.47264809830594

Epoch: 5| Step: 5
Training loss: 2.758070893110277
Validation loss: 2.4652280835320375

Epoch: 5| Step: 6
Training loss: 2.496788250653931
Validation loss: 2.4544305141974774

Epoch: 5| Step: 7
Training loss: 2.629875559890668
Validation loss: 2.4521177779387227

Epoch: 5| Step: 8
Training loss: 2.344815126626801
Validation loss: 2.449853615053112

Epoch: 5| Step: 9
Training loss: 2.375533796856472
Validation loss: 2.450119927611069

Epoch: 5| Step: 10
Training loss: 3.0138993934491256
Validation loss: 2.457782652702588

Epoch: 5| Step: 11
Training loss: 2.8384719326774497
Validation loss: 2.4501171644409983

Epoch: 170| Step: 0
Training loss: 2.493530581197852
Validation loss: 2.4639265648229784

Epoch: 5| Step: 1
Training loss: 2.9971738855209633
Validation loss: 2.4714271901754463

Epoch: 5| Step: 2
Training loss: 2.7726437574563594
Validation loss: 2.473949088363774

Epoch: 5| Step: 3
Training loss: 2.8331219276396418
Validation loss: 2.487234465325828

Epoch: 5| Step: 4
Training loss: 2.966751550324452
Validation loss: 2.496242600342301

Epoch: 5| Step: 5
Training loss: 2.3484389131888213
Validation loss: 2.5125985233797086

Epoch: 5| Step: 6
Training loss: 2.547863072361651
Validation loss: 2.520380276302564

Epoch: 5| Step: 7
Training loss: 2.4020461975914973
Validation loss: 2.5272035830118726

Epoch: 5| Step: 8
Training loss: 2.2773960951584957
Validation loss: 2.533407661378651

Epoch: 5| Step: 9
Training loss: 2.82244175556051
Validation loss: 2.5433222324317395

Epoch: 5| Step: 10
Training loss: 2.5181246830837556
Validation loss: 2.5483574794459463

Epoch: 5| Step: 11
Training loss: 1.8533864755124076
Validation loss: 2.540730754845595

Epoch: 171| Step: 0
Training loss: 2.8042291038178777
Validation loss: 2.5496507313520818

Epoch: 5| Step: 1
Training loss: 2.534469723136644
Validation loss: 2.5337039763165214

Epoch: 5| Step: 2
Training loss: 2.2986076203851487
Validation loss: 2.53272210394615

Epoch: 5| Step: 3
Training loss: 2.3734238062269544
Validation loss: 2.529661091978273

Epoch: 5| Step: 4
Training loss: 2.840400819566826
Validation loss: 2.522590254834676

Epoch: 5| Step: 5
Training loss: 2.934197537679512
Validation loss: 2.5187064148923675

Epoch: 5| Step: 6
Training loss: 2.4991636784726357
Validation loss: 2.5180308800746247

Epoch: 5| Step: 7
Training loss: 2.6956289796647277
Validation loss: 2.5049737250751463

Epoch: 5| Step: 8
Training loss: 2.950501906807585
Validation loss: 2.4963647439595817

Epoch: 5| Step: 9
Training loss: 2.356092784706078
Validation loss: 2.4935816947849103

Epoch: 5| Step: 10
Training loss: 2.630392892739052
Validation loss: 2.4887301181373953

Epoch: 5| Step: 11
Training loss: 2.001403197143904
Validation loss: 2.481580758329658

Epoch: 172| Step: 0
Training loss: 3.1163331966870036
Validation loss: 2.4766517526807337

Epoch: 5| Step: 1
Training loss: 2.3135295328860908
Validation loss: 2.469902337012237

Epoch: 5| Step: 2
Training loss: 2.1387458962646924
Validation loss: 2.4703514522318164

Epoch: 5| Step: 3
Training loss: 2.7859674799788157
Validation loss: 2.459718868737496

Epoch: 5| Step: 4
Training loss: 2.8437676062405703
Validation loss: 2.4612357064873915

Epoch: 5| Step: 5
Training loss: 2.9688282203408285
Validation loss: 2.468559551538556

Epoch: 5| Step: 6
Training loss: 2.135979728588252
Validation loss: 2.462920101754737

Epoch: 5| Step: 7
Training loss: 2.07567308378823
Validation loss: 2.4623378059623207

Epoch: 5| Step: 8
Training loss: 2.5549259366164527
Validation loss: 2.4629462546172496

Epoch: 5| Step: 9
Training loss: 2.6993777370416923
Validation loss: 2.45087505838372

Epoch: 5| Step: 10
Training loss: 2.3752796610763025
Validation loss: 2.4586970914155852

Epoch: 5| Step: 11
Training loss: 2.775431687053297
Validation loss: 2.4679410429942212

Epoch: 173| Step: 0
Training loss: 2.525110215907026
Validation loss: 2.4592082129040898

Epoch: 5| Step: 1
Training loss: 2.3394616122242318
Validation loss: 2.4564014066214033

Epoch: 5| Step: 2
Training loss: 2.856297405358708
Validation loss: 2.460348250471232

Epoch: 5| Step: 3
Training loss: 2.478453098046503
Validation loss: 2.462272314334557

Epoch: 5| Step: 4
Training loss: 2.2974367038778665
Validation loss: 2.4623012397156776

Epoch: 5| Step: 5
Training loss: 2.549340114106986
Validation loss: 2.4531036181641808

Epoch: 5| Step: 6
Training loss: 2.2634458387875136
Validation loss: 2.449576550986001

Epoch: 5| Step: 7
Training loss: 2.7235068438790466
Validation loss: 2.4464303164331698

Epoch: 5| Step: 8
Training loss: 2.510571539653669
Validation loss: 2.446800319624911

Epoch: 5| Step: 9
Training loss: 2.7025263128843493
Validation loss: 2.446034114747903

Epoch: 5| Step: 10
Training loss: 2.536704415062621
Validation loss: 2.436086807422142

Epoch: 5| Step: 11
Training loss: 3.0422008167322176
Validation loss: 2.439875451886767

Epoch: 174| Step: 0
Training loss: 2.364542978981495
Validation loss: 2.442306163489593

Epoch: 5| Step: 1
Training loss: 2.318278747544902
Validation loss: 2.4442767264225136

Epoch: 5| Step: 2
Training loss: 2.590049954083596
Validation loss: 2.441970265660868

Epoch: 5| Step: 3
Training loss: 2.412938025837884
Validation loss: 2.439805481067326

Epoch: 5| Step: 4
Training loss: 3.1030265369909453
Validation loss: 2.4400679681644917

Epoch: 5| Step: 5
Training loss: 2.694835764422517
Validation loss: 2.4502105043441262

Epoch: 5| Step: 6
Training loss: 2.9768769506127315
Validation loss: 2.443727530094009

Epoch: 5| Step: 7
Training loss: 2.4906124291766845
Validation loss: 2.4477933013889084

Epoch: 5| Step: 8
Training loss: 2.0243090074646797
Validation loss: 2.4388231655716086

Epoch: 5| Step: 9
Training loss: 2.4090532100338535
Validation loss: 2.44112000681994

Epoch: 5| Step: 10
Training loss: 2.1247924254517954
Validation loss: 2.4438143661523246

Epoch: 5| Step: 11
Training loss: 2.770488019569323
Validation loss: 2.442765519232587

Epoch: 175| Step: 0
Training loss: 2.8952871306080423
Validation loss: 2.4471817915577923

Epoch: 5| Step: 1
Training loss: 2.3785016196507827
Validation loss: 2.444897058802559

Epoch: 5| Step: 2
Training loss: 2.362889583699039
Validation loss: 2.443678906407437

Epoch: 5| Step: 3
Training loss: 2.9819693731095036
Validation loss: 2.4447601271356936

Epoch: 5| Step: 4
Training loss: 2.014073210718102
Validation loss: 2.4432397249495543

Epoch: 5| Step: 5
Training loss: 2.1903216011771542
Validation loss: 2.4439205802837325

Epoch: 5| Step: 6
Training loss: 2.9626723871092873
Validation loss: 2.443522264157085

Epoch: 5| Step: 7
Training loss: 2.3363860347161283
Validation loss: 2.442439427787936

Epoch: 5| Step: 8
Training loss: 2.8324235315598174
Validation loss: 2.446710077479049

Epoch: 5| Step: 9
Training loss: 2.6246703712948185
Validation loss: 2.4483074052237144

Epoch: 5| Step: 10
Training loss: 2.1033626065078668
Validation loss: 2.451716915897601

Epoch: 5| Step: 11
Training loss: 1.5298812353875282
Validation loss: 2.4480236063926184

Epoch: 176| Step: 0
Training loss: 2.5202834315081066
Validation loss: 2.4443546568270222

Epoch: 5| Step: 1
Training loss: 2.721696331409909
Validation loss: 2.44528079190075

Epoch: 5| Step: 2
Training loss: 2.514913517581773
Validation loss: 2.4460566792927514

Epoch: 5| Step: 3
Training loss: 2.240385388021251
Validation loss: 2.444044326658082

Epoch: 5| Step: 4
Training loss: 2.52732167536486
Validation loss: 2.448303217837912

Epoch: 5| Step: 5
Training loss: 2.6461533680797684
Validation loss: 2.4480527488273216

Epoch: 5| Step: 6
Training loss: 2.642281999934014
Validation loss: 2.449094534953213

Epoch: 5| Step: 7
Training loss: 2.143782577044692
Validation loss: 2.4442988316799026

Epoch: 5| Step: 8
Training loss: 2.4336224549683987
Validation loss: 2.4472305242563857

Epoch: 5| Step: 9
Training loss: 2.571937858768216
Validation loss: 2.443569236339869

Epoch: 5| Step: 10
Training loss: 2.668440993418754
Validation loss: 2.444516827418954

Epoch: 5| Step: 11
Training loss: 2.189793392695222
Validation loss: 2.4543499368673904

Epoch: 177| Step: 0
Training loss: 2.0998008179436023
Validation loss: 2.4665262371332677

Epoch: 5| Step: 1
Training loss: 2.8090912400851793
Validation loss: 2.4631167657639197

Epoch: 5| Step: 2
Training loss: 2.605092446120105
Validation loss: 2.459472175594563

Epoch: 5| Step: 3
Training loss: 2.6254430124567008
Validation loss: 2.4641370450396947

Epoch: 5| Step: 4
Training loss: 1.7953865852707234
Validation loss: 2.4666960497558064

Epoch: 5| Step: 5
Training loss: 2.459649999577656
Validation loss: 2.4646110364357123

Epoch: 5| Step: 6
Training loss: 2.6392893827491397
Validation loss: 2.461929924487723

Epoch: 5| Step: 7
Training loss: 2.5682099157439766
Validation loss: 2.4400663518808385

Epoch: 5| Step: 8
Training loss: 2.8300368448831184
Validation loss: 2.4429063221960066

Epoch: 5| Step: 9
Training loss: 2.6408630805498383
Validation loss: 2.4454802271770832

Epoch: 5| Step: 10
Training loss: 2.69540378581828
Validation loss: 2.4552419137957826

Epoch: 5| Step: 11
Training loss: 2.4230200244990825
Validation loss: 2.456227359554141

Epoch: 178| Step: 0
Training loss: 2.2214779269649916
Validation loss: 2.4650617766038434

Epoch: 5| Step: 1
Training loss: 3.109968885897806
Validation loss: 2.477363801760943

Epoch: 5| Step: 2
Training loss: 2.5836223830259155
Validation loss: 2.462366393703889

Epoch: 5| Step: 3
Training loss: 2.5954983804867093
Validation loss: 2.478550723573605

Epoch: 5| Step: 4
Training loss: 2.9311265996729903
Validation loss: 2.4700404066186192

Epoch: 5| Step: 5
Training loss: 2.379719311807744
Validation loss: 2.4573489187464412

Epoch: 5| Step: 6
Training loss: 2.345635024836296
Validation loss: 2.4624476426427386

Epoch: 5| Step: 7
Training loss: 2.373986479684562
Validation loss: 2.4637414933200854

Epoch: 5| Step: 8
Training loss: 2.573022405225133
Validation loss: 2.4629782273647587

Epoch: 5| Step: 9
Training loss: 2.2234016335141913
Validation loss: 2.4568316828912793

Epoch: 5| Step: 10
Training loss: 2.6525633416266525
Validation loss: 2.455809244338265

Epoch: 5| Step: 11
Training loss: 2.328032421345112
Validation loss: 2.450610903396412

Epoch: 179| Step: 0
Training loss: 2.641339267534692
Validation loss: 2.4437596404657027

Epoch: 5| Step: 1
Training loss: 2.216713629012398
Validation loss: 2.4524837554798062

Epoch: 5| Step: 2
Training loss: 2.8170839042044236
Validation loss: 2.445675259333765

Epoch: 5| Step: 3
Training loss: 2.8629085199288933
Validation loss: 2.449585442519141

Epoch: 5| Step: 4
Training loss: 1.9452980990815163
Validation loss: 2.454203783530709

Epoch: 5| Step: 5
Training loss: 2.4125910845545238
Validation loss: 2.452202378437681

Epoch: 5| Step: 6
Training loss: 2.8512852364135104
Validation loss: 2.456183436351654

Epoch: 5| Step: 7
Training loss: 2.38065247735921
Validation loss: 2.450430964012146

Epoch: 5| Step: 8
Training loss: 2.4781885434791375
Validation loss: 2.4568363389342567

Epoch: 5| Step: 9
Training loss: 2.72346543665973
Validation loss: 2.4489295013971852

Epoch: 5| Step: 10
Training loss: 2.2630754529348485
Validation loss: 2.451783260781758

Epoch: 5| Step: 11
Training loss: 2.216564660366398
Validation loss: 2.4451002449321964

Epoch: 180| Step: 0
Training loss: 2.7710989535562223
Validation loss: 2.4446041108917203

Epoch: 5| Step: 1
Training loss: 2.461232194966884
Validation loss: 2.4463843209710205

Epoch: 5| Step: 2
Training loss: 2.3173900142771577
Validation loss: 2.453746992171872

Epoch: 5| Step: 3
Training loss: 2.5463310550154
Validation loss: 2.4436975453983822

Epoch: 5| Step: 4
Training loss: 2.7890718176763563
Validation loss: 2.4491586145444075

Epoch: 5| Step: 5
Training loss: 2.5792837602188636
Validation loss: 2.4447691235493747

Epoch: 5| Step: 6
Training loss: 2.244180146110878
Validation loss: 2.456357328805632

Epoch: 5| Step: 7
Training loss: 2.913860733369754
Validation loss: 2.4533389376838914

Epoch: 5| Step: 8
Training loss: 1.8638306773356494
Validation loss: 2.443459297086531

Epoch: 5| Step: 9
Training loss: 2.711396719874535
Validation loss: 2.4575729541162494

Epoch: 5| Step: 10
Training loss: 2.384510573386301
Validation loss: 2.4512246256670323

Epoch: 5| Step: 11
Training loss: 1.8173169549962913
Validation loss: 2.455285081053647

Epoch: 181| Step: 0
Training loss: 2.6663256566240423
Validation loss: 2.4529403608938227

Epoch: 5| Step: 1
Training loss: 2.2960176489680038
Validation loss: 2.448634693000702

Epoch: 5| Step: 2
Training loss: 2.404001944555426
Validation loss: 2.4591497598448453

Epoch: 5| Step: 3
Training loss: 2.906361895632371
Validation loss: 2.4542498915009974

Epoch: 5| Step: 4
Training loss: 2.716437836431299
Validation loss: 2.4623246718695824

Epoch: 5| Step: 5
Training loss: 2.880309468172871
Validation loss: 2.4605013385149688

Epoch: 5| Step: 6
Training loss: 2.0526629434601156
Validation loss: 2.467477772447367

Epoch: 5| Step: 7
Training loss: 2.8289298076855007
Validation loss: 2.462261509843925

Epoch: 5| Step: 8
Training loss: 2.4842065718076576
Validation loss: 2.4573014256853725

Epoch: 5| Step: 9
Training loss: 2.150469897175035
Validation loss: 2.465469196362331

Epoch: 5| Step: 10
Training loss: 1.9977463303218281
Validation loss: 2.466441827887393

Epoch: 5| Step: 11
Training loss: 2.385221770430272
Validation loss: 2.453023673554611

Epoch: 182| Step: 0
Training loss: 2.4328283879049786
Validation loss: 2.4482954232760807

Epoch: 5| Step: 1
Training loss: 2.428487794301535
Validation loss: 2.44974016219509

Epoch: 5| Step: 2
Training loss: 2.5842080224926987
Validation loss: 2.454258654791294

Epoch: 5| Step: 3
Training loss: 2.856441473020924
Validation loss: 2.458810042104088

Epoch: 5| Step: 4
Training loss: 2.622708455720398
Validation loss: 2.460451330370892

Epoch: 5| Step: 5
Training loss: 2.7401893051911013
Validation loss: 2.465512591508358

Epoch: 5| Step: 6
Training loss: 1.9176417303114546
Validation loss: 2.461306876259493

Epoch: 5| Step: 7
Training loss: 3.1683104080368776
Validation loss: 2.4639191462637124

Epoch: 5| Step: 8
Training loss: 2.0516883224637654
Validation loss: 2.462993604547574

Epoch: 5| Step: 9
Training loss: 2.5471616244367805
Validation loss: 2.458955945897712

Epoch: 5| Step: 10
Training loss: 2.4461298055071863
Validation loss: 2.4632677378930654

Epoch: 5| Step: 11
Training loss: 1.7850869330172565
Validation loss: 2.4611547424664924

Epoch: 183| Step: 0
Training loss: 2.2186496335821566
Validation loss: 2.453033498203554

Epoch: 5| Step: 1
Training loss: 2.310422634418601
Validation loss: 2.4558415041674224

Epoch: 5| Step: 2
Training loss: 2.715256386553664
Validation loss: 2.444249191096244

Epoch: 5| Step: 3
Training loss: 2.3179490096611617
Validation loss: 2.4406254895771884

Epoch: 5| Step: 4
Training loss: 2.5865417880788764
Validation loss: 2.4457380881169066

Epoch: 5| Step: 5
Training loss: 3.0147362224524383
Validation loss: 2.4411593747250033

Epoch: 5| Step: 6
Training loss: 2.452600508097341
Validation loss: 2.460960456700702

Epoch: 5| Step: 7
Training loss: 2.1349927776134106
Validation loss: 2.4575127926749314

Epoch: 5| Step: 8
Training loss: 3.1031656037869406
Validation loss: 2.480805942314565

Epoch: 5| Step: 9
Training loss: 2.730411730868122
Validation loss: 2.475580628519178

Epoch: 5| Step: 10
Training loss: 2.2505314517210255
Validation loss: 2.466200622841547

Epoch: 5| Step: 11
Training loss: 1.0056993672035413
Validation loss: 2.4493920580779456

Epoch: 184| Step: 0
Training loss: 2.5748044911948553
Validation loss: 2.449843323492203

Epoch: 5| Step: 1
Training loss: 2.9091293673790894
Validation loss: 2.46349191649019

Epoch: 5| Step: 2
Training loss: 2.5557920535393834
Validation loss: 2.465441873548454

Epoch: 5| Step: 3
Training loss: 2.351152453997502
Validation loss: 2.459410364138294

Epoch: 5| Step: 4
Training loss: 2.1540492893413243
Validation loss: 2.4590585145486976

Epoch: 5| Step: 5
Training loss: 1.9927156234530756
Validation loss: 2.4528498890165915

Epoch: 5| Step: 6
Training loss: 2.388030096193498
Validation loss: 2.4663442325779994

Epoch: 5| Step: 7
Training loss: 2.9527313131474733
Validation loss: 2.468383303099337

Epoch: 5| Step: 8
Training loss: 2.277500363129002
Validation loss: 2.4623772098373777

Epoch: 5| Step: 9
Training loss: 2.4603854089916095
Validation loss: 2.464427931060173

Epoch: 5| Step: 10
Training loss: 2.824917486555522
Validation loss: 2.462996724339376

Epoch: 5| Step: 11
Training loss: 3.2599461290085894
Validation loss: 2.461847332891509

Epoch: 185| Step: 0
Training loss: 2.7364609963111617
Validation loss: 2.4668939148015294

Epoch: 5| Step: 1
Training loss: 2.6838919794543057
Validation loss: 2.4577544845520998

Epoch: 5| Step: 2
Training loss: 2.201034311431809
Validation loss: 2.450781993077459

Epoch: 5| Step: 3
Training loss: 1.8430015208527308
Validation loss: 2.454938562392295

Epoch: 5| Step: 4
Training loss: 3.125046386374479
Validation loss: 2.4553018294540276

Epoch: 5| Step: 5
Training loss: 2.1762498662555267
Validation loss: 2.4502896974522073

Epoch: 5| Step: 6
Training loss: 2.3951063850045373
Validation loss: 2.4620652294241125

Epoch: 5| Step: 7
Training loss: 2.409117340283144
Validation loss: 2.4529969572760373

Epoch: 5| Step: 8
Training loss: 2.2378514061859005
Validation loss: 2.456234303878059

Epoch: 5| Step: 9
Training loss: 2.7019137276091683
Validation loss: 2.4588975434024807

Epoch: 5| Step: 10
Training loss: 2.811244430027622
Validation loss: 2.458887370496171

Epoch: 5| Step: 11
Training loss: 2.6559361889538917
Validation loss: 2.4635589806000033

Epoch: 186| Step: 0
Training loss: 2.796292036454205
Validation loss: 2.4703304024710575

Epoch: 5| Step: 1
Training loss: 2.3747537384855146
Validation loss: 2.4633198564986247

Epoch: 5| Step: 2
Training loss: 2.6520642679692377
Validation loss: 2.481368398844291

Epoch: 5| Step: 3
Training loss: 2.4728708761636184
Validation loss: 2.4711758087295093

Epoch: 5| Step: 4
Training loss: 2.710882356725953
Validation loss: 2.4651543955008015

Epoch: 5| Step: 5
Training loss: 2.375705614174906
Validation loss: 2.45461655078567

Epoch: 5| Step: 6
Training loss: 2.3737136971428163
Validation loss: 2.4592283217279407

Epoch: 5| Step: 7
Training loss: 2.3115555149007383
Validation loss: 2.4546523553221102

Epoch: 5| Step: 8
Training loss: 2.6665600119560935
Validation loss: 2.4523552741907806

Epoch: 5| Step: 9
Training loss: 2.756772544961688
Validation loss: 2.4561898590568116

Epoch: 5| Step: 10
Training loss: 2.3242165958170165
Validation loss: 2.4594270420344415

Epoch: 5| Step: 11
Training loss: 1.9757440252029108
Validation loss: 2.4506215038694585

Epoch: 187| Step: 0
Training loss: 2.899183151696788
Validation loss: 2.457922942987803

Epoch: 5| Step: 1
Training loss: 2.3996974356984984
Validation loss: 2.4567657230192768

Epoch: 5| Step: 2
Training loss: 2.4093541521686905
Validation loss: 2.4598372164420623

Epoch: 5| Step: 3
Training loss: 2.0784861315387753
Validation loss: 2.455712624120297

Epoch: 5| Step: 4
Training loss: 2.5091322043881825
Validation loss: 2.468562247786399

Epoch: 5| Step: 5
Training loss: 2.3877730967327513
Validation loss: 2.464609117821812

Epoch: 5| Step: 6
Training loss: 2.9099183260542967
Validation loss: 2.468497243247509

Epoch: 5| Step: 7
Training loss: 2.999714201983099
Validation loss: 2.46750842232444

Epoch: 5| Step: 8
Training loss: 2.426059577933649
Validation loss: 2.4579392025626805

Epoch: 5| Step: 9
Training loss: 2.2506136587207304
Validation loss: 2.4607888696584737

Epoch: 5| Step: 10
Training loss: 2.2514274096019147
Validation loss: 2.472953296434011

Epoch: 5| Step: 11
Training loss: 1.4559509526941492
Validation loss: 2.4576396502233466

Epoch: 188| Step: 0
Training loss: 2.5955172114101965
Validation loss: 2.462715007541774

Epoch: 5| Step: 1
Training loss: 2.1768525532110874
Validation loss: 2.4599095453131485

Epoch: 5| Step: 2
Training loss: 1.7890339145292398
Validation loss: 2.466296844263108

Epoch: 5| Step: 3
Training loss: 2.3336513393410763
Validation loss: 2.4695800520586184

Epoch: 5| Step: 4
Training loss: 2.7528451593310588
Validation loss: 2.463124910687104

Epoch: 5| Step: 5
Training loss: 2.8032832548617925
Validation loss: 2.470386127948654

Epoch: 5| Step: 6
Training loss: 2.3495076982754006
Validation loss: 2.4668648197726566

Epoch: 5| Step: 7
Training loss: 2.3431885110301898
Validation loss: 2.4672389536656802

Epoch: 5| Step: 8
Training loss: 3.1647071464247425
Validation loss: 2.4657096087592887

Epoch: 5| Step: 9
Training loss: 2.133297372554641
Validation loss: 2.4671176511553896

Epoch: 5| Step: 10
Training loss: 2.7446688214969153
Validation loss: 2.45976801538899

Epoch: 5| Step: 11
Training loss: 2.4324719337028236
Validation loss: 2.4567179558466856

Epoch: 189| Step: 0
Training loss: 2.478428183020911
Validation loss: 2.462439915041805

Epoch: 5| Step: 1
Training loss: 2.556375208541998
Validation loss: 2.4545092999814493

Epoch: 5| Step: 2
Training loss: 2.167070082252543
Validation loss: 2.464005829121715

Epoch: 5| Step: 3
Training loss: 2.4408577508856584
Validation loss: 2.46211136366913

Epoch: 5| Step: 4
Training loss: 2.3129691601720466
Validation loss: 2.4571476126945084

Epoch: 5| Step: 5
Training loss: 2.5982311100290993
Validation loss: 2.4661690826018337

Epoch: 5| Step: 6
Training loss: 2.562611647243851
Validation loss: 2.466635879252512

Epoch: 5| Step: 7
Training loss: 2.7875297031616184
Validation loss: 2.473755462091734

Epoch: 5| Step: 8
Training loss: 2.832157695183689
Validation loss: 2.468520407322099

Epoch: 5| Step: 9
Training loss: 1.6929967859443849
Validation loss: 2.460631368659688

Epoch: 5| Step: 10
Training loss: 3.0229845126579016
Validation loss: 2.4652629038462024

Epoch: 5| Step: 11
Training loss: 2.427707859179915
Validation loss: 2.464448767207887

Epoch: 190| Step: 0
Training loss: 2.7279931280155827
Validation loss: 2.459261445587112

Epoch: 5| Step: 1
Training loss: 2.3733086837960085
Validation loss: 2.4565217420277237

Epoch: 5| Step: 2
Training loss: 2.499881932331634
Validation loss: 2.458005892773438

Epoch: 5| Step: 3
Training loss: 1.8398732954435022
Validation loss: 2.4591716829345933

Epoch: 5| Step: 4
Training loss: 2.681140383455954
Validation loss: 2.457028759427974

Epoch: 5| Step: 5
Training loss: 2.794170841206717
Validation loss: 2.4656208020566552

Epoch: 5| Step: 6
Training loss: 2.6261545094737655
Validation loss: 2.4796945319810146

Epoch: 5| Step: 7
Training loss: 2.2440729487932463
Validation loss: 2.48213238532591

Epoch: 5| Step: 8
Training loss: 2.441021258707393
Validation loss: 2.46939957599645

Epoch: 5| Step: 9
Training loss: 2.516395403493098
Validation loss: 2.4916684238933717

Epoch: 5| Step: 10
Training loss: 2.53993871975364
Validation loss: 2.482651514556246

Epoch: 5| Step: 11
Training loss: 1.9256354038808072
Validation loss: 2.474483371367857

Epoch: 191| Step: 0
Training loss: 2.6836074317905414
Validation loss: 2.488240583517666

Epoch: 5| Step: 1
Training loss: 2.6916067992679085
Validation loss: 2.5422211469546663

Epoch: 5| Step: 2
Training loss: 2.7149622170926206
Validation loss: 2.549117499400372

Epoch: 5| Step: 3
Training loss: 3.0933771390389198
Validation loss: 2.497805474621935

Epoch: 5| Step: 4
Training loss: 2.4063020180368166
Validation loss: 2.474547259186689

Epoch: 5| Step: 5
Training loss: 2.6185667133147628
Validation loss: 2.4660119071024824

Epoch: 5| Step: 6
Training loss: 2.5393980772832108
Validation loss: 2.460443867014365

Epoch: 5| Step: 7
Training loss: 2.1047547780635276
Validation loss: 2.459299620281425

Epoch: 5| Step: 8
Training loss: 2.1040004500907155
Validation loss: 2.4619215799086005

Epoch: 5| Step: 9
Training loss: 2.018304507582329
Validation loss: 2.4725401872712416

Epoch: 5| Step: 10
Training loss: 2.648787033736679
Validation loss: 2.4715356039983445

Epoch: 5| Step: 11
Training loss: 2.3883296942921626
Validation loss: 2.475456666800343

Epoch: 192| Step: 0
Training loss: 1.8606126016415807
Validation loss: 2.4764168633320156

Epoch: 5| Step: 1
Training loss: 2.931608257076894
Validation loss: 2.4831962668165306

Epoch: 5| Step: 2
Training loss: 2.360232468971366
Validation loss: 2.474104338235923

Epoch: 5| Step: 3
Training loss: 2.160384926582728
Validation loss: 2.4804245792170647

Epoch: 5| Step: 4
Training loss: 2.9631072375705156
Validation loss: 2.474743127658097

Epoch: 5| Step: 5
Training loss: 2.5660559939238734
Validation loss: 2.4708812664479556

Epoch: 5| Step: 6
Training loss: 2.454149360358244
Validation loss: 2.46444948875057

Epoch: 5| Step: 7
Training loss: 2.9727244225202805
Validation loss: 2.463953735105581

Epoch: 5| Step: 8
Training loss: 2.4846419664811106
Validation loss: 2.4600197791451905

Epoch: 5| Step: 9
Training loss: 2.407263109034188
Validation loss: 2.4578949381136304

Epoch: 5| Step: 10
Training loss: 2.4527259064668065
Validation loss: 2.455674298598166

Epoch: 5| Step: 11
Training loss: 2.122745889140592
Validation loss: 2.4569293892047352

Epoch: 193| Step: 0
Training loss: 2.772466785173474
Validation loss: 2.4611192020568384

Epoch: 5| Step: 1
Training loss: 2.3558476840718874
Validation loss: 2.4653655929028786

Epoch: 5| Step: 2
Training loss: 2.444769753378361
Validation loss: 2.4631174554316457

Epoch: 5| Step: 3
Training loss: 2.61074299844053
Validation loss: 2.4789982799971853

Epoch: 5| Step: 4
Training loss: 2.058621545708932
Validation loss: 2.476593482689142

Epoch: 5| Step: 5
Training loss: 2.3336770848967654
Validation loss: 2.4636630350315913

Epoch: 5| Step: 6
Training loss: 2.8352658656088185
Validation loss: 2.4558984341475045

Epoch: 5| Step: 7
Training loss: 2.360095387810202
Validation loss: 2.463359367663625

Epoch: 5| Step: 8
Training loss: 2.6718818709078778
Validation loss: 2.4599167215458055

Epoch: 5| Step: 9
Training loss: 2.5113048538741363
Validation loss: 2.4645104724521962

Epoch: 5| Step: 10
Training loss: 2.4322957944869006
Validation loss: 2.469535392863149

Epoch: 5| Step: 11
Training loss: 2.737590446894045
Validation loss: 2.4684599573234465

Epoch: 194| Step: 0
Training loss: 2.1115836554361347
Validation loss: 2.468080896733934

Epoch: 5| Step: 1
Training loss: 2.556231484194527
Validation loss: 2.463000021594031

Epoch: 5| Step: 2
Training loss: 2.381637733911953
Validation loss: 2.467310872294027

Epoch: 5| Step: 3
Training loss: 2.72530329355094
Validation loss: 2.466939407060665

Epoch: 5| Step: 4
Training loss: 3.4397528462004847
Validation loss: 2.469998522821106

Epoch: 5| Step: 5
Training loss: 2.0779150376339954
Validation loss: 2.46534849984777

Epoch: 5| Step: 6
Training loss: 2.69974743403537
Validation loss: 2.460266605137939

Epoch: 5| Step: 7
Training loss: 2.393351278140376
Validation loss: 2.4635877436925173

Epoch: 5| Step: 8
Training loss: 2.2929288220544075
Validation loss: 2.470358690621811

Epoch: 5| Step: 9
Training loss: 2.216758478983285
Validation loss: 2.471174148472175

Epoch: 5| Step: 10
Training loss: 2.3200507738871377
Validation loss: 2.4738475507058535

Epoch: 5| Step: 11
Training loss: 2.142382269421141
Validation loss: 2.48520789989662

Epoch: 195| Step: 0
Training loss: 2.251172078344603
Validation loss: 2.470029732632031

Epoch: 5| Step: 1
Training loss: 1.9671539012896915
Validation loss: 2.4821866952266554

Epoch: 5| Step: 2
Training loss: 2.350805014847993
Validation loss: 2.4747093419349397

Epoch: 5| Step: 3
Training loss: 2.407900058706446
Validation loss: 2.473422236665569

Epoch: 5| Step: 4
Training loss: 2.669251252389435
Validation loss: 2.459726586712838

Epoch: 5| Step: 5
Training loss: 2.3952357887680216
Validation loss: 2.467178278997003

Epoch: 5| Step: 6
Training loss: 2.4967114754268906
Validation loss: 2.4676116660880414

Epoch: 5| Step: 7
Training loss: 2.7528147597341004
Validation loss: 2.47100416920201

Epoch: 5| Step: 8
Training loss: 2.8335754814642353
Validation loss: 2.4678998642280283

Epoch: 5| Step: 9
Training loss: 2.689765330292488
Validation loss: 2.4636370752635997

Epoch: 5| Step: 10
Training loss: 2.363272372142416
Validation loss: 2.471726421998043

Epoch: 5| Step: 11
Training loss: 3.317663235360352
Validation loss: 2.471643016296472

Epoch: 196| Step: 0
Training loss: 2.352967815038008
Validation loss: 2.4654098118690024

Epoch: 5| Step: 1
Training loss: 2.423468674558213
Validation loss: 2.4680134402812817

Epoch: 5| Step: 2
Training loss: 2.6469559478091687
Validation loss: 2.4634571235672307

Epoch: 5| Step: 3
Training loss: 2.883201180077416
Validation loss: 2.4652888968639326

Epoch: 5| Step: 4
Training loss: 2.3359165764831626
Validation loss: 2.4695549751066497

Epoch: 5| Step: 5
Training loss: 2.812187770890546
Validation loss: 2.472560095260833

Epoch: 5| Step: 6
Training loss: 2.071391619742652
Validation loss: 2.463705413623945

Epoch: 5| Step: 7
Training loss: 2.690675057578007
Validation loss: 2.459768419252549

Epoch: 5| Step: 8
Training loss: 2.3363386849459875
Validation loss: 2.4590624452720937

Epoch: 5| Step: 9
Training loss: 2.2892172699251025
Validation loss: 2.465096113663434

Epoch: 5| Step: 10
Training loss: 2.369483564420852
Validation loss: 2.475577402194205

Epoch: 5| Step: 11
Training loss: 3.59045072951016
Validation loss: 2.4811623191875696

Epoch: 197| Step: 0
Training loss: 2.1095904204960108
Validation loss: 2.4780726677017815

Epoch: 5| Step: 1
Training loss: 2.6018658252108047
Validation loss: 2.4846146026167064

Epoch: 5| Step: 2
Training loss: 1.8552107139656375
Validation loss: 2.477034815566309

Epoch: 5| Step: 3
Training loss: 2.1478652469413797
Validation loss: 2.489546493566285

Epoch: 5| Step: 4
Training loss: 2.670186183881528
Validation loss: 2.4815203462556106

Epoch: 5| Step: 5
Training loss: 2.463915957082728
Validation loss: 2.4740131084334633

Epoch: 5| Step: 6
Training loss: 2.9258941913802747
Validation loss: 2.4778648265545167

Epoch: 5| Step: 7
Training loss: 1.9233216214388114
Validation loss: 2.460116502770458

Epoch: 5| Step: 8
Training loss: 2.668556874633152
Validation loss: 2.4667268945992

Epoch: 5| Step: 9
Training loss: 2.880663559287874
Validation loss: 2.462468372503325

Epoch: 5| Step: 10
Training loss: 2.866458311567277
Validation loss: 2.455156064572964

Epoch: 5| Step: 11
Training loss: 2.160081858673285
Validation loss: 2.446558889608155

Epoch: 198| Step: 0
Training loss: 2.6251336926520286
Validation loss: 2.453042905693261

Epoch: 5| Step: 1
Training loss: 2.3943395740155617
Validation loss: 2.4482003122042033

Epoch: 5| Step: 2
Training loss: 1.9560045301583844
Validation loss: 2.4493279075329712

Epoch: 5| Step: 3
Training loss: 2.3704582757952894
Validation loss: 2.443827347698043

Epoch: 5| Step: 4
Training loss: 2.8345146708368705
Validation loss: 2.4570090611784594

Epoch: 5| Step: 5
Training loss: 2.6543306484698266
Validation loss: 2.4512871541630044

Epoch: 5| Step: 6
Training loss: 2.455634807393293
Validation loss: 2.4515348310106595

Epoch: 5| Step: 7
Training loss: 2.674709935371087
Validation loss: 2.4495350837746463

Epoch: 5| Step: 8
Training loss: 2.8333822881919835
Validation loss: 2.4543747077568057

Epoch: 5| Step: 9
Training loss: 2.3392838714159714
Validation loss: 2.4490886696277276

Epoch: 5| Step: 10
Training loss: 2.175953938669863
Validation loss: 2.458615979147788

Epoch: 5| Step: 11
Training loss: 2.530368039045882
Validation loss: 2.4500106553410412

Epoch: 199| Step: 0
Training loss: 2.225087852029503
Validation loss: 2.4471909211476275

Epoch: 5| Step: 1
Training loss: 1.9111167817376653
Validation loss: 2.4426732348839804

Epoch: 5| Step: 2
Training loss: 2.7185425076286176
Validation loss: 2.46396382258638

Epoch: 5| Step: 3
Training loss: 2.7575485492212564
Validation loss: 2.458709794384686

Epoch: 5| Step: 4
Training loss: 2.5252443818529393
Validation loss: 2.461291789230784

Epoch: 5| Step: 5
Training loss: 1.926002907522033
Validation loss: 2.467709438720387

Epoch: 5| Step: 6
Training loss: 3.2959392358585995
Validation loss: 2.465937299817416

Epoch: 5| Step: 7
Training loss: 2.315583724710687
Validation loss: 2.4815530484614445

Epoch: 5| Step: 8
Training loss: 2.002528499633826
Validation loss: 2.475423954285872

Epoch: 5| Step: 9
Training loss: 2.8247115468984
Validation loss: 2.4551377796258516

Epoch: 5| Step: 10
Training loss: 2.3976203445923163
Validation loss: 2.4622995795262037

Epoch: 5| Step: 11
Training loss: 2.869446075363492
Validation loss: 2.463617683888433

Epoch: 200| Step: 0
Training loss: 1.9534347288593854
Validation loss: 2.460888933782361

Epoch: 5| Step: 1
Training loss: 2.8483723392870064
Validation loss: 2.4684729320035474

Epoch: 5| Step: 2
Training loss: 2.352795147922394
Validation loss: 2.457690507820324

Epoch: 5| Step: 3
Training loss: 2.2617851603349135
Validation loss: 2.4636904199113037

Epoch: 5| Step: 4
Training loss: 2.565409613430217
Validation loss: 2.4641571539560956

Epoch: 5| Step: 5
Training loss: 2.1223881321554745
Validation loss: 2.4585331226781517

Epoch: 5| Step: 6
Training loss: 2.8422389784434903
Validation loss: 2.4610965414981796

Epoch: 5| Step: 7
Training loss: 2.764566596142704
Validation loss: 2.4641564726422476

Epoch: 5| Step: 8
Training loss: 2.417908207099977
Validation loss: 2.4618572756653894

Epoch: 5| Step: 9
Training loss: 2.4165114539277712
Validation loss: 2.470377333399718

Epoch: 5| Step: 10
Training loss: 2.515725175272772
Validation loss: 2.469936878263954

Epoch: 5| Step: 11
Training loss: 3.1279304497247744
Validation loss: 2.4641615885386705

Epoch: 201| Step: 0
Training loss: 2.3973300626192846
Validation loss: 2.476501030866076

Epoch: 5| Step: 1
Training loss: 2.4672617228905254
Validation loss: 2.485179670843693

Epoch: 5| Step: 2
Training loss: 2.685873737210811
Validation loss: 2.468869214459038

Epoch: 5| Step: 3
Training loss: 2.4006867936058742
Validation loss: 2.472851159487641

Epoch: 5| Step: 4
Training loss: 2.7386020793517156
Validation loss: 2.473564868891972

Epoch: 5| Step: 5
Training loss: 2.728163284784704
Validation loss: 2.478289979443473

Epoch: 5| Step: 6
Training loss: 2.6754286485003766
Validation loss: 2.4617023752778273

Epoch: 5| Step: 7
Training loss: 2.7419664777491533
Validation loss: 2.4740376924870175

Epoch: 5| Step: 8
Training loss: 1.7564574041112626
Validation loss: 2.4610398851521302

Epoch: 5| Step: 9
Training loss: 2.3186989256793944
Validation loss: 2.467836098176719

Epoch: 5| Step: 10
Training loss: 2.5151998978153722
Validation loss: 2.459174090544111

Epoch: 5| Step: 11
Training loss: 1.433815255579947
Validation loss: 2.4634943239100062

Epoch: 202| Step: 0
Training loss: 2.4691001547194564
Validation loss: 2.461395269536638

Epoch: 5| Step: 1
Training loss: 2.2180428251048316
Validation loss: 2.465441083797377

Epoch: 5| Step: 2
Training loss: 2.025857663727055
Validation loss: 2.470920775304527

Epoch: 5| Step: 3
Training loss: 2.5610781190539607
Validation loss: 2.472602204851579

Epoch: 5| Step: 4
Training loss: 2.140528321693427
Validation loss: 2.472621342963513

Epoch: 5| Step: 5
Training loss: 2.303977210296401
Validation loss: 2.4644260969547727

Epoch: 5| Step: 6
Training loss: 3.231784391208257
Validation loss: 2.467168840849533

Epoch: 5| Step: 7
Training loss: 3.0195044038869647
Validation loss: 2.4697932521815518

Epoch: 5| Step: 8
Training loss: 2.079171971051235
Validation loss: 2.456630971352487

Epoch: 5| Step: 9
Training loss: 2.5025614014675512
Validation loss: 2.4627135997440854

Epoch: 5| Step: 10
Training loss: 2.7016227825757384
Validation loss: 2.4612394198139724

Epoch: 5| Step: 11
Training loss: 1.0821345310978991
Validation loss: 2.4641433260700993

Epoch: 203| Step: 0
Training loss: 2.8643959862682924
Validation loss: 2.4630988222357444

Epoch: 5| Step: 1
Training loss: 2.671706523379825
Validation loss: 2.469811641805942

Epoch: 5| Step: 2
Training loss: 1.9608607790099286
Validation loss: 2.45907709352409

Epoch: 5| Step: 3
Training loss: 2.3913706694893713
Validation loss: 2.4549177669250444

Epoch: 5| Step: 4
Training loss: 2.755928065730128
Validation loss: 2.46464900533632

Epoch: 5| Step: 5
Training loss: 2.248265975761345
Validation loss: 2.4553180052375225

Epoch: 5| Step: 6
Training loss: 2.3157749184123664
Validation loss: 2.4530744081694587

Epoch: 5| Step: 7
Training loss: 2.576686388395108
Validation loss: 2.4631184032203106

Epoch: 5| Step: 8
Training loss: 2.152641483490763
Validation loss: 2.465128004124203

Epoch: 5| Step: 9
Training loss: 2.6187121149568404
Validation loss: 2.463744594020322

Epoch: 5| Step: 10
Training loss: 2.534224657898194
Validation loss: 2.4631822147740348

Epoch: 5| Step: 11
Training loss: 2.4307969678848886
Validation loss: 2.459713792065472

Epoch: 204| Step: 0
Training loss: 2.2420857369859544
Validation loss: 2.4671899880478634

Epoch: 5| Step: 1
Training loss: 2.796436893525222
Validation loss: 2.467822129886654

Epoch: 5| Step: 2
Training loss: 2.7386996701872746
Validation loss: 2.4717856426782174

Epoch: 5| Step: 3
Training loss: 1.967754415036777
Validation loss: 2.4729480340238226

Epoch: 5| Step: 4
Training loss: 2.6850466508559863
Validation loss: 2.4791936185050307

Epoch: 5| Step: 5
Training loss: 2.2573835235997515
Validation loss: 2.474251994054301

Epoch: 5| Step: 6
Training loss: 2.3071135602168193
Validation loss: 2.482637689644999

Epoch: 5| Step: 7
Training loss: 2.245140550117679
Validation loss: 2.4702952333474615

Epoch: 5| Step: 8
Training loss: 2.2395040690271606
Validation loss: 2.476911040929528

Epoch: 5| Step: 9
Training loss: 2.6300822514193274
Validation loss: 2.469725210989646

Epoch: 5| Step: 10
Training loss: 2.779264620113256
Validation loss: 2.4660570651670923

Epoch: 5| Step: 11
Training loss: 3.1848014927779844
Validation loss: 2.470336947238698

Epoch: 205| Step: 0
Training loss: 2.1779239862802027
Validation loss: 2.468494224979949

Epoch: 5| Step: 1
Training loss: 2.205332198258415
Validation loss: 2.4642670607173462

Epoch: 5| Step: 2
Training loss: 2.5316958564580645
Validation loss: 2.4572429919519228

Epoch: 5| Step: 3
Training loss: 2.018560829393172
Validation loss: 2.464673185013917

Epoch: 5| Step: 4
Training loss: 2.469298675987356
Validation loss: 2.469822027136996

Epoch: 5| Step: 5
Training loss: 2.0945442173694078
Validation loss: 2.4624281249069937

Epoch: 5| Step: 6
Training loss: 2.809518293178275
Validation loss: 2.4721255262683286

Epoch: 5| Step: 7
Training loss: 3.0121059935665433
Validation loss: 2.4729828219628907

Epoch: 5| Step: 8
Training loss: 2.6050934528420995
Validation loss: 2.470375304657305

Epoch: 5| Step: 9
Training loss: 2.492444637988475
Validation loss: 2.478585933873457

Epoch: 5| Step: 10
Training loss: 2.5621424169630043
Validation loss: 2.4625820155129294

Epoch: 5| Step: 11
Training loss: 2.5636160676326165
Validation loss: 2.4739724342881275

Epoch: 206| Step: 0
Training loss: 2.118855512574301
Validation loss: 2.4768268632635086

Epoch: 5| Step: 1
Training loss: 2.0581217447273095
Validation loss: 2.476634565040954

Epoch: 5| Step: 2
Training loss: 2.257355534862133
Validation loss: 2.4739786020084424

Epoch: 5| Step: 3
Training loss: 2.5635455719877895
Validation loss: 2.4751185831888667

Epoch: 5| Step: 4
Training loss: 2.06487692071292
Validation loss: 2.480131976476816

Epoch: 5| Step: 5
Training loss: 2.365425688033321
Validation loss: 2.4749510101967145

Epoch: 5| Step: 6
Training loss: 2.514983575209874
Validation loss: 2.478995282529646

Epoch: 5| Step: 7
Training loss: 3.0230029678557298
Validation loss: 2.47716123080402

Epoch: 5| Step: 8
Training loss: 2.2743928874738852
Validation loss: 2.4828080648002917

Epoch: 5| Step: 9
Training loss: 2.8260742676810486
Validation loss: 2.484509522416794

Epoch: 5| Step: 10
Training loss: 2.8030072547908533
Validation loss: 2.481606452330727

Epoch: 5| Step: 11
Training loss: 3.143856985649287
Validation loss: 2.4797961346859694

Epoch: 207| Step: 0
Training loss: 1.8418184928393964
Validation loss: 2.479999587978052

Epoch: 5| Step: 1
Training loss: 2.3286457887389447
Validation loss: 2.4819650457284186

Epoch: 5| Step: 2
Training loss: 2.80872888995982
Validation loss: 2.4823406215188673

Epoch: 5| Step: 3
Training loss: 2.3195884936506967
Validation loss: 2.4873384758729036

Epoch: 5| Step: 4
Training loss: 2.128909945703501
Validation loss: 2.4844379497046343

Epoch: 5| Step: 5
Training loss: 2.6976552318634046
Validation loss: 2.482606310211995

Epoch: 5| Step: 6
Training loss: 1.8721254566490328
Validation loss: 2.485889908618563

Epoch: 5| Step: 7
Training loss: 2.4272022354623637
Validation loss: 2.478620498398428

Epoch: 5| Step: 8
Training loss: 2.8093148739568434
Validation loss: 2.4804632151784745

Epoch: 5| Step: 9
Training loss: 2.5793542878946405
Validation loss: 2.482892455791545

Epoch: 5| Step: 10
Training loss: 2.8372554186302783
Validation loss: 2.4821454246131345

Epoch: 5| Step: 11
Training loss: 2.9518717372083914
Validation loss: 2.4789907222044327

Epoch: 208| Step: 0
Training loss: 2.53229265755671
Validation loss: 2.4821751929931395

Epoch: 5| Step: 1
Training loss: 3.0404507719426155
Validation loss: 2.4717870131569706

Epoch: 5| Step: 2
Training loss: 2.1479693648357627
Validation loss: 2.477179962746026

Epoch: 5| Step: 3
Training loss: 2.318699336976532
Validation loss: 2.4808032473605426

Epoch: 5| Step: 4
Training loss: 2.4169694009342546
Validation loss: 2.4851356457524987

Epoch: 5| Step: 5
Training loss: 2.2118640481376444
Validation loss: 2.482521509331535

Epoch: 5| Step: 6
Training loss: 2.7242490031053346
Validation loss: 2.471330432891773

Epoch: 5| Step: 7
Training loss: 2.398067781363757
Validation loss: 2.4781016551934965

Epoch: 5| Step: 8
Training loss: 2.313657316374295
Validation loss: 2.4684371750045777

Epoch: 5| Step: 9
Training loss: 2.464051519839944
Validation loss: 2.4837859873027583

Epoch: 5| Step: 10
Training loss: 2.5961684017371103
Validation loss: 2.4873526580661895

Epoch: 5| Step: 11
Training loss: 0.7159213089829236
Validation loss: 2.473394997690034

Epoch: 209| Step: 0
Training loss: 2.5832495419439
Validation loss: 2.4819899372572585

Epoch: 5| Step: 1
Training loss: 2.422151217552471
Validation loss: 2.4854563473019735

Epoch: 5| Step: 2
Training loss: 2.6808379347926445
Validation loss: 2.4858777321744383

Epoch: 5| Step: 3
Training loss: 1.931081044729158
Validation loss: 2.494382869912272

Epoch: 5| Step: 4
Training loss: 2.726187518985419
Validation loss: 2.484477047053988

Epoch: 5| Step: 5
Training loss: 2.64941298262971
Validation loss: 2.4919039845014788

Epoch: 5| Step: 6
Training loss: 2.5661541076076664
Validation loss: 2.4849270621097577

Epoch: 5| Step: 7
Training loss: 2.120072204871718
Validation loss: 2.476132091742829

Epoch: 5| Step: 8
Training loss: 2.6588397696638
Validation loss: 2.487136609484689

Epoch: 5| Step: 9
Training loss: 2.1261353545142256
Validation loss: 2.4731786315716033

Epoch: 5| Step: 10
Training loss: 2.6163370601131617
Validation loss: 2.4851152408865476

Epoch: 5| Step: 11
Training loss: 2.843527984336549
Validation loss: 2.4785513327942006

Epoch: 210| Step: 0
Training loss: 3.008339417117687
Validation loss: 2.4745329072534066

Epoch: 5| Step: 1
Training loss: 2.7983328147404523
Validation loss: 2.4881605381532963

Epoch: 5| Step: 2
Training loss: 2.3696703086771738
Validation loss: 2.4823124398981635

Epoch: 5| Step: 3
Training loss: 2.0537591149469754
Validation loss: 2.4740913489203527

Epoch: 5| Step: 4
Training loss: 2.510145296701563
Validation loss: 2.485219040330965

Epoch: 5| Step: 5
Training loss: 1.9232127178371448
Validation loss: 2.477850974936443

Epoch: 5| Step: 6
Training loss: 2.397216684986535
Validation loss: 2.4758962743940383

Epoch: 5| Step: 7
Training loss: 2.3405485540519155
Validation loss: 2.480658216073845

Epoch: 5| Step: 8
Training loss: 2.285936219220901
Validation loss: 2.4874996073481315

Epoch: 5| Step: 9
Training loss: 2.6632173601601683
Validation loss: 2.4942744136287294

Epoch: 5| Step: 10
Training loss: 2.4941762803650027
Validation loss: 2.4996419133590537

Epoch: 5| Step: 11
Training loss: 2.608671173381674
Validation loss: 2.4903255151762864

Epoch: 211| Step: 0
Training loss: 2.750689593464429
Validation loss: 2.489267186850207

Epoch: 5| Step: 1
Training loss: 2.7080301750902294
Validation loss: 2.4889497043733257

Epoch: 5| Step: 2
Training loss: 2.2690689745423054
Validation loss: 2.495900412779453

Epoch: 5| Step: 3
Training loss: 1.9800294166845802
Validation loss: 2.485834668564403

Epoch: 5| Step: 4
Training loss: 2.440900142854118
Validation loss: 2.4875723019991582

Epoch: 5| Step: 5
Training loss: 2.1620605242688757
Validation loss: 2.4722001115534087

Epoch: 5| Step: 6
Training loss: 2.4488983674836153
Validation loss: 2.472516180955572

Epoch: 5| Step: 7
Training loss: 2.66587056753953
Validation loss: 2.4809481900858508

Epoch: 5| Step: 8
Training loss: 2.4934551399315517
Validation loss: 2.47550679518619

Epoch: 5| Step: 9
Training loss: 2.805238717404848
Validation loss: 2.477159927463029

Epoch: 5| Step: 10
Training loss: 2.2249045105063683
Validation loss: 2.4779168245571976

Epoch: 5| Step: 11
Training loss: 2.999466530734114
Validation loss: 2.4798961829623494

Epoch: 212| Step: 0
Training loss: 2.4561735029660188
Validation loss: 2.492292443819304

Epoch: 5| Step: 1
Training loss: 2.233907370550031
Validation loss: 2.490790590487662

Epoch: 5| Step: 2
Training loss: 2.2858412017668295
Validation loss: 2.4815329884374493

Epoch: 5| Step: 3
Training loss: 2.6725854654090617
Validation loss: 2.4956368001723694

Epoch: 5| Step: 4
Training loss: 2.559279674575984
Validation loss: 2.4970773819380865

Epoch: 5| Step: 5
Training loss: 1.81686074098097
Validation loss: 2.4875805485525913

Epoch: 5| Step: 6
Training loss: 2.3129365869744443
Validation loss: 2.4985925089973167

Epoch: 5| Step: 7
Training loss: 2.756863871266335
Validation loss: 2.5261572519711537

Epoch: 5| Step: 8
Training loss: 2.9926341547648514
Validation loss: 2.5035441231480773

Epoch: 5| Step: 9
Training loss: 1.8248581347783313
Validation loss: 2.498707047539044

Epoch: 5| Step: 10
Training loss: 2.984535732234966
Validation loss: 2.4810742177442067

Epoch: 5| Step: 11
Training loss: 2.320044094192829
Validation loss: 2.4835181168052283

Epoch: 213| Step: 0
Training loss: 2.132423002008999
Validation loss: 2.483453195727987

Epoch: 5| Step: 1
Training loss: 3.0373511509471793
Validation loss: 2.4794176092221574

Epoch: 5| Step: 2
Training loss: 2.778032477675789
Validation loss: 2.48424085818729

Epoch: 5| Step: 3
Training loss: 2.405763056642235
Validation loss: 2.4836821239676308

Epoch: 5| Step: 4
Training loss: 3.095334350570434
Validation loss: 2.483106429232786

Epoch: 5| Step: 5
Training loss: 2.6274174956953056
Validation loss: 2.4740484134269356

Epoch: 5| Step: 6
Training loss: 1.9085108373232833
Validation loss: 2.472603703443206

Epoch: 5| Step: 7
Training loss: 2.234628516266829
Validation loss: 2.479299346728666

Epoch: 5| Step: 8
Training loss: 2.39078915101006
Validation loss: 2.476641957545681

Epoch: 5| Step: 9
Training loss: 2.3895210260207307
Validation loss: 2.4699991542606217

Epoch: 5| Step: 10
Training loss: 2.149141175600983
Validation loss: 2.4779373307940955

Epoch: 5| Step: 11
Training loss: 2.5068308016966285
Validation loss: 2.48564092504234

Epoch: 214| Step: 0
Training loss: 2.296432660126113
Validation loss: 2.4908947476685683

Epoch: 5| Step: 1
Training loss: 2.189670684649716
Validation loss: 2.4938856615406473

Epoch: 5| Step: 2
Training loss: 2.6754861265167484
Validation loss: 2.4975801478773723

Epoch: 5| Step: 3
Training loss: 2.7315713514449276
Validation loss: 2.489319984255259

Epoch: 5| Step: 4
Training loss: 2.445448801550222
Validation loss: 2.489513481362595

Epoch: 5| Step: 5
Training loss: 2.6994215451586654
Validation loss: 2.4794306066938305

Epoch: 5| Step: 6
Training loss: 2.239758601464558
Validation loss: 2.4776150605691494

Epoch: 5| Step: 7
Training loss: 2.740838656475882
Validation loss: 2.4884539254327613

Epoch: 5| Step: 8
Training loss: 2.550203734094236
Validation loss: 2.4760786520496305

Epoch: 5| Step: 9
Training loss: 1.8443883663612248
Validation loss: 2.480477825158206

Epoch: 5| Step: 10
Training loss: 2.4360717110061745
Validation loss: 2.4778043278904867

Epoch: 5| Step: 11
Training loss: 3.034908171620429
Validation loss: 2.4832824887974057

Epoch: 215| Step: 0
Training loss: 2.8301404652597344
Validation loss: 2.493223108672483

Epoch: 5| Step: 1
Training loss: 2.6756874235089523
Validation loss: 2.48877713119507

Epoch: 5| Step: 2
Training loss: 2.9683744494164213
Validation loss: 2.4919734173288637

Epoch: 5| Step: 3
Training loss: 2.1548543642756446
Validation loss: 2.511217113689049

Epoch: 5| Step: 4
Training loss: 2.466255376223134
Validation loss: 2.515961462625461

Epoch: 5| Step: 5
Training loss: 2.1330418725390468
Validation loss: 2.511659458344546

Epoch: 5| Step: 6
Training loss: 2.0477470112945166
Validation loss: 2.511102674994275

Epoch: 5| Step: 7
Training loss: 2.1988405813845966
Validation loss: 2.4960740436379005

Epoch: 5| Step: 8
Training loss: 2.8995576323813563
Validation loss: 2.497944692311836

Epoch: 5| Step: 9
Training loss: 2.494854591122931
Validation loss: 2.4879346732929304

Epoch: 5| Step: 10
Training loss: 2.179153978688907
Validation loss: 2.466565948655328

Epoch: 5| Step: 11
Training loss: 1.6109718622488853
Validation loss: 2.4757632982673132

Epoch: 216| Step: 0
Training loss: 2.600412475439124
Validation loss: 2.486182576903985

Epoch: 5| Step: 1
Training loss: 2.6846589441193895
Validation loss: 2.4778363975783413

Epoch: 5| Step: 2
Training loss: 2.49467014555669
Validation loss: 2.471897951092693

Epoch: 5| Step: 3
Training loss: 2.6690306218928637
Validation loss: 2.4705506449855212

Epoch: 5| Step: 4
Training loss: 2.604688810772672
Validation loss: 2.4743260675814227

Epoch: 5| Step: 5
Training loss: 2.584037336180139
Validation loss: 2.4694463496230044

Epoch: 5| Step: 6
Training loss: 1.524764358575491
Validation loss: 2.472138489747047

Epoch: 5| Step: 7
Training loss: 2.5469985651102807
Validation loss: 2.476882171857912

Epoch: 5| Step: 8
Training loss: 2.480172111014949
Validation loss: 2.479421848232428

Epoch: 5| Step: 9
Training loss: 2.608070915679748
Validation loss: 2.476901720082392

Epoch: 5| Step: 10
Training loss: 2.7166379420004167
Validation loss: 2.466458093732484

Epoch: 5| Step: 11
Training loss: 1.3208315128269745
Validation loss: 2.482085782721682

Epoch: 217| Step: 0
Training loss: 2.794543781204431
Validation loss: 2.4796041468628855

Epoch: 5| Step: 1
Training loss: 2.1848635453273597
Validation loss: 2.4888182838559025

Epoch: 5| Step: 2
Training loss: 2.188876127904022
Validation loss: 2.4812050515050417

Epoch: 5| Step: 3
Training loss: 2.8413461439159255
Validation loss: 2.49414804926011

Epoch: 5| Step: 4
Training loss: 2.3615940597381937
Validation loss: 2.51443432732794

Epoch: 5| Step: 5
Training loss: 2.077562528511594
Validation loss: 2.505457853129613

Epoch: 5| Step: 6
Training loss: 2.1614111347483864
Validation loss: 2.523380188345262

Epoch: 5| Step: 7
Training loss: 2.3945409080721314
Validation loss: 2.5191916145665063

Epoch: 5| Step: 8
Training loss: 2.9057122830323614
Validation loss: 2.523949298587949

Epoch: 5| Step: 9
Training loss: 2.2785259338804917
Validation loss: 2.518977389708535

Epoch: 5| Step: 10
Training loss: 2.6800248626011207
Validation loss: 2.503855493976345

Epoch: 5| Step: 11
Training loss: 3.458996781898274
Validation loss: 2.4896636707852076

Epoch: 218| Step: 0
Training loss: 2.0691073382758876
Validation loss: 2.483892573894711

Epoch: 5| Step: 1
Training loss: 2.6672716249273485
Validation loss: 2.4668967497866876

Epoch: 5| Step: 2
Training loss: 2.78848884731044
Validation loss: 2.4682320985107866

Epoch: 5| Step: 3
Training loss: 2.6396726437106914
Validation loss: 2.4700306777683494

Epoch: 5| Step: 4
Training loss: 2.772768095656844
Validation loss: 2.4688896751326257

Epoch: 5| Step: 5
Training loss: 2.2844154656997
Validation loss: 2.4738218905652807

Epoch: 5| Step: 6
Training loss: 2.4499797703433295
Validation loss: 2.4664589959329595

Epoch: 5| Step: 7
Training loss: 2.8331476786505445
Validation loss: 2.475245393282379

Epoch: 5| Step: 8
Training loss: 2.8611671376426733
Validation loss: 2.4749037264713794

Epoch: 5| Step: 9
Training loss: 2.3753121823377263
Validation loss: 2.4739660175940315

Epoch: 5| Step: 10
Training loss: 2.0492670190953053
Validation loss: 2.474789314582538

Epoch: 5| Step: 11
Training loss: 1.2098753177623882
Validation loss: 2.4778679617001624

Epoch: 219| Step: 0
Training loss: 2.5884881017248267
Validation loss: 2.4722848686634196

Epoch: 5| Step: 1
Training loss: 1.8890567296699634
Validation loss: 2.4766059735290167

Epoch: 5| Step: 2
Training loss: 2.452399468495329
Validation loss: 2.469680932527106

Epoch: 5| Step: 3
Training loss: 2.2662270633906565
Validation loss: 2.4665198796055825

Epoch: 5| Step: 4
Training loss: 3.5414931011679407
Validation loss: 2.465306540367675

Epoch: 5| Step: 5
Training loss: 1.689612867267337
Validation loss: 2.4654762174022333

Epoch: 5| Step: 6
Training loss: 3.085878473031202
Validation loss: 2.4600773069916677

Epoch: 5| Step: 7
Training loss: 2.447106431561598
Validation loss: 2.4667175936650394

Epoch: 5| Step: 8
Training loss: 2.108226548256134
Validation loss: 2.460383567835065

Epoch: 5| Step: 9
Training loss: 2.8859538508986247
Validation loss: 2.4631392625448862

Epoch: 5| Step: 10
Training loss: 2.569577468544548
Validation loss: 2.469502788968213

Epoch: 5| Step: 11
Training loss: 1.2419781778417966
Validation loss: 2.477595977069331

Epoch: 220| Step: 0
Training loss: 2.396054453942678
Validation loss: 2.471481920215667

Epoch: 5| Step: 1
Training loss: 2.324798768061701
Validation loss: 2.461657379460448

Epoch: 5| Step: 2
Training loss: 2.506166197024969
Validation loss: 2.4658001204567235

Epoch: 5| Step: 3
Training loss: 2.2689934255774564
Validation loss: 2.472494633330977

Epoch: 5| Step: 4
Training loss: 2.8709465975257578
Validation loss: 2.4772396746279193

Epoch: 5| Step: 5
Training loss: 2.7133611129663353
Validation loss: 2.473334719044005

Epoch: 5| Step: 6
Training loss: 2.9407244901620033
Validation loss: 2.4617335611339906

Epoch: 5| Step: 7
Training loss: 2.2745114441166754
Validation loss: 2.4798158442152327

Epoch: 5| Step: 8
Training loss: 2.2938879402946855
Validation loss: 2.4692424975039806

Epoch: 5| Step: 9
Training loss: 2.254125098540315
Validation loss: 2.472787155535062

Epoch: 5| Step: 10
Training loss: 2.4581082989988325
Validation loss: 2.479261233559066

Epoch: 5| Step: 11
Training loss: 2.473236546212126
Validation loss: 2.4767960479394504

Epoch: 221| Step: 0
Training loss: 2.0915781400065296
Validation loss: 2.4804247354121705

Epoch: 5| Step: 1
Training loss: 1.9188168392903322
Validation loss: 2.48226130636786

Epoch: 5| Step: 2
Training loss: 2.3068155065743925
Validation loss: 2.490372139105736

Epoch: 5| Step: 3
Training loss: 2.976560737829613
Validation loss: 2.4864645593632093

Epoch: 5| Step: 4
Training loss: 2.624208149231296
Validation loss: 2.500308538312252

Epoch: 5| Step: 5
Training loss: 2.5031478137859002
Validation loss: 2.4967973023039876

Epoch: 5| Step: 6
Training loss: 2.6266890042060353
Validation loss: 2.5032220501764364

Epoch: 5| Step: 7
Training loss: 2.517767710387366
Validation loss: 2.488496257090371

Epoch: 5| Step: 8
Training loss: 2.74545519419415
Validation loss: 2.4881349537559374

Epoch: 5| Step: 9
Training loss: 2.1824505974945114
Validation loss: 2.4984329000927294

Epoch: 5| Step: 10
Training loss: 2.2347687060943846
Validation loss: 2.495073180485563

Epoch: 5| Step: 11
Training loss: 2.71428120225517
Validation loss: 2.501777543501297

Epoch: 222| Step: 0
Training loss: 2.374436361790698
Validation loss: 2.5099004172458548

Epoch: 5| Step: 1
Training loss: 2.154954382818534
Validation loss: 2.502798957402264

Epoch: 5| Step: 2
Training loss: 2.1708400098975
Validation loss: 2.5056228704483905

Epoch: 5| Step: 3
Training loss: 2.591924185597781
Validation loss: 2.4985725897521434

Epoch: 5| Step: 4
Training loss: 2.6264243121901636
Validation loss: 2.5140943629124797

Epoch: 5| Step: 5
Training loss: 2.2401528514073448
Validation loss: 2.495535390585607

Epoch: 5| Step: 6
Training loss: 2.6575179720079807
Validation loss: 2.4948366170402814

Epoch: 5| Step: 7
Training loss: 2.486733522649924
Validation loss: 2.4912751779083084

Epoch: 5| Step: 8
Training loss: 3.2020705557679725
Validation loss: 2.4779817864500684

Epoch: 5| Step: 9
Training loss: 2.1527276501579093
Validation loss: 2.4782305654495325

Epoch: 5| Step: 10
Training loss: 2.264039635921258
Validation loss: 2.475841629898652

Epoch: 5| Step: 11
Training loss: 1.6783773591228193
Validation loss: 2.4780625374335306

Epoch: 223| Step: 0
Training loss: 2.377362531825353
Validation loss: 2.472301487836593

Epoch: 5| Step: 1
Training loss: 2.8519039419939007
Validation loss: 2.478120424122893

Epoch: 5| Step: 2
Training loss: 3.063069660377271
Validation loss: 2.4784995004115893

Epoch: 5| Step: 3
Training loss: 2.8932064592286975
Validation loss: 2.4786422011788414

Epoch: 5| Step: 4
Training loss: 2.5008416666385456
Validation loss: 2.4693210762178364

Epoch: 5| Step: 5
Training loss: 2.5290969357207755
Validation loss: 2.4808396169798383

Epoch: 5| Step: 6
Training loss: 2.329847479482064
Validation loss: 2.482330220529107

Epoch: 5| Step: 7
Training loss: 2.051415220088903
Validation loss: 2.490152494792297

Epoch: 5| Step: 8
Training loss: 1.8303695332709229
Validation loss: 2.4975900239728728

Epoch: 5| Step: 9
Training loss: 1.911234358329961
Validation loss: 2.482340425425196

Epoch: 5| Step: 10
Training loss: 2.1936862121176555
Validation loss: 2.4938491854147804

Epoch: 5| Step: 11
Training loss: 2.999432192156008
Validation loss: 2.495825353608619

Epoch: 224| Step: 0
Training loss: 2.266611239746683
Validation loss: 2.5075291902384036

Epoch: 5| Step: 1
Training loss: 2.5857708004237767
Validation loss: 2.507007235876332

Epoch: 5| Step: 2
Training loss: 2.9120514094457333
Validation loss: 2.5159364175847485

Epoch: 5| Step: 3
Training loss: 2.522707618055705
Validation loss: 2.513351420003114

Epoch: 5| Step: 4
Training loss: 2.2666884458654915
Validation loss: 2.500993674211155

Epoch: 5| Step: 5
Training loss: 2.6893217432846908
Validation loss: 2.507537878256876

Epoch: 5| Step: 6
Training loss: 2.4699904789914866
Validation loss: 2.508353978026673

Epoch: 5| Step: 7
Training loss: 2.7623097004656487
Validation loss: 2.495519887498842

Epoch: 5| Step: 8
Training loss: 2.564771436356845
Validation loss: 2.4882275362470287

Epoch: 5| Step: 9
Training loss: 1.85953828751816
Validation loss: 2.482748686904875

Epoch: 5| Step: 10
Training loss: 2.021341659741795
Validation loss: 2.488202515478799

Epoch: 5| Step: 11
Training loss: 1.7426569695284395
Validation loss: 2.482917314017102

Epoch: 225| Step: 0
Training loss: 1.8674665426093993
Validation loss: 2.485655700421102

Epoch: 5| Step: 1
Training loss: 2.3615271245435303
Validation loss: 2.490948356049937

Epoch: 5| Step: 2
Training loss: 2.879668550227175
Validation loss: 2.4893778964929365

Epoch: 5| Step: 3
Training loss: 2.068433722437688
Validation loss: 2.4862020040539554

Epoch: 5| Step: 4
Training loss: 2.6081191827127324
Validation loss: 2.482386519017466

Epoch: 5| Step: 5
Training loss: 2.314185997077816
Validation loss: 2.4860843460026305

Epoch: 5| Step: 6
Training loss: 2.558176254105708
Validation loss: 2.4895734959704607

Epoch: 5| Step: 7
Training loss: 1.822007270316935
Validation loss: 2.486783381772803

Epoch: 5| Step: 8
Training loss: 2.925947971457669
Validation loss: 2.496841008381075

Epoch: 5| Step: 9
Training loss: 2.258675169557572
Validation loss: 2.4949067845128816

Epoch: 5| Step: 10
Training loss: 2.9924988746481604
Validation loss: 2.5084334740551575

Epoch: 5| Step: 11
Training loss: 1.8634965880137313
Validation loss: 2.515291207640044

Epoch: 226| Step: 0
Training loss: 2.521954268825153
Validation loss: 2.5108337326304815

Epoch: 5| Step: 1
Training loss: 2.318257561804505
Validation loss: 2.513716493026316

Epoch: 5| Step: 2
Training loss: 2.2734038360305604
Validation loss: 2.507555242318504

Epoch: 5| Step: 3
Training loss: 2.4165354287478498
Validation loss: 2.5136504786167886

Epoch: 5| Step: 4
Training loss: 2.4348598756362048
Validation loss: 2.50576427633083

Epoch: 5| Step: 5
Training loss: 3.168674000086352
Validation loss: 2.494077478065982

Epoch: 5| Step: 6
Training loss: 2.322027221454411
Validation loss: 2.4892326424544478

Epoch: 5| Step: 7
Training loss: 2.4731047646883106
Validation loss: 2.4908897863822665

Epoch: 5| Step: 8
Training loss: 1.6832114934104603
Validation loss: 2.4834085860040647

Epoch: 5| Step: 9
Training loss: 2.016171640007421
Validation loss: 2.4764226719545253

Epoch: 5| Step: 10
Training loss: 3.1313972606028346
Validation loss: 2.4799090978090605

Epoch: 5| Step: 11
Training loss: 1.989181224938591
Validation loss: 2.4794723111297876

Epoch: 227| Step: 0
Training loss: 2.3653059428040097
Validation loss: 2.4815542814410656

Epoch: 5| Step: 1
Training loss: 1.9612290974871345
Validation loss: 2.488549402181537

Epoch: 5| Step: 2
Training loss: 1.9433544676445578
Validation loss: 2.48484207856891

Epoch: 5| Step: 3
Training loss: 2.8241935929355866
Validation loss: 2.501016950399112

Epoch: 5| Step: 4
Training loss: 2.2221526797327535
Validation loss: 2.487318019184699

Epoch: 5| Step: 5
Training loss: 1.892059223542555
Validation loss: 2.503321392373289

Epoch: 5| Step: 6
Training loss: 3.0270304462374886
Validation loss: 2.494282753523544

Epoch: 5| Step: 7
Training loss: 2.891570725255613
Validation loss: 2.5043686009918633

Epoch: 5| Step: 8
Training loss: 2.259935061104127
Validation loss: 2.4959703195029364

Epoch: 5| Step: 9
Training loss: 2.82517733734668
Validation loss: 2.497415008842565

Epoch: 5| Step: 10
Training loss: 2.4700839145012328
Validation loss: 2.490181967987916

Epoch: 5| Step: 11
Training loss: 2.1457799392526193
Validation loss: 2.491572548344313

Epoch: 228| Step: 0
Training loss: 2.321906264904535
Validation loss: 2.4860929950809427

Epoch: 5| Step: 1
Training loss: 2.092014219531134
Validation loss: 2.483923261186306

Epoch: 5| Step: 2
Training loss: 2.82929942999807
Validation loss: 2.48889276804248

Epoch: 5| Step: 3
Training loss: 1.9273075763723497
Validation loss: 2.486441318745138

Epoch: 5| Step: 4
Training loss: 1.9727316662564074
Validation loss: 2.5002254980431697

Epoch: 5| Step: 5
Training loss: 2.647898031109638
Validation loss: 2.5117886436154855

Epoch: 5| Step: 6
Training loss: 2.4673133243030168
Validation loss: 2.5078467250877203

Epoch: 5| Step: 7
Training loss: 2.637726767676199
Validation loss: 2.4974871941258203

Epoch: 5| Step: 8
Training loss: 2.602194219649045
Validation loss: 2.4969667948566108

Epoch: 5| Step: 9
Training loss: 2.259357913468414
Validation loss: 2.50030592397645

Epoch: 5| Step: 10
Training loss: 2.6129788849623865
Validation loss: 2.487273131301295

Epoch: 5| Step: 11
Training loss: 2.9074678228013116
Validation loss: 2.4954527587582076

Epoch: 229| Step: 0
Training loss: 2.853134934072759
Validation loss: 2.4954911501062647

Epoch: 5| Step: 1
Training loss: 2.0736722351908616
Validation loss: 2.506998833303785

Epoch: 5| Step: 2
Training loss: 2.173767363186634
Validation loss: 2.510547940527163

Epoch: 5| Step: 3
Training loss: 2.820505405073933
Validation loss: 2.508080025542263

Epoch: 5| Step: 4
Training loss: 2.542755164861567
Validation loss: 2.5184595061203527

Epoch: 5| Step: 5
Training loss: 2.872897000945135
Validation loss: 2.51515876208879

Epoch: 5| Step: 6
Training loss: 2.810243930885773
Validation loss: 2.5251406383376045

Epoch: 5| Step: 7
Training loss: 1.9352212857224196
Validation loss: 2.5227025854463334

Epoch: 5| Step: 8
Training loss: 2.3938339736591643
Validation loss: 2.5036058806142734

Epoch: 5| Step: 9
Training loss: 2.2360529434610203
Validation loss: 2.514192651225154

Epoch: 5| Step: 10
Training loss: 1.9365057701578414
Validation loss: 2.509251182861698

Epoch: 5| Step: 11
Training loss: 1.1916760248648162
Validation loss: 2.5030231277303114

Epoch: 230| Step: 0
Training loss: 2.570052577271322
Validation loss: 2.508969393641932

Epoch: 5| Step: 1
Training loss: 2.4854690733823244
Validation loss: 2.514944328010452

Epoch: 5| Step: 2
Training loss: 1.7739533333774185
Validation loss: 2.501958139788257

Epoch: 5| Step: 3
Training loss: 2.2577578000105105
Validation loss: 2.493724267471493

Epoch: 5| Step: 4
Training loss: 2.394603833938903
Validation loss: 2.5031018485063425

Epoch: 5| Step: 5
Training loss: 3.1210558606116927
Validation loss: 2.5097637448631596

Epoch: 5| Step: 6
Training loss: 2.7173868028354677
Validation loss: 2.5021580799022103

Epoch: 5| Step: 7
Training loss: 2.102368281861702
Validation loss: 2.5181643856727605

Epoch: 5| Step: 8
Training loss: 2.3294100703042315
Validation loss: 2.512812936250911

Epoch: 5| Step: 9
Training loss: 2.763351885599487
Validation loss: 2.518691265440533

Epoch: 5| Step: 10
Training loss: 2.258578371875073
Validation loss: 2.510615235438599

Epoch: 5| Step: 11
Training loss: 1.0879838722029413
Validation loss: 2.5196949474374946

Epoch: 231| Step: 0
Training loss: 2.7139007467450966
Validation loss: 2.525801654437881

Epoch: 5| Step: 1
Training loss: 2.1081528125220963
Validation loss: 2.5120842995427948

Epoch: 5| Step: 2
Training loss: 1.8559752726593042
Validation loss: 2.522124757023731

Epoch: 5| Step: 3
Training loss: 2.346956120090993
Validation loss: 2.514898313681148

Epoch: 5| Step: 4
Training loss: 2.585977513675034
Validation loss: 2.5104036977177056

Epoch: 5| Step: 5
Training loss: 2.2579585361441086
Validation loss: 2.507162570416562

Epoch: 5| Step: 6
Training loss: 2.7632204799209013
Validation loss: 2.5131487140170727

Epoch: 5| Step: 7
Training loss: 2.892720220914781
Validation loss: 2.5066919289133516

Epoch: 5| Step: 8
Training loss: 2.36528386789542
Validation loss: 2.495139686398429

Epoch: 5| Step: 9
Training loss: 2.247072646742051
Validation loss: 2.4990779229272118

Epoch: 5| Step: 10
Training loss: 2.2383133118681533
Validation loss: 2.4904637249815065

Epoch: 5| Step: 11
Training loss: 2.8434605713162058
Validation loss: 2.4947130845236236

Epoch: 232| Step: 0
Training loss: 2.737094769031245
Validation loss: 2.4958942156473714

Epoch: 5| Step: 1
Training loss: 1.9963984247588553
Validation loss: 2.498676494104346

Epoch: 5| Step: 2
Training loss: 1.9624216003308435
Validation loss: 2.4827013476205915

Epoch: 5| Step: 3
Training loss: 3.104122153012074
Validation loss: 2.5006896974965294

Epoch: 5| Step: 4
Training loss: 2.023666192169628
Validation loss: 2.5008147124133537

Epoch: 5| Step: 5
Training loss: 2.29960884831641
Validation loss: 2.512592861648325

Epoch: 5| Step: 6
Training loss: 1.77089505555539
Validation loss: 2.510335202036292

Epoch: 5| Step: 7
Training loss: 2.446996139704158
Validation loss: 2.5222482388532126

Epoch: 5| Step: 8
Training loss: 2.940678601480793
Validation loss: 2.5472888610276123

Epoch: 5| Step: 9
Training loss: 2.9306855396372313
Validation loss: 2.545916199363066

Epoch: 5| Step: 10
Training loss: 2.234848932541468
Validation loss: 2.539483564626955

Epoch: 5| Step: 11
Training loss: 2.484543416774528
Validation loss: 2.535570687782757

Epoch: 233| Step: 0
Training loss: 2.591132256298182
Validation loss: 2.5364459322731325

Epoch: 5| Step: 1
Training loss: 2.171932741124875
Validation loss: 2.517447496590869

Epoch: 5| Step: 2
Training loss: 2.5715815880827617
Validation loss: 2.521943434441038

Epoch: 5| Step: 3
Training loss: 2.3586172946135098
Validation loss: 2.505499794409556

Epoch: 5| Step: 4
Training loss: 2.104514845440672
Validation loss: 2.495601388590455

Epoch: 5| Step: 5
Training loss: 2.301624396191746
Validation loss: 2.4968618684629464

Epoch: 5| Step: 6
Training loss: 2.5645736119829543
Validation loss: 2.467893898684099

Epoch: 5| Step: 7
Training loss: 2.2348207682657626
Validation loss: 2.479895722288845

Epoch: 5| Step: 8
Training loss: 2.911428124959749
Validation loss: 2.4759614497890556

Epoch: 5| Step: 9
Training loss: 2.4699858457337363
Validation loss: 2.472643409763964

Epoch: 5| Step: 10
Training loss: 2.4358112647507344
Validation loss: 2.4820260993728773

Epoch: 5| Step: 11
Training loss: 2.4800225284537607
Validation loss: 2.4785860020090107

Epoch: 234| Step: 0
Training loss: 2.390041903523481
Validation loss: 2.4820501738040903

Epoch: 5| Step: 1
Training loss: 2.1401887992215727
Validation loss: 2.488359349261283

Epoch: 5| Step: 2
Training loss: 2.396237237027704
Validation loss: 2.4981504771263485

Epoch: 5| Step: 3
Training loss: 2.803627089970979
Validation loss: 2.501919454585759

Epoch: 5| Step: 4
Training loss: 2.7296932576320216
Validation loss: 2.5118540227602093

Epoch: 5| Step: 5
Training loss: 1.860001274231505
Validation loss: 2.5298900011900396

Epoch: 5| Step: 6
Training loss: 2.6689944438969397
Validation loss: 2.5393694256849586

Epoch: 5| Step: 7
Training loss: 2.005213379956785
Validation loss: 2.528925809803246

Epoch: 5| Step: 8
Training loss: 2.850104473943041
Validation loss: 2.5055997282374363

Epoch: 5| Step: 9
Training loss: 2.323173223676933
Validation loss: 2.4991379682167887

Epoch: 5| Step: 10
Training loss: 2.283962048571023
Validation loss: 2.498078215568738

Epoch: 5| Step: 11
Training loss: 2.2390674322144517
Validation loss: 2.4898185113466154

Epoch: 235| Step: 0
Training loss: 2.564417145150539
Validation loss: 2.48594325728502

Epoch: 5| Step: 1
Training loss: 2.109324023725765
Validation loss: 2.4820679322997057

Epoch: 5| Step: 2
Training loss: 2.6818589734941205
Validation loss: 2.4884631431287025

Epoch: 5| Step: 3
Training loss: 1.597246112736957
Validation loss: 2.504805095574951

Epoch: 5| Step: 4
Training loss: 1.902791873233065
Validation loss: 2.499394844245401

Epoch: 5| Step: 5
Training loss: 2.59319860273468
Validation loss: 2.5202477749741323

Epoch: 5| Step: 6
Training loss: 3.086410602085064
Validation loss: 2.5203389373925194

Epoch: 5| Step: 7
Training loss: 2.5997270404144097
Validation loss: 2.505808880545739

Epoch: 5| Step: 8
Training loss: 2.0538172746483663
Validation loss: 2.491510644118954

Epoch: 5| Step: 9
Training loss: 2.7010429169494663
Validation loss: 2.480663854580319

Epoch: 5| Step: 10
Training loss: 2.6915431991304994
Validation loss: 2.4809978691713614

Epoch: 5| Step: 11
Training loss: 1.8671168868626742
Validation loss: 2.481941758974863

Epoch: 236| Step: 0
Training loss: 2.7479959468284156
Validation loss: 2.4962155785477242

Epoch: 5| Step: 1
Training loss: 2.63822530021228
Validation loss: 2.496192030745359

Epoch: 5| Step: 2
Training loss: 2.5374516938220175
Validation loss: 2.5033172335172584

Epoch: 5| Step: 3
Training loss: 2.1314989453571958
Validation loss: 2.51347255040004

Epoch: 5| Step: 4
Training loss: 2.2460285741223163
Validation loss: 2.5264345997380055

Epoch: 5| Step: 5
Training loss: 2.1916413478573404
Validation loss: 2.516757690339373

Epoch: 5| Step: 6
Training loss: 2.468577994619826
Validation loss: 2.5186966413173657

Epoch: 5| Step: 7
Training loss: 2.258945062233576
Validation loss: 2.500382906677319

Epoch: 5| Step: 8
Training loss: 2.3197072071264584
Validation loss: 2.5322349382451526

Epoch: 5| Step: 9
Training loss: 2.7258721382118045
Validation loss: 2.5097266128615163

Epoch: 5| Step: 10
Training loss: 2.441034932700385
Validation loss: 2.528111442935086

Epoch: 5| Step: 11
Training loss: 1.3766702997299791
Validation loss: 2.5083740294968773

Epoch: 237| Step: 0
Training loss: 3.0795376242327257
Validation loss: 2.504149212408779

Epoch: 5| Step: 1
Training loss: 2.5390219347721095
Validation loss: 2.486636006645238

Epoch: 5| Step: 2
Training loss: 2.6051258507785713
Validation loss: 2.5181821261841226

Epoch: 5| Step: 3
Training loss: 2.444884241402325
Validation loss: 2.504908648203371

Epoch: 5| Step: 4
Training loss: 2.4235788566048617
Validation loss: 2.517763681925252

Epoch: 5| Step: 5
Training loss: 2.277654871945757
Validation loss: 2.5308583274447014

Epoch: 5| Step: 6
Training loss: 2.157057016806668
Validation loss: 2.5215657932916966

Epoch: 5| Step: 7
Training loss: 1.9134892442140297
Validation loss: 2.5133360149538304

Epoch: 5| Step: 8
Training loss: 2.8819196605510373
Validation loss: 2.4989190824563163

Epoch: 5| Step: 9
Training loss: 2.2415830216052726
Validation loss: 2.4988992492975894

Epoch: 5| Step: 10
Training loss: 1.7131538145417804
Validation loss: 2.504283422349566

Epoch: 5| Step: 11
Training loss: 2.103700252495553
Validation loss: 2.493374704183058

Epoch: 238| Step: 0
Training loss: 2.665506458218117
Validation loss: 2.4971326915442185

Epoch: 5| Step: 1
Training loss: 2.357512288228409
Validation loss: 2.5040717107464654

Epoch: 5| Step: 2
Training loss: 2.4335070452238377
Validation loss: 2.501685925087025

Epoch: 5| Step: 3
Training loss: 2.282980171328039
Validation loss: 2.4970667081530133

Epoch: 5| Step: 4
Training loss: 2.6692342814602297
Validation loss: 2.5056831533779302

Epoch: 5| Step: 5
Training loss: 2.0756024416806422
Validation loss: 2.52173357775409

Epoch: 5| Step: 6
Training loss: 2.6162528575402266
Validation loss: 2.526937578866702

Epoch: 5| Step: 7
Training loss: 2.042988939349631
Validation loss: 2.5141672290004378

Epoch: 5| Step: 8
Training loss: 2.7252699622023364
Validation loss: 2.5053453579794343

Epoch: 5| Step: 9
Training loss: 2.238430158045752
Validation loss: 2.524834347632317

Epoch: 5| Step: 10
Training loss: 2.395107579532786
Validation loss: 2.5236213073869727

Epoch: 5| Step: 11
Training loss: 2.283125955209185
Validation loss: 2.5176387490528946

Epoch: 239| Step: 0
Training loss: 2.3530109798371384
Validation loss: 2.520641009557915

Epoch: 5| Step: 1
Training loss: 2.3116415337716094
Validation loss: 2.497571914453368

Epoch: 5| Step: 2
Training loss: 2.9785149846310786
Validation loss: 2.502630228997848

Epoch: 5| Step: 3
Training loss: 2.895092126042611
Validation loss: 2.4961503628880957

Epoch: 5| Step: 4
Training loss: 2.2116528758941643
Validation loss: 2.4853156726096945

Epoch: 5| Step: 5
Training loss: 2.671808431588047
Validation loss: 2.4807788164476405

Epoch: 5| Step: 6
Training loss: 2.31317417524376
Validation loss: 2.4814052345855577

Epoch: 5| Step: 7
Training loss: 2.002372526571531
Validation loss: 2.4879096336075808

Epoch: 5| Step: 8
Training loss: 2.3884530766513365
Validation loss: 2.5008685192805222

Epoch: 5| Step: 9
Training loss: 2.282706644788083
Validation loss: 2.501454768500911

Epoch: 5| Step: 10
Training loss: 2.0544251249051526
Validation loss: 2.525865785958095

Epoch: 5| Step: 11
Training loss: 1.6311235225360046
Validation loss: 2.5399158158957076

Epoch: 240| Step: 0
Training loss: 2.70447572686729
Validation loss: 2.5694779236362226

Epoch: 5| Step: 1
Training loss: 3.094981709366153
Validation loss: 2.5596101406762926

Epoch: 5| Step: 2
Training loss: 2.2908572299118415
Validation loss: 2.56642320028327

Epoch: 5| Step: 3
Training loss: 2.3011211150720574
Validation loss: 2.543863052336608

Epoch: 5| Step: 4
Training loss: 2.220551632400053
Validation loss: 2.526270403124477

Epoch: 5| Step: 5
Training loss: 2.4887468749735135
Validation loss: 2.5073754275353752

Epoch: 5| Step: 6
Training loss: 2.1237789460578873
Validation loss: 2.4934884107037503

Epoch: 5| Step: 7
Training loss: 2.640763950642214
Validation loss: 2.482426881222363

Epoch: 5| Step: 8
Training loss: 2.206272771355794
Validation loss: 2.4828869663832247

Epoch: 5| Step: 9
Training loss: 2.174949391094147
Validation loss: 2.4765132413792923

Epoch: 5| Step: 10
Training loss: 2.336978029937048
Validation loss: 2.489463401576492

Epoch: 5| Step: 11
Training loss: 2.533477462466546
Validation loss: 2.479932019092852

Epoch: 241| Step: 0
Training loss: 2.341017796314747
Validation loss: 2.497525997701158

Epoch: 5| Step: 1
Training loss: 2.463252259582022
Validation loss: 2.5026987172398796

Epoch: 5| Step: 2
Training loss: 2.4137712321441542
Validation loss: 2.528268408116697

Epoch: 5| Step: 3
Training loss: 2.326584479110944
Validation loss: 2.5505726774271062

Epoch: 5| Step: 4
Training loss: 2.3185285395646167
Validation loss: 2.576167679504418

Epoch: 5| Step: 5
Training loss: 2.854681279552011
Validation loss: 2.5695176137065756

Epoch: 5| Step: 6
Training loss: 2.315121376365543
Validation loss: 2.5696002510589775

Epoch: 5| Step: 7
Training loss: 2.100161514428886
Validation loss: 2.529399195188453

Epoch: 5| Step: 8
Training loss: 1.9588397838899931
Validation loss: 2.487004214388686

Epoch: 5| Step: 9
Training loss: 2.705374779254813
Validation loss: 2.480423902371494

Epoch: 5| Step: 10
Training loss: 2.711958371419626
Validation loss: 2.4858684889067657

Epoch: 5| Step: 11
Training loss: 2.6867488432338913
Validation loss: 2.477411912685919

Epoch: 242| Step: 0
Training loss: 2.8482442701361275
Validation loss: 2.502634589453266

Epoch: 5| Step: 1
Training loss: 2.0875386582866695
Validation loss: 2.4933709869202025

Epoch: 5| Step: 2
Training loss: 1.962828313493244
Validation loss: 2.5147155713252403

Epoch: 5| Step: 3
Training loss: 2.8712930415526645
Validation loss: 2.5142769963268914

Epoch: 5| Step: 4
Training loss: 1.9067053329219534
Validation loss: 2.5372826739986407

Epoch: 5| Step: 5
Training loss: 2.1635629235663467
Validation loss: 2.5365484497124826

Epoch: 5| Step: 6
Training loss: 2.2987736749804144
Validation loss: 2.5499102286824322

Epoch: 5| Step: 7
Training loss: 2.3896599111838874
Validation loss: 2.545802157617492

Epoch: 5| Step: 8
Training loss: 2.6889689666954726
Validation loss: 2.5158126792636932

Epoch: 5| Step: 9
Training loss: 3.074382850309688
Validation loss: 2.513754095646098

Epoch: 5| Step: 10
Training loss: 2.0429395742867706
Validation loss: 2.5082567797878155

Epoch: 5| Step: 11
Training loss: 1.7401288789396676
Validation loss: 2.508630615156748

Epoch: 243| Step: 0
Training loss: 2.141522296042187
Validation loss: 2.496467622030145

Epoch: 5| Step: 1
Training loss: 2.440716308761327
Validation loss: 2.4947631146755582

Epoch: 5| Step: 2
Training loss: 2.4217022249674613
Validation loss: 2.4928875122414307

Epoch: 5| Step: 3
Training loss: 1.9887424376300191
Validation loss: 2.5125580053450185

Epoch: 5| Step: 4
Training loss: 2.563525762176676
Validation loss: 2.5006988820084257

Epoch: 5| Step: 5
Training loss: 2.5659671680731604
Validation loss: 2.526355304451683

Epoch: 5| Step: 6
Training loss: 2.2466870395102694
Validation loss: 2.538471145234718

Epoch: 5| Step: 7
Training loss: 2.711152081970369
Validation loss: 2.530672761066476

Epoch: 5| Step: 8
Training loss: 2.2721683066245664
Validation loss: 2.5473086294159186

Epoch: 5| Step: 9
Training loss: 2.2791357825195786
Validation loss: 2.561075031465867

Epoch: 5| Step: 10
Training loss: 2.5182842155259673
Validation loss: 2.5635855902843843

Epoch: 5| Step: 11
Training loss: 3.142639425093554
Validation loss: 2.525833846257568

Epoch: 244| Step: 0
Training loss: 1.7809449988798178
Validation loss: 2.577587957993487

Epoch: 5| Step: 1
Training loss: 2.7365569210311445
Validation loss: 2.6141564462717524

Epoch: 5| Step: 2
Training loss: 2.873599499133604
Validation loss: 2.62423964304063

Epoch: 5| Step: 3
Training loss: 2.672118237226463
Validation loss: 2.605503068704603

Epoch: 5| Step: 4
Training loss: 2.2863046743655753
Validation loss: 2.569897603692837

Epoch: 5| Step: 5
Training loss: 2.5247225014061336
Validation loss: 2.5351480994267415

Epoch: 5| Step: 6
Training loss: 1.9416388942167588
Validation loss: 2.490444255286938

Epoch: 5| Step: 7
Training loss: 2.568760922448171
Validation loss: 2.482258080722036

Epoch: 5| Step: 8
Training loss: 2.5131381994060664
Validation loss: 2.4841850016174414

Epoch: 5| Step: 9
Training loss: 2.666235253087148
Validation loss: 2.4719898235789026

Epoch: 5| Step: 10
Training loss: 2.4900112874951046
Validation loss: 2.4714937254421985

Epoch: 5| Step: 11
Training loss: 3.540938194004833
Validation loss: 2.476462437386229

Epoch: 245| Step: 0
Training loss: 2.5941945809507483
Validation loss: 2.4836793401401023

Epoch: 5| Step: 1
Training loss: 2.028936153950903
Validation loss: 2.4834429994045983

Epoch: 5| Step: 2
Training loss: 2.9128914696864974
Validation loss: 2.486631708022987

Epoch: 5| Step: 3
Training loss: 2.3006002099096188
Validation loss: 2.4773480606482696

Epoch: 5| Step: 4
Training loss: 2.8267742324401754
Validation loss: 2.4800072628666037

Epoch: 5| Step: 5
Training loss: 2.8088251477499138
Validation loss: 2.4805983902502042

Epoch: 5| Step: 6
Training loss: 2.3607997003276537
Validation loss: 2.4845585525330742

Epoch: 5| Step: 7
Training loss: 2.340574020013907
Validation loss: 2.4868809519176676

Epoch: 5| Step: 8
Training loss: 2.194913889036571
Validation loss: 2.4808194731018802

Epoch: 5| Step: 9
Training loss: 2.924551650677914
Validation loss: 2.4822251036557628

Epoch: 5| Step: 10
Training loss: 2.2688573470348126
Validation loss: 2.4849252791143592

Epoch: 5| Step: 11
Training loss: 1.9492573399823265
Validation loss: 2.4829359705260416

Epoch: 246| Step: 0
Training loss: 2.8106359450466685
Validation loss: 2.4785637917233445

Epoch: 5| Step: 1
Training loss: 2.5008823744954523
Validation loss: 2.4958334455240654

Epoch: 5| Step: 2
Training loss: 2.0821904162747615
Validation loss: 2.480613091541866

Epoch: 5| Step: 3
Training loss: 2.460213012621949
Validation loss: 2.4793056654765513

Epoch: 5| Step: 4
Training loss: 1.8745360754188956
Validation loss: 2.4839936089617756

Epoch: 5| Step: 5
Training loss: 2.541253843290516
Validation loss: 2.4913898016505387

Epoch: 5| Step: 6
Training loss: 2.316355815679349
Validation loss: 2.497673529711433

Epoch: 5| Step: 7
Training loss: 2.244591889191315
Validation loss: 2.4864615449270713

Epoch: 5| Step: 8
Training loss: 2.9392847361444647
Validation loss: 2.4878410696583746

Epoch: 5| Step: 9
Training loss: 3.0319269741795916
Validation loss: 2.515109824904092

Epoch: 5| Step: 10
Training loss: 2.045796233835911
Validation loss: 2.4980828205830115

Epoch: 5| Step: 11
Training loss: 2.1566663699417656
Validation loss: 2.5004766168851806

Epoch: 247| Step: 0
Training loss: 2.31667960549819
Validation loss: 2.488103184499369

Epoch: 5| Step: 1
Training loss: 2.5680758591734083
Validation loss: 2.475416267193583

Epoch: 5| Step: 2
Training loss: 2.633379685521105
Validation loss: 2.4837786000625277

Epoch: 5| Step: 3
Training loss: 3.054336410600288
Validation loss: 2.477263875776602

Epoch: 5| Step: 4
Training loss: 2.903750257225206
Validation loss: 2.483731920355371

Epoch: 5| Step: 5
Training loss: 2.141645536306121
Validation loss: 2.4855437298761363

Epoch: 5| Step: 6
Training loss: 1.610398346803729
Validation loss: 2.4854246916938485

Epoch: 5| Step: 7
Training loss: 2.460610891800235
Validation loss: 2.4854104705204647

Epoch: 5| Step: 8
Training loss: 2.262954611444032
Validation loss: 2.496125513072686

Epoch: 5| Step: 9
Training loss: 2.079861711159862
Validation loss: 2.5070466033665126

Epoch: 5| Step: 10
Training loss: 2.2571712229983
Validation loss: 2.5096100874028964

Epoch: 5| Step: 11
Training loss: 2.880990132096143
Validation loss: 2.512924213561491

Epoch: 248| Step: 0
Training loss: 1.9782559826048276
Validation loss: 2.524700541569029

Epoch: 5| Step: 1
Training loss: 2.2432718346580116
Validation loss: 2.5498638518769634

Epoch: 5| Step: 2
Training loss: 3.019182231911036
Validation loss: 2.5690139574560455

Epoch: 5| Step: 3
Training loss: 2.808587892656227
Validation loss: 2.59117291818134

Epoch: 5| Step: 4
Training loss: 2.7977023472699303
Validation loss: 2.5853535702609136

Epoch: 5| Step: 5
Training loss: 2.994379500622792
Validation loss: 2.576873888022755

Epoch: 5| Step: 6
Training loss: 2.3955585709181104
Validation loss: 2.5731919768113825

Epoch: 5| Step: 7
Training loss: 1.9571003244967449
Validation loss: 2.50103586512132

Epoch: 5| Step: 8
Training loss: 2.466226181015791
Validation loss: 2.509622512873405

Epoch: 5| Step: 9
Training loss: 2.040989575379517
Validation loss: 2.4749775657536137

Epoch: 5| Step: 10
Training loss: 2.1925985591227786
Validation loss: 2.4638571963899563

Epoch: 5| Step: 11
Training loss: 2.7627591732191465
Validation loss: 2.4789145198523377

Epoch: 249| Step: 0
Training loss: 2.137139259816924
Validation loss: 2.4702430909982263

Epoch: 5| Step: 1
Training loss: 2.349617391241261
Validation loss: 2.4835813522229424

Epoch: 5| Step: 2
Training loss: 2.1568724245306403
Validation loss: 2.477135007451369

Epoch: 5| Step: 3
Training loss: 2.1720000306510574
Validation loss: 2.4836545695373466

Epoch: 5| Step: 4
Training loss: 2.4746947360351457
Validation loss: 2.4837758643383188

Epoch: 5| Step: 5
Training loss: 3.0869843457773185
Validation loss: 2.490041418640712

Epoch: 5| Step: 6
Training loss: 2.513672064697448
Validation loss: 2.4855677522514616

Epoch: 5| Step: 7
Training loss: 2.7499933242716823
Validation loss: 2.488563844931386

Epoch: 5| Step: 8
Training loss: 2.7919831357517664
Validation loss: 2.4936150515125535

Epoch: 5| Step: 9
Training loss: 2.571304454532833
Validation loss: 2.48763430822268

Epoch: 5| Step: 10
Training loss: 2.2594044494820116
Validation loss: 2.488904295110373

Epoch: 5| Step: 11
Training loss: 1.6704494066931974
Validation loss: 2.495348308133526

Epoch: 250| Step: 0
Training loss: 2.4328840515943617
Validation loss: 2.4923869683971125

Epoch: 5| Step: 1
Training loss: 2.6477217255592658
Validation loss: 2.490635886142605

Epoch: 5| Step: 2
Training loss: 2.4127546304522554
Validation loss: 2.4914506044025244

Epoch: 5| Step: 3
Training loss: 2.9236177357296307
Validation loss: 2.4976269386662886

Epoch: 5| Step: 4
Training loss: 2.160106251363899
Validation loss: 2.4982349005855253

Epoch: 5| Step: 5
Training loss: 1.8757289105429276
Validation loss: 2.509943000670592

Epoch: 5| Step: 6
Training loss: 2.632259412677843
Validation loss: 2.522402906568746

Epoch: 5| Step: 7
Training loss: 2.637662772267812
Validation loss: 2.5286588318186536

Epoch: 5| Step: 8
Training loss: 2.562735756054238
Validation loss: 2.523942379199803

Epoch: 5| Step: 9
Training loss: 2.428272485365593
Validation loss: 2.5181440630276666

Epoch: 5| Step: 10
Training loss: 1.9406480133608657
Validation loss: 2.499770690414972

Epoch: 5| Step: 11
Training loss: 2.5141274869970345
Validation loss: 2.511160982888828

Epoch: 251| Step: 0
Training loss: 2.5439778331354654
Validation loss: 2.4990605198388542

Epoch: 5| Step: 1
Training loss: 2.664981090772008
Validation loss: 2.5069512208357994

Epoch: 5| Step: 2
Training loss: 2.0293293015034375
Validation loss: 2.4975460088219505

Epoch: 5| Step: 3
Training loss: 2.240520003451042
Validation loss: 2.494160284902368

Epoch: 5| Step: 4
Training loss: 2.2951421104430345
Validation loss: 2.4994886988077645

Epoch: 5| Step: 5
Training loss: 2.4605551770850376
Validation loss: 2.4793523163299116

Epoch: 5| Step: 6
Training loss: 2.112582784080256
Validation loss: 2.4964833520170826

Epoch: 5| Step: 7
Training loss: 2.4565380674922532
Validation loss: 2.491629375595476

Epoch: 5| Step: 8
Training loss: 2.4772938511880818
Validation loss: 2.491029743507306

Epoch: 5| Step: 9
Training loss: 2.4420563587555426
Validation loss: 2.4988898594008506

Epoch: 5| Step: 10
Training loss: 2.8157978644107633
Validation loss: 2.4956625942637554

Epoch: 5| Step: 11
Training loss: 2.690117382055259
Validation loss: 2.4979816753358235

Epoch: 252| Step: 0
Training loss: 2.334443804481431
Validation loss: 2.497355234388258

Epoch: 5| Step: 1
Training loss: 2.3956797896125246
Validation loss: 2.5051399599659696

Epoch: 5| Step: 2
Training loss: 2.7871608716007277
Validation loss: 2.5041253821724765

Epoch: 5| Step: 3
Training loss: 2.3511323757247595
Validation loss: 2.5169378491898478

Epoch: 5| Step: 4
Training loss: 2.429579263220435
Validation loss: 2.5283421269538193

Epoch: 5| Step: 5
Training loss: 2.4628917866521842
Validation loss: 2.5288670865713936

Epoch: 5| Step: 6
Training loss: 2.4007426066691453
Validation loss: 2.5295537437685978

Epoch: 5| Step: 7
Training loss: 2.579969728721045
Validation loss: 2.5541231735617007

Epoch: 5| Step: 8
Training loss: 2.289477626407135
Validation loss: 2.5622716468541533

Epoch: 5| Step: 9
Training loss: 2.1443362399239243
Validation loss: 2.5235749749527683

Epoch: 5| Step: 10
Training loss: 2.4936934079893054
Validation loss: 2.5320988632821493

Epoch: 5| Step: 11
Training loss: 1.7265036732590102
Validation loss: 2.510721814668769

Epoch: 253| Step: 0
Training loss: 1.768509458219448
Validation loss: 2.4905513367235543

Epoch: 5| Step: 1
Training loss: 2.8270589600207914
Validation loss: 2.492273100017686

Epoch: 5| Step: 2
Training loss: 2.779819249102039
Validation loss: 2.4895777655716143

Epoch: 5| Step: 3
Training loss: 2.102622066406177
Validation loss: 2.4893102190146332

Epoch: 5| Step: 4
Training loss: 2.652441368497685
Validation loss: 2.4941474159683983

Epoch: 5| Step: 5
Training loss: 3.0172857741674326
Validation loss: 2.4876631603373007

Epoch: 5| Step: 6
Training loss: 2.2787249451482445
Validation loss: 2.492619641425614

Epoch: 5| Step: 7
Training loss: 2.3406960490588244
Validation loss: 2.4891455250742474

Epoch: 5| Step: 8
Training loss: 2.2306311125710305
Validation loss: 2.4919449579570063

Epoch: 5| Step: 9
Training loss: 2.236523855381041
Validation loss: 2.4808588517179015

Epoch: 5| Step: 10
Training loss: 2.368516907509002
Validation loss: 2.4944085614763

Epoch: 5| Step: 11
Training loss: 1.472655602411993
Validation loss: 2.5078874024230573

Epoch: 254| Step: 0
Training loss: 2.224362326980079
Validation loss: 2.5174871171276307

Epoch: 5| Step: 1
Training loss: 2.6995002390025373
Validation loss: 2.5301792957141576

Epoch: 5| Step: 2
Training loss: 2.0029212360027078
Validation loss: 2.5294317418181262

Epoch: 5| Step: 3
Training loss: 2.7037813128573007
Validation loss: 2.562506569101861

Epoch: 5| Step: 4
Training loss: 2.419265029840041
Validation loss: 2.5583088801164853

Epoch: 5| Step: 5
Training loss: 2.6985440107838166
Validation loss: 2.5599170417463326

Epoch: 5| Step: 6
Training loss: 2.279863014288823
Validation loss: 2.52432753748522

Epoch: 5| Step: 7
Training loss: 2.283065282676108
Validation loss: 2.5155136762987915

Epoch: 5| Step: 8
Training loss: 2.1753103407520418
Validation loss: 2.4836744244370337

Epoch: 5| Step: 9
Training loss: 2.733324295897391
Validation loss: 2.478088546523296

Epoch: 5| Step: 10
Training loss: 2.4737694812102022
Validation loss: 2.4862041177762535

Epoch: 5| Step: 11
Training loss: 2.383796463720075
Validation loss: 2.48301152335279

Epoch: 255| Step: 0
Training loss: 2.3824701782473663
Validation loss: 2.478246078483747

Epoch: 5| Step: 1
Training loss: 2.262319323665208
Validation loss: 2.4908105280948782

Epoch: 5| Step: 2
Training loss: 2.5444793667772827
Validation loss: 2.5028255231111003

Epoch: 5| Step: 3
Training loss: 2.9396665983530608
Validation loss: 2.5113608627887234

Epoch: 5| Step: 4
Training loss: 2.928777853572403
Validation loss: 2.5186379241303793

Epoch: 5| Step: 5
Training loss: 2.4340425080636514
Validation loss: 2.5294016812677347

Epoch: 5| Step: 6
Training loss: 2.5305699506346255
Validation loss: 2.5588024568732495

Epoch: 5| Step: 7
Training loss: 2.319215046191482
Validation loss: 2.554980394408869

Epoch: 5| Step: 8
Training loss: 2.0823306786255786
Validation loss: 2.52814826561683

Epoch: 5| Step: 9
Training loss: 2.149602622635565
Validation loss: 2.5253980911353002

Epoch: 5| Step: 10
Training loss: 1.7955070927988945
Validation loss: 2.507744706010965

Epoch: 5| Step: 11
Training loss: 3.123393599567596
Validation loss: 2.4973472826510923

Epoch: 256| Step: 0
Training loss: 2.8712516896928357
Validation loss: 2.4990286052491912

Epoch: 5| Step: 1
Training loss: 2.5008732224354806
Validation loss: 2.480069854781821

Epoch: 5| Step: 2
Training loss: 1.9192842839329143
Validation loss: 2.483625478862824

Epoch: 5| Step: 3
Training loss: 2.716028012834902
Validation loss: 2.4761205312943493

Epoch: 5| Step: 4
Training loss: 1.764552643143872
Validation loss: 2.481283723808588

Epoch: 5| Step: 5
Training loss: 2.414537006643596
Validation loss: 2.501136251364001

Epoch: 5| Step: 6
Training loss: 1.7547722188823063
Validation loss: 2.4945418777661557

Epoch: 5| Step: 7
Training loss: 2.5331250063248865
Validation loss: 2.5128180716878634

Epoch: 5| Step: 8
Training loss: 2.7717761584424103
Validation loss: 2.500117458127355

Epoch: 5| Step: 9
Training loss: 2.5473924356948907
Validation loss: 2.5152128683648773

Epoch: 5| Step: 10
Training loss: 2.2452252906634915
Validation loss: 2.5162348077248775

Epoch: 5| Step: 11
Training loss: 2.4839325516860726
Validation loss: 2.5199529014076445

Epoch: 257| Step: 0
Training loss: 2.1800220738614535
Validation loss: 2.5192278420565137

Epoch: 5| Step: 1
Training loss: 2.842194519537614
Validation loss: 2.5371220690904246

Epoch: 5| Step: 2
Training loss: 2.6835802458266484
Validation loss: 2.526009700350033

Epoch: 5| Step: 3
Training loss: 2.1042572102721717
Validation loss: 2.526312105049966

Epoch: 5| Step: 4
Training loss: 2.4688514012625613
Validation loss: 2.5100496777048615

Epoch: 5| Step: 5
Training loss: 2.5470390032989623
Validation loss: 2.53641019353805

Epoch: 5| Step: 6
Training loss: 3.1119948808387683
Validation loss: 2.521279978525839

Epoch: 5| Step: 7
Training loss: 2.1182257439728183
Validation loss: 2.5263883149657445

Epoch: 5| Step: 8
Training loss: 2.4565564107631386
Validation loss: 2.5306967220881535

Epoch: 5| Step: 9
Training loss: 1.6532526064335484
Validation loss: 2.5153190395140514

Epoch: 5| Step: 10
Training loss: 2.2490422011606004
Validation loss: 2.5148874271736195

Epoch: 5| Step: 11
Training loss: 2.0058875448743096
Validation loss: 2.512854454317454

Epoch: 258| Step: 0
Training loss: 2.677397881420651
Validation loss: 2.5095715933876708

Epoch: 5| Step: 1
Training loss: 2.58128680925702
Validation loss: 2.4998488539463954

Epoch: 5| Step: 2
Training loss: 2.5331980426534404
Validation loss: 2.499584378026443

Epoch: 5| Step: 3
Training loss: 2.040269516363428
Validation loss: 2.50446598186327

Epoch: 5| Step: 4
Training loss: 2.190254765676385
Validation loss: 2.504198244776955

Epoch: 5| Step: 5
Training loss: 1.878702069329119
Validation loss: 2.485478965626531

Epoch: 5| Step: 6
Training loss: 2.28551064376005
Validation loss: 2.4924101296601804

Epoch: 5| Step: 7
Training loss: 2.6691097651321827
Validation loss: 2.493175306841463

Epoch: 5| Step: 8
Training loss: 2.110713618764571
Validation loss: 2.4970181205704627

Epoch: 5| Step: 9
Training loss: 2.6971622035635052
Validation loss: 2.4987888104298523

Epoch: 5| Step: 10
Training loss: 2.761623181277169
Validation loss: 2.5103935514997766

Epoch: 5| Step: 11
Training loss: 1.6798287975407618
Validation loss: 2.5055750038574462

Epoch: 259| Step: 0
Training loss: 2.454672355775113
Validation loss: 2.515321490141817

Epoch: 5| Step: 1
Training loss: 2.8705884839207716
Validation loss: 2.5191238980874893

Epoch: 5| Step: 2
Training loss: 2.3941076504525785
Validation loss: 2.512330494408836

Epoch: 5| Step: 3
Training loss: 2.043037369635119
Validation loss: 2.538763875762169

Epoch: 5| Step: 4
Training loss: 2.0073793886658007
Validation loss: 2.532713474861414

Epoch: 5| Step: 5
Training loss: 2.6282404018108187
Validation loss: 2.5173649703832983

Epoch: 5| Step: 6
Training loss: 2.2087013609733055
Validation loss: 2.517526113576101

Epoch: 5| Step: 7
Training loss: 2.272622398210898
Validation loss: 2.528802744393447

Epoch: 5| Step: 8
Training loss: 2.7989025758263337
Validation loss: 2.5318459174322854

Epoch: 5| Step: 9
Training loss: 1.8875180401476788
Validation loss: 2.5267871595600324

Epoch: 5| Step: 10
Training loss: 2.5760603527024326
Validation loss: 2.5028182277898887

Epoch: 5| Step: 11
Training loss: 2.1005845754877033
Validation loss: 2.487936018904351

Epoch: 260| Step: 0
Training loss: 2.6447286827958414
Validation loss: 2.4986650081426816

Epoch: 5| Step: 1
Training loss: 1.9721733484197177
Validation loss: 2.5004011905150754

Epoch: 5| Step: 2
Training loss: 2.148636909247242
Validation loss: 2.5138438180064395

Epoch: 5| Step: 3
Training loss: 2.314733509189966
Validation loss: 2.53847452642861

Epoch: 5| Step: 4
Training loss: 2.15101851357722
Validation loss: 2.532129727458996

Epoch: 5| Step: 5
Training loss: 2.4402234439473736
Validation loss: 2.518968041134969

Epoch: 5| Step: 6
Training loss: 2.1297440026695083
Validation loss: 2.545002004826224

Epoch: 5| Step: 7
Training loss: 2.48723049524949
Validation loss: 2.563778728781064

Epoch: 5| Step: 8
Training loss: 2.825417756106342
Validation loss: 2.55460328362852

Epoch: 5| Step: 9
Training loss: 2.561263553700812
Validation loss: 2.5500697282221045

Epoch: 5| Step: 10
Training loss: 2.515403974786569
Validation loss: 2.538185731188953

Epoch: 5| Step: 11
Training loss: 2.394499188903939
Validation loss: 2.5255478812198686

Epoch: 261| Step: 0
Training loss: 2.803664251913427
Validation loss: 2.5201189799705093

Epoch: 5| Step: 1
Training loss: 2.693385045936854
Validation loss: 2.4953390820320918

Epoch: 5| Step: 2
Training loss: 2.405783273589885
Validation loss: 2.4936886793419504

Epoch: 5| Step: 3
Training loss: 2.333556834370455
Validation loss: 2.4879039476353086

Epoch: 5| Step: 4
Training loss: 2.2146489025707248
Validation loss: 2.4904784298650493

Epoch: 5| Step: 5
Training loss: 2.035816985960056
Validation loss: 2.495579534744319

Epoch: 5| Step: 6
Training loss: 2.206977451985357
Validation loss: 2.4915523297625293

Epoch: 5| Step: 7
Training loss: 2.2780313647876533
Validation loss: 2.499463528452178

Epoch: 5| Step: 8
Training loss: 2.544919064477055
Validation loss: 2.495298060799586

Epoch: 5| Step: 9
Training loss: 2.4903848759668326
Validation loss: 2.49942605662426

Epoch: 5| Step: 10
Training loss: 2.356689541645892
Validation loss: 2.501576002387531

Epoch: 5| Step: 11
Training loss: 2.5492548209048733
Validation loss: 2.497688762893474

Epoch: 262| Step: 0
Training loss: 2.6591648937742645
Validation loss: 2.5143076881225404

Epoch: 5| Step: 1
Training loss: 2.324940391514733
Validation loss: 2.5132539446668343

Epoch: 5| Step: 2
Training loss: 2.5286230890971253
Validation loss: 2.533561008715073

Epoch: 5| Step: 3
Training loss: 2.1088977415093093
Validation loss: 2.5355577430145444

Epoch: 5| Step: 4
Training loss: 1.8521381239909123
Validation loss: 2.5252108292328264

Epoch: 5| Step: 5
Training loss: 1.4859853742811584
Validation loss: 2.5407201315135666

Epoch: 5| Step: 6
Training loss: 3.031862020156118
Validation loss: 2.5207852025336916

Epoch: 5| Step: 7
Training loss: 2.897990313064255
Validation loss: 2.506046529011427

Epoch: 5| Step: 8
Training loss: 2.69435275032132
Validation loss: 2.490728838330297

Epoch: 5| Step: 9
Training loss: 2.4362436627011497
Validation loss: 2.50497738149689

Epoch: 5| Step: 10
Training loss: 2.208397582457051
Validation loss: 2.5013790141952197

Epoch: 5| Step: 11
Training loss: 2.337279989730954
Validation loss: 2.507003915268618

Epoch: 263| Step: 0
Training loss: 2.017582260969563
Validation loss: 2.508947438465024

Epoch: 5| Step: 1
Training loss: 2.2757985023711513
Validation loss: 2.497064878129373

Epoch: 5| Step: 2
Training loss: 2.414971337948
Validation loss: 2.5311305367179098

Epoch: 5| Step: 3
Training loss: 2.3544498599601575
Validation loss: 2.530587144880868

Epoch: 5| Step: 4
Training loss: 3.054259755657547
Validation loss: 2.533914466655308

Epoch: 5| Step: 5
Training loss: 2.0596544692606478
Validation loss: 2.53912660566735

Epoch: 5| Step: 6
Training loss: 2.22255251999409
Validation loss: 2.547746314256625

Epoch: 5| Step: 7
Training loss: 2.269340887966349
Validation loss: 2.552152762474194

Epoch: 5| Step: 8
Training loss: 2.1798802225647638
Validation loss: 2.5391309758269403

Epoch: 5| Step: 9
Training loss: 3.23493547236664
Validation loss: 2.548224152273391

Epoch: 5| Step: 10
Training loss: 2.277141791102585
Validation loss: 2.532181642925656

Epoch: 5| Step: 11
Training loss: 1.8345567421506177
Validation loss: 2.5028280673394487

Epoch: 264| Step: 0
Training loss: 2.1376591762592123
Validation loss: 2.5014644585323143

Epoch: 5| Step: 1
Training loss: 2.4346431716684993
Validation loss: 2.488172300180289

Epoch: 5| Step: 2
Training loss: 2.4537845380998156
Validation loss: 2.4875132454946

Epoch: 5| Step: 3
Training loss: 2.895133466789976
Validation loss: 2.4773347013755975

Epoch: 5| Step: 4
Training loss: 2.270343471034933
Validation loss: 2.4898898336380824

Epoch: 5| Step: 5
Training loss: 2.178567359259421
Validation loss: 2.4913286544919027

Epoch: 5| Step: 6
Training loss: 2.133347552470663
Validation loss: 2.4822410879826466

Epoch: 5| Step: 7
Training loss: 2.7181564209245357
Validation loss: 2.4997382543553486

Epoch: 5| Step: 8
Training loss: 2.806110669183865
Validation loss: 2.5019206378226206

Epoch: 5| Step: 9
Training loss: 2.1740855212827572
Validation loss: 2.5065129875401118

Epoch: 5| Step: 10
Training loss: 2.287313476629002
Validation loss: 2.5015624984909586

Epoch: 5| Step: 11
Training loss: 1.9833594900164175
Validation loss: 2.5154384204234947

Epoch: 265| Step: 0
Training loss: 2.2187257147521064
Validation loss: 2.523855999393788

Epoch: 5| Step: 1
Training loss: 2.84372635716262
Validation loss: 2.5274629854654496

Epoch: 5| Step: 2
Training loss: 2.7151172088557627
Validation loss: 2.51917768259781

Epoch: 5| Step: 3
Training loss: 1.9622957305536721
Validation loss: 2.5368519946866948

Epoch: 5| Step: 4
Training loss: 2.3763686803952737
Validation loss: 2.5414054467987315

Epoch: 5| Step: 5
Training loss: 2.5224465706859545
Validation loss: 2.5460377313522975

Epoch: 5| Step: 6
Training loss: 2.554873958397623
Validation loss: 2.5587445319011226

Epoch: 5| Step: 7
Training loss: 2.2689998352534912
Validation loss: 2.533084934274481

Epoch: 5| Step: 8
Training loss: 2.2289920869244417
Validation loss: 2.5215761289639143

Epoch: 5| Step: 9
Training loss: 2.6886532105742007
Validation loss: 2.523864341908564

Epoch: 5| Step: 10
Training loss: 1.5069788075800408
Validation loss: 2.521210182542517

Epoch: 5| Step: 11
Training loss: 2.7151732320298905
Validation loss: 2.52083880184831

Epoch: 266| Step: 0
Training loss: 2.499321750189042
Validation loss: 2.528395719301261

Epoch: 5| Step: 1
Training loss: 2.2435267897915665
Validation loss: 2.51458778678565

Epoch: 5| Step: 2
Training loss: 2.210709415168952
Validation loss: 2.513626408456

Epoch: 5| Step: 3
Training loss: 2.0208466781752383
Validation loss: 2.5142105778088046

Epoch: 5| Step: 4
Training loss: 3.114558973610494
Validation loss: 2.5171737701306776

Epoch: 5| Step: 5
Training loss: 2.4895321083917312
Validation loss: 2.526765850646348

Epoch: 5| Step: 6
Training loss: 2.277624620028402
Validation loss: 2.533469020248559

Epoch: 5| Step: 7
Training loss: 2.5926570198086907
Validation loss: 2.5402964249303017

Epoch: 5| Step: 8
Training loss: 2.24711445048459
Validation loss: 2.544825175612932

Epoch: 5| Step: 9
Training loss: 2.4158905909756547
Validation loss: 2.5592313209916044

Epoch: 5| Step: 10
Training loss: 1.8081432465292904
Validation loss: 2.541482900532089

Epoch: 5| Step: 11
Training loss: 2.9072710110076274
Validation loss: 2.526638897692472

Epoch: 267| Step: 0
Training loss: 2.3550795301546126
Validation loss: 2.5119112691469994

Epoch: 5| Step: 1
Training loss: 2.9132779371754762
Validation loss: 2.5073269525529764

Epoch: 5| Step: 2
Training loss: 2.1475442034931507
Validation loss: 2.5018177437565843

Epoch: 5| Step: 3
Training loss: 2.36318702194638
Validation loss: 2.511865438525525

Epoch: 5| Step: 4
Training loss: 2.7766227376454067
Validation loss: 2.5086051227062702

Epoch: 5| Step: 5
Training loss: 2.8585534087965514
Validation loss: 2.5048962965138206

Epoch: 5| Step: 6
Training loss: 2.2707472152012516
Validation loss: 2.5294691854375646

Epoch: 5| Step: 7
Training loss: 2.05743966515887
Validation loss: 2.5092885000507046

Epoch: 5| Step: 8
Training loss: 2.1309832319282855
Validation loss: 2.531923334022422

Epoch: 5| Step: 9
Training loss: 2.102339930479506
Validation loss: 2.522640704794934

Epoch: 5| Step: 10
Training loss: 2.042794973302019
Validation loss: 2.534802569388914

Epoch: 5| Step: 11
Training loss: 1.6464352130903697
Validation loss: 2.5339176618272776

Epoch: 268| Step: 0
Training loss: 2.4036537134462233
Validation loss: 2.57559500350585

Epoch: 5| Step: 1
Training loss: 2.4779468602231653
Validation loss: 2.563587628577339

Epoch: 5| Step: 2
Training loss: 2.075500207381306
Validation loss: 2.56786102372254

Epoch: 5| Step: 3
Training loss: 2.6690270487792884
Validation loss: 2.5636236588191252

Epoch: 5| Step: 4
Training loss: 1.7897230369859025
Validation loss: 2.575081302075349

Epoch: 5| Step: 5
Training loss: 2.935787107342123
Validation loss: 2.5499882577800292

Epoch: 5| Step: 6
Training loss: 1.987059092049512
Validation loss: 2.568370553150679

Epoch: 5| Step: 7
Training loss: 2.4362364208142457
Validation loss: 2.5562505305444345

Epoch: 5| Step: 8
Training loss: 2.56352966834873
Validation loss: 2.54283077648943

Epoch: 5| Step: 9
Training loss: 1.9407439608516193
Validation loss: 2.549827494739035

Epoch: 5| Step: 10
Training loss: 2.3820271182626516
Validation loss: 2.5290553504185715

Epoch: 5| Step: 11
Training loss: 3.2582417669544212
Validation loss: 2.501093760282468

Epoch: 269| Step: 0
Training loss: 2.2647048660229414
Validation loss: 2.4969443084429694

Epoch: 5| Step: 1
Training loss: 2.243927602725452
Validation loss: 2.491136303297973

Epoch: 5| Step: 2
Training loss: 2.0252600750099834
Validation loss: 2.490023100623249

Epoch: 5| Step: 3
Training loss: 2.756348391482962
Validation loss: 2.486237523540034

Epoch: 5| Step: 4
Training loss: 2.270683796943265
Validation loss: 2.4859791301228253

Epoch: 5| Step: 5
Training loss: 2.098063907046336
Validation loss: 2.4919897018911747

Epoch: 5| Step: 6
Training loss: 2.54512675376267
Validation loss: 2.4889879445805403

Epoch: 5| Step: 7
Training loss: 3.0997522870429233
Validation loss: 2.4860561848427

Epoch: 5| Step: 8
Training loss: 1.7936083747698877
Validation loss: 2.4943272046128535

Epoch: 5| Step: 9
Training loss: 2.602393581768744
Validation loss: 2.4938353269761495

Epoch: 5| Step: 10
Training loss: 2.3525155502924258
Validation loss: 2.4925603159216605

Epoch: 5| Step: 11
Training loss: 3.8367063913241446
Validation loss: 2.5054408135406447

Epoch: 270| Step: 0
Training loss: 2.286327511832792
Validation loss: 2.50788068431091

Epoch: 5| Step: 1
Training loss: 2.6449334924769783
Validation loss: 2.52565914023677

Epoch: 5| Step: 2
Training loss: 1.5944330584259452
Validation loss: 2.5296299345658233

Epoch: 5| Step: 3
Training loss: 1.9406987518694943
Validation loss: 2.5354603456189544

Epoch: 5| Step: 4
Training loss: 3.058804052925243
Validation loss: 2.547317088164522

Epoch: 5| Step: 5
Training loss: 2.1871570863338308
Validation loss: 2.550989050041523

Epoch: 5| Step: 6
Training loss: 2.405204248459295
Validation loss: 2.5464096073183824

Epoch: 5| Step: 7
Training loss: 2.3166782676168465
Validation loss: 2.566086016087415

Epoch: 5| Step: 8
Training loss: 2.674516587829782
Validation loss: 2.5724480713192928

Epoch: 5| Step: 9
Training loss: 2.5986555658295494
Validation loss: 2.557319498525747

Epoch: 5| Step: 10
Training loss: 2.5854061998457194
Validation loss: 2.5748931549336938

Epoch: 5| Step: 11
Training loss: 1.4712692731374393
Validation loss: 2.544130699544052

Epoch: 271| Step: 0
Training loss: 2.123003077471996
Validation loss: 2.5261031952800526

Epoch: 5| Step: 1
Training loss: 2.592809115809135
Validation loss: 2.514881340031125

Epoch: 5| Step: 2
Training loss: 2.7114056009935816
Validation loss: 2.520238500093264

Epoch: 5| Step: 3
Training loss: 2.265031092179809
Validation loss: 2.503314558829482

Epoch: 5| Step: 4
Training loss: 2.4499434717624697
Validation loss: 2.4957774185217807

Epoch: 5| Step: 5
Training loss: 2.4765187930513317
Validation loss: 2.5040759040540097

Epoch: 5| Step: 6
Training loss: 2.1852813368486905
Validation loss: 2.5036239187129166

Epoch: 5| Step: 7
Training loss: 1.868148364944831
Validation loss: 2.4997154749450137

Epoch: 5| Step: 8
Training loss: 2.2121484897502577
Validation loss: 2.501568635912774

Epoch: 5| Step: 9
Training loss: 2.254807528382693
Validation loss: 2.5064838728386856

Epoch: 5| Step: 10
Training loss: 2.7831700587399792
Validation loss: 2.5215462367523416

Epoch: 5| Step: 11
Training loss: 2.583824931305286
Validation loss: 2.512995200281737

Epoch: 272| Step: 0
Training loss: 3.178202664336896
Validation loss: 2.5606117773765993

Epoch: 5| Step: 1
Training loss: 2.3666769049875223
Validation loss: 2.6050598647255137

Epoch: 5| Step: 2
Training loss: 2.6457285121869503
Validation loss: 2.6575992000028394

Epoch: 5| Step: 3
Training loss: 1.9076519797839204
Validation loss: 2.673607370585898

Epoch: 5| Step: 4
Training loss: 2.0625816097875234
Validation loss: 2.6799581926676606

Epoch: 5| Step: 5
Training loss: 2.519962528192364
Validation loss: 2.6671876001162476

Epoch: 5| Step: 6
Training loss: 2.082319801475084
Validation loss: 2.592564944058033

Epoch: 5| Step: 7
Training loss: 2.7770383857434044
Validation loss: 2.5391757255153067

Epoch: 5| Step: 8
Training loss: 2.614996058094562
Validation loss: 2.508146760872926

Epoch: 5| Step: 9
Training loss: 2.467247131284143
Validation loss: 2.5058682987394185

Epoch: 5| Step: 10
Training loss: 2.4780850228047107
Validation loss: 2.491164572521192

Epoch: 5| Step: 11
Training loss: 2.2086424221401146
Validation loss: 2.4920215970009734

Epoch: 273| Step: 0
Training loss: 3.109942207167424
Validation loss: 2.477904035635362

Epoch: 5| Step: 1
Training loss: 2.455745293789144
Validation loss: 2.4768598119331178

Epoch: 5| Step: 2
Training loss: 2.4439425302357196
Validation loss: 2.4796548985063

Epoch: 5| Step: 3
Training loss: 2.5839236620678334
Validation loss: 2.4820228894310725

Epoch: 5| Step: 4
Training loss: 1.9574063183423798
Validation loss: 2.4843332898939137

Epoch: 5| Step: 5
Training loss: 2.3341955113379314
Validation loss: 2.4859952861176513

Epoch: 5| Step: 6
Training loss: 2.201047201611525
Validation loss: 2.489923152050504

Epoch: 5| Step: 7
Training loss: 2.614991772932309
Validation loss: 2.4899083401541526

Epoch: 5| Step: 8
Training loss: 1.8652654355643552
Validation loss: 2.487244971619004

Epoch: 5| Step: 9
Training loss: 3.2679478902969503
Validation loss: 2.481175267481785

Epoch: 5| Step: 10
Training loss: 2.565175962008153
Validation loss: 2.4761722590172415

Epoch: 5| Step: 11
Training loss: 3.1743405535849925
Validation loss: 2.479309976800679

Epoch: 274| Step: 0
Training loss: 2.462485368559304
Validation loss: 2.4685926145773958

Epoch: 5| Step: 1
Training loss: 2.4760127374940764
Validation loss: 2.47913968982498

Epoch: 5| Step: 2
Training loss: 2.6744962627950315
Validation loss: 2.476386460105583

Epoch: 5| Step: 3
Training loss: 2.375242020171508
Validation loss: 2.473389426957264

Epoch: 5| Step: 4
Training loss: 2.170069540992671
Validation loss: 2.472322635331842

Epoch: 5| Step: 5
Training loss: 2.2631612074978325
Validation loss: 2.4683843816758344

Epoch: 5| Step: 6
Training loss: 2.5050168245097
Validation loss: 2.470201226723665

Epoch: 5| Step: 7
Training loss: 2.697389106769109
Validation loss: 2.4789352362399066

Epoch: 5| Step: 8
Training loss: 2.4275829363090136
Validation loss: 2.477045387178475

Epoch: 5| Step: 9
Training loss: 2.5200374597459754
Validation loss: 2.4908203672193037

Epoch: 5| Step: 10
Training loss: 2.493094539308024
Validation loss: 2.4853361177995064

Epoch: 5| Step: 11
Training loss: 2.4620261070360923
Validation loss: 2.5168912989951693

Epoch: 275| Step: 0
Training loss: 3.128158346602431
Validation loss: 2.5171348826747693

Epoch: 5| Step: 1
Training loss: 2.178096942912461
Validation loss: 2.5480828258850203

Epoch: 5| Step: 2
Training loss: 2.0742190948313626
Validation loss: 2.5794049370688095

Epoch: 5| Step: 3
Training loss: 2.347262484363798
Validation loss: 2.5714479699866435

Epoch: 5| Step: 4
Training loss: 2.3694798414600817
Validation loss: 2.584679304209937

Epoch: 5| Step: 5
Training loss: 2.59517529404542
Validation loss: 2.572027297240455

Epoch: 5| Step: 6
Training loss: 2.386882170781034
Validation loss: 2.536983393868767

Epoch: 5| Step: 7
Training loss: 2.674925462629069
Validation loss: 2.530102186985276

Epoch: 5| Step: 8
Training loss: 2.841406894418404
Validation loss: 2.500453852147253

Epoch: 5| Step: 9
Training loss: 2.015735002221802
Validation loss: 2.5137370352313506

Epoch: 5| Step: 10
Training loss: 2.2121866424554573
Validation loss: 2.510699736331359

Epoch: 5| Step: 11
Training loss: 2.6345636447321845
Validation loss: 2.512038096391123

Epoch: 276| Step: 0
Training loss: 1.9426539381932852
Validation loss: 2.504711003945835

Epoch: 5| Step: 1
Training loss: 2.2398529127057967
Validation loss: 2.4711816859511084

Epoch: 5| Step: 2
Training loss: 2.888744175375625
Validation loss: 2.4856906422238083

Epoch: 5| Step: 3
Training loss: 2.5019830468180517
Validation loss: 2.489635783538139

Epoch: 5| Step: 4
Training loss: 1.7092692284924547
Validation loss: 2.4940774820490605

Epoch: 5| Step: 5
Training loss: 3.0345164524348283
Validation loss: 2.4825790479572105

Epoch: 5| Step: 6
Training loss: 2.547647464366224
Validation loss: 2.4916821189601106

Epoch: 5| Step: 7
Training loss: 1.7383424212375769
Validation loss: 2.485496651661992

Epoch: 5| Step: 8
Training loss: 2.419437387657848
Validation loss: 2.486785487011424

Epoch: 5| Step: 9
Training loss: 2.680233824621422
Validation loss: 2.4842416419618374

Epoch: 5| Step: 10
Training loss: 2.6790401466440033
Validation loss: 2.489002616275308

Epoch: 5| Step: 11
Training loss: 1.8627427320593264
Validation loss: 2.483954907933539

Epoch: 277| Step: 0
Training loss: 2.309403588888449
Validation loss: 2.4853126787642634

Epoch: 5| Step: 1
Training loss: 2.38533321939848
Validation loss: 2.4893106061131722

Epoch: 5| Step: 2
Training loss: 2.1020294011144123
Validation loss: 2.4907895236078024

Epoch: 5| Step: 3
Training loss: 2.829254262145876
Validation loss: 2.5000325280298608

Epoch: 5| Step: 4
Training loss: 2.18762402864067
Validation loss: 2.5124669243642437

Epoch: 5| Step: 5
Training loss: 2.700539294884511
Validation loss: 2.527663476482496

Epoch: 5| Step: 6
Training loss: 2.8758583446097825
Validation loss: 2.5415716557384935

Epoch: 5| Step: 7
Training loss: 1.576344533773345
Validation loss: 2.5312480494801735

Epoch: 5| Step: 8
Training loss: 2.2153471520967045
Validation loss: 2.5335345535506786

Epoch: 5| Step: 9
Training loss: 2.6755745244049045
Validation loss: 2.5259779473097455

Epoch: 5| Step: 10
Training loss: 2.7606724074794635
Validation loss: 2.5326000938016158

Epoch: 5| Step: 11
Training loss: 2.3632137572684204
Validation loss: 2.520076481772427

Epoch: 278| Step: 0
Training loss: 2.2104485176612814
Validation loss: 2.4973595563198234

Epoch: 5| Step: 1
Training loss: 1.749851016106087
Validation loss: 2.4913066594899367

Epoch: 5| Step: 2
Training loss: 2.408506648109325
Validation loss: 2.489310201056452

Epoch: 5| Step: 3
Training loss: 2.060957476307245
Validation loss: 2.493907227495369

Epoch: 5| Step: 4
Training loss: 2.6460067712202675
Validation loss: 2.5009761573466456

Epoch: 5| Step: 5
Training loss: 3.1952578812760084
Validation loss: 2.4997930123154157

Epoch: 5| Step: 6
Training loss: 2.5386908156437804
Validation loss: 2.5006152111301403

Epoch: 5| Step: 7
Training loss: 2.1764546145109205
Validation loss: 2.5137098576764307

Epoch: 5| Step: 8
Training loss: 2.978090709957203
Validation loss: 2.5115677396112015

Epoch: 5| Step: 9
Training loss: 2.5341202275057144
Validation loss: 2.5147098353522934

Epoch: 5| Step: 10
Training loss: 2.908878245491675
Validation loss: 2.515883276497264

Epoch: 5| Step: 11
Training loss: 1.7587221631719023
Validation loss: 2.5119473524858487

Epoch: 279| Step: 0
Training loss: 2.1446038461428882
Validation loss: 2.5195193623107093

Epoch: 5| Step: 1
Training loss: 2.471400130192524
Validation loss: 2.511637356607561

Epoch: 5| Step: 2
Training loss: 2.3656087212147336
Validation loss: 2.508463172044619

Epoch: 5| Step: 3
Training loss: 2.40000978308909
Validation loss: 2.5105249109846164

Epoch: 5| Step: 4
Training loss: 2.79274858794084
Validation loss: 2.5155071562655946

Epoch: 5| Step: 5
Training loss: 2.4981604483930826
Validation loss: 2.499279216334202

Epoch: 5| Step: 6
Training loss: 2.3050055850079247
Validation loss: 2.5025983539769165

Epoch: 5| Step: 7
Training loss: 2.3695042921495495
Validation loss: 2.4956354288586584

Epoch: 5| Step: 8
Training loss: 2.609501270277069
Validation loss: 2.489330902762555

Epoch: 5| Step: 9
Training loss: 2.969459689792774
Validation loss: 2.4943938220142434

Epoch: 5| Step: 10
Training loss: 2.651797433582298
Validation loss: 2.4900760455692295

Epoch: 5| Step: 11
Training loss: 2.7011434535629673
Validation loss: 2.4889781580809958

Epoch: 280| Step: 0
Training loss: 2.0527711932131627
Validation loss: 2.4858282165515178

Epoch: 5| Step: 1
Training loss: 2.43922597959201
Validation loss: 2.4833760522415287

Epoch: 5| Step: 2
Training loss: 2.5807682243545496
Validation loss: 2.4783140380581132

Epoch: 5| Step: 3
Training loss: 2.602476766960812
Validation loss: 2.4766713709121255

Epoch: 5| Step: 4
Training loss: 2.278574066485165
Validation loss: 2.4875419173071505

Epoch: 5| Step: 5
Training loss: 2.1668678581531604
Validation loss: 2.488740360657108

Epoch: 5| Step: 6
Training loss: 2.234927875967994
Validation loss: 2.492071410119097

Epoch: 5| Step: 7
Training loss: 2.8272651503326753
Validation loss: 2.48740797623427

Epoch: 5| Step: 8
Training loss: 1.8523260546112157
Validation loss: 2.492553329324515

Epoch: 5| Step: 9
Training loss: 2.5294339293827766
Validation loss: 2.5007605230347796

Epoch: 5| Step: 10
Training loss: 3.0637042733448863
Validation loss: 2.498753753616035

Epoch: 5| Step: 11
Training loss: 2.8337353439860715
Validation loss: 2.500872034730798

Epoch: 281| Step: 0
Training loss: 2.102606191595572
Validation loss: 2.5004027260811954

Epoch: 5| Step: 1
Training loss: 2.7990847760739013
Validation loss: 2.5142597656115977

Epoch: 5| Step: 2
Training loss: 2.2270784549879763
Validation loss: 2.515663924617022

Epoch: 5| Step: 3
Training loss: 2.326833174557837
Validation loss: 2.5144718678528357

Epoch: 5| Step: 4
Training loss: 2.7899163485876595
Validation loss: 2.5179635821431563

Epoch: 5| Step: 5
Training loss: 1.8726189435760725
Validation loss: 2.535090380470739

Epoch: 5| Step: 6
Training loss: 2.7610033287572637
Validation loss: 2.531589414658087

Epoch: 5| Step: 7
Training loss: 2.2594932978936493
Validation loss: 2.552662856937213

Epoch: 5| Step: 8
Training loss: 2.0364727075041844
Validation loss: 2.5411860970566806

Epoch: 5| Step: 9
Training loss: 2.817675512173223
Validation loss: 2.545042084406533

Epoch: 5| Step: 10
Training loss: 2.5812389641403484
Validation loss: 2.533525774311763

Epoch: 5| Step: 11
Training loss: 2.6110231596651183
Validation loss: 2.5352859855728345

Epoch: 282| Step: 0
Training loss: 2.37888430129576
Validation loss: 2.5280912572293057

Epoch: 5| Step: 1
Training loss: 1.5149426841595204
Validation loss: 2.523592216858587

Epoch: 5| Step: 2
Training loss: 2.2667101135951873
Validation loss: 2.512510628701498

Epoch: 5| Step: 3
Training loss: 2.653965854284261
Validation loss: 2.5050443620744725

Epoch: 5| Step: 4
Training loss: 2.7953867442387508
Validation loss: 2.5123778131611805

Epoch: 5| Step: 5
Training loss: 2.692927801065998
Validation loss: 2.5191057856319485

Epoch: 5| Step: 6
Training loss: 2.2794001146485696
Validation loss: 2.518054101349381

Epoch: 5| Step: 7
Training loss: 2.7111863783340246
Validation loss: 2.505976669488085

Epoch: 5| Step: 8
Training loss: 2.422806197775373
Validation loss: 2.509021717062688

Epoch: 5| Step: 9
Training loss: 2.5010796123159165
Validation loss: 2.515693276625959

Epoch: 5| Step: 10
Training loss: 2.1663005837479545
Validation loss: 2.523435185198121

Epoch: 5| Step: 11
Training loss: 1.0441902237345912
Validation loss: 2.529080866521464

Epoch: 283| Step: 0
Training loss: 2.5682791693750318
Validation loss: 2.5331167315650824

Epoch: 5| Step: 1
Training loss: 2.109703886035993
Validation loss: 2.5292463574955284

Epoch: 5| Step: 2
Training loss: 1.8290905481140274
Validation loss: 2.53108652984169

Epoch: 5| Step: 3
Training loss: 2.097458927811799
Validation loss: 2.5476232104443577

Epoch: 5| Step: 4
Training loss: 2.4786197048305567
Validation loss: 2.553089746568788

Epoch: 5| Step: 5
Training loss: 2.724223798042086
Validation loss: 2.552654670807777

Epoch: 5| Step: 6
Training loss: 2.203633351216631
Validation loss: 2.534211541614488

Epoch: 5| Step: 7
Training loss: 2.5928262191543756
Validation loss: 2.5585411512874816

Epoch: 5| Step: 8
Training loss: 2.4216851929150462
Validation loss: 2.5390626447628666

Epoch: 5| Step: 9
Training loss: 2.7769579398102335
Validation loss: 2.5626955636150845

Epoch: 5| Step: 10
Training loss: 2.1129405087185464
Validation loss: 2.5368923635766505

Epoch: 5| Step: 11
Training loss: 2.9184465336335585
Validation loss: 2.55431347674501

Epoch: 284| Step: 0
Training loss: 2.1635797836724584
Validation loss: 2.530303055827792

Epoch: 5| Step: 1
Training loss: 2.2508586728551476
Validation loss: 2.522315583943678

Epoch: 5| Step: 2
Training loss: 2.855315615282909
Validation loss: 2.5243449552756165

Epoch: 5| Step: 3
Training loss: 2.218058518665394
Validation loss: 2.5115913548650646

Epoch: 5| Step: 4
Training loss: 2.3051904161954675
Validation loss: 2.5155386979046903

Epoch: 5| Step: 5
Training loss: 2.6187602769017286
Validation loss: 2.5166921820094483

Epoch: 5| Step: 6
Training loss: 2.5930024873815007
Validation loss: 2.505143231493084

Epoch: 5| Step: 7
Training loss: 2.13669665672136
Validation loss: 2.5118199827875376

Epoch: 5| Step: 8
Training loss: 2.5622315615101194
Validation loss: 2.5122353994870408

Epoch: 5| Step: 9
Training loss: 2.5072359271973004
Validation loss: 2.51361732453359

Epoch: 5| Step: 10
Training loss: 1.850321615461134
Validation loss: 2.5264551564951563

Epoch: 5| Step: 11
Training loss: 2.660705420094365
Validation loss: 2.517980752005573

Epoch: 285| Step: 0
Training loss: 2.346377718034954
Validation loss: 2.5175318155106114

Epoch: 5| Step: 1
Training loss: 2.382599467775991
Validation loss: 2.5183750742813524

Epoch: 5| Step: 2
Training loss: 2.6465223921969567
Validation loss: 2.5001517170328427

Epoch: 5| Step: 3
Training loss: 1.926676389324291
Validation loss: 2.516879343578985

Epoch: 5| Step: 4
Training loss: 2.2396198949860517
Validation loss: 2.5097964590432245

Epoch: 5| Step: 5
Training loss: 1.838899730651693
Validation loss: 2.5173045784898176

Epoch: 5| Step: 6
Training loss: 2.8961006059506285
Validation loss: 2.5192523023170783

Epoch: 5| Step: 7
Training loss: 1.8738117903585316
Validation loss: 2.519748199348703

Epoch: 5| Step: 8
Training loss: 2.468102768667237
Validation loss: 2.521355654983906

Epoch: 5| Step: 9
Training loss: 2.8035401784250316
Validation loss: 2.5354344529306716

Epoch: 5| Step: 10
Training loss: 2.490111727218677
Validation loss: 2.5245517321787863

Epoch: 5| Step: 11
Training loss: 1.9643226372357312
Validation loss: 2.5544875141537284

Epoch: 286| Step: 0
Training loss: 1.686294195502312
Validation loss: 2.5489040865242276

Epoch: 5| Step: 1
Training loss: 2.555447433322129
Validation loss: 2.552467781745313

Epoch: 5| Step: 2
Training loss: 2.5531421151865707
Validation loss: 2.5616665391874394

Epoch: 5| Step: 3
Training loss: 2.2863332472339257
Validation loss: 2.5390365403633366

Epoch: 5| Step: 4
Training loss: 2.424606849812907
Validation loss: 2.527757511535094

Epoch: 5| Step: 5
Training loss: 2.7097263763915556
Validation loss: 2.5303998704772956

Epoch: 5| Step: 6
Training loss: 2.634079263362025
Validation loss: 2.529902197476593

Epoch: 5| Step: 7
Training loss: 2.213129688894653
Validation loss: 2.5307227280189353

Epoch: 5| Step: 8
Training loss: 2.3814364102507786
Validation loss: 2.543751667875076

Epoch: 5| Step: 9
Training loss: 2.4002028935818918
Validation loss: 2.553220179747431

Epoch: 5| Step: 10
Training loss: 2.082920936457493
Validation loss: 2.55220103608751

Epoch: 5| Step: 11
Training loss: 2.5753940799226505
Validation loss: 2.5246793724357657

Epoch: 287| Step: 0
Training loss: 2.644690639814469
Validation loss: 2.5230115288861494

Epoch: 5| Step: 1
Training loss: 2.6562693875671144
Validation loss: 2.530132647550137

Epoch: 5| Step: 2
Training loss: 1.9968077694555275
Validation loss: 2.521427883753457

Epoch: 5| Step: 3
Training loss: 2.045100250771479
Validation loss: 2.5199080271752603

Epoch: 5| Step: 4
Training loss: 2.1179579568135516
Validation loss: 2.511102702686791

Epoch: 5| Step: 5
Training loss: 2.70692864205676
Validation loss: 2.5075467088658714

Epoch: 5| Step: 6
Training loss: 1.7729255508696329
Validation loss: 2.5197585759875323

Epoch: 5| Step: 7
Training loss: 2.6671634648407196
Validation loss: 2.5115342257812574

Epoch: 5| Step: 8
Training loss: 2.0071060778492145
Validation loss: 2.5110080874447136

Epoch: 5| Step: 9
Training loss: 2.5891948364545776
Validation loss: 2.5228107449582824

Epoch: 5| Step: 10
Training loss: 2.334532043812298
Validation loss: 2.5435605744823424

Epoch: 5| Step: 11
Training loss: 2.951789998242691
Validation loss: 2.5440412018826315

Epoch: 288| Step: 0
Training loss: 2.2966264862768306
Validation loss: 2.5634402589195244

Epoch: 5| Step: 1
Training loss: 2.072682762048328
Validation loss: 2.570746473105244

Epoch: 5| Step: 2
Training loss: 2.359065155500786
Validation loss: 2.5678100772119077

Epoch: 5| Step: 3
Training loss: 2.637123269027704
Validation loss: 2.564399356476893

Epoch: 5| Step: 4
Training loss: 1.8737778813359882
Validation loss: 2.5786712491647457

Epoch: 5| Step: 5
Training loss: 2.997529761235846
Validation loss: 2.5917388901863507

Epoch: 5| Step: 6
Training loss: 2.4423936479855106
Validation loss: 2.595996140741919

Epoch: 5| Step: 7
Training loss: 1.6955479049732218
Validation loss: 2.5771943695727995

Epoch: 5| Step: 8
Training loss: 2.4853793819047163
Validation loss: 2.5646287248335287

Epoch: 5| Step: 9
Training loss: 1.905191721842912
Validation loss: 2.590503138800121

Epoch: 5| Step: 10
Training loss: 3.017368425409904
Validation loss: 2.5592361963723427

Epoch: 5| Step: 11
Training loss: 1.3541925672352781
Validation loss: 2.5611522782330076

Epoch: 289| Step: 0
Training loss: 2.611955292054761
Validation loss: 2.560021535452523

Epoch: 5| Step: 1
Training loss: 2.370488650491319
Validation loss: 2.5564335835637797

Epoch: 5| Step: 2
Training loss: 2.2289811767221455
Validation loss: 2.5876319535252312

Epoch: 5| Step: 3
Training loss: 2.2480887666804343
Validation loss: 2.5951565314578375

Epoch: 5| Step: 4
Training loss: 2.2865006103314607
Validation loss: 2.6044182477862905

Epoch: 5| Step: 5
Training loss: 2.3323868012430515
Validation loss: 2.5925671933048893

Epoch: 5| Step: 6
Training loss: 2.2825930051876404
Validation loss: 2.616149681392763

Epoch: 5| Step: 7
Training loss: 2.4114745258312205
Validation loss: 2.6215510568714997

Epoch: 5| Step: 8
Training loss: 2.612596270963987
Validation loss: 2.6206320267363314

Epoch: 5| Step: 9
Training loss: 2.9234937783741533
Validation loss: 2.6053572368254523

Epoch: 5| Step: 10
Training loss: 2.1117104493830805
Validation loss: 2.573996646698361

Epoch: 5| Step: 11
Training loss: 1.8115204762231525
Validation loss: 2.5701502678254013

Epoch: 290| Step: 0
Training loss: 1.9474097287530032
Validation loss: 2.543115762972078

Epoch: 5| Step: 1
Training loss: 2.020702737999552
Validation loss: 2.540736793742362

Epoch: 5| Step: 2
Training loss: 2.2510601301258344
Validation loss: 2.525247623400314

Epoch: 5| Step: 3
Training loss: 2.166245223896905
Validation loss: 2.522619408111728

Epoch: 5| Step: 4
Training loss: 3.0914911828702745
Validation loss: 2.51898509964291

Epoch: 5| Step: 5
Training loss: 2.288656882324698
Validation loss: 2.529639391002803

Epoch: 5| Step: 6
Training loss: 2.657974491195035
Validation loss: 2.5159882466840724

Epoch: 5| Step: 7
Training loss: 2.1657208310016487
Validation loss: 2.5233776175969034

Epoch: 5| Step: 8
Training loss: 3.055745207555521
Validation loss: 2.5181348020959775

Epoch: 5| Step: 9
Training loss: 2.506592070335313
Validation loss: 2.5271389429672872

Epoch: 5| Step: 10
Training loss: 2.5081995965362194
Validation loss: 2.520106894014744

Epoch: 5| Step: 11
Training loss: 1.581581711184162
Validation loss: 2.5282581115906115

Epoch: 291| Step: 0
Training loss: 2.36713703970429
Validation loss: 2.5360293655537984

Epoch: 5| Step: 1
Training loss: 2.288558539940559
Validation loss: 2.544298897428688

Epoch: 5| Step: 2
Training loss: 2.3388272276074913
Validation loss: 2.5367227112355666

Epoch: 5| Step: 3
Training loss: 2.108234238337555
Validation loss: 2.5476433895675146

Epoch: 5| Step: 4
Training loss: 2.5760941338251064
Validation loss: 2.5592939898875233

Epoch: 5| Step: 5
Training loss: 2.327677434105433
Validation loss: 2.5639944506473316

Epoch: 5| Step: 6
Training loss: 2.2937810911311396
Validation loss: 2.576501658908629

Epoch: 5| Step: 7
Training loss: 2.9171327672644836
Validation loss: 2.5754502803960504

Epoch: 5| Step: 8
Training loss: 2.434124492248128
Validation loss: 2.5893937876028446

Epoch: 5| Step: 9
Training loss: 1.9024441984316813
Validation loss: 2.5905326283809003

Epoch: 5| Step: 10
Training loss: 2.3797799245878672
Validation loss: 2.6081409162981384

Epoch: 5| Step: 11
Training loss: 2.2475116533395267
Validation loss: 2.5906545559892415

Epoch: 292| Step: 0
Training loss: 1.9753443164311966
Validation loss: 2.597343651646609

Epoch: 5| Step: 1
Training loss: 2.480337160479797
Validation loss: 2.573572632469422

Epoch: 5| Step: 2
Training loss: 2.913536208339393
Validation loss: 2.5528519439669743

Epoch: 5| Step: 3
Training loss: 2.55394349069595
Validation loss: 2.5664510118208876

Epoch: 5| Step: 4
Training loss: 2.141341931651625
Validation loss: 2.553714504689241

Epoch: 5| Step: 5
Training loss: 2.3639943962095296
Validation loss: 2.537866707943014

Epoch: 5| Step: 6
Training loss: 2.5114998492165483
Validation loss: 2.528687545846138

Epoch: 5| Step: 7
Training loss: 2.1596625041439736
Validation loss: 2.5236274915413293

Epoch: 5| Step: 8
Training loss: 2.4327515542414737
Validation loss: 2.5317758987167864

Epoch: 5| Step: 9
Training loss: 2.1773719657107256
Validation loss: 2.5281102110497367

Epoch: 5| Step: 10
Training loss: 2.5045934439339597
Validation loss: 2.5242616943182186

Epoch: 5| Step: 11
Training loss: 0.4724107214934393
Validation loss: 2.5290772645871997

Epoch: 293| Step: 0
Training loss: 1.5548972750277337
Validation loss: 2.5305501299989643

Epoch: 5| Step: 1
Training loss: 2.606030725270185
Validation loss: 2.5220443966494943

Epoch: 5| Step: 2
Training loss: 2.6225145471567606
Validation loss: 2.5349702419074296

Epoch: 5| Step: 3
Training loss: 2.5228327448710806
Validation loss: 2.521154711600689

Epoch: 5| Step: 4
Training loss: 2.644801161274364
Validation loss: 2.5345855721054042

Epoch: 5| Step: 5
Training loss: 2.0777806735344404
Validation loss: 2.5295604710830486

Epoch: 5| Step: 6
Training loss: 1.6547213283463331
Validation loss: 2.546245969233243

Epoch: 5| Step: 7
Training loss: 2.5139470161007695
Validation loss: 2.544752523740849

Epoch: 5| Step: 8
Training loss: 2.7570449582302574
Validation loss: 2.5450669991605754

Epoch: 5| Step: 9
Training loss: 2.1824171687222726
Validation loss: 2.538314677909013

Epoch: 5| Step: 10
Training loss: 2.552675067005431
Validation loss: 2.5333632921237665

Epoch: 5| Step: 11
Training loss: 1.9803838768102586
Validation loss: 2.5399535234522013

Epoch: 294| Step: 0
Training loss: 2.2596192835947417
Validation loss: 2.526589431886522

Epoch: 5| Step: 1
Training loss: 2.9030603112116404
Validation loss: 2.5267784276449943

Epoch: 5| Step: 2
Training loss: 2.2752894039315232
Validation loss: 2.5225935273589912

Epoch: 5| Step: 3
Training loss: 2.2492921563506063
Validation loss: 2.5394695092704307

Epoch: 5| Step: 4
Training loss: 2.1420600702961345
Validation loss: 2.54990551857661

Epoch: 5| Step: 5
Training loss: 2.5364198988575044
Validation loss: 2.5782686366903236

Epoch: 5| Step: 6
Training loss: 2.23281613904204
Validation loss: 2.5635577282847413

Epoch: 5| Step: 7
Training loss: 2.295752114614954
Validation loss: 2.5689405356697517

Epoch: 5| Step: 8
Training loss: 2.051587220716327
Validation loss: 2.567790648486685

Epoch: 5| Step: 9
Training loss: 2.0243239651848537
Validation loss: 2.5514075545798756

Epoch: 5| Step: 10
Training loss: 2.87607819615623
Validation loss: 2.5392073956740915

Epoch: 5| Step: 11
Training loss: 1.6129688025033593
Validation loss: 2.5453192868268113

Epoch: 295| Step: 0
Training loss: 2.699262560697279
Validation loss: 2.542598656416008

Epoch: 5| Step: 1
Training loss: 2.889942810390313
Validation loss: 2.5294739650163907

Epoch: 5| Step: 2
Training loss: 1.6486336107797794
Validation loss: 2.5534291157475697

Epoch: 5| Step: 3
Training loss: 2.936871887582062
Validation loss: 2.5471343784052602

Epoch: 5| Step: 4
Training loss: 2.037829497672578
Validation loss: 2.5489803965405735

Epoch: 5| Step: 5
Training loss: 2.325837618164285
Validation loss: 2.5361166821205403

Epoch: 5| Step: 6
Training loss: 2.1215507338205035
Validation loss: 2.5608544959006854

Epoch: 5| Step: 7
Training loss: 2.5542114000826666
Validation loss: 2.5571402539233388

Epoch: 5| Step: 8
Training loss: 1.8091798825383816
Validation loss: 2.564174568211412

Epoch: 5| Step: 9
Training loss: 2.7109776034947966
Validation loss: 2.5515624481406736

Epoch: 5| Step: 10
Training loss: 1.6531678798140488
Validation loss: 2.553746227946882

Epoch: 5| Step: 11
Training loss: 1.3058757738732043
Validation loss: 2.5524710081797233

Epoch: 296| Step: 0
Training loss: 1.9537798584787742
Validation loss: 2.5485011722945443

Epoch: 5| Step: 1
Training loss: 2.415016158782416
Validation loss: 2.571547029147151

Epoch: 5| Step: 2
Training loss: 2.038361059682839
Validation loss: 2.557213633810605

Epoch: 5| Step: 3
Training loss: 2.1287953759115603
Validation loss: 2.562549187412989

Epoch: 5| Step: 4
Training loss: 1.4860013384498534
Validation loss: 2.5495371216111797

Epoch: 5| Step: 5
Training loss: 2.7999655414913267
Validation loss: 2.557226845773718

Epoch: 5| Step: 6
Training loss: 2.356324503805944
Validation loss: 2.5493999633851208

Epoch: 5| Step: 7
Training loss: 2.7888354468154017
Validation loss: 2.567680499304486

Epoch: 5| Step: 8
Training loss: 1.9697511337631415
Validation loss: 2.5416597903007503

Epoch: 5| Step: 9
Training loss: 2.40907795184464
Validation loss: 2.5505025106723185

Epoch: 5| Step: 10
Training loss: 2.899867771685757
Validation loss: 2.5345883705703254

Epoch: 5| Step: 11
Training loss: 2.91921337296864
Validation loss: 2.538790292086747

Epoch: 297| Step: 0
Training loss: 2.5568442850032747
Validation loss: 2.5238214521541766

Epoch: 5| Step: 1
Training loss: 2.4558154859909385
Validation loss: 2.5418493538744484

Epoch: 5| Step: 2
Training loss: 2.3125578383352385
Validation loss: 2.553172612145121

Epoch: 5| Step: 3
Training loss: 2.3733725744210834
Validation loss: 2.554482458598589

Epoch: 5| Step: 4
Training loss: 1.9189770567309146
Validation loss: 2.5609249376132794

Epoch: 5| Step: 5
Training loss: 2.1330588621163105
Validation loss: 2.572329331876081

Epoch: 5| Step: 6
Training loss: 2.608372844197728
Validation loss: 2.5641272774370423

Epoch: 5| Step: 7
Training loss: 1.8397978110763908
Validation loss: 2.5841077072071035

Epoch: 5| Step: 8
Training loss: 2.4958601052743514
Validation loss: 2.57581815684486

Epoch: 5| Step: 9
Training loss: 2.639488562548846
Validation loss: 2.591274688941681

Epoch: 5| Step: 10
Training loss: 2.2633732622619958
Validation loss: 2.5913654496303984

Epoch: 5| Step: 11
Training loss: 1.999169773397805
Validation loss: 2.567568240622337

Epoch: 298| Step: 0
Training loss: 2.716130364807693
Validation loss: 2.560072303243906

Epoch: 5| Step: 1
Training loss: 2.174979755702021
Validation loss: 2.543005298951499

Epoch: 5| Step: 2
Training loss: 1.8574236078585173
Validation loss: 2.545423999277721

Epoch: 5| Step: 3
Training loss: 2.039600520569727
Validation loss: 2.531896222202262

Epoch: 5| Step: 4
Training loss: 2.075064334101866
Validation loss: 2.5211634078291505

Epoch: 5| Step: 5
Training loss: 2.4915095157460714
Validation loss: 2.5270144893224304

Epoch: 5| Step: 6
Training loss: 1.942794456993334
Validation loss: 2.5232584548277392

Epoch: 5| Step: 7
Training loss: 2.2748865707122485
Validation loss: 2.5051456940579486

Epoch: 5| Step: 8
Training loss: 2.261840500791178
Validation loss: 2.528018360222919

Epoch: 5| Step: 9
Training loss: 2.5665758793945566
Validation loss: 2.555778876915306

Epoch: 5| Step: 10
Training loss: 3.0291734642012007
Validation loss: 2.528702050057869

Epoch: 5| Step: 11
Training loss: 2.562047313619587
Validation loss: 2.56845510326145

Epoch: 299| Step: 0
Training loss: 2.0216822725444783
Validation loss: 2.576577195911588

Epoch: 5| Step: 1
Training loss: 2.340588280831597
Validation loss: 2.584468870137969

Epoch: 5| Step: 2
Training loss: 1.8654589452916415
Validation loss: 2.58074704936145

Epoch: 5| Step: 3
Training loss: 2.0048747259944077
Validation loss: 2.610554141275622

Epoch: 5| Step: 4
Training loss: 2.509872208643927
Validation loss: 2.5756893443545104

Epoch: 5| Step: 5
Training loss: 2.481096035194558
Validation loss: 2.566665257003529

Epoch: 5| Step: 6
Training loss: 2.5961351573304023
Validation loss: 2.561888668361663

Epoch: 5| Step: 7
Training loss: 2.5074800169919627
Validation loss: 2.5454716004537215

Epoch: 5| Step: 8
Training loss: 2.360866252195239
Validation loss: 2.5329395824746386

Epoch: 5| Step: 9
Training loss: 2.3080572805585557
Validation loss: 2.5370250959056047

Epoch: 5| Step: 10
Training loss: 2.6045855579438935
Validation loss: 2.532075998361457

Epoch: 5| Step: 11
Training loss: 2.2662821901773698
Validation loss: 2.524334207891359

Epoch: 300| Step: 0
Training loss: 2.181682589681446
Validation loss: 2.54323774517695

Epoch: 5| Step: 1
Training loss: 1.8855965951734253
Validation loss: 2.51613235096263

Epoch: 5| Step: 2
Training loss: 1.9629469830217772
Validation loss: 2.522544033421082

Epoch: 5| Step: 3
Training loss: 1.8520036646639857
Validation loss: 2.5279897289764115

Epoch: 5| Step: 4
Training loss: 2.410206897766053
Validation loss: 2.5373195554281858

Epoch: 5| Step: 5
Training loss: 2.5529510476140493
Validation loss: 2.5574491935324732

Epoch: 5| Step: 6
Training loss: 2.58615895040507
Validation loss: 2.571723929225262

Epoch: 5| Step: 7
Training loss: 2.687231981974215
Validation loss: 2.5906327140518397

Epoch: 5| Step: 8
Training loss: 2.2647753996994897
Validation loss: 2.5700627933245155

Epoch: 5| Step: 9
Training loss: 2.84210929070944
Validation loss: 2.5686839586355408

Epoch: 5| Step: 10
Training loss: 2.234304467001628
Validation loss: 2.5483279637556056

Epoch: 5| Step: 11
Training loss: 2.7654486131185507
Validation loss: 2.540341103251528

Epoch: 301| Step: 0
Training loss: 2.4717059245199717
Validation loss: 2.5350339964869955

Epoch: 5| Step: 1
Training loss: 2.0366258349074218
Validation loss: 2.5401163916847365

Epoch: 5| Step: 2
Training loss: 2.2645467362755767
Validation loss: 2.548902788688564

Epoch: 5| Step: 3
Training loss: 1.9003039317729078
Validation loss: 2.534424737488498

Epoch: 5| Step: 4
Training loss: 2.387832007366526
Validation loss: 2.5617298581633956

Epoch: 5| Step: 5
Training loss: 2.641845601597153
Validation loss: 2.55382390255643

Epoch: 5| Step: 6
Training loss: 2.2796882613705676
Validation loss: 2.542765174135593

Epoch: 5| Step: 7
Training loss: 2.243304569160115
Validation loss: 2.51951372401724

Epoch: 5| Step: 8
Training loss: 2.1118888286895343
Validation loss: 2.5409253334308044

Epoch: 5| Step: 9
Training loss: 2.388225972312989
Validation loss: 2.5215306552350034

Epoch: 5| Step: 10
Training loss: 2.816674419445075
Validation loss: 2.523295541240515

Epoch: 5| Step: 11
Training loss: 2.635663127808828
Validation loss: 2.5670713146477158

Epoch: 302| Step: 0
Training loss: 2.714173246505893
Validation loss: 2.5652134047483175

Epoch: 5| Step: 1
Training loss: 2.727551037864196
Validation loss: 2.606681002206928

Epoch: 5| Step: 2
Training loss: 2.560493800401026
Validation loss: 2.616501797100616

Epoch: 5| Step: 3
Training loss: 2.2809788791024834
Validation loss: 2.633617229087306

Epoch: 5| Step: 4
Training loss: 2.41056743558041
Validation loss: 2.5979945371245874

Epoch: 5| Step: 5
Training loss: 1.9305251924915676
Validation loss: 2.6064507817991958

Epoch: 5| Step: 6
Training loss: 2.0432867382559565
Validation loss: 2.6086493985163237

Epoch: 5| Step: 7
Training loss: 2.6177344818165307
Validation loss: 2.597401232140433

Epoch: 5| Step: 8
Training loss: 1.9582379365235572
Validation loss: 2.566169406562451

Epoch: 5| Step: 9
Training loss: 2.118011539467417
Validation loss: 2.5507720316184344

Epoch: 5| Step: 10
Training loss: 2.3379273375876855
Validation loss: 2.556627530461974

Epoch: 5| Step: 11
Training loss: 2.1457364946260564
Validation loss: 2.5667885273536575

Epoch: 303| Step: 0
Training loss: 2.4543718218801045
Validation loss: 2.547928913853287

Epoch: 5| Step: 1
Training loss: 2.223788812565583
Validation loss: 2.544765246068458

Epoch: 5| Step: 2
Training loss: 2.0056380434881107
Validation loss: 2.5537927987646167

Epoch: 5| Step: 3
Training loss: 1.993217291861804
Validation loss: 2.5585097515110964

Epoch: 5| Step: 4
Training loss: 2.3847882193979815
Validation loss: 2.5487479244783118

Epoch: 5| Step: 5
Training loss: 2.403441338125003
Validation loss: 2.556003041295932

Epoch: 5| Step: 6
Training loss: 2.3341456656809023
Validation loss: 2.579983324710422

Epoch: 5| Step: 7
Training loss: 3.0490109512868093
Validation loss: 2.576369298504577

Epoch: 5| Step: 8
Training loss: 2.5829247387397203
Validation loss: 2.566816946425388

Epoch: 5| Step: 9
Training loss: 1.8246773708955444
Validation loss: 2.5541469690414855

Epoch: 5| Step: 10
Training loss: 2.268735027001104
Validation loss: 2.5591888259879414

Epoch: 5| Step: 11
Training loss: 1.2727161072575657
Validation loss: 2.557638701583529

Epoch: 304| Step: 0
Training loss: 2.1771369696281133
Validation loss: 2.5678182014859163

Epoch: 5| Step: 1
Training loss: 2.670721686336242
Validation loss: 2.567745635333651

Epoch: 5| Step: 2
Training loss: 2.303255625608715
Validation loss: 2.6030791656806462

Epoch: 5| Step: 3
Training loss: 2.4389232490666135
Validation loss: 2.577721358018444

Epoch: 5| Step: 4
Training loss: 2.52288557222978
Validation loss: 2.5813054821588057

Epoch: 5| Step: 5
Training loss: 2.089784653443056
Validation loss: 2.5586765965063143

Epoch: 5| Step: 6
Training loss: 1.6459570568596626
Validation loss: 2.544888882387789

Epoch: 5| Step: 7
Training loss: 2.6745958361611017
Validation loss: 2.5378024921612132

Epoch: 5| Step: 8
Training loss: 2.251912999188536
Validation loss: 2.5122027210214686

Epoch: 5| Step: 9
Training loss: 1.606666953151461
Validation loss: 2.5197593171743846

Epoch: 5| Step: 10
Training loss: 2.9343416807255362
Validation loss: 2.5263801675626985

Epoch: 5| Step: 11
Training loss: 2.177067977145366
Validation loss: 2.5307246200626405

Epoch: 305| Step: 0
Training loss: 2.0377859745718196
Validation loss: 2.552041292168653

Epoch: 5| Step: 1
Training loss: 2.102627055607614
Validation loss: 2.57101495375353

Epoch: 5| Step: 2
Training loss: 2.430557536775296
Validation loss: 2.600230508911534

Epoch: 5| Step: 3
Training loss: 2.366281468201822
Validation loss: 2.6448317807312987

Epoch: 5| Step: 4
Training loss: 3.034828512006904
Validation loss: 2.63054748967174

Epoch: 5| Step: 5
Training loss: 2.406685430589196
Validation loss: 2.621014555460958

Epoch: 5| Step: 6
Training loss: 2.2375340038251768
Validation loss: 2.5868509221774754

Epoch: 5| Step: 7
Training loss: 2.249897212753628
Validation loss: 2.567631023292886

Epoch: 5| Step: 8
Training loss: 2.4097876367353614
Validation loss: 2.5423462472535734

Epoch: 5| Step: 9
Training loss: 2.2464619475724197
Validation loss: 2.517655376613392

Epoch: 5| Step: 10
Training loss: 1.9980763482598312
Validation loss: 2.5249279234610995

Epoch: 5| Step: 11
Training loss: 1.9290747654270168
Validation loss: 2.515361653635702

Epoch: 306| Step: 0
Training loss: 2.0665515062589757
Validation loss: 2.5299920539454748

Epoch: 5| Step: 1
Training loss: 2.3039962507786975
Validation loss: 2.5084046351056166

Epoch: 5| Step: 2
Training loss: 2.89033647076696
Validation loss: 2.506674511314691

Epoch: 5| Step: 3
Training loss: 1.531435974660865
Validation loss: 2.5181713209375785

Epoch: 5| Step: 4
Training loss: 2.5461078260652443
Validation loss: 2.5420790374257702

Epoch: 5| Step: 5
Training loss: 2.425603543712272
Validation loss: 2.57003247359895

Epoch: 5| Step: 6
Training loss: 2.006934304158583
Validation loss: 2.5871788917542977

Epoch: 5| Step: 7
Training loss: 2.303227366187282
Validation loss: 2.60787611301517

Epoch: 5| Step: 8
Training loss: 2.11501637301409
Validation loss: 2.624504682191391

Epoch: 5| Step: 9
Training loss: 2.7140241744300786
Validation loss: 2.6222141446635283

Epoch: 5| Step: 10
Training loss: 2.675486304741235
Validation loss: 2.615813810521343

Epoch: 5| Step: 11
Training loss: 2.578712535147767
Validation loss: 2.5838079490800863

Epoch: 307| Step: 0
Training loss: 2.2358861761380573
Validation loss: 2.6081226450152797

Epoch: 5| Step: 1
Training loss: 2.1485830916578053
Validation loss: 2.603262455682005

Epoch: 5| Step: 2
Training loss: 2.61950380678987
Validation loss: 2.6119761265704997

Epoch: 5| Step: 3
Training loss: 2.5165855516746705
Validation loss: 2.582687096494733

Epoch: 5| Step: 4
Training loss: 2.723982762846556
Validation loss: 2.5909703960484403

Epoch: 5| Step: 5
Training loss: 2.7754138191215025
Validation loss: 2.5581152315603335

Epoch: 5| Step: 6
Training loss: 1.5152380537837609
Validation loss: 2.591580414231153

Epoch: 5| Step: 7
Training loss: 2.5358518048918572
Validation loss: 2.5656527531277016

Epoch: 5| Step: 8
Training loss: 2.0169406116311825
Validation loss: 2.5872033546546516

Epoch: 5| Step: 9
Training loss: 2.5756454103360493
Validation loss: 2.587687895889436

Epoch: 5| Step: 10
Training loss: 1.747385728999191
Validation loss: 2.5787855939616766

Epoch: 5| Step: 11
Training loss: 1.3734264039165323
Validation loss: 2.566497890127209

Epoch: 308| Step: 0
Training loss: 2.2327583706850174
Validation loss: 2.549957243554686

Epoch: 5| Step: 1
Training loss: 2.2689698882511165
Validation loss: 2.55193581576462

Epoch: 5| Step: 2
Training loss: 2.4949817837220247
Validation loss: 2.541690866688654

Epoch: 5| Step: 3
Training loss: 1.6890268835499607
Validation loss: 2.5607027170809595

Epoch: 5| Step: 4
Training loss: 1.8226503740813584
Validation loss: 2.5494956203367467

Epoch: 5| Step: 5
Training loss: 2.7569741333698277
Validation loss: 2.566725042895117

Epoch: 5| Step: 6
Training loss: 2.3556905107505495
Validation loss: 2.565946912375411

Epoch: 5| Step: 7
Training loss: 2.50812564213904
Validation loss: 2.563166427017066

Epoch: 5| Step: 8
Training loss: 2.2983744391549945
Validation loss: 2.5628537887486593

Epoch: 5| Step: 9
Training loss: 2.173026678336735
Validation loss: 2.597188807140504

Epoch: 5| Step: 10
Training loss: 3.018223092986681
Validation loss: 2.589540938544144

Epoch: 5| Step: 11
Training loss: 1.444603658525275
Validation loss: 2.59804072773417

Epoch: 309| Step: 0
Training loss: 1.9763182236575385
Validation loss: 2.597461752434021

Epoch: 5| Step: 1
Training loss: 2.1195252522131667
Validation loss: 2.5891383549611895

Epoch: 5| Step: 2
Training loss: 2.413903092241466
Validation loss: 2.568388790063704

Epoch: 5| Step: 3
Training loss: 1.9183709680404641
Validation loss: 2.547882996152378

Epoch: 5| Step: 4
Training loss: 3.115314886792677
Validation loss: 2.5519348114289255

Epoch: 5| Step: 5
Training loss: 2.212091798357186
Validation loss: 2.5203370217858563

Epoch: 5| Step: 6
Training loss: 2.4239433070625376
Validation loss: 2.5370836303125204

Epoch: 5| Step: 7
Training loss: 2.1069208633197385
Validation loss: 2.5600124628786864

Epoch: 5| Step: 8
Training loss: 1.680208205309597
Validation loss: 2.552265769250644

Epoch: 5| Step: 9
Training loss: 2.613312086713149
Validation loss: 2.5604374404128643

Epoch: 5| Step: 10
Training loss: 2.7986064644757347
Validation loss: 2.563679892574764

Epoch: 5| Step: 11
Training loss: 1.2138626700061756
Validation loss: 2.5745060190730666

Epoch: 310| Step: 0
Training loss: 2.0857046618864787
Validation loss: 2.566520568376311

Epoch: 5| Step: 1
Training loss: 2.1008575278067605
Validation loss: 2.5813526256317516

Epoch: 5| Step: 2
Training loss: 2.566515312025781
Validation loss: 2.5937817697992256

Epoch: 5| Step: 3
Training loss: 2.7531133714272276
Validation loss: 2.6078013549956616

Epoch: 5| Step: 4
Training loss: 1.9912982227451415
Validation loss: 2.6115372411652054

Epoch: 5| Step: 5
Training loss: 1.949902982010056
Validation loss: 2.6059013057204483

Epoch: 5| Step: 6
Training loss: 2.596878738492439
Validation loss: 2.5791874555531575

Epoch: 5| Step: 7
Training loss: 2.1584006378795
Validation loss: 2.582511010855842

Epoch: 5| Step: 8
Training loss: 2.137102333242717
Validation loss: 2.5606275012806607

Epoch: 5| Step: 9
Training loss: 2.6258145839546785
Validation loss: 2.5290884867362613

Epoch: 5| Step: 10
Training loss: 2.354761729244314
Validation loss: 2.5121801772194567

Epoch: 5| Step: 11
Training loss: 3.351415670953354
Validation loss: 2.5223051114846617

Epoch: 311| Step: 0
Training loss: 1.9938307025325215
Validation loss: 2.5144995566926696

Epoch: 5| Step: 1
Training loss: 2.4057788139836846
Validation loss: 2.511023647220802

Epoch: 5| Step: 2
Training loss: 3.232374964255524
Validation loss: 2.51352365961329

Epoch: 5| Step: 3
Training loss: 2.5741167757388905
Validation loss: 2.503530510826256

Epoch: 5| Step: 4
Training loss: 2.4583869432541436
Validation loss: 2.51646267230482

Epoch: 5| Step: 5
Training loss: 2.1086123747990673
Validation loss: 2.533864754749117

Epoch: 5| Step: 6
Training loss: 2.076469278072941
Validation loss: 2.5371472652230342

Epoch: 5| Step: 7
Training loss: 2.3753608630234986
Validation loss: 2.555102478915934

Epoch: 5| Step: 8
Training loss: 1.948172064644993
Validation loss: 2.5826668699993447

Epoch: 5| Step: 9
Training loss: 2.6165918384065785
Validation loss: 2.5815696130499184

Epoch: 5| Step: 10
Training loss: 2.044417325418167
Validation loss: 2.57037108025084

Epoch: 5| Step: 11
Training loss: 1.7458572398197554
Validation loss: 2.5559946695912936

Epoch: 312| Step: 0
Training loss: 2.027720039741757
Validation loss: 2.571978507386698

Epoch: 5| Step: 1
Training loss: 2.941617150110583
Validation loss: 2.538149762546733

Epoch: 5| Step: 2
Training loss: 1.9432463799986057
Validation loss: 2.5324036947807276

Epoch: 5| Step: 3
Training loss: 2.0211018518286226
Validation loss: 2.5114895709634677

Epoch: 5| Step: 4
Training loss: 1.822236121164726
Validation loss: 2.51624336698504

Epoch: 5| Step: 5
Training loss: 3.2047091404757513
Validation loss: 2.5103151622738946

Epoch: 5| Step: 6
Training loss: 2.0718589908677547
Validation loss: 2.511561252843188

Epoch: 5| Step: 7
Training loss: 2.1190260895747226
Validation loss: 2.519478312880065

Epoch: 5| Step: 8
Training loss: 1.920875351364194
Validation loss: 2.5137219151098233

Epoch: 5| Step: 9
Training loss: 2.397334438490622
Validation loss: 2.516186410640832

Epoch: 5| Step: 10
Training loss: 2.424833791483614
Validation loss: 2.538700981812639

Epoch: 5| Step: 11
Training loss: 3.610074458529958
Validation loss: 2.566101994858444

Epoch: 313| Step: 0
Training loss: 1.8064860839730084
Validation loss: 2.6071675475404636

Epoch: 5| Step: 1
Training loss: 2.5460076288556968
Validation loss: 2.6205391313650184

Epoch: 5| Step: 2
Training loss: 2.3440151827519027
Validation loss: 2.626285571208912

Epoch: 5| Step: 3
Training loss: 2.2411106195209203
Validation loss: 2.610771700063303

Epoch: 5| Step: 4
Training loss: 2.482361655476559
Validation loss: 2.6383805338837862

Epoch: 5| Step: 5
Training loss: 2.5888264817268527
Validation loss: 2.5871334556515997

Epoch: 5| Step: 6
Training loss: 2.113718266172775
Validation loss: 2.5667482958132477

Epoch: 5| Step: 7
Training loss: 1.9610926350175601
Validation loss: 2.540506458997008

Epoch: 5| Step: 8
Training loss: 2.6086042716427333
Validation loss: 2.5324588840206

Epoch: 5| Step: 9
Training loss: 2.2346203009128214
Validation loss: 2.5119468897808166

Epoch: 5| Step: 10
Training loss: 2.3300775110670817
Validation loss: 2.508107588886837

Epoch: 5| Step: 11
Training loss: 2.3221852358418285
Validation loss: 2.492865885659891

Epoch: 314| Step: 0
Training loss: 2.821061729602272
Validation loss: 2.494707903852825

Epoch: 5| Step: 1
Training loss: 1.825019807577421
Validation loss: 2.5025882555045293

Epoch: 5| Step: 2
Training loss: 2.2745440434895796
Validation loss: 2.500762656231214

Epoch: 5| Step: 3
Training loss: 2.1973557924207694
Validation loss: 2.4914934393673698

Epoch: 5| Step: 4
Training loss: 2.1540256028561986
Validation loss: 2.48767046016876

Epoch: 5| Step: 5
Training loss: 2.1145809781166327
Validation loss: 2.493168696513628

Epoch: 5| Step: 6
Training loss: 2.1226672664015287
Validation loss: 2.4991020139599627

Epoch: 5| Step: 7
Training loss: 2.3437801104836664
Validation loss: 2.508781938949852

Epoch: 5| Step: 8
Training loss: 2.96905403588095
Validation loss: 2.5129692559887187

Epoch: 5| Step: 9
Training loss: 2.416189793420287
Validation loss: 2.531307486678026

Epoch: 5| Step: 10
Training loss: 2.519562098587796
Validation loss: 2.5366775344869805

Epoch: 5| Step: 11
Training loss: 1.6497878198313465
Validation loss: 2.554460875154493

Epoch: 315| Step: 0
Training loss: 2.6024739269815744
Validation loss: 2.5953906818199006

Epoch: 5| Step: 1
Training loss: 2.4371635009116193
Validation loss: 2.5977643021599883

Epoch: 5| Step: 2
Training loss: 2.8840182297615886
Validation loss: 2.576563491343008

Epoch: 5| Step: 3
Training loss: 2.2752018011110153
Validation loss: 2.5729701632499307

Epoch: 5| Step: 4
Training loss: 2.141242168031389
Validation loss: 2.5629515056281535

Epoch: 5| Step: 5
Training loss: 2.0260664309938834
Validation loss: 2.54541862521021

Epoch: 5| Step: 6
Training loss: 1.8934611336239986
Validation loss: 2.538830086268023

Epoch: 5| Step: 7
Training loss: 2.33679010147746
Validation loss: 2.559779091104005

Epoch: 5| Step: 8
Training loss: 2.733316096584897
Validation loss: 2.5513580628142627

Epoch: 5| Step: 9
Training loss: 2.549394356106324
Validation loss: 2.5626382557858394

Epoch: 5| Step: 10
Training loss: 1.9007897266680274
Validation loss: 2.5885957345106605

Epoch: 5| Step: 11
Training loss: 1.5309612235422922
Validation loss: 2.562592062808289

Epoch: 316| Step: 0
Training loss: 2.6439500448958535
Validation loss: 2.571074963059278

Epoch: 5| Step: 1
Training loss: 1.7178171574080288
Validation loss: 2.5697185618580534

Epoch: 5| Step: 2
Training loss: 3.091455398566061
Validation loss: 2.580491026442369

Epoch: 5| Step: 3
Training loss: 2.3539947401974883
Validation loss: 2.606011230789522

Epoch: 5| Step: 4
Training loss: 2.1012593444217043
Validation loss: 2.604535505241854

Epoch: 5| Step: 5
Training loss: 1.4606014415977788
Validation loss: 2.5891065320215283

Epoch: 5| Step: 6
Training loss: 2.508316322176038
Validation loss: 2.5582107179585054

Epoch: 5| Step: 7
Training loss: 2.0838118448673746
Validation loss: 2.5264330898242298

Epoch: 5| Step: 8
Training loss: 2.4897437476240416
Validation loss: 2.5401604806835425

Epoch: 5| Step: 9
Training loss: 2.527829909107304
Validation loss: 2.5225230588511196

Epoch: 5| Step: 10
Training loss: 2.2516398282243415
Validation loss: 2.533935072503378

Epoch: 5| Step: 11
Training loss: 0.9984989224973929
Validation loss: 2.5337411882096417

Epoch: 317| Step: 0
Training loss: 2.732261494857646
Validation loss: 2.524503610622609

Epoch: 5| Step: 1
Training loss: 2.304725775966587
Validation loss: 2.547204376640286

Epoch: 5| Step: 2
Training loss: 2.2507324086338336
Validation loss: 2.573972519485941

Epoch: 5| Step: 3
Training loss: 2.8903765597417395
Validation loss: 2.5866124635069174

Epoch: 5| Step: 4
Training loss: 2.115495519465167
Validation loss: 2.6269167834938805

Epoch: 5| Step: 5
Training loss: 2.2382982929106823
Validation loss: 2.6284262722998464

Epoch: 5| Step: 6
Training loss: 2.1758279298880594
Validation loss: 2.6179780743435828

Epoch: 5| Step: 7
Training loss: 1.9643526771823316
Validation loss: 2.632960970924855

Epoch: 5| Step: 8
Training loss: 1.9199319957571177
Validation loss: 2.584030767991695

Epoch: 5| Step: 9
Training loss: 2.337157068239337
Validation loss: 2.5547200005473387

Epoch: 5| Step: 10
Training loss: 2.5464538038712274
Validation loss: 2.5563711904013298

Epoch: 5| Step: 11
Training loss: 1.4723835902677156
Validation loss: 2.5535283156498743

Epoch: 318| Step: 0
Training loss: 1.7666656668078393
Validation loss: 2.5451097982587845

Epoch: 5| Step: 1
Training loss: 1.9024769072566041
Validation loss: 2.5161318534937016

Epoch: 5| Step: 2
Training loss: 2.4490896674641753
Validation loss: 2.5139869427277395

Epoch: 5| Step: 3
Training loss: 2.6871633096975365
Validation loss: 2.502045958496852

Epoch: 5| Step: 4
Training loss: 2.630055690654402
Validation loss: 2.506797161131802

Epoch: 5| Step: 5
Training loss: 2.4728218975295926
Validation loss: 2.5097024516307576

Epoch: 5| Step: 6
Training loss: 2.0381542536166504
Validation loss: 2.516849811997234

Epoch: 5| Step: 7
Training loss: 2.8426169349418786
Validation loss: 2.5303027751148863

Epoch: 5| Step: 8
Training loss: 2.232838669363952
Validation loss: 2.5362378023899916

Epoch: 5| Step: 9
Training loss: 2.0111449376956156
Validation loss: 2.5453654068892186

Epoch: 5| Step: 10
Training loss: 2.180480484638737
Validation loss: 2.5529337958088143

Epoch: 5| Step: 11
Training loss: 1.8611441778531925
Validation loss: 2.5650065537419167

Epoch: 319| Step: 0
Training loss: 2.082514093175051
Validation loss: 2.560424906534004

Epoch: 5| Step: 1
Training loss: 2.28065106616148
Validation loss: 2.5814587087669176

Epoch: 5| Step: 2
Training loss: 2.434063959389407
Validation loss: 2.5633491450538477

Epoch: 5| Step: 3
Training loss: 2.357484578054881
Validation loss: 2.5901497707549392

Epoch: 5| Step: 4
Training loss: 2.0549112060372012
Validation loss: 2.619693163972162

Epoch: 5| Step: 5
Training loss: 2.1956946423890473
Validation loss: 2.6302854822508617

Epoch: 5| Step: 6
Training loss: 1.751523240506126
Validation loss: 2.602238969039979

Epoch: 5| Step: 7
Training loss: 3.45019158094017
Validation loss: 2.5799557148813084

Epoch: 5| Step: 8
Training loss: 2.0243424560719876
Validation loss: 2.603001197688877

Epoch: 5| Step: 9
Training loss: 1.9989494306304127
Validation loss: 2.5805101632130776

Epoch: 5| Step: 10
Training loss: 2.4315176691428757
Validation loss: 2.5404939382295963

Epoch: 5| Step: 11
Training loss: 1.2624790038827383
Validation loss: 2.525897699690887

Epoch: 320| Step: 0
Training loss: 2.472483069937574
Validation loss: 2.504490384004014

Epoch: 5| Step: 1
Training loss: 2.3158258801432186
Validation loss: 2.509813589783134

Epoch: 5| Step: 2
Training loss: 2.0528603904365466
Validation loss: 2.5058799578286433

Epoch: 5| Step: 3
Training loss: 2.505236101426203
Validation loss: 2.5041738080532756

Epoch: 5| Step: 4
Training loss: 2.2328714500424227
Validation loss: 2.5060898319793052

Epoch: 5| Step: 5
Training loss: 2.7412112854025428
Validation loss: 2.5033897307536774

Epoch: 5| Step: 6
Training loss: 2.250789291965957
Validation loss: 2.519612648607657

Epoch: 5| Step: 7
Training loss: 2.727976347728453
Validation loss: 2.51828355378702

Epoch: 5| Step: 8
Training loss: 1.851091155888123
Validation loss: 2.535240900774735

Epoch: 5| Step: 9
Training loss: 1.7755167866984594
Validation loss: 2.5370558218410095

Epoch: 5| Step: 10
Training loss: 2.5809244389312633
Validation loss: 2.5658265828011513

Epoch: 5| Step: 11
Training loss: 1.2498712473363858
Validation loss: 2.604441465502049

Epoch: 321| Step: 0
Training loss: 2.0127334554094376
Validation loss: 2.6538076055080957

Epoch: 5| Step: 1
Training loss: 2.388783662040831
Validation loss: 2.713376705893466

Epoch: 5| Step: 2
Training loss: 2.5650104228025454
Validation loss: 2.6824754349554643

Epoch: 5| Step: 3
Training loss: 2.9376564795838562
Validation loss: 2.668910957205572

Epoch: 5| Step: 4
Training loss: 2.5252321079950786
Validation loss: 2.686338817003258

Epoch: 5| Step: 5
Training loss: 2.0930832897369083
Validation loss: 2.6234932124674892

Epoch: 5| Step: 6
Training loss: 2.414652039474989
Validation loss: 2.5957189463297574

Epoch: 5| Step: 7
Training loss: 2.2000670076049182
Validation loss: 2.5575327374378825

Epoch: 5| Step: 8
Training loss: 2.7358831115928677
Validation loss: 2.572429202822932

Epoch: 5| Step: 9
Training loss: 1.8220479003103598
Validation loss: 2.5487895119812762

Epoch: 5| Step: 10
Training loss: 2.222169417177758
Validation loss: 2.5430278429391477

Epoch: 5| Step: 11
Training loss: 1.1070282520800092
Validation loss: 2.5593296419626146

Epoch: 322| Step: 0
Training loss: 2.2241937183704072
Validation loss: 2.545307730335991

Epoch: 5| Step: 1
Training loss: 2.486930828057443
Validation loss: 2.544711627604563

Epoch: 5| Step: 2
Training loss: 1.983994334797308
Validation loss: 2.549802645981126

Epoch: 5| Step: 3
Training loss: 2.4715751224918505
Validation loss: 2.5627621229752884

Epoch: 5| Step: 4
Training loss: 2.2624884631458166
Validation loss: 2.554381322060305

Epoch: 5| Step: 5
Training loss: 2.5379154372620683
Validation loss: 2.5431034659912033

Epoch: 5| Step: 6
Training loss: 1.8220812018354597
Validation loss: 2.5501245273464805

Epoch: 5| Step: 7
Training loss: 2.547190453587667
Validation loss: 2.541814793246622

Epoch: 5| Step: 8
Training loss: 2.5586173253028845
Validation loss: 2.5675035102248223

Epoch: 5| Step: 9
Training loss: 2.1888499862690765
Validation loss: 2.5491751404162413

Epoch: 5| Step: 10
Training loss: 2.2861912136122284
Validation loss: 2.56335278409003

Epoch: 5| Step: 11
Training loss: 2.237341452154555
Validation loss: 2.5909445845823367

Epoch: 323| Step: 0
Training loss: 2.7543487842576866
Validation loss: 2.5660428003204023

Epoch: 5| Step: 1
Training loss: 2.199619182225406
Validation loss: 2.5749610367083227

Epoch: 5| Step: 2
Training loss: 2.574767730014766
Validation loss: 2.553855962871823

Epoch: 5| Step: 3
Training loss: 1.3693433059235143
Validation loss: 2.557970999139486

Epoch: 5| Step: 4
Training loss: 2.7088649423643214
Validation loss: 2.556740333627506

Epoch: 5| Step: 5
Training loss: 2.916619291374915
Validation loss: 2.561563945008344

Epoch: 5| Step: 6
Training loss: 2.3181119303104745
Validation loss: 2.532769508475455

Epoch: 5| Step: 7
Training loss: 2.193336547841477
Validation loss: 2.556618737267197

Epoch: 5| Step: 8
Training loss: 2.3235155596572272
Validation loss: 2.533378993007704

Epoch: 5| Step: 9
Training loss: 1.613380780047789
Validation loss: 2.5298223354697753

Epoch: 5| Step: 10
Training loss: 2.1652514775492135
Validation loss: 2.530163739877927

Epoch: 5| Step: 11
Training loss: 1.4480116101795322
Validation loss: 2.5555462361219963

Epoch: 324| Step: 0
Training loss: 2.4480665986158434
Validation loss: 2.5453806668765036

Epoch: 5| Step: 1
Training loss: 3.025480147158399
Validation loss: 2.5442401737069487

Epoch: 5| Step: 2
Training loss: 1.7994536100377065
Validation loss: 2.5635959018600514

Epoch: 5| Step: 3
Training loss: 1.9918753585120872
Validation loss: 2.5295809199669836

Epoch: 5| Step: 4
Training loss: 2.2385570096613914
Validation loss: 2.5480569386540575

Epoch: 5| Step: 5
Training loss: 2.0139208546290286
Validation loss: 2.5912268250553567

Epoch: 5| Step: 6
Training loss: 2.389479219207792
Validation loss: 2.6020952200535366

Epoch: 5| Step: 7
Training loss: 2.4051608308242813
Validation loss: 2.6105736665227592

Epoch: 5| Step: 8
Training loss: 2.6402773656504195
Validation loss: 2.623992688806067

Epoch: 5| Step: 9
Training loss: 2.351335178679883
Validation loss: 2.578247718587597

Epoch: 5| Step: 10
Training loss: 2.1780311553310088
Validation loss: 2.5534217315742196

Epoch: 5| Step: 11
Training loss: 1.5257588233998902
Validation loss: 2.5722581017996555

Epoch: 325| Step: 0
Training loss: 2.4504576352949847
Validation loss: 2.5392631960069596

Epoch: 5| Step: 1
Training loss: 2.6961168056619784
Validation loss: 2.5252395077222958

Epoch: 5| Step: 2
Training loss: 2.516782316704266
Validation loss: 2.529012330691755

Epoch: 5| Step: 3
Training loss: 2.49351556961954
Validation loss: 2.5304178157217314

Epoch: 5| Step: 4
Training loss: 2.0129771028401784
Validation loss: 2.510525203801432

Epoch: 5| Step: 5
Training loss: 2.278288081105059
Validation loss: 2.521522007549826

Epoch: 5| Step: 6
Training loss: 2.465176180565358
Validation loss: 2.541903665832906

Epoch: 5| Step: 7
Training loss: 1.5565507161633139
Validation loss: 2.5364139691388936

Epoch: 5| Step: 8
Training loss: 2.027733443775672
Validation loss: 2.542033893342242

Epoch: 5| Step: 9
Training loss: 2.0868807028218117
Validation loss: 2.5488937038204136

Epoch: 5| Step: 10
Training loss: 2.3598962675346917
Validation loss: 2.589882725210915

Epoch: 5| Step: 11
Training loss: 2.973096857489044
Validation loss: 2.5816013441898766

Epoch: 326| Step: 0
Training loss: 1.4989323790289024
Validation loss: 2.622777266480671

Epoch: 5| Step: 1
Training loss: 2.4277070735215687
Validation loss: 2.6773883643327703

Epoch: 5| Step: 2
Training loss: 2.601803880095684
Validation loss: 2.663658861026952

Epoch: 5| Step: 3
Training loss: 2.3720961436235055
Validation loss: 2.6662820349901635

Epoch: 5| Step: 4
Training loss: 2.2436699303071634
Validation loss: 2.662952870671139

Epoch: 5| Step: 5
Training loss: 2.8272449957873893
Validation loss: 2.6762662239242188

Epoch: 5| Step: 6
Training loss: 2.494913362363403
Validation loss: 2.6476641475784453

Epoch: 5| Step: 7
Training loss: 2.2957184663019494
Validation loss: 2.645945641744761

Epoch: 5| Step: 8
Training loss: 2.221370063417773
Validation loss: 2.5788501914070845

Epoch: 5| Step: 9
Training loss: 2.4714009019608474
Validation loss: 2.5493234321221236

Epoch: 5| Step: 10
Training loss: 1.8786968027224213
Validation loss: 2.5194896724138753

Epoch: 5| Step: 11
Training loss: 1.2078068287705177
Validation loss: 2.507730579721753

Epoch: 327| Step: 0
Training loss: 2.6992653871694596
Validation loss: 2.502971190903387

Epoch: 5| Step: 1
Training loss: 3.1396255041444694
Validation loss: 2.506154836558711

Epoch: 5| Step: 2
Training loss: 2.286909425303822
Validation loss: 2.489995372996442

Epoch: 5| Step: 3
Training loss: 1.7592297075626444
Validation loss: 2.5084260524730757

Epoch: 5| Step: 4
Training loss: 2.792087485257149
Validation loss: 2.5113923378343497

Epoch: 5| Step: 5
Training loss: 2.7699174060282488
Validation loss: 2.5016400917881567

Epoch: 5| Step: 6
Training loss: 1.915676759702
Validation loss: 2.5238512249202234

Epoch: 5| Step: 7
Training loss: 2.1422907898289707
Validation loss: 2.526350338091633

Epoch: 5| Step: 8
Training loss: 2.238836569078778
Validation loss: 2.576245514861004

Epoch: 5| Step: 9
Training loss: 1.8888971930053282
Validation loss: 2.602401181994634

Epoch: 5| Step: 10
Training loss: 1.991534436463777
Validation loss: 2.635010964499287

Epoch: 5| Step: 11
Training loss: 2.268062674495719
Validation loss: 2.590156405886271

Epoch: 328| Step: 0
Training loss: 2.2429058771678827
Validation loss: 2.523610509683298

Epoch: 5| Step: 1
Training loss: 1.6950307866904273
Validation loss: 2.4961703691180217

Epoch: 5| Step: 2
Training loss: 2.4023999215358804
Validation loss: 2.497011611918861

Epoch: 5| Step: 3
Training loss: 2.774620126378226
Validation loss: 2.4967916067310876

Epoch: 5| Step: 4
Training loss: 1.9674877177028383
Validation loss: 2.4980787782717147

Epoch: 5| Step: 5
Training loss: 3.424787144416147
Validation loss: 2.505910811933267

Epoch: 5| Step: 6
Training loss: 2.4342672968141494
Validation loss: 2.503651213688099

Epoch: 5| Step: 7
Training loss: 2.1683521928292038
Validation loss: 2.4987369466055505

Epoch: 5| Step: 8
Training loss: 3.0326783266020154
Validation loss: 2.48785462607215

Epoch: 5| Step: 9
Training loss: 2.2630452168288344
Validation loss: 2.494532841826187

Epoch: 5| Step: 10
Training loss: 1.8692985954217762
Validation loss: 2.4955555908298046

Epoch: 5| Step: 11
Training loss: 2.6306364309072077
Validation loss: 2.4798450076215572

Epoch: 329| Step: 0
Training loss: 2.2589118155617802
Validation loss: 2.4845237407503276

Epoch: 5| Step: 1
Training loss: 2.424782072676962
Validation loss: 2.505483050494395

Epoch: 5| Step: 2
Training loss: 2.1648240935508056
Validation loss: 2.4883751125388365

Epoch: 5| Step: 3
Training loss: 1.6868984421765079
Validation loss: 2.492230095095744

Epoch: 5| Step: 4
Training loss: 2.946865491962972
Validation loss: 2.5061931709892518

Epoch: 5| Step: 5
Training loss: 2.6435797598206117
Validation loss: 2.509152689104815

Epoch: 5| Step: 6
Training loss: 2.284466918264953
Validation loss: 2.5235722626879107

Epoch: 5| Step: 7
Training loss: 1.6840787750947066
Validation loss: 2.5269849739734993

Epoch: 5| Step: 8
Training loss: 2.984478214735936
Validation loss: 2.5505632401791005

Epoch: 5| Step: 9
Training loss: 2.439409730523764
Validation loss: 2.5522942799690846

Epoch: 5| Step: 10
Training loss: 1.9851358111641833
Validation loss: 2.5485524229406193

Epoch: 5| Step: 11
Training loss: 1.4283778962105702
Validation loss: 2.5550407997526725

Epoch: 330| Step: 0
Training loss: 2.4491402888773135
Validation loss: 2.5652853377339313

Epoch: 5| Step: 1
Training loss: 1.789610932758686
Validation loss: 2.558040176570947

Epoch: 5| Step: 2
Training loss: 2.1787478154445603
Validation loss: 2.553480218855154

Epoch: 5| Step: 3
Training loss: 2.558561694694236
Validation loss: 2.5714769865800338

Epoch: 5| Step: 4
Training loss: 2.4295446225072523
Validation loss: 2.5700701219551405

Epoch: 5| Step: 5
Training loss: 1.889236949504559
Validation loss: 2.5815758200086587

Epoch: 5| Step: 6
Training loss: 2.427837882133275
Validation loss: 2.562540840970976

Epoch: 5| Step: 7
Training loss: 2.335548291905355
Validation loss: 2.552993107520817

Epoch: 5| Step: 8
Training loss: 2.7732471669395045
Validation loss: 2.537866289107154

Epoch: 5| Step: 9
Training loss: 2.59683448585462
Validation loss: 2.517109020516537

Epoch: 5| Step: 10
Training loss: 1.8457236637002084
Validation loss: 2.5238368305953003

Epoch: 5| Step: 11
Training loss: 2.515704609813698
Validation loss: 2.508560683053183

Epoch: 331| Step: 0
Training loss: 2.25169615921294
Validation loss: 2.5050881939246508

Epoch: 5| Step: 1
Training loss: 2.4627409608942448
Validation loss: 2.505742685559969

Epoch: 5| Step: 2
Training loss: 1.91788738878395
Validation loss: 2.5139517698684113

Epoch: 5| Step: 3
Training loss: 2.4779037549999736
Validation loss: 2.5186436294642154

Epoch: 5| Step: 4
Training loss: 2.0291937176770145
Validation loss: 2.4998562890708804

Epoch: 5| Step: 5
Training loss: 2.2002214276981533
Validation loss: 2.5108664526518623

Epoch: 5| Step: 6
Training loss: 2.5646752219907323
Validation loss: 2.5215487148153777

Epoch: 5| Step: 7
Training loss: 2.2296930089827702
Validation loss: 2.5590019269339455

Epoch: 5| Step: 8
Training loss: 2.582278979907481
Validation loss: 2.5597388541804222

Epoch: 5| Step: 9
Training loss: 2.2687239926531584
Validation loss: 2.5869941281420497

Epoch: 5| Step: 10
Training loss: 2.078101710138819
Validation loss: 2.5938925378386184

Epoch: 5| Step: 11
Training loss: 3.567467154637035
Validation loss: 2.6376719280149308

Epoch: 332| Step: 0
Training loss: 2.683901040420322
Validation loss: 2.6039356485258653

Epoch: 5| Step: 1
Training loss: 2.128405926909472
Validation loss: 2.5829898364878394

Epoch: 5| Step: 2
Training loss: 2.752814932952128
Validation loss: 2.57098611355022

Epoch: 5| Step: 3
Training loss: 2.3613263075752933
Validation loss: 2.552188915222555

Epoch: 5| Step: 4
Training loss: 2.330055511697426
Validation loss: 2.551799580635736

Epoch: 5| Step: 5
Training loss: 2.2087803754029363
Validation loss: 2.5365983400863312

Epoch: 5| Step: 6
Training loss: 1.9191442177845848
Validation loss: 2.52544167986501

Epoch: 5| Step: 7
Training loss: 2.3621832700878977
Validation loss: 2.528649356000171

Epoch: 5| Step: 8
Training loss: 1.5021978806386378
Validation loss: 2.5039302211810215

Epoch: 5| Step: 9
Training loss: 2.1053899350392205
Validation loss: 2.5052232338719294

Epoch: 5| Step: 10
Training loss: 2.563268964808357
Validation loss: 2.5121940768160895

Epoch: 5| Step: 11
Training loss: 2.7928627260798327
Validation loss: 2.5126106770812244

Epoch: 333| Step: 0
Training loss: 2.355103117999535
Validation loss: 2.5117488323366017

Epoch: 5| Step: 1
Training loss: 1.9412916675426335
Validation loss: 2.5399093858820674

Epoch: 5| Step: 2
Training loss: 1.998014298785941
Validation loss: 2.534266052538452

Epoch: 5| Step: 3
Training loss: 2.7092211124139918
Validation loss: 2.5585249719281378

Epoch: 5| Step: 4
Training loss: 2.44580258464385
Validation loss: 2.581106196224027

Epoch: 5| Step: 5
Training loss: 1.8626131983414436
Validation loss: 2.590874909210191

Epoch: 5| Step: 6
Training loss: 2.3173086328927672
Validation loss: 2.590422832636505

Epoch: 5| Step: 7
Training loss: 1.89788270229708
Validation loss: 2.5716115766419168

Epoch: 5| Step: 8
Training loss: 2.8381928862496477
Validation loss: 2.5696960336069608

Epoch: 5| Step: 9
Training loss: 2.66079027683663
Validation loss: 2.529649909676576

Epoch: 5| Step: 10
Training loss: 2.2203369912414854
Validation loss: 2.5138699508595295

Epoch: 5| Step: 11
Training loss: 2.609588248853111
Validation loss: 2.520696460276235

Epoch: 334| Step: 0
Training loss: 2.2522760111784224
Validation loss: 2.5002592270286126

Epoch: 5| Step: 1
Training loss: 2.823386590748832
Validation loss: 2.49910803220992

Epoch: 5| Step: 2
Training loss: 2.581420549203358
Validation loss: 2.5053664902366166

Epoch: 5| Step: 3
Training loss: 2.2510655317287425
Validation loss: 2.515132895409797

Epoch: 5| Step: 4
Training loss: 1.6751833117939043
Validation loss: 2.5122050026754748

Epoch: 5| Step: 5
Training loss: 2.4717156668719213
Validation loss: 2.5352547719000404

Epoch: 5| Step: 6
Training loss: 2.2253350337810356
Validation loss: 2.5648288495144835

Epoch: 5| Step: 7
Training loss: 2.4026716303179603
Validation loss: 2.588501211626755

Epoch: 5| Step: 8
Training loss: 2.2379713659491602
Validation loss: 2.558023267826807

Epoch: 5| Step: 9
Training loss: 1.9172674011642556
Validation loss: 2.5554870303153336

Epoch: 5| Step: 10
Training loss: 2.604044695223037
Validation loss: 2.538021054037267

Epoch: 5| Step: 11
Training loss: 1.8900839922169828
Validation loss: 2.5507712079211218

Epoch: 335| Step: 0
Training loss: 2.0873918927918202
Validation loss: 2.5589825710879763

Epoch: 5| Step: 1
Training loss: 2.4127104593297313
Validation loss: 2.5740996252657458

Epoch: 5| Step: 2
Training loss: 2.002870169154692
Validation loss: 2.5960641671583664

Epoch: 5| Step: 3
Training loss: 2.4218475340239447
Validation loss: 2.5956055273839205

Epoch: 5| Step: 4
Training loss: 2.0469115741752684
Validation loss: 2.588960016371367

Epoch: 5| Step: 5
Training loss: 2.5357748960777022
Validation loss: 2.5540893429932074

Epoch: 5| Step: 6
Training loss: 3.447880832144002
Validation loss: 2.537697347787316

Epoch: 5| Step: 7
Training loss: 1.8596104064151342
Validation loss: 2.5454621208775388

Epoch: 5| Step: 8
Training loss: 1.902700026595058
Validation loss: 2.548490928278506

Epoch: 5| Step: 9
Training loss: 2.177420363431672
Validation loss: 2.5186532711137635

Epoch: 5| Step: 10
Training loss: 2.2665275091575805
Validation loss: 2.525511229099466

Epoch: 5| Step: 11
Training loss: 0.7339584305397104
Validation loss: 2.522891533745076

Epoch: 336| Step: 0
Training loss: 3.0540853623986792
Validation loss: 2.530246818399516

Epoch: 5| Step: 1
Training loss: 2.0465248332545203
Validation loss: 2.5542536998148364

Epoch: 5| Step: 2
Training loss: 2.376262028326086
Validation loss: 2.5598062297135336

Epoch: 5| Step: 3
Training loss: 2.6102983131785837
Validation loss: 2.581102224280988

Epoch: 5| Step: 4
Training loss: 2.2101400170483534
Validation loss: 2.560518820866221

Epoch: 5| Step: 5
Training loss: 1.8826573098200512
Validation loss: 2.5611891630818597

Epoch: 5| Step: 6
Training loss: 2.2267190443186906
Validation loss: 2.5415011662136506

Epoch: 5| Step: 7
Training loss: 2.050335354240826
Validation loss: 2.584712027207874

Epoch: 5| Step: 8
Training loss: 2.498102326184054
Validation loss: 2.6059647850019907

Epoch: 5| Step: 9
Training loss: 2.36667720720693
Validation loss: 2.671160719579538

Epoch: 5| Step: 10
Training loss: 1.9116371202832338
Validation loss: 2.6769657937950635

Epoch: 5| Step: 11
Training loss: 1.1821619822536025
Validation loss: 2.6837472922624332

Epoch: 337| Step: 0
Training loss: 2.0568160138964187
Validation loss: 2.6448517102315368

Epoch: 5| Step: 1
Training loss: 2.4109476975567103
Validation loss: 2.635817702065438

Epoch: 5| Step: 2
Training loss: 1.5627394683439078
Validation loss: 2.6489433323151275

Epoch: 5| Step: 3
Training loss: 3.0544561508260903
Validation loss: 2.602914350121973

Epoch: 5| Step: 4
Training loss: 2.5947923519134126
Validation loss: 2.586620947347348

Epoch: 5| Step: 5
Training loss: 1.9678250516648985
Validation loss: 2.5727379282490617

Epoch: 5| Step: 6
Training loss: 2.6917469268580048
Validation loss: 2.5698573280505053

Epoch: 5| Step: 7
Training loss: 2.183204902870709
Validation loss: 2.56035964634358

Epoch: 5| Step: 8
Training loss: 2.4054546280211277
Validation loss: 2.5343281314716526

Epoch: 5| Step: 9
Training loss: 1.8305712252370552
Validation loss: 2.526108779540043

Epoch: 5| Step: 10
Training loss: 1.8521052985360293
Validation loss: 2.531162668613277

Epoch: 5| Step: 11
Training loss: 2.581114451841894
Validation loss: 2.519959993379152

Epoch: 338| Step: 0
Training loss: 2.186172300411704
Validation loss: 2.52541880580818

Epoch: 5| Step: 1
Training loss: 2.0669136217705955
Validation loss: 2.5481510982965587

Epoch: 5| Step: 2
Training loss: 2.8017687047757946
Validation loss: 2.579534965825326

Epoch: 5| Step: 3
Training loss: 2.1776369355303102
Validation loss: 2.602068877555412

Epoch: 5| Step: 4
Training loss: 2.142371919736245
Validation loss: 2.6421002850913413

Epoch: 5| Step: 5
Training loss: 1.7124217662900874
Validation loss: 2.7229146009309417

Epoch: 5| Step: 6
Training loss: 2.10163635351034
Validation loss: 2.729723510766684

Epoch: 5| Step: 7
Training loss: 2.7959301593991563
Validation loss: 2.7159075877863943

Epoch: 5| Step: 8
Training loss: 2.6130177546064766
Validation loss: 2.687931011443346

Epoch: 5| Step: 9
Training loss: 2.7507300708259956
Validation loss: 2.6418830989499624

Epoch: 5| Step: 10
Training loss: 2.228612765603031
Validation loss: 2.565456669528438

Epoch: 5| Step: 11
Training loss: 1.4112528924768775
Validation loss: 2.5342806247804943

Epoch: 339| Step: 0
Training loss: 2.847503532427572
Validation loss: 2.517994023850247

Epoch: 5| Step: 1
Training loss: 2.422458307716463
Validation loss: 2.515433219249438

Epoch: 5| Step: 2
Training loss: 2.661243547007996
Validation loss: 2.513219271452867

Epoch: 5| Step: 3
Training loss: 2.3724686031856788
Validation loss: 2.5213550561058735

Epoch: 5| Step: 4
Training loss: 2.2400561048089065
Validation loss: 2.5140084014471227

Epoch: 5| Step: 5
Training loss: 2.128365712269293
Validation loss: 2.526804855257492

Epoch: 5| Step: 6
Training loss: 2.1300811605258723
Validation loss: 2.5334988325628394

Epoch: 5| Step: 7
Training loss: 2.025116566258247
Validation loss: 2.560128882747582

Epoch: 5| Step: 8
Training loss: 2.179130018034272
Validation loss: 2.5691762633169697

Epoch: 5| Step: 9
Training loss: 2.4848978703962965
Validation loss: 2.574211290394033

Epoch: 5| Step: 10
Training loss: 1.9009293266094334
Validation loss: 2.5853608843656555

Epoch: 5| Step: 11
Training loss: 4.251280199104598
Validation loss: 2.5960349623584333

Epoch: 340| Step: 0
Training loss: 2.2084733690690515
Validation loss: 2.616110801322994

Epoch: 5| Step: 1
Training loss: 2.2146075625692614
Validation loss: 2.63639602758326

Epoch: 5| Step: 2
Training loss: 1.617922850675682
Validation loss: 2.631685232590634

Epoch: 5| Step: 3
Training loss: 2.120952004320835
Validation loss: 2.659137734371612

Epoch: 5| Step: 4
Training loss: 2.6591986950752924
Validation loss: 2.653844829032366

Epoch: 5| Step: 5
Training loss: 2.1695796995484797
Validation loss: 2.6181785111655276

Epoch: 5| Step: 6
Training loss: 3.0154754127204684
Validation loss: 2.6162353681558272

Epoch: 5| Step: 7
Training loss: 2.3276032752900813
Validation loss: 2.590140895760794

Epoch: 5| Step: 8
Training loss: 2.260301320404206
Validation loss: 2.5508447729733

Epoch: 5| Step: 9
Training loss: 2.5889922478398812
Validation loss: 2.5419008167995236

Epoch: 5| Step: 10
Training loss: 1.8037623556643125
Validation loss: 2.525065669379795

Epoch: 5| Step: 11
Training loss: 1.8391505917928506
Validation loss: 2.5379126581229148

Epoch: 341| Step: 0
Training loss: 2.0971365343431403
Validation loss: 2.53761842792684

Epoch: 5| Step: 1
Training loss: 2.312442366423121
Validation loss: 2.5296301780459562

Epoch: 5| Step: 2
Training loss: 1.6246829824060145
Validation loss: 2.554487191376276

Epoch: 5| Step: 3
Training loss: 2.339799425217949
Validation loss: 2.595660233938583

Epoch: 5| Step: 4
Training loss: 2.6564498826161427
Validation loss: 2.5909238033280024

Epoch: 5| Step: 5
Training loss: 2.419619094096498
Validation loss: 2.6539324280296785

Epoch: 5| Step: 6
Training loss: 2.2862413748051296
Validation loss: 2.678150184598989

Epoch: 5| Step: 7
Training loss: 2.3658682291221504
Validation loss: 2.6813996890475913

Epoch: 5| Step: 8
Training loss: 2.5000877364975707
Validation loss: 2.6647239415816815

Epoch: 5| Step: 9
Training loss: 2.3496574720373347
Validation loss: 2.67528213338183

Epoch: 5| Step: 10
Training loss: 2.304414170431235
Validation loss: 2.663708992452521

Epoch: 5| Step: 11
Training loss: 1.7478391385380183
Validation loss: 2.6534927531154735

Epoch: 342| Step: 0
Training loss: 1.9688207220060414
Validation loss: 2.602868009370677

Epoch: 5| Step: 1
Training loss: 2.3246262649899454
Validation loss: 2.546758383829016

Epoch: 5| Step: 2
Training loss: 2.606487023715515
Validation loss: 2.496240797571887

Epoch: 5| Step: 3
Training loss: 2.0357682667891437
Validation loss: 2.506385577507213

Epoch: 5| Step: 4
Training loss: 2.654907874827679
Validation loss: 2.5211570718396534

Epoch: 5| Step: 5
Training loss: 1.9483414321135009
Validation loss: 2.5104103675277845

Epoch: 5| Step: 6
Training loss: 3.2510799667675636
Validation loss: 2.5095179968755663

Epoch: 5| Step: 7
Training loss: 2.6888000537535217
Validation loss: 2.503557086628431

Epoch: 5| Step: 8
Training loss: 1.9487627065463309
Validation loss: 2.513797929750417

Epoch: 5| Step: 9
Training loss: 1.97361517534487
Validation loss: 2.5094154479748303

Epoch: 5| Step: 10
Training loss: 2.2678504274352536
Validation loss: 2.5333797537373712

Epoch: 5| Step: 11
Training loss: 3.1542852348372685
Validation loss: 2.529137114164174

Epoch: 343| Step: 0
Training loss: 3.1713726980179873
Validation loss: 2.523377763259591

Epoch: 5| Step: 1
Training loss: 1.8044050912227527
Validation loss: 2.5304007223983622

Epoch: 5| Step: 2
Training loss: 2.414547769604416
Validation loss: 2.532535881768633

Epoch: 5| Step: 3
Training loss: 1.9229077301423898
Validation loss: 2.5493337819018063

Epoch: 5| Step: 4
Training loss: 2.2463490216692823
Validation loss: 2.5348772072693952

Epoch: 5| Step: 5
Training loss: 1.6920873666937704
Validation loss: 2.5621868461679083

Epoch: 5| Step: 6
Training loss: 1.9363030458772803
Validation loss: 2.546960513311704

Epoch: 5| Step: 7
Training loss: 2.3632449312808457
Validation loss: 2.58632255215206

Epoch: 5| Step: 8
Training loss: 2.4436525798608915
Validation loss: 2.58769170032554

Epoch: 5| Step: 9
Training loss: 2.860642115929514
Validation loss: 2.5913696320209976

Epoch: 5| Step: 10
Training loss: 1.9329520962261149
Validation loss: 2.5642992231562447

Epoch: 5| Step: 11
Training loss: 2.0377307503747764
Validation loss: 2.5557547545773316

Epoch: 344| Step: 0
Training loss: 2.4658731043234923
Validation loss: 2.5319706318790787

Epoch: 5| Step: 1
Training loss: 1.5919824410145922
Validation loss: 2.5241071877304533

Epoch: 5| Step: 2
Training loss: 2.545631245418823
Validation loss: 2.503449908730412

Epoch: 5| Step: 3
Training loss: 2.558656834414331
Validation loss: 2.504133502806191

Epoch: 5| Step: 4
Training loss: 2.015509550351621
Validation loss: 2.4913897298777727

Epoch: 5| Step: 5
Training loss: 2.5442189602101224
Validation loss: 2.5052295308528176

Epoch: 5| Step: 6
Training loss: 2.271948572617759
Validation loss: 2.5094119801217265

Epoch: 5| Step: 7
Training loss: 2.58890678752484
Validation loss: 2.5169730908326144

Epoch: 5| Step: 8
Training loss: 2.167741313379758
Validation loss: 2.5134399552099898

Epoch: 5| Step: 9
Training loss: 2.398080606653642
Validation loss: 2.54820848438146

Epoch: 5| Step: 10
Training loss: 2.2961764149096755
Validation loss: 2.5892219122963898

Epoch: 5| Step: 11
Training loss: 2.595266151818189
Validation loss: 2.592527591714221

Epoch: 345| Step: 0
Training loss: 2.904605194944913
Validation loss: 2.585586351138534

Epoch: 5| Step: 1
Training loss: 2.292564759416175
Validation loss: 2.5693883229619114

Epoch: 5| Step: 2
Training loss: 1.860611704662567
Validation loss: 2.575251328292231

Epoch: 5| Step: 3
Training loss: 1.6396015426354877
Validation loss: 2.565576896417871

Epoch: 5| Step: 4
Training loss: 1.933726296553918
Validation loss: 2.564241038818262

Epoch: 5| Step: 5
Training loss: 2.7053723998046473
Validation loss: 2.534839271356946

Epoch: 5| Step: 6
Training loss: 2.596864324334301
Validation loss: 2.5628032039738406

Epoch: 5| Step: 7
Training loss: 1.873277126953312
Validation loss: 2.5675307954664217

Epoch: 5| Step: 8
Training loss: 2.4127489979379915
Validation loss: 2.5592582829728814

Epoch: 5| Step: 9
Training loss: 1.9344535380305596
Validation loss: 2.558657754577994

Epoch: 5| Step: 10
Training loss: 2.89233512810776
Validation loss: 2.561331467022465

Epoch: 5| Step: 11
Training loss: 1.5828824237768993
Validation loss: 2.558531355157723

Epoch: 346| Step: 0
Training loss: 2.1047741482010136
Validation loss: 2.591825636948706

Epoch: 5| Step: 1
Training loss: 2.4731913344689063
Validation loss: 2.556483311253791

Epoch: 5| Step: 2
Training loss: 2.4728418554759224
Validation loss: 2.5698814996965926

Epoch: 5| Step: 3
Training loss: 2.1427830864961406
Validation loss: 2.5604614255193625

Epoch: 5| Step: 4
Training loss: 2.44933059656028
Validation loss: 2.534253124625874

Epoch: 5| Step: 5
Training loss: 2.3686448448815796
Validation loss: 2.553976786423082

Epoch: 5| Step: 6
Training loss: 2.0024061034782807
Validation loss: 2.547052658063163

Epoch: 5| Step: 7
Training loss: 1.719966180712871
Validation loss: 2.5681018927518595

Epoch: 5| Step: 8
Training loss: 2.2868794000650525
Validation loss: 2.5734417041156696

Epoch: 5| Step: 9
Training loss: 2.6176620736356493
Validation loss: 2.5919167807812586

Epoch: 5| Step: 10
Training loss: 2.1699400041785992
Validation loss: 2.6253352026889956

Epoch: 5| Step: 11
Training loss: 1.7304661322373682
Validation loss: 2.6682175929359415

Epoch: 347| Step: 0
Training loss: 1.7732478641167468
Validation loss: 2.712275479952565

Epoch: 5| Step: 1
Training loss: 1.9752902433339148
Validation loss: 2.654122568394945

Epoch: 5| Step: 2
Training loss: 2.8982094728993815
Validation loss: 2.6825142456344797

Epoch: 5| Step: 3
Training loss: 2.330548043201672
Validation loss: 2.629719119638341

Epoch: 5| Step: 4
Training loss: 2.154389172787662
Validation loss: 2.6076986025528397

Epoch: 5| Step: 5
Training loss: 2.855886029648813
Validation loss: 2.5645221314511875

Epoch: 5| Step: 6
Training loss: 1.840425371053452
Validation loss: 2.5282983603371085

Epoch: 5| Step: 7
Training loss: 1.562323979953586
Validation loss: 2.5256335836647135

Epoch: 5| Step: 8
Training loss: 2.442410047547821
Validation loss: 2.522762314547607

Epoch: 5| Step: 9
Training loss: 2.1464100652159415
Validation loss: 2.4991150442081027

Epoch: 5| Step: 10
Training loss: 2.652474086969269
Validation loss: 2.5092114085249144

Epoch: 5| Step: 11
Training loss: 3.119991102939538
Validation loss: 2.5101685236466444

Epoch: 348| Step: 0
Training loss: 2.657895554596585
Validation loss: 2.5241929568003316

Epoch: 5| Step: 1
Training loss: 2.054096093297012
Validation loss: 2.640245071707779

Epoch: 5| Step: 2
Training loss: 2.586219795238732
Validation loss: 2.7528366572933596

Epoch: 5| Step: 3
Training loss: 3.022147443101789
Validation loss: 2.7721192249107727

Epoch: 5| Step: 4
Training loss: 2.48805952057371
Validation loss: 2.8520994334095033

Epoch: 5| Step: 5
Training loss: 2.757669331668006
Validation loss: 2.8390449474396062

Epoch: 5| Step: 6
Training loss: 2.048696741013517
Validation loss: 2.743036260148013

Epoch: 5| Step: 7
Training loss: 2.1833712169282267
Validation loss: 2.687619129024576

Epoch: 5| Step: 8
Training loss: 1.8827371542642692
Validation loss: 2.5986530122063862

Epoch: 5| Step: 9
Training loss: 2.4185534927228436
Validation loss: 2.5630094517997297

Epoch: 5| Step: 10
Training loss: 2.5253171740454325
Validation loss: 2.557281083643834

Epoch: 5| Step: 11
Training loss: 0.8104425202260757
Validation loss: 2.5182222026319705

Epoch: 349| Step: 0
Training loss: 2.4662940448399078
Validation loss: 2.5223243706931577

Epoch: 5| Step: 1
Training loss: 2.2513459736193657
Validation loss: 2.531500270229182

Epoch: 5| Step: 2
Training loss: 2.3291540751745257
Validation loss: 2.521691532228823

Epoch: 5| Step: 3
Training loss: 1.8736129716745007
Validation loss: 2.5151493815480555

Epoch: 5| Step: 4
Training loss: 1.6482559755003787
Validation loss: 2.5129355315652186

Epoch: 5| Step: 5
Training loss: 1.9134156671724154
Validation loss: 2.528655798932024

Epoch: 5| Step: 6
Training loss: 2.619133524703743
Validation loss: 2.5270526920818543

Epoch: 5| Step: 7
Training loss: 2.6882193733683692
Validation loss: 2.5408498605878957

Epoch: 5| Step: 8
Training loss: 2.512696071584611
Validation loss: 2.544754096956331

Epoch: 5| Step: 9
Training loss: 2.2073300319744105
Validation loss: 2.5459765583359086

Epoch: 5| Step: 10
Training loss: 2.6209353812707077
Validation loss: 2.5685128247118665

Epoch: 5| Step: 11
Training loss: 2.9640875896222494
Validation loss: 2.575390835918285

Epoch: 350| Step: 0
Training loss: 2.608670807803063
Validation loss: 2.5913047792895285

Epoch: 5| Step: 1
Training loss: 2.6454951953833494
Validation loss: 2.627158220077382

Epoch: 5| Step: 2
Training loss: 2.232214463311553
Validation loss: 2.658155842140286

Epoch: 5| Step: 3
Training loss: 2.2451678415950047
Validation loss: 2.663166193678939

Epoch: 5| Step: 4
Training loss: 2.220823688975203
Validation loss: 2.6485039131592223

Epoch: 5| Step: 5
Training loss: 2.5385741717908488
Validation loss: 2.6436701752776415

Epoch: 5| Step: 6
Training loss: 1.9354092792524666
Validation loss: 2.62752493268496

Epoch: 5| Step: 7
Training loss: 2.7502424826788445
Validation loss: 2.593551352374023

Epoch: 5| Step: 8
Training loss: 1.997751999142873
Validation loss: 2.555817485397835

Epoch: 5| Step: 9
Training loss: 1.6593907644668866
Validation loss: 2.5181003578377164

Epoch: 5| Step: 10
Training loss: 2.3359737329639243
Validation loss: 2.5241814610096087

Epoch: 5| Step: 11
Training loss: 1.4736409019617263
Validation loss: 2.520222591208346

Epoch: 351| Step: 0
Training loss: 2.1182232677439172
Validation loss: 2.506783112723666

Epoch: 5| Step: 1
Training loss: 2.543740244853742
Validation loss: 2.4975827591001374

Epoch: 5| Step: 2
Training loss: 2.597366018502172
Validation loss: 2.511109956137519

Epoch: 5| Step: 3
Training loss: 1.6622813547097182
Validation loss: 2.5160015724712426

Epoch: 5| Step: 4
Training loss: 2.2019877643713004
Validation loss: 2.5475049985150884

Epoch: 5| Step: 5
Training loss: 2.651103160771979
Validation loss: 2.557887768594353

Epoch: 5| Step: 6
Training loss: 1.9185714862301244
Validation loss: 2.6122697812419133

Epoch: 5| Step: 7
Training loss: 2.5075738621004087
Validation loss: 2.6336509282700398

Epoch: 5| Step: 8
Training loss: 2.257663603100157
Validation loss: 2.690889878329149

Epoch: 5| Step: 9
Training loss: 2.454232712932601
Validation loss: 2.710766969240386

Epoch: 5| Step: 10
Training loss: 2.48910791387993
Validation loss: 2.6660089290101636

Epoch: 5| Step: 11
Training loss: 0.7306627230210048
Validation loss: 2.670463959051987

Epoch: 352| Step: 0
Training loss: 2.1705348868300387
Validation loss: 2.687380233579987

Epoch: 5| Step: 1
Training loss: 1.5356485679100365
Validation loss: 2.6530629354825233

Epoch: 5| Step: 2
Training loss: 2.9460729937655525
Validation loss: 2.6431159303710556

Epoch: 5| Step: 3
Training loss: 2.4523144980609444
Validation loss: 2.6314030165590427

Epoch: 5| Step: 4
Training loss: 2.1995429821423693
Validation loss: 2.6367214136934365

Epoch: 5| Step: 5
Training loss: 1.6363870289122724
Validation loss: 2.618235193329985

Epoch: 5| Step: 6
Training loss: 2.4401022884941135
Validation loss: 2.586398226751016

Epoch: 5| Step: 7
Training loss: 2.0461268331643128
Validation loss: 2.560183478202759

Epoch: 5| Step: 8
Training loss: 2.756593083418601
Validation loss: 2.5825107492812194

Epoch: 5| Step: 9
Training loss: 2.330941870731706
Validation loss: 2.558899804367069

Epoch: 5| Step: 10
Training loss: 2.2881846127823846
Validation loss: 2.5482649803433617

Epoch: 5| Step: 11
Training loss: 1.6175623657372722
Validation loss: 2.5406955064825687

Epoch: 353| Step: 0
Training loss: 2.5053747575220484
Validation loss: 2.5488959955019195

Epoch: 5| Step: 1
Training loss: 1.827165531178392
Validation loss: 2.5385817635090167

Epoch: 5| Step: 2
Training loss: 2.82156158430351
Validation loss: 2.547360141940623

Epoch: 5| Step: 3
Training loss: 2.3703092128703207
Validation loss: 2.5531378079189992

Epoch: 5| Step: 4
Training loss: 1.7143652037515538
Validation loss: 2.564088495755421

Epoch: 5| Step: 5
Training loss: 2.4009687256784065
Validation loss: 2.586840081180072

Epoch: 5| Step: 6
Training loss: 2.7573167393121727
Validation loss: 2.588070607194537

Epoch: 5| Step: 7
Training loss: 2.045251333372649
Validation loss: 2.6078843715021325

Epoch: 5| Step: 8
Training loss: 2.077750953913692
Validation loss: 2.618594282128856

Epoch: 5| Step: 9
Training loss: 2.390941424403362
Validation loss: 2.6280009244583824

Epoch: 5| Step: 10
Training loss: 2.049711867762083
Validation loss: 2.6231266557798687

Epoch: 5| Step: 11
Training loss: 1.9124987384068934
Validation loss: 2.6200607887100444

Epoch: 354| Step: 0
Training loss: 2.5555528580840243
Validation loss: 2.6000695054227254

Epoch: 5| Step: 1
Training loss: 2.2337113041613357
Validation loss: 2.6192675395486456

Epoch: 5| Step: 2
Training loss: 2.82391389544251
Validation loss: 2.5795911261464908

Epoch: 5| Step: 3
Training loss: 2.10254518585093
Validation loss: 2.593558082221169

Epoch: 5| Step: 4
Training loss: 2.626139983642167
Validation loss: 2.5990549590674967

Epoch: 5| Step: 5
Training loss: 2.0853594146806484
Validation loss: 2.588584747314149

Epoch: 5| Step: 6
Training loss: 1.9936738098319307
Validation loss: 2.607292227313817

Epoch: 5| Step: 7
Training loss: 1.9003713671501437
Validation loss: 2.5983771831938633

Epoch: 5| Step: 8
Training loss: 2.117467657605627
Validation loss: 2.5854007859296892

Epoch: 5| Step: 9
Training loss: 1.7501632750501042
Validation loss: 2.5881880218637248

Epoch: 5| Step: 10
Training loss: 2.084077956324943
Validation loss: 2.6367491845152293

Epoch: 5| Step: 11
Training loss: 3.0101608818883876
Validation loss: 2.6449113363261576

Epoch: 355| Step: 0
Training loss: 2.703547450224019
Validation loss: 2.6396218751433413

Epoch: 5| Step: 1
Training loss: 1.8669798029219364
Validation loss: 2.673728437587924

Epoch: 5| Step: 2
Training loss: 2.7914285320990926
Validation loss: 2.623729409659086

Epoch: 5| Step: 3
Training loss: 1.8572123797472189
Validation loss: 2.6483399589828602

Epoch: 5| Step: 4
Training loss: 1.9872188465221383
Validation loss: 2.6569691301647977

Epoch: 5| Step: 5
Training loss: 1.8613504766701305
Validation loss: 2.673966475948532

Epoch: 5| Step: 6
Training loss: 1.6976172606427522
Validation loss: 2.6452371583932197

Epoch: 5| Step: 7
Training loss: 2.0993621538682845
Validation loss: 2.6637360082826036

Epoch: 5| Step: 8
Training loss: 2.6708208648184293
Validation loss: 2.6363861477024306

Epoch: 5| Step: 9
Training loss: 2.674383759151057
Validation loss: 2.5693036914340293

Epoch: 5| Step: 10
Training loss: 2.1325157993174115
Validation loss: 2.6012208464145337

Epoch: 5| Step: 11
Training loss: 2.0451781249874657
Validation loss: 2.574105773051999

Epoch: 356| Step: 0
Training loss: 2.0176105035065275
Validation loss: 2.5548581057636235

Epoch: 5| Step: 1
Training loss: 2.5888195745751323
Validation loss: 2.5461426912722813

Epoch: 5| Step: 2
Training loss: 2.6185863798825215
Validation loss: 2.5406846953225912

Epoch: 5| Step: 3
Training loss: 1.6016682659674422
Validation loss: 2.5401465933278824

Epoch: 5| Step: 4
Training loss: 1.8147255618053657
Validation loss: 2.517958918800931

Epoch: 5| Step: 5
Training loss: 2.807684442129262
Validation loss: 2.517997164264614

Epoch: 5| Step: 6
Training loss: 1.6331019532847262
Validation loss: 2.522774202706706

Epoch: 5| Step: 7
Training loss: 2.2045642669647294
Validation loss: 2.546070513990403

Epoch: 5| Step: 8
Training loss: 2.26596498240444
Validation loss: 2.547493565026848

Epoch: 5| Step: 9
Training loss: 2.634721013307224
Validation loss: 2.5682736458630706

Epoch: 5| Step: 10
Training loss: 2.285638950588012
Validation loss: 2.540465893363633

Epoch: 5| Step: 11
Training loss: 1.4705447330772365
Validation loss: 2.585627849436822

Epoch: 357| Step: 0
Training loss: 2.316812463559036
Validation loss: 2.6025916212928584

Epoch: 5| Step: 1
Training loss: 1.8854099575646954
Validation loss: 2.5849319954061225

Epoch: 5| Step: 2
Training loss: 2.2880107038554325
Validation loss: 2.6023744952171137

Epoch: 5| Step: 3
Training loss: 2.0551618021360225
Validation loss: 2.6020965677132994

Epoch: 5| Step: 4
Training loss: 2.370531194527099
Validation loss: 2.5725506060089547

Epoch: 5| Step: 5
Training loss: 2.225589794040099
Validation loss: 2.5461928579404116

Epoch: 5| Step: 6
Training loss: 2.3788576418666447
Validation loss: 2.561988225089666

Epoch: 5| Step: 7
Training loss: 2.47404298871745
Validation loss: 2.5467042963279485

Epoch: 5| Step: 8
Training loss: 2.1800172617867575
Validation loss: 2.5530720229393635

Epoch: 5| Step: 9
Training loss: 2.0361374962476106
Validation loss: 2.5498662011255466

Epoch: 5| Step: 10
Training loss: 2.400850554588421
Validation loss: 2.5522190343369777

Epoch: 5| Step: 11
Training loss: 1.833149582873279
Validation loss: 2.616379232524359

Epoch: 358| Step: 0
Training loss: 1.7456041712189234
Validation loss: 2.624205067780526

Epoch: 5| Step: 1
Training loss: 1.9917104710931837
Validation loss: 2.609496736256564

Epoch: 5| Step: 2
Training loss: 2.3687605965812617
Validation loss: 2.6088944561792586

Epoch: 5| Step: 3
Training loss: 2.2460857888785544
Validation loss: 2.626384929862676

Epoch: 5| Step: 4
Training loss: 2.5482018881662425
Validation loss: 2.6057972050431277

Epoch: 5| Step: 5
Training loss: 1.7564960891067658
Validation loss: 2.6213681702240104

Epoch: 5| Step: 6
Training loss: 1.7418261781987874
Validation loss: 2.667887752079779

Epoch: 5| Step: 7
Training loss: 2.7135538014282763
Validation loss: 2.6813654673921747

Epoch: 5| Step: 8
Training loss: 2.5756071800720735
Validation loss: 2.690948702118061

Epoch: 5| Step: 9
Training loss: 2.6848718079097273
Validation loss: 2.6643503505286312

Epoch: 5| Step: 10
Training loss: 2.1806881156308915
Validation loss: 2.641161264143661

Epoch: 5| Step: 11
Training loss: 2.3951617308544035
Validation loss: 2.5963737935989086

Epoch: 359| Step: 0
Training loss: 2.0516538089790375
Validation loss: 2.5976682696148043

Epoch: 5| Step: 1
Training loss: 1.8443111277023194
Validation loss: 2.5914462440953545

Epoch: 5| Step: 2
Training loss: 2.0112614676727674
Validation loss: 2.5600111629135913

Epoch: 5| Step: 3
Training loss: 2.251688429668225
Validation loss: 2.5515464620247745

Epoch: 5| Step: 4
Training loss: 2.5561723506111735
Validation loss: 2.567886378606731

Epoch: 5| Step: 5
Training loss: 1.6872443252719007
Validation loss: 2.570728191088712

Epoch: 5| Step: 6
Training loss: 2.5919619912257086
Validation loss: 2.5615296348606367

Epoch: 5| Step: 7
Training loss: 2.437346526963037
Validation loss: 2.591386246510567

Epoch: 5| Step: 8
Training loss: 2.4192922294883266
Validation loss: 2.5681857167605915

Epoch: 5| Step: 9
Training loss: 2.408779845594748
Validation loss: 2.5827170464950107

Epoch: 5| Step: 10
Training loss: 1.9566853535467637
Validation loss: 2.577830870062654

Epoch: 5| Step: 11
Training loss: 3.243601589446079
Validation loss: 2.6162705708336107

Epoch: 360| Step: 0
Training loss: 1.7395436706894478
Validation loss: 2.6044430408053127

Epoch: 5| Step: 1
Training loss: 2.1769775170219696
Validation loss: 2.595343816309127

Epoch: 5| Step: 2
Training loss: 1.9688420349891542
Validation loss: 2.5633405105575497

Epoch: 5| Step: 3
Training loss: 2.2327977729242274
Validation loss: 2.5633406965793206

Epoch: 5| Step: 4
Training loss: 2.8579127841079024
Validation loss: 2.554332864082632

Epoch: 5| Step: 5
Training loss: 2.4678000058856213
Validation loss: 2.6042182701084307

Epoch: 5| Step: 6
Training loss: 2.1387806764561956
Validation loss: 2.620391057929037

Epoch: 5| Step: 7
Training loss: 2.4343689591574
Validation loss: 2.606949438378111

Epoch: 5| Step: 8
Training loss: 1.9207608474768725
Validation loss: 2.642364846715794

Epoch: 5| Step: 9
Training loss: 2.2260031549683292
Validation loss: 2.629774442456811

Epoch: 5| Step: 10
Training loss: 2.4512214807605
Validation loss: 2.670634894703477

Epoch: 5| Step: 11
Training loss: 1.8137801023649773
Validation loss: 2.6097954927115294

Epoch: 361| Step: 0
Training loss: 1.803412048657331
Validation loss: 2.618255558618241

Epoch: 5| Step: 1
Training loss: 1.8372700501927324
Validation loss: 2.5766369619380387

Epoch: 5| Step: 2
Training loss: 2.174234658997615
Validation loss: 2.5509709885945253

Epoch: 5| Step: 3
Training loss: 2.5077449040795132
Validation loss: 2.555534315769646

Epoch: 5| Step: 4
Training loss: 2.1014600537370183
Validation loss: 2.5754916990128236

Epoch: 5| Step: 5
Training loss: 1.7676853547844105
Validation loss: 2.561300054910938

Epoch: 5| Step: 6
Training loss: 2.6748090551089296
Validation loss: 2.549688922226965

Epoch: 5| Step: 7
Training loss: 1.8816825040021816
Validation loss: 2.549670709357629

Epoch: 5| Step: 8
Training loss: 2.663154335388605
Validation loss: 2.5565778483199098

Epoch: 5| Step: 9
Training loss: 3.079742316576377
Validation loss: 2.591081638914791

Epoch: 5| Step: 10
Training loss: 1.9226283015979315
Validation loss: 2.6082186849420497

Epoch: 5| Step: 11
Training loss: 1.6167315886265987
Validation loss: 2.6180646878214477

Epoch: 362| Step: 0
Training loss: 1.8192519999382095
Validation loss: 2.597640696696516

Epoch: 5| Step: 1
Training loss: 1.9018460039679443
Validation loss: 2.6384858452431295

Epoch: 5| Step: 2
Training loss: 2.488978888477682
Validation loss: 2.625038941412409

Epoch: 5| Step: 3
Training loss: 1.9353696740080926
Validation loss: 2.664360574135446

Epoch: 5| Step: 4
Training loss: 1.944426062663552
Validation loss: 2.6725184128807675

Epoch: 5| Step: 5
Training loss: 2.175782784096744
Validation loss: 2.6927124456279548

Epoch: 5| Step: 6
Training loss: 2.295408650170347
Validation loss: 2.6399848884453463

Epoch: 5| Step: 7
Training loss: 2.664849755093919
Validation loss: 2.6191271640053335

Epoch: 5| Step: 8
Training loss: 2.2155615233890753
Validation loss: 2.592042127062099

Epoch: 5| Step: 9
Training loss: 2.12489161495479
Validation loss: 2.5873961968417007

Epoch: 5| Step: 10
Training loss: 2.8778576125072988
Validation loss: 2.563327481249101

Epoch: 5| Step: 11
Training loss: 1.9173856575307404
Validation loss: 2.5387812688552533

Epoch: 363| Step: 0
Training loss: 2.370602200129698
Validation loss: 2.558337890411775

Epoch: 5| Step: 1
Training loss: 1.865425395671072
Validation loss: 2.5377459316058832

Epoch: 5| Step: 2
Training loss: 1.7314608724360767
Validation loss: 2.534399510369741

Epoch: 5| Step: 3
Training loss: 2.0056646711278168
Validation loss: 2.519102717582819

Epoch: 5| Step: 4
Training loss: 2.2047279965191295
Validation loss: 2.5526182425053205

Epoch: 5| Step: 5
Training loss: 2.626362220076919
Validation loss: 2.548931863166938

Epoch: 5| Step: 6
Training loss: 2.2090338069872533
Validation loss: 2.6067993697294947

Epoch: 5| Step: 7
Training loss: 2.4121214337375703
Validation loss: 2.624702209656713

Epoch: 5| Step: 8
Training loss: 2.504206361207422
Validation loss: 2.6583454505999007

Epoch: 5| Step: 9
Training loss: 2.242554425245731
Validation loss: 2.6661399057785307

Epoch: 5| Step: 10
Training loss: 2.5446535497455094
Validation loss: 2.7029921475142453

Epoch: 5| Step: 11
Training loss: 2.3932421949915432
Validation loss: 2.6772972991181985

Epoch: 364| Step: 0
Training loss: 2.522171600560144
Validation loss: 2.6583029611241624

Epoch: 5| Step: 1
Training loss: 2.530613760401515
Validation loss: 2.637748483279402

Epoch: 5| Step: 2
Training loss: 1.9168989068459983
Validation loss: 2.5824787831242713

Epoch: 5| Step: 3
Training loss: 1.5461084797886642
Validation loss: 2.5572688586635186

Epoch: 5| Step: 4
Training loss: 2.143771344403923
Validation loss: 2.5801295569638527

Epoch: 5| Step: 5
Training loss: 2.6666747232156487
Validation loss: 2.573321423888031

Epoch: 5| Step: 6
Training loss: 2.29358754427255
Validation loss: 2.571657974585304

Epoch: 5| Step: 7
Training loss: 1.8309500621150503
Validation loss: 2.533876116436369

Epoch: 5| Step: 8
Training loss: 2.0189931953319284
Validation loss: 2.5390505003034254

Epoch: 5| Step: 9
Training loss: 2.1924427321641904
Validation loss: 2.5150950092700093

Epoch: 5| Step: 10
Training loss: 2.505355534554468
Validation loss: 2.5202530292795124

Epoch: 5| Step: 11
Training loss: 3.4005858197134695
Validation loss: 2.522085160106092

Epoch: 365| Step: 0
Training loss: 2.3344847585671187
Validation loss: 2.5583659606948856

Epoch: 5| Step: 1
Training loss: 1.7688799537393618
Validation loss: 2.5755467788011717

Epoch: 5| Step: 2
Training loss: 2.345003225328387
Validation loss: 2.5806142060933412

Epoch: 5| Step: 3
Training loss: 1.6768663712264233
Validation loss: 2.6037446875418047

Epoch: 5| Step: 4
Training loss: 1.5238166532888975
Validation loss: 2.629056607878413

Epoch: 5| Step: 5
Training loss: 1.9542746860388975
Validation loss: 2.667278224636385

Epoch: 5| Step: 6
Training loss: 2.3784724499283905
Validation loss: 2.6468930781654207

Epoch: 5| Step: 7
Training loss: 2.3188533626252434
Validation loss: 2.6523314500541306

Epoch: 5| Step: 8
Training loss: 1.988575551973415
Validation loss: 2.625197121242773

Epoch: 5| Step: 9
Training loss: 3.0554711782962256
Validation loss: 2.669618360024572

Epoch: 5| Step: 10
Training loss: 2.7566275063454317
Validation loss: 2.636245408133301

Epoch: 5| Step: 11
Training loss: 2.012571994607344
Validation loss: 2.629944398434889

Epoch: 366| Step: 0
Training loss: 2.6769940154814207
Validation loss: 2.5744276179089987

Epoch: 5| Step: 1
Training loss: 1.853507264000834
Validation loss: 2.540569441196858

Epoch: 5| Step: 2
Training loss: 2.3145415083994507
Validation loss: 2.5278773110627557

Epoch: 5| Step: 3
Training loss: 2.66025546388842
Validation loss: 2.5014364049941653

Epoch: 5| Step: 4
Training loss: 1.7947996676977542
Validation loss: 2.516608884971228

Epoch: 5| Step: 5
Training loss: 2.609678787547622
Validation loss: 2.514682227836661

Epoch: 5| Step: 6
Training loss: 2.299561674395393
Validation loss: 2.5116239918443974

Epoch: 5| Step: 7
Training loss: 2.1535356548006823
Validation loss: 2.5274130346440304

Epoch: 5| Step: 8
Training loss: 1.388228977573844
Validation loss: 2.5336576322190294

Epoch: 5| Step: 9
Training loss: 2.5501684881159403
Validation loss: 2.533544140491878

Epoch: 5| Step: 10
Training loss: 2.2322171335123833
Validation loss: 2.553133811919913

Epoch: 5| Step: 11
Training loss: 1.6655582636476884
Validation loss: 2.5421717381628617

Epoch: 367| Step: 0
Training loss: 2.414748998515183
Validation loss: 2.584239440616176

Epoch: 5| Step: 1
Training loss: 2.3574849825853046
Validation loss: 2.6000547001354297

Epoch: 5| Step: 2
Training loss: 1.751458513914719
Validation loss: 2.6137321246676275

Epoch: 5| Step: 3
Training loss: 2.92213038996041
Validation loss: 2.609529227992675

Epoch: 5| Step: 4
Training loss: 1.9910143221498582
Validation loss: 2.580520449505538

Epoch: 5| Step: 5
Training loss: 1.9154466256611893
Validation loss: 2.6335140995159767

Epoch: 5| Step: 6
Training loss: 2.0586361383058844
Validation loss: 2.588591513099425

Epoch: 5| Step: 7
Training loss: 2.1602975202449692
Validation loss: 2.6032451537796115

Epoch: 5| Step: 8
Training loss: 2.4069882536071776
Validation loss: 2.5735880880452005

Epoch: 5| Step: 9
Training loss: 2.6904796671854956
Validation loss: 2.590467459409907

Epoch: 5| Step: 10
Training loss: 1.7703643925898558
Validation loss: 2.5976019832134165

Epoch: 5| Step: 11
Training loss: 1.6195160691635044
Validation loss: 2.5743325709493674

Epoch: 368| Step: 0
Training loss: 1.729658087641437
Validation loss: 2.5710357645567385

Epoch: 5| Step: 1
Training loss: 2.420037637055342
Validation loss: 2.5427985888856925

Epoch: 5| Step: 2
Training loss: 2.5512350943399547
Validation loss: 2.5613740292565708

Epoch: 5| Step: 3
Training loss: 2.237845972687384
Validation loss: 2.5428588695001073

Epoch: 5| Step: 4
Training loss: 1.6054389004125207
Validation loss: 2.53882401740222

Epoch: 5| Step: 5
Training loss: 2.401481461259019
Validation loss: 2.5149674652092155

Epoch: 5| Step: 6
Training loss: 1.9801093683959294
Validation loss: 2.5204740588787886

Epoch: 5| Step: 7
Training loss: 2.441918696219289
Validation loss: 2.5339013683683485

Epoch: 5| Step: 8
Training loss: 1.5650852178948824
Validation loss: 2.5785577930966226

Epoch: 5| Step: 9
Training loss: 2.511939719819299
Validation loss: 2.6080781565534368

Epoch: 5| Step: 10
Training loss: 2.6719018589030585
Validation loss: 2.650432907737991

Epoch: 5| Step: 11
Training loss: 2.4425228891696045
Validation loss: 2.642784732731221

Epoch: 369| Step: 0
Training loss: 2.2580170324272775
Validation loss: 2.605470843221347

Epoch: 5| Step: 1
Training loss: 2.1366312682045847
Validation loss: 2.5676807701277005

Epoch: 5| Step: 2
Training loss: 2.5210864567894973
Validation loss: 2.521981101500461

Epoch: 5| Step: 3
Training loss: 2.9941181697115393
Validation loss: 2.508273517068626

Epoch: 5| Step: 4
Training loss: 2.6917027281086536
Validation loss: 2.500281484969588

Epoch: 5| Step: 5
Training loss: 1.3776079068436595
Validation loss: 2.5108324645727027

Epoch: 5| Step: 6
Training loss: 2.0447603907033716
Validation loss: 2.49360726114512

Epoch: 5| Step: 7
Training loss: 2.3653806330901994
Validation loss: 2.5161800325080836

Epoch: 5| Step: 8
Training loss: 2.135241567984733
Validation loss: 2.50619793153679

Epoch: 5| Step: 9
Training loss: 1.862626702524135
Validation loss: 2.5381219031327475

Epoch: 5| Step: 10
Training loss: 1.525488934542103
Validation loss: 2.5701949837670783

Epoch: 5| Step: 11
Training loss: 3.3098218635959538
Validation loss: 2.6291709887523966

Epoch: 370| Step: 0
Training loss: 2.617710983532071
Validation loss: 2.6945458616481943

Epoch: 5| Step: 1
Training loss: 2.389860342566112
Validation loss: 2.638399122754929

Epoch: 5| Step: 2
Training loss: 1.8883764594131702
Validation loss: 2.622952233957855

Epoch: 5| Step: 3
Training loss: 1.9210633835907636
Validation loss: 2.6133543991700336

Epoch: 5| Step: 4
Training loss: 2.461484043042496
Validation loss: 2.6030678770675384

Epoch: 5| Step: 5
Training loss: 1.6790571582509715
Validation loss: 2.5893161172914065

Epoch: 5| Step: 6
Training loss: 2.7965390307278963
Validation loss: 2.554415720444024

Epoch: 5| Step: 7
Training loss: 2.31266340760945
Validation loss: 2.5467781212290372

Epoch: 5| Step: 8
Training loss: 2.4233751142626456
Validation loss: 2.577078728349211

Epoch: 5| Step: 9
Training loss: 2.1908515323285926
Validation loss: 2.5714673749421744

Epoch: 5| Step: 10
Training loss: 1.7276517444216157
Validation loss: 2.587248616745948

Epoch: 5| Step: 11
Training loss: 1.2321426873374806
Validation loss: 2.6144473140539315

Epoch: 371| Step: 0
Training loss: 2.1073229945958087
Validation loss: 2.596033955950274

Epoch: 5| Step: 1
Training loss: 1.892397719407305
Validation loss: 2.5658267183106025

Epoch: 5| Step: 2
Training loss: 2.1106757780365593
Validation loss: 2.5808077330936774

Epoch: 5| Step: 3
Training loss: 3.139772062107335
Validation loss: 2.548379827954275

Epoch: 5| Step: 4
Training loss: 2.186968493604012
Validation loss: 2.563573957258212

Epoch: 5| Step: 5
Training loss: 1.810413079940468
Validation loss: 2.5648811914703353

Epoch: 5| Step: 6
Training loss: 2.3082902066532065
Validation loss: 2.5399059713974044

Epoch: 5| Step: 7
Training loss: 2.6064739432965256
Validation loss: 2.576795358431764

Epoch: 5| Step: 8
Training loss: 1.7354843440908923
Validation loss: 2.582001340137866

Epoch: 5| Step: 9
Training loss: 2.3649092686288062
Validation loss: 2.596821911510562

Epoch: 5| Step: 10
Training loss: 1.9635399802392115
Validation loss: 2.617629500686028

Epoch: 5| Step: 11
Training loss: 1.7552364207509805
Validation loss: 2.641972000745453

Epoch: 372| Step: 0
Training loss: 2.528581884945978
Validation loss: 2.642164361011347

Epoch: 5| Step: 1
Training loss: 2.4273834588689076
Validation loss: 2.6565969913703995

Epoch: 5| Step: 2
Training loss: 2.0665668504462373
Validation loss: 2.6448663135845476

Epoch: 5| Step: 3
Training loss: 2.14998379634695
Validation loss: 2.6224791896468345

Epoch: 5| Step: 4
Training loss: 1.9217107439017818
Validation loss: 2.604304734702576

Epoch: 5| Step: 5
Training loss: 2.392375529528316
Validation loss: 2.5997665590857615

Epoch: 5| Step: 6
Training loss: 2.374287046534096
Validation loss: 2.593004973778133

Epoch: 5| Step: 7
Training loss: 1.6320021229103716
Validation loss: 2.564292149213749

Epoch: 5| Step: 8
Training loss: 2.375565210647319
Validation loss: 2.5593345947864514

Epoch: 5| Step: 9
Training loss: 2.5195539606534587
Validation loss: 2.581180742149017

Epoch: 5| Step: 10
Training loss: 1.9638096418253403
Validation loss: 2.5670616013776706

Epoch: 5| Step: 11
Training loss: 1.497508363780004
Validation loss: 2.6206628357102666

Epoch: 373| Step: 0
Training loss: 2.3770805080262183
Validation loss: 2.6340887936159145

Epoch: 5| Step: 1
Training loss: 2.397132941221789
Validation loss: 2.6495098804883073

Epoch: 5| Step: 2
Training loss: 2.8517425898290716
Validation loss: 2.679638842705367

Epoch: 5| Step: 3
Training loss: 2.030578267459977
Validation loss: 2.6789156818937694

Epoch: 5| Step: 4
Training loss: 2.8100062016591774
Validation loss: 2.6491432487418325

Epoch: 5| Step: 5
Training loss: 2.265461988175247
Validation loss: 2.6315233600542887

Epoch: 5| Step: 6
Training loss: 1.9233146175793965
Validation loss: 2.625094330697343

Epoch: 5| Step: 7
Training loss: 1.1449066692111736
Validation loss: 2.6308084137003895

Epoch: 5| Step: 8
Training loss: 2.417452607661736
Validation loss: 2.629843995697528

Epoch: 5| Step: 9
Training loss: 1.7487582842267284
Validation loss: 2.655304138223104

Epoch: 5| Step: 10
Training loss: 1.9747583048242978
Validation loss: 2.662348276838897

Epoch: 5| Step: 11
Training loss: 1.385491357190623
Validation loss: 2.599152281920008

Epoch: 374| Step: 0
Training loss: 2.2912332182673905
Validation loss: 2.575583528861935

Epoch: 5| Step: 1
Training loss: 2.4839256408053547
Validation loss: 2.5450824795193987

Epoch: 5| Step: 2
Training loss: 2.787548006610856
Validation loss: 2.534842175355435

Epoch: 5| Step: 3
Training loss: 2.155269012654044
Validation loss: 2.5063722144664675

Epoch: 5| Step: 4
Training loss: 2.1069448530442205
Validation loss: 2.5149305976660394

Epoch: 5| Step: 5
Training loss: 1.7703680960670014
Validation loss: 2.5299351342245293

Epoch: 5| Step: 6
Training loss: 1.7336011655218257
Validation loss: 2.50682382515058

Epoch: 5| Step: 7
Training loss: 1.932579252189742
Validation loss: 2.5213625578309578

Epoch: 5| Step: 8
Training loss: 2.397502107907702
Validation loss: 2.51649155707547

Epoch: 5| Step: 9
Training loss: 1.6954429330179426
Validation loss: 2.5550999089805244

Epoch: 5| Step: 10
Training loss: 2.6168852218745347
Validation loss: 2.582298234226194

Epoch: 5| Step: 11
Training loss: 3.2762933987126734
Validation loss: 2.6125819549299765

Epoch: 375| Step: 0
Training loss: 2.2014625716154326
Validation loss: 2.6516141154762187

Epoch: 5| Step: 1
Training loss: 2.7059269313603664
Validation loss: 2.6746445294857355

Epoch: 5| Step: 2
Training loss: 2.0326340874879976
Validation loss: 2.6559116409813726

Epoch: 5| Step: 3
Training loss: 2.038740344559699
Validation loss: 2.6555751541665655

Epoch: 5| Step: 4
Training loss: 1.6744782332619952
Validation loss: 2.637640677447302

Epoch: 5| Step: 5
Training loss: 2.4544270941264643
Validation loss: 2.593047062096503

Epoch: 5| Step: 6
Training loss: 2.2135215728446123
Validation loss: 2.597744527669608

Epoch: 5| Step: 7
Training loss: 2.2058525786540866
Validation loss: 2.5758996260021156

Epoch: 5| Step: 8
Training loss: 2.3083877084251787
Validation loss: 2.57905262529079

Epoch: 5| Step: 9
Training loss: 2.3239046285235427
Validation loss: 2.5622287660971304

Epoch: 5| Step: 10
Training loss: 2.172537723121564
Validation loss: 2.5528124773238217

Epoch: 5| Step: 11
Training loss: 0.7053324486409043
Validation loss: 2.5510914503426614

Epoch: 376| Step: 0
Training loss: 2.47692926139989
Validation loss: 2.559925592714539

Epoch: 5| Step: 1
Training loss: 2.00590121365811
Validation loss: 2.557086440408688

Epoch: 5| Step: 2
Training loss: 2.1572606026626207
Validation loss: 2.5579542647007094

Epoch: 5| Step: 3
Training loss: 1.332446215476312
Validation loss: 2.5766840096240005

Epoch: 5| Step: 4
Training loss: 2.340959235291462
Validation loss: 2.6014364553776823

Epoch: 5| Step: 5
Training loss: 2.7929387017614395
Validation loss: 2.5860768690709355

Epoch: 5| Step: 6
Training loss: 1.6187611170795713
Validation loss: 2.5828490931416233

Epoch: 5| Step: 7
Training loss: 2.599279461568116
Validation loss: 2.572298382333518

Epoch: 5| Step: 8
Training loss: 1.7878988554591937
Validation loss: 2.621870309600454

Epoch: 5| Step: 9
Training loss: 2.7176221941836993
Validation loss: 2.6660306899840975

Epoch: 5| Step: 10
Training loss: 2.0657371779090874
Validation loss: 2.6245158369638233

Epoch: 5| Step: 11
Training loss: 2.109369009503936
Validation loss: 2.630526832458216

Epoch: 377| Step: 0
Training loss: 2.4228384747165155
Validation loss: 2.666823145378133

Epoch: 5| Step: 1
Training loss: 2.330453719302591
Validation loss: 2.6989000742337055

Epoch: 5| Step: 2
Training loss: 1.9729942712019102
Validation loss: 2.6446468867043134

Epoch: 5| Step: 3
Training loss: 2.5334229737869136
Validation loss: 2.6600042291299286

Epoch: 5| Step: 4
Training loss: 2.0859816185789644
Validation loss: 2.665844788160534

Epoch: 5| Step: 5
Training loss: 2.0573209993870774
Validation loss: 2.670738342805812

Epoch: 5| Step: 6
Training loss: 1.5126908205580094
Validation loss: 2.6862352189571097

Epoch: 5| Step: 7
Training loss: 2.0970939010312417
Validation loss: 2.616532014968161

Epoch: 5| Step: 8
Training loss: 2.5929924651484058
Validation loss: 2.6170231022610104

Epoch: 5| Step: 9
Training loss: 1.3565395204416344
Validation loss: 2.6124014064674057

Epoch: 5| Step: 10
Training loss: 2.490160078548541
Validation loss: 2.610294496022123

Epoch: 5| Step: 11
Training loss: 3.007148808168258
Validation loss: 2.598082994481369

Epoch: 378| Step: 0
Training loss: 2.537940707717316
Validation loss: 2.6032173537242915

Epoch: 5| Step: 1
Training loss: 1.8298365088426967
Validation loss: 2.6109507936496508

Epoch: 5| Step: 2
Training loss: 2.6298995840824757
Validation loss: 2.564658620386745

Epoch: 5| Step: 3
Training loss: 1.9259327795988113
Validation loss: 2.5812947525689296

Epoch: 5| Step: 4
Training loss: 2.5599015249743333
Validation loss: 2.6199213239817953

Epoch: 5| Step: 5
Training loss: 1.8989780739577575
Validation loss: 2.628404165977327

Epoch: 5| Step: 6
Training loss: 1.6144996457304792
Validation loss: 2.6493899227945037

Epoch: 5| Step: 7
Training loss: 1.590184505601812
Validation loss: 2.6835605743297286

Epoch: 5| Step: 8
Training loss: 3.140076394822238
Validation loss: 2.6928900110774032

Epoch: 5| Step: 9
Training loss: 2.1125800755238813
Validation loss: 2.6781834347083446

Epoch: 5| Step: 10
Training loss: 1.8825060329872514
Validation loss: 2.653170509681943

Epoch: 5| Step: 11
Training loss: 0.9225024658004763
Validation loss: 2.6548978168773845

Epoch: 379| Step: 0
Training loss: 2.27110207276973
Validation loss: 2.6186582276098416

Epoch: 5| Step: 1
Training loss: 2.510156124624326
Validation loss: 2.591791052812957

Epoch: 5| Step: 2
Training loss: 1.851439009141682
Validation loss: 2.580803406562102

Epoch: 5| Step: 3
Training loss: 1.6575625994384433
Validation loss: 2.581511525505631

Epoch: 5| Step: 4
Training loss: 2.1035023638378996
Validation loss: 2.5811867152746846

Epoch: 5| Step: 5
Training loss: 2.2857540033500032
Validation loss: 2.5526297522783428

Epoch: 5| Step: 6
Training loss: 2.1659655414703987
Validation loss: 2.5654286729578035

Epoch: 5| Step: 7
Training loss: 1.4315222968397967
Validation loss: 2.5598757533815193

Epoch: 5| Step: 8
Training loss: 2.721787871095115
Validation loss: 2.547013908919883

Epoch: 5| Step: 9
Training loss: 2.691855073442788
Validation loss: 2.5531236876566457

Epoch: 5| Step: 10
Training loss: 1.9140787552123857
Validation loss: 2.590749211203825

Epoch: 5| Step: 11
Training loss: 2.5321787319528215
Validation loss: 2.622489296170365

Epoch: 380| Step: 0
Training loss: 2.7302840665646793
Validation loss: 2.658420760312516

Epoch: 5| Step: 1
Training loss: 1.9003063155758806
Validation loss: 2.651555726599598

Epoch: 5| Step: 2
Training loss: 1.9071104265316143
Validation loss: 2.6745228762275577

Epoch: 5| Step: 3
Training loss: 2.0773849890647975
Validation loss: 2.6463219812171883

Epoch: 5| Step: 4
Training loss: 2.006378017631221
Validation loss: 2.6095492976713683

Epoch: 5| Step: 5
Training loss: 2.5578984138354106
Validation loss: 2.5934242442294413

Epoch: 5| Step: 6
Training loss: 2.0601256604431697
Validation loss: 2.5667529788821266

Epoch: 5| Step: 7
Training loss: 1.9720691373749222
Validation loss: 2.568192749033422

Epoch: 5| Step: 8
Training loss: 1.730673956490276
Validation loss: 2.5363792208658587

Epoch: 5| Step: 9
Training loss: 2.4585240715730547
Validation loss: 2.571965672473276

Epoch: 5| Step: 10
Training loss: 2.7481240896779147
Validation loss: 2.563928504463059

Epoch: 5| Step: 11
Training loss: 1.4936545784451247
Validation loss: 2.573292671301957

Epoch: 381| Step: 0
Training loss: 2.017952218691361
Validation loss: 2.5778033315953577

Epoch: 5| Step: 1
Training loss: 2.252439765590531
Validation loss: 2.5774825943027064

Epoch: 5| Step: 2
Training loss: 1.7681766402954828
Validation loss: 2.541663898143407

Epoch: 5| Step: 3
Training loss: 1.4005271600325249
Validation loss: 2.5664446715135725

Epoch: 5| Step: 4
Training loss: 2.1470114674290803
Validation loss: 2.5764927022011235

Epoch: 5| Step: 5
Training loss: 2.120979207636146
Validation loss: 2.557775581138477

Epoch: 5| Step: 6
Training loss: 2.3323687080810767
Validation loss: 2.5528534966256315

Epoch: 5| Step: 7
Training loss: 2.033074601185204
Validation loss: 2.5791915883620176

Epoch: 5| Step: 8
Training loss: 2.83373248336756
Validation loss: 2.6112478429816752

Epoch: 5| Step: 9
Training loss: 2.777417918313474
Validation loss: 2.6101768255350493

Epoch: 5| Step: 10
Training loss: 2.14163985872622
Validation loss: 2.6536140003235427

Epoch: 5| Step: 11
Training loss: 2.4433190748762335
Validation loss: 2.642799858720688

Epoch: 382| Step: 0
Training loss: 1.9889561195423815
Validation loss: 2.668284146687318

Epoch: 5| Step: 1
Training loss: 2.0760425660137316
Validation loss: 2.7024916162222588

Epoch: 5| Step: 2
Training loss: 1.3490804472138826
Validation loss: 2.622308668388235

Epoch: 5| Step: 3
Training loss: 2.1219326769893168
Validation loss: 2.570243822936891

Epoch: 5| Step: 4
Training loss: 2.1295592820101774
Validation loss: 2.5268119319291853

Epoch: 5| Step: 5
Training loss: 1.697972404017597
Validation loss: 2.4780915711446387

Epoch: 5| Step: 6
Training loss: 2.580886194486142
Validation loss: 2.4851869779699975

Epoch: 5| Step: 7
Training loss: 3.2071631308050446
Validation loss: 2.4883276766882867

Epoch: 5| Step: 8
Training loss: 2.4073732404919816
Validation loss: 2.5009899364959405

Epoch: 5| Step: 9
Training loss: 2.4052838454213004
Validation loss: 2.4909561008940457

Epoch: 5| Step: 10
Training loss: 2.5044000052490625
Validation loss: 2.513955353958271

Epoch: 5| Step: 11
Training loss: 3.152174329400214
Validation loss: 2.535175066752222

Epoch: 383| Step: 0
Training loss: 2.273400165474158
Validation loss: 2.5714121536867363

Epoch: 5| Step: 1
Training loss: 2.1519572331529018
Validation loss: 2.640207088288255

Epoch: 5| Step: 2
Training loss: 2.803311661339025
Validation loss: 2.7033130418644644

Epoch: 5| Step: 3
Training loss: 2.70195793580491
Validation loss: 2.770714464482175

Epoch: 5| Step: 4
Training loss: 2.20181170339829
Validation loss: 2.7724667600915676

Epoch: 5| Step: 5
Training loss: 2.5064380717880783
Validation loss: 2.753946135392174

Epoch: 5| Step: 6
Training loss: 2.0092212766516795
Validation loss: 2.71920853252216

Epoch: 5| Step: 7
Training loss: 1.7213187009665702
Validation loss: 2.641189221478552

Epoch: 5| Step: 8
Training loss: 2.0137848253512445
Validation loss: 2.596040113019181

Epoch: 5| Step: 9
Training loss: 1.2474448792352897
Validation loss: 2.5587403854788304

Epoch: 5| Step: 10
Training loss: 2.0425015383916545
Validation loss: 2.553921043062976

Epoch: 5| Step: 11
Training loss: 3.1692396218302292
Validation loss: 2.532132171625223

Epoch: 384| Step: 0
Training loss: 2.4891071476018127
Validation loss: 2.5314886624258603

Epoch: 5| Step: 1
Training loss: 2.3277379680720403
Validation loss: 2.513112070802516

Epoch: 5| Step: 2
Training loss: 2.360229337508278
Validation loss: 2.5294950586783327

Epoch: 5| Step: 3
Training loss: 1.9577042265816444
Validation loss: 2.5265392573696532

Epoch: 5| Step: 4
Training loss: 2.1483523820141586
Validation loss: 2.5479827960133203

Epoch: 5| Step: 5
Training loss: 2.374774119025648
Validation loss: 2.5525817514143805

Epoch: 5| Step: 6
Training loss: 1.9875027494591462
Validation loss: 2.6061080518132993

Epoch: 5| Step: 7
Training loss: 2.4269365148929127
Validation loss: 2.640930432745137

Epoch: 5| Step: 8
Training loss: 2.014656011407237
Validation loss: 2.6647001381555704

Epoch: 5| Step: 9
Training loss: 1.9891350192794117
Validation loss: 2.652747848657027

Epoch: 5| Step: 10
Training loss: 2.182411487964979
Validation loss: 2.639676075916627

Epoch: 5| Step: 11
Training loss: 1.6191605772622824
Validation loss: 2.6468093240900172

Epoch: 385| Step: 0
Training loss: 1.5267687249254225
Validation loss: 2.645031868953567

Epoch: 5| Step: 1
Training loss: 2.2115781684806652
Validation loss: 2.6425535262439155

Epoch: 5| Step: 2
Training loss: 2.5902644257347647
Validation loss: 2.603955124210287

Epoch: 5| Step: 3
Training loss: 2.281262645947665
Validation loss: 2.5552633493946413

Epoch: 5| Step: 4
Training loss: 1.8988633168845295
Validation loss: 2.5345629177518187

Epoch: 5| Step: 5
Training loss: 1.9625960551280663
Validation loss: 2.509653827636253

Epoch: 5| Step: 6
Training loss: 2.640186702310858
Validation loss: 2.528969722686227

Epoch: 5| Step: 7
Training loss: 1.8576163301454887
Validation loss: 2.4974787356579085

Epoch: 5| Step: 8
Training loss: 2.882177598297836
Validation loss: 2.4997894436860033

Epoch: 5| Step: 9
Training loss: 2.390312822690751
Validation loss: 2.5370259377706508

Epoch: 5| Step: 10
Training loss: 2.048049473328864
Validation loss: 2.573836402881685

Epoch: 5| Step: 11
Training loss: 1.7259938956514091
Validation loss: 2.627931275184744

Epoch: 386| Step: 0
Training loss: 1.8971281206404795
Validation loss: 2.6327055240559867

Epoch: 5| Step: 1
Training loss: 2.4297406843932947
Validation loss: 2.644215448964249

Epoch: 5| Step: 2
Training loss: 2.092245443850805
Validation loss: 2.613629008648441

Epoch: 5| Step: 3
Training loss: 1.9887583222086218
Validation loss: 2.6370480291778273

Epoch: 5| Step: 4
Training loss: 2.5934077577118506
Validation loss: 2.64729619073505

Epoch: 5| Step: 5
Training loss: 1.877385275290624
Validation loss: 2.640537775920269

Epoch: 5| Step: 6
Training loss: 1.930444360484021
Validation loss: 2.6435264282444737

Epoch: 5| Step: 7
Training loss: 2.3731510594735266
Validation loss: 2.65922181554535

Epoch: 5| Step: 8
Training loss: 2.271464222288074
Validation loss: 2.611399894722904

Epoch: 5| Step: 9
Training loss: 2.01033105486753
Validation loss: 2.6518561393012545

Epoch: 5| Step: 10
Training loss: 2.2536462273511786
Validation loss: 2.6468465972421362

Epoch: 5| Step: 11
Training loss: 2.191535714688977
Validation loss: 2.6583320199630345

Epoch: 387| Step: 0
Training loss: 2.3898012824024844
Validation loss: 2.559444225960255

Epoch: 5| Step: 1
Training loss: 1.682058532748719
Validation loss: 2.53749854020451

Epoch: 5| Step: 2
Training loss: 2.458972158242587
Validation loss: 2.527076321838749

Epoch: 5| Step: 3
Training loss: 2.5451749967055273
Validation loss: 2.500291860948438

Epoch: 5| Step: 4
Training loss: 2.4427284505594575
Validation loss: 2.508854860339083

Epoch: 5| Step: 5
Training loss: 2.3219500071345904
Validation loss: 2.5166242463018804

Epoch: 5| Step: 6
Training loss: 2.6998735398241305
Validation loss: 2.5045398618671553

Epoch: 5| Step: 7
Training loss: 1.8227546910576264
Validation loss: 2.524263758461269

Epoch: 5| Step: 8
Training loss: 2.16378220488472
Validation loss: 2.5885248829676795

Epoch: 5| Step: 9
Training loss: 2.2686050284650703
Validation loss: 2.6214869242692562

Epoch: 5| Step: 10
Training loss: 1.5867137794285298
Validation loss: 2.6112602109026155

Epoch: 5| Step: 11
Training loss: 1.6919047477821045
Validation loss: 2.623147462159853

Epoch: 388| Step: 0
Training loss: 1.4990425232905507
Validation loss: 2.608156963079096

Epoch: 5| Step: 1
Training loss: 1.653541870053092
Validation loss: 2.562683959498529

Epoch: 5| Step: 2
Training loss: 2.193707622759987
Validation loss: 2.5214068309503297

Epoch: 5| Step: 3
Training loss: 2.342341801075929
Validation loss: 2.5367918023783993

Epoch: 5| Step: 4
Training loss: 2.569807565364409
Validation loss: 2.5104657652447346

Epoch: 5| Step: 5
Training loss: 2.0796960614126347
Validation loss: 2.545540192662837

Epoch: 5| Step: 6
Training loss: 2.332507009873891
Validation loss: 2.519937676663208

Epoch: 5| Step: 7
Training loss: 2.6147962891277925
Validation loss: 2.5388260834007177

Epoch: 5| Step: 8
Training loss: 1.9848420802411697
Validation loss: 2.561054364699971

Epoch: 5| Step: 9
Training loss: 1.8555407058416036
Validation loss: 2.600981023985668

Epoch: 5| Step: 10
Training loss: 2.5842446493835354
Validation loss: 2.6046100518745896

Epoch: 5| Step: 11
Training loss: 2.1744008916293036
Validation loss: 2.6447323056400855

Epoch: 389| Step: 0
Training loss: 1.884673848660124
Validation loss: 2.692866637386763

Epoch: 5| Step: 1
Training loss: 2.2739220591115927
Validation loss: 2.739244296243995

Epoch: 5| Step: 2
Training loss: 2.3116304979563735
Validation loss: 2.713535353982115

Epoch: 5| Step: 3
Training loss: 2.767785989927917
Validation loss: 2.6814998581427645

Epoch: 5| Step: 4
Training loss: 2.039228527573822
Validation loss: 2.6875537859539436

Epoch: 5| Step: 5
Training loss: 1.7258599003924018
Validation loss: 2.6293672910298778

Epoch: 5| Step: 6
Training loss: 2.5138303622276053
Validation loss: 2.6159106465868756

Epoch: 5| Step: 7
Training loss: 2.2365180988496234
Validation loss: 2.597022030306436

Epoch: 5| Step: 8
Training loss: 2.226555325680602
Validation loss: 2.5932592479225014

Epoch: 5| Step: 9
Training loss: 1.5726831106970511
Validation loss: 2.597769522049665

Epoch: 5| Step: 10
Training loss: 2.7037774329484643
Validation loss: 2.5800263262238485

Epoch: 5| Step: 11
Training loss: 1.9553681576711588
Validation loss: 2.5729742732272243

Epoch: 390| Step: 0
Training loss: 2.26981088094178
Validation loss: 2.6199551917447432

Epoch: 5| Step: 1
Training loss: 2.5094509773581297
Validation loss: 2.6354228360150365

Epoch: 5| Step: 2
Training loss: 2.077529936757244
Validation loss: 2.6754356736575056

Epoch: 5| Step: 3
Training loss: 2.0792392812317066
Validation loss: 2.7127193015086575

Epoch: 5| Step: 4
Training loss: 2.746901847699472
Validation loss: 2.7299728234246055

Epoch: 5| Step: 5
Training loss: 2.4615778982918926
Validation loss: 2.7624016420624637

Epoch: 5| Step: 6
Training loss: 2.2199375037254487
Validation loss: 2.6783020805235913

Epoch: 5| Step: 7
Training loss: 2.202509043195434
Validation loss: 2.6561465897719803

Epoch: 5| Step: 8
Training loss: 2.2595235815301247
Validation loss: 2.6260703795841915

Epoch: 5| Step: 9
Training loss: 2.1843952489086287
Validation loss: 2.6045094963750595

Epoch: 5| Step: 10
Training loss: 1.5521146869266107
Validation loss: 2.5749534770164013

Epoch: 5| Step: 11
Training loss: 1.7254401654348521
Validation loss: 2.551339587355538

Epoch: 391| Step: 0
Training loss: 2.361308941001994
Validation loss: 2.5196073574823643

Epoch: 5| Step: 1
Training loss: 1.6654985705518128
Validation loss: 2.5130574212186176

Epoch: 5| Step: 2
Training loss: 2.6119442471838346
Validation loss: 2.4960726168458742

Epoch: 5| Step: 3
Training loss: 2.221822411280998
Validation loss: 2.5084765338470496

Epoch: 5| Step: 4
Training loss: 2.35418848573369
Validation loss: 2.5145469630238813

Epoch: 5| Step: 5
Training loss: 1.7136959327276855
Validation loss: 2.5369591123952193

Epoch: 5| Step: 6
Training loss: 2.3616581663285188
Validation loss: 2.560878442188439

Epoch: 5| Step: 7
Training loss: 2.074108630919317
Validation loss: 2.6113039147322996

Epoch: 5| Step: 8
Training loss: 2.190217210631981
Validation loss: 2.6303897354469057

Epoch: 5| Step: 9
Training loss: 2.3276278585845898
Validation loss: 2.680160032228268

Epoch: 5| Step: 10
Training loss: 2.9361388928668832
Validation loss: 2.6426223484275795

Epoch: 5| Step: 11
Training loss: 1.3244114738363675
Validation loss: 2.663790930426512

Epoch: 392| Step: 0
Training loss: 2.0970172725797473
Validation loss: 2.6136741551894938

Epoch: 5| Step: 1
Training loss: 2.2932683953620656
Validation loss: 2.6252226772925074

Epoch: 5| Step: 2
Training loss: 2.1562821759020867
Validation loss: 2.635085746032322

Epoch: 5| Step: 3
Training loss: 1.9528863379574124
Validation loss: 2.6451330960420263

Epoch: 5| Step: 4
Training loss: 2.4137746892424
Validation loss: 2.6146281277794885

Epoch: 5| Step: 5
Training loss: 2.439925136668416
Validation loss: 2.5823375964545834

Epoch: 5| Step: 6
Training loss: 2.213315729316349
Validation loss: 2.5678920286807014

Epoch: 5| Step: 7
Training loss: 1.8310313800599936
Validation loss: 2.565685045079429

Epoch: 5| Step: 8
Training loss: 2.3735312889709546
Validation loss: 2.558934378820987

Epoch: 5| Step: 9
Training loss: 1.913186008860166
Validation loss: 2.588055564374538

Epoch: 5| Step: 10
Training loss: 2.296856108088229
Validation loss: 2.591945911253362

Epoch: 5| Step: 11
Training loss: 2.0991782805982324
Validation loss: 2.6321138875686603

Epoch: 393| Step: 0
Training loss: 1.6556556642946436
Validation loss: 2.6401227552419657

Epoch: 5| Step: 1
Training loss: 1.903825750515794
Validation loss: 2.6914983142153255

Epoch: 5| Step: 2
Training loss: 1.959068897435849
Validation loss: 2.717820085241008

Epoch: 5| Step: 3
Training loss: 2.207389761914429
Validation loss: 2.732837957078604

Epoch: 5| Step: 4
Training loss: 2.001482414174066
Validation loss: 2.7080428896958315

Epoch: 5| Step: 5
Training loss: 2.192455672856673
Validation loss: 2.6898899060744283

Epoch: 5| Step: 6
Training loss: 2.6510142166924933
Validation loss: 2.6153716245290135

Epoch: 5| Step: 7
Training loss: 2.16909656229164
Validation loss: 2.5959233079862694

Epoch: 5| Step: 8
Training loss: 2.249258766997592
Validation loss: 2.574770531105525

Epoch: 5| Step: 9
Training loss: 2.614825740281477
Validation loss: 2.545832235228889

Epoch: 5| Step: 10
Training loss: 2.3873984310255243
Validation loss: 2.539729092467314

Epoch: 5| Step: 11
Training loss: 3.270097945493394
Validation loss: 2.554927871003873

Epoch: 394| Step: 0
Training loss: 2.6655106621713083
Validation loss: 2.562802622533843

Epoch: 5| Step: 1
Training loss: 2.523820121739458
Validation loss: 2.612782839928508

Epoch: 5| Step: 2
Training loss: 1.61630608316051
Validation loss: 2.6279780849922503

Epoch: 5| Step: 3
Training loss: 2.174541894308721
Validation loss: 2.6420179300996884

Epoch: 5| Step: 4
Training loss: 1.9718793793401437
Validation loss: 2.652418233867781

Epoch: 5| Step: 5
Training loss: 2.7057603987848453
Validation loss: 2.6373636620283247

Epoch: 5| Step: 6
Training loss: 1.780793784093162
Validation loss: 2.629717553809984

Epoch: 5| Step: 7
Training loss: 2.5454886940424233
Validation loss: 2.595335322705932

Epoch: 5| Step: 8
Training loss: 2.229801111461196
Validation loss: 2.61247016168739

Epoch: 5| Step: 9
Training loss: 2.087505765438684
Validation loss: 2.6372774977940874

Epoch: 5| Step: 10
Training loss: 1.7031845642313153
Validation loss: 2.5850499907246163

Epoch: 5| Step: 11
Training loss: 1.1461603333856307
Validation loss: 2.5554383794957953

Epoch: 395| Step: 0
Training loss: 2.5487864056092375
Validation loss: 2.571218777227292

Epoch: 5| Step: 1
Training loss: 2.4786885759569697
Validation loss: 2.5415357701933052

Epoch: 5| Step: 2
Training loss: 2.0299993332734916
Validation loss: 2.538656611156267

Epoch: 5| Step: 3
Training loss: 2.4101308267943473
Validation loss: 2.5173886989674936

Epoch: 5| Step: 4
Training loss: 1.8749310162887793
Validation loss: 2.505961411366773

Epoch: 5| Step: 5
Training loss: 2.142840943956455
Validation loss: 2.5301942625213356

Epoch: 5| Step: 6
Training loss: 2.081980520349669
Validation loss: 2.56131496204017

Epoch: 5| Step: 7
Training loss: 2.413515689486695
Validation loss: 2.5798037987411737

Epoch: 5| Step: 8
Training loss: 2.2297814374140965
Validation loss: 2.6310229761523685

Epoch: 5| Step: 9
Training loss: 2.052377773274442
Validation loss: 2.681510568360493

Epoch: 5| Step: 10
Training loss: 1.8180240112876085
Validation loss: 2.6768144714972397

Epoch: 5| Step: 11
Training loss: 2.214510453592908
Validation loss: 2.673001826964645

Epoch: 396| Step: 0
Training loss: 1.9613947848092264
Validation loss: 2.636366655365193

Epoch: 5| Step: 1
Training loss: 1.6906489203095285
Validation loss: 2.6249800370986196

Epoch: 5| Step: 2
Training loss: 2.95069987513349
Validation loss: 2.6030500014218303

Epoch: 5| Step: 3
Training loss: 2.0265911962025984
Validation loss: 2.564196261664004

Epoch: 5| Step: 4
Training loss: 2.565438702193193
Validation loss: 2.556610985397845

Epoch: 5| Step: 5
Training loss: 1.8571103192717326
Validation loss: 2.5354216700692334

Epoch: 5| Step: 6
Training loss: 1.6708631216360261
Validation loss: 2.5499650351302585

Epoch: 5| Step: 7
Training loss: 2.415249134742322
Validation loss: 2.5513623828205603

Epoch: 5| Step: 8
Training loss: 2.017169094814308
Validation loss: 2.5753201919846287

Epoch: 5| Step: 9
Training loss: 1.9145963586053556
Validation loss: 2.5737821394914717

Epoch: 5| Step: 10
Training loss: 2.4044218178086187
Validation loss: 2.5614524343783875

Epoch: 5| Step: 11
Training loss: 2.527133089746125
Validation loss: 2.555614054541294

Epoch: 397| Step: 0
Training loss: 2.2152176798684278
Validation loss: 2.5583659335139606

Epoch: 5| Step: 1
Training loss: 2.2651345610068674
Validation loss: 2.5882197102451103

Epoch: 5| Step: 2
Training loss: 2.101004600922941
Validation loss: 2.6539111368207133

Epoch: 5| Step: 3
Training loss: 2.145644046866696
Validation loss: 2.603121052953102

Epoch: 5| Step: 4
Training loss: 2.7225072045489247
Validation loss: 2.6362661203959004

Epoch: 5| Step: 5
Training loss: 2.234682075366943
Validation loss: 2.665768231102483

Epoch: 5| Step: 6
Training loss: 2.6083063004365443
Validation loss: 2.6719722321127746

Epoch: 5| Step: 7
Training loss: 2.130525585573304
Validation loss: 2.643106938184122

Epoch: 5| Step: 8
Training loss: 1.9946564577924282
Validation loss: 2.646036092743648

Epoch: 5| Step: 9
Training loss: 1.4851913616558994
Validation loss: 2.612252953513237

Epoch: 5| Step: 10
Training loss: 1.9502247142915405
Validation loss: 2.60818081405792

Epoch: 5| Step: 11
Training loss: 1.6158677027671755
Validation loss: 2.5797266599231032

Epoch: 398| Step: 0
Training loss: 2.5532545451399535
Validation loss: 2.558567860401975

Epoch: 5| Step: 1
Training loss: 1.9907516391301405
Validation loss: 2.545632478581404

Epoch: 5| Step: 2
Training loss: 1.802384794153987
Validation loss: 2.5462700021876072

Epoch: 5| Step: 3
Training loss: 2.8946045571541137
Validation loss: 2.527334461853475

Epoch: 5| Step: 4
Training loss: 1.8384239728249363
Validation loss: 2.5523640899890836

Epoch: 5| Step: 5
Training loss: 1.7139790990216113
Validation loss: 2.6084254016003814

Epoch: 5| Step: 6
Training loss: 2.084371142977187
Validation loss: 2.631181681600081

Epoch: 5| Step: 7
Training loss: 2.480649349816863
Validation loss: 2.6400094396399543

Epoch: 5| Step: 8
Training loss: 2.2027429560565035
Validation loss: 2.6233734700134907

Epoch: 5| Step: 9
Training loss: 2.6421599131203704
Validation loss: 2.5946422941770924

Epoch: 5| Step: 10
Training loss: 1.6934216761760479
Validation loss: 2.5825254358858944

Epoch: 5| Step: 11
Training loss: 1.7748414922512312
Validation loss: 2.5713729989578704

Epoch: 399| Step: 0
Training loss: 2.2282588453071277
Validation loss: 2.556969909211936

Epoch: 5| Step: 1
Training loss: 1.989962782967057
Validation loss: 2.560797265189098

Epoch: 5| Step: 2
Training loss: 2.035244696337152
Validation loss: 2.6090318678818565

Epoch: 5| Step: 3
Training loss: 1.9290460918253345
Validation loss: 2.637087628969875

Epoch: 5| Step: 4
Training loss: 2.1579585286310543
Validation loss: 2.6376311543775834

Epoch: 5| Step: 5
Training loss: 2.447469813907872
Validation loss: 2.6858633883675855

Epoch: 5| Step: 6
Training loss: 2.303827054023073
Validation loss: 2.6794567731725745

Epoch: 5| Step: 7
Training loss: 1.7397113532131643
Validation loss: 2.657129261871527

Epoch: 5| Step: 8
Training loss: 2.8998133434866094
Validation loss: 2.681277215963269

Epoch: 5| Step: 9
Training loss: 2.1647083406696606
Validation loss: 2.6245895019360246

Epoch: 5| Step: 10
Training loss: 1.6477510731571612
Validation loss: 2.5897426173130724

Epoch: 5| Step: 11
Training loss: 2.129343082512354
Validation loss: 2.560230025050214

Epoch: 400| Step: 0
Training loss: 2.5449583178331343
Validation loss: 2.570299884799969

Epoch: 5| Step: 1
Training loss: 2.0357675641002646
Validation loss: 2.5779378264328305

Epoch: 5| Step: 2
Training loss: 2.1207666302916715
Validation loss: 2.559948992767411

Epoch: 5| Step: 3
Training loss: 2.663555734711873
Validation loss: 2.556812598241624

Epoch: 5| Step: 4
Training loss: 2.0325621841508776
Validation loss: 2.567149290364293

Epoch: 5| Step: 5
Training loss: 1.7766854544762105
Validation loss: 2.5799540726445227

Epoch: 5| Step: 6
Training loss: 2.2506240403189994
Validation loss: 2.5662298582202947

Epoch: 5| Step: 7
Training loss: 2.2421650636195074
Validation loss: 2.581948523800068

Epoch: 5| Step: 8
Training loss: 1.3224491685065598
Validation loss: 2.609976008293992

Epoch: 5| Step: 9
Training loss: 2.333752480961728
Validation loss: 2.630488738922618

Epoch: 5| Step: 10
Training loss: 2.286474646392072
Validation loss: 2.6745099836961765

Epoch: 5| Step: 11
Training loss: 1.1794084130402247
Validation loss: 2.680777036304812

Epoch: 401| Step: 0
Training loss: 2.161614641413032
Validation loss: 2.699065767655539

Epoch: 5| Step: 1
Training loss: 2.1013961782901207
Validation loss: 2.608569106413724

Epoch: 5| Step: 2
Training loss: 1.7496599139413136
Validation loss: 2.5965931755920093

Epoch: 5| Step: 3
Training loss: 2.0643847552538768
Validation loss: 2.5124911815811193

Epoch: 5| Step: 4
Training loss: 2.5561502451191243
Validation loss: 2.5140996695916713

Epoch: 5| Step: 5
Training loss: 2.4971688452157403
Validation loss: 2.508727456387366

Epoch: 5| Step: 6
Training loss: 2.6699061585126307
Validation loss: 2.4879159744096477

Epoch: 5| Step: 7
Training loss: 2.4734072637005142
Validation loss: 2.5267560217510616

Epoch: 5| Step: 8
Training loss: 1.973707949846953
Validation loss: 2.5426074004205788

Epoch: 5| Step: 9
Training loss: 2.567419215104231
Validation loss: 2.5453897681859807

Epoch: 5| Step: 10
Training loss: 1.512695785335223
Validation loss: 2.6025480135441073

Epoch: 5| Step: 11
Training loss: 1.7008068161647505
Validation loss: 2.6771172559694163

Epoch: 402| Step: 0
Training loss: 1.688840616140032
Validation loss: 2.6929006686161627

Epoch: 5| Step: 1
Training loss: 2.5603315901582944
Validation loss: 2.7462403903550543

Epoch: 5| Step: 2
Training loss: 2.19527340239873
Validation loss: 2.6900676430619757

Epoch: 5| Step: 3
Training loss: 2.0937301862547795
Validation loss: 2.6701907301821035

Epoch: 5| Step: 4
Training loss: 2.454158298065822
Validation loss: 2.5907452693825954

Epoch: 5| Step: 5
Training loss: 2.2362934759529214
Validation loss: 2.559626972959349

Epoch: 5| Step: 6
Training loss: 2.1456020440446757
Validation loss: 2.522110447376798

Epoch: 5| Step: 7
Training loss: 2.4166960440417635
Validation loss: 2.5123790962552404

Epoch: 5| Step: 8
Training loss: 1.9700947362127843
Validation loss: 2.5147237051652733

Epoch: 5| Step: 9
Training loss: 2.373377798106822
Validation loss: 2.5129950085566475

Epoch: 5| Step: 10
Training loss: 2.1071356295260784
Validation loss: 2.5194197637451277

Epoch: 5| Step: 11
Training loss: 1.0101991530746206
Validation loss: 2.5328599142899755

Epoch: 403| Step: 0
Training loss: 2.0497318743767288
Validation loss: 2.543961557249797

Epoch: 5| Step: 1
Training loss: 2.0742613937103624
Validation loss: 2.5562602965529173

Epoch: 5| Step: 2
Training loss: 1.7483407737833014
Validation loss: 2.584956491099262

Epoch: 5| Step: 3
Training loss: 1.665037272611758
Validation loss: 2.6706184905336126

Epoch: 5| Step: 4
Training loss: 2.157798874222966
Validation loss: 2.6871519232977223

Epoch: 5| Step: 5
Training loss: 1.926154729132076
Validation loss: 2.6989944114516486

Epoch: 5| Step: 6
Training loss: 2.6354672775133268
Validation loss: 2.6892878957914585

Epoch: 5| Step: 7
Training loss: 1.8863234332878078
Validation loss: 2.696876289688574

Epoch: 5| Step: 8
Training loss: 2.4991829490661206
Validation loss: 2.683889207118314

Epoch: 5| Step: 9
Training loss: 2.5469455826228966
Validation loss: 2.623570832739367

Epoch: 5| Step: 10
Training loss: 2.4540757201807892
Validation loss: 2.568603531095052

Epoch: 5| Step: 11
Training loss: 1.9096825135081175
Validation loss: 2.5629179950887004

Epoch: 404| Step: 0
Training loss: 2.2957049652969803
Validation loss: 2.5058706813050744

Epoch: 5| Step: 1
Training loss: 2.1316624709329877
Validation loss: 2.509053676771997

Epoch: 5| Step: 2
Training loss: 2.2906728034346195
Validation loss: 2.5140873847901046

Epoch: 5| Step: 3
Training loss: 2.5018105626343083
Validation loss: 2.507043976244747

Epoch: 5| Step: 4
Training loss: 1.4575777639644274
Validation loss: 2.4968939639227927

Epoch: 5| Step: 5
Training loss: 2.3719597480922445
Validation loss: 2.4889560325475477

Epoch: 5| Step: 6
Training loss: 1.851622954721621
Validation loss: 2.5063004416497394

Epoch: 5| Step: 7
Training loss: 1.6799690897686554
Validation loss: 2.532251348348434

Epoch: 5| Step: 8
Training loss: 2.4929626598660333
Validation loss: 2.5834505390425595

Epoch: 5| Step: 9
Training loss: 2.701686321926767
Validation loss: 2.643115582711314

Epoch: 5| Step: 10
Training loss: 2.507435422695232
Validation loss: 2.727542038135246

Epoch: 5| Step: 11
Training loss: 2.8998960542136922
Validation loss: 2.707778999868331

Epoch: 405| Step: 0
Training loss: 2.1828710352941316
Validation loss: 2.7209173055681957

Epoch: 5| Step: 1
Training loss: 2.3725389478599817
Validation loss: 2.779813509810515

Epoch: 5| Step: 2
Training loss: 2.2133987799509005
Validation loss: 2.7269616549870808

Epoch: 5| Step: 3
Training loss: 2.176337179665018
Validation loss: 2.7158238094178837

Epoch: 5| Step: 4
Training loss: 2.291247682128
Validation loss: 2.62791423398505

Epoch: 5| Step: 5
Training loss: 1.687513351387612
Validation loss: 2.553953421114198

Epoch: 5| Step: 6
Training loss: 1.587798506538639
Validation loss: 2.49982010273582

Epoch: 5| Step: 7
Training loss: 1.8948439507159152
Validation loss: 2.457941942793642

Epoch: 5| Step: 8
Training loss: 2.620877889508141
Validation loss: 2.4772714729235648

Epoch: 5| Step: 9
Training loss: 2.6460272249881363
Validation loss: 2.4792272830145605

Epoch: 5| Step: 10
Training loss: 2.4107977756796957
Validation loss: 2.475144835931968

Epoch: 5| Step: 11
Training loss: 2.111955773490171
Validation loss: 2.475768426292354

Epoch: 406| Step: 0
Training loss: 1.6238938014348792
Validation loss: 2.4909379590972502

Epoch: 5| Step: 1
Training loss: 2.126843045891706
Validation loss: 2.4742047210607203

Epoch: 5| Step: 2
Training loss: 2.486770051216673
Validation loss: 2.4843681383338074

Epoch: 5| Step: 3
Training loss: 2.319650060964902
Validation loss: 2.5006296556997207

Epoch: 5| Step: 4
Training loss: 2.166352530472684
Validation loss: 2.5088787881979933

Epoch: 5| Step: 5
Training loss: 1.9945974097689199
Validation loss: 2.5079014624703952

Epoch: 5| Step: 6
Training loss: 2.34490775441359
Validation loss: 2.5365002032720474

Epoch: 5| Step: 7
Training loss: 2.495804317689932
Validation loss: 2.5482711709646706

Epoch: 5| Step: 8
Training loss: 2.187261077912104
Validation loss: 2.585786974502937

Epoch: 5| Step: 9
Training loss: 2.123897715388415
Validation loss: 2.5938678163174638

Epoch: 5| Step: 10
Training loss: 1.9952426596466966
Validation loss: 2.638208735942386

Epoch: 5| Step: 11
Training loss: 1.5549284015130045
Validation loss: 2.618776861764681

Epoch: 407| Step: 0
Training loss: 1.308059218821825
Validation loss: 2.627621613146225

Epoch: 5| Step: 1
Training loss: 2.1026334054832296
Validation loss: 2.5993351876531157

Epoch: 5| Step: 2
Training loss: 2.35115833547927
Validation loss: 2.561842461868186

Epoch: 5| Step: 3
Training loss: 1.8348693987237688
Validation loss: 2.555277726083471

Epoch: 5| Step: 4
Training loss: 2.1733326582917334
Validation loss: 2.5270016422470185

Epoch: 5| Step: 5
Training loss: 2.2111073351220245
Validation loss: 2.516022285539868

Epoch: 5| Step: 6
Training loss: 2.4117279121761195
Validation loss: 2.509161878271062

Epoch: 5| Step: 7
Training loss: 2.665285964996537
Validation loss: 2.5082381492331494

Epoch: 5| Step: 8
Training loss: 1.6947511367625223
Validation loss: 2.5169024294405373

Epoch: 5| Step: 9
Training loss: 2.196225665353344
Validation loss: 2.497354064899737

Epoch: 5| Step: 10
Training loss: 2.2928692407802416
Validation loss: 2.503505109293794

Epoch: 5| Step: 11
Training loss: 2.46237595918655
Validation loss: 2.526874115363718

Epoch: 408| Step: 0
Training loss: 2.7332634110539993
Validation loss: 2.5268930684853537

Epoch: 5| Step: 1
Training loss: 2.5841607850307273
Validation loss: 2.5890664515966826

Epoch: 5| Step: 2
Training loss: 2.5044135235954883
Validation loss: 2.5334064144230193

Epoch: 5| Step: 3
Training loss: 1.583427811196413
Validation loss: 2.6015063022962672

Epoch: 5| Step: 4
Training loss: 2.640107504794329
Validation loss: 2.6537384164299525

Epoch: 5| Step: 5
Training loss: 2.137454058058624
Validation loss: 2.673390291571191

Epoch: 5| Step: 6
Training loss: 1.3905475894941788
Validation loss: 2.6991823288723316

Epoch: 5| Step: 7
Training loss: 2.0946368716229555
Validation loss: 2.672060924701564

Epoch: 5| Step: 8
Training loss: 1.2829380080870234
Validation loss: 2.6327680061421765

Epoch: 5| Step: 9
Training loss: 1.9807834713760828
Validation loss: 2.5992610859535588

Epoch: 5| Step: 10
Training loss: 2.1778627913721316
Validation loss: 2.5480871455961482

Epoch: 5| Step: 11
Training loss: 1.8188298289814258
Validation loss: 2.571649607488287

Epoch: 409| Step: 0
Training loss: 1.4083270522359395
Validation loss: 2.528860498830977

Epoch: 5| Step: 1
Training loss: 2.364483689772814
Validation loss: 2.5291376876323013

Epoch: 5| Step: 2
Training loss: 1.6243083655739106
Validation loss: 2.50603658119447

Epoch: 5| Step: 3
Training loss: 2.2406121544888715
Validation loss: 2.5104256639015983

Epoch: 5| Step: 4
Training loss: 2.4620675535068095
Validation loss: 2.495301241720907

Epoch: 5| Step: 5
Training loss: 1.8252186944646636
Validation loss: 2.5237850111330484

Epoch: 5| Step: 6
Training loss: 2.7885004754219107
Validation loss: 2.504917192625955

Epoch: 5| Step: 7
Training loss: 2.079881657021465
Validation loss: 2.5530124932118046

Epoch: 5| Step: 8
Training loss: 2.3904522602777476
Validation loss: 2.551206490013099

Epoch: 5| Step: 9
Training loss: 2.207460506859242
Validation loss: 2.6248525358590036

Epoch: 5| Step: 10
Training loss: 1.9151750717613822
Validation loss: 2.6786430406837116

Epoch: 5| Step: 11
Training loss: 1.8520123542884404
Validation loss: 2.708082606863229

Epoch: 410| Step: 0
Training loss: 1.4841393534685063
Validation loss: 2.6885966421835117

Epoch: 5| Step: 1
Training loss: 2.1681378822680717
Validation loss: 2.6745745348742305

Epoch: 5| Step: 2
Training loss: 2.418621314122306
Validation loss: 2.6939482327575424

Epoch: 5| Step: 3
Training loss: 1.6964675554657822
Validation loss: 2.627478379463993

Epoch: 5| Step: 4
Training loss: 2.2763401653399353
Validation loss: 2.616211165328121

Epoch: 5| Step: 5
Training loss: 1.9773870263701248
Validation loss: 2.552569433875104

Epoch: 5| Step: 6
Training loss: 1.7287629203837636
Validation loss: 2.5234737373954648

Epoch: 5| Step: 7
Training loss: 2.3106261213164205
Validation loss: 2.5402313711074416

Epoch: 5| Step: 8
Training loss: 2.079931176954348
Validation loss: 2.5187041351837527

Epoch: 5| Step: 9
Training loss: 2.4922441338588612
Validation loss: 2.510852935417814

Epoch: 5| Step: 10
Training loss: 2.419231128401028
Validation loss: 2.501747001755431

Epoch: 5| Step: 11
Training loss: 1.8147420499159528
Validation loss: 2.510189134461725

Epoch: 411| Step: 0
Training loss: 1.7082016901916997
Validation loss: 2.5348051089549095

Epoch: 5| Step: 1
Training loss: 1.982194137646325
Validation loss: 2.534674917647688

Epoch: 5| Step: 2
Training loss: 1.9457003654884693
Validation loss: 2.579664248649176

Epoch: 5| Step: 3
Training loss: 1.78795966260328
Validation loss: 2.552827856234253

Epoch: 5| Step: 4
Training loss: 1.786026089557814
Validation loss: 2.5434803719052868

Epoch: 5| Step: 5
Training loss: 1.6434328302642405
Validation loss: 2.537900449445992

Epoch: 5| Step: 6
Training loss: 2.7112214657032516
Validation loss: 2.562482422869185

Epoch: 5| Step: 7
Training loss: 2.5871562563579364
Validation loss: 2.574098996207065

Epoch: 5| Step: 8
Training loss: 1.948998692996985
Validation loss: 2.590681708604455

Epoch: 5| Step: 9
Training loss: 2.6450933087337316
Validation loss: 2.637868096667652

Epoch: 5| Step: 10
Training loss: 2.212741183481354
Validation loss: 2.6833885332811365

Epoch: 5| Step: 11
Training loss: 1.735324084440584
Validation loss: 2.74493260658142

Epoch: 412| Step: 0
Training loss: 1.879806144439042
Validation loss: 2.7709012429560684

Epoch: 5| Step: 1
Training loss: 2.106652770881858
Validation loss: 2.785246367421087

Epoch: 5| Step: 2
Training loss: 2.4022995859444056
Validation loss: 2.7768882023757

Epoch: 5| Step: 3
Training loss: 2.126452902969488
Validation loss: 2.7641177371557935

Epoch: 5| Step: 4
Training loss: 2.434170233717249
Validation loss: 2.7263598617264724

Epoch: 5| Step: 5
Training loss: 1.8626693904577358
Validation loss: 2.6275758707106425

Epoch: 5| Step: 6
Training loss: 2.062510634886171
Validation loss: 2.564168877015408

Epoch: 5| Step: 7
Training loss: 1.7745335086809142
Validation loss: 2.558795367734615

Epoch: 5| Step: 8
Training loss: 2.724020836272912
Validation loss: 2.5265482614116395

Epoch: 5| Step: 9
Training loss: 1.514312490447591
Validation loss: 2.5204692779988833

Epoch: 5| Step: 10
Training loss: 2.3876318051370182
Validation loss: 2.501894002945974

Epoch: 5| Step: 11
Training loss: 2.697864860911172
Validation loss: 2.5024605444199577

Epoch: 413| Step: 0
Training loss: 2.4507016403406316
Validation loss: 2.5145570806309108

Epoch: 5| Step: 1
Training loss: 1.736736648611484
Validation loss: 2.535444113008952

Epoch: 5| Step: 2
Training loss: 2.3460792665545798
Validation loss: 2.582196498244087

Epoch: 5| Step: 3
Training loss: 2.3211546117917354
Validation loss: 2.5940260606185577

Epoch: 5| Step: 4
Training loss: 1.942773533222169
Validation loss: 2.612129333885341

Epoch: 5| Step: 5
Training loss: 2.5377116674076614
Validation loss: 2.6592686423801553

Epoch: 5| Step: 6
Training loss: 2.10956194013939
Validation loss: 2.6823913901349288

Epoch: 5| Step: 7
Training loss: 1.9005177093700418
Validation loss: 2.628028821451595

Epoch: 5| Step: 8
Training loss: 1.6489576630903253
Validation loss: 2.636200292030316

Epoch: 5| Step: 9
Training loss: 2.173144950347244
Validation loss: 2.62348111426713

Epoch: 5| Step: 10
Training loss: 2.144540032818707
Validation loss: 2.562356394333689

Epoch: 5| Step: 11
Training loss: 1.391208269190877
Validation loss: 2.5519718781611416

Epoch: 414| Step: 0
Training loss: 1.9774828792173287
Validation loss: 2.544296195542514

Epoch: 5| Step: 1
Training loss: 2.5238631984798845
Validation loss: 2.5110305072592682

Epoch: 5| Step: 2
Training loss: 2.6817305092080623
Validation loss: 2.5288506564712683

Epoch: 5| Step: 3
Training loss: 1.5972152884881083
Validation loss: 2.5206721283201814

Epoch: 5| Step: 4
Training loss: 2.338646584063913
Validation loss: 2.5564334786438208

Epoch: 5| Step: 5
Training loss: 1.518593309898717
Validation loss: 2.5417650130792713

Epoch: 5| Step: 6
Training loss: 1.8833578119403203
Validation loss: 2.5558395238050333

Epoch: 5| Step: 7
Training loss: 1.7704633737700783
Validation loss: 2.5776302672137605

Epoch: 5| Step: 8
Training loss: 2.2393846172325347
Validation loss: 2.57902337037239

Epoch: 5| Step: 9
Training loss: 2.2786645739556723
Validation loss: 2.5820404260330934

Epoch: 5| Step: 10
Training loss: 1.9676024710546443
Validation loss: 2.6115051643200737

Epoch: 5| Step: 11
Training loss: 3.174307656081714
Validation loss: 2.638617593360816

Epoch: 415| Step: 0
Training loss: 1.8658387488212327
Validation loss: 2.675615982186604

Epoch: 5| Step: 1
Training loss: 2.1691141487922487
Validation loss: 2.715317803212804

Epoch: 5| Step: 2
Training loss: 2.2963307053655275
Validation loss: 2.655007030408307

Epoch: 5| Step: 3
Training loss: 2.1311121160478095
Validation loss: 2.606677600871403

Epoch: 5| Step: 4
Training loss: 2.586624100456142
Validation loss: 2.592221951308438

Epoch: 5| Step: 5
Training loss: 1.2342850857593057
Validation loss: 2.5668045346483415

Epoch: 5| Step: 6
Training loss: 2.111025016546085
Validation loss: 2.5541412010499873

Epoch: 5| Step: 7
Training loss: 2.250747026834089
Validation loss: 2.56430857692374

Epoch: 5| Step: 8
Training loss: 2.1061485198163052
Validation loss: 2.5716398767442663

Epoch: 5| Step: 9
Training loss: 1.620770010736828
Validation loss: 2.5510815594068164

Epoch: 5| Step: 10
Training loss: 2.2526132454808616
Validation loss: 2.5569219315476146

Epoch: 5| Step: 11
Training loss: 1.7116120981186915
Validation loss: 2.6009140199243617

Epoch: 416| Step: 0
Training loss: 2.5285345512022444
Validation loss: 2.588074426421727

Epoch: 5| Step: 1
Training loss: 1.9219651239864979
Validation loss: 2.6536650383990246

Epoch: 5| Step: 2
Training loss: 2.206589484099086
Validation loss: 2.664704294916409

Epoch: 5| Step: 3
Training loss: 1.9691744755501177
Validation loss: 2.657208086646096

Epoch: 5| Step: 4
Training loss: 1.711861278288137
Validation loss: 2.6644520442154938

Epoch: 5| Step: 5
Training loss: 2.024106301791823
Validation loss: 2.610664034055344

Epoch: 5| Step: 6
Training loss: 1.7075008907287865
Validation loss: 2.5972819276113404

Epoch: 5| Step: 7
Training loss: 2.1624278150208345
Validation loss: 2.5917023538747097

Epoch: 5| Step: 8
Training loss: 2.2713604119965862
Validation loss: 2.573163010442573

Epoch: 5| Step: 9
Training loss: 2.5004002250745736
Validation loss: 2.56064005938487

Epoch: 5| Step: 10
Training loss: 1.9019742446262724
Validation loss: 2.571149332316415

Epoch: 5| Step: 11
Training loss: 2.5688180956202857
Validation loss: 2.575111936555923

Epoch: 417| Step: 0
Training loss: 2.0421633473072034
Validation loss: 2.55118011269237

Epoch: 5| Step: 1
Training loss: 2.157769814745144
Validation loss: 2.566849440459854

Epoch: 5| Step: 2
Training loss: 2.406089876470192
Validation loss: 2.558057306560421

Epoch: 5| Step: 3
Training loss: 2.0178331212134264
Validation loss: 2.532722190236849

Epoch: 5| Step: 4
Training loss: 1.8968430090630837
Validation loss: 2.569361285562241

Epoch: 5| Step: 5
Training loss: 2.204916908445902
Validation loss: 2.545183306421083

Epoch: 5| Step: 6
Training loss: 2.042816915030258
Validation loss: 2.5864279129281673

Epoch: 5| Step: 7
Training loss: 1.9552837800996625
Validation loss: 2.6570623539389557

Epoch: 5| Step: 8
Training loss: 1.8913658519087737
Validation loss: 2.688059197881164

Epoch: 5| Step: 9
Training loss: 2.601495323803079
Validation loss: 2.7011494041422113

Epoch: 5| Step: 10
Training loss: 1.916454704284826
Validation loss: 2.720263231749015

Epoch: 5| Step: 11
Training loss: 2.4458735495731805
Validation loss: 2.6908175004895174

Epoch: 418| Step: 0
Training loss: 2.0390793372149676
Validation loss: 2.6016713445154234

Epoch: 5| Step: 1
Training loss: 2.046176587409203
Validation loss: 2.5143068188955837

Epoch: 5| Step: 2
Training loss: 2.843901242436769
Validation loss: 2.5098048779773805

Epoch: 5| Step: 3
Training loss: 2.020633831860314
Validation loss: 2.4938669037087666

Epoch: 5| Step: 4
Training loss: 2.3407167261381088
Validation loss: 2.4971503626713334

Epoch: 5| Step: 5
Training loss: 2.5600371271659834
Validation loss: 2.5060383670079136

Epoch: 5| Step: 6
Training loss: 2.6220372146421305
Validation loss: 2.508467175840545

Epoch: 5| Step: 7
Training loss: 1.7609853634764878
Validation loss: 2.499184022300251

Epoch: 5| Step: 8
Training loss: 1.738866540333896
Validation loss: 2.5131298865076546

Epoch: 5| Step: 9
Training loss: 2.2487092024286737
Validation loss: 2.5266834007562897

Epoch: 5| Step: 10
Training loss: 1.9141429027875296
Validation loss: 2.6230351155941323

Epoch: 5| Step: 11
Training loss: 2.626755173042441
Validation loss: 2.648222015226756

Epoch: 419| Step: 0
Training loss: 2.2000839130697583
Validation loss: 2.6708610276340146

Epoch: 5| Step: 1
Training loss: 2.249345790273788
Validation loss: 2.7065400140727736

Epoch: 5| Step: 2
Training loss: 2.0520019386014647
Validation loss: 2.723608371337268

Epoch: 5| Step: 3
Training loss: 2.08373381262283
Validation loss: 2.6756095181416515

Epoch: 5| Step: 4
Training loss: 1.6614176905652573
Validation loss: 2.6296411236311314

Epoch: 5| Step: 5
Training loss: 1.9538558203020817
Validation loss: 2.5937217151677583

Epoch: 5| Step: 6
Training loss: 1.9071578068603958
Validation loss: 2.555493102370186

Epoch: 5| Step: 7
Training loss: 2.785754724006444
Validation loss: 2.527118949974597

Epoch: 5| Step: 8
Training loss: 1.9632180619308204
Validation loss: 2.550640927982988

Epoch: 5| Step: 9
Training loss: 1.6227966923699486
Validation loss: 2.5286672783101705

Epoch: 5| Step: 10
Training loss: 2.3266149142210724
Validation loss: 2.500048446185867

Epoch: 5| Step: 11
Training loss: 2.823234418226944
Validation loss: 2.506705928294853

Epoch: 420| Step: 0
Training loss: 1.8632442062822208
Validation loss: 2.5035936137600148

Epoch: 5| Step: 1
Training loss: 1.6753557282947273
Validation loss: 2.532166754559034

Epoch: 5| Step: 2
Training loss: 2.078641669500914
Validation loss: 2.5776539073519613

Epoch: 5| Step: 3
Training loss: 2.266201814032958
Validation loss: 2.58092876910899

Epoch: 5| Step: 4
Training loss: 2.199378541389079
Validation loss: 2.6147807010054662

Epoch: 5| Step: 5
Training loss: 1.8244552295656178
Validation loss: 2.5901510786058703

Epoch: 5| Step: 6
Training loss: 2.627753130972159
Validation loss: 2.5851995062376996

Epoch: 5| Step: 7
Training loss: 1.9075586798405213
Validation loss: 2.611668342258311

Epoch: 5| Step: 8
Training loss: 2.7649756924766216
Validation loss: 2.5868375274138877

Epoch: 5| Step: 9
Training loss: 2.2590723449686703
Validation loss: 2.543676501500253

Epoch: 5| Step: 10
Training loss: 1.828485045883285
Validation loss: 2.55394652078066

Epoch: 5| Step: 11
Training loss: 1.8814020849453783
Validation loss: 2.522797140119355

Epoch: 421| Step: 0
Training loss: 2.7343164056221965
Validation loss: 2.5191530973946223

Epoch: 5| Step: 1
Training loss: 1.4556654186541884
Validation loss: 2.484029721912304

Epoch: 5| Step: 2
Training loss: 2.7724525099488857
Validation loss: 2.4844952360283967

Epoch: 5| Step: 3
Training loss: 1.7775337536875797
Validation loss: 2.4566090983780335

Epoch: 5| Step: 4
Training loss: 2.164532001120453
Validation loss: 2.470363656949345

Epoch: 5| Step: 5
Training loss: 2.105690004970744
Validation loss: 2.49305616285505

Epoch: 5| Step: 6
Training loss: 2.2541174830948796
Validation loss: 2.575389686436566

Epoch: 5| Step: 7
Training loss: 2.053620267962549
Validation loss: 2.596389901627262

Epoch: 5| Step: 8
Training loss: 2.1470728753865016
Validation loss: 2.6166291034992932

Epoch: 5| Step: 9
Training loss: 1.772598000683626
Validation loss: 2.5971007859869544

Epoch: 5| Step: 10
Training loss: 2.1889622841657745
Validation loss: 2.6047057178808357

Epoch: 5| Step: 11
Training loss: 2.184070514637505
Validation loss: 2.602645896641708

Epoch: 422| Step: 0
Training loss: 1.6104970187349388
Validation loss: 2.6145824961768604

Epoch: 5| Step: 1
Training loss: 2.4106736578368757
Validation loss: 2.635725053578661

Epoch: 5| Step: 2
Training loss: 2.2054353328366303
Validation loss: 2.6468905842159773

Epoch: 5| Step: 3
Training loss: 2.077082551773011
Validation loss: 2.6405274074058815

Epoch: 5| Step: 4
Training loss: 2.4234420136853014
Validation loss: 2.628294206086935

Epoch: 5| Step: 5
Training loss: 2.1469156319716998
Validation loss: 2.6194074524689777

Epoch: 5| Step: 6
Training loss: 1.8809378380813966
Validation loss: 2.6082142324850515

Epoch: 5| Step: 7
Training loss: 2.1769447708448735
Validation loss: 2.5931914735470505

Epoch: 5| Step: 8
Training loss: 2.000208962968202
Validation loss: 2.590668314474658

Epoch: 5| Step: 9
Training loss: 2.0315786242582314
Validation loss: 2.5690327156956516

Epoch: 5| Step: 10
Training loss: 2.475178906688805
Validation loss: 2.5682243437377807

Epoch: 5| Step: 11
Training loss: 1.2787981065667495
Validation loss: 2.5524286244158674

Epoch: 423| Step: 0
Training loss: 2.2970508326484627
Validation loss: 2.5775573201809667

Epoch: 5| Step: 1
Training loss: 2.013425469700777
Validation loss: 2.582448766888892

Epoch: 5| Step: 2
Training loss: 2.2065921853087453
Validation loss: 2.5587947077371385

Epoch: 5| Step: 3
Training loss: 1.670191121843212
Validation loss: 2.5564141305525667

Epoch: 5| Step: 4
Training loss: 1.84455362683642
Validation loss: 2.5526125313814374

Epoch: 5| Step: 5
Training loss: 2.685898858325559
Validation loss: 2.570697384572688

Epoch: 5| Step: 6
Training loss: 2.121785930848453
Validation loss: 2.5810562539838604

Epoch: 5| Step: 7
Training loss: 2.4673772930952276
Validation loss: 2.604070491286394

Epoch: 5| Step: 8
Training loss: 1.7384855343225338
Validation loss: 2.625949309521986

Epoch: 5| Step: 9
Training loss: 1.2187039782320122
Validation loss: 2.6562614066683126

Epoch: 5| Step: 10
Training loss: 2.3678233485573084
Validation loss: 2.6313808635146017

Epoch: 5| Step: 11
Training loss: 4.432239476877971
Validation loss: 2.628901231750566

Epoch: 424| Step: 0
Training loss: 2.1924175030315
Validation loss: 2.6493590372991593

Epoch: 5| Step: 1
Training loss: 2.3426658666099494
Validation loss: 2.70660072928911

Epoch: 5| Step: 2
Training loss: 2.355519561472581
Validation loss: 2.684398617416658

Epoch: 5| Step: 3
Training loss: 1.9015038612119886
Validation loss: 2.6708862378796643

Epoch: 5| Step: 4
Training loss: 1.9729530639943287
Validation loss: 2.6043772815730666

Epoch: 5| Step: 5
Training loss: 2.0062133120215604
Validation loss: 2.5658916923322055

Epoch: 5| Step: 6
Training loss: 2.0034505166020806
Validation loss: 2.493838856324254

Epoch: 5| Step: 7
Training loss: 2.376448540899109
Validation loss: 2.462353943593617

Epoch: 5| Step: 8
Training loss: 2.527923376014633
Validation loss: 2.4437583477661438

Epoch: 5| Step: 9
Training loss: 2.571627109674133
Validation loss: 2.45888368189822

Epoch: 5| Step: 10
Training loss: 1.773940632571847
Validation loss: 2.4397107353030756

Epoch: 5| Step: 11
Training loss: 2.1637514627629124
Validation loss: 2.4393655655893727

Epoch: 425| Step: 0
Training loss: 2.256157291441438
Validation loss: 2.4534924104439844

Epoch: 5| Step: 1
Training loss: 2.5330832165505766
Validation loss: 2.4778112959364695

Epoch: 5| Step: 2
Training loss: 2.125963217150638
Validation loss: 2.469331568209935

Epoch: 5| Step: 3
Training loss: 2.6133653658571023
Validation loss: 2.481672056193122

Epoch: 5| Step: 4
Training loss: 2.438108221610941
Validation loss: 2.5234203869502148

Epoch: 5| Step: 5
Training loss: 2.2963884318347585
Validation loss: 2.512442896243061

Epoch: 5| Step: 6
Training loss: 1.7265885985460319
Validation loss: 2.5194401648170923

Epoch: 5| Step: 7
Training loss: 2.1214803831554234
Validation loss: 2.5188544732096476

Epoch: 5| Step: 8
Training loss: 2.079178736568218
Validation loss: 2.4985901115396874

Epoch: 5| Step: 9
Training loss: 2.407432166675937
Validation loss: 2.516408746862806

Epoch: 5| Step: 10
Training loss: 2.2701094870693947
Validation loss: 2.517726561375517

Epoch: 5| Step: 11
Training loss: 1.2268037498022533
Validation loss: 2.562663747626371

Epoch: 426| Step: 0
Training loss: 1.9503230023021099
Validation loss: 2.5799673645286636

Epoch: 5| Step: 1
Training loss: 2.185171795688468
Validation loss: 2.650808872476602

Epoch: 5| Step: 2
Training loss: 2.582969968118323
Validation loss: 2.650759209135467

Epoch: 5| Step: 3
Training loss: 2.2444037672433765
Validation loss: 2.7065582192376865

Epoch: 5| Step: 4
Training loss: 1.4513714782708913
Validation loss: 2.698597212178821

Epoch: 5| Step: 5
Training loss: 2.240293014809851
Validation loss: 2.710116343581513

Epoch: 5| Step: 6
Training loss: 2.077082666558325
Validation loss: 2.7039005071165154

Epoch: 5| Step: 7
Training loss: 2.6507016746478578
Validation loss: 2.6887276676893346

Epoch: 5| Step: 8
Training loss: 1.523206644417592
Validation loss: 2.6852947361809623

Epoch: 5| Step: 9
Training loss: 2.29460737954789
Validation loss: 2.641813112485679

Epoch: 5| Step: 10
Training loss: 1.880258434469982
Validation loss: 2.6417288908765015

Epoch: 5| Step: 11
Training loss: 1.4114159534280843
Validation loss: 2.6141144128095983

Epoch: 427| Step: 0
Training loss: 1.6565370850699468
Validation loss: 2.613999405407467

Epoch: 5| Step: 1
Training loss: 2.123078094224809
Validation loss: 2.61712562905432

Epoch: 5| Step: 2
Training loss: 1.5527868106073568
Validation loss: 2.613292969666466

Epoch: 5| Step: 3
Training loss: 1.9333900421419654
Validation loss: 2.607265403900794

Epoch: 5| Step: 4
Training loss: 2.4691086520656733
Validation loss: 2.6110734113943157

Epoch: 5| Step: 5
Training loss: 2.0031290610714123
Validation loss: 2.5923792729214314

Epoch: 5| Step: 6
Training loss: 1.7538092571533213
Validation loss: 2.618129344398389

Epoch: 5| Step: 7
Training loss: 2.409781700472702
Validation loss: 2.5705902080993237

Epoch: 5| Step: 8
Training loss: 2.08215663739902
Validation loss: 2.6280173980844865

Epoch: 5| Step: 9
Training loss: 2.0707254249913403
Validation loss: 2.633909960781849

Epoch: 5| Step: 10
Training loss: 2.4489776151918363
Validation loss: 2.599110112826064

Epoch: 5| Step: 11
Training loss: 1.6440700872058032
Validation loss: 2.5974247305816465

Epoch: 428| Step: 0
Training loss: 2.0468910740810884
Validation loss: 2.6032428984944933

Epoch: 5| Step: 1
Training loss: 2.075341906586922
Validation loss: 2.6362337509373184

Epoch: 5| Step: 2
Training loss: 2.3577643953930916
Validation loss: 2.632968788526533

Epoch: 5| Step: 3
Training loss: 1.8678619571218418
Validation loss: 2.6527878357217816

Epoch: 5| Step: 4
Training loss: 2.757962749592026
Validation loss: 2.6350607964706136

Epoch: 5| Step: 5
Training loss: 2.2432517473406817
Validation loss: 2.649041886136383

Epoch: 5| Step: 6
Training loss: 1.5043782075753465
Validation loss: 2.6244031250244486

Epoch: 5| Step: 7
Training loss: 1.972842247380803
Validation loss: 2.6026047422174186

Epoch: 5| Step: 8
Training loss: 2.4333635101885793
Validation loss: 2.537343336227035

Epoch: 5| Step: 9
Training loss: 2.101214071553255
Validation loss: 2.4900441115754

Epoch: 5| Step: 10
Training loss: 1.6150514067744246
Validation loss: 2.493192065677251

Epoch: 5| Step: 11
Training loss: 1.8660179529461025
Validation loss: 2.490298014307593

Epoch: 429| Step: 0
Training loss: 1.8381771630464137
Validation loss: 2.49273766451098

Epoch: 5| Step: 1
Training loss: 1.618786228908615
Validation loss: 2.5036005040771077

Epoch: 5| Step: 2
Training loss: 1.7695030226992885
Validation loss: 2.4973243620944388

Epoch: 5| Step: 3
Training loss: 2.65962086133872
Validation loss: 2.4827902835902678

Epoch: 5| Step: 4
Training loss: 2.400775478168654
Validation loss: 2.5090342404710237

Epoch: 5| Step: 5
Training loss: 2.0168518354458658
Validation loss: 2.5800750216461315

Epoch: 5| Step: 6
Training loss: 1.621247507180185
Validation loss: 2.649596884194368

Epoch: 5| Step: 7
Training loss: 1.9912618244248708
Validation loss: 2.725821058136246

Epoch: 5| Step: 8
Training loss: 1.9019155784186743
Validation loss: 2.710241552722055

Epoch: 5| Step: 9
Training loss: 2.514880526304276
Validation loss: 2.6781531891439085

Epoch: 5| Step: 10
Training loss: 2.3628486174249903
Validation loss: 2.664623354347049

Epoch: 5| Step: 11
Training loss: 1.437431665537816
Validation loss: 2.5997366087109746

Epoch: 430| Step: 0
Training loss: 2.1480170931002798
Validation loss: 2.5305118544164644

Epoch: 5| Step: 1
Training loss: 1.7083995930297196
Validation loss: 2.494046959528471

Epoch: 5| Step: 2
Training loss: 2.791122744128342
Validation loss: 2.488359315327312

Epoch: 5| Step: 3
Training loss: 1.9321319911682473
Validation loss: 2.500929496746293

Epoch: 5| Step: 4
Training loss: 1.701724955612523
Validation loss: 2.4771447204306902

Epoch: 5| Step: 5
Training loss: 1.6664770813243563
Validation loss: 2.4626477409393117

Epoch: 5| Step: 6
Training loss: 2.4302970882013923
Validation loss: 2.4644009554646837

Epoch: 5| Step: 7
Training loss: 2.5210191222104568
Validation loss: 2.470169749630353

Epoch: 5| Step: 8
Training loss: 2.333430447146939
Validation loss: 2.4932915086816663

Epoch: 5| Step: 9
Training loss: 1.885225641117271
Validation loss: 2.541715700948113

Epoch: 5| Step: 10
Training loss: 1.9040055115644037
Validation loss: 2.5998253965437828

Epoch: 5| Step: 11
Training loss: 1.9242522880676391
Validation loss: 2.6508497057491773

Epoch: 431| Step: 0
Training loss: 2.559144404902553
Validation loss: 2.6932670940757397

Epoch: 5| Step: 1
Training loss: 2.2346948781489817
Validation loss: 2.6571357073165185

Epoch: 5| Step: 2
Training loss: 1.7671608785416775
Validation loss: 2.7191648312955183

Epoch: 5| Step: 3
Training loss: 2.171585393025487
Validation loss: 2.6898536190014783

Epoch: 5| Step: 4
Training loss: 1.8394373224130083
Validation loss: 2.604646826664694

Epoch: 5| Step: 5
Training loss: 2.0357187266289403
Validation loss: 2.574043499504932

Epoch: 5| Step: 6
Training loss: 1.9509400620475004
Validation loss: 2.5010128155153337

Epoch: 5| Step: 7
Training loss: 2.6550673600899453
Validation loss: 2.499753256383291

Epoch: 5| Step: 8
Training loss: 2.6583052818069937
Validation loss: 2.4901499116822543

Epoch: 5| Step: 9
Training loss: 2.0280025639188612
Validation loss: 2.491144952781203

Epoch: 5| Step: 10
Training loss: 1.6975306050571197
Validation loss: 2.485190411672367

Epoch: 5| Step: 11
Training loss: 1.1192449018487112
Validation loss: 2.5047388899257528

Epoch: 432| Step: 0
Training loss: 1.8356628212492212
Validation loss: 2.509961927284768

Epoch: 5| Step: 1
Training loss: 1.3142515484222237
Validation loss: 2.526538915294063

Epoch: 5| Step: 2
Training loss: 1.9455974936938143
Validation loss: 2.5253097509428906

Epoch: 5| Step: 3
Training loss: 1.9451201316978985
Validation loss: 2.569386838290119

Epoch: 5| Step: 4
Training loss: 2.3815213066395757
Validation loss: 2.6003059583154617

Epoch: 5| Step: 5
Training loss: 1.953327931352161
Validation loss: 2.6214467742789576

Epoch: 5| Step: 6
Training loss: 1.6225569774104198
Validation loss: 2.6149062676616603

Epoch: 5| Step: 7
Training loss: 2.668506841726898
Validation loss: 2.557584055690467

Epoch: 5| Step: 8
Training loss: 2.278396807914009
Validation loss: 2.566878412283292

Epoch: 5| Step: 9
Training loss: 1.8469412389969577
Validation loss: 2.53095996042712

Epoch: 5| Step: 10
Training loss: 2.36727482096448
Validation loss: 2.536468591349471

Epoch: 5| Step: 11
Training loss: 3.0996410654295232
Validation loss: 2.521260463111007

Epoch: 433| Step: 0
Training loss: 1.9587167269881707
Validation loss: 2.580008233177986

Epoch: 5| Step: 1
Training loss: 2.463425507874984
Validation loss: 2.578131388646697

Epoch: 5| Step: 2
Training loss: 1.8410407382119114
Validation loss: 2.6439092779013516

Epoch: 5| Step: 3
Training loss: 1.887162118947309
Validation loss: 2.63922075407299

Epoch: 5| Step: 4
Training loss: 2.236385801146261
Validation loss: 2.6908557293742454

Epoch: 5| Step: 5
Training loss: 1.946432564857556
Validation loss: 2.6566936309451985

Epoch: 5| Step: 6
Training loss: 2.327907577705381
Validation loss: 2.6151648491527

Epoch: 5| Step: 7
Training loss: 2.3036699538003442
Validation loss: 2.583750211755368

Epoch: 5| Step: 8
Training loss: 2.1069896633073877
Validation loss: 2.5661904386052043

Epoch: 5| Step: 9
Training loss: 1.7578880463366742
Validation loss: 2.505072747974305

Epoch: 5| Step: 10
Training loss: 1.989130164926066
Validation loss: 2.477350741316098

Epoch: 5| Step: 11
Training loss: 3.0926405333379474
Validation loss: 2.502266174632044

Epoch: 434| Step: 0
Training loss: 2.1188348083626987
Validation loss: 2.5092379360366945

Epoch: 5| Step: 1
Training loss: 2.5006956086395427
Validation loss: 2.5114436535358116

Epoch: 5| Step: 2
Training loss: 1.987727359746905
Validation loss: 2.5372160863912363

Epoch: 5| Step: 3
Training loss: 2.247408115770379
Validation loss: 2.543390831830668

Epoch: 5| Step: 4
Training loss: 1.71809138770614
Validation loss: 2.5882228690825997

Epoch: 5| Step: 5
Training loss: 2.196466434520144
Validation loss: 2.612277945978781

Epoch: 5| Step: 6
Training loss: 1.8852577001952888
Validation loss: 2.6162488971883455

Epoch: 5| Step: 7
Training loss: 1.9922714514901652
Validation loss: 2.6333233406585514

Epoch: 5| Step: 8
Training loss: 1.8882124459385692
Validation loss: 2.5979587082467943

Epoch: 5| Step: 9
Training loss: 1.8780711136131363
Validation loss: 2.546670983535127

Epoch: 5| Step: 10
Training loss: 2.17001175029052
Validation loss: 2.5503475449465713

Epoch: 5| Step: 11
Training loss: 1.9076571039620818
Validation loss: 2.5502449550657915

Epoch: 435| Step: 0
Training loss: 1.626789135126995
Validation loss: 2.507384092314986

Epoch: 5| Step: 1
Training loss: 2.430538506826523
Validation loss: 2.5175701621644624

Epoch: 5| Step: 2
Training loss: 2.245956920934179
Validation loss: 2.5326466494493265

Epoch: 5| Step: 3
Training loss: 1.9907912803201409
Validation loss: 2.514888414703459

Epoch: 5| Step: 4
Training loss: 2.5238352364689507
Validation loss: 2.514954681019772

Epoch: 5| Step: 5
Training loss: 2.549385097639844
Validation loss: 2.520011915148465

Epoch: 5| Step: 6
Training loss: 1.9107123503528771
Validation loss: 2.537019134318387

Epoch: 5| Step: 7
Training loss: 1.730941535654372
Validation loss: 2.561968073646729

Epoch: 5| Step: 8
Training loss: 2.145542038586814
Validation loss: 2.5853060809104584

Epoch: 5| Step: 9
Training loss: 1.702510547913353
Validation loss: 2.578349290589622

Epoch: 5| Step: 10
Training loss: 1.7671758541731928
Validation loss: 2.6323991860482114

Epoch: 5| Step: 11
Training loss: 1.2865160673007683
Validation loss: 2.6531884782294246

Epoch: 436| Step: 0
Training loss: 2.2886794879745693
Validation loss: 2.656145557519392

Epoch: 5| Step: 1
Training loss: 2.036512863586844
Validation loss: 2.6876910607488873

Epoch: 5| Step: 2
Training loss: 1.8925114197682527
Validation loss: 2.702746888545377

Epoch: 5| Step: 3
Training loss: 2.5039704265493414
Validation loss: 2.6426227093093573

Epoch: 5| Step: 4
Training loss: 2.3477617643132866
Validation loss: 2.5926290449129263

Epoch: 5| Step: 5
Training loss: 2.590050966652428
Validation loss: 2.553531972572052

Epoch: 5| Step: 6
Training loss: 1.9584614596827021
Validation loss: 2.5642554658988526

Epoch: 5| Step: 7
Training loss: 2.2208424761824315
Validation loss: 2.5398377980796423

Epoch: 5| Step: 8
Training loss: 1.4107625402920392
Validation loss: 2.5787652964160652

Epoch: 5| Step: 9
Training loss: 1.7521119997247516
Validation loss: 2.561921566132601

Epoch: 5| Step: 10
Training loss: 1.4749421609432865
Validation loss: 2.556557712517032

Epoch: 5| Step: 11
Training loss: 1.4394584251937699
Validation loss: 2.5732444536366823

Epoch: 437| Step: 0
Training loss: 2.2188781916161457
Validation loss: 2.5726167231153942

Epoch: 5| Step: 1
Training loss: 1.7875430388704516
Validation loss: 2.5458970952100572

Epoch: 5| Step: 2
Training loss: 2.2722460584107917
Validation loss: 2.5583324696935965

Epoch: 5| Step: 3
Training loss: 1.765036020532747
Validation loss: 2.557259213046764

Epoch: 5| Step: 4
Training loss: 2.47083841187168
Validation loss: 2.553716768704255

Epoch: 5| Step: 5
Training loss: 2.5112848218494483
Validation loss: 2.55046779464987

Epoch: 5| Step: 6
Training loss: 2.0324153198394552
Validation loss: 2.638149496834006

Epoch: 5| Step: 7
Training loss: 1.7375612289288493
Validation loss: 2.611400830538978

Epoch: 5| Step: 8
Training loss: 2.034748292769698
Validation loss: 2.6493982206087283

Epoch: 5| Step: 9
Training loss: 1.4049897374765947
Validation loss: 2.603498462144429

Epoch: 5| Step: 10
Training loss: 2.1044689628576383
Validation loss: 2.581770521611163

Epoch: 5| Step: 11
Training loss: 1.224723068386597
Validation loss: 2.5479402206238815

Epoch: 438| Step: 0
Training loss: 2.378804221885864
Validation loss: 2.547680861872712

Epoch: 5| Step: 1
Training loss: 1.6196457612129838
Validation loss: 2.5267176729676133

Epoch: 5| Step: 2
Training loss: 1.6548260739722065
Validation loss: 2.540344736141309

Epoch: 5| Step: 3
Training loss: 1.9100837303702543
Validation loss: 2.5373966170925386

Epoch: 5| Step: 4
Training loss: 2.315813114077536
Validation loss: 2.5813093190924223

Epoch: 5| Step: 5
Training loss: 2.0737834121560157
Validation loss: 2.537717707616945

Epoch: 5| Step: 6
Training loss: 1.459719063105836
Validation loss: 2.587831009472045

Epoch: 5| Step: 7
Training loss: 2.3553502193759437
Validation loss: 2.55728174014732

Epoch: 5| Step: 8
Training loss: 2.026025361793894
Validation loss: 2.561665662762411

Epoch: 5| Step: 9
Training loss: 1.937796477737714
Validation loss: 2.5629564708330372

Epoch: 5| Step: 10
Training loss: 2.045583419400519
Validation loss: 2.57407673592116

Epoch: 5| Step: 11
Training loss: 3.1985165077965396
Validation loss: 2.5487072990299096

Epoch: 439| Step: 0
Training loss: 1.4902118966143416
Validation loss: 2.550778153842607

Epoch: 5| Step: 1
Training loss: 1.7347146466329613
Validation loss: 2.521888117498091

Epoch: 5| Step: 2
Training loss: 2.034555767600945
Validation loss: 2.5204288470789074

Epoch: 5| Step: 3
Training loss: 2.1470295679679774
Validation loss: 2.5110878357176634

Epoch: 5| Step: 4
Training loss: 2.396649716369932
Validation loss: 2.5087578517763705

Epoch: 5| Step: 5
Training loss: 2.341067495651408
Validation loss: 2.5111881682494746

Epoch: 5| Step: 6
Training loss: 2.160593385252696
Validation loss: 2.5269699409834643

Epoch: 5| Step: 7
Training loss: 2.497288855103465
Validation loss: 2.5355310912368996

Epoch: 5| Step: 8
Training loss: 1.5037688749909275
Validation loss: 2.529991386434093

Epoch: 5| Step: 9
Training loss: 1.7952772915594035
Validation loss: 2.5507153263501445

Epoch: 5| Step: 10
Training loss: 2.086627060430025
Validation loss: 2.58522953664685

Epoch: 5| Step: 11
Training loss: 3.088222922506048
Validation loss: 2.5988022687963537

Epoch: 440| Step: 0
Training loss: 2.542515961963582
Validation loss: 2.6442250798126405

Epoch: 5| Step: 1
Training loss: 2.1813757043157205
Validation loss: 2.706505122944712

Epoch: 5| Step: 2
Training loss: 2.402799039047148
Validation loss: 2.7362148561888495

Epoch: 5| Step: 3
Training loss: 2.4472095090334043
Validation loss: 2.6887307786453993

Epoch: 5| Step: 4
Training loss: 2.292540112126819
Validation loss: 2.652175369873211

Epoch: 5| Step: 5
Training loss: 2.1334828870724865
Validation loss: 2.6176226050206832

Epoch: 5| Step: 6
Training loss: 1.8785113199160484
Validation loss: 2.599816455231237

Epoch: 5| Step: 7
Training loss: 1.975645855434825
Validation loss: 2.559228436904518

Epoch: 5| Step: 8
Training loss: 1.4538607631744245
Validation loss: 2.541352554881378

Epoch: 5| Step: 9
Training loss: 1.729799369357785
Validation loss: 2.5151890679082425

Epoch: 5| Step: 10
Training loss: 1.3595387151943055
Validation loss: 2.517323676667728

Epoch: 5| Step: 11
Training loss: 1.7976784941396602
Validation loss: 2.5069157233901596

Epoch: 441| Step: 0
Training loss: 1.4514648634612795
Validation loss: 2.5062958358797025

Epoch: 5| Step: 1
Training loss: 2.365920530376007
Validation loss: 2.491347004778242

Epoch: 5| Step: 2
Training loss: 1.396209817852872
Validation loss: 2.4975455792468018

Epoch: 5| Step: 3
Training loss: 2.0991104739750845
Validation loss: 2.518583287952702

Epoch: 5| Step: 4
Training loss: 2.0529131171808306
Validation loss: 2.531935187014965

Epoch: 5| Step: 5
Training loss: 2.020418131014791
Validation loss: 2.5157771015190287

Epoch: 5| Step: 6
Training loss: 1.4811061805407095
Validation loss: 2.571211958000909

Epoch: 5| Step: 7
Training loss: 2.551591496206472
Validation loss: 2.617809320473475

Epoch: 5| Step: 8
Training loss: 2.5930934212858805
Validation loss: 2.6578159129670103

Epoch: 5| Step: 9
Training loss: 1.8198480627546467
Validation loss: 2.688492913132348

Epoch: 5| Step: 10
Training loss: 2.277900536131581
Validation loss: 2.6345945377665636

Epoch: 5| Step: 11
Training loss: 3.371594724417182
Validation loss: 2.658861566895073

Epoch: 442| Step: 0
Training loss: 1.9753993535994618
Validation loss: 2.587380958128482

Epoch: 5| Step: 1
Training loss: 1.8628096713495945
Validation loss: 2.573863821688661

Epoch: 5| Step: 2
Training loss: 2.0602904535355417
Validation loss: 2.566608980281956

Epoch: 5| Step: 3
Training loss: 2.1095865779306515
Validation loss: 2.538236027725003

Epoch: 5| Step: 4
Training loss: 1.3519453267266874
Validation loss: 2.548308903022142

Epoch: 5| Step: 5
Training loss: 2.273131359763763
Validation loss: 2.521100734814895

Epoch: 5| Step: 6
Training loss: 1.8705746880420737
Validation loss: 2.5344820345702628

Epoch: 5| Step: 7
Training loss: 2.262849146421486
Validation loss: 2.535371145301059

Epoch: 5| Step: 8
Training loss: 1.936718198492257
Validation loss: 2.579781861084181

Epoch: 5| Step: 9
Training loss: 2.1076473366492827
Validation loss: 2.5865501108426283

Epoch: 5| Step: 10
Training loss: 2.1524795517077555
Validation loss: 2.586734687266809

Epoch: 5| Step: 11
Training loss: 2.1540043512086124
Validation loss: 2.5863285940638754

Epoch: 443| Step: 0
Training loss: 1.881730144478587
Validation loss: 2.640151340657428

Epoch: 5| Step: 1
Training loss: 2.5062066281340076
Validation loss: 2.671580110602619

Epoch: 5| Step: 2
Training loss: 2.4685753869221756
Validation loss: 2.656218640759426

Epoch: 5| Step: 3
Training loss: 2.003337221612611
Validation loss: 2.645054561164018

Epoch: 5| Step: 4
Training loss: 1.6653902013586401
Validation loss: 2.6120159315194917

Epoch: 5| Step: 5
Training loss: 1.7943823733123474
Validation loss: 2.59948671903273

Epoch: 5| Step: 6
Training loss: 2.0080993684901323
Validation loss: 2.5687382446416094

Epoch: 5| Step: 7
Training loss: 2.54925931009192
Validation loss: 2.5219459751388182

Epoch: 5| Step: 8
Training loss: 2.0576002702347975
Validation loss: 2.515039525900111

Epoch: 5| Step: 9
Training loss: 1.7380209052756797
Validation loss: 2.511896486059945

Epoch: 5| Step: 10
Training loss: 1.4149460534909275
Validation loss: 2.518294314173275

Epoch: 5| Step: 11
Training loss: 1.24188271868092
Validation loss: 2.4878788597246806

Epoch: 444| Step: 0
Training loss: 2.275317695987921
Validation loss: 2.4934664427212203

Epoch: 5| Step: 1
Training loss: 1.6494439112761377
Validation loss: 2.489656057585786

Epoch: 5| Step: 2
Training loss: 2.157969355976356
Validation loss: 2.502798205238914

Epoch: 5| Step: 3
Training loss: 2.1847633682367547
Validation loss: 2.50500262731743

Epoch: 5| Step: 4
Training loss: 2.2689096778185402
Validation loss: 2.5367531784567534

Epoch: 5| Step: 5
Training loss: 1.4912255666798382
Validation loss: 2.5422996171933625

Epoch: 5| Step: 6
Training loss: 1.9110520959337562
Validation loss: 2.555638605791996

Epoch: 5| Step: 7
Training loss: 2.275352693822789
Validation loss: 2.605912162723764

Epoch: 5| Step: 8
Training loss: 2.124511213747498
Validation loss: 2.601374377836873

Epoch: 5| Step: 9
Training loss: 1.751535695506391
Validation loss: 2.607999621901017

Epoch: 5| Step: 10
Training loss: 1.920417046552761
Validation loss: 2.585948552226163

Epoch: 5| Step: 11
Training loss: 2.3507969012362206
Validation loss: 2.563863779038944

Epoch: 445| Step: 0
Training loss: 1.9292355521682991
Validation loss: 2.542991688864634

Epoch: 5| Step: 1
Training loss: 2.094628903973524
Validation loss: 2.5817071785363805

Epoch: 5| Step: 2
Training loss: 1.9346796858871116
Validation loss: 2.5491343814825185

Epoch: 5| Step: 3
Training loss: 2.3623181106545568
Validation loss: 2.5460555468683124

Epoch: 5| Step: 4
Training loss: 1.9963905427363648
Validation loss: 2.548949615584165

Epoch: 5| Step: 5
Training loss: 2.054286322935618
Validation loss: 2.5461505608484267

Epoch: 5| Step: 6
Training loss: 1.729685655711775
Validation loss: 2.5686530405851493

Epoch: 5| Step: 7
Training loss: 2.029483202841964
Validation loss: 2.5284625902708084

Epoch: 5| Step: 8
Training loss: 1.7856218995310056
Validation loss: 2.5487686364647955

Epoch: 5| Step: 9
Training loss: 1.7262055040904878
Validation loss: 2.570400769883351

Epoch: 5| Step: 10
Training loss: 2.372211123888953
Validation loss: 2.604998914611014

Epoch: 5| Step: 11
Training loss: 2.041180325666306
Validation loss: 2.5735752650191075

Epoch: 446| Step: 0
Training loss: 2.3744816465393446
Validation loss: 2.5916090175885493

Epoch: 5| Step: 1
Training loss: 2.141774001443779
Validation loss: 2.5757776382416337

Epoch: 5| Step: 2
Training loss: 2.44855204243083
Validation loss: 2.5524282274296284

Epoch: 5| Step: 3
Training loss: 1.396935450122765
Validation loss: 2.57028878074454

Epoch: 5| Step: 4
Training loss: 1.7826156734904413
Validation loss: 2.573198659529906

Epoch: 5| Step: 5
Training loss: 1.7222976138249622
Validation loss: 2.565290528835827

Epoch: 5| Step: 6
Training loss: 2.058849919574763
Validation loss: 2.5434118647552286

Epoch: 5| Step: 7
Training loss: 1.1878128643481933
Validation loss: 2.5468673432904003

Epoch: 5| Step: 8
Training loss: 2.3517118387549703
Validation loss: 2.530666766850118

Epoch: 5| Step: 9
Training loss: 2.6084740276802214
Validation loss: 2.530168482808346

Epoch: 5| Step: 10
Training loss: 2.0427507389951027
Validation loss: 2.5508772270680304

Epoch: 5| Step: 11
Training loss: 1.5789240711986354
Validation loss: 2.5849459111711646

Epoch: 447| Step: 0
Training loss: 2.3310092750603717
Validation loss: 2.5889360343636048

Epoch: 5| Step: 1
Training loss: 1.6151383543245543
Validation loss: 2.6004023022146185

Epoch: 5| Step: 2
Training loss: 2.470299246726535
Validation loss: 2.651280511665221

Epoch: 5| Step: 3
Training loss: 1.9800165325977335
Validation loss: 2.6413207068775364

Epoch: 5| Step: 4
Training loss: 2.0668099194787155
Validation loss: 2.632762421717494

Epoch: 5| Step: 5
Training loss: 1.8524337843207699
Validation loss: 2.6058299525826287

Epoch: 5| Step: 6
Training loss: 1.7741454471712588
Validation loss: 2.632011570964953

Epoch: 5| Step: 7
Training loss: 2.132346077805436
Validation loss: 2.6051424919348865

Epoch: 5| Step: 8
Training loss: 1.463937056631886
Validation loss: 2.6007649341826617

Epoch: 5| Step: 9
Training loss: 1.9320969462071118
Validation loss: 2.5749279660269453

Epoch: 5| Step: 10
Training loss: 2.1972248260101095
Validation loss: 2.5692337346383822

Epoch: 5| Step: 11
Training loss: 1.579671875888671
Validation loss: 2.554699237652644

Epoch: 448| Step: 0
Training loss: 1.993814081100928
Validation loss: 2.5468257165988843

Epoch: 5| Step: 1
Training loss: 2.61220502146323
Validation loss: 2.524640472706936

Epoch: 5| Step: 2
Training loss: 2.780590450649276
Validation loss: 2.506774505310307

Epoch: 5| Step: 3
Training loss: 2.360867867998742
Validation loss: 2.5380919846465995

Epoch: 5| Step: 4
Training loss: 1.2601710413841014
Validation loss: 2.530087317793154

Epoch: 5| Step: 5
Training loss: 1.8790201323132623
Validation loss: 2.5672015269649493

Epoch: 5| Step: 6
Training loss: 1.3472879542322282
Validation loss: 2.574469898034066

Epoch: 5| Step: 7
Training loss: 1.7197339102714266
Validation loss: 2.5873001403837748

Epoch: 5| Step: 8
Training loss: 2.034764814166125
Validation loss: 2.5827788801364795

Epoch: 5| Step: 9
Training loss: 2.0678604287837437
Validation loss: 2.562912035589407

Epoch: 5| Step: 10
Training loss: 1.758260847770111
Validation loss: 2.5134486781305747

Epoch: 5| Step: 11
Training loss: 1.1441194490014468
Validation loss: 2.5175165603406175

Epoch: 449| Step: 0
Training loss: 2.447856518162023
Validation loss: 2.5376998022495756

Epoch: 5| Step: 1
Training loss: 2.2847309466668557
Validation loss: 2.501207258871923

Epoch: 5| Step: 2
Training loss: 2.0504825628841954
Validation loss: 2.521681277788908

Epoch: 5| Step: 3
Training loss: 1.6669072295464022
Validation loss: 2.5034789515766547

Epoch: 5| Step: 4
Training loss: 2.0322800592129786
Validation loss: 2.525384476632808

Epoch: 5| Step: 5
Training loss: 1.5470354401585924
Validation loss: 2.5527568564170506

Epoch: 5| Step: 6
Training loss: 2.222968590751734
Validation loss: 2.5406337708168927

Epoch: 5| Step: 7
Training loss: 1.8104411303144403
Validation loss: 2.560802855258028

Epoch: 5| Step: 8
Training loss: 1.8102682119358744
Validation loss: 2.558104105681631

Epoch: 5| Step: 9
Training loss: 1.4903003683014373
Validation loss: 2.574441787249773

Epoch: 5| Step: 10
Training loss: 2.366822167333965
Validation loss: 2.610339057075143

Epoch: 5| Step: 11
Training loss: 1.6089943741248993
Validation loss: 2.6056740340116944

Epoch: 450| Step: 0
Training loss: 1.4148679515300089
Validation loss: 2.575968439583617

Epoch: 5| Step: 1
Training loss: 2.48062282294007
Validation loss: 2.609438212042128

Epoch: 5| Step: 2
Training loss: 2.261265948204032
Validation loss: 2.6095830602177243

Epoch: 5| Step: 3
Training loss: 1.902949869150076
Validation loss: 2.630733925958524

Epoch: 5| Step: 4
Training loss: 2.2627913018792953
Validation loss: 2.6074932112442353

Epoch: 5| Step: 5
Training loss: 1.4736269071648989
Validation loss: 2.5729295727693104

Epoch: 5| Step: 6
Training loss: 2.1982669159537602
Validation loss: 2.581506788398171

Epoch: 5| Step: 7
Training loss: 1.8970215465868387
Validation loss: 2.5747261955772545

Epoch: 5| Step: 8
Training loss: 2.1506381884134202
Validation loss: 2.5742573829264193

Epoch: 5| Step: 9
Training loss: 1.683643242978112
Validation loss: 2.566055138354813

Epoch: 5| Step: 10
Training loss: 1.5085215112191113
Validation loss: 2.57103641947995

Epoch: 5| Step: 11
Training loss: 1.5925586211764844
Validation loss: 2.585053914329985

Testing loss: 2.153317811310722
