Epoch: 1| Step: 0
Training loss: 5.524189553866774
Validation loss: 5.8442863449418

Epoch: 6| Step: 1
Training loss: 6.628717495102866
Validation loss: 5.842409683985482

Epoch: 6| Step: 2
Training loss: 5.495867824181103
Validation loss: 5.840595066898032

Epoch: 6| Step: 3
Training loss: 6.529846624702503
Validation loss: 5.838763089593735

Epoch: 6| Step: 4
Training loss: 5.948467845954576
Validation loss: 5.83705185035139

Epoch: 6| Step: 5
Training loss: 6.468445111889514
Validation loss: 5.835361464199714

Epoch: 6| Step: 6
Training loss: 6.479593964088577
Validation loss: 5.833644459011334

Epoch: 6| Step: 7
Training loss: 5.893481788721684
Validation loss: 5.831911740331589

Epoch: 6| Step: 8
Training loss: 5.9094429871568295
Validation loss: 5.830276187703839

Epoch: 6| Step: 9
Training loss: 6.082081740016022
Validation loss: 5.828569628789144

Epoch: 6| Step: 10
Training loss: 4.811507283658442
Validation loss: 5.826863333847837

Epoch: 6| Step: 11
Training loss: 5.601234245525015
Validation loss: 5.825118611319215

Epoch: 6| Step: 12
Training loss: 6.533780862440861
Validation loss: 5.82318576834672

Epoch: 6| Step: 13
Training loss: 5.034991087768304
Validation loss: 5.821418619551358

Epoch: 2| Step: 0
Training loss: 5.736780311807945
Validation loss: 5.819248834487203

Epoch: 6| Step: 1
Training loss: 7.264553327382677
Validation loss: 5.817279313768614

Epoch: 6| Step: 2
Training loss: 5.612118021109439
Validation loss: 5.815172380957547

Epoch: 6| Step: 3
Training loss: 6.22575620171583
Validation loss: 5.812860484549558

Epoch: 6| Step: 4
Training loss: 6.387096820805196
Validation loss: 5.810516976244855

Epoch: 6| Step: 5
Training loss: 5.944208792098617
Validation loss: 5.8081135212459065

Epoch: 6| Step: 6
Training loss: 5.217660938772955
Validation loss: 5.805487391524454

Epoch: 6| Step: 7
Training loss: 6.201249691933008
Validation loss: 5.802723911429616

Epoch: 6| Step: 8
Training loss: 5.876681472722163
Validation loss: 5.799978544480551

Epoch: 6| Step: 9
Training loss: 5.744142617306693
Validation loss: 5.797095281728974

Epoch: 6| Step: 10
Training loss: 5.8308380602921535
Validation loss: 5.794060118769231

Epoch: 6| Step: 11
Training loss: 4.752467066908081
Validation loss: 5.790850584134651

Epoch: 6| Step: 12
Training loss: 7.118890116906008
Validation loss: 5.787651875139308

Epoch: 6| Step: 13
Training loss: 4.276748629761058
Validation loss: 5.784146437344636

Epoch: 3| Step: 0
Training loss: 4.6762915311313575
Validation loss: 5.780574339828429

Epoch: 6| Step: 1
Training loss: 6.654146677017841
Validation loss: 5.777116827369585

Epoch: 6| Step: 2
Training loss: 5.838384276238696
Validation loss: 5.77325031698036

Epoch: 6| Step: 3
Training loss: 6.618656792493202
Validation loss: 5.769305480245051

Epoch: 6| Step: 4
Training loss: 6.881401826740989
Validation loss: 5.76508781597817

Epoch: 6| Step: 5
Training loss: 5.967804679108414
Validation loss: 5.760708995205486

Epoch: 6| Step: 6
Training loss: 5.675958681844664
Validation loss: 5.756395818718254

Epoch: 6| Step: 7
Training loss: 5.192964364502342
Validation loss: 5.751815730355375

Epoch: 6| Step: 8
Training loss: 4.915530229686808
Validation loss: 5.747226599094516

Epoch: 6| Step: 9
Training loss: 4.333954888785454
Validation loss: 5.742483284526938

Epoch: 6| Step: 10
Training loss: 6.169339434165953
Validation loss: 5.737780371459432

Epoch: 6| Step: 11
Training loss: 6.58282636147069
Validation loss: 5.733057437217089

Epoch: 6| Step: 12
Training loss: 6.257824082191217
Validation loss: 5.727858524676292

Epoch: 6| Step: 13
Training loss: 5.728119392621198
Validation loss: 5.722780124334773

Epoch: 4| Step: 0
Training loss: 6.319681143141366
Validation loss: 5.717348799124719

Epoch: 6| Step: 1
Training loss: 6.493552898687041
Validation loss: 5.712031936668423

Epoch: 6| Step: 2
Training loss: 6.009854171938679
Validation loss: 5.706165635375604

Epoch: 6| Step: 3
Training loss: 6.160864635078246
Validation loss: 5.700300128463889

Epoch: 6| Step: 4
Training loss: 5.023234741485451
Validation loss: 5.6942704254273995

Epoch: 6| Step: 5
Training loss: 6.040890909135358
Validation loss: 5.688211641050334

Epoch: 6| Step: 6
Training loss: 4.82610073677842
Validation loss: 5.682162172943976

Epoch: 6| Step: 7
Training loss: 4.349873350207083
Validation loss: 5.675658954336344

Epoch: 6| Step: 8
Training loss: 5.696753718538963
Validation loss: 5.669056033362835

Epoch: 6| Step: 9
Training loss: 6.123248414246977
Validation loss: 5.662444149637332

Epoch: 6| Step: 10
Training loss: 5.799947659486524
Validation loss: 5.655450135609792

Epoch: 6| Step: 11
Training loss: 5.708265021070873
Validation loss: 5.648228980472084

Epoch: 6| Step: 12
Training loss: 5.8873456736300565
Validation loss: 5.640698715108697

Epoch: 6| Step: 13
Training loss: 6.2683382699682095
Validation loss: 5.632994248080995

Epoch: 5| Step: 0
Training loss: 5.547386983964028
Validation loss: 5.625113931137862

Epoch: 6| Step: 1
Training loss: 5.315260226176387
Validation loss: 5.616943920020124

Epoch: 6| Step: 2
Training loss: 6.222520461579487
Validation loss: 5.609064970241748

Epoch: 6| Step: 3
Training loss: 5.149636946538304
Validation loss: 5.600813967722328

Epoch: 6| Step: 4
Training loss: 6.49709548612758
Validation loss: 5.592535615232653

Epoch: 6| Step: 5
Training loss: 5.142695696885216
Validation loss: 5.584489455968709

Epoch: 6| Step: 6
Training loss: 6.011148268294334
Validation loss: 5.576076498290423

Epoch: 6| Step: 7
Training loss: 6.508848769535785
Validation loss: 5.567834760505028

Epoch: 6| Step: 8
Training loss: 4.640389073600891
Validation loss: 5.559562850617468

Epoch: 6| Step: 9
Training loss: 5.635072971470629
Validation loss: 5.5510664742888345

Epoch: 6| Step: 10
Training loss: 5.322939679219865
Validation loss: 5.542881031879113

Epoch: 6| Step: 11
Training loss: 5.6044684497831065
Validation loss: 5.534746031455352

Epoch: 6| Step: 12
Training loss: 5.661926456061369
Validation loss: 5.526676737120825

Epoch: 6| Step: 13
Training loss: 6.065905057169759
Validation loss: 5.518869859395403

Epoch: 6| Step: 0
Training loss: 5.514468495963029
Validation loss: 5.510909242974868

Epoch: 6| Step: 1
Training loss: 5.820744399872953
Validation loss: 5.502993173805628

Epoch: 6| Step: 2
Training loss: 6.0117834730921365
Validation loss: 5.4955677900543645

Epoch: 6| Step: 3
Training loss: 6.128821601550563
Validation loss: 5.487706113751886

Epoch: 6| Step: 4
Training loss: 5.674705786787678
Validation loss: 5.480366052203244

Epoch: 6| Step: 5
Training loss: 5.337917424123177
Validation loss: 5.47304164519666

Epoch: 6| Step: 6
Training loss: 5.322981961540977
Validation loss: 5.466058413851658

Epoch: 6| Step: 7
Training loss: 5.503571651080696
Validation loss: 5.459302520125252

Epoch: 6| Step: 8
Training loss: 4.16899758308617
Validation loss: 5.452736273229903

Epoch: 6| Step: 9
Training loss: 5.29364329188866
Validation loss: 5.446307244241138

Epoch: 6| Step: 10
Training loss: 5.7433150864612195
Validation loss: 5.439936095825412

Epoch: 6| Step: 11
Training loss: 5.985020057434279
Validation loss: 5.433890244351901

Epoch: 6| Step: 12
Training loss: 4.203003835527048
Validation loss: 5.427808580123526

Epoch: 6| Step: 13
Training loss: 6.893624342796019
Validation loss: 5.4220298429836

Epoch: 7| Step: 0
Training loss: 5.170608042630729
Validation loss: 5.415918865914667

Epoch: 6| Step: 1
Training loss: 4.070575844707912
Validation loss: 5.410061648353105

Epoch: 6| Step: 2
Training loss: 5.689444743921908
Validation loss: 5.404284610603404

Epoch: 6| Step: 3
Training loss: 5.707446324099813
Validation loss: 5.3984621731037405

Epoch: 6| Step: 4
Training loss: 6.049915584259019
Validation loss: 5.392893408825116

Epoch: 6| Step: 5
Training loss: 5.888854876406032
Validation loss: 5.386905584859647

Epoch: 6| Step: 6
Training loss: 4.563425048694109
Validation loss: 5.381829056135215

Epoch: 6| Step: 7
Training loss: 5.737301279919201
Validation loss: 5.376667651140691

Epoch: 6| Step: 8
Training loss: 5.7177626794572145
Validation loss: 5.371336405503498

Epoch: 6| Step: 9
Training loss: 5.8223825754565866
Validation loss: 5.366530406398863

Epoch: 6| Step: 10
Training loss: 5.750674995940524
Validation loss: 5.36119349761715

Epoch: 6| Step: 11
Training loss: 4.890823116494394
Validation loss: 5.356202546202149

Epoch: 6| Step: 12
Training loss: 5.761840901777189
Validation loss: 5.350980184017554

Epoch: 6| Step: 13
Training loss: 5.793245315380636
Validation loss: 5.345923504127156

Epoch: 8| Step: 0
Training loss: 5.424779636108899
Validation loss: 5.340817782853137

Epoch: 6| Step: 1
Training loss: 5.342409913977478
Validation loss: 5.33538347815107

Epoch: 6| Step: 2
Training loss: 5.1607989965662275
Validation loss: 5.330252065274779

Epoch: 6| Step: 3
Training loss: 5.050028190911799
Validation loss: 5.325082098338447

Epoch: 6| Step: 4
Training loss: 5.896293523327381
Validation loss: 5.320445025002963

Epoch: 6| Step: 5
Training loss: 5.620548775918635
Validation loss: 5.315243270775746

Epoch: 6| Step: 6
Training loss: 4.77043654389574
Validation loss: 5.309964521137494

Epoch: 6| Step: 7
Training loss: 5.041943671233022
Validation loss: 5.305286881111095

Epoch: 6| Step: 8
Training loss: 5.7877451109424545
Validation loss: 5.300319185782217

Epoch: 6| Step: 9
Training loss: 5.460276988063605
Validation loss: 5.295371263196172

Epoch: 6| Step: 10
Training loss: 5.728723053374602
Validation loss: 5.290693488957366

Epoch: 6| Step: 11
Training loss: 5.3713797864176875
Validation loss: 5.285985610446788

Epoch: 6| Step: 12
Training loss: 5.224896859789155
Validation loss: 5.281130546708668

Epoch: 6| Step: 13
Training loss: 5.982048518691609
Validation loss: 5.276120736627036

Epoch: 9| Step: 0
Training loss: 5.257623496208231
Validation loss: 5.271321973905573

Epoch: 6| Step: 1
Training loss: 5.018977580724041
Validation loss: 5.265997174521216

Epoch: 6| Step: 2
Training loss: 5.537212025062617
Validation loss: 5.261732917507915

Epoch: 6| Step: 3
Training loss: 4.76337076872274
Validation loss: 5.2572620967212025

Epoch: 6| Step: 4
Training loss: 5.614753885692535
Validation loss: 5.252163940602003

Epoch: 6| Step: 5
Training loss: 5.256211557145667
Validation loss: 5.248009864592391

Epoch: 6| Step: 6
Training loss: 5.372599753354163
Validation loss: 5.24282285778833

Epoch: 6| Step: 7
Training loss: 5.780683829962697
Validation loss: 5.238363691568273

Epoch: 6| Step: 8
Training loss: 5.845973606651673
Validation loss: 5.233720577191604

Epoch: 6| Step: 9
Training loss: 5.928500774179199
Validation loss: 5.229416931161739

Epoch: 6| Step: 10
Training loss: 4.843186277995536
Validation loss: 5.224307787975843

Epoch: 6| Step: 11
Training loss: 5.459660764223395
Validation loss: 5.219488887294254

Epoch: 6| Step: 12
Training loss: 5.433948628665402
Validation loss: 5.213837525328077

Epoch: 6| Step: 13
Training loss: 4.787595041790783
Validation loss: 5.208538214150628

Epoch: 10| Step: 0
Training loss: 5.507352076555629
Validation loss: 5.203242395124824

Epoch: 6| Step: 1
Training loss: 5.938778388281313
Validation loss: 5.197870604693855

Epoch: 6| Step: 2
Training loss: 4.101832208394233
Validation loss: 5.192167243072334

Epoch: 6| Step: 3
Training loss: 5.029151621082032
Validation loss: 5.186731304527565

Epoch: 6| Step: 4
Training loss: 4.438767373070628
Validation loss: 5.181621115799119

Epoch: 6| Step: 5
Training loss: 5.651211512484548
Validation loss: 5.176196518079514

Epoch: 6| Step: 6
Training loss: 5.207076488163859
Validation loss: 5.170841724635879

Epoch: 6| Step: 7
Training loss: 5.417542059171357
Validation loss: 5.16573495565146

Epoch: 6| Step: 8
Training loss: 5.824932297734744
Validation loss: 5.160391914555748

Epoch: 6| Step: 9
Training loss: 5.4546889546331485
Validation loss: 5.154417818324175

Epoch: 6| Step: 10
Training loss: 6.127190645798525
Validation loss: 5.148596059299655

Epoch: 6| Step: 11
Training loss: 5.469506783574403
Validation loss: 5.142809804567322

Epoch: 6| Step: 12
Training loss: 4.6026375879611985
Validation loss: 5.13755717620838

Epoch: 6| Step: 13
Training loss: 4.871697896952347
Validation loss: 5.131791336925599

Epoch: 11| Step: 0
Training loss: 5.133698315876917
Validation loss: 5.126644769993035

Epoch: 6| Step: 1
Training loss: 5.361206097768851
Validation loss: 5.121129536061161

Epoch: 6| Step: 2
Training loss: 5.420961330504597
Validation loss: 5.115315599198418

Epoch: 6| Step: 3
Training loss: 4.361626812572166
Validation loss: 5.109365636290079

Epoch: 6| Step: 4
Training loss: 4.578965666469561
Validation loss: 5.104615805451041

Epoch: 6| Step: 5
Training loss: 4.978809083151774
Validation loss: 5.098506493140087

Epoch: 6| Step: 6
Training loss: 5.303732065444246
Validation loss: 5.092632366115011

Epoch: 6| Step: 7
Training loss: 5.28808061735074
Validation loss: 5.087206391681164

Epoch: 6| Step: 8
Training loss: 5.036773303603176
Validation loss: 5.082251991366783

Epoch: 6| Step: 9
Training loss: 5.6761327478479044
Validation loss: 5.077614595242918

Epoch: 6| Step: 10
Training loss: 4.9276854111593344
Validation loss: 5.072168011681471

Epoch: 6| Step: 11
Training loss: 6.049644762439278
Validation loss: 5.06672263156366

Epoch: 6| Step: 12
Training loss: 5.067587474337132
Validation loss: 5.060642765166786

Epoch: 6| Step: 13
Training loss: 5.5637575935306804
Validation loss: 5.054916541734046

Epoch: 12| Step: 0
Training loss: 5.177276280246867
Validation loss: 5.04948076153383

Epoch: 6| Step: 1
Training loss: 5.169835913173708
Validation loss: 5.044235625872012

Epoch: 6| Step: 2
Training loss: 5.159105099989654
Validation loss: 5.038394885724564

Epoch: 6| Step: 3
Training loss: 5.796649938774578
Validation loss: 5.032302177774608

Epoch: 6| Step: 4
Training loss: 4.627969561741336
Validation loss: 5.025602247040141

Epoch: 6| Step: 5
Training loss: 5.4874843032369105
Validation loss: 5.020510915109591

Epoch: 6| Step: 6
Training loss: 4.8322222956371865
Validation loss: 5.0148330649536295

Epoch: 6| Step: 7
Training loss: 4.614103936753067
Validation loss: 5.009485434466855

Epoch: 6| Step: 8
Training loss: 5.300616627936088
Validation loss: 5.003644727453519

Epoch: 6| Step: 9
Training loss: 5.437068878270768
Validation loss: 4.9979826036211294

Epoch: 6| Step: 10
Training loss: 4.840139310739236
Validation loss: 4.992497935465802

Epoch: 6| Step: 11
Training loss: 5.547742319131048
Validation loss: 4.987987440951519

Epoch: 6| Step: 12
Training loss: 5.476315915900231
Validation loss: 4.9825719842912255

Epoch: 6| Step: 13
Training loss: 4.196535298112097
Validation loss: 4.978160272294904

Epoch: 13| Step: 0
Training loss: 5.098242153829301
Validation loss: 4.972813158538851

Epoch: 6| Step: 1
Training loss: 4.758806597706509
Validation loss: 4.967511132580909

Epoch: 6| Step: 2
Training loss: 4.203082343243115
Validation loss: 4.962966367905958

Epoch: 6| Step: 3
Training loss: 5.774135851919816
Validation loss: 4.957476704860633

Epoch: 6| Step: 4
Training loss: 4.31243763754162
Validation loss: 4.953030076907369

Epoch: 6| Step: 5
Training loss: 5.006802128171152
Validation loss: 4.94825651373658

Epoch: 6| Step: 6
Training loss: 5.5891742425316195
Validation loss: 4.943909488746562

Epoch: 6| Step: 7
Training loss: 4.665336396578204
Validation loss: 4.9393485427631205

Epoch: 6| Step: 8
Training loss: 4.985803668438504
Validation loss: 4.934713035828089

Epoch: 6| Step: 9
Training loss: 5.759508977729854
Validation loss: 4.929995664706849

Epoch: 6| Step: 10
Training loss: 5.012687987800269
Validation loss: 4.924798168042152

Epoch: 6| Step: 11
Training loss: 5.528315913568069
Validation loss: 4.920636767090638

Epoch: 6| Step: 12
Training loss: 4.9258317816227475
Validation loss: 4.915960142590169

Epoch: 6| Step: 13
Training loss: 5.000865098500302
Validation loss: 4.911337027428783

Epoch: 14| Step: 0
Training loss: 4.512514937526674
Validation loss: 4.906504338955183

Epoch: 6| Step: 1
Training loss: 4.4259850908761775
Validation loss: 4.902487995107718

Epoch: 6| Step: 2
Training loss: 5.686567628332715
Validation loss: 4.898207923258947

Epoch: 6| Step: 3
Training loss: 5.786908324216037
Validation loss: 4.893515970440698

Epoch: 6| Step: 4
Training loss: 4.60679176488261
Validation loss: 4.888550404670147

Epoch: 6| Step: 5
Training loss: 5.758433252876344
Validation loss: 4.883885461539445

Epoch: 6| Step: 6
Training loss: 5.212993988121455
Validation loss: 4.879895385131559

Epoch: 6| Step: 7
Training loss: 5.464659637992694
Validation loss: 4.875152748518839

Epoch: 6| Step: 8
Training loss: 4.504960610813425
Validation loss: 4.870848820087667

Epoch: 6| Step: 9
Training loss: 4.023580900432984
Validation loss: 4.866322774799375

Epoch: 6| Step: 10
Training loss: 5.939496798795365
Validation loss: 4.862153921747924

Epoch: 6| Step: 11
Training loss: 4.222725358621575
Validation loss: 4.857394846355406

Epoch: 6| Step: 12
Training loss: 4.309076249332169
Validation loss: 4.853453238564087

Epoch: 6| Step: 13
Training loss: 5.011677837725157
Validation loss: 4.849021586146617

Epoch: 15| Step: 0
Training loss: 4.6227572390259475
Validation loss: 4.844681057610237

Epoch: 6| Step: 1
Training loss: 5.33653816651405
Validation loss: 4.840554214725061

Epoch: 6| Step: 2
Training loss: 4.907906610994762
Validation loss: 4.835912093268865

Epoch: 6| Step: 3
Training loss: 4.954479140727933
Validation loss: 4.8313044641607

Epoch: 6| Step: 4
Training loss: 5.746636111597906
Validation loss: 4.82760926818194

Epoch: 6| Step: 5
Training loss: 5.428775321028312
Validation loss: 4.823325972631638

Epoch: 6| Step: 6
Training loss: 4.460207797628095
Validation loss: 4.819135541785149

Epoch: 6| Step: 7
Training loss: 4.8244314540659055
Validation loss: 4.815063355353543

Epoch: 6| Step: 8
Training loss: 4.223484349811254
Validation loss: 4.811170551254916

Epoch: 6| Step: 9
Training loss: 5.112378465471697
Validation loss: 4.80745389533058

Epoch: 6| Step: 10
Training loss: 4.605563589062732
Validation loss: 4.802714286390904

Epoch: 6| Step: 11
Training loss: 5.475889765931898
Validation loss: 4.79880967613424

Epoch: 6| Step: 12
Training loss: 4.582357799864765
Validation loss: 4.794291377260975

Epoch: 6| Step: 13
Training loss: 4.675315789149593
Validation loss: 4.790044305340318

Epoch: 16| Step: 0
Training loss: 5.785279555362162
Validation loss: 4.786388021733754

Epoch: 6| Step: 1
Training loss: 5.234095141772358
Validation loss: 4.782496021945095

Epoch: 6| Step: 2
Training loss: 4.361201734201968
Validation loss: 4.778180036441978

Epoch: 6| Step: 3
Training loss: 3.844042014838134
Validation loss: 4.774477681457659

Epoch: 6| Step: 4
Training loss: 5.214152063795682
Validation loss: 4.770006660680699

Epoch: 6| Step: 5
Training loss: 5.217270327285021
Validation loss: 4.766133032229826

Epoch: 6| Step: 6
Training loss: 4.613215097959238
Validation loss: 4.762211962622729

Epoch: 6| Step: 7
Training loss: 4.231597552542029
Validation loss: 4.758225379739186

Epoch: 6| Step: 8
Training loss: 4.6447542360002
Validation loss: 4.753901769739912

Epoch: 6| Step: 9
Training loss: 5.997169144708538
Validation loss: 4.750398987192158

Epoch: 6| Step: 10
Training loss: 4.558757553491802
Validation loss: 4.746272079822298

Epoch: 6| Step: 11
Training loss: 4.031032822547477
Validation loss: 4.743203587950192

Epoch: 6| Step: 12
Training loss: 5.04187444253495
Validation loss: 4.73881726903387

Epoch: 6| Step: 13
Training loss: 5.105758647087099
Validation loss: 4.734530808305347

Epoch: 17| Step: 0
Training loss: 5.184450287183149
Validation loss: 4.730612994388078

Epoch: 6| Step: 1
Training loss: 4.560002518703367
Validation loss: 4.727021536066589

Epoch: 6| Step: 2
Training loss: 5.187327922127122
Validation loss: 4.722713330231285

Epoch: 6| Step: 3
Training loss: 5.341181980148997
Validation loss: 4.718791633068614

Epoch: 6| Step: 4
Training loss: 4.399609045519609
Validation loss: 4.715010552878249

Epoch: 6| Step: 5
Training loss: 5.516550478139074
Validation loss: 4.711033944006779

Epoch: 6| Step: 6
Training loss: 4.791691965229864
Validation loss: 4.707293415287326

Epoch: 6| Step: 7
Training loss: 4.875643174218627
Validation loss: 4.703248048780085

Epoch: 6| Step: 8
Training loss: 4.663665192261629
Validation loss: 4.699462004908586

Epoch: 6| Step: 9
Training loss: 3.860869824732224
Validation loss: 4.695370725079223

Epoch: 6| Step: 10
Training loss: 5.182122994238654
Validation loss: 4.691753238039621

Epoch: 6| Step: 11
Training loss: 4.534078202107047
Validation loss: 4.687954452525565

Epoch: 6| Step: 12
Training loss: 4.927801336618958
Validation loss: 4.683863980152097

Epoch: 6| Step: 13
Training loss: 4.359521569416647
Validation loss: 4.67993299278696

Epoch: 18| Step: 0
Training loss: 4.156596922198833
Validation loss: 4.67615332699225

Epoch: 6| Step: 1
Training loss: 4.966183941486041
Validation loss: 4.672578807538366

Epoch: 6| Step: 2
Training loss: 4.242474569088229
Validation loss: 4.668589786093903

Epoch: 6| Step: 3
Training loss: 4.689531623536036
Validation loss: 4.664641906088848

Epoch: 6| Step: 4
Training loss: 3.9999566075832407
Validation loss: 4.6606406860442275

Epoch: 6| Step: 5
Training loss: 3.736269035609925
Validation loss: 4.656954360017435

Epoch: 6| Step: 6
Training loss: 4.637672589732974
Validation loss: 4.653662199287974

Epoch: 6| Step: 7
Training loss: 5.3272657848269125
Validation loss: 4.649705934968065

Epoch: 6| Step: 8
Training loss: 4.44735933455564
Validation loss: 4.6460789614122895

Epoch: 6| Step: 9
Training loss: 5.942758901538611
Validation loss: 4.642016012901289

Epoch: 6| Step: 10
Training loss: 4.566881558079577
Validation loss: 4.638338975170751

Epoch: 6| Step: 11
Training loss: 6.121882365340611
Validation loss: 4.634588663393702

Epoch: 6| Step: 12
Training loss: 4.90600313185146
Validation loss: 4.631081028651645

Epoch: 6| Step: 13
Training loss: 4.511863329663965
Validation loss: 4.627282069354021

Epoch: 19| Step: 0
Training loss: 4.944348957030311
Validation loss: 4.623227303812576

Epoch: 6| Step: 1
Training loss: 4.983538422888134
Validation loss: 4.61911526458639

Epoch: 6| Step: 2
Training loss: 4.384703202854673
Validation loss: 4.615207787737285

Epoch: 6| Step: 3
Training loss: 4.443198400243431
Validation loss: 4.6111934200023725

Epoch: 6| Step: 4
Training loss: 4.356456805318566
Validation loss: 4.607244604866366

Epoch: 6| Step: 5
Training loss: 4.554764552307081
Validation loss: 4.603356418114377

Epoch: 6| Step: 6
Training loss: 4.692057720756131
Validation loss: 4.599426205410467

Epoch: 6| Step: 7
Training loss: 5.013095871665119
Validation loss: 4.595827631919462

Epoch: 6| Step: 8
Training loss: 4.170816465807993
Validation loss: 4.591845993629515

Epoch: 6| Step: 9
Training loss: 5.2882045123190276
Validation loss: 4.5881156709208355

Epoch: 6| Step: 10
Training loss: 4.564413009290983
Validation loss: 4.584114522539733

Epoch: 6| Step: 11
Training loss: 5.210351822409044
Validation loss: 4.580433581344802

Epoch: 6| Step: 12
Training loss: 4.738411671226512
Validation loss: 4.576154525665336

Epoch: 6| Step: 13
Training loss: 4.654080698465289
Validation loss: 4.572375022886306

Epoch: 20| Step: 0
Training loss: 4.899200623371825
Validation loss: 4.568480486906873

Epoch: 6| Step: 1
Training loss: 5.904903197758821
Validation loss: 4.564397408642261

Epoch: 6| Step: 2
Training loss: 4.175017013058291
Validation loss: 4.560138108465356

Epoch: 6| Step: 3
Training loss: 5.176780195463071
Validation loss: 4.556246299375855

Epoch: 6| Step: 4
Training loss: 4.673666926153499
Validation loss: 4.552369301526054

Epoch: 6| Step: 5
Training loss: 4.227840096516644
Validation loss: 4.5480400943593615

Epoch: 6| Step: 6
Training loss: 4.383749795331208
Validation loss: 4.544464416169851

Epoch: 6| Step: 7
Training loss: 4.870967272942025
Validation loss: 4.539807291912401

Epoch: 6| Step: 8
Training loss: 4.639656145574791
Validation loss: 4.536399002942724

Epoch: 6| Step: 9
Training loss: 4.4027273828381395
Validation loss: 4.532398998988853

Epoch: 6| Step: 10
Training loss: 3.6827219379410634
Validation loss: 4.528538947428011

Epoch: 6| Step: 11
Training loss: 4.627973889157715
Validation loss: 4.524866979621415

Epoch: 6| Step: 12
Training loss: 4.898502136485432
Validation loss: 4.521262322858069

Epoch: 6| Step: 13
Training loss: 4.467762017574203
Validation loss: 4.517016380162689

Epoch: 21| Step: 0
Training loss: 4.72463561575495
Validation loss: 4.513732953760847

Epoch: 6| Step: 1
Training loss: 4.738996509931462
Validation loss: 4.50937636479608

Epoch: 6| Step: 2
Training loss: 4.884778315219921
Validation loss: 4.505746104460991

Epoch: 6| Step: 3
Training loss: 4.874340306175817
Validation loss: 4.5022449545010765

Epoch: 6| Step: 4
Training loss: 4.461900490205611
Validation loss: 4.497912381859075

Epoch: 6| Step: 5
Training loss: 4.400058156409431
Validation loss: 4.494412697573966

Epoch: 6| Step: 6
Training loss: 4.751149891654519
Validation loss: 4.490182127115554

Epoch: 6| Step: 7
Training loss: 4.941659840948442
Validation loss: 4.48642782084754

Epoch: 6| Step: 8
Training loss: 4.2757809645075735
Validation loss: 4.4827557519082255

Epoch: 6| Step: 9
Training loss: 4.107523569978594
Validation loss: 4.478671107121233

Epoch: 6| Step: 10
Training loss: 4.297259615243843
Validation loss: 4.474847541641509

Epoch: 6| Step: 11
Training loss: 4.157539798548376
Validation loss: 4.471697033411615

Epoch: 6| Step: 12
Training loss: 4.798336440139795
Validation loss: 4.467220889528551

Epoch: 6| Step: 13
Training loss: 5.088198579631754
Validation loss: 4.463649159416471

Epoch: 22| Step: 0
Training loss: 4.965569011739899
Validation loss: 4.4594184172988784

Epoch: 6| Step: 1
Training loss: 4.638701480168684
Validation loss: 4.455838310410618

Epoch: 6| Step: 2
Training loss: 3.8642307885000853
Validation loss: 4.451998348374016

Epoch: 6| Step: 3
Training loss: 4.222029478012678
Validation loss: 4.447989070877764

Epoch: 6| Step: 4
Training loss: 5.27741766030081
Validation loss: 4.444231828266349

Epoch: 6| Step: 5
Training loss: 4.6234936709793315
Validation loss: 4.440128425539332

Epoch: 6| Step: 6
Training loss: 4.534962363291961
Validation loss: 4.436567324914539

Epoch: 6| Step: 7
Training loss: 5.133326395864051
Validation loss: 4.432043921079722

Epoch: 6| Step: 8
Training loss: 4.277553326772082
Validation loss: 4.428412916200344

Epoch: 6| Step: 9
Training loss: 4.633668354098239
Validation loss: 4.424815912961419

Epoch: 6| Step: 10
Training loss: 4.808483082220624
Validation loss: 4.420608662688761

Epoch: 6| Step: 11
Training loss: 4.233528531197456
Validation loss: 4.416797899899648

Epoch: 6| Step: 12
Training loss: 3.928079386031279
Validation loss: 4.412489295060354

Epoch: 6| Step: 13
Training loss: 4.511749399584747
Validation loss: 4.408670955245349

Epoch: 23| Step: 0
Training loss: 4.261025880317365
Validation loss: 4.404761890524296

Epoch: 6| Step: 1
Training loss: 4.2570038473780825
Validation loss: 4.401113126577149

Epoch: 6| Step: 2
Training loss: 4.709121278080437
Validation loss: 4.397537925430892

Epoch: 6| Step: 3
Training loss: 4.266698681194677
Validation loss: 4.394219408061793

Epoch: 6| Step: 4
Training loss: 5.083008844410318
Validation loss: 4.3898781427431395

Epoch: 6| Step: 5
Training loss: 4.696716606428741
Validation loss: 4.3859574565154835

Epoch: 6| Step: 6
Training loss: 4.9447096326104
Validation loss: 4.381615169759886

Epoch: 6| Step: 7
Training loss: 4.880691726937734
Validation loss: 4.377850902471628

Epoch: 6| Step: 8
Training loss: 4.743338883468873
Validation loss: 4.37355969653425

Epoch: 6| Step: 9
Training loss: 4.047914349445198
Validation loss: 4.369622476945092

Epoch: 6| Step: 10
Training loss: 3.834624211327891
Validation loss: 4.365587263187682

Epoch: 6| Step: 11
Training loss: 3.989037990233286
Validation loss: 4.361936283944604

Epoch: 6| Step: 12
Training loss: 3.688179212183714
Validation loss: 4.358051732717209

Epoch: 6| Step: 13
Training loss: 5.36833984797802
Validation loss: 4.354169465327238

Epoch: 24| Step: 0
Training loss: 3.871352417095803
Validation loss: 4.350250502933494

Epoch: 6| Step: 1
Training loss: 4.206207619803563
Validation loss: 4.3458578543673765

Epoch: 6| Step: 2
Training loss: 5.10808376596663
Validation loss: 4.342443951362351

Epoch: 6| Step: 3
Training loss: 4.732320711233004
Validation loss: 4.338615621399747

Epoch: 6| Step: 4
Training loss: 3.6486732684460863
Validation loss: 4.334680525122081

Epoch: 6| Step: 5
Training loss: 4.3595316322107465
Validation loss: 4.330604806820738

Epoch: 6| Step: 6
Training loss: 5.026556443912462
Validation loss: 4.326492166825741

Epoch: 6| Step: 7
Training loss: 4.426228136225698
Validation loss: 4.321897633259523

Epoch: 6| Step: 8
Training loss: 4.012498402818023
Validation loss: 4.318317782924798

Epoch: 6| Step: 9
Training loss: 4.925864501055999
Validation loss: 4.314252377570445

Epoch: 6| Step: 10
Training loss: 5.305882539820042
Validation loss: 4.310236295254467

Epoch: 6| Step: 11
Training loss: 3.5831471476127397
Validation loss: 4.305813013945168

Epoch: 6| Step: 12
Training loss: 4.287650120723385
Validation loss: 4.302073881248208

Epoch: 6| Step: 13
Training loss: 4.442765885845287
Validation loss: 4.2977040363820205

Epoch: 25| Step: 0
Training loss: 4.644685657652026
Validation loss: 4.293433476922885

Epoch: 6| Step: 1
Training loss: 4.8142257172458995
Validation loss: 4.289000500877696

Epoch: 6| Step: 2
Training loss: 4.33193438518846
Validation loss: 4.2852309344218655

Epoch: 6| Step: 3
Training loss: 3.948694452786861
Validation loss: 4.281020703637622

Epoch: 6| Step: 4
Training loss: 4.328077405537049
Validation loss: 4.276211430489886

Epoch: 6| Step: 5
Training loss: 4.653078368743005
Validation loss: 4.272521948969135

Epoch: 6| Step: 6
Training loss: 4.68644539731726
Validation loss: 4.26817206607753

Epoch: 6| Step: 7
Training loss: 4.092290953165638
Validation loss: 4.263809041129198

Epoch: 6| Step: 8
Training loss: 4.5165968116529065
Validation loss: 4.2594531896611505

Epoch: 6| Step: 9
Training loss: 4.481891648922979
Validation loss: 4.255261268737812

Epoch: 6| Step: 10
Training loss: 4.440266136578692
Validation loss: 4.250814808546717

Epoch: 6| Step: 11
Training loss: 4.636764204771406
Validation loss: 4.246134851672621

Epoch: 6| Step: 12
Training loss: 4.110474414036324
Validation loss: 4.241792813856616

Epoch: 6| Step: 13
Training loss: 3.734995515098075
Validation loss: 4.237370481359062

Epoch: 26| Step: 0
Training loss: 4.324525954887665
Validation loss: 4.233395508937857

Epoch: 6| Step: 1
Training loss: 4.955632005528533
Validation loss: 4.229369636262785

Epoch: 6| Step: 2
Training loss: 4.1038474847960416
Validation loss: 4.224890866647683

Epoch: 6| Step: 3
Training loss: 3.124342429595483
Validation loss: 4.220515147972814

Epoch: 6| Step: 4
Training loss: 4.603835679436966
Validation loss: 4.217002582111734

Epoch: 6| Step: 5
Training loss: 4.890942840485511
Validation loss: 4.212544433631076

Epoch: 6| Step: 6
Training loss: 3.9843911563321335
Validation loss: 4.208676629495232

Epoch: 6| Step: 7
Training loss: 4.737506296762595
Validation loss: 4.204284508033122

Epoch: 6| Step: 8
Training loss: 4.208468192681108
Validation loss: 4.2005244911526365

Epoch: 6| Step: 9
Training loss: 3.9205569297880976
Validation loss: 4.196035615249245

Epoch: 6| Step: 10
Training loss: 3.8891392824004334
Validation loss: 4.192218513388271

Epoch: 6| Step: 11
Training loss: 4.419541460996137
Validation loss: 4.18825211104788

Epoch: 6| Step: 12
Training loss: 4.649876681097474
Validation loss: 4.1837995130110635

Epoch: 6| Step: 13
Training loss: 4.555280224819955
Validation loss: 4.1792962482377165

Epoch: 27| Step: 0
Training loss: 4.078972622415962
Validation loss: 4.174936816409361

Epoch: 6| Step: 1
Training loss: 4.841172449272361
Validation loss: 4.170469182924026

Epoch: 6| Step: 2
Training loss: 4.72029624009323
Validation loss: 4.166569110999874

Epoch: 6| Step: 3
Training loss: 4.626612407978134
Validation loss: 4.162236427004092

Epoch: 6| Step: 4
Training loss: 4.587614776256519
Validation loss: 4.157874896376812

Epoch: 6| Step: 5
Training loss: 4.731939413216484
Validation loss: 4.153776843198249

Epoch: 6| Step: 6
Training loss: 3.5276757439970523
Validation loss: 4.149250724284772

Epoch: 6| Step: 7
Training loss: 4.293494542059001
Validation loss: 4.14493073010208

Epoch: 6| Step: 8
Training loss: 3.4691997614526726
Validation loss: 4.140892835867555

Epoch: 6| Step: 9
Training loss: 4.15393644490154
Validation loss: 4.13641755926049

Epoch: 6| Step: 10
Training loss: 4.296248400690371
Validation loss: 4.132474773719996

Epoch: 6| Step: 11
Training loss: 4.014689176886764
Validation loss: 4.128486123510338

Epoch: 6| Step: 12
Training loss: 4.038368268735008
Validation loss: 4.124508240797166

Epoch: 6| Step: 13
Training loss: 4.271766126538735
Validation loss: 4.120103318699746

Epoch: 28| Step: 0
Training loss: 4.191191682896204
Validation loss: 4.116016064454646

Epoch: 6| Step: 1
Training loss: 3.998690510027365
Validation loss: 4.111940827854325

Epoch: 6| Step: 2
Training loss: 4.40324526663844
Validation loss: 4.107774604166947

Epoch: 6| Step: 3
Training loss: 4.299523553401572
Validation loss: 4.103717075773177

Epoch: 6| Step: 4
Training loss: 4.619449893848546
Validation loss: 4.099442133128192

Epoch: 6| Step: 5
Training loss: 4.132341498665942
Validation loss: 4.095496487017034

Epoch: 6| Step: 6
Training loss: 4.087687422162281
Validation loss: 4.091479091397712

Epoch: 6| Step: 7
Training loss: 3.800345008647691
Validation loss: 4.087352092061706

Epoch: 6| Step: 8
Training loss: 4.483426834511736
Validation loss: 4.083096510319018

Epoch: 6| Step: 9
Training loss: 4.215010730734274
Validation loss: 4.079059381733421

Epoch: 6| Step: 10
Training loss: 4.217698934099737
Validation loss: 4.074934138602457

Epoch: 6| Step: 11
Training loss: 4.697631060369226
Validation loss: 4.070838762407902

Epoch: 6| Step: 12
Training loss: 4.324945597223775
Validation loss: 4.066562831574462

Epoch: 6| Step: 13
Training loss: 3.488215908280094
Validation loss: 4.0623048001857045

Epoch: 29| Step: 0
Training loss: 3.41777092061418
Validation loss: 4.058293908859189

Epoch: 6| Step: 1
Training loss: 4.658441834161464
Validation loss: 4.054328094018207

Epoch: 6| Step: 2
Training loss: 4.036103395012865
Validation loss: 4.050116126040041

Epoch: 6| Step: 3
Training loss: 4.366934835532594
Validation loss: 4.046082702609852

Epoch: 6| Step: 4
Training loss: 4.035556356086409
Validation loss: 4.042099500203765

Epoch: 6| Step: 5
Training loss: 4.47657613435969
Validation loss: 4.03799400732343

Epoch: 6| Step: 6
Training loss: 4.51218544664144
Validation loss: 4.034049941997449

Epoch: 6| Step: 7
Training loss: 4.1090918613840905
Validation loss: 4.029388786644592

Epoch: 6| Step: 8
Training loss: 4.599235321839305
Validation loss: 4.025463515104058

Epoch: 6| Step: 9
Training loss: 3.1859171808258067
Validation loss: 4.021402025607039

Epoch: 6| Step: 10
Training loss: 4.70364691287578
Validation loss: 4.0173739373828345

Epoch: 6| Step: 11
Training loss: 4.5350561533419675
Validation loss: 4.013116827560743

Epoch: 6| Step: 12
Training loss: 3.210693053062134
Validation loss: 4.008829108102866

Epoch: 6| Step: 13
Training loss: 4.03154191727097
Validation loss: 4.004486726690998

Epoch: 30| Step: 0
Training loss: 3.8468104638296006
Validation loss: 4.000510044163642

Epoch: 6| Step: 1
Training loss: 4.3862626202918955
Validation loss: 3.996255632081735

Epoch: 6| Step: 2
Training loss: 4.305584656538429
Validation loss: 3.99229716668542

Epoch: 6| Step: 3
Training loss: 4.344961752070221
Validation loss: 3.988231851668502

Epoch: 6| Step: 4
Training loss: 4.110275576000829
Validation loss: 3.984023254426244

Epoch: 6| Step: 5
Training loss: 3.4468686142669487
Validation loss: 3.9794560205731258

Epoch: 6| Step: 6
Training loss: 4.219380423455192
Validation loss: 3.975652324484862

Epoch: 6| Step: 7
Training loss: 4.021217815352192
Validation loss: 3.9713835101268224

Epoch: 6| Step: 8
Training loss: 4.174112127314215
Validation loss: 3.9672127497398995

Epoch: 6| Step: 9
Training loss: 4.538905339630791
Validation loss: 3.963152474917407

Epoch: 6| Step: 10
Training loss: 4.15935199825768
Validation loss: 3.9589535210612694

Epoch: 6| Step: 11
Training loss: 2.9766382723397733
Validation loss: 3.9547708776620514

Epoch: 6| Step: 12
Training loss: 4.5478820734227225
Validation loss: 3.9506659216024484

Epoch: 6| Step: 13
Training loss: 4.14797080193215
Validation loss: 3.9466684762095694

Epoch: 31| Step: 0
Training loss: 4.267803823408201
Validation loss: 3.9427720757206806

Epoch: 6| Step: 1
Training loss: 4.137149835157644
Validation loss: 3.9386606877276638

Epoch: 6| Step: 2
Training loss: 4.129558472019512
Validation loss: 3.9342478082411625

Epoch: 6| Step: 3
Training loss: 4.005784144222879
Validation loss: 3.9300665144917413

Epoch: 6| Step: 4
Training loss: 4.765387657383865
Validation loss: 3.926362245500256

Epoch: 6| Step: 5
Training loss: 3.392774753000436
Validation loss: 3.9219957715572096

Epoch: 6| Step: 6
Training loss: 4.21840818927794
Validation loss: 3.9175985458693305

Epoch: 6| Step: 7
Training loss: 3.7816767175932315
Validation loss: 3.9136491609292374

Epoch: 6| Step: 8
Training loss: 3.8388983648330126
Validation loss: 3.9095409111110007

Epoch: 6| Step: 9
Training loss: 3.8091047834233485
Validation loss: 3.905470930611295

Epoch: 6| Step: 10
Training loss: 2.6760074714761615
Validation loss: 3.9014798959327095

Epoch: 6| Step: 11
Training loss: 4.567963973242329
Validation loss: 3.8976813572385702

Epoch: 6| Step: 12
Training loss: 4.473442548242
Validation loss: 3.893820516357001

Epoch: 6| Step: 13
Training loss: 4.2043704772081085
Validation loss: 3.889535345358017

Epoch: 32| Step: 0
Training loss: 4.043806525517796
Validation loss: 3.885323115118288

Epoch: 6| Step: 1
Training loss: 4.170594208093612
Validation loss: 3.881405202452038

Epoch: 6| Step: 2
Training loss: 4.245377214294437
Validation loss: 3.8771572466075015

Epoch: 6| Step: 3
Training loss: 4.466491341827074
Validation loss: 3.872895992416077

Epoch: 6| Step: 4
Training loss: 4.159439125397873
Validation loss: 3.8684155091039862

Epoch: 6| Step: 5
Training loss: 2.772370468980102
Validation loss: 3.8640366173543343

Epoch: 6| Step: 6
Training loss: 4.257358687828191
Validation loss: 3.8602568819617

Epoch: 6| Step: 7
Training loss: 4.044119231687837
Validation loss: 3.855994675982165

Epoch: 6| Step: 8
Training loss: 2.9529194432324455
Validation loss: 3.8520748888620866

Epoch: 6| Step: 9
Training loss: 4.50859012871324
Validation loss: 3.8480234348511413

Epoch: 6| Step: 10
Training loss: 3.8232584011469744
Validation loss: 3.8440114787827135

Epoch: 6| Step: 11
Training loss: 4.371293159688498
Validation loss: 3.8401210991321295

Epoch: 6| Step: 12
Training loss: 4.161481733896908
Validation loss: 3.836045812047515

Epoch: 6| Step: 13
Training loss: 3.476875891115361
Validation loss: 3.831936844477196

Epoch: 33| Step: 0
Training loss: 4.068909738337807
Validation loss: 3.827835549550831

Epoch: 6| Step: 1
Training loss: 3.142914653846379
Validation loss: 3.8237644402375857

Epoch: 6| Step: 2
Training loss: 3.7239412889779673
Validation loss: 3.8199055356766776

Epoch: 6| Step: 3
Training loss: 4.094460927952219
Validation loss: 3.815899589170521

Epoch: 6| Step: 4
Training loss: 4.223875873605886
Validation loss: 3.811973577124281

Epoch: 6| Step: 5
Training loss: 3.919361905109695
Validation loss: 3.808056613181393

Epoch: 6| Step: 6
Training loss: 4.197052948020352
Validation loss: 3.8040857276509246

Epoch: 6| Step: 7
Training loss: 4.253986284328027
Validation loss: 3.7999498347267187

Epoch: 6| Step: 8
Training loss: 3.874434276015981
Validation loss: 3.7957799350124515

Epoch: 6| Step: 9
Training loss: 4.382229744150525
Validation loss: 3.791705763618757

Epoch: 6| Step: 10
Training loss: 4.308912913864422
Validation loss: 3.7876001216802866

Epoch: 6| Step: 11
Training loss: 3.6697191768131145
Validation loss: 3.7831523933219255

Epoch: 6| Step: 12
Training loss: 3.003290120645538
Validation loss: 3.7792103628529534

Epoch: 6| Step: 13
Training loss: 3.9713876925027853
Validation loss: 3.774885090811665

Epoch: 34| Step: 0
Training loss: 4.201219091145645
Validation loss: 3.7709908355922543

Epoch: 6| Step: 1
Training loss: 4.030323720571654
Validation loss: 3.766718830883966

Epoch: 6| Step: 2
Training loss: 3.802774626014827
Validation loss: 3.762590359503645

Epoch: 6| Step: 3
Training loss: 4.053364973530336
Validation loss: 3.7585056905422154

Epoch: 6| Step: 4
Training loss: 3.209137126423769
Validation loss: 3.7544206206656

Epoch: 6| Step: 5
Training loss: 4.056518376528243
Validation loss: 3.750431311492982

Epoch: 6| Step: 6
Training loss: 3.3883036036828194
Validation loss: 3.7464779950781204

Epoch: 6| Step: 7
Training loss: 3.81853532702818
Validation loss: 3.742500711499157

Epoch: 6| Step: 8
Training loss: 4.265474533389587
Validation loss: 3.738671612263763

Epoch: 6| Step: 9
Training loss: 3.450253634873601
Validation loss: 3.734791539582438

Epoch: 6| Step: 10
Training loss: 4.118729420264642
Validation loss: 3.7309272417785406

Epoch: 6| Step: 11
Training loss: 3.396070054741425
Validation loss: 3.7268902030079025

Epoch: 6| Step: 12
Training loss: 4.296153170904303
Validation loss: 3.7230023453041032

Epoch: 6| Step: 13
Training loss: 4.027392767266567
Validation loss: 3.7189716732515383

Epoch: 35| Step: 0
Training loss: 3.826497506601799
Validation loss: 3.7150635599113118

Epoch: 6| Step: 1
Training loss: 3.536530723823402
Validation loss: 3.7107477721852877

Epoch: 6| Step: 2
Training loss: 3.834925997938939
Validation loss: 3.706798121387756

Epoch: 6| Step: 3
Training loss: 3.9020011071731977
Validation loss: 3.702739325289773

Epoch: 6| Step: 4
Training loss: 4.114796126774325
Validation loss: 3.698788643055301

Epoch: 6| Step: 5
Training loss: 3.8754737318317827
Validation loss: 3.694683384319118

Epoch: 6| Step: 6
Training loss: 4.495932966418137
Validation loss: 3.690648281315762

Epoch: 6| Step: 7
Training loss: 4.147631895648031
Validation loss: 3.686474328798184

Epoch: 6| Step: 8
Training loss: 3.5596151885459957
Validation loss: 3.6822157244515306

Epoch: 6| Step: 9
Training loss: 4.1312709882840775
Validation loss: 3.6781311199317734

Epoch: 6| Step: 10
Training loss: 3.7276846357806943
Validation loss: 3.6738377296691302

Epoch: 6| Step: 11
Training loss: 2.7123754024455216
Validation loss: 3.6697447529173655

Epoch: 6| Step: 12
Training loss: 3.973182905878416
Validation loss: 3.66584631383745

Epoch: 6| Step: 13
Training loss: 3.4355946201912575
Validation loss: 3.66190307578645

Epoch: 36| Step: 0
Training loss: 3.558604201668927
Validation loss: 3.6579850908006524

Epoch: 6| Step: 1
Training loss: 3.6364300179924864
Validation loss: 3.6543930424361797

Epoch: 6| Step: 2
Training loss: 3.946189737521378
Validation loss: 3.6504846094400323

Epoch: 6| Step: 3
Training loss: 3.4131008862780643
Validation loss: 3.6464960785623313

Epoch: 6| Step: 4
Training loss: 4.070158327664399
Validation loss: 3.6428353908256264

Epoch: 6| Step: 5
Training loss: 3.441578058636969
Validation loss: 3.6388712357601647

Epoch: 6| Step: 6
Training loss: 3.803594224581344
Validation loss: 3.6350126652276127

Epoch: 6| Step: 7
Training loss: 3.8897288565782775
Validation loss: 3.631243141855055

Epoch: 6| Step: 8
Training loss: 3.86744975732423
Validation loss: 3.627498927327652

Epoch: 6| Step: 9
Training loss: 3.9376458035070847
Validation loss: 3.62334764025641

Epoch: 6| Step: 10
Training loss: 3.1038649922338193
Validation loss: 3.619569547502599

Epoch: 6| Step: 11
Training loss: 4.577952098510836
Validation loss: 3.6157377783205606

Epoch: 6| Step: 12
Training loss: 3.5855688765802802
Validation loss: 3.611611580199014

Epoch: 6| Step: 13
Training loss: 3.745075552856904
Validation loss: 3.6077065402849238

Epoch: 37| Step: 0
Training loss: 4.205079032164324
Validation loss: 3.6039127120731815

Epoch: 6| Step: 1
Training loss: 3.4170330750536704
Validation loss: 3.599800633278885

Epoch: 6| Step: 2
Training loss: 3.305130732687627
Validation loss: 3.5959117192771117

Epoch: 6| Step: 3
Training loss: 4.318404868173983
Validation loss: 3.5921742619749937

Epoch: 6| Step: 4
Training loss: 2.3451324454769313
Validation loss: 3.5882679466235166

Epoch: 6| Step: 5
Training loss: 3.409713803807726
Validation loss: 3.584642695945982

Epoch: 6| Step: 6
Training loss: 4.123147028109145
Validation loss: 3.5809926364954

Epoch: 6| Step: 7
Training loss: 4.120383251104966
Validation loss: 3.5772633188267977

Epoch: 6| Step: 8
Training loss: 4.1275700741231365
Validation loss: 3.5733364440657707

Epoch: 6| Step: 9
Training loss: 3.927059439966721
Validation loss: 3.5693231793761386

Epoch: 6| Step: 10
Training loss: 3.456410773678581
Validation loss: 3.565376002014538

Epoch: 6| Step: 11
Training loss: 3.4029199964079564
Validation loss: 3.5613768072951273

Epoch: 6| Step: 12
Training loss: 3.8551986275054015
Validation loss: 3.557596077281761

Epoch: 6| Step: 13
Training loss: 3.5524256626112396
Validation loss: 3.553688551722282

Epoch: 38| Step: 0
Training loss: 4.229504927213266
Validation loss: 3.549894618767127

Epoch: 6| Step: 1
Training loss: 3.842773809760147
Validation loss: 3.5460096919799935

Epoch: 6| Step: 2
Training loss: 3.8117870226963735
Validation loss: 3.5420332027080295

Epoch: 6| Step: 3
Training loss: 3.468722506577417
Validation loss: 3.5381935742724173

Epoch: 6| Step: 4
Training loss: 3.6304693068948626
Validation loss: 3.5344676209401786

Epoch: 6| Step: 5
Training loss: 3.6757877361957916
Validation loss: 3.530521115047434

Epoch: 6| Step: 6
Training loss: 3.496569041758183
Validation loss: 3.52666984307976

Epoch: 6| Step: 7
Training loss: 3.592868862766781
Validation loss: 3.522992587422912

Epoch: 6| Step: 8
Training loss: 3.4314673460894003
Validation loss: 3.5192498967160155

Epoch: 6| Step: 9
Training loss: 2.59248891300196
Validation loss: 3.5153454591735

Epoch: 6| Step: 10
Training loss: 3.7881880232844645
Validation loss: 3.5114945172837357

Epoch: 6| Step: 11
Training loss: 3.480133759788975
Validation loss: 3.507825175986719

Epoch: 6| Step: 12
Training loss: 4.435149093925881
Validation loss: 3.5043032848988536

Epoch: 6| Step: 13
Training loss: 3.511576988066079
Validation loss: 3.5003018249071034

Epoch: 39| Step: 0
Training loss: 3.456037165071079
Validation loss: 3.496458305233571

Epoch: 6| Step: 1
Training loss: 3.144570827827407
Validation loss: 3.4929550886189196

Epoch: 6| Step: 2
Training loss: 3.586516157015224
Validation loss: 3.489297830469803

Epoch: 6| Step: 3
Training loss: 3.6448373941956524
Validation loss: 3.4859961828071206

Epoch: 6| Step: 4
Training loss: 3.028965984205118
Validation loss: 3.4821779768666734

Epoch: 6| Step: 5
Training loss: 3.129651079808683
Validation loss: 3.478762452787133

Epoch: 6| Step: 6
Training loss: 3.5881247903477935
Validation loss: 3.4756304345136737

Epoch: 6| Step: 7
Training loss: 4.021682623209615
Validation loss: 3.4722603571175163

Epoch: 6| Step: 8
Training loss: 3.274339355927152
Validation loss: 3.468723583407235

Epoch: 6| Step: 9
Training loss: 3.8919892274760413
Validation loss: 3.465149611857349

Epoch: 6| Step: 10
Training loss: 4.488992367444568
Validation loss: 3.461503510013417

Epoch: 6| Step: 11
Training loss: 3.3057461388905893
Validation loss: 3.4577366800638916

Epoch: 6| Step: 12
Training loss: 3.507337372341077
Validation loss: 3.45408837874304

Epoch: 6| Step: 13
Training loss: 4.155174403013429
Validation loss: 3.450147354738516

Epoch: 40| Step: 0
Training loss: 3.0221326116603384
Validation loss: 3.4463996123615637

Epoch: 6| Step: 1
Training loss: 2.9604498227594016
Validation loss: 3.44250772019617

Epoch: 6| Step: 2
Training loss: 3.704991252646886
Validation loss: 3.4389932799085527

Epoch: 6| Step: 3
Training loss: 4.043251801685858
Validation loss: 3.435347640387203

Epoch: 6| Step: 4
Training loss: 2.9667059034974597
Validation loss: 3.4315573215957946

Epoch: 6| Step: 5
Training loss: 3.073392531624033
Validation loss: 3.427915957025637

Epoch: 6| Step: 6
Training loss: 3.794673579756801
Validation loss: 3.4244544121412

Epoch: 6| Step: 7
Training loss: 3.938487943202005
Validation loss: 3.4209445286349256

Epoch: 6| Step: 8
Training loss: 3.6371144408292237
Validation loss: 3.4173600183378516

Epoch: 6| Step: 9
Training loss: 3.7410709889642852
Validation loss: 3.4137999363080906

Epoch: 6| Step: 10
Training loss: 4.036707769090687
Validation loss: 3.4102543849159495

Epoch: 6| Step: 11
Training loss: 3.184964836082194
Validation loss: 3.406541071129959

Epoch: 6| Step: 12
Training loss: 3.7566050534638267
Validation loss: 3.4029539300559764

Epoch: 6| Step: 13
Training loss: 3.6941766586071054
Validation loss: 3.3992488900954556

Epoch: 41| Step: 0
Training loss: 3.1336067695889307
Validation loss: 3.3954304103094906

Epoch: 6| Step: 1
Training loss: 3.7755015160091903
Validation loss: 3.391745210873781

Epoch: 6| Step: 2
Training loss: 2.945160960541222
Validation loss: 3.3879291112487704

Epoch: 6| Step: 3
Training loss: 3.769676972571929
Validation loss: 3.384374256550762

Epoch: 6| Step: 4
Training loss: 3.618092499924884
Validation loss: 3.3807291218454916

Epoch: 6| Step: 5
Training loss: 2.8451554734264963
Validation loss: 3.3769749879175284

Epoch: 6| Step: 6
Training loss: 3.7337949932849663
Validation loss: 3.3735408454390985

Epoch: 6| Step: 7
Training loss: 3.668962208006081
Validation loss: 3.370246082229776

Epoch: 6| Step: 8
Training loss: 3.3959674145648298
Validation loss: 3.3667020632201847

Epoch: 6| Step: 9
Training loss: 4.080985166126858
Validation loss: 3.3630906958213767

Epoch: 6| Step: 10
Training loss: 3.579343097025708
Validation loss: 3.359531747872276

Epoch: 6| Step: 11
Training loss: 3.683949199529211
Validation loss: 3.3562036019734522

Epoch: 6| Step: 12
Training loss: 3.343849109357344
Validation loss: 3.3524079816205172

Epoch: 6| Step: 13
Training loss: 3.379761621770849
Validation loss: 3.3489386447705463

Epoch: 42| Step: 0
Training loss: 3.82201586235264
Validation loss: 3.345373811119874

Epoch: 6| Step: 1
Training loss: 2.336702049448219
Validation loss: 3.341855686070816

Epoch: 6| Step: 2
Training loss: 3.908116253407322
Validation loss: 3.338624513801285

Epoch: 6| Step: 3
Training loss: 2.7664536780983635
Validation loss: 3.3352901834257005

Epoch: 6| Step: 4
Training loss: 2.5545376141642886
Validation loss: 3.3321232665617297

Epoch: 6| Step: 5
Training loss: 4.01414801007962
Validation loss: 3.3290064544385984

Epoch: 6| Step: 6
Training loss: 3.1285599839610216
Validation loss: 3.325959350223602

Epoch: 6| Step: 7
Training loss: 3.23206279869256
Validation loss: 3.322861666009946

Epoch: 6| Step: 8
Training loss: 3.0377702883175615
Validation loss: 3.3196106411992674

Epoch: 6| Step: 9
Training loss: 3.9608310782979053
Validation loss: 3.3167037920255806

Epoch: 6| Step: 10
Training loss: 3.6600632304582046
Validation loss: 3.313588485379016

Epoch: 6| Step: 11
Training loss: 4.109457152963274
Validation loss: 3.310134931082578

Epoch: 6| Step: 12
Training loss: 4.062923233287205
Validation loss: 3.3067833857804523

Epoch: 6| Step: 13
Training loss: 3.214538337226138
Validation loss: 3.3032391728422685

Epoch: 43| Step: 0
Training loss: 3.7874702175467614
Validation loss: 3.29977121041702

Epoch: 6| Step: 1
Training loss: 2.4575396619760883
Validation loss: 3.2960039768982017

Epoch: 6| Step: 2
Training loss: 4.026647261473863
Validation loss: 3.29254456575125

Epoch: 6| Step: 3
Training loss: 3.626338580054596
Validation loss: 3.2889803938837527

Epoch: 6| Step: 4
Training loss: 3.3836258753940616
Validation loss: 3.2854670597937496

Epoch: 6| Step: 5
Training loss: 3.0536811126921384
Validation loss: 3.2820012156065634

Epoch: 6| Step: 6
Training loss: 3.701324153776998
Validation loss: 3.2787309695646685

Epoch: 6| Step: 7
Training loss: 3.5958162421523516
Validation loss: 3.275211627325152

Epoch: 6| Step: 8
Training loss: 2.824822030327086
Validation loss: 3.2718438371390586

Epoch: 6| Step: 9
Training loss: 3.147245953088732
Validation loss: 3.2686135034404806

Epoch: 6| Step: 10
Training loss: 3.307681916208612
Validation loss: 3.2655325455179582

Epoch: 6| Step: 11
Training loss: 3.841086356354496
Validation loss: 3.262492842197483

Epoch: 6| Step: 12
Training loss: 3.193215425845769
Validation loss: 3.2592824764901844

Epoch: 6| Step: 13
Training loss: 3.5723566593273453
Validation loss: 3.2561209576811194

Epoch: 44| Step: 0
Training loss: 3.6401901312836027
Validation loss: 3.2528845139635183

Epoch: 6| Step: 1
Training loss: 3.998502450991613
Validation loss: 3.249625722412439

Epoch: 6| Step: 2
Training loss: 3.058287077786958
Validation loss: 3.246304379334435

Epoch: 6| Step: 3
Training loss: 3.1241273806070695
Validation loss: 3.2430568770397543

Epoch: 6| Step: 4
Training loss: 3.593625273820655
Validation loss: 3.2398335563622567

Epoch: 6| Step: 5
Training loss: 3.102330187285419
Validation loss: 3.2367165608068342

Epoch: 6| Step: 6
Training loss: 2.8504420757420497
Validation loss: 3.233791698004616

Epoch: 6| Step: 7
Training loss: 3.4274975991049383
Validation loss: 3.2308626376844947

Epoch: 6| Step: 8
Training loss: 4.148817486790216
Validation loss: 3.2278589779752704

Epoch: 6| Step: 9
Training loss: 3.4729163090721515
Validation loss: 3.2246556716759365

Epoch: 6| Step: 10
Training loss: 3.3993470125892578
Validation loss: 3.2214190826824045

Epoch: 6| Step: 11
Training loss: 2.8514091554980503
Validation loss: 3.218249729623998

Epoch: 6| Step: 12
Training loss: 3.151223438579225
Validation loss: 3.215289431487446

Epoch: 6| Step: 13
Training loss: 3.128155450358317
Validation loss: 3.2121399038142027

Epoch: 45| Step: 0
Training loss: 3.556396878231276
Validation loss: 3.2092826644258565

Epoch: 6| Step: 1
Training loss: 3.4739087209442676
Validation loss: 3.2061381984202404

Epoch: 6| Step: 2
Training loss: 3.95538482607122
Validation loss: 3.2029948262381196

Epoch: 6| Step: 3
Training loss: 3.260791614817057
Validation loss: 3.199780263906311

Epoch: 6| Step: 4
Training loss: 2.8763326790343564
Validation loss: 3.196426035907183

Epoch: 6| Step: 5
Training loss: 2.72772262070314
Validation loss: 3.1933520209084856

Epoch: 6| Step: 6
Training loss: 3.1399801171031676
Validation loss: 3.1903962584177394

Epoch: 6| Step: 7
Training loss: 3.396770059461345
Validation loss: 3.1874394005892874

Epoch: 6| Step: 8
Training loss: 4.126043245578006
Validation loss: 3.1844890061205327

Epoch: 6| Step: 9
Training loss: 2.4507991188183462
Validation loss: 3.1814816198861724

Epoch: 6| Step: 10
Training loss: 3.04022947524459
Validation loss: 3.1785875522088243

Epoch: 6| Step: 11
Training loss: 3.5745902780350582
Validation loss: 3.1756187106458564

Epoch: 6| Step: 12
Training loss: 2.944074051630559
Validation loss: 3.1728891088867375

Epoch: 6| Step: 13
Training loss: 3.69780468121955
Validation loss: 3.170099635378505

Epoch: 46| Step: 0
Training loss: 3.448737623932918
Validation loss: 3.1673211793269562

Epoch: 6| Step: 1
Training loss: 3.680945309009619
Validation loss: 3.164563903012289

Epoch: 6| Step: 2
Training loss: 3.3785627422031
Validation loss: 3.161781286160491

Epoch: 6| Step: 3
Training loss: 3.205488867886007
Validation loss: 3.1589955892875223

Epoch: 6| Step: 4
Training loss: 3.1417641163358065
Validation loss: 3.156109419609622

Epoch: 6| Step: 5
Training loss: 3.259818724056369
Validation loss: 3.153255363922529

Epoch: 6| Step: 6
Training loss: 3.2440350886844938
Validation loss: 3.1502079556965294

Epoch: 6| Step: 7
Training loss: 3.0551654412507823
Validation loss: 3.147414919344885

Epoch: 6| Step: 8
Training loss: 3.8986686683872303
Validation loss: 3.1448330499420236

Epoch: 6| Step: 9
Training loss: 2.778799713554933
Validation loss: 3.1420189087475014

Epoch: 6| Step: 10
Training loss: 3.3790125130057325
Validation loss: 3.1393619483769104

Epoch: 6| Step: 11
Training loss: 2.7551209712945974
Validation loss: 3.136562991204153

Epoch: 6| Step: 12
Training loss: 2.908048995873753
Validation loss: 3.1338684889825537

Epoch: 6| Step: 13
Training loss: 3.715163480876209
Validation loss: 3.1312793204939227

Epoch: 47| Step: 0
Training loss: 3.4755858003038047
Validation loss: 3.1286550001087696

Epoch: 6| Step: 1
Training loss: 3.35109780386799
Validation loss: 3.125797525999292

Epoch: 6| Step: 2
Training loss: 2.875599342568344
Validation loss: 3.1230265935001102

Epoch: 6| Step: 3
Training loss: 2.8907892953731755
Validation loss: 3.1200464661512646

Epoch: 6| Step: 4
Training loss: 3.2316715164764616
Validation loss: 3.1173864570422536

Epoch: 6| Step: 5
Training loss: 3.52771102328149
Validation loss: 3.11460161150584

Epoch: 6| Step: 6
Training loss: 3.150509590225141
Validation loss: 3.111814746210787

Epoch: 6| Step: 7
Training loss: 2.6761926042441315
Validation loss: 3.1091557334381177

Epoch: 6| Step: 8
Training loss: 3.591969720810537
Validation loss: 3.1065305162305568

Epoch: 6| Step: 9
Training loss: 3.6631900749160393
Validation loss: 3.103977125043412

Epoch: 6| Step: 10
Training loss: 3.4165104310825396
Validation loss: 3.1012673033324214

Epoch: 6| Step: 11
Training loss: 3.459599703526779
Validation loss: 3.0985130225188984

Epoch: 6| Step: 12
Training loss: 3.1598112957780815
Validation loss: 3.095873274273828

Epoch: 6| Step: 13
Training loss: 2.894616253180001
Validation loss: 3.093227483634707

Epoch: 48| Step: 0
Training loss: 3.222241776140302
Validation loss: 3.090618616707603

Epoch: 6| Step: 1
Training loss: 2.937235881213357
Validation loss: 3.0878863912702568

Epoch: 6| Step: 2
Training loss: 3.587265666259909
Validation loss: 3.0853394649170482

Epoch: 6| Step: 3
Training loss: 3.874650385682183
Validation loss: 3.0827367609267893

Epoch: 6| Step: 4
Training loss: 3.4438905441488883
Validation loss: 3.0800755576778363

Epoch: 6| Step: 5
Training loss: 2.5960934634672013
Validation loss: 3.0772979709680413

Epoch: 6| Step: 6
Training loss: 2.854123822932505
Validation loss: 3.0748184181502407

Epoch: 6| Step: 7
Training loss: 2.5192051402931432
Validation loss: 3.072073175215258

Epoch: 6| Step: 8
Training loss: 3.2961494406737546
Validation loss: 3.069711369108369

Epoch: 6| Step: 9
Training loss: 3.459349119232598
Validation loss: 3.0671941890893004

Epoch: 6| Step: 10
Training loss: 3.1080816444857207
Validation loss: 3.0647103254577397

Epoch: 6| Step: 11
Training loss: 3.6088165247473514
Validation loss: 3.062251178208996

Epoch: 6| Step: 12
Training loss: 2.781055915146948
Validation loss: 3.0596258339226003

Epoch: 6| Step: 13
Training loss: 3.4166975872842626
Validation loss: 3.057127957398997

Epoch: 49| Step: 0
Training loss: 3.419724158601517
Validation loss: 3.054630705036338

Epoch: 6| Step: 1
Training loss: 3.2440347947066748
Validation loss: 3.0522891594722843

Epoch: 6| Step: 2
Training loss: 3.2628380962003924
Validation loss: 3.0500492613102614

Epoch: 6| Step: 3
Training loss: 3.3501676489030867
Validation loss: 3.0474266661368197

Epoch: 6| Step: 4
Training loss: 3.210187169973079
Validation loss: 3.044967184490236

Epoch: 6| Step: 5
Training loss: 3.4169205982158437
Validation loss: 3.0427528079468686

Epoch: 6| Step: 6
Training loss: 2.783487941155986
Validation loss: 3.04036694457829

Epoch: 6| Step: 7
Training loss: 2.7071614199741374
Validation loss: 3.0381252540097017

Epoch: 6| Step: 8
Training loss: 3.4579363828756504
Validation loss: 3.035886816523483

Epoch: 6| Step: 9
Training loss: 3.039207317755782
Validation loss: 3.0336757798475236

Epoch: 6| Step: 10
Training loss: 2.4323599980712736
Validation loss: 3.0313166450436544

Epoch: 6| Step: 11
Training loss: 3.4655675637358967
Validation loss: 3.028983550241041

Epoch: 6| Step: 12
Training loss: 3.6357887463863476
Validation loss: 3.0266453747553568

Epoch: 6| Step: 13
Training loss: 2.869589981404478
Validation loss: 3.0241895031235413

Epoch: 50| Step: 0
Training loss: 3.391175678027909
Validation loss: 3.0217444438010603

Epoch: 6| Step: 1
Training loss: 3.0561359220405784
Validation loss: 3.0191672542893286

Epoch: 6| Step: 2
Training loss: 2.5228018417709737
Validation loss: 3.0168243948305964

Epoch: 6| Step: 3
Training loss: 3.393544711091451
Validation loss: 3.014573304204245

Epoch: 6| Step: 4
Training loss: 3.1088395927719437
Validation loss: 3.012285086113661

Epoch: 6| Step: 5
Training loss: 2.895156195714319
Validation loss: 3.0100952733656725

Epoch: 6| Step: 6
Training loss: 2.7315039684665545
Validation loss: 3.0077532609662905

Epoch: 6| Step: 7
Training loss: 3.5573849011886636
Validation loss: 3.005612263014288

Epoch: 6| Step: 8
Training loss: 3.68474307692799
Validation loss: 3.003395715129853

Epoch: 6| Step: 9
Training loss: 3.296122098892592
Validation loss: 3.0010692095107774

Epoch: 6| Step: 10
Training loss: 3.001717393761731
Validation loss: 2.9986162438190918

Epoch: 6| Step: 11
Training loss: 3.5264349323231783
Validation loss: 2.99623751471545

Epoch: 6| Step: 12
Training loss: 2.8500966105901155
Validation loss: 2.993787027553438

Epoch: 6| Step: 13
Training loss: 2.829231509409912
Validation loss: 2.9912420626772933

Epoch: 51| Step: 0
Training loss: 3.4181026759476247
Validation loss: 2.9890695234483067

Epoch: 6| Step: 1
Training loss: 3.4238749194605997
Validation loss: 2.986745415576092

Epoch: 6| Step: 2
Training loss: 2.8308303286184904
Validation loss: 2.984526252575306

Epoch: 6| Step: 3
Training loss: 3.2945409530847747
Validation loss: 2.982349833726103

Epoch: 6| Step: 4
Training loss: 2.9367275439854033
Validation loss: 2.980311451665382

Epoch: 6| Step: 5
Training loss: 2.66485163391969
Validation loss: 2.978278198784981

Epoch: 6| Step: 6
Training loss: 3.189923879498479
Validation loss: 2.976245933379335

Epoch: 6| Step: 7
Training loss: 3.3225175065726793
Validation loss: 2.974338398089855

Epoch: 6| Step: 8
Training loss: 3.177053949605838
Validation loss: 2.97212360838425

Epoch: 6| Step: 9
Training loss: 3.5120871141704293
Validation loss: 2.970021654792901

Epoch: 6| Step: 10
Training loss: 3.3336874455868357
Validation loss: 2.967727967064876

Epoch: 6| Step: 11
Training loss: 2.3756517218793274
Validation loss: 2.9657298067879214

Epoch: 6| Step: 12
Training loss: 2.5202809719093153
Validation loss: 2.963740891306253

Epoch: 6| Step: 13
Training loss: 3.364263481943699
Validation loss: 2.96150949500822

Epoch: 52| Step: 0
Training loss: 3.0342513494313352
Validation loss: 2.9592972291034645

Epoch: 6| Step: 1
Training loss: 3.2224474660114497
Validation loss: 2.957093507354063

Epoch: 6| Step: 2
Training loss: 3.012577394623041
Validation loss: 2.954859901803518

Epoch: 6| Step: 3
Training loss: 2.353448662656054
Validation loss: 2.952571891105378

Epoch: 6| Step: 4
Training loss: 3.4612151092721484
Validation loss: 2.950371011474958

Epoch: 6| Step: 5
Training loss: 3.118726001715973
Validation loss: 2.9482423896701033

Epoch: 6| Step: 6
Training loss: 2.879556445297656
Validation loss: 2.945998472003148

Epoch: 6| Step: 7
Training loss: 2.9566709835647442
Validation loss: 2.9438584682299584

Epoch: 6| Step: 8
Training loss: 3.5720180052317354
Validation loss: 2.941808922077346

Epoch: 6| Step: 9
Training loss: 3.243200084253055
Validation loss: 2.9396708427901586

Epoch: 6| Step: 10
Training loss: 2.9800010704192217
Validation loss: 2.9377617550284887

Epoch: 6| Step: 11
Training loss: 3.3673027709206376
Validation loss: 2.935714909762627

Epoch: 6| Step: 12
Training loss: 2.9032061644542564
Validation loss: 2.9337513589659463

Epoch: 6| Step: 13
Training loss: 2.9556880102219063
Validation loss: 2.9315999888315267

Epoch: 53| Step: 0
Training loss: 2.968823883743451
Validation loss: 2.929692925342199

Epoch: 6| Step: 1
Training loss: 3.067709248687832
Validation loss: 2.9277686587229264

Epoch: 6| Step: 2
Training loss: 2.83082611750852
Validation loss: 2.9259196555552873

Epoch: 6| Step: 3
Training loss: 3.2151736047364143
Validation loss: 2.9239747973228725

Epoch: 6| Step: 4
Training loss: 2.507547810213758
Validation loss: 2.921940903081907

Epoch: 6| Step: 5
Training loss: 3.1870565666969535
Validation loss: 2.920148138595328

Epoch: 6| Step: 6
Training loss: 3.111590798802814
Validation loss: 2.918052130839425

Epoch: 6| Step: 7
Training loss: 2.915638515363403
Validation loss: 2.916069382863799

Epoch: 6| Step: 8
Training loss: 3.292398170281037
Validation loss: 2.914073681575537

Epoch: 6| Step: 9
Training loss: 3.310798351897728
Validation loss: 2.9120961527329143

Epoch: 6| Step: 10
Training loss: 3.0361562134732636
Validation loss: 2.910204135577611

Epoch: 6| Step: 11
Training loss: 3.1571644883996024
Validation loss: 2.908377084339215

Epoch: 6| Step: 12
Training loss: 3.0739052599353327
Validation loss: 2.9064867476970497

Epoch: 6| Step: 13
Training loss: 3.08067874216887
Validation loss: 2.9045936075445753

Epoch: 54| Step: 0
Training loss: 2.8845938784457847
Validation loss: 2.9027324979212463

Epoch: 6| Step: 1
Training loss: 3.2728635152721552
Validation loss: 2.9008887825385585

Epoch: 6| Step: 2
Training loss: 3.1224730383729833
Validation loss: 2.8991093709411433

Epoch: 6| Step: 3
Training loss: 3.0280027004617924
Validation loss: 2.897197146097396

Epoch: 6| Step: 4
Training loss: 2.4476753494681525
Validation loss: 2.895242155002464

Epoch: 6| Step: 5
Training loss: 2.309928598497683
Validation loss: 2.893628019394342

Epoch: 6| Step: 6
Training loss: 2.607812196469846
Validation loss: 2.8919427978052026

Epoch: 6| Step: 7
Training loss: 3.063192483889867
Validation loss: 2.890382086367491

Epoch: 6| Step: 8
Training loss: 2.925674986596643
Validation loss: 2.888741149140481

Epoch: 6| Step: 9
Training loss: 3.291040980753584
Validation loss: 2.8870297592623624

Epoch: 6| Step: 10
Training loss: 3.1850049594618963
Validation loss: 2.885486551441508

Epoch: 6| Step: 11
Training loss: 3.1708635493345554
Validation loss: 2.88388645254403

Epoch: 6| Step: 12
Training loss: 3.6182514380897137
Validation loss: 2.882053568253723

Epoch: 6| Step: 13
Training loss: 3.268708885619927
Validation loss: 2.880203817316876

Epoch: 55| Step: 0
Training loss: 2.9897887971212285
Validation loss: 2.87836385281862

Epoch: 6| Step: 1
Training loss: 2.9277749290991317
Validation loss: 2.8764430032139563

Epoch: 6| Step: 2
Training loss: 2.8271209451923203
Validation loss: 2.874391809347855

Epoch: 6| Step: 3
Training loss: 3.276713696048836
Validation loss: 2.8725778493798355

Epoch: 6| Step: 4
Training loss: 2.7680866040865464
Validation loss: 2.8709669158669815

Epoch: 6| Step: 5
Training loss: 2.934618571514588
Validation loss: 2.869155970307982

Epoch: 6| Step: 6
Training loss: 3.030729426093166
Validation loss: 2.867347608872069

Epoch: 6| Step: 7
Training loss: 3.9611405841598235
Validation loss: 2.8655664641136647

Epoch: 6| Step: 8
Training loss: 3.51324517976119
Validation loss: 2.8636939361559217

Epoch: 6| Step: 9
Training loss: 2.2976162291838222
Validation loss: 2.86167319238356

Epoch: 6| Step: 10
Training loss: 2.787188843607993
Validation loss: 2.8597862489892205

Epoch: 6| Step: 11
Training loss: 2.634539301082634
Validation loss: 2.857727980019985

Epoch: 6| Step: 12
Training loss: 2.65471856344369
Validation loss: 2.856069659014918

Epoch: 6| Step: 13
Training loss: 3.1821300675754554
Validation loss: 2.854460336840493

Epoch: 56| Step: 0
Training loss: 3.3573066909142977
Validation loss: 2.8527900178822736

Epoch: 6| Step: 1
Training loss: 2.8801550052573703
Validation loss: 2.8511078493861612

Epoch: 6| Step: 2
Training loss: 3.0287447929888596
Validation loss: 2.8493496744032116

Epoch: 6| Step: 3
Training loss: 3.5838183289192083
Validation loss: 2.8475408334458487

Epoch: 6| Step: 4
Training loss: 2.8932971047918117
Validation loss: 2.8457421391975712

Epoch: 6| Step: 5
Training loss: 2.9614360460070457
Validation loss: 2.8440465388248177

Epoch: 6| Step: 6
Training loss: 3.0434286335636678
Validation loss: 2.842141727178893

Epoch: 6| Step: 7
Training loss: 3.106046802774844
Validation loss: 2.8405161765068314

Epoch: 6| Step: 8
Training loss: 2.886495083414685
Validation loss: 2.8389922924664948

Epoch: 6| Step: 9
Training loss: 2.647533161074523
Validation loss: 2.8371882487265014

Epoch: 6| Step: 10
Training loss: 2.914050391123468
Validation loss: 2.8356108954672097

Epoch: 6| Step: 11
Training loss: 2.493623039053994
Validation loss: 2.834047751021494

Epoch: 6| Step: 12
Training loss: 3.0253480695239783
Validation loss: 2.8325785912578065

Epoch: 6| Step: 13
Training loss: 2.8363125976002985
Validation loss: 2.831193232581243

Epoch: 57| Step: 0
Training loss: 3.5755021922974715
Validation loss: 2.829650411322402

Epoch: 6| Step: 1
Training loss: 3.386350407088706
Validation loss: 2.828140736460593

Epoch: 6| Step: 2
Training loss: 2.76475390492819
Validation loss: 2.826673651640137

Epoch: 6| Step: 3
Training loss: 2.934260103456462
Validation loss: 2.825054433742687

Epoch: 6| Step: 4
Training loss: 2.0307057752009694
Validation loss: 2.823659740399725

Epoch: 6| Step: 5
Training loss: 2.8616767332432813
Validation loss: 2.822322238587489

Epoch: 6| Step: 6
Training loss: 3.278345766443111
Validation loss: 2.8209814967166493

Epoch: 6| Step: 7
Training loss: 2.7899889863046363
Validation loss: 2.8196958535221555

Epoch: 6| Step: 8
Training loss: 2.3192215226713304
Validation loss: 2.818215715250148

Epoch: 6| Step: 9
Training loss: 3.249847408527197
Validation loss: 2.816791100734812

Epoch: 6| Step: 10
Training loss: 2.8605180967332267
Validation loss: 2.815524206075622

Epoch: 6| Step: 11
Training loss: 2.7768871076836343
Validation loss: 2.8142607087280074

Epoch: 6| Step: 12
Training loss: 3.0754378154423527
Validation loss: 2.8129687024683165

Epoch: 6| Step: 13
Training loss: 3.20716045458557
Validation loss: 2.8115449343432912

Epoch: 58| Step: 0
Training loss: 2.706959556962347
Validation loss: 2.8100683650143248

Epoch: 6| Step: 1
Training loss: 2.5367415398648094
Validation loss: 2.8085862373177295

Epoch: 6| Step: 2
Training loss: 3.0906340966317405
Validation loss: 2.8071955922141174

Epoch: 6| Step: 3
Training loss: 2.9207418763938224
Validation loss: 2.8058374114347284

Epoch: 6| Step: 4
Training loss: 3.297244661407117
Validation loss: 2.80466511468623

Epoch: 6| Step: 5
Training loss: 3.025729471320621
Validation loss: 2.8030904971196198

Epoch: 6| Step: 6
Training loss: 2.838419855053084
Validation loss: 2.801663340086799

Epoch: 6| Step: 7
Training loss: 2.9404142817078154
Validation loss: 2.800267156843949

Epoch: 6| Step: 8
Training loss: 2.7187322857159075
Validation loss: 2.7987020197497188

Epoch: 6| Step: 9
Training loss: 2.8825220308016104
Validation loss: 2.7972413006102133

Epoch: 6| Step: 10
Training loss: 2.674944982230286
Validation loss: 2.7957100173504927

Epoch: 6| Step: 11
Training loss: 3.313711844404118
Validation loss: 2.794204459893761

Epoch: 6| Step: 12
Training loss: 3.216423453061916
Validation loss: 2.7927015768100083

Epoch: 6| Step: 13
Training loss: 2.9279907195772776
Validation loss: 2.791398851634144

Epoch: 59| Step: 0
Training loss: 3.3636440387141513
Validation loss: 2.7899440793274937

Epoch: 6| Step: 1
Training loss: 3.1111626015292573
Validation loss: 2.788693001969854

Epoch: 6| Step: 2
Training loss: 2.2801027940700127
Validation loss: 2.7870530156418796

Epoch: 6| Step: 3
Training loss: 2.7888972556692444
Validation loss: 2.7858229628756073

Epoch: 6| Step: 4
Training loss: 2.9423290086974236
Validation loss: 2.7843917503666553

Epoch: 6| Step: 5
Training loss: 2.7725357523918452
Validation loss: 2.783097185940654

Epoch: 6| Step: 6
Training loss: 3.013058850381827
Validation loss: 2.7815623018751627

Epoch: 6| Step: 7
Training loss: 2.9616596881166704
Validation loss: 2.780281984266734

Epoch: 6| Step: 8
Training loss: 2.7985063622126147
Validation loss: 2.7788027880218156

Epoch: 6| Step: 9
Training loss: 2.945555821089427
Validation loss: 2.777460881806696

Epoch: 6| Step: 10
Training loss: 2.9765343051486175
Validation loss: 2.7761059169717726

Epoch: 6| Step: 11
Training loss: 3.408228588282387
Validation loss: 2.7745668932436316

Epoch: 6| Step: 12
Training loss: 2.78538317511621
Validation loss: 2.773041774832655

Epoch: 6| Step: 13
Training loss: 2.6231943914157467
Validation loss: 2.7717621377118524

Epoch: 60| Step: 0
Training loss: 3.0020190438334287
Validation loss: 2.7707329829885867

Epoch: 6| Step: 1
Training loss: 2.7729075610562797
Validation loss: 2.7694180729549025

Epoch: 6| Step: 2
Training loss: 2.843299578533035
Validation loss: 2.768350741473114

Epoch: 6| Step: 3
Training loss: 2.954284117551458
Validation loss: 2.7674526203192484

Epoch: 6| Step: 4
Training loss: 2.8531636798488775
Validation loss: 2.766069143088475

Epoch: 6| Step: 5
Training loss: 2.9943342749673323
Validation loss: 2.765104887883149

Epoch: 6| Step: 6
Training loss: 3.3310562621386635
Validation loss: 2.763969414356374

Epoch: 6| Step: 7
Training loss: 2.9568954698639835
Validation loss: 2.7627223815706543

Epoch: 6| Step: 8
Training loss: 3.033844771254676
Validation loss: 2.761281152828377

Epoch: 6| Step: 9
Training loss: 2.4901420785592
Validation loss: 2.7600122887342424

Epoch: 6| Step: 10
Training loss: 3.0459856349233134
Validation loss: 2.7588539642531713

Epoch: 6| Step: 11
Training loss: 2.5296116931246906
Validation loss: 2.757676421096072

Epoch: 6| Step: 12
Training loss: 2.7570391643234378
Validation loss: 2.756480369830569

Epoch: 6| Step: 13
Training loss: 3.010102269916091
Validation loss: 2.755238297893841

Epoch: 61| Step: 0
Training loss: 3.0568214241157605
Validation loss: 2.7542298183232106

Epoch: 6| Step: 1
Training loss: 3.126236327704634
Validation loss: 2.7528986681575027

Epoch: 6| Step: 2
Training loss: 2.844247963033414
Validation loss: 2.751771082022453

Epoch: 6| Step: 3
Training loss: 3.021293412174046
Validation loss: 2.7505471956713334

Epoch: 6| Step: 4
Training loss: 3.0169870729811152
Validation loss: 2.749394321210443

Epoch: 6| Step: 5
Training loss: 2.160707924122999
Validation loss: 2.7482627959151165

Epoch: 6| Step: 6
Training loss: 2.496841915517766
Validation loss: 2.747198006737826

Epoch: 6| Step: 7
Training loss: 2.747502146226289
Validation loss: 2.746099436768983

Epoch: 6| Step: 8
Training loss: 3.3047587790591546
Validation loss: 2.7449801897215402

Epoch: 6| Step: 9
Training loss: 3.43251744609714
Validation loss: 2.7438602544114246

Epoch: 6| Step: 10
Training loss: 2.598671529740229
Validation loss: 2.74251975340729

Epoch: 6| Step: 11
Training loss: 2.742594370857025
Validation loss: 2.7413559655453232

Epoch: 6| Step: 12
Training loss: 2.736142181461046
Validation loss: 2.740326774491256

Epoch: 6| Step: 13
Training loss: 2.9158874197369276
Validation loss: 2.7393282540705104

Epoch: 62| Step: 0
Training loss: 3.492446650846479
Validation loss: 2.738148960431578

Epoch: 6| Step: 1
Training loss: 2.6325495104648704
Validation loss: 2.7370287560720192

Epoch: 6| Step: 2
Training loss: 2.8437885659086497
Validation loss: 2.735944853140439

Epoch: 6| Step: 3
Training loss: 3.0161897594951155
Validation loss: 2.734757518352177

Epoch: 6| Step: 4
Training loss: 3.552287270218822
Validation loss: 2.7336496680857287

Epoch: 6| Step: 5
Training loss: 2.60915643381967
Validation loss: 2.732550559150554

Epoch: 6| Step: 6
Training loss: 2.763153696176499
Validation loss: 2.731335401909327

Epoch: 6| Step: 7
Training loss: 2.692175856181518
Validation loss: 2.7302630942358164

Epoch: 6| Step: 8
Training loss: 2.3828587261781466
Validation loss: 2.7293231327156358

Epoch: 6| Step: 9
Training loss: 3.1680614678941237
Validation loss: 2.728200644441753

Epoch: 6| Step: 10
Training loss: 2.279487242344799
Validation loss: 2.727202740166204

Epoch: 6| Step: 11
Training loss: 2.6051609023295215
Validation loss: 2.726147114501487

Epoch: 6| Step: 12
Training loss: 3.000349978060014
Validation loss: 2.724956327199213

Epoch: 6| Step: 13
Training loss: 2.876909865541617
Validation loss: 2.724026408660786

Epoch: 63| Step: 0
Training loss: 2.9979164517640937
Validation loss: 2.7228998835035974

Epoch: 6| Step: 1
Training loss: 2.8029381867315046
Validation loss: 2.7219957584027594

Epoch: 6| Step: 2
Training loss: 2.876513870383522
Validation loss: 2.7208785278710566

Epoch: 6| Step: 3
Training loss: 2.6306930749975543
Validation loss: 2.7198055746676686

Epoch: 6| Step: 4
Training loss: 2.6438981035020355
Validation loss: 2.7187450306580243

Epoch: 6| Step: 5
Training loss: 3.100805387165126
Validation loss: 2.7177001416887197

Epoch: 6| Step: 6
Training loss: 2.566560366109576
Validation loss: 2.7165094694827605

Epoch: 6| Step: 7
Training loss: 2.694789846857373
Validation loss: 2.715416746710725

Epoch: 6| Step: 8
Training loss: 3.0772232826207975
Validation loss: 2.7143396289150767

Epoch: 6| Step: 9
Training loss: 2.188121816267254
Validation loss: 2.713374329799298

Epoch: 6| Step: 10
Training loss: 2.964477838143547
Validation loss: 2.7123462193929044

Epoch: 6| Step: 11
Training loss: 3.303462240999579
Validation loss: 2.711407359627566

Epoch: 6| Step: 12
Training loss: 3.14292330176833
Validation loss: 2.7105238247994614

Epoch: 6| Step: 13
Training loss: 2.8423899657626612
Validation loss: 2.709688967325773

Epoch: 64| Step: 0
Training loss: 2.9767713898979284
Validation loss: 2.708692282340647

Epoch: 6| Step: 1
Training loss: 2.8649697522868465
Validation loss: 2.707773845299118

Epoch: 6| Step: 2
Training loss: 2.6176112500935296
Validation loss: 2.706827175270155

Epoch: 6| Step: 3
Training loss: 2.8359178274433887
Validation loss: 2.705818994748638

Epoch: 6| Step: 4
Training loss: 2.6377720516245877
Validation loss: 2.7049215296694116

Epoch: 6| Step: 5
Training loss: 2.855256830745536
Validation loss: 2.7039977779656748

Epoch: 6| Step: 6
Training loss: 3.065306175832868
Validation loss: 2.703000633598138

Epoch: 6| Step: 7
Training loss: 2.5143151516089044
Validation loss: 2.7020018932703906

Epoch: 6| Step: 8
Training loss: 2.8472794648492354
Validation loss: 2.70096878461467

Epoch: 6| Step: 9
Training loss: 2.964577402809057
Validation loss: 2.7000556380814738

Epoch: 6| Step: 10
Training loss: 3.0183965566899094
Validation loss: 2.699190999912942

Epoch: 6| Step: 11
Training loss: 2.929470695102922
Validation loss: 2.698400628317134

Epoch: 6| Step: 12
Training loss: 2.6997092832244407
Validation loss: 2.697703162819339

Epoch: 6| Step: 13
Training loss: 2.9326971845357783
Validation loss: 2.696622579879852

Epoch: 65| Step: 0
Training loss: 2.7796652918974343
Validation loss: 2.6957359828990795

Epoch: 6| Step: 1
Training loss: 2.9610444303745838
Validation loss: 2.6949496259917924

Epoch: 6| Step: 2
Training loss: 2.7386745110628183
Validation loss: 2.694195767579893

Epoch: 6| Step: 3
Training loss: 2.581906406541235
Validation loss: 2.693205137679839

Epoch: 6| Step: 4
Training loss: 2.938694163335157
Validation loss: 2.6925214829291813

Epoch: 6| Step: 5
Training loss: 2.638252049838871
Validation loss: 2.6914707982591364

Epoch: 6| Step: 6
Training loss: 2.9455069318387714
Validation loss: 2.6908891879707846

Epoch: 6| Step: 7
Training loss: 2.990245378051686
Validation loss: 2.690129834200678

Epoch: 6| Step: 8
Training loss: 2.671107042384985
Validation loss: 2.689287005548246

Epoch: 6| Step: 9
Training loss: 2.8957105285805125
Validation loss: 2.6886551023247662

Epoch: 6| Step: 10
Training loss: 2.976305372291025
Validation loss: 2.6878418520184546

Epoch: 6| Step: 11
Training loss: 2.5458892599685945
Validation loss: 2.6867498933082126

Epoch: 6| Step: 12
Training loss: 3.143663142011156
Validation loss: 2.685544618547821

Epoch: 6| Step: 13
Training loss: 2.7597625149265914
Validation loss: 2.685073585188608

Epoch: 66| Step: 0
Training loss: 3.1927019941672556
Validation loss: 2.6842391909734324

Epoch: 6| Step: 1
Training loss: 2.941662051563767
Validation loss: 2.683386708157199

Epoch: 6| Step: 2
Training loss: 2.691261675180783
Validation loss: 2.6826391248126584

Epoch: 6| Step: 3
Training loss: 2.4485756061605435
Validation loss: 2.6817210704705485

Epoch: 6| Step: 4
Training loss: 2.5082517815531014
Validation loss: 2.680823986885807

Epoch: 6| Step: 5
Training loss: 1.993539030100106
Validation loss: 2.679893344873003

Epoch: 6| Step: 6
Training loss: 2.9531140201102097
Validation loss: 2.678967259541959

Epoch: 6| Step: 7
Training loss: 2.549233310107247
Validation loss: 2.6782134128667217

Epoch: 6| Step: 8
Training loss: 3.514262295577366
Validation loss: 2.677413375835214

Epoch: 6| Step: 9
Training loss: 3.2636350564574896
Validation loss: 2.6764447579928268

Epoch: 6| Step: 10
Training loss: 2.6481679593550314
Validation loss: 2.675493092114946

Epoch: 6| Step: 11
Training loss: 2.806146183939755
Validation loss: 2.6747872764166507

Epoch: 6| Step: 12
Training loss: 2.8280803192149886
Validation loss: 2.6738804360904322

Epoch: 6| Step: 13
Training loss: 2.8076274626170674
Validation loss: 2.673135723990061

Epoch: 67| Step: 0
Training loss: 3.136801446606031
Validation loss: 2.6723455866093033

Epoch: 6| Step: 1
Training loss: 2.628158122794023
Validation loss: 2.6716314877791665

Epoch: 6| Step: 2
Training loss: 2.7231360824040753
Validation loss: 2.6710023254237782

Epoch: 6| Step: 3
Training loss: 2.7506072500982786
Validation loss: 2.6702967810498315

Epoch: 6| Step: 4
Training loss: 2.149444898759383
Validation loss: 2.669654012329591

Epoch: 6| Step: 5
Training loss: 2.87771428560629
Validation loss: 2.6688894356029937

Epoch: 6| Step: 6
Training loss: 3.0619665187248524
Validation loss: 2.668261130803768

Epoch: 6| Step: 7
Training loss: 2.803734832736253
Validation loss: 2.66749272863606

Epoch: 6| Step: 8
Training loss: 2.533119547339462
Validation loss: 2.6665688486834696

Epoch: 6| Step: 9
Training loss: 2.144660542799618
Validation loss: 2.665869896786947

Epoch: 6| Step: 10
Training loss: 2.8225883114618355
Validation loss: 2.6652836392101698

Epoch: 6| Step: 11
Training loss: 3.154072227391216
Validation loss: 2.6645130809344253

Epoch: 6| Step: 12
Training loss: 3.0119996094519776
Validation loss: 2.6637084815210126

Epoch: 6| Step: 13
Training loss: 3.2430465846966636
Validation loss: 2.6630418748407916

Epoch: 68| Step: 0
Training loss: 2.859020106903708
Validation loss: 2.6621402282494233

Epoch: 6| Step: 1
Training loss: 3.2243115422155855
Validation loss: 2.661529306160935

Epoch: 6| Step: 2
Training loss: 2.7576692452114533
Validation loss: 2.6608424858352406

Epoch: 6| Step: 3
Training loss: 2.813989372086942
Validation loss: 2.6600817848721223

Epoch: 6| Step: 4
Training loss: 2.886802826974612
Validation loss: 2.6592694567525963

Epoch: 6| Step: 5
Training loss: 2.755580614943366
Validation loss: 2.6584772383943696

Epoch: 6| Step: 6
Training loss: 2.7064537764512777
Validation loss: 2.657660405320235

Epoch: 6| Step: 7
Training loss: 3.0020226971240325
Validation loss: 2.657001807836631

Epoch: 6| Step: 8
Training loss: 2.5177489608203425
Validation loss: 2.656011772692683

Epoch: 6| Step: 9
Training loss: 3.264130318732832
Validation loss: 2.6550701288467007

Epoch: 6| Step: 10
Training loss: 2.60151796045066
Validation loss: 2.6540034498955527

Epoch: 6| Step: 11
Training loss: 2.3557212782789647
Validation loss: 2.65388789147664

Epoch: 6| Step: 12
Training loss: 2.9155739145004587
Validation loss: 2.653253922552089

Epoch: 6| Step: 13
Training loss: 2.329713011000077
Validation loss: 2.652616274301902

Epoch: 69| Step: 0
Training loss: 2.5650549456267937
Validation loss: 2.6520085148672248

Epoch: 6| Step: 1
Training loss: 3.0656521203944207
Validation loss: 2.6511866162037685

Epoch: 6| Step: 2
Training loss: 2.73003361062959
Validation loss: 2.650544355371413

Epoch: 6| Step: 3
Training loss: 2.5799634447391275
Validation loss: 2.6494133425865223

Epoch: 6| Step: 4
Training loss: 2.509160995384082
Validation loss: 2.6492503971364623

Epoch: 6| Step: 5
Training loss: 2.642870067137706
Validation loss: 2.6471732243685224

Epoch: 6| Step: 6
Training loss: 2.878047157585188
Validation loss: 2.6455467899981393

Epoch: 6| Step: 7
Training loss: 2.8730483687219945
Validation loss: 2.6532709357897595

Epoch: 6| Step: 8
Training loss: 2.8491334367368673
Validation loss: 2.6484129087793695

Epoch: 6| Step: 9
Training loss: 2.7307075537952152
Validation loss: 2.64289060532191

Epoch: 6| Step: 10
Training loss: 3.3577635692725285
Validation loss: 2.6603804842510566

Epoch: 6| Step: 11
Training loss: 2.5758831102376174
Validation loss: 2.6430213708738823

Epoch: 6| Step: 12
Training loss: 3.1570060504303146
Validation loss: 2.6447624131806347

Epoch: 6| Step: 13
Training loss: 2.3700653812387613
Validation loss: 2.651804251619042

Epoch: 70| Step: 0
Training loss: 2.9092496752763766
Validation loss: 2.661483933735629

Epoch: 6| Step: 1
Training loss: 2.8936323038969984
Validation loss: 2.6495042451141937

Epoch: 6| Step: 2
Training loss: 2.820794146297048
Validation loss: 2.649193009874231

Epoch: 6| Step: 3
Training loss: 2.7922429775710205
Validation loss: 2.6439961239934955

Epoch: 6| Step: 4
Training loss: 3.465890066262347
Validation loss: 2.6422205511786023

Epoch: 6| Step: 5
Training loss: 2.975998071536598
Validation loss: 2.640355775490295

Epoch: 6| Step: 6
Training loss: 2.7653630881564863
Validation loss: 2.6396499729751826

Epoch: 6| Step: 7
Training loss: 3.09048443697356
Validation loss: 2.6383087111589494

Epoch: 6| Step: 8
Training loss: 2.999643463565012
Validation loss: 2.637900261541497

Epoch: 6| Step: 9
Training loss: 2.5064070616711813
Validation loss: 2.643897727764856

Epoch: 6| Step: 10
Training loss: 2.103957162631288
Validation loss: 2.6449372033042318

Epoch: 6| Step: 11
Training loss: 2.5381837233771996
Validation loss: 2.654732828125615

Epoch: 6| Step: 12
Training loss: 2.505035859725026
Validation loss: 2.648068292589989

Epoch: 6| Step: 13
Training loss: 2.3787635296884346
Validation loss: 2.637248994234087

Epoch: 71| Step: 0
Training loss: 3.0264213879665705
Validation loss: 2.6434275034389154

Epoch: 6| Step: 1
Training loss: 2.21303520841382
Validation loss: 2.650146233224645

Epoch: 6| Step: 2
Training loss: 3.4782642100152272
Validation loss: 2.6640130688210224

Epoch: 6| Step: 3
Training loss: 2.6774391106129825
Validation loss: 2.647915784073829

Epoch: 6| Step: 4
Training loss: 2.291632761848949
Validation loss: 2.6403560238095056

Epoch: 6| Step: 5
Training loss: 3.2088591074625588
Validation loss: 2.6354287842081203

Epoch: 6| Step: 6
Training loss: 2.9322905102869243
Validation loss: 2.635386264510069

Epoch: 6| Step: 7
Training loss: 2.51532644075807
Validation loss: 2.636746479406659

Epoch: 6| Step: 8
Training loss: 2.746630945744991
Validation loss: 2.6407893278316164

Epoch: 6| Step: 9
Training loss: 2.9386078389066803
Validation loss: 2.6385529493915714

Epoch: 6| Step: 10
Training loss: 2.699216365123087
Validation loss: 2.6322675191850777

Epoch: 6| Step: 11
Training loss: 2.4830099710301914
Validation loss: 2.6303832999975896

Epoch: 6| Step: 12
Training loss: 3.2533194389463467
Validation loss: 2.6296163868558224

Epoch: 6| Step: 13
Training loss: 2.10976208561341
Validation loss: 2.625734453541898

Epoch: 72| Step: 0
Training loss: 2.834849755882617
Validation loss: 2.6255509388736376

Epoch: 6| Step: 1
Training loss: 2.4699294737349504
Validation loss: 2.6203036910750455

Epoch: 6| Step: 2
Training loss: 2.1181065440337656
Validation loss: 2.621941510381048

Epoch: 6| Step: 3
Training loss: 2.8851003278347815
Validation loss: 2.618975007095123

Epoch: 6| Step: 4
Training loss: 3.252270858867834
Validation loss: 2.617249445395648

Epoch: 6| Step: 5
Training loss: 2.760899445164089
Validation loss: 2.618617700407731

Epoch: 6| Step: 6
Training loss: 2.611123601283869
Validation loss: 2.617987909856885

Epoch: 6| Step: 7
Training loss: 2.583281936954598
Validation loss: 2.617034376229355

Epoch: 6| Step: 8
Training loss: 2.7285422758686355
Validation loss: 2.6167705602329243

Epoch: 6| Step: 9
Training loss: 2.7189823796724464
Validation loss: 2.6166784749908634

Epoch: 6| Step: 10
Training loss: 2.2955597725483083
Validation loss: 2.6157563960814376

Epoch: 6| Step: 11
Training loss: 2.663097038847415
Validation loss: 2.6154517495808207

Epoch: 6| Step: 12
Training loss: 3.2032845806284818
Validation loss: 2.6155663930752504

Epoch: 6| Step: 13
Training loss: 3.236088543014165
Validation loss: 2.615354239404639

Epoch: 73| Step: 0
Training loss: 2.874981092307901
Validation loss: 2.616539202053773

Epoch: 6| Step: 1
Training loss: 2.7474438318094427
Validation loss: 2.6153953983191043

Epoch: 6| Step: 2
Training loss: 2.8544208571206577
Validation loss: 2.616204892453278

Epoch: 6| Step: 3
Training loss: 2.596247929446883
Validation loss: 2.616544152892601

Epoch: 6| Step: 4
Training loss: 2.8142744612520674
Validation loss: 2.612654051429108

Epoch: 6| Step: 5
Training loss: 2.536777818260549
Validation loss: 2.613990752000704

Epoch: 6| Step: 6
Training loss: 2.807772414187198
Validation loss: 2.6149889541426723

Epoch: 6| Step: 7
Training loss: 2.4785192803730927
Validation loss: 2.6168583904984697

Epoch: 6| Step: 8
Training loss: 2.774241672035513
Validation loss: 2.6159840412197517

Epoch: 6| Step: 9
Training loss: 3.3110950297477886
Validation loss: 2.61714479022501

Epoch: 6| Step: 10
Training loss: 2.273842896697101
Validation loss: 2.61713933947837

Epoch: 6| Step: 11
Training loss: 2.9879956077737457
Validation loss: 2.617091193253909

Epoch: 6| Step: 12
Training loss: 2.4954617316541623
Validation loss: 2.6177815384703766

Epoch: 6| Step: 13
Training loss: 2.909866052277958
Validation loss: 2.616423173578021

Epoch: 74| Step: 0
Training loss: 2.2786333937532475
Validation loss: 2.6153002258929248

Epoch: 6| Step: 1
Training loss: 2.6512576591672428
Validation loss: 2.613298173744131

Epoch: 6| Step: 2
Training loss: 2.7350400279461677
Validation loss: 2.612547645560262

Epoch: 6| Step: 3
Training loss: 2.75130379720846
Validation loss: 2.6114945169647283

Epoch: 6| Step: 4
Training loss: 2.7269087519667274
Validation loss: 2.610980851281305

Epoch: 6| Step: 5
Training loss: 3.127083960898834
Validation loss: 2.6103455495521297

Epoch: 6| Step: 6
Training loss: 2.8586439855456276
Validation loss: 2.610100970671951

Epoch: 6| Step: 7
Training loss: 2.9642634169352204
Validation loss: 2.6097474127498805

Epoch: 6| Step: 8
Training loss: 3.072121279090782
Validation loss: 2.608669520661297

Epoch: 6| Step: 9
Training loss: 2.4670782102473554
Validation loss: 2.6084033276202523

Epoch: 6| Step: 10
Training loss: 2.6293946672614865
Validation loss: 2.608176711948859

Epoch: 6| Step: 11
Training loss: 2.643252718715628
Validation loss: 2.6075015395206576

Epoch: 6| Step: 12
Training loss: 2.6217494093376943
Validation loss: 2.6073872348422693

Epoch: 6| Step: 13
Training loss: 2.827904202604407
Validation loss: 2.6064060399267484

Epoch: 75| Step: 0
Training loss: 2.4690050403826262
Validation loss: 2.6054215777243246

Epoch: 6| Step: 1
Training loss: 2.59422564454091
Validation loss: 2.6051855815111065

Epoch: 6| Step: 2
Training loss: 2.8874603268758907
Validation loss: 2.6036227739115105

Epoch: 6| Step: 3
Training loss: 2.605676462567002
Validation loss: 2.602679435756633

Epoch: 6| Step: 4
Training loss: 2.3926545547422546
Validation loss: 2.6022422292026928

Epoch: 6| Step: 5
Training loss: 3.2810323007209217
Validation loss: 2.6016496370708415

Epoch: 6| Step: 6
Training loss: 2.896514336809802
Validation loss: 2.6054344804102856

Epoch: 6| Step: 7
Training loss: 2.4794989184257794
Validation loss: 2.608867039987935

Epoch: 6| Step: 8
Training loss: 2.640698493973096
Validation loss: 2.6150641790747957

Epoch: 6| Step: 9
Training loss: 3.4836331933528935
Validation loss: 2.612192730272228

Epoch: 6| Step: 10
Training loss: 2.599189110997698
Validation loss: 2.6124491295736627

Epoch: 6| Step: 11
Training loss: 2.3140333092681677
Validation loss: 2.601455686283809

Epoch: 6| Step: 12
Training loss: 2.4055022031385045
Validation loss: 2.596237452927748

Epoch: 6| Step: 13
Training loss: 3.1154982499919854
Validation loss: 2.5983051302270095

Epoch: 76| Step: 0
Training loss: 2.3864216471305038
Validation loss: 2.5979780184290866

Epoch: 6| Step: 1
Training loss: 3.007503186459649
Validation loss: 2.5986916221091083

Epoch: 6| Step: 2
Training loss: 2.469561962406153
Validation loss: 2.599405335621324

Epoch: 6| Step: 3
Training loss: 3.1542811532115933
Validation loss: 2.599242480893658

Epoch: 6| Step: 4
Training loss: 2.055790478223996
Validation loss: 2.6000697040995555

Epoch: 6| Step: 5
Training loss: 2.5758550650120995
Validation loss: 2.599936281548293

Epoch: 6| Step: 6
Training loss: 3.1592039882662752
Validation loss: 2.5998885962265574

Epoch: 6| Step: 7
Training loss: 2.6320879474080314
Validation loss: 2.6008860612694766

Epoch: 6| Step: 8
Training loss: 2.4411214677655315
Validation loss: 2.6015625305481263

Epoch: 6| Step: 9
Training loss: 2.9369868378128356
Validation loss: 2.599184188253726

Epoch: 6| Step: 10
Training loss: 2.8523856033267867
Validation loss: 2.5990201424159056

Epoch: 6| Step: 11
Training loss: 2.8325848058141005
Validation loss: 2.5980996272175942

Epoch: 6| Step: 12
Training loss: 2.6687035728543598
Validation loss: 2.5965297923987567

Epoch: 6| Step: 13
Training loss: 2.9008778788948906
Validation loss: 2.5963951013233917

Epoch: 77| Step: 0
Training loss: 2.8613121266617596
Validation loss: 2.595911374049224

Epoch: 6| Step: 1
Training loss: 2.77444104588031
Validation loss: 2.595615711754318

Epoch: 6| Step: 2
Training loss: 2.5703900450166133
Validation loss: 2.5951047522901827

Epoch: 6| Step: 3
Training loss: 2.6202393004646005
Validation loss: 2.594672502445795

Epoch: 6| Step: 4
Training loss: 2.2378195507810523
Validation loss: 2.5941956225367218

Epoch: 6| Step: 5
Training loss: 2.6162475720069436
Validation loss: 2.594037097530343

Epoch: 6| Step: 6
Training loss: 2.559103692175428
Validation loss: 2.5938584791425185

Epoch: 6| Step: 7
Training loss: 2.512649577229029
Validation loss: 2.593276474712655

Epoch: 6| Step: 8
Training loss: 2.990624719378579
Validation loss: 2.5925618939688886

Epoch: 6| Step: 9
Training loss: 2.829228812777225
Validation loss: 2.5912368502837584

Epoch: 6| Step: 10
Training loss: 2.9712345367786748
Validation loss: 2.591077845207027

Epoch: 6| Step: 11
Training loss: 2.913401347165881
Validation loss: 2.5890187540849725

Epoch: 6| Step: 12
Training loss: 2.7964693766294437
Validation loss: 2.5898078160312674

Epoch: 6| Step: 13
Training loss: 2.8572589986901265
Validation loss: 2.587473371924648

Epoch: 78| Step: 0
Training loss: 1.9698946819134293
Validation loss: 2.5871202082644507

Epoch: 6| Step: 1
Training loss: 3.0209739564633593
Validation loss: 2.5846763524321767

Epoch: 6| Step: 2
Training loss: 2.663436323839461
Validation loss: 2.5829421844510096

Epoch: 6| Step: 3
Training loss: 2.7870834552546064
Validation loss: 2.5843483996915473

Epoch: 6| Step: 4
Training loss: 2.826120920519407
Validation loss: 2.5843302177414684

Epoch: 6| Step: 5
Training loss: 3.1595713447813885
Validation loss: 2.5831982259388084

Epoch: 6| Step: 6
Training loss: 2.9223811889201743
Validation loss: 2.5821159221945544

Epoch: 6| Step: 7
Training loss: 2.828440274532358
Validation loss: 2.5795538285587627

Epoch: 6| Step: 8
Training loss: 2.6067142283530695
Validation loss: 2.5786711913785454

Epoch: 6| Step: 9
Training loss: 2.866867671247803
Validation loss: 2.5778473675677684

Epoch: 6| Step: 10
Training loss: 2.668042741813473
Validation loss: 2.5782996224499213

Epoch: 6| Step: 11
Training loss: 2.9418617493635155
Validation loss: 2.581267004749854

Epoch: 6| Step: 12
Training loss: 2.1928882177750735
Validation loss: 2.5807306242835084

Epoch: 6| Step: 13
Training loss: 2.3851934825541408
Validation loss: 2.5801486771645163

Epoch: 79| Step: 0
Training loss: 3.144690164850928
Validation loss: 2.5788247440050207

Epoch: 6| Step: 1
Training loss: 2.525661657530377
Validation loss: 2.5747255512383895

Epoch: 6| Step: 2
Training loss: 3.3115065902420904
Validation loss: 2.5738258968931644

Epoch: 6| Step: 3
Training loss: 2.7453716517042723
Validation loss: 2.5754006836382928

Epoch: 6| Step: 4
Training loss: 3.1684678292527706
Validation loss: 2.5770197339075174

Epoch: 6| Step: 5
Training loss: 2.5525595292072003
Validation loss: 2.577474199863367

Epoch: 6| Step: 6
Training loss: 3.122192342244894
Validation loss: 2.5732220199537807

Epoch: 6| Step: 7
Training loss: 2.208205405314584
Validation loss: 2.5724638155563238

Epoch: 6| Step: 8
Training loss: 2.2877497635696282
Validation loss: 2.571957263890094

Epoch: 6| Step: 9
Training loss: 2.6805920200360327
Validation loss: 2.572253173859782

Epoch: 6| Step: 10
Training loss: 2.282718133771025
Validation loss: 2.57249220668649

Epoch: 6| Step: 11
Training loss: 2.4876746571628163
Validation loss: 2.570432403148561

Epoch: 6| Step: 12
Training loss: 2.6007239104229902
Validation loss: 2.5706225887416814

Epoch: 6| Step: 13
Training loss: 2.591598077665765
Validation loss: 2.5710036750469456

Epoch: 80| Step: 0
Training loss: 2.3592960773935183
Validation loss: 2.571727946555262

Epoch: 6| Step: 1
Training loss: 3.0778771315175577
Validation loss: 2.573710984361522

Epoch: 6| Step: 2
Training loss: 2.0825583987617082
Validation loss: 2.5722427154733483

Epoch: 6| Step: 3
Training loss: 2.8557733250697064
Validation loss: 2.574135948319771

Epoch: 6| Step: 4
Training loss: 2.9695955377417778
Validation loss: 2.579701883517392

Epoch: 6| Step: 5
Training loss: 2.8893657518981892
Validation loss: 2.5820295879225927

Epoch: 6| Step: 6
Training loss: 2.9681691454787202
Validation loss: 2.5836138316634156

Epoch: 6| Step: 7
Training loss: 2.9936709399525374
Validation loss: 2.5829154158509864

Epoch: 6| Step: 8
Training loss: 2.803566456270538
Validation loss: 2.583008474002554

Epoch: 6| Step: 9
Training loss: 2.1068079268903714
Validation loss: 2.5870096033736694

Epoch: 6| Step: 10
Training loss: 2.411039267942872
Validation loss: 2.5847506070672384

Epoch: 6| Step: 11
Training loss: 2.548381336559236
Validation loss: 2.583606249226589

Epoch: 6| Step: 12
Training loss: 2.9262575950996554
Validation loss: 2.582111520909343

Epoch: 6| Step: 13
Training loss: 2.8464553875505287
Validation loss: 2.5789645899017697

Epoch: 81| Step: 0
Training loss: 3.3053661758783437
Validation loss: 2.581339379364938

Epoch: 6| Step: 1
Training loss: 2.7082875957050434
Validation loss: 2.580746945429952

Epoch: 6| Step: 2
Training loss: 2.3973354330057206
Validation loss: 2.580313753375146

Epoch: 6| Step: 3
Training loss: 3.114466193982833
Validation loss: 2.5785187391687945

Epoch: 6| Step: 4
Training loss: 2.608975225650459
Validation loss: 2.576722998831957

Epoch: 6| Step: 5
Training loss: 2.281562992728629
Validation loss: 2.5753456315844625

Epoch: 6| Step: 6
Training loss: 2.803484730512422
Validation loss: 2.5746398797415595

Epoch: 6| Step: 7
Training loss: 2.68749485458946
Validation loss: 2.575327008047622

Epoch: 6| Step: 8
Training loss: 2.5668248222802283
Validation loss: 2.570449067944908

Epoch: 6| Step: 9
Training loss: 2.4082847018320166
Validation loss: 2.572060745101346

Epoch: 6| Step: 10
Training loss: 2.6392765552355195
Validation loss: 2.5733611511874734

Epoch: 6| Step: 11
Training loss: 2.5505972032030186
Validation loss: 2.572432504626698

Epoch: 6| Step: 12
Training loss: 3.1472395896900047
Validation loss: 2.5732802212707475

Epoch: 6| Step: 13
Training loss: 2.5688702557484566
Validation loss: 2.5712846735902217

Epoch: 82| Step: 0
Training loss: 3.074333838280146
Validation loss: 2.566230353719803

Epoch: 6| Step: 1
Training loss: 2.9970609255208975
Validation loss: 2.568022723549974

Epoch: 6| Step: 2
Training loss: 3.0380873500780226
Validation loss: 2.5660185654142764

Epoch: 6| Step: 3
Training loss: 2.3806366538565995
Validation loss: 2.5603266703032204

Epoch: 6| Step: 4
Training loss: 2.5113911511488216
Validation loss: 2.560283640568454

Epoch: 6| Step: 5
Training loss: 2.7231968434688683
Validation loss: 2.5627394773650356

Epoch: 6| Step: 6
Training loss: 2.518018922178694
Validation loss: 2.5652362202122223

Epoch: 6| Step: 7
Training loss: 2.5123986826343723
Validation loss: 2.565269919266775

Epoch: 6| Step: 8
Training loss: 2.850326813815679
Validation loss: 2.5673801194296924

Epoch: 6| Step: 9
Training loss: 2.1245264759923286
Validation loss: 2.568020170412837

Epoch: 6| Step: 10
Training loss: 2.738548711973472
Validation loss: 2.570810240812368

Epoch: 6| Step: 11
Training loss: 2.696918219333857
Validation loss: 2.569426827470567

Epoch: 6| Step: 12
Training loss: 2.6493746469492496
Validation loss: 2.5708690918012644

Epoch: 6| Step: 13
Training loss: 2.9318027845412535
Validation loss: 2.5688309655961215

Epoch: 83| Step: 0
Training loss: 2.3999307066132993
Validation loss: 2.5672669924476637

Epoch: 6| Step: 1
Training loss: 2.980815582293633
Validation loss: 2.567300966664858

Epoch: 6| Step: 2
Training loss: 2.296660328908443
Validation loss: 2.5645032201340046

Epoch: 6| Step: 3
Training loss: 2.844661859888963
Validation loss: 2.5655849154737145

Epoch: 6| Step: 4
Training loss: 2.6888087434970984
Validation loss: 2.564958633451174

Epoch: 6| Step: 5
Training loss: 2.1375108328204573
Validation loss: 2.5713078080056744

Epoch: 6| Step: 6
Training loss: 2.900341467649505
Validation loss: 2.565838089463907

Epoch: 6| Step: 7
Training loss: 3.01933037211831
Validation loss: 2.5607084664132165

Epoch: 6| Step: 8
Training loss: 2.7637607304068426
Validation loss: 2.5620885068905612

Epoch: 6| Step: 9
Training loss: 2.945160960541222
Validation loss: 2.5612061653463356

Epoch: 6| Step: 10
Training loss: 3.027961598998132
Validation loss: 2.5591869025846945

Epoch: 6| Step: 11
Training loss: 2.6662257743983195
Validation loss: 2.556751098266537

Epoch: 6| Step: 12
Training loss: 2.37611182439686
Validation loss: 2.554278015231994

Epoch: 6| Step: 13
Training loss: 2.566101613537023
Validation loss: 2.554686177882359

Epoch: 84| Step: 0
Training loss: 3.144645281317513
Validation loss: 2.5529452263345065

Epoch: 6| Step: 1
Training loss: 2.496543784009909
Validation loss: 2.5522744451057076

Epoch: 6| Step: 2
Training loss: 2.6040304122883353
Validation loss: 2.5562179134379046

Epoch: 6| Step: 3
Training loss: 2.6247993574209687
Validation loss: 2.557439894307072

Epoch: 6| Step: 4
Training loss: 2.6855997864105805
Validation loss: 2.5665688968796876

Epoch: 6| Step: 5
Training loss: 2.2172369297531405
Validation loss: 2.563672053557818

Epoch: 6| Step: 6
Training loss: 2.443357325857204
Validation loss: 2.5615805860595042

Epoch: 6| Step: 7
Training loss: 2.4347056486275673
Validation loss: 2.5617767026503593

Epoch: 6| Step: 8
Training loss: 2.9691907053647157
Validation loss: 2.562859223160859

Epoch: 6| Step: 9
Training loss: 2.500921461041285
Validation loss: 2.5611664628368276

Epoch: 6| Step: 10
Training loss: 2.450335526360001
Validation loss: 2.559344217055519

Epoch: 6| Step: 11
Training loss: 3.085127093944594
Validation loss: 2.558563092463036

Epoch: 6| Step: 12
Training loss: 3.119049816207084
Validation loss: 2.5544759835845086

Epoch: 6| Step: 13
Training loss: 2.8138252526841145
Validation loss: 2.552429173190861

Epoch: 85| Step: 0
Training loss: 3.3935974030585023
Validation loss: 2.5479278494547124

Epoch: 6| Step: 1
Training loss: 2.89676965812083
Validation loss: 2.5506200267241925

Epoch: 6| Step: 2
Training loss: 2.3123753488297987
Validation loss: 2.547551344172232

Epoch: 6| Step: 3
Training loss: 2.4860869453245464
Validation loss: 2.547245802146774

Epoch: 6| Step: 4
Training loss: 2.547103029118057
Validation loss: 2.545813333356832

Epoch: 6| Step: 5
Training loss: 2.6056679530822744
Validation loss: 2.5480679797461754

Epoch: 6| Step: 6
Training loss: 2.8271474255179534
Validation loss: 2.5505955050625637

Epoch: 6| Step: 7
Training loss: 2.47083320124488
Validation loss: 2.547719834824987

Epoch: 6| Step: 8
Training loss: 2.4740549383208106
Validation loss: 2.545050062775123

Epoch: 6| Step: 9
Training loss: 3.124134706863002
Validation loss: 2.5363725547202836

Epoch: 6| Step: 10
Training loss: 2.542874804752299
Validation loss: 2.5385499564061442

Epoch: 6| Step: 11
Training loss: 2.939055984384391
Validation loss: 2.5377638092461985

Epoch: 6| Step: 12
Training loss: 2.1341511643916804
Validation loss: 2.536540385857136

Epoch: 6| Step: 13
Training loss: 2.535941309523527
Validation loss: 2.532876641953508

Epoch: 86| Step: 0
Training loss: 2.5171068459203907
Validation loss: 2.527846241700367

Epoch: 6| Step: 1
Training loss: 2.6156918023806828
Validation loss: 2.5269461726373468

Epoch: 6| Step: 2
Training loss: 2.5797870249412402
Validation loss: 2.526256407953434

Epoch: 6| Step: 3
Training loss: 2.0447376536229664
Validation loss: 2.528796761458006

Epoch: 6| Step: 4
Training loss: 2.7162931895432125
Validation loss: 2.5380362916430377

Epoch: 6| Step: 5
Training loss: 2.8080658608888354
Validation loss: 2.5394859000070737

Epoch: 6| Step: 6
Training loss: 2.345831188609722
Validation loss: 2.5338337431212303

Epoch: 6| Step: 7
Training loss: 2.6334436039431197
Validation loss: 2.5243154756146167

Epoch: 6| Step: 8
Training loss: 2.4998133589693046
Validation loss: 2.5178905497405397

Epoch: 6| Step: 9
Training loss: 3.0449232844067455
Validation loss: 2.5163087725104156

Epoch: 6| Step: 10
Training loss: 3.2250550376276585
Validation loss: 2.519146336372389

Epoch: 6| Step: 11
Training loss: 2.796502882428238
Validation loss: 2.522443057735421

Epoch: 6| Step: 12
Training loss: 2.7693146485071938
Validation loss: 2.5347961264045087

Epoch: 6| Step: 13
Training loss: 2.5580024327139066
Validation loss: 2.5358459130195676

Epoch: 87| Step: 0
Training loss: 2.805484074184512
Validation loss: 2.535356087589127

Epoch: 6| Step: 1
Training loss: 2.193044339227075
Validation loss: 2.5298283513208983

Epoch: 6| Step: 2
Training loss: 2.6424476608246668
Validation loss: 2.527974210752454

Epoch: 6| Step: 3
Training loss: 2.582691287169366
Validation loss: 2.526296816390022

Epoch: 6| Step: 4
Training loss: 2.5014240977155553
Validation loss: 2.5242119576022253

Epoch: 6| Step: 5
Training loss: 2.7283899692008187
Validation loss: 2.518429647918539

Epoch: 6| Step: 6
Training loss: 2.766688514148289
Validation loss: 2.5177058425994114

Epoch: 6| Step: 7
Training loss: 2.509815402594888
Validation loss: 2.5178779480733864

Epoch: 6| Step: 8
Training loss: 2.696522847298613
Validation loss: 2.5192911984925286

Epoch: 6| Step: 9
Training loss: 2.595434354324891
Validation loss: 2.523769061624491

Epoch: 6| Step: 10
Training loss: 2.768945284946568
Validation loss: 2.5267980773600223

Epoch: 6| Step: 11
Training loss: 2.8936267010845564
Validation loss: 2.519992299244735

Epoch: 6| Step: 12
Training loss: 2.3068861996180656
Validation loss: 2.5193533901157497

Epoch: 6| Step: 13
Training loss: 3.1926837731433673
Validation loss: 2.519845025290165

Epoch: 88| Step: 0
Training loss: 2.3948674673788974
Validation loss: 2.519666123045417

Epoch: 6| Step: 1
Training loss: 3.1731868342501666
Validation loss: 2.5216025815520084

Epoch: 6| Step: 2
Training loss: 2.3886870464052135
Validation loss: 2.522646359727204

Epoch: 6| Step: 3
Training loss: 2.8721451890634895
Validation loss: 2.5257358379000325

Epoch: 6| Step: 4
Training loss: 2.806325450129307
Validation loss: 2.529115554024956

Epoch: 6| Step: 5
Training loss: 2.284902183559252
Validation loss: 2.528893476643877

Epoch: 6| Step: 6
Training loss: 2.232783250770633
Validation loss: 2.5279308975453794

Epoch: 6| Step: 7
Training loss: 2.7535704928854736
Validation loss: 2.5261129362664017

Epoch: 6| Step: 8
Training loss: 2.648168769638562
Validation loss: 2.525463412977283

Epoch: 6| Step: 9
Training loss: 3.0521438818297253
Validation loss: 2.5260734529887707

Epoch: 6| Step: 10
Training loss: 2.117784817038907
Validation loss: 2.525054932931539

Epoch: 6| Step: 11
Training loss: 2.735149687971902
Validation loss: 2.523081877444427

Epoch: 6| Step: 12
Training loss: 2.755579057545403
Validation loss: 2.5201290081950902

Epoch: 6| Step: 13
Training loss: 2.8217631912470624
Validation loss: 2.520968383660415

Epoch: 89| Step: 0
Training loss: 2.157432342564684
Validation loss: 2.5169619528059948

Epoch: 6| Step: 1
Training loss: 2.9703411456095865
Validation loss: 2.513501362820654

Epoch: 6| Step: 2
Training loss: 2.8776591069887267
Validation loss: 2.5162407889452596

Epoch: 6| Step: 3
Training loss: 2.685257974517434
Validation loss: 2.5162376147548273

Epoch: 6| Step: 4
Training loss: 2.186623752025566
Validation loss: 2.519832906481482

Epoch: 6| Step: 5
Training loss: 2.367797269436125
Validation loss: 2.51464353097974

Epoch: 6| Step: 6
Training loss: 2.937874952694702
Validation loss: 2.5198287591074147

Epoch: 6| Step: 7
Training loss: 2.8583962688431304
Validation loss: 2.517692821761614

Epoch: 6| Step: 8
Training loss: 3.097142988787112
Validation loss: 2.523013052659776

Epoch: 6| Step: 9
Training loss: 2.393239903694007
Validation loss: 2.523959315529786

Epoch: 6| Step: 10
Training loss: 2.459029944908865
Validation loss: 2.513200495858057

Epoch: 6| Step: 11
Training loss: 2.619546038195937
Validation loss: 2.5103360132792285

Epoch: 6| Step: 12
Training loss: 2.850763412758495
Validation loss: 2.507368165262183

Epoch: 6| Step: 13
Training loss: 2.5943442893272555
Validation loss: 2.511893417114969

Epoch: 90| Step: 0
Training loss: 2.4628406734377393
Validation loss: 2.5181787059084684

Epoch: 6| Step: 1
Training loss: 3.046410158351182
Validation loss: 2.5145033711190647

Epoch: 6| Step: 2
Training loss: 2.9043359503718005
Validation loss: 2.5165244759144274

Epoch: 6| Step: 3
Training loss: 2.837454229985602
Validation loss: 2.51871384562377

Epoch: 6| Step: 4
Training loss: 2.2662155960089043
Validation loss: 2.519965997294961

Epoch: 6| Step: 5
Training loss: 2.416954801636364
Validation loss: 2.5194747563615545

Epoch: 6| Step: 6
Training loss: 2.3243573315762562
Validation loss: 2.515833796648217

Epoch: 6| Step: 7
Training loss: 2.655191367628795
Validation loss: 2.5170775774889047

Epoch: 6| Step: 8
Training loss: 2.509297059251332
Validation loss: 2.5203414994156157

Epoch: 6| Step: 9
Training loss: 2.9429786400442723
Validation loss: 2.5156190765500672

Epoch: 6| Step: 10
Training loss: 2.5894560602838714
Validation loss: 2.5218045804301044

Epoch: 6| Step: 11
Training loss: 2.7375128480095903
Validation loss: 2.5200379170234486

Epoch: 6| Step: 12
Training loss: 2.460684820857327
Validation loss: 2.5168014366072646

Epoch: 6| Step: 13
Training loss: 2.9545570413322264
Validation loss: 2.5173852578828364

Epoch: 91| Step: 0
Training loss: 2.062867334194996
Validation loss: 2.5140643521071513

Epoch: 6| Step: 1
Training loss: 2.618062980319782
Validation loss: 2.5107896667525513

Epoch: 6| Step: 2
Training loss: 2.9237129836004137
Validation loss: 2.511951473325195

Epoch: 6| Step: 3
Training loss: 3.2308554550514246
Validation loss: 2.506690910413189

Epoch: 6| Step: 4
Training loss: 2.601339244713935
Validation loss: 2.5107627303001325

Epoch: 6| Step: 5
Training loss: 1.9595217514446646
Validation loss: 2.5030238143401697

Epoch: 6| Step: 6
Training loss: 2.4668554448584206
Validation loss: 2.5043650507826496

Epoch: 6| Step: 7
Training loss: 2.5574279458792692
Validation loss: 2.5070662135745905

Epoch: 6| Step: 8
Training loss: 2.823819418463805
Validation loss: 2.4998775134280375

Epoch: 6| Step: 9
Training loss: 2.4973899568098115
Validation loss: 2.5079510770322435

Epoch: 6| Step: 10
Training loss: 1.9400397851148232
Validation loss: 2.4998596628854397

Epoch: 6| Step: 11
Training loss: 2.956275188185506
Validation loss: 2.496886714928509

Epoch: 6| Step: 12
Training loss: 2.806645382085391
Validation loss: 2.4988731387776424

Epoch: 6| Step: 13
Training loss: 3.2060059036229083
Validation loss: 2.49758775680982

Epoch: 92| Step: 0
Training loss: 2.6514483866191925
Validation loss: 2.4968605197045783

Epoch: 6| Step: 1
Training loss: 2.424189882539915
Validation loss: 2.5000335214274845

Epoch: 6| Step: 2
Training loss: 3.019765590639795
Validation loss: 2.504294727836041

Epoch: 6| Step: 3
Training loss: 2.6030329767014884
Validation loss: 2.5042068531114534

Epoch: 6| Step: 4
Training loss: 2.5438753964120773
Validation loss: 2.502650588309957

Epoch: 6| Step: 5
Training loss: 2.4933562692141473
Validation loss: 2.5034834752305355

Epoch: 6| Step: 6
Training loss: 2.8220723333463074
Validation loss: 2.5044140313253878

Epoch: 6| Step: 7
Training loss: 2.7289928545943916
Validation loss: 2.5013495299595068

Epoch: 6| Step: 8
Training loss: 2.878790802627125
Validation loss: 2.504377918779592

Epoch: 6| Step: 9
Training loss: 2.7866546751826
Validation loss: 2.5041585349798803

Epoch: 6| Step: 10
Training loss: 2.6536881602876368
Validation loss: 2.5013084166627158

Epoch: 6| Step: 11
Training loss: 2.1497881718456293
Validation loss: 2.5004431013979205

Epoch: 6| Step: 12
Training loss: 2.6401876053475184
Validation loss: 2.499306932384011

Epoch: 6| Step: 13
Training loss: 2.4544926615216975
Validation loss: 2.4994121337177297

Epoch: 93| Step: 0
Training loss: 2.314005078434626
Validation loss: 2.5030047479478563

Epoch: 6| Step: 1
Training loss: 3.016861894166944
Validation loss: 2.5042037112711393

Epoch: 6| Step: 2
Training loss: 2.4013885335760796
Validation loss: 2.5060597094612183

Epoch: 6| Step: 3
Training loss: 2.949975327210779
Validation loss: 2.5079340603245277

Epoch: 6| Step: 4
Training loss: 2.408214114273132
Validation loss: 2.500301136317933

Epoch: 6| Step: 5
Training loss: 2.9281486844109503
Validation loss: 2.5016886888771976

Epoch: 6| Step: 6
Training loss: 2.0688856282102077
Validation loss: 2.501218625923115

Epoch: 6| Step: 7
Training loss: 2.9146277976217534
Validation loss: 2.500329933647662

Epoch: 6| Step: 8
Training loss: 2.8861886287490317
Validation loss: 2.4949536572919557

Epoch: 6| Step: 9
Training loss: 2.9056385996880394
Validation loss: 2.4943947897794874

Epoch: 6| Step: 10
Training loss: 2.700740931537986
Validation loss: 2.4992540200199125

Epoch: 6| Step: 11
Training loss: 2.498056228298068
Validation loss: 2.4993710839432524

Epoch: 6| Step: 12
Training loss: 2.188368597605997
Validation loss: 2.4978003997935994

Epoch: 6| Step: 13
Training loss: 2.3901424544268512
Validation loss: 2.499969609393733

Epoch: 94| Step: 0
Training loss: 2.61981633947647
Validation loss: 2.4970860187989863

Epoch: 6| Step: 1
Training loss: 2.5050967714420835
Validation loss: 2.4964974185923383

Epoch: 6| Step: 2
Training loss: 2.7425213471992795
Validation loss: 2.498656038798417

Epoch: 6| Step: 3
Training loss: 2.7277018180607557
Validation loss: 2.496822921279836

Epoch: 6| Step: 4
Training loss: 2.463163791787574
Validation loss: 2.4907644069303085

Epoch: 6| Step: 5
Training loss: 2.5432650017047935
Validation loss: 2.492405402563912

Epoch: 6| Step: 6
Training loss: 2.5525161895089084
Validation loss: 2.4955205682115675

Epoch: 6| Step: 7
Training loss: 2.8083816893929985
Validation loss: 2.498381678991643

Epoch: 6| Step: 8
Training loss: 2.687068283536573
Validation loss: 2.493477498449351

Epoch: 6| Step: 9
Training loss: 2.6932922753267
Validation loss: 2.4930776443376583

Epoch: 6| Step: 10
Training loss: 2.3033370894729455
Validation loss: 2.494417793010718

Epoch: 6| Step: 11
Training loss: 2.9672269427835256
Validation loss: 2.4978571768308404

Epoch: 6| Step: 12
Training loss: 2.469322524501606
Validation loss: 2.4964378569468155

Epoch: 6| Step: 13
Training loss: 2.6518908466528246
Validation loss: 2.497874866694752

Epoch: 95| Step: 0
Training loss: 2.2364539231812257
Validation loss: 2.4995999651969867

Epoch: 6| Step: 1
Training loss: 2.9039113469319005
Validation loss: 2.495770691694255

Epoch: 6| Step: 2
Training loss: 2.5109135833721643
Validation loss: 2.495001612186867

Epoch: 6| Step: 3
Training loss: 2.1266063901476793
Validation loss: 2.494408362348779

Epoch: 6| Step: 4
Training loss: 2.873205869049829
Validation loss: 2.4945416627199255

Epoch: 6| Step: 5
Training loss: 2.5622011336052157
Validation loss: 2.4907165778541542

Epoch: 6| Step: 6
Training loss: 2.7520807370662834
Validation loss: 2.4911497022080464

Epoch: 6| Step: 7
Training loss: 3.054869195163771
Validation loss: 2.489223052468438

Epoch: 6| Step: 8
Training loss: 2.913858605991033
Validation loss: 2.4904485393508016

Epoch: 6| Step: 9
Training loss: 2.344536407780273
Validation loss: 2.4911191717294

Epoch: 6| Step: 10
Training loss: 2.7146998964248197
Validation loss: 2.4914803453354453

Epoch: 6| Step: 11
Training loss: 2.1776404390474804
Validation loss: 2.490771091441184

Epoch: 6| Step: 12
Training loss: 2.8372917199680434
Validation loss: 2.49498245263666

Epoch: 6| Step: 13
Training loss: 2.5033161104662107
Validation loss: 2.494967768326517

Epoch: 96| Step: 0
Training loss: 2.1786929907373787
Validation loss: 2.4904499593926905

Epoch: 6| Step: 1
Training loss: 2.381544031928275
Validation loss: 2.49801752641392

Epoch: 6| Step: 2
Training loss: 2.305383919706744
Validation loss: 2.4948817471120663

Epoch: 6| Step: 3
Training loss: 3.005817970749195
Validation loss: 2.4921431263448137

Epoch: 6| Step: 4
Training loss: 2.938678586182188
Validation loss: 2.4897734171765893

Epoch: 6| Step: 5
Training loss: 2.7060790045370786
Validation loss: 2.490640397225669

Epoch: 6| Step: 6
Training loss: 3.036062608498008
Validation loss: 2.493975118803077

Epoch: 6| Step: 7
Training loss: 2.821396891328123
Validation loss: 2.496461907798358

Epoch: 6| Step: 8
Training loss: 2.5211003585081015
Validation loss: 2.49580587001544

Epoch: 6| Step: 9
Training loss: 2.795692833346774
Validation loss: 2.495348258370395

Epoch: 6| Step: 10
Training loss: 2.550205323423954
Validation loss: 2.4931718562445506

Epoch: 6| Step: 11
Training loss: 2.304325812456036
Validation loss: 2.4916721078139212

Epoch: 6| Step: 12
Training loss: 2.465944265139505
Validation loss: 2.49075263321359

Epoch: 6| Step: 13
Training loss: 2.547075135026299
Validation loss: 2.494359105676912

Epoch: 97| Step: 0
Training loss: 2.6991536509368945
Validation loss: 2.492250479577056

Epoch: 6| Step: 1
Training loss: 2.5885474181287234
Validation loss: 2.4915148585672178

Epoch: 6| Step: 2
Training loss: 2.3441521871720563
Validation loss: 2.4932822251649176

Epoch: 6| Step: 3
Training loss: 2.730320654960924
Validation loss: 2.491246778349222

Epoch: 6| Step: 4
Training loss: 2.3109684589367903
Validation loss: 2.4872973546435637

Epoch: 6| Step: 5
Training loss: 2.646666708432957
Validation loss: 2.493454948696037

Epoch: 6| Step: 6
Training loss: 2.6832900673673588
Validation loss: 2.4939221251830332

Epoch: 6| Step: 7
Training loss: 2.774901957111644
Validation loss: 2.4926175949175176

Epoch: 6| Step: 8
Training loss: 2.848399961290117
Validation loss: 2.4947185678198904

Epoch: 6| Step: 9
Training loss: 2.4595069239131764
Validation loss: 2.4922056287147996

Epoch: 6| Step: 10
Training loss: 2.194076026969344
Validation loss: 2.4953555197959645

Epoch: 6| Step: 11
Training loss: 2.9387843793888724
Validation loss: 2.4881373612876883

Epoch: 6| Step: 12
Training loss: 2.6626245639657937
Validation loss: 2.4850680266343055

Epoch: 6| Step: 13
Training loss: 2.545246750536805
Validation loss: 2.485526755602882

Epoch: 98| Step: 0
Training loss: 2.779243431194037
Validation loss: 2.4897278513654353

Epoch: 6| Step: 1
Training loss: 2.6376751556812663
Validation loss: 2.4894132728964284

Epoch: 6| Step: 2
Training loss: 2.6865910612058856
Validation loss: 2.492434833175942

Epoch: 6| Step: 3
Training loss: 2.5203251497219648
Validation loss: 2.492077624730027

Epoch: 6| Step: 4
Training loss: 2.4517948893874597
Validation loss: 2.481549125340391

Epoch: 6| Step: 5
Training loss: 2.7721389524414297
Validation loss: 2.485509745242426

Epoch: 6| Step: 6
Training loss: 2.8848714118213556
Validation loss: 2.4850433378323094

Epoch: 6| Step: 7
Training loss: 2.4340314394974265
Validation loss: 2.48875124977447

Epoch: 6| Step: 8
Training loss: 2.794842796886412
Validation loss: 2.489144407602133

Epoch: 6| Step: 9
Training loss: 3.1153467235814833
Validation loss: 2.490011861995034

Epoch: 6| Step: 10
Training loss: 2.506273219127072
Validation loss: 2.491760408643261

Epoch: 6| Step: 11
Training loss: 2.2559552325074805
Validation loss: 2.48550908976568

Epoch: 6| Step: 12
Training loss: 2.204293015818215
Validation loss: 2.4836229829606746

Epoch: 6| Step: 13
Training loss: 2.3495863408381013
Validation loss: 2.4838035294105287

Epoch: 99| Step: 0
Training loss: 2.741045939742805
Validation loss: 2.480010142946523

Epoch: 6| Step: 1
Training loss: 2.3744903820788497
Validation loss: 2.4857762221876323

Epoch: 6| Step: 2
Training loss: 2.24115881100874
Validation loss: 2.478874563324622

Epoch: 6| Step: 3
Training loss: 2.494613088907454
Validation loss: 2.4832099165960333

Epoch: 6| Step: 4
Training loss: 2.8840040106778555
Validation loss: 2.4805907692521356

Epoch: 6| Step: 5
Training loss: 3.0506377632110144
Validation loss: 2.4818616745699216

Epoch: 6| Step: 6
Training loss: 2.3468121678948646
Validation loss: 2.4779462348179218

Epoch: 6| Step: 7
Training loss: 2.7023344261976874
Validation loss: 2.479780975868272

Epoch: 6| Step: 8
Training loss: 2.373132674310556
Validation loss: 2.4778820096697936

Epoch: 6| Step: 9
Training loss: 2.8940322178099827
Validation loss: 2.4810550827734357

Epoch: 6| Step: 10
Training loss: 2.6358917974049985
Validation loss: 2.4794764659093196

Epoch: 6| Step: 11
Training loss: 2.622201699600443
Validation loss: 2.4805900483998187

Epoch: 6| Step: 12
Training loss: 1.8621319759238486
Validation loss: 2.4822930303311868

Epoch: 6| Step: 13
Training loss: 2.9308785014015895
Validation loss: 2.476075077326295

Epoch: 100| Step: 0
Training loss: 2.180271630994224
Validation loss: 2.4821119657765527

Epoch: 6| Step: 1
Training loss: 2.2788317678976204
Validation loss: 2.482541205226528

Epoch: 6| Step: 2
Training loss: 2.539069073008319
Validation loss: 2.4837929865626194

Epoch: 6| Step: 3
Training loss: 2.3517007882147847
Validation loss: 2.485497754786814

Epoch: 6| Step: 4
Training loss: 2.473496329017014
Validation loss: 2.4835156087951265

Epoch: 6| Step: 5
Training loss: 2.672743985035959
Validation loss: 2.487041585781373

Epoch: 6| Step: 6
Training loss: 2.8499860194348536
Validation loss: 2.4836609332019717

Epoch: 6| Step: 7
Training loss: 2.291889619096663
Validation loss: 2.481287327060461

Epoch: 6| Step: 8
Training loss: 2.647231465986546
Validation loss: 2.4878584553962693

Epoch: 6| Step: 9
Training loss: 2.636575064806079
Validation loss: 2.4822797276867035

Epoch: 6| Step: 10
Training loss: 2.4282206434268
Validation loss: 2.4851727594336697

Epoch: 6| Step: 11
Training loss: 3.1792168796185276
Validation loss: 2.482130992543483

Epoch: 6| Step: 12
Training loss: 2.525713859341073
Validation loss: 2.4885085644336047

Epoch: 6| Step: 13
Training loss: 3.090756596154075
Validation loss: 2.4830158442456347

Epoch: 101| Step: 0
Training loss: 2.7198587546419826
Validation loss: 2.479091648494819

Epoch: 6| Step: 1
Training loss: 3.1686616603116997
Validation loss: 2.478234930755025

Epoch: 6| Step: 2
Training loss: 2.7602862537215467
Validation loss: 2.4778818172323915

Epoch: 6| Step: 3
Training loss: 2.2479723164832457
Validation loss: 2.480873743671445

Epoch: 6| Step: 4
Training loss: 2.62013993624815
Validation loss: 2.4821890084738616

Epoch: 6| Step: 5
Training loss: 2.6876060997179647
Validation loss: 2.481290906285474

Epoch: 6| Step: 6
Training loss: 2.661377389850236
Validation loss: 2.484507287300157

Epoch: 6| Step: 7
Training loss: 2.321813232914654
Validation loss: 2.4795459142019696

Epoch: 6| Step: 8
Training loss: 2.1840118935928396
Validation loss: 2.484659574512704

Epoch: 6| Step: 9
Training loss: 2.4102564563662767
Validation loss: 2.47910985694571

Epoch: 6| Step: 10
Training loss: 2.561260574937086
Validation loss: 2.478648954452171

Epoch: 6| Step: 11
Training loss: 2.9103915330643093
Validation loss: 2.4774363326929305

Epoch: 6| Step: 12
Training loss: 2.3827389565046713
Validation loss: 2.4836385823079588

Epoch: 6| Step: 13
Training loss: 2.550541023754564
Validation loss: 2.478416751525733

Epoch: 102| Step: 0
Training loss: 2.785274722453966
Validation loss: 2.4851694016566803

Epoch: 6| Step: 1
Training loss: 2.698185370969174
Validation loss: 2.4810495892998636

Epoch: 6| Step: 2
Training loss: 2.9526134229510346
Validation loss: 2.4818441907855986

Epoch: 6| Step: 3
Training loss: 2.4153840728275076
Validation loss: 2.4819366837304115

Epoch: 6| Step: 4
Training loss: 2.153832005884004
Validation loss: 2.4764460587429324

Epoch: 6| Step: 5
Training loss: 2.0499976413992362
Validation loss: 2.4699731364057054

Epoch: 6| Step: 6
Training loss: 2.2803312567950633
Validation loss: 2.4727381431031263

Epoch: 6| Step: 7
Training loss: 3.349091728405395
Validation loss: 2.4769130101745858

Epoch: 6| Step: 8
Training loss: 2.585962577767374
Validation loss: 2.4765658373564525

Epoch: 6| Step: 9
Training loss: 2.674077693195698
Validation loss: 2.474755415085876

Epoch: 6| Step: 10
Training loss: 2.6529212289296336
Validation loss: 2.4802788609187743

Epoch: 6| Step: 11
Training loss: 2.604916538358564
Validation loss: 2.482693961154365

Epoch: 6| Step: 12
Training loss: 2.4167442857401094
Validation loss: 2.483389909044333

Epoch: 6| Step: 13
Training loss: 2.440905612731904
Validation loss: 2.4835317848157663

Epoch: 103| Step: 0
Training loss: 2.7613582132944843
Validation loss: 2.4835082647509803

Epoch: 6| Step: 1
Training loss: 2.2707997124192483
Validation loss: 2.484395233007929

Epoch: 6| Step: 2
Training loss: 2.7952245179217394
Validation loss: 2.483040153128569

Epoch: 6| Step: 3
Training loss: 2.729271185429048
Validation loss: 2.4839139306580234

Epoch: 6| Step: 4
Training loss: 2.461321507117948
Validation loss: 2.488771830395495

Epoch: 6| Step: 5
Training loss: 2.532738801141632
Validation loss: 2.48039947973733

Epoch: 6| Step: 6
Training loss: 3.171600931287887
Validation loss: 2.479147812159886

Epoch: 6| Step: 7
Training loss: 2.5805774468336433
Validation loss: 2.483071639099486

Epoch: 6| Step: 8
Training loss: 2.015457737806303
Validation loss: 2.4801246464461184

Epoch: 6| Step: 9
Training loss: 2.641936208008259
Validation loss: 2.4703890996707325

Epoch: 6| Step: 10
Training loss: 2.879782141021875
Validation loss: 2.473108636935145

Epoch: 6| Step: 11
Training loss: 2.419899214545335
Validation loss: 2.4749481683820314

Epoch: 6| Step: 12
Training loss: 2.3565841235534704
Validation loss: 2.4761117551066354

Epoch: 6| Step: 13
Training loss: 2.5338166022709876
Validation loss: 2.474268302907086

Epoch: 104| Step: 0
Training loss: 2.741779090485623
Validation loss: 2.477154104528131

Epoch: 6| Step: 1
Training loss: 2.656880382459703
Validation loss: 2.480392462891441

Epoch: 6| Step: 2
Training loss: 2.2613760205901725
Validation loss: 2.4701923068470593

Epoch: 6| Step: 3
Training loss: 2.823746300062075
Validation loss: 2.4694417314355985

Epoch: 6| Step: 4
Training loss: 3.338614111405433
Validation loss: 2.4748907212815605

Epoch: 6| Step: 5
Training loss: 2.911557509223646
Validation loss: 2.476297968105056

Epoch: 6| Step: 6
Training loss: 2.149646987322565
Validation loss: 2.470078718369933

Epoch: 6| Step: 7
Training loss: 2.2043380103429633
Validation loss: 2.4765435989252285

Epoch: 6| Step: 8
Training loss: 2.1154735426450855
Validation loss: 2.481643358594663

Epoch: 6| Step: 9
Training loss: 2.797988414246879
Validation loss: 2.4825551947392754

Epoch: 6| Step: 10
Training loss: 2.5477700562195356
Validation loss: 2.479307769051063

Epoch: 6| Step: 11
Training loss: 2.6575949461547275
Validation loss: 2.4792915013617027

Epoch: 6| Step: 12
Training loss: 2.3153693466014533
Validation loss: 2.480463062990733

Epoch: 6| Step: 13
Training loss: 2.5184342709435534
Validation loss: 2.485628255794504

Epoch: 105| Step: 0
Training loss: 2.8174313863338747
Validation loss: 2.482229237819279

Epoch: 6| Step: 1
Training loss: 2.3664985888082204
Validation loss: 2.478618630707983

Epoch: 6| Step: 2
Training loss: 2.765792582978801
Validation loss: 2.47826327899808

Epoch: 6| Step: 3
Training loss: 2.9333736575851788
Validation loss: 2.474213136635088

Epoch: 6| Step: 4
Training loss: 2.69311256744001
Validation loss: 2.466573037054493

Epoch: 6| Step: 5
Training loss: 2.5611567814750535
Validation loss: 2.4698880465743547

Epoch: 6| Step: 6
Training loss: 2.1647271743383385
Validation loss: 2.4654816831218946

Epoch: 6| Step: 7
Training loss: 2.662547287498666
Validation loss: 2.471056653288136

Epoch: 6| Step: 8
Training loss: 2.9758386407607396
Validation loss: 2.4715420350411486

Epoch: 6| Step: 9
Training loss: 2.8687573534636486
Validation loss: 2.4684737328578077

Epoch: 6| Step: 10
Training loss: 2.2022374306436023
Validation loss: 2.474124257730815

Epoch: 6| Step: 11
Training loss: 2.3135901278716497
Validation loss: 2.481638715068671

Epoch: 6| Step: 12
Training loss: 2.403256027558567
Validation loss: 2.484105869326851

Epoch: 6| Step: 13
Training loss: 2.5296049070393924
Validation loss: 2.4811154621333062

Epoch: 106| Step: 0
Training loss: 2.8086884844723556
Validation loss: 2.487038725827171

Epoch: 6| Step: 1
Training loss: 2.1508911548140173
Validation loss: 2.484754953180073

Epoch: 6| Step: 2
Training loss: 2.7359755708931184
Validation loss: 2.4856215414666316

Epoch: 6| Step: 3
Training loss: 2.779554557516007
Validation loss: 2.4866766034900167

Epoch: 6| Step: 4
Training loss: 2.292856346897586
Validation loss: 2.4829060272212473

Epoch: 6| Step: 5
Training loss: 2.3716310398252296
Validation loss: 2.483222070117335

Epoch: 6| Step: 6
Training loss: 2.495198598231551
Validation loss: 2.4789087711693703

Epoch: 6| Step: 7
Training loss: 2.7047103907312318
Validation loss: 2.4806351573323178

Epoch: 6| Step: 8
Training loss: 2.6393776379661738
Validation loss: 2.4779740892522697

Epoch: 6| Step: 9
Training loss: 2.3421157225336366
Validation loss: 2.480492010533162

Epoch: 6| Step: 10
Training loss: 2.610019170318006
Validation loss: 2.478279016301859

Epoch: 6| Step: 11
Training loss: 2.939009258430905
Validation loss: 2.4799758461447654

Epoch: 6| Step: 12
Training loss: 2.8531155472230116
Validation loss: 2.472285640155556

Epoch: 6| Step: 13
Training loss: 2.4427305002298003
Validation loss: 2.4681661696134607

Epoch: 107| Step: 0
Training loss: 2.4239996665727745
Validation loss: 2.4679319579628443

Epoch: 6| Step: 1
Training loss: 2.119781369146006
Validation loss: 2.4696470152027206

Epoch: 6| Step: 2
Training loss: 2.512409405949159
Validation loss: 2.483115766795989

Epoch: 6| Step: 3
Training loss: 2.8728505267818853
Validation loss: 2.504985336773482

Epoch: 6| Step: 4
Training loss: 2.6607204740750405
Validation loss: 2.4890988462404193

Epoch: 6| Step: 5
Training loss: 2.4985320549894032
Validation loss: 2.5113711356350903

Epoch: 6| Step: 6
Training loss: 2.763893663113644
Validation loss: 2.5068532786842583

Epoch: 6| Step: 7
Training loss: 2.6904220664025456
Validation loss: 2.499617746057655

Epoch: 6| Step: 8
Training loss: 3.23431617572753
Validation loss: 2.4950190356234914

Epoch: 6| Step: 9
Training loss: 2.8616344092685164
Validation loss: 2.4953800269512594

Epoch: 6| Step: 10
Training loss: 3.04779211082276
Validation loss: 2.4872156213860195

Epoch: 6| Step: 11
Training loss: 2.840806045050542
Validation loss: 2.4765562424445293

Epoch: 6| Step: 12
Training loss: 1.7818150209777484
Validation loss: 2.469298209313727

Epoch: 6| Step: 13
Training loss: 1.9466321521251146
Validation loss: 2.4775796560395955

Epoch: 108| Step: 0
Training loss: 2.5159151845806362
Validation loss: 2.480669004511823

Epoch: 6| Step: 1
Training loss: 2.417128705109223
Validation loss: 2.485134080765773

Epoch: 6| Step: 2
Training loss: 2.293929306630516
Validation loss: 2.486076603963142

Epoch: 6| Step: 3
Training loss: 2.371339185100317
Validation loss: 2.489537056422315

Epoch: 6| Step: 4
Training loss: 2.1394489705489605
Validation loss: 2.4926778854973977

Epoch: 6| Step: 5
Training loss: 2.640851344051879
Validation loss: 2.4937420723007504

Epoch: 6| Step: 6
Training loss: 2.9475726858144107
Validation loss: 2.4949475254969835

Epoch: 6| Step: 7
Training loss: 2.7761957771127896
Validation loss: 2.496740266413693

Epoch: 6| Step: 8
Training loss: 2.7134237623806032
Validation loss: 2.4920410623448324

Epoch: 6| Step: 9
Training loss: 2.9855900233413806
Validation loss: 2.4926561574633608

Epoch: 6| Step: 10
Training loss: 2.338312173187084
Validation loss: 2.4905131743697297

Epoch: 6| Step: 11
Training loss: 3.1479019201721385
Validation loss: 2.4896415054569134

Epoch: 6| Step: 12
Training loss: 2.4245449976412394
Validation loss: 2.483239544200401

Epoch: 6| Step: 13
Training loss: 2.7370662850774132
Validation loss: 2.483644598030067

Epoch: 109| Step: 0
Training loss: 2.7617195269679335
Validation loss: 2.48210369705198

Epoch: 6| Step: 1
Training loss: 2.309466666543276
Validation loss: 2.475864516615791

Epoch: 6| Step: 2
Training loss: 2.9094761815490044
Validation loss: 2.4770579679798335

Epoch: 6| Step: 3
Training loss: 1.8036215800821922
Validation loss: 2.4748026053064365

Epoch: 6| Step: 4
Training loss: 2.013911738942036
Validation loss: 2.470736255850824

Epoch: 6| Step: 5
Training loss: 2.7283803569055842
Validation loss: 2.470426802832885

Epoch: 6| Step: 6
Training loss: 2.43830955950954
Validation loss: 2.483696211047021

Epoch: 6| Step: 7
Training loss: 2.2932517609763634
Validation loss: 2.4805311300288566

Epoch: 6| Step: 8
Training loss: 3.072082009621542
Validation loss: 2.476588284170744

Epoch: 6| Step: 9
Training loss: 2.3204912829639164
Validation loss: 2.4779010608986267

Epoch: 6| Step: 10
Training loss: 2.524207313674621
Validation loss: 2.4823598946497976

Epoch: 6| Step: 11
Training loss: 3.185334610781354
Validation loss: 2.4750813608893036

Epoch: 6| Step: 12
Training loss: 2.900765771719242
Validation loss: 2.4762279553293056

Epoch: 6| Step: 13
Training loss: 2.7248395925083595
Validation loss: 2.4744460230873067

Epoch: 110| Step: 0
Training loss: 2.601782437212216
Validation loss: 2.4761273857260675

Epoch: 6| Step: 1
Training loss: 3.341729810566835
Validation loss: 2.472921428552642

Epoch: 6| Step: 2
Training loss: 2.351849003064468
Validation loss: 2.4719672506152706

Epoch: 6| Step: 3
Training loss: 2.7030376795077014
Validation loss: 2.477440831722151

Epoch: 6| Step: 4
Training loss: 2.129270078035209
Validation loss: 2.4811120828498607

Epoch: 6| Step: 5
Training loss: 2.312298637077406
Validation loss: 2.4763055902795164

Epoch: 6| Step: 6
Training loss: 2.7346761483161828
Validation loss: 2.4776205857151004

Epoch: 6| Step: 7
Training loss: 2.893377529750151
Validation loss: 2.4825524416606175

Epoch: 6| Step: 8
Training loss: 2.0960363174742804
Validation loss: 2.479873337459297

Epoch: 6| Step: 9
Training loss: 2.367216305195513
Validation loss: 2.4804282838419174

Epoch: 6| Step: 10
Training loss: 2.2459564963158805
Validation loss: 2.4796180527882963

Epoch: 6| Step: 11
Training loss: 3.1542548492749924
Validation loss: 2.481758499248286

Epoch: 6| Step: 12
Training loss: 2.48881910610388
Validation loss: 2.4770964198385745

Epoch: 6| Step: 13
Training loss: 2.6648816054850246
Validation loss: 2.479374665796469

Epoch: 111| Step: 0
Training loss: 2.806970203987605
Validation loss: 2.480035987408314

Epoch: 6| Step: 1
Training loss: 3.2595593642616034
Validation loss: 2.475682468275363

Epoch: 6| Step: 2
Training loss: 3.0279976612318875
Validation loss: 2.4730713442146888

Epoch: 6| Step: 3
Training loss: 2.7474567617497323
Validation loss: 2.4730467445294364

Epoch: 6| Step: 4
Training loss: 2.7147121040754794
Validation loss: 2.4767032266419573

Epoch: 6| Step: 5
Training loss: 2.5435662805444936
Validation loss: 2.479654125300706

Epoch: 6| Step: 6
Training loss: 2.6249129871297527
Validation loss: 2.4855118395694054

Epoch: 6| Step: 7
Training loss: 2.06181370269695
Validation loss: 2.479256417282101

Epoch: 6| Step: 8
Training loss: 2.083443854897172
Validation loss: 2.487526867592024

Epoch: 6| Step: 9
Training loss: 2.6200233695756996
Validation loss: 2.4996243194595937

Epoch: 6| Step: 10
Training loss: 2.9029174073467803
Validation loss: 2.495414900266088

Epoch: 6| Step: 11
Training loss: 1.9655294567958594
Validation loss: 2.489278899749875

Epoch: 6| Step: 12
Training loss: 2.66212415236292
Validation loss: 2.486595744723006

Epoch: 6| Step: 13
Training loss: 2.1605316994726715
Validation loss: 2.4743823093050366

Epoch: 112| Step: 0
Training loss: 2.370179554700655
Validation loss: 2.473416637879696

Epoch: 6| Step: 1
Training loss: 2.70179530608382
Validation loss: 2.4757850461565396

Epoch: 6| Step: 2
Training loss: 2.7752789468866417
Validation loss: 2.473039883567702

Epoch: 6| Step: 3
Training loss: 2.2123199562050346
Validation loss: 2.4768460308995546

Epoch: 6| Step: 4
Training loss: 1.7510180917847675
Validation loss: 2.475727714777513

Epoch: 6| Step: 5
Training loss: 2.078623317544628
Validation loss: 2.4793554576080856

Epoch: 6| Step: 6
Training loss: 2.4486638220772172
Validation loss: 2.4820838616061986

Epoch: 6| Step: 7
Training loss: 2.882606230181932
Validation loss: 2.478826873531152

Epoch: 6| Step: 8
Training loss: 3.026852278654655
Validation loss: 2.4828434827986814

Epoch: 6| Step: 9
Training loss: 2.3848444045392783
Validation loss: 2.4842089071674045

Epoch: 6| Step: 10
Training loss: 2.485931292897165
Validation loss: 2.4807152092510507

Epoch: 6| Step: 11
Training loss: 3.0822824972845053
Validation loss: 2.479436865008232

Epoch: 6| Step: 12
Training loss: 2.7033927652557823
Validation loss: 2.4816515728107413

Epoch: 6| Step: 13
Training loss: 3.1018001743986368
Validation loss: 2.4819678554938114

Epoch: 113| Step: 0
Training loss: 3.0671998375961746
Validation loss: 2.4790491482318906

Epoch: 6| Step: 1
Training loss: 2.0552643520984923
Validation loss: 2.477500601472342

Epoch: 6| Step: 2
Training loss: 2.045420355462904
Validation loss: 2.4854823989255186

Epoch: 6| Step: 3
Training loss: 3.083431259524745
Validation loss: 2.4809141384962388

Epoch: 6| Step: 4
Training loss: 2.219846320288741
Validation loss: 2.4774231322855336

Epoch: 6| Step: 5
Training loss: 2.180469113018097
Validation loss: 2.4875101744221673

Epoch: 6| Step: 6
Training loss: 1.8390786428723458
Validation loss: 2.4799201899422645

Epoch: 6| Step: 7
Training loss: 2.9043901296393506
Validation loss: 2.475736943742573

Epoch: 6| Step: 8
Training loss: 2.934092391667617
Validation loss: 2.4800719256635766

Epoch: 6| Step: 9
Training loss: 2.5749552343236477
Validation loss: 2.477625012238235

Epoch: 6| Step: 10
Training loss: 2.440214357497035
Validation loss: 2.4745264679253802

Epoch: 6| Step: 11
Training loss: 2.92666543350831
Validation loss: 2.4759376130623028

Epoch: 6| Step: 12
Training loss: 2.908342654004687
Validation loss: 2.4763294034060537

Epoch: 6| Step: 13
Training loss: 2.797481364579299
Validation loss: 2.477030199495404

Epoch: 114| Step: 0
Training loss: 2.051258663738024
Validation loss: 2.478351223831233

Epoch: 6| Step: 1
Training loss: 1.993814798575657
Validation loss: 2.474846856359573

Epoch: 6| Step: 2
Training loss: 2.6220513994895183
Validation loss: 2.472681207114087

Epoch: 6| Step: 3
Training loss: 2.9483942155031113
Validation loss: 2.4713974933156004

Epoch: 6| Step: 4
Training loss: 2.5600563120608992
Validation loss: 2.4698789244615678

Epoch: 6| Step: 5
Training loss: 2.783650937109905
Validation loss: 2.4715882898235093

Epoch: 6| Step: 6
Training loss: 2.5188292952330396
Validation loss: 2.4666170249488752

Epoch: 6| Step: 7
Training loss: 2.590126908186681
Validation loss: 2.4651325941243356

Epoch: 6| Step: 8
Training loss: 2.7229283113432494
Validation loss: 2.4673118587347185

Epoch: 6| Step: 9
Training loss: 3.052450077732768
Validation loss: 2.46482171211527

Epoch: 6| Step: 10
Training loss: 2.8580282406222537
Validation loss: 2.4690983361548193

Epoch: 6| Step: 11
Training loss: 2.320944959968277
Validation loss: 2.467321304387652

Epoch: 6| Step: 12
Training loss: 2.5893721805661207
Validation loss: 2.4627271815294773

Epoch: 6| Step: 13
Training loss: 2.3032370965766584
Validation loss: 2.466116502554523

Epoch: 115| Step: 0
Training loss: 2.332698758438309
Validation loss: 2.471212036633613

Epoch: 6| Step: 1
Training loss: 2.8919132145883024
Validation loss: 2.4735238962031256

Epoch: 6| Step: 2
Training loss: 2.569582293366771
Validation loss: 2.477709170806734

Epoch: 6| Step: 3
Training loss: 2.356501566361284
Validation loss: 2.4750649048743054

Epoch: 6| Step: 4
Training loss: 1.9697039276169102
Validation loss: 2.4771189260104656

Epoch: 6| Step: 5
Training loss: 2.2612574078811254
Validation loss: 2.480389539199795

Epoch: 6| Step: 6
Training loss: 2.5119564246510535
Validation loss: 2.479008955440372

Epoch: 6| Step: 7
Training loss: 2.523135235047293
Validation loss: 2.4830412413415943

Epoch: 6| Step: 8
Training loss: 2.547510266793389
Validation loss: 2.4860966792714825

Epoch: 6| Step: 9
Training loss: 2.414790466569827
Validation loss: 2.4811147254178767

Epoch: 6| Step: 10
Training loss: 2.802697285795536
Validation loss: 2.484674575625559

Epoch: 6| Step: 11
Training loss: 3.0533984652350896
Validation loss: 2.4837133938159304

Epoch: 6| Step: 12
Training loss: 2.871386371673894
Validation loss: 2.4828135543830605

Epoch: 6| Step: 13
Training loss: 3.021442080141922
Validation loss: 2.482290068858138

Epoch: 116| Step: 0
Training loss: 3.151972222917418
Validation loss: 2.479547428629048

Epoch: 6| Step: 1
Training loss: 2.849094608448555
Validation loss: 2.480570849622696

Epoch: 6| Step: 2
Training loss: 1.969652483733424
Validation loss: 2.480012402144564

Epoch: 6| Step: 3
Training loss: 2.1870958227332844
Validation loss: 2.4809058577709213

Epoch: 6| Step: 4
Training loss: 2.863686734536795
Validation loss: 2.4774960303763964

Epoch: 6| Step: 5
Training loss: 2.68051686256255
Validation loss: 2.4842439213047807

Epoch: 6| Step: 6
Training loss: 2.727742199515754
Validation loss: 2.479798137694062

Epoch: 6| Step: 7
Training loss: 2.70171138425982
Validation loss: 2.481425728008156

Epoch: 6| Step: 8
Training loss: 2.5644356464798497
Validation loss: 2.476356858822316

Epoch: 6| Step: 9
Training loss: 2.660546900091534
Validation loss: 2.472882718948843

Epoch: 6| Step: 10
Training loss: 2.177668357498507
Validation loss: 2.4772316543110757

Epoch: 6| Step: 11
Training loss: 2.3500880691583226
Validation loss: 2.4750048756150025

Epoch: 6| Step: 12
Training loss: 2.3113984242177015
Validation loss: 2.4759416253198654

Epoch: 6| Step: 13
Training loss: 2.90303567311612
Validation loss: 2.4786384457898065

Epoch: 117| Step: 0
Training loss: 2.6083277810944603
Validation loss: 2.481550886742448

Epoch: 6| Step: 1
Training loss: 2.405073101019247
Validation loss: 2.4768881438287824

Epoch: 6| Step: 2
Training loss: 2.3399169095276977
Validation loss: 2.4866469609073785

Epoch: 6| Step: 3
Training loss: 2.0228568757397998
Validation loss: 2.476713767581451

Epoch: 6| Step: 4
Training loss: 2.7729354189022044
Validation loss: 2.492829394612235

Epoch: 6| Step: 5
Training loss: 2.995911036842354
Validation loss: 2.4830266784512967

Epoch: 6| Step: 6
Training loss: 2.5305316046893274
Validation loss: 2.489496338626508

Epoch: 6| Step: 7
Training loss: 2.832936277804632
Validation loss: 2.4859552935449605

Epoch: 6| Step: 8
Training loss: 2.7477980381075207
Validation loss: 2.4911185655823576

Epoch: 6| Step: 9
Training loss: 2.624044789496074
Validation loss: 2.4850029621579934

Epoch: 6| Step: 10
Training loss: 2.1556308244342817
Validation loss: 2.4797959023369263

Epoch: 6| Step: 11
Training loss: 3.2009716704478604
Validation loss: 2.4769435392887216

Epoch: 6| Step: 12
Training loss: 2.5524267990570615
Validation loss: 2.475262674848693

Epoch: 6| Step: 13
Training loss: 2.2476160347489613
Validation loss: 2.4773782174928574

Epoch: 118| Step: 0
Training loss: 1.7224812321408656
Validation loss: 2.474103627539431

Epoch: 6| Step: 1
Training loss: 2.6126361501160216
Validation loss: 2.4758001331408916

Epoch: 6| Step: 2
Training loss: 2.88864942520012
Validation loss: 2.475312054674227

Epoch: 6| Step: 3
Training loss: 2.464615075193705
Validation loss: 2.476392385133605

Epoch: 6| Step: 4
Training loss: 2.614213671648267
Validation loss: 2.4732859584567444

Epoch: 6| Step: 5
Training loss: 2.8613989499020382
Validation loss: 2.477818696958096

Epoch: 6| Step: 6
Training loss: 1.9639761433094465
Validation loss: 2.4741828307971474

Epoch: 6| Step: 7
Training loss: 2.8597852068719005
Validation loss: 2.478189393305688

Epoch: 6| Step: 8
Training loss: 3.0942437904938527
Validation loss: 2.4696888808270256

Epoch: 6| Step: 9
Training loss: 2.5495198564461283
Validation loss: 2.4757900858615387

Epoch: 6| Step: 10
Training loss: 2.195937641231195
Validation loss: 2.472628504400083

Epoch: 6| Step: 11
Training loss: 2.6189434480799165
Validation loss: 2.468741662377551

Epoch: 6| Step: 12
Training loss: 2.0876011304286184
Validation loss: 2.4695241012236457

Epoch: 6| Step: 13
Training loss: 3.113441147281877
Validation loss: 2.463681696218029

Epoch: 119| Step: 0
Training loss: 2.8214780137487994
Validation loss: 2.465088402424811

Epoch: 6| Step: 1
Training loss: 2.749503871206724
Validation loss: 2.471721558886273

Epoch: 6| Step: 2
Training loss: 2.4168260675236066
Validation loss: 2.465391651323433

Epoch: 6| Step: 3
Training loss: 2.1541015315092595
Validation loss: 2.464543650273534

Epoch: 6| Step: 4
Training loss: 2.389319867678714
Validation loss: 2.470265160946893

Epoch: 6| Step: 5
Training loss: 2.938915155297795
Validation loss: 2.4657702591351387

Epoch: 6| Step: 6
Training loss: 2.382284337276987
Validation loss: 2.4661514190857634

Epoch: 6| Step: 7
Training loss: 2.358105349444933
Validation loss: 2.467139736983163

Epoch: 6| Step: 8
Training loss: 2.428878796785187
Validation loss: 2.4670788142476385

Epoch: 6| Step: 9
Training loss: 2.5851620897427146
Validation loss: 2.4689141391962632

Epoch: 6| Step: 10
Training loss: 3.019574203284401
Validation loss: 2.464833222783375

Epoch: 6| Step: 11
Training loss: 2.344035321988293
Validation loss: 2.4723616711319125

Epoch: 6| Step: 12
Training loss: 2.835712854824961
Validation loss: 2.4655935655337866

Epoch: 6| Step: 13
Training loss: 2.3275846327853085
Validation loss: 2.468280586651014

Epoch: 120| Step: 0
Training loss: 2.556099131266208
Validation loss: 2.471318779636081

Epoch: 6| Step: 1
Training loss: 3.021378478923624
Validation loss: 2.467478831289611

Epoch: 6| Step: 2
Training loss: 2.7749137280774523
Validation loss: 2.4671236950816002

Epoch: 6| Step: 3
Training loss: 2.456252515951717
Validation loss: 2.465558310712001

Epoch: 6| Step: 4
Training loss: 2.5052306768381913
Validation loss: 2.471907885590308

Epoch: 6| Step: 5
Training loss: 2.2823436676002395
Validation loss: 2.4701446102966087

Epoch: 6| Step: 6
Training loss: 2.5205906732796026
Validation loss: 2.4707088585989343

Epoch: 6| Step: 7
Training loss: 2.034580962131339
Validation loss: 2.4707379123817033

Epoch: 6| Step: 8
Training loss: 2.8491056544809825
Validation loss: 2.4702326028777017

Epoch: 6| Step: 9
Training loss: 2.7506950540426094
Validation loss: 2.4660962162578715

Epoch: 6| Step: 10
Training loss: 3.0923760956572193
Validation loss: 2.4682285707828155

Epoch: 6| Step: 11
Training loss: 2.4013396855315654
Validation loss: 2.469077414518404

Epoch: 6| Step: 12
Training loss: 2.147471817773142
Validation loss: 2.4659136481922848

Epoch: 6| Step: 13
Training loss: 2.325783185410263
Validation loss: 2.467968813115387

Epoch: 121| Step: 0
Training loss: 2.1476694294680185
Validation loss: 2.4731390523394805

Epoch: 6| Step: 1
Training loss: 2.6071816551621247
Validation loss: 2.470298185071783

Epoch: 6| Step: 2
Training loss: 2.7873896863517884
Validation loss: 2.4767660705141554

Epoch: 6| Step: 3
Training loss: 2.52369296549363
Validation loss: 2.4695490899910393

Epoch: 6| Step: 4
Training loss: 2.417541959254453
Validation loss: 2.4689489920208776

Epoch: 6| Step: 5
Training loss: 2.1115330712205655
Validation loss: 2.4723340186607206

Epoch: 6| Step: 6
Training loss: 3.037532784241882
Validation loss: 2.4724407132237145

Epoch: 6| Step: 7
Training loss: 2.0342017221562223
Validation loss: 2.475508938105409

Epoch: 6| Step: 8
Training loss: 2.5493085035820098
Validation loss: 2.4722583966936336

Epoch: 6| Step: 9
Training loss: 2.103596550280043
Validation loss: 2.4739481447244285

Epoch: 6| Step: 10
Training loss: 2.0284072938138356
Validation loss: 2.472156572601334

Epoch: 6| Step: 11
Training loss: 3.00250711584717
Validation loss: 2.4720549854286546

Epoch: 6| Step: 12
Training loss: 3.4658190742548505
Validation loss: 2.474685615583472

Epoch: 6| Step: 13
Training loss: 2.666015177855961
Validation loss: 2.470103058048546

Epoch: 122| Step: 0
Training loss: 3.1323678707134683
Validation loss: 2.474825212619668

Epoch: 6| Step: 1
Training loss: 2.363696756958515
Validation loss: 2.471657758796607

Epoch: 6| Step: 2
Training loss: 2.286297791796475
Validation loss: 2.4704997465237377

Epoch: 6| Step: 3
Training loss: 2.158006919814391
Validation loss: 2.4696953327682722

Epoch: 6| Step: 4
Training loss: 2.66091715367547
Validation loss: 2.4749119630562513

Epoch: 6| Step: 5
Training loss: 2.2525173515980934
Validation loss: 2.473858067672485

Epoch: 6| Step: 6
Training loss: 3.0041300636915165
Validation loss: 2.4757566534866724

Epoch: 6| Step: 7
Training loss: 2.6068936730911627
Validation loss: 2.4772310768472607

Epoch: 6| Step: 8
Training loss: 2.2575647554794758
Validation loss: 2.475819890531367

Epoch: 6| Step: 9
Training loss: 2.704583893394226
Validation loss: 2.4803777883276537

Epoch: 6| Step: 10
Training loss: 2.4674437724995433
Validation loss: 2.472190134028333

Epoch: 6| Step: 11
Training loss: 2.358573120471743
Validation loss: 2.473231822635827

Epoch: 6| Step: 12
Training loss: 2.828215539652682
Validation loss: 2.4713600622226726

Epoch: 6| Step: 13
Training loss: 2.7095781155560985
Validation loss: 2.4716249136078674

Epoch: 123| Step: 0
Training loss: 2.402665775704651
Validation loss: 2.4707521778006902

Epoch: 6| Step: 1
Training loss: 2.2584790364614826
Validation loss: 2.4689653037141315

Epoch: 6| Step: 2
Training loss: 2.9042049308748132
Validation loss: 2.459845648862179

Epoch: 6| Step: 3
Training loss: 2.8345331755624694
Validation loss: 2.463091227756375

Epoch: 6| Step: 4
Training loss: 2.421418473069538
Validation loss: 2.4596517443514663

Epoch: 6| Step: 5
Training loss: 2.725812661319889
Validation loss: 2.460597980632882

Epoch: 6| Step: 6
Training loss: 2.323030774060879
Validation loss: 2.4670778881138107

Epoch: 6| Step: 7
Training loss: 2.420611045554883
Validation loss: 2.4706786143176496

Epoch: 6| Step: 8
Training loss: 2.369559431049965
Validation loss: 2.454927757997554

Epoch: 6| Step: 9
Training loss: 2.786393798841377
Validation loss: 2.4551925693200642

Epoch: 6| Step: 10
Training loss: 2.384232595048407
Validation loss: 2.455115286404976

Epoch: 6| Step: 11
Training loss: 2.6972180693105865
Validation loss: 2.457633166632725

Epoch: 6| Step: 12
Training loss: 2.8634008197876772
Validation loss: 2.4585872993105813

Epoch: 6| Step: 13
Training loss: 2.379646273861389
Validation loss: 2.4583007977374693

Epoch: 124| Step: 0
Training loss: 2.406056284847824
Validation loss: 2.4640884007794184

Epoch: 6| Step: 1
Training loss: 2.6290283174785327
Validation loss: 2.4623958888370514

Epoch: 6| Step: 2
Training loss: 2.869322270511492
Validation loss: 2.4562398245408987

Epoch: 6| Step: 3
Training loss: 2.6374583019558173
Validation loss: 2.4558223060806483

Epoch: 6| Step: 4
Training loss: 2.6580446351596922
Validation loss: 2.4580381399392146

Epoch: 6| Step: 5
Training loss: 1.7877522964089376
Validation loss: 2.457285873408413

Epoch: 6| Step: 6
Training loss: 2.7425336048776243
Validation loss: 2.4547931320607788

Epoch: 6| Step: 7
Training loss: 2.544707048414366
Validation loss: 2.4527892998693193

Epoch: 6| Step: 8
Training loss: 2.721772541697376
Validation loss: 2.451864789516411

Epoch: 6| Step: 9
Training loss: 2.6593498542574023
Validation loss: 2.4598817609397523

Epoch: 6| Step: 10
Training loss: 2.144850187783158
Validation loss: 2.4633404177080767

Epoch: 6| Step: 11
Training loss: 2.674259125975598
Validation loss: 2.457161225245502

Epoch: 6| Step: 12
Training loss: 2.7853572393072894
Validation loss: 2.4554294849654337

Epoch: 6| Step: 13
Training loss: 2.304423378503038
Validation loss: 2.460179869270997

Epoch: 125| Step: 0
Training loss: 2.179182315378791
Validation loss: 2.4634876339385707

Epoch: 6| Step: 1
Training loss: 2.8172710218018473
Validation loss: 2.463095744921647

Epoch: 6| Step: 2
Training loss: 2.766418084693206
Validation loss: 2.4633354493193598

Epoch: 6| Step: 3
Training loss: 2.407844708602918
Validation loss: 2.4658435178363542

Epoch: 6| Step: 4
Training loss: 2.6760914866342715
Validation loss: 2.4653275665365677

Epoch: 6| Step: 5
Training loss: 2.611833978473674
Validation loss: 2.4620043828673697

Epoch: 6| Step: 6
Training loss: 2.8589006874792173
Validation loss: 2.4685277074214778

Epoch: 6| Step: 7
Training loss: 2.3452787372718125
Validation loss: 2.4601344014232644

Epoch: 6| Step: 8
Training loss: 2.960923650301547
Validation loss: 2.464008623081245

Epoch: 6| Step: 9
Training loss: 2.454005381061403
Validation loss: 2.4616224032197396

Epoch: 6| Step: 10
Training loss: 2.4244839305946977
Validation loss: 2.4633866974449385

Epoch: 6| Step: 11
Training loss: 2.344856001249428
Validation loss: 2.4616676175944927

Epoch: 6| Step: 12
Training loss: 2.5521400185861656
Validation loss: 2.46079369987697

Epoch: 6| Step: 13
Training loss: 2.3218785405292444
Validation loss: 2.4594022452862108

Epoch: 126| Step: 0
Training loss: 2.740126919695739
Validation loss: 2.4576755764429508

Epoch: 6| Step: 1
Training loss: 2.658262051749734
Validation loss: 2.4564235079167793

Epoch: 6| Step: 2
Training loss: 2.3857847593290304
Validation loss: 2.461896501614944

Epoch: 6| Step: 3
Training loss: 3.091569536710663
Validation loss: 2.452977526336164

Epoch: 6| Step: 4
Training loss: 2.421070186651731
Validation loss: 2.4521991092009587

Epoch: 6| Step: 5
Training loss: 2.607473628641344
Validation loss: 2.457540082375036

Epoch: 6| Step: 6
Training loss: 2.6426821488729826
Validation loss: 2.456656358154629

Epoch: 6| Step: 7
Training loss: 2.4277186619563906
Validation loss: 2.455175364977947

Epoch: 6| Step: 8
Training loss: 2.2786174895930635
Validation loss: 2.454835752805544

Epoch: 6| Step: 9
Training loss: 2.0343343938709846
Validation loss: 2.4563793779229037

Epoch: 6| Step: 10
Training loss: 2.5012636805612525
Validation loss: 2.4582235236346754

Epoch: 6| Step: 11
Training loss: 2.4736902566859396
Validation loss: 2.456365773171802

Epoch: 6| Step: 12
Training loss: 2.7621729799612527
Validation loss: 2.4585095412471514

Epoch: 6| Step: 13
Training loss: 2.6838429431074804
Validation loss: 2.462662656288551

Epoch: 127| Step: 0
Training loss: 2.552251184873318
Validation loss: 2.461473743607342

Epoch: 6| Step: 1
Training loss: 1.8196378448173427
Validation loss: 2.4718354174968886

Epoch: 6| Step: 2
Training loss: 3.05791363517201
Validation loss: 2.466967804565045

Epoch: 6| Step: 3
Training loss: 2.429623716443231
Validation loss: 2.4680865720241707

Epoch: 6| Step: 4
Training loss: 2.549105550933944
Validation loss: 2.470246565580482

Epoch: 6| Step: 5
Training loss: 2.323798543947294
Validation loss: 2.4691603919044027

Epoch: 6| Step: 6
Training loss: 2.424530247287797
Validation loss: 2.4659601294029043

Epoch: 6| Step: 7
Training loss: 3.103310042258715
Validation loss: 2.4685015010106723

Epoch: 6| Step: 8
Training loss: 2.725089563420276
Validation loss: 2.4685369633047554

Epoch: 6| Step: 9
Training loss: 2.4829887505229236
Validation loss: 2.466869926025389

Epoch: 6| Step: 10
Training loss: 2.4145032363083114
Validation loss: 2.472789043699482

Epoch: 6| Step: 11
Training loss: 2.579711425966045
Validation loss: 2.4626709176790853

Epoch: 6| Step: 12
Training loss: 2.5239140205308552
Validation loss: 2.464596130862402

Epoch: 6| Step: 13
Training loss: 2.6738707467270433
Validation loss: 2.4633035900951197

Epoch: 128| Step: 0
Training loss: 2.918878007650776
Validation loss: 2.4607309406119477

Epoch: 6| Step: 1
Training loss: 2.5927802421638577
Validation loss: 2.4588953011650316

Epoch: 6| Step: 2
Training loss: 2.4308221749498724
Validation loss: 2.455472741976908

Epoch: 6| Step: 3
Training loss: 2.1545610309135816
Validation loss: 2.4629058555073615

Epoch: 6| Step: 4
Training loss: 2.6095306898257737
Validation loss: 2.463842520109645

Epoch: 6| Step: 5
Training loss: 2.4249323098085274
Validation loss: 2.461103015964801

Epoch: 6| Step: 6
Training loss: 2.530437009258422
Validation loss: 2.4606301574937204

Epoch: 6| Step: 7
Training loss: 2.472691733058992
Validation loss: 2.4663976254099436

Epoch: 6| Step: 8
Training loss: 2.4206859007526234
Validation loss: 2.4590755462914453

Epoch: 6| Step: 9
Training loss: 2.722576211330266
Validation loss: 2.4794631641798226

Epoch: 6| Step: 10
Training loss: 2.458393538001841
Validation loss: 2.4754747153834735

Epoch: 6| Step: 11
Training loss: 3.025288648468965
Validation loss: 2.4756168521553445

Epoch: 6| Step: 12
Training loss: 2.2111801176096457
Validation loss: 2.473993599623571

Epoch: 6| Step: 13
Training loss: 2.7654000745785856
Validation loss: 2.467712216409763

Epoch: 129| Step: 0
Training loss: 2.4980945001018693
Validation loss: 2.475602638845393

Epoch: 6| Step: 1
Training loss: 2.7947773659466186
Validation loss: 2.4796093350521864

Epoch: 6| Step: 2
Training loss: 3.175398049220931
Validation loss: 2.4780058079677905

Epoch: 6| Step: 3
Training loss: 2.1619474906932057
Validation loss: 2.478721487856301

Epoch: 6| Step: 4
Training loss: 2.4991064382098562
Validation loss: 2.4707998384989778

Epoch: 6| Step: 5
Training loss: 2.313974992641676
Validation loss: 2.4629603957625195

Epoch: 6| Step: 6
Training loss: 2.8488843909413415
Validation loss: 2.461150032029435

Epoch: 6| Step: 7
Training loss: 2.4914495158752525
Validation loss: 2.4636838978093545

Epoch: 6| Step: 8
Training loss: 3.0788001854570255
Validation loss: 2.45892821942949

Epoch: 6| Step: 9
Training loss: 2.33478704081774
Validation loss: 2.457938426567517

Epoch: 6| Step: 10
Training loss: 2.1495760033838605
Validation loss: 2.466410055108247

Epoch: 6| Step: 11
Training loss: 2.409678407161408
Validation loss: 2.466590886842156

Epoch: 6| Step: 12
Training loss: 2.3137438753728112
Validation loss: 2.4619468112791525

Epoch: 6| Step: 13
Training loss: 2.5878761607791536
Validation loss: 2.465827709224673

Epoch: 130| Step: 0
Training loss: 2.6416401914920495
Validation loss: 2.456922091033823

Epoch: 6| Step: 1
Training loss: 2.7033782134777593
Validation loss: 2.457478913572129

Epoch: 6| Step: 2
Training loss: 2.9654588626676843
Validation loss: 2.466386637601147

Epoch: 6| Step: 3
Training loss: 2.338814077391518
Validation loss: 2.4629915495565036

Epoch: 6| Step: 4
Training loss: 2.2843864513689445
Validation loss: 2.4650764012957613

Epoch: 6| Step: 5
Training loss: 2.525378918307166
Validation loss: 2.472815791201433

Epoch: 6| Step: 6
Training loss: 2.592841851145432
Validation loss: 2.4755016184635683

Epoch: 6| Step: 7
Training loss: 2.471926130882415
Validation loss: 2.473198299444824

Epoch: 6| Step: 8
Training loss: 1.8719195811164309
Validation loss: 2.47702322925214

Epoch: 6| Step: 9
Training loss: 2.8891728233122898
Validation loss: 2.4757866832592885

Epoch: 6| Step: 10
Training loss: 2.8877542623231345
Validation loss: 2.4761570579549668

Epoch: 6| Step: 11
Training loss: 2.095079142457196
Validation loss: 2.4774441598757644

Epoch: 6| Step: 12
Training loss: 2.835950951242204
Validation loss: 2.4821274305388945

Epoch: 6| Step: 13
Training loss: 2.880464253888968
Validation loss: 2.477088800097551

Epoch: 131| Step: 0
Training loss: 2.4623476862396356
Validation loss: 2.4802301887874765

Epoch: 6| Step: 1
Training loss: 2.8488432159505344
Validation loss: 2.481490566016671

Epoch: 6| Step: 2
Training loss: 2.245894076552695
Validation loss: 2.4813876635127574

Epoch: 6| Step: 3
Training loss: 1.9919815256188955
Validation loss: 2.4750334374580563

Epoch: 6| Step: 4
Training loss: 2.358026384343537
Validation loss: 2.472360827338325

Epoch: 6| Step: 5
Training loss: 2.816538221677224
Validation loss: 2.4677569649572653

Epoch: 6| Step: 6
Training loss: 2.4134613572546435
Validation loss: 2.4693967076786603

Epoch: 6| Step: 7
Training loss: 2.6294887855234066
Validation loss: 2.4746082027907232

Epoch: 6| Step: 8
Training loss: 2.6243074502629944
Validation loss: 2.4737750551028905

Epoch: 6| Step: 9
Training loss: 2.9112217533482343
Validation loss: 2.4753409982427845

Epoch: 6| Step: 10
Training loss: 2.4871087538159857
Validation loss: 2.4667051353118334

Epoch: 6| Step: 11
Training loss: 2.220140585528975
Validation loss: 2.470303219884966

Epoch: 6| Step: 12
Training loss: 2.875552912079849
Validation loss: 2.4695292904765695

Epoch: 6| Step: 13
Training loss: 2.7273419421978664
Validation loss: 2.46752446977669

Epoch: 132| Step: 0
Training loss: 2.201359250911742
Validation loss: 2.4704472948392096

Epoch: 6| Step: 1
Training loss: 2.751373381562693
Validation loss: 2.471441596320009

Epoch: 6| Step: 2
Training loss: 2.1421018086662937
Validation loss: 2.468893264283451

Epoch: 6| Step: 3
Training loss: 2.9694693246038395
Validation loss: 2.465722396467627

Epoch: 6| Step: 4
Training loss: 2.2025372959057825
Validation loss: 2.467500636091991

Epoch: 6| Step: 5
Training loss: 2.9690209516053905
Validation loss: 2.472515791227688

Epoch: 6| Step: 6
Training loss: 2.5141149692027094
Validation loss: 2.468705543085588

Epoch: 6| Step: 7
Training loss: 2.4216755446472344
Validation loss: 2.4642027168960934

Epoch: 6| Step: 8
Training loss: 2.523094413747693
Validation loss: 2.4594231845993946

Epoch: 6| Step: 9
Training loss: 2.3445817615898545
Validation loss: 2.465599609166906

Epoch: 6| Step: 10
Training loss: 2.874117508494863
Validation loss: 2.4661043291852534

Epoch: 6| Step: 11
Training loss: 2.5779142351407764
Validation loss: 2.46753546862247

Epoch: 6| Step: 12
Training loss: 2.717422687515152
Validation loss: 2.4657092783891335

Epoch: 6| Step: 13
Training loss: 2.629651988396587
Validation loss: 2.469664472707271

Epoch: 133| Step: 0
Training loss: 2.3946065221906845
Validation loss: 2.462826765555019

Epoch: 6| Step: 1
Training loss: 2.6983063366085105
Validation loss: 2.45972900589531

Epoch: 6| Step: 2
Training loss: 2.308709827480466
Validation loss: 2.4630165481341884

Epoch: 6| Step: 3
Training loss: 2.040108014407379
Validation loss: 2.459964079310324

Epoch: 6| Step: 4
Training loss: 2.5860355969403397
Validation loss: 2.462369536479389

Epoch: 6| Step: 5
Training loss: 2.8893674022154663
Validation loss: 2.4555595288117464

Epoch: 6| Step: 6
Training loss: 2.3001632508100807
Validation loss: 2.459487536326463

Epoch: 6| Step: 7
Training loss: 2.8920085173569823
Validation loss: 2.4617438231635704

Epoch: 6| Step: 8
Training loss: 2.7012939425543476
Validation loss: 2.4567390433907206

Epoch: 6| Step: 9
Training loss: 2.1085345819290984
Validation loss: 2.4639218758123

Epoch: 6| Step: 10
Training loss: 2.326861557144241
Validation loss: 2.4502936381881533

Epoch: 6| Step: 11
Training loss: 3.0272114386408955
Validation loss: 2.4531679088946086

Epoch: 6| Step: 12
Training loss: 2.250382284961112
Validation loss: 2.4583457903357804

Epoch: 6| Step: 13
Training loss: 2.821139903761935
Validation loss: 2.4672472923398723

Epoch: 134| Step: 0
Training loss: 2.453834382528675
Validation loss: 2.472759178393732

Epoch: 6| Step: 1
Training loss: 2.3953964387901445
Validation loss: 2.466386702045916

Epoch: 6| Step: 2
Training loss: 2.458086572536349
Validation loss: 2.468686694528651

Epoch: 6| Step: 3
Training loss: 2.9257998294011216
Validation loss: 2.46919973920529

Epoch: 6| Step: 4
Training loss: 2.7183759585495646
Validation loss: 2.468631419621525

Epoch: 6| Step: 5
Training loss: 2.6920058159786615
Validation loss: 2.472702050048531

Epoch: 6| Step: 6
Training loss: 2.514024877177799
Validation loss: 2.4663610448391085

Epoch: 6| Step: 7
Training loss: 3.03805878448369
Validation loss: 2.460558439256755

Epoch: 6| Step: 8
Training loss: 2.4456909666808673
Validation loss: 2.4635065222740873

Epoch: 6| Step: 9
Training loss: 2.741144226371405
Validation loss: 2.4671208603572268

Epoch: 6| Step: 10
Training loss: 2.477316564087766
Validation loss: 2.473584435300253

Epoch: 6| Step: 11
Training loss: 2.470692510167415
Validation loss: 2.4721640950297603

Epoch: 6| Step: 12
Training loss: 2.5062449657361086
Validation loss: 2.466156027321994

Epoch: 6| Step: 13
Training loss: 1.827464448971815
Validation loss: 2.468084213359033

Epoch: 135| Step: 0
Training loss: 2.737854928475028
Validation loss: 2.471980222961381

Epoch: 6| Step: 1
Training loss: 2.764254472879174
Validation loss: 2.472509571644481

Epoch: 6| Step: 2
Training loss: 2.6771301878949094
Validation loss: 2.4699274788118792

Epoch: 6| Step: 3
Training loss: 2.7737536612817877
Validation loss: 2.4605391407027644

Epoch: 6| Step: 4
Training loss: 2.5071939911865893
Validation loss: 2.4745824702485595

Epoch: 6| Step: 5
Training loss: 2.42516197371534
Validation loss: 2.4747595095435213

Epoch: 6| Step: 6
Training loss: 2.5128782452599028
Validation loss: 2.4795416593780857

Epoch: 6| Step: 7
Training loss: 2.874427572567116
Validation loss: 2.4732133540085677

Epoch: 6| Step: 8
Training loss: 2.704253561997411
Validation loss: 2.468020158236103

Epoch: 6| Step: 9
Training loss: 2.2187044380775287
Validation loss: 2.469189150095591

Epoch: 6| Step: 10
Training loss: 2.4260200714639595
Validation loss: 2.466838241314877

Epoch: 6| Step: 11
Training loss: 2.33798964568783
Validation loss: 2.4690055071116683

Epoch: 6| Step: 12
Training loss: 2.2532062997316493
Validation loss: 2.467331104315007

Epoch: 6| Step: 13
Training loss: 2.415508540851241
Validation loss: 2.467322971263828

Epoch: 136| Step: 0
Training loss: 2.506932754935512
Validation loss: 2.4639448248663682

Epoch: 6| Step: 1
Training loss: 2.675533622922522
Validation loss: 2.466321257515498

Epoch: 6| Step: 2
Training loss: 2.977898565692544
Validation loss: 2.4614384459215324

Epoch: 6| Step: 3
Training loss: 2.708706864249863
Validation loss: 2.4675542454552692

Epoch: 6| Step: 4
Training loss: 1.9994968138943867
Validation loss: 2.462105932832983

Epoch: 6| Step: 5
Training loss: 1.7445850382813926
Validation loss: 2.465255291855636

Epoch: 6| Step: 6
Training loss: 1.8750968272321225
Validation loss: 2.4636931799548116

Epoch: 6| Step: 7
Training loss: 2.910507692967458
Validation loss: 2.4658551848813

Epoch: 6| Step: 8
Training loss: 3.1140377795917327
Validation loss: 2.4610077540143602

Epoch: 6| Step: 9
Training loss: 2.4216373450054607
Validation loss: 2.4597432543875355

Epoch: 6| Step: 10
Training loss: 2.5965667504939107
Validation loss: 2.4615251677086136

Epoch: 6| Step: 11
Training loss: 2.901027129232165
Validation loss: 2.471850882250596

Epoch: 6| Step: 12
Training loss: 2.454355599385232
Validation loss: 2.461287813633987

Epoch: 6| Step: 13
Training loss: 2.706752393927766
Validation loss: 2.4669532675964088

Epoch: 137| Step: 0
Training loss: 2.2604848496896124
Validation loss: 2.4645922613640563

Epoch: 6| Step: 1
Training loss: 2.8384329585453045
Validation loss: 2.4637141634423263

Epoch: 6| Step: 2
Training loss: 2.466082326735328
Validation loss: 2.4648518267467465

Epoch: 6| Step: 3
Training loss: 2.5390987452340874
Validation loss: 2.4693732621735465

Epoch: 6| Step: 4
Training loss: 2.561870032308229
Validation loss: 2.4715425656014327

Epoch: 6| Step: 5
Training loss: 2.6209075452266952
Validation loss: 2.4663624465270004

Epoch: 6| Step: 6
Training loss: 2.6891490401462743
Validation loss: 2.4656362574408575

Epoch: 6| Step: 7
Training loss: 3.2139231219969226
Validation loss: 2.459287706027182

Epoch: 6| Step: 8
Training loss: 1.985375399992932
Validation loss: 2.4680697795672946

Epoch: 6| Step: 9
Training loss: 3.0109775289142338
Validation loss: 2.465315300621582

Epoch: 6| Step: 10
Training loss: 1.8354825369207588
Validation loss: 2.4597112436287087

Epoch: 6| Step: 11
Training loss: 2.548563204623143
Validation loss: 2.4604132199781428

Epoch: 6| Step: 12
Training loss: 2.7491007982010105
Validation loss: 2.458592503566242

Epoch: 6| Step: 13
Training loss: 1.8927475545371335
Validation loss: 2.4613918147473726

Epoch: 138| Step: 0
Training loss: 2.4489111212805663
Validation loss: 2.4611191616926518

Epoch: 6| Step: 1
Training loss: 2.06801007917298
Validation loss: 2.4662923369887975

Epoch: 6| Step: 2
Training loss: 2.7931089139327043
Validation loss: 2.4640019788548337

Epoch: 6| Step: 3
Training loss: 2.589423374218613
Validation loss: 2.4635169180553733

Epoch: 6| Step: 4
Training loss: 2.5802572969285973
Validation loss: 2.4659382545793287

Epoch: 6| Step: 5
Training loss: 2.754643854151406
Validation loss: 2.463271843379779

Epoch: 6| Step: 6
Training loss: 2.5568448444864336
Validation loss: 2.461335165198083

Epoch: 6| Step: 7
Training loss: 2.295862506697255
Validation loss: 2.4624531917351056

Epoch: 6| Step: 8
Training loss: 2.7387988244862163
Validation loss: 2.4641633059294143

Epoch: 6| Step: 9
Training loss: 2.7097146741991245
Validation loss: 2.4653085309708818

Epoch: 6| Step: 10
Training loss: 2.831396413221524
Validation loss: 2.4660098485840227

Epoch: 6| Step: 11
Training loss: 2.6671754431158727
Validation loss: 2.4649993315380496

Epoch: 6| Step: 12
Training loss: 2.276148696815445
Validation loss: 2.4634122485200174

Epoch: 6| Step: 13
Training loss: 2.406812824960793
Validation loss: 2.4627842831020756

Epoch: 139| Step: 0
Training loss: 2.6495730685963914
Validation loss: 2.46606166955131

Epoch: 6| Step: 1
Training loss: 2.3492751038328334
Validation loss: 2.456914206558892

Epoch: 6| Step: 2
Training loss: 1.8621563024671466
Validation loss: 2.458899801798133

Epoch: 6| Step: 3
Training loss: 2.440233800505425
Validation loss: 2.4542638884642924

Epoch: 6| Step: 4
Training loss: 2.2947161643175553
Validation loss: 2.4478307560123427

Epoch: 6| Step: 5
Training loss: 2.4369932772825837
Validation loss: 2.455439890668554

Epoch: 6| Step: 6
Training loss: 2.248842895522917
Validation loss: 2.4547333355110155

Epoch: 6| Step: 7
Training loss: 3.179894742843153
Validation loss: 2.4503397427061957

Epoch: 6| Step: 8
Training loss: 2.479790446134165
Validation loss: 2.4473485138523716

Epoch: 6| Step: 9
Training loss: 2.866445003485644
Validation loss: 2.4436016333664843

Epoch: 6| Step: 10
Training loss: 2.731642922218128
Validation loss: 2.4420823119931074

Epoch: 6| Step: 11
Training loss: 2.874979433732486
Validation loss: 2.4489529681961653

Epoch: 6| Step: 12
Training loss: 2.6193136660131286
Validation loss: 2.451257111991176

Epoch: 6| Step: 13
Training loss: 2.393710569848788
Validation loss: 2.4567585011902517

Epoch: 140| Step: 0
Training loss: 2.3717297576140193
Validation loss: 2.461701564149744

Epoch: 6| Step: 1
Training loss: 2.087899760270006
Validation loss: 2.464214536838108

Epoch: 6| Step: 2
Training loss: 2.6206828447649784
Validation loss: 2.465524231914823

Epoch: 6| Step: 3
Training loss: 3.149563798523802
Validation loss: 2.463813352758987

Epoch: 6| Step: 4
Training loss: 2.0948577910890456
Validation loss: 2.4715487554629982

Epoch: 6| Step: 5
Training loss: 2.376766952959764
Validation loss: 2.46309237318121

Epoch: 6| Step: 6
Training loss: 2.602181850631993
Validation loss: 2.4606763590157836

Epoch: 6| Step: 7
Training loss: 3.04654038376919
Validation loss: 2.4583745942182285

Epoch: 6| Step: 8
Training loss: 2.2452073446243723
Validation loss: 2.4551034550256627

Epoch: 6| Step: 9
Training loss: 2.5783071742572994
Validation loss: 2.449609509314325

Epoch: 6| Step: 10
Training loss: 1.9203371547671326
Validation loss: 2.4543695876506506

Epoch: 6| Step: 11
Training loss: 2.969965314566243
Validation loss: 2.4480006237377254

Epoch: 6| Step: 12
Training loss: 2.700816673816719
Validation loss: 2.447973864813731

Epoch: 6| Step: 13
Training loss: 2.4147174033288974
Validation loss: 2.456944013784469

Epoch: 141| Step: 0
Training loss: 2.9297307939509416
Validation loss: 2.456645682627872

Epoch: 6| Step: 1
Training loss: 1.856059347823453
Validation loss: 2.4556663453908087

Epoch: 6| Step: 2
Training loss: 2.7023577179979243
Validation loss: 2.4567834742333217

Epoch: 6| Step: 3
Training loss: 2.37515188032689
Validation loss: 2.4613143390171968

Epoch: 6| Step: 4
Training loss: 2.2789794910105656
Validation loss: 2.4549517784898938

Epoch: 6| Step: 5
Training loss: 2.917555936850795
Validation loss: 2.4728514326618947

Epoch: 6| Step: 6
Training loss: 1.8101462504275758
Validation loss: 2.4768377847031062

Epoch: 6| Step: 7
Training loss: 2.768342488009822
Validation loss: 2.4823353870131153

Epoch: 6| Step: 8
Training loss: 2.810135419575893
Validation loss: 2.477366640804626

Epoch: 6| Step: 9
Training loss: 2.0814093543096033
Validation loss: 2.478554471079503

Epoch: 6| Step: 10
Training loss: 2.7574191150578518
Validation loss: 2.476598376346181

Epoch: 6| Step: 11
Training loss: 2.4715617139281827
Validation loss: 2.4777110792766166

Epoch: 6| Step: 12
Training loss: 2.9822818146139953
Validation loss: 2.481813177579445

Epoch: 6| Step: 13
Training loss: 2.562656118707983
Validation loss: 2.482719765674411

Epoch: 142| Step: 0
Training loss: 2.202907253894883
Validation loss: 2.478131420035783

Epoch: 6| Step: 1
Training loss: 2.211640909941387
Validation loss: 2.4745251672112007

Epoch: 6| Step: 2
Training loss: 2.1445583765645466
Validation loss: 2.4672320242100123

Epoch: 6| Step: 3
Training loss: 2.4977591962602084
Validation loss: 2.468416521429393

Epoch: 6| Step: 4
Training loss: 2.8111645388981237
Validation loss: 2.4684236367101926

Epoch: 6| Step: 5
Training loss: 2.9590594694472747
Validation loss: 2.468006150736221

Epoch: 6| Step: 6
Training loss: 2.9831418990050755
Validation loss: 2.4686925374357314

Epoch: 6| Step: 7
Training loss: 2.1067687711638805
Validation loss: 2.471986283129481

Epoch: 6| Step: 8
Training loss: 2.408490809623633
Validation loss: 2.4689488230289185

Epoch: 6| Step: 9
Training loss: 2.2485312860478364
Validation loss: 2.469757679212422

Epoch: 6| Step: 10
Training loss: 2.7418879592620558
Validation loss: 2.47418839572844

Epoch: 6| Step: 11
Training loss: 2.990515019896826
Validation loss: 2.4685557808108882

Epoch: 6| Step: 12
Training loss: 2.3582775266624645
Validation loss: 2.4664310074261366

Epoch: 6| Step: 13
Training loss: 2.5466286943843555
Validation loss: 2.4695777068876668

Epoch: 143| Step: 0
Training loss: 2.368822294958825
Validation loss: 2.4641792380982284

Epoch: 6| Step: 1
Training loss: 2.190983097340281
Validation loss: 2.4662469818308157

Epoch: 6| Step: 2
Training loss: 1.9775159142163696
Validation loss: 2.459113859201912

Epoch: 6| Step: 3
Training loss: 2.4320943508668726
Validation loss: 2.459468907942928

Epoch: 6| Step: 4
Training loss: 3.06776551655882
Validation loss: 2.4549800233099397

Epoch: 6| Step: 5
Training loss: 3.16358171742677
Validation loss: 2.463389730035892

Epoch: 6| Step: 6
Training loss: 2.554078475732289
Validation loss: 2.4600977519496134

Epoch: 6| Step: 7
Training loss: 2.1082331074449874
Validation loss: 2.4580968861637627

Epoch: 6| Step: 8
Training loss: 2.443360155625375
Validation loss: 2.464227808001481

Epoch: 6| Step: 9
Training loss: 2.634000244273853
Validation loss: 2.4653117062617396

Epoch: 6| Step: 10
Training loss: 2.3177594354260735
Validation loss: 2.458741450512258

Epoch: 6| Step: 11
Training loss: 2.503571343601708
Validation loss: 2.462176508560433

Epoch: 6| Step: 12
Training loss: 2.5851407855007387
Validation loss: 2.4694589329330157

Epoch: 6| Step: 13
Training loss: 2.7419170017994854
Validation loss: 2.467180549945186

Epoch: 144| Step: 0
Training loss: 2.9600786961584604
Validation loss: 2.4734309119471973

Epoch: 6| Step: 1
Training loss: 1.9941907198271378
Validation loss: 2.4781553679469996

Epoch: 6| Step: 2
Training loss: 2.715631560042242
Validation loss: 2.481822528013848

Epoch: 6| Step: 3
Training loss: 2.618813991447609
Validation loss: 2.4817176378172334

Epoch: 6| Step: 4
Training loss: 2.8342081477169176
Validation loss: 2.472668093813171

Epoch: 6| Step: 5
Training loss: 2.390720340597838
Validation loss: 2.4776346350873313

Epoch: 6| Step: 6
Training loss: 2.7557110006401384
Validation loss: 2.479450503431245

Epoch: 6| Step: 7
Training loss: 2.031641526268787
Validation loss: 2.4812601584123266

Epoch: 6| Step: 8
Training loss: 2.5521743965770076
Validation loss: 2.4830326796526996

Epoch: 6| Step: 9
Training loss: 2.798142130145137
Validation loss: 2.477388358579178

Epoch: 6| Step: 10
Training loss: 2.229940749437571
Validation loss: 2.4755847978557943

Epoch: 6| Step: 11
Training loss: 2.903942217333418
Validation loss: 2.4785493247704857

Epoch: 6| Step: 12
Training loss: 2.2242425979606
Validation loss: 2.4696283025515955

Epoch: 6| Step: 13
Training loss: 2.4151330444461
Validation loss: 2.469876269872153

Epoch: 145| Step: 0
Training loss: 1.9829280113199754
Validation loss: 2.471304847109931

Epoch: 6| Step: 1
Training loss: 2.673662089953112
Validation loss: 2.465817379587777

Epoch: 6| Step: 2
Training loss: 2.5140206095807427
Validation loss: 2.46244860884329

Epoch: 6| Step: 3
Training loss: 2.138065116197604
Validation loss: 2.4648948539195974

Epoch: 6| Step: 4
Training loss: 2.319766715751615
Validation loss: 2.457090246708238

Epoch: 6| Step: 5
Training loss: 2.9294438375235305
Validation loss: 2.4563064921372355

Epoch: 6| Step: 6
Training loss: 2.990068048576759
Validation loss: 2.453569505595189

Epoch: 6| Step: 7
Training loss: 1.8213640703807077
Validation loss: 2.454634232553182

Epoch: 6| Step: 8
Training loss: 3.1748470419737074
Validation loss: 2.4542398531438696

Epoch: 6| Step: 9
Training loss: 2.577615953532692
Validation loss: 2.453682854268592

Epoch: 6| Step: 10
Training loss: 2.653235306710175
Validation loss: 2.4572196932659933

Epoch: 6| Step: 11
Training loss: 2.4082636148817738
Validation loss: 2.457758938771011

Epoch: 6| Step: 12
Training loss: 2.2121856724795785
Validation loss: 2.4570976697134674

Epoch: 6| Step: 13
Training loss: 2.783502588056071
Validation loss: 2.457463778787995

Epoch: 146| Step: 0
Training loss: 2.5045368989346115
Validation loss: 2.460815668874816

Epoch: 6| Step: 1
Training loss: 2.862289527584811
Validation loss: 2.461495617748128

Epoch: 6| Step: 2
Training loss: 3.413818630002157
Validation loss: 2.4602654240760473

Epoch: 6| Step: 3
Training loss: 2.2175398199211194
Validation loss: 2.463495102187601

Epoch: 6| Step: 4
Training loss: 2.41586976779054
Validation loss: 2.4551505212420186

Epoch: 6| Step: 5
Training loss: 2.0598254346492637
Validation loss: 2.4587779262697693

Epoch: 6| Step: 6
Training loss: 2.282697453560096
Validation loss: 2.4703117291784884

Epoch: 6| Step: 7
Training loss: 2.2958755913899465
Validation loss: 2.468747505154536

Epoch: 6| Step: 8
Training loss: 2.3441973450035682
Validation loss: 2.467661009807493

Epoch: 6| Step: 9
Training loss: 2.6513206070378796
Validation loss: 2.4651724409305236

Epoch: 6| Step: 10
Training loss: 2.9950775452320304
Validation loss: 2.4625018682973008

Epoch: 6| Step: 11
Training loss: 2.311041500905748
Validation loss: 2.4673544403863055

Epoch: 6| Step: 12
Training loss: 2.0538620831952445
Validation loss: 2.465891168665337

Epoch: 6| Step: 13
Training loss: 2.7153432263104276
Validation loss: 2.4700461739305353

Epoch: 147| Step: 0
Training loss: 2.9156596125503613
Validation loss: 2.479497155566032

Epoch: 6| Step: 1
Training loss: 2.27012744629823
Validation loss: 2.4714803445734037

Epoch: 6| Step: 2
Training loss: 2.9244334397629084
Validation loss: 2.4767445879401837

Epoch: 6| Step: 3
Training loss: 1.8624323864639436
Validation loss: 2.4704527153807434

Epoch: 6| Step: 4
Training loss: 2.6345747757683764
Validation loss: 2.464912740041146

Epoch: 6| Step: 5
Training loss: 1.9734592729516618
Validation loss: 2.464690705962297

Epoch: 6| Step: 6
Training loss: 2.683388514770758
Validation loss: 2.45891792544913

Epoch: 6| Step: 7
Training loss: 2.9427845272676323
Validation loss: 2.4662331576061467

Epoch: 6| Step: 8
Training loss: 2.4513400441875763
Validation loss: 2.4591575361612543

Epoch: 6| Step: 9
Training loss: 2.1219930130019287
Validation loss: 2.464507275974675

Epoch: 6| Step: 10
Training loss: 2.903192860577052
Validation loss: 2.458464478911671

Epoch: 6| Step: 11
Training loss: 2.748319372400373
Validation loss: 2.462171021382257

Epoch: 6| Step: 12
Training loss: 2.2137476447516673
Validation loss: 2.4656344363213725

Epoch: 6| Step: 13
Training loss: 2.5405099352391014
Validation loss: 2.460503207845392

Epoch: 148| Step: 0
Training loss: 2.6435516210847565
Validation loss: 2.452379036323727

Epoch: 6| Step: 1
Training loss: 2.483349474485369
Validation loss: 2.4545672767056574

Epoch: 6| Step: 2
Training loss: 2.4681638190741846
Validation loss: 2.446669733069817

Epoch: 6| Step: 3
Training loss: 2.544658234437452
Validation loss: 2.4607462490789165

Epoch: 6| Step: 4
Training loss: 2.5054597364976625
Validation loss: 2.453932416667686

Epoch: 6| Step: 5
Training loss: 2.2765789547170434
Validation loss: 2.4448954558693536

Epoch: 6| Step: 6
Training loss: 2.3701661760684534
Validation loss: 2.4467290283418586

Epoch: 6| Step: 7
Training loss: 2.384685243193836
Validation loss: 2.451805667070326

Epoch: 6| Step: 8
Training loss: 2.5825390568869775
Validation loss: 2.4496288939736384

Epoch: 6| Step: 9
Training loss: 2.2831534191820007
Validation loss: 2.4535131127200325

Epoch: 6| Step: 10
Training loss: 2.2687181076456433
Validation loss: 2.45497702888883

Epoch: 6| Step: 11
Training loss: 2.634023054150928
Validation loss: 2.4589204787481203

Epoch: 6| Step: 12
Training loss: 3.2695919199866803
Validation loss: 2.4695096195299024

Epoch: 6| Step: 13
Training loss: 2.567212679200261
Validation loss: 2.4652717327587057

Epoch: 149| Step: 0
Training loss: 2.538666961378727
Validation loss: 2.4637830238316063

Epoch: 6| Step: 1
Training loss: 2.6593506611338964
Validation loss: 2.4692889160532636

Epoch: 6| Step: 2
Training loss: 2.924343759329517
Validation loss: 2.476082724259039

Epoch: 6| Step: 3
Training loss: 2.8146847186874755
Validation loss: 2.475501329529894

Epoch: 6| Step: 4
Training loss: 2.6765826953275247
Validation loss: 2.469505339368604

Epoch: 6| Step: 5
Training loss: 2.2625403089778877
Validation loss: 2.4745570104247765

Epoch: 6| Step: 6
Training loss: 1.9614116201917542
Validation loss: 2.469018382360793

Epoch: 6| Step: 7
Training loss: 2.4933281563213816
Validation loss: 2.464561176173578

Epoch: 6| Step: 8
Training loss: 2.405093422897283
Validation loss: 2.462023831333498

Epoch: 6| Step: 9
Training loss: 2.2983330490890377
Validation loss: 2.4686408763219614

Epoch: 6| Step: 10
Training loss: 2.228840836809591
Validation loss: 2.466189815420417

Epoch: 6| Step: 11
Training loss: 2.8406230796412997
Validation loss: 2.4634087723634464

Epoch: 6| Step: 12
Training loss: 2.649930819921968
Validation loss: 2.46398792432173

Epoch: 6| Step: 13
Training loss: 2.3552632661329835
Validation loss: 2.4592006952802676

Epoch: 150| Step: 0
Training loss: 2.4432800426456995
Validation loss: 2.4648133773262404

Epoch: 6| Step: 1
Training loss: 2.7299015618487115
Validation loss: 2.466945721224897

Epoch: 6| Step: 2
Training loss: 3.05331538376953
Validation loss: 2.46569773957935

Epoch: 6| Step: 3
Training loss: 2.8042852171674038
Validation loss: 2.46644389611458

Epoch: 6| Step: 4
Training loss: 2.3768552260036495
Validation loss: 2.463644002733882

Epoch: 6| Step: 5
Training loss: 2.2060316674803255
Validation loss: 2.4660899965973555

Epoch: 6| Step: 6
Training loss: 2.677120124376072
Validation loss: 2.461247613329979

Epoch: 6| Step: 7
Training loss: 2.314266148994131
Validation loss: 2.4699330613748063

Epoch: 6| Step: 8
Training loss: 2.67849019608618
Validation loss: 2.466439868406676

Epoch: 6| Step: 9
Training loss: 2.0565796469028803
Validation loss: 2.466623017745405

Epoch: 6| Step: 10
Training loss: 2.702361423493089
Validation loss: 2.4603825503532253

Epoch: 6| Step: 11
Training loss: 2.091173323042448
Validation loss: 2.4617231779987847

Epoch: 6| Step: 12
Training loss: 2.4789165295839495
Validation loss: 2.4644467476934446

Epoch: 6| Step: 13
Training loss: 2.4195919966593236
Validation loss: 2.468141199044128

Epoch: 151| Step: 0
Training loss: 2.533459770243093
Validation loss: 2.4705521649266213

Epoch: 6| Step: 1
Training loss: 2.913823913134239
Validation loss: 2.468935368012936

Epoch: 6| Step: 2
Training loss: 2.7075141156815765
Validation loss: 2.4744078592506753

Epoch: 6| Step: 3
Training loss: 2.7113414100724897
Validation loss: 2.4678213006427403

Epoch: 6| Step: 4
Training loss: 2.2716315263627025
Validation loss: 2.4700597998552674

Epoch: 6| Step: 5
Training loss: 1.864677753579643
Validation loss: 2.4722849008089303

Epoch: 6| Step: 6
Training loss: 2.7023469543879166
Validation loss: 2.4782538349644394

Epoch: 6| Step: 7
Training loss: 2.7807771087836852
Validation loss: 2.477369287367842

Epoch: 6| Step: 8
Training loss: 2.203014073386242
Validation loss: 2.470171426649273

Epoch: 6| Step: 9
Training loss: 2.6169098208570443
Validation loss: 2.4731847631126294

Epoch: 6| Step: 10
Training loss: 2.3715852985198564
Validation loss: 2.467821630730157

Epoch: 6| Step: 11
Training loss: 2.297699241923418
Validation loss: 2.4564007393330893

Epoch: 6| Step: 12
Training loss: 2.9316572154552216
Validation loss: 2.470014111688331

Epoch: 6| Step: 13
Training loss: 2.2532199495707914
Validation loss: 2.464327782876687

Epoch: 152| Step: 0
Training loss: 2.3569492223398094
Validation loss: 2.461079765930611

Epoch: 6| Step: 1
Training loss: 2.5310785682929855
Validation loss: 2.46305094395543

Epoch: 6| Step: 2
Training loss: 3.0036727358135455
Validation loss: 2.464721160758129

Epoch: 6| Step: 3
Training loss: 2.6477842172250985
Validation loss: 2.4563152197800955

Epoch: 6| Step: 4
Training loss: 3.0027769270088087
Validation loss: 2.4571132595686556

Epoch: 6| Step: 5
Training loss: 2.9166568937592037
Validation loss: 2.4562098065453473

Epoch: 6| Step: 6
Training loss: 2.382651802022313
Validation loss: 2.4638985394854265

Epoch: 6| Step: 7
Training loss: 2.4458867090521723
Validation loss: 2.4573527551819394

Epoch: 6| Step: 8
Training loss: 2.324559085835953
Validation loss: 2.456865847892474

Epoch: 6| Step: 9
Training loss: 2.4518944636497846
Validation loss: 2.4610651861096167

Epoch: 6| Step: 10
Training loss: 1.645741866584068
Validation loss: 2.4621808660167437

Epoch: 6| Step: 11
Training loss: 2.7621698725984127
Validation loss: 2.462790801535917

Epoch: 6| Step: 12
Training loss: 2.5096783218339462
Validation loss: 2.4590501440664285

Epoch: 6| Step: 13
Training loss: 1.916209297618839
Validation loss: 2.4572412414249793

Epoch: 153| Step: 0
Training loss: 2.1239733740508044
Validation loss: 2.460340381013563

Epoch: 6| Step: 1
Training loss: 3.1861701135808462
Validation loss: 2.4556350501192945

Epoch: 6| Step: 2
Training loss: 2.815616068259583
Validation loss: 2.453632197014565

Epoch: 6| Step: 3
Training loss: 2.8005552320381994
Validation loss: 2.4594465310771234

Epoch: 6| Step: 4
Training loss: 2.7797966063488273
Validation loss: 2.4656962166458127

Epoch: 6| Step: 5
Training loss: 2.6235244781998173
Validation loss: 2.461485544367219

Epoch: 6| Step: 6
Training loss: 2.052901735751522
Validation loss: 2.45777956873227

Epoch: 6| Step: 7
Training loss: 2.0184516898916036
Validation loss: 2.469177418338963

Epoch: 6| Step: 8
Training loss: 2.653944922685647
Validation loss: 2.4701044254391054

Epoch: 6| Step: 9
Training loss: 2.8017980626520207
Validation loss: 2.466068856079574

Epoch: 6| Step: 10
Training loss: 2.5230929963295927
Validation loss: 2.469668173360586

Epoch: 6| Step: 11
Training loss: 2.3229209546333274
Validation loss: 2.4705189029330974

Epoch: 6| Step: 12
Training loss: 2.0349542733568535
Validation loss: 2.4617767033383027

Epoch: 6| Step: 13
Training loss: 2.169694423343074
Validation loss: 2.465438891833879

Epoch: 154| Step: 0
Training loss: 2.0328516587657424
Validation loss: 2.465789847107075

Epoch: 6| Step: 1
Training loss: 2.448663237876302
Validation loss: 2.461041653159846

Epoch: 6| Step: 2
Training loss: 3.335573842151499
Validation loss: 2.4622454522982644

Epoch: 6| Step: 3
Training loss: 2.634709701906051
Validation loss: 2.4676722898436814

Epoch: 6| Step: 4
Training loss: 2.1754977522680394
Validation loss: 2.4695718902104806

Epoch: 6| Step: 5
Training loss: 2.931827343529224
Validation loss: 2.4779513182354576

Epoch: 6| Step: 6
Training loss: 2.4691044033962206
Validation loss: 2.478968834129573

Epoch: 6| Step: 7
Training loss: 2.6475619779109767
Validation loss: 2.486433412011213

Epoch: 6| Step: 8
Training loss: 2.335404555340096
Validation loss: 2.4658893155052266

Epoch: 6| Step: 9
Training loss: 2.09107048180775
Validation loss: 2.4621683584825584

Epoch: 6| Step: 10
Training loss: 2.278115300496702
Validation loss: 2.4811610579864696

Epoch: 6| Step: 11
Training loss: 2.2040288707829188
Validation loss: 2.4800068102250883

Epoch: 6| Step: 12
Training loss: 3.1629341279852214
Validation loss: 2.4724694975465145

Epoch: 6| Step: 13
Training loss: 2.394880807574568
Validation loss: 2.4790793865665313

Epoch: 155| Step: 0
Training loss: 2.8478493121390533
Validation loss: 2.4754144071183304

Epoch: 6| Step: 1
Training loss: 2.4256305739926756
Validation loss: 2.4719814285662984

Epoch: 6| Step: 2
Training loss: 2.639407176156538
Validation loss: 2.4792961813384453

Epoch: 6| Step: 3
Training loss: 2.5348464470880563
Validation loss: 2.476426338439896

Epoch: 6| Step: 4
Training loss: 2.76132065468049
Validation loss: 2.4798865568712545

Epoch: 6| Step: 5
Training loss: 2.249877396528077
Validation loss: 2.47607245345201

Epoch: 6| Step: 6
Training loss: 2.6666535337442623
Validation loss: 2.4776439371392653

Epoch: 6| Step: 7
Training loss: 2.4969208828908176
Validation loss: 2.4796789158346217

Epoch: 6| Step: 8
Training loss: 2.167072722703564
Validation loss: 2.476026892280285

Epoch: 6| Step: 9
Training loss: 2.4741189255374603
Validation loss: 2.483182624963106

Epoch: 6| Step: 10
Training loss: 2.8361248028065913
Validation loss: 2.4786705407561582

Epoch: 6| Step: 11
Training loss: 2.5795588349777123
Validation loss: 2.482453704958066

Epoch: 6| Step: 12
Training loss: 2.5603478861407067
Validation loss: 2.4762336841593258

Epoch: 6| Step: 13
Training loss: 2.86916189789595
Validation loss: 2.475870751845326

Epoch: 156| Step: 0
Training loss: 2.449931501871243
Validation loss: 2.4721182367932135

Epoch: 6| Step: 1
Training loss: 2.700356449334179
Validation loss: 2.4710029430189198

Epoch: 6| Step: 2
Training loss: 2.5763384553326416
Validation loss: 2.4777040949111937

Epoch: 6| Step: 3
Training loss: 2.4158804261257223
Validation loss: 2.4739494457419853

Epoch: 6| Step: 4
Training loss: 2.789171574701011
Validation loss: 2.475231531019126

Epoch: 6| Step: 5
Training loss: 1.790590857801104
Validation loss: 2.4750007976183905

Epoch: 6| Step: 6
Training loss: 2.192090150462039
Validation loss: 2.4696878510892075

Epoch: 6| Step: 7
Training loss: 2.7068471694604255
Validation loss: 2.4751562704978873

Epoch: 6| Step: 8
Training loss: 2.3749947798822157
Validation loss: 2.4672546686809964

Epoch: 6| Step: 9
Training loss: 2.886370027408064
Validation loss: 2.4568858222396366

Epoch: 6| Step: 10
Training loss: 2.7733485247886733
Validation loss: 2.4597788833342427

Epoch: 6| Step: 11
Training loss: 2.386343419208181
Validation loss: 2.459868522867743

Epoch: 6| Step: 12
Training loss: 2.999678594538459
Validation loss: 2.459331250639761

Epoch: 6| Step: 13
Training loss: 2.3755954196837603
Validation loss: 2.454472149638416

Epoch: 157| Step: 0
Training loss: 2.461762595747166
Validation loss: 2.4504795591234387

Epoch: 6| Step: 1
Training loss: 3.2764703725834288
Validation loss: 2.454973953533618

Epoch: 6| Step: 2
Training loss: 2.2285834526953305
Validation loss: 2.452245307527161

Epoch: 6| Step: 3
Training loss: 2.290392388454612
Validation loss: 2.4559323390976524

Epoch: 6| Step: 4
Training loss: 3.199406395929707
Validation loss: 2.4580005700711074

Epoch: 6| Step: 5
Training loss: 1.931766517478693
Validation loss: 2.4540522740316706

Epoch: 6| Step: 6
Training loss: 2.7075888759858473
Validation loss: 2.4570384467686153

Epoch: 6| Step: 7
Training loss: 2.367602321423699
Validation loss: 2.456513811783979

Epoch: 6| Step: 8
Training loss: 2.571907638398327
Validation loss: 2.4514823402864705

Epoch: 6| Step: 9
Training loss: 2.82011949718874
Validation loss: 2.4593841655969184

Epoch: 6| Step: 10
Training loss: 1.9011827251061229
Validation loss: 2.4633866651833127

Epoch: 6| Step: 11
Training loss: 3.1008819679055564
Validation loss: 2.4643879593461597

Epoch: 6| Step: 12
Training loss: 1.9579857727484642
Validation loss: 2.4677781554220912

Epoch: 6| Step: 13
Training loss: 2.2793853664136314
Validation loss: 2.4652463782613703

Epoch: 158| Step: 0
Training loss: 2.9101914781319955
Validation loss: 2.4550673697758776

Epoch: 6| Step: 1
Training loss: 3.3087309501511726
Validation loss: 2.4466395895375204

Epoch: 6| Step: 2
Training loss: 3.020020123345233
Validation loss: 2.4530952759579985

Epoch: 6| Step: 3
Training loss: 2.3471815292572966
Validation loss: 2.453250420152346

Epoch: 6| Step: 4
Training loss: 2.231533992015253
Validation loss: 2.4644660962667833

Epoch: 6| Step: 5
Training loss: 2.4889182528493086
Validation loss: 2.464632358745959

Epoch: 6| Step: 6
Training loss: 2.019098054625658
Validation loss: 2.4710776546507662

Epoch: 6| Step: 7
Training loss: 2.335486939524591
Validation loss: 2.465323988312745

Epoch: 6| Step: 8
Training loss: 2.5276356076047715
Validation loss: 2.4556927373185804

Epoch: 6| Step: 9
Training loss: 2.404889700693914
Validation loss: 2.4547429509721983

Epoch: 6| Step: 10
Training loss: 1.9068830095721196
Validation loss: 2.4597136991747965

Epoch: 6| Step: 11
Training loss: 2.3626924143752377
Validation loss: 2.4585770443087234

Epoch: 6| Step: 12
Training loss: 2.665914210811507
Validation loss: 2.468452145921428

Epoch: 6| Step: 13
Training loss: 2.539849825346952
Validation loss: 2.473358046668693

Epoch: 159| Step: 0
Training loss: 2.257857906320563
Validation loss: 2.4723127547366825

Epoch: 6| Step: 1
Training loss: 2.266857154172242
Validation loss: 2.477377018524194

Epoch: 6| Step: 2
Training loss: 2.326820161487305
Validation loss: 2.477573481245369

Epoch: 6| Step: 3
Training loss: 2.8926478550740247
Validation loss: 2.477441000134851

Epoch: 6| Step: 4
Training loss: 2.550506997663287
Validation loss: 2.472888335012377

Epoch: 6| Step: 5
Training loss: 2.276446576331757
Validation loss: 2.4732450052471386

Epoch: 6| Step: 6
Training loss: 2.4051719331251697
Validation loss: 2.464608964655092

Epoch: 6| Step: 7
Training loss: 2.6977254929923413
Validation loss: 2.4643419080320457

Epoch: 6| Step: 8
Training loss: 2.5326626450333576
Validation loss: 2.4590073701340334

Epoch: 6| Step: 9
Training loss: 2.4410948043534795
Validation loss: 2.4557323327689664

Epoch: 6| Step: 10
Training loss: 2.7340376291594657
Validation loss: 2.4578245062028574

Epoch: 6| Step: 11
Training loss: 2.710774265618704
Validation loss: 2.4541159408154205

Epoch: 6| Step: 12
Training loss: 3.0268381004124416
Validation loss: 2.4521423283051056

Epoch: 6| Step: 13
Training loss: 2.4235637068704765
Validation loss: 2.4581672698575905

Epoch: 160| Step: 0
Training loss: 2.8918569877794016
Validation loss: 2.453165705964729

Epoch: 6| Step: 1
Training loss: 2.0093705481306388
Validation loss: 2.460130904482946

Epoch: 6| Step: 2
Training loss: 2.3553938466272455
Validation loss: 2.468384228743375

Epoch: 6| Step: 3
Training loss: 2.3930932560885347
Validation loss: 2.473725596406014

Epoch: 6| Step: 4
Training loss: 2.636127049494284
Validation loss: 2.4653753321035796

Epoch: 6| Step: 5
Training loss: 2.9342605909767587
Validation loss: 2.471627743166516

Epoch: 6| Step: 6
Training loss: 2.3994027348252147
Validation loss: 2.4687091486001504

Epoch: 6| Step: 7
Training loss: 2.344760117614438
Validation loss: 2.470673033439323

Epoch: 6| Step: 8
Training loss: 2.879122887668208
Validation loss: 2.4730248600838474

Epoch: 6| Step: 9
Training loss: 3.226394612006227
Validation loss: 2.4729982192859237

Epoch: 6| Step: 10
Training loss: 2.4812121140977172
Validation loss: 2.4715209893913492

Epoch: 6| Step: 11
Training loss: 2.3914410563356427
Validation loss: 2.479083954742982

Epoch: 6| Step: 12
Training loss: 2.602379014925189
Validation loss: 2.4672706614147253

Epoch: 6| Step: 13
Training loss: 1.613040933883057
Validation loss: 2.4682597546769305

Epoch: 161| Step: 0
Training loss: 2.648475309118946
Validation loss: 2.4662901457818673

Epoch: 6| Step: 1
Training loss: 2.580478957615388
Validation loss: 2.4593866618621956

Epoch: 6| Step: 2
Training loss: 2.5766802814645406
Validation loss: 2.461580787827411

Epoch: 6| Step: 3
Training loss: 2.5368291334473296
Validation loss: 2.464692560023621

Epoch: 6| Step: 4
Training loss: 2.761038560210494
Validation loss: 2.458420369390945

Epoch: 6| Step: 5
Training loss: 2.844154580648789
Validation loss: 2.4568062392699956

Epoch: 6| Step: 6
Training loss: 2.1938056525754446
Validation loss: 2.4653275181822263

Epoch: 6| Step: 7
Training loss: 2.5017946477485267
Validation loss: 2.4689038224726696

Epoch: 6| Step: 8
Training loss: 2.452235163739157
Validation loss: 2.4546753829440067

Epoch: 6| Step: 9
Training loss: 2.33922404392034
Validation loss: 2.4724910574437273

Epoch: 6| Step: 10
Training loss: 2.944690588093583
Validation loss: 2.474710841257689

Epoch: 6| Step: 11
Training loss: 2.8012067612558376
Validation loss: 2.468955421753977

Epoch: 6| Step: 12
Training loss: 2.2142917813160836
Validation loss: 2.4713831351498134

Epoch: 6| Step: 13
Training loss: 1.9321241554662656
Validation loss: 2.4672223205235206

Epoch: 162| Step: 0
Training loss: 2.2373865279935368
Validation loss: 2.466429170782551

Epoch: 6| Step: 1
Training loss: 1.9219397557211781
Validation loss: 2.466147471463963

Epoch: 6| Step: 2
Training loss: 2.5454753001716948
Validation loss: 2.4635825822482356

Epoch: 6| Step: 3
Training loss: 2.5471500178033883
Validation loss: 2.473736374920163

Epoch: 6| Step: 4
Training loss: 2.6107576099384566
Validation loss: 2.4687532996304506

Epoch: 6| Step: 5
Training loss: 2.3690443153020566
Validation loss: 2.467062409547421

Epoch: 6| Step: 6
Training loss: 2.959847362809916
Validation loss: 2.468754023938984

Epoch: 6| Step: 7
Training loss: 2.2732471504357177
Validation loss: 2.4736789960599777

Epoch: 6| Step: 8
Training loss: 2.803681684691525
Validation loss: 2.4769003043052105

Epoch: 6| Step: 9
Training loss: 2.9904381640836526
Validation loss: 2.4659452480983544

Epoch: 6| Step: 10
Training loss: 1.4333231408104266
Validation loss: 2.469754871645101

Epoch: 6| Step: 11
Training loss: 2.254620364558355
Validation loss: 2.4772934020608472

Epoch: 6| Step: 12
Training loss: 3.1402417608602033
Validation loss: 2.4716954426066744

Epoch: 6| Step: 13
Training loss: 2.7399282685517665
Validation loss: 2.473496843093226

Epoch: 163| Step: 0
Training loss: 3.0163511676792965
Validation loss: 2.472777176361289

Epoch: 6| Step: 1
Training loss: 2.60353970927884
Validation loss: 2.464319575414751

Epoch: 6| Step: 2
Training loss: 2.6928691016680073
Validation loss: 2.4590526891485114

Epoch: 6| Step: 3
Training loss: 1.8575054354479035
Validation loss: 2.470121598191389

Epoch: 6| Step: 4
Training loss: 2.7585251187343713
Validation loss: 2.4721453371367637

Epoch: 6| Step: 5
Training loss: 3.0747688702814484
Validation loss: 2.4695169408412423

Epoch: 6| Step: 6
Training loss: 2.621910820626506
Validation loss: 2.4770346992622825

Epoch: 6| Step: 7
Training loss: 1.913586366560861
Validation loss: 2.4783242715166662

Epoch: 6| Step: 8
Training loss: 3.0283377904304563
Validation loss: 2.4711782046436954

Epoch: 6| Step: 9
Training loss: 2.091518522490163
Validation loss: 2.4686440875677422

Epoch: 6| Step: 10
Training loss: 2.003872460271894
Validation loss: 2.4652296792891635

Epoch: 6| Step: 11
Training loss: 1.8612645909933243
Validation loss: 2.458766225642658

Epoch: 6| Step: 12
Training loss: 2.653169528690851
Validation loss: 2.4547210652213383

Epoch: 6| Step: 13
Training loss: 2.9209568804751664
Validation loss: 2.467837313857013

Epoch: 164| Step: 0
Training loss: 1.9346202245028403
Validation loss: 2.4717664679529823

Epoch: 6| Step: 1
Training loss: 2.758351389507959
Validation loss: 2.4689446384624256

Epoch: 6| Step: 2
Training loss: 2.547909392010921
Validation loss: 2.465755416972978

Epoch: 6| Step: 3
Training loss: 2.5330129065231857
Validation loss: 2.4615107277421964

Epoch: 6| Step: 4
Training loss: 2.596490721840445
Validation loss: 2.470999984095908

Epoch: 6| Step: 5
Training loss: 2.749473174523941
Validation loss: 2.464612995355086

Epoch: 6| Step: 6
Training loss: 1.8516770983292554
Validation loss: 2.471474813739548

Epoch: 6| Step: 7
Training loss: 2.0979642446578524
Validation loss: 2.4680537759114594

Epoch: 6| Step: 8
Training loss: 2.734959131245833
Validation loss: 2.4673685160051377

Epoch: 6| Step: 9
Training loss: 2.3103780547740334
Validation loss: 2.471005757208714

Epoch: 6| Step: 10
Training loss: 2.243498415642679
Validation loss: 2.478485500031373

Epoch: 6| Step: 11
Training loss: 2.682954892627079
Validation loss: 2.473912013105467

Epoch: 6| Step: 12
Training loss: 2.808226835984107
Validation loss: 2.468255456249268

Epoch: 6| Step: 13
Training loss: 3.251059726191095
Validation loss: 2.4632668022605584

Epoch: 165| Step: 0
Training loss: 2.6858758676324874
Validation loss: 2.461421551606496

Epoch: 6| Step: 1
Training loss: 2.619119415083537
Validation loss: 2.4667348725537526

Epoch: 6| Step: 2
Training loss: 2.4552590387735562
Validation loss: 2.4590834319160675

Epoch: 6| Step: 3
Training loss: 2.3642877626471934
Validation loss: 2.460410425973375

Epoch: 6| Step: 4
Training loss: 2.3970213446273525
Validation loss: 2.459113843043071

Epoch: 6| Step: 5
Training loss: 2.7020405264242817
Validation loss: 2.4587006186779004

Epoch: 6| Step: 6
Training loss: 2.044071636497375
Validation loss: 2.4586260077185957

Epoch: 6| Step: 7
Training loss: 2.8729336818074094
Validation loss: 2.4598205776738964

Epoch: 6| Step: 8
Training loss: 2.4462382846214523
Validation loss: 2.462349187037785

Epoch: 6| Step: 9
Training loss: 2.3870807379439203
Validation loss: 2.4593222428657144

Epoch: 6| Step: 10
Training loss: 2.2754922606726984
Validation loss: 2.460976889966155

Epoch: 6| Step: 11
Training loss: 2.4286455575865253
Validation loss: 2.4578367852500427

Epoch: 6| Step: 12
Training loss: 2.4635327414955155
Validation loss: 2.4618762451075757

Epoch: 6| Step: 13
Training loss: 2.9502281230073044
Validation loss: 2.4606030433688675

Epoch: 166| Step: 0
Training loss: 2.3845118732088797
Validation loss: 2.45982754012359

Epoch: 6| Step: 1
Training loss: 3.1728339789159583
Validation loss: 2.4560198458455824

Epoch: 6| Step: 2
Training loss: 2.531702071899333
Validation loss: 2.4592524819916908

Epoch: 6| Step: 3
Training loss: 2.6289127797560066
Validation loss: 2.461078070607026

Epoch: 6| Step: 4
Training loss: 2.597126429168768
Validation loss: 2.4635308381717014

Epoch: 6| Step: 5
Training loss: 2.724499115712566
Validation loss: 2.464648320127797

Epoch: 6| Step: 6
Training loss: 2.4789832765939193
Validation loss: 2.4667313769160644

Epoch: 6| Step: 7
Training loss: 2.8135246953319384
Validation loss: 2.466769135984428

Epoch: 6| Step: 8
Training loss: 2.0815933081857256
Validation loss: 2.4691562398827056

Epoch: 6| Step: 9
Training loss: 2.4276882176449854
Validation loss: 2.4653363911879858

Epoch: 6| Step: 10
Training loss: 2.62388877963241
Validation loss: 2.462877685448348

Epoch: 6| Step: 11
Training loss: 1.832262362154921
Validation loss: 2.463410006359264

Epoch: 6| Step: 12
Training loss: 2.1563888726226312
Validation loss: 2.457474305234266

Epoch: 6| Step: 13
Training loss: 2.3693157235118885
Validation loss: 2.4629444315087565

Epoch: 167| Step: 0
Training loss: 2.4588790761931203
Validation loss: 2.4712956819893104

Epoch: 6| Step: 1
Training loss: 2.715557986926239
Validation loss: 2.4670677972592276

Epoch: 6| Step: 2
Training loss: 2.2708729965059176
Validation loss: 2.473178890651109

Epoch: 6| Step: 3
Training loss: 2.3592782916528945
Validation loss: 2.457632285445148

Epoch: 6| Step: 4
Training loss: 3.2329677892957016
Validation loss: 2.468359163790082

Epoch: 6| Step: 5
Training loss: 1.9344719635999126
Validation loss: 2.464721080147732

Epoch: 6| Step: 6
Training loss: 2.9174312316059656
Validation loss: 2.4626970973908286

Epoch: 6| Step: 7
Training loss: 2.7231999953026778
Validation loss: 2.473913049116115

Epoch: 6| Step: 8
Training loss: 2.4674231911312012
Validation loss: 2.468631709359268

Epoch: 6| Step: 9
Training loss: 2.2782179657814514
Validation loss: 2.4698683704407136

Epoch: 6| Step: 10
Training loss: 2.433252889357305
Validation loss: 2.47181209157828

Epoch: 6| Step: 11
Training loss: 2.205580621166418
Validation loss: 2.4681631106920463

Epoch: 6| Step: 12
Training loss: 2.4031500726986694
Validation loss: 2.470353117063393

Epoch: 6| Step: 13
Training loss: 2.486179871795167
Validation loss: 2.47187838741027

Epoch: 168| Step: 0
Training loss: 2.239508859741646
Validation loss: 2.4687010764251998

Epoch: 6| Step: 1
Training loss: 2.3613833538503552
Validation loss: 2.4642470373550167

Epoch: 6| Step: 2
Training loss: 2.429945953458833
Validation loss: 2.4675733764209826

Epoch: 6| Step: 3
Training loss: 2.6905602175969565
Validation loss: 2.463178883482397

Epoch: 6| Step: 4
Training loss: 2.6559482178638425
Validation loss: 2.4682248518718852

Epoch: 6| Step: 5
Training loss: 2.301979258214336
Validation loss: 2.473399728987465

Epoch: 6| Step: 6
Training loss: 2.9699466903474647
Validation loss: 2.4820815082377057

Epoch: 6| Step: 7
Training loss: 2.0642105869532883
Validation loss: 2.4722593449961714

Epoch: 6| Step: 8
Training loss: 2.773968369087022
Validation loss: 2.4749981806327734

Epoch: 6| Step: 9
Training loss: 2.574322572504446
Validation loss: 2.4717216473065724

Epoch: 6| Step: 10
Training loss: 2.2177603220247373
Validation loss: 2.460605966347261

Epoch: 6| Step: 11
Training loss: 2.107844836168696
Validation loss: 2.4619123596806927

Epoch: 6| Step: 12
Training loss: 2.7647604587811396
Validation loss: 2.4602182295902226

Epoch: 6| Step: 13
Training loss: 2.9925731280959456
Validation loss: 2.4511445751924303

Epoch: 169| Step: 0
Training loss: 3.2974138587881154
Validation loss: 2.4572826392339584

Epoch: 6| Step: 1
Training loss: 1.9755572752068415
Validation loss: 2.449470957253518

Epoch: 6| Step: 2
Training loss: 2.4159091441837046
Validation loss: 2.446074597569938

Epoch: 6| Step: 3
Training loss: 2.7680465527958202
Validation loss: 2.447685674495974

Epoch: 6| Step: 4
Training loss: 2.9799114621214033
Validation loss: 2.462454159950595

Epoch: 6| Step: 5
Training loss: 2.387276891699327
Validation loss: 2.4694746378437937

Epoch: 6| Step: 6
Training loss: 2.938227461971951
Validation loss: 2.4734168065663997

Epoch: 6| Step: 7
Training loss: 2.73829439734161
Validation loss: 2.472398805800658

Epoch: 6| Step: 8
Training loss: 2.4042046511430004
Validation loss: 2.4798794584563817

Epoch: 6| Step: 9
Training loss: 2.5823136952824894
Validation loss: 2.462113009863754

Epoch: 6| Step: 10
Training loss: 2.349697044810794
Validation loss: 2.4663189696644574

Epoch: 6| Step: 11
Training loss: 1.8722619091484942
Validation loss: 2.4615030113251906

Epoch: 6| Step: 12
Training loss: 2.488813741529658
Validation loss: 2.4586972651525647

Epoch: 6| Step: 13
Training loss: 2.3800839670580074
Validation loss: 2.451166071384647

Epoch: 170| Step: 0
Training loss: 2.7476930478614445
Validation loss: 2.458417411487111

Epoch: 6| Step: 1
Training loss: 2.5378818055596044
Validation loss: 2.453089225815961

Epoch: 6| Step: 2
Training loss: 2.0927831210768146
Validation loss: 2.4593584111004416

Epoch: 6| Step: 3
Training loss: 2.1428413890077875
Validation loss: 2.4555437672688343

Epoch: 6| Step: 4
Training loss: 2.537104488423893
Validation loss: 2.4548728855059916

Epoch: 6| Step: 5
Training loss: 2.3771274474516972
Validation loss: 2.4589187980959184

Epoch: 6| Step: 6
Training loss: 2.462931766514275
Validation loss: 2.466585876671114

Epoch: 6| Step: 7
Training loss: 2.4632557440253
Validation loss: 2.473574033636959

Epoch: 6| Step: 8
Training loss: 2.1725772298731254
Validation loss: 2.472042270664206

Epoch: 6| Step: 9
Training loss: 2.7263454580407798
Validation loss: 2.470270485372916

Epoch: 6| Step: 10
Training loss: 2.498849604092265
Validation loss: 2.474990233328202

Epoch: 6| Step: 11
Training loss: 3.0059862810279947
Validation loss: 2.475976210710481

Epoch: 6| Step: 12
Training loss: 2.4000536912634405
Validation loss: 2.4784599600558934

Epoch: 6| Step: 13
Training loss: 2.8774426905462303
Validation loss: 2.4687032735402386

Epoch: 171| Step: 0
Training loss: 2.4554276077265826
Validation loss: 2.4806959794060646

Epoch: 6| Step: 1
Training loss: 1.7883931202892036
Validation loss: 2.48108387926681

Epoch: 6| Step: 2
Training loss: 2.051778031566844
Validation loss: 2.4783726123124854

Epoch: 6| Step: 3
Training loss: 2.541304317556229
Validation loss: 2.466844193303488

Epoch: 6| Step: 4
Training loss: 2.680036249627308
Validation loss: 2.4755135449741545

Epoch: 6| Step: 5
Training loss: 1.894528984776352
Validation loss: 2.47048666989703

Epoch: 6| Step: 6
Training loss: 2.439795660155122
Validation loss: 2.4791069557842342

Epoch: 6| Step: 7
Training loss: 3.3800928755420374
Validation loss: 2.4711508042515553

Epoch: 6| Step: 8
Training loss: 1.96911084940169
Validation loss: 2.4749254738861097

Epoch: 6| Step: 9
Training loss: 2.3113707801038057
Validation loss: 2.478297655617967

Epoch: 6| Step: 10
Training loss: 2.815464915340655
Validation loss: 2.47710225895057

Epoch: 6| Step: 11
Training loss: 2.495777569775682
Validation loss: 2.471419134917384

Epoch: 6| Step: 12
Training loss: 3.165527607360104
Validation loss: 2.472910598280375

Epoch: 6| Step: 13
Training loss: 2.398515432874736
Validation loss: 2.4759355266858

Epoch: 172| Step: 0
Training loss: 2.101687629689947
Validation loss: 2.4729161901776164

Epoch: 6| Step: 1
Training loss: 2.275175708231436
Validation loss: 2.477445122232602

Epoch: 6| Step: 2
Training loss: 2.5487575945102607
Validation loss: 2.471334046635998

Epoch: 6| Step: 3
Training loss: 2.2157158320522474
Validation loss: 2.4788932061776414

Epoch: 6| Step: 4
Training loss: 2.2054625751275143
Validation loss: 2.469868660033351

Epoch: 6| Step: 5
Training loss: 2.228762426593089
Validation loss: 2.465990786057476

Epoch: 6| Step: 6
Training loss: 2.584191231150054
Validation loss: 2.4704212374705765

Epoch: 6| Step: 7
Training loss: 3.070110285266034
Validation loss: 2.468676570009536

Epoch: 6| Step: 8
Training loss: 2.1934942677868388
Validation loss: 2.47173964479076

Epoch: 6| Step: 9
Training loss: 2.954448262196612
Validation loss: 2.467496746992539

Epoch: 6| Step: 10
Training loss: 2.705717221999521
Validation loss: 2.4746257537564715

Epoch: 6| Step: 11
Training loss: 2.900932451494651
Validation loss: 2.470877515345293

Epoch: 6| Step: 12
Training loss: 2.133958892698052
Validation loss: 2.4744724957416286

Epoch: 6| Step: 13
Training loss: 2.595861012498496
Validation loss: 2.467494750102654

Epoch: 173| Step: 0
Training loss: 2.645760322424505
Validation loss: 2.4746419076002986

Epoch: 6| Step: 1
Training loss: 1.7603810173202157
Validation loss: 2.465997908337385

Epoch: 6| Step: 2
Training loss: 2.679470576189362
Validation loss: 2.465351421229329

Epoch: 6| Step: 3
Training loss: 2.985688085434555
Validation loss: 2.470520696325698

Epoch: 6| Step: 4
Training loss: 2.2279545230573095
Validation loss: 2.4604442283729657

Epoch: 6| Step: 5
Training loss: 2.1964519977981745
Validation loss: 2.460349336607846

Epoch: 6| Step: 6
Training loss: 2.370752853699169
Validation loss: 2.4592631300446146

Epoch: 6| Step: 7
Training loss: 2.036198149806015
Validation loss: 2.4685621874226733

Epoch: 6| Step: 8
Training loss: 3.1175940685870662
Validation loss: 2.454182439428484

Epoch: 6| Step: 9
Training loss: 2.3575960235619124
Validation loss: 2.463511667747732

Epoch: 6| Step: 10
Training loss: 2.175134312659034
Validation loss: 2.4549127046042547

Epoch: 6| Step: 11
Training loss: 2.8569816203262204
Validation loss: 2.461382152612396

Epoch: 6| Step: 12
Training loss: 2.0861547692690476
Validation loss: 2.467218133028765

Epoch: 6| Step: 13
Training loss: 3.036341530247489
Validation loss: 2.46309250224313

Epoch: 174| Step: 0
Training loss: 2.5058410120564028
Validation loss: 2.464114267099363

Epoch: 6| Step: 1
Training loss: 2.9199457173984777
Validation loss: 2.4632751987430135

Epoch: 6| Step: 2
Training loss: 2.496965664970878
Validation loss: 2.4694891358336295

Epoch: 6| Step: 3
Training loss: 2.418943144112371
Validation loss: 2.4715779360301493

Epoch: 6| Step: 4
Training loss: 2.5653650038238687
Validation loss: 2.469633757070735

Epoch: 6| Step: 5
Training loss: 2.17602669172185
Validation loss: 2.4682686251912527

Epoch: 6| Step: 6
Training loss: 1.9148596524434651
Validation loss: 2.468993388222089

Epoch: 6| Step: 7
Training loss: 2.3911345693004016
Validation loss: 2.4674660124236816

Epoch: 6| Step: 8
Training loss: 2.346535210323112
Validation loss: 2.4762681370956265

Epoch: 6| Step: 9
Training loss: 2.6601069553642107
Validation loss: 2.474731370045942

Epoch: 6| Step: 10
Training loss: 2.3856932189637807
Validation loss: 2.473171170471863

Epoch: 6| Step: 11
Training loss: 2.548898372924434
Validation loss: 2.4799249808952544

Epoch: 6| Step: 12
Training loss: 2.6567111344327308
Validation loss: 2.4681253246501322

Epoch: 6| Step: 13
Training loss: 2.796190572353563
Validation loss: 2.473994699846643

Epoch: 175| Step: 0
Training loss: 2.442647731221752
Validation loss: 2.4756550695835

Epoch: 6| Step: 1
Training loss: 2.2854915535920335
Validation loss: 2.4747245378400526

Epoch: 6| Step: 2
Training loss: 2.0724105856166575
Validation loss: 2.474116211253899

Epoch: 6| Step: 3
Training loss: 2.0940683606784036
Validation loss: 2.4703832607763316

Epoch: 6| Step: 4
Training loss: 2.5154329783443803
Validation loss: 2.471890540381578

Epoch: 6| Step: 5
Training loss: 2.543416114283211
Validation loss: 2.4785057570689633

Epoch: 6| Step: 6
Training loss: 2.757859183718719
Validation loss: 2.47557295194552

Epoch: 6| Step: 7
Training loss: 2.1052046629659626
Validation loss: 2.4755195322855306

Epoch: 6| Step: 8
Training loss: 2.281876778394246
Validation loss: 2.4756849721828718

Epoch: 6| Step: 9
Training loss: 2.655891484020034
Validation loss: 2.4767752234138225

Epoch: 6| Step: 10
Training loss: 2.9652805333319514
Validation loss: 2.473310162143526

Epoch: 6| Step: 11
Training loss: 2.546488914011716
Validation loss: 2.466429364113519

Epoch: 6| Step: 12
Training loss: 3.054517502213023
Validation loss: 2.467519372930361

Epoch: 6| Step: 13
Training loss: 2.5441679814978047
Validation loss: 2.464780384504674

Epoch: 176| Step: 0
Training loss: 2.6707948877321948
Validation loss: 2.4676934407789743

Epoch: 6| Step: 1
Training loss: 2.5132601029464214
Validation loss: 2.4671840127344917

Epoch: 6| Step: 2
Training loss: 2.706318022333405
Validation loss: 2.465051141508855

Epoch: 6| Step: 3
Training loss: 2.610346539025516
Validation loss: 2.468246988163883

Epoch: 6| Step: 4
Training loss: 1.9069022641753792
Validation loss: 2.4521929353145175

Epoch: 6| Step: 5
Training loss: 2.6223773570516316
Validation loss: 2.468389106479267

Epoch: 6| Step: 6
Training loss: 1.847576179946959
Validation loss: 2.464711213415167

Epoch: 6| Step: 7
Training loss: 3.2460649583184633
Validation loss: 2.464657268129974

Epoch: 6| Step: 8
Training loss: 2.6513441671422364
Validation loss: 2.467009449888515

Epoch: 6| Step: 9
Training loss: 2.680808408425855
Validation loss: 2.471139725016126

Epoch: 6| Step: 10
Training loss: 1.8210938704468937
Validation loss: 2.458847175388353

Epoch: 6| Step: 11
Training loss: 2.6357476148517667
Validation loss: 2.4686749925767457

Epoch: 6| Step: 12
Training loss: 2.501916532226548
Validation loss: 2.46748788980735

Epoch: 6| Step: 13
Training loss: 2.2254698096622794
Validation loss: 2.471290520564316

Epoch: 177| Step: 0
Training loss: 2.4236850004643404
Validation loss: 2.478775816382369

Epoch: 6| Step: 1
Training loss: 3.273033244587996
Validation loss: 2.4624019483870683

Epoch: 6| Step: 2
Training loss: 2.3543982152804404
Validation loss: 2.466975689123284

Epoch: 6| Step: 3
Training loss: 2.3829323660296735
Validation loss: 2.4717133197081314

Epoch: 6| Step: 4
Training loss: 2.4028857604393448
Validation loss: 2.4670009775261605

Epoch: 6| Step: 5
Training loss: 2.534795656113035
Validation loss: 2.473998145067552

Epoch: 6| Step: 6
Training loss: 2.364825893066253
Validation loss: 2.4662971866383896

Epoch: 6| Step: 7
Training loss: 2.7601175590025435
Validation loss: 2.472064469217963

Epoch: 6| Step: 8
Training loss: 2.082487646755476
Validation loss: 2.4635883082248298

Epoch: 6| Step: 9
Training loss: 1.9060093462015388
Validation loss: 2.468119238902034

Epoch: 6| Step: 10
Training loss: 3.2021135919879002
Validation loss: 2.4713359037527765

Epoch: 6| Step: 11
Training loss: 2.0868857296567582
Validation loss: 2.46391299771261

Epoch: 6| Step: 12
Training loss: 2.1113234951310824
Validation loss: 2.467363298050543

Epoch: 6| Step: 13
Training loss: 2.6945283053042766
Validation loss: 2.473389029334186

Epoch: 178| Step: 0
Training loss: 2.928730312383812
Validation loss: 2.4803933119628896

Epoch: 6| Step: 1
Training loss: 2.6719984059528916
Validation loss: 2.4664364367943534

Epoch: 6| Step: 2
Training loss: 2.1822280571042274
Validation loss: 2.471778107040999

Epoch: 6| Step: 3
Training loss: 2.524302425904384
Validation loss: 2.4714931747740496

Epoch: 6| Step: 4
Training loss: 2.3066414518944325
Validation loss: 2.4728085358998206

Epoch: 6| Step: 5
Training loss: 3.017885931914405
Validation loss: 2.469976305699955

Epoch: 6| Step: 6
Training loss: 2.427400058060088
Validation loss: 2.4758393909693104

Epoch: 6| Step: 7
Training loss: 2.4404427786388574
Validation loss: 2.4726369655152416

Epoch: 6| Step: 8
Training loss: 2.3522462579496923
Validation loss: 2.480090735759869

Epoch: 6| Step: 9
Training loss: 2.7396758224675297
Validation loss: 2.47582449682151

Epoch: 6| Step: 10
Training loss: 2.16166736250812
Validation loss: 2.4796079729031506

Epoch: 6| Step: 11
Training loss: 2.147160931110408
Validation loss: 2.4789864343690318

Epoch: 6| Step: 12
Training loss: 2.623339354796166
Validation loss: 2.47594481104774

Epoch: 6| Step: 13
Training loss: 2.1361365492746986
Validation loss: 2.480137584135947

Epoch: 179| Step: 0
Training loss: 2.743697921501991
Validation loss: 2.4719728446464773

Epoch: 6| Step: 1
Training loss: 2.151945821597699
Validation loss: 2.4747381540625035

Epoch: 6| Step: 2
Training loss: 1.9246176401854695
Validation loss: 2.4761208221617523

Epoch: 6| Step: 3
Training loss: 3.0687506588315547
Validation loss: 2.4811386205111754

Epoch: 6| Step: 4
Training loss: 2.8350519316153724
Validation loss: 2.487369212509434

Epoch: 6| Step: 5
Training loss: 2.7662013256205245
Validation loss: 2.4876435089887217

Epoch: 6| Step: 6
Training loss: 2.0950900671633113
Validation loss: 2.4841986619598746

Epoch: 6| Step: 7
Training loss: 2.59731773522698
Validation loss: 2.4820597514804574

Epoch: 6| Step: 8
Training loss: 2.213247433722868
Validation loss: 2.478682371862697

Epoch: 6| Step: 9
Training loss: 1.7473721528663528
Validation loss: 2.4822075864121707

Epoch: 6| Step: 10
Training loss: 2.661958730777544
Validation loss: 2.4810994144998606

Epoch: 6| Step: 11
Training loss: 2.8802929130584354
Validation loss: 2.4744795936086827

Epoch: 6| Step: 12
Training loss: 2.315292528096962
Validation loss: 2.4735131488926334

Epoch: 6| Step: 13
Training loss: 2.5091733478553055
Validation loss: 2.4763184436195207

Epoch: 180| Step: 0
Training loss: 3.209597268435608
Validation loss: 2.478182129684453

Epoch: 6| Step: 1
Training loss: 2.4865446393477915
Validation loss: 2.481087306635866

Epoch: 6| Step: 2
Training loss: 2.7551417399809495
Validation loss: 2.479884297558567

Epoch: 6| Step: 3
Training loss: 2.6408928729642533
Validation loss: 2.4724007826576706

Epoch: 6| Step: 4
Training loss: 2.469207141899386
Validation loss: 2.4698261860838167

Epoch: 6| Step: 5
Training loss: 2.087672394355389
Validation loss: 2.473643719929852

Epoch: 6| Step: 6
Training loss: 1.9739867303125913
Validation loss: 2.471824614617772

Epoch: 6| Step: 7
Training loss: 2.187816705938077
Validation loss: 2.4703889870751032

Epoch: 6| Step: 8
Training loss: 2.3174842526128194
Validation loss: 2.4741410412162126

Epoch: 6| Step: 9
Training loss: 2.840722117426747
Validation loss: 2.472177339591702

Epoch: 6| Step: 10
Training loss: 2.4962612806284024
Validation loss: 2.4738976936270265

Epoch: 6| Step: 11
Training loss: 2.103551214372214
Validation loss: 2.472478843138163

Epoch: 6| Step: 12
Training loss: 2.495771073810387
Validation loss: 2.4660217887728475

Epoch: 6| Step: 13
Training loss: 2.5478942329456755
Validation loss: 2.4719615440474043

Epoch: 181| Step: 0
Training loss: 2.5746036409671014
Validation loss: 2.4691722766255886

Epoch: 6| Step: 1
Training loss: 3.004686827121447
Validation loss: 2.47315851768061

Epoch: 6| Step: 2
Training loss: 2.73412230277662
Validation loss: 2.470090116061588

Epoch: 6| Step: 3
Training loss: 2.5638336804820856
Validation loss: 2.4854601363553224

Epoch: 6| Step: 4
Training loss: 2.1449211058079456
Validation loss: 2.478249145002271

Epoch: 6| Step: 5
Training loss: 2.5939296062744512
Validation loss: 2.4701035889179117

Epoch: 6| Step: 6
Training loss: 2.253822047414377
Validation loss: 2.4619840868976115

Epoch: 6| Step: 7
Training loss: 2.4656016881732743
Validation loss: 2.466657645191844

Epoch: 6| Step: 8
Training loss: 2.3939325726159133
Validation loss: 2.47087929239571

Epoch: 6| Step: 9
Training loss: 2.273585993056402
Validation loss: 2.4782049547007112

Epoch: 6| Step: 10
Training loss: 1.9937547689637933
Validation loss: 2.477975275905156

Epoch: 6| Step: 11
Training loss: 2.4347031025759325
Validation loss: 2.4761659964636964

Epoch: 6| Step: 12
Training loss: 2.602781909254937
Validation loss: 2.470845616670882

Epoch: 6| Step: 13
Training loss: 2.811449829706818
Validation loss: 2.467431195017067

Epoch: 182| Step: 0
Training loss: 2.607985806291958
Validation loss: 2.4757352424055137

Epoch: 6| Step: 1
Training loss: 2.9846565153750118
Validation loss: 2.4735339526875437

Epoch: 6| Step: 2
Training loss: 2.644609143055217
Validation loss: 2.4768706570231958

Epoch: 6| Step: 3
Training loss: 2.0921075556369053
Validation loss: 2.4764237390066266

Epoch: 6| Step: 4
Training loss: 2.098234242631333
Validation loss: 2.485272067634198

Epoch: 6| Step: 5
Training loss: 2.527515246367008
Validation loss: 2.4809931643759717

Epoch: 6| Step: 6
Training loss: 3.10296983282907
Validation loss: 2.477382046970822

Epoch: 6| Step: 7
Training loss: 2.5807604641881907
Validation loss: 2.4757287901543434

Epoch: 6| Step: 8
Training loss: 2.107303195330364
Validation loss: 2.4735760577478385

Epoch: 6| Step: 9
Training loss: 2.3111384739641636
Validation loss: 2.4695806594695995

Epoch: 6| Step: 10
Training loss: 2.2629920129436987
Validation loss: 2.4767041090663144

Epoch: 6| Step: 11
Training loss: 2.5831254034551994
Validation loss: 2.4757560114779364

Epoch: 6| Step: 12
Training loss: 2.503166291733297
Validation loss: 2.4730037065424986

Epoch: 6| Step: 13
Training loss: 2.4004509144623056
Validation loss: 2.465935031752825

Epoch: 183| Step: 0
Training loss: 2.748704952132803
Validation loss: 2.467917821152783

Epoch: 6| Step: 1
Training loss: 2.3997942041537725
Validation loss: 2.4643842507637883

Epoch: 6| Step: 2
Training loss: 2.2980993212690963
Validation loss: 2.466292965349249

Epoch: 6| Step: 3
Training loss: 2.507609706772129
Validation loss: 2.457708850573935

Epoch: 6| Step: 4
Training loss: 2.3623676646473113
Validation loss: 2.4544662243110977

Epoch: 6| Step: 5
Training loss: 2.49292756097109
Validation loss: 2.455910868443895

Epoch: 6| Step: 6
Training loss: 3.1316212508268575
Validation loss: 2.4502299531728227

Epoch: 6| Step: 7
Training loss: 2.6759022483477235
Validation loss: 2.447714344077561

Epoch: 6| Step: 8
Training loss: 2.607450037886295
Validation loss: 2.451403149235222

Epoch: 6| Step: 9
Training loss: 2.516509664661351
Validation loss: 2.4505031529652572

Epoch: 6| Step: 10
Training loss: 2.578722243055625
Validation loss: 2.4571534951693677

Epoch: 6| Step: 11
Training loss: 2.1011311254966363
Validation loss: 2.4516587299483836

Epoch: 6| Step: 12
Training loss: 2.5070354648268167
Validation loss: 2.4531432635038484

Epoch: 6| Step: 13
Training loss: 1.7642935399686672
Validation loss: 2.455907875157739

Epoch: 184| Step: 0
Training loss: 2.40877489664052
Validation loss: 2.4590629502463806

Epoch: 6| Step: 1
Training loss: 2.4139062528445407
Validation loss: 2.4599638289348413

Epoch: 6| Step: 2
Training loss: 2.6517237976684322
Validation loss: 2.4599138179404036

Epoch: 6| Step: 3
Training loss: 2.2855169027968203
Validation loss: 2.4633583554436793

Epoch: 6| Step: 4
Training loss: 3.013551938333597
Validation loss: 2.467906308770415

Epoch: 6| Step: 5
Training loss: 2.773559481664985
Validation loss: 2.474524685465035

Epoch: 6| Step: 6
Training loss: 2.0454831814928873
Validation loss: 2.4635724851415906

Epoch: 6| Step: 7
Training loss: 2.4949111644394923
Validation loss: 2.4627646954272606

Epoch: 6| Step: 8
Training loss: 2.3233453215404247
Validation loss: 2.4675747532650663

Epoch: 6| Step: 9
Training loss: 2.3433963763175205
Validation loss: 2.4634342344918037

Epoch: 6| Step: 10
Training loss: 2.880199043760213
Validation loss: 2.4552638697557274

Epoch: 6| Step: 11
Training loss: 2.188599010686434
Validation loss: 2.4675777565538812

Epoch: 6| Step: 12
Training loss: 2.8154318045701805
Validation loss: 2.4676952603789473

Epoch: 6| Step: 13
Training loss: 2.187313180847873
Validation loss: 2.4601569900842697

Epoch: 185| Step: 0
Training loss: 2.491372480429748
Validation loss: 2.469511630881334

Epoch: 6| Step: 1
Training loss: 2.1377957992670895
Validation loss: 2.4673403163722796

Epoch: 6| Step: 2
Training loss: 3.0735281298200157
Validation loss: 2.4732957508165665

Epoch: 6| Step: 3
Training loss: 2.2721831017038343
Validation loss: 2.4872500500109145

Epoch: 6| Step: 4
Training loss: 3.023608456689661
Validation loss: 2.4655500509380093

Epoch: 6| Step: 5
Training loss: 2.681833992339847
Validation loss: 2.4694161783819357

Epoch: 6| Step: 6
Training loss: 1.779585880797836
Validation loss: 2.4676382080351247

Epoch: 6| Step: 7
Training loss: 2.374002749228553
Validation loss: 2.46076551371267

Epoch: 6| Step: 8
Training loss: 2.3317350522152487
Validation loss: 2.462360967464604

Epoch: 6| Step: 9
Training loss: 2.2531397423546284
Validation loss: 2.4650446612920645

Epoch: 6| Step: 10
Training loss: 2.315061645346173
Validation loss: 2.469443573884223

Epoch: 6| Step: 11
Training loss: 2.158817918302126
Validation loss: 2.4639913029001166

Epoch: 6| Step: 12
Training loss: 3.300192081756645
Validation loss: 2.4516527978213944

Epoch: 6| Step: 13
Training loss: 2.582874800893583
Validation loss: 2.467699108908983

Epoch: 186| Step: 0
Training loss: 2.1314675139014865
Validation loss: 2.455770908188391

Epoch: 6| Step: 1
Training loss: 2.894949981837142
Validation loss: 2.464593776918299

Epoch: 6| Step: 2
Training loss: 2.5872834267026743
Validation loss: 2.486932737439679

Epoch: 6| Step: 3
Training loss: 3.571575984637326
Validation loss: 2.476716479018298

Epoch: 6| Step: 4
Training loss: 2.0251673075943084
Validation loss: 2.4793502568673165

Epoch: 6| Step: 5
Training loss: 2.2049391831987624
Validation loss: 2.4801925705674925

Epoch: 6| Step: 6
Training loss: 2.8528875747281184
Validation loss: 2.4905493682903415

Epoch: 6| Step: 7
Training loss: 2.5020728101252305
Validation loss: 2.4848399816784847

Epoch: 6| Step: 8
Training loss: 2.2072906071683014
Validation loss: 2.4752716486938717

Epoch: 6| Step: 9
Training loss: 2.155426310349232
Validation loss: 2.4683182093302705

Epoch: 6| Step: 10
Training loss: 2.19879547436453
Validation loss: 2.4741271486742153

Epoch: 6| Step: 11
Training loss: 2.1330456728509732
Validation loss: 2.4586972005062484

Epoch: 6| Step: 12
Training loss: 2.3049850013228377
Validation loss: 2.462182479887495

Epoch: 6| Step: 13
Training loss: 2.6175600612274974
Validation loss: 2.477723853156935

Epoch: 187| Step: 0
Training loss: 2.762875326905194
Validation loss: 2.470058738097599

Epoch: 6| Step: 1
Training loss: 2.397827269619144
Validation loss: 2.481988636451916

Epoch: 6| Step: 2
Training loss: 2.054363036554619
Validation loss: 2.4846578632925826

Epoch: 6| Step: 3
Training loss: 2.2320009437135186
Validation loss: 2.4812460174656703

Epoch: 6| Step: 4
Training loss: 2.808041917602147
Validation loss: 2.4843938974745403

Epoch: 6| Step: 5
Training loss: 2.1943787458969646
Validation loss: 2.4796276679028737

Epoch: 6| Step: 6
Training loss: 1.9763921128967015
Validation loss: 2.4793917663279137

Epoch: 6| Step: 7
Training loss: 2.863727196578071
Validation loss: 2.478343159011145

Epoch: 6| Step: 8
Training loss: 2.17246386551739
Validation loss: 2.4778658368576387

Epoch: 6| Step: 9
Training loss: 3.0729284426361136
Validation loss: 2.465241832799445

Epoch: 6| Step: 10
Training loss: 2.496100149609118
Validation loss: 2.4765396518234946

Epoch: 6| Step: 11
Training loss: 2.610618432100421
Validation loss: 2.471726060279315

Epoch: 6| Step: 12
Training loss: 2.2764463668661867
Validation loss: 2.4755368520672016

Epoch: 6| Step: 13
Training loss: 2.7070283435624276
Validation loss: 2.4752611899069525

Epoch: 188| Step: 0
Training loss: 2.5581893018837487
Validation loss: 2.4689515108044247

Epoch: 6| Step: 1
Training loss: 2.61176889219085
Validation loss: 2.4652475388034976

Epoch: 6| Step: 2
Training loss: 2.4800326226765232
Validation loss: 2.4689656980260533

Epoch: 6| Step: 3
Training loss: 2.6647058867863316
Validation loss: 2.4710702977618864

Epoch: 6| Step: 4
Training loss: 1.9021759899199147
Validation loss: 2.4731378472988816

Epoch: 6| Step: 5
Training loss: 2.6835509273216354
Validation loss: 2.4781799650250003

Epoch: 6| Step: 6
Training loss: 2.248969265827453
Validation loss: 2.475958075507897

Epoch: 6| Step: 7
Training loss: 2.1734655031529706
Validation loss: 2.474446320173564

Epoch: 6| Step: 8
Training loss: 2.435336008250914
Validation loss: 2.4721890249654677

Epoch: 6| Step: 9
Training loss: 2.6794845459711816
Validation loss: 2.481806404896911

Epoch: 6| Step: 10
Training loss: 2.7016880868874087
Validation loss: 2.4782234983684175

Epoch: 6| Step: 11
Training loss: 3.170753619027067
Validation loss: 2.4797767695202984

Epoch: 6| Step: 12
Training loss: 2.1889162111379057
Validation loss: 2.475752632904219

Epoch: 6| Step: 13
Training loss: 2.111390570776639
Validation loss: 2.4803644754113803

Epoch: 189| Step: 0
Training loss: 1.5030968011126278
Validation loss: 2.4795963865934527

Epoch: 6| Step: 1
Training loss: 2.5412655706721394
Validation loss: 2.477547546941564

Epoch: 6| Step: 2
Training loss: 2.904185556562845
Validation loss: 2.4774719878767772

Epoch: 6| Step: 3
Training loss: 2.4588560960198214
Validation loss: 2.4840639587441573

Epoch: 6| Step: 4
Training loss: 2.5422264691667866
Validation loss: 2.478117702195982

Epoch: 6| Step: 5
Training loss: 2.57527326596794
Validation loss: 2.48035002496892

Epoch: 6| Step: 6
Training loss: 2.6728006287677646
Validation loss: 2.4798495583639175

Epoch: 6| Step: 7
Training loss: 2.442974398722033
Validation loss: 2.482010265754333

Epoch: 6| Step: 8
Training loss: 2.0312818084573774
Validation loss: 2.4800940683685258

Epoch: 6| Step: 9
Training loss: 2.8967044718404007
Validation loss: 2.4821276626696864

Epoch: 6| Step: 10
Training loss: 2.944444604389818
Validation loss: 2.4799149983974718

Epoch: 6| Step: 11
Training loss: 2.0194108288867807
Validation loss: 2.483200627393168

Epoch: 6| Step: 12
Training loss: 2.4120189325465784
Validation loss: 2.482096284793373

Epoch: 6| Step: 13
Training loss: 2.225646355860468
Validation loss: 2.483219197763159

Epoch: 190| Step: 0
Training loss: 2.5491409986670424
Validation loss: 2.482805047925293

Epoch: 6| Step: 1
Training loss: 2.568140474571309
Validation loss: 2.4812947977860063

Epoch: 6| Step: 2
Training loss: 2.1953741859104814
Validation loss: 2.4745506996237814

Epoch: 6| Step: 3
Training loss: 3.415545737139984
Validation loss: 2.4863898945597325

Epoch: 6| Step: 4
Training loss: 2.348835425252147
Validation loss: 2.4835338488108203

Epoch: 6| Step: 5
Training loss: 1.6587153386143276
Validation loss: 2.491772129757035

Epoch: 6| Step: 6
Training loss: 3.0719347058350803
Validation loss: 2.4917432973128615

Epoch: 6| Step: 7
Training loss: 2.026440957806285
Validation loss: 2.48400085958854

Epoch: 6| Step: 8
Training loss: 1.8721401020507367
Validation loss: 2.4794398138628075

Epoch: 6| Step: 9
Training loss: 2.370471853935991
Validation loss: 2.4833063190279496

Epoch: 6| Step: 10
Training loss: 2.655109654405351
Validation loss: 2.486070993716622

Epoch: 6| Step: 11
Training loss: 2.327798500464473
Validation loss: 2.483281884737893

Epoch: 6| Step: 12
Training loss: 2.5462238438891616
Validation loss: 2.4825408530867463

Epoch: 6| Step: 13
Training loss: 2.4975658010190487
Validation loss: 2.4762708730907494

Epoch: 191| Step: 0
Training loss: 3.415522282932723
Validation loss: 2.4816503638976055

Epoch: 6| Step: 1
Training loss: 2.714550238461493
Validation loss: 2.48654227422057

Epoch: 6| Step: 2
Training loss: 1.953035703525098
Validation loss: 2.484417193232427

Epoch: 6| Step: 3
Training loss: 1.9307336481160864
Validation loss: 2.482639946451977

Epoch: 6| Step: 4
Training loss: 2.081210720848611
Validation loss: 2.4864741799646377

Epoch: 6| Step: 5
Training loss: 2.3648215578598735
Validation loss: 2.4808353183248477

Epoch: 6| Step: 6
Training loss: 2.335658028001336
Validation loss: 2.486846909659566

Epoch: 6| Step: 7
Training loss: 1.5768848494177894
Validation loss: 2.477288493736476

Epoch: 6| Step: 8
Training loss: 2.0735547283411115
Validation loss: 2.47203968269529

Epoch: 6| Step: 9
Training loss: 2.64777377203491
Validation loss: 2.47946218658002

Epoch: 6| Step: 10
Training loss: 3.238945868637792
Validation loss: 2.478418795731056

Epoch: 6| Step: 11
Training loss: 3.1349317274918693
Validation loss: 2.4739904354756574

Epoch: 6| Step: 12
Training loss: 2.100375723151875
Validation loss: 2.481136362338612

Epoch: 6| Step: 13
Training loss: 2.2784201432130606
Validation loss: 2.4652295825766397

Epoch: 192| Step: 0
Training loss: 2.685859445588376
Validation loss: 2.4701478758908144

Epoch: 6| Step: 1
Training loss: 2.2602722074930117
Validation loss: 2.4744026400814616

Epoch: 6| Step: 2
Training loss: 2.4304372728419135
Validation loss: 2.467850275709014

Epoch: 6| Step: 3
Training loss: 2.414435397979334
Validation loss: 2.475022945554571

Epoch: 6| Step: 4
Training loss: 2.6766547566295777
Validation loss: 2.468613439718398

Epoch: 6| Step: 5
Training loss: 2.759698930435258
Validation loss: 2.4751337464797434

Epoch: 6| Step: 6
Training loss: 2.3291942010206266
Validation loss: 2.4691733789969637

Epoch: 6| Step: 7
Training loss: 2.216835592998885
Validation loss: 2.4732299749759767

Epoch: 6| Step: 8
Training loss: 1.6611446534934011
Validation loss: 2.4684640903942676

Epoch: 6| Step: 9
Training loss: 2.5387259392323642
Validation loss: 2.4738155176534273

Epoch: 6| Step: 10
Training loss: 2.37889833245424
Validation loss: 2.472846274484126

Epoch: 6| Step: 11
Training loss: 2.389159507603248
Validation loss: 2.4746811838025664

Epoch: 6| Step: 12
Training loss: 2.7162737037547813
Validation loss: 2.4766407501983427

Epoch: 6| Step: 13
Training loss: 2.8911010350214585
Validation loss: 2.4717626739842706

Epoch: 193| Step: 0
Training loss: 1.786948475082619
Validation loss: 2.46693696676072

Epoch: 6| Step: 1
Training loss: 2.5239064634133275
Validation loss: 2.4763870257317544

Epoch: 6| Step: 2
Training loss: 2.2573517325917574
Validation loss: 2.4682326358197386

Epoch: 6| Step: 3
Training loss: 2.855863322121041
Validation loss: 2.4744482472186915

Epoch: 6| Step: 4
Training loss: 1.9598890442485208
Validation loss: 2.476636097292797

Epoch: 6| Step: 5
Training loss: 2.263687252226136
Validation loss: 2.473257673662369

Epoch: 6| Step: 6
Training loss: 3.1352999508109547
Validation loss: 2.476082852643857

Epoch: 6| Step: 7
Training loss: 2.291264331063146
Validation loss: 2.482271115346963

Epoch: 6| Step: 8
Training loss: 2.434059747500179
Validation loss: 2.4751283843525593

Epoch: 6| Step: 9
Training loss: 2.4002887154806136
Validation loss: 2.471595765749824

Epoch: 6| Step: 10
Training loss: 1.94710002106984
Validation loss: 2.488125567154675

Epoch: 6| Step: 11
Training loss: 3.2660363043258287
Validation loss: 2.49538601436782

Epoch: 6| Step: 12
Training loss: 2.596140575646721
Validation loss: 2.479735258492219

Epoch: 6| Step: 13
Training loss: 2.6590394576044125
Validation loss: 2.46853657697293

Epoch: 194| Step: 0
Training loss: 2.1397990840109458
Validation loss: 2.4764732240456135

Epoch: 6| Step: 1
Training loss: 3.1265874264022306
Validation loss: 2.481102521534798

Epoch: 6| Step: 2
Training loss: 2.2242603915798127
Validation loss: 2.478701240597332

Epoch: 6| Step: 3
Training loss: 2.6231875747586493
Validation loss: 2.475255635414275

Epoch: 6| Step: 4
Training loss: 2.1067639049389384
Validation loss: 2.469065851214826

Epoch: 6| Step: 5
Training loss: 2.3273062066222234
Validation loss: 2.4693932158090277

Epoch: 6| Step: 6
Training loss: 2.4495097935004444
Validation loss: 2.4684381891663283

Epoch: 6| Step: 7
Training loss: 2.328535312619914
Validation loss: 2.475392848603715

Epoch: 6| Step: 8
Training loss: 2.4716684016373613
Validation loss: 2.4682948823707607

Epoch: 6| Step: 9
Training loss: 2.5346323656386285
Validation loss: 2.4710247328048047

Epoch: 6| Step: 10
Training loss: 2.4791761980487954
Validation loss: 2.4687709405067273

Epoch: 6| Step: 11
Training loss: 2.583908529747154
Validation loss: 2.4713476011445623

Epoch: 6| Step: 12
Training loss: 2.570036342824023
Validation loss: 2.462370407902951

Epoch: 6| Step: 13
Training loss: 2.8393045409367557
Validation loss: 2.464225034447121

Epoch: 195| Step: 0
Training loss: 3.2605960946888524
Validation loss: 2.466032600958733

Epoch: 6| Step: 1
Training loss: 2.565378386787224
Validation loss: 2.475229652744711

Epoch: 6| Step: 2
Training loss: 2.104321791970657
Validation loss: 2.477324824730572

Epoch: 6| Step: 3
Training loss: 2.4862489170783646
Validation loss: 2.4667102982768982

Epoch: 6| Step: 4
Training loss: 2.098257195402089
Validation loss: 2.46675202849179

Epoch: 6| Step: 5
Training loss: 3.1155928354697866
Validation loss: 2.464203627985046

Epoch: 6| Step: 6
Training loss: 2.5387188018579816
Validation loss: 2.464495199459759

Epoch: 6| Step: 7
Training loss: 1.8343060976049481
Validation loss: 2.4650086812710534

Epoch: 6| Step: 8
Training loss: 2.698091616659302
Validation loss: 2.463102722312438

Epoch: 6| Step: 9
Training loss: 2.094760821580279
Validation loss: 2.4684234757312153

Epoch: 6| Step: 10
Training loss: 1.960616552829026
Validation loss: 2.4593016985544778

Epoch: 6| Step: 11
Training loss: 2.558927790843505
Validation loss: 2.455907292680009

Epoch: 6| Step: 12
Training loss: 2.107639078820723
Validation loss: 2.4720894885654956

Epoch: 6| Step: 13
Training loss: 2.6017228727197494
Validation loss: 2.4729075291589857

Epoch: 196| Step: 0
Training loss: 2.4648074768589403
Validation loss: 2.4803341806508814

Epoch: 6| Step: 1
Training loss: 2.483964226310011
Validation loss: 2.4642353385083298

Epoch: 6| Step: 2
Training loss: 2.7880246237511646
Validation loss: 2.467093012238363

Epoch: 6| Step: 3
Training loss: 1.968081042761005
Validation loss: 2.4695193383648535

Epoch: 6| Step: 4
Training loss: 2.669572161282027
Validation loss: 2.485129515715851

Epoch: 6| Step: 5
Training loss: 2.769829264588029
Validation loss: 2.4737133078787887

Epoch: 6| Step: 6
Training loss: 2.2280932067058044
Validation loss: 2.4725461014273677

Epoch: 6| Step: 7
Training loss: 1.5394717219482217
Validation loss: 2.480272468550484

Epoch: 6| Step: 8
Training loss: 2.600698608295507
Validation loss: 2.4915431673537567

Epoch: 6| Step: 9
Training loss: 2.4903667818659634
Validation loss: 2.4830846894573075

Epoch: 6| Step: 10
Training loss: 2.8242878885630853
Validation loss: 2.4849721722672564

Epoch: 6| Step: 11
Training loss: 2.463851317824437
Validation loss: 2.462094764478504

Epoch: 6| Step: 12
Training loss: 2.0775800865335357
Validation loss: 2.4777986508028635

Epoch: 6| Step: 13
Training loss: 2.7799832320222198
Validation loss: 2.471800693788855

Epoch: 197| Step: 0
Training loss: 1.8817461721868647
Validation loss: 2.474950239535428

Epoch: 6| Step: 1
Training loss: 2.3302203484334734
Validation loss: 2.464014525461525

Epoch: 6| Step: 2
Training loss: 2.49855447940239
Validation loss: 2.4763957227193156

Epoch: 6| Step: 3
Training loss: 2.626053280913774
Validation loss: 2.4739919131492982

Epoch: 6| Step: 4
Training loss: 2.483681060033915
Validation loss: 2.480046610317297

Epoch: 6| Step: 5
Training loss: 1.5683431850182032
Validation loss: 2.4758291191528294

Epoch: 6| Step: 6
Training loss: 2.4396905103987145
Validation loss: 2.482319347266208

Epoch: 6| Step: 7
Training loss: 3.2439798203862553
Validation loss: 2.480747493591037

Epoch: 6| Step: 8
Training loss: 3.0419141241990157
Validation loss: 2.4772142661749856

Epoch: 6| Step: 9
Training loss: 3.05115118970832
Validation loss: 2.474052127599405

Epoch: 6| Step: 10
Training loss: 2.871064685492769
Validation loss: 2.4677053889241867

Epoch: 6| Step: 11
Training loss: 2.1899574644931032
Validation loss: 2.4780375583482

Epoch: 6| Step: 12
Training loss: 1.947109633217167
Validation loss: 2.4741373151316792

Epoch: 6| Step: 13
Training loss: 1.7275621101045249
Validation loss: 2.4738110602195

Epoch: 198| Step: 0
Training loss: 2.6306856433624133
Validation loss: 2.4705799579704313

Epoch: 6| Step: 1
Training loss: 2.6569367362499565
Validation loss: 2.4742832867213913

Epoch: 6| Step: 2
Training loss: 3.072264228136602
Validation loss: 2.4865412035203445

Epoch: 6| Step: 3
Training loss: 2.1705601506276384
Validation loss: 2.4760570391374497

Epoch: 6| Step: 4
Training loss: 2.113617875511475
Validation loss: 2.4731652256764156

Epoch: 6| Step: 5
Training loss: 2.08023812838251
Validation loss: 2.4798187765952235

Epoch: 6| Step: 6
Training loss: 1.7070179814362043
Validation loss: 2.480397877719469

Epoch: 6| Step: 7
Training loss: 3.1641624152337737
Validation loss: 2.473270253647777

Epoch: 6| Step: 8
Training loss: 2.4448181237597533
Validation loss: 2.483252713689074

Epoch: 6| Step: 9
Training loss: 2.514439273764669
Validation loss: 2.478513011725581

Epoch: 6| Step: 10
Training loss: 2.3214951914356066
Validation loss: 2.4730446396462447

Epoch: 6| Step: 11
Training loss: 2.2774530453243655
Validation loss: 2.4722472581298183

Epoch: 6| Step: 12
Training loss: 2.499074860103752
Validation loss: 2.473627117806541

Epoch: 6| Step: 13
Training loss: 2.5205537835428986
Validation loss: 2.473697886895509

Epoch: 199| Step: 0
Training loss: 2.2996979058941682
Validation loss: 2.475884329665351

Epoch: 6| Step: 1
Training loss: 1.6127572675005164
Validation loss: 2.4774735757475237

Epoch: 6| Step: 2
Training loss: 2.6193558094629648
Validation loss: 2.488448739715273

Epoch: 6| Step: 3
Training loss: 2.883826431564517
Validation loss: 2.482888230708666

Epoch: 6| Step: 4
Training loss: 2.384962269066709
Validation loss: 2.486536920714833

Epoch: 6| Step: 5
Training loss: 2.611925534692614
Validation loss: 2.49181858309834

Epoch: 6| Step: 6
Training loss: 2.6465727506288843
Validation loss: 2.4883631718203487

Epoch: 6| Step: 7
Training loss: 2.825236157024142
Validation loss: 2.490872210427568

Epoch: 6| Step: 8
Training loss: 2.718735705809451
Validation loss: 2.496641414380511

Epoch: 6| Step: 9
Training loss: 2.5864167014335857
Validation loss: 2.486679192205524

Epoch: 6| Step: 10
Training loss: 2.1555230947171804
Validation loss: 2.4805509218236974

Epoch: 6| Step: 11
Training loss: 1.9379930791701758
Validation loss: 2.4947796836570553

Epoch: 6| Step: 12
Training loss: 2.586740052306294
Validation loss: 2.4981217640300755

Epoch: 6| Step: 13
Training loss: 2.2114494458914042
Validation loss: 2.4851995655239536

Epoch: 200| Step: 0
Training loss: 2.4029765466441666
Validation loss: 2.5050143499210833

Epoch: 6| Step: 1
Training loss: 1.9542056946696957
Validation loss: 2.4882774971814405

Epoch: 6| Step: 2
Training loss: 2.1335864776185676
Validation loss: 2.5040219855973427

Epoch: 6| Step: 3
Training loss: 3.033772313837918
Validation loss: 2.487698840655702

Epoch: 6| Step: 4
Training loss: 2.450165828620185
Validation loss: 2.4921124485876716

Epoch: 6| Step: 5
Training loss: 2.4779876555473237
Validation loss: 2.4908897185832695

Epoch: 6| Step: 6
Training loss: 3.291248021282756
Validation loss: 2.497320805848991

Epoch: 6| Step: 7
Training loss: 2.243432739269765
Validation loss: 2.496885195103768

Epoch: 6| Step: 8
Training loss: 1.6380975055388456
Validation loss: 2.4969163155191096

Epoch: 6| Step: 9
Training loss: 2.8813903112442825
Validation loss: 2.4949238263659046

Epoch: 6| Step: 10
Training loss: 2.1883755702726537
Validation loss: 2.4978457069870217

Epoch: 6| Step: 11
Training loss: 2.0958056251509363
Validation loss: 2.4850488544576623

Epoch: 6| Step: 12
Training loss: 2.3538778572383223
Validation loss: 2.493699279944981

Epoch: 6| Step: 13
Training loss: 2.6594404022028115
Validation loss: 2.4876750245492096

Epoch: 201| Step: 0
Training loss: 2.0070142532169437
Validation loss: 2.4903883942489573

Epoch: 6| Step: 1
Training loss: 2.5582882764329886
Validation loss: 2.488889754551593

Epoch: 6| Step: 2
Training loss: 2.447774896506974
Validation loss: 2.4880368099188135

Epoch: 6| Step: 3
Training loss: 2.3764403141872785
Validation loss: 2.485979214039963

Epoch: 6| Step: 4
Training loss: 2.4305093730595893
Validation loss: 2.488400842177132

Epoch: 6| Step: 5
Training loss: 2.7862486763390963
Validation loss: 2.4874953501544477

Epoch: 6| Step: 6
Training loss: 2.8640452116482438
Validation loss: 2.496180191095434

Epoch: 6| Step: 7
Training loss: 2.1647852162515386
Validation loss: 2.5008135425564597

Epoch: 6| Step: 8
Training loss: 2.3828763359148923
Validation loss: 2.502511638369127

Epoch: 6| Step: 9
Training loss: 2.406852349526633
Validation loss: 2.505483240811843

Epoch: 6| Step: 10
Training loss: 2.259635004935484
Validation loss: 2.5045530978429573

Epoch: 6| Step: 11
Training loss: 3.0073581104626417
Validation loss: 2.510382138934194

Epoch: 6| Step: 12
Training loss: 1.8661946486117031
Validation loss: 2.5101709179608473

Epoch: 6| Step: 13
Training loss: 2.7250260448086094
Validation loss: 2.499592429952787

Epoch: 202| Step: 0
Training loss: 1.8681593404850803
Validation loss: 2.497762171209902

Epoch: 6| Step: 1
Training loss: 2.0787671466608812
Validation loss: 2.4820844219317015

Epoch: 6| Step: 2
Training loss: 2.2613408064441334
Validation loss: 2.4809226914794453

Epoch: 6| Step: 3
Training loss: 2.6979783295368387
Validation loss: 2.488279189942853

Epoch: 6| Step: 4
Training loss: 2.410666932544159
Validation loss: 2.485065516190901

Epoch: 6| Step: 5
Training loss: 2.6797906171793735
Validation loss: 2.4809596579666113

Epoch: 6| Step: 6
Training loss: 2.4798903384112885
Validation loss: 2.483962490615068

Epoch: 6| Step: 7
Training loss: 3.609067829487187
Validation loss: 2.489398699395499

Epoch: 6| Step: 8
Training loss: 2.8697637890098053
Validation loss: 2.4865563690671197

Epoch: 6| Step: 9
Training loss: 1.950503978647938
Validation loss: 2.488391684133111

Epoch: 6| Step: 10
Training loss: 1.8947215820347707
Validation loss: 2.484300504323288

Epoch: 6| Step: 11
Training loss: 2.163513444457169
Validation loss: 2.473932420026019

Epoch: 6| Step: 12
Training loss: 2.5808958942178917
Validation loss: 2.481354018304335

Epoch: 6| Step: 13
Training loss: 2.4467792438658806
Validation loss: 2.4847491160596302

Epoch: 203| Step: 0
Training loss: 2.425807393742472
Validation loss: 2.5090515308280508

Epoch: 6| Step: 1
Training loss: 1.7228857047617416
Validation loss: 2.5018139616087702

Epoch: 6| Step: 2
Training loss: 2.5296203642071906
Validation loss: 2.509413211289302

Epoch: 6| Step: 3
Training loss: 2.9882242833111783
Validation loss: 2.506240018981694

Epoch: 6| Step: 4
Training loss: 2.1642991360073287
Validation loss: 2.4929910000300595

Epoch: 6| Step: 5
Training loss: 2.684171078700131
Validation loss: 2.492701350923784

Epoch: 6| Step: 6
Training loss: 2.1338107389488226
Validation loss: 2.5066940412100345

Epoch: 6| Step: 7
Training loss: 2.8905585204031916
Validation loss: 2.4902334494994194

Epoch: 6| Step: 8
Training loss: 2.450771685147796
Validation loss: 2.488465586271491

Epoch: 6| Step: 9
Training loss: 2.7269153093449017
Validation loss: 2.4961220227761083

Epoch: 6| Step: 10
Training loss: 2.78366207153516
Validation loss: 2.4701697938682767

Epoch: 6| Step: 11
Training loss: 2.4108503878487215
Validation loss: 2.485162750046964

Epoch: 6| Step: 12
Training loss: 2.2533636382094744
Validation loss: 2.464296839473719

Epoch: 6| Step: 13
Training loss: 2.7293140769537607
Validation loss: 2.4692987323100297

Epoch: 204| Step: 0
Training loss: 2.724062585142536
Validation loss: 2.4743159360260734

Epoch: 6| Step: 1
Training loss: 2.6472021952304403
Validation loss: 2.47770775148154

Epoch: 6| Step: 2
Training loss: 2.857410527361268
Validation loss: 2.481313982954559

Epoch: 6| Step: 3
Training loss: 2.362230202745219
Validation loss: 2.4810099494434246

Epoch: 6| Step: 4
Training loss: 2.3348616862531935
Validation loss: 2.4797572119115334

Epoch: 6| Step: 5
Training loss: 2.24338682843042
Validation loss: 2.4900646595685614

Epoch: 6| Step: 6
Training loss: 1.606503860658957
Validation loss: 2.49117082129618

Epoch: 6| Step: 7
Training loss: 2.395881210069922
Validation loss: 2.4899965818476164

Epoch: 6| Step: 8
Training loss: 2.2565997077252673
Validation loss: 2.496961622840266

Epoch: 6| Step: 9
Training loss: 2.459419290805421
Validation loss: 2.485447114457918

Epoch: 6| Step: 10
Training loss: 2.6150403680840157
Validation loss: 2.4816056336975754

Epoch: 6| Step: 11
Training loss: 2.7075367465215776
Validation loss: 2.481671491771522

Epoch: 6| Step: 12
Training loss: 2.4882189684488645
Validation loss: 2.4722970678546328

Epoch: 6| Step: 13
Training loss: 2.9373918878667302
Validation loss: 2.478042882109535

Epoch: 205| Step: 0
Training loss: 1.7590017407242238
Validation loss: 2.471149324879016

Epoch: 6| Step: 1
Training loss: 2.7851139616464367
Validation loss: 2.469594127060127

Epoch: 6| Step: 2
Training loss: 2.372044983654395
Validation loss: 2.474832068631946

Epoch: 6| Step: 3
Training loss: 2.4895532731245864
Validation loss: 2.4774016153103187

Epoch: 6| Step: 4
Training loss: 2.354286314587907
Validation loss: 2.4793881442945476

Epoch: 6| Step: 5
Training loss: 2.765991531480471
Validation loss: 2.489566536903915

Epoch: 6| Step: 6
Training loss: 2.590143476952806
Validation loss: 2.4838217673118694

Epoch: 6| Step: 7
Training loss: 2.2205169519173777
Validation loss: 2.4871648642563633

Epoch: 6| Step: 8
Training loss: 2.2797092826278442
Validation loss: 2.4880997827653104

Epoch: 6| Step: 9
Training loss: 2.2184452331124462
Validation loss: 2.478681434033142

Epoch: 6| Step: 10
Training loss: 2.944809928939069
Validation loss: 2.4829484054535014

Epoch: 6| Step: 11
Training loss: 2.578957902864274
Validation loss: 2.479779958333321

Epoch: 6| Step: 12
Training loss: 2.2323828933262706
Validation loss: 2.4789557060007423

Epoch: 6| Step: 13
Training loss: 2.4187326041293447
Validation loss: 2.476929036803228

Epoch: 206| Step: 0
Training loss: 2.483225430527474
Validation loss: 2.4751927612198426

Epoch: 6| Step: 1
Training loss: 2.5984434383505692
Validation loss: 2.4832735399007193

Epoch: 6| Step: 2
Training loss: 2.3069924418139984
Validation loss: 2.4698548721684395

Epoch: 6| Step: 3
Training loss: 2.556074599984761
Validation loss: 2.4773241269880213

Epoch: 6| Step: 4
Training loss: 2.098253104827667
Validation loss: 2.4767346086676825

Epoch: 6| Step: 5
Training loss: 2.1546753371948686
Validation loss: 2.483305990998798

Epoch: 6| Step: 6
Training loss: 2.630021605457286
Validation loss: 2.4822978327124035

Epoch: 6| Step: 7
Training loss: 2.9648612804673595
Validation loss: 2.4896485281565415

Epoch: 6| Step: 8
Training loss: 2.5566279423386726
Validation loss: 2.4868211519595644

Epoch: 6| Step: 9
Training loss: 2.477332539985675
Validation loss: 2.487369052756588

Epoch: 6| Step: 10
Training loss: 2.566117129595361
Validation loss: 2.4840294939584493

Epoch: 6| Step: 11
Training loss: 2.706645635357157
Validation loss: 2.4796657113406178

Epoch: 6| Step: 12
Training loss: 1.9993084665659828
Validation loss: 2.4829729550502284

Epoch: 6| Step: 13
Training loss: 2.1520210481131956
Validation loss: 2.4918866269889888

Epoch: 207| Step: 0
Training loss: 2.8389971912957326
Validation loss: 2.49545363455249

Epoch: 6| Step: 1
Training loss: 2.3804272329117193
Validation loss: 2.509145182548516

Epoch: 6| Step: 2
Training loss: 2.103684952490153
Validation loss: 2.5228072128262546

Epoch: 6| Step: 3
Training loss: 2.53593867707945
Validation loss: 2.528032691442895

Epoch: 6| Step: 4
Training loss: 2.2868200782087946
Validation loss: 2.5297499006718507

Epoch: 6| Step: 5
Training loss: 2.629248677550003
Validation loss: 2.515822519323562

Epoch: 6| Step: 6
Training loss: 1.9050065033969357
Validation loss: 2.51078898622294

Epoch: 6| Step: 7
Training loss: 2.9176535072246352
Validation loss: 2.477685378960054

Epoch: 6| Step: 8
Training loss: 2.962259525888686
Validation loss: 2.4777312303836165

Epoch: 6| Step: 9
Training loss: 2.218876794765018
Validation loss: 2.4743521500730665

Epoch: 6| Step: 10
Training loss: 1.5838577840810366
Validation loss: 2.475177622371455

Epoch: 6| Step: 11
Training loss: 2.178907904448211
Validation loss: 2.477025467111436

Epoch: 6| Step: 12
Training loss: 3.2395508857565813
Validation loss: 2.4758466133147565

Epoch: 6| Step: 13
Training loss: 2.488377160539962
Validation loss: 2.47822627229035

Epoch: 208| Step: 0
Training loss: 2.7226488942466993
Validation loss: 2.4732579387585067

Epoch: 6| Step: 1
Training loss: 2.9080583422342783
Validation loss: 2.4714134431623247

Epoch: 6| Step: 2
Training loss: 2.2626327222811704
Validation loss: 2.4727792091592127

Epoch: 6| Step: 3
Training loss: 3.328348788048997
Validation loss: 2.4724445302595504

Epoch: 6| Step: 4
Training loss: 2.1015820130076914
Validation loss: 2.4843411233379675

Epoch: 6| Step: 5
Training loss: 2.8541859721252507
Validation loss: 2.476227329489929

Epoch: 6| Step: 6
Training loss: 1.796418107036696
Validation loss: 2.479149719522291

Epoch: 6| Step: 7
Training loss: 2.097332522738705
Validation loss: 2.49004365078456

Epoch: 6| Step: 8
Training loss: 2.0203999582288
Validation loss: 2.482120250482647

Epoch: 6| Step: 9
Training loss: 3.0440576292139387
Validation loss: 2.4730064140130725

Epoch: 6| Step: 10
Training loss: 2.2925548797328528
Validation loss: 2.4783717465154798

Epoch: 6| Step: 11
Training loss: 2.289853528931482
Validation loss: 2.4878324046954083

Epoch: 6| Step: 12
Training loss: 2.1489764283220145
Validation loss: 2.477088495307423

Epoch: 6| Step: 13
Training loss: 2.3485057138166794
Validation loss: 2.467338287145834

Epoch: 209| Step: 0
Training loss: 2.251288151224483
Validation loss: 2.485323327084619

Epoch: 6| Step: 1
Training loss: 3.0714303425375054
Validation loss: 2.4844440954424605

Epoch: 6| Step: 2
Training loss: 2.3904989371378167
Validation loss: 2.49161583573239

Epoch: 6| Step: 3
Training loss: 2.6865464226513547
Validation loss: 2.489841133932625

Epoch: 6| Step: 4
Training loss: 2.3269052062224445
Validation loss: 2.499951028344208

Epoch: 6| Step: 5
Training loss: 2.3947940949743924
Validation loss: 2.4883453983679558

Epoch: 6| Step: 6
Training loss: 2.2992813065548035
Validation loss: 2.493384804113634

Epoch: 6| Step: 7
Training loss: 2.3139444943153276
Validation loss: 2.49518772928811

Epoch: 6| Step: 8
Training loss: 2.263619001822656
Validation loss: 2.499801786830215

Epoch: 6| Step: 9
Training loss: 2.4696103299062364
Validation loss: 2.489768341936616

Epoch: 6| Step: 10
Training loss: 2.1482202038549234
Validation loss: 2.493101552280965

Epoch: 6| Step: 11
Training loss: 2.6888495317141157
Validation loss: 2.4947928400109918

Epoch: 6| Step: 12
Training loss: 2.3864312381169195
Validation loss: 2.4844908777239514

Epoch: 6| Step: 13
Training loss: 2.3470218455041967
Validation loss: 2.4947143627658788

Epoch: 210| Step: 0
Training loss: 2.203245984806933
Validation loss: 2.4900473051926886

Epoch: 6| Step: 1
Training loss: 2.4236817542428315
Validation loss: 2.4948204665356704

Epoch: 6| Step: 2
Training loss: 2.477298855743187
Validation loss: 2.4817883283085864

Epoch: 6| Step: 3
Training loss: 2.864137945518594
Validation loss: 2.4869519110712326

Epoch: 6| Step: 4
Training loss: 2.722918417087762
Validation loss: 2.4864809399330756

Epoch: 6| Step: 5
Training loss: 2.205427116841587
Validation loss: 2.4842591168709576

Epoch: 6| Step: 6
Training loss: 2.8241719813187576
Validation loss: 2.4883250138343205

Epoch: 6| Step: 7
Training loss: 2.3753102752390065
Validation loss: 2.483196610862305

Epoch: 6| Step: 8
Training loss: 2.387042484085966
Validation loss: 2.4938479784310914

Epoch: 6| Step: 9
Training loss: 2.0421682507192216
Validation loss: 2.4956050069956937

Epoch: 6| Step: 10
Training loss: 2.6040696901702587
Validation loss: 2.48899290566655

Epoch: 6| Step: 11
Training loss: 2.35714353421024
Validation loss: 2.504415237183486

Epoch: 6| Step: 12
Training loss: 1.958359440839175
Validation loss: 2.5009855076338066

Epoch: 6| Step: 13
Training loss: 2.3100603999048372
Validation loss: 2.4978805458780924

Epoch: 211| Step: 0
Training loss: 2.568105010574317
Validation loss: 2.506865848590179

Epoch: 6| Step: 1
Training loss: 2.491716585541697
Validation loss: 2.505269505209308

Epoch: 6| Step: 2
Training loss: 2.208883133110429
Validation loss: 2.5114591077700266

Epoch: 6| Step: 3
Training loss: 2.959389314546376
Validation loss: 2.5080517489353618

Epoch: 6| Step: 4
Training loss: 2.1529235612736595
Validation loss: 2.5010857767401538

Epoch: 6| Step: 5
Training loss: 1.5572905099241454
Validation loss: 2.4999814509657328

Epoch: 6| Step: 6
Training loss: 1.800034904141564
Validation loss: 2.4991004120059137

Epoch: 6| Step: 7
Training loss: 2.935341874183476
Validation loss: 2.4983188539746655

Epoch: 6| Step: 8
Training loss: 2.4170930968518523
Validation loss: 2.498173714192133

Epoch: 6| Step: 9
Training loss: 3.0210271488145404
Validation loss: 2.4962428152419984

Epoch: 6| Step: 10
Training loss: 3.030895409048425
Validation loss: 2.4867084988338717

Epoch: 6| Step: 11
Training loss: 2.596602743959215
Validation loss: 2.497816753748929

Epoch: 6| Step: 12
Training loss: 1.9483107781824638
Validation loss: 2.4899236587454667

Epoch: 6| Step: 13
Training loss: 1.9717538110215678
Validation loss: 2.4970564679600074

Epoch: 212| Step: 0
Training loss: 2.232991784107556
Validation loss: 2.4909261862008507

Epoch: 6| Step: 1
Training loss: 2.390168189990075
Validation loss: 2.48710750761302

Epoch: 6| Step: 2
Training loss: 2.1134047833507417
Validation loss: 2.5009016318455966

Epoch: 6| Step: 3
Training loss: 1.6720649397435874
Validation loss: 2.4939141107161307

Epoch: 6| Step: 4
Training loss: 2.6871702302390443
Validation loss: 2.483876432219174

Epoch: 6| Step: 5
Training loss: 1.5637278500824672
Validation loss: 2.4952324389610605

Epoch: 6| Step: 6
Training loss: 2.198036973984165
Validation loss: 2.4809926999020706

Epoch: 6| Step: 7
Training loss: 2.677454871929131
Validation loss: 2.483546744741078

Epoch: 6| Step: 8
Training loss: 3.240209946129281
Validation loss: 2.4762339248661793

Epoch: 6| Step: 9
Training loss: 2.561543728176879
Validation loss: 2.4810299216037905

Epoch: 6| Step: 10
Training loss: 2.742061079540028
Validation loss: 2.4856266251736883

Epoch: 6| Step: 11
Training loss: 2.4292613940692616
Validation loss: 2.489251020164596

Epoch: 6| Step: 12
Training loss: 2.6835380448469275
Validation loss: 2.479892629765368

Epoch: 6| Step: 13
Training loss: 2.3468307592537103
Validation loss: 2.492660334106765

Epoch: 213| Step: 0
Training loss: 1.95153682988115
Validation loss: 2.497520456927185

Epoch: 6| Step: 1
Training loss: 2.663393535132546
Validation loss: 2.491873240014596

Epoch: 6| Step: 2
Training loss: 2.654289689099912
Validation loss: 2.497270548478656

Epoch: 6| Step: 3
Training loss: 2.3788480203451727
Validation loss: 2.5030497545607764

Epoch: 6| Step: 4
Training loss: 2.1080514782260593
Validation loss: 2.4991232606231164

Epoch: 6| Step: 5
Training loss: 2.1480322993245817
Validation loss: 2.5034512221933642

Epoch: 6| Step: 6
Training loss: 2.819830771434486
Validation loss: 2.510019695716373

Epoch: 6| Step: 7
Training loss: 2.4627915921368677
Validation loss: 2.5015033334489614

Epoch: 6| Step: 8
Training loss: 2.877600116065211
Validation loss: 2.5084272445216245

Epoch: 6| Step: 9
Training loss: 2.070867845438299
Validation loss: 2.5228179391517003

Epoch: 6| Step: 10
Training loss: 2.5632551987756296
Validation loss: 2.502597270298459

Epoch: 6| Step: 11
Training loss: 2.5373298249707377
Validation loss: 2.4975473293673156

Epoch: 6| Step: 12
Training loss: 2.462286491626371
Validation loss: 2.4951972525554074

Epoch: 6| Step: 13
Training loss: 2.0707951972668464
Validation loss: 2.5031321455226068

Epoch: 214| Step: 0
Training loss: 2.462671062898593
Validation loss: 2.5037379295044198

Epoch: 6| Step: 1
Training loss: 2.1159549517821006
Validation loss: 2.4902926329735644

Epoch: 6| Step: 2
Training loss: 2.5233077733380123
Validation loss: 2.502174298181061

Epoch: 6| Step: 3
Training loss: 1.9336542909950942
Validation loss: 2.4939564293596614

Epoch: 6| Step: 4
Training loss: 2.269590393451345
Validation loss: 2.5019560631986146

Epoch: 6| Step: 5
Training loss: 2.1763617188132405
Validation loss: 2.4882638512466717

Epoch: 6| Step: 6
Training loss: 2.7289236606028298
Validation loss: 2.4945746203295287

Epoch: 6| Step: 7
Training loss: 2.8738560266502673
Validation loss: 2.5041649298468824

Epoch: 6| Step: 8
Training loss: 1.9413767146544523
Validation loss: 2.5038726058500855

Epoch: 6| Step: 9
Training loss: 2.474153423982691
Validation loss: 2.511289157388088

Epoch: 6| Step: 10
Training loss: 3.012149369344453
Validation loss: 2.5163466403757724

Epoch: 6| Step: 11
Training loss: 2.007447799631016
Validation loss: 2.5191160347818333

Epoch: 6| Step: 12
Training loss: 2.2207207322575955
Validation loss: 2.5130919978420847

Epoch: 6| Step: 13
Training loss: 2.830155291930185
Validation loss: 2.5144702480354004

Epoch: 215| Step: 0
Training loss: 2.0115871941966517
Validation loss: 2.4983825219494844

Epoch: 6| Step: 1
Training loss: 2.7861077394102702
Validation loss: 2.499821990351356

Epoch: 6| Step: 2
Training loss: 2.520012009758563
Validation loss: 2.506027703641271

Epoch: 6| Step: 3
Training loss: 2.4250862735463796
Validation loss: 2.504167659164799

Epoch: 6| Step: 4
Training loss: 1.6063856490630215
Validation loss: 2.504900706563766

Epoch: 6| Step: 5
Training loss: 3.006597417159409
Validation loss: 2.502427257963053

Epoch: 6| Step: 6
Training loss: 1.609785231369279
Validation loss: 2.50100743340373

Epoch: 6| Step: 7
Training loss: 2.5675650989336107
Validation loss: 2.500677644759756

Epoch: 6| Step: 8
Training loss: 2.244746645116758
Validation loss: 2.4941196585152094

Epoch: 6| Step: 9
Training loss: 2.52995106842007
Validation loss: 2.496875845376239

Epoch: 6| Step: 10
Training loss: 2.877793654795298
Validation loss: 2.5029699327535258

Epoch: 6| Step: 11
Training loss: 2.205299548780962
Validation loss: 2.4952062980331635

Epoch: 6| Step: 12
Training loss: 2.344921988875351
Validation loss: 2.504643570230542

Epoch: 6| Step: 13
Training loss: 2.5766836125193717
Validation loss: 2.5031934686726935

Epoch: 216| Step: 0
Training loss: 2.3824444596020236
Validation loss: 2.4932052463467524

Epoch: 6| Step: 1
Training loss: 2.2812113301383246
Validation loss: 2.5055275130153465

Epoch: 6| Step: 2
Training loss: 2.783470467560329
Validation loss: 2.5120934285538765

Epoch: 6| Step: 3
Training loss: 2.588257823300354
Validation loss: 2.5106768862346986

Epoch: 6| Step: 4
Training loss: 1.9925366264049722
Validation loss: 2.5001796419451074

Epoch: 6| Step: 5
Training loss: 1.6265880454454906
Validation loss: 2.519708608451929

Epoch: 6| Step: 6
Training loss: 2.772534376504011
Validation loss: 2.526295463685201

Epoch: 6| Step: 7
Training loss: 1.7846658980622392
Validation loss: 2.521615077934675

Epoch: 6| Step: 8
Training loss: 2.679005082766733
Validation loss: 2.527429185196625

Epoch: 6| Step: 9
Training loss: 2.40858494809275
Validation loss: 2.5160295623170583

Epoch: 6| Step: 10
Training loss: 2.8527339671517407
Validation loss: 2.5079226682554925

Epoch: 6| Step: 11
Training loss: 2.0482803063270794
Validation loss: 2.5080907554389476

Epoch: 6| Step: 12
Training loss: 2.585558445742211
Validation loss: 2.5008832801662324

Epoch: 6| Step: 13
Training loss: 2.694015765964562
Validation loss: 2.500756149380533

Epoch: 217| Step: 0
Training loss: 1.8532622056572245
Validation loss: 2.4998299699819153

Epoch: 6| Step: 1
Training loss: 1.816017486643519
Validation loss: 2.4989658441996525

Epoch: 6| Step: 2
Training loss: 2.887315494868328
Validation loss: 2.5023271299491685

Epoch: 6| Step: 3
Training loss: 2.562651839060895
Validation loss: 2.5256817013912007

Epoch: 6| Step: 4
Training loss: 3.195864305673556
Validation loss: 2.5155925709152576

Epoch: 6| Step: 5
Training loss: 2.8356361754518598
Validation loss: 2.538347943823936

Epoch: 6| Step: 6
Training loss: 1.462879053536094
Validation loss: 2.5205166331406224

Epoch: 6| Step: 7
Training loss: 2.7488289854073544
Validation loss: 2.522565330740636

Epoch: 6| Step: 8
Training loss: 2.3528513877229815
Validation loss: 2.5241616138228427

Epoch: 6| Step: 9
Training loss: 2.3364126685401367
Validation loss: 2.497089575378808

Epoch: 6| Step: 10
Training loss: 2.494778138656944
Validation loss: 2.4827077457390683

Epoch: 6| Step: 11
Training loss: 2.469867694724428
Validation loss: 2.475343261702264

Epoch: 6| Step: 12
Training loss: 1.9828697563063096
Validation loss: 2.4887436816832884

Epoch: 6| Step: 13
Training loss: 2.4474348419213205
Validation loss: 2.475647108336742

Epoch: 218| Step: 0
Training loss: 2.4575666320398164
Validation loss: 2.4860521649334766

Epoch: 6| Step: 1
Training loss: 1.9067565995238829
Validation loss: 2.483187329610759

Epoch: 6| Step: 2
Training loss: 2.192014885086141
Validation loss: 2.481366685354483

Epoch: 6| Step: 3
Training loss: 2.65043110489767
Validation loss: 2.4812317002756266

Epoch: 6| Step: 4
Training loss: 2.391930317275191
Validation loss: 2.4735110444063375

Epoch: 6| Step: 5
Training loss: 2.2296818883513825
Validation loss: 2.4748970472713174

Epoch: 6| Step: 6
Training loss: 2.3628233915334502
Validation loss: 2.471135721042191

Epoch: 6| Step: 7
Training loss: 1.8792608168446607
Validation loss: 2.4649472625486735

Epoch: 6| Step: 8
Training loss: 3.072702967222877
Validation loss: 2.4643120774148266

Epoch: 6| Step: 9
Training loss: 2.2798006862390032
Validation loss: 2.4778516685214758

Epoch: 6| Step: 10
Training loss: 3.0202561627307682
Validation loss: 2.4795160501520512

Epoch: 6| Step: 11
Training loss: 2.331094166965116
Validation loss: 2.4684501739510134

Epoch: 6| Step: 12
Training loss: 2.657957807063927
Validation loss: 2.473388740153725

Epoch: 6| Step: 13
Training loss: 2.731767817454072
Validation loss: 2.480599739841221

Epoch: 219| Step: 0
Training loss: 2.59710292802854
Validation loss: 2.484331958325929

Epoch: 6| Step: 1
Training loss: 2.2904227840163083
Validation loss: 2.4917220794189188

Epoch: 6| Step: 2
Training loss: 2.6030042164636873
Validation loss: 2.5037586091265407

Epoch: 6| Step: 3
Training loss: 2.2556534842460203
Validation loss: 2.50733672290273

Epoch: 6| Step: 4
Training loss: 2.5244797010023086
Validation loss: 2.5086924196613194

Epoch: 6| Step: 5
Training loss: 2.672558078116957
Validation loss: 2.5061188363041906

Epoch: 6| Step: 6
Training loss: 2.4533300617790523
Validation loss: 2.4988896129255243

Epoch: 6| Step: 7
Training loss: 2.949946231675315
Validation loss: 2.507113548474167

Epoch: 6| Step: 8
Training loss: 2.2128393397907553
Validation loss: 2.491929011955927

Epoch: 6| Step: 9
Training loss: 2.260962588810998
Validation loss: 2.506016310834358

Epoch: 6| Step: 10
Training loss: 2.485727769599009
Validation loss: 2.5121502226352477

Epoch: 6| Step: 11
Training loss: 1.968022348265409
Validation loss: 2.508032863359044

Epoch: 6| Step: 12
Training loss: 2.1320819651609435
Validation loss: 2.503263473331745

Epoch: 6| Step: 13
Training loss: 2.672068449457084
Validation loss: 2.512281545628194

Epoch: 220| Step: 0
Training loss: 2.4384929884058297
Validation loss: 2.5105873514191526

Epoch: 6| Step: 1
Training loss: 2.3946551093323163
Validation loss: 2.505622739612438

Epoch: 6| Step: 2
Training loss: 2.60402409481146
Validation loss: 2.5019311439884673

Epoch: 6| Step: 3
Training loss: 1.6289855791346983
Validation loss: 2.5091872680673077

Epoch: 6| Step: 4
Training loss: 2.08913733406103
Validation loss: 2.5058072828793665

Epoch: 6| Step: 5
Training loss: 2.69209836523357
Validation loss: 2.5039812970432878

Epoch: 6| Step: 6
Training loss: 2.7861661003148575
Validation loss: 2.5095955599350264

Epoch: 6| Step: 7
Training loss: 2.4547648203404644
Validation loss: 2.511551079658635

Epoch: 6| Step: 8
Training loss: 2.4054416438152346
Validation loss: 2.504610451607709

Epoch: 6| Step: 9
Training loss: 2.1008730753743805
Validation loss: 2.5145086176743483

Epoch: 6| Step: 10
Training loss: 2.3722778581303534
Validation loss: 2.523998359575862

Epoch: 6| Step: 11
Training loss: 2.7139346569743825
Validation loss: 2.5300148199046935

Epoch: 6| Step: 12
Training loss: 2.8005448458404003
Validation loss: 2.525936294927266

Epoch: 6| Step: 13
Training loss: 2.1082818483642867
Validation loss: 2.524789296540013

Epoch: 221| Step: 0
Training loss: 2.3582164623116504
Validation loss: 2.52860426287491

Epoch: 6| Step: 1
Training loss: 2.6376262544180906
Validation loss: 2.5182376192116065

Epoch: 6| Step: 2
Training loss: 2.0824558190173397
Validation loss: 2.5095248451956347

Epoch: 6| Step: 3
Training loss: 2.301404677481227
Validation loss: 2.507916488947442

Epoch: 6| Step: 4
Training loss: 2.393545921929074
Validation loss: 2.521000995787611

Epoch: 6| Step: 5
Training loss: 2.038177415067925
Validation loss: 2.498734543323021

Epoch: 6| Step: 6
Training loss: 2.8527419903854776
Validation loss: 2.5037165513885675

Epoch: 6| Step: 7
Training loss: 3.072430140024673
Validation loss: 2.4990065349103143

Epoch: 6| Step: 8
Training loss: 2.335822979725721
Validation loss: 2.498932785490871

Epoch: 6| Step: 9
Training loss: 2.5477304718613736
Validation loss: 2.4865067490998065

Epoch: 6| Step: 10
Training loss: 2.395929970381779
Validation loss: 2.494916117729049

Epoch: 6| Step: 11
Training loss: 1.554383674723152
Validation loss: 2.48770724252753

Epoch: 6| Step: 12
Training loss: 1.8806971146260874
Validation loss: 2.4855028867088964

Epoch: 6| Step: 13
Training loss: 2.9701488210980633
Validation loss: 2.4766223791928095

Epoch: 222| Step: 0
Training loss: 2.9546708193771614
Validation loss: 2.479486850824431

Epoch: 6| Step: 1
Training loss: 2.3026434675784566
Validation loss: 2.4880627147420182

Epoch: 6| Step: 2
Training loss: 2.5833020567282463
Validation loss: 2.4848562610177494

Epoch: 6| Step: 3
Training loss: 2.5260073210488585
Validation loss: 2.4928796618180082

Epoch: 6| Step: 4
Training loss: 1.8753051509500227
Validation loss: 2.4875547105916374

Epoch: 6| Step: 5
Training loss: 2.176415616328269
Validation loss: 2.490999295306428

Epoch: 6| Step: 6
Training loss: 1.9498696014624977
Validation loss: 2.4912624575617204

Epoch: 6| Step: 7
Training loss: 2.104074444654048
Validation loss: 2.5027973578145004

Epoch: 6| Step: 8
Training loss: 2.534311585861809
Validation loss: 2.514534518429924

Epoch: 6| Step: 9
Training loss: 2.5383309117299597
Validation loss: 2.504250267228599

Epoch: 6| Step: 10
Training loss: 2.5751379105756427
Validation loss: 2.509364237273347

Epoch: 6| Step: 11
Training loss: 2.324869529590932
Validation loss: 2.5213269677783665

Epoch: 6| Step: 12
Training loss: 2.7631761301724835
Validation loss: 2.5335643376468275

Epoch: 6| Step: 13
Training loss: 2.199525638938186
Validation loss: 2.5049512153590814

Epoch: 223| Step: 0
Training loss: 2.0507062625799244
Validation loss: 2.520459854160412

Epoch: 6| Step: 1
Training loss: 2.688304869313288
Validation loss: 2.5297074032637292

Epoch: 6| Step: 2
Training loss: 1.7998060121909123
Validation loss: 2.5123458878301865

Epoch: 6| Step: 3
Training loss: 2.236163084111961
Validation loss: 2.5113301547575255

Epoch: 6| Step: 4
Training loss: 2.412599583285129
Validation loss: 2.4817503654433852

Epoch: 6| Step: 5
Training loss: 1.7368297903485217
Validation loss: 2.486503728721999

Epoch: 6| Step: 6
Training loss: 2.782382777264834
Validation loss: 2.4964663168307224

Epoch: 6| Step: 7
Training loss: 2.101820692347071
Validation loss: 2.496919386958147

Epoch: 6| Step: 8
Training loss: 2.441025751599254
Validation loss: 2.503905408901762

Epoch: 6| Step: 9
Training loss: 2.4423185795357067
Validation loss: 2.5044880635896116

Epoch: 6| Step: 10
Training loss: 3.156638848552433
Validation loss: 2.4922286680960872

Epoch: 6| Step: 11
Training loss: 2.6533390026255605
Validation loss: 2.4951890431189536

Epoch: 6| Step: 12
Training loss: 3.06152795429292
Validation loss: 2.493007656500329

Epoch: 6| Step: 13
Training loss: 2.7900079572557304
Validation loss: 2.5012146224392797

Epoch: 224| Step: 0
Training loss: 2.154520529846837
Validation loss: 2.499934036656216

Epoch: 6| Step: 1
Training loss: 2.46955337007651
Validation loss: 2.5021794991246007

Epoch: 6| Step: 2
Training loss: 1.9401651325930318
Validation loss: 2.505241272221385

Epoch: 6| Step: 3
Training loss: 2.5671541700561957
Validation loss: 2.500345587686096

Epoch: 6| Step: 4
Training loss: 2.104543847248775
Validation loss: 2.4944315327204216

Epoch: 6| Step: 5
Training loss: 2.052295525386865
Validation loss: 2.4958567141126076

Epoch: 6| Step: 6
Training loss: 2.433067399564836
Validation loss: 2.5105347875978077

Epoch: 6| Step: 7
Training loss: 2.889378954410013
Validation loss: 2.5156201585679625

Epoch: 6| Step: 8
Training loss: 2.8207873845454987
Validation loss: 2.511394885250723

Epoch: 6| Step: 9
Training loss: 2.0083162737025524
Validation loss: 2.486139051066082

Epoch: 6| Step: 10
Training loss: 2.711857444493602
Validation loss: 2.492712366207403

Epoch: 6| Step: 11
Training loss: 2.0765868496238635
Validation loss: 2.5006436790881645

Epoch: 6| Step: 12
Training loss: 2.133667044566202
Validation loss: 2.507766057710421

Epoch: 6| Step: 13
Training loss: 2.905077954295242
Validation loss: 2.503830803951027

Epoch: 225| Step: 0
Training loss: 2.0690352044482214
Validation loss: 2.520866328146987

Epoch: 6| Step: 1
Training loss: 1.9393076923773884
Validation loss: 2.5038232814395163

Epoch: 6| Step: 2
Training loss: 2.8902633853203477
Validation loss: 2.511171968626608

Epoch: 6| Step: 3
Training loss: 2.7398803221189993
Validation loss: 2.5275365175199447

Epoch: 6| Step: 4
Training loss: 2.529242013461482
Validation loss: 2.512080362807181

Epoch: 6| Step: 5
Training loss: 2.1214703810343902
Validation loss: 2.5181429091115177

Epoch: 6| Step: 6
Training loss: 2.154480691989265
Validation loss: 2.5228921086328606

Epoch: 6| Step: 7
Training loss: 2.3729072184342486
Validation loss: 2.5085275488234076

Epoch: 6| Step: 8
Training loss: 2.506087901516903
Validation loss: 2.513268783011923

Epoch: 6| Step: 9
Training loss: 2.690381656501843
Validation loss: 2.5138923253925176

Epoch: 6| Step: 10
Training loss: 2.5364392623863283
Validation loss: 2.503048817923462

Epoch: 6| Step: 11
Training loss: 1.7932622000378853
Validation loss: 2.501478338245512

Epoch: 6| Step: 12
Training loss: 2.1248144180940445
Validation loss: 2.500566394541532

Epoch: 6| Step: 13
Training loss: 2.7399386234788015
Validation loss: 2.5083439185678515

Epoch: 226| Step: 0
Training loss: 2.188348115269208
Validation loss: 2.4946736816879858

Epoch: 6| Step: 1
Training loss: 2.566198053145456
Validation loss: 2.5032810773699223

Epoch: 6| Step: 2
Training loss: 1.9105634820809487
Validation loss: 2.50654976685917

Epoch: 6| Step: 3
Training loss: 2.3860953308144195
Validation loss: 2.521714857674261

Epoch: 6| Step: 4
Training loss: 2.1237964587774014
Validation loss: 2.5219077245644526

Epoch: 6| Step: 5
Training loss: 2.20637586196797
Validation loss: 2.5259174958742303

Epoch: 6| Step: 6
Training loss: 2.3303762726397896
Validation loss: 2.535435501024498

Epoch: 6| Step: 7
Training loss: 1.85574158921225
Validation loss: 2.5374774386901597

Epoch: 6| Step: 8
Training loss: 2.1658015235638364
Validation loss: 2.523512848003734

Epoch: 6| Step: 9
Training loss: 3.2319943424779645
Validation loss: 2.5255236274723187

Epoch: 6| Step: 10
Training loss: 2.0385559154305564
Validation loss: 2.5371711063681537

Epoch: 6| Step: 11
Training loss: 3.1267969686961234
Validation loss: 2.524528007960919

Epoch: 6| Step: 12
Training loss: 2.5361891230933318
Validation loss: 2.5220021829910775

Epoch: 6| Step: 13
Training loss: 2.4309611524006716
Validation loss: 2.5004745509838324

Epoch: 227| Step: 0
Training loss: 2.4339749204586374
Validation loss: 2.5152047479555986

Epoch: 6| Step: 1
Training loss: 2.3985179179374994
Validation loss: 2.5129978686190966

Epoch: 6| Step: 2
Training loss: 2.474232826397636
Validation loss: 2.503421556016219

Epoch: 6| Step: 3
Training loss: 1.660215345340677
Validation loss: 2.511549798119245

Epoch: 6| Step: 4
Training loss: 2.191024121373257
Validation loss: 2.515099701621039

Epoch: 6| Step: 5
Training loss: 1.973323595832736
Validation loss: 2.504597798988285

Epoch: 6| Step: 6
Training loss: 2.6915711904624846
Validation loss: 2.508948626306382

Epoch: 6| Step: 7
Training loss: 2.3598794966175514
Validation loss: 2.510128643138549

Epoch: 6| Step: 8
Training loss: 2.451387604114843
Validation loss: 2.499942015929132

Epoch: 6| Step: 9
Training loss: 2.081053083572235
Validation loss: 2.4991714058076706

Epoch: 6| Step: 10
Training loss: 2.614616018954735
Validation loss: 2.4996072619624425

Epoch: 6| Step: 11
Training loss: 2.723149565523969
Validation loss: 2.493108501480148

Epoch: 6| Step: 12
Training loss: 3.201484669548719
Validation loss: 2.5049916502152887

Epoch: 6| Step: 13
Training loss: 1.8787383640967041
Validation loss: 2.503893887414432

Epoch: 228| Step: 0
Training loss: 2.9663995372504375
Validation loss: 2.5012516385336303

Epoch: 6| Step: 1
Training loss: 2.090662487475117
Validation loss: 2.496096106076907

Epoch: 6| Step: 2
Training loss: 2.486159445531347
Validation loss: 2.4934274823429425

Epoch: 6| Step: 3
Training loss: 2.430118044274073
Validation loss: 2.4946715313384704

Epoch: 6| Step: 4
Training loss: 2.5996259750420876
Validation loss: 2.4921472400693956

Epoch: 6| Step: 5
Training loss: 2.289541877831777
Validation loss: 2.5113531294476976

Epoch: 6| Step: 6
Training loss: 2.048837434440242
Validation loss: 2.5015696842964887

Epoch: 6| Step: 7
Training loss: 1.8197252365882124
Validation loss: 2.499914589058674

Epoch: 6| Step: 8
Training loss: 2.5178098490562464
Validation loss: 2.5129980741797833

Epoch: 6| Step: 9
Training loss: 1.8839401730313847
Validation loss: 2.5145162978530036

Epoch: 6| Step: 10
Training loss: 2.600828691613055
Validation loss: 2.51948576499237

Epoch: 6| Step: 11
Training loss: 2.315985861805931
Validation loss: 2.5156124975553262

Epoch: 6| Step: 12
Training loss: 2.5687482068132144
Validation loss: 2.5248907606962927

Epoch: 6| Step: 13
Training loss: 2.568779949375619
Validation loss: 2.53148648448523

Epoch: 229| Step: 0
Training loss: 2.7505953751147296
Validation loss: 2.5223820765454463

Epoch: 6| Step: 1
Training loss: 2.437568174533641
Validation loss: 2.528297429124266

Epoch: 6| Step: 2
Training loss: 2.9206060418155095
Validation loss: 2.5188851171179323

Epoch: 6| Step: 3
Training loss: 2.202765469264817
Validation loss: 2.510937131586149

Epoch: 6| Step: 4
Training loss: 2.018703032617459
Validation loss: 2.5082278279096655

Epoch: 6| Step: 5
Training loss: 2.944955333636532
Validation loss: 2.5071009243367084

Epoch: 6| Step: 6
Training loss: 2.2683535226805858
Validation loss: 2.501827088913043

Epoch: 6| Step: 7
Training loss: 1.753268731357018
Validation loss: 2.5101559821519612

Epoch: 6| Step: 8
Training loss: 2.624080860345828
Validation loss: 2.5057567120496134

Epoch: 6| Step: 9
Training loss: 2.125756073129344
Validation loss: 2.5032069935349126

Epoch: 6| Step: 10
Training loss: 2.1458693813024428
Validation loss: 2.490440386060914

Epoch: 6| Step: 11
Training loss: 2.806220525574046
Validation loss: 2.5073725392688506

Epoch: 6| Step: 12
Training loss: 1.9766444615193823
Validation loss: 2.490609030869813

Epoch: 6| Step: 13
Training loss: 2.4401074670357437
Validation loss: 2.4902581028026023

Epoch: 230| Step: 0
Training loss: 2.749405709988556
Validation loss: 2.5024500365069677

Epoch: 6| Step: 1
Training loss: 1.6733393450675869
Validation loss: 2.5042170719991543

Epoch: 6| Step: 2
Training loss: 2.5755672829929397
Validation loss: 2.505963841414137

Epoch: 6| Step: 3
Training loss: 2.0223986930607545
Validation loss: 2.5129870845656583

Epoch: 6| Step: 4
Training loss: 3.1721711419827776
Validation loss: 2.5084743478071823

Epoch: 6| Step: 5
Training loss: 1.654978065806363
Validation loss: 2.51041265674656

Epoch: 6| Step: 6
Training loss: 2.009387634142702
Validation loss: 2.5084746329429253

Epoch: 6| Step: 7
Training loss: 2.055259479930987
Validation loss: 2.506566372861947

Epoch: 6| Step: 8
Training loss: 2.660935700842114
Validation loss: 2.5232756555895115

Epoch: 6| Step: 9
Training loss: 1.764959564394191
Validation loss: 2.5357942488616088

Epoch: 6| Step: 10
Training loss: 1.9885578675073896
Validation loss: 2.5260858643325874

Epoch: 6| Step: 11
Training loss: 2.9424555757162207
Validation loss: 2.575053749634574

Epoch: 6| Step: 12
Training loss: 2.626559384699874
Validation loss: 2.5615466910986626

Epoch: 6| Step: 13
Training loss: 2.8714720600036903
Validation loss: 2.5622859183104127

Epoch: 231| Step: 0
Training loss: 2.3290503794166497
Validation loss: 2.52866884974734

Epoch: 6| Step: 1
Training loss: 2.09017593738392
Validation loss: 2.520486040598973

Epoch: 6| Step: 2
Training loss: 2.7186587088154908
Validation loss: 2.5078395790547447

Epoch: 6| Step: 3
Training loss: 2.351177095279707
Validation loss: 2.495184034632817

Epoch: 6| Step: 4
Training loss: 2.725768840014787
Validation loss: 2.4769767470938677

Epoch: 6| Step: 5
Training loss: 2.4950715122409397
Validation loss: 2.491279476493507

Epoch: 6| Step: 6
Training loss: 3.090103620748484
Validation loss: 2.489646086174599

Epoch: 6| Step: 7
Training loss: 2.065824892007073
Validation loss: 2.489620612808389

Epoch: 6| Step: 8
Training loss: 1.9147387497189514
Validation loss: 2.5038269474764303

Epoch: 6| Step: 9
Training loss: 2.06908198801602
Validation loss: 2.483160909858249

Epoch: 6| Step: 10
Training loss: 2.709647539592255
Validation loss: 2.5050162693137485

Epoch: 6| Step: 11
Training loss: 2.5291305899731027
Validation loss: 2.4958486103318434

Epoch: 6| Step: 12
Training loss: 2.4498080042132533
Validation loss: 2.4879945343290766

Epoch: 6| Step: 13
Training loss: 2.427428836270483
Validation loss: 2.506341409641381

Epoch: 232| Step: 0
Training loss: 2.4234415217845213
Validation loss: 2.4830626374331812

Epoch: 6| Step: 1
Training loss: 2.7343969725679678
Validation loss: 2.4956383008544347

Epoch: 6| Step: 2
Training loss: 2.1775957687813308
Validation loss: 2.4941661159295125

Epoch: 6| Step: 3
Training loss: 2.568914340440196
Validation loss: 2.511097350113315

Epoch: 6| Step: 4
Training loss: 1.7320864588189513
Validation loss: 2.5070371766226884

Epoch: 6| Step: 5
Training loss: 2.323313406918571
Validation loss: 2.5068899737563717

Epoch: 6| Step: 6
Training loss: 2.110471426381093
Validation loss: 2.5092261935744697

Epoch: 6| Step: 7
Training loss: 1.8055135974736471
Validation loss: 2.5264153168130026

Epoch: 6| Step: 8
Training loss: 2.30193192572407
Validation loss: 2.5146236598698386

Epoch: 6| Step: 9
Training loss: 2.197893356513005
Validation loss: 2.530925235400644

Epoch: 6| Step: 10
Training loss: 2.5998074680348178
Validation loss: 2.5191672523019175

Epoch: 6| Step: 11
Training loss: 2.4984841519521694
Validation loss: 2.5485044076487395

Epoch: 6| Step: 12
Training loss: 2.4178072331580585
Validation loss: 2.5448356998322756

Epoch: 6| Step: 13
Training loss: 3.1650886284590793
Validation loss: 2.556369107494204

Epoch: 233| Step: 0
Training loss: 2.8448504320461017
Validation loss: 2.5255673517049684

Epoch: 6| Step: 1
Training loss: 2.596205594560511
Validation loss: 2.535155764101175

Epoch: 6| Step: 2
Training loss: 2.290157329701957
Validation loss: 2.5102134611795166

Epoch: 6| Step: 3
Training loss: 2.600261832771559
Validation loss: 2.4949577026757126

Epoch: 6| Step: 4
Training loss: 1.9323437898774203
Validation loss: 2.4963767817047446

Epoch: 6| Step: 5
Training loss: 1.9022300106567012
Validation loss: 2.4976159808544263

Epoch: 6| Step: 6
Training loss: 2.712540649953273
Validation loss: 2.5012395408446007

Epoch: 6| Step: 7
Training loss: 2.237364150030958
Validation loss: 2.497326040767824

Epoch: 6| Step: 8
Training loss: 2.2433113710746384
Validation loss: 2.4864081454529012

Epoch: 6| Step: 9
Training loss: 1.4674257842603189
Validation loss: 2.495058046798393

Epoch: 6| Step: 10
Training loss: 2.210259970654678
Validation loss: 2.48852501138825

Epoch: 6| Step: 11
Training loss: 2.6255330952244065
Validation loss: 2.496397792902674

Epoch: 6| Step: 12
Training loss: 3.2181049181974113
Validation loss: 2.489609759415283

Epoch: 6| Step: 13
Training loss: 2.6206197978140255
Validation loss: 2.5040812081614408

Epoch: 234| Step: 0
Training loss: 2.675628702312172
Validation loss: 2.5309597916505915

Epoch: 6| Step: 1
Training loss: 2.449542691894563
Validation loss: 2.550625043197715

Epoch: 6| Step: 2
Training loss: 2.29123914950185
Validation loss: 2.557198444436114

Epoch: 6| Step: 3
Training loss: 2.7045446647951796
Validation loss: 2.5653220508552703

Epoch: 6| Step: 4
Training loss: 2.4522070655513755
Validation loss: 2.5619191542641695

Epoch: 6| Step: 5
Training loss: 2.1550624728606764
Validation loss: 2.5858969786082393

Epoch: 6| Step: 6
Training loss: 2.738404362369309
Validation loss: 2.575400575633734

Epoch: 6| Step: 7
Training loss: 2.172010458694484
Validation loss: 2.582440888675245

Epoch: 6| Step: 8
Training loss: 2.0776616777474084
Validation loss: 2.578658632480265

Epoch: 6| Step: 9
Training loss: 2.0602353696707527
Validation loss: 2.59706438631021

Epoch: 6| Step: 10
Training loss: 2.645968656508536
Validation loss: 2.5852459062431308

Epoch: 6| Step: 11
Training loss: 2.056873159856909
Validation loss: 2.561574947272176

Epoch: 6| Step: 12
Training loss: 3.016157824629091
Validation loss: 2.524735973893973

Epoch: 6| Step: 13
Training loss: 1.957413322020484
Validation loss: 2.507909137135467

Epoch: 235| Step: 0
Training loss: 2.716305741125704
Validation loss: 2.4881242655644646

Epoch: 6| Step: 1
Training loss: 2.4302226271510783
Validation loss: 2.489693744291367

Epoch: 6| Step: 2
Training loss: 3.1042035674562336
Validation loss: 2.4954256328685593

Epoch: 6| Step: 3
Training loss: 2.3190554929133165
Validation loss: 2.497385008426843

Epoch: 6| Step: 4
Training loss: 2.147198906108845
Validation loss: 2.505999867680032

Epoch: 6| Step: 5
Training loss: 2.3339905040452997
Validation loss: 2.49888142357022

Epoch: 6| Step: 6
Training loss: 2.4301731813986747
Validation loss: 2.4999361506891695

Epoch: 6| Step: 7
Training loss: 2.6752292035742458
Validation loss: 2.5043383784353956

Epoch: 6| Step: 8
Training loss: 2.1174797053529906
Validation loss: 2.4970070566483265

Epoch: 6| Step: 9
Training loss: 2.7038627014797494
Validation loss: 2.4914231358894225

Epoch: 6| Step: 10
Training loss: 2.576507615892291
Validation loss: 2.4938815745839897

Epoch: 6| Step: 11
Training loss: 1.4578230192044115
Validation loss: 2.488178628335419

Epoch: 6| Step: 12
Training loss: 2.0089164103790833
Validation loss: 2.4994886352164705

Epoch: 6| Step: 13
Training loss: 2.7332265131321667
Validation loss: 2.505281765840369

Epoch: 236| Step: 0
Training loss: 2.122200411983526
Validation loss: 2.5249155162614474

Epoch: 6| Step: 1
Training loss: 2.090697953529358
Validation loss: 2.5085748482285792

Epoch: 6| Step: 2
Training loss: 2.666388338186981
Validation loss: 2.514750990273321

Epoch: 6| Step: 3
Training loss: 2.7239391746844075
Validation loss: 2.5120524120046475

Epoch: 6| Step: 4
Training loss: 1.9605505816144728
Validation loss: 2.504533820971523

Epoch: 6| Step: 5
Training loss: 2.1545396738885696
Validation loss: 2.493358101959756

Epoch: 6| Step: 6
Training loss: 2.09422410749823
Validation loss: 2.489763825283537

Epoch: 6| Step: 7
Training loss: 2.1963125102961327
Validation loss: 2.488288005059144

Epoch: 6| Step: 8
Training loss: 2.7927910167989984
Validation loss: 2.492110949768655

Epoch: 6| Step: 9
Training loss: 3.0807886362449177
Validation loss: 2.4992235885434955

Epoch: 6| Step: 10
Training loss: 2.843716799364056
Validation loss: 2.4927854866896904

Epoch: 6| Step: 11
Training loss: 1.8771955351437677
Validation loss: 2.4933162672135367

Epoch: 6| Step: 12
Training loss: 2.217142731830891
Validation loss: 2.4953832674830165

Epoch: 6| Step: 13
Training loss: 2.544159547421186
Validation loss: 2.4940984528714507

Epoch: 237| Step: 0
Training loss: 2.2278160448135766
Validation loss: 2.499093097860235

Epoch: 6| Step: 1
Training loss: 2.5238412823354026
Validation loss: 2.497578576767158

Epoch: 6| Step: 2
Training loss: 2.5505305542363654
Validation loss: 2.5204661761370786

Epoch: 6| Step: 3
Training loss: 2.680467230791658
Validation loss: 2.5206374783265786

Epoch: 6| Step: 4
Training loss: 1.9085826672026514
Validation loss: 2.536534432921734

Epoch: 6| Step: 5
Training loss: 2.6674951716685906
Validation loss: 2.5374172416433374

Epoch: 6| Step: 6
Training loss: 2.3998019534095683
Validation loss: 2.5319875419726037

Epoch: 6| Step: 7
Training loss: 1.8418759665795708
Validation loss: 2.553589860174456

Epoch: 6| Step: 8
Training loss: 2.168587591153037
Validation loss: 2.5415116455663864

Epoch: 6| Step: 9
Training loss: 2.6180169001209386
Validation loss: 2.5278596268026248

Epoch: 6| Step: 10
Training loss: 2.140252296691596
Validation loss: 2.5312202671643824

Epoch: 6| Step: 11
Training loss: 2.649424321245804
Validation loss: 2.511075836846301

Epoch: 6| Step: 12
Training loss: 2.297535703960685
Validation loss: 2.5101140553497485

Epoch: 6| Step: 13
Training loss: 2.5676613907201666
Validation loss: 2.507114158678824

Epoch: 238| Step: 0
Training loss: 1.6200799552589633
Validation loss: 2.5092172778179678

Epoch: 6| Step: 1
Training loss: 2.162536303265093
Validation loss: 2.49697583392407

Epoch: 6| Step: 2
Training loss: 2.8253504172878716
Validation loss: 2.502955660447727

Epoch: 6| Step: 3
Training loss: 2.418567786635265
Validation loss: 2.5074838916188895

Epoch: 6| Step: 4
Training loss: 2.650778486957004
Validation loss: 2.505434011550195

Epoch: 6| Step: 5
Training loss: 2.411222793797397
Validation loss: 2.495218345348304

Epoch: 6| Step: 6
Training loss: 2.9689324573865665
Validation loss: 2.5068688761369153

Epoch: 6| Step: 7
Training loss: 2.1357421875
Validation loss: 2.505773053722865

Epoch: 6| Step: 8
Training loss: 2.2218568567750467
Validation loss: 2.515382221898744

Epoch: 6| Step: 9
Training loss: 2.328856385320066
Validation loss: 2.512224746607039

Epoch: 6| Step: 10
Training loss: 2.303515533918198
Validation loss: 2.5374499399042216

Epoch: 6| Step: 11
Training loss: 2.172592812894227
Validation loss: 2.537475434232917

Epoch: 6| Step: 12
Training loss: 2.412972410920912
Validation loss: 2.5324623124687773

Epoch: 6| Step: 13
Training loss: 2.4061132615115355
Validation loss: 2.5387213062021554

Epoch: 239| Step: 0
Training loss: 2.273345001541278
Validation loss: 2.5229787025626265

Epoch: 6| Step: 1
Training loss: 1.6724269348059437
Validation loss: 2.527394549229256

Epoch: 6| Step: 2
Training loss: 2.3767708651300006
Validation loss: 2.5145809542295194

Epoch: 6| Step: 3
Training loss: 2.9422999996125014
Validation loss: 2.5124465734264088

Epoch: 6| Step: 4
Training loss: 2.4815297658481317
Validation loss: 2.5194667522050804

Epoch: 6| Step: 5
Training loss: 2.40592885041729
Validation loss: 2.507924870620579

Epoch: 6| Step: 6
Training loss: 2.557750953302028
Validation loss: 2.512174241692598

Epoch: 6| Step: 7
Training loss: 1.7759079048446933
Validation loss: 2.5001219560758394

Epoch: 6| Step: 8
Training loss: 2.7666765358377328
Validation loss: 2.5045990126906

Epoch: 6| Step: 9
Training loss: 2.1651764904793134
Validation loss: 2.507359258746759

Epoch: 6| Step: 10
Training loss: 2.5542344557793304
Validation loss: 2.496454124325104

Epoch: 6| Step: 11
Training loss: 1.86123013313507
Validation loss: 2.5085897538509596

Epoch: 6| Step: 12
Training loss: 2.4915271230894382
Validation loss: 2.504280145732367

Epoch: 6| Step: 13
Training loss: 2.6732995769655794
Validation loss: 2.4884683088558903

Epoch: 240| Step: 0
Training loss: 2.1099236799059997
Validation loss: 2.500628233493328

Epoch: 6| Step: 1
Training loss: 2.2982483994150456
Validation loss: 2.490086386278753

Epoch: 6| Step: 2
Training loss: 2.789750898445669
Validation loss: 2.498625345585963

Epoch: 6| Step: 3
Training loss: 2.068246868989286
Validation loss: 2.492258419674051

Epoch: 6| Step: 4
Training loss: 2.282628727068782
Validation loss: 2.4988022796214993

Epoch: 6| Step: 5
Training loss: 2.38094329060227
Validation loss: 2.5107413012120827

Epoch: 6| Step: 6
Training loss: 2.5178597516913075
Validation loss: 2.5001159164258357

Epoch: 6| Step: 7
Training loss: 2.1185434651493007
Validation loss: 2.5072341521422805

Epoch: 6| Step: 8
Training loss: 2.562929722180017
Validation loss: 2.5149503320500446

Epoch: 6| Step: 9
Training loss: 2.369323169943343
Validation loss: 2.5111849283332615

Epoch: 6| Step: 10
Training loss: 2.352274435257993
Validation loss: 2.504162708306847

Epoch: 6| Step: 11
Training loss: 2.319326583040346
Validation loss: 2.506301345362661

Epoch: 6| Step: 12
Training loss: 2.68648492140011
Validation loss: 2.502754434499526

Epoch: 6| Step: 13
Training loss: 2.38191131059631
Validation loss: 2.523415769123246

Epoch: 241| Step: 0
Training loss: 1.9211138326705168
Validation loss: 2.5377550094074532

Epoch: 6| Step: 1
Training loss: 2.1976632669705007
Validation loss: 2.542068908213632

Epoch: 6| Step: 2
Training loss: 2.108881348666901
Validation loss: 2.550127678834922

Epoch: 6| Step: 3
Training loss: 2.9345262774878336
Validation loss: 2.5349885858658765

Epoch: 6| Step: 4
Training loss: 2.4800050317036435
Validation loss: 2.5514401981393164

Epoch: 6| Step: 5
Training loss: 2.471179491039616
Validation loss: 2.5527824741726652

Epoch: 6| Step: 6
Training loss: 1.5150933660561754
Validation loss: 2.546767031637537

Epoch: 6| Step: 7
Training loss: 2.85503353867481
Validation loss: 2.5458497556249338

Epoch: 6| Step: 8
Training loss: 2.1882004842456575
Validation loss: 2.5604098099279713

Epoch: 6| Step: 9
Training loss: 2.8293897635393037
Validation loss: 2.553582064098017

Epoch: 6| Step: 10
Training loss: 2.3081126478263907
Validation loss: 2.542250118097933

Epoch: 6| Step: 11
Training loss: 2.3265501494685092
Validation loss: 2.524233760334558

Epoch: 6| Step: 12
Training loss: 2.3747107681036055
Validation loss: 2.496703422167181

Epoch: 6| Step: 13
Training loss: 2.3382299905110684
Validation loss: 2.5065821940395807

Epoch: 242| Step: 0
Training loss: 2.38950236770056
Validation loss: 2.4965139402508005

Epoch: 6| Step: 1
Training loss: 2.3666571599026147
Validation loss: 2.492265163953437

Epoch: 6| Step: 2
Training loss: 2.3721763489769794
Validation loss: 2.4856531306225578

Epoch: 6| Step: 3
Training loss: 2.520737470164962
Validation loss: 2.492020859523355

Epoch: 6| Step: 4
Training loss: 2.615315055030015
Validation loss: 2.486400250599618

Epoch: 6| Step: 5
Training loss: 2.263894518615754
Validation loss: 2.492387004269137

Epoch: 6| Step: 6
Training loss: 2.6467808406074704
Validation loss: 2.4860585903916315

Epoch: 6| Step: 7
Training loss: 1.6995231268112487
Validation loss: 2.4860056757694635

Epoch: 6| Step: 8
Training loss: 1.9948642475147458
Validation loss: 2.4955105445984

Epoch: 6| Step: 9
Training loss: 2.714033925417188
Validation loss: 2.495338273875735

Epoch: 6| Step: 10
Training loss: 2.430884946271476
Validation loss: 2.5087976946792994

Epoch: 6| Step: 11
Training loss: 2.422307523436722
Validation loss: 2.496064887877402

Epoch: 6| Step: 12
Training loss: 2.525655332825422
Validation loss: 2.506669874527414

Epoch: 6| Step: 13
Training loss: 2.3114889873198567
Validation loss: 2.505865384949722

Epoch: 243| Step: 0
Training loss: 1.773591560024334
Validation loss: 2.4992572157804194

Epoch: 6| Step: 1
Training loss: 1.9148820640562658
Validation loss: 2.5047802840300517

Epoch: 6| Step: 2
Training loss: 2.9326975097225274
Validation loss: 2.5209107873120105

Epoch: 6| Step: 3
Training loss: 2.1476828619625445
Validation loss: 2.5388025864815096

Epoch: 6| Step: 4
Training loss: 2.412632589699148
Validation loss: 2.5396985553350473

Epoch: 6| Step: 5
Training loss: 2.502557019051905
Validation loss: 2.558044328011709

Epoch: 6| Step: 6
Training loss: 2.176713781309382
Validation loss: 2.568798651315744

Epoch: 6| Step: 7
Training loss: 3.396789291409518
Validation loss: 2.5782420584565804

Epoch: 6| Step: 8
Training loss: 2.5526521840249647
Validation loss: 2.5481722907539615

Epoch: 6| Step: 9
Training loss: 1.7795223089086134
Validation loss: 2.554478208035641

Epoch: 6| Step: 10
Training loss: 2.0808583117253714
Validation loss: 2.567192797075883

Epoch: 6| Step: 11
Training loss: 2.454451184276704
Validation loss: 2.5519960557195622

Epoch: 6| Step: 12
Training loss: 2.0809655530682485
Validation loss: 2.5624858731756577

Epoch: 6| Step: 13
Training loss: 2.4496631857902256
Validation loss: 2.5353005735033043

Epoch: 244| Step: 0
Training loss: 2.238085034143286
Validation loss: 2.518505839968331

Epoch: 6| Step: 1
Training loss: 2.489012127286947
Validation loss: 2.523037275418225

Epoch: 6| Step: 2
Training loss: 2.8679076909169523
Validation loss: 2.5049682285352377

Epoch: 6| Step: 3
Training loss: 2.780024569286207
Validation loss: 2.510073014371412

Epoch: 6| Step: 4
Training loss: 1.8249015102199828
Validation loss: 2.5068021345268146

Epoch: 6| Step: 5
Training loss: 1.945353189678618
Validation loss: 2.5061967344640723

Epoch: 6| Step: 6
Training loss: 2.455559852456332
Validation loss: 2.505807972690779

Epoch: 6| Step: 7
Training loss: 2.3132533315553983
Validation loss: 2.509084796712217

Epoch: 6| Step: 8
Training loss: 2.416755828089586
Validation loss: 2.5133524674244607

Epoch: 6| Step: 9
Training loss: 2.4936123305636664
Validation loss: 2.517822774596483

Epoch: 6| Step: 10
Training loss: 2.552084807311171
Validation loss: 2.5072552546123643

Epoch: 6| Step: 11
Training loss: 2.0111103211829295
Validation loss: 2.5063145522178205

Epoch: 6| Step: 12
Training loss: 2.427711001810757
Validation loss: 2.519714963853891

Epoch: 6| Step: 13
Training loss: 2.1499869013542554
Validation loss: 2.5323161952657443

Epoch: 245| Step: 0
Training loss: 2.0800744571563907
Validation loss: 2.524117959695384

Epoch: 6| Step: 1
Training loss: 2.7859067186675843
Validation loss: 2.535535661532232

Epoch: 6| Step: 2
Training loss: 2.5934495866831484
Validation loss: 2.5333515281609444

Epoch: 6| Step: 3
Training loss: 2.6913693983326126
Validation loss: 2.5291599860147627

Epoch: 6| Step: 4
Training loss: 2.5517502444097016
Validation loss: 2.519978060273632

Epoch: 6| Step: 5
Training loss: 2.375602344624701
Validation loss: 2.5124388552891332

Epoch: 6| Step: 6
Training loss: 2.4038015021065156
Validation loss: 2.500126104353311

Epoch: 6| Step: 7
Training loss: 2.7252291066861596
Validation loss: 2.5079051601764726

Epoch: 6| Step: 8
Training loss: 2.280407893854412
Validation loss: 2.5106445040272454

Epoch: 6| Step: 9
Training loss: 1.8456269102154492
Validation loss: 2.482631223321446

Epoch: 6| Step: 10
Training loss: 1.8673947271169034
Validation loss: 2.5065563062290037

Epoch: 6| Step: 11
Training loss: 1.940279658699019
Validation loss: 2.517267689926279

Epoch: 6| Step: 12
Training loss: 2.33622693976568
Validation loss: 2.511231331130049

Epoch: 6| Step: 13
Training loss: 2.1730806585686184
Validation loss: 2.499323085695051

Epoch: 246| Step: 0
Training loss: 2.46776802717551
Validation loss: 2.5026603530996545

Epoch: 6| Step: 1
Training loss: 1.9237889629580016
Validation loss: 2.520140802345263

Epoch: 6| Step: 2
Training loss: 2.4245423425842425
Validation loss: 2.509378960061185

Epoch: 6| Step: 3
Training loss: 2.147566962302797
Validation loss: 2.5230701600393273

Epoch: 6| Step: 4
Training loss: 2.3628024033864388
Validation loss: 2.5417585877436375

Epoch: 6| Step: 5
Training loss: 2.389163798647719
Validation loss: 2.5482530668635603

Epoch: 6| Step: 6
Training loss: 2.4312962544804737
Validation loss: 2.545493548912896

Epoch: 6| Step: 7
Training loss: 2.609058200998496
Validation loss: 2.545292071812167

Epoch: 6| Step: 8
Training loss: 2.478793610358948
Validation loss: 2.5517595721556394

Epoch: 6| Step: 9
Training loss: 1.7184539539959733
Validation loss: 2.5212304194000055

Epoch: 6| Step: 10
Training loss: 2.435215490781411
Validation loss: 2.5242119418601123

Epoch: 6| Step: 11
Training loss: 2.765934037868069
Validation loss: 2.517914940139437

Epoch: 6| Step: 12
Training loss: 2.328919345597511
Validation loss: 2.52400355490743

Epoch: 6| Step: 13
Training loss: 2.361999466769217
Validation loss: 2.517077482768509

Epoch: 247| Step: 0
Training loss: 2.2645900072305336
Validation loss: 2.511230104809707

Epoch: 6| Step: 1
Training loss: 2.3721205673453762
Validation loss: 2.5032600763254576

Epoch: 6| Step: 2
Training loss: 1.4149158073962045
Validation loss: 2.495633874436836

Epoch: 6| Step: 3
Training loss: 2.274568676146338
Validation loss: 2.506815822210029

Epoch: 6| Step: 4
Training loss: 2.895580930253033
Validation loss: 2.5093718421444278

Epoch: 6| Step: 5
Training loss: 2.4707639181626466
Validation loss: 2.4978987287227787

Epoch: 6| Step: 6
Training loss: 1.8517826770295638
Validation loss: 2.5072331536732797

Epoch: 6| Step: 7
Training loss: 2.0836557774560034
Validation loss: 2.499606212755649

Epoch: 6| Step: 8
Training loss: 1.6931463369360693
Validation loss: 2.5026932911214543

Epoch: 6| Step: 9
Training loss: 2.8376523552546438
Validation loss: 2.5129131445598847

Epoch: 6| Step: 10
Training loss: 2.253846271847386
Validation loss: 2.52656869535644

Epoch: 6| Step: 11
Training loss: 2.5787964842282283
Validation loss: 2.5244752385826605

Epoch: 6| Step: 12
Training loss: 3.0367736827140104
Validation loss: 2.5531970390201453

Epoch: 6| Step: 13
Training loss: 2.4218598396072877
Validation loss: 2.5466449844309462

Epoch: 248| Step: 0
Training loss: 1.9194881845812624
Validation loss: 2.54347416962354

Epoch: 6| Step: 1
Training loss: 2.4704643767428363
Validation loss: 2.536064208714551

Epoch: 6| Step: 2
Training loss: 2.9439264977546786
Validation loss: 2.551198912499516

Epoch: 6| Step: 3
Training loss: 2.367233527714904
Validation loss: 2.545198118646208

Epoch: 6| Step: 4
Training loss: 2.780708774668837
Validation loss: 2.549440585589052

Epoch: 6| Step: 5
Training loss: 1.684783444397707
Validation loss: 2.5167879216454625

Epoch: 6| Step: 6
Training loss: 2.209300483191573
Validation loss: 2.5153677356664805

Epoch: 6| Step: 7
Training loss: 2.170645605989554
Validation loss: 2.506734416249865

Epoch: 6| Step: 8
Training loss: 2.553620935316481
Validation loss: 2.4976712506921355

Epoch: 6| Step: 9
Training loss: 2.5193020501975134
Validation loss: 2.5046049939339405

Epoch: 6| Step: 10
Training loss: 2.0019208505401487
Validation loss: 2.496271277349568

Epoch: 6| Step: 11
Training loss: 1.6010114512656493
Validation loss: 2.499134994904832

Epoch: 6| Step: 12
Training loss: 2.6839204947440103
Validation loss: 2.517411460519106

Epoch: 6| Step: 13
Training loss: 2.8434900856710525
Validation loss: 2.5083267144235197

Epoch: 249| Step: 0
Training loss: 2.910477875211761
Validation loss: 2.5231030284827987

Epoch: 6| Step: 1
Training loss: 2.4113970117757213
Validation loss: 2.532688713147306

Epoch: 6| Step: 2
Training loss: 2.134913042428302
Validation loss: 2.5537274002118338

Epoch: 6| Step: 3
Training loss: 1.7515833367666032
Validation loss: 2.5507456536995505

Epoch: 6| Step: 4
Training loss: 2.733140503276521
Validation loss: 2.5569055166003154

Epoch: 6| Step: 5
Training loss: 1.5490590100213486
Validation loss: 2.566279438665656

Epoch: 6| Step: 6
Training loss: 2.889464769266452
Validation loss: 2.5724491873598714

Epoch: 6| Step: 7
Training loss: 2.333311614435023
Validation loss: 2.545111624962146

Epoch: 6| Step: 8
Training loss: 2.36850241220169
Validation loss: 2.5361394087693787

Epoch: 6| Step: 9
Training loss: 2.0944081880358403
Validation loss: 2.525130358563384

Epoch: 6| Step: 10
Training loss: 1.8997554521287907
Validation loss: 2.5129700861469937

Epoch: 6| Step: 11
Training loss: 2.2883578833670586
Validation loss: 2.505945542663488

Epoch: 6| Step: 12
Training loss: 2.125005273251442
Validation loss: 2.502936895178772

Epoch: 6| Step: 13
Training loss: 2.7181751915145456
Validation loss: 2.5075642273709486

Epoch: 250| Step: 0
Training loss: 2.4755252627549744
Validation loss: 2.499493770208275

Epoch: 6| Step: 1
Training loss: 2.7276165954955447
Validation loss: 2.4936556582344496

Epoch: 6| Step: 2
Training loss: 2.6355815328261647
Validation loss: 2.507533738279188

Epoch: 6| Step: 3
Training loss: 2.977785995418287
Validation loss: 2.4998784512535543

Epoch: 6| Step: 4
Training loss: 2.163227236849395
Validation loss: 2.5034094450038964

Epoch: 6| Step: 5
Training loss: 2.425129236140046
Validation loss: 2.507589058909297

Epoch: 6| Step: 6
Training loss: 1.8871441789946077
Validation loss: 2.5073099553817766

Epoch: 6| Step: 7
Training loss: 2.744058953967039
Validation loss: 2.509115813327099

Epoch: 6| Step: 8
Training loss: 2.109278697888501
Validation loss: 2.5047706702835466

Epoch: 6| Step: 9
Training loss: 2.434816399296857
Validation loss: 2.516442112872892

Epoch: 6| Step: 10
Training loss: 1.9063604354136952
Validation loss: 2.4966330823647005

Epoch: 6| Step: 11
Training loss: 2.4690130552346106
Validation loss: 2.501879081255795

Epoch: 6| Step: 12
Training loss: 1.724320764466444
Validation loss: 2.5187745527738303

Epoch: 6| Step: 13
Training loss: 2.2024342421242338
Validation loss: 2.5448616666739494

Epoch: 251| Step: 0
Training loss: 2.42884002330231
Validation loss: 2.5447425886479036

Epoch: 6| Step: 1
Training loss: 2.2878065602152886
Validation loss: 2.5357370519479545

Epoch: 6| Step: 2
Training loss: 2.556802043671203
Validation loss: 2.556903045607407

Epoch: 6| Step: 3
Training loss: 2.7424454526944815
Validation loss: 2.5866763316626082

Epoch: 6| Step: 4
Training loss: 2.2051398620883096
Validation loss: 2.5889972206592926

Epoch: 6| Step: 5
Training loss: 2.9244538212960496
Validation loss: 2.566877533767672

Epoch: 6| Step: 6
Training loss: 1.7704019656894836
Validation loss: 2.559804972332576

Epoch: 6| Step: 7
Training loss: 1.9203749594529187
Validation loss: 2.5476777229546657

Epoch: 6| Step: 8
Training loss: 1.7933728130537558
Validation loss: 2.5263985974856547

Epoch: 6| Step: 9
Training loss: 2.3453328192108325
Validation loss: 2.5229215064869916

Epoch: 6| Step: 10
Training loss: 2.8133365658504963
Validation loss: 2.5083346353149416

Epoch: 6| Step: 11
Training loss: 1.2668545249033396
Validation loss: 2.5068395832799584

Epoch: 6| Step: 12
Training loss: 2.3249153696059732
Validation loss: 2.505940278180145

Epoch: 6| Step: 13
Training loss: 2.824297258860811
Validation loss: 2.517988023122957

Epoch: 252| Step: 0
Training loss: 2.327662684474035
Validation loss: 2.5076624032139447

Epoch: 6| Step: 1
Training loss: 2.7380566906239463
Validation loss: 2.50755625650593

Epoch: 6| Step: 2
Training loss: 2.577536775935278
Validation loss: 2.503501768168572

Epoch: 6| Step: 3
Training loss: 1.9422275333467711
Validation loss: 2.512527438467837

Epoch: 6| Step: 4
Training loss: 2.1934087243307423
Validation loss: 2.5130517249440496

Epoch: 6| Step: 5
Training loss: 2.237992033322961
Validation loss: 2.504804889341895

Epoch: 6| Step: 6
Training loss: 1.6983344221376793
Validation loss: 2.502595587221829

Epoch: 6| Step: 7
Training loss: 1.7911673744668566
Validation loss: 2.5073487990975036

Epoch: 6| Step: 8
Training loss: 2.2448890706206597
Validation loss: 2.4914746595376696

Epoch: 6| Step: 9
Training loss: 2.78345290819929
Validation loss: 2.509002371580002

Epoch: 6| Step: 10
Training loss: 2.184013421908207
Validation loss: 2.5018878325718434

Epoch: 6| Step: 11
Training loss: 2.649607532156959
Validation loss: 2.5019996275440306

Epoch: 6| Step: 12
Training loss: 2.375038849362306
Validation loss: 2.4963357218116595

Epoch: 6| Step: 13
Training loss: 2.8059297748514136
Validation loss: 2.501917048404374

Epoch: 253| Step: 0
Training loss: 2.7130871256003988
Validation loss: 2.523660183461342

Epoch: 6| Step: 1
Training loss: 2.7613569181783677
Validation loss: 2.565291179417047

Epoch: 6| Step: 2
Training loss: 2.3720071909057308
Validation loss: 2.623961697452979

Epoch: 6| Step: 3
Training loss: 2.486373193756394
Validation loss: 2.6127902920682575

Epoch: 6| Step: 4
Training loss: 1.8773043142201793
Validation loss: 2.5734015148235563

Epoch: 6| Step: 5
Training loss: 2.7725782325927555
Validation loss: 2.545724558236393

Epoch: 6| Step: 6
Training loss: 2.2225005995381664
Validation loss: 2.5295165998737716

Epoch: 6| Step: 7
Training loss: 2.625781624092273
Validation loss: 2.518750336349629

Epoch: 6| Step: 8
Training loss: 2.634262545935615
Validation loss: 2.5057389033896262

Epoch: 6| Step: 9
Training loss: 2.0357184923936407
Validation loss: 2.494509580800614

Epoch: 6| Step: 10
Training loss: 2.3622559396130347
Validation loss: 2.5042708156802496

Epoch: 6| Step: 11
Training loss: 2.369481350769207
Validation loss: 2.4911918125991117

Epoch: 6| Step: 12
Training loss: 1.908314134537296
Validation loss: 2.502741010393238

Epoch: 6| Step: 13
Training loss: 1.5443598789662007
Validation loss: 2.486769795550529

Epoch: 254| Step: 0
Training loss: 3.0360366938588736
Validation loss: 2.505826993967437

Epoch: 6| Step: 1
Training loss: 2.34635302634993
Validation loss: 2.4978099926422477

Epoch: 6| Step: 2
Training loss: 2.470753014102291
Validation loss: 2.498343761499521

Epoch: 6| Step: 3
Training loss: 2.078698215447481
Validation loss: 2.489894621366974

Epoch: 6| Step: 4
Training loss: 1.8764576014692402
Validation loss: 2.5095272995023246

Epoch: 6| Step: 5
Training loss: 1.9472139556365857
Validation loss: 2.4993968871915806

Epoch: 6| Step: 6
Training loss: 2.7783833850211126
Validation loss: 2.5277443774139448

Epoch: 6| Step: 7
Training loss: 1.8247669384691911
Validation loss: 2.532661374176526

Epoch: 6| Step: 8
Training loss: 2.2145225117017855
Validation loss: 2.5295068680674464

Epoch: 6| Step: 9
Training loss: 2.256926365967425
Validation loss: 2.527464386676209

Epoch: 6| Step: 10
Training loss: 2.2275390625
Validation loss: 2.5328047730102274

Epoch: 6| Step: 11
Training loss: 2.165593235944395
Validation loss: 2.53037224766462

Epoch: 6| Step: 12
Training loss: 1.9093791730619738
Validation loss: 2.509852624317949

Epoch: 6| Step: 13
Training loss: 2.8953034352934193
Validation loss: 2.5005467770599967

Epoch: 255| Step: 0
Training loss: 2.3589279054343963
Validation loss: 2.4970456468867988

Epoch: 6| Step: 1
Training loss: 2.068503226229978
Validation loss: 2.5026331068595815

Epoch: 6| Step: 2
Training loss: 2.549485536177059
Validation loss: 2.499743273586905

Epoch: 6| Step: 3
Training loss: 2.851796932251287
Validation loss: 2.4982255519328675

Epoch: 6| Step: 4
Training loss: 2.0054592487509884
Validation loss: 2.4995382359345015

Epoch: 6| Step: 5
Training loss: 2.6116795214263826
Validation loss: 2.511115286925828

Epoch: 6| Step: 6
Training loss: 2.1203949340897963
Validation loss: 2.5152319054083683

Epoch: 6| Step: 7
Training loss: 2.554690206450449
Validation loss: 2.512617837220734

Epoch: 6| Step: 8
Training loss: 2.437619328634602
Validation loss: 2.5200408183682392

Epoch: 6| Step: 9
Training loss: 2.3060313299454416
Validation loss: 2.5110185516322328

Epoch: 6| Step: 10
Training loss: 2.3229608802408084
Validation loss: 2.515028414859615

Epoch: 6| Step: 11
Training loss: 2.0430426210428663
Validation loss: 2.5164247588130615

Epoch: 6| Step: 12
Training loss: 2.0868869863636026
Validation loss: 2.515342506990842

Epoch: 6| Step: 13
Training loss: 1.9658024839681483
Validation loss: 2.528178262483507

Epoch: 256| Step: 0
Training loss: 1.8556093182773243
Validation loss: 2.5159100594139776

Epoch: 6| Step: 1
Training loss: 2.0464881356662215
Validation loss: 2.502425860597039

Epoch: 6| Step: 2
Training loss: 2.6685337345306093
Validation loss: 2.5134680368194533

Epoch: 6| Step: 3
Training loss: 2.5374062168473643
Validation loss: 2.5172869797822695

Epoch: 6| Step: 4
Training loss: 2.71410279625652
Validation loss: 2.5367410386052756

Epoch: 6| Step: 5
Training loss: 2.4359005301889596
Validation loss: 2.5389243611636214

Epoch: 6| Step: 6
Training loss: 2.2649915138405654
Validation loss: 2.567053385702643

Epoch: 6| Step: 7
Training loss: 2.279238088024561
Validation loss: 2.5533003467872577

Epoch: 6| Step: 8
Training loss: 2.1672386245913047
Validation loss: 2.557701028870025

Epoch: 6| Step: 9
Training loss: 2.2264134407342295
Validation loss: 2.547386664108427

Epoch: 6| Step: 10
Training loss: 2.716899812285381
Validation loss: 2.5432362764878778

Epoch: 6| Step: 11
Training loss: 2.062728060048909
Validation loss: 2.551715440248685

Epoch: 6| Step: 12
Training loss: 1.7382210367467974
Validation loss: 2.535285135293342

Epoch: 6| Step: 13
Training loss: 2.4003752295898173
Validation loss: 2.516190877890384

Epoch: 257| Step: 0
Training loss: 1.5973096252336727
Validation loss: 2.513808990904253

Epoch: 6| Step: 1
Training loss: 2.1388671785824354
Validation loss: 2.5089155169976287

Epoch: 6| Step: 2
Training loss: 1.9606668353884322
Validation loss: 2.514738357072027

Epoch: 6| Step: 3
Training loss: 2.3384663343863012
Validation loss: 2.520068743641053

Epoch: 6| Step: 4
Training loss: 2.2078413025312953
Validation loss: 2.5184911823685083

Epoch: 6| Step: 5
Training loss: 2.340969216230297
Validation loss: 2.5071567299929582

Epoch: 6| Step: 6
Training loss: 2.9427464485513233
Validation loss: 2.512778146255372

Epoch: 6| Step: 7
Training loss: 2.5432948124652777
Validation loss: 2.5166285469839744

Epoch: 6| Step: 8
Training loss: 2.2151317913725617
Validation loss: 2.5118340307094735

Epoch: 6| Step: 9
Training loss: 2.6412296844293275
Validation loss: 2.519852712858174

Epoch: 6| Step: 10
Training loss: 2.6226411848002016
Validation loss: 2.5292157448579338

Epoch: 6| Step: 11
Training loss: 2.2466547787782893
Validation loss: 2.534508573913822

Epoch: 6| Step: 12
Training loss: 2.6251010875311223
Validation loss: 2.5304026578677377

Epoch: 6| Step: 13
Training loss: 2.0364290383289605
Validation loss: 2.5428765705549274

Epoch: 258| Step: 0
Training loss: 1.6883800472388273
Validation loss: 2.536549644210488

Epoch: 6| Step: 1
Training loss: 2.2303048790161037
Validation loss: 2.53014652704914

Epoch: 6| Step: 2
Training loss: 1.8779416215331932
Validation loss: 2.538218227773121

Epoch: 6| Step: 3
Training loss: 2.3260587189102426
Validation loss: 2.5330088434789118

Epoch: 6| Step: 4
Training loss: 2.9305867760448097
Validation loss: 2.519264841903955

Epoch: 6| Step: 5
Training loss: 2.2932010253547306
Validation loss: 2.5033849212149697

Epoch: 6| Step: 6
Training loss: 2.5083624216042737
Validation loss: 2.4868294928817014

Epoch: 6| Step: 7
Training loss: 2.0827150063043556
Validation loss: 2.4765732581449473

Epoch: 6| Step: 8
Training loss: 2.7704711524385415
Validation loss: 2.4728499864449143

Epoch: 6| Step: 9
Training loss: 2.7547102383580118
Validation loss: 2.474529005118972

Epoch: 6| Step: 10
Training loss: 2.247041452579773
Validation loss: 2.471948796652448

Epoch: 6| Step: 11
Training loss: 2.2283611327638737
Validation loss: 2.484028742110498

Epoch: 6| Step: 12
Training loss: 2.0628363595133696
Validation loss: 2.5072004734049003

Epoch: 6| Step: 13
Training loss: 2.6892505533448854
Validation loss: 2.511287052912238

Epoch: 259| Step: 0
Training loss: 3.211299680902417
Validation loss: 2.5349730125159446

Epoch: 6| Step: 1
Training loss: 2.5370535547049293
Validation loss: 2.540623737505372

Epoch: 6| Step: 2
Training loss: 1.9019703586727568
Validation loss: 2.530539518887787

Epoch: 6| Step: 3
Training loss: 2.185247078550049
Validation loss: 2.5241071129523114

Epoch: 6| Step: 4
Training loss: 1.877201377496025
Validation loss: 2.5382346031072403

Epoch: 6| Step: 5
Training loss: 2.0027773170041514
Validation loss: 2.5340238843001486

Epoch: 6| Step: 6
Training loss: 2.3179088948656847
Validation loss: 2.5466201592321362

Epoch: 6| Step: 7
Training loss: 2.2704387170266096
Validation loss: 2.5358220946729086

Epoch: 6| Step: 8
Training loss: 1.7203108895802735
Validation loss: 2.519121681852371

Epoch: 6| Step: 9
Training loss: 2.1852660625143683
Validation loss: 2.527060853041005

Epoch: 6| Step: 10
Training loss: 2.27265901116249
Validation loss: 2.5158066614874075

Epoch: 6| Step: 11
Training loss: 3.1597854906019576
Validation loss: 2.5178886638344404

Epoch: 6| Step: 12
Training loss: 2.569335844706146
Validation loss: 2.5084994475488456

Epoch: 6| Step: 13
Training loss: 1.8073713154973219
Validation loss: 2.4966215114007295

Epoch: 260| Step: 0
Training loss: 1.649677406911727
Validation loss: 2.5015047710428355

Epoch: 6| Step: 1
Training loss: 1.6824580563989546
Validation loss: 2.494519823484039

Epoch: 6| Step: 2
Training loss: 2.044534990936227
Validation loss: 2.505261717377563

Epoch: 6| Step: 3
Training loss: 2.668961213305634
Validation loss: 2.4988706263015286

Epoch: 6| Step: 4
Training loss: 2.665409854913805
Validation loss: 2.5000441865195038

Epoch: 6| Step: 5
Training loss: 2.7022685199024923
Validation loss: 2.502457983938992

Epoch: 6| Step: 6
Training loss: 2.2074568346583545
Validation loss: 2.5190832562844143

Epoch: 6| Step: 7
Training loss: 1.9320537561200195
Validation loss: 2.5157517268956364

Epoch: 6| Step: 8
Training loss: 1.3913007230329202
Validation loss: 2.5092288223705173

Epoch: 6| Step: 9
Training loss: 2.621460844845784
Validation loss: 2.509480493085004

Epoch: 6| Step: 10
Training loss: 2.993117384678856
Validation loss: 2.516452439981815

Epoch: 6| Step: 11
Training loss: 2.6120878268631365
Validation loss: 2.528729207909903

Epoch: 6| Step: 12
Training loss: 2.4942341117096674
Validation loss: 2.5252040509908147

Epoch: 6| Step: 13
Training loss: 2.0085440761220794
Validation loss: 2.5460657031393263

Epoch: 261| Step: 0
Training loss: 2.560175981582349
Validation loss: 2.549346832072394

Epoch: 6| Step: 1
Training loss: 1.7103540828033275
Validation loss: 2.5488363019829126

Epoch: 6| Step: 2
Training loss: 2.217558419921369
Validation loss: 2.528563914885658

Epoch: 6| Step: 3
Training loss: 2.162739814294243
Validation loss: 2.521497990861766

Epoch: 6| Step: 4
Training loss: 1.7655753069610995
Validation loss: 2.5241236113180787

Epoch: 6| Step: 5
Training loss: 3.003034011145183
Validation loss: 2.5329072809419366

Epoch: 6| Step: 6
Training loss: 2.1718490928367156
Validation loss: 2.5185714115663873

Epoch: 6| Step: 7
Training loss: 2.5097239212549236
Validation loss: 2.511355376272506

Epoch: 6| Step: 8
Training loss: 2.716204712407253
Validation loss: 2.5100008882721117

Epoch: 6| Step: 9
Training loss: 2.4260420850985733
Validation loss: 2.5058196835980757

Epoch: 6| Step: 10
Training loss: 2.35244298527348
Validation loss: 2.514682119199491

Epoch: 6| Step: 11
Training loss: 2.1869647869943454
Validation loss: 2.5208068772706316

Epoch: 6| Step: 12
Training loss: 2.2283341704171815
Validation loss: 2.5036986329904924

Epoch: 6| Step: 13
Training loss: 2.3718959199286895
Validation loss: 2.5067240570309566

Epoch: 262| Step: 0
Training loss: 2.48130455053213
Validation loss: 2.5095344882319774

Epoch: 6| Step: 1
Training loss: 3.130430766923144
Validation loss: 2.518344380775051

Epoch: 6| Step: 2
Training loss: 2.7775142311535066
Validation loss: 2.4965790548940388

Epoch: 6| Step: 3
Training loss: 1.9263000408507476
Validation loss: 2.5007920123250744

Epoch: 6| Step: 4
Training loss: 2.030115015877586
Validation loss: 2.500644020733474

Epoch: 6| Step: 5
Training loss: 1.8574132106831631
Validation loss: 2.4913135618582705

Epoch: 6| Step: 6
Training loss: 1.879999108618667
Validation loss: 2.511288777633178

Epoch: 6| Step: 7
Training loss: 2.450134982069128
Validation loss: 2.5099708562276053

Epoch: 6| Step: 8
Training loss: 2.2660461034436454
Validation loss: 2.5190337564746423

Epoch: 6| Step: 9
Training loss: 1.976439822766268
Validation loss: 2.5338618770742114

Epoch: 6| Step: 10
Training loss: 2.5903397167210445
Validation loss: 2.5688854766538514

Epoch: 6| Step: 11
Training loss: 2.3655062203463584
Validation loss: 2.591392019771575

Epoch: 6| Step: 12
Training loss: 2.10053531544942
Validation loss: 2.589858694210827

Epoch: 6| Step: 13
Training loss: 2.1248095931971243
Validation loss: 2.582253358553459

Epoch: 263| Step: 0
Training loss: 2.2279305521690045
Validation loss: 2.547781223326768

Epoch: 6| Step: 1
Training loss: 2.6174372767354033
Validation loss: 2.5203435963310428

Epoch: 6| Step: 2
Training loss: 2.7008717577762047
Validation loss: 2.5128069271042768

Epoch: 6| Step: 3
Training loss: 2.0806245614415464
Validation loss: 2.49678785277845

Epoch: 6| Step: 4
Training loss: 2.0396881897429697
Validation loss: 2.5107040451834237

Epoch: 6| Step: 5
Training loss: 2.512849212215106
Validation loss: 2.508063647409165

Epoch: 6| Step: 6
Training loss: 2.461515812815494
Validation loss: 2.5061767646699598

Epoch: 6| Step: 7
Training loss: 2.70153885539239
Validation loss: 2.5169419500178636

Epoch: 6| Step: 8
Training loss: 2.8325058532815977
Validation loss: 2.5012570558645764

Epoch: 6| Step: 9
Training loss: 2.2468964046472086
Validation loss: 2.515061941376306

Epoch: 6| Step: 10
Training loss: 2.1432123071525773
Validation loss: 2.49461683219496

Epoch: 6| Step: 11
Training loss: 2.411460288742514
Validation loss: 2.5074983837798195

Epoch: 6| Step: 12
Training loss: 1.7123343283157968
Validation loss: 2.517550298370792

Epoch: 6| Step: 13
Training loss: 1.8406691592866369
Validation loss: 2.5381732498538794

Epoch: 264| Step: 0
Training loss: 2.3858207349303577
Validation loss: 2.5660104818994753

Epoch: 6| Step: 1
Training loss: 2.4147043701941175
Validation loss: 2.615667632502593

Epoch: 6| Step: 2
Training loss: 2.3258051226809533
Validation loss: 2.6267886501475033

Epoch: 6| Step: 3
Training loss: 2.573501417504649
Validation loss: 2.6168897468899073

Epoch: 6| Step: 4
Training loss: 2.5761748365221795
Validation loss: 2.648233501488447

Epoch: 6| Step: 5
Training loss: 1.8263630649624965
Validation loss: 2.606183489248903

Epoch: 6| Step: 6
Training loss: 2.3861740664534596
Validation loss: 2.5867833562548417

Epoch: 6| Step: 7
Training loss: 1.5269966218832305
Validation loss: 2.561448680171227

Epoch: 6| Step: 8
Training loss: 2.5048889992918237
Validation loss: 2.54942917636779

Epoch: 6| Step: 9
Training loss: 2.694718182041944
Validation loss: 2.5411667149686514

Epoch: 6| Step: 10
Training loss: 1.9799007526724008
Validation loss: 2.529397639914864

Epoch: 6| Step: 11
Training loss: 2.4520398309219975
Validation loss: 2.5185096897435906

Epoch: 6| Step: 12
Training loss: 2.0369396632776082
Validation loss: 2.5168086677135655

Epoch: 6| Step: 13
Training loss: 2.336734291364232
Validation loss: 2.5186539731837554

Epoch: 265| Step: 0
Training loss: 1.8153135232763284
Validation loss: 2.508285279832847

Epoch: 6| Step: 1
Training loss: 2.2157972863363975
Validation loss: 2.5054594034389948

Epoch: 6| Step: 2
Training loss: 2.573191042542014
Validation loss: 2.507466158614749

Epoch: 6| Step: 3
Training loss: 2.4974301481359023
Validation loss: 2.511882501764826

Epoch: 6| Step: 4
Training loss: 2.562344616156422
Validation loss: 2.501531640393991

Epoch: 6| Step: 5
Training loss: 1.8325908920416456
Validation loss: 2.5103090244710633

Epoch: 6| Step: 6
Training loss: 2.442379981599469
Validation loss: 2.4959662478999434

Epoch: 6| Step: 7
Training loss: 2.0995521431153255
Validation loss: 2.5039588577528527

Epoch: 6| Step: 8
Training loss: 2.231193785400052
Validation loss: 2.5535217642996018

Epoch: 6| Step: 9
Training loss: 1.922224431719579
Validation loss: 2.5878206524296146

Epoch: 6| Step: 10
Training loss: 2.4011444820034904
Validation loss: 2.5794235966347716

Epoch: 6| Step: 11
Training loss: 3.0838807797079557
Validation loss: 2.5736592697324148

Epoch: 6| Step: 12
Training loss: 2.1338416889605805
Validation loss: 2.5754009459350597

Epoch: 6| Step: 13
Training loss: 2.661373627292006
Validation loss: 2.5786622075348373

Epoch: 266| Step: 0
Training loss: 2.3685691502764095
Validation loss: 2.5676642227768696

Epoch: 6| Step: 1
Training loss: 2.212886099882289
Validation loss: 2.5365310648073573

Epoch: 6| Step: 2
Training loss: 2.29172108903478
Validation loss: 2.5251213258607943

Epoch: 6| Step: 3
Training loss: 2.5436579507205113
Validation loss: 2.520142000678288

Epoch: 6| Step: 4
Training loss: 2.3021528368738187
Validation loss: 2.5221373177781996

Epoch: 6| Step: 5
Training loss: 2.6412937739473374
Validation loss: 2.519770805542721

Epoch: 6| Step: 6
Training loss: 1.1189040221847475
Validation loss: 2.5223298451652556

Epoch: 6| Step: 7
Training loss: 1.8214865896991548
Validation loss: 2.5357287935472597

Epoch: 6| Step: 8
Training loss: 2.958090185641188
Validation loss: 2.525106108673781

Epoch: 6| Step: 9
Training loss: 2.158782798283796
Validation loss: 2.556049866369487

Epoch: 6| Step: 10
Training loss: 2.658088855403486
Validation loss: 2.5303542981710416

Epoch: 6| Step: 11
Training loss: 2.1176569231744784
Validation loss: 2.5310748161321905

Epoch: 6| Step: 12
Training loss: 2.794048564753689
Validation loss: 2.542536466843991

Epoch: 6| Step: 13
Training loss: 1.725660545925294
Validation loss: 2.5555538687723462

Epoch: 267| Step: 0
Training loss: 1.3317522668520234
Validation loss: 2.559992998257638

Epoch: 6| Step: 1
Training loss: 1.7105738980706149
Validation loss: 2.558059698769274

Epoch: 6| Step: 2
Training loss: 2.456917133925871
Validation loss: 2.5563849779601795

Epoch: 6| Step: 3
Training loss: 2.268934161485629
Validation loss: 2.5508337166391373

Epoch: 6| Step: 4
Training loss: 2.5014840489606542
Validation loss: 2.5524452783221707

Epoch: 6| Step: 5
Training loss: 2.4816041285327386
Validation loss: 2.537051988461204

Epoch: 6| Step: 6
Training loss: 1.4672992115331391
Validation loss: 2.5460460304485264

Epoch: 6| Step: 7
Training loss: 2.4267356088647216
Validation loss: 2.5403165879531286

Epoch: 6| Step: 8
Training loss: 2.114256684829376
Validation loss: 2.5145419772923634

Epoch: 6| Step: 9
Training loss: 2.6034917236513064
Validation loss: 2.5372890284487726

Epoch: 6| Step: 10
Training loss: 1.8859782848989088
Validation loss: 2.5621823990171606

Epoch: 6| Step: 11
Training loss: 2.9156954283554066
Validation loss: 2.5465606152171

Epoch: 6| Step: 12
Training loss: 2.2342285961924184
Validation loss: 2.5727632196257457

Epoch: 6| Step: 13
Training loss: 2.7667461644283353
Validation loss: 2.5689301643397706

Epoch: 268| Step: 0
Training loss: 1.9467788133694603
Validation loss: 2.568610279896313

Epoch: 6| Step: 1
Training loss: 1.7274595666064818
Validation loss: 2.5613135715909108

Epoch: 6| Step: 2
Training loss: 2.150126511156274
Validation loss: 2.5488481114019232

Epoch: 6| Step: 3
Training loss: 2.288284846674527
Validation loss: 2.5234420036220615

Epoch: 6| Step: 4
Training loss: 2.6103142058856603
Validation loss: 2.5183707154396697

Epoch: 6| Step: 5
Training loss: 2.9205671841274174
Validation loss: 2.5192926811410246

Epoch: 6| Step: 6
Training loss: 1.8192983266123781
Validation loss: 2.5101546840700437

Epoch: 6| Step: 7
Training loss: 1.811284545611119
Validation loss: 2.509787331572596

Epoch: 6| Step: 8
Training loss: 1.5118294608806315
Validation loss: 2.5064290034295786

Epoch: 6| Step: 9
Training loss: 3.1212833428120113
Validation loss: 2.5062664332687423

Epoch: 6| Step: 10
Training loss: 2.2854886326779438
Validation loss: 2.5024524104178782

Epoch: 6| Step: 11
Training loss: 3.196004703971829
Validation loss: 2.5059564997304036

Epoch: 6| Step: 12
Training loss: 2.481487779730569
Validation loss: 2.5022799268275686

Epoch: 6| Step: 13
Training loss: 1.5536090426597298
Validation loss: 2.5098675540160267

Epoch: 269| Step: 0
Training loss: 2.2629110984988943
Validation loss: 2.543562265602713

Epoch: 6| Step: 1
Training loss: 2.078759576955493
Validation loss: 2.539755170191362

Epoch: 6| Step: 2
Training loss: 1.8659772581900014
Validation loss: 2.5557489707795695

Epoch: 6| Step: 3
Training loss: 1.8539496376950204
Validation loss: 2.544081780793598

Epoch: 6| Step: 4
Training loss: 2.7250577168083105
Validation loss: 2.526292192024036

Epoch: 6| Step: 5
Training loss: 2.981811540928231
Validation loss: 2.546013801554779

Epoch: 6| Step: 6
Training loss: 2.2899834664759915
Validation loss: 2.5374629533189936

Epoch: 6| Step: 7
Training loss: 2.2717345896152343
Validation loss: 2.543847841822736

Epoch: 6| Step: 8
Training loss: 1.4932593844757684
Validation loss: 2.5660380307850823

Epoch: 6| Step: 9
Training loss: 1.491387517300874
Validation loss: 2.5783459038932475

Epoch: 6| Step: 10
Training loss: 3.124263829304058
Validation loss: 2.5972325182578624

Epoch: 6| Step: 11
Training loss: 2.7491497112428527
Validation loss: 2.6007607478025707

Epoch: 6| Step: 12
Training loss: 2.1979859930256858
Validation loss: 2.5800869345003212

Epoch: 6| Step: 13
Training loss: 2.3800591241881675
Validation loss: 2.5414805005376366

Epoch: 270| Step: 0
Training loss: 2.442681502877424
Validation loss: 2.52426374862265

Epoch: 6| Step: 1
Training loss: 2.975460138719619
Validation loss: 2.528530060579442

Epoch: 6| Step: 2
Training loss: 2.4574764072841875
Validation loss: 2.5111408349920503

Epoch: 6| Step: 3
Training loss: 2.3340936738921636
Validation loss: 2.498854676789812

Epoch: 6| Step: 4
Training loss: 2.156840146893248
Validation loss: 2.493336810153774

Epoch: 6| Step: 5
Training loss: 2.82895323707224
Validation loss: 2.496560512275651

Epoch: 6| Step: 6
Training loss: 1.8807322299720695
Validation loss: 2.4968693681827667

Epoch: 6| Step: 7
Training loss: 2.0480706602960335
Validation loss: 2.526529691031373

Epoch: 6| Step: 8
Training loss: 2.1340015715831915
Validation loss: 2.513964908871869

Epoch: 6| Step: 9
Training loss: 2.041398037216186
Validation loss: 2.5119847166245415

Epoch: 6| Step: 10
Training loss: 1.9393994034840092
Validation loss: 2.516254291053849

Epoch: 6| Step: 11
Training loss: 1.8438436193458867
Validation loss: 2.5339849947289657

Epoch: 6| Step: 12
Training loss: 1.8735502360246332
Validation loss: 2.5670946224760876

Epoch: 6| Step: 13
Training loss: 2.6466884182469363
Validation loss: 2.571955904300337

Epoch: 271| Step: 0
Training loss: 2.4664244502800425
Validation loss: 2.584241512592051

Epoch: 6| Step: 1
Training loss: 1.7338707680641283
Validation loss: 2.555245061569734

Epoch: 6| Step: 2
Training loss: 2.2540872325992063
Validation loss: 2.5283604050580277

Epoch: 6| Step: 3
Training loss: 2.162765499861545
Validation loss: 2.5342325292038197

Epoch: 6| Step: 4
Training loss: 2.114424250088613
Validation loss: 2.5208048437941426

Epoch: 6| Step: 5
Training loss: 2.8961073565105577
Validation loss: 2.525145953275257

Epoch: 6| Step: 6
Training loss: 1.938708144030636
Validation loss: 2.5180915997447952

Epoch: 6| Step: 7
Training loss: 2.4085725746869615
Validation loss: 2.5160084623690775

Epoch: 6| Step: 8
Training loss: 2.0892859168978304
Validation loss: 2.523536908501546

Epoch: 6| Step: 9
Training loss: 1.7638881546512921
Validation loss: 2.4995233876176473

Epoch: 6| Step: 10
Training loss: 2.2920247462869052
Validation loss: 2.4993839140575114

Epoch: 6| Step: 11
Training loss: 1.791412143223448
Validation loss: 2.5236110017415245

Epoch: 6| Step: 12
Training loss: 2.800210168307789
Validation loss: 2.5108495209842374

Epoch: 6| Step: 13
Training loss: 2.753793267712304
Validation loss: 2.5373064590583776

Epoch: 272| Step: 0
Training loss: 1.8207298749895449
Validation loss: 2.557338431889593

Epoch: 6| Step: 1
Training loss: 2.69340646770378
Validation loss: 2.565328417171888

Epoch: 6| Step: 2
Training loss: 2.1983689721115343
Validation loss: 2.594656085118551

Epoch: 6| Step: 3
Training loss: 2.84668136256383
Validation loss: 2.6065552146269226

Epoch: 6| Step: 4
Training loss: 2.4196548622489087
Validation loss: 2.606063919681905

Epoch: 6| Step: 5
Training loss: 2.2946065483168065
Validation loss: 2.5847204596351583

Epoch: 6| Step: 6
Training loss: 2.4930219538793503
Validation loss: 2.584972113035241

Epoch: 6| Step: 7
Training loss: 2.2888695957806897
Validation loss: 2.5353827470836814

Epoch: 6| Step: 8
Training loss: 1.6402808418787238
Validation loss: 2.5143271942866146

Epoch: 6| Step: 9
Training loss: 1.8053994363959918
Validation loss: 2.505610020739353

Epoch: 6| Step: 10
Training loss: 2.215836021801409
Validation loss: 2.5079882947363665

Epoch: 6| Step: 11
Training loss: 2.635006225549629
Validation loss: 2.4959590519323704

Epoch: 6| Step: 12
Training loss: 2.3005871520884074
Validation loss: 2.5086706719355965

Epoch: 6| Step: 13
Training loss: 2.0277203924806266
Validation loss: 2.501887776982818

Epoch: 273| Step: 0
Training loss: 3.049165617831511
Validation loss: 2.502112195697872

Epoch: 6| Step: 1
Training loss: 2.2904866966555715
Validation loss: 2.5133683723651585

Epoch: 6| Step: 2
Training loss: 1.8727920247471534
Validation loss: 2.5054330758042176

Epoch: 6| Step: 3
Training loss: 1.9187555194986587
Validation loss: 2.5327079247754685

Epoch: 6| Step: 4
Training loss: 1.8356813942049621
Validation loss: 2.5416078300128127

Epoch: 6| Step: 5
Training loss: 2.2421004115613736
Validation loss: 2.5683653160577675

Epoch: 6| Step: 6
Training loss: 2.0931453685845853
Validation loss: 2.5633086657567015

Epoch: 6| Step: 7
Training loss: 2.3416773468896253
Validation loss: 2.5475752322313028

Epoch: 6| Step: 8
Training loss: 2.672628552991078
Validation loss: 2.5576666863229884

Epoch: 6| Step: 9
Training loss: 2.0681830052725845
Validation loss: 2.5513406308623567

Epoch: 6| Step: 10
Training loss: 2.038256957441958
Validation loss: 2.531992407036596

Epoch: 6| Step: 11
Training loss: 2.3864626083657647
Validation loss: 2.5117774351392326

Epoch: 6| Step: 12
Training loss: 2.7796242066114742
Validation loss: 2.4985507181585147

Epoch: 6| Step: 13
Training loss: 2.5141316595812926
Validation loss: 2.4868681691483294

Epoch: 274| Step: 0
Training loss: 2.5391286988064987
Validation loss: 2.490069893784164

Epoch: 6| Step: 1
Training loss: 2.501405130329271
Validation loss: 2.4732060034726175

Epoch: 6| Step: 2
Training loss: 2.267395380165876
Validation loss: 2.4905967458720206

Epoch: 6| Step: 3
Training loss: 2.743372386764093
Validation loss: 2.4940422435008474

Epoch: 6| Step: 4
Training loss: 2.279258276605218
Validation loss: 2.4941477067249904

Epoch: 6| Step: 5
Training loss: 2.375388866512361
Validation loss: 2.4987276495270603

Epoch: 6| Step: 6
Training loss: 1.9811329226393486
Validation loss: 2.4978232921193952

Epoch: 6| Step: 7
Training loss: 2.839150702324597
Validation loss: 2.4939823921931117

Epoch: 6| Step: 8
Training loss: 2.0190845932642545
Validation loss: 2.5134863756603676

Epoch: 6| Step: 9
Training loss: 2.135593264340905
Validation loss: 2.5175781881343733

Epoch: 6| Step: 10
Training loss: 2.302556801922663
Validation loss: 2.5220722485327114

Epoch: 6| Step: 11
Training loss: 1.9544802426998344
Validation loss: 2.5416355808629225

Epoch: 6| Step: 12
Training loss: 2.0809395452587585
Validation loss: 2.5188366467234014

Epoch: 6| Step: 13
Training loss: 1.9638738039304569
Validation loss: 2.521332137094285

Epoch: 275| Step: 0
Training loss: 2.525895660480511
Validation loss: 2.542629627560452

Epoch: 6| Step: 1
Training loss: 2.4256368646329074
Validation loss: 2.5497484204597565

Epoch: 6| Step: 2
Training loss: 1.5329615311495906
Validation loss: 2.54518359915364

Epoch: 6| Step: 3
Training loss: 2.7698877963260244
Validation loss: 2.56036391818219

Epoch: 6| Step: 4
Training loss: 2.1858322325439627
Validation loss: 2.5659365676607493

Epoch: 6| Step: 5
Training loss: 2.2116695849991808
Validation loss: 2.577400028523567

Epoch: 6| Step: 6
Training loss: 1.576368884474562
Validation loss: 2.5611882767966994

Epoch: 6| Step: 7
Training loss: 2.715245410653645
Validation loss: 2.5690336592109912

Epoch: 6| Step: 8
Training loss: 1.9897064916496094
Validation loss: 2.534230741698313

Epoch: 6| Step: 9
Training loss: 2.413650230586012
Validation loss: 2.531658610577434

Epoch: 6| Step: 10
Training loss: 1.8522929750560235
Validation loss: 2.530439977196691

Epoch: 6| Step: 11
Training loss: 2.2884886351043363
Validation loss: 2.5239620706738113

Epoch: 6| Step: 12
Training loss: 2.3577601483235533
Validation loss: 2.517234224358993

Epoch: 6| Step: 13
Training loss: 2.2228699164105854
Validation loss: 2.51486126539189

Epoch: 276| Step: 0
Training loss: 3.1025862457558717
Validation loss: 2.5393811461211317

Epoch: 6| Step: 1
Training loss: 2.2526100702520786
Validation loss: 2.558527946111301

Epoch: 6| Step: 2
Training loss: 2.342372540372134
Validation loss: 2.6056434004705733

Epoch: 6| Step: 3
Training loss: 1.947209302877805
Validation loss: 2.60831318645395

Epoch: 6| Step: 4
Training loss: 2.455298754505641
Validation loss: 2.6139616410764104

Epoch: 6| Step: 5
Training loss: 2.6397730790495064
Validation loss: 2.6455452279052136

Epoch: 6| Step: 6
Training loss: 1.9182882567256996
Validation loss: 2.6201417713052253

Epoch: 6| Step: 7
Training loss: 2.4257934373435797
Validation loss: 2.6334232636881696

Epoch: 6| Step: 8
Training loss: 2.0152788678245246
Validation loss: 2.5799443308667143

Epoch: 6| Step: 9
Training loss: 2.216905821421159
Validation loss: 2.5553671489823184

Epoch: 6| Step: 10
Training loss: 2.1474305168519496
Validation loss: 2.507780809687491

Epoch: 6| Step: 11
Training loss: 2.182153216380445
Validation loss: 2.48691635185657

Epoch: 6| Step: 12
Training loss: 2.1665603049165485
Validation loss: 2.499461370299991

Epoch: 6| Step: 13
Training loss: 2.0586233987428497
Validation loss: 2.493599630107042

Epoch: 277| Step: 0
Training loss: 2.3479797851238193
Validation loss: 2.49848079616049

Epoch: 6| Step: 1
Training loss: 1.8984677033710102
Validation loss: 2.503741913082669

Epoch: 6| Step: 2
Training loss: 2.0673908851548815
Validation loss: 2.5173711620144776

Epoch: 6| Step: 3
Training loss: 2.680877688152335
Validation loss: 2.500375560525803

Epoch: 6| Step: 4
Training loss: 2.7446373758014
Validation loss: 2.512688053741823

Epoch: 6| Step: 5
Training loss: 2.615418431227411
Validation loss: 2.5236612541588452

Epoch: 6| Step: 6
Training loss: 1.7714450751911404
Validation loss: 2.5190570868120963

Epoch: 6| Step: 7
Training loss: 1.6193229103323543
Validation loss: 2.5158219191283964

Epoch: 6| Step: 8
Training loss: 2.146729279171684
Validation loss: 2.518570812026304

Epoch: 6| Step: 9
Training loss: 1.8335330883210201
Validation loss: 2.5098847001026656

Epoch: 6| Step: 10
Training loss: 2.870947261887963
Validation loss: 2.504479480020897

Epoch: 6| Step: 11
Training loss: 2.502384669707431
Validation loss: 2.513866386406531

Epoch: 6| Step: 12
Training loss: 2.383522203159967
Validation loss: 2.506918536892135

Epoch: 6| Step: 13
Training loss: 1.7563612987507062
Validation loss: 2.542287099395937

Epoch: 278| Step: 0
Training loss: 2.369029118743394
Validation loss: 2.5474114038437023

Epoch: 6| Step: 1
Training loss: 2.4882966764202443
Validation loss: 2.558249957644794

Epoch: 6| Step: 2
Training loss: 2.356269358750206
Validation loss: 2.574235374848512

Epoch: 6| Step: 3
Training loss: 1.7880644700633093
Validation loss: 2.592081444800978

Epoch: 6| Step: 4
Training loss: 2.3823419825538017
Validation loss: 2.6279842277016785

Epoch: 6| Step: 5
Training loss: 2.2219361544963894
Validation loss: 2.625278367314577

Epoch: 6| Step: 6
Training loss: 2.1726188209269806
Validation loss: 2.610563437762117

Epoch: 6| Step: 7
Training loss: 1.6301052154330278
Validation loss: 2.601054190617115

Epoch: 6| Step: 8
Training loss: 1.8701669073841
Validation loss: 2.6084681475069673

Epoch: 6| Step: 9
Training loss: 2.3996871029018547
Validation loss: 2.5837217597789945

Epoch: 6| Step: 10
Training loss: 2.614680851995935
Validation loss: 2.582039621929191

Epoch: 6| Step: 11
Training loss: 2.492266901838075
Validation loss: 2.5756222840254477

Epoch: 6| Step: 12
Training loss: 2.602113224424919
Validation loss: 2.5585618344711505

Epoch: 6| Step: 13
Training loss: 1.8893861100617542
Validation loss: 2.577797500924955

Epoch: 279| Step: 0
Training loss: 2.0667817724638984
Validation loss: 2.5458122485630543

Epoch: 6| Step: 1
Training loss: 1.5247396528296668
Validation loss: 2.559364866578998

Epoch: 6| Step: 2
Training loss: 1.980438292380133
Validation loss: 2.5496702866164704

Epoch: 6| Step: 3
Training loss: 2.1503624632721126
Validation loss: 2.5273347723760646

Epoch: 6| Step: 4
Training loss: 2.4421374881477997
Validation loss: 2.5258267235824134

Epoch: 6| Step: 5
Training loss: 2.635142396267875
Validation loss: 2.529362433920512

Epoch: 6| Step: 6
Training loss: 2.3069922351218692
Validation loss: 2.528309043720663

Epoch: 6| Step: 7
Training loss: 2.204612500316165
Validation loss: 2.5173826060345705

Epoch: 6| Step: 8
Training loss: 3.264990055834361
Validation loss: 2.536269513151165

Epoch: 6| Step: 9
Training loss: 1.848507062259274
Validation loss: 2.5240226201083145

Epoch: 6| Step: 10
Training loss: 2.1339260450166933
Validation loss: 2.5404785042068387

Epoch: 6| Step: 11
Training loss: 2.3160820102040263
Validation loss: 2.55014365047171

Epoch: 6| Step: 12
Training loss: 2.301410789695052
Validation loss: 2.554389819612535

Epoch: 6| Step: 13
Training loss: 1.9145483529178364
Validation loss: 2.5516602976507943

Epoch: 280| Step: 0
Training loss: 2.2220001056715755
Validation loss: 2.5555949956734563

Epoch: 6| Step: 1
Training loss: 2.5595395735110524
Validation loss: 2.5768830824207187

Epoch: 6| Step: 2
Training loss: 2.8244593347669995
Validation loss: 2.585941756476427

Epoch: 6| Step: 3
Training loss: 2.185216201979967
Validation loss: 2.587486870896698

Epoch: 6| Step: 4
Training loss: 2.1087505405246696
Validation loss: 2.5538495601765976

Epoch: 6| Step: 5
Training loss: 2.3914972845656672
Validation loss: 2.5322690097847143

Epoch: 6| Step: 6
Training loss: 2.1441227536004845
Validation loss: 2.5076373347094454

Epoch: 6| Step: 7
Training loss: 2.1792613060594386
Validation loss: 2.524703378534181

Epoch: 6| Step: 8
Training loss: 1.6404199381240083
Validation loss: 2.5039467652088527

Epoch: 6| Step: 9
Training loss: 1.7818253240548343
Validation loss: 2.498014472232308

Epoch: 6| Step: 10
Training loss: 2.586295019599613
Validation loss: 2.502024371373285

Epoch: 6| Step: 11
Training loss: 2.1506072584028493
Validation loss: 2.495761091007234

Epoch: 6| Step: 12
Training loss: 2.6767677883114
Validation loss: 2.5130500646811624

Epoch: 6| Step: 13
Training loss: 1.967783736209092
Validation loss: 2.515054468256486

Epoch: 281| Step: 0
Training loss: 1.3909510540992815
Validation loss: 2.536077761967602

Epoch: 6| Step: 1
Training loss: 1.8045572341209524
Validation loss: 2.548164953723719

Epoch: 6| Step: 2
Training loss: 2.2935234061843746
Validation loss: 2.5746583924961466

Epoch: 6| Step: 3
Training loss: 2.6313616549979044
Validation loss: 2.564889352133369

Epoch: 6| Step: 4
Training loss: 2.287719853576588
Validation loss: 2.5657417602238253

Epoch: 6| Step: 5
Training loss: 2.2483885610634555
Validation loss: 2.5787538012083475

Epoch: 6| Step: 6
Training loss: 1.997689163837946
Validation loss: 2.578693412003322

Epoch: 6| Step: 7
Training loss: 2.766611645239525
Validation loss: 2.584482742271632

Epoch: 6| Step: 8
Training loss: 1.57819736428109
Validation loss: 2.589601047933011

Epoch: 6| Step: 9
Training loss: 2.4500718281395777
Validation loss: 2.5887315911989726

Epoch: 6| Step: 10
Training loss: 2.4115389871532367
Validation loss: 2.589430264414107

Epoch: 6| Step: 11
Training loss: 2.2926232046718567
Validation loss: 2.5504942221821323

Epoch: 6| Step: 12
Training loss: 2.4135419660910227
Validation loss: 2.51807757884253

Epoch: 6| Step: 13
Training loss: 2.5212211205526387
Validation loss: 2.4956173867583136

Epoch: 282| Step: 0
Training loss: 1.7871233830137476
Validation loss: 2.491350924432925

Epoch: 6| Step: 1
Training loss: 2.2546542032364685
Validation loss: 2.4921764664520323

Epoch: 6| Step: 2
Training loss: 2.2231637814377687
Validation loss: 2.493468558253531

Epoch: 6| Step: 3
Training loss: 2.1435036342510845
Validation loss: 2.4680954753609994

Epoch: 6| Step: 4
Training loss: 1.870563216841244
Validation loss: 2.491723889445481

Epoch: 6| Step: 5
Training loss: 2.8594965674400905
Validation loss: 2.488085441131147

Epoch: 6| Step: 6
Training loss: 2.6565364010063606
Validation loss: 2.511901437494191

Epoch: 6| Step: 7
Training loss: 2.22727692502817
Validation loss: 2.526687875002758

Epoch: 6| Step: 8
Training loss: 2.023666309984796
Validation loss: 2.5653432408697983

Epoch: 6| Step: 9
Training loss: 2.6861054106683304
Validation loss: 2.5967431626745716

Epoch: 6| Step: 10
Training loss: 1.8649298134654348
Validation loss: 2.5777671334395844

Epoch: 6| Step: 11
Training loss: 1.6642032617484515
Validation loss: 2.5720324650792437

Epoch: 6| Step: 12
Training loss: 2.5082286834008705
Validation loss: 2.5566224247396567

Epoch: 6| Step: 13
Training loss: 2.577714829617188
Validation loss: 2.5578882695935574

Epoch: 283| Step: 0
Training loss: 2.5523448784121894
Validation loss: 2.5507703452780244

Epoch: 6| Step: 1
Training loss: 2.791113006195645
Validation loss: 2.54740099165779

Epoch: 6| Step: 2
Training loss: 1.4039344372941998
Validation loss: 2.554266005342788

Epoch: 6| Step: 3
Training loss: 1.8594110950204192
Validation loss: 2.536138570527072

Epoch: 6| Step: 4
Training loss: 2.6162281612499947
Validation loss: 2.556444145484293

Epoch: 6| Step: 5
Training loss: 2.0070321908297473
Validation loss: 2.559764099353491

Epoch: 6| Step: 6
Training loss: 2.0838121881112617
Validation loss: 2.543687663146327

Epoch: 6| Step: 7
Training loss: 1.9404406228066933
Validation loss: 2.52480780496378

Epoch: 6| Step: 8
Training loss: 2.1092793760877577
Validation loss: 2.5246818552931116

Epoch: 6| Step: 9
Training loss: 2.435625382468155
Validation loss: 2.5331447087721304

Epoch: 6| Step: 10
Training loss: 1.8046374953967543
Validation loss: 2.5358080072691678

Epoch: 6| Step: 11
Training loss: 2.3857795628084446
Validation loss: 2.5325869573367403

Epoch: 6| Step: 12
Training loss: 2.5568570598382263
Validation loss: 2.5049932682304767

Epoch: 6| Step: 13
Training loss: 2.1837949711274707
Validation loss: 2.5388671017311815

Epoch: 284| Step: 0
Training loss: 1.667462238530471
Validation loss: 2.5487062856265834

Epoch: 6| Step: 1
Training loss: 2.3334817385027424
Validation loss: 2.575173771497728

Epoch: 6| Step: 2
Training loss: 2.40093506240572
Validation loss: 2.5960613966961676

Epoch: 6| Step: 3
Training loss: 2.5606758323802676
Validation loss: 2.592834004510721

Epoch: 6| Step: 4
Training loss: 2.4833744361428645
Validation loss: 2.570600947588988

Epoch: 6| Step: 5
Training loss: 2.220958523922527
Validation loss: 2.538677088512071

Epoch: 6| Step: 6
Training loss: 1.9344582830936266
Validation loss: 2.5337438503818697

Epoch: 6| Step: 7
Training loss: 2.0831021244179064
Validation loss: 2.526632390641134

Epoch: 6| Step: 8
Training loss: 2.2040313587830975
Validation loss: 2.508500350469552

Epoch: 6| Step: 9
Training loss: 2.7547108442038994
Validation loss: 2.5003010091766686

Epoch: 6| Step: 10
Training loss: 1.959446739331471
Validation loss: 2.500509814096612

Epoch: 6| Step: 11
Training loss: 2.447995794654176
Validation loss: 2.497935006522672

Epoch: 6| Step: 12
Training loss: 1.641572660410729
Validation loss: 2.5048103465801153

Epoch: 6| Step: 13
Training loss: 2.2703607983318532
Validation loss: 2.5049344003581524

Epoch: 285| Step: 0
Training loss: 1.8701618717124089
Validation loss: 2.513007925260661

Epoch: 6| Step: 1
Training loss: 1.9073344413534548
Validation loss: 2.5165302788069774

Epoch: 6| Step: 2
Training loss: 2.4269403461910075
Validation loss: 2.5099029701344118

Epoch: 6| Step: 3
Training loss: 2.267919391511533
Validation loss: 2.528134614842085

Epoch: 6| Step: 4
Training loss: 2.4688095858179526
Validation loss: 2.5016767203730237

Epoch: 6| Step: 5
Training loss: 2.348142246714032
Validation loss: 2.518057490233108

Epoch: 6| Step: 6
Training loss: 2.638441639081091
Validation loss: 2.527550989033496

Epoch: 6| Step: 7
Training loss: 1.9369605143928506
Validation loss: 2.5528701866737227

Epoch: 6| Step: 8
Training loss: 2.7190869002041507
Validation loss: 2.5906004109613416

Epoch: 6| Step: 9
Training loss: 1.6001229119774076
Validation loss: 2.5994655341008293

Epoch: 6| Step: 10
Training loss: 1.9723832045329532
Validation loss: 2.584325189813879

Epoch: 6| Step: 11
Training loss: 2.3664416658428142
Validation loss: 2.584156325720507

Epoch: 6| Step: 12
Training loss: 1.9878177964551194
Validation loss: 2.5800663122137237

Epoch: 6| Step: 13
Training loss: 2.636306662676334
Validation loss: 2.562438196506925

Epoch: 286| Step: 0
Training loss: 2.539895915654738
Validation loss: 2.5210335838499964

Epoch: 6| Step: 1
Training loss: 1.623845570653858
Validation loss: 2.5150112722408413

Epoch: 6| Step: 2
Training loss: 2.2966918872321402
Validation loss: 2.5138903179363687

Epoch: 6| Step: 3
Training loss: 2.659246213419131
Validation loss: 2.5091140079283174

Epoch: 6| Step: 4
Training loss: 1.809395861464231
Validation loss: 2.5191848398458103

Epoch: 6| Step: 5
Training loss: 1.9564139178646542
Validation loss: 2.5201365017440907

Epoch: 6| Step: 6
Training loss: 2.1853473425659162
Validation loss: 2.516306861731464

Epoch: 6| Step: 7
Training loss: 1.8878217359776939
Validation loss: 2.5134269636541133

Epoch: 6| Step: 8
Training loss: 1.80386968140277
Validation loss: 2.5076152371378346

Epoch: 6| Step: 9
Training loss: 2.5153594261869845
Validation loss: 2.506090454325184

Epoch: 6| Step: 10
Training loss: 2.1472864015020643
Validation loss: 2.4996627262218545

Epoch: 6| Step: 11
Training loss: 2.9964292256364153
Validation loss: 2.516383070682555

Epoch: 6| Step: 12
Training loss: 2.4066970211802343
Validation loss: 2.5391989490329383

Epoch: 6| Step: 13
Training loss: 2.2558080097642406
Validation loss: 2.5168002051067413

Epoch: 287| Step: 0
Training loss: 2.187559181502732
Validation loss: 2.536549769534836

Epoch: 6| Step: 1
Training loss: 2.568474387723071
Validation loss: 2.576364814140849

Epoch: 6| Step: 2
Training loss: 1.8207476836544263
Validation loss: 2.5579131097101375

Epoch: 6| Step: 3
Training loss: 2.0682151679323595
Validation loss: 2.5772755466119763

Epoch: 6| Step: 4
Training loss: 2.257558207727831
Validation loss: 2.5557217851999545

Epoch: 6| Step: 5
Training loss: 1.5948805445600043
Validation loss: 2.5474567178051077

Epoch: 6| Step: 6
Training loss: 2.274731769049764
Validation loss: 2.5121932226752426

Epoch: 6| Step: 7
Training loss: 2.16438527919125
Validation loss: 2.5195312815427164

Epoch: 6| Step: 8
Training loss: 2.4768205863217854
Validation loss: 2.511654969192162

Epoch: 6| Step: 9
Training loss: 2.159547799424233
Validation loss: 2.5026557644471272

Epoch: 6| Step: 10
Training loss: 2.8522321358969815
Validation loss: 2.4895155962636624

Epoch: 6| Step: 11
Training loss: 2.09227974355703
Validation loss: 2.489840607271584

Epoch: 6| Step: 12
Training loss: 2.488689299321703
Validation loss: 2.478026798542633

Epoch: 6| Step: 13
Training loss: 2.0660081562867223
Validation loss: 2.500572472830826

Epoch: 288| Step: 0
Training loss: 1.9228289337919064
Validation loss: 2.512804476000866

Epoch: 6| Step: 1
Training loss: 2.210902237358205
Validation loss: 2.5145781493008412

Epoch: 6| Step: 2
Training loss: 3.0434685860948028
Validation loss: 2.527829846228975

Epoch: 6| Step: 3
Training loss: 2.590561803178068
Validation loss: 2.5372999597884727

Epoch: 6| Step: 4
Training loss: 2.182778849577884
Validation loss: 2.5167729382676995

Epoch: 6| Step: 5
Training loss: 2.075700880511261
Validation loss: 2.5096921442459372

Epoch: 6| Step: 6
Training loss: 1.8298817858009582
Validation loss: 2.5366252136686547

Epoch: 6| Step: 7
Training loss: 1.7370490003404453
Validation loss: 2.5557015104930763

Epoch: 6| Step: 8
Training loss: 2.120688159023449
Validation loss: 2.554557789222864

Epoch: 6| Step: 9
Training loss: 2.411076053339121
Validation loss: 2.5789350527873243

Epoch: 6| Step: 10
Training loss: 2.374940469899232
Validation loss: 2.5439204453359148

Epoch: 6| Step: 11
Training loss: 2.6742100913029923
Validation loss: 2.552610994143184

Epoch: 6| Step: 12
Training loss: 1.7511904618287109
Validation loss: 2.5513814674656676

Epoch: 6| Step: 13
Training loss: 2.293834412396178
Validation loss: 2.5666529954405815

Epoch: 289| Step: 0
Training loss: 1.86656076295479
Validation loss: 2.5377766018399157

Epoch: 6| Step: 1
Training loss: 2.295227705685705
Validation loss: 2.546665744727236

Epoch: 6| Step: 2
Training loss: 1.7914324392940566
Validation loss: 2.5586982220391423

Epoch: 6| Step: 3
Training loss: 2.7538949952673386
Validation loss: 2.5399332754126798

Epoch: 6| Step: 4
Training loss: 2.8397836377105894
Validation loss: 2.560733317966777

Epoch: 6| Step: 5
Training loss: 2.571316786637234
Validation loss: 2.540093033806409

Epoch: 6| Step: 6
Training loss: 2.0040596053725515
Validation loss: 2.556286326105974

Epoch: 6| Step: 7
Training loss: 2.0724723633693967
Validation loss: 2.5459568108198973

Epoch: 6| Step: 8
Training loss: 1.7764458368893117
Validation loss: 2.565287771608825

Epoch: 6| Step: 9
Training loss: 2.4111318236758805
Validation loss: 2.544514004433487

Epoch: 6| Step: 10
Training loss: 2.0953740895298965
Validation loss: 2.5569334433164284

Epoch: 6| Step: 11
Training loss: 2.676634893201063
Validation loss: 2.5278893598677987

Epoch: 6| Step: 12
Training loss: 1.9106218827521364
Validation loss: 2.5396899108387117

Epoch: 6| Step: 13
Training loss: 1.9740449455269373
Validation loss: 2.505573227625757

Epoch: 290| Step: 0
Training loss: 2.8540807186653336
Validation loss: 2.527942914657257

Epoch: 6| Step: 1
Training loss: 1.685149215520856
Validation loss: 2.5032270743281795

Epoch: 6| Step: 2
Training loss: 2.595215073421321
Validation loss: 2.5111532489322523

Epoch: 6| Step: 3
Training loss: 2.165732940581981
Validation loss: 2.506349844144769

Epoch: 6| Step: 4
Training loss: 2.8036138238035675
Validation loss: 2.5023919583529217

Epoch: 6| Step: 5
Training loss: 2.4266493467963453
Validation loss: 2.51774755617544

Epoch: 6| Step: 6
Training loss: 2.34330826729201
Validation loss: 2.5137617267554524

Epoch: 6| Step: 7
Training loss: 1.757417219011253
Validation loss: 2.5152981152816096

Epoch: 6| Step: 8
Training loss: 1.6483745834131367
Validation loss: 2.5243629829162892

Epoch: 6| Step: 9
Training loss: 1.993154851881891
Validation loss: 2.5245768570196483

Epoch: 6| Step: 10
Training loss: 2.4039574142530555
Validation loss: 2.5211753350497608

Epoch: 6| Step: 11
Training loss: 2.137056034672655
Validation loss: 2.529566169453915

Epoch: 6| Step: 12
Training loss: 2.029372301067582
Validation loss: 2.54541391850124

Epoch: 6| Step: 13
Training loss: 1.980771976409217
Validation loss: 2.5667211144935074

Epoch: 291| Step: 0
Training loss: 2.669867134788834
Validation loss: 2.556008218213771

Epoch: 6| Step: 1
Training loss: 2.197171004907148
Validation loss: 2.5833617844604353

Epoch: 6| Step: 2
Training loss: 2.5174183583966783
Validation loss: 2.5587554958168326

Epoch: 6| Step: 3
Training loss: 2.467875265323455
Validation loss: 2.5694369570877913

Epoch: 6| Step: 4
Training loss: 2.5148154905069964
Validation loss: 2.5693686007283367

Epoch: 6| Step: 5
Training loss: 1.6345250398171283
Validation loss: 2.5758713090660703

Epoch: 6| Step: 6
Training loss: 1.842895956570632
Validation loss: 2.569572365357338

Epoch: 6| Step: 7
Training loss: 1.7386412515645215
Validation loss: 2.5711845302329266

Epoch: 6| Step: 8
Training loss: 2.381032310007071
Validation loss: 2.5593161148047874

Epoch: 6| Step: 9
Training loss: 1.7622713630583866
Validation loss: 2.5233555830659475

Epoch: 6| Step: 10
Training loss: 2.2456323829824667
Validation loss: 2.5256210186650105

Epoch: 6| Step: 11
Training loss: 2.5983913213373517
Validation loss: 2.512381949110717

Epoch: 6| Step: 12
Training loss: 2.240209790521436
Validation loss: 2.5213280394666837

Epoch: 6| Step: 13
Training loss: 1.6059781865007872
Validation loss: 2.5350460034396534

Epoch: 292| Step: 0
Training loss: 2.6810559040232724
Validation loss: 2.526542194499539

Epoch: 6| Step: 1
Training loss: 2.555648296396487
Validation loss: 2.527429845523666

Epoch: 6| Step: 2
Training loss: 2.1061196533077298
Validation loss: 2.515187495948482

Epoch: 6| Step: 3
Training loss: 2.0887678853061975
Validation loss: 2.521866938543848

Epoch: 6| Step: 4
Training loss: 2.508848742721446
Validation loss: 2.5234982509799715

Epoch: 6| Step: 5
Training loss: 2.2464320185156406
Validation loss: 2.537048448746822

Epoch: 6| Step: 6
Training loss: 1.6538563832084383
Validation loss: 2.52288098098713

Epoch: 6| Step: 7
Training loss: 1.7845769230153503
Validation loss: 2.5365750692608424

Epoch: 6| Step: 8
Training loss: 2.357684003135827
Validation loss: 2.548175596699048

Epoch: 6| Step: 9
Training loss: 1.8933131126322476
Validation loss: 2.5637748772356383

Epoch: 6| Step: 10
Training loss: 2.4480836419046694
Validation loss: 2.600819982926086

Epoch: 6| Step: 11
Training loss: 2.7026235302721346
Validation loss: 2.628706767206946

Epoch: 6| Step: 12
Training loss: 2.0672557216929093
Validation loss: 2.6236654552537213

Epoch: 6| Step: 13
Training loss: 1.3866377685971376
Validation loss: 2.5764101201222562

Epoch: 293| Step: 0
Training loss: 1.9821184198549715
Validation loss: 2.589973028378848

Epoch: 6| Step: 1
Training loss: 2.215333699391178
Validation loss: 2.5625522422117233

Epoch: 6| Step: 2
Training loss: 2.443199439116278
Validation loss: 2.5572302138227876

Epoch: 6| Step: 3
Training loss: 1.7429684654793023
Validation loss: 2.521415774522493

Epoch: 6| Step: 4
Training loss: 2.384475377920975
Validation loss: 2.5117743739588296

Epoch: 6| Step: 5
Training loss: 2.383272120438838
Validation loss: 2.504627268783492

Epoch: 6| Step: 6
Training loss: 1.9586194688335576
Validation loss: 2.495431373358797

Epoch: 6| Step: 7
Training loss: 1.8507169571446214
Validation loss: 2.501187535207682

Epoch: 6| Step: 8
Training loss: 2.1331138537674836
Validation loss: 2.511086629107739

Epoch: 6| Step: 9
Training loss: 2.063946303534099
Validation loss: 2.5048664729506878

Epoch: 6| Step: 10
Training loss: 2.8189747350723664
Validation loss: 2.5066370600953984

Epoch: 6| Step: 11
Training loss: 1.6125399384986325
Validation loss: 2.5349553228926918

Epoch: 6| Step: 12
Training loss: 2.6538646084963515
Validation loss: 2.581229827592674

Epoch: 6| Step: 13
Training loss: 2.0653509607484275
Validation loss: 2.605372010074086

Epoch: 294| Step: 0
Training loss: 1.5496329949792687
Validation loss: 2.6581083939989814

Epoch: 6| Step: 1
Training loss: 2.604631601156002
Validation loss: 2.645710549296497

Epoch: 6| Step: 2
Training loss: 2.649776514094348
Validation loss: 2.6306150644395245

Epoch: 6| Step: 3
Training loss: 2.6318509754324553
Validation loss: 2.602404667173669

Epoch: 6| Step: 4
Training loss: 1.861960848916034
Validation loss: 2.5708962563141244

Epoch: 6| Step: 5
Training loss: 2.294649148522107
Validation loss: 2.5090886055129946

Epoch: 6| Step: 6
Training loss: 1.4431938520406298
Validation loss: 2.5022595843498943

Epoch: 6| Step: 7
Training loss: 1.8231211593006835
Validation loss: 2.4890212910304648

Epoch: 6| Step: 8
Training loss: 2.108442651480305
Validation loss: 2.4913084578557987

Epoch: 6| Step: 9
Training loss: 2.016619769515266
Validation loss: 2.486949218782723

Epoch: 6| Step: 10
Training loss: 2.459372952568239
Validation loss: 2.4942654324787257

Epoch: 6| Step: 11
Training loss: 2.909380303694565
Validation loss: 2.4989517716425915

Epoch: 6| Step: 12
Training loss: 2.1271752836084814
Validation loss: 2.487649427171811

Epoch: 6| Step: 13
Training loss: 2.253786821027546
Validation loss: 2.4946078482955087

Epoch: 295| Step: 0
Training loss: 1.5491879828048287
Validation loss: 2.492868902314273

Epoch: 6| Step: 1
Training loss: 2.433874221241311
Validation loss: 2.4936766764251197

Epoch: 6| Step: 2
Training loss: 2.5439616197294033
Validation loss: 2.4800048554537013

Epoch: 6| Step: 3
Training loss: 2.6702030594722
Validation loss: 2.488867921601355

Epoch: 6| Step: 4
Training loss: 1.8217706038596513
Validation loss: 2.5064754070792983

Epoch: 6| Step: 5
Training loss: 2.733865134523096
Validation loss: 2.5294204819177235

Epoch: 6| Step: 6
Training loss: 2.3575310985985687
Validation loss: 2.542084484986905

Epoch: 6| Step: 7
Training loss: 2.1128705484117343
Validation loss: 2.540346159575716

Epoch: 6| Step: 8
Training loss: 2.2097185097159766
Validation loss: 2.5550770438286805

Epoch: 6| Step: 9
Training loss: 1.8562107891218453
Validation loss: 2.567380955210435

Epoch: 6| Step: 10
Training loss: 1.6858317288089244
Validation loss: 2.6011995476677496

Epoch: 6| Step: 11
Training loss: 2.5767260830910015
Validation loss: 2.623555300538396

Epoch: 6| Step: 12
Training loss: 1.7235006395188825
Validation loss: 2.644434421406334

Epoch: 6| Step: 13
Training loss: 1.6669642262273077
Validation loss: 2.6435064060784614

Epoch: 296| Step: 0
Training loss: 2.8376869711424137
Validation loss: 2.6032009521248174

Epoch: 6| Step: 1
Training loss: 2.347124442547457
Validation loss: 2.599051905128026

Epoch: 6| Step: 2
Training loss: 1.8748784343729483
Validation loss: 2.5462968946385565

Epoch: 6| Step: 3
Training loss: 1.7143832133586976
Validation loss: 2.53815954340643

Epoch: 6| Step: 4
Training loss: 2.9548402679182395
Validation loss: 2.529783506969039

Epoch: 6| Step: 5
Training loss: 1.5676981100803067
Validation loss: 2.529529693374942

Epoch: 6| Step: 6
Training loss: 1.960981877649305
Validation loss: 2.5308298460838285

Epoch: 6| Step: 7
Training loss: 2.159706551786965
Validation loss: 2.5365110910139204

Epoch: 6| Step: 8
Training loss: 1.935283562141891
Validation loss: 2.5562683564936144

Epoch: 6| Step: 9
Training loss: 1.6784449750001915
Validation loss: 2.5581557347868107

Epoch: 6| Step: 10
Training loss: 2.9193750794463167
Validation loss: 2.5813246937090284

Epoch: 6| Step: 11
Training loss: 2.396707016132593
Validation loss: 2.591080360288287

Epoch: 6| Step: 12
Training loss: 2.28368613401746
Validation loss: 2.6161245588353608

Epoch: 6| Step: 13
Training loss: 1.4729801702051617
Validation loss: 2.6170286139849357

Epoch: 297| Step: 0
Training loss: 2.1340444730577386
Validation loss: 2.575264532581185

Epoch: 6| Step: 1
Training loss: 1.8233332639318776
Validation loss: 2.565694384114879

Epoch: 6| Step: 2
Training loss: 1.79018976271243
Validation loss: 2.5275507925170286

Epoch: 6| Step: 3
Training loss: 2.6564210724438126
Validation loss: 2.543152926993155

Epoch: 6| Step: 4
Training loss: 2.1047739216507284
Validation loss: 2.516700798923197

Epoch: 6| Step: 5
Training loss: 1.7727184434372987
Validation loss: 2.5039518593191525

Epoch: 6| Step: 6
Training loss: 2.8388255312776254
Validation loss: 2.5097879648760526

Epoch: 6| Step: 7
Training loss: 2.350705114052727
Validation loss: 2.5248303894637543

Epoch: 6| Step: 8
Training loss: 2.2491863686979063
Validation loss: 2.5276681808728063

Epoch: 6| Step: 9
Training loss: 2.217463913100301
Validation loss: 2.5385737335053955

Epoch: 6| Step: 10
Training loss: 2.2960377938486225
Validation loss: 2.5830358108320315

Epoch: 6| Step: 11
Training loss: 1.901105850042013
Validation loss: 2.5866432801849357

Epoch: 6| Step: 12
Training loss: 2.0337695414724464
Validation loss: 2.592975600431733

Epoch: 6| Step: 13
Training loss: 2.050481748963407
Validation loss: 2.5763783944514005

Epoch: 298| Step: 0
Training loss: 2.1641687029727508
Validation loss: 2.6040157172641387

Epoch: 6| Step: 1
Training loss: 2.494577726510011
Validation loss: 2.5365705262945744

Epoch: 6| Step: 2
Training loss: 1.6752595956536378
Validation loss: 2.567308194834386

Epoch: 6| Step: 3
Training loss: 2.4033130706095176
Validation loss: 2.555275385697778

Epoch: 6| Step: 4
Training loss: 2.078722645573295
Validation loss: 2.56324812195188

Epoch: 6| Step: 5
Training loss: 2.1442715291270833
Validation loss: 2.566475351023638

Epoch: 6| Step: 6
Training loss: 1.8760286688332297
Validation loss: 2.565970838239816

Epoch: 6| Step: 7
Training loss: 1.9548765949413751
Validation loss: 2.543197840280827

Epoch: 6| Step: 8
Training loss: 2.403499071153176
Validation loss: 2.534094950313381

Epoch: 6| Step: 9
Training loss: 2.473868941984247
Validation loss: 2.5365975803219234

Epoch: 6| Step: 10
Training loss: 2.4391138651764788
Validation loss: 2.530293586166843

Epoch: 6| Step: 11
Training loss: 2.2483692617446547
Validation loss: 2.5244753802468973

Epoch: 6| Step: 12
Training loss: 1.9483750835782605
Validation loss: 2.5292388712983893

Epoch: 6| Step: 13
Training loss: 2.3276237613868687
Validation loss: 2.5395146050566155

Epoch: 299| Step: 0
Training loss: 2.2019483521906986
Validation loss: 2.5610330616203303

Epoch: 6| Step: 1
Training loss: 2.2221964543226154
Validation loss: 2.5807895031037

Epoch: 6| Step: 2
Training loss: 1.9715129900859174
Validation loss: 2.572749674290345

Epoch: 6| Step: 3
Training loss: 2.4870186421455296
Validation loss: 2.601399337341141

Epoch: 6| Step: 4
Training loss: 2.159355691252086
Validation loss: 2.6114190598648825

Epoch: 6| Step: 5
Training loss: 2.4026359070316525
Validation loss: 2.5947891666171112

Epoch: 6| Step: 6
Training loss: 2.106724408883457
Validation loss: 2.5659686624665463

Epoch: 6| Step: 7
Training loss: 1.7523917475201523
Validation loss: 2.5549513965370827

Epoch: 6| Step: 8
Training loss: 2.2277338527282176
Validation loss: 2.5635478350707093

Epoch: 6| Step: 9
Training loss: 2.029350918884543
Validation loss: 2.537908900408797

Epoch: 6| Step: 10
Training loss: 2.1863237760908483
Validation loss: 2.515498156143551

Epoch: 6| Step: 11
Training loss: 2.242933195836177
Validation loss: 2.518507386190249

Epoch: 6| Step: 12
Training loss: 2.5124102600165106
Validation loss: 2.524961202468173

Epoch: 6| Step: 13
Training loss: 2.041184997831783
Validation loss: 2.505911275752833

Epoch: 300| Step: 0
Training loss: 2.2179718802263046
Validation loss: 2.5228452981629554

Epoch: 6| Step: 1
Training loss: 2.113348263508297
Validation loss: 2.5273496459703493

Epoch: 6| Step: 2
Training loss: 2.6501551096884337
Validation loss: 2.5391636754932154

Epoch: 6| Step: 3
Training loss: 1.746805408708931
Validation loss: 2.5493867264465693

Epoch: 6| Step: 4
Training loss: 2.1508988032032317
Validation loss: 2.576411299995043

Epoch: 6| Step: 5
Training loss: 2.8367869888708688
Validation loss: 2.5364840517300293

Epoch: 6| Step: 6
Training loss: 1.8662317615187605
Validation loss: 2.5834772290382366

Epoch: 6| Step: 7
Training loss: 2.434918332463453
Validation loss: 2.5844437355947285

Epoch: 6| Step: 8
Training loss: 2.4217419003244562
Validation loss: 2.565658359721139

Epoch: 6| Step: 9
Training loss: 2.4133644452732845
Validation loss: 2.5439841903869054

Epoch: 6| Step: 10
Training loss: 1.8477996060847146
Validation loss: 2.555269033211521

Epoch: 6| Step: 11
Training loss: 1.6506694851549786
Validation loss: 2.5537719330271362

Epoch: 6| Step: 12
Training loss: 2.0919224748561085
Validation loss: 2.5449142007036256

Epoch: 6| Step: 13
Training loss: 1.8050894021377675
Validation loss: 2.538436217707873

Epoch: 301| Step: 0
Training loss: 1.5155431980985348
Validation loss: 2.5514487638896513

Epoch: 6| Step: 1
Training loss: 1.7567292669290724
Validation loss: 2.5470391905113057

Epoch: 6| Step: 2
Training loss: 1.9257138996843481
Validation loss: 2.542523635684379

Epoch: 6| Step: 3
Training loss: 1.9702590729429874
Validation loss: 2.5489410570247966

Epoch: 6| Step: 4
Training loss: 1.51020630873407
Validation loss: 2.5766833889070293

Epoch: 6| Step: 5
Training loss: 2.9082396884769186
Validation loss: 2.5650968651578876

Epoch: 6| Step: 6
Training loss: 1.5828403993879776
Validation loss: 2.550168098568808

Epoch: 6| Step: 7
Training loss: 2.1404354262116243
Validation loss: 2.590356913071669

Epoch: 6| Step: 8
Training loss: 2.3133964862869685
Validation loss: 2.614763395535369

Epoch: 6| Step: 9
Training loss: 2.5134860594745887
Validation loss: 2.611949328438794

Epoch: 6| Step: 10
Training loss: 2.8464617532894154
Validation loss: 2.6320877511480214

Epoch: 6| Step: 11
Training loss: 2.6994891990393257
Validation loss: 2.627913175521797

Epoch: 6| Step: 12
Training loss: 2.2821994007797466
Validation loss: 2.5961399174902575

Epoch: 6| Step: 13
Training loss: 1.8387692952651011
Validation loss: 2.589552382030765

Epoch: 302| Step: 0
Training loss: 1.8023925324887653
Validation loss: 2.54914424879732

Epoch: 6| Step: 1
Training loss: 1.8169592887083987
Validation loss: 2.5268176325669693

Epoch: 6| Step: 2
Training loss: 2.2940864503330216
Validation loss: 2.517202810520721

Epoch: 6| Step: 3
Training loss: 2.5581821256140618
Validation loss: 2.5244095763530012

Epoch: 6| Step: 4
Training loss: 2.456732945611355
Validation loss: 2.505328063853056

Epoch: 6| Step: 5
Training loss: 1.531762173690971
Validation loss: 2.5284856450223616

Epoch: 6| Step: 6
Training loss: 2.4270476200821616
Validation loss: 2.5220291412025175

Epoch: 6| Step: 7
Training loss: 1.9013105716123107
Validation loss: 2.535886011954405

Epoch: 6| Step: 8
Training loss: 2.007046920934952
Validation loss: 2.5149004664863805

Epoch: 6| Step: 9
Training loss: 2.52179260497466
Validation loss: 2.513012368512433

Epoch: 6| Step: 10
Training loss: 3.3038874530234974
Validation loss: 2.511551846999809

Epoch: 6| Step: 11
Training loss: 1.6772505714323418
Validation loss: 2.5087311231773812

Epoch: 6| Step: 12
Training loss: 2.547273195182644
Validation loss: 2.5312042389175105

Epoch: 6| Step: 13
Training loss: 1.6319935766448976
Validation loss: 2.525736813321982

Epoch: 303| Step: 0
Training loss: 2.2252851067801447
Validation loss: 2.596943585912773

Epoch: 6| Step: 1
Training loss: 1.3981447819217097
Validation loss: 2.597813146915307

Epoch: 6| Step: 2
Training loss: 2.386413554705733
Validation loss: 2.6315168896267855

Epoch: 6| Step: 3
Training loss: 1.744908555703517
Validation loss: 2.636164582968236

Epoch: 6| Step: 4
Training loss: 2.597119085085291
Validation loss: 2.631227055537929

Epoch: 6| Step: 5
Training loss: 2.4417515380829533
Validation loss: 2.5808274410460967

Epoch: 6| Step: 6
Training loss: 1.7137758583883715
Validation loss: 2.5739242084196023

Epoch: 6| Step: 7
Training loss: 1.948105121274927
Validation loss: 2.5490440306439273

Epoch: 6| Step: 8
Training loss: 2.6616278567636744
Validation loss: 2.544296956912463

Epoch: 6| Step: 9
Training loss: 1.8760867466259332
Validation loss: 2.5412625528311064

Epoch: 6| Step: 10
Training loss: 2.620902723921061
Validation loss: 2.5260978823564475

Epoch: 6| Step: 11
Training loss: 1.9444590462030409
Validation loss: 2.496902279153766

Epoch: 6| Step: 12
Training loss: 2.4397779726413904
Validation loss: 2.5038542045306222

Epoch: 6| Step: 13
Training loss: 1.53898380291343
Validation loss: 2.4903675158443948

Epoch: 304| Step: 0
Training loss: 2.089396263057726
Validation loss: 2.5223333661503835

Epoch: 6| Step: 1
Training loss: 1.891660044430248
Validation loss: 2.5121043271695354

Epoch: 6| Step: 2
Training loss: 1.4115401897647715
Validation loss: 2.5326539686771166

Epoch: 6| Step: 3
Training loss: 1.5640502106053231
Validation loss: 2.555472390461786

Epoch: 6| Step: 4
Training loss: 2.546397158490704
Validation loss: 2.580724342154347

Epoch: 6| Step: 5
Training loss: 2.409222636866352
Validation loss: 2.5667581766915473

Epoch: 6| Step: 6
Training loss: 2.333828691852733
Validation loss: 2.5797620411729336

Epoch: 6| Step: 7
Training loss: 1.8688497127607957
Validation loss: 2.6041241807650835

Epoch: 6| Step: 8
Training loss: 2.626543953380199
Validation loss: 2.5858175474622

Epoch: 6| Step: 9
Training loss: 1.906712960479282
Validation loss: 2.553381801033994

Epoch: 6| Step: 10
Training loss: 2.9102871654173357
Validation loss: 2.5500339349969496

Epoch: 6| Step: 11
Training loss: 1.9086561807234925
Validation loss: 2.5311013480284617

Epoch: 6| Step: 12
Training loss: 2.1023014853945052
Validation loss: 2.5733613056019777

Epoch: 6| Step: 13
Training loss: 1.9074728748597727
Validation loss: 2.5747103185576634

Epoch: 305| Step: 0
Training loss: 1.8846832731765968
Validation loss: 2.585075334573979

Epoch: 6| Step: 1
Training loss: 2.4464939176326745
Validation loss: 2.578884590841482

Epoch: 6| Step: 2
Training loss: 1.430317390805251
Validation loss: 2.557444314745084

Epoch: 6| Step: 3
Training loss: 2.7018228382279106
Validation loss: 2.571842144261461

Epoch: 6| Step: 4
Training loss: 2.3802343209904873
Validation loss: 2.5553582076107637

Epoch: 6| Step: 5
Training loss: 1.2926104645590115
Validation loss: 2.5698861770558765

Epoch: 6| Step: 6
Training loss: 2.3932096185117606
Validation loss: 2.545795672232293

Epoch: 6| Step: 7
Training loss: 2.086999744161198
Validation loss: 2.5407480445460675

Epoch: 6| Step: 8
Training loss: 1.8877870050965304
Validation loss: 2.5635545313043586

Epoch: 6| Step: 9
Training loss: 1.9341178414974058
Validation loss: 2.55646357495184

Epoch: 6| Step: 10
Training loss: 2.7663885237204777
Validation loss: 2.5611767337287032

Epoch: 6| Step: 11
Training loss: 2.0168927368102887
Validation loss: 2.5381094527956285

Epoch: 6| Step: 12
Training loss: 2.259787464613296
Validation loss: 2.5653673272600153

Epoch: 6| Step: 13
Training loss: 1.9851287851907051
Validation loss: 2.563207063586733

Epoch: 306| Step: 0
Training loss: 2.4512928723871044
Validation loss: 2.5656005120977006

Epoch: 6| Step: 1
Training loss: 2.0026130295761155
Validation loss: 2.5412289966991866

Epoch: 6| Step: 2
Training loss: 1.7789170899393874
Validation loss: 2.5601257862540407

Epoch: 6| Step: 3
Training loss: 1.8745261547251175
Validation loss: 2.5239982178848512

Epoch: 6| Step: 4
Training loss: 1.7581290405096823
Validation loss: 2.552141746838608

Epoch: 6| Step: 5
Training loss: 2.2768866209434644
Validation loss: 2.539595781712512

Epoch: 6| Step: 6
Training loss: 2.4855666271757597
Validation loss: 2.5500387656313257

Epoch: 6| Step: 7
Training loss: 1.8181162014955212
Validation loss: 2.563719932023967

Epoch: 6| Step: 8
Training loss: 1.7269888649180056
Validation loss: 2.6011997462582688

Epoch: 6| Step: 9
Training loss: 2.914072481603632
Validation loss: 2.6013353342152534

Epoch: 6| Step: 10
Training loss: 2.184909267331192
Validation loss: 2.6373872338123685

Epoch: 6| Step: 11
Training loss: 2.0541984643338584
Validation loss: 2.62555258853483

Epoch: 6| Step: 12
Training loss: 2.533003964679686
Validation loss: 2.5796261357095145

Epoch: 6| Step: 13
Training loss: 2.3637910655553127
Validation loss: 2.548432386912805

Epoch: 307| Step: 0
Training loss: 2.2845889177891308
Validation loss: 2.508571204970532

Epoch: 6| Step: 1
Training loss: 2.4514929329390784
Validation loss: 2.5160850909752788

Epoch: 6| Step: 2
Training loss: 1.7872245042748323
Validation loss: 2.5073094323900667

Epoch: 6| Step: 3
Training loss: 1.9869800799273138
Validation loss: 2.51993516942045

Epoch: 6| Step: 4
Training loss: 2.1182691900634976
Validation loss: 2.504384281352912

Epoch: 6| Step: 5
Training loss: 2.053913043022893
Validation loss: 2.5141978984288387

Epoch: 6| Step: 6
Training loss: 2.54721338563378
Validation loss: 2.5159195279340385

Epoch: 6| Step: 7
Training loss: 2.4666449348248465
Validation loss: 2.5119966834718634

Epoch: 6| Step: 8
Training loss: 2.442473985265999
Validation loss: 2.519109898704803

Epoch: 6| Step: 9
Training loss: 1.8404744680924523
Validation loss: 2.5122240664661732

Epoch: 6| Step: 10
Training loss: 1.9631534533304427
Validation loss: 2.4929773719261537

Epoch: 6| Step: 11
Training loss: 1.9835218262525716
Validation loss: 2.4940659350765197

Epoch: 6| Step: 12
Training loss: 2.0873754452762534
Validation loss: 2.5133672972828753

Epoch: 6| Step: 13
Training loss: 2.6199492956307426
Validation loss: 2.519152614324228

Epoch: 308| Step: 0
Training loss: 2.174826832158811
Validation loss: 2.544855124241515

Epoch: 6| Step: 1
Training loss: 1.8450168201537867
Validation loss: 2.551760428624759

Epoch: 6| Step: 2
Training loss: 1.8019456388167914
Validation loss: 2.55479654901826

Epoch: 6| Step: 3
Training loss: 1.4174647420706548
Validation loss: 2.5563591359414297

Epoch: 6| Step: 4
Training loss: 2.576811207183608
Validation loss: 2.534382894670676

Epoch: 6| Step: 5
Training loss: 2.4985904534657917
Validation loss: 2.572005976898898

Epoch: 6| Step: 6
Training loss: 2.4184114362152886
Validation loss: 2.545169469890492

Epoch: 6| Step: 7
Training loss: 2.714726419452005
Validation loss: 2.5100777161105823

Epoch: 6| Step: 8
Training loss: 1.8134632839359714
Validation loss: 2.478174417074362

Epoch: 6| Step: 9
Training loss: 2.0649293406222635
Validation loss: 2.478067191669555

Epoch: 6| Step: 10
Training loss: 2.6300905912628774
Validation loss: 2.481562367850672

Epoch: 6| Step: 11
Training loss: 1.7332343397237735
Validation loss: 2.4814814064896775

Epoch: 6| Step: 12
Training loss: 1.9528921980396938
Validation loss: 2.4849820864778205

Epoch: 6| Step: 13
Training loss: 2.1589509936906763
Validation loss: 2.474773189799937

Epoch: 309| Step: 0
Training loss: 2.1862461311214494
Validation loss: 2.4810244280745066

Epoch: 6| Step: 1
Training loss: 1.9673689585068899
Validation loss: 2.4770436747087015

Epoch: 6| Step: 2
Training loss: 2.3279732264260566
Validation loss: 2.497038565423799

Epoch: 6| Step: 3
Training loss: 2.8599654458366093
Validation loss: 2.501068522669114

Epoch: 6| Step: 4
Training loss: 1.9508962503374414
Validation loss: 2.4932217898212223

Epoch: 6| Step: 5
Training loss: 1.951671211873709
Validation loss: 2.5224986499975577

Epoch: 6| Step: 6
Training loss: 1.9278854419143752
Validation loss: 2.538578820742607

Epoch: 6| Step: 7
Training loss: 1.9244872537390516
Validation loss: 2.5480211171543212

Epoch: 6| Step: 8
Training loss: 1.874064148365776
Validation loss: 2.5345779017872525

Epoch: 6| Step: 9
Training loss: 2.444119000685965
Validation loss: 2.5266804205420312

Epoch: 6| Step: 10
Training loss: 2.408336378929386
Validation loss: 2.5312514834929463

Epoch: 6| Step: 11
Training loss: 2.29289981147033
Validation loss: 2.5251723350281847

Epoch: 6| Step: 12
Training loss: 1.8165890837502132
Validation loss: 2.521634949104168

Epoch: 6| Step: 13
Training loss: 2.3294365791879246
Validation loss: 2.4976594936241208

Epoch: 310| Step: 0
Training loss: 1.911453898439451
Validation loss: 2.5591579446133648

Epoch: 6| Step: 1
Training loss: 2.3901629032497023
Validation loss: 2.5145669453573345

Epoch: 6| Step: 2
Training loss: 2.207742060072847
Validation loss: 2.5119235369075996

Epoch: 6| Step: 3
Training loss: 1.877677658554528
Validation loss: 2.532100236426271

Epoch: 6| Step: 4
Training loss: 1.688162073309461
Validation loss: 2.525521456188068

Epoch: 6| Step: 5
Training loss: 1.7327406459870136
Validation loss: 2.521302129697979

Epoch: 6| Step: 6
Training loss: 2.3363770546610474
Validation loss: 2.543527661853468

Epoch: 6| Step: 7
Training loss: 2.1818805996318416
Validation loss: 2.5368938790128177

Epoch: 6| Step: 8
Training loss: 2.8384537896135433
Validation loss: 2.5627683948668785

Epoch: 6| Step: 9
Training loss: 2.186649702207927
Validation loss: 2.614688823035946

Epoch: 6| Step: 10
Training loss: 2.0589473066067177
Validation loss: 2.6348235828763698

Epoch: 6| Step: 11
Training loss: 2.43038292650224
Validation loss: 2.6374393787618855

Epoch: 6| Step: 12
Training loss: 2.0272567230538394
Validation loss: 2.6412854845221245

Epoch: 6| Step: 13
Training loss: 2.1288589892259893
Validation loss: 2.6179840242264154

Epoch: 311| Step: 0
Training loss: 2.342472592970069
Validation loss: 2.5449546485912133

Epoch: 6| Step: 1
Training loss: 2.2798993018148885
Validation loss: 2.4907832240218957

Epoch: 6| Step: 2
Training loss: 1.6112886181236357
Validation loss: 2.5119988348091566

Epoch: 6| Step: 3
Training loss: 1.7804064175255496
Validation loss: 2.5099727005886128

Epoch: 6| Step: 4
Training loss: 1.561519162361252
Validation loss: 2.506246963461085

Epoch: 6| Step: 5
Training loss: 3.0264755874624774
Validation loss: 2.514638340013101

Epoch: 6| Step: 6
Training loss: 2.9634559408883447
Validation loss: 2.5076100870842013

Epoch: 6| Step: 7
Training loss: 2.0415613056426363
Validation loss: 2.513316016904875

Epoch: 6| Step: 8
Training loss: 2.6855007098304777
Validation loss: 2.5092597025998225

Epoch: 6| Step: 9
Training loss: 2.1027777465905415
Validation loss: 2.5092982469271883

Epoch: 6| Step: 10
Training loss: 2.6497907304006088
Validation loss: 2.514394012715591

Epoch: 6| Step: 11
Training loss: 1.798268847341953
Validation loss: 2.5126464933893065

Epoch: 6| Step: 12
Training loss: 1.7733850681435634
Validation loss: 2.564833113909445

Epoch: 6| Step: 13
Training loss: 1.6180350621153106
Validation loss: 2.5846965228463534

Epoch: 312| Step: 0
Training loss: 2.033738709777743
Validation loss: 2.6426445425652334

Epoch: 6| Step: 1
Training loss: 1.8937454953785315
Validation loss: 2.6306147849900525

Epoch: 6| Step: 2
Training loss: 2.901015623422057
Validation loss: 2.5708501576182776

Epoch: 6| Step: 3
Training loss: 2.6666218833341855
Validation loss: 2.590859192500036

Epoch: 6| Step: 4
Training loss: 1.7554622960704125
Validation loss: 2.542151230340567

Epoch: 6| Step: 5
Training loss: 2.2517276065390974
Validation loss: 2.5309141430740842

Epoch: 6| Step: 6
Training loss: 1.9388836872731814
Validation loss: 2.48135233683264

Epoch: 6| Step: 7
Training loss: 1.9439859424914812
Validation loss: 2.4851672270939242

Epoch: 6| Step: 8
Training loss: 1.8112953392024864
Validation loss: 2.483005218036406

Epoch: 6| Step: 9
Training loss: 2.2375873868276486
Validation loss: 2.502185374986739

Epoch: 6| Step: 10
Training loss: 2.2777815278598754
Validation loss: 2.488949592617345

Epoch: 6| Step: 11
Training loss: 2.7448135365453936
Validation loss: 2.506717954028086

Epoch: 6| Step: 12
Training loss: 1.8340881123316803
Validation loss: 2.5246029299260706

Epoch: 6| Step: 13
Training loss: 1.2935984942048226
Validation loss: 2.52440431889339

Epoch: 313| Step: 0
Training loss: 2.3829455729362894
Validation loss: 2.5759895188827215

Epoch: 6| Step: 1
Training loss: 1.9935151706268526
Validation loss: 2.5787416125340044

Epoch: 6| Step: 2
Training loss: 1.722243763505218
Validation loss: 2.6085658693913425

Epoch: 6| Step: 3
Training loss: 2.3744652798673243
Validation loss: 2.560139739846976

Epoch: 6| Step: 4
Training loss: 2.3078275335257423
Validation loss: 2.616292179750031

Epoch: 6| Step: 5
Training loss: 2.1615787947458163
Validation loss: 2.5918055526791273

Epoch: 6| Step: 6
Training loss: 2.5830622705152453
Validation loss: 2.5895789132319624

Epoch: 6| Step: 7
Training loss: 1.6996770131200907
Validation loss: 2.5698002437164416

Epoch: 6| Step: 8
Training loss: 2.2470071809430685
Validation loss: 2.5323122880211892

Epoch: 6| Step: 9
Training loss: 1.6161891048374304
Validation loss: 2.5003297429379603

Epoch: 6| Step: 10
Training loss: 2.571756160396074
Validation loss: 2.4942339683278263

Epoch: 6| Step: 11
Training loss: 2.3832247017954575
Validation loss: 2.4855019914210716

Epoch: 6| Step: 12
Training loss: 1.9017622605328874
Validation loss: 2.464411500651929

Epoch: 6| Step: 13
Training loss: 2.0241681403632024
Validation loss: 2.466829381765314

Epoch: 314| Step: 0
Training loss: 1.6081614687446824
Validation loss: 2.4741953097165497

Epoch: 6| Step: 1
Training loss: 1.920070390205715
Validation loss: 2.4860601408106398

Epoch: 6| Step: 2
Training loss: 2.5391800603793975
Validation loss: 2.4916561760144655

Epoch: 6| Step: 3
Training loss: 1.9517781000334078
Validation loss: 2.487619133273785

Epoch: 6| Step: 4
Training loss: 1.4561167447267687
Validation loss: 2.5251892591749043

Epoch: 6| Step: 5
Training loss: 1.9067814820850246
Validation loss: 2.532807926438203

Epoch: 6| Step: 6
Training loss: 2.389816646166589
Validation loss: 2.5430750358312757

Epoch: 6| Step: 7
Training loss: 1.8094436922359078
Validation loss: 2.537015463383329

Epoch: 6| Step: 8
Training loss: 2.30671494095329
Validation loss: 2.55004866061188

Epoch: 6| Step: 9
Training loss: 2.655392317585205
Validation loss: 2.5356454401757147

Epoch: 6| Step: 10
Training loss: 1.9890867149395348
Validation loss: 2.562753253920685

Epoch: 6| Step: 11
Training loss: 2.168650696869309
Validation loss: 2.5333533006015045

Epoch: 6| Step: 12
Training loss: 3.1871888251909195
Validation loss: 2.545087737199273

Epoch: 6| Step: 13
Training loss: 2.0245401920051354
Validation loss: 2.575654150145197

Epoch: 315| Step: 0
Training loss: 2.00103744779106
Validation loss: 2.5494096932899435

Epoch: 6| Step: 1
Training loss: 2.3608257557587673
Validation loss: 2.5810702368308425

Epoch: 6| Step: 2
Training loss: 2.5136041520961605
Validation loss: 2.5802544632937052

Epoch: 6| Step: 3
Training loss: 1.8755381765484471
Validation loss: 2.5683779407598935

Epoch: 6| Step: 4
Training loss: 2.1075793500014974
Validation loss: 2.607191714297458

Epoch: 6| Step: 5
Training loss: 1.890171091116523
Validation loss: 2.5826455144024214

Epoch: 6| Step: 6
Training loss: 2.450353429564611
Validation loss: 2.5692557623608274

Epoch: 6| Step: 7
Training loss: 2.1411702373588986
Validation loss: 2.549787802063828

Epoch: 6| Step: 8
Training loss: 1.5698097904663542
Validation loss: 2.5491823225568373

Epoch: 6| Step: 9
Training loss: 1.9252971172167137
Validation loss: 2.531724469335115

Epoch: 6| Step: 10
Training loss: 1.9736746095122668
Validation loss: 2.519508807257321

Epoch: 6| Step: 11
Training loss: 2.3791768338263997
Validation loss: 2.518795739982023

Epoch: 6| Step: 12
Training loss: 2.149636783525632
Validation loss: 2.5094874285970636

Epoch: 6| Step: 13
Training loss: 2.3905278603758022
Validation loss: 2.5043646858446578

Epoch: 316| Step: 0
Training loss: 2.1766319597913215
Validation loss: 2.4830044018648407

Epoch: 6| Step: 1
Training loss: 2.0046601838460685
Validation loss: 2.4837560782432577

Epoch: 6| Step: 2
Training loss: 1.9049115093834523
Validation loss: 2.4850067519026484

Epoch: 6| Step: 3
Training loss: 2.5290044549229287
Validation loss: 2.4845495742465333

Epoch: 6| Step: 4
Training loss: 2.115992585426998
Validation loss: 2.4722599075483527

Epoch: 6| Step: 5
Training loss: 1.945546699122274
Validation loss: 2.4892911273996217

Epoch: 6| Step: 6
Training loss: 2.144546592115544
Validation loss: 2.5402726795981265

Epoch: 6| Step: 7
Training loss: 1.6292795169832153
Validation loss: 2.501106470347006

Epoch: 6| Step: 8
Training loss: 2.7592646852174907
Validation loss: 2.5286432744860186

Epoch: 6| Step: 9
Training loss: 1.7350235147559185
Validation loss: 2.483984686622574

Epoch: 6| Step: 10
Training loss: 1.464170743834902
Validation loss: 2.4934525184100966

Epoch: 6| Step: 11
Training loss: 2.7881466513201163
Validation loss: 2.4915557188085873

Epoch: 6| Step: 12
Training loss: 1.9308874438061359
Validation loss: 2.491601474466223

Epoch: 6| Step: 13
Training loss: 2.417812952497898
Validation loss: 2.4849519199706536

Epoch: 317| Step: 0
Training loss: 1.8741135091043244
Validation loss: 2.478968289129271

Epoch: 6| Step: 1
Training loss: 1.959516762893668
Validation loss: 2.5090303721976

Epoch: 6| Step: 2
Training loss: 2.3605123645835984
Validation loss: 2.532047381610089

Epoch: 6| Step: 3
Training loss: 2.0670822566569846
Validation loss: 2.5346746707328682

Epoch: 6| Step: 4
Training loss: 2.563070466345805
Validation loss: 2.538652592362865

Epoch: 6| Step: 5
Training loss: 2.150554044440428
Validation loss: 2.551896603558478

Epoch: 6| Step: 6
Training loss: 2.38453786951167
Validation loss: 2.569627618417855

Epoch: 6| Step: 7
Training loss: 1.624061533560804
Validation loss: 2.536465080194815

Epoch: 6| Step: 8
Training loss: 2.7849781894343444
Validation loss: 2.5479422987248808

Epoch: 6| Step: 9
Training loss: 1.9914507532066943
Validation loss: 2.5345324359603567

Epoch: 6| Step: 10
Training loss: 1.838712891412332
Validation loss: 2.524427678300845

Epoch: 6| Step: 11
Training loss: 2.286447118037936
Validation loss: 2.5226217551662518

Epoch: 6| Step: 12
Training loss: 1.9467216810961712
Validation loss: 2.531020581873005

Epoch: 6| Step: 13
Training loss: 1.3607491749430365
Validation loss: 2.517770890539977

Epoch: 318| Step: 0
Training loss: 1.5459716933744576
Validation loss: 2.5324520349557664

Epoch: 6| Step: 1
Training loss: 1.9171880621003785
Validation loss: 2.539059010038667

Epoch: 6| Step: 2
Training loss: 1.529605683271073
Validation loss: 2.5375574590882946

Epoch: 6| Step: 3
Training loss: 2.047755161357602
Validation loss: 2.545969796360415

Epoch: 6| Step: 4
Training loss: 1.981607203969693
Validation loss: 2.558051326028501

Epoch: 6| Step: 5
Training loss: 1.9933180051020738
Validation loss: 2.568448071706931

Epoch: 6| Step: 6
Training loss: 1.7694524280095845
Validation loss: 2.556565911406121

Epoch: 6| Step: 7
Training loss: 1.6178780523396785
Validation loss: 2.573438079345984

Epoch: 6| Step: 8
Training loss: 2.7367922316478035
Validation loss: 2.563412356586809

Epoch: 6| Step: 9
Training loss: 2.451600591243275
Validation loss: 2.586581101091989

Epoch: 6| Step: 10
Training loss: 2.0536578829556373
Validation loss: 2.5933643651869165

Epoch: 6| Step: 11
Training loss: 2.0229477455378717
Validation loss: 2.6119452969049806

Epoch: 6| Step: 12
Training loss: 2.358265091500693
Validation loss: 2.6094909078777437

Epoch: 6| Step: 13
Training loss: 3.236884870968956
Validation loss: 2.594516717429173

Epoch: 319| Step: 0
Training loss: 2.0337119807820296
Validation loss: 2.6152193022966195

Epoch: 6| Step: 1
Training loss: 2.1607606673413744
Validation loss: 2.688681394563961

Epoch: 6| Step: 2
Training loss: 2.9518187525242645
Validation loss: 2.7191307707402816

Epoch: 6| Step: 3
Training loss: 2.154104077175747
Validation loss: 2.6849240370316494

Epoch: 6| Step: 4
Training loss: 2.746515146755062
Validation loss: 2.6454854170765563

Epoch: 6| Step: 5
Training loss: 2.1619538868971797
Validation loss: 2.590995336919289

Epoch: 6| Step: 6
Training loss: 2.266893544716781
Validation loss: 2.5380235786404874

Epoch: 6| Step: 7
Training loss: 2.309217855968389
Validation loss: 2.5180152136807914

Epoch: 6| Step: 8
Training loss: 2.377187023080051
Validation loss: 2.557433057762236

Epoch: 6| Step: 9
Training loss: 2.2505077213069296
Validation loss: 2.5613069625832736

Epoch: 6| Step: 10
Training loss: 1.732258648155317
Validation loss: 2.5576087977740403

Epoch: 6| Step: 11
Training loss: 1.756414985373712
Validation loss: 2.542699280977577

Epoch: 6| Step: 12
Training loss: 2.2606837617315345
Validation loss: 2.5548234255966054

Epoch: 6| Step: 13
Training loss: 1.7711085685308616
Validation loss: 2.5470918278360357

Epoch: 320| Step: 0
Training loss: 1.6179445862634976
Validation loss: 2.5360513839800833

Epoch: 6| Step: 1
Training loss: 2.3561885107299254
Validation loss: 2.5338036328589317

Epoch: 6| Step: 2
Training loss: 2.379315320752768
Validation loss: 2.5301558873245753

Epoch: 6| Step: 3
Training loss: 1.4201985631383502
Validation loss: 2.537905401032522

Epoch: 6| Step: 4
Training loss: 1.6953548303057
Validation loss: 2.5367601803833817

Epoch: 6| Step: 5
Training loss: 2.1366702114359493
Validation loss: 2.566242199226436

Epoch: 6| Step: 6
Training loss: 2.3869373077866354
Validation loss: 2.530769726436781

Epoch: 6| Step: 7
Training loss: 1.6100526142408451
Validation loss: 2.5385542297261123

Epoch: 6| Step: 8
Training loss: 2.432008376903914
Validation loss: 2.5496505248501835

Epoch: 6| Step: 9
Training loss: 2.34790575983402
Validation loss: 2.5604512468138876

Epoch: 6| Step: 10
Training loss: 1.8367982185984821
Validation loss: 2.5802169789392857

Epoch: 6| Step: 11
Training loss: 2.0220997044311746
Validation loss: 2.5829476612108513

Epoch: 6| Step: 12
Training loss: 2.540808725693515
Validation loss: 2.6086094812659737

Epoch: 6| Step: 13
Training loss: 2.449321154532821
Validation loss: 2.5768920878873005

Epoch: 321| Step: 0
Training loss: 2.666168365015674
Validation loss: 2.550416913576015

Epoch: 6| Step: 1
Training loss: 2.6289604827592346
Validation loss: 2.5279268341924683

Epoch: 6| Step: 2
Training loss: 2.097533039473889
Validation loss: 2.5159930953045797

Epoch: 6| Step: 3
Training loss: 2.5769201989272785
Validation loss: 2.50664046045142

Epoch: 6| Step: 4
Training loss: 2.110602579717868
Validation loss: 2.4856298544413242

Epoch: 6| Step: 5
Training loss: 2.2477286848555935
Validation loss: 2.527261550879439

Epoch: 6| Step: 6
Training loss: 1.2799964913677766
Validation loss: 2.502534789289127

Epoch: 6| Step: 7
Training loss: 1.9775189886133933
Validation loss: 2.5376091343253897

Epoch: 6| Step: 8
Training loss: 2.1991481735803005
Validation loss: 2.5419132837395724

Epoch: 6| Step: 9
Training loss: 1.8900898578011427
Validation loss: 2.5452422854966654

Epoch: 6| Step: 10
Training loss: 1.5344236533226332
Validation loss: 2.5557330419462954

Epoch: 6| Step: 11
Training loss: 1.6154263992285327
Validation loss: 2.556383959828444

Epoch: 6| Step: 12
Training loss: 1.4089900131683872
Validation loss: 2.540554074106406

Epoch: 6| Step: 13
Training loss: 2.3759839880561113
Validation loss: 2.570055530383569

Epoch: 322| Step: 0
Training loss: 2.8138982052370043
Validation loss: 2.571793598108956

Epoch: 6| Step: 1
Training loss: 1.6964500583635966
Validation loss: 2.568656472934456

Epoch: 6| Step: 2
Training loss: 1.9152402407396663
Validation loss: 2.5665941948588147

Epoch: 6| Step: 3
Training loss: 1.6013590613693
Validation loss: 2.5578514089947584

Epoch: 6| Step: 4
Training loss: 2.2685495377349536
Validation loss: 2.5375526360124736

Epoch: 6| Step: 5
Training loss: 1.1950807035001518
Validation loss: 2.5514744142463894

Epoch: 6| Step: 6
Training loss: 2.1274244278463827
Validation loss: 2.5261510504147444

Epoch: 6| Step: 7
Training loss: 1.403300434521271
Validation loss: 2.5489371908537644

Epoch: 6| Step: 8
Training loss: 2.0143575305755252
Validation loss: 2.5260477334700155

Epoch: 6| Step: 9
Training loss: 2.085477056654666
Validation loss: 2.5520387347210547

Epoch: 6| Step: 10
Training loss: 2.0686668909441357
Validation loss: 2.5479926872817202

Epoch: 6| Step: 11
Training loss: 1.9899322909428931
Validation loss: 2.561673767743499

Epoch: 6| Step: 12
Training loss: 2.4003910222996008
Validation loss: 2.5758351338961414

Epoch: 6| Step: 13
Training loss: 2.7924681314888553
Validation loss: 2.5778643697914605

Epoch: 323| Step: 0
Training loss: 1.9612685452247576
Validation loss: 2.5969094333439204

Epoch: 6| Step: 1
Training loss: 1.8356561972824819
Validation loss: 2.6136075411527906

Epoch: 6| Step: 2
Training loss: 2.391401775546594
Validation loss: 2.6304173351882993

Epoch: 6| Step: 3
Training loss: 1.9952150564514288
Validation loss: 2.6106779762830974

Epoch: 6| Step: 4
Training loss: 1.5221044723806934
Validation loss: 2.590749820881865

Epoch: 6| Step: 5
Training loss: 2.3157199402573108
Validation loss: 2.5913962442877487

Epoch: 6| Step: 6
Training loss: 1.312017442912941
Validation loss: 2.5779850469036703

Epoch: 6| Step: 7
Training loss: 2.4634363475866063
Validation loss: 2.5222179666512208

Epoch: 6| Step: 8
Training loss: 2.5265774397918497
Validation loss: 2.497086623497479

Epoch: 6| Step: 9
Training loss: 2.0565947177034523
Validation loss: 2.497626831275988

Epoch: 6| Step: 10
Training loss: 2.347602830936027
Validation loss: 2.507288124347166

Epoch: 6| Step: 11
Training loss: 2.292978731877762
Validation loss: 2.5184656063091975

Epoch: 6| Step: 12
Training loss: 2.2993233016958348
Validation loss: 2.5368422361972507

Epoch: 6| Step: 13
Training loss: 1.6577756081232549
Validation loss: 2.5507897400726898

Epoch: 324| Step: 0
Training loss: 1.7067759167949867
Validation loss: 2.5917357471332103

Epoch: 6| Step: 1
Training loss: 1.9783384765369605
Validation loss: 2.60924153548164

Epoch: 6| Step: 2
Training loss: 1.9712097907939428
Validation loss: 2.6006794329081124

Epoch: 6| Step: 3
Training loss: 1.7445283909392857
Validation loss: 2.6315721557763787

Epoch: 6| Step: 4
Training loss: 2.001924066100077
Validation loss: 2.6057697753263223

Epoch: 6| Step: 5
Training loss: 2.128211679807966
Validation loss: 2.578287508688215

Epoch: 6| Step: 6
Training loss: 2.099491275748332
Validation loss: 2.578219741467662

Epoch: 6| Step: 7
Training loss: 2.1928334204241335
Validation loss: 2.53736429399687

Epoch: 6| Step: 8
Training loss: 1.9884179448651922
Validation loss: 2.53941294281304

Epoch: 6| Step: 9
Training loss: 2.364744531007511
Validation loss: 2.5266822133890248

Epoch: 6| Step: 10
Training loss: 2.266565798403755
Validation loss: 2.5103457640030835

Epoch: 6| Step: 11
Training loss: 1.8470659341242914
Validation loss: 2.479000347766798

Epoch: 6| Step: 12
Training loss: 2.5013353596105006
Validation loss: 2.5091278651225295

Epoch: 6| Step: 13
Training loss: 1.9746989636421237
Validation loss: 2.4737458201368736

Epoch: 325| Step: 0
Training loss: 2.022482628293872
Validation loss: 2.481805364175734

Epoch: 6| Step: 1
Training loss: 2.3854545579146915
Validation loss: 2.4752457063262225

Epoch: 6| Step: 2
Training loss: 2.0679949762737118
Validation loss: 2.4846247741409453

Epoch: 6| Step: 3
Training loss: 1.9903711753003028
Validation loss: 2.4848787288893974

Epoch: 6| Step: 4
Training loss: 2.2765749750993343
Validation loss: 2.507070160164908

Epoch: 6| Step: 5
Training loss: 1.5354537869663092
Validation loss: 2.5055145081862755

Epoch: 6| Step: 6
Training loss: 1.9385974606112353
Validation loss: 2.5232048911643328

Epoch: 6| Step: 7
Training loss: 2.234632570586248
Validation loss: 2.5830952985883338

Epoch: 6| Step: 8
Training loss: 1.6364221417921052
Validation loss: 2.585404539937964

Epoch: 6| Step: 9
Training loss: 2.84712337746176
Validation loss: 2.574922935172119

Epoch: 6| Step: 10
Training loss: 2.395484025341794
Validation loss: 2.531955636337394

Epoch: 6| Step: 11
Training loss: 2.2861165433530464
Validation loss: 2.521127389408172

Epoch: 6| Step: 12
Training loss: 1.9901258384751224
Validation loss: 2.4933554883047395

Epoch: 6| Step: 13
Training loss: 1.8054571450956955
Validation loss: 2.473729756821661

Epoch: 326| Step: 0
Training loss: 2.299500087644306
Validation loss: 2.485098327646062

Epoch: 6| Step: 1
Training loss: 2.3231329938347174
Validation loss: 2.490484933651982

Epoch: 6| Step: 2
Training loss: 1.9782053637338433
Validation loss: 2.498491698490928

Epoch: 6| Step: 3
Training loss: 1.591990528145605
Validation loss: 2.4622376736304536

Epoch: 6| Step: 4
Training loss: 2.0231249947204684
Validation loss: 2.502446344634355

Epoch: 6| Step: 5
Training loss: 1.4175859255036052
Validation loss: 2.489090297405664

Epoch: 6| Step: 6
Training loss: 1.9649886879825889
Validation loss: 2.4803101977039295

Epoch: 6| Step: 7
Training loss: 1.6143136404252694
Validation loss: 2.5335617497850644

Epoch: 6| Step: 8
Training loss: 1.992881265153424
Validation loss: 2.528057958517956

Epoch: 6| Step: 9
Training loss: 2.18859399959617
Validation loss: 2.6040170677449006

Epoch: 6| Step: 10
Training loss: 2.685863440148888
Validation loss: 2.600034568630175

Epoch: 6| Step: 11
Training loss: 2.733810628141077
Validation loss: 2.592531569143688

Epoch: 6| Step: 12
Training loss: 2.0406415532654365
Validation loss: 2.555780921434291

Epoch: 6| Step: 13
Training loss: 2.28688440429889
Validation loss: 2.557602847266539

Epoch: 327| Step: 0
Training loss: 2.038605035788777
Validation loss: 2.5397864458966417

Epoch: 6| Step: 1
Training loss: 2.2520823908923564
Validation loss: 2.561446430746945

Epoch: 6| Step: 2
Training loss: 2.0058661500691937
Validation loss: 2.5502667300029525

Epoch: 6| Step: 3
Training loss: 2.2275705297673274
Validation loss: 2.5531372826419694

Epoch: 6| Step: 4
Training loss: 2.0514182418459956
Validation loss: 2.543966969540033

Epoch: 6| Step: 5
Training loss: 2.0871653853991305
Validation loss: 2.5439983106133712

Epoch: 6| Step: 6
Training loss: 1.906474553624452
Validation loss: 2.531757570718665

Epoch: 6| Step: 7
Training loss: 1.3750334648915035
Validation loss: 2.5106080379329354

Epoch: 6| Step: 8
Training loss: 1.735651525913577
Validation loss: 2.5259545432465993

Epoch: 6| Step: 9
Training loss: 2.3220605912102528
Validation loss: 2.53212341498667

Epoch: 6| Step: 10
Training loss: 2.192954320693645
Validation loss: 2.564657528070256

Epoch: 6| Step: 11
Training loss: 2.328527838142669
Validation loss: 2.5458495058918507

Epoch: 6| Step: 12
Training loss: 2.0690630903475076
Validation loss: 2.583949036187159

Epoch: 6| Step: 13
Training loss: 2.3042436592616586
Validation loss: 2.6098591703662666

Epoch: 328| Step: 0
Training loss: 2.008209308050076
Validation loss: 2.62716325300013

Epoch: 6| Step: 1
Training loss: 2.60810903574018
Validation loss: 2.630729492727222

Epoch: 6| Step: 2
Training loss: 1.5395560465637048
Validation loss: 2.6518175579787235

Epoch: 6| Step: 3
Training loss: 1.5537602712302472
Validation loss: 2.604380794622757

Epoch: 6| Step: 4
Training loss: 2.2066545283088397
Validation loss: 2.5672671240115585

Epoch: 6| Step: 5
Training loss: 2.5538567641800594
Validation loss: 2.533113272629039

Epoch: 6| Step: 6
Training loss: 1.4987211338855375
Validation loss: 2.558781103986523

Epoch: 6| Step: 7
Training loss: 1.6940300657133123
Validation loss: 2.5337932196432837

Epoch: 6| Step: 8
Training loss: 2.040546330429583
Validation loss: 2.529943497922726

Epoch: 6| Step: 9
Training loss: 1.5703875775205882
Validation loss: 2.5382408181920546

Epoch: 6| Step: 10
Training loss: 2.1517273285004817
Validation loss: 2.554468516881229

Epoch: 6| Step: 11
Training loss: 2.522550161144615
Validation loss: 2.554150065004577

Epoch: 6| Step: 12
Training loss: 2.5191818586474612
Validation loss: 2.536705613403329

Epoch: 6| Step: 13
Training loss: 2.125196784388563
Validation loss: 2.5421550013225906

Epoch: 329| Step: 0
Training loss: 2.62094757081782
Validation loss: 2.5854800339238135

Epoch: 6| Step: 1
Training loss: 2.0230463894528405
Validation loss: 2.5688160692119646

Epoch: 6| Step: 2
Training loss: 1.8134016885332438
Validation loss: 2.5357210052396084

Epoch: 6| Step: 3
Training loss: 2.572703817317614
Validation loss: 2.5208115905160313

Epoch: 6| Step: 4
Training loss: 2.4146239976418262
Validation loss: 2.5125184553490234

Epoch: 6| Step: 5
Training loss: 1.0735753577495573
Validation loss: 2.5036581851873296

Epoch: 6| Step: 6
Training loss: 1.8471671943148653
Validation loss: 2.516034410857947

Epoch: 6| Step: 7
Training loss: 1.808970797229768
Validation loss: 2.5117099854754903

Epoch: 6| Step: 8
Training loss: 1.376987494722871
Validation loss: 2.5094639934564404

Epoch: 6| Step: 9
Training loss: 2.582190065794668
Validation loss: 2.52203033076044

Epoch: 6| Step: 10
Training loss: 2.0762168900928994
Validation loss: 2.5811132664214647

Epoch: 6| Step: 11
Training loss: 2.2038326344438337
Validation loss: 2.6128030214904645

Epoch: 6| Step: 12
Training loss: 2.666554468496654
Validation loss: 2.7233833352832724

Epoch: 6| Step: 13
Training loss: 1.7198420436542565
Validation loss: 2.7000535335649585

Epoch: 330| Step: 0
Training loss: 2.318458407182182
Validation loss: 2.6610788621012462

Epoch: 6| Step: 1
Training loss: 1.7963924921123928
Validation loss: 2.5764684267839337

Epoch: 6| Step: 2
Training loss: 2.0678744949979406
Validation loss: 2.5315360233416793

Epoch: 6| Step: 3
Training loss: 2.5351640557167485
Validation loss: 2.491911088528911

Epoch: 6| Step: 4
Training loss: 2.033893684136804
Validation loss: 2.507171691593645

Epoch: 6| Step: 5
Training loss: 2.217558204893356
Validation loss: 2.5136035355627446

Epoch: 6| Step: 6
Training loss: 1.7838169808700204
Validation loss: 2.525564315105859

Epoch: 6| Step: 7
Training loss: 1.910373792371747
Validation loss: 2.508848695205911

Epoch: 6| Step: 8
Training loss: 2.561975006660568
Validation loss: 2.5286744440557367

Epoch: 6| Step: 9
Training loss: 2.5053235593905927
Validation loss: 2.4949296715354112

Epoch: 6| Step: 10
Training loss: 1.763153980210327
Validation loss: 2.5075629992572144

Epoch: 6| Step: 11
Training loss: 1.6312078594742445
Validation loss: 2.5289162917748462

Epoch: 6| Step: 12
Training loss: 2.2950086211996275
Validation loss: 2.590772321352186

Epoch: 6| Step: 13
Training loss: 2.3003856791674524
Validation loss: 2.657182058727835

Epoch: 331| Step: 0
Training loss: 1.3267914303783175
Validation loss: 2.7142318218899435

Epoch: 6| Step: 1
Training loss: 2.5434969164569234
Validation loss: 2.6899332962841758

Epoch: 6| Step: 2
Training loss: 1.7671638466949446
Validation loss: 2.680692775181118

Epoch: 6| Step: 3
Training loss: 1.938907665676707
Validation loss: 2.68494306955062

Epoch: 6| Step: 4
Training loss: 2.1682770930783186
Validation loss: 2.6218980748006495

Epoch: 6| Step: 5
Training loss: 1.789917321027226
Validation loss: 2.532160716801219

Epoch: 6| Step: 6
Training loss: 2.734018531451875
Validation loss: 2.5038571563684657

Epoch: 6| Step: 7
Training loss: 2.1931326146834755
Validation loss: 2.5075055387086507

Epoch: 6| Step: 8
Training loss: 2.6323237205962013
Validation loss: 2.490127373684109

Epoch: 6| Step: 9
Training loss: 1.6858018878914882
Validation loss: 2.4868709893524636

Epoch: 6| Step: 10
Training loss: 2.259843698008495
Validation loss: 2.48070610292488

Epoch: 6| Step: 11
Training loss: 1.716243233663914
Validation loss: 2.4782302808425714

Epoch: 6| Step: 12
Training loss: 1.485424112708791
Validation loss: 2.4808751611853537

Epoch: 6| Step: 13
Training loss: 2.613765380901688
Validation loss: 2.5097842758811697

Epoch: 332| Step: 0
Training loss: 2.2519870037564362
Validation loss: 2.5491989548047385

Epoch: 6| Step: 1
Training loss: 2.075110062587184
Validation loss: 2.616369895952072

Epoch: 6| Step: 2
Training loss: 2.0700870031234166
Validation loss: 2.707291979983582

Epoch: 6| Step: 3
Training loss: 2.003512516714724
Validation loss: 2.7622779952611287

Epoch: 6| Step: 4
Training loss: 2.1990880029545816
Validation loss: 2.769999792211458

Epoch: 6| Step: 5
Training loss: 2.324995151637775
Validation loss: 2.7799542012318574

Epoch: 6| Step: 6
Training loss: 1.824446408689812
Validation loss: 2.713215862686823

Epoch: 6| Step: 7
Training loss: 2.479351218484305
Validation loss: 2.6837721260531557

Epoch: 6| Step: 8
Training loss: 2.239596581235042
Validation loss: 2.5661712182747407

Epoch: 6| Step: 9
Training loss: 2.4319196548616975
Validation loss: 2.484716875717223

Epoch: 6| Step: 10
Training loss: 1.6656947480962558
Validation loss: 2.525751554733644

Epoch: 6| Step: 11
Training loss: 1.933981869980452
Validation loss: 2.5342760561417372

Epoch: 6| Step: 12
Training loss: 2.634735491829865
Validation loss: 2.565988104987182

Epoch: 6| Step: 13
Training loss: 2.688314270153753
Validation loss: 2.5577450963396107

Epoch: 333| Step: 0
Training loss: 2.322953079918991
Validation loss: 2.5618678995843553

Epoch: 6| Step: 1
Training loss: 2.465500346660106
Validation loss: 2.54119526811821

Epoch: 6| Step: 2
Training loss: 2.05720800559637
Validation loss: 2.527041842210958

Epoch: 6| Step: 3
Training loss: 1.6870671176233163
Validation loss: 2.5092464874917986

Epoch: 6| Step: 4
Training loss: 1.6804767972007753
Validation loss: 2.5123357178228516

Epoch: 6| Step: 5
Training loss: 2.2591802025022107
Validation loss: 2.5055009719906636

Epoch: 6| Step: 6
Training loss: 2.8315584195803014
Validation loss: 2.5268935009340954

Epoch: 6| Step: 7
Training loss: 2.084796035999385
Validation loss: 2.5767631633063686

Epoch: 6| Step: 8
Training loss: 2.0721701295297477
Validation loss: 2.597759135797314

Epoch: 6| Step: 9
Training loss: 2.012002336087397
Validation loss: 2.6261377896293685

Epoch: 6| Step: 10
Training loss: 2.4073871056062033
Validation loss: 2.6467706316683715

Epoch: 6| Step: 11
Training loss: 1.991049407798112
Validation loss: 2.6789197201824497

Epoch: 6| Step: 12
Training loss: 1.592671496919823
Validation loss: 2.699259366191303

Epoch: 6| Step: 13
Training loss: 1.5096308363030726
Validation loss: 2.656727190724282

Epoch: 334| Step: 0
Training loss: 2.6011495176501076
Validation loss: 2.681987342730644

Epoch: 6| Step: 1
Training loss: 2.6783799965889696
Validation loss: 2.649481328552536

Epoch: 6| Step: 2
Training loss: 2.067877031518187
Validation loss: 2.610466780083835

Epoch: 6| Step: 3
Training loss: 2.192740674962057
Validation loss: 2.549902070726882

Epoch: 6| Step: 4
Training loss: 2.381060747450711
Validation loss: 2.520392565904987

Epoch: 6| Step: 5
Training loss: 2.0120759221004527
Validation loss: 2.5007073991034994

Epoch: 6| Step: 6
Training loss: 1.687602146024169
Validation loss: 2.487806170038269

Epoch: 6| Step: 7
Training loss: 1.9425913457614283
Validation loss: 2.4922583399543274

Epoch: 6| Step: 8
Training loss: 1.3351648338224975
Validation loss: 2.476962814308093

Epoch: 6| Step: 9
Training loss: 1.7227780392039136
Validation loss: 2.4871354032376454

Epoch: 6| Step: 10
Training loss: 1.690577420677493
Validation loss: 2.484660973874077

Epoch: 6| Step: 11
Training loss: 1.8396822783608429
Validation loss: 2.499670833534152

Epoch: 6| Step: 12
Training loss: 2.2817521261182527
Validation loss: 2.4785912885206582

Epoch: 6| Step: 13
Training loss: 2.252554608867491
Validation loss: 2.490405108015649

Epoch: 335| Step: 0
Training loss: 2.102015563457158
Validation loss: 2.4705352123030937

Epoch: 6| Step: 1
Training loss: 1.6009533723978475
Validation loss: 2.4677727934143734

Epoch: 6| Step: 2
Training loss: 1.8895512834359312
Validation loss: 2.492799928807293

Epoch: 6| Step: 3
Training loss: 1.8885056147331578
Validation loss: 2.484676330813815

Epoch: 6| Step: 4
Training loss: 1.8924826961114272
Validation loss: 2.5033719370016203

Epoch: 6| Step: 5
Training loss: 1.7029571450486694
Validation loss: 2.5005361379483335

Epoch: 6| Step: 6
Training loss: 2.9569065969742736
Validation loss: 2.5110255461952637

Epoch: 6| Step: 7
Training loss: 2.3018129169793426
Validation loss: 2.529577354089386

Epoch: 6| Step: 8
Training loss: 1.7791514834516242
Validation loss: 2.541309039694614

Epoch: 6| Step: 9
Training loss: 1.7440342715859423
Validation loss: 2.543053113374962

Epoch: 6| Step: 10
Training loss: 2.241577384428126
Validation loss: 2.54127390489845

Epoch: 6| Step: 11
Training loss: 2.408712934873002
Validation loss: 2.552467797313161

Epoch: 6| Step: 12
Training loss: 1.8352789813851627
Validation loss: 2.5509867018269916

Epoch: 6| Step: 13
Training loss: 1.738719550605899
Validation loss: 2.513901912159026

Epoch: 336| Step: 0
Training loss: 1.9442256970960905
Validation loss: 2.509973887944767

Epoch: 6| Step: 1
Training loss: 1.691998736983024
Validation loss: 2.516835965742018

Epoch: 6| Step: 2
Training loss: 2.863989603183565
Validation loss: 2.518247244663827

Epoch: 6| Step: 3
Training loss: 2.444394362784321
Validation loss: 2.4984704424809774

Epoch: 6| Step: 4
Training loss: 2.1593051220066877
Validation loss: 2.501557524606847

Epoch: 6| Step: 5
Training loss: 2.2244919100353004
Validation loss: 2.5054311250106314

Epoch: 6| Step: 6
Training loss: 1.915387874196285
Validation loss: 2.5100429673589004

Epoch: 6| Step: 7
Training loss: 1.605655705688097
Validation loss: 2.5022054322176124

Epoch: 6| Step: 8
Training loss: 2.459050693481196
Validation loss: 2.511310265341544

Epoch: 6| Step: 9
Training loss: 2.0878762368686887
Validation loss: 2.5259519633197987

Epoch: 6| Step: 10
Training loss: 2.2435386919494325
Validation loss: 2.527711585043372

Epoch: 6| Step: 11
Training loss: 2.0187740123726097
Validation loss: 2.570614937069228

Epoch: 6| Step: 12
Training loss: 1.2715396898370144
Validation loss: 2.5854233291093394

Epoch: 6| Step: 13
Training loss: 1.3935222234332876
Validation loss: 2.561161513555493

Epoch: 337| Step: 0
Training loss: 2.7048279794653367
Validation loss: 2.5927594832854837

Epoch: 6| Step: 1
Training loss: 1.8274079571257091
Validation loss: 2.5636526322222664

Epoch: 6| Step: 2
Training loss: 2.5796439580171286
Validation loss: 2.5484789300977755

Epoch: 6| Step: 3
Training loss: 2.1939058514739953
Validation loss: 2.5413039735590504

Epoch: 6| Step: 4
Training loss: 1.8832200111909194
Validation loss: 2.5314451856671747

Epoch: 6| Step: 5
Training loss: 2.2089095773352754
Validation loss: 2.496457451006826

Epoch: 6| Step: 6
Training loss: 2.2816916260377007
Validation loss: 2.489065656482382

Epoch: 6| Step: 7
Training loss: 1.432498357482288
Validation loss: 2.510479547707652

Epoch: 6| Step: 8
Training loss: 1.237843673841263
Validation loss: 2.502737438028755

Epoch: 6| Step: 9
Training loss: 2.145729383401363
Validation loss: 2.5027795201586116

Epoch: 6| Step: 10
Training loss: 1.930462021547739
Validation loss: 2.5013843279927657

Epoch: 6| Step: 11
Training loss: 1.473435254059877
Validation loss: 2.490699156227969

Epoch: 6| Step: 12
Training loss: 2.5471415936008666
Validation loss: 2.5217248637948253

Epoch: 6| Step: 13
Training loss: 1.4501418800657253
Validation loss: 2.5382841668112697

Epoch: 338| Step: 0
Training loss: 2.050990037734873
Validation loss: 2.548831804255806

Epoch: 6| Step: 1
Training loss: 1.8103033105665385
Validation loss: 2.593454382415869

Epoch: 6| Step: 2
Training loss: 2.320061564121935
Validation loss: 2.6150542110029327

Epoch: 6| Step: 3
Training loss: 1.87961975635148
Validation loss: 2.6437398082154933

Epoch: 6| Step: 4
Training loss: 1.5850936824658008
Validation loss: 2.6395911576160866

Epoch: 6| Step: 5
Training loss: 2.7752732769548634
Validation loss: 2.6267741126951836

Epoch: 6| Step: 6
Training loss: 1.621231110050268
Validation loss: 2.594435528470534

Epoch: 6| Step: 7
Training loss: 1.438942227219831
Validation loss: 2.5729939890580154

Epoch: 6| Step: 8
Training loss: 2.1761733956743363
Validation loss: 2.571448495386532

Epoch: 6| Step: 9
Training loss: 2.2071575297460084
Validation loss: 2.514107066522683

Epoch: 6| Step: 10
Training loss: 1.7968101821486926
Validation loss: 2.508026288229888

Epoch: 6| Step: 11
Training loss: 1.725445830740373
Validation loss: 2.4969074035502588

Epoch: 6| Step: 12
Training loss: 2.0664663612550016
Validation loss: 2.5291032832424096

Epoch: 6| Step: 13
Training loss: 2.307291919257593
Validation loss: 2.496090773061809

Epoch: 339| Step: 0
Training loss: 2.2277919654151312
Validation loss: 2.4728005494191687

Epoch: 6| Step: 1
Training loss: 2.063455533716204
Validation loss: 2.4975560958616136

Epoch: 6| Step: 2
Training loss: 1.4887519152266244
Validation loss: 2.4608120679426326

Epoch: 6| Step: 3
Training loss: 1.9839199475550633
Validation loss: 2.4693717736902436

Epoch: 6| Step: 4
Training loss: 2.307313309016167
Validation loss: 2.4869985343352057

Epoch: 6| Step: 5
Training loss: 2.577993586109786
Validation loss: 2.479652146213786

Epoch: 6| Step: 6
Training loss: 2.0923966546100643
Validation loss: 2.542641129804389

Epoch: 6| Step: 7
Training loss: 1.3894233226395147
Validation loss: 2.563815205806681

Epoch: 6| Step: 8
Training loss: 1.79106880533352
Validation loss: 2.59254590010099

Epoch: 6| Step: 9
Training loss: 1.7775279190725177
Validation loss: 2.600107368367522

Epoch: 6| Step: 10
Training loss: 2.3652947541774587
Validation loss: 2.601769714962069

Epoch: 6| Step: 11
Training loss: 1.7610135242261271
Validation loss: 2.625592407106598

Epoch: 6| Step: 12
Training loss: 2.4044586052872265
Validation loss: 2.594796325871345

Epoch: 6| Step: 13
Training loss: 1.9443058335384547
Validation loss: 2.570667369891238

Epoch: 340| Step: 0
Training loss: 1.5050695106701393
Validation loss: 2.5474724722121476

Epoch: 6| Step: 1
Training loss: 1.963410296375376
Validation loss: 2.5212609713884153

Epoch: 6| Step: 2
Training loss: 1.8687806295991356
Validation loss: 2.5117086407352693

Epoch: 6| Step: 3
Training loss: 1.9987440934371274
Validation loss: 2.5146894986155095

Epoch: 6| Step: 4
Training loss: 1.6806239157120288
Validation loss: 2.490917898877942

Epoch: 6| Step: 5
Training loss: 1.778202595551248
Validation loss: 2.4950313306993293

Epoch: 6| Step: 6
Training loss: 2.69119416883701
Validation loss: 2.4891146587136

Epoch: 6| Step: 7
Training loss: 1.5768979278119268
Validation loss: 2.486577191579712

Epoch: 6| Step: 8
Training loss: 2.0011048841311894
Validation loss: 2.4728522682535425

Epoch: 6| Step: 9
Training loss: 2.3472820878780722
Validation loss: 2.4677893785656972

Epoch: 6| Step: 10
Training loss: 1.388004104866532
Validation loss: 2.495022332366092

Epoch: 6| Step: 11
Training loss: 2.136192019743273
Validation loss: 2.5305463652775977

Epoch: 6| Step: 12
Training loss: 2.424636644493068
Validation loss: 2.515646482261407

Epoch: 6| Step: 13
Training loss: 2.045781899276347
Validation loss: 2.518725662176966

Epoch: 341| Step: 0
Training loss: 2.171382601240615
Validation loss: 2.5099640645346155

Epoch: 6| Step: 1
Training loss: 1.6440878517271447
Validation loss: 2.5122994977111603

Epoch: 6| Step: 2
Training loss: 1.9245990583338015
Validation loss: 2.579722085124419

Epoch: 6| Step: 3
Training loss: 1.6597826728115872
Validation loss: 2.556039637060777

Epoch: 6| Step: 4
Training loss: 1.2031164788278803
Validation loss: 2.544689481112105

Epoch: 6| Step: 5
Training loss: 2.1305979875198955
Validation loss: 2.531655644067807

Epoch: 6| Step: 6
Training loss: 1.9922972405819173
Validation loss: 2.505783401015452

Epoch: 6| Step: 7
Training loss: 2.02239256282296
Validation loss: 2.5358123635603294

Epoch: 6| Step: 8
Training loss: 1.8629532691307873
Validation loss: 2.4890464193108435

Epoch: 6| Step: 9
Training loss: 2.5126907579875164
Validation loss: 2.4738255408268683

Epoch: 6| Step: 10
Training loss: 2.412004105591324
Validation loss: 2.470624976247808

Epoch: 6| Step: 11
Training loss: 1.3155917129473647
Validation loss: 2.483444391451216

Epoch: 6| Step: 12
Training loss: 2.0332941187011118
Validation loss: 2.49983237817219

Epoch: 6| Step: 13
Training loss: 2.5652399069150036
Validation loss: 2.5056385508895853

Epoch: 342| Step: 0
Training loss: 1.7799765736399198
Validation loss: 2.5141230931318828

Epoch: 6| Step: 1
Training loss: 2.0710956747592197
Validation loss: 2.519848313206738

Epoch: 6| Step: 2
Training loss: 2.0024790896349076
Validation loss: 2.5259320002605348

Epoch: 6| Step: 3
Training loss: 1.898818115258216
Validation loss: 2.532092209407517

Epoch: 6| Step: 4
Training loss: 2.1656012727833036
Validation loss: 2.5453715030894863

Epoch: 6| Step: 5
Training loss: 1.9183154754183083
Validation loss: 2.635489245434344

Epoch: 6| Step: 6
Training loss: 1.9926699783401478
Validation loss: 2.5905691505121036

Epoch: 6| Step: 7
Training loss: 2.030737474777891
Validation loss: 2.6098223015399213

Epoch: 6| Step: 8
Training loss: 1.734059898001911
Validation loss: 2.586670463385532

Epoch: 6| Step: 9
Training loss: 1.9058853801275244
Validation loss: 2.5823861867438715

Epoch: 6| Step: 10
Training loss: 1.9466281103644412
Validation loss: 2.5726672037453087

Epoch: 6| Step: 11
Training loss: 2.1070539349504176
Validation loss: 2.5464437076656568

Epoch: 6| Step: 12
Training loss: 1.7918554103114466
Validation loss: 2.5718924662791474

Epoch: 6| Step: 13
Training loss: 2.4126196441235184
Validation loss: 2.5226984821689777

Epoch: 343| Step: 0
Training loss: 2.183093073295021
Validation loss: 2.5452261425938874

Epoch: 6| Step: 1
Training loss: 2.2678520043811576
Validation loss: 2.5077635382985726

Epoch: 6| Step: 2
Training loss: 1.2838135171868308
Validation loss: 2.5492581722084515

Epoch: 6| Step: 3
Training loss: 1.6699999696194765
Validation loss: 2.5414203748555764

Epoch: 6| Step: 4
Training loss: 2.336470221053988
Validation loss: 2.552657834739214

Epoch: 6| Step: 5
Training loss: 1.7258847662781391
Validation loss: 2.537581887513342

Epoch: 6| Step: 6
Training loss: 1.6218215227957695
Validation loss: 2.5348145774377997

Epoch: 6| Step: 7
Training loss: 2.3507731687610347
Validation loss: 2.573229293260112

Epoch: 6| Step: 8
Training loss: 1.8194309441192598
Validation loss: 2.5510526690876034

Epoch: 6| Step: 9
Training loss: 2.0004537782866363
Validation loss: 2.555497471752843

Epoch: 6| Step: 10
Training loss: 2.136595002379514
Validation loss: 2.548190816466384

Epoch: 6| Step: 11
Training loss: 1.2767060814260343
Validation loss: 2.5638548208030323

Epoch: 6| Step: 12
Training loss: 2.1090808804641314
Validation loss: 2.598110103874949

Epoch: 6| Step: 13
Training loss: 2.2719644185221655
Validation loss: 2.6080862277613828

Epoch: 344| Step: 0
Training loss: 1.8906551390208133
Validation loss: 2.6009788125698163

Epoch: 6| Step: 1
Training loss: 2.5772603752570515
Validation loss: 2.6277422432337234

Epoch: 6| Step: 2
Training loss: 2.3183741838195946
Validation loss: 2.5958167731265593

Epoch: 6| Step: 3
Training loss: 2.0433332945848037
Validation loss: 2.5805049353586043

Epoch: 6| Step: 4
Training loss: 1.2832168740939596
Validation loss: 2.5905670644235563

Epoch: 6| Step: 5
Training loss: 1.3806106364935042
Validation loss: 2.5597553285760064

Epoch: 6| Step: 6
Training loss: 1.700796933467609
Validation loss: 2.519272381399101

Epoch: 6| Step: 7
Training loss: 1.656378543112134
Validation loss: 2.530040985976638

Epoch: 6| Step: 8
Training loss: 2.4510957136138405
Validation loss: 2.5295625093026346

Epoch: 6| Step: 9
Training loss: 2.378874980551879
Validation loss: 2.515527695695129

Epoch: 6| Step: 10
Training loss: 1.5014091865954668
Validation loss: 2.5104898914300033

Epoch: 6| Step: 11
Training loss: 1.6277849834457692
Validation loss: 2.542657929863378

Epoch: 6| Step: 12
Training loss: 2.864454250317265
Validation loss: 2.5332805667786005

Epoch: 6| Step: 13
Training loss: 1.9894797679316263
Validation loss: 2.540114183988224

Epoch: 345| Step: 0
Training loss: 1.8100095278663029
Validation loss: 2.577328106032055

Epoch: 6| Step: 1
Training loss: 2.051745959850938
Validation loss: 2.6376604070593594

Epoch: 6| Step: 2
Training loss: 2.0148391966160015
Validation loss: 2.69525526787629

Epoch: 6| Step: 3
Training loss: 2.789297569477181
Validation loss: 2.7151231068566974

Epoch: 6| Step: 4
Training loss: 1.6026266888843954
Validation loss: 2.6819581031177133

Epoch: 6| Step: 5
Training loss: 1.7820507056860386
Validation loss: 2.6396902337189396

Epoch: 6| Step: 6
Training loss: 2.0678334490559602
Validation loss: 2.555403318454777

Epoch: 6| Step: 7
Training loss: 2.2581117425102324
Validation loss: 2.513228006997587

Epoch: 6| Step: 8
Training loss: 2.0511113945568287
Validation loss: 2.451453074502598

Epoch: 6| Step: 9
Training loss: 1.5449367671977006
Validation loss: 2.4700881936599783

Epoch: 6| Step: 10
Training loss: 1.5189078260762239
Validation loss: 2.4902387631446223

Epoch: 6| Step: 11
Training loss: 2.7441931017001964
Validation loss: 2.4907112492744656

Epoch: 6| Step: 12
Training loss: 2.1855077117874626
Validation loss: 2.500886036898957

Epoch: 6| Step: 13
Training loss: 1.6606344813261762
Validation loss: 2.505400142081223

Epoch: 346| Step: 0
Training loss: 1.7388334961512693
Validation loss: 2.542605755549808

Epoch: 6| Step: 1
Training loss: 2.3410666809166907
Validation loss: 2.553465151218665

Epoch: 6| Step: 2
Training loss: 2.4765556648232274
Validation loss: 2.54663408540269

Epoch: 6| Step: 3
Training loss: 2.101786208034068
Validation loss: 2.606901065851884

Epoch: 6| Step: 4
Training loss: 1.5197308955898658
Validation loss: 2.5979245231364825

Epoch: 6| Step: 5
Training loss: 2.8465930853572163
Validation loss: 2.6322166304365435

Epoch: 6| Step: 6
Training loss: 1.7056154014174738
Validation loss: 2.6790826261241936

Epoch: 6| Step: 7
Training loss: 2.133116648020853
Validation loss: 2.6396471504098207

Epoch: 6| Step: 8
Training loss: 2.1765191352506092
Validation loss: 2.628611260424791

Epoch: 6| Step: 9
Training loss: 2.1459480427818693
Validation loss: 2.552517995344363

Epoch: 6| Step: 10
Training loss: 1.5515728906934692
Validation loss: 2.5393210098519727

Epoch: 6| Step: 11
Training loss: 1.5027177350139607
Validation loss: 2.495640896196354

Epoch: 6| Step: 12
Training loss: 1.8219152769998805
Validation loss: 2.4718017869500626

Epoch: 6| Step: 13
Training loss: 2.033948778075775
Validation loss: 2.4743643551313497

Epoch: 347| Step: 0
Training loss: 2.562903581797857
Validation loss: 2.507931921344719

Epoch: 6| Step: 1
Training loss: 2.1710171549087214
Validation loss: 2.512196512697651

Epoch: 6| Step: 2
Training loss: 2.436031583935169
Validation loss: 2.4892623300712162

Epoch: 6| Step: 3
Training loss: 1.882741016597993
Validation loss: 2.467832064690127

Epoch: 6| Step: 4
Training loss: 2.2255654763004697
Validation loss: 2.4737708305110253

Epoch: 6| Step: 5
Training loss: 2.340809312395931
Validation loss: 2.480530481246183

Epoch: 6| Step: 6
Training loss: 1.97214620813849
Validation loss: 2.494513467609229

Epoch: 6| Step: 7
Training loss: 1.4604023652004543
Validation loss: 2.51697914528849

Epoch: 6| Step: 8
Training loss: 1.6881377816307788
Validation loss: 2.5581470516946587

Epoch: 6| Step: 9
Training loss: 1.9697505890832905
Validation loss: 2.5716556954618524

Epoch: 6| Step: 10
Training loss: 1.9182875731462563
Validation loss: 2.580177830770045

Epoch: 6| Step: 11
Training loss: 1.7420342895470347
Validation loss: 2.5587840701072633

Epoch: 6| Step: 12
Training loss: 1.9485165357428909
Validation loss: 2.5131173597913965

Epoch: 6| Step: 13
Training loss: 1.7867233109509792
Validation loss: 2.543705846604814

Epoch: 348| Step: 0
Training loss: 1.9751703237172944
Validation loss: 2.541983003681567

Epoch: 6| Step: 1
Training loss: 2.2561724028624206
Validation loss: 2.5974237247119722

Epoch: 6| Step: 2
Training loss: 1.368476652259117
Validation loss: 2.6154062007175853

Epoch: 6| Step: 3
Training loss: 2.3601982246815707
Validation loss: 2.6233485340258054

Epoch: 6| Step: 4
Training loss: 1.7992792381888751
Validation loss: 2.5881669805027343

Epoch: 6| Step: 5
Training loss: 2.0941970120270694
Validation loss: 2.6045049269652734

Epoch: 6| Step: 6
Training loss: 2.2108787286178835
Validation loss: 2.5915920825378262

Epoch: 6| Step: 7
Training loss: 2.311233379826224
Validation loss: 2.5543229429178114

Epoch: 6| Step: 8
Training loss: 2.6915041347913395
Validation loss: 2.5669521639519934

Epoch: 6| Step: 9
Training loss: 1.446500382835741
Validation loss: 2.5167759381081134

Epoch: 6| Step: 10
Training loss: 2.0067728519965824
Validation loss: 2.5523340582140577

Epoch: 6| Step: 11
Training loss: 1.6242306428577562
Validation loss: 2.5510938062488906

Epoch: 6| Step: 12
Training loss: 1.7668655223612482
Validation loss: 2.5689247041000027

Epoch: 6| Step: 13
Training loss: 1.495749013041917
Validation loss: 2.5564067394575627

Epoch: 349| Step: 0
Training loss: 1.4603073474638846
Validation loss: 2.5277485275206417

Epoch: 6| Step: 1
Training loss: 2.1416026757720545
Validation loss: 2.547906007741829

Epoch: 6| Step: 2
Training loss: 2.5893077266866147
Validation loss: 2.536539007283865

Epoch: 6| Step: 3
Training loss: 2.2255036630525358
Validation loss: 2.5008654765252207

Epoch: 6| Step: 4
Training loss: 2.583429416797507
Validation loss: 2.5332770845375863

Epoch: 6| Step: 5
Training loss: 1.5670414347863946
Validation loss: 2.5378550000846523

Epoch: 6| Step: 6
Training loss: 2.29066551765943
Validation loss: 2.6062743444243432

Epoch: 6| Step: 7
Training loss: 2.0836998299255316
Validation loss: 2.6053754264593145

Epoch: 6| Step: 8
Training loss: 1.9361720918234215
Validation loss: 2.6013634866195097

Epoch: 6| Step: 9
Training loss: 1.6137405000461684
Validation loss: 2.589696880949778

Epoch: 6| Step: 10
Training loss: 1.5628895083354077
Validation loss: 2.550708467887117

Epoch: 6| Step: 11
Training loss: 1.7226697441143464
Validation loss: 2.5258014420531025

Epoch: 6| Step: 12
Training loss: 2.0293988522560285
Validation loss: 2.5169451391076016

Epoch: 6| Step: 13
Training loss: 1.4673232595666115
Validation loss: 2.498787570052

Epoch: 350| Step: 0
Training loss: 2.1436255371619826
Validation loss: 2.5310473419819957

Epoch: 6| Step: 1
Training loss: 1.9307100621456434
Validation loss: 2.5162937704878896

Epoch: 6| Step: 2
Training loss: 1.7201257921395434
Validation loss: 2.5304112634256173

Epoch: 6| Step: 3
Training loss: 2.047017682176634
Validation loss: 2.5290163962286587

Epoch: 6| Step: 4
Training loss: 1.5610315670655877
Validation loss: 2.5797106711973807

Epoch: 6| Step: 5
Training loss: 1.4931439435163545
Validation loss: 2.570576879321614

Epoch: 6| Step: 6
Training loss: 1.6283208952512975
Validation loss: 2.550831520165496

Epoch: 6| Step: 7
Training loss: 1.7860743459368837
Validation loss: 2.5697728820617285

Epoch: 6| Step: 8
Training loss: 1.723774449740064
Validation loss: 2.5702840847929864

Epoch: 6| Step: 9
Training loss: 1.664483102288135
Validation loss: 2.5655611951036437

Epoch: 6| Step: 10
Training loss: 2.5799756430429857
Validation loss: 2.543108911357922

Epoch: 6| Step: 11
Training loss: 1.8012055995533054
Validation loss: 2.5264956718481737

Epoch: 6| Step: 12
Training loss: 2.859608791778449
Validation loss: 2.5907467073044588

Epoch: 6| Step: 13
Training loss: 1.772106528251079
Validation loss: 2.5608532739473873

Epoch: 351| Step: 0
Training loss: 1.4810519315383828
Validation loss: 2.539573790104882

Epoch: 6| Step: 1
Training loss: 2.198013761524165
Validation loss: 2.528737944874209

Epoch: 6| Step: 2
Training loss: 1.827259413072414
Validation loss: 2.5464143082857396

Epoch: 6| Step: 3
Training loss: 1.9249370341716407
Validation loss: 2.548391783721537

Epoch: 6| Step: 4
Training loss: 1.6105989413064783
Validation loss: 2.5403984350428592

Epoch: 6| Step: 5
Training loss: 1.6470865797761471
Validation loss: 2.5523130092943394

Epoch: 6| Step: 6
Training loss: 2.624355055280584
Validation loss: 2.582431240908218

Epoch: 6| Step: 7
Training loss: 1.8419304614200371
Validation loss: 2.5816616576778055

Epoch: 6| Step: 8
Training loss: 1.8870005268850232
Validation loss: 2.586423515139751

Epoch: 6| Step: 9
Training loss: 2.0608442191414778
Validation loss: 2.56625638279382

Epoch: 6| Step: 10
Training loss: 1.757540533431321
Validation loss: 2.6001909017782148

Epoch: 6| Step: 11
Training loss: 1.561076545822893
Validation loss: 2.6025066476297876

Epoch: 6| Step: 12
Training loss: 2.1032247669878728
Validation loss: 2.5962183134655117

Epoch: 6| Step: 13
Training loss: 2.111205486508172
Validation loss: 2.5902151970097527

Epoch: 352| Step: 0
Training loss: 1.563266108571569
Validation loss: 2.5777431860357596

Epoch: 6| Step: 1
Training loss: 2.130545728556641
Validation loss: 2.5979013121843804

Epoch: 6| Step: 2
Training loss: 1.767858729561318
Validation loss: 2.566537390173914

Epoch: 6| Step: 3
Training loss: 1.3656231458987431
Validation loss: 2.5336050686743685

Epoch: 6| Step: 4
Training loss: 2.0964361012876656
Validation loss: 2.548864246955287

Epoch: 6| Step: 5
Training loss: 1.9944375888396124
Validation loss: 2.5581016940973536

Epoch: 6| Step: 6
Training loss: 1.8774066738294102
Validation loss: 2.556190196537024

Epoch: 6| Step: 7
Training loss: 2.065595673368785
Validation loss: 2.564240941965943

Epoch: 6| Step: 8
Training loss: 2.1905760799066374
Validation loss: 2.5760072275202512

Epoch: 6| Step: 9
Training loss: 1.4270119567990354
Validation loss: 2.5706512166151883

Epoch: 6| Step: 10
Training loss: 2.962774426590125
Validation loss: 2.561793920110752

Epoch: 6| Step: 11
Training loss: 1.827049721641015
Validation loss: 2.523165992326338

Epoch: 6| Step: 12
Training loss: 1.5284026784913813
Validation loss: 2.551488493021108

Epoch: 6| Step: 13
Training loss: 1.4966091931415662
Validation loss: 2.5197984657232664

Epoch: 353| Step: 0
Training loss: 1.2961412675182322
Validation loss: 2.504371445122317

Epoch: 6| Step: 1
Training loss: 2.227733959751134
Validation loss: 2.5284775436663405

Epoch: 6| Step: 2
Training loss: 1.6807091732942117
Validation loss: 2.4876928986303586

Epoch: 6| Step: 3
Training loss: 2.0063005387545108
Validation loss: 2.5357840005231846

Epoch: 6| Step: 4
Training loss: 1.5398123991013546
Validation loss: 2.535572129568831

Epoch: 6| Step: 5
Training loss: 1.533540375179574
Validation loss: 2.5641134888923656

Epoch: 6| Step: 6
Training loss: 1.7295187243208698
Validation loss: 2.554705496286201

Epoch: 6| Step: 7
Training loss: 2.5618633316716126
Validation loss: 2.563143129976849

Epoch: 6| Step: 8
Training loss: 1.3367188605838554
Validation loss: 2.554210031046899

Epoch: 6| Step: 9
Training loss: 1.9088374853164218
Validation loss: 2.5299746907391865

Epoch: 6| Step: 10
Training loss: 1.9156879607615098
Validation loss: 2.5201183334955433

Epoch: 6| Step: 11
Training loss: 1.9254358070785367
Validation loss: 2.5610995226087816

Epoch: 6| Step: 12
Training loss: 2.3219647930541725
Validation loss: 2.5288106679309412

Epoch: 6| Step: 13
Training loss: 2.247118694475881
Validation loss: 2.5236105057468317

Epoch: 354| Step: 0
Training loss: 1.7235931824188777
Validation loss: 2.5330051098649142

Epoch: 6| Step: 1
Training loss: 2.0293699513881562
Validation loss: 2.572750245759756

Epoch: 6| Step: 2
Training loss: 1.618598359417458
Validation loss: 2.563470284590527

Epoch: 6| Step: 3
Training loss: 2.5617726852262837
Validation loss: 2.588925620347375

Epoch: 6| Step: 4
Training loss: 1.8450576541648727
Validation loss: 2.58167243191802

Epoch: 6| Step: 5
Training loss: 1.9667868135681699
Validation loss: 2.5903421404776426

Epoch: 6| Step: 6
Training loss: 1.5569792299055174
Validation loss: 2.5760366748021544

Epoch: 6| Step: 7
Training loss: 1.5468680641712405
Validation loss: 2.6087471669231506

Epoch: 6| Step: 8
Training loss: 2.120889840063383
Validation loss: 2.5871543825452568

Epoch: 6| Step: 9
Training loss: 2.079519621323336
Validation loss: 2.5923296858176657

Epoch: 6| Step: 10
Training loss: 2.1527183469820446
Validation loss: 2.607749645952965

Epoch: 6| Step: 11
Training loss: 1.4836801609227548
Validation loss: 2.5809559085730007

Epoch: 6| Step: 12
Training loss: 1.7300120282719709
Validation loss: 2.5587691851158967

Epoch: 6| Step: 13
Training loss: 1.9133080688939643
Validation loss: 2.582714334796705

Epoch: 355| Step: 0
Training loss: 1.7614373703454966
Validation loss: 2.600187807147037

Epoch: 6| Step: 1
Training loss: 2.7165153352054263
Validation loss: 2.565082969513398

Epoch: 6| Step: 2
Training loss: 1.6427377811454082
Validation loss: 2.6078911710208907

Epoch: 6| Step: 3
Training loss: 1.9128472031722021
Validation loss: 2.6305809789375902

Epoch: 6| Step: 4
Training loss: 1.8334819849032724
Validation loss: 2.5898281459424575

Epoch: 6| Step: 5
Training loss: 1.6984081220147829
Validation loss: 2.5721860973255612

Epoch: 6| Step: 6
Training loss: 1.7469713024147167
Validation loss: 2.592367010356537

Epoch: 6| Step: 7
Training loss: 1.7937352488904774
Validation loss: 2.5932208827562495

Epoch: 6| Step: 8
Training loss: 1.7161333453158671
Validation loss: 2.670504153274785

Epoch: 6| Step: 9
Training loss: 2.0217563317214955
Validation loss: 2.6353484636209052

Epoch: 6| Step: 10
Training loss: 2.7674647532133667
Validation loss: 2.5905066975085647

Epoch: 6| Step: 11
Training loss: 1.4906311706799116
Validation loss: 2.5337626933059205

Epoch: 6| Step: 12
Training loss: 1.3399402817186994
Validation loss: 2.5712434885612976

Epoch: 6| Step: 13
Training loss: 1.7807134522909411
Validation loss: 2.5421574749274503

Epoch: 356| Step: 0
Training loss: 1.6809581120325274
Validation loss: 2.542309192573199

Epoch: 6| Step: 1
Training loss: 2.467259403700577
Validation loss: 2.5394336918175964

Epoch: 6| Step: 2
Training loss: 1.8849580182325727
Validation loss: 2.5583198070686284

Epoch: 6| Step: 3
Training loss: 2.0913018104715757
Validation loss: 2.5656892112536718

Epoch: 6| Step: 4
Training loss: 1.9020651235332025
Validation loss: 2.5411966363470584

Epoch: 6| Step: 5
Training loss: 1.7896295173674868
Validation loss: 2.5504583414336626

Epoch: 6| Step: 6
Training loss: 1.6256735946156193
Validation loss: 2.5640931875564843

Epoch: 6| Step: 7
Training loss: 2.452939749362276
Validation loss: 2.5841446853468786

Epoch: 6| Step: 8
Training loss: 1.749198730136106
Validation loss: 2.6065687672246587

Epoch: 6| Step: 9
Training loss: 2.1773270709353993
Validation loss: 2.6423135208164124

Epoch: 6| Step: 10
Training loss: 2.308142603443737
Validation loss: 2.651644510152222

Epoch: 6| Step: 11
Training loss: 1.7959032167554678
Validation loss: 2.664506608595586

Epoch: 6| Step: 12
Training loss: 2.095151972755301
Validation loss: 2.6041281938889873

Epoch: 6| Step: 13
Training loss: 1.6282835577492778
Validation loss: 2.549967099893795

Epoch: 357| Step: 0
Training loss: 2.169628051312593
Validation loss: 2.546124712496401

Epoch: 6| Step: 1
Training loss: 1.668103036232083
Validation loss: 2.5419458850850076

Epoch: 6| Step: 2
Training loss: 1.8520362988204193
Validation loss: 2.528018269842058

Epoch: 6| Step: 3
Training loss: 1.3882786962757225
Validation loss: 2.507629815693848

Epoch: 6| Step: 4
Training loss: 1.9684344447515396
Validation loss: 2.5109270033491353

Epoch: 6| Step: 5
Training loss: 1.6824484201945065
Validation loss: 2.5044033055093826

Epoch: 6| Step: 6
Training loss: 1.8793024926110566
Validation loss: 2.5364324475690125

Epoch: 6| Step: 7
Training loss: 1.9443409650000922
Validation loss: 2.531189089697639

Epoch: 6| Step: 8
Training loss: 2.0399871717311453
Validation loss: 2.5506692407072924

Epoch: 6| Step: 9
Training loss: 1.519458445395976
Validation loss: 2.5969134729184957

Epoch: 6| Step: 10
Training loss: 2.2352220756920627
Validation loss: 2.6359698251589987

Epoch: 6| Step: 11
Training loss: 2.1384568197739795
Validation loss: 2.6616873795004583

Epoch: 6| Step: 12
Training loss: 1.9819623442728675
Validation loss: 2.6888639700035304

Epoch: 6| Step: 13
Training loss: 2.6366986761388644
Validation loss: 2.6456230760869692

Epoch: 358| Step: 0
Training loss: 1.7204290338418031
Validation loss: 2.5549228649228666

Epoch: 6| Step: 1
Training loss: 2.1245320870841873
Validation loss: 2.5421542236801233

Epoch: 6| Step: 2
Training loss: 1.479941241412458
Validation loss: 2.515304521322185

Epoch: 6| Step: 3
Training loss: 2.307353504692698
Validation loss: 2.464234951502115

Epoch: 6| Step: 4
Training loss: 1.908420015501411
Validation loss: 2.482921783109966

Epoch: 6| Step: 5
Training loss: 1.0756463569502464
Validation loss: 2.49276202205531

Epoch: 6| Step: 6
Training loss: 1.5660079487712135
Validation loss: 2.473943502816705

Epoch: 6| Step: 7
Training loss: 2.1513113325420674
Validation loss: 2.4576468775473463

Epoch: 6| Step: 8
Training loss: 1.6743307171441115
Validation loss: 2.4966051257417146

Epoch: 6| Step: 9
Training loss: 2.449653939699624
Validation loss: 2.4494723848290514

Epoch: 6| Step: 10
Training loss: 2.042680825828469
Validation loss: 2.46559388786126

Epoch: 6| Step: 11
Training loss: 1.618770985117506
Validation loss: 2.5058467524729178

Epoch: 6| Step: 12
Training loss: 2.1637149903601625
Validation loss: 2.518141015504385

Epoch: 6| Step: 13
Training loss: 2.2804448000051134
Validation loss: 2.5081036043209073

Epoch: 359| Step: 0
Training loss: 1.9241740424057643
Validation loss: 2.531209521499803

Epoch: 6| Step: 1
Training loss: 1.8681565327948753
Validation loss: 2.5401722209345667

Epoch: 6| Step: 2
Training loss: 1.3085015563372524
Validation loss: 2.5318673248413237

Epoch: 6| Step: 3
Training loss: 1.4190081525357388
Validation loss: 2.5006917155496127

Epoch: 6| Step: 4
Training loss: 2.034100102897391
Validation loss: 2.5149419421907395

Epoch: 6| Step: 5
Training loss: 2.1807178536804894
Validation loss: 2.4910613956825585

Epoch: 6| Step: 6
Training loss: 2.595681172458196
Validation loss: 2.462398123852575

Epoch: 6| Step: 7
Training loss: 1.7231032295498312
Validation loss: 2.469511333201426

Epoch: 6| Step: 8
Training loss: 2.1609945757231626
Validation loss: 2.4446080973660256

Epoch: 6| Step: 9
Training loss: 1.4554318401347677
Validation loss: 2.452653195635103

Epoch: 6| Step: 10
Training loss: 2.5878337810679186
Validation loss: 2.4664653878527685

Epoch: 6| Step: 11
Training loss: 1.2393938234932167
Validation loss: 2.5017741424919437

Epoch: 6| Step: 12
Training loss: 1.5971758057120096
Validation loss: 2.499322545133181

Epoch: 6| Step: 13
Training loss: 1.9979287986135101
Validation loss: 2.510949546533445

Epoch: 360| Step: 0
Training loss: 2.1590652884099404
Validation loss: 2.5347638485305057

Epoch: 6| Step: 1
Training loss: 1.850641077674562
Validation loss: 2.5445417860541304

Epoch: 6| Step: 2
Training loss: 1.749861098635321
Validation loss: 2.5950214685962

Epoch: 6| Step: 3
Training loss: 1.9931292533171217
Validation loss: 2.634865704467424

Epoch: 6| Step: 4
Training loss: 1.6327597869687196
Validation loss: 2.6200818052212087

Epoch: 6| Step: 5
Training loss: 1.624939477233611
Validation loss: 2.6113619672607604

Epoch: 6| Step: 6
Training loss: 1.4910221042747123
Validation loss: 2.6514041005861597

Epoch: 6| Step: 7
Training loss: 2.1982862213076384
Validation loss: 2.625215884822627

Epoch: 6| Step: 8
Training loss: 1.7310793382829968
Validation loss: 2.6044291605580505

Epoch: 6| Step: 9
Training loss: 1.5040456731993554
Validation loss: 2.566439043413248

Epoch: 6| Step: 10
Training loss: 2.344747000672325
Validation loss: 2.5760404848763705

Epoch: 6| Step: 11
Training loss: 2.0189208061780564
Validation loss: 2.5544045512287785

Epoch: 6| Step: 12
Training loss: 2.073101885266804
Validation loss: 2.589774137072498

Epoch: 6| Step: 13
Training loss: 1.966791420013227
Validation loss: 2.6021759791459127

Epoch: 361| Step: 0
Training loss: 1.5701401649157598
Validation loss: 2.5530560307114984

Epoch: 6| Step: 1
Training loss: 2.451230623673458
Validation loss: 2.549943304366591

Epoch: 6| Step: 2
Training loss: 1.8998613708517234
Validation loss: 2.5867240762074872

Epoch: 6| Step: 3
Training loss: 1.4794583458382031
Validation loss: 2.572500486086548

Epoch: 6| Step: 4
Training loss: 1.898705357622582
Validation loss: 2.5978872096133583

Epoch: 6| Step: 5
Training loss: 1.7137130450626414
Validation loss: 2.5190087774728798

Epoch: 6| Step: 6
Training loss: 2.2813974620241484
Validation loss: 2.551947396738741

Epoch: 6| Step: 7
Training loss: 1.6722435945994696
Validation loss: 2.552569258743785

Epoch: 6| Step: 8
Training loss: 2.1672354342901516
Validation loss: 2.564303453565981

Epoch: 6| Step: 9
Training loss: 1.9027798444577368
Validation loss: 2.554148330332252

Epoch: 6| Step: 10
Training loss: 1.7063673461134334
Validation loss: 2.5823433322413365

Epoch: 6| Step: 11
Training loss: 1.3994733501048917
Validation loss: 2.6426302577419145

Epoch: 6| Step: 12
Training loss: 2.232732636055846
Validation loss: 2.6185970325450536

Epoch: 6| Step: 13
Training loss: 1.5936633067768178
Validation loss: 2.5981486912573195

Epoch: 362| Step: 0
Training loss: 1.842739280784398
Validation loss: 2.578491539378646

Epoch: 6| Step: 1
Training loss: 1.9799090013882144
Validation loss: 2.595683759622355

Epoch: 6| Step: 2
Training loss: 1.6781536106959694
Validation loss: 2.5659259286666893

Epoch: 6| Step: 3
Training loss: 1.597077579675361
Validation loss: 2.5495360968483842

Epoch: 6| Step: 4
Training loss: 1.4453539043372592
Validation loss: 2.5677232000347434

Epoch: 6| Step: 5
Training loss: 1.7816051329908353
Validation loss: 2.551915896366192

Epoch: 6| Step: 6
Training loss: 1.8613920410966516
Validation loss: 2.5647342757287666

Epoch: 6| Step: 7
Training loss: 1.522000383229151
Validation loss: 2.5812396722791715

Epoch: 6| Step: 8
Training loss: 2.085577544397491
Validation loss: 2.6081613242213493

Epoch: 6| Step: 9
Training loss: 2.14255653725166
Validation loss: 2.5950858265006382

Epoch: 6| Step: 10
Training loss: 1.3041851424268445
Validation loss: 2.5709478951457263

Epoch: 6| Step: 11
Training loss: 2.0235619230567945
Validation loss: 2.620139541938198

Epoch: 6| Step: 12
Training loss: 1.7221540553777706
Validation loss: 2.629206360176256

Epoch: 6| Step: 13
Training loss: 2.5232219781161525
Validation loss: 2.5898251846898517

Epoch: 363| Step: 0
Training loss: 2.0235143227151613
Validation loss: 2.5293216345715415

Epoch: 6| Step: 1
Training loss: 2.074786035008057
Validation loss: 2.5387309322520757

Epoch: 6| Step: 2
Training loss: 1.5217516055987772
Validation loss: 2.527796850609932

Epoch: 6| Step: 3
Training loss: 1.6955259689731685
Validation loss: 2.5200541108997627

Epoch: 6| Step: 4
Training loss: 1.99864997599179
Validation loss: 2.5458701868298164

Epoch: 6| Step: 5
Training loss: 1.4749165398213135
Validation loss: 2.4991652684612204

Epoch: 6| Step: 6
Training loss: 1.4967920650689817
Validation loss: 2.524325298271184

Epoch: 6| Step: 7
Training loss: 1.8439508102459483
Validation loss: 2.487493241522983

Epoch: 6| Step: 8
Training loss: 2.355095019195293
Validation loss: 2.5225349599522127

Epoch: 6| Step: 9
Training loss: 2.1818129591807076
Validation loss: 2.510798877623561

Epoch: 6| Step: 10
Training loss: 1.7771171676914996
Validation loss: 2.572097560419503

Epoch: 6| Step: 11
Training loss: 1.9301901097131338
Validation loss: 2.6066790719257433

Epoch: 6| Step: 12
Training loss: 2.1420310199104935
Validation loss: 2.5987460266934286

Epoch: 6| Step: 13
Training loss: 1.6759186801710835
Validation loss: 2.578465857273772

Epoch: 364| Step: 0
Training loss: 1.4568507514811064
Validation loss: 2.5928609005914445

Epoch: 6| Step: 1
Training loss: 1.3635490613503243
Validation loss: 2.556629201282132

Epoch: 6| Step: 2
Training loss: 1.4253256710073727
Validation loss: 2.5533446069257706

Epoch: 6| Step: 3
Training loss: 2.15631136599583
Validation loss: 2.556095307013488

Epoch: 6| Step: 4
Training loss: 1.4517382495865085
Validation loss: 2.5130933734656007

Epoch: 6| Step: 5
Training loss: 1.934650602412466
Validation loss: 2.5199824991198776

Epoch: 6| Step: 6
Training loss: 1.5371208529789053
Validation loss: 2.5214911199036756

Epoch: 6| Step: 7
Training loss: 2.17837714729328
Validation loss: 2.507518319278228

Epoch: 6| Step: 8
Training loss: 2.0744812650204625
Validation loss: 2.5479943403713143

Epoch: 6| Step: 9
Training loss: 1.7126010837097552
Validation loss: 2.570588217868712

Epoch: 6| Step: 10
Training loss: 1.6592021040274982
Validation loss: 2.5835931760073874

Epoch: 6| Step: 11
Training loss: 1.5951367497193385
Validation loss: 2.611834358823528

Epoch: 6| Step: 12
Training loss: 2.1266491044773272
Validation loss: 2.601152175757692

Epoch: 6| Step: 13
Training loss: 2.5135519833490707
Validation loss: 2.5428537556654778

Epoch: 365| Step: 0
Training loss: 2.0822095383106585
Validation loss: 2.540696323671453

Epoch: 6| Step: 1
Training loss: 1.8094481721883313
Validation loss: 2.532105062041134

Epoch: 6| Step: 2
Training loss: 1.6619954770574068
Validation loss: 2.5602355038332107

Epoch: 6| Step: 3
Training loss: 1.7304533189210403
Validation loss: 2.5790247878665404

Epoch: 6| Step: 4
Training loss: 2.015492989408905
Validation loss: 2.533280206006105

Epoch: 6| Step: 5
Training loss: 1.8263249460621755
Validation loss: 2.559253093221135

Epoch: 6| Step: 6
Training loss: 1.2981022003625369
Validation loss: 2.573762597597753

Epoch: 6| Step: 7
Training loss: 2.3456041250054698
Validation loss: 2.5301729901545116

Epoch: 6| Step: 8
Training loss: 2.016339552440229
Validation loss: 2.518145773189601

Epoch: 6| Step: 9
Training loss: 1.9823011239394683
Validation loss: 2.556525810428243

Epoch: 6| Step: 10
Training loss: 2.0404064674841798
Validation loss: 2.54809375770297

Epoch: 6| Step: 11
Training loss: 1.7225889854533425
Validation loss: 2.598580791034398

Epoch: 6| Step: 12
Training loss: 1.3597748705410733
Validation loss: 2.6068612056669935

Epoch: 6| Step: 13
Training loss: 1.6323251681449154
Validation loss: 2.588362395272219

Epoch: 366| Step: 0
Training loss: 1.6477823989639309
Validation loss: 2.6346699004697194

Epoch: 6| Step: 1
Training loss: 1.3304321893315518
Validation loss: 2.60943790748284

Epoch: 6| Step: 2
Training loss: 1.84401597512994
Validation loss: 2.6075528115532123

Epoch: 6| Step: 3
Training loss: 2.3866618098133188
Validation loss: 2.583414204674981

Epoch: 6| Step: 4
Training loss: 1.5880024813096962
Validation loss: 2.571584199492513

Epoch: 6| Step: 5
Training loss: 1.9342626782470556
Validation loss: 2.5701056863895766

Epoch: 6| Step: 6
Training loss: 1.2746649601115556
Validation loss: 2.5632664844475603

Epoch: 6| Step: 7
Training loss: 1.5004101033673238
Validation loss: 2.562731305979648

Epoch: 6| Step: 8
Training loss: 2.488244743618338
Validation loss: 2.554924070271423

Epoch: 6| Step: 9
Training loss: 1.6214438922031018
Validation loss: 2.5825277323432445

Epoch: 6| Step: 10
Training loss: 1.876514395447424
Validation loss: 2.5782687676928266

Epoch: 6| Step: 11
Training loss: 2.135661363925645
Validation loss: 2.6107167279791974

Epoch: 6| Step: 12
Training loss: 1.6949984351857033
Validation loss: 2.5994355114681453

Epoch: 6| Step: 13
Training loss: 1.845580727691793
Validation loss: 2.574768084974094

Epoch: 367| Step: 0
Training loss: 1.8496035099440076
Validation loss: 2.570191524483943

Epoch: 6| Step: 1
Training loss: 1.9579566701550344
Validation loss: 2.5418486816604533

Epoch: 6| Step: 2
Training loss: 1.7212297064665993
Validation loss: 2.5660307061242946

Epoch: 6| Step: 3
Training loss: 1.8653469830618692
Validation loss: 2.583705342077098

Epoch: 6| Step: 4
Training loss: 1.1953251657251243
Validation loss: 2.546575033235278

Epoch: 6| Step: 5
Training loss: 2.4235725606228513
Validation loss: 2.571131273395932

Epoch: 6| Step: 6
Training loss: 2.3926703984119944
Validation loss: 2.54001861567947

Epoch: 6| Step: 7
Training loss: 1.3697312587090194
Validation loss: 2.5095926940159017

Epoch: 6| Step: 8
Training loss: 1.5000768482867775
Validation loss: 2.54990517184391

Epoch: 6| Step: 9
Training loss: 1.733320998490289
Validation loss: 2.5856231621334684

Epoch: 6| Step: 10
Training loss: 1.9052387744716524
Validation loss: 2.5300112467856337

Epoch: 6| Step: 11
Training loss: 2.0317348195078355
Validation loss: 2.5967433310010812

Epoch: 6| Step: 12
Training loss: 1.5972086458965251
Validation loss: 2.5466176002412535

Epoch: 6| Step: 13
Training loss: 1.320640478084072
Validation loss: 2.5811668869073965

Epoch: 368| Step: 0
Training loss: 1.301181628495018
Validation loss: 2.5847308060398015

Epoch: 6| Step: 1
Training loss: 2.5099761280885162
Validation loss: 2.566758192172721

Epoch: 6| Step: 2
Training loss: 1.267133214425131
Validation loss: 2.5796699826781606

Epoch: 6| Step: 3
Training loss: 2.0624240514470005
Validation loss: 2.5550371527661153

Epoch: 6| Step: 4
Training loss: 1.1994038293026454
Validation loss: 2.5670661252119973

Epoch: 6| Step: 5
Training loss: 1.8272675027388714
Validation loss: 2.569304982831021

Epoch: 6| Step: 6
Training loss: 2.280480032798506
Validation loss: 2.5369157528820843

Epoch: 6| Step: 7
Training loss: 1.7627548249995182
Validation loss: 2.5705873135692445

Epoch: 6| Step: 8
Training loss: 2.4301552276324663
Validation loss: 2.5360782085186377

Epoch: 6| Step: 9
Training loss: 1.411414602054989
Validation loss: 2.5888113934138093

Epoch: 6| Step: 10
Training loss: 1.6012184331732016
Validation loss: 2.608022114485416

Epoch: 6| Step: 11
Training loss: 1.9835438226619264
Validation loss: 2.6200340315620276

Epoch: 6| Step: 12
Training loss: 1.5757739995998605
Validation loss: 2.550201809757418

Epoch: 6| Step: 13
Training loss: 1.6903801816570196
Validation loss: 2.5340209284000714

Epoch: 369| Step: 0
Training loss: 1.8772267788161914
Validation loss: 2.4821616655939405

Epoch: 6| Step: 1
Training loss: 1.9914536863703072
Validation loss: 2.5171397764456054

Epoch: 6| Step: 2
Training loss: 1.5083253610867453
Validation loss: 2.4870002998665797

Epoch: 6| Step: 3
Training loss: 1.3157950320879332
Validation loss: 2.5035905961403673

Epoch: 6| Step: 4
Training loss: 1.9833833514512738
Validation loss: 2.5068908772567715

Epoch: 6| Step: 5
Training loss: 2.3620796112158624
Validation loss: 2.5110464427318857

Epoch: 6| Step: 6
Training loss: 1.5833679580248798
Validation loss: 2.521417098326074

Epoch: 6| Step: 7
Training loss: 2.0840996922171477
Validation loss: 2.530471556472439

Epoch: 6| Step: 8
Training loss: 2.0565522873211464
Validation loss: 2.495891644449968

Epoch: 6| Step: 9
Training loss: 1.5925813766120687
Validation loss: 2.5245483913627877

Epoch: 6| Step: 10
Training loss: 1.5747268651851702
Validation loss: 2.607998901982749

Epoch: 6| Step: 11
Training loss: 1.577344871547049
Validation loss: 2.6621672152203795

Epoch: 6| Step: 12
Training loss: 1.8394614306359791
Validation loss: 2.7376217267800516

Epoch: 6| Step: 13
Training loss: 2.0539735199020908
Validation loss: 2.7353417422358826

Epoch: 370| Step: 0
Training loss: 2.172298033427438
Validation loss: 2.7104757393907226

Epoch: 6| Step: 1
Training loss: 1.2907085197709582
Validation loss: 2.6214418213305146

Epoch: 6| Step: 2
Training loss: 1.826724828550585
Validation loss: 2.58612225843468

Epoch: 6| Step: 3
Training loss: 1.6209346095644594
Validation loss: 2.5544474233265464

Epoch: 6| Step: 4
Training loss: 2.315901033780719
Validation loss: 2.4710668404185636

Epoch: 6| Step: 5
Training loss: 1.27144790339277
Validation loss: 2.468056166806274

Epoch: 6| Step: 6
Training loss: 1.6210607318503047
Validation loss: 2.4760562607962724

Epoch: 6| Step: 7
Training loss: 1.9836443659847711
Validation loss: 2.472089335862247

Epoch: 6| Step: 8
Training loss: 2.3661076566076766
Validation loss: 2.4814622306221983

Epoch: 6| Step: 9
Training loss: 2.0863788723554575
Validation loss: 2.4700511609955336

Epoch: 6| Step: 10
Training loss: 2.1959364469326714
Validation loss: 2.4460062946031687

Epoch: 6| Step: 11
Training loss: 1.6733400574709887
Validation loss: 2.435888132407045

Epoch: 6| Step: 12
Training loss: 1.6096145303487461
Validation loss: 2.454916815970297

Epoch: 6| Step: 13
Training loss: 1.746563671123271
Validation loss: 2.53794894326361

Epoch: 371| Step: 0
Training loss: 1.8680495183658854
Validation loss: 2.607050379887837

Epoch: 6| Step: 1
Training loss: 2.1059638805353202
Validation loss: 2.683036365029888

Epoch: 6| Step: 2
Training loss: 1.389804812524368
Validation loss: 2.716482217842018

Epoch: 6| Step: 3
Training loss: 2.3395318283521602
Validation loss: 2.6894119765588163

Epoch: 6| Step: 4
Training loss: 2.055253099694169
Validation loss: 2.700212162418229

Epoch: 6| Step: 5
Training loss: 2.1537341492214077
Validation loss: 2.6213220533837793

Epoch: 6| Step: 6
Training loss: 1.936556555637447
Validation loss: 2.5456779646926417

Epoch: 6| Step: 7
Training loss: 1.9010246450280512
Validation loss: 2.4606641425844384

Epoch: 6| Step: 8
Training loss: 1.6804172084109739
Validation loss: 2.459120177300626

Epoch: 6| Step: 9
Training loss: 2.0205780208847828
Validation loss: 2.4382536366993373

Epoch: 6| Step: 10
Training loss: 1.3672178428552553
Validation loss: 2.421211594812198

Epoch: 6| Step: 11
Training loss: 2.1874585828947444
Validation loss: 2.434682521894136

Epoch: 6| Step: 12
Training loss: 1.4551675858614685
Validation loss: 2.4601658332826224

Epoch: 6| Step: 13
Training loss: 1.6687273002537906
Validation loss: 2.449956187680414

Epoch: 372| Step: 0
Training loss: 1.8608051217732746
Validation loss: 2.4583599013708657

Epoch: 6| Step: 1
Training loss: 1.3261590207000833
Validation loss: 2.460763511360443

Epoch: 6| Step: 2
Training loss: 1.961695611924384
Validation loss: 2.4730110094756292

Epoch: 6| Step: 3
Training loss: 1.721874241214315
Validation loss: 2.4799994477789276

Epoch: 6| Step: 4
Training loss: 1.6089421403106172
Validation loss: 2.490526113936251

Epoch: 6| Step: 5
Training loss: 1.6965189916850176
Validation loss: 2.5793980932684715

Epoch: 6| Step: 6
Training loss: 1.6826154871581658
Validation loss: 2.6146331620249232

Epoch: 6| Step: 7
Training loss: 2.3328486915637527
Validation loss: 2.702054754521264

Epoch: 6| Step: 8
Training loss: 1.7945849877674538
Validation loss: 2.738024457861756

Epoch: 6| Step: 9
Training loss: 1.6182652811866753
Validation loss: 2.6488450748554047

Epoch: 6| Step: 10
Training loss: 1.7294687520468939
Validation loss: 2.602798947067599

Epoch: 6| Step: 11
Training loss: 2.1317426632280365
Validation loss: 2.577760674522194

Epoch: 6| Step: 12
Training loss: 2.481602303118839
Validation loss: 2.5832279911918206

Epoch: 6| Step: 13
Training loss: 1.5719456317420244
Validation loss: 2.5343457039591315

Epoch: 373| Step: 0
Training loss: 1.2227248882490902
Validation loss: 2.521757607955905

Epoch: 6| Step: 1
Training loss: 2.1272955444567585
Validation loss: 2.5558853296571877

Epoch: 6| Step: 2
Training loss: 1.3023255033994015
Validation loss: 2.5261900448562282

Epoch: 6| Step: 3
Training loss: 2.3104341919638194
Validation loss: 2.5326540157460373

Epoch: 6| Step: 4
Training loss: 1.6009216515111986
Validation loss: 2.5526477630717612

Epoch: 6| Step: 5
Training loss: 1.212367732905594
Validation loss: 2.517517381107419

Epoch: 6| Step: 6
Training loss: 1.874871694625361
Validation loss: 2.497843694588743

Epoch: 6| Step: 7
Training loss: 2.1532483424055537
Validation loss: 2.4953121499809985

Epoch: 6| Step: 8
Training loss: 2.3190715309813332
Validation loss: 2.5214614689833286

Epoch: 6| Step: 9
Training loss: 1.3184380401877855
Validation loss: 2.5463592537568847

Epoch: 6| Step: 10
Training loss: 1.4066060357262498
Validation loss: 2.490172405593836

Epoch: 6| Step: 11
Training loss: 2.2854648479528246
Validation loss: 2.522738601066571

Epoch: 6| Step: 12
Training loss: 1.9217789788798687
Validation loss: 2.5465501137304005

Epoch: 6| Step: 13
Training loss: 1.7250364990795812
Validation loss: 2.520114896138059

Epoch: 374| Step: 0
Training loss: 1.5039237677804829
Validation loss: 2.49067961259203

Epoch: 6| Step: 1
Training loss: 1.6636930960103196
Validation loss: 2.5039034648528653

Epoch: 6| Step: 2
Training loss: 2.1309939725693052
Validation loss: 2.5039855896851995

Epoch: 6| Step: 3
Training loss: 1.31120818006886
Validation loss: 2.486830036159184

Epoch: 6| Step: 4
Training loss: 1.608799952018278
Validation loss: 2.506766159419961

Epoch: 6| Step: 5
Training loss: 2.0525174012648755
Validation loss: 2.556730163420678

Epoch: 6| Step: 6
Training loss: 2.408509617813797
Validation loss: 2.5465604981873975

Epoch: 6| Step: 7
Training loss: 2.0096307381165235
Validation loss: 2.545768403777291

Epoch: 6| Step: 8
Training loss: 1.323931457502861
Validation loss: 2.565200762535524

Epoch: 6| Step: 9
Training loss: 1.0445544586228181
Validation loss: 2.5929716083587095

Epoch: 6| Step: 10
Training loss: 2.0300824844815613
Validation loss: 2.5812177198853163

Epoch: 6| Step: 11
Training loss: 1.6022624649417707
Validation loss: 2.5677729528212967

Epoch: 6| Step: 12
Training loss: 1.7766998801547338
Validation loss: 2.5549292649283726

Epoch: 6| Step: 13
Training loss: 1.3799090318827787
Validation loss: 2.525063155426235

Epoch: 375| Step: 0
Training loss: 1.7285401768206896
Validation loss: 2.5535155708461206

Epoch: 6| Step: 1
Training loss: 2.1810518322312173
Validation loss: 2.520015415719731

Epoch: 6| Step: 2
Training loss: 1.9672370425675143
Validation loss: 2.526416645861088

Epoch: 6| Step: 3
Training loss: 1.1202496796981876
Validation loss: 2.5414166770523363

Epoch: 6| Step: 4
Training loss: 2.0261930459811865
Validation loss: 2.5378192224763088

Epoch: 6| Step: 5
Training loss: 1.7668676813795134
Validation loss: 2.5628532228249004

Epoch: 6| Step: 6
Training loss: 1.6111717194451356
Validation loss: 2.566155594149784

Epoch: 6| Step: 7
Training loss: 1.5946704973782955
Validation loss: 2.5885393282126925

Epoch: 6| Step: 8
Training loss: 1.08536333232523
Validation loss: 2.6047212976476173

Epoch: 6| Step: 9
Training loss: 2.2179617757711108
Validation loss: 2.6600492122586528

Epoch: 6| Step: 10
Training loss: 2.1181918644080806
Validation loss: 2.6098902149910113

Epoch: 6| Step: 11
Training loss: 1.8571940221131191
Validation loss: 2.634633567371771

Epoch: 6| Step: 12
Training loss: 1.6512534149157712
Validation loss: 2.5932755706633595

Epoch: 6| Step: 13
Training loss: 1.138399016206039
Validation loss: 2.609224021944825

Epoch: 376| Step: 0
Training loss: 2.3296733034495767
Validation loss: 2.6071773571561025

Epoch: 6| Step: 1
Training loss: 1.410916321723302
Validation loss: 2.5876813312085343

Epoch: 6| Step: 2
Training loss: 1.7308256930735304
Validation loss: 2.5784585910332587

Epoch: 6| Step: 3
Training loss: 2.0918928421759495
Validation loss: 2.6082197971029193

Epoch: 6| Step: 4
Training loss: 1.225393673835539
Validation loss: 2.6275596551871043

Epoch: 6| Step: 5
Training loss: 2.459462913871041
Validation loss: 2.6129930885691675

Epoch: 6| Step: 6
Training loss: 1.9874443286320302
Validation loss: 2.6686866728917176

Epoch: 6| Step: 7
Training loss: 1.417157826643979
Validation loss: 2.606410323959029

Epoch: 6| Step: 8
Training loss: 1.5380467194900902
Validation loss: 2.6458598658715684

Epoch: 6| Step: 9
Training loss: 1.34766071705838
Validation loss: 2.6424081714353256

Epoch: 6| Step: 10
Training loss: 2.0130762353324463
Validation loss: 2.588228100538882

Epoch: 6| Step: 11
Training loss: 1.4517095090994667
Validation loss: 2.551335896141427

Epoch: 6| Step: 12
Training loss: 1.308741683569192
Validation loss: 2.557771242834707

Epoch: 6| Step: 13
Training loss: 1.8382661377058243
Validation loss: 2.545006548355362

Epoch: 377| Step: 0
Training loss: 2.3343638347067635
Validation loss: 2.512696917647397

Epoch: 6| Step: 1
Training loss: 1.2000777557136062
Validation loss: 2.5224438138866216

Epoch: 6| Step: 2
Training loss: 1.5187014002932122
Validation loss: 2.522343590370168

Epoch: 6| Step: 3
Training loss: 1.6024124495325003
Validation loss: 2.5463836601631518

Epoch: 6| Step: 4
Training loss: 1.431269120001203
Validation loss: 2.561809756969898

Epoch: 6| Step: 5
Training loss: 1.524254760629641
Validation loss: 2.6041151016216424

Epoch: 6| Step: 6
Training loss: 1.4720851286549566
Validation loss: 2.535503831888968

Epoch: 6| Step: 7
Training loss: 1.6037387111917654
Validation loss: 2.572508742290109

Epoch: 6| Step: 8
Training loss: 1.9080658690520826
Validation loss: 2.5987069818099227

Epoch: 6| Step: 9
Training loss: 1.7994526825725723
Validation loss: 2.597138952313214

Epoch: 6| Step: 10
Training loss: 1.8401682703157292
Validation loss: 2.5612011695974326

Epoch: 6| Step: 11
Training loss: 2.3723356460546436
Validation loss: 2.5305130282095996

Epoch: 6| Step: 12
Training loss: 1.836232652679623
Validation loss: 2.5274730965691443

Epoch: 6| Step: 13
Training loss: 1.7458635216821308
Validation loss: 2.6059465861395585

Epoch: 378| Step: 0
Training loss: 1.8796448713052476
Validation loss: 2.5896113978548243

Epoch: 6| Step: 1
Training loss: 2.0772551817159632
Validation loss: 2.597329530748734

Epoch: 6| Step: 2
Training loss: 1.427714586446953
Validation loss: 2.5297709881061143

Epoch: 6| Step: 3
Training loss: 1.5999558740730049
Validation loss: 2.5987042218106433

Epoch: 6| Step: 4
Training loss: 1.4862828091143432
Validation loss: 2.554117868360765

Epoch: 6| Step: 5
Training loss: 2.270209573826663
Validation loss: 2.5648091774317603

Epoch: 6| Step: 6
Training loss: 1.278328332373143
Validation loss: 2.5683962124308892

Epoch: 6| Step: 7
Training loss: 1.4035376351953406
Validation loss: 2.611676204577153

Epoch: 6| Step: 8
Training loss: 1.582575198250521
Validation loss: 2.640212483886051

Epoch: 6| Step: 9
Training loss: 1.3252419988494655
Validation loss: 2.6458133836930267

Epoch: 6| Step: 10
Training loss: 2.116856059915189
Validation loss: 2.581085924625148

Epoch: 6| Step: 11
Training loss: 1.8857648187323368
Validation loss: 2.6152535500273357

Epoch: 6| Step: 12
Training loss: 1.5654245092124273
Validation loss: 2.597142586079316

Epoch: 6| Step: 13
Training loss: 1.992400154282863
Validation loss: 2.5686104036563995

Epoch: 379| Step: 0
Training loss: 1.0734453225996012
Validation loss: 2.542539748859802

Epoch: 6| Step: 1
Training loss: 1.073837379035471
Validation loss: 2.5691383717930005

Epoch: 6| Step: 2
Training loss: 1.8116936040780662
Validation loss: 2.567997903854687

Epoch: 6| Step: 3
Training loss: 1.7664432486329327
Validation loss: 2.5538245093800165

Epoch: 6| Step: 4
Training loss: 1.65298023996237
Validation loss: 2.604575999832468

Epoch: 6| Step: 5
Training loss: 2.5729267773963684
Validation loss: 2.5463081774450473

Epoch: 6| Step: 6
Training loss: 1.449725368405626
Validation loss: 2.5886830087267567

Epoch: 6| Step: 7
Training loss: 1.5984245262477141
Validation loss: 2.627476583558575

Epoch: 6| Step: 8
Training loss: 1.780161608742579
Validation loss: 2.62340339667257

Epoch: 6| Step: 9
Training loss: 1.756785452998929
Validation loss: 2.5626492805728094

Epoch: 6| Step: 10
Training loss: 1.2222971038324648
Validation loss: 2.6094476076786925

Epoch: 6| Step: 11
Training loss: 1.7406932769479007
Validation loss: 2.5189975380243776

Epoch: 6| Step: 12
Training loss: 1.9900232264826228
Validation loss: 2.5089444371833527

Epoch: 6| Step: 13
Training loss: 1.8524395117105736
Validation loss: 2.504684367012322

Epoch: 380| Step: 0
Training loss: 1.59895752980298
Validation loss: 2.524343424435322

Epoch: 6| Step: 1
Training loss: 1.9881220006215585
Validation loss: 2.502334617259049

Epoch: 6| Step: 2
Training loss: 1.308149302147964
Validation loss: 2.484475371694405

Epoch: 6| Step: 3
Training loss: 2.0135872172811142
Validation loss: 2.4833597311967965

Epoch: 6| Step: 4
Training loss: 1.5215238632151018
Validation loss: 2.518996370696325

Epoch: 6| Step: 5
Training loss: 2.1203775057178262
Validation loss: 2.5603355012035327

Epoch: 6| Step: 6
Training loss: 1.8137216068624498
Validation loss: 2.582296245325196

Epoch: 6| Step: 7
Training loss: 1.8159477721740893
Validation loss: 2.591030970700083

Epoch: 6| Step: 8
Training loss: 1.804839751191523
Validation loss: 2.5701089331996365

Epoch: 6| Step: 9
Training loss: 1.8582152267809364
Validation loss: 2.5261007452804

Epoch: 6| Step: 10
Training loss: 1.6411515617048682
Validation loss: 2.4644378311747657

Epoch: 6| Step: 11
Training loss: 1.4966056884090642
Validation loss: 2.525917480142746

Epoch: 6| Step: 12
Training loss: 2.4794941106235155
Validation loss: 2.471544205514318

Epoch: 6| Step: 13
Training loss: 1.3556392683348475
Validation loss: 2.5010454852800454

Epoch: 381| Step: 0
Training loss: 1.6573630857234336
Validation loss: 2.472612474002798

Epoch: 6| Step: 1
Training loss: 1.108606313966254
Validation loss: 2.569859968271749

Epoch: 6| Step: 2
Training loss: 1.2785914682095
Validation loss: 2.554868872500743

Epoch: 6| Step: 3
Training loss: 1.6199561850191615
Validation loss: 2.6052080945779132

Epoch: 6| Step: 4
Training loss: 2.002992060827937
Validation loss: 2.6474754063872115

Epoch: 6| Step: 5
Training loss: 1.9746423977015837
Validation loss: 2.6166486346682465

Epoch: 6| Step: 6
Training loss: 1.9852004849828573
Validation loss: 2.6388693396083993

Epoch: 6| Step: 7
Training loss: 1.8154101193724175
Validation loss: 2.622508433303874

Epoch: 6| Step: 8
Training loss: 1.804877465228525
Validation loss: 2.5736055931868886

Epoch: 6| Step: 9
Training loss: 1.3590637376840604
Validation loss: 2.5252076859876325

Epoch: 6| Step: 10
Training loss: 1.2796616361843267
Validation loss: 2.506487915466508

Epoch: 6| Step: 11
Training loss: 2.667368160804473
Validation loss: 2.5509033485465293

Epoch: 6| Step: 12
Training loss: 1.9143122918758648
Validation loss: 2.540983957830755

Epoch: 6| Step: 13
Training loss: 1.9639899216915813
Validation loss: 2.5137798895719468

Epoch: 382| Step: 0
Training loss: 1.9144349027870542
Validation loss: 2.5085932703610747

Epoch: 6| Step: 1
Training loss: 1.9348186273860728
Validation loss: 2.502714146087314

Epoch: 6| Step: 2
Training loss: 1.7242670464676229
Validation loss: 2.5172478316386098

Epoch: 6| Step: 3
Training loss: 1.7566034524728402
Validation loss: 2.5540722680707284

Epoch: 6| Step: 4
Training loss: 1.439919301791808
Validation loss: 2.538632400471104

Epoch: 6| Step: 5
Training loss: 1.139335530529132
Validation loss: 2.5725483933232214

Epoch: 6| Step: 6
Training loss: 2.5017064946016023
Validation loss: 2.5662141183189426

Epoch: 6| Step: 7
Training loss: 1.3207761413193817
Validation loss: 2.543207879061682

Epoch: 6| Step: 8
Training loss: 1.623772230693588
Validation loss: 2.485627104768157

Epoch: 6| Step: 9
Training loss: 1.0504070877935732
Validation loss: 2.5233356860774303

Epoch: 6| Step: 10
Training loss: 1.645836753680703
Validation loss: 2.533102197727216

Epoch: 6| Step: 11
Training loss: 1.9834906342047052
Validation loss: 2.498210457224616

Epoch: 6| Step: 12
Training loss: 1.927750329412512
Validation loss: 2.52798823178043

Epoch: 6| Step: 13
Training loss: 1.3421603714107526
Validation loss: 2.518367117910354

Epoch: 383| Step: 0
Training loss: 1.4110578787684427
Validation loss: 2.4772695340392357

Epoch: 6| Step: 1
Training loss: 1.5444481047275143
Validation loss: 2.541486629509201

Epoch: 6| Step: 2
Training loss: 1.5740015528476137
Validation loss: 2.5308539312246916

Epoch: 6| Step: 3
Training loss: 2.0131693230492567
Validation loss: 2.591993127563573

Epoch: 6| Step: 4
Training loss: 1.4700362883519764
Validation loss: 2.53950476291483

Epoch: 6| Step: 5
Training loss: 1.0891584750866834
Validation loss: 2.585365593277932

Epoch: 6| Step: 6
Training loss: 1.377023335283363
Validation loss: 2.6065460067475397

Epoch: 6| Step: 7
Training loss: 1.2265151190869756
Validation loss: 2.593962695121902

Epoch: 6| Step: 8
Training loss: 1.7556939137270255
Validation loss: 2.587445667329115

Epoch: 6| Step: 9
Training loss: 2.2172623065912767
Validation loss: 2.530787437465787

Epoch: 6| Step: 10
Training loss: 1.2249042454099335
Validation loss: 2.5806199765066027

Epoch: 6| Step: 11
Training loss: 2.279193630675029
Validation loss: 2.5623678623028527

Epoch: 6| Step: 12
Training loss: 2.2900586353108126
Validation loss: 2.670991331318002

Epoch: 6| Step: 13
Training loss: 1.8917655972170133
Validation loss: 2.6984352045540914

Epoch: 384| Step: 0
Training loss: 1.8286984840171923
Validation loss: 2.6814165385232482

Epoch: 6| Step: 1
Training loss: 1.2945443778330656
Validation loss: 2.6263314458100546

Epoch: 6| Step: 2
Training loss: 1.6664412425498885
Validation loss: 2.6571534060392357

Epoch: 6| Step: 3
Training loss: 2.0985305640517313
Validation loss: 2.6011795510524753

Epoch: 6| Step: 4
Training loss: 1.6436281601456737
Validation loss: 2.593158424660353

Epoch: 6| Step: 5
Training loss: 1.2280133650422091
Validation loss: 2.5814619874768017

Epoch: 6| Step: 6
Training loss: 1.8715683369044716
Validation loss: 2.5993117790975444

Epoch: 6| Step: 7
Training loss: 1.3320815448830516
Validation loss: 2.619504550092774

Epoch: 6| Step: 8
Training loss: 2.36580242262647
Validation loss: 2.6434748843881746

Epoch: 6| Step: 9
Training loss: 1.9275085255079318
Validation loss: 2.6187993035117385

Epoch: 6| Step: 10
Training loss: 1.4234354867093937
Validation loss: 2.594315831002775

Epoch: 6| Step: 11
Training loss: 1.7436798273002034
Validation loss: 2.5972131489840597

Epoch: 6| Step: 12
Training loss: 0.9332406242057011
Validation loss: 2.6452779612546196

Epoch: 6| Step: 13
Training loss: 1.9796609227926327
Validation loss: 2.6526552522090476

Epoch: 385| Step: 0
Training loss: 1.6514359092737947
Validation loss: 2.59338313499461

Epoch: 6| Step: 1
Training loss: 1.700349418409004
Validation loss: 2.58510799107372

Epoch: 6| Step: 2
Training loss: 1.1987000875255158
Validation loss: 2.605629416053539

Epoch: 6| Step: 3
Training loss: 1.9100092107740474
Validation loss: 2.606704899083938

Epoch: 6| Step: 4
Training loss: 1.5776270467921567
Validation loss: 2.635522340206421

Epoch: 6| Step: 5
Training loss: 1.8182933561835493
Validation loss: 2.585909740533339

Epoch: 6| Step: 6
Training loss: 1.6397124159271956
Validation loss: 2.5947785463821993

Epoch: 6| Step: 7
Training loss: 1.1031986827935147
Validation loss: 2.5675683025274947

Epoch: 6| Step: 8
Training loss: 2.0561789549638974
Validation loss: 2.5296891348921684

Epoch: 6| Step: 9
Training loss: 1.8783195356772207
Validation loss: 2.484964824532455

Epoch: 6| Step: 10
Training loss: 2.1341763003170477
Validation loss: 2.544140539408961

Epoch: 6| Step: 11
Training loss: 1.4415185569285893
Validation loss: 2.523574675777107

Epoch: 6| Step: 12
Training loss: 1.7722511524654627
Validation loss: 2.535702936900562

Epoch: 6| Step: 13
Training loss: 1.3980153048527542
Validation loss: 2.5733360741490343

Epoch: 386| Step: 0
Training loss: 1.6292621763417368
Validation loss: 2.565705906858042

Epoch: 6| Step: 1
Training loss: 1.3995127034212136
Validation loss: 2.6061783205172566

Epoch: 6| Step: 2
Training loss: 1.4670356322513662
Validation loss: 2.571466312560383

Epoch: 6| Step: 3
Training loss: 1.9124839657379384
Validation loss: 2.559486276197196

Epoch: 6| Step: 4
Training loss: 1.1166437066028392
Validation loss: 2.5349877785934196

Epoch: 6| Step: 5
Training loss: 1.5971973011818508
Validation loss: 2.5792782140551003

Epoch: 6| Step: 6
Training loss: 1.5926494164190672
Validation loss: 2.604736316683411

Epoch: 6| Step: 7
Training loss: 2.1185208447069876
Validation loss: 2.5697124905573157

Epoch: 6| Step: 8
Training loss: 1.758387289379474
Validation loss: 2.5363497596600184

Epoch: 6| Step: 9
Training loss: 1.656344501030616
Validation loss: 2.583254633494331

Epoch: 6| Step: 10
Training loss: 1.9577900829691033
Validation loss: 2.5471879575701895

Epoch: 6| Step: 11
Training loss: 1.287541827661259
Validation loss: 2.5541474124334145

Epoch: 6| Step: 12
Training loss: 1.7885102998193256
Validation loss: 2.555947804639903

Epoch: 6| Step: 13
Training loss: 1.6996838163408527
Validation loss: 2.5438209117656196

Epoch: 387| Step: 0
Training loss: 1.6460475862653545
Validation loss: 2.522599324166612

Epoch: 6| Step: 1
Training loss: 1.549745074197098
Validation loss: 2.5304632573324786

Epoch: 6| Step: 2
Training loss: 1.8326262786779592
Validation loss: 2.5199172717345926

Epoch: 6| Step: 3
Training loss: 1.4358501088112035
Validation loss: 2.5505418338940617

Epoch: 6| Step: 4
Training loss: 1.6946428092509775
Validation loss: 2.5173564188829443

Epoch: 6| Step: 5
Training loss: 1.5636403309568114
Validation loss: 2.541735278178024

Epoch: 6| Step: 6
Training loss: 1.714811077110795
Validation loss: 2.546385158246965

Epoch: 6| Step: 7
Training loss: 1.6403042434307258
Validation loss: 2.55502487428057

Epoch: 6| Step: 8
Training loss: 1.8689763904833587
Validation loss: 2.5952096072383672

Epoch: 6| Step: 9
Training loss: 1.9686621389008636
Validation loss: 2.6083128817632986

Epoch: 6| Step: 10
Training loss: 1.3042775497992751
Validation loss: 2.653781117493265

Epoch: 6| Step: 11
Training loss: 1.4411888889084539
Validation loss: 2.6361983927846557

Epoch: 6| Step: 12
Training loss: 1.8602362168966093
Validation loss: 2.665758161956657

Epoch: 6| Step: 13
Training loss: 1.802635446398496
Validation loss: 2.6535867541583955

Epoch: 388| Step: 0
Training loss: 1.6145793135398128
Validation loss: 2.6548212883975175

Epoch: 6| Step: 1
Training loss: 1.8813353002733042
Validation loss: 2.6239296986672054

Epoch: 6| Step: 2
Training loss: 1.5492853978489687
Validation loss: 2.6573375495070746

Epoch: 6| Step: 3
Training loss: 1.4324088123850467
Validation loss: 2.6722453643323703

Epoch: 6| Step: 4
Training loss: 1.6869763162213331
Validation loss: 2.64079033599242

Epoch: 6| Step: 5
Training loss: 1.3298219498505968
Validation loss: 2.649343045092891

Epoch: 6| Step: 6
Training loss: 1.7368721383295305
Validation loss: 2.617386145193821

Epoch: 6| Step: 7
Training loss: 1.2272727027886643
Validation loss: 2.630863166094576

Epoch: 6| Step: 8
Training loss: 2.3303423057881423
Validation loss: 2.6365429854973548

Epoch: 6| Step: 9
Training loss: 1.3230937128417721
Validation loss: 2.577059739564309

Epoch: 6| Step: 10
Training loss: 1.6548170692786193
Validation loss: 2.619828701073516

Epoch: 6| Step: 11
Training loss: 1.9941642976527072
Validation loss: 2.632734250378327

Epoch: 6| Step: 12
Training loss: 1.4557353538786597
Validation loss: 2.552197696432969

Epoch: 6| Step: 13
Training loss: 1.2375113322962523
Validation loss: 2.615708072487112

Epoch: 389| Step: 0
Training loss: 1.5108928938142403
Validation loss: 2.572096309047218

Epoch: 6| Step: 1
Training loss: 1.0466325393709546
Validation loss: 2.5865256340825806

Epoch: 6| Step: 2
Training loss: 2.420095860813142
Validation loss: 2.580569824678436

Epoch: 6| Step: 3
Training loss: 1.690194274976787
Validation loss: 2.555867862507559

Epoch: 6| Step: 4
Training loss: 1.6755965693508132
Validation loss: 2.5707286586709706

Epoch: 6| Step: 5
Training loss: 1.487144296254634
Validation loss: 2.5759270286324085

Epoch: 6| Step: 6
Training loss: 1.2764169206102025
Validation loss: 2.5416666067363125

Epoch: 6| Step: 7
Training loss: 1.4601830967312333
Validation loss: 2.5484387018671404

Epoch: 6| Step: 8
Training loss: 1.6278110545593745
Validation loss: 2.5345865323633237

Epoch: 6| Step: 9
Training loss: 1.7197904731966618
Validation loss: 2.5642575075334

Epoch: 6| Step: 10
Training loss: 1.3449345623817273
Validation loss: 2.542746882372395

Epoch: 6| Step: 11
Training loss: 1.648418408323981
Validation loss: 2.5268479990580013

Epoch: 6| Step: 12
Training loss: 1.882195842635128
Validation loss: 2.504618051081316

Epoch: 6| Step: 13
Training loss: 1.464942542241535
Validation loss: 2.5175927089981966

Epoch: 390| Step: 0
Training loss: 1.6040243440716577
Validation loss: 2.52274855587287

Epoch: 6| Step: 1
Training loss: 1.3131148396842893
Validation loss: 2.5303740221920648

Epoch: 6| Step: 2
Training loss: 2.339448567486482
Validation loss: 2.5349292545742395

Epoch: 6| Step: 3
Training loss: 1.483309554148747
Validation loss: 2.613010546429764

Epoch: 6| Step: 4
Training loss: 1.5107365061302351
Validation loss: 2.6097684399911696

Epoch: 6| Step: 5
Training loss: 1.5095078814598661
Validation loss: 2.617765880842202

Epoch: 6| Step: 6
Training loss: 1.6324265311330612
Validation loss: 2.5804492530467322

Epoch: 6| Step: 7
Training loss: 1.1649540296988743
Validation loss: 2.5644706188960065

Epoch: 6| Step: 8
Training loss: 1.95325561086722
Validation loss: 2.5770000585137347

Epoch: 6| Step: 9
Training loss: 1.7512942705133776
Validation loss: 2.546704854137983

Epoch: 6| Step: 10
Training loss: 1.2839585030377298
Validation loss: 2.5552758055677947

Epoch: 6| Step: 11
Training loss: 1.4587652202684949
Validation loss: 2.517576751826987

Epoch: 6| Step: 12
Training loss: 1.5914584870864161
Validation loss: 2.5543413929089263

Epoch: 6| Step: 13
Training loss: 1.0796605108175321
Validation loss: 2.591871032957106

Epoch: 391| Step: 0
Training loss: 1.566427482784515
Validation loss: 2.5565429699934428

Epoch: 6| Step: 1
Training loss: 1.1738230471889963
Validation loss: 2.587949924389391

Epoch: 6| Step: 2
Training loss: 1.8025684548975318
Validation loss: 2.596754210991452

Epoch: 6| Step: 3
Training loss: 1.427609126367574
Validation loss: 2.5759072137696855

Epoch: 6| Step: 4
Training loss: 1.22376130594675
Validation loss: 2.6150446227760056

Epoch: 6| Step: 5
Training loss: 1.5917040089858665
Validation loss: 2.6509705979289895

Epoch: 6| Step: 6
Training loss: 2.2354793353745674
Validation loss: 2.6663331379531705

Epoch: 6| Step: 7
Training loss: 2.079287211173356
Validation loss: 2.6124205034198136

Epoch: 6| Step: 8
Training loss: 1.5061437039046186
Validation loss: 2.572373017444647

Epoch: 6| Step: 9
Training loss: 1.4346642096674511
Validation loss: 2.5547148287961114

Epoch: 6| Step: 10
Training loss: 1.9231880478663688
Validation loss: 2.5871187337684685

Epoch: 6| Step: 11
Training loss: 1.4265191663864425
Validation loss: 2.5620071510936784

Epoch: 6| Step: 12
Training loss: 1.9876242640773245
Validation loss: 2.5967361388586507

Epoch: 6| Step: 13
Training loss: 1.353750805700455
Validation loss: 2.630598939401146

Epoch: 392| Step: 0
Training loss: 1.4032218542846027
Validation loss: 2.6047355844216122

Epoch: 6| Step: 1
Training loss: 2.427170802383481
Validation loss: 2.5874566785592013

Epoch: 6| Step: 2
Training loss: 1.2605936330770977
Validation loss: 2.5872815222653545

Epoch: 6| Step: 3
Training loss: 1.3254660074803046
Validation loss: 2.569243791552469

Epoch: 6| Step: 4
Training loss: 1.656799729003405
Validation loss: 2.5776985663497167

Epoch: 6| Step: 5
Training loss: 1.840033713736786
Validation loss: 2.5724770225682567

Epoch: 6| Step: 6
Training loss: 0.8427357405523014
Validation loss: 2.5936348518028693

Epoch: 6| Step: 7
Training loss: 2.0741607025702398
Validation loss: 2.627265694137724

Epoch: 6| Step: 8
Training loss: 1.4310605485956729
Validation loss: 2.633463944040966

Epoch: 6| Step: 9
Training loss: 1.6276135335016928
Validation loss: 2.623995619071428

Epoch: 6| Step: 10
Training loss: 1.43109311905668
Validation loss: 2.6720230477941835

Epoch: 6| Step: 11
Training loss: 1.5331759893846693
Validation loss: 2.6121554152006787

Epoch: 6| Step: 12
Training loss: 2.1141116613746433
Validation loss: 2.594743622577917

Epoch: 6| Step: 13
Training loss: 1.331382078683996
Validation loss: 2.5830109815572087

Epoch: 393| Step: 0
Training loss: 1.3273099305602727
Validation loss: 2.5985966177809803

Epoch: 6| Step: 1
Training loss: 1.6362317073023886
Validation loss: 2.535947553732626

Epoch: 6| Step: 2
Training loss: 2.056036676628924
Validation loss: 2.5690965336735987

Epoch: 6| Step: 3
Training loss: 1.857270404082786
Validation loss: 2.5287793350466723

Epoch: 6| Step: 4
Training loss: 2.0342546981189074
Validation loss: 2.5138679829027337

Epoch: 6| Step: 5
Training loss: 1.6784573330699106
Validation loss: 2.5152720486103908

Epoch: 6| Step: 6
Training loss: 1.148342673610208
Validation loss: 2.5316617261935916

Epoch: 6| Step: 7
Training loss: 1.7404472657554115
Validation loss: 2.5256861380798656

Epoch: 6| Step: 8
Training loss: 1.6065101680012353
Validation loss: 2.4889353317147713

Epoch: 6| Step: 9
Training loss: 1.259159196486027
Validation loss: 2.5308419043837853

Epoch: 6| Step: 10
Training loss: 1.582719591884113
Validation loss: 2.5155812609169454

Epoch: 6| Step: 11
Training loss: 1.3848388394261502
Validation loss: 2.5770615050723373

Epoch: 6| Step: 12
Training loss: 1.5618373228537863
Validation loss: 2.581710864805774

Epoch: 6| Step: 13
Training loss: 1.7887819561612959
Validation loss: 2.5461202021759353

Epoch: 394| Step: 0
Training loss: 1.7719353182851454
Validation loss: 2.5194756553489692

Epoch: 6| Step: 1
Training loss: 1.7732488725143154
Validation loss: 2.5660547860615877

Epoch: 6| Step: 2
Training loss: 1.7684467015193028
Validation loss: 2.562063567670074

Epoch: 6| Step: 3
Training loss: 1.4504723897500167
Validation loss: 2.570177888292333

Epoch: 6| Step: 4
Training loss: 1.51168515663377
Validation loss: 2.5529641065324364

Epoch: 6| Step: 5
Training loss: 1.4228733456422809
Validation loss: 2.5682613765068867

Epoch: 6| Step: 6
Training loss: 1.8871628769697242
Validation loss: 2.600107009226136

Epoch: 6| Step: 7
Training loss: 1.5922618725058972
Validation loss: 2.5914347936380606

Epoch: 6| Step: 8
Training loss: 0.9910243868863381
Validation loss: 2.6107794813715985

Epoch: 6| Step: 9
Training loss: 1.790418419230829
Validation loss: 2.647048345817241

Epoch: 6| Step: 10
Training loss: 1.1148344214623183
Validation loss: 2.6674282853968516

Epoch: 6| Step: 11
Training loss: 1.454769065856552
Validation loss: 2.700104159241637

Epoch: 6| Step: 12
Training loss: 1.7601856403631548
Validation loss: 2.727853886379248

Epoch: 6| Step: 13
Training loss: 1.9248280361700612
Validation loss: 2.6664250284229096

Epoch: 395| Step: 0
Training loss: 1.2508922253662829
Validation loss: 2.6188067537043813

Epoch: 6| Step: 1
Training loss: 1.495998289882478
Validation loss: 2.5207142420819704

Epoch: 6| Step: 2
Training loss: 1.6616141346873448
Validation loss: 2.544722507540038

Epoch: 6| Step: 3
Training loss: 1.6326588827632735
Validation loss: 2.525687585508524

Epoch: 6| Step: 4
Training loss: 1.1908766272869986
Validation loss: 2.5258414723353164

Epoch: 6| Step: 5
Training loss: 2.4863106726238424
Validation loss: 2.4961523487931623

Epoch: 6| Step: 6
Training loss: 1.5116163115577013
Validation loss: 2.506281939245146

Epoch: 6| Step: 7
Training loss: 1.8407028363128328
Validation loss: 2.4808322109552607

Epoch: 6| Step: 8
Training loss: 1.5681456233736575
Validation loss: 2.5505286768851803

Epoch: 6| Step: 9
Training loss: 1.2036587410596076
Validation loss: 2.6739024450814166

Epoch: 6| Step: 10
Training loss: 1.2231793731782805
Validation loss: 2.7842393590196237

Epoch: 6| Step: 11
Training loss: 2.5479657230556887
Validation loss: 2.8039799243101307

Epoch: 6| Step: 12
Training loss: 2.3248616331212446
Validation loss: 2.8472956815924686

Epoch: 6| Step: 13
Training loss: 1.7055835302559708
Validation loss: 2.666548716400214

Epoch: 396| Step: 0
Training loss: 1.953068480627536
Validation loss: 2.5405820788972657

Epoch: 6| Step: 1
Training loss: 1.631364755503771
Validation loss: 2.5182391024804125

Epoch: 6| Step: 2
Training loss: 1.536279476121992
Validation loss: 2.556553197288211

Epoch: 6| Step: 3
Training loss: 2.090089245218614
Validation loss: 2.582850831615262

Epoch: 6| Step: 4
Training loss: 1.3929109536769937
Validation loss: 2.5676232582426723

Epoch: 6| Step: 5
Training loss: 2.4870959083093087
Validation loss: 2.5598273489643475

Epoch: 6| Step: 6
Training loss: 1.6690477369920114
Validation loss: 2.4976794917433547

Epoch: 6| Step: 7
Training loss: 1.654398765263567
Validation loss: 2.476302846299413

Epoch: 6| Step: 8
Training loss: 2.42780645728418
Validation loss: 2.5188428781201044

Epoch: 6| Step: 9
Training loss: 1.5963029049415876
Validation loss: 2.532268131031134

Epoch: 6| Step: 10
Training loss: 1.4255872620601122
Validation loss: 2.7114882702126772

Epoch: 6| Step: 11
Training loss: 2.2319270242157474
Validation loss: 2.8548842361104594

Epoch: 6| Step: 12
Training loss: 1.8327758187007979
Validation loss: 2.746981843006779

Epoch: 6| Step: 13
Training loss: 1.6773706825769905
Validation loss: 2.592431809691293

Epoch: 397| Step: 0
Training loss: 1.268544726373035
Validation loss: 2.483401301646459

Epoch: 6| Step: 1
Training loss: 1.7775474347788287
Validation loss: 2.474825750504222

Epoch: 6| Step: 2
Training loss: 1.4237206186908473
Validation loss: 2.49319147597215

Epoch: 6| Step: 3
Training loss: 1.8299243907213314
Validation loss: 2.527621458853721

Epoch: 6| Step: 4
Training loss: 2.0798354602803557
Validation loss: 2.514586366547844

Epoch: 6| Step: 5
Training loss: 1.9175586145387187
Validation loss: 2.52623446538252

Epoch: 6| Step: 6
Training loss: 2.2303190966104105
Validation loss: 2.5237434130918524

Epoch: 6| Step: 7
Training loss: 1.7166766752796931
Validation loss: 2.4891623828784244

Epoch: 6| Step: 8
Training loss: 1.8291399493978124
Validation loss: 2.493554293570551

Epoch: 6| Step: 9
Training loss: 2.069839135521414
Validation loss: 2.5212025385159196

Epoch: 6| Step: 10
Training loss: 1.8529065239762172
Validation loss: 2.55108491220472

Epoch: 6| Step: 11
Training loss: 1.6188138441066464
Validation loss: 2.559883798058056

Epoch: 6| Step: 12
Training loss: 1.49949748840834
Validation loss: 2.615043483127044

Epoch: 6| Step: 13
Training loss: 2.283075934425107
Validation loss: 2.6307158229209775

Epoch: 398| Step: 0
Training loss: 1.4633231854068809
Validation loss: 2.6081541940356447

Epoch: 6| Step: 1
Training loss: 1.2794054291073722
Validation loss: 2.6755325832979007

Epoch: 6| Step: 2
Training loss: 2.01844460270694
Validation loss: 2.5810074385129735

Epoch: 6| Step: 3
Training loss: 1.6068752838098905
Validation loss: 2.5784605944526238

Epoch: 6| Step: 4
Training loss: 1.83947244772946
Validation loss: 2.576659230949

Epoch: 6| Step: 5
Training loss: 1.617445699378759
Validation loss: 2.55522924622786

Epoch: 6| Step: 6
Training loss: 1.4627966653267932
Validation loss: 2.5450146985831803

Epoch: 6| Step: 7
Training loss: 1.3190181640317138
Validation loss: 2.57935903280665

Epoch: 6| Step: 8
Training loss: 2.181513961079331
Validation loss: 2.5649606009389103

Epoch: 6| Step: 9
Training loss: 2.2185265871853095
Validation loss: 2.5440392572649877

Epoch: 6| Step: 10
Training loss: 2.3695726118744616
Validation loss: 2.5134803127911294

Epoch: 6| Step: 11
Training loss: 1.821575332520486
Validation loss: 2.5038004439718113

Epoch: 6| Step: 12
Training loss: 1.072529300031598
Validation loss: 2.540711697721471

Epoch: 6| Step: 13
Training loss: 1.6037573684439859
Validation loss: 2.523709128043982

Epoch: 399| Step: 0
Training loss: 1.5385733664657668
Validation loss: 2.5221860634690145

Epoch: 6| Step: 1
Training loss: 1.6716338366970438
Validation loss: 2.5425947766938934

Epoch: 6| Step: 2
Training loss: 1.4653511491015865
Validation loss: 2.526192404323089

Epoch: 6| Step: 3
Training loss: 1.7580123448681646
Validation loss: 2.5281504582214476

Epoch: 6| Step: 4
Training loss: 1.4913373192853414
Validation loss: 2.489320195761886

Epoch: 6| Step: 5
Training loss: 1.4287411418650209
Validation loss: 2.4856441782709546

Epoch: 6| Step: 6
Training loss: 1.2904859140004992
Validation loss: 2.484126080532617

Epoch: 6| Step: 7
Training loss: 1.9946711597613016
Validation loss: 2.5252047669754503

Epoch: 6| Step: 8
Training loss: 1.9342909047422783
Validation loss: 2.462997914174898

Epoch: 6| Step: 9
Training loss: 1.8380509569080041
Validation loss: 2.4791870169779404

Epoch: 6| Step: 10
Training loss: 1.5426701123922557
Validation loss: 2.4909157612386856

Epoch: 6| Step: 11
Training loss: 1.6621393543950986
Validation loss: 2.479360666351389

Epoch: 6| Step: 12
Training loss: 1.8103798930212587
Validation loss: 2.5412959365208003

Epoch: 6| Step: 13
Training loss: 1.4902657321815624
Validation loss: 2.5388861961777103

Epoch: 400| Step: 0
Training loss: 1.52008768205216
Validation loss: 2.521160582641771

Epoch: 6| Step: 1
Training loss: 1.116671729906664
Validation loss: 2.473016135173791

Epoch: 6| Step: 2
Training loss: 1.392919554726888
Validation loss: 2.5070929044498866

Epoch: 6| Step: 3
Training loss: 1.3980901276046909
Validation loss: 2.523149046734084

Epoch: 6| Step: 4
Training loss: 1.2913925382482752
Validation loss: 2.5493707890346022

Epoch: 6| Step: 5
Training loss: 1.887875157140364
Validation loss: 2.5492448526991205

Epoch: 6| Step: 6
Training loss: 1.6950078593834255
Validation loss: 2.5464451589001422

Epoch: 6| Step: 7
Training loss: 1.085290620090657
Validation loss: 2.524677503405249

Epoch: 6| Step: 8
Training loss: 1.3137513507868739
Validation loss: 2.518114015667779

Epoch: 6| Step: 9
Training loss: 1.73705661797364
Validation loss: 2.4943880353278116

Epoch: 6| Step: 10
Training loss: 1.301930146425166
Validation loss: 2.521373522759769

Epoch: 6| Step: 11
Training loss: 2.528753108778366
Validation loss: 2.500334606030816

Epoch: 6| Step: 12
Training loss: 1.9250719106544556
Validation loss: 2.512000021207611

Epoch: 6| Step: 13
Training loss: 1.2155736956520395
Validation loss: 2.4890322747064646

Testing loss: 2.274458479791283
