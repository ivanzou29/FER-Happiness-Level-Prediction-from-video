Epoch: 1| Step: 0
Training loss: 6.401837573893121
Validation loss: 5.914350091953711

Epoch: 6| Step: 1
Training loss: 6.422312774958452
Validation loss: 5.912534354219642

Epoch: 6| Step: 2
Training loss: 5.3655985738806695
Validation loss: 5.910970372521956

Epoch: 6| Step: 3
Training loss: 6.183609172635537
Validation loss: 5.909346829943502

Epoch: 6| Step: 4
Training loss: 5.86886178622154
Validation loss: 5.90799793570174

Epoch: 6| Step: 5
Training loss: 6.069772664421124
Validation loss: 5.906672790572965

Epoch: 6| Step: 6
Training loss: 5.838126184504015
Validation loss: 5.905377385771355

Epoch: 6| Step: 7
Training loss: 6.293925235736986
Validation loss: 5.9041495919457425

Epoch: 6| Step: 8
Training loss: 6.5785297622651075
Validation loss: 5.903003937621012

Epoch: 6| Step: 9
Training loss: 5.710702372040697
Validation loss: 5.901790489457018

Epoch: 6| Step: 10
Training loss: 5.560037131974529
Validation loss: 5.90061140610194

Epoch: 6| Step: 11
Training loss: 5.511241694838006
Validation loss: 5.89937510333105

Epoch: 6| Step: 12
Training loss: 6.145172842278288
Validation loss: 5.898200980659093

Epoch: 6| Step: 13
Training loss: 6.208301143008077
Validation loss: 5.896940857439157

Epoch: 2| Step: 0
Training loss: 5.697137736394581
Validation loss: 5.895690143405533

Epoch: 6| Step: 1
Training loss: 6.350422774531094
Validation loss: 5.894431370992222

Epoch: 6| Step: 2
Training loss: 6.721923930097803
Validation loss: 5.893098131566891

Epoch: 6| Step: 3
Training loss: 4.675214613613969
Validation loss: 5.891748943410828

Epoch: 6| Step: 4
Training loss: 6.3210264729224725
Validation loss: 5.890276344565188

Epoch: 6| Step: 5
Training loss: 5.753207763209181
Validation loss: 5.88881017924236

Epoch: 6| Step: 6
Training loss: 6.170782142167535
Validation loss: 5.88728179635274

Epoch: 6| Step: 7
Training loss: 6.205764170644127
Validation loss: 5.885558414158867

Epoch: 6| Step: 8
Training loss: 6.155904227678625
Validation loss: 5.883902980181782

Epoch: 6| Step: 9
Training loss: 5.944149109029071
Validation loss: 5.882178472942211

Epoch: 6| Step: 10
Training loss: 5.891610546285418
Validation loss: 5.880374965778898

Epoch: 6| Step: 11
Training loss: 5.721558261773718
Validation loss: 5.878358030051922

Epoch: 6| Step: 12
Training loss: 6.483820806513437
Validation loss: 5.876314624852167

Epoch: 6| Step: 13
Training loss: 5.680298994012283
Validation loss: 5.874152886752484

Epoch: 3| Step: 0
Training loss: 5.328319736177391
Validation loss: 5.871821253735116

Epoch: 6| Step: 1
Training loss: 6.0707856807614515
Validation loss: 5.869652851113968

Epoch: 6| Step: 2
Training loss: 6.150117404716505
Validation loss: 5.867124541072268

Epoch: 6| Step: 3
Training loss: 7.163815958987101
Validation loss: 5.864433336344183

Epoch: 6| Step: 4
Training loss: 6.228002977491781
Validation loss: 5.861702527083028

Epoch: 6| Step: 5
Training loss: 6.162513605996485
Validation loss: 5.8587372971121585

Epoch: 6| Step: 6
Training loss: 6.005896531897254
Validation loss: 5.855656236357661

Epoch: 6| Step: 7
Training loss: 5.594711476813533
Validation loss: 5.852349765244719

Epoch: 6| Step: 8
Training loss: 6.261941412038501
Validation loss: 5.848868374176598

Epoch: 6| Step: 9
Training loss: 4.988138434293184
Validation loss: 5.8452270055611475

Epoch: 6| Step: 10
Training loss: 5.411659841545899
Validation loss: 5.841728554405531

Epoch: 6| Step: 11
Training loss: 5.533513355007723
Validation loss: 5.837635070850035

Epoch: 6| Step: 12
Training loss: 6.332423730414262
Validation loss: 5.833654240455135

Epoch: 6| Step: 13
Training loss: 6.020174124597935
Validation loss: 5.829088310422195

Epoch: 4| Step: 0
Training loss: 6.04792118140234
Validation loss: 5.824413982814473

Epoch: 6| Step: 1
Training loss: 5.235932166934393
Validation loss: 5.819799372436528

Epoch: 6| Step: 2
Training loss: 6.3528488376863015
Validation loss: 5.814691684122959

Epoch: 6| Step: 3
Training loss: 5.920873874397548
Validation loss: 5.809126582587683

Epoch: 6| Step: 4
Training loss: 6.043648265467594
Validation loss: 5.803405647564954

Epoch: 6| Step: 5
Training loss: 6.095371754350219
Validation loss: 5.7973524584193

Epoch: 6| Step: 6
Training loss: 5.657396063429346
Validation loss: 5.791247162846003

Epoch: 6| Step: 7
Training loss: 5.657337400330799
Validation loss: 5.784309498673502

Epoch: 6| Step: 8
Training loss: 6.528026314551479
Validation loss: 5.777174769422069

Epoch: 6| Step: 9
Training loss: 5.711887264987789
Validation loss: 5.7698045311604345

Epoch: 6| Step: 10
Training loss: 5.697698483192235
Validation loss: 5.761933120791363

Epoch: 6| Step: 11
Training loss: 5.47481527495877
Validation loss: 5.753876029300163

Epoch: 6| Step: 12
Training loss: 6.5249895819219095
Validation loss: 5.745826948391486

Epoch: 6| Step: 13
Training loss: 5.498041497832628
Validation loss: 5.737945941557385

Epoch: 5| Step: 0
Training loss: 6.276918046684608
Validation loss: 5.729401277304512

Epoch: 6| Step: 1
Training loss: 5.972097366959887
Validation loss: 5.72043989050611

Epoch: 6| Step: 2
Training loss: 6.166083368431318
Validation loss: 5.712031741883088

Epoch: 6| Step: 3
Training loss: 5.774933864990969
Validation loss: 5.70286527416761

Epoch: 6| Step: 4
Training loss: 5.462279584614655
Validation loss: 5.694524960866145

Epoch: 6| Step: 5
Training loss: 5.938283768171417
Validation loss: 5.685713854335815

Epoch: 6| Step: 6
Training loss: 5.8421641763291445
Validation loss: 5.676818122851829

Epoch: 6| Step: 7
Training loss: 5.184357576070781
Validation loss: 5.6682217745452474

Epoch: 6| Step: 8
Training loss: 5.437137986332687
Validation loss: 5.659987140636416

Epoch: 6| Step: 9
Training loss: 6.5238889252488335
Validation loss: 5.651506967915948

Epoch: 6| Step: 10
Training loss: 5.3383004582195035
Validation loss: 5.643114549722437

Epoch: 6| Step: 11
Training loss: 5.251813666101194
Validation loss: 5.634880740853651

Epoch: 6| Step: 12
Training loss: 5.644088231425101
Validation loss: 5.627050915986846

Epoch: 6| Step: 13
Training loss: 6.090582860856664
Validation loss: 5.619176180995215

Epoch: 6| Step: 0
Training loss: 5.143571281804682
Validation loss: 5.611378318207174

Epoch: 6| Step: 1
Training loss: 6.075381407518887
Validation loss: 5.604085002242708

Epoch: 6| Step: 2
Training loss: 5.7187886888206325
Validation loss: 5.59666560108083

Epoch: 6| Step: 3
Training loss: 6.574894707710571
Validation loss: 5.589679224208591

Epoch: 6| Step: 4
Training loss: 4.888204444792771
Validation loss: 5.582483378760147

Epoch: 6| Step: 5
Training loss: 5.687154235390415
Validation loss: 5.575910312020681

Epoch: 6| Step: 6
Training loss: 6.213186257604039
Validation loss: 5.5691461470014385

Epoch: 6| Step: 7
Training loss: 5.512079844822482
Validation loss: 5.563029974789539

Epoch: 6| Step: 8
Training loss: 6.075519856631226
Validation loss: 5.556559759086813

Epoch: 6| Step: 9
Training loss: 5.182648193772662
Validation loss: 5.550325765585834

Epoch: 6| Step: 10
Training loss: 5.300639117590599
Validation loss: 5.544296281313304

Epoch: 6| Step: 11
Training loss: 5.6214853114576036
Validation loss: 5.538408751079944

Epoch: 6| Step: 12
Training loss: 6.101863213820495
Validation loss: 5.532596977292946

Epoch: 6| Step: 13
Training loss: 5.252724984827909
Validation loss: 5.526841499146269

Epoch: 7| Step: 0
Training loss: 5.717808380150488
Validation loss: 5.5208608470687

Epoch: 6| Step: 1
Training loss: 6.8885364784149274
Validation loss: 5.515216585335003

Epoch: 6| Step: 2
Training loss: 5.624758566867282
Validation loss: 5.509486686626065

Epoch: 6| Step: 3
Training loss: 5.614883650731766
Validation loss: 5.504080992307912

Epoch: 6| Step: 4
Training loss: 5.443442594167865
Validation loss: 5.498543257408542

Epoch: 6| Step: 5
Training loss: 5.5319272073961425
Validation loss: 5.492828143664104

Epoch: 6| Step: 6
Training loss: 4.761431941218878
Validation loss: 5.487307786869935

Epoch: 6| Step: 7
Training loss: 6.064686803569549
Validation loss: 5.482245978439795

Epoch: 6| Step: 8
Training loss: 5.965123218117478
Validation loss: 5.47726774005622

Epoch: 6| Step: 9
Training loss: 5.82071851299892
Validation loss: 5.4722190680497445

Epoch: 6| Step: 10
Training loss: 4.542969169846283
Validation loss: 5.466838306353139

Epoch: 6| Step: 11
Training loss: 4.398696810462287
Validation loss: 5.462318023979261

Epoch: 6| Step: 12
Training loss: 6.063608599106976
Validation loss: 5.457337858943024

Epoch: 6| Step: 13
Training loss: 5.572427869614873
Validation loss: 5.452381597087756

Epoch: 8| Step: 0
Training loss: 5.321480554196951
Validation loss: 5.447493887470861

Epoch: 6| Step: 1
Training loss: 5.741382609936533
Validation loss: 5.442540868589064

Epoch: 6| Step: 2
Training loss: 6.320236450794014
Validation loss: 5.438170263846395

Epoch: 6| Step: 3
Training loss: 5.601040825167704
Validation loss: 5.433101731417318

Epoch: 6| Step: 4
Training loss: 5.576615500632488
Validation loss: 5.427850543345346

Epoch: 6| Step: 5
Training loss: 5.9203126804153445
Validation loss: 5.4233805886530835

Epoch: 6| Step: 6
Training loss: 5.317785707733438
Validation loss: 5.418112762304753

Epoch: 6| Step: 7
Training loss: 5.069837174669531
Validation loss: 5.413420022088712

Epoch: 6| Step: 8
Training loss: 5.270555129518239
Validation loss: 5.408589733298062

Epoch: 6| Step: 9
Training loss: 5.561107161083633
Validation loss: 5.404082641105198

Epoch: 6| Step: 10
Training loss: 5.596728677290604
Validation loss: 5.399752319212986

Epoch: 6| Step: 11
Training loss: 5.010678332733601
Validation loss: 5.395161099578517

Epoch: 6| Step: 12
Training loss: 5.4431592933940225
Validation loss: 5.390420189251584

Epoch: 6| Step: 13
Training loss: 5.652606612646416
Validation loss: 5.38640815073614

Epoch: 9| Step: 0
Training loss: 5.058940248147449
Validation loss: 5.3821751808282885

Epoch: 6| Step: 1
Training loss: 6.318077720248586
Validation loss: 5.377967252011913

Epoch: 6| Step: 2
Training loss: 4.545082814015041
Validation loss: 5.373380313475442

Epoch: 6| Step: 3
Training loss: 5.965111707103452
Validation loss: 5.369230885520039

Epoch: 6| Step: 4
Training loss: 5.830645059850998
Validation loss: 5.364904874282422

Epoch: 6| Step: 5
Training loss: 5.325922446430806
Validation loss: 5.360432008063311

Epoch: 6| Step: 6
Training loss: 6.054301903044077
Validation loss: 5.356354302392665

Epoch: 6| Step: 7
Training loss: 5.652092686200257
Validation loss: 5.352114609502825

Epoch: 6| Step: 8
Training loss: 4.291851866840165
Validation loss: 5.34769361105352

Epoch: 6| Step: 9
Training loss: 5.2370573088893915
Validation loss: 5.343335022159595

Epoch: 6| Step: 10
Training loss: 5.656692740463262
Validation loss: 5.339064776835311

Epoch: 6| Step: 11
Training loss: 5.044744933743747
Validation loss: 5.334588807075972

Epoch: 6| Step: 12
Training loss: 5.300401442097352
Validation loss: 5.330511161049923

Epoch: 6| Step: 13
Training loss: 5.984725583317683
Validation loss: 5.326259312496596

Epoch: 10| Step: 0
Training loss: 5.717089469258962
Validation loss: 5.322140492126082

Epoch: 6| Step: 1
Training loss: 6.0417572365472525
Validation loss: 5.317863569195067

Epoch: 6| Step: 2
Training loss: 4.877292387516376
Validation loss: 5.313086204349774

Epoch: 6| Step: 3
Training loss: 4.246783666351403
Validation loss: 5.308757915115175

Epoch: 6| Step: 4
Training loss: 5.384488624086778
Validation loss: 5.304343121098983

Epoch: 6| Step: 5
Training loss: 5.337270634388613
Validation loss: 5.300065901484522

Epoch: 6| Step: 6
Training loss: 5.308598780120869
Validation loss: 5.2963628080549325

Epoch: 6| Step: 7
Training loss: 6.038053638039318
Validation loss: 5.292235286329086

Epoch: 6| Step: 8
Training loss: 5.231593608623573
Validation loss: 5.288324346830273

Epoch: 6| Step: 9
Training loss: 5.513941002553317
Validation loss: 5.284293838139383

Epoch: 6| Step: 10
Training loss: 6.069193811816412
Validation loss: 5.280632840725377

Epoch: 6| Step: 11
Training loss: 5.148202801045087
Validation loss: 5.27668625213272

Epoch: 6| Step: 12
Training loss: 5.521764866195302
Validation loss: 5.2729174246825785

Epoch: 6| Step: 13
Training loss: 5.108534250876939
Validation loss: 5.268814343549409

Epoch: 11| Step: 0
Training loss: 6.139085105801946
Validation loss: 5.264744021770331

Epoch: 6| Step: 1
Training loss: 5.1407999397356186
Validation loss: 5.260699193436636

Epoch: 6| Step: 2
Training loss: 4.652794291655176
Validation loss: 5.256890362027854

Epoch: 6| Step: 3
Training loss: 5.704618744343091
Validation loss: 5.252980355096821

Epoch: 6| Step: 4
Training loss: 5.6258498503511705
Validation loss: 5.249147164239469

Epoch: 6| Step: 5
Training loss: 5.5643537197158155
Validation loss: 5.245458576288393

Epoch: 6| Step: 6
Training loss: 5.288719898662048
Validation loss: 5.241304159238663

Epoch: 6| Step: 7
Training loss: 5.845435241209989
Validation loss: 5.237439100447081

Epoch: 6| Step: 8
Training loss: 5.347209680495753
Validation loss: 5.233240443010697

Epoch: 6| Step: 9
Training loss: 4.524221296380522
Validation loss: 5.229475257957735

Epoch: 6| Step: 10
Training loss: 5.806537153782942
Validation loss: 5.2255014693015065

Epoch: 6| Step: 11
Training loss: 5.013201642099159
Validation loss: 5.221600878841185

Epoch: 6| Step: 12
Training loss: 4.620439497615248
Validation loss: 5.217651708469157

Epoch: 6| Step: 13
Training loss: 5.510196597266503
Validation loss: 5.214148070452764

Epoch: 12| Step: 0
Training loss: 4.723239405166292
Validation loss: 5.210721050992512

Epoch: 6| Step: 1
Training loss: 5.358803943872392
Validation loss: 5.206536687595366

Epoch: 6| Step: 2
Training loss: 5.490968397992645
Validation loss: 5.202253480613021

Epoch: 6| Step: 3
Training loss: 5.541006847289928
Validation loss: 5.199113920718405

Epoch: 6| Step: 4
Training loss: 5.383948927287084
Validation loss: 5.19480091147948

Epoch: 6| Step: 5
Training loss: 5.5911238488835755
Validation loss: 5.191444551830348

Epoch: 6| Step: 6
Training loss: 5.655408596451919
Validation loss: 5.1872404715333325

Epoch: 6| Step: 7
Training loss: 6.012223825436678
Validation loss: 5.183165642989036

Epoch: 6| Step: 8
Training loss: 5.694873766751839
Validation loss: 5.178623801782416

Epoch: 6| Step: 9
Training loss: 5.139720895217687
Validation loss: 5.174744853734258

Epoch: 6| Step: 10
Training loss: 5.516474412562611
Validation loss: 5.170907367029786

Epoch: 6| Step: 11
Training loss: 4.871446537069394
Validation loss: 5.167060185899861

Epoch: 6| Step: 12
Training loss: 4.671633098552916
Validation loss: 5.162190785357229

Epoch: 6| Step: 13
Training loss: 4.410891205574786
Validation loss: 5.158286415014084

Epoch: 13| Step: 0
Training loss: 5.358532007943161
Validation loss: 5.154830829793453

Epoch: 6| Step: 1
Training loss: 5.471590013124934
Validation loss: 5.150674506647982

Epoch: 6| Step: 2
Training loss: 4.920778570212294
Validation loss: 5.146722518555254

Epoch: 6| Step: 3
Training loss: 4.81741834712847
Validation loss: 5.142903759154718

Epoch: 6| Step: 4
Training loss: 4.527157744305061
Validation loss: 5.138738345899507

Epoch: 6| Step: 5
Training loss: 6.274520077533352
Validation loss: 5.13533522391075

Epoch: 6| Step: 6
Training loss: 5.810715268043129
Validation loss: 5.1313748913278525

Epoch: 6| Step: 7
Training loss: 6.118303959518884
Validation loss: 5.127173203361802

Epoch: 6| Step: 8
Training loss: 4.886395365186591
Validation loss: 5.122666083380689

Epoch: 6| Step: 9
Training loss: 5.242260632523591
Validation loss: 5.118843474600103

Epoch: 6| Step: 10
Training loss: 5.379015819622038
Validation loss: 5.1143511417097685

Epoch: 6| Step: 11
Training loss: 5.417550508820845
Validation loss: 5.1102346772256135

Epoch: 6| Step: 12
Training loss: 4.379319157049058
Validation loss: 5.105457729102967

Epoch: 6| Step: 13
Training loss: 4.507777592409794
Validation loss: 5.101668461414326

Epoch: 14| Step: 0
Training loss: 5.769152381560064
Validation loss: 5.096437022439282

Epoch: 6| Step: 1
Training loss: 5.076038295724638
Validation loss: 5.0917554511504655

Epoch: 6| Step: 2
Training loss: 4.57708332592503
Validation loss: 5.087897122916516

Epoch: 6| Step: 3
Training loss: 4.861978992311638
Validation loss: 5.082768810173179

Epoch: 6| Step: 4
Training loss: 5.7894258989981235
Validation loss: 5.078464938792216

Epoch: 6| Step: 5
Training loss: 6.3161263200377675
Validation loss: 5.073500733431355

Epoch: 6| Step: 6
Training loss: 4.475403853792528
Validation loss: 5.067861818012977

Epoch: 6| Step: 7
Training loss: 4.434254493715834
Validation loss: 5.0635635451886785

Epoch: 6| Step: 8
Training loss: 5.214234734452103
Validation loss: 5.058040491433029

Epoch: 6| Step: 9
Training loss: 5.397264366925561
Validation loss: 5.053965938111666

Epoch: 6| Step: 10
Training loss: 5.688552591364239
Validation loss: 5.048462010974153

Epoch: 6| Step: 11
Training loss: 5.392622337173884
Validation loss: 5.043963242899318

Epoch: 6| Step: 12
Training loss: 4.258491112062308
Validation loss: 5.039912441441725

Epoch: 6| Step: 13
Training loss: 4.960739876723201
Validation loss: 5.035467682236605

Epoch: 15| Step: 0
Training loss: 5.306649970087466
Validation loss: 5.031086257576259

Epoch: 6| Step: 1
Training loss: 4.098603378237471
Validation loss: 5.026757961746057

Epoch: 6| Step: 2
Training loss: 4.9924856941579785
Validation loss: 5.021763294673283

Epoch: 6| Step: 3
Training loss: 4.721096238674257
Validation loss: 5.018124441873033

Epoch: 6| Step: 4
Training loss: 5.572949313724711
Validation loss: 5.013208173413717

Epoch: 6| Step: 5
Training loss: 5.922906549234657
Validation loss: 5.008118332973028

Epoch: 6| Step: 6
Training loss: 5.081320358859051
Validation loss: 5.003285854215133

Epoch: 6| Step: 7
Training loss: 4.784818626482103
Validation loss: 4.999484067365319

Epoch: 6| Step: 8
Training loss: 5.401310422630439
Validation loss: 4.994406209584098

Epoch: 6| Step: 9
Training loss: 5.641702564901002
Validation loss: 4.989900243114946

Epoch: 6| Step: 10
Training loss: 4.896584289529567
Validation loss: 4.984970009425638

Epoch: 6| Step: 11
Training loss: 5.095052915229083
Validation loss: 4.980118818767863

Epoch: 6| Step: 12
Training loss: 4.827735662965582
Validation loss: 4.976508554977688

Epoch: 6| Step: 13
Training loss: 5.154521860616391
Validation loss: 4.97204442242076

Epoch: 16| Step: 0
Training loss: 3.939903736584467
Validation loss: 4.967049041639062

Epoch: 6| Step: 1
Training loss: 5.434736930986927
Validation loss: 4.962889359939536

Epoch: 6| Step: 2
Training loss: 5.246874832780391
Validation loss: 4.957980915442684

Epoch: 6| Step: 3
Training loss: 5.20003236613838
Validation loss: 4.9545362449647365

Epoch: 6| Step: 4
Training loss: 5.980182663287075
Validation loss: 4.949250255023788

Epoch: 6| Step: 5
Training loss: 4.88494172326021
Validation loss: 4.944969643453693

Epoch: 6| Step: 6
Training loss: 5.07407628564923
Validation loss: 4.939710307436752

Epoch: 6| Step: 7
Training loss: 4.688328377325208
Validation loss: 4.934415763378982

Epoch: 6| Step: 8
Training loss: 4.697537268003027
Validation loss: 4.9303838577582315

Epoch: 6| Step: 9
Training loss: 5.1018834619196065
Validation loss: 4.925705225713547

Epoch: 6| Step: 10
Training loss: 4.638360186896731
Validation loss: 4.922376334679461

Epoch: 6| Step: 11
Training loss: 5.574953860789052
Validation loss: 4.919130042265741

Epoch: 6| Step: 12
Training loss: 4.921029929622183
Validation loss: 4.913044656807461

Epoch: 6| Step: 13
Training loss: 5.198174948636383
Validation loss: 4.908844183010267

Epoch: 17| Step: 0
Training loss: 5.362839360380751
Validation loss: 4.904649218227275

Epoch: 6| Step: 1
Training loss: 5.014828627635324
Validation loss: 4.899488386057166

Epoch: 6| Step: 2
Training loss: 5.523591855494392
Validation loss: 4.895621821386523

Epoch: 6| Step: 3
Training loss: 4.721341463616506
Validation loss: 4.89130296974347

Epoch: 6| Step: 4
Training loss: 4.767957173007922
Validation loss: 4.886155057088635

Epoch: 6| Step: 5
Training loss: 5.306986921381644
Validation loss: 4.8819499238105415

Epoch: 6| Step: 6
Training loss: 4.704822728124427
Validation loss: 4.877105258314977

Epoch: 6| Step: 7
Training loss: 5.362032128755355
Validation loss: 4.873256926000634

Epoch: 6| Step: 8
Training loss: 4.7977226576986824
Validation loss: 4.8692919904876435

Epoch: 6| Step: 9
Training loss: 4.974646949701046
Validation loss: 4.864056751359336

Epoch: 6| Step: 10
Training loss: 5.060056308538577
Validation loss: 4.86011021194765

Epoch: 6| Step: 11
Training loss: 4.331848746085205
Validation loss: 4.855447406471258

Epoch: 6| Step: 12
Training loss: 4.897154328170189
Validation loss: 4.851281789131465

Epoch: 6| Step: 13
Training loss: 5.066310249307313
Validation loss: 4.84750693042844

Epoch: 18| Step: 0
Training loss: 4.2274187105688705
Validation loss: 4.843105215820778

Epoch: 6| Step: 1
Training loss: 4.834828288077594
Validation loss: 4.839219860539773

Epoch: 6| Step: 2
Training loss: 3.784721861361954
Validation loss: 4.83467650111384

Epoch: 6| Step: 3
Training loss: 5.961630844649881
Validation loss: 4.8307443568838275

Epoch: 6| Step: 4
Training loss: 5.336515113319506
Validation loss: 4.826593051071517

Epoch: 6| Step: 5
Training loss: 4.850611791662776
Validation loss: 4.821905415954714

Epoch: 6| Step: 6
Training loss: 5.692093220594125
Validation loss: 4.818632734812204

Epoch: 6| Step: 7
Training loss: 5.555609045830816
Validation loss: 4.81413099386108

Epoch: 6| Step: 8
Training loss: 5.28219541856806
Validation loss: 4.809450446634502

Epoch: 6| Step: 9
Training loss: 4.858609547077953
Validation loss: 4.806223157155414

Epoch: 6| Step: 10
Training loss: 5.2883282240490175
Validation loss: 4.802322889243081

Epoch: 6| Step: 11
Training loss: 4.215617507464153
Validation loss: 4.797573871212787

Epoch: 6| Step: 12
Training loss: 4.370754689011232
Validation loss: 4.792342870793313

Epoch: 6| Step: 13
Training loss: 4.382660616658623
Validation loss: 4.788783436081528

Epoch: 19| Step: 0
Training loss: 5.054299388294935
Validation loss: 4.783926121380499

Epoch: 6| Step: 1
Training loss: 4.344005769293732
Validation loss: 4.780093616276466

Epoch: 6| Step: 2
Training loss: 3.569935050394907
Validation loss: 4.776015963497352

Epoch: 6| Step: 3
Training loss: 5.038640440779147
Validation loss: 4.771907363445435

Epoch: 6| Step: 4
Training loss: 4.766776724302856
Validation loss: 4.768074815114086

Epoch: 6| Step: 5
Training loss: 5.009865183891339
Validation loss: 4.764760907323379

Epoch: 6| Step: 6
Training loss: 4.781742644018292
Validation loss: 4.761449733746672

Epoch: 6| Step: 7
Training loss: 4.845074478694993
Validation loss: 4.756974771345726

Epoch: 6| Step: 8
Training loss: 5.12738000455004
Validation loss: 4.753006836715908

Epoch: 6| Step: 9
Training loss: 5.304767681072045
Validation loss: 4.748986537632323

Epoch: 6| Step: 10
Training loss: 4.477000057013407
Validation loss: 4.74470763929424

Epoch: 6| Step: 11
Training loss: 4.871467679989033
Validation loss: 4.740493429927715

Epoch: 6| Step: 12
Training loss: 4.9612477603521885
Validation loss: 4.7363701740508874

Epoch: 6| Step: 13
Training loss: 5.860620961276869
Validation loss: 4.732655362929047

Epoch: 20| Step: 0
Training loss: 4.123181491318514
Validation loss: 4.728327347585022

Epoch: 6| Step: 1
Training loss: 4.805993375636317
Validation loss: 4.723850718670557

Epoch: 6| Step: 2
Training loss: 3.9864975006887997
Validation loss: 4.720642451405533

Epoch: 6| Step: 3
Training loss: 3.947778637300782
Validation loss: 4.717384696647038

Epoch: 6| Step: 4
Training loss: 5.247488238433698
Validation loss: 4.712833897965514

Epoch: 6| Step: 5
Training loss: 5.04061416274796
Validation loss: 4.70768241546452

Epoch: 6| Step: 6
Training loss: 5.25813317419206
Validation loss: 4.7046116605212225

Epoch: 6| Step: 7
Training loss: 5.201674983881582
Validation loss: 4.701725275178545

Epoch: 6| Step: 8
Training loss: 6.181376808647753
Validation loss: 4.696643811980918

Epoch: 6| Step: 9
Training loss: 4.93596499762343
Validation loss: 4.691843182420454

Epoch: 6| Step: 10
Training loss: 4.504358088648313
Validation loss: 4.687945060794305

Epoch: 6| Step: 11
Training loss: 4.438582597227645
Validation loss: 4.685205822185646

Epoch: 6| Step: 12
Training loss: 4.308514508705816
Validation loss: 4.6800864532017075

Epoch: 6| Step: 13
Training loss: 5.107677305993224
Validation loss: 4.6747176453972745

Epoch: 21| Step: 0
Training loss: 5.452184907605724
Validation loss: 4.672499956158536

Epoch: 6| Step: 1
Training loss: 4.18613582424628
Validation loss: 4.667718746029251

Epoch: 6| Step: 2
Training loss: 4.4898956025015
Validation loss: 4.663452994661221

Epoch: 6| Step: 3
Training loss: 4.1676516068130605
Validation loss: 4.658231582394731

Epoch: 6| Step: 4
Training loss: 4.709903736467139
Validation loss: 4.654351412738678

Epoch: 6| Step: 5
Training loss: 5.0756583928321595
Validation loss: 4.65085461600995

Epoch: 6| Step: 6
Training loss: 4.042168550037722
Validation loss: 4.64674041286347

Epoch: 6| Step: 7
Training loss: 5.037159357788073
Validation loss: 4.642238109667553

Epoch: 6| Step: 8
Training loss: 4.952555049029932
Validation loss: 4.63841614563724

Epoch: 6| Step: 9
Training loss: 4.832147694004181
Validation loss: 4.63373839897005

Epoch: 6| Step: 10
Training loss: 4.85169852491477
Validation loss: 4.630429835075813

Epoch: 6| Step: 11
Training loss: 4.663481556352553
Validation loss: 4.625312382226601

Epoch: 6| Step: 12
Training loss: 4.882800976548903
Validation loss: 4.62166010916119

Epoch: 6| Step: 13
Training loss: 5.22029903973029
Validation loss: 4.6174651620236

Epoch: 22| Step: 0
Training loss: 4.015880532056937
Validation loss: 4.6131077711459545

Epoch: 6| Step: 1
Training loss: 4.781530833255705
Validation loss: 4.609306912538921

Epoch: 6| Step: 2
Training loss: 4.673550206556374
Validation loss: 4.604588945221006

Epoch: 6| Step: 3
Training loss: 4.906112183014096
Validation loss: 4.600763585112919

Epoch: 6| Step: 4
Training loss: 4.07659111553894
Validation loss: 4.596153824053894

Epoch: 6| Step: 5
Training loss: 4.256044017047853
Validation loss: 4.592246192227378

Epoch: 6| Step: 6
Training loss: 5.079886638547955
Validation loss: 4.587804809477946

Epoch: 6| Step: 7
Training loss: 5.776236344804042
Validation loss: 4.58418662480125

Epoch: 6| Step: 8
Training loss: 4.5397112541971625
Validation loss: 4.579734163579099

Epoch: 6| Step: 9
Training loss: 4.9593274485009635
Validation loss: 4.575622673254659

Epoch: 6| Step: 10
Training loss: 4.380741602504654
Validation loss: 4.571335133097173

Epoch: 6| Step: 11
Training loss: 5.244985274447852
Validation loss: 4.567207920874055

Epoch: 6| Step: 12
Training loss: 4.473694953078844
Validation loss: 4.563183702774782

Epoch: 6| Step: 13
Training loss: 4.509585661537556
Validation loss: 4.558597602831714

Epoch: 23| Step: 0
Training loss: 4.815609410463085
Validation loss: 4.554580259723701

Epoch: 6| Step: 1
Training loss: 4.583133392596809
Validation loss: 4.5497493856529445

Epoch: 6| Step: 2
Training loss: 4.7122428439374024
Validation loss: 4.546045006923754

Epoch: 6| Step: 3
Training loss: 5.119162607855318
Validation loss: 4.541633057542853

Epoch: 6| Step: 4
Training loss: 5.0089262439478555
Validation loss: 4.53749392660556

Epoch: 6| Step: 5
Training loss: 4.0701213066899955
Validation loss: 4.532965394590465

Epoch: 6| Step: 6
Training loss: 4.544813809751464
Validation loss: 4.5285974565422435

Epoch: 6| Step: 7
Training loss: 4.123334143681448
Validation loss: 4.5241302855743255

Epoch: 6| Step: 8
Training loss: 4.135495330036761
Validation loss: 4.520521999954108

Epoch: 6| Step: 9
Training loss: 4.991740461938648
Validation loss: 4.51592048637415

Epoch: 6| Step: 10
Training loss: 4.579199342666035
Validation loss: 4.512258733497143

Epoch: 6| Step: 11
Training loss: 5.563185060299245
Validation loss: 4.50800536837818

Epoch: 6| Step: 12
Training loss: 4.252612937580259
Validation loss: 4.5035312360813435

Epoch: 6| Step: 13
Training loss: 4.417821745108965
Validation loss: 4.499539086791089

Epoch: 24| Step: 0
Training loss: 3.7698923837292626
Validation loss: 4.495175247651689

Epoch: 6| Step: 1
Training loss: 3.9404426357051823
Validation loss: 4.491075708773118

Epoch: 6| Step: 2
Training loss: 3.820783402765989
Validation loss: 4.487057334438943

Epoch: 6| Step: 3
Training loss: 5.418878700285531
Validation loss: 4.483760477065675

Epoch: 6| Step: 4
Training loss: 5.102328139330736
Validation loss: 4.4794577333965835

Epoch: 6| Step: 5
Training loss: 4.740593681659487
Validation loss: 4.475066178470057

Epoch: 6| Step: 6
Training loss: 5.329045638479013
Validation loss: 4.470970651319661

Epoch: 6| Step: 7
Training loss: 4.605210728167613
Validation loss: 4.466693502791528

Epoch: 6| Step: 8
Training loss: 4.373522045630748
Validation loss: 4.46271674932531

Epoch: 6| Step: 9
Training loss: 3.9985877166472372
Validation loss: 4.457815383819279

Epoch: 6| Step: 10
Training loss: 4.488676022265511
Validation loss: 4.4533697406818655

Epoch: 6| Step: 11
Training loss: 5.3018760815517805
Validation loss: 4.449415113823141

Epoch: 6| Step: 12
Training loss: 5.382411194390756
Validation loss: 4.4448902039042535

Epoch: 6| Step: 13
Training loss: 3.4063612893499045
Validation loss: 4.440883045363299

Epoch: 25| Step: 0
Training loss: 3.86258060902056
Validation loss: 4.436124454118067

Epoch: 6| Step: 1
Training loss: 5.015532780925481
Validation loss: 4.431926110056806

Epoch: 6| Step: 2
Training loss: 4.1807232580558615
Validation loss: 4.427010581222836

Epoch: 6| Step: 3
Training loss: 4.699648563962614
Validation loss: 4.422630398303062

Epoch: 6| Step: 4
Training loss: 5.050342797457037
Validation loss: 4.418285732888249

Epoch: 6| Step: 5
Training loss: 4.687919089338424
Validation loss: 4.414404049602733

Epoch: 6| Step: 6
Training loss: 4.527618636836575
Validation loss: 4.409893973035395

Epoch: 6| Step: 7
Training loss: 4.185376668042382
Validation loss: 4.405150688962667

Epoch: 6| Step: 8
Training loss: 4.241596665519863
Validation loss: 4.400388168783528

Epoch: 6| Step: 9
Training loss: 4.551684794958483
Validation loss: 4.395922938634355

Epoch: 6| Step: 10
Training loss: 4.921657206242804
Validation loss: 4.391638225967611

Epoch: 6| Step: 11
Training loss: 5.055575309034795
Validation loss: 4.387517768555804

Epoch: 6| Step: 12
Training loss: 3.9176683700593737
Validation loss: 4.382320129335952

Epoch: 6| Step: 13
Training loss: 4.3909325542860556
Validation loss: 4.377286259145824

Epoch: 26| Step: 0
Training loss: 5.226005946521317
Validation loss: 4.373159620936609

Epoch: 6| Step: 1
Training loss: 4.731847308612818
Validation loss: 4.368954796236279

Epoch: 6| Step: 2
Training loss: 4.873332594329179
Validation loss: 4.364512507456537

Epoch: 6| Step: 3
Training loss: 4.153444189201595
Validation loss: 4.3591210805213

Epoch: 6| Step: 4
Training loss: 4.284582024823589
Validation loss: 4.355381493485546

Epoch: 6| Step: 5
Training loss: 4.015994518808219
Validation loss: 4.350501725066469

Epoch: 6| Step: 6
Training loss: 4.923239092035713
Validation loss: 4.345619019112379

Epoch: 6| Step: 7
Training loss: 3.9871280508649507
Validation loss: 4.3424660594128435

Epoch: 6| Step: 8
Training loss: 3.9261231534495
Validation loss: 4.337030294822531

Epoch: 6| Step: 9
Training loss: 4.709819705371373
Validation loss: 4.331808934700244

Epoch: 6| Step: 10
Training loss: 4.918400388747667
Validation loss: 4.326863716783386

Epoch: 6| Step: 11
Training loss: 5.167096561061917
Validation loss: 4.320879144281649

Epoch: 6| Step: 12
Training loss: 3.3858169710247625
Validation loss: 4.315921697562098

Epoch: 6| Step: 13
Training loss: 3.883490090760395
Validation loss: 4.311220264828141

Epoch: 27| Step: 0
Training loss: 3.944924756627079
Validation loss: 4.306925575477173

Epoch: 6| Step: 1
Training loss: 4.010586081885644
Validation loss: 4.302786202392037

Epoch: 6| Step: 2
Training loss: 3.701079628632768
Validation loss: 4.29760563967442

Epoch: 6| Step: 3
Training loss: 4.255135967085972
Validation loss: 4.292893404150469

Epoch: 6| Step: 4
Training loss: 4.985214114933131
Validation loss: 4.28838957815774

Epoch: 6| Step: 5
Training loss: 4.561230835690099
Validation loss: 4.284215378147056

Epoch: 6| Step: 6
Training loss: 4.330569241572601
Validation loss: 4.27898779733274

Epoch: 6| Step: 7
Training loss: 4.8779655630875425
Validation loss: 4.2737794096564174

Epoch: 6| Step: 8
Training loss: 4.184859852694513
Validation loss: 4.268694228724415

Epoch: 6| Step: 9
Training loss: 4.3139577419738515
Validation loss: 4.263785015474253

Epoch: 6| Step: 10
Training loss: 4.471480169133494
Validation loss: 4.259068201835484

Epoch: 6| Step: 11
Training loss: 4.508167272718868
Validation loss: 4.253694443206777

Epoch: 6| Step: 12
Training loss: 5.032001320794786
Validation loss: 4.2487661964322525

Epoch: 6| Step: 13
Training loss: 4.28136494057614
Validation loss: 4.244279583269588

Epoch: 28| Step: 0
Training loss: 5.198611206051063
Validation loss: 4.2393650807931955

Epoch: 6| Step: 1
Training loss: 4.369435286359061
Validation loss: 4.234798246019394

Epoch: 6| Step: 2
Training loss: 4.114314950165491
Validation loss: 4.229953010003488

Epoch: 6| Step: 3
Training loss: 5.323914595471367
Validation loss: 4.22483304237476

Epoch: 6| Step: 4
Training loss: 3.6137516849583826
Validation loss: 4.219739821369858

Epoch: 6| Step: 5
Training loss: 4.370275507781634
Validation loss: 4.2154377497246704

Epoch: 6| Step: 6
Training loss: 4.389723933061861
Validation loss: 4.209796890228112

Epoch: 6| Step: 7
Training loss: 3.9028896679267997
Validation loss: 4.205163832265159

Epoch: 6| Step: 8
Training loss: 4.795971316228743
Validation loss: 4.200473218325946

Epoch: 6| Step: 9
Training loss: 4.072473344147748
Validation loss: 4.195666704906782

Epoch: 6| Step: 10
Training loss: 4.605007779490706
Validation loss: 4.191115683005536

Epoch: 6| Step: 11
Training loss: 4.1133394445521265
Validation loss: 4.186134381402897

Epoch: 6| Step: 12
Training loss: 3.7201079125287984
Validation loss: 4.180454171952025

Epoch: 6| Step: 13
Training loss: 3.7821003611868687
Validation loss: 4.176072560430247

Epoch: 29| Step: 0
Training loss: 3.93777440643836
Validation loss: 4.17176630114273

Epoch: 6| Step: 1
Training loss: 3.835672217866777
Validation loss: 4.167364761364219

Epoch: 6| Step: 2
Training loss: 4.030850412835879
Validation loss: 4.163158402098231

Epoch: 6| Step: 3
Training loss: 3.8827429905278517
Validation loss: 4.158580442181911

Epoch: 6| Step: 4
Training loss: 4.664969862404115
Validation loss: 4.153779904425018

Epoch: 6| Step: 5
Training loss: 5.010355335053203
Validation loss: 4.149034609210401

Epoch: 6| Step: 6
Training loss: 3.5401085661280423
Validation loss: 4.1448240089864345

Epoch: 6| Step: 7
Training loss: 4.027982585274593
Validation loss: 4.140500432665849

Epoch: 6| Step: 8
Training loss: 4.935871869864802
Validation loss: 4.135327790632094

Epoch: 6| Step: 9
Training loss: 4.530291436191073
Validation loss: 4.130458822587774

Epoch: 6| Step: 10
Training loss: 4.747889602046132
Validation loss: 4.126000331230847

Epoch: 6| Step: 11
Training loss: 4.277783403489238
Validation loss: 4.121281903688859

Epoch: 6| Step: 12
Training loss: 4.550548000661376
Validation loss: 4.116768513447975

Epoch: 6| Step: 13
Training loss: 3.479753654135482
Validation loss: 4.111870379113147

Epoch: 30| Step: 0
Training loss: 4.194371748428323
Validation loss: 4.1070497458824375

Epoch: 6| Step: 1
Training loss: 4.80910540662312
Validation loss: 4.1021306107668645

Epoch: 6| Step: 2
Training loss: 3.855554334314784
Validation loss: 4.097216334940386

Epoch: 6| Step: 3
Training loss: 4.255316606480265
Validation loss: 4.0921608167440855

Epoch: 6| Step: 4
Training loss: 4.144904462313816
Validation loss: 4.086927518894613

Epoch: 6| Step: 5
Training loss: 4.0594055127648225
Validation loss: 4.082439921727965

Epoch: 6| Step: 6
Training loss: 3.291671044712938
Validation loss: 4.077402296862326

Epoch: 6| Step: 7
Training loss: 5.488398714267882
Validation loss: 4.07348023375003

Epoch: 6| Step: 8
Training loss: 4.368451258059653
Validation loss: 4.0684621831192676

Epoch: 6| Step: 9
Training loss: 4.0423336986148275
Validation loss: 4.063621268445752

Epoch: 6| Step: 10
Training loss: 4.026493548867584
Validation loss: 4.059351302408848

Epoch: 6| Step: 11
Training loss: 4.143709236048079
Validation loss: 4.0537652036789735

Epoch: 6| Step: 12
Training loss: 4.363557074288839
Validation loss: 4.049473108939233

Epoch: 6| Step: 13
Training loss: 3.439683532795733
Validation loss: 4.044663422691746

Epoch: 31| Step: 0
Training loss: 3.802088795836544
Validation loss: 4.0397435689502315

Epoch: 6| Step: 1
Training loss: 3.9763008436293967
Validation loss: 4.0351620206640835

Epoch: 6| Step: 2
Training loss: 4.413758069908524
Validation loss: 4.030426453838429

Epoch: 6| Step: 3
Training loss: 4.368804250224795
Validation loss: 4.025219726883336

Epoch: 6| Step: 4
Training loss: 4.243542646193564
Validation loss: 4.020821065669872

Epoch: 6| Step: 5
Training loss: 4.077476011354198
Validation loss: 4.015269539583184

Epoch: 6| Step: 6
Training loss: 4.596391191054257
Validation loss: 4.011197589624201

Epoch: 6| Step: 7
Training loss: 4.274903208211292
Validation loss: 4.006066113485556

Epoch: 6| Step: 8
Training loss: 4.337500158304437
Validation loss: 4.001464516044449

Epoch: 6| Step: 9
Training loss: 3.257205897512324
Validation loss: 3.9963406672656356

Epoch: 6| Step: 10
Training loss: 4.292490660935531
Validation loss: 3.9912177672987705

Epoch: 6| Step: 11
Training loss: 3.1131878196261393
Validation loss: 3.9868790480860317

Epoch: 6| Step: 12
Training loss: 4.647296464145491
Validation loss: 3.982042754497628

Epoch: 6| Step: 13
Training loss: 4.274914585621035
Validation loss: 3.9781929675556684

Epoch: 32| Step: 0
Training loss: 4.220892016249858
Validation loss: 3.9727447910000624

Epoch: 6| Step: 1
Training loss: 4.0170829293444354
Validation loss: 3.9678066664442024

Epoch: 6| Step: 2
Training loss: 4.025345137115623
Validation loss: 3.963485991412346

Epoch: 6| Step: 3
Training loss: 4.03268028731297
Validation loss: 3.959021391379531

Epoch: 6| Step: 4
Training loss: 4.5685952636565945
Validation loss: 3.953943401554829

Epoch: 6| Step: 5
Training loss: 3.9869175596188673
Validation loss: 3.949862464490132

Epoch: 6| Step: 6
Training loss: 4.751290798478766
Validation loss: 3.944513825506332

Epoch: 6| Step: 7
Training loss: 3.648627919490456
Validation loss: 3.939636942342206

Epoch: 6| Step: 8
Training loss: 3.473061845777401
Validation loss: 3.935079244213999

Epoch: 6| Step: 9
Training loss: 3.6287822065721134
Validation loss: 3.930371143491673

Epoch: 6| Step: 10
Training loss: 4.28310203867833
Validation loss: 3.9259602621331036

Epoch: 6| Step: 11
Training loss: 4.768921759275754
Validation loss: 3.9207272211540247

Epoch: 6| Step: 12
Training loss: 3.315680650249429
Validation loss: 3.9163205352317805

Epoch: 6| Step: 13
Training loss: 4.039561139433188
Validation loss: 3.911184139605468

Epoch: 33| Step: 0
Training loss: 4.00776157755783
Validation loss: 3.9065368547018156

Epoch: 6| Step: 1
Training loss: 4.086930980214388
Validation loss: 3.901709600834587

Epoch: 6| Step: 2
Training loss: 4.297850120178411
Validation loss: 3.8974079818906686

Epoch: 6| Step: 3
Training loss: 3.7446827384092676
Validation loss: 3.8925679983979333

Epoch: 6| Step: 4
Training loss: 4.072827402422886
Validation loss: 3.888008964232588

Epoch: 6| Step: 5
Training loss: 3.919406798107062
Validation loss: 3.8830616881901268

Epoch: 6| Step: 6
Training loss: 3.988716423063099
Validation loss: 3.8790156568942415

Epoch: 6| Step: 7
Training loss: 5.126909598029517
Validation loss: 3.8740775333182706

Epoch: 6| Step: 8
Training loss: 3.567583572916499
Validation loss: 3.868949124127043

Epoch: 6| Step: 9
Training loss: 2.706430696088842
Validation loss: 3.864416723781365

Epoch: 6| Step: 10
Training loss: 4.3786239873344845
Validation loss: 3.8595554036796353

Epoch: 6| Step: 11
Training loss: 3.5836927248499664
Validation loss: 3.855005939279509

Epoch: 6| Step: 12
Training loss: 4.129836050848116
Validation loss: 3.8506865727296673

Epoch: 6| Step: 13
Training loss: 4.089964069684304
Validation loss: 3.846164100339865

Epoch: 34| Step: 0
Training loss: 3.5283093656849975
Validation loss: 3.8413653329321673

Epoch: 6| Step: 1
Training loss: 4.09557738540893
Validation loss: 3.8371114287664914

Epoch: 6| Step: 2
Training loss: 4.688830174223626
Validation loss: 3.832180070855098

Epoch: 6| Step: 3
Training loss: 3.9284805658905313
Validation loss: 3.826919739614476

Epoch: 6| Step: 4
Training loss: 3.7164797224120045
Validation loss: 3.822369396871811

Epoch: 6| Step: 5
Training loss: 3.674740716000788
Validation loss: 3.817922935681912

Epoch: 6| Step: 6
Training loss: 3.638343849487298
Validation loss: 3.8133736531809226

Epoch: 6| Step: 7
Training loss: 3.3904607355082934
Validation loss: 3.8086702048950034

Epoch: 6| Step: 8
Training loss: 3.9126921975212854
Validation loss: 3.8041915622549753

Epoch: 6| Step: 9
Training loss: 4.036690759017286
Validation loss: 3.8002969316284374

Epoch: 6| Step: 10
Training loss: 4.172161192489245
Validation loss: 3.795329173022528

Epoch: 6| Step: 11
Training loss: 4.246384148375096
Validation loss: 3.7904696968134353

Epoch: 6| Step: 12
Training loss: 4.2151353963190505
Validation loss: 3.785822979891004

Epoch: 6| Step: 13
Training loss: 3.8142228533125127
Validation loss: 3.7807592909010834

Epoch: 35| Step: 0
Training loss: 3.8092449863894298
Validation loss: 3.7764828479023294

Epoch: 6| Step: 1
Training loss: 3.7801282495611024
Validation loss: 3.7716435708824894

Epoch: 6| Step: 2
Training loss: 3.784255921611146
Validation loss: 3.7669010981184226

Epoch: 6| Step: 3
Training loss: 4.523334403172598
Validation loss: 3.762428879514528

Epoch: 6| Step: 4
Training loss: 3.475722719412642
Validation loss: 3.7581451543710265

Epoch: 6| Step: 5
Training loss: 3.949351322654263
Validation loss: 3.752663514168529

Epoch: 6| Step: 6
Training loss: 3.5566669025319766
Validation loss: 3.7479808881741232

Epoch: 6| Step: 7
Training loss: 4.090618071175019
Validation loss: 3.7432913005118738

Epoch: 6| Step: 8
Training loss: 4.515214208377514
Validation loss: 3.7386944209314357

Epoch: 6| Step: 9
Training loss: 3.5386841426476283
Validation loss: 3.734309261067938

Epoch: 6| Step: 10
Training loss: 3.252220715576467
Validation loss: 3.7291932913115695

Epoch: 6| Step: 11
Training loss: 4.079138618868969
Validation loss: 3.7248400660237824

Epoch: 6| Step: 12
Training loss: 3.7097894759996546
Validation loss: 3.7199531339954155

Epoch: 6| Step: 13
Training loss: 4.051861963705674
Validation loss: 3.7160047768561104

Epoch: 36| Step: 0
Training loss: 4.375233671215102
Validation loss: 3.7111321863336157

Epoch: 6| Step: 1
Training loss: 3.9287914065910785
Validation loss: 3.706185708391616

Epoch: 6| Step: 2
Training loss: 4.333612041802707
Validation loss: 3.7008980924052275

Epoch: 6| Step: 3
Training loss: 3.2120715735075023
Validation loss: 3.696087380285962

Epoch: 6| Step: 4
Training loss: 3.30849689940892
Validation loss: 3.6916579818336395

Epoch: 6| Step: 5
Training loss: 4.082757766537786
Validation loss: 3.687375104265373

Epoch: 6| Step: 6
Training loss: 3.7664447066364075
Validation loss: 3.6823241984626804

Epoch: 6| Step: 7
Training loss: 3.094578333464946
Validation loss: 3.6778765391112

Epoch: 6| Step: 8
Training loss: 3.853324316953606
Validation loss: 3.673213006129822

Epoch: 6| Step: 9
Training loss: 4.11883014143686
Validation loss: 3.66906552883134

Epoch: 6| Step: 10
Training loss: 3.259719400323846
Validation loss: 3.6647724691959476

Epoch: 6| Step: 11
Training loss: 4.051778407583534
Validation loss: 3.6604060708972566

Epoch: 6| Step: 12
Training loss: 4.007065731323419
Validation loss: 3.655640271418472

Epoch: 6| Step: 13
Training loss: 3.7444090809144206
Validation loss: 3.6513601790880634

Epoch: 37| Step: 0
Training loss: 4.45908617930214
Validation loss: 3.646777061753391

Epoch: 6| Step: 1
Training loss: 4.002385620160284
Validation loss: 3.641928879982109

Epoch: 6| Step: 2
Training loss: 3.603716754210863
Validation loss: 3.6368626922191134

Epoch: 6| Step: 3
Training loss: 3.989964054490708
Validation loss: 3.6329703129224726

Epoch: 6| Step: 4
Training loss: 3.5737782024432896
Validation loss: 3.6279253501404085

Epoch: 6| Step: 5
Training loss: 3.5732495270575755
Validation loss: 3.622990259377672

Epoch: 6| Step: 6
Training loss: 3.676839645711169
Validation loss: 3.6184021109978053

Epoch: 6| Step: 7
Training loss: 3.70287969235462
Validation loss: 3.614028265087651

Epoch: 6| Step: 8
Training loss: 4.481644174432591
Validation loss: 3.609222056573693

Epoch: 6| Step: 9
Training loss: 3.9640058863006216
Validation loss: 3.604787534183621

Epoch: 6| Step: 10
Training loss: 3.1044889619851914
Validation loss: 3.599877902009034

Epoch: 6| Step: 11
Training loss: 3.1052920117258505
Validation loss: 3.5950961701497963

Epoch: 6| Step: 12
Training loss: 3.203791851316577
Validation loss: 3.590712593322706

Epoch: 6| Step: 13
Training loss: 3.81406583055275
Validation loss: 3.586756749091372

Epoch: 38| Step: 0
Training loss: 4.133556392762586
Validation loss: 3.5825716953952074

Epoch: 6| Step: 1
Training loss: 3.574489429000952
Validation loss: 3.57836695579033

Epoch: 6| Step: 2
Training loss: 3.5004244955676334
Validation loss: 3.5741216705423806

Epoch: 6| Step: 3
Training loss: 3.8512680838759894
Validation loss: 3.5697453978476545

Epoch: 6| Step: 4
Training loss: 4.009095817473266
Validation loss: 3.565267369185328

Epoch: 6| Step: 5
Training loss: 3.4136839772463983
Validation loss: 3.560702980512943

Epoch: 6| Step: 6
Training loss: 3.8180029505163255
Validation loss: 3.5565547971164695

Epoch: 6| Step: 7
Training loss: 4.102452935338798
Validation loss: 3.552234113220776

Epoch: 6| Step: 8
Training loss: 3.7581481149261724
Validation loss: 3.5474135204309807

Epoch: 6| Step: 9
Training loss: 4.077649552849594
Validation loss: 3.5432031701823172

Epoch: 6| Step: 10
Training loss: 2.8828346644430805
Validation loss: 3.5386720600570976

Epoch: 6| Step: 11
Training loss: 3.051840311384894
Validation loss: 3.534247350031867

Epoch: 6| Step: 12
Training loss: 3.9146115342458048
Validation loss: 3.529604356745391

Epoch: 6| Step: 13
Training loss: 3.335212289210257
Validation loss: 3.525255702599072

Epoch: 39| Step: 0
Training loss: 2.911282192263526
Validation loss: 3.5210832510888217

Epoch: 6| Step: 1
Training loss: 4.460920397296462
Validation loss: 3.5169742396993677

Epoch: 6| Step: 2
Training loss: 3.232515399421187
Validation loss: 3.5125654456579327

Epoch: 6| Step: 3
Training loss: 3.2879155349648927
Validation loss: 3.5081715106265254

Epoch: 6| Step: 4
Training loss: 3.7228365971529778
Validation loss: 3.504021854258453

Epoch: 6| Step: 5
Training loss: 4.38756631219642
Validation loss: 3.500081356556246

Epoch: 6| Step: 6
Training loss: 4.190903376607548
Validation loss: 3.4951039651807325

Epoch: 6| Step: 7
Training loss: 3.460535168135464
Validation loss: 3.4907934491418326

Epoch: 6| Step: 8
Training loss: 3.3575509730579114
Validation loss: 3.486542442423414

Epoch: 6| Step: 9
Training loss: 3.188057944140946
Validation loss: 3.481991818171746

Epoch: 6| Step: 10
Training loss: 3.19244390308441
Validation loss: 3.47790583685208

Epoch: 6| Step: 11
Training loss: 3.2511318876701067
Validation loss: 3.474223929818034

Epoch: 6| Step: 12
Training loss: 3.9962548366084225
Validation loss: 3.470841587662852

Epoch: 6| Step: 13
Training loss: 3.7832849244593136
Validation loss: 3.466382613526699

Epoch: 40| Step: 0
Training loss: 3.6577445342061066
Validation loss: 3.461910102529911

Epoch: 6| Step: 1
Training loss: 3.244835638459624
Validation loss: 3.458175969660869

Epoch: 6| Step: 2
Training loss: 3.4001548900104552
Validation loss: 3.4534299897017404

Epoch: 6| Step: 3
Training loss: 3.7536745506018416
Validation loss: 3.4497557438432307

Epoch: 6| Step: 4
Training loss: 4.028665113084456
Validation loss: 3.4453295695025474

Epoch: 6| Step: 5
Training loss: 3.816224702013408
Validation loss: 3.441130553109087

Epoch: 6| Step: 6
Training loss: 3.4749960810138365
Validation loss: 3.4368368144855643

Epoch: 6| Step: 7
Training loss: 3.3227544443997545
Validation loss: 3.4335118133177267

Epoch: 6| Step: 8
Training loss: 3.9927791746751695
Validation loss: 3.428822239527254

Epoch: 6| Step: 9
Training loss: 4.165034826529205
Validation loss: 3.42471657668564

Epoch: 6| Step: 10
Training loss: 3.8677124900120883
Validation loss: 3.4203261029963525

Epoch: 6| Step: 11
Training loss: 2.374785564178391
Validation loss: 3.41560634969754

Epoch: 6| Step: 12
Training loss: 3.6350588180631696
Validation loss: 3.41148797330526

Epoch: 6| Step: 13
Training loss: 2.8806359155919448
Validation loss: 3.4076517236543595

Epoch: 41| Step: 0
Training loss: 4.005703198137908
Validation loss: 3.403765691131949

Epoch: 6| Step: 1
Training loss: 3.0670524548005447
Validation loss: 3.40001752231795

Epoch: 6| Step: 2
Training loss: 3.34189775449541
Validation loss: 3.3955931237260675

Epoch: 6| Step: 3
Training loss: 3.2938270400590586
Validation loss: 3.3910015383482266

Epoch: 6| Step: 4
Training loss: 2.7071078731377143
Validation loss: 3.387173256594112

Epoch: 6| Step: 5
Training loss: 3.981507469966424
Validation loss: 3.383597878196921

Epoch: 6| Step: 6
Training loss: 3.326876553913666
Validation loss: 3.3793905568927407

Epoch: 6| Step: 7
Training loss: 3.2842749321789673
Validation loss: 3.374620722428422

Epoch: 6| Step: 8
Training loss: 3.701661927484819
Validation loss: 3.370957378813204

Epoch: 6| Step: 9
Training loss: 4.498606148063045
Validation loss: 3.367154209004844

Epoch: 6| Step: 10
Training loss: 3.234881817458685
Validation loss: 3.363391456467244

Epoch: 6| Step: 11
Training loss: 3.520713683734375
Validation loss: 3.359545917746574

Epoch: 6| Step: 12
Training loss: 3.3228870418427827
Validation loss: 3.3576919952965194

Epoch: 6| Step: 13
Training loss: 3.589416544901483
Validation loss: 3.3540815180678236

Epoch: 42| Step: 0
Training loss: 4.102735137430901
Validation loss: 3.347712299318382

Epoch: 6| Step: 1
Training loss: 3.433700820242936
Validation loss: 3.344008367426076

Epoch: 6| Step: 2
Training loss: 3.845929900031912
Validation loss: 3.3389786282068945

Epoch: 6| Step: 3
Training loss: 3.122312687309518
Validation loss: 3.335029377195499

Epoch: 6| Step: 4
Training loss: 2.9501783414047615
Validation loss: 3.3308270966680866

Epoch: 6| Step: 5
Training loss: 3.3579155169021666
Validation loss: 3.3278328733035205

Epoch: 6| Step: 6
Training loss: 3.488749815429333
Validation loss: 3.3245698449813843

Epoch: 6| Step: 7
Training loss: 3.192483633741759
Validation loss: 3.3207287097437868

Epoch: 6| Step: 8
Training loss: 3.211496123566798
Validation loss: 3.316880047386215

Epoch: 6| Step: 9
Training loss: 3.4941866142952382
Validation loss: 3.31275507106829

Epoch: 6| Step: 10
Training loss: 3.0525597383869325
Validation loss: 3.309215800941167

Epoch: 6| Step: 11
Training loss: 3.21731579873526
Validation loss: 3.3058064327262566

Epoch: 6| Step: 12
Training loss: 4.210086771961049
Validation loss: 3.3017621691424104

Epoch: 6| Step: 13
Training loss: 3.5252269590644856
Validation loss: 3.297760083804285

Epoch: 43| Step: 0
Training loss: 2.748978511788764
Validation loss: 3.2942824211469657

Epoch: 6| Step: 1
Training loss: 3.320164863445637
Validation loss: 3.290324955731684

Epoch: 6| Step: 2
Training loss: 4.1066337696425705
Validation loss: 3.286655937980747

Epoch: 6| Step: 3
Training loss: 3.565232416952596
Validation loss: 3.282620897470869

Epoch: 6| Step: 4
Training loss: 3.449135249024667
Validation loss: 3.2784803539124012

Epoch: 6| Step: 5
Training loss: 3.27807318080096
Validation loss: 3.2749378586714566

Epoch: 6| Step: 6
Training loss: 3.573164654161903
Validation loss: 3.271032416405906

Epoch: 6| Step: 7
Training loss: 3.869110061085743
Validation loss: 3.267093456051377

Epoch: 6| Step: 8
Training loss: 3.6330515136846637
Validation loss: 3.2631627828537666

Epoch: 6| Step: 9
Training loss: 3.1873005823323646
Validation loss: 3.2593443735304635

Epoch: 6| Step: 10
Training loss: 3.076298360494834
Validation loss: 3.255743356097203

Epoch: 6| Step: 11
Training loss: 3.16596441680518
Validation loss: 3.2515712021175527

Epoch: 6| Step: 12
Training loss: 3.541593812679369
Validation loss: 3.2479357766369588

Epoch: 6| Step: 13
Training loss: 2.993121845389468
Validation loss: 3.243825206240019

Epoch: 44| Step: 0
Training loss: 3.613459402280412
Validation loss: 3.240678734917827

Epoch: 6| Step: 1
Training loss: 3.5141339340175097
Validation loss: 3.2364245077885974

Epoch: 6| Step: 2
Training loss: 3.455945550295381
Validation loss: 3.2333901175857864

Epoch: 6| Step: 3
Training loss: 3.051401385435725
Validation loss: 3.230159992314325

Epoch: 6| Step: 4
Training loss: 2.6359817944362525
Validation loss: 3.226419145479914

Epoch: 6| Step: 5
Training loss: 2.793042076588797
Validation loss: 3.223031514214825

Epoch: 6| Step: 6
Training loss: 3.334553987799026
Validation loss: 3.220972226114431

Epoch: 6| Step: 7
Training loss: 3.534180901794141
Validation loss: 3.2177159151329815

Epoch: 6| Step: 8
Training loss: 3.2590277072586677
Validation loss: 3.2136851587311175

Epoch: 6| Step: 9
Training loss: 3.6600163289524055
Validation loss: 3.2109189616934306

Epoch: 6| Step: 10
Training loss: 3.7102312239081923
Validation loss: 3.208623418863546

Epoch: 6| Step: 11
Training loss: 3.3089521590019952
Validation loss: 3.2078034016956614

Epoch: 6| Step: 12
Training loss: 3.8825533682550497
Validation loss: 3.2055109581433503

Epoch: 6| Step: 13
Training loss: 3.029484185355865
Validation loss: 3.202010492717858

Epoch: 45| Step: 0
Training loss: 2.6899180512549155
Validation loss: 3.197501268443755

Epoch: 6| Step: 1
Training loss: 3.19798364890131
Validation loss: 3.1935049725703806

Epoch: 6| Step: 2
Training loss: 2.659336675240014
Validation loss: 3.1897474356772872

Epoch: 6| Step: 3
Training loss: 3.691153575181636
Validation loss: 3.1850189326595437

Epoch: 6| Step: 4
Training loss: 3.390515303705058
Validation loss: 3.1820813290040784

Epoch: 6| Step: 5
Training loss: 4.110762097318689
Validation loss: 3.178972018488026

Epoch: 6| Step: 6
Training loss: 2.946247144785919
Validation loss: 3.1749166928272987

Epoch: 6| Step: 7
Training loss: 3.5179209354140846
Validation loss: 3.17178998560735

Epoch: 6| Step: 8
Training loss: 2.339829484644536
Validation loss: 3.168277171996888

Epoch: 6| Step: 9
Training loss: 3.5392681003158106
Validation loss: 3.165210807493173

Epoch: 6| Step: 10
Training loss: 3.3837000010826404
Validation loss: 3.16166373794841

Epoch: 6| Step: 11
Training loss: 3.600459461561897
Validation loss: 3.15803409423688

Epoch: 6| Step: 12
Training loss: 3.544574815138931
Validation loss: 3.153724705124318

Epoch: 6| Step: 13
Training loss: 3.3299031410221027
Validation loss: 3.149951227002266

Epoch: 46| Step: 0
Training loss: 3.0236037255460153
Validation loss: 3.146364727148831

Epoch: 6| Step: 1
Training loss: 3.442031232046039
Validation loss: 3.1430683911325032

Epoch: 6| Step: 2
Training loss: 3.7275189785694858
Validation loss: 3.1396900259282234

Epoch: 6| Step: 3
Training loss: 3.862130729529058
Validation loss: 3.136457990589121

Epoch: 6| Step: 4
Training loss: 3.234361141746428
Validation loss: 3.132424981430904

Epoch: 6| Step: 5
Training loss: 3.2521718911025204
Validation loss: 3.128763615488036

Epoch: 6| Step: 6
Training loss: 3.2951871338932315
Validation loss: 3.1252769601796886

Epoch: 6| Step: 7
Training loss: 2.5497586828002246
Validation loss: 3.1212329920971307

Epoch: 6| Step: 8
Training loss: 3.0725443641433245
Validation loss: 3.1176338864117707

Epoch: 6| Step: 9
Training loss: 3.583919181542617
Validation loss: 3.114651227400293

Epoch: 6| Step: 10
Training loss: 2.7524663096071604
Validation loss: 3.1109986786356725

Epoch: 6| Step: 11
Training loss: 2.886490127533378
Validation loss: 3.107739655881392

Epoch: 6| Step: 12
Training loss: 3.1654140270309687
Validation loss: 3.1043699355852445

Epoch: 6| Step: 13
Training loss: 3.620130886219698
Validation loss: 3.1013878069284133

Epoch: 47| Step: 0
Training loss: 3.2953205511900077
Validation loss: 3.098378825565927

Epoch: 6| Step: 1
Training loss: 3.1245446445586027
Validation loss: 3.0953870866708963

Epoch: 6| Step: 2
Training loss: 2.876891301896414
Validation loss: 3.091905962653603

Epoch: 6| Step: 3
Training loss: 3.421796963293967
Validation loss: 3.0900156364744857

Epoch: 6| Step: 4
Training loss: 3.4001797123705115
Validation loss: 3.0879644376653905

Epoch: 6| Step: 5
Training loss: 3.1236616702068476
Validation loss: 3.0865499025619276

Epoch: 6| Step: 6
Training loss: 2.5998694607169326
Validation loss: 3.0812360916700734

Epoch: 6| Step: 7
Training loss: 3.623330224979568
Validation loss: 3.0769563964268465

Epoch: 6| Step: 8
Training loss: 3.437790459585714
Validation loss: 3.074415938157873

Epoch: 6| Step: 9
Training loss: 3.231286237207273
Validation loss: 3.0720059527001724

Epoch: 6| Step: 10
Training loss: 3.3243576002875868
Validation loss: 3.069362658470228

Epoch: 6| Step: 11
Training loss: 3.7574429716958946
Validation loss: 3.0666831893752216

Epoch: 6| Step: 12
Training loss: 3.365862734021532
Validation loss: 3.06544309096471

Epoch: 6| Step: 13
Training loss: 2.18748779293469
Validation loss: 3.0612617895985266

Epoch: 48| Step: 0
Training loss: 3.287116047880185
Validation loss: 3.0578985613740763

Epoch: 6| Step: 1
Training loss: 2.3601837793011833
Validation loss: 3.0544621871495212

Epoch: 6| Step: 2
Training loss: 3.4094464064689425
Validation loss: 3.05109012227095

Epoch: 6| Step: 3
Training loss: 3.697418064656556
Validation loss: 3.048978135114479

Epoch: 6| Step: 4
Training loss: 2.5702716858936605
Validation loss: 3.0461816634636056

Epoch: 6| Step: 5
Training loss: 3.1865075754278815
Validation loss: 3.043876463595174

Epoch: 6| Step: 6
Training loss: 3.476648222477219
Validation loss: 3.0403785242364183

Epoch: 6| Step: 7
Training loss: 3.3130348781381347
Validation loss: 3.0363256164825714

Epoch: 6| Step: 8
Training loss: 3.2303775280915734
Validation loss: 3.033496797439966

Epoch: 6| Step: 9
Training loss: 3.420735487349769
Validation loss: 3.0298496170830433

Epoch: 6| Step: 10
Training loss: 2.908841853968085
Validation loss: 3.027183374238211

Epoch: 6| Step: 11
Training loss: 3.2855662703494373
Validation loss: 3.0242611258555105

Epoch: 6| Step: 12
Training loss: 3.0764563050548306
Validation loss: 3.0211252707241183

Epoch: 6| Step: 13
Training loss: 3.038060040119854
Validation loss: 3.0181834382264885

Epoch: 49| Step: 0
Training loss: 3.0631316175936125
Validation loss: 3.0151924653247346

Epoch: 6| Step: 1
Training loss: 3.092861009278834
Validation loss: 3.013489621070435

Epoch: 6| Step: 2
Training loss: 3.1110074919141697
Validation loss: 3.0105432837939063

Epoch: 6| Step: 3
Training loss: 2.909531740090532
Validation loss: 3.0084432229623963

Epoch: 6| Step: 4
Training loss: 3.0695198724914015
Validation loss: 3.0051433924242565

Epoch: 6| Step: 5
Training loss: 3.6160025911321894
Validation loss: 3.0013382628846776

Epoch: 6| Step: 6
Training loss: 3.0831335535709887
Validation loss: 2.9986162703222696

Epoch: 6| Step: 7
Training loss: 2.3454349818768003
Validation loss: 2.9962689324880114

Epoch: 6| Step: 8
Training loss: 3.4514738942728047
Validation loss: 2.9940044573672338

Epoch: 6| Step: 9
Training loss: 3.1235917542282183
Validation loss: 2.9907350393025953

Epoch: 6| Step: 10
Training loss: 3.681137932980564
Validation loss: 2.9881399881720676

Epoch: 6| Step: 11
Training loss: 3.5944536929934454
Validation loss: 2.9846137918269644

Epoch: 6| Step: 12
Training loss: 2.9018094172924433
Validation loss: 2.9826789150628863

Epoch: 6| Step: 13
Training loss: 2.637259420839675
Validation loss: 2.9815559320870935

Epoch: 50| Step: 0
Training loss: 2.531569472509223
Validation loss: 2.9774758447008396

Epoch: 6| Step: 1
Training loss: 3.128610889910068
Validation loss: 2.9740358243467893

Epoch: 6| Step: 2
Training loss: 3.0062976539942983
Validation loss: 2.9711244289818075

Epoch: 6| Step: 3
Training loss: 3.0629694053424634
Validation loss: 2.9683721469209976

Epoch: 6| Step: 4
Training loss: 3.0754913061642677
Validation loss: 2.966065648808946

Epoch: 6| Step: 5
Training loss: 2.396778638909548
Validation loss: 2.9646068506833845

Epoch: 6| Step: 6
Training loss: 3.368516133246419
Validation loss: 2.961604798879536

Epoch: 6| Step: 7
Training loss: 2.3647961513743487
Validation loss: 2.95881288071344

Epoch: 6| Step: 8
Training loss: 4.02178577481216
Validation loss: 2.957434213142555

Epoch: 6| Step: 9
Training loss: 3.1273727564308698
Validation loss: 2.953495210993182

Epoch: 6| Step: 10
Training loss: 2.8286346482151945
Validation loss: 2.9508394819524337

Epoch: 6| Step: 11
Training loss: 3.772985332558576
Validation loss: 2.947646318491902

Epoch: 6| Step: 12
Training loss: 3.230165405053795
Validation loss: 2.9446112947354077

Epoch: 6| Step: 13
Training loss: 3.024334757143561
Validation loss: 2.9432676250803063

Epoch: 51| Step: 0
Training loss: 3.4607477760409755
Validation loss: 2.939820272808287

Epoch: 6| Step: 1
Training loss: 2.811768839422554
Validation loss: 2.9374867161660108

Epoch: 6| Step: 2
Training loss: 2.8111387561381966
Validation loss: 2.934754177263953

Epoch: 6| Step: 3
Training loss: 3.3637468146483083
Validation loss: 2.9312868627034656

Epoch: 6| Step: 4
Training loss: 3.0061926505156253
Validation loss: 2.9291446301502724

Epoch: 6| Step: 5
Training loss: 3.1834794661715105
Validation loss: 2.926367938133608

Epoch: 6| Step: 6
Training loss: 3.7057797215601687
Validation loss: 2.9236446740123494

Epoch: 6| Step: 7
Training loss: 2.7130683198081793
Validation loss: 2.9207309652357623

Epoch: 6| Step: 8
Training loss: 2.862188070700978
Validation loss: 2.917127672728538

Epoch: 6| Step: 9
Training loss: 3.3319714307167017
Validation loss: 2.9149811960991188

Epoch: 6| Step: 10
Training loss: 2.6791906313222364
Validation loss: 2.912745173753608

Epoch: 6| Step: 11
Training loss: 2.9601028594625953
Validation loss: 2.90965672244507

Epoch: 6| Step: 12
Training loss: 2.839845093276849
Validation loss: 2.9079796760956023

Epoch: 6| Step: 13
Training loss: 2.9849298570529057
Validation loss: 2.90527923668889

Epoch: 52| Step: 0
Training loss: 3.679249083365225
Validation loss: 2.90225886361536

Epoch: 6| Step: 1
Training loss: 3.1248268079448627
Validation loss: 2.89985338366598

Epoch: 6| Step: 2
Training loss: 2.991316945099606
Validation loss: 2.8986247671386787

Epoch: 6| Step: 3
Training loss: 2.4542033747036407
Validation loss: 2.894753828941892

Epoch: 6| Step: 4
Training loss: 3.6559978952464385
Validation loss: 2.8952079253123117

Epoch: 6| Step: 5
Training loss: 2.7031846232812042
Validation loss: 2.8903626468957966

Epoch: 6| Step: 6
Training loss: 2.920007608743448
Validation loss: 2.8889703087051757

Epoch: 6| Step: 7
Training loss: 3.0407857446630944
Validation loss: 2.885704788163602

Epoch: 6| Step: 8
Training loss: 2.149970378228105
Validation loss: 2.8848656129307315

Epoch: 6| Step: 9
Training loss: 2.5410348596805146
Validation loss: 2.8833139564068864

Epoch: 6| Step: 10
Training loss: 2.740876408771322
Validation loss: 2.8825644754266397

Epoch: 6| Step: 11
Training loss: 3.7798803702099018
Validation loss: 2.881311220413727

Epoch: 6| Step: 12
Training loss: 3.4152567365661044
Validation loss: 2.8756920078437895

Epoch: 6| Step: 13
Training loss: 2.682088682524822
Validation loss: 2.873925021896704

Epoch: 53| Step: 0
Training loss: 3.329644800894244
Validation loss: 2.8716562701845376

Epoch: 6| Step: 1
Training loss: 2.9765961412345976
Validation loss: 2.8690888270546995

Epoch: 6| Step: 2
Training loss: 2.6567455951384575
Validation loss: 2.8687592926650565

Epoch: 6| Step: 3
Training loss: 2.5841583862303237
Validation loss: 2.8663383009349572

Epoch: 6| Step: 4
Training loss: 3.257988428721712
Validation loss: 2.8636144953283096

Epoch: 6| Step: 5
Training loss: 3.0395065022502714
Validation loss: 2.8592358609169826

Epoch: 6| Step: 6
Training loss: 3.045103526493073
Validation loss: 2.8577546216896037

Epoch: 6| Step: 7
Training loss: 2.7250254323629983
Validation loss: 2.856528986822

Epoch: 6| Step: 8
Training loss: 2.816111132520442
Validation loss: 2.859445817692308

Epoch: 6| Step: 9
Training loss: 3.4359499124022617
Validation loss: 2.8540736459391685

Epoch: 6| Step: 10
Training loss: 2.8842409311465933
Validation loss: 2.8510782187677095

Epoch: 6| Step: 11
Training loss: 3.535439360858025
Validation loss: 2.8473112702336225

Epoch: 6| Step: 12
Training loss: 2.7424238054232695
Validation loss: 2.8457385505839823

Epoch: 6| Step: 13
Training loss: 2.7835135517670997
Validation loss: 2.8440075153389244

Epoch: 54| Step: 0
Training loss: 3.4352420673838164
Validation loss: 2.844167350353923

Epoch: 6| Step: 1
Training loss: 2.350557942812108
Validation loss: 2.8478892527118695

Epoch: 6| Step: 2
Training loss: 2.735138879070892
Validation loss: 2.8497036104959665

Epoch: 6| Step: 3
Training loss: 3.045606143547818
Validation loss: 2.850057391096349

Epoch: 6| Step: 4
Training loss: 2.981979607126671
Validation loss: 2.847750424544641

Epoch: 6| Step: 5
Training loss: 3.5392970666349997
Validation loss: 2.8453190565513777

Epoch: 6| Step: 6
Training loss: 3.0130911346032674
Validation loss: 2.841694434767679

Epoch: 6| Step: 7
Training loss: 3.4369169260906123
Validation loss: 2.837730996564386

Epoch: 6| Step: 8
Training loss: 2.6416461482489653
Validation loss: 2.8338583478503567

Epoch: 6| Step: 9
Training loss: 2.93267848623706
Validation loss: 2.8293234181040123

Epoch: 6| Step: 10
Training loss: 2.366286304515784
Validation loss: 2.8264917114908266

Epoch: 6| Step: 11
Training loss: 2.9757495480844494
Validation loss: 2.824774315070345

Epoch: 6| Step: 12
Training loss: 2.8919184909482794
Validation loss: 2.822003745982466

Epoch: 6| Step: 13
Training loss: 3.0804502737684563
Validation loss: 2.821942788989427

Epoch: 55| Step: 0
Training loss: 3.5895213583217673
Validation loss: 2.818731356134101

Epoch: 6| Step: 1
Training loss: 3.1920238630315856
Validation loss: 2.817016747029134

Epoch: 6| Step: 2
Training loss: 3.195250568862314
Validation loss: 2.8154059620912917

Epoch: 6| Step: 3
Training loss: 2.409317043611775
Validation loss: 2.8135614017122563

Epoch: 6| Step: 4
Training loss: 2.7840777819718574
Validation loss: 2.8111709138752174

Epoch: 6| Step: 5
Training loss: 3.1063352515574296
Validation loss: 2.8090392118917302

Epoch: 6| Step: 6
Training loss: 2.8123875913408916
Validation loss: 2.807510117410403

Epoch: 6| Step: 7
Training loss: 2.876852682500709
Validation loss: 2.804205666242987

Epoch: 6| Step: 8
Training loss: 3.013674881266728
Validation loss: 2.800432744815552

Epoch: 6| Step: 9
Training loss: 2.4926709510390275
Validation loss: 2.7993096777893145

Epoch: 6| Step: 10
Training loss: 3.0852510485522524
Validation loss: 2.797998980354958

Epoch: 6| Step: 11
Training loss: 2.541963299394055
Validation loss: 2.7967413758478843

Epoch: 6| Step: 12
Training loss: 2.9837658644958824
Validation loss: 2.7953280925227

Epoch: 6| Step: 13
Training loss: 2.9670442198057505
Validation loss: 2.7913445149244733

Epoch: 56| Step: 0
Training loss: 3.376178111977925
Validation loss: 2.7915823672268165

Epoch: 6| Step: 1
Training loss: 2.5090213132084545
Validation loss: 2.788401934191589

Epoch: 6| Step: 2
Training loss: 2.700279546324028
Validation loss: 2.7844335359356474

Epoch: 6| Step: 3
Training loss: 3.2959063946663205
Validation loss: 2.7842583406030066

Epoch: 6| Step: 4
Training loss: 2.599442910153203
Validation loss: 2.7807094891705693

Epoch: 6| Step: 5
Training loss: 2.9139959005563947
Validation loss: 2.77982187930889

Epoch: 6| Step: 6
Training loss: 3.2861724261635357
Validation loss: 2.7784388047053903

Epoch: 6| Step: 7
Training loss: 2.712982110279126
Validation loss: 2.773378656327235

Epoch: 6| Step: 8
Training loss: 3.1451823253575
Validation loss: 2.775240918031597

Epoch: 6| Step: 9
Training loss: 2.473893421057674
Validation loss: 2.773910396179391

Epoch: 6| Step: 10
Training loss: 3.4384497977604314
Validation loss: 2.775683987723749

Epoch: 6| Step: 11
Training loss: 2.725740412643717
Validation loss: 2.767238871641256

Epoch: 6| Step: 12
Training loss: 2.762566982510148
Validation loss: 2.7683349952792287

Epoch: 6| Step: 13
Training loss: 2.6997721611248724
Validation loss: 2.770329269412931

Epoch: 57| Step: 0
Training loss: 3.152940582538244
Validation loss: 2.770398218127236

Epoch: 6| Step: 1
Training loss: 2.9283164109370894
Validation loss: 2.767145633219245

Epoch: 6| Step: 2
Training loss: 3.330312663569862
Validation loss: 2.766717971379684

Epoch: 6| Step: 3
Training loss: 2.275413886348374
Validation loss: 2.762374634580782

Epoch: 6| Step: 4
Training loss: 1.63593974728143
Validation loss: 2.760711889254765

Epoch: 6| Step: 5
Training loss: 2.389964991197396
Validation loss: 2.7576500806087973

Epoch: 6| Step: 6
Training loss: 2.584963704487091
Validation loss: 2.756954920695718

Epoch: 6| Step: 7
Training loss: 2.8675018055119437
Validation loss: 2.7551276201758075

Epoch: 6| Step: 8
Training loss: 3.354726867018375
Validation loss: 2.7542396866606835

Epoch: 6| Step: 9
Training loss: 2.8441410005493504
Validation loss: 2.7517036305037212

Epoch: 6| Step: 10
Training loss: 3.238117503776186
Validation loss: 2.750167986045012

Epoch: 6| Step: 11
Training loss: 3.5948959513795553
Validation loss: 2.7508154151453885

Epoch: 6| Step: 12
Training loss: 2.6002758613373524
Validation loss: 2.7537011613525055

Epoch: 6| Step: 13
Training loss: 3.1445949382137366
Validation loss: 2.7542436974661006

Epoch: 58| Step: 0
Training loss: 3.275793279420585
Validation loss: 2.742221371983998

Epoch: 6| Step: 1
Training loss: 2.782143524312552
Validation loss: 2.7422293780281737

Epoch: 6| Step: 2
Training loss: 2.857705885043987
Validation loss: 2.738948550250477

Epoch: 6| Step: 3
Training loss: 3.1485989436934547
Validation loss: 2.739093030754696

Epoch: 6| Step: 4
Training loss: 2.742625405322812
Validation loss: 2.7392256954166645

Epoch: 6| Step: 5
Training loss: 2.942809480712353
Validation loss: 2.739718188507044

Epoch: 6| Step: 6
Training loss: 2.582819877378586
Validation loss: 2.7316483626839534

Epoch: 6| Step: 7
Training loss: 3.0320671002756074
Validation loss: 2.7324778633116797

Epoch: 6| Step: 8
Training loss: 3.116562247609551
Validation loss: 2.7303807467721333

Epoch: 6| Step: 9
Training loss: 2.3070488680726493
Validation loss: 2.732622562334362

Epoch: 6| Step: 10
Training loss: 2.6846056589274547
Validation loss: 2.7306916778472656

Epoch: 6| Step: 11
Training loss: 2.878071346880472
Validation loss: 2.7331170957985895

Epoch: 6| Step: 12
Training loss: 2.805746574529606
Validation loss: 2.732565624499557

Epoch: 6| Step: 13
Training loss: 2.9883388538667743
Validation loss: 2.730407568628607

Epoch: 59| Step: 0
Training loss: 3.494661346749753
Validation loss: 2.72999990764846

Epoch: 6| Step: 1
Training loss: 2.7618724990629677
Validation loss: 2.7283354408226503

Epoch: 6| Step: 2
Training loss: 3.2438316496640676
Validation loss: 2.72631460263404

Epoch: 6| Step: 3
Training loss: 2.612033973998662
Validation loss: 2.7243090538123234

Epoch: 6| Step: 4
Training loss: 3.0165059280425783
Validation loss: 2.721724888618196

Epoch: 6| Step: 5
Training loss: 3.012360540303945
Validation loss: 2.721168713737698

Epoch: 6| Step: 6
Training loss: 2.7175312160464262
Validation loss: 2.7182103494749477

Epoch: 6| Step: 7
Training loss: 2.40933792343012
Validation loss: 2.7172389892238984

Epoch: 6| Step: 8
Training loss: 3.178722488218261
Validation loss: 2.713199693995687

Epoch: 6| Step: 9
Training loss: 2.066476168107664
Validation loss: 2.7125789425755302

Epoch: 6| Step: 10
Training loss: 3.09079609118669
Validation loss: 2.7120718511151893

Epoch: 6| Step: 11
Training loss: 2.452656014678102
Validation loss: 2.7110154051859534

Epoch: 6| Step: 12
Training loss: 3.0657424888689917
Validation loss: 2.7073128513878695

Epoch: 6| Step: 13
Training loss: 2.533852922544471
Validation loss: 2.7074554976976715

Epoch: 60| Step: 0
Training loss: 2.775323103231684
Validation loss: 2.705771912477903

Epoch: 6| Step: 1
Training loss: 2.8919931833864867
Validation loss: 2.7042252905025537

Epoch: 6| Step: 2
Training loss: 3.185910595326104
Validation loss: 2.7016085007242454

Epoch: 6| Step: 3
Training loss: 3.0032805943348193
Validation loss: 2.7039242189536443

Epoch: 6| Step: 4
Training loss: 2.3923845983594036
Validation loss: 2.705232081984102

Epoch: 6| Step: 5
Training loss: 2.720407879344342
Validation loss: 2.705326249807882

Epoch: 6| Step: 6
Training loss: 3.1969443633458967
Validation loss: 2.7043939012020206

Epoch: 6| Step: 7
Training loss: 2.885622386737026
Validation loss: 2.6956430868227037

Epoch: 6| Step: 8
Training loss: 2.6091430926489028
Validation loss: 2.6928628893139597

Epoch: 6| Step: 9
Training loss: 3.239650091891948
Validation loss: 2.692526987684956

Epoch: 6| Step: 10
Training loss: 2.766337071361499
Validation loss: 2.691569463157704

Epoch: 6| Step: 11
Training loss: 2.6843443685611352
Validation loss: 2.6913131158860115

Epoch: 6| Step: 12
Training loss: 2.5681534717250636
Validation loss: 2.6956567369387217

Epoch: 6| Step: 13
Training loss: 2.7041740366439035
Validation loss: 2.698124444293013

Epoch: 61| Step: 0
Training loss: 3.2553197897585653
Validation loss: 2.699642724076032

Epoch: 6| Step: 1
Training loss: 3.1087486364640027
Validation loss: 2.6951584776578463

Epoch: 6| Step: 2
Training loss: 2.365715148095026
Validation loss: 2.6931752157380346

Epoch: 6| Step: 3
Training loss: 2.487332580913238
Validation loss: 2.6889468667472096

Epoch: 6| Step: 4
Training loss: 2.1703823092104177
Validation loss: 2.6865159828140848

Epoch: 6| Step: 5
Training loss: 3.1398844438902342
Validation loss: 2.684781377642447

Epoch: 6| Step: 6
Training loss: 2.5053757091502753
Validation loss: 2.6829790043321573

Epoch: 6| Step: 7
Training loss: 2.3721909223402933
Validation loss: 2.681182177559499

Epoch: 6| Step: 8
Training loss: 2.599753727620157
Validation loss: 2.6785326694530176

Epoch: 6| Step: 9
Training loss: 2.5097016916406956
Validation loss: 2.6793208932659773

Epoch: 6| Step: 10
Training loss: 3.444137822795021
Validation loss: 2.6793857030088977

Epoch: 6| Step: 11
Training loss: 2.800407693337055
Validation loss: 2.6820091074040526

Epoch: 6| Step: 12
Training loss: 3.344659984510728
Validation loss: 2.675106139766023

Epoch: 6| Step: 13
Training loss: 2.993371634574595
Validation loss: 2.6730952757469426

Epoch: 62| Step: 0
Training loss: 2.676766986685072
Validation loss: 2.6685133639267784

Epoch: 6| Step: 1
Training loss: 2.108756532777663
Validation loss: 2.6667640688114913

Epoch: 6| Step: 2
Training loss: 3.1461771762378206
Validation loss: 2.6664005285813244

Epoch: 6| Step: 3
Training loss: 3.076511327997013
Validation loss: 2.6660162510015293

Epoch: 6| Step: 4
Training loss: 2.660853895216848
Validation loss: 2.666439409307799

Epoch: 6| Step: 5
Training loss: 3.052719692163186
Validation loss: 2.6650608910337263

Epoch: 6| Step: 6
Training loss: 3.073998022819682
Validation loss: 2.6619383994239763

Epoch: 6| Step: 7
Training loss: 2.856501234762418
Validation loss: 2.6636999485773973

Epoch: 6| Step: 8
Training loss: 2.561901115587759
Validation loss: 2.663489435783066

Epoch: 6| Step: 9
Training loss: 2.8883225627624247
Validation loss: 2.6626113563855314

Epoch: 6| Step: 10
Training loss: 2.994254650674511
Validation loss: 2.660243559014665

Epoch: 6| Step: 11
Training loss: 2.7380168966770926
Validation loss: 2.6549825599035346

Epoch: 6| Step: 12
Training loss: 2.5460106254649584
Validation loss: 2.6568577239507523

Epoch: 6| Step: 13
Training loss: 2.6323392086065733
Validation loss: 2.661660402593565

Epoch: 63| Step: 0
Training loss: 2.507114396420858
Validation loss: 2.675238888017483

Epoch: 6| Step: 1
Training loss: 2.749999133023212
Validation loss: 2.6648212221286225

Epoch: 6| Step: 2
Training loss: 2.663174388886796
Validation loss: 2.65202417260225

Epoch: 6| Step: 3
Training loss: 3.020937179008223
Validation loss: 2.6467427970961412

Epoch: 6| Step: 4
Training loss: 3.1534195096080477
Validation loss: 2.647386985842575

Epoch: 6| Step: 5
Training loss: 2.9675528270772435
Validation loss: 2.647145273941133

Epoch: 6| Step: 6
Training loss: 2.6704832322666134
Validation loss: 2.6455828981198413

Epoch: 6| Step: 7
Training loss: 2.314609905357067
Validation loss: 2.647183101516652

Epoch: 6| Step: 8
Training loss: 2.5432734387479305
Validation loss: 2.6437216664773233

Epoch: 6| Step: 9
Training loss: 3.0053080647457557
Validation loss: 2.643680091817409

Epoch: 6| Step: 10
Training loss: 2.844807019652641
Validation loss: 2.6426262579775477

Epoch: 6| Step: 11
Training loss: 2.9553224168893237
Validation loss: 2.6422449142922524

Epoch: 6| Step: 12
Training loss: 2.7588310630099326
Validation loss: 2.6423080167199613

Epoch: 6| Step: 13
Training loss: 2.748131811026383
Validation loss: 2.642183133811058

Epoch: 64| Step: 0
Training loss: 2.807733353575056
Validation loss: 2.636878928511379

Epoch: 6| Step: 1
Training loss: 2.5672300459435196
Validation loss: 2.6419125339238407

Epoch: 6| Step: 2
Training loss: 2.709193655454764
Validation loss: 2.6458941525254955

Epoch: 6| Step: 3
Training loss: 3.218933989071689
Validation loss: 2.6490881166655447

Epoch: 6| Step: 4
Training loss: 2.948320628459232
Validation loss: 2.6581965625540858

Epoch: 6| Step: 5
Training loss: 3.0414126216058355
Validation loss: 2.6609758112612125

Epoch: 6| Step: 6
Training loss: 2.999408186712842
Validation loss: 2.660846353680822

Epoch: 6| Step: 7
Training loss: 2.6863652872275017
Validation loss: 2.6553894144843886

Epoch: 6| Step: 8
Training loss: 2.5813009409461527
Validation loss: 2.6486217843516187

Epoch: 6| Step: 9
Training loss: 2.7559318722192616
Validation loss: 2.6446294273284954

Epoch: 6| Step: 10
Training loss: 2.5734395307985687
Validation loss: 2.6415045061690985

Epoch: 6| Step: 11
Training loss: 2.550468857988438
Validation loss: 2.6399207445732484

Epoch: 6| Step: 12
Training loss: 2.987427433680823
Validation loss: 2.6374368174911282

Epoch: 6| Step: 13
Training loss: 2.482368090487372
Validation loss: 2.6349021097683933

Epoch: 65| Step: 0
Training loss: 2.48444918155882
Validation loss: 2.6314018311418237

Epoch: 6| Step: 1
Training loss: 2.350360347634573
Validation loss: 2.629860435113942

Epoch: 6| Step: 2
Training loss: 1.9992957067193673
Validation loss: 2.6310694326752584

Epoch: 6| Step: 3
Training loss: 2.519199840425236
Validation loss: 2.631046642500436

Epoch: 6| Step: 4
Training loss: 2.6723066728570632
Validation loss: 2.6288770472816183

Epoch: 6| Step: 5
Training loss: 3.3791773340046656
Validation loss: 2.6285664082265976

Epoch: 6| Step: 6
Training loss: 3.1308546536244033
Validation loss: 2.6294720868804426

Epoch: 6| Step: 7
Training loss: 3.575662623532408
Validation loss: 2.629069730862912

Epoch: 6| Step: 8
Training loss: 2.259547850353497
Validation loss: 2.625984824590712

Epoch: 6| Step: 9
Training loss: 2.5663634228435246
Validation loss: 2.625414331222518

Epoch: 6| Step: 10
Training loss: 3.1586859339325954
Validation loss: 2.623212993225434

Epoch: 6| Step: 11
Training loss: 2.2607789928496986
Validation loss: 2.6216663885348837

Epoch: 6| Step: 12
Training loss: 2.9260509656950977
Validation loss: 2.619788582549103

Epoch: 6| Step: 13
Training loss: 2.877572442939999
Validation loss: 2.620068504515344

Epoch: 66| Step: 0
Training loss: 2.6849830729201396
Validation loss: 2.6159040046260604

Epoch: 6| Step: 1
Training loss: 3.442404837030607
Validation loss: 2.6163901865327377

Epoch: 6| Step: 2
Training loss: 2.7092490971053245
Validation loss: 2.6129973161802584

Epoch: 6| Step: 3
Training loss: 2.5077083958203787
Validation loss: 2.613132839426822

Epoch: 6| Step: 4
Training loss: 2.4077386586069998
Validation loss: 2.6106373670542466

Epoch: 6| Step: 5
Training loss: 2.5018540183337503
Validation loss: 2.609593106289655

Epoch: 6| Step: 6
Training loss: 2.830180564484869
Validation loss: 2.6122441916427803

Epoch: 6| Step: 7
Training loss: 2.8278916404931596
Validation loss: 2.616368392377332

Epoch: 6| Step: 8
Training loss: 3.205559377669846
Validation loss: 2.625087766845243

Epoch: 6| Step: 9
Training loss: 2.8779262080590606
Validation loss: 2.629030917170027

Epoch: 6| Step: 10
Training loss: 2.45884339380655
Validation loss: 2.6247935289592865

Epoch: 6| Step: 11
Training loss: 2.327578896599954
Validation loss: 2.6122882136600887

Epoch: 6| Step: 12
Training loss: 2.1572592764325744
Validation loss: 2.6129567582048527

Epoch: 6| Step: 13
Training loss: 3.337709193156446
Validation loss: 2.6069390353503095

Epoch: 67| Step: 0
Training loss: 2.6540832658137457
Validation loss: 2.6050731200330617

Epoch: 6| Step: 1
Training loss: 3.122925336714185
Validation loss: 2.6042869438369967

Epoch: 6| Step: 2
Training loss: 2.9570941389242176
Validation loss: 2.60798377984411

Epoch: 6| Step: 3
Training loss: 2.822211727696862
Validation loss: 2.6080927639360167

Epoch: 6| Step: 4
Training loss: 2.106819922429745
Validation loss: 2.6117454163055984

Epoch: 6| Step: 5
Training loss: 2.590344594912392
Validation loss: 2.6173904264360344

Epoch: 6| Step: 6
Training loss: 2.5015712568712383
Validation loss: 2.6229333613932186

Epoch: 6| Step: 7
Training loss: 2.593596028733081
Validation loss: 2.6236416163055782

Epoch: 6| Step: 8
Training loss: 3.2454995025695506
Validation loss: 2.6155553330684507

Epoch: 6| Step: 9
Training loss: 3.048938541502337
Validation loss: 2.610915424124994

Epoch: 6| Step: 10
Training loss: 2.9199408182913946
Validation loss: 2.607188833730851

Epoch: 6| Step: 11
Training loss: 2.655662381866792
Validation loss: 2.6060403161656955

Epoch: 6| Step: 12
Training loss: 2.5642845638802343
Validation loss: 2.603630702496282

Epoch: 6| Step: 13
Training loss: 2.46733342343756
Validation loss: 2.601436707411923

Epoch: 68| Step: 0
Training loss: 2.993758384358366
Validation loss: 2.5983688868434536

Epoch: 6| Step: 1
Training loss: 2.135438525080264
Validation loss: 2.6000615736199384

Epoch: 6| Step: 2
Training loss: 2.7044007923438205
Validation loss: 2.599074096751664

Epoch: 6| Step: 3
Training loss: 2.673445836583154
Validation loss: 2.603885442172025

Epoch: 6| Step: 4
Training loss: 2.719492931364495
Validation loss: 2.5981475900795594

Epoch: 6| Step: 5
Training loss: 2.736779686905211
Validation loss: 2.5969348641973027

Epoch: 6| Step: 6
Training loss: 2.326884201486547
Validation loss: 2.597123828141578

Epoch: 6| Step: 7
Training loss: 3.0745233678098765
Validation loss: 2.5928010085388675

Epoch: 6| Step: 8
Training loss: 2.5919554603658814
Validation loss: 2.589918163337137

Epoch: 6| Step: 9
Training loss: 2.5781612509288507
Validation loss: 2.586687161824873

Epoch: 6| Step: 10
Training loss: 3.225579728649792
Validation loss: 2.5874134012372236

Epoch: 6| Step: 11
Training loss: 2.7698017198127443
Validation loss: 2.5849252431009786

Epoch: 6| Step: 12
Training loss: 2.5227372937077623
Validation loss: 2.5830252114991747

Epoch: 6| Step: 13
Training loss: 2.93325791550988
Validation loss: 2.5805138203951095

Epoch: 69| Step: 0
Training loss: 3.0824195607526796
Validation loss: 2.580835709103197

Epoch: 6| Step: 1
Training loss: 2.9497913739416
Validation loss: 2.5857032446963

Epoch: 6| Step: 2
Training loss: 2.9071379914917537
Validation loss: 2.590210748122816

Epoch: 6| Step: 3
Training loss: 2.799933524705066
Validation loss: 2.5765679637942767

Epoch: 6| Step: 4
Training loss: 2.3180612245427774
Validation loss: 2.574421960955414

Epoch: 6| Step: 5
Training loss: 2.9538823524039106
Validation loss: 2.575969650510336

Epoch: 6| Step: 6
Training loss: 2.6594501740244914
Validation loss: 2.573697274180423

Epoch: 6| Step: 7
Training loss: 2.4658226330434627
Validation loss: 2.5755923228793267

Epoch: 6| Step: 8
Training loss: 2.6996621238380447
Validation loss: 2.575937965692597

Epoch: 6| Step: 9
Training loss: 2.92135191126316
Validation loss: 2.576520385768141

Epoch: 6| Step: 10
Training loss: 2.678016163629778
Validation loss: 2.5723251301132612

Epoch: 6| Step: 11
Training loss: 2.4418360949722797
Validation loss: 2.5709359940403553

Epoch: 6| Step: 12
Training loss: 2.338829470272603
Validation loss: 2.5736045278277544

Epoch: 6| Step: 13
Training loss: 2.66154849104393
Validation loss: 2.571412165276602

Epoch: 70| Step: 0
Training loss: 2.5140838641105927
Validation loss: 2.571061818393928

Epoch: 6| Step: 1
Training loss: 2.7024983467993327
Validation loss: 2.5707856644261153

Epoch: 6| Step: 2
Training loss: 2.8609474736138276
Validation loss: 2.56970635932151

Epoch: 6| Step: 3
Training loss: 2.405102344643156
Validation loss: 2.5711056182287577

Epoch: 6| Step: 4
Training loss: 2.891136990130894
Validation loss: 2.572489735218622

Epoch: 6| Step: 5
Training loss: 2.596899211968066
Validation loss: 2.5696310359344996

Epoch: 6| Step: 6
Training loss: 2.755322940127805
Validation loss: 2.571084506616057

Epoch: 6| Step: 7
Training loss: 2.6251824633443728
Validation loss: 2.5661689729900896

Epoch: 6| Step: 8
Training loss: 2.421528748402463
Validation loss: 2.567611295299226

Epoch: 6| Step: 9
Training loss: 2.7438026301521727
Validation loss: 2.5709974309729637

Epoch: 6| Step: 10
Training loss: 2.7841274506784157
Validation loss: 2.56923912075682

Epoch: 6| Step: 11
Training loss: 2.95141261271996
Validation loss: 2.573816726311188

Epoch: 6| Step: 12
Training loss: 2.737506925669928
Validation loss: 2.565005930199067

Epoch: 6| Step: 13
Training loss: 2.777478436129664
Validation loss: 2.566077348215787

Epoch: 71| Step: 0
Training loss: 2.2635480107936674
Validation loss: 2.5656763564935345

Epoch: 6| Step: 1
Training loss: 2.596273458610862
Validation loss: 2.563491861933511

Epoch: 6| Step: 2
Training loss: 2.9116529878478077
Validation loss: 2.5626558861186512

Epoch: 6| Step: 3
Training loss: 2.5122513035913108
Validation loss: 2.5650377500555823

Epoch: 6| Step: 4
Training loss: 2.4560051793593676
Validation loss: 2.5631559664357826

Epoch: 6| Step: 5
Training loss: 2.8105489109183037
Validation loss: 2.560235348627055

Epoch: 6| Step: 6
Training loss: 3.0793144909825303
Validation loss: 2.5608971863157657

Epoch: 6| Step: 7
Training loss: 2.715265342855205
Validation loss: 2.5555871046463894

Epoch: 6| Step: 8
Training loss: 2.2100381808197684
Validation loss: 2.5570463903289498

Epoch: 6| Step: 9
Training loss: 2.6467164335528413
Validation loss: 2.561438720636313

Epoch: 6| Step: 10
Training loss: 3.249596497356231
Validation loss: 2.5574078245385397

Epoch: 6| Step: 11
Training loss: 2.6788332275334907
Validation loss: 2.55763628179223

Epoch: 6| Step: 12
Training loss: 2.7262929876087543
Validation loss: 2.5522882859332174

Epoch: 6| Step: 13
Training loss: 2.7118889186244353
Validation loss: 2.5575425801192693

Epoch: 72| Step: 0
Training loss: 2.239714957221032
Validation loss: 2.5556314417956187

Epoch: 6| Step: 1
Training loss: 2.0225781121748136
Validation loss: 2.552881969649659

Epoch: 6| Step: 2
Training loss: 2.663059974490694
Validation loss: 2.5541228779642844

Epoch: 6| Step: 3
Training loss: 2.8653287345467087
Validation loss: 2.5542173429339683

Epoch: 6| Step: 4
Training loss: 2.8133133453936687
Validation loss: 2.5512363870953143

Epoch: 6| Step: 5
Training loss: 2.876199886543617
Validation loss: 2.551993066138531

Epoch: 6| Step: 6
Training loss: 2.8332532048582166
Validation loss: 2.565163182129979

Epoch: 6| Step: 7
Training loss: 2.983485703510945
Validation loss: 2.567087780684887

Epoch: 6| Step: 8
Training loss: 3.0054624418108675
Validation loss: 2.5588877113504482

Epoch: 6| Step: 9
Training loss: 3.14050991170115
Validation loss: 2.5563353377370137

Epoch: 6| Step: 10
Training loss: 2.568542984465963
Validation loss: 2.5666687094279825

Epoch: 6| Step: 11
Training loss: 2.672002064321486
Validation loss: 2.563332709257383

Epoch: 6| Step: 12
Training loss: 2.4952549726510993
Validation loss: 2.5514850356300878

Epoch: 6| Step: 13
Training loss: 2.2994912745904745
Validation loss: 2.547136929076745

Epoch: 73| Step: 0
Training loss: 3.2854029940407545
Validation loss: 2.5507119107521796

Epoch: 6| Step: 1
Training loss: 2.8580639444382707
Validation loss: 2.5539503210230268

Epoch: 6| Step: 2
Training loss: 2.507306104258445
Validation loss: 2.5520103651761032

Epoch: 6| Step: 3
Training loss: 2.3718227415899347
Validation loss: 2.555593363049166

Epoch: 6| Step: 4
Training loss: 2.41956056325201
Validation loss: 2.557105053051141

Epoch: 6| Step: 5
Training loss: 2.8367629518167012
Validation loss: 2.5618438811132713

Epoch: 6| Step: 6
Training loss: 2.3855564015424546
Validation loss: 2.5671777441389287

Epoch: 6| Step: 7
Training loss: 2.748511605188117
Validation loss: 2.56757766566545

Epoch: 6| Step: 8
Training loss: 2.7818666267483265
Validation loss: 2.5627629214988032

Epoch: 6| Step: 9
Training loss: 2.455781894952435
Validation loss: 2.558194210316356

Epoch: 6| Step: 10
Training loss: 2.7008005191732423
Validation loss: 2.55711989334108

Epoch: 6| Step: 11
Training loss: 2.319056520997927
Validation loss: 2.5531723397829795

Epoch: 6| Step: 12
Training loss: 3.1559656600534365
Validation loss: 2.5512123697743183

Epoch: 6| Step: 13
Training loss: 2.5718577647413836
Validation loss: 2.547644968796496

Epoch: 74| Step: 0
Training loss: 2.40915633222364
Validation loss: 2.5429573429943693

Epoch: 6| Step: 1
Training loss: 2.479853804647673
Validation loss: 2.542936044571552

Epoch: 6| Step: 2
Training loss: 2.6347954863601553
Validation loss: 2.5423000411601375

Epoch: 6| Step: 3
Training loss: 2.909554520424771
Validation loss: 2.5458306197564564

Epoch: 6| Step: 4
Training loss: 3.007910313192445
Validation loss: 2.543961322951258

Epoch: 6| Step: 5
Training loss: 2.932789698711811
Validation loss: 2.5444709181160285

Epoch: 6| Step: 6
Training loss: 3.1223782031675347
Validation loss: 2.54359386942829

Epoch: 6| Step: 7
Training loss: 2.2910443472464266
Validation loss: 2.5470085343067024

Epoch: 6| Step: 8
Training loss: 3.099486609986144
Validation loss: 2.5484130443441932

Epoch: 6| Step: 9
Training loss: 2.4607666925160414
Validation loss: 2.54219995959448

Epoch: 6| Step: 10
Training loss: 2.0158322249944742
Validation loss: 2.541638957847102

Epoch: 6| Step: 11
Training loss: 2.702524460250444
Validation loss: 2.541045602889918

Epoch: 6| Step: 12
Training loss: 2.8338198150663523
Validation loss: 2.542082226243461

Epoch: 6| Step: 13
Training loss: 2.3048958377099975
Validation loss: 2.543640141844678

Epoch: 75| Step: 0
Training loss: 2.9790619696157776
Validation loss: 2.5455265024674163

Epoch: 6| Step: 1
Training loss: 2.7367877887247114
Validation loss: 2.550426947312205

Epoch: 6| Step: 2
Training loss: 2.3811709894003243
Validation loss: 2.555644891278519

Epoch: 6| Step: 3
Training loss: 2.8690113222863425
Validation loss: 2.553640417385926

Epoch: 6| Step: 4
Training loss: 2.751639311030836
Validation loss: 2.5535602629675003

Epoch: 6| Step: 5
Training loss: 2.3386994940861716
Validation loss: 2.5515208552198003

Epoch: 6| Step: 6
Training loss: 2.9328501809188654
Validation loss: 2.550189398918688

Epoch: 6| Step: 7
Training loss: 2.794146608196664
Validation loss: 2.5467866909576653

Epoch: 6| Step: 8
Training loss: 2.464036715704604
Validation loss: 2.542708782574714

Epoch: 6| Step: 9
Training loss: 2.8063929056258443
Validation loss: 2.5430219715992823

Epoch: 6| Step: 10
Training loss: 2.251957254000714
Validation loss: 2.5373217127011527

Epoch: 6| Step: 11
Training loss: 2.8761723657348828
Validation loss: 2.5359589844344175

Epoch: 6| Step: 12
Training loss: 2.599822140992518
Validation loss: 2.5363100127315614

Epoch: 6| Step: 13
Training loss: 2.6014250297998105
Validation loss: 2.5337688174220996

Epoch: 76| Step: 0
Training loss: 2.594938442551168
Validation loss: 2.53287180996451

Epoch: 6| Step: 1
Training loss: 1.942091024738635
Validation loss: 2.5352866712818947

Epoch: 6| Step: 2
Training loss: 2.5679138493392206
Validation loss: 2.5350088459690703

Epoch: 6| Step: 3
Training loss: 2.758808939364235
Validation loss: 2.5332967544307397

Epoch: 6| Step: 4
Training loss: 2.7667192783485546
Validation loss: 2.534116526890333

Epoch: 6| Step: 5
Training loss: 2.542678933687963
Validation loss: 2.5315602901210355

Epoch: 6| Step: 6
Training loss: 2.5958278560019354
Validation loss: 2.535171500906112

Epoch: 6| Step: 7
Training loss: 2.8691489347437527
Validation loss: 2.531399632179531

Epoch: 6| Step: 8
Training loss: 3.2038086696555794
Validation loss: 2.5314274478455934

Epoch: 6| Step: 9
Training loss: 2.633900041402594
Validation loss: 2.53027502364405

Epoch: 6| Step: 10
Training loss: 2.5965116574888674
Validation loss: 2.5288076037994056

Epoch: 6| Step: 11
Training loss: 2.7909574509278
Validation loss: 2.5261934896771043

Epoch: 6| Step: 12
Training loss: 2.7615202706978006
Validation loss: 2.5275803877249574

Epoch: 6| Step: 13
Training loss: 2.4984641125605407
Validation loss: 2.529427221368842

Epoch: 77| Step: 0
Training loss: 2.3783738115159037
Validation loss: 2.529013646590889

Epoch: 6| Step: 1
Training loss: 2.1881712837194742
Validation loss: 2.530081820842334

Epoch: 6| Step: 2
Training loss: 2.783294269340936
Validation loss: 2.526521402534723

Epoch: 6| Step: 3
Training loss: 2.559559507321718
Validation loss: 2.5253232163639834

Epoch: 6| Step: 4
Training loss: 2.5734547246786184
Validation loss: 2.5273273041006807

Epoch: 6| Step: 5
Training loss: 2.609865976159156
Validation loss: 2.525465584311436

Epoch: 6| Step: 6
Training loss: 2.186552660032503
Validation loss: 2.5233113953188115

Epoch: 6| Step: 7
Training loss: 2.9774429741178143
Validation loss: 2.5281266773974336

Epoch: 6| Step: 8
Training loss: 2.734139917349967
Validation loss: 2.5198241622951016

Epoch: 6| Step: 9
Training loss: 2.4258082783002592
Validation loss: 2.5242096749948097

Epoch: 6| Step: 10
Training loss: 2.930692047829561
Validation loss: 2.5288723583226806

Epoch: 6| Step: 11
Training loss: 3.009325474285004
Validation loss: 2.5167780379942752

Epoch: 6| Step: 12
Training loss: 3.020775858014426
Validation loss: 2.5231291717401576

Epoch: 6| Step: 13
Training loss: 2.5953354183978763
Validation loss: 2.5203692479296813

Epoch: 78| Step: 0
Training loss: 2.967939567372242
Validation loss: 2.518038790165933

Epoch: 6| Step: 1
Training loss: 2.6934204537241397
Validation loss: 2.5199415873261763

Epoch: 6| Step: 2
Training loss: 2.258396060067773
Validation loss: 2.522781617518877

Epoch: 6| Step: 3
Training loss: 2.2996184903393955
Validation loss: 2.52790021396068

Epoch: 6| Step: 4
Training loss: 2.975989419231269
Validation loss: 2.5282853744055442

Epoch: 6| Step: 5
Training loss: 2.415948519935092
Validation loss: 2.5205272036800093

Epoch: 6| Step: 6
Training loss: 2.23049044890797
Validation loss: 2.514826598538021

Epoch: 6| Step: 7
Training loss: 2.891353865826388
Validation loss: 2.5200083672672204

Epoch: 6| Step: 8
Training loss: 1.7503811557397013
Validation loss: 2.522520672323096

Epoch: 6| Step: 9
Training loss: 2.9228837011159072
Validation loss: 2.5214972659450527

Epoch: 6| Step: 10
Training loss: 2.6445836297261387
Validation loss: 2.5176865559526385

Epoch: 6| Step: 11
Training loss: 2.966915648081285
Validation loss: 2.519486869007133

Epoch: 6| Step: 12
Training loss: 2.8199963167856392
Validation loss: 2.521100673738927

Epoch: 6| Step: 13
Training loss: 2.821183426814778
Validation loss: 2.521843303306327

Epoch: 79| Step: 0
Training loss: 2.644568123271599
Validation loss: 2.519854557871006

Epoch: 6| Step: 1
Training loss: 2.6509316552100097
Validation loss: 2.517462523306766

Epoch: 6| Step: 2
Training loss: 2.7943891848018763
Validation loss: 2.518850734390687

Epoch: 6| Step: 3
Training loss: 3.088911492183447
Validation loss: 2.5219124672653934

Epoch: 6| Step: 4
Training loss: 2.9887401353137992
Validation loss: 2.519461121679774

Epoch: 6| Step: 5
Training loss: 2.5574574051010606
Validation loss: 2.5211729551265334

Epoch: 6| Step: 6
Training loss: 2.745588752686198
Validation loss: 2.5231226044533943

Epoch: 6| Step: 7
Training loss: 2.5650885928434795
Validation loss: 2.519905563267795

Epoch: 6| Step: 8
Training loss: 2.8211953427179908
Validation loss: 2.5197826329090747

Epoch: 6| Step: 9
Training loss: 2.4260753017227032
Validation loss: 2.5228766496184796

Epoch: 6| Step: 10
Training loss: 1.8177038008698043
Validation loss: 2.5232113794951485

Epoch: 6| Step: 11
Training loss: 2.4482029416043165
Validation loss: 2.5171378189384126

Epoch: 6| Step: 12
Training loss: 2.509451072366391
Validation loss: 2.51562831712587

Epoch: 6| Step: 13
Training loss: 2.7750157123842545
Validation loss: 2.514708152481715

Epoch: 80| Step: 0
Training loss: 2.082467496877038
Validation loss: 2.519518932539134

Epoch: 6| Step: 1
Training loss: 2.398861428237568
Validation loss: 2.516337023444769

Epoch: 6| Step: 2
Training loss: 2.609839483711078
Validation loss: 2.515380105049943

Epoch: 6| Step: 3
Training loss: 2.5513848004013897
Validation loss: 2.51737738125392

Epoch: 6| Step: 4
Training loss: 2.8272188536945264
Validation loss: 2.510987139157572

Epoch: 6| Step: 5
Training loss: 2.393994219799282
Validation loss: 2.516263166084593

Epoch: 6| Step: 6
Training loss: 2.7964179661881507
Validation loss: 2.511698009351939

Epoch: 6| Step: 7
Training loss: 2.528338134985706
Validation loss: 2.5126944427152678

Epoch: 6| Step: 8
Training loss: 2.967848148893015
Validation loss: 2.5108120449956033

Epoch: 6| Step: 9
Training loss: 3.3541547091884993
Validation loss: 2.5116168486479444

Epoch: 6| Step: 10
Training loss: 2.488701466001385
Validation loss: 2.5076198801001977

Epoch: 6| Step: 11
Training loss: 2.4767896866911427
Validation loss: 2.509922981524374

Epoch: 6| Step: 12
Training loss: 2.544077829142108
Validation loss: 2.502451632346992

Epoch: 6| Step: 13
Training loss: 2.6609799626401296
Validation loss: 2.5109219708661765

Epoch: 81| Step: 0
Training loss: 2.6978703400354633
Validation loss: 2.5075907861737172

Epoch: 6| Step: 1
Training loss: 2.8366488150525373
Validation loss: 2.511421767456061

Epoch: 6| Step: 2
Training loss: 2.7680686026103696
Validation loss: 2.513355123524938

Epoch: 6| Step: 3
Training loss: 2.5828080617470754
Validation loss: 2.5147325026401512

Epoch: 6| Step: 4
Training loss: 2.469175277971316
Validation loss: 2.521128555749524

Epoch: 6| Step: 5
Training loss: 1.9661863074441992
Validation loss: 2.51680846246411

Epoch: 6| Step: 6
Training loss: 2.9810718411167842
Validation loss: 2.5114258496021593

Epoch: 6| Step: 7
Training loss: 2.646078313664794
Validation loss: 2.5026732298616423

Epoch: 6| Step: 8
Training loss: 2.0853910837754244
Validation loss: 2.5155886376953545

Epoch: 6| Step: 9
Training loss: 2.953975171624703
Validation loss: 2.5129839537027663

Epoch: 6| Step: 10
Training loss: 2.582631190052224
Validation loss: 2.5106499169179743

Epoch: 6| Step: 11
Training loss: 2.636317062863423
Validation loss: 2.505846720757946

Epoch: 6| Step: 12
Training loss: 2.6468531728157543
Validation loss: 2.5091497355784864

Epoch: 6| Step: 13
Training loss: 2.8223522133397525
Validation loss: 2.5045402148803038

Epoch: 82| Step: 0
Training loss: 2.632129433426305
Validation loss: 2.506493083679247

Epoch: 6| Step: 1
Training loss: 2.882907772815929
Validation loss: 2.5069312808277378

Epoch: 6| Step: 2
Training loss: 2.3731680379947937
Validation loss: 2.5044293742397308

Epoch: 6| Step: 3
Training loss: 2.0577554172022356
Validation loss: 2.508339451204699

Epoch: 6| Step: 4
Training loss: 2.5551342121564904
Validation loss: 2.504367684681364

Epoch: 6| Step: 5
Training loss: 2.65244999758432
Validation loss: 2.5072993528921566

Epoch: 6| Step: 6
Training loss: 2.9568349957063034
Validation loss: 2.5066373137351676

Epoch: 6| Step: 7
Training loss: 2.657185558043372
Validation loss: 2.505956483873612

Epoch: 6| Step: 8
Training loss: 2.4900211497255045
Validation loss: 2.509113326944229

Epoch: 6| Step: 9
Training loss: 2.7650204444943403
Validation loss: 2.5068709367687285

Epoch: 6| Step: 10
Training loss: 2.5007600582598957
Validation loss: 2.5080002885744292

Epoch: 6| Step: 11
Training loss: 2.3690265021075616
Validation loss: 2.5081843400556827

Epoch: 6| Step: 12
Training loss: 2.427183179206877
Validation loss: 2.506209545490763

Epoch: 6| Step: 13
Training loss: 3.2171589891338517
Validation loss: 2.5056416116368245

Epoch: 83| Step: 0
Training loss: 2.8537940086015796
Validation loss: 2.4996709607074687

Epoch: 6| Step: 1
Training loss: 2.9780173763590576
Validation loss: 2.507449677426073

Epoch: 6| Step: 2
Training loss: 2.7654940471788563
Validation loss: 2.508172156984335

Epoch: 6| Step: 3
Training loss: 2.1538954332237124
Validation loss: 2.506418080136005

Epoch: 6| Step: 4
Training loss: 2.8792509082296918
Validation loss: 2.5210760540927795

Epoch: 6| Step: 5
Training loss: 2.980470989821406
Validation loss: 2.5257039476878456

Epoch: 6| Step: 6
Training loss: 2.934165522986762
Validation loss: 2.527163468170339

Epoch: 6| Step: 7
Training loss: 2.645699585264962
Validation loss: 2.514588657890778

Epoch: 6| Step: 8
Training loss: 2.536321762972346
Validation loss: 2.5061947684096255

Epoch: 6| Step: 9
Training loss: 2.7511495441709615
Validation loss: 2.4957162713909535

Epoch: 6| Step: 10
Training loss: 2.5076481180001546
Validation loss: 2.5007622351534775

Epoch: 6| Step: 11
Training loss: 2.1026865849387066
Validation loss: 2.497290621315709

Epoch: 6| Step: 12
Training loss: 2.2722498357577394
Validation loss: 2.4963191273426366

Epoch: 6| Step: 13
Training loss: 2.363946792584678
Validation loss: 2.5003586114535357

Epoch: 84| Step: 0
Training loss: 3.097659944433484
Validation loss: 2.5017507780481814

Epoch: 6| Step: 1
Training loss: 2.768532986026057
Validation loss: 2.501529241782002

Epoch: 6| Step: 2
Training loss: 2.603657380213464
Validation loss: 2.501657921684512

Epoch: 6| Step: 3
Training loss: 2.4249494173732464
Validation loss: 2.501702348944705

Epoch: 6| Step: 4
Training loss: 2.3851154142720628
Validation loss: 2.4999524111986724

Epoch: 6| Step: 5
Training loss: 2.6813738885459037
Validation loss: 2.4993029576359587

Epoch: 6| Step: 6
Training loss: 2.9398519961413547
Validation loss: 2.501623389547252

Epoch: 6| Step: 7
Training loss: 3.0071407211964054
Validation loss: 2.5016922309716327

Epoch: 6| Step: 8
Training loss: 2.131877316865358
Validation loss: 2.499325009458405

Epoch: 6| Step: 9
Training loss: 2.4972268936779254
Validation loss: 2.5026424430172094

Epoch: 6| Step: 10
Training loss: 2.5169273464612565
Validation loss: 2.5016461039322198

Epoch: 6| Step: 11
Training loss: 2.463046184712362
Validation loss: 2.497896485701851

Epoch: 6| Step: 12
Training loss: 2.251026978828024
Validation loss: 2.501949233866794

Epoch: 6| Step: 13
Training loss: 2.652816348325284
Validation loss: 2.5080219945820272

Epoch: 85| Step: 0
Training loss: 3.0012925860185056
Validation loss: 2.5174067724771074

Epoch: 6| Step: 1
Training loss: 2.7415034209777427
Validation loss: 2.5052566417919087

Epoch: 6| Step: 2
Training loss: 2.668234324606957
Validation loss: 2.502496871209515

Epoch: 6| Step: 3
Training loss: 2.1539391560439802
Validation loss: 2.498083174508628

Epoch: 6| Step: 4
Training loss: 2.0780864511227253
Validation loss: 2.491880248451494

Epoch: 6| Step: 5
Training loss: 2.3385155781832023
Validation loss: 2.4957306328618505

Epoch: 6| Step: 6
Training loss: 2.3252706759823147
Validation loss: 2.500931836351055

Epoch: 6| Step: 7
Training loss: 2.732068816819303
Validation loss: 2.4985609840348837

Epoch: 6| Step: 8
Training loss: 2.9128600393262314
Validation loss: 2.497426838660804

Epoch: 6| Step: 9
Training loss: 2.823593302546171
Validation loss: 2.49781936273579

Epoch: 6| Step: 10
Training loss: 2.654908503448307
Validation loss: 2.497595600389731

Epoch: 6| Step: 11
Training loss: 2.2158998262438465
Validation loss: 2.4952887728046136

Epoch: 6| Step: 12
Training loss: 3.012395681260766
Validation loss: 2.4960786423999557

Epoch: 6| Step: 13
Training loss: 2.8383852481032927
Validation loss: 2.4962883258055713

Epoch: 86| Step: 0
Training loss: 2.4515382530904892
Validation loss: 2.49788573189978

Epoch: 6| Step: 1
Training loss: 2.3795931721637933
Validation loss: 2.4945160481919317

Epoch: 6| Step: 2
Training loss: 2.112876190457835
Validation loss: 2.490829289002218

Epoch: 6| Step: 3
Training loss: 2.2706702520857744
Validation loss: 2.4937762355460125

Epoch: 6| Step: 4
Training loss: 2.5151335431661908
Validation loss: 2.4912421527234287

Epoch: 6| Step: 5
Training loss: 2.4728696227854727
Validation loss: 2.496038715868221

Epoch: 6| Step: 6
Training loss: 3.0559067110132823
Validation loss: 2.497555578782495

Epoch: 6| Step: 7
Training loss: 2.1301901769136333
Validation loss: 2.494758945534551

Epoch: 6| Step: 8
Training loss: 2.562209694397866
Validation loss: 2.4883839472762834

Epoch: 6| Step: 9
Training loss: 2.903859786061388
Validation loss: 2.4956451793007353

Epoch: 6| Step: 10
Training loss: 2.8318815625850733
Validation loss: 2.492521831604323

Epoch: 6| Step: 11
Training loss: 3.438800635067299
Validation loss: 2.4866329784344257

Epoch: 6| Step: 12
Training loss: 2.6534148400533843
Validation loss: 2.487881279483252

Epoch: 6| Step: 13
Training loss: 2.576407953164947
Validation loss: 2.4947678333224474

Epoch: 87| Step: 0
Training loss: 2.845381048928005
Validation loss: 2.4949194464615223

Epoch: 6| Step: 1
Training loss: 2.0664413247259543
Validation loss: 2.4985873840809467

Epoch: 6| Step: 2
Training loss: 2.2182483374603277
Validation loss: 2.501546953332878

Epoch: 6| Step: 3
Training loss: 2.7287517164210096
Validation loss: 2.4972331949100672

Epoch: 6| Step: 4
Training loss: 2.7392762644209188
Validation loss: 2.500250541530566

Epoch: 6| Step: 5
Training loss: 2.5037983649425164
Validation loss: 2.502124408275723

Epoch: 6| Step: 6
Training loss: 2.4074141423492557
Validation loss: 2.506930876636745

Epoch: 6| Step: 7
Training loss: 2.873497279978179
Validation loss: 2.504424550831081

Epoch: 6| Step: 8
Training loss: 3.1716729461506192
Validation loss: 2.5020575004046606

Epoch: 6| Step: 9
Training loss: 2.442262935632676
Validation loss: 2.504513671325912

Epoch: 6| Step: 10
Training loss: 2.5010143129716322
Validation loss: 2.502651271052589

Epoch: 6| Step: 11
Training loss: 2.7495217340903766
Validation loss: 2.5011444492237493

Epoch: 6| Step: 12
Training loss: 2.8929656578581064
Validation loss: 2.497915066126506

Epoch: 6| Step: 13
Training loss: 2.3705022284580353
Validation loss: 2.4991754443642114

Epoch: 88| Step: 0
Training loss: 2.5289175330880513
Validation loss: 2.495488212257488

Epoch: 6| Step: 1
Training loss: 2.352028733986221
Validation loss: 2.4929889757433132

Epoch: 6| Step: 2
Training loss: 2.992659807901673
Validation loss: 2.491131717344935

Epoch: 6| Step: 3
Training loss: 2.1353512141423616
Validation loss: 2.4879215285876017

Epoch: 6| Step: 4
Training loss: 2.305072092844484
Validation loss: 2.487498752715087

Epoch: 6| Step: 5
Training loss: 2.2866152026703155
Validation loss: 2.4920827590473147

Epoch: 6| Step: 6
Training loss: 2.30975426229659
Validation loss: 2.4905625390134456

Epoch: 6| Step: 7
Training loss: 3.255983566542636
Validation loss: 2.4935708028581782

Epoch: 6| Step: 8
Training loss: 2.505778976661092
Validation loss: 2.4928947888047186

Epoch: 6| Step: 9
Training loss: 2.9016634938417893
Validation loss: 2.492646512897464

Epoch: 6| Step: 10
Training loss: 2.3209324275102987
Validation loss: 2.486090909235288

Epoch: 6| Step: 11
Training loss: 2.642579207663304
Validation loss: 2.4895772707770893

Epoch: 6| Step: 12
Training loss: 2.806451864139997
Validation loss: 2.4892686833907143

Epoch: 6| Step: 13
Training loss: 3.0321830021528915
Validation loss: 2.4842425457015707

Epoch: 89| Step: 0
Training loss: 2.8676857164634
Validation loss: 2.4824169127872153

Epoch: 6| Step: 1
Training loss: 2.499491258356017
Validation loss: 2.4864453500111194

Epoch: 6| Step: 2
Training loss: 2.604278155165584
Validation loss: 2.4875025865806535

Epoch: 6| Step: 3
Training loss: 2.9872061995962467
Validation loss: 2.48994708629289

Epoch: 6| Step: 4
Training loss: 2.6816226655785176
Validation loss: 2.4878370526332128

Epoch: 6| Step: 5
Training loss: 2.6053151967612473
Validation loss: 2.4897707039992745

Epoch: 6| Step: 6
Training loss: 2.9251652923569744
Validation loss: 2.4930264168125316

Epoch: 6| Step: 7
Training loss: 2.97020099717562
Validation loss: 2.4927387644313983

Epoch: 6| Step: 8
Training loss: 2.7264451490796473
Validation loss: 2.4896026887234384

Epoch: 6| Step: 9
Training loss: 2.5877461634207535
Validation loss: 2.4919907224134454

Epoch: 6| Step: 10
Training loss: 2.44179371925288
Validation loss: 2.4893086227313623

Epoch: 6| Step: 11
Training loss: 2.361432624568136
Validation loss: 2.4888504630861545

Epoch: 6| Step: 12
Training loss: 2.0883983711939202
Validation loss: 2.4898596148767975

Epoch: 6| Step: 13
Training loss: 2.026324359487166
Validation loss: 2.4865087786637856

Epoch: 90| Step: 0
Training loss: 3.121173499548243
Validation loss: 2.4842819100459477

Epoch: 6| Step: 1
Training loss: 2.445431642402538
Validation loss: 2.48599089847473

Epoch: 6| Step: 2
Training loss: 2.5943816920970457
Validation loss: 2.48022022353944

Epoch: 6| Step: 3
Training loss: 2.3480768572756174
Validation loss: 2.4853192660188745

Epoch: 6| Step: 4
Training loss: 2.303117223594508
Validation loss: 2.483545312752127

Epoch: 6| Step: 5
Training loss: 2.7060683438339552
Validation loss: 2.489485436806493

Epoch: 6| Step: 6
Training loss: 2.463062737158795
Validation loss: 2.4917545161713606

Epoch: 6| Step: 7
Training loss: 2.5915368071114724
Validation loss: 2.4877998209700776

Epoch: 6| Step: 8
Training loss: 2.657392547817925
Validation loss: 2.4832551139528745

Epoch: 6| Step: 9
Training loss: 2.7654774082263187
Validation loss: 2.480394577559415

Epoch: 6| Step: 10
Training loss: 2.633824275725161
Validation loss: 2.4820869834181036

Epoch: 6| Step: 11
Training loss: 2.412877653141734
Validation loss: 2.479382278512474

Epoch: 6| Step: 12
Training loss: 2.7241224503295824
Validation loss: 2.4829004258146763

Epoch: 6| Step: 13
Training loss: 2.7761670931786595
Validation loss: 2.4885459611381138

Epoch: 91| Step: 0
Training loss: 2.5307398152420117
Validation loss: 2.486319223024904

Epoch: 6| Step: 1
Training loss: 2.795197564582659
Validation loss: 2.484864320690447

Epoch: 6| Step: 2
Training loss: 2.8940867547329847
Validation loss: 2.481452054141316

Epoch: 6| Step: 3
Training loss: 2.7224375829906604
Validation loss: 2.4882342195882092

Epoch: 6| Step: 4
Training loss: 2.549162603771825
Validation loss: 2.4849644087731444

Epoch: 6| Step: 5
Training loss: 2.2135807048870704
Validation loss: 2.485461191533708

Epoch: 6| Step: 6
Training loss: 2.510889939983521
Validation loss: 2.4839716969831542

Epoch: 6| Step: 7
Training loss: 2.599114168090881
Validation loss: 2.484277127495339

Epoch: 6| Step: 8
Training loss: 2.3733528850407293
Validation loss: 2.4889460723013834

Epoch: 6| Step: 9
Training loss: 2.4943623873612313
Validation loss: 2.4807401894060144

Epoch: 6| Step: 10
Training loss: 2.8955768133114876
Validation loss: 2.481196323329857

Epoch: 6| Step: 11
Training loss: 2.8111033892703476
Validation loss: 2.4782539472027416

Epoch: 6| Step: 12
Training loss: 2.2019689245707785
Validation loss: 2.4814215644821997

Epoch: 6| Step: 13
Training loss: 2.6787060422223314
Validation loss: 2.4814938647191602

Epoch: 92| Step: 0
Training loss: 2.2793007452636913
Validation loss: 2.4744696694359574

Epoch: 6| Step: 1
Training loss: 2.8269656001974464
Validation loss: 2.4771943033534884

Epoch: 6| Step: 2
Training loss: 2.719093388762424
Validation loss: 2.4785963625993226

Epoch: 6| Step: 3
Training loss: 2.251455472034415
Validation loss: 2.4752355604748146

Epoch: 6| Step: 4
Training loss: 2.8892918167171064
Validation loss: 2.4788151633424014

Epoch: 6| Step: 5
Training loss: 2.3669056740367997
Validation loss: 2.4789958595825023

Epoch: 6| Step: 6
Training loss: 2.9183388594032773
Validation loss: 2.4809594817844864

Epoch: 6| Step: 7
Training loss: 3.2724871655730494
Validation loss: 2.4837056023888926

Epoch: 6| Step: 8
Training loss: 1.9743340637078588
Validation loss: 2.476196245935202

Epoch: 6| Step: 9
Training loss: 2.2763726337879935
Validation loss: 2.4865963519725574

Epoch: 6| Step: 10
Training loss: 3.0103367109581423
Validation loss: 2.4765399486586

Epoch: 6| Step: 11
Training loss: 2.2875038021869014
Validation loss: 2.4838285824932624

Epoch: 6| Step: 12
Training loss: 2.6124832919375915
Validation loss: 2.4782368388200244

Epoch: 6| Step: 13
Training loss: 2.223471761775948
Validation loss: 2.480281264060487

Epoch: 93| Step: 0
Training loss: 2.2539956324686488
Validation loss: 2.4749630035820607

Epoch: 6| Step: 1
Training loss: 2.349863243181976
Validation loss: 2.4783669204932948

Epoch: 6| Step: 2
Training loss: 2.2770604371236978
Validation loss: 2.4839227612660477

Epoch: 6| Step: 3
Training loss: 3.0092839592683447
Validation loss: 2.475512646073609

Epoch: 6| Step: 4
Training loss: 2.9579328525600284
Validation loss: 2.477342901808153

Epoch: 6| Step: 5
Training loss: 2.639710578370484
Validation loss: 2.4717922217731005

Epoch: 6| Step: 6
Training loss: 2.6831773993002628
Validation loss: 2.4804517690322623

Epoch: 6| Step: 7
Training loss: 2.079232745244968
Validation loss: 2.4752687590871685

Epoch: 6| Step: 8
Training loss: 2.353297002618186
Validation loss: 2.4764405470222974

Epoch: 6| Step: 9
Training loss: 2.3552072863862588
Validation loss: 2.483366307630665

Epoch: 6| Step: 10
Training loss: 3.265052562716975
Validation loss: 2.4798573218470135

Epoch: 6| Step: 11
Training loss: 2.576945086887759
Validation loss: 2.4749414250798942

Epoch: 6| Step: 12
Training loss: 3.0175430443956013
Validation loss: 2.475063556278957

Epoch: 6| Step: 13
Training loss: 2.073537251215356
Validation loss: 2.4774783233145943

Epoch: 94| Step: 0
Training loss: 2.2792829629167866
Validation loss: 2.4808522005637648

Epoch: 6| Step: 1
Training loss: 2.671706434141512
Validation loss: 2.483562952558457

Epoch: 6| Step: 2
Training loss: 2.7205255783216313
Validation loss: 2.481348333324017

Epoch: 6| Step: 3
Training loss: 2.7724901757440312
Validation loss: 2.4850297940653707

Epoch: 6| Step: 4
Training loss: 2.3811339422664117
Validation loss: 2.488213091545087

Epoch: 6| Step: 5
Training loss: 2.748294301339007
Validation loss: 2.4799181389629044

Epoch: 6| Step: 6
Training loss: 2.4373634495756162
Validation loss: 2.4809490710003583

Epoch: 6| Step: 7
Training loss: 2.6644431818256598
Validation loss: 2.488062650858692

Epoch: 6| Step: 8
Training loss: 2.2437858599929164
Validation loss: 2.4825787718518217

Epoch: 6| Step: 9
Training loss: 2.9152356769958065
Validation loss: 2.4879173280170637

Epoch: 6| Step: 10
Training loss: 2.7829942698500236
Validation loss: 2.4844828968090202

Epoch: 6| Step: 11
Training loss: 2.549158675584575
Validation loss: 2.4769660789344727

Epoch: 6| Step: 12
Training loss: 2.449631067641352
Validation loss: 2.48440210259647

Epoch: 6| Step: 13
Training loss: 2.62992904741432
Validation loss: 2.478315180455699

Epoch: 95| Step: 0
Training loss: 2.5724020583597573
Validation loss: 2.473743603405578

Epoch: 6| Step: 1
Training loss: 2.756348823972848
Validation loss: 2.4772106810597943

Epoch: 6| Step: 2
Training loss: 2.2451853631857386
Validation loss: 2.4746893247853032

Epoch: 6| Step: 3
Training loss: 2.5809572326297503
Validation loss: 2.4759605630877934

Epoch: 6| Step: 4
Training loss: 2.3379905634706764
Validation loss: 2.474650723122683

Epoch: 6| Step: 5
Training loss: 2.4498886822693544
Validation loss: 2.4717125962667876

Epoch: 6| Step: 6
Training loss: 3.108008923275975
Validation loss: 2.4755898700710466

Epoch: 6| Step: 7
Training loss: 2.761074913763269
Validation loss: 2.475276769710798

Epoch: 6| Step: 8
Training loss: 2.039512730728222
Validation loss: 2.475151751261931

Epoch: 6| Step: 9
Training loss: 3.072446280646895
Validation loss: 2.4713941168227493

Epoch: 6| Step: 10
Training loss: 2.864731238043657
Validation loss: 2.4743898249669685

Epoch: 6| Step: 11
Training loss: 1.7492457535547559
Validation loss: 2.484370921389513

Epoch: 6| Step: 12
Training loss: 2.651317729453535
Validation loss: 2.491140610098356

Epoch: 6| Step: 13
Training loss: 2.7091394447438275
Validation loss: 2.4903338004814604

Epoch: 96| Step: 0
Training loss: 2.419114145078261
Validation loss: 2.4844520444939517

Epoch: 6| Step: 1
Training loss: 2.4794874758410828
Validation loss: 2.479735611030415

Epoch: 6| Step: 2
Training loss: 2.913011458516133
Validation loss: 2.4891394108992544

Epoch: 6| Step: 3
Training loss: 3.2155206275958084
Validation loss: 2.482383769753581

Epoch: 6| Step: 4
Training loss: 2.4307054552145484
Validation loss: 2.4788104103205058

Epoch: 6| Step: 5
Training loss: 2.547535067720295
Validation loss: 2.4716734336594053

Epoch: 6| Step: 6
Training loss: 2.7740053267204337
Validation loss: 2.4842908833016786

Epoch: 6| Step: 7
Training loss: 1.5465351078107352
Validation loss: 2.481760868934463

Epoch: 6| Step: 8
Training loss: 2.562948048196433
Validation loss: 2.4795873322473594

Epoch: 6| Step: 9
Training loss: 2.6223495363140836
Validation loss: 2.488231121458568

Epoch: 6| Step: 10
Training loss: 2.761024225898965
Validation loss: 2.4857390875432466

Epoch: 6| Step: 11
Training loss: 2.8903513186002288
Validation loss: 2.487942579248716

Epoch: 6| Step: 12
Training loss: 2.480907395393186
Validation loss: 2.484876026359001

Epoch: 6| Step: 13
Training loss: 2.610828291905083
Validation loss: 2.492889512700706

Epoch: 97| Step: 0
Training loss: 2.3271582727708657
Validation loss: 2.487137320451215

Epoch: 6| Step: 1
Training loss: 2.3566561563878845
Validation loss: 2.4894347099941156

Epoch: 6| Step: 2
Training loss: 2.49187694755193
Validation loss: 2.4845774026309804

Epoch: 6| Step: 3
Training loss: 2.354021681200393
Validation loss: 2.4847808282502304

Epoch: 6| Step: 4
Training loss: 3.071933774492569
Validation loss: 2.481025765421677

Epoch: 6| Step: 5
Training loss: 2.383722850562938
Validation loss: 2.4838420208243193

Epoch: 6| Step: 6
Training loss: 2.3999086521566375
Validation loss: 2.4769852896094293

Epoch: 6| Step: 7
Training loss: 2.0982329927207664
Validation loss: 2.478132758944192

Epoch: 6| Step: 8
Training loss: 1.8906258827396571
Validation loss: 2.4751825348817165

Epoch: 6| Step: 9
Training loss: 2.5438820507069377
Validation loss: 2.472567901720367

Epoch: 6| Step: 10
Training loss: 3.060258473219639
Validation loss: 2.4813864144365434

Epoch: 6| Step: 11
Training loss: 3.0737955851546808
Validation loss: 2.4846049348321926

Epoch: 6| Step: 12
Training loss: 2.5468551541356765
Validation loss: 2.4910082682923202

Epoch: 6| Step: 13
Training loss: 3.2969344436565677
Validation loss: 2.485600503121849

Epoch: 98| Step: 0
Training loss: 2.734364013649804
Validation loss: 2.4809724711785024

Epoch: 6| Step: 1
Training loss: 2.175860364150187
Validation loss: 2.4777073585608624

Epoch: 6| Step: 2
Training loss: 2.1677122772000055
Validation loss: 2.484036228586331

Epoch: 6| Step: 3
Training loss: 2.631857588471936
Validation loss: 2.480900195789054

Epoch: 6| Step: 4
Training loss: 1.6820055203522981
Validation loss: 2.4767299880262814

Epoch: 6| Step: 5
Training loss: 2.763737783555973
Validation loss: 2.4772253904255614

Epoch: 6| Step: 6
Training loss: 3.01448614723514
Validation loss: 2.482617402298668

Epoch: 6| Step: 7
Training loss: 3.37508363973329
Validation loss: 2.480131848301602

Epoch: 6| Step: 8
Training loss: 2.6705406381685832
Validation loss: 2.482972442935957

Epoch: 6| Step: 9
Training loss: 2.1909490370157614
Validation loss: 2.4867943393805043

Epoch: 6| Step: 10
Training loss: 2.2017456498322363
Validation loss: 2.4860823100983245

Epoch: 6| Step: 11
Training loss: 2.7134589965488973
Validation loss: 2.492659425448299

Epoch: 6| Step: 12
Training loss: 2.844636213109951
Validation loss: 2.4944630979233686

Epoch: 6| Step: 13
Training loss: 2.703569144215422
Validation loss: 2.4813405985270625

Epoch: 99| Step: 0
Training loss: 2.4490263892263293
Validation loss: 2.4839614108042385

Epoch: 6| Step: 1
Training loss: 2.005272947649266
Validation loss: 2.4845645360402457

Epoch: 6| Step: 2
Training loss: 2.4339390688802642
Validation loss: 2.481600069386846

Epoch: 6| Step: 3
Training loss: 2.9935635821253324
Validation loss: 2.480546460473774

Epoch: 6| Step: 4
Training loss: 2.6348942074177186
Validation loss: 2.481319940255514

Epoch: 6| Step: 5
Training loss: 2.9621598833142695
Validation loss: 2.4769280742458766

Epoch: 6| Step: 6
Training loss: 2.107839067544761
Validation loss: 2.475877187677103

Epoch: 6| Step: 7
Training loss: 2.438314644078535
Validation loss: 2.4820499456684315

Epoch: 6| Step: 8
Training loss: 1.9484608615921681
Validation loss: 2.4789966289861014

Epoch: 6| Step: 9
Training loss: 2.4919210548632265
Validation loss: 2.4797320215482586

Epoch: 6| Step: 10
Training loss: 2.6955624671792218
Validation loss: 2.4814239985443765

Epoch: 6| Step: 11
Training loss: 2.6050515362699285
Validation loss: 2.4793488785489814

Epoch: 6| Step: 12
Training loss: 3.031172289294638
Validation loss: 2.48185237231539

Epoch: 6| Step: 13
Training loss: 2.9417661165567672
Validation loss: 2.4766274332384874

Epoch: 100| Step: 0
Training loss: 2.7175723627557673
Validation loss: 2.4780325392494795

Epoch: 6| Step: 1
Training loss: 2.621234281726547
Validation loss: 2.4851630858257656

Epoch: 6| Step: 2
Training loss: 2.7702833695878373
Validation loss: 2.483972064917225

Epoch: 6| Step: 3
Training loss: 1.8404352812473028
Validation loss: 2.484699715880271

Epoch: 6| Step: 4
Training loss: 2.9054652969737815
Validation loss: 2.48229634397522

Epoch: 6| Step: 5
Training loss: 3.106550457736034
Validation loss: 2.4763020840821786

Epoch: 6| Step: 6
Training loss: 2.513937721925597
Validation loss: 2.4695619302251988

Epoch: 6| Step: 7
Training loss: 2.493036968429921
Validation loss: 2.476906360456887

Epoch: 6| Step: 8
Training loss: 2.195206609052324
Validation loss: 2.48797546456087

Epoch: 6| Step: 9
Training loss: 2.5332168661081633
Validation loss: 2.5037617673960813

Epoch: 6| Step: 10
Training loss: 2.4130345597272305
Validation loss: 2.493272997394701

Epoch: 6| Step: 11
Training loss: 2.678695272579971
Validation loss: 2.491573405567089

Epoch: 6| Step: 12
Training loss: 2.6470842983540916
Validation loss: 2.4790921774393806

Epoch: 6| Step: 13
Training loss: 2.599686412973838
Validation loss: 2.469669967370958

Epoch: 101| Step: 0
Training loss: 3.5457640937353476
Validation loss: 2.4740968739049545

Epoch: 6| Step: 1
Training loss: 1.9083950293727883
Validation loss: 2.476751518858196

Epoch: 6| Step: 2
Training loss: 3.207023072319431
Validation loss: 2.482420754501206

Epoch: 6| Step: 3
Training loss: 2.0873319272662316
Validation loss: 2.49046744658373

Epoch: 6| Step: 4
Training loss: 2.5838503986667707
Validation loss: 2.4792695758735666

Epoch: 6| Step: 5
Training loss: 2.4043130386019937
Validation loss: 2.4834776883337484

Epoch: 6| Step: 6
Training loss: 2.6022375565560365
Validation loss: 2.4772810670703267

Epoch: 6| Step: 7
Training loss: 2.3931735547356228
Validation loss: 2.4830333677895338

Epoch: 6| Step: 8
Training loss: 2.7280568397283393
Validation loss: 2.4795864187982186

Epoch: 6| Step: 9
Training loss: 2.953624864688912
Validation loss: 2.477790167221129

Epoch: 6| Step: 10
Training loss: 2.203247824417299
Validation loss: 2.4763731778822518

Epoch: 6| Step: 11
Training loss: 1.9670803922622997
Validation loss: 2.4729219909542093

Epoch: 6| Step: 12
Training loss: 2.48859790362152
Validation loss: 2.468934901270635

Epoch: 6| Step: 13
Training loss: 2.672054530129822
Validation loss: 2.468267353377182

Epoch: 102| Step: 0
Training loss: 2.31192751834863
Validation loss: 2.466504214281335

Epoch: 6| Step: 1
Training loss: 2.4593130411682953
Validation loss: 2.466671467037513

Epoch: 6| Step: 2
Training loss: 2.4720271125220177
Validation loss: 2.464030458592338

Epoch: 6| Step: 3
Training loss: 2.224317523141897
Validation loss: 2.4710283188544744

Epoch: 6| Step: 4
Training loss: 2.6426440764301127
Validation loss: 2.465071960299012

Epoch: 6| Step: 5
Training loss: 2.346610193259393
Validation loss: 2.4665918051039126

Epoch: 6| Step: 6
Training loss: 2.5073688625681054
Validation loss: 2.464399713902972

Epoch: 6| Step: 7
Training loss: 3.0736814075338925
Validation loss: 2.472706822846886

Epoch: 6| Step: 8
Training loss: 2.9431239731989973
Validation loss: 2.4692693075612384

Epoch: 6| Step: 9
Training loss: 2.6354141737934933
Validation loss: 2.460380523463545

Epoch: 6| Step: 10
Training loss: 3.007667280382327
Validation loss: 2.4656407054792546

Epoch: 6| Step: 11
Training loss: 2.7371451160900557
Validation loss: 2.4592647458301036

Epoch: 6| Step: 12
Training loss: 2.514385984483545
Validation loss: 2.465047756323105

Epoch: 6| Step: 13
Training loss: 1.9264286338167227
Validation loss: 2.4643729153665497

Epoch: 103| Step: 0
Training loss: 3.0038414837783916
Validation loss: 2.466067776490342

Epoch: 6| Step: 1
Training loss: 2.815478379711397
Validation loss: 2.470308769427544

Epoch: 6| Step: 2
Training loss: 2.8783727019473897
Validation loss: 2.4654260140089717

Epoch: 6| Step: 3
Training loss: 2.125945834427107
Validation loss: 2.465540735491408

Epoch: 6| Step: 4
Training loss: 2.4298558805451256
Validation loss: 2.4619774936976735

Epoch: 6| Step: 5
Training loss: 2.1732495027105134
Validation loss: 2.470543640377149

Epoch: 6| Step: 6
Training loss: 2.014402743440537
Validation loss: 2.4732072888138132

Epoch: 6| Step: 7
Training loss: 2.196158466722247
Validation loss: 2.479325174559117

Epoch: 6| Step: 8
Training loss: 3.2940910843170905
Validation loss: 2.4770406588339977

Epoch: 6| Step: 9
Training loss: 2.6052879259310195
Validation loss: 2.48148220714898

Epoch: 6| Step: 10
Training loss: 2.542153692225838
Validation loss: 2.47813349654612

Epoch: 6| Step: 11
Training loss: 2.4040849531844097
Validation loss: 2.474833818758501

Epoch: 6| Step: 12
Training loss: 2.6807317450756605
Validation loss: 2.4714222300046758

Epoch: 6| Step: 13
Training loss: 2.663654105914161
Validation loss: 2.480184784101453

Epoch: 104| Step: 0
Training loss: 2.8072272996948606
Validation loss: 2.47771188115428

Epoch: 6| Step: 1
Training loss: 1.7411021456960636
Validation loss: 2.4711068568614243

Epoch: 6| Step: 2
Training loss: 2.8310235276074955
Validation loss: 2.473952047775047

Epoch: 6| Step: 3
Training loss: 2.3484382025336297
Validation loss: 2.46907071955731

Epoch: 6| Step: 4
Training loss: 2.5891084619746336
Validation loss: 2.4773512746423356

Epoch: 6| Step: 5
Training loss: 2.4193087856462587
Validation loss: 2.474308452258926

Epoch: 6| Step: 6
Training loss: 2.564100370528432
Validation loss: 2.4755990513962733

Epoch: 6| Step: 7
Training loss: 2.998271762229145
Validation loss: 2.4751616486187342

Epoch: 6| Step: 8
Training loss: 2.519790139315456
Validation loss: 2.4773328768257867

Epoch: 6| Step: 9
Training loss: 2.6238590667431296
Validation loss: 2.4775325989078167

Epoch: 6| Step: 10
Training loss: 2.366036919190487
Validation loss: 2.4686200071467175

Epoch: 6| Step: 11
Training loss: 2.3418958323284875
Validation loss: 2.468855537701843

Epoch: 6| Step: 12
Training loss: 3.3161580742131314
Validation loss: 2.458925569178069

Epoch: 6| Step: 13
Training loss: 2.325332092850614
Validation loss: 2.463051008487476

Epoch: 105| Step: 0
Training loss: 2.7266078824963733
Validation loss: 2.460634533837268

Epoch: 6| Step: 1
Training loss: 2.801357662203617
Validation loss: 2.461525208066143

Epoch: 6| Step: 2
Training loss: 2.5028269996370716
Validation loss: 2.469518228102531

Epoch: 6| Step: 3
Training loss: 1.8878715578896634
Validation loss: 2.4542513891555977

Epoch: 6| Step: 4
Training loss: 2.0075151393979844
Validation loss: 2.466042236816189

Epoch: 6| Step: 5
Training loss: 2.6140514202532956
Validation loss: 2.4674433054750917

Epoch: 6| Step: 6
Training loss: 1.6036445296371957
Validation loss: 2.4612825343544062

Epoch: 6| Step: 7
Training loss: 1.928535086425597
Validation loss: 2.4606280904357587

Epoch: 6| Step: 8
Training loss: 2.4192099397603957
Validation loss: 2.4588443634434642

Epoch: 6| Step: 9
Training loss: 2.835072787526149
Validation loss: 2.462343772863816

Epoch: 6| Step: 10
Training loss: 3.459182328645384
Validation loss: 2.4582865974595864

Epoch: 6| Step: 11
Training loss: 2.496354496907632
Validation loss: 2.4682339800978026

Epoch: 6| Step: 12
Training loss: 2.8758759200875232
Validation loss: 2.4687279165060882

Epoch: 6| Step: 13
Training loss: 3.120023503337267
Validation loss: 2.474355249521202

Epoch: 106| Step: 0
Training loss: 2.705907282812005
Validation loss: 2.4853147093033474

Epoch: 6| Step: 1
Training loss: 2.57127459761408
Validation loss: 2.482406700201947

Epoch: 6| Step: 2
Training loss: 2.4473455100938173
Validation loss: 2.483530952817275

Epoch: 6| Step: 3
Training loss: 2.478264545682367
Validation loss: 2.480359941634173

Epoch: 6| Step: 4
Training loss: 2.4931275319860937
Validation loss: 2.4805581544798643

Epoch: 6| Step: 5
Training loss: 2.1889702352048537
Validation loss: 2.486813849635033

Epoch: 6| Step: 6
Training loss: 3.138158484430141
Validation loss: 2.47951085776108

Epoch: 6| Step: 7
Training loss: 2.687553405231092
Validation loss: 2.4759453486890672

Epoch: 6| Step: 8
Training loss: 2.0262716468440747
Validation loss: 2.4740224783093896

Epoch: 6| Step: 9
Training loss: 1.9450231130055324
Validation loss: 2.467558963796451

Epoch: 6| Step: 10
Training loss: 2.634946959683758
Validation loss: 2.4743062681509422

Epoch: 6| Step: 11
Training loss: 2.6552452431038063
Validation loss: 2.466122238760643

Epoch: 6| Step: 12
Training loss: 2.812781510569634
Validation loss: 2.472498273498529

Epoch: 6| Step: 13
Training loss: 2.967956597568649
Validation loss: 2.4562586149237724

Epoch: 107| Step: 0
Training loss: 2.7065756938785834
Validation loss: 2.4599027204016664

Epoch: 6| Step: 1
Training loss: 3.2869679357660906
Validation loss: 2.452086307736659

Epoch: 6| Step: 2
Training loss: 2.0557258796005184
Validation loss: 2.4505949478751954

Epoch: 6| Step: 3
Training loss: 2.546290699217325
Validation loss: 2.4571861456810256

Epoch: 6| Step: 4
Training loss: 2.7894868073822416
Validation loss: 2.462171521684303

Epoch: 6| Step: 5
Training loss: 1.9671708085834392
Validation loss: 2.4555572956629477

Epoch: 6| Step: 6
Training loss: 2.3021032295115247
Validation loss: 2.460604432187764

Epoch: 6| Step: 7
Training loss: 2.528567930069813
Validation loss: 2.4548200028026232

Epoch: 6| Step: 8
Training loss: 2.3237323668797405
Validation loss: 2.4606351151959727

Epoch: 6| Step: 9
Training loss: 3.0229747329347485
Validation loss: 2.4533045028810023

Epoch: 6| Step: 10
Training loss: 2.5892946515610267
Validation loss: 2.4535834173659357

Epoch: 6| Step: 11
Training loss: 2.422930087716304
Validation loss: 2.4648706885073346

Epoch: 6| Step: 12
Training loss: 2.424948040906987
Validation loss: 2.4599394939316346

Epoch: 6| Step: 13
Training loss: 2.5691109953556928
Validation loss: 2.460834287063443

Epoch: 108| Step: 0
Training loss: 2.6041395465710235
Validation loss: 2.4670167866730917

Epoch: 6| Step: 1
Training loss: 3.1490815594826893
Validation loss: 2.4675650026158586

Epoch: 6| Step: 2
Training loss: 2.1928166765159918
Validation loss: 2.461211287189337

Epoch: 6| Step: 3
Training loss: 1.9066834504160182
Validation loss: 2.4561193054475927

Epoch: 6| Step: 4
Training loss: 2.271055041581355
Validation loss: 2.463461478758345

Epoch: 6| Step: 5
Training loss: 2.171669051470829
Validation loss: 2.4698894784373233

Epoch: 6| Step: 6
Training loss: 2.439600308622812
Validation loss: 2.477167178040518

Epoch: 6| Step: 7
Training loss: 2.5410699508688737
Validation loss: 2.476287537723037

Epoch: 6| Step: 8
Training loss: 2.627483736926126
Validation loss: 2.4581231550036295

Epoch: 6| Step: 9
Training loss: 2.874410320014381
Validation loss: 2.4616051388900444

Epoch: 6| Step: 10
Training loss: 3.0530441039192464
Validation loss: 2.465721220033461

Epoch: 6| Step: 11
Training loss: 2.489921568129364
Validation loss: 2.4699106506063657

Epoch: 6| Step: 12
Training loss: 2.7486296620727346
Validation loss: 2.4613438023609406

Epoch: 6| Step: 13
Training loss: 2.448888923789638
Validation loss: 2.4734386634462457

Epoch: 109| Step: 0
Training loss: 2.4238519290858713
Validation loss: 2.4668226323780207

Epoch: 6| Step: 1
Training loss: 2.631551921856291
Validation loss: 2.4677331496204356

Epoch: 6| Step: 2
Training loss: 2.9593021436220557
Validation loss: 2.46941498761606

Epoch: 6| Step: 3
Training loss: 2.289686723294809
Validation loss: 2.4706465602827934

Epoch: 6| Step: 4
Training loss: 2.3594515958567404
Validation loss: 2.4744139054437087

Epoch: 6| Step: 5
Training loss: 2.938353718820166
Validation loss: 2.470821686363967

Epoch: 6| Step: 6
Training loss: 3.1104535096616703
Validation loss: 2.4636344704007005

Epoch: 6| Step: 7
Training loss: 2.167553671202054
Validation loss: 2.4609438618572694

Epoch: 6| Step: 8
Training loss: 2.1813665233191823
Validation loss: 2.464979551899808

Epoch: 6| Step: 9
Training loss: 2.7441868462521923
Validation loss: 2.4673257413357548

Epoch: 6| Step: 10
Training loss: 2.235886069505355
Validation loss: 2.464383928278101

Epoch: 6| Step: 11
Training loss: 2.453674254917136
Validation loss: 2.463140908052533

Epoch: 6| Step: 12
Training loss: 2.816434354813828
Validation loss: 2.462578814515218

Epoch: 6| Step: 13
Training loss: 2.3883740168440823
Validation loss: 2.4576107730522563

Epoch: 110| Step: 0
Training loss: 2.3154107410391007
Validation loss: 2.4568592166967824

Epoch: 6| Step: 1
Training loss: 2.569581272732056
Validation loss: 2.4579008390084405

Epoch: 6| Step: 2
Training loss: 3.134192412545443
Validation loss: 2.4593175168006645

Epoch: 6| Step: 3
Training loss: 2.3895158376254675
Validation loss: 2.4653863485961875

Epoch: 6| Step: 4
Training loss: 2.2581776254425416
Validation loss: 2.463568162405967

Epoch: 6| Step: 5
Training loss: 2.329578944132566
Validation loss: 2.465978620124533

Epoch: 6| Step: 6
Training loss: 2.760581034439141
Validation loss: 2.4698360484713007

Epoch: 6| Step: 7
Training loss: 2.165182877144444
Validation loss: 2.4754711678791366

Epoch: 6| Step: 8
Training loss: 2.975754355311321
Validation loss: 2.4752544233773666

Epoch: 6| Step: 9
Training loss: 2.7769484097747545
Validation loss: 2.4768268191444847

Epoch: 6| Step: 10
Training loss: 2.5606729460406443
Validation loss: 2.4768849833785644

Epoch: 6| Step: 11
Training loss: 2.844016932441106
Validation loss: 2.472180072077448

Epoch: 6| Step: 12
Training loss: 2.2038331753618374
Validation loss: 2.467814964565969

Epoch: 6| Step: 13
Training loss: 2.204135095073345
Validation loss: 2.473565029536348

Epoch: 111| Step: 0
Training loss: 2.2837187068238007
Validation loss: 2.4677179167016474

Epoch: 6| Step: 1
Training loss: 2.6040219889824288
Validation loss: 2.4634694148645777

Epoch: 6| Step: 2
Training loss: 2.106460932009197
Validation loss: 2.4661431371290754

Epoch: 6| Step: 3
Training loss: 2.0073319984532105
Validation loss: 2.467171288973164

Epoch: 6| Step: 4
Training loss: 2.540302431619471
Validation loss: 2.4567584364929194

Epoch: 6| Step: 5
Training loss: 2.214045520359314
Validation loss: 2.4596151361526317

Epoch: 6| Step: 6
Training loss: 2.321630238587032
Validation loss: 2.461590812390819

Epoch: 6| Step: 7
Training loss: 2.647225791988343
Validation loss: 2.461748100678015

Epoch: 6| Step: 8
Training loss: 2.629382516874246
Validation loss: 2.454196720122778

Epoch: 6| Step: 9
Training loss: 3.097371149592841
Validation loss: 2.461667214042518

Epoch: 6| Step: 10
Training loss: 3.122275881760568
Validation loss: 2.4714513718702804

Epoch: 6| Step: 11
Training loss: 2.8011998671097365
Validation loss: 2.4749283076990576

Epoch: 6| Step: 12
Training loss: 2.224266608593933
Validation loss: 2.48265403144208

Epoch: 6| Step: 13
Training loss: 2.9785431607333748
Validation loss: 2.478879404388496

Epoch: 112| Step: 0
Training loss: 2.222733373929678
Validation loss: 2.4773206623324455

Epoch: 6| Step: 1
Training loss: 2.9145333980911707
Validation loss: 2.477918893229261

Epoch: 6| Step: 2
Training loss: 2.202962991155133
Validation loss: 2.484256765563112

Epoch: 6| Step: 3
Training loss: 2.3931827201667013
Validation loss: 2.4882031422986284

Epoch: 6| Step: 4
Training loss: 2.298890559435193
Validation loss: 2.485928815294621

Epoch: 6| Step: 5
Training loss: 1.9659062995429777
Validation loss: 2.489337722814634

Epoch: 6| Step: 6
Training loss: 2.4283060642126024
Validation loss: 2.4902982177529065

Epoch: 6| Step: 7
Training loss: 2.6843385065549086
Validation loss: 2.489214104974183

Epoch: 6| Step: 8
Training loss: 2.0962417351247584
Validation loss: 2.4916921539874286

Epoch: 6| Step: 9
Training loss: 3.0750618036773743
Validation loss: 2.494284724984576

Epoch: 6| Step: 10
Training loss: 3.0274751105573015
Validation loss: 2.4953299136222027

Epoch: 6| Step: 11
Training loss: 2.5989361126904753
Validation loss: 2.4901626556640264

Epoch: 6| Step: 12
Training loss: 3.0457152678171915
Validation loss: 2.495485282366916

Epoch: 6| Step: 13
Training loss: 3.0389269330302886
Validation loss: 2.485948907780842

Epoch: 113| Step: 0
Training loss: 2.3226370422205487
Validation loss: 2.485682593223469

Epoch: 6| Step: 1
Training loss: 2.3924984042840975
Validation loss: 2.48553014487132

Epoch: 6| Step: 2
Training loss: 2.8232733488259973
Validation loss: 2.479206346680481

Epoch: 6| Step: 3
Training loss: 2.4348112095017815
Validation loss: 2.48065146426585

Epoch: 6| Step: 4
Training loss: 3.0215591786352816
Validation loss: 2.4759519287675005

Epoch: 6| Step: 5
Training loss: 2.411772595574652
Validation loss: 2.4699665886630813

Epoch: 6| Step: 6
Training loss: 2.8004810805523643
Validation loss: 2.46639990513247

Epoch: 6| Step: 7
Training loss: 2.26236168875947
Validation loss: 2.462993170962751

Epoch: 6| Step: 8
Training loss: 2.3437712604829986
Validation loss: 2.4537376238186455

Epoch: 6| Step: 9
Training loss: 2.1570492797230685
Validation loss: 2.4580546452806105

Epoch: 6| Step: 10
Training loss: 2.659575770114012
Validation loss: 2.461954849109081

Epoch: 6| Step: 11
Training loss: 2.8087947598444583
Validation loss: 2.4794357351472613

Epoch: 6| Step: 12
Training loss: 2.420754942771044
Validation loss: 2.515966325117077

Epoch: 6| Step: 13
Training loss: 2.634742640571078
Validation loss: 2.56637223297134

Epoch: 114| Step: 0
Training loss: 2.4974082864259275
Validation loss: 2.5843661509942404

Epoch: 6| Step: 1
Training loss: 3.392128606607457
Validation loss: 2.5981201216610827

Epoch: 6| Step: 2
Training loss: 2.8603463946159358
Validation loss: 2.596512376766187

Epoch: 6| Step: 3
Training loss: 2.4492393869993805
Validation loss: 2.5397661847908326

Epoch: 6| Step: 4
Training loss: 2.307560568497112
Validation loss: 2.5100233052097596

Epoch: 6| Step: 5
Training loss: 2.9009674628930537
Validation loss: 2.4789985044063743

Epoch: 6| Step: 6
Training loss: 2.283330830574984
Validation loss: 2.459171868756888

Epoch: 6| Step: 7
Training loss: 2.8589360468230516
Validation loss: 2.470249123255964

Epoch: 6| Step: 8
Training loss: 2.8494490643092347
Validation loss: 2.463515176019055

Epoch: 6| Step: 9
Training loss: 2.459334369018425
Validation loss: 2.471218018287067

Epoch: 6| Step: 10
Training loss: 2.749182232730487
Validation loss: 2.4724721895305337

Epoch: 6| Step: 11
Training loss: 2.1886786419070945
Validation loss: 2.480731027108429

Epoch: 6| Step: 12
Training loss: 2.3111811820843684
Validation loss: 2.4878436012593697

Epoch: 6| Step: 13
Training loss: 2.4365740264349878
Validation loss: 2.4803238954074427

Epoch: 115| Step: 0
Training loss: 2.0929959206065205
Validation loss: 2.4848151147019166

Epoch: 6| Step: 1
Training loss: 2.7667365992183544
Validation loss: 2.486345241634547

Epoch: 6| Step: 2
Training loss: 2.582970706550587
Validation loss: 2.484026678526654

Epoch: 6| Step: 3
Training loss: 2.921145751033196
Validation loss: 2.475421213341581

Epoch: 6| Step: 4
Training loss: 3.2000993534400157
Validation loss: 2.4805741255196696

Epoch: 6| Step: 5
Training loss: 2.3217835563632705
Validation loss: 2.4783388460051388

Epoch: 6| Step: 6
Training loss: 2.74444747783924
Validation loss: 2.483398917524777

Epoch: 6| Step: 7
Training loss: 2.3380223797199395
Validation loss: 2.4776957393069456

Epoch: 6| Step: 8
Training loss: 2.292011743631951
Validation loss: 2.4792670194900697

Epoch: 6| Step: 9
Training loss: 2.670917093884796
Validation loss: 2.473441587321442

Epoch: 6| Step: 10
Training loss: 2.0424031337147692
Validation loss: 2.4752935614349196

Epoch: 6| Step: 11
Training loss: 2.5848129916106353
Validation loss: 2.4699601374303994

Epoch: 6| Step: 12
Training loss: 2.5152452075557323
Validation loss: 2.4653901765539303

Epoch: 6| Step: 13
Training loss: 2.719199658621497
Validation loss: 2.463212688220628

Epoch: 116| Step: 0
Training loss: 2.817957605604826
Validation loss: 2.456205001690657

Epoch: 6| Step: 1
Training loss: 2.727482768842637
Validation loss: 2.4544198897009277

Epoch: 6| Step: 2
Training loss: 3.009799687256557
Validation loss: 2.4623895468686006

Epoch: 6| Step: 3
Training loss: 2.4378059390835154
Validation loss: 2.462887946744265

Epoch: 6| Step: 4
Training loss: 2.3376159761594395
Validation loss: 2.4831837451181173

Epoch: 6| Step: 5
Training loss: 2.4136283014910953
Validation loss: 2.505756386959448

Epoch: 6| Step: 6
Training loss: 2.4955351059618236
Validation loss: 2.5155872318441785

Epoch: 6| Step: 7
Training loss: 2.5672842814335066
Validation loss: 2.5293886695808525

Epoch: 6| Step: 8
Training loss: 2.941833870290051
Validation loss: 2.5304818106229163

Epoch: 6| Step: 9
Training loss: 2.630342496465462
Validation loss: 2.4966624392671877

Epoch: 6| Step: 10
Training loss: 2.75451895749418
Validation loss: 2.474189576166802

Epoch: 6| Step: 11
Training loss: 2.418764639718949
Validation loss: 2.459438113445303

Epoch: 6| Step: 12
Training loss: 2.6440608678266497
Validation loss: 2.4616726054914357

Epoch: 6| Step: 13
Training loss: 2.2290329462271776
Validation loss: 2.4565939703666335

Epoch: 117| Step: 0
Training loss: 2.420504372898337
Validation loss: 2.4567752577419903

Epoch: 6| Step: 1
Training loss: 2.895746261787916
Validation loss: 2.4664960140616485

Epoch: 6| Step: 2
Training loss: 2.7668846408356345
Validation loss: 2.470965618518558

Epoch: 6| Step: 3
Training loss: 2.7248734541041255
Validation loss: 2.479772803528531

Epoch: 6| Step: 4
Training loss: 2.5399875305650665
Validation loss: 2.4773916627438486

Epoch: 6| Step: 5
Training loss: 2.240290673503849
Validation loss: 2.485825569003447

Epoch: 6| Step: 6
Training loss: 2.2888783455680968
Validation loss: 2.4850247411180666

Epoch: 6| Step: 7
Training loss: 2.112751384878647
Validation loss: 2.4852501069691075

Epoch: 6| Step: 8
Training loss: 2.4512875229503615
Validation loss: 2.4789838215909263

Epoch: 6| Step: 9
Training loss: 2.7456132405995506
Validation loss: 2.4812732583340353

Epoch: 6| Step: 10
Training loss: 2.7354892749161257
Validation loss: 2.4853279157611565

Epoch: 6| Step: 11
Training loss: 2.8157871957479816
Validation loss: 2.476637814055516

Epoch: 6| Step: 12
Training loss: 3.305581695567262
Validation loss: 2.4788039340129333

Epoch: 6| Step: 13
Training loss: 1.8038914233391807
Validation loss: 2.4721298260037705

Epoch: 118| Step: 0
Training loss: 2.4312383970165166
Validation loss: 2.4691223958175406

Epoch: 6| Step: 1
Training loss: 2.7268531447659803
Validation loss: 2.4678673433854463

Epoch: 6| Step: 2
Training loss: 3.029774414830375
Validation loss: 2.4597313564175693

Epoch: 6| Step: 3
Training loss: 2.379851956611626
Validation loss: 2.4588785105796185

Epoch: 6| Step: 4
Training loss: 2.1168814012032544
Validation loss: 2.4533573858578213

Epoch: 6| Step: 5
Training loss: 2.429060091414755
Validation loss: 2.452146841332511

Epoch: 6| Step: 6
Training loss: 2.9179759402103516
Validation loss: 2.462902418971026

Epoch: 6| Step: 7
Training loss: 2.792123007603247
Validation loss: 2.4543032560134517

Epoch: 6| Step: 8
Training loss: 2.127220564353104
Validation loss: 2.4538734411981156

Epoch: 6| Step: 9
Training loss: 2.4206975227994114
Validation loss: 2.452046256377895

Epoch: 6| Step: 10
Training loss: 2.7324368828885555
Validation loss: 2.4530906431865853

Epoch: 6| Step: 11
Training loss: 2.8262262029375673
Validation loss: 2.454643298001439

Epoch: 6| Step: 12
Training loss: 2.4682996314935712
Validation loss: 2.4566709156163538

Epoch: 6| Step: 13
Training loss: 2.489502228462553
Validation loss: 2.457085734674493

Epoch: 119| Step: 0
Training loss: 3.0494721127805016
Validation loss: 2.4577013970784023

Epoch: 6| Step: 1
Training loss: 2.0401336078274053
Validation loss: 2.4548097482500046

Epoch: 6| Step: 2
Training loss: 2.7895388583758636
Validation loss: 2.453248444061216

Epoch: 6| Step: 3
Training loss: 2.535495635416874
Validation loss: 2.45281271759018

Epoch: 6| Step: 4
Training loss: 3.286560701850529
Validation loss: 2.4549369275730726

Epoch: 6| Step: 5
Training loss: 2.236843426234561
Validation loss: 2.4567486348273717

Epoch: 6| Step: 6
Training loss: 2.1476170308350633
Validation loss: 2.4468806624397765

Epoch: 6| Step: 7
Training loss: 2.7736792230708867
Validation loss: 2.459861156685781

Epoch: 6| Step: 8
Training loss: 2.3738406513857218
Validation loss: 2.4449051831588777

Epoch: 6| Step: 9
Training loss: 2.3940542719910862
Validation loss: 2.4482535813518775

Epoch: 6| Step: 10
Training loss: 2.717177890192448
Validation loss: 2.45165751434976

Epoch: 6| Step: 11
Training loss: 2.1405171833591665
Validation loss: 2.452148696775839

Epoch: 6| Step: 12
Training loss: 2.862836066762086
Validation loss: 2.4480144129507506

Epoch: 6| Step: 13
Training loss: 2.0832614377649805
Validation loss: 2.4551877948439804

Epoch: 120| Step: 0
Training loss: 2.754961912580736
Validation loss: 2.452353143446165

Epoch: 6| Step: 1
Training loss: 2.332430449140841
Validation loss: 2.4520303507104177

Epoch: 6| Step: 2
Training loss: 3.204196062354153
Validation loss: 2.4527863351747743

Epoch: 6| Step: 3
Training loss: 2.017143801002328
Validation loss: 2.455212411619502

Epoch: 6| Step: 4
Training loss: 2.6134620683777143
Validation loss: 2.4594357545644234

Epoch: 6| Step: 5
Training loss: 2.872487006494203
Validation loss: 2.462799401324465

Epoch: 6| Step: 6
Training loss: 2.2029890735440105
Validation loss: 2.4624564836662164

Epoch: 6| Step: 7
Training loss: 2.5289806978417513
Validation loss: 2.454973597439608

Epoch: 6| Step: 8
Training loss: 2.782419537445933
Validation loss: 2.4590181323646343

Epoch: 6| Step: 9
Training loss: 2.4645881822613065
Validation loss: 2.456930258514507

Epoch: 6| Step: 10
Training loss: 2.3550878314832007
Validation loss: 2.457647297927954

Epoch: 6| Step: 11
Training loss: 2.5640652225905334
Validation loss: 2.4601543330805637

Epoch: 6| Step: 12
Training loss: 2.6565587481409514
Validation loss: 2.4572081631040654

Epoch: 6| Step: 13
Training loss: 2.2945239432260447
Validation loss: 2.45920265850934

Epoch: 121| Step: 0
Training loss: 2.515864295714191
Validation loss: 2.453900540618586

Epoch: 6| Step: 1
Training loss: 2.6922598981283037
Validation loss: 2.452600410886816

Epoch: 6| Step: 2
Training loss: 2.6857111100349087
Validation loss: 2.456213851028541

Epoch: 6| Step: 3
Training loss: 2.8347912197842056
Validation loss: 2.460571835109628

Epoch: 6| Step: 4
Training loss: 2.08219385138397
Validation loss: 2.459157762381

Epoch: 6| Step: 5
Training loss: 2.129903185439588
Validation loss: 2.4598433711423535

Epoch: 6| Step: 6
Training loss: 2.994241592088386
Validation loss: 2.4619665023018533

Epoch: 6| Step: 7
Training loss: 2.0436509927922075
Validation loss: 2.4632675846429377

Epoch: 6| Step: 8
Training loss: 2.5046737851381957
Validation loss: 2.465251971424649

Epoch: 6| Step: 9
Training loss: 2.360040937004
Validation loss: 2.4669788300536637

Epoch: 6| Step: 10
Training loss: 2.469211197278916
Validation loss: 2.4624964060490906

Epoch: 6| Step: 11
Training loss: 2.719134599514316
Validation loss: 2.45817097165433

Epoch: 6| Step: 12
Training loss: 2.8707011051666593
Validation loss: 2.457448579231487

Epoch: 6| Step: 13
Training loss: 2.646811016800177
Validation loss: 2.4542210473046433

Epoch: 122| Step: 0
Training loss: 2.554139057983071
Validation loss: 2.462492549387961

Epoch: 6| Step: 1
Training loss: 2.6787111155099286
Validation loss: 2.462342465714218

Epoch: 6| Step: 2
Training loss: 2.229703274131746
Validation loss: 2.456554113817849

Epoch: 6| Step: 3
Training loss: 2.9890560168023
Validation loss: 2.4636521156719864

Epoch: 6| Step: 4
Training loss: 2.7211292423339812
Validation loss: 2.4597720580602243

Epoch: 6| Step: 5
Training loss: 2.3977377799681965
Validation loss: 2.4561418905886745

Epoch: 6| Step: 6
Training loss: 2.2618543093415657
Validation loss: 2.4539154949659783

Epoch: 6| Step: 7
Training loss: 2.533301099354645
Validation loss: 2.4539827276791497

Epoch: 6| Step: 8
Training loss: 2.9383668635015483
Validation loss: 2.4541230165996253

Epoch: 6| Step: 9
Training loss: 2.734063877389212
Validation loss: 2.460165881738416

Epoch: 6| Step: 10
Training loss: 2.896413090986874
Validation loss: 2.4521558430553663

Epoch: 6| Step: 11
Training loss: 2.437705789339817
Validation loss: 2.4582897899025697

Epoch: 6| Step: 12
Training loss: 2.445543954638686
Validation loss: 2.454252036789736

Epoch: 6| Step: 13
Training loss: 1.6529930768799774
Validation loss: 2.4568529898259976

Epoch: 123| Step: 0
Training loss: 2.4936515310632363
Validation loss: 2.4593684608795856

Epoch: 6| Step: 1
Training loss: 2.7041825888174285
Validation loss: 2.4591617050646537

Epoch: 6| Step: 2
Training loss: 2.4580217799811734
Validation loss: 2.4494425677945566

Epoch: 6| Step: 3
Training loss: 2.291828866478179
Validation loss: 2.4482014808268246

Epoch: 6| Step: 4
Training loss: 2.5436673237629743
Validation loss: 2.4460254154023398

Epoch: 6| Step: 5
Training loss: 2.039918449492188
Validation loss: 2.4502940760473115

Epoch: 6| Step: 6
Training loss: 3.0530031833925717
Validation loss: 2.4500603129949323

Epoch: 6| Step: 7
Training loss: 2.2466937250645413
Validation loss: 2.452080879004932

Epoch: 6| Step: 8
Training loss: 3.056068361965716
Validation loss: 2.4424607423238918

Epoch: 6| Step: 9
Training loss: 2.4598854359257545
Validation loss: 2.4504186519084383

Epoch: 6| Step: 10
Training loss: 2.814571380778096
Validation loss: 2.4495451414121514

Epoch: 6| Step: 11
Training loss: 2.8296796203537276
Validation loss: 2.4517637229792886

Epoch: 6| Step: 12
Training loss: 2.1998483085354787
Validation loss: 2.454290578808688

Epoch: 6| Step: 13
Training loss: 2.20108370532432
Validation loss: 2.460868818343943

Epoch: 124| Step: 0
Training loss: 2.3109897114992255
Validation loss: 2.4632704802621594

Epoch: 6| Step: 1
Training loss: 2.71774518967758
Validation loss: 2.474301498437834

Epoch: 6| Step: 2
Training loss: 2.73873005235129
Validation loss: 2.4798808685268674

Epoch: 6| Step: 3
Training loss: 2.8088881294568693
Validation loss: 2.4716087078913844

Epoch: 6| Step: 4
Training loss: 2.365371763112148
Validation loss: 2.477898326703491

Epoch: 6| Step: 5
Training loss: 2.6219997517275018
Validation loss: 2.4844606332795527

Epoch: 6| Step: 6
Training loss: 2.364991330701492
Validation loss: 2.47987067754486

Epoch: 6| Step: 7
Training loss: 1.9290655577867264
Validation loss: 2.48557881713403

Epoch: 6| Step: 8
Training loss: 2.694101431949949
Validation loss: 2.4788309452333754

Epoch: 6| Step: 9
Training loss: 2.9875956627760525
Validation loss: 2.475506265475535

Epoch: 6| Step: 10
Training loss: 2.8233920796155103
Validation loss: 2.4708789546758196

Epoch: 6| Step: 11
Training loss: 2.350426789345189
Validation loss: 2.4705098957398093

Epoch: 6| Step: 12
Training loss: 2.5394425797254514
Validation loss: 2.469110953425241

Epoch: 6| Step: 13
Training loss: 2.5250477097035806
Validation loss: 2.466614246026188

Epoch: 125| Step: 0
Training loss: 2.766146077351364
Validation loss: 2.465398275687038

Epoch: 6| Step: 1
Training loss: 3.2791392485568194
Validation loss: 2.4570368942090792

Epoch: 6| Step: 2
Training loss: 2.889299078291889
Validation loss: 2.4510502069478224

Epoch: 6| Step: 3
Training loss: 2.170140513779774
Validation loss: 2.4564003753575685

Epoch: 6| Step: 4
Training loss: 1.5258151549182324
Validation loss: 2.4583627461974524

Epoch: 6| Step: 5
Training loss: 2.7453998758027693
Validation loss: 2.4624257184619336

Epoch: 6| Step: 6
Training loss: 1.9821173372921053
Validation loss: 2.4530081670521215

Epoch: 6| Step: 7
Training loss: 2.8689543142261256
Validation loss: 2.4728686104411217

Epoch: 6| Step: 8
Training loss: 2.5202914724874037
Validation loss: 2.467895891225679

Epoch: 6| Step: 9
Training loss: 2.51635807326399
Validation loss: 2.45907468985938

Epoch: 6| Step: 10
Training loss: 2.3058298157211436
Validation loss: 2.456577875774814

Epoch: 6| Step: 11
Training loss: 2.3130494573297007
Validation loss: 2.4566651573418063

Epoch: 6| Step: 12
Training loss: 2.4690844152395552
Validation loss: 2.4547651440898264

Epoch: 6| Step: 13
Training loss: 2.835597666826659
Validation loss: 2.4510018622823067

Epoch: 126| Step: 0
Training loss: 2.9222428197420864
Validation loss: 2.4508745436158312

Epoch: 6| Step: 1
Training loss: 2.6727234681125376
Validation loss: 2.463644389832927

Epoch: 6| Step: 2
Training loss: 2.8349259519241534
Validation loss: 2.460156691272446

Epoch: 6| Step: 3
Training loss: 2.5872572559251625
Validation loss: 2.4624649474590905

Epoch: 6| Step: 4
Training loss: 2.100597060567366
Validation loss: 2.4592638329114327

Epoch: 6| Step: 5
Training loss: 2.509822622164077
Validation loss: 2.4668187019387258

Epoch: 6| Step: 6
Training loss: 2.534973984383561
Validation loss: 2.4650677127320217

Epoch: 6| Step: 7
Training loss: 1.8926013673471243
Validation loss: 2.458571282417359

Epoch: 6| Step: 8
Training loss: 2.4977671188456645
Validation loss: 2.4619676643900745

Epoch: 6| Step: 9
Training loss: 2.0521664546133156
Validation loss: 2.4585305366515238

Epoch: 6| Step: 10
Training loss: 2.9661243271599256
Validation loss: 2.4639985277204532

Epoch: 6| Step: 11
Training loss: 2.3406990029384764
Validation loss: 2.460650666490347

Epoch: 6| Step: 12
Training loss: 2.6623492059406026
Validation loss: 2.4645851672679777

Epoch: 6| Step: 13
Training loss: 2.7289021681725845
Validation loss: 2.4685958621036996

Epoch: 127| Step: 0
Training loss: 2.7919140511593974
Validation loss: 2.4666276814842427

Epoch: 6| Step: 1
Training loss: 2.41811043812579
Validation loss: 2.463270875485689

Epoch: 6| Step: 2
Training loss: 2.6103679115591176
Validation loss: 2.457785518406794

Epoch: 6| Step: 3
Training loss: 2.81142167506441
Validation loss: 2.460690715061819

Epoch: 6| Step: 4
Training loss: 2.8169044762917053
Validation loss: 2.4661006795797142

Epoch: 6| Step: 5
Training loss: 2.431409611892999
Validation loss: 2.4634216204072605

Epoch: 6| Step: 6
Training loss: 2.4357068239504462
Validation loss: 2.462858485738953

Epoch: 6| Step: 7
Training loss: 2.557792340049456
Validation loss: 2.4616907329411704

Epoch: 6| Step: 8
Training loss: 2.460758457028623
Validation loss: 2.459469473420654

Epoch: 6| Step: 9
Training loss: 2.3819621585623474
Validation loss: 2.4541284570056443

Epoch: 6| Step: 10
Training loss: 2.5937204014571535
Validation loss: 2.4585863780592083

Epoch: 6| Step: 11
Training loss: 2.34725405378659
Validation loss: 2.455194527661807

Epoch: 6| Step: 12
Training loss: 2.2041175716631716
Validation loss: 2.4457725928940186

Epoch: 6| Step: 13
Training loss: 2.492875437722079
Validation loss: 2.4533011176837882

Epoch: 128| Step: 0
Training loss: 2.493059059738015
Validation loss: 2.4632355793547247

Epoch: 6| Step: 1
Training loss: 2.236852272943589
Validation loss: 2.447659618327882

Epoch: 6| Step: 2
Training loss: 2.381209437708172
Validation loss: 2.4482850358984747

Epoch: 6| Step: 3
Training loss: 2.157340396003495
Validation loss: 2.4423741082838784

Epoch: 6| Step: 4
Training loss: 2.4694730448297313
Validation loss: 2.4470308906196525

Epoch: 6| Step: 5
Training loss: 3.3132563753100537
Validation loss: 2.441065975635854

Epoch: 6| Step: 6
Training loss: 2.407419787345203
Validation loss: 2.450684550400997

Epoch: 6| Step: 7
Training loss: 2.979190817426058
Validation loss: 2.449713779131212

Epoch: 6| Step: 8
Training loss: 2.484581800766666
Validation loss: 2.4516755213557055

Epoch: 6| Step: 9
Training loss: 2.030055237568211
Validation loss: 2.4486039732147846

Epoch: 6| Step: 10
Training loss: 2.179941907686127
Validation loss: 2.4439212631740985

Epoch: 6| Step: 11
Training loss: 2.978043635758948
Validation loss: 2.452773390920001

Epoch: 6| Step: 12
Training loss: 2.563785509656837
Validation loss: 2.452551934758152

Epoch: 6| Step: 13
Training loss: 2.4433023886739846
Validation loss: 2.444306935671602

Epoch: 129| Step: 0
Training loss: 2.632568348054374
Validation loss: 2.4497831465968236

Epoch: 6| Step: 1
Training loss: 2.651271327974754
Validation loss: 2.446581632031207

Epoch: 6| Step: 2
Training loss: 2.30101998973587
Validation loss: 2.4474095137081795

Epoch: 6| Step: 3
Training loss: 2.246106487735621
Validation loss: 2.4431163932314943

Epoch: 6| Step: 4
Training loss: 2.3804347447419367
Validation loss: 2.447838580462023

Epoch: 6| Step: 5
Training loss: 2.2774742965839025
Validation loss: 2.452095447425012

Epoch: 6| Step: 6
Training loss: 2.716093146354759
Validation loss: 2.450114449922392

Epoch: 6| Step: 7
Training loss: 2.780070193934521
Validation loss: 2.445652768446747

Epoch: 6| Step: 8
Training loss: 2.3779996701072674
Validation loss: 2.4489416181631296

Epoch: 6| Step: 9
Training loss: 2.481226911845756
Validation loss: 2.452718761848225

Epoch: 6| Step: 10
Training loss: 2.4036105653786763
Validation loss: 2.451973744171442

Epoch: 6| Step: 11
Training loss: 3.0064554695449
Validation loss: 2.4465774173292356

Epoch: 6| Step: 12
Training loss: 2.414104967453627
Validation loss: 2.452260263866477

Epoch: 6| Step: 13
Training loss: 2.542236035053072
Validation loss: 2.450598482745561

Epoch: 130| Step: 0
Training loss: 2.4593002443694356
Validation loss: 2.4584416726588

Epoch: 6| Step: 1
Training loss: 2.842406406119869
Validation loss: 2.4534009871363134

Epoch: 6| Step: 2
Training loss: 2.314445502031223
Validation loss: 2.461825675744636

Epoch: 6| Step: 3
Training loss: 3.163897926854268
Validation loss: 2.469244299869898

Epoch: 6| Step: 4
Training loss: 2.442020821085028
Validation loss: 2.453870315879704

Epoch: 6| Step: 5
Training loss: 2.805159080196694
Validation loss: 2.4569073005467295

Epoch: 6| Step: 6
Training loss: 1.9319800839434211
Validation loss: 2.4580152650663822

Epoch: 6| Step: 7
Training loss: 2.625973657143242
Validation loss: 2.445263074998981

Epoch: 6| Step: 8
Training loss: 2.084909135590377
Validation loss: 2.458675414600794

Epoch: 6| Step: 9
Training loss: 2.5199500393834735
Validation loss: 2.464567254584504

Epoch: 6| Step: 10
Training loss: 2.7805841055958433
Validation loss: 2.462656298871497

Epoch: 6| Step: 11
Training loss: 2.22871214846798
Validation loss: 2.464512193630683

Epoch: 6| Step: 12
Training loss: 2.5824711088796795
Validation loss: 2.466044976099897

Epoch: 6| Step: 13
Training loss: 2.33478755139654
Validation loss: 2.474647945192789

Epoch: 131| Step: 0
Training loss: 2.454476731234159
Validation loss: 2.4662848288746058

Epoch: 6| Step: 1
Training loss: 2.664427343539366
Validation loss: 2.4708608785533777

Epoch: 6| Step: 2
Training loss: 2.2210749949744564
Validation loss: 2.477005374431362

Epoch: 6| Step: 3
Training loss: 2.5760380476635536
Validation loss: 2.4673899513756754

Epoch: 6| Step: 4
Training loss: 2.68438931018359
Validation loss: 2.470220393491122

Epoch: 6| Step: 5
Training loss: 2.465357417102291
Validation loss: 2.4726799214994246

Epoch: 6| Step: 6
Training loss: 2.847593623389708
Validation loss: 2.470170831448444

Epoch: 6| Step: 7
Training loss: 2.3001880237184977
Validation loss: 2.471228928335447

Epoch: 6| Step: 8
Training loss: 2.024304767460903
Validation loss: 2.4768043183399966

Epoch: 6| Step: 9
Training loss: 3.0020423930489533
Validation loss: 2.4601637012267497

Epoch: 6| Step: 10
Training loss: 2.7769527884437655
Validation loss: 2.4625741108361745

Epoch: 6| Step: 11
Training loss: 2.3764001834773643
Validation loss: 2.4542987307607738

Epoch: 6| Step: 12
Training loss: 2.741856916449281
Validation loss: 2.4516668663396524

Epoch: 6| Step: 13
Training loss: 2.1665933180889185
Validation loss: 2.4494114039010486

Epoch: 132| Step: 0
Training loss: 3.1382154644430535
Validation loss: 2.4615989482383562

Epoch: 6| Step: 1
Training loss: 2.5787249242808783
Validation loss: 2.468908699182019

Epoch: 6| Step: 2
Training loss: 2.386644727492413
Validation loss: 2.455407605333847

Epoch: 6| Step: 3
Training loss: 2.2988376665849137
Validation loss: 2.4596438443934963

Epoch: 6| Step: 4
Training loss: 2.692525467606068
Validation loss: 2.455483827171437

Epoch: 6| Step: 5
Training loss: 2.659929397477807
Validation loss: 2.449567324845659

Epoch: 6| Step: 6
Training loss: 2.2677568600155222
Validation loss: 2.455435181405575

Epoch: 6| Step: 7
Training loss: 2.6939622233403555
Validation loss: 2.4479743680173054

Epoch: 6| Step: 8
Training loss: 2.544682688389384
Validation loss: 2.451524345922827

Epoch: 6| Step: 9
Training loss: 2.062173297322734
Validation loss: 2.4524044104303804

Epoch: 6| Step: 10
Training loss: 2.696786405626523
Validation loss: 2.4589758588276296

Epoch: 6| Step: 11
Training loss: 2.9839999777152135
Validation loss: 2.455577531476981

Epoch: 6| Step: 12
Training loss: 1.9949559740835119
Validation loss: 2.4511725720813664

Epoch: 6| Step: 13
Training loss: 2.15801542682808
Validation loss: 2.459190079273688

Epoch: 133| Step: 0
Training loss: 1.8361451376517643
Validation loss: 2.4558342958009836

Epoch: 6| Step: 1
Training loss: 2.0647270432339293
Validation loss: 2.457142991606444

Epoch: 6| Step: 2
Training loss: 2.7138755334243294
Validation loss: 2.4549033811659857

Epoch: 6| Step: 3
Training loss: 2.361313787500414
Validation loss: 2.4511803372301637

Epoch: 6| Step: 4
Training loss: 2.6369230064114393
Validation loss: 2.4627472051477417

Epoch: 6| Step: 5
Training loss: 2.6566213011687396
Validation loss: 2.458874931051154

Epoch: 6| Step: 6
Training loss: 2.71759289201105
Validation loss: 2.4541246519610356

Epoch: 6| Step: 7
Training loss: 2.6098599468670236
Validation loss: 2.460494454683348

Epoch: 6| Step: 8
Training loss: 2.9941469952639346
Validation loss: 2.447301021562486

Epoch: 6| Step: 9
Training loss: 2.801365151717433
Validation loss: 2.4516470601767164

Epoch: 6| Step: 10
Training loss: 2.568040022921405
Validation loss: 2.4611183059717336

Epoch: 6| Step: 11
Training loss: 2.2081160048542636
Validation loss: 2.450881547692483

Epoch: 6| Step: 12
Training loss: 2.561577793814236
Validation loss: 2.4462108322903835

Epoch: 6| Step: 13
Training loss: 2.44243855128696
Validation loss: 2.4537942220544546

Epoch: 134| Step: 0
Training loss: 2.7090067295288
Validation loss: 2.4486722442915854

Epoch: 6| Step: 1
Training loss: 2.6888098962160756
Validation loss: 2.453159259143863

Epoch: 6| Step: 2
Training loss: 2.4470259540710764
Validation loss: 2.45137799170224

Epoch: 6| Step: 3
Training loss: 2.5102305890736503
Validation loss: 2.4512718474124386

Epoch: 6| Step: 4
Training loss: 2.123150300960808
Validation loss: 2.4479756016772436

Epoch: 6| Step: 5
Training loss: 2.4689126262940966
Validation loss: 2.450697197616365

Epoch: 6| Step: 6
Training loss: 2.6545586081519787
Validation loss: 2.44833492736903

Epoch: 6| Step: 7
Training loss: 2.1428418340590274
Validation loss: 2.452038793772431

Epoch: 6| Step: 8
Training loss: 2.9235133509375926
Validation loss: 2.4469156098680225

Epoch: 6| Step: 9
Training loss: 2.841389777004937
Validation loss: 2.4441570603131706

Epoch: 6| Step: 10
Training loss: 2.216177940509621
Validation loss: 2.444732771983404

Epoch: 6| Step: 11
Training loss: 2.252283209424726
Validation loss: 2.4507502017102976

Epoch: 6| Step: 12
Training loss: 2.535084116516397
Validation loss: 2.454547752969053

Epoch: 6| Step: 13
Training loss: 2.816364515527077
Validation loss: 2.45115993542442

Epoch: 135| Step: 0
Training loss: 2.4643109164321535
Validation loss: 2.4540680613459402

Epoch: 6| Step: 1
Training loss: 2.090952812461446
Validation loss: 2.4580901127989123

Epoch: 6| Step: 2
Training loss: 3.0857373909110453
Validation loss: 2.456680830815898

Epoch: 6| Step: 3
Training loss: 2.571192350209553
Validation loss: 2.453217255625238

Epoch: 6| Step: 4
Training loss: 2.5711032381581043
Validation loss: 2.4521792749278553

Epoch: 6| Step: 5
Training loss: 2.4057363977603683
Validation loss: 2.4495745354321543

Epoch: 6| Step: 6
Training loss: 2.234348537048275
Validation loss: 2.4591856518844954

Epoch: 6| Step: 7
Training loss: 2.0439135844706575
Validation loss: 2.4417045065211997

Epoch: 6| Step: 8
Training loss: 2.249705825224451
Validation loss: 2.4513303181174355

Epoch: 6| Step: 9
Training loss: 2.578596037402696
Validation loss: 2.4562934936348224

Epoch: 6| Step: 10
Training loss: 2.2601757946679135
Validation loss: 2.4606010085862784

Epoch: 6| Step: 11
Training loss: 2.9934554239818256
Validation loss: 2.4600009649941637

Epoch: 6| Step: 12
Training loss: 2.7942934536025725
Validation loss: 2.454055350541906

Epoch: 6| Step: 13
Training loss: 2.821669402717335
Validation loss: 2.452933933730143

Epoch: 136| Step: 0
Training loss: 2.2523534969736856
Validation loss: 2.4525867122650937

Epoch: 6| Step: 1
Training loss: 3.0684362993122427
Validation loss: 2.457895067448463

Epoch: 6| Step: 2
Training loss: 2.478257041771069
Validation loss: 2.455905124567244

Epoch: 6| Step: 3
Training loss: 2.380021558872319
Validation loss: 2.451987259850897

Epoch: 6| Step: 4
Training loss: 2.1833683777925637
Validation loss: 2.4515432453878425

Epoch: 6| Step: 5
Training loss: 2.3263586115092534
Validation loss: 2.451507829032636

Epoch: 6| Step: 6
Training loss: 2.5862712356632174
Validation loss: 2.448749990185771

Epoch: 6| Step: 7
Training loss: 2.6364241371866055
Validation loss: 2.4442447041295527

Epoch: 6| Step: 8
Training loss: 2.582211671374694
Validation loss: 2.44655401301393

Epoch: 6| Step: 9
Training loss: 2.950759020644112
Validation loss: 2.453238968520159

Epoch: 6| Step: 10
Training loss: 2.688735411820325
Validation loss: 2.45637496164454

Epoch: 6| Step: 11
Training loss: 2.247477176707376
Validation loss: 2.45291949178737

Epoch: 6| Step: 12
Training loss: 2.3891891455903993
Validation loss: 2.4536624003945335

Epoch: 6| Step: 13
Training loss: 2.4921377529811597
Validation loss: 2.451644872088345

Epoch: 137| Step: 0
Training loss: 2.0919669230893216
Validation loss: 2.446532638717742

Epoch: 6| Step: 1
Training loss: 2.6384718202868407
Validation loss: 2.453066507277905

Epoch: 6| Step: 2
Training loss: 3.011447998226187
Validation loss: 2.4498829567128304

Epoch: 6| Step: 3
Training loss: 2.163438617552276
Validation loss: 2.4517902784695678

Epoch: 6| Step: 4
Training loss: 3.158744204190926
Validation loss: 2.4599521420250783

Epoch: 6| Step: 5
Training loss: 2.569604468875481
Validation loss: 2.457237845480009

Epoch: 6| Step: 6
Training loss: 2.612764179068985
Validation loss: 2.460996225453623

Epoch: 6| Step: 7
Training loss: 3.007646987126302
Validation loss: 2.462098847712245

Epoch: 6| Step: 8
Training loss: 2.119742228113471
Validation loss: 2.4520433069903933

Epoch: 6| Step: 9
Training loss: 2.274570038796159
Validation loss: 2.454070830187513

Epoch: 6| Step: 10
Training loss: 2.0193368017562108
Validation loss: 2.458271257511175

Epoch: 6| Step: 11
Training loss: 2.458954123870712
Validation loss: 2.4582065183182786

Epoch: 6| Step: 12
Training loss: 2.7880250513273035
Validation loss: 2.4499668355889925

Epoch: 6| Step: 13
Training loss: 2.3262455669936832
Validation loss: 2.4581703897128535

Epoch: 138| Step: 0
Training loss: 2.7306342122557092
Validation loss: 2.462694572210421

Epoch: 6| Step: 1
Training loss: 2.5569448035126707
Validation loss: 2.458093976367307

Epoch: 6| Step: 2
Training loss: 2.599778213578255
Validation loss: 2.4484340905460136

Epoch: 6| Step: 3
Training loss: 2.5965414996783704
Validation loss: 2.456023211116331

Epoch: 6| Step: 4
Training loss: 2.5383224582585266
Validation loss: 2.460133044643315

Epoch: 6| Step: 5
Training loss: 2.6623665789633946
Validation loss: 2.452430027317715

Epoch: 6| Step: 6
Training loss: 2.4785884428637805
Validation loss: 2.460001481890555

Epoch: 6| Step: 7
Training loss: 2.722443100235705
Validation loss: 2.4487145334310347

Epoch: 6| Step: 8
Training loss: 1.4316345464517528
Validation loss: 2.45672419519065

Epoch: 6| Step: 9
Training loss: 2.330591520936987
Validation loss: 2.4525595416204644

Epoch: 6| Step: 10
Training loss: 2.507260555956018
Validation loss: 2.4573939570705354

Epoch: 6| Step: 11
Training loss: 2.7249772237123335
Validation loss: 2.4682232097535874

Epoch: 6| Step: 12
Training loss: 2.91798688890572
Validation loss: 2.454169413484635

Epoch: 6| Step: 13
Training loss: 2.138603425345821
Validation loss: 2.4534635370972198

Epoch: 139| Step: 0
Training loss: 2.7233419991413323
Validation loss: 2.453826156162485

Epoch: 6| Step: 1
Training loss: 2.2963451371188808
Validation loss: 2.454990010082588

Epoch: 6| Step: 2
Training loss: 2.271831246522726
Validation loss: 2.460548798073389

Epoch: 6| Step: 3
Training loss: 2.8906804259888905
Validation loss: 2.4602291803421332

Epoch: 6| Step: 4
Training loss: 1.79061648914385
Validation loss: 2.4654306397185257

Epoch: 6| Step: 5
Training loss: 2.6137725869967428
Validation loss: 2.4620958780883777

Epoch: 6| Step: 6
Training loss: 2.4320010243714836
Validation loss: 2.467456575376807

Epoch: 6| Step: 7
Training loss: 2.1961904921744564
Validation loss: 2.465739446642248

Epoch: 6| Step: 8
Training loss: 2.5002833205852935
Validation loss: 2.4559538581026046

Epoch: 6| Step: 9
Training loss: 2.5737248643015485
Validation loss: 2.4553990929392917

Epoch: 6| Step: 10
Training loss: 2.4261238482783725
Validation loss: 2.462460033783071

Epoch: 6| Step: 11
Training loss: 3.0454404926364025
Validation loss: 2.451811712276217

Epoch: 6| Step: 12
Training loss: 3.076926680709489
Validation loss: 2.4596936347066505

Epoch: 6| Step: 13
Training loss: 2.168397053518512
Validation loss: 2.462629239326485

Epoch: 140| Step: 0
Training loss: 1.8338571002578854
Validation loss: 2.4604297093867498

Epoch: 6| Step: 1
Training loss: 2.2894145187145503
Validation loss: 2.4610583563298754

Epoch: 6| Step: 2
Training loss: 2.0598217307424846
Validation loss: 2.46694526215993

Epoch: 6| Step: 3
Training loss: 2.606885990694922
Validation loss: 2.4636643092225423

Epoch: 6| Step: 4
Training loss: 1.8595345052054841
Validation loss: 2.4690793618474296

Epoch: 6| Step: 5
Training loss: 2.4147125652794994
Validation loss: 2.4671077819275964

Epoch: 6| Step: 6
Training loss: 3.0253137094806357
Validation loss: 2.45644342115516

Epoch: 6| Step: 7
Training loss: 2.5296260192449815
Validation loss: 2.4611531642490823

Epoch: 6| Step: 8
Training loss: 2.709443397934588
Validation loss: 2.4604333674041428

Epoch: 6| Step: 9
Training loss: 2.4328395599447927
Validation loss: 2.4556448966838667

Epoch: 6| Step: 10
Training loss: 2.8586438187402563
Validation loss: 2.4611847687681094

Epoch: 6| Step: 11
Training loss: 1.9579052829296488
Validation loss: 2.4532456985877014

Epoch: 6| Step: 12
Training loss: 2.9407392457342025
Validation loss: 2.4615784632851376

Epoch: 6| Step: 13
Training loss: 3.160149912597941
Validation loss: 2.452126544797441

Epoch: 141| Step: 0
Training loss: 2.593800371898866
Validation loss: 2.4524923266006593

Epoch: 6| Step: 1
Training loss: 2.339481281105351
Validation loss: 2.4515005674009465

Epoch: 6| Step: 2
Training loss: 2.1671484142648567
Validation loss: 2.4531183343946603

Epoch: 6| Step: 3
Training loss: 2.5229915071239404
Validation loss: 2.456374557223047

Epoch: 6| Step: 4
Training loss: 2.5958343771192025
Validation loss: 2.4657139277406626

Epoch: 6| Step: 5
Training loss: 2.189478606076635
Validation loss: 2.4609877485362737

Epoch: 6| Step: 6
Training loss: 2.751461507664903
Validation loss: 2.4637551379847777

Epoch: 6| Step: 7
Training loss: 2.4712899577914684
Validation loss: 2.4704477130416507

Epoch: 6| Step: 8
Training loss: 2.514648816747544
Validation loss: 2.4582337073704954

Epoch: 6| Step: 9
Training loss: 2.615621342992562
Validation loss: 2.4605031109470894

Epoch: 6| Step: 10
Training loss: 2.9872603124768875
Validation loss: 2.458771752741409

Epoch: 6| Step: 11
Training loss: 2.592890217767903
Validation loss: 2.461734122056099

Epoch: 6| Step: 12
Training loss: 2.27832805633864
Validation loss: 2.450569173975903

Epoch: 6| Step: 13
Training loss: 2.3679314882574314
Validation loss: 2.4599118472021004

Epoch: 142| Step: 0
Training loss: 2.6676085914595875
Validation loss: 2.461643323647741

Epoch: 6| Step: 1
Training loss: 2.960226089245665
Validation loss: 2.4942412011348623

Epoch: 6| Step: 2
Training loss: 1.8623606968955253
Validation loss: 2.4645142735543697

Epoch: 6| Step: 3
Training loss: 2.921937992824477
Validation loss: 2.460748445222485

Epoch: 6| Step: 4
Training loss: 2.210011857980529
Validation loss: 2.4603686285753157

Epoch: 6| Step: 5
Training loss: 2.736859135970513
Validation loss: 2.4612775779562375

Epoch: 6| Step: 6
Training loss: 2.2681876586433005
Validation loss: 2.4609502075513094

Epoch: 6| Step: 7
Training loss: 1.9845523304439487
Validation loss: 2.4537902545525765

Epoch: 6| Step: 8
Training loss: 2.814120016828744
Validation loss: 2.4631063602274277

Epoch: 6| Step: 9
Training loss: 2.185388472393079
Validation loss: 2.457658963461132

Epoch: 6| Step: 10
Training loss: 2.293917873798222
Validation loss: 2.4619767028352952

Epoch: 6| Step: 11
Training loss: 2.447000719058637
Validation loss: 2.458475599105655

Epoch: 6| Step: 12
Training loss: 2.982442499775198
Validation loss: 2.470398911555862

Epoch: 6| Step: 13
Training loss: 2.6316049223170044
Validation loss: 2.4621439565039305

Epoch: 143| Step: 0
Training loss: 2.21839493610342
Validation loss: 2.4685375267052256

Epoch: 6| Step: 1
Training loss: 2.7498136804058237
Validation loss: 2.4594940958104075

Epoch: 6| Step: 2
Training loss: 2.529329112668589
Validation loss: 2.475229171135657

Epoch: 6| Step: 3
Training loss: 2.4577105967258026
Validation loss: 2.4652510365452147

Epoch: 6| Step: 4
Training loss: 2.592897206026592
Validation loss: 2.4671507858627337

Epoch: 6| Step: 5
Training loss: 2.484014616924777
Validation loss: 2.4654498355145664

Epoch: 6| Step: 6
Training loss: 2.97809855558457
Validation loss: 2.4565131566581595

Epoch: 6| Step: 7
Training loss: 2.6207350643234175
Validation loss: 2.4529163895530104

Epoch: 6| Step: 8
Training loss: 1.869221620787875
Validation loss: 2.459967091890748

Epoch: 6| Step: 9
Training loss: 2.036530892590891
Validation loss: 2.462210448099592

Epoch: 6| Step: 10
Training loss: 3.2034998232485843
Validation loss: 2.4707729244298973

Epoch: 6| Step: 11
Training loss: 2.4929999578776627
Validation loss: 2.474325748398917

Epoch: 6| Step: 12
Training loss: 2.171714721913084
Validation loss: 2.4840983430701007

Epoch: 6| Step: 13
Training loss: 2.2871781753368725
Validation loss: 2.495120611518158

Epoch: 144| Step: 0
Training loss: 2.564985976747843
Validation loss: 2.4891552949519418

Epoch: 6| Step: 1
Training loss: 2.659582941731691
Validation loss: 2.4869455678111563

Epoch: 6| Step: 2
Training loss: 2.722695305214416
Validation loss: 2.4694887657417177

Epoch: 6| Step: 3
Training loss: 1.948335803084471
Validation loss: 2.4788997864461106

Epoch: 6| Step: 4
Training loss: 2.8317577992982943
Validation loss: 2.4587249174585692

Epoch: 6| Step: 5
Training loss: 1.8851582330724133
Validation loss: 2.4483815069719945

Epoch: 6| Step: 6
Training loss: 3.0183565882505414
Validation loss: 2.4431808817124403

Epoch: 6| Step: 7
Training loss: 2.7128111770674117
Validation loss: 2.446105113572162

Epoch: 6| Step: 8
Training loss: 2.4985073401904576
Validation loss: 2.4381599429502416

Epoch: 6| Step: 9
Training loss: 2.23342448470819
Validation loss: 2.4458088234015065

Epoch: 6| Step: 10
Training loss: 2.6837438905075173
Validation loss: 2.4530895821835097

Epoch: 6| Step: 11
Training loss: 2.6679091439912344
Validation loss: 2.4633429502919753

Epoch: 6| Step: 12
Training loss: 2.8000303403027993
Validation loss: 2.462552972407775

Epoch: 6| Step: 13
Training loss: 2.179296314863703
Validation loss: 2.4652991017835713

Epoch: 145| Step: 0
Training loss: 2.2743454001886194
Validation loss: 2.460614670665669

Epoch: 6| Step: 1
Training loss: 2.786936144400788
Validation loss: 2.465212633648266

Epoch: 6| Step: 2
Training loss: 3.003782113515165
Validation loss: 2.461940290610694

Epoch: 6| Step: 3
Training loss: 2.9593247019633364
Validation loss: 2.4634881742986017

Epoch: 6| Step: 4
Training loss: 2.2678447504209185
Validation loss: 2.4569063786654173

Epoch: 6| Step: 5
Training loss: 2.85399016416976
Validation loss: 2.458884102067379

Epoch: 6| Step: 6
Training loss: 2.096987143415734
Validation loss: 2.457379573679671

Epoch: 6| Step: 7
Training loss: 2.7195670117024395
Validation loss: 2.4628262492515964

Epoch: 6| Step: 8
Training loss: 2.625171110843264
Validation loss: 2.4549299107871163

Epoch: 6| Step: 9
Training loss: 2.1855586565533653
Validation loss: 2.451053044046459

Epoch: 6| Step: 10
Training loss: 2.052547834724094
Validation loss: 2.4528674012693883

Epoch: 6| Step: 11
Training loss: 2.626657961461444
Validation loss: 2.450654699471027

Epoch: 6| Step: 12
Training loss: 2.311385427399364
Validation loss: 2.4483348624491046

Epoch: 6| Step: 13
Training loss: 2.1839616769216
Validation loss: 2.453698579181729

Epoch: 146| Step: 0
Training loss: 2.508726339718068
Validation loss: 2.450927349320692

Epoch: 6| Step: 1
Training loss: 2.08215217167613
Validation loss: 2.4681442740924178

Epoch: 6| Step: 2
Training loss: 2.1378409665859355
Validation loss: 2.4767181315493585

Epoch: 6| Step: 3
Training loss: 1.6060308878435432
Validation loss: 2.4583520780807775

Epoch: 6| Step: 4
Training loss: 2.4171257459942463
Validation loss: 2.468477886027493

Epoch: 6| Step: 5
Training loss: 2.492177550675673
Validation loss: 2.4591615434793823

Epoch: 6| Step: 6
Training loss: 2.984455367199542
Validation loss: 2.4607715207595744

Epoch: 6| Step: 7
Training loss: 2.5818864605773237
Validation loss: 2.462412413380412

Epoch: 6| Step: 8
Training loss: 2.5932009012326933
Validation loss: 2.460583842059837

Epoch: 6| Step: 9
Training loss: 2.541418678401058
Validation loss: 2.463046555772322

Epoch: 6| Step: 10
Training loss: 2.761361925957318
Validation loss: 2.459412957318237

Epoch: 6| Step: 11
Training loss: 2.9539267445690447
Validation loss: 2.4604040546616184

Epoch: 6| Step: 12
Training loss: 2.863596483808869
Validation loss: 2.4636257283639056

Epoch: 6| Step: 13
Training loss: 2.485193273753604
Validation loss: 2.464227662873714

Epoch: 147| Step: 0
Training loss: 1.778317966281573
Validation loss: 2.4716397366007334

Epoch: 6| Step: 1
Training loss: 2.1922373020336403
Validation loss: 2.4695621072204417

Epoch: 6| Step: 2
Training loss: 3.0417706894179175
Validation loss: 2.4705181710998687

Epoch: 6| Step: 3
Training loss: 2.406123764888342
Validation loss: 2.4658848034573957

Epoch: 6| Step: 4
Training loss: 1.8649825480363027
Validation loss: 2.467244651024588

Epoch: 6| Step: 5
Training loss: 2.4484164978957255
Validation loss: 2.4601339330112237

Epoch: 6| Step: 6
Training loss: 2.095132058472149
Validation loss: 2.4719683437028235

Epoch: 6| Step: 7
Training loss: 2.8008154703388013
Validation loss: 2.464843862848939

Epoch: 6| Step: 8
Training loss: 2.9546879260518266
Validation loss: 2.46911103389232

Epoch: 6| Step: 9
Training loss: 2.5432507524128325
Validation loss: 2.4632271101438583

Epoch: 6| Step: 10
Training loss: 2.5486155921926668
Validation loss: 2.4657965268035964

Epoch: 6| Step: 11
Training loss: 3.0161483389601886
Validation loss: 2.4584781528640316

Epoch: 6| Step: 12
Training loss: 2.7333858771817527
Validation loss: 2.456852035576872

Epoch: 6| Step: 13
Training loss: 2.2825144568629954
Validation loss: 2.4640411827569904

Epoch: 148| Step: 0
Training loss: 2.2419818424983475
Validation loss: 2.480280511076334

Epoch: 6| Step: 1
Training loss: 1.852857756361958
Validation loss: 2.494549197291593

Epoch: 6| Step: 2
Training loss: 2.3162658545933956
Validation loss: 2.51661012051279

Epoch: 6| Step: 3
Training loss: 2.912062216670476
Validation loss: 2.521094968054885

Epoch: 6| Step: 4
Training loss: 2.3781436393097564
Validation loss: 2.4848186168828046

Epoch: 6| Step: 5
Training loss: 1.880257927266064
Validation loss: 2.4644996737428806

Epoch: 6| Step: 6
Training loss: 3.268066223864947
Validation loss: 2.455727081999125

Epoch: 6| Step: 7
Training loss: 2.8681210029858493
Validation loss: 2.441857168644961

Epoch: 6| Step: 8
Training loss: 2.572199074037049
Validation loss: 2.45276145103995

Epoch: 6| Step: 9
Training loss: 2.3424693359843274
Validation loss: 2.4607125154215077

Epoch: 6| Step: 10
Training loss: 2.6282246175023105
Validation loss: 2.462044796769309

Epoch: 6| Step: 11
Training loss: 2.221829171653724
Validation loss: 2.4637014378897493

Epoch: 6| Step: 12
Training loss: 2.549500592264786
Validation loss: 2.4652562670299063

Epoch: 6| Step: 13
Training loss: 2.443714143533899
Validation loss: 2.4605517695644172

Epoch: 149| Step: 0
Training loss: 2.333508098960147
Validation loss: 2.470641928255409

Epoch: 6| Step: 1
Training loss: 2.458408667062067
Validation loss: 2.4680844226604672

Epoch: 6| Step: 2
Training loss: 2.0104620999224556
Validation loss: 2.4629678494766933

Epoch: 6| Step: 3
Training loss: 2.51318307198059
Validation loss: 2.468456283029749

Epoch: 6| Step: 4
Training loss: 3.0305074195135315
Validation loss: 2.460408875541615

Epoch: 6| Step: 5
Training loss: 2.2835978092623432
Validation loss: 2.454840965014472

Epoch: 6| Step: 6
Training loss: 2.4216472887846563
Validation loss: 2.4483150131011047

Epoch: 6| Step: 7
Training loss: 2.420907005550338
Validation loss: 2.447839034993601

Epoch: 6| Step: 8
Training loss: 2.3057008746002428
Validation loss: 2.456040611757628

Epoch: 6| Step: 9
Training loss: 2.9009314652519573
Validation loss: 2.458267822578103

Epoch: 6| Step: 10
Training loss: 2.940964948116486
Validation loss: 2.4700720100356497

Epoch: 6| Step: 11
Training loss: 2.473928886372173
Validation loss: 2.4576294478573177

Epoch: 6| Step: 12
Training loss: 2.6994891990393257
Validation loss: 2.463483867545212

Epoch: 6| Step: 13
Training loss: 2.1940740710041524
Validation loss: 2.4579460410094685

Epoch: 150| Step: 0
Training loss: 2.3005214473236166
Validation loss: 2.4602885525968667

Epoch: 6| Step: 1
Training loss: 2.291368592268552
Validation loss: 2.4616643084663488

Epoch: 6| Step: 2
Training loss: 3.0476092114176283
Validation loss: 2.456874630155805

Epoch: 6| Step: 3
Training loss: 2.532525671238532
Validation loss: 2.4547266499913953

Epoch: 6| Step: 4
Training loss: 2.4238324530330013
Validation loss: 2.4521270795586037

Epoch: 6| Step: 5
Training loss: 2.770352993586905
Validation loss: 2.467703585434277

Epoch: 6| Step: 6
Training loss: 2.1261562119060673
Validation loss: 2.461012048954553

Epoch: 6| Step: 7
Training loss: 2.050617087923579
Validation loss: 2.4662673152232606

Epoch: 6| Step: 8
Training loss: 2.167837217997549
Validation loss: 2.465168878600686

Epoch: 6| Step: 9
Training loss: 2.88577358273954
Validation loss: 2.4548282905865406

Epoch: 6| Step: 10
Training loss: 1.9317286888853642
Validation loss: 2.4649336889657563

Epoch: 6| Step: 11
Training loss: 2.2534078645324658
Validation loss: 2.4653821579830013

Epoch: 6| Step: 12
Training loss: 3.1006586790187685
Validation loss: 2.454492467250521

Epoch: 6| Step: 13
Training loss: 2.653086315362758
Validation loss: 2.4518981262978192

Epoch: 151| Step: 0
Training loss: 2.163061798856567
Validation loss: 2.4554644240024546

Epoch: 6| Step: 1
Training loss: 2.203657586404402
Validation loss: 2.454685459990031

Epoch: 6| Step: 2
Training loss: 1.9517644797533538
Validation loss: 2.4605052911579697

Epoch: 6| Step: 3
Training loss: 2.8059082774739235
Validation loss: 2.4629363646408207

Epoch: 6| Step: 4
Training loss: 2.161953114942532
Validation loss: 2.4573262032063714

Epoch: 6| Step: 5
Training loss: 2.790166385297049
Validation loss: 2.458549228714014

Epoch: 6| Step: 6
Training loss: 2.6746645636900483
Validation loss: 2.461070748410319

Epoch: 6| Step: 7
Training loss: 3.1972536938537313
Validation loss: 2.471372257939571

Epoch: 6| Step: 8
Training loss: 2.264298675623788
Validation loss: 2.4534031574620254

Epoch: 6| Step: 9
Training loss: 3.0391701333566874
Validation loss: 2.470331240926129

Epoch: 6| Step: 10
Training loss: 2.373216762662397
Validation loss: 2.463951332166414

Epoch: 6| Step: 11
Training loss: 2.024578347282082
Validation loss: 2.463660244712396

Epoch: 6| Step: 12
Training loss: 2.8283919740561116
Validation loss: 2.4585489458693375

Epoch: 6| Step: 13
Training loss: 2.1229044735763933
Validation loss: 2.465203953624136

Epoch: 152| Step: 0
Training loss: 2.404186404283272
Validation loss: 2.4700422325333324

Epoch: 6| Step: 1
Training loss: 2.2690215859863736
Validation loss: 2.4599640066206705

Epoch: 6| Step: 2
Training loss: 3.0123315724502127
Validation loss: 2.4616962857574802

Epoch: 6| Step: 3
Training loss: 2.700740931537986
Validation loss: 2.4609384203712317

Epoch: 6| Step: 4
Training loss: 2.426371086514818
Validation loss: 2.4638093046227616

Epoch: 6| Step: 5
Training loss: 3.128554801871853
Validation loss: 2.4622922125479882

Epoch: 6| Step: 6
Training loss: 2.49616080180627
Validation loss: 2.4625691812418053

Epoch: 6| Step: 7
Training loss: 2.3124189620381626
Validation loss: 2.4658740711961666

Epoch: 6| Step: 8
Training loss: 2.6243806744173703
Validation loss: 2.46324729101549

Epoch: 6| Step: 9
Training loss: 2.228367124352169
Validation loss: 2.4705865684226724

Epoch: 6| Step: 10
Training loss: 2.087011625073842
Validation loss: 2.469640386145625

Epoch: 6| Step: 11
Training loss: 2.4034714943814497
Validation loss: 2.4691266122694056

Epoch: 6| Step: 12
Training loss: 2.5493242153712274
Validation loss: 2.4670491858461423

Epoch: 6| Step: 13
Training loss: 2.263122544602034
Validation loss: 2.469350878508313

Epoch: 153| Step: 0
Training loss: 2.4477246364728393
Validation loss: 2.471510780016159

Epoch: 6| Step: 1
Training loss: 2.162749515316884
Validation loss: 2.4638759286800784

Epoch: 6| Step: 2
Training loss: 2.230092138773242
Validation loss: 2.4575375842340796

Epoch: 6| Step: 3
Training loss: 2.974112395901848
Validation loss: 2.448761511492126

Epoch: 6| Step: 4
Training loss: 2.9707800098429242
Validation loss: 2.452468614173267

Epoch: 6| Step: 5
Training loss: 2.757724663305515
Validation loss: 2.4550027322333126

Epoch: 6| Step: 6
Training loss: 2.257682717365046
Validation loss: 2.4545391728366828

Epoch: 6| Step: 7
Training loss: 2.482487183198756
Validation loss: 2.459756032727028

Epoch: 6| Step: 8
Training loss: 2.2411505132105183
Validation loss: 2.464970975837813

Epoch: 6| Step: 9
Training loss: 2.753784436717491
Validation loss: 2.4598803151745234

Epoch: 6| Step: 10
Training loss: 2.198020052775858
Validation loss: 2.4577792292123655

Epoch: 6| Step: 11
Training loss: 1.8198232361606885
Validation loss: 2.4550630158794267

Epoch: 6| Step: 12
Training loss: 2.4859036714852425
Validation loss: 2.4533642694692723

Epoch: 6| Step: 13
Training loss: 3.009065916800493
Validation loss: 2.453862567339946

Epoch: 154| Step: 0
Training loss: 2.626951491344752
Validation loss: 2.454132650643719

Epoch: 6| Step: 1
Training loss: 2.1862989125524614
Validation loss: 2.449219269171928

Epoch: 6| Step: 2
Training loss: 2.3008199018201254
Validation loss: 2.4519895448684785

Epoch: 6| Step: 3
Training loss: 2.930479385165486
Validation loss: 2.4495658729927174

Epoch: 6| Step: 4
Training loss: 2.444658478363835
Validation loss: 2.4510836358671373

Epoch: 6| Step: 5
Training loss: 2.061443867631853
Validation loss: 2.463106836140521

Epoch: 6| Step: 6
Training loss: 2.31721551920644
Validation loss: 2.460559618159332

Epoch: 6| Step: 7
Training loss: 2.1724532201578963
Validation loss: 2.441517787165719

Epoch: 6| Step: 8
Training loss: 2.6259706609907187
Validation loss: 2.456516505077178

Epoch: 6| Step: 9
Training loss: 3.2487610142555243
Validation loss: 2.4471997015969613

Epoch: 6| Step: 10
Training loss: 2.940138261100108
Validation loss: 2.4463764025337023

Epoch: 6| Step: 11
Training loss: 2.237351042834649
Validation loss: 2.455474246977057

Epoch: 6| Step: 12
Training loss: 1.9594154073877483
Validation loss: 2.4525059690412547

Epoch: 6| Step: 13
Training loss: 2.403073877552274
Validation loss: 2.46551456179909

Epoch: 155| Step: 0
Training loss: 2.0628550830705485
Validation loss: 2.446791683904337

Epoch: 6| Step: 1
Training loss: 2.800515730228118
Validation loss: 2.4643617089126217

Epoch: 6| Step: 2
Training loss: 2.4291533346012044
Validation loss: 2.4626675614925233

Epoch: 6| Step: 3
Training loss: 2.9258718642092796
Validation loss: 2.4686573993039502

Epoch: 6| Step: 4
Training loss: 2.3817258264318504
Validation loss: 2.4730700588028376

Epoch: 6| Step: 5
Training loss: 2.349585833475165
Validation loss: 2.4772909478998772

Epoch: 6| Step: 6
Training loss: 2.49195195821925
Validation loss: 2.4661217392600787

Epoch: 6| Step: 7
Training loss: 2.222445995931956
Validation loss: 2.4676626361970486

Epoch: 6| Step: 8
Training loss: 2.4683182737246088
Validation loss: 2.4673193234608775

Epoch: 6| Step: 9
Training loss: 2.170267731635325
Validation loss: 2.4651411535047396

Epoch: 6| Step: 10
Training loss: 2.6853500460540576
Validation loss: 2.4684923576765705

Epoch: 6| Step: 11
Training loss: 2.6698382908002944
Validation loss: 2.4690936529423757

Epoch: 6| Step: 12
Training loss: 2.706681133930021
Validation loss: 2.4590973448109588

Epoch: 6| Step: 13
Training loss: 2.4934081911725556
Validation loss: 2.4632248194189637

Epoch: 156| Step: 0
Training loss: 2.583150139332591
Validation loss: 2.4644531004917742

Epoch: 6| Step: 1
Training loss: 2.6873561022181995
Validation loss: 2.471468720161173

Epoch: 6| Step: 2
Training loss: 3.161331165820853
Validation loss: 2.4593275182746077

Epoch: 6| Step: 3
Training loss: 2.300331266015972
Validation loss: 2.4553922473990673

Epoch: 6| Step: 4
Training loss: 2.3100934264871458
Validation loss: 2.460623181166141

Epoch: 6| Step: 5
Training loss: 2.835440600030491
Validation loss: 2.45302324023242

Epoch: 6| Step: 6
Training loss: 1.778090100205685
Validation loss: 2.4599858134204386

Epoch: 6| Step: 7
Training loss: 2.6799043172864945
Validation loss: 2.468235268028195

Epoch: 6| Step: 8
Training loss: 1.8184885210666635
Validation loss: 2.4572200975483893

Epoch: 6| Step: 9
Training loss: 2.170678557029856
Validation loss: 2.466084969295527

Epoch: 6| Step: 10
Training loss: 2.386103124559522
Validation loss: 2.461132691731019

Epoch: 6| Step: 11
Training loss: 3.1590195392657656
Validation loss: 2.4601960695124565

Epoch: 6| Step: 12
Training loss: 2.1759914111781313
Validation loss: 2.4645958164658883

Epoch: 6| Step: 13
Training loss: 2.5172707996757415
Validation loss: 2.4603869432876775

Epoch: 157| Step: 0
Training loss: 2.494340403179974
Validation loss: 2.458396059518344

Epoch: 6| Step: 1
Training loss: 2.1751662092170627
Validation loss: 2.4546715139948643

Epoch: 6| Step: 2
Training loss: 2.9085421803278173
Validation loss: 2.4623677129439008

Epoch: 6| Step: 3
Training loss: 2.6612508933091354
Validation loss: 2.4643850086049874

Epoch: 6| Step: 4
Training loss: 2.197552281648519
Validation loss: 2.466292755895783

Epoch: 6| Step: 5
Training loss: 2.5758404406479625
Validation loss: 2.4773075655697903

Epoch: 6| Step: 6
Training loss: 2.3393435954646766
Validation loss: 2.4753095022301457

Epoch: 6| Step: 7
Training loss: 2.957754714328806
Validation loss: 2.477073769087063

Epoch: 6| Step: 8
Training loss: 1.8081263026665624
Validation loss: 2.468994192931076

Epoch: 6| Step: 9
Training loss: 2.246972908783641
Validation loss: 2.4759773983208833

Epoch: 6| Step: 10
Training loss: 2.2327237730236034
Validation loss: 2.4721882534431807

Epoch: 6| Step: 11
Training loss: 2.6146192104922745
Validation loss: 2.471258997047781

Epoch: 6| Step: 12
Training loss: 2.1181888253508725
Validation loss: 2.472455740257044

Epoch: 6| Step: 13
Training loss: 3.1233635241482047
Validation loss: 2.4662671218795893

Epoch: 158| Step: 0
Training loss: 1.730877830081559
Validation loss: 2.471459153695158

Epoch: 6| Step: 1
Training loss: 2.7974244329287568
Validation loss: 2.463554194111388

Epoch: 6| Step: 2
Training loss: 2.0680246055216482
Validation loss: 2.4652044533106623

Epoch: 6| Step: 3
Training loss: 2.2442521747324884
Validation loss: 2.4646817097145046

Epoch: 6| Step: 4
Training loss: 3.0801415978122244
Validation loss: 2.460268694707589

Epoch: 6| Step: 5
Training loss: 2.491348938687987
Validation loss: 2.458243519279229

Epoch: 6| Step: 6
Training loss: 2.4486792059844835
Validation loss: 2.473568860901631

Epoch: 6| Step: 7
Training loss: 2.862341504102611
Validation loss: 2.465675886601676

Epoch: 6| Step: 8
Training loss: 2.7571077391860728
Validation loss: 2.4738014787172222

Epoch: 6| Step: 9
Training loss: 2.624027889632667
Validation loss: 2.4806798649855155

Epoch: 6| Step: 10
Training loss: 2.030380062736461
Validation loss: 2.47190923590729

Epoch: 6| Step: 11
Training loss: 1.96873086586994
Validation loss: 2.4654302367824985

Epoch: 6| Step: 12
Training loss: 2.9045854949687757
Validation loss: 2.4607510127702006

Epoch: 6| Step: 13
Training loss: 2.191160681253887
Validation loss: 2.465295475163464

Epoch: 159| Step: 0
Training loss: 2.313560654998678
Validation loss: 2.4744234845745376

Epoch: 6| Step: 1
Training loss: 2.047462786661201
Validation loss: 2.475668472027774

Epoch: 6| Step: 2
Training loss: 2.3910485185449266
Validation loss: 2.4662565040663735

Epoch: 6| Step: 3
Training loss: 2.504108771883634
Validation loss: 2.4627400734667524

Epoch: 6| Step: 4
Training loss: 2.113508906767799
Validation loss: 2.465592147292402

Epoch: 6| Step: 5
Training loss: 2.7775360341314093
Validation loss: 2.4689927766430833

Epoch: 6| Step: 6
Training loss: 2.5696944679296605
Validation loss: 2.4558631857705975

Epoch: 6| Step: 7
Training loss: 1.9701488913992302
Validation loss: 2.4665841206923598

Epoch: 6| Step: 8
Training loss: 3.2811064189195984
Validation loss: 2.456264099132397

Epoch: 6| Step: 9
Training loss: 1.9077329026971903
Validation loss: 2.4625944826231434

Epoch: 6| Step: 10
Training loss: 2.079683565498603
Validation loss: 2.4595814839163945

Epoch: 6| Step: 11
Training loss: 2.415986809523998
Validation loss: 2.465508840296089

Epoch: 6| Step: 12
Training loss: 2.926568163587769
Validation loss: 2.4625227247761305

Epoch: 6| Step: 13
Training loss: 2.962056051863692
Validation loss: 2.4511119009434377

Epoch: 160| Step: 0
Training loss: 2.1751954747196782
Validation loss: 2.472002566743648

Epoch: 6| Step: 1
Training loss: 2.211576227994741
Validation loss: 2.465746698571142

Epoch: 6| Step: 2
Training loss: 2.7580242129750583
Validation loss: 2.4643715286714163

Epoch: 6| Step: 3
Training loss: 1.442214615092684
Validation loss: 2.4676241983670977

Epoch: 6| Step: 4
Training loss: 2.944719249769142
Validation loss: 2.481807557695243

Epoch: 6| Step: 5
Training loss: 2.813835505131557
Validation loss: 2.4942259548629404

Epoch: 6| Step: 6
Training loss: 2.3922467683492625
Validation loss: 2.5336383336908757

Epoch: 6| Step: 7
Training loss: 2.8118811032376736
Validation loss: 2.521179669341257

Epoch: 6| Step: 8
Training loss: 3.295410409470375
Validation loss: 2.5108500748903473

Epoch: 6| Step: 9
Training loss: 2.22998233976342
Validation loss: 2.498111591788277

Epoch: 6| Step: 10
Training loss: 1.8837586870607022
Validation loss: 2.4812674770812695

Epoch: 6| Step: 11
Training loss: 1.9033925887780956
Validation loss: 2.497521697934341

Epoch: 6| Step: 12
Training loss: 2.80837880294922
Validation loss: 2.4833153598143505

Epoch: 6| Step: 13
Training loss: 2.524875101456328
Validation loss: 2.4662724710489012

Epoch: 161| Step: 0
Training loss: 2.3441656125641845
Validation loss: 2.4665181900349684

Epoch: 6| Step: 1
Training loss: 2.537001116339258
Validation loss: 2.4728319407996913

Epoch: 6| Step: 2
Training loss: 3.067473129987978
Validation loss: 2.483699290835108

Epoch: 6| Step: 3
Training loss: 2.0879348164976594
Validation loss: 2.481897042031779

Epoch: 6| Step: 4
Training loss: 2.574400089342627
Validation loss: 2.477171011854993

Epoch: 6| Step: 5
Training loss: 2.6026123494606224
Validation loss: 2.483416046348163

Epoch: 6| Step: 6
Training loss: 2.3701103471265115
Validation loss: 2.4724033461406303

Epoch: 6| Step: 7
Training loss: 2.6568423340018015
Validation loss: 2.474064302015369

Epoch: 6| Step: 8
Training loss: 2.4984218384595995
Validation loss: 2.4679565442266362

Epoch: 6| Step: 9
Training loss: 2.790699710678866
Validation loss: 2.4690976763213017

Epoch: 6| Step: 10
Training loss: 2.3409665682302636
Validation loss: 2.4609425378172642

Epoch: 6| Step: 11
Training loss: 2.8149251866266236
Validation loss: 2.456010364817619

Epoch: 6| Step: 12
Training loss: 2.255063188094694
Validation loss: 2.4626913290036714

Epoch: 6| Step: 13
Training loss: 2.333919303976546
Validation loss: 2.4736491495309063

Epoch: 162| Step: 0
Training loss: 2.0374493411266625
Validation loss: 2.473554290436829

Epoch: 6| Step: 1
Training loss: 2.269220275058876
Validation loss: 2.4780052627556852

Epoch: 6| Step: 2
Training loss: 2.7199338768887777
Validation loss: 2.4707003024239684

Epoch: 6| Step: 3
Training loss: 2.2527649103631577
Validation loss: 2.470666841383775

Epoch: 6| Step: 4
Training loss: 2.223471976232072
Validation loss: 2.4629660021838324

Epoch: 6| Step: 5
Training loss: 2.7605926937383276
Validation loss: 2.4723814479638944

Epoch: 6| Step: 6
Training loss: 2.098305827175903
Validation loss: 2.4664562530813834

Epoch: 6| Step: 7
Training loss: 2.760124642142295
Validation loss: 2.4638046113568994

Epoch: 6| Step: 8
Training loss: 2.3977474251244986
Validation loss: 2.476840271399479

Epoch: 6| Step: 9
Training loss: 2.0052150445470756
Validation loss: 2.489027205937589

Epoch: 6| Step: 10
Training loss: 3.2871505725656607
Validation loss: 2.503798841056248

Epoch: 6| Step: 11
Training loss: 2.2096337022626735
Validation loss: 2.529046209966254

Epoch: 6| Step: 12
Training loss: 2.6388454422525247
Validation loss: 2.5322310347982824

Epoch: 6| Step: 13
Training loss: 2.6729889270968417
Validation loss: 2.543363025920257

Epoch: 163| Step: 0
Training loss: 2.548726725114233
Validation loss: 2.526106266624575

Epoch: 6| Step: 1
Training loss: 2.370549499291012
Validation loss: 2.4830441619109602

Epoch: 6| Step: 2
Training loss: 2.303660121743755
Validation loss: 2.4730724207465995

Epoch: 6| Step: 3
Training loss: 2.590601193234674
Validation loss: 2.4689394157916036

Epoch: 6| Step: 4
Training loss: 2.2849707373283312
Validation loss: 2.470172424012503

Epoch: 6| Step: 5
Training loss: 1.5977086289454006
Validation loss: 2.4772549693001653

Epoch: 6| Step: 6
Training loss: 2.8701387854325167
Validation loss: 2.4772533171272197

Epoch: 6| Step: 7
Training loss: 2.729639628732442
Validation loss: 2.4738172042479536

Epoch: 6| Step: 8
Training loss: 2.864166081413392
Validation loss: 2.486538327009993

Epoch: 6| Step: 9
Training loss: 2.3294450742489876
Validation loss: 2.477387043327937

Epoch: 6| Step: 10
Training loss: 2.3712060640937085
Validation loss: 2.482935474407953

Epoch: 6| Step: 11
Training loss: 2.7059833210207667
Validation loss: 2.478123603041112

Epoch: 6| Step: 12
Training loss: 2.929865066233503
Validation loss: 2.4771188618449065

Epoch: 6| Step: 13
Training loss: 2.2214655846353963
Validation loss: 2.4845372912742487

Epoch: 164| Step: 0
Training loss: 2.089205007892342
Validation loss: 2.4705795156646015

Epoch: 6| Step: 1
Training loss: 2.425539849351277
Validation loss: 2.4826810167794546

Epoch: 6| Step: 2
Training loss: 2.684987601565926
Validation loss: 2.4743690283679904

Epoch: 6| Step: 3
Training loss: 2.617617261531688
Validation loss: 2.4741355805731717

Epoch: 6| Step: 4
Training loss: 2.9180435926855988
Validation loss: 2.4725226375725082

Epoch: 6| Step: 5
Training loss: 2.2342225136109266
Validation loss: 2.477493063169251

Epoch: 6| Step: 6
Training loss: 2.817031431185948
Validation loss: 2.482910628367191

Epoch: 6| Step: 7
Training loss: 2.754748839129806
Validation loss: 2.501043094145783

Epoch: 6| Step: 8
Training loss: 2.7139719050280786
Validation loss: 2.5067766532035165

Epoch: 6| Step: 9
Training loss: 2.1864457996209685
Validation loss: 2.4810803077510264

Epoch: 6| Step: 10
Training loss: 1.859028246947641
Validation loss: 2.490475508041717

Epoch: 6| Step: 11
Training loss: 2.228736431874274
Validation loss: 2.4968177250932198

Epoch: 6| Step: 12
Training loss: 2.4445008707277087
Validation loss: 2.4901381051397666

Epoch: 6| Step: 13
Training loss: 2.5432402528834586
Validation loss: 2.496429946060161

Epoch: 165| Step: 0
Training loss: 3.049705716303573
Validation loss: 2.4872659461293436

Epoch: 6| Step: 1
Training loss: 2.063368527734175
Validation loss: 2.471889929519367

Epoch: 6| Step: 2
Training loss: 2.380742008361254
Validation loss: 2.4850240375423103

Epoch: 6| Step: 3
Training loss: 1.848091187204886
Validation loss: 2.4683377046393975

Epoch: 6| Step: 4
Training loss: 2.3106767838783604
Validation loss: 2.4677354683651553

Epoch: 6| Step: 5
Training loss: 3.0088188568591354
Validation loss: 2.4791175586313905

Epoch: 6| Step: 6
Training loss: 2.0721774931924766
Validation loss: 2.478073862325066

Epoch: 6| Step: 7
Training loss: 2.3763685800663197
Validation loss: 2.472388061635513

Epoch: 6| Step: 8
Training loss: 2.6133893593634365
Validation loss: 2.4764906815666055

Epoch: 6| Step: 9
Training loss: 2.397165066551055
Validation loss: 2.4809037915895025

Epoch: 6| Step: 10
Training loss: 2.6344070812729075
Validation loss: 2.4813055914633604

Epoch: 6| Step: 11
Training loss: 2.238497898341955
Validation loss: 2.4738064582117216

Epoch: 6| Step: 12
Training loss: 2.664143759643218
Validation loss: 2.4765350308183494

Epoch: 6| Step: 13
Training loss: 2.6282126431360693
Validation loss: 2.467886624887341

Epoch: 166| Step: 0
Training loss: 2.7757099137076504
Validation loss: 2.4715147190714264

Epoch: 6| Step: 1
Training loss: 2.269252004859764
Validation loss: 2.4907829687676832

Epoch: 6| Step: 2
Training loss: 2.504736894964097
Validation loss: 2.4704770674591727

Epoch: 6| Step: 3
Training loss: 2.773962524578974
Validation loss: 2.4816800581564564

Epoch: 6| Step: 4
Training loss: 2.737395008460147
Validation loss: 2.48115532451815

Epoch: 6| Step: 5
Training loss: 2.412699786990913
Validation loss: 2.490461319698654

Epoch: 6| Step: 6
Training loss: 2.0577977069157916
Validation loss: 2.485060495296483

Epoch: 6| Step: 7
Training loss: 2.915720940715345
Validation loss: 2.487085890685296

Epoch: 6| Step: 8
Training loss: 1.9328674801999242
Validation loss: 2.4864004263962194

Epoch: 6| Step: 9
Training loss: 2.391500973250861
Validation loss: 2.4886422526705685

Epoch: 6| Step: 10
Training loss: 2.4799587896983883
Validation loss: 2.4812970077712455

Epoch: 6| Step: 11
Training loss: 2.285916506813634
Validation loss: 2.4925272519666595

Epoch: 6| Step: 12
Training loss: 2.6932460658725357
Validation loss: 2.4838363575365237

Epoch: 6| Step: 13
Training loss: 2.211403949180845
Validation loss: 2.4891385328833353

Epoch: 167| Step: 0
Training loss: 2.7223017501459417
Validation loss: 2.4802844842667318

Epoch: 6| Step: 1
Training loss: 2.499576055820624
Validation loss: 2.479535729856164

Epoch: 6| Step: 2
Training loss: 2.504244729431705
Validation loss: 2.4790978836220208

Epoch: 6| Step: 3
Training loss: 2.981044168784266
Validation loss: 2.4701385777836427

Epoch: 6| Step: 4
Training loss: 1.580185479854051
Validation loss: 2.4802173557194824

Epoch: 6| Step: 5
Training loss: 1.7674072857487182
Validation loss: 2.470230013012864

Epoch: 6| Step: 6
Training loss: 2.6246391229977615
Validation loss: 2.473935584248134

Epoch: 6| Step: 7
Training loss: 2.7249067903028577
Validation loss: 2.472507988621451

Epoch: 6| Step: 8
Training loss: 2.0842962201513973
Validation loss: 2.473472319932411

Epoch: 6| Step: 9
Training loss: 2.0105159385825404
Validation loss: 2.4647387821277436

Epoch: 6| Step: 10
Training loss: 2.1244984203107404
Validation loss: 2.472368365217499

Epoch: 6| Step: 11
Training loss: 2.1345701695317456
Validation loss: 2.4704678027601346

Epoch: 6| Step: 12
Training loss: 2.7761864162207557
Validation loss: 2.470062856427825

Epoch: 6| Step: 13
Training loss: 3.5033555974957613
Validation loss: 2.4773830815303457

Epoch: 168| Step: 0
Training loss: 2.522229546224946
Validation loss: 2.473530289947154

Epoch: 6| Step: 1
Training loss: 2.558312134131989
Validation loss: 2.4774683469975876

Epoch: 6| Step: 2
Training loss: 2.7492295833286398
Validation loss: 2.468158900644006

Epoch: 6| Step: 3
Training loss: 2.671333124191064
Validation loss: 2.4709714881994467

Epoch: 6| Step: 4
Training loss: 1.6296181712486275
Validation loss: 2.473230906839378

Epoch: 6| Step: 5
Training loss: 2.9435957299242075
Validation loss: 2.474892326864248

Epoch: 6| Step: 6
Training loss: 2.66361794440221
Validation loss: 2.4848609465052567

Epoch: 6| Step: 7
Training loss: 1.9915048065280783
Validation loss: 2.4956499559884016

Epoch: 6| Step: 8
Training loss: 2.504087825386673
Validation loss: 2.4984688043372767

Epoch: 6| Step: 9
Training loss: 2.82229814873669
Validation loss: 2.4986847437673196

Epoch: 6| Step: 10
Training loss: 2.536324395018819
Validation loss: 2.486648463019796

Epoch: 6| Step: 11
Training loss: 2.2406072597253592
Validation loss: 2.4867738862056803

Epoch: 6| Step: 12
Training loss: 2.1167679825011394
Validation loss: 2.4912519781803764

Epoch: 6| Step: 13
Training loss: 2.564393065331067
Validation loss: 2.4841405809916752

Epoch: 169| Step: 0
Training loss: 2.513139053225744
Validation loss: 2.4759139727087276

Epoch: 6| Step: 1
Training loss: 2.4400856780034004
Validation loss: 2.470743292078695

Epoch: 6| Step: 2
Training loss: 1.9609472266940042
Validation loss: 2.4671647821128984

Epoch: 6| Step: 3
Training loss: 2.6531436483673607
Validation loss: 2.468863504754082

Epoch: 6| Step: 4
Training loss: 3.2370404303909828
Validation loss: 2.4677003810159177

Epoch: 6| Step: 5
Training loss: 2.682783379282839
Validation loss: 2.46858105302714

Epoch: 6| Step: 6
Training loss: 2.986264254957932
Validation loss: 2.4668219075023923

Epoch: 6| Step: 7
Training loss: 1.6376513462158835
Validation loss: 2.469678551250085

Epoch: 6| Step: 8
Training loss: 2.5732438552532546
Validation loss: 2.4684577962116054

Epoch: 6| Step: 9
Training loss: 2.306667912359765
Validation loss: 2.4728300285642084

Epoch: 6| Step: 10
Training loss: 2.868119174189084
Validation loss: 2.4715076930786646

Epoch: 6| Step: 11
Training loss: 1.9967409044113273
Validation loss: 2.479638949589773

Epoch: 6| Step: 12
Training loss: 2.3240748256711967
Validation loss: 2.4837296805392937

Epoch: 6| Step: 13
Training loss: 2.081369491675244
Validation loss: 2.468293916446359

Epoch: 170| Step: 0
Training loss: 1.8590760190994475
Validation loss: 2.4798057410980534

Epoch: 6| Step: 1
Training loss: 2.3278331189593726
Validation loss: 2.4956417560022843

Epoch: 6| Step: 2
Training loss: 2.2424822357732936
Validation loss: 2.4786363055762206

Epoch: 6| Step: 3
Training loss: 2.381950447611261
Validation loss: 2.4783851663350793

Epoch: 6| Step: 4
Training loss: 1.837188489290436
Validation loss: 2.475957449600304

Epoch: 6| Step: 5
Training loss: 2.678372608253713
Validation loss: 2.4788071881992986

Epoch: 6| Step: 6
Training loss: 2.3183192673052373
Validation loss: 2.471810652791117

Epoch: 6| Step: 7
Training loss: 3.1066287387393636
Validation loss: 2.4722479573052136

Epoch: 6| Step: 8
Training loss: 2.588855123186007
Validation loss: 2.4642596230267566

Epoch: 6| Step: 9
Training loss: 2.8660056357478054
Validation loss: 2.4673340032178577

Epoch: 6| Step: 10
Training loss: 2.132372912145105
Validation loss: 2.4656834046280176

Epoch: 6| Step: 11
Training loss: 3.073434111569529
Validation loss: 2.4586735398402655

Epoch: 6| Step: 12
Training loss: 2.3017049855387857
Validation loss: 2.464662814262763

Epoch: 6| Step: 13
Training loss: 2.4785033121246562
Validation loss: 2.4601689506034137

Epoch: 171| Step: 0
Training loss: 2.792640592063438
Validation loss: 2.4728316676232844

Epoch: 6| Step: 1
Training loss: 2.673173020265777
Validation loss: 2.4654251033717474

Epoch: 6| Step: 2
Training loss: 2.2890532301366804
Validation loss: 2.4660474817361537

Epoch: 6| Step: 3
Training loss: 2.2213060941037353
Validation loss: 2.4769107160641037

Epoch: 6| Step: 4
Training loss: 2.2968899473365676
Validation loss: 2.47372823080129

Epoch: 6| Step: 5
Training loss: 2.5944938971711795
Validation loss: 2.47927093019479

Epoch: 6| Step: 6
Training loss: 2.938882867494058
Validation loss: 2.471594174102891

Epoch: 6| Step: 7
Training loss: 1.9505232304624964
Validation loss: 2.478150429260448

Epoch: 6| Step: 8
Training loss: 2.0024775418321155
Validation loss: 2.4942088285842803

Epoch: 6| Step: 9
Training loss: 2.592937663996209
Validation loss: 2.4971168582354073

Epoch: 6| Step: 10
Training loss: 2.848890416499836
Validation loss: 2.5291960903595014

Epoch: 6| Step: 11
Training loss: 2.5896986608585824
Validation loss: 2.497452391513395

Epoch: 6| Step: 12
Training loss: 2.2912693257200996
Validation loss: 2.4774176307584046

Epoch: 6| Step: 13
Training loss: 2.2067023918433115
Validation loss: 2.465392835973706

Epoch: 172| Step: 0
Training loss: 2.2109508716192376
Validation loss: 2.458663794294832

Epoch: 6| Step: 1
Training loss: 2.4874389755968114
Validation loss: 2.4703017882618146

Epoch: 6| Step: 2
Training loss: 2.518052724490778
Validation loss: 2.4755815715362552

Epoch: 6| Step: 3
Training loss: 2.2441503991029537
Validation loss: 2.4721016967578326

Epoch: 6| Step: 4
Training loss: 2.7098039791257307
Validation loss: 2.4825869989789253

Epoch: 6| Step: 5
Training loss: 2.3004326289094768
Validation loss: 2.471681150478421

Epoch: 6| Step: 6
Training loss: 2.351015756103991
Validation loss: 2.484571597079955

Epoch: 6| Step: 7
Training loss: 2.6043520340114017
Validation loss: 2.469501043109013

Epoch: 6| Step: 8
Training loss: 1.7949281179757453
Validation loss: 2.4588705758164924

Epoch: 6| Step: 9
Training loss: 2.6530362603002655
Validation loss: 2.4596299022789783

Epoch: 6| Step: 10
Training loss: 2.785795205376743
Validation loss: 2.459358976603574

Epoch: 6| Step: 11
Training loss: 2.493186726450307
Validation loss: 2.4670959355808186

Epoch: 6| Step: 12
Training loss: 2.851185060369481
Validation loss: 2.470584445359647

Epoch: 6| Step: 13
Training loss: 2.45370729180906
Validation loss: 2.474005340664978

Epoch: 173| Step: 0
Training loss: 2.2066531237199136
Validation loss: 2.482515386845545

Epoch: 6| Step: 1
Training loss: 2.362087686072288
Validation loss: 2.4880558792168372

Epoch: 6| Step: 2
Training loss: 2.1405416876180348
Validation loss: 2.484206715768253

Epoch: 6| Step: 3
Training loss: 2.3427769993655185
Validation loss: 2.4839837427963825

Epoch: 6| Step: 4
Training loss: 2.339560974050484
Validation loss: 2.4784663090009316

Epoch: 6| Step: 5
Training loss: 2.2843837377795975
Validation loss: 2.474930258452261

Epoch: 6| Step: 6
Training loss: 3.120461181399176
Validation loss: 2.4803645555133764

Epoch: 6| Step: 7
Training loss: 2.23834665146324
Validation loss: 2.4803091243134405

Epoch: 6| Step: 8
Training loss: 2.835920853999442
Validation loss: 2.476632695852867

Epoch: 6| Step: 9
Training loss: 2.4591639349403147
Validation loss: 2.4734512826740787

Epoch: 6| Step: 10
Training loss: 2.8763093040217953
Validation loss: 2.4618298482002703

Epoch: 6| Step: 11
Training loss: 2.519536738426677
Validation loss: 2.4684260674914666

Epoch: 6| Step: 12
Training loss: 2.589482669198539
Validation loss: 2.4582729870991877

Epoch: 6| Step: 13
Training loss: 2.3103164467661133
Validation loss: 2.475461600828523

Epoch: 174| Step: 0
Training loss: 2.752615378557587
Validation loss: 2.465138638887591

Epoch: 6| Step: 1
Training loss: 2.810315873525693
Validation loss: 2.4729588038757346

Epoch: 6| Step: 2
Training loss: 2.0675630558458624
Validation loss: 2.5079459910451076

Epoch: 6| Step: 3
Training loss: 2.3115407655402476
Validation loss: 2.5328043651038343

Epoch: 6| Step: 4
Training loss: 2.7874986554471866
Validation loss: 2.5606731012202766

Epoch: 6| Step: 5
Training loss: 2.6852588623968927
Validation loss: 2.5488047397753846

Epoch: 6| Step: 6
Training loss: 1.881389285789583
Validation loss: 2.5028680879888996

Epoch: 6| Step: 7
Training loss: 2.699547666170892
Validation loss: 2.5001445092714936

Epoch: 6| Step: 8
Training loss: 2.028057230094861
Validation loss: 2.4701583965442677

Epoch: 6| Step: 9
Training loss: 2.6518363635871585
Validation loss: 2.464143051930467

Epoch: 6| Step: 10
Training loss: 2.626539233193721
Validation loss: 2.461458875537952

Epoch: 6| Step: 11
Training loss: 2.6020559581806024
Validation loss: 2.4694915172932994

Epoch: 6| Step: 12
Training loss: 1.7293009724987456
Validation loss: 2.465667224324254

Epoch: 6| Step: 13
Training loss: 2.622242523732594
Validation loss: 2.4741855610680323

Epoch: 175| Step: 0
Training loss: 2.7042604388028204
Validation loss: 2.472563795598044

Epoch: 6| Step: 1
Training loss: 3.1365402759974406
Validation loss: 2.467918255885051

Epoch: 6| Step: 2
Training loss: 2.2763508485578363
Validation loss: 2.471435856381848

Epoch: 6| Step: 3
Training loss: 2.087330899270774
Validation loss: 2.4699437759991385

Epoch: 6| Step: 4
Training loss: 2.61179554763883
Validation loss: 2.469804031768011

Epoch: 6| Step: 5
Training loss: 2.7680089126674954
Validation loss: 2.468491697681073

Epoch: 6| Step: 6
Training loss: 1.8298471278557729
Validation loss: 2.468641399457524

Epoch: 6| Step: 7
Training loss: 2.5364484741102875
Validation loss: 2.4673330530222986

Epoch: 6| Step: 8
Training loss: 2.193053797481649
Validation loss: 2.47672783814158

Epoch: 6| Step: 9
Training loss: 2.1586980882155973
Validation loss: 2.4716204763389182

Epoch: 6| Step: 10
Training loss: 2.3650061499614474
Validation loss: 2.4731250738324344

Epoch: 6| Step: 11
Training loss: 2.080843302079433
Validation loss: 2.4833505785639844

Epoch: 6| Step: 12
Training loss: 2.604998636227066
Validation loss: 2.477856816279469

Epoch: 6| Step: 13
Training loss: 3.011653835126447
Validation loss: 2.492714805185472

Epoch: 176| Step: 0
Training loss: 2.7519503526423224
Validation loss: 2.5078138943645527

Epoch: 6| Step: 1
Training loss: 2.9253675833023998
Validation loss: 2.5039088367720566

Epoch: 6| Step: 2
Training loss: 2.44215925887382
Validation loss: 2.51321823583424

Epoch: 6| Step: 3
Training loss: 2.7395071640352646
Validation loss: 2.5065214610991795

Epoch: 6| Step: 4
Training loss: 1.8732865451703224
Validation loss: 2.5050400791781717

Epoch: 6| Step: 5
Training loss: 2.6079954052340515
Validation loss: 2.4894825237937943

Epoch: 6| Step: 6
Training loss: 1.6399935279113715
Validation loss: 2.494405478980495

Epoch: 6| Step: 7
Training loss: 2.2408807116467773
Validation loss: 2.4920251807404554

Epoch: 6| Step: 8
Training loss: 2.5654755970506717
Validation loss: 2.501839167878086

Epoch: 6| Step: 9
Training loss: 2.5676015918099786
Validation loss: 2.506071157567069

Epoch: 6| Step: 10
Training loss: 2.7509124282548956
Validation loss: 2.490258533634857

Epoch: 6| Step: 11
Training loss: 2.3901203096506443
Validation loss: 2.485625649997983

Epoch: 6| Step: 12
Training loss: 2.846169584710588
Validation loss: 2.4738304238966533

Epoch: 6| Step: 13
Training loss: 1.5704839053004847
Validation loss: 2.48262137975202

Epoch: 177| Step: 0
Training loss: 2.63081116267535
Validation loss: 2.4819803112815775

Epoch: 6| Step: 1
Training loss: 2.003813683823918
Validation loss: 2.4759055548908564

Epoch: 6| Step: 2
Training loss: 2.8517838901643953
Validation loss: 2.4719620584427946

Epoch: 6| Step: 3
Training loss: 2.029912537630848
Validation loss: 2.4747831609251

Epoch: 6| Step: 4
Training loss: 2.2508906614913604
Validation loss: 2.477555069040315

Epoch: 6| Step: 5
Training loss: 2.2851779512858443
Validation loss: 2.4749354845365987

Epoch: 6| Step: 6
Training loss: 2.8674954864812316
Validation loss: 2.4772085797146977

Epoch: 6| Step: 7
Training loss: 2.4095662042372976
Validation loss: 2.472750581104068

Epoch: 6| Step: 8
Training loss: 2.399215522349058
Validation loss: 2.4727680649065853

Epoch: 6| Step: 9
Training loss: 2.70969804468084
Validation loss: 2.4727437996694506

Epoch: 6| Step: 10
Training loss: 1.7977975881784642
Validation loss: 2.479992662131826

Epoch: 6| Step: 11
Training loss: 2.8371288645013326
Validation loss: 2.4840021713378393

Epoch: 6| Step: 12
Training loss: 2.174531149480792
Validation loss: 2.482612320432498

Epoch: 6| Step: 13
Training loss: 2.76431760759004
Validation loss: 2.4785302945567897

Epoch: 178| Step: 0
Training loss: 2.5390902004198117
Validation loss: 2.487195730849568

Epoch: 6| Step: 1
Training loss: 2.4144689717719325
Validation loss: 2.481500534169779

Epoch: 6| Step: 2
Training loss: 2.593475327253238
Validation loss: 2.4848196083669083

Epoch: 6| Step: 3
Training loss: 3.131584554681562
Validation loss: 2.489115065797651

Epoch: 6| Step: 4
Training loss: 2.270975884212513
Validation loss: 2.4917617880697174

Epoch: 6| Step: 5
Training loss: 1.5583119532024556
Validation loss: 2.4819738112253233

Epoch: 6| Step: 6
Training loss: 1.9964629128649167
Validation loss: 2.4906168326096774

Epoch: 6| Step: 7
Training loss: 2.2086383201114983
Validation loss: 2.5038984420583215

Epoch: 6| Step: 8
Training loss: 2.3041118355470527
Validation loss: 2.498133677986959

Epoch: 6| Step: 9
Training loss: 2.4475738501780073
Validation loss: 2.511173202887266

Epoch: 6| Step: 10
Training loss: 2.7984646163810902
Validation loss: 2.4910939048434138

Epoch: 6| Step: 11
Training loss: 2.3154762292348967
Validation loss: 2.4914747233335093

Epoch: 6| Step: 12
Training loss: 2.2158476423088707
Validation loss: 2.484741887606544

Epoch: 6| Step: 13
Training loss: 2.792453190096152
Validation loss: 2.491332901147763

Epoch: 179| Step: 0
Training loss: 2.56767253322031
Validation loss: 2.4837030105740703

Epoch: 6| Step: 1
Training loss: 2.0688147543369975
Validation loss: 2.4830709109659135

Epoch: 6| Step: 2
Training loss: 2.0510051496079336
Validation loss: 2.4892462232162056

Epoch: 6| Step: 3
Training loss: 2.235089594604799
Validation loss: 2.4770725258563906

Epoch: 6| Step: 4
Training loss: 2.39389412946529
Validation loss: 2.4819592901021985

Epoch: 6| Step: 5
Training loss: 2.6831708238884113
Validation loss: 2.4874980817880057

Epoch: 6| Step: 6
Training loss: 3.0040410164116755
Validation loss: 2.4797288086368323

Epoch: 6| Step: 7
Training loss: 2.6472019250373378
Validation loss: 2.4786959182500246

Epoch: 6| Step: 8
Training loss: 2.556991238372794
Validation loss: 2.4799402990641126

Epoch: 6| Step: 9
Training loss: 2.0310661819621374
Validation loss: 2.4847179232150816

Epoch: 6| Step: 10
Training loss: 2.1496001825512154
Validation loss: 2.4805113781247257

Epoch: 6| Step: 11
Training loss: 2.523973437579076
Validation loss: 2.478212114032011

Epoch: 6| Step: 12
Training loss: 2.569968528109563
Validation loss: 2.478054732248069

Epoch: 6| Step: 13
Training loss: 2.5854248276263303
Validation loss: 2.4865985412657605

Epoch: 180| Step: 0
Training loss: 2.482275405512502
Validation loss: 2.4922080921051823

Epoch: 6| Step: 1
Training loss: 2.3411441812873646
Validation loss: 2.49279068331118

Epoch: 6| Step: 2
Training loss: 2.611515104094942
Validation loss: 2.5077852542779646

Epoch: 6| Step: 3
Training loss: 2.9593158397783412
Validation loss: 2.514350244316625

Epoch: 6| Step: 4
Training loss: 2.105936936110797
Validation loss: 2.508384092795305

Epoch: 6| Step: 5
Training loss: 2.9243326713758093
Validation loss: 2.5181574898387473

Epoch: 6| Step: 6
Training loss: 2.3713202831769675
Validation loss: 2.5358440012921064

Epoch: 6| Step: 7
Training loss: 2.362909360266793
Validation loss: 2.5500344803916115

Epoch: 6| Step: 8
Training loss: 2.1013155086547193
Validation loss: 2.530568309716435

Epoch: 6| Step: 9
Training loss: 2.533391917538445
Validation loss: 2.545399415850718

Epoch: 6| Step: 10
Training loss: 2.295258868209581
Validation loss: 2.515215704182564

Epoch: 6| Step: 11
Training loss: 1.4646441921361328
Validation loss: 2.4939820576017024

Epoch: 6| Step: 12
Training loss: 2.466197178812001
Validation loss: 2.4803191372663758

Epoch: 6| Step: 13
Training loss: 2.5733707866347926
Validation loss: 2.475669691887363

Epoch: 181| Step: 0
Training loss: 3.0911302359920487
Validation loss: 2.476168724547905

Epoch: 6| Step: 1
Training loss: 2.265825565273844
Validation loss: 2.4807896764405952

Epoch: 6| Step: 2
Training loss: 2.218745594288925
Validation loss: 2.4737226407396817

Epoch: 6| Step: 3
Training loss: 2.776579203042885
Validation loss: 2.475520174355596

Epoch: 6| Step: 4
Training loss: 3.127453108206542
Validation loss: 2.467750346925263

Epoch: 6| Step: 5
Training loss: 2.199938153351261
Validation loss: 2.4763301495683803

Epoch: 6| Step: 6
Training loss: 2.478901044790223
Validation loss: 2.4721473302701127

Epoch: 6| Step: 7
Training loss: 2.402370843501946
Validation loss: 2.4814328860537604

Epoch: 6| Step: 8
Training loss: 2.2765752892799327
Validation loss: 2.47426141321282

Epoch: 6| Step: 9
Training loss: 2.1213479917120903
Validation loss: 2.476009110517693

Epoch: 6| Step: 10
Training loss: 2.041525336323931
Validation loss: 2.4711894284255322

Epoch: 6| Step: 11
Training loss: 2.1634690335135764
Validation loss: 2.469310568089042

Epoch: 6| Step: 12
Training loss: 2.2165064684504348
Validation loss: 2.4651106071804456

Epoch: 6| Step: 13
Training loss: 2.962092594510197
Validation loss: 2.480653883065133

Epoch: 182| Step: 0
Training loss: 2.5502519744844463
Validation loss: 2.502397944871574

Epoch: 6| Step: 1
Training loss: 2.3379654772765597
Validation loss: 2.5037040291557546

Epoch: 6| Step: 2
Training loss: 2.8460238242636633
Validation loss: 2.5227583531280566

Epoch: 6| Step: 3
Training loss: 2.8223628571864627
Validation loss: 2.5393830082415247

Epoch: 6| Step: 4
Training loss: 2.244081873245026
Validation loss: 2.5675946817270985

Epoch: 6| Step: 5
Training loss: 2.4322911874469773
Validation loss: 2.55504290707089

Epoch: 6| Step: 6
Training loss: 1.8968637481808222
Validation loss: 2.514852029897982

Epoch: 6| Step: 7
Training loss: 2.792541556599814
Validation loss: 2.4989744944100885

Epoch: 6| Step: 8
Training loss: 1.840045375264487
Validation loss: 2.493928132032991

Epoch: 6| Step: 9
Training loss: 1.9420176105663296
Validation loss: 2.4879942628174896

Epoch: 6| Step: 10
Training loss: 2.8016913516810216
Validation loss: 2.4911679820334185

Epoch: 6| Step: 11
Training loss: 2.702414005686376
Validation loss: 2.4922909132210607

Epoch: 6| Step: 12
Training loss: 2.4039483890801066
Validation loss: 2.48904337008577

Epoch: 6| Step: 13
Training loss: 2.3011230836564294
Validation loss: 2.4841280800493766

Epoch: 183| Step: 0
Training loss: 2.77175671863748
Validation loss: 2.4853088575090485

Epoch: 6| Step: 1
Training loss: 2.0900137288495944
Validation loss: 2.487557474108161

Epoch: 6| Step: 2
Training loss: 2.5697076427844405
Validation loss: 2.4819967694759733

Epoch: 6| Step: 3
Training loss: 2.3174414548917057
Validation loss: 2.486936372452017

Epoch: 6| Step: 4
Training loss: 2.0348549178610162
Validation loss: 2.4810681036986546

Epoch: 6| Step: 5
Training loss: 2.5982725860691667
Validation loss: 2.4939838739545266

Epoch: 6| Step: 6
Training loss: 2.9387000047462326
Validation loss: 2.4721738677231038

Epoch: 6| Step: 7
Training loss: 2.511553009877223
Validation loss: 2.5211350336626195

Epoch: 6| Step: 8
Training loss: 2.179685093594662
Validation loss: 2.516919910455552

Epoch: 6| Step: 9
Training loss: 2.55149459795237
Validation loss: 2.533701710102025

Epoch: 6| Step: 10
Training loss: 2.6119528275008337
Validation loss: 2.5336246576030588

Epoch: 6| Step: 11
Training loss: 1.7838963710126794
Validation loss: 2.5104194947117326

Epoch: 6| Step: 12
Training loss: 2.5533347558431756
Validation loss: 2.5161585271651075

Epoch: 6| Step: 13
Training loss: 2.7651750446393693
Validation loss: 2.5154021739010375

Epoch: 184| Step: 0
Training loss: 2.4072500355409825
Validation loss: 2.5087767081366694

Epoch: 6| Step: 1
Training loss: 2.160189250673275
Validation loss: 2.4990689769281076

Epoch: 6| Step: 2
Training loss: 2.4766295029875502
Validation loss: 2.4921253001264922

Epoch: 6| Step: 3
Training loss: 2.985598647824029
Validation loss: 2.4899486023731745

Epoch: 6| Step: 4
Training loss: 2.5139542238047983
Validation loss: 2.479830906676708

Epoch: 6| Step: 5
Training loss: 2.887201539835489
Validation loss: 2.4749738569837647

Epoch: 6| Step: 6
Training loss: 2.3780215267172755
Validation loss: 2.4738457637406803

Epoch: 6| Step: 7
Training loss: 1.8700121339618496
Validation loss: 2.478567793717696

Epoch: 6| Step: 8
Training loss: 2.3543888988646646
Validation loss: 2.4846609818704253

Epoch: 6| Step: 9
Training loss: 2.3204311764355294
Validation loss: 2.4886336383986762

Epoch: 6| Step: 10
Training loss: 2.579193263823182
Validation loss: 2.480942648325592

Epoch: 6| Step: 11
Training loss: 2.1614732366454077
Validation loss: 2.4998852703471575

Epoch: 6| Step: 12
Training loss: 2.4993996853097085
Validation loss: 2.5302218951294626

Epoch: 6| Step: 13
Training loss: 2.6385170914481515
Validation loss: 2.521929980517338

Epoch: 185| Step: 0
Training loss: 2.6957952536989382
Validation loss: 2.5246024262564175

Epoch: 6| Step: 1
Training loss: 2.603574507463127
Validation loss: 2.5206925271382556

Epoch: 6| Step: 2
Training loss: 2.1715939566364613
Validation loss: 2.5101092666105793

Epoch: 6| Step: 3
Training loss: 3.4566232214183588
Validation loss: 2.4957679293113095

Epoch: 6| Step: 4
Training loss: 2.2926902796860493
Validation loss: 2.4823906449085005

Epoch: 6| Step: 5
Training loss: 2.488067953169166
Validation loss: 2.483781323784953

Epoch: 6| Step: 6
Training loss: 2.267574760441087
Validation loss: 2.4827613868517555

Epoch: 6| Step: 7
Training loss: 2.097810139330123
Validation loss: 2.487366688413265

Epoch: 6| Step: 8
Training loss: 1.6190091253427559
Validation loss: 2.4801176047896694

Epoch: 6| Step: 9
Training loss: 3.127239492957563
Validation loss: 2.4841878328655453

Epoch: 6| Step: 10
Training loss: 2.4449402157079896
Validation loss: 2.4795756256499955

Epoch: 6| Step: 11
Training loss: 2.5968194287685624
Validation loss: 2.4980516789091647

Epoch: 6| Step: 12
Training loss: 2.209584499500055
Validation loss: 2.505315232458025

Epoch: 6| Step: 13
Training loss: 1.76406568690807
Validation loss: 2.514132750141946

Epoch: 186| Step: 0
Training loss: 2.294325471040547
Validation loss: 2.513218093535464

Epoch: 6| Step: 1
Training loss: 2.2611585064835396
Validation loss: 2.495175347393753

Epoch: 6| Step: 2
Training loss: 2.633732484995534
Validation loss: 2.505422544672842

Epoch: 6| Step: 3
Training loss: 1.738793321257674
Validation loss: 2.4999159321955298

Epoch: 6| Step: 4
Training loss: 2.6119353929973808
Validation loss: 2.495073455208318

Epoch: 6| Step: 5
Training loss: 2.4311021813808438
Validation loss: 2.4898343352088044

Epoch: 6| Step: 6
Training loss: 2.6152912615172252
Validation loss: 2.5016146611325807

Epoch: 6| Step: 7
Training loss: 2.8631050503212077
Validation loss: 2.4787410295907337

Epoch: 6| Step: 8
Training loss: 1.822737948421641
Validation loss: 2.485648766355179

Epoch: 6| Step: 9
Training loss: 2.3525710873702352
Validation loss: 2.488344296505542

Epoch: 6| Step: 10
Training loss: 2.2205970490551548
Validation loss: 2.4744576254835566

Epoch: 6| Step: 11
Training loss: 2.4026019694176783
Validation loss: 2.4843119327369503

Epoch: 6| Step: 12
Training loss: 2.864608561086829
Validation loss: 2.493980440409259

Epoch: 6| Step: 13
Training loss: 2.6693799599771366
Validation loss: 2.4879598125480986

Epoch: 187| Step: 0
Training loss: 1.884781816640295
Validation loss: 2.4945996369193937

Epoch: 6| Step: 1
Training loss: 2.0579782104969846
Validation loss: 2.51450921818299

Epoch: 6| Step: 2
Training loss: 2.9377668543599866
Validation loss: 2.5299788057748795

Epoch: 6| Step: 3
Training loss: 2.0890120232703113
Validation loss: 2.5386755232699896

Epoch: 6| Step: 4
Training loss: 2.6501690540731992
Validation loss: 2.558420966528944

Epoch: 6| Step: 5
Training loss: 2.546026263962312
Validation loss: 2.5731352482868752

Epoch: 6| Step: 6
Training loss: 2.118823330940845
Validation loss: 2.554815882141063

Epoch: 6| Step: 7
Training loss: 3.0944156123366104
Validation loss: 2.538796028434933

Epoch: 6| Step: 8
Training loss: 1.7547122318362594
Validation loss: 2.532480419619232

Epoch: 6| Step: 9
Training loss: 2.957242486985309
Validation loss: 2.5301772305076855

Epoch: 6| Step: 10
Training loss: 1.9101901997238635
Validation loss: 2.5020163828595234

Epoch: 6| Step: 11
Training loss: 3.371618484200567
Validation loss: 2.490845417526437

Epoch: 6| Step: 12
Training loss: 2.2994090523548154
Validation loss: 2.4919319300817526

Epoch: 6| Step: 13
Training loss: 1.8030762188162195
Validation loss: 2.4786571705759224

Epoch: 188| Step: 0
Training loss: 2.430768425717541
Validation loss: 2.473973546566951

Epoch: 6| Step: 1
Training loss: 2.368404969222131
Validation loss: 2.483241040373044

Epoch: 6| Step: 2
Training loss: 2.105436476989148
Validation loss: 2.4708311990103637

Epoch: 6| Step: 3
Training loss: 2.099379075305614
Validation loss: 2.4818502829057474

Epoch: 6| Step: 4
Training loss: 2.488736528698316
Validation loss: 2.477913160277249

Epoch: 6| Step: 5
Training loss: 2.769483557802956
Validation loss: 2.4757360449231403

Epoch: 6| Step: 6
Training loss: 2.7842247302674425
Validation loss: 2.481553528843188

Epoch: 6| Step: 7
Training loss: 2.3794421765218696
Validation loss: 2.4760604012475587

Epoch: 6| Step: 8
Training loss: 3.0222324858129666
Validation loss: 2.47521512416369

Epoch: 6| Step: 9
Training loss: 3.199909959956851
Validation loss: 2.483763109584359

Epoch: 6| Step: 10
Training loss: 2.853675205956576
Validation loss: 2.488695781838228

Epoch: 6| Step: 11
Training loss: 2.180007090775743
Validation loss: 2.4845049442240272

Epoch: 6| Step: 12
Training loss: 1.391072404876148
Validation loss: 2.4891444395299147

Epoch: 6| Step: 13
Training loss: 2.319264698741472
Validation loss: 2.498588489377996

Epoch: 189| Step: 0
Training loss: 1.9714153352533974
Validation loss: 2.4960444788281095

Epoch: 6| Step: 1
Training loss: 2.5361224715206
Validation loss: 2.5213279764262073

Epoch: 6| Step: 2
Training loss: 1.6500997975542049
Validation loss: 2.5081566943794367

Epoch: 6| Step: 3
Training loss: 2.629634489906647
Validation loss: 2.52914685132111

Epoch: 6| Step: 4
Training loss: 3.118131489856884
Validation loss: 2.5326780835394986

Epoch: 6| Step: 5
Training loss: 2.3638571297643485
Validation loss: 2.531478902882691

Epoch: 6| Step: 6
Training loss: 2.5588746826624873
Validation loss: 2.545179617987982

Epoch: 6| Step: 7
Training loss: 2.983094584823276
Validation loss: 2.5202629663117273

Epoch: 6| Step: 8
Training loss: 2.156298208388853
Validation loss: 2.5050444413872976

Epoch: 6| Step: 9
Training loss: 2.6550110564208196
Validation loss: 2.4980110521807584

Epoch: 6| Step: 10
Training loss: 2.480606868232631
Validation loss: 2.482148474307629

Epoch: 6| Step: 11
Training loss: 2.150885501639292
Validation loss: 2.477532999875564

Epoch: 6| Step: 12
Training loss: 2.39846851440656
Validation loss: 2.4811897571594805

Epoch: 6| Step: 13
Training loss: 2.3425794603026877
Validation loss: 2.4775990463972697

Epoch: 190| Step: 0
Training loss: 2.365577679139385
Validation loss: 2.4767539093786604

Epoch: 6| Step: 1
Training loss: 2.348342059055828
Validation loss: 2.472872242023695

Epoch: 6| Step: 2
Training loss: 2.680204736376317
Validation loss: 2.480891923025695

Epoch: 6| Step: 3
Training loss: 2.6174547656795175
Validation loss: 2.477345500276962

Epoch: 6| Step: 4
Training loss: 2.14581104995367
Validation loss: 2.476287280974618

Epoch: 6| Step: 5
Training loss: 2.0409275455725653
Validation loss: 2.4842783591229645

Epoch: 6| Step: 6
Training loss: 2.7321492755148444
Validation loss: 2.481486754888917

Epoch: 6| Step: 7
Training loss: 2.491808823662859
Validation loss: 2.469174473321345

Epoch: 6| Step: 8
Training loss: 2.5474351138311038
Validation loss: 2.4738862974152966

Epoch: 6| Step: 9
Training loss: 2.0391214296441458
Validation loss: 2.49990357371972

Epoch: 6| Step: 10
Training loss: 2.2168839895465684
Validation loss: 2.4937873735551253

Epoch: 6| Step: 11
Training loss: 2.5858970247080215
Validation loss: 2.484807054869615

Epoch: 6| Step: 12
Training loss: 2.940439093101862
Validation loss: 2.488959762391043

Epoch: 6| Step: 13
Training loss: 2.536160826941443
Validation loss: 2.5002606097126177

Epoch: 191| Step: 0
Training loss: 2.4575866168601497
Validation loss: 2.4903864396483906

Epoch: 6| Step: 1
Training loss: 2.9126961703399292
Validation loss: 2.4989209548510227

Epoch: 6| Step: 2
Training loss: 2.2978489685692436
Validation loss: 2.4996074845214027

Epoch: 6| Step: 3
Training loss: 2.1385068786239327
Validation loss: 2.4878885786747174

Epoch: 6| Step: 4
Training loss: 2.395174571705134
Validation loss: 2.5054925187699

Epoch: 6| Step: 5
Training loss: 2.5352811385840734
Validation loss: 2.4808371202770783

Epoch: 6| Step: 6
Training loss: 2.525228425826087
Validation loss: 2.477014686867421

Epoch: 6| Step: 7
Training loss: 2.3575601229075325
Validation loss: 2.481791786727167

Epoch: 6| Step: 8
Training loss: 2.525142318189574
Validation loss: 2.485981283995132

Epoch: 6| Step: 9
Training loss: 2.483159373631406
Validation loss: 2.4737484705738586

Epoch: 6| Step: 10
Training loss: 2.6193439765973494
Validation loss: 2.4820615365343155

Epoch: 6| Step: 11
Training loss: 2.2764415491527528
Validation loss: 2.4827529282302137

Epoch: 6| Step: 12
Training loss: 2.459329230962351
Validation loss: 2.4810620657135383

Epoch: 6| Step: 13
Training loss: 1.9581928879177106
Validation loss: 2.468422719129884

Epoch: 192| Step: 0
Training loss: 2.581172182697419
Validation loss: 2.480368112039405

Epoch: 6| Step: 1
Training loss: 2.7717684169435093
Validation loss: 2.4629194563998995

Epoch: 6| Step: 2
Training loss: 2.7153939766721447
Validation loss: 2.463402828204998

Epoch: 6| Step: 3
Training loss: 2.851079194380934
Validation loss: 2.477251336122284

Epoch: 6| Step: 4
Training loss: 2.2970877827804745
Validation loss: 2.4768443784538277

Epoch: 6| Step: 5
Training loss: 3.2882151474928114
Validation loss: 2.499475662558605

Epoch: 6| Step: 6
Training loss: 1.983854210465413
Validation loss: 2.5009026646200865

Epoch: 6| Step: 7
Training loss: 2.062122426007076
Validation loss: 2.531899467004136

Epoch: 6| Step: 8
Training loss: 2.618078188428741
Validation loss: 2.533958006897512

Epoch: 6| Step: 9
Training loss: 1.942232750436854
Validation loss: 2.526509307886459

Epoch: 6| Step: 10
Training loss: 2.3161839190309013
Validation loss: 2.5200922851467418

Epoch: 6| Step: 11
Training loss: 2.217862986172354
Validation loss: 2.5032238201394175

Epoch: 6| Step: 12
Training loss: 2.207656420720453
Validation loss: 2.500638522621896

Epoch: 6| Step: 13
Training loss: 1.8301753748048613
Validation loss: 2.4821889284307415

Epoch: 193| Step: 0
Training loss: 2.667306306737185
Validation loss: 2.4821012156287776

Epoch: 6| Step: 1
Training loss: 2.1501404827264157
Validation loss: 2.481872697936564

Epoch: 6| Step: 2
Training loss: 2.7114336510696386
Validation loss: 2.472237678603338

Epoch: 6| Step: 3
Training loss: 3.045229423411467
Validation loss: 2.472991101098931

Epoch: 6| Step: 4
Training loss: 2.2096080220101024
Validation loss: 2.4850870227735378

Epoch: 6| Step: 5
Training loss: 2.2642423422752262
Validation loss: 2.4814763142904672

Epoch: 6| Step: 6
Training loss: 2.6367851192457232
Validation loss: 2.48483687931686

Epoch: 6| Step: 7
Training loss: 2.1510029959416155
Validation loss: 2.4974141814691864

Epoch: 6| Step: 8
Training loss: 1.9650738621193338
Validation loss: 2.4870826313539514

Epoch: 6| Step: 9
Training loss: 2.396373345151082
Validation loss: 2.46596787215768

Epoch: 6| Step: 10
Training loss: 2.998504265801743
Validation loss: 2.4952061785948505

Epoch: 6| Step: 11
Training loss: 2.222594034031475
Validation loss: 2.496641430296465

Epoch: 6| Step: 12
Training loss: 1.7410226528615587
Validation loss: 2.50548114731912

Epoch: 6| Step: 13
Training loss: 2.2746507481371676
Validation loss: 2.500245590862644

Epoch: 194| Step: 0
Training loss: 2.9190805709503302
Validation loss: 2.520649427741237

Epoch: 6| Step: 1
Training loss: 1.8242457385792987
Validation loss: 2.541928564451026

Epoch: 6| Step: 2
Training loss: 2.227870195754425
Validation loss: 2.5771016565615645

Epoch: 6| Step: 3
Training loss: 2.337808835440146
Validation loss: 2.571813483292411

Epoch: 6| Step: 4
Training loss: 2.7088303525631288
Validation loss: 2.570839415305521

Epoch: 6| Step: 5
Training loss: 1.650383112963673
Validation loss: 2.5604778778068042

Epoch: 6| Step: 6
Training loss: 1.9969259718238381
Validation loss: 2.5373237172798335

Epoch: 6| Step: 7
Training loss: 2.70799724743251
Validation loss: 2.522730079595164

Epoch: 6| Step: 8
Training loss: 2.9355093521491593
Validation loss: 2.5005167268161683

Epoch: 6| Step: 9
Training loss: 2.4351282563006387
Validation loss: 2.4893896168528604

Epoch: 6| Step: 10
Training loss: 2.9049445060642705
Validation loss: 2.4861824130791623

Epoch: 6| Step: 11
Training loss: 2.4474458498707006
Validation loss: 2.492664287564303

Epoch: 6| Step: 12
Training loss: 2.401616080883303
Validation loss: 2.482761602918343

Epoch: 6| Step: 13
Training loss: 2.152821122693643
Validation loss: 2.4752562855795244

Epoch: 195| Step: 0
Training loss: 2.512679561442567
Validation loss: 2.480726093549558

Epoch: 6| Step: 1
Training loss: 2.0743838027257016
Validation loss: 2.4802634887672017

Epoch: 6| Step: 2
Training loss: 2.8492030585494703
Validation loss: 2.4863651709382517

Epoch: 6| Step: 3
Training loss: 1.8629807843759691
Validation loss: 2.4855975615761703

Epoch: 6| Step: 4
Training loss: 2.236498164080031
Validation loss: 2.482104561547223

Epoch: 6| Step: 5
Training loss: 3.233852768169307
Validation loss: 2.487729756528967

Epoch: 6| Step: 6
Training loss: 2.052086638110706
Validation loss: 2.499603001544241

Epoch: 6| Step: 7
Training loss: 1.7084806735380496
Validation loss: 2.49753972428926

Epoch: 6| Step: 8
Training loss: 2.1945882125094336
Validation loss: 2.522938177981495

Epoch: 6| Step: 9
Training loss: 2.5011397624661362
Validation loss: 2.5235032032698808

Epoch: 6| Step: 10
Training loss: 2.861285629217281
Validation loss: 2.506676572106283

Epoch: 6| Step: 11
Training loss: 2.419670036456861
Validation loss: 2.5129721417758275

Epoch: 6| Step: 12
Training loss: 2.3444890192303105
Validation loss: 2.5115409697190105

Epoch: 6| Step: 13
Training loss: 2.9620591105165905
Validation loss: 2.5044534911436376

Epoch: 196| Step: 0
Training loss: 2.6555032914718946
Validation loss: 2.506936876092431

Epoch: 6| Step: 1
Training loss: 2.2540160471388124
Validation loss: 2.495906243721408

Epoch: 6| Step: 2
Training loss: 2.5815215884629823
Validation loss: 2.490914078245294

Epoch: 6| Step: 3
Training loss: 2.03758870499247
Validation loss: 2.4955663785570485

Epoch: 6| Step: 4
Training loss: 2.3575001524260744
Validation loss: 2.4910221065672005

Epoch: 6| Step: 5
Training loss: 2.197915377021399
Validation loss: 2.4893863445754243

Epoch: 6| Step: 6
Training loss: 2.001310872588323
Validation loss: 2.4848333771617117

Epoch: 6| Step: 7
Training loss: 1.885661016265044
Validation loss: 2.49328955635698

Epoch: 6| Step: 8
Training loss: 2.3893179717606072
Validation loss: 2.4823402373353343

Epoch: 6| Step: 9
Training loss: 2.6370737246585785
Validation loss: 2.500520254679473

Epoch: 6| Step: 10
Training loss: 2.1422059840901118
Validation loss: 2.508546002984104

Epoch: 6| Step: 11
Training loss: 3.3467020568901518
Validation loss: 2.5347060483187125

Epoch: 6| Step: 12
Training loss: 2.2075678620324486
Validation loss: 2.536780794444426

Epoch: 6| Step: 13
Training loss: 2.8531733731266913
Validation loss: 2.52065518172677

Epoch: 197| Step: 0
Training loss: 2.6940878034526645
Validation loss: 2.5200907872008216

Epoch: 6| Step: 1
Training loss: 2.356282613918125
Validation loss: 2.495939995254308

Epoch: 6| Step: 2
Training loss: 2.704790076608628
Validation loss: 2.499532783083207

Epoch: 6| Step: 3
Training loss: 2.797199081313393
Validation loss: 2.510373330170912

Epoch: 6| Step: 4
Training loss: 2.4641663698160325
Validation loss: 2.5076530619768644

Epoch: 6| Step: 5
Training loss: 2.7044884214514835
Validation loss: 2.513574874496261

Epoch: 6| Step: 6
Training loss: 1.9516795188204823
Validation loss: 2.5001505329588105

Epoch: 6| Step: 7
Training loss: 2.4709157980355068
Validation loss: 2.4939491001279337

Epoch: 6| Step: 8
Training loss: 2.7205388991062587
Validation loss: 2.492350398592423

Epoch: 6| Step: 9
Training loss: 2.2186487738930136
Validation loss: 2.4837626536276898

Epoch: 6| Step: 10
Training loss: 2.5757146491759317
Validation loss: 2.4990712188966757

Epoch: 6| Step: 11
Training loss: 1.7627065388752614
Validation loss: 2.4761956521825526

Epoch: 6| Step: 12
Training loss: 1.8374085721476285
Validation loss: 2.490512663805924

Epoch: 6| Step: 13
Training loss: 2.133969841812813
Validation loss: 2.4900183729849736

Epoch: 198| Step: 0
Training loss: 2.1161244105810812
Validation loss: 2.487229089345686

Epoch: 6| Step: 1
Training loss: 3.076830286680939
Validation loss: 2.483591311984462

Epoch: 6| Step: 2
Training loss: 2.4878929709568545
Validation loss: 2.501474684651795

Epoch: 6| Step: 3
Training loss: 2.4733261960518704
Validation loss: 2.4950379082215006

Epoch: 6| Step: 4
Training loss: 2.265036460465113
Validation loss: 2.511788896735049

Epoch: 6| Step: 5
Training loss: 2.4247869889607823
Validation loss: 2.509309664422409

Epoch: 6| Step: 6
Training loss: 2.4137723186612794
Validation loss: 2.522069522835189

Epoch: 6| Step: 7
Training loss: 2.404346257933651
Validation loss: 2.524775383655948

Epoch: 6| Step: 8
Training loss: 2.348068125007819
Validation loss: 2.5266184721789906

Epoch: 6| Step: 9
Training loss: 2.5695127037077246
Validation loss: 2.494092111855054

Epoch: 6| Step: 10
Training loss: 2.4586096031858506
Validation loss: 2.5070105644047103

Epoch: 6| Step: 11
Training loss: 2.0024265827336296
Validation loss: 2.5027762415725148

Epoch: 6| Step: 12
Training loss: 1.8803480806133628
Validation loss: 2.5027217354417353

Epoch: 6| Step: 13
Training loss: 2.733999956841179
Validation loss: 2.4988966732413695

Epoch: 199| Step: 0
Training loss: 1.8179439475773733
Validation loss: 2.493977580445671

Epoch: 6| Step: 1
Training loss: 2.2235647265666008
Validation loss: 2.489483952367571

Epoch: 6| Step: 2
Training loss: 2.9014902823832873
Validation loss: 2.4831188393026813

Epoch: 6| Step: 3
Training loss: 2.2236473944131014
Validation loss: 2.4803663978585777

Epoch: 6| Step: 4
Training loss: 2.401745034641642
Validation loss: 2.4950861163111453

Epoch: 6| Step: 5
Training loss: 2.623325358681229
Validation loss: 2.492888604125776

Epoch: 6| Step: 6
Training loss: 2.011134149736736
Validation loss: 2.484815978253827

Epoch: 6| Step: 7
Training loss: 2.2209895476842867
Validation loss: 2.483169807153357

Epoch: 6| Step: 8
Training loss: 2.5475199064276257
Validation loss: 2.489942202912225

Epoch: 6| Step: 9
Training loss: 2.6336569860805357
Validation loss: 2.5102851854349444

Epoch: 6| Step: 10
Training loss: 2.9681339628622867
Validation loss: 2.5437867176801956

Epoch: 6| Step: 11
Training loss: 2.198805233173274
Validation loss: 2.5258014577853087

Epoch: 6| Step: 12
Training loss: 1.9739928297049827
Validation loss: 2.5133594080620534

Epoch: 6| Step: 13
Training loss: 2.7049485599047824
Validation loss: 2.51323855285456

Epoch: 200| Step: 0
Training loss: 2.79600690444072
Validation loss: 2.51671005131629

Epoch: 6| Step: 1
Training loss: 2.1514821067312453
Validation loss: 2.5083599819994062

Epoch: 6| Step: 2
Training loss: 2.719541763245892
Validation loss: 2.4934497534589495

Epoch: 6| Step: 3
Training loss: 2.3470233692554703
Validation loss: 2.510076180526704

Epoch: 6| Step: 4
Training loss: 2.414079487071099
Validation loss: 2.514362800449073

Epoch: 6| Step: 5
Training loss: 1.8245610114131279
Validation loss: 2.503443309659895

Epoch: 6| Step: 6
Training loss: 1.5999534898196828
Validation loss: 2.4904076928554706

Epoch: 6| Step: 7
Training loss: 3.1034378800638236
Validation loss: 2.503744880923699

Epoch: 6| Step: 8
Training loss: 2.591940374936615
Validation loss: 2.4970388677788096

Epoch: 6| Step: 9
Training loss: 2.166358693560755
Validation loss: 2.508077035105144

Epoch: 6| Step: 10
Training loss: 2.412088420329021
Validation loss: 2.504286468885682

Epoch: 6| Step: 11
Training loss: 2.4813012836066637
Validation loss: 2.526573492217741

Epoch: 6| Step: 12
Training loss: 2.4029010405433953
Validation loss: 2.5123657848638907

Epoch: 6| Step: 13
Training loss: 2.4055279726008867
Validation loss: 2.5178262466472674

Testing loss: 1.990867554800409
