Epoch: 1| Step: 0
Training loss: 5.942508552618937
Validation loss: 5.809461134668351

Epoch: 6| Step: 1
Training loss: 5.956361386517517
Validation loss: 5.799984735250276

Epoch: 6| Step: 2
Training loss: 7.272299836342556
Validation loss: 5.7899762591435415

Epoch: 6| Step: 3
Training loss: 6.368030403371337
Validation loss: 5.780372119734631

Epoch: 6| Step: 4
Training loss: 6.59579363787095
Validation loss: 5.770242134405533

Epoch: 6| Step: 5
Training loss: 6.816085291960143
Validation loss: 5.7598914500915575

Epoch: 6| Step: 6
Training loss: 5.32013521725326
Validation loss: 5.748714331821774

Epoch: 6| Step: 7
Training loss: 5.316574867596045
Validation loss: 5.737073988905871

Epoch: 6| Step: 8
Training loss: 5.363412120581012
Validation loss: 5.724837843353883

Epoch: 6| Step: 9
Training loss: 4.940997852441552
Validation loss: 5.711455370813947

Epoch: 6| Step: 10
Training loss: 4.823629218153953
Validation loss: 5.697229896684329

Epoch: 6| Step: 11
Training loss: 4.084692333126061
Validation loss: 5.682007313672714

Epoch: 6| Step: 12
Training loss: 5.432216840053726
Validation loss: 5.665788053383678

Epoch: 6| Step: 13
Training loss: 5.962016036827532
Validation loss: 5.648718044702

Epoch: 2| Step: 0
Training loss: 5.430238281417193
Validation loss: 5.629668122029958

Epoch: 6| Step: 1
Training loss: 5.727165991819302
Validation loss: 5.610353287022637

Epoch: 6| Step: 2
Training loss: 5.979890183681195
Validation loss: 5.589226388663466

Epoch: 6| Step: 3
Training loss: 5.551593847210436
Validation loss: 5.567107768589544

Epoch: 6| Step: 4
Training loss: 4.673670190995425
Validation loss: 5.5429414215451365

Epoch: 6| Step: 5
Training loss: 5.282583937260176
Validation loss: 5.518743333094914

Epoch: 6| Step: 6
Training loss: 5.713903155463831
Validation loss: 5.4917918957118586

Epoch: 6| Step: 7
Training loss: 5.5188402524936295
Validation loss: 5.465066854703374

Epoch: 6| Step: 8
Training loss: 5.754573495871329
Validation loss: 5.437485486120708

Epoch: 6| Step: 9
Training loss: 5.218986460188497
Validation loss: 5.407829187274544

Epoch: 6| Step: 10
Training loss: 5.1828419557734335
Validation loss: 5.378868584331167

Epoch: 6| Step: 11
Training loss: 5.36679799805742
Validation loss: 5.346725954507493

Epoch: 6| Step: 12
Training loss: 6.067462581083757
Validation loss: 5.315873157929405

Epoch: 6| Step: 13
Training loss: 5.711505574623479
Validation loss: 5.283943376342124

Epoch: 3| Step: 0
Training loss: 4.669933311100594
Validation loss: 5.250589666735227

Epoch: 6| Step: 1
Training loss: 6.0677134326918845
Validation loss: 5.21645907147844

Epoch: 6| Step: 2
Training loss: 6.062997070070188
Validation loss: 5.1835040266387375

Epoch: 6| Step: 3
Training loss: 4.694456914299549
Validation loss: 5.147919939440594

Epoch: 6| Step: 4
Training loss: 5.972561083896832
Validation loss: 5.11222456985361

Epoch: 6| Step: 5
Training loss: 5.040876762786178
Validation loss: 5.074948700336872

Epoch: 6| Step: 6
Training loss: 3.663770847059513
Validation loss: 5.036572275059409

Epoch: 6| Step: 7
Training loss: 4.933906309687925
Validation loss: 4.998036911867084

Epoch: 6| Step: 8
Training loss: 4.503888886973254
Validation loss: 4.957711659677232

Epoch: 6| Step: 9
Training loss: 5.082189816956003
Validation loss: 4.915988371988376

Epoch: 6| Step: 10
Training loss: 4.640724874635486
Validation loss: 4.874162844498639

Epoch: 6| Step: 11
Training loss: 5.98538526169845
Validation loss: 4.827999068878291

Epoch: 6| Step: 12
Training loss: 3.90862330246923
Validation loss: 4.784359238334986

Epoch: 6| Step: 13
Training loss: 5.316153313578042
Validation loss: 4.739675069807112

Epoch: 4| Step: 0
Training loss: 4.158170328149783
Validation loss: 4.6972149835441925

Epoch: 6| Step: 1
Training loss: 4.806192401198569
Validation loss: 4.65740913828301

Epoch: 6| Step: 2
Training loss: 3.843272109678575
Validation loss: 4.623142668794926

Epoch: 6| Step: 3
Training loss: 4.494899614377941
Validation loss: 4.592159665363732

Epoch: 6| Step: 4
Training loss: 4.7890804221983165
Validation loss: 4.562288298213678

Epoch: 6| Step: 5
Training loss: 4.865176353277065
Validation loss: 4.5306276294984675

Epoch: 6| Step: 6
Training loss: 4.812643866432195
Validation loss: 4.502503593064273

Epoch: 6| Step: 7
Training loss: 4.2104716140556695
Validation loss: 4.472915239972604

Epoch: 6| Step: 8
Training loss: 5.127894258858045
Validation loss: 4.449839880397982

Epoch: 6| Step: 9
Training loss: 4.638203512539146
Validation loss: 4.4252319499008

Epoch: 6| Step: 10
Training loss: 5.09353094273507
Validation loss: 4.400123168996352

Epoch: 6| Step: 11
Training loss: 4.7026583924862
Validation loss: 4.377913147094979

Epoch: 6| Step: 12
Training loss: 4.594678720028551
Validation loss: 4.35570987972208

Epoch: 6| Step: 13
Training loss: 3.5477347655303566
Validation loss: 4.334787277886183

Epoch: 5| Step: 0
Training loss: 4.296384915233242
Validation loss: 4.315682731069353

Epoch: 6| Step: 1
Training loss: 4.492330797646518
Validation loss: 4.300299887419885

Epoch: 6| Step: 2
Training loss: 4.9894091018912405
Validation loss: 4.282369837402888

Epoch: 6| Step: 3
Training loss: 3.416593752447413
Validation loss: 4.256770131334505

Epoch: 6| Step: 4
Training loss: 4.829243650747108
Validation loss: 4.2334083422745685

Epoch: 6| Step: 5
Training loss: 4.150155554004756
Validation loss: 4.21270548756054

Epoch: 6| Step: 6
Training loss: 3.307738570809341
Validation loss: 4.197125715505637

Epoch: 6| Step: 7
Training loss: 4.0508551742591665
Validation loss: 4.179760272949214

Epoch: 6| Step: 8
Training loss: 4.684403273972377
Validation loss: 4.162409323206272

Epoch: 6| Step: 9
Training loss: 3.56335786897249
Validation loss: 4.147447048254892

Epoch: 6| Step: 10
Training loss: 4.972981120942251
Validation loss: 4.129072580970613

Epoch: 6| Step: 11
Training loss: 4.090603849794921
Validation loss: 4.119228523002075

Epoch: 6| Step: 12
Training loss: 4.754272948316056
Validation loss: 4.103248735068605

Epoch: 6| Step: 13
Training loss: 4.728030142428236
Validation loss: 4.091273710103078

Epoch: 6| Step: 0
Training loss: 4.501567143838719
Validation loss: 4.076640680154638

Epoch: 6| Step: 1
Training loss: 4.062369476569082
Validation loss: 4.0624308388552075

Epoch: 6| Step: 2
Training loss: 3.835261951636537
Validation loss: 4.050540183040352

Epoch: 6| Step: 3
Training loss: 3.9697183944411663
Validation loss: 4.038218189203633

Epoch: 6| Step: 4
Training loss: 4.059192426068942
Validation loss: 4.027151216950896

Epoch: 6| Step: 5
Training loss: 3.7132342810121197
Validation loss: 4.015923203417016

Epoch: 6| Step: 6
Training loss: 4.173457499191599
Validation loss: 4.003941760042015

Epoch: 6| Step: 7
Training loss: 4.3012677297806
Validation loss: 3.994006644190448

Epoch: 6| Step: 8
Training loss: 4.2660676495946435
Validation loss: 3.981201467683306

Epoch: 6| Step: 9
Training loss: 3.4972313420671104
Validation loss: 3.9718828368726644

Epoch: 6| Step: 10
Training loss: 4.1234470102793885
Validation loss: 3.9604970038988583

Epoch: 6| Step: 11
Training loss: 3.923025745098304
Validation loss: 3.951243829641999

Epoch: 6| Step: 12
Training loss: 4.606884920624239
Validation loss: 3.9384737986846554

Epoch: 6| Step: 13
Training loss: 5.377887571193131
Validation loss: 3.929343105139813

Epoch: 7| Step: 0
Training loss: 4.189883791966735
Validation loss: 3.9194186475643753

Epoch: 6| Step: 1
Training loss: 3.426799418429738
Validation loss: 3.9091033607983037

Epoch: 6| Step: 2
Training loss: 4.516309217734689
Validation loss: 3.899595350692474

Epoch: 6| Step: 3
Training loss: 4.129842054842923
Validation loss: 3.8936486801538455

Epoch: 6| Step: 4
Training loss: 3.023248237777798
Validation loss: 3.8809340680399695

Epoch: 6| Step: 5
Training loss: 4.295887004666248
Validation loss: 3.869747453708979

Epoch: 6| Step: 6
Training loss: 3.436523298744314
Validation loss: 3.861980758052746

Epoch: 6| Step: 7
Training loss: 4.800195991965255
Validation loss: 3.849892560410348

Epoch: 6| Step: 8
Training loss: 4.527396411605932
Validation loss: 3.828864384849369

Epoch: 6| Step: 9
Training loss: 4.0484832749305735
Validation loss: 3.807136721141902

Epoch: 6| Step: 10
Training loss: 2.4471939210365417
Validation loss: 3.796939309319671

Epoch: 6| Step: 11
Training loss: 4.23144880585622
Validation loss: 3.788841836024668

Epoch: 6| Step: 12
Training loss: 4.301129596402986
Validation loss: 3.7828623101206196

Epoch: 6| Step: 13
Training loss: 4.280056306700344
Validation loss: 3.7613013687475347

Epoch: 8| Step: 0
Training loss: 3.898161425399687
Validation loss: 3.765513627506404

Epoch: 6| Step: 1
Training loss: 4.371765685061143
Validation loss: 3.7717314453820507

Epoch: 6| Step: 2
Training loss: 4.076250953802882
Validation loss: 3.7415362742472476

Epoch: 6| Step: 3
Training loss: 3.1935248189176435
Validation loss: 3.734939651270774

Epoch: 6| Step: 4
Training loss: 3.0639173380903864
Validation loss: 3.738340411135606

Epoch: 6| Step: 5
Training loss: 3.462460701509415
Validation loss: 3.742696076671965

Epoch: 6| Step: 6
Training loss: 2.256716346625871
Validation loss: 3.745308405743239

Epoch: 6| Step: 7
Training loss: 3.7914882799601526
Validation loss: 3.7375113161910107

Epoch: 6| Step: 8
Training loss: 4.508665007532327
Validation loss: 3.722745713989681

Epoch: 6| Step: 9
Training loss: 3.798774275606446
Validation loss: 3.7112369173473825

Epoch: 6| Step: 10
Training loss: 4.358972455652895
Validation loss: 3.703787719469816

Epoch: 6| Step: 11
Training loss: 4.142666065338389
Validation loss: 3.7007010464520254

Epoch: 6| Step: 12
Training loss: 4.707766450947311
Validation loss: 3.6936963057069554

Epoch: 6| Step: 13
Training loss: 4.68045918975144
Validation loss: 3.685834785003327

Epoch: 9| Step: 0
Training loss: 3.0073749174392885
Validation loss: 3.680235938101171

Epoch: 6| Step: 1
Training loss: 4.06370596958926
Validation loss: 3.6717464091995287

Epoch: 6| Step: 2
Training loss: 3.0650417134618624
Validation loss: 3.662757347747854

Epoch: 6| Step: 3
Training loss: 3.76247568724625
Validation loss: 3.6567109852197177

Epoch: 6| Step: 4
Training loss: 3.944028498130735
Validation loss: 3.6498450156007074

Epoch: 6| Step: 5
Training loss: 3.8109803219649794
Validation loss: 3.6433975793113644

Epoch: 6| Step: 6
Training loss: 3.9270961096814645
Validation loss: 3.6354659187912466

Epoch: 6| Step: 7
Training loss: 4.472167942094183
Validation loss: 3.631204468637907

Epoch: 6| Step: 8
Training loss: 3.1201677727217874
Validation loss: 3.62526596389267

Epoch: 6| Step: 9
Training loss: 3.4480189896965627
Validation loss: 3.6177551579623857

Epoch: 6| Step: 10
Training loss: 4.266320699334535
Validation loss: 3.6116770922104826

Epoch: 6| Step: 11
Training loss: 4.1801675396064795
Validation loss: 3.6063814250265143

Epoch: 6| Step: 12
Training loss: 4.237129469794241
Validation loss: 3.600101055472456

Epoch: 6| Step: 13
Training loss: 3.9516551787103364
Validation loss: 3.592133999842251

Epoch: 10| Step: 0
Training loss: 4.227192435149962
Validation loss: 3.5872459118407614

Epoch: 6| Step: 1
Training loss: 3.1751685871211035
Validation loss: 3.5831908741186913

Epoch: 6| Step: 2
Training loss: 3.3506637826591654
Validation loss: 3.579224557207982

Epoch: 6| Step: 3
Training loss: 4.411116057189509
Validation loss: 3.5759706547272145

Epoch: 6| Step: 4
Training loss: 3.2429824773672062
Validation loss: 3.5721423447533427

Epoch: 6| Step: 5
Training loss: 4.351123287697798
Validation loss: 3.5658899789500014

Epoch: 6| Step: 6
Training loss: 3.7509505020980285
Validation loss: 3.5627108333241178

Epoch: 6| Step: 7
Training loss: 3.664212677242873
Validation loss: 3.558012745109024

Epoch: 6| Step: 8
Training loss: 4.03254335932352
Validation loss: 3.555896416524657

Epoch: 6| Step: 9
Training loss: 2.8805981740697715
Validation loss: 3.550491313048071

Epoch: 6| Step: 10
Training loss: 3.979373200866858
Validation loss: 3.5472094568005144

Epoch: 6| Step: 11
Training loss: 3.4421503689252857
Validation loss: 3.540197593027547

Epoch: 6| Step: 12
Training loss: 3.6212486061143547
Validation loss: 3.536480990799752

Epoch: 6| Step: 13
Training loss: 4.478074169735615
Validation loss: 3.532707953720426

Epoch: 11| Step: 0
Training loss: 3.452674249426993
Validation loss: 3.527652770776854

Epoch: 6| Step: 1
Training loss: 4.2938337070795765
Validation loss: 3.521927897087572

Epoch: 6| Step: 2
Training loss: 3.756556691678619
Validation loss: 3.516802148484166

Epoch: 6| Step: 3
Training loss: 4.6989695291872735
Validation loss: 3.5137707223483736

Epoch: 6| Step: 4
Training loss: 3.3139073962831453
Validation loss: 3.5090272834784697

Epoch: 6| Step: 5
Training loss: 3.6296690764269566
Validation loss: 3.5054752458075296

Epoch: 6| Step: 6
Training loss: 3.735406836805088
Validation loss: 3.49966723974134

Epoch: 6| Step: 7
Training loss: 4.107684233626483
Validation loss: 3.498857919782693

Epoch: 6| Step: 8
Training loss: 3.231947720605268
Validation loss: 3.4946173150704714

Epoch: 6| Step: 9
Training loss: 3.511784604890371
Validation loss: 3.489148846855936

Epoch: 6| Step: 10
Training loss: 4.3747844097969155
Validation loss: 3.4858923139880478

Epoch: 6| Step: 11
Training loss: 3.3790177343421894
Validation loss: 3.483249000634966

Epoch: 6| Step: 12
Training loss: 2.821637040726466
Validation loss: 3.4796214261807052

Epoch: 6| Step: 13
Training loss: 2.8106497718579533
Validation loss: 3.478609997109543

Epoch: 12| Step: 0
Training loss: 2.94449626429161
Validation loss: 3.47403609666965

Epoch: 6| Step: 1
Training loss: 3.430540495790965
Validation loss: 3.4713281940473597

Epoch: 6| Step: 2
Training loss: 4.061168041488317
Validation loss: 3.471469757802153

Epoch: 6| Step: 3
Training loss: 3.7410621942093374
Validation loss: 3.468121822894755

Epoch: 6| Step: 4
Training loss: 3.0485103033416303
Validation loss: 3.4665586257913086

Epoch: 6| Step: 5
Training loss: 3.565874475816937
Validation loss: 3.463571863862394

Epoch: 6| Step: 6
Training loss: 4.5566393692400755
Validation loss: 3.461760887037491

Epoch: 6| Step: 7
Training loss: 4.297397873016171
Validation loss: 3.4579257752118844

Epoch: 6| Step: 8
Training loss: 3.924234356888075
Validation loss: 3.456869018226053

Epoch: 6| Step: 9
Training loss: 3.805624468536014
Validation loss: 3.455366446643791

Epoch: 6| Step: 10
Training loss: 2.9371193172440284
Validation loss: 3.4524164363290923

Epoch: 6| Step: 11
Training loss: 3.6533686051673144
Validation loss: 3.4506166362716253

Epoch: 6| Step: 12
Training loss: 3.357338505409424
Validation loss: 3.449824664639286

Epoch: 6| Step: 13
Training loss: 3.8539187514842594
Validation loss: 3.4453079788743484

Epoch: 13| Step: 0
Training loss: 4.266011314924341
Validation loss: 3.4437820681122253

Epoch: 6| Step: 1
Training loss: 2.3536599775816343
Validation loss: 3.4419379097459384

Epoch: 6| Step: 2
Training loss: 4.119093857161009
Validation loss: 3.4412524269135703

Epoch: 6| Step: 3
Training loss: 2.9719142714672446
Validation loss: 3.437810236112206

Epoch: 6| Step: 4
Training loss: 3.942997319235339
Validation loss: 3.4385018165086123

Epoch: 6| Step: 5
Training loss: 3.567701056628452
Validation loss: 3.4365741918654065

Epoch: 6| Step: 6
Training loss: 3.0346715434537472
Validation loss: 3.433117041349254

Epoch: 6| Step: 7
Training loss: 3.5603209406597727
Validation loss: 3.4322696932628745

Epoch: 6| Step: 8
Training loss: 1.8534621139535947
Validation loss: 3.430705163731426

Epoch: 6| Step: 9
Training loss: 4.385853411143944
Validation loss: 3.4301624550865437

Epoch: 6| Step: 10
Training loss: 3.9271308363141895
Validation loss: 3.428959315306164

Epoch: 6| Step: 11
Training loss: 4.210225627226327
Validation loss: 3.4279320250070735

Epoch: 6| Step: 12
Training loss: 3.5070007336487667
Validation loss: 3.4252216349137425

Epoch: 6| Step: 13
Training loss: 4.91172727763396
Validation loss: 3.423972363937107

Epoch: 14| Step: 0
Training loss: 3.5026163131711243
Validation loss: 3.4206664271307576

Epoch: 6| Step: 1
Training loss: 3.6360827749333473
Validation loss: 3.420432585716875

Epoch: 6| Step: 2
Training loss: 3.685444404378347
Validation loss: 3.4188477472374266

Epoch: 6| Step: 3
Training loss: 3.22608024188981
Validation loss: 3.416943867261073

Epoch: 6| Step: 4
Training loss: 3.142322593907202
Validation loss: 3.414744350839799

Epoch: 6| Step: 5
Training loss: 3.546910222756688
Validation loss: 3.4152778671182724

Epoch: 6| Step: 6
Training loss: 3.996244813631121
Validation loss: 3.412839915463385

Epoch: 6| Step: 7
Training loss: 3.6389871605051436
Validation loss: 3.411063682625742

Epoch: 6| Step: 8
Training loss: 4.112885922583146
Validation loss: 3.4097213916095166

Epoch: 6| Step: 9
Training loss: 3.5890868076934526
Validation loss: 3.4093795207721254

Epoch: 6| Step: 10
Training loss: 3.8402141652386916
Validation loss: 3.4081368001242227

Epoch: 6| Step: 11
Training loss: 4.047102638234456
Validation loss: 3.4070553451767975

Epoch: 6| Step: 12
Training loss: 3.7615274636187497
Validation loss: 3.4040263454316726

Epoch: 6| Step: 13
Training loss: 2.4803425433874735
Validation loss: 3.4035386366153166

Epoch: 15| Step: 0
Training loss: 3.4548713790425745
Validation loss: 3.403280477507977

Epoch: 6| Step: 1
Training loss: 3.1114458252219364
Validation loss: 3.401890174522437

Epoch: 6| Step: 2
Training loss: 3.7365704710593737
Validation loss: 3.402478627012264

Epoch: 6| Step: 3
Training loss: 3.9773902855876138
Validation loss: 3.3987699280780714

Epoch: 6| Step: 4
Training loss: 3.809948426946382
Validation loss: 3.39744629870462

Epoch: 6| Step: 5
Training loss: 4.454137426029976
Validation loss: 3.3962279381835345

Epoch: 6| Step: 6
Training loss: 3.533731854354748
Validation loss: 3.3947477182584507

Epoch: 6| Step: 7
Training loss: 3.501669213210688
Validation loss: 3.394004396198138

Epoch: 6| Step: 8
Training loss: 4.425604767070969
Validation loss: 3.392219969400201

Epoch: 6| Step: 9
Training loss: 2.8314693340706896
Validation loss: 3.3907718247663876

Epoch: 6| Step: 10
Training loss: 3.405674177022315
Validation loss: 3.389961738449153

Epoch: 6| Step: 11
Training loss: 3.999038819224081
Validation loss: 3.3897282761552265

Epoch: 6| Step: 12
Training loss: 2.9775001470788363
Validation loss: 3.3860054391389736

Epoch: 6| Step: 13
Training loss: 2.5646982765831243
Validation loss: 3.384176221191658

Epoch: 16| Step: 0
Training loss: 3.469233573679512
Validation loss: 3.3827630094613674

Epoch: 6| Step: 1
Training loss: 2.842491961545826
Validation loss: 3.381984769046444

Epoch: 6| Step: 2
Training loss: 3.1919446885520104
Validation loss: 3.3801700335735037

Epoch: 6| Step: 3
Training loss: 4.265241333192191
Validation loss: 3.379082963950554

Epoch: 6| Step: 4
Training loss: 4.429088303072217
Validation loss: 3.3774978800984408

Epoch: 6| Step: 5
Training loss: 3.5663253591165285
Validation loss: 3.376639698190019

Epoch: 6| Step: 6
Training loss: 3.1967242044064554
Validation loss: 3.3762416811496587

Epoch: 6| Step: 7
Training loss: 3.6305974955148193
Validation loss: 3.3742805330886814

Epoch: 6| Step: 8
Training loss: 3.7930727157722974
Validation loss: 3.3758211325732135

Epoch: 6| Step: 9
Training loss: 4.053356503453871
Validation loss: 3.3770949448638823

Epoch: 6| Step: 10
Training loss: 4.4716676377390066
Validation loss: 3.36830530712569

Epoch: 6| Step: 11
Training loss: 2.3028840848677996
Validation loss: 3.3687831007585975

Epoch: 6| Step: 12
Training loss: 2.794155908919037
Validation loss: 3.3676272858984957

Epoch: 6| Step: 13
Training loss: 3.8529624638613864
Validation loss: 3.3689351236244938

Epoch: 17| Step: 0
Training loss: 3.814692132809047
Validation loss: 3.3661329781701443

Epoch: 6| Step: 1
Training loss: 4.149165719982151
Validation loss: 3.363453104169292

Epoch: 6| Step: 2
Training loss: 3.7133971084058324
Validation loss: 3.362108382029367

Epoch: 6| Step: 3
Training loss: 3.046307476692678
Validation loss: 3.361149010856605

Epoch: 6| Step: 4
Training loss: 4.236143073845576
Validation loss: 3.3665500080516093

Epoch: 6| Step: 5
Training loss: 3.086335361763364
Validation loss: 3.366296923410621

Epoch: 6| Step: 6
Training loss: 3.26533616536294
Validation loss: 3.3682597545657043

Epoch: 6| Step: 7
Training loss: 3.753099178126916
Validation loss: 3.360701029642076

Epoch: 6| Step: 8
Training loss: 3.4912220006380656
Validation loss: 3.357034337213267

Epoch: 6| Step: 9
Training loss: 3.5893254118610427
Validation loss: 3.3566792971710897

Epoch: 6| Step: 10
Training loss: 3.6838750317198077
Validation loss: 3.3552447383724715

Epoch: 6| Step: 11
Training loss: 3.7092359637304484
Validation loss: 3.3557258324204997

Epoch: 6| Step: 12
Training loss: 3.457250555808712
Validation loss: 3.3533924768260808

Epoch: 6| Step: 13
Training loss: 2.6361382643713998
Validation loss: 3.3517399725688555

Epoch: 18| Step: 0
Training loss: 3.904857295673269
Validation loss: 3.352353033635948

Epoch: 6| Step: 1
Training loss: 2.7472265302853374
Validation loss: 3.357401788357688

Epoch: 6| Step: 2
Training loss: 4.3654912885806825
Validation loss: 3.3642057644267114

Epoch: 6| Step: 3
Training loss: 3.9159797038954123
Validation loss: 3.3574782415723767

Epoch: 6| Step: 4
Training loss: 3.1846772204916247
Validation loss: 3.3497595702759746

Epoch: 6| Step: 5
Training loss: 3.3094376137549317
Validation loss: 3.34702186567482

Epoch: 6| Step: 6
Training loss: 3.77867177283517
Validation loss: 3.3479095767860705

Epoch: 6| Step: 7
Training loss: 3.440018996696361
Validation loss: 3.348528259666459

Epoch: 6| Step: 8
Training loss: 3.7997695501620066
Validation loss: 3.349589495607508

Epoch: 6| Step: 9
Training loss: 3.3222529945380135
Validation loss: 3.347965794152873

Epoch: 6| Step: 10
Training loss: 3.6332083537686812
Validation loss: 3.3454894619904048

Epoch: 6| Step: 11
Training loss: 3.90126146309344
Validation loss: 3.3437626826655604

Epoch: 6| Step: 12
Training loss: 3.7828567495992074
Validation loss: 3.342317967812706

Epoch: 6| Step: 13
Training loss: 1.851714695337067
Validation loss: 3.3426708327329275

Epoch: 19| Step: 0
Training loss: 4.513292389932374
Validation loss: 3.342028421832855

Epoch: 6| Step: 1
Training loss: 3.084378932961968
Validation loss: 3.3430648951350697

Epoch: 6| Step: 2
Training loss: 3.1985069666159434
Validation loss: 3.3428692382708265

Epoch: 6| Step: 3
Training loss: 4.176965929063654
Validation loss: 3.3419040648284923

Epoch: 6| Step: 4
Training loss: 3.5386857596454617
Validation loss: 3.3398137262330105

Epoch: 6| Step: 5
Training loss: 3.764557366562196
Validation loss: 3.340606806848543

Epoch: 6| Step: 6
Training loss: 3.511316261521843
Validation loss: 3.337386245113196

Epoch: 6| Step: 7
Training loss: 3.297482402948332
Validation loss: 3.33692211546397

Epoch: 6| Step: 8
Training loss: 3.58454884753558
Validation loss: 3.335622300490487

Epoch: 6| Step: 9
Training loss: 3.6569691790272145
Validation loss: 3.3358129143928745

Epoch: 6| Step: 10
Training loss: 2.845438194117125
Validation loss: 3.33528764152909

Epoch: 6| Step: 11
Training loss: 3.4612835782104105
Validation loss: 3.333340090057744

Epoch: 6| Step: 12
Training loss: 3.532223862574998
Validation loss: 3.333743290661292

Epoch: 6| Step: 13
Training loss: 3.596022045241898
Validation loss: 3.3336026103455385

Epoch: 20| Step: 0
Training loss: 3.362871488449588
Validation loss: 3.33351327477089

Epoch: 6| Step: 1
Training loss: 3.701919552613676
Validation loss: 3.334140618816766

Epoch: 6| Step: 2
Training loss: 3.7922292159292614
Validation loss: 3.3341087013770694

Epoch: 6| Step: 3
Training loss: 2.870678847040658
Validation loss: 3.333650935844612

Epoch: 6| Step: 4
Training loss: 3.486139372516448
Validation loss: 3.3345590281178707

Epoch: 6| Step: 5
Training loss: 4.436879289224402
Validation loss: 3.3293799172410985

Epoch: 6| Step: 6
Training loss: 3.9199583681970958
Validation loss: 3.326915750251214

Epoch: 6| Step: 7
Training loss: 3.9362729294982186
Validation loss: 3.32569164885495

Epoch: 6| Step: 8
Training loss: 2.807517491436461
Validation loss: 3.326516164228852

Epoch: 6| Step: 9
Training loss: 3.6516937819889814
Validation loss: 3.32614284079255

Epoch: 6| Step: 10
Training loss: 3.632883641356511
Validation loss: 3.3228037161732633

Epoch: 6| Step: 11
Training loss: 3.4041425152361184
Validation loss: 3.321998027652981

Epoch: 6| Step: 12
Training loss: 3.0676944820866376
Validation loss: 3.32162549767523

Epoch: 6| Step: 13
Training loss: 3.4761889996435285
Validation loss: 3.31921955532824

Epoch: 21| Step: 0
Training loss: 4.126111429933341
Validation loss: 3.3255107401945705

Epoch: 6| Step: 1
Training loss: 2.4533179140470223
Validation loss: 3.3199286566307693

Epoch: 6| Step: 2
Training loss: 3.3114733274555763
Validation loss: 3.32243820255057

Epoch: 6| Step: 3
Training loss: 4.021589665935861
Validation loss: 3.3175262809731434

Epoch: 6| Step: 4
Training loss: 2.714057380350804
Validation loss: 3.3162906864828265

Epoch: 6| Step: 5
Training loss: 3.465072194237704
Validation loss: 3.316521917709088

Epoch: 6| Step: 6
Training loss: 3.400347994778726
Validation loss: 3.3143670301278574

Epoch: 6| Step: 7
Training loss: 3.6304082318313093
Validation loss: 3.314056934540128

Epoch: 6| Step: 8
Training loss: 4.009714251680156
Validation loss: 3.3143711868781542

Epoch: 6| Step: 9
Training loss: 4.123401678984234
Validation loss: 3.3137757361347173

Epoch: 6| Step: 10
Training loss: 3.8435614314772
Validation loss: 3.3143365466173864

Epoch: 6| Step: 11
Training loss: 3.301506369132115
Validation loss: 3.311557100792708

Epoch: 6| Step: 12
Training loss: 3.718812060439347
Validation loss: 3.317222212008167

Epoch: 6| Step: 13
Training loss: 2.91397544587629
Validation loss: 3.314200700146611

Epoch: 22| Step: 0
Training loss: 3.1313884285729525
Validation loss: 3.3112169312727766

Epoch: 6| Step: 1
Training loss: 3.3174295273333603
Validation loss: 3.3073103657682283

Epoch: 6| Step: 2
Training loss: 3.073870667039449
Validation loss: 3.3078662303789823

Epoch: 6| Step: 3
Training loss: 3.5091964608326243
Validation loss: 3.305982546345347

Epoch: 6| Step: 4
Training loss: 3.3722214740861975
Validation loss: 3.3031513661620955

Epoch: 6| Step: 5
Training loss: 3.7708569661167384
Validation loss: 3.3028288998773854

Epoch: 6| Step: 6
Training loss: 3.7385952776769718
Validation loss: 3.3011528565643906

Epoch: 6| Step: 7
Training loss: 3.870675904542747
Validation loss: 3.299172956756183

Epoch: 6| Step: 8
Training loss: 3.1526498941335794
Validation loss: 3.2978442816736067

Epoch: 6| Step: 9
Training loss: 4.441009423235401
Validation loss: 3.2980565353429516

Epoch: 6| Step: 10
Training loss: 3.8133141320641033
Validation loss: 3.2980040534838735

Epoch: 6| Step: 11
Training loss: 3.5589330115792013
Validation loss: 3.294789576013904

Epoch: 6| Step: 12
Training loss: 2.935571565099097
Validation loss: 3.2962512341983183

Epoch: 6| Step: 13
Training loss: 3.696360014180322
Validation loss: 3.293466395049464

Epoch: 23| Step: 0
Training loss: 4.274707556643404
Validation loss: 3.291557327849197

Epoch: 6| Step: 1
Training loss: 3.60321152807326
Validation loss: 3.2903129631081276

Epoch: 6| Step: 2
Training loss: 3.3668861342805965
Validation loss: 3.290962047767018

Epoch: 6| Step: 3
Training loss: 3.590991479084355
Validation loss: 3.291463050967393

Epoch: 6| Step: 4
Training loss: 3.2966268003063446
Validation loss: 3.28957146261473

Epoch: 6| Step: 5
Training loss: 2.8442258331943266
Validation loss: 3.2888464122672523

Epoch: 6| Step: 6
Training loss: 2.8658036470627337
Validation loss: 3.291238041660009

Epoch: 6| Step: 7
Training loss: 3.9625872725734674
Validation loss: 3.2979990676793696

Epoch: 6| Step: 8
Training loss: 3.7394545735725284
Validation loss: 3.294844812112903

Epoch: 6| Step: 9
Training loss: 3.2768338958298413
Validation loss: 3.2828544354479288

Epoch: 6| Step: 10
Training loss: 4.270333510513626
Validation loss: 3.2825729640782035

Epoch: 6| Step: 11
Training loss: 3.7330962349897736
Validation loss: 3.285365560681919

Epoch: 6| Step: 12
Training loss: 3.22527001012064
Validation loss: 3.2836664235337714

Epoch: 6| Step: 13
Training loss: 2.539793971409061
Validation loss: 3.2834255212018473

Epoch: 24| Step: 0
Training loss: 3.2086931167274293
Validation loss: 3.28059352513233

Epoch: 6| Step: 1
Training loss: 3.5917733768858193
Validation loss: 3.278377279011085

Epoch: 6| Step: 2
Training loss: 3.61440451818237
Validation loss: 3.2775710772851543

Epoch: 6| Step: 3
Training loss: 2.8941175651687105
Validation loss: 3.2766212141043503

Epoch: 6| Step: 4
Training loss: 3.36424463100647
Validation loss: 3.2796298088304052

Epoch: 6| Step: 5
Training loss: 3.2870966094523366
Validation loss: 3.2833740313264532

Epoch: 6| Step: 6
Training loss: 2.9823689534126703
Validation loss: 3.2752587377860283

Epoch: 6| Step: 7
Training loss: 4.385653358771163
Validation loss: 3.274320963621175

Epoch: 6| Step: 8
Training loss: 3.7867789712111057
Validation loss: 3.272809380821158

Epoch: 6| Step: 9
Training loss: 3.3818580743482096
Validation loss: 3.2723609947074164

Epoch: 6| Step: 10
Training loss: 4.176478671150635
Validation loss: 3.2720523164560533

Epoch: 6| Step: 11
Training loss: 3.77947224843424
Validation loss: 3.2717558468576518

Epoch: 6| Step: 12
Training loss: 3.1497407776271937
Validation loss: 3.27217301182337

Epoch: 6| Step: 13
Training loss: 3.2707805912762677
Validation loss: 3.2727400739439534

Epoch: 25| Step: 0
Training loss: 3.3635883257573154
Validation loss: 3.2714004845256284

Epoch: 6| Step: 1
Training loss: 3.574617357383722
Validation loss: 3.2778373367208147

Epoch: 6| Step: 2
Training loss: 3.1912950848907182
Validation loss: 3.2728246742272193

Epoch: 6| Step: 3
Training loss: 3.547886641161224
Validation loss: 3.270661581491584

Epoch: 6| Step: 4
Training loss: 3.718875402051196
Validation loss: 3.2684494029981024

Epoch: 6| Step: 5
Training loss: 3.491467019672804
Validation loss: 3.268697864651036

Epoch: 6| Step: 6
Training loss: 3.7782395414117933
Validation loss: 3.268531930735789

Epoch: 6| Step: 7
Training loss: 2.822198042010886
Validation loss: 3.2689824450294624

Epoch: 6| Step: 8
Training loss: 4.113887267649386
Validation loss: 3.2676398135122375

Epoch: 6| Step: 9
Training loss: 3.5400692347852116
Validation loss: 3.2672769535096595

Epoch: 6| Step: 10
Training loss: 3.9367888277648397
Validation loss: 3.2648305184102875

Epoch: 6| Step: 11
Training loss: 3.206922113417836
Validation loss: 3.2662758574810646

Epoch: 6| Step: 12
Training loss: 2.7768458954330977
Validation loss: 3.2650285692231864

Epoch: 6| Step: 13
Training loss: 4.162526375168643
Validation loss: 3.265781599606646

Epoch: 26| Step: 0
Training loss: 3.694502953533727
Validation loss: 3.267006202574474

Epoch: 6| Step: 1
Training loss: 3.8465444439842233
Validation loss: 3.2681779514338447

Epoch: 6| Step: 2
Training loss: 3.7062229766632475
Validation loss: 3.2649234748890965

Epoch: 6| Step: 3
Training loss: 3.7558136697687075
Validation loss: 3.263415366681714

Epoch: 6| Step: 4
Training loss: 3.682722196900143
Validation loss: 3.264574492205315

Epoch: 6| Step: 5
Training loss: 3.660821909103323
Validation loss: 3.272178533696415

Epoch: 6| Step: 6
Training loss: 4.005594156414056
Validation loss: 3.2789329023837146

Epoch: 6| Step: 7
Training loss: 3.257355362908093
Validation loss: 3.277493041687943

Epoch: 6| Step: 8
Training loss: 2.8831077362476476
Validation loss: 3.260210286179111

Epoch: 6| Step: 9
Training loss: 3.890490426183515
Validation loss: 3.2588960798035846

Epoch: 6| Step: 10
Training loss: 3.025951355698843
Validation loss: 3.25807398016274

Epoch: 6| Step: 11
Training loss: 2.856303248336906
Validation loss: 3.256416899092949

Epoch: 6| Step: 12
Training loss: 2.783965510302693
Validation loss: 3.2557398560090496

Epoch: 6| Step: 13
Training loss: 3.910987971334899
Validation loss: 3.259474866417816

Epoch: 27| Step: 0
Training loss: 2.987079134229689
Validation loss: 3.2584847553678813

Epoch: 6| Step: 1
Training loss: 3.15439906471465
Validation loss: 3.2592081113366764

Epoch: 6| Step: 2
Training loss: 4.1789474830440305
Validation loss: 3.2569905644903154

Epoch: 6| Step: 3
Training loss: 3.8551498946005807
Validation loss: 3.255153337699076

Epoch: 6| Step: 4
Training loss: 2.271507886271271
Validation loss: 3.25255606625502

Epoch: 6| Step: 5
Training loss: 3.1178670730395233
Validation loss: 3.2557095385525923

Epoch: 6| Step: 6
Training loss: 4.124384747485143
Validation loss: 3.256331456848611

Epoch: 6| Step: 7
Training loss: 3.744752518507161
Validation loss: 3.256790014447071

Epoch: 6| Step: 8
Training loss: 3.547001101230981
Validation loss: 3.2556645634378945

Epoch: 6| Step: 9
Training loss: 3.4949680668541276
Validation loss: 3.255097722625114

Epoch: 6| Step: 10
Training loss: 4.304626796730567
Validation loss: 3.249594562947231

Epoch: 6| Step: 11
Training loss: 3.0089198068294647
Validation loss: 3.249930962396457

Epoch: 6| Step: 12
Training loss: 2.9005619293898186
Validation loss: 3.249532788268314

Epoch: 6| Step: 13
Training loss: 3.9272313718272023
Validation loss: 3.249271285884225

Epoch: 28| Step: 0
Training loss: 3.467893340031448
Validation loss: 3.250098795686776

Epoch: 6| Step: 1
Training loss: 3.6763958310773197
Validation loss: 3.2487107457690128

Epoch: 6| Step: 2
Training loss: 4.507469336076933
Validation loss: 3.2483491530561137

Epoch: 6| Step: 3
Training loss: 3.786071981512546
Validation loss: 3.2488425286402967

Epoch: 6| Step: 4
Training loss: 2.9109521379169334
Validation loss: 3.2459707138464724

Epoch: 6| Step: 5
Training loss: 2.9829075585830274
Validation loss: 3.2468446839053753

Epoch: 6| Step: 6
Training loss: 3.390437248410977
Validation loss: 3.24659761205262

Epoch: 6| Step: 7
Training loss: 3.666558755384871
Validation loss: 3.2467172228110877

Epoch: 6| Step: 8
Training loss: 2.4536219779852093
Validation loss: 3.2481921920840455

Epoch: 6| Step: 9
Training loss: 4.107133493353554
Validation loss: 3.246095842867926

Epoch: 6| Step: 10
Training loss: 3.5246233583342255
Validation loss: 3.2452975662101684

Epoch: 6| Step: 11
Training loss: 3.5550185500035214
Validation loss: 3.2434854569375546

Epoch: 6| Step: 12
Training loss: 2.8852814643849123
Validation loss: 3.244925042897118

Epoch: 6| Step: 13
Training loss: 3.5814113933419285
Validation loss: 3.245217435295613

Epoch: 29| Step: 0
Training loss: 2.706062793203306
Validation loss: 3.2449073442343206

Epoch: 6| Step: 1
Training loss: 3.1541881814186783
Validation loss: 3.2545471422965413

Epoch: 6| Step: 2
Training loss: 4.178049839801721
Validation loss: 3.2553122752012382

Epoch: 6| Step: 3
Training loss: 3.487333811967083
Validation loss: 3.239847460840927

Epoch: 6| Step: 4
Training loss: 3.281951248076512
Validation loss: 3.2405797378762333

Epoch: 6| Step: 5
Training loss: 4.06844094973426
Validation loss: 3.2467120840246415

Epoch: 6| Step: 6
Training loss: 3.2759103106842624
Validation loss: 3.249213708082879

Epoch: 6| Step: 7
Training loss: 3.681329510644542
Validation loss: 3.248864818878006

Epoch: 6| Step: 8
Training loss: 3.7948119284526682
Validation loss: 3.241549273071711

Epoch: 6| Step: 9
Training loss: 3.2198330436688116
Validation loss: 3.238332103126745

Epoch: 6| Step: 10
Training loss: 4.014488445296236
Validation loss: 3.240303059047616

Epoch: 6| Step: 11
Training loss: 3.4704335569026497
Validation loss: 3.254042740116604

Epoch: 6| Step: 12
Training loss: 3.060987760901323
Validation loss: 3.264211265534505

Epoch: 6| Step: 13
Training loss: 3.0251739010597114
Validation loss: 3.26818464571032

Epoch: 30| Step: 0
Training loss: 3.399016092090049
Validation loss: 3.2824970256737993

Epoch: 6| Step: 1
Training loss: 2.4429391671912684
Validation loss: 3.25556732573983

Epoch: 6| Step: 2
Training loss: 4.04550300818494
Validation loss: 3.2485390732839896

Epoch: 6| Step: 3
Training loss: 4.099386048288254
Validation loss: 3.2439902077623888

Epoch: 6| Step: 4
Training loss: 3.9538419171435923
Validation loss: 3.240633372015774

Epoch: 6| Step: 5
Training loss: 4.2554219385678005
Validation loss: 3.2372350338765954

Epoch: 6| Step: 6
Training loss: 3.697796557271274
Validation loss: 3.236292817327444

Epoch: 6| Step: 7
Training loss: 2.844619282756581
Validation loss: 3.2347574371029753

Epoch: 6| Step: 8
Training loss: 3.8086848947427256
Validation loss: 3.238445314094603

Epoch: 6| Step: 9
Training loss: 2.9982335930251875
Validation loss: 3.2353349366573414

Epoch: 6| Step: 10
Training loss: 3.718905405596045
Validation loss: 3.2354881872094086

Epoch: 6| Step: 11
Training loss: 3.281434408183031
Validation loss: 3.2358216925260987

Epoch: 6| Step: 12
Training loss: 2.4654591513046222
Validation loss: 3.234503931859535

Epoch: 6| Step: 13
Training loss: 2.967423795317761
Validation loss: 3.2324574470204683

Epoch: 31| Step: 0
Training loss: 3.3252427779743696
Validation loss: 3.2323356263733096

Epoch: 6| Step: 1
Training loss: 3.8987487791009956
Validation loss: 3.231996141471009

Epoch: 6| Step: 2
Training loss: 2.9822093835463686
Validation loss: 3.230462602117312

Epoch: 6| Step: 3
Training loss: 3.5491151163537733
Validation loss: 3.2312507332189897

Epoch: 6| Step: 4
Training loss: 2.724716917260456
Validation loss: 3.230377674114712

Epoch: 6| Step: 5
Training loss: 2.72077112598975
Validation loss: 3.2318588027641666

Epoch: 6| Step: 6
Training loss: 3.4286320828567662
Validation loss: 3.231564135463264

Epoch: 6| Step: 7
Training loss: 4.754343556560526
Validation loss: 3.231984766075296

Epoch: 6| Step: 8
Training loss: 2.135816087041676
Validation loss: 3.2297258991723226

Epoch: 6| Step: 9
Training loss: 3.8158097206035495
Validation loss: 3.228390831820242

Epoch: 6| Step: 10
Training loss: 3.616647239199258
Validation loss: 3.2300956085906827

Epoch: 6| Step: 11
Training loss: 3.907316748873246
Validation loss: 3.2266685204037446

Epoch: 6| Step: 12
Training loss: 3.3004911577406504
Validation loss: 3.2297687192893414

Epoch: 6| Step: 13
Training loss: 3.9864008521660725
Validation loss: 3.2275397757830904

Epoch: 32| Step: 0
Training loss: 3.482710094152907
Validation loss: 3.2297653505971917

Epoch: 6| Step: 1
Training loss: 3.8359399861562715
Validation loss: 3.228650704775888

Epoch: 6| Step: 2
Training loss: 3.409923986890985
Validation loss: 3.2240746295714473

Epoch: 6| Step: 3
Training loss: 3.5882154223223814
Validation loss: 3.223478301635084

Epoch: 6| Step: 4
Training loss: 3.0626337450367442
Validation loss: 3.2199763219828137

Epoch: 6| Step: 5
Training loss: 4.5995204260905735
Validation loss: 3.221048187954514

Epoch: 6| Step: 6
Training loss: 3.4240015119834486
Validation loss: 3.219036662590601

Epoch: 6| Step: 7
Training loss: 3.2315673436179373
Validation loss: 3.219245583373699

Epoch: 6| Step: 8
Training loss: 3.3284654040264234
Validation loss: 3.2208073818043887

Epoch: 6| Step: 9
Training loss: 3.437305930468126
Validation loss: 3.2169857301316718

Epoch: 6| Step: 10
Training loss: 3.1150837541957515
Validation loss: 3.219312778539034

Epoch: 6| Step: 11
Training loss: 3.404640587478688
Validation loss: 3.217967944221818

Epoch: 6| Step: 12
Training loss: 3.0645968985154677
Validation loss: 3.2189265902716655

Epoch: 6| Step: 13
Training loss: 3.303514204671121
Validation loss: 3.216770729607062

Epoch: 33| Step: 0
Training loss: 3.1931922798886276
Validation loss: 3.2187143951654584

Epoch: 6| Step: 1
Training loss: 2.9350068895821235
Validation loss: 3.226715205841999

Epoch: 6| Step: 2
Training loss: 3.4073873598396642
Validation loss: 3.2322618912402836

Epoch: 6| Step: 3
Training loss: 3.040467709651365
Validation loss: 3.244053974332737

Epoch: 6| Step: 4
Training loss: 4.416585069778331
Validation loss: 3.238635265747058

Epoch: 6| Step: 5
Training loss: 3.7482603488418724
Validation loss: 3.2153194922112083

Epoch: 6| Step: 6
Training loss: 3.6960420110222247
Validation loss: 3.212607102324293

Epoch: 6| Step: 7
Training loss: 3.85656883368433
Validation loss: 3.2178122738179433

Epoch: 6| Step: 8
Training loss: 2.6506065106438523
Validation loss: 3.2161807701973597

Epoch: 6| Step: 9
Training loss: 3.9109941893738998
Validation loss: 3.218047018569429

Epoch: 6| Step: 10
Training loss: 2.952925095023795
Validation loss: 3.213849890539706

Epoch: 6| Step: 11
Training loss: 3.288866195800893
Validation loss: 3.2139627291134967

Epoch: 6| Step: 12
Training loss: 3.1732331173029262
Validation loss: 3.213177966711843

Epoch: 6| Step: 13
Training loss: 4.27280924919483
Validation loss: 3.214282481232121

Epoch: 34| Step: 0
Training loss: 3.2064841915510054
Validation loss: 3.213969357638314

Epoch: 6| Step: 1
Training loss: 3.1476065246638507
Validation loss: 3.2143694343901617

Epoch: 6| Step: 2
Training loss: 3.630696786048331
Validation loss: 3.2189826248076634

Epoch: 6| Step: 3
Training loss: 2.9465237259465464
Validation loss: 3.2234076255005006

Epoch: 6| Step: 4
Training loss: 2.75814722207369
Validation loss: 3.21617826568577

Epoch: 6| Step: 5
Training loss: 3.3608253364521445
Validation loss: 3.2166667312969763

Epoch: 6| Step: 6
Training loss: 3.4453656458486015
Validation loss: 3.2144429467076128

Epoch: 6| Step: 7
Training loss: 3.573443686242664
Validation loss: 3.2140313428567566

Epoch: 6| Step: 8
Training loss: 2.8153229004147735
Validation loss: 3.211714342783055

Epoch: 6| Step: 9
Training loss: 3.578014655264986
Validation loss: 3.2100252139394687

Epoch: 6| Step: 10
Training loss: 4.259551366903566
Validation loss: 3.208271651413533

Epoch: 6| Step: 11
Training loss: 4.408114857058239
Validation loss: 3.2080249699448915

Epoch: 6| Step: 12
Training loss: 3.7543003855835604
Validation loss: 3.2068097026285174

Epoch: 6| Step: 13
Training loss: 2.9231104559268415
Validation loss: 3.2028092935819688

Epoch: 35| Step: 0
Training loss: 2.642843183826713
Validation loss: 3.205196001034724

Epoch: 6| Step: 1
Training loss: 3.3873260903849425
Validation loss: 3.206313704275757

Epoch: 6| Step: 2
Training loss: 4.489262804713615
Validation loss: 3.20601734320805

Epoch: 6| Step: 3
Training loss: 3.605983180814545
Validation loss: 3.2016792161861733

Epoch: 6| Step: 4
Training loss: 2.559954984388344
Validation loss: 3.203865821581446

Epoch: 6| Step: 5
Training loss: 3.143675276548894
Validation loss: 3.20176478692309

Epoch: 6| Step: 6
Training loss: 4.382711970354416
Validation loss: 3.2020615728028017

Epoch: 6| Step: 7
Training loss: 3.127270445963973
Validation loss: 3.2023050350703173

Epoch: 6| Step: 8
Training loss: 3.0920886578599918
Validation loss: 3.2010223506512094

Epoch: 6| Step: 9
Training loss: 3.1866510794137333
Validation loss: 3.199776138562365

Epoch: 6| Step: 10
Training loss: 2.9346890899943117
Validation loss: 3.200650550103091

Epoch: 6| Step: 11
Training loss: 4.198552817836183
Validation loss: 3.2003527642332417

Epoch: 6| Step: 12
Training loss: 3.2776610592537088
Validation loss: 3.1994039055307986

Epoch: 6| Step: 13
Training loss: 3.907567282772873
Validation loss: 3.200269702343907

Epoch: 36| Step: 0
Training loss: 2.758852408703045
Validation loss: 3.2004580107801734

Epoch: 6| Step: 1
Training loss: 3.5169737538651007
Validation loss: 3.1991336312406453

Epoch: 6| Step: 2
Training loss: 3.5918210367424144
Validation loss: 3.1970967333941918

Epoch: 6| Step: 3
Training loss: 3.2729850219607624
Validation loss: 3.1982778094287663

Epoch: 6| Step: 4
Training loss: 2.8041537741316986
Validation loss: 3.19731531838677

Epoch: 6| Step: 5
Training loss: 4.336791248296237
Validation loss: 3.195503016370122

Epoch: 6| Step: 6
Training loss: 3.3714404231779884
Validation loss: 3.1957651072437017

Epoch: 6| Step: 7
Training loss: 3.9982350747259163
Validation loss: 3.1974572597290645

Epoch: 6| Step: 8
Training loss: 2.7872948267400552
Validation loss: 3.1965494544436033

Epoch: 6| Step: 9
Training loss: 3.6170819063201773
Validation loss: 3.1962461964994

Epoch: 6| Step: 10
Training loss: 2.5724506239235017
Validation loss: 3.1944946282148305

Epoch: 6| Step: 11
Training loss: 4.109126210387146
Validation loss: 3.19568097467907

Epoch: 6| Step: 12
Training loss: 3.6945498044344034
Validation loss: 3.1943646240130064

Epoch: 6| Step: 13
Training loss: 3.162307214703533
Validation loss: 3.194896507347781

Epoch: 37| Step: 0
Training loss: 3.7346811847379615
Validation loss: 3.20765955966649

Epoch: 6| Step: 1
Training loss: 3.46941884783657
Validation loss: 3.1948885906876363

Epoch: 6| Step: 2
Training loss: 3.8306067071354346
Validation loss: 3.193872848693252

Epoch: 6| Step: 3
Training loss: 3.6674960383294364
Validation loss: 3.1924203516197087

Epoch: 6| Step: 4
Training loss: 3.9340618805820813
Validation loss: 3.194236860148461

Epoch: 6| Step: 5
Training loss: 3.3513934753052137
Validation loss: 3.1902164447338777

Epoch: 6| Step: 6
Training loss: 3.187307314565144
Validation loss: 3.1907989253032887

Epoch: 6| Step: 7
Training loss: 2.8047716558470266
Validation loss: 3.188972437072592

Epoch: 6| Step: 8
Training loss: 2.962271437700751
Validation loss: 3.188329388888164

Epoch: 6| Step: 9
Training loss: 3.5123023035202245
Validation loss: 3.1885057423350682

Epoch: 6| Step: 10
Training loss: 3.377055778289025
Validation loss: 3.186922744543182

Epoch: 6| Step: 11
Training loss: 3.1602099665165766
Validation loss: 3.1879065453609683

Epoch: 6| Step: 12
Training loss: 3.178024269390644
Validation loss: 3.186393167612556

Epoch: 6| Step: 13
Training loss: 4.070758582801629
Validation loss: 3.186463853754799

Epoch: 38| Step: 0
Training loss: 2.860523764394388
Validation loss: 3.1851121490613634

Epoch: 6| Step: 1
Training loss: 3.906946593162457
Validation loss: 3.1845839752586333

Epoch: 6| Step: 2
Training loss: 3.62705935156773
Validation loss: 3.185435715463627

Epoch: 6| Step: 3
Training loss: 1.9511628327336774
Validation loss: 3.1845698198281363

Epoch: 6| Step: 4
Training loss: 3.4829610513091476
Validation loss: 3.1835839821052696

Epoch: 6| Step: 5
Training loss: 3.238967068228293
Validation loss: 3.18242459954107

Epoch: 6| Step: 6
Training loss: 3.4440312154775246
Validation loss: 3.1823146110249825

Epoch: 6| Step: 7
Training loss: 4.1541550024258465
Validation loss: 3.180950450036528

Epoch: 6| Step: 8
Training loss: 3.785569427268753
Validation loss: 3.1817784683131394

Epoch: 6| Step: 9
Training loss: 3.513142841200833
Validation loss: 3.1816561140981694

Epoch: 6| Step: 10
Training loss: 4.371474671321104
Validation loss: 3.1829121963140987

Epoch: 6| Step: 11
Training loss: 2.6631884441504314
Validation loss: 3.182968855200021

Epoch: 6| Step: 12
Training loss: 3.3764669268002434
Validation loss: 3.180739225080649

Epoch: 6| Step: 13
Training loss: 2.7341049496948804
Validation loss: 3.1824201818354614

Epoch: 39| Step: 0
Training loss: 3.7234203599158318
Validation loss: 3.1807646104069947

Epoch: 6| Step: 1
Training loss: 3.6126189743566695
Validation loss: 3.178804629212362

Epoch: 6| Step: 2
Training loss: 4.002416357706861
Validation loss: 3.1774298796462

Epoch: 6| Step: 3
Training loss: 3.8513750568454395
Validation loss: 3.17572205077945

Epoch: 6| Step: 4
Training loss: 3.154494600033518
Validation loss: 3.1765616201231035

Epoch: 6| Step: 5
Training loss: 2.1748266129058687
Validation loss: 3.1760776315230825

Epoch: 6| Step: 6
Training loss: 3.5216075941247444
Validation loss: 3.176903767842858

Epoch: 6| Step: 7
Training loss: 2.6880340045640017
Validation loss: 3.1761828236525735

Epoch: 6| Step: 8
Training loss: 3.1889597224374167
Validation loss: 3.175830441651074

Epoch: 6| Step: 9
Training loss: 3.2782699858365265
Validation loss: 3.176690322449938

Epoch: 6| Step: 10
Training loss: 2.3293969692773526
Validation loss: 3.176857543108973

Epoch: 6| Step: 11
Training loss: 4.093488146145866
Validation loss: 3.17572636155712

Epoch: 6| Step: 12
Training loss: 3.9278782344443397
Validation loss: 3.17364085210522

Epoch: 6| Step: 13
Training loss: 4.076523506559987
Validation loss: 3.173860061421724

Epoch: 40| Step: 0
Training loss: 4.207034650285882
Validation loss: 3.1725645715509945

Epoch: 6| Step: 1
Training loss: 3.375632897833753
Validation loss: 3.1729093075908374

Epoch: 6| Step: 2
Training loss: 2.658170477045101
Validation loss: 3.173902010099467

Epoch: 6| Step: 3
Training loss: 3.625882929120304
Validation loss: 3.1710946310060035

Epoch: 6| Step: 4
Training loss: 3.6814542444948413
Validation loss: 3.1712329553550136

Epoch: 6| Step: 5
Training loss: 3.5761721416746215
Validation loss: 3.17082513892203

Epoch: 6| Step: 6
Training loss: 3.4654349217345497
Validation loss: 3.1716429817840077

Epoch: 6| Step: 7
Training loss: 4.065150643310481
Validation loss: 3.1694903896468416

Epoch: 6| Step: 8
Training loss: 3.5097539410107412
Validation loss: 3.1770401705441293

Epoch: 6| Step: 9
Training loss: 2.667196449662553
Validation loss: 3.1746283223447214

Epoch: 6| Step: 10
Training loss: 2.3580514593357558
Validation loss: 3.1743204649404797

Epoch: 6| Step: 11
Training loss: 3.54077161062851
Validation loss: 3.1667835416960037

Epoch: 6| Step: 12
Training loss: 3.486303505690384
Validation loss: 3.1665767684982304

Epoch: 6| Step: 13
Training loss: 3.0776531032033527
Validation loss: 3.166143233772491

Epoch: 41| Step: 0
Training loss: 3.1935381078135157
Validation loss: 3.163916079486788

Epoch: 6| Step: 1
Training loss: 3.545393714294009
Validation loss: 3.165545523077383

Epoch: 6| Step: 2
Training loss: 3.0092031459521635
Validation loss: 3.1652881180471932

Epoch: 6| Step: 3
Training loss: 3.1228321948766955
Validation loss: 3.167397276095368

Epoch: 6| Step: 4
Training loss: 3.271378554725122
Validation loss: 3.1662988810749706

Epoch: 6| Step: 5
Training loss: 4.212502608029608
Validation loss: 3.170595541545233

Epoch: 6| Step: 6
Training loss: 3.7928706901909752
Validation loss: 3.1685611616078773

Epoch: 6| Step: 7
Training loss: 3.3875741197423337
Validation loss: 3.1646808878320476

Epoch: 6| Step: 8
Training loss: 3.8796571617461235
Validation loss: 3.164153967957864

Epoch: 6| Step: 9
Training loss: 3.0497496517808798
Validation loss: 3.163719717134058

Epoch: 6| Step: 10
Training loss: 3.0204577683879696
Validation loss: 3.164024439696354

Epoch: 6| Step: 11
Training loss: 3.1891316744204827
Validation loss: 3.1680494008675364

Epoch: 6| Step: 12
Training loss: 3.6715712401366973
Validation loss: 3.169202128468884

Epoch: 6| Step: 13
Training loss: 3.3175508390899284
Validation loss: 3.1673522465065562

Epoch: 42| Step: 0
Training loss: 3.598000045072376
Validation loss: 3.167460523966163

Epoch: 6| Step: 1
Training loss: 3.3040159007468013
Validation loss: 3.1657850309782125

Epoch: 6| Step: 2
Training loss: 3.233889335989523
Validation loss: 3.1688557351620963

Epoch: 6| Step: 3
Training loss: 3.02749968096403
Validation loss: 3.167671820195391

Epoch: 6| Step: 4
Training loss: 3.376736512084693
Validation loss: 3.1673582441214863

Epoch: 6| Step: 5
Training loss: 4.061887254721426
Validation loss: 3.1692015088337704

Epoch: 6| Step: 6
Training loss: 3.43700502473288
Validation loss: 3.1654583974135764

Epoch: 6| Step: 7
Training loss: 3.963394757161925
Validation loss: 3.1605761273022273

Epoch: 6| Step: 8
Training loss: 3.364619362149073
Validation loss: 3.1589683450738266

Epoch: 6| Step: 9
Training loss: 3.771711693288611
Validation loss: 3.156350350162946

Epoch: 6| Step: 10
Training loss: 3.496864958366042
Validation loss: 3.1589102664201008

Epoch: 6| Step: 11
Training loss: 2.90047151086708
Validation loss: 3.1576646014422227

Epoch: 6| Step: 12
Training loss: 2.7835055002960245
Validation loss: 3.1555586652404854

Epoch: 6| Step: 13
Training loss: 3.2295736897222507
Validation loss: 3.1563534357728855

Epoch: 43| Step: 0
Training loss: 2.957220880230737
Validation loss: 3.156205620378038

Epoch: 6| Step: 1
Training loss: 3.8626002375858093
Validation loss: 3.1574975042655042

Epoch: 6| Step: 2
Training loss: 4.159287110280688
Validation loss: 3.1642872388097647

Epoch: 6| Step: 3
Training loss: 3.546036003467904
Validation loss: 3.163348297532743

Epoch: 6| Step: 4
Training loss: 3.058700228380867
Validation loss: 3.159012758109817

Epoch: 6| Step: 5
Training loss: 2.55316424672324
Validation loss: 3.15724205688078

Epoch: 6| Step: 6
Training loss: 3.6085106281189017
Validation loss: 3.1548761435618373

Epoch: 6| Step: 7
Training loss: 3.3866952369516103
Validation loss: 3.1552070284191593

Epoch: 6| Step: 8
Training loss: 3.0785258850228723
Validation loss: 3.157869892912263

Epoch: 6| Step: 9
Training loss: 3.3578158286722974
Validation loss: 3.1544555124332656

Epoch: 6| Step: 10
Training loss: 3.809759186671095
Validation loss: 3.1532029086384337

Epoch: 6| Step: 11
Training loss: 3.2896013339522363
Validation loss: 3.1530483710910837

Epoch: 6| Step: 12
Training loss: 3.6382489616430833
Validation loss: 3.153367833455201

Epoch: 6| Step: 13
Training loss: 2.929824866571259
Validation loss: 3.153445227048091

Epoch: 44| Step: 0
Training loss: 3.7535125811807957
Validation loss: 3.1531924270706555

Epoch: 6| Step: 1
Training loss: 3.111949525742512
Validation loss: 3.153055783004196

Epoch: 6| Step: 2
Training loss: 2.9174944838183245
Validation loss: 3.152974398983389

Epoch: 6| Step: 3
Training loss: 3.219905460699473
Validation loss: 3.153625251385346

Epoch: 6| Step: 4
Training loss: 4.049369367315017
Validation loss: 3.1519999318307907

Epoch: 6| Step: 5
Training loss: 3.657841653882843
Validation loss: 3.152070691423637

Epoch: 6| Step: 6
Training loss: 3.6436740402758017
Validation loss: 3.1497865229193094

Epoch: 6| Step: 7
Training loss: 3.3003981147831927
Validation loss: 3.1486352054225373

Epoch: 6| Step: 8
Training loss: 3.456370213989286
Validation loss: 3.1494269937661716

Epoch: 6| Step: 9
Training loss: 3.3643432783501863
Validation loss: 3.1480159026861174

Epoch: 6| Step: 10
Training loss: 3.2863291348766723
Validation loss: 3.148054698896517

Epoch: 6| Step: 11
Training loss: 2.9656773778633294
Validation loss: 3.1463950935780503

Epoch: 6| Step: 12
Training loss: 3.12126378824399
Validation loss: 3.148572709534431

Epoch: 6| Step: 13
Training loss: 3.856733522442893
Validation loss: 3.147566753694349

Epoch: 45| Step: 0
Training loss: 3.2094565733113884
Validation loss: 3.148686406409656

Epoch: 6| Step: 1
Training loss: 3.3106412170831065
Validation loss: 3.1498395372712213

Epoch: 6| Step: 2
Training loss: 2.917007226589119
Validation loss: 3.147661748708991

Epoch: 6| Step: 3
Training loss: 3.778959983773308
Validation loss: 3.147920577943058

Epoch: 6| Step: 4
Training loss: 3.438930837909126
Validation loss: 3.1486716930809258

Epoch: 6| Step: 5
Training loss: 3.477910224198993
Validation loss: 3.146921841629528

Epoch: 6| Step: 6
Training loss: 3.942313748582264
Validation loss: 3.1490918951718356

Epoch: 6| Step: 7
Training loss: 2.257718833379596
Validation loss: 3.1444875479863668

Epoch: 6| Step: 8
Training loss: 4.069561733483929
Validation loss: 3.14280841672692

Epoch: 6| Step: 9
Training loss: 2.9503490176878864
Validation loss: 3.140939687677554

Epoch: 6| Step: 10
Training loss: 3.583662387613883
Validation loss: 3.140734620074738

Epoch: 6| Step: 11
Training loss: 3.186085555456258
Validation loss: 3.139961792618244

Epoch: 6| Step: 12
Training loss: 3.425344023864425
Validation loss: 3.1394867540158287

Epoch: 6| Step: 13
Training loss: 3.859460868343518
Validation loss: 3.1388444338052404

Epoch: 46| Step: 0
Training loss: 3.008465743034838
Validation loss: 3.1397048001269936

Epoch: 6| Step: 1
Training loss: 3.3409369213334608
Validation loss: 3.139157839780313

Epoch: 6| Step: 2
Training loss: 3.824792026026827
Validation loss: 3.140125691065606

Epoch: 6| Step: 3
Training loss: 3.0356847040353934
Validation loss: 3.142018468965807

Epoch: 6| Step: 4
Training loss: 3.1130689598849273
Validation loss: 3.14213241850571

Epoch: 6| Step: 5
Training loss: 3.9679969613848094
Validation loss: 3.1362928872918325

Epoch: 6| Step: 6
Training loss: 3.046946050353476
Validation loss: 3.1359502825932317

Epoch: 6| Step: 7
Training loss: 3.4343635815750813
Validation loss: 3.1357139776495924

Epoch: 6| Step: 8
Training loss: 3.7682291104260246
Validation loss: 3.1346887009087983

Epoch: 6| Step: 9
Training loss: 4.094449282027523
Validation loss: 3.135664495953396

Epoch: 6| Step: 10
Training loss: 2.939787116355493
Validation loss: 3.133609927498839

Epoch: 6| Step: 11
Training loss: 3.2708575658852213
Validation loss: 3.1356144779562856

Epoch: 6| Step: 12
Training loss: 2.865794162894822
Validation loss: 3.1329521496064054

Epoch: 6| Step: 13
Training loss: 3.6223045061538843
Validation loss: 3.1411808227954094

Epoch: 47| Step: 0
Training loss: 3.239144020508459
Validation loss: 3.144834975423355

Epoch: 6| Step: 1
Training loss: 4.002599824974602
Validation loss: 3.1435860099450563

Epoch: 6| Step: 2
Training loss: 3.5663351196014563
Validation loss: 3.1379817050146497

Epoch: 6| Step: 3
Training loss: 3.592805157723862
Validation loss: 3.1334229426594797

Epoch: 6| Step: 4
Training loss: 3.0458259537203443
Validation loss: 3.131044300588205

Epoch: 6| Step: 5
Training loss: 3.1489308919582695
Validation loss: 3.1302619407925163

Epoch: 6| Step: 6
Training loss: 3.5278536236904086
Validation loss: 3.1295156360295096

Epoch: 6| Step: 7
Training loss: 3.161564045395058
Validation loss: 3.130708227671813

Epoch: 6| Step: 8
Training loss: 3.768854426365363
Validation loss: 3.129707379195284

Epoch: 6| Step: 9
Training loss: 2.818515532695258
Validation loss: 3.1307313041405327

Epoch: 6| Step: 10
Training loss: 2.651214404121227
Validation loss: 3.1304144994207808

Epoch: 6| Step: 11
Training loss: 3.923444456689061
Validation loss: 3.1277036772028026

Epoch: 6| Step: 12
Training loss: 3.457524599551874
Validation loss: 3.1294716735379624

Epoch: 6| Step: 13
Training loss: 3.1921784716836505
Validation loss: 3.1292617188513767

Epoch: 48| Step: 0
Training loss: 3.7479150698228834
Validation loss: 3.1271475601156373

Epoch: 6| Step: 1
Training loss: 3.844492026557051
Validation loss: 3.1279186491530897

Epoch: 6| Step: 2
Training loss: 3.380697880088238
Validation loss: 3.1268314204328753

Epoch: 6| Step: 3
Training loss: 3.3209084368692454
Validation loss: 3.1266478084657825

Epoch: 6| Step: 4
Training loss: 3.4400733332247246
Validation loss: 3.125152995968614

Epoch: 6| Step: 5
Training loss: 2.6630529017649796
Validation loss: 3.127173911707879

Epoch: 6| Step: 6
Training loss: 2.4348432293817726
Validation loss: 3.1257000752211073

Epoch: 6| Step: 7
Training loss: 3.2223219819538986
Validation loss: 3.1231718183490202

Epoch: 6| Step: 8
Training loss: 3.65105179564431
Validation loss: 3.1313862688644134

Epoch: 6| Step: 9
Training loss: 3.754043433692634
Validation loss: 3.1487275188521364

Epoch: 6| Step: 10
Training loss: 3.246285590093128
Validation loss: 3.1273326740404497

Epoch: 6| Step: 11
Training loss: 3.5168145773879687
Validation loss: 3.1252855658543925

Epoch: 6| Step: 12
Training loss: 3.07293045989136
Validation loss: 3.1337738366521624

Epoch: 6| Step: 13
Training loss: 4.106296328859533
Validation loss: 3.1249498572479775

Epoch: 49| Step: 0
Training loss: 2.2540907230617337
Validation loss: 3.1212753725005213

Epoch: 6| Step: 1
Training loss: 2.8596751571453933
Validation loss: 3.1196289255617695

Epoch: 6| Step: 2
Training loss: 3.938364085495636
Validation loss: 3.1199255583185717

Epoch: 6| Step: 3
Training loss: 3.639239788527725
Validation loss: 3.120120942432892

Epoch: 6| Step: 4
Training loss: 3.2211169086357487
Validation loss: 3.1200134706876885

Epoch: 6| Step: 5
Training loss: 3.022653088601264
Validation loss: 3.1167761998333106

Epoch: 6| Step: 6
Training loss: 3.4359127194706667
Validation loss: 3.119733618249418

Epoch: 6| Step: 7
Training loss: 3.9468872553377627
Validation loss: 3.1174965241977244

Epoch: 6| Step: 8
Training loss: 3.1872881650657146
Validation loss: 3.1183093386923972

Epoch: 6| Step: 9
Training loss: 2.364117132489757
Validation loss: 3.1185860619718104

Epoch: 6| Step: 10
Training loss: 4.30841357355024
Validation loss: 3.15008065113447

Epoch: 6| Step: 11
Training loss: 4.207815056540488
Validation loss: 3.1153476781534604

Epoch: 6| Step: 12
Training loss: 2.985096789249307
Validation loss: 3.1171461253669306

Epoch: 6| Step: 13
Training loss: 3.219436424171508
Validation loss: 3.1166723767747526

Epoch: 50| Step: 0
Training loss: 2.648106016946781
Validation loss: 3.120055062013491

Epoch: 6| Step: 1
Training loss: 3.33242677440737
Validation loss: 3.1281585645991914

Epoch: 6| Step: 2
Training loss: 3.7567111679550873
Validation loss: 3.13486461680527

Epoch: 6| Step: 3
Training loss: 3.1683624813124336
Validation loss: 3.142342032928709

Epoch: 6| Step: 4
Training loss: 2.888110577651111
Validation loss: 3.1377778934959144

Epoch: 6| Step: 5
Training loss: 3.0759641546931316
Validation loss: 3.1379215050983844

Epoch: 6| Step: 6
Training loss: 3.3073402381193855
Validation loss: 3.1327447620771407

Epoch: 6| Step: 7
Training loss: 3.537377906013319
Validation loss: 3.121233506676058

Epoch: 6| Step: 8
Training loss: 2.5402624493273134
Validation loss: 3.119528001443294

Epoch: 6| Step: 9
Training loss: 3.0761498635125184
Validation loss: 3.1170433821819947

Epoch: 6| Step: 10
Training loss: 4.564498254751222
Validation loss: 3.1146097412921394

Epoch: 6| Step: 11
Training loss: 3.423067346755656
Validation loss: 3.1166343431527825

Epoch: 6| Step: 12
Training loss: 3.8450776575230328
Validation loss: 3.116377693319182

Epoch: 6| Step: 13
Training loss: 3.9027225283825806
Validation loss: 3.117290569037288

Epoch: 51| Step: 0
Training loss: 3.2247726241989842
Validation loss: 3.1163437479333083

Epoch: 6| Step: 1
Training loss: 2.629525779062435
Validation loss: 3.118928171481745

Epoch: 6| Step: 2
Training loss: 3.1516646512847326
Validation loss: 3.116718824576512

Epoch: 6| Step: 3
Training loss: 4.156341322275622
Validation loss: 3.116398950129047

Epoch: 6| Step: 4
Training loss: 3.5745306493864786
Validation loss: 3.1164749881047387

Epoch: 6| Step: 5
Training loss: 3.5269537252792573
Validation loss: 3.1168283074694974

Epoch: 6| Step: 6
Training loss: 3.6448737634638206
Validation loss: 3.1158488588210416

Epoch: 6| Step: 7
Training loss: 3.5651675493370845
Validation loss: 3.1113575125706507

Epoch: 6| Step: 8
Training loss: 3.4857868704061636
Validation loss: 3.1143246082740728

Epoch: 6| Step: 9
Training loss: 2.6703904695773923
Validation loss: 3.1182215361309775

Epoch: 6| Step: 10
Training loss: 2.396619275313804
Validation loss: 3.1108165377251904

Epoch: 6| Step: 11
Training loss: 4.085794187406617
Validation loss: 3.1107713516991975

Epoch: 6| Step: 12
Training loss: 3.381485817630893
Validation loss: 3.108614030296881

Epoch: 6| Step: 13
Training loss: 3.148744932551469
Validation loss: 3.1102251677768296

Epoch: 52| Step: 0
Training loss: 3.0221909903177875
Validation loss: 3.1088888474978873

Epoch: 6| Step: 1
Training loss: 3.6283217371023877
Validation loss: 3.1099930584566313

Epoch: 6| Step: 2
Training loss: 3.6810069705033883
Validation loss: 3.107784725954698

Epoch: 6| Step: 3
Training loss: 3.1763973975631723
Validation loss: 3.107476858665786

Epoch: 6| Step: 4
Training loss: 4.052988743899829
Validation loss: 3.1041536503648506

Epoch: 6| Step: 5
Training loss: 2.329419896026037
Validation loss: 3.1004930870177967

Epoch: 6| Step: 6
Training loss: 4.194411537990093
Validation loss: 3.1020212439403876

Epoch: 6| Step: 7
Training loss: 3.030979419705086
Validation loss: 3.102193765521593

Epoch: 6| Step: 8
Training loss: 3.5219856197447026
Validation loss: 3.1031197296997663

Epoch: 6| Step: 9
Training loss: 3.21360693833863
Validation loss: 3.104467319734634

Epoch: 6| Step: 10
Training loss: 3.529477645221757
Validation loss: 3.1030843099925627

Epoch: 6| Step: 11
Training loss: 2.4710545467097527
Validation loss: 3.1049149982107767

Epoch: 6| Step: 12
Training loss: 3.4527283867961986
Validation loss: 3.10574307454496

Epoch: 6| Step: 13
Training loss: 3.2945771367706413
Validation loss: 3.1067167385579375

Epoch: 53| Step: 0
Training loss: 2.992848136620378
Validation loss: 3.107200982608441

Epoch: 6| Step: 1
Training loss: 3.688468288728475
Validation loss: 3.1075835941763863

Epoch: 6| Step: 2
Training loss: 3.8390179791040673
Validation loss: 3.1008616480847313

Epoch: 6| Step: 3
Training loss: 3.8539390428015183
Validation loss: 3.1000289177645706

Epoch: 6| Step: 4
Training loss: 2.4417208781641673
Validation loss: 3.0985323495884383

Epoch: 6| Step: 5
Training loss: 3.4547292167667267
Validation loss: 3.094904333208532

Epoch: 6| Step: 6
Training loss: 3.7066853465380287
Validation loss: 3.097536479773507

Epoch: 6| Step: 7
Training loss: 3.034104094900405
Validation loss: 3.0961502010638213

Epoch: 6| Step: 8
Training loss: 3.2377609736887156
Validation loss: 3.0951133732761305

Epoch: 6| Step: 9
Training loss: 3.240672591769477
Validation loss: 3.0921716924421028

Epoch: 6| Step: 10
Training loss: 3.3949303079679667
Validation loss: 3.0959446376611597

Epoch: 6| Step: 11
Training loss: 3.38129826368483
Validation loss: 3.096976217115807

Epoch: 6| Step: 12
Training loss: 2.680692967882637
Validation loss: 3.0942140846210164

Epoch: 6| Step: 13
Training loss: 4.14974305609885
Validation loss: 3.0939638708790977

Epoch: 54| Step: 0
Training loss: 3.177923889698786
Validation loss: 3.0926125313209685

Epoch: 6| Step: 1
Training loss: 3.964521543442589
Validation loss: 3.09125040121784

Epoch: 6| Step: 2
Training loss: 2.6222563437847817
Validation loss: 3.0928417151530954

Epoch: 6| Step: 3
Training loss: 3.2311032466655707
Validation loss: 3.090879122339442

Epoch: 6| Step: 4
Training loss: 3.2037086513320197
Validation loss: 3.090799742394689

Epoch: 6| Step: 5
Training loss: 3.248588548958579
Validation loss: 3.0878636434351927

Epoch: 6| Step: 6
Training loss: 2.329302189341267
Validation loss: 3.090608017452154

Epoch: 6| Step: 7
Training loss: 3.9930666200051452
Validation loss: 3.0905087171368053

Epoch: 6| Step: 8
Training loss: 3.5425314501952636
Validation loss: 3.0961203429106092

Epoch: 6| Step: 9
Training loss: 2.886116429571743
Validation loss: 3.0997565976085633

Epoch: 6| Step: 10
Training loss: 2.7453453378987698
Validation loss: 3.108444495950073

Epoch: 6| Step: 11
Training loss: 3.9874380268315477
Validation loss: 3.1018019083970403

Epoch: 6| Step: 12
Training loss: 3.9133680264323125
Validation loss: 3.102447833884872

Epoch: 6| Step: 13
Training loss: 3.8315898551614667
Validation loss: 3.092861508270393

Epoch: 55| Step: 0
Training loss: 3.430092894071951
Validation loss: 3.0892778251214397

Epoch: 6| Step: 1
Training loss: 3.159951032428153
Validation loss: 3.086081294381367

Epoch: 6| Step: 2
Training loss: 3.9192805124292165
Validation loss: 3.086907371262548

Epoch: 6| Step: 3
Training loss: 3.078253883723084
Validation loss: 3.0855275810349094

Epoch: 6| Step: 4
Training loss: 3.7188689910059516
Validation loss: 3.0857528031035413

Epoch: 6| Step: 5
Training loss: 3.4700540376792497
Validation loss: 3.084461646482669

Epoch: 6| Step: 6
Training loss: 3.116902962225121
Validation loss: 3.0861485380154496

Epoch: 6| Step: 7
Training loss: 3.5417359887612903
Validation loss: 3.085355156204514

Epoch: 6| Step: 8
Training loss: 2.9125681463954556
Validation loss: 3.083928968328043

Epoch: 6| Step: 9
Training loss: 2.960915276033846
Validation loss: 3.08470337441474

Epoch: 6| Step: 10
Training loss: 3.4390883504129115
Validation loss: 3.083425545969525

Epoch: 6| Step: 11
Training loss: 2.853776297128549
Validation loss: 3.0840145651156288

Epoch: 6| Step: 12
Training loss: 3.1428824894366043
Validation loss: 3.0852047236223914

Epoch: 6| Step: 13
Training loss: 4.350022870584634
Validation loss: 3.083593394701081

Epoch: 56| Step: 0
Training loss: 2.831662489461559
Validation loss: 3.082902078864631

Epoch: 6| Step: 1
Training loss: 4.169849146760382
Validation loss: 3.0835355433502265

Epoch: 6| Step: 2
Training loss: 3.080350120015165
Validation loss: 3.0824204689662134

Epoch: 6| Step: 3
Training loss: 2.529491331659814
Validation loss: 3.0788645189380737

Epoch: 6| Step: 4
Training loss: 3.3256768190289425
Validation loss: 3.0813513396697636

Epoch: 6| Step: 5
Training loss: 3.9189987274035474
Validation loss: 3.080304522022322

Epoch: 6| Step: 6
Training loss: 3.044620090330779
Validation loss: 3.0789836666368546

Epoch: 6| Step: 7
Training loss: 2.37611001827982
Validation loss: 3.078923766968239

Epoch: 6| Step: 8
Training loss: 3.2547146272742062
Validation loss: 3.077763610083517

Epoch: 6| Step: 9
Training loss: 3.5100593422766675
Validation loss: 3.0778976647147713

Epoch: 6| Step: 10
Training loss: 3.3761057984827474
Validation loss: 3.07838090493205

Epoch: 6| Step: 11
Training loss: 3.1675800879996077
Validation loss: 3.0782418444102464

Epoch: 6| Step: 12
Training loss: 3.925674239640728
Validation loss: 3.076323606802332

Epoch: 6| Step: 13
Training loss: 4.154041363131384
Validation loss: 3.076139527759715

Epoch: 57| Step: 0
Training loss: 3.583047737154915
Validation loss: 3.0762760282360393

Epoch: 6| Step: 1
Training loss: 2.9761491623690373
Validation loss: 3.0791622679751667

Epoch: 6| Step: 2
Training loss: 3.2905374513519825
Validation loss: 3.077026222713171

Epoch: 6| Step: 3
Training loss: 2.4704779842764593
Validation loss: 3.07805279537283

Epoch: 6| Step: 4
Training loss: 3.666154016434225
Validation loss: 3.0840272868050165

Epoch: 6| Step: 5
Training loss: 3.2811796634946493
Validation loss: 3.078630663102429

Epoch: 6| Step: 6
Training loss: 3.5439626693826134
Validation loss: 3.084265192015097

Epoch: 6| Step: 7
Training loss: 2.239783297342664
Validation loss: 3.076645762163067

Epoch: 6| Step: 8
Training loss: 4.230354680912507
Validation loss: 3.076825792351906

Epoch: 6| Step: 9
Training loss: 3.2513119910408377
Validation loss: 3.075464736804628

Epoch: 6| Step: 10
Training loss: 2.662450039533643
Validation loss: 3.0758302625031133

Epoch: 6| Step: 11
Training loss: 4.001475538852776
Validation loss: 3.074971395606788

Epoch: 6| Step: 12
Training loss: 3.583063440730612
Validation loss: 3.071485827772909

Epoch: 6| Step: 13
Training loss: 3.445968738434034
Validation loss: 3.073282750123859

Epoch: 58| Step: 0
Training loss: 3.040417523573262
Validation loss: 3.0719856071127523

Epoch: 6| Step: 1
Training loss: 3.3373328692133244
Validation loss: 3.0719308552827616

Epoch: 6| Step: 2
Training loss: 3.223206333260789
Validation loss: 3.07740538998037

Epoch: 6| Step: 3
Training loss: 3.0731237999023677
Validation loss: 3.085953521790768

Epoch: 6| Step: 4
Training loss: 3.436343882954875
Validation loss: 3.0725212770225268

Epoch: 6| Step: 5
Training loss: 2.694449289280402
Validation loss: 3.071092577622849

Epoch: 6| Step: 6
Training loss: 4.073768364068093
Validation loss: 3.0698972595169196

Epoch: 6| Step: 7
Training loss: 3.4207693604323794
Validation loss: 3.0717678074191026

Epoch: 6| Step: 8
Training loss: 3.413084959540275
Validation loss: 3.0715279902392614

Epoch: 6| Step: 9
Training loss: 3.052579420651454
Validation loss: 3.0693675362416357

Epoch: 6| Step: 10
Training loss: 3.045083169537314
Validation loss: 3.07036469397505

Epoch: 6| Step: 11
Training loss: 4.148299335255103
Validation loss: 3.068485203356687

Epoch: 6| Step: 12
Training loss: 3.5146948368012554
Validation loss: 3.072048424305564

Epoch: 6| Step: 13
Training loss: 2.746124918558669
Validation loss: 3.0744119439531628

Epoch: 59| Step: 0
Training loss: 4.05219970117625
Validation loss: 3.0697349404441114

Epoch: 6| Step: 1
Training loss: 3.628167708586644
Validation loss: 3.068916321272607

Epoch: 6| Step: 2
Training loss: 3.706191455192117
Validation loss: 3.0676015051860497

Epoch: 6| Step: 3
Training loss: 2.8232974162814037
Validation loss: 3.0683666255350355

Epoch: 6| Step: 4
Training loss: 2.817144162336084
Validation loss: 3.067844433743144

Epoch: 6| Step: 5
Training loss: 2.644875440639234
Validation loss: 3.0686860314473323

Epoch: 6| Step: 6
Training loss: 4.102872744590159
Validation loss: 3.066036686006112

Epoch: 6| Step: 7
Training loss: 3.88724956625744
Validation loss: 3.0652718446868996

Epoch: 6| Step: 8
Training loss: 2.666258323717247
Validation loss: 3.0654840670510284

Epoch: 6| Step: 9
Training loss: 3.535290322474884
Validation loss: 3.0641466618845192

Epoch: 6| Step: 10
Training loss: 3.0966844609806317
Validation loss: 3.0643888353162936

Epoch: 6| Step: 11
Training loss: 3.429096005817606
Validation loss: 3.063263031909176

Epoch: 6| Step: 12
Training loss: 2.9554831157338213
Validation loss: 3.0647741232357175

Epoch: 6| Step: 13
Training loss: 2.3135667350976163
Validation loss: 3.0638572576650005

Epoch: 60| Step: 0
Training loss: 3.74945712928462
Validation loss: 3.062893051831438

Epoch: 6| Step: 1
Training loss: 2.6071254147358585
Validation loss: 3.0623270814289874

Epoch: 6| Step: 2
Training loss: 3.288288088714601
Validation loss: 3.0616319877382554

Epoch: 6| Step: 3
Training loss: 2.794984743489508
Validation loss: 3.0646355327752834

Epoch: 6| Step: 4
Training loss: 3.721749898888356
Validation loss: 3.0620925729409545

Epoch: 6| Step: 5
Training loss: 3.6083627577735324
Validation loss: 3.0626525254949164

Epoch: 6| Step: 6
Training loss: 2.8546523820192133
Validation loss: 3.060214020106965

Epoch: 6| Step: 7
Training loss: 3.2526430973179754
Validation loss: 3.059178147763069

Epoch: 6| Step: 8
Training loss: 3.0783790444816743
Validation loss: 3.0601048733485525

Epoch: 6| Step: 9
Training loss: 3.5824581378585956
Validation loss: 3.058206471291014

Epoch: 6| Step: 10
Training loss: 3.6847774994342486
Validation loss: 3.058506442639497

Epoch: 6| Step: 11
Training loss: 3.441471649137387
Validation loss: 3.058636614033001

Epoch: 6| Step: 12
Training loss: 3.228059213712079
Validation loss: 3.0577857385955682

Epoch: 6| Step: 13
Training loss: 3.6133609577357024
Validation loss: 3.057795668562211

Epoch: 61| Step: 0
Training loss: 2.906022257751793
Validation loss: 3.0559467638250863

Epoch: 6| Step: 1
Training loss: 2.8595320861691786
Validation loss: 3.0567576851226708

Epoch: 6| Step: 2
Training loss: 4.096960774214127
Validation loss: 3.05890934898399

Epoch: 6| Step: 3
Training loss: 3.6454684410963285
Validation loss: 3.0593478848975457

Epoch: 6| Step: 4
Training loss: 3.135157594507016
Validation loss: 3.0563488534243493

Epoch: 6| Step: 5
Training loss: 2.6661769496748597
Validation loss: 3.055352904261045

Epoch: 6| Step: 6
Training loss: 3.1786588837423775
Validation loss: 3.0556514509285804

Epoch: 6| Step: 7
Training loss: 3.5041690247324033
Validation loss: 3.0551835191295447

Epoch: 6| Step: 8
Training loss: 3.5390258517694084
Validation loss: 3.053770294095827

Epoch: 6| Step: 9
Training loss: 3.2907327864365583
Validation loss: 3.054971666255186

Epoch: 6| Step: 10
Training loss: 3.420257046503984
Validation loss: 3.0559012320659242

Epoch: 6| Step: 11
Training loss: 3.962036822953314
Validation loss: 3.058208394310216

Epoch: 6| Step: 12
Training loss: 2.8558795179497545
Validation loss: 3.0580862994725106

Epoch: 6| Step: 13
Training loss: 3.0322764123821013
Validation loss: 3.0651858725379997

Epoch: 62| Step: 0
Training loss: 3.660600861177842
Validation loss: 3.0601240119694815

Epoch: 6| Step: 1
Training loss: 3.2853220059810573
Validation loss: 3.0572741272964374

Epoch: 6| Step: 2
Training loss: 3.4464015493738347
Validation loss: 3.052217552736191

Epoch: 6| Step: 3
Training loss: 2.8603368923531276
Validation loss: 3.0521541258122937

Epoch: 6| Step: 4
Training loss: 2.93690565873806
Validation loss: 3.0517927938183274

Epoch: 6| Step: 5
Training loss: 3.637104083665668
Validation loss: 3.050902884281232

Epoch: 6| Step: 6
Training loss: 3.376414249948584
Validation loss: 3.0507030334441634

Epoch: 6| Step: 7
Training loss: 3.2359656509066435
Validation loss: 3.0489310883713348

Epoch: 6| Step: 8
Training loss: 3.4670672759864094
Validation loss: 3.0476774544668026

Epoch: 6| Step: 9
Training loss: 3.0855097607038027
Validation loss: 3.05072428567525

Epoch: 6| Step: 10
Training loss: 3.1853705380186996
Validation loss: 3.0495554149625024

Epoch: 6| Step: 11
Training loss: 2.78931090373375
Validation loss: 3.0482612226756083

Epoch: 6| Step: 12
Training loss: 3.8150143696325616
Validation loss: 3.048097250154935

Epoch: 6| Step: 13
Training loss: 3.7382067570294693
Validation loss: 3.0474126223155658

Epoch: 63| Step: 0
Training loss: 3.5364397111195465
Validation loss: 3.0467659997282412

Epoch: 6| Step: 1
Training loss: 3.001434618932839
Validation loss: 3.047970085563858

Epoch: 6| Step: 2
Training loss: 3.2634360538118923
Validation loss: 3.0491464633965855

Epoch: 6| Step: 3
Training loss: 2.8441703401890734
Validation loss: 3.0478567850742433

Epoch: 6| Step: 4
Training loss: 3.197860783555691
Validation loss: 3.0489522201028527

Epoch: 6| Step: 5
Training loss: 3.219569129785805
Validation loss: 3.0507448369209

Epoch: 6| Step: 6
Training loss: 3.4334140422433226
Validation loss: 3.0477727778429817

Epoch: 6| Step: 7
Training loss: 3.4546360489953303
Validation loss: 3.045359669014493

Epoch: 6| Step: 8
Training loss: 3.594269557382007
Validation loss: 3.046929963959465

Epoch: 6| Step: 9
Training loss: 2.7877376198523227
Validation loss: 3.045617617427903

Epoch: 6| Step: 10
Training loss: 3.0692326245836425
Validation loss: 3.0454631065691005

Epoch: 6| Step: 11
Training loss: 3.672801318911526
Validation loss: 3.0459934420185886

Epoch: 6| Step: 12
Training loss: 3.685151208805779
Validation loss: 3.045027846423171

Epoch: 6| Step: 13
Training loss: 3.6836025525146683
Validation loss: 3.046090832082951

Epoch: 64| Step: 0
Training loss: 4.160551441030027
Validation loss: 3.0434311623057275

Epoch: 6| Step: 1
Training loss: 3.4098758822587176
Validation loss: 3.044353242338724

Epoch: 6| Step: 2
Training loss: 2.6826954855530634
Validation loss: 3.0427026932611336

Epoch: 6| Step: 3
Training loss: 3.257745902206353
Validation loss: 3.0430797801125475

Epoch: 6| Step: 4
Training loss: 3.1801949360916493
Validation loss: 3.041492434130368

Epoch: 6| Step: 5
Training loss: 2.937420133763015
Validation loss: 3.042246942014047

Epoch: 6| Step: 6
Training loss: 3.726177075685646
Validation loss: 3.042207966129284

Epoch: 6| Step: 7
Training loss: 3.5717188362966983
Validation loss: 3.043602734484433

Epoch: 6| Step: 8
Training loss: 3.2071421670260585
Validation loss: 3.042099396966708

Epoch: 6| Step: 9
Training loss: 3.209427898680482
Validation loss: 3.042146032781915

Epoch: 6| Step: 10
Training loss: 2.6902076034133295
Validation loss: 3.0437030765794044

Epoch: 6| Step: 11
Training loss: 3.5831242581667317
Validation loss: 3.042175042864644

Epoch: 6| Step: 12
Training loss: 3.1244608604749935
Validation loss: 3.0388213157720987

Epoch: 6| Step: 13
Training loss: 3.4443587801819096
Validation loss: 3.037603666574865

Epoch: 65| Step: 0
Training loss: 2.9422244774130135
Validation loss: 3.0373208093076083

Epoch: 6| Step: 1
Training loss: 4.118231566800605
Validation loss: 3.037330733592608

Epoch: 6| Step: 2
Training loss: 3.435026909113378
Validation loss: 3.0361510805408645

Epoch: 6| Step: 3
Training loss: 3.221918120960529
Validation loss: 3.037467583795997

Epoch: 6| Step: 4
Training loss: 3.3132611245999244
Validation loss: 3.0354086931588022

Epoch: 6| Step: 5
Training loss: 2.98890813098876
Validation loss: 3.037424561977345

Epoch: 6| Step: 6
Training loss: 3.252799515651999
Validation loss: 3.0361884370123424

Epoch: 6| Step: 7
Training loss: 3.2801109153323345
Validation loss: 3.0361453649821404

Epoch: 6| Step: 8
Training loss: 2.9601695491585653
Validation loss: 3.0332175980424236

Epoch: 6| Step: 9
Training loss: 3.3055842921043523
Validation loss: 3.035093201391165

Epoch: 6| Step: 10
Training loss: 3.285583250619733
Validation loss: 3.035150383064792

Epoch: 6| Step: 11
Training loss: 3.1856862311927143
Validation loss: 3.0356390034864935

Epoch: 6| Step: 12
Training loss: 4.0901035055107124
Validation loss: 3.036185690303127

Epoch: 6| Step: 13
Training loss: 2.0053545085257376
Validation loss: 3.0336539695936247

Epoch: 66| Step: 0
Training loss: 3.028531458043386
Validation loss: 3.0328861696914955

Epoch: 6| Step: 1
Training loss: 3.062549201414401
Validation loss: 3.033467881839174

Epoch: 6| Step: 2
Training loss: 3.963160867064008
Validation loss: 3.0314794871541806

Epoch: 6| Step: 3
Training loss: 3.420379032970909
Validation loss: 3.032075254355391

Epoch: 6| Step: 4
Training loss: 3.9199554487538304
Validation loss: 3.033180636033684

Epoch: 6| Step: 5
Training loss: 3.259998201241026
Validation loss: 3.030429796357556

Epoch: 6| Step: 6
Training loss: 3.257309250417658
Validation loss: 3.031298311502074

Epoch: 6| Step: 7
Training loss: 3.4949459642590783
Validation loss: 3.030669435520686

Epoch: 6| Step: 8
Training loss: 3.6545166080048936
Validation loss: 3.0302387644412536

Epoch: 6| Step: 9
Training loss: 3.2383598805856217
Validation loss: 3.0278553164557542

Epoch: 6| Step: 10
Training loss: 2.456012848332748
Validation loss: 3.028261268077867

Epoch: 6| Step: 11
Training loss: 2.865750235813041
Validation loss: 3.027417822866774

Epoch: 6| Step: 12
Training loss: 2.8519171507306007
Validation loss: 3.028232778262589

Epoch: 6| Step: 13
Training loss: 3.539354055491899
Validation loss: 3.0283654581115202

Epoch: 67| Step: 0
Training loss: 2.495332174874493
Validation loss: 3.0260702959990637

Epoch: 6| Step: 1
Training loss: 3.1992685316448886
Validation loss: 3.0269460541123756

Epoch: 6| Step: 2
Training loss: 3.2977337193466396
Validation loss: 3.0386971882770593

Epoch: 6| Step: 3
Training loss: 3.6790323828401967
Validation loss: 3.0371454003636797

Epoch: 6| Step: 4
Training loss: 3.4292165654485256
Validation loss: 3.0276640628297

Epoch: 6| Step: 5
Training loss: 2.4614025826960497
Validation loss: 3.029352348303525

Epoch: 6| Step: 6
Training loss: 3.5743129363444024
Validation loss: 3.0273550144902943

Epoch: 6| Step: 7
Training loss: 3.501286134107795
Validation loss: 3.026501519592412

Epoch: 6| Step: 8
Training loss: 3.346667861583643
Validation loss: 3.0237016154698346

Epoch: 6| Step: 9
Training loss: 3.1500894079689616
Validation loss: 3.024179525964967

Epoch: 6| Step: 10
Training loss: 4.062240827069386
Validation loss: 3.0257815091277274

Epoch: 6| Step: 11
Training loss: 2.733790831154095
Validation loss: 3.0237042675385273

Epoch: 6| Step: 12
Training loss: 3.669402113606233
Validation loss: 3.0233966798881324

Epoch: 6| Step: 13
Training loss: 3.1347052357403604
Validation loss: 3.0229051765820625

Epoch: 68| Step: 0
Training loss: 3.9526313805264293
Validation loss: 3.022019721001826

Epoch: 6| Step: 1
Training loss: 4.042877225715249
Validation loss: 3.0219704247079084

Epoch: 6| Step: 2
Training loss: 3.643911294655158
Validation loss: 3.02246597238993

Epoch: 6| Step: 3
Training loss: 2.9341554472243905
Validation loss: 3.0207475309877405

Epoch: 6| Step: 4
Training loss: 3.073990732192673
Validation loss: 3.0208611464077535

Epoch: 6| Step: 5
Training loss: 3.3538498975710005
Validation loss: 3.0194089479754207

Epoch: 6| Step: 6
Training loss: 2.979287809741027
Validation loss: 3.019530467204004

Epoch: 6| Step: 7
Training loss: 2.851902437197231
Validation loss: 3.02196750813378

Epoch: 6| Step: 8
Training loss: 2.8042766301972875
Validation loss: 3.0203758111095556

Epoch: 6| Step: 9
Training loss: 3.5986110815999233
Validation loss: 3.0172272615169633

Epoch: 6| Step: 10
Training loss: 3.421547512600321
Validation loss: 3.0191335227386804

Epoch: 6| Step: 11
Training loss: 2.918671019177817
Validation loss: 3.0202007982239

Epoch: 6| Step: 12
Training loss: 3.1870016568637127
Validation loss: 3.022765195698092

Epoch: 6| Step: 13
Training loss: 2.8006144837086455
Validation loss: 3.0227155349943504

Epoch: 69| Step: 0
Training loss: 2.840434226836605
Validation loss: 3.0243596548314313

Epoch: 6| Step: 1
Training loss: 3.175429884275698
Validation loss: 3.0287111571019745

Epoch: 6| Step: 2
Training loss: 3.2298276327337363
Validation loss: 3.0200299398003945

Epoch: 6| Step: 3
Training loss: 3.2192557224638447
Validation loss: 3.016555362078692

Epoch: 6| Step: 4
Training loss: 3.574997780539084
Validation loss: 3.0147033214653844

Epoch: 6| Step: 5
Training loss: 3.2042018661913607
Validation loss: 3.016874056059701

Epoch: 6| Step: 6
Training loss: 3.678238958183127
Validation loss: 3.0167647859149707

Epoch: 6| Step: 7
Training loss: 3.481752512086395
Validation loss: 3.023077901823276

Epoch: 6| Step: 8
Training loss: 3.0932971353166834
Validation loss: 3.0239663826999488

Epoch: 6| Step: 9
Training loss: 3.3549426269173703
Validation loss: 3.021607018934935

Epoch: 6| Step: 10
Training loss: 3.249091975203238
Validation loss: 3.0165675838471886

Epoch: 6| Step: 11
Training loss: 3.3788859284070987
Validation loss: 3.0155576494064222

Epoch: 6| Step: 12
Training loss: 3.176824757210398
Validation loss: 3.0141608770760566

Epoch: 6| Step: 13
Training loss: 3.437852321255768
Validation loss: 3.0139417618316906

Epoch: 70| Step: 0
Training loss: 3.185206467001277
Validation loss: 3.016535100570342

Epoch: 6| Step: 1
Training loss: 3.6827807211850168
Validation loss: 3.0122344492156854

Epoch: 6| Step: 2
Training loss: 2.651270968270196
Validation loss: 3.0112829133353713

Epoch: 6| Step: 3
Training loss: 3.8829380068844284
Validation loss: 3.0126188914858862

Epoch: 6| Step: 4
Training loss: 3.7238962163835216
Validation loss: 3.0153199992215325

Epoch: 6| Step: 5
Training loss: 3.151456005924149
Validation loss: 3.014442910537989

Epoch: 6| Step: 6
Training loss: 3.0752641579900835
Validation loss: 3.0166747569731065

Epoch: 6| Step: 7
Training loss: 2.9296905924462844
Validation loss: 3.0233102173725444

Epoch: 6| Step: 8
Training loss: 2.9762113268893873
Validation loss: 3.0256584726442703

Epoch: 6| Step: 9
Training loss: 3.4211990873362557
Validation loss: 3.017697782713003

Epoch: 6| Step: 10
Training loss: 2.312411332363675
Validation loss: 3.0168152949349594

Epoch: 6| Step: 11
Training loss: 3.513534534732484
Validation loss: 3.00705656458841

Epoch: 6| Step: 12
Training loss: 3.451979779516873
Validation loss: 3.008168265082577

Epoch: 6| Step: 13
Training loss: 3.95343872755377
Validation loss: 3.007671361519597

Epoch: 71| Step: 0
Training loss: 2.8256379884026024
Validation loss: 3.005281893439696

Epoch: 6| Step: 1
Training loss: 3.8043511024603154
Validation loss: 3.0073079344805747

Epoch: 6| Step: 2
Training loss: 2.4900516936669788
Validation loss: 3.007783844620474

Epoch: 6| Step: 3
Training loss: 3.7851587695102555
Validation loss: 3.0063816476559078

Epoch: 6| Step: 4
Training loss: 2.719724984570907
Validation loss: 3.0060708769533213

Epoch: 6| Step: 5
Training loss: 3.2970991736396753
Validation loss: 3.0078740356952207

Epoch: 6| Step: 6
Training loss: 3.5907142090235737
Validation loss: 3.0051096075369688

Epoch: 6| Step: 7
Training loss: 2.394276043732236
Validation loss: 3.006038384294267

Epoch: 6| Step: 8
Training loss: 3.251962216109665
Validation loss: 3.003795142573727

Epoch: 6| Step: 9
Training loss: 2.9949232697250405
Validation loss: 3.003928010822981

Epoch: 6| Step: 10
Training loss: 3.895777098441931
Validation loss: 3.0044818337772035

Epoch: 6| Step: 11
Training loss: 3.3166860365821167
Validation loss: 3.0032679659512542

Epoch: 6| Step: 12
Training loss: 3.6527419255716795
Validation loss: 3.0014515393673267

Epoch: 6| Step: 13
Training loss: 3.6250895785082986
Validation loss: 3.002248476885506

Epoch: 72| Step: 0
Training loss: 3.0610492929292525
Validation loss: 3.002381367472418

Epoch: 6| Step: 1
Training loss: 3.4235175384121272
Validation loss: 3.0014967466105316

Epoch: 6| Step: 2
Training loss: 3.4397764124399313
Validation loss: 3.0014058035806417

Epoch: 6| Step: 3
Training loss: 3.0062740206006633
Validation loss: 3.001179025917707

Epoch: 6| Step: 4
Training loss: 2.6501918147500687
Validation loss: 3.0001391734037077

Epoch: 6| Step: 5
Training loss: 2.8880298409122287
Validation loss: 2.999040184332597

Epoch: 6| Step: 6
Training loss: 3.7642923743338232
Validation loss: 3.0007378634710746

Epoch: 6| Step: 7
Training loss: 3.4817344342166816
Validation loss: 2.9996887476259477

Epoch: 6| Step: 8
Training loss: 3.61473524377213
Validation loss: 3.002595042315593

Epoch: 6| Step: 9
Training loss: 2.9883303968589243
Validation loss: 3.003144269176745

Epoch: 6| Step: 10
Training loss: 3.292443646504109
Validation loss: 3.011457893701654

Epoch: 6| Step: 11
Training loss: 3.284580248254952
Validation loss: 3.0164879124252484

Epoch: 6| Step: 12
Training loss: 3.9287424942027434
Validation loss: 3.0192085968960094

Epoch: 6| Step: 13
Training loss: 2.4420667075403877
Validation loss: 2.998615290559478

Epoch: 73| Step: 0
Training loss: 3.6213110207369836
Validation loss: 2.998459554220057

Epoch: 6| Step: 1
Training loss: 2.7063986299151033
Validation loss: 3.0001897358798577

Epoch: 6| Step: 2
Training loss: 2.987744251944409
Validation loss: 3.0097078417887637

Epoch: 6| Step: 3
Training loss: 3.8059194086134878
Validation loss: 3.0257877144947387

Epoch: 6| Step: 4
Training loss: 3.5242374975255064
Validation loss: 3.004567518143412

Epoch: 6| Step: 5
Training loss: 3.352846126567323
Validation loss: 3.000576216895334

Epoch: 6| Step: 6
Training loss: 3.908531926253447
Validation loss: 2.9970178292094265

Epoch: 6| Step: 7
Training loss: 2.5958059963625852
Validation loss: 2.9960204138190463

Epoch: 6| Step: 8
Training loss: 2.922080945595502
Validation loss: 2.994693591351968

Epoch: 6| Step: 9
Training loss: 2.9901087140888896
Validation loss: 2.9951083148127142

Epoch: 6| Step: 10
Training loss: 3.1483869146254198
Validation loss: 2.9954092097241407

Epoch: 6| Step: 11
Training loss: 3.1507759591721944
Validation loss: 2.999614414778203

Epoch: 6| Step: 12
Training loss: 4.0339478920411365
Validation loss: 3.0045230183811764

Epoch: 6| Step: 13
Training loss: 2.396679560167261
Validation loss: 3.0008970725900164

Epoch: 74| Step: 0
Training loss: 2.8283932384769983
Validation loss: 3.005978697519903

Epoch: 6| Step: 1
Training loss: 2.601935649149389
Validation loss: 2.9991431858537547

Epoch: 6| Step: 2
Training loss: 2.551595794404447
Validation loss: 3.000445715632359

Epoch: 6| Step: 3
Training loss: 3.206431845105573
Validation loss: 3.007387944571726

Epoch: 6| Step: 4
Training loss: 3.205169174323745
Validation loss: 3.0046448435838347

Epoch: 6| Step: 5
Training loss: 3.383876289685615
Validation loss: 2.999779561533838

Epoch: 6| Step: 6
Training loss: 2.8769121859888447
Validation loss: 2.9953453852525884

Epoch: 6| Step: 7
Training loss: 3.341884484806445
Validation loss: 2.990109521734826

Epoch: 6| Step: 8
Training loss: 3.4818097580545926
Validation loss: 2.9910560545769025

Epoch: 6| Step: 9
Training loss: 3.6632293860208827
Validation loss: 2.989149522572486

Epoch: 6| Step: 10
Training loss: 3.303087645349255
Validation loss: 2.989217095961192

Epoch: 6| Step: 11
Training loss: 3.7915934181823494
Validation loss: 2.9891863343495393

Epoch: 6| Step: 12
Training loss: 3.6851069557268596
Validation loss: 2.9889988333027384

Epoch: 6| Step: 13
Training loss: 3.7954701779977555
Validation loss: 2.989400760243374

Epoch: 75| Step: 0
Training loss: 3.645503757657469
Validation loss: 2.9859538768960703

Epoch: 6| Step: 1
Training loss: 3.575697829423816
Validation loss: 2.9874428029865867

Epoch: 6| Step: 2
Training loss: 3.1792134299449115
Validation loss: 2.987920802988309

Epoch: 6| Step: 3
Training loss: 3.7098663390315028
Validation loss: 2.9857352005299735

Epoch: 6| Step: 4
Training loss: 3.1224481463192686
Validation loss: 2.9855051304494538

Epoch: 6| Step: 5
Training loss: 3.0909463528309744
Validation loss: 2.984434821619114

Epoch: 6| Step: 6
Training loss: 3.1247787397256164
Validation loss: 2.983767622411025

Epoch: 6| Step: 7
Training loss: 2.55885930903595
Validation loss: 2.9843037141544437

Epoch: 6| Step: 8
Training loss: 2.8564775305341175
Validation loss: 2.986894693768064

Epoch: 6| Step: 9
Training loss: 3.298752814924478
Validation loss: 2.988167143950183

Epoch: 6| Step: 10
Training loss: 3.319263678558522
Validation loss: 2.9892089296023454

Epoch: 6| Step: 11
Training loss: 2.8699962360742854
Validation loss: 2.9877708746125182

Epoch: 6| Step: 12
Training loss: 3.8611005253879207
Validation loss: 2.9924732475460107

Epoch: 6| Step: 13
Training loss: 3.2662136879678814
Validation loss: 2.990393365762757

Epoch: 76| Step: 0
Training loss: 3.434421895117446
Validation loss: 2.9840503849597457

Epoch: 6| Step: 1
Training loss: 3.928020753288995
Validation loss: 2.9827240875278487

Epoch: 6| Step: 2
Training loss: 3.7680210705469706
Validation loss: 2.982694849895282

Epoch: 6| Step: 3
Training loss: 2.553840613491741
Validation loss: 2.9828144484543424

Epoch: 6| Step: 4
Training loss: 2.759721738084344
Validation loss: 2.981501072507619

Epoch: 6| Step: 5
Training loss: 2.6830729016591546
Validation loss: 2.981578205121875

Epoch: 6| Step: 6
Training loss: 3.0230681122259266
Validation loss: 2.9832571734782274

Epoch: 6| Step: 7
Training loss: 2.5931153957348148
Validation loss: 2.987435405820818

Epoch: 6| Step: 8
Training loss: 2.462871070439322
Validation loss: 2.997898671624114

Epoch: 6| Step: 9
Training loss: 4.437750795826022
Validation loss: 3.036445722481828

Epoch: 6| Step: 10
Training loss: 3.7204161686013477
Validation loss: 2.9808253076859677

Epoch: 6| Step: 11
Training loss: 2.8059793116594673
Validation loss: 2.9796413339222854

Epoch: 6| Step: 12
Training loss: 3.6129412846823983
Validation loss: 2.981582473298703

Epoch: 6| Step: 13
Training loss: 3.051229485517439
Validation loss: 2.990952254274565

Epoch: 77| Step: 0
Training loss: 3.8863776742619796
Validation loss: 3.0260413331550926

Epoch: 6| Step: 1
Training loss: 3.550357403024234
Validation loss: 2.9963987228698676

Epoch: 6| Step: 2
Training loss: 3.6397863903876786
Validation loss: 2.9914575714229676

Epoch: 6| Step: 3
Training loss: 3.9683038656034375
Validation loss: 2.9875977951411463

Epoch: 6| Step: 4
Training loss: 3.2475535648383294
Validation loss: 2.983354812130444

Epoch: 6| Step: 5
Training loss: 2.586057631361565
Validation loss: 2.9819062866333375

Epoch: 6| Step: 6
Training loss: 2.6995991550583844
Validation loss: 2.977737418375039

Epoch: 6| Step: 7
Training loss: 3.2550505495614344
Validation loss: 2.981187871545868

Epoch: 6| Step: 8
Training loss: 3.7592047572730714
Validation loss: 2.980139710206443

Epoch: 6| Step: 9
Training loss: 3.13975550823456
Validation loss: 2.9870361745526903

Epoch: 6| Step: 10
Training loss: 2.7808288941211226
Validation loss: 2.9938819705623287

Epoch: 6| Step: 11
Training loss: 2.87111434410131
Validation loss: 2.9955290734612023

Epoch: 6| Step: 12
Training loss: 3.0347508929363105
Validation loss: 3.0089605719966417

Epoch: 6| Step: 13
Training loss: 2.7915318774426203
Validation loss: 2.993777485561017

Epoch: 78| Step: 0
Training loss: 3.4663635842786436
Validation loss: 2.98242654425392

Epoch: 6| Step: 1
Training loss: 3.570696720342481
Validation loss: 2.9813888291492763

Epoch: 6| Step: 2
Training loss: 3.422087222969176
Validation loss: 2.9760968200901616

Epoch: 6| Step: 3
Training loss: 3.2346322514788493
Validation loss: 2.9771889087286936

Epoch: 6| Step: 4
Training loss: 2.395180444629424
Validation loss: 2.974068024024724

Epoch: 6| Step: 5
Training loss: 2.6495745083363538
Validation loss: 2.9754244822716065

Epoch: 6| Step: 6
Training loss: 3.2501003543325275
Validation loss: 2.9736134836139287

Epoch: 6| Step: 7
Training loss: 3.0640956847685876
Validation loss: 2.974131307795289

Epoch: 6| Step: 8
Training loss: 3.1651986048669922
Validation loss: 2.9764992868678206

Epoch: 6| Step: 9
Training loss: 3.3638627704838764
Validation loss: 2.9723847086398303

Epoch: 6| Step: 10
Training loss: 3.357253287333999
Validation loss: 2.9732278331439272

Epoch: 6| Step: 11
Training loss: 3.3815440559501133
Validation loss: 2.9678301799770646

Epoch: 6| Step: 12
Training loss: 3.0382995432280673
Validation loss: 2.969567967385358

Epoch: 6| Step: 13
Training loss: 4.384645129886689
Validation loss: 2.9700686813461616

Epoch: 79| Step: 0
Training loss: 2.9626007642389216
Validation loss: 2.9666696043323753

Epoch: 6| Step: 1
Training loss: 3.444949868422945
Validation loss: 2.9658335714272663

Epoch: 6| Step: 2
Training loss: 3.224759168282247
Validation loss: 2.968875493331654

Epoch: 6| Step: 3
Training loss: 3.209663082516837
Validation loss: 2.9668461444492324

Epoch: 6| Step: 4
Training loss: 3.2962818064075496
Validation loss: 2.9671032589736344

Epoch: 6| Step: 5
Training loss: 3.5037157225931006
Validation loss: 2.966646818399025

Epoch: 6| Step: 6
Training loss: 3.090032636846631
Validation loss: 2.966799785323082

Epoch: 6| Step: 7
Training loss: 3.2353938612632622
Validation loss: 2.9672841812614905

Epoch: 6| Step: 8
Training loss: 3.196222077905267
Validation loss: 2.9666237799556536

Epoch: 6| Step: 9
Training loss: 3.8031258325254584
Validation loss: 2.96500937912141

Epoch: 6| Step: 10
Training loss: 3.3689192635613177
Validation loss: 2.9648817507063177

Epoch: 6| Step: 11
Training loss: 3.1265965770139754
Validation loss: 2.966019242045761

Epoch: 6| Step: 12
Training loss: 3.166550249335605
Validation loss: 2.966071737098364

Epoch: 6| Step: 13
Training loss: 2.4641932673518743
Validation loss: 2.9633520960218713

Epoch: 80| Step: 0
Training loss: 3.6345113740166566
Validation loss: 2.9642894323477225

Epoch: 6| Step: 1
Training loss: 3.741616223398092
Validation loss: 2.96937612980557

Epoch: 6| Step: 2
Training loss: 3.2173034973131216
Validation loss: 2.96859608171866

Epoch: 6| Step: 3
Training loss: 2.868741728993047
Validation loss: 2.9690212330944132

Epoch: 6| Step: 4
Training loss: 3.8667171924403103
Validation loss: 2.9646939179491274

Epoch: 6| Step: 5
Training loss: 2.6487882038725954
Validation loss: 2.9631542012566143

Epoch: 6| Step: 6
Training loss: 3.01486639255029
Validation loss: 2.9638928482981006

Epoch: 6| Step: 7
Training loss: 2.7648080599837352
Validation loss: 2.9633608704387506

Epoch: 6| Step: 8
Training loss: 4.205438253854457
Validation loss: 2.9632915477279016

Epoch: 6| Step: 9
Training loss: 2.402038554832663
Validation loss: 2.9635408563939163

Epoch: 6| Step: 10
Training loss: 2.5060514642556333
Validation loss: 2.9627138214947837

Epoch: 6| Step: 11
Training loss: 3.7140326832949393
Validation loss: 2.9622690768048687

Epoch: 6| Step: 12
Training loss: 3.4073505548519516
Validation loss: 2.9620955284959427

Epoch: 6| Step: 13
Training loss: 2.6548361212949882
Validation loss: 2.961412676157217

Epoch: 81| Step: 0
Training loss: 4.008520112209771
Validation loss: 2.9615794484954536

Epoch: 6| Step: 1
Training loss: 3.227451894624721
Validation loss: 2.960581402945256

Epoch: 6| Step: 2
Training loss: 2.7041588718985747
Validation loss: 2.9594256319751095

Epoch: 6| Step: 3
Training loss: 2.8351508276375883
Validation loss: 2.9580109741400746

Epoch: 6| Step: 4
Training loss: 3.10101943942967
Validation loss: 2.9580191243611296

Epoch: 6| Step: 5
Training loss: 3.69979799080024
Validation loss: 2.959259055326221

Epoch: 6| Step: 6
Training loss: 2.4958652636523952
Validation loss: 2.9665779341309038

Epoch: 6| Step: 7
Training loss: 3.4240963488597127
Validation loss: 2.9701720151823747

Epoch: 6| Step: 8
Training loss: 4.186194372892486
Validation loss: 2.959121123166464

Epoch: 6| Step: 9
Training loss: 2.9409104698170414
Validation loss: 2.9590883575507316

Epoch: 6| Step: 10
Training loss: 3.635407864069005
Validation loss: 2.95777373254614

Epoch: 6| Step: 11
Training loss: 2.3621263440650093
Validation loss: 2.9573150076840076

Epoch: 6| Step: 12
Training loss: 3.1760617140532093
Validation loss: 2.9571405574441423

Epoch: 6| Step: 13
Training loss: 2.861186636593528
Validation loss: 2.9560365497622354

Epoch: 82| Step: 0
Training loss: 3.2456618479593384
Validation loss: 2.953884629742556

Epoch: 6| Step: 1
Training loss: 3.0367413362213176
Validation loss: 2.955676918422688

Epoch: 6| Step: 2
Training loss: 3.3261334545270755
Validation loss: 2.953817615888506

Epoch: 6| Step: 3
Training loss: 2.8081215579574073
Validation loss: 2.9562153500073345

Epoch: 6| Step: 4
Training loss: 3.0488179589736824
Validation loss: 2.95578262535902

Epoch: 6| Step: 5
Training loss: 3.2272205189818077
Validation loss: 2.9548565650065868

Epoch: 6| Step: 6
Training loss: 4.157039710718932
Validation loss: 2.9569661229218513

Epoch: 6| Step: 7
Training loss: 3.1505002063629464
Validation loss: 2.955367045056858

Epoch: 6| Step: 8
Training loss: 3.2694447641544477
Validation loss: 2.9543801087657955

Epoch: 6| Step: 9
Training loss: 3.7467179240819184
Validation loss: 2.955909935469988

Epoch: 6| Step: 10
Training loss: 3.1204679050246718
Validation loss: 2.9515637130802994

Epoch: 6| Step: 11
Training loss: 2.925581921458122
Validation loss: 2.951219416913574

Epoch: 6| Step: 12
Training loss: 3.229897315929371
Validation loss: 2.950712283660321

Epoch: 6| Step: 13
Training loss: 2.5810387993741033
Validation loss: 2.953211368848023

Epoch: 83| Step: 0
Training loss: 3.0713722787812165
Validation loss: 2.951224442174781

Epoch: 6| Step: 1
Training loss: 2.51203501180073
Validation loss: 2.94932139228308

Epoch: 6| Step: 2
Training loss: 4.0858926861787195
Validation loss: 2.9509535158360762

Epoch: 6| Step: 3
Training loss: 2.5616539279453066
Validation loss: 2.951463721571459

Epoch: 6| Step: 4
Training loss: 3.659386487726151
Validation loss: 2.9509075064815544

Epoch: 6| Step: 5
Training loss: 3.521016373851681
Validation loss: 2.9531710685613

Epoch: 6| Step: 6
Training loss: 3.3034164834231334
Validation loss: 2.95215212124322

Epoch: 6| Step: 7
Training loss: 3.513360001705905
Validation loss: 2.953610175226305

Epoch: 6| Step: 8
Training loss: 3.7673123326735283
Validation loss: 2.9567386619370537

Epoch: 6| Step: 9
Training loss: 2.8231255617071493
Validation loss: 2.9569227309497204

Epoch: 6| Step: 10
Training loss: 3.24310422139726
Validation loss: 2.9619254131057793

Epoch: 6| Step: 11
Training loss: 2.8200649670631757
Validation loss: 2.966200010060296

Epoch: 6| Step: 12
Training loss: 3.2636303810572906
Validation loss: 2.9705644072622404

Epoch: 6| Step: 13
Training loss: 2.263900310848991
Validation loss: 2.9478093743062757

Epoch: 84| Step: 0
Training loss: 2.790508931684118
Validation loss: 2.94545281258431

Epoch: 6| Step: 1
Training loss: 3.511647869748389
Validation loss: 2.942388918427093

Epoch: 6| Step: 2
Training loss: 3.855670340078662
Validation loss: 2.9439038231627737

Epoch: 6| Step: 3
Training loss: 2.98560184207054
Validation loss: 2.9443472827316017

Epoch: 6| Step: 4
Training loss: 2.843286497468986
Validation loss: 2.9458534603687685

Epoch: 6| Step: 5
Training loss: 3.138735985946817
Validation loss: 2.9455689667040774

Epoch: 6| Step: 6
Training loss: 3.0857560889122118
Validation loss: 2.9476219269634325

Epoch: 6| Step: 7
Training loss: 3.426475741587912
Validation loss: 2.9497378104347276

Epoch: 6| Step: 8
Training loss: 2.4424579765898176
Validation loss: 2.95028592589487

Epoch: 6| Step: 9
Training loss: 3.687253135564465
Validation loss: 2.9512319440008277

Epoch: 6| Step: 10
Training loss: 3.364001685415383
Validation loss: 2.9480508318459187

Epoch: 6| Step: 11
Training loss: 2.9013578195847587
Validation loss: 2.94711518111462

Epoch: 6| Step: 12
Training loss: 3.0650536925449763
Validation loss: 2.942925895963138

Epoch: 6| Step: 13
Training loss: 4.306238909127137
Validation loss: 2.94287076750959

Epoch: 85| Step: 0
Training loss: 3.190334182024379
Validation loss: 2.9435336761174433

Epoch: 6| Step: 1
Training loss: 3.6922902174071512
Validation loss: 2.941275239693942

Epoch: 6| Step: 2
Training loss: 3.010331642155754
Validation loss: 2.941295025141393

Epoch: 6| Step: 3
Training loss: 3.4515852451222617
Validation loss: 2.940298244814885

Epoch: 6| Step: 4
Training loss: 3.332523788058179
Validation loss: 2.9387536377090284

Epoch: 6| Step: 5
Training loss: 3.296899009002478
Validation loss: 2.942546681849922

Epoch: 6| Step: 6
Training loss: 2.9281006444612245
Validation loss: 2.9402130137904448

Epoch: 6| Step: 7
Training loss: 3.1831776352864893
Validation loss: 2.935871808452296

Epoch: 6| Step: 8
Training loss: 3.2209770127820097
Validation loss: 2.941758130458029

Epoch: 6| Step: 9
Training loss: 3.371068006220503
Validation loss: 2.9396630873347136

Epoch: 6| Step: 10
Training loss: 3.1697205992592097
Validation loss: 2.942769205238968

Epoch: 6| Step: 11
Training loss: 3.479485198342335
Validation loss: 2.9443817300000164

Epoch: 6| Step: 12
Training loss: 2.76664551263405
Validation loss: 2.939228761380949

Epoch: 6| Step: 13
Training loss: 2.823439283428463
Validation loss: 2.9431199027279322

Epoch: 86| Step: 0
Training loss: 3.5689534411590653
Validation loss: 2.9410558546139502

Epoch: 6| Step: 1
Training loss: 3.217083397654369
Validation loss: 2.9442375081623435

Epoch: 6| Step: 2
Training loss: 3.1098709094372805
Validation loss: 2.9371038521915542

Epoch: 6| Step: 3
Training loss: 3.2311984325551526
Validation loss: 2.940586724327042

Epoch: 6| Step: 4
Training loss: 2.8205841863491177
Validation loss: 2.9379154540768884

Epoch: 6| Step: 5
Training loss: 2.8587385626240107
Validation loss: 2.938197811224884

Epoch: 6| Step: 6
Training loss: 3.6070459290772354
Validation loss: 2.9379336932165327

Epoch: 6| Step: 7
Training loss: 3.116166714910675
Validation loss: 2.940774967930394

Epoch: 6| Step: 8
Training loss: 3.6550812768835934
Validation loss: 2.937203053005366

Epoch: 6| Step: 9
Training loss: 2.969892101447169
Validation loss: 2.935302721601788

Epoch: 6| Step: 10
Training loss: 3.3680104535590747
Validation loss: 2.932715324131842

Epoch: 6| Step: 11
Training loss: 3.3507510183210845
Validation loss: 2.9322230186521887

Epoch: 6| Step: 12
Training loss: 2.5930435873267474
Validation loss: 2.930984207040295

Epoch: 6| Step: 13
Training loss: 3.6054805205742997
Validation loss: 2.9312440526450527

Epoch: 87| Step: 0
Training loss: 2.919516687762636
Validation loss: 2.9319712585964166

Epoch: 6| Step: 1
Training loss: 4.001359946811858
Validation loss: 2.930770290215866

Epoch: 6| Step: 2
Training loss: 3.4309924864590817
Validation loss: 2.9299550624068105

Epoch: 6| Step: 3
Training loss: 3.1404535806666174
Validation loss: 2.9287062465074567

Epoch: 6| Step: 4
Training loss: 2.9783283112207335
Validation loss: 2.929475888064938

Epoch: 6| Step: 5
Training loss: 3.0252908551072584
Validation loss: 2.9284104134354583

Epoch: 6| Step: 6
Training loss: 3.026028727746156
Validation loss: 2.9280365076672137

Epoch: 6| Step: 7
Training loss: 3.188749479849312
Validation loss: 2.927623730571325

Epoch: 6| Step: 8
Training loss: 3.026994057424236
Validation loss: 2.9293023485349514

Epoch: 6| Step: 9
Training loss: 3.252061336882005
Validation loss: 2.928464129795006

Epoch: 6| Step: 10
Training loss: 3.5370190512521837
Validation loss: 2.9299314895810404

Epoch: 6| Step: 11
Training loss: 3.0538525623238773
Validation loss: 2.927210511669346

Epoch: 6| Step: 12
Training loss: 3.5082099536455087
Validation loss: 2.927817453208569

Epoch: 6| Step: 13
Training loss: 2.3445155610039774
Validation loss: 2.9271722163423624

Epoch: 88| Step: 0
Training loss: 2.998726256492405
Validation loss: 2.9280511231770303

Epoch: 6| Step: 1
Training loss: 3.3665702944518108
Validation loss: 2.9274723841194974

Epoch: 6| Step: 2
Training loss: 3.9516456459502067
Validation loss: 2.9274724506740744

Epoch: 6| Step: 3
Training loss: 3.4614093536361663
Validation loss: 2.9276665874385914

Epoch: 6| Step: 4
Training loss: 3.239817292984119
Validation loss: 2.9277108210712566

Epoch: 6| Step: 5
Training loss: 3.137990881221595
Validation loss: 2.9246160234311662

Epoch: 6| Step: 6
Training loss: 2.9180630383967254
Validation loss: 2.92544952772281

Epoch: 6| Step: 7
Training loss: 2.3919241373413973
Validation loss: 2.9234920543687823

Epoch: 6| Step: 8
Training loss: 3.4822501644605808
Validation loss: 2.9292740016072267

Epoch: 6| Step: 9
Training loss: 2.9782655504650544
Validation loss: 2.943470976493359

Epoch: 6| Step: 10
Training loss: 3.311764761462703
Validation loss: 2.940037601976349

Epoch: 6| Step: 11
Training loss: 3.0422131992345913
Validation loss: 2.922710809583434

Epoch: 6| Step: 12
Training loss: 3.2396942479484743
Validation loss: 2.9255444670875392

Epoch: 6| Step: 13
Training loss: 3.365628689309651
Validation loss: 2.9228680019873554

Epoch: 89| Step: 0
Training loss: 2.8269198046854465
Validation loss: 2.9226141229425404

Epoch: 6| Step: 1
Training loss: 3.0966416533753054
Validation loss: 2.923701609155932

Epoch: 6| Step: 2
Training loss: 2.4774926782340096
Validation loss: 2.923169085330008

Epoch: 6| Step: 3
Training loss: 3.8943231004744163
Validation loss: 2.9454655078077967

Epoch: 6| Step: 4
Training loss: 3.451361849035258
Validation loss: 2.9346086685310926

Epoch: 6| Step: 5
Training loss: 3.6269535194113276
Validation loss: 2.9295779654422915

Epoch: 6| Step: 6
Training loss: 2.9220453712444865
Validation loss: 2.9269280063821914

Epoch: 6| Step: 7
Training loss: 2.94627660053919
Validation loss: 2.9229366998529245

Epoch: 6| Step: 8
Training loss: 3.3258851443500275
Validation loss: 2.920297759061513

Epoch: 6| Step: 9
Training loss: 3.2698375052578705
Validation loss: 2.921536673291172

Epoch: 6| Step: 10
Training loss: 2.9792868494365536
Validation loss: 2.922178368390322

Epoch: 6| Step: 11
Training loss: 2.9748969436875496
Validation loss: 2.9252854166169557

Epoch: 6| Step: 12
Training loss: 3.1859436723575416
Validation loss: 2.9259143673488905

Epoch: 6| Step: 13
Training loss: 4.088001670732549
Validation loss: 2.9179834677722924

Epoch: 90| Step: 0
Training loss: 2.7597296861601914
Validation loss: 2.9200888414475523

Epoch: 6| Step: 1
Training loss: 3.0650189997471524
Validation loss: 2.9189558658495462

Epoch: 6| Step: 2
Training loss: 2.8265177337829757
Validation loss: 2.918693209952445

Epoch: 6| Step: 3
Training loss: 3.4096052810563604
Validation loss: 2.917707270496241

Epoch: 6| Step: 4
Training loss: 3.2216053861923037
Validation loss: 2.9164050997218958

Epoch: 6| Step: 5
Training loss: 3.249504638480735
Validation loss: 2.9175112531310186

Epoch: 6| Step: 6
Training loss: 2.700197431622134
Validation loss: 2.919701586120799

Epoch: 6| Step: 7
Training loss: 3.6097825385874858
Validation loss: 2.915239884013458

Epoch: 6| Step: 8
Training loss: 3.8946365449344142
Validation loss: 2.915226346610999

Epoch: 6| Step: 9
Training loss: 2.9603940923064105
Validation loss: 2.9149452092539856

Epoch: 6| Step: 10
Training loss: 2.7293500668780357
Validation loss: 2.9157559521445187

Epoch: 6| Step: 11
Training loss: 3.563882927424208
Validation loss: 2.9170849237990573

Epoch: 6| Step: 12
Training loss: 2.6277948668849245
Validation loss: 2.9166938689643644

Epoch: 6| Step: 13
Training loss: 4.391333037605776
Validation loss: 2.9159597627183027

Epoch: 91| Step: 0
Training loss: 2.837031213964483
Validation loss: 2.9142005731764127

Epoch: 6| Step: 1
Training loss: 3.150036578495846
Validation loss: 2.9152462754325024

Epoch: 6| Step: 2
Training loss: 3.765526481384354
Validation loss: 2.912860271675569

Epoch: 6| Step: 3
Training loss: 2.674494123308704
Validation loss: 2.911581338230076

Epoch: 6| Step: 4
Training loss: 3.4740738437251553
Validation loss: 2.9127870842381354

Epoch: 6| Step: 5
Training loss: 2.1589678898128994
Validation loss: 2.910840121934832

Epoch: 6| Step: 6
Training loss: 3.3007984409223194
Validation loss: 2.911599986230883

Epoch: 6| Step: 7
Training loss: 3.22088122873033
Validation loss: 2.909785845172692

Epoch: 6| Step: 8
Training loss: 3.5617597379708634
Validation loss: 2.9104322090244525

Epoch: 6| Step: 9
Training loss: 3.6907700086202557
Validation loss: 2.911607771531165

Epoch: 6| Step: 10
Training loss: 4.018206171286005
Validation loss: 2.912419473407233

Epoch: 6| Step: 11
Training loss: 2.8112976047120166
Validation loss: 2.9138270752057025

Epoch: 6| Step: 12
Training loss: 2.3761563748492684
Validation loss: 2.9082219665578575

Epoch: 6| Step: 13
Training loss: 3.196086164981604
Validation loss: 2.9091172132941243

Epoch: 92| Step: 0
Training loss: 2.6598705076664375
Validation loss: 2.9108392447356897

Epoch: 6| Step: 1
Training loss: 2.621410640656714
Validation loss: 2.9099410117387894

Epoch: 6| Step: 2
Training loss: 3.301938187129792
Validation loss: 2.913209275543422

Epoch: 6| Step: 3
Training loss: 3.383817105087625
Validation loss: 2.9271869535252795

Epoch: 6| Step: 4
Training loss: 3.1843389656940575
Validation loss: 2.9216049567030637

Epoch: 6| Step: 5
Training loss: 3.6435383285363794
Validation loss: 2.9087652797519663

Epoch: 6| Step: 6
Training loss: 3.3979051194890366
Validation loss: 2.9108861190339494

Epoch: 6| Step: 7
Training loss: 2.536943414089385
Validation loss: 2.9078225882591275

Epoch: 6| Step: 8
Training loss: 3.701416909352528
Validation loss: 2.9073591123856133

Epoch: 6| Step: 9
Training loss: 3.8137665192662964
Validation loss: 2.9075352559929595

Epoch: 6| Step: 10
Training loss: 3.1037070597621454
Validation loss: 2.90834336271307

Epoch: 6| Step: 11
Training loss: 3.7657487144566786
Validation loss: 2.9110966781282013

Epoch: 6| Step: 12
Training loss: 2.39415375812829
Validation loss: 2.913658797030498

Epoch: 6| Step: 13
Training loss: 2.4950193382232353
Validation loss: 2.9123397521110195

Epoch: 93| Step: 0
Training loss: 3.9445906479175594
Validation loss: 2.9114206139095393

Epoch: 6| Step: 1
Training loss: 2.6686973191361645
Validation loss: 2.9092427366727196

Epoch: 6| Step: 2
Training loss: 3.2597264218358637
Validation loss: 2.906065233814139

Epoch: 6| Step: 3
Training loss: 2.663813336038735
Validation loss: 2.905732961747099

Epoch: 6| Step: 4
Training loss: 2.736628971266162
Validation loss: 2.904685841653075

Epoch: 6| Step: 5
Training loss: 2.7531279201253933
Validation loss: 2.9037980873203955

Epoch: 6| Step: 6
Training loss: 2.7716105716677126
Validation loss: 2.904435956142864

Epoch: 6| Step: 7
Training loss: 3.5441378480439356
Validation loss: 2.90408476003432

Epoch: 6| Step: 8
Training loss: 3.756200369254715
Validation loss: 2.901992965900321

Epoch: 6| Step: 9
Training loss: 3.108402425971365
Validation loss: 2.901097333126607

Epoch: 6| Step: 10
Training loss: 3.612684969802936
Validation loss: 2.9022560988037465

Epoch: 6| Step: 11
Training loss: 3.2142149448172903
Validation loss: 2.9043243323268806

Epoch: 6| Step: 12
Training loss: 3.188944769652884
Validation loss: 2.900804303415531

Epoch: 6| Step: 13
Training loss: 3.2519337696496065
Validation loss: 2.8999074442361152

Epoch: 94| Step: 0
Training loss: 2.701457838035529
Validation loss: 2.899940905041367

Epoch: 6| Step: 1
Training loss: 2.449182926871193
Validation loss: 2.901342314125288

Epoch: 6| Step: 2
Training loss: 3.571488535241411
Validation loss: 2.899327744559162

Epoch: 6| Step: 3
Training loss: 3.404316064427055
Validation loss: 2.900279163704697

Epoch: 6| Step: 4
Training loss: 3.241221529905108
Validation loss: 2.900794701250513

Epoch: 6| Step: 5
Training loss: 3.459543192702304
Validation loss: 2.8971757242187794

Epoch: 6| Step: 6
Training loss: 4.059879338017057
Validation loss: 2.897586137701848

Epoch: 6| Step: 7
Training loss: 3.292440460292382
Validation loss: 2.8980428656272017

Epoch: 6| Step: 8
Training loss: 2.1532609650268357
Validation loss: 2.902104932915796

Epoch: 6| Step: 9
Training loss: 2.7210439015372425
Validation loss: 2.9028308615155236

Epoch: 6| Step: 10
Training loss: 3.2554466384125784
Validation loss: 2.9065777693804473

Epoch: 6| Step: 11
Training loss: 3.477596789177921
Validation loss: 2.9084656572784198

Epoch: 6| Step: 12
Training loss: 3.0676083680700694
Validation loss: 2.9190225997956185

Epoch: 6| Step: 13
Training loss: 3.4727526416423875
Validation loss: 2.916586514146583

Epoch: 95| Step: 0
Training loss: 3.5337251074136518
Validation loss: 2.905030109973189

Epoch: 6| Step: 1
Training loss: 3.4345283841981553
Validation loss: 2.9005083220638994

Epoch: 6| Step: 2
Training loss: 2.98103185211435
Validation loss: 2.901261111454748

Epoch: 6| Step: 3
Training loss: 2.7669535748578618
Validation loss: 2.900103848782857

Epoch: 6| Step: 4
Training loss: 3.791094740327543
Validation loss: 2.901208305260221

Epoch: 6| Step: 5
Training loss: 3.128564099143364
Validation loss: 2.8932624400663682

Epoch: 6| Step: 6
Training loss: 2.8582457934024723
Validation loss: 2.892881581872269

Epoch: 6| Step: 7
Training loss: 3.1942942892710633
Validation loss: 2.8929367829618142

Epoch: 6| Step: 8
Training loss: 3.170791967241611
Validation loss: 2.8919346249193993

Epoch: 6| Step: 9
Training loss: 3.0150283460407463
Validation loss: 2.8922583340296724

Epoch: 6| Step: 10
Training loss: 2.73119583599933
Validation loss: 2.893028907974199

Epoch: 6| Step: 11
Training loss: 3.092189356652503
Validation loss: 2.8925199860729918

Epoch: 6| Step: 12
Training loss: 3.4278996354392484
Validation loss: 2.893241131270456

Epoch: 6| Step: 13
Training loss: 3.5032430337967155
Validation loss: 2.8932553018565224

Epoch: 96| Step: 0
Training loss: 2.9174369521466916
Validation loss: 2.890719019395414

Epoch: 6| Step: 1
Training loss: 2.9216334605211376
Validation loss: 2.892791656633265

Epoch: 6| Step: 2
Training loss: 3.5765761308922754
Validation loss: 2.8920620748084165

Epoch: 6| Step: 3
Training loss: 3.30727737704016
Validation loss: 2.8933888302487825

Epoch: 6| Step: 4
Training loss: 3.5632434537690005
Validation loss: 2.893056803657473

Epoch: 6| Step: 5
Training loss: 2.706472628204327
Validation loss: 2.8909294369417107

Epoch: 6| Step: 6
Training loss: 2.6042833734428124
Validation loss: 2.892200365510642

Epoch: 6| Step: 7
Training loss: 2.9852852756277555
Validation loss: 2.890996432088573

Epoch: 6| Step: 8
Training loss: 2.062322319931548
Validation loss: 2.8917113475841245

Epoch: 6| Step: 9
Training loss: 3.095244383892895
Validation loss: 2.893420159352402

Epoch: 6| Step: 10
Training loss: 3.473814008575346
Validation loss: 2.891797405281762

Epoch: 6| Step: 11
Training loss: 3.8864592652467573
Validation loss: 2.8908475684297947

Epoch: 6| Step: 12
Training loss: 3.85390316174111
Validation loss: 2.888748570066882

Epoch: 6| Step: 13
Training loss: 3.171926413434147
Validation loss: 2.889433439863786

Epoch: 97| Step: 0
Training loss: 3.8351935696646233
Validation loss: 2.8853921243214624

Epoch: 6| Step: 1
Training loss: 2.2633178539430325
Validation loss: 2.887785800810002

Epoch: 6| Step: 2
Training loss: 3.105722707285037
Validation loss: 2.888945388938224

Epoch: 6| Step: 3
Training loss: 3.742137422803965
Validation loss: 2.883172920507275

Epoch: 6| Step: 4
Training loss: 2.872863473231479
Validation loss: 2.888427354833949

Epoch: 6| Step: 5
Training loss: 2.6601245222846353
Validation loss: 2.890232444211168

Epoch: 6| Step: 6
Training loss: 2.9048964106725528
Validation loss: 2.886663387375537

Epoch: 6| Step: 7
Training loss: 3.7216347156411036
Validation loss: 2.889680542620728

Epoch: 6| Step: 8
Training loss: 3.0778222879189667
Validation loss: 2.8862590265817496

Epoch: 6| Step: 9
Training loss: 2.607636655040946
Validation loss: 2.890724087751518

Epoch: 6| Step: 10
Training loss: 3.523462807169024
Validation loss: 2.8857163399178214

Epoch: 6| Step: 11
Training loss: 3.438780944751545
Validation loss: 2.8877920026461084

Epoch: 6| Step: 12
Training loss: 2.800975244845107
Validation loss: 2.886210387099705

Epoch: 6| Step: 13
Training loss: 3.7804724784528396
Validation loss: 2.886023792544815

Epoch: 98| Step: 0
Training loss: 3.1968092269321353
Validation loss: 2.8858844885304054

Epoch: 6| Step: 1
Training loss: 3.739983469064663
Validation loss: 2.88601124979152

Epoch: 6| Step: 2
Training loss: 3.080086639721506
Validation loss: 2.8841858471718567

Epoch: 6| Step: 3
Training loss: 3.3040004584194356
Validation loss: 2.883489100340882

Epoch: 6| Step: 4
Training loss: 3.7780058003467403
Validation loss: 2.8818645855821465

Epoch: 6| Step: 5
Training loss: 3.0019572548971265
Validation loss: 2.88169492222947

Epoch: 6| Step: 6
Training loss: 3.7179118261690887
Validation loss: 2.8804468630502615

Epoch: 6| Step: 7
Training loss: 2.537372296507066
Validation loss: 2.88113146659932

Epoch: 6| Step: 8
Training loss: 3.0112706505371007
Validation loss: 2.8782079578902753

Epoch: 6| Step: 9
Training loss: 2.535291294915289
Validation loss: 2.8793410333279934

Epoch: 6| Step: 10
Training loss: 3.4735741962917035
Validation loss: 2.8816080610605144

Epoch: 6| Step: 11
Training loss: 2.61876583049059
Validation loss: 2.8801893826910634

Epoch: 6| Step: 12
Training loss: 2.927548698456772
Validation loss: 2.8825752184437046

Epoch: 6| Step: 13
Training loss: 3.241946291855765
Validation loss: 2.880558548855203

Epoch: 99| Step: 0
Training loss: 2.9291656436258178
Validation loss: 2.8824462800295563

Epoch: 6| Step: 1
Training loss: 3.224445230244527
Validation loss: 2.885069102098114

Epoch: 6| Step: 2
Training loss: 2.9333544759277412
Validation loss: 2.8838373979009106

Epoch: 6| Step: 3
Training loss: 3.1578963112408913
Validation loss: 2.88533770471426

Epoch: 6| Step: 4
Training loss: 3.0521424757572797
Validation loss: 2.886047610301582

Epoch: 6| Step: 5
Training loss: 3.577126709384938
Validation loss: 2.8834423239007987

Epoch: 6| Step: 6
Training loss: 3.0511507208650883
Validation loss: 2.8815776862565725

Epoch: 6| Step: 7
Training loss: 2.634812498135226
Validation loss: 2.8793926379409918

Epoch: 6| Step: 8
Training loss: 3.212107498593335
Validation loss: 2.8814585824775394

Epoch: 6| Step: 9
Training loss: 3.640108653113218
Validation loss: 2.88504980810089

Epoch: 6| Step: 10
Training loss: 3.8973964608407026
Validation loss: 2.8831207789082853

Epoch: 6| Step: 11
Training loss: 2.5509373381966407
Validation loss: 2.8811085789848145

Epoch: 6| Step: 12
Training loss: 3.0792829010687623
Validation loss: 2.882440750639736

Epoch: 6| Step: 13
Training loss: 3.2273159671382667
Validation loss: 2.8787775791628873

Epoch: 100| Step: 0
Training loss: 3.135646384981564
Validation loss: 2.8754288156092866

Epoch: 6| Step: 1
Training loss: 2.8386903123111167
Validation loss: 2.8765285168496413

Epoch: 6| Step: 2
Training loss: 2.969823382228455
Validation loss: 2.876013147036578

Epoch: 6| Step: 3
Training loss: 3.649689616762781
Validation loss: 2.876388407164392

Epoch: 6| Step: 4
Training loss: 3.2136949268727752
Validation loss: 2.8769893478132538

Epoch: 6| Step: 5
Training loss: 2.6619913322714592
Validation loss: 2.8756998038827626

Epoch: 6| Step: 6
Training loss: 3.340729249160837
Validation loss: 2.874410637525075

Epoch: 6| Step: 7
Training loss: 3.7851835865966557
Validation loss: 2.879014937740316

Epoch: 6| Step: 8
Training loss: 3.1504834061527522
Validation loss: 2.8766067637566013

Epoch: 6| Step: 9
Training loss: 3.4715399991675615
Validation loss: 2.889565492001454

Epoch: 6| Step: 10
Training loss: 2.994602274780184
Validation loss: 2.8825195832428587

Epoch: 6| Step: 11
Training loss: 3.062202906308512
Validation loss: 2.8731273787270233

Epoch: 6| Step: 12
Training loss: 2.9412760712083776
Validation loss: 2.8748413067107634

Epoch: 6| Step: 13
Training loss: 2.902871578065877
Validation loss: 2.8727812906635037

Epoch: 101| Step: 0
Training loss: 3.281712381390972
Validation loss: 2.8742756905360425

Epoch: 6| Step: 1
Training loss: 3.650548810067475
Validation loss: 2.871908079497317

Epoch: 6| Step: 2
Training loss: 3.272586393214059
Validation loss: 2.8723143650987533

Epoch: 6| Step: 3
Training loss: 3.327817517614509
Validation loss: 2.8714105188711394

Epoch: 6| Step: 4
Training loss: 2.466963689121675
Validation loss: 2.8702001108845265

Epoch: 6| Step: 5
Training loss: 3.2304944333735692
Validation loss: 2.868360055834722

Epoch: 6| Step: 6
Training loss: 2.8053124031813925
Validation loss: 2.8702093956034567

Epoch: 6| Step: 7
Training loss: 3.1546078177332304
Validation loss: 2.8717425717889826

Epoch: 6| Step: 8
Training loss: 2.7914346816811397
Validation loss: 2.868737888098373

Epoch: 6| Step: 9
Training loss: 3.450542329925177
Validation loss: 2.868510880123403

Epoch: 6| Step: 10
Training loss: 3.192406561790293
Validation loss: 2.868536140065902

Epoch: 6| Step: 11
Training loss: 3.044928765426777
Validation loss: 2.8676652711719224

Epoch: 6| Step: 12
Training loss: 3.384847332936178
Validation loss: 2.868202006965517

Epoch: 6| Step: 13
Training loss: 3.116178650481045
Validation loss: 2.8679910714929013

Epoch: 102| Step: 0
Training loss: 2.5518741340271367
Validation loss: 2.866273243195416

Epoch: 6| Step: 1
Training loss: 3.2547285453709858
Validation loss: 2.8667007081780995

Epoch: 6| Step: 2
Training loss: 3.457946449301989
Validation loss: 2.872440638151966

Epoch: 6| Step: 3
Training loss: 3.288236174452354
Validation loss: 2.8938162515648966

Epoch: 6| Step: 4
Training loss: 3.1473162526375087
Validation loss: 2.90800042640437

Epoch: 6| Step: 5
Training loss: 3.1839139625196435
Validation loss: 2.9108504272435125

Epoch: 6| Step: 6
Training loss: 3.2515989918381916
Validation loss: 2.8794831022640452

Epoch: 6| Step: 7
Training loss: 3.2260601400787285
Validation loss: 2.864317051358925

Epoch: 6| Step: 8
Training loss: 3.5867369847217403
Validation loss: 2.8668753553605644

Epoch: 6| Step: 9
Training loss: 3.868528684531683
Validation loss: 2.8664284577334733

Epoch: 6| Step: 10
Training loss: 2.934945639475669
Validation loss: 2.8701115235984074

Epoch: 6| Step: 11
Training loss: 2.757117943118213
Validation loss: 2.8821953504940447

Epoch: 6| Step: 12
Training loss: 2.8630782363759923
Validation loss: 2.889003298092373

Epoch: 6| Step: 13
Training loss: 2.797263858977326
Validation loss: 2.9088006974723606

Epoch: 103| Step: 0
Training loss: 2.953235119577984
Validation loss: 2.909161999506546

Epoch: 6| Step: 1
Training loss: 2.3585177247265117
Validation loss: 2.875106638339135

Epoch: 6| Step: 2
Training loss: 3.274494883481017
Validation loss: 2.8689943954839143

Epoch: 6| Step: 3
Training loss: 2.383260716041155
Validation loss: 2.871649740681296

Epoch: 6| Step: 4
Training loss: 3.5579537277772326
Validation loss: 2.8697948784459677

Epoch: 6| Step: 5
Training loss: 3.253750177970351
Validation loss: 2.8678597592627946

Epoch: 6| Step: 6
Training loss: 3.9045159725449197
Validation loss: 2.8745688712153705

Epoch: 6| Step: 7
Training loss: 3.2552544593086163
Validation loss: 2.875434637543153

Epoch: 6| Step: 8
Training loss: 2.60979234475919
Validation loss: 2.875122811368143

Epoch: 6| Step: 9
Training loss: 3.4888117302490738
Validation loss: 2.8739990339487425

Epoch: 6| Step: 10
Training loss: 3.8036886231694633
Validation loss: 2.8724426908911163

Epoch: 6| Step: 11
Training loss: 2.9952671547065655
Validation loss: 2.8735671733076513

Epoch: 6| Step: 12
Training loss: 2.837771660660328
Validation loss: 2.8761161191069715

Epoch: 6| Step: 13
Training loss: 3.270222325364441
Validation loss: 2.877793325186159

Epoch: 104| Step: 0
Training loss: 3.440937889347846
Validation loss: 2.8728961237611883

Epoch: 6| Step: 1
Training loss: 2.8009967800831426
Validation loss: 2.876007780882032

Epoch: 6| Step: 2
Training loss: 2.8643728467886165
Validation loss: 2.878602360968528

Epoch: 6| Step: 3
Training loss: 2.78320398163364
Validation loss: 2.876633052343166

Epoch: 6| Step: 4
Training loss: 3.291742895346248
Validation loss: 2.8738690399343607

Epoch: 6| Step: 5
Training loss: 2.6927388605764477
Validation loss: 2.8905725786443965

Epoch: 6| Step: 6
Training loss: 2.9176821076370856
Validation loss: 2.8844732469816217

Epoch: 6| Step: 7
Training loss: 2.755208717927864
Validation loss: 2.8820471450318017

Epoch: 6| Step: 8
Training loss: 2.5447215706260042
Validation loss: 2.8771250247054576

Epoch: 6| Step: 9
Training loss: 3.810418733429735
Validation loss: 2.878509665588138

Epoch: 6| Step: 10
Training loss: 3.2139253474872733
Validation loss: 2.8693127559809453

Epoch: 6| Step: 11
Training loss: 3.588843404470516
Validation loss: 2.8692743982273154

Epoch: 6| Step: 12
Training loss: 3.578338749926915
Validation loss: 2.86240710125516

Epoch: 6| Step: 13
Training loss: 3.971142025477209
Validation loss: 2.8558076153812735

Epoch: 105| Step: 0
Training loss: 2.4100558416141493
Validation loss: 2.8588466038388844

Epoch: 6| Step: 1
Training loss: 3.287553527164193
Validation loss: 2.8565955202154516

Epoch: 6| Step: 2
Training loss: 2.7248806288585046
Validation loss: 2.85612860275095

Epoch: 6| Step: 3
Training loss: 2.9105606105399957
Validation loss: 2.855386973588567

Epoch: 6| Step: 4
Training loss: 3.578247867790146
Validation loss: 2.85618594669021

Epoch: 6| Step: 5
Training loss: 3.103077093486418
Validation loss: 2.8568325591129886

Epoch: 6| Step: 6
Training loss: 3.2404715903599106
Validation loss: 2.8560728527144317

Epoch: 6| Step: 7
Training loss: 3.2418920175500276
Validation loss: 2.856647305978365

Epoch: 6| Step: 8
Training loss: 3.356851170863134
Validation loss: 2.8529485916663395

Epoch: 6| Step: 9
Training loss: 3.4566337055141783
Validation loss: 2.853146728214364

Epoch: 6| Step: 10
Training loss: 3.3829538787124496
Validation loss: 2.8544639867874717

Epoch: 6| Step: 11
Training loss: 3.1311365529598434
Validation loss: 2.8565459520399505

Epoch: 6| Step: 12
Training loss: 2.971191045154559
Validation loss: 2.8536712342841475

Epoch: 6| Step: 13
Training loss: 3.352940131759087
Validation loss: 2.855008777053002

Epoch: 106| Step: 0
Training loss: 3.248243297296651
Validation loss: 2.8570349155419232

Epoch: 6| Step: 1
Training loss: 3.515991191866
Validation loss: 2.8602219986960415

Epoch: 6| Step: 2
Training loss: 2.3078116239366566
Validation loss: 2.8648474327496913

Epoch: 6| Step: 3
Training loss: 3.3512338330434885
Validation loss: 2.8599896697415645

Epoch: 6| Step: 4
Training loss: 2.396407370974036
Validation loss: 2.8647497936818667

Epoch: 6| Step: 5
Training loss: 3.3499706551704196
Validation loss: 2.8643553851019123

Epoch: 6| Step: 6
Training loss: 3.8768300072941737
Validation loss: 2.8676422421076158

Epoch: 6| Step: 7
Training loss: 3.4805756112593444
Validation loss: 2.8665057211059777

Epoch: 6| Step: 8
Training loss: 2.7496367127871872
Validation loss: 2.8731891534417033

Epoch: 6| Step: 9
Training loss: 2.929626789735551
Validation loss: 2.8710968493038256

Epoch: 6| Step: 10
Training loss: 3.544989803283403
Validation loss: 2.878445081108147

Epoch: 6| Step: 11
Training loss: 2.711418175201492
Validation loss: 2.870330297855117

Epoch: 6| Step: 12
Training loss: 3.34195554123624
Validation loss: 2.882295107833415

Epoch: 6| Step: 13
Training loss: 2.933676158494233
Validation loss: 2.8768349659534826

Epoch: 107| Step: 0
Training loss: 2.918868859299034
Validation loss: 2.8546136790911505

Epoch: 6| Step: 1
Training loss: 3.142199828409663
Validation loss: 2.848194821248156

Epoch: 6| Step: 2
Training loss: 3.2453076160083767
Validation loss: 2.8478501601295383

Epoch: 6| Step: 3
Training loss: 3.465420749104321
Validation loss: 2.8460951218895567

Epoch: 6| Step: 4
Training loss: 3.919218463061999
Validation loss: 2.846156774448204

Epoch: 6| Step: 5
Training loss: 3.223691831717
Validation loss: 2.8478896355175234

Epoch: 6| Step: 6
Training loss: 2.2667263116655856
Validation loss: 2.8502123207604253

Epoch: 6| Step: 7
Training loss: 3.207263784771596
Validation loss: 2.852064831100205

Epoch: 6| Step: 8
Training loss: 3.0166413961233736
Validation loss: 2.852981546488565

Epoch: 6| Step: 9
Training loss: 3.012230420218909
Validation loss: 2.8509096754486323

Epoch: 6| Step: 10
Training loss: 2.565032916685082
Validation loss: 2.849379822790594

Epoch: 6| Step: 11
Training loss: 2.799138522455705
Validation loss: 2.8504826394490688

Epoch: 6| Step: 12
Training loss: 3.678864016384651
Validation loss: 2.847766998247227

Epoch: 6| Step: 13
Training loss: 3.436350821094553
Validation loss: 2.8451288912884025

Epoch: 108| Step: 0
Training loss: 3.045373634754256
Validation loss: 2.844567935026364

Epoch: 6| Step: 1
Training loss: 3.41607927685123
Validation loss: 2.845313769912128

Epoch: 6| Step: 2
Training loss: 3.9232104941826713
Validation loss: 2.841558671164038

Epoch: 6| Step: 3
Training loss: 2.964199071461616
Validation loss: 2.842219538919811

Epoch: 6| Step: 4
Training loss: 3.1162077241149992
Validation loss: 2.8442125635006765

Epoch: 6| Step: 5
Training loss: 3.3186639979366954
Validation loss: 2.8418470847286534

Epoch: 6| Step: 6
Training loss: 3.3073053474844176
Validation loss: 2.8435740397854117

Epoch: 6| Step: 7
Training loss: 3.089929861612172
Validation loss: 2.8428126262718196

Epoch: 6| Step: 8
Training loss: 3.2547995999901733
Validation loss: 2.84582412339403

Epoch: 6| Step: 9
Training loss: 2.7709034693357606
Validation loss: 2.84606424917029

Epoch: 6| Step: 10
Training loss: 3.125095671142947
Validation loss: 2.84345745270858

Epoch: 6| Step: 11
Training loss: 2.7051147899139747
Validation loss: 2.8447262074309094

Epoch: 6| Step: 12
Training loss: 2.886895160162815
Validation loss: 2.843663222088617

Epoch: 6| Step: 13
Training loss: 2.8997575987433373
Validation loss: 2.8408879235337645

Epoch: 109| Step: 0
Training loss: 3.9653149254360294
Validation loss: 2.8396081702175735

Epoch: 6| Step: 1
Training loss: 2.090558366611706
Validation loss: 2.842070131928904

Epoch: 6| Step: 2
Training loss: 3.3906207809773576
Validation loss: 2.842300200528974

Epoch: 6| Step: 3
Training loss: 3.3847022295527354
Validation loss: 2.8405135492514746

Epoch: 6| Step: 4
Training loss: 3.431762067874597
Validation loss: 2.8413283945487073

Epoch: 6| Step: 5
Training loss: 2.9458641931912886
Validation loss: 2.837388435430325

Epoch: 6| Step: 6
Training loss: 2.663174388886796
Validation loss: 2.834114300650751

Epoch: 6| Step: 7
Training loss: 3.644705781508934
Validation loss: 2.8373900482152283

Epoch: 6| Step: 8
Training loss: 3.2020534304676778
Validation loss: 2.8366832723784983

Epoch: 6| Step: 9
Training loss: 2.8965992817944275
Validation loss: 2.833811794348197

Epoch: 6| Step: 10
Training loss: 2.8515509618238313
Validation loss: 2.8347650143417944

Epoch: 6| Step: 11
Training loss: 2.851357146929459
Validation loss: 2.839022619018448

Epoch: 6| Step: 12
Training loss: 3.09338885424653
Validation loss: 2.8349401730051262

Epoch: 6| Step: 13
Training loss: 3.1614269441473977
Validation loss: 2.836498353631281

Epoch: 110| Step: 0
Training loss: 2.9817739606060747
Validation loss: 2.8371610615319094

Epoch: 6| Step: 1
Training loss: 3.3248802450312143
Validation loss: 2.839760868228269

Epoch: 6| Step: 2
Training loss: 3.4451893202717683
Validation loss: 2.8340272313126484

Epoch: 6| Step: 3
Training loss: 2.891653671748473
Validation loss: 2.8339535910742235

Epoch: 6| Step: 4
Training loss: 2.8883592128162907
Validation loss: 2.833781554969116

Epoch: 6| Step: 5
Training loss: 3.4027484780086
Validation loss: 2.833410727682266

Epoch: 6| Step: 6
Training loss: 3.4842311675487974
Validation loss: 2.83206267399198

Epoch: 6| Step: 7
Training loss: 2.8268489593379256
Validation loss: 2.8317280911400746

Epoch: 6| Step: 8
Training loss: 2.6894398275474645
Validation loss: 2.83378781528709

Epoch: 6| Step: 9
Training loss: 2.7574620010649094
Validation loss: 2.8331037946540487

Epoch: 6| Step: 10
Training loss: 3.3868896722836546
Validation loss: 2.8336749700287647

Epoch: 6| Step: 11
Training loss: 3.427363762015601
Validation loss: 2.8391198191052496

Epoch: 6| Step: 12
Training loss: 2.906586822352221
Validation loss: 2.8314672099780447

Epoch: 6| Step: 13
Training loss: 3.4900014294727972
Validation loss: 2.8315166123750934

Epoch: 111| Step: 0
Training loss: 3.792934932224049
Validation loss: 2.830686654685805

Epoch: 6| Step: 1
Training loss: 2.9301454720171516
Validation loss: 2.829804433018536

Epoch: 6| Step: 2
Training loss: 2.8939053454628634
Validation loss: 2.8292532781006274

Epoch: 6| Step: 3
Training loss: 3.2222709286688076
Validation loss: 2.8279515495768113

Epoch: 6| Step: 4
Training loss: 3.806094933468965
Validation loss: 2.830771187759644

Epoch: 6| Step: 5
Training loss: 3.041196882644053
Validation loss: 2.8299096245986624

Epoch: 6| Step: 6
Training loss: 2.8144027207763167
Validation loss: 2.8298064614234884

Epoch: 6| Step: 7
Training loss: 3.1262393782540845
Validation loss: 2.828858499741094

Epoch: 6| Step: 8
Training loss: 2.922941941260548
Validation loss: 2.8284890391485735

Epoch: 6| Step: 9
Training loss: 2.9814678632356304
Validation loss: 2.828977925893458

Epoch: 6| Step: 10
Training loss: 3.0349230977453967
Validation loss: 2.82871925711157

Epoch: 6| Step: 11
Training loss: 3.4007613732046047
Validation loss: 2.828765127713519

Epoch: 6| Step: 12
Training loss: 3.082417704403306
Validation loss: 2.828122915093698

Epoch: 6| Step: 13
Training loss: 2.1123068320536387
Validation loss: 2.82813200889983

Epoch: 112| Step: 0
Training loss: 3.3622177516080836
Validation loss: 2.8311982875209436

Epoch: 6| Step: 1
Training loss: 2.6488236677466737
Validation loss: 2.8321668774154882

Epoch: 6| Step: 2
Training loss: 2.391676229087862
Validation loss: 2.8314567569925164

Epoch: 6| Step: 3
Training loss: 3.5903644038919467
Validation loss: 2.8312805045197567

Epoch: 6| Step: 4
Training loss: 3.531936713769549
Validation loss: 2.8266454776727032

Epoch: 6| Step: 5
Training loss: 3.0262450753336956
Validation loss: 2.827305906923447

Epoch: 6| Step: 6
Training loss: 3.250939453499906
Validation loss: 2.831127827231399

Epoch: 6| Step: 7
Training loss: 3.1240251164910307
Validation loss: 2.824829984001568

Epoch: 6| Step: 8
Training loss: 3.1330572398947694
Validation loss: 2.8255915371754274

Epoch: 6| Step: 9
Training loss: 3.3485393983944847
Validation loss: 2.826641522438585

Epoch: 6| Step: 10
Training loss: 2.867492825832555
Validation loss: 2.8310971209084443

Epoch: 6| Step: 11
Training loss: 3.275360343852273
Validation loss: 2.8348199652761203

Epoch: 6| Step: 12
Training loss: 2.7822655527443008
Validation loss: 2.834014594123022

Epoch: 6| Step: 13
Training loss: 3.5572449591247928
Validation loss: 2.831811537545478

Epoch: 113| Step: 0
Training loss: 3.156744134577423
Validation loss: 2.834600740300406

Epoch: 6| Step: 1
Training loss: 3.3444247411722743
Validation loss: 2.8297194760616975

Epoch: 6| Step: 2
Training loss: 3.2425598666062267
Validation loss: 2.8278967498351735

Epoch: 6| Step: 3
Training loss: 2.8596948330134575
Validation loss: 2.830657852729173

Epoch: 6| Step: 4
Training loss: 3.3098499566036965
Validation loss: 2.831169549627119

Epoch: 6| Step: 5
Training loss: 3.2311311386352912
Validation loss: 2.8311891428952545

Epoch: 6| Step: 6
Training loss: 2.8441736932714847
Validation loss: 2.8338513205459877

Epoch: 6| Step: 7
Training loss: 3.2614921445423004
Validation loss: 2.832100264826079

Epoch: 6| Step: 8
Training loss: 2.4883532072049928
Validation loss: 2.8324740468283354

Epoch: 6| Step: 9
Training loss: 2.9429682704032993
Validation loss: 2.8329090326101785

Epoch: 6| Step: 10
Training loss: 3.1429245155098573
Validation loss: 2.8346469371755862

Epoch: 6| Step: 11
Training loss: 3.783001202584382
Validation loss: 2.8325378340559233

Epoch: 6| Step: 12
Training loss: 2.8536713627504535
Validation loss: 2.8313632415723466

Epoch: 6| Step: 13
Training loss: 3.2930166799874083
Validation loss: 2.82402342057866

Epoch: 114| Step: 0
Training loss: 2.4127443535742334
Validation loss: 2.82019870830624

Epoch: 6| Step: 1
Training loss: 3.305156268697481
Validation loss: 2.817452389057447

Epoch: 6| Step: 2
Training loss: 3.2200966397586215
Validation loss: 2.8182677800716682

Epoch: 6| Step: 3
Training loss: 2.685372686112278
Validation loss: 2.820046343763328

Epoch: 6| Step: 4
Training loss: 2.9149126137252033
Validation loss: 2.8169830888928735

Epoch: 6| Step: 5
Training loss: 2.409950185712046
Validation loss: 2.820180770392363

Epoch: 6| Step: 6
Training loss: 3.33555125517557
Validation loss: 2.8220515521429292

Epoch: 6| Step: 7
Training loss: 3.237665686178699
Validation loss: 2.8216286283106644

Epoch: 6| Step: 8
Training loss: 3.595169583115637
Validation loss: 2.819047142406653

Epoch: 6| Step: 9
Training loss: 2.695297904597031
Validation loss: 2.8204946505993007

Epoch: 6| Step: 10
Training loss: 3.657561238233173
Validation loss: 2.8175122025586945

Epoch: 6| Step: 11
Training loss: 3.5570619805925303
Validation loss: 2.817970113747887

Epoch: 6| Step: 12
Training loss: 3.181027891428323
Validation loss: 2.8152274612598682

Epoch: 6| Step: 13
Training loss: 3.2317734727789804
Validation loss: 2.816399512303447

Epoch: 115| Step: 0
Training loss: 3.293097913206772
Validation loss: 2.819339022775437

Epoch: 6| Step: 1
Training loss: 2.443921458285597
Validation loss: 2.81976136720891

Epoch: 6| Step: 2
Training loss: 2.9199617210910005
Validation loss: 2.821224380308432

Epoch: 6| Step: 3
Training loss: 3.3489336850380043
Validation loss: 2.8174258976836626

Epoch: 6| Step: 4
Training loss: 3.337253427148097
Validation loss: 2.8191070666632134

Epoch: 6| Step: 5
Training loss: 3.2139275729760834
Validation loss: 2.818038464961047

Epoch: 6| Step: 6
Training loss: 2.9075503157823688
Validation loss: 2.8154907021902513

Epoch: 6| Step: 7
Training loss: 2.7783057240939493
Validation loss: 2.8167603250412157

Epoch: 6| Step: 8
Training loss: 2.987003786384116
Validation loss: 2.8167875985598383

Epoch: 6| Step: 9
Training loss: 2.7517823598821267
Validation loss: 2.815971847679885

Epoch: 6| Step: 10
Training loss: 3.66332518880099
Validation loss: 2.8173193800833105

Epoch: 6| Step: 11
Training loss: 3.282885044173316
Validation loss: 2.818021211969617

Epoch: 6| Step: 12
Training loss: 2.934639044796172
Validation loss: 2.8115122766385103

Epoch: 6| Step: 13
Training loss: 3.965081870158616
Validation loss: 2.815013113633719

Epoch: 116| Step: 0
Training loss: 3.3803370627101286
Validation loss: 2.81464681237644

Epoch: 6| Step: 1
Training loss: 3.2475382945186704
Validation loss: 2.815743400818793

Epoch: 6| Step: 2
Training loss: 3.3247765544872436
Validation loss: 2.8176701013353065

Epoch: 6| Step: 3
Training loss: 3.551857830209496
Validation loss: 2.817367716606074

Epoch: 6| Step: 4
Training loss: 2.80529413064911
Validation loss: 2.813120466586069

Epoch: 6| Step: 5
Training loss: 3.178715437784833
Validation loss: 2.8165968631522595

Epoch: 6| Step: 6
Training loss: 2.707410293177868
Validation loss: 2.8136421974339276

Epoch: 6| Step: 7
Training loss: 3.04625237779051
Validation loss: 2.8187260923887645

Epoch: 6| Step: 8
Training loss: 2.99189617441947
Validation loss: 2.8203624813743744

Epoch: 6| Step: 9
Training loss: 2.905713759962255
Validation loss: 2.815210630879905

Epoch: 6| Step: 10
Training loss: 3.130311647932773
Validation loss: 2.812339170134781

Epoch: 6| Step: 11
Training loss: 2.5826776246603336
Validation loss: 2.810469812765945

Epoch: 6| Step: 12
Training loss: 3.8262103839706443
Validation loss: 2.8111477389106976

Epoch: 6| Step: 13
Training loss: 2.847569845011145
Validation loss: 2.8275420492821026

Epoch: 117| Step: 0
Training loss: 3.5949927793385195
Validation loss: 2.861706804170609

Epoch: 6| Step: 1
Training loss: 3.7653605894591746
Validation loss: 2.892187678911364

Epoch: 6| Step: 2
Training loss: 3.5861603578284877
Validation loss: 2.882036690475883

Epoch: 6| Step: 3
Training loss: 3.2881559812575922
Validation loss: 2.858350577784198

Epoch: 6| Step: 4
Training loss: 2.8977349347507952
Validation loss: 2.8131609906773876

Epoch: 6| Step: 5
Training loss: 3.4487359647613895
Validation loss: 2.811501180473391

Epoch: 6| Step: 6
Training loss: 3.3970593694575224
Validation loss: 2.8090663609656077

Epoch: 6| Step: 7
Training loss: 2.5556247869964013
Validation loss: 2.808125540189762

Epoch: 6| Step: 8
Training loss: 2.9639226917681776
Validation loss: 2.808893395666102

Epoch: 6| Step: 9
Training loss: 2.5721392879294096
Validation loss: 2.810978892641076

Epoch: 6| Step: 10
Training loss: 2.9523178693005945
Validation loss: 2.809460066055075

Epoch: 6| Step: 11
Training loss: 2.7549940192959044
Validation loss: 2.8120543378633043

Epoch: 6| Step: 12
Training loss: 2.8220972558720123
Validation loss: 2.8117074941410922

Epoch: 6| Step: 13
Training loss: 2.705609365141828
Validation loss: 2.81322430589542

Epoch: 118| Step: 0
Training loss: 2.481461550056329
Validation loss: 2.813777996918936

Epoch: 6| Step: 1
Training loss: 3.693423153121328
Validation loss: 2.8110238653145028

Epoch: 6| Step: 2
Training loss: 3.0067552169763427
Validation loss: 2.8114738433623687

Epoch: 6| Step: 3
Training loss: 2.5411635875505194
Validation loss: 2.813630786210263

Epoch: 6| Step: 4
Training loss: 2.9421073007212906
Validation loss: 2.8124685050996616

Epoch: 6| Step: 5
Training loss: 3.6242767138573178
Validation loss: 2.8193786036591115

Epoch: 6| Step: 6
Training loss: 2.9652123504813725
Validation loss: 2.835190691430863

Epoch: 6| Step: 7
Training loss: 3.449180317682971
Validation loss: 2.8284308286813227

Epoch: 6| Step: 8
Training loss: 3.0835187873397887
Validation loss: 2.816690159807882

Epoch: 6| Step: 9
Training loss: 3.5055971350389594
Validation loss: 2.8152500448818403

Epoch: 6| Step: 10
Training loss: 3.2106868154119543
Validation loss: 2.8124322105997788

Epoch: 6| Step: 11
Training loss: 2.732714775698079
Validation loss: 2.808538440195848

Epoch: 6| Step: 12
Training loss: 3.40235243926488
Validation loss: 2.807077032103766

Epoch: 6| Step: 13
Training loss: 2.4800236820812986
Validation loss: 2.802806905532792

Epoch: 119| Step: 0
Training loss: 3.268032518932424
Validation loss: 2.802741710825747

Epoch: 6| Step: 1
Training loss: 2.6908085883373096
Validation loss: 2.8042271693591534

Epoch: 6| Step: 2
Training loss: 3.035138497122711
Validation loss: 2.803839188333975

Epoch: 6| Step: 3
Training loss: 2.533536090600544
Validation loss: 2.8035764993407155

Epoch: 6| Step: 4
Training loss: 3.619911305305196
Validation loss: 2.804022674186483

Epoch: 6| Step: 5
Training loss: 2.646020467152806
Validation loss: 2.801395008908166

Epoch: 6| Step: 6
Training loss: 2.7203880724633804
Validation loss: 2.803401579449084

Epoch: 6| Step: 7
Training loss: 3.6171996279156837
Validation loss: 2.80153839512925

Epoch: 6| Step: 8
Training loss: 2.4781922955413327
Validation loss: 2.8033898659144465

Epoch: 6| Step: 9
Training loss: 2.8637558360312982
Validation loss: 2.802139692147255

Epoch: 6| Step: 10
Training loss: 3.3168499293726708
Validation loss: 2.804414035932757

Epoch: 6| Step: 11
Training loss: 3.1184828894217476
Validation loss: 2.8005179437063497

Epoch: 6| Step: 12
Training loss: 3.495590156642064
Validation loss: 2.803949578981202

Epoch: 6| Step: 13
Training loss: 4.205931906837776
Validation loss: 2.803283828261755

Epoch: 120| Step: 0
Training loss: 2.901665794493668
Validation loss: 2.8049830342900712

Epoch: 6| Step: 1
Training loss: 2.5716649355566297
Validation loss: 2.801037128119455

Epoch: 6| Step: 2
Training loss: 3.5457995964862965
Validation loss: 2.8060023242010317

Epoch: 6| Step: 3
Training loss: 2.937225004269848
Validation loss: 2.803841765835445

Epoch: 6| Step: 4
Training loss: 3.060217804979903
Validation loss: 2.8054380422380003

Epoch: 6| Step: 5
Training loss: 3.1223930165859026
Validation loss: 2.8085412406722225

Epoch: 6| Step: 6
Training loss: 2.782868075364701
Validation loss: 2.8090303738752067

Epoch: 6| Step: 7
Training loss: 3.090379825197747
Validation loss: 2.8158426290163567

Epoch: 6| Step: 8
Training loss: 3.1502849752704973
Validation loss: 2.814367767488145

Epoch: 6| Step: 9
Training loss: 3.0197935397583247
Validation loss: 2.8182156147318325

Epoch: 6| Step: 10
Training loss: 3.1997117627983673
Validation loss: 2.8164597650524934

Epoch: 6| Step: 11
Training loss: 3.75718788459812
Validation loss: 2.8029783860929287

Epoch: 6| Step: 12
Training loss: 3.047218342533924
Validation loss: 2.7952249361421844

Epoch: 6| Step: 13
Training loss: 3.2414855932609603
Validation loss: 2.7983969679405365

Epoch: 121| Step: 0
Training loss: 3.4847459809427686
Validation loss: 2.796205105957296

Epoch: 6| Step: 1
Training loss: 2.9065349808298535
Validation loss: 2.7962334339819277

Epoch: 6| Step: 2
Training loss: 2.57168579518029
Validation loss: 2.796996767930662

Epoch: 6| Step: 3
Training loss: 3.2663710622618853
Validation loss: 2.7939090021806843

Epoch: 6| Step: 4
Training loss: 3.874276862811536
Validation loss: 2.795302657106709

Epoch: 6| Step: 5
Training loss: 2.94282762853925
Validation loss: 2.795106216803948

Epoch: 6| Step: 6
Training loss: 2.4765284201987763
Validation loss: 2.794961914487487

Epoch: 6| Step: 7
Training loss: 2.016530860973081
Validation loss: 2.7941452282703367

Epoch: 6| Step: 8
Training loss: 3.489052955214637
Validation loss: 2.7921873420418586

Epoch: 6| Step: 9
Training loss: 3.6135763181885405
Validation loss: 2.791467631675088

Epoch: 6| Step: 10
Training loss: 2.7822764356380265
Validation loss: 2.7920843120231016

Epoch: 6| Step: 11
Training loss: 3.1374270730832956
Validation loss: 2.7913987207611237

Epoch: 6| Step: 12
Training loss: 2.956643566685021
Validation loss: 2.7902509984051846

Epoch: 6| Step: 13
Training loss: 3.7232718023841223
Validation loss: 2.789735528051338

Epoch: 122| Step: 0
Training loss: 3.613409520527269
Validation loss: 2.787641966471493

Epoch: 6| Step: 1
Training loss: 3.0185968648480874
Validation loss: 2.7915719673895074

Epoch: 6| Step: 2
Training loss: 2.863299568815035
Validation loss: 2.7931161171698085

Epoch: 6| Step: 3
Training loss: 2.6611522540860926
Validation loss: 2.798428188809658

Epoch: 6| Step: 4
Training loss: 3.5872821489175317
Validation loss: 2.8152501914926655

Epoch: 6| Step: 5
Training loss: 3.699900063892008
Validation loss: 2.8202160688766202

Epoch: 6| Step: 6
Training loss: 2.7238614494837816
Validation loss: 2.828601293727725

Epoch: 6| Step: 7
Training loss: 3.0810306989458383
Validation loss: 2.819890574488807

Epoch: 6| Step: 8
Training loss: 2.99117427234303
Validation loss: 2.789131582609902

Epoch: 6| Step: 9
Training loss: 2.190783842371068
Validation loss: 2.7873881642013583

Epoch: 6| Step: 10
Training loss: 3.4830515447893773
Validation loss: 2.791516444303447

Epoch: 6| Step: 11
Training loss: 2.8074986388015506
Validation loss: 2.8025829691475863

Epoch: 6| Step: 12
Training loss: 3.4612083587400955
Validation loss: 2.811798392851588

Epoch: 6| Step: 13
Training loss: 3.078011757563591
Validation loss: 2.8212240095596695

Epoch: 123| Step: 0
Training loss: 2.670706688729431
Validation loss: 2.8122219700271205

Epoch: 6| Step: 1
Training loss: 2.470873149102867
Validation loss: 2.815532093596479

Epoch: 6| Step: 2
Training loss: 3.276139266476193
Validation loss: 2.8093881215752687

Epoch: 6| Step: 3
Training loss: 3.649294113462259
Validation loss: 2.805729735704791

Epoch: 6| Step: 4
Training loss: 2.906081163978119
Validation loss: 2.7946705244989656

Epoch: 6| Step: 5
Training loss: 3.134765929225063
Validation loss: 2.7904880394485576

Epoch: 6| Step: 6
Training loss: 3.4180883070607937
Validation loss: 2.7866564691248756

Epoch: 6| Step: 7
Training loss: 2.7785196511035517
Validation loss: 2.7859473984338496

Epoch: 6| Step: 8
Training loss: 3.8651478947106073
Validation loss: 2.7846141792146124

Epoch: 6| Step: 9
Training loss: 3.820022415974142
Validation loss: 2.796933567031776

Epoch: 6| Step: 10
Training loss: 2.740407338736734
Validation loss: 2.7942541430989367

Epoch: 6| Step: 11
Training loss: 2.6716630639686336
Validation loss: 2.811665530360246

Epoch: 6| Step: 12
Training loss: 2.598419215080077
Validation loss: 2.809949683431285

Epoch: 6| Step: 13
Training loss: 3.2397688703160363
Validation loss: 2.8169601715167127

Epoch: 124| Step: 0
Training loss: 3.5513449579183147
Validation loss: 2.8120367673634514

Epoch: 6| Step: 1
Training loss: 3.7390428044413753
Validation loss: 2.801048565021757

Epoch: 6| Step: 2
Training loss: 3.1072275998941477
Validation loss: 2.790326956998575

Epoch: 6| Step: 3
Training loss: 3.033110372153161
Validation loss: 2.7920879314928975

Epoch: 6| Step: 4
Training loss: 2.8770661600545537
Validation loss: 2.7816149029901736

Epoch: 6| Step: 5
Training loss: 2.681448933083997
Validation loss: 2.7820835521291065

Epoch: 6| Step: 6
Training loss: 2.9391216914996643
Validation loss: 2.7856848232612386

Epoch: 6| Step: 7
Training loss: 2.88701507327641
Validation loss: 2.7865345345398365

Epoch: 6| Step: 8
Training loss: 3.0628753743462784
Validation loss: 2.785999176925609

Epoch: 6| Step: 9
Training loss: 2.4348366687678786
Validation loss: 2.7848218818301014

Epoch: 6| Step: 10
Training loss: 3.093324574205998
Validation loss: 2.7867038573018608

Epoch: 6| Step: 11
Training loss: 3.7129101459244853
Validation loss: 2.78574781094544

Epoch: 6| Step: 12
Training loss: 3.0351656762643198
Validation loss: 2.784126121034559

Epoch: 6| Step: 13
Training loss: 2.893662624811412
Validation loss: 2.783527503174306

Epoch: 125| Step: 0
Training loss: 2.6110805944819333
Validation loss: 2.783987132916827

Epoch: 6| Step: 1
Training loss: 3.3108015204423946
Validation loss: 2.784099131152769

Epoch: 6| Step: 2
Training loss: 3.34744543348742
Validation loss: 2.7856767762252255

Epoch: 6| Step: 3
Training loss: 2.8815015174164054
Validation loss: 2.7846562173813245

Epoch: 6| Step: 4
Training loss: 3.7221487205675245
Validation loss: 2.7841001044542035

Epoch: 6| Step: 5
Training loss: 3.9391584990688218
Validation loss: 2.7830528452725303

Epoch: 6| Step: 6
Training loss: 2.66654668975188
Validation loss: 2.778506875865548

Epoch: 6| Step: 7
Training loss: 3.0675401279899526
Validation loss: 2.7821190953157435

Epoch: 6| Step: 8
Training loss: 2.5906195075663656
Validation loss: 2.77955236608122

Epoch: 6| Step: 9
Training loss: 3.259571359924408
Validation loss: 2.776118273848644

Epoch: 6| Step: 10
Training loss: 2.3098399353718375
Validation loss: 2.7765670642726055

Epoch: 6| Step: 11
Training loss: 2.095160848774807
Validation loss: 2.778954975185644

Epoch: 6| Step: 12
Training loss: 3.3336017659504193
Validation loss: 2.7788055340506497

Epoch: 6| Step: 13
Training loss: 4.022924534957727
Validation loss: 2.775274218249325

Epoch: 126| Step: 0
Training loss: 2.228200958797672
Validation loss: 2.775642614910126

Epoch: 6| Step: 1
Training loss: 3.1721954935450585
Validation loss: 2.7867230511655636

Epoch: 6| Step: 2
Training loss: 2.7412775600316017
Validation loss: 2.8002514889572367

Epoch: 6| Step: 3
Training loss: 2.94982855347104
Validation loss: 2.7885419318924676

Epoch: 6| Step: 4
Training loss: 3.373826564670532
Validation loss: 2.786911908275517

Epoch: 6| Step: 5
Training loss: 3.2775477276548797
Validation loss: 2.7767404385863044

Epoch: 6| Step: 6
Training loss: 3.345628157453296
Validation loss: 2.7769174302403963

Epoch: 6| Step: 7
Training loss: 3.3898770258831443
Validation loss: 2.7763450733955066

Epoch: 6| Step: 8
Training loss: 3.4312412505046974
Validation loss: 2.7766396061855585

Epoch: 6| Step: 9
Training loss: 2.258428258648676
Validation loss: 2.7743297416722497

Epoch: 6| Step: 10
Training loss: 3.086276496906336
Validation loss: 2.77430251325577

Epoch: 6| Step: 11
Training loss: 3.468069748719368
Validation loss: 2.7746283200517934

Epoch: 6| Step: 12
Training loss: 2.968473401485543
Validation loss: 2.77281601612526

Epoch: 6| Step: 13
Training loss: 3.420631496284571
Validation loss: 2.7694543470606496

Epoch: 127| Step: 0
Training loss: 2.624772924865024
Validation loss: 2.7728343168473364

Epoch: 6| Step: 1
Training loss: 2.8965931908609956
Validation loss: 2.769816866696359

Epoch: 6| Step: 2
Training loss: 3.31533720761115
Validation loss: 2.768683785345128

Epoch: 6| Step: 3
Training loss: 2.579812994249124
Validation loss: 2.7720573516528906

Epoch: 6| Step: 4
Training loss: 3.1160666379450643
Validation loss: 2.778646350309319

Epoch: 6| Step: 5
Training loss: 3.1678271091467134
Validation loss: 2.778906497276498

Epoch: 6| Step: 6
Training loss: 2.913328676663772
Validation loss: 2.7818408009959477

Epoch: 6| Step: 7
Training loss: 3.617015991099653
Validation loss: 2.7844249950067574

Epoch: 6| Step: 8
Training loss: 2.5271531848315987
Validation loss: 2.7840920574418657

Epoch: 6| Step: 9
Training loss: 2.6867626864342395
Validation loss: 2.7833472208869456

Epoch: 6| Step: 10
Training loss: 3.6338629403686604
Validation loss: 2.7802266718639768

Epoch: 6| Step: 11
Training loss: 2.9531530954144682
Validation loss: 2.7823992414118077

Epoch: 6| Step: 12
Training loss: 3.2912626541653607
Validation loss: 2.778519351237668

Epoch: 6| Step: 13
Training loss: 3.9274286713609365
Validation loss: 2.7724793487528028

Epoch: 128| Step: 0
Training loss: 3.3534472308019025
Validation loss: 2.7646642329730318

Epoch: 6| Step: 1
Training loss: 3.299518411348264
Validation loss: 2.7648194937565775

Epoch: 6| Step: 2
Training loss: 2.4250978745048073
Validation loss: 2.7659335225324506

Epoch: 6| Step: 3
Training loss: 3.2880098012884846
Validation loss: 2.7620174089069516

Epoch: 6| Step: 4
Training loss: 2.5872718157565893
Validation loss: 2.7677976411060774

Epoch: 6| Step: 5
Training loss: 3.0041516505133736
Validation loss: 2.7643226971813437

Epoch: 6| Step: 6
Training loss: 3.465949500313111
Validation loss: 2.7656177483346496

Epoch: 6| Step: 7
Training loss: 3.327057143275291
Validation loss: 2.763768752205473

Epoch: 6| Step: 8
Training loss: 2.684461250740281
Validation loss: 2.7681041979458962

Epoch: 6| Step: 9
Training loss: 2.6998461644181577
Validation loss: 2.762162007650681

Epoch: 6| Step: 10
Training loss: 3.022394991203023
Validation loss: 2.765575675693683

Epoch: 6| Step: 11
Training loss: 3.1348060866742307
Validation loss: 2.7656925119713742

Epoch: 6| Step: 12
Training loss: 3.0408327884382613
Validation loss: 2.778096401098264

Epoch: 6| Step: 13
Training loss: 3.816008157573434
Validation loss: 2.7723881050064674

Epoch: 129| Step: 0
Training loss: 3.4404594859712234
Validation loss: 2.7691843636049462

Epoch: 6| Step: 1
Training loss: 2.7393768774257232
Validation loss: 2.7649851868223068

Epoch: 6| Step: 2
Training loss: 3.275706376635454
Validation loss: 2.7602299164846387

Epoch: 6| Step: 3
Training loss: 2.928924379778511
Validation loss: 2.760255887779786

Epoch: 6| Step: 4
Training loss: 3.010152010960469
Validation loss: 2.758280242219632

Epoch: 6| Step: 5
Training loss: 2.9996255005101133
Validation loss: 2.7598042200877018

Epoch: 6| Step: 6
Training loss: 3.082279093825127
Validation loss: 2.758813483423885

Epoch: 6| Step: 7
Training loss: 2.98638432950707
Validation loss: 2.7624913046369675

Epoch: 6| Step: 8
Training loss: 3.048645600568188
Validation loss: 2.759104388953354

Epoch: 6| Step: 9
Training loss: 3.3296075661855116
Validation loss: 2.7614417716027297

Epoch: 6| Step: 10
Training loss: 2.8090297906965587
Validation loss: 2.7579029459662565

Epoch: 6| Step: 11
Training loss: 3.446185980898507
Validation loss: 2.757209235667238

Epoch: 6| Step: 12
Training loss: 3.1017297656408593
Validation loss: 2.7595062646062014

Epoch: 6| Step: 13
Training loss: 2.542105391946012
Validation loss: 2.7622755339672236

Epoch: 130| Step: 0
Training loss: 3.371965669079344
Validation loss: 2.768318250235638

Epoch: 6| Step: 1
Training loss: 2.5914408504647604
Validation loss: 2.76535081486267

Epoch: 6| Step: 2
Training loss: 3.2399862515193147
Validation loss: 2.7742777481570258

Epoch: 6| Step: 3
Training loss: 2.939847292405021
Validation loss: 2.76993065587876

Epoch: 6| Step: 4
Training loss: 3.5389215639190548
Validation loss: 2.771863067076308

Epoch: 6| Step: 5
Training loss: 3.160074315464789
Validation loss: 2.7657197009438197

Epoch: 6| Step: 6
Training loss: 3.034292051397464
Validation loss: 2.758026472638988

Epoch: 6| Step: 7
Training loss: 2.9142493630394064
Validation loss: 2.7573653355383625

Epoch: 6| Step: 8
Training loss: 3.3917373731086684
Validation loss: 2.7538090342166455

Epoch: 6| Step: 9
Training loss: 2.954186142900738
Validation loss: 2.756988710047888

Epoch: 6| Step: 10
Training loss: 3.113817118591692
Validation loss: 2.7549228737056555

Epoch: 6| Step: 11
Training loss: 2.6297546196824544
Validation loss: 2.756113691998267

Epoch: 6| Step: 12
Training loss: 2.9022116547580867
Validation loss: 2.7570733008687496

Epoch: 6| Step: 13
Training loss: 3.166909827550346
Validation loss: 2.7545479925005183

Epoch: 131| Step: 0
Training loss: 2.3283705613863037
Validation loss: 2.7539639267575837

Epoch: 6| Step: 1
Training loss: 2.4903961727462165
Validation loss: 2.7531951845067484

Epoch: 6| Step: 2
Training loss: 3.510197361888528
Validation loss: 2.755261155028505

Epoch: 6| Step: 3
Training loss: 3.913077407496318
Validation loss: 2.7532349601995834

Epoch: 6| Step: 4
Training loss: 2.925272226299875
Validation loss: 2.753486023492576

Epoch: 6| Step: 5
Training loss: 3.036080827142194
Validation loss: 2.7541873315711642

Epoch: 6| Step: 6
Training loss: 3.417855187845589
Validation loss: 2.754777854031515

Epoch: 6| Step: 7
Training loss: 3.1261236078153294
Validation loss: 2.754156460432141

Epoch: 6| Step: 8
Training loss: 2.7311422366044837
Validation loss: 2.751670447519167

Epoch: 6| Step: 9
Training loss: 2.9513780381744983
Validation loss: 2.7526218197473113

Epoch: 6| Step: 10
Training loss: 3.0004195873569603
Validation loss: 2.760896466365419

Epoch: 6| Step: 11
Training loss: 2.8754912246997373
Validation loss: 2.7638253725667004

Epoch: 6| Step: 12
Training loss: 3.349940336464746
Validation loss: 2.7611188655192604

Epoch: 6| Step: 13
Training loss: 2.998745338019706
Validation loss: 2.7539320779946492

Epoch: 132| Step: 0
Training loss: 3.120013722120578
Validation loss: 2.76010581874661

Epoch: 6| Step: 1
Training loss: 2.8987867448261833
Validation loss: 2.752356032711215

Epoch: 6| Step: 2
Training loss: 3.4348447775161373
Validation loss: 2.75436586367046

Epoch: 6| Step: 3
Training loss: 2.7587204430072316
Validation loss: 2.7503935829636035

Epoch: 6| Step: 4
Training loss: 2.889644477122159
Validation loss: 2.750862446866095

Epoch: 6| Step: 5
Training loss: 3.136315268745446
Validation loss: 2.7497656630070204

Epoch: 6| Step: 6
Training loss: 2.9404635799586902
Validation loss: 2.7553900792829764

Epoch: 6| Step: 7
Training loss: 2.7228471423620064
Validation loss: 2.759450043368692

Epoch: 6| Step: 8
Training loss: 3.3307712404140335
Validation loss: 2.757515127914595

Epoch: 6| Step: 9
Training loss: 3.000975450241821
Validation loss: 2.754327549792668

Epoch: 6| Step: 10
Training loss: 3.0288504315207505
Validation loss: 2.7585017751738916

Epoch: 6| Step: 11
Training loss: 3.6732006520738163
Validation loss: 2.7777154522401735

Epoch: 6| Step: 12
Training loss: 3.1894190378230522
Validation loss: 2.7773713039738284

Epoch: 6| Step: 13
Training loss: 2.314376482117065
Validation loss: 2.7693622899216086

Epoch: 133| Step: 0
Training loss: 3.3034535803081866
Validation loss: 2.78189881276113

Epoch: 6| Step: 1
Training loss: 2.709776088149442
Validation loss: 2.7741855553614174

Epoch: 6| Step: 2
Training loss: 3.2862052195310394
Validation loss: 2.7518558197226155

Epoch: 6| Step: 3
Training loss: 2.501209824604973
Validation loss: 2.754473253985366

Epoch: 6| Step: 4
Training loss: 2.8096215671376283
Validation loss: 2.749422909620854

Epoch: 6| Step: 5
Training loss: 3.1258276796980513
Validation loss: 2.749334650104744

Epoch: 6| Step: 6
Training loss: 3.0879676804407743
Validation loss: 2.7445225015183836

Epoch: 6| Step: 7
Training loss: 3.286489753552796
Validation loss: 2.7460457254361077

Epoch: 6| Step: 8
Training loss: 3.367733515039501
Validation loss: 2.7458935923157997

Epoch: 6| Step: 9
Training loss: 3.516468811495657
Validation loss: 2.745996565718179

Epoch: 6| Step: 10
Training loss: 2.449064940470465
Validation loss: 2.745969647325903

Epoch: 6| Step: 11
Training loss: 3.083284961905246
Validation loss: 2.74736118774

Epoch: 6| Step: 12
Training loss: 3.282548048215406
Validation loss: 2.7475536079323377

Epoch: 6| Step: 13
Training loss: 2.928499107929945
Validation loss: 2.7423838589025014

Epoch: 134| Step: 0
Training loss: 3.0618933251933
Validation loss: 2.743661737621299

Epoch: 6| Step: 1
Training loss: 3.77631074494767
Validation loss: 2.7428668930854108

Epoch: 6| Step: 2
Training loss: 3.51386376239168
Validation loss: 2.7434410303777335

Epoch: 6| Step: 3
Training loss: 2.786254751784122
Validation loss: 2.744145967818946

Epoch: 6| Step: 4
Training loss: 2.7826723040950294
Validation loss: 2.7417693166189316

Epoch: 6| Step: 5
Training loss: 2.9837923929233723
Validation loss: 2.744028706480355

Epoch: 6| Step: 6
Training loss: 3.8212090748800063
Validation loss: 2.7459073165996792

Epoch: 6| Step: 7
Training loss: 2.8088988243234474
Validation loss: 2.7432807430825075

Epoch: 6| Step: 8
Training loss: 2.1478149621850315
Validation loss: 2.747275116498213

Epoch: 6| Step: 9
Training loss: 2.933092747561164
Validation loss: 2.752428364205594

Epoch: 6| Step: 10
Training loss: 2.508078397635876
Validation loss: 2.7586416662975046

Epoch: 6| Step: 11
Training loss: 2.8984957378119875
Validation loss: 2.770944514616498

Epoch: 6| Step: 12
Training loss: 3.58365506938252
Validation loss: 2.767077093103101

Epoch: 6| Step: 13
Training loss: 2.5723310620117177
Validation loss: 2.763372372554692

Epoch: 135| Step: 0
Training loss: 3.416835749714543
Validation loss: 2.783017271637279

Epoch: 6| Step: 1
Training loss: 3.108598468371403
Validation loss: 2.789814264818671

Epoch: 6| Step: 2
Training loss: 2.1872742672663072
Validation loss: 2.7830114157337484

Epoch: 6| Step: 3
Training loss: 3.4042551341208958
Validation loss: 2.777600485841978

Epoch: 6| Step: 4
Training loss: 2.8611113065783322
Validation loss: 2.7537863926465724

Epoch: 6| Step: 5
Training loss: 3.428396064383429
Validation loss: 2.7505038611795594

Epoch: 6| Step: 6
Training loss: 3.1228230332344187
Validation loss: 2.738965538497018

Epoch: 6| Step: 7
Training loss: 3.3956371476931904
Validation loss: 2.742213404713971

Epoch: 6| Step: 8
Training loss: 3.007275025537843
Validation loss: 2.7384206518607357

Epoch: 6| Step: 9
Training loss: 2.6686910654033142
Validation loss: 2.741639437669458

Epoch: 6| Step: 10
Training loss: 2.9902716895328556
Validation loss: 2.742352399158861

Epoch: 6| Step: 11
Training loss: 2.899888161442947
Validation loss: 2.7424728468997257

Epoch: 6| Step: 12
Training loss: 3.4242935343084193
Validation loss: 2.74165180495383

Epoch: 6| Step: 13
Training loss: 2.53749538477586
Validation loss: 2.7432320580880902

Epoch: 136| Step: 0
Training loss: 3.152575932192553
Validation loss: 2.738910154553116

Epoch: 6| Step: 1
Training loss: 3.123331616406968
Validation loss: 2.739047837805893

Epoch: 6| Step: 2
Training loss: 3.4304868422682495
Validation loss: 2.73774839952358

Epoch: 6| Step: 3
Training loss: 3.262993441276728
Validation loss: 2.742132316692969

Epoch: 6| Step: 4
Training loss: 3.273031059287931
Validation loss: 2.753038661477783

Epoch: 6| Step: 5
Training loss: 3.3651910160258094
Validation loss: 2.769494381695117

Epoch: 6| Step: 6
Training loss: 2.7486633173314363
Validation loss: 2.7610025506592684

Epoch: 6| Step: 7
Training loss: 2.5587661335655
Validation loss: 2.7462099840421588

Epoch: 6| Step: 8
Training loss: 3.7238460212612816
Validation loss: 2.746776876209283

Epoch: 6| Step: 9
Training loss: 3.0556475211281264
Validation loss: 2.7378068605214345

Epoch: 6| Step: 10
Training loss: 3.437031107047265
Validation loss: 2.736452341720552

Epoch: 6| Step: 11
Training loss: 2.4305759780268006
Validation loss: 2.7359095079721616

Epoch: 6| Step: 12
Training loss: 2.273085104776037
Validation loss: 2.7344199200059336

Epoch: 6| Step: 13
Training loss: 2.1605662393124603
Validation loss: 2.733975333964934

Epoch: 137| Step: 0
Training loss: 2.9520436078083847
Validation loss: 2.7450849045610473

Epoch: 6| Step: 1
Training loss: 2.4277953602871647
Validation loss: 2.7500468927824655

Epoch: 6| Step: 2
Training loss: 3.3439159886881575
Validation loss: 2.766240579738187

Epoch: 6| Step: 3
Training loss: 3.134200019554151
Validation loss: 2.7729311476058816

Epoch: 6| Step: 4
Training loss: 3.307895266903376
Validation loss: 2.7436893691613253

Epoch: 6| Step: 5
Training loss: 2.9578009829370004
Validation loss: 2.737963662087683

Epoch: 6| Step: 6
Training loss: 2.690822144838828
Validation loss: 2.7322589971411926

Epoch: 6| Step: 7
Training loss: 3.1879296106778643
Validation loss: 2.7309161993265207

Epoch: 6| Step: 8
Training loss: 3.0182469487866403
Validation loss: 2.731457201284707

Epoch: 6| Step: 9
Training loss: 2.7865618439934883
Validation loss: 2.734330193640311

Epoch: 6| Step: 10
Training loss: 3.612747004423192
Validation loss: 2.7306509733933204

Epoch: 6| Step: 11
Training loss: 2.9548660877951405
Validation loss: 2.7323054344021753

Epoch: 6| Step: 12
Training loss: 2.9206679191676646
Validation loss: 2.731090247884853

Epoch: 6| Step: 13
Training loss: 3.6112978878787554
Validation loss: 2.733527026440504

Epoch: 138| Step: 0
Training loss: 2.7905894141582106
Validation loss: 2.7284460787715825

Epoch: 6| Step: 1
Training loss: 3.682678173595059
Validation loss: 2.7312547263495985

Epoch: 6| Step: 2
Training loss: 3.445891385740673
Validation loss: 2.7333425430779976

Epoch: 6| Step: 3
Training loss: 2.0818387456077434
Validation loss: 2.732599581273959

Epoch: 6| Step: 4
Training loss: 2.4771268664856056
Validation loss: 2.7396076441028945

Epoch: 6| Step: 5
Training loss: 1.9281256528881088
Validation loss: 2.743677041895978

Epoch: 6| Step: 6
Training loss: 3.019343953905766
Validation loss: 2.7524360557826255

Epoch: 6| Step: 7
Training loss: 3.4704015425826813
Validation loss: 2.751231164058356

Epoch: 6| Step: 8
Training loss: 3.562089595244047
Validation loss: 2.7326030665701415

Epoch: 6| Step: 9
Training loss: 2.994377271205078
Validation loss: 2.7331067600505823

Epoch: 6| Step: 10
Training loss: 2.829943162057513
Validation loss: 2.7270864142064095

Epoch: 6| Step: 11
Training loss: 3.342012898939022
Validation loss: 2.7275381489075428

Epoch: 6| Step: 12
Training loss: 2.6029462370565
Validation loss: 2.7347426000685346

Epoch: 6| Step: 13
Training loss: 4.356841195270452
Validation loss: 2.734688272417555

Epoch: 139| Step: 0
Training loss: 3.3427349225432366
Validation loss: 2.7380010766880467

Epoch: 6| Step: 1
Training loss: 3.3021940740233076
Validation loss: 2.7346878590009265

Epoch: 6| Step: 2
Training loss: 2.687554735912668
Validation loss: 2.737042699491147

Epoch: 6| Step: 3
Training loss: 3.255109438601933
Validation loss: 2.7337388013705843

Epoch: 6| Step: 4
Training loss: 2.6479118073001415
Validation loss: 2.731711157657604

Epoch: 6| Step: 5
Training loss: 3.046954814158944
Validation loss: 2.727561227362332

Epoch: 6| Step: 6
Training loss: 3.5612099972182363
Validation loss: 2.728817566505583

Epoch: 6| Step: 7
Training loss: 3.232298843485644
Validation loss: 2.7247096103509767

Epoch: 6| Step: 8
Training loss: 3.154445169937046
Validation loss: 2.723204466984171

Epoch: 6| Step: 9
Training loss: 2.9304014429566343
Validation loss: 2.7245651570263174

Epoch: 6| Step: 10
Training loss: 2.372839296155224
Validation loss: 2.7259797406875084

Epoch: 6| Step: 11
Training loss: 2.7791481219525602
Validation loss: 2.7394980249621725

Epoch: 6| Step: 12
Training loss: 3.2962789132242873
Validation loss: 2.7448649748742744

Epoch: 6| Step: 13
Training loss: 2.9397936043985133
Validation loss: 2.7643460416662915

Epoch: 140| Step: 0
Training loss: 2.634334678839095
Validation loss: 2.7660851132623545

Epoch: 6| Step: 1
Training loss: 2.679806008790744
Validation loss: 2.745375236577733

Epoch: 6| Step: 2
Training loss: 3.4199596601192916
Validation loss: 2.7372194033319532

Epoch: 6| Step: 3
Training loss: 3.2718940683299267
Validation loss: 2.7343904303190056

Epoch: 6| Step: 4
Training loss: 2.6587879398079886
Validation loss: 2.7268139065416603

Epoch: 6| Step: 5
Training loss: 3.3303103726747043
Validation loss: 2.7319233966306338

Epoch: 6| Step: 6
Training loss: 3.5360018735682153
Validation loss: 2.727920718120494

Epoch: 6| Step: 7
Training loss: 2.8438487612164547
Validation loss: 2.723259682702134

Epoch: 6| Step: 8
Training loss: 2.6958295685527127
Validation loss: 2.723838310504836

Epoch: 6| Step: 9
Training loss: 3.47965444164563
Validation loss: 2.722836928631922

Epoch: 6| Step: 10
Training loss: 2.833217693287721
Validation loss: 2.7255400780344625

Epoch: 6| Step: 11
Training loss: 2.852616290464345
Validation loss: 2.721869661274068

Epoch: 6| Step: 12
Training loss: 3.1964031866942535
Validation loss: 2.721868839023596

Epoch: 6| Step: 13
Training loss: 3.062570065066656
Validation loss: 2.7214059366227175

Epoch: 141| Step: 0
Training loss: 3.157875473398716
Validation loss: 2.7227682118668706

Epoch: 6| Step: 1
Training loss: 3.495231922842604
Validation loss: 2.727927773496794

Epoch: 6| Step: 2
Training loss: 3.2641035852544564
Validation loss: 2.733752059177651

Epoch: 6| Step: 3
Training loss: 3.864002989647382
Validation loss: 2.7339241220980033

Epoch: 6| Step: 4
Training loss: 2.3662506364679463
Validation loss: 2.7265236807098696

Epoch: 6| Step: 5
Training loss: 2.893432903012164
Validation loss: 2.724978127814658

Epoch: 6| Step: 6
Training loss: 2.668861965716309
Validation loss: 2.720370782553648

Epoch: 6| Step: 7
Training loss: 2.8667964824588403
Validation loss: 2.725267615173885

Epoch: 6| Step: 8
Training loss: 2.6681968848346735
Validation loss: 2.71903307248124

Epoch: 6| Step: 9
Training loss: 3.467586012738156
Validation loss: 2.7211652698519053

Epoch: 6| Step: 10
Training loss: 2.704050071173711
Validation loss: 2.7186897383364315

Epoch: 6| Step: 11
Training loss: 3.145269650784724
Validation loss: 2.72367279495546

Epoch: 6| Step: 12
Training loss: 2.9255604068541863
Validation loss: 2.7231321924146106

Epoch: 6| Step: 13
Training loss: 2.595149478465985
Validation loss: 2.727617041939962

Epoch: 142| Step: 0
Training loss: 2.4161050297347324
Validation loss: 2.7465505024512047

Epoch: 6| Step: 1
Training loss: 3.0981435693088537
Validation loss: 2.7406431035717587

Epoch: 6| Step: 2
Training loss: 3.1353262616850444
Validation loss: 2.7520959442210673

Epoch: 6| Step: 3
Training loss: 3.01495512010058
Validation loss: 2.7441060192752302

Epoch: 6| Step: 4
Training loss: 3.186073732106025
Validation loss: 2.7293568541511024

Epoch: 6| Step: 5
Training loss: 3.1527400376296564
Validation loss: 2.7208026637834197

Epoch: 6| Step: 6
Training loss: 3.317428808648599
Validation loss: 2.7130646072032016

Epoch: 6| Step: 7
Training loss: 2.6144844330298507
Validation loss: 2.714597110872144

Epoch: 6| Step: 8
Training loss: 3.1131772510958515
Validation loss: 2.713275685628313

Epoch: 6| Step: 9
Training loss: 3.0458124900205585
Validation loss: 2.716751976895736

Epoch: 6| Step: 10
Training loss: 3.0392741543926376
Validation loss: 2.718102722853093

Epoch: 6| Step: 11
Training loss: 3.666044760472929
Validation loss: 2.7198733945048503

Epoch: 6| Step: 12
Training loss: 2.8957503784885534
Validation loss: 2.721939507389667

Epoch: 6| Step: 13
Training loss: 2.7085397103736355
Validation loss: 2.7145471710253593

Epoch: 143| Step: 0
Training loss: 2.9412616425691933
Validation loss: 2.7132220799348814

Epoch: 6| Step: 1
Training loss: 2.4946469216509164
Validation loss: 2.7133986202122617

Epoch: 6| Step: 2
Training loss: 2.657220640670083
Validation loss: 2.7139059006587183

Epoch: 6| Step: 3
Training loss: 3.592696989282469
Validation loss: 2.7120674333914243

Epoch: 6| Step: 4
Training loss: 3.7220642964150885
Validation loss: 2.714451692509396

Epoch: 6| Step: 5
Training loss: 2.815732327700871
Validation loss: 2.7272651834778228

Epoch: 6| Step: 6
Training loss: 2.653707566571146
Validation loss: 2.729796297446688

Epoch: 6| Step: 7
Training loss: 3.133100158726857
Validation loss: 2.813447303706825

Epoch: 6| Step: 8
Training loss: 2.9918156883364446
Validation loss: 2.7964069824800117

Epoch: 6| Step: 9
Training loss: 3.622413633381897
Validation loss: 2.7572290616245976

Epoch: 6| Step: 10
Training loss: 2.712526235145935
Validation loss: 2.73456495430953

Epoch: 6| Step: 11
Training loss: 2.980304598506322
Validation loss: 2.7255158292809343

Epoch: 6| Step: 12
Training loss: 3.0318700411883213
Validation loss: 2.7196566925438246

Epoch: 6| Step: 13
Training loss: 3.0348138996614953
Validation loss: 2.7263851882057772

Epoch: 144| Step: 0
Training loss: 3.373068079967365
Validation loss: 2.7370060117503727

Epoch: 6| Step: 1
Training loss: 3.2366789200063355
Validation loss: 2.742806909860985

Epoch: 6| Step: 2
Training loss: 3.3673798048153003
Validation loss: 2.7407226277206487

Epoch: 6| Step: 3
Training loss: 3.140264993407531
Validation loss: 2.7314878573477563

Epoch: 6| Step: 4
Training loss: 2.3188529513554252
Validation loss: 2.7220385413585957

Epoch: 6| Step: 5
Training loss: 3.01940428157214
Validation loss: 2.7198357163979243

Epoch: 6| Step: 6
Training loss: 2.89504205518361
Validation loss: 2.716941044043105

Epoch: 6| Step: 7
Training loss: 2.3394342997212814
Validation loss: 2.71327532186074

Epoch: 6| Step: 8
Training loss: 3.4120295776748804
Validation loss: 2.7237322244523123

Epoch: 6| Step: 9
Training loss: 3.017321331862809
Validation loss: 2.736128087755676

Epoch: 6| Step: 10
Training loss: 3.1619073003298035
Validation loss: 2.7582749044725134

Epoch: 6| Step: 11
Training loss: 3.162336165817095
Validation loss: 2.7467912876715137

Epoch: 6| Step: 12
Training loss: 2.9003488659662175
Validation loss: 2.759978797873368

Epoch: 6| Step: 13
Training loss: 3.300002363955489
Validation loss: 2.7398800938140124

Epoch: 145| Step: 0
Training loss: 3.021366168855763
Validation loss: 2.7133168260088785

Epoch: 6| Step: 1
Training loss: 3.5781837691765546
Validation loss: 2.7094553766379357

Epoch: 6| Step: 2
Training loss: 3.66571307064317
Validation loss: 2.713675195342362

Epoch: 6| Step: 3
Training loss: 2.8773184011576864
Validation loss: 2.713626424636308

Epoch: 6| Step: 4
Training loss: 2.7580432309032963
Validation loss: 2.719252390371904

Epoch: 6| Step: 5
Training loss: 2.447460072457652
Validation loss: 2.7174362895500304

Epoch: 6| Step: 6
Training loss: 2.617031719069473
Validation loss: 2.7162765984121306

Epoch: 6| Step: 7
Training loss: 2.547612744532802
Validation loss: 2.712716003182986

Epoch: 6| Step: 8
Training loss: 3.0158936375954264
Validation loss: 2.712191574975159

Epoch: 6| Step: 9
Training loss: 2.6387046738512523
Validation loss: 2.7107367636731357

Epoch: 6| Step: 10
Training loss: 3.3841290808153457
Validation loss: 2.7089308282356095

Epoch: 6| Step: 11
Training loss: 2.6479793366089837
Validation loss: 2.7104852316920156

Epoch: 6| Step: 12
Training loss: 3.4896315538101805
Validation loss: 2.7120666308556194

Epoch: 6| Step: 13
Training loss: 3.8560801661851993
Validation loss: 2.7094511008335536

Epoch: 146| Step: 0
Training loss: 2.7960582371705733
Validation loss: 2.712778838544857

Epoch: 6| Step: 1
Training loss: 3.651358176682182
Validation loss: 2.71012817966487

Epoch: 6| Step: 2
Training loss: 3.12788852708635
Validation loss: 2.7174149072111584

Epoch: 6| Step: 3
Training loss: 3.3980780049621604
Validation loss: 2.7200647083640725

Epoch: 6| Step: 4
Training loss: 3.194030355253112
Validation loss: 2.7192330841760235

Epoch: 6| Step: 5
Training loss: 3.5373311302397714
Validation loss: 2.7311067922042427

Epoch: 6| Step: 6
Training loss: 2.7813437799651943
Validation loss: 2.7352443249557665

Epoch: 6| Step: 7
Training loss: 3.057391674652413
Validation loss: 2.710208408120553

Epoch: 6| Step: 8
Training loss: 3.247984481276472
Validation loss: 2.7122587137208924

Epoch: 6| Step: 9
Training loss: 3.024635255119809
Validation loss: 2.7108656256162553

Epoch: 6| Step: 10
Training loss: 2.509196627347319
Validation loss: 2.7095015461905754

Epoch: 6| Step: 11
Training loss: 2.613853768213984
Validation loss: 2.7084302280658523

Epoch: 6| Step: 12
Training loss: 2.253747362589126
Validation loss: 2.7064321737835435

Epoch: 6| Step: 13
Training loss: 2.9919642272993445
Validation loss: 2.7053112336662037

Epoch: 147| Step: 0
Training loss: 3.08830985131543
Validation loss: 2.7034563711111144

Epoch: 6| Step: 1
Training loss: 2.726583661103861
Validation loss: 2.70616989307056

Epoch: 6| Step: 2
Training loss: 3.8935180692957645
Validation loss: 2.7064073673504496

Epoch: 6| Step: 3
Training loss: 2.6071041985200587
Validation loss: 2.701523451899915

Epoch: 6| Step: 4
Training loss: 3.127587734732976
Validation loss: 2.7043112132406097

Epoch: 6| Step: 5
Training loss: 2.287736423969475
Validation loss: 2.7022323533403623

Epoch: 6| Step: 6
Training loss: 3.770359339701731
Validation loss: 2.701723485491652

Epoch: 6| Step: 7
Training loss: 3.107756687159874
Validation loss: 2.7012780109441

Epoch: 6| Step: 8
Training loss: 3.0329044192503978
Validation loss: 2.70344584705034

Epoch: 6| Step: 9
Training loss: 3.084669253334273
Validation loss: 2.700554857777284

Epoch: 6| Step: 10
Training loss: 3.0169709517585486
Validation loss: 2.699553687930516

Epoch: 6| Step: 11
Training loss: 2.9081124521522193
Validation loss: 2.7039179613641546

Epoch: 6| Step: 12
Training loss: 2.7714948701021336
Validation loss: 2.7001923806652015

Epoch: 6| Step: 13
Training loss: 2.3673502548216026
Validation loss: 2.7078139312690936

Epoch: 148| Step: 0
Training loss: 2.66824352809822
Validation loss: 2.70856488250075

Epoch: 6| Step: 1
Training loss: 2.7955773609246277
Validation loss: 2.7326161080117872

Epoch: 6| Step: 2
Training loss: 3.6806847907515294
Validation loss: 2.75624586063227

Epoch: 6| Step: 3
Training loss: 2.271491722298414
Validation loss: 2.772075054407966

Epoch: 6| Step: 4
Training loss: 3.3591419227828796
Validation loss: 2.736743495862387

Epoch: 6| Step: 5
Training loss: 3.439394064920953
Validation loss: 2.72006903534378

Epoch: 6| Step: 6
Training loss: 3.047055283127876
Validation loss: 2.707189960050704

Epoch: 6| Step: 7
Training loss: 2.6757363420045386
Validation loss: 2.7017112011230635

Epoch: 6| Step: 8
Training loss: 2.7904087098169446
Validation loss: 2.697800332600111

Epoch: 6| Step: 9
Training loss: 2.633865281792491
Validation loss: 2.69502256503578

Epoch: 6| Step: 10
Training loss: 3.1354762142436816
Validation loss: 2.695468925037572

Epoch: 6| Step: 11
Training loss: 3.1274159057435194
Validation loss: 2.694574677342435

Epoch: 6| Step: 12
Training loss: 3.1713160130325395
Validation loss: 2.694801445475871

Epoch: 6| Step: 13
Training loss: 3.575635018670553
Validation loss: 2.6946526526847157

Epoch: 149| Step: 0
Training loss: 2.910990141117721
Validation loss: 2.694226947530237

Epoch: 6| Step: 1
Training loss: 3.2315797382983558
Validation loss: 2.6930907658940892

Epoch: 6| Step: 2
Training loss: 3.5935310628792303
Validation loss: 2.694143380873096

Epoch: 6| Step: 3
Training loss: 2.654922782076775
Validation loss: 2.6926096947738922

Epoch: 6| Step: 4
Training loss: 3.05690238246224
Validation loss: 2.692113081781303

Epoch: 6| Step: 5
Training loss: 2.78216477684006
Validation loss: 2.6940416704491383

Epoch: 6| Step: 6
Training loss: 2.960749879393333
Validation loss: 2.688565927340814

Epoch: 6| Step: 7
Training loss: 2.9081050735863303
Validation loss: 2.6894613693875544

Epoch: 6| Step: 8
Training loss: 3.2077200332299065
Validation loss: 2.6919396720473254

Epoch: 6| Step: 9
Training loss: 3.0560672697582425
Validation loss: 2.68910745757122

Epoch: 6| Step: 10
Training loss: 3.2655912698710337
Validation loss: 2.6900573281027427

Epoch: 6| Step: 11
Training loss: 2.4574993033422685
Validation loss: 2.692059386086473

Epoch: 6| Step: 12
Training loss: 2.975500202602661
Validation loss: 2.6926750253561247

Epoch: 6| Step: 13
Training loss: 3.2082650974167852
Validation loss: 2.7005413681700245

Epoch: 150| Step: 0
Training loss: 3.240150933458847
Validation loss: 2.69501558285059

Epoch: 6| Step: 1
Training loss: 3.3454639641060004
Validation loss: 2.691993859146588

Epoch: 6| Step: 2
Training loss: 3.4147225097693643
Validation loss: 2.6955118018546056

Epoch: 6| Step: 3
Training loss: 2.915279676260978
Validation loss: 2.6944861549599897

Epoch: 6| Step: 4
Training loss: 2.4379921440767767
Validation loss: 2.6881017266480365

Epoch: 6| Step: 5
Training loss: 2.761616965310729
Validation loss: 2.6911289080466383

Epoch: 6| Step: 6
Training loss: 2.500494145194867
Validation loss: 2.694326363564714

Epoch: 6| Step: 7
Training loss: 2.65724298205029
Validation loss: 2.693080415036118

Epoch: 6| Step: 8
Training loss: 1.8885067509577735
Validation loss: 2.70263599451656

Epoch: 6| Step: 9
Training loss: 2.96019661121534
Validation loss: 2.700005655727137

Epoch: 6| Step: 10
Training loss: 3.3936947756606926
Validation loss: 2.702121219863866

Epoch: 6| Step: 11
Training loss: 3.437220059180019
Validation loss: 2.699993673079418

Epoch: 6| Step: 12
Training loss: 3.166740282775758
Validation loss: 2.697366362277945

Epoch: 6| Step: 13
Training loss: 4.2324761781962845
Validation loss: 2.694086016384439

Epoch: 151| Step: 0
Training loss: 3.1506329400087942
Validation loss: 2.69053859879962

Epoch: 6| Step: 1
Training loss: 2.6825775487947876
Validation loss: 2.6893634703005254

Epoch: 6| Step: 2
Training loss: 3.054273338241819
Validation loss: 2.690147160755522

Epoch: 6| Step: 3
Training loss: 2.8459499359445575
Validation loss: 2.6911081349936303

Epoch: 6| Step: 4
Training loss: 3.4128801406571823
Validation loss: 2.688671946855535

Epoch: 6| Step: 5
Training loss: 2.447963752023196
Validation loss: 2.6920927400895374

Epoch: 6| Step: 6
Training loss: 3.3161055897005838
Validation loss: 2.6954945758838176

Epoch: 6| Step: 7
Training loss: 3.3796905136624047
Validation loss: 2.6887652773360236

Epoch: 6| Step: 8
Training loss: 2.9170927190681866
Validation loss: 2.687736453132953

Epoch: 6| Step: 9
Training loss: 3.487949881027334
Validation loss: 2.691796824942377

Epoch: 6| Step: 10
Training loss: 2.412177970621298
Validation loss: 2.6879118088511347

Epoch: 6| Step: 11
Training loss: 3.2492278722408914
Validation loss: 2.6936469269121783

Epoch: 6| Step: 12
Training loss: 3.1900149129202076
Validation loss: 2.6897098759093976

Epoch: 6| Step: 13
Training loss: 1.9777141126227242
Validation loss: 2.691102500158658

Epoch: 152| Step: 0
Training loss: 2.9146655892977713
Validation loss: 2.689634743509066

Epoch: 6| Step: 1
Training loss: 3.087251098731467
Validation loss: 2.692509160385707

Epoch: 6| Step: 2
Training loss: 2.8247647212804856
Validation loss: 2.6884982350674034

Epoch: 6| Step: 3
Training loss: 2.745401178446464
Validation loss: 2.6862574617014086

Epoch: 6| Step: 4
Training loss: 3.041094965748068
Validation loss: 2.6898481485061976

Epoch: 6| Step: 5
Training loss: 3.302545813936487
Validation loss: 2.684772804727511

Epoch: 6| Step: 6
Training loss: 3.518928840388197
Validation loss: 2.6864982034191884

Epoch: 6| Step: 7
Training loss: 2.8541632510719372
Validation loss: 2.6870047152715717

Epoch: 6| Step: 8
Training loss: 3.1190900231199903
Validation loss: 2.6883845160305047

Epoch: 6| Step: 9
Training loss: 2.98239021809083
Validation loss: 2.6879993765557306

Epoch: 6| Step: 10
Training loss: 2.7079900279460185
Validation loss: 2.6828457938651162

Epoch: 6| Step: 11
Training loss: 2.806465116891985
Validation loss: 2.68765867870893

Epoch: 6| Step: 12
Training loss: 3.033924299529149
Validation loss: 2.6888866810608927

Epoch: 6| Step: 13
Training loss: 3.3191983137474455
Validation loss: 2.697458473859195

Epoch: 153| Step: 0
Training loss: 2.5478735528408527
Validation loss: 2.695402596923496

Epoch: 6| Step: 1
Training loss: 2.998641024188017
Validation loss: 2.702524405231087

Epoch: 6| Step: 2
Training loss: 3.3640425083046535
Validation loss: 2.7101160781236517

Epoch: 6| Step: 3
Training loss: 3.0442999497656382
Validation loss: 2.710162482364176

Epoch: 6| Step: 4
Training loss: 2.665551717450731
Validation loss: 2.701248409996251

Epoch: 6| Step: 5
Training loss: 3.2375823257171237
Validation loss: 2.6988293935459344

Epoch: 6| Step: 6
Training loss: 3.433950637826966
Validation loss: 2.6829808475299908

Epoch: 6| Step: 7
Training loss: 2.5727025199040034
Validation loss: 2.6832661094135206

Epoch: 6| Step: 8
Training loss: 3.1387554316623714
Validation loss: 2.6790523081769035

Epoch: 6| Step: 9
Training loss: 2.712607712958259
Validation loss: 2.679754798742702

Epoch: 6| Step: 10
Training loss: 3.372978735469104
Validation loss: 2.682401110364399

Epoch: 6| Step: 11
Training loss: 2.8923102337861955
Validation loss: 2.6790543942632383

Epoch: 6| Step: 12
Training loss: 3.1536968215529133
Validation loss: 2.6777880257353806

Epoch: 6| Step: 13
Training loss: 3.037299343435833
Validation loss: 2.678910766295735

Epoch: 154| Step: 0
Training loss: 3.2689163194870243
Validation loss: 2.6808597484830057

Epoch: 6| Step: 1
Training loss: 2.635770500062136
Validation loss: 2.688689865864945

Epoch: 6| Step: 2
Training loss: 3.124472001293216
Validation loss: 2.700243468950087

Epoch: 6| Step: 3
Training loss: 2.5588473827650784
Validation loss: 2.71157941186531

Epoch: 6| Step: 4
Training loss: 3.1429850502738823
Validation loss: 2.7074170066743837

Epoch: 6| Step: 5
Training loss: 3.077942198926361
Validation loss: 2.717669955991319

Epoch: 6| Step: 6
Training loss: 2.7138942457719106
Validation loss: 2.752665458503854

Epoch: 6| Step: 7
Training loss: 3.4332230750839035
Validation loss: 2.770164876043742

Epoch: 6| Step: 8
Training loss: 3.7871688043299883
Validation loss: 2.7185479450779417

Epoch: 6| Step: 9
Training loss: 3.2765004979399115
Validation loss: 2.6760859945324813

Epoch: 6| Step: 10
Training loss: 2.7090401729676215
Validation loss: 2.6793906788512074

Epoch: 6| Step: 11
Training loss: 3.2303761995981484
Validation loss: 2.6892209687228767

Epoch: 6| Step: 12
Training loss: 2.659946338140969
Validation loss: 2.6873613547381514

Epoch: 6| Step: 13
Training loss: 2.3269480348037956
Validation loss: 2.7121747441851753

Epoch: 155| Step: 0
Training loss: 2.822076135101743
Validation loss: 2.7502154930531484

Epoch: 6| Step: 1
Training loss: 2.8903105693641176
Validation loss: 2.77657847362866

Epoch: 6| Step: 2
Training loss: 3.61279319972504
Validation loss: 2.7880347742990534

Epoch: 6| Step: 3
Training loss: 3.615285814311925
Validation loss: 2.7104990520298013

Epoch: 6| Step: 4
Training loss: 2.2033777835919475
Validation loss: 2.6870303314749733

Epoch: 6| Step: 5
Training loss: 3.0203191560769582
Validation loss: 2.6843640526985446

Epoch: 6| Step: 6
Training loss: 3.0585006758168567
Validation loss: 2.689700135865937

Epoch: 6| Step: 7
Training loss: 3.235810039815306
Validation loss: 2.686368287594464

Epoch: 6| Step: 8
Training loss: 2.6971281708561117
Validation loss: 2.689607153323215

Epoch: 6| Step: 9
Training loss: 3.2382844895000384
Validation loss: 2.6961723479135813

Epoch: 6| Step: 10
Training loss: 2.5392016563429354
Validation loss: 2.695902726279004

Epoch: 6| Step: 11
Training loss: 3.1294283199167654
Validation loss: 2.7033382637265535

Epoch: 6| Step: 12
Training loss: 2.8336099788767926
Validation loss: 2.7012626012189407

Epoch: 6| Step: 13
Training loss: 3.5927353463171703
Validation loss: 2.7111049552033726

Epoch: 156| Step: 0
Training loss: 2.995722263984859
Validation loss: 2.699088402132189

Epoch: 6| Step: 1
Training loss: 2.9597616553358623
Validation loss: 2.688649891425965

Epoch: 6| Step: 2
Training loss: 3.8251388424875037
Validation loss: 2.6874234512237045

Epoch: 6| Step: 3
Training loss: 2.956863862191855
Validation loss: 2.683532405580288

Epoch: 6| Step: 4
Training loss: 2.7840210044167137
Validation loss: 2.680692995616353

Epoch: 6| Step: 5
Training loss: 2.803301880698219
Validation loss: 2.680533950468945

Epoch: 6| Step: 6
Training loss: 2.7501843997513147
Validation loss: 2.682235455942007

Epoch: 6| Step: 7
Training loss: 2.3707572786259066
Validation loss: 2.6829965399815667

Epoch: 6| Step: 8
Training loss: 2.7581181775528867
Validation loss: 2.680388246916103

Epoch: 6| Step: 9
Training loss: 3.5763105431198334
Validation loss: 2.6804368787712134

Epoch: 6| Step: 10
Training loss: 3.8113150083928624
Validation loss: 2.6806072339437046

Epoch: 6| Step: 11
Training loss: 2.886663743502904
Validation loss: 2.672494723004964

Epoch: 6| Step: 12
Training loss: 2.484974434949441
Validation loss: 2.6733190547359365

Epoch: 6| Step: 13
Training loss: 2.841728246325527
Validation loss: 2.67208778749226

Epoch: 157| Step: 0
Training loss: 3.365841200321074
Validation loss: 2.671938798688801

Epoch: 6| Step: 1
Training loss: 2.20479158173381
Validation loss: 2.6752458873201586

Epoch: 6| Step: 2
Training loss: 2.76182666011995
Validation loss: 2.6732369874489077

Epoch: 6| Step: 3
Training loss: 2.91996433393043
Validation loss: 2.6804506331042033

Epoch: 6| Step: 4
Training loss: 3.1200496373751907
Validation loss: 2.6851687669124398

Epoch: 6| Step: 5
Training loss: 3.879558220321391
Validation loss: 2.6919231222396256

Epoch: 6| Step: 6
Training loss: 3.076931329862824
Validation loss: 2.705939783986157

Epoch: 6| Step: 7
Training loss: 3.45178320866782
Validation loss: 2.7079543287887318

Epoch: 6| Step: 8
Training loss: 3.1872277237034914
Validation loss: 2.702864908071074

Epoch: 6| Step: 9
Training loss: 3.212984421123274
Validation loss: 2.709342415171062

Epoch: 6| Step: 10
Training loss: 2.2469359833952907
Validation loss: 2.699818302559708

Epoch: 6| Step: 11
Training loss: 2.8625953758375635
Validation loss: 2.683906346506291

Epoch: 6| Step: 12
Training loss: 2.847341093564413
Validation loss: 2.675437305975013

Epoch: 6| Step: 13
Training loss: 2.0488937556516302
Validation loss: 2.6768941108944055

Epoch: 158| Step: 0
Training loss: 3.42317836795791
Validation loss: 2.671380744338841

Epoch: 6| Step: 1
Training loss: 2.7271533752103836
Validation loss: 2.6715262731820184

Epoch: 6| Step: 2
Training loss: 2.4766363379605396
Validation loss: 2.6713441164103267

Epoch: 6| Step: 3
Training loss: 3.3443237953208445
Validation loss: 2.6727591879842154

Epoch: 6| Step: 4
Training loss: 2.8296834961448414
Validation loss: 2.666953398942731

Epoch: 6| Step: 5
Training loss: 3.118327226440822
Validation loss: 2.666649518098862

Epoch: 6| Step: 6
Training loss: 2.7185722380654744
Validation loss: 2.667234062069399

Epoch: 6| Step: 7
Training loss: 3.015792130498626
Validation loss: 2.671542820757332

Epoch: 6| Step: 8
Training loss: 2.8012214857332842
Validation loss: 2.6727774438771505

Epoch: 6| Step: 9
Training loss: 2.993319862380723
Validation loss: 2.666790735975824

Epoch: 6| Step: 10
Training loss: 2.5722130702739108
Validation loss: 2.67051462091726

Epoch: 6| Step: 11
Training loss: 2.8911736045075824
Validation loss: 2.670958999967296

Epoch: 6| Step: 12
Training loss: 3.524123029988193
Validation loss: 2.6727335865532202

Epoch: 6| Step: 13
Training loss: 3.6713968168521354
Validation loss: 2.6711251233760143

Epoch: 159| Step: 0
Training loss: 3.0997898215138773
Validation loss: 2.6829192492554843

Epoch: 6| Step: 1
Training loss: 2.569033597341144
Validation loss: 2.6906011440991797

Epoch: 6| Step: 2
Training loss: 2.7007080915681754
Validation loss: 2.712517256568685

Epoch: 6| Step: 3
Training loss: 3.2124716256517623
Validation loss: 2.734847818446451

Epoch: 6| Step: 4
Training loss: 3.634471096300163
Validation loss: 2.756660342295973

Epoch: 6| Step: 5
Training loss: 3.2920606997005226
Validation loss: 2.7457826471677493

Epoch: 6| Step: 6
Training loss: 3.5699876766900402
Validation loss: 2.7105399016307703

Epoch: 6| Step: 7
Training loss: 2.5219359285352034
Validation loss: 2.6872235141864373

Epoch: 6| Step: 8
Training loss: 2.2379600733859353
Validation loss: 2.674561705135779

Epoch: 6| Step: 9
Training loss: 3.338488280315319
Validation loss: 2.667980093353765

Epoch: 6| Step: 10
Training loss: 3.304290098279639
Validation loss: 2.6638088272143436

Epoch: 6| Step: 11
Training loss: 2.8850234735813216
Validation loss: 2.6618355634065014

Epoch: 6| Step: 12
Training loss: 2.313104498957127
Validation loss: 2.6630844280520325

Epoch: 6| Step: 13
Training loss: 3.0079873566767605
Validation loss: 2.664766092612196

Epoch: 160| Step: 0
Training loss: 3.0740001944924704
Validation loss: 2.666019741606439

Epoch: 6| Step: 1
Training loss: 3.4145321730263904
Validation loss: 2.6675822265479683

Epoch: 6| Step: 2
Training loss: 3.0476351841147427
Validation loss: 2.666886294329254

Epoch: 6| Step: 3
Training loss: 3.1600456454203534
Validation loss: 2.6628614525884817

Epoch: 6| Step: 4
Training loss: 2.5571128228471913
Validation loss: 2.661922108996652

Epoch: 6| Step: 5
Training loss: 2.8134119038962475
Validation loss: 2.660752439413625

Epoch: 6| Step: 6
Training loss: 3.031087340090489
Validation loss: 2.661795177005562

Epoch: 6| Step: 7
Training loss: 2.617406306443509
Validation loss: 2.6613327127401236

Epoch: 6| Step: 8
Training loss: 2.937633267889947
Validation loss: 2.6698949145612434

Epoch: 6| Step: 9
Training loss: 3.413637182773353
Validation loss: 2.668794392290052

Epoch: 6| Step: 10
Training loss: 2.9908060017085623
Validation loss: 2.674061134462844

Epoch: 6| Step: 11
Training loss: 2.92702564621596
Validation loss: 2.6930020276639475

Epoch: 6| Step: 12
Training loss: 3.1537642557772236
Validation loss: 2.704784237114043

Epoch: 6| Step: 13
Training loss: 2.567918491597053
Validation loss: 2.702707393419618

Epoch: 161| Step: 0
Training loss: 2.719668178513824
Validation loss: 2.707325777449568

Epoch: 6| Step: 1
Training loss: 3.5184979038489774
Validation loss: 2.6972582237649

Epoch: 6| Step: 2
Training loss: 3.167717675585499
Validation loss: 2.731559558886736

Epoch: 6| Step: 3
Training loss: 3.682706400362974
Validation loss: 2.7120610707600434

Epoch: 6| Step: 4
Training loss: 3.4841138801751725
Validation loss: 2.6989147300650944

Epoch: 6| Step: 5
Training loss: 2.3957617928701236
Validation loss: 2.6880931118687896

Epoch: 6| Step: 6
Training loss: 2.9558380420591024
Validation loss: 2.6750263617244654

Epoch: 6| Step: 7
Training loss: 3.2273047380899063
Validation loss: 2.679055636345064

Epoch: 6| Step: 8
Training loss: 2.6711923719945565
Validation loss: 2.6664912832047776

Epoch: 6| Step: 9
Training loss: 2.7887084052293765
Validation loss: 2.6651884033446427

Epoch: 6| Step: 10
Training loss: 3.150346730843469
Validation loss: 2.656228768868864

Epoch: 6| Step: 11
Training loss: 2.790234573238216
Validation loss: 2.656429121141638

Epoch: 6| Step: 12
Training loss: 2.685730995108851
Validation loss: 2.6579709601248043

Epoch: 6| Step: 13
Training loss: 2.1955266556186985
Validation loss: 2.6579262373302988

Epoch: 162| Step: 0
Training loss: 3.5669994383208077
Validation loss: 2.6590498219045897

Epoch: 6| Step: 1
Training loss: 3.0541557766319927
Validation loss: 2.6611216991049877

Epoch: 6| Step: 2
Training loss: 3.0354874085347556
Validation loss: 2.6675288741407948

Epoch: 6| Step: 3
Training loss: 3.343352106966484
Validation loss: 2.6709656755090543

Epoch: 6| Step: 4
Training loss: 3.3262158859665365
Validation loss: 2.6845895719392603

Epoch: 6| Step: 5
Training loss: 3.4570762157209827
Validation loss: 2.672987683155034

Epoch: 6| Step: 6
Training loss: 2.6020597148848563
Validation loss: 2.6788434233810983

Epoch: 6| Step: 7
Training loss: 3.313655148029661
Validation loss: 2.668548133352586

Epoch: 6| Step: 8
Training loss: 2.5551424233890545
Validation loss: 2.6651201163358578

Epoch: 6| Step: 9
Training loss: 2.5126565988807394
Validation loss: 2.6664280791095014

Epoch: 6| Step: 10
Training loss: 3.0348165707406425
Validation loss: 2.673665015402565

Epoch: 6| Step: 11
Training loss: 2.7027434151392566
Validation loss: 2.6693733083211604

Epoch: 6| Step: 12
Training loss: 2.2182200698922774
Validation loss: 2.6691547673300335

Epoch: 6| Step: 13
Training loss: 2.637615497826357
Validation loss: 2.6805186825870915

Epoch: 163| Step: 0
Training loss: 2.5504467030624958
Validation loss: 2.6795600529072483

Epoch: 6| Step: 1
Training loss: 3.7018820692719756
Validation loss: 2.6954300754768483

Epoch: 6| Step: 2
Training loss: 2.2504704301506435
Validation loss: 2.710792559143154

Epoch: 6| Step: 3
Training loss: 3.2411741580468223
Validation loss: 2.674538055285063

Epoch: 6| Step: 4
Training loss: 2.83817020517188
Validation loss: 2.6806012336990044

Epoch: 6| Step: 5
Training loss: 3.2974893440496658
Validation loss: 2.6792937379625776

Epoch: 6| Step: 6
Training loss: 3.186567282250843
Validation loss: 2.6562699174224726

Epoch: 6| Step: 7
Training loss: 3.2993033627484696
Validation loss: 2.653424712324726

Epoch: 6| Step: 8
Training loss: 2.9802181993516967
Validation loss: 2.658086089308909

Epoch: 6| Step: 9
Training loss: 2.459056898627699
Validation loss: 2.6531628460568273

Epoch: 6| Step: 10
Training loss: 3.2116864669762215
Validation loss: 2.664224211407727

Epoch: 6| Step: 11
Training loss: 2.9265161872128016
Validation loss: 2.6591540835530014

Epoch: 6| Step: 12
Training loss: 2.9055939620984566
Validation loss: 2.656523541933873

Epoch: 6| Step: 13
Training loss: 2.587963589773277
Validation loss: 2.6526461644864425

Epoch: 164| Step: 0
Training loss: 2.400123624796573
Validation loss: 2.6514479292834463

Epoch: 6| Step: 1
Training loss: 3.248630822150761
Validation loss: 2.6548433255117976

Epoch: 6| Step: 2
Training loss: 2.944375453196689
Validation loss: 2.6597964012831183

Epoch: 6| Step: 3
Training loss: 2.6978182879054113
Validation loss: 2.671872301909293

Epoch: 6| Step: 4
Training loss: 3.532498029423493
Validation loss: 2.6622531409575614

Epoch: 6| Step: 5
Training loss: 3.1205563804742034
Validation loss: 2.6824357284502383

Epoch: 6| Step: 6
Training loss: 3.053297892646611
Validation loss: 2.7017695433109714

Epoch: 6| Step: 7
Training loss: 3.301717230460821
Validation loss: 2.6965455932002755

Epoch: 6| Step: 8
Training loss: 2.806702721319634
Validation loss: 2.7003462445238964

Epoch: 6| Step: 9
Training loss: 2.823666087166463
Validation loss: 2.6742485617878087

Epoch: 6| Step: 10
Training loss: 2.697418098090198
Validation loss: 2.6742631570362545

Epoch: 6| Step: 11
Training loss: 2.603110279714813
Validation loss: 2.6625493614824047

Epoch: 6| Step: 12
Training loss: 2.754877619855085
Validation loss: 2.660934005194619

Epoch: 6| Step: 13
Training loss: 4.057615424751422
Validation loss: 2.650609201365617

Epoch: 165| Step: 0
Training loss: 3.2873606140989318
Validation loss: 2.655514096281556

Epoch: 6| Step: 1
Training loss: 3.1448035838981787
Validation loss: 2.6505072122022026

Epoch: 6| Step: 2
Training loss: 2.387484213891692
Validation loss: 2.6534104903680555

Epoch: 6| Step: 3
Training loss: 2.9898573764224365
Validation loss: 2.647451866081314

Epoch: 6| Step: 4
Training loss: 2.7085849547264003
Validation loss: 2.6523034442791538

Epoch: 6| Step: 5
Training loss: 3.131127567905304
Validation loss: 2.6475095254183154

Epoch: 6| Step: 6
Training loss: 3.2942812872960774
Validation loss: 2.6546613658525504

Epoch: 6| Step: 7
Training loss: 2.8193911582367055
Validation loss: 2.65547748119868

Epoch: 6| Step: 8
Training loss: 3.2093992237933797
Validation loss: 2.65543591488444

Epoch: 6| Step: 9
Training loss: 2.582838985355781
Validation loss: 2.654386869024377

Epoch: 6| Step: 10
Training loss: 2.7633863968887016
Validation loss: 2.6574932762181867

Epoch: 6| Step: 11
Training loss: 3.341225499992013
Validation loss: 2.6668640020122036

Epoch: 6| Step: 12
Training loss: 2.896198569850807
Validation loss: 2.6677299931622405

Epoch: 6| Step: 13
Training loss: 3.0924117151115693
Validation loss: 2.6830317026646986

Epoch: 166| Step: 0
Training loss: 3.149028410254323
Validation loss: 2.6731420147970746

Epoch: 6| Step: 1
Training loss: 3.043861189736288
Validation loss: 2.688818901518119

Epoch: 6| Step: 2
Training loss: 2.6282034808947548
Validation loss: 2.679802656681533

Epoch: 6| Step: 3
Training loss: 2.5724219851809944
Validation loss: 2.6820722975103015

Epoch: 6| Step: 4
Training loss: 3.0031124499770288
Validation loss: 2.672521144972422

Epoch: 6| Step: 5
Training loss: 3.1706128545461185
Validation loss: 2.673668315758283

Epoch: 6| Step: 6
Training loss: 2.7451104130452695
Validation loss: 2.6657017979838185

Epoch: 6| Step: 7
Training loss: 2.367775016368153
Validation loss: 2.673707196748603

Epoch: 6| Step: 8
Training loss: 2.791604302312288
Validation loss: 2.6609422791734194

Epoch: 6| Step: 9
Training loss: 3.53866851163048
Validation loss: 2.660503740183663

Epoch: 6| Step: 10
Training loss: 3.1443562524092954
Validation loss: 2.6631442671895016

Epoch: 6| Step: 11
Training loss: 3.229439771034786
Validation loss: 2.66768454264856

Epoch: 6| Step: 12
Training loss: 2.665236586327036
Validation loss: 2.6766594698502235

Epoch: 6| Step: 13
Training loss: 3.758991778113813
Validation loss: 2.65899698090581

Epoch: 167| Step: 0
Training loss: 3.4524715029612865
Validation loss: 2.6636613252608115

Epoch: 6| Step: 1
Training loss: 2.758663316409678
Validation loss: 2.661112813943117

Epoch: 6| Step: 2
Training loss: 3.1325695676149423
Validation loss: 2.66690572665629

Epoch: 6| Step: 3
Training loss: 2.8407540102158824
Validation loss: 2.676661960067088

Epoch: 6| Step: 4
Training loss: 3.310610250130855
Validation loss: 2.6748250389441326

Epoch: 6| Step: 5
Training loss: 2.8892937971484027
Validation loss: 2.668019373367263

Epoch: 6| Step: 6
Training loss: 2.858071452193294
Validation loss: 2.6672957476905177

Epoch: 6| Step: 7
Training loss: 2.7286858365618643
Validation loss: 2.666968430633003

Epoch: 6| Step: 8
Training loss: 2.994071347504557
Validation loss: 2.6748665943601426

Epoch: 6| Step: 9
Training loss: 2.9522657002016945
Validation loss: 2.6688988159798264

Epoch: 6| Step: 10
Training loss: 3.073189588593018
Validation loss: 2.666294701332002

Epoch: 6| Step: 11
Training loss: 2.4784784937993862
Validation loss: 2.6794654306681913

Epoch: 6| Step: 12
Training loss: 2.895059349492677
Validation loss: 2.6846320008521043

Epoch: 6| Step: 13
Training loss: 3.399975238036697
Validation loss: 2.716050106455442

Epoch: 168| Step: 0
Training loss: 3.109302922472542
Validation loss: 2.6757082559204113

Epoch: 6| Step: 1
Training loss: 2.4679005767110556
Validation loss: 2.669330533148139

Epoch: 6| Step: 2
Training loss: 2.6710411689182005
Validation loss: 2.6593891990825003

Epoch: 6| Step: 3
Training loss: 2.8941865991253293
Validation loss: 2.6489976518102676

Epoch: 6| Step: 4
Training loss: 3.1622788664813437
Validation loss: 2.6465695782512833

Epoch: 6| Step: 5
Training loss: 2.67008260649147
Validation loss: 2.6442065332313

Epoch: 6| Step: 6
Training loss: 3.3624032499440597
Validation loss: 2.644315348261456

Epoch: 6| Step: 7
Training loss: 2.2654745117720414
Validation loss: 2.653387729281769

Epoch: 6| Step: 8
Training loss: 2.979923463388993
Validation loss: 2.6523780702734356

Epoch: 6| Step: 9
Training loss: 2.474717954498085
Validation loss: 2.6573283593750463

Epoch: 6| Step: 10
Training loss: 3.1053459095201355
Validation loss: 2.6619468388180967

Epoch: 6| Step: 11
Training loss: 3.80598530968674
Validation loss: 2.6852422666401483

Epoch: 6| Step: 12
Training loss: 3.441894773693512
Validation loss: 2.667763484137412

Epoch: 6| Step: 13
Training loss: 3.0767169965909793
Validation loss: 2.6527909728793713

Epoch: 169| Step: 0
Training loss: 3.1546341187267135
Validation loss: 2.6433765317963873

Epoch: 6| Step: 1
Training loss: 2.865338553086478
Validation loss: 2.6445142251296136

Epoch: 6| Step: 2
Training loss: 2.5329794921044813
Validation loss: 2.646006831774738

Epoch: 6| Step: 3
Training loss: 3.331310628085207
Validation loss: 2.644529764860221

Epoch: 6| Step: 4
Training loss: 2.464572897658151
Validation loss: 2.6408445030765253

Epoch: 6| Step: 5
Training loss: 2.9252163146801466
Validation loss: 2.6506432055859572

Epoch: 6| Step: 6
Training loss: 3.338577690862503
Validation loss: 2.653695714921046

Epoch: 6| Step: 7
Training loss: 3.0659756303429635
Validation loss: 2.6494276885674033

Epoch: 6| Step: 8
Training loss: 2.488348991394176
Validation loss: 2.6462559890902115

Epoch: 6| Step: 9
Training loss: 3.0956100883101634
Validation loss: 2.6469026135550555

Epoch: 6| Step: 10
Training loss: 3.0256847142609398
Validation loss: 2.6457441930375247

Epoch: 6| Step: 11
Training loss: 2.9526169758750602
Validation loss: 2.6430689853441565

Epoch: 6| Step: 12
Training loss: 3.33135743388411
Validation loss: 2.639843837751619

Epoch: 6| Step: 13
Training loss: 3.097161771890478
Validation loss: 2.646458393458732

Epoch: 170| Step: 0
Training loss: 2.8843530193247653
Validation loss: 2.6455945627538013

Epoch: 6| Step: 1
Training loss: 3.046695175733117
Validation loss: 2.6445089282224057

Epoch: 6| Step: 2
Training loss: 3.305291880359082
Validation loss: 2.648882480866831

Epoch: 6| Step: 3
Training loss: 2.5402742751412366
Validation loss: 2.6572990850327685

Epoch: 6| Step: 4
Training loss: 2.9658638828808956
Validation loss: 2.657022054910527

Epoch: 6| Step: 5
Training loss: 2.67862264311739
Validation loss: 2.6532957718483057

Epoch: 6| Step: 6
Training loss: 3.1716485905762783
Validation loss: 2.6566694841670895

Epoch: 6| Step: 7
Training loss: 3.0445626116031312
Validation loss: 2.6468996992057026

Epoch: 6| Step: 8
Training loss: 2.963080363022902
Validation loss: 2.641813105692812

Epoch: 6| Step: 9
Training loss: 2.7709977715440957
Validation loss: 2.64477872642556

Epoch: 6| Step: 10
Training loss: 3.0472896978402755
Validation loss: 2.6413640231245674

Epoch: 6| Step: 11
Training loss: 3.2802599185211894
Validation loss: 2.639550338111424

Epoch: 6| Step: 12
Training loss: 2.949180916044576
Validation loss: 2.643502255382814

Epoch: 6| Step: 13
Training loss: 2.9712454497062173
Validation loss: 2.6389243803748146

Epoch: 171| Step: 0
Training loss: 3.0156397053256256
Validation loss: 2.6467656037029634

Epoch: 6| Step: 1
Training loss: 2.8984674416201117
Validation loss: 2.6393352343354817

Epoch: 6| Step: 2
Training loss: 2.8239104338753034
Validation loss: 2.6511490072396

Epoch: 6| Step: 3
Training loss: 2.6517038373981308
Validation loss: 2.644864576859862

Epoch: 6| Step: 4
Training loss: 3.015763195606966
Validation loss: 2.6445000076017697

Epoch: 6| Step: 5
Training loss: 2.6376808502241436
Validation loss: 2.646640008013766

Epoch: 6| Step: 6
Training loss: 2.6237133142415483
Validation loss: 2.6425004534219854

Epoch: 6| Step: 7
Training loss: 3.344836762555035
Validation loss: 2.6481196613619975

Epoch: 6| Step: 8
Training loss: 3.5108598076611224
Validation loss: 2.6428795481102814

Epoch: 6| Step: 9
Training loss: 3.3864574221552397
Validation loss: 2.6328348508348456

Epoch: 6| Step: 10
Training loss: 2.5555127412093643
Validation loss: 2.639850314232607

Epoch: 6| Step: 11
Training loss: 3.1148682190771404
Validation loss: 2.637551924472329

Epoch: 6| Step: 12
Training loss: 3.1208520444776786
Validation loss: 2.6425874469493436

Epoch: 6| Step: 13
Training loss: 2.56644080848593
Validation loss: 2.6328988029313134

Epoch: 172| Step: 0
Training loss: 3.5641430194728208
Validation loss: 2.6320398997936043

Epoch: 6| Step: 1
Training loss: 2.7243983908285996
Validation loss: 2.637500099104756

Epoch: 6| Step: 2
Training loss: 2.8926524707170085
Validation loss: 2.6354284354735102

Epoch: 6| Step: 3
Training loss: 3.0726303398229007
Validation loss: 2.631899735615061

Epoch: 6| Step: 4
Training loss: 3.1387326437023235
Validation loss: 2.632069399554917

Epoch: 6| Step: 5
Training loss: 2.633341659661501
Validation loss: 2.629199086199635

Epoch: 6| Step: 6
Training loss: 2.6848669238650817
Validation loss: 2.62896335556057

Epoch: 6| Step: 7
Training loss: 1.807096252723597
Validation loss: 2.629400349512868

Epoch: 6| Step: 8
Training loss: 3.5836577305592905
Validation loss: 2.628394495263823

Epoch: 6| Step: 9
Training loss: 2.42441037275408
Validation loss: 2.6379614673932417

Epoch: 6| Step: 10
Training loss: 3.4349214072308176
Validation loss: 2.6408749985266904

Epoch: 6| Step: 11
Training loss: 2.364210415868886
Validation loss: 2.6355676386859512

Epoch: 6| Step: 12
Training loss: 3.298906613325819
Validation loss: 2.636780958942006

Epoch: 6| Step: 13
Training loss: 3.6897694990742753
Validation loss: 2.644535241551376

Epoch: 173| Step: 0
Training loss: 2.9670127202485497
Validation loss: 2.6486755229287255

Epoch: 6| Step: 1
Training loss: 3.056487428768795
Validation loss: 2.649515830558563

Epoch: 6| Step: 2
Training loss: 3.8090917643146542
Validation loss: 2.651281620145786

Epoch: 6| Step: 3
Training loss: 2.9341175815500034
Validation loss: 2.65414305192356

Epoch: 6| Step: 4
Training loss: 2.6388180661875853
Validation loss: 2.6584994747112103

Epoch: 6| Step: 5
Training loss: 2.928541116856671
Validation loss: 2.6579184815603543

Epoch: 6| Step: 6
Training loss: 2.2334441266642764
Validation loss: 2.6505591082283915

Epoch: 6| Step: 7
Training loss: 2.9020133363087375
Validation loss: 2.6418424380990775

Epoch: 6| Step: 8
Training loss: 3.386127635931831
Validation loss: 2.6420688903530682

Epoch: 6| Step: 9
Training loss: 3.045357507223373
Validation loss: 2.6343443053634066

Epoch: 6| Step: 10
Training loss: 3.0788777781527368
Validation loss: 2.6378959936633204

Epoch: 6| Step: 11
Training loss: 2.764486218500033
Validation loss: 2.6344561532265995

Epoch: 6| Step: 12
Training loss: 2.874612533333297
Validation loss: 2.632118219974135

Epoch: 6| Step: 13
Training loss: 2.3833359440431323
Validation loss: 2.6310210780413277

Epoch: 174| Step: 0
Training loss: 3.057972890071319
Validation loss: 2.6263846111627367

Epoch: 6| Step: 1
Training loss: 1.9291870456660047
Validation loss: 2.634621042191378

Epoch: 6| Step: 2
Training loss: 2.5719695619647873
Validation loss: 2.6331689359077166

Epoch: 6| Step: 3
Training loss: 2.844448129664789
Validation loss: 2.636175768511135

Epoch: 6| Step: 4
Training loss: 3.3732255580205726
Validation loss: 2.6425369970477828

Epoch: 6| Step: 5
Training loss: 2.654092248884424
Validation loss: 2.638788511687597

Epoch: 6| Step: 6
Training loss: 3.353657385663091
Validation loss: 2.6562662306307203

Epoch: 6| Step: 7
Training loss: 2.7375135447545906
Validation loss: 2.658796490444261

Epoch: 6| Step: 8
Training loss: 3.3360629984992873
Validation loss: 2.6870452160284937

Epoch: 6| Step: 9
Training loss: 2.477790985110236
Validation loss: 2.6911811486226473

Epoch: 6| Step: 10
Training loss: 2.949774885478551
Validation loss: 2.6809529588657415

Epoch: 6| Step: 11
Training loss: 3.253832098401047
Validation loss: 2.6435638353267454

Epoch: 6| Step: 12
Training loss: 3.422998809912316
Validation loss: 2.6345317761763485

Epoch: 6| Step: 13
Training loss: 3.3787294198219846
Validation loss: 2.630988745633591

Epoch: 175| Step: 0
Training loss: 3.2526557048850844
Validation loss: 2.627851833677465

Epoch: 6| Step: 1
Training loss: 3.002470588635319
Validation loss: 2.6271503096807094

Epoch: 6| Step: 2
Training loss: 2.758981257132689
Validation loss: 2.6268797695599337

Epoch: 6| Step: 3
Training loss: 3.2365311516921977
Validation loss: 2.6230654710144026

Epoch: 6| Step: 4
Training loss: 2.880157488649506
Validation loss: 2.6242837978716644

Epoch: 6| Step: 5
Training loss: 3.2009469419334713
Validation loss: 2.6241333190462006

Epoch: 6| Step: 6
Training loss: 2.891695721248539
Validation loss: 2.6222114175945626

Epoch: 6| Step: 7
Training loss: 2.737207482442812
Validation loss: 2.6220066115600242

Epoch: 6| Step: 8
Training loss: 3.4360928516387634
Validation loss: 2.620300423299218

Epoch: 6| Step: 9
Training loss: 2.819018629853557
Validation loss: 2.6258369811747797

Epoch: 6| Step: 10
Training loss: 2.5611976477437475
Validation loss: 2.6191498923552397

Epoch: 6| Step: 11
Training loss: 2.8077263905393024
Validation loss: 2.619767885759301

Epoch: 6| Step: 12
Training loss: 2.5714428859645295
Validation loss: 2.623141133062071

Epoch: 6| Step: 13
Training loss: 3.4808993260511034
Validation loss: 2.6253102300395823

Epoch: 176| Step: 0
Training loss: 2.5229648584435176
Validation loss: 2.6195153521832575

Epoch: 6| Step: 1
Training loss: 3.2213826200091584
Validation loss: 2.621610151054017

Epoch: 6| Step: 2
Training loss: 3.1960309626925936
Validation loss: 2.6191447154431584

Epoch: 6| Step: 3
Training loss: 3.4860433510269573
Validation loss: 2.619875722558576

Epoch: 6| Step: 4
Training loss: 2.9099376621975903
Validation loss: 2.6216897049326766

Epoch: 6| Step: 5
Training loss: 2.988790072336393
Validation loss: 2.6198487931312453

Epoch: 6| Step: 6
Training loss: 3.049220664091924
Validation loss: 2.618146719296043

Epoch: 6| Step: 7
Training loss: 2.2588562978063487
Validation loss: 2.6218819995521567

Epoch: 6| Step: 8
Training loss: 2.1894152295170533
Validation loss: 2.623249955061792

Epoch: 6| Step: 9
Training loss: 3.107620741200988
Validation loss: 2.6273826122689234

Epoch: 6| Step: 10
Training loss: 2.9889539173462563
Validation loss: 2.6292139973425197

Epoch: 6| Step: 11
Training loss: 3.087730640028546
Validation loss: 2.6271540568484992

Epoch: 6| Step: 12
Training loss: 3.4928379349176235
Validation loss: 2.627069457378891

Epoch: 6| Step: 13
Training loss: 2.4107829412140025
Validation loss: 2.6214116772964884

Epoch: 177| Step: 0
Training loss: 2.9971606805576116
Validation loss: 2.6232931464201146

Epoch: 6| Step: 1
Training loss: 2.540124759013092
Validation loss: 2.6296296144082643

Epoch: 6| Step: 2
Training loss: 3.290441228620245
Validation loss: 2.636889674010569

Epoch: 6| Step: 3
Training loss: 3.10651576787636
Validation loss: 2.6271856840978716

Epoch: 6| Step: 4
Training loss: 2.7468765033114577
Validation loss: 2.6374281713614165

Epoch: 6| Step: 5
Training loss: 2.97124464728644
Validation loss: 2.6375254991927135

Epoch: 6| Step: 6
Training loss: 3.008550221522786
Validation loss: 2.6300960234539033

Epoch: 6| Step: 7
Training loss: 2.9209687974746172
Validation loss: 2.6375534621399916

Epoch: 6| Step: 8
Training loss: 2.757382972703338
Validation loss: 2.6371131743553677

Epoch: 6| Step: 9
Training loss: 2.8730229753424705
Validation loss: 2.6278840720052505

Epoch: 6| Step: 10
Training loss: 3.2194127261647583
Validation loss: 2.625527195647612

Epoch: 6| Step: 11
Training loss: 2.9412462411346607
Validation loss: 2.6293042058816285

Epoch: 6| Step: 12
Training loss: 3.2016225873410598
Validation loss: 2.629626666292079

Epoch: 6| Step: 13
Training loss: 2.637532607324449
Validation loss: 2.633613393285668

Epoch: 178| Step: 0
Training loss: 2.4660265422732266
Validation loss: 2.6272428534029024

Epoch: 6| Step: 1
Training loss: 2.7895294567904303
Validation loss: 2.63976512524143

Epoch: 6| Step: 2
Training loss: 3.2193576276247873
Validation loss: 2.6407268611559425

Epoch: 6| Step: 3
Training loss: 2.735682496409422
Validation loss: 2.645764083931467

Epoch: 6| Step: 4
Training loss: 3.364150232995122
Validation loss: 2.645906976539401

Epoch: 6| Step: 5
Training loss: 2.889315581803068
Validation loss: 2.6744015975145

Epoch: 6| Step: 6
Training loss: 2.961205462808812
Validation loss: 2.643912356264682

Epoch: 6| Step: 7
Training loss: 2.89339664682943
Validation loss: 2.6449466802594412

Epoch: 6| Step: 8
Training loss: 3.2529406815053634
Validation loss: 2.639232984351169

Epoch: 6| Step: 9
Training loss: 3.091349585657078
Validation loss: 2.63116089929144

Epoch: 6| Step: 10
Training loss: 2.5763025489271243
Validation loss: 2.627318893764423

Epoch: 6| Step: 11
Training loss: 2.5972706444000884
Validation loss: 2.6297524242984904

Epoch: 6| Step: 12
Training loss: 3.0240361214957945
Validation loss: 2.6232980874442866

Epoch: 6| Step: 13
Training loss: 3.7145496657138906
Validation loss: 2.6201247626104585

Epoch: 179| Step: 0
Training loss: 2.761124737213646
Validation loss: 2.619996067882694

Epoch: 6| Step: 1
Training loss: 2.8486545733227806
Validation loss: 2.617956202826271

Epoch: 6| Step: 2
Training loss: 3.190903286655683
Validation loss: 2.623360250127782

Epoch: 6| Step: 3
Training loss: 2.7677772035789157
Validation loss: 2.6195183752926074

Epoch: 6| Step: 4
Training loss: 3.1107783385582244
Validation loss: 2.6286049683771213

Epoch: 6| Step: 5
Training loss: 2.744030020986104
Validation loss: 2.6268579946056336

Epoch: 6| Step: 6
Training loss: 3.1481454870009133
Validation loss: 2.63749990373347

Epoch: 6| Step: 7
Training loss: 2.9566288904861104
Validation loss: 2.6428695462361396

Epoch: 6| Step: 8
Training loss: 3.151966322907754
Validation loss: 2.642458272593968

Epoch: 6| Step: 9
Training loss: 2.7669343596718052
Validation loss: 2.6431040026756945

Epoch: 6| Step: 10
Training loss: 3.3469576557399714
Validation loss: 2.6445955813443893

Epoch: 6| Step: 11
Training loss: 3.0681753704375776
Validation loss: 2.635889802623218

Epoch: 6| Step: 12
Training loss: 2.5111417448750286
Validation loss: 2.640099987990421

Epoch: 6| Step: 13
Training loss: 2.921362847306051
Validation loss: 2.6419506314641596

Epoch: 180| Step: 0
Training loss: 2.784705426510848
Validation loss: 2.635841370103219

Epoch: 6| Step: 1
Training loss: 2.3025103096829533
Validation loss: 2.6150951942599234

Epoch: 6| Step: 2
Training loss: 2.8585812660397156
Validation loss: 2.627805608067985

Epoch: 6| Step: 3
Training loss: 3.064546485193545
Validation loss: 2.6177033554072975

Epoch: 6| Step: 4
Training loss: 2.6608043446939473
Validation loss: 2.6170023084151306

Epoch: 6| Step: 5
Training loss: 2.409111204438085
Validation loss: 2.6202600140770396

Epoch: 6| Step: 6
Training loss: 3.0530400431281355
Validation loss: 2.6168894676891417

Epoch: 6| Step: 7
Training loss: 2.9605512945894903
Validation loss: 2.6150841499061834

Epoch: 6| Step: 8
Training loss: 2.7669862317513725
Validation loss: 2.615337165266268

Epoch: 6| Step: 9
Training loss: 3.415348605100269
Validation loss: 2.6210530586018943

Epoch: 6| Step: 10
Training loss: 3.24117371669085
Validation loss: 2.6178471274731563

Epoch: 6| Step: 11
Training loss: 3.509485606134541
Validation loss: 2.626749764197652

Epoch: 6| Step: 12
Training loss: 3.6277200425210845
Validation loss: 2.6234246589256327

Epoch: 6| Step: 13
Training loss: 1.8542203216790378
Validation loss: 2.626259596786422

Epoch: 181| Step: 0
Training loss: 2.9120645091069317
Validation loss: 2.6287520373349316

Epoch: 6| Step: 1
Training loss: 3.4918778045353536
Validation loss: 2.6312460706630474

Epoch: 6| Step: 2
Training loss: 3.2477118433455927
Validation loss: 2.6401046878160668

Epoch: 6| Step: 3
Training loss: 2.9327284022992703
Validation loss: 2.6378312773422716

Epoch: 6| Step: 4
Training loss: 2.9889574270729407
Validation loss: 2.6438683546485944

Epoch: 6| Step: 5
Training loss: 1.9941828290786772
Validation loss: 2.6413815885239385

Epoch: 6| Step: 6
Training loss: 2.6158781049951223
Validation loss: 2.627204680171171

Epoch: 6| Step: 7
Training loss: 2.9545555888182222
Validation loss: 2.6339718328727693

Epoch: 6| Step: 8
Training loss: 3.0837694495445565
Validation loss: 2.628918608349184

Epoch: 6| Step: 9
Training loss: 3.17927402366734
Validation loss: 2.626381111805574

Epoch: 6| Step: 10
Training loss: 2.8362132377141807
Validation loss: 2.617888945908816

Epoch: 6| Step: 11
Training loss: 3.049265075691363
Validation loss: 2.6313349697747146

Epoch: 6| Step: 12
Training loss: 2.731627560844368
Validation loss: 2.6300152490377218

Epoch: 6| Step: 13
Training loss: 3.1464663409729154
Validation loss: 2.615798566461011

Epoch: 182| Step: 0
Training loss: 2.9843195565550964
Validation loss: 2.6196063874473365

Epoch: 6| Step: 1
Training loss: 3.0056894711667272
Validation loss: 2.617096708752729

Epoch: 6| Step: 2
Training loss: 2.8416589447841343
Validation loss: 2.616558242107585

Epoch: 6| Step: 3
Training loss: 2.818583034806085
Validation loss: 2.607837953545708

Epoch: 6| Step: 4
Training loss: 2.8068754964627165
Validation loss: 2.6145259581403977

Epoch: 6| Step: 5
Training loss: 3.464562990668317
Validation loss: 2.6110620250406633

Epoch: 6| Step: 6
Training loss: 3.0998081270950766
Validation loss: 2.615482091688024

Epoch: 6| Step: 7
Training loss: 3.0848678859818945
Validation loss: 2.6151109568423485

Epoch: 6| Step: 8
Training loss: 2.8678963847683008
Validation loss: 2.607123505126175

Epoch: 6| Step: 9
Training loss: 2.377851781802626
Validation loss: 2.6143844607953124

Epoch: 6| Step: 10
Training loss: 2.962486968836714
Validation loss: 2.621700428103181

Epoch: 6| Step: 11
Training loss: 2.6594239065691543
Validation loss: 2.6383475020498754

Epoch: 6| Step: 12
Training loss: 3.4184426289802485
Validation loss: 2.650441154649823

Epoch: 6| Step: 13
Training loss: 2.7581442830587077
Validation loss: 2.690149507929767

Epoch: 183| Step: 0
Training loss: 2.8791664451087464
Validation loss: 2.6638477568359176

Epoch: 6| Step: 1
Training loss: 3.176970199488421
Validation loss: 2.6527820801091115

Epoch: 6| Step: 2
Training loss: 3.5586047376511214
Validation loss: 2.620584873793148

Epoch: 6| Step: 3
Training loss: 2.170587391262538
Validation loss: 2.608811768954725

Epoch: 6| Step: 4
Training loss: 3.140464361077553
Validation loss: 2.6073979671805243

Epoch: 6| Step: 5
Training loss: 2.957404693847861
Validation loss: 2.6111094886351762

Epoch: 6| Step: 6
Training loss: 2.925223487075957
Validation loss: 2.6110201983951224

Epoch: 6| Step: 7
Training loss: 2.7406563247056215
Validation loss: 2.609773765169255

Epoch: 6| Step: 8
Training loss: 2.7120660636923626
Validation loss: 2.6084196048583084

Epoch: 6| Step: 9
Training loss: 3.2835577705730152
Validation loss: 2.6115147870161803

Epoch: 6| Step: 10
Training loss: 3.1093167246816087
Validation loss: 2.605857171132942

Epoch: 6| Step: 11
Training loss: 2.9725566351061463
Validation loss: 2.609170295673847

Epoch: 6| Step: 12
Training loss: 2.7060577711943363
Validation loss: 2.6015471135531034

Epoch: 6| Step: 13
Training loss: 2.8385164498891853
Validation loss: 2.606703227168379

Epoch: 184| Step: 0
Training loss: 3.1795897222758085
Validation loss: 2.6089615641987427

Epoch: 6| Step: 1
Training loss: 3.094528562664511
Validation loss: 2.6063164154322824

Epoch: 6| Step: 2
Training loss: 3.3712982787571
Validation loss: 2.614422499586297

Epoch: 6| Step: 3
Training loss: 3.0021694604262783
Validation loss: 2.6068615980517262

Epoch: 6| Step: 4
Training loss: 2.863165672228203
Validation loss: 2.606157030684375

Epoch: 6| Step: 5
Training loss: 2.0845325324653126
Validation loss: 2.607093985647168

Epoch: 6| Step: 6
Training loss: 3.044471457826388
Validation loss: 2.6079518917129554

Epoch: 6| Step: 7
Training loss: 2.759069053822721
Validation loss: 2.607211103835035

Epoch: 6| Step: 8
Training loss: 3.0012441280614186
Validation loss: 2.605900995091041

Epoch: 6| Step: 9
Training loss: 2.7547540320174693
Validation loss: 2.606941681654406

Epoch: 6| Step: 10
Training loss: 3.620795080219185
Validation loss: 2.604464396203014

Epoch: 6| Step: 11
Training loss: 2.6361910821834305
Validation loss: 2.628030694531784

Epoch: 6| Step: 12
Training loss: 2.7651116708344814
Validation loss: 2.62450558390834

Epoch: 6| Step: 13
Training loss: 2.707441114523239
Validation loss: 2.6555027276743295

Epoch: 185| Step: 0
Training loss: 3.0831559791763947
Validation loss: 2.6657647750295212

Epoch: 6| Step: 1
Training loss: 3.2735687448051753
Validation loss: 2.6579011971365154

Epoch: 6| Step: 2
Training loss: 2.994115143808729
Validation loss: 2.6159920487133914

Epoch: 6| Step: 3
Training loss: 2.5837633841453527
Validation loss: 2.6051391898884027

Epoch: 6| Step: 4
Training loss: 3.001416825468445
Validation loss: 2.6022885040098194

Epoch: 6| Step: 5
Training loss: 2.6491149216028522
Validation loss: 2.607208289661895

Epoch: 6| Step: 6
Training loss: 2.65077246077902
Validation loss: 2.618934729149706

Epoch: 6| Step: 7
Training loss: 2.72874158116159
Validation loss: 2.6200653930004933

Epoch: 6| Step: 8
Training loss: 3.211213557124541
Validation loss: 2.6138227083838634

Epoch: 6| Step: 9
Training loss: 3.331263105928502
Validation loss: 2.6092691992613664

Epoch: 6| Step: 10
Training loss: 3.17920608062777
Validation loss: 2.6065647750701304

Epoch: 6| Step: 11
Training loss: 2.888469325270702
Validation loss: 2.602525697257588

Epoch: 6| Step: 12
Training loss: 2.859224576068064
Validation loss: 2.6004515565769686

Epoch: 6| Step: 13
Training loss: 3.0814572030555114
Validation loss: 2.59925635764656

Epoch: 186| Step: 0
Training loss: 2.416550129240055
Validation loss: 2.607465615634787

Epoch: 6| Step: 1
Training loss: 3.27735247968891
Validation loss: 2.628624499374458

Epoch: 6| Step: 2
Training loss: 3.5023878671257345
Validation loss: 2.631795455052342

Epoch: 6| Step: 3
Training loss: 3.1900697708870633
Validation loss: 2.6456833450428436

Epoch: 6| Step: 4
Training loss: 2.3085638002366715
Validation loss: 2.6222934452199977

Epoch: 6| Step: 5
Training loss: 3.217129790282701
Validation loss: 2.609326007538564

Epoch: 6| Step: 6
Training loss: 3.139846629387987
Validation loss: 2.602850172119122

Epoch: 6| Step: 7
Training loss: 3.065839853641855
Validation loss: 2.602017264697876

Epoch: 6| Step: 8
Training loss: 3.016970319551987
Validation loss: 2.597137677224101

Epoch: 6| Step: 9
Training loss: 2.2951754555712487
Validation loss: 2.6008325476743033

Epoch: 6| Step: 10
Training loss: 2.992217937742952
Validation loss: 2.6028946396263075

Epoch: 6| Step: 11
Training loss: 3.0352370007155445
Validation loss: 2.601649826758491

Epoch: 6| Step: 12
Training loss: 2.8852614672037715
Validation loss: 2.6005427850186194

Epoch: 6| Step: 13
Training loss: 2.4826374815704932
Validation loss: 2.600042324021426

Epoch: 187| Step: 0
Training loss: 2.7880266761160337
Validation loss: 2.6027028934386527

Epoch: 6| Step: 1
Training loss: 3.0594906715915418
Validation loss: 2.5987853686596076

Epoch: 6| Step: 2
Training loss: 2.9460851328786237
Validation loss: 2.6029318466490707

Epoch: 6| Step: 3
Training loss: 2.8431365640522066
Validation loss: 2.6000153479190162

Epoch: 6| Step: 4
Training loss: 2.48896241259212
Validation loss: 2.5965543517077214

Epoch: 6| Step: 5
Training loss: 3.3213302668074034
Validation loss: 2.5968382353042507

Epoch: 6| Step: 6
Training loss: 3.060253954553024
Validation loss: 2.5962000796089266

Epoch: 6| Step: 7
Training loss: 3.045160368656699
Validation loss: 2.5978083444264524

Epoch: 6| Step: 8
Training loss: 2.6501619469443254
Validation loss: 2.6049030711519867

Epoch: 6| Step: 9
Training loss: 2.2464513344773462
Validation loss: 2.5986514559600176

Epoch: 6| Step: 10
Training loss: 3.8194074748398217
Validation loss: 2.604291558665128

Epoch: 6| Step: 11
Training loss: 3.2740386192453594
Validation loss: 2.609908624801146

Epoch: 6| Step: 12
Training loss: 2.5324400000134677
Validation loss: 2.6059282614730943

Epoch: 6| Step: 13
Training loss: 2.8285473250040556
Validation loss: 2.6042589879232496

Epoch: 188| Step: 0
Training loss: 3.1263009987156245
Validation loss: 2.613365428639368

Epoch: 6| Step: 1
Training loss: 2.736630016721148
Validation loss: 2.6082827801172472

Epoch: 6| Step: 2
Training loss: 3.2593040802391204
Validation loss: 2.61778748390333

Epoch: 6| Step: 3
Training loss: 2.9297613922973142
Validation loss: 2.611842748591074

Epoch: 6| Step: 4
Training loss: 3.3021022342818847
Validation loss: 2.628024463038434

Epoch: 6| Step: 5
Training loss: 3.1920501544998903
Validation loss: 2.6100480349683606

Epoch: 6| Step: 6
Training loss: 2.9717364899681304
Validation loss: 2.618511658279391

Epoch: 6| Step: 7
Training loss: 3.283865767036699
Validation loss: 2.612718018171619

Epoch: 6| Step: 8
Training loss: 1.924515128068541
Validation loss: 2.6069914643193917

Epoch: 6| Step: 9
Training loss: 2.514770836675269
Validation loss: 2.602383882370116

Epoch: 6| Step: 10
Training loss: 2.9504333824313065
Validation loss: 2.5970086765274116

Epoch: 6| Step: 11
Training loss: 2.8183826384770567
Validation loss: 2.601286471210752

Epoch: 6| Step: 12
Training loss: 3.0943735438347097
Validation loss: 2.592086139711742

Epoch: 6| Step: 13
Training loss: 2.6767701041194436
Validation loss: 2.5923388551891633

Epoch: 189| Step: 0
Training loss: 2.771504849014844
Validation loss: 2.590425067413947

Epoch: 6| Step: 1
Training loss: 3.435262055597069
Validation loss: 2.5923089794536964

Epoch: 6| Step: 2
Training loss: 2.7849375249679937
Validation loss: 2.59383981358701

Epoch: 6| Step: 3
Training loss: 2.7958818089413384
Validation loss: 2.593400912187934

Epoch: 6| Step: 4
Training loss: 3.0939076701358887
Validation loss: 2.593396817715751

Epoch: 6| Step: 5
Training loss: 3.1281179513766117
Validation loss: 2.595263249618585

Epoch: 6| Step: 6
Training loss: 2.869459369526646
Validation loss: 2.5985337734118725

Epoch: 6| Step: 7
Training loss: 3.592236009214656
Validation loss: 2.595484343877841

Epoch: 6| Step: 8
Training loss: 3.075137319832667
Validation loss: 2.599239760175431

Epoch: 6| Step: 9
Training loss: 2.5305008898275396
Validation loss: 2.6018672923348176

Epoch: 6| Step: 10
Training loss: 2.897295210071241
Validation loss: 2.6033761171164556

Epoch: 6| Step: 11
Training loss: 2.4532995465619627
Validation loss: 2.6047388510556555

Epoch: 6| Step: 12
Training loss: 2.635234680727651
Validation loss: 2.6098028319431568

Epoch: 6| Step: 13
Training loss: 2.7772676052380576
Validation loss: 2.623377583295703

Epoch: 190| Step: 0
Training loss: 3.3364720508119965
Validation loss: 2.64819870348756

Epoch: 6| Step: 1
Training loss: 2.554994523850636
Validation loss: 2.661206216965376

Epoch: 6| Step: 2
Training loss: 3.2603600510301796
Validation loss: 2.7109924984141305

Epoch: 6| Step: 3
Training loss: 2.897665491652491
Validation loss: 2.6894317594409896

Epoch: 6| Step: 4
Training loss: 3.1317462581192848
Validation loss: 2.6320754276458658

Epoch: 6| Step: 5
Training loss: 2.584663007894817
Validation loss: 2.6181218146772287

Epoch: 6| Step: 6
Training loss: 3.4263702547387656
Validation loss: 2.6064768300628094

Epoch: 6| Step: 7
Training loss: 2.9463848721785215
Validation loss: 2.5940852407558093

Epoch: 6| Step: 8
Training loss: 2.6302611896504215
Validation loss: 2.5901195076348564

Epoch: 6| Step: 9
Training loss: 2.6273532491802056
Validation loss: 2.58672930809339

Epoch: 6| Step: 10
Training loss: 2.470752917605967
Validation loss: 2.5908063109064354

Epoch: 6| Step: 11
Training loss: 2.7603777228913198
Validation loss: 2.591225882571827

Epoch: 6| Step: 12
Training loss: 3.373023408014054
Validation loss: 2.588325540159395

Epoch: 6| Step: 13
Training loss: 3.113442678825331
Validation loss: 2.5894557048628757

Epoch: 191| Step: 0
Training loss: 3.051971398775767
Validation loss: 2.5864769395543727

Epoch: 6| Step: 1
Training loss: 3.4263658013966443
Validation loss: 2.589239133521628

Epoch: 6| Step: 2
Training loss: 3.0069693039905814
Validation loss: 2.590116805542322

Epoch: 6| Step: 3
Training loss: 2.824958925876949
Validation loss: 2.590259432584512

Epoch: 6| Step: 4
Training loss: 2.7551427784111575
Validation loss: 2.5896747329610976

Epoch: 6| Step: 5
Training loss: 3.2281695559474257
Validation loss: 2.5848777271613756

Epoch: 6| Step: 6
Training loss: 2.648705212951178
Validation loss: 2.5874900468529147

Epoch: 6| Step: 7
Training loss: 3.3757961888193524
Validation loss: 2.58790837206553

Epoch: 6| Step: 8
Training loss: 2.4009493619066484
Validation loss: 2.5882117057264677

Epoch: 6| Step: 9
Training loss: 3.4782384368960915
Validation loss: 2.596469665565752

Epoch: 6| Step: 10
Training loss: 2.639879200367964
Validation loss: 2.5951054788725765

Epoch: 6| Step: 11
Training loss: 2.4029490630949923
Validation loss: 2.6038026692304603

Epoch: 6| Step: 12
Training loss: 2.622467454211945
Validation loss: 2.609185935860076

Epoch: 6| Step: 13
Training loss: 2.9994716178974365
Validation loss: 2.6188686211531054

Epoch: 192| Step: 0
Training loss: 3.107590820016509
Validation loss: 2.6402862257731674

Epoch: 6| Step: 1
Training loss: 3.057711848033668
Validation loss: 2.640398796748475

Epoch: 6| Step: 2
Training loss: 2.9781774910526893
Validation loss: 2.684673426431601

Epoch: 6| Step: 3
Training loss: 2.925508738560617
Validation loss: 2.7159332801637426

Epoch: 6| Step: 4
Training loss: 2.5053305064103015
Validation loss: 2.687275639884728

Epoch: 6| Step: 5
Training loss: 2.8530045716857115
Validation loss: 2.670384242850351

Epoch: 6| Step: 6
Training loss: 2.97160186314665
Validation loss: 2.641016447223771

Epoch: 6| Step: 7
Training loss: 2.6134116193016044
Validation loss: 2.6479052120873745

Epoch: 6| Step: 8
Training loss: 3.1953799513433867
Validation loss: 2.606162605227955

Epoch: 6| Step: 9
Training loss: 3.026321494492101
Validation loss: 2.5972936949182266

Epoch: 6| Step: 10
Training loss: 2.6024522147798224
Validation loss: 2.5982634553981767

Epoch: 6| Step: 11
Training loss: 2.734875442486017
Validation loss: 2.5883959819186666

Epoch: 6| Step: 12
Training loss: 2.8380450359639586
Validation loss: 2.587332986168897

Epoch: 6| Step: 13
Training loss: 3.9417748633301155
Validation loss: 2.5884311213599855

Epoch: 193| Step: 0
Training loss: 2.9201723737657823
Validation loss: 2.5889217064468784

Epoch: 6| Step: 1
Training loss: 3.1066621994292047
Validation loss: 2.591655483986035

Epoch: 6| Step: 2
Training loss: 3.1259895283919636
Validation loss: 2.591471614671958

Epoch: 6| Step: 3
Training loss: 2.129796281304768
Validation loss: 2.590265433271151

Epoch: 6| Step: 4
Training loss: 2.6362567412071805
Validation loss: 2.5921854449230404

Epoch: 6| Step: 5
Training loss: 3.029900948696365
Validation loss: 2.5889042782539193

Epoch: 6| Step: 6
Training loss: 2.9837872790279905
Validation loss: 2.5895787726542885

Epoch: 6| Step: 7
Training loss: 3.4735765299769823
Validation loss: 2.583336159952333

Epoch: 6| Step: 8
Training loss: 2.583193518844134
Validation loss: 2.587811778611275

Epoch: 6| Step: 9
Training loss: 2.4912672107521208
Validation loss: 2.5852319860190547

Epoch: 6| Step: 10
Training loss: 3.4540056167318314
Validation loss: 2.591331940178579

Epoch: 6| Step: 11
Training loss: 3.0870671389699016
Validation loss: 2.5949720964716327

Epoch: 6| Step: 12
Training loss: 2.9160947693127675
Validation loss: 2.587437851888532

Epoch: 6| Step: 13
Training loss: 2.996054916428579
Validation loss: 2.5966828270371294

Epoch: 194| Step: 0
Training loss: 3.1063472249033977
Validation loss: 2.6056655012750665

Epoch: 6| Step: 1
Training loss: 3.051742343710796
Validation loss: 2.597654103480157

Epoch: 6| Step: 2
Training loss: 3.0366863777980915
Validation loss: 2.614583399354739

Epoch: 6| Step: 3
Training loss: 3.0471967478355464
Validation loss: 2.6134202654295304

Epoch: 6| Step: 4
Training loss: 3.779700726363343
Validation loss: 2.6132766628189867

Epoch: 6| Step: 5
Training loss: 3.094230537471078
Validation loss: 2.5893880284501685

Epoch: 6| Step: 6
Training loss: 2.7824993113665144
Validation loss: 2.587546350445334

Epoch: 6| Step: 7
Training loss: 3.308520535826599
Validation loss: 2.583825084102266

Epoch: 6| Step: 8
Training loss: 2.248378063102897
Validation loss: 2.585177408101176

Epoch: 6| Step: 9
Training loss: 2.6258245717100914
Validation loss: 2.5871832387136826

Epoch: 6| Step: 10
Training loss: 2.951723280768865
Validation loss: 2.5840608321352057

Epoch: 6| Step: 11
Training loss: 2.309208976755382
Validation loss: 2.5823877379012123

Epoch: 6| Step: 12
Training loss: 2.5636082555458493
Validation loss: 2.5852633070375965

Epoch: 6| Step: 13
Training loss: 2.846828429325882
Validation loss: 2.5841014056335774

Epoch: 195| Step: 0
Training loss: 2.5727727646425222
Validation loss: 2.582393660583646

Epoch: 6| Step: 1
Training loss: 3.1851841610735185
Validation loss: 2.5873914303799173

Epoch: 6| Step: 2
Training loss: 2.4363326187177976
Validation loss: 2.587217985390112

Epoch: 6| Step: 3
Training loss: 2.790064271166087
Validation loss: 2.5820185292226157

Epoch: 6| Step: 4
Training loss: 2.9251861578235263
Validation loss: 2.581931867010635

Epoch: 6| Step: 5
Training loss: 2.6966509605519313
Validation loss: 2.5876043975046406

Epoch: 6| Step: 6
Training loss: 3.194079023459731
Validation loss: 2.5861544192019092

Epoch: 6| Step: 7
Training loss: 3.6960430431254103
Validation loss: 2.5898806664095133

Epoch: 6| Step: 8
Training loss: 2.5920724614458104
Validation loss: 2.593587720795448

Epoch: 6| Step: 9
Training loss: 3.06300941434454
Validation loss: 2.6018151631080157

Epoch: 6| Step: 10
Training loss: 2.7038807777102156
Validation loss: 2.6089762298915873

Epoch: 6| Step: 11
Training loss: 2.7380337895829463
Validation loss: 2.5919746028698327

Epoch: 6| Step: 12
Training loss: 3.1741033534509664
Validation loss: 2.597018359477007

Epoch: 6| Step: 13
Training loss: 3.1039302829798094
Validation loss: 2.6114596471212135

Epoch: 196| Step: 0
Training loss: 3.06588604639029
Validation loss: 2.6077864961577313

Epoch: 6| Step: 1
Training loss: 3.112991759890083
Validation loss: 2.631031997033041

Epoch: 6| Step: 2
Training loss: 2.479323523765716
Validation loss: 2.613662435147934

Epoch: 6| Step: 3
Training loss: 3.6687185152902635
Validation loss: 2.619644317139712

Epoch: 6| Step: 4
Training loss: 3.2975681534463446
Validation loss: 2.6197224412980877

Epoch: 6| Step: 5
Training loss: 2.217704849156811
Validation loss: 2.624842635602738

Epoch: 6| Step: 6
Training loss: 3.1822670260826587
Validation loss: 2.6054156685227476

Epoch: 6| Step: 7
Training loss: 2.47907579613422
Validation loss: 2.5949967717842513

Epoch: 6| Step: 8
Training loss: 2.2123089637826157
Validation loss: 2.5851303490058832

Epoch: 6| Step: 9
Training loss: 2.9645917179706642
Validation loss: 2.5854020877544857

Epoch: 6| Step: 10
Training loss: 2.318847913294232
Validation loss: 2.580438093689241

Epoch: 6| Step: 11
Training loss: 3.071059895563926
Validation loss: 2.5841022568398415

Epoch: 6| Step: 12
Training loss: 3.1114997696690243
Validation loss: 2.5767731633495643

Epoch: 6| Step: 13
Training loss: 3.708201859675993
Validation loss: 2.578438423025897

Epoch: 197| Step: 0
Training loss: 2.9610167319131993
Validation loss: 2.5788755674804364

Epoch: 6| Step: 1
Training loss: 3.4041069358587603
Validation loss: 2.5814851543259296

Epoch: 6| Step: 2
Training loss: 2.9654940770215017
Validation loss: 2.580352053000259

Epoch: 6| Step: 3
Training loss: 3.5445223496451237
Validation loss: 2.582461018972291

Epoch: 6| Step: 4
Training loss: 2.595907853364676
Validation loss: 2.5815409702053937

Epoch: 6| Step: 5
Training loss: 2.408465170854154
Validation loss: 2.575718591605187

Epoch: 6| Step: 6
Training loss: 2.8350959979561456
Validation loss: 2.5852086851563842

Epoch: 6| Step: 7
Training loss: 2.323982906396872
Validation loss: 2.580181830963007

Epoch: 6| Step: 8
Training loss: 3.2726024208914546
Validation loss: 2.5805582833663587

Epoch: 6| Step: 9
Training loss: 2.7941876506008003
Validation loss: 2.585696744627444

Epoch: 6| Step: 10
Training loss: 3.3808785564158352
Validation loss: 2.618709349365091

Epoch: 6| Step: 11
Training loss: 2.495866314431801
Validation loss: 2.5898822155528562

Epoch: 6| Step: 12
Training loss: 2.878501087182552
Validation loss: 2.60254494917403

Epoch: 6| Step: 13
Training loss: 2.7830274238674493
Validation loss: 2.6001981565849204

Epoch: 198| Step: 0
Training loss: 2.786520689269558
Validation loss: 2.588625509253198

Epoch: 6| Step: 1
Training loss: 3.0277170258784003
Validation loss: 2.6064653774011943

Epoch: 6| Step: 2
Training loss: 3.1132876828078144
Validation loss: 2.5952880505777562

Epoch: 6| Step: 3
Training loss: 2.953518472929208
Validation loss: 2.5916792758834992

Epoch: 6| Step: 4
Training loss: 2.958681560670836
Validation loss: 2.5996052163439685

Epoch: 6| Step: 5
Training loss: 2.594363588121018
Validation loss: 2.590063094682172

Epoch: 6| Step: 6
Training loss: 2.486314508321413
Validation loss: 2.5931576831974583

Epoch: 6| Step: 7
Training loss: 2.4118067007089254
Validation loss: 2.588900200435925

Epoch: 6| Step: 8
Training loss: 2.585769786178862
Validation loss: 2.5919749708033177

Epoch: 6| Step: 9
Training loss: 3.2768436454976877
Validation loss: 2.5922579584964556

Epoch: 6| Step: 10
Training loss: 3.1650503617990995
Validation loss: 2.594777146633132

Epoch: 6| Step: 11
Training loss: 3.1250259398337463
Validation loss: 2.5805592112430658

Epoch: 6| Step: 12
Training loss: 3.084541410616196
Validation loss: 2.5829482775689248

Epoch: 6| Step: 13
Training loss: 3.3451151690307452
Validation loss: 2.5812770653085146

Epoch: 199| Step: 0
Training loss: 3.1378062490114726
Validation loss: 2.5825331385087282

Epoch: 6| Step: 1
Training loss: 2.9641543505347263
Validation loss: 2.5767770464549935

Epoch: 6| Step: 2
Training loss: 2.868699343032541
Validation loss: 2.576618354699546

Epoch: 6| Step: 3
Training loss: 2.7607190428371893
Validation loss: 2.5772217054050097

Epoch: 6| Step: 4
Training loss: 2.8423193382484406
Validation loss: 2.573769763295582

Epoch: 6| Step: 5
Training loss: 3.062558231967898
Validation loss: 2.57709882642035

Epoch: 6| Step: 6
Training loss: 2.831927193670244
Validation loss: 2.582364611910048

Epoch: 6| Step: 7
Training loss: 3.577709856895804
Validation loss: 2.5788350608787667

Epoch: 6| Step: 8
Training loss: 2.865906972542646
Validation loss: 2.5836236739636527

Epoch: 6| Step: 9
Training loss: 3.0200207549133538
Validation loss: 2.587537782327929

Epoch: 6| Step: 10
Training loss: 3.1240069528128687
Validation loss: 2.596350532373103

Epoch: 6| Step: 11
Training loss: 2.5715105690825144
Validation loss: 2.6062031848309206

Epoch: 6| Step: 12
Training loss: 2.6061279744002244
Validation loss: 2.610792115530347

Epoch: 6| Step: 13
Training loss: 2.111895037824407
Validation loss: 2.6238839120215602

Epoch: 200| Step: 0
Training loss: 2.605580569131165
Validation loss: 2.632395972851281

Epoch: 6| Step: 1
Training loss: 2.722798982707305
Validation loss: 2.6414808748011005

Epoch: 6| Step: 2
Training loss: 2.7799180516850623
Validation loss: 2.6451855396881996

Epoch: 6| Step: 3
Training loss: 2.5189952191424463
Validation loss: 2.6384721448140587

Epoch: 6| Step: 4
Training loss: 2.6090422092589503
Validation loss: 2.658252582242309

Epoch: 6| Step: 5
Training loss: 3.234790719999868
Validation loss: 2.6585793919006364

Epoch: 6| Step: 6
Training loss: 2.6889594794781475
Validation loss: 2.6454354212176545

Epoch: 6| Step: 7
Training loss: 2.958555043110612
Validation loss: 2.638250948880588

Epoch: 6| Step: 8
Training loss: 3.0562115937922676
Validation loss: 2.595770242705502

Epoch: 6| Step: 9
Training loss: 3.2366180750469624
Validation loss: 2.586013147947666

Epoch: 6| Step: 10
Training loss: 3.30046544116067
Validation loss: 2.580942784183805

Epoch: 6| Step: 11
Training loss: 3.560264019551923
Validation loss: 2.578246632898395

Epoch: 6| Step: 12
Training loss: 3.0221950925594188
Validation loss: 2.580422524653233

Epoch: 6| Step: 13
Training loss: 2.401014304401664
Validation loss: 2.576423755418634

Testing loss: 2.829438644317681
