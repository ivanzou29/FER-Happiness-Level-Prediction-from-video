Epoch: 1| Step: 0
Training loss: 5.676505728452694
Validation loss: 5.852714546196201

Epoch: 6| Step: 1
Training loss: 6.00559958787731
Validation loss: 5.842935109282448

Epoch: 6| Step: 2
Training loss: 6.383984386950835
Validation loss: 5.833320225057801

Epoch: 6| Step: 3
Training loss: 6.637690643044003
Validation loss: 5.82314535352288

Epoch: 6| Step: 4
Training loss: 4.927590965697105
Validation loss: 5.813139464925876

Epoch: 6| Step: 5
Training loss: 5.012716906033025
Validation loss: 5.8030165043401825

Epoch: 6| Step: 6
Training loss: 6.441615890691025
Validation loss: 5.791804885306811

Epoch: 6| Step: 7
Training loss: 5.085289792305697
Validation loss: 5.780343398092394

Epoch: 6| Step: 8
Training loss: 6.364947003236076
Validation loss: 5.767405851665971

Epoch: 6| Step: 9
Training loss: 6.1103992432862775
Validation loss: 5.753900215496574

Epoch: 6| Step: 10
Training loss: 5.96066167550745
Validation loss: 5.739568184998116

Epoch: 6| Step: 11
Training loss: 5.700091833077567
Validation loss: 5.722829968976327

Epoch: 6| Step: 12
Training loss: 5.687598594397823
Validation loss: 5.704752609259717

Epoch: 6| Step: 13
Training loss: 4.341886930436952
Validation loss: 5.686598477227347

Epoch: 2| Step: 0
Training loss: 6.396452767097478
Validation loss: 5.665875842354596

Epoch: 6| Step: 1
Training loss: 4.5114540980279605
Validation loss: 5.644588035096035

Epoch: 6| Step: 2
Training loss: 6.692426631555254
Validation loss: 5.620512078266404

Epoch: 6| Step: 3
Training loss: 5.837154481125494
Validation loss: 5.594953453246218

Epoch: 6| Step: 4
Training loss: 4.039148680248998
Validation loss: 5.569202317008803

Epoch: 6| Step: 5
Training loss: 4.782998158123755
Validation loss: 5.541902203874012

Epoch: 6| Step: 6
Training loss: 4.85249061736861
Validation loss: 5.512430295767904

Epoch: 6| Step: 7
Training loss: 5.014576074362259
Validation loss: 5.483260835827295

Epoch: 6| Step: 8
Training loss: 4.694828052886175
Validation loss: 5.451566988441044

Epoch: 6| Step: 9
Training loss: 6.1223179141437685
Validation loss: 5.419004087748621

Epoch: 6| Step: 10
Training loss: 6.04799434740317
Validation loss: 5.3862119983017935

Epoch: 6| Step: 11
Training loss: 4.921488622607105
Validation loss: 5.351076361954078

Epoch: 6| Step: 12
Training loss: 6.523729000317233
Validation loss: 5.314865382914789

Epoch: 6| Step: 13
Training loss: 6.413438885164513
Validation loss: 5.277581434082444

Epoch: 3| Step: 0
Training loss: 6.236934585783608
Validation loss: 5.239808604961026

Epoch: 6| Step: 1
Training loss: 5.432213328873473
Validation loss: 5.199384681243926

Epoch: 6| Step: 2
Training loss: 4.911303207951985
Validation loss: 5.159162847240851

Epoch: 6| Step: 3
Training loss: 4.382402098237309
Validation loss: 5.121357962039355

Epoch: 6| Step: 4
Training loss: 5.360042252445222
Validation loss: 5.080877471693734

Epoch: 6| Step: 5
Training loss: 3.9501473894265464
Validation loss: 5.040385594127906

Epoch: 6| Step: 6
Training loss: 4.572106685752033
Validation loss: 5.001987339196871

Epoch: 6| Step: 7
Training loss: 4.992583687452891
Validation loss: 4.960345600924579

Epoch: 6| Step: 8
Training loss: 5.335487089793355
Validation loss: 4.918985664976613

Epoch: 6| Step: 9
Training loss: 5.398332917764115
Validation loss: 4.878745109524105

Epoch: 6| Step: 10
Training loss: 4.973887924042179
Validation loss: 4.837652145341484

Epoch: 6| Step: 11
Training loss: 5.088257244468745
Validation loss: 4.796949196764379

Epoch: 6| Step: 12
Training loss: 4.894230205414215
Validation loss: 4.758669100560656

Epoch: 6| Step: 13
Training loss: 4.718453505340035
Validation loss: 4.7217185658881435

Epoch: 4| Step: 0
Training loss: 5.4066444208994335
Validation loss: 4.689393864273131

Epoch: 6| Step: 1
Training loss: 4.618218476266714
Validation loss: 4.657324197469466

Epoch: 6| Step: 2
Training loss: 3.383754255547893
Validation loss: 4.6233549953523125

Epoch: 6| Step: 3
Training loss: 5.1451095916375715
Validation loss: 4.595859601539048

Epoch: 6| Step: 4
Training loss: 4.434640742290585
Validation loss: 4.565278660630533

Epoch: 6| Step: 5
Training loss: 4.73143009462852
Validation loss: 4.536228491941712

Epoch: 6| Step: 6
Training loss: 4.083380925945675
Validation loss: 4.50917313716265

Epoch: 6| Step: 7
Training loss: 4.459987345450885
Validation loss: 4.486493469823117

Epoch: 6| Step: 8
Training loss: 4.487132218359957
Validation loss: 4.461145607523641

Epoch: 6| Step: 9
Training loss: 4.84248581663151
Validation loss: 4.440657427541945

Epoch: 6| Step: 10
Training loss: 5.470532284908353
Validation loss: 4.421818419382596

Epoch: 6| Step: 11
Training loss: 3.3718784166094253
Validation loss: 4.401097153281517

Epoch: 6| Step: 12
Training loss: 5.043380425017549
Validation loss: 4.382944947317743

Epoch: 6| Step: 13
Training loss: 4.4351237207334915
Validation loss: 4.367260788064799

Epoch: 5| Step: 0
Training loss: 3.964301672649298
Validation loss: 4.3526228774117115

Epoch: 6| Step: 1
Training loss: 5.550714931320045
Validation loss: 4.3407642097279995

Epoch: 6| Step: 2
Training loss: 4.203242530739429
Validation loss: 4.32615824780843

Epoch: 6| Step: 3
Training loss: 3.4647375045364974
Validation loss: 4.315364909106992

Epoch: 6| Step: 4
Training loss: 3.847615353129734
Validation loss: 4.304210993721753

Epoch: 6| Step: 5
Training loss: 4.802509391016915
Validation loss: 4.295727440713998

Epoch: 6| Step: 6
Training loss: 5.260720705619079
Validation loss: 4.286216922320966

Epoch: 6| Step: 7
Training loss: 4.346506684836471
Validation loss: 4.275244205515883

Epoch: 6| Step: 8
Training loss: 4.03732598936588
Validation loss: 4.263714166090581

Epoch: 6| Step: 9
Training loss: 4.366548058061353
Validation loss: 4.255614308088636

Epoch: 6| Step: 10
Training loss: 4.263364535275459
Validation loss: 4.2489894181790016

Epoch: 6| Step: 11
Training loss: 4.188587559914477
Validation loss: 4.23702474301699

Epoch: 6| Step: 12
Training loss: 4.2973379544635595
Validation loss: 4.227142420969183

Epoch: 6| Step: 13
Training loss: 4.878139169832479
Validation loss: 4.222536682953809

Epoch: 6| Step: 0
Training loss: 4.542398562938951
Validation loss: 4.212930904158622

Epoch: 6| Step: 1
Training loss: 2.9437100936225717
Validation loss: 4.204623162307693

Epoch: 6| Step: 2
Training loss: 5.707351748679443
Validation loss: 4.194249030397361

Epoch: 6| Step: 3
Training loss: 3.725702790393865
Validation loss: 4.182534305411299

Epoch: 6| Step: 4
Training loss: 3.7058194815843812
Validation loss: 4.173790573995445

Epoch: 6| Step: 5
Training loss: 4.167657556330167
Validation loss: 4.1642536083382815

Epoch: 6| Step: 6
Training loss: 4.393290189339209
Validation loss: 4.156464661155807

Epoch: 6| Step: 7
Training loss: 4.899192447679954
Validation loss: 4.150306977038948

Epoch: 6| Step: 8
Training loss: 4.607874532329247
Validation loss: 4.139654141151975

Epoch: 6| Step: 9
Training loss: 4.375426135426943
Validation loss: 4.13146925146097

Epoch: 6| Step: 10
Training loss: 4.4217710449076835
Validation loss: 4.1260226198060055

Epoch: 6| Step: 11
Training loss: 4.22299523276571
Validation loss: 4.117112506436341

Epoch: 6| Step: 12
Training loss: 3.9021180539165727
Validation loss: 4.105893052388286

Epoch: 6| Step: 13
Training loss: 3.4927239400710457
Validation loss: 4.096236729185436

Epoch: 7| Step: 0
Training loss: 5.095897947178841
Validation loss: 4.084761709814971

Epoch: 6| Step: 1
Training loss: 3.9508130697425234
Validation loss: 4.0792415694768325

Epoch: 6| Step: 2
Training loss: 4.110168148415823
Validation loss: 4.070012476579632

Epoch: 6| Step: 3
Training loss: 3.2359491470547277
Validation loss: 4.062644870090236

Epoch: 6| Step: 4
Training loss: 3.8972349586438817
Validation loss: 4.058101823330962

Epoch: 6| Step: 5
Training loss: 4.70333385320634
Validation loss: 4.049816083257907

Epoch: 6| Step: 6
Training loss: 5.114370721048139
Validation loss: 4.043219052655729

Epoch: 6| Step: 7
Training loss: 3.7239935315298247
Validation loss: 4.034128817002731

Epoch: 6| Step: 8
Training loss: 4.6276907439568715
Validation loss: 4.025937068663864

Epoch: 6| Step: 9
Training loss: 4.28252263888796
Validation loss: 4.018361214020747

Epoch: 6| Step: 10
Training loss: 2.9411400501015796
Validation loss: 4.010806713572295

Epoch: 6| Step: 11
Training loss: 4.462917977213775
Validation loss: 4.002286066756863

Epoch: 6| Step: 12
Training loss: 3.523809375296532
Validation loss: 3.994966393104207

Epoch: 6| Step: 13
Training loss: 4.430132915836447
Validation loss: 3.99020370294848

Epoch: 8| Step: 0
Training loss: 3.292894319573273
Validation loss: 3.9825337166590993

Epoch: 6| Step: 1
Training loss: 5.239241885314794
Validation loss: 3.975471724607373

Epoch: 6| Step: 2
Training loss: 5.035672157675661
Validation loss: 3.965473692431424

Epoch: 6| Step: 3
Training loss: 3.481075075641285
Validation loss: 3.954968693519611

Epoch: 6| Step: 4
Training loss: 4.565302575937687
Validation loss: 3.946696074428043

Epoch: 6| Step: 5
Training loss: 3.7862384772542557
Validation loss: 3.940875961609575

Epoch: 6| Step: 6
Training loss: 2.949398858842262
Validation loss: 3.9340012177979187

Epoch: 6| Step: 7
Training loss: 4.425261477918476
Validation loss: 3.928099448281591

Epoch: 6| Step: 8
Training loss: 4.564648057254434
Validation loss: 3.92245218072554

Epoch: 6| Step: 9
Training loss: 3.1732176396039176
Validation loss: 3.91469532130799

Epoch: 6| Step: 10
Training loss: 2.696990356099924
Validation loss: 3.911528834276484

Epoch: 6| Step: 11
Training loss: 4.6026365519526
Validation loss: 3.9079216485740544

Epoch: 6| Step: 12
Training loss: 4.158884231882299
Validation loss: 3.901718845597703

Epoch: 6| Step: 13
Training loss: 4.522554459631419
Validation loss: 3.895248584163622

Epoch: 9| Step: 0
Training loss: 4.206528884235344
Validation loss: 3.890381228644772

Epoch: 6| Step: 1
Training loss: 4.0656139470389245
Validation loss: 3.8837247390802423

Epoch: 6| Step: 2
Training loss: 4.020469266916575
Validation loss: 3.8782932459807493

Epoch: 6| Step: 3
Training loss: 5.095281265476559
Validation loss: 3.8760064227616517

Epoch: 6| Step: 4
Training loss: 3.2112199422425203
Validation loss: 3.8693099042158354

Epoch: 6| Step: 5
Training loss: 3.861053225466815
Validation loss: 3.8654802176812293

Epoch: 6| Step: 6
Training loss: 3.5999259623225726
Validation loss: 3.8607538570029267

Epoch: 6| Step: 7
Training loss: 3.900132661177088
Validation loss: 3.8559451420162847

Epoch: 6| Step: 8
Training loss: 3.861285150083312
Validation loss: 3.848005709288654

Epoch: 6| Step: 9
Training loss: 3.607514930107326
Validation loss: 3.848082301840318

Epoch: 6| Step: 10
Training loss: 4.179744998144231
Validation loss: 3.8409530530648364

Epoch: 6| Step: 11
Training loss: 3.818232244926478
Validation loss: 3.835078631729213

Epoch: 6| Step: 12
Training loss: 3.7342467984335648
Validation loss: 3.8331471130879646

Epoch: 6| Step: 13
Training loss: 5.349660359947805
Validation loss: 3.8266303929527723

Epoch: 10| Step: 0
Training loss: 3.5785720745789855
Validation loss: 3.8205739328253903

Epoch: 6| Step: 1
Training loss: 3.984507839008001
Validation loss: 3.8165384613276707

Epoch: 6| Step: 2
Training loss: 4.262729654250268
Validation loss: 3.809962315178018

Epoch: 6| Step: 3
Training loss: 4.508445867143454
Validation loss: 3.8052804830170186

Epoch: 6| Step: 4
Training loss: 4.222983263817698
Validation loss: 3.8019484395590553

Epoch: 6| Step: 5
Training loss: 3.395652313712362
Validation loss: 3.795773090580459

Epoch: 6| Step: 6
Training loss: 5.195987055303529
Validation loss: 3.788708627065628

Epoch: 6| Step: 7
Training loss: 3.575256397149565
Validation loss: 3.7811775034462816

Epoch: 6| Step: 8
Training loss: 3.260517122876268
Validation loss: 3.787894685900188

Epoch: 6| Step: 9
Training loss: 2.6287929742903806
Validation loss: 3.7812105897310557

Epoch: 6| Step: 10
Training loss: 3.6228523469508964
Validation loss: 3.7690284165371666

Epoch: 6| Step: 11
Training loss: 4.423008857637109
Validation loss: 3.7632697709625957

Epoch: 6| Step: 12
Training loss: 4.131385484744745
Validation loss: 3.756147325644115

Epoch: 6| Step: 13
Training loss: 4.101327420718624
Validation loss: 3.7487330932058684

Epoch: 11| Step: 0
Training loss: 4.728353063474755
Validation loss: 3.7440159144331076

Epoch: 6| Step: 1
Training loss: 4.324054222112794
Validation loss: 3.7391373791783558

Epoch: 6| Step: 2
Training loss: 3.0399821245772194
Validation loss: 3.73378949220525

Epoch: 6| Step: 3
Training loss: 4.792581531704715
Validation loss: 3.7288825034014677

Epoch: 6| Step: 4
Training loss: 3.569269541319869
Validation loss: 3.730164990575337

Epoch: 6| Step: 5
Training loss: 4.92897978960732
Validation loss: 3.7276878763631482

Epoch: 6| Step: 6
Training loss: 3.3007971407716603
Validation loss: 3.7124026210102703

Epoch: 6| Step: 7
Training loss: 3.775049343165591
Validation loss: 3.7085919213408043

Epoch: 6| Step: 8
Training loss: 4.003546096606888
Validation loss: 3.7150809488545007

Epoch: 6| Step: 9
Training loss: 3.787039745806204
Validation loss: 3.6967634973584405

Epoch: 6| Step: 10
Training loss: 3.416217324707453
Validation loss: 3.6949131850980748

Epoch: 6| Step: 11
Training loss: 2.907514563644553
Validation loss: 3.7033846388444958

Epoch: 6| Step: 12
Training loss: 3.8971211689863736
Validation loss: 3.702051201828082

Epoch: 6| Step: 13
Training loss: 3.119372679904999
Validation loss: 3.6920125584587025

Epoch: 12| Step: 0
Training loss: 3.2452965961446796
Validation loss: 3.6866497869312282

Epoch: 6| Step: 1
Training loss: 4.033605079849234
Validation loss: 3.6784664939709866

Epoch: 6| Step: 2
Training loss: 3.6550557068886085
Validation loss: 3.676721149213793

Epoch: 6| Step: 3
Training loss: 4.44288351675817
Validation loss: 3.674953372389694

Epoch: 6| Step: 4
Training loss: 3.7234819583263636
Validation loss: 3.6662380442489013

Epoch: 6| Step: 5
Training loss: 4.009558224969907
Validation loss: 3.6650565244073015

Epoch: 6| Step: 6
Training loss: 3.4131813570799836
Validation loss: 3.6554930921666395

Epoch: 6| Step: 7
Training loss: 4.248565880651532
Validation loss: 3.6528657933302813

Epoch: 6| Step: 8
Training loss: 3.160566796039755
Validation loss: 3.6467289306570616

Epoch: 6| Step: 9
Training loss: 3.2417900853006074
Validation loss: 3.641549206600718

Epoch: 6| Step: 10
Training loss: 4.214217852768851
Validation loss: 3.640277100731928

Epoch: 6| Step: 11
Training loss: 3.9387013858081934
Validation loss: 3.6329081296600947

Epoch: 6| Step: 12
Training loss: 4.485757966735701
Validation loss: 3.6258457012047924

Epoch: 6| Step: 13
Training loss: 3.539744869241122
Validation loss: 3.622195551162332

Epoch: 13| Step: 0
Training loss: 3.034087750306919
Validation loss: 3.6195168403317464

Epoch: 6| Step: 1
Training loss: 4.193470129461348
Validation loss: 3.62677971274497

Epoch: 6| Step: 2
Training loss: 4.828078581454147
Validation loss: 3.608012542034149

Epoch: 6| Step: 3
Training loss: 3.208276244477159
Validation loss: 3.602700299287095

Epoch: 6| Step: 4
Training loss: 3.131088581607295
Validation loss: 3.6064685344638434

Epoch: 6| Step: 5
Training loss: 3.6531510220817203
Validation loss: 3.6173080430983404

Epoch: 6| Step: 6
Training loss: 3.4980915861185005
Validation loss: 3.593201220942472

Epoch: 6| Step: 7
Training loss: 4.325934671826669
Validation loss: 3.5862204750832474

Epoch: 6| Step: 8
Training loss: 3.4321269264492265
Validation loss: 3.586316759528537

Epoch: 6| Step: 9
Training loss: 4.298066684892547
Validation loss: 3.5855291687571733

Epoch: 6| Step: 10
Training loss: 3.4673893639833477
Validation loss: 3.5811849412859122

Epoch: 6| Step: 11
Training loss: 4.266057813435975
Validation loss: 3.577701599258947

Epoch: 6| Step: 12
Training loss: 3.8551710452516854
Validation loss: 3.569880067855901

Epoch: 6| Step: 13
Training loss: 3.058467467759429
Validation loss: 3.569819689784725

Epoch: 14| Step: 0
Training loss: 2.7209487442690294
Validation loss: 3.564969493387562

Epoch: 6| Step: 1
Training loss: 3.5187263880965665
Validation loss: 3.5784985353189

Epoch: 6| Step: 2
Training loss: 3.1467500239446733
Validation loss: 3.5645146958060523

Epoch: 6| Step: 3
Training loss: 3.405001770332761
Validation loss: 3.576541504213913

Epoch: 6| Step: 4
Training loss: 4.158439346419708
Validation loss: 3.5684667451989664

Epoch: 6| Step: 5
Training loss: 4.060861579916291
Validation loss: 3.5643298795022873

Epoch: 6| Step: 6
Training loss: 4.384394559048497
Validation loss: 3.558521339579679

Epoch: 6| Step: 7
Training loss: 3.8528728616085592
Validation loss: 3.5603033063746357

Epoch: 6| Step: 8
Training loss: 4.7508010188856495
Validation loss: 3.5595549158023023

Epoch: 6| Step: 9
Training loss: 3.3480846794111723
Validation loss: 3.550715677953746

Epoch: 6| Step: 10
Training loss: 3.801000418229696
Validation loss: 3.575311471966988

Epoch: 6| Step: 11
Training loss: 3.7197443810694906
Validation loss: 3.5470628824616055

Epoch: 6| Step: 12
Training loss: 3.636031236411569
Validation loss: 3.5348665298077977

Epoch: 6| Step: 13
Training loss: 3.7434826483178516
Validation loss: 3.5504678274953

Epoch: 15| Step: 0
Training loss: 3.8869293922584744
Validation loss: 3.5613442319832376

Epoch: 6| Step: 1
Training loss: 3.4739761161444376
Validation loss: 3.546823051360963

Epoch: 6| Step: 2
Training loss: 3.383381361847533
Validation loss: 3.5614938601483495

Epoch: 6| Step: 3
Training loss: 3.448531880575799
Validation loss: 3.542770337314014

Epoch: 6| Step: 4
Training loss: 3.6347340085859634
Validation loss: 3.5304545454830056

Epoch: 6| Step: 5
Training loss: 3.7604045216090376
Validation loss: 3.528810886185303

Epoch: 6| Step: 6
Training loss: 4.156500557825901
Validation loss: 3.5307299475756455

Epoch: 6| Step: 7
Training loss: 2.432773310958797
Validation loss: 3.5250803528471595

Epoch: 6| Step: 8
Training loss: 3.3211486481638675
Validation loss: 3.523823816532399

Epoch: 6| Step: 9
Training loss: 3.491170645527985
Validation loss: 3.5235127108428648

Epoch: 6| Step: 10
Training loss: 4.059441456827066
Validation loss: 3.524742372876294

Epoch: 6| Step: 11
Training loss: 4.2253136332197005
Validation loss: 3.5211031065826184

Epoch: 6| Step: 12
Training loss: 4.737295326502037
Validation loss: 3.5132143407361527

Epoch: 6| Step: 13
Training loss: 3.8531406720934065
Validation loss: 3.505580781686478

Epoch: 16| Step: 0
Training loss: 4.209105593889597
Validation loss: 3.4968461756420135

Epoch: 6| Step: 1
Training loss: 3.6094150293285576
Validation loss: 3.4927413533163723

Epoch: 6| Step: 2
Training loss: 3.7507849825375876
Validation loss: 3.489706018109813

Epoch: 6| Step: 3
Training loss: 3.57833435245731
Validation loss: 3.481249206558196

Epoch: 6| Step: 4
Training loss: 2.7369942463545
Validation loss: 3.4715114393221347

Epoch: 6| Step: 5
Training loss: 3.1729487964575487
Validation loss: 3.4689593685678926

Epoch: 6| Step: 6
Training loss: 3.4439308354414147
Validation loss: 3.4628952090466902

Epoch: 6| Step: 7
Training loss: 4.156743529424107
Validation loss: 3.4541685040067023

Epoch: 6| Step: 8
Training loss: 3.742603000199467
Validation loss: 3.449246101585437

Epoch: 6| Step: 9
Training loss: 3.811700956064995
Validation loss: 3.4518501223509843

Epoch: 6| Step: 10
Training loss: 4.256401178081024
Validation loss: 3.457407921807912

Epoch: 6| Step: 11
Training loss: 4.083285402808152
Validation loss: 3.448042161887844

Epoch: 6| Step: 12
Training loss: 3.300854057998783
Validation loss: 3.435229604542644

Epoch: 6| Step: 13
Training loss: 2.9473743456587367
Validation loss: 3.4306286505718067

Epoch: 17| Step: 0
Training loss: 3.6695792305700596
Validation loss: 3.425903035276207

Epoch: 6| Step: 1
Training loss: 3.871135630607205
Validation loss: 3.422331428139364

Epoch: 6| Step: 2
Training loss: 3.963105039403413
Validation loss: 3.4180864365059924

Epoch: 6| Step: 3
Training loss: 2.4488139570918315
Validation loss: 3.4161143112798897

Epoch: 6| Step: 4
Training loss: 3.5147971301729455
Validation loss: 3.416599105439104

Epoch: 6| Step: 5
Training loss: 3.3242049794074355
Validation loss: 3.413063747810308

Epoch: 6| Step: 6
Training loss: 4.076960254826332
Validation loss: 3.412564452915393

Epoch: 6| Step: 7
Training loss: 3.798490957482609
Validation loss: 3.405107886782441

Epoch: 6| Step: 8
Training loss: 3.4744361804256223
Validation loss: 3.404122413581274

Epoch: 6| Step: 9
Training loss: 3.62403883194487
Validation loss: 3.3986337445016503

Epoch: 6| Step: 10
Training loss: 3.480758500802054
Validation loss: 3.3969683873777323

Epoch: 6| Step: 11
Training loss: 3.985092158382692
Validation loss: 3.3913706139280673

Epoch: 6| Step: 12
Training loss: 3.835396971367959
Validation loss: 3.3880243559195535

Epoch: 6| Step: 13
Training loss: 3.374103144409455
Validation loss: 3.3864620960384126

Epoch: 18| Step: 0
Training loss: 3.779239592992897
Validation loss: 3.384631238875936

Epoch: 6| Step: 1
Training loss: 3.5415255499756557
Validation loss: 3.385601187221739

Epoch: 6| Step: 2
Training loss: 3.8055697129133965
Validation loss: 3.388173725237637

Epoch: 6| Step: 3
Training loss: 3.569977659054048
Validation loss: 3.3802548597172457

Epoch: 6| Step: 4
Training loss: 3.9830169158354143
Validation loss: 3.3725388750965

Epoch: 6| Step: 5
Training loss: 2.990763751312047
Validation loss: 3.3686226737794627

Epoch: 6| Step: 6
Training loss: 3.7058957836075153
Validation loss: 3.3682642162321277

Epoch: 6| Step: 7
Training loss: 3.902623316437291
Validation loss: 3.3674311293138715

Epoch: 6| Step: 8
Training loss: 3.648454229083702
Validation loss: 3.362124579223811

Epoch: 6| Step: 9
Training loss: 3.292054326532716
Validation loss: 3.35890106879824

Epoch: 6| Step: 10
Training loss: 4.1466370894510804
Validation loss: 3.354766748203203

Epoch: 6| Step: 11
Training loss: 3.550917418232702
Validation loss: 3.3560429418577966

Epoch: 6| Step: 12
Training loss: 3.0626974236827906
Validation loss: 3.3580614311552646

Epoch: 6| Step: 13
Training loss: 2.9245839336557875
Validation loss: 3.3560732069604042

Epoch: 19| Step: 0
Training loss: 4.155082825570811
Validation loss: 3.356442671291227

Epoch: 6| Step: 1
Training loss: 4.388781829257889
Validation loss: 3.35124449996496

Epoch: 6| Step: 2
Training loss: 3.6121313626385505
Validation loss: 3.344408610032298

Epoch: 6| Step: 3
Training loss: 3.8762620900988747
Validation loss: 3.3446756514819915

Epoch: 6| Step: 4
Training loss: 3.4612788942618167
Validation loss: 3.3466903398280596

Epoch: 6| Step: 5
Training loss: 3.383529481385349
Validation loss: 3.34387731745794

Epoch: 6| Step: 6
Training loss: 3.2620565821957745
Validation loss: 3.344046212248801

Epoch: 6| Step: 7
Training loss: 3.5969282608662576
Validation loss: 3.3394999289395626

Epoch: 6| Step: 8
Training loss: 3.2167713787316847
Validation loss: 3.3350483163985727

Epoch: 6| Step: 9
Training loss: 2.774690844523823
Validation loss: 3.33317266558986

Epoch: 6| Step: 10
Training loss: 3.617941858055356
Validation loss: 3.3351585595198134

Epoch: 6| Step: 11
Training loss: 4.007533608412859
Validation loss: 3.330217362232147

Epoch: 6| Step: 12
Training loss: 3.5978195368753383
Validation loss: 3.3248236126513593

Epoch: 6| Step: 13
Training loss: 1.96205058935352
Validation loss: 3.32649051628817

Epoch: 20| Step: 0
Training loss: 3.289207473423143
Validation loss: 3.328130036189985

Epoch: 6| Step: 1
Training loss: 3.836959547325207
Validation loss: 3.326151766121422

Epoch: 6| Step: 2
Training loss: 3.28968844947428
Validation loss: 3.3241966565619596

Epoch: 6| Step: 3
Training loss: 3.801627869520239
Validation loss: 3.3189733479338845

Epoch: 6| Step: 4
Training loss: 3.9289473638622963
Validation loss: 3.3178899922014877

Epoch: 6| Step: 5
Training loss: 3.1905053126558887
Validation loss: 3.3156393749595847

Epoch: 6| Step: 6
Training loss: 2.626525798770392
Validation loss: 3.316429109599783

Epoch: 6| Step: 7
Training loss: 3.1067759323824373
Validation loss: 3.333811034048791

Epoch: 6| Step: 8
Training loss: 3.628073474606874
Validation loss: 3.3457671659200723

Epoch: 6| Step: 9
Training loss: 4.011174567141283
Validation loss: 3.3290630249029554

Epoch: 6| Step: 10
Training loss: 4.1687187227966005
Validation loss: 3.3115057835657953

Epoch: 6| Step: 11
Training loss: 2.852967801730325
Validation loss: 3.317365862078377

Epoch: 6| Step: 12
Training loss: 3.989757776389165
Validation loss: 3.3666022376693254

Epoch: 6| Step: 13
Training loss: 3.979047617038488
Validation loss: 3.3221803854265475

Epoch: 21| Step: 0
Training loss: 4.6294043936864275
Validation loss: 3.324105248877109

Epoch: 6| Step: 1
Training loss: 4.026941406990784
Validation loss: 3.331663066001875

Epoch: 6| Step: 2
Training loss: 3.198369659911955
Validation loss: 3.332197678571795

Epoch: 6| Step: 3
Training loss: 2.0502483729186367
Validation loss: 3.3296072612841927

Epoch: 6| Step: 4
Training loss: 3.2288742097067478
Validation loss: 3.3287172770213265

Epoch: 6| Step: 5
Training loss: 3.382299653045715
Validation loss: 3.331954974608823

Epoch: 6| Step: 6
Training loss: 3.905553526777594
Validation loss: 3.3288426634307493

Epoch: 6| Step: 7
Training loss: 3.4136223760303737
Validation loss: 3.32062204383864

Epoch: 6| Step: 8
Training loss: 4.489949340534524
Validation loss: 3.3203617902519764

Epoch: 6| Step: 9
Training loss: 3.564343962369524
Validation loss: 3.308446963589444

Epoch: 6| Step: 10
Training loss: 3.334941777946428
Validation loss: 3.3025144838557963

Epoch: 6| Step: 11
Training loss: 3.3615236020477415
Validation loss: 3.296780584356144

Epoch: 6| Step: 12
Training loss: 2.7454361759090284
Validation loss: 3.290915804783233

Epoch: 6| Step: 13
Training loss: 3.835306088443688
Validation loss: 3.2895626765088646

Epoch: 22| Step: 0
Training loss: 3.008950550731608
Validation loss: 3.2879096356276856

Epoch: 6| Step: 1
Training loss: 3.9007397659207603
Validation loss: 3.293644916696336

Epoch: 6| Step: 2
Training loss: 3.5962616477886407
Validation loss: 3.291379596492103

Epoch: 6| Step: 3
Training loss: 3.2623563771405673
Validation loss: 3.2968975937856504

Epoch: 6| Step: 4
Training loss: 3.295962528312042
Validation loss: 3.2924500469494324

Epoch: 6| Step: 5
Training loss: 3.4095136773343753
Validation loss: 3.2958176933433867

Epoch: 6| Step: 6
Training loss: 3.989229961844336
Validation loss: 3.3006043819450843

Epoch: 6| Step: 7
Training loss: 3.5714077594695643
Validation loss: 3.2816675173471506

Epoch: 6| Step: 8
Training loss: 3.1232195550583888
Validation loss: 3.2791338494214175

Epoch: 6| Step: 9
Training loss: 3.7372519930714865
Validation loss: 3.278842634750437

Epoch: 6| Step: 10
Training loss: 3.9220684353364366
Validation loss: 3.2812739811346647

Epoch: 6| Step: 11
Training loss: 3.288994940202068
Validation loss: 3.274225549184352

Epoch: 6| Step: 12
Training loss: 3.455333849045822
Validation loss: 3.271470028229455

Epoch: 6| Step: 13
Training loss: 3.7675238289487667
Validation loss: 3.266111320124497

Epoch: 23| Step: 0
Training loss: 3.289131653119889
Validation loss: 3.2643753850497497

Epoch: 6| Step: 1
Training loss: 3.03096117039712
Validation loss: 3.2637374407010293

Epoch: 6| Step: 2
Training loss: 3.7877353506962526
Validation loss: 3.2716013817394383

Epoch: 6| Step: 3
Training loss: 3.6105762150740426
Validation loss: 3.270876009800962

Epoch: 6| Step: 4
Training loss: 3.335106489320091
Validation loss: 3.2658131274350395

Epoch: 6| Step: 5
Training loss: 4.22173153106179
Validation loss: 3.267016345673494

Epoch: 6| Step: 6
Training loss: 3.459734498790915
Validation loss: 3.2569818368981136

Epoch: 6| Step: 7
Training loss: 3.6315760979834
Validation loss: 3.254753484372102

Epoch: 6| Step: 8
Training loss: 2.820569478424027
Validation loss: 3.2542433192412483

Epoch: 6| Step: 9
Training loss: 3.499810622405189
Validation loss: 3.2527660930981526

Epoch: 6| Step: 10
Training loss: 4.084264117182709
Validation loss: 3.249458771184715

Epoch: 6| Step: 11
Training loss: 2.9236958587839483
Validation loss: 3.2467371003943115

Epoch: 6| Step: 12
Training loss: 3.3685240604310853
Validation loss: 3.2464744133707564

Epoch: 6| Step: 13
Training loss: 3.907415841649096
Validation loss: 3.243132836999856

Epoch: 24| Step: 0
Training loss: 3.2143910345352182
Validation loss: 3.240267062053693

Epoch: 6| Step: 1
Training loss: 3.2853876093658134
Validation loss: 3.239252976868852

Epoch: 6| Step: 2
Training loss: 2.7520177547968845
Validation loss: 3.2390053559961256

Epoch: 6| Step: 3
Training loss: 4.1037273397758325
Validation loss: 3.235456225217661

Epoch: 6| Step: 4
Training loss: 3.040847842292604
Validation loss: 3.2348591138673957

Epoch: 6| Step: 5
Training loss: 2.8442171153316527
Validation loss: 3.23406126293912

Epoch: 6| Step: 6
Training loss: 3.453547249088185
Validation loss: 3.234908264627512

Epoch: 6| Step: 7
Training loss: 4.232043986576851
Validation loss: 3.23443921610826

Epoch: 6| Step: 8
Training loss: 4.367899773506311
Validation loss: 3.231484838133347

Epoch: 6| Step: 9
Training loss: 2.882848723889539
Validation loss: 3.229517019731628

Epoch: 6| Step: 10
Training loss: 3.8010840927492473
Validation loss: 3.2282903608918616

Epoch: 6| Step: 11
Training loss: 3.6050841352615413
Validation loss: 3.2261284456750503

Epoch: 6| Step: 12
Training loss: 2.6158205020813043
Validation loss: 3.227496636964341

Epoch: 6| Step: 13
Training loss: 4.311221168092062
Validation loss: 3.2284516468141717

Epoch: 25| Step: 0
Training loss: 4.256828432367495
Validation loss: 3.228581737900988

Epoch: 6| Step: 1
Training loss: 3.0626429310356214
Validation loss: 3.2243075937611563

Epoch: 6| Step: 2
Training loss: 4.165975106386995
Validation loss: 3.2213066771970817

Epoch: 6| Step: 3
Training loss: 3.4301793608188618
Validation loss: 3.2218862614673003

Epoch: 6| Step: 4
Training loss: 3.9589595633935137
Validation loss: 3.223808650221513

Epoch: 6| Step: 5
Training loss: 3.9548999284702346
Validation loss: 3.217816501121191

Epoch: 6| Step: 6
Training loss: 2.2760363010602216
Validation loss: 3.2187552292252954

Epoch: 6| Step: 7
Training loss: 3.5174140955474185
Validation loss: 3.215115846878243

Epoch: 6| Step: 8
Training loss: 3.6558099465585525
Validation loss: 3.2149888327128773

Epoch: 6| Step: 9
Training loss: 2.900399174019387
Validation loss: 3.215496359378989

Epoch: 6| Step: 10
Training loss: 2.8783900964113847
Validation loss: 3.2152205535611813

Epoch: 6| Step: 11
Training loss: 3.544558268413184
Validation loss: 3.2198758806961028

Epoch: 6| Step: 12
Training loss: 3.3626894192007803
Validation loss: 3.220212001243095

Epoch: 6| Step: 13
Training loss: 2.848523001504481
Validation loss: 3.219949682106638

Epoch: 26| Step: 0
Training loss: 3.278313767168399
Validation loss: 3.2182380292199686

Epoch: 6| Step: 1
Training loss: 3.226731265921534
Validation loss: 3.2179484553605673

Epoch: 6| Step: 2
Training loss: 3.402407797770082
Validation loss: 3.2097290142562755

Epoch: 6| Step: 3
Training loss: 3.239783146983381
Validation loss: 3.2090361349707

Epoch: 6| Step: 4
Training loss: 3.075703089280271
Validation loss: 3.20944540159446

Epoch: 6| Step: 5
Training loss: 3.5082726123716905
Validation loss: 3.2070421791217685

Epoch: 6| Step: 6
Training loss: 3.428667824956807
Validation loss: 3.20830568371735

Epoch: 6| Step: 7
Training loss: 3.48548946604808
Validation loss: 3.2093767920536993

Epoch: 6| Step: 8
Training loss: 3.10101667160675
Validation loss: 3.2077562667907698

Epoch: 6| Step: 9
Training loss: 3.9652442166136117
Validation loss: 3.2098449823655453

Epoch: 6| Step: 10
Training loss: 4.230872701166576
Validation loss: 3.208808825868462

Epoch: 6| Step: 11
Training loss: 3.6287875941395837
Validation loss: 3.209012734837925

Epoch: 6| Step: 12
Training loss: 3.634814951304208
Validation loss: 3.2077551694882

Epoch: 6| Step: 13
Training loss: 2.8464431585911445
Validation loss: 3.2073702784439653

Epoch: 27| Step: 0
Training loss: 3.8674035214286335
Validation loss: 3.206997842084975

Epoch: 6| Step: 1
Training loss: 3.4212952562543837
Validation loss: 3.2058467783271025

Epoch: 6| Step: 2
Training loss: 3.111638457775379
Validation loss: 3.203635197586829

Epoch: 6| Step: 3
Training loss: 4.038727678185906
Validation loss: 3.2034393948606144

Epoch: 6| Step: 4
Training loss: 3.182596062036745
Validation loss: 3.202934717688706

Epoch: 6| Step: 5
Training loss: 3.5825559674807366
Validation loss: 3.2031397249176976

Epoch: 6| Step: 6
Training loss: 4.162578153592509
Validation loss: 3.1989086365977806

Epoch: 6| Step: 7
Training loss: 3.004723327391379
Validation loss: 3.200228201832931

Epoch: 6| Step: 8
Training loss: 2.968679648117899
Validation loss: 3.1982264877543947

Epoch: 6| Step: 9
Training loss: 2.7823285358308834
Validation loss: 3.1990381163531434

Epoch: 6| Step: 10
Training loss: 3.252217929815389
Validation loss: 3.197826813257222

Epoch: 6| Step: 11
Training loss: 4.125955875502873
Validation loss: 3.197690447424792

Epoch: 6| Step: 12
Training loss: 3.1417286010897367
Validation loss: 3.195355926498581

Epoch: 6| Step: 13
Training loss: 3.3596123190156972
Validation loss: 3.19687633715458

Epoch: 28| Step: 0
Training loss: 3.58452064597396
Validation loss: 3.196782350691695

Epoch: 6| Step: 1
Training loss: 2.960847314754522
Validation loss: 3.1955301504660687

Epoch: 6| Step: 2
Training loss: 3.7370267893806086
Validation loss: 3.2068579250733804

Epoch: 6| Step: 3
Training loss: 3.4732390902639003
Validation loss: 3.197814983613718

Epoch: 6| Step: 4
Training loss: 3.8161629762295295
Validation loss: 3.195778638713393

Epoch: 6| Step: 5
Training loss: 3.4196876258295803
Validation loss: 3.1915737293966657

Epoch: 6| Step: 6
Training loss: 2.653509274389068
Validation loss: 3.1900386493008104

Epoch: 6| Step: 7
Training loss: 3.564483759500206
Validation loss: 3.1895344864872746

Epoch: 6| Step: 8
Training loss: 3.390518819667001
Validation loss: 3.1900258617655997

Epoch: 6| Step: 9
Training loss: 3.2328160163782833
Validation loss: 3.1893126553234743

Epoch: 6| Step: 10
Training loss: 3.687500258623534
Validation loss: 3.187685739702145

Epoch: 6| Step: 11
Training loss: 2.886489301552333
Validation loss: 3.18889872749881

Epoch: 6| Step: 12
Training loss: 3.8867502795910207
Validation loss: 3.1881980670474905

Epoch: 6| Step: 13
Training loss: 3.981959908759231
Validation loss: 3.1860731833418687

Epoch: 29| Step: 0
Training loss: 3.5994023197791254
Validation loss: 3.1851777543482087

Epoch: 6| Step: 1
Training loss: 3.819358285259664
Validation loss: 3.183444923653118

Epoch: 6| Step: 2
Training loss: 2.8680987248367438
Validation loss: 3.1831560496456124

Epoch: 6| Step: 3
Training loss: 3.5197173989167516
Validation loss: 3.185607512423882

Epoch: 6| Step: 4
Training loss: 3.509834777116822
Validation loss: 3.1820068172812537

Epoch: 6| Step: 5
Training loss: 2.6743031672605713
Validation loss: 3.1863216173959197

Epoch: 6| Step: 6
Training loss: 3.8202306196491183
Validation loss: 3.1875372089656806

Epoch: 6| Step: 7
Training loss: 3.255178287621755
Validation loss: 3.1799499221215473

Epoch: 6| Step: 8
Training loss: 2.8643200747579907
Validation loss: 3.179015927872611

Epoch: 6| Step: 9
Training loss: 3.431853077738057
Validation loss: 3.1789754579399405

Epoch: 6| Step: 10
Training loss: 3.547404648814629
Validation loss: 3.1793528186153166

Epoch: 6| Step: 11
Training loss: 4.4603055115482455
Validation loss: 3.178971162858261

Epoch: 6| Step: 12
Training loss: 3.3641262787240405
Validation loss: 3.1789531163551508

Epoch: 6| Step: 13
Training loss: 2.7929201775442034
Validation loss: 3.177340226837969

Epoch: 30| Step: 0
Training loss: 2.6948312523265026
Validation loss: 3.1776125903639763

Epoch: 6| Step: 1
Training loss: 3.218275312957273
Validation loss: 3.1770438735316238

Epoch: 6| Step: 2
Training loss: 4.039076194518612
Validation loss: 3.1745455548347756

Epoch: 6| Step: 3
Training loss: 3.349674288729603
Validation loss: 3.1744011805597747

Epoch: 6| Step: 4
Training loss: 2.2317628329892947
Validation loss: 3.1754302847146056

Epoch: 6| Step: 5
Training loss: 2.9847552471681906
Validation loss: 3.1743346176194054

Epoch: 6| Step: 6
Training loss: 3.5460252458133055
Validation loss: 3.1745639817186353

Epoch: 6| Step: 7
Training loss: 3.2405619395345555
Validation loss: 3.173240074083124

Epoch: 6| Step: 8
Training loss: 3.4848974546125513
Validation loss: 3.1742455509591263

Epoch: 6| Step: 9
Training loss: 3.6164180851839713
Validation loss: 3.174075328656069

Epoch: 6| Step: 10
Training loss: 3.74197775744745
Validation loss: 3.170291206374352

Epoch: 6| Step: 11
Training loss: 4.240363246904472
Validation loss: 3.1710596867907492

Epoch: 6| Step: 12
Training loss: 3.1659044720424894
Validation loss: 3.168528919744122

Epoch: 6| Step: 13
Training loss: 4.388462606617791
Validation loss: 3.167655180659197

Epoch: 31| Step: 0
Training loss: 2.9524073460420213
Validation loss: 3.1655179294939706

Epoch: 6| Step: 1
Training loss: 3.8826031081539583
Validation loss: 3.163144590293222

Epoch: 6| Step: 2
Training loss: 3.2575342439152903
Validation loss: 3.1638131915840257

Epoch: 6| Step: 3
Training loss: 3.3073511954329313
Validation loss: 3.1641362145072525

Epoch: 6| Step: 4
Training loss: 3.3091524591447534
Validation loss: 3.1642939389870905

Epoch: 6| Step: 5
Training loss: 4.167119777202094
Validation loss: 3.1678067606917795

Epoch: 6| Step: 6
Training loss: 2.6360318115583983
Validation loss: 3.1621334740802247

Epoch: 6| Step: 7
Training loss: 3.728389779830134
Validation loss: 3.1650658032993184

Epoch: 6| Step: 8
Training loss: 3.5076964089399243
Validation loss: 3.1712767495860827

Epoch: 6| Step: 9
Training loss: 3.1495280684307305
Validation loss: 3.1769651205717038

Epoch: 6| Step: 10
Training loss: 3.7389869462321257
Validation loss: 3.1765413744292945

Epoch: 6| Step: 11
Training loss: 3.155397507764566
Validation loss: 3.1696350636327315

Epoch: 6| Step: 12
Training loss: 3.5226721090880675
Validation loss: 3.1685081971374065

Epoch: 6| Step: 13
Training loss: 3.4285507229906385
Validation loss: 3.1679610751776908

Epoch: 32| Step: 0
Training loss: 3.4071396532069356
Validation loss: 3.168169870005252

Epoch: 6| Step: 1
Training loss: 2.9474718996217857
Validation loss: 3.1701518656649146

Epoch: 6| Step: 2
Training loss: 3.4155486689045675
Validation loss: 3.162331141222476

Epoch: 6| Step: 3
Training loss: 3.024170621559442
Validation loss: 3.156387295250208

Epoch: 6| Step: 4
Training loss: 3.4373132828373554
Validation loss: 3.1543497078924316

Epoch: 6| Step: 5
Training loss: 3.29892034497726
Validation loss: 3.1535666345317583

Epoch: 6| Step: 6
Training loss: 3.3582050504076575
Validation loss: 3.151983186788042

Epoch: 6| Step: 7
Training loss: 3.5145906410224224
Validation loss: 3.1519048577168345

Epoch: 6| Step: 8
Training loss: 3.612065489089746
Validation loss: 3.150682363192592

Epoch: 6| Step: 9
Training loss: 3.770816121492393
Validation loss: 3.1531061032217207

Epoch: 6| Step: 10
Training loss: 3.979959591991084
Validation loss: 3.1488431470085705

Epoch: 6| Step: 11
Training loss: 3.009081921908466
Validation loss: 3.137047380608487

Epoch: 6| Step: 12
Training loss: 3.4126426135993637
Validation loss: 3.1361562859297782

Epoch: 6| Step: 13
Training loss: 3.6155159632958567
Validation loss: 3.1367025804925937

Epoch: 33| Step: 0
Training loss: 3.8967521250425254
Validation loss: 3.1441657572711645

Epoch: 6| Step: 1
Training loss: 3.1851941912751274
Validation loss: 3.1350070608278386

Epoch: 6| Step: 2
Training loss: 3.5573784671915205
Validation loss: 3.132609920985927

Epoch: 6| Step: 3
Training loss: 3.5161067378276325
Validation loss: 3.1296309189265457

Epoch: 6| Step: 4
Training loss: 3.508442369761612
Validation loss: 3.1285456832096035

Epoch: 6| Step: 5
Training loss: 2.762878778648787
Validation loss: 3.1286300494872425

Epoch: 6| Step: 6
Training loss: 3.8654438442009345
Validation loss: 3.126876194005206

Epoch: 6| Step: 7
Training loss: 3.643298824899578
Validation loss: 3.126345970127071

Epoch: 6| Step: 8
Training loss: 3.718392619423099
Validation loss: 3.124884362491061

Epoch: 6| Step: 9
Training loss: 2.926571259330191
Validation loss: 3.122315442822831

Epoch: 6| Step: 10
Training loss: 2.9429079961417215
Validation loss: 3.120637456531421

Epoch: 6| Step: 11
Training loss: 3.0787518632691877
Validation loss: 3.1230089715468092

Epoch: 6| Step: 12
Training loss: 3.1548392287218108
Validation loss: 3.1206861668746155

Epoch: 6| Step: 13
Training loss: 3.7704925102075526
Validation loss: 3.120013225828188

Epoch: 34| Step: 0
Training loss: 3.7913964702763834
Validation loss: 3.118566370470457

Epoch: 6| Step: 1
Training loss: 2.8500019140404413
Validation loss: 3.119861848034843

Epoch: 6| Step: 2
Training loss: 3.2746716633219086
Validation loss: 3.1190605900470008

Epoch: 6| Step: 3
Training loss: 3.0524221151977233
Validation loss: 3.119221824975877

Epoch: 6| Step: 4
Training loss: 3.6513156035320584
Validation loss: 3.121053271552414

Epoch: 6| Step: 5
Training loss: 3.8381610959481245
Validation loss: 3.1158972606167548

Epoch: 6| Step: 6
Training loss: 3.2087039650860723
Validation loss: 3.114154517957958

Epoch: 6| Step: 7
Training loss: 3.731683375559841
Validation loss: 3.1151578113221348

Epoch: 6| Step: 8
Training loss: 3.246888505248546
Validation loss: 3.115235996184839

Epoch: 6| Step: 9
Training loss: 3.066001914026866
Validation loss: 3.1100616628548527

Epoch: 6| Step: 10
Training loss: 2.3114887810298064
Validation loss: 3.1123665624326753

Epoch: 6| Step: 11
Training loss: 3.354906525766532
Validation loss: 3.109975806140413

Epoch: 6| Step: 12
Training loss: 3.5986848866228907
Validation loss: 3.1134091329107507

Epoch: 6| Step: 13
Training loss: 4.487896005483001
Validation loss: 3.1177780361370973

Epoch: 35| Step: 0
Training loss: 4.541311314297793
Validation loss: 3.109775165612923

Epoch: 6| Step: 1
Training loss: 3.511026995358166
Validation loss: 3.107690905949915

Epoch: 6| Step: 2
Training loss: 3.0666858326962614
Validation loss: 3.107315947417804

Epoch: 6| Step: 3
Training loss: 2.772069287291521
Validation loss: 3.106284259508094

Epoch: 6| Step: 4
Training loss: 3.91949171624596
Validation loss: 3.1080963734496265

Epoch: 6| Step: 5
Training loss: 2.024820451664965
Validation loss: 3.104254131209477

Epoch: 6| Step: 6
Training loss: 3.28010321059316
Validation loss: 3.1041479460460137

Epoch: 6| Step: 7
Training loss: 2.8128275362665405
Validation loss: 3.1046645783804663

Epoch: 6| Step: 8
Training loss: 3.571690666935741
Validation loss: 3.1096802514913953

Epoch: 6| Step: 9
Training loss: 4.138757133235792
Validation loss: 3.111044102805102

Epoch: 6| Step: 10
Training loss: 3.047357609014209
Validation loss: 3.106025681461779

Epoch: 6| Step: 11
Training loss: 3.054197930717654
Validation loss: 3.1040648213607014

Epoch: 6| Step: 12
Training loss: 3.285863920323065
Validation loss: 3.103705386299661

Epoch: 6| Step: 13
Training loss: 3.6797959621504943
Validation loss: 3.105755342382627

Epoch: 36| Step: 0
Training loss: 3.3336193597782984
Validation loss: 3.1011138299716867

Epoch: 6| Step: 1
Training loss: 3.054510477307525
Validation loss: 3.10096185034698

Epoch: 6| Step: 2
Training loss: 2.647958267649461
Validation loss: 3.1026788832178447

Epoch: 6| Step: 3
Training loss: 4.2645526138836685
Validation loss: 3.0999426227437223

Epoch: 6| Step: 4
Training loss: 3.6475927122280685
Validation loss: 3.099068175916698

Epoch: 6| Step: 5
Training loss: 3.3314175504592356
Validation loss: 3.100255500123309

Epoch: 6| Step: 6
Training loss: 3.366060639277748
Validation loss: 3.098719478235589

Epoch: 6| Step: 7
Training loss: 2.992494413008928
Validation loss: 3.099535286315269

Epoch: 6| Step: 8
Training loss: 3.870325776417353
Validation loss: 3.102487956825349

Epoch: 6| Step: 9
Training loss: 2.099204403168433
Validation loss: 3.101051732994629

Epoch: 6| Step: 10
Training loss: 3.5375892654856496
Validation loss: 3.098835049737413

Epoch: 6| Step: 11
Training loss: 3.5987617376413685
Validation loss: 3.0992974953048185

Epoch: 6| Step: 12
Training loss: 3.350630339348027
Validation loss: 3.0972844221259273

Epoch: 6| Step: 13
Training loss: 3.8141500935699026
Validation loss: 3.096033106766445

Epoch: 37| Step: 0
Training loss: 3.2540536689107276
Validation loss: 3.096265772421248

Epoch: 6| Step: 1
Training loss: 2.0907262347105804
Validation loss: 3.0946880238989802

Epoch: 6| Step: 2
Training loss: 2.936903548052187
Validation loss: 3.095177467907025

Epoch: 6| Step: 3
Training loss: 3.6610433344210485
Validation loss: 3.095498799029077

Epoch: 6| Step: 4
Training loss: 3.4195487419589172
Validation loss: 3.0971884497936397

Epoch: 6| Step: 5
Training loss: 3.7723336510609395
Validation loss: 3.0930127404477648

Epoch: 6| Step: 6
Training loss: 3.5540446276505913
Validation loss: 3.0936612948978537

Epoch: 6| Step: 7
Training loss: 3.41795033477182
Validation loss: 3.09329705575449

Epoch: 6| Step: 8
Training loss: 3.6341524011695983
Validation loss: 3.0921407147480933

Epoch: 6| Step: 9
Training loss: 3.9114781907039364
Validation loss: 3.0916414206819334

Epoch: 6| Step: 10
Training loss: 3.0145481539037635
Validation loss: 3.091586005292983

Epoch: 6| Step: 11
Training loss: 3.242461337739187
Validation loss: 3.089745799147706

Epoch: 6| Step: 12
Training loss: 3.2561707236218544
Validation loss: 3.090779323112012

Epoch: 6| Step: 13
Training loss: 3.7451148956968217
Validation loss: 3.089575683328931

Epoch: 38| Step: 0
Training loss: 3.654442495261333
Validation loss: 3.094303748196157

Epoch: 6| Step: 1
Training loss: 3.1323703063761617
Validation loss: 3.0973174275511224

Epoch: 6| Step: 2
Training loss: 3.882717446098203
Validation loss: 3.098242451158671

Epoch: 6| Step: 3
Training loss: 3.6219947459426596
Validation loss: 3.0893270108350888

Epoch: 6| Step: 4
Training loss: 2.9540452280269025
Validation loss: 3.0885063888332667

Epoch: 6| Step: 5
Training loss: 3.517530137009562
Validation loss: 3.088453235586985

Epoch: 6| Step: 6
Training loss: 3.5187540328712457
Validation loss: 3.0909212466957205

Epoch: 6| Step: 7
Training loss: 3.24530276727296
Validation loss: 3.0921515458666273

Epoch: 6| Step: 8
Training loss: 3.433953692737744
Validation loss: 3.095633803225784

Epoch: 6| Step: 9
Training loss: 3.4966927297643298
Validation loss: 3.0979649417973603

Epoch: 6| Step: 10
Training loss: 3.0192946801530627
Validation loss: 3.088673631109742

Epoch: 6| Step: 11
Training loss: 2.5690438986502624
Validation loss: 3.0854825547554956

Epoch: 6| Step: 12
Training loss: 3.7425274465569953
Validation loss: 3.083416970628272

Epoch: 6| Step: 13
Training loss: 2.754670165684125
Validation loss: 3.0842101079119257

Epoch: 39| Step: 0
Training loss: 3.3359284948008576
Validation loss: 3.0822198370986733

Epoch: 6| Step: 1
Training loss: 3.548926478583436
Validation loss: 3.079897157880227

Epoch: 6| Step: 2
Training loss: 3.9274806353736937
Validation loss: 3.081877272896351

Epoch: 6| Step: 3
Training loss: 3.0600086900176278
Validation loss: 3.0815350366642407

Epoch: 6| Step: 4
Training loss: 3.100905649117135
Validation loss: 3.0793509358694275

Epoch: 6| Step: 5
Training loss: 3.3078315514478525
Validation loss: 3.078046834463445

Epoch: 6| Step: 6
Training loss: 3.4823835352628696
Validation loss: 3.0771894784914795

Epoch: 6| Step: 7
Training loss: 2.6700740343895135
Validation loss: 3.076997843647251

Epoch: 6| Step: 8
Training loss: 3.0961889036246983
Validation loss: 3.0752539176294573

Epoch: 6| Step: 9
Training loss: 2.695524699385776
Validation loss: 3.073664878050192

Epoch: 6| Step: 10
Training loss: 3.2221004492305387
Validation loss: 3.073614007918786

Epoch: 6| Step: 11
Training loss: 3.569304543081838
Validation loss: 3.0763739729626574

Epoch: 6| Step: 12
Training loss: 3.86480553220441
Validation loss: 3.0756647399097656

Epoch: 6| Step: 13
Training loss: 4.038643614189254
Validation loss: 3.073143956097149

Epoch: 40| Step: 0
Training loss: 3.5406339747962434
Validation loss: 3.06989757518094

Epoch: 6| Step: 1
Training loss: 3.042016327151411
Validation loss: 3.0698606088663167

Epoch: 6| Step: 2
Training loss: 2.609069532228899
Validation loss: 3.0691479937712707

Epoch: 6| Step: 3
Training loss: 3.4899444545052902
Validation loss: 3.068639085515961

Epoch: 6| Step: 4
Training loss: 3.9615623688492794
Validation loss: 3.0665192973487914

Epoch: 6| Step: 5
Training loss: 3.413297449633608
Validation loss: 3.0672379559694494

Epoch: 6| Step: 6
Training loss: 2.697666897988868
Validation loss: 3.0670590246894234

Epoch: 6| Step: 7
Training loss: 3.1960091799053942
Validation loss: 3.065197867785133

Epoch: 6| Step: 8
Training loss: 3.2089879412639952
Validation loss: 3.06881596318688

Epoch: 6| Step: 9
Training loss: 3.2787733631414206
Validation loss: 3.0596803379911446

Epoch: 6| Step: 10
Training loss: 3.688382835096219
Validation loss: 3.059630287742322

Epoch: 6| Step: 11
Training loss: 3.5295587050947264
Validation loss: 3.0593974554277765

Epoch: 6| Step: 12
Training loss: 3.321465218103053
Validation loss: 3.0587267070085034

Epoch: 6| Step: 13
Training loss: 3.650725404951849
Validation loss: 3.056467503267098

Epoch: 41| Step: 0
Training loss: 3.6051620402537825
Validation loss: 3.0564032402066887

Epoch: 6| Step: 1
Training loss: 2.7748052958323135
Validation loss: 3.0581005030162185

Epoch: 6| Step: 2
Training loss: 3.866920415729669
Validation loss: 3.05872303427763

Epoch: 6| Step: 3
Training loss: 3.501640752678011
Validation loss: 3.0591997819110106

Epoch: 6| Step: 4
Training loss: 3.1539860527973542
Validation loss: 3.0574233146663494

Epoch: 6| Step: 5
Training loss: 3.1034219006261674
Validation loss: 3.058914287843023

Epoch: 6| Step: 6
Training loss: 3.7692084139605617
Validation loss: 3.058107076209153

Epoch: 6| Step: 7
Training loss: 2.4243901144541464
Validation loss: 3.057306586931411

Epoch: 6| Step: 8
Training loss: 3.385087514672941
Validation loss: 3.0554203912168276

Epoch: 6| Step: 9
Training loss: 3.066055102804354
Validation loss: 3.0572038083653124

Epoch: 6| Step: 10
Training loss: 2.857385662524724
Validation loss: 3.056227838522411

Epoch: 6| Step: 11
Training loss: 3.613795096486469
Validation loss: 3.0570598984792383

Epoch: 6| Step: 12
Training loss: 3.7634524334379464
Validation loss: 3.0546079525129803

Epoch: 6| Step: 13
Training loss: 3.4446879748593524
Validation loss: 3.0569529084278244

Epoch: 42| Step: 0
Training loss: 3.298559544924289
Validation loss: 3.060826378132009

Epoch: 6| Step: 1
Training loss: 3.3982853997931466
Validation loss: 3.055965781680062

Epoch: 6| Step: 2
Training loss: 4.2047855542961035
Validation loss: 3.0495750039694545

Epoch: 6| Step: 3
Training loss: 3.026578784400564
Validation loss: 3.048164953261196

Epoch: 6| Step: 4
Training loss: 2.5633450487098135
Validation loss: 3.0487099733329224

Epoch: 6| Step: 5
Training loss: 3.179936129810291
Validation loss: 3.0481709381239357

Epoch: 6| Step: 6
Training loss: 3.5750930133803918
Validation loss: 3.049237437063003

Epoch: 6| Step: 7
Training loss: 3.583890176725303
Validation loss: 3.04840254227653

Epoch: 6| Step: 8
Training loss: 2.8918622642419676
Validation loss: 3.046694354478133

Epoch: 6| Step: 9
Training loss: 3.1923919238838314
Validation loss: 3.0469450196623327

Epoch: 6| Step: 10
Training loss: 3.2433843035350405
Validation loss: 3.0470921256313135

Epoch: 6| Step: 11
Training loss: 3.85037887987867
Validation loss: 3.0449990420061566

Epoch: 6| Step: 12
Training loss: 2.6877600078337895
Validation loss: 3.0453787437240676

Epoch: 6| Step: 13
Training loss: 3.58450268731673
Validation loss: 3.0444999396750267

Epoch: 43| Step: 0
Training loss: 3.4805545132706417
Validation loss: 3.047354647753806

Epoch: 6| Step: 1
Training loss: 2.9208664402919773
Validation loss: 3.044763880914744

Epoch: 6| Step: 2
Training loss: 3.7018210131192713
Validation loss: 3.0455418011398923

Epoch: 6| Step: 3
Training loss: 2.6796912368436954
Validation loss: 3.0503383005724536

Epoch: 6| Step: 4
Training loss: 4.122644387626244
Validation loss: 3.0579747763501897

Epoch: 6| Step: 5
Training loss: 2.850719923142257
Validation loss: 3.0547242084906854

Epoch: 6| Step: 6
Training loss: 3.9490155357350836
Validation loss: 3.0490596254221844

Epoch: 6| Step: 7
Training loss: 3.0190328208855206
Validation loss: 3.0448162720388923

Epoch: 6| Step: 8
Training loss: 3.208633673015264
Validation loss: 3.040647866800158

Epoch: 6| Step: 9
Training loss: 2.377155329834002
Validation loss: 3.042084194244314

Epoch: 6| Step: 10
Training loss: 3.287963973690277
Validation loss: 3.0405314731065447

Epoch: 6| Step: 11
Training loss: 4.185260230647813
Validation loss: 3.040659694951953

Epoch: 6| Step: 12
Training loss: 3.048097648818587
Validation loss: 3.040923294230681

Epoch: 6| Step: 13
Training loss: 2.943863813463809
Validation loss: 3.040264629683111

Epoch: 44| Step: 0
Training loss: 2.9773319881770433
Validation loss: 3.040763473650036

Epoch: 6| Step: 1
Training loss: 3.1063595052102952
Validation loss: 3.0395170937266074

Epoch: 6| Step: 2
Training loss: 3.476614756673624
Validation loss: 3.039758921481135

Epoch: 6| Step: 3
Training loss: 3.5058563827459377
Validation loss: 3.0382181668075687

Epoch: 6| Step: 4
Training loss: 3.7658909114165073
Validation loss: 3.039277020618693

Epoch: 6| Step: 5
Training loss: 3.4254624882878213
Validation loss: 3.0366746143713295

Epoch: 6| Step: 6
Training loss: 3.415890551240868
Validation loss: 3.036194958009236

Epoch: 6| Step: 7
Training loss: 3.26738009220402
Validation loss: 3.0360666143123534

Epoch: 6| Step: 8
Training loss: 3.8143054876942655
Validation loss: 3.0375575214237984

Epoch: 6| Step: 9
Training loss: 3.6053920419453758
Validation loss: 3.038062553922146

Epoch: 6| Step: 10
Training loss: 2.855292903218755
Validation loss: 3.0407771316952554

Epoch: 6| Step: 11
Training loss: 3.1420254597740236
Validation loss: 3.0461860797118696

Epoch: 6| Step: 12
Training loss: 2.733882925170948
Validation loss: 3.048453222576415

Epoch: 6| Step: 13
Training loss: 2.9943189872673495
Validation loss: 3.0495586985804626

Epoch: 45| Step: 0
Training loss: 3.0964790406752023
Validation loss: 3.043581768608

Epoch: 6| Step: 1
Training loss: 2.960296158795319
Validation loss: 3.0405524574865876

Epoch: 6| Step: 2
Training loss: 3.3081564586130274
Validation loss: 3.0392321610874493

Epoch: 6| Step: 3
Training loss: 3.7227582086968694
Validation loss: 3.0349644174716723

Epoch: 6| Step: 4
Training loss: 3.6605736363203825
Validation loss: 3.035799211227764

Epoch: 6| Step: 5
Training loss: 3.3535119280519807
Validation loss: 3.030218209485366

Epoch: 6| Step: 6
Training loss: 3.5063983471065163
Validation loss: 3.0284921363425723

Epoch: 6| Step: 7
Training loss: 2.506165626228172
Validation loss: 3.0294476279959657

Epoch: 6| Step: 8
Training loss: 3.115087121813651
Validation loss: 3.030030952966155

Epoch: 6| Step: 9
Training loss: 3.4579598251930177
Validation loss: 3.029864032531704

Epoch: 6| Step: 10
Training loss: 3.3891796775951444
Validation loss: 3.028938004616044

Epoch: 6| Step: 11
Training loss: 3.1301683030872085
Validation loss: 3.0288209865659907

Epoch: 6| Step: 12
Training loss: 3.0150473243959484
Validation loss: 3.028104394257413

Epoch: 6| Step: 13
Training loss: 4.311252358232154
Validation loss: 3.0304950365548065

Epoch: 46| Step: 0
Training loss: 2.739112455757902
Validation loss: 3.028111114685157

Epoch: 6| Step: 1
Training loss: 3.338383155586827
Validation loss: 3.0292039813878584

Epoch: 6| Step: 2
Training loss: 3.483717783712914
Validation loss: 3.028072427574153

Epoch: 6| Step: 3
Training loss: 3.479486842851284
Validation loss: 3.0272322900890405

Epoch: 6| Step: 4
Training loss: 3.3232922635718047
Validation loss: 3.0277669559335663

Epoch: 6| Step: 5
Training loss: 3.635721858785163
Validation loss: 3.025561247635655

Epoch: 6| Step: 6
Training loss: 2.8116493634149595
Validation loss: 3.0264787876961883

Epoch: 6| Step: 7
Training loss: 3.3848869183132346
Validation loss: 3.0267920858842463

Epoch: 6| Step: 8
Training loss: 3.2883154956342198
Validation loss: 3.028827950863647

Epoch: 6| Step: 9
Training loss: 3.6254537890299474
Validation loss: 3.030053021968041

Epoch: 6| Step: 10
Training loss: 2.483588712050568
Validation loss: 3.030568797230391

Epoch: 6| Step: 11
Training loss: 4.037424489546407
Validation loss: 3.0282462693278913

Epoch: 6| Step: 12
Training loss: 3.2439906977321398
Validation loss: 3.0266870412628193

Epoch: 6| Step: 13
Training loss: 2.880714873229763
Validation loss: 3.0259085437730064

Epoch: 47| Step: 0
Training loss: 3.7090748820579087
Validation loss: 3.023437286323526

Epoch: 6| Step: 1
Training loss: 3.579955719615361
Validation loss: 3.022361045449841

Epoch: 6| Step: 2
Training loss: 3.4573277922778507
Validation loss: 3.019957522744336

Epoch: 6| Step: 3
Training loss: 3.138862988600499
Validation loss: 3.0198127852952283

Epoch: 6| Step: 4
Training loss: 3.269398530479059
Validation loss: 3.0202370660163664

Epoch: 6| Step: 5
Training loss: 2.900538585241137
Validation loss: 3.0206478555588663

Epoch: 6| Step: 6
Training loss: 2.7344054302157192
Validation loss: 3.0188200207888713

Epoch: 6| Step: 7
Training loss: 2.7237767194861524
Validation loss: 3.0188255373132873

Epoch: 6| Step: 8
Training loss: 3.286273707278563
Validation loss: 3.0183315459164612

Epoch: 6| Step: 9
Training loss: 3.265922861341105
Validation loss: 3.019363721088033

Epoch: 6| Step: 10
Training loss: 3.3311069364764037
Validation loss: 3.016207183624702

Epoch: 6| Step: 11
Training loss: 3.1086602851245337
Validation loss: 3.017842895136048

Epoch: 6| Step: 12
Training loss: 3.5479557222616105
Validation loss: 3.01649267002726

Epoch: 6| Step: 13
Training loss: 4.33175561989458
Validation loss: 3.0149132412875206

Epoch: 48| Step: 0
Training loss: 2.4585481215789504
Validation loss: 3.0154693884711534

Epoch: 6| Step: 1
Training loss: 3.626158562039617
Validation loss: 3.0147803801319655

Epoch: 6| Step: 2
Training loss: 2.8877210722346147
Validation loss: 3.01403042984339

Epoch: 6| Step: 3
Training loss: 3.7449782762292108
Validation loss: 3.0133735421295205

Epoch: 6| Step: 4
Training loss: 2.82417155921522
Validation loss: 3.014005887427584

Epoch: 6| Step: 5
Training loss: 3.0997762845439656
Validation loss: 3.0162223025878756

Epoch: 6| Step: 6
Training loss: 3.85012487233762
Validation loss: 3.0144806729456763

Epoch: 6| Step: 7
Training loss: 3.2278717562077843
Validation loss: 3.014082307297067

Epoch: 6| Step: 8
Training loss: 3.4870811183498653
Validation loss: 3.0144450859948058

Epoch: 6| Step: 9
Training loss: 2.56039714593691
Validation loss: 3.017063306026969

Epoch: 6| Step: 10
Training loss: 3.7034888752692594
Validation loss: 3.026469672357751

Epoch: 6| Step: 11
Training loss: 3.439131609626552
Validation loss: 3.0254965941774055

Epoch: 6| Step: 12
Training loss: 3.575115287362371
Validation loss: 3.0239597310563777

Epoch: 6| Step: 13
Training loss: 3.224225174435537
Validation loss: 3.0077412343675145

Epoch: 49| Step: 0
Training loss: 3.135346641054273
Validation loss: 3.0013096387965277

Epoch: 6| Step: 1
Training loss: 3.95786324102177
Validation loss: 2.999200116104329

Epoch: 6| Step: 2
Training loss: 3.613598354961974
Validation loss: 2.9859615430285

Epoch: 6| Step: 3
Training loss: 2.9932435564994355
Validation loss: 2.9823966633093657

Epoch: 6| Step: 4
Training loss: 2.2948094636697705
Validation loss: 2.9814527761193292

Epoch: 6| Step: 5
Training loss: 3.2436720057759674
Validation loss: 2.9823578009575873

Epoch: 6| Step: 6
Training loss: 2.24308838506976
Validation loss: 2.9860502340018127

Epoch: 6| Step: 7
Training loss: 3.169941881531521
Validation loss: 2.9844397059103103

Epoch: 6| Step: 8
Training loss: 3.5638706180708404
Validation loss: 2.9819099654248413

Epoch: 6| Step: 9
Training loss: 3.0178495908434706
Validation loss: 2.9749404397326003

Epoch: 6| Step: 10
Training loss: 3.4758597703134257
Validation loss: 2.9703143157981917

Epoch: 6| Step: 11
Training loss: 3.797526236990323
Validation loss: 2.9720048454678096

Epoch: 6| Step: 12
Training loss: 3.3875123252503663
Validation loss: 2.977992154927512

Epoch: 6| Step: 13
Training loss: 3.393555109037744
Validation loss: 2.984802079809753

Epoch: 50| Step: 0
Training loss: 3.4479024066610955
Validation loss: 2.990948938886478

Epoch: 6| Step: 1
Training loss: 3.6424927729611514
Validation loss: 2.984657757401881

Epoch: 6| Step: 2
Training loss: 2.655791568465616
Validation loss: 2.983001890473981

Epoch: 6| Step: 3
Training loss: 3.124417975584769
Validation loss: 2.9849884789118217

Epoch: 6| Step: 4
Training loss: 3.207423754147848
Validation loss: 2.9737798941380555

Epoch: 6| Step: 5
Training loss: 3.022435852834113
Validation loss: 2.9679416024322993

Epoch: 6| Step: 6
Training loss: 2.5404084848859574
Validation loss: 2.968675971066186

Epoch: 6| Step: 7
Training loss: 2.814252688744555
Validation loss: 2.963755355827838

Epoch: 6| Step: 8
Training loss: 2.990892573298106
Validation loss: 2.9639151701660404

Epoch: 6| Step: 9
Training loss: 3.9517962367389465
Validation loss: 2.962107434043678

Epoch: 6| Step: 10
Training loss: 3.5363357515209652
Validation loss: 2.9625298111527094

Epoch: 6| Step: 11
Training loss: 2.884750583121329
Validation loss: 2.9604418524232754

Epoch: 6| Step: 12
Training loss: 3.7603905730605818
Validation loss: 2.961657297302384

Epoch: 6| Step: 13
Training loss: 3.7999090936729294
Validation loss: 2.9613556713370714

Epoch: 51| Step: 0
Training loss: 3.4947786894707518
Validation loss: 2.9597748314017367

Epoch: 6| Step: 1
Training loss: 3.2161542184491316
Validation loss: 2.959234959635508

Epoch: 6| Step: 2
Training loss: 3.3294337032263743
Validation loss: 2.959523942518918

Epoch: 6| Step: 3
Training loss: 3.0630195332700456
Validation loss: 2.9553203557902576

Epoch: 6| Step: 4
Training loss: 3.1272285144777467
Validation loss: 2.958779916732539

Epoch: 6| Step: 5
Training loss: 3.5708195766568274
Validation loss: 2.959465793383252

Epoch: 6| Step: 6
Training loss: 2.8017725340814437
Validation loss: 2.9586066056700653

Epoch: 6| Step: 7
Training loss: 2.9586743082180194
Validation loss: 2.9586676917473493

Epoch: 6| Step: 8
Training loss: 2.7362713150999607
Validation loss: 2.957672224364241

Epoch: 6| Step: 9
Training loss: 3.835488100783581
Validation loss: 2.96282652140699

Epoch: 6| Step: 10
Training loss: 3.5457580420946115
Validation loss: 2.963219329024472

Epoch: 6| Step: 11
Training loss: 3.022690791694113
Validation loss: 2.960219303037301

Epoch: 6| Step: 12
Training loss: 3.416275529260087
Validation loss: 2.9598288342963115

Epoch: 6| Step: 13
Training loss: 3.0512937147110337
Validation loss: 2.9581664051435546

Epoch: 52| Step: 0
Training loss: 3.4781753742035235
Validation loss: 2.9546782447759052

Epoch: 6| Step: 1
Training loss: 3.648846687063039
Validation loss: 2.953973839457358

Epoch: 6| Step: 2
Training loss: 2.490411969004347
Validation loss: 2.9533697650707427

Epoch: 6| Step: 3
Training loss: 4.120347607216759
Validation loss: 2.9525108925085677

Epoch: 6| Step: 4
Training loss: 3.394063445451916
Validation loss: 2.9529417594976852

Epoch: 6| Step: 5
Training loss: 2.728864337589454
Validation loss: 2.9508595069096333

Epoch: 6| Step: 6
Training loss: 3.1221518698293345
Validation loss: 2.9499200645672286

Epoch: 6| Step: 7
Training loss: 2.9567171078593573
Validation loss: 2.9504897910796357

Epoch: 6| Step: 8
Training loss: 3.275567793220125
Validation loss: 2.9514244084851846

Epoch: 6| Step: 9
Training loss: 3.04867359774155
Validation loss: 2.950603896256722

Epoch: 6| Step: 10
Training loss: 3.456638671653731
Validation loss: 2.949918654091807

Epoch: 6| Step: 11
Training loss: 3.515191759329553
Validation loss: 2.9506335370231778

Epoch: 6| Step: 12
Training loss: 2.802075713382462
Validation loss: 2.9492745907935416

Epoch: 6| Step: 13
Training loss: 2.6485819819377245
Validation loss: 2.9486218150478294

Epoch: 53| Step: 0
Training loss: 2.7200708797980777
Validation loss: 2.948898893311126

Epoch: 6| Step: 1
Training loss: 3.682770621927919
Validation loss: 2.946838422316049

Epoch: 6| Step: 2
Training loss: 4.0582191801107
Validation loss: 2.947603640794823

Epoch: 6| Step: 3
Training loss: 2.9976616329237245
Validation loss: 2.9491370192162827

Epoch: 6| Step: 4
Training loss: 3.353232938908081
Validation loss: 2.9476238542885547

Epoch: 6| Step: 5
Training loss: 3.779010203920848
Validation loss: 2.9463457802012134

Epoch: 6| Step: 6
Training loss: 2.916072857672607
Validation loss: 2.9464041708667588

Epoch: 6| Step: 7
Training loss: 2.904533946065643
Validation loss: 2.9437929173522734

Epoch: 6| Step: 8
Training loss: 2.7793272422906177
Validation loss: 2.9437022591072446

Epoch: 6| Step: 9
Training loss: 2.7674269328684846
Validation loss: 2.944907329325636

Epoch: 6| Step: 10
Training loss: 3.5930924850694015
Validation loss: 2.9433955627272796

Epoch: 6| Step: 11
Training loss: 3.036155428208629
Validation loss: 2.944227796006061

Epoch: 6| Step: 12
Training loss: 3.3659815919024823
Validation loss: 2.943603495049535

Epoch: 6| Step: 13
Training loss: 2.7185230379628145
Validation loss: 2.9415685230908544

Epoch: 54| Step: 0
Training loss: 3.347171922009427
Validation loss: 2.9553896668312167

Epoch: 6| Step: 1
Training loss: 2.036584042102578
Validation loss: 2.9919222880164975

Epoch: 6| Step: 2
Training loss: 3.561319255911957
Validation loss: 2.990047865656754

Epoch: 6| Step: 3
Training loss: 3.1096485726855807
Validation loss: 2.977508435095358

Epoch: 6| Step: 4
Training loss: 3.5372908243941117
Validation loss: 2.9603933441000163

Epoch: 6| Step: 5
Training loss: 3.4500463233823235
Validation loss: 2.95264577419825

Epoch: 6| Step: 6
Training loss: 2.527521094772798
Validation loss: 2.944686708272707

Epoch: 6| Step: 7
Training loss: 3.353949134991445
Validation loss: 2.944508721598167

Epoch: 6| Step: 8
Training loss: 3.3519844554276665
Validation loss: 2.9413846193030384

Epoch: 6| Step: 9
Training loss: 3.3756843155704996
Validation loss: 2.941089218602

Epoch: 6| Step: 10
Training loss: 3.3548125756750875
Validation loss: 2.9433355410954576

Epoch: 6| Step: 11
Training loss: 3.6417376082877233
Validation loss: 2.9418100763132076

Epoch: 6| Step: 12
Training loss: 3.2436152612121796
Validation loss: 2.9435634246579165

Epoch: 6| Step: 13
Training loss: 2.8608731373537393
Validation loss: 2.9422725673187027

Epoch: 55| Step: 0
Training loss: 2.745035545521988
Validation loss: 2.942355234601801

Epoch: 6| Step: 1
Training loss: 3.4254766870389393
Validation loss: 2.9425261172194994

Epoch: 6| Step: 2
Training loss: 3.1193823102690748
Validation loss: 2.9417876973899526

Epoch: 6| Step: 3
Training loss: 2.293360610049329
Validation loss: 2.9401359556750237

Epoch: 6| Step: 4
Training loss: 3.6252712279828705
Validation loss: 2.939672211090025

Epoch: 6| Step: 5
Training loss: 2.7726993061935
Validation loss: 2.941447361656607

Epoch: 6| Step: 6
Training loss: 3.813496443810211
Validation loss: 2.941356252849395

Epoch: 6| Step: 7
Training loss: 3.3457005595984035
Validation loss: 2.941602276930472

Epoch: 6| Step: 8
Training loss: 3.6135844995213082
Validation loss: 2.9396451327620228

Epoch: 6| Step: 9
Training loss: 2.399453311485815
Validation loss: 2.939616086726537

Epoch: 6| Step: 10
Training loss: 3.451138991159833
Validation loss: 2.9393760748729756

Epoch: 6| Step: 11
Training loss: 3.1484078152679387
Validation loss: 2.9374471348543945

Epoch: 6| Step: 12
Training loss: 3.140279722449816
Validation loss: 2.9368077241091695

Epoch: 6| Step: 13
Training loss: 4.2037185193169675
Validation loss: 2.939141532439518

Epoch: 56| Step: 0
Training loss: 3.5752930741123725
Validation loss: 2.9391565305904304

Epoch: 6| Step: 1
Training loss: 2.489188275987863
Validation loss: 2.9395813472702694

Epoch: 6| Step: 2
Training loss: 3.728502580271183
Validation loss: 2.944923508147244

Epoch: 6| Step: 3
Training loss: 3.416205739510296
Validation loss: 2.9479775232074394

Epoch: 6| Step: 4
Training loss: 2.9692038741248745
Validation loss: 2.951306537313298

Epoch: 6| Step: 5
Training loss: 3.5989754543458456
Validation loss: 2.949954911699622

Epoch: 6| Step: 6
Training loss: 2.435183084173012
Validation loss: 2.942880874411975

Epoch: 6| Step: 7
Training loss: 3.4018132423571497
Validation loss: 2.9341910058088807

Epoch: 6| Step: 8
Training loss: 3.657335299618487
Validation loss: 2.9311399919214653

Epoch: 6| Step: 9
Training loss: 3.0814872232543946
Validation loss: 2.9307299070274

Epoch: 6| Step: 10
Training loss: 3.32379986895235
Validation loss: 2.931524011703282

Epoch: 6| Step: 11
Training loss: 3.376105092288634
Validation loss: 2.931095469805709

Epoch: 6| Step: 12
Training loss: 2.9832652959755146
Validation loss: 2.930295036518196

Epoch: 6| Step: 13
Training loss: 2.2119489856514574
Validation loss: 2.9317852627676775

Epoch: 57| Step: 0
Training loss: 2.627494081296343
Validation loss: 2.93062405487638

Epoch: 6| Step: 1
Training loss: 2.098860922194544
Validation loss: 2.930884076736719

Epoch: 6| Step: 2
Training loss: 3.0621449790234614
Validation loss: 2.933498822948167

Epoch: 6| Step: 3
Training loss: 2.3724670957769747
Validation loss: 2.9302213930251395

Epoch: 6| Step: 4
Training loss: 4.025970787355473
Validation loss: 2.9336216479577524

Epoch: 6| Step: 5
Training loss: 3.552351299183066
Validation loss: 2.9313791905077218

Epoch: 6| Step: 6
Training loss: 3.8622911069609533
Validation loss: 2.930439230673372

Epoch: 6| Step: 7
Training loss: 3.2740073060902035
Validation loss: 2.9279852350448734

Epoch: 6| Step: 8
Training loss: 3.5484498682650614
Validation loss: 2.9281097858581036

Epoch: 6| Step: 9
Training loss: 2.8976858969061685
Validation loss: 2.930532955125363

Epoch: 6| Step: 10
Training loss: 3.138520251957639
Validation loss: 2.929435234994912

Epoch: 6| Step: 11
Training loss: 3.7153405981407506
Validation loss: 2.937679874356178

Epoch: 6| Step: 12
Training loss: 2.9366531774735716
Validation loss: 2.9300813616088353

Epoch: 6| Step: 13
Training loss: 3.429015074137486
Validation loss: 2.9281834912129034

Epoch: 58| Step: 0
Training loss: 3.073982045465576
Validation loss: 2.925046611926694

Epoch: 6| Step: 1
Training loss: 2.7875443288246293
Validation loss: 2.9243853510544935

Epoch: 6| Step: 2
Training loss: 2.8257059953670725
Validation loss: 2.92438995605419

Epoch: 6| Step: 3
Training loss: 3.153220053715459
Validation loss: 2.9231927495222774

Epoch: 6| Step: 4
Training loss: 3.107590052802862
Validation loss: 2.9242391900491804

Epoch: 6| Step: 5
Training loss: 3.3973346192204286
Validation loss: 2.9223919614535796

Epoch: 6| Step: 6
Training loss: 3.021533613044187
Validation loss: 2.922602517032499

Epoch: 6| Step: 7
Training loss: 4.0851781661028825
Validation loss: 2.9230755273247606

Epoch: 6| Step: 8
Training loss: 3.142935287445374
Validation loss: 2.923580449110071

Epoch: 6| Step: 9
Training loss: 4.212235004907996
Validation loss: 2.92375852477736

Epoch: 6| Step: 10
Training loss: 2.0885202941054657
Validation loss: 2.9211486998173113

Epoch: 6| Step: 11
Training loss: 3.261643752646393
Validation loss: 2.920043364194558

Epoch: 6| Step: 12
Training loss: 3.3139271091141222
Validation loss: 2.9186029666511213

Epoch: 6| Step: 13
Training loss: 2.7753980127782567
Validation loss: 2.9186907171878045

Epoch: 59| Step: 0
Training loss: 3.8820497926548247
Validation loss: 2.91877029488129

Epoch: 6| Step: 1
Training loss: 2.3457064791360804
Validation loss: 2.917293880779357

Epoch: 6| Step: 2
Training loss: 3.288024303559933
Validation loss: 2.919341806264698

Epoch: 6| Step: 3
Training loss: 3.3331846362962123
Validation loss: 2.917244038076615

Epoch: 6| Step: 4
Training loss: 2.2304758048405287
Validation loss: 2.924517838548728

Epoch: 6| Step: 5
Training loss: 3.1323123066438536
Validation loss: 2.934881837450811

Epoch: 6| Step: 6
Training loss: 3.687780078661055
Validation loss: 2.950671890160452

Epoch: 6| Step: 7
Training loss: 3.0591338985152987
Validation loss: 2.971043378031442

Epoch: 6| Step: 8
Training loss: 2.9349857690001495
Validation loss: 2.981110369368252

Epoch: 6| Step: 9
Training loss: 3.670612783803021
Validation loss: 2.9682207094471655

Epoch: 6| Step: 10
Training loss: 3.521934171651742
Validation loss: 2.9409069620271326

Epoch: 6| Step: 11
Training loss: 3.4511664864930345
Validation loss: 2.9164692268404213

Epoch: 6| Step: 12
Training loss: 3.239353494780702
Validation loss: 2.913081662248389

Epoch: 6| Step: 13
Training loss: 2.3449450688547153
Validation loss: 2.913261118855251

Epoch: 60| Step: 0
Training loss: 2.997263932274219
Validation loss: 2.916452164973342

Epoch: 6| Step: 1
Training loss: 2.719919939545843
Validation loss: 2.9208733082761174

Epoch: 6| Step: 2
Training loss: 2.928014496272322
Validation loss: 2.9321989508413178

Epoch: 6| Step: 3
Training loss: 2.396957686488827
Validation loss: 2.941352842337114

Epoch: 6| Step: 4
Training loss: 3.3191991757093735
Validation loss: 2.9275835605547824

Epoch: 6| Step: 5
Training loss: 3.303380685255817
Validation loss: 2.9208295824196715

Epoch: 6| Step: 6
Training loss: 3.5890878705534237
Validation loss: 2.914605201191678

Epoch: 6| Step: 7
Training loss: 3.8592719554658386
Validation loss: 2.9153143641050665

Epoch: 6| Step: 8
Training loss: 3.401785628465752
Validation loss: 2.919158692479374

Epoch: 6| Step: 9
Training loss: 3.1556988225421243
Validation loss: 2.9285594056259865

Epoch: 6| Step: 10
Training loss: 3.0338923941674674
Validation loss: 2.9272939563677265

Epoch: 6| Step: 11
Training loss: 2.9934404503815455
Validation loss: 2.9217919305014495

Epoch: 6| Step: 12
Training loss: 3.6897216828375767
Validation loss: 2.929721371471985

Epoch: 6| Step: 13
Training loss: 3.299014152309176
Validation loss: 2.948939533648739

Epoch: 61| Step: 0
Training loss: 3.536405327932959
Validation loss: 2.961713769170576

Epoch: 6| Step: 1
Training loss: 3.421057198401735
Validation loss: 2.9468451314636983

Epoch: 6| Step: 2
Training loss: 3.1163751217618416
Validation loss: 2.9273096921878445

Epoch: 6| Step: 3
Training loss: 2.738556721499505
Validation loss: 2.9150092752655574

Epoch: 6| Step: 4
Training loss: 2.7903872637495244
Validation loss: 2.908014935443619

Epoch: 6| Step: 5
Training loss: 2.543685038718904
Validation loss: 2.9064269164724235

Epoch: 6| Step: 6
Training loss: 3.306096058598667
Validation loss: 2.9089876958162497

Epoch: 6| Step: 7
Training loss: 3.6067890630415134
Validation loss: 2.910952685704822

Epoch: 6| Step: 8
Training loss: 3.5875958366751823
Validation loss: 2.9221227414829882

Epoch: 6| Step: 9
Training loss: 3.4354402786902387
Validation loss: 2.9269209117374753

Epoch: 6| Step: 10
Training loss: 3.7274661458024037
Validation loss: 2.907188778176895

Epoch: 6| Step: 11
Training loss: 3.1418166295964487
Validation loss: 2.9035825525568555

Epoch: 6| Step: 12
Training loss: 2.9076354303413567
Validation loss: 2.9020042690697068

Epoch: 6| Step: 13
Training loss: 2.197996080841097
Validation loss: 2.901845451748868

Epoch: 62| Step: 0
Training loss: 3.208478222502447
Validation loss: 2.9005668417836694

Epoch: 6| Step: 1
Training loss: 2.7781545150441955
Validation loss: 2.9003877576433545

Epoch: 6| Step: 2
Training loss: 2.7187271994149884
Validation loss: 2.8992981257245316

Epoch: 6| Step: 3
Training loss: 3.976452899014529
Validation loss: 2.900410417992149

Epoch: 6| Step: 4
Training loss: 3.033463761037268
Validation loss: 2.8972580306554185

Epoch: 6| Step: 5
Training loss: 3.5050789902257793
Validation loss: 2.8985294537189557

Epoch: 6| Step: 6
Training loss: 3.136037940301854
Validation loss: 2.8958066819715147

Epoch: 6| Step: 7
Training loss: 3.203150604890039
Validation loss: 2.8981173940313543

Epoch: 6| Step: 8
Training loss: 3.4280226018420934
Validation loss: 2.898293230690653

Epoch: 6| Step: 9
Training loss: 3.6164248097030636
Validation loss: 2.8972707193858738

Epoch: 6| Step: 10
Training loss: 3.5742886562494305
Validation loss: 2.900261108516331

Epoch: 6| Step: 11
Training loss: 2.8969136882614106
Validation loss: 2.8975649195389

Epoch: 6| Step: 12
Training loss: 2.2234562136518674
Validation loss: 2.89672576622207

Epoch: 6| Step: 13
Training loss: 2.8291789246089
Validation loss: 2.895609079352002

Epoch: 63| Step: 0
Training loss: 3.619613723589246
Validation loss: 2.8955688060647593

Epoch: 6| Step: 1
Training loss: 3.2559188352211503
Validation loss: 2.9041203195817755

Epoch: 6| Step: 2
Training loss: 3.702113146099265
Validation loss: 2.9066868371151697

Epoch: 6| Step: 3
Training loss: 4.13814185197421
Validation loss: 2.8948980080826807

Epoch: 6| Step: 4
Training loss: 3.4913662279711337
Validation loss: 2.889721135729651

Epoch: 6| Step: 5
Training loss: 2.57571974019364
Validation loss: 2.8886603909764763

Epoch: 6| Step: 6
Training loss: 2.142006866607915
Validation loss: 2.8909228135168714

Epoch: 6| Step: 7
Training loss: 2.7438367790801905
Validation loss: 2.890495159466884

Epoch: 6| Step: 8
Training loss: 3.043343556426288
Validation loss: 2.8924117606069752

Epoch: 6| Step: 9
Training loss: 3.21086384115635
Validation loss: 2.895672211525093

Epoch: 6| Step: 10
Training loss: 3.5503936656763027
Validation loss: 2.895528833246264

Epoch: 6| Step: 11
Training loss: 2.6695877904265815
Validation loss: 2.8932372063802094

Epoch: 6| Step: 12
Training loss: 2.7661421125345425
Validation loss: 2.88765508598115

Epoch: 6| Step: 13
Training loss: 3.302514915461504
Validation loss: 2.888518134396252

Epoch: 64| Step: 0
Training loss: 3.276915966754996
Validation loss: 2.8877891263309903

Epoch: 6| Step: 1
Training loss: 2.8013600452329124
Validation loss: 2.8876010881164555

Epoch: 6| Step: 2
Training loss: 3.140990278722663
Validation loss: 2.890284561290895

Epoch: 6| Step: 3
Training loss: 3.8709281939875626
Validation loss: 2.8920386017716133

Epoch: 6| Step: 4
Training loss: 2.7038349255730343
Validation loss: 2.904786027775642

Epoch: 6| Step: 5
Training loss: 2.964404811206558
Validation loss: 2.902883308784526

Epoch: 6| Step: 6
Training loss: 2.289714212700416
Validation loss: 2.9174967631992272

Epoch: 6| Step: 7
Training loss: 4.5031892283489885
Validation loss: 2.9154239702664295

Epoch: 6| Step: 8
Training loss: 2.6413232004445315
Validation loss: 2.9001369166063395

Epoch: 6| Step: 9
Training loss: 3.2442855481062955
Validation loss: 2.889815020413073

Epoch: 6| Step: 10
Training loss: 3.353013371496391
Validation loss: 2.885727845429719

Epoch: 6| Step: 11
Training loss: 2.433321476824716
Validation loss: 2.887667721914544

Epoch: 6| Step: 12
Training loss: 3.5267783690888277
Validation loss: 2.8859353836262964

Epoch: 6| Step: 13
Training loss: 3.097970568956097
Validation loss: 2.886695175788435

Epoch: 65| Step: 0
Training loss: 3.154878979521599
Validation loss: 2.885439597702436

Epoch: 6| Step: 1
Training loss: 2.971927428159145
Validation loss: 2.890325268318975

Epoch: 6| Step: 2
Training loss: 3.8560729939844918
Validation loss: 2.8888571874579294

Epoch: 6| Step: 3
Training loss: 2.953113051294445
Validation loss: 2.8870221558762954

Epoch: 6| Step: 4
Training loss: 3.3054870648238475
Validation loss: 2.8816803038014585

Epoch: 6| Step: 5
Training loss: 2.8632089728045074
Validation loss: 2.882271787401874

Epoch: 6| Step: 6
Training loss: 3.6384767407335294
Validation loss: 2.8808335254330526

Epoch: 6| Step: 7
Training loss: 2.979586289381729
Validation loss: 2.8816607887250205

Epoch: 6| Step: 8
Training loss: 3.027158354958269
Validation loss: 2.880073518543901

Epoch: 6| Step: 9
Training loss: 3.0013558185039604
Validation loss: 2.8799820793498982

Epoch: 6| Step: 10
Training loss: 2.7108223750489744
Validation loss: 2.881616261010548

Epoch: 6| Step: 11
Training loss: 3.6070973529670276
Validation loss: 2.8820880920479697

Epoch: 6| Step: 12
Training loss: 3.3543415063501127
Validation loss: 2.8806766931098116

Epoch: 6| Step: 13
Training loss: 2.7579732961489145
Validation loss: 2.8814638388345637

Epoch: 66| Step: 0
Training loss: 3.425342631778691
Validation loss: 2.8816737845564884

Epoch: 6| Step: 1
Training loss: 3.653636813634106
Validation loss: 2.888911734221941

Epoch: 6| Step: 2
Training loss: 3.60424810475566
Validation loss: 2.87785283060485

Epoch: 6| Step: 3
Training loss: 3.149131982280401
Validation loss: 2.8778296265063714

Epoch: 6| Step: 4
Training loss: 2.3194432540961567
Validation loss: 2.8758954369787864

Epoch: 6| Step: 5
Training loss: 2.879633445460099
Validation loss: 2.8755396692681705

Epoch: 6| Step: 6
Training loss: 3.1438318078865635
Validation loss: 2.8739550378131278

Epoch: 6| Step: 7
Training loss: 2.835401079712871
Validation loss: 2.8740818961769294

Epoch: 6| Step: 8
Training loss: 3.3361367516790015
Validation loss: 2.874845209007485

Epoch: 6| Step: 9
Training loss: 3.4831012399062597
Validation loss: 2.874752602938629

Epoch: 6| Step: 10
Training loss: 3.4001017386978427
Validation loss: 2.876226930678141

Epoch: 6| Step: 11
Training loss: 3.040399330915376
Validation loss: 2.874214400309522

Epoch: 6| Step: 12
Training loss: 3.1601057013204583
Validation loss: 2.8761294813795297

Epoch: 6| Step: 13
Training loss: 2.376376004397478
Validation loss: 2.8765909190144696

Epoch: 67| Step: 0
Training loss: 3.7415072593348357
Validation loss: 2.8751735625949326

Epoch: 6| Step: 1
Training loss: 2.4135295193141073
Validation loss: 2.877957204865908

Epoch: 6| Step: 2
Training loss: 3.4386514295832318
Validation loss: 2.888013388640786

Epoch: 6| Step: 3
Training loss: 2.6155751286244873
Validation loss: 2.8806810520517097

Epoch: 6| Step: 4
Training loss: 3.7163144638983496
Validation loss: 2.8798141531673602

Epoch: 6| Step: 5
Training loss: 2.8684790921751713
Validation loss: 2.8751819904325036

Epoch: 6| Step: 6
Training loss: 3.2073384183173217
Validation loss: 2.870895289368363

Epoch: 6| Step: 7
Training loss: 3.123600150334534
Validation loss: 2.8714997490654905

Epoch: 6| Step: 8
Training loss: 3.4794561452227444
Validation loss: 2.8711878169794054

Epoch: 6| Step: 9
Training loss: 2.4901168017587785
Validation loss: 2.8712586736757224

Epoch: 6| Step: 10
Training loss: 2.636341932709665
Validation loss: 2.869670967145664

Epoch: 6| Step: 11
Training loss: 3.0941673536751093
Validation loss: 2.8688982745866665

Epoch: 6| Step: 12
Training loss: 3.2192466871122054
Validation loss: 2.8673606467766666

Epoch: 6| Step: 13
Training loss: 4.3353963978244865
Validation loss: 2.8672774454646466

Epoch: 68| Step: 0
Training loss: 2.8693187806328835
Validation loss: 2.8678071944267027

Epoch: 6| Step: 1
Training loss: 3.248623776656931
Validation loss: 2.868324642848095

Epoch: 6| Step: 2
Training loss: 3.531053385704514
Validation loss: 2.8674940050652538

Epoch: 6| Step: 3
Training loss: 3.517458560485318
Validation loss: 2.8644934673513673

Epoch: 6| Step: 4
Training loss: 3.48756078304796
Validation loss: 2.8667870176721197

Epoch: 6| Step: 5
Training loss: 3.5214323779439014
Validation loss: 2.864146192799715

Epoch: 6| Step: 6
Training loss: 2.9601001209647038
Validation loss: 2.8665611108384796

Epoch: 6| Step: 7
Training loss: 2.889031543225422
Validation loss: 2.8666266078563467

Epoch: 6| Step: 8
Training loss: 3.6806163870784694
Validation loss: 2.8666978321637338

Epoch: 6| Step: 9
Training loss: 3.3201548101341354
Validation loss: 2.8642067461273895

Epoch: 6| Step: 10
Training loss: 2.6601376973988233
Validation loss: 2.8621892037518757

Epoch: 6| Step: 11
Training loss: 2.809411366262341
Validation loss: 2.863946130010365

Epoch: 6| Step: 12
Training loss: 3.1118899195601313
Validation loss: 2.864158645128818

Epoch: 6| Step: 13
Training loss: 1.5075705536737574
Validation loss: 2.864676567342816

Epoch: 69| Step: 0
Training loss: 2.7520464305343126
Validation loss: 2.863070050488546

Epoch: 6| Step: 1
Training loss: 3.1721597177286447
Validation loss: 2.864252077043657

Epoch: 6| Step: 2
Training loss: 3.27667804272353
Validation loss: 2.8661336715476677

Epoch: 6| Step: 3
Training loss: 2.761494715127303
Validation loss: 2.8640012165658666

Epoch: 6| Step: 4
Training loss: 3.792039845864881
Validation loss: 2.8629787738404286

Epoch: 6| Step: 5
Training loss: 3.046857158902092
Validation loss: 2.863965872315831

Epoch: 6| Step: 6
Training loss: 3.557364660866707
Validation loss: 2.859262685790647

Epoch: 6| Step: 7
Training loss: 3.211785346073571
Validation loss: 2.858647341380659

Epoch: 6| Step: 8
Training loss: 2.8672764735747975
Validation loss: 2.8596091423101124

Epoch: 6| Step: 9
Training loss: 2.688020700091175
Validation loss: 2.8573964252913844

Epoch: 6| Step: 10
Training loss: 2.664072254867817
Validation loss: 2.8582220713527273

Epoch: 6| Step: 11
Training loss: 3.3899165525265165
Validation loss: 2.8569305674694307

Epoch: 6| Step: 12
Training loss: 3.452347197469426
Validation loss: 2.8566139267765704

Epoch: 6| Step: 13
Training loss: 3.4945991262201326
Validation loss: 2.8561538887274227

Epoch: 70| Step: 0
Training loss: 3.1373261544139655
Validation loss: 2.8647298742196425

Epoch: 6| Step: 1
Training loss: 3.310961095951786
Validation loss: 2.859511247277267

Epoch: 6| Step: 2
Training loss: 3.4687634716975166
Validation loss: 2.859167206994729

Epoch: 6| Step: 3
Training loss: 3.094297264323122
Validation loss: 2.857808908548303

Epoch: 6| Step: 4
Training loss: 3.0713868724489046
Validation loss: 2.855515469348633

Epoch: 6| Step: 5
Training loss: 2.2994866088424186
Validation loss: 2.8549468756507506

Epoch: 6| Step: 6
Training loss: 3.3309939917696587
Validation loss: 2.8566312724512177

Epoch: 6| Step: 7
Training loss: 2.6754989586494657
Validation loss: 2.8599355188477382

Epoch: 6| Step: 8
Training loss: 4.128743640364652
Validation loss: 2.8587236420696227

Epoch: 6| Step: 9
Training loss: 3.123361386797734
Validation loss: 2.859679571407872

Epoch: 6| Step: 10
Training loss: 2.936024396665072
Validation loss: 2.85643856782961

Epoch: 6| Step: 11
Training loss: 2.9258410622119726
Validation loss: 2.857961352622621

Epoch: 6| Step: 12
Training loss: 3.2616690443443193
Validation loss: 2.8555540936189923

Epoch: 6| Step: 13
Training loss: 3.0156657952430064
Validation loss: 2.855113776311743

Epoch: 71| Step: 0
Training loss: 3.229483180787637
Validation loss: 2.8514019336409406

Epoch: 6| Step: 1
Training loss: 3.4797135035652764
Validation loss: 2.8532736572639434

Epoch: 6| Step: 2
Training loss: 2.0133694589081172
Validation loss: 2.8519975039091747

Epoch: 6| Step: 3
Training loss: 2.912168976796172
Validation loss: 2.8515255082658957

Epoch: 6| Step: 4
Training loss: 3.760347839458241
Validation loss: 2.8495067819831825

Epoch: 6| Step: 5
Training loss: 3.3656316645564237
Validation loss: 2.8536122245165902

Epoch: 6| Step: 6
Training loss: 2.733957313243425
Validation loss: 2.853010575063777

Epoch: 6| Step: 7
Training loss: 3.2952561584836486
Validation loss: 2.849807256136952

Epoch: 6| Step: 8
Training loss: 2.675703818878518
Validation loss: 2.848253470713664

Epoch: 6| Step: 9
Training loss: 3.9386299570689176
Validation loss: 2.8497981262456475

Epoch: 6| Step: 10
Training loss: 3.0881077342041934
Validation loss: 2.84827494101252

Epoch: 6| Step: 11
Training loss: 2.304058234737147
Validation loss: 2.850336004073321

Epoch: 6| Step: 12
Training loss: 3.4247172496501475
Validation loss: 2.8468851474377463

Epoch: 6| Step: 13
Training loss: 3.497677168486419
Validation loss: 2.847910849306657

Epoch: 72| Step: 0
Training loss: 3.2039594354240464
Validation loss: 2.849429395066603

Epoch: 6| Step: 1
Training loss: 3.376693583234006
Validation loss: 2.8488449221382117

Epoch: 6| Step: 2
Training loss: 3.191185559564616
Validation loss: 2.8477055173874457

Epoch: 6| Step: 3
Training loss: 3.8309995485373727
Validation loss: 2.8502992356695303

Epoch: 6| Step: 4
Training loss: 3.079334621640872
Validation loss: 2.8505076994047682

Epoch: 6| Step: 5
Training loss: 3.4015492892414
Validation loss: 2.8562926232625876

Epoch: 6| Step: 6
Training loss: 3.1594783777365474
Validation loss: 2.8487485272316975

Epoch: 6| Step: 7
Training loss: 2.189472399175031
Validation loss: 2.847584278434992

Epoch: 6| Step: 8
Training loss: 2.6209934175620444
Validation loss: 2.847502403436525

Epoch: 6| Step: 9
Training loss: 3.533216350946086
Validation loss: 2.8451631125577608

Epoch: 6| Step: 10
Training loss: 2.9849490267748036
Validation loss: 2.848601389506577

Epoch: 6| Step: 11
Training loss: 3.275508980839028
Validation loss: 2.8447967860040246

Epoch: 6| Step: 12
Training loss: 2.848990171116283
Validation loss: 2.8418180891651272

Epoch: 6| Step: 13
Training loss: 2.9968326060426094
Validation loss: 2.8446879642477887

Epoch: 73| Step: 0
Training loss: 2.842570636713718
Validation loss: 2.844455722477427

Epoch: 6| Step: 1
Training loss: 3.0165813293470047
Validation loss: 2.8456362535996376

Epoch: 6| Step: 2
Training loss: 2.9766429179384426
Validation loss: 2.84760513438715

Epoch: 6| Step: 3
Training loss: 2.9931779223272095
Validation loss: 2.8440197682925126

Epoch: 6| Step: 4
Training loss: 2.5968163989784996
Validation loss: 2.8478867238527696

Epoch: 6| Step: 5
Training loss: 3.1495377579875523
Validation loss: 2.8448322674815665

Epoch: 6| Step: 6
Training loss: 2.843487905643957
Validation loss: 2.853483208213485

Epoch: 6| Step: 7
Training loss: 3.6015546885507073
Validation loss: 2.847192513582425

Epoch: 6| Step: 8
Training loss: 3.6272282822137765
Validation loss: 2.8475806457781325

Epoch: 6| Step: 9
Training loss: 2.863958135639862
Validation loss: 2.8452712457839056

Epoch: 6| Step: 10
Training loss: 3.3203158030774014
Validation loss: 2.8438406497895565

Epoch: 6| Step: 11
Training loss: 3.6362232235328817
Validation loss: 2.8423569043746055

Epoch: 6| Step: 12
Training loss: 2.5947091041353763
Validation loss: 2.843531210153577

Epoch: 6| Step: 13
Training loss: 4.0070071833455465
Validation loss: 2.8399158617636107

Epoch: 74| Step: 0
Training loss: 2.782523217391414
Validation loss: 2.842952740469887

Epoch: 6| Step: 1
Training loss: 3.428332502123618
Validation loss: 2.8475980671840047

Epoch: 6| Step: 2
Training loss: 2.6496697993856455
Validation loss: 2.8556718925318014

Epoch: 6| Step: 3
Training loss: 3.4704346561015247
Validation loss: 2.867817514917543

Epoch: 6| Step: 4
Training loss: 3.730681951531962
Validation loss: 2.8761994426616946

Epoch: 6| Step: 5
Training loss: 3.5408819039750465
Validation loss: 2.8781668274086645

Epoch: 6| Step: 6
Training loss: 2.7963304895336596
Validation loss: 2.8601448129640934

Epoch: 6| Step: 7
Training loss: 3.387945988986836
Validation loss: 2.836408655016147

Epoch: 6| Step: 8
Training loss: 3.0082852078830182
Validation loss: 2.835979119093786

Epoch: 6| Step: 9
Training loss: 3.118926287544127
Validation loss: 2.838179050000827

Epoch: 6| Step: 10
Training loss: 2.692763740564701
Validation loss: 2.840282292522944

Epoch: 6| Step: 11
Training loss: 3.648351762242052
Validation loss: 2.8415033786901533

Epoch: 6| Step: 12
Training loss: 2.7613356781873906
Validation loss: 2.844904113121953

Epoch: 6| Step: 13
Training loss: 2.3034860356451814
Validation loss: 2.847215277657259

Epoch: 75| Step: 0
Training loss: 3.0353783878451566
Validation loss: 2.858876351223104

Epoch: 6| Step: 1
Training loss: 3.548069958484169
Validation loss: 2.85249342860848

Epoch: 6| Step: 2
Training loss: 2.2877032830636783
Validation loss: 2.8471450975965515

Epoch: 6| Step: 3
Training loss: 2.7940472847904303
Validation loss: 2.844154468878688

Epoch: 6| Step: 4
Training loss: 3.316070072312602
Validation loss: 2.8446193007810714

Epoch: 6| Step: 5
Training loss: 3.4221482537960672
Validation loss: 2.84357492871928

Epoch: 6| Step: 6
Training loss: 3.7438767349622766
Validation loss: 2.8408738973680596

Epoch: 6| Step: 7
Training loss: 3.575171972019892
Validation loss: 2.838474522082779

Epoch: 6| Step: 8
Training loss: 3.2400480634162006
Validation loss: 2.8380831699345603

Epoch: 6| Step: 9
Training loss: 2.895317104807371
Validation loss: 2.839918540124009

Epoch: 6| Step: 10
Training loss: 3.153567845802759
Validation loss: 2.838335786420174

Epoch: 6| Step: 11
Training loss: 2.509033761391425
Validation loss: 2.8428583407127324

Epoch: 6| Step: 12
Training loss: 2.9719211707153823
Validation loss: 2.843959882190211

Epoch: 6| Step: 13
Training loss: 3.203058158363181
Validation loss: 2.847437591037361

Testing loss: 3.0506621748506606
