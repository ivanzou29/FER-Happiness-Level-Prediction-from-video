Epoch: 1| Step: 0
Training loss: 5.054211616516113
Validation loss: 5.1506435691669425

Epoch: 5| Step: 1
Training loss: 5.05513334274292
Validation loss: 5.142630777051372

Epoch: 5| Step: 2
Training loss: 4.323124885559082
Validation loss: 5.135925513441845

Epoch: 5| Step: 3
Training loss: 5.313449859619141
Validation loss: 5.129608077387656

Epoch: 5| Step: 4
Training loss: 4.098897457122803
Validation loss: 5.123303854337302

Epoch: 5| Step: 5
Training loss: 5.151425361633301
Validation loss: 5.1167897767918085

Epoch: 5| Step: 6
Training loss: 5.624289512634277
Validation loss: 5.109919204506823

Epoch: 5| Step: 7
Training loss: 4.494382381439209
Validation loss: 5.102605306974021

Epoch: 5| Step: 8
Training loss: 5.048699378967285
Validation loss: 5.094897172784292

Epoch: 5| Step: 9
Training loss: 4.327645301818848
Validation loss: 5.086218336577057

Epoch: 5| Step: 10
Training loss: 5.659608840942383
Validation loss: 5.076927882368847

Epoch: 2| Step: 0
Training loss: 4.804863452911377
Validation loss: 5.066969276756368

Epoch: 5| Step: 1
Training loss: 4.883208751678467
Validation loss: 5.056192633926227

Epoch: 5| Step: 2
Training loss: 4.925209999084473
Validation loss: 5.044937118407218

Epoch: 5| Step: 3
Training loss: 4.452269077301025
Validation loss: 5.0316396938857215

Epoch: 5| Step: 4
Training loss: 5.595582008361816
Validation loss: 5.018191532422137

Epoch: 5| Step: 5
Training loss: 3.6433799266815186
Validation loss: 5.003829017762215

Epoch: 5| Step: 6
Training loss: 3.9376816749572754
Validation loss: 4.988258736107939

Epoch: 5| Step: 7
Training loss: 5.961474418640137
Validation loss: 4.971712620027604

Epoch: 5| Step: 8
Training loss: 5.558326721191406
Validation loss: 4.953979789569813

Epoch: 5| Step: 9
Training loss: 3.9299213886260986
Validation loss: 4.93513629257038

Epoch: 5| Step: 10
Training loss: 5.106351852416992
Validation loss: 4.9149010104517785

Epoch: 3| Step: 0
Training loss: 4.5590667724609375
Validation loss: 4.8937943981539815

Epoch: 5| Step: 1
Training loss: 4.960122108459473
Validation loss: 4.871285951265725

Epoch: 5| Step: 2
Training loss: 3.55102801322937
Validation loss: 4.847373213819278

Epoch: 5| Step: 3
Training loss: 4.352071762084961
Validation loss: 4.82201151694021

Epoch: 5| Step: 4
Training loss: 4.86519193649292
Validation loss: 4.7957730088182675

Epoch: 5| Step: 5
Training loss: 4.0417375564575195
Validation loss: 4.768210841763404

Epoch: 5| Step: 6
Training loss: 4.765172004699707
Validation loss: 4.739179621460617

Epoch: 5| Step: 7
Training loss: 4.634700775146484
Validation loss: 4.710053523381551

Epoch: 5| Step: 8
Training loss: 4.701292991638184
Validation loss: 4.679557328583092

Epoch: 5| Step: 9
Training loss: 3.8662352561950684
Validation loss: 4.649163046190815

Epoch: 5| Step: 10
Training loss: 5.999922752380371
Validation loss: 4.61744176700551

Epoch: 4| Step: 0
Training loss: 4.397542476654053
Validation loss: 4.585485883938369

Epoch: 5| Step: 1
Training loss: 4.442259311676025
Validation loss: 4.554723739624023

Epoch: 5| Step: 2
Training loss: 2.943619966506958
Validation loss: 4.521490266246181

Epoch: 5| Step: 3
Training loss: 4.246455192565918
Validation loss: 4.487430216163717

Epoch: 5| Step: 4
Training loss: 4.4771728515625
Validation loss: 4.454967144996889

Epoch: 5| Step: 5
Training loss: 4.699799537658691
Validation loss: 4.4210822761699715

Epoch: 5| Step: 6
Training loss: 3.7355198860168457
Validation loss: 4.385635852813721

Epoch: 5| Step: 7
Training loss: 3.4841723442077637
Validation loss: 4.349423377744613

Epoch: 5| Step: 8
Training loss: 4.382021903991699
Validation loss: 4.3123798652361796

Epoch: 5| Step: 9
Training loss: 5.280014991760254
Validation loss: 4.27554375638244

Epoch: 5| Step: 10
Training loss: 4.181031227111816
Validation loss: 4.2375259143049995

Epoch: 5| Step: 0
Training loss: 3.36810302734375
Validation loss: 4.195938489770376

Epoch: 5| Step: 1
Training loss: 4.62588357925415
Validation loss: 4.153946845762191

Epoch: 5| Step: 2
Training loss: 4.766645431518555
Validation loss: 4.11394501501514

Epoch: 5| Step: 3
Training loss: 3.3892321586608887
Validation loss: 4.078234390545917

Epoch: 5| Step: 4
Training loss: 3.690455675125122
Validation loss: 4.039032479768158

Epoch: 5| Step: 5
Training loss: 2.3934311866760254
Validation loss: 4.00429323668121

Epoch: 5| Step: 6
Training loss: 4.391181945800781
Validation loss: 3.9748660313185824

Epoch: 5| Step: 7
Training loss: 3.6182942390441895
Validation loss: 3.9478044099705194

Epoch: 5| Step: 8
Training loss: 3.534327745437622
Validation loss: 3.924478966702697

Epoch: 5| Step: 9
Training loss: 4.826525688171387
Validation loss: 3.904797851398427

Epoch: 5| Step: 10
Training loss: 3.903310775756836
Validation loss: 3.887594146113242

Epoch: 6| Step: 0
Training loss: 2.741178512573242
Validation loss: 3.871722031665105

Epoch: 5| Step: 1
Training loss: 3.5223145484924316
Validation loss: 3.8583077410215973

Epoch: 5| Step: 2
Training loss: 3.8587486743927
Validation loss: 3.8460171120141142

Epoch: 5| Step: 3
Training loss: 4.2803778648376465
Validation loss: 3.831888347543696

Epoch: 5| Step: 4
Training loss: 3.1722264289855957
Validation loss: 3.815808957622897

Epoch: 5| Step: 5
Training loss: 3.0289440155029297
Validation loss: 3.797320878633889

Epoch: 5| Step: 6
Training loss: 4.292722225189209
Validation loss: 3.779887404493106

Epoch: 5| Step: 7
Training loss: 4.774779319763184
Validation loss: 3.7602796810929493

Epoch: 5| Step: 8
Training loss: 3.0731489658355713
Validation loss: 3.7384265340784544

Epoch: 5| Step: 9
Training loss: 3.621242046356201
Validation loss: 3.7149343721328245

Epoch: 5| Step: 10
Training loss: 4.110004901885986
Validation loss: 3.692482525302518

Epoch: 7| Step: 0
Training loss: 3.0396015644073486
Validation loss: 3.675808552772768

Epoch: 5| Step: 1
Training loss: 3.752652406692505
Validation loss: 3.656840714075232

Epoch: 5| Step: 2
Training loss: 4.651121616363525
Validation loss: 3.638727016346429

Epoch: 5| Step: 3
Training loss: 3.0400261878967285
Validation loss: 3.6236728442612516

Epoch: 5| Step: 4
Training loss: 4.01139497756958
Validation loss: 3.606700656234577

Epoch: 5| Step: 5
Training loss: 3.6446521282196045
Validation loss: 3.590552040325698

Epoch: 5| Step: 6
Training loss: 3.0857532024383545
Validation loss: 3.5810787934128956

Epoch: 5| Step: 7
Training loss: 3.049619674682617
Validation loss: 3.5695025972140733

Epoch: 5| Step: 8
Training loss: 3.405518054962158
Validation loss: 3.5608364177006546

Epoch: 5| Step: 9
Training loss: 2.9526963233947754
Validation loss: 3.552901537187638

Epoch: 5| Step: 10
Training loss: 4.196908950805664
Validation loss: 3.543714689952071

Epoch: 8| Step: 0
Training loss: 2.9789175987243652
Validation loss: 3.534893584507768

Epoch: 5| Step: 1
Training loss: 3.0319175720214844
Validation loss: 3.5228288404403196

Epoch: 5| Step: 2
Training loss: 4.613481044769287
Validation loss: 3.51508439740827

Epoch: 5| Step: 3
Training loss: 1.7997897863388062
Validation loss: 3.5091056131547496

Epoch: 5| Step: 4
Training loss: 3.9348785877227783
Validation loss: 3.497495238498975

Epoch: 5| Step: 5
Training loss: 4.702815532684326
Validation loss: 3.4919018027602986

Epoch: 5| Step: 6
Training loss: 3.0912461280822754
Validation loss: 3.4834207719372166

Epoch: 5| Step: 7
Training loss: 3.5878424644470215
Validation loss: 3.4758148347177813

Epoch: 5| Step: 8
Training loss: 3.4800896644592285
Validation loss: 3.4666746688145462

Epoch: 5| Step: 9
Training loss: 3.080430507659912
Validation loss: 3.4584446235369612

Epoch: 5| Step: 10
Training loss: 3.355043411254883
Validation loss: 3.4508794379490677

Epoch: 9| Step: 0
Training loss: 2.923600673675537
Validation loss: 3.4414554795911236

Epoch: 5| Step: 1
Training loss: 3.452335834503174
Validation loss: 3.433382959776027

Epoch: 5| Step: 2
Training loss: 3.341513156890869
Validation loss: 3.426230981785764

Epoch: 5| Step: 3
Training loss: 3.6176445484161377
Validation loss: 3.419537082795174

Epoch: 5| Step: 4
Training loss: 3.89509916305542
Validation loss: 3.414027024340886

Epoch: 5| Step: 5
Training loss: 2.863637924194336
Validation loss: 3.4041684366041616

Epoch: 5| Step: 6
Training loss: 3.5537571907043457
Validation loss: 3.39798552502868

Epoch: 5| Step: 7
Training loss: 2.3665854930877686
Validation loss: 3.3918373636020127

Epoch: 5| Step: 8
Training loss: 3.8089089393615723
Validation loss: 3.3855935091613443

Epoch: 5| Step: 9
Training loss: 3.513314723968506
Validation loss: 3.381313177847093

Epoch: 5| Step: 10
Training loss: 3.621948719024658
Validation loss: 3.371418563268518

Epoch: 10| Step: 0
Training loss: 3.697260618209839
Validation loss: 3.3643544566246772

Epoch: 5| Step: 1
Training loss: 3.3847060203552246
Validation loss: 3.3628191999209824

Epoch: 5| Step: 2
Training loss: 3.4434051513671875
Validation loss: 3.3524103626128166

Epoch: 5| Step: 3
Training loss: 3.6688666343688965
Validation loss: 3.3457240443075857

Epoch: 5| Step: 4
Training loss: 3.72724986076355
Validation loss: 3.3430079542180544

Epoch: 5| Step: 5
Training loss: 2.9317333698272705
Validation loss: 3.3357597704856627

Epoch: 5| Step: 6
Training loss: 2.966667890548706
Validation loss: 3.3303711747610443

Epoch: 5| Step: 7
Training loss: 3.404526948928833
Validation loss: 3.3223066970866215

Epoch: 5| Step: 8
Training loss: 3.051967144012451
Validation loss: 3.3146840551848054

Epoch: 5| Step: 9
Training loss: 2.294877290725708
Validation loss: 3.3063542304500455

Epoch: 5| Step: 10
Training loss: 3.7751407623291016
Validation loss: 3.3021589248411116

Epoch: 11| Step: 0
Training loss: 3.8696351051330566
Validation loss: 3.2941214499935025

Epoch: 5| Step: 1
Training loss: 2.6347293853759766
Validation loss: 3.292003813610282

Epoch: 5| Step: 2
Training loss: 3.1064765453338623
Validation loss: 3.286311129088043

Epoch: 5| Step: 3
Training loss: 2.770070791244507
Validation loss: 3.281193594778738

Epoch: 5| Step: 4
Training loss: 2.81970477104187
Validation loss: 3.2728674232318835

Epoch: 5| Step: 5
Training loss: 2.9360404014587402
Validation loss: 3.265284876669607

Epoch: 5| Step: 6
Training loss: 3.2773635387420654
Validation loss: 3.2557220253893124

Epoch: 5| Step: 7
Training loss: 3.694517135620117
Validation loss: 3.2501209782015894

Epoch: 5| Step: 8
Training loss: 3.527627944946289
Validation loss: 3.2459430848398516

Epoch: 5| Step: 9
Training loss: 3.366076707839966
Validation loss: 3.245986638530608

Epoch: 5| Step: 10
Training loss: 3.764043092727661
Validation loss: 3.2378562599100094

Epoch: 12| Step: 0
Training loss: 3.153808355331421
Validation loss: 3.235575191436275

Epoch: 5| Step: 1
Training loss: 2.9303102493286133
Validation loss: 3.2293091358677035

Epoch: 5| Step: 2
Training loss: 3.213986873626709
Validation loss: 3.2188422372264247

Epoch: 5| Step: 3
Training loss: 2.7314562797546387
Validation loss: 3.2127985467192945

Epoch: 5| Step: 4
Training loss: 2.706723928451538
Validation loss: 3.210034829314037

Epoch: 5| Step: 5
Training loss: 3.496777296066284
Validation loss: 3.210962244259414

Epoch: 5| Step: 6
Training loss: 3.712780714035034
Validation loss: 3.2063445480920936

Epoch: 5| Step: 7
Training loss: 3.8278281688690186
Validation loss: 3.2007080893362723

Epoch: 5| Step: 8
Training loss: 3.388474225997925
Validation loss: 3.1947674623099704

Epoch: 5| Step: 9
Training loss: 3.2060844898223877
Validation loss: 3.184723843810379

Epoch: 5| Step: 10
Training loss: 2.773495674133301
Validation loss: 3.175906986318609

Epoch: 13| Step: 0
Training loss: 3.3680572509765625
Validation loss: 3.1737512824355916

Epoch: 5| Step: 1
Training loss: 3.5146706104278564
Validation loss: 3.1697977896659606

Epoch: 5| Step: 2
Training loss: 3.2075629234313965
Validation loss: 3.1697659236128612

Epoch: 5| Step: 3
Training loss: 2.904531478881836
Validation loss: 3.1643671348530757

Epoch: 5| Step: 4
Training loss: 2.918117046356201
Validation loss: 3.150384428680584

Epoch: 5| Step: 5
Training loss: 3.748927354812622
Validation loss: 3.1490810378905265

Epoch: 5| Step: 6
Training loss: 3.011098623275757
Validation loss: 3.1422212021325224

Epoch: 5| Step: 7
Training loss: 2.648010730743408
Validation loss: 3.1400156995301605

Epoch: 5| Step: 8
Training loss: 3.1386189460754395
Validation loss: 3.1401714048077984

Epoch: 5| Step: 9
Training loss: 3.3130881786346436
Validation loss: 3.1377106507619223

Epoch: 5| Step: 10
Training loss: 3.0507304668426514
Validation loss: 3.1312559548244683

Epoch: 14| Step: 0
Training loss: 2.281978130340576
Validation loss: 3.1244526909243677

Epoch: 5| Step: 1
Training loss: 2.906952381134033
Validation loss: 3.1310554524903655

Epoch: 5| Step: 2
Training loss: 3.400864839553833
Validation loss: 3.119803123576667

Epoch: 5| Step: 3
Training loss: 2.874164581298828
Validation loss: 3.107264236737323

Epoch: 5| Step: 4
Training loss: 2.7229866981506348
Validation loss: 3.1027721717793453

Epoch: 5| Step: 5
Training loss: 4.089334011077881
Validation loss: 3.1065603943281275

Epoch: 5| Step: 6
Training loss: 3.5467605590820312
Validation loss: 3.109098534430227

Epoch: 5| Step: 7
Training loss: 2.328028440475464
Validation loss: 3.104736502452563

Epoch: 5| Step: 8
Training loss: 3.702092409133911
Validation loss: 3.105216831289312

Epoch: 5| Step: 9
Training loss: 3.289344072341919
Validation loss: 3.092072707350536

Epoch: 5| Step: 10
Training loss: 3.341224431991577
Validation loss: 3.080933996426162

Epoch: 15| Step: 0
Training loss: 2.592092752456665
Validation loss: 3.078811735235235

Epoch: 5| Step: 1
Training loss: 3.0328598022460938
Validation loss: 3.0861817713706725

Epoch: 5| Step: 2
Training loss: 3.1154582500457764
Validation loss: 3.0839300078730427

Epoch: 5| Step: 3
Training loss: 3.1872074604034424
Validation loss: 3.0767754200966126

Epoch: 5| Step: 4
Training loss: 2.6926543712615967
Validation loss: 3.070087032933389

Epoch: 5| Step: 5
Training loss: 2.4546353816986084
Validation loss: 3.068358623853294

Epoch: 5| Step: 6
Training loss: 3.9995627403259277
Validation loss: 3.0653698880185365

Epoch: 5| Step: 7
Training loss: 3.7631843090057373
Validation loss: 3.0603342415184103

Epoch: 5| Step: 8
Training loss: 3.140733480453491
Validation loss: 3.0478512753722486

Epoch: 5| Step: 9
Training loss: 2.831730365753174
Validation loss: 3.0395723286495415

Epoch: 5| Step: 10
Training loss: 3.3670849800109863
Validation loss: 3.0405796445826048

Epoch: 16| Step: 0
Training loss: 2.76967453956604
Validation loss: 3.038947477135607

Epoch: 5| Step: 1
Training loss: 3.450080394744873
Validation loss: 3.041065098136984

Epoch: 5| Step: 2
Training loss: 3.571514129638672
Validation loss: 3.037850195361722

Epoch: 5| Step: 3
Training loss: 2.7523365020751953
Validation loss: 3.0268977354931574

Epoch: 5| Step: 4
Training loss: 2.3149170875549316
Validation loss: 3.0209800812505905

Epoch: 5| Step: 5
Training loss: 2.4356789588928223
Validation loss: 3.042082514814151

Epoch: 5| Step: 6
Training loss: 2.77582049369812
Validation loss: 3.0252502451660814

Epoch: 5| Step: 7
Training loss: 3.5949268341064453
Validation loss: 3.0200426040157193

Epoch: 5| Step: 8
Training loss: 3.285184860229492
Validation loss: 3.0172513684918805

Epoch: 5| Step: 9
Training loss: 3.229750156402588
Validation loss: 3.0203064513462845

Epoch: 5| Step: 10
Training loss: 3.782660961151123
Validation loss: 3.0190933237793627

Epoch: 17| Step: 0
Training loss: 3.572535276412964
Validation loss: 3.0152395643213743

Epoch: 5| Step: 1
Training loss: 3.5124378204345703
Validation loss: 3.0102392447892057

Epoch: 5| Step: 2
Training loss: 2.552711009979248
Validation loss: 3.001330191089261

Epoch: 5| Step: 3
Training loss: 2.924283504486084
Validation loss: 2.9988708598639375

Epoch: 5| Step: 4
Training loss: 2.5971031188964844
Validation loss: 2.9997127568849953

Epoch: 5| Step: 5
Training loss: 3.4908833503723145
Validation loss: 2.995515420872678

Epoch: 5| Step: 6
Training loss: 3.190640926361084
Validation loss: 2.9888180225126204

Epoch: 5| Step: 7
Training loss: 2.66060209274292
Validation loss: 2.99073153029206

Epoch: 5| Step: 8
Training loss: 2.929258346557617
Validation loss: 2.9845353557217504

Epoch: 5| Step: 9
Training loss: 3.5079846382141113
Validation loss: 2.9801467054633686

Epoch: 5| Step: 10
Training loss: 2.6458263397216797
Validation loss: 2.9785833256219023

Epoch: 18| Step: 0
Training loss: 2.714815855026245
Validation loss: 2.9778073474925053

Epoch: 5| Step: 1
Training loss: 3.3104958534240723
Validation loss: 2.9755741088621077

Epoch: 5| Step: 2
Training loss: 2.563598155975342
Validation loss: 2.97591737521592

Epoch: 5| Step: 3
Training loss: 3.2986347675323486
Validation loss: 2.9735329228062786

Epoch: 5| Step: 4
Training loss: 3.8036186695098877
Validation loss: 2.967584538203414

Epoch: 5| Step: 5
Training loss: 2.5099754333496094
Validation loss: 2.963127738686018

Epoch: 5| Step: 6
Training loss: 3.150908946990967
Validation loss: 2.9589877359328733

Epoch: 5| Step: 7
Training loss: 2.567943572998047
Validation loss: 2.9560054989271265

Epoch: 5| Step: 8
Training loss: 3.2904891967773438
Validation loss: 2.963040413395051

Epoch: 5| Step: 9
Training loss: 3.532646894454956
Validation loss: 2.9706456866315616

Epoch: 5| Step: 10
Training loss: 2.612867593765259
Validation loss: 2.9600558075853574

Epoch: 19| Step: 0
Training loss: 2.9425251483917236
Validation loss: 2.956347747515607

Epoch: 5| Step: 1
Training loss: 3.017582893371582
Validation loss: 2.9671561179622525

Epoch: 5| Step: 2
Training loss: 2.5680172443389893
Validation loss: 2.9768956784279115

Epoch: 5| Step: 3
Training loss: 3.757056474685669
Validation loss: 2.9662157284316195

Epoch: 5| Step: 4
Training loss: 3.37050199508667
Validation loss: 2.9538256558038856

Epoch: 5| Step: 5
Training loss: 2.7712206840515137
Validation loss: 2.9474178847446235

Epoch: 5| Step: 6
Training loss: 2.806821823120117
Validation loss: 2.9571604856880764

Epoch: 5| Step: 7
Training loss: 3.6788604259490967
Validation loss: 2.9635231059084655

Epoch: 5| Step: 8
Training loss: 2.5836453437805176
Validation loss: 2.959935421584755

Epoch: 5| Step: 9
Training loss: 2.8351500034332275
Validation loss: 2.949898119895689

Epoch: 5| Step: 10
Training loss: 3.1026692390441895
Validation loss: 2.9414307096953034

Epoch: 20| Step: 0
Training loss: 3.2068591117858887
Validation loss: 2.9418284149580103

Epoch: 5| Step: 1
Training loss: 3.2050538063049316
Validation loss: 2.9410223730148806

Epoch: 5| Step: 2
Training loss: 2.4785282611846924
Validation loss: 2.937408552374891

Epoch: 5| Step: 3
Training loss: 2.7149853706359863
Validation loss: 2.935975579805272

Epoch: 5| Step: 4
Training loss: 3.740633010864258
Validation loss: 2.9306706766928396

Epoch: 5| Step: 5
Training loss: 2.903001308441162
Validation loss: 2.925975781615062

Epoch: 5| Step: 6
Training loss: 3.1949265003204346
Validation loss: 2.922621960281044

Epoch: 5| Step: 7
Training loss: 1.7838541269302368
Validation loss: 2.922418402087304

Epoch: 5| Step: 8
Training loss: 3.471503734588623
Validation loss: 2.920058714446201

Epoch: 5| Step: 9
Training loss: 3.814448595046997
Validation loss: 2.9211886364926576

Epoch: 5| Step: 10
Training loss: 2.574922800064087
Validation loss: 2.919621946991131

Epoch: 21| Step: 0
Training loss: 3.671494960784912
Validation loss: 2.9166282684572282

Epoch: 5| Step: 1
Training loss: 2.890622138977051
Validation loss: 2.915340946566674

Epoch: 5| Step: 2
Training loss: 2.7142319679260254
Validation loss: 2.912782630612773

Epoch: 5| Step: 3
Training loss: 3.003152370452881
Validation loss: 2.908592565085298

Epoch: 5| Step: 4
Training loss: 3.063789129257202
Validation loss: 2.904575376100438

Epoch: 5| Step: 5
Training loss: 2.723278045654297
Validation loss: 2.900980018800305

Epoch: 5| Step: 6
Training loss: 2.5659778118133545
Validation loss: 2.9028676607275523

Epoch: 5| Step: 7
Training loss: 3.1312661170959473
Validation loss: 2.900750588345271

Epoch: 5| Step: 8
Training loss: 2.9158644676208496
Validation loss: 2.901968712447792

Epoch: 5| Step: 9
Training loss: 2.7479491233825684
Validation loss: 2.9010441098161923

Epoch: 5| Step: 10
Training loss: 3.642324447631836
Validation loss: 2.914429008319814

Epoch: 22| Step: 0
Training loss: 2.845856189727783
Validation loss: 2.9235706098618044

Epoch: 5| Step: 1
Training loss: 3.3130791187286377
Validation loss: 2.9045670340138097

Epoch: 5| Step: 2
Training loss: 2.7934091091156006
Validation loss: 2.894946208564184

Epoch: 5| Step: 3
Training loss: 2.918943405151367
Validation loss: 2.8935359344687512

Epoch: 5| Step: 4
Training loss: 2.1856422424316406
Validation loss: 2.901641861084969

Epoch: 5| Step: 5
Training loss: 3.048361301422119
Validation loss: 2.9099533275891374

Epoch: 5| Step: 6
Training loss: 3.219296932220459
Validation loss: 2.891923899291664

Epoch: 5| Step: 7
Training loss: 2.922712564468384
Validation loss: 2.8867478345030095

Epoch: 5| Step: 8
Training loss: 2.387446641921997
Validation loss: 2.8874216848804104

Epoch: 5| Step: 9
Training loss: 3.7232253551483154
Validation loss: 2.886696389926377

Epoch: 5| Step: 10
Training loss: 3.5292301177978516
Validation loss: 2.8850544216812297

Epoch: 23| Step: 0
Training loss: 3.0557448863983154
Validation loss: 2.885291358476044

Epoch: 5| Step: 1
Training loss: 2.759542942047119
Validation loss: 2.883225656324817

Epoch: 5| Step: 2
Training loss: 2.6801161766052246
Validation loss: 2.878338454872049

Epoch: 5| Step: 3
Training loss: 2.434701681137085
Validation loss: 2.8759163271996284

Epoch: 5| Step: 4
Training loss: 3.7353148460388184
Validation loss: 2.8785348092356036

Epoch: 5| Step: 5
Training loss: 2.0854508876800537
Validation loss: 2.8850941145291893

Epoch: 5| Step: 6
Training loss: 3.282972812652588
Validation loss: 2.887564233554307

Epoch: 5| Step: 7
Training loss: 3.6895670890808105
Validation loss: 2.8894285642972557

Epoch: 5| Step: 8
Training loss: 3.66120982170105
Validation loss: 2.8941317271160822

Epoch: 5| Step: 9
Training loss: 2.722442150115967
Validation loss: 2.885195142479353

Epoch: 5| Step: 10
Training loss: 2.6534197330474854
Validation loss: 2.8766756826831448

Epoch: 24| Step: 0
Training loss: 3.2966034412384033
Validation loss: 2.872965625537339

Epoch: 5| Step: 1
Training loss: 3.6664555072784424
Validation loss: 2.8710046711788384

Epoch: 5| Step: 2
Training loss: 3.1012885570526123
Validation loss: 2.8730508460793445

Epoch: 5| Step: 3
Training loss: 3.470649003982544
Validation loss: 2.8737947376825477

Epoch: 5| Step: 4
Training loss: 3.5137856006622314
Validation loss: 2.8788307277105187

Epoch: 5| Step: 5
Training loss: 2.6592867374420166
Validation loss: 2.871253864739531

Epoch: 5| Step: 6
Training loss: 2.6576101779937744
Validation loss: 2.871477400102923

Epoch: 5| Step: 7
Training loss: 1.769274115562439
Validation loss: 2.8639292383706696

Epoch: 5| Step: 8
Training loss: 3.496173858642578
Validation loss: 2.8654137272988596

Epoch: 5| Step: 9
Training loss: 2.399446725845337
Validation loss: 2.8607809646155244

Epoch: 5| Step: 10
Training loss: 2.635040044784546
Validation loss: 2.8581982940755863

Epoch: 25| Step: 0
Training loss: 3.162928819656372
Validation loss: 2.86583213908698

Epoch: 5| Step: 1
Training loss: 3.289288282394409
Validation loss: 2.8738286161935456

Epoch: 5| Step: 2
Training loss: 2.8615236282348633
Validation loss: 2.861272647816648

Epoch: 5| Step: 3
Training loss: 2.712867021560669
Validation loss: 2.852032043600595

Epoch: 5| Step: 4
Training loss: 3.8605904579162598
Validation loss: 2.851094279237973

Epoch: 5| Step: 5
Training loss: 2.3450660705566406
Validation loss: 2.8511972709368636

Epoch: 5| Step: 6
Training loss: 2.938655138015747
Validation loss: 2.8533520057637203

Epoch: 5| Step: 7
Training loss: 2.7098782062530518
Validation loss: 2.8573261127677014

Epoch: 5| Step: 8
Training loss: 2.95671010017395
Validation loss: 2.855296729713358

Epoch: 5| Step: 9
Training loss: 2.3843894004821777
Validation loss: 2.8539494288864957

Epoch: 5| Step: 10
Training loss: 3.3998630046844482
Validation loss: 2.861999019499748

Epoch: 26| Step: 0
Training loss: 3.497375011444092
Validation loss: 2.8599105727288032

Epoch: 5| Step: 1
Training loss: 3.331740140914917
Validation loss: 2.8542241588715584

Epoch: 5| Step: 2
Training loss: 2.929421901702881
Validation loss: 2.8499530361544703

Epoch: 5| Step: 3
Training loss: 2.5075201988220215
Validation loss: 2.848669146978727

Epoch: 5| Step: 4
Training loss: 2.7752413749694824
Validation loss: 2.8409467333106586

Epoch: 5| Step: 5
Training loss: 2.7132859230041504
Validation loss: 2.839626460947016

Epoch: 5| Step: 6
Training loss: 3.3822684288024902
Validation loss: 2.8343181276834137

Epoch: 5| Step: 7
Training loss: 2.924802303314209
Validation loss: 2.8324022472545667

Epoch: 5| Step: 8
Training loss: 2.4831442832946777
Validation loss: 2.834110700955955

Epoch: 5| Step: 9
Training loss: 3.0488905906677246
Validation loss: 2.832113460827899

Epoch: 5| Step: 10
Training loss: 2.884708881378174
Validation loss: 2.8307113211642028

Epoch: 27| Step: 0
Training loss: 2.9465878009796143
Validation loss: 2.828089480758995

Epoch: 5| Step: 1
Training loss: 2.7765464782714844
Validation loss: 2.824417365494595

Epoch: 5| Step: 2
Training loss: 2.678222179412842
Validation loss: 2.825559372543007

Epoch: 5| Step: 3
Training loss: 3.0579745769500732
Validation loss: 2.824024397839782

Epoch: 5| Step: 4
Training loss: 2.8663268089294434
Validation loss: 2.822687905321839

Epoch: 5| Step: 5
Training loss: 3.0599513053894043
Validation loss: 2.824650308137299

Epoch: 5| Step: 6
Training loss: 3.2805142402648926
Validation loss: 2.8211995863145396

Epoch: 5| Step: 7
Training loss: 2.7817444801330566
Validation loss: 2.8248432195314797

Epoch: 5| Step: 8
Training loss: 2.72898006439209
Validation loss: 2.818547148858347

Epoch: 5| Step: 9
Training loss: 2.704643726348877
Validation loss: 2.816320547493555

Epoch: 5| Step: 10
Training loss: 3.5092618465423584
Validation loss: 2.8183870700097855

Epoch: 28| Step: 0
Training loss: 1.9873714447021484
Validation loss: 2.8171540716642975

Epoch: 5| Step: 1
Training loss: 2.1550230979919434
Validation loss: 2.8138546354027203

Epoch: 5| Step: 2
Training loss: 3.1448252201080322
Validation loss: 2.815929074441233

Epoch: 5| Step: 3
Training loss: 2.370952606201172
Validation loss: 2.814302349603304

Epoch: 5| Step: 4
Training loss: 2.6452183723449707
Validation loss: 2.8113460181861796

Epoch: 5| Step: 5
Training loss: 3.9676384925842285
Validation loss: 2.807680494041853

Epoch: 5| Step: 6
Training loss: 3.730788469314575
Validation loss: 2.8068008038305465

Epoch: 5| Step: 7
Training loss: 2.7247657775878906
Validation loss: 2.805576462899485

Epoch: 5| Step: 8
Training loss: 3.9961204528808594
Validation loss: 2.806406815846761

Epoch: 5| Step: 9
Training loss: 3.040709972381592
Validation loss: 2.806292131382932

Epoch: 5| Step: 10
Training loss: 2.3489975929260254
Validation loss: 2.801726407902215

Epoch: 29| Step: 0
Training loss: 3.5776264667510986
Validation loss: 2.803764325316234

Epoch: 5| Step: 1
Training loss: 2.6898725032806396
Validation loss: 2.8002971423569547

Epoch: 5| Step: 2
Training loss: 2.7159972190856934
Validation loss: 2.8014629886996363

Epoch: 5| Step: 3
Training loss: 2.7779386043548584
Validation loss: 2.8018934393441803

Epoch: 5| Step: 4
Training loss: 2.9532437324523926
Validation loss: 2.800799692830732

Epoch: 5| Step: 5
Training loss: 2.619539737701416
Validation loss: 2.808268657294653

Epoch: 5| Step: 6
Training loss: 3.3638720512390137
Validation loss: 2.8110893234129875

Epoch: 5| Step: 7
Training loss: 3.6499571800231934
Validation loss: 2.858155583822599

Epoch: 5| Step: 8
Training loss: 2.5581436157226562
Validation loss: 2.8252822686267156

Epoch: 5| Step: 9
Training loss: 3.211167573928833
Validation loss: 2.803222023030763

Epoch: 5| Step: 10
Training loss: 1.8992846012115479
Validation loss: 2.7957646359679518

Epoch: 30| Step: 0
Training loss: 3.1423563957214355
Validation loss: 2.80060508174281

Epoch: 5| Step: 1
Training loss: 2.962510824203491
Validation loss: 2.8053506958869194

Epoch: 5| Step: 2
Training loss: 2.8882596492767334
Validation loss: 2.8088125669828026

Epoch: 5| Step: 3
Training loss: 2.8486976623535156
Validation loss: 2.814431354563723

Epoch: 5| Step: 4
Training loss: 2.737455129623413
Validation loss: 2.8042290005632626

Epoch: 5| Step: 5
Training loss: 3.1248021125793457
Validation loss: 2.7989528281714326

Epoch: 5| Step: 6
Training loss: 2.563343048095703
Validation loss: 2.7959715166399555

Epoch: 5| Step: 7
Training loss: 3.2513885498046875
Validation loss: 2.7918860040685183

Epoch: 5| Step: 8
Training loss: 2.5532326698303223
Validation loss: 2.791858555168234

Epoch: 5| Step: 9
Training loss: 3.0244498252868652
Validation loss: 2.7929240401073168

Epoch: 5| Step: 10
Training loss: 3.094057321548462
Validation loss: 2.793894172996603

Epoch: 31| Step: 0
Training loss: 2.151870012283325
Validation loss: 2.7977184505872827

Epoch: 5| Step: 1
Training loss: 2.7890517711639404
Validation loss: 2.807661061645836

Epoch: 5| Step: 2
Training loss: 2.84653902053833
Validation loss: 2.8117594103659354

Epoch: 5| Step: 3
Training loss: 3.261620283126831
Validation loss: 2.8075699960031817

Epoch: 5| Step: 4
Training loss: 2.421668529510498
Validation loss: 2.797530384473903

Epoch: 5| Step: 5
Training loss: 3.4734840393066406
Validation loss: 2.7927675093373945

Epoch: 5| Step: 6
Training loss: 2.206045150756836
Validation loss: 2.7875046986405567

Epoch: 5| Step: 7
Training loss: 3.4554221630096436
Validation loss: 2.783584581908359

Epoch: 5| Step: 8
Training loss: 2.831770658493042
Validation loss: 2.786545761169926

Epoch: 5| Step: 9
Training loss: 3.248729705810547
Validation loss: 2.7832073857707362

Epoch: 5| Step: 10
Training loss: 3.472519874572754
Validation loss: 2.7868203091365036

Epoch: 32| Step: 0
Training loss: 2.579219102859497
Validation loss: 2.7838249796180317

Epoch: 5| Step: 1
Training loss: 2.9321439266204834
Validation loss: 2.778513708422261

Epoch: 5| Step: 2
Training loss: 3.29622220993042
Validation loss: 2.7795880558670207

Epoch: 5| Step: 3
Training loss: 3.5077857971191406
Validation loss: 2.7757910502854215

Epoch: 5| Step: 4
Training loss: 2.4916765689849854
Validation loss: 2.774668393596526

Epoch: 5| Step: 5
Training loss: 3.0162553787231445
Validation loss: 2.77318065140837

Epoch: 5| Step: 6
Training loss: 2.6847338676452637
Validation loss: 2.7737100380723194

Epoch: 5| Step: 7
Training loss: 3.275423049926758
Validation loss: 2.7749715082107054

Epoch: 5| Step: 8
Training loss: 2.5393238067626953
Validation loss: 2.7719272336652203

Epoch: 5| Step: 9
Training loss: 2.8315703868865967
Validation loss: 2.770914921196558

Epoch: 5| Step: 10
Training loss: 2.805203437805176
Validation loss: 2.7662161319486556

Epoch: 33| Step: 0
Training loss: 2.9147677421569824
Validation loss: 2.763499059984761

Epoch: 5| Step: 1
Training loss: 2.749114990234375
Validation loss: 2.7571586998560096

Epoch: 5| Step: 2
Training loss: 2.6154913902282715
Validation loss: 2.758150280162852

Epoch: 5| Step: 3
Training loss: 3.153632640838623
Validation loss: 2.7552728088953162

Epoch: 5| Step: 4
Training loss: 3.3528084754943848
Validation loss: 2.755620887202601

Epoch: 5| Step: 5
Training loss: 3.0652995109558105
Validation loss: 2.755319667118852

Epoch: 5| Step: 6
Training loss: 2.9937820434570312
Validation loss: 2.754589106446953

Epoch: 5| Step: 7
Training loss: 3.1170616149902344
Validation loss: 2.75790491924491

Epoch: 5| Step: 8
Training loss: 3.052028179168701
Validation loss: 2.7736329442711285

Epoch: 5| Step: 9
Training loss: 2.2775180339813232
Validation loss: 2.7790627120643534

Epoch: 5| Step: 10
Training loss: 2.5069875717163086
Validation loss: 2.7706900040308633

Epoch: 34| Step: 0
Training loss: 3.17562198638916
Validation loss: 2.77007403168627

Epoch: 5| Step: 1
Training loss: 2.662909746170044
Validation loss: 2.7608692928027083

Epoch: 5| Step: 2
Training loss: 2.298757314682007
Validation loss: 2.762399673461914

Epoch: 5| Step: 3
Training loss: 3.6041665077209473
Validation loss: 2.7644560849794777

Epoch: 5| Step: 4
Training loss: 2.4532339572906494
Validation loss: 2.7576905963241414

Epoch: 5| Step: 5
Training loss: 2.4125771522521973
Validation loss: 2.779254856929984

Epoch: 5| Step: 6
Training loss: 3.064362049102783
Validation loss: 2.7802272048047794

Epoch: 5| Step: 7
Training loss: 2.444554090499878
Validation loss: 2.7696347569906585

Epoch: 5| Step: 8
Training loss: 3.4044063091278076
Validation loss: 2.755590308097101

Epoch: 5| Step: 9
Training loss: 3.2002246379852295
Validation loss: 2.7501595558658725

Epoch: 5| Step: 10
Training loss: 3.0831515789031982
Validation loss: 2.7464932600657144

Epoch: 35| Step: 0
Training loss: 2.204179048538208
Validation loss: 2.746273797045472

Epoch: 5| Step: 1
Training loss: 2.674948215484619
Validation loss: 2.745063797120125

Epoch: 5| Step: 2
Training loss: 2.9957969188690186
Validation loss: 2.7462357269820346

Epoch: 5| Step: 3
Training loss: 3.625143051147461
Validation loss: 2.745442280205347

Epoch: 5| Step: 4
Training loss: 2.3592114448547363
Validation loss: 2.7441046468673216

Epoch: 5| Step: 5
Training loss: 3.1649742126464844
Validation loss: 2.7455851083160727

Epoch: 5| Step: 6
Training loss: 3.05637788772583
Validation loss: 2.7478197518215386

Epoch: 5| Step: 7
Training loss: 3.0458946228027344
Validation loss: 2.743988747237831

Epoch: 5| Step: 8
Training loss: 3.784820556640625
Validation loss: 2.74027935407495

Epoch: 5| Step: 9
Training loss: 2.016293525695801
Validation loss: 2.743989126656645

Epoch: 5| Step: 10
Training loss: 2.7597405910491943
Validation loss: 2.742959366049818

Epoch: 36| Step: 0
Training loss: 2.0717079639434814
Validation loss: 2.7418051842720277

Epoch: 5| Step: 1
Training loss: 3.7071633338928223
Validation loss: 2.7385993772937405

Epoch: 5| Step: 2
Training loss: 2.379258155822754
Validation loss: 2.739417124820012

Epoch: 5| Step: 3
Training loss: 3.2385830879211426
Validation loss: 2.7349956317614486

Epoch: 5| Step: 4
Training loss: 2.8967838287353516
Validation loss: 2.7374654995497836

Epoch: 5| Step: 5
Training loss: 2.803678512573242
Validation loss: 2.735825992399646

Epoch: 5| Step: 6
Training loss: 3.0436911582946777
Validation loss: 2.7370658946293656

Epoch: 5| Step: 7
Training loss: 2.8269765377044678
Validation loss: 2.7402079336104856

Epoch: 5| Step: 8
Training loss: 3.1121773719787598
Validation loss: 2.7357562562470794

Epoch: 5| Step: 9
Training loss: 3.389359951019287
Validation loss: 2.7368536738939184

Epoch: 5| Step: 10
Training loss: 2.0771968364715576
Validation loss: 2.7343049331377913

Epoch: 37| Step: 0
Training loss: 2.5353145599365234
Validation loss: 2.731861542629939

Epoch: 5| Step: 1
Training loss: 3.032803773880005
Validation loss: 2.7321835205119145

Epoch: 5| Step: 2
Training loss: 3.7897868156433105
Validation loss: 2.7319343654058312

Epoch: 5| Step: 3
Training loss: 2.905907392501831
Validation loss: 2.731776132378527

Epoch: 5| Step: 4
Training loss: 2.6459717750549316
Validation loss: 2.7321073752577587

Epoch: 5| Step: 5
Training loss: 2.378695249557495
Validation loss: 2.7293495003895094

Epoch: 5| Step: 6
Training loss: 2.3390426635742188
Validation loss: 2.7332807869039555

Epoch: 5| Step: 7
Training loss: 3.081169366836548
Validation loss: 2.729389654692783

Epoch: 5| Step: 8
Training loss: 3.07073974609375
Validation loss: 2.733237966414421

Epoch: 5| Step: 9
Training loss: 2.353236675262451
Validation loss: 2.731901430314587

Epoch: 5| Step: 10
Training loss: 3.573843479156494
Validation loss: 2.7326373643772577

Epoch: 38| Step: 0
Training loss: 2.682831287384033
Validation loss: 2.731448914415093

Epoch: 5| Step: 1
Training loss: 3.1405625343322754
Validation loss: 2.730872766945952

Epoch: 5| Step: 2
Training loss: 3.1877942085266113
Validation loss: 2.7348488684623473

Epoch: 5| Step: 3
Training loss: 3.051454544067383
Validation loss: 2.736261003760881

Epoch: 5| Step: 4
Training loss: 3.1258697509765625
Validation loss: 2.731078237615606

Epoch: 5| Step: 5
Training loss: 2.536160945892334
Validation loss: 2.73065322701649

Epoch: 5| Step: 6
Training loss: 3.057889461517334
Validation loss: 2.7260675891753166

Epoch: 5| Step: 7
Training loss: 2.2750649452209473
Validation loss: 2.7320712253611577

Epoch: 5| Step: 8
Training loss: 2.644562244415283
Validation loss: 2.7408998294543196

Epoch: 5| Step: 9
Training loss: 2.8692786693573
Validation loss: 2.743042581824846

Epoch: 5| Step: 10
Training loss: 2.9567575454711914
Validation loss: 2.7398103462752474

Epoch: 39| Step: 0
Training loss: 2.499218463897705
Validation loss: 2.735122191008701

Epoch: 5| Step: 1
Training loss: 2.8420932292938232
Validation loss: 2.7364868066644155

Epoch: 5| Step: 2
Training loss: 2.746208667755127
Validation loss: 2.7420593538591937

Epoch: 5| Step: 3
Training loss: 2.9303231239318848
Validation loss: 2.744555378472933

Epoch: 5| Step: 4
Training loss: 3.179335832595825
Validation loss: 2.7299969145046767

Epoch: 5| Step: 5
Training loss: 3.66154408454895
Validation loss: 2.7273928144926667

Epoch: 5| Step: 6
Training loss: 2.9591479301452637
Validation loss: 2.7266062510910856

Epoch: 5| Step: 7
Training loss: 2.139396905899048
Validation loss: 2.72629274347777

Epoch: 5| Step: 8
Training loss: 3.0276553630828857
Validation loss: 2.7274498683150097

Epoch: 5| Step: 9
Training loss: 2.6691203117370605
Validation loss: 2.727167947317964

Epoch: 5| Step: 10
Training loss: 2.94766902923584
Validation loss: 2.726123120195122

Epoch: 40| Step: 0
Training loss: 1.961804747581482
Validation loss: 2.727128544161397

Epoch: 5| Step: 1
Training loss: 2.325899600982666
Validation loss: 2.7269825038089546

Epoch: 5| Step: 2
Training loss: 3.2848525047302246
Validation loss: 2.7249478217094176

Epoch: 5| Step: 3
Training loss: 2.843621015548706
Validation loss: 2.727253216569142

Epoch: 5| Step: 4
Training loss: 2.8097259998321533
Validation loss: 2.735514156280025

Epoch: 5| Step: 5
Training loss: 2.3090460300445557
Validation loss: 2.7376652943190707

Epoch: 5| Step: 6
Training loss: 3.181942939758301
Validation loss: 2.738342754302486

Epoch: 5| Step: 7
Training loss: 2.788160800933838
Validation loss: 2.732755955829415

Epoch: 5| Step: 8
Training loss: 3.133697271347046
Validation loss: 2.741565755618516

Epoch: 5| Step: 9
Training loss: 4.044145584106445
Validation loss: 2.7517898005823933

Epoch: 5| Step: 10
Training loss: 2.9765143394470215
Validation loss: 2.732728863275179

Epoch: 41| Step: 0
Training loss: 2.8050522804260254
Validation loss: 2.7317244468196744

Epoch: 5| Step: 1
Training loss: 3.9632599353790283
Validation loss: 2.7325465961169173

Epoch: 5| Step: 2
Training loss: 2.470283031463623
Validation loss: 2.720520668132331

Epoch: 5| Step: 3
Training loss: 2.4560463428497314
Validation loss: 2.7188780538497435

Epoch: 5| Step: 4
Training loss: 2.530885934829712
Validation loss: 2.726259103385351

Epoch: 5| Step: 5
Training loss: 2.9266412258148193
Validation loss: 2.7289178858521166

Epoch: 5| Step: 6
Training loss: 2.984968662261963
Validation loss: 2.7305196510848178

Epoch: 5| Step: 7
Training loss: 2.612839937210083
Validation loss: 2.7306179231212986

Epoch: 5| Step: 8
Training loss: 2.6246562004089355
Validation loss: 2.7298372048203663

Epoch: 5| Step: 9
Training loss: 3.4692511558532715
Validation loss: 2.7277242111903366

Epoch: 5| Step: 10
Training loss: 2.768498420715332
Validation loss: 2.72360913215145

Epoch: 42| Step: 0
Training loss: 3.5812389850616455
Validation loss: 2.723008507041521

Epoch: 5| Step: 1
Training loss: 2.5558371543884277
Validation loss: 2.72140936441319

Epoch: 5| Step: 2
Training loss: 2.9719958305358887
Validation loss: 2.7193437340439006

Epoch: 5| Step: 3
Training loss: 3.159606456756592
Validation loss: 2.7179061520484185

Epoch: 5| Step: 4
Training loss: 3.3936455249786377
Validation loss: 2.716886620367727

Epoch: 5| Step: 5
Training loss: 2.0272774696350098
Validation loss: 2.7162149413939445

Epoch: 5| Step: 6
Training loss: 2.079806089401245
Validation loss: 2.711141917013353

Epoch: 5| Step: 7
Training loss: 2.856562852859497
Validation loss: 2.7163410212403987

Epoch: 5| Step: 8
Training loss: 2.7232825756073
Validation loss: 2.7153745928118305

Epoch: 5| Step: 9
Training loss: 2.814328670501709
Validation loss: 2.718926647657989

Epoch: 5| Step: 10
Training loss: 3.3922433853149414
Validation loss: 2.719044464890675

Epoch: 43| Step: 0
Training loss: 2.998295307159424
Validation loss: 2.7161726361961773

Epoch: 5| Step: 1
Training loss: 2.8719348907470703
Validation loss: 2.713033760747602

Epoch: 5| Step: 2
Training loss: 2.895188093185425
Validation loss: 2.71048161291307

Epoch: 5| Step: 3
Training loss: 2.4768989086151123
Validation loss: 2.7085901255248697

Epoch: 5| Step: 4
Training loss: 3.2064247131347656
Validation loss: 2.7079923947652182

Epoch: 5| Step: 5
Training loss: 3.089369058609009
Validation loss: 2.710175642403223

Epoch: 5| Step: 6
Training loss: 2.1190974712371826
Validation loss: 2.70959028890056

Epoch: 5| Step: 7
Training loss: 2.5406460762023926
Validation loss: 2.7140674155245543

Epoch: 5| Step: 8
Training loss: 3.572033643722534
Validation loss: 2.709982536172354

Epoch: 5| Step: 9
Training loss: 2.8688337802886963
Validation loss: 2.7066314810065815

Epoch: 5| Step: 10
Training loss: 2.835043430328369
Validation loss: 2.7060923153354275

Epoch: 44| Step: 0
Training loss: 2.8750905990600586
Validation loss: 2.705365070732691

Epoch: 5| Step: 1
Training loss: 3.5654540061950684
Validation loss: 2.705308432220131

Epoch: 5| Step: 2
Training loss: 3.126023769378662
Validation loss: 2.7079162341292187

Epoch: 5| Step: 3
Training loss: 2.935194492340088
Validation loss: 2.705502556216332

Epoch: 5| Step: 4
Training loss: 2.7016537189483643
Validation loss: 2.7107074132529636

Epoch: 5| Step: 5
Training loss: 2.7282040119171143
Validation loss: 2.6993609192550823

Epoch: 5| Step: 6
Training loss: 3.345019578933716
Validation loss: 2.7065431046229538

Epoch: 5| Step: 7
Training loss: 2.89805269241333
Validation loss: 2.7085514414695

Epoch: 5| Step: 8
Training loss: 2.9459495544433594
Validation loss: 2.711628824151972

Epoch: 5| Step: 9
Training loss: 2.242485523223877
Validation loss: 2.7234583259910665

Epoch: 5| Step: 10
Training loss: 1.8235833644866943
Validation loss: 2.7268282572428384

Epoch: 45| Step: 0
Training loss: 2.791508197784424
Validation loss: 2.711059012720662

Epoch: 5| Step: 1
Training loss: 2.823551893234253
Validation loss: 2.722722643165178

Epoch: 5| Step: 2
Training loss: 3.1773974895477295
Validation loss: 2.7229253758666334

Epoch: 5| Step: 3
Training loss: 2.119697332382202
Validation loss: 2.705618891664731

Epoch: 5| Step: 4
Training loss: 2.9588987827301025
Validation loss: 2.705239349795926

Epoch: 5| Step: 5
Training loss: 2.723245620727539
Validation loss: 2.7084945478746967

Epoch: 5| Step: 6
Training loss: 3.487438678741455
Validation loss: 2.7128987107225644

Epoch: 5| Step: 7
Training loss: 3.161613941192627
Validation loss: 2.70881732561255

Epoch: 5| Step: 8
Training loss: 2.361983060836792
Validation loss: 2.7096234213921333

Epoch: 5| Step: 9
Training loss: 2.8822593688964844
Validation loss: 2.708741541831724

Epoch: 5| Step: 10
Training loss: 2.8760323524475098
Validation loss: 2.7065186680004163

Epoch: 46| Step: 0
Training loss: 2.4658989906311035
Validation loss: 2.7049979112481557

Epoch: 5| Step: 1
Training loss: 2.316786527633667
Validation loss: 2.7007390837515555

Epoch: 5| Step: 2
Training loss: 3.3836166858673096
Validation loss: 2.701658818029588

Epoch: 5| Step: 3
Training loss: 3.272125244140625
Validation loss: 2.6981380703628703

Epoch: 5| Step: 4
Training loss: 3.3158926963806152
Validation loss: 2.6986147101207445

Epoch: 5| Step: 5
Training loss: 2.848865509033203
Validation loss: 2.697775299831103

Epoch: 5| Step: 6
Training loss: 3.044315814971924
Validation loss: 2.699049795827558

Epoch: 5| Step: 7
Training loss: 2.402895212173462
Validation loss: 2.7011865851699666

Epoch: 5| Step: 8
Training loss: 2.701603651046753
Validation loss: 2.6996806616424234

Epoch: 5| Step: 9
Training loss: 3.173279285430908
Validation loss: 2.697684108570058

Epoch: 5| Step: 10
Training loss: 2.3468453884124756
Validation loss: 2.699264987822502

Epoch: 47| Step: 0
Training loss: 3.403425693511963
Validation loss: 2.6951237852855394

Epoch: 5| Step: 1
Training loss: 2.129310131072998
Validation loss: 2.6998677253723145

Epoch: 5| Step: 2
Training loss: 3.1483349800109863
Validation loss: 2.6947189761746313

Epoch: 5| Step: 3
Training loss: 2.798551559448242
Validation loss: 2.693622450674734

Epoch: 5| Step: 4
Training loss: 2.676647663116455
Validation loss: 2.692126399727278

Epoch: 5| Step: 5
Training loss: 2.630803108215332
Validation loss: 2.692896230246431

Epoch: 5| Step: 6
Training loss: 3.260221481323242
Validation loss: 2.6911329377082085

Epoch: 5| Step: 7
Training loss: 2.678065776824951
Validation loss: 2.691432878535281

Epoch: 5| Step: 8
Training loss: 3.249037981033325
Validation loss: 2.694321652894379

Epoch: 5| Step: 9
Training loss: 2.668072462081909
Validation loss: 2.6934805121473087

Epoch: 5| Step: 10
Training loss: 2.626765489578247
Validation loss: 2.692407981041939

Epoch: 48| Step: 0
Training loss: 2.9392247200012207
Validation loss: 2.691916327322683

Epoch: 5| Step: 1
Training loss: 2.743340253829956
Validation loss: 2.6904750306119203

Epoch: 5| Step: 2
Training loss: 2.6374244689941406
Validation loss: 2.689476679730159

Epoch: 5| Step: 3
Training loss: 2.54883074760437
Validation loss: 2.6892551914338143

Epoch: 5| Step: 4
Training loss: 2.3988194465637207
Validation loss: 2.6876768886402087

Epoch: 5| Step: 5
Training loss: 2.7047581672668457
Validation loss: 2.690194022270941

Epoch: 5| Step: 6
Training loss: 3.0996994972229004
Validation loss: 2.6903162925474104

Epoch: 5| Step: 7
Training loss: 2.721499443054199
Validation loss: 2.6898914460212953

Epoch: 5| Step: 8
Training loss: 3.056375741958618
Validation loss: 2.6881162710087274

Epoch: 5| Step: 9
Training loss: 3.8977763652801514
Validation loss: 2.6876339784232517

Epoch: 5| Step: 10
Training loss: 2.455497980117798
Validation loss: 2.688011848798362

Epoch: 49| Step: 0
Training loss: 3.161267042160034
Validation loss: 2.6859159161967616

Epoch: 5| Step: 1
Training loss: 2.407092571258545
Validation loss: 2.6857771078745523

Epoch: 5| Step: 2
Training loss: 2.5650699138641357
Validation loss: 2.683232589434552

Epoch: 5| Step: 3
Training loss: 2.624295711517334
Validation loss: 2.685780297043503

Epoch: 5| Step: 4
Training loss: 2.6938650608062744
Validation loss: 2.688265021129321

Epoch: 5| Step: 5
Training loss: 2.5057151317596436
Validation loss: 2.690925359725952

Epoch: 5| Step: 6
Training loss: 2.9476120471954346
Validation loss: 2.689449034711366

Epoch: 5| Step: 7
Training loss: 2.804718494415283
Validation loss: 2.689114119416924

Epoch: 5| Step: 8
Training loss: 2.5789830684661865
Validation loss: 2.6866741231692735

Epoch: 5| Step: 9
Training loss: 3.4759573936462402
Validation loss: 2.682407192004624

Epoch: 5| Step: 10
Training loss: 3.5745139122009277
Validation loss: 2.6852986094772175

Epoch: 50| Step: 0
Training loss: 2.098637819290161
Validation loss: 2.685308387202601

Epoch: 5| Step: 1
Training loss: 2.9237751960754395
Validation loss: 2.6863402987039215

Epoch: 5| Step: 2
Training loss: 1.901023507118225
Validation loss: 2.6885398216145013

Epoch: 5| Step: 3
Training loss: 3.204868793487549
Validation loss: 2.690342769827894

Epoch: 5| Step: 4
Training loss: 2.7415881156921387
Validation loss: 2.6871359604661182

Epoch: 5| Step: 5
Training loss: 2.6215996742248535
Validation loss: 2.6823244992122857

Epoch: 5| Step: 6
Training loss: 3.3819127082824707
Validation loss: 2.679018871758574

Epoch: 5| Step: 7
Training loss: 3.1031081676483154
Validation loss: 2.679370172562138

Epoch: 5| Step: 8
Training loss: 3.6268134117126465
Validation loss: 2.6781484901264148

Epoch: 5| Step: 9
Training loss: 2.790874481201172
Validation loss: 2.679200062187769

Epoch: 5| Step: 10
Training loss: 2.828437328338623
Validation loss: 2.678040204509612

Testing loss: 2.772009982003106
