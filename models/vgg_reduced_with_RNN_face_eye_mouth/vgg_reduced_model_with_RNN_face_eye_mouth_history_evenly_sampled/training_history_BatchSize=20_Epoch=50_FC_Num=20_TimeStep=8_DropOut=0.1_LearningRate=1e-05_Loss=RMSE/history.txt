Epoch: 1| Step: 0
Training loss: 5.239947731689216
Validation loss: 5.7891070940284255

Epoch: 5| Step: 1
Training loss: 5.7052543114056276
Validation loss: 5.781386116906476

Epoch: 5| Step: 2
Training loss: 5.693354684817965
Validation loss: 5.774717559108393

Epoch: 5| Step: 3
Training loss: 5.7292151246766965
Validation loss: 5.768511546055544

Epoch: 5| Step: 4
Training loss: 4.873012626695782
Validation loss: 5.762501730133517

Epoch: 5| Step: 5
Training loss: 5.8134607320935565
Validation loss: 5.756144019196059

Epoch: 5| Step: 6
Training loss: 6.047192626812171
Validation loss: 5.749306521478207

Epoch: 5| Step: 7
Training loss: 5.711393700785395
Validation loss: 5.742381934152164

Epoch: 5| Step: 8
Training loss: 6.508352341992521
Validation loss: 5.734561923937174

Epoch: 5| Step: 9
Training loss: 6.622290291034551
Validation loss: 5.726342939703212

Epoch: 5| Step: 10
Training loss: 5.47740438958508
Validation loss: 5.717224222388084

Epoch: 2| Step: 0
Training loss: 5.554569033876491
Validation loss: 5.707150500739413

Epoch: 5| Step: 1
Training loss: 5.592755106673949
Validation loss: 5.696282033544182

Epoch: 5| Step: 2
Training loss: 4.899768021989564
Validation loss: 5.684404782445846

Epoch: 5| Step: 3
Training loss: 5.0724837205229845
Validation loss: 5.671788180762612

Epoch: 5| Step: 4
Training loss: 6.212995310635641
Validation loss: 5.65839188928278

Epoch: 5| Step: 5
Training loss: 5.856850367563384
Validation loss: 5.642996151846406

Epoch: 5| Step: 6
Training loss: 6.414828478927749
Validation loss: 5.6277428979794974

Epoch: 5| Step: 7
Training loss: 5.743328038303785
Validation loss: 5.610681139578935

Epoch: 5| Step: 8
Training loss: 5.631850246400021
Validation loss: 5.591792081292615

Epoch: 5| Step: 9
Training loss: 5.399195483994782
Validation loss: 5.571134463037445

Epoch: 5| Step: 10
Training loss: 5.910549637333305
Validation loss: 5.549458258907207

Epoch: 3| Step: 0
Training loss: 5.495981829384164
Validation loss: 5.526905593020099

Epoch: 5| Step: 1
Training loss: 5.189681180595354
Validation loss: 5.501932399459878

Epoch: 5| Step: 2
Training loss: 5.192867948731124
Validation loss: 5.475826186369685

Epoch: 5| Step: 3
Training loss: 5.975059489827898
Validation loss: 5.449609870942405

Epoch: 5| Step: 4
Training loss: 6.230596405921855
Validation loss: 5.42059218320899

Epoch: 5| Step: 5
Training loss: 5.158722255919648
Validation loss: 5.390858676738667

Epoch: 5| Step: 6
Training loss: 5.907888033953294
Validation loss: 5.359768328342655

Epoch: 5| Step: 7
Training loss: 6.265624391170482
Validation loss: 5.328671516939187

Epoch: 5| Step: 8
Training loss: 5.028130363807638
Validation loss: 5.294423759105639

Epoch: 5| Step: 9
Training loss: 4.447933128499189
Validation loss: 5.2598629200597005

Epoch: 5| Step: 10
Training loss: 4.350257664207388
Validation loss: 5.225816090639604

Epoch: 4| Step: 0
Training loss: 5.972845938984182
Validation loss: 5.189252853519787

Epoch: 5| Step: 1
Training loss: 5.517878344984937
Validation loss: 5.152154376174162

Epoch: 5| Step: 2
Training loss: 5.955289832556103
Validation loss: 5.1125202696747145

Epoch: 5| Step: 3
Training loss: 4.788270072656333
Validation loss: 5.072664578240633

Epoch: 5| Step: 4
Training loss: 4.055553659818952
Validation loss: 5.030898779801791

Epoch: 5| Step: 5
Training loss: 4.758783351018787
Validation loss: 4.98775755185685

Epoch: 5| Step: 6
Training loss: 4.701762360026412
Validation loss: 4.941391769012474

Epoch: 5| Step: 7
Training loss: 3.997351723426555
Validation loss: 4.898665482371975

Epoch: 5| Step: 8
Training loss: 5.441040289649926
Validation loss: 4.852974890554764

Epoch: 5| Step: 9
Training loss: 5.066255095145419
Validation loss: 4.809374325456295

Epoch: 5| Step: 10
Training loss: 4.875471043448808
Validation loss: 4.766590632623852

Epoch: 5| Step: 0
Training loss: 5.087682937219824
Validation loss: 4.725969528472244

Epoch: 5| Step: 1
Training loss: 4.819272119163321
Validation loss: 4.6909721351052465

Epoch: 5| Step: 2
Training loss: 5.691352964425404
Validation loss: 4.652573579876405

Epoch: 5| Step: 3
Training loss: 4.850340266925204
Validation loss: 4.615499001679723

Epoch: 5| Step: 4
Training loss: 4.297961066579592
Validation loss: 4.584601844067073

Epoch: 5| Step: 5
Training loss: 4.9331284497649035
Validation loss: 4.550956567285564

Epoch: 5| Step: 6
Training loss: 4.081199451735206
Validation loss: 4.522463856871818

Epoch: 5| Step: 7
Training loss: 5.221673934416833
Validation loss: 4.495192707069326

Epoch: 5| Step: 8
Training loss: 3.266613970221204
Validation loss: 4.466994248378655

Epoch: 5| Step: 9
Training loss: 4.2633855621343955
Validation loss: 4.44405875241556

Epoch: 5| Step: 10
Training loss: 4.324685613418301
Validation loss: 4.421571794294693

Epoch: 6| Step: 0
Training loss: 4.8610024624747465
Validation loss: 4.40110402561529

Epoch: 5| Step: 1
Training loss: 4.521485640523581
Validation loss: 4.381898515161122

Epoch: 5| Step: 2
Training loss: 4.9115791292461815
Validation loss: 4.362983585277459

Epoch: 5| Step: 3
Training loss: 3.9545272330459245
Validation loss: 4.348091678234021

Epoch: 5| Step: 4
Training loss: 4.691110669940217
Validation loss: 4.331684602697302

Epoch: 5| Step: 5
Training loss: 4.189039032929769
Validation loss: 4.319778606103729

Epoch: 5| Step: 6
Training loss: 4.670416664960507
Validation loss: 4.308260652570079

Epoch: 5| Step: 7
Training loss: 4.436203888207139
Validation loss: 4.294679918184125

Epoch: 5| Step: 8
Training loss: 4.682814226987086
Validation loss: 4.2849288546415165

Epoch: 5| Step: 9
Training loss: 3.853063325782834
Validation loss: 4.271775214988649

Epoch: 5| Step: 10
Training loss: 3.97213216529846
Validation loss: 4.260205821626169

Epoch: 7| Step: 0
Training loss: 4.186239252039638
Validation loss: 4.24972151556282

Epoch: 5| Step: 1
Training loss: 3.7566852742647914
Validation loss: 4.239696547835937

Epoch: 5| Step: 2
Training loss: 5.24019797671854
Validation loss: 4.2320083478307975

Epoch: 5| Step: 3
Training loss: 3.9040826506855346
Validation loss: 4.222410254149613

Epoch: 5| Step: 4
Training loss: 4.415924921669113
Validation loss: 4.21174616161228

Epoch: 5| Step: 5
Training loss: 5.280243907554517
Validation loss: 4.201194201683393

Epoch: 5| Step: 6
Training loss: 4.456029968393798
Validation loss: 4.18997164253297

Epoch: 5| Step: 7
Training loss: 4.103418943708757
Validation loss: 4.176549227657822

Epoch: 5| Step: 8
Training loss: 3.9309781270103983
Validation loss: 4.163445143269252

Epoch: 5| Step: 9
Training loss: 3.972622401450563
Validation loss: 4.149518063322321

Epoch: 5| Step: 10
Training loss: 4.107650104735622
Validation loss: 4.140832396699934

Epoch: 8| Step: 0
Training loss: 4.958969759234074
Validation loss: 4.127735522352537

Epoch: 5| Step: 1
Training loss: 3.6573436438201563
Validation loss: 4.116315601586786

Epoch: 5| Step: 2
Training loss: 4.347602946733555
Validation loss: 4.104515590965365

Epoch: 5| Step: 3
Training loss: 4.016739627497334
Validation loss: 4.091447059855326

Epoch: 5| Step: 4
Training loss: 4.224943686567086
Validation loss: 4.078288453665469

Epoch: 5| Step: 5
Training loss: 4.61263767440145
Validation loss: 4.066876288040679

Epoch: 5| Step: 6
Training loss: 4.179282937123338
Validation loss: 4.0580331456902305

Epoch: 5| Step: 7
Training loss: 4.244986100999704
Validation loss: 4.045762693189923

Epoch: 5| Step: 8
Training loss: 3.308312558381955
Validation loss: 4.036932696183784

Epoch: 5| Step: 9
Training loss: 4.190336946035901
Validation loss: 4.027460092150133

Epoch: 5| Step: 10
Training loss: 4.460745304597131
Validation loss: 4.01907318438082

Epoch: 9| Step: 0
Training loss: 4.278135182916798
Validation loss: 4.009924170249401

Epoch: 5| Step: 1
Training loss: 4.232266847933757
Validation loss: 4.004291140037108

Epoch: 5| Step: 2
Training loss: 4.394187486554504
Validation loss: 3.9979245739001894

Epoch: 5| Step: 3
Training loss: 3.4259481356782
Validation loss: 3.9918889902837336

Epoch: 5| Step: 4
Training loss: 5.053276985444789
Validation loss: 3.9845733470957843

Epoch: 5| Step: 5
Training loss: 3.775215314573027
Validation loss: 3.973245937192569

Epoch: 5| Step: 6
Training loss: 4.128704834846062
Validation loss: 3.964286184596614

Epoch: 5| Step: 7
Training loss: 4.630904063536483
Validation loss: 3.9624135480094584

Epoch: 5| Step: 8
Training loss: 3.7426041468703177
Validation loss: 3.953816261474019

Epoch: 5| Step: 9
Training loss: 3.739741854198945
Validation loss: 3.9496452168058696

Epoch: 5| Step: 10
Training loss: 3.738342986199996
Validation loss: 3.9444096118044327

Epoch: 10| Step: 0
Training loss: 3.771108979043662
Validation loss: 3.9333921361010478

Epoch: 5| Step: 1
Training loss: 4.506908623635149
Validation loss: 3.927864085660066

Epoch: 5| Step: 2
Training loss: 3.869633065110147
Validation loss: 3.9157644492490333

Epoch: 5| Step: 3
Training loss: 4.893029545042837
Validation loss: 3.907379879539394

Epoch: 5| Step: 4
Training loss: 4.33078901471663
Validation loss: 3.897742807600277

Epoch: 5| Step: 5
Training loss: 3.8008065923647676
Validation loss: 3.891617653396177

Epoch: 5| Step: 6
Training loss: 3.5935733917626984
Validation loss: 3.881748833778362

Epoch: 5| Step: 7
Training loss: 4.7038689211922975
Validation loss: 3.8725587615674444

Epoch: 5| Step: 8
Training loss: 3.8083629988190366
Validation loss: 3.8656311887702706

Epoch: 5| Step: 9
Training loss: 3.069387670330414
Validation loss: 3.861010061575446

Epoch: 5| Step: 10
Training loss: 3.907371665130894
Validation loss: 3.8524370742046163

Epoch: 11| Step: 0
Training loss: 3.6333273902167846
Validation loss: 3.84584080319828

Epoch: 5| Step: 1
Training loss: 4.110851182252522
Validation loss: 3.841519042902758

Epoch: 5| Step: 2
Training loss: 3.8446688910536806
Validation loss: 3.8329029635277005

Epoch: 5| Step: 3
Training loss: 4.457606794155225
Validation loss: 3.825682501130459

Epoch: 5| Step: 4
Training loss: 4.976392710138296
Validation loss: 3.8233572385345873

Epoch: 5| Step: 5
Training loss: 3.8414575206786696
Validation loss: 3.8135274534456407

Epoch: 5| Step: 6
Training loss: 3.275130605641367
Validation loss: 3.8074011513873764

Epoch: 5| Step: 7
Training loss: 4.082711049106714
Validation loss: 3.8019572391185728

Epoch: 5| Step: 8
Training loss: 4.183905581865914
Validation loss: 3.793537841569034

Epoch: 5| Step: 9
Training loss: 3.6296391234702625
Validation loss: 3.7896535361916954

Epoch: 5| Step: 10
Training loss: 3.4993247334432813
Validation loss: 3.78610538660621

Epoch: 12| Step: 0
Training loss: 3.58396361966061
Validation loss: 3.7797776558109737

Epoch: 5| Step: 1
Training loss: 3.55801028379141
Validation loss: 3.7722972941741113

Epoch: 5| Step: 2
Training loss: 4.410416168851949
Validation loss: 3.764184901671819

Epoch: 5| Step: 3
Training loss: 4.473774892519787
Validation loss: 3.7540063874874257

Epoch: 5| Step: 4
Training loss: 4.315248801969638
Validation loss: 3.7482760715617056

Epoch: 5| Step: 5
Training loss: 3.4073963161263423
Validation loss: 3.7430094230067086

Epoch: 5| Step: 6
Training loss: 3.922670564851395
Validation loss: 3.7414271858892807

Epoch: 5| Step: 7
Training loss: 4.048303064950606
Validation loss: 3.7251955218747947

Epoch: 5| Step: 8
Training loss: 3.14146814368351
Validation loss: 3.7194856112761463

Epoch: 5| Step: 9
Training loss: 3.996392292046504
Validation loss: 3.716502008515926

Epoch: 5| Step: 10
Training loss: 4.1108367988782675
Validation loss: 3.7086102524097924

Epoch: 13| Step: 0
Training loss: 3.9597665835474696
Validation loss: 3.7004396896273954

Epoch: 5| Step: 1
Training loss: 4.690888057806754
Validation loss: 3.685294885036029

Epoch: 5| Step: 2
Training loss: 3.9072227792642895
Validation loss: 3.6773316245704586

Epoch: 5| Step: 3
Training loss: 4.387757366054912
Validation loss: 3.671566800719361

Epoch: 5| Step: 4
Training loss: 3.828956731631994
Validation loss: 3.6363090470370563

Epoch: 5| Step: 5
Training loss: 3.5800448268875646
Validation loss: 3.6319705703353993

Epoch: 5| Step: 6
Training loss: 3.5734424852904394
Validation loss: 3.6266391458393077

Epoch: 5| Step: 7
Training loss: 3.738250636630137
Validation loss: 3.6200820835859933

Epoch: 5| Step: 8
Training loss: 3.504427017416392
Validation loss: 3.6146712545877477

Epoch: 5| Step: 9
Training loss: 3.900018467003554
Validation loss: 3.6047431806693084

Epoch: 5| Step: 10
Training loss: 2.6714382595472337
Validation loss: 3.60374644457559

Epoch: 14| Step: 0
Training loss: 3.344924292741156
Validation loss: 3.601118111647593

Epoch: 5| Step: 1
Training loss: 3.4949888049643554
Validation loss: 3.612061744480174

Epoch: 5| Step: 2
Training loss: 3.9744992402585044
Validation loss: 3.5952562354552584

Epoch: 5| Step: 3
Training loss: 3.759296592091341
Validation loss: 3.5768546588876915

Epoch: 5| Step: 4
Training loss: 4.184483594674684
Validation loss: 3.5786560871003403

Epoch: 5| Step: 5
Training loss: 3.3742006556208377
Validation loss: 3.5764857731082755

Epoch: 5| Step: 6
Training loss: 4.056746884140348
Validation loss: 3.567575468615272

Epoch: 5| Step: 7
Training loss: 3.055901873835645
Validation loss: 3.55554210293269

Epoch: 5| Step: 8
Training loss: 3.8945061502059155
Validation loss: 3.5549385797985136

Epoch: 5| Step: 9
Training loss: 4.148467615165527
Validation loss: 3.546827733650672

Epoch: 5| Step: 10
Training loss: 4.115935104377529
Validation loss: 3.5414218714236254

Epoch: 15| Step: 0
Training loss: 3.7320603096229683
Validation loss: 3.5354961262022644

Epoch: 5| Step: 1
Training loss: 4.072343842923876
Validation loss: 3.5301142884576646

Epoch: 5| Step: 2
Training loss: 3.692468431837595
Validation loss: 3.5237727459457857

Epoch: 5| Step: 3
Training loss: 3.2160092138186887
Validation loss: 3.517197893830657

Epoch: 5| Step: 4
Training loss: 4.0103214137007175
Validation loss: 3.5110426428301076

Epoch: 5| Step: 5
Training loss: 4.75841760154347
Validation loss: 3.505911986189653

Epoch: 5| Step: 6
Training loss: 3.670415060495011
Validation loss: 3.50241469516428

Epoch: 5| Step: 7
Training loss: 3.6586955442243547
Validation loss: 3.5035660898548406

Epoch: 5| Step: 8
Training loss: 3.473163717842495
Validation loss: 3.4984907200987827

Epoch: 5| Step: 9
Training loss: 2.867110331897508
Validation loss: 3.491622755443319

Epoch: 5| Step: 10
Training loss: 3.4350016444839473
Validation loss: 3.4973925093569194

Epoch: 16| Step: 0
Training loss: 3.9686286487199114
Validation loss: 3.4968530802476083

Epoch: 5| Step: 1
Training loss: 2.6988894403857637
Validation loss: 3.4897188667543517

Epoch: 5| Step: 2
Training loss: 4.036831562465879
Validation loss: 3.4861720262211575

Epoch: 5| Step: 3
Training loss: 4.3828901804195555
Validation loss: 3.478126795397461

Epoch: 5| Step: 4
Training loss: 3.3601933391894874
Validation loss: 3.4729566400919634

Epoch: 5| Step: 5
Training loss: 4.366111663802361
Validation loss: 3.47207133161497

Epoch: 5| Step: 6
Training loss: 3.17756600804352
Validation loss: 3.4697814489870344

Epoch: 5| Step: 7
Training loss: 3.70064542141424
Validation loss: 3.46439572294231

Epoch: 5| Step: 8
Training loss: 3.7237019626250327
Validation loss: 3.4572527329279037

Epoch: 5| Step: 9
Training loss: 3.290082397356711
Validation loss: 3.453980192549225

Epoch: 5| Step: 10
Training loss: 3.5024717322440244
Validation loss: 3.451208402823602

Epoch: 17| Step: 0
Training loss: 3.6935315992202473
Validation loss: 3.4500729015602536

Epoch: 5| Step: 1
Training loss: 2.821773583838233
Validation loss: 3.448634790957594

Epoch: 5| Step: 2
Training loss: 4.115418606089146
Validation loss: 3.4485802429054804

Epoch: 5| Step: 3
Training loss: 2.7184881325372023
Validation loss: 3.4456068485272566

Epoch: 5| Step: 4
Training loss: 3.4028984169540526
Validation loss: 3.448421263767473

Epoch: 5| Step: 5
Training loss: 3.4731186858156344
Validation loss: 3.4416914935235665

Epoch: 5| Step: 6
Training loss: 3.5430021273923944
Validation loss: 3.4335084474060076

Epoch: 5| Step: 7
Training loss: 3.0987922346122945
Validation loss: 3.432855580325937

Epoch: 5| Step: 8
Training loss: 4.631949899274037
Validation loss: 3.4285747281279364

Epoch: 5| Step: 9
Training loss: 3.4783379639498917
Validation loss: 3.4257399684604684

Epoch: 5| Step: 10
Training loss: 4.838147867668857
Validation loss: 3.426206557690608

Epoch: 18| Step: 0
Training loss: 1.9701674671929288
Validation loss: 3.4233584003537416

Epoch: 5| Step: 1
Training loss: 3.924210419172299
Validation loss: 3.42108649867758

Epoch: 5| Step: 2
Training loss: 4.205899482168061
Validation loss: 3.4195943684845087

Epoch: 5| Step: 3
Training loss: 3.9183192452897213
Validation loss: 3.4151651523142195

Epoch: 5| Step: 4
Training loss: 3.669409650672468
Validation loss: 3.4136525557034085

Epoch: 5| Step: 5
Training loss: 4.257097488702874
Validation loss: 3.4115170108445922

Epoch: 5| Step: 6
Training loss: 3.63157819883221
Validation loss: 3.4118220910861523

Epoch: 5| Step: 7
Training loss: 3.2494033852739017
Validation loss: 3.4068950995412695

Epoch: 5| Step: 8
Training loss: 3.5962949283406784
Validation loss: 3.4086553678162157

Epoch: 5| Step: 9
Training loss: 3.7668242384998534
Validation loss: 3.40363580164171

Epoch: 5| Step: 10
Training loss: 3.226082163379899
Validation loss: 3.4005033485395906

Epoch: 19| Step: 0
Training loss: 3.714535416604081
Validation loss: 3.400014332108327

Epoch: 5| Step: 1
Training loss: 3.7223242244377284
Validation loss: 3.398519002945826

Epoch: 5| Step: 2
Training loss: 4.190407498011338
Validation loss: 3.3955862042308547

Epoch: 5| Step: 3
Training loss: 3.4025522862326265
Validation loss: 3.393754492031755

Epoch: 5| Step: 4
Training loss: 3.9452610125817356
Validation loss: 3.390833686873736

Epoch: 5| Step: 5
Training loss: 4.158744579663655
Validation loss: 3.3894748361620946

Epoch: 5| Step: 6
Training loss: 3.341907885082701
Validation loss: 3.3887997719823595

Epoch: 5| Step: 7
Training loss: 3.2289408122828878
Validation loss: 3.3873747422970144

Epoch: 5| Step: 8
Training loss: 3.3103100717298513
Validation loss: 3.387588522705377

Epoch: 5| Step: 9
Training loss: 3.3893710159990214
Validation loss: 3.3838627618687656

Epoch: 5| Step: 10
Training loss: 3.1598045049626915
Validation loss: 3.3832825694530975

Epoch: 20| Step: 0
Training loss: 3.4102162359146377
Validation loss: 3.382455453760872

Epoch: 5| Step: 1
Training loss: 3.2327966939503794
Validation loss: 3.3814801982904004

Epoch: 5| Step: 2
Training loss: 3.9343885207909675
Validation loss: 3.3786766962975623

Epoch: 5| Step: 3
Training loss: 3.9817026788214838
Validation loss: 3.376488786032566

Epoch: 5| Step: 4
Training loss: 3.751407994747332
Validation loss: 3.3753592065659554

Epoch: 5| Step: 5
Training loss: 3.425689800438108
Validation loss: 3.372835988524466

Epoch: 5| Step: 6
Training loss: 4.045691829031011
Validation loss: 3.371678851606742

Epoch: 5| Step: 7
Training loss: 3.4161517212651193
Validation loss: 3.369166910057977

Epoch: 5| Step: 8
Training loss: 3.009967458048466
Validation loss: 3.3670312090357326

Epoch: 5| Step: 9
Training loss: 4.068797702773358
Validation loss: 3.3665658396784575

Epoch: 5| Step: 10
Training loss: 3.1078395406966837
Validation loss: 3.3652843823269074

Epoch: 21| Step: 0
Training loss: 3.46691969962881
Validation loss: 3.3614512455654384

Epoch: 5| Step: 1
Training loss: 2.9447961653162396
Validation loss: 3.361503608553503

Epoch: 5| Step: 2
Training loss: 3.786654810506321
Validation loss: 3.3600181137618255

Epoch: 5| Step: 3
Training loss: 3.2615069109258514
Validation loss: 3.362649830199844

Epoch: 5| Step: 4
Training loss: 3.2140900294970587
Validation loss: 3.359918034689594

Epoch: 5| Step: 5
Training loss: 3.582373882450992
Validation loss: 3.355950458201762

Epoch: 5| Step: 6
Training loss: 3.8118732124771
Validation loss: 3.3558613531495314

Epoch: 5| Step: 7
Training loss: 3.972519893800486
Validation loss: 3.3529489979888245

Epoch: 5| Step: 8
Training loss: 3.035493849115827
Validation loss: 3.3547507355686115

Epoch: 5| Step: 9
Training loss: 4.022667316681587
Validation loss: 3.352589890811947

Epoch: 5| Step: 10
Training loss: 4.257474049406769
Validation loss: 3.3572807161835896

Epoch: 22| Step: 0
Training loss: 3.752802882160356
Validation loss: 3.350964451421489

Epoch: 5| Step: 1
Training loss: 3.744302108378622
Validation loss: 3.3481794522725106

Epoch: 5| Step: 2
Training loss: 4.458584834815644
Validation loss: 3.3482532371681226

Epoch: 5| Step: 3
Training loss: 3.4739821555690114
Validation loss: 3.3481614204135854

Epoch: 5| Step: 4
Training loss: 3.7862159340082533
Validation loss: 3.344712661727452

Epoch: 5| Step: 5
Training loss: 2.9078735410749537
Validation loss: 3.3460801823956694

Epoch: 5| Step: 6
Training loss: 2.7443131687858773
Validation loss: 3.3419493383956693

Epoch: 5| Step: 7
Training loss: 3.8367307507034623
Validation loss: 3.340568102682416

Epoch: 5| Step: 8
Training loss: 3.1175506303801064
Validation loss: 3.3393757111561206

Epoch: 5| Step: 9
Training loss: 3.916283622570581
Validation loss: 3.3385246972262657

Epoch: 5| Step: 10
Training loss: 3.256568433307587
Validation loss: 3.3386666705473798

Epoch: 23| Step: 0
Training loss: 2.998138326933766
Validation loss: 3.3356520806918906

Epoch: 5| Step: 1
Training loss: 3.4627559525949048
Validation loss: 3.335514240119102

Epoch: 5| Step: 2
Training loss: 3.1276718924265063
Validation loss: 3.3335835260407936

Epoch: 5| Step: 3
Training loss: 3.228435573058513
Validation loss: 3.336141168703157

Epoch: 5| Step: 4
Training loss: 3.9031432958438286
Validation loss: 3.3351640893364967

Epoch: 5| Step: 5
Training loss: 3.5220386917267827
Validation loss: 3.332967594037322

Epoch: 5| Step: 6
Training loss: 3.8712255492037166
Validation loss: 3.3316744696427727

Epoch: 5| Step: 7
Training loss: 3.507470468952828
Validation loss: 3.3304963164900796

Epoch: 5| Step: 8
Training loss: 4.227622190183812
Validation loss: 3.3317202161639523

Epoch: 5| Step: 9
Training loss: 3.4812476659797773
Validation loss: 3.330213888839476

Epoch: 5| Step: 10
Training loss: 3.80917526109508
Validation loss: 3.328640860996056

Epoch: 24| Step: 0
Training loss: 4.117806838646076
Validation loss: 3.3285816431462516

Epoch: 5| Step: 1
Training loss: 3.701459936844177
Validation loss: 3.3259819757465

Epoch: 5| Step: 2
Training loss: 3.5958227399815144
Validation loss: 3.3264255046545443

Epoch: 5| Step: 3
Training loss: 3.375117970983266
Validation loss: 3.325047135618456

Epoch: 5| Step: 4
Training loss: 3.205563840262206
Validation loss: 3.3249625918855945

Epoch: 5| Step: 5
Training loss: 3.741363753282351
Validation loss: 3.325849481653209

Epoch: 5| Step: 6
Training loss: 3.6349401006787527
Validation loss: 3.322013420274296

Epoch: 5| Step: 7
Training loss: 3.8092461129995074
Validation loss: 3.323015298278703

Epoch: 5| Step: 8
Training loss: 2.810343784738004
Validation loss: 3.3216897419384637

Epoch: 5| Step: 9
Training loss: 3.422422739721496
Validation loss: 3.3222044600286083

Epoch: 5| Step: 10
Training loss: 3.645069340175841
Validation loss: 3.32054120602566

Epoch: 25| Step: 0
Training loss: 3.6551483320412093
Validation loss: 3.3180193851918403

Epoch: 5| Step: 1
Training loss: 3.876211284701212
Validation loss: 3.318224745495113

Epoch: 5| Step: 2
Training loss: 3.7944159688357395
Validation loss: 3.3177389754345263

Epoch: 5| Step: 3
Training loss: 3.058256518016871
Validation loss: 3.3188122172582055

Epoch: 5| Step: 4
Training loss: 3.6866032431345306
Validation loss: 3.317450914702386

Epoch: 5| Step: 5
Training loss: 3.7223214061927776
Validation loss: 3.3173882606658163

Epoch: 5| Step: 6
Training loss: 2.9273713174972134
Validation loss: 3.314814229133476

Epoch: 5| Step: 7
Training loss: 3.6287356891934643
Validation loss: 3.315376079512005

Epoch: 5| Step: 8
Training loss: 4.335856998830409
Validation loss: 3.317288523038437

Epoch: 5| Step: 9
Training loss: 2.483231383242844
Validation loss: 3.319590608416532

Epoch: 5| Step: 10
Training loss: 3.6057386700239866
Validation loss: 3.3176437533656795

Epoch: 26| Step: 0
Training loss: 3.4183819504703914
Validation loss: 3.3166210089999764

Epoch: 5| Step: 1
Training loss: 3.4697294484842347
Validation loss: 3.3145710806566235

Epoch: 5| Step: 2
Training loss: 3.435422512317046
Validation loss: 3.314722563489692

Epoch: 5| Step: 3
Training loss: 3.4937357020213495
Validation loss: 3.3230183039643535

Epoch: 5| Step: 4
Training loss: 3.7929309092715258
Validation loss: 3.311293837657008

Epoch: 5| Step: 5
Training loss: 3.3014644841143097
Validation loss: 3.3109988748433645

Epoch: 5| Step: 6
Training loss: 3.8103157415245605
Validation loss: 3.3152701770626782

Epoch: 5| Step: 7
Training loss: 4.313972332380668
Validation loss: 3.3164635741760042

Epoch: 5| Step: 8
Training loss: 3.3537371500617192
Validation loss: 3.315602054875898

Epoch: 5| Step: 9
Training loss: 2.6638503004118212
Validation loss: 3.3138026723198957

Epoch: 5| Step: 10
Training loss: 3.8463741122042663
Validation loss: 3.31021927189586

Epoch: 27| Step: 0
Training loss: 3.197753272505759
Validation loss: 3.308969462425405

Epoch: 5| Step: 1
Training loss: 3.2368420024279283
Validation loss: 3.3063826879184983

Epoch: 5| Step: 2
Training loss: 4.108418748649876
Validation loss: 3.3083495895181834

Epoch: 5| Step: 3
Training loss: 2.8805900628886087
Validation loss: 3.3066090484042387

Epoch: 5| Step: 4
Training loss: 3.5522712963560426
Validation loss: 3.3068210402930736

Epoch: 5| Step: 5
Training loss: 3.7156692694745033
Validation loss: 3.3049325965800738

Epoch: 5| Step: 6
Training loss: 4.331276087386489
Validation loss: 3.304644912115224

Epoch: 5| Step: 7
Training loss: 3.869118071812424
Validation loss: 3.303323364541612

Epoch: 5| Step: 8
Training loss: 2.985404590938092
Validation loss: 3.302006621844712

Epoch: 5| Step: 9
Training loss: 3.8710654187440814
Validation loss: 3.2997058526007077

Epoch: 5| Step: 10
Training loss: 2.798953599905695
Validation loss: 3.3018273006881227

Epoch: 28| Step: 0
Training loss: 4.466225291028177
Validation loss: 3.303078490052729

Epoch: 5| Step: 1
Training loss: 4.0532390969598655
Validation loss: 3.304856494748469

Epoch: 5| Step: 2
Training loss: 4.192167954145172
Validation loss: 3.3069733037302917

Epoch: 5| Step: 3
Training loss: 3.53800925104065
Validation loss: 3.302276483530131

Epoch: 5| Step: 4
Training loss: 2.8514875846323617
Validation loss: 3.298289046454987

Epoch: 5| Step: 5
Training loss: 3.2876428725378055
Validation loss: 3.2954193044557707

Epoch: 5| Step: 6
Training loss: 2.9949455597631194
Validation loss: 3.2950866869242077

Epoch: 5| Step: 7
Training loss: 3.297981401982101
Validation loss: 3.297534319357817

Epoch: 5| Step: 8
Training loss: 3.5880950221616934
Validation loss: 3.2960691180044277

Epoch: 5| Step: 9
Training loss: 3.0081950155004478
Validation loss: 3.293684587897183

Epoch: 5| Step: 10
Training loss: 3.2208345940420062
Validation loss: 3.2947268972092933

Epoch: 29| Step: 0
Training loss: 3.699047821833074
Validation loss: 3.2925877391615983

Epoch: 5| Step: 1
Training loss: 3.732483452608869
Validation loss: 3.293528370828906

Epoch: 5| Step: 2
Training loss: 4.251987217077382
Validation loss: 3.291428256847571

Epoch: 5| Step: 3
Training loss: 2.9204638332223305
Validation loss: 3.2902703005849525

Epoch: 5| Step: 4
Training loss: 3.218632816292614
Validation loss: 3.2902353200977483

Epoch: 5| Step: 5
Training loss: 3.3944367109156155
Validation loss: 3.2886958336945753

Epoch: 5| Step: 6
Training loss: 3.9054420551166835
Validation loss: 3.2879997728524

Epoch: 5| Step: 7
Training loss: 3.705817165478167
Validation loss: 3.2889135495204265

Epoch: 5| Step: 8
Training loss: 3.3480072015573215
Validation loss: 3.2875196945029095

Epoch: 5| Step: 9
Training loss: 3.0900354145082285
Validation loss: 3.2878644974725773

Epoch: 5| Step: 10
Training loss: 3.3690030542565323
Validation loss: 3.288505881428117

Epoch: 30| Step: 0
Training loss: 3.8019744160697897
Validation loss: 3.2854268465430554

Epoch: 5| Step: 1
Training loss: 3.4011256318099297
Validation loss: 3.286781147099163

Epoch: 5| Step: 2
Training loss: 2.9980877503829975
Validation loss: 3.2860883473920537

Epoch: 5| Step: 3
Training loss: 4.160843913235931
Validation loss: 3.286182867402554

Epoch: 5| Step: 4
Training loss: 3.2094265615152757
Validation loss: 3.2846436959049856

Epoch: 5| Step: 5
Training loss: 3.9287111802448345
Validation loss: 3.2836973892854564

Epoch: 5| Step: 6
Training loss: 2.9351301982536793
Validation loss: 3.2845136327962843

Epoch: 5| Step: 7
Training loss: 3.992633951384847
Validation loss: 3.281302702949762

Epoch: 5| Step: 8
Training loss: 3.938662766023571
Validation loss: 3.282051743993409

Epoch: 5| Step: 9
Training loss: 3.41203810252194
Validation loss: 3.2828855033488793

Epoch: 5| Step: 10
Training loss: 2.4884153895849157
Validation loss: 3.2804714968911313

Epoch: 31| Step: 0
Training loss: 3.5880297704969184
Validation loss: 3.2814534567138796

Epoch: 5| Step: 1
Training loss: 3.372968415461618
Validation loss: 3.2808184924496873

Epoch: 5| Step: 2
Training loss: 2.946125919932173
Validation loss: 3.282590197250593

Epoch: 5| Step: 3
Training loss: 3.3198032123200125
Validation loss: 3.2781338929009833

Epoch: 5| Step: 4
Training loss: 3.4649484784147724
Validation loss: 3.2830016227262546

Epoch: 5| Step: 5
Training loss: 3.611863768626618
Validation loss: 3.286834581890577

Epoch: 5| Step: 6
Training loss: 4.062986374130141
Validation loss: 3.291786785641775

Epoch: 5| Step: 7
Training loss: 3.0793352410436574
Validation loss: 3.2776573361913983

Epoch: 5| Step: 8
Training loss: 4.052627540007513
Validation loss: 3.2813565004002805

Epoch: 5| Step: 9
Training loss: 3.2236826608820057
Validation loss: 3.2755218416372944

Epoch: 5| Step: 10
Training loss: 3.9001086977947494
Validation loss: 3.2770252600302783

Epoch: 32| Step: 0
Training loss: 3.0832674861440874
Validation loss: 3.2747051637030813

Epoch: 5| Step: 1
Training loss: 3.2228385365112344
Validation loss: 3.276461462147522

Epoch: 5| Step: 2
Training loss: 3.658543837160196
Validation loss: 3.279788065155291

Epoch: 5| Step: 3
Training loss: 3.477300467015014
Validation loss: 3.276811612777612

Epoch: 5| Step: 4
Training loss: 3.8169199852535716
Validation loss: 3.276527403337496

Epoch: 5| Step: 5
Training loss: 3.396330221756967
Validation loss: 3.2743469881048446

Epoch: 5| Step: 6
Training loss: 3.370273954536261
Validation loss: 3.275406348184558

Epoch: 5| Step: 7
Training loss: 3.5078182092972745
Validation loss: 3.274931055298426

Epoch: 5| Step: 8
Training loss: 3.5644576733703857
Validation loss: 3.272754529512907

Epoch: 5| Step: 9
Training loss: 3.6277237229135904
Validation loss: 3.2707604655597047

Epoch: 5| Step: 10
Training loss: 3.9543599849564783
Validation loss: 3.2701761716694198

Epoch: 33| Step: 0
Training loss: 3.2656391636299458
Validation loss: 3.2697116210401043

Epoch: 5| Step: 1
Training loss: 2.986218587040299
Validation loss: 3.271667572117981

Epoch: 5| Step: 2
Training loss: 4.08830306537391
Validation loss: 3.269216204466824

Epoch: 5| Step: 3
Training loss: 3.7572630165276175
Validation loss: 3.2703094412952876

Epoch: 5| Step: 4
Training loss: 3.6859023949154905
Validation loss: 3.269216122128351

Epoch: 5| Step: 5
Training loss: 3.5644790773883983
Validation loss: 3.269456224848406

Epoch: 5| Step: 6
Training loss: 3.394090279227611
Validation loss: 3.2731783562127044

Epoch: 5| Step: 7
Training loss: 3.4924683596598407
Validation loss: 3.2718771909614794

Epoch: 5| Step: 8
Training loss: 3.6295793481906427
Validation loss: 3.269992284189603

Epoch: 5| Step: 9
Training loss: 3.2011450626165106
Validation loss: 3.265482736974237

Epoch: 5| Step: 10
Training loss: 3.421489815827961
Validation loss: 3.265628813713741

Epoch: 34| Step: 0
Training loss: 3.54550077056984
Validation loss: 3.264013889292643

Epoch: 5| Step: 1
Training loss: 3.952686632299502
Validation loss: 3.2657904708867944

Epoch: 5| Step: 2
Training loss: 3.9815467520266816
Validation loss: 3.2646020652228924

Epoch: 5| Step: 3
Training loss: 3.126947940247888
Validation loss: 3.2650737749606065

Epoch: 5| Step: 4
Training loss: 2.897298172511668
Validation loss: 3.2625734218101985

Epoch: 5| Step: 5
Training loss: 3.0149431001219007
Validation loss: 3.262984247337015

Epoch: 5| Step: 6
Training loss: 3.808099677488304
Validation loss: 3.2610556594764635

Epoch: 5| Step: 7
Training loss: 3.162207391644096
Validation loss: 3.26061304460217

Epoch: 5| Step: 8
Training loss: 3.2413506956159828
Validation loss: 3.2601499181364195

Epoch: 5| Step: 9
Training loss: 3.922407623234125
Validation loss: 3.2646725138848094

Epoch: 5| Step: 10
Training loss: 3.7273769808143222
Validation loss: 3.260256330902554

Epoch: 35| Step: 0
Training loss: 3.608078232367445
Validation loss: 3.265418873058586

Epoch: 5| Step: 1
Training loss: 4.028453004443367
Validation loss: 3.266863335021011

Epoch: 5| Step: 2
Training loss: 3.249914755070072
Validation loss: 3.2717503023313004

Epoch: 5| Step: 3
Training loss: 2.48504149895447
Validation loss: 3.2758404699493093

Epoch: 5| Step: 4
Training loss: 3.3958754429614886
Validation loss: 3.2621525419573945

Epoch: 5| Step: 5
Training loss: 3.8055406432466787
Validation loss: 3.257859373391129

Epoch: 5| Step: 6
Training loss: 3.428144729265385
Validation loss: 3.2560667220251887

Epoch: 5| Step: 7
Training loss: 4.1651456472660655
Validation loss: 3.2565582183055866

Epoch: 5| Step: 8
Training loss: 3.586865008044978
Validation loss: 3.2605623078189163

Epoch: 5| Step: 9
Training loss: 2.889324328625772
Validation loss: 3.27554991262735

Epoch: 5| Step: 10
Training loss: 3.5956250150651696
Validation loss: 3.2933027895794367

Epoch: 36| Step: 0
Training loss: 3.6772946881436774
Validation loss: 3.2541990179096336

Epoch: 5| Step: 1
Training loss: 3.6193490542214835
Validation loss: 3.254588258944343

Epoch: 5| Step: 2
Training loss: 3.6017082664797564
Validation loss: 3.2581814600058685

Epoch: 5| Step: 3
Training loss: 3.898849434962051
Validation loss: 3.2590567273891287

Epoch: 5| Step: 4
Training loss: 2.907273635252515
Validation loss: 3.260426218007773

Epoch: 5| Step: 5
Training loss: 3.275820354189149
Validation loss: 3.257910904542012

Epoch: 5| Step: 6
Training loss: 2.5072152921050828
Validation loss: 3.2590220655617554

Epoch: 5| Step: 7
Training loss: 3.1220136487565937
Validation loss: 3.256554417586121

Epoch: 5| Step: 8
Training loss: 4.063128613474926
Validation loss: 3.255951640395589

Epoch: 5| Step: 9
Training loss: 3.7898593969106624
Validation loss: 3.252975572843468

Epoch: 5| Step: 10
Training loss: 3.729019474697844
Validation loss: 3.2507139333644717

Epoch: 37| Step: 0
Training loss: 3.5974274768637025
Validation loss: 3.249285441901387

Epoch: 5| Step: 1
Training loss: 3.672074462667526
Validation loss: 3.251076396209075

Epoch: 5| Step: 2
Training loss: 3.666219308323444
Validation loss: 3.251398736861145

Epoch: 5| Step: 3
Training loss: 3.6447424137479514
Validation loss: 3.249306447007048

Epoch: 5| Step: 4
Training loss: 3.446728335430821
Validation loss: 3.2493545074214647

Epoch: 5| Step: 5
Training loss: 3.7859083753119704
Validation loss: 3.24740866126411

Epoch: 5| Step: 6
Training loss: 3.315416599523136
Validation loss: 3.2441448266885233

Epoch: 5| Step: 7
Training loss: 3.1039713002284026
Validation loss: 3.245153137013634

Epoch: 5| Step: 8
Training loss: 3.2565469090266332
Validation loss: 3.2444482244753408

Epoch: 5| Step: 9
Training loss: 3.0041180003999757
Validation loss: 3.2444296081984034

Epoch: 5| Step: 10
Training loss: 3.862997601995432
Validation loss: 3.2449941427605

Epoch: 38| Step: 0
Training loss: 2.9789540852993652
Validation loss: 3.245369520878332

Epoch: 5| Step: 1
Training loss: 3.165996346717987
Validation loss: 3.244196671299731

Epoch: 5| Step: 2
Training loss: 3.3651663606736837
Validation loss: 3.2450365386189532

Epoch: 5| Step: 3
Training loss: 4.273683865156252
Validation loss: 3.2441944618339114

Epoch: 5| Step: 4
Training loss: 3.8193677736543896
Validation loss: 3.2435186455308047

Epoch: 5| Step: 5
Training loss: 3.3170264644768874
Validation loss: 3.242060017121086

Epoch: 5| Step: 6
Training loss: 3.425566054297946
Validation loss: 3.24380119720065

Epoch: 5| Step: 7
Training loss: 3.467854014658054
Validation loss: 3.2447476790027565

Epoch: 5| Step: 8
Training loss: 3.909363017380217
Validation loss: 3.2405383082045356

Epoch: 5| Step: 9
Training loss: 2.5349716330903016
Validation loss: 3.242030549108279

Epoch: 5| Step: 10
Training loss: 3.809231717401223
Validation loss: 3.2395588974429583

Epoch: 39| Step: 0
Training loss: 3.8236554893144277
Validation loss: 3.2397313179967333

Epoch: 5| Step: 1
Training loss: 3.5886860870548287
Validation loss: 3.241132709871252

Epoch: 5| Step: 2
Training loss: 3.2728002833882623
Validation loss: 3.2414557973422613

Epoch: 5| Step: 3
Training loss: 3.6425905610963984
Validation loss: 3.2402462839681387

Epoch: 5| Step: 4
Training loss: 3.5131208529513196
Validation loss: 3.2453553446204264

Epoch: 5| Step: 5
Training loss: 3.080998198026126
Validation loss: 3.2388494002004897

Epoch: 5| Step: 6
Training loss: 3.4274914777720737
Validation loss: 3.238407314589899

Epoch: 5| Step: 7
Training loss: 3.262371578100605
Validation loss: 3.239501314787113

Epoch: 5| Step: 8
Training loss: 3.106245910519032
Validation loss: 3.2337632359885884

Epoch: 5| Step: 9
Training loss: 3.5963266175043818
Validation loss: 3.236891332168617

Epoch: 5| Step: 10
Training loss: 3.9335561710748426
Validation loss: 3.2350216508866017

Epoch: 40| Step: 0
Training loss: 3.3915470117805646
Validation loss: 3.2343681596546228

Epoch: 5| Step: 1
Training loss: 3.2013497247918425
Validation loss: 3.232475948250129

Epoch: 5| Step: 2
Training loss: 4.074918809327654
Validation loss: 3.232923079853728

Epoch: 5| Step: 3
Training loss: 2.797663231281432
Validation loss: 3.2340146692779284

Epoch: 5| Step: 4
Training loss: 3.8198937184592854
Validation loss: 3.23298084628365

Epoch: 5| Step: 5
Training loss: 3.8134966938889243
Validation loss: 3.233553552586446

Epoch: 5| Step: 6
Training loss: 2.602962174652586
Validation loss: 3.2334299980339325

Epoch: 5| Step: 7
Training loss: 2.8947923467872556
Validation loss: 3.2327654587151544

Epoch: 5| Step: 8
Training loss: 3.7255680188789277
Validation loss: 3.233329418075554

Epoch: 5| Step: 9
Training loss: 3.977530071305514
Validation loss: 3.2339655303038404

Epoch: 5| Step: 10
Training loss: 3.5755631383443114
Validation loss: 3.23891809145537

Epoch: 41| Step: 0
Training loss: 4.007333232339153
Validation loss: 3.235390577665456

Epoch: 5| Step: 1
Training loss: 2.694693497053107
Validation loss: 3.23253311200288

Epoch: 5| Step: 2
Training loss: 3.6264081390414074
Validation loss: 3.230126275981347

Epoch: 5| Step: 3
Training loss: 3.039057008400003
Validation loss: 3.229292212886236

Epoch: 5| Step: 4
Training loss: 3.5265847505840204
Validation loss: 3.227844096580004

Epoch: 5| Step: 5
Training loss: 3.676041467194062
Validation loss: 3.228319117332841

Epoch: 5| Step: 6
Training loss: 3.328146347908719
Validation loss: 3.2285282712020136

Epoch: 5| Step: 7
Training loss: 2.9274573217289492
Validation loss: 3.226663133578941

Epoch: 5| Step: 8
Training loss: 3.40919954878202
Validation loss: 3.2281736553307847

Epoch: 5| Step: 9
Training loss: 4.146179159236055
Validation loss: 3.2308435622517933

Epoch: 5| Step: 10
Training loss: 3.5224104439564337
Validation loss: 3.2287275689946338

Epoch: 42| Step: 0
Training loss: 3.598385284482279
Validation loss: 3.227249025989922

Epoch: 5| Step: 1
Training loss: 3.5194816628200747
Validation loss: 3.2262279453551916

Epoch: 5| Step: 2
Training loss: 3.148620751587765
Validation loss: 3.2249097805594764

Epoch: 5| Step: 3
Training loss: 3.679351208135094
Validation loss: 3.224448373926434

Epoch: 5| Step: 4
Training loss: 3.130883286373522
Validation loss: 3.224848973498832

Epoch: 5| Step: 5
Training loss: 4.044844777225769
Validation loss: 3.221352719322297

Epoch: 5| Step: 6
Training loss: 3.27460176798517
Validation loss: 3.2223352459693966

Epoch: 5| Step: 7
Training loss: 3.772922141065721
Validation loss: 3.2228204906446405

Epoch: 5| Step: 8
Training loss: 3.4253868998279864
Validation loss: 3.2208342915789463

Epoch: 5| Step: 9
Training loss: 2.8355808506690745
Validation loss: 3.221070872690609

Epoch: 5| Step: 10
Training loss: 3.5359711271634824
Validation loss: 3.2223392485535607

Epoch: 43| Step: 0
Training loss: 3.171984590788811
Validation loss: 3.21919584387315

Epoch: 5| Step: 1
Training loss: 3.2872895380105884
Validation loss: 3.2198539447251653

Epoch: 5| Step: 2
Training loss: 4.228042428055506
Validation loss: 3.217876681829258

Epoch: 5| Step: 3
Training loss: 3.9224330307523805
Validation loss: 3.218079035567317

Epoch: 5| Step: 4
Training loss: 3.231929720841557
Validation loss: 3.2182881244622763

Epoch: 5| Step: 5
Training loss: 3.143996521401847
Validation loss: 3.2183045269059867

Epoch: 5| Step: 6
Training loss: 2.621863534968228
Validation loss: 3.2161669690548336

Epoch: 5| Step: 7
Training loss: 3.2732386562797946
Validation loss: 3.2174404533616627

Epoch: 5| Step: 8
Training loss: 3.1202666484155412
Validation loss: 3.2186902673158535

Epoch: 5| Step: 9
Training loss: 3.9350469304816142
Validation loss: 3.217479330350993

Epoch: 5| Step: 10
Training loss: 3.8656325788122956
Validation loss: 3.222196192265559

Epoch: 44| Step: 0
Training loss: 3.625150217035059
Validation loss: 3.2227648330746987

Epoch: 5| Step: 1
Training loss: 2.9487656807411797
Validation loss: 3.2145851741085267

Epoch: 5| Step: 2
Training loss: 3.3066691776491703
Validation loss: 3.215222810844615

Epoch: 5| Step: 3
Training loss: 3.5622898508295533
Validation loss: 3.213114924611335

Epoch: 5| Step: 4
Training loss: 3.150963614681992
Validation loss: 3.2148985798186067

Epoch: 5| Step: 5
Training loss: 2.978937918321867
Validation loss: 3.214898221774743

Epoch: 5| Step: 6
Training loss: 3.9495021216568764
Validation loss: 3.215458136904929

Epoch: 5| Step: 7
Training loss: 3.2282741338619023
Validation loss: 3.2180585953917964

Epoch: 5| Step: 8
Training loss: 3.191371586026556
Validation loss: 3.2177655070130258

Epoch: 5| Step: 9
Training loss: 4.013699437253296
Validation loss: 3.212969118958451

Epoch: 5| Step: 10
Training loss: 3.9704177836480867
Validation loss: 3.2117938787988427

Epoch: 45| Step: 0
Training loss: 3.057770794957835
Validation loss: 3.2097076463134018

Epoch: 5| Step: 1
Training loss: 3.5581126720135163
Validation loss: 3.2115009387271236

Epoch: 5| Step: 2
Training loss: 3.4818780959085953
Validation loss: 3.2135508339998227

Epoch: 5| Step: 3
Training loss: 3.12194430681952
Validation loss: 3.2116640751585446

Epoch: 5| Step: 4
Training loss: 3.443466833972693
Validation loss: 3.2146976702757413

Epoch: 5| Step: 5
Training loss: 3.70943161777393
Validation loss: 3.2193440965175717

Epoch: 5| Step: 6
Training loss: 3.8015138521856495
Validation loss: 3.2146156537230457

Epoch: 5| Step: 7
Training loss: 3.6667962195888677
Validation loss: 3.2149353807736714

Epoch: 5| Step: 8
Training loss: 2.9085413606092163
Validation loss: 3.2138103362757695

Epoch: 5| Step: 9
Training loss: 3.3598923395710614
Validation loss: 3.210890454217434

Epoch: 5| Step: 10
Training loss: 3.8402295622156672
Validation loss: 3.2132212706380368

Epoch: 46| Step: 0
Training loss: 4.330905503173325
Validation loss: 3.206071415605852

Epoch: 5| Step: 1
Training loss: 3.1676896768455625
Validation loss: 3.206636871797433

Epoch: 5| Step: 2
Training loss: 2.995722263984859
Validation loss: 3.221311587518343

Epoch: 5| Step: 3
Training loss: 3.8148533796180684
Validation loss: 3.2407617408383254

Epoch: 5| Step: 4
Training loss: 3.0353218337836196
Validation loss: 3.2416447089852145

Epoch: 5| Step: 5
Training loss: 3.112129563191549
Validation loss: 3.2315548759050086

Epoch: 5| Step: 6
Training loss: 4.218323636585808
Validation loss: 3.2081310643676306

Epoch: 5| Step: 7
Training loss: 3.6461608448970475
Validation loss: 3.2226843709952413

Epoch: 5| Step: 8
Training loss: 3.4038016943450553
Validation loss: 3.205593854633285

Epoch: 5| Step: 9
Training loss: 2.897839589925645
Validation loss: 3.210027397408646

Epoch: 5| Step: 10
Training loss: 3.055436220632342
Validation loss: 3.2165440774857808

Epoch: 47| Step: 0
Training loss: 3.470753958635189
Validation loss: 3.2187147543777774

Epoch: 5| Step: 1
Training loss: 3.349434130118757
Validation loss: 3.219667303385049

Epoch: 5| Step: 2
Training loss: 2.3689701430958126
Validation loss: 3.229251210789368

Epoch: 5| Step: 3
Training loss: 3.341823700396424
Validation loss: 3.2328526625372285

Epoch: 5| Step: 4
Training loss: 2.9254940691626867
Validation loss: 3.2323198582509107

Epoch: 5| Step: 5
Training loss: 3.567965681535384
Validation loss: 3.2323970516014917

Epoch: 5| Step: 6
Training loss: 3.7069104640243817
Validation loss: 3.2281752642698285

Epoch: 5| Step: 7
Training loss: 4.1505606582817425
Validation loss: 3.221664988435399

Epoch: 5| Step: 8
Training loss: 3.6116336509651945
Validation loss: 3.2164022467597615

Epoch: 5| Step: 9
Training loss: 3.6067314210062724
Validation loss: 3.2147506285512915

Epoch: 5| Step: 10
Training loss: 3.7765825958411727
Validation loss: 3.210217367916657

Epoch: 48| Step: 0
Training loss: 3.0981374128784456
Validation loss: 3.2068036964566775

Epoch: 5| Step: 1
Training loss: 2.839728057897456
Validation loss: 3.205374654484547

Epoch: 5| Step: 2
Training loss: 2.831056034947075
Validation loss: 3.205311666859045

Epoch: 5| Step: 3
Training loss: 3.68251489432975
Validation loss: 3.203882549913465

Epoch: 5| Step: 4
Training loss: 3.7430650800978142
Validation loss: 3.1987518591292883

Epoch: 5| Step: 5
Training loss: 3.915414298828379
Validation loss: 3.1946506411997575

Epoch: 5| Step: 6
Training loss: 3.1983708526122863
Validation loss: 3.194069207367856

Epoch: 5| Step: 7
Training loss: 3.5194250296124365
Validation loss: 3.1922532298424446

Epoch: 5| Step: 8
Training loss: 3.4996533903429725
Validation loss: 3.19334531386271

Epoch: 5| Step: 9
Training loss: 3.7863903573015567
Validation loss: 3.193447593877072

Epoch: 5| Step: 10
Training loss: 3.65080351150292
Validation loss: 3.1910263556173044

Epoch: 49| Step: 0
Training loss: 3.25641322102095
Validation loss: 3.192043053190507

Epoch: 5| Step: 1
Training loss: 3.4443133715503342
Validation loss: 3.191451616565121

Epoch: 5| Step: 2
Training loss: 3.108275252575995
Validation loss: 3.1916427489531833

Epoch: 5| Step: 3
Training loss: 4.115320814009727
Validation loss: 3.1901709649745937

Epoch: 5| Step: 4
Training loss: 2.646495455898158
Validation loss: 3.18768639595584

Epoch: 5| Step: 5
Training loss: 4.296213105980889
Validation loss: 3.188248755709334

Epoch: 5| Step: 6
Training loss: 2.573423780950169
Validation loss: 3.1867235876036797

Epoch: 5| Step: 7
Training loss: 2.846474484724481
Validation loss: 3.187217983032844

Epoch: 5| Step: 8
Training loss: 3.4722046016669874
Validation loss: 3.1859747727902965

Epoch: 5| Step: 9
Training loss: 4.212297945242263
Validation loss: 3.185674700895367

Epoch: 5| Step: 10
Training loss: 3.3075208849835023
Validation loss: 3.185134257493748

Epoch: 50| Step: 0
Training loss: 3.403972179097434
Validation loss: 3.184010467343277

Epoch: 5| Step: 1
Training loss: 2.6155368439141817
Validation loss: 3.184039720313598

Epoch: 5| Step: 2
Training loss: 4.583696639949568
Validation loss: 3.1833470503435244

Epoch: 5| Step: 3
Training loss: 3.8637781392568873
Validation loss: 3.185699087650374

Epoch: 5| Step: 4
Training loss: 3.3098744477492317
Validation loss: 3.18669505273457

Epoch: 5| Step: 5
Training loss: 3.4254346474285144
Validation loss: 3.184059272600477

Epoch: 5| Step: 6
Training loss: 3.3249149512406175
Validation loss: 3.182717233907749

Epoch: 5| Step: 7
Training loss: 3.4530755639313377
Validation loss: 3.1810563949306077

Epoch: 5| Step: 8
Training loss: 3.2413481947342278
Validation loss: 3.179644552090297

Epoch: 5| Step: 9
Training loss: 3.2539516780104694
Validation loss: 3.1792993739241537

Epoch: 5| Step: 10
Training loss: 2.8600884886703946
Validation loss: 3.178505458030978

Testing loss: 3.362370727020517
