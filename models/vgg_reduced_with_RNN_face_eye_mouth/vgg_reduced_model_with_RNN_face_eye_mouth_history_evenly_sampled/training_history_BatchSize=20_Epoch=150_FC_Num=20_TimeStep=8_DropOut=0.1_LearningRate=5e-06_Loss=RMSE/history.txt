Epoch: 1| Step: 0
Training loss: 5.94354999899691
Validation loss: 5.7817805682266155

Epoch: 5| Step: 1
Training loss: 6.2265306421706965
Validation loss: 5.777468675762322

Epoch: 5| Step: 2
Training loss: 5.861439414971451
Validation loss: 5.77383394359556

Epoch: 5| Step: 3
Training loss: 5.680590110534842
Validation loss: 5.769978417689073

Epoch: 5| Step: 4
Training loss: 5.875809958608067
Validation loss: 5.766606174435996

Epoch: 5| Step: 5
Training loss: 6.033907764269756
Validation loss: 5.762753190468719

Epoch: 5| Step: 6
Training loss: 6.481893997789842
Validation loss: 5.759071470589108

Epoch: 5| Step: 7
Training loss: 5.17870881974193
Validation loss: 5.75531817477886

Epoch: 5| Step: 8
Training loss: 5.221114850604526
Validation loss: 5.751493699576093

Epoch: 5| Step: 9
Training loss: 6.028873271785209
Validation loss: 5.747637384156487

Epoch: 5| Step: 10
Training loss: 4.939197876090781
Validation loss: 5.743700963494711

Epoch: 2| Step: 0
Training loss: 6.061457278844892
Validation loss: 5.7395969713269865

Epoch: 5| Step: 1
Training loss: 5.24645876661999
Validation loss: 5.735454062482636

Epoch: 5| Step: 2
Training loss: 6.322287648150551
Validation loss: 5.73101571442541

Epoch: 5| Step: 3
Training loss: 5.075711941697232
Validation loss: 5.726554370210621

Epoch: 5| Step: 4
Training loss: 5.926580084792986
Validation loss: 5.721533182520555

Epoch: 5| Step: 5
Training loss: 5.247568203072585
Validation loss: 5.716845076720116

Epoch: 5| Step: 6
Training loss: 6.920142652331185
Validation loss: 5.711612930870707

Epoch: 5| Step: 7
Training loss: 5.0371250893390975
Validation loss: 5.706214636749579

Epoch: 5| Step: 8
Training loss: 6.267863570548873
Validation loss: 5.700691489485406

Epoch: 5| Step: 9
Training loss: 5.521488693014318
Validation loss: 5.694508943843579

Epoch: 5| Step: 10
Training loss: 5.243173975445789
Validation loss: 5.688475469168119

Epoch: 3| Step: 0
Training loss: 6.010551076495737
Validation loss: 5.682226365537953

Epoch: 5| Step: 1
Training loss: 5.190262392206311
Validation loss: 5.676044389440749

Epoch: 5| Step: 2
Training loss: 6.283534000069491
Validation loss: 5.669281261643888

Epoch: 5| Step: 3
Training loss: 5.463884030777211
Validation loss: 5.6619217325965785

Epoch: 5| Step: 4
Training loss: 5.225654831148594
Validation loss: 5.654266954353068

Epoch: 5| Step: 5
Training loss: 5.620357717078151
Validation loss: 5.646076437667878

Epoch: 5| Step: 6
Training loss: 5.254206470860061
Validation loss: 5.638190838590673

Epoch: 5| Step: 7
Training loss: 6.4263196725413065
Validation loss: 5.630023646334798

Epoch: 5| Step: 8
Training loss: 5.021916611599343
Validation loss: 5.6210934033829485

Epoch: 5| Step: 9
Training loss: 5.934651866237606
Validation loss: 5.612103765137226

Epoch: 5| Step: 10
Training loss: 5.9205568804305955
Validation loss: 5.602308799829607

Epoch: 4| Step: 0
Training loss: 5.657922992612398
Validation loss: 5.593113661210529

Epoch: 5| Step: 1
Training loss: 4.839877050745505
Validation loss: 5.582617052416309

Epoch: 5| Step: 2
Training loss: 5.7693358680737745
Validation loss: 5.571961645624615

Epoch: 5| Step: 3
Training loss: 5.97223980726073
Validation loss: 5.561379338570777

Epoch: 5| Step: 4
Training loss: 5.208288248502783
Validation loss: 5.550161228648373

Epoch: 5| Step: 5
Training loss: 5.377385519414994
Validation loss: 5.5394330398829235

Epoch: 5| Step: 6
Training loss: 6.186502087201714
Validation loss: 5.527552241920401

Epoch: 5| Step: 7
Training loss: 6.18247118729149
Validation loss: 5.5149146064702155

Epoch: 5| Step: 8
Training loss: 5.163700893282182
Validation loss: 5.5026075832354255

Epoch: 5| Step: 9
Training loss: 4.796943788314801
Validation loss: 5.490532235236641

Epoch: 5| Step: 10
Training loss: 6.046617921396515
Validation loss: 5.477639192391469

Epoch: 5| Step: 0
Training loss: 6.013708983626169
Validation loss: 5.465180046379819

Epoch: 5| Step: 1
Training loss: 5.860254165813925
Validation loss: 5.451505762442869

Epoch: 5| Step: 2
Training loss: 4.3641978285553895
Validation loss: 5.437780399186072

Epoch: 5| Step: 3
Training loss: 5.690924986086675
Validation loss: 5.424920593454819

Epoch: 5| Step: 4
Training loss: 5.3355051426798825
Validation loss: 5.411266856911909

Epoch: 5| Step: 5
Training loss: 5.155785926973722
Validation loss: 5.398263130561374

Epoch: 5| Step: 6
Training loss: 5.340465763367662
Validation loss: 5.383997710981731

Epoch: 5| Step: 7
Training loss: 4.135589416636768
Validation loss: 5.370487905332046

Epoch: 5| Step: 8
Training loss: 5.850760920669215
Validation loss: 5.356415499889161

Epoch: 5| Step: 9
Training loss: 6.274702768771265
Validation loss: 5.3412619704762525

Epoch: 5| Step: 10
Training loss: 5.460716406803883
Validation loss: 5.327746077011832

Epoch: 6| Step: 0
Training loss: 4.752709268600984
Validation loss: 5.3131373718610915

Epoch: 5| Step: 1
Training loss: 6.023022034958344
Validation loss: 5.297825301076765

Epoch: 5| Step: 2
Training loss: 6.133649985114294
Validation loss: 5.283510292753903

Epoch: 5| Step: 3
Training loss: 5.2296565866140785
Validation loss: 5.268492328320714

Epoch: 5| Step: 4
Training loss: 5.0158141864023085
Validation loss: 5.252955226579393

Epoch: 5| Step: 5
Training loss: 5.186080554576326
Validation loss: 5.238019251288918

Epoch: 5| Step: 6
Training loss: 5.18131871379204
Validation loss: 5.222079908409582

Epoch: 5| Step: 7
Training loss: 5.264991790098508
Validation loss: 5.206891206333376

Epoch: 5| Step: 8
Training loss: 4.903918058348656
Validation loss: 5.191825926093323

Epoch: 5| Step: 9
Training loss: 4.2699623274202185
Validation loss: 5.175534284151549

Epoch: 5| Step: 10
Training loss: 6.060981166964539
Validation loss: 5.16029127844982

Epoch: 7| Step: 0
Training loss: 5.273735523986117
Validation loss: 5.144557132855634

Epoch: 5| Step: 1
Training loss: 5.370140007651777
Validation loss: 5.127873281323083

Epoch: 5| Step: 2
Training loss: 5.755275462407804
Validation loss: 5.113867601503106

Epoch: 5| Step: 3
Training loss: 4.812014864954895
Validation loss: 5.096932452870362

Epoch: 5| Step: 4
Training loss: 4.232086126074896
Validation loss: 5.081581696830523

Epoch: 5| Step: 5
Training loss: 5.749990380320588
Validation loss: 5.067119063520577

Epoch: 5| Step: 6
Training loss: 4.8584246426743025
Validation loss: 5.050993362369806

Epoch: 5| Step: 7
Training loss: 4.790823732398439
Validation loss: 5.036331646344123

Epoch: 5| Step: 8
Training loss: 5.125644922384043
Validation loss: 5.021445898936225

Epoch: 5| Step: 9
Training loss: 5.415497384656166
Validation loss: 5.00718456631204

Epoch: 5| Step: 10
Training loss: 4.837923544939975
Validation loss: 4.993248214008231

Epoch: 8| Step: 0
Training loss: 5.056846570255758
Validation loss: 4.978152323095546

Epoch: 5| Step: 1
Training loss: 5.227012991200678
Validation loss: 4.963819562395881

Epoch: 5| Step: 2
Training loss: 4.4787901017749014
Validation loss: 4.948841679045678

Epoch: 5| Step: 3
Training loss: 3.8332525051275197
Validation loss: 4.9353203220602975

Epoch: 5| Step: 4
Training loss: 5.812159374469895
Validation loss: 4.921531826490589

Epoch: 5| Step: 5
Training loss: 5.051836250266998
Validation loss: 4.907175789137108

Epoch: 5| Step: 6
Training loss: 5.490014809065616
Validation loss: 4.8917761935879565

Epoch: 5| Step: 7
Training loss: 4.262752026577184
Validation loss: 4.875463307517117

Epoch: 5| Step: 8
Training loss: 5.14287149336493
Validation loss: 4.862189829375015

Epoch: 5| Step: 9
Training loss: 4.975774825444314
Validation loss: 4.845489141042524

Epoch: 5| Step: 10
Training loss: 5.182785465605837
Validation loss: 4.832100178737946

Epoch: 9| Step: 0
Training loss: 5.001114911707931
Validation loss: 4.816412735203874

Epoch: 5| Step: 1
Training loss: 4.490103966543658
Validation loss: 4.801362177989535

Epoch: 5| Step: 2
Training loss: 4.520608969656961
Validation loss: 4.786971608998792

Epoch: 5| Step: 3
Training loss: 4.642040306590176
Validation loss: 4.771778038769668

Epoch: 5| Step: 4
Training loss: 5.0344773834444885
Validation loss: 4.757403048850251

Epoch: 5| Step: 5
Training loss: 4.813499049735716
Validation loss: 4.7436116603619345

Epoch: 5| Step: 6
Training loss: 5.061467194874913
Validation loss: 4.727854589465042

Epoch: 5| Step: 7
Training loss: 4.942528976332335
Validation loss: 4.714692934186871

Epoch: 5| Step: 8
Training loss: 5.049990044008015
Validation loss: 4.70003254053794

Epoch: 5| Step: 9
Training loss: 4.784534597693732
Validation loss: 4.687196603889696

Epoch: 5| Step: 10
Training loss: 4.709641513991019
Validation loss: 4.674050446101757

Epoch: 10| Step: 0
Training loss: 4.76018917060461
Validation loss: 4.661487270954465

Epoch: 5| Step: 1
Training loss: 4.665196368795619
Validation loss: 4.648236211436141

Epoch: 5| Step: 2
Training loss: 4.301323602695735
Validation loss: 4.635084461873106

Epoch: 5| Step: 3
Training loss: 5.00071291609401
Validation loss: 4.6230302322699295

Epoch: 5| Step: 4
Training loss: 4.719355058088619
Validation loss: 4.609432940208447

Epoch: 5| Step: 5
Training loss: 4.855709152837835
Validation loss: 4.598558829998671

Epoch: 5| Step: 6
Training loss: 4.977187568059545
Validation loss: 4.588341524900925

Epoch: 5| Step: 7
Training loss: 5.0044364320755985
Validation loss: 4.576676820561011

Epoch: 5| Step: 8
Training loss: 4.1796770042216345
Validation loss: 4.565286735738861

Epoch: 5| Step: 9
Training loss: 4.649667887979297
Validation loss: 4.555377628250922

Epoch: 5| Step: 10
Training loss: 4.441193883376542
Validation loss: 4.544605265551265

Epoch: 11| Step: 0
Training loss: 5.4106140163398715
Validation loss: 4.533740688174982

Epoch: 5| Step: 1
Training loss: 3.783170732429406
Validation loss: 4.523261601255336

Epoch: 5| Step: 2
Training loss: 5.2447750794629195
Validation loss: 4.511426458189501

Epoch: 5| Step: 3
Training loss: 4.602918130508309
Validation loss: 4.5020455869095555

Epoch: 5| Step: 4
Training loss: 5.080428226173824
Validation loss: 4.490365085682338

Epoch: 5| Step: 5
Training loss: 4.270945155222775
Validation loss: 4.47906451823047

Epoch: 5| Step: 6
Training loss: 4.223654375848135
Validation loss: 4.4688413911689375

Epoch: 5| Step: 7
Training loss: 4.145273960019202
Validation loss: 4.460486381605803

Epoch: 5| Step: 8
Training loss: 4.301783861477601
Validation loss: 4.450910184478111

Epoch: 5| Step: 9
Training loss: 5.351857242681733
Validation loss: 4.44074615705578

Epoch: 5| Step: 10
Training loss: 3.4446593203910787
Validation loss: 4.430861699625818

Epoch: 12| Step: 0
Training loss: 4.283082667238564
Validation loss: 4.422175543694997

Epoch: 5| Step: 1
Training loss: 4.352581459610931
Validation loss: 4.41416052222051

Epoch: 5| Step: 2
Training loss: 4.667373989633405
Validation loss: 4.405229387298071

Epoch: 5| Step: 3
Training loss: 4.178938354665539
Validation loss: 4.395908267400125

Epoch: 5| Step: 4
Training loss: 4.161448504548129
Validation loss: 4.383532085581468

Epoch: 5| Step: 5
Training loss: 5.114436357902325
Validation loss: 4.37596807126544

Epoch: 5| Step: 6
Training loss: 4.138088385012787
Validation loss: 4.365515588973749

Epoch: 5| Step: 7
Training loss: 5.485528460545536
Validation loss: 4.357034695525768

Epoch: 5| Step: 8
Training loss: 4.238437407117479
Validation loss: 4.346411282177183

Epoch: 5| Step: 9
Training loss: 4.542082577947858
Validation loss: 4.337343989445503

Epoch: 5| Step: 10
Training loss: 3.9186290667550283
Validation loss: 4.330338680183212

Epoch: 13| Step: 0
Training loss: 5.1747266393140015
Validation loss: 4.32026705658365

Epoch: 5| Step: 1
Training loss: 4.188429771939333
Validation loss: 4.314500567906796

Epoch: 5| Step: 2
Training loss: 4.7314837096932685
Validation loss: 4.30655761650658

Epoch: 5| Step: 3
Training loss: 4.13977226257512
Validation loss: 4.296210344355154

Epoch: 5| Step: 4
Training loss: 4.546399488196612
Validation loss: 4.2868399704783915

Epoch: 5| Step: 5
Training loss: 4.365373538399749
Validation loss: 4.279565697659321

Epoch: 5| Step: 6
Training loss: 4.630190025038794
Validation loss: 4.275246534547171

Epoch: 5| Step: 7
Training loss: 4.584541069200443
Validation loss: 4.264501854784522

Epoch: 5| Step: 8
Training loss: 3.580768391712238
Validation loss: 4.2566394928314

Epoch: 5| Step: 9
Training loss: 4.07467727787407
Validation loss: 4.249870970309754

Epoch: 5| Step: 10
Training loss: 4.2527138516199
Validation loss: 4.243007560932811

Epoch: 14| Step: 0
Training loss: 4.140063899187483
Validation loss: 4.23524032340349

Epoch: 5| Step: 1
Training loss: 3.641983760992357
Validation loss: 4.225662171642823

Epoch: 5| Step: 2
Training loss: 4.142830430494359
Validation loss: 4.2226264696588025

Epoch: 5| Step: 3
Training loss: 4.216210625354658
Validation loss: 4.214084433868936

Epoch: 5| Step: 4
Training loss: 4.990727791775621
Validation loss: 4.202906117258193

Epoch: 5| Step: 5
Training loss: 4.738394563708455
Validation loss: 4.199916140622036

Epoch: 5| Step: 6
Training loss: 4.305662622795461
Validation loss: 4.189980387106169

Epoch: 5| Step: 7
Training loss: 5.117978193623462
Validation loss: 4.182134110301362

Epoch: 5| Step: 8
Training loss: 3.841097280766591
Validation loss: 4.175311982831457

Epoch: 5| Step: 9
Training loss: 3.960898374706604
Validation loss: 4.166393991387553

Epoch: 5| Step: 10
Training loss: 4.249337088551422
Validation loss: 4.160368146193439

Epoch: 15| Step: 0
Training loss: 3.6475695735578935
Validation loss: 4.154994113937151

Epoch: 5| Step: 1
Training loss: 4.291239646234642
Validation loss: 4.1476870394622045

Epoch: 5| Step: 2
Training loss: 4.4875542937583175
Validation loss: 4.142229783605965

Epoch: 5| Step: 3
Training loss: 4.293409913211331
Validation loss: 4.134100153979163

Epoch: 5| Step: 4
Training loss: 4.639053643829434
Validation loss: 4.128905708574585

Epoch: 5| Step: 5
Training loss: 4.244034788213845
Validation loss: 4.122243429397207

Epoch: 5| Step: 6
Training loss: 3.922258943404452
Validation loss: 4.115831739894179

Epoch: 5| Step: 7
Training loss: 4.153887313791002
Validation loss: 4.11096336884902

Epoch: 5| Step: 8
Training loss: 4.995335119421145
Validation loss: 4.105203724365701

Epoch: 5| Step: 9
Training loss: 3.8896385075899484
Validation loss: 4.097793985170504

Epoch: 5| Step: 10
Training loss: 4.134099691369175
Validation loss: 4.096684880260512

Epoch: 16| Step: 0
Training loss: 4.004193253814257
Validation loss: 4.090608577726172

Epoch: 5| Step: 1
Training loss: 4.362363604405417
Validation loss: 4.085051457411136

Epoch: 5| Step: 2
Training loss: 3.8131849580411066
Validation loss: 4.078830163765839

Epoch: 5| Step: 3
Training loss: 4.535444120722069
Validation loss: 4.073295134862436

Epoch: 5| Step: 4
Training loss: 4.0237878146947
Validation loss: 4.067240402993731

Epoch: 5| Step: 5
Training loss: 4.1492222620195545
Validation loss: 4.061772733073122

Epoch: 5| Step: 6
Training loss: 4.401946001608177
Validation loss: 4.057936616490142

Epoch: 5| Step: 7
Training loss: 4.315449908196856
Validation loss: 4.052260171066431

Epoch: 5| Step: 8
Training loss: 4.550441116916085
Validation loss: 4.047873963449486

Epoch: 5| Step: 9
Training loss: 3.6799269677254425
Validation loss: 4.043163200522612

Epoch: 5| Step: 10
Training loss: 4.389945524047145
Validation loss: 4.039641636807617

Epoch: 17| Step: 0
Training loss: 4.015371351728898
Validation loss: 4.037209513693859

Epoch: 5| Step: 1
Training loss: 2.975804029534267
Validation loss: 4.030080893015691

Epoch: 5| Step: 2
Training loss: 4.209726361150639
Validation loss: 4.027194285793865

Epoch: 5| Step: 3
Training loss: 3.704245868489784
Validation loss: 4.0247568753483645

Epoch: 5| Step: 4
Training loss: 4.27795773632686
Validation loss: 4.020001204136469

Epoch: 5| Step: 5
Training loss: 4.731357128789938
Validation loss: 4.017991957530941

Epoch: 5| Step: 6
Training loss: 4.597956178487036
Validation loss: 4.013214764424827

Epoch: 5| Step: 7
Training loss: 4.442086012597071
Validation loss: 4.010574818840667

Epoch: 5| Step: 8
Training loss: 3.631646344456411
Validation loss: 4.005972976222926

Epoch: 5| Step: 9
Training loss: 4.152386009309889
Validation loss: 4.001856426940374

Epoch: 5| Step: 10
Training loss: 4.821932577604024
Validation loss: 3.999083215237997

Epoch: 18| Step: 0
Training loss: 4.021762299162743
Validation loss: 3.992792703050849

Epoch: 5| Step: 1
Training loss: 4.233083605471676
Validation loss: 3.989164160058177

Epoch: 5| Step: 2
Training loss: 4.318419664394273
Validation loss: 3.9863560795328237

Epoch: 5| Step: 3
Training loss: 5.057874285226577
Validation loss: 3.9849738639128547

Epoch: 5| Step: 4
Training loss: 4.6014153500718615
Validation loss: 3.9796221836966303

Epoch: 5| Step: 5
Training loss: 4.036901017391775
Validation loss: 3.9794482364689836

Epoch: 5| Step: 6
Training loss: 3.3868271613451424
Validation loss: 3.9800803066534063

Epoch: 5| Step: 7
Training loss: 3.5028907554638864
Validation loss: 3.9744052774595247

Epoch: 5| Step: 8
Training loss: 3.902396292423428
Validation loss: 3.9713489257950063

Epoch: 5| Step: 9
Training loss: 4.757128135432535
Validation loss: 3.962760518554306

Epoch: 5| Step: 10
Training loss: 3.0696966509724866
Validation loss: 3.9566354906666894

Epoch: 19| Step: 0
Training loss: 3.1907054267034924
Validation loss: 3.9570215682234093

Epoch: 5| Step: 1
Training loss: 4.065019031963394
Validation loss: 3.9553303573596734

Epoch: 5| Step: 2
Training loss: 3.6990125008501002
Validation loss: 3.94874296611408

Epoch: 5| Step: 3
Training loss: 5.053919360889336
Validation loss: 3.947063436421798

Epoch: 5| Step: 4
Training loss: 4.0377079298964205
Validation loss: 3.9417736939516743

Epoch: 5| Step: 5
Training loss: 4.60468200745399
Validation loss: 3.9399887465062307

Epoch: 5| Step: 6
Training loss: 2.7297980667718926
Validation loss: 3.9375864733348127

Epoch: 5| Step: 7
Training loss: 4.4550008470254046
Validation loss: 3.934130869107257

Epoch: 5| Step: 8
Training loss: 3.632443645168793
Validation loss: 3.927975423558

Epoch: 5| Step: 9
Training loss: 4.109417004968897
Validation loss: 3.924491824763937

Epoch: 5| Step: 10
Training loss: 5.034897329274253
Validation loss: 3.9212301335535042

Epoch: 20| Step: 0
Training loss: 3.4837975814739988
Validation loss: 3.9221377472455474

Epoch: 5| Step: 1
Training loss: 3.9694516019858224
Validation loss: 3.9185028842434306

Epoch: 5| Step: 2
Training loss: 4.729444095131542
Validation loss: 3.91578720777242

Epoch: 5| Step: 3
Training loss: 4.015055456479215
Validation loss: 3.9087086503355732

Epoch: 5| Step: 4
Training loss: 3.9041107423428145
Validation loss: 3.906110058974748

Epoch: 5| Step: 5
Training loss: 4.5589477087838794
Validation loss: 3.9020648836005276

Epoch: 5| Step: 6
Training loss: 3.3621203183368
Validation loss: 3.893397973601856

Epoch: 5| Step: 7
Training loss: 4.419975600714679
Validation loss: 3.8908629868685414

Epoch: 5| Step: 8
Training loss: 3.682431633360625
Validation loss: 3.8874363862141417

Epoch: 5| Step: 9
Training loss: 4.029532606410208
Validation loss: 3.887514549554971

Epoch: 5| Step: 10
Training loss: 4.341459040640888
Validation loss: 3.886588040818807

Epoch: 21| Step: 0
Training loss: 4.248313344731579
Validation loss: 3.8794027926730186

Epoch: 5| Step: 1
Training loss: 3.3171061034599614
Validation loss: 3.875030374556787

Epoch: 5| Step: 2
Training loss: 4.963923383233696
Validation loss: 3.871426647254842

Epoch: 5| Step: 3
Training loss: 4.442930096021629
Validation loss: 3.867184001763167

Epoch: 5| Step: 4
Training loss: 3.979736859809658
Validation loss: 3.8646891877149874

Epoch: 5| Step: 5
Training loss: 3.713987233671516
Validation loss: 3.8659176064506697

Epoch: 5| Step: 6
Training loss: 3.8498090424183298
Validation loss: 3.8682300669185703

Epoch: 5| Step: 7
Training loss: 4.192839904363515
Validation loss: 3.864527897489278

Epoch: 5| Step: 8
Training loss: 3.799224879867626
Validation loss: 3.851017970777801

Epoch: 5| Step: 9
Training loss: 3.6039445988739796
Validation loss: 3.8484964945232574

Epoch: 5| Step: 10
Training loss: 3.9376591241563506
Validation loss: 3.8473181121696114

Epoch: 22| Step: 0
Training loss: 3.7972591504082107
Validation loss: 3.842952589199061

Epoch: 5| Step: 1
Training loss: 4.229562199078532
Validation loss: 3.8418618510289626

Epoch: 5| Step: 2
Training loss: 4.78925147624958
Validation loss: 3.8325657033593163

Epoch: 5| Step: 3
Training loss: 3.985056022336407
Validation loss: 3.8360366977214

Epoch: 5| Step: 4
Training loss: 3.396921385279046
Validation loss: 3.8350406743945866

Epoch: 5| Step: 5
Training loss: 3.297092665587546
Validation loss: 3.8276351029267666

Epoch: 5| Step: 6
Training loss: 3.285641011907853
Validation loss: 3.823087592488213

Epoch: 5| Step: 7
Training loss: 4.262844199325682
Validation loss: 3.8272649894337447

Epoch: 5| Step: 8
Training loss: 4.272431584720598
Validation loss: 3.8181280658503693

Epoch: 5| Step: 9
Training loss: 3.8487536109642244
Validation loss: 3.8134864554378582

Epoch: 5| Step: 10
Training loss: 4.596573772713547
Validation loss: 3.8125183579762574

Epoch: 23| Step: 0
Training loss: 5.127406973959774
Validation loss: 3.812793277950039

Epoch: 5| Step: 1
Training loss: 3.940725549417894
Validation loss: 3.8077963074079095

Epoch: 5| Step: 2
Training loss: 4.4422854557300155
Validation loss: 3.8099318040661427

Epoch: 5| Step: 3
Training loss: 2.9814262801861413
Validation loss: 3.804296821790413

Epoch: 5| Step: 4
Training loss: 3.905009812893425
Validation loss: 3.8007131744400295

Epoch: 5| Step: 5
Training loss: 3.29999080425484
Validation loss: 3.799402109377228

Epoch: 5| Step: 6
Training loss: 2.7922767048543324
Validation loss: 3.799500439194573

Epoch: 5| Step: 7
Training loss: 4.317265627827491
Validation loss: 3.793204129156774

Epoch: 5| Step: 8
Training loss: 4.224002535299061
Validation loss: 3.7892582648174633

Epoch: 5| Step: 9
Training loss: 4.055265587553508
Validation loss: 3.787327391703337

Epoch: 5| Step: 10
Training loss: 4.035069275442144
Validation loss: 3.789009603848542

Epoch: 24| Step: 0
Training loss: 3.8833606724465715
Validation loss: 3.7850191536038906

Epoch: 5| Step: 1
Training loss: 4.255812765061425
Validation loss: 3.7773836051067704

Epoch: 5| Step: 2
Training loss: 5.114036183765929
Validation loss: 3.776352768396044

Epoch: 5| Step: 3
Training loss: 4.462433946478599
Validation loss: 3.7726076627144423

Epoch: 5| Step: 4
Training loss: 3.7554481348654716
Validation loss: 3.7697500752055175

Epoch: 5| Step: 5
Training loss: 3.159280662750664
Validation loss: 3.7660714536130384

Epoch: 5| Step: 6
Training loss: 4.576105811716379
Validation loss: 3.7689565065795985

Epoch: 5| Step: 7
Training loss: 3.2880431564171895
Validation loss: 3.763030478315415

Epoch: 5| Step: 8
Training loss: 2.87835033748208
Validation loss: 3.758999787539033

Epoch: 5| Step: 9
Training loss: 3.575169171152039
Validation loss: 3.7558368364384283

Epoch: 5| Step: 10
Training loss: 3.896509951552962
Validation loss: 3.755896707351951

Epoch: 25| Step: 0
Training loss: 3.832626498748117
Validation loss: 3.752063590881012

Epoch: 5| Step: 1
Training loss: 4.158575110328319
Validation loss: 3.7502402990867307

Epoch: 5| Step: 2
Training loss: 3.3593309976224304
Validation loss: 3.7499082752344584

Epoch: 5| Step: 3
Training loss: 3.65760399942388
Validation loss: 3.745834198393985

Epoch: 5| Step: 4
Training loss: 4.771522350058666
Validation loss: 3.744123674346274

Epoch: 5| Step: 5
Training loss: 4.099172946040791
Validation loss: 3.7398830753803742

Epoch: 5| Step: 6
Training loss: 3.6801674564242615
Validation loss: 3.735056034445395

Epoch: 5| Step: 7
Training loss: 3.5386561145677846
Validation loss: 3.7320095346261724

Epoch: 5| Step: 8
Training loss: 3.8442418473822055
Validation loss: 3.733682315658313

Epoch: 5| Step: 9
Training loss: 4.097454695203846
Validation loss: 3.730196243484037

Epoch: 5| Step: 10
Training loss: 3.9190369326055063
Validation loss: 3.7214093149939904

Epoch: 26| Step: 0
Training loss: 3.751443457949017
Validation loss: 3.719643348774445

Epoch: 5| Step: 1
Training loss: 4.321510962699554
Validation loss: 3.719429741953062

Epoch: 5| Step: 2
Training loss: 4.113879849457381
Validation loss: 3.7135406651999134

Epoch: 5| Step: 3
Training loss: 4.5701829158311895
Validation loss: 3.7133174450524606

Epoch: 5| Step: 4
Training loss: 3.6289653793790104
Validation loss: 3.7076894503707667

Epoch: 5| Step: 5
Training loss: 3.9001495332661205
Validation loss: 3.70849129171145

Epoch: 5| Step: 6
Training loss: 4.000654405468819
Validation loss: 3.7067556067927523

Epoch: 5| Step: 7
Training loss: 4.07127723316973
Validation loss: 3.707161922419414

Epoch: 5| Step: 8
Training loss: 2.99933950782757
Validation loss: 3.6970692841229837

Epoch: 5| Step: 9
Training loss: 3.5277498165701244
Validation loss: 3.7004298186921667

Epoch: 5| Step: 10
Training loss: 3.6967776984649316
Validation loss: 3.6972361295318876

Epoch: 27| Step: 0
Training loss: 3.77074669726133
Validation loss: 3.6975565398603547

Epoch: 5| Step: 1
Training loss: 4.133898529254304
Validation loss: 3.694301255696487

Epoch: 5| Step: 2
Training loss: 3.456449401511609
Validation loss: 3.6909069995669292

Epoch: 5| Step: 3
Training loss: 3.3698922112316625
Validation loss: 3.6894846852490923

Epoch: 5| Step: 4
Training loss: 3.9492048646284705
Validation loss: 3.686898862610991

Epoch: 5| Step: 5
Training loss: 4.6762370793241335
Validation loss: 3.6839909348801148

Epoch: 5| Step: 6
Training loss: 4.069423234267324
Validation loss: 3.6807689479252894

Epoch: 5| Step: 7
Training loss: 4.476960861829106
Validation loss: 3.683845856328493

Epoch: 5| Step: 8
Training loss: 3.1255459117895072
Validation loss: 3.68178640389084

Epoch: 5| Step: 9
Training loss: 3.3039593266345855
Validation loss: 3.6823966932396854

Epoch: 5| Step: 10
Training loss: 3.984571384751216
Validation loss: 3.676275745664917

Epoch: 28| Step: 0
Training loss: 4.908584719547439
Validation loss: 3.6743318729049896

Epoch: 5| Step: 1
Training loss: 2.8986709377335727
Validation loss: 3.6776941788992503

Epoch: 5| Step: 2
Training loss: 3.7040901053161197
Validation loss: 3.669446940338394

Epoch: 5| Step: 3
Training loss: 4.138429225056973
Validation loss: 3.667887187163935

Epoch: 5| Step: 4
Training loss: 4.035033114272592
Validation loss: 3.6672936506611253

Epoch: 5| Step: 5
Training loss: 3.495798722930523
Validation loss: 3.6681603025854295

Epoch: 5| Step: 6
Training loss: 4.213008562399391
Validation loss: 3.6694891228817372

Epoch: 5| Step: 7
Training loss: 2.7869934613959044
Validation loss: 3.670596792673663

Epoch: 5| Step: 8
Training loss: 4.121999400635314
Validation loss: 3.664545910432033

Epoch: 5| Step: 9
Training loss: 4.486114696164006
Validation loss: 3.658694713196437

Epoch: 5| Step: 10
Training loss: 2.8796864336232257
Validation loss: 3.65989207908338

Epoch: 29| Step: 0
Training loss: 4.555179314208687
Validation loss: 3.6640201528286664

Epoch: 5| Step: 1
Training loss: 3.7510496577833052
Validation loss: 3.652308609781188

Epoch: 5| Step: 2
Training loss: 3.9388496871047236
Validation loss: 3.648116448063306

Epoch: 5| Step: 3
Training loss: 3.829362443492756
Validation loss: 3.644920646001407

Epoch: 5| Step: 4
Training loss: 3.737291035503874
Validation loss: 3.6499224470381066

Epoch: 5| Step: 5
Training loss: 3.70144138613067
Validation loss: 3.6481095767635274

Epoch: 5| Step: 6
Training loss: 3.3907899596698914
Validation loss: 3.647128297027874

Epoch: 5| Step: 7
Training loss: 2.7518964643852066
Validation loss: 3.6484113177900888

Epoch: 5| Step: 8
Training loss: 4.124949368252829
Validation loss: 3.654734482966263

Epoch: 5| Step: 9
Training loss: 4.195731200736994
Validation loss: 3.6418611034504216

Epoch: 5| Step: 10
Training loss: 4.022945633238556
Validation loss: 3.6401007088729003

Epoch: 30| Step: 0
Training loss: 3.0594607472701645
Validation loss: 3.635338949767936

Epoch: 5| Step: 1
Training loss: 4.316709592352943
Validation loss: 3.6383070816573535

Epoch: 5| Step: 2
Training loss: 4.288186350345909
Validation loss: 3.637164561358902

Epoch: 5| Step: 3
Training loss: 3.42576886199834
Validation loss: 3.6391133949902796

Epoch: 5| Step: 4
Training loss: 2.698199597304568
Validation loss: 3.6319265657242368

Epoch: 5| Step: 5
Training loss: 4.831043731510469
Validation loss: 3.6342659792906793

Epoch: 5| Step: 6
Training loss: 3.9237932476128514
Validation loss: 3.6281240747468675

Epoch: 5| Step: 7
Training loss: 4.144616387703535
Validation loss: 3.627402201668113

Epoch: 5| Step: 8
Training loss: 3.3497087380488386
Validation loss: 3.6322418085719996

Epoch: 5| Step: 9
Training loss: 4.218226195418849
Validation loss: 3.6315632104917923

Epoch: 5| Step: 10
Training loss: 3.1712354193725525
Validation loss: 3.6212652243498695

Epoch: 31| Step: 0
Training loss: 4.032961459920864
Validation loss: 3.620352473372372

Epoch: 5| Step: 1
Training loss: 3.5405050878597315
Validation loss: 3.619346705446889

Epoch: 5| Step: 2
Training loss: 3.7916693774762087
Validation loss: 3.6144545493370672

Epoch: 5| Step: 3
Training loss: 3.487950564576593
Validation loss: 3.6106111955592084

Epoch: 5| Step: 4
Training loss: 4.281579888992519
Validation loss: 3.608374325659779

Epoch: 5| Step: 5
Training loss: 3.688212051178789
Validation loss: 3.6091251941184086

Epoch: 5| Step: 6
Training loss: 3.1369154548962572
Validation loss: 3.6095317310599317

Epoch: 5| Step: 7
Training loss: 4.30884385960946
Validation loss: 3.6071529565239198

Epoch: 5| Step: 8
Training loss: 3.8997250191019077
Validation loss: 3.603026226301294

Epoch: 5| Step: 9
Training loss: 4.135147790631698
Validation loss: 3.598228922874784

Epoch: 5| Step: 10
Training loss: 3.3028214328690906
Validation loss: 3.6000318598163528

Epoch: 32| Step: 0
Training loss: 3.8905259698114527
Validation loss: 3.5969748275276383

Epoch: 5| Step: 1
Training loss: 2.850948236226342
Validation loss: 3.595537862526763

Epoch: 5| Step: 2
Training loss: 4.113736351173683
Validation loss: 3.600336293666314

Epoch: 5| Step: 3
Training loss: 3.3865951286730094
Validation loss: 3.5988521986191047

Epoch: 5| Step: 4
Training loss: 3.613444226687652
Validation loss: 3.595534870751681

Epoch: 5| Step: 5
Training loss: 3.8365269225582983
Validation loss: 3.595033974287386

Epoch: 5| Step: 6
Training loss: 4.013198535045264
Validation loss: 3.597553457954547

Epoch: 5| Step: 7
Training loss: 3.558905544921548
Validation loss: 3.593507888578112

Epoch: 5| Step: 8
Training loss: 3.4080925953603147
Validation loss: 3.587251813450931

Epoch: 5| Step: 9
Training loss: 4.239703552391158
Validation loss: 3.586726140432157

Epoch: 5| Step: 10
Training loss: 4.6225282404745105
Validation loss: 3.5867155276920197

Epoch: 33| Step: 0
Training loss: 4.0340504936118196
Validation loss: 3.588857129699351

Epoch: 5| Step: 1
Training loss: 3.5401173213332506
Validation loss: 3.5975420262999807

Epoch: 5| Step: 2
Training loss: 3.7856764932889893
Validation loss: 3.5800000264739578

Epoch: 5| Step: 3
Training loss: 3.758391845202541
Validation loss: 3.579094653251685

Epoch: 5| Step: 4
Training loss: 3.5129358475992905
Validation loss: 3.5839481432064835

Epoch: 5| Step: 5
Training loss: 4.065773452054078
Validation loss: 3.590135483150621

Epoch: 5| Step: 6
Training loss: 4.245401475161417
Validation loss: 3.5857791628415434

Epoch: 5| Step: 7
Training loss: 4.147584759269803
Validation loss: 3.581933023855388

Epoch: 5| Step: 8
Training loss: 3.4034927827980765
Validation loss: 3.6035221103685777

Epoch: 5| Step: 9
Training loss: 3.3286171132922235
Validation loss: 3.5838207696508713

Epoch: 5| Step: 10
Training loss: 3.7184734081339768
Validation loss: 3.575379029384932

Epoch: 34| Step: 0
Training loss: 3.748733560971922
Validation loss: 3.577826980866574

Epoch: 5| Step: 1
Training loss: 3.2904147089088944
Validation loss: 3.5774083232758556

Epoch: 5| Step: 2
Training loss: 3.727020299530223
Validation loss: 3.5782434530139975

Epoch: 5| Step: 3
Training loss: 3.2358168184846443
Validation loss: 3.5801843446250268

Epoch: 5| Step: 4
Training loss: 4.193605668928557
Validation loss: 3.5824589135790763

Epoch: 5| Step: 5
Training loss: 3.919235009655977
Validation loss: 3.5783267625467476

Epoch: 5| Step: 6
Training loss: 3.8058832001236453
Validation loss: 3.575785913613379

Epoch: 5| Step: 7
Training loss: 4.24203597723755
Validation loss: 3.5716531390242676

Epoch: 5| Step: 8
Training loss: 3.118906565312108
Validation loss: 3.567095352566704

Epoch: 5| Step: 9
Training loss: 4.251889201618137
Validation loss: 3.5696841621581

Epoch: 5| Step: 10
Training loss: 3.8126276964158263
Validation loss: 3.5665266922847647

Epoch: 35| Step: 0
Training loss: 4.407153530686444
Validation loss: 3.567905480878137

Epoch: 5| Step: 1
Training loss: 4.3029670946767755
Validation loss: 3.5637795655167106

Epoch: 5| Step: 2
Training loss: 3.3308545591816805
Validation loss: 3.56320402093337

Epoch: 5| Step: 3
Training loss: 4.0731039305009284
Validation loss: 3.5615887285082177

Epoch: 5| Step: 4
Training loss: 3.0196727408634967
Validation loss: 3.560920984268342

Epoch: 5| Step: 5
Training loss: 4.069652188972539
Validation loss: 3.5621465001346357

Epoch: 5| Step: 6
Training loss: 3.7724015292694744
Validation loss: 3.5598280132865163

Epoch: 5| Step: 7
Training loss: 2.36030479451107
Validation loss: 3.5581758007262043

Epoch: 5| Step: 8
Training loss: 4.126003721249373
Validation loss: 3.5552812634138795

Epoch: 5| Step: 9
Training loss: 3.915138690581944
Validation loss: 3.5555186348796157

Epoch: 5| Step: 10
Training loss: 3.4764664883160843
Validation loss: 3.558445782253653

Epoch: 36| Step: 0
Training loss: 2.809724413027129
Validation loss: 3.56153740765652

Epoch: 5| Step: 1
Training loss: 3.5307885602738716
Validation loss: 3.5591525564155733

Epoch: 5| Step: 2
Training loss: 4.333175411770209
Validation loss: 3.563615645489134

Epoch: 5| Step: 3
Training loss: 3.723305228345548
Validation loss: 3.55918802573721

Epoch: 5| Step: 4
Training loss: 4.677621018981422
Validation loss: 3.554320623934825

Epoch: 5| Step: 5
Training loss: 3.401207227119018
Validation loss: 3.5530311826565906

Epoch: 5| Step: 6
Training loss: 3.5432947044623453
Validation loss: 3.549094222106933

Epoch: 5| Step: 7
Training loss: 4.085583877578276
Validation loss: 3.548476157324609

Epoch: 5| Step: 8
Training loss: 3.9123918999798986
Validation loss: 3.547466940447518

Epoch: 5| Step: 9
Training loss: 3.1494702332684685
Validation loss: 3.5474192743951205

Epoch: 5| Step: 10
Training loss: 3.7864757399266056
Validation loss: 3.5471539059074764

Epoch: 37| Step: 0
Training loss: 3.7178382076295833
Validation loss: 3.5462161857165735

Epoch: 5| Step: 1
Training loss: 3.2057921679473025
Validation loss: 3.5458480637034726

Epoch: 5| Step: 2
Training loss: 2.9441401326372816
Validation loss: 3.5469964957830915

Epoch: 5| Step: 3
Training loss: 3.7943631878541586
Validation loss: 3.549685216151629

Epoch: 5| Step: 4
Training loss: 4.45744333861277
Validation loss: 3.5556082608391093

Epoch: 5| Step: 5
Training loss: 4.591149456897617
Validation loss: 3.543442950380791

Epoch: 5| Step: 6
Training loss: 2.620971767810541
Validation loss: 3.543945159142152

Epoch: 5| Step: 7
Training loss: 3.82779539596669
Validation loss: 3.5464759144253017

Epoch: 5| Step: 8
Training loss: 3.879873840797895
Validation loss: 3.5461787316099613

Epoch: 5| Step: 9
Training loss: 3.7280894735838723
Validation loss: 3.550128591733996

Epoch: 5| Step: 10
Training loss: 4.097481461134488
Validation loss: 3.547763210369695

Epoch: 38| Step: 0
Training loss: 3.5118841316904157
Validation loss: 3.5439518996473383

Epoch: 5| Step: 1
Training loss: 3.8755091671058253
Validation loss: 3.543161353081308

Epoch: 5| Step: 2
Training loss: 3.550583837076157
Validation loss: 3.543335159789879

Epoch: 5| Step: 3
Training loss: 3.5083314643425996
Validation loss: 3.5444418750080318

Epoch: 5| Step: 4
Training loss: 4.443528714149564
Validation loss: 3.5443759339736434

Epoch: 5| Step: 5
Training loss: 3.4470766701932276
Validation loss: 3.5451788457692057

Epoch: 5| Step: 6
Training loss: 3.5656238713041186
Validation loss: 3.543103830698152

Epoch: 5| Step: 7
Training loss: 2.958036183938716
Validation loss: 3.544469569471618

Epoch: 5| Step: 8
Training loss: 3.5693513006252817
Validation loss: 3.5443632979320463

Epoch: 5| Step: 9
Training loss: 4.845526191159621
Validation loss: 3.542681265073166

Epoch: 5| Step: 10
Training loss: 3.596841030142723
Validation loss: 3.5382398184157138

Epoch: 39| Step: 0
Training loss: 3.9381800473011563
Validation loss: 3.5385175937091162

Epoch: 5| Step: 1
Training loss: 3.4537433053447772
Validation loss: 3.537882910470036

Epoch: 5| Step: 2
Training loss: 3.847489065807885
Validation loss: 3.537471928215706

Epoch: 5| Step: 3
Training loss: 4.2068943295384
Validation loss: 3.536898246338373

Epoch: 5| Step: 4
Training loss: 3.597967973058717
Validation loss: 3.5353719234538814

Epoch: 5| Step: 5
Training loss: 3.5067392589273783
Validation loss: 3.5361187173278967

Epoch: 5| Step: 6
Training loss: 3.6015989090740326
Validation loss: 3.5335176508242014

Epoch: 5| Step: 7
Training loss: 3.5831862722574632
Validation loss: 3.5330789098502997

Epoch: 5| Step: 8
Training loss: 4.150863943599149
Validation loss: 3.532100280734145

Epoch: 5| Step: 9
Training loss: 3.564068097783718
Validation loss: 3.530619287715295

Epoch: 5| Step: 10
Training loss: 3.6347448972575296
Validation loss: 3.534334880195357

Epoch: 40| Step: 0
Training loss: 3.281151470339868
Validation loss: 3.5330406118984112

Epoch: 5| Step: 1
Training loss: 3.2746699159566726
Validation loss: 3.5317581846348873

Epoch: 5| Step: 2
Training loss: 3.85155581460183
Validation loss: 3.531272884479508

Epoch: 5| Step: 3
Training loss: 3.7451268639868474
Validation loss: 3.533790636352656

Epoch: 5| Step: 4
Training loss: 3.3639269839151966
Validation loss: 3.536493182363627

Epoch: 5| Step: 5
Training loss: 3.803923042465566
Validation loss: 3.535881273163921

Epoch: 5| Step: 6
Training loss: 3.8132426054594037
Validation loss: 3.5317140332959416

Epoch: 5| Step: 7
Training loss: 4.1248684486451115
Validation loss: 3.5313935115923027

Epoch: 5| Step: 8
Training loss: 3.510594002218583
Validation loss: 3.529078164270461

Epoch: 5| Step: 9
Training loss: 4.173373863909029
Validation loss: 3.5280586956898885

Epoch: 5| Step: 10
Training loss: 4.0812092660737616
Validation loss: 3.5291825076371914

Epoch: 41| Step: 0
Training loss: 3.084488076839817
Validation loss: 3.5273187512184756

Epoch: 5| Step: 1
Training loss: 3.9863570724849255
Validation loss: 3.5248473027946297

Epoch: 5| Step: 2
Training loss: 3.7482403759407585
Validation loss: 3.527487852209466

Epoch: 5| Step: 3
Training loss: 4.001738647254182
Validation loss: 3.5272970490275855

Epoch: 5| Step: 4
Training loss: 3.826135235037046
Validation loss: 3.530907608059519

Epoch: 5| Step: 5
Training loss: 3.865238446064367
Validation loss: 3.5272803631062972

Epoch: 5| Step: 6
Training loss: 3.3614789185289196
Validation loss: 3.5278193515748852

Epoch: 5| Step: 7
Training loss: 4.149440148519144
Validation loss: 3.5299788566682864

Epoch: 5| Step: 8
Training loss: 3.757167451499328
Validation loss: 3.527364978038908

Epoch: 5| Step: 9
Training loss: 3.474556127507962
Validation loss: 3.5231868355599527

Epoch: 5| Step: 10
Training loss: 3.6985014690351385
Validation loss: 3.523356075195037

Epoch: 42| Step: 0
Training loss: 3.7263237258901483
Validation loss: 3.522763394524316

Epoch: 5| Step: 1
Training loss: 3.5204770662232288
Validation loss: 3.5221866706368683

Epoch: 5| Step: 2
Training loss: 3.3103973624977163
Validation loss: 3.5252395226177575

Epoch: 5| Step: 3
Training loss: 3.5160467954435735
Validation loss: 3.520081095253095

Epoch: 5| Step: 4
Training loss: 4.17295063453799
Validation loss: 3.520013312629703

Epoch: 5| Step: 5
Training loss: 4.7650578395859595
Validation loss: 3.521866841063875

Epoch: 5| Step: 6
Training loss: 3.450529063472889
Validation loss: 3.522611100896326

Epoch: 5| Step: 7
Training loss: 4.084361718877843
Validation loss: 3.523568307772999

Epoch: 5| Step: 8
Training loss: 3.2530493002813583
Validation loss: 3.522107388883375

Epoch: 5| Step: 9
Training loss: 3.5452003054395216
Validation loss: 3.5204700237136715

Epoch: 5| Step: 10
Training loss: 3.3595484489198317
Validation loss: 3.5209510673346935

Epoch: 43| Step: 0
Training loss: 4.03908847232341
Validation loss: 3.515717028435384

Epoch: 5| Step: 1
Training loss: 3.649706340107181
Validation loss: 3.520747167255331

Epoch: 5| Step: 2
Training loss: 4.227623318092299
Validation loss: 3.5209911146280657

Epoch: 5| Step: 3
Training loss: 2.6863866762206863
Validation loss: 3.5212530905398887

Epoch: 5| Step: 4
Training loss: 3.8602770782009155
Validation loss: 3.5189961922214867

Epoch: 5| Step: 5
Training loss: 3.2665748492461546
Validation loss: 3.516676041832084

Epoch: 5| Step: 6
Training loss: 3.918193046257637
Validation loss: 3.5178654882615854

Epoch: 5| Step: 7
Training loss: 3.248366165295324
Validation loss: 3.5177810106737724

Epoch: 5| Step: 8
Training loss: 3.6359306489480736
Validation loss: 3.5179168705143926

Epoch: 5| Step: 9
Training loss: 3.9452065028691163
Validation loss: 3.5199152800567086

Epoch: 5| Step: 10
Training loss: 4.311510940136191
Validation loss: 3.5188442601043572

Epoch: 44| Step: 0
Training loss: 4.394876288537907
Validation loss: 3.5232239425132557

Epoch: 5| Step: 1
Training loss: 3.6210408129726828
Validation loss: 3.518898811764327

Epoch: 5| Step: 2
Training loss: 3.168997826750935
Validation loss: 3.5169847840723123

Epoch: 5| Step: 3
Training loss: 2.7196440706464142
Validation loss: 3.5160470798026466

Epoch: 5| Step: 4
Training loss: 4.184562449854049
Validation loss: 3.5146390280216253

Epoch: 5| Step: 5
Training loss: 4.514053863379805
Validation loss: 3.5174287423343897

Epoch: 5| Step: 6
Training loss: 3.8069748161731467
Validation loss: 3.5197441808133783

Epoch: 5| Step: 7
Training loss: 2.8490502565235274
Validation loss: 3.517173166973297

Epoch: 5| Step: 8
Training loss: 3.4137540979126815
Validation loss: 3.526318464161437

Epoch: 5| Step: 9
Training loss: 3.7298329076081624
Validation loss: 3.5190434929093573

Epoch: 5| Step: 10
Training loss: 4.155004788062025
Validation loss: 3.5134621179608905

Epoch: 45| Step: 0
Training loss: 3.6733283879777003
Validation loss: 3.5147009783971246

Epoch: 5| Step: 1
Training loss: 3.712008094951419
Validation loss: 3.5157999040308567

Epoch: 5| Step: 2
Training loss: 2.8858960209102924
Validation loss: 3.5111246846772044

Epoch: 5| Step: 3
Training loss: 3.500866646417852
Validation loss: 3.510292772324614

Epoch: 5| Step: 4
Training loss: 3.968300741404431
Validation loss: 3.5131553764555217

Epoch: 5| Step: 5
Training loss: 4.229481477091899
Validation loss: 3.510894226344662

Epoch: 5| Step: 6
Training loss: 3.567331751790341
Validation loss: 3.5118070847705285

Epoch: 5| Step: 7
Training loss: 3.8491401405739105
Validation loss: 3.5136565442188497

Epoch: 5| Step: 8
Training loss: 4.125768416532304
Validation loss: 3.5105883061987164

Epoch: 5| Step: 9
Training loss: 3.069595369643596
Validation loss: 3.5137934302879685

Epoch: 5| Step: 10
Training loss: 4.17240416639016
Validation loss: 3.5109849666188873

Epoch: 46| Step: 0
Training loss: 3.672820663423602
Validation loss: 3.5135055304069196

Epoch: 5| Step: 1
Training loss: 4.079501215795594
Validation loss: 3.5135971627120868

Epoch: 5| Step: 2
Training loss: 3.3345685736428723
Validation loss: 3.51052185633236

Epoch: 5| Step: 3
Training loss: 3.867567502242128
Validation loss: 3.5099532267342837

Epoch: 5| Step: 4
Training loss: 3.525393194900379
Validation loss: 3.5164929571630563

Epoch: 5| Step: 5
Training loss: 3.4236217203721706
Validation loss: 3.5125443923848945

Epoch: 5| Step: 6
Training loss: 4.706484586383476
Validation loss: 3.507884621218491

Epoch: 5| Step: 7
Training loss: 4.016879705791646
Validation loss: 3.5067755807786174

Epoch: 5| Step: 8
Training loss: 3.630341113748521
Validation loss: 3.505217557003081

Epoch: 5| Step: 9
Training loss: 2.9174683331991327
Validation loss: 3.508354297367095

Epoch: 5| Step: 10
Training loss: 3.401402655347307
Validation loss: 3.506494087557221

Epoch: 47| Step: 0
Training loss: 3.719063112556799
Validation loss: 3.5055904436442273

Epoch: 5| Step: 1
Training loss: 4.245341272014435
Validation loss: 3.5073305351551056

Epoch: 5| Step: 2
Training loss: 2.9769881136922502
Validation loss: 3.506794444832934

Epoch: 5| Step: 3
Training loss: 4.149758223878879
Validation loss: 3.505647512421287

Epoch: 5| Step: 4
Training loss: 3.105782738892663
Validation loss: 3.506388601101134

Epoch: 5| Step: 5
Training loss: 3.2295596632182124
Validation loss: 3.5056302744401666

Epoch: 5| Step: 6
Training loss: 3.8061638382303182
Validation loss: 3.5051986932389587

Epoch: 5| Step: 7
Training loss: 3.7488460036727207
Validation loss: 3.50685413013761

Epoch: 5| Step: 8
Training loss: 3.982222869675258
Validation loss: 3.5072905416627034

Epoch: 5| Step: 9
Training loss: 4.085761042736083
Validation loss: 3.5046194022110266

Epoch: 5| Step: 10
Training loss: 3.5347525181665915
Validation loss: 3.5064573679854134

Epoch: 48| Step: 0
Training loss: 3.030037234238078
Validation loss: 3.5045267634095496

Epoch: 5| Step: 1
Training loss: 3.612281586799277
Validation loss: 3.5023848616582174

Epoch: 5| Step: 2
Training loss: 4.1514346113452625
Validation loss: 3.4999943255599706

Epoch: 5| Step: 3
Training loss: 4.502405583282892
Validation loss: 3.502894004939801

Epoch: 5| Step: 4
Training loss: 3.9163658080646813
Validation loss: 3.4995253309906924

Epoch: 5| Step: 5
Training loss: 4.34129428743179
Validation loss: 3.502295933494347

Epoch: 5| Step: 6
Training loss: 2.6011866392514897
Validation loss: 3.5047629919030054

Epoch: 5| Step: 7
Training loss: 4.0642698687513406
Validation loss: 3.501133941629307

Epoch: 5| Step: 8
Training loss: 3.298000631671241
Validation loss: 3.500366647328741

Epoch: 5| Step: 9
Training loss: 3.5721035728176362
Validation loss: 3.502590246417256

Epoch: 5| Step: 10
Training loss: 3.2082774334946467
Validation loss: 3.4999561995594397

Epoch: 49| Step: 0
Training loss: 3.245216076538333
Validation loss: 3.502353001787234

Epoch: 5| Step: 1
Training loss: 3.5398151868864582
Validation loss: 3.50402635888939

Epoch: 5| Step: 2
Training loss: 3.786634158635182
Validation loss: 3.5073405051331896

Epoch: 5| Step: 3
Training loss: 3.6634294495774378
Validation loss: 3.507170738268045

Epoch: 5| Step: 4
Training loss: 3.7828600269532187
Validation loss: 3.501497128664894

Epoch: 5| Step: 5
Training loss: 4.027880539441885
Validation loss: 3.5006528529686567

Epoch: 5| Step: 6
Training loss: 3.7627458764526893
Validation loss: 3.4988672207636755

Epoch: 5| Step: 7
Training loss: 3.791639320917695
Validation loss: 3.4988646943928403

Epoch: 5| Step: 8
Training loss: 3.954301500718116
Validation loss: 3.497490783276761

Epoch: 5| Step: 9
Training loss: 3.6263734254605153
Validation loss: 3.49680514728236

Epoch: 5| Step: 10
Training loss: 3.5429504461351886
Validation loss: 3.496600117038139

Epoch: 50| Step: 0
Training loss: 3.623124656973351
Validation loss: 3.4964291702518775

Epoch: 5| Step: 1
Training loss: 3.433168491245693
Validation loss: 3.497779947816792

Epoch: 5| Step: 2
Training loss: 3.91334840881026
Validation loss: 3.492147687661328

Epoch: 5| Step: 3
Training loss: 3.8151498559639716
Validation loss: 3.494232903793044

Epoch: 5| Step: 4
Training loss: 3.790090519772752
Validation loss: 3.4948784306200587

Epoch: 5| Step: 5
Training loss: 4.251444851482295
Validation loss: 3.4956962608345443

Epoch: 5| Step: 6
Training loss: 3.8138885470880473
Validation loss: 3.497962313080239

Epoch: 5| Step: 7
Training loss: 4.0665596265203
Validation loss: 3.4974285089968133

Epoch: 5| Step: 8
Training loss: 3.545891579232902
Validation loss: 3.4973239586026326

Epoch: 5| Step: 9
Training loss: 3.150603881353495
Validation loss: 3.4976935455988554

Epoch: 5| Step: 10
Training loss: 3.1337648689760247
Validation loss: 3.4952479974894977

Epoch: 51| Step: 0
Training loss: 3.589033664293582
Validation loss: 3.4957543990335846

Epoch: 5| Step: 1
Training loss: 3.7455012993617434
Validation loss: 3.492970549158521

Epoch: 5| Step: 2
Training loss: 3.9477335837931613
Validation loss: 3.4925944243162763

Epoch: 5| Step: 3
Training loss: 3.0760832080475375
Validation loss: 3.494169620586731

Epoch: 5| Step: 4
Training loss: 3.6920882306534453
Validation loss: 3.4979382197925037

Epoch: 5| Step: 5
Training loss: 4.3191284985444085
Validation loss: 3.4964097238216176

Epoch: 5| Step: 6
Training loss: 3.5186843784643465
Validation loss: 3.494634783437602

Epoch: 5| Step: 7
Training loss: 3.715257302739815
Validation loss: 3.492709381991104

Epoch: 5| Step: 8
Training loss: 3.541392925379604
Validation loss: 3.4898424897487

Epoch: 5| Step: 9
Training loss: 3.5361777162900796
Validation loss: 3.4911383910543767

Epoch: 5| Step: 10
Training loss: 3.9671582010936848
Validation loss: 3.4919199017323863

Epoch: 52| Step: 0
Training loss: 3.8707849281221804
Validation loss: 3.4917646872787196

Epoch: 5| Step: 1
Training loss: 4.184957387107923
Validation loss: 3.491619140112022

Epoch: 5| Step: 2
Training loss: 3.923220946831347
Validation loss: 3.491119373376308

Epoch: 5| Step: 3
Training loss: 4.414877379152134
Validation loss: 3.4891043062260922

Epoch: 5| Step: 4
Training loss: 3.500351615682437
Validation loss: 3.4911330598291026

Epoch: 5| Step: 5
Training loss: 3.0217171439408155
Validation loss: 3.487285519530572

Epoch: 5| Step: 6
Training loss: 4.035947679602073
Validation loss: 3.488382811362527

Epoch: 5| Step: 7
Training loss: 3.4054150039131725
Validation loss: 3.4897277498490347

Epoch: 5| Step: 8
Training loss: 4.0644144095795465
Validation loss: 3.490076070987743

Epoch: 5| Step: 9
Training loss: 2.9799497059923916
Validation loss: 3.49057806117508

Epoch: 5| Step: 10
Training loss: 2.784152969772717
Validation loss: 3.4891070586213173

Epoch: 53| Step: 0
Training loss: 3.872056027322325
Validation loss: 3.488773286579293

Epoch: 5| Step: 1
Training loss: 3.0131276913187555
Validation loss: 3.4899196873448095

Epoch: 5| Step: 2
Training loss: 3.8515304347438697
Validation loss: 3.4892346700941186

Epoch: 5| Step: 3
Training loss: 3.853823974770465
Validation loss: 3.4892077113268014

Epoch: 5| Step: 4
Training loss: 3.5286923488727613
Validation loss: 3.488713436708667

Epoch: 5| Step: 5
Training loss: 3.6759203115299917
Validation loss: 3.4882134653279713

Epoch: 5| Step: 6
Training loss: 4.364177287415819
Validation loss: 3.4874388221105566

Epoch: 5| Step: 7
Training loss: 3.8423233486017234
Validation loss: 3.4881480282637276

Epoch: 5| Step: 8
Training loss: 3.153900480607647
Validation loss: 3.486053175973803

Epoch: 5| Step: 9
Training loss: 3.9393496331922275
Validation loss: 3.4858353262811796

Epoch: 5| Step: 10
Training loss: 3.3214756981338063
Validation loss: 3.485155829361083

Epoch: 54| Step: 0
Training loss: 3.9895378621483997
Validation loss: 3.4849235543950248

Epoch: 5| Step: 1
Training loss: 3.144265868557055
Validation loss: 3.4855852453718303

Epoch: 5| Step: 2
Training loss: 4.099951087845987
Validation loss: 3.485484242394526

Epoch: 5| Step: 3
Training loss: 3.3476686421791495
Validation loss: 3.4835224334518626

Epoch: 5| Step: 4
Training loss: 3.5268332617867424
Validation loss: 3.4859110174727967

Epoch: 5| Step: 5
Training loss: 4.2311048654658
Validation loss: 3.486640586878624

Epoch: 5| Step: 6
Training loss: 3.6017813460913017
Validation loss: 3.4851847312499746

Epoch: 5| Step: 7
Training loss: 2.831032117666157
Validation loss: 3.4836118783893455

Epoch: 5| Step: 8
Training loss: 4.0393826562548325
Validation loss: 3.487099506683355

Epoch: 5| Step: 9
Training loss: 3.504130106465733
Validation loss: 3.4884046160164446

Epoch: 5| Step: 10
Training loss: 4.112487774398859
Validation loss: 3.482560515858245

Epoch: 55| Step: 0
Training loss: 3.0378961752151303
Validation loss: 3.4822479264048214

Epoch: 5| Step: 1
Training loss: 3.2412774336919457
Validation loss: 3.4826084336114937

Epoch: 5| Step: 2
Training loss: 3.9083956509456734
Validation loss: 3.4827846401900056

Epoch: 5| Step: 3
Training loss: 3.8111422262846246
Validation loss: 3.481497640210302

Epoch: 5| Step: 4
Training loss: 3.6309769125592872
Validation loss: 3.4787812535601224

Epoch: 5| Step: 5
Training loss: 3.722229683965033
Validation loss: 3.480827476484773

Epoch: 5| Step: 6
Training loss: 4.1795994259120075
Validation loss: 3.481140931397543

Epoch: 5| Step: 7
Training loss: 4.593654294217217
Validation loss: 3.479778860541377

Epoch: 5| Step: 8
Training loss: 3.9802793508285728
Validation loss: 3.4791592467766033

Epoch: 5| Step: 9
Training loss: 3.072781955330922
Validation loss: 3.4801601140806295

Epoch: 5| Step: 10
Training loss: 2.987323682362379
Validation loss: 3.4772535230257775

Epoch: 56| Step: 0
Training loss: 3.073917669847945
Validation loss: 3.4800941734645643

Epoch: 5| Step: 1
Training loss: 3.539918909598869
Validation loss: 3.4795912056896383

Epoch: 5| Step: 2
Training loss: 4.231821564199122
Validation loss: 3.4791382558860136

Epoch: 5| Step: 3
Training loss: 4.8667376021001285
Validation loss: 3.4775440857748965

Epoch: 5| Step: 4
Training loss: 3.244746436982036
Validation loss: 3.4770685837586184

Epoch: 5| Step: 5
Training loss: 3.293242853777644
Validation loss: 3.4802020804619533

Epoch: 5| Step: 6
Training loss: 3.1330738291584384
Validation loss: 3.4809176527706276

Epoch: 5| Step: 7
Training loss: 3.5725472632792776
Validation loss: 3.478228185969611

Epoch: 5| Step: 8
Training loss: 3.433121823459213
Validation loss: 3.4786808740008635

Epoch: 5| Step: 9
Training loss: 4.2493148700259935
Validation loss: 3.4794692881201916

Epoch: 5| Step: 10
Training loss: 3.4877223883927595
Validation loss: 3.479830557635241

Epoch: 57| Step: 0
Training loss: 3.816702105983687
Validation loss: 3.4769397353491667

Epoch: 5| Step: 1
Training loss: 3.398391337464853
Validation loss: 3.4774766402952353

Epoch: 5| Step: 2
Training loss: 4.105320543976904
Validation loss: 3.4742041369865895

Epoch: 5| Step: 3
Training loss: 3.987411478907591
Validation loss: 3.4726720880838218

Epoch: 5| Step: 4
Training loss: 3.7487546760349297
Validation loss: 3.478072602266037

Epoch: 5| Step: 5
Training loss: 3.0228889223942366
Validation loss: 3.4737634012679157

Epoch: 5| Step: 6
Training loss: 3.699047821833074
Validation loss: 3.4732141272148227

Epoch: 5| Step: 7
Training loss: 3.8733608101304093
Validation loss: 3.476465039271511

Epoch: 5| Step: 8
Training loss: 4.548738812052571
Validation loss: 3.4748428108510048

Epoch: 5| Step: 9
Training loss: 3.187305818514644
Validation loss: 3.4714167102879885

Epoch: 5| Step: 10
Training loss: 2.653068881570255
Validation loss: 3.4713577036504213

Epoch: 58| Step: 0
Training loss: 3.7057546300632027
Validation loss: 3.4710625047469232

Epoch: 5| Step: 1
Training loss: 3.8003616963964757
Validation loss: 3.4719412566235515

Epoch: 5| Step: 2
Training loss: 3.566276021462007
Validation loss: 3.471895601777758

Epoch: 5| Step: 3
Training loss: 2.8239963808009483
Validation loss: 3.471199336397508

Epoch: 5| Step: 4
Training loss: 3.9853208129863114
Validation loss: 3.4723551561620334

Epoch: 5| Step: 5
Training loss: 3.3631764748941944
Validation loss: 3.4722117708657323

Epoch: 5| Step: 6
Training loss: 4.231807141270524
Validation loss: 3.471968765907285

Epoch: 5| Step: 7
Training loss: 3.673851877041441
Validation loss: 3.469706110807151

Epoch: 5| Step: 8
Training loss: 3.7943990036003
Validation loss: 3.471067931793148

Epoch: 5| Step: 9
Training loss: 3.4437311743136894
Validation loss: 3.471345925835024

Epoch: 5| Step: 10
Training loss: 3.9957148725646667
Validation loss: 3.473564073304772

Epoch: 59| Step: 0
Training loss: 3.320547153932505
Validation loss: 3.469413496536939

Epoch: 5| Step: 1
Training loss: 3.989811318891103
Validation loss: 3.4689693202368543

Epoch: 5| Step: 2
Training loss: 3.559500251153786
Validation loss: 3.47046423387601

Epoch: 5| Step: 3
Training loss: 3.2017095648377043
Validation loss: 3.479011018329483

Epoch: 5| Step: 4
Training loss: 4.237918736296639
Validation loss: 3.481115057327347

Epoch: 5| Step: 5
Training loss: 3.4688169455726676
Validation loss: 3.4748056077768634

Epoch: 5| Step: 6
Training loss: 3.77460431684147
Validation loss: 3.470041448677696

Epoch: 5| Step: 7
Training loss: 3.633454034416129
Validation loss: 3.468009746318723

Epoch: 5| Step: 8
Training loss: 3.528068932627533
Validation loss: 3.4659847895381977

Epoch: 5| Step: 9
Training loss: 4.233050938195916
Validation loss: 3.4657291116762963

Epoch: 5| Step: 10
Training loss: 3.466512422309119
Validation loss: 3.472158337459996

Epoch: 60| Step: 0
Training loss: 2.8704748615492406
Validation loss: 3.4734651549071303

Epoch: 5| Step: 1
Training loss: 3.9452155677294103
Validation loss: 3.4730865751909885

Epoch: 5| Step: 2
Training loss: 3.78197188619395
Validation loss: 3.4753317818492193

Epoch: 5| Step: 3
Training loss: 3.9476899792385134
Validation loss: 3.4752451770854225

Epoch: 5| Step: 4
Training loss: 3.020801114316104
Validation loss: 3.4805139815571566

Epoch: 5| Step: 5
Training loss: 2.7960382840287425
Validation loss: 3.4750537990319406

Epoch: 5| Step: 6
Training loss: 3.7112995814309957
Validation loss: 3.4734826558437732

Epoch: 5| Step: 7
Training loss: 3.4224692747465935
Validation loss: 3.4716831360312295

Epoch: 5| Step: 8
Training loss: 4.677339044163638
Validation loss: 3.4709652271231906

Epoch: 5| Step: 9
Training loss: 4.3719345252325
Validation loss: 3.46576036583732

Epoch: 5| Step: 10
Training loss: 3.462872861761759
Validation loss: 3.465407131251553

Epoch: 61| Step: 0
Training loss: 3.5899986258586494
Validation loss: 3.465878713674653

Epoch: 5| Step: 1
Training loss: 3.421171351160515
Validation loss: 3.4629554496080517

Epoch: 5| Step: 2
Training loss: 4.030118561697396
Validation loss: 3.466744533931135

Epoch: 5| Step: 3
Training loss: 4.078690412941284
Validation loss: 3.464327148269942

Epoch: 5| Step: 4
Training loss: 3.4389964227771483
Validation loss: 3.4632518488225434

Epoch: 5| Step: 5
Training loss: 3.90380062367268
Validation loss: 3.4617541123906435

Epoch: 5| Step: 6
Training loss: 3.6397352973352293
Validation loss: 3.460412108002516

Epoch: 5| Step: 7
Training loss: 3.4770167364771467
Validation loss: 3.462357408326887

Epoch: 5| Step: 8
Training loss: 3.9954334656951036
Validation loss: 3.4619161093158635

Epoch: 5| Step: 9
Training loss: 3.6933385887751276
Validation loss: 3.463023444405233

Epoch: 5| Step: 10
Training loss: 2.9693048862087545
Validation loss: 3.4619641306455717

Epoch: 62| Step: 0
Training loss: 3.2833914898467627
Validation loss: 3.4638869291216454

Epoch: 5| Step: 1
Training loss: 4.18881205031
Validation loss: 3.4634539390529917

Epoch: 5| Step: 2
Training loss: 3.0799768754165324
Validation loss: 3.4620672193375173

Epoch: 5| Step: 3
Training loss: 4.083549312147609
Validation loss: 3.458989924757847

Epoch: 5| Step: 4
Training loss: 3.6070446071166757
Validation loss: 3.463273210628304

Epoch: 5| Step: 5
Training loss: 3.4552032982819543
Validation loss: 3.460351280854148

Epoch: 5| Step: 6
Training loss: 3.1328668375606403
Validation loss: 3.459716848281684

Epoch: 5| Step: 7
Training loss: 3.2717209277816877
Validation loss: 3.458885339081963

Epoch: 5| Step: 8
Training loss: 4.265478557825664
Validation loss: 3.459640300937988

Epoch: 5| Step: 9
Training loss: 3.659228554392476
Validation loss: 3.456912329326844

Epoch: 5| Step: 10
Training loss: 4.213110877775781
Validation loss: 3.458068961100231

Epoch: 63| Step: 0
Training loss: 3.5968153112581107
Validation loss: 3.4574121171676273

Epoch: 5| Step: 1
Training loss: 4.028785129433019
Validation loss: 3.457674205091845

Epoch: 5| Step: 2
Training loss: 4.34899607506858
Validation loss: 3.4584810798912153

Epoch: 5| Step: 3
Training loss: 2.9552154408260622
Validation loss: 3.456467021237702

Epoch: 5| Step: 4
Training loss: 3.439807186933065
Validation loss: 3.4578536454974285

Epoch: 5| Step: 5
Training loss: 3.699873901486624
Validation loss: 3.4557493934577552

Epoch: 5| Step: 6
Training loss: 3.816588913793264
Validation loss: 3.4572912238128963

Epoch: 5| Step: 7
Training loss: 4.058916829883212
Validation loss: 3.4551220061334855

Epoch: 5| Step: 8
Training loss: 3.07380256598576
Validation loss: 3.454664427771304

Epoch: 5| Step: 9
Training loss: 3.7301337126627594
Validation loss: 3.454200441670916

Epoch: 5| Step: 10
Training loss: 3.35838324523134
Validation loss: 3.4545750028919837

Epoch: 64| Step: 0
Training loss: 3.495950672482544
Validation loss: 3.4540825442669507

Epoch: 5| Step: 1
Training loss: 2.9974211098770427
Validation loss: 3.456140377885486

Epoch: 5| Step: 2
Training loss: 4.496970110345392
Validation loss: 3.4554527913988435

Epoch: 5| Step: 3
Training loss: 2.9533313497474962
Validation loss: 3.455014793910798

Epoch: 5| Step: 4
Training loss: 3.2497741914211593
Validation loss: 3.4531010779251576

Epoch: 5| Step: 5
Training loss: 3.4937961636736596
Validation loss: 3.4535743785870867

Epoch: 5| Step: 6
Training loss: 3.525166901228728
Validation loss: 3.4552139543698464

Epoch: 5| Step: 7
Training loss: 3.9886994474214714
Validation loss: 3.4546291921042873

Epoch: 5| Step: 8
Training loss: 4.27053829507615
Validation loss: 3.4535621251689164

Epoch: 5| Step: 9
Training loss: 3.3994697493912733
Validation loss: 3.452217854116072

Epoch: 5| Step: 10
Training loss: 4.223741079717848
Validation loss: 3.452505415158014

Epoch: 65| Step: 0
Training loss: 2.988462674486552
Validation loss: 3.451978952195686

Epoch: 5| Step: 1
Training loss: 3.796225158590032
Validation loss: 3.4519169604699025

Epoch: 5| Step: 2
Training loss: 3.6028351428124186
Validation loss: 3.4526900752209517

Epoch: 5| Step: 3
Training loss: 4.463218840502098
Validation loss: 3.4502788101112234

Epoch: 5| Step: 4
Training loss: 3.524810726414038
Validation loss: 3.450026429740749

Epoch: 5| Step: 5
Training loss: 3.8003761255938717
Validation loss: 3.4497392862951735

Epoch: 5| Step: 6
Training loss: 3.901939760666997
Validation loss: 3.4506743928340318

Epoch: 5| Step: 7
Training loss: 2.8580816293408393
Validation loss: 3.450619243287281

Epoch: 5| Step: 8
Training loss: 3.8186519579000295
Validation loss: 3.4492645608100263

Epoch: 5| Step: 9
Training loss: 3.3170839657395774
Validation loss: 3.4483474855371408

Epoch: 5| Step: 10
Training loss: 4.027733740437953
Validation loss: 3.448848890673559

Epoch: 66| Step: 0
Training loss: 4.349469049431538
Validation loss: 3.4561439717303717

Epoch: 5| Step: 1
Training loss: 3.32959166970226
Validation loss: 3.4558658853630577

Epoch: 5| Step: 2
Training loss: 3.476509145262985
Validation loss: 3.4516988799533252

Epoch: 5| Step: 3
Training loss: 3.837080340473158
Validation loss: 3.4483634040450113

Epoch: 5| Step: 4
Training loss: 3.4450979706629274
Validation loss: 3.4475095338941

Epoch: 5| Step: 5
Training loss: 3.237564062714538
Validation loss: 3.446591087156559

Epoch: 5| Step: 6
Training loss: 3.6930977957177564
Validation loss: 3.446839030369524

Epoch: 5| Step: 7
Training loss: 3.389857332721549
Validation loss: 3.4476131574163587

Epoch: 5| Step: 8
Training loss: 3.876120128553366
Validation loss: 3.4459486412145486

Epoch: 5| Step: 9
Training loss: 3.6179839013428428
Validation loss: 3.446784556539389

Epoch: 5| Step: 10
Training loss: 3.981206374475831
Validation loss: 3.4448005006195643

Epoch: 67| Step: 0
Training loss: 3.5885569328053513
Validation loss: 3.4426591068614636

Epoch: 5| Step: 1
Training loss: 3.5606048629483262
Validation loss: 3.448205782896385

Epoch: 5| Step: 2
Training loss: 3.527809289773154
Validation loss: 3.447286287166976

Epoch: 5| Step: 3
Training loss: 3.307346870181921
Validation loss: 3.444597384486285

Epoch: 5| Step: 4
Training loss: 3.782262997460384
Validation loss: 3.4462996122522656

Epoch: 5| Step: 5
Training loss: 3.6621059895817685
Validation loss: 3.442547737615304

Epoch: 5| Step: 6
Training loss: 3.6099555799546352
Validation loss: 3.445066274550805

Epoch: 5| Step: 7
Training loss: 3.4364755664557918
Validation loss: 3.443300885223907

Epoch: 5| Step: 8
Training loss: 3.768266313427321
Validation loss: 3.4404411449272274

Epoch: 5| Step: 9
Training loss: 3.5742926584742403
Validation loss: 3.4427348373505136

Epoch: 5| Step: 10
Training loss: 4.497131917160834
Validation loss: 3.4428122408596646

Epoch: 68| Step: 0
Training loss: 4.217191054917569
Validation loss: 3.441527264839856

Epoch: 5| Step: 1
Training loss: 3.3465397685589195
Validation loss: 3.4449348695720285

Epoch: 5| Step: 2
Training loss: 3.025660601908597
Validation loss: 3.443301244087324

Epoch: 5| Step: 3
Training loss: 3.526285378144434
Validation loss: 3.444726885968552

Epoch: 5| Step: 4
Training loss: 3.162106811447
Validation loss: 3.4456272021976466

Epoch: 5| Step: 5
Training loss: 3.787340539779571
Validation loss: 3.446796983550657

Epoch: 5| Step: 6
Training loss: 4.051970231047595
Validation loss: 3.443686013496137

Epoch: 5| Step: 7
Training loss: 3.5048192768603843
Validation loss: 3.442585359291772

Epoch: 5| Step: 8
Training loss: 4.099212961718088
Validation loss: 3.4430407976881012

Epoch: 5| Step: 9
Training loss: 3.4223951527911187
Validation loss: 3.442269427205904

Epoch: 5| Step: 10
Training loss: 3.933040697451225
Validation loss: 3.4413411029041208

Epoch: 69| Step: 0
Training loss: 3.5306936180184776
Validation loss: 3.441902530387208

Epoch: 5| Step: 1
Training loss: 4.500763510463977
Validation loss: 3.4414891801738734

Epoch: 5| Step: 2
Training loss: 3.1534544395541455
Validation loss: 3.4432272727609017

Epoch: 5| Step: 3
Training loss: 4.0214959950809535
Validation loss: 3.4454543439559524

Epoch: 5| Step: 4
Training loss: 4.378464553158072
Validation loss: 3.439473389865876

Epoch: 5| Step: 5
Training loss: 3.0494012776544586
Validation loss: 3.4399327310741983

Epoch: 5| Step: 6
Training loss: 3.9886039282036445
Validation loss: 3.436075027459884

Epoch: 5| Step: 7
Training loss: 2.598748320284948
Validation loss: 3.437740125873666

Epoch: 5| Step: 8
Training loss: 3.7647678776853644
Validation loss: 3.4392374489835773

Epoch: 5| Step: 9
Training loss: 3.4786403661483996
Validation loss: 3.435283003394375

Epoch: 5| Step: 10
Training loss: 3.266626085950548
Validation loss: 3.4409441432183403

Epoch: 70| Step: 0
Training loss: 3.218430438427948
Validation loss: 3.4388710710825294

Epoch: 5| Step: 1
Training loss: 4.065973293623913
Validation loss: 3.44182491648295

Epoch: 5| Step: 2
Training loss: 4.255611977951557
Validation loss: 3.4380484940459057

Epoch: 5| Step: 3
Training loss: 2.883030167299094
Validation loss: 3.438455532759772

Epoch: 5| Step: 4
Training loss: 3.3316004699369612
Validation loss: 3.4386661076772875

Epoch: 5| Step: 5
Training loss: 4.115969396271663
Validation loss: 3.437229355405783

Epoch: 5| Step: 6
Training loss: 4.040080490065877
Validation loss: 3.4372989927646627

Epoch: 5| Step: 7
Training loss: 4.060788542366548
Validation loss: 3.4346184788076193

Epoch: 5| Step: 8
Training loss: 3.2394222370746473
Validation loss: 3.437615866400344

Epoch: 5| Step: 9
Training loss: 2.863909684936255
Validation loss: 3.4350932028801995

Epoch: 5| Step: 10
Training loss: 3.7909703436244704
Validation loss: 3.435094346225247

Epoch: 71| Step: 0
Training loss: 4.280939912356062
Validation loss: 3.4342151776531735

Epoch: 5| Step: 1
Training loss: 3.0263715992021734
Validation loss: 3.4340518187292175

Epoch: 5| Step: 2
Training loss: 3.493192592095894
Validation loss: 3.4328207764983265

Epoch: 5| Step: 3
Training loss: 3.8303398109066773
Validation loss: 3.4316180308501165

Epoch: 5| Step: 4
Training loss: 4.520729638007667
Validation loss: 3.4332188382179547

Epoch: 5| Step: 5
Training loss: 2.9434983714899294
Validation loss: 3.4325786574352

Epoch: 5| Step: 6
Training loss: 3.687017635542283
Validation loss: 3.4325306148648695

Epoch: 5| Step: 7
Training loss: 3.2503456518791127
Validation loss: 3.4319995027098056

Epoch: 5| Step: 8
Training loss: 3.692162620922315
Validation loss: 3.431730680378786

Epoch: 5| Step: 9
Training loss: 3.6106318147584093
Validation loss: 3.432883290802903

Epoch: 5| Step: 10
Training loss: 3.5187873689283204
Validation loss: 3.4305418618538797

Epoch: 72| Step: 0
Training loss: 3.089983718730415
Validation loss: 3.4321989708918337

Epoch: 5| Step: 1
Training loss: 4.158193033689023
Validation loss: 3.4319747790222537

Epoch: 5| Step: 2
Training loss: 4.295837499034994
Validation loss: 3.429599863715888

Epoch: 5| Step: 3
Training loss: 3.209852643299879
Validation loss: 3.4307709043523396

Epoch: 5| Step: 4
Training loss: 3.6990787596432635
Validation loss: 3.429144453861596

Epoch: 5| Step: 5
Training loss: 3.4224836252404574
Validation loss: 3.431687631546054

Epoch: 5| Step: 6
Training loss: 3.742024141381589
Validation loss: 3.429617032351611

Epoch: 5| Step: 7
Training loss: 3.3613755058216412
Validation loss: 3.4332691187418307

Epoch: 5| Step: 8
Training loss: 3.588637455444767
Validation loss: 3.4333317503271883

Epoch: 5| Step: 9
Training loss: 3.839994999961777
Validation loss: 3.4287181124034105

Epoch: 5| Step: 10
Training loss: 3.5366307676784197
Validation loss: 3.4289990673037662

Epoch: 73| Step: 0
Training loss: 3.845189763063046
Validation loss: 3.42920989695843

Epoch: 5| Step: 1
Training loss: 3.541472500733234
Validation loss: 3.4314456876648634

Epoch: 5| Step: 2
Training loss: 3.5315208668757303
Validation loss: 3.4284877588045903

Epoch: 5| Step: 3
Training loss: 3.9285353076810052
Validation loss: 3.43073810892498

Epoch: 5| Step: 4
Training loss: 2.9366565873329944
Validation loss: 3.4297998197713695

Epoch: 5| Step: 5
Training loss: 4.010097395173141
Validation loss: 3.4296740063706848

Epoch: 5| Step: 6
Training loss: 3.3435062783092335
Validation loss: 3.427289267187903

Epoch: 5| Step: 7
Training loss: 3.571737393242485
Validation loss: 3.4276441413280376

Epoch: 5| Step: 8
Training loss: 4.458317670467826
Validation loss: 3.4247604658214574

Epoch: 5| Step: 9
Training loss: 3.087181748269866
Validation loss: 3.4261682024565245

Epoch: 5| Step: 10
Training loss: 3.601921146434135
Validation loss: 3.4274104304140165

Epoch: 74| Step: 0
Training loss: 3.5485322416382648
Validation loss: 3.4264301228971203

Epoch: 5| Step: 1
Training loss: 4.070160436443944
Validation loss: 3.426335450877948

Epoch: 5| Step: 2
Training loss: 2.5261610704234885
Validation loss: 3.4272135739015472

Epoch: 5| Step: 3
Training loss: 3.681135083203747
Validation loss: 3.4250711358053403

Epoch: 5| Step: 4
Training loss: 3.406180844786092
Validation loss: 3.424860280427131

Epoch: 5| Step: 5
Training loss: 4.034208409824223
Validation loss: 3.4248109064552414

Epoch: 5| Step: 6
Training loss: 3.6641853490866065
Validation loss: 3.4248762437273252

Epoch: 5| Step: 7
Training loss: 3.571441004595232
Validation loss: 3.425537079720012

Epoch: 5| Step: 8
Training loss: 3.776862633568269
Validation loss: 3.4250095792150943

Epoch: 5| Step: 9
Training loss: 3.8863206209015777
Validation loss: 3.4240150174852486

Epoch: 5| Step: 10
Training loss: 3.6951551988603333
Validation loss: 3.42422663615614

Epoch: 75| Step: 0
Training loss: 3.215058515381053
Validation loss: 3.426602704876589

Epoch: 5| Step: 1
Training loss: 3.7250658784711708
Validation loss: 3.426718644978914

Epoch: 5| Step: 2
Training loss: 3.471047405282976
Validation loss: 3.4268242557634303

Epoch: 5| Step: 3
Training loss: 3.6729954085597862
Validation loss: 3.4296193929575516

Epoch: 5| Step: 4
Training loss: 2.931564340227926
Validation loss: 3.4249492685518756

Epoch: 5| Step: 5
Training loss: 2.8001148915561136
Validation loss: 3.424467825273274

Epoch: 5| Step: 6
Training loss: 4.445907579759578
Validation loss: 3.4258854888369354

Epoch: 5| Step: 7
Training loss: 3.2239267145351427
Validation loss: 3.423527595215628

Epoch: 5| Step: 8
Training loss: 4.129806492592572
Validation loss: 3.421987696816684

Epoch: 5| Step: 9
Training loss: 3.8915498545811946
Validation loss: 3.4202342587248253

Epoch: 5| Step: 10
Training loss: 4.241597564873847
Validation loss: 3.420486546849178

Epoch: 76| Step: 0
Training loss: 3.9345707972666615
Validation loss: 3.419286327387718

Epoch: 5| Step: 1
Training loss: 3.3983552769327745
Validation loss: 3.421551823859735

Epoch: 5| Step: 2
Training loss: 3.7348373318425403
Validation loss: 3.418285795587525

Epoch: 5| Step: 3
Training loss: 3.2700947375091682
Validation loss: 3.420670664555097

Epoch: 5| Step: 4
Training loss: 3.1293329336098132
Validation loss: 3.420701101308734

Epoch: 5| Step: 5
Training loss: 3.997785670586198
Validation loss: 3.420772047151974

Epoch: 5| Step: 6
Training loss: 3.8002143899772336
Validation loss: 3.4197750933243447

Epoch: 5| Step: 7
Training loss: 3.280043752657599
Validation loss: 3.41887189398812

Epoch: 5| Step: 8
Training loss: 3.982686002689706
Validation loss: 3.420055907365243

Epoch: 5| Step: 9
Training loss: 4.170313625114006
Validation loss: 3.4191198063615706

Epoch: 5| Step: 10
Training loss: 3.035034020121669
Validation loss: 3.418380935028002

Epoch: 77| Step: 0
Training loss: 3.1758276453887313
Validation loss: 3.4190486905182493

Epoch: 5| Step: 1
Training loss: 4.000466557949761
Validation loss: 3.42022060337411

Epoch: 5| Step: 2
Training loss: 4.072091151463238
Validation loss: 3.4246200763981807

Epoch: 5| Step: 3
Training loss: 3.689354640278319
Validation loss: 3.4188117090083425

Epoch: 5| Step: 4
Training loss: 2.8016523764853076
Validation loss: 3.4189886946070676

Epoch: 5| Step: 5
Training loss: 4.197730477544905
Validation loss: 3.417245693249473

Epoch: 5| Step: 6
Training loss: 4.190767067045065
Validation loss: 3.4176111459074177

Epoch: 5| Step: 7
Training loss: 3.437482521706275
Validation loss: 3.4172292921911054

Epoch: 5| Step: 8
Training loss: 3.7332249869791885
Validation loss: 3.416914860084248

Epoch: 5| Step: 9
Training loss: 2.8804357805633694
Validation loss: 3.4161462700141345

Epoch: 5| Step: 10
Training loss: 3.487535215357249
Validation loss: 3.415607155055593

Epoch: 78| Step: 0
Training loss: 2.105034778153636
Validation loss: 3.4149719815543236

Epoch: 5| Step: 1
Training loss: 3.8223475865078673
Validation loss: 3.4139729247283133

Epoch: 5| Step: 2
Training loss: 3.3293005071734556
Validation loss: 3.4124047792661636

Epoch: 5| Step: 3
Training loss: 4.0327990017723785
Validation loss: 3.4149379563770608

Epoch: 5| Step: 4
Training loss: 4.122767451154482
Validation loss: 3.412985789063352

Epoch: 5| Step: 5
Training loss: 3.18672320306443
Validation loss: 3.414448460480804

Epoch: 5| Step: 6
Training loss: 3.3252039165637584
Validation loss: 3.4144959300767677

Epoch: 5| Step: 7
Training loss: 4.154705477672415
Validation loss: 3.413461704169932

Epoch: 5| Step: 8
Training loss: 2.964879454145194
Validation loss: 3.413614777373591

Epoch: 5| Step: 9
Training loss: 4.159002783533858
Validation loss: 3.4147896947142335

Epoch: 5| Step: 10
Training loss: 4.280008177704887
Validation loss: 3.4143940089842295

Epoch: 79| Step: 0
Training loss: 3.788012046319484
Validation loss: 3.4159200819574354

Epoch: 5| Step: 1
Training loss: 3.1209828305736242
Validation loss: 3.4171697234731324

Epoch: 5| Step: 2
Training loss: 4.155688714009284
Validation loss: 3.41474561999299

Epoch: 5| Step: 3
Training loss: 3.7871821506190817
Validation loss: 3.4164929729723945

Epoch: 5| Step: 4
Training loss: 4.016195412581541
Validation loss: 3.420489651259778

Epoch: 5| Step: 5
Training loss: 3.9718416442190807
Validation loss: 3.419603852068108

Epoch: 5| Step: 6
Training loss: 2.853255931778894
Validation loss: 3.421469757647264

Epoch: 5| Step: 7
Training loss: 3.090701981097808
Validation loss: 3.418133684576597

Epoch: 5| Step: 8
Training loss: 3.7625491927977044
Validation loss: 3.413292232666225

Epoch: 5| Step: 9
Training loss: 3.0709991851974494
Validation loss: 3.4110790115382983

Epoch: 5| Step: 10
Training loss: 4.104236014824301
Validation loss: 3.4097057438174527

Epoch: 80| Step: 0
Training loss: 2.9978269017936436
Validation loss: 3.410450125347288

Epoch: 5| Step: 1
Training loss: 3.106971310043842
Validation loss: 3.4110181479237554

Epoch: 5| Step: 2
Training loss: 4.1550020337702325
Validation loss: 3.4096418406530535

Epoch: 5| Step: 3
Training loss: 3.7823898236855906
Validation loss: 3.4090456245798073

Epoch: 5| Step: 4
Training loss: 4.2998633518241425
Validation loss: 3.408873757854183

Epoch: 5| Step: 5
Training loss: 4.32556848042347
Validation loss: 3.4097554959084664

Epoch: 5| Step: 6
Training loss: 2.830765982174684
Validation loss: 3.408755092208443

Epoch: 5| Step: 7
Training loss: 3.9673505102790116
Validation loss: 3.409865979164103

Epoch: 5| Step: 8
Training loss: 3.7383941346347607
Validation loss: 3.4093246544521314

Epoch: 5| Step: 9
Training loss: 3.3053557890323764
Validation loss: 3.408836143908083

Epoch: 5| Step: 10
Training loss: 2.8331847058376867
Validation loss: 3.409698583041455

Epoch: 81| Step: 0
Training loss: 2.6989815769252274
Validation loss: 3.410065554200823

Epoch: 5| Step: 1
Training loss: 3.648702411713732
Validation loss: 3.4090147558825725

Epoch: 5| Step: 2
Training loss: 3.062302407877524
Validation loss: 3.4083088070593517

Epoch: 5| Step: 3
Training loss: 3.896763627602934
Validation loss: 3.40848002910996

Epoch: 5| Step: 4
Training loss: 3.86904350979206
Validation loss: 3.4114872406191394

Epoch: 5| Step: 5
Training loss: 4.168688753927789
Validation loss: 3.405959114749252

Epoch: 5| Step: 6
Training loss: 3.5714188412125054
Validation loss: 3.407783931347944

Epoch: 5| Step: 7
Training loss: 3.3800305210518715
Validation loss: 3.408088115125921

Epoch: 5| Step: 8
Training loss: 4.008194873557071
Validation loss: 3.406383065120222

Epoch: 5| Step: 9
Training loss: 3.7125777624957736
Validation loss: 3.4078269680634024

Epoch: 5| Step: 10
Training loss: 3.6381717651486176
Validation loss: 3.4080995759689885

Epoch: 82| Step: 0
Training loss: 3.5526390796901945
Validation loss: 3.405020842852272

Epoch: 5| Step: 1
Training loss: 3.6053650614830253
Validation loss: 3.403471202456424

Epoch: 5| Step: 2
Training loss: 3.799155221698578
Validation loss: 3.4059082744926266

Epoch: 5| Step: 3
Training loss: 3.871361408545915
Validation loss: 3.4053271510101917

Epoch: 5| Step: 4
Training loss: 3.8827293586656335
Validation loss: 3.4041085173731447

Epoch: 5| Step: 5
Training loss: 3.7058566677581815
Validation loss: 3.403305347879524

Epoch: 5| Step: 6
Training loss: 4.019123853792518
Validation loss: 3.404198279912855

Epoch: 5| Step: 7
Training loss: 3.2110628349550088
Validation loss: 3.403357194215836

Epoch: 5| Step: 8
Training loss: 3.2597185226337806
Validation loss: 3.4022684888256767

Epoch: 5| Step: 9
Training loss: 3.002970496419864
Validation loss: 3.4029979130387167

Epoch: 5| Step: 10
Training loss: 3.8432783132046295
Validation loss: 3.402064407545466

Epoch: 83| Step: 0
Training loss: 4.457882344380333
Validation loss: 3.401799849926653

Epoch: 5| Step: 1
Training loss: 3.0192533022139245
Validation loss: 3.4031901061955687

Epoch: 5| Step: 2
Training loss: 3.4881943097018446
Validation loss: 3.403109670334239

Epoch: 5| Step: 3
Training loss: 3.784356598687263
Validation loss: 3.401737882024999

Epoch: 5| Step: 4
Training loss: 3.443999371093267
Validation loss: 3.4013756018954697

Epoch: 5| Step: 5
Training loss: 3.3703991648461327
Validation loss: 3.4009341798157506

Epoch: 5| Step: 6
Training loss: 3.211221130170046
Validation loss: 3.3995615015887046

Epoch: 5| Step: 7
Training loss: 3.8950993191515266
Validation loss: 3.3993528919905183

Epoch: 5| Step: 8
Training loss: 4.088466350404351
Validation loss: 3.40084895658829

Epoch: 5| Step: 9
Training loss: 3.6198554529657962
Validation loss: 3.3999780452424786

Epoch: 5| Step: 10
Training loss: 3.1641019842250895
Validation loss: 3.39877579640907

Epoch: 84| Step: 0
Training loss: 3.902489645123719
Validation loss: 3.399996679209101

Epoch: 5| Step: 1
Training loss: 3.9126302874142365
Validation loss: 3.398713743953007

Epoch: 5| Step: 2
Training loss: 3.6490317275303252
Validation loss: 3.3968646754907454

Epoch: 5| Step: 3
Training loss: 3.3837815938319453
Validation loss: 3.39825119622457

Epoch: 5| Step: 4
Training loss: 3.66514171331567
Validation loss: 3.3979138050150413

Epoch: 5| Step: 5
Training loss: 4.069621256233736
Validation loss: 3.397302249593965

Epoch: 5| Step: 6
Training loss: 3.968263250824501
Validation loss: 3.397122987092208

Epoch: 5| Step: 7
Training loss: 3.17461708943784
Validation loss: 3.397476670361826

Epoch: 5| Step: 8
Training loss: 3.018281389277819
Validation loss: 3.397542483490874

Epoch: 5| Step: 9
Training loss: 3.49952735434321
Validation loss: 3.397059820746956

Epoch: 5| Step: 10
Training loss: 3.4167239641797087
Validation loss: 3.396510795650847

Epoch: 85| Step: 0
Training loss: 2.9519315053752107
Validation loss: 3.3958503430306215

Epoch: 5| Step: 1
Training loss: 4.274493155075592
Validation loss: 3.395033523936776

Epoch: 5| Step: 2
Training loss: 3.411841746131695
Validation loss: 3.3942674148931755

Epoch: 5| Step: 3
Training loss: 3.7339666294921723
Validation loss: 3.3939306889366296

Epoch: 5| Step: 4
Training loss: 3.7208976634673885
Validation loss: 3.3928399213782052

Epoch: 5| Step: 5
Training loss: 3.4925263856998376
Validation loss: 3.394965545541324

Epoch: 5| Step: 6
Training loss: 2.784241685340936
Validation loss: 3.3944079267919203

Epoch: 5| Step: 7
Training loss: 3.706064465978536
Validation loss: 3.393020670445253

Epoch: 5| Step: 8
Training loss: 3.9510397254918295
Validation loss: 3.391584754731348

Epoch: 5| Step: 9
Training loss: 3.332291265362239
Validation loss: 3.3949471716662716

Epoch: 5| Step: 10
Training loss: 4.245201543509982
Validation loss: 3.391667581847197

Epoch: 86| Step: 0
Training loss: 3.86057352460004
Validation loss: 3.3934563197069334

Epoch: 5| Step: 1
Training loss: 3.049255223878303
Validation loss: 3.392888253946989

Epoch: 5| Step: 2
Training loss: 3.7525040213647856
Validation loss: 3.3923060064300032

Epoch: 5| Step: 3
Training loss: 3.7693756545769466
Validation loss: 3.3906235240987694

Epoch: 5| Step: 4
Training loss: 3.5685718391694845
Validation loss: 3.3906554100760107

Epoch: 5| Step: 5
Training loss: 3.1691573202868204
Validation loss: 3.3916511976918238

Epoch: 5| Step: 6
Training loss: 3.9130166002170523
Validation loss: 3.390840193435891

Epoch: 5| Step: 7
Training loss: 3.934608366501258
Validation loss: 3.390435615151105

Epoch: 5| Step: 8
Training loss: 3.7480866955365775
Validation loss: 3.3899868108935856

Epoch: 5| Step: 9
Training loss: 3.267759948523875
Validation loss: 3.3906783331350225

Epoch: 5| Step: 10
Training loss: 3.628633716808137
Validation loss: 3.390277384833785

Epoch: 87| Step: 0
Training loss: 4.249379729840451
Validation loss: 3.390492991249971

Epoch: 5| Step: 1
Training loss: 3.58113085164096
Validation loss: 3.389950317622288

Epoch: 5| Step: 2
Training loss: 3.886506010588034
Validation loss: 3.390000485181736

Epoch: 5| Step: 3
Training loss: 3.1424790408847443
Validation loss: 3.390331251994606

Epoch: 5| Step: 4
Training loss: 3.3400095045217175
Validation loss: 3.390589430752737

Epoch: 5| Step: 5
Training loss: 3.672481275787298
Validation loss: 3.3916073147348462

Epoch: 5| Step: 6
Training loss: 4.058471090392629
Validation loss: 3.39117989031241

Epoch: 5| Step: 7
Training loss: 2.843338653660843
Validation loss: 3.389145797409105

Epoch: 5| Step: 8
Training loss: 3.7322974391377675
Validation loss: 3.390299974709627

Epoch: 5| Step: 9
Training loss: 3.5973847956764455
Validation loss: 3.3948415282616016

Epoch: 5| Step: 10
Training loss: 3.3838782624877206
Validation loss: 3.3930702055448485

Epoch: 88| Step: 0
Training loss: 3.6215622484649956
Validation loss: 3.3878947346430914

Epoch: 5| Step: 1
Training loss: 4.013016978201561
Validation loss: 3.3918315135265305

Epoch: 5| Step: 2
Training loss: 3.697776440751107
Validation loss: 3.388783897464915

Epoch: 5| Step: 3
Training loss: 4.237401352355859
Validation loss: 3.3893974210002886

Epoch: 5| Step: 4
Training loss: 2.4906546443768858
Validation loss: 3.387662004713075

Epoch: 5| Step: 5
Training loss: 3.807358824228505
Validation loss: 3.3878085038579773

Epoch: 5| Step: 6
Training loss: 3.610016208517191
Validation loss: 3.386152352161028

Epoch: 5| Step: 7
Training loss: 3.467841776950878
Validation loss: 3.387593329733637

Epoch: 5| Step: 8
Training loss: 2.4317538683156474
Validation loss: 3.3860535967009198

Epoch: 5| Step: 9
Training loss: 3.6790820229032675
Validation loss: 3.387623149502765

Epoch: 5| Step: 10
Training loss: 4.2543279265434375
Validation loss: 3.385470006378982

Epoch: 89| Step: 0
Training loss: 4.387204395562995
Validation loss: 3.384298288594411

Epoch: 5| Step: 1
Training loss: 3.5370423738736347
Validation loss: 3.3864218916507047

Epoch: 5| Step: 2
Training loss: 3.297155865461544
Validation loss: 3.38417757415349

Epoch: 5| Step: 3
Training loss: 4.162296572001555
Validation loss: 3.3852895122467803

Epoch: 5| Step: 4
Training loss: 3.000533692254512
Validation loss: 3.3849601181554427

Epoch: 5| Step: 5
Training loss: 3.300842934658459
Validation loss: 3.384502820785967

Epoch: 5| Step: 6
Training loss: 3.6019045983812292
Validation loss: 3.3842571358424776

Epoch: 5| Step: 7
Training loss: 3.6053442969700997
Validation loss: 3.3849390119215514

Epoch: 5| Step: 8
Training loss: 3.7821350322968184
Validation loss: 3.383093005457177

Epoch: 5| Step: 9
Training loss: 3.568760774666309
Validation loss: 3.386667222737635

Epoch: 5| Step: 10
Training loss: 3.115289784479797
Validation loss: 3.3826376702056646

Epoch: 90| Step: 0
Training loss: 3.6938140605399687
Validation loss: 3.3844772153601625

Epoch: 5| Step: 1
Training loss: 3.5226802308194194
Validation loss: 3.3891433208669293

Epoch: 5| Step: 2
Training loss: 4.175683729640614
Validation loss: 3.388605284349085

Epoch: 5| Step: 3
Training loss: 3.5042762518465023
Validation loss: 3.3834428317200302

Epoch: 5| Step: 4
Training loss: 3.464259497272241
Validation loss: 3.3833472644764195

Epoch: 5| Step: 5
Training loss: 3.7024145289825916
Validation loss: 3.3824193840150842

Epoch: 5| Step: 6
Training loss: 3.317489177625837
Validation loss: 3.381940307354117

Epoch: 5| Step: 7
Training loss: 3.4982454806911805
Validation loss: 3.3819497206619262

Epoch: 5| Step: 8
Training loss: 3.5329761168609064
Validation loss: 3.3826770207326264

Epoch: 5| Step: 9
Training loss: 3.2882009360922826
Validation loss: 3.3813393599507373

Epoch: 5| Step: 10
Training loss: 3.915259629333397
Validation loss: 3.3819522797914896

Epoch: 91| Step: 0
Training loss: 4.304969736805876
Validation loss: 3.380915296227423

Epoch: 5| Step: 1
Training loss: 2.865799986510417
Validation loss: 3.382778164992642

Epoch: 5| Step: 2
Training loss: 3.164417388228264
Validation loss: 3.3809817759820473

Epoch: 5| Step: 3
Training loss: 3.7731278886795043
Validation loss: 3.380043839701093

Epoch: 5| Step: 4
Training loss: 3.621454017272448
Validation loss: 3.378653219094023

Epoch: 5| Step: 5
Training loss: 3.269362943229985
Validation loss: 3.382130865260121

Epoch: 5| Step: 6
Training loss: 3.801104415218112
Validation loss: 3.3792441058888696

Epoch: 5| Step: 7
Training loss: 3.910310999411886
Validation loss: 3.382011161977651

Epoch: 5| Step: 8
Training loss: 3.674046689903361
Validation loss: 3.383434951612405

Epoch: 5| Step: 9
Training loss: 3.576882492289544
Validation loss: 3.382713218084061

Epoch: 5| Step: 10
Training loss: 3.4413407110583227
Validation loss: 3.386418176119816

Epoch: 92| Step: 0
Training loss: 3.3802869853237927
Validation loss: 3.3922671696487234

Epoch: 5| Step: 1
Training loss: 3.6262323323726413
Validation loss: 3.381137365981975

Epoch: 5| Step: 2
Training loss: 3.815993162696839
Validation loss: 3.380431874773056

Epoch: 5| Step: 3
Training loss: 3.6704805364099213
Validation loss: 3.377204314932928

Epoch: 5| Step: 4
Training loss: 3.6458621360004386
Validation loss: 3.377063216283815

Epoch: 5| Step: 5
Training loss: 3.4805895851814577
Validation loss: 3.375086990991533

Epoch: 5| Step: 6
Training loss: 3.461083953720942
Validation loss: 3.3758872995325295

Epoch: 5| Step: 7
Training loss: 3.3108961433106825
Validation loss: 3.3773758356189827

Epoch: 5| Step: 8
Training loss: 3.696394586505606
Validation loss: 3.3770537544349843

Epoch: 5| Step: 9
Training loss: 3.2656690968725774
Validation loss: 3.3754363330550414

Epoch: 5| Step: 10
Training loss: 4.274819772947922
Validation loss: 3.374311883646146

Epoch: 93| Step: 0
Training loss: 3.473643657076479
Validation loss: 3.3731013479364242

Epoch: 5| Step: 1
Training loss: 3.6179839013428428
Validation loss: 3.376127180148114

Epoch: 5| Step: 2
Training loss: 3.5565829746322994
Validation loss: 3.3730212190913775

Epoch: 5| Step: 3
Training loss: 3.069929181502948
Validation loss: 3.3729160290418347

Epoch: 5| Step: 4
Training loss: 3.8601000641418595
Validation loss: 3.375243587963002

Epoch: 5| Step: 5
Training loss: 3.2551205717336242
Validation loss: 3.3752357114990623

Epoch: 5| Step: 6
Training loss: 4.235726566613943
Validation loss: 3.377697342653606

Epoch: 5| Step: 7
Training loss: 3.073086405231085
Validation loss: 3.3771593970842155

Epoch: 5| Step: 8
Training loss: 3.6169516566860827
Validation loss: 3.380808433314376

Epoch: 5| Step: 9
Training loss: 3.6438627457883266
Validation loss: 3.3824138594512347

Epoch: 5| Step: 10
Training loss: 4.057834234756
Validation loss: 3.379498176573596

Epoch: 94| Step: 0
Training loss: 3.750511007459868
Validation loss: 3.378068333597573

Epoch: 5| Step: 1
Training loss: 3.8177683965616818
Validation loss: 3.3760945175836334

Epoch: 5| Step: 2
Training loss: 3.800364080354606
Validation loss: 3.3761346247447594

Epoch: 5| Step: 3
Training loss: 3.50497301208293
Validation loss: 3.375204968048882

Epoch: 5| Step: 4
Training loss: 3.4154015191374305
Validation loss: 3.371944183476498

Epoch: 5| Step: 5
Training loss: 3.454262938651431
Validation loss: 3.373285240041437

Epoch: 5| Step: 6
Training loss: 3.3260937433479794
Validation loss: 3.373424315648503

Epoch: 5| Step: 7
Training loss: 3.3323440673244153
Validation loss: 3.3720062419785073

Epoch: 5| Step: 8
Training loss: 3.998599164764648
Validation loss: 3.3698605685076406

Epoch: 5| Step: 9
Training loss: 3.288789352709313
Validation loss: 3.3694944805872358

Epoch: 5| Step: 10
Training loss: 3.8024591268917183
Validation loss: 3.3687053790322037

Epoch: 95| Step: 0
Training loss: 3.7276838682739113
Validation loss: 3.3701419876775085

Epoch: 5| Step: 1
Training loss: 3.2103490731172286
Validation loss: 3.369884205865093

Epoch: 5| Step: 2
Training loss: 2.787521064576073
Validation loss: 3.3696810132067667

Epoch: 5| Step: 3
Training loss: 3.831218232712342
Validation loss: 3.36983055199706

Epoch: 5| Step: 4
Training loss: 3.605454334300474
Validation loss: 3.371358553042564

Epoch: 5| Step: 5
Training loss: 3.2103296154646177
Validation loss: 3.369003495607118

Epoch: 5| Step: 6
Training loss: 4.272231578665085
Validation loss: 3.366849704332792

Epoch: 5| Step: 7
Training loss: 3.4826425941340236
Validation loss: 3.366791878862061

Epoch: 5| Step: 8
Training loss: 2.8074738414493488
Validation loss: 3.3667915225038643

Epoch: 5| Step: 9
Training loss: 4.271243911484288
Validation loss: 3.3679383559465244

Epoch: 5| Step: 10
Training loss: 4.0082500731980275
Validation loss: 3.3670204474619903

Epoch: 96| Step: 0
Training loss: 2.556531981046019
Validation loss: 3.3657737314329115

Epoch: 5| Step: 1
Training loss: 3.113298863608817
Validation loss: 3.3650837619470635

Epoch: 5| Step: 2
Training loss: 3.113241274396345
Validation loss: 3.3658381688963224

Epoch: 5| Step: 3
Training loss: 3.001868302009984
Validation loss: 3.365871834314481

Epoch: 5| Step: 4
Training loss: 3.5032230251185412
Validation loss: 3.368340961753948

Epoch: 5| Step: 5
Training loss: 3.652756024107725
Validation loss: 3.365598763025329

Epoch: 5| Step: 6
Training loss: 3.8748851882169095
Validation loss: 3.3689200230075573

Epoch: 5| Step: 7
Training loss: 3.752678232655536
Validation loss: 3.367176594266972

Epoch: 5| Step: 8
Training loss: 4.034191389212332
Validation loss: 3.3668100774462912

Epoch: 5| Step: 9
Training loss: 4.165397501612007
Validation loss: 3.367233123405496

Epoch: 5| Step: 10
Training loss: 4.410250531819929
Validation loss: 3.3655006735126043

Epoch: 97| Step: 0
Training loss: 3.4198563426224213
Validation loss: 3.3660917358546865

Epoch: 5| Step: 1
Training loss: 3.1222233452875994
Validation loss: 3.3646561697819997

Epoch: 5| Step: 2
Training loss: 3.1912523510360575
Validation loss: 3.3663452532513407

Epoch: 5| Step: 3
Training loss: 3.7792903141092924
Validation loss: 3.3634601774238746

Epoch: 5| Step: 4
Training loss: 3.8980940245106686
Validation loss: 3.363292293371573

Epoch: 5| Step: 5
Training loss: 4.100607682761169
Validation loss: 3.3673131067693034

Epoch: 5| Step: 6
Training loss: 3.9183379861686944
Validation loss: 3.367192467106575

Epoch: 5| Step: 7
Training loss: 4.229752272979055
Validation loss: 3.3684867501396076

Epoch: 5| Step: 8
Training loss: 3.7139396008421586
Validation loss: 3.3662448931572664

Epoch: 5| Step: 9
Training loss: 3.1765332522267795
Validation loss: 3.364226016192873

Epoch: 5| Step: 10
Training loss: 2.3760253299172134
Validation loss: 3.363052877021397

Epoch: 98| Step: 0
Training loss: 3.176321436511423
Validation loss: 3.3617794939355234

Epoch: 5| Step: 1
Training loss: 4.063903800801989
Validation loss: 3.360332517199234

Epoch: 5| Step: 2
Training loss: 3.690990024897331
Validation loss: 3.363426875069971

Epoch: 5| Step: 3
Training loss: 3.7792398453384446
Validation loss: 3.358944902791934

Epoch: 5| Step: 4
Training loss: 3.9510017090612455
Validation loss: 3.359948968372834

Epoch: 5| Step: 5
Training loss: 2.67890015537729
Validation loss: 3.3600976646017324

Epoch: 5| Step: 6
Training loss: 3.8005110045721513
Validation loss: 3.360009815535733

Epoch: 5| Step: 7
Training loss: 4.010559211608692
Validation loss: 3.359724925828565

Epoch: 5| Step: 8
Training loss: 3.498166012505668
Validation loss: 3.3616214171467678

Epoch: 5| Step: 9
Training loss: 3.2477006848167487
Validation loss: 3.359942118152993

Epoch: 5| Step: 10
Training loss: 3.2269443535394045
Validation loss: 3.3607902138633747

Epoch: 99| Step: 0
Training loss: 3.248585026167733
Validation loss: 3.359235620528609

Epoch: 5| Step: 1
Training loss: 3.791019398423547
Validation loss: 3.359525064682861

Epoch: 5| Step: 2
Training loss: 3.684353795528464
Validation loss: 3.358775268043444

Epoch: 5| Step: 3
Training loss: 4.06905177062319
Validation loss: 3.3601331003757346

Epoch: 5| Step: 4
Training loss: 3.727784538231329
Validation loss: 3.3589992518146268

Epoch: 5| Step: 5
Training loss: 3.333040860378571
Validation loss: 3.3582882855064122

Epoch: 5| Step: 6
Training loss: 3.8005621945963624
Validation loss: 3.3624283159248822

Epoch: 5| Step: 7
Training loss: 3.1362252613245922
Validation loss: 3.360586438548175

Epoch: 5| Step: 8
Training loss: 3.1624610144583207
Validation loss: 3.36660511915378

Epoch: 5| Step: 9
Training loss: 3.323365726242932
Validation loss: 3.362913922896603

Epoch: 5| Step: 10
Training loss: 4.050837517313525
Validation loss: 3.363528307043057

Epoch: 100| Step: 0
Training loss: 3.212644693997549
Validation loss: 3.3612843907282484

Epoch: 5| Step: 1
Training loss: 3.904286371687348
Validation loss: 3.3563566452672453

Epoch: 5| Step: 2
Training loss: 3.827907135661157
Validation loss: 3.355718553400792

Epoch: 5| Step: 3
Training loss: 3.202977619036973
Validation loss: 3.356278212615808

Epoch: 5| Step: 4
Training loss: 3.602887950288827
Validation loss: 3.3551985194816822

Epoch: 5| Step: 5
Training loss: 3.3723317654487794
Validation loss: 3.3538322845100597

Epoch: 5| Step: 6
Training loss: 4.113846003786614
Validation loss: 3.3530818739372217

Epoch: 5| Step: 7
Training loss: 3.3332328463348824
Validation loss: 3.3519528057947285

Epoch: 5| Step: 8
Training loss: 3.7611617233449657
Validation loss: 3.3538610041016725

Epoch: 5| Step: 9
Training loss: 3.4883515114879398
Validation loss: 3.3532766573950212

Epoch: 5| Step: 10
Training loss: 3.449006537435944
Validation loss: 3.352409743143782

Epoch: 101| Step: 0
Training loss: 3.7418742835224332
Validation loss: 3.3537945355915406

Epoch: 5| Step: 1
Training loss: 3.4532940162963652
Validation loss: 3.3537542392376034

Epoch: 5| Step: 2
Training loss: 3.6177843561302736
Validation loss: 3.3527276716544634

Epoch: 5| Step: 3
Training loss: 3.435105894585936
Validation loss: 3.354439462095515

Epoch: 5| Step: 4
Training loss: 3.7994842982459063
Validation loss: 3.353972177453334

Epoch: 5| Step: 5
Training loss: 3.049994490571596
Validation loss: 3.3514374044321924

Epoch: 5| Step: 6
Training loss: 3.5564324089158523
Validation loss: 3.3530245144392903

Epoch: 5| Step: 7
Training loss: 3.736320212436081
Validation loss: 3.354285310239105

Epoch: 5| Step: 8
Training loss: 3.4225282089152036
Validation loss: 3.353694565865988

Epoch: 5| Step: 9
Training loss: 3.746263804469165
Validation loss: 3.353253974066834

Epoch: 5| Step: 10
Training loss: 3.757664160070771
Validation loss: 3.3515578952440905

Epoch: 102| Step: 0
Training loss: 3.2332404906586474
Validation loss: 3.3528663582522835

Epoch: 5| Step: 1
Training loss: 2.9981863579625525
Validation loss: 3.353622742222607

Epoch: 5| Step: 2
Training loss: 3.621659416780151
Validation loss: 3.3535368831364782

Epoch: 5| Step: 3
Training loss: 4.19857689498659
Validation loss: 3.3556245832612754

Epoch: 5| Step: 4
Training loss: 4.105993932348823
Validation loss: 3.358364920066965

Epoch: 5| Step: 5
Training loss: 3.1927394813565653
Validation loss: 3.353030422309529

Epoch: 5| Step: 6
Training loss: 3.5314726632734614
Validation loss: 3.3506513235154163

Epoch: 5| Step: 7
Training loss: 3.286492655353705
Validation loss: 3.3485117019465287

Epoch: 5| Step: 8
Training loss: 3.5982242761234575
Validation loss: 3.350352870176156

Epoch: 5| Step: 9
Training loss: 3.9834576915870543
Validation loss: 3.355453605588551

Epoch: 5| Step: 10
Training loss: 3.4002480079853155
Validation loss: 3.350582653551698

Epoch: 103| Step: 0
Training loss: 2.9940858401706767
Validation loss: 3.3495398723818277

Epoch: 5| Step: 1
Training loss: 4.3818240759603775
Validation loss: 3.350360799016449

Epoch: 5| Step: 2
Training loss: 3.4412854245957507
Validation loss: 3.348162778740438

Epoch: 5| Step: 3
Training loss: 2.945796532155998
Validation loss: 3.350011681181406

Epoch: 5| Step: 4
Training loss: 2.6555493496601086
Validation loss: 3.3458360082738525

Epoch: 5| Step: 5
Training loss: 3.8751565224814426
Validation loss: 3.348488461130272

Epoch: 5| Step: 6
Training loss: 3.493112872449565
Validation loss: 3.3480054419291685

Epoch: 5| Step: 7
Training loss: 3.8373998274760326
Validation loss: 3.348801910697819

Epoch: 5| Step: 8
Training loss: 4.070745463416951
Validation loss: 3.348422703660452

Epoch: 5| Step: 9
Training loss: 3.8549297230372
Validation loss: 3.352413093361945

Epoch: 5| Step: 10
Training loss: 3.399607770398478
Validation loss: 3.3505388769585855

Epoch: 104| Step: 0
Training loss: 3.511904498355046
Validation loss: 3.3497773754167977

Epoch: 5| Step: 1
Training loss: 3.511992752536951
Validation loss: 3.3498475083068966

Epoch: 5| Step: 2
Training loss: 3.4563816645620324
Validation loss: 3.3474925007575647

Epoch: 5| Step: 3
Training loss: 3.275187095364714
Validation loss: 3.345753704693677

Epoch: 5| Step: 4
Training loss: 3.5346115451382225
Validation loss: 3.3442267498854554

Epoch: 5| Step: 5
Training loss: 3.7168698727149168
Validation loss: 3.3445306763078384

Epoch: 5| Step: 6
Training loss: 3.9626530951639336
Validation loss: 3.344309589313272

Epoch: 5| Step: 7
Training loss: 3.9306218456583806
Validation loss: 3.342644597016818

Epoch: 5| Step: 8
Training loss: 2.8258901797079403
Validation loss: 3.3449571125215507

Epoch: 5| Step: 9
Training loss: 3.9631625515070623
Validation loss: 3.341622523086632

Epoch: 5| Step: 10
Training loss: 3.466192316345006
Validation loss: 3.3411165328105352

Epoch: 105| Step: 0
Training loss: 3.4204498528321894
Validation loss: 3.342836982373971

Epoch: 5| Step: 1
Training loss: 3.6793281395897344
Validation loss: 3.3431825076706225

Epoch: 5| Step: 2
Training loss: 4.173672292510929
Validation loss: 3.3404995815332224

Epoch: 5| Step: 3
Training loss: 3.2471105495627253
Validation loss: 3.3434825211761408

Epoch: 5| Step: 4
Training loss: 3.02161188725766
Validation loss: 3.342316682278962

Epoch: 5| Step: 5
Training loss: 4.1408398842383916
Validation loss: 3.3447242293571646

Epoch: 5| Step: 6
Training loss: 2.7718660442633385
Validation loss: 3.3439598811157447

Epoch: 5| Step: 7
Training loss: 4.3279002437694345
Validation loss: 3.349858268417426

Epoch: 5| Step: 8
Training loss: 3.341648760689749
Validation loss: 3.3428597501919657

Epoch: 5| Step: 9
Training loss: 3.371429532722909
Validation loss: 3.342298252150138

Epoch: 5| Step: 10
Training loss: 3.4894108667978125
Validation loss: 3.3428975320958596

Epoch: 106| Step: 0
Training loss: 2.6546583006781446
Validation loss: 3.3433666130211193

Epoch: 5| Step: 1
Training loss: 3.762277215083924
Validation loss: 3.3437413455213627

Epoch: 5| Step: 2
Training loss: 3.769676213614793
Validation loss: 3.3446166500831405

Epoch: 5| Step: 3
Training loss: 3.6578872796863373
Validation loss: 3.3398235998557495

Epoch: 5| Step: 4
Training loss: 3.6895049512059397
Validation loss: 3.342545662095118

Epoch: 5| Step: 5
Training loss: 3.268459276505567
Validation loss: 3.338730523938681

Epoch: 5| Step: 6
Training loss: 3.533770176735791
Validation loss: 3.337590093480884

Epoch: 5| Step: 7
Training loss: 3.873526262171892
Validation loss: 3.3383941369508836

Epoch: 5| Step: 8
Training loss: 3.9735251707664876
Validation loss: 3.338426971781863

Epoch: 5| Step: 9
Training loss: 3.8957370739364796
Validation loss: 3.339054561959133

Epoch: 5| Step: 10
Training loss: 2.925117692454352
Validation loss: 3.339382010901052

Epoch: 107| Step: 0
Training loss: 3.3351275065924377
Validation loss: 3.3382315583882547

Epoch: 5| Step: 1
Training loss: 3.040647431748577
Validation loss: 3.338333494796562

Epoch: 5| Step: 2
Training loss: 3.4042676004102024
Validation loss: 3.3355889845934126

Epoch: 5| Step: 3
Training loss: 3.1229622872964664
Validation loss: 3.336780315307394

Epoch: 5| Step: 4
Training loss: 4.327174774413476
Validation loss: 3.3357818860015787

Epoch: 5| Step: 5
Training loss: 4.262093783624447
Validation loss: 3.3378184313309407

Epoch: 5| Step: 6
Training loss: 3.349898202972126
Validation loss: 3.3342295339178474

Epoch: 5| Step: 7
Training loss: 3.7641059059056805
Validation loss: 3.3368379870757163

Epoch: 5| Step: 8
Training loss: 3.876836526111891
Validation loss: 3.3359386942360536

Epoch: 5| Step: 9
Training loss: 2.7600347194699277
Validation loss: 3.33375303077084

Epoch: 5| Step: 10
Training loss: 3.695346953088266
Validation loss: 3.336366785715355

Epoch: 108| Step: 0
Training loss: 3.9724077805317397
Validation loss: 3.3375320806033404

Epoch: 5| Step: 1
Training loss: 3.2706565242205223
Validation loss: 3.3385339334697286

Epoch: 5| Step: 2
Training loss: 4.275484309731901
Validation loss: 3.335740140855125

Epoch: 5| Step: 3
Training loss: 3.7424086981207076
Validation loss: 3.3362030110378766

Epoch: 5| Step: 4
Training loss: 4.2090711544853345
Validation loss: 3.3378665621532373

Epoch: 5| Step: 5
Training loss: 2.647460577277733
Validation loss: 3.337393466560691

Epoch: 5| Step: 6
Training loss: 2.4314823696619827
Validation loss: 3.336572582655907

Epoch: 5| Step: 7
Training loss: 3.7303572872745923
Validation loss: 3.336268738874162

Epoch: 5| Step: 8
Training loss: 3.597474929266251
Validation loss: 3.3366516997939932

Epoch: 5| Step: 9
Training loss: 3.12813700579341
Validation loss: 3.3354684364924285

Epoch: 5| Step: 10
Training loss: 3.7368726478131578
Validation loss: 3.338061986162042

Epoch: 109| Step: 0
Training loss: 2.975816528079153
Validation loss: 3.3352990942684015

Epoch: 5| Step: 1
Training loss: 3.297266787711929
Validation loss: 3.3369248289750226

Epoch: 5| Step: 2
Training loss: 4.124062402691544
Validation loss: 3.3375741612784595

Epoch: 5| Step: 3
Training loss: 3.516067002379529
Validation loss: 3.3365348950947245

Epoch: 5| Step: 4
Training loss: 3.577819411375801
Validation loss: 3.337051730016317

Epoch: 5| Step: 5
Training loss: 3.757282306915772
Validation loss: 3.342408033714559

Epoch: 5| Step: 6
Training loss: 4.050252440320512
Validation loss: 3.3408656161007544

Epoch: 5| Step: 7
Training loss: 3.2840305717615736
Validation loss: 3.3404535715164303

Epoch: 5| Step: 8
Training loss: 3.708299458095401
Validation loss: 3.337271234484674

Epoch: 5| Step: 9
Training loss: 3.2298648366608385
Validation loss: 3.334643453094782

Epoch: 5| Step: 10
Training loss: 3.48219867703478
Validation loss: 3.3340590522734623

Epoch: 110| Step: 0
Training loss: 3.3579257411686645
Validation loss: 3.3365654124476993

Epoch: 5| Step: 1
Training loss: 4.231231986927361
Validation loss: 3.3338673338206553

Epoch: 5| Step: 2
Training loss: 2.98697648828459
Validation loss: 3.3371283667443667

Epoch: 5| Step: 3
Training loss: 4.016584585994697
Validation loss: 3.332821261132883

Epoch: 5| Step: 4
Training loss: 3.2602175975798513
Validation loss: 3.330162735938508

Epoch: 5| Step: 5
Training loss: 3.7346684169018407
Validation loss: 3.3326922574439037

Epoch: 5| Step: 6
Training loss: 3.072150924879313
Validation loss: 3.333156187723801

Epoch: 5| Step: 7
Training loss: 3.4136374621452443
Validation loss: 3.3316050930429997

Epoch: 5| Step: 8
Training loss: 3.3967196628178544
Validation loss: 3.3296580700858

Epoch: 5| Step: 9
Training loss: 3.803113419852889
Validation loss: 3.3299468055020687

Epoch: 5| Step: 10
Training loss: 3.6744801471509736
Validation loss: 3.3295606218329636

Epoch: 111| Step: 0
Training loss: 2.9975871873763493
Validation loss: 3.3299971241094646

Epoch: 5| Step: 1
Training loss: 3.8805698849313277
Validation loss: 3.329754307484257

Epoch: 5| Step: 2
Training loss: 3.2606620493109824
Validation loss: 3.331260404736194

Epoch: 5| Step: 3
Training loss: 3.1404473553420384
Validation loss: 3.3337779353617725

Epoch: 5| Step: 4
Training loss: 3.4477555313182155
Validation loss: 3.3355007083080124

Epoch: 5| Step: 5
Training loss: 3.795133214730902
Validation loss: 3.3300472402555323

Epoch: 5| Step: 6
Training loss: 3.5422983092487486
Validation loss: 3.3305291183411185

Epoch: 5| Step: 7
Training loss: 3.0770884671143666
Validation loss: 3.3300781619525113

Epoch: 5| Step: 8
Training loss: 4.004818160254483
Validation loss: 3.3291712592495473

Epoch: 5| Step: 9
Training loss: 3.69048563462322
Validation loss: 3.327062443836455

Epoch: 5| Step: 10
Training loss: 4.142908697324288
Validation loss: 3.3252758675608938

Epoch: 112| Step: 0
Training loss: 3.3612733666915404
Validation loss: 3.3277828925213835

Epoch: 5| Step: 1
Training loss: 3.8003573048907424
Validation loss: 3.3274256473922144

Epoch: 5| Step: 2
Training loss: 3.6305562549977277
Validation loss: 3.3261161648611655

Epoch: 5| Step: 3
Training loss: 2.9639670944343575
Validation loss: 3.3246824145701876

Epoch: 5| Step: 4
Training loss: 3.9544236534119688
Validation loss: 3.32772894580669

Epoch: 5| Step: 5
Training loss: 3.5161710187962774
Validation loss: 3.3253183947514446

Epoch: 5| Step: 6
Training loss: 2.891669502220266
Validation loss: 3.323456645158161

Epoch: 5| Step: 7
Training loss: 3.6111889529193184
Validation loss: 3.3263598158424874

Epoch: 5| Step: 8
Training loss: 3.3814549354033354
Validation loss: 3.3250041577676095

Epoch: 5| Step: 9
Training loss: 3.984140187244446
Validation loss: 3.3320366342060073

Epoch: 5| Step: 10
Training loss: 3.8366237422774634
Validation loss: 3.328611369270696

Epoch: 113| Step: 0
Training loss: 3.04779367535544
Validation loss: 3.3246272254159748

Epoch: 5| Step: 1
Training loss: 3.2900870351670957
Validation loss: 3.3242444339769923

Epoch: 5| Step: 2
Training loss: 2.953480209705339
Validation loss: 3.323792126652667

Epoch: 5| Step: 3
Training loss: 4.238494558284282
Validation loss: 3.322778207771543

Epoch: 5| Step: 4
Training loss: 4.183278247323653
Validation loss: 3.324279890248522

Epoch: 5| Step: 5
Training loss: 3.010723657145781
Validation loss: 3.3250827267366643

Epoch: 5| Step: 6
Training loss: 3.9155500863010957
Validation loss: 3.3247213869439123

Epoch: 5| Step: 7
Training loss: 3.8255464549945395
Validation loss: 3.32262494955403

Epoch: 5| Step: 8
Training loss: 2.737815392846124
Validation loss: 3.3225547111718505

Epoch: 5| Step: 9
Training loss: 4.096701220704731
Validation loss: 3.3230522920931898

Epoch: 5| Step: 10
Training loss: 3.287080942576084
Validation loss: 3.3255808621815848

Epoch: 114| Step: 0
Training loss: 3.5280894761708743
Validation loss: 3.324006675314979

Epoch: 5| Step: 1
Training loss: 3.763648689804365
Validation loss: 3.3253709026922715

Epoch: 5| Step: 2
Training loss: 3.871256958632209
Validation loss: 3.3211578431889057

Epoch: 5| Step: 3
Training loss: 3.363315985275407
Validation loss: 3.3198389121677927

Epoch: 5| Step: 4
Training loss: 2.812507883696633
Validation loss: 3.3198792441167098

Epoch: 5| Step: 5
Training loss: 3.4397242892469095
Validation loss: 3.3184364897662726

Epoch: 5| Step: 6
Training loss: 3.2671832149847857
Validation loss: 3.319619963275259

Epoch: 5| Step: 7
Training loss: 3.771760998562003
Validation loss: 3.31768731955927

Epoch: 5| Step: 8
Training loss: 3.4465180448244834
Validation loss: 3.319159750762923

Epoch: 5| Step: 9
Training loss: 3.8140213229258957
Validation loss: 3.317911704985801

Epoch: 5| Step: 10
Training loss: 3.89711713122781
Validation loss: 3.318769500096088

Epoch: 115| Step: 0
Training loss: 3.2814560598430482
Validation loss: 3.3183352524149794

Epoch: 5| Step: 1
Training loss: 3.5825257537192963
Validation loss: 3.317238450620399

Epoch: 5| Step: 2
Training loss: 3.8680485547084373
Validation loss: 3.316638912427583

Epoch: 5| Step: 3
Training loss: 3.4738299314150396
Validation loss: 3.316204789291757

Epoch: 5| Step: 4
Training loss: 3.8424294537116084
Validation loss: 3.3169659278634755

Epoch: 5| Step: 5
Training loss: 3.4818704267974057
Validation loss: 3.3159965191397864

Epoch: 5| Step: 6
Training loss: 3.218416215200442
Validation loss: 3.3155894036688442

Epoch: 5| Step: 7
Training loss: 3.2760833753751855
Validation loss: 3.3171633467588704

Epoch: 5| Step: 8
Training loss: 3.805053192047586
Validation loss: 3.317468581820198

Epoch: 5| Step: 9
Training loss: 2.879619039134669
Validation loss: 3.3151747603535435

Epoch: 5| Step: 10
Training loss: 4.227120015433431
Validation loss: 3.319129816408459

Epoch: 116| Step: 0
Training loss: 3.5353939081889547
Validation loss: 3.315277380955253

Epoch: 5| Step: 1
Training loss: 3.911129764550935
Validation loss: 3.3173107552217864

Epoch: 5| Step: 2
Training loss: 3.513106058310924
Validation loss: 3.3149214531343416

Epoch: 5| Step: 3
Training loss: 3.1698086025568264
Validation loss: 3.315984569880846

Epoch: 5| Step: 4
Training loss: 2.752553794397531
Validation loss: 3.3161972302571696

Epoch: 5| Step: 5
Training loss: 3.680068982348531
Validation loss: 3.3178296977408843

Epoch: 5| Step: 6
Training loss: 3.668828471447701
Validation loss: 3.3146519356803195

Epoch: 5| Step: 7
Training loss: 4.042245698855648
Validation loss: 3.3146790519129676

Epoch: 5| Step: 8
Training loss: 3.9796719188707184
Validation loss: 3.314678275398723

Epoch: 5| Step: 9
Training loss: 3.903233820892502
Validation loss: 3.315157170715347

Epoch: 5| Step: 10
Training loss: 2.2100258824830803
Validation loss: 3.3150088482916855

Epoch: 117| Step: 0
Training loss: 3.7724029196855615
Validation loss: 3.3146173091816777

Epoch: 5| Step: 1
Training loss: 2.83051464644812
Validation loss: 3.313826376105517

Epoch: 5| Step: 2
Training loss: 3.883840750968278
Validation loss: 3.312686811965696

Epoch: 5| Step: 3
Training loss: 3.0806620255433734
Validation loss: 3.3141987044331858

Epoch: 5| Step: 4
Training loss: 3.598123161841568
Validation loss: 3.3151406589820116

Epoch: 5| Step: 5
Training loss: 3.5458100858674118
Validation loss: 3.3129359937585128

Epoch: 5| Step: 6
Training loss: 3.8542396882159196
Validation loss: 3.3156178344093665

Epoch: 5| Step: 7
Training loss: 3.842333152588536
Validation loss: 3.314744025556566

Epoch: 5| Step: 8
Training loss: 3.728308182826083
Validation loss: 3.315158508539521

Epoch: 5| Step: 9
Training loss: 3.1492768865474643
Validation loss: 3.316480145027991

Epoch: 5| Step: 10
Training loss: 3.511006759415402
Validation loss: 3.3148074093828606

Epoch: 118| Step: 0
Training loss: 3.156655011771525
Validation loss: 3.3137388182433654

Epoch: 5| Step: 1
Training loss: 3.9583047698479428
Validation loss: 3.3142722479996616

Epoch: 5| Step: 2
Training loss: 3.416643716378395
Validation loss: 3.313225980622183

Epoch: 5| Step: 3
Training loss: 3.7448597328391537
Validation loss: 3.3136791499536624

Epoch: 5| Step: 4
Training loss: 3.4184550435311496
Validation loss: 3.3136566241715726

Epoch: 5| Step: 5
Training loss: 2.7402882315794024
Validation loss: 3.3133007381166575

Epoch: 5| Step: 6
Training loss: 3.882735130721244
Validation loss: 3.3111144031658695

Epoch: 5| Step: 7
Training loss: 3.5282259795720634
Validation loss: 3.3121534565997197

Epoch: 5| Step: 8
Training loss: 3.6042256139150024
Validation loss: 3.3130208985601532

Epoch: 5| Step: 9
Training loss: 3.8688949976851004
Validation loss: 3.314594610337144

Epoch: 5| Step: 10
Training loss: 3.4243279291946616
Validation loss: 3.3126154109625854

Epoch: 119| Step: 0
Training loss: 3.131717633260166
Validation loss: 3.3191241007666834

Epoch: 5| Step: 1
Training loss: 3.5284692398682997
Validation loss: 3.318178205649435

Epoch: 5| Step: 2
Training loss: 4.107296029782797
Validation loss: 3.3129682018458566

Epoch: 5| Step: 3
Training loss: 2.914508038944107
Validation loss: 3.309500601122569

Epoch: 5| Step: 4
Training loss: 3.8421406672083482
Validation loss: 3.31040200127517

Epoch: 5| Step: 5
Training loss: 4.034538406384042
Validation loss: 3.3083621413272097

Epoch: 5| Step: 6
Training loss: 3.246303216485524
Validation loss: 3.3078386583875523

Epoch: 5| Step: 7
Training loss: 4.19364864948905
Validation loss: 3.309153656074818

Epoch: 5| Step: 8
Training loss: 3.179299220716898
Validation loss: 3.309681018530426

Epoch: 5| Step: 9
Training loss: 2.925383394334017
Validation loss: 3.3068161918237755

Epoch: 5| Step: 10
Training loss: 3.500283638496566
Validation loss: 3.3110239846527305

Epoch: 120| Step: 0
Training loss: 3.878841710778225
Validation loss: 3.3109236542229588

Epoch: 5| Step: 1
Training loss: 2.8583920983445252
Validation loss: 3.3066555588074533

Epoch: 5| Step: 2
Training loss: 3.7369597998282273
Validation loss: 3.3075790149961364

Epoch: 5| Step: 3
Training loss: 3.2176127971093074
Validation loss: 3.304623040015439

Epoch: 5| Step: 4
Training loss: 3.6820993476655546
Validation loss: 3.3058778443066252

Epoch: 5| Step: 5
Training loss: 4.502132758075653
Validation loss: 3.30444168390255

Epoch: 5| Step: 6
Training loss: 3.679229643049804
Validation loss: 3.3032665053839474

Epoch: 5| Step: 7
Training loss: 3.389143096964432
Validation loss: 3.303245094472369

Epoch: 5| Step: 8
Training loss: 2.8356070838313463
Validation loss: 3.303699746179522

Epoch: 5| Step: 9
Training loss: 3.4464253468643116
Validation loss: 3.305101209581412

Epoch: 5| Step: 10
Training loss: 3.3510242376723096
Validation loss: 3.303833325640649

Epoch: 121| Step: 0
Training loss: 3.764150750379431
Validation loss: 3.3035153795869805

Epoch: 5| Step: 1
Training loss: 3.986319632102969
Validation loss: 3.303963432852753

Epoch: 5| Step: 2
Training loss: 3.827322365832854
Validation loss: 3.3039481260683434

Epoch: 5| Step: 3
Training loss: 3.8237266964309864
Validation loss: 3.301803325192318

Epoch: 5| Step: 4
Training loss: 3.5907482049718813
Validation loss: 3.3020028788726576

Epoch: 5| Step: 5
Training loss: 2.9302284656804467
Validation loss: 3.301800810313519

Epoch: 5| Step: 6
Training loss: 2.857204092595698
Validation loss: 3.3024175993673195

Epoch: 5| Step: 7
Training loss: 2.8316549116866967
Validation loss: 3.3017705291278863

Epoch: 5| Step: 8
Training loss: 3.230016010114833
Validation loss: 3.3036134021059693

Epoch: 5| Step: 9
Training loss: 3.9810559379674113
Validation loss: 3.3031441831670554

Epoch: 5| Step: 10
Training loss: 3.7909710983184945
Validation loss: 3.3036826859775585

Epoch: 122| Step: 0
Training loss: 3.669151692275774
Validation loss: 3.302845099035888

Epoch: 5| Step: 1
Training loss: 3.5215759096187367
Validation loss: 3.302701097606514

Epoch: 5| Step: 2
Training loss: 3.537161411216489
Validation loss: 3.298982654250318

Epoch: 5| Step: 3
Training loss: 3.4658974955744295
Validation loss: 3.3017305156091132

Epoch: 5| Step: 4
Training loss: 3.682015559282224
Validation loss: 3.3004096171302

Epoch: 5| Step: 5
Training loss: 2.865063121959106
Validation loss: 3.2998413231127626

Epoch: 5| Step: 6
Training loss: 2.8376941967356193
Validation loss: 3.3007844203936902

Epoch: 5| Step: 7
Training loss: 3.695453665297185
Validation loss: 3.301360621886619

Epoch: 5| Step: 8
Training loss: 2.996894818857988
Validation loss: 3.299656964692037

Epoch: 5| Step: 9
Training loss: 4.527915201006406
Validation loss: 3.2989523596304635

Epoch: 5| Step: 10
Training loss: 3.761263525682739
Validation loss: 3.2985500677332933

Epoch: 123| Step: 0
Training loss: 3.2581327358719667
Validation loss: 3.298854547544379

Epoch: 5| Step: 1
Training loss: 3.695251851461215
Validation loss: 3.2973216759813946

Epoch: 5| Step: 2
Training loss: 3.1996788280960806
Validation loss: 3.2969459440911435

Epoch: 5| Step: 3
Training loss: 3.9791379731160665
Validation loss: 3.299978776840522

Epoch: 5| Step: 4
Training loss: 3.216455623311691
Validation loss: 3.299473624698211

Epoch: 5| Step: 5
Training loss: 3.8874540467321412
Validation loss: 3.300450406329357

Epoch: 5| Step: 6
Training loss: 3.133425987848713
Validation loss: 3.299939617910928

Epoch: 5| Step: 7
Training loss: 3.7888326988143053
Validation loss: 3.2999520323502933

Epoch: 5| Step: 8
Training loss: 3.836253974740961
Validation loss: 3.304466117379488

Epoch: 5| Step: 9
Training loss: 2.8100526121922655
Validation loss: 3.300847344544689

Epoch: 5| Step: 10
Training loss: 3.856930472062052
Validation loss: 3.3096025239061144

Epoch: 124| Step: 0
Training loss: 3.9846208085175303
Validation loss: 3.300549116404435

Epoch: 5| Step: 1
Training loss: 3.405131024992031
Validation loss: 3.3043527322315147

Epoch: 5| Step: 2
Training loss: 4.4143303983969
Validation loss: 3.3087788021231606

Epoch: 5| Step: 3
Training loss: 3.6341506954391205
Validation loss: 3.3111201667010293

Epoch: 5| Step: 4
Training loss: 2.9708036045835873
Validation loss: 3.296808695178655

Epoch: 5| Step: 5
Training loss: 3.2928307482852848
Validation loss: 3.3005931241672837

Epoch: 5| Step: 6
Training loss: 3.5107755996323835
Validation loss: 3.298517264970731

Epoch: 5| Step: 7
Training loss: 3.063332736403027
Validation loss: 3.2975955003410475

Epoch: 5| Step: 8
Training loss: 2.8028287120719826
Validation loss: 3.3004581148348104

Epoch: 5| Step: 9
Training loss: 3.9824328906480804
Validation loss: 3.303348538903575

Epoch: 5| Step: 10
Training loss: 3.3845428904192367
Validation loss: 3.2960199412589795

Epoch: 125| Step: 0
Training loss: 3.1313514251424572
Validation loss: 3.2944551580319743

Epoch: 5| Step: 1
Training loss: 3.4510558129890097
Validation loss: 3.2961092966948753

Epoch: 5| Step: 2
Training loss: 3.2575788894433955
Validation loss: 3.2954199633714354

Epoch: 5| Step: 3
Training loss: 3.4432771167677525
Validation loss: 3.295309620778199

Epoch: 5| Step: 4
Training loss: 3.6772201267693743
Validation loss: 3.29667907390833

Epoch: 5| Step: 5
Training loss: 3.6131760700485365
Validation loss: 3.2954083759273995

Epoch: 5| Step: 6
Training loss: 3.4171359197406725
Validation loss: 3.2949929560646822

Epoch: 5| Step: 7
Training loss: 3.8789990616649996
Validation loss: 3.294579066556058

Epoch: 5| Step: 8
Training loss: 3.4217306306945323
Validation loss: 3.2934855763742448

Epoch: 5| Step: 9
Training loss: 3.4688317916437317
Validation loss: 3.2934616125444642

Epoch: 5| Step: 10
Training loss: 4.023075539316152
Validation loss: 3.293364555148948

Epoch: 126| Step: 0
Training loss: 4.4879440300455276
Validation loss: 3.2928750351510225

Epoch: 5| Step: 1
Training loss: 3.200888248188708
Validation loss: 3.292826556557552

Epoch: 5| Step: 2
Training loss: 2.5502717004276616
Validation loss: 3.2921673658840724

Epoch: 5| Step: 3
Training loss: 2.955649613753671
Validation loss: 3.291869310834343

Epoch: 5| Step: 4
Training loss: 3.370804191875194
Validation loss: 3.2905025235673864

Epoch: 5| Step: 5
Training loss: 4.193788276418097
Validation loss: 3.291260628185654

Epoch: 5| Step: 6
Training loss: 3.7723058421311957
Validation loss: 3.290677691661253

Epoch: 5| Step: 7
Training loss: 4.032844169105119
Validation loss: 3.290841232883338

Epoch: 5| Step: 8
Training loss: 3.1743739013910317
Validation loss: 3.2905387555564283

Epoch: 5| Step: 9
Training loss: 2.6150809393294856
Validation loss: 3.2905538387913142

Epoch: 5| Step: 10
Training loss: 3.862652086146362
Validation loss: 3.2898345205671142

Epoch: 127| Step: 0
Training loss: 3.593113054967969
Validation loss: 3.291776672140931

Epoch: 5| Step: 1
Training loss: 3.792996533151657
Validation loss: 3.2912670005536024

Epoch: 5| Step: 2
Training loss: 4.022953693226741
Validation loss: 3.2905412595651877

Epoch: 5| Step: 3
Training loss: 2.9657767414790097
Validation loss: 3.2887318493926108

Epoch: 5| Step: 4
Training loss: 3.4553864267656618
Validation loss: 3.2907717807020975

Epoch: 5| Step: 5
Training loss: 3.540364074519931
Validation loss: 3.2883942816546208

Epoch: 5| Step: 6
Training loss: 3.231989916379703
Validation loss: 3.289440687958574

Epoch: 5| Step: 7
Training loss: 2.9004922251775525
Validation loss: 3.2907239504559387

Epoch: 5| Step: 8
Training loss: 2.7730212261874647
Validation loss: 3.2904699514439035

Epoch: 5| Step: 9
Training loss: 3.7225960469456463
Validation loss: 3.2878171177274216

Epoch: 5| Step: 10
Training loss: 4.51307220635191
Validation loss: 3.290153908673941

Epoch: 128| Step: 0
Training loss: 3.831462541817496
Validation loss: 3.2893373143027085

Epoch: 5| Step: 1
Training loss: 2.543579215800204
Validation loss: 3.288458913190995

Epoch: 5| Step: 2
Training loss: 3.394385858194245
Validation loss: 3.28992633184915

Epoch: 5| Step: 3
Training loss: 3.51807775766949
Validation loss: 3.2884770089204154

Epoch: 5| Step: 4
Training loss: 3.2589759121496558
Validation loss: 3.2864732772034695

Epoch: 5| Step: 5
Training loss: 3.2452601568622774
Validation loss: 3.287688994686275

Epoch: 5| Step: 6
Training loss: 3.6340986046689805
Validation loss: 3.2860685822415268

Epoch: 5| Step: 7
Training loss: 3.87558545027683
Validation loss: 3.2857102261151767

Epoch: 5| Step: 8
Training loss: 3.5733398691041685
Validation loss: 3.285597309486796

Epoch: 5| Step: 9
Training loss: 2.906826495346403
Validation loss: 3.285898250632747

Epoch: 5| Step: 10
Training loss: 4.684078544616197
Validation loss: 3.2851042082072013

Epoch: 129| Step: 0
Training loss: 3.002292551819597
Validation loss: 3.2853398045167124

Epoch: 5| Step: 1
Training loss: 4.03009466131082
Validation loss: 3.2843726656353325

Epoch: 5| Step: 2
Training loss: 3.3366272546026514
Validation loss: 3.2874519782269145

Epoch: 5| Step: 3
Training loss: 2.962362384416607
Validation loss: 3.2850977388228384

Epoch: 5| Step: 4
Training loss: 3.1976960113312507
Validation loss: 3.2837296639960885

Epoch: 5| Step: 5
Training loss: 3.3162311197685965
Validation loss: 3.2850475932482763

Epoch: 5| Step: 6
Training loss: 3.7816033316484385
Validation loss: 3.2875623326759658

Epoch: 5| Step: 7
Training loss: 4.134771160541878
Validation loss: 3.28776272421453

Epoch: 5| Step: 8
Training loss: 4.034512641148484
Validation loss: 3.2876414455387173

Epoch: 5| Step: 9
Training loss: 3.1836888585774177
Validation loss: 3.285069154760753

Epoch: 5| Step: 10
Training loss: 3.4447962229217644
Validation loss: 3.2825496031682118

Epoch: 130| Step: 0
Training loss: 3.3244836793574373
Validation loss: 3.2813335355329993

Epoch: 5| Step: 1
Training loss: 3.213900570274437
Validation loss: 3.280247535844236

Epoch: 5| Step: 2
Training loss: 3.824150544630858
Validation loss: 3.2789259454561854

Epoch: 5| Step: 3
Training loss: 3.557494813509154
Validation loss: 3.283242314104988

Epoch: 5| Step: 4
Training loss: 3.1437708343968236
Validation loss: 3.279587037821521

Epoch: 5| Step: 5
Training loss: 3.5485497104602355
Validation loss: 3.281453475463917

Epoch: 5| Step: 6
Training loss: 3.875396092998045
Validation loss: 3.2785965980314398

Epoch: 5| Step: 7
Training loss: 4.142527477884642
Validation loss: 3.2771632608181736

Epoch: 5| Step: 8
Training loss: 3.3795024367909368
Validation loss: 3.27788740489452

Epoch: 5| Step: 9
Training loss: 2.8679233199314007
Validation loss: 3.2766787593928317

Epoch: 5| Step: 10
Training loss: 3.649568892847167
Validation loss: 3.279479967148945

Epoch: 131| Step: 0
Training loss: 3.015799878045449
Validation loss: 3.277299511396397

Epoch: 5| Step: 1
Training loss: 3.737668297081916
Validation loss: 3.2797553029864734

Epoch: 5| Step: 2
Training loss: 3.4914065176860634
Validation loss: 3.2803422350935203

Epoch: 5| Step: 3
Training loss: 3.177390128576408
Validation loss: 3.2820491475855804

Epoch: 5| Step: 4
Training loss: 3.0310896998227523
Validation loss: 3.282195792981

Epoch: 5| Step: 5
Training loss: 3.2208112024202444
Validation loss: 3.2795838109781323

Epoch: 5| Step: 6
Training loss: 4.046849784625232
Validation loss: 3.278102648582685

Epoch: 5| Step: 7
Training loss: 3.6223268847436345
Validation loss: 3.2765086962579004

Epoch: 5| Step: 8
Training loss: 3.713236078829896
Validation loss: 3.276622531671954

Epoch: 5| Step: 9
Training loss: 4.25761718302015
Validation loss: 3.275454702266692

Epoch: 5| Step: 10
Training loss: 3.003313142438359
Validation loss: 3.273264144257038

Epoch: 132| Step: 0
Training loss: 4.044139040314091
Validation loss: 3.274473610132881

Epoch: 5| Step: 1
Training loss: 3.9011946046777637
Validation loss: 3.273433040657269

Epoch: 5| Step: 2
Training loss: 3.300106543930657
Validation loss: 3.2731204486186893

Epoch: 5| Step: 3
Training loss: 2.9474770765246308
Validation loss: 3.272177121890374

Epoch: 5| Step: 4
Training loss: 3.6511693361664705
Validation loss: 3.273368092077469

Epoch: 5| Step: 5
Training loss: 4.105373276200165
Validation loss: 3.2726190469778644

Epoch: 5| Step: 6
Training loss: 3.5642199463541484
Validation loss: 3.27282949472157

Epoch: 5| Step: 7
Training loss: 3.40866297376813
Validation loss: 3.2716265463084473

Epoch: 5| Step: 8
Training loss: 3.2847698406256396
Validation loss: 3.2723447355202375

Epoch: 5| Step: 9
Training loss: 2.6068156591341065
Validation loss: 3.2717729755922575

Epoch: 5| Step: 10
Training loss: 3.5375113551089012
Validation loss: 3.2732151253661663

Epoch: 133| Step: 0
Training loss: 3.2049367851414683
Validation loss: 3.2715321511416744

Epoch: 5| Step: 1
Training loss: 3.7214548227709017
Validation loss: 3.2718291095725136

Epoch: 5| Step: 2
Training loss: 3.464750303709233
Validation loss: 3.2695541138945514

Epoch: 5| Step: 3
Training loss: 3.394893087015499
Validation loss: 3.2706005864558954

Epoch: 5| Step: 4
Training loss: 3.6455966255003274
Validation loss: 3.2699466086241666

Epoch: 5| Step: 5
Training loss: 3.665798662499671
Validation loss: 3.269928488748332

Epoch: 5| Step: 6
Training loss: 3.5710782287968046
Validation loss: 3.2705010508628933

Epoch: 5| Step: 7
Training loss: 3.254491343564225
Validation loss: 3.2690721364126802

Epoch: 5| Step: 8
Training loss: 3.7508577001718524
Validation loss: 3.270219876351638

Epoch: 5| Step: 9
Training loss: 3.386019624665605
Validation loss: 3.269136287337507

Epoch: 5| Step: 10
Training loss: 3.4953688909000262
Validation loss: 3.269090584128006

Epoch: 134| Step: 0
Training loss: 3.0764245307949225
Validation loss: 3.2689455325893606

Epoch: 5| Step: 1
Training loss: 4.148376349449254
Validation loss: 3.268438225850466

Epoch: 5| Step: 2
Training loss: 3.737596726202511
Validation loss: 3.2697316489335164

Epoch: 5| Step: 3
Training loss: 3.818161060227284
Validation loss: 3.267594487930946

Epoch: 5| Step: 4
Training loss: 4.003520131915821
Validation loss: 3.268557751109634

Epoch: 5| Step: 5
Training loss: 3.0747476241588525
Validation loss: 3.267754456841557

Epoch: 5| Step: 6
Training loss: 2.740705040488217
Validation loss: 3.266892297317815

Epoch: 5| Step: 7
Training loss: 3.977488351897154
Validation loss: 3.268879688632634

Epoch: 5| Step: 8
Training loss: 3.196299952958456
Validation loss: 3.268622282328247

Epoch: 5| Step: 9
Training loss: 3.298484951529091
Validation loss: 3.2679533691025466

Epoch: 5| Step: 10
Training loss: 3.124947814505674
Validation loss: 3.2668689325716618

Epoch: 135| Step: 0
Training loss: 3.13905576151708
Validation loss: 3.268435141735351

Epoch: 5| Step: 1
Training loss: 3.305219602921288
Validation loss: 3.267344588110296

Epoch: 5| Step: 2
Training loss: 3.850566619197673
Validation loss: 3.2659226494000935

Epoch: 5| Step: 3
Training loss: 3.7022437483609627
Validation loss: 3.2665516313443472

Epoch: 5| Step: 4
Training loss: 2.844890659155256
Validation loss: 3.2667436480999785

Epoch: 5| Step: 5
Training loss: 3.0108579600369025
Validation loss: 3.264749698467809

Epoch: 5| Step: 6
Training loss: 3.8919589655125346
Validation loss: 3.2671854748159586

Epoch: 5| Step: 7
Training loss: 3.620707766013114
Validation loss: 3.2731174072942504

Epoch: 5| Step: 8
Training loss: 3.6974928635430993
Validation loss: 3.2690217348164694

Epoch: 5| Step: 9
Training loss: 4.272236936092186
Validation loss: 3.2784569669680477

Epoch: 5| Step: 10
Training loss: 2.809030724329923
Validation loss: 3.2650500250274295

Epoch: 136| Step: 0
Training loss: 3.5413086354914958
Validation loss: 3.2646582266999276

Epoch: 5| Step: 1
Training loss: 3.156122186169021
Validation loss: 3.2643718133269504

Epoch: 5| Step: 2
Training loss: 2.3192121677501882
Validation loss: 3.266778717689185

Epoch: 5| Step: 3
Training loss: 3.7999525117416533
Validation loss: 3.268711017340193

Epoch: 5| Step: 4
Training loss: 3.811526064684913
Validation loss: 3.266109640392292

Epoch: 5| Step: 5
Training loss: 3.7987669952102783
Validation loss: 3.266754007040373

Epoch: 5| Step: 6
Training loss: 4.130522066237251
Validation loss: 3.263677785157459

Epoch: 5| Step: 7
Training loss: 4.106634234098043
Validation loss: 3.2640771625797202

Epoch: 5| Step: 8
Training loss: 2.674413267300008
Validation loss: 3.262407157531497

Epoch: 5| Step: 9
Training loss: 3.7196082399056523
Validation loss: 3.2612212851690847

Epoch: 5| Step: 10
Training loss: 2.8998730335723053
Validation loss: 3.2611226912250464

Epoch: 137| Step: 0
Training loss: 3.6236826377415867
Validation loss: 3.262333319387011

Epoch: 5| Step: 1
Training loss: 2.547790175693028
Validation loss: 3.261703594728389

Epoch: 5| Step: 2
Training loss: 3.0734173555397595
Validation loss: 3.2604697986278293

Epoch: 5| Step: 3
Training loss: 3.3780581429753065
Validation loss: 3.2603243179449857

Epoch: 5| Step: 4
Training loss: 3.536873315088464
Validation loss: 3.259604082722933

Epoch: 5| Step: 5
Training loss: 4.010758713176631
Validation loss: 3.2618045494226395

Epoch: 5| Step: 6
Training loss: 2.909902922593965
Validation loss: 3.259881984399732

Epoch: 5| Step: 7
Training loss: 3.0644243383666256
Validation loss: 3.260094906518678

Epoch: 5| Step: 8
Training loss: 4.3756386427005305
Validation loss: 3.260699127856116

Epoch: 5| Step: 9
Training loss: 3.9426533717461405
Validation loss: 3.2591165335924046

Epoch: 5| Step: 10
Training loss: 3.659062013345071
Validation loss: 3.2592635595240567

Epoch: 138| Step: 0
Training loss: 3.111487816150613
Validation loss: 3.2592228935744347

Epoch: 5| Step: 1
Training loss: 3.1044060190247396
Validation loss: 3.259957973831655

Epoch: 5| Step: 2
Training loss: 3.539915811432013
Validation loss: 3.2603031141163368

Epoch: 5| Step: 3
Training loss: 3.695308628846413
Validation loss: 3.2589767585741276

Epoch: 5| Step: 4
Training loss: 3.4878232853947178
Validation loss: 3.263091600014069

Epoch: 5| Step: 5
Training loss: 3.5564494367030153
Validation loss: 3.2604412990157097

Epoch: 5| Step: 6
Training loss: 3.2805980216290753
Validation loss: 3.2662036852278873

Epoch: 5| Step: 7
Training loss: 4.004209925602789
Validation loss: 3.2584423794918247

Epoch: 5| Step: 8
Training loss: 3.1678055839993684
Validation loss: 3.25989612107841

Epoch: 5| Step: 9
Training loss: 4.151474812435471
Validation loss: 3.262590731547772

Epoch: 5| Step: 10
Training loss: 3.153527927268367
Validation loss: 3.260279296404985

Epoch: 139| Step: 0
Training loss: 2.7627388069879513
Validation loss: 3.2587554087264876

Epoch: 5| Step: 1
Training loss: 3.685976651296284
Validation loss: 3.2570589250975073

Epoch: 5| Step: 2
Training loss: 3.7325202453840953
Validation loss: 3.259358204607496

Epoch: 5| Step: 3
Training loss: 3.511829141105928
Validation loss: 3.2558678898559528

Epoch: 5| Step: 4
Training loss: 3.8130696605899073
Validation loss: 3.25799922624886

Epoch: 5| Step: 5
Training loss: 3.609470118470689
Validation loss: 3.256308787864701

Epoch: 5| Step: 6
Training loss: 3.924616246992466
Validation loss: 3.2557773087255524

Epoch: 5| Step: 7
Training loss: 3.7515225180735996
Validation loss: 3.256998284548773

Epoch: 5| Step: 8
Training loss: 3.742436219552963
Validation loss: 3.2550500927600265

Epoch: 5| Step: 9
Training loss: 2.5725792626272956
Validation loss: 3.2549538149196415

Epoch: 5| Step: 10
Training loss: 2.9673098634837136
Validation loss: 3.2557974160360064

Epoch: 140| Step: 0
Training loss: 2.9109809679767493
Validation loss: 3.255274376115165

Epoch: 5| Step: 1
Training loss: 3.904433537620384
Validation loss: 3.253334007599329

Epoch: 5| Step: 2
Training loss: 3.979353788812712
Validation loss: 3.254186601454181

Epoch: 5| Step: 3
Training loss: 3.834604315207949
Validation loss: 3.253500214700924

Epoch: 5| Step: 4
Training loss: 3.2293046655188324
Validation loss: 3.2542667809380825

Epoch: 5| Step: 5
Training loss: 3.4225257010989147
Validation loss: 3.253029284739274

Epoch: 5| Step: 6
Training loss: 3.9246988654790296
Validation loss: 3.25270192433149

Epoch: 5| Step: 7
Training loss: 2.825355564798066
Validation loss: 3.2530421682120156

Epoch: 5| Step: 8
Training loss: 3.8043610043030895
Validation loss: 3.2518995837452396

Epoch: 5| Step: 9
Training loss: 3.241024682054282
Validation loss: 3.252852589712794

Epoch: 5| Step: 10
Training loss: 2.9952103208844965
Validation loss: 3.2531023734191815

Epoch: 141| Step: 0
Training loss: 3.386773237694253
Validation loss: 3.253468027005386

Epoch: 5| Step: 1
Training loss: 3.826414637047242
Validation loss: 3.252385216291753

Epoch: 5| Step: 2
Training loss: 2.9371659109176718
Validation loss: 3.251524226250633

Epoch: 5| Step: 3
Training loss: 4.229406841705585
Validation loss: 3.253424733977832

Epoch: 5| Step: 4
Training loss: 3.0777925418296133
Validation loss: 3.2515133394152005

Epoch: 5| Step: 5
Training loss: 3.555046314951837
Validation loss: 3.2514280584687945

Epoch: 5| Step: 6
Training loss: 3.629172456008959
Validation loss: 3.252362846133666

Epoch: 5| Step: 7
Training loss: 3.3868196993767508
Validation loss: 3.251853499530458

Epoch: 5| Step: 8
Training loss: 3.7829865810671572
Validation loss: 3.2499464754756557

Epoch: 5| Step: 9
Training loss: 2.939313774988045
Validation loss: 3.251191920081482

Epoch: 5| Step: 10
Training loss: 3.420189986947211
Validation loss: 3.2497912608872577

Epoch: 142| Step: 0
Training loss: 3.4740778241441927
Validation loss: 3.2499695043655508

Epoch: 5| Step: 1
Training loss: 3.579129540306747
Validation loss: 3.2502635173754113

Epoch: 5| Step: 2
Training loss: 3.7306644408342304
Validation loss: 3.249747331955876

Epoch: 5| Step: 3
Training loss: 2.6918068021625285
Validation loss: 3.249336757143857

Epoch: 5| Step: 4
Training loss: 3.459963280367186
Validation loss: 3.248360934412182

Epoch: 5| Step: 5
Training loss: 3.3778167555746306
Validation loss: 3.247745648654608

Epoch: 5| Step: 6
Training loss: 3.67495260921725
Validation loss: 3.2496183248572574

Epoch: 5| Step: 7
Training loss: 3.441908350502918
Validation loss: 3.2485957760341133

Epoch: 5| Step: 8
Training loss: 2.811778844989827
Validation loss: 3.2490559935232817

Epoch: 5| Step: 9
Training loss: 3.4113046082472644
Validation loss: 3.2485745856159736

Epoch: 5| Step: 10
Training loss: 4.584914449145311
Validation loss: 3.2478758857137637

Epoch: 143| Step: 0
Training loss: 3.718737690368282
Validation loss: 3.246885309073998

Epoch: 5| Step: 1
Training loss: 3.5505689299402885
Validation loss: 3.246082253418049

Epoch: 5| Step: 2
Training loss: 3.2299311235483352
Validation loss: 3.2473425685112365

Epoch: 5| Step: 3
Training loss: 3.2680389389463715
Validation loss: 3.2478959614299243

Epoch: 5| Step: 4
Training loss: 3.4403720301902996
Validation loss: 3.246669613712056

Epoch: 5| Step: 5
Training loss: 3.936038396919411
Validation loss: 3.2459449333643553

Epoch: 5| Step: 6
Training loss: 3.8247038832590294
Validation loss: 3.245949493654482

Epoch: 5| Step: 7
Training loss: 3.3677768412798867
Validation loss: 3.2430085707273326

Epoch: 5| Step: 8
Training loss: 3.3512537531705426
Validation loss: 3.2453729808048295

Epoch: 5| Step: 9
Training loss: 3.1430785051640093
Validation loss: 3.244921347058982

Epoch: 5| Step: 10
Training loss: 3.4180591505902282
Validation loss: 3.2453456757229437

Epoch: 144| Step: 0
Training loss: 2.914143333643449
Validation loss: 3.2436630653088723

Epoch: 5| Step: 1
Training loss: 4.251110829310505
Validation loss: 3.2428559854685393

Epoch: 5| Step: 2
Training loss: 3.9412816371065342
Validation loss: 3.2438472551367585

Epoch: 5| Step: 3
Training loss: 3.142887192743487
Validation loss: 3.24541869572475

Epoch: 5| Step: 4
Training loss: 3.336638115739445
Validation loss: 3.2438391702689082

Epoch: 5| Step: 5
Training loss: 3.304553306506341
Validation loss: 3.2437479347343983

Epoch: 5| Step: 6
Training loss: 3.0991312101639874
Validation loss: 3.2447023315067325

Epoch: 5| Step: 7
Training loss: 4.048989704476059
Validation loss: 3.242771521979021

Epoch: 5| Step: 8
Training loss: 3.0797427810669804
Validation loss: 3.242946775732525

Epoch: 5| Step: 9
Training loss: 4.164226707670462
Validation loss: 3.2430750095075873

Epoch: 5| Step: 10
Training loss: 2.387838896820296
Validation loss: 3.242487459012298

Epoch: 145| Step: 0
Training loss: 3.4182855600942883
Validation loss: 3.2432864194230526

Epoch: 5| Step: 1
Training loss: 3.0410620380208946
Validation loss: 3.242866057063184

Epoch: 5| Step: 2
Training loss: 3.9639369585353745
Validation loss: 3.2425582885234268

Epoch: 5| Step: 3
Training loss: 3.260954514931128
Validation loss: 3.2411724424531085

Epoch: 5| Step: 4
Training loss: 3.5037402195543903
Validation loss: 3.2404215619532026

Epoch: 5| Step: 5
Training loss: 3.6117317465173504
Validation loss: 3.241241537686977

Epoch: 5| Step: 6
Training loss: 3.2930273953574556
Validation loss: 3.241206315176169

Epoch: 5| Step: 7
Training loss: 3.6840170235835923
Validation loss: 3.240910514662806

Epoch: 5| Step: 8
Training loss: 2.901315417063783
Validation loss: 3.240956737868157

Epoch: 5| Step: 9
Training loss: 3.666266260536986
Validation loss: 3.2398913198537524

Epoch: 5| Step: 10
Training loss: 3.8660760072122846
Validation loss: 3.2392878945538937

Epoch: 146| Step: 0
Training loss: 3.6168613492775004
Validation loss: 3.241208118547647

Epoch: 5| Step: 1
Training loss: 2.6918665875652614
Validation loss: 3.2409911246259866

Epoch: 5| Step: 2
Training loss: 3.7801766882074945
Validation loss: 3.242021204388539

Epoch: 5| Step: 3
Training loss: 3.23191481932198
Validation loss: 3.2399454876213056

Epoch: 5| Step: 4
Training loss: 3.635446819774254
Validation loss: 3.2412731420743404

Epoch: 5| Step: 5
Training loss: 3.7532257193614234
Validation loss: 3.2392420187162982

Epoch: 5| Step: 6
Training loss: 2.970044626741973
Validation loss: 3.2387446112530593

Epoch: 5| Step: 7
Training loss: 3.3010170034151503
Validation loss: 3.2381221431764997

Epoch: 5| Step: 8
Training loss: 3.6727471797019056
Validation loss: 3.238975876813634

Epoch: 5| Step: 9
Training loss: 3.375748727893851
Validation loss: 3.237712182957247

Epoch: 5| Step: 10
Training loss: 4.118794484108103
Validation loss: 3.2380769380334304

Epoch: 147| Step: 0
Training loss: 4.043558182802612
Validation loss: 3.2373413066048515

Epoch: 5| Step: 1
Training loss: 3.547971312362828
Validation loss: 3.2385714684770757

Epoch: 5| Step: 2
Training loss: 3.2004749780054316
Validation loss: 3.23663502855188

Epoch: 5| Step: 3
Training loss: 2.8287619194962983
Validation loss: 3.2366996338667535

Epoch: 5| Step: 4
Training loss: 3.7264184184181435
Validation loss: 3.234724551717495

Epoch: 5| Step: 5
Training loss: 3.2058770987214924
Validation loss: 3.2367544071001424

Epoch: 5| Step: 6
Training loss: 4.2533578510434795
Validation loss: 3.2361811241350256

Epoch: 5| Step: 7
Training loss: 4.044034100653823
Validation loss: 3.2366800494822576

Epoch: 5| Step: 8
Training loss: 2.720590779435222
Validation loss: 3.235834294329418

Epoch: 5| Step: 9
Training loss: 2.8615834197116725
Validation loss: 3.2355043954903393

Epoch: 5| Step: 10
Training loss: 3.3968695871262646
Validation loss: 3.2355965932020267

Epoch: 148| Step: 0
Training loss: 3.6468805752722218
Validation loss: 3.234593664665033

Epoch: 5| Step: 1
Training loss: 3.0990696649294507
Validation loss: 3.234819501076359

Epoch: 5| Step: 2
Training loss: 3.887262691601959
Validation loss: 3.234663755591553

Epoch: 5| Step: 3
Training loss: 3.8598961111526826
Validation loss: 3.2335104337430582

Epoch: 5| Step: 4
Training loss: 2.574531131019041
Validation loss: 3.234530202993906

Epoch: 5| Step: 5
Training loss: 3.3217059633412727
Validation loss: 3.2335699846262873

Epoch: 5| Step: 6
Training loss: 3.5324402550182556
Validation loss: 3.232325702006466

Epoch: 5| Step: 7
Training loss: 3.294216440025663
Validation loss: 3.233473171863352

Epoch: 5| Step: 8
Training loss: 3.504525528599132
Validation loss: 3.233204072496166

Epoch: 5| Step: 9
Training loss: 3.452054095024524
Validation loss: 3.2319834802826337

Epoch: 5| Step: 10
Training loss: 3.900469722337376
Validation loss: 3.2335315865148946

Epoch: 149| Step: 0
Training loss: 3.7324741266047545
Validation loss: 3.232570197555162

Epoch: 5| Step: 1
Training loss: 3.862427404023923
Validation loss: 3.233050046012109

Epoch: 5| Step: 2
Training loss: 4.071373272283644
Validation loss: 3.232129456918939

Epoch: 5| Step: 3
Training loss: 3.235116477414148
Validation loss: 3.2320166505555066

Epoch: 5| Step: 4
Training loss: 4.0460281958962305
Validation loss: 3.231933596526277

Epoch: 5| Step: 5
Training loss: 2.9869691448935973
Validation loss: 3.2312316093001603

Epoch: 5| Step: 6
Training loss: 3.9014719312832202
Validation loss: 3.2328618755566803

Epoch: 5| Step: 7
Training loss: 2.7569690311423485
Validation loss: 3.2325452206466454

Epoch: 5| Step: 8
Training loss: 3.0890263417838275
Validation loss: 3.2325589931031455

Epoch: 5| Step: 9
Training loss: 3.1430314746413117
Validation loss: 3.230673904968502

Epoch: 5| Step: 10
Training loss: 2.9510726659573705
Validation loss: 3.230579111511266

Epoch: 150| Step: 0
Training loss: 3.184981005266162
Validation loss: 3.2322452542640194

Epoch: 5| Step: 1
Training loss: 3.58582646482677
Validation loss: 3.232331153154913

Epoch: 5| Step: 2
Training loss: 2.8033138726096083
Validation loss: 3.23255774005471

Epoch: 5| Step: 3
Training loss: 2.4932250730025234
Validation loss: 3.2308822700276187

Epoch: 5| Step: 4
Training loss: 3.8699968094529202
Validation loss: 3.2311906921119333

Epoch: 5| Step: 5
Training loss: 3.295978297643599
Validation loss: 3.2322135155996325

Epoch: 5| Step: 6
Training loss: 3.1863895052588336
Validation loss: 3.231549846284624

Epoch: 5| Step: 7
Training loss: 3.813797776764739
Validation loss: 3.2295545860373878

Epoch: 5| Step: 8
Training loss: 4.096740562159456
Validation loss: 3.2296832245421183

Epoch: 5| Step: 9
Training loss: 3.7688923823092524
Validation loss: 3.228604947766034

Epoch: 5| Step: 10
Training loss: 3.7744662381177063
Validation loss: 3.2291836500300124

Testing loss: 3.4031909968532417
