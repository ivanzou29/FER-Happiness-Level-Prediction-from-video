Epoch: 1| Step: 0
Training loss: 4.734230041503906
Validation loss: 5.152673834113664

Epoch: 6| Step: 1
Training loss: 5.1373820304870605
Validation loss: 5.143194388317806

Epoch: 6| Step: 2
Training loss: 5.787295818328857
Validation loss: 5.133965220502628

Epoch: 6| Step: 3
Training loss: 5.8718695640563965
Validation loss: 5.124422596346948

Epoch: 6| Step: 4
Training loss: 4.865658283233643
Validation loss: 5.114407954677459

Epoch: 6| Step: 5
Training loss: 3.4197962284088135
Validation loss: 5.103430809513215

Epoch: 6| Step: 6
Training loss: 4.652827739715576
Validation loss: 5.091649137517457

Epoch: 6| Step: 7
Training loss: 4.624731063842773
Validation loss: 5.079980891237977

Epoch: 6| Step: 8
Training loss: 4.755776405334473
Validation loss: 5.06689792038292

Epoch: 6| Step: 9
Training loss: 4.80949592590332
Validation loss: 5.053612098898939

Epoch: 6| Step: 10
Training loss: 5.6069817543029785
Validation loss: 5.039393137860042

Epoch: 6| Step: 11
Training loss: 4.2316131591796875
Validation loss: 5.024120694847517

Epoch: 6| Step: 12
Training loss: 5.364300727844238
Validation loss: 5.008292208435715

Epoch: 6| Step: 13
Training loss: 4.170027732849121
Validation loss: 4.990949133391021

Epoch: 2| Step: 0
Training loss: 5.357522964477539
Validation loss: 4.972234525988179

Epoch: 6| Step: 1
Training loss: 4.460290431976318
Validation loss: 4.953418013870075

Epoch: 6| Step: 2
Training loss: 4.426529884338379
Validation loss: 4.9323841269298265

Epoch: 6| Step: 3
Training loss: 3.8391270637512207
Validation loss: 4.911891465545983

Epoch: 6| Step: 4
Training loss: 6.415065765380859
Validation loss: 4.888359551788659

Epoch: 6| Step: 5
Training loss: 4.848839282989502
Validation loss: 4.864176629691996

Epoch: 6| Step: 6
Training loss: 4.7936906814575195
Validation loss: 4.839671124694168

Epoch: 6| Step: 7
Training loss: 4.687908172607422
Validation loss: 4.813428325037802

Epoch: 6| Step: 8
Training loss: 4.39640474319458
Validation loss: 4.786869936091925

Epoch: 6| Step: 9
Training loss: 3.6463615894317627
Validation loss: 4.758204906217514

Epoch: 6| Step: 10
Training loss: 4.447006702423096
Validation loss: 4.730154827076902

Epoch: 6| Step: 11
Training loss: 4.6401214599609375
Validation loss: 4.7011796941039385

Epoch: 6| Step: 12
Training loss: 3.8430354595184326
Validation loss: 4.672431679182155

Epoch: 6| Step: 13
Training loss: 4.929128646850586
Validation loss: 4.643318099360312

Epoch: 3| Step: 0
Training loss: 3.8816347122192383
Validation loss: 4.614745334912372

Epoch: 6| Step: 1
Training loss: 3.4171645641326904
Validation loss: 4.586972400706301

Epoch: 6| Step: 2
Training loss: 4.925254821777344
Validation loss: 4.5579815269798365

Epoch: 6| Step: 3
Training loss: 5.214455604553223
Validation loss: 4.530437315663984

Epoch: 6| Step: 4
Training loss: 4.247406959533691
Validation loss: 4.502242170354371

Epoch: 6| Step: 5
Training loss: 3.0645217895507812
Validation loss: 4.474861688511346

Epoch: 6| Step: 6
Training loss: 3.7655205726623535
Validation loss: 4.447010383811048

Epoch: 6| Step: 7
Training loss: 4.524859428405762
Validation loss: 4.419776493503202

Epoch: 6| Step: 8
Training loss: 3.8912997245788574
Validation loss: 4.3930088371358895

Epoch: 6| Step: 9
Training loss: 3.943215847015381
Validation loss: 4.367798218163111

Epoch: 6| Step: 10
Training loss: 4.587944030761719
Validation loss: 4.340390333565333

Epoch: 6| Step: 11
Training loss: 5.19000244140625
Validation loss: 4.3155320562342165

Epoch: 6| Step: 12
Training loss: 4.678203582763672
Validation loss: 4.289433679273052

Epoch: 6| Step: 13
Training loss: 3.9503250122070312
Validation loss: 4.264137903849284

Epoch: 4| Step: 0
Training loss: 4.692323684692383
Validation loss: 4.239035467947683

Epoch: 6| Step: 1
Training loss: 2.569316864013672
Validation loss: 4.213746034970847

Epoch: 6| Step: 2
Training loss: 3.389927864074707
Validation loss: 4.189423550841629

Epoch: 6| Step: 3
Training loss: 3.375185012817383
Validation loss: 4.165371894836426

Epoch: 6| Step: 4
Training loss: 4.907070159912109
Validation loss: 4.1463446822217715

Epoch: 6| Step: 5
Training loss: 4.470646381378174
Validation loss: 4.125489368233629

Epoch: 6| Step: 6
Training loss: 3.8939175605773926
Validation loss: 4.107357035401047

Epoch: 6| Step: 7
Training loss: 3.8507800102233887
Validation loss: 4.0896041495825655

Epoch: 6| Step: 8
Training loss: 4.627595901489258
Validation loss: 4.072213685640725

Epoch: 6| Step: 9
Training loss: 3.708784580230713
Validation loss: 4.055040451788133

Epoch: 6| Step: 10
Training loss: 2.7749476432800293
Validation loss: 4.0388460005483315

Epoch: 6| Step: 11
Training loss: 2.9582252502441406
Validation loss: 4.020187821439517

Epoch: 6| Step: 12
Training loss: 5.369835376739502
Validation loss: 4.007240628683439

Epoch: 6| Step: 13
Training loss: 5.034332752227783
Validation loss: 3.9930985102089505

Epoch: 5| Step: 0
Training loss: 3.496856212615967
Validation loss: 3.9792690969282583

Epoch: 6| Step: 1
Training loss: 3.7392477989196777
Validation loss: 3.9654718983557915

Epoch: 6| Step: 2
Training loss: 5.199688911437988
Validation loss: 3.952754266800419

Epoch: 6| Step: 3
Training loss: 2.96178936958313
Validation loss: 3.938239492395873

Epoch: 6| Step: 4
Training loss: 2.885714292526245
Validation loss: 3.926555049034857

Epoch: 6| Step: 5
Training loss: 2.6177330017089844
Validation loss: 3.916218924266036

Epoch: 6| Step: 6
Training loss: 3.266261339187622
Validation loss: 3.902426601738058

Epoch: 6| Step: 7
Training loss: 3.5026938915252686
Validation loss: 3.8922960348026727

Epoch: 6| Step: 8
Training loss: 3.748666286468506
Validation loss: 3.881603887004237

Epoch: 6| Step: 9
Training loss: 4.1803436279296875
Validation loss: 3.8702766151838404

Epoch: 6| Step: 10
Training loss: 4.196854591369629
Validation loss: 3.8589135805765786

Epoch: 6| Step: 11
Training loss: 4.31391716003418
Validation loss: 3.846072453324513

Epoch: 6| Step: 12
Training loss: 4.789198875427246
Validation loss: 3.832746413446242

Epoch: 6| Step: 13
Training loss: 3.7600932121276855
Validation loss: 3.8207793825416156

Epoch: 6| Step: 0
Training loss: 2.684478521347046
Validation loss: 3.808836829277777

Epoch: 6| Step: 1
Training loss: 4.317539215087891
Validation loss: 3.7986719531397664

Epoch: 6| Step: 2
Training loss: 3.8461713790893555
Validation loss: 3.782527639019874

Epoch: 6| Step: 3
Training loss: 3.146294116973877
Validation loss: 3.7708257859753025

Epoch: 6| Step: 4
Training loss: 3.3036932945251465
Validation loss: 3.7595137447439213

Epoch: 6| Step: 5
Training loss: 3.789151191711426
Validation loss: 3.7512308910328853

Epoch: 6| Step: 6
Training loss: 4.054756164550781
Validation loss: 3.73764621057818

Epoch: 6| Step: 7
Training loss: 3.379943370819092
Validation loss: 3.7281068089187785

Epoch: 6| Step: 8
Training loss: 3.0915398597717285
Validation loss: 3.7214099130322857

Epoch: 6| Step: 9
Training loss: 3.645488739013672
Validation loss: 3.71244651527815

Epoch: 6| Step: 10
Training loss: 3.5982892513275146
Validation loss: 3.7030092054797756

Epoch: 6| Step: 11
Training loss: 3.4184436798095703
Validation loss: 3.693055850203319

Epoch: 6| Step: 12
Training loss: 3.916249990463257
Validation loss: 3.6866030872509046

Epoch: 6| Step: 13
Training loss: 5.519402980804443
Validation loss: 3.6778032984784854

Epoch: 7| Step: 0
Training loss: 3.2091803550720215
Validation loss: 3.6669310241617183

Epoch: 6| Step: 1
Training loss: 4.054591655731201
Validation loss: 3.6613698467131583

Epoch: 6| Step: 2
Training loss: 3.6336193084716797
Validation loss: 3.6545027994340464

Epoch: 6| Step: 3
Training loss: 3.1200456619262695
Validation loss: 3.6488079691445954

Epoch: 6| Step: 4
Training loss: 3.5266971588134766
Validation loss: 3.6429425311344925

Epoch: 6| Step: 5
Training loss: 3.12475848197937
Validation loss: 3.6362276589998634

Epoch: 6| Step: 6
Training loss: 3.543280601501465
Validation loss: 3.632336329388362

Epoch: 6| Step: 7
Training loss: 3.4713010787963867
Validation loss: 3.623229977905109

Epoch: 6| Step: 8
Training loss: 2.6253957748413086
Validation loss: 3.6144938238205446

Epoch: 6| Step: 9
Training loss: 3.4238269329071045
Validation loss: 3.609043575102283

Epoch: 6| Step: 10
Training loss: 3.872044324874878
Validation loss: 3.606277004364998

Epoch: 6| Step: 11
Training loss: 4.414786338806152
Validation loss: 3.5982091657577024

Epoch: 6| Step: 12
Training loss: 4.177404403686523
Validation loss: 3.592417588797949

Epoch: 6| Step: 13
Training loss: 3.276189088821411
Validation loss: 3.5859254508890133

Epoch: 8| Step: 0
Training loss: 3.314171552658081
Validation loss: 3.578347485552552

Epoch: 6| Step: 1
Training loss: 3.0883326530456543
Validation loss: 3.5743733606030865

Epoch: 6| Step: 2
Training loss: 4.797813415527344
Validation loss: 3.5656253932624735

Epoch: 6| Step: 3
Training loss: 3.579888105392456
Validation loss: 3.5615551958801928

Epoch: 6| Step: 4
Training loss: 3.3164336681365967
Validation loss: 3.5558667746923303

Epoch: 6| Step: 5
Training loss: 2.9779770374298096
Validation loss: 3.546088485307591

Epoch: 6| Step: 6
Training loss: 4.320305824279785
Validation loss: 3.5412974819060294

Epoch: 6| Step: 7
Training loss: 2.9644522666931152
Validation loss: 3.5355601644003265

Epoch: 6| Step: 8
Training loss: 2.6624317169189453
Validation loss: 3.527210081777265

Epoch: 6| Step: 9
Training loss: 3.759398937225342
Validation loss: 3.5188980358903126

Epoch: 6| Step: 10
Training loss: 3.03132700920105
Validation loss: 3.5130629744580997

Epoch: 6| Step: 11
Training loss: 3.7084476947784424
Validation loss: 3.5083232310510453

Epoch: 6| Step: 12
Training loss: 4.406154155731201
Validation loss: 3.502687397823539

Epoch: 6| Step: 13
Training loss: 2.062206268310547
Validation loss: 3.494686747110018

Epoch: 9| Step: 0
Training loss: 3.001290798187256
Validation loss: 3.4893323836788053

Epoch: 6| Step: 1
Training loss: 3.2347195148468018
Validation loss: 3.4901371591834613

Epoch: 6| Step: 2
Training loss: 3.096867084503174
Validation loss: 3.481265857655515

Epoch: 6| Step: 3
Training loss: 3.006787061691284
Validation loss: 3.477566598564066

Epoch: 6| Step: 4
Training loss: 3.5205912590026855
Validation loss: 3.4770137725337857

Epoch: 6| Step: 5
Training loss: 3.4656739234924316
Validation loss: 3.4692008623512844

Epoch: 6| Step: 6
Training loss: 2.9871866703033447
Validation loss: 3.4623394653361332

Epoch: 6| Step: 7
Training loss: 3.747069835662842
Validation loss: 3.4587092630324827

Epoch: 6| Step: 8
Training loss: 3.477945327758789
Validation loss: 3.4542195873875774

Epoch: 6| Step: 9
Training loss: 3.1070852279663086
Validation loss: 3.450416836687314

Epoch: 6| Step: 10
Training loss: 3.145270586013794
Validation loss: 3.4452221624312864

Epoch: 6| Step: 11
Training loss: 3.645148277282715
Validation loss: 3.4399379991715953

Epoch: 6| Step: 12
Training loss: 4.377556324005127
Validation loss: 3.43574514953039

Epoch: 6| Step: 13
Training loss: 4.176219940185547
Validation loss: 3.431158176032446

Epoch: 10| Step: 0
Training loss: 3.886772632598877
Validation loss: 3.4297690955541467

Epoch: 6| Step: 1
Training loss: 2.875945568084717
Validation loss: 3.4267005792228122

Epoch: 6| Step: 2
Training loss: 4.211026191711426
Validation loss: 3.425041539694673

Epoch: 6| Step: 3
Training loss: 2.882969379425049
Validation loss: 3.414019400073636

Epoch: 6| Step: 4
Training loss: 4.148403644561768
Validation loss: 3.409321087662892

Epoch: 6| Step: 5
Training loss: 2.7101454734802246
Validation loss: 3.406988892503964

Epoch: 6| Step: 6
Training loss: 3.2210006713867188
Validation loss: 3.4039769480305333

Epoch: 6| Step: 7
Training loss: 3.98840594291687
Validation loss: 3.398255104659706

Epoch: 6| Step: 8
Training loss: 2.8599491119384766
Validation loss: 3.3949445037431616

Epoch: 6| Step: 9
Training loss: 2.913856029510498
Validation loss: 3.396151296554073

Epoch: 6| Step: 10
Training loss: 2.7285971641540527
Validation loss: 3.386821708371562

Epoch: 6| Step: 11
Training loss: 3.604796886444092
Validation loss: 3.3797103307580434

Epoch: 6| Step: 12
Training loss: 3.1625277996063232
Validation loss: 3.376141281538112

Epoch: 6| Step: 13
Training loss: 4.066233158111572
Validation loss: 3.374232010174823

Epoch: 11| Step: 0
Training loss: 3.8008108139038086
Validation loss: 3.3692786001390025

Epoch: 6| Step: 1
Training loss: 3.305739402770996
Validation loss: 3.3768628438313804

Epoch: 6| Step: 2
Training loss: 3.2092132568359375
Validation loss: 3.362263374431159

Epoch: 6| Step: 3
Training loss: 2.2669224739074707
Validation loss: 3.356702891729211

Epoch: 6| Step: 4
Training loss: 2.6947832107543945
Validation loss: 3.359865568017447

Epoch: 6| Step: 5
Training loss: 3.352475643157959
Validation loss: 3.3578310217908633

Epoch: 6| Step: 6
Training loss: 3.908146619796753
Validation loss: 3.35304836047593

Epoch: 6| Step: 7
Training loss: 3.207563877105713
Validation loss: 3.3480970808254775

Epoch: 6| Step: 8
Training loss: 3.448838710784912
Validation loss: 3.3393115407677105

Epoch: 6| Step: 9
Training loss: 2.7340400218963623
Validation loss: 3.3354777982158046

Epoch: 6| Step: 10
Training loss: 3.334146022796631
Validation loss: 3.33625913435413

Epoch: 6| Step: 11
Training loss: 3.539882183074951
Validation loss: 3.3478331924766622

Epoch: 6| Step: 12
Training loss: 3.7624683380126953
Validation loss: 3.3202166095856698

Epoch: 6| Step: 13
Training loss: 4.1641693115234375
Validation loss: 3.320028992109401

Epoch: 12| Step: 0
Training loss: 3.2360806465148926
Validation loss: 3.3453413824881277

Epoch: 6| Step: 1
Training loss: 2.8625845909118652
Validation loss: 3.3218026520103536

Epoch: 6| Step: 2
Training loss: 3.826488494873047
Validation loss: 3.3188884258270264

Epoch: 6| Step: 3
Training loss: 3.4088222980499268
Validation loss: 3.3152715672728834

Epoch: 6| Step: 4
Training loss: 4.310186862945557
Validation loss: 3.3155497222818355

Epoch: 6| Step: 5
Training loss: 2.604259967803955
Validation loss: 3.304305648290983

Epoch: 6| Step: 6
Training loss: 2.369582176208496
Validation loss: 3.2941926628030758

Epoch: 6| Step: 7
Training loss: 3.8790931701660156
Validation loss: 3.2908018378801245

Epoch: 6| Step: 8
Training loss: 3.3359804153442383
Validation loss: 3.2822014208762877

Epoch: 6| Step: 9
Training loss: 3.470581531524658
Validation loss: 3.277113909362465

Epoch: 6| Step: 10
Training loss: 1.874255657196045
Validation loss: 3.270291310484691

Epoch: 6| Step: 11
Training loss: 4.096635818481445
Validation loss: 3.2759091110639673

Epoch: 6| Step: 12
Training loss: 3.1482768058776855
Validation loss: 3.264795939127604

Epoch: 6| Step: 13
Training loss: 3.450416088104248
Validation loss: 3.2558594647274224

Epoch: 13| Step: 0
Training loss: 3.495854139328003
Validation loss: 3.2480309496643724

Epoch: 6| Step: 1
Training loss: 3.753973960876465
Validation loss: 3.2468635907737156

Epoch: 6| Step: 2
Training loss: 3.4225552082061768
Validation loss: 3.2406366102157103

Epoch: 6| Step: 3
Training loss: 3.821608781814575
Validation loss: 3.2382537344450593

Epoch: 6| Step: 4
Training loss: 3.725159168243408
Validation loss: 3.2325313475824173

Epoch: 6| Step: 5
Training loss: 3.2285332679748535
Validation loss: 3.231317861105806

Epoch: 6| Step: 6
Training loss: 2.2915663719177246
Validation loss: 3.2236496197280062

Epoch: 6| Step: 7
Training loss: 3.2398343086242676
Validation loss: 3.218954481104369

Epoch: 6| Step: 8
Training loss: 2.524714946746826
Validation loss: 3.211542352553337

Epoch: 6| Step: 9
Training loss: 3.6792960166931152
Validation loss: 3.2034634544003393

Epoch: 6| Step: 10
Training loss: 3.992899179458618
Validation loss: 3.201087882441859

Epoch: 6| Step: 11
Training loss: 2.48140811920166
Validation loss: 3.1970671992148123

Epoch: 6| Step: 12
Training loss: 2.826378345489502
Validation loss: 3.193897578024095

Epoch: 6| Step: 13
Training loss: 1.9628548622131348
Validation loss: 3.192697096896428

Epoch: 14| Step: 0
Training loss: 4.6284894943237305
Validation loss: 3.185163187724288

Epoch: 6| Step: 1
Training loss: 2.9136805534362793
Validation loss: 3.181340161190238

Epoch: 6| Step: 2
Training loss: 2.7997612953186035
Validation loss: 3.1790406703948975

Epoch: 6| Step: 3
Training loss: 3.261857032775879
Validation loss: 3.1728287307165

Epoch: 6| Step: 4
Training loss: 3.134023666381836
Validation loss: 3.1728634962471585

Epoch: 6| Step: 5
Training loss: 4.351858139038086
Validation loss: 3.1654256236168647

Epoch: 6| Step: 6
Training loss: 3.477222442626953
Validation loss: 3.1587134253594185

Epoch: 6| Step: 7
Training loss: 3.361605167388916
Validation loss: 3.1498325153063704

Epoch: 6| Step: 8
Training loss: 1.7157169580459595
Validation loss: 3.1497549241588962

Epoch: 6| Step: 9
Training loss: 3.2785065174102783
Validation loss: 3.1468208528334096

Epoch: 6| Step: 10
Training loss: 2.2918267250061035
Validation loss: 3.140536928689608

Epoch: 6| Step: 11
Training loss: 2.0086894035339355
Validation loss: 3.133101955536873

Epoch: 6| Step: 12
Training loss: 3.713916063308716
Validation loss: 3.1288177249252156

Epoch: 6| Step: 13
Training loss: 3.6424407958984375
Validation loss: 3.1262805026064635

Epoch: 15| Step: 0
Training loss: 3.5832910537719727
Validation loss: 3.122732852094917

Epoch: 6| Step: 1
Training loss: 2.9442200660705566
Validation loss: 3.124217317950341

Epoch: 6| Step: 2
Training loss: 4.2994890213012695
Validation loss: 3.1115464984729724

Epoch: 6| Step: 3
Training loss: 3.9553475379943848
Validation loss: 3.10860425426114

Epoch: 6| Step: 4
Training loss: 2.3547229766845703
Validation loss: 3.103326571884976

Epoch: 6| Step: 5
Training loss: 2.586987018585205
Validation loss: 3.098849311951668

Epoch: 6| Step: 6
Training loss: 2.586482524871826
Validation loss: 3.1006848683921238

Epoch: 6| Step: 7
Training loss: 2.7163028717041016
Validation loss: 3.0931692713050434

Epoch: 6| Step: 8
Training loss: 2.8759751319885254
Validation loss: 3.0885753554682576

Epoch: 6| Step: 9
Training loss: 4.235452651977539
Validation loss: 3.087945956055836

Epoch: 6| Step: 10
Training loss: 2.8214645385742188
Validation loss: 3.08036474515033

Epoch: 6| Step: 11
Training loss: 3.16929030418396
Validation loss: 3.077917621981713

Epoch: 6| Step: 12
Training loss: 2.8529162406921387
Validation loss: 3.073548824556412

Epoch: 6| Step: 13
Training loss: 2.544365882873535
Validation loss: 3.0678644077752226

Epoch: 16| Step: 0
Training loss: 3.3015880584716797
Validation loss: 3.073192242653139

Epoch: 6| Step: 1
Training loss: 4.086294174194336
Validation loss: 3.065762073762955

Epoch: 6| Step: 2
Training loss: 2.6888294219970703
Validation loss: 3.0603010628813054

Epoch: 6| Step: 3
Training loss: 2.7241268157958984
Validation loss: 3.0602169729048208

Epoch: 6| Step: 4
Training loss: 1.665855884552002
Validation loss: 3.0586376369640393

Epoch: 6| Step: 5
Training loss: 2.125800371170044
Validation loss: 3.0526073901884017

Epoch: 6| Step: 6
Training loss: 3.3391947746276855
Validation loss: 3.049998337222684

Epoch: 6| Step: 7
Training loss: 3.169002056121826
Validation loss: 3.0470380757444646

Epoch: 6| Step: 8
Training loss: 3.2945780754089355
Validation loss: 3.04688528532623

Epoch: 6| Step: 9
Training loss: 4.026398658752441
Validation loss: 3.0457301832014516

Epoch: 6| Step: 10
Training loss: 3.4447216987609863
Validation loss: 3.0327755789602957

Epoch: 6| Step: 11
Training loss: 3.0224764347076416
Validation loss: 3.029989537372384

Epoch: 6| Step: 12
Training loss: 3.4501922130584717
Validation loss: 3.033731811790056

Epoch: 6| Step: 13
Training loss: 2.947321891784668
Validation loss: 3.0279737134133615

Epoch: 17| Step: 0
Training loss: 2.666102409362793
Validation loss: 3.0268849634355113

Epoch: 6| Step: 1
Training loss: 3.5858378410339355
Validation loss: 3.049509279189571

Epoch: 6| Step: 2
Training loss: 3.781485080718994
Validation loss: 3.013615938924974

Epoch: 6| Step: 3
Training loss: 2.6876673698425293
Validation loss: 3.014793328059617

Epoch: 6| Step: 4
Training loss: 2.8486320972442627
Validation loss: 3.0166358153025308

Epoch: 6| Step: 5
Training loss: 3.175779342651367
Validation loss: 3.016763510242585

Epoch: 6| Step: 6
Training loss: 2.772162675857544
Validation loss: 3.0167947712764946

Epoch: 6| Step: 7
Training loss: 2.819094657897949
Validation loss: 3.0127432910344933

Epoch: 6| Step: 8
Training loss: 3.3039486408233643
Validation loss: 3.00312138629216

Epoch: 6| Step: 9
Training loss: 3.1568827629089355
Validation loss: 2.996135163050826

Epoch: 6| Step: 10
Training loss: 3.0768566131591797
Validation loss: 3.003475276372766

Epoch: 6| Step: 11
Training loss: 2.5307164192199707
Validation loss: 2.996152441988709

Epoch: 6| Step: 12
Training loss: 2.891479253768921
Validation loss: 2.99085630396361

Epoch: 6| Step: 13
Training loss: 4.216341495513916
Validation loss: 2.983364018060828

Epoch: 18| Step: 0
Training loss: 2.940154552459717
Validation loss: 2.983930480095648

Epoch: 6| Step: 1
Training loss: 3.4983646869659424
Validation loss: 2.981614843491585

Epoch: 6| Step: 2
Training loss: 3.2454874515533447
Validation loss: 2.984512200919531

Epoch: 6| Step: 3
Training loss: 3.7027924060821533
Validation loss: 2.979802372635052

Epoch: 6| Step: 4
Training loss: 2.9824042320251465
Validation loss: 2.9749975640286683

Epoch: 6| Step: 5
Training loss: 3.650224208831787
Validation loss: 2.965599585604924

Epoch: 6| Step: 6
Training loss: 2.8926584720611572
Validation loss: 2.980498867650186

Epoch: 6| Step: 7
Training loss: 2.1200995445251465
Validation loss: 2.9600770319661787

Epoch: 6| Step: 8
Training loss: 3.030941963195801
Validation loss: 2.9607060211960987

Epoch: 6| Step: 9
Training loss: 3.7672696113586426
Validation loss: 2.9580998548897366

Epoch: 6| Step: 10
Training loss: 2.679762125015259
Validation loss: 2.9571854376023814

Epoch: 6| Step: 11
Training loss: 2.011868476867676
Validation loss: 2.9570475291180354

Epoch: 6| Step: 12
Training loss: 2.7507386207580566
Validation loss: 2.9538583806765977

Epoch: 6| Step: 13
Training loss: 3.609192371368408
Validation loss: 2.9507239839082122

Epoch: 19| Step: 0
Training loss: 2.7439749240875244
Validation loss: 2.9517677830111597

Epoch: 6| Step: 1
Training loss: 2.4390265941619873
Validation loss: 2.9488521493891233

Epoch: 6| Step: 2
Training loss: 3.338449001312256
Validation loss: 2.948295600952641

Epoch: 6| Step: 3
Training loss: 3.1094837188720703
Validation loss: 2.94408171151274

Epoch: 6| Step: 4
Training loss: 3.6018786430358887
Validation loss: 2.9441355248933196

Epoch: 6| Step: 5
Training loss: 3.9363784790039062
Validation loss: 2.944917683960289

Epoch: 6| Step: 6
Training loss: 2.886406421661377
Validation loss: 2.9346240464077202

Epoch: 6| Step: 7
Training loss: 3.053419589996338
Validation loss: 2.927376598440191

Epoch: 6| Step: 8
Training loss: 2.954470157623291
Validation loss: 2.926276840189452

Epoch: 6| Step: 9
Training loss: 2.9208931922912598
Validation loss: 2.927239441102551

Epoch: 6| Step: 10
Training loss: 2.1719350814819336
Validation loss: 2.9238714453994588

Epoch: 6| Step: 11
Training loss: 3.3775646686553955
Validation loss: 2.9207325468781176

Epoch: 6| Step: 12
Training loss: 2.8910512924194336
Validation loss: 2.9137171109517417

Epoch: 6| Step: 13
Training loss: 2.7391276359558105
Validation loss: 2.931809648390739

Epoch: 20| Step: 0
Training loss: 3.580780029296875
Validation loss: 2.9223477071331394

Epoch: 6| Step: 1
Training loss: 2.7628440856933594
Validation loss: 2.9087160966729604

Epoch: 6| Step: 2
Training loss: 3.3601841926574707
Validation loss: 2.910120733322636

Epoch: 6| Step: 3
Training loss: 3.3759617805480957
Validation loss: 2.9098685915752123

Epoch: 6| Step: 4
Training loss: 2.977217435836792
Validation loss: 2.9057117277576077

Epoch: 6| Step: 5
Training loss: 2.5191102027893066
Validation loss: 2.907268247296733

Epoch: 6| Step: 6
Training loss: 2.910491943359375
Validation loss: 2.9075017052312053

Epoch: 6| Step: 7
Training loss: 2.7584726810455322
Validation loss: 2.9055292426898913

Epoch: 6| Step: 8
Training loss: 3.44882869720459
Validation loss: 2.900477655472294

Epoch: 6| Step: 9
Training loss: 2.845757246017456
Validation loss: 2.897883479313184

Epoch: 6| Step: 10
Training loss: 2.237799644470215
Validation loss: 2.8930790039800827

Epoch: 6| Step: 11
Training loss: 2.5324912071228027
Validation loss: 2.912647670315158

Epoch: 6| Step: 12
Training loss: 3.560276985168457
Validation loss: 2.8976011635154806

Epoch: 6| Step: 13
Training loss: 3.300205707550049
Validation loss: 2.8894735920813774

Epoch: 21| Step: 0
Training loss: 2.7470922470092773
Validation loss: 2.886369776982133

Epoch: 6| Step: 1
Training loss: 2.798023223876953
Validation loss: 2.888021602425524

Epoch: 6| Step: 2
Training loss: 2.9664180278778076
Validation loss: 2.888950155627343

Epoch: 6| Step: 3
Training loss: 3.6079983711242676
Validation loss: 2.8837939052171606

Epoch: 6| Step: 4
Training loss: 3.3447425365448
Validation loss: 2.883323787361063

Epoch: 6| Step: 5
Training loss: 1.9894953966140747
Validation loss: 2.8884485447278587

Epoch: 6| Step: 6
Training loss: 2.8266472816467285
Validation loss: 2.8904306709125476

Epoch: 6| Step: 7
Training loss: 2.8010027408599854
Validation loss: 2.8978038013622327

Epoch: 6| Step: 8
Training loss: 3.0675501823425293
Validation loss: 2.995785854196036

Epoch: 6| Step: 9
Training loss: 3.3538131713867188
Validation loss: 2.9292008466618036

Epoch: 6| Step: 10
Training loss: 3.7476768493652344
Validation loss: 2.8903839357437624

Epoch: 6| Step: 11
Training loss: 3.5342750549316406
Validation loss: 2.8873443654788438

Epoch: 6| Step: 12
Training loss: 2.4039063453674316
Validation loss: 2.895973115838984

Epoch: 6| Step: 13
Training loss: 2.6803553104400635
Validation loss: 2.9051446812127226

Epoch: 22| Step: 0
Training loss: 3.608424186706543
Validation loss: 2.905552000127813

Epoch: 6| Step: 1
Training loss: 2.754300355911255
Validation loss: 2.8990468286698863

Epoch: 6| Step: 2
Training loss: 2.916400909423828
Validation loss: 2.894277854632306

Epoch: 6| Step: 3
Training loss: 2.6993794441223145
Validation loss: 2.892798295585058

Epoch: 6| Step: 4
Training loss: 3.1192679405212402
Validation loss: 2.891175208553191

Epoch: 6| Step: 5
Training loss: 3.3040943145751953
Validation loss: 2.8889449052913214

Epoch: 6| Step: 6
Training loss: 3.515026569366455
Validation loss: 2.8897053964676394

Epoch: 6| Step: 7
Training loss: 2.916794776916504
Validation loss: 2.8913282014990367

Epoch: 6| Step: 8
Training loss: 2.554417610168457
Validation loss: 2.8872568735512356

Epoch: 6| Step: 9
Training loss: 2.7083237171173096
Validation loss: 2.8771617104930263

Epoch: 6| Step: 10
Training loss: 3.2175307273864746
Validation loss: 2.870681324312764

Epoch: 6| Step: 11
Training loss: 2.7504615783691406
Validation loss: 2.8674323686989407

Epoch: 6| Step: 12
Training loss: 3.1184287071228027
Validation loss: 2.865642632207563

Epoch: 6| Step: 13
Training loss: 2.354395866394043
Validation loss: 2.865576249296947

Epoch: 23| Step: 0
Training loss: 3.3790128231048584
Validation loss: 2.8628539705789215

Epoch: 6| Step: 1
Training loss: 2.378424882888794
Validation loss: 2.8589623666578725

Epoch: 6| Step: 2
Training loss: 3.157754421234131
Validation loss: 2.85763979470858

Epoch: 6| Step: 3
Training loss: 3.4283432960510254
Validation loss: 2.861141150997531

Epoch: 6| Step: 4
Training loss: 3.0918684005737305
Validation loss: 2.8540202289499264

Epoch: 6| Step: 5
Training loss: 3.102640390396118
Validation loss: 2.8488654167421403

Epoch: 6| Step: 6
Training loss: 2.68710994720459
Validation loss: 2.846654922731461

Epoch: 6| Step: 7
Training loss: 2.4793429374694824
Validation loss: 2.84630173765203

Epoch: 6| Step: 8
Training loss: 2.817251205444336
Validation loss: 2.846735897884574

Epoch: 6| Step: 9
Training loss: 2.61857271194458
Validation loss: 2.8436678558267574

Epoch: 6| Step: 10
Training loss: 2.9408764839172363
Validation loss: 2.838876488388226

Epoch: 6| Step: 11
Training loss: 3.542983293533325
Validation loss: 2.837214772419263

Epoch: 6| Step: 12
Training loss: 2.852905511856079
Validation loss: 2.8346430127338698

Epoch: 6| Step: 13
Training loss: 3.067615509033203
Validation loss: 2.8319607729552896

Epoch: 24| Step: 0
Training loss: 2.518494129180908
Validation loss: 2.832613709152386

Epoch: 6| Step: 1
Training loss: 2.4464807510375977
Validation loss: 2.8366891132887972

Epoch: 6| Step: 2
Training loss: 3.552569627761841
Validation loss: 2.8297706034875687

Epoch: 6| Step: 3
Training loss: 3.2974188327789307
Validation loss: 2.828492041557066

Epoch: 6| Step: 4
Training loss: 3.4969544410705566
Validation loss: 2.8274181478766987

Epoch: 6| Step: 5
Training loss: 3.614262819290161
Validation loss: 2.826910170175696

Epoch: 6| Step: 6
Training loss: 2.3901398181915283
Validation loss: 2.825093351384645

Epoch: 6| Step: 7
Training loss: 2.882524013519287
Validation loss: 2.8252628618671047

Epoch: 6| Step: 8
Training loss: 3.3822133541107178
Validation loss: 2.825796450338056

Epoch: 6| Step: 9
Training loss: 2.598489761352539
Validation loss: 2.8254598750863025

Epoch: 6| Step: 10
Training loss: 2.6055545806884766
Validation loss: 2.825630457170548

Epoch: 6| Step: 11
Training loss: 2.12312388420105
Validation loss: 2.824341958568942

Epoch: 6| Step: 12
Training loss: 3.046602725982666
Validation loss: 2.823092568305231

Epoch: 6| Step: 13
Training loss: 3.686038017272949
Validation loss: 2.8225137854135163

Epoch: 25| Step: 0
Training loss: 3.188338279724121
Validation loss: 2.8219771718466156

Epoch: 6| Step: 1
Training loss: 2.922208070755005
Validation loss: 2.820903129475091

Epoch: 6| Step: 2
Training loss: 2.610100269317627
Validation loss: 2.819827102845715

Epoch: 6| Step: 3
Training loss: 2.430575370788574
Validation loss: 2.817394354010141

Epoch: 6| Step: 4
Training loss: 3.472668170928955
Validation loss: 2.815560738245646

Epoch: 6| Step: 5
Training loss: 2.9447021484375
Validation loss: 2.813046032382596

Epoch: 6| Step: 6
Training loss: 2.980215311050415
Validation loss: 2.812809190442485

Epoch: 6| Step: 7
Training loss: 2.9452266693115234
Validation loss: 2.811883444427162

Epoch: 6| Step: 8
Training loss: 2.474308490753174
Validation loss: 2.808997300363356

Epoch: 6| Step: 9
Training loss: 3.6474082469940186
Validation loss: 2.8073237275564544

Epoch: 6| Step: 10
Training loss: 2.6052846908569336
Validation loss: 2.8066096895484516

Epoch: 6| Step: 11
Training loss: 3.2041969299316406
Validation loss: 2.8063308885020595

Epoch: 6| Step: 12
Training loss: 2.99245285987854
Validation loss: 2.8051164662966164

Epoch: 6| Step: 13
Training loss: 2.622701406478882
Validation loss: 2.803646851611394

Epoch: 26| Step: 0
Training loss: 2.179978847503662
Validation loss: 2.806908158845799

Epoch: 6| Step: 1
Training loss: 2.543262481689453
Validation loss: 2.8025024167953

Epoch: 6| Step: 2
Training loss: 2.2241764068603516
Validation loss: 2.801507116645895

Epoch: 6| Step: 3
Training loss: 3.332031726837158
Validation loss: 2.802767297273041

Epoch: 6| Step: 4
Training loss: 2.8394219875335693
Validation loss: 2.7995614928583943

Epoch: 6| Step: 5
Training loss: 3.561835765838623
Validation loss: 2.79760403274208

Epoch: 6| Step: 6
Training loss: 3.750803232192993
Validation loss: 2.7962410988346225

Epoch: 6| Step: 7
Training loss: 2.6217217445373535
Validation loss: 2.7969428057311685

Epoch: 6| Step: 8
Training loss: 3.799553155899048
Validation loss: 2.797020004641625

Epoch: 6| Step: 9
Training loss: 2.38138484954834
Validation loss: 2.796225465754027

Epoch: 6| Step: 10
Training loss: 3.2413551807403564
Validation loss: 2.797898138723066

Epoch: 6| Step: 11
Training loss: 2.6388673782348633
Validation loss: 2.795469355839555

Epoch: 6| Step: 12
Training loss: 2.2194628715515137
Validation loss: 2.7962634717264483

Epoch: 6| Step: 13
Training loss: 4.350487232208252
Validation loss: 2.7956769415127334

Epoch: 27| Step: 0
Training loss: 3.467479705810547
Validation loss: 2.79336033585251

Epoch: 6| Step: 1
Training loss: 2.9339816570281982
Validation loss: 2.7922492052919123

Epoch: 6| Step: 2
Training loss: 3.012335777282715
Validation loss: 2.790793562448153

Epoch: 6| Step: 3
Training loss: 2.7959156036376953
Validation loss: 2.7891250656497095

Epoch: 6| Step: 4
Training loss: 3.0765695571899414
Validation loss: 2.7873101952255412

Epoch: 6| Step: 5
Training loss: 2.1042871475219727
Validation loss: 2.7868063167859147

Epoch: 6| Step: 6
Training loss: 2.575869560241699
Validation loss: 2.7851146728761735

Epoch: 6| Step: 7
Training loss: 2.5127205848693848
Validation loss: 2.7844850119724067

Epoch: 6| Step: 8
Training loss: 2.4572103023529053
Validation loss: 2.783469077079527

Epoch: 6| Step: 9
Training loss: 2.823965549468994
Validation loss: 2.784466484541534

Epoch: 6| Step: 10
Training loss: 3.99446439743042
Validation loss: 2.7819454362315517

Epoch: 6| Step: 11
Training loss: 3.8154168128967285
Validation loss: 2.7814283037698395

Epoch: 6| Step: 12
Training loss: 2.429428815841675
Validation loss: 2.782597113681096

Epoch: 6| Step: 13
Training loss: 2.9884588718414307
Validation loss: 2.781312373376662

Epoch: 28| Step: 0
Training loss: 3.502983570098877
Validation loss: 2.780821782286449

Epoch: 6| Step: 1
Training loss: 2.2366228103637695
Validation loss: 2.7780126089690835

Epoch: 6| Step: 2
Training loss: 2.194242000579834
Validation loss: 2.7780937353769937

Epoch: 6| Step: 3
Training loss: 2.6756556034088135
Validation loss: 2.777972203429027

Epoch: 6| Step: 4
Training loss: 2.9991350173950195
Validation loss: 2.776890867499895

Epoch: 6| Step: 5
Training loss: 3.414318561553955
Validation loss: 2.775680051055006

Epoch: 6| Step: 6
Training loss: 2.4112966060638428
Validation loss: 2.775943648430609

Epoch: 6| Step: 7
Training loss: 2.297196388244629
Validation loss: 2.7759188682802263

Epoch: 6| Step: 8
Training loss: 2.500084400177002
Validation loss: 2.7748399601187757

Epoch: 6| Step: 9
Training loss: 2.7988510131835938
Validation loss: 2.77390613607181

Epoch: 6| Step: 10
Training loss: 3.2750320434570312
Validation loss: 2.7734928848922893

Epoch: 6| Step: 11
Training loss: 3.7200961112976074
Validation loss: 2.773845177824779

Epoch: 6| Step: 12
Training loss: 3.774054765701294
Validation loss: 2.7720200272016626

Epoch: 6| Step: 13
Training loss: 3.1435329914093018
Validation loss: 2.7731864990726596

Epoch: 29| Step: 0
Training loss: 2.6177666187286377
Validation loss: 2.7737123581670944

Epoch: 6| Step: 1
Training loss: 1.7454016208648682
Validation loss: 2.7814475003109185

Epoch: 6| Step: 2
Training loss: 2.4874086380004883
Validation loss: 2.7700742880503335

Epoch: 6| Step: 3
Training loss: 3.172760009765625
Validation loss: 2.7714259675754014

Epoch: 6| Step: 4
Training loss: 3.173964500427246
Validation loss: 2.766905725643199

Epoch: 6| Step: 5
Training loss: 3.133477210998535
Validation loss: 2.7676986494371967

Epoch: 6| Step: 6
Training loss: 4.106928825378418
Validation loss: 2.764427013294671

Epoch: 6| Step: 7
Training loss: 3.093644618988037
Validation loss: 2.7698017192143265

Epoch: 6| Step: 8
Training loss: 2.9346108436584473
Validation loss: 2.765895325650451

Epoch: 6| Step: 9
Training loss: 2.385556221008301
Validation loss: 2.760445951133646

Epoch: 6| Step: 10
Training loss: 3.2409305572509766
Validation loss: 2.7765789775438208

Epoch: 6| Step: 11
Training loss: 3.018643856048584
Validation loss: 2.79657990958101

Epoch: 6| Step: 12
Training loss: 3.2816624641418457
Validation loss: 2.758166577226372

Epoch: 6| Step: 13
Training loss: 2.074108123779297
Validation loss: 2.759094245972172

Epoch: 30| Step: 0
Training loss: 3.005869150161743
Validation loss: 2.8020705305119997

Epoch: 6| Step: 1
Training loss: 2.9693667888641357
Validation loss: 2.8124919219683577

Epoch: 6| Step: 2
Training loss: 2.0255837440490723
Validation loss: 2.7955591473528134

Epoch: 6| Step: 3
Training loss: 2.4965920448303223
Validation loss: 2.7606486274350073

Epoch: 6| Step: 4
Training loss: 2.8999435901641846
Validation loss: 2.762460877818446

Epoch: 6| Step: 5
Training loss: 1.9485304355621338
Validation loss: 2.7703114581364456

Epoch: 6| Step: 6
Training loss: 3.3231732845306396
Validation loss: 2.773887718877485

Epoch: 6| Step: 7
Training loss: 4.144749641418457
Validation loss: 2.7804965511445077

Epoch: 6| Step: 8
Training loss: 2.321237802505493
Validation loss: 2.781790666682746

Epoch: 6| Step: 9
Training loss: 2.6472411155700684
Validation loss: 2.7834301225600706

Epoch: 6| Step: 10
Training loss: 2.5165255069732666
Validation loss: 2.7881772851431244

Epoch: 6| Step: 11
Training loss: 3.3303284645080566
Validation loss: 2.792084014543923

Epoch: 6| Step: 12
Training loss: 4.054893493652344
Validation loss: 2.7885063668733

Epoch: 6| Step: 13
Training loss: 3.5245563983917236
Validation loss: 2.7786061122853267

Epoch: 31| Step: 0
Training loss: 2.9558446407318115
Validation loss: 2.7735797384733796

Epoch: 6| Step: 1
Training loss: 2.7866997718811035
Validation loss: 2.7702267016133955

Epoch: 6| Step: 2
Training loss: 3.1041364669799805
Validation loss: 2.7659199212187078

Epoch: 6| Step: 3
Training loss: 2.4622490406036377
Validation loss: 2.7652307300157446

Epoch: 6| Step: 4
Training loss: 3.3659708499908447
Validation loss: 2.7664584370069605

Epoch: 6| Step: 5
Training loss: 2.2627086639404297
Validation loss: 2.7664692324976765

Epoch: 6| Step: 6
Training loss: 2.1601059436798096
Validation loss: 2.764485151537003

Epoch: 6| Step: 7
Training loss: 3.8193821907043457
Validation loss: 2.7607832185683714

Epoch: 6| Step: 8
Training loss: 3.2840991020202637
Validation loss: 2.7602433568687847

Epoch: 6| Step: 9
Training loss: 2.700697183609009
Validation loss: 2.7547181806256695

Epoch: 6| Step: 10
Training loss: 2.9376115798950195
Validation loss: 2.7484266988692747

Epoch: 6| Step: 11
Training loss: 3.093719959259033
Validation loss: 2.7449169338390393

Epoch: 6| Step: 12
Training loss: 2.490370988845825
Validation loss: 2.744329067968553

Epoch: 6| Step: 13
Training loss: 3.6064555644989014
Validation loss: 2.741111437479655

Epoch: 32| Step: 0
Training loss: 3.0168347358703613
Validation loss: 2.738292847910235

Epoch: 6| Step: 1
Training loss: 2.772437810897827
Validation loss: 2.7370855987712903

Epoch: 6| Step: 2
Training loss: 2.5762035846710205
Validation loss: 2.7338177260532173

Epoch: 6| Step: 3
Training loss: 2.612786293029785
Validation loss: 2.7323046422773793

Epoch: 6| Step: 4
Training loss: 3.2570292949676514
Validation loss: 2.730984651914207

Epoch: 6| Step: 5
Training loss: 1.997381567955017
Validation loss: 2.732008041874055

Epoch: 6| Step: 6
Training loss: 3.2683048248291016
Validation loss: 2.731601607414984

Epoch: 6| Step: 7
Training loss: 3.87815523147583
Validation loss: 2.7398337138596403

Epoch: 6| Step: 8
Training loss: 3.330479621887207
Validation loss: 2.729192151818224

Epoch: 6| Step: 9
Training loss: 3.054281711578369
Validation loss: 2.7251516080671743

Epoch: 6| Step: 10
Training loss: 2.7107720375061035
Validation loss: 2.7240374934288765

Epoch: 6| Step: 11
Training loss: 3.040680408477783
Validation loss: 2.7220450447451685

Epoch: 6| Step: 12
Training loss: 2.1327874660491943
Validation loss: 2.7224266657265286

Epoch: 6| Step: 13
Training loss: 2.651756763458252
Validation loss: 2.7238297334281345

Epoch: 33| Step: 0
Training loss: 2.6568875312805176
Validation loss: 2.7234076094883743

Epoch: 6| Step: 1
Training loss: 3.4653894901275635
Validation loss: 2.7623872474957536

Epoch: 6| Step: 2
Training loss: 2.8986902236938477
Validation loss: 2.727487535886867

Epoch: 6| Step: 3
Training loss: 3.6037817001342773
Validation loss: 2.719079607276506

Epoch: 6| Step: 4
Training loss: 2.3789262771606445
Validation loss: 2.7189976733217955

Epoch: 6| Step: 5
Training loss: 3.327953815460205
Validation loss: 2.720851021428262

Epoch: 6| Step: 6
Training loss: 2.5763392448425293
Validation loss: 2.7238158872050624

Epoch: 6| Step: 7
Training loss: 2.8142547607421875
Validation loss: 2.7445581497684604

Epoch: 6| Step: 8
Training loss: 2.004286050796509
Validation loss: 2.729527755450177

Epoch: 6| Step: 9
Training loss: 3.883146286010742
Validation loss: 2.7459642476932977

Epoch: 6| Step: 10
Training loss: 2.245462417602539
Validation loss: 2.736691100623018

Epoch: 6| Step: 11
Training loss: 3.0456881523132324
Validation loss: 2.731255062164799

Epoch: 6| Step: 12
Training loss: 2.725006580352783
Validation loss: 2.715053871113767

Epoch: 6| Step: 13
Training loss: 2.7190921306610107
Validation loss: 2.7133259132344234

Epoch: 34| Step: 0
Training loss: 2.3866162300109863
Validation loss: 2.714318444651942

Epoch: 6| Step: 1
Training loss: 2.3771252632141113
Validation loss: 2.71855733471532

Epoch: 6| Step: 2
Training loss: 2.6515235900878906
Validation loss: 2.7240777861687446

Epoch: 6| Step: 3
Training loss: 3.8534133434295654
Validation loss: 2.7248633318049933

Epoch: 6| Step: 4
Training loss: 3.7941126823425293
Validation loss: 2.742419445386497

Epoch: 6| Step: 5
Training loss: 2.276273727416992
Validation loss: 2.7449688219255015

Epoch: 6| Step: 6
Training loss: 2.3433547019958496
Validation loss: 2.7456267905491654

Epoch: 6| Step: 7
Training loss: 2.9463658332824707
Validation loss: 2.713507947101388

Epoch: 6| Step: 8
Training loss: 3.1683194637298584
Validation loss: 2.709572115252095

Epoch: 6| Step: 9
Training loss: 2.411518096923828
Validation loss: 2.708017651752759

Epoch: 6| Step: 10
Training loss: 3.5669617652893066
Validation loss: 2.7070559122229136

Epoch: 6| Step: 11
Training loss: 2.6937170028686523
Validation loss: 2.709098433935514

Epoch: 6| Step: 12
Training loss: 3.1801252365112305
Validation loss: 2.712527177667105

Epoch: 6| Step: 13
Training loss: 2.4950361251831055
Validation loss: 2.7112346054405294

Epoch: 35| Step: 0
Training loss: 3.059718132019043
Validation loss: 2.7116700474933912

Epoch: 6| Step: 1
Training loss: 2.4978058338165283
Validation loss: 2.710601311857982

Epoch: 6| Step: 2
Training loss: 2.905015468597412
Validation loss: 2.706966248891687

Epoch: 6| Step: 3
Training loss: 3.666001558303833
Validation loss: 2.701619786600913

Epoch: 6| Step: 4
Training loss: 3.4343924522399902
Validation loss: 2.7033080029231247

Epoch: 6| Step: 5
Training loss: 2.2212133407592773
Validation loss: 2.69887904197939

Epoch: 6| Step: 6
Training loss: 2.8363687992095947
Validation loss: 2.693989566577378

Epoch: 6| Step: 7
Training loss: 2.2845327854156494
Validation loss: 2.6935287188458186

Epoch: 6| Step: 8
Training loss: 2.5921921730041504
Validation loss: 2.6922305886463453

Epoch: 6| Step: 9
Training loss: 2.6882596015930176
Validation loss: 2.6894950789789998

Epoch: 6| Step: 10
Training loss: 2.67685604095459
Validation loss: 2.69439221197559

Epoch: 6| Step: 11
Training loss: 3.4155750274658203
Validation loss: 2.7199273263254473

Epoch: 6| Step: 12
Training loss: 3.7695260047912598
Validation loss: 2.6878619091485136

Epoch: 6| Step: 13
Training loss: 1.4938772916793823
Validation loss: 2.6887383845544632

Epoch: 36| Step: 0
Training loss: 2.3395462036132812
Validation loss: 2.6865084607114076

Epoch: 6| Step: 1
Training loss: 3.326054096221924
Validation loss: 2.691466974955733

Epoch: 6| Step: 2
Training loss: 2.618673324584961
Validation loss: 2.689172360204881

Epoch: 6| Step: 3
Training loss: 3.730077028274536
Validation loss: 2.688532588302448

Epoch: 6| Step: 4
Training loss: 2.2669458389282227
Validation loss: 2.6893091150509414

Epoch: 6| Step: 5
Training loss: 2.555379867553711
Validation loss: 2.6860268705634662

Epoch: 6| Step: 6
Training loss: 3.029520034790039
Validation loss: 2.6869445616199124

Epoch: 6| Step: 7
Training loss: 2.7754299640655518
Validation loss: 2.6858447136417514

Epoch: 6| Step: 8
Training loss: 3.3346409797668457
Validation loss: 2.685331639423165

Epoch: 6| Step: 9
Training loss: 3.2741661071777344
Validation loss: 2.6839773424210085

Epoch: 6| Step: 10
Training loss: 2.6803035736083984
Validation loss: 2.6841218650981946

Epoch: 6| Step: 11
Training loss: 2.43923282623291
Validation loss: 2.683888763509771

Epoch: 6| Step: 12
Training loss: 2.6131234169006348
Validation loss: 2.683782995388072

Epoch: 6| Step: 13
Training loss: 3.21417236328125
Validation loss: 2.6818107994653846

Epoch: 37| Step: 0
Training loss: 2.0087027549743652
Validation loss: 2.6815725834138933

Epoch: 6| Step: 1
Training loss: 2.7687792778015137
Validation loss: 2.6825175605794436

Epoch: 6| Step: 2
Training loss: 2.712035894393921
Validation loss: 2.679804212303572

Epoch: 6| Step: 3
Training loss: 2.9190380573272705
Validation loss: 2.681632488004623

Epoch: 6| Step: 4
Training loss: 2.7666573524475098
Validation loss: 2.6778554147289646

Epoch: 6| Step: 5
Training loss: 3.336369514465332
Validation loss: 2.6783189671013945

Epoch: 6| Step: 6
Training loss: 3.2376222610473633
Validation loss: 2.6768620783282864

Epoch: 6| Step: 7
Training loss: 3.300861358642578
Validation loss: 2.675187590301678

Epoch: 6| Step: 8
Training loss: 3.285574197769165
Validation loss: 2.6757574555694417

Epoch: 6| Step: 9
Training loss: 2.9948348999023438
Validation loss: 2.6742721424307874

Epoch: 6| Step: 10
Training loss: 2.890822649002075
Validation loss: 2.6736495161569245

Epoch: 6| Step: 11
Training loss: 2.4955878257751465
Validation loss: 2.672470469628611

Epoch: 6| Step: 12
Training loss: 1.9175775051116943
Validation loss: 2.6710206385581725

Epoch: 6| Step: 13
Training loss: 3.6415023803710938
Validation loss: 2.674453978897423

Epoch: 38| Step: 0
Training loss: 2.521895408630371
Validation loss: 2.6793202507880425

Epoch: 6| Step: 1
Training loss: 2.810675621032715
Validation loss: 2.6810159580681914

Epoch: 6| Step: 2
Training loss: 3.4354701042175293
Validation loss: 2.6912682799882788

Epoch: 6| Step: 3
Training loss: 3.3096044063568115
Validation loss: 2.6683730925283125

Epoch: 6| Step: 4
Training loss: 2.611670970916748
Validation loss: 2.667147236485635

Epoch: 6| Step: 5
Training loss: 2.4220404624938965
Validation loss: 2.668896516164144

Epoch: 6| Step: 6
Training loss: 2.620534896850586
Validation loss: 2.668477996703117

Epoch: 6| Step: 7
Training loss: 1.9448728561401367
Validation loss: 2.6682036538277902

Epoch: 6| Step: 8
Training loss: 3.0171146392822266
Validation loss: 2.6700470934632006

Epoch: 6| Step: 9
Training loss: 2.7856059074401855
Validation loss: 2.6665571915206088

Epoch: 6| Step: 10
Training loss: 3.1630473136901855
Validation loss: 2.671148810335385

Epoch: 6| Step: 11
Training loss: 3.467708110809326
Validation loss: 2.6691704129660003

Epoch: 6| Step: 12
Training loss: 2.6115493774414062
Validation loss: 2.6694301533442673

Epoch: 6| Step: 13
Training loss: 3.328146457672119
Validation loss: 2.666002368414274

Epoch: 39| Step: 0
Training loss: 3.0989837646484375
Validation loss: 2.6671124171185236

Epoch: 6| Step: 1
Training loss: 2.1014323234558105
Validation loss: 2.6650810190426406

Epoch: 6| Step: 2
Training loss: 3.8329272270202637
Validation loss: 2.663964330509145

Epoch: 6| Step: 3
Training loss: 3.2934021949768066
Validation loss: 2.6660056421833653

Epoch: 6| Step: 4
Training loss: 3.2066211700439453
Validation loss: 2.6662303478487077

Epoch: 6| Step: 5
Training loss: 2.3761749267578125
Validation loss: 2.674776928399199

Epoch: 6| Step: 6
Training loss: 3.4353089332580566
Validation loss: 2.681277403267481

Epoch: 6| Step: 7
Training loss: 2.996863603591919
Validation loss: 2.6849799745826313

Epoch: 6| Step: 8
Training loss: 2.5721731185913086
Validation loss: 2.684254910356255

Epoch: 6| Step: 9
Training loss: 2.6591176986694336
Validation loss: 2.6872664907927155

Epoch: 6| Step: 10
Training loss: 2.2270095348358154
Validation loss: 2.6939105321002264

Epoch: 6| Step: 11
Training loss: 2.3892486095428467
Validation loss: 2.6762983927162747

Epoch: 6| Step: 12
Training loss: 2.6817378997802734
Validation loss: 2.664183957602388

Epoch: 6| Step: 13
Training loss: 3.194387197494507
Validation loss: 2.6715187026608374

Epoch: 40| Step: 0
Training loss: 2.5621936321258545
Validation loss: 2.681344393760927

Epoch: 6| Step: 1
Training loss: 3.5266036987304688
Validation loss: 2.6959605755344516

Epoch: 6| Step: 2
Training loss: 2.006150722503662
Validation loss: 2.725627617169452

Epoch: 6| Step: 3
Training loss: 2.5029683113098145
Validation loss: 2.681529055359543

Epoch: 6| Step: 4
Training loss: 2.632302761077881
Validation loss: 2.6682125086425454

Epoch: 6| Step: 5
Training loss: 2.5229949951171875
Validation loss: 2.6659654237890757

Epoch: 6| Step: 6
Training loss: 3.2710957527160645
Validation loss: 2.659743062911495

Epoch: 6| Step: 7
Training loss: 2.983952522277832
Validation loss: 2.661211782886136

Epoch: 6| Step: 8
Training loss: 3.574817419052124
Validation loss: 2.666036016197615

Epoch: 6| Step: 9
Training loss: 2.264326810836792
Validation loss: 2.66467978877406

Epoch: 6| Step: 10
Training loss: 2.726231098175049
Validation loss: 2.670420872267856

Epoch: 6| Step: 11
Training loss: 3.3335728645324707
Validation loss: 2.6792472947028374

Epoch: 6| Step: 12
Training loss: 3.0757546424865723
Validation loss: 2.687298269682033

Epoch: 6| Step: 13
Training loss: 2.6940362453460693
Validation loss: 2.687276904300977

Epoch: 41| Step: 0
Training loss: 2.0122289657592773
Validation loss: 2.6851948820134646

Epoch: 6| Step: 1
Training loss: 1.901355504989624
Validation loss: 2.6826070124103176

Epoch: 6| Step: 2
Training loss: 3.4031639099121094
Validation loss: 2.696953852971395

Epoch: 6| Step: 3
Training loss: 3.6763224601745605
Validation loss: 2.684869791871758

Epoch: 6| Step: 4
Training loss: 3.3366281986236572
Validation loss: 2.7008946839199273

Epoch: 6| Step: 5
Training loss: 3.3410768508911133
Validation loss: 2.6733670029588925

Epoch: 6| Step: 6
Training loss: 2.674647808074951
Validation loss: 2.656757257317984

Epoch: 6| Step: 7
Training loss: 2.804785966873169
Validation loss: 2.660795270755727

Epoch: 6| Step: 8
Training loss: 2.6059253215789795
Validation loss: 2.6688996899512505

Epoch: 6| Step: 9
Training loss: 2.3122899532318115
Validation loss: 2.6695452120996292

Epoch: 6| Step: 10
Training loss: 3.4269561767578125
Validation loss: 2.6740867143036215

Epoch: 6| Step: 11
Training loss: 3.2554216384887695
Validation loss: 2.6713238428997736

Epoch: 6| Step: 12
Training loss: 1.926802158355713
Validation loss: 2.6686119315444783

Epoch: 6| Step: 13
Training loss: 3.312983512878418
Validation loss: 2.6647250729222454

Epoch: 42| Step: 0
Training loss: 3.2656307220458984
Validation loss: 2.6704164294786352

Epoch: 6| Step: 1
Training loss: 3.2939562797546387
Validation loss: 2.654650695862309

Epoch: 6| Step: 2
Training loss: 2.358851432800293
Validation loss: 2.6532723980565227

Epoch: 6| Step: 3
Training loss: 2.6183254718780518
Validation loss: 2.661663996276035

Epoch: 6| Step: 4
Training loss: 2.687962055206299
Validation loss: 2.697230403141309

Epoch: 6| Step: 5
Training loss: 3.0238900184631348
Validation loss: 2.7366321932884956

Epoch: 6| Step: 6
Training loss: 2.778897523880005
Validation loss: 2.71247532034433

Epoch: 6| Step: 7
Training loss: 2.819506883621216
Validation loss: 2.67816985038019

Epoch: 6| Step: 8
Training loss: 3.014913320541382
Validation loss: 2.67952827484377

Epoch: 6| Step: 9
Training loss: 2.4018759727478027
Validation loss: 2.693335258832542

Epoch: 6| Step: 10
Training loss: 2.2558326721191406
Validation loss: 2.666882740553989

Epoch: 6| Step: 11
Training loss: 2.5837795734405518
Validation loss: 2.6575638606984127

Epoch: 6| Step: 12
Training loss: 3.626730442047119
Validation loss: 2.654050491189444

Epoch: 6| Step: 13
Training loss: 3.4463305473327637
Validation loss: 2.6500216684033795

Epoch: 43| Step: 0
Training loss: 2.94655704498291
Validation loss: 2.653419704847438

Epoch: 6| Step: 1
Training loss: 2.3010365962982178
Validation loss: 2.6488635514372136

Epoch: 6| Step: 2
Training loss: 2.5956597328186035
Validation loss: 2.6549068509891467

Epoch: 6| Step: 3
Training loss: 3.1251957416534424
Validation loss: 2.6562584241231284

Epoch: 6| Step: 4
Training loss: 1.9537811279296875
Validation loss: 2.656059426646079

Epoch: 6| Step: 5
Training loss: 3.3278164863586426
Validation loss: 2.6545901965069514

Epoch: 6| Step: 6
Training loss: 2.181549072265625
Validation loss: 2.6541688032047723

Epoch: 6| Step: 7
Training loss: 3.0240895748138428
Validation loss: 2.680537223815918

Epoch: 6| Step: 8
Training loss: 3.0617876052856445
Validation loss: 2.7729989610692507

Epoch: 6| Step: 9
Training loss: 3.1075403690338135
Validation loss: 2.7599862211494037

Epoch: 6| Step: 10
Training loss: 2.9244086742401123
Validation loss: 2.7089929375597226

Epoch: 6| Step: 11
Training loss: 3.5166900157928467
Validation loss: 2.665414120561333

Epoch: 6| Step: 12
Training loss: 3.0866541862487793
Validation loss: 2.6616069885992233

Epoch: 6| Step: 13
Training loss: 2.671886920928955
Validation loss: 2.67066454374662

Epoch: 44| Step: 0
Training loss: 3.0948643684387207
Validation loss: 2.6828659452417845

Epoch: 6| Step: 1
Training loss: 2.636533260345459
Validation loss: 2.6758749305561023

Epoch: 6| Step: 2
Training loss: 2.4835026264190674
Validation loss: 2.688413796886321

Epoch: 6| Step: 3
Training loss: 3.81396222114563
Validation loss: 2.700163302883025

Epoch: 6| Step: 4
Training loss: 2.495997428894043
Validation loss: 2.7052721567051385

Epoch: 6| Step: 5
Training loss: 3.443185329437256
Validation loss: 2.6933443751386417

Epoch: 6| Step: 6
Training loss: 2.805294990539551
Validation loss: 2.6815003592480897

Epoch: 6| Step: 7
Training loss: 3.0974113941192627
Validation loss: 2.6701108563330864

Epoch: 6| Step: 8
Training loss: 2.1315879821777344
Validation loss: 2.6647964651866625

Epoch: 6| Step: 9
Training loss: 2.797417640686035
Validation loss: 2.6638005959090365

Epoch: 6| Step: 10
Training loss: 2.5167617797851562
Validation loss: 2.659535636184036

Epoch: 6| Step: 11
Training loss: 3.515911102294922
Validation loss: 2.6531415344566427

Epoch: 6| Step: 12
Training loss: 1.6653265953063965
Validation loss: 2.6546005689969627

Epoch: 6| Step: 13
Training loss: 3.7398571968078613
Validation loss: 2.6524625388524865

Epoch: 45| Step: 0
Training loss: 3.339634895324707
Validation loss: 2.6482871655494935

Epoch: 6| Step: 1
Training loss: 2.5610756874084473
Validation loss: 2.6435895530126428

Epoch: 6| Step: 2
Training loss: 2.636547803878784
Validation loss: 2.6459501199824835

Epoch: 6| Step: 3
Training loss: 3.041691303253174
Validation loss: 2.6471530698960826

Epoch: 6| Step: 4
Training loss: 3.160637140274048
Validation loss: 2.6453096174424693

Epoch: 6| Step: 5
Training loss: 2.71309757232666
Validation loss: 2.647548565300562

Epoch: 6| Step: 6
Training loss: 2.6217923164367676
Validation loss: 2.6396728843771

Epoch: 6| Step: 7
Training loss: 2.606541395187378
Validation loss: 2.641965845579742

Epoch: 6| Step: 8
Training loss: 2.430493116378784
Validation loss: 2.6376662779879827

Epoch: 6| Step: 9
Training loss: 2.4070138931274414
Validation loss: 2.643034917052074

Epoch: 6| Step: 10
Training loss: 2.966479778289795
Validation loss: 2.646512762192757

Epoch: 6| Step: 11
Training loss: 2.3743715286254883
Validation loss: 2.642645110366165

Epoch: 6| Step: 12
Training loss: 3.7314558029174805
Validation loss: 2.6342535172739336

Epoch: 6| Step: 13
Training loss: 2.996830463409424
Validation loss: 2.6327268462027273

Epoch: 46| Step: 0
Training loss: 2.634922981262207
Validation loss: 2.6331157120325233

Epoch: 6| Step: 1
Training loss: 1.6983671188354492
Validation loss: 2.6289268949980378

Epoch: 6| Step: 2
Training loss: 2.577852725982666
Validation loss: 2.629706031532698

Epoch: 6| Step: 3
Training loss: 3.2265214920043945
Validation loss: 2.631082965481666

Epoch: 6| Step: 4
Training loss: 2.294482469558716
Validation loss: 2.6279947988448606

Epoch: 6| Step: 5
Training loss: 2.454629898071289
Validation loss: 2.628438480438725

Epoch: 6| Step: 6
Training loss: 4.012608051300049
Validation loss: 2.62886712115298

Epoch: 6| Step: 7
Training loss: 3.1794309616088867
Validation loss: 2.636368441325362

Epoch: 6| Step: 8
Training loss: 3.0512337684631348
Validation loss: 2.6392019102650304

Epoch: 6| Step: 9
Training loss: 3.3673737049102783
Validation loss: 2.632786748229816

Epoch: 6| Step: 10
Training loss: 3.0895304679870605
Validation loss: 2.6230745213006132

Epoch: 6| Step: 11
Training loss: 3.1726021766662598
Validation loss: 2.623302031588811

Epoch: 6| Step: 12
Training loss: 1.9500086307525635
Validation loss: 2.6312758896940496

Epoch: 6| Step: 13
Training loss: 2.482558250427246
Validation loss: 2.636194631617556

Epoch: 47| Step: 0
Training loss: 3.0142455101013184
Validation loss: 2.637009031029158

Epoch: 6| Step: 1
Training loss: 3.3031840324401855
Validation loss: 2.6381879006662676

Epoch: 6| Step: 2
Training loss: 3.3604652881622314
Validation loss: 2.633576977637506

Epoch: 6| Step: 3
Training loss: 2.812808036804199
Validation loss: 2.633295983396551

Epoch: 6| Step: 4
Training loss: 2.571098566055298
Validation loss: 2.632085671988867

Epoch: 6| Step: 5
Training loss: 3.3472707271575928
Validation loss: 2.6279291286263415

Epoch: 6| Step: 6
Training loss: 2.869117021560669
Validation loss: 2.6296636494257117

Epoch: 6| Step: 7
Training loss: 1.8235256671905518
Validation loss: 2.6274506507381314

Epoch: 6| Step: 8
Training loss: 2.9095516204833984
Validation loss: 2.623242670489896

Epoch: 6| Step: 9
Training loss: 2.1572647094726562
Validation loss: 2.629061875804778

Epoch: 6| Step: 10
Training loss: 3.1055853366851807
Validation loss: 2.6298041394961778

Epoch: 6| Step: 11
Training loss: 2.508317470550537
Validation loss: 2.623734010163174

Epoch: 6| Step: 12
Training loss: 2.3753724098205566
Validation loss: 2.6202828525215067

Epoch: 6| Step: 13
Training loss: 3.303436279296875
Validation loss: 2.623318397870628

Epoch: 48| Step: 0
Training loss: 4.065181255340576
Validation loss: 2.6214989410933627

Epoch: 6| Step: 1
Training loss: 2.6670119762420654
Validation loss: 2.6176355551647883

Epoch: 6| Step: 2
Training loss: 3.098430633544922
Validation loss: 2.6203289647256174

Epoch: 6| Step: 3
Training loss: 2.5348634719848633
Validation loss: 2.6158273220062256

Epoch: 6| Step: 4
Training loss: 3.083878993988037
Validation loss: 2.6112432864404496

Epoch: 6| Step: 5
Training loss: 3.1245267391204834
Validation loss: 2.613756020863851

Epoch: 6| Step: 6
Training loss: 2.7734017372131348
Validation loss: 2.61159695348432

Epoch: 6| Step: 7
Training loss: 2.521904706954956
Validation loss: 2.6118327417681293

Epoch: 6| Step: 8
Training loss: 2.4631576538085938
Validation loss: 2.6142857202919583

Epoch: 6| Step: 9
Training loss: 2.442227602005005
Validation loss: 2.618377629146781

Epoch: 6| Step: 10
Training loss: 2.470384120941162
Validation loss: 2.624024009191862

Epoch: 6| Step: 11
Training loss: 2.286466598510742
Validation loss: 2.627194942966584

Epoch: 6| Step: 12
Training loss: 2.6672472953796387
Validation loss: 2.627185893315141

Epoch: 6| Step: 13
Training loss: 3.0011191368103027
Validation loss: 2.621920052395072

Epoch: 49| Step: 0
Training loss: 3.224159002304077
Validation loss: 2.619163067110123

Epoch: 6| Step: 1
Training loss: 2.1950016021728516
Validation loss: 2.617340364763814

Epoch: 6| Step: 2
Training loss: 2.6097183227539062
Validation loss: 2.622676344328029

Epoch: 6| Step: 3
Training loss: 2.3908779621124268
Validation loss: 2.6226193366512174

Epoch: 6| Step: 4
Training loss: 2.433441638946533
Validation loss: 2.63112219431067

Epoch: 6| Step: 5
Training loss: 2.6682331562042236
Validation loss: 2.6324829619417907

Epoch: 6| Step: 6
Training loss: 2.1799750328063965
Validation loss: 2.6226257021709154

Epoch: 6| Step: 7
Training loss: 3.3533294200897217
Validation loss: 2.609436822193925

Epoch: 6| Step: 8
Training loss: 3.6941442489624023
Validation loss: 2.6053246272507535

Epoch: 6| Step: 9
Training loss: 3.2895963191986084
Validation loss: 2.610115340960923

Epoch: 6| Step: 10
Training loss: 2.540367603302002
Validation loss: 2.6100082141096874

Epoch: 6| Step: 11
Training loss: 3.1471691131591797
Validation loss: 2.6207322535976285

Epoch: 6| Step: 12
Training loss: 3.0712625980377197
Validation loss: 2.6226651463457333

Epoch: 6| Step: 13
Training loss: 2.039771556854248
Validation loss: 2.6219517569388113

Epoch: 50| Step: 0
Training loss: 2.798267364501953
Validation loss: 2.6229234357034006

Epoch: 6| Step: 1
Training loss: 2.7740988731384277
Validation loss: 2.6110931545175533

Epoch: 6| Step: 2
Training loss: 3.0945348739624023
Validation loss: 2.6067964389760006

Epoch: 6| Step: 3
Training loss: 2.127843141555786
Validation loss: 2.604537381920763

Epoch: 6| Step: 4
Training loss: 3.0735924243927
Validation loss: 2.605532459033433

Epoch: 6| Step: 5
Training loss: 3.190978765487671
Validation loss: 2.6043475135680167

Epoch: 6| Step: 6
Training loss: 2.789642333984375
Validation loss: 2.607308982520975

Epoch: 6| Step: 7
Training loss: 1.9800692796707153
Validation loss: 2.604222079759003

Epoch: 6| Step: 8
Training loss: 3.189007520675659
Validation loss: 2.599226538852979

Epoch: 6| Step: 9
Training loss: 2.858640670776367
Validation loss: 2.6008487260469826

Epoch: 6| Step: 10
Training loss: 2.4401016235351562
Validation loss: 2.6045937999602287

Epoch: 6| Step: 11
Training loss: 2.669045925140381
Validation loss: 2.6044638490164154

Epoch: 6| Step: 12
Training loss: 3.0805130004882812
Validation loss: 2.5994598186144264

Epoch: 6| Step: 13
Training loss: 3.0624284744262695
Validation loss: 2.6050988653654694

Epoch: 51| Step: 0
Training loss: 1.7673165798187256
Validation loss: 2.607020103803245

Epoch: 6| Step: 1
Training loss: 2.588408946990967
Validation loss: 2.6065303151325514

Epoch: 6| Step: 2
Training loss: 2.8148083686828613
Validation loss: 2.603198702617358

Epoch: 6| Step: 3
Training loss: 2.447317600250244
Validation loss: 2.5973751596225205

Epoch: 6| Step: 4
Training loss: 3.065486192703247
Validation loss: 2.5948860158202467

Epoch: 6| Step: 5
Training loss: 3.28745174407959
Validation loss: 2.594277940770631

Epoch: 6| Step: 6
Training loss: 2.6679563522338867
Validation loss: 2.5951358349092546

Epoch: 6| Step: 7
Training loss: 3.8660945892333984
Validation loss: 2.5951881152327343

Epoch: 6| Step: 8
Training loss: 2.0972487926483154
Validation loss: 2.604061201054563

Epoch: 6| Step: 9
Training loss: 3.1734819412231445
Validation loss: 2.6036671938434726

Epoch: 6| Step: 10
Training loss: 2.7917768955230713
Validation loss: 2.614950164671867

Epoch: 6| Step: 11
Training loss: 2.3926773071289062
Validation loss: 2.628407892360482

Epoch: 6| Step: 12
Training loss: 2.7878408432006836
Validation loss: 2.671727067680769

Epoch: 6| Step: 13
Training loss: 3.758908271789551
Validation loss: 2.660715418477212

Epoch: 52| Step: 0
Training loss: 1.9538264274597168
Validation loss: 2.6336946846336446

Epoch: 6| Step: 1
Training loss: 3.175548553466797
Validation loss: 2.6147416740335445

Epoch: 6| Step: 2
Training loss: 2.480769157409668
Validation loss: 2.5924699409033662

Epoch: 6| Step: 3
Training loss: 3.380103588104248
Validation loss: 2.589308654108355

Epoch: 6| Step: 4
Training loss: 2.748953104019165
Validation loss: 2.595531981478455

Epoch: 6| Step: 5
Training loss: 2.68302059173584
Validation loss: 2.5962384080374115

Epoch: 6| Step: 6
Training loss: 2.7576775550842285
Validation loss: 2.6017515659332275

Epoch: 6| Step: 7
Training loss: 2.0915627479553223
Validation loss: 2.597418536422073

Epoch: 6| Step: 8
Training loss: 3.0532450675964355
Validation loss: 2.5975133219072895

Epoch: 6| Step: 9
Training loss: 3.05842661857605
Validation loss: 2.587352911631266

Epoch: 6| Step: 10
Training loss: 2.864654064178467
Validation loss: 2.593212304576751

Epoch: 6| Step: 11
Training loss: 3.152696132659912
Validation loss: 2.591165247783866

Epoch: 6| Step: 12
Training loss: 2.8723549842834473
Validation loss: 2.588446201816682

Epoch: 6| Step: 13
Training loss: 2.6279373168945312
Validation loss: 2.59142808247638

Epoch: 53| Step: 0
Training loss: 3.5218887329101562
Validation loss: 2.596005365412722

Epoch: 6| Step: 1
Training loss: 2.8543100357055664
Validation loss: 2.5957483373662478

Epoch: 6| Step: 2
Training loss: 2.607118606567383
Validation loss: 2.614253087710309

Epoch: 6| Step: 3
Training loss: 3.036456346511841
Validation loss: 2.6165519247772875

Epoch: 6| Step: 4
Training loss: 3.163316249847412
Validation loss: 2.6246026331378567

Epoch: 6| Step: 5
Training loss: 3.1540708541870117
Validation loss: 2.619942670227379

Epoch: 6| Step: 6
Training loss: 2.49295711517334
Validation loss: 2.622972765276509

Epoch: 6| Step: 7
Training loss: 2.141383647918701
Validation loss: 2.6112056291231545

Epoch: 6| Step: 8
Training loss: 3.0771305561065674
Validation loss: 2.6147858968345066

Epoch: 6| Step: 9
Training loss: 2.435542583465576
Validation loss: 2.6118027061544438

Epoch: 6| Step: 10
Training loss: 2.945570468902588
Validation loss: 2.58915114402771

Epoch: 6| Step: 11
Training loss: 2.412355422973633
Validation loss: 2.576248909837456

Epoch: 6| Step: 12
Training loss: 3.1199216842651367
Validation loss: 2.573897877047139

Epoch: 6| Step: 13
Training loss: 1.231289029121399
Validation loss: 2.577254338931012

Epoch: 54| Step: 0
Training loss: 2.696539878845215
Validation loss: 2.581617991129557

Epoch: 6| Step: 1
Training loss: 3.3414244651794434
Validation loss: 2.583437660688995

Epoch: 6| Step: 2
Training loss: 2.709141254425049
Validation loss: 2.5871068969849618

Epoch: 6| Step: 3
Training loss: 2.48233699798584
Validation loss: 2.58469513411163

Epoch: 6| Step: 4
Training loss: 2.535362482070923
Validation loss: 2.5802534062375306

Epoch: 6| Step: 5
Training loss: 2.6871795654296875
Validation loss: 2.571916123872162

Epoch: 6| Step: 6
Training loss: 2.6763858795166016
Validation loss: 2.572151353282313

Epoch: 6| Step: 7
Training loss: 3.222637414932251
Validation loss: 2.577887947841357

Epoch: 6| Step: 8
Training loss: 2.269437313079834
Validation loss: 2.5867714112804783

Epoch: 6| Step: 9
Training loss: 3.1610779762268066
Validation loss: 2.5963466654541674

Epoch: 6| Step: 10
Training loss: 2.331012010574341
Validation loss: 2.601627967690909

Epoch: 6| Step: 11
Training loss: 2.827028751373291
Validation loss: 2.6107497138361775

Epoch: 6| Step: 12
Training loss: 3.253190279006958
Validation loss: 2.611458945017989

Epoch: 6| Step: 13
Training loss: 2.53157377243042
Validation loss: 2.6067297227921022

Epoch: 55| Step: 0
Training loss: 3.5141265392303467
Validation loss: 2.584728930586128

Epoch: 6| Step: 1
Training loss: 2.187324285507202
Validation loss: 2.573112310901765

Epoch: 6| Step: 2
Training loss: 2.578447103500366
Validation loss: 2.571891197594263

Epoch: 6| Step: 3
Training loss: 2.9952640533447266
Validation loss: 2.5751576731281896

Epoch: 6| Step: 4
Training loss: 3.5626962184906006
Validation loss: 2.5840468586132093

Epoch: 6| Step: 5
Training loss: 3.5614309310913086
Validation loss: 2.587856033796905

Epoch: 6| Step: 6
Training loss: 3.026923894882202
Validation loss: 2.583094517389933

Epoch: 6| Step: 7
Training loss: 2.786783218383789
Validation loss: 2.590812370341311

Epoch: 6| Step: 8
Training loss: 3.0741207599639893
Validation loss: 2.593578550123399

Epoch: 6| Step: 9
Training loss: 2.398001194000244
Validation loss: 2.5860804357836322

Epoch: 6| Step: 10
Training loss: 2.5296196937561035
Validation loss: 2.590981824423677

Epoch: 6| Step: 11
Training loss: 2.2207436561584473
Validation loss: 2.589921923093898

Epoch: 6| Step: 12
Training loss: 2.0417673587799072
Validation loss: 2.5756421319900022

Epoch: 6| Step: 13
Training loss: 1.953925609588623
Validation loss: 2.5689599257643505

Epoch: 56| Step: 0
Training loss: 3.523447036743164
Validation loss: 2.5732211195012575

Epoch: 6| Step: 1
Training loss: 2.800640344619751
Validation loss: 2.5738791778523433

Epoch: 6| Step: 2
Training loss: 2.836557626724243
Validation loss: 2.5819909700783352

Epoch: 6| Step: 3
Training loss: 3.048834800720215
Validation loss: 2.585199368897305

Epoch: 6| Step: 4
Training loss: 3.0273866653442383
Validation loss: 2.578017319402387

Epoch: 6| Step: 5
Training loss: 2.413609504699707
Validation loss: 2.5840641631874988

Epoch: 6| Step: 6
Training loss: 2.876047372817993
Validation loss: 2.590771416182159

Epoch: 6| Step: 7
Training loss: 2.6051440238952637
Validation loss: 2.5949210248967653

Epoch: 6| Step: 8
Training loss: 2.8316595554351807
Validation loss: 2.590590907681373

Epoch: 6| Step: 9
Training loss: 2.6413655281066895
Validation loss: 2.5833968142027497

Epoch: 6| Step: 10
Training loss: 2.967568874359131
Validation loss: 2.5772940087062057

Epoch: 6| Step: 11
Training loss: 2.289219617843628
Validation loss: 2.5732379267292638

Epoch: 6| Step: 12
Training loss: 2.061861515045166
Validation loss: 2.5773396543277207

Epoch: 6| Step: 13
Training loss: 2.563817262649536
Validation loss: 2.5792854498791438

Epoch: 57| Step: 0
Training loss: 3.7035484313964844
Validation loss: 2.576726480196881

Epoch: 6| Step: 1
Training loss: 2.245540142059326
Validation loss: 2.5772624656718266

Epoch: 6| Step: 2
Training loss: 3.808176040649414
Validation loss: 2.5789105892181396

Epoch: 6| Step: 3
Training loss: 2.2757019996643066
Validation loss: 2.573442635997649

Epoch: 6| Step: 4
Training loss: 2.490353584289551
Validation loss: 2.5742208265489146

Epoch: 6| Step: 5
Training loss: 2.7751786708831787
Validation loss: 2.580619663320562

Epoch: 6| Step: 6
Training loss: 2.2031702995300293
Validation loss: 2.5849259361144035

Epoch: 6| Step: 7
Training loss: 1.9679243564605713
Validation loss: 2.5763813910945768

Epoch: 6| Step: 8
Training loss: 2.806309223175049
Validation loss: 2.577708710906326

Epoch: 6| Step: 9
Training loss: 2.7041358947753906
Validation loss: 2.578694789640365

Epoch: 6| Step: 10
Training loss: 2.7490930557250977
Validation loss: 2.5696290205883723

Epoch: 6| Step: 11
Training loss: 2.962033271789551
Validation loss: 2.5656023051149104

Epoch: 6| Step: 12
Training loss: 3.347456693649292
Validation loss: 2.5611103401389173

Epoch: 6| Step: 13
Training loss: 2.244157075881958
Validation loss: 2.5576537091244935

Epoch: 58| Step: 0
Training loss: 2.2385287284851074
Validation loss: 2.5621002310065815

Epoch: 6| Step: 1
Training loss: 2.833305835723877
Validation loss: 2.5614143802273657

Epoch: 6| Step: 2
Training loss: 2.572693347930908
Validation loss: 2.5559245950432232

Epoch: 6| Step: 3
Training loss: 3.3333511352539062
Validation loss: 2.56184474883541

Epoch: 6| Step: 4
Training loss: 3.0773277282714844
Validation loss: 2.566081654640936

Epoch: 6| Step: 5
Training loss: 2.6918704509735107
Validation loss: 2.5739929137691373

Epoch: 6| Step: 6
Training loss: 2.7092080116271973
Validation loss: 2.587177171502062

Epoch: 6| Step: 7
Training loss: 2.5766777992248535
Validation loss: 2.5981436006484495

Epoch: 6| Step: 8
Training loss: 2.936378002166748
Validation loss: 2.5836986162329234

Epoch: 6| Step: 9
Training loss: 2.862741231918335
Validation loss: 2.5700939163084953

Epoch: 6| Step: 10
Training loss: 2.6706714630126953
Validation loss: 2.563957352792063

Epoch: 6| Step: 11
Training loss: 2.443358898162842
Validation loss: 2.5571907989440428

Epoch: 6| Step: 12
Training loss: 3.2375593185424805
Validation loss: 2.5551261594218593

Epoch: 6| Step: 13
Training loss: 1.9668971300125122
Validation loss: 2.5554147202481508

Epoch: 59| Step: 0
Training loss: 2.566434144973755
Validation loss: 2.5630493548608597

Epoch: 6| Step: 1
Training loss: 2.7094452381134033
Validation loss: 2.5763368427112536

Epoch: 6| Step: 2
Training loss: 2.8154523372650146
Validation loss: 2.578123600252213

Epoch: 6| Step: 3
Training loss: 2.4693169593811035
Validation loss: 2.5807049812809115

Epoch: 6| Step: 4
Training loss: 2.8986635208129883
Validation loss: 2.5862327826920377

Epoch: 6| Step: 5
Training loss: 3.2613816261291504
Validation loss: 2.5831874339811263

Epoch: 6| Step: 6
Training loss: 2.658848285675049
Validation loss: 2.580397205968057

Epoch: 6| Step: 7
Training loss: 3.056230068206787
Validation loss: 2.576125849959671

Epoch: 6| Step: 8
Training loss: 3.0131874084472656
Validation loss: 2.5741994611678587

Epoch: 6| Step: 9
Training loss: 2.867584466934204
Validation loss: 2.573845189104798

Epoch: 6| Step: 10
Training loss: 2.71968674659729
Validation loss: 2.5647529325177594

Epoch: 6| Step: 11
Training loss: 2.7738304138183594
Validation loss: 2.562380261318658

Epoch: 6| Step: 12
Training loss: 2.3004379272460938
Validation loss: 2.5530638182035057

Epoch: 6| Step: 13
Training loss: 1.9113211631774902
Validation loss: 2.5525925774728098

Epoch: 60| Step: 0
Training loss: 3.1202571392059326
Validation loss: 2.552723878173418

Epoch: 6| Step: 1
Training loss: 2.8507187366485596
Validation loss: 2.547668246812718

Epoch: 6| Step: 2
Training loss: 2.471041440963745
Validation loss: 2.548193662397323

Epoch: 6| Step: 3
Training loss: 1.9029093980789185
Validation loss: 2.5437400084669872

Epoch: 6| Step: 4
Training loss: 2.999746799468994
Validation loss: 2.5467420111420336

Epoch: 6| Step: 5
Training loss: 2.304810047149658
Validation loss: 2.5486759806192048

Epoch: 6| Step: 6
Training loss: 2.56929874420166
Validation loss: 2.5470814858713458

Epoch: 6| Step: 7
Training loss: 2.777648448944092
Validation loss: 2.5460657868334042

Epoch: 6| Step: 8
Training loss: 2.639709711074829
Validation loss: 2.550444310711276

Epoch: 6| Step: 9
Training loss: 2.455059766769409
Validation loss: 2.5548227038434757

Epoch: 6| Step: 10
Training loss: 3.255340814590454
Validation loss: 2.5660625632091234

Epoch: 6| Step: 11
Training loss: 2.9009523391723633
Validation loss: 2.558340408468759

Epoch: 6| Step: 12
Training loss: 3.1146116256713867
Validation loss: 2.557823322152579

Epoch: 6| Step: 13
Training loss: 3.2696549892425537
Validation loss: 2.559043279258154

Epoch: 61| Step: 0
Training loss: 2.619333028793335
Validation loss: 2.5531427552623134

Epoch: 6| Step: 1
Training loss: 2.5044918060302734
Validation loss: 2.5484894116719565

Epoch: 6| Step: 2
Training loss: 3.048349618911743
Validation loss: 2.5458617774389123

Epoch: 6| Step: 3
Training loss: 2.9832913875579834
Validation loss: 2.544103548090945

Epoch: 6| Step: 4
Training loss: 2.4046497344970703
Validation loss: 2.5418205363776094

Epoch: 6| Step: 5
Training loss: 2.59462571144104
Validation loss: 2.5436783400915

Epoch: 6| Step: 6
Training loss: 3.163062572479248
Validation loss: 2.5416180113310456

Epoch: 6| Step: 7
Training loss: 3.1841745376586914
Validation loss: 2.5403799779953493

Epoch: 6| Step: 8
Training loss: 2.678530693054199
Validation loss: 2.5389789740244546

Epoch: 6| Step: 9
Training loss: 3.0198450088500977
Validation loss: 2.5507064711663032

Epoch: 6| Step: 10
Training loss: 2.2668354511260986
Validation loss: 2.5630081494649253

Epoch: 6| Step: 11
Training loss: 2.639008045196533
Validation loss: 2.574381072034118

Epoch: 6| Step: 12
Training loss: 2.5857605934143066
Validation loss: 2.5917031047164754

Epoch: 6| Step: 13
Training loss: 2.4513063430786133
Validation loss: 2.5763551881236415

Epoch: 62| Step: 0
Training loss: 2.6017770767211914
Validation loss: 2.588788899042273

Epoch: 6| Step: 1
Training loss: 2.0586767196655273
Validation loss: 2.611992753962035

Epoch: 6| Step: 2
Training loss: 2.2632217407226562
Validation loss: 2.607623343826622

Epoch: 6| Step: 3
Training loss: 2.570662498474121
Validation loss: 2.6036456400348293

Epoch: 6| Step: 4
Training loss: 2.9097042083740234
Validation loss: 2.603920531529252

Epoch: 6| Step: 5
Training loss: 2.7439370155334473
Validation loss: 2.6044851810701433

Epoch: 6| Step: 6
Training loss: 2.2218668460845947
Validation loss: 2.604283853243756

Epoch: 6| Step: 7
Training loss: 2.7304434776306152
Validation loss: 2.604482986593759

Epoch: 6| Step: 8
Training loss: 3.69515323638916
Validation loss: 2.599607693251743

Epoch: 6| Step: 9
Training loss: 3.462665319442749
Validation loss: 2.5979672862637426

Epoch: 6| Step: 10
Training loss: 2.7197303771972656
Validation loss: 2.595859255841983

Epoch: 6| Step: 11
Training loss: 2.7505550384521484
Validation loss: 2.5991641142035045

Epoch: 6| Step: 12
Training loss: 3.5938544273376465
Validation loss: 2.5985252754662627

Epoch: 6| Step: 13
Training loss: 2.2784781455993652
Validation loss: 2.603125697822981

Epoch: 63| Step: 0
Training loss: 3.3207802772521973
Validation loss: 2.6051376609392065

Epoch: 6| Step: 1
Training loss: 2.3399767875671387
Validation loss: 2.607954325214509

Epoch: 6| Step: 2
Training loss: 2.112455368041992
Validation loss: 2.6139722126786427

Epoch: 6| Step: 3
Training loss: 2.9631214141845703
Validation loss: 2.6189920056250786

Epoch: 6| Step: 4
Training loss: 2.9910058975219727
Validation loss: 2.6173492400876937

Epoch: 6| Step: 5
Training loss: 3.047532558441162
Validation loss: 2.6201254680592525

Epoch: 6| Step: 6
Training loss: 2.369680166244507
Validation loss: 2.631331202804401

Epoch: 6| Step: 7
Training loss: 2.268796443939209
Validation loss: 2.6295746910956597

Epoch: 6| Step: 8
Training loss: 2.355574131011963
Validation loss: 2.6092295979940765

Epoch: 6| Step: 9
Training loss: 2.673764705657959
Validation loss: 2.611701252639935

Epoch: 6| Step: 10
Training loss: 2.30185604095459
Validation loss: 2.613878932050479

Epoch: 6| Step: 11
Training loss: 3.0274720191955566
Validation loss: 2.602753685366723

Epoch: 6| Step: 12
Training loss: 3.223728656768799
Validation loss: 2.599923933705976

Epoch: 6| Step: 13
Training loss: 4.526987552642822
Validation loss: 2.5781677076893468

Epoch: 64| Step: 0
Training loss: 2.654062509536743
Validation loss: 2.566431153205133

Epoch: 6| Step: 1
Training loss: 2.6196937561035156
Validation loss: 2.5619991210199173

Epoch: 6| Step: 2
Training loss: 3.474874258041382
Validation loss: 2.551242318204654

Epoch: 6| Step: 3
Training loss: 2.653057098388672
Validation loss: 2.542179779339862

Epoch: 6| Step: 4
Training loss: 2.3088650703430176
Validation loss: 2.535073213679816

Epoch: 6| Step: 5
Training loss: 3.169121026992798
Validation loss: 2.5334938162116596

Epoch: 6| Step: 6
Training loss: 2.3520376682281494
Validation loss: 2.5329069424700994

Epoch: 6| Step: 7
Training loss: 3.393911600112915
Validation loss: 2.5300372544155327

Epoch: 6| Step: 8
Training loss: 2.4505510330200195
Validation loss: 2.528651257996918

Epoch: 6| Step: 9
Training loss: 2.5835070610046387
Validation loss: 2.5303451040739655

Epoch: 6| Step: 10
Training loss: 2.9904441833496094
Validation loss: 2.52802929570598

Epoch: 6| Step: 11
Training loss: 3.1148176193237305
Validation loss: 2.526051672556067

Epoch: 6| Step: 12
Training loss: 1.953106164932251
Validation loss: 2.536335386255736

Epoch: 6| Step: 13
Training loss: 2.3085367679595947
Validation loss: 2.5387638153568393

Epoch: 65| Step: 0
Training loss: 3.7615790367126465
Validation loss: 2.547032053752612

Epoch: 6| Step: 1
Training loss: 2.5600597858428955
Validation loss: 2.5432958731087307

Epoch: 6| Step: 2
Training loss: 2.175365447998047
Validation loss: 2.556542352963519

Epoch: 6| Step: 3
Training loss: 1.9186489582061768
Validation loss: 2.549003344710155

Epoch: 6| Step: 4
Training loss: 3.3498826026916504
Validation loss: 2.560054991834907

Epoch: 6| Step: 5
Training loss: 3.240140676498413
Validation loss: 2.546878663442468

Epoch: 6| Step: 6
Training loss: 2.653203248977661
Validation loss: 2.5438639271643853

Epoch: 6| Step: 7
Training loss: 3.197169780731201
Validation loss: 2.5422309649887906

Epoch: 6| Step: 8
Training loss: 2.7384159564971924
Validation loss: 2.5392174002944783

Epoch: 6| Step: 9
Training loss: 2.261385917663574
Validation loss: 2.5500205601415327

Epoch: 6| Step: 10
Training loss: 2.6248371601104736
Validation loss: 2.564933992201282

Epoch: 6| Step: 11
Training loss: 2.7487573623657227
Validation loss: 2.5795183591945197

Epoch: 6| Step: 12
Training loss: 2.9223504066467285
Validation loss: 2.584436144880069

Epoch: 6| Step: 13
Training loss: 1.7203354835510254
Validation loss: 2.5675125968071724

Epoch: 66| Step: 0
Training loss: 2.349801540374756
Validation loss: 2.5502767614139024

Epoch: 6| Step: 1
Training loss: 2.4081804752349854
Validation loss: 2.5383509512870543

Epoch: 6| Step: 2
Training loss: 2.414820909500122
Validation loss: 2.5228034937253563

Epoch: 6| Step: 3
Training loss: 2.889582872390747
Validation loss: 2.5166856742674306

Epoch: 6| Step: 4
Training loss: 2.931499481201172
Validation loss: 2.5179642784980034

Epoch: 6| Step: 5
Training loss: 2.699323892593384
Validation loss: 2.5192653440660044

Epoch: 6| Step: 6
Training loss: 2.3616437911987305
Validation loss: 2.524053568481117

Epoch: 6| Step: 7
Training loss: 2.6067678928375244
Validation loss: 2.5228781879589124

Epoch: 6| Step: 8
Training loss: 2.8657710552215576
Validation loss: 2.517232797479117

Epoch: 6| Step: 9
Training loss: 2.537069082260132
Validation loss: 2.515201045620826

Epoch: 6| Step: 10
Training loss: 2.602670907974243
Validation loss: 2.51492835885735

Epoch: 6| Step: 11
Training loss: 2.92732572555542
Validation loss: 2.514062496923631

Epoch: 6| Step: 12
Training loss: 3.55629825592041
Validation loss: 2.5130448674642913

Epoch: 6| Step: 13
Training loss: 3.1372408866882324
Validation loss: 2.516878627961682

Epoch: 67| Step: 0
Training loss: 2.6503639221191406
Validation loss: 2.5153573918086227

Epoch: 6| Step: 1
Training loss: 2.663367986679077
Validation loss: 2.5183959212354434

Epoch: 6| Step: 2
Training loss: 2.6588258743286133
Validation loss: 2.5227390309815765

Epoch: 6| Step: 3
Training loss: 1.8347253799438477
Validation loss: 2.5249413136513

Epoch: 6| Step: 4
Training loss: 3.003607749938965
Validation loss: 2.527422479403916

Epoch: 6| Step: 5
Training loss: 3.3465118408203125
Validation loss: 2.5220079075905586

Epoch: 6| Step: 6
Training loss: 2.6544029712677
Validation loss: 2.527791905146773

Epoch: 6| Step: 7
Training loss: 2.629164218902588
Validation loss: 2.528569065114503

Epoch: 6| Step: 8
Training loss: 3.0314512252807617
Validation loss: 2.525719783639395

Epoch: 6| Step: 9
Training loss: 3.332447052001953
Validation loss: 2.5211355686187744

Epoch: 6| Step: 10
Training loss: 3.530579090118408
Validation loss: 2.5157773481902255

Epoch: 6| Step: 11
Training loss: 1.5918524265289307
Validation loss: 2.515842185225538

Epoch: 6| Step: 12
Training loss: 2.4396982192993164
Validation loss: 2.509023920182259

Epoch: 6| Step: 13
Training loss: 2.617936372756958
Validation loss: 2.507220647668326

Epoch: 68| Step: 0
Training loss: 2.8720576763153076
Validation loss: 2.5056832554519817

Epoch: 6| Step: 1
Training loss: 2.0259289741516113
Validation loss: 2.506519474009032

Epoch: 6| Step: 2
Training loss: 2.1747119426727295
Validation loss: 2.506556533998059

Epoch: 6| Step: 3
Training loss: 3.013918876647949
Validation loss: 2.5061477281714

Epoch: 6| Step: 4
Training loss: 2.0635604858398438
Validation loss: 2.5081350572647585

Epoch: 6| Step: 5
Training loss: 2.5721874237060547
Validation loss: 2.5042828026638237

Epoch: 6| Step: 6
Training loss: 3.162604570388794
Validation loss: 2.5037252364620084

Epoch: 6| Step: 7
Training loss: 3.1719908714294434
Validation loss: 2.5036757325613372

Epoch: 6| Step: 8
Training loss: 2.8524365425109863
Validation loss: 2.5051449345004175

Epoch: 6| Step: 9
Training loss: 1.758400559425354
Validation loss: 2.5019181287416847

Epoch: 6| Step: 10
Training loss: 3.2087950706481934
Validation loss: 2.5053550120322936

Epoch: 6| Step: 11
Training loss: 3.177769184112549
Validation loss: 2.5020237481722267

Epoch: 6| Step: 12
Training loss: 3.1220855712890625
Validation loss: 2.5058683887604745

Epoch: 6| Step: 13
Training loss: 2.699633836746216
Validation loss: 2.5054213590519403

Epoch: 69| Step: 0
Training loss: 2.208491325378418
Validation loss: 2.5137391833848852

Epoch: 6| Step: 1
Training loss: 2.5456557273864746
Validation loss: 2.50666715252784

Epoch: 6| Step: 2
Training loss: 2.560814380645752
Validation loss: 2.4999435665786907

Epoch: 6| Step: 3
Training loss: 2.8755486011505127
Validation loss: 2.507982220700992

Epoch: 6| Step: 4
Training loss: 3.455620050430298
Validation loss: 2.5047463345271286

Epoch: 6| Step: 5
Training loss: 3.308739185333252
Validation loss: 2.505081356212657

Epoch: 6| Step: 6
Training loss: 2.641556978225708
Validation loss: 2.501863823142103

Epoch: 6| Step: 7
Training loss: 2.535656452178955
Validation loss: 2.5073936703384563

Epoch: 6| Step: 8
Training loss: 3.012143135070801
Validation loss: 2.501314560572306

Epoch: 6| Step: 9
Training loss: 2.510958433151245
Validation loss: 2.503710198146041

Epoch: 6| Step: 10
Training loss: 2.279578685760498
Validation loss: 2.507323218930152

Epoch: 6| Step: 11
Training loss: 2.7275280952453613
Validation loss: 2.5036519368489585

Epoch: 6| Step: 12
Training loss: 2.2752504348754883
Validation loss: 2.5022287189319568

Epoch: 6| Step: 13
Training loss: 3.1640968322753906
Validation loss: 2.5074298766351517

Epoch: 70| Step: 0
Training loss: 2.400815725326538
Validation loss: 2.502158805888186

Epoch: 6| Step: 1
Training loss: 2.6481080055236816
Validation loss: 2.499739872511997

Epoch: 6| Step: 2
Training loss: 2.585549831390381
Validation loss: 2.4994909635154148

Epoch: 6| Step: 3
Training loss: 3.2446401119232178
Validation loss: 2.4987423240497546

Epoch: 6| Step: 4
Training loss: 2.974377393722534
Validation loss: 2.5010232822869414

Epoch: 6| Step: 5
Training loss: 2.257500648498535
Validation loss: 2.497578747810856

Epoch: 6| Step: 6
Training loss: 2.974015235900879
Validation loss: 2.5044808618484007

Epoch: 6| Step: 7
Training loss: 2.4371049404144287
Validation loss: 2.503815871413036

Epoch: 6| Step: 8
Training loss: 2.3260302543640137
Validation loss: 2.5174691113092567

Epoch: 6| Step: 9
Training loss: 2.511288642883301
Validation loss: 2.5298066446858067

Epoch: 6| Step: 10
Training loss: 2.626702308654785
Validation loss: 2.5235756879211753

Epoch: 6| Step: 11
Training loss: 2.551053047180176
Validation loss: 2.5237061772295224

Epoch: 6| Step: 12
Training loss: 3.159977912902832
Validation loss: 2.5263730595188756

Epoch: 6| Step: 13
Training loss: 3.56887149810791
Validation loss: 2.5123322471495597

Epoch: 71| Step: 0
Training loss: 3.2644333839416504
Validation loss: 2.5038306866922686

Epoch: 6| Step: 1
Training loss: 2.577908992767334
Validation loss: 2.503997154133294

Epoch: 6| Step: 2
Training loss: 2.6342873573303223
Validation loss: 2.497069153734433

Epoch: 6| Step: 3
Training loss: 1.9829833507537842
Validation loss: 2.496784963915425

Epoch: 6| Step: 4
Training loss: 2.6943159103393555
Validation loss: 2.4977920132298626

Epoch: 6| Step: 5
Training loss: 3.08518385887146
Validation loss: 2.494331672627439

Epoch: 6| Step: 6
Training loss: 3.01173996925354
Validation loss: 2.498407686910322

Epoch: 6| Step: 7
Training loss: 3.0385663509368896
Validation loss: 2.4950795686373146

Epoch: 6| Step: 8
Training loss: 2.639647960662842
Validation loss: 2.5006054127088158

Epoch: 6| Step: 9
Training loss: 2.965127944946289
Validation loss: 2.501330575635356

Epoch: 6| Step: 10
Training loss: 2.4966788291931152
Validation loss: 2.5011132455641225

Epoch: 6| Step: 11
Training loss: 2.0581417083740234
Validation loss: 2.5042091569592877

Epoch: 6| Step: 12
Training loss: 2.174501419067383
Validation loss: 2.5114567600270754

Epoch: 6| Step: 13
Training loss: 3.4352102279663086
Validation loss: 2.513878365998627

Epoch: 72| Step: 0
Training loss: 2.6986539363861084
Validation loss: 2.51039473472103

Epoch: 6| Step: 1
Training loss: 2.3905696868896484
Validation loss: 2.506805660904095

Epoch: 6| Step: 2
Training loss: 2.6056694984436035
Validation loss: 2.5147413925458024

Epoch: 6| Step: 3
Training loss: 3.0401153564453125
Validation loss: 2.5234402815500894

Epoch: 6| Step: 4
Training loss: 2.508049249649048
Validation loss: 2.525850047347366

Epoch: 6| Step: 5
Training loss: 3.1783928871154785
Validation loss: 2.52772863962317

Epoch: 6| Step: 6
Training loss: 2.866035223007202
Validation loss: 2.5276502793835056

Epoch: 6| Step: 7
Training loss: 2.7996394634246826
Validation loss: 2.517195637508105

Epoch: 6| Step: 8
Training loss: 2.6853270530700684
Validation loss: 2.5124195801314486

Epoch: 6| Step: 9
Training loss: 2.8438186645507812
Validation loss: 2.5079499008835002

Epoch: 6| Step: 10
Training loss: 2.996152877807617
Validation loss: 2.5169660404164302

Epoch: 6| Step: 11
Training loss: 1.6633336544036865
Validation loss: 2.522579793007143

Epoch: 6| Step: 12
Training loss: 2.567739963531494
Validation loss: 2.5268116766406643

Epoch: 6| Step: 13
Training loss: 3.0220577716827393
Validation loss: 2.5410832256399174

Epoch: 73| Step: 0
Training loss: 2.287919282913208
Validation loss: 2.512441050621771

Epoch: 6| Step: 1
Training loss: 3.548438549041748
Validation loss: 2.492542069445374

Epoch: 6| Step: 2
Training loss: 2.9794623851776123
Validation loss: 2.4982092636887745

Epoch: 6| Step: 3
Training loss: 2.5548410415649414
Validation loss: 2.5038370445210445

Epoch: 6| Step: 4
Training loss: 2.7346010208129883
Validation loss: 2.5258358793873943

Epoch: 6| Step: 5
Training loss: 2.29093861579895
Validation loss: 2.5554924036866877

Epoch: 6| Step: 6
Training loss: 2.5601491928100586
Validation loss: 2.576458341331892

Epoch: 6| Step: 7
Training loss: 3.430295944213867
Validation loss: 2.594259323612336

Epoch: 6| Step: 8
Training loss: 2.923091411590576
Validation loss: 2.60403246777032

Epoch: 6| Step: 9
Training loss: 2.8367161750793457
Validation loss: 2.582802172630064

Epoch: 6| Step: 10
Training loss: 1.7074987888336182
Validation loss: 2.540786914927985

Epoch: 6| Step: 11
Training loss: 1.7172536849975586
Validation loss: 2.518903911754649

Epoch: 6| Step: 12
Training loss: 3.1467654705047607
Validation loss: 2.4911691706667662

Epoch: 6| Step: 13
Training loss: 3.6594700813293457
Validation loss: 2.4850850925650647

Epoch: 74| Step: 0
Training loss: 1.8435461521148682
Validation loss: 2.493074555550852

Epoch: 6| Step: 1
Training loss: 2.507242202758789
Validation loss: 2.499415010534307

Epoch: 6| Step: 2
Training loss: 3.0764293670654297
Validation loss: 2.5015173983830277

Epoch: 6| Step: 3
Training loss: 2.1484854221343994
Validation loss: 2.5068379115032893

Epoch: 6| Step: 4
Training loss: 2.9646668434143066
Validation loss: 2.505011794387653

Epoch: 6| Step: 5
Training loss: 2.5973589420318604
Validation loss: 2.505151899912024

Epoch: 6| Step: 6
Training loss: 2.7905826568603516
Validation loss: 2.5045172963091122

Epoch: 6| Step: 7
Training loss: 3.340269088745117
Validation loss: 2.4995115674952024

Epoch: 6| Step: 8
Training loss: 2.1613950729370117
Validation loss: 2.4976630979968655

Epoch: 6| Step: 9
Training loss: 3.112701892852783
Validation loss: 2.4938596140953804

Epoch: 6| Step: 10
Training loss: 3.0585808753967285
Validation loss: 2.4944356667098178

Epoch: 6| Step: 11
Training loss: 2.2349867820739746
Validation loss: 2.49072108217465

Epoch: 6| Step: 12
Training loss: 3.4356071949005127
Validation loss: 2.488133612499442

Epoch: 6| Step: 13
Training loss: 2.7816436290740967
Validation loss: 2.484832427834952

Epoch: 75| Step: 0
Training loss: 2.3111352920532227
Validation loss: 2.4824766792276853

Epoch: 6| Step: 1
Training loss: 2.195916175842285
Validation loss: 2.482860331894249

Epoch: 6| Step: 2
Training loss: 3.40909481048584
Validation loss: 2.487149912823913

Epoch: 6| Step: 3
Training loss: 3.6214194297790527
Validation loss: 2.492082359970257

Epoch: 6| Step: 4
Training loss: 2.6337757110595703
Validation loss: 2.494808071403093

Epoch: 6| Step: 5
Training loss: 2.8940184116363525
Validation loss: 2.4966120181545133

Epoch: 6| Step: 6
Training loss: 2.328845739364624
Validation loss: 2.5009193292228122

Epoch: 6| Step: 7
Training loss: 2.590867757797241
Validation loss: 2.51104974362158

Epoch: 6| Step: 8
Training loss: 2.567314386367798
Validation loss: 2.5239254479767173

Epoch: 6| Step: 9
Training loss: 2.5362532138824463
Validation loss: 2.5098546679301927

Epoch: 6| Step: 10
Training loss: 2.5194473266601562
Validation loss: 2.503520683575702

Epoch: 6| Step: 11
Training loss: 2.3528735637664795
Validation loss: 2.4924662497735794

Epoch: 6| Step: 12
Training loss: 2.6263890266418457
Validation loss: 2.4916606744130454

Epoch: 6| Step: 13
Training loss: 3.5028128623962402
Validation loss: 2.484078866179271

Epoch: 76| Step: 0
Training loss: 2.993250846862793
Validation loss: 2.4903392945566485

Epoch: 6| Step: 1
Training loss: 2.6182148456573486
Validation loss: 2.4906945895123225

Epoch: 6| Step: 2
Training loss: 2.465270519256592
Validation loss: 2.4930216138080885

Epoch: 6| Step: 3
Training loss: 2.9724197387695312
Validation loss: 2.491135758738364

Epoch: 6| Step: 4
Training loss: 3.4955263137817383
Validation loss: 2.487396499162079

Epoch: 6| Step: 5
Training loss: 2.944244861602783
Validation loss: 2.4826676717368503

Epoch: 6| Step: 6
Training loss: 2.441190719604492
Validation loss: 2.479410227908883

Epoch: 6| Step: 7
Training loss: 3.6726245880126953
Validation loss: 2.4800186644318285

Epoch: 6| Step: 8
Training loss: 2.1040899753570557
Validation loss: 2.4784819464529715

Epoch: 6| Step: 9
Training loss: 2.46016788482666
Validation loss: 2.4795988426413587

Epoch: 6| Step: 10
Training loss: 2.2991743087768555
Validation loss: 2.475099766126243

Epoch: 6| Step: 11
Training loss: 1.852170467376709
Validation loss: 2.474291575852261

Epoch: 6| Step: 12
Training loss: 2.7165603637695312
Validation loss: 2.4737354042709514

Epoch: 6| Step: 13
Training loss: 2.6079187393188477
Validation loss: 2.4832851194566294

Epoch: 77| Step: 0
Training loss: 2.764657497406006
Validation loss: 2.477421014539657

Epoch: 6| Step: 1
Training loss: 2.359389305114746
Validation loss: 2.487127125904124

Epoch: 6| Step: 2
Training loss: 2.0700531005859375
Validation loss: 2.4864660232297835

Epoch: 6| Step: 3
Training loss: 2.882239580154419
Validation loss: 2.4803026568505073

Epoch: 6| Step: 4
Training loss: 2.6582210063934326
Validation loss: 2.47409987449646

Epoch: 6| Step: 5
Training loss: 2.4603629112243652
Validation loss: 2.4793315497777795

Epoch: 6| Step: 6
Training loss: 2.3892900943756104
Validation loss: 2.4853391749884493

Epoch: 6| Step: 7
Training loss: 2.456686019897461
Validation loss: 2.4937805488545406

Epoch: 6| Step: 8
Training loss: 3.5839009284973145
Validation loss: 2.502943500395744

Epoch: 6| Step: 9
Training loss: 3.600409984588623
Validation loss: 2.5179167204005743

Epoch: 6| Step: 10
Training loss: 2.095484733581543
Validation loss: 2.510253567849436

Epoch: 6| Step: 11
Training loss: 3.3223843574523926
Validation loss: 2.4883311435740483

Epoch: 6| Step: 12
Training loss: 2.469695568084717
Validation loss: 2.465677358770883

Epoch: 6| Step: 13
Training loss: 2.4579734802246094
Validation loss: 2.461210781528104

Epoch: 78| Step: 0
Training loss: 2.185380697250366
Validation loss: 2.4562531927580475

Epoch: 6| Step: 1
Training loss: 3.1077122688293457
Validation loss: 2.460998632574594

Epoch: 6| Step: 2
Training loss: 2.4974701404571533
Validation loss: 2.459959594152307

Epoch: 6| Step: 3
Training loss: 2.497912883758545
Validation loss: 2.4565258769578833

Epoch: 6| Step: 4
Training loss: 2.3347153663635254
Validation loss: 2.454982652459093

Epoch: 6| Step: 5
Training loss: 2.345120906829834
Validation loss: 2.4563401809302707

Epoch: 6| Step: 6
Training loss: 3.1751022338867188
Validation loss: 2.4568338137800976

Epoch: 6| Step: 7
Training loss: 3.4051103591918945
Validation loss: 2.4557382881000476

Epoch: 6| Step: 8
Training loss: 3.353550434112549
Validation loss: 2.456552969512119

Epoch: 6| Step: 9
Training loss: 2.6068201065063477
Validation loss: 2.45867742517943

Epoch: 6| Step: 10
Training loss: 2.4325032234191895
Validation loss: 2.4621539987543577

Epoch: 6| Step: 11
Training loss: 2.599417209625244
Validation loss: 2.463385933188982

Epoch: 6| Step: 12
Training loss: 2.6662142276763916
Validation loss: 2.4615426576265724

Epoch: 6| Step: 13
Training loss: 2.002734422683716
Validation loss: 2.4604705969492593

Epoch: 79| Step: 0
Training loss: 3.0066423416137695
Validation loss: 2.4597011458489204

Epoch: 6| Step: 1
Training loss: 3.371088981628418
Validation loss: 2.458795060393631

Epoch: 6| Step: 2
Training loss: 1.6267619132995605
Validation loss: 2.463269700286209

Epoch: 6| Step: 3
Training loss: 2.767007827758789
Validation loss: 2.459048617270685

Epoch: 6| Step: 4
Training loss: 2.0197815895080566
Validation loss: 2.4617959043031097

Epoch: 6| Step: 5
Training loss: 3.383800506591797
Validation loss: 2.451491258477652

Epoch: 6| Step: 6
Training loss: 3.1887052059173584
Validation loss: 2.4586128547627437

Epoch: 6| Step: 7
Training loss: 3.327077865600586
Validation loss: 2.458103464495751

Epoch: 6| Step: 8
Training loss: 2.0880942344665527
Validation loss: 2.4610518640087498

Epoch: 6| Step: 9
Training loss: 2.4827961921691895
Validation loss: 2.4682226155393865

Epoch: 6| Step: 10
Training loss: 2.9555912017822266
Validation loss: 2.486327548180857

Epoch: 6| Step: 11
Training loss: 2.346590995788574
Validation loss: 2.5088596625994612

Epoch: 6| Step: 12
Training loss: 2.610804557800293
Validation loss: 2.522299992140903

Epoch: 6| Step: 13
Training loss: 2.1501681804656982
Validation loss: 2.51583408540295

Epoch: 80| Step: 0
Training loss: 2.4750239849090576
Validation loss: 2.4982531609073764

Epoch: 6| Step: 1
Training loss: 2.453995943069458
Validation loss: 2.52103941927674

Epoch: 6| Step: 2
Training loss: 2.9608261585235596
Validation loss: 2.5217063350062214

Epoch: 6| Step: 3
Training loss: 2.3113596439361572
Validation loss: 2.4889640269740934

Epoch: 6| Step: 4
Training loss: 2.598508834838867
Validation loss: 2.477361168912662

Epoch: 6| Step: 5
Training loss: 2.119569778442383
Validation loss: 2.476465476456509

Epoch: 6| Step: 6
Training loss: 2.747288227081299
Validation loss: 2.468656098970803

Epoch: 6| Step: 7
Training loss: 3.3571105003356934
Validation loss: 2.4632881584987847

Epoch: 6| Step: 8
Training loss: 2.619804859161377
Validation loss: 2.4539519022869807

Epoch: 6| Step: 9
Training loss: 1.8041963577270508
Validation loss: 2.451176874099239

Epoch: 6| Step: 10
Training loss: 3.333064079284668
Validation loss: 2.4448033814789145

Epoch: 6| Step: 11
Training loss: 2.853830575942993
Validation loss: 2.4469122245747554

Epoch: 6| Step: 12
Training loss: 2.6809377670288086
Validation loss: 2.4479974521103727

Epoch: 6| Step: 13
Training loss: 3.384514331817627
Validation loss: 2.4443947474161782

Epoch: 81| Step: 0
Training loss: 2.510000228881836
Validation loss: 2.4459971920136483

Epoch: 6| Step: 1
Training loss: 2.633079767227173
Validation loss: 2.446918567021688

Epoch: 6| Step: 2
Training loss: 2.913180112838745
Validation loss: 2.446629785722302

Epoch: 6| Step: 3
Training loss: 2.610004425048828
Validation loss: 2.446351687113444

Epoch: 6| Step: 4
Training loss: 2.006368637084961
Validation loss: 2.4558297664888444

Epoch: 6| Step: 5
Training loss: 2.7457756996154785
Validation loss: 2.4550416110664286

Epoch: 6| Step: 6
Training loss: 2.5897045135498047
Validation loss: 2.4601735863634335

Epoch: 6| Step: 7
Training loss: 2.5057218074798584
Validation loss: 2.46610087989479

Epoch: 6| Step: 8
Training loss: 3.056384801864624
Validation loss: 2.4745902707499843

Epoch: 6| Step: 9
Training loss: 2.189610004425049
Validation loss: 2.475994979181597

Epoch: 6| Step: 10
Training loss: 2.6871840953826904
Validation loss: 2.4976575656603743

Epoch: 6| Step: 11
Training loss: 3.0789742469787598
Validation loss: 2.493259811914095

Epoch: 6| Step: 12
Training loss: 2.6353859901428223
Validation loss: 2.4973583529072423

Epoch: 6| Step: 13
Training loss: 3.760434865951538
Validation loss: 2.4821752835345525

Epoch: 82| Step: 0
Training loss: 3.417226552963257
Validation loss: 2.472839255486765

Epoch: 6| Step: 1
Training loss: 3.2552852630615234
Validation loss: 2.464105334333194

Epoch: 6| Step: 2
Training loss: 2.8211073875427246
Validation loss: 2.4546078738345893

Epoch: 6| Step: 3
Training loss: 3.187952995300293
Validation loss: 2.4459304937752346

Epoch: 6| Step: 4
Training loss: 2.8558132648468018
Validation loss: 2.448322557633923

Epoch: 6| Step: 5
Training loss: 2.077953815460205
Validation loss: 2.444197459887433

Epoch: 6| Step: 6
Training loss: 2.943819999694824
Validation loss: 2.446633349182785

Epoch: 6| Step: 7
Training loss: 1.9024658203125
Validation loss: 2.4452327246307046

Epoch: 6| Step: 8
Training loss: 2.626067876815796
Validation loss: 2.4459338136898574

Epoch: 6| Step: 9
Training loss: 3.021327018737793
Validation loss: 2.45210273035111

Epoch: 6| Step: 10
Training loss: 2.416769027709961
Validation loss: 2.458776035616475

Epoch: 6| Step: 11
Training loss: 2.0212035179138184
Validation loss: 2.4647519460288425

Epoch: 6| Step: 12
Training loss: 2.241063356399536
Validation loss: 2.467903285898188

Epoch: 6| Step: 13
Training loss: 2.3996241092681885
Validation loss: 2.460530945049819

Epoch: 83| Step: 0
Training loss: 1.5073699951171875
Validation loss: 2.452900919862973

Epoch: 6| Step: 1
Training loss: 3.155466079711914
Validation loss: 2.443911265301448

Epoch: 6| Step: 2
Training loss: 2.6062564849853516
Validation loss: 2.440072177558817

Epoch: 6| Step: 3
Training loss: 3.511577606201172
Validation loss: 2.4305820311269453

Epoch: 6| Step: 4
Training loss: 2.9614906311035156
Validation loss: 2.432548115330358

Epoch: 6| Step: 5
Training loss: 2.354720115661621
Validation loss: 2.4323898284666

Epoch: 6| Step: 6
Training loss: 2.967379093170166
Validation loss: 2.430117719916887

Epoch: 6| Step: 7
Training loss: 3.0194413661956787
Validation loss: 2.4328525553467455

Epoch: 6| Step: 8
Training loss: 2.4139325618743896
Validation loss: 2.4299202913879068

Epoch: 6| Step: 9
Training loss: 2.908836603164673
Validation loss: 2.43702603924659

Epoch: 6| Step: 10
Training loss: 2.145127773284912
Validation loss: 2.4395960659109135

Epoch: 6| Step: 11
Training loss: 2.466949462890625
Validation loss: 2.442184708451712

Epoch: 6| Step: 12
Training loss: 2.551064968109131
Validation loss: 2.4330332894479074

Epoch: 6| Step: 13
Training loss: 2.8021950721740723
Validation loss: 2.434312992198493

Epoch: 84| Step: 0
Training loss: 2.3371353149414062
Validation loss: 2.4307360162017164

Epoch: 6| Step: 1
Training loss: 3.082458734512329
Validation loss: 2.4348505966125

Epoch: 6| Step: 2
Training loss: 2.1138367652893066
Validation loss: 2.4342885709577993

Epoch: 6| Step: 3
Training loss: 2.1894371509552
Validation loss: 2.4391284732408423

Epoch: 6| Step: 4
Training loss: 2.2366952896118164
Validation loss: 2.4401870132774435

Epoch: 6| Step: 5
Training loss: 2.339873790740967
Validation loss: 2.442185248098066

Epoch: 6| Step: 6
Training loss: 3.513279914855957
Validation loss: 2.4451497049741846

Epoch: 6| Step: 7
Training loss: 3.005049705505371
Validation loss: 2.44429491155891

Epoch: 6| Step: 8
Training loss: 2.4991865158081055
Validation loss: 2.4438388809081046

Epoch: 6| Step: 9
Training loss: 2.306375026702881
Validation loss: 2.4486472965568624

Epoch: 6| Step: 10
Training loss: 2.7372422218322754
Validation loss: 2.451691278847315

Epoch: 6| Step: 11
Training loss: 3.333939552307129
Validation loss: 2.460665936111122

Epoch: 6| Step: 12
Training loss: 2.599033832550049
Validation loss: 2.4603641135718233

Epoch: 6| Step: 13
Training loss: 3.019162654876709
Validation loss: 2.457604977392381

Epoch: 85| Step: 0
Training loss: 2.8289599418640137
Validation loss: 2.452073715066397

Epoch: 6| Step: 1
Training loss: 2.694221019744873
Validation loss: 2.452080313877393

Epoch: 6| Step: 2
Training loss: 2.164259910583496
Validation loss: 2.44465059362432

Epoch: 6| Step: 3
Training loss: 2.6594905853271484
Validation loss: 2.435746536459974

Epoch: 6| Step: 4
Training loss: 3.3433775901794434
Validation loss: 2.4279854887275287

Epoch: 6| Step: 5
Training loss: 3.171863079071045
Validation loss: 2.428400190927649

Epoch: 6| Step: 6
Training loss: 2.467589855194092
Validation loss: 2.431640307108561

Epoch: 6| Step: 7
Training loss: 2.6065192222595215
Validation loss: 2.437616330321117

Epoch: 6| Step: 8
Training loss: 2.430616855621338
Validation loss: 2.4429150640323596

Epoch: 6| Step: 9
Training loss: 2.3932719230651855
Validation loss: 2.4336362372162523

Epoch: 6| Step: 10
Training loss: 2.516113519668579
Validation loss: 2.429175382019371

Epoch: 6| Step: 11
Training loss: 2.688891649246216
Validation loss: 2.4259536881600656

Epoch: 6| Step: 12
Training loss: 2.648087978363037
Validation loss: 2.421184562867688

Epoch: 6| Step: 13
Training loss: 2.7545888423919678
Validation loss: 2.4256203328409502

Epoch: 86| Step: 0
Training loss: 3.048299789428711
Validation loss: 2.4308277945364676

Epoch: 6| Step: 1
Training loss: 2.560521364212036
Validation loss: 2.433097977792063

Epoch: 6| Step: 2
Training loss: 2.5680501461029053
Validation loss: 2.457799924317227

Epoch: 6| Step: 3
Training loss: 1.7395086288452148
Validation loss: 2.4716852916184293

Epoch: 6| Step: 4
Training loss: 2.1799278259277344
Validation loss: 2.473686420789329

Epoch: 6| Step: 5
Training loss: 2.7861878871917725
Validation loss: 2.4824177706113426

Epoch: 6| Step: 6
Training loss: 3.239132881164551
Validation loss: 2.468727816817581

Epoch: 6| Step: 7
Training loss: 3.1781530380249023
Validation loss: 2.4612963532888763

Epoch: 6| Step: 8
Training loss: 3.2217955589294434
Validation loss: 2.4464898109436035

Epoch: 6| Step: 9
Training loss: 1.9239295721054077
Validation loss: 2.4332706518070673

Epoch: 6| Step: 10
Training loss: 2.612832546234131
Validation loss: 2.4237718005334177

Epoch: 6| Step: 11
Training loss: 2.6078639030456543
Validation loss: 2.419745619579028

Epoch: 6| Step: 12
Training loss: 2.574803590774536
Validation loss: 2.420379066980013

Epoch: 6| Step: 13
Training loss: 3.1523611545562744
Validation loss: 2.4215944608052573

Epoch: 87| Step: 0
Training loss: 2.2597732543945312
Validation loss: 2.4259840647379556

Epoch: 6| Step: 1
Training loss: 3.0326757431030273
Validation loss: 2.4301534545037056

Epoch: 6| Step: 2
Training loss: 1.9468419551849365
Validation loss: 2.433206299299835

Epoch: 6| Step: 3
Training loss: 2.749556064605713
Validation loss: 2.431049100814327

Epoch: 6| Step: 4
Training loss: 3.2958626747131348
Validation loss: 2.4349847006541427

Epoch: 6| Step: 5
Training loss: 3.282796859741211
Validation loss: 2.426174420182423

Epoch: 6| Step: 6
Training loss: 2.893491268157959
Validation loss: 2.424150828392275

Epoch: 6| Step: 7
Training loss: 2.8962087631225586
Validation loss: 2.419487709640175

Epoch: 6| Step: 8
Training loss: 3.0505611896514893
Validation loss: 2.4188379164664977

Epoch: 6| Step: 9
Training loss: 2.334256649017334
Validation loss: 2.4194956056533323

Epoch: 6| Step: 10
Training loss: 2.692462682723999
Validation loss: 2.4173557066148326

Epoch: 6| Step: 11
Training loss: 1.805904746055603
Validation loss: 2.4143258935661724

Epoch: 6| Step: 12
Training loss: 2.4036550521850586
Validation loss: 2.4201820255607687

Epoch: 6| Step: 13
Training loss: 2.5762627124786377
Validation loss: 2.4200890730786067

Epoch: 88| Step: 0
Training loss: 2.8548011779785156
Validation loss: 2.4246446330060243

Epoch: 6| Step: 1
Training loss: 2.7478749752044678
Validation loss: 2.4351128532040502

Epoch: 6| Step: 2
Training loss: 2.527409553527832
Validation loss: 2.4511128574289303

Epoch: 6| Step: 3
Training loss: 2.403357982635498
Validation loss: 2.458338286287041

Epoch: 6| Step: 4
Training loss: 2.3422389030456543
Validation loss: 2.4674223289694837

Epoch: 6| Step: 5
Training loss: 2.487630605697632
Validation loss: 2.4726877776525353

Epoch: 6| Step: 6
Training loss: 2.689110517501831
Validation loss: 2.4724607903470277

Epoch: 6| Step: 7
Training loss: 2.2610268592834473
Validation loss: 2.4648303267776326

Epoch: 6| Step: 8
Training loss: 3.0630054473876953
Validation loss: 2.4624600000278924

Epoch: 6| Step: 9
Training loss: 2.3625030517578125
Validation loss: 2.446229220718466

Epoch: 6| Step: 10
Training loss: 2.204838275909424
Validation loss: 2.435508499863327

Epoch: 6| Step: 11
Training loss: 2.767380952835083
Validation loss: 2.4234758500129945

Epoch: 6| Step: 12
Training loss: 3.0485146045684814
Validation loss: 2.4139894131691224

Epoch: 6| Step: 13
Training loss: 3.908557891845703
Validation loss: 2.41428388831436

Epoch: 89| Step: 0
Training loss: 3.015338897705078
Validation loss: 2.4191994487598376

Epoch: 6| Step: 1
Training loss: 2.074553966522217
Validation loss: 2.418936465376167

Epoch: 6| Step: 2
Training loss: 1.9598946571350098
Validation loss: 2.4191040505645094

Epoch: 6| Step: 3
Training loss: 2.2564995288848877
Validation loss: 2.422104045908938

Epoch: 6| Step: 4
Training loss: 2.412642478942871
Validation loss: 2.425260933496619

Epoch: 6| Step: 5
Training loss: 2.9309093952178955
Validation loss: 2.422138637112033

Epoch: 6| Step: 6
Training loss: 2.5826125144958496
Validation loss: 2.4239240205416115

Epoch: 6| Step: 7
Training loss: 2.3669238090515137
Validation loss: 2.421494035310643

Epoch: 6| Step: 8
Training loss: 3.3737008571624756
Validation loss: 2.4176246402084187

Epoch: 6| Step: 9
Training loss: 3.276444911956787
Validation loss: 2.418545244842447

Epoch: 6| Step: 10
Training loss: 2.5146231651306152
Validation loss: 2.414039904071439

Epoch: 6| Step: 11
Training loss: 1.9242591857910156
Validation loss: 2.4100578215814408

Epoch: 6| Step: 12
Training loss: 3.286801815032959
Validation loss: 2.4119025712372153

Epoch: 6| Step: 13
Training loss: 3.736233949661255
Validation loss: 2.415798356456141

Epoch: 90| Step: 0
Training loss: 3.1412606239318848
Validation loss: 2.425701928395097

Epoch: 6| Step: 1
Training loss: 2.6054844856262207
Validation loss: 2.4336591766726587

Epoch: 6| Step: 2
Training loss: 2.39479660987854
Validation loss: 2.4399234530746297

Epoch: 6| Step: 3
Training loss: 3.068854808807373
Validation loss: 2.448442538579305

Epoch: 6| Step: 4
Training loss: 2.711350440979004
Validation loss: 2.458807888851371

Epoch: 6| Step: 5
Training loss: 3.160534143447876
Validation loss: 2.4633942060573126

Epoch: 6| Step: 6
Training loss: 1.9582850933074951
Validation loss: 2.4824371824982348

Epoch: 6| Step: 7
Training loss: 2.69351863861084
Validation loss: 2.484064007318148

Epoch: 6| Step: 8
Training loss: 3.0123748779296875
Validation loss: 2.4626446667537896

Epoch: 6| Step: 9
Training loss: 2.2838096618652344
Validation loss: 2.438673015563719

Epoch: 6| Step: 10
Training loss: 2.2250192165374756
Validation loss: 2.427863444051435

Epoch: 6| Step: 11
Training loss: 2.784830331802368
Validation loss: 2.41487955790694

Epoch: 6| Step: 12
Training loss: 2.3920040130615234
Validation loss: 2.41541168766637

Epoch: 6| Step: 13
Training loss: 2.639070987701416
Validation loss: 2.4120042529157413

Epoch: 91| Step: 0
Training loss: 2.02722430229187
Validation loss: 2.412072843120944

Epoch: 6| Step: 1
Training loss: 2.9571008682250977
Validation loss: 2.405914630941165

Epoch: 6| Step: 2
Training loss: 2.787519931793213
Validation loss: 2.4064790715453444

Epoch: 6| Step: 3
Training loss: 2.978908061981201
Validation loss: 2.4076382729314987

Epoch: 6| Step: 4
Training loss: 2.897352933883667
Validation loss: 2.406411196595879

Epoch: 6| Step: 5
Training loss: 2.106886386871338
Validation loss: 2.4106366865096556

Epoch: 6| Step: 6
Training loss: 3.2408695220947266
Validation loss: 2.413306943831905

Epoch: 6| Step: 7
Training loss: 2.9141721725463867
Validation loss: 2.421255039912398

Epoch: 6| Step: 8
Training loss: 2.7465906143188477
Validation loss: 2.4259419082313456

Epoch: 6| Step: 9
Training loss: 2.2147717475891113
Validation loss: 2.438510746084234

Epoch: 6| Step: 10
Training loss: 1.9061357975006104
Validation loss: 2.4421615139130624

Epoch: 6| Step: 11
Training loss: 2.291679859161377
Validation loss: 2.456608674859488

Epoch: 6| Step: 12
Training loss: 2.9353442192077637
Validation loss: 2.466434463377922

Epoch: 6| Step: 13
Training loss: 3.3415985107421875
Validation loss: 2.475312679044662

Epoch: 92| Step: 0
Training loss: 2.3697118759155273
Validation loss: 2.4810653604486936

Epoch: 6| Step: 1
Training loss: 2.3554320335388184
Validation loss: 2.4804218212763467

Epoch: 6| Step: 2
Training loss: 2.9043149948120117
Validation loss: 2.475029194226829

Epoch: 6| Step: 3
Training loss: 2.390059471130371
Validation loss: 2.4672155149521364

Epoch: 6| Step: 4
Training loss: 2.852898120880127
Validation loss: 2.4579826337034985

Epoch: 6| Step: 5
Training loss: 3.5630180835723877
Validation loss: 2.447121315104987

Epoch: 6| Step: 6
Training loss: 2.383607864379883
Validation loss: 2.4315596883014967

Epoch: 6| Step: 7
Training loss: 2.906087636947632
Validation loss: 2.424104828988352

Epoch: 6| Step: 8
Training loss: 1.7051081657409668
Validation loss: 2.4108579953511557

Epoch: 6| Step: 9
Training loss: 1.985329508781433
Validation loss: 2.401291762628863

Epoch: 6| Step: 10
Training loss: 2.681243419647217
Validation loss: 2.3987150269169963

Epoch: 6| Step: 11
Training loss: 3.013054847717285
Validation loss: 2.398007356992332

Epoch: 6| Step: 12
Training loss: 3.245696783065796
Validation loss: 2.399435284317181

Epoch: 6| Step: 13
Training loss: 2.884695053100586
Validation loss: 2.3977652236979496

Epoch: 93| Step: 0
Training loss: 2.2355806827545166
Validation loss: 2.4035833369019213

Epoch: 6| Step: 1
Training loss: 1.9610575437545776
Validation loss: 2.4042106290017404

Epoch: 6| Step: 2
Training loss: 3.3076729774475098
Validation loss: 2.416872170663649

Epoch: 6| Step: 3
Training loss: 2.4654083251953125
Validation loss: 2.421717123318744

Epoch: 6| Step: 4
Training loss: 2.472130298614502
Validation loss: 2.4276784850705053

Epoch: 6| Step: 5
Training loss: 2.23822021484375
Validation loss: 2.4334601074136715

Epoch: 6| Step: 6
Training loss: 2.782155990600586
Validation loss: 2.4335934064721547

Epoch: 6| Step: 7
Training loss: 2.4980719089508057
Validation loss: 2.428176341518279

Epoch: 6| Step: 8
Training loss: 2.4175515174865723
Validation loss: 2.4202314730613463

Epoch: 6| Step: 9
Training loss: 2.617905378341675
Validation loss: 2.4312370977094098

Epoch: 6| Step: 10
Training loss: 3.4278206825256348
Validation loss: 2.4467810815380466

Epoch: 6| Step: 11
Training loss: 2.673804759979248
Validation loss: 2.4647100228135304

Epoch: 6| Step: 12
Training loss: 3.1322431564331055
Validation loss: 2.494897228415294

Epoch: 6| Step: 13
Training loss: 2.9683332443237305
Validation loss: 2.532448632742769

Epoch: 94| Step: 0
Training loss: 2.6311721801757812
Validation loss: 2.5593472680737896

Epoch: 6| Step: 1
Training loss: 3.586979627609253
Validation loss: 2.567937038278067

Epoch: 6| Step: 2
Training loss: 3.037395477294922
Validation loss: 2.5602414428546862

Epoch: 6| Step: 3
Training loss: 2.5433332920074463
Validation loss: 2.5589797419886433

Epoch: 6| Step: 4
Training loss: 2.9904420375823975
Validation loss: 2.5423276808954056

Epoch: 6| Step: 5
Training loss: 2.2800211906433105
Validation loss: 2.526419416550667

Epoch: 6| Step: 6
Training loss: 2.6231958866119385
Validation loss: 2.5127056824263705

Epoch: 6| Step: 7
Training loss: 2.6805849075317383
Validation loss: 2.4967563639404955

Epoch: 6| Step: 8
Training loss: 2.280118227005005
Validation loss: 2.4797350924502135

Epoch: 6| Step: 9
Training loss: 2.840794801712036
Validation loss: 2.4625017053337506

Epoch: 6| Step: 10
Training loss: 2.907125949859619
Validation loss: 2.4569973125252673

Epoch: 6| Step: 11
Training loss: 2.0135903358459473
Validation loss: 2.4528307632733415

Epoch: 6| Step: 12
Training loss: 2.5206422805786133
Validation loss: 2.4490528593781176

Epoch: 6| Step: 13
Training loss: 2.499445915222168
Validation loss: 2.448845273704939

Epoch: 95| Step: 0
Training loss: 2.6148359775543213
Validation loss: 2.4462084078019664

Epoch: 6| Step: 1
Training loss: 3.835310697555542
Validation loss: 2.4563563639117825

Epoch: 6| Step: 2
Training loss: 3.137626886367798
Validation loss: 2.4529217058612454

Epoch: 6| Step: 3
Training loss: 2.1977782249450684
Validation loss: 2.4585650941377044

Epoch: 6| Step: 4
Training loss: 2.4063892364501953
Validation loss: 2.458504540945894

Epoch: 6| Step: 5
Training loss: 2.4856224060058594
Validation loss: 2.4591231807585685

Epoch: 6| Step: 6
Training loss: 1.8803166151046753
Validation loss: 2.4593837389381985

Epoch: 6| Step: 7
Training loss: 3.0400376319885254
Validation loss: 2.4546541783117477

Epoch: 6| Step: 8
Training loss: 2.856450319290161
Validation loss: 2.4458530846462456

Epoch: 6| Step: 9
Training loss: 2.515612840652466
Validation loss: 2.4414451519648233

Epoch: 6| Step: 10
Training loss: 2.214676856994629
Validation loss: 2.438667307617844

Epoch: 6| Step: 11
Training loss: 2.9234843254089355
Validation loss: 2.429692957990913

Epoch: 6| Step: 12
Training loss: 2.519152879714966
Validation loss: 2.4225888072803454

Epoch: 6| Step: 13
Training loss: 2.2218916416168213
Validation loss: 2.419621467590332

Epoch: 96| Step: 0
Training loss: 2.7692079544067383
Validation loss: 2.427226927972609

Epoch: 6| Step: 1
Training loss: 2.4848732948303223
Validation loss: 2.4360512725768553

Epoch: 6| Step: 2
Training loss: 2.3268909454345703
Validation loss: 2.4197503700051257

Epoch: 6| Step: 3
Training loss: 2.076021194458008
Validation loss: 2.4208346156663794

Epoch: 6| Step: 4
Training loss: 3.703871250152588
Validation loss: 2.4239769443388908

Epoch: 6| Step: 5
Training loss: 2.7023372650146484
Validation loss: 2.4282187979708434

Epoch: 6| Step: 6
Training loss: 2.5950136184692383
Validation loss: 2.4338940958822928

Epoch: 6| Step: 7
Training loss: 2.703402519226074
Validation loss: 2.4483071860446723

Epoch: 6| Step: 8
Training loss: 2.386063575744629
Validation loss: 2.4313949410633375

Epoch: 6| Step: 9
Training loss: 2.7982113361358643
Validation loss: 2.4208687018322688

Epoch: 6| Step: 10
Training loss: 2.3523306846618652
Validation loss: 2.417305892513644

Epoch: 6| Step: 11
Training loss: 3.1447272300720215
Validation loss: 2.4135969684969996

Epoch: 6| Step: 12
Training loss: 2.6100425720214844
Validation loss: 2.4116326608965473

Epoch: 6| Step: 13
Training loss: 1.9960598945617676
Validation loss: 2.4109812013564573

Epoch: 97| Step: 0
Training loss: 2.3133928775787354
Validation loss: 2.4068649763702066

Epoch: 6| Step: 1
Training loss: 2.8328499794006348
Validation loss: 2.398134077748945

Epoch: 6| Step: 2
Training loss: 2.763641834259033
Validation loss: 2.400935075616324

Epoch: 6| Step: 3
Training loss: 2.7971510887145996
Validation loss: 2.3955589225215297

Epoch: 6| Step: 4
Training loss: 2.3813185691833496
Validation loss: 2.3890242627871934

Epoch: 6| Step: 5
Training loss: 2.1661832332611084
Validation loss: 2.3999942528304232

Epoch: 6| Step: 6
Training loss: 2.6689817905426025
Validation loss: 2.4005215398726927

Epoch: 6| Step: 7
Training loss: 2.6402459144592285
Validation loss: 2.411683290235458

Epoch: 6| Step: 8
Training loss: 2.9206666946411133
Validation loss: 2.4139950813785678

Epoch: 6| Step: 9
Training loss: 2.4766368865966797
Validation loss: 2.4111251369599374

Epoch: 6| Step: 10
Training loss: 2.4460504055023193
Validation loss: 2.39378938880018

Epoch: 6| Step: 11
Training loss: 3.1558752059936523
Validation loss: 2.3864231596710863

Epoch: 6| Step: 12
Training loss: 2.124711036682129
Validation loss: 2.378564924322149

Epoch: 6| Step: 13
Training loss: 3.7247836589813232
Validation loss: 2.3769182979419665

Epoch: 98| Step: 0
Training loss: 2.9683852195739746
Validation loss: 2.3802226461390013

Epoch: 6| Step: 1
Training loss: 2.1072030067443848
Validation loss: 2.3886540833339898

Epoch: 6| Step: 2
Training loss: 1.9474390745162964
Validation loss: 2.3946318370039745

Epoch: 6| Step: 3
Training loss: 2.7969508171081543
Validation loss: 2.3900913782017206

Epoch: 6| Step: 4
Training loss: 2.6914854049682617
Validation loss: 2.3872373129731868

Epoch: 6| Step: 5
Training loss: 2.5300426483154297
Validation loss: 2.3813813988880446

Epoch: 6| Step: 6
Training loss: 3.1935794353485107
Validation loss: 2.377169624451668

Epoch: 6| Step: 7
Training loss: 2.3117613792419434
Validation loss: 2.375500671325191

Epoch: 6| Step: 8
Training loss: 2.712414264678955
Validation loss: 2.375284364146571

Epoch: 6| Step: 9
Training loss: 2.3378705978393555
Validation loss: 2.373373205943774

Epoch: 6| Step: 10
Training loss: 2.7449731826782227
Validation loss: 2.373396623519159

Epoch: 6| Step: 11
Training loss: 2.7992701530456543
Validation loss: 2.3725161090973885

Epoch: 6| Step: 12
Training loss: 3.189528465270996
Validation loss: 2.374094340109056

Epoch: 6| Step: 13
Training loss: 2.744624137878418
Validation loss: 2.374094047854024

Epoch: 99| Step: 0
Training loss: 2.043339490890503
Validation loss: 2.3717219470649638

Epoch: 6| Step: 1
Training loss: 2.7081048488616943
Validation loss: 2.3727955638721423

Epoch: 6| Step: 2
Training loss: 3.0096774101257324
Validation loss: 2.374679942284861

Epoch: 6| Step: 3
Training loss: 2.4361345767974854
Validation loss: 2.37572237753099

Epoch: 6| Step: 4
Training loss: 2.7273247241973877
Validation loss: 2.378456284922938

Epoch: 6| Step: 5
Training loss: 2.831620454788208
Validation loss: 2.377831833336943

Epoch: 6| Step: 6
Training loss: 2.907900333404541
Validation loss: 2.3802415247886413

Epoch: 6| Step: 7
Training loss: 2.038245677947998
Validation loss: 2.379958406571419

Epoch: 6| Step: 8
Training loss: 3.047579050064087
Validation loss: 2.381034561382827

Epoch: 6| Step: 9
Training loss: 2.708171844482422
Validation loss: 2.380144883227605

Epoch: 6| Step: 10
Training loss: 2.7944514751434326
Validation loss: 2.384877589441115

Epoch: 6| Step: 11
Training loss: 2.3548667430877686
Validation loss: 2.388983985429169

Epoch: 6| Step: 12
Training loss: 2.946751356124878
Validation loss: 2.3921431238933275

Epoch: 6| Step: 13
Training loss: 1.9232637882232666
Validation loss: 2.389407314280028

Epoch: 100| Step: 0
Training loss: 3.107288360595703
Validation loss: 2.3901449506000807

Epoch: 6| Step: 1
Training loss: 3.017094612121582
Validation loss: 2.390153528541647

Epoch: 6| Step: 2
Training loss: 2.8677563667297363
Validation loss: 2.396653216372254

Epoch: 6| Step: 3
Training loss: 2.935356616973877
Validation loss: 2.3891880909601846

Epoch: 6| Step: 4
Training loss: 2.608865737915039
Validation loss: 2.3914052594092583

Epoch: 6| Step: 5
Training loss: 2.36381459236145
Validation loss: 2.388754637010636

Epoch: 6| Step: 6
Training loss: 2.2841436862945557
Validation loss: 2.3838724397843882

Epoch: 6| Step: 7
Training loss: 2.374713182449341
Validation loss: 2.3917948353675103

Epoch: 6| Step: 8
Training loss: 2.1958770751953125
Validation loss: 2.398500637341571

Epoch: 6| Step: 9
Training loss: 2.918736457824707
Validation loss: 2.4009325453030166

Epoch: 6| Step: 10
Training loss: 1.9770771265029907
Validation loss: 2.400187115515432

Epoch: 6| Step: 11
Training loss: 2.9571757316589355
Validation loss: 2.405694102728239

Epoch: 6| Step: 12
Training loss: 2.595816135406494
Validation loss: 2.4031590774495113

Epoch: 6| Step: 13
Training loss: 2.3562254905700684
Validation loss: 2.394306500752767

Epoch: 101| Step: 0
Training loss: 2.1750829219818115
Validation loss: 2.391967031263536

Epoch: 6| Step: 1
Training loss: 2.4010066986083984
Validation loss: 2.3815750742471344

Epoch: 6| Step: 2
Training loss: 3.8816580772399902
Validation loss: 2.3751519444168254

Epoch: 6| Step: 3
Training loss: 1.843667984008789
Validation loss: 2.37188434344466

Epoch: 6| Step: 4
Training loss: 2.540313243865967
Validation loss: 2.3689086667953

Epoch: 6| Step: 5
Training loss: 2.391047954559326
Validation loss: 2.365842483376944

Epoch: 6| Step: 6
Training loss: 3.214628219604492
Validation loss: 2.364045630219162

Epoch: 6| Step: 7
Training loss: 2.443418025970459
Validation loss: 2.3614673306865077

Epoch: 6| Step: 8
Training loss: 2.6914143562316895
Validation loss: 2.3623937419665757

Epoch: 6| Step: 9
Training loss: 2.6648082733154297
Validation loss: 2.362791347247298

Epoch: 6| Step: 10
Training loss: 2.027254104614258
Validation loss: 2.364327028233518

Epoch: 6| Step: 11
Training loss: 2.821018695831299
Validation loss: 2.3694089099925053

Epoch: 6| Step: 12
Training loss: 2.8725006580352783
Validation loss: 2.3819009232264694

Epoch: 6| Step: 13
Training loss: 2.786637306213379
Validation loss: 2.3842004755491852

Epoch: 102| Step: 0
Training loss: 3.069464683532715
Validation loss: 2.397513440860215

Epoch: 6| Step: 1
Training loss: 3.49977970123291
Validation loss: 2.403982618803619

Epoch: 6| Step: 2
Training loss: 2.6215758323669434
Validation loss: 2.395120107999412

Epoch: 6| Step: 3
Training loss: 2.778240203857422
Validation loss: 2.404213620770362

Epoch: 6| Step: 4
Training loss: 2.2171077728271484
Validation loss: 2.389997648936446

Epoch: 6| Step: 5
Training loss: 2.414548873901367
Validation loss: 2.3832896601769233

Epoch: 6| Step: 6
Training loss: 2.398111343383789
Validation loss: 2.372784668399442

Epoch: 6| Step: 7
Training loss: 2.5096054077148438
Validation loss: 2.3649482188686246

Epoch: 6| Step: 8
Training loss: 2.3042945861816406
Validation loss: 2.3667512606549006

Epoch: 6| Step: 9
Training loss: 3.365216016769409
Validation loss: 2.3693545403019076

Epoch: 6| Step: 10
Training loss: 3.08357310295105
Validation loss: 2.3685132918819303

Epoch: 6| Step: 11
Training loss: 1.933767318725586
Validation loss: 2.370242800763858

Epoch: 6| Step: 12
Training loss: 2.4127984046936035
Validation loss: 2.3800882652241695

Epoch: 6| Step: 13
Training loss: 1.6724307537078857
Validation loss: 2.3756250386597006

Epoch: 103| Step: 0
Training loss: 2.7802367210388184
Validation loss: 2.379452872019942

Epoch: 6| Step: 1
Training loss: 2.1752915382385254
Validation loss: 2.3911399046579995

Epoch: 6| Step: 2
Training loss: 2.8500571250915527
Validation loss: 2.385955314482412

Epoch: 6| Step: 3
Training loss: 2.2567951679229736
Validation loss: 2.3809980436037947

Epoch: 6| Step: 4
Training loss: 2.2699432373046875
Validation loss: 2.366230054568219

Epoch: 6| Step: 5
Training loss: 2.409944772720337
Validation loss: 2.3624367406291347

Epoch: 6| Step: 6
Training loss: 2.29292631149292
Validation loss: 2.3627919586755897

Epoch: 6| Step: 7
Training loss: 2.720177173614502
Validation loss: 2.367380380630493

Epoch: 6| Step: 8
Training loss: 2.611957550048828
Validation loss: 2.366182529798118

Epoch: 6| Step: 9
Training loss: 2.960317611694336
Validation loss: 2.3658411272110476

Epoch: 6| Step: 10
Training loss: 2.693154811859131
Validation loss: 2.366415205822196

Epoch: 6| Step: 11
Training loss: 3.33276104927063
Validation loss: 2.3816903662937943

Epoch: 6| Step: 12
Training loss: 2.530975103378296
Validation loss: 2.398657978221934

Epoch: 6| Step: 13
Training loss: 2.930913209915161
Validation loss: 2.4015797927815425

Epoch: 104| Step: 0
Training loss: 2.9692482948303223
Validation loss: 2.3940583967393443

Epoch: 6| Step: 1
Training loss: 2.670459747314453
Validation loss: 2.3866485805921656

Epoch: 6| Step: 2
Training loss: 2.7145614624023438
Validation loss: 2.374630323020361

Epoch: 6| Step: 3
Training loss: 3.113893985748291
Validation loss: 2.3573718993894515

Epoch: 6| Step: 4
Training loss: 1.8537918329238892
Validation loss: 2.361693941136842

Epoch: 6| Step: 5
Training loss: 3.0577239990234375
Validation loss: 2.363612964589109

Epoch: 6| Step: 6
Training loss: 2.748241424560547
Validation loss: 2.3667636917483423

Epoch: 6| Step: 7
Training loss: 3.127664566040039
Validation loss: 2.3654732217070875

Epoch: 6| Step: 8
Training loss: 2.464554786682129
Validation loss: 2.37131558310601

Epoch: 6| Step: 9
Training loss: 2.8173904418945312
Validation loss: 2.3744539496719197

Epoch: 6| Step: 10
Training loss: 2.1336851119995117
Validation loss: 2.3703453874075286

Epoch: 6| Step: 11
Training loss: 2.9309864044189453
Validation loss: 2.3676527725752963

Epoch: 6| Step: 12
Training loss: 1.5128638744354248
Validation loss: 2.363976217085315

Epoch: 6| Step: 13
Training loss: 3.1112606525421143
Validation loss: 2.3583227895921275

Epoch: 105| Step: 0
Training loss: 3.543851375579834
Validation loss: 2.3558275212523756

Epoch: 6| Step: 1
Training loss: 2.6603124141693115
Validation loss: 2.3595782813205513

Epoch: 6| Step: 2
Training loss: 2.3820128440856934
Validation loss: 2.37712412880313

Epoch: 6| Step: 3
Training loss: 2.622931957244873
Validation loss: 2.3977342497917915

Epoch: 6| Step: 4
Training loss: 2.330697536468506
Validation loss: 2.4235126356924734

Epoch: 6| Step: 5
Training loss: 2.1288862228393555
Validation loss: 2.445355433289723

Epoch: 6| Step: 6
Training loss: 2.553750991821289
Validation loss: 2.4170614416881273

Epoch: 6| Step: 7
Training loss: 2.0798823833465576
Validation loss: 2.4018618201696746

Epoch: 6| Step: 8
Training loss: 2.620539665222168
Validation loss: 2.376377487695345

Epoch: 6| Step: 9
Training loss: 2.298074722290039
Validation loss: 2.3628189384296374

Epoch: 6| Step: 10
Training loss: 2.9906959533691406
Validation loss: 2.357594797688146

Epoch: 6| Step: 11
Training loss: 3.7753660678863525
Validation loss: 2.348002051794401

Epoch: 6| Step: 12
Training loss: 1.8831610679626465
Validation loss: 2.3439074588078324

Epoch: 6| Step: 13
Training loss: 2.8267807960510254
Validation loss: 2.346345058051489

Epoch: 106| Step: 0
Training loss: 3.1680893898010254
Validation loss: 2.34835543171052

Epoch: 6| Step: 1
Training loss: 2.308576822280884
Validation loss: 2.3535608117298414

Epoch: 6| Step: 2
Training loss: 2.076411485671997
Validation loss: 2.353825871662427

Epoch: 6| Step: 3
Training loss: 2.256387233734131
Validation loss: 2.3574976895445134

Epoch: 6| Step: 4
Training loss: 2.3356614112854004
Validation loss: 2.360837559546194

Epoch: 6| Step: 5
Training loss: 2.611241102218628
Validation loss: 2.356878703640353

Epoch: 6| Step: 6
Training loss: 2.4983043670654297
Validation loss: 2.3572898833982405

Epoch: 6| Step: 7
Training loss: 2.9945225715637207
Validation loss: 2.3493563539238385

Epoch: 6| Step: 8
Training loss: 3.504411458969116
Validation loss: 2.347908914730113

Epoch: 6| Step: 9
Training loss: 1.9542042016983032
Validation loss: 2.346004539920438

Epoch: 6| Step: 10
Training loss: 2.8427555561065674
Validation loss: 2.3560564492338445

Epoch: 6| Step: 11
Training loss: 2.795612335205078
Validation loss: 2.3673798294477564

Epoch: 6| Step: 12
Training loss: 2.4572649002075195
Validation loss: 2.3670802885486233

Epoch: 6| Step: 13
Training loss: 2.9778926372528076
Validation loss: 2.378314515595795

Epoch: 107| Step: 0
Training loss: 2.612514019012451
Validation loss: 2.377835342960973

Epoch: 6| Step: 1
Training loss: 2.095381736755371
Validation loss: 2.389920788426553

Epoch: 6| Step: 2
Training loss: 2.4475297927856445
Validation loss: 2.3927406546890095

Epoch: 6| Step: 3
Training loss: 2.5611634254455566
Validation loss: 2.3917795919602916

Epoch: 6| Step: 4
Training loss: 2.478717803955078
Validation loss: 2.399854747197961

Epoch: 6| Step: 5
Training loss: 1.6644153594970703
Validation loss: 2.40978306083269

Epoch: 6| Step: 6
Training loss: 2.4999186992645264
Validation loss: 2.4195201935306674

Epoch: 6| Step: 7
Training loss: 3.219994068145752
Validation loss: 2.4312321396284204

Epoch: 6| Step: 8
Training loss: 3.0796685218811035
Validation loss: 2.4158760732220066

Epoch: 6| Step: 9
Training loss: 2.3401694297790527
Validation loss: 2.400786833096576

Epoch: 6| Step: 10
Training loss: 2.6148977279663086
Validation loss: 2.3833412688265563

Epoch: 6| Step: 11
Training loss: 2.794776201248169
Validation loss: 2.371553364620414

Epoch: 6| Step: 12
Training loss: 2.68788743019104
Validation loss: 2.358308302458896

Epoch: 6| Step: 13
Training loss: 3.895419120788574
Validation loss: 2.3435247200791554

Epoch: 108| Step: 0
Training loss: 2.785795211791992
Validation loss: 2.3418932460969493

Epoch: 6| Step: 1
Training loss: 2.891124725341797
Validation loss: 2.3415458048543623

Epoch: 6| Step: 2
Training loss: 3.3317952156066895
Validation loss: 2.341828202688566

Epoch: 6| Step: 3
Training loss: 2.5117053985595703
Validation loss: 2.3420870816835793

Epoch: 6| Step: 4
Training loss: 2.490691661834717
Validation loss: 2.3492754479890228

Epoch: 6| Step: 5
Training loss: 2.0619795322418213
Validation loss: 2.3552545860249507

Epoch: 6| Step: 6
Training loss: 2.60276460647583
Validation loss: 2.3534152264236123

Epoch: 6| Step: 7
Training loss: 2.998105525970459
Validation loss: 2.352211767627347

Epoch: 6| Step: 8
Training loss: 3.049508571624756
Validation loss: 2.3522790119212162

Epoch: 6| Step: 9
Training loss: 2.653409957885742
Validation loss: 2.3474361870878484

Epoch: 6| Step: 10
Training loss: 1.8923742771148682
Validation loss: 2.3444174438394527

Epoch: 6| Step: 11
Training loss: 2.6558353900909424
Validation loss: 2.346532339690834

Epoch: 6| Step: 12
Training loss: 2.6218228340148926
Validation loss: 2.354032593388711

Epoch: 6| Step: 13
Training loss: 1.8690071105957031
Validation loss: 2.3563973083291003

Epoch: 109| Step: 0
Training loss: 2.732567071914673
Validation loss: 2.3653246433504167

Epoch: 6| Step: 1
Training loss: 2.46553897857666
Validation loss: 2.383598945474112

Epoch: 6| Step: 2
Training loss: 1.6247456073760986
Validation loss: 2.3973984949050413

Epoch: 6| Step: 3
Training loss: 2.9652695655822754
Validation loss: 2.4032249014864684

Epoch: 6| Step: 4
Training loss: 2.9685325622558594
Validation loss: 2.408129653623027

Epoch: 6| Step: 5
Training loss: 2.928884744644165
Validation loss: 2.3903284841968166

Epoch: 6| Step: 6
Training loss: 2.391038179397583
Validation loss: 2.3693261659273537

Epoch: 6| Step: 7
Training loss: 2.243675708770752
Validation loss: 2.3573954874469387

Epoch: 6| Step: 8
Training loss: 2.2401742935180664
Validation loss: 2.346422577417025

Epoch: 6| Step: 9
Training loss: 2.852576732635498
Validation loss: 2.341226875141103

Epoch: 6| Step: 10
Training loss: 2.2813267707824707
Validation loss: 2.3357020578076764

Epoch: 6| Step: 11
Training loss: 3.5029821395874023
Validation loss: 2.334023388483191

Epoch: 6| Step: 12
Training loss: 2.4649500846862793
Validation loss: 2.333015808495142

Epoch: 6| Step: 13
Training loss: 2.87977933883667
Validation loss: 2.3341149668539725

Epoch: 110| Step: 0
Training loss: 2.69871187210083
Validation loss: 2.3350989972391436

Epoch: 6| Step: 1
Training loss: 2.90712833404541
Validation loss: 2.330114374878586

Epoch: 6| Step: 2
Training loss: 2.5357279777526855
Validation loss: 2.329639747578611

Epoch: 6| Step: 3
Training loss: 2.9746057987213135
Validation loss: 2.329469757695352

Epoch: 6| Step: 4
Training loss: 2.6851677894592285
Validation loss: 2.3308784218244654

Epoch: 6| Step: 5
Training loss: 2.3467330932617188
Validation loss: 2.3321157578499085

Epoch: 6| Step: 6
Training loss: 1.9051275253295898
Validation loss: 2.3295883658111736

Epoch: 6| Step: 7
Training loss: 2.7336647510528564
Validation loss: 2.3391822884159703

Epoch: 6| Step: 8
Training loss: 2.989590644836426
Validation loss: 2.341197888056437

Epoch: 6| Step: 9
Training loss: 2.839972496032715
Validation loss: 2.3506685674831433

Epoch: 6| Step: 10
Training loss: 2.0251998901367188
Validation loss: 2.36702831586202

Epoch: 6| Step: 11
Training loss: 2.597609519958496
Validation loss: 2.387070289222143

Epoch: 6| Step: 12
Training loss: 2.420046806335449
Validation loss: 2.3964712824872745

Epoch: 6| Step: 13
Training loss: 2.8018991947174072
Validation loss: 2.4057456703596216

Epoch: 111| Step: 0
Training loss: 2.1214849948883057
Validation loss: 2.3998345662188787

Epoch: 6| Step: 1
Training loss: 2.5855202674865723
Validation loss: 2.3744667114750033

Epoch: 6| Step: 2
Training loss: 2.853229284286499
Validation loss: 2.3703760382949666

Epoch: 6| Step: 3
Training loss: 2.6247429847717285
Validation loss: 2.362970913610151

Epoch: 6| Step: 4
Training loss: 3.1062610149383545
Validation loss: 2.348175064209969

Epoch: 6| Step: 5
Training loss: 2.3163681030273438
Validation loss: 2.338267813446701

Epoch: 6| Step: 6
Training loss: 2.40812087059021
Validation loss: 2.3334813348708616

Epoch: 6| Step: 7
Training loss: 2.680056095123291
Validation loss: 2.3309422410944456

Epoch: 6| Step: 8
Training loss: 2.1870203018188477
Validation loss: 2.3342177150070027

Epoch: 6| Step: 9
Training loss: 2.6910758018493652
Validation loss: 2.332166378216077

Epoch: 6| Step: 10
Training loss: 2.899789810180664
Validation loss: 2.334732614537721

Epoch: 6| Step: 11
Training loss: 2.5197691917419434
Validation loss: 2.337236137800319

Epoch: 6| Step: 12
Training loss: 2.997647285461426
Validation loss: 2.3450477661625033

Epoch: 6| Step: 13
Training loss: 2.15598201751709
Validation loss: 2.3358367386684624

Epoch: 112| Step: 0
Training loss: 2.869119882583618
Validation loss: 2.3458133538564048

Epoch: 6| Step: 1
Training loss: 2.7735118865966797
Validation loss: 2.364475298953313

Epoch: 6| Step: 2
Training loss: 3.0221683979034424
Validation loss: 2.3583716936008905

Epoch: 6| Step: 3
Training loss: 2.2033779621124268
Validation loss: 2.3609311760112806

Epoch: 6| Step: 4
Training loss: 3.1996116638183594
Validation loss: 2.354545388170468

Epoch: 6| Step: 5
Training loss: 2.2933802604675293
Validation loss: 2.3546473954313543

Epoch: 6| Step: 6
Training loss: 2.1672139167785645
Validation loss: 2.3430908392834406

Epoch: 6| Step: 7
Training loss: 1.4535377025604248
Validation loss: 2.3390316245376424

Epoch: 6| Step: 8
Training loss: 2.4120283126831055
Validation loss: 2.3344903710067912

Epoch: 6| Step: 9
Training loss: 2.598320484161377
Validation loss: 2.332152707602388

Epoch: 6| Step: 10
Training loss: 2.3085756301879883
Validation loss: 2.3330610644432808

Epoch: 6| Step: 11
Training loss: 3.1199355125427246
Validation loss: 2.3319722657562583

Epoch: 6| Step: 12
Training loss: 3.146385669708252
Validation loss: 2.3296437519852833

Epoch: 6| Step: 13
Training loss: 2.938263416290283
Validation loss: 2.3260758820400445

Epoch: 113| Step: 0
Training loss: 1.9257776737213135
Validation loss: 2.3306636579575075

Epoch: 6| Step: 1
Training loss: 3.5172903537750244
Validation loss: 2.3419750326423237

Epoch: 6| Step: 2
Training loss: 2.3846473693847656
Validation loss: 2.3419324454440864

Epoch: 6| Step: 3
Training loss: 2.652496814727783
Validation loss: 2.3526751943813857

Epoch: 6| Step: 4
Training loss: 2.4255809783935547
Validation loss: 2.3498096542973674

Epoch: 6| Step: 5
Training loss: 2.0213546752929688
Validation loss: 2.348566993590324

Epoch: 6| Step: 6
Training loss: 2.655996799468994
Validation loss: 2.339487316787884

Epoch: 6| Step: 7
Training loss: 3.4339230060577393
Validation loss: 2.33735397554213

Epoch: 6| Step: 8
Training loss: 2.429750919342041
Validation loss: 2.3232225346308883

Epoch: 6| Step: 9
Training loss: 2.722548484802246
Validation loss: 2.3221439110335482

Epoch: 6| Step: 10
Training loss: 2.4991254806518555
Validation loss: 2.317768632724721

Epoch: 6| Step: 11
Training loss: 2.548229694366455
Validation loss: 2.32066673104481

Epoch: 6| Step: 12
Training loss: 3.0876593589782715
Validation loss: 2.3180542684370473

Epoch: 6| Step: 13
Training loss: 1.7947711944580078
Validation loss: 2.320136975216609

Epoch: 114| Step: 0
Training loss: 1.9523569345474243
Validation loss: 2.3235188273973364

Epoch: 6| Step: 1
Training loss: 2.0059146881103516
Validation loss: 2.3202978718665337

Epoch: 6| Step: 2
Training loss: 2.9723806381225586
Validation loss: 2.3188502762907293

Epoch: 6| Step: 3
Training loss: 2.937314510345459
Validation loss: 2.3175652232221378

Epoch: 6| Step: 4
Training loss: 2.2611687183380127
Validation loss: 2.3214485542748564

Epoch: 6| Step: 5
Training loss: 3.2068145275115967
Validation loss: 2.328786516702303

Epoch: 6| Step: 6
Training loss: 2.8893094062805176
Validation loss: 2.3434060952996694

Epoch: 6| Step: 7
Training loss: 2.4403724670410156
Validation loss: 2.3625777588095715

Epoch: 6| Step: 8
Training loss: 2.670908212661743
Validation loss: 2.373538506928311

Epoch: 6| Step: 9
Training loss: 3.1368653774261475
Validation loss: 2.402819956502607

Epoch: 6| Step: 10
Training loss: 2.418858051300049
Validation loss: 2.3861430639861734

Epoch: 6| Step: 11
Training loss: 2.299560308456421
Validation loss: 2.371814573964765

Epoch: 6| Step: 12
Training loss: 2.382129669189453
Validation loss: 2.377764824898012

Epoch: 6| Step: 13
Training loss: 2.989065170288086
Validation loss: 2.375386889262866

Epoch: 115| Step: 0
Training loss: 3.055083751678467
Validation loss: 2.363417071680869

Epoch: 6| Step: 1
Training loss: 2.3181564807891846
Validation loss: 2.348447991955665

Epoch: 6| Step: 2
Training loss: 1.8368237018585205
Validation loss: 2.340642629131194

Epoch: 6| Step: 3
Training loss: 1.7660584449768066
Validation loss: 2.3346996256100234

Epoch: 6| Step: 4
Training loss: 2.154420852661133
Validation loss: 2.3484475151185067

Epoch: 6| Step: 5
Training loss: 2.575671672821045
Validation loss: 2.356998365412476

Epoch: 6| Step: 6
Training loss: 2.357192039489746
Validation loss: 2.3638650550637195

Epoch: 6| Step: 7
Training loss: 3.0030577182769775
Validation loss: 2.377094148307718

Epoch: 6| Step: 8
Training loss: 3.342522144317627
Validation loss: 2.368953320287889

Epoch: 6| Step: 9
Training loss: 2.7149791717529297
Validation loss: 2.3627170490962204

Epoch: 6| Step: 10
Training loss: 3.3724682331085205
Validation loss: 2.3382243571742887

Epoch: 6| Step: 11
Training loss: 3.0562267303466797
Validation loss: 2.3214939948051208

Epoch: 6| Step: 12
Training loss: 2.4717555046081543
Validation loss: 2.3138653206568893

Epoch: 6| Step: 13
Training loss: 1.9103761911392212
Validation loss: 2.322654075520013

Epoch: 116| Step: 0
Training loss: 2.9437549114227295
Validation loss: 2.3189711288739274

Epoch: 6| Step: 1
Training loss: 2.2686004638671875
Validation loss: 2.3185669811823035

Epoch: 6| Step: 2
Training loss: 2.636629104614258
Validation loss: 2.3190184972619496

Epoch: 6| Step: 3
Training loss: 2.8966121673583984
Validation loss: 2.3167934520270235

Epoch: 6| Step: 4
Training loss: 2.625352382659912
Validation loss: 2.3138430246742825

Epoch: 6| Step: 5
Training loss: 2.302891254425049
Validation loss: 2.3098579581065843

Epoch: 6| Step: 6
Training loss: 2.831271171569824
Validation loss: 2.3187597567035305

Epoch: 6| Step: 7
Training loss: 3.0705223083496094
Validation loss: 2.333245946514991

Epoch: 6| Step: 8
Training loss: 2.782113790512085
Validation loss: 2.356249709283152

Epoch: 6| Step: 9
Training loss: 2.3606536388397217
Validation loss: 2.3792269870799077

Epoch: 6| Step: 10
Training loss: 2.401815414428711
Validation loss: 2.3847918202800136

Epoch: 6| Step: 11
Training loss: 3.3035929203033447
Validation loss: 2.379997453381938

Epoch: 6| Step: 12
Training loss: 1.4050774574279785
Validation loss: 2.3647931365556616

Epoch: 6| Step: 13
Training loss: 2.5215470790863037
Validation loss: 2.3511888724501415

Epoch: 117| Step: 0
Training loss: 3.1851227283477783
Validation loss: 2.3373689190033944

Epoch: 6| Step: 1
Training loss: 2.070577621459961
Validation loss: 2.334630008666746

Epoch: 6| Step: 2
Training loss: 2.3260116577148438
Validation loss: 2.339096215463454

Epoch: 6| Step: 3
Training loss: 2.2322163581848145
Validation loss: 2.334857274127263

Epoch: 6| Step: 4
Training loss: 2.9598793983459473
Validation loss: 2.347003324057466

Epoch: 6| Step: 5
Training loss: 2.305850028991699
Validation loss: 2.3516265910158873

Epoch: 6| Step: 6
Training loss: 2.680158853530884
Validation loss: 2.3557390038685133

Epoch: 6| Step: 7
Training loss: 3.013528823852539
Validation loss: 2.3670944962450253

Epoch: 6| Step: 8
Training loss: 2.7400388717651367
Validation loss: 2.3690776158404607

Epoch: 6| Step: 9
Training loss: 2.96563458442688
Validation loss: 2.3822309765764462

Epoch: 6| Step: 10
Training loss: 2.74475359916687
Validation loss: 2.3844716420737644

Epoch: 6| Step: 11
Training loss: 1.9071789979934692
Validation loss: 2.376985380726476

Epoch: 6| Step: 12
Training loss: 2.701572895050049
Validation loss: 2.3729112789195073

Epoch: 6| Step: 13
Training loss: 2.3542277812957764
Validation loss: 2.3502274405571724

Epoch: 118| Step: 0
Training loss: 2.6483843326568604
Validation loss: 2.3368192565056587

Epoch: 6| Step: 1
Training loss: 2.4921395778656006
Validation loss: 2.330552037044238

Epoch: 6| Step: 2
Training loss: 3.1419126987457275
Validation loss: 2.33775923585379

Epoch: 6| Step: 3
Training loss: 2.4377245903015137
Validation loss: 2.3357304027003627

Epoch: 6| Step: 4
Training loss: 1.5941556692123413
Validation loss: 2.328986503744638

Epoch: 6| Step: 5
Training loss: 2.7832114696502686
Validation loss: 2.328912934949321

Epoch: 6| Step: 6
Training loss: 2.8477396965026855
Validation loss: 2.327033040344074

Epoch: 6| Step: 7
Training loss: 2.3999807834625244
Validation loss: 2.3227716210067912

Epoch: 6| Step: 8
Training loss: 2.9216747283935547
Validation loss: 2.319467544555664

Epoch: 6| Step: 9
Training loss: 2.7308435440063477
Validation loss: 2.3214962097906295

Epoch: 6| Step: 10
Training loss: 2.814271926879883
Validation loss: 2.309370171639227

Epoch: 6| Step: 11
Training loss: 2.833765983581543
Validation loss: 2.321965550863615

Epoch: 6| Step: 12
Training loss: 2.47739839553833
Validation loss: 2.326435544157541

Epoch: 6| Step: 13
Training loss: 1.528070330619812
Validation loss: 2.315260641036495

Epoch: 119| Step: 0
Training loss: 2.425212860107422
Validation loss: 2.3159754750549153

Epoch: 6| Step: 1
Training loss: 2.4246277809143066
Validation loss: 2.31544755863887

Epoch: 6| Step: 2
Training loss: 2.9581241607666016
Validation loss: 2.3173511643563547

Epoch: 6| Step: 3
Training loss: 2.7518796920776367
Validation loss: 2.3149561010381228

Epoch: 6| Step: 4
Training loss: 3.11008882522583
Validation loss: 2.3144279910672094

Epoch: 6| Step: 5
Training loss: 2.6870248317718506
Validation loss: 2.318448225657145

Epoch: 6| Step: 6
Training loss: 3.1188578605651855
Validation loss: 2.311160707986483

Epoch: 6| Step: 7
Training loss: 2.5610244274139404
Validation loss: 2.308983774595363

Epoch: 6| Step: 8
Training loss: 2.564714193344116
Validation loss: 2.3059089747808312

Epoch: 6| Step: 9
Training loss: 2.2807679176330566
Validation loss: 2.3055909782327633

Epoch: 6| Step: 10
Training loss: 2.1165740489959717
Validation loss: 2.306739409764608

Epoch: 6| Step: 11
Training loss: 2.2576398849487305
Validation loss: 2.3139617007265807

Epoch: 6| Step: 12
Training loss: 2.283538341522217
Validation loss: 2.313674326865904

Epoch: 6| Step: 13
Training loss: 2.4091875553131104
Validation loss: 2.3258872391075216

Epoch: 120| Step: 0
Training loss: 1.9742789268493652
Validation loss: 2.3389330371733634

Epoch: 6| Step: 1
Training loss: 3.0845792293548584
Validation loss: 2.3488164845333306

Epoch: 6| Step: 2
Training loss: 3.0660808086395264
Validation loss: 2.3514764103838193

Epoch: 6| Step: 3
Training loss: 3.292423963546753
Validation loss: 2.3247699455548356

Epoch: 6| Step: 4
Training loss: 2.644826889038086
Validation loss: 2.3225243758129817

Epoch: 6| Step: 5
Training loss: 2.3960399627685547
Validation loss: 2.31975039615426

Epoch: 6| Step: 6
Training loss: 2.548584461212158
Validation loss: 2.310660708335138

Epoch: 6| Step: 7
Training loss: 2.9982852935791016
Validation loss: 2.3027961023392214

Epoch: 6| Step: 8
Training loss: 1.79532790184021
Validation loss: 2.2999370533932924

Epoch: 6| Step: 9
Training loss: 2.749561309814453
Validation loss: 2.302984570944181

Epoch: 6| Step: 10
Training loss: 2.2353227138519287
Validation loss: 2.3000904129397486

Epoch: 6| Step: 11
Training loss: 2.8867366313934326
Validation loss: 2.296260259484732

Epoch: 6| Step: 12
Training loss: 2.238097906112671
Validation loss: 2.2969350404636835

Epoch: 6| Step: 13
Training loss: 1.936280369758606
Validation loss: 2.2997800175861647

Epoch: 121| Step: 0
Training loss: 2.3079278469085693
Validation loss: 2.3006034422946233

Epoch: 6| Step: 1
Training loss: 3.051455020904541
Validation loss: 2.2985431173796296

Epoch: 6| Step: 2
Training loss: 2.0795111656188965
Validation loss: 2.298774693601875

Epoch: 6| Step: 3
Training loss: 2.9801065921783447
Validation loss: 2.3073954351486696

Epoch: 6| Step: 4
Training loss: 2.7137575149536133
Validation loss: 2.3163037389837284

Epoch: 6| Step: 5
Training loss: 2.3882546424865723
Validation loss: 2.3412427158765894

Epoch: 6| Step: 6
Training loss: 2.1206517219543457
Validation loss: 2.3695315058513353

Epoch: 6| Step: 7
Training loss: 2.461172103881836
Validation loss: 2.3773885696165022

Epoch: 6| Step: 8
Training loss: 2.6945223808288574
Validation loss: 2.3893872666102585

Epoch: 6| Step: 9
Training loss: 3.141005754470825
Validation loss: 2.3999902586783133

Epoch: 6| Step: 10
Training loss: 2.957108974456787
Validation loss: 2.369123471680508

Epoch: 6| Step: 11
Training loss: 1.8705145120620728
Validation loss: 2.3361093818500476

Epoch: 6| Step: 12
Training loss: 3.0628292560577393
Validation loss: 2.324068033567039

Epoch: 6| Step: 13
Training loss: 2.0434646606445312
Validation loss: 2.314447036353491

Epoch: 122| Step: 0
Training loss: 2.729343891143799
Validation loss: 2.3133697535402034

Epoch: 6| Step: 1
Training loss: 2.0475146770477295
Validation loss: 2.311824280728576

Epoch: 6| Step: 2
Training loss: 3.2233524322509766
Validation loss: 2.3054958440924205

Epoch: 6| Step: 3
Training loss: 3.1455507278442383
Validation loss: 2.3215022305006623

Epoch: 6| Step: 4
Training loss: 2.6964497566223145
Validation loss: 2.3250684994523243

Epoch: 6| Step: 5
Training loss: 2.3727169036865234
Validation loss: 2.330810723766204

Epoch: 6| Step: 6
Training loss: 1.9249818325042725
Validation loss: 2.320839435823502

Epoch: 6| Step: 7
Training loss: 3.2183544635772705
Validation loss: 2.3186138676058863

Epoch: 6| Step: 8
Training loss: 2.28472900390625
Validation loss: 2.3049053940721738

Epoch: 6| Step: 9
Training loss: 2.1747231483459473
Validation loss: 2.302865171945223

Epoch: 6| Step: 10
Training loss: 2.264235734939575
Validation loss: 2.29496737962128

Epoch: 6| Step: 11
Training loss: 2.0776867866516113
Validation loss: 2.294131258482574

Epoch: 6| Step: 12
Training loss: 2.576333522796631
Validation loss: 2.293511131758331

Epoch: 6| Step: 13
Training loss: 3.700467348098755
Validation loss: 2.291812407073154

Epoch: 123| Step: 0
Training loss: 2.4098238945007324
Validation loss: 2.2958465904317875

Epoch: 6| Step: 1
Training loss: 2.4251809120178223
Validation loss: 2.2891966540326356

Epoch: 6| Step: 2
Training loss: 2.199453592300415
Validation loss: 2.2886391250036096

Epoch: 6| Step: 3
Training loss: 2.46453595161438
Validation loss: 2.2879117304278958

Epoch: 6| Step: 4
Training loss: 2.3141140937805176
Validation loss: 2.3217950072339786

Epoch: 6| Step: 5
Training loss: 3.081007719039917
Validation loss: 2.335451349135368

Epoch: 6| Step: 6
Training loss: 2.9356303215026855
Validation loss: 2.367995346746137

Epoch: 6| Step: 7
Training loss: 2.419813632965088
Validation loss: 2.3743732795920423

Epoch: 6| Step: 8
Training loss: 3.031808376312256
Validation loss: 2.380898029573502

Epoch: 6| Step: 9
Training loss: 2.2776598930358887
Validation loss: 2.381176951111004

Epoch: 6| Step: 10
Training loss: 2.372760772705078
Validation loss: 2.3683802363693074

Epoch: 6| Step: 11
Training loss: 3.245433807373047
Validation loss: 2.3604363497867378

Epoch: 6| Step: 12
Training loss: 2.1192216873168945
Validation loss: 2.366466106907014

Epoch: 6| Step: 13
Training loss: 2.645932197570801
Validation loss: 2.387613957928073

Epoch: 124| Step: 0
Training loss: 2.2507071495056152
Validation loss: 2.375382836147021

Epoch: 6| Step: 1
Training loss: 3.023824691772461
Validation loss: 2.3630488072672198

Epoch: 6| Step: 2
Training loss: 2.93914794921875
Validation loss: 2.3533082610817364

Epoch: 6| Step: 3
Training loss: 2.00321102142334
Validation loss: 2.3382066142174507

Epoch: 6| Step: 4
Training loss: 1.9974912405014038
Validation loss: 2.321228401635283

Epoch: 6| Step: 5
Training loss: 2.5746560096740723
Validation loss: 2.312781218559511

Epoch: 6| Step: 6
Training loss: 2.2344141006469727
Validation loss: 2.318409594156409

Epoch: 6| Step: 7
Training loss: 2.9474198818206787
Validation loss: 2.3060159785773164

Epoch: 6| Step: 8
Training loss: 2.966566801071167
Validation loss: 2.29994709004638

Epoch: 6| Step: 9
Training loss: 2.70432186126709
Validation loss: 2.2938096087466002

Epoch: 6| Step: 10
Training loss: 2.670037269592285
Validation loss: 2.292516598137476

Epoch: 6| Step: 11
Training loss: 2.3182199001312256
Validation loss: 2.2836366776497132

Epoch: 6| Step: 12
Training loss: 2.9131526947021484
Validation loss: 2.2802916778031217

Epoch: 6| Step: 13
Training loss: 2.108945369720459
Validation loss: 2.292348579693866

Epoch: 125| Step: 0
Training loss: 2.2079219818115234
Validation loss: 2.2847417041819584

Epoch: 6| Step: 1
Training loss: 2.23720383644104
Validation loss: 2.296616195350565

Epoch: 6| Step: 2
Training loss: 2.260951042175293
Validation loss: 2.313444865647183

Epoch: 6| Step: 3
Training loss: 1.978806495666504
Validation loss: 2.3281379079306

Epoch: 6| Step: 4
Training loss: 2.293280601501465
Validation loss: 2.3324706374957995

Epoch: 6| Step: 5
Training loss: 2.8542261123657227
Validation loss: 2.336189695583877

Epoch: 6| Step: 6
Training loss: 3.1944990158081055
Validation loss: 2.3562831660752654

Epoch: 6| Step: 7
Training loss: 3.1368250846862793
Validation loss: 2.394184043330531

Epoch: 6| Step: 8
Training loss: 2.4270224571228027
Validation loss: 2.3963285620494554

Epoch: 6| Step: 9
Training loss: 2.4445364475250244
Validation loss: 2.3893093498804236

Epoch: 6| Step: 10
Training loss: 2.727245807647705
Validation loss: 2.391739555584487

Epoch: 6| Step: 11
Training loss: 2.648573637008667
Validation loss: 2.356396762273645

Epoch: 6| Step: 12
Training loss: 2.672881603240967
Validation loss: 2.353753323196083

Epoch: 6| Step: 13
Training loss: 3.222071647644043
Validation loss: 2.3241254078444613

Epoch: 126| Step: 0
Training loss: 1.9830005168914795
Validation loss: 2.301205345379409

Epoch: 6| Step: 1
Training loss: 2.5883471965789795
Validation loss: 2.2893765408505677

Epoch: 6| Step: 2
Training loss: 2.605771541595459
Validation loss: 2.284788659823838

Epoch: 6| Step: 3
Training loss: 2.436965227127075
Validation loss: 2.2812081575393677

Epoch: 6| Step: 4
Training loss: 2.8063764572143555
Validation loss: 2.2889380967745216

Epoch: 6| Step: 5
Training loss: 2.786951780319214
Validation loss: 2.298386986537646

Epoch: 6| Step: 6
Training loss: 2.0758121013641357
Validation loss: 2.30851048807944

Epoch: 6| Step: 7
Training loss: 2.8868770599365234
Validation loss: 2.3308774373864614

Epoch: 6| Step: 8
Training loss: 2.407174587249756
Validation loss: 2.32151000730453

Epoch: 6| Step: 9
Training loss: 2.8025474548339844
Validation loss: 2.290012263482617

Epoch: 6| Step: 10
Training loss: 2.6799721717834473
Validation loss: 2.2757684364113757

Epoch: 6| Step: 11
Training loss: 2.434130907058716
Validation loss: 2.28854941039957

Epoch: 6| Step: 12
Training loss: 3.2701823711395264
Validation loss: 2.337372015881282

Epoch: 6| Step: 13
Training loss: 2.3364267349243164
Validation loss: 2.3582141476292766

Epoch: 127| Step: 0
Training loss: 2.154465913772583
Validation loss: 2.3991716061868975

Epoch: 6| Step: 1
Training loss: 3.3916304111480713
Validation loss: 2.439521335786389

Epoch: 6| Step: 2
Training loss: 2.6510379314422607
Validation loss: 2.4755812357830744

Epoch: 6| Step: 3
Training loss: 2.2081499099731445
Validation loss: 2.458366286370062

Epoch: 6| Step: 4
Training loss: 1.8762391805648804
Validation loss: 2.3956488486259215

Epoch: 6| Step: 5
Training loss: 1.9477407932281494
Validation loss: 2.3897213756397204

Epoch: 6| Step: 6
Training loss: 3.172166585922241
Validation loss: 2.3894583102195495

Epoch: 6| Step: 7
Training loss: 3.3150081634521484
Validation loss: 2.374220214864259

Epoch: 6| Step: 8
Training loss: 2.786419630050659
Validation loss: 2.3371830909482894

Epoch: 6| Step: 9
Training loss: 2.761678457260132
Validation loss: 2.3094571918569584

Epoch: 6| Step: 10
Training loss: 2.3488411903381348
Validation loss: 2.304945550939088

Epoch: 6| Step: 11
Training loss: 3.251229763031006
Validation loss: 2.3000316568600234

Epoch: 6| Step: 12
Training loss: 2.0070457458496094
Validation loss: 2.2957220231333086

Epoch: 6| Step: 13
Training loss: 2.3956525325775146
Validation loss: 2.2966641277395268

Epoch: 128| Step: 0
Training loss: 2.12349271774292
Validation loss: 2.2973895047300603

Epoch: 6| Step: 1
Training loss: 2.742352247238159
Validation loss: 2.3015226215444584

Epoch: 6| Step: 2
Training loss: 2.492176055908203
Validation loss: 2.3116953039682038

Epoch: 6| Step: 3
Training loss: 2.188150405883789
Validation loss: 2.31687686263874

Epoch: 6| Step: 4
Training loss: 3.082094192504883
Validation loss: 2.3194943845912976

Epoch: 6| Step: 5
Training loss: 2.70554780960083
Validation loss: 2.318075967091386

Epoch: 6| Step: 6
Training loss: 2.956171989440918
Validation loss: 2.3277925496460288

Epoch: 6| Step: 7
Training loss: 2.6598854064941406
Validation loss: 2.3274153124901558

Epoch: 6| Step: 8
Training loss: 2.6839284896850586
Validation loss: 2.3204879863287813

Epoch: 6| Step: 9
Training loss: 2.9195451736450195
Validation loss: 2.3245367362935054

Epoch: 6| Step: 10
Training loss: 2.488708019256592
Validation loss: 2.323500656312512

Epoch: 6| Step: 11
Training loss: 1.5879842042922974
Validation loss: 2.332230524350238

Epoch: 6| Step: 12
Training loss: 2.5437800884246826
Validation loss: 2.332210333116593

Epoch: 6| Step: 13
Training loss: 2.6735613346099854
Validation loss: 2.3424803903025966

Epoch: 129| Step: 0
Training loss: 2.5184125900268555
Validation loss: 2.333355447297455

Epoch: 6| Step: 1
Training loss: 2.262852191925049
Validation loss: 2.3315436660602527

Epoch: 6| Step: 2
Training loss: 2.3236851692199707
Validation loss: 2.3322187264760337

Epoch: 6| Step: 3
Training loss: 3.030733346939087
Validation loss: 2.3332045180823213

Epoch: 6| Step: 4
Training loss: 2.450331449508667
Validation loss: 2.3324397148624545

Epoch: 6| Step: 5
Training loss: 2.5715689659118652
Validation loss: 2.328269530368108

Epoch: 6| Step: 6
Training loss: 2.668731689453125
Validation loss: 2.3247266046462522

Epoch: 6| Step: 7
Training loss: 2.5965049266815186
Validation loss: 2.324763439034903

Epoch: 6| Step: 8
Training loss: 1.785642385482788
Validation loss: 2.3006899818297355

Epoch: 6| Step: 9
Training loss: 1.8624262809753418
Validation loss: 2.2934283671840543

Epoch: 6| Step: 10
Training loss: 2.717061996459961
Validation loss: 2.293810003547258

Epoch: 6| Step: 11
Training loss: 3.1119534969329834
Validation loss: 2.2844450730149464

Epoch: 6| Step: 12
Training loss: 2.999185085296631
Validation loss: 2.2687248568381033

Epoch: 6| Step: 13
Training loss: 3.0162222385406494
Validation loss: 2.271968836425453

Epoch: 130| Step: 0
Training loss: 2.5597989559173584
Validation loss: 2.2699306190654798

Epoch: 6| Step: 1
Training loss: 2.7444205284118652
Validation loss: 2.276604690859395

Epoch: 6| Step: 2
Training loss: 2.806816577911377
Validation loss: 2.2794944906747467

Epoch: 6| Step: 3
Training loss: 2.63967227935791
Validation loss: 2.2816870417646182

Epoch: 6| Step: 4
Training loss: 2.793239116668701
Validation loss: 2.2823254510920536

Epoch: 6| Step: 5
Training loss: 1.9532065391540527
Validation loss: 2.275488697072511

Epoch: 6| Step: 6
Training loss: 2.6026926040649414
Validation loss: 2.2843512258222027

Epoch: 6| Step: 7
Training loss: 2.3562142848968506
Validation loss: 2.2870640959790958

Epoch: 6| Step: 8
Training loss: 2.326770067214966
Validation loss: 2.2918524101216304

Epoch: 6| Step: 9
Training loss: 2.064692258834839
Validation loss: 2.288889338893275

Epoch: 6| Step: 10
Training loss: 2.310720920562744
Validation loss: 2.2884158524133826

Epoch: 6| Step: 11
Training loss: 3.4142563343048096
Validation loss: 2.2858099655438493

Epoch: 6| Step: 12
Training loss: 2.7870945930480957
Validation loss: 2.2871335244947866

Epoch: 6| Step: 13
Training loss: 1.9451552629470825
Validation loss: 2.282331589729555

Epoch: 131| Step: 0
Training loss: 2.6809253692626953
Validation loss: 2.2883227743128294

Epoch: 6| Step: 1
Training loss: 2.4399914741516113
Validation loss: 2.287285645802816

Epoch: 6| Step: 2
Training loss: 2.5483686923980713
Validation loss: 2.2970608742006364

Epoch: 6| Step: 3
Training loss: 2.0540668964385986
Validation loss: 2.3118484250960813

Epoch: 6| Step: 4
Training loss: 2.3182315826416016
Validation loss: 2.3116465307051137

Epoch: 6| Step: 5
Training loss: 2.652848720550537
Validation loss: 2.2951991250438075

Epoch: 6| Step: 6
Training loss: 2.4160022735595703
Validation loss: 2.2760202935946885

Epoch: 6| Step: 7
Training loss: 2.4855055809020996
Validation loss: 2.269137118452339

Epoch: 6| Step: 8
Training loss: 2.8577394485473633
Validation loss: 2.2655688434518795

Epoch: 6| Step: 9
Training loss: 3.3033509254455566
Validation loss: 2.2752958677148305

Epoch: 6| Step: 10
Training loss: 2.985612392425537
Validation loss: 2.273431072952927

Epoch: 6| Step: 11
Training loss: 2.4202382564544678
Validation loss: 2.2768368028825328

Epoch: 6| Step: 12
Training loss: 1.8550490140914917
Validation loss: 2.2845191904293594

Epoch: 6| Step: 13
Training loss: 2.4723310470581055
Validation loss: 2.2967558394196215

Epoch: 132| Step: 0
Training loss: 2.6235713958740234
Validation loss: 2.302677498068861

Epoch: 6| Step: 1
Training loss: 2.363251209259033
Validation loss: 2.329836896670762

Epoch: 6| Step: 2
Training loss: 2.661581516265869
Validation loss: 2.3486070094570035

Epoch: 6| Step: 3
Training loss: 2.7492408752441406
Validation loss: 2.3545962033733243

Epoch: 6| Step: 4
Training loss: 1.825974702835083
Validation loss: 2.3582454471177954

Epoch: 6| Step: 5
Training loss: 2.633612632751465
Validation loss: 2.3481708957302954

Epoch: 6| Step: 6
Training loss: 2.8911643028259277
Validation loss: 2.3204634471606185

Epoch: 6| Step: 7
Training loss: 2.040750026702881
Validation loss: 2.320404465480517

Epoch: 6| Step: 8
Training loss: 2.3379859924316406
Validation loss: 2.3177089511707263

Epoch: 6| Step: 9
Training loss: 3.163111686706543
Validation loss: 2.3216941356658936

Epoch: 6| Step: 10
Training loss: 2.9015886783599854
Validation loss: 2.321951368803619

Epoch: 6| Step: 11
Training loss: 2.6423566341400146
Validation loss: 2.320702075958252

Epoch: 6| Step: 12
Training loss: 2.709792137145996
Validation loss: 2.3228979572173087

Epoch: 6| Step: 13
Training loss: 1.6698622703552246
Validation loss: 2.3093255155829975

Epoch: 133| Step: 0
Training loss: 2.54071044921875
Validation loss: 2.2976230344464703

Epoch: 6| Step: 1
Training loss: 2.3614940643310547
Validation loss: 2.291481028320969

Epoch: 6| Step: 2
Training loss: 2.741478204727173
Validation loss: 2.2962325849840717

Epoch: 6| Step: 3
Training loss: 2.3575663566589355
Validation loss: 2.3050838516604517

Epoch: 6| Step: 4
Training loss: 2.9505767822265625
Validation loss: 2.3178167445685274

Epoch: 6| Step: 5
Training loss: 2.603863000869751
Validation loss: 2.3036724187994517

Epoch: 6| Step: 6
Training loss: 2.6959028244018555
Validation loss: 2.2888062179729505

Epoch: 6| Step: 7
Training loss: 2.302994728088379
Validation loss: 2.277580258666828

Epoch: 6| Step: 8
Training loss: 3.0618584156036377
Validation loss: 2.2731833175946305

Epoch: 6| Step: 9
Training loss: 2.3353796005249023
Validation loss: 2.2778663712163127

Epoch: 6| Step: 10
Training loss: 2.4107770919799805
Validation loss: 2.285520940698603

Epoch: 6| Step: 11
Training loss: 1.985448956489563
Validation loss: 2.286837677801809

Epoch: 6| Step: 12
Training loss: 2.822173595428467
Validation loss: 2.3040137239681777

Epoch: 6| Step: 13
Training loss: 3.1811132431030273
Validation loss: 2.316325613247451

Epoch: 134| Step: 0
Training loss: 2.6632895469665527
Validation loss: 2.3500134996188584

Epoch: 6| Step: 1
Training loss: 2.966146230697632
Validation loss: 2.34989099092381

Epoch: 6| Step: 2
Training loss: 2.5586090087890625
Validation loss: 2.364836485155167

Epoch: 6| Step: 3
Training loss: 2.167412281036377
Validation loss: 2.3977881323906685

Epoch: 6| Step: 4
Training loss: 2.644559860229492
Validation loss: 2.4238887756101546

Epoch: 6| Step: 5
Training loss: 3.2190873622894287
Validation loss: 2.424414104030978

Epoch: 6| Step: 6
Training loss: 2.3795671463012695
Validation loss: 2.3642893119524886

Epoch: 6| Step: 7
Training loss: 2.8508076667785645
Validation loss: 2.3313459042579896

Epoch: 6| Step: 8
Training loss: 2.470167636871338
Validation loss: 2.2901215168737594

Epoch: 6| Step: 9
Training loss: 2.7277534008026123
Validation loss: 2.282617517696914

Epoch: 6| Step: 10
Training loss: 2.5606799125671387
Validation loss: 2.277518287781746

Epoch: 6| Step: 11
Training loss: 1.8277199268341064
Validation loss: 2.264144676987843

Epoch: 6| Step: 12
Training loss: 2.461761951446533
Validation loss: 2.262989810718003

Epoch: 6| Step: 13
Training loss: 1.595715045928955
Validation loss: 2.259197973435925

Epoch: 135| Step: 0
Training loss: 3.6333096027374268
Validation loss: 2.2616227698582474

Epoch: 6| Step: 1
Training loss: 1.7688968181610107
Validation loss: 2.258008958191

Epoch: 6| Step: 2
Training loss: 2.6599292755126953
Validation loss: 2.261943619738343

Epoch: 6| Step: 3
Training loss: 2.548069477081299
Validation loss: 2.2629648459854947

Epoch: 6| Step: 4
Training loss: 2.725522994995117
Validation loss: 2.263048193788016

Epoch: 6| Step: 5
Training loss: 2.0243427753448486
Validation loss: 2.2615126230383433

Epoch: 6| Step: 6
Training loss: 2.6184866428375244
Validation loss: 2.2582957462597917

Epoch: 6| Step: 7
Training loss: 2.5079665184020996
Validation loss: 2.2590641616493143

Epoch: 6| Step: 8
Training loss: 2.5725250244140625
Validation loss: 2.26484316138811

Epoch: 6| Step: 9
Training loss: 2.513741970062256
Validation loss: 2.273759342009021

Epoch: 6| Step: 10
Training loss: 2.3601269721984863
Validation loss: 2.2899437847957818

Epoch: 6| Step: 11
Training loss: 2.663787841796875
Validation loss: 2.3054107542960875

Epoch: 6| Step: 12
Training loss: 2.5257067680358887
Validation loss: 2.3335428058460193

Epoch: 6| Step: 13
Training loss: 2.3077991008758545
Validation loss: 2.3555832652635473

Epoch: 136| Step: 0
Training loss: 2.611987590789795
Validation loss: 2.360842932936966

Epoch: 6| Step: 1
Training loss: 2.8093156814575195
Validation loss: 2.323097348213196

Epoch: 6| Step: 2
Training loss: 2.8675594329833984
Validation loss: 2.307991382896259

Epoch: 6| Step: 3
Training loss: 3.08776593208313
Validation loss: 2.290394990674911

Epoch: 6| Step: 4
Training loss: 2.450629711151123
Validation loss: 2.2782687064140075

Epoch: 6| Step: 5
Training loss: 2.661384105682373
Validation loss: 2.26333107999576

Epoch: 6| Step: 6
Training loss: 2.2553462982177734
Validation loss: 2.2593842924282117

Epoch: 6| Step: 7
Training loss: 2.3183798789978027
Validation loss: 2.2550428580212336

Epoch: 6| Step: 8
Training loss: 2.59242582321167
Validation loss: 2.258169904831917

Epoch: 6| Step: 9
Training loss: 1.8677241802215576
Validation loss: 2.2555570769053634

Epoch: 6| Step: 10
Training loss: 2.5230588912963867
Validation loss: 2.254378549514278

Epoch: 6| Step: 11
Training loss: 2.907101631164551
Validation loss: 2.2576211319174817

Epoch: 6| Step: 12
Training loss: 2.1584067344665527
Validation loss: 2.2514979941870576

Epoch: 6| Step: 13
Training loss: 2.220311403274536
Validation loss: 2.257249834716961

Epoch: 137| Step: 0
Training loss: 3.4679012298583984
Validation loss: 2.2747487047667145

Epoch: 6| Step: 1
Training loss: 2.9286513328552246
Validation loss: 2.2752759072088424

Epoch: 6| Step: 2
Training loss: 2.0146560668945312
Validation loss: 2.2812778847191924

Epoch: 6| Step: 3
Training loss: 2.420710802078247
Validation loss: 2.290759084045246

Epoch: 6| Step: 4
Training loss: 1.793416142463684
Validation loss: 2.305617206840105

Epoch: 6| Step: 5
Training loss: 2.422412395477295
Validation loss: 2.3151727568718696

Epoch: 6| Step: 6
Training loss: 2.8272886276245117
Validation loss: 2.320887096466557

Epoch: 6| Step: 7
Training loss: 2.409618616104126
Validation loss: 2.3282362414944555

Epoch: 6| Step: 8
Training loss: 2.5363855361938477
Validation loss: 2.314412698950819

Epoch: 6| Step: 9
Training loss: 2.851555347442627
Validation loss: 2.289644741242932

Epoch: 6| Step: 10
Training loss: 2.8331308364868164
Validation loss: 2.268608106079922

Epoch: 6| Step: 11
Training loss: 2.4255013465881348
Validation loss: 2.2557695065775225

Epoch: 6| Step: 12
Training loss: 2.203747272491455
Validation loss: 2.253951786666788

Epoch: 6| Step: 13
Training loss: 2.1584653854370117
Validation loss: 2.2545481548514417

Epoch: 138| Step: 0
Training loss: 2.4739882946014404
Validation loss: 2.2624890855563584

Epoch: 6| Step: 1
Training loss: 1.9063018560409546
Validation loss: 2.269729914203767

Epoch: 6| Step: 2
Training loss: 2.765073776245117
Validation loss: 2.273294097633772

Epoch: 6| Step: 3
Training loss: 1.7205880880355835
Validation loss: 2.2760158610600296

Epoch: 6| Step: 4
Training loss: 2.6889286041259766
Validation loss: 2.2812996782282347

Epoch: 6| Step: 5
Training loss: 2.976155996322632
Validation loss: 2.2871613399956816

Epoch: 6| Step: 6
Training loss: 2.845566749572754
Validation loss: 2.297987778981527

Epoch: 6| Step: 7
Training loss: 2.317065715789795
Validation loss: 2.300786446499568

Epoch: 6| Step: 8
Training loss: 2.987724781036377
Validation loss: 2.3021009378535773

Epoch: 6| Step: 9
Training loss: 2.5376601219177246
Validation loss: 2.3053295573880597

Epoch: 6| Step: 10
Training loss: 1.617952585220337
Validation loss: 2.30320768971597

Epoch: 6| Step: 11
Training loss: 2.4783623218536377
Validation loss: 2.2992569220963346

Epoch: 6| Step: 12
Training loss: 2.9288647174835205
Validation loss: 2.296201200895412

Epoch: 6| Step: 13
Training loss: 3.5226364135742188
Validation loss: 2.289834204540458

Epoch: 139| Step: 0
Training loss: 2.3919730186462402
Validation loss: 2.2834333155744817

Epoch: 6| Step: 1
Training loss: 3.6717615127563477
Validation loss: 2.275913094961515

Epoch: 6| Step: 2
Training loss: 2.591747283935547
Validation loss: 2.2695824228307253

Epoch: 6| Step: 3
Training loss: 2.2311344146728516
Validation loss: 2.26141684286056

Epoch: 6| Step: 4
Training loss: 2.572659969329834
Validation loss: 2.272416112243488

Epoch: 6| Step: 5
Training loss: 2.096043586730957
Validation loss: 2.261460606769849

Epoch: 6| Step: 6
Training loss: 1.5112433433532715
Validation loss: 2.257262155573855

Epoch: 6| Step: 7
Training loss: 3.0105814933776855
Validation loss: 2.259149561646164

Epoch: 6| Step: 8
Training loss: 2.1319549083709717
Validation loss: 2.255701880301199

Epoch: 6| Step: 9
Training loss: 2.3289780616760254
Validation loss: 2.2496116238255657

Epoch: 6| Step: 10
Training loss: 2.0372629165649414
Validation loss: 2.2634284662944015

Epoch: 6| Step: 11
Training loss: 3.28409481048584
Validation loss: 2.2602970356582315

Epoch: 6| Step: 12
Training loss: 3.0086569786071777
Validation loss: 2.268942972665192

Epoch: 6| Step: 13
Training loss: 2.3170995712280273
Validation loss: 2.2710732798422537

Epoch: 140| Step: 0
Training loss: 2.9976463317871094
Validation loss: 2.2854290470000236

Epoch: 6| Step: 1
Training loss: 2.3223876953125
Validation loss: 2.289436230095484

Epoch: 6| Step: 2
Training loss: 2.878694772720337
Validation loss: 2.3093618346798803

Epoch: 6| Step: 3
Training loss: 2.7017579078674316
Validation loss: 2.335643611928468

Epoch: 6| Step: 4
Training loss: 2.386059284210205
Validation loss: 2.3146644740976314

Epoch: 6| Step: 5
Training loss: 2.4365639686584473
Validation loss: 2.313304421722248

Epoch: 6| Step: 6
Training loss: 2.742748975753784
Validation loss: 2.3088981874527468

Epoch: 6| Step: 7
Training loss: 2.587763786315918
Validation loss: 2.295741165837934

Epoch: 6| Step: 8
Training loss: 2.166294574737549
Validation loss: 2.2818646764242523

Epoch: 6| Step: 9
Training loss: 2.4498705863952637
Validation loss: 2.2697712862363426

Epoch: 6| Step: 10
Training loss: 2.075395107269287
Validation loss: 2.2720893506080873

Epoch: 6| Step: 11
Training loss: 2.1956403255462646
Validation loss: 2.268473517510199

Epoch: 6| Step: 12
Training loss: 2.5210018157958984
Validation loss: 2.2751730898375153

Epoch: 6| Step: 13
Training loss: 2.770484209060669
Validation loss: 2.277695091821814

Epoch: 141| Step: 0
Training loss: 2.522523880004883
Validation loss: 2.276877862150951

Epoch: 6| Step: 1
Training loss: 2.3071446418762207
Validation loss: 2.2852483821171585

Epoch: 6| Step: 2
Training loss: 2.2329883575439453
Validation loss: 2.2959927307662142

Epoch: 6| Step: 3
Training loss: 2.3484108448028564
Validation loss: 2.301061281593897

Epoch: 6| Step: 4
Training loss: 2.5399527549743652
Validation loss: 2.3080510593229726

Epoch: 6| Step: 5
Training loss: 3.2078380584716797
Validation loss: 2.30640729524756

Epoch: 6| Step: 6
Training loss: 2.4464645385742188
Validation loss: 2.307213537154659

Epoch: 6| Step: 7
Training loss: 2.8507120609283447
Validation loss: 2.3068196824801865

Epoch: 6| Step: 8
Training loss: 1.8285599946975708
Validation loss: 2.2931288185939995

Epoch: 6| Step: 9
Training loss: 2.847092866897583
Validation loss: 2.299931990203037

Epoch: 6| Step: 10
Training loss: 2.819709300994873
Validation loss: 2.29125569200003

Epoch: 6| Step: 11
Training loss: 2.62658429145813
Validation loss: 2.287481238765101

Epoch: 6| Step: 12
Training loss: 2.7040843963623047
Validation loss: 2.279362601618613

Epoch: 6| Step: 13
Training loss: 1.607092261314392
Validation loss: 2.277597540168352

Epoch: 142| Step: 0
Training loss: 2.5405707359313965
Validation loss: 2.2745847740480976

Epoch: 6| Step: 1
Training loss: 3.5596346855163574
Validation loss: 2.269737634607541

Epoch: 6| Step: 2
Training loss: 2.255077362060547
Validation loss: 2.264809795605239

Epoch: 6| Step: 3
Training loss: 3.2229974269866943
Validation loss: 2.2804071723773913

Epoch: 6| Step: 4
Training loss: 2.354800224304199
Validation loss: 2.27573739072328

Epoch: 6| Step: 5
Training loss: 2.6991031169891357
Validation loss: 2.2718278592632664

Epoch: 6| Step: 6
Training loss: 2.571317672729492
Validation loss: 2.2648569691565728

Epoch: 6| Step: 7
Training loss: 2.696915626525879
Validation loss: 2.2521114721093127

Epoch: 6| Step: 8
Training loss: 1.6214396953582764
Validation loss: 2.251115692559109

Epoch: 6| Step: 9
Training loss: 2.4312281608581543
Validation loss: 2.2440831661224365

Epoch: 6| Step: 10
Training loss: 2.5540566444396973
Validation loss: 2.239669288358381

Epoch: 6| Step: 11
Training loss: 2.781660556793213
Validation loss: 2.2502226957710842

Epoch: 6| Step: 12
Training loss: 1.8217802047729492
Validation loss: 2.264293452744843

Epoch: 6| Step: 13
Training loss: 1.7195178270339966
Validation loss: 2.2644572347723027

Epoch: 143| Step: 0
Training loss: 2.6955032348632812
Validation loss: 2.275764403804656

Epoch: 6| Step: 1
Training loss: 2.477012872695923
Validation loss: 2.2814743159919657

Epoch: 6| Step: 2
Training loss: 3.2070159912109375
Validation loss: 2.2965693576361543

Epoch: 6| Step: 3
Training loss: 2.47153377532959
Validation loss: 2.286720952680034

Epoch: 6| Step: 4
Training loss: 2.9552135467529297
Validation loss: 2.2674900485623266

Epoch: 6| Step: 5
Training loss: 1.9617888927459717
Validation loss: 2.2382668577214724

Epoch: 6| Step: 6
Training loss: 2.4469830989837646
Validation loss: 2.2267089915531937

Epoch: 6| Step: 7
Training loss: 2.902644157409668
Validation loss: 2.2292689584916636

Epoch: 6| Step: 8
Training loss: 1.9372048377990723
Validation loss: 2.230840952165665

Epoch: 6| Step: 9
Training loss: 2.9024124145507812
Validation loss: 2.231899357611133

Epoch: 6| Step: 10
Training loss: 2.1505308151245117
Validation loss: 2.227219625185895

Epoch: 6| Step: 11
Training loss: 1.7631534337997437
Validation loss: 2.2277051620585944

Epoch: 6| Step: 12
Training loss: 2.717038869857788
Validation loss: 2.233134053086722

Epoch: 6| Step: 13
Training loss: 2.4264583587646484
Validation loss: 2.2264809544368456

Epoch: 144| Step: 0
Training loss: 1.822249174118042
Validation loss: 2.232524791071492

Epoch: 6| Step: 1
Training loss: 2.318875312805176
Validation loss: 2.226645226119667

Epoch: 6| Step: 2
Training loss: 2.178579568862915
Validation loss: 2.2284224238446964

Epoch: 6| Step: 3
Training loss: 2.031923770904541
Validation loss: 2.2315782039396224

Epoch: 6| Step: 4
Training loss: 2.078218460083008
Validation loss: 2.2375945839830624

Epoch: 6| Step: 5
Training loss: 2.489122152328491
Validation loss: 2.246880973539045

Epoch: 6| Step: 6
Training loss: 2.3819591999053955
Validation loss: 2.274493848123858

Epoch: 6| Step: 7
Training loss: 3.3501157760620117
Validation loss: 2.3261759281158447

Epoch: 6| Step: 8
Training loss: 2.691344976425171
Validation loss: 2.3433682277638423

Epoch: 6| Step: 9
Training loss: 2.700624704360962
Validation loss: 2.355440419207337

Epoch: 6| Step: 10
Training loss: 2.009249448776245
Validation loss: 2.337962970938734

Epoch: 6| Step: 11
Training loss: 3.464012622833252
Validation loss: 2.3392314808343047

Epoch: 6| Step: 12
Training loss: 2.582470417022705
Validation loss: 2.2953327650664956

Epoch: 6| Step: 13
Training loss: 3.6718335151672363
Validation loss: 2.274290088684328

Epoch: 145| Step: 0
Training loss: 2.7858338356018066
Validation loss: 2.265840907250681

Epoch: 6| Step: 1
Training loss: 2.4366374015808105
Validation loss: 2.260108618326085

Epoch: 6| Step: 2
Training loss: 2.1708528995513916
Validation loss: 2.2540946673321467

Epoch: 6| Step: 3
Training loss: 3.13167667388916
Validation loss: 2.257895872157107

Epoch: 6| Step: 4
Training loss: 1.8387985229492188
Validation loss: 2.2476405046319448

Epoch: 6| Step: 5
Training loss: 2.371337652206421
Validation loss: 2.2530157104615243

Epoch: 6| Step: 6
Training loss: 2.6651771068573
Validation loss: 2.2502521545656267

Epoch: 6| Step: 7
Training loss: 3.1658716201782227
Validation loss: 2.2496326251696517

Epoch: 6| Step: 8
Training loss: 3.0998289585113525
Validation loss: 2.2463983515257477

Epoch: 6| Step: 9
Training loss: 2.450788974761963
Validation loss: 2.2481351488380024

Epoch: 6| Step: 10
Training loss: 1.9930073022842407
Validation loss: 2.239247275936988

Epoch: 6| Step: 11
Training loss: 1.7353380918502808
Validation loss: 2.250400156103155

Epoch: 6| Step: 12
Training loss: 2.69598126411438
Validation loss: 2.254934101976374

Epoch: 6| Step: 13
Training loss: 2.7407853603363037
Validation loss: 2.2662938948600524

Epoch: 146| Step: 0
Training loss: 2.8934757709503174
Validation loss: 2.268693975223008

Epoch: 6| Step: 1
Training loss: 1.5198230743408203
Validation loss: 2.277052851133449

Epoch: 6| Step: 2
Training loss: 2.5013246536254883
Validation loss: 2.271678488741639

Epoch: 6| Step: 3
Training loss: 2.145106315612793
Validation loss: 2.262723663801788

Epoch: 6| Step: 4
Training loss: 2.0914130210876465
Validation loss: 2.254605911111319

Epoch: 6| Step: 5
Training loss: 2.6288676261901855
Validation loss: 2.2491235681759414

Epoch: 6| Step: 6
Training loss: 2.828143358230591
Validation loss: 2.2539618220380557

Epoch: 6| Step: 7
Training loss: 2.0493292808532715
Validation loss: 2.2543205445812595

Epoch: 6| Step: 8
Training loss: 3.274534225463867
Validation loss: 2.258397945793726

Epoch: 6| Step: 9
Training loss: 2.4256186485290527
Validation loss: 2.24685303882886

Epoch: 6| Step: 10
Training loss: 2.9427127838134766
Validation loss: 2.259029515327946

Epoch: 6| Step: 11
Training loss: 2.13258957862854
Validation loss: 2.252945033452844

Epoch: 6| Step: 12
Training loss: 3.0751397609710693
Validation loss: 2.241795975674865

Epoch: 6| Step: 13
Training loss: 2.303680419921875
Validation loss: 2.229725096815376

Epoch: 147| Step: 0
Training loss: 2.73677396774292
Validation loss: 2.2351623812029437

Epoch: 6| Step: 1
Training loss: 1.7977890968322754
Validation loss: 2.2318291459032285

Epoch: 6| Step: 2
Training loss: 2.6353657245635986
Validation loss: 2.2530703647162325

Epoch: 6| Step: 3
Training loss: 2.2377357482910156
Validation loss: 2.274734922634658

Epoch: 6| Step: 4
Training loss: 2.3462653160095215
Validation loss: 2.288900754785025

Epoch: 6| Step: 5
Training loss: 2.815173387527466
Validation loss: 2.291169315256098

Epoch: 6| Step: 6
Training loss: 2.417384147644043
Validation loss: 2.289487869508805

Epoch: 6| Step: 7
Training loss: 2.8477988243103027
Validation loss: 2.299628629479357

Epoch: 6| Step: 8
Training loss: 2.123837947845459
Validation loss: 2.3078961167284238

Epoch: 6| Step: 9
Training loss: 2.3038766384124756
Validation loss: 2.300229526335193

Epoch: 6| Step: 10
Training loss: 2.648833751678467
Validation loss: 2.282207496704594

Epoch: 6| Step: 11
Training loss: 2.813857316970825
Validation loss: 2.2559156558846913

Epoch: 6| Step: 12
Training loss: 3.189828395843506
Validation loss: 2.249684695274599

Epoch: 6| Step: 13
Training loss: 1.9020788669586182
Validation loss: 2.241021571620818

Epoch: 148| Step: 0
Training loss: 2.9217824935913086
Validation loss: 2.229601019172258

Epoch: 6| Step: 1
Training loss: 2.105696201324463
Validation loss: 2.2288245308783745

Epoch: 6| Step: 2
Training loss: 2.5669827461242676
Validation loss: 2.230278279191704

Epoch: 6| Step: 3
Training loss: 2.0486693382263184
Validation loss: 2.224760683633948

Epoch: 6| Step: 4
Training loss: 3.0808305740356445
Validation loss: 2.2284736966574066

Epoch: 6| Step: 5
Training loss: 3.0950767993927
Validation loss: 2.2308281980535036

Epoch: 6| Step: 6
Training loss: 2.9308605194091797
Validation loss: 2.2335562757266465

Epoch: 6| Step: 7
Training loss: 2.4915826320648193
Validation loss: 2.226458490535777

Epoch: 6| Step: 8
Training loss: 2.062387466430664
Validation loss: 2.2308763611701226

Epoch: 6| Step: 9
Training loss: 2.684110641479492
Validation loss: 2.231435260465068

Epoch: 6| Step: 10
Training loss: 2.155941963195801
Validation loss: 2.229661169872489

Epoch: 6| Step: 11
Training loss: 2.05192232131958
Validation loss: 2.234856991357701

Epoch: 6| Step: 12
Training loss: 2.3528401851654053
Validation loss: 2.2366628390486523

Epoch: 6| Step: 13
Training loss: 2.3986151218414307
Validation loss: 2.239674260539393

Epoch: 149| Step: 0
Training loss: 2.525533676147461
Validation loss: 2.2511869425414712

Epoch: 6| Step: 1
Training loss: 2.7545511722564697
Validation loss: 2.2665839118342244

Epoch: 6| Step: 2
Training loss: 2.3230605125427246
Validation loss: 2.278091792137392

Epoch: 6| Step: 3
Training loss: 2.168020248413086
Validation loss: 2.2992760263463503

Epoch: 6| Step: 4
Training loss: 2.687044858932495
Validation loss: 2.326912449252221

Epoch: 6| Step: 5
Training loss: 3.65258526802063
Validation loss: 2.347187162727438

Epoch: 6| Step: 6
Training loss: 2.7981014251708984
Validation loss: 2.352968100578554

Epoch: 6| Step: 7
Training loss: 1.8548269271850586
Validation loss: 2.308251384765871

Epoch: 6| Step: 8
Training loss: 2.902709484100342
Validation loss: 2.300615995160995

Epoch: 6| Step: 9
Training loss: 2.0710642337799072
Validation loss: 2.28221494408064

Epoch: 6| Step: 10
Training loss: 2.8390135765075684
Validation loss: 2.27095264773215

Epoch: 6| Step: 11
Training loss: 2.45119571685791
Validation loss: 2.2527096809879428

Epoch: 6| Step: 12
Training loss: 1.3950951099395752
Validation loss: 2.24081616504218

Epoch: 6| Step: 13
Training loss: 2.6401588916778564
Validation loss: 2.2352518625156854

Epoch: 150| Step: 0
Training loss: 2.4665791988372803
Validation loss: 2.2697832994563605

Epoch: 6| Step: 1
Training loss: 2.382073402404785
Validation loss: 2.283548811430572

Epoch: 6| Step: 2
Training loss: 1.4003843069076538
Validation loss: 2.2974875075842744

Epoch: 6| Step: 3
Training loss: 2.3376924991607666
Validation loss: 2.288081205019387

Epoch: 6| Step: 4
Training loss: 2.9918646812438965
Validation loss: 2.296279179152622

Epoch: 6| Step: 5
Training loss: 2.9495463371276855
Validation loss: 2.291744509050923

Epoch: 6| Step: 6
Training loss: 2.4278316497802734
Validation loss: 2.2887673634354786

Epoch: 6| Step: 7
Training loss: 2.936767101287842
Validation loss: 2.2849012036477365

Epoch: 6| Step: 8
Training loss: 2.535020589828491
Validation loss: 2.299516749638383

Epoch: 6| Step: 9
Training loss: 2.6375813484191895
Validation loss: 2.3068382842566377

Epoch: 6| Step: 10
Training loss: 2.1440091133117676
Validation loss: 2.303473611031809

Epoch: 6| Step: 11
Training loss: 2.538754940032959
Validation loss: 2.3035904181900846

Epoch: 6| Step: 12
Training loss: 2.645127773284912
Validation loss: 2.298382615530363

Epoch: 6| Step: 13
Training loss: 3.5473344326019287
Validation loss: 2.2890165262324835

Epoch: 151| Step: 0
Training loss: 2.048767566680908
Validation loss: 2.2935806794833113

Epoch: 6| Step: 1
Training loss: 2.622274875640869
Validation loss: 2.287512920236075

Epoch: 6| Step: 2
Training loss: 2.706418514251709
Validation loss: 2.280632067752141

Epoch: 6| Step: 3
Training loss: 2.423424482345581
Validation loss: 2.2853783035791047

Epoch: 6| Step: 4
Training loss: 2.3613924980163574
Validation loss: 2.2822759843641713

Epoch: 6| Step: 5
Training loss: 1.9591494798660278
Validation loss: 2.2784187511731218

Epoch: 6| Step: 6
Training loss: 2.3937947750091553
Validation loss: 2.278582460136824

Epoch: 6| Step: 7
Training loss: 3.137424945831299
Validation loss: 2.282613021071239

Epoch: 6| Step: 8
Training loss: 2.9766407012939453
Validation loss: 2.2910937288756013

Epoch: 6| Step: 9
Training loss: 2.425353527069092
Validation loss: 2.3035579086631857

Epoch: 6| Step: 10
Training loss: 2.939948797225952
Validation loss: 2.314140958170737

Epoch: 6| Step: 11
Training loss: 2.34501051902771
Validation loss: 2.3203021916010047

Epoch: 6| Step: 12
Training loss: 2.811047315597534
Validation loss: 2.3092063191116496

Epoch: 6| Step: 13
Training loss: 1.735047698020935
Validation loss: 2.2983994714675413

Epoch: 152| Step: 0
Training loss: 2.554989814758301
Validation loss: 2.2870655187996487

Epoch: 6| Step: 1
Training loss: 2.341296911239624
Validation loss: 2.271971630793746

Epoch: 6| Step: 2
Training loss: 2.883911609649658
Validation loss: 2.2620429685038905

Epoch: 6| Step: 3
Training loss: 2.8251867294311523
Validation loss: 2.252730720786638

Epoch: 6| Step: 4
Training loss: 2.1094274520874023
Validation loss: 2.2480348310162945

Epoch: 6| Step: 5
Training loss: 2.686101198196411
Validation loss: 2.2444155677672355

Epoch: 6| Step: 6
Training loss: 2.891005039215088
Validation loss: 2.248536635470647

Epoch: 6| Step: 7
Training loss: 1.702763319015503
Validation loss: 2.2468182399708736

Epoch: 6| Step: 8
Training loss: 2.563016414642334
Validation loss: 2.250618052738969

Epoch: 6| Step: 9
Training loss: 2.044025182723999
Validation loss: 2.25593553819964

Epoch: 6| Step: 10
Training loss: 2.7768216133117676
Validation loss: 2.251662785007108

Epoch: 6| Step: 11
Training loss: 2.4840946197509766
Validation loss: 2.252193772664634

Epoch: 6| Step: 12
Training loss: 2.656463146209717
Validation loss: 2.263893278696204

Epoch: 6| Step: 13
Training loss: 2.792452812194824
Validation loss: 2.265315335283997

Epoch: 153| Step: 0
Training loss: 2.5946075916290283
Validation loss: 2.280253892303795

Epoch: 6| Step: 1
Training loss: 3.188595771789551
Validation loss: 2.2774045364831084

Epoch: 6| Step: 2
Training loss: 2.4969372749328613
Validation loss: 2.282586584809006

Epoch: 6| Step: 3
Training loss: 1.9727978706359863
Validation loss: 2.278579842659735

Epoch: 6| Step: 4
Training loss: 2.337310791015625
Validation loss: 2.2762801749731905

Epoch: 6| Step: 5
Training loss: 2.824249029159546
Validation loss: 2.2812390814545336

Epoch: 6| Step: 6
Training loss: 1.7970257997512817
Validation loss: 2.280471755612281

Epoch: 6| Step: 7
Training loss: 2.037120819091797
Validation loss: 2.28953287165652

Epoch: 6| Step: 8
Training loss: 2.839195489883423
Validation loss: 2.299740973339286

Epoch: 6| Step: 9
Training loss: 2.020723819732666
Validation loss: 2.3203039220584336

Epoch: 6| Step: 10
Training loss: 3.1399760246276855
Validation loss: 2.3275470041459605

Epoch: 6| Step: 11
Training loss: 3.2991421222686768
Validation loss: 2.315018799997145

Epoch: 6| Step: 12
Training loss: 2.0561952590942383
Validation loss: 2.2904258081989903

Epoch: 6| Step: 13
Training loss: 2.32564115524292
Validation loss: 2.2662417273367605

Epoch: 154| Step: 0
Training loss: 2.339409351348877
Validation loss: 2.2417076044185187

Epoch: 6| Step: 1
Training loss: 2.222248077392578
Validation loss: 2.2411415218025126

Epoch: 6| Step: 2
Training loss: 2.6672163009643555
Validation loss: 2.247224739802781

Epoch: 6| Step: 3
Training loss: 1.9673936367034912
Validation loss: 2.250289096627184

Epoch: 6| Step: 4
Training loss: 2.7124431133270264
Validation loss: 2.2443457213781213

Epoch: 6| Step: 5
Training loss: 3.290030002593994
Validation loss: 2.2513524409263366

Epoch: 6| Step: 6
Training loss: 2.3759851455688477
Validation loss: 2.242165337326706

Epoch: 6| Step: 7
Training loss: 2.034221649169922
Validation loss: 2.246682846417991

Epoch: 6| Step: 8
Training loss: 3.0217621326446533
Validation loss: 2.2411144241209953

Epoch: 6| Step: 9
Training loss: 2.1671431064605713
Validation loss: 2.2379063073024956

Epoch: 6| Step: 10
Training loss: 2.4787468910217285
Validation loss: 2.235223066422247

Epoch: 6| Step: 11
Training loss: 3.050261974334717
Validation loss: 2.235007039962276

Epoch: 6| Step: 12
Training loss: 2.6887588500976562
Validation loss: 2.2445921692796933

Epoch: 6| Step: 13
Training loss: 2.1702113151550293
Validation loss: 2.2632411500459075

Epoch: 155| Step: 0
Training loss: 1.8001935482025146
Validation loss: 2.2645121723093014

Epoch: 6| Step: 1
Training loss: 3.377814531326294
Validation loss: 2.2741106761399137

Epoch: 6| Step: 2
Training loss: 2.735192060470581
Validation loss: 2.3079807937786145

Epoch: 6| Step: 3
Training loss: 2.7797510623931885
Validation loss: 2.3246759137799664

Epoch: 6| Step: 4
Training loss: 2.4925570487976074
Validation loss: 2.3016483988813174

Epoch: 6| Step: 5
Training loss: 2.1733970642089844
Validation loss: 2.2795467017799296

Epoch: 6| Step: 6
Training loss: 2.401947498321533
Validation loss: 2.262387906351397

Epoch: 6| Step: 7
Training loss: 2.2980637550354004
Validation loss: 2.2463666392910864

Epoch: 6| Step: 8
Training loss: 2.698896884918213
Validation loss: 2.2222400839610765

Epoch: 6| Step: 9
Training loss: 2.847067356109619
Validation loss: 2.2202968930685394

Epoch: 6| Step: 10
Training loss: 2.500370502471924
Validation loss: 2.217945860278222

Epoch: 6| Step: 11
Training loss: 2.4641919136047363
Validation loss: 2.223269434385402

Epoch: 6| Step: 12
Training loss: 2.479430675506592
Validation loss: 2.2213187474076466

Epoch: 6| Step: 13
Training loss: 1.9163678884506226
Validation loss: 2.2208463966205554

Epoch: 156| Step: 0
Training loss: 2.7041797637939453
Validation loss: 2.2165837185357207

Epoch: 6| Step: 1
Training loss: 2.0602149963378906
Validation loss: 2.2129802344947733

Epoch: 6| Step: 2
Training loss: 2.4317612648010254
Validation loss: 2.2164078245880785

Epoch: 6| Step: 3
Training loss: 2.315894365310669
Validation loss: 2.2180846788549937

Epoch: 6| Step: 4
Training loss: 2.8530330657958984
Validation loss: 2.2281738558123187

Epoch: 6| Step: 5
Training loss: 2.912584066390991
Validation loss: 2.2417921789230837

Epoch: 6| Step: 6
Training loss: 2.993748188018799
Validation loss: 2.2519503639590357

Epoch: 6| Step: 7
Training loss: 2.238295793533325
Validation loss: 2.2567553289474978

Epoch: 6| Step: 8
Training loss: 2.653252601623535
Validation loss: 2.2675776699537873

Epoch: 6| Step: 9
Training loss: 2.2989697456359863
Validation loss: 2.309132892598388

Epoch: 6| Step: 10
Training loss: 2.3341283798217773
Validation loss: 2.294825448784777

Epoch: 6| Step: 11
Training loss: 2.348345994949341
Validation loss: 2.272669871648153

Epoch: 6| Step: 12
Training loss: 2.4973926544189453
Validation loss: 2.2566349942197084

Epoch: 6| Step: 13
Training loss: 2.2962567806243896
Validation loss: 2.2400830022750364

Epoch: 157| Step: 0
Training loss: 1.8210195302963257
Validation loss: 2.2198839533713555

Epoch: 6| Step: 1
Training loss: 2.6147584915161133
Validation loss: 2.2186278899510703

Epoch: 6| Step: 2
Training loss: 2.671968460083008
Validation loss: 2.2130620876948037

Epoch: 6| Step: 3
Training loss: 1.7410929203033447
Validation loss: 2.2226524045390468

Epoch: 6| Step: 4
Training loss: 2.1791269779205322
Validation loss: 2.2484657123524654

Epoch: 6| Step: 5
Training loss: 2.2754156589508057
Validation loss: 2.228107844629595

Epoch: 6| Step: 6
Training loss: 3.135347604751587
Validation loss: 2.2391372137172247

Epoch: 6| Step: 7
Training loss: 2.1790122985839844
Validation loss: 2.2472399306553665

Epoch: 6| Step: 8
Training loss: 2.4743523597717285
Validation loss: 2.2588320957717074

Epoch: 6| Step: 9
Training loss: 2.8532543182373047
Validation loss: 2.240911942656322

Epoch: 6| Step: 10
Training loss: 2.8621444702148438
Validation loss: 2.217773422118156

Epoch: 6| Step: 11
Training loss: 2.690117359161377
Validation loss: 2.1822713985238025

Epoch: 6| Step: 12
Training loss: 2.7193915843963623
Validation loss: 2.1786075356186076

Epoch: 6| Step: 13
Training loss: 2.0946130752563477
Validation loss: 2.17897129571566

Epoch: 158| Step: 0
Training loss: 2.8008780479431152
Validation loss: 2.1890133273216987

Epoch: 6| Step: 1
Training loss: 1.9870860576629639
Validation loss: 2.185611911999282

Epoch: 6| Step: 2
Training loss: 2.684088945388794
Validation loss: 2.190066720849724

Epoch: 6| Step: 3
Training loss: 2.4461216926574707
Validation loss: 2.1832434387617212

Epoch: 6| Step: 4
Training loss: 3.1610097885131836
Validation loss: 2.1846865069481636

Epoch: 6| Step: 5
Training loss: 2.891176462173462
Validation loss: 2.182903015485374

Epoch: 6| Step: 6
Training loss: 2.341374635696411
Validation loss: 2.185537204947523

Epoch: 6| Step: 7
Training loss: 1.620140790939331
Validation loss: 2.1838908785132953

Epoch: 6| Step: 8
Training loss: 2.987680673599243
Validation loss: 2.1799564951209613

Epoch: 6| Step: 9
Training loss: 2.7634778022766113
Validation loss: 2.1707308856389855

Epoch: 6| Step: 10
Training loss: 2.6919851303100586
Validation loss: 2.172342554215462

Epoch: 6| Step: 11
Training loss: 1.5291919708251953
Validation loss: 2.1652764556228474

Epoch: 6| Step: 12
Training loss: 2.6110782623291016
Validation loss: 2.174254230273667

Epoch: 6| Step: 13
Training loss: 2.70854115486145
Validation loss: 2.2052294720885572

Epoch: 159| Step: 0
Training loss: 2.396254539489746
Validation loss: 2.2462483118939143

Epoch: 6| Step: 1
Training loss: 2.384506940841675
Validation loss: 2.270346754340715

Epoch: 6| Step: 2
Training loss: 2.588402032852173
Validation loss: 2.293071062334122

Epoch: 6| Step: 3
Training loss: 2.156576633453369
Validation loss: 2.3058852277776247

Epoch: 6| Step: 4
Training loss: 1.6731986999511719
Validation loss: 2.2839792454114525

Epoch: 6| Step: 5
Training loss: 2.5838074684143066
Validation loss: 2.2325128842425603

Epoch: 6| Step: 6
Training loss: 2.632497549057007
Validation loss: 2.1951032761604554

Epoch: 6| Step: 7
Training loss: 2.349306583404541
Validation loss: 2.186677090583309

Epoch: 6| Step: 8
Training loss: 2.9925894737243652
Validation loss: 2.1674685260300994

Epoch: 6| Step: 9
Training loss: 3.107762336730957
Validation loss: 2.1586957926391275

Epoch: 6| Step: 10
Training loss: 3.0980772972106934
Validation loss: 2.167443449779223

Epoch: 6| Step: 11
Training loss: 2.158222198486328
Validation loss: 2.161820627027942

Epoch: 6| Step: 12
Training loss: 1.892257809638977
Validation loss: 2.163761285043532

Epoch: 6| Step: 13
Training loss: 2.8086369037628174
Validation loss: 2.1639979936743297

Epoch: 160| Step: 0
Training loss: 2.244371175765991
Validation loss: 2.171660651442825

Epoch: 6| Step: 1
Training loss: 1.6317782402038574
Validation loss: 2.180874301541236

Epoch: 6| Step: 2
Training loss: 2.8799402713775635
Validation loss: 2.195357086837933

Epoch: 6| Step: 3
Training loss: 2.618088483810425
Validation loss: 2.201476994381156

Epoch: 6| Step: 4
Training loss: 2.131301164627075
Validation loss: 2.2356021558084795

Epoch: 6| Step: 5
Training loss: 2.648977756500244
Validation loss: 2.2573081934323875

Epoch: 6| Step: 6
Training loss: 2.9936108589172363
Validation loss: 2.275371120822045

Epoch: 6| Step: 7
Training loss: 2.33585262298584
Validation loss: 2.2926990191141763

Epoch: 6| Step: 8
Training loss: 2.4362006187438965
Validation loss: 2.3030862987682386

Epoch: 6| Step: 9
Training loss: 3.1010406017303467
Validation loss: 2.3030738984384844

Epoch: 6| Step: 10
Training loss: 2.0662307739257812
Validation loss: 2.259562421870488

Epoch: 6| Step: 11
Training loss: 2.1447689533233643
Validation loss: 2.236267558989986

Epoch: 6| Step: 12
Training loss: 2.5384395122528076
Validation loss: 2.2115001909194456

Epoch: 6| Step: 13
Training loss: 2.6683709621429443
Validation loss: 2.1986976003134124

Epoch: 161| Step: 0
Training loss: 2.6627488136291504
Validation loss: 2.197350404595816

Epoch: 6| Step: 1
Training loss: 2.4122400283813477
Validation loss: 2.183317333139399

Epoch: 6| Step: 2
Training loss: 2.735785961151123
Validation loss: 2.1816338210977535

Epoch: 6| Step: 3
Training loss: 3.3991949558258057
Validation loss: 2.170760928943593

Epoch: 6| Step: 4
Training loss: 2.2077596187591553
Validation loss: 2.1691993398051106

Epoch: 6| Step: 5
Training loss: 2.0394694805145264
Validation loss: 2.169458835355697

Epoch: 6| Step: 6
Training loss: 2.2968392372131348
Validation loss: 2.1663362338978756

Epoch: 6| Step: 7
Training loss: 2.923060417175293
Validation loss: 2.1740187060448433

Epoch: 6| Step: 8
Training loss: 1.3210593461990356
Validation loss: 2.208820625018048

Epoch: 6| Step: 9
Training loss: 2.1498842239379883
Validation loss: 2.216873099727015

Epoch: 6| Step: 10
Training loss: 2.399466037750244
Validation loss: 2.2184573245304886

Epoch: 6| Step: 11
Training loss: 3.1255345344543457
Validation loss: 2.2109308217161443

Epoch: 6| Step: 12
Training loss: 2.4869439601898193
Validation loss: 2.1898053153868644

Epoch: 6| Step: 13
Training loss: 2.3217732906341553
Validation loss: 2.183226041896369

Epoch: 162| Step: 0
Training loss: 2.350642204284668
Validation loss: 2.185276457058486

Epoch: 6| Step: 1
Training loss: 1.5870318412780762
Validation loss: 2.1764785935801845

Epoch: 6| Step: 2
Training loss: 2.5636496543884277
Validation loss: 2.1742614033401653

Epoch: 6| Step: 3
Training loss: 2.918393611907959
Validation loss: 2.186392989209903

Epoch: 6| Step: 4
Training loss: 2.913756847381592
Validation loss: 2.2016702723759476

Epoch: 6| Step: 5
Training loss: 2.174966335296631
Validation loss: 2.190610824092742

Epoch: 6| Step: 6
Training loss: 2.1152377128601074
Validation loss: 2.2033313679438766

Epoch: 6| Step: 7
Training loss: 2.487760305404663
Validation loss: 2.204493062470549

Epoch: 6| Step: 8
Training loss: 2.6366264820098877
Validation loss: 2.2104394589701006

Epoch: 6| Step: 9
Training loss: 2.49586820602417
Validation loss: 2.2028612859787478

Epoch: 6| Step: 10
Training loss: 3.0778415203094482
Validation loss: 2.2030128548222203

Epoch: 6| Step: 11
Training loss: 2.381974697113037
Validation loss: 2.1815529843812347

Epoch: 6| Step: 12
Training loss: 2.201537847518921
Validation loss: 2.1813872603959936

Epoch: 6| Step: 13
Training loss: 2.181596279144287
Validation loss: 2.1696510391850627

Epoch: 163| Step: 0
Training loss: 2.260277509689331
Validation loss: 2.1696292085032307

Epoch: 6| Step: 1
Training loss: 2.3705732822418213
Validation loss: 2.183801240818475

Epoch: 6| Step: 2
Training loss: 2.337726354598999
Validation loss: 2.1809490021838935

Epoch: 6| Step: 3
Training loss: 2.429870128631592
Validation loss: 2.184609243946691

Epoch: 6| Step: 4
Training loss: 2.8378548622131348
Validation loss: 2.176779621390886

Epoch: 6| Step: 5
Training loss: 2.591261386871338
Validation loss: 2.1911828030822096

Epoch: 6| Step: 6
Training loss: 1.9826233386993408
Validation loss: 2.188924297209709

Epoch: 6| Step: 7
Training loss: 2.170785427093506
Validation loss: 2.2043084354810816

Epoch: 6| Step: 8
Training loss: 2.8218929767608643
Validation loss: 2.2311209529958744

Epoch: 6| Step: 9
Training loss: 1.8643176555633545
Validation loss: 2.2645218039071686

Epoch: 6| Step: 10
Training loss: 2.675142765045166
Validation loss: 2.3045349223639375

Epoch: 6| Step: 11
Training loss: 3.4933767318725586
Validation loss: 2.284635930932978

Epoch: 6| Step: 12
Training loss: 2.2066726684570312
Validation loss: 2.2553473467467935

Epoch: 6| Step: 13
Training loss: 2.571465015411377
Validation loss: 2.2415951426311205

Epoch: 164| Step: 0
Training loss: 1.9035310745239258
Validation loss: 2.2055411518261

Epoch: 6| Step: 1
Training loss: 3.1686971187591553
Validation loss: 2.2053683573199856

Epoch: 6| Step: 2
Training loss: 2.9409844875335693
Validation loss: 2.178831828537808

Epoch: 6| Step: 3
Training loss: 2.785464286804199
Validation loss: 2.1818063233488347

Epoch: 6| Step: 4
Training loss: 2.583984613418579
Validation loss: 2.1742763057831795

Epoch: 6| Step: 5
Training loss: 2.116962432861328
Validation loss: 2.16239526707639

Epoch: 6| Step: 6
Training loss: 2.747875213623047
Validation loss: 2.1536498044126775

Epoch: 6| Step: 7
Training loss: 2.9229564666748047
Validation loss: 2.151230267299119

Epoch: 6| Step: 8
Training loss: 2.0908374786376953
Validation loss: 2.148146995934107

Epoch: 6| Step: 9
Training loss: 2.5331034660339355
Validation loss: 2.1499481995900473

Epoch: 6| Step: 10
Training loss: 2.1493852138519287
Validation loss: 2.172174310171476

Epoch: 6| Step: 11
Training loss: 1.740434169769287
Validation loss: 2.1832936502272084

Epoch: 6| Step: 12
Training loss: 2.4433388710021973
Validation loss: 2.194124032092351

Epoch: 6| Step: 13
Training loss: 1.91763436794281
Validation loss: 2.1947039327313824

Epoch: 165| Step: 0
Training loss: 2.1972999572753906
Validation loss: 2.179138891158565

Epoch: 6| Step: 1
Training loss: 2.5942885875701904
Validation loss: 2.1747280602814048

Epoch: 6| Step: 2
Training loss: 2.536332130432129
Validation loss: 2.170448262204406

Epoch: 6| Step: 3
Training loss: 2.2984371185302734
Validation loss: 2.182083091428203

Epoch: 6| Step: 4
Training loss: 1.8089317083358765
Validation loss: 2.20204746594993

Epoch: 6| Step: 5
Training loss: 1.9672014713287354
Validation loss: 2.2050992211987896

Epoch: 6| Step: 6
Training loss: 2.707693338394165
Validation loss: 2.2031938029873754

Epoch: 6| Step: 7
Training loss: 2.5923030376434326
Validation loss: 2.2047607155256372

Epoch: 6| Step: 8
Training loss: 2.7888264656066895
Validation loss: 2.2131204066738004

Epoch: 6| Step: 9
Training loss: 2.7334132194519043
Validation loss: 2.2319217240938576

Epoch: 6| Step: 10
Training loss: 2.8861331939697266
Validation loss: 2.218454016152249

Epoch: 6| Step: 11
Training loss: 1.888393759727478
Validation loss: 2.212532745894565

Epoch: 6| Step: 12
Training loss: 2.4709043502807617
Validation loss: 2.228926812448809

Epoch: 6| Step: 13
Training loss: 2.6395368576049805
Validation loss: 2.221235179132031

Epoch: 166| Step: 0
Training loss: 1.3197555541992188
Validation loss: 2.2171919038218837

Epoch: 6| Step: 1
Training loss: 2.3514883518218994
Validation loss: 2.207041791690293

Epoch: 6| Step: 2
Training loss: 2.7480509281158447
Validation loss: 2.1993449887921734

Epoch: 6| Step: 3
Training loss: 2.533656120300293
Validation loss: 2.2025386364229265

Epoch: 6| Step: 4
Training loss: 2.232865571975708
Validation loss: 2.201848873528101

Epoch: 6| Step: 5
Training loss: 2.0873794555664062
Validation loss: 2.189045759939378

Epoch: 6| Step: 6
Training loss: 2.4065749645233154
Validation loss: 2.181103793523645

Epoch: 6| Step: 7
Training loss: 2.325317621231079
Validation loss: 2.189404074863721

Epoch: 6| Step: 8
Training loss: 1.7744309902191162
Validation loss: 2.1882964487998717

Epoch: 6| Step: 9
Training loss: 2.7779059410095215
Validation loss: 2.1704329136879212

Epoch: 6| Step: 10
Training loss: 2.4832777976989746
Validation loss: 2.172902848130913

Epoch: 6| Step: 11
Training loss: 2.8863019943237305
Validation loss: 2.172896892793717

Epoch: 6| Step: 12
Training loss: 3.1818957328796387
Validation loss: 2.1815601048930997

Epoch: 6| Step: 13
Training loss: 3.136596918106079
Validation loss: 2.2014056226258636

Epoch: 167| Step: 0
Training loss: 2.5313124656677246
Validation loss: 2.2202338210998045

Epoch: 6| Step: 1
Training loss: 2.5129241943359375
Validation loss: 2.226803336092221

Epoch: 6| Step: 2
Training loss: 1.699568510055542
Validation loss: 2.2228045566107637

Epoch: 6| Step: 3
Training loss: 1.6138970851898193
Validation loss: 2.214455444325683

Epoch: 6| Step: 4
Training loss: 2.5989890098571777
Validation loss: 2.206015340743526

Epoch: 6| Step: 5
Training loss: 2.437614917755127
Validation loss: 2.1999070208559752

Epoch: 6| Step: 6
Training loss: 2.6808786392211914
Validation loss: 2.192468233005975

Epoch: 6| Step: 7
Training loss: 2.6259613037109375
Validation loss: 2.196306897747901

Epoch: 6| Step: 8
Training loss: 1.1397390365600586
Validation loss: 2.196964144706726

Epoch: 6| Step: 9
Training loss: 2.9141502380371094
Validation loss: 2.1846095464562856

Epoch: 6| Step: 10
Training loss: 2.906963586807251
Validation loss: 2.177384876435803

Epoch: 6| Step: 11
Training loss: 2.4953088760375977
Validation loss: 2.1732775447189168

Epoch: 6| Step: 12
Training loss: 2.991558074951172
Validation loss: 2.1770931238769204

Epoch: 6| Step: 13
Training loss: 2.8533856868743896
Validation loss: 2.184649590523012

Epoch: 168| Step: 0
Training loss: 2.0578603744506836
Validation loss: 2.1983641270668275

Epoch: 6| Step: 1
Training loss: 2.4957900047302246
Validation loss: 2.216837985541231

Epoch: 6| Step: 2
Training loss: 2.179356098175049
Validation loss: 2.2467013174487698

Epoch: 6| Step: 3
Training loss: 2.8635001182556152
Validation loss: 2.2456831060430056

Epoch: 6| Step: 4
Training loss: 1.5815813541412354
Validation loss: 2.2247147149937128

Epoch: 6| Step: 5
Training loss: 1.9876588582992554
Validation loss: 2.2222588087922786

Epoch: 6| Step: 6
Training loss: 3.1182708740234375
Validation loss: 2.226107597351074

Epoch: 6| Step: 7
Training loss: 2.391597270965576
Validation loss: 2.2362731297810874

Epoch: 6| Step: 8
Training loss: 3.167266845703125
Validation loss: 2.218328599006899

Epoch: 6| Step: 9
Training loss: 2.3066248893737793
Validation loss: 2.2065018812815347

Epoch: 6| Step: 10
Training loss: 2.1398391723632812
Validation loss: 2.2099454877197102

Epoch: 6| Step: 11
Training loss: 2.304144859313965
Validation loss: 2.183608893425234

Epoch: 6| Step: 12
Training loss: 2.8513965606689453
Validation loss: 2.177358179964045

Epoch: 6| Step: 13
Training loss: 2.36898136138916
Validation loss: 2.1813577477649977

Epoch: 169| Step: 0
Training loss: 2.519340753555298
Validation loss: 2.1767723380878405

Epoch: 6| Step: 1
Training loss: 2.66371488571167
Validation loss: 2.1768790778293403

Epoch: 6| Step: 2
Training loss: 2.277230739593506
Validation loss: 2.1849780441612325

Epoch: 6| Step: 3
Training loss: 2.752708911895752
Validation loss: 2.2004614645434963

Epoch: 6| Step: 4
Training loss: 1.9197373390197754
Validation loss: 2.2108005503172516

Epoch: 6| Step: 5
Training loss: 2.231529474258423
Validation loss: 2.1992526874747327

Epoch: 6| Step: 6
Training loss: 2.6122727394104004
Validation loss: 2.1973040027003132

Epoch: 6| Step: 7
Training loss: 2.5671141147613525
Validation loss: 2.2052079349435787

Epoch: 6| Step: 8
Training loss: 2.1599574089050293
Validation loss: 2.2012343637404905

Epoch: 6| Step: 9
Training loss: 2.0134479999542236
Validation loss: 2.2249998277233494

Epoch: 6| Step: 10
Training loss: 2.570702075958252
Validation loss: 2.217458160974646

Epoch: 6| Step: 11
Training loss: 2.6832752227783203
Validation loss: 2.2377142624188493

Epoch: 6| Step: 12
Training loss: 2.6574909687042236
Validation loss: 2.241250871330179

Epoch: 6| Step: 13
Training loss: 2.062191963195801
Validation loss: 2.2443111353023077

Epoch: 170| Step: 0
Training loss: 2.8578598499298096
Validation loss: 2.2482986219467653

Epoch: 6| Step: 1
Training loss: 2.9017531871795654
Validation loss: 2.2295429142572547

Epoch: 6| Step: 2
Training loss: 2.2390942573547363
Validation loss: 2.2377471000917497

Epoch: 6| Step: 3
Training loss: 1.898736834526062
Validation loss: 2.1810683409372964

Epoch: 6| Step: 4
Training loss: 3.103731632232666
Validation loss: 2.1805829360920894

Epoch: 6| Step: 5
Training loss: 2.28542423248291
Validation loss: 2.1679883080144084

Epoch: 6| Step: 6
Training loss: 1.915748953819275
Validation loss: 2.1644317360334497

Epoch: 6| Step: 7
Training loss: 2.4155452251434326
Validation loss: 2.172897364503594

Epoch: 6| Step: 8
Training loss: 2.784313678741455
Validation loss: 2.1722395881529777

Epoch: 6| Step: 9
Training loss: 2.6708478927612305
Validation loss: 2.1930763772738877

Epoch: 6| Step: 10
Training loss: 2.287139892578125
Validation loss: 2.201140293511011

Epoch: 6| Step: 11
Training loss: 1.7117257118225098
Validation loss: 2.2153323875960482

Epoch: 6| Step: 12
Training loss: 1.9074134826660156
Validation loss: 2.210630157942413

Epoch: 6| Step: 13
Training loss: 3.098989486694336
Validation loss: 2.191062875973281

Epoch: 171| Step: 0
Training loss: 2.118504762649536
Validation loss: 2.1994870965198805

Epoch: 6| Step: 1
Training loss: 2.9988601207733154
Validation loss: 2.196273857547391

Epoch: 6| Step: 2
Training loss: 2.2015271186828613
Validation loss: 2.1894923102471138

Epoch: 6| Step: 3
Training loss: 2.4413771629333496
Validation loss: 2.185703812106963

Epoch: 6| Step: 4
Training loss: 2.640010356903076
Validation loss: 2.184401181436354

Epoch: 6| Step: 5
Training loss: 2.0246996879577637
Validation loss: 2.1915960645162933

Epoch: 6| Step: 6
Training loss: 2.700451135635376
Validation loss: 2.2147397994995117

Epoch: 6| Step: 7
Training loss: 2.846841335296631
Validation loss: 2.180243138344057

Epoch: 6| Step: 8
Training loss: 1.9804966449737549
Validation loss: 2.1645936530123473

Epoch: 6| Step: 9
Training loss: 2.7713379859924316
Validation loss: 2.164361387170771

Epoch: 6| Step: 10
Training loss: 2.301177740097046
Validation loss: 2.153317007967221

Epoch: 6| Step: 11
Training loss: 2.473545551300049
Validation loss: 2.1536417955993326

Epoch: 6| Step: 12
Training loss: 2.188324213027954
Validation loss: 2.1643671451076383

Epoch: 6| Step: 13
Training loss: 1.7091418504714966
Validation loss: 2.163213635003695

Epoch: 172| Step: 0
Training loss: 2.9065146446228027
Validation loss: 2.1869612175931215

Epoch: 6| Step: 1
Training loss: 3.0912106037139893
Validation loss: 2.213419901427402

Epoch: 6| Step: 2
Training loss: 2.2603206634521484
Validation loss: 2.2410170852497058

Epoch: 6| Step: 3
Training loss: 1.7909157276153564
Validation loss: 2.238476755798504

Epoch: 6| Step: 4
Training loss: 2.7838363647460938
Validation loss: 2.2207556706602856

Epoch: 6| Step: 5
Training loss: 2.2556402683258057
Validation loss: 2.206474786163658

Epoch: 6| Step: 6
Training loss: 3.01206111907959
Validation loss: 2.1707431398412234

Epoch: 6| Step: 7
Training loss: 2.6936514377593994
Validation loss: 2.141961666845506

Epoch: 6| Step: 8
Training loss: 2.2101166248321533
Validation loss: 2.1403988612595426

Epoch: 6| Step: 9
Training loss: 2.5683956146240234
Validation loss: 2.1451556169858543

Epoch: 6| Step: 10
Training loss: 1.5361790657043457
Validation loss: 2.147420011540895

Epoch: 6| Step: 11
Training loss: 2.808736562728882
Validation loss: 2.143272481938844

Epoch: 6| Step: 12
Training loss: 1.9308079481124878
Validation loss: 2.1447216015990063

Epoch: 6| Step: 13
Training loss: 1.8530077934265137
Validation loss: 2.1503221296495005

Epoch: 173| Step: 0
Training loss: 2.177762985229492
Validation loss: 2.147044943224999

Epoch: 6| Step: 1
Training loss: 2.8778533935546875
Validation loss: 2.1500601871039278

Epoch: 6| Step: 2
Training loss: 2.0876379013061523
Validation loss: 2.1993048139797744

Epoch: 6| Step: 3
Training loss: 2.5799732208251953
Validation loss: 2.237019246624362

Epoch: 6| Step: 4
Training loss: 2.312836170196533
Validation loss: 2.254380031298566

Epoch: 6| Step: 5
Training loss: 2.555145740509033
Validation loss: 2.255693348505164

Epoch: 6| Step: 6
Training loss: 1.8286572694778442
Validation loss: 2.2585642671072357

Epoch: 6| Step: 7
Training loss: 2.4848484992980957
Validation loss: 2.265102676166001

Epoch: 6| Step: 8
Training loss: 2.6807847023010254
Validation loss: 2.2577845588807137

Epoch: 6| Step: 9
Training loss: 2.3117856979370117
Validation loss: 2.270846318173152

Epoch: 6| Step: 10
Training loss: 2.6536483764648438
Validation loss: 2.2353422821208997

Epoch: 6| Step: 11
Training loss: 2.8509340286254883
Validation loss: 2.2256461804912937

Epoch: 6| Step: 12
Training loss: 2.5504531860351562
Validation loss: 2.2159755127404326

Epoch: 6| Step: 13
Training loss: 1.1424280405044556
Validation loss: 2.1786817299422396

Epoch: 174| Step: 0
Training loss: 2.554461717605591
Validation loss: 2.1585461913898425

Epoch: 6| Step: 1
Training loss: 1.7858030796051025
Validation loss: 2.1740030627096854

Epoch: 6| Step: 2
Training loss: 2.670866012573242
Validation loss: 2.1725403647268973

Epoch: 6| Step: 3
Training loss: 2.8228859901428223
Validation loss: 2.1658904424277683

Epoch: 6| Step: 4
Training loss: 2.405214548110962
Validation loss: 2.169785229108667

Epoch: 6| Step: 5
Training loss: 2.1855170726776123
Validation loss: 2.1609922532112367

Epoch: 6| Step: 6
Training loss: 1.652689814567566
Validation loss: 2.1659472142496417

Epoch: 6| Step: 7
Training loss: 2.790465831756592
Validation loss: 2.159103024390436

Epoch: 6| Step: 8
Training loss: 2.1877315044403076
Validation loss: 2.1695018199182328

Epoch: 6| Step: 9
Training loss: 2.324861526489258
Validation loss: 2.180151670209823

Epoch: 6| Step: 10
Training loss: 2.984673500061035
Validation loss: 2.186316009490721

Epoch: 6| Step: 11
Training loss: 2.4206223487854004
Validation loss: 2.187677844878166

Epoch: 6| Step: 12
Training loss: 2.2371675968170166
Validation loss: 2.1838099648875575

Epoch: 6| Step: 13
Training loss: 2.462355375289917
Validation loss: 2.2038780771276003

Epoch: 175| Step: 0
Training loss: 2.337975025177002
Validation loss: 2.205418579040035

Epoch: 6| Step: 1
Training loss: 2.1581783294677734
Validation loss: 2.210995853588145

Epoch: 6| Step: 2
Training loss: 2.692423105239868
Validation loss: 2.201265360719414

Epoch: 6| Step: 3
Training loss: 2.857283592224121
Validation loss: 2.21660896911416

Epoch: 6| Step: 4
Training loss: 2.7013282775878906
Validation loss: 2.1950573562293925

Epoch: 6| Step: 5
Training loss: 2.6167564392089844
Validation loss: 2.188429319730369

Epoch: 6| Step: 6
Training loss: 2.311032295227051
Validation loss: 2.1881930930640108

Epoch: 6| Step: 7
Training loss: 2.3994269371032715
Validation loss: 2.2055009462500132

Epoch: 6| Step: 8
Training loss: 2.7284951210021973
Validation loss: 2.1871982800063265

Epoch: 6| Step: 9
Training loss: 1.6311063766479492
Validation loss: 2.159753486674319

Epoch: 6| Step: 10
Training loss: 1.4305450916290283
Validation loss: 2.144631278130316

Epoch: 6| Step: 11
Training loss: 2.6829867362976074
Validation loss: 2.139556630965202

Epoch: 6| Step: 12
Training loss: 2.2151076793670654
Validation loss: 2.1312598823219218

Epoch: 6| Step: 13
Training loss: 2.666066884994507
Validation loss: 2.1307004164623957

Epoch: 176| Step: 0
Training loss: 2.409470558166504
Validation loss: 2.1457690833717264

Epoch: 6| Step: 1
Training loss: 2.4047253131866455
Validation loss: 2.143392990994197

Epoch: 6| Step: 2
Training loss: 2.240450382232666
Validation loss: 2.1511902347687752

Epoch: 6| Step: 3
Training loss: 2.2085072994232178
Validation loss: 2.1731623923906715

Epoch: 6| Step: 4
Training loss: 2.366583824157715
Validation loss: 2.1826353637121056

Epoch: 6| Step: 5
Training loss: 2.42885160446167
Validation loss: 2.216928538455758

Epoch: 6| Step: 6
Training loss: 2.6921420097351074
Validation loss: 2.221328702024234

Epoch: 6| Step: 7
Training loss: 2.5862743854522705
Validation loss: 2.230364397007932

Epoch: 6| Step: 8
Training loss: 2.542492628097534
Validation loss: 2.2010491407045754

Epoch: 6| Step: 9
Training loss: 2.459379196166992
Validation loss: 2.194266314147621

Epoch: 6| Step: 10
Training loss: 2.324100971221924
Validation loss: 2.17709320334978

Epoch: 6| Step: 11
Training loss: 2.1002776622772217
Validation loss: 2.175525034627607

Epoch: 6| Step: 12
Training loss: 2.713273048400879
Validation loss: 2.180171243606075

Epoch: 6| Step: 13
Training loss: 1.8823844194412231
Validation loss: 2.200262833667058

Epoch: 177| Step: 0
Training loss: 3.109421730041504
Validation loss: 2.212370921206731

Epoch: 6| Step: 1
Training loss: 2.210268974304199
Validation loss: 2.2273112215021604

Epoch: 6| Step: 2
Training loss: 2.513284921646118
Validation loss: 2.2213382362037577

Epoch: 6| Step: 3
Training loss: 3.0861339569091797
Validation loss: 2.195692672524401

Epoch: 6| Step: 4
Training loss: 2.4670767784118652
Validation loss: 2.174218204713637

Epoch: 6| Step: 5
Training loss: 2.7090706825256348
Validation loss: 2.1399179299672446

Epoch: 6| Step: 6
Training loss: 1.6318254470825195
Validation loss: 2.1266290039144535

Epoch: 6| Step: 7
Training loss: 2.108973741531372
Validation loss: 2.127698613751319

Epoch: 6| Step: 8
Training loss: 2.189161539077759
Validation loss: 2.1229297371320826

Epoch: 6| Step: 9
Training loss: 2.436311960220337
Validation loss: 2.1375418555351997

Epoch: 6| Step: 10
Training loss: 1.9288661479949951
Validation loss: 2.159252949940261

Epoch: 6| Step: 11
Training loss: 2.0621771812438965
Validation loss: 2.164055537152034

Epoch: 6| Step: 12
Training loss: 2.6027417182922363
Validation loss: 2.1467892251988894

Epoch: 6| Step: 13
Training loss: 2.543215036392212
Validation loss: 2.125508436592676

Epoch: 178| Step: 0
Training loss: 2.5521225929260254
Validation loss: 2.1107310159232027

Epoch: 6| Step: 1
Training loss: 2.5266494750976562
Validation loss: 2.1151190034804808

Epoch: 6| Step: 2
Training loss: 3.117738723754883
Validation loss: 2.1190920247826526

Epoch: 6| Step: 3
Training loss: 2.170191526412964
Validation loss: 2.1199644150272494

Epoch: 6| Step: 4
Training loss: 1.6021369695663452
Validation loss: 2.1200831705524075

Epoch: 6| Step: 5
Training loss: 2.179899215698242
Validation loss: 2.1341046492258706

Epoch: 6| Step: 6
Training loss: 2.6202316284179688
Validation loss: 2.1304099303419872

Epoch: 6| Step: 7
Training loss: 1.9411094188690186
Validation loss: 2.1583527903403006

Epoch: 6| Step: 8
Training loss: 2.088871955871582
Validation loss: 2.171093452361322

Epoch: 6| Step: 9
Training loss: 2.7275032997131348
Validation loss: 2.185603892931374

Epoch: 6| Step: 10
Training loss: 2.988006353378296
Validation loss: 2.162185086998888

Epoch: 6| Step: 11
Training loss: 1.9484217166900635
Validation loss: 2.139520151640779

Epoch: 6| Step: 12
Training loss: 2.827237129211426
Validation loss: 2.12914337137694

Epoch: 6| Step: 13
Training loss: 2.1120033264160156
Validation loss: 2.113847248015865

Epoch: 179| Step: 0
Training loss: 2.5519630908966064
Validation loss: 2.1208577091975878

Epoch: 6| Step: 1
Training loss: 2.2792344093322754
Validation loss: 2.1208699992907944

Epoch: 6| Step: 2
Training loss: 2.9850833415985107
Validation loss: 2.1299469727341847

Epoch: 6| Step: 3
Training loss: 2.6989517211914062
Validation loss: 2.144848294155572

Epoch: 6| Step: 4
Training loss: 1.748594045639038
Validation loss: 2.169741710027059

Epoch: 6| Step: 5
Training loss: 2.3281092643737793
Validation loss: 2.1731252619015273

Epoch: 6| Step: 6
Training loss: 1.6429232358932495
Validation loss: 2.17464388955024

Epoch: 6| Step: 7
Training loss: 2.139403820037842
Validation loss: 2.1637495486967024

Epoch: 6| Step: 8
Training loss: 2.144360065460205
Validation loss: 2.15997927675965

Epoch: 6| Step: 9
Training loss: 2.749134063720703
Validation loss: 2.1423446004108717

Epoch: 6| Step: 10
Training loss: 2.875401020050049
Validation loss: 2.124544361586212

Epoch: 6| Step: 11
Training loss: 2.0097434520721436
Validation loss: 2.119654502919925

Epoch: 6| Step: 12
Training loss: 2.7459211349487305
Validation loss: 2.122936135979109

Epoch: 6| Step: 13
Training loss: 2.0805811882019043
Validation loss: 2.121722637966115

Epoch: 180| Step: 0
Training loss: 2.274874687194824
Validation loss: 2.1276503506527153

Epoch: 6| Step: 1
Training loss: 2.7780954837799072
Validation loss: 2.1406372772750033

Epoch: 6| Step: 2
Training loss: 2.3849544525146484
Validation loss: 2.148074742286436

Epoch: 6| Step: 3
Training loss: 2.03237247467041
Validation loss: 2.1667441809049217

Epoch: 6| Step: 4
Training loss: 1.9200016260147095
Validation loss: 2.1635583754508727

Epoch: 6| Step: 5
Training loss: 1.7702983617782593
Validation loss: 2.1750911179409234

Epoch: 6| Step: 6
Training loss: 2.7393879890441895
Validation loss: 2.19260633889065

Epoch: 6| Step: 7
Training loss: 2.248499631881714
Validation loss: 2.2043860932832122

Epoch: 6| Step: 8
Training loss: 2.3021461963653564
Validation loss: 2.2193067766004995

Epoch: 6| Step: 9
Training loss: 2.2040858268737793
Validation loss: 2.2063535900526148

Epoch: 6| Step: 10
Training loss: 2.925495147705078
Validation loss: 2.2040620465432443

Epoch: 6| Step: 11
Training loss: 2.6366195678710938
Validation loss: 2.2115229175936792

Epoch: 6| Step: 12
Training loss: 2.7300095558166504
Validation loss: 2.205036165893719

Epoch: 6| Step: 13
Training loss: 1.8192040920257568
Validation loss: 2.2095086369463193

Epoch: 181| Step: 0
Training loss: 2.763951301574707
Validation loss: 2.201086659585276

Epoch: 6| Step: 1
Training loss: 1.9375364780426025
Validation loss: 2.197076887212774

Epoch: 6| Step: 2
Training loss: 2.1199216842651367
Validation loss: 2.2130187416589386

Epoch: 6| Step: 3
Training loss: 3.1817455291748047
Validation loss: 2.2137967514735397

Epoch: 6| Step: 4
Training loss: 2.0008397102355957
Validation loss: 2.210468310181813

Epoch: 6| Step: 5
Training loss: 2.5361366271972656
Validation loss: 2.2157123473382767

Epoch: 6| Step: 6
Training loss: 2.0524370670318604
Validation loss: 2.2232478408403296

Epoch: 6| Step: 7
Training loss: 2.380465507507324
Validation loss: 2.2433508006475305

Epoch: 6| Step: 8
Training loss: 2.207360029220581
Validation loss: 2.2153791509648806

Epoch: 6| Step: 9
Training loss: 2.3022122383117676
Validation loss: 2.230314311160836

Epoch: 6| Step: 10
Training loss: 2.549880027770996
Validation loss: 2.2236211120441394

Epoch: 6| Step: 11
Training loss: 2.2760939598083496
Validation loss: 2.250567284963464

Epoch: 6| Step: 12
Training loss: 1.8980249166488647
Validation loss: 2.2012028155788297

Epoch: 6| Step: 13
Training loss: 2.8008203506469727
Validation loss: 2.207878585784666

Epoch: 182| Step: 0
Training loss: 2.118215560913086
Validation loss: 2.173663798198905

Epoch: 6| Step: 1
Training loss: 2.3333277702331543
Validation loss: 2.167571472865279

Epoch: 6| Step: 2
Training loss: 1.2648732662200928
Validation loss: 2.151196842552513

Epoch: 6| Step: 3
Training loss: 2.9269795417785645
Validation loss: 2.1539122519954557

Epoch: 6| Step: 4
Training loss: 1.8227850198745728
Validation loss: 2.14191892198337

Epoch: 6| Step: 5
Training loss: 1.930747628211975
Validation loss: 2.1347813349898144

Epoch: 6| Step: 6
Training loss: 2.992234468460083
Validation loss: 2.143253320006914

Epoch: 6| Step: 7
Training loss: 2.7692580223083496
Validation loss: 2.1318011386420137

Epoch: 6| Step: 8
Training loss: 2.393293857574463
Validation loss: 2.140610658994285

Epoch: 6| Step: 9
Training loss: 2.624964714050293
Validation loss: 2.136947065271357

Epoch: 6| Step: 10
Training loss: 1.8073163032531738
Validation loss: 2.153048401237816

Epoch: 6| Step: 11
Training loss: 2.8553080558776855
Validation loss: 2.1546545310686995

Epoch: 6| Step: 12
Training loss: 2.515057325363159
Validation loss: 2.1620512623940744

Epoch: 6| Step: 13
Training loss: 2.3727691173553467
Validation loss: 2.147420529396303

Epoch: 183| Step: 0
Training loss: 1.8507901430130005
Validation loss: 2.120756446674306

Epoch: 6| Step: 1
Training loss: 2.513132333755493
Validation loss: 2.123364415220035

Epoch: 6| Step: 2
Training loss: 2.823173761367798
Validation loss: 2.1161835847362394

Epoch: 6| Step: 3
Training loss: 1.8701331615447998
Validation loss: 2.1158655817790697

Epoch: 6| Step: 4
Training loss: 2.3269429206848145
Validation loss: 2.113264245371665

Epoch: 6| Step: 5
Training loss: 2.065688133239746
Validation loss: 2.115748210619855

Epoch: 6| Step: 6
Training loss: 2.235074758529663
Validation loss: 2.1169447821955525

Epoch: 6| Step: 7
Training loss: 2.924687623977661
Validation loss: 2.1459520555311635

Epoch: 6| Step: 8
Training loss: 1.922849178314209
Validation loss: 2.162099463965303

Epoch: 6| Step: 9
Training loss: 2.5317044258117676
Validation loss: 2.1671353053021174

Epoch: 6| Step: 10
Training loss: 2.2638611793518066
Validation loss: 2.191150503773843

Epoch: 6| Step: 11
Training loss: 2.487727642059326
Validation loss: 2.1704352760827668

Epoch: 6| Step: 12
Training loss: 2.516756057739258
Validation loss: 2.1497919815842823

Epoch: 6| Step: 13
Training loss: 2.5153748989105225
Validation loss: 2.140566973276036

Epoch: 184| Step: 0
Training loss: 2.507075309753418
Validation loss: 2.1500853005275933

Epoch: 6| Step: 1
Training loss: 2.211637020111084
Validation loss: 2.174766799455048

Epoch: 6| Step: 2
Training loss: 2.2154746055603027
Validation loss: 2.176442253974176

Epoch: 6| Step: 3
Training loss: 1.8983783721923828
Validation loss: 2.1703062929132932

Epoch: 6| Step: 4
Training loss: 2.1150076389312744
Validation loss: 2.163399814277567

Epoch: 6| Step: 5
Training loss: 2.1934547424316406
Validation loss: 2.171790402422669

Epoch: 6| Step: 6
Training loss: 3.065080404281616
Validation loss: 2.198423659929665

Epoch: 6| Step: 7
Training loss: 3.025580406188965
Validation loss: 2.214671024712183

Epoch: 6| Step: 8
Training loss: 2.278646230697632
Validation loss: 2.2410984987853677

Epoch: 6| Step: 9
Training loss: 2.244765281677246
Validation loss: 2.258778904073982

Epoch: 6| Step: 10
Training loss: 2.747696876525879
Validation loss: 2.253945073773784

Epoch: 6| Step: 11
Training loss: 1.7400264739990234
Validation loss: 2.24993553725622

Epoch: 6| Step: 12
Training loss: 2.5001838207244873
Validation loss: 2.269792543944492

Epoch: 6| Step: 13
Training loss: 2.1165552139282227
Validation loss: 2.29978972096597

Epoch: 185| Step: 0
Training loss: 2.5829596519470215
Validation loss: 2.3029849272902294

Epoch: 6| Step: 1
Training loss: 2.2640762329101562
Validation loss: 2.2541402668081303

Epoch: 6| Step: 2
Training loss: 2.6475863456726074
Validation loss: 2.1993060573454826

Epoch: 6| Step: 3
Training loss: 2.439016819000244
Validation loss: 2.1384984113836802

Epoch: 6| Step: 4
Training loss: 2.8169140815734863
Validation loss: 2.140558188961398

Epoch: 6| Step: 5
Training loss: 2.4693565368652344
Validation loss: 2.129417706561345

Epoch: 6| Step: 6
Training loss: 2.733203649520874
Validation loss: 2.1091798428566224

Epoch: 6| Step: 7
Training loss: 1.669137954711914
Validation loss: 2.1055544473791636

Epoch: 6| Step: 8
Training loss: 2.3422322273254395
Validation loss: 2.0899951022158385

Epoch: 6| Step: 9
Training loss: 2.223484516143799
Validation loss: 2.0933453036892797

Epoch: 6| Step: 10
Training loss: 2.1777796745300293
Validation loss: 2.1072691281636557

Epoch: 6| Step: 11
Training loss: 2.1841557025909424
Validation loss: 2.125771786576958

Epoch: 6| Step: 12
Training loss: 2.6340737342834473
Validation loss: 2.155269779184813

Epoch: 6| Step: 13
Training loss: 2.108050584793091
Validation loss: 2.20674725245404

Epoch: 186| Step: 0
Training loss: 2.4789390563964844
Validation loss: 2.23890087937796

Epoch: 6| Step: 1
Training loss: 2.5132157802581787
Validation loss: 2.241519425504951

Epoch: 6| Step: 2
Training loss: 2.553955554962158
Validation loss: 2.2124111216555358

Epoch: 6| Step: 3
Training loss: 2.4366798400878906
Validation loss: 2.1998955203640844

Epoch: 6| Step: 4
Training loss: 2.8842201232910156
Validation loss: 2.208120954933987

Epoch: 6| Step: 5
Training loss: 2.225451946258545
Validation loss: 2.1567453440799507

Epoch: 6| Step: 6
Training loss: 2.4132609367370605
Validation loss: 2.1347747233606156

Epoch: 6| Step: 7
Training loss: 1.9805753231048584
Validation loss: 2.114617445135629

Epoch: 6| Step: 8
Training loss: 1.9821158647537231
Validation loss: 2.1082509820179274

Epoch: 6| Step: 9
Training loss: 2.482907772064209
Validation loss: 2.102458756457093

Epoch: 6| Step: 10
Training loss: 2.1854004859924316
Validation loss: 2.108375173743053

Epoch: 6| Step: 11
Training loss: 2.193535327911377
Validation loss: 2.1060131339616674

Epoch: 6| Step: 12
Training loss: 2.620370388031006
Validation loss: 2.110682382378527

Epoch: 6| Step: 13
Training loss: 1.7553871870040894
Validation loss: 2.118456709769464

Epoch: 187| Step: 0
Training loss: 2.81351375579834
Validation loss: 2.117865229165682

Epoch: 6| Step: 1
Training loss: 1.9818590879440308
Validation loss: 2.1065700464351202

Epoch: 6| Step: 2
Training loss: 2.2119317054748535
Validation loss: 2.1014575214796167

Epoch: 6| Step: 3
Training loss: 2.2683305740356445
Validation loss: 2.1015582187201387

Epoch: 6| Step: 4
Training loss: 1.6985048055648804
Validation loss: 2.1256312657428045

Epoch: 6| Step: 5
Training loss: 1.7534303665161133
Validation loss: 2.1185920200040265

Epoch: 6| Step: 6
Training loss: 2.073038101196289
Validation loss: 2.142428646805466

Epoch: 6| Step: 7
Training loss: 2.1396994590759277
Validation loss: 2.1524965840001262

Epoch: 6| Step: 8
Training loss: 3.1363377571105957
Validation loss: 2.182565007158505

Epoch: 6| Step: 9
Training loss: 2.1148154735565186
Validation loss: 2.2024248235969135

Epoch: 6| Step: 10
Training loss: 2.719482421875
Validation loss: 2.2023306944036998

Epoch: 6| Step: 11
Training loss: 2.1958436965942383
Validation loss: 2.1951373994991346

Epoch: 6| Step: 12
Training loss: 3.274512529373169
Validation loss: 2.1965325032511065

Epoch: 6| Step: 13
Training loss: 2.571652412414551
Validation loss: 2.1742420017078357

Epoch: 188| Step: 0
Training loss: 2.334507703781128
Validation loss: 2.1614457881578835

Epoch: 6| Step: 1
Training loss: 2.1215062141418457
Validation loss: 2.148062357338526

Epoch: 6| Step: 2
Training loss: 2.342540979385376
Validation loss: 2.138112565522553

Epoch: 6| Step: 3
Training loss: 2.5949809551239014
Validation loss: 2.1376119980248074

Epoch: 6| Step: 4
Training loss: 2.670909881591797
Validation loss: 2.12898689059801

Epoch: 6| Step: 5
Training loss: 2.2759008407592773
Validation loss: 2.1487222768927134

Epoch: 6| Step: 6
Training loss: 1.6669719219207764
Validation loss: 2.1649757251944592

Epoch: 6| Step: 7
Training loss: 2.264845132827759
Validation loss: 2.1890945408933904

Epoch: 6| Step: 8
Training loss: 2.3293094635009766
Validation loss: 2.2067108756752423

Epoch: 6| Step: 9
Training loss: 2.957906723022461
Validation loss: 2.2157324411535777

Epoch: 6| Step: 10
Training loss: 2.6801841259002686
Validation loss: 2.2296965301677747

Epoch: 6| Step: 11
Training loss: 2.221146583557129
Validation loss: 2.2406358565053632

Epoch: 6| Step: 12
Training loss: 2.474824905395508
Validation loss: 2.2589068951145297

Epoch: 6| Step: 13
Training loss: 1.4632498025894165
Validation loss: 2.2693949617365354

Epoch: 189| Step: 0
Training loss: 2.1415841579437256
Validation loss: 2.2013269932039323

Epoch: 6| Step: 1
Training loss: 2.152876138687134
Validation loss: 2.133458734840475

Epoch: 6| Step: 2
Training loss: 2.4520442485809326
Validation loss: 2.1061582744762464

Epoch: 6| Step: 3
Training loss: 2.5513670444488525
Validation loss: 2.1055071174457507

Epoch: 6| Step: 4
Training loss: 2.3115994930267334
Validation loss: 2.1210389457723147

Epoch: 6| Step: 5
Training loss: 2.7742462158203125
Validation loss: 2.12078341104651

Epoch: 6| Step: 6
Training loss: 2.254251480102539
Validation loss: 2.1212080050540227

Epoch: 6| Step: 7
Training loss: 2.279256820678711
Validation loss: 2.1240865645870084

Epoch: 6| Step: 8
Training loss: 2.193861484527588
Validation loss: 2.095999280611674

Epoch: 6| Step: 9
Training loss: 2.6243207454681396
Validation loss: 2.0930772827517603

Epoch: 6| Step: 10
Training loss: 2.4441137313842773
Validation loss: 2.1039495570685274

Epoch: 6| Step: 11
Training loss: 2.171971559524536
Validation loss: 2.1308040875260548

Epoch: 6| Step: 12
Training loss: 2.178786277770996
Validation loss: 2.1801281949525237

Epoch: 6| Step: 13
Training loss: 2.320512533187866
Validation loss: 2.2067015119778213

Epoch: 190| Step: 0
Training loss: 2.1153478622436523
Validation loss: 2.227454032949222

Epoch: 6| Step: 1
Training loss: 2.0709877014160156
Validation loss: 2.2178565212475356

Epoch: 6| Step: 2
Training loss: 2.128512382507324
Validation loss: 2.2060342040113223

Epoch: 6| Step: 3
Training loss: 2.518995761871338
Validation loss: 2.179501055389322

Epoch: 6| Step: 4
Training loss: 2.6201467514038086
Validation loss: 2.1733776523220922

Epoch: 6| Step: 5
Training loss: 1.9393943548202515
Validation loss: 2.1465248753947597

Epoch: 6| Step: 6
Training loss: 2.2938570976257324
Validation loss: 2.1256849688868367

Epoch: 6| Step: 7
Training loss: 2.4003219604492188
Validation loss: 2.1138769272835023

Epoch: 6| Step: 8
Training loss: 2.3453762531280518
Validation loss: 2.1200097658300914

Epoch: 6| Step: 9
Training loss: 2.1342098712921143
Validation loss: 2.1257787878795336

Epoch: 6| Step: 10
Training loss: 2.3037426471710205
Validation loss: 2.1432701644077095

Epoch: 6| Step: 11
Training loss: 2.6234450340270996
Validation loss: 2.1501154848324355

Epoch: 6| Step: 12
Training loss: 2.4408247470855713
Validation loss: 2.1606788942890782

Epoch: 6| Step: 13
Training loss: 3.1599912643432617
Validation loss: 2.1643059151147

Epoch: 191| Step: 0
Training loss: 2.3284592628479004
Validation loss: 2.130449225825648

Epoch: 6| Step: 1
Training loss: 2.0911002159118652
Validation loss: 2.115868906820974

Epoch: 6| Step: 2
Training loss: 2.888021469116211
Validation loss: 2.119865773826517

Epoch: 6| Step: 3
Training loss: 1.8457260131835938
Validation loss: 2.126125689475767

Epoch: 6| Step: 4
Training loss: 2.680144786834717
Validation loss: 2.160332436202675

Epoch: 6| Step: 5
Training loss: 2.412895679473877
Validation loss: 2.182096774860095

Epoch: 6| Step: 6
Training loss: 2.5040526390075684
Validation loss: 2.2042599749821488

Epoch: 6| Step: 7
Training loss: 3.016494035720825
Validation loss: 2.211210455945743

Epoch: 6| Step: 8
Training loss: 2.239866256713867
Validation loss: 2.22994629926579

Epoch: 6| Step: 9
Training loss: 1.9422392845153809
Validation loss: 2.2074935743885655

Epoch: 6| Step: 10
Training loss: 2.7408981323242188
Validation loss: 2.195441563924154

Epoch: 6| Step: 11
Training loss: 2.2496471405029297
Validation loss: 2.17127130364859

Epoch: 6| Step: 12
Training loss: 1.682708501815796
Validation loss: 2.173661901104835

Epoch: 6| Step: 13
Training loss: 1.821103811264038
Validation loss: 2.1541216193988757

Epoch: 192| Step: 0
Training loss: 1.5135304927825928
Validation loss: 2.1504150616225375

Epoch: 6| Step: 1
Training loss: 2.756606101989746
Validation loss: 2.1558382921321417

Epoch: 6| Step: 2
Training loss: 2.2021732330322266
Validation loss: 2.153227260035853

Epoch: 6| Step: 3
Training loss: 2.811760902404785
Validation loss: 2.1684182049125753

Epoch: 6| Step: 4
Training loss: 3.099386692047119
Validation loss: 2.1672832017303794

Epoch: 6| Step: 5
Training loss: 2.6577649116516113
Validation loss: 2.1555866426037205

Epoch: 6| Step: 6
Training loss: 1.980645775794983
Validation loss: 2.152355659392572

Epoch: 6| Step: 7
Training loss: 2.6167149543762207
Validation loss: 2.143785276720601

Epoch: 6| Step: 8
Training loss: 2.1629819869995117
Validation loss: 2.14548034052695

Epoch: 6| Step: 9
Training loss: 2.145170211791992
Validation loss: 2.129684002168717

Epoch: 6| Step: 10
Training loss: 2.082577705383301
Validation loss: 2.12205615351277

Epoch: 6| Step: 11
Training loss: 2.0687341690063477
Validation loss: 2.132970848391133

Epoch: 6| Step: 12
Training loss: 1.7686841487884521
Validation loss: 2.1412022011254424

Epoch: 6| Step: 13
Training loss: 2.6229591369628906
Validation loss: 2.1591082619082544

Epoch: 193| Step: 0
Training loss: 1.6949663162231445
Validation loss: 2.1778767621645363

Epoch: 6| Step: 1
Training loss: 2.147993803024292
Validation loss: 2.1788273370394142

Epoch: 6| Step: 2
Training loss: 2.5463552474975586
Validation loss: 2.166844549999442

Epoch: 6| Step: 3
Training loss: 2.803504228591919
Validation loss: 2.166982646911375

Epoch: 6| Step: 4
Training loss: 1.789777398109436
Validation loss: 2.1546039119843514

Epoch: 6| Step: 5
Training loss: 1.5895342826843262
Validation loss: 2.1499205558530745

Epoch: 6| Step: 6
Training loss: 2.2043509483337402
Validation loss: 2.1380935638181624

Epoch: 6| Step: 7
Training loss: 3.178619384765625
Validation loss: 2.129556530265398

Epoch: 6| Step: 8
Training loss: 2.6737687587738037
Validation loss: 2.111503234473608

Epoch: 6| Step: 9
Training loss: 1.9756767749786377
Validation loss: 2.104366535781532

Epoch: 6| Step: 10
Training loss: 2.623387098312378
Validation loss: 2.1041479405536445

Epoch: 6| Step: 11
Training loss: 1.994776964187622
Validation loss: 2.091602622821767

Epoch: 6| Step: 12
Training loss: 2.094326972961426
Validation loss: 2.0909549997698877

Epoch: 6| Step: 13
Training loss: 3.2885680198669434
Validation loss: 2.0811927062208935

Epoch: 194| Step: 0
Training loss: 1.8774008750915527
Validation loss: 2.07593196950933

Epoch: 6| Step: 1
Training loss: 2.415468215942383
Validation loss: 2.0872886821787846

Epoch: 6| Step: 2
Training loss: 2.5858702659606934
Validation loss: 2.1057405010346444

Epoch: 6| Step: 3
Training loss: 2.605445146560669
Validation loss: 2.099595521086006

Epoch: 6| Step: 4
Training loss: 2.731203556060791
Validation loss: 2.1117561094222532

Epoch: 6| Step: 5
Training loss: 2.2234303951263428
Validation loss: 2.1124105748309883

Epoch: 6| Step: 6
Training loss: 1.9472687244415283
Validation loss: 2.1100687493560133

Epoch: 6| Step: 7
Training loss: 2.1139822006225586
Validation loss: 2.116057772790232

Epoch: 6| Step: 8
Training loss: 2.25140380859375
Validation loss: 2.120799646582655

Epoch: 6| Step: 9
Training loss: 2.4153811931610107
Validation loss: 2.1276595015679636

Epoch: 6| Step: 10
Training loss: 2.334151268005371
Validation loss: 2.122635179950345

Epoch: 6| Step: 11
Training loss: 2.141324043273926
Validation loss: 2.1234296521832867

Epoch: 6| Step: 12
Training loss: 2.574282169342041
Validation loss: 2.12832228086328

Epoch: 6| Step: 13
Training loss: 1.5686438083648682
Validation loss: 2.1332916995530486

Epoch: 195| Step: 0
Training loss: 2.306060791015625
Validation loss: 2.159924586613973

Epoch: 6| Step: 1
Training loss: 2.0968713760375977
Validation loss: 2.186090071996053

Epoch: 6| Step: 2
Training loss: 1.840468406677246
Validation loss: 2.1962419632942445

Epoch: 6| Step: 3
Training loss: 2.150468587875366
Validation loss: 2.1892899146644016

Epoch: 6| Step: 4
Training loss: 1.6938354969024658
Validation loss: 2.19478060994097

Epoch: 6| Step: 5
Training loss: 2.4193506240844727
Validation loss: 2.1931490975041545

Epoch: 6| Step: 6
Training loss: 2.6295957565307617
Validation loss: 2.1675892901676956

Epoch: 6| Step: 7
Training loss: 2.2484161853790283
Validation loss: 2.1490141448154243

Epoch: 6| Step: 8
Training loss: 2.0785796642303467
Validation loss: 2.1331377234510196

Epoch: 6| Step: 9
Training loss: 2.603712558746338
Validation loss: 2.121837403184624

Epoch: 6| Step: 10
Training loss: 2.3312864303588867
Validation loss: 2.114725649997752

Epoch: 6| Step: 11
Training loss: 2.483853340148926
Validation loss: 2.121690172021107

Epoch: 6| Step: 12
Training loss: 2.485206127166748
Validation loss: 2.1244394548477663

Epoch: 6| Step: 13
Training loss: 3.0997304916381836
Validation loss: 2.126409525512367

Epoch: 196| Step: 0
Training loss: 2.033371925354004
Validation loss: 2.1286428538701867

Epoch: 6| Step: 1
Training loss: 1.5628440380096436
Validation loss: 2.159169445755661

Epoch: 6| Step: 2
Training loss: 2.0296154022216797
Validation loss: 2.1939082043145293

Epoch: 6| Step: 3
Training loss: 3.1420156955718994
Validation loss: 2.1907844030728905

Epoch: 6| Step: 4
Training loss: 2.625013828277588
Validation loss: 2.1770729531524

Epoch: 6| Step: 5
Training loss: 1.640453577041626
Validation loss: 2.1629884730103197

Epoch: 6| Step: 6
Training loss: 1.9661632776260376
Validation loss: 2.141547833719561

Epoch: 6| Step: 7
Training loss: 2.0227150917053223
Validation loss: 2.133807272039434

Epoch: 6| Step: 8
Training loss: 1.9288026094436646
Validation loss: 2.1177839720120994

Epoch: 6| Step: 9
Training loss: 2.3318238258361816
Validation loss: 2.1122280756632485

Epoch: 6| Step: 10
Training loss: 2.100767135620117
Validation loss: 2.112745723416728

Epoch: 6| Step: 11
Training loss: 2.7765614986419678
Validation loss: 2.112397454118216

Epoch: 6| Step: 12
Training loss: 2.843972682952881
Validation loss: 2.115817464807982

Epoch: 6| Step: 13
Training loss: 3.210984230041504
Validation loss: 2.119808881513534

Epoch: 197| Step: 0
Training loss: 1.9494361877441406
Validation loss: 2.1097625455548688

Epoch: 6| Step: 1
Training loss: 1.9750044345855713
Validation loss: 2.0996054962117183

Epoch: 6| Step: 2
Training loss: 1.9804604053497314
Validation loss: 2.0922262130245084

Epoch: 6| Step: 3
Training loss: 2.5808792114257812
Validation loss: 2.10241828298056

Epoch: 6| Step: 4
Training loss: 2.8915486335754395
Validation loss: 2.1055791634385304

Epoch: 6| Step: 5
Training loss: 1.817030429840088
Validation loss: 2.121956807310863

Epoch: 6| Step: 6
Training loss: 2.8303308486938477
Validation loss: 2.121288171378515

Epoch: 6| Step: 7
Training loss: 1.728308916091919
Validation loss: 2.132064812926836

Epoch: 6| Step: 8
Training loss: 2.5662412643432617
Validation loss: 2.1404225005898425

Epoch: 6| Step: 9
Training loss: 2.360290765762329
Validation loss: 2.131641621230751

Epoch: 6| Step: 10
Training loss: 2.6635873317718506
Validation loss: 2.1292882196364866

Epoch: 6| Step: 11
Training loss: 2.2661194801330566
Validation loss: 2.1488999448796755

Epoch: 6| Step: 12
Training loss: 1.6221387386322021
Validation loss: 2.1311481665539485

Epoch: 6| Step: 13
Training loss: 2.867981433868408
Validation loss: 2.137678010489351

Epoch: 198| Step: 0
Training loss: 2.415616989135742
Validation loss: 2.126053640919347

Epoch: 6| Step: 1
Training loss: 2.269996166229248
Validation loss: 2.1249219499608523

Epoch: 6| Step: 2
Training loss: 2.2443151473999023
Validation loss: 2.1132962434522566

Epoch: 6| Step: 3
Training loss: 2.752855062484741
Validation loss: 2.108253031648615

Epoch: 6| Step: 4
Training loss: 2.0655736923217773
Validation loss: 2.0894554981621365

Epoch: 6| Step: 5
Training loss: 2.0956201553344727
Validation loss: 2.079812243420591

Epoch: 6| Step: 6
Training loss: 2.021341562271118
Validation loss: 2.0840057724265644

Epoch: 6| Step: 7
Training loss: 2.454129934310913
Validation loss: 2.071324262567746

Epoch: 6| Step: 8
Training loss: 2.259586811065674
Validation loss: 2.0789308278791365

Epoch: 6| Step: 9
Training loss: 2.5972838401794434
Validation loss: 2.073752312250035

Epoch: 6| Step: 10
Training loss: 2.5842654705047607
Validation loss: 2.0913945692841724

Epoch: 6| Step: 11
Training loss: 1.9035545587539673
Validation loss: 2.0970955202656407

Epoch: 6| Step: 12
Training loss: 1.830733299255371
Validation loss: 2.1214020905956144

Epoch: 6| Step: 13
Training loss: 2.2710118293762207
Validation loss: 2.1234100659688315

Epoch: 199| Step: 0
Training loss: 2.596259355545044
Validation loss: 2.1113782159743772

Epoch: 6| Step: 1
Training loss: 2.5232434272766113
Validation loss: 2.1062432694178757

Epoch: 6| Step: 2
Training loss: 1.2923548221588135
Validation loss: 2.105822068388744

Epoch: 6| Step: 3
Training loss: 2.23300838470459
Validation loss: 2.1172211785470285

Epoch: 6| Step: 4
Training loss: 2.4046263694763184
Validation loss: 2.122878610446889

Epoch: 6| Step: 5
Training loss: 1.9247071743011475
Validation loss: 2.146695734352194

Epoch: 6| Step: 6
Training loss: 1.746819019317627
Validation loss: 2.1783940330628426

Epoch: 6| Step: 7
Training loss: 3.210106134414673
Validation loss: 2.175272028933289

Epoch: 6| Step: 8
Training loss: 2.166728973388672
Validation loss: 2.1678562215579453

Epoch: 6| Step: 9
Training loss: 1.8733378648757935
Validation loss: 2.1655440202323337

Epoch: 6| Step: 10
Training loss: 2.1864185333251953
Validation loss: 2.1431470327479865

Epoch: 6| Step: 11
Training loss: 2.2219395637512207
Validation loss: 2.1227660743139123

Epoch: 6| Step: 12
Training loss: 2.867767333984375
Validation loss: 2.1238062740654073

Epoch: 6| Step: 13
Training loss: 2.495892286300659
Validation loss: 2.1218572713995494

Epoch: 200| Step: 0
Training loss: 1.6452610492706299
Validation loss: 2.099308377952986

Epoch: 6| Step: 1
Training loss: 2.1181535720825195
Validation loss: 2.0987120879593717

Epoch: 6| Step: 2
Training loss: 2.4483461380004883
Validation loss: 2.1081957611986386

Epoch: 6| Step: 3
Training loss: 2.6486501693725586
Validation loss: 2.1135311818891958

Epoch: 6| Step: 4
Training loss: 2.404294967651367
Validation loss: 2.116164448440716

Epoch: 6| Step: 5
Training loss: 2.2494466304779053
Validation loss: 2.1352328869604293

Epoch: 6| Step: 6
Training loss: 2.3095126152038574
Validation loss: 2.1408275045374388

Epoch: 6| Step: 7
Training loss: 1.9176249504089355
Validation loss: 2.165947050176641

Epoch: 6| Step: 8
Training loss: 2.244601011276245
Validation loss: 2.1781582191426265

Epoch: 6| Step: 9
Training loss: 1.9115655422210693
Validation loss: 2.2023763502797773

Epoch: 6| Step: 10
Training loss: 3.0058674812316895
Validation loss: 2.1857213615089335

Epoch: 6| Step: 11
Training loss: 2.460508346557617
Validation loss: 2.1764589535292758

Epoch: 6| Step: 12
Training loss: 2.3125176429748535
Validation loss: 2.1712989448219218

Epoch: 6| Step: 13
Training loss: 1.9652525186538696
Validation loss: 2.1410527190854474

Epoch: 201| Step: 0
Training loss: 2.840022087097168
Validation loss: 2.1343346283000004

Epoch: 6| Step: 1
Training loss: 2.7269694805145264
Validation loss: 2.1005268455833517

Epoch: 6| Step: 2
Training loss: 1.8898060321807861
Validation loss: 2.0903597621507544

Epoch: 6| Step: 3
Training loss: 2.520397663116455
Validation loss: 2.0881308868367183

Epoch: 6| Step: 4
Training loss: 2.2195394039154053
Validation loss: 2.0811579176174697

Epoch: 6| Step: 5
Training loss: 2.484938621520996
Validation loss: 2.0866410591269053

Epoch: 6| Step: 6
Training loss: 1.8704133033752441
Validation loss: 2.085312115248813

Epoch: 6| Step: 7
Training loss: 2.344717502593994
Validation loss: 2.0861783232740176

Epoch: 6| Step: 8
Training loss: 3.0250930786132812
Validation loss: 2.091344089918239

Epoch: 6| Step: 9
Training loss: 1.8297772407531738
Validation loss: 2.1013276115540536

Epoch: 6| Step: 10
Training loss: 2.2348508834838867
Validation loss: 2.1084612005500385

Epoch: 6| Step: 11
Training loss: 1.6671550273895264
Validation loss: 2.139571720553983

Epoch: 6| Step: 12
Training loss: 1.824744462966919
Validation loss: 2.1572672346586823

Epoch: 6| Step: 13
Training loss: 2.0199975967407227
Validation loss: 2.1490135474871566

Epoch: 202| Step: 0
Training loss: 1.8274095058441162
Validation loss: 2.143392898703134

Epoch: 6| Step: 1
Training loss: 2.6166114807128906
Validation loss: 2.1402792597329743

Epoch: 6| Step: 2
Training loss: 2.03975772857666
Validation loss: 2.136828781456076

Epoch: 6| Step: 3
Training loss: 2.129446506500244
Validation loss: 2.13673980774418

Epoch: 6| Step: 4
Training loss: 1.6342809200286865
Validation loss: 2.1189719835917153

Epoch: 6| Step: 5
Training loss: 2.3245911598205566
Validation loss: 2.1209325867314495

Epoch: 6| Step: 6
Training loss: 1.9935927391052246
Validation loss: 2.118194321150421

Epoch: 6| Step: 7
Training loss: 2.1302525997161865
Validation loss: 2.1126243273417153

Epoch: 6| Step: 8
Training loss: 2.2921175956726074
Validation loss: 2.11878211908443

Epoch: 6| Step: 9
Training loss: 2.407414436340332
Validation loss: 2.1019185217477943

Epoch: 6| Step: 10
Training loss: 2.504951000213623
Validation loss: 2.122892440006297

Epoch: 6| Step: 11
Training loss: 2.714712619781494
Validation loss: 2.1123400349770822

Epoch: 6| Step: 12
Training loss: 2.84317684173584
Validation loss: 2.1071209176894157

Epoch: 6| Step: 13
Training loss: 1.645630955696106
Validation loss: 2.0957354858357418

Epoch: 203| Step: 0
Training loss: 2.2982137203216553
Validation loss: 2.0815308606752785

Epoch: 6| Step: 1
Training loss: 2.789332151412964
Validation loss: 2.076715402705695

Epoch: 6| Step: 2
Training loss: 1.6400233507156372
Validation loss: 2.071144248849602

Epoch: 6| Step: 3
Training loss: 2.305889368057251
Validation loss: 2.077708710906326

Epoch: 6| Step: 4
Training loss: 2.0821189880371094
Validation loss: 2.0788708656064925

Epoch: 6| Step: 5
Training loss: 2.6003713607788086
Validation loss: 2.0806880804800216

Epoch: 6| Step: 6
Training loss: 1.9842138290405273
Validation loss: 2.069706375880908

Epoch: 6| Step: 7
Training loss: 1.7218294143676758
Validation loss: 2.0797649762963735

Epoch: 6| Step: 8
Training loss: 2.2641899585723877
Validation loss: 2.084799464030932

Epoch: 6| Step: 9
Training loss: 2.246080160140991
Validation loss: 2.0956212115544144

Epoch: 6| Step: 10
Training loss: 2.488673686981201
Validation loss: 2.078528736227302

Epoch: 6| Step: 11
Training loss: 2.091869831085205
Validation loss: 2.0922329989812707

Epoch: 6| Step: 12
Training loss: 2.334296941757202
Validation loss: 2.088521868951859

Epoch: 6| Step: 13
Training loss: 2.5356597900390625
Validation loss: 2.099750926417689

Epoch: 204| Step: 0
Training loss: 1.655336618423462
Validation loss: 2.1245630787264917

Epoch: 6| Step: 1
Training loss: 2.5333666801452637
Validation loss: 2.1301138965032433

Epoch: 6| Step: 2
Training loss: 2.1691665649414062
Validation loss: 2.1419395682632283

Epoch: 6| Step: 3
Training loss: 2.368943691253662
Validation loss: 2.155506359633579

Epoch: 6| Step: 4
Training loss: 2.45650053024292
Validation loss: 2.1677142035576606

Epoch: 6| Step: 5
Training loss: 2.2798237800598145
Validation loss: 2.175236116173447

Epoch: 6| Step: 6
Training loss: 2.8803188800811768
Validation loss: 2.196075318962015

Epoch: 6| Step: 7
Training loss: 2.9229283332824707
Validation loss: 2.1972655993635937

Epoch: 6| Step: 8
Training loss: 2.8468027114868164
Validation loss: 2.1908027561762

Epoch: 6| Step: 9
Training loss: 1.8963449001312256
Validation loss: 2.1491859753926597

Epoch: 6| Step: 10
Training loss: 1.7119187116622925
Validation loss: 2.1385390579059558

Epoch: 6| Step: 11
Training loss: 2.0196404457092285
Validation loss: 2.127252023707154

Epoch: 6| Step: 12
Training loss: 1.8408339023590088
Validation loss: 2.118522218478623

Epoch: 6| Step: 13
Training loss: 1.3064519166946411
Validation loss: 2.102716576668524

Epoch: 205| Step: 0
Training loss: 2.879338264465332
Validation loss: 2.09146761637862

Epoch: 6| Step: 1
Training loss: 2.2779338359832764
Validation loss: 2.0987623583885933

Epoch: 6| Step: 2
Training loss: 2.5300681591033936
Validation loss: 2.0956605813836537

Epoch: 6| Step: 3
Training loss: 2.191671371459961
Validation loss: 2.0859015744219542

Epoch: 6| Step: 4
Training loss: 1.7478612661361694
Validation loss: 2.071280538394887

Epoch: 6| Step: 5
Training loss: 2.9189839363098145
Validation loss: 2.0600668794365338

Epoch: 6| Step: 6
Training loss: 1.7660305500030518
Validation loss: 2.0546785029031898

Epoch: 6| Step: 7
Training loss: 2.4785265922546387
Validation loss: 2.0626167225581344

Epoch: 6| Step: 8
Training loss: 1.9955739974975586
Validation loss: 2.0682903182122017

Epoch: 6| Step: 9
Training loss: 2.0847222805023193
Validation loss: 2.065557154276038

Epoch: 6| Step: 10
Training loss: 2.6869068145751953
Validation loss: 2.0870077968925558

Epoch: 6| Step: 11
Training loss: 1.8711904287338257
Validation loss: 2.090666522261917

Epoch: 6| Step: 12
Training loss: 2.0322458744049072
Validation loss: 2.1093041691728818

Epoch: 6| Step: 13
Training loss: 2.0055532455444336
Validation loss: 2.122640312358897

Epoch: 206| Step: 0
Training loss: 2.083430290222168
Validation loss: 2.100282005084458

Epoch: 6| Step: 1
Training loss: 2.635715961456299
Validation loss: 2.0808497116129887

Epoch: 6| Step: 2
Training loss: 1.9758028984069824
Validation loss: 2.066771302171933

Epoch: 6| Step: 3
Training loss: 2.5830507278442383
Validation loss: 2.071001220774907

Epoch: 6| Step: 4
Training loss: 2.4066786766052246
Validation loss: 2.0744827024398313

Epoch: 6| Step: 5
Training loss: 2.055975914001465
Validation loss: 2.081235903565602

Epoch: 6| Step: 6
Training loss: 2.616908073425293
Validation loss: 2.0770030688214045

Epoch: 6| Step: 7
Training loss: 1.794191598892212
Validation loss: 2.087852506227391

Epoch: 6| Step: 8
Training loss: 2.485234260559082
Validation loss: 2.1028679686207927

Epoch: 6| Step: 9
Training loss: 2.1290626525878906
Validation loss: 2.1137771426990466

Epoch: 6| Step: 10
Training loss: 2.9669740200042725
Validation loss: 2.1219927392980105

Epoch: 6| Step: 11
Training loss: 1.2018227577209473
Validation loss: 2.1185280533247095

Epoch: 6| Step: 12
Training loss: 2.279660224914551
Validation loss: 2.1043291322646605

Epoch: 6| Step: 13
Training loss: 1.5451160669326782
Validation loss: 2.109948645355881

Epoch: 207| Step: 0
Training loss: 2.651674509048462
Validation loss: 2.10487469550102

Epoch: 6| Step: 1
Training loss: 2.9405884742736816
Validation loss: 2.1271566652482554

Epoch: 6| Step: 2
Training loss: 1.900080680847168
Validation loss: 2.1388108986680225

Epoch: 6| Step: 3
Training loss: 2.246184825897217
Validation loss: 2.1616611737076954

Epoch: 6| Step: 4
Training loss: 2.2553277015686035
Validation loss: 2.165573652072619

Epoch: 6| Step: 5
Training loss: 1.6241540908813477
Validation loss: 2.165051867884974

Epoch: 6| Step: 6
Training loss: 2.5711445808410645
Validation loss: 2.1615592407923874

Epoch: 6| Step: 7
Training loss: 2.0185441970825195
Validation loss: 2.133422041452059

Epoch: 6| Step: 8
Training loss: 1.4854183197021484
Validation loss: 2.1216460658657934

Epoch: 6| Step: 9
Training loss: 1.9292110204696655
Validation loss: 2.107217570786835

Epoch: 6| Step: 10
Training loss: 2.007913589477539
Validation loss: 2.093628429597424

Epoch: 6| Step: 11
Training loss: 2.89689040184021
Validation loss: 2.092961690759146

Epoch: 6| Step: 12
Training loss: 2.57684588432312
Validation loss: 2.0816935954555387

Epoch: 6| Step: 13
Training loss: 1.900016188621521
Validation loss: 2.0803648271868305

Epoch: 208| Step: 0
Training loss: 1.74369478225708
Validation loss: 2.083351283945063

Epoch: 6| Step: 1
Training loss: 2.5336663722991943
Validation loss: 2.077076654280386

Epoch: 6| Step: 2
Training loss: 2.6902015209198
Validation loss: 2.073258520454489

Epoch: 6| Step: 3
Training loss: 1.5825202465057373
Validation loss: 2.0669139046822824

Epoch: 6| Step: 4
Training loss: 2.4265389442443848
Validation loss: 2.062524782714023

Epoch: 6| Step: 5
Training loss: 2.896970748901367
Validation loss: 2.070473599177535

Epoch: 6| Step: 6
Training loss: 1.9312396049499512
Validation loss: 2.074374447586716

Epoch: 6| Step: 7
Training loss: 2.2250113487243652
Validation loss: 2.088539590117752

Epoch: 6| Step: 8
Training loss: 1.9998489618301392
Validation loss: 2.089626204582953

Epoch: 6| Step: 9
Training loss: 2.281130313873291
Validation loss: 2.1069870584754535

Epoch: 6| Step: 10
Training loss: 2.2180237770080566
Validation loss: 2.1094466435011996

Epoch: 6| Step: 11
Training loss: 2.196134090423584
Validation loss: 2.1042649874123196

Epoch: 6| Step: 12
Training loss: 1.9557523727416992
Validation loss: 2.094163897216961

Epoch: 6| Step: 13
Training loss: 1.9126352071762085
Validation loss: 2.0902052502478323

Epoch: 209| Step: 0
Training loss: 1.0423508882522583
Validation loss: 2.1170655194149224

Epoch: 6| Step: 1
Training loss: 2.633842945098877
Validation loss: 2.115513506756034

Epoch: 6| Step: 2
Training loss: 2.4222609996795654
Validation loss: 2.1070121718991186

Epoch: 6| Step: 3
Training loss: 2.3122076988220215
Validation loss: 2.0993714050580095

Epoch: 6| Step: 4
Training loss: 2.17134428024292
Validation loss: 2.0893762034754597

Epoch: 6| Step: 5
Training loss: 2.549623489379883
Validation loss: 2.0975670353058846

Epoch: 6| Step: 6
Training loss: 1.661415934562683
Validation loss: 2.0979886029356267

Epoch: 6| Step: 7
Training loss: 2.5084829330444336
Validation loss: 2.1025138721671155

Epoch: 6| Step: 8
Training loss: 2.6744179725646973
Validation loss: 2.1206539241216515

Epoch: 6| Step: 9
Training loss: 2.189117670059204
Validation loss: 2.121669884650938

Epoch: 6| Step: 10
Training loss: 2.0797557830810547
Validation loss: 2.117465514008717

Epoch: 6| Step: 11
Training loss: 2.6004397869110107
Validation loss: 2.139546708394122

Epoch: 6| Step: 12
Training loss: 1.8608958721160889
Validation loss: 2.137729629393547

Epoch: 6| Step: 13
Training loss: 1.6728816032409668
Validation loss: 2.129126597476262

Epoch: 210| Step: 0
Training loss: 1.705824851989746
Validation loss: 2.1145480268745014

Epoch: 6| Step: 1
Training loss: 1.63248872756958
Validation loss: 2.112616285201042

Epoch: 6| Step: 2
Training loss: 2.4057674407958984
Validation loss: 2.117380929249589

Epoch: 6| Step: 3
Training loss: 2.0217838287353516
Validation loss: 2.1382755079577045

Epoch: 6| Step: 4
Training loss: 2.105531692504883
Validation loss: 2.1501801783038723

Epoch: 6| Step: 5
Training loss: 1.976449728012085
Validation loss: 2.143080392191487

Epoch: 6| Step: 6
Training loss: 2.0225887298583984
Validation loss: 2.1357630170801634

Epoch: 6| Step: 7
Training loss: 1.9218950271606445
Validation loss: 2.1183446581645677

Epoch: 6| Step: 8
Training loss: 1.8219859600067139
Validation loss: 2.0925752270606255

Epoch: 6| Step: 9
Training loss: 2.7665257453918457
Validation loss: 2.089836679479127

Epoch: 6| Step: 10
Training loss: 2.9006776809692383
Validation loss: 2.083679206909672

Epoch: 6| Step: 11
Training loss: 3.027189016342163
Validation loss: 2.074862831382341

Epoch: 6| Step: 12
Training loss: 2.3238258361816406
Validation loss: 2.0732523113168697

Epoch: 6| Step: 13
Training loss: 1.5717923641204834
Validation loss: 2.069081926858553

Epoch: 211| Step: 0
Training loss: 1.879702091217041
Validation loss: 2.0715737060834

Epoch: 6| Step: 1
Training loss: 2.548576831817627
Validation loss: 2.0662093675264748

Epoch: 6| Step: 2
Training loss: 1.6645162105560303
Validation loss: 2.0916461406215543

Epoch: 6| Step: 3
Training loss: 2.4151015281677246
Validation loss: 2.081559988760179

Epoch: 6| Step: 4
Training loss: 2.700467109680176
Validation loss: 2.082480014011424

Epoch: 6| Step: 5
Training loss: 2.9747748374938965
Validation loss: 2.0776556230360463

Epoch: 6| Step: 6
Training loss: 1.8626084327697754
Validation loss: 2.0865062872568765

Epoch: 6| Step: 7
Training loss: 1.8321545124053955
Validation loss: 2.082828757583454

Epoch: 6| Step: 8
Training loss: 2.1494061946868896
Validation loss: 2.0940068767916773

Epoch: 6| Step: 9
Training loss: 2.137786388397217
Validation loss: 2.092888347564205

Epoch: 6| Step: 10
Training loss: 1.8832687139511108
Validation loss: 2.1253198705693728

Epoch: 6| Step: 11
Training loss: 1.4655122756958008
Validation loss: 2.132370912900535

Epoch: 6| Step: 12
Training loss: 2.964080572128296
Validation loss: 2.1598419553490094

Epoch: 6| Step: 13
Training loss: 2.100754499435425
Validation loss: 2.1662454964012228

Epoch: 212| Step: 0
Training loss: 2.2073216438293457
Validation loss: 2.156298619444652

Epoch: 6| Step: 1
Training loss: 1.841872215270996
Validation loss: 2.174294150003823

Epoch: 6| Step: 2
Training loss: 1.833452582359314
Validation loss: 2.154575494027907

Epoch: 6| Step: 3
Training loss: 1.8750373125076294
Validation loss: 2.1374179214559574

Epoch: 6| Step: 4
Training loss: 2.1083953380584717
Validation loss: 2.1181645483099003

Epoch: 6| Step: 5
Training loss: 1.539745569229126
Validation loss: 2.0827574729919434

Epoch: 6| Step: 6
Training loss: 1.9369159936904907
Validation loss: 2.0743382438536613

Epoch: 6| Step: 7
Training loss: 1.9596648216247559
Validation loss: 2.0645899849553264

Epoch: 6| Step: 8
Training loss: 2.572394371032715
Validation loss: 2.0681006652052685

Epoch: 6| Step: 9
Training loss: 2.4477319717407227
Validation loss: 2.0712129159640242

Epoch: 6| Step: 10
Training loss: 2.842165946960449
Validation loss: 2.0613708367911716

Epoch: 6| Step: 11
Training loss: 2.6089067459106445
Validation loss: 2.0621441115615187

Epoch: 6| Step: 12
Training loss: 2.3114371299743652
Validation loss: 2.066185159067954

Epoch: 6| Step: 13
Training loss: 2.361764669418335
Validation loss: 2.079046283998797

Epoch: 213| Step: 0
Training loss: 2.5670230388641357
Validation loss: 2.101473093032837

Epoch: 6| Step: 1
Training loss: 2.4304213523864746
Validation loss: 2.1140982720159713

Epoch: 6| Step: 2
Training loss: 1.6092064380645752
Validation loss: 2.1240071583819646

Epoch: 6| Step: 3
Training loss: 2.2333877086639404
Validation loss: 2.127909021992837

Epoch: 6| Step: 4
Training loss: 2.172611713409424
Validation loss: 2.1176201656300533

Epoch: 6| Step: 5
Training loss: 1.8665037155151367
Validation loss: 2.117953318421559

Epoch: 6| Step: 6
Training loss: 2.1085381507873535
Validation loss: 2.116844050345882

Epoch: 6| Step: 7
Training loss: 2.204906463623047
Validation loss: 2.1134377474425943

Epoch: 6| Step: 8
Training loss: 2.6698427200317383
Validation loss: 2.1059214966271513

Epoch: 6| Step: 9
Training loss: 2.0436034202575684
Validation loss: 2.090654114241241

Epoch: 6| Step: 10
Training loss: 2.6314597129821777
Validation loss: 2.1008671163230814

Epoch: 6| Step: 11
Training loss: 1.8574250936508179
Validation loss: 2.1072338729776363

Epoch: 6| Step: 12
Training loss: 1.9968054294586182
Validation loss: 2.09750299556281

Epoch: 6| Step: 13
Training loss: 1.4170337915420532
Validation loss: 2.099482015896869

Epoch: 214| Step: 0
Training loss: 2.502817392349243
Validation loss: 2.0840002849537838

Epoch: 6| Step: 1
Training loss: 2.2917640209198
Validation loss: 2.0848470016192366

Epoch: 6| Step: 2
Training loss: 1.8417428731918335
Validation loss: 2.083988845989268

Epoch: 6| Step: 3
Training loss: 2.2129788398742676
Validation loss: 2.0800736911835207

Epoch: 6| Step: 4
Training loss: 1.7569594383239746
Validation loss: 2.089307233851443

Epoch: 6| Step: 5
Training loss: 2.1425580978393555
Validation loss: 2.104582501995948

Epoch: 6| Step: 6
Training loss: 2.57243013381958
Validation loss: 2.119116193504744

Epoch: 6| Step: 7
Training loss: 1.5905178785324097
Validation loss: 2.124087825898201

Epoch: 6| Step: 8
Training loss: 2.173750638961792
Validation loss: 2.1233410527629237

Epoch: 6| Step: 9
Training loss: 1.1689146757125854
Validation loss: 2.1347243837130967

Epoch: 6| Step: 10
Training loss: 2.4397926330566406
Validation loss: 2.1231295139558855

Epoch: 6| Step: 11
Training loss: 2.551480770111084
Validation loss: 2.108173849762127

Epoch: 6| Step: 12
Training loss: 2.580505609512329
Validation loss: 2.0969669165149813

Epoch: 6| Step: 13
Training loss: 2.3023998737335205
Validation loss: 2.0783145658431517

Epoch: 215| Step: 0
Training loss: 1.6094582080841064
Validation loss: 2.072071503567439

Epoch: 6| Step: 1
Training loss: 2.5873734951019287
Validation loss: 2.0655004311633367

Epoch: 6| Step: 2
Training loss: 3.022355556488037
Validation loss: 2.0537454030847035

Epoch: 6| Step: 3
Training loss: 2.629145860671997
Validation loss: 2.055825215513988

Epoch: 6| Step: 4
Training loss: 2.0683372020721436
Validation loss: 2.0545125033265803

Epoch: 6| Step: 5
Training loss: 1.928870677947998
Validation loss: 2.06077786543036

Epoch: 6| Step: 6
Training loss: 2.4075770378112793
Validation loss: 2.0605103200481785

Epoch: 6| Step: 7
Training loss: 1.8514918088912964
Validation loss: 2.088190842700261

Epoch: 6| Step: 8
Training loss: 1.3166205883026123
Validation loss: 2.1051501484327417

Epoch: 6| Step: 9
Training loss: 2.0749783515930176
Validation loss: 2.13188684627574

Epoch: 6| Step: 10
Training loss: 2.4451732635498047
Validation loss: 2.142238293924639

Epoch: 6| Step: 11
Training loss: 2.2494640350341797
Validation loss: 2.149362861469228

Epoch: 6| Step: 12
Training loss: 2.5801796913146973
Validation loss: 2.139240913493659

Epoch: 6| Step: 13
Training loss: 1.0121040344238281
Validation loss: 2.1354466099892893

Epoch: 216| Step: 0
Training loss: 1.6095941066741943
Validation loss: 2.107538648830947

Epoch: 6| Step: 1
Training loss: 2.2324252128601074
Validation loss: 2.1035380312191543

Epoch: 6| Step: 2
Training loss: 1.7512075901031494
Validation loss: 2.1039361364098004

Epoch: 6| Step: 3
Training loss: 3.076179027557373
Validation loss: 2.10119435351382

Epoch: 6| Step: 4
Training loss: 1.902134656906128
Validation loss: 2.087755705720635

Epoch: 6| Step: 5
Training loss: 1.983288049697876
Validation loss: 2.0999581377993346

Epoch: 6| Step: 6
Training loss: 1.7741378545761108
Validation loss: 2.105097419472151

Epoch: 6| Step: 7
Training loss: 1.6994470357894897
Validation loss: 2.1132986135380243

Epoch: 6| Step: 8
Training loss: 2.6207399368286133
Validation loss: 2.1250010998018327

Epoch: 6| Step: 9
Training loss: 3.403189182281494
Validation loss: 2.1198084636401107

Epoch: 6| Step: 10
Training loss: 1.7699015140533447
Validation loss: 2.1423543627544115

Epoch: 6| Step: 11
Training loss: 2.4254276752471924
Validation loss: 2.1282765852507723

Epoch: 6| Step: 12
Training loss: 1.78390371799469
Validation loss: 2.1197189695091656

Epoch: 6| Step: 13
Training loss: 1.8223190307617188
Validation loss: 2.104095084692842

Epoch: 217| Step: 0
Training loss: 1.9302234649658203
Validation loss: 2.0920407477245537

Epoch: 6| Step: 1
Training loss: 1.2683887481689453
Validation loss: 2.0972109956126057

Epoch: 6| Step: 2
Training loss: 1.6732310056686401
Validation loss: 2.091910257134386

Epoch: 6| Step: 3
Training loss: 1.8955612182617188
Validation loss: 2.0837274392445884

Epoch: 6| Step: 4
Training loss: 2.4518070220947266
Validation loss: 2.1078035062359226

Epoch: 6| Step: 5
Training loss: 1.5407578945159912
Validation loss: 2.100863951508717

Epoch: 6| Step: 6
Training loss: 1.9548890590667725
Validation loss: 2.1118598958497405

Epoch: 6| Step: 7
Training loss: 1.9497078657150269
Validation loss: 2.111604106041693

Epoch: 6| Step: 8
Training loss: 2.511329174041748
Validation loss: 2.1171300770134054

Epoch: 6| Step: 9
Training loss: 3.1014106273651123
Validation loss: 2.1154703171022478

Epoch: 6| Step: 10
Training loss: 2.7766001224517822
Validation loss: 2.130099105578597

Epoch: 6| Step: 11
Training loss: 2.9133012294769287
Validation loss: 2.107532292283991

Epoch: 6| Step: 12
Training loss: 1.672396183013916
Validation loss: 2.105416497876567

Epoch: 6| Step: 13
Training loss: 2.483464002609253
Validation loss: 2.0998370185975106

Epoch: 218| Step: 0
Training loss: 1.9724242687225342
Validation loss: 2.0934787322116155

Epoch: 6| Step: 1
Training loss: 1.9580087661743164
Validation loss: 2.0974760516997306

Epoch: 6| Step: 2
Training loss: 2.8960065841674805
Validation loss: 2.078034621413036

Epoch: 6| Step: 3
Training loss: 2.1110341548919678
Validation loss: 2.0697321635420605

Epoch: 6| Step: 4
Training loss: 3.006114959716797
Validation loss: 2.0765547419107087

Epoch: 6| Step: 5
Training loss: 2.7195687294006348
Validation loss: 2.0705604630131877

Epoch: 6| Step: 6
Training loss: 2.1206893920898438
Validation loss: 2.0698722613755094

Epoch: 6| Step: 7
Training loss: 2.0925965309143066
Validation loss: 2.0747334931486394

Epoch: 6| Step: 8
Training loss: 1.4493358135223389
Validation loss: 2.0680419975711453

Epoch: 6| Step: 9
Training loss: 3.1418068408966064
Validation loss: 2.0778848996726413

Epoch: 6| Step: 10
Training loss: 1.8256042003631592
Validation loss: 2.0746131481662875

Epoch: 6| Step: 11
Training loss: 0.8063924908638
Validation loss: 2.0897055723333873

Epoch: 6| Step: 12
Training loss: 1.8911339044570923
Validation loss: 2.1076033525569464

Epoch: 6| Step: 13
Training loss: 1.5301011800765991
Validation loss: 2.100316147650442

Epoch: 219| Step: 0
Training loss: 2.265927314758301
Validation loss: 2.11327834539516

Epoch: 6| Step: 1
Training loss: 2.3387770652770996
Validation loss: 2.07350524779289

Epoch: 6| Step: 2
Training loss: 2.3880529403686523
Validation loss: 2.0575356688550723

Epoch: 6| Step: 3
Training loss: 1.8480050563812256
Validation loss: 2.0712787874283327

Epoch: 6| Step: 4
Training loss: 2.137812852859497
Validation loss: 2.060426080098716

Epoch: 6| Step: 5
Training loss: 1.882838249206543
Validation loss: 2.0772735431630123

Epoch: 6| Step: 6
Training loss: 2.2612404823303223
Validation loss: 2.09274911239583

Epoch: 6| Step: 7
Training loss: 1.4715924263000488
Validation loss: 2.0911319294283466

Epoch: 6| Step: 8
Training loss: 1.8532624244689941
Validation loss: 2.116731564203898

Epoch: 6| Step: 9
Training loss: 2.1761322021484375
Validation loss: 2.144125328269056

Epoch: 6| Step: 10
Training loss: 2.4202287197113037
Validation loss: 2.157225453725425

Epoch: 6| Step: 11
Training loss: 2.1812803745269775
Validation loss: 2.1884536743164062

Epoch: 6| Step: 12
Training loss: 2.2419304847717285
Validation loss: 2.1844268588609594

Epoch: 6| Step: 13
Training loss: 2.1860692501068115
Validation loss: 2.1711294215212584

Epoch: 220| Step: 0
Training loss: 3.506129264831543
Validation loss: 2.1708357539228214

Epoch: 6| Step: 1
Training loss: 2.233858585357666
Validation loss: 2.149784098389328

Epoch: 6| Step: 2
Training loss: 2.6465799808502197
Validation loss: 2.131835999027375

Epoch: 6| Step: 3
Training loss: 0.9479715824127197
Validation loss: 2.133859085780318

Epoch: 6| Step: 4
Training loss: 1.919187307357788
Validation loss: 2.113330579573108

Epoch: 6| Step: 5
Training loss: 2.0309736728668213
Validation loss: 2.0983039871338875

Epoch: 6| Step: 6
Training loss: 1.9027385711669922
Validation loss: 2.077152749543549

Epoch: 6| Step: 7
Training loss: 1.9882361888885498
Validation loss: 2.093797811897852

Epoch: 6| Step: 8
Training loss: 2.300079822540283
Validation loss: 2.1009494181602233

Epoch: 6| Step: 9
Training loss: 2.172027111053467
Validation loss: 2.112677034511361

Epoch: 6| Step: 10
Training loss: 1.6950857639312744
Validation loss: 2.1200229301247546

Epoch: 6| Step: 11
Training loss: 1.8324294090270996
Validation loss: 2.112364844609332

Epoch: 6| Step: 12
Training loss: 2.178354501724243
Validation loss: 2.106549983383507

Epoch: 6| Step: 13
Training loss: 2.9571335315704346
Validation loss: 2.0913333533912577

Epoch: 221| Step: 0
Training loss: 1.9129056930541992
Validation loss: 2.076119572885575

Epoch: 6| Step: 1
Training loss: 2.3397395610809326
Validation loss: 2.068621200899924

Epoch: 6| Step: 2
Training loss: 2.5366063117980957
Validation loss: 2.057199352531023

Epoch: 6| Step: 3
Training loss: 2.248129367828369
Validation loss: 2.04608351953568

Epoch: 6| Step: 4
Training loss: 1.5955231189727783
Validation loss: 2.045813604067731

Epoch: 6| Step: 5
Training loss: 1.972548484802246
Validation loss: 2.0556307018444104

Epoch: 6| Step: 6
Training loss: 2.180205821990967
Validation loss: 2.056086722240653

Epoch: 6| Step: 7
Training loss: 2.2444262504577637
Validation loss: 2.0615695202222435

Epoch: 6| Step: 8
Training loss: 2.1295228004455566
Validation loss: 2.073209257536037

Epoch: 6| Step: 9
Training loss: 2.246710777282715
Validation loss: 2.0903732481823174

Epoch: 6| Step: 10
Training loss: 1.840653419494629
Validation loss: 2.118165618629866

Epoch: 6| Step: 11
Training loss: 2.6388943195343018
Validation loss: 2.150963124408517

Epoch: 6| Step: 12
Training loss: 1.802757978439331
Validation loss: 2.1833459561870945

Epoch: 6| Step: 13
Training loss: 1.9107003211975098
Validation loss: 2.1613563952907437

Epoch: 222| Step: 0
Training loss: 1.7258350849151611
Validation loss: 2.1427003542582193

Epoch: 6| Step: 1
Training loss: 2.5862393379211426
Validation loss: 2.131903274084932

Epoch: 6| Step: 2
Training loss: 2.3206748962402344
Validation loss: 2.1249652113965762

Epoch: 6| Step: 3
Training loss: 1.9762380123138428
Validation loss: 2.118018093929496

Epoch: 6| Step: 4
Training loss: 2.1664600372314453
Validation loss: 2.099669083472221

Epoch: 6| Step: 5
Training loss: 2.4621527194976807
Validation loss: 2.082564802579982

Epoch: 6| Step: 6
Training loss: 2.6160011291503906
Validation loss: 2.086790023311492

Epoch: 6| Step: 7
Training loss: 2.3327574729919434
Validation loss: 2.0742486035952004

Epoch: 6| Step: 8
Training loss: 2.3233044147491455
Validation loss: 2.069298105855142

Epoch: 6| Step: 9
Training loss: 1.7154724597930908
Validation loss: 2.0729181869055635

Epoch: 6| Step: 10
Training loss: 1.6729331016540527
Validation loss: 2.0736661752065024

Epoch: 6| Step: 11
Training loss: 2.1723594665527344
Validation loss: 2.0827120337434994

Epoch: 6| Step: 12
Training loss: 1.7576992511749268
Validation loss: 2.0811799264723256

Epoch: 6| Step: 13
Training loss: 1.8669427633285522
Validation loss: 2.0778765319496073

Epoch: 223| Step: 0
Training loss: 2.3579838275909424
Validation loss: 2.0882165137157647

Epoch: 6| Step: 1
Training loss: 2.794389486312866
Validation loss: 2.101800787833429

Epoch: 6| Step: 2
Training loss: 2.452476978302002
Validation loss: 2.112128047532933

Epoch: 6| Step: 3
Training loss: 2.1648154258728027
Validation loss: 2.1216546002254693

Epoch: 6| Step: 4
Training loss: 2.3581910133361816
Validation loss: 2.113377217323549

Epoch: 6| Step: 5
Training loss: 2.451589584350586
Validation loss: 2.1319100151779833

Epoch: 6| Step: 6
Training loss: 1.8242443799972534
Validation loss: 2.114683852400831

Epoch: 6| Step: 7
Training loss: 1.5220460891723633
Validation loss: 2.1002968806092457

Epoch: 6| Step: 8
Training loss: 2.3747928142547607
Validation loss: 2.085111859024212

Epoch: 6| Step: 9
Training loss: 1.3771464824676514
Validation loss: 2.070911915071549

Epoch: 6| Step: 10
Training loss: 1.8110136985778809
Validation loss: 2.0535832822963758

Epoch: 6| Step: 11
Training loss: 1.8875432014465332
Validation loss: 2.053009566440377

Epoch: 6| Step: 12
Training loss: 2.016557455062866
Validation loss: 2.043420931344391

Epoch: 6| Step: 13
Training loss: 2.4492716789245605
Validation loss: 2.0442523623025544

Epoch: 224| Step: 0
Training loss: 1.9744725227355957
Validation loss: 2.041775122765572

Epoch: 6| Step: 1
Training loss: 2.4372429847717285
Validation loss: 2.042950091823455

Epoch: 6| Step: 2
Training loss: 2.2564704418182373
Validation loss: 2.0481428471944665

Epoch: 6| Step: 3
Training loss: 2.14562726020813
Validation loss: 2.0527252612575406

Epoch: 6| Step: 4
Training loss: 1.931706428527832
Validation loss: 2.042614757373769

Epoch: 6| Step: 5
Training loss: 2.5024406909942627
Validation loss: 2.041106936752155

Epoch: 6| Step: 6
Training loss: 1.3754982948303223
Validation loss: 2.044618788585868

Epoch: 6| Step: 7
Training loss: 2.3966057300567627
Validation loss: 2.0420640309651694

Epoch: 6| Step: 8
Training loss: 2.559605121612549
Validation loss: 2.0542651478962233

Epoch: 6| Step: 9
Training loss: 2.271876335144043
Validation loss: 2.064708950699017

Epoch: 6| Step: 10
Training loss: 1.262209177017212
Validation loss: 2.0773076729107927

Epoch: 6| Step: 11
Training loss: 2.0895135402679443
Validation loss: 2.094333441026749

Epoch: 6| Step: 12
Training loss: 1.4340951442718506
Validation loss: 2.1105618758868148

Epoch: 6| Step: 13
Training loss: 3.0207481384277344
Validation loss: 2.105428623896773

Epoch: 225| Step: 0
Training loss: 2.133026123046875
Validation loss: 2.1061330764524397

Epoch: 6| Step: 1
Training loss: 2.5349478721618652
Validation loss: 2.1163593158927014

Epoch: 6| Step: 2
Training loss: 2.934938907623291
Validation loss: 2.1110841561389226

Epoch: 6| Step: 3
Training loss: 1.6700397729873657
Validation loss: 2.098465799003519

Epoch: 6| Step: 4
Training loss: 2.8312225341796875
Validation loss: 2.0975284320051952

Epoch: 6| Step: 5
Training loss: 2.144705057144165
Validation loss: 2.096250896812767

Epoch: 6| Step: 6
Training loss: 2.1895828247070312
Validation loss: 2.084240803154566

Epoch: 6| Step: 7
Training loss: 2.4558613300323486
Validation loss: 2.0755170942634664

Epoch: 6| Step: 8
Training loss: 1.3857388496398926
Validation loss: 2.0735968953819683

Epoch: 6| Step: 9
Training loss: 1.722417950630188
Validation loss: 2.0628740723415087

Epoch: 6| Step: 10
Training loss: 2.368246555328369
Validation loss: 2.0706537590231946

Epoch: 6| Step: 11
Training loss: 1.5017602443695068
Validation loss: 2.062929489279306

Epoch: 6| Step: 12
Training loss: 1.5915664434432983
Validation loss: 2.0648024825639624

Epoch: 6| Step: 13
Training loss: 1.7143582105636597
Validation loss: 2.0661000974716677

Epoch: 226| Step: 0
Training loss: 1.9346981048583984
Validation loss: 2.0798900229956514

Epoch: 6| Step: 1
Training loss: 2.6272199153900146
Validation loss: 2.1040411174938245

Epoch: 6| Step: 2
Training loss: 1.7233641147613525
Validation loss: 2.114652438830304

Epoch: 6| Step: 3
Training loss: 1.9051802158355713
Validation loss: 2.110151316529961

Epoch: 6| Step: 4
Training loss: 2.6501500606536865
Validation loss: 2.1286746122503795

Epoch: 6| Step: 5
Training loss: 2.0358927249908447
Validation loss: 2.126589459757651

Epoch: 6| Step: 6
Training loss: 1.4939868450164795
Validation loss: 2.1031586841870378

Epoch: 6| Step: 7
Training loss: 2.5624032020568848
Validation loss: 2.086533546447754

Epoch: 6| Step: 8
Training loss: 1.8214962482452393
Validation loss: 2.087589366461641

Epoch: 6| Step: 9
Training loss: 1.430534839630127
Validation loss: 2.0712199493121077

Epoch: 6| Step: 10
Training loss: 2.336411476135254
Validation loss: 2.0713285220566617

Epoch: 6| Step: 11
Training loss: 2.8447682857513428
Validation loss: 2.048813742976035

Epoch: 6| Step: 12
Training loss: 1.788020372390747
Validation loss: 2.033430549406236

Epoch: 6| Step: 13
Training loss: 2.237767219543457
Validation loss: 2.0339443837442706

Epoch: 227| Step: 0
Training loss: 2.488767385482788
Validation loss: 2.038250811638371

Epoch: 6| Step: 1
Training loss: 1.9150891304016113
Validation loss: 2.050249175358844

Epoch: 6| Step: 2
Training loss: 2.2020599842071533
Validation loss: 2.0503219148164153

Epoch: 6| Step: 3
Training loss: 1.6338998079299927
Validation loss: 2.0704358957147084

Epoch: 6| Step: 4
Training loss: 2.340451240539551
Validation loss: 2.088360778747066

Epoch: 6| Step: 5
Training loss: 2.2724807262420654
Validation loss: 2.148520378656285

Epoch: 6| Step: 6
Training loss: 2.0185916423797607
Validation loss: 2.137331166575032

Epoch: 6| Step: 7
Training loss: 2.210941791534424
Validation loss: 2.1582222036136094

Epoch: 6| Step: 8
Training loss: 1.7277610301971436
Validation loss: 2.135954649217667

Epoch: 6| Step: 9
Training loss: 2.5312368869781494
Validation loss: 2.1219206830506683

Epoch: 6| Step: 10
Training loss: 1.7542672157287598
Validation loss: 2.0932184239869476

Epoch: 6| Step: 11
Training loss: 1.5860226154327393
Validation loss: 2.0841285503038796

Epoch: 6| Step: 12
Training loss: 2.0426082611083984
Validation loss: 2.0658970545696955

Epoch: 6| Step: 13
Training loss: 2.8350515365600586
Validation loss: 2.061637032416559

Epoch: 228| Step: 0
Training loss: 1.7629449367523193
Validation loss: 2.0618676088189565

Epoch: 6| Step: 1
Training loss: 2.1027958393096924
Validation loss: 2.0644843142519713

Epoch: 6| Step: 2
Training loss: 1.7959463596343994
Validation loss: 2.0747385025024414

Epoch: 6| Step: 3
Training loss: 2.926069736480713
Validation loss: 2.0528544790001324

Epoch: 6| Step: 4
Training loss: 1.7079665660858154
Validation loss: 2.04302292741755

Epoch: 6| Step: 5
Training loss: 2.5416243076324463
Validation loss: 2.062430981666811

Epoch: 6| Step: 6
Training loss: 1.8506135940551758
Validation loss: 2.069868198005102

Epoch: 6| Step: 7
Training loss: 1.4898021221160889
Validation loss: 2.0866590802387526

Epoch: 6| Step: 8
Training loss: 2.2463278770446777
Validation loss: 2.103943306912658

Epoch: 6| Step: 9
Training loss: 2.372361421585083
Validation loss: 2.113358142555401

Epoch: 6| Step: 10
Training loss: 1.688023567199707
Validation loss: 2.0959090007248746

Epoch: 6| Step: 11
Training loss: 2.4761338233947754
Validation loss: 2.1050732751046457

Epoch: 6| Step: 12
Training loss: 2.0929036140441895
Validation loss: 2.1045001783678607

Epoch: 6| Step: 13
Training loss: 2.171128988265991
Validation loss: 2.0833922073405278

Epoch: 229| Step: 0
Training loss: 2.396375894546509
Validation loss: 2.0696848233540854

Epoch: 6| Step: 1
Training loss: 2.074111223220825
Validation loss: 2.0717371381739134

Epoch: 6| Step: 2
Training loss: 1.7581877708435059
Validation loss: 2.065098113911126

Epoch: 6| Step: 3
Training loss: 1.5361003875732422
Validation loss: 2.0665271282196045

Epoch: 6| Step: 4
Training loss: 1.8649485111236572
Validation loss: 2.069731822577856

Epoch: 6| Step: 5
Training loss: 1.8578507900238037
Validation loss: 2.066820567654025

Epoch: 6| Step: 6
Training loss: 2.0845370292663574
Validation loss: 2.0827893339177614

Epoch: 6| Step: 7
Training loss: 2.394056797027588
Validation loss: 2.06901268933409

Epoch: 6| Step: 8
Training loss: 2.212082862854004
Validation loss: 2.0841765916475685

Epoch: 6| Step: 9
Training loss: 2.064920425415039
Validation loss: 2.080034993028128

Epoch: 6| Step: 10
Training loss: 2.655651092529297
Validation loss: 2.088891383140318

Epoch: 6| Step: 11
Training loss: 2.348968267440796
Validation loss: 2.0930542971498225

Epoch: 6| Step: 12
Training loss: 1.8424654006958008
Validation loss: 2.1024002541777906

Epoch: 6| Step: 13
Training loss: 1.9130706787109375
Validation loss: 2.0984168642310688

Epoch: 230| Step: 0
Training loss: 2.1732614040374756
Validation loss: 2.088517391553489

Epoch: 6| Step: 1
Training loss: 1.8747929334640503
Validation loss: 2.0919243815124675

Epoch: 6| Step: 2
Training loss: 1.7664151191711426
Validation loss: 2.094859424457755

Epoch: 6| Step: 3
Training loss: 2.1098475456237793
Validation loss: 2.0967934362349974

Epoch: 6| Step: 4
Training loss: 2.4331064224243164
Validation loss: 2.1230892801797516

Epoch: 6| Step: 5
Training loss: 1.7940396070480347
Validation loss: 2.1230156626752628

Epoch: 6| Step: 6
Training loss: 1.702897071838379
Validation loss: 2.1251605608130015

Epoch: 6| Step: 7
Training loss: 2.460081100463867
Validation loss: 2.1101830646555912

Epoch: 6| Step: 8
Training loss: 2.023414134979248
Validation loss: 2.1013929177356023

Epoch: 6| Step: 9
Training loss: 1.5849990844726562
Validation loss: 2.0835441415027907

Epoch: 6| Step: 10
Training loss: 2.515451669692993
Validation loss: 2.0768238472682174

Epoch: 6| Step: 11
Training loss: 1.899402141571045
Validation loss: 2.0531212424719207

Epoch: 6| Step: 12
Training loss: 2.6457581520080566
Validation loss: 2.0365064605589835

Epoch: 6| Step: 13
Training loss: 1.8056528568267822
Validation loss: 2.03662440084642

Epoch: 231| Step: 0
Training loss: 1.3822407722473145
Validation loss: 2.0330587356321272

Epoch: 6| Step: 1
Training loss: 2.5021677017211914
Validation loss: 2.025942430701307

Epoch: 6| Step: 2
Training loss: 2.0448508262634277
Validation loss: 2.020595706919188

Epoch: 6| Step: 3
Training loss: 2.1766955852508545
Validation loss: 2.011205925736376

Epoch: 6| Step: 4
Training loss: 1.7339903116226196
Validation loss: 2.0211356570643764

Epoch: 6| Step: 5
Training loss: 1.8789998292922974
Validation loss: 2.0011974073225454

Epoch: 6| Step: 6
Training loss: 1.8373379707336426
Validation loss: 2.0084358120477326

Epoch: 6| Step: 7
Training loss: 2.343453884124756
Validation loss: 2.017139820642369

Epoch: 6| Step: 8
Training loss: 1.3525021076202393
Validation loss: 2.0071009923053045

Epoch: 6| Step: 9
Training loss: 2.448941469192505
Validation loss: 2.0338305016999603

Epoch: 6| Step: 10
Training loss: 2.0334043502807617
Validation loss: 2.057572357116207

Epoch: 6| Step: 11
Training loss: 2.0116031169891357
Validation loss: 2.0792099275896625

Epoch: 6| Step: 12
Training loss: 3.4327926635742188
Validation loss: 2.109289656403244

Epoch: 6| Step: 13
Training loss: 1.6634864807128906
Validation loss: 2.1381640818811234

Epoch: 232| Step: 0
Training loss: 2.7971949577331543
Validation loss: 2.1541327532901557

Epoch: 6| Step: 1
Training loss: 1.7724052667617798
Validation loss: 2.1176299766827653

Epoch: 6| Step: 2
Training loss: 1.9661319255828857
Validation loss: 2.0868663621205155

Epoch: 6| Step: 3
Training loss: 1.7133805751800537
Validation loss: 2.058341674907233

Epoch: 6| Step: 4
Training loss: 2.521995782852173
Validation loss: 2.036373387100876

Epoch: 6| Step: 5
Training loss: 1.7038593292236328
Validation loss: 2.0456683533166045

Epoch: 6| Step: 6
Training loss: 2.256286144256592
Validation loss: 2.0440842156769126

Epoch: 6| Step: 7
Training loss: 2.0710062980651855
Validation loss: 2.055851503085065

Epoch: 6| Step: 8
Training loss: 1.851967692375183
Validation loss: 2.059618696089714

Epoch: 6| Step: 9
Training loss: 2.3529844284057617
Validation loss: 2.078153902484525

Epoch: 6| Step: 10
Training loss: 1.6934642791748047
Validation loss: 2.0824775747073594

Epoch: 6| Step: 11
Training loss: 2.3324759006500244
Validation loss: 2.0914711798391035

Epoch: 6| Step: 12
Training loss: 2.0879056453704834
Validation loss: 2.1066493026671873

Epoch: 6| Step: 13
Training loss: 2.127913236618042
Validation loss: 2.1384866904186945

Epoch: 233| Step: 0
Training loss: 1.6350834369659424
Validation loss: 2.1868883755899247

Epoch: 6| Step: 1
Training loss: 2.0560550689697266
Validation loss: 2.221799491554178

Epoch: 6| Step: 2
Training loss: 2.485295295715332
Validation loss: 2.2501435766937914

Epoch: 6| Step: 3
Training loss: 2.7295970916748047
Validation loss: 2.2533853246319677

Epoch: 6| Step: 4
Training loss: 1.8048564195632935
Validation loss: 2.183429710326656

Epoch: 6| Step: 5
Training loss: 2.2455615997314453
Validation loss: 2.1436750299187115

Epoch: 6| Step: 6
Training loss: 2.1994168758392334
Validation loss: 2.0962156941813808

Epoch: 6| Step: 7
Training loss: 1.5398633480072021
Validation loss: 2.0580547625018704

Epoch: 6| Step: 8
Training loss: 1.3500425815582275
Validation loss: 2.038618331314415

Epoch: 6| Step: 9
Training loss: 2.9841010570526123
Validation loss: 2.0267759420538463

Epoch: 6| Step: 10
Training loss: 1.9346331357955933
Validation loss: 2.0264540615902153

Epoch: 6| Step: 11
Training loss: 2.5689749717712402
Validation loss: 2.0299764704960648

Epoch: 6| Step: 12
Training loss: 2.1395747661590576
Validation loss: 2.0370487987354235

Epoch: 6| Step: 13
Training loss: 1.6208523511886597
Validation loss: 2.052765166887673

Epoch: 234| Step: 0
Training loss: 2.6886324882507324
Validation loss: 2.047953892779607

Epoch: 6| Step: 1
Training loss: 3.083754062652588
Validation loss: 2.0535936611954884

Epoch: 6| Step: 2
Training loss: 2.2777137756347656
Validation loss: 2.062845532612134

Epoch: 6| Step: 3
Training loss: 2.3690009117126465
Validation loss: 2.0620885126052366

Epoch: 6| Step: 4
Training loss: 2.0636887550354004
Validation loss: 2.060643821634272

Epoch: 6| Step: 5
Training loss: 1.3406420946121216
Validation loss: 2.085458183801302

Epoch: 6| Step: 6
Training loss: 1.8769562244415283
Validation loss: 2.0962050345636185

Epoch: 6| Step: 7
Training loss: 1.6690895557403564
Validation loss: 2.119417812234612

Epoch: 6| Step: 8
Training loss: 1.8156641721725464
Validation loss: 2.129509896360418

Epoch: 6| Step: 9
Training loss: 2.0047762393951416
Validation loss: 2.1700952924707884

Epoch: 6| Step: 10
Training loss: 1.8160516023635864
Validation loss: 2.170469163566507

Epoch: 6| Step: 11
Training loss: 2.4294252395629883
Validation loss: 2.1690456175035044

Epoch: 6| Step: 12
Training loss: 1.7944648265838623
Validation loss: 2.1350389014008226

Epoch: 6| Step: 13
Training loss: 1.741272211074829
Validation loss: 2.115099266011228

Epoch: 235| Step: 0
Training loss: 1.3650766611099243
Validation loss: 2.114895746272097

Epoch: 6| Step: 1
Training loss: 2.119173526763916
Validation loss: 2.0949683932847876

Epoch: 6| Step: 2
Training loss: 1.7937893867492676
Validation loss: 2.0890361878179733

Epoch: 6| Step: 3
Training loss: 1.7149525880813599
Validation loss: 2.0806214604326474

Epoch: 6| Step: 4
Training loss: 2.3978590965270996
Validation loss: 2.08280788570322

Epoch: 6| Step: 5
Training loss: 1.724579930305481
Validation loss: 2.078889698110601

Epoch: 6| Step: 6
Training loss: 2.3543801307678223
Validation loss: 2.069186543905607

Epoch: 6| Step: 7
Training loss: 2.460644483566284
Validation loss: 2.053435471750075

Epoch: 6| Step: 8
Training loss: 2.3927087783813477
Validation loss: 2.0331985642833095

Epoch: 6| Step: 9
Training loss: 1.8799970149993896
Validation loss: 2.03385474476763

Epoch: 6| Step: 10
Training loss: 1.770404577255249
Validation loss: 2.0326177727791572

Epoch: 6| Step: 11
Training loss: 2.696610450744629
Validation loss: 2.022346205608819

Epoch: 6| Step: 12
Training loss: 1.9208879470825195
Validation loss: 2.026519395971811

Epoch: 6| Step: 13
Training loss: 2.065807342529297
Validation loss: 2.0274340388595418

Epoch: 236| Step: 0
Training loss: 1.956520915031433
Validation loss: 2.032605996695898

Epoch: 6| Step: 1
Training loss: 2.322033405303955
Validation loss: 2.0302523336102887

Epoch: 6| Step: 2
Training loss: 2.4703829288482666
Validation loss: 2.0541449464777464

Epoch: 6| Step: 3
Training loss: 2.317424774169922
Validation loss: 2.0756704012552896

Epoch: 6| Step: 4
Training loss: 1.4432603120803833
Validation loss: 2.098333752283486

Epoch: 6| Step: 5
Training loss: 1.7131801843643188
Validation loss: 2.1219728813376477

Epoch: 6| Step: 6
Training loss: 2.4109044075012207
Validation loss: 2.128845808326557

Epoch: 6| Step: 7
Training loss: 1.5153709650039673
Validation loss: 2.1212882329058904

Epoch: 6| Step: 8
Training loss: 2.5334370136260986
Validation loss: 2.1065580293696415

Epoch: 6| Step: 9
Training loss: 1.7976393699645996
Validation loss: 2.0899410452893985

Epoch: 6| Step: 10
Training loss: 1.6918721199035645
Validation loss: 2.0806184353366977

Epoch: 6| Step: 11
Training loss: 2.2477989196777344
Validation loss: 2.0633572788648706

Epoch: 6| Step: 12
Training loss: 2.08646821975708
Validation loss: 2.0575033977467525

Epoch: 6| Step: 13
Training loss: 2.6455252170562744
Validation loss: 2.0501267730548816

Epoch: 237| Step: 0
Training loss: 1.786913514137268
Validation loss: 2.046346487537507

Epoch: 6| Step: 1
Training loss: 1.8497130870819092
Validation loss: 2.040600371617143

Epoch: 6| Step: 2
Training loss: 1.6675829887390137
Validation loss: 2.0405313148293445

Epoch: 6| Step: 3
Training loss: 2.182389736175537
Validation loss: 2.05861940691548

Epoch: 6| Step: 4
Training loss: 2.523560047149658
Validation loss: 2.0552093187967935

Epoch: 6| Step: 5
Training loss: 1.6809828281402588
Validation loss: 2.0498135602602394

Epoch: 6| Step: 6
Training loss: 2.3882603645324707
Validation loss: 2.0426887530152515

Epoch: 6| Step: 7
Training loss: 1.7505981922149658
Validation loss: 2.0378585195028656

Epoch: 6| Step: 8
Training loss: 2.9727249145507812
Validation loss: 2.039150808447151

Epoch: 6| Step: 9
Training loss: 2.0140793323516846
Validation loss: 2.0521054575520177

Epoch: 6| Step: 10
Training loss: 1.8027455806732178
Validation loss: 2.059698356095181

Epoch: 6| Step: 11
Training loss: 2.363246440887451
Validation loss: 2.0719257093244985

Epoch: 6| Step: 12
Training loss: 2.177532196044922
Validation loss: 2.0752873959079867

Epoch: 6| Step: 13
Training loss: 1.4916495084762573
Validation loss: 2.062126155822508

Epoch: 238| Step: 0
Training loss: 2.3603854179382324
Validation loss: 2.060437678008951

Epoch: 6| Step: 1
Training loss: 2.415285348892212
Validation loss: 2.0602667511150403

Epoch: 6| Step: 2
Training loss: 1.8692351579666138
Validation loss: 2.0581474227289998

Epoch: 6| Step: 3
Training loss: 2.4179346561431885
Validation loss: 2.0438898224984445

Epoch: 6| Step: 4
Training loss: 2.387317657470703
Validation loss: 2.04955538370276

Epoch: 6| Step: 5
Training loss: 2.192934989929199
Validation loss: 2.0493425451299196

Epoch: 6| Step: 6
Training loss: 1.590336561203003
Validation loss: 2.0480098070636874

Epoch: 6| Step: 7
Training loss: 2.0694074630737305
Validation loss: 2.040183454431513

Epoch: 6| Step: 8
Training loss: 3.155810832977295
Validation loss: 2.042195886693975

Epoch: 6| Step: 9
Training loss: 1.2561290264129639
Validation loss: 2.0370931356183943

Epoch: 6| Step: 10
Training loss: 1.904175877571106
Validation loss: 2.0424010445994716

Epoch: 6| Step: 11
Training loss: 1.31864333152771
Validation loss: 2.042296653152794

Epoch: 6| Step: 12
Training loss: 1.6282716989517212
Validation loss: 2.0376803157150105

Epoch: 6| Step: 13
Training loss: 1.4505558013916016
Validation loss: 2.0393332806966638

Epoch: 239| Step: 0
Training loss: 1.5342754125595093
Validation loss: 2.0444055949487994

Epoch: 6| Step: 1
Training loss: 1.4897282123565674
Validation loss: 2.0499199949285036

Epoch: 6| Step: 2
Training loss: 2.0668787956237793
Validation loss: 2.0627423909402665

Epoch: 6| Step: 3
Training loss: 2.9376509189605713
Validation loss: 2.0812383223605413

Epoch: 6| Step: 4
Training loss: 1.8829673528671265
Validation loss: 2.0827691760114444

Epoch: 6| Step: 5
Training loss: 2.3369109630584717
Validation loss: 2.0933748393930416

Epoch: 6| Step: 6
Training loss: 1.3660762310028076
Validation loss: 2.0859881447207544

Epoch: 6| Step: 7
Training loss: 1.7378349304199219
Validation loss: 2.0864069205458446

Epoch: 6| Step: 8
Training loss: 2.678579092025757
Validation loss: 2.0667478346055552

Epoch: 6| Step: 9
Training loss: 2.1781373023986816
Validation loss: 2.057923497692231

Epoch: 6| Step: 10
Training loss: 2.063201904296875
Validation loss: 2.062007998907438

Epoch: 6| Step: 11
Training loss: 1.7859288454055786
Validation loss: 2.0469818320325626

Epoch: 6| Step: 12
Training loss: 2.3499810695648193
Validation loss: 2.042971564877418

Epoch: 6| Step: 13
Training loss: 1.628221035003662
Validation loss: 2.045035075115901

Epoch: 240| Step: 0
Training loss: 1.978743076324463
Validation loss: 2.0310100483637985

Epoch: 6| Step: 1
Training loss: 2.523364305496216
Validation loss: 2.030110546337661

Epoch: 6| Step: 2
Training loss: 1.7345147132873535
Validation loss: 2.0264485318173646

Epoch: 6| Step: 3
Training loss: 1.994157314300537
Validation loss: 2.014446853309549

Epoch: 6| Step: 4
Training loss: 2.4334752559661865
Validation loss: 2.023506567042361

Epoch: 6| Step: 5
Training loss: 1.4948372840881348
Validation loss: 2.0239185799834547

Epoch: 6| Step: 6
Training loss: 1.5730139017105103
Validation loss: 2.0276299650951097

Epoch: 6| Step: 7
Training loss: 1.7197072505950928
Validation loss: 2.0304758882009857

Epoch: 6| Step: 8
Training loss: 1.5795292854309082
Validation loss: 2.0624827697712886

Epoch: 6| Step: 9
Training loss: 2.071492910385132
Validation loss: 2.10028741949348

Epoch: 6| Step: 10
Training loss: 2.385298252105713
Validation loss: 2.1165417458421443

Epoch: 6| Step: 11
Training loss: 2.1036219596862793
Validation loss: 2.1154311331369544

Epoch: 6| Step: 12
Training loss: 2.5203821659088135
Validation loss: 2.100340932928106

Epoch: 6| Step: 13
Training loss: 2.7211811542510986
Validation loss: 2.063677751889793

Epoch: 241| Step: 0
Training loss: 1.3741883039474487
Validation loss: 2.0477840028783327

Epoch: 6| Step: 1
Training loss: 1.8842132091522217
Validation loss: 2.052473912956894

Epoch: 6| Step: 2
Training loss: 1.622750163078308
Validation loss: 2.051759732666836

Epoch: 6| Step: 3
Training loss: 1.8622633218765259
Validation loss: 2.0649241298757572

Epoch: 6| Step: 4
Training loss: 2.6466128826141357
Validation loss: 2.0691993441633

Epoch: 6| Step: 5
Training loss: 1.6514551639556885
Validation loss: 2.089584469795227

Epoch: 6| Step: 6
Training loss: 2.460301399230957
Validation loss: 2.0814111540394444

Epoch: 6| Step: 7
Training loss: 2.2683470249176025
Validation loss: 2.099747024556642

Epoch: 6| Step: 8
Training loss: 2.0566606521606445
Validation loss: 2.11541429386344

Epoch: 6| Step: 9
Training loss: 1.8908705711364746
Validation loss: 2.1130090746828305

Epoch: 6| Step: 10
Training loss: 2.5917794704437256
Validation loss: 2.1219055434708953

Epoch: 6| Step: 11
Training loss: 1.7558674812316895
Validation loss: 2.0931771339908725

Epoch: 6| Step: 12
Training loss: 1.644791603088379
Validation loss: 2.0704979883727206

Epoch: 6| Step: 13
Training loss: 3.005171537399292
Validation loss: 2.0514861588836997

Epoch: 242| Step: 0
Training loss: 2.5802831649780273
Validation loss: 2.0588288999372915

Epoch: 6| Step: 1
Training loss: 1.7707157135009766
Validation loss: 2.0385393916919665

Epoch: 6| Step: 2
Training loss: 1.7923191785812378
Validation loss: 2.0413594040819394

Epoch: 6| Step: 3
Training loss: 2.197385787963867
Validation loss: 2.0387794125464653

Epoch: 6| Step: 4
Training loss: 1.4938716888427734
Validation loss: 2.034639517466227

Epoch: 6| Step: 5
Training loss: 2.1489739418029785
Validation loss: 2.0387159368043304

Epoch: 6| Step: 6
Training loss: 1.5919737815856934
Validation loss: 2.0352351934679094

Epoch: 6| Step: 7
Training loss: 2.1537063121795654
Validation loss: 2.05553178633413

Epoch: 6| Step: 8
Training loss: 1.466450572013855
Validation loss: 2.0696281130595873

Epoch: 6| Step: 9
Training loss: 1.6465755701065063
Validation loss: 2.0871767485013573

Epoch: 6| Step: 10
Training loss: 2.481658935546875
Validation loss: 2.090011659488883

Epoch: 6| Step: 11
Training loss: 2.4714059829711914
Validation loss: 2.09647286066445

Epoch: 6| Step: 12
Training loss: 2.310883045196533
Validation loss: 2.102269326486895

Epoch: 6| Step: 13
Training loss: 2.040797710418701
Validation loss: 2.100062611282513

Epoch: 243| Step: 0
Training loss: 1.6446278095245361
Validation loss: 2.102600388629462

Epoch: 6| Step: 1
Training loss: 2.1507997512817383
Validation loss: 2.072566573337842

Epoch: 6| Step: 2
Training loss: 2.153912305831909
Validation loss: 2.060710007144559

Epoch: 6| Step: 3
Training loss: 2.312974214553833
Validation loss: 2.0433410662476734

Epoch: 6| Step: 4
Training loss: 2.296142816543579
Validation loss: 2.026422764665337

Epoch: 6| Step: 5
Training loss: 1.8005311489105225
Validation loss: 2.0224405745024323

Epoch: 6| Step: 6
Training loss: 1.970779299736023
Validation loss: 2.015620275210309

Epoch: 6| Step: 7
Training loss: 2.081874132156372
Validation loss: 2.016497893999982

Epoch: 6| Step: 8
Training loss: 0.8148001432418823
Validation loss: 2.013157175433251

Epoch: 6| Step: 9
Training loss: 2.438579559326172
Validation loss: 2.014754278685457

Epoch: 6| Step: 10
Training loss: 2.0076310634613037
Validation loss: 2.020110587919912

Epoch: 6| Step: 11
Training loss: 2.035144805908203
Validation loss: 2.0273120839108705

Epoch: 6| Step: 12
Training loss: 2.083251953125
Validation loss: 2.0410556613758044

Epoch: 6| Step: 13
Training loss: 2.3915507793426514
Validation loss: 2.042095394544704

Epoch: 244| Step: 0
Training loss: 1.6575202941894531
Validation loss: 2.0502493612227903

Epoch: 6| Step: 1
Training loss: 1.6832674741744995
Validation loss: 2.05089601778215

Epoch: 6| Step: 2
Training loss: 1.8794045448303223
Validation loss: 2.0685047885423065

Epoch: 6| Step: 3
Training loss: 1.839436411857605
Validation loss: 2.0679562912192395

Epoch: 6| Step: 4
Training loss: 2.2827863693237305
Validation loss: 2.066396338965303

Epoch: 6| Step: 5
Training loss: 1.934383749961853
Validation loss: 2.062583415738998

Epoch: 6| Step: 6
Training loss: 1.9193189144134521
Validation loss: 2.06203935223241

Epoch: 6| Step: 7
Training loss: 1.7679476737976074
Validation loss: 2.0537501381289576

Epoch: 6| Step: 8
Training loss: 2.322868824005127
Validation loss: 2.0596139200272097

Epoch: 6| Step: 9
Training loss: 2.134337902069092
Validation loss: 2.036553100873065

Epoch: 6| Step: 10
Training loss: 1.7482922077178955
Validation loss: 2.044147760637345

Epoch: 6| Step: 11
Training loss: 2.751715660095215
Validation loss: 2.0275028751742457

Epoch: 6| Step: 12
Training loss: 1.8693208694458008
Validation loss: 2.0305804462843042

Epoch: 6| Step: 13
Training loss: 1.9460326433181763
Validation loss: 2.020725593771986

Epoch: 245| Step: 0
Training loss: 2.0869081020355225
Validation loss: 2.0227721583458687

Epoch: 6| Step: 1
Training loss: 2.02713680267334
Validation loss: 2.0144278375051354

Epoch: 6| Step: 2
Training loss: 2.517902135848999
Validation loss: 2.0279404758125223

Epoch: 6| Step: 3
Training loss: 1.718173861503601
Validation loss: 2.043534540360974

Epoch: 6| Step: 4
Training loss: 1.1258476972579956
Validation loss: 2.0469584093298963

Epoch: 6| Step: 5
Training loss: 2.5285115242004395
Validation loss: 2.0544364503634873

Epoch: 6| Step: 6
Training loss: 2.3767640590667725
Validation loss: 2.0727119291982343

Epoch: 6| Step: 7
Training loss: 2.7051210403442383
Validation loss: 2.058134648107713

Epoch: 6| Step: 8
Training loss: 2.2963337898254395
Validation loss: 2.0626333298221713

Epoch: 6| Step: 9
Training loss: 1.451207160949707
Validation loss: 2.0367892711393294

Epoch: 6| Step: 10
Training loss: 1.6801316738128662
Validation loss: 2.035114129384359

Epoch: 6| Step: 11
Training loss: 1.564673662185669
Validation loss: 2.0418356490391556

Epoch: 6| Step: 12
Training loss: 2.318537473678589
Validation loss: 2.0286696598094

Epoch: 6| Step: 13
Training loss: 0.7540238499641418
Validation loss: 2.0253292975887174

Epoch: 246| Step: 0
Training loss: 2.411628246307373
Validation loss: 2.043950560272381

Epoch: 6| Step: 1
Training loss: 1.2298874855041504
Validation loss: 2.0505052228127756

Epoch: 6| Step: 2
Training loss: 1.5859777927398682
Validation loss: 2.086079079617736

Epoch: 6| Step: 3
Training loss: 1.8866393566131592
Validation loss: 2.068601562130836

Epoch: 6| Step: 4
Training loss: 1.7114957571029663
Validation loss: 2.078033724138814

Epoch: 6| Step: 5
Training loss: 3.1228322982788086
Validation loss: 2.070376223133456

Epoch: 6| Step: 6
Training loss: 2.2753541469573975
Validation loss: 2.0668535591453634

Epoch: 6| Step: 7
Training loss: 2.3347678184509277
Validation loss: 2.041685365861462

Epoch: 6| Step: 8
Training loss: 2.124659776687622
Validation loss: 2.038776174668343

Epoch: 6| Step: 9
Training loss: 1.6615062952041626
Validation loss: 2.0297196539499427

Epoch: 6| Step: 10
Training loss: 1.704034447669983
Validation loss: 2.012563451643913

Epoch: 6| Step: 11
Training loss: 2.047074317932129
Validation loss: 2.0061631997426352

Epoch: 6| Step: 12
Training loss: 1.557264804840088
Validation loss: 2.0030264290430213

Epoch: 6| Step: 13
Training loss: 2.325841188430786
Validation loss: 2.0177280082497546

Epoch: 247| Step: 0
Training loss: 1.7185474634170532
Validation loss: 2.0172899666652886

Epoch: 6| Step: 1
Training loss: 2.0678369998931885
Validation loss: 2.022906570024388

Epoch: 6| Step: 2
Training loss: 1.6517174243927002
Validation loss: 2.0381023345455045

Epoch: 6| Step: 3
Training loss: 1.5466654300689697
Validation loss: 2.054649419682

Epoch: 6| Step: 4
Training loss: 1.223644495010376
Validation loss: 2.044829768519248

Epoch: 6| Step: 5
Training loss: 2.215149164199829
Validation loss: 2.046094879027336

Epoch: 6| Step: 6
Training loss: 2.08103346824646
Validation loss: 2.039438639917681

Epoch: 6| Step: 7
Training loss: 2.764204978942871
Validation loss: 2.039153814315796

Epoch: 6| Step: 8
Training loss: 2.296977996826172
Validation loss: 2.042945629806929

Epoch: 6| Step: 9
Training loss: 1.8573280572891235
Validation loss: 2.0646787715214554

Epoch: 6| Step: 10
Training loss: 2.368598222732544
Validation loss: 2.0849886530189106

Epoch: 6| Step: 11
Training loss: 2.6536448001861572
Validation loss: 2.101910444997972

Epoch: 6| Step: 12
Training loss: 1.492402195930481
Validation loss: 2.116285503551524

Epoch: 6| Step: 13
Training loss: 1.474525809288025
Validation loss: 2.1218548103045394

Epoch: 248| Step: 0
Training loss: 1.767788290977478
Validation loss: 2.1240696932679866

Epoch: 6| Step: 1
Training loss: 2.112954616546631
Validation loss: 2.0906146034117667

Epoch: 6| Step: 2
Training loss: 1.7093791961669922
Validation loss: 2.082057063297559

Epoch: 6| Step: 3
Training loss: 2.035064220428467
Validation loss: 2.0605571923717374

Epoch: 6| Step: 4
Training loss: 1.5460652112960815
Validation loss: 2.061080899289859

Epoch: 6| Step: 5
Training loss: 1.7996734380722046
Validation loss: 2.039878802914773

Epoch: 6| Step: 6
Training loss: 2.4739503860473633
Validation loss: 2.0414250589186147

Epoch: 6| Step: 7
Training loss: 1.8195055723190308
Validation loss: 2.0374776009590394

Epoch: 6| Step: 8
Training loss: 2.5973193645477295
Validation loss: 2.0257234086272535

Epoch: 6| Step: 9
Training loss: 2.082822322845459
Validation loss: 2.037751418288036

Epoch: 6| Step: 10
Training loss: 2.3159992694854736
Validation loss: 2.037922848937332

Epoch: 6| Step: 11
Training loss: 1.7882872819900513
Validation loss: 2.0291808010429464

Epoch: 6| Step: 12
Training loss: 1.8302034139633179
Validation loss: 2.026923256535684

Epoch: 6| Step: 13
Training loss: 1.365159511566162
Validation loss: 2.0345499400169618

Epoch: 249| Step: 0
Training loss: 1.869566559791565
Validation loss: 2.0490125020345054

Epoch: 6| Step: 1
Training loss: 2.3890175819396973
Validation loss: 2.0471553853763047

Epoch: 6| Step: 2
Training loss: 1.7084007263183594
Validation loss: 2.0428789264412335

Epoch: 6| Step: 3
Training loss: 2.0093495845794678
Validation loss: 2.0383189570519233

Epoch: 6| Step: 4
Training loss: 1.601454734802246
Validation loss: 2.028309791318832

Epoch: 6| Step: 5
Training loss: 2.8283753395080566
Validation loss: 2.0262870916756253

Epoch: 6| Step: 6
Training loss: 1.7424713373184204
Validation loss: 2.004443012258058

Epoch: 6| Step: 7
Training loss: 1.679078221321106
Validation loss: 2.0092384199942313

Epoch: 6| Step: 8
Training loss: 2.2023022174835205
Validation loss: 2.003571473142152

Epoch: 6| Step: 9
Training loss: 1.8738242387771606
Validation loss: 1.9983977412664762

Epoch: 6| Step: 10
Training loss: 2.5235791206359863
Validation loss: 1.999824470089328

Epoch: 6| Step: 11
Training loss: 1.3864238262176514
Validation loss: 2.005398852850801

Epoch: 6| Step: 12
Training loss: 2.1881160736083984
Validation loss: 1.9952871645650556

Epoch: 6| Step: 13
Training loss: 0.7854692339897156
Validation loss: 2.007398415637273

Epoch: 250| Step: 0
Training loss: 2.0646214485168457
Validation loss: 2.003998235989642

Epoch: 6| Step: 1
Training loss: 2.1156322956085205
Validation loss: 2.010526048239841

Epoch: 6| Step: 2
Training loss: 1.6032931804656982
Validation loss: 2.015523027348262

Epoch: 6| Step: 3
Training loss: 2.193125009536743
Validation loss: 2.0249001146644674

Epoch: 6| Step: 4
Training loss: 2.170441150665283
Validation loss: 2.0334938841481365

Epoch: 6| Step: 5
Training loss: 1.7999627590179443
Validation loss: 2.0300403589843423

Epoch: 6| Step: 6
Training loss: 2.01082706451416
Validation loss: 2.027702567397907

Epoch: 6| Step: 7
Training loss: 1.436082363128662
Validation loss: 2.0255890661670315

Epoch: 6| Step: 8
Training loss: 1.9314732551574707
Validation loss: 2.021796654629451

Epoch: 6| Step: 9
Training loss: 1.6521964073181152
Validation loss: 2.02642067914368

Epoch: 6| Step: 10
Training loss: 2.3458728790283203
Validation loss: 2.043909744549823

Epoch: 6| Step: 11
Training loss: 2.111646890640259
Validation loss: 2.06367023657727

Epoch: 6| Step: 12
Training loss: 2.03132963180542
Validation loss: 2.050838085912889

Epoch: 6| Step: 13
Training loss: 1.958859920501709
Validation loss: 2.038784573155065

Epoch: 251| Step: 0
Training loss: 1.7851486206054688
Validation loss: 2.0492509077954035

Epoch: 6| Step: 1
Training loss: 2.250410795211792
Validation loss: 2.049770103987827

Epoch: 6| Step: 2
Training loss: 1.2463908195495605
Validation loss: 2.0435087501361804

Epoch: 6| Step: 3
Training loss: 1.8846274614334106
Validation loss: 2.0443927113727858

Epoch: 6| Step: 4
Training loss: 2.046853542327881
Validation loss: 2.051178498934674

Epoch: 6| Step: 5
Training loss: 2.1068038940429688
Validation loss: 2.037799900577914

Epoch: 6| Step: 6
Training loss: 2.139279365539551
Validation loss: 2.030401160640101

Epoch: 6| Step: 7
Training loss: 1.4762845039367676
Validation loss: 2.0280356842984437

Epoch: 6| Step: 8
Training loss: 2.301328182220459
Validation loss: 2.0390874314051803

Epoch: 6| Step: 9
Training loss: 2.271757125854492
Validation loss: 2.033609087749194

Epoch: 6| Step: 10
Training loss: 2.1680963039398193
Validation loss: 2.0455595216443463

Epoch: 6| Step: 11
Training loss: 1.5777324438095093
Validation loss: 2.0570021662660825

Epoch: 6| Step: 12
Training loss: 1.5630455017089844
Validation loss: 2.058603766143963

Epoch: 6| Step: 13
Training loss: 2.3958635330200195
Validation loss: 2.056373514154906

Epoch: 252| Step: 0
Training loss: 1.6985881328582764
Validation loss: 2.0568110084020965

Epoch: 6| Step: 1
Training loss: 1.7588106393814087
Validation loss: 2.0518559217453003

Epoch: 6| Step: 2
Training loss: 2.3257193565368652
Validation loss: 2.042850281602593

Epoch: 6| Step: 3
Training loss: 1.9438154697418213
Validation loss: 2.0361148670155513

Epoch: 6| Step: 4
Training loss: 2.03208589553833
Validation loss: 2.048249194698949

Epoch: 6| Step: 5
Training loss: 2.2924184799194336
Validation loss: 2.0475812522313928

Epoch: 6| Step: 6
Training loss: 2.0272703170776367
Validation loss: 2.02761770063831

Epoch: 6| Step: 7
Training loss: 1.6683826446533203
Validation loss: 2.0240500357843216

Epoch: 6| Step: 8
Training loss: 1.5526924133300781
Validation loss: 2.0381248087011357

Epoch: 6| Step: 9
Training loss: 1.209771990776062
Validation loss: 2.022969895793546

Epoch: 6| Step: 10
Training loss: 2.406026840209961
Validation loss: 2.047151809097618

Epoch: 6| Step: 11
Training loss: 1.7858784198760986
Validation loss: 2.0439932269434773

Epoch: 6| Step: 12
Training loss: 2.237757444381714
Validation loss: 2.0472283952979633

Epoch: 6| Step: 13
Training loss: 2.268444061279297
Validation loss: 2.068426153993094

Epoch: 253| Step: 0
Training loss: 2.046567678451538
Validation loss: 2.080457563041359

Epoch: 6| Step: 1
Training loss: 2.4050559997558594
Validation loss: 2.073310785396125

Epoch: 6| Step: 2
Training loss: 1.486863613128662
Validation loss: 2.0728514463670793

Epoch: 6| Step: 3
Training loss: 2.3840508460998535
Validation loss: 2.097297183928951

Epoch: 6| Step: 4
Training loss: 1.9497852325439453
Validation loss: 2.128231812548894

Epoch: 6| Step: 5
Training loss: 1.8781790733337402
Validation loss: 2.149193251004783

Epoch: 6| Step: 6
Training loss: 1.449153184890747
Validation loss: 2.1543431307679866

Epoch: 6| Step: 7
Training loss: 2.1720938682556152
Validation loss: 2.138768639615787

Epoch: 6| Step: 8
Training loss: 2.224437713623047
Validation loss: 2.1110267434068906

Epoch: 6| Step: 9
Training loss: 2.0522141456604004
Validation loss: 2.087978014381983

Epoch: 6| Step: 10
Training loss: 2.295706272125244
Validation loss: 2.0806243009464715

Epoch: 6| Step: 11
Training loss: 1.2924749851226807
Validation loss: 2.0800136314925326

Epoch: 6| Step: 12
Training loss: 1.8699421882629395
Validation loss: 2.057318118310744

Epoch: 6| Step: 13
Training loss: 1.4481931924819946
Validation loss: 2.0350220626400364

Epoch: 254| Step: 0
Training loss: 2.0334558486938477
Validation loss: 2.0296398516624206

Epoch: 6| Step: 1
Training loss: 1.7038449048995972
Validation loss: 2.0348019420459704

Epoch: 6| Step: 2
Training loss: 1.788752794265747
Validation loss: 2.0414456526438394

Epoch: 6| Step: 3
Training loss: 2.188237190246582
Validation loss: 2.0365944703420005

Epoch: 6| Step: 4
Training loss: 2.4301764965057373
Validation loss: 2.0495446869122085

Epoch: 6| Step: 5
Training loss: 1.6903116703033447
Validation loss: 2.059331485020217

Epoch: 6| Step: 6
Training loss: 1.8188891410827637
Validation loss: 2.0787024446713027

Epoch: 6| Step: 7
Training loss: 2.172152042388916
Validation loss: 2.073068218846475

Epoch: 6| Step: 8
Training loss: 2.113656759262085
Validation loss: 2.045668271280104

Epoch: 6| Step: 9
Training loss: 2.536452293395996
Validation loss: 2.029171574500299

Epoch: 6| Step: 10
Training loss: 2.2300734519958496
Validation loss: 2.012350161870321

Epoch: 6| Step: 11
Training loss: 1.5244553089141846
Validation loss: 2.009657093273696

Epoch: 6| Step: 12
Training loss: 1.379244089126587
Validation loss: 2.0161662486291703

Epoch: 6| Step: 13
Training loss: 0.8794164657592773
Validation loss: 2.027610609608312

Epoch: 255| Step: 0
Training loss: 1.616950273513794
Validation loss: 2.0217260058208177

Epoch: 6| Step: 1
Training loss: 1.8552372455596924
Validation loss: 2.0393871697046424

Epoch: 6| Step: 2
Training loss: 1.9538660049438477
Validation loss: 2.029086387285622

Epoch: 6| Step: 3
Training loss: 1.9860410690307617
Validation loss: 2.054035714877549

Epoch: 6| Step: 4
Training loss: 2.0152502059936523
Validation loss: 2.057070606498308

Epoch: 6| Step: 5
Training loss: 2.215216636657715
Validation loss: 2.078205503443236

Epoch: 6| Step: 6
Training loss: 1.5835280418395996
Validation loss: 2.0672784338715258

Epoch: 6| Step: 7
Training loss: 1.3790751695632935
Validation loss: 2.0878698838654386

Epoch: 6| Step: 8
Training loss: 2.0544636249542236
Validation loss: 2.0895859118430846

Epoch: 6| Step: 9
Training loss: 2.255415439605713
Validation loss: 2.089856614348709

Epoch: 6| Step: 10
Training loss: 1.5847058296203613
Validation loss: 2.0842555940792127

Epoch: 6| Step: 11
Training loss: 1.4155464172363281
Validation loss: 2.075642298626643

Epoch: 6| Step: 12
Training loss: 2.6996910572052
Validation loss: 2.0686979909096994

Epoch: 6| Step: 13
Training loss: 2.4266209602355957
Validation loss: 2.0626374624108754

Epoch: 256| Step: 0
Training loss: 2.390205144882202
Validation loss: 2.045936797254829

Epoch: 6| Step: 1
Training loss: 1.5188229084014893
Validation loss: 2.045232231898974

Epoch: 6| Step: 2
Training loss: 2.299551486968994
Validation loss: 2.034366556393203

Epoch: 6| Step: 3
Training loss: 2.248807907104492
Validation loss: 2.0337480165625132

Epoch: 6| Step: 4
Training loss: 2.00291109085083
Validation loss: 2.0364007642192226

Epoch: 6| Step: 5
Training loss: 1.8354907035827637
Validation loss: 2.044712208932446

Epoch: 6| Step: 6
Training loss: 1.896032452583313
Validation loss: 2.0490765033229703

Epoch: 6| Step: 7
Training loss: 1.564148187637329
Validation loss: 2.0396511657263643

Epoch: 6| Step: 8
Training loss: 1.5586282014846802
Validation loss: 2.0503285623365834

Epoch: 6| Step: 9
Training loss: 1.9983657598495483
Validation loss: 2.059792294297167

Epoch: 6| Step: 10
Training loss: 2.1883702278137207
Validation loss: 2.0715436909788396

Epoch: 6| Step: 11
Training loss: 1.3604005575180054
Validation loss: 2.073150319437827

Epoch: 6| Step: 12
Training loss: 1.869996190071106
Validation loss: 2.0558327039082847

Epoch: 6| Step: 13
Training loss: 1.7452133893966675
Validation loss: 2.0537079534223004

Epoch: 257| Step: 0
Training loss: 1.8204705715179443
Validation loss: 2.034054022963329

Epoch: 6| Step: 1
Training loss: 2.0519580841064453
Validation loss: 2.0324756637696297

Epoch: 6| Step: 2
Training loss: 2.3902697563171387
Validation loss: 2.044924364295057

Epoch: 6| Step: 3
Training loss: 2.4189202785491943
Validation loss: 2.0363540495595625

Epoch: 6| Step: 4
Training loss: 1.5170338153839111
Validation loss: 2.037385391932662

Epoch: 6| Step: 5
Training loss: 1.6531908512115479
Validation loss: 2.040185946290211

Epoch: 6| Step: 6
Training loss: 1.6210846900939941
Validation loss: 2.0241590110204553

Epoch: 6| Step: 7
Training loss: 2.2386083602905273
Validation loss: 2.025992049965807

Epoch: 6| Step: 8
Training loss: 1.9561870098114014
Validation loss: 2.0421095637864966

Epoch: 6| Step: 9
Training loss: 1.6227288246154785
Validation loss: 2.0485348598931425

Epoch: 6| Step: 10
Training loss: 1.8840229511260986
Validation loss: 2.0357192357381186

Epoch: 6| Step: 11
Training loss: 1.3960797786712646
Validation loss: 2.0487451912254415

Epoch: 6| Step: 12
Training loss: 2.1053125858306885
Validation loss: 2.0441749890645347

Epoch: 6| Step: 13
Training loss: 1.9807565212249756
Validation loss: 2.016880998047449

Epoch: 258| Step: 0
Training loss: 2.0206246376037598
Validation loss: 2.019637166812856

Epoch: 6| Step: 1
Training loss: 1.924114465713501
Validation loss: 2.0063361403762654

Epoch: 6| Step: 2
Training loss: 1.7505953311920166
Validation loss: 1.992213446606872

Epoch: 6| Step: 3
Training loss: 2.0674948692321777
Validation loss: 1.9848789873943533

Epoch: 6| Step: 4
Training loss: 1.2881046533584595
Validation loss: 1.9837524198716687

Epoch: 6| Step: 5
Training loss: 2.7117066383361816
Validation loss: 1.9892578753091956

Epoch: 6| Step: 6
Training loss: 2.274256706237793
Validation loss: 1.9980577679090603

Epoch: 6| Step: 7
Training loss: 1.5179733037948608
Validation loss: 2.009119645241768

Epoch: 6| Step: 8
Training loss: 1.2321820259094238
Validation loss: 2.017463381572436

Epoch: 6| Step: 9
Training loss: 1.839881420135498
Validation loss: 2.0411477729838383

Epoch: 6| Step: 10
Training loss: 1.7124207019805908
Validation loss: 2.056611587924342

Epoch: 6| Step: 11
Training loss: 1.8846633434295654
Validation loss: 2.0707521515507854

Epoch: 6| Step: 12
Training loss: 2.7408790588378906
Validation loss: 2.075770661395083

Epoch: 6| Step: 13
Training loss: 1.3137211799621582
Validation loss: 2.0722859713339035

Epoch: 259| Step: 0
Training loss: 1.3313283920288086
Validation loss: 2.0781897806352183

Epoch: 6| Step: 1
Training loss: 2.012718439102173
Validation loss: 2.0910268175986504

Epoch: 6| Step: 2
Training loss: 1.7433363199234009
Validation loss: 2.0981240041794313

Epoch: 6| Step: 3
Training loss: 1.7888933420181274
Validation loss: 2.0998268896533596

Epoch: 6| Step: 4
Training loss: 1.9218158721923828
Validation loss: 2.096519067723264

Epoch: 6| Step: 5
Training loss: 1.9843170642852783
Validation loss: 2.1009383022144275

Epoch: 6| Step: 6
Training loss: 2.0448853969573975
Validation loss: 2.085380918236189

Epoch: 6| Step: 7
Training loss: 1.8288092613220215
Validation loss: 2.057067054574208

Epoch: 6| Step: 8
Training loss: 2.3796606063842773
Validation loss: 2.0222149100354923

Epoch: 6| Step: 9
Training loss: 1.9719138145446777
Validation loss: 2.0014784489908526

Epoch: 6| Step: 10
Training loss: 2.34061861038208
Validation loss: 1.9954090656772736

Epoch: 6| Step: 11
Training loss: 1.9767497777938843
Validation loss: 1.9886862693294403

Epoch: 6| Step: 12
Training loss: 1.3561079502105713
Validation loss: 1.9816040454372283

Epoch: 6| Step: 13
Training loss: 2.4618842601776123
Validation loss: 1.995705609680504

Epoch: 260| Step: 0
Training loss: 2.6557705402374268
Validation loss: 1.9867705734827186

Epoch: 6| Step: 1
Training loss: 1.5258359909057617
Validation loss: 1.997929851214091

Epoch: 6| Step: 2
Training loss: 1.3147896528244019
Validation loss: 2.0234747830257622

Epoch: 6| Step: 3
Training loss: 2.3162360191345215
Validation loss: 2.0148744903584963

Epoch: 6| Step: 4
Training loss: 2.2148590087890625
Validation loss: 2.024861740809615

Epoch: 6| Step: 5
Training loss: 1.7658635377883911
Validation loss: 2.040619945013395

Epoch: 6| Step: 6
Training loss: 1.7688851356506348
Validation loss: 2.0708244628803705

Epoch: 6| Step: 7
Training loss: 1.5067720413208008
Validation loss: 2.0789564194217807

Epoch: 6| Step: 8
Training loss: 2.076016426086426
Validation loss: 2.080562606934578

Epoch: 6| Step: 9
Training loss: 1.6835119724273682
Validation loss: 2.0872088119547856

Epoch: 6| Step: 10
Training loss: 2.1772966384887695
Validation loss: 2.077829973672026

Epoch: 6| Step: 11
Training loss: 1.6901500225067139
Validation loss: 2.059735523757114

Epoch: 6| Step: 12
Training loss: 1.6840124130249023
Validation loss: 2.0666406052086943

Epoch: 6| Step: 13
Training loss: 2.934187173843384
Validation loss: 2.0437514179496357

Epoch: 261| Step: 0
Training loss: 1.710559368133545
Validation loss: 2.034128463396462

Epoch: 6| Step: 1
Training loss: 1.5411561727523804
Validation loss: 2.0184753992224254

Epoch: 6| Step: 2
Training loss: 2.4611964225769043
Validation loss: 2.019795384458316

Epoch: 6| Step: 3
Training loss: 1.7522913217544556
Validation loss: 2.002613495754939

Epoch: 6| Step: 4
Training loss: 2.0891525745391846
Validation loss: 2.006851127070765

Epoch: 6| Step: 5
Training loss: 1.2573437690734863
Validation loss: 2.012192206357115

Epoch: 6| Step: 6
Training loss: 2.030921459197998
Validation loss: 2.0218657203899917

Epoch: 6| Step: 7
Training loss: 2.3884644508361816
Validation loss: 2.0297683490219938

Epoch: 6| Step: 8
Training loss: 1.3022515773773193
Validation loss: 2.05244864443297

Epoch: 6| Step: 9
Training loss: 2.228442907333374
Validation loss: 2.077233640096521

Epoch: 6| Step: 10
Training loss: 1.6912362575531006
Validation loss: 2.0880588049529702

Epoch: 6| Step: 11
Training loss: 1.7339696884155273
Validation loss: 2.103559617073305

Epoch: 6| Step: 12
Training loss: 2.3122763633728027
Validation loss: 2.0907202766787623

Epoch: 6| Step: 13
Training loss: 2.047588348388672
Validation loss: 2.0782739385481803

Epoch: 262| Step: 0
Training loss: 1.730445384979248
Validation loss: 2.0631547102364163

Epoch: 6| Step: 1
Training loss: 1.5677480697631836
Validation loss: 2.023098490571463

Epoch: 6| Step: 2
Training loss: 2.01598858833313
Validation loss: 2.010830253683111

Epoch: 6| Step: 3
Training loss: 1.5261669158935547
Validation loss: 2.00472685598558

Epoch: 6| Step: 4
Training loss: 1.9936695098876953
Validation loss: 2.0046967524354176

Epoch: 6| Step: 5
Training loss: 1.6470973491668701
Validation loss: 2.0188116206917712

Epoch: 6| Step: 6
Training loss: 2.156592845916748
Validation loss: 2.0381462727823565

Epoch: 6| Step: 7
Training loss: 1.8637536764144897
Validation loss: 2.0433817627609416

Epoch: 6| Step: 8
Training loss: 1.6114168167114258
Validation loss: 2.05398876179931

Epoch: 6| Step: 9
Training loss: 2.4535269737243652
Validation loss: 2.062477687353729

Epoch: 6| Step: 10
Training loss: 2.355747699737549
Validation loss: 2.069380283355713

Epoch: 6| Step: 11
Training loss: 0.9195696115493774
Validation loss: 2.0727368593215942

Epoch: 6| Step: 12
Training loss: 2.539968252182007
Validation loss: 2.0828199437869492

Epoch: 6| Step: 13
Training loss: 2.103541374206543
Validation loss: 2.0783988096380748

Epoch: 263| Step: 0
Training loss: 1.6605361700057983
Validation loss: 2.080181808881862

Epoch: 6| Step: 1
Training loss: 1.6053028106689453
Validation loss: 2.0502467975821546

Epoch: 6| Step: 2
Training loss: 2.1662468910217285
Validation loss: 2.0308583128836846

Epoch: 6| Step: 3
Training loss: 1.4395296573638916
Validation loss: 2.0028106653562157

Epoch: 6| Step: 4
Training loss: 2.5861153602600098
Validation loss: 1.997455850724251

Epoch: 6| Step: 5
Training loss: 1.8221969604492188
Validation loss: 2.000570562578017

Epoch: 6| Step: 6
Training loss: 1.9027646780014038
Validation loss: 2.0020851858200563

Epoch: 6| Step: 7
Training loss: 1.8134760856628418
Validation loss: 1.9972690792493923

Epoch: 6| Step: 8
Training loss: 1.8871232271194458
Validation loss: 2.0036804829874346

Epoch: 6| Step: 9
Training loss: 2.102403163909912
Validation loss: 2.0125688186255832

Epoch: 6| Step: 10
Training loss: 1.027846336364746
Validation loss: 2.033631932350897

Epoch: 6| Step: 11
Training loss: 1.9183841943740845
Validation loss: 2.0506467998668714

Epoch: 6| Step: 12
Training loss: 1.9584665298461914
Validation loss: 2.059336777656309

Epoch: 6| Step: 13
Training loss: 2.520587205886841
Validation loss: 2.0842213169220956

Epoch: 264| Step: 0
Training loss: 1.3911583423614502
Validation loss: 2.0792822786556777

Epoch: 6| Step: 1
Training loss: 1.9703185558319092
Validation loss: 2.0894600293969594

Epoch: 6| Step: 2
Training loss: 1.8814953565597534
Validation loss: 2.0642028829102874

Epoch: 6| Step: 3
Training loss: 1.8150666952133179
Validation loss: 2.0793341667421403

Epoch: 6| Step: 4
Training loss: 1.7828954458236694
Validation loss: 2.056439058755034

Epoch: 6| Step: 5
Training loss: 2.5653443336486816
Validation loss: 2.042044257604948

Epoch: 6| Step: 6
Training loss: 1.4782800674438477
Validation loss: 2.0372719380163375

Epoch: 6| Step: 7
Training loss: 2.3895022869110107
Validation loss: 2.0263717430894093

Epoch: 6| Step: 8
Training loss: 1.1654398441314697
Validation loss: 2.016824053179833

Epoch: 6| Step: 9
Training loss: 1.7715332508087158
Validation loss: 2.014050317066972

Epoch: 6| Step: 10
Training loss: 2.880279541015625
Validation loss: 2.0255822494465816

Epoch: 6| Step: 11
Training loss: 1.5055127143859863
Validation loss: 2.0168623167981385

Epoch: 6| Step: 12
Training loss: 1.7673426866531372
Validation loss: 2.0454003477609284

Epoch: 6| Step: 13
Training loss: 1.7594753503799438
Validation loss: 2.0450246923713276

Epoch: 265| Step: 0
Training loss: 2.010972023010254
Validation loss: 2.0612203574949697

Epoch: 6| Step: 1
Training loss: 2.241405487060547
Validation loss: 2.067797489063714

Epoch: 6| Step: 2
Training loss: 2.4338512420654297
Validation loss: 2.03066663588247

Epoch: 6| Step: 3
Training loss: 2.2500481605529785
Validation loss: 2.0146753518812117

Epoch: 6| Step: 4
Training loss: 1.5583735704421997
Validation loss: 1.9971794184818064

Epoch: 6| Step: 5
Training loss: 1.1753692626953125
Validation loss: 2.0031355273339058

Epoch: 6| Step: 6
Training loss: 1.7167515754699707
Validation loss: 2.0001520687533962

Epoch: 6| Step: 7
Training loss: 1.8193103075027466
Validation loss: 2.0103454794935

Epoch: 6| Step: 8
Training loss: 1.5760796070098877
Validation loss: 2.0085579708058345

Epoch: 6| Step: 9
Training loss: 2.5704567432403564
Validation loss: 2.016264300192556

Epoch: 6| Step: 10
Training loss: 0.9654500484466553
Validation loss: 2.016077531281338

Epoch: 6| Step: 11
Training loss: 1.692030429840088
Validation loss: 2.0397039075051584

Epoch: 6| Step: 12
Training loss: 2.056645154953003
Validation loss: 2.0355736158227407

Epoch: 6| Step: 13
Training loss: 1.7959191799163818
Validation loss: 2.0576378401889595

Epoch: 266| Step: 0
Training loss: 1.5559077262878418
Validation loss: 2.0558029849042176

Epoch: 6| Step: 1
Training loss: 1.6541032791137695
Validation loss: 2.0495445856484036

Epoch: 6| Step: 2
Training loss: 2.6639297008514404
Validation loss: 2.044171720422724

Epoch: 6| Step: 3
Training loss: 1.9613277912139893
Validation loss: 2.0599067416242374

Epoch: 6| Step: 4
Training loss: 2.227612257003784
Validation loss: 2.0320195305731987

Epoch: 6| Step: 5
Training loss: 1.8604614734649658
Validation loss: 2.0330368024046703

Epoch: 6| Step: 6
Training loss: 1.2307250499725342
Validation loss: 2.0494891007741294

Epoch: 6| Step: 7
Training loss: 2.0202465057373047
Validation loss: 2.0268757548383487

Epoch: 6| Step: 8
Training loss: 1.79206383228302
Validation loss: 2.0567470647955455

Epoch: 6| Step: 9
Training loss: 1.685311198234558
Validation loss: 2.0338212841300556

Epoch: 6| Step: 10
Training loss: 1.5062354803085327
Validation loss: 2.0262537771655666

Epoch: 6| Step: 11
Training loss: 2.2124931812286377
Validation loss: 2.028884865904367

Epoch: 6| Step: 12
Training loss: 2.1486122608184814
Validation loss: 2.0352744825424685

Epoch: 6| Step: 13
Training loss: 0.8943625688552856
Validation loss: 2.0345204068768408

Epoch: 267| Step: 0
Training loss: 2.497023105621338
Validation loss: 2.0337410165417578

Epoch: 6| Step: 1
Training loss: 1.8570430278778076
Validation loss: 2.050437263263169

Epoch: 6| Step: 2
Training loss: 1.9761388301849365
Validation loss: 2.0620317305288007

Epoch: 6| Step: 3
Training loss: 1.9167087078094482
Validation loss: 2.058991075843893

Epoch: 6| Step: 4
Training loss: 1.4439153671264648
Validation loss: 2.0514194221906763

Epoch: 6| Step: 5
Training loss: 1.5741162300109863
Validation loss: 2.0454945064360097

Epoch: 6| Step: 6
Training loss: 1.6040624380111694
Validation loss: 2.0542222786975164

Epoch: 6| Step: 7
Training loss: 1.5101478099822998
Validation loss: 2.0607315878714285

Epoch: 6| Step: 8
Training loss: 1.6104848384857178
Validation loss: 2.0403098226875387

Epoch: 6| Step: 9
Training loss: 2.0433130264282227
Validation loss: 2.0304140147342475

Epoch: 6| Step: 10
Training loss: 2.146995782852173
Validation loss: 2.022888993704191

Epoch: 6| Step: 11
Training loss: 2.434058427810669
Validation loss: 2.009822081494075

Epoch: 6| Step: 12
Training loss: 1.0796672105789185
Validation loss: 2.0050035574102916

Epoch: 6| Step: 13
Training loss: 2.1439898014068604
Validation loss: 1.9878716263719785

Epoch: 268| Step: 0
Training loss: 1.6528730392456055
Validation loss: 1.9823719609168269

Epoch: 6| Step: 1
Training loss: 2.3550262451171875
Validation loss: 1.9879873286011398

Epoch: 6| Step: 2
Training loss: 1.2563657760620117
Validation loss: 1.981343266784504

Epoch: 6| Step: 3
Training loss: 2.030669689178467
Validation loss: 1.9973999223401468

Epoch: 6| Step: 4
Training loss: 0.9401147365570068
Validation loss: 1.9976643939172067

Epoch: 6| Step: 5
Training loss: 1.8408031463623047
Validation loss: 2.01222159272881

Epoch: 6| Step: 6
Training loss: 1.9651674032211304
Validation loss: 2.007059094726398

Epoch: 6| Step: 7
Training loss: 1.595290184020996
Validation loss: 2.020209458566481

Epoch: 6| Step: 8
Training loss: 1.7598835229873657
Validation loss: 2.0172790570925643

Epoch: 6| Step: 9
Training loss: 2.469080686569214
Validation loss: 2.0068911647283905

Epoch: 6| Step: 10
Training loss: 2.3506388664245605
Validation loss: 2.025013194289259

Epoch: 6| Step: 11
Training loss: 1.691300868988037
Validation loss: 2.0243073432676253

Epoch: 6| Step: 12
Training loss: 1.8968737125396729
Validation loss: 2.0112002588087514

Epoch: 6| Step: 13
Training loss: 1.9157600402832031
Validation loss: 2.0208565829902567

Epoch: 269| Step: 0
Training loss: 2.1830832958221436
Validation loss: 2.0054328262165027

Epoch: 6| Step: 1
Training loss: 2.055061101913452
Validation loss: 2.003827776960147

Epoch: 6| Step: 2
Training loss: 2.1408023834228516
Validation loss: 2.008188747590588

Epoch: 6| Step: 3
Training loss: 1.174654483795166
Validation loss: 2.0310541737464165

Epoch: 6| Step: 4
Training loss: 2.1206040382385254
Validation loss: 2.046150479265439

Epoch: 6| Step: 5
Training loss: 2.469587802886963
Validation loss: 2.064697651452916

Epoch: 6| Step: 6
Training loss: 1.3728728294372559
Validation loss: 2.062905942240069

Epoch: 6| Step: 7
Training loss: 1.6991908550262451
Validation loss: 2.0510678034956737

Epoch: 6| Step: 8
Training loss: 1.769897222518921
Validation loss: 2.0516972208535798

Epoch: 6| Step: 9
Training loss: 1.5622880458831787
Validation loss: 2.03759144454874

Epoch: 6| Step: 10
Training loss: 2.319356679916382
Validation loss: 2.0410003739018596

Epoch: 6| Step: 11
Training loss: 1.6364136934280396
Validation loss: 2.0312607685724893

Epoch: 6| Step: 12
Training loss: 1.1485481262207031
Validation loss: 2.0262760731481735

Epoch: 6| Step: 13
Training loss: 1.9425873756408691
Validation loss: 2.0188687437324115

Epoch: 270| Step: 0
Training loss: 1.7395589351654053
Validation loss: 2.0153959476819603

Epoch: 6| Step: 1
Training loss: 1.6331597566604614
Validation loss: 2.0315918307150564

Epoch: 6| Step: 2
Training loss: 1.8601247072219849
Validation loss: 2.0395145646987425

Epoch: 6| Step: 3
Training loss: 1.0338023900985718
Validation loss: 2.0879468174390894

Epoch: 6| Step: 4
Training loss: 1.8157888650894165
Validation loss: 2.0817659272942493

Epoch: 6| Step: 5
Training loss: 1.8625588417053223
Validation loss: 2.068395568478492

Epoch: 6| Step: 6
Training loss: 1.824183464050293
Validation loss: 2.0620269621572187

Epoch: 6| Step: 7
Training loss: 1.4987425804138184
Validation loss: 2.0300803863874046

Epoch: 6| Step: 8
Training loss: 2.2481346130371094
Validation loss: 2.0220765298412693

Epoch: 6| Step: 9
Training loss: 1.8058497905731201
Validation loss: 2.0268494044580767

Epoch: 6| Step: 10
Training loss: 2.2515907287597656
Validation loss: 2.0163810535143782

Epoch: 6| Step: 11
Training loss: 1.7680823802947998
Validation loss: 2.0322193714880172

Epoch: 6| Step: 12
Training loss: 2.836111307144165
Validation loss: 2.0248581209490375

Epoch: 6| Step: 13
Training loss: 0.9228706359863281
Validation loss: 2.045802980340937

Epoch: 271| Step: 0
Training loss: 1.6286145448684692
Validation loss: 2.0456490747390257

Epoch: 6| Step: 1
Training loss: 2.1363794803619385
Validation loss: 2.070312761491345

Epoch: 6| Step: 2
Training loss: 1.641687035560608
Validation loss: 2.04891872918734

Epoch: 6| Step: 3
Training loss: 1.3908733129501343
Validation loss: 2.056531374172498

Epoch: 6| Step: 4
Training loss: 1.5144025087356567
Validation loss: 2.068482509223364

Epoch: 6| Step: 5
Training loss: 1.9200071096420288
Validation loss: 2.03307540698718

Epoch: 6| Step: 6
Training loss: 1.4200544357299805
Validation loss: 2.0175362376756567

Epoch: 6| Step: 7
Training loss: 2.1454381942749023
Validation loss: 2.0171157852295907

Epoch: 6| Step: 8
Training loss: 1.181807041168213
Validation loss: 1.9945806892969276

Epoch: 6| Step: 9
Training loss: 2.471205711364746
Validation loss: 1.9915159902264994

Epoch: 6| Step: 10
Training loss: 1.6660826206207275
Validation loss: 1.9790833432187316

Epoch: 6| Step: 11
Training loss: 2.3480842113494873
Validation loss: 1.9619049974667129

Epoch: 6| Step: 12
Training loss: 2.0915491580963135
Validation loss: 1.970481482885217

Epoch: 6| Step: 13
Training loss: 1.6838889122009277
Validation loss: 1.9794758583909722

Epoch: 272| Step: 0
Training loss: 2.20170259475708
Validation loss: 2.004119619246452

Epoch: 6| Step: 1
Training loss: 2.3779046535491943
Validation loss: 2.0653101295553227

Epoch: 6| Step: 2
Training loss: 1.6070581674575806
Validation loss: 2.0994789574735906

Epoch: 6| Step: 3
Training loss: 1.7945153713226318
Validation loss: 2.0852850624310073

Epoch: 6| Step: 4
Training loss: 1.548790454864502
Validation loss: 2.066975220557182

Epoch: 6| Step: 5
Training loss: 1.5718529224395752
Validation loss: 2.051672471466885

Epoch: 6| Step: 6
Training loss: 1.4222275018692017
Validation loss: 2.0489076055506223

Epoch: 6| Step: 7
Training loss: 2.7565767765045166
Validation loss: 2.0390299327911867

Epoch: 6| Step: 8
Training loss: 2.012521266937256
Validation loss: 2.0524018182549426

Epoch: 6| Step: 9
Training loss: 1.4192218780517578
Validation loss: 2.053509158472861

Epoch: 6| Step: 10
Training loss: 1.213531494140625
Validation loss: 2.0489898945695613

Epoch: 6| Step: 11
Training loss: 1.8057775497436523
Validation loss: 2.057810478312995

Epoch: 6| Step: 12
Training loss: 1.8019461631774902
Validation loss: 2.0544191175891506

Epoch: 6| Step: 13
Training loss: 1.9008604288101196
Validation loss: 2.063609387284966

Epoch: 273| Step: 0
Training loss: 2.4001479148864746
Validation loss: 2.04079149359016

Epoch: 6| Step: 1
Training loss: 1.6899877786636353
Validation loss: 2.0529321470568256

Epoch: 6| Step: 2
Training loss: 2.1355841159820557
Validation loss: 2.04773239679234

Epoch: 6| Step: 3
Training loss: 1.6426422595977783
Validation loss: 2.0143616237948017

Epoch: 6| Step: 4
Training loss: 1.9999215602874756
Validation loss: 2.0105250112472044

Epoch: 6| Step: 5
Training loss: 1.637819528579712
Validation loss: 1.9983223356226438

Epoch: 6| Step: 6
Training loss: 1.973413109779358
Validation loss: 1.9909217024362216

Epoch: 6| Step: 7
Training loss: 1.5917136669158936
Validation loss: 1.9797404132863528

Epoch: 6| Step: 8
Training loss: 2.151890754699707
Validation loss: 1.986375016550864

Epoch: 6| Step: 9
Training loss: 1.7980902194976807
Validation loss: 1.9944026957276046

Epoch: 6| Step: 10
Training loss: 1.4980379343032837
Validation loss: 1.9834807534371652

Epoch: 6| Step: 11
Training loss: 1.7852590084075928
Validation loss: 1.976544245596855

Epoch: 6| Step: 12
Training loss: 1.118187427520752
Validation loss: 1.9697411239788096

Epoch: 6| Step: 13
Training loss: 1.7717677354812622
Validation loss: 1.969571659641881

Epoch: 274| Step: 0
Training loss: 1.8599451780319214
Validation loss: 1.9878117371630926

Epoch: 6| Step: 1
Training loss: 1.9999446868896484
Validation loss: 2.0138751204295824

Epoch: 6| Step: 2
Training loss: 1.4806697368621826
Validation loss: 2.0309319931973695

Epoch: 6| Step: 3
Training loss: 1.686676025390625
Validation loss: 2.0526668845966296

Epoch: 6| Step: 4
Training loss: 1.8038443326950073
Validation loss: 2.0623051171661704

Epoch: 6| Step: 5
Training loss: 1.798764944076538
Validation loss: 2.084539141706241

Epoch: 6| Step: 6
Training loss: 1.893752098083496
Validation loss: 2.083488020845639

Epoch: 6| Step: 7
Training loss: 1.5394783020019531
Validation loss: 2.080737293407481

Epoch: 6| Step: 8
Training loss: 1.2355146408081055
Validation loss: 2.09344103131243

Epoch: 6| Step: 9
Training loss: 1.84228515625
Validation loss: 2.0826766324299637

Epoch: 6| Step: 10
Training loss: 1.45607590675354
Validation loss: 2.0926127843959357

Epoch: 6| Step: 11
Training loss: 2.0083377361297607
Validation loss: 2.083242351009

Epoch: 6| Step: 12
Training loss: 2.1049301624298096
Validation loss: 2.0824261608944146

Epoch: 6| Step: 13
Training loss: 2.4646201133728027
Validation loss: 2.0625653984726116

Epoch: 275| Step: 0
Training loss: 1.8134257793426514
Validation loss: 2.0743699868520102

Epoch: 6| Step: 1
Training loss: 2.1298980712890625
Validation loss: 2.091447035471598

Epoch: 6| Step: 2
Training loss: 1.832780361175537
Validation loss: 2.080327644143053

Epoch: 6| Step: 3
Training loss: 2.05631685256958
Validation loss: 2.048340041150329

Epoch: 6| Step: 4
Training loss: 1.7961838245391846
Validation loss: 2.033806388096143

Epoch: 6| Step: 5
Training loss: 1.4478964805603027
Validation loss: 2.007718560516193

Epoch: 6| Step: 6
Training loss: 1.9796823263168335
Validation loss: 1.985017486797866

Epoch: 6| Step: 7
Training loss: 1.2869980335235596
Validation loss: 1.9898176423964962

Epoch: 6| Step: 8
Training loss: 1.4599649906158447
Validation loss: 1.9754609484826364

Epoch: 6| Step: 9
Training loss: 1.975765347480774
Validation loss: 1.9868045391574982

Epoch: 6| Step: 10
Training loss: 2.0203847885131836
Validation loss: 1.9960054710347166

Epoch: 6| Step: 11
Training loss: 1.5467407703399658
Validation loss: 2.01017713803117

Epoch: 6| Step: 12
Training loss: 2.1972479820251465
Validation loss: 2.045082608858744

Epoch: 6| Step: 13
Training loss: 1.212700366973877
Validation loss: 2.0360817986149944

Epoch: 276| Step: 0
Training loss: 2.503833770751953
Validation loss: 2.0421719474177205

Epoch: 6| Step: 1
Training loss: 2.0271475315093994
Validation loss: 2.034288050026022

Epoch: 6| Step: 2
Training loss: 1.2666175365447998
Validation loss: 2.0146472018252135

Epoch: 6| Step: 3
Training loss: 1.6997809410095215
Validation loss: 1.99942744675503

Epoch: 6| Step: 4
Training loss: 1.7877440452575684
Validation loss: 1.9806009313111663

Epoch: 6| Step: 5
Training loss: 2.157078504562378
Validation loss: 1.9645204441521757

Epoch: 6| Step: 6
Training loss: 2.0756306648254395
Validation loss: 1.9712008558293825

Epoch: 6| Step: 7
Training loss: 1.8579456806182861
Validation loss: 1.973686736117127

Epoch: 6| Step: 8
Training loss: 1.8523194789886475
Validation loss: 1.984254361480795

Epoch: 6| Step: 9
Training loss: 1.794461727142334
Validation loss: 1.99420291121288

Epoch: 6| Step: 10
Training loss: 1.5699458122253418
Validation loss: 2.0169618360457884

Epoch: 6| Step: 11
Training loss: 1.9397821426391602
Validation loss: 2.0298833026680896

Epoch: 6| Step: 12
Training loss: 1.3411049842834473
Validation loss: 2.0575563651259228

Epoch: 6| Step: 13
Training loss: 0.4792265295982361
Validation loss: 2.0703845972655923

Epoch: 277| Step: 0
Training loss: 1.671313762664795
Validation loss: 2.090817964205178

Epoch: 6| Step: 1
Training loss: 2.334035873413086
Validation loss: 2.11752462515267

Epoch: 6| Step: 2
Training loss: 2.0084757804870605
Validation loss: 2.127996389583875

Epoch: 6| Step: 3
Training loss: 0.7787179946899414
Validation loss: 2.1170548777426443

Epoch: 6| Step: 4
Training loss: 1.6417018175125122
Validation loss: 2.105426978039485

Epoch: 6| Step: 5
Training loss: 2.3203649520874023
Validation loss: 2.0963481062202045

Epoch: 6| Step: 6
Training loss: 1.5433716773986816
Validation loss: 2.0871891142219625

Epoch: 6| Step: 7
Training loss: 1.908286213874817
Validation loss: 2.0576546884352163

Epoch: 6| Step: 8
Training loss: 1.977101445198059
Validation loss: 2.0400202825505245

Epoch: 6| Step: 9
Training loss: 1.9756340980529785
Validation loss: 2.0333796726760043

Epoch: 6| Step: 10
Training loss: 1.8174288272857666
Validation loss: 2.025944512377503

Epoch: 6| Step: 11
Training loss: 1.747859001159668
Validation loss: 2.0500888760371874

Epoch: 6| Step: 12
Training loss: 1.5813887119293213
Validation loss: 2.015823889804143

Epoch: 6| Step: 13
Training loss: 1.2993592023849487
Validation loss: 2.014290641712886

Epoch: 278| Step: 0
Training loss: 2.248189687728882
Validation loss: 1.9959615609979118

Epoch: 6| Step: 1
Training loss: 1.7862002849578857
Validation loss: 2.024396300315857

Epoch: 6| Step: 2
Training loss: 2.1736679077148438
Validation loss: 2.0148258209228516

Epoch: 6| Step: 3
Training loss: 2.390185832977295
Validation loss: 2.0075699078139437

Epoch: 6| Step: 4
Training loss: 1.8591142892837524
Validation loss: 2.0067475905982395

Epoch: 6| Step: 5
Training loss: 1.6288137435913086
Validation loss: 2.015520400898431

Epoch: 6| Step: 6
Training loss: 1.3258068561553955
Validation loss: 2.024506962427529

Epoch: 6| Step: 7
Training loss: 1.5821099281311035
Validation loss: 2.0425199231793805

Epoch: 6| Step: 8
Training loss: 1.7034324407577515
Validation loss: 2.078680863944433

Epoch: 6| Step: 9
Training loss: 1.2416837215423584
Validation loss: 2.1106105107133106

Epoch: 6| Step: 10
Training loss: 1.5120341777801514
Validation loss: 2.1036660978871007

Epoch: 6| Step: 11
Training loss: 1.0065476894378662
Validation loss: 2.1116830559187036

Epoch: 6| Step: 12
Training loss: 2.7588839530944824
Validation loss: 2.086991443428942

Epoch: 6| Step: 13
Training loss: 0.9249000549316406
Validation loss: 2.057880766930119

Epoch: 279| Step: 0
Training loss: 2.0302071571350098
Validation loss: 2.035996206345097

Epoch: 6| Step: 1
Training loss: 1.1194188594818115
Validation loss: 1.9916541230294011

Epoch: 6| Step: 2
Training loss: 1.6634160280227661
Validation loss: 1.9711339806997648

Epoch: 6| Step: 3
Training loss: 1.0868606567382812
Validation loss: 1.9658088248263124

Epoch: 6| Step: 4
Training loss: 1.5856969356536865
Validation loss: 1.972608543211414

Epoch: 6| Step: 5
Training loss: 1.9961633682250977
Validation loss: 1.990747163372655

Epoch: 6| Step: 6
Training loss: 2.2092278003692627
Validation loss: 1.9870738624244608

Epoch: 6| Step: 7
Training loss: 1.6896789073944092
Validation loss: 2.005249314410712

Epoch: 6| Step: 8
Training loss: 2.064326524734497
Validation loss: 2.007584801284216

Epoch: 6| Step: 9
Training loss: 1.5794633626937866
Validation loss: 2.0290983543601087

Epoch: 6| Step: 10
Training loss: 1.8243767023086548
Validation loss: 2.0399320740853586

Epoch: 6| Step: 11
Training loss: 2.21720814704895
Validation loss: 2.0821255073752454

Epoch: 6| Step: 12
Training loss: 1.7557847499847412
Validation loss: 2.10176416366331

Epoch: 6| Step: 13
Training loss: 1.626585841178894
Validation loss: 2.095070272363642

Epoch: 280| Step: 0
Training loss: 1.650412917137146
Validation loss: 2.1201422650326966

Epoch: 6| Step: 1
Training loss: 1.079942226409912
Validation loss: 2.111244204223797

Epoch: 6| Step: 2
Training loss: 1.5152385234832764
Validation loss: 2.0777299942508822

Epoch: 6| Step: 3
Training loss: 2.1430773735046387
Validation loss: 2.0619245088228615

Epoch: 6| Step: 4
Training loss: 1.859558343887329
Validation loss: 2.057837035066338

Epoch: 6| Step: 5
Training loss: 1.4228448867797852
Validation loss: 2.016155619775095

Epoch: 6| Step: 6
Training loss: 1.6155109405517578
Validation loss: 2.0005026555830434

Epoch: 6| Step: 7
Training loss: 1.3756318092346191
Validation loss: 2.0156270637307117

Epoch: 6| Step: 8
Training loss: 2.1214218139648438
Validation loss: 2.002554824275355

Epoch: 6| Step: 9
Training loss: 1.8137948513031006
Validation loss: 2.0019586547728507

Epoch: 6| Step: 10
Training loss: 2.057056427001953
Validation loss: 1.9828543637388496

Epoch: 6| Step: 11
Training loss: 2.2150516510009766
Validation loss: 2.000955234291733

Epoch: 6| Step: 12
Training loss: 1.3863525390625
Validation loss: 2.018281000916676

Epoch: 6| Step: 13
Training loss: 2.4144086837768555
Validation loss: 2.0425350601955126

Epoch: 281| Step: 0
Training loss: 1.2453174591064453
Validation loss: 2.046100224218061

Epoch: 6| Step: 1
Training loss: 1.766967535018921
Validation loss: 2.0697124619637766

Epoch: 6| Step: 2
Training loss: 1.269789218902588
Validation loss: 2.0964068302544216

Epoch: 6| Step: 3
Training loss: 2.2471120357513428
Validation loss: 2.0933116456513763

Epoch: 6| Step: 4
Training loss: 1.9113399982452393
Validation loss: 2.0924302801009147

Epoch: 6| Step: 5
Training loss: 1.5888543128967285
Validation loss: 2.0788904877119165

Epoch: 6| Step: 6
Training loss: 1.6756529808044434
Validation loss: 2.0639550403882096

Epoch: 6| Step: 7
Training loss: 1.8417412042617798
Validation loss: 2.0607246814235562

Epoch: 6| Step: 8
Training loss: 1.9675695896148682
Validation loss: 2.037788778223017

Epoch: 6| Step: 9
Training loss: 1.543590784072876
Validation loss: 2.023536156582576

Epoch: 6| Step: 10
Training loss: 1.5831935405731201
Validation loss: 2.009281289192938

Epoch: 6| Step: 11
Training loss: 2.057234525680542
Validation loss: 2.0032066196523686

Epoch: 6| Step: 12
Training loss: 1.977088451385498
Validation loss: 2.0032024460454143

Epoch: 6| Step: 13
Training loss: 1.6487159729003906
Validation loss: 1.979392292678997

Epoch: 282| Step: 0
Training loss: 1.4694852828979492
Validation loss: 1.9988463463321808

Epoch: 6| Step: 1
Training loss: 1.9637959003448486
Validation loss: 1.9981111070161224

Epoch: 6| Step: 2
Training loss: 1.7266618013381958
Validation loss: 2.0123143311469787

Epoch: 6| Step: 3
Training loss: 1.9264233112335205
Validation loss: 2.0135466001367055

Epoch: 6| Step: 4
Training loss: 1.6390386819839478
Validation loss: 2.061567929483229

Epoch: 6| Step: 5
Training loss: 1.6647257804870605
Validation loss: 2.0564554237550303

Epoch: 6| Step: 6
Training loss: 1.461795687675476
Validation loss: 2.075776066831363

Epoch: 6| Step: 7
Training loss: 1.3944050073623657
Validation loss: 2.0642885584985056

Epoch: 6| Step: 8
Training loss: 1.9475468397140503
Validation loss: 2.0600487980791318

Epoch: 6| Step: 9
Training loss: 1.5520600080490112
Validation loss: 2.0240534172263196

Epoch: 6| Step: 10
Training loss: 1.5319790840148926
Validation loss: 2.0055834311310963

Epoch: 6| Step: 11
Training loss: 1.8620357513427734
Validation loss: 2.0342212518056235

Epoch: 6| Step: 12
Training loss: 2.3322644233703613
Validation loss: 2.0018181967478927

Epoch: 6| Step: 13
Training loss: 1.9518470764160156
Validation loss: 2.0031730962055985

Epoch: 283| Step: 0
Training loss: 1.7970385551452637
Validation loss: 2.0175658797705047

Epoch: 6| Step: 1
Training loss: 1.4109092950820923
Validation loss: 2.025653167437482

Epoch: 6| Step: 2
Training loss: 2.330009698867798
Validation loss: 2.0494487208704792

Epoch: 6| Step: 3
Training loss: 1.7787277698516846
Validation loss: 2.0895509566030195

Epoch: 6| Step: 4
Training loss: 1.5059733390808105
Validation loss: 2.0980215918633247

Epoch: 6| Step: 5
Training loss: 1.9416629076004028
Validation loss: 2.084700906148521

Epoch: 6| Step: 6
Training loss: 1.1366748809814453
Validation loss: 2.062463487348249

Epoch: 6| Step: 7
Training loss: 1.3863658905029297
Validation loss: 2.037747867645756

Epoch: 6| Step: 8
Training loss: 1.802343726158142
Validation loss: 2.0276019201483777

Epoch: 6| Step: 9
Training loss: 1.7652177810668945
Validation loss: 2.008174648848913

Epoch: 6| Step: 10
Training loss: 1.8427081108093262
Validation loss: 1.993499404640608

Epoch: 6| Step: 11
Training loss: 1.1336928606033325
Validation loss: 1.9909593725717196

Epoch: 6| Step: 12
Training loss: 2.042879581451416
Validation loss: 1.9797398608217958

Epoch: 6| Step: 13
Training loss: 2.3667707443237305
Validation loss: 1.9914224763070383

Epoch: 284| Step: 0
Training loss: 2.0345849990844727
Validation loss: 1.9950095017751057

Epoch: 6| Step: 1
Training loss: 1.5376605987548828
Validation loss: 2.033836864656018

Epoch: 6| Step: 2
Training loss: 0.9834995269775391
Validation loss: 2.0376644185794297

Epoch: 6| Step: 3
Training loss: 1.3504242897033691
Validation loss: 2.0562364388537664

Epoch: 6| Step: 4
Training loss: 2.240196704864502
Validation loss: 2.04064445213605

Epoch: 6| Step: 5
Training loss: 1.9506278038024902
Validation loss: 2.070291496092273

Epoch: 6| Step: 6
Training loss: 1.6373116970062256
Validation loss: 2.0554308276022635

Epoch: 6| Step: 7
Training loss: 1.4461426734924316
Validation loss: 2.0354851317662064

Epoch: 6| Step: 8
Training loss: 1.34080171585083
Validation loss: 2.00691568979653

Epoch: 6| Step: 9
Training loss: 1.8567171096801758
Validation loss: 2.006400277537684

Epoch: 6| Step: 10
Training loss: 1.9272472858428955
Validation loss: 1.9995602664127146

Epoch: 6| Step: 11
Training loss: 1.7095365524291992
Validation loss: 2.011718502608679

Epoch: 6| Step: 12
Training loss: 1.9261904954910278
Validation loss: 1.9818702205534904

Epoch: 6| Step: 13
Training loss: 2.0100808143615723
Validation loss: 1.9878693883137037

Epoch: 285| Step: 0
Training loss: 1.7631490230560303
Validation loss: 2.0084649234689693

Epoch: 6| Step: 1
Training loss: 1.8761305809020996
Validation loss: 2.0204070691139466

Epoch: 6| Step: 2
Training loss: 1.5653290748596191
Validation loss: 2.049343260385657

Epoch: 6| Step: 3
Training loss: 0.7897447943687439
Validation loss: 2.0630899142193537

Epoch: 6| Step: 4
Training loss: 2.676924705505371
Validation loss: 2.09368622174827

Epoch: 6| Step: 5
Training loss: 1.7361451387405396
Validation loss: 2.091627146608086

Epoch: 6| Step: 6
Training loss: 2.294642448425293
Validation loss: 2.086222865248239

Epoch: 6| Step: 7
Training loss: 1.8499271869659424
Validation loss: 2.1093160170380787

Epoch: 6| Step: 8
Training loss: 1.5459113121032715
Validation loss: 2.0724510005725327

Epoch: 6| Step: 9
Training loss: 1.8317506313323975
Validation loss: 2.0269551559161116

Epoch: 6| Step: 10
Training loss: 1.45101797580719
Validation loss: 2.0029800732930503

Epoch: 6| Step: 11
Training loss: 1.3093845844268799
Validation loss: 1.9832601931787306

Epoch: 6| Step: 12
Training loss: 1.4425134658813477
Validation loss: 1.9825112460761942

Epoch: 6| Step: 13
Training loss: 1.9908900260925293
Validation loss: 1.9935734528367237

Epoch: 286| Step: 0
Training loss: 1.9329402446746826
Validation loss: 2.0133680656392086

Epoch: 6| Step: 1
Training loss: 1.3426437377929688
Validation loss: 2.0225658442384455

Epoch: 6| Step: 2
Training loss: 1.7130649089813232
Validation loss: 2.0523000096762054

Epoch: 6| Step: 3
Training loss: 1.1859157085418701
Validation loss: 2.0674023858962522

Epoch: 6| Step: 4
Training loss: 1.7998791933059692
Validation loss: 2.0745000903324415

Epoch: 6| Step: 5
Training loss: 1.1487400531768799
Validation loss: 2.078963287415043

Epoch: 6| Step: 6
Training loss: 1.770920753479004
Validation loss: 2.078127227803712

Epoch: 6| Step: 7
Training loss: 2.093170642852783
Validation loss: 2.0668698280088362

Epoch: 6| Step: 8
Training loss: 1.6547114849090576
Validation loss: 2.066049047695693

Epoch: 6| Step: 9
Training loss: 2.3758978843688965
Validation loss: 2.051091586389849

Epoch: 6| Step: 10
Training loss: 1.899742603302002
Validation loss: 2.040461351794581

Epoch: 6| Step: 11
Training loss: 1.5082602500915527
Validation loss: 2.004738243677283

Epoch: 6| Step: 12
Training loss: 1.587794542312622
Validation loss: 2.0085648849446285

Epoch: 6| Step: 13
Training loss: 1.4696340560913086
Validation loss: 1.9980277681863436

Epoch: 287| Step: 0
Training loss: 1.277989387512207
Validation loss: 1.9948392234822756

Epoch: 6| Step: 1
Training loss: 1.9543988704681396
Validation loss: 1.973143969812701

Epoch: 6| Step: 2
Training loss: 1.8880324363708496
Validation loss: 1.9743047580924085

Epoch: 6| Step: 3
Training loss: 1.913974404335022
Validation loss: 1.9731368044371247

Epoch: 6| Step: 4
Training loss: 1.4257997274398804
Validation loss: 1.9792012706879647

Epoch: 6| Step: 5
Training loss: 1.4762225151062012
Validation loss: 1.9681242678755073

Epoch: 6| Step: 6
Training loss: 1.4645485877990723
Validation loss: 1.974676388566212

Epoch: 6| Step: 7
Training loss: 0.9297803044319153
Validation loss: 1.99152930449414

Epoch: 6| Step: 8
Training loss: 1.5983293056488037
Validation loss: 1.990133946941745

Epoch: 6| Step: 9
Training loss: 1.562148928642273
Validation loss: 2.017430123462472

Epoch: 6| Step: 10
Training loss: 2.2996983528137207
Validation loss: 2.014589698083939

Epoch: 6| Step: 11
Training loss: 1.8723236322402954
Validation loss: 2.012792792371524

Epoch: 6| Step: 12
Training loss: 1.8718714714050293
Validation loss: 2.0290009667796474

Epoch: 6| Step: 13
Training loss: 1.7640056610107422
Validation loss: 2.0456908466995403

Epoch: 288| Step: 0
Training loss: 1.9555563926696777
Validation loss: 2.034600847510881

Epoch: 6| Step: 1
Training loss: 1.5960497856140137
Validation loss: 2.0632243681979436

Epoch: 6| Step: 2
Training loss: 2.1028356552124023
Validation loss: 2.0485484407794092

Epoch: 6| Step: 3
Training loss: 2.1313867568969727
Validation loss: 2.037042325542819

Epoch: 6| Step: 4
Training loss: 1.4170418977737427
Validation loss: 2.0294102699525896

Epoch: 6| Step: 5
Training loss: 1.3880964517593384
Validation loss: 2.001971420421395

Epoch: 6| Step: 6
Training loss: 1.6642060279846191
Validation loss: 1.9840528657359462

Epoch: 6| Step: 7
Training loss: 1.9019508361816406
Validation loss: 1.9893116053714548

Epoch: 6| Step: 8
Training loss: 1.8256640434265137
Validation loss: 1.9918298541858632

Epoch: 6| Step: 9
Training loss: 1.2876754999160767
Validation loss: 1.9799589239140993

Epoch: 6| Step: 10
Training loss: 2.209608554840088
Validation loss: 1.9836983860179942

Epoch: 6| Step: 11
Training loss: 1.2228798866271973
Validation loss: 1.973345011793157

Epoch: 6| Step: 12
Training loss: 1.2026093006134033
Validation loss: 1.9667006115759573

Epoch: 6| Step: 13
Training loss: 1.315511703491211
Validation loss: 2.0031023410058792

Epoch: 289| Step: 0
Training loss: 1.7668894529342651
Validation loss: 2.029588048176099

Epoch: 6| Step: 1
Training loss: 1.6101391315460205
Validation loss: 2.064115639655821

Epoch: 6| Step: 2
Training loss: 1.921440601348877
Validation loss: 2.0835363685443835

Epoch: 6| Step: 3
Training loss: 1.7917356491088867
Validation loss: 2.081535993083831

Epoch: 6| Step: 4
Training loss: 1.7536323070526123
Validation loss: 2.0698844412321686

Epoch: 6| Step: 5
Training loss: 1.5779649019241333
Validation loss: 2.070052889085585

Epoch: 6| Step: 6
Training loss: 2.0310025215148926
Validation loss: 2.071862374582598

Epoch: 6| Step: 7
Training loss: 1.7433006763458252
Validation loss: 2.06521846402076

Epoch: 6| Step: 8
Training loss: 1.451340913772583
Validation loss: 2.033141184878606

Epoch: 6| Step: 9
Training loss: 1.930374264717102
Validation loss: 2.0183635937270297

Epoch: 6| Step: 10
Training loss: 1.4043991565704346
Validation loss: 2.034996665934081

Epoch: 6| Step: 11
Training loss: 1.3843605518341064
Validation loss: 1.9918559020565403

Epoch: 6| Step: 12
Training loss: 1.583178997039795
Validation loss: 1.9897028041142288

Epoch: 6| Step: 13
Training loss: 1.16239595413208
Validation loss: 1.9666122390377907

Epoch: 290| Step: 0
Training loss: 1.1191530227661133
Validation loss: 1.9604997686160508

Epoch: 6| Step: 1
Training loss: 1.6575913429260254
Validation loss: 1.9758605828849218

Epoch: 6| Step: 2
Training loss: 1.922631859779358
Validation loss: 1.9757381613536547

Epoch: 6| Step: 3
Training loss: 2.2531485557556152
Validation loss: 2.0079269562998125

Epoch: 6| Step: 4
Training loss: 1.9970309734344482
Validation loss: 2.0013777261139243

Epoch: 6| Step: 5
Training loss: 1.272036075592041
Validation loss: 1.9908603852795017

Epoch: 6| Step: 6
Training loss: 1.7698484659194946
Validation loss: 2.0158475598981305

Epoch: 6| Step: 7
Training loss: 2.115501880645752
Validation loss: 2.0293792396463375

Epoch: 6| Step: 8
Training loss: 1.2808871269226074
Validation loss: 2.039423085028125

Epoch: 6| Step: 9
Training loss: 1.1898300647735596
Validation loss: 2.041275311541814

Epoch: 6| Step: 10
Training loss: 1.495815396308899
Validation loss: 2.0562192791251728

Epoch: 6| Step: 11
Training loss: 1.6936626434326172
Validation loss: 2.0605571833989953

Epoch: 6| Step: 12
Training loss: 1.7650268077850342
Validation loss: 2.07071324317686

Epoch: 6| Step: 13
Training loss: 1.7578011751174927
Validation loss: 2.083094681462934

Epoch: 291| Step: 0
Training loss: 1.5529109239578247
Validation loss: 2.0642430346499205

Epoch: 6| Step: 1
Training loss: 2.0259644985198975
Validation loss: 2.020704415536696

Epoch: 6| Step: 2
Training loss: 1.676020860671997
Validation loss: 2.0092085894717964

Epoch: 6| Step: 3
Training loss: 1.5752229690551758
Validation loss: 1.98222315695978

Epoch: 6| Step: 4
Training loss: 1.5233229398727417
Validation loss: 1.952389979875216

Epoch: 6| Step: 5
Training loss: 1.7004070281982422
Validation loss: 1.940801380782999

Epoch: 6| Step: 6
Training loss: 1.9186817407608032
Validation loss: 1.9460152259436987

Epoch: 6| Step: 7
Training loss: 1.7220377922058105
Validation loss: 1.9683467957281298

Epoch: 6| Step: 8
Training loss: 1.8366378545761108
Validation loss: 1.9676452349590998

Epoch: 6| Step: 9
Training loss: 1.9666093587875366
Validation loss: 2.0138819781682824

Epoch: 6| Step: 10
Training loss: 1.5992045402526855
Validation loss: 2.04168874730346

Epoch: 6| Step: 11
Training loss: 1.7392566204071045
Validation loss: 2.0448127613272717

Epoch: 6| Step: 12
Training loss: 1.0913364887237549
Validation loss: 2.0378918288856425

Epoch: 6| Step: 13
Training loss: 0.9196813106536865
Validation loss: 2.014927734610855

Epoch: 292| Step: 0
Training loss: 1.9763559103012085
Validation loss: 2.0213923172284196

Epoch: 6| Step: 1
Training loss: 1.7974048852920532
Validation loss: 2.0478224549242245

Epoch: 6| Step: 2
Training loss: 1.3074814081192017
Validation loss: 2.0682013752639934

Epoch: 6| Step: 3
Training loss: 1.1050496101379395
Validation loss: 2.077164101344283

Epoch: 6| Step: 4
Training loss: 2.451610565185547
Validation loss: 2.089317972942065

Epoch: 6| Step: 5
Training loss: 1.7479791641235352
Validation loss: 2.0840895406661497

Epoch: 6| Step: 6
Training loss: 1.942989706993103
Validation loss: 2.0747100999278407

Epoch: 6| Step: 7
Training loss: 1.8377618789672852
Validation loss: 2.0385531392148746

Epoch: 6| Step: 8
Training loss: 1.441065788269043
Validation loss: 2.03226218428663

Epoch: 6| Step: 9
Training loss: 1.339139461517334
Validation loss: 2.0200936102098033

Epoch: 6| Step: 10
Training loss: 2.0433616638183594
Validation loss: 2.0049938155758764

Epoch: 6| Step: 11
Training loss: 1.2659928798675537
Validation loss: 1.9980966852557274

Epoch: 6| Step: 12
Training loss: 1.3014116287231445
Validation loss: 1.9863875963354622

Epoch: 6| Step: 13
Training loss: 1.077609658241272
Validation loss: 1.9844085375467937

Epoch: 293| Step: 0
Training loss: 1.6035058498382568
Validation loss: 1.9673613322678434

Epoch: 6| Step: 1
Training loss: 1.3520948886871338
Validation loss: 1.9382294057517924

Epoch: 6| Step: 2
Training loss: 1.6020371913909912
Validation loss: 1.9484932320092314

Epoch: 6| Step: 3
Training loss: 2.234391689300537
Validation loss: 1.9563557601744128

Epoch: 6| Step: 4
Training loss: 1.8094946146011353
Validation loss: 1.963711900095786

Epoch: 6| Step: 5
Training loss: 0.9387511014938354
Validation loss: 1.9810328381035918

Epoch: 6| Step: 6
Training loss: 1.6866481304168701
Validation loss: 1.9939789028577908

Epoch: 6| Step: 7
Training loss: 1.7654708623886108
Validation loss: 2.0082449349023963

Epoch: 6| Step: 8
Training loss: 1.0883424282073975
Validation loss: 1.9988467167782527

Epoch: 6| Step: 9
Training loss: 1.4827433824539185
Validation loss: 2.0004863841559297

Epoch: 6| Step: 10
Training loss: 1.4474194049835205
Validation loss: 1.9872728727197135

Epoch: 6| Step: 11
Training loss: 1.7641630172729492
Validation loss: 1.9693621281654603

Epoch: 6| Step: 12
Training loss: 2.650080680847168
Validation loss: 1.9554640644340104

Epoch: 6| Step: 13
Training loss: 1.3588930368423462
Validation loss: 1.9782326631648566

Epoch: 294| Step: 0
Training loss: 2.267012357711792
Validation loss: 1.9804876107041554

Epoch: 6| Step: 1
Training loss: 1.5527749061584473
Validation loss: 1.9816760414390153

Epoch: 6| Step: 2
Training loss: 1.4366583824157715
Validation loss: 1.9964726983859975

Epoch: 6| Step: 3
Training loss: 1.6795313358306885
Validation loss: 2.0244341460607385

Epoch: 6| Step: 4
Training loss: 1.313333511352539
Validation loss: 2.0216236601593676

Epoch: 6| Step: 5
Training loss: 1.2815626859664917
Validation loss: 2.0231646747999292

Epoch: 6| Step: 6
Training loss: 1.4317132234573364
Validation loss: 2.0459101469286027

Epoch: 6| Step: 7
Training loss: 1.3756587505340576
Validation loss: 2.013190487379669

Epoch: 6| Step: 8
Training loss: 1.538973331451416
Validation loss: 1.998550791894236

Epoch: 6| Step: 9
Training loss: 1.6128681898117065
Validation loss: 1.9614729650558964

Epoch: 6| Step: 10
Training loss: 2.038348913192749
Validation loss: 1.964760503461284

Epoch: 6| Step: 11
Training loss: 1.7470402717590332
Validation loss: 1.98629548985471

Epoch: 6| Step: 12
Training loss: 2.1801652908325195
Validation loss: 2.0117454900536487

Epoch: 6| Step: 13
Training loss: 1.215478539466858
Validation loss: 1.9929566908908147

Epoch: 295| Step: 0
Training loss: 1.5613820552825928
Validation loss: 2.006182993611982

Epoch: 6| Step: 1
Training loss: 1.6977920532226562
Validation loss: 2.0021019674116567

Epoch: 6| Step: 2
Training loss: 0.8671880960464478
Validation loss: 2.0033044904790898

Epoch: 6| Step: 3
Training loss: 1.2135553359985352
Validation loss: 1.9936870759533298

Epoch: 6| Step: 4
Training loss: 2.096439838409424
Validation loss: 1.9875410910575622

Epoch: 6| Step: 5
Training loss: 1.5622881650924683
Validation loss: 1.9763310801598333

Epoch: 6| Step: 6
Training loss: 2.218740701675415
Validation loss: 1.9677061521878807

Epoch: 6| Step: 7
Training loss: 1.3769848346710205
Validation loss: 1.976885308501541

Epoch: 6| Step: 8
Training loss: 1.3428475856781006
Validation loss: 1.987048864364624

Epoch: 6| Step: 9
Training loss: 1.827627182006836
Validation loss: 1.9894223546469083

Epoch: 6| Step: 10
Training loss: 2.4239368438720703
Validation loss: 2.010242554449266

Epoch: 6| Step: 11
Training loss: 0.9576411247253418
Validation loss: 2.035308358489826

Epoch: 6| Step: 12
Training loss: 2.0865352153778076
Validation loss: 2.036531889310447

Epoch: 6| Step: 13
Training loss: 1.0418680906295776
Validation loss: 2.040184579869752

Epoch: 296| Step: 0
Training loss: 1.7987009286880493
Validation loss: 2.020173970089164

Epoch: 6| Step: 1
Training loss: 2.2575125694274902
Validation loss: 1.9988494957647016

Epoch: 6| Step: 2
Training loss: 1.4571447372436523
Validation loss: 1.9979584114525908

Epoch: 6| Step: 3
Training loss: 1.6774535179138184
Validation loss: 1.9909475772611556

Epoch: 6| Step: 4
Training loss: 1.86236572265625
Validation loss: 1.97122835856612

Epoch: 6| Step: 5
Training loss: 1.9305696487426758
Validation loss: 1.9660652811809252

Epoch: 6| Step: 6
Training loss: 1.1599271297454834
Validation loss: 1.9443467317088958

Epoch: 6| Step: 7
Training loss: 1.4478238821029663
Validation loss: 1.9459611369717507

Epoch: 6| Step: 8
Training loss: 1.1606725454330444
Validation loss: 1.9354730549679007

Epoch: 6| Step: 9
Training loss: 2.0995216369628906
Validation loss: 1.943887815680555

Epoch: 6| Step: 10
Training loss: 1.152430772781372
Validation loss: 1.979997460560132

Epoch: 6| Step: 11
Training loss: 1.4401108026504517
Validation loss: 2.009863486853979

Epoch: 6| Step: 12
Training loss: 1.5440813302993774
Validation loss: 2.003638767427014

Epoch: 6| Step: 13
Training loss: 1.8691058158874512
Validation loss: 2.0081396423360354

Epoch: 297| Step: 0
Training loss: 1.8930706977844238
Validation loss: 2.000572525044923

Epoch: 6| Step: 1
Training loss: 1.1706562042236328
Validation loss: 1.998367812043877

Epoch: 6| Step: 2
Training loss: 1.6157128810882568
Validation loss: 1.9970477524624075

Epoch: 6| Step: 3
Training loss: 1.0492582321166992
Validation loss: 2.020949504708731

Epoch: 6| Step: 4
Training loss: 1.8686460256576538
Validation loss: 2.034106557087232

Epoch: 6| Step: 5
Training loss: 1.6481714248657227
Validation loss: 2.0344784195705126

Epoch: 6| Step: 6
Training loss: 1.0895617008209229
Validation loss: 2.0412819385528564

Epoch: 6| Step: 7
Training loss: 1.703162431716919
Validation loss: 2.065693848876543

Epoch: 6| Step: 8
Training loss: 1.3460004329681396
Validation loss: 2.068059935364672

Epoch: 6| Step: 9
Training loss: 2.067615032196045
Validation loss: 2.0522277252648466

Epoch: 6| Step: 10
Training loss: 2.1449859142303467
Validation loss: 2.052621005683817

Epoch: 6| Step: 11
Training loss: 2.0403475761413574
Validation loss: 2.0229752230387863

Epoch: 6| Step: 12
Training loss: 1.0885227918624878
Validation loss: 2.021004788337215

Epoch: 6| Step: 13
Training loss: 1.6496639251708984
Validation loss: 2.029684741009948

Epoch: 298| Step: 0
Training loss: 1.9645729064941406
Validation loss: 2.0250369553924887

Epoch: 6| Step: 1
Training loss: 1.3855645656585693
Validation loss: 2.020436494581161

Epoch: 6| Step: 2
Training loss: 1.462191104888916
Validation loss: 2.0483507494772635

Epoch: 6| Step: 3
Training loss: 1.2748138904571533
Validation loss: 2.079000283313054

Epoch: 6| Step: 4
Training loss: 1.8184936046600342
Validation loss: 2.0702198679729173

Epoch: 6| Step: 5
Training loss: 1.7398757934570312
Validation loss: 2.058931125107632

Epoch: 6| Step: 6
Training loss: 1.4981557130813599
Validation loss: 2.0264843663861676

Epoch: 6| Step: 7
Training loss: 1.6434094905853271
Validation loss: 1.9832501693438458

Epoch: 6| Step: 8
Training loss: 1.6699795722961426
Validation loss: 1.9591099780092958

Epoch: 6| Step: 9
Training loss: 1.6043891906738281
Validation loss: 1.9385923121565132

Epoch: 6| Step: 10
Training loss: 1.8409645557403564
Validation loss: 1.9184816229727961

Epoch: 6| Step: 11
Training loss: 1.4208688735961914
Validation loss: 1.914363025337137

Epoch: 6| Step: 12
Training loss: 1.4394986629486084
Validation loss: 1.9205083821409492

Epoch: 6| Step: 13
Training loss: 1.002660870552063
Validation loss: 1.9200721017775997

Epoch: 299| Step: 0
Training loss: 1.8229739665985107
Validation loss: 1.9457550792283909

Epoch: 6| Step: 1
Training loss: 1.7359079122543335
Validation loss: 1.964998887431237

Epoch: 6| Step: 2
Training loss: 1.8856163024902344
Validation loss: 1.982445711730629

Epoch: 6| Step: 3
Training loss: 1.483325719833374
Validation loss: 2.007834957491967

Epoch: 6| Step: 4
Training loss: 1.7777891159057617
Validation loss: 2.049615724112398

Epoch: 6| Step: 5
Training loss: 1.4001481533050537
Validation loss: 2.045803346941548

Epoch: 6| Step: 6
Training loss: 1.8217413425445557
Validation loss: 2.0458852642325946

Epoch: 6| Step: 7
Training loss: 1.7569929361343384
Validation loss: 2.0393795838920017

Epoch: 6| Step: 8
Training loss: 1.7237522602081299
Validation loss: 2.049953124856436

Epoch: 6| Step: 9
Training loss: 1.2207772731781006
Validation loss: 2.031752468437277

Epoch: 6| Step: 10
Training loss: 1.8536183834075928
Validation loss: 2.0311546171865156

Epoch: 6| Step: 11
Training loss: 1.3356997966766357
Validation loss: 2.0304759612647434

Epoch: 6| Step: 12
Training loss: 0.9856400489807129
Validation loss: 1.9926377419502503

Epoch: 6| Step: 13
Training loss: 1.2261967658996582
Validation loss: 1.9881244782478578

Epoch: 300| Step: 0
Training loss: 1.8939216136932373
Validation loss: 1.9578343065836097

Epoch: 6| Step: 1
Training loss: 1.5945093631744385
Validation loss: 1.9539308599246445

Epoch: 6| Step: 2
Training loss: 1.917227864265442
Validation loss: 1.922359687025829

Epoch: 6| Step: 3
Training loss: 1.732893943786621
Validation loss: 1.93439132167447

Epoch: 6| Step: 4
Training loss: 1.3180067539215088
Validation loss: 1.9564899154888686

Epoch: 6| Step: 5
Training loss: 2.081031560897827
Validation loss: 1.9747103106591009

Epoch: 6| Step: 6
Training loss: 1.4530847072601318
Validation loss: 1.9917816474873533

Epoch: 6| Step: 7
Training loss: 1.268527865409851
Validation loss: 1.9895980435032998

Epoch: 6| Step: 8
Training loss: 1.2246079444885254
Validation loss: 1.9967756348271524

Epoch: 6| Step: 9
Training loss: 1.3939687013626099
Validation loss: 2.0094490871634534

Epoch: 6| Step: 10
Training loss: 2.2638378143310547
Validation loss: 2.013702154159546

Epoch: 6| Step: 11
Training loss: 1.5248394012451172
Validation loss: 2.027198924813219

Epoch: 6| Step: 12
Training loss: 1.2253005504608154
Validation loss: 2.0252378576545307

Epoch: 6| Step: 13
Training loss: 0.9678723812103271
Validation loss: 2.0384601162325953

Epoch: 301| Step: 0
Training loss: 1.6294399499893188
Validation loss: 2.030848859458841

Epoch: 6| Step: 1
Training loss: 1.4157898426055908
Validation loss: 2.040617066044961

Epoch: 6| Step: 2
Training loss: 1.1750671863555908
Validation loss: 2.0938481028361986

Epoch: 6| Step: 3
Training loss: 1.500254511833191
Validation loss: 2.0725930583092476

Epoch: 6| Step: 4
Training loss: 2.244541883468628
Validation loss: 2.094483273003691

Epoch: 6| Step: 5
Training loss: 1.6725778579711914
Validation loss: 2.0679584087864047

Epoch: 6| Step: 6
Training loss: 1.1735336780548096
Validation loss: 2.038846908077117

Epoch: 6| Step: 7
Training loss: 1.2840776443481445
Validation loss: 2.0476484208978634

Epoch: 6| Step: 8
Training loss: 1.6768968105316162
Validation loss: 2.011656863715059

Epoch: 6| Step: 9
Training loss: 1.5204386711120605
Validation loss: 2.0268823613402662

Epoch: 6| Step: 10
Training loss: 1.3661531209945679
Validation loss: 2.0230441093444824

Epoch: 6| Step: 11
Training loss: 1.9961342811584473
Validation loss: 1.9908485886871174

Epoch: 6| Step: 12
Training loss: 1.665417194366455
Validation loss: 1.9922757430743145

Epoch: 6| Step: 13
Training loss: 1.318852186203003
Validation loss: 1.9876897078688427

Epoch: 302| Step: 0
Training loss: 1.2168610095977783
Validation loss: 1.9272609090292325

Epoch: 6| Step: 1
Training loss: 2.321829319000244
Validation loss: 1.9151963815894177

Epoch: 6| Step: 2
Training loss: 1.2830636501312256
Validation loss: 1.9060479928088445

Epoch: 6| Step: 3
Training loss: 1.3020108938217163
Validation loss: 1.8809685758365098

Epoch: 6| Step: 4
Training loss: 1.543458342552185
Validation loss: 1.8968317418970086

Epoch: 6| Step: 5
Training loss: 1.6992850303649902
Validation loss: 1.9151850490159885

Epoch: 6| Step: 6
Training loss: 1.3423280715942383
Validation loss: 1.9387354735405213

Epoch: 6| Step: 7
Training loss: 1.1836811304092407
Validation loss: 1.9362336435625631

Epoch: 6| Step: 8
Training loss: 1.4488896131515503
Validation loss: 1.9440961166094708

Epoch: 6| Step: 9
Training loss: 1.1879746913909912
Validation loss: 1.964729247554656

Epoch: 6| Step: 10
Training loss: 1.4038984775543213
Validation loss: 1.9646520781260666

Epoch: 6| Step: 11
Training loss: 2.4066061973571777
Validation loss: 1.9939376461890437

Epoch: 6| Step: 12
Training loss: 1.6290682554244995
Validation loss: 1.980141644836754

Epoch: 6| Step: 13
Training loss: 1.9088186025619507
Validation loss: 2.009416890400712

Epoch: 303| Step: 0
Training loss: 1.3126178979873657
Validation loss: 2.042233968293795

Epoch: 6| Step: 1
Training loss: 1.8123444318771362
Validation loss: 2.066921650722463

Epoch: 6| Step: 2
Training loss: 1.520293951034546
Validation loss: 2.0883684183961604

Epoch: 6| Step: 3
Training loss: 1.9915145635604858
Validation loss: 2.0907426188069005

Epoch: 6| Step: 4
Training loss: 1.0863773822784424
Validation loss: 2.077172194757769

Epoch: 6| Step: 5
Training loss: 1.7369604110717773
Validation loss: 2.0674592743637743

Epoch: 6| Step: 6
Training loss: 1.625112771987915
Validation loss: 2.066111392872308

Epoch: 6| Step: 7
Training loss: 1.4617406129837036
Validation loss: 2.0433740500480897

Epoch: 6| Step: 8
Training loss: 1.0245170593261719
Validation loss: 2.009827845840044

Epoch: 6| Step: 9
Training loss: 1.3770513534545898
Validation loss: 2.0045180730922247

Epoch: 6| Step: 10
Training loss: 1.6903297901153564
Validation loss: 1.978296878517315

Epoch: 6| Step: 11
Training loss: 1.9055625200271606
Validation loss: 1.9844794299012871

Epoch: 6| Step: 12
Training loss: 1.364149808883667
Validation loss: 1.9431978707672448

Epoch: 6| Step: 13
Training loss: 1.8115378618240356
Validation loss: 1.9347236720464562

Epoch: 304| Step: 0
Training loss: 2.0335729122161865
Validation loss: 1.9174839706831082

Epoch: 6| Step: 1
Training loss: 1.909019947052002
Validation loss: 1.9214107605718798

Epoch: 6| Step: 2
Training loss: 1.2445156574249268
Validation loss: 1.913147316184095

Epoch: 6| Step: 3
Training loss: 1.4692010879516602
Validation loss: 1.9167919030753515

Epoch: 6| Step: 4
Training loss: 1.1095889806747437
Validation loss: 1.9434756489210232

Epoch: 6| Step: 5
Training loss: 2.1072988510131836
Validation loss: 1.9755447744041361

Epoch: 6| Step: 6
Training loss: 1.404788613319397
Validation loss: 2.0098949709246234

Epoch: 6| Step: 7
Training loss: 1.805107831954956
Validation loss: 2.0302597758590535

Epoch: 6| Step: 8
Training loss: 1.802687644958496
Validation loss: 2.0543806373432116

Epoch: 6| Step: 9
Training loss: 1.3224960565567017
Validation loss: 2.060912952628187

Epoch: 6| Step: 10
Training loss: 1.3515876531600952
Validation loss: 2.0517394029965965

Epoch: 6| Step: 11
Training loss: 1.4409198760986328
Validation loss: 2.0608181722702517

Epoch: 6| Step: 12
Training loss: 1.2659785747528076
Validation loss: 2.065297193424676

Epoch: 6| Step: 13
Training loss: 0.8874059915542603
Validation loss: 2.0376601808814594

Epoch: 305| Step: 0
Training loss: 1.604507327079773
Validation loss: 2.066093311514906

Epoch: 6| Step: 1
Training loss: 2.084456443786621
Validation loss: 2.079001618969825

Epoch: 6| Step: 2
Training loss: 1.8477988243103027
Validation loss: 2.0825648641073577

Epoch: 6| Step: 3
Training loss: 1.0411231517791748
Validation loss: 2.0911668077591927

Epoch: 6| Step: 4
Training loss: 1.2203060388565063
Validation loss: 2.098005256345195

Epoch: 6| Step: 5
Training loss: 1.0810482501983643
Validation loss: 2.106900066457769

Epoch: 6| Step: 6
Training loss: 2.115983009338379
Validation loss: 2.1228497361624115

Epoch: 6| Step: 7
Training loss: 1.8474864959716797
Validation loss: 2.086336753701651

Epoch: 6| Step: 8
Training loss: 1.5960606336593628
Validation loss: 2.04994737332867

Epoch: 6| Step: 9
Training loss: 0.9823423624038696
Validation loss: 2.0326564363254014

Epoch: 6| Step: 10
Training loss: 1.7228385210037231
Validation loss: 2.0065447053601666

Epoch: 6| Step: 11
Training loss: 1.4653737545013428
Validation loss: 1.982308526192942

Epoch: 6| Step: 12
Training loss: 0.9498591423034668
Validation loss: 1.9530319334358297

Epoch: 6| Step: 13
Training loss: 1.529676914215088
Validation loss: 1.9226988746273903

Epoch: 306| Step: 0
Training loss: 1.0680782794952393
Validation loss: 1.891009549940786

Epoch: 6| Step: 1
Training loss: 1.286775827407837
Validation loss: 1.8831875285794657

Epoch: 6| Step: 2
Training loss: 1.4717226028442383
Validation loss: 1.8880325671165221

Epoch: 6| Step: 3
Training loss: 1.971835732460022
Validation loss: 1.9012392041503743

Epoch: 6| Step: 4
Training loss: 2.0423543453216553
Validation loss: 1.9295081964103125

Epoch: 6| Step: 5
Training loss: 0.8784893751144409
Validation loss: 1.9303835579144057

Epoch: 6| Step: 6
Training loss: 1.1491855382919312
Validation loss: 1.9452356805083573

Epoch: 6| Step: 7
Training loss: 2.1780314445495605
Validation loss: 1.9415050616828344

Epoch: 6| Step: 8
Training loss: 2.4219202995300293
Validation loss: 1.9676018145776564

Epoch: 6| Step: 9
Training loss: 1.600543737411499
Validation loss: 1.9819075727975497

Epoch: 6| Step: 10
Training loss: 1.025292158126831
Validation loss: 2.025775965823922

Epoch: 6| Step: 11
Training loss: 1.1912977695465088
Validation loss: 2.0259983526763095

Epoch: 6| Step: 12
Training loss: 1.5111582279205322
Validation loss: 2.0509279145989368

Epoch: 6| Step: 13
Training loss: 1.6960701942443848
Validation loss: 2.0451203866671492

Epoch: 307| Step: 0
Training loss: 1.5593512058258057
Validation loss: 2.0245615692548853

Epoch: 6| Step: 1
Training loss: 1.139075756072998
Validation loss: 1.9831955984074583

Epoch: 6| Step: 2
Training loss: 1.317094087600708
Validation loss: 2.0165176237783125

Epoch: 6| Step: 3
Training loss: 1.8250679969787598
Validation loss: 2.0061375274453113

Epoch: 6| Step: 4
Training loss: 1.3198859691619873
Validation loss: 2.0075576472026047

Epoch: 6| Step: 5
Training loss: 1.3192331790924072
Validation loss: 2.0028292620053856

Epoch: 6| Step: 6
Training loss: 1.5815314054489136
Validation loss: 1.996242884666689

Epoch: 6| Step: 7
Training loss: 1.237919807434082
Validation loss: 1.9828145016906082

Epoch: 6| Step: 8
Training loss: 1.3827500343322754
Validation loss: 1.993167616987741

Epoch: 6| Step: 9
Training loss: 1.8914432525634766
Validation loss: 2.0223482552395073

Epoch: 6| Step: 10
Training loss: 2.468376874923706
Validation loss: 1.998292141063239

Epoch: 6| Step: 11
Training loss: 0.8547112345695496
Validation loss: 2.016592574375932

Epoch: 6| Step: 12
Training loss: 1.9123127460479736
Validation loss: 1.9905187532465944

Epoch: 6| Step: 13
Training loss: 1.1308422088623047
Validation loss: 1.95406654701438

Epoch: 308| Step: 0
Training loss: 1.7244648933410645
Validation loss: 1.9502080614848802

Epoch: 6| Step: 1
Training loss: 1.727408766746521
Validation loss: 1.9352568375167025

Epoch: 6| Step: 2
Training loss: 1.5091607570648193
Validation loss: 1.9387008592646608

Epoch: 6| Step: 3
Training loss: 1.8030163049697876
Validation loss: 1.9192041632949666

Epoch: 6| Step: 4
Training loss: 0.9870378971099854
Validation loss: 1.9075651463641916

Epoch: 6| Step: 5
Training loss: 1.4818782806396484
Validation loss: 1.9484558118286954

Epoch: 6| Step: 6
Training loss: 1.586470365524292
Validation loss: 1.9490735453944052

Epoch: 6| Step: 7
Training loss: 1.6812050342559814
Validation loss: 1.945804097319162

Epoch: 6| Step: 8
Training loss: 1.3631877899169922
Validation loss: 1.9542342578211138

Epoch: 6| Step: 9
Training loss: 1.3810001611709595
Validation loss: 1.9838900976283576

Epoch: 6| Step: 10
Training loss: 1.110344648361206
Validation loss: 2.0289383793389923

Epoch: 6| Step: 11
Training loss: 1.553797960281372
Validation loss: 2.0465037604813934

Epoch: 6| Step: 12
Training loss: 1.8466567993164062
Validation loss: 2.091028371164876

Epoch: 6| Step: 13
Training loss: 1.3721815347671509
Validation loss: 2.1245838903611705

Epoch: 309| Step: 0
Training loss: 2.007510185241699
Validation loss: 2.1311632728063934

Epoch: 6| Step: 1
Training loss: 1.3122003078460693
Validation loss: 2.095074640807285

Epoch: 6| Step: 2
Training loss: 1.5380163192749023
Validation loss: 2.031768798828125

Epoch: 6| Step: 3
Training loss: 1.662164568901062
Validation loss: 1.9980575781996532

Epoch: 6| Step: 4
Training loss: 1.647933006286621
Validation loss: 1.988911521050238

Epoch: 6| Step: 5
Training loss: 1.4403855800628662
Validation loss: 1.95909381810055

Epoch: 6| Step: 6
Training loss: 1.6579208374023438
Validation loss: 1.9435882132540467

Epoch: 6| Step: 7
Training loss: 1.6170148849487305
Validation loss: 1.925440639577886

Epoch: 6| Step: 8
Training loss: 1.431169033050537
Validation loss: 1.9041539866437194

Epoch: 6| Step: 9
Training loss: 1.2168585062026978
Validation loss: 1.8958642867303663

Epoch: 6| Step: 10
Training loss: 1.4062005281448364
Validation loss: 1.9006409991172053

Epoch: 6| Step: 11
Training loss: 0.9864541888237
Validation loss: 1.903862202039329

Epoch: 6| Step: 12
Training loss: 1.1555339097976685
Validation loss: 1.925379830022012

Epoch: 6| Step: 13
Training loss: 2.7499258518218994
Validation loss: 1.9362237812370382

Epoch: 310| Step: 0
Training loss: 1.5005652904510498
Validation loss: 1.9575102982982513

Epoch: 6| Step: 1
Training loss: 1.1152677536010742
Validation loss: 1.9874752413841985

Epoch: 6| Step: 2
Training loss: 1.7641098499298096
Validation loss: 2.0460561398536927

Epoch: 6| Step: 3
Training loss: 1.7522274255752563
Validation loss: 2.098140880625735

Epoch: 6| Step: 4
Training loss: 1.3238551616668701
Validation loss: 2.1436054347663798

Epoch: 6| Step: 5
Training loss: 2.091754198074341
Validation loss: 2.1621907757174585

Epoch: 6| Step: 6
Training loss: 1.3664978742599487
Validation loss: 2.151814260790425

Epoch: 6| Step: 7
Training loss: 1.3645412921905518
Validation loss: 2.110735777885683

Epoch: 6| Step: 8
Training loss: 1.2492462396621704
Validation loss: 2.0955820006708943

Epoch: 6| Step: 9
Training loss: 1.3628170490264893
Validation loss: 2.0577797146253687

Epoch: 6| Step: 10
Training loss: 2.0053696632385254
Validation loss: 1.9987568201557282

Epoch: 6| Step: 11
Training loss: 1.0262919664382935
Validation loss: 1.9542120502841087

Epoch: 6| Step: 12
Training loss: 1.9275280237197876
Validation loss: 1.9505946174744637

Epoch: 6| Step: 13
Training loss: 1.8494248390197754
Validation loss: 1.9320920539158646

Epoch: 311| Step: 0
Training loss: 2.191729784011841
Validation loss: 1.9246005165961482

Epoch: 6| Step: 1
Training loss: 1.3051973581314087
Validation loss: 1.9346300632722917

Epoch: 6| Step: 2
Training loss: 1.529525637626648
Validation loss: 1.951049094559044

Epoch: 6| Step: 3
Training loss: 1.8268308639526367
Validation loss: 1.9190751916618758

Epoch: 6| Step: 4
Training loss: 1.033290982246399
Validation loss: 1.9014144892333655

Epoch: 6| Step: 5
Training loss: 1.7124730348587036
Validation loss: 1.91415984143493

Epoch: 6| Step: 6
Training loss: 1.600029706954956
Validation loss: 1.897029043525778

Epoch: 6| Step: 7
Training loss: 1.6021674871444702
Validation loss: 1.9314659821089877

Epoch: 6| Step: 8
Training loss: 1.2396167516708374
Validation loss: 1.9634521494629562

Epoch: 6| Step: 9
Training loss: 1.6150763034820557
Validation loss: 1.9700102088271931

Epoch: 6| Step: 10
Training loss: 1.41241455078125
Validation loss: 1.9835953994463849

Epoch: 6| Step: 11
Training loss: 1.0646021366119385
Validation loss: 2.0162296359257033

Epoch: 6| Step: 12
Training loss: 1.6478614807128906
Validation loss: 2.011298579554404

Epoch: 6| Step: 13
Training loss: 1.828499674797058
Validation loss: 2.0081115179164435

Epoch: 312| Step: 0
Training loss: 0.9512056112289429
Validation loss: 2.0216404250873032

Epoch: 6| Step: 1
Training loss: 1.6915957927703857
Validation loss: 1.9814004449434177

Epoch: 6| Step: 2
Training loss: 1.8246355056762695
Validation loss: 1.9602028567303893

Epoch: 6| Step: 3
Training loss: 1.8656773567199707
Validation loss: 1.9260908762613933

Epoch: 6| Step: 4
Training loss: 1.1859310865402222
Validation loss: 1.9188242496982697

Epoch: 6| Step: 5
Training loss: 1.5233583450317383
Validation loss: 1.931497553343414

Epoch: 6| Step: 6
Training loss: 1.7167010307312012
Validation loss: 1.9503639462173625

Epoch: 6| Step: 7
Training loss: 1.899503469467163
Validation loss: 1.9514489994254163

Epoch: 6| Step: 8
Training loss: 1.882989525794983
Validation loss: 1.9708446841086111

Epoch: 6| Step: 9
Training loss: 1.584407091140747
Validation loss: 1.9801490191490418

Epoch: 6| Step: 10
Training loss: 1.4078468084335327
Validation loss: 1.991466792680884

Epoch: 6| Step: 11
Training loss: 1.3171592950820923
Validation loss: 2.0000004704280565

Epoch: 6| Step: 12
Training loss: 0.7891966700553894
Validation loss: 2.024807637737643

Epoch: 6| Step: 13
Training loss: 0.8331291675567627
Validation loss: 2.0327164870436474

Epoch: 313| Step: 0
Training loss: 1.2187976837158203
Validation loss: 2.0326242216171755

Epoch: 6| Step: 1
Training loss: 1.2195249795913696
Validation loss: 2.052000791795792

Epoch: 6| Step: 2
Training loss: 1.484410047531128
Validation loss: 2.07145348928308

Epoch: 6| Step: 3
Training loss: 1.2956626415252686
Validation loss: 2.0323333701779767

Epoch: 6| Step: 4
Training loss: 1.2501802444458008
Validation loss: 2.020517086469999

Epoch: 6| Step: 5
Training loss: 1.2309943437576294
Validation loss: 2.0004245132528324

Epoch: 6| Step: 6
Training loss: 1.9879369735717773
Validation loss: 1.9528811106117823

Epoch: 6| Step: 7
Training loss: 1.3100769519805908
Validation loss: 1.9269340820209955

Epoch: 6| Step: 8
Training loss: 1.831505298614502
Validation loss: 1.916967071512694

Epoch: 6| Step: 9
Training loss: 1.2468931674957275
Validation loss: 1.925446589787801

Epoch: 6| Step: 10
Training loss: 1.3007488250732422
Validation loss: 1.9102970964165145

Epoch: 6| Step: 11
Training loss: 1.606792688369751
Validation loss: 1.9224868141194826

Epoch: 6| Step: 12
Training loss: 1.6611989736557007
Validation loss: 1.9396014803199357

Epoch: 6| Step: 13
Training loss: 1.9348106384277344
Validation loss: 1.9349853710461689

Epoch: 314| Step: 0
Training loss: 1.7124203443527222
Validation loss: 1.9437167118954402

Epoch: 6| Step: 1
Training loss: 1.336390495300293
Validation loss: 1.9622523387273152

Epoch: 6| Step: 2
Training loss: 2.0134050846099854
Validation loss: 1.9552720951777633

Epoch: 6| Step: 3
Training loss: 1.5412195920944214
Validation loss: 1.9555072745969218

Epoch: 6| Step: 4
Training loss: 1.4300320148468018
Validation loss: 1.9490275229177167

Epoch: 6| Step: 5
Training loss: 1.805855393409729
Validation loss: 1.9492431776497954

Epoch: 6| Step: 6
Training loss: 1.249990463256836
Validation loss: 1.9609341493216894

Epoch: 6| Step: 7
Training loss: 1.06327223777771
Validation loss: 1.9678016772834204

Epoch: 6| Step: 8
Training loss: 0.8487919569015503
Validation loss: 1.9931052577111028

Epoch: 6| Step: 9
Training loss: 1.0369539260864258
Validation loss: 2.008677631296137

Epoch: 6| Step: 10
Training loss: 1.7362666130065918
Validation loss: 2.034183709852157

Epoch: 6| Step: 11
Training loss: 1.4273343086242676
Validation loss: 2.019974285556424

Epoch: 6| Step: 12
Training loss: 1.6150233745574951
Validation loss: 2.0422599674553

Epoch: 6| Step: 13
Training loss: 1.3485639095306396
Validation loss: 2.0433189304926063

Epoch: 315| Step: 0
Training loss: 1.3064944744110107
Validation loss: 2.020698819109189

Epoch: 6| Step: 1
Training loss: 0.9359666109085083
Validation loss: 2.008083802397533

Epoch: 6| Step: 2
Training loss: 1.5686004161834717
Validation loss: 2.0130082881578835

Epoch: 6| Step: 3
Training loss: 1.480236291885376
Validation loss: 1.9832777861625916

Epoch: 6| Step: 4
Training loss: 1.4467394351959229
Validation loss: 1.9697302823425622

Epoch: 6| Step: 5
Training loss: 1.2606431245803833
Validation loss: 1.9490945954476633

Epoch: 6| Step: 6
Training loss: 1.700652837753296
Validation loss: 1.940028400831325

Epoch: 6| Step: 7
Training loss: 1.8694911003112793
Validation loss: 1.9548352328679894

Epoch: 6| Step: 8
Training loss: 1.5427864789962769
Validation loss: 1.9803217880187496

Epoch: 6| Step: 9
Training loss: 1.5977249145507812
Validation loss: 1.9472322951080978

Epoch: 6| Step: 10
Training loss: 1.3871185779571533
Validation loss: 1.9787602629712833

Epoch: 6| Step: 11
Training loss: 1.554641604423523
Validation loss: 1.982679231192476

Epoch: 6| Step: 12
Training loss: 1.2000043392181396
Validation loss: 2.0072931704982633

Epoch: 6| Step: 13
Training loss: 0.8710747361183167
Validation loss: 1.9844318743674987

Epoch: 316| Step: 0
Training loss: 1.099496841430664
Validation loss: 1.9962356385364328

Epoch: 6| Step: 1
Training loss: 1.2725918292999268
Validation loss: 1.992771512718611

Epoch: 6| Step: 2
Training loss: 1.6319489479064941
Validation loss: 2.001764584613103

Epoch: 6| Step: 3
Training loss: 1.1501089334487915
Validation loss: 2.012653048320483

Epoch: 6| Step: 4
Training loss: 1.4101059436798096
Validation loss: 2.051111126458773

Epoch: 6| Step: 5
Training loss: 1.5101838111877441
Validation loss: 2.0601690635886243

Epoch: 6| Step: 6
Training loss: 1.9105443954467773
Validation loss: 2.014864416532619

Epoch: 6| Step: 7
Training loss: 1.9452917575836182
Validation loss: 1.992648386186169

Epoch: 6| Step: 8
Training loss: 0.7828830480575562
Validation loss: 1.9823621806278025

Epoch: 6| Step: 9
Training loss: 2.1686670780181885
Validation loss: 1.958343812214431

Epoch: 6| Step: 10
Training loss: 1.3973480463027954
Validation loss: 1.9324487627193492

Epoch: 6| Step: 11
Training loss: 1.601628303527832
Validation loss: 1.9266469773425852

Epoch: 6| Step: 12
Training loss: 1.1082314252853394
Validation loss: 1.9394124348958333

Epoch: 6| Step: 13
Training loss: 0.725084125995636
Validation loss: 1.9160901269605082

Epoch: 317| Step: 0
Training loss: 1.2232582569122314
Validation loss: 1.9257856158800022

Epoch: 6| Step: 1
Training loss: 1.3586622476577759
Validation loss: 1.9313781543444561

Epoch: 6| Step: 2
Training loss: 1.2466646432876587
Validation loss: 1.9274992609536776

Epoch: 6| Step: 3
Training loss: 1.8802251815795898
Validation loss: 1.9380695384035829

Epoch: 6| Step: 4
Training loss: 1.5905060768127441
Validation loss: 1.9317359488497499

Epoch: 6| Step: 5
Training loss: 1.6688951253890991
Validation loss: 1.9553219246607956

Epoch: 6| Step: 6
Training loss: 1.5187838077545166
Validation loss: 1.948402989295221

Epoch: 6| Step: 7
Training loss: 1.7523871660232544
Validation loss: 1.944413810647944

Epoch: 6| Step: 8
Training loss: 1.6621360778808594
Validation loss: 1.9576736547613656

Epoch: 6| Step: 9
Training loss: 0.9134411811828613
Validation loss: 1.9519435180130826

Epoch: 6| Step: 10
Training loss: 1.7720623016357422
Validation loss: 1.978310554258285

Epoch: 6| Step: 11
Training loss: 1.0579112768173218
Validation loss: 1.9882298349052347

Epoch: 6| Step: 12
Training loss: 0.8932600617408752
Validation loss: 2.0125660204118296

Epoch: 6| Step: 13
Training loss: 1.416799545288086
Validation loss: 2.0118270407440844

Epoch: 318| Step: 0
Training loss: 1.4650689363479614
Validation loss: 2.010894779236086

Epoch: 6| Step: 1
Training loss: 1.6441519260406494
Validation loss: 2.045633354494649

Epoch: 6| Step: 2
Training loss: 1.139035701751709
Validation loss: 1.9905753699682092

Epoch: 6| Step: 3
Training loss: 0.9347097873687744
Validation loss: 2.02073533304276

Epoch: 6| Step: 4
Training loss: 1.3309814929962158
Validation loss: 1.987868724330779

Epoch: 6| Step: 5
Training loss: 1.0086711645126343
Validation loss: 1.942546768855023

Epoch: 6| Step: 6
Training loss: 1.6826238632202148
Validation loss: 1.9306370276276783

Epoch: 6| Step: 7
Training loss: 0.9821314215660095
Validation loss: 1.9010197193391862

Epoch: 6| Step: 8
Training loss: 1.663670539855957
Validation loss: 1.8723413854516961

Epoch: 6| Step: 9
Training loss: 1.5055243968963623
Validation loss: 1.896726062220912

Epoch: 6| Step: 10
Training loss: 1.1362162828445435
Validation loss: 1.8849796120838453

Epoch: 6| Step: 11
Training loss: 2.057004928588867
Validation loss: 1.8963707172742454

Epoch: 6| Step: 12
Training loss: 1.8962604999542236
Validation loss: 1.921101075346752

Epoch: 6| Step: 13
Training loss: 1.4976242780685425
Validation loss: 1.9274111358068322

Epoch: 319| Step: 0
Training loss: 1.130906581878662
Validation loss: 1.935231360056067

Epoch: 6| Step: 1
Training loss: 1.5209373235702515
Validation loss: 1.9242051186100129

Epoch: 6| Step: 2
Training loss: 0.842464804649353
Validation loss: 1.9080286961729809

Epoch: 6| Step: 3
Training loss: 0.8648604154586792
Validation loss: 1.9114807151979016

Epoch: 6| Step: 4
Training loss: 2.069937229156494
Validation loss: 1.930418396508822

Epoch: 6| Step: 5
Training loss: 0.9702872037887573
Validation loss: 1.9317871165531937

Epoch: 6| Step: 6
Training loss: 1.326902985572815
Validation loss: 1.964306067394954

Epoch: 6| Step: 7
Training loss: 1.5625152587890625
Validation loss: 1.981290073804958

Epoch: 6| Step: 8
Training loss: 1.6607203483581543
Validation loss: 2.0055519906423425

Epoch: 6| Step: 9
Training loss: 1.691157579421997
Validation loss: 2.005483268409647

Epoch: 6| Step: 10
Training loss: 1.7608323097229004
Validation loss: 2.050595942363944

Epoch: 6| Step: 11
Training loss: 1.5537855625152588
Validation loss: 2.042995440062656

Epoch: 6| Step: 12
Training loss: 1.792178750038147
Validation loss: 2.0187482808225896

Epoch: 6| Step: 13
Training loss: 1.0245070457458496
Validation loss: 1.9921820304727043

Epoch: 320| Step: 0
Training loss: 0.7652311325073242
Validation loss: 1.9829196763294998

Epoch: 6| Step: 1
Training loss: 1.2377955913543701
Validation loss: 1.9521720217120262

Epoch: 6| Step: 2
Training loss: 1.297654390335083
Validation loss: 1.939014660414829

Epoch: 6| Step: 3
Training loss: 1.5173015594482422
Validation loss: 1.9261820034314228

Epoch: 6| Step: 4
Training loss: 1.7917383909225464
Validation loss: 1.932362219338776

Epoch: 6| Step: 5
Training loss: 1.2229671478271484
Validation loss: 1.9277398150454286

Epoch: 6| Step: 6
Training loss: 0.966136634349823
Validation loss: 1.9276055738490114

Epoch: 6| Step: 7
Training loss: 1.8775373697280884
Validation loss: 1.965389492691204

Epoch: 6| Step: 8
Training loss: 1.1485075950622559
Validation loss: 1.972788905584684

Epoch: 6| Step: 9
Training loss: 1.7522608041763306
Validation loss: 2.0128896672238588

Epoch: 6| Step: 10
Training loss: 1.8754009008407593
Validation loss: 1.982090985903176

Epoch: 6| Step: 11
Training loss: 1.2758536338806152
Validation loss: 2.0154873760797645

Epoch: 6| Step: 12
Training loss: 1.4222397804260254
Validation loss: 2.0047113408324537

Epoch: 6| Step: 13
Training loss: 1.1914076805114746
Validation loss: 1.9833191748588317

Epoch: 321| Step: 0
Training loss: 1.1745375394821167
Validation loss: 1.9759037392113799

Epoch: 6| Step: 1
Training loss: 1.5597689151763916
Validation loss: 2.0284203073029876

Epoch: 6| Step: 2
Training loss: 1.3223586082458496
Validation loss: 2.098807329772621

Epoch: 6| Step: 3
Training loss: 1.697645902633667
Validation loss: 2.0877492017643426

Epoch: 6| Step: 4
Training loss: 1.35469651222229
Validation loss: 2.053233782450358

Epoch: 6| Step: 5
Training loss: 2.1019349098205566
Validation loss: 2.0076146843612834

Epoch: 6| Step: 6
Training loss: 1.7232959270477295
Validation loss: 1.9919999453329271

Epoch: 6| Step: 7
Training loss: 0.844474732875824
Validation loss: 2.005984583208638

Epoch: 6| Step: 8
Training loss: 1.0491533279418945
Validation loss: 1.9932210086494364

Epoch: 6| Step: 9
Training loss: 1.5822209119796753
Validation loss: 1.9733155376167708

Epoch: 6| Step: 10
Training loss: 1.224614143371582
Validation loss: 1.9788946003042243

Epoch: 6| Step: 11
Training loss: 1.6381793022155762
Validation loss: 1.955438583127914

Epoch: 6| Step: 12
Training loss: 1.181736946105957
Validation loss: 1.920804342915935

Epoch: 6| Step: 13
Training loss: 1.4594563245773315
Validation loss: 1.9198647622139222

Epoch: 322| Step: 0
Training loss: 1.479766607284546
Validation loss: 1.8885223827054423

Epoch: 6| Step: 1
Training loss: 1.3381340503692627
Validation loss: 1.8868854398368506

Epoch: 6| Step: 2
Training loss: 1.036963939666748
Validation loss: 1.8837954792925107

Epoch: 6| Step: 3
Training loss: 1.577420711517334
Validation loss: 1.87931009902749

Epoch: 6| Step: 4
Training loss: 1.5931119918823242
Validation loss: 1.9180079813926452

Epoch: 6| Step: 5
Training loss: 0.8925560712814331
Validation loss: 1.9299571873039327

Epoch: 6| Step: 6
Training loss: 1.5796761512756348
Validation loss: 1.9507726007892239

Epoch: 6| Step: 7
Training loss: 1.711622953414917
Validation loss: 1.9536187571863974

Epoch: 6| Step: 8
Training loss: 1.8979977369308472
Validation loss: 1.9291834908147012

Epoch: 6| Step: 9
Training loss: 1.1680090427398682
Validation loss: 1.9575331839182044

Epoch: 6| Step: 10
Training loss: 0.9481586813926697
Validation loss: 1.9645720399836057

Epoch: 6| Step: 11
Training loss: 1.7719560861587524
Validation loss: 1.9573541059288928

Epoch: 6| Step: 12
Training loss: 1.3769469261169434
Validation loss: 1.9969081545388827

Epoch: 6| Step: 13
Training loss: 1.3373701572418213
Validation loss: 2.0123174126430223

Epoch: 323| Step: 0
Training loss: 1.5045509338378906
Validation loss: 2.016206446514335

Epoch: 6| Step: 1
Training loss: 1.159421443939209
Validation loss: 1.9987562189819992

Epoch: 6| Step: 2
Training loss: 0.8999835252761841
Validation loss: 2.0357398140814995

Epoch: 6| Step: 3
Training loss: 1.3021790981292725
Validation loss: 2.0316932560295187

Epoch: 6| Step: 4
Training loss: 1.164109706878662
Validation loss: 2.023207164579822

Epoch: 6| Step: 5
Training loss: 1.6669455766677856
Validation loss: 2.029333104369461

Epoch: 6| Step: 6
Training loss: 1.1696569919586182
Validation loss: 2.009604207931026

Epoch: 6| Step: 7
Training loss: 1.1459602117538452
Validation loss: 2.0242663737266295

Epoch: 6| Step: 8
Training loss: 1.7382245063781738
Validation loss: 1.9970976332182526

Epoch: 6| Step: 9
Training loss: 1.0344055891036987
Validation loss: 1.9696362172403643

Epoch: 6| Step: 10
Training loss: 1.4542992115020752
Validation loss: 1.9528546294858378

Epoch: 6| Step: 11
Training loss: 1.439694881439209
Validation loss: 1.9140539015493085

Epoch: 6| Step: 12
Training loss: 1.9640092849731445
Validation loss: 1.9059668087190198

Epoch: 6| Step: 13
Training loss: 1.1731752157211304
Validation loss: 1.9072435568737727

Epoch: 324| Step: 0
Training loss: 1.5798137187957764
Validation loss: 1.8968334928635628

Epoch: 6| Step: 1
Training loss: 1.9066518545150757
Validation loss: 1.8784149295540267

Epoch: 6| Step: 2
Training loss: 1.0620667934417725
Validation loss: 1.8966605714572373

Epoch: 6| Step: 3
Training loss: 1.6244497299194336
Validation loss: 1.923822251699304

Epoch: 6| Step: 4
Training loss: 1.49299955368042
Validation loss: 1.9657272446540095

Epoch: 6| Step: 5
Training loss: 1.0005548000335693
Validation loss: 2.021228358309756

Epoch: 6| Step: 6
Training loss: 1.2960705757141113
Validation loss: 2.049944721242433

Epoch: 6| Step: 7
Training loss: 0.9156267642974854
Validation loss: 2.035834786712482

Epoch: 6| Step: 8
Training loss: 1.7925801277160645
Validation loss: 2.0264621216763734

Epoch: 6| Step: 9
Training loss: 1.0326577425003052
Validation loss: 2.0003368880159114

Epoch: 6| Step: 10
Training loss: 1.0617449283599854
Validation loss: 1.9552652553845478

Epoch: 6| Step: 11
Training loss: 1.4723237752914429
Validation loss: 1.9375296369675667

Epoch: 6| Step: 12
Training loss: 1.1706953048706055
Validation loss: 1.9144193280127741

Epoch: 6| Step: 13
Training loss: 2.0319759845733643
Validation loss: 1.8988451842338807

Epoch: 325| Step: 0
Training loss: 1.4289469718933105
Validation loss: 1.919134114378242

Epoch: 6| Step: 1
Training loss: 1.1131415367126465
Validation loss: 1.9043398762261996

Epoch: 6| Step: 2
Training loss: 1.127411961555481
Validation loss: 1.9172060925473449

Epoch: 6| Step: 3
Training loss: 1.7841639518737793
Validation loss: 1.9118901657801803

Epoch: 6| Step: 4
Training loss: 1.2050222158432007
Validation loss: 1.9427958124427385

Epoch: 6| Step: 5
Training loss: 1.0453451871871948
Validation loss: 1.95547592255377

Epoch: 6| Step: 6
Training loss: 1.2906322479248047
Validation loss: 2.0127398954924716

Epoch: 6| Step: 7
Training loss: 1.166994333267212
Validation loss: 2.051201776791644

Epoch: 6| Step: 8
Training loss: 2.092398166656494
Validation loss: 2.0677691762165358

Epoch: 6| Step: 9
Training loss: 1.425965428352356
Validation loss: 2.058526446742396

Epoch: 6| Step: 10
Training loss: 1.4116487503051758
Validation loss: 2.021173918119041

Epoch: 6| Step: 11
Training loss: 1.3694329261779785
Validation loss: 1.9713345740431099

Epoch: 6| Step: 12
Training loss: 1.2446043491363525
Validation loss: 1.9211558616289528

Epoch: 6| Step: 13
Training loss: 1.7687593698501587
Validation loss: 1.9036307463081934

Epoch: 326| Step: 0
Training loss: 1.2953109741210938
Validation loss: 1.893881138934884

Epoch: 6| Step: 1
Training loss: 1.738184928894043
Validation loss: 1.9171572603205198

Epoch: 6| Step: 2
Training loss: 1.1757919788360596
Validation loss: 1.8975253284618419

Epoch: 6| Step: 3
Training loss: 1.183469295501709
Validation loss: 1.9244725986193585

Epoch: 6| Step: 4
Training loss: 1.5289348363876343
Validation loss: 1.9598836437348397

Epoch: 6| Step: 5
Training loss: 1.385793924331665
Validation loss: 2.018147176311862

Epoch: 6| Step: 6
Training loss: 1.7892940044403076
Validation loss: 2.054200715916131

Epoch: 6| Step: 7
Training loss: 1.3731013536453247
Validation loss: 2.0340357390783166

Epoch: 6| Step: 8
Training loss: 1.2742509841918945
Validation loss: 2.008706021052535

Epoch: 6| Step: 9
Training loss: 1.2860909700393677
Validation loss: 2.013963459640421

Epoch: 6| Step: 10
Training loss: 0.9918309450149536
Validation loss: 2.008251214540133

Epoch: 6| Step: 11
Training loss: 1.2858966588974
Validation loss: 1.9910808455559514

Epoch: 6| Step: 12
Training loss: 1.207495093345642
Validation loss: 1.9928251594625495

Epoch: 6| Step: 13
Training loss: 0.8574464917182922
Validation loss: 1.9899739065477926

Epoch: 327| Step: 0
Training loss: 1.181016445159912
Validation loss: 1.9728314222828034

Epoch: 6| Step: 1
Training loss: 1.1713840961456299
Validation loss: 1.9426510257105674

Epoch: 6| Step: 2
Training loss: 1.180334448814392
Validation loss: 1.9418137868245442

Epoch: 6| Step: 3
Training loss: 0.9072434902191162
Validation loss: 1.9039553211581322

Epoch: 6| Step: 4
Training loss: 1.1063623428344727
Validation loss: 1.9297053839570733

Epoch: 6| Step: 5
Training loss: 1.3141021728515625
Validation loss: 1.9697648261183052

Epoch: 6| Step: 6
Training loss: 1.4249743223190308
Validation loss: 1.9815251442693895

Epoch: 6| Step: 7
Training loss: 2.011000871658325
Validation loss: 2.032744158980667

Epoch: 6| Step: 8
Training loss: 1.5322751998901367
Validation loss: 2.024944977093768

Epoch: 6| Step: 9
Training loss: 1.4203532934188843
Validation loss: 2.006075718069589

Epoch: 6| Step: 10
Training loss: 0.6394301652908325
Validation loss: 2.0034067041130474

Epoch: 6| Step: 11
Training loss: 1.4858901500701904
Validation loss: 1.990337493599102

Epoch: 6| Step: 12
Training loss: 1.791326642036438
Validation loss: 1.9738738177925028

Epoch: 6| Step: 13
Training loss: 1.665952205657959
Validation loss: 1.9439869606366722

Epoch: 328| Step: 0
Training loss: 1.530224323272705
Validation loss: 1.9705658112802813

Epoch: 6| Step: 1
Training loss: 1.1743496656417847
Validation loss: 1.9210106275414909

Epoch: 6| Step: 2
Training loss: 1.7355915307998657
Validation loss: 1.9281111455732776

Epoch: 6| Step: 3
Training loss: 0.8713036775588989
Validation loss: 1.9125370453762751

Epoch: 6| Step: 4
Training loss: 1.4830772876739502
Validation loss: 1.9083337501813007

Epoch: 6| Step: 5
Training loss: 1.144014835357666
Validation loss: 1.9210880879432923

Epoch: 6| Step: 6
Training loss: 0.9584113955497742
Validation loss: 1.9197922470749065

Epoch: 6| Step: 7
Training loss: 1.346785545349121
Validation loss: 1.911210544647709

Epoch: 6| Step: 8
Training loss: 1.1168580055236816
Validation loss: 1.9205422401428223

Epoch: 6| Step: 9
Training loss: 1.9295637607574463
Validation loss: 1.9387101063164331

Epoch: 6| Step: 10
Training loss: 1.199765682220459
Validation loss: 1.9413074293444235

Epoch: 6| Step: 11
Training loss: 1.2695221900939941
Validation loss: 1.9463129274306759

Epoch: 6| Step: 12
Training loss: 1.1534595489501953
Validation loss: 1.9373344900787517

Epoch: 6| Step: 13
Training loss: 1.4609488248825073
Validation loss: 1.970418978762883

Epoch: 329| Step: 0
Training loss: 1.439042329788208
Validation loss: 1.9819907129451793

Epoch: 6| Step: 1
Training loss: 1.1437526941299438
Validation loss: 1.9845027436492264

Epoch: 6| Step: 2
Training loss: 1.0285083055496216
Validation loss: 2.0230510478378623

Epoch: 6| Step: 3
Training loss: 1.513771653175354
Validation loss: 2.0202791844644854

Epoch: 6| Step: 4
Training loss: 1.5254822969436646
Validation loss: 1.9937177422226116

Epoch: 6| Step: 5
Training loss: 1.535728931427002
Validation loss: 1.953657780924151

Epoch: 6| Step: 6
Training loss: 1.276329517364502
Validation loss: 1.939583674553902

Epoch: 6| Step: 7
Training loss: 1.3590364456176758
Validation loss: 1.8988116454052668

Epoch: 6| Step: 8
Training loss: 1.466193437576294
Validation loss: 1.8954639255359609

Epoch: 6| Step: 9
Training loss: 1.5826388597488403
Validation loss: 1.890114999586536

Epoch: 6| Step: 10
Training loss: 1.0466217994689941
Validation loss: 1.9026199028056154

Epoch: 6| Step: 11
Training loss: 1.0074095726013184
Validation loss: 1.920430507711185

Epoch: 6| Step: 12
Training loss: 1.381511926651001
Validation loss: 1.9496490801534345

Epoch: 6| Step: 13
Training loss: 1.3076770305633545
Validation loss: 1.9190064463564145

Epoch: 330| Step: 0
Training loss: 0.8017593622207642
Validation loss: 1.9539403479586366

Epoch: 6| Step: 1
Training loss: 0.7114486694335938
Validation loss: 1.9717238385190246

Epoch: 6| Step: 2
Training loss: 1.2527137994766235
Validation loss: 2.0258884737568517

Epoch: 6| Step: 3
Training loss: 1.4695255756378174
Validation loss: 2.0280621359425206

Epoch: 6| Step: 4
Training loss: 0.9618402719497681
Validation loss: 2.0181687275568643

Epoch: 6| Step: 5
Training loss: 1.4838802814483643
Validation loss: 2.0301331935390348

Epoch: 6| Step: 6
Training loss: 1.9092938899993896
Validation loss: 1.9980540096118886

Epoch: 6| Step: 7
Training loss: 1.7669825553894043
Validation loss: 1.9736757637352071

Epoch: 6| Step: 8
Training loss: 1.2829904556274414
Validation loss: 1.9630796999059699

Epoch: 6| Step: 9
Training loss: 1.043869137763977
Validation loss: 1.9528975256027714

Epoch: 6| Step: 10
Training loss: 1.0964086055755615
Validation loss: 1.9141030196220643

Epoch: 6| Step: 11
Training loss: 1.38150954246521
Validation loss: 1.9044388878730036

Epoch: 6| Step: 12
Training loss: 1.2449383735656738
Validation loss: 1.8985368500473678

Epoch: 6| Step: 13
Training loss: 2.0380406379699707
Validation loss: 1.8827684412720382

Epoch: 331| Step: 0
Training loss: 1.9727909564971924
Validation loss: 1.8700964976382513

Epoch: 6| Step: 1
Training loss: 0.9594126343727112
Validation loss: 1.8558037268218173

Epoch: 6| Step: 2
Training loss: 1.2527903318405151
Validation loss: 1.844197360418176

Epoch: 6| Step: 3
Training loss: 0.946210503578186
Validation loss: 1.8536701074210546

Epoch: 6| Step: 4
Training loss: 1.3518532514572144
Validation loss: 1.8485628046015257

Epoch: 6| Step: 5
Training loss: 1.8535252809524536
Validation loss: 1.869962675597078

Epoch: 6| Step: 6
Training loss: 1.384674310684204
Validation loss: 1.9068371813784364

Epoch: 6| Step: 7
Training loss: 0.7501993179321289
Validation loss: 1.930031232936408

Epoch: 6| Step: 8
Training loss: 0.8935819268226624
Validation loss: 1.9625904560089111

Epoch: 6| Step: 9
Training loss: 1.086822748184204
Validation loss: 2.033941603476001

Epoch: 6| Step: 10
Training loss: 1.6200809478759766
Validation loss: 2.075407028198242

Epoch: 6| Step: 11
Training loss: 1.512941598892212
Validation loss: 2.0906450389533915

Epoch: 6| Step: 12
Training loss: 0.9222577810287476
Validation loss: 2.0797627382380988

Epoch: 6| Step: 13
Training loss: 1.850799560546875
Validation loss: 2.04999525572664

Epoch: 332| Step: 0
Training loss: 1.0616511106491089
Validation loss: 1.9808458384647165

Epoch: 6| Step: 1
Training loss: 1.0477780103683472
Validation loss: 1.9368271007332751

Epoch: 6| Step: 2
Training loss: 1.6707059144973755
Validation loss: 1.8927475380641159

Epoch: 6| Step: 3
Training loss: 1.0251665115356445
Validation loss: 1.8733520687267344

Epoch: 6| Step: 4
Training loss: 1.594693899154663
Validation loss: 1.8593217916386102

Epoch: 6| Step: 5
Training loss: 1.2751216888427734
Validation loss: 1.8613640544235066

Epoch: 6| Step: 6
Training loss: 1.9007920026779175
Validation loss: 1.86994807950912

Epoch: 6| Step: 7
Training loss: 0.8133214712142944
Validation loss: 1.8919913935404953

Epoch: 6| Step: 8
Training loss: 1.3504761457443237
Validation loss: 1.924288280548588

Epoch: 6| Step: 9
Training loss: 1.4205195903778076
Validation loss: 1.954388847915075

Epoch: 6| Step: 10
Training loss: 1.3540074825286865
Validation loss: 1.9706460199048441

Epoch: 6| Step: 11
Training loss: 1.463437795639038
Validation loss: 1.9899577069026169

Epoch: 6| Step: 12
Training loss: 0.8209289312362671
Validation loss: 2.0149714305836666

Epoch: 6| Step: 13
Training loss: 1.6208548545837402
Validation loss: 2.031963525279876

Epoch: 333| Step: 0
Training loss: 1.0544192790985107
Validation loss: 2.065294516983853

Epoch: 6| Step: 1
Training loss: 1.6240167617797852
Validation loss: 2.0380821356209378

Epoch: 6| Step: 2
Training loss: 1.5884504318237305
Validation loss: 2.074055920365036

Epoch: 6| Step: 3
Training loss: 1.6196712255477905
Validation loss: 2.0849873019802954

Epoch: 6| Step: 4
Training loss: 0.8045278191566467
Validation loss: 2.047402035805487

Epoch: 6| Step: 5
Training loss: 1.2957775592803955
Validation loss: 2.0047730130534016

Epoch: 6| Step: 6
Training loss: 1.0537440776824951
Validation loss: 1.9323207716788016

Epoch: 6| Step: 7
Training loss: 1.8188891410827637
Validation loss: 1.9027097135461786

Epoch: 6| Step: 8
Training loss: 1.2464967966079712
Validation loss: 1.8933636603816864

Epoch: 6| Step: 9
Training loss: 1.199817419052124
Validation loss: 1.864706373983814

Epoch: 6| Step: 10
Training loss: 1.1226506233215332
Validation loss: 1.862598862699283

Epoch: 6| Step: 11
Training loss: 1.5387165546417236
Validation loss: 1.904099541325723

Epoch: 6| Step: 12
Training loss: 0.895620584487915
Validation loss: 1.9251495612564908

Epoch: 6| Step: 13
Training loss: 1.4525896310806274
Validation loss: 1.9459185805372012

Epoch: 334| Step: 0
Training loss: 1.2333762645721436
Validation loss: 1.993987811508999

Epoch: 6| Step: 1
Training loss: 0.8893240690231323
Validation loss: 2.031991442044576

Epoch: 6| Step: 2
Training loss: 1.3705716133117676
Validation loss: 2.055380851991715

Epoch: 6| Step: 3
Training loss: 1.1000299453735352
Validation loss: 2.0837995813738917

Epoch: 6| Step: 4
Training loss: 1.840578317642212
Validation loss: 2.0565085923799904

Epoch: 6| Step: 5
Training loss: 1.2591131925582886
Validation loss: 2.025174770303952

Epoch: 6| Step: 6
Training loss: 1.4776344299316406
Validation loss: 2.0306095564237205

Epoch: 6| Step: 7
Training loss: 1.0085115432739258
Validation loss: 1.9755887985229492

Epoch: 6| Step: 8
Training loss: 1.5948686599731445
Validation loss: 1.9727701820353025

Epoch: 6| Step: 9
Training loss: 1.5016515254974365
Validation loss: 1.9027588944281302

Epoch: 6| Step: 10
Training loss: 1.2002625465393066
Validation loss: 1.8868124344015633

Epoch: 6| Step: 11
Training loss: 1.0733411312103271
Validation loss: 1.888818952345079

Epoch: 6| Step: 12
Training loss: 1.0450786352157593
Validation loss: 1.8795820115714945

Epoch: 6| Step: 13
Training loss: 1.4144009351730347
Validation loss: 1.8877570988029562

Epoch: 335| Step: 0
Training loss: 1.438402533531189
Validation loss: 1.8866156326827181

Epoch: 6| Step: 1
Training loss: 0.9641283750534058
Validation loss: 1.8800690392012238

Epoch: 6| Step: 2
Training loss: 1.3395631313323975
Validation loss: 1.914292622638005

Epoch: 6| Step: 3
Training loss: 1.5220227241516113
Validation loss: 1.9459194534568376

Epoch: 6| Step: 4
Training loss: 1.7187485694885254
Validation loss: 1.9472765255999822

Epoch: 6| Step: 5
Training loss: 1.0912508964538574
Validation loss: 1.9491148969178558

Epoch: 6| Step: 6
Training loss: 1.0127766132354736
Validation loss: 1.9539747597068868

Epoch: 6| Step: 7
Training loss: 1.023791790008545
Validation loss: 1.9555838543881652

Epoch: 6| Step: 8
Training loss: 1.5716346502304077
Validation loss: 1.9526389286082277

Epoch: 6| Step: 9
Training loss: 1.5865929126739502
Validation loss: 1.9342734659871748

Epoch: 6| Step: 10
Training loss: 0.9398648738861084
Validation loss: 1.905767201095499

Epoch: 6| Step: 11
Training loss: 1.6278530359268188
Validation loss: 1.87803683229672

Epoch: 6| Step: 12
Training loss: 0.946530282497406
Validation loss: 1.868165510956959

Epoch: 6| Step: 13
Training loss: 1.268226146697998
Validation loss: 1.870094048079624

Epoch: 336| Step: 0
Training loss: 0.9011470079421997
Validation loss: 1.8301617176302019

Epoch: 6| Step: 1
Training loss: 0.6388024091720581
Validation loss: 1.825896272095301

Epoch: 6| Step: 2
Training loss: 1.4714473485946655
Validation loss: 1.8386935469924763

Epoch: 6| Step: 3
Training loss: 1.152864694595337
Validation loss: 1.8704381309529787

Epoch: 6| Step: 4
Training loss: 1.7225451469421387
Validation loss: 1.8648753691745061

Epoch: 6| Step: 5
Training loss: 1.560693383216858
Validation loss: 1.9029625064583235

Epoch: 6| Step: 6
Training loss: 1.303297519683838
Validation loss: 1.9181340381663332

Epoch: 6| Step: 7
Training loss: 1.2078285217285156
Validation loss: 1.9169866064543366

Epoch: 6| Step: 8
Training loss: 1.0647622346878052
Validation loss: 1.9168331661532003

Epoch: 6| Step: 9
Training loss: 1.6158969402313232
Validation loss: 1.941225718426448

Epoch: 6| Step: 10
Training loss: 1.2477741241455078
Validation loss: 1.9370974251019057

Epoch: 6| Step: 11
Training loss: 1.6020643711090088
Validation loss: 1.9850889072623303

Epoch: 6| Step: 12
Training loss: 1.0888499021530151
Validation loss: 1.9608861554053523

Epoch: 6| Step: 13
Training loss: 0.8681896924972534
Validation loss: 1.9279834762696297

Epoch: 337| Step: 0
Training loss: 1.5274200439453125
Validation loss: 1.8767136245645502

Epoch: 6| Step: 1
Training loss: 0.7151753306388855
Validation loss: 1.8829496586194603

Epoch: 6| Step: 2
Training loss: 1.1770589351654053
Validation loss: 1.8338289094227616

Epoch: 6| Step: 3
Training loss: 1.062165379524231
Validation loss: 1.844285229200958

Epoch: 6| Step: 4
Training loss: 0.9045629501342773
Validation loss: 1.849178534682079

Epoch: 6| Step: 5
Training loss: 1.1451419591903687
Validation loss: 1.8628227069813719

Epoch: 6| Step: 6
Training loss: 1.5261666774749756
Validation loss: 1.8664003661883775

Epoch: 6| Step: 7
Training loss: 1.3065043687820435
Validation loss: 1.895305231053342

Epoch: 6| Step: 8
Training loss: 1.4028204679489136
Validation loss: 1.9239958922068279

Epoch: 6| Step: 9
Training loss: 1.2334489822387695
Validation loss: 1.9602027375210997

Epoch: 6| Step: 10
Training loss: 1.6118276119232178
Validation loss: 2.0003639485246394

Epoch: 6| Step: 11
Training loss: 1.5390260219573975
Validation loss: 2.043460933111047

Epoch: 6| Step: 12
Training loss: 0.8883675932884216
Validation loss: 2.0336532656864454

Epoch: 6| Step: 13
Training loss: 1.2905031442642212
Validation loss: 2.0412388911811252

Epoch: 338| Step: 0
Training loss: 1.1828941106796265
Validation loss: 2.051024657423778

Epoch: 6| Step: 1
Training loss: 0.8250190019607544
Validation loss: 2.016399868073002

Epoch: 6| Step: 2
Training loss: 1.2570693492889404
Validation loss: 2.001528360510385

Epoch: 6| Step: 3
Training loss: 1.458862066268921
Validation loss: 1.9870351155598958

Epoch: 6| Step: 4
Training loss: 1.6688156127929688
Validation loss: 1.956343053489603

Epoch: 6| Step: 5
Training loss: 1.1306830644607544
Validation loss: 1.924848621891391

Epoch: 6| Step: 6
Training loss: 0.8484212160110474
Validation loss: 1.9248921602003035

Epoch: 6| Step: 7
Training loss: 1.474738597869873
Validation loss: 1.8719106156338927

Epoch: 6| Step: 8
Training loss: 0.9398095607757568
Validation loss: 1.8509842939274286

Epoch: 6| Step: 9
Training loss: 1.1667466163635254
Validation loss: 1.8319136160676197

Epoch: 6| Step: 10
Training loss: 0.8475203514099121
Validation loss: 1.8536317220298193

Epoch: 6| Step: 11
Training loss: 1.4668328762054443
Validation loss: 1.8834076850645003

Epoch: 6| Step: 12
Training loss: 1.5679681301116943
Validation loss: 1.9154068923765613

Epoch: 6| Step: 13
Training loss: 1.1650042533874512
Validation loss: 1.9082152407656434

Epoch: 339| Step: 0
Training loss: 0.9676060676574707
Validation loss: 1.899028120502349

Epoch: 6| Step: 1
Training loss: 1.4746215343475342
Validation loss: 1.8809746311556907

Epoch: 6| Step: 2
Training loss: 1.4927668571472168
Validation loss: 1.91505939473388

Epoch: 6| Step: 3
Training loss: 1.2207940816879272
Validation loss: 1.9647681892559092

Epoch: 6| Step: 4
Training loss: 1.9057774543762207
Validation loss: 1.9764642997454571

Epoch: 6| Step: 5
Training loss: 1.0684010982513428
Validation loss: 1.957327599166542

Epoch: 6| Step: 6
Training loss: 0.9970530271530151
Validation loss: 1.9461066825415498

Epoch: 6| Step: 7
Training loss: 0.902899444103241
Validation loss: 1.9205052288629676

Epoch: 6| Step: 8
Training loss: 0.8486411571502686
Validation loss: 1.9010255336761475

Epoch: 6| Step: 9
Training loss: 1.1060481071472168
Validation loss: 1.8487695596551383

Epoch: 6| Step: 10
Training loss: 0.9443858861923218
Validation loss: 1.8436789454952363

Epoch: 6| Step: 11
Training loss: 1.7288259267807007
Validation loss: 1.8230311050209949

Epoch: 6| Step: 12
Training loss: 0.942428708076477
Validation loss: 1.8471958893601612

Epoch: 6| Step: 13
Training loss: 1.6224424839019775
Validation loss: 1.840672126380346

Epoch: 340| Step: 0
Training loss: 0.8596852421760559
Validation loss: 1.868457753171203

Epoch: 6| Step: 1
Training loss: 1.4499295949935913
Validation loss: 1.8644404603588967

Epoch: 6| Step: 2
Training loss: 1.4086384773254395
Validation loss: 1.89923797627931

Epoch: 6| Step: 3
Training loss: 1.6374995708465576
Validation loss: 1.8864701217220676

Epoch: 6| Step: 4
Training loss: 0.852467954158783
Validation loss: 1.9346822179773802

Epoch: 6| Step: 5
Training loss: 1.1592307090759277
Validation loss: 1.9590973854064941

Epoch: 6| Step: 6
Training loss: 0.655022144317627
Validation loss: 1.9754231386287238

Epoch: 6| Step: 7
Training loss: 0.8645163774490356
Validation loss: 1.967704608876218

Epoch: 6| Step: 8
Training loss: 1.9020874500274658
Validation loss: 1.9835060155519875

Epoch: 6| Step: 9
Training loss: 0.5500522255897522
Validation loss: 2.0192692202906453

Epoch: 6| Step: 10
Training loss: 1.7934013605117798
Validation loss: 2.010283162516932

Epoch: 6| Step: 11
Training loss: 1.63411283493042
Validation loss: 1.9863316109103542

Epoch: 6| Step: 12
Training loss: 1.2889082431793213
Validation loss: 1.9932048756589171

Epoch: 6| Step: 13
Training loss: 0.5741915106773376
Validation loss: 1.9561108081571517

Epoch: 341| Step: 0
Training loss: 1.822925090789795
Validation loss: 1.916082048928866

Epoch: 6| Step: 1
Training loss: 0.9703802466392517
Validation loss: 1.9123757244438253

Epoch: 6| Step: 2
Training loss: 0.6583647727966309
Validation loss: 1.8513394222464612

Epoch: 6| Step: 3
Training loss: 1.093982458114624
Validation loss: 1.8747070053572297

Epoch: 6| Step: 4
Training loss: 0.9830235242843628
Validation loss: 1.8787890595774497

Epoch: 6| Step: 5
Training loss: 1.9173837900161743
Validation loss: 1.8840783975457633

Epoch: 6| Step: 6
Training loss: 1.3125667572021484
Validation loss: 1.9095201351309334

Epoch: 6| Step: 7
Training loss: 1.0796723365783691
Validation loss: 1.9094978468392485

Epoch: 6| Step: 8
Training loss: 1.260038137435913
Validation loss: 1.9268080342200495

Epoch: 6| Step: 9
Training loss: 1.1339048147201538
Validation loss: 1.9418992175850818

Epoch: 6| Step: 10
Training loss: 1.274423599243164
Validation loss: 1.9928588931278517

Epoch: 6| Step: 11
Training loss: 0.9740328788757324
Validation loss: 1.9938437079870572

Epoch: 6| Step: 12
Training loss: 1.0437037944793701
Validation loss: 2.0020719369252524

Epoch: 6| Step: 13
Training loss: 1.4014980792999268
Validation loss: 1.975088147706883

Epoch: 342| Step: 0
Training loss: 0.8068844079971313
Validation loss: 1.995005456350183

Epoch: 6| Step: 1
Training loss: 0.8916527032852173
Validation loss: 1.9622872619218723

Epoch: 6| Step: 2
Training loss: 1.3898828029632568
Validation loss: 1.97254958973136

Epoch: 6| Step: 3
Training loss: 1.559032917022705
Validation loss: 1.9058579373103317

Epoch: 6| Step: 4
Training loss: 0.9354850649833679
Validation loss: 1.9036405137790147

Epoch: 6| Step: 5
Training loss: 1.2298259735107422
Validation loss: 1.9141441314451155

Epoch: 6| Step: 6
Training loss: 1.3899104595184326
Validation loss: 1.8764531099668114

Epoch: 6| Step: 7
Training loss: 1.2067089080810547
Validation loss: 1.8779546201870005

Epoch: 6| Step: 8
Training loss: 1.1478731632232666
Validation loss: 1.8527553504513157

Epoch: 6| Step: 9
Training loss: 1.1696178913116455
Validation loss: 1.8586001408997403

Epoch: 6| Step: 10
Training loss: 1.0909879207611084
Validation loss: 1.8621873394135506

Epoch: 6| Step: 11
Training loss: 1.0809199810028076
Validation loss: 1.8486636120785949

Epoch: 6| Step: 12
Training loss: 1.2415435314178467
Validation loss: 1.8374204186983005

Epoch: 6| Step: 13
Training loss: 1.6068634986877441
Validation loss: 1.8676471582023046

Epoch: 343| Step: 0
Training loss: 0.9623997211456299
Validation loss: 1.9004593946600472

Epoch: 6| Step: 1
Training loss: 0.8405460715293884
Validation loss: 1.9280022164826751

Epoch: 6| Step: 2
Training loss: 1.188019037246704
Validation loss: 1.9302687491140058

Epoch: 6| Step: 3
Training loss: 1.5445441007614136
Validation loss: 1.9570123636594383

Epoch: 6| Step: 4
Training loss: 1.0394911766052246
Validation loss: 1.9766481948155228

Epoch: 6| Step: 5
Training loss: 1.0367627143859863
Validation loss: 1.9376768450583182

Epoch: 6| Step: 6
Training loss: 1.5430278778076172
Validation loss: 1.9001813537331038

Epoch: 6| Step: 7
Training loss: 1.3910114765167236
Validation loss: 1.89514680575299

Epoch: 6| Step: 8
Training loss: 1.0213825702667236
Validation loss: 1.8629169425656718

Epoch: 6| Step: 9
Training loss: 1.3919930458068848
Validation loss: 1.8515776959798669

Epoch: 6| Step: 10
Training loss: 0.9503914713859558
Validation loss: 1.845035223550694

Epoch: 6| Step: 11
Training loss: 1.0719261169433594
Validation loss: 1.8408811874287103

Epoch: 6| Step: 12
Training loss: 1.5059902667999268
Validation loss: 1.8762872372904131

Epoch: 6| Step: 13
Training loss: 0.7111477851867676
Validation loss: 1.8838490388726676

Epoch: 344| Step: 0
Training loss: 1.4081230163574219
Validation loss: 1.88228835598115

Epoch: 6| Step: 1
Training loss: 0.9057117700576782
Validation loss: 1.8842397659055647

Epoch: 6| Step: 2
Training loss: 1.4556925296783447
Validation loss: 1.8425949401752924

Epoch: 6| Step: 3
Training loss: 0.741477370262146
Validation loss: 1.8206725505090529

Epoch: 6| Step: 4
Training loss: 1.4313931465148926
Validation loss: 1.8258375083246539

Epoch: 6| Step: 5
Training loss: 1.0588696002960205
Validation loss: 1.7949847687957108

Epoch: 6| Step: 6
Training loss: 1.1817586421966553
Validation loss: 1.8195856309706164

Epoch: 6| Step: 7
Training loss: 1.3137388229370117
Validation loss: 1.8347352473966536

Epoch: 6| Step: 8
Training loss: 1.2163487672805786
Validation loss: 1.8894707810494207

Epoch: 6| Step: 9
Training loss: 1.0417940616607666
Validation loss: 1.9032062599735875

Epoch: 6| Step: 10
Training loss: 0.9183861613273621
Validation loss: 1.9128864478039485

Epoch: 6| Step: 11
Training loss: 1.1656765937805176
Validation loss: 1.9319287525710238

Epoch: 6| Step: 12
Training loss: 1.1682038307189941
Validation loss: 1.925268429581837

Epoch: 6| Step: 13
Training loss: 1.639109492301941
Validation loss: 1.911735196267405

Epoch: 345| Step: 0
Training loss: 0.8197412490844727
Validation loss: 1.9217241720486713

Epoch: 6| Step: 1
Training loss: 1.3302817344665527
Validation loss: 1.924586699854943

Epoch: 6| Step: 2
Training loss: 1.2589137554168701
Validation loss: 1.8989313264046945

Epoch: 6| Step: 3
Training loss: 1.2512177228927612
Validation loss: 1.89931688257443

Epoch: 6| Step: 4
Training loss: 1.3371367454528809
Validation loss: 1.9037601153055828

Epoch: 6| Step: 5
Training loss: 0.8806586265563965
Validation loss: 1.8891904892459992

Epoch: 6| Step: 6
Training loss: 1.036128044128418
Validation loss: 1.9170719910693426

Epoch: 6| Step: 7
Training loss: 1.0653631687164307
Validation loss: 1.9001151656591764

Epoch: 6| Step: 8
Training loss: 1.318562388420105
Validation loss: 1.9238806732239262

Epoch: 6| Step: 9
Training loss: 1.0022575855255127
Validation loss: 1.9346507646704232

Epoch: 6| Step: 10
Training loss: 1.3161952495574951
Validation loss: 1.9552732180523615

Epoch: 6| Step: 11
Training loss: 0.8933935165405273
Validation loss: 1.969486451918079

Epoch: 6| Step: 12
Training loss: 1.7119181156158447
Validation loss: 1.950971548275281

Epoch: 6| Step: 13
Training loss: 0.9222132563591003
Validation loss: 1.9403946450961533

Epoch: 346| Step: 0
Training loss: 1.3663597106933594
Validation loss: 1.916416400222368

Epoch: 6| Step: 1
Training loss: 1.450577974319458
Validation loss: 1.9064200873016028

Epoch: 6| Step: 2
Training loss: 1.4886302947998047
Validation loss: 1.9246562475799232

Epoch: 6| Step: 3
Training loss: 1.0888009071350098
Validation loss: 1.881378528892353

Epoch: 6| Step: 4
Training loss: 0.9126462936401367
Validation loss: 1.888982242153537

Epoch: 6| Step: 5
Training loss: 0.9376815557479858
Validation loss: 1.8733444982959377

Epoch: 6| Step: 6
Training loss: 1.0001192092895508
Validation loss: 1.8444248425063265

Epoch: 6| Step: 7
Training loss: 1.0629971027374268
Validation loss: 1.8466957743449877

Epoch: 6| Step: 8
Training loss: 1.2944304943084717
Validation loss: 1.8580140682958788

Epoch: 6| Step: 9
Training loss: 1.1046993732452393
Validation loss: 1.862800987817908

Epoch: 6| Step: 10
Training loss: 1.3871585130691528
Validation loss: 1.868844743697874

Epoch: 6| Step: 11
Training loss: 0.6189309358596802
Validation loss: 1.8892641528960197

Epoch: 6| Step: 12
Training loss: 1.2783424854278564
Validation loss: 1.8910810344962663

Epoch: 6| Step: 13
Training loss: 1.1543477773666382
Validation loss: 1.9117532058428692

Epoch: 347| Step: 0
Training loss: 0.8323718309402466
Validation loss: 1.9387195059048232

Epoch: 6| Step: 1
Training loss: 1.0456024408340454
Validation loss: 1.9805929917161182

Epoch: 6| Step: 2
Training loss: 1.4571651220321655
Validation loss: 2.0268299682165987

Epoch: 6| Step: 3
Training loss: 1.3142167329788208
Validation loss: 1.985434527038246

Epoch: 6| Step: 4
Training loss: 1.0841574668884277
Validation loss: 2.001190593165736

Epoch: 6| Step: 5
Training loss: 1.2639684677124023
Validation loss: 1.9756894829452678

Epoch: 6| Step: 6
Training loss: 1.104456901550293
Validation loss: 1.9319642448938021

Epoch: 6| Step: 7
Training loss: 0.6772347688674927
Validation loss: 1.9015397102602067

Epoch: 6| Step: 8
Training loss: 1.33262038230896
Validation loss: 1.9036542382291568

Epoch: 6| Step: 9
Training loss: 1.3347928524017334
Validation loss: 1.878088096136688

Epoch: 6| Step: 10
Training loss: 1.1170332431793213
Validation loss: 1.826136553159324

Epoch: 6| Step: 11
Training loss: 1.2919703722000122
Validation loss: 1.8223717187040596

Epoch: 6| Step: 12
Training loss: 1.2925360202789307
Validation loss: 1.8079242116661483

Epoch: 6| Step: 13
Training loss: 1.5211691856384277
Validation loss: 1.8363757774394045

Epoch: 348| Step: 0
Training loss: 0.9352786540985107
Validation loss: 1.871204844085119

Epoch: 6| Step: 1
Training loss: 1.0168479681015015
Validation loss: 1.894484773758919

Epoch: 6| Step: 2
Training loss: 0.7123721837997437
Validation loss: 1.9352714336046608

Epoch: 6| Step: 3
Training loss: 1.0965893268585205
Validation loss: 1.9646256175092471

Epoch: 6| Step: 4
Training loss: 1.3626646995544434
Validation loss: 1.9675835768381755

Epoch: 6| Step: 5
Training loss: 1.0004618167877197
Validation loss: 1.9670537261552707

Epoch: 6| Step: 6
Training loss: 1.2075512409210205
Validation loss: 1.9207611635167112

Epoch: 6| Step: 7
Training loss: 0.8841571807861328
Validation loss: 1.8775485600194624

Epoch: 6| Step: 8
Training loss: 1.5841271877288818
Validation loss: 1.8352926751618743

Epoch: 6| Step: 9
Training loss: 1.9398877620697021
Validation loss: 1.8181278115959578

Epoch: 6| Step: 10
Training loss: 1.082425832748413
Validation loss: 1.829126073468116

Epoch: 6| Step: 11
Training loss: 1.5269432067871094
Validation loss: 1.7779902642773044

Epoch: 6| Step: 12
Training loss: 0.5740189552307129
Validation loss: 1.8161677237479918

Epoch: 6| Step: 13
Training loss: 1.0488859415054321
Validation loss: 1.8140359911867368

Epoch: 349| Step: 0
Training loss: 0.9732310771942139
Validation loss: 1.8618550505689395

Epoch: 6| Step: 1
Training loss: 1.374021053314209
Validation loss: 1.8961731156995218

Epoch: 6| Step: 2
Training loss: 1.1585334539413452
Validation loss: 1.9470406116977814

Epoch: 6| Step: 3
Training loss: 1.4493536949157715
Validation loss: 1.9808818704338484

Epoch: 6| Step: 4
Training loss: 1.2049000263214111
Validation loss: 1.9967998394402124

Epoch: 6| Step: 5
Training loss: 0.8666840195655823
Validation loss: 1.9499927297715218

Epoch: 6| Step: 6
Training loss: 1.4235000610351562
Validation loss: 1.949120634345598

Epoch: 6| Step: 7
Training loss: 0.9545509815216064
Validation loss: 1.8966715963937903

Epoch: 6| Step: 8
Training loss: 1.202258825302124
Validation loss: 1.8666199227815032

Epoch: 6| Step: 9
Training loss: 1.2901853322982788
Validation loss: 1.8485997299994192

Epoch: 6| Step: 10
Training loss: 0.9288922548294067
Validation loss: 1.80684684553454

Epoch: 6| Step: 11
Training loss: 0.8054269552230835
Validation loss: 1.7880251292259461

Epoch: 6| Step: 12
Training loss: 1.2073678970336914
Validation loss: 1.789700593999637

Epoch: 6| Step: 13
Training loss: 0.8665667772293091
Validation loss: 1.812184855502139

Epoch: 350| Step: 0
Training loss: 0.8653929233551025
Validation loss: 1.8108860267105924

Epoch: 6| Step: 1
Training loss: 0.7586691975593567
Validation loss: 1.8145584085936188

Epoch: 6| Step: 2
Training loss: 1.1918089389801025
Validation loss: 1.8812091171100576

Epoch: 6| Step: 3
Training loss: 1.3537824153900146
Validation loss: 1.8976395066066454

Epoch: 6| Step: 4
Training loss: 1.2502723932266235
Validation loss: 1.9525458223076277

Epoch: 6| Step: 5
Training loss: 1.4450030326843262
Validation loss: 1.9982109826098207

Epoch: 6| Step: 6
Training loss: 1.639374017715454
Validation loss: 1.9583156108856201

Epoch: 6| Step: 7
Training loss: 1.71681547164917
Validation loss: 1.9657427303252681

Epoch: 6| Step: 8
Training loss: 0.8109878301620483
Validation loss: 1.9763766565630514

Epoch: 6| Step: 9
Training loss: 0.5719912648200989
Validation loss: 1.9977393419511857

Epoch: 6| Step: 10
Training loss: 1.5982204675674438
Validation loss: 1.9514245307573708

Epoch: 6| Step: 11
Training loss: 0.733444333076477
Validation loss: 1.9185041176375521

Epoch: 6| Step: 12
Training loss: 0.8957718014717102
Validation loss: 1.921016707215258

Epoch: 6| Step: 13
Training loss: 1.056129813194275
Validation loss: 1.9029953889949347

Epoch: 351| Step: 0
Training loss: 1.5299688577651978
Validation loss: 1.8901995753729215

Epoch: 6| Step: 1
Training loss: 1.0787124633789062
Validation loss: 1.8658796202751897

Epoch: 6| Step: 2
Training loss: 0.8793498277664185
Validation loss: 1.8411999197416409

Epoch: 6| Step: 3
Training loss: 1.4144501686096191
Validation loss: 1.8632839841227378

Epoch: 6| Step: 4
Training loss: 1.1175119876861572
Validation loss: 1.8220026826345792

Epoch: 6| Step: 5
Training loss: 1.1783102750778198
Validation loss: 1.868420862382458

Epoch: 6| Step: 6
Training loss: 1.1876975297927856
Validation loss: 1.8650440426282986

Epoch: 6| Step: 7
Training loss: 1.09684419631958
Validation loss: 1.925582242268388

Epoch: 6| Step: 8
Training loss: 1.1039751768112183
Validation loss: 1.9283929999156664

Epoch: 6| Step: 9
Training loss: 0.9510986804962158
Validation loss: 1.8826166634918542

Epoch: 6| Step: 10
Training loss: 0.903265118598938
Validation loss: 1.8941690588510165

Epoch: 6| Step: 11
Training loss: 1.0999975204467773
Validation loss: 1.9125473922298801

Epoch: 6| Step: 12
Training loss: 1.3920077085494995
Validation loss: 1.9238713043992237

Epoch: 6| Step: 13
Training loss: 0.9649732112884521
Validation loss: 1.89124717122765

Epoch: 352| Step: 0
Training loss: 1.0620136260986328
Validation loss: 1.945938132142508

Epoch: 6| Step: 1
Training loss: 1.1123359203338623
Validation loss: 1.9336316431722333

Epoch: 6| Step: 2
Training loss: 1.421299695968628
Validation loss: 1.9425465163364206

Epoch: 6| Step: 3
Training loss: 1.2712270021438599
Validation loss: 1.9091386102860974

Epoch: 6| Step: 4
Training loss: 1.4000704288482666
Validation loss: 1.8763519602437173

Epoch: 6| Step: 5
Training loss: 1.43641197681427
Validation loss: 1.8540300182116929

Epoch: 6| Step: 6
Training loss: 0.8143256306648254
Validation loss: 1.8400471197661532

Epoch: 6| Step: 7
Training loss: 0.7313859462738037
Validation loss: 1.8649568865376134

Epoch: 6| Step: 8
Training loss: 0.9241032004356384
Validation loss: 1.8490372101465862

Epoch: 6| Step: 9
Training loss: 1.1155674457550049
Validation loss: 1.852796245646733

Epoch: 6| Step: 10
Training loss: 0.9977152347564697
Validation loss: 1.8771627628675072

Epoch: 6| Step: 11
Training loss: 1.491055965423584
Validation loss: 1.852463447919456

Epoch: 6| Step: 12
Training loss: 0.579380989074707
Validation loss: 1.8421001113871092

Epoch: 6| Step: 13
Training loss: 0.6662372946739197
Validation loss: 1.8570961952209473

Epoch: 353| Step: 0
Training loss: 1.0546948909759521
Validation loss: 1.8560249395267938

Epoch: 6| Step: 1
Training loss: 0.7991905808448792
Validation loss: 1.8514178440135012

Epoch: 6| Step: 2
Training loss: 1.12669837474823
Validation loss: 1.8552197346123316

Epoch: 6| Step: 3
Training loss: 1.3929392099380493
Validation loss: 1.8500817770599036

Epoch: 6| Step: 4
Training loss: 1.4181466102600098
Validation loss: 1.8533429855941443

Epoch: 6| Step: 5
Training loss: 0.5035714507102966
Validation loss: 1.8773857701209284

Epoch: 6| Step: 6
Training loss: 1.3627917766571045
Validation loss: 1.8746497220890497

Epoch: 6| Step: 7
Training loss: 1.7050578594207764
Validation loss: 1.8957416113986765

Epoch: 6| Step: 8
Training loss: 1.2161173820495605
Validation loss: 1.87021194734881

Epoch: 6| Step: 9
Training loss: 0.9318790435791016
Validation loss: 1.8934660803887151

Epoch: 6| Step: 10
Training loss: 1.0968841314315796
Validation loss: 1.9262655588888353

Epoch: 6| Step: 11
Training loss: 1.340305209159851
Validation loss: 1.9442367066619217

Epoch: 6| Step: 12
Training loss: 0.6519194841384888
Validation loss: 1.8988754774934502

Epoch: 6| Step: 13
Training loss: 0.8657894730567932
Validation loss: 1.897724437457259

Epoch: 354| Step: 0
Training loss: 1.4538156986236572
Validation loss: 1.9131302936102754

Epoch: 6| Step: 1
Training loss: 1.2735637426376343
Validation loss: 1.8990644152446459

Epoch: 6| Step: 2
Training loss: 0.8576239347457886
Validation loss: 1.901639412808162

Epoch: 6| Step: 3
Training loss: 1.444586157798767
Validation loss: 1.8865143778503581

Epoch: 6| Step: 4
Training loss: 1.030949354171753
Validation loss: 1.8751450636053597

Epoch: 6| Step: 5
Training loss: 1.3272972106933594
Validation loss: 1.859430738674697

Epoch: 6| Step: 6
Training loss: 1.3952699899673462
Validation loss: 1.8840867652687976

Epoch: 6| Step: 7
Training loss: 1.2302632331848145
Validation loss: 1.8592300056129374

Epoch: 6| Step: 8
Training loss: 1.1025744676589966
Validation loss: 1.8688351492727957

Epoch: 6| Step: 9
Training loss: 0.7507656812667847
Validation loss: 1.8509748546026086

Epoch: 6| Step: 10
Training loss: 1.3797950744628906
Validation loss: 1.8676933921793455

Epoch: 6| Step: 11
Training loss: 0.6448063850402832
Validation loss: 1.90282642456793

Epoch: 6| Step: 12
Training loss: 0.8766071796417236
Validation loss: 1.8622664225998746

Epoch: 6| Step: 13
Training loss: 0.7362410426139832
Validation loss: 1.845619196532875

Epoch: 355| Step: 0
Training loss: 0.6345064043998718
Validation loss: 1.83734756131326

Epoch: 6| Step: 1
Training loss: 1.2097827196121216
Validation loss: 1.8374658541012836

Epoch: 6| Step: 2
Training loss: 0.8085620403289795
Validation loss: 1.8711377959097586

Epoch: 6| Step: 3
Training loss: 1.7949244976043701
Validation loss: 1.8878862524545321

Epoch: 6| Step: 4
Training loss: 1.445587158203125
Validation loss: 1.926523406018493

Epoch: 6| Step: 5
Training loss: 0.9581998586654663
Validation loss: 1.9190717576652445

Epoch: 6| Step: 6
Training loss: 1.5374430418014526
Validation loss: 1.9147522885312316

Epoch: 6| Step: 7
Training loss: 1.1233744621276855
Validation loss: 1.8977319963516728

Epoch: 6| Step: 8
Training loss: 0.8988932371139526
Validation loss: 1.8536521952639344

Epoch: 6| Step: 9
Training loss: 1.3091869354248047
Validation loss: 1.8541554917571366

Epoch: 6| Step: 10
Training loss: 1.0384732484817505
Validation loss: 1.8628939121000228

Epoch: 6| Step: 11
Training loss: 1.0319950580596924
Validation loss: 1.819792442424323

Epoch: 6| Step: 12
Training loss: 0.4754061996936798
Validation loss: 1.8176568272293254

Epoch: 6| Step: 13
Training loss: 0.8075225353240967
Validation loss: 1.8175784323805122

Epoch: 356| Step: 0
Training loss: 1.18088698387146
Validation loss: 1.7773333518735823

Epoch: 6| Step: 1
Training loss: 1.0008121728897095
Validation loss: 1.8048623582368255

Epoch: 6| Step: 2
Training loss: 1.5244345664978027
Validation loss: 1.8068060362210838

Epoch: 6| Step: 3
Training loss: 0.5109174251556396
Validation loss: 1.8089991615664573

Epoch: 6| Step: 4
Training loss: 1.199893593788147
Validation loss: 1.8637273888434134

Epoch: 6| Step: 5
Training loss: 0.9026567935943604
Validation loss: 1.8751188042343303

Epoch: 6| Step: 6
Training loss: 0.8427764177322388
Validation loss: 1.9290794685322752

Epoch: 6| Step: 7
Training loss: 1.572800874710083
Validation loss: 1.9712113847014725

Epoch: 6| Step: 8
Training loss: 1.8195101022720337
Validation loss: 1.974240428657942

Epoch: 6| Step: 9
Training loss: 1.1614810228347778
Validation loss: 1.9707858639378701

Epoch: 6| Step: 10
Training loss: 1.0448040962219238
Validation loss: 1.9098256159854192

Epoch: 6| Step: 11
Training loss: 0.8908480405807495
Validation loss: 1.858728172958538

Epoch: 6| Step: 12
Training loss: 1.0954612493515015
Validation loss: 1.826344184978034

Epoch: 6| Step: 13
Training loss: 0.6564672589302063
Validation loss: 1.7975783155810448

Epoch: 357| Step: 0
Training loss: 1.941162347793579
Validation loss: 1.7684968056217316

Epoch: 6| Step: 1
Training loss: 1.140415906906128
Validation loss: 1.7843335238836144

Epoch: 6| Step: 2
Training loss: 0.9683501124382019
Validation loss: 1.7881525178109445

Epoch: 6| Step: 3
Training loss: 0.7488770484924316
Validation loss: 1.7918015500550628

Epoch: 6| Step: 4
Training loss: 1.1189370155334473
Validation loss: 1.8474606903650428

Epoch: 6| Step: 5
Training loss: 0.7910468578338623
Validation loss: 1.8778578953076435

Epoch: 6| Step: 6
Training loss: 1.0798683166503906
Validation loss: 1.9165219927346835

Epoch: 6| Step: 7
Training loss: 1.1081314086914062
Validation loss: 1.8812139367544523

Epoch: 6| Step: 8
Training loss: 1.0970863103866577
Validation loss: 1.9104096094767253

Epoch: 6| Step: 9
Training loss: 0.9907811284065247
Validation loss: 1.8708260700266848

Epoch: 6| Step: 10
Training loss: 0.763432502746582
Validation loss: 1.802472714454897

Epoch: 6| Step: 11
Training loss: 1.3970537185668945
Validation loss: 1.7672441992708432

Epoch: 6| Step: 12
Training loss: 1.2644095420837402
Validation loss: 1.7370276604929278

Epoch: 6| Step: 13
Training loss: 0.9510905742645264
Validation loss: 1.7407296216616066

Epoch: 358| Step: 0
Training loss: 0.9520886540412903
Validation loss: 1.7638426147481447

Epoch: 6| Step: 1
Training loss: 1.4747666120529175
Validation loss: 1.7672217763880247

Epoch: 6| Step: 2
Training loss: 0.7872992753982544
Validation loss: 1.8253508844683248

Epoch: 6| Step: 3
Training loss: 1.0357955694198608
Validation loss: 1.878129223341583

Epoch: 6| Step: 4
Training loss: 1.130577564239502
Validation loss: 1.9245484413639191

Epoch: 6| Step: 5
Training loss: 1.3145250082015991
Validation loss: 1.9792997016701648

Epoch: 6| Step: 6
Training loss: 1.1810067892074585
Validation loss: 2.0167490974549325

Epoch: 6| Step: 7
Training loss: 1.1226626634597778
Validation loss: 1.9827976842080393

Epoch: 6| Step: 8
Training loss: 1.2230138778686523
Validation loss: 1.9698791683361094

Epoch: 6| Step: 9
Training loss: 0.5937619805335999
Validation loss: 1.9292653273510676

Epoch: 6| Step: 10
Training loss: 0.9165247678756714
Validation loss: 1.8948893085602792

Epoch: 6| Step: 11
Training loss: 1.1535875797271729
Validation loss: 1.836771265152962

Epoch: 6| Step: 12
Training loss: 0.9758163690567017
Validation loss: 1.8301864465077717

Epoch: 6| Step: 13
Training loss: 1.5937931537628174
Validation loss: 1.8033684774111676

Epoch: 359| Step: 0
Training loss: 1.0633935928344727
Validation loss: 1.801633051646653

Epoch: 6| Step: 1
Training loss: 0.7350283265113831
Validation loss: 1.798854544598569

Epoch: 6| Step: 2
Training loss: 1.0071802139282227
Validation loss: 1.8050284488226778

Epoch: 6| Step: 3
Training loss: 0.7002680897712708
Validation loss: 1.8110148599070888

Epoch: 6| Step: 4
Training loss: 1.226957082748413
Validation loss: 1.819747313376396

Epoch: 6| Step: 5
Training loss: 1.1616013050079346
Validation loss: 1.808786153793335

Epoch: 6| Step: 6
Training loss: 0.8844927549362183
Validation loss: 1.854795155986663

Epoch: 6| Step: 7
Training loss: 1.309943437576294
Validation loss: 1.8926805744888962

Epoch: 6| Step: 8
Training loss: 0.6321386098861694
Validation loss: 1.8984666562849475

Epoch: 6| Step: 9
Training loss: 0.891899585723877
Validation loss: 1.8988313226289646

Epoch: 6| Step: 10
Training loss: 1.0951573848724365
Validation loss: 1.8974452685284358

Epoch: 6| Step: 11
Training loss: 1.3998878002166748
Validation loss: 1.9194120950596307

Epoch: 6| Step: 12
Training loss: 1.8354160785675049
Validation loss: 1.8987889725674865

Epoch: 6| Step: 13
Training loss: 1.5389057397842407
Validation loss: 1.915024608694097

Epoch: 360| Step: 0
Training loss: 0.941072940826416
Validation loss: 1.8673724051444762

Epoch: 6| Step: 1
Training loss: 1.4852955341339111
Validation loss: 1.892520180312536

Epoch: 6| Step: 2
Training loss: 1.3304200172424316
Validation loss: 1.8481420252912788

Epoch: 6| Step: 3
Training loss: 0.9643712639808655
Validation loss: 1.8044757035470778

Epoch: 6| Step: 4
Training loss: 1.4205067157745361
Validation loss: 1.7639936657362087

Epoch: 6| Step: 5
Training loss: 0.4356701076030731
Validation loss: 1.7447157893129575

Epoch: 6| Step: 6
Training loss: 1.3837028741836548
Validation loss: 1.7120548678982643

Epoch: 6| Step: 7
Training loss: 1.1065785884857178
Validation loss: 1.7402041689042123

Epoch: 6| Step: 8
Training loss: 0.44121143221855164
Validation loss: 1.7359157172582482

Epoch: 6| Step: 9
Training loss: 0.8801196217536926
Validation loss: 1.7591172226013676

Epoch: 6| Step: 10
Training loss: 1.0607831478118896
Validation loss: 1.750248832087363

Epoch: 6| Step: 11
Training loss: 1.199492335319519
Validation loss: 1.8104559580485027

Epoch: 6| Step: 12
Training loss: 1.3916115760803223
Validation loss: 1.8399973454013947

Epoch: 6| Step: 13
Training loss: 1.6079822778701782
Validation loss: 1.8377868347270514

Epoch: 361| Step: 0
Training loss: 0.6353220343589783
Validation loss: 1.8454006974415114

Epoch: 6| Step: 1
Training loss: 0.8517792224884033
Validation loss: 1.8778654708657214

Epoch: 6| Step: 2
Training loss: 1.1658391952514648
Validation loss: 1.897107667820428

Epoch: 6| Step: 3
Training loss: 1.4201030731201172
Validation loss: 1.9175563960947015

Epoch: 6| Step: 4
Training loss: 0.8179965615272522
Validation loss: 1.9188323379844747

Epoch: 6| Step: 5
Training loss: 1.3878681659698486
Validation loss: 1.8924469127449939

Epoch: 6| Step: 6
Training loss: 1.1069437265396118
Validation loss: 1.8540785261379775

Epoch: 6| Step: 7
Training loss: 1.503812313079834
Validation loss: 1.8591037514389201

Epoch: 6| Step: 8
Training loss: 1.0013936758041382
Validation loss: 1.8364668828184887

Epoch: 6| Step: 9
Training loss: 1.2270050048828125
Validation loss: 1.8334435775715818

Epoch: 6| Step: 10
Training loss: 0.8788525462150574
Validation loss: 1.8419717204186223

Epoch: 6| Step: 11
Training loss: 0.6133849024772644
Validation loss: 1.8103085487119612

Epoch: 6| Step: 12
Training loss: 1.4445593357086182
Validation loss: 1.842375211818244

Epoch: 6| Step: 13
Training loss: 1.1680588722229004
Validation loss: 1.8460218611583914

Epoch: 362| Step: 0
Training loss: 0.9095326066017151
Validation loss: 1.8339043253211564

Epoch: 6| Step: 1
Training loss: 1.3800318241119385
Validation loss: 1.8314888182506766

Epoch: 6| Step: 2
Training loss: 1.1784229278564453
Validation loss: 1.845978235685697

Epoch: 6| Step: 3
Training loss: 1.2407854795455933
Validation loss: 1.836576174664241

Epoch: 6| Step: 4
Training loss: 1.5839014053344727
Validation loss: 1.8326346233326902

Epoch: 6| Step: 5
Training loss: 0.8357961177825928
Validation loss: 1.8121602740339053

Epoch: 6| Step: 6
Training loss: 1.2713912725448608
Validation loss: 1.8161413913132043

Epoch: 6| Step: 7
Training loss: 1.1553943157196045
Validation loss: 1.8261207854875954

Epoch: 6| Step: 8
Training loss: 0.6058160066604614
Validation loss: 1.8339504144525016

Epoch: 6| Step: 9
Training loss: 0.7762114405632019
Validation loss: 1.8673726102357269

Epoch: 6| Step: 10
Training loss: 0.9848579168319702
Validation loss: 1.9073758894397366

Epoch: 6| Step: 11
Training loss: 0.7020541429519653
Validation loss: 1.9236695561357724

Epoch: 6| Step: 12
Training loss: 1.024505376815796
Validation loss: 1.9479692379633586

Epoch: 6| Step: 13
Training loss: 1.464333415031433
Validation loss: 1.9572925490717734

Epoch: 363| Step: 0
Training loss: 1.2247002124786377
Validation loss: 1.9616466106907013

Epoch: 6| Step: 1
Training loss: 1.2438890933990479
Validation loss: 1.96835660037174

Epoch: 6| Step: 2
Training loss: 0.9659008383750916
Validation loss: 1.9640635418635544

Epoch: 6| Step: 3
Training loss: 1.0377329587936401
Validation loss: 1.907442590241791

Epoch: 6| Step: 4
Training loss: 1.2535629272460938
Validation loss: 1.8654394970145276

Epoch: 6| Step: 5
Training loss: 0.9939003586769104
Validation loss: 1.836274698216428

Epoch: 6| Step: 6
Training loss: 0.36836951971054077
Validation loss: 1.8048342248444915

Epoch: 6| Step: 7
Training loss: 0.9012412428855896
Validation loss: 1.7775315443674724

Epoch: 6| Step: 8
Training loss: 1.4453415870666504
Validation loss: 1.768912128222886

Epoch: 6| Step: 9
Training loss: 0.8956932425498962
Validation loss: 1.7639015848918627

Epoch: 6| Step: 10
Training loss: 1.1964818239212036
Validation loss: 1.7797710921174736

Epoch: 6| Step: 11
Training loss: 1.0931119918823242
Validation loss: 1.794958814497917

Epoch: 6| Step: 12
Training loss: 1.0214778184890747
Validation loss: 1.8218958634202198

Epoch: 6| Step: 13
Training loss: 1.3760032653808594
Validation loss: 1.8337378091709589

Epoch: 364| Step: 0
Training loss: 0.8100098371505737
Validation loss: 1.8639760978760258

Epoch: 6| Step: 1
Training loss: 1.2528629302978516
Validation loss: 1.8928162282513035

Epoch: 6| Step: 2
Training loss: 1.224529504776001
Validation loss: 1.8729299319687711

Epoch: 6| Step: 3
Training loss: 1.0036908388137817
Validation loss: 1.8511125720957273

Epoch: 6| Step: 4
Training loss: 0.7986738681793213
Validation loss: 1.8204269652725549

Epoch: 6| Step: 5
Training loss: 1.0930538177490234
Validation loss: 1.8210125148937266

Epoch: 6| Step: 6
Training loss: 0.6530537009239197
Validation loss: 1.8456948636680521

Epoch: 6| Step: 7
Training loss: 0.9320232272148132
Validation loss: 1.830284123779625

Epoch: 6| Step: 8
Training loss: 0.7968034744262695
Validation loss: 1.8481870120571506

Epoch: 6| Step: 9
Training loss: 1.9684319496154785
Validation loss: 1.8349174761003064

Epoch: 6| Step: 10
Training loss: 1.1510952711105347
Validation loss: 1.8281884090874785

Epoch: 6| Step: 11
Training loss: 1.3440080881118774
Validation loss: 1.825708463627805

Epoch: 6| Step: 12
Training loss: 0.9166489243507385
Validation loss: 1.8075110745686356

Epoch: 6| Step: 13
Training loss: 0.5128384828567505
Validation loss: 1.8162460750149143

Epoch: 365| Step: 0
Training loss: 0.905745267868042
Validation loss: 1.8552445519355036

Epoch: 6| Step: 1
Training loss: 0.8217686414718628
Validation loss: 1.871907300846551

Epoch: 6| Step: 2
Training loss: 1.1646099090576172
Validation loss: 1.864691480513542

Epoch: 6| Step: 3
Training loss: 0.9313311576843262
Validation loss: 1.9034180077173377

Epoch: 6| Step: 4
Training loss: 1.4202896356582642
Validation loss: 1.8874562658289427

Epoch: 6| Step: 5
Training loss: 1.308250904083252
Validation loss: 1.8989435139522757

Epoch: 6| Step: 6
Training loss: 0.8116226196289062
Validation loss: 1.865883437536096

Epoch: 6| Step: 7
Training loss: 0.978694498538971
Validation loss: 1.8322521730135846

Epoch: 6| Step: 8
Training loss: 0.8343437910079956
Validation loss: 1.8310217395905526

Epoch: 6| Step: 9
Training loss: 1.016479253768921
Validation loss: 1.7973195814317273

Epoch: 6| Step: 10
Training loss: 1.1169992685317993
Validation loss: 1.7751480828049362

Epoch: 6| Step: 11
Training loss: 1.2605128288269043
Validation loss: 1.7742366739498672

Epoch: 6| Step: 12
Training loss: 0.6708823442459106
Validation loss: 1.7611442765881937

Epoch: 6| Step: 13
Training loss: 1.1685302257537842
Validation loss: 1.7478358514847294

Epoch: 366| Step: 0
Training loss: 0.5014206171035767
Validation loss: 1.7602382193329513

Epoch: 6| Step: 1
Training loss: 1.05299711227417
Validation loss: 1.772303613283301

Epoch: 6| Step: 2
Training loss: 1.2568367719650269
Validation loss: 1.8084029843730312

Epoch: 6| Step: 3
Training loss: 0.7428926229476929
Validation loss: 1.8176488850706367

Epoch: 6| Step: 4
Training loss: 0.9680092930793762
Validation loss: 1.832476645387629

Epoch: 6| Step: 5
Training loss: 1.3366665840148926
Validation loss: 1.843302164026486

Epoch: 6| Step: 6
Training loss: 1.5388033390045166
Validation loss: 1.8418270182865921

Epoch: 6| Step: 7
Training loss: 1.3376491069793701
Validation loss: 1.8234123299198766

Epoch: 6| Step: 8
Training loss: 0.30624914169311523
Validation loss: 1.8088108647254206

Epoch: 6| Step: 9
Training loss: 0.7365752458572388
Validation loss: 1.8102348594255344

Epoch: 6| Step: 10
Training loss: 1.1109614372253418
Validation loss: 1.8238734852883123

Epoch: 6| Step: 11
Training loss: 1.0541774034500122
Validation loss: 1.8489831263019192

Epoch: 6| Step: 12
Training loss: 1.1749190092086792
Validation loss: 1.8561610226990075

Epoch: 6| Step: 13
Training loss: 1.2932106256484985
Validation loss: 1.880194261509885

Epoch: 367| Step: 0
Training loss: 1.2361423969268799
Validation loss: 1.847231053536938

Epoch: 6| Step: 1
Training loss: 1.1073613166809082
Validation loss: 1.8045551597431142

Epoch: 6| Step: 2
Training loss: 1.3180856704711914
Validation loss: 1.7551371615420106

Epoch: 6| Step: 3
Training loss: 0.7852577567100525
Validation loss: 1.7776841732763475

Epoch: 6| Step: 4
Training loss: 1.019620418548584
Validation loss: 1.7801730120053856

Epoch: 6| Step: 5
Training loss: 0.8187236785888672
Validation loss: 1.7837667952301681

Epoch: 6| Step: 6
Training loss: 1.3467164039611816
Validation loss: 1.8137521038773239

Epoch: 6| Step: 7
Training loss: 1.1079355478286743
Validation loss: 1.837286477447838

Epoch: 6| Step: 8
Training loss: 1.1045130491256714
Validation loss: 1.8689929785266999

Epoch: 6| Step: 9
Training loss: 0.7686281800270081
Validation loss: 1.911845031604972

Epoch: 6| Step: 10
Training loss: 1.1788508892059326
Validation loss: 1.9218525476353143

Epoch: 6| Step: 11
Training loss: 0.7516555190086365
Validation loss: 1.8464227414900256

Epoch: 6| Step: 12
Training loss: 0.898929238319397
Validation loss: 1.8637460700927242

Epoch: 6| Step: 13
Training loss: 0.766655683517456
Validation loss: 1.8085525510131673

Epoch: 368| Step: 0
Training loss: 1.418674111366272
Validation loss: 1.7701652024381904

Epoch: 6| Step: 1
Training loss: 0.7045202851295471
Validation loss: 1.7769349108460128

Epoch: 6| Step: 2
Training loss: 0.7988128662109375
Validation loss: 1.7966182667721984

Epoch: 6| Step: 3
Training loss: 1.2640633583068848
Validation loss: 1.7915078978384695

Epoch: 6| Step: 4
Training loss: 0.9458440542221069
Validation loss: 1.8183543759007608

Epoch: 6| Step: 5
Training loss: 1.4349365234375
Validation loss: 1.8134973728528587

Epoch: 6| Step: 6
Training loss: 0.7737271785736084
Validation loss: 1.8758325320418163

Epoch: 6| Step: 7
Training loss: 1.0054205656051636
Validation loss: 1.8912318637294154

Epoch: 6| Step: 8
Training loss: 0.667264997959137
Validation loss: 1.8771809993251678

Epoch: 6| Step: 9
Training loss: 1.0461878776550293
Validation loss: 1.9147988237360472

Epoch: 6| Step: 10
Training loss: 0.6640191078186035
Validation loss: 1.9315494491207985

Epoch: 6| Step: 11
Training loss: 1.172992467880249
Validation loss: 1.8786096246011796

Epoch: 6| Step: 12
Training loss: 1.2907689809799194
Validation loss: 1.8754460978251632

Epoch: 6| Step: 13
Training loss: 1.427502155303955
Validation loss: 1.8663726596422092

Epoch: 369| Step: 0
Training loss: 0.9585303068161011
Validation loss: 1.8319048445711854

Epoch: 6| Step: 1
Training loss: 0.9445699453353882
Validation loss: 1.828290202284372

Epoch: 6| Step: 2
Training loss: 1.390569806098938
Validation loss: 1.798886719570365

Epoch: 6| Step: 3
Training loss: 1.3290183544158936
Validation loss: 1.7851087867572744

Epoch: 6| Step: 4
Training loss: 1.0208203792572021
Validation loss: 1.760011351236733

Epoch: 6| Step: 5
Training loss: 0.6667112112045288
Validation loss: 1.7769326061330817

Epoch: 6| Step: 6
Training loss: 1.0349016189575195
Validation loss: 1.787818754872968

Epoch: 6| Step: 7
Training loss: 1.1180529594421387
Validation loss: 1.767610211526194

Epoch: 6| Step: 8
Training loss: 0.8709882497787476
Validation loss: 1.7766473793214368

Epoch: 6| Step: 9
Training loss: 0.7841048240661621
Validation loss: 1.7746800068886048

Epoch: 6| Step: 10
Training loss: 0.8516445159912109
Validation loss: 1.7785575697498937

Epoch: 6| Step: 11
Training loss: 1.3910653591156006
Validation loss: 1.7872578867020146

Epoch: 6| Step: 12
Training loss: 0.7171815633773804
Validation loss: 1.8112422445768952

Epoch: 6| Step: 13
Training loss: 0.35592126846313477
Validation loss: 1.8081205019386866

Epoch: 370| Step: 0
Training loss: 0.8795747756958008
Validation loss: 1.852798907987533

Epoch: 6| Step: 1
Training loss: 1.0344514846801758
Validation loss: 1.8490086063261955

Epoch: 6| Step: 2
Training loss: 1.463653802871704
Validation loss: 1.8855924144867928

Epoch: 6| Step: 3
Training loss: 1.2704875469207764
Validation loss: 1.8844705781629008

Epoch: 6| Step: 4
Training loss: 0.7249553203582764
Validation loss: 1.839108637584153

Epoch: 6| Step: 5
Training loss: 0.7046080231666565
Validation loss: 1.8285957638935377

Epoch: 6| Step: 6
Training loss: 0.9024247527122498
Validation loss: 1.78104648282451

Epoch: 6| Step: 7
Training loss: 0.9970215559005737
Validation loss: 1.789581730801572

Epoch: 6| Step: 8
Training loss: 0.8780788779258728
Validation loss: 1.7815283037001086

Epoch: 6| Step: 9
Training loss: 1.0770034790039062
Validation loss: 1.7608928526601484

Epoch: 6| Step: 10
Training loss: 0.9512993097305298
Validation loss: 1.774322461056453

Epoch: 6| Step: 11
Training loss: 1.1079643964767456
Validation loss: 1.7686393004591747

Epoch: 6| Step: 12
Training loss: 0.6236644387245178
Validation loss: 1.777731769828386

Epoch: 6| Step: 13
Training loss: 1.1334500312805176
Validation loss: 1.8129003317125383

Epoch: 371| Step: 0
Training loss: 0.6372021436691284
Validation loss: 1.839344592504604

Epoch: 6| Step: 1
Training loss: 0.8424527645111084
Validation loss: 1.8530757901489094

Epoch: 6| Step: 2
Training loss: 1.1639487743377686
Validation loss: 1.8719176887184061

Epoch: 6| Step: 3
Training loss: 1.0986875295639038
Validation loss: 1.8561276799889022

Epoch: 6| Step: 4
Training loss: 1.4602339267730713
Validation loss: 1.8260385003141177

Epoch: 6| Step: 5
Training loss: 1.260040044784546
Validation loss: 1.7873334448824647

Epoch: 6| Step: 6
Training loss: 0.910643458366394
Validation loss: 1.777969866670588

Epoch: 6| Step: 7
Training loss: 0.7878907322883606
Validation loss: 1.7319361984088857

Epoch: 6| Step: 8
Training loss: 0.6794387102127075
Validation loss: 1.7165266916316042

Epoch: 6| Step: 9
Training loss: 0.8753302097320557
Validation loss: 1.7321016621846024

Epoch: 6| Step: 10
Training loss: 0.934594452381134
Validation loss: 1.7404779195785522

Epoch: 6| Step: 11
Training loss: 0.9489040374755859
Validation loss: 1.758799414480886

Epoch: 6| Step: 12
Training loss: 1.1845731735229492
Validation loss: 1.7872415434929632

Epoch: 6| Step: 13
Training loss: 1.2890682220458984
Validation loss: 1.8610428558882846

Epoch: 372| Step: 0
Training loss: 0.919342041015625
Validation loss: 1.9254287647944626

Epoch: 6| Step: 1
Training loss: 1.0808931589126587
Validation loss: 1.9342199974162604

Epoch: 6| Step: 2
Training loss: 0.5963164567947388
Validation loss: 1.936114481700364

Epoch: 6| Step: 3
Training loss: 0.9324910640716553
Validation loss: 1.9239051418919717

Epoch: 6| Step: 4
Training loss: 0.9333738088607788
Validation loss: 1.9008969555618942

Epoch: 6| Step: 5
Training loss: 1.2468674182891846
Validation loss: 1.8197657318525418

Epoch: 6| Step: 6
Training loss: 0.7741919159889221
Validation loss: 1.7903922142521027

Epoch: 6| Step: 7
Training loss: 0.7718735933303833
Validation loss: 1.7484846179203322

Epoch: 6| Step: 8
Training loss: 1.4248051643371582
Validation loss: 1.7334954994981007

Epoch: 6| Step: 9
Training loss: 1.3045291900634766
Validation loss: 1.690345210413779

Epoch: 6| Step: 10
Training loss: 0.8543440699577332
Validation loss: 1.6987640088604343

Epoch: 6| Step: 11
Training loss: 0.8357837200164795
Validation loss: 1.693595645248249

Epoch: 6| Step: 12
Training loss: 1.2331159114837646
Validation loss: 1.7244992281800957

Epoch: 6| Step: 13
Training loss: 1.2129207849502563
Validation loss: 1.7729170527509464

Epoch: 373| Step: 0
Training loss: 0.7949063777923584
Validation loss: 1.7725616321768811

Epoch: 6| Step: 1
Training loss: 1.1875419616699219
Validation loss: 1.792023672852465

Epoch: 6| Step: 2
Training loss: 0.8707519769668579
Validation loss: 1.8314599670389646

Epoch: 6| Step: 3
Training loss: 1.1202716827392578
Validation loss: 1.867322378261115

Epoch: 6| Step: 4
Training loss: 0.9159063100814819
Validation loss: 1.8710782476650771

Epoch: 6| Step: 5
Training loss: 0.7616207003593445
Validation loss: 1.893830410895809

Epoch: 6| Step: 6
Training loss: 0.5350044369697571
Validation loss: 1.875958260669503

Epoch: 6| Step: 7
Training loss: 1.4637452363967896
Validation loss: 1.8701604796994118

Epoch: 6| Step: 8
Training loss: 1.3278684616088867
Validation loss: 1.8092063832026657

Epoch: 6| Step: 9
Training loss: 1.086127758026123
Validation loss: 1.8035996126872238

Epoch: 6| Step: 10
Training loss: 0.7044469118118286
Validation loss: 1.7973180342746038

Epoch: 6| Step: 11
Training loss: 0.7761086821556091
Validation loss: 1.7810243893695135

Epoch: 6| Step: 12
Training loss: 0.8268430829048157
Validation loss: 1.7925049399816861

Epoch: 6| Step: 13
Training loss: 1.1191699504852295
Validation loss: 1.7973421581329838

Epoch: 374| Step: 0
Training loss: 0.5230686664581299
Validation loss: 1.7770129794715552

Epoch: 6| Step: 1
Training loss: 0.8218179941177368
Validation loss: 1.797336645023797

Epoch: 6| Step: 2
Training loss: 0.9018166065216064
Validation loss: 1.76773371747745

Epoch: 6| Step: 3
Training loss: 1.1814627647399902
Validation loss: 1.8296437660853069

Epoch: 6| Step: 4
Training loss: 1.207658290863037
Validation loss: 1.7931040153708508

Epoch: 6| Step: 5
Training loss: 0.567507266998291
Validation loss: 1.8172423826750888

Epoch: 6| Step: 6
Training loss: 1.309445858001709
Validation loss: 1.819865490800591

Epoch: 6| Step: 7
Training loss: 0.1874636709690094
Validation loss: 1.8370211778148529

Epoch: 6| Step: 8
Training loss: 0.9129641056060791
Validation loss: 1.8352044705421693

Epoch: 6| Step: 9
Training loss: 1.3408691883087158
Validation loss: 1.8702667964402067

Epoch: 6| Step: 10
Training loss: 0.8935714960098267
Validation loss: 1.8761128533271052

Epoch: 6| Step: 11
Training loss: 0.9814347624778748
Validation loss: 1.8953778666834677

Epoch: 6| Step: 12
Training loss: 1.4429781436920166
Validation loss: 1.880762392474759

Epoch: 6| Step: 13
Training loss: 1.2748160362243652
Validation loss: 1.863751919038834

Epoch: 375| Step: 0
Training loss: 1.4036322832107544
Validation loss: 1.8096027553722422

Epoch: 6| Step: 1
Training loss: 0.7778328657150269
Validation loss: 1.8010630171786073

Epoch: 6| Step: 2
Training loss: 0.6704957485198975
Validation loss: 1.8052681517857376

Epoch: 6| Step: 3
Training loss: 1.009465217590332
Validation loss: 1.83262199612074

Epoch: 6| Step: 4
Training loss: 1.4498705863952637
Validation loss: 1.8139607188522175

Epoch: 6| Step: 5
Training loss: 1.168929100036621
Validation loss: 1.8267313395777056

Epoch: 6| Step: 6
Training loss: 1.7411024570465088
Validation loss: 1.8261848495852562

Epoch: 6| Step: 7
Training loss: 0.9825521111488342
Validation loss: 1.825683278422202

Epoch: 6| Step: 8
Training loss: 1.4011385440826416
Validation loss: 1.810271773287045

Epoch: 6| Step: 9
Training loss: 0.3391371965408325
Validation loss: 1.7981685156463294

Epoch: 6| Step: 10
Training loss: 0.6341897249221802
Validation loss: 1.7647865446664954

Epoch: 6| Step: 11
Training loss: 0.7047463655471802
Validation loss: 1.7402235410546745

Epoch: 6| Step: 12
Training loss: 0.641837477684021
Validation loss: 1.78076583339322

Epoch: 6| Step: 13
Training loss: 0.5230802297592163
Validation loss: 1.7936472700488182

Epoch: 376| Step: 0
Training loss: 1.2610950469970703
Validation loss: 1.8164187208298714

Epoch: 6| Step: 1
Training loss: 1.1585502624511719
Validation loss: 1.851692816262604

Epoch: 6| Step: 2
Training loss: 0.9173004031181335
Validation loss: 1.8568770347102996

Epoch: 6| Step: 3
Training loss: 0.7708841562271118
Validation loss: 1.8699637074624338

Epoch: 6| Step: 4
Training loss: 0.714877188205719
Validation loss: 1.8875388099301247

Epoch: 6| Step: 5
Training loss: 1.0881714820861816
Validation loss: 1.8715809442663704

Epoch: 6| Step: 6
Training loss: 0.49048298597335815
Validation loss: 1.8454863820024716

Epoch: 6| Step: 7
Training loss: 0.9259544610977173
Validation loss: 1.83604254645686

Epoch: 6| Step: 8
Training loss: 0.643872857093811
Validation loss: 1.8005158567941317

Epoch: 6| Step: 9
Training loss: 0.7835143804550171
Validation loss: 1.7916327663647231

Epoch: 6| Step: 10
Training loss: 0.9629926681518555
Validation loss: 1.7778526416388891

Epoch: 6| Step: 11
Training loss: 1.112499475479126
Validation loss: 1.7303384978284118

Epoch: 6| Step: 12
Training loss: 0.8169341087341309
Validation loss: 1.7569380562792543

Epoch: 6| Step: 13
Training loss: 2.0867319107055664
Validation loss: 1.784123069496565

Epoch: 377| Step: 0
Training loss: 1.009221076965332
Validation loss: 1.7881184777905863

Epoch: 6| Step: 1
Training loss: 0.7946915626525879
Validation loss: 1.8199247160265524

Epoch: 6| Step: 2
Training loss: 0.9998520612716675
Validation loss: 1.836323058733376

Epoch: 6| Step: 3
Training loss: 0.8517303466796875
Validation loss: 1.8521205725208405

Epoch: 6| Step: 4
Training loss: 0.8816677331924438
Validation loss: 1.8270866191515358

Epoch: 6| Step: 5
Training loss: 1.0434962511062622
Validation loss: 1.7822283955030545

Epoch: 6| Step: 6
Training loss: 1.289832353591919
Validation loss: 1.793712596739492

Epoch: 6| Step: 7
Training loss: 0.9568742513656616
Validation loss: 1.7784754409584949

Epoch: 6| Step: 8
Training loss: 0.6153472661972046
Validation loss: 1.7648833938824233

Epoch: 6| Step: 9
Training loss: 0.7662174701690674
Validation loss: 1.8202312454100578

Epoch: 6| Step: 10
Training loss: 0.8240988850593567
Validation loss: 1.8191021334740423

Epoch: 6| Step: 11
Training loss: 1.3668586015701294
Validation loss: 1.810705518209806

Epoch: 6| Step: 12
Training loss: 0.8033155202865601
Validation loss: 1.8649922455510786

Epoch: 6| Step: 13
Training loss: 0.950280487537384
Validation loss: 1.8462339780663932

Epoch: 378| Step: 0
Training loss: 0.42151421308517456
Validation loss: 1.841798263211404

Epoch: 6| Step: 1
Training loss: 1.0280569791793823
Validation loss: 1.8276131665834816

Epoch: 6| Step: 2
Training loss: 1.2718150615692139
Validation loss: 1.8370149648317726

Epoch: 6| Step: 3
Training loss: 1.8046555519104004
Validation loss: 1.797509075492941

Epoch: 6| Step: 4
Training loss: 0.8570669889450073
Validation loss: 1.7862457741973221

Epoch: 6| Step: 5
Training loss: 0.7909038066864014
Validation loss: 1.7620462038183724

Epoch: 6| Step: 6
Training loss: 1.2333124876022339
Validation loss: 1.782245405258671

Epoch: 6| Step: 7
Training loss: 0.9858895540237427
Validation loss: 1.7673262806348904

Epoch: 6| Step: 8
Training loss: 0.5394262075424194
Validation loss: 1.8296944479788504

Epoch: 6| Step: 9
Training loss: 1.0224374532699585
Validation loss: 1.8554672271974626

Epoch: 6| Step: 10
Training loss: 0.6531674265861511
Validation loss: 1.8212779247632591

Epoch: 6| Step: 11
Training loss: 0.7018744945526123
Validation loss: 1.8649353711835799

Epoch: 6| Step: 12
Training loss: 0.8252156972885132
Validation loss: 1.824771474766475

Epoch: 6| Step: 13
Training loss: 1.0399466753005981
Validation loss: 1.817145828277834

Epoch: 379| Step: 0
Training loss: 0.6274977326393127
Validation loss: 1.7750235014064337

Epoch: 6| Step: 1
Training loss: 0.7000834941864014
Validation loss: 1.8117633481179514

Epoch: 6| Step: 2
Training loss: 0.6835801601409912
Validation loss: 1.7975730908814298

Epoch: 6| Step: 3
Training loss: 1.2864723205566406
Validation loss: 1.7896341816071542

Epoch: 6| Step: 4
Training loss: 1.0978200435638428
Validation loss: 1.7984966360112673

Epoch: 6| Step: 5
Training loss: 1.0598582029342651
Validation loss: 1.8119853260696575

Epoch: 6| Step: 6
Training loss: 1.3067402839660645
Validation loss: 1.7762947864429925

Epoch: 6| Step: 7
Training loss: 0.5767840147018433
Validation loss: 1.7367051365554973

Epoch: 6| Step: 8
Training loss: 0.9245079159736633
Validation loss: 1.7453325563861477

Epoch: 6| Step: 9
Training loss: 0.8877288699150085
Validation loss: 1.7297456520859913

Epoch: 6| Step: 10
Training loss: 1.624725103378296
Validation loss: 1.726678127883583

Epoch: 6| Step: 11
Training loss: 0.6289772987365723
Validation loss: 1.7489376914116643

Epoch: 6| Step: 12
Training loss: 0.9134088754653931
Validation loss: 1.7521808160248624

Epoch: 6| Step: 13
Training loss: 0.8828549981117249
Validation loss: 1.7945106516602218

Epoch: 380| Step: 0
Training loss: 1.0153930187225342
Validation loss: 1.8016482873629498

Epoch: 6| Step: 1
Training loss: 0.8772491812705994
Validation loss: 1.8075242939815725

Epoch: 6| Step: 2
Training loss: 1.125054955482483
Validation loss: 1.8390220378034858

Epoch: 6| Step: 3
Training loss: 0.9563466310501099
Validation loss: 1.8379425207773845

Epoch: 6| Step: 4
Training loss: 0.941156268119812
Validation loss: 1.8001382402194444

Epoch: 6| Step: 5
Training loss: 0.951968252658844
Validation loss: 1.7946381261271815

Epoch: 6| Step: 6
Training loss: 0.5735220909118652
Validation loss: 1.8023679833258353

Epoch: 6| Step: 7
Training loss: 0.9580032229423523
Validation loss: 1.797209314120713

Epoch: 6| Step: 8
Training loss: 0.9924923181533813
Validation loss: 1.794292164105241

Epoch: 6| Step: 9
Training loss: 1.3925141096115112
Validation loss: 1.793575345828969

Epoch: 6| Step: 10
Training loss: 0.5012699365615845
Validation loss: 1.7931707033547022

Epoch: 6| Step: 11
Training loss: 1.26111900806427
Validation loss: 1.7902900749637234

Epoch: 6| Step: 12
Training loss: 1.1026101112365723
Validation loss: 1.7265170851061422

Epoch: 6| Step: 13
Training loss: 0.7643598318099976
Validation loss: 1.7329143157569311

Epoch: 381| Step: 0
Training loss: 0.9135710000991821
Validation loss: 1.7015836033769833

Epoch: 6| Step: 1
Training loss: 0.6063305735588074
Validation loss: 1.6941718683447888

Epoch: 6| Step: 2
Training loss: 1.2240632772445679
Validation loss: 1.7423624466824275

Epoch: 6| Step: 3
Training loss: 0.9200248718261719
Validation loss: 1.802747134239443

Epoch: 6| Step: 4
Training loss: 0.8651089668273926
Validation loss: 1.808832101924445

Epoch: 6| Step: 5
Training loss: 0.724355936050415
Validation loss: 1.8627648174121816

Epoch: 6| Step: 6
Training loss: 1.0985718965530396
Validation loss: 1.8689299885944655

Epoch: 6| Step: 7
Training loss: 1.2174607515335083
Validation loss: 1.8841478273432741

Epoch: 6| Step: 8
Training loss: 0.6092180013656616
Validation loss: 1.8662597748541063

Epoch: 6| Step: 9
Training loss: 1.0712687969207764
Validation loss: 1.833915219512037

Epoch: 6| Step: 10
Training loss: 1.2760396003723145
Validation loss: 1.7961875354090044

Epoch: 6| Step: 11
Training loss: 0.9746812582015991
Validation loss: 1.7695655284389373

Epoch: 6| Step: 12
Training loss: 0.7295960187911987
Validation loss: 1.7679280388739802

Epoch: 6| Step: 13
Training loss: 1.0671650171279907
Validation loss: 1.7937384126006917

Epoch: 382| Step: 0
Training loss: 0.8386644124984741
Validation loss: 1.7594652201539727

Epoch: 6| Step: 1
Training loss: 1.110065221786499
Validation loss: 1.7611676595544303

Epoch: 6| Step: 2
Training loss: 0.9359232187271118
Validation loss: 1.7689238325242074

Epoch: 6| Step: 3
Training loss: 0.8508641719818115
Validation loss: 1.7770828777743923

Epoch: 6| Step: 4
Training loss: 0.907895565032959
Validation loss: 1.8270703720790085

Epoch: 6| Step: 5
Training loss: 0.5588980913162231
Validation loss: 1.8587765386027675

Epoch: 6| Step: 6
Training loss: 1.1684725284576416
Validation loss: 1.8538969819263746

Epoch: 6| Step: 7
Training loss: 0.8006422519683838
Validation loss: 1.8780620803115189

Epoch: 6| Step: 8
Training loss: 0.8982950448989868
Validation loss: 1.873826922908906

Epoch: 6| Step: 9
Training loss: 0.8234712481498718
Validation loss: 1.8767880188521517

Epoch: 6| Step: 10
Training loss: 1.2472927570343018
Validation loss: 1.832237474380001

Epoch: 6| Step: 11
Training loss: 1.0069715976715088
Validation loss: 1.7977335081305554

Epoch: 6| Step: 12
Training loss: 0.9331604838371277
Validation loss: 1.8412131673546248

Epoch: 6| Step: 13
Training loss: 0.9450485706329346
Validation loss: 1.8063956396554106

Epoch: 383| Step: 0
Training loss: 0.8192747831344604
Validation loss: 1.7878836431810934

Epoch: 6| Step: 1
Training loss: 1.1411001682281494
Validation loss: 1.7959451906142696

Epoch: 6| Step: 2
Training loss: 0.8827313184738159
Validation loss: 1.7786300438706593

Epoch: 6| Step: 3
Training loss: 0.8188187479972839
Validation loss: 1.800832579212804

Epoch: 6| Step: 4
Training loss: 0.6539166569709778
Validation loss: 1.754847829059888

Epoch: 6| Step: 5
Training loss: 1.0313992500305176
Validation loss: 1.7678791758834675

Epoch: 6| Step: 6
Training loss: 0.9806777834892273
Validation loss: 1.7883433193288825

Epoch: 6| Step: 7
Training loss: 0.7099441289901733
Validation loss: 1.7891226994094027

Epoch: 6| Step: 8
Training loss: 1.0825259685516357
Validation loss: 1.8009869103790612

Epoch: 6| Step: 9
Training loss: 1.1173670291900635
Validation loss: 1.8115460654740692

Epoch: 6| Step: 10
Training loss: 0.6707285642623901
Validation loss: 1.81736090747259

Epoch: 6| Step: 11
Training loss: 0.7453876733779907
Validation loss: 1.7819072251678796

Epoch: 6| Step: 12
Training loss: 1.1767826080322266
Validation loss: 1.779560624912221

Epoch: 6| Step: 13
Training loss: 0.9571823477745056
Validation loss: 1.7969372798037786

Epoch: 384| Step: 0
Training loss: 1.002845048904419
Validation loss: 1.783410720927741

Epoch: 6| Step: 1
Training loss: 1.1597633361816406
Validation loss: 1.7866064527983307

Epoch: 6| Step: 2
Training loss: 1.6352550983428955
Validation loss: 1.7709134471031927

Epoch: 6| Step: 3
Training loss: 0.49950799345970154
Validation loss: 1.7716899751335062

Epoch: 6| Step: 4
Training loss: 1.0880494117736816
Validation loss: 1.76377833274103

Epoch: 6| Step: 5
Training loss: 0.8746957778930664
Validation loss: 1.7381630277120939

Epoch: 6| Step: 6
Training loss: 0.6162732839584351
Validation loss: 1.7475938848269883

Epoch: 6| Step: 7
Training loss: 0.6892073154449463
Validation loss: 1.7388349386953539

Epoch: 6| Step: 8
Training loss: 1.1334798336029053
Validation loss: 1.7532200608202206

Epoch: 6| Step: 9
Training loss: 0.7059484720230103
Validation loss: 1.782290042087596

Epoch: 6| Step: 10
Training loss: 0.6339536905288696
Validation loss: 1.7976693312327068

Epoch: 6| Step: 11
Training loss: 1.070188283920288
Validation loss: 1.842847345977701

Epoch: 6| Step: 12
Training loss: 0.7913140058517456
Validation loss: 1.8318552663249354

Epoch: 6| Step: 13
Training loss: 0.5159538984298706
Validation loss: 1.8321917915856967

Epoch: 385| Step: 0
Training loss: 0.7827747464179993
Validation loss: 1.8323025024065407

Epoch: 6| Step: 1
Training loss: 0.8726158738136292
Validation loss: 1.8240923125256774

Epoch: 6| Step: 2
Training loss: 0.8382568359375
Validation loss: 1.8179852001128658

Epoch: 6| Step: 3
Training loss: 1.4295778274536133
Validation loss: 1.7501406464525449

Epoch: 6| Step: 4
Training loss: 0.8833013772964478
Validation loss: 1.7461449407762097

Epoch: 6| Step: 5
Training loss: 1.0881291627883911
Validation loss: 1.7614082264643844

Epoch: 6| Step: 6
Training loss: 1.1319687366485596
Validation loss: 1.7628332056025022

Epoch: 6| Step: 7
Training loss: 0.7206568717956543
Validation loss: 1.7661875806828982

Epoch: 6| Step: 8
Training loss: 0.874542236328125
Validation loss: 1.8222277843823997

Epoch: 6| Step: 9
Training loss: 0.5966615676879883
Validation loss: 1.8347099737454486

Epoch: 6| Step: 10
Training loss: 0.7911977767944336
Validation loss: 1.8634487249517953

Epoch: 6| Step: 11
Training loss: 0.7642867565155029
Validation loss: 1.8805058528018255

Epoch: 6| Step: 12
Training loss: 1.0525108575820923
Validation loss: 1.8925931530614053

Epoch: 6| Step: 13
Training loss: 0.8802044987678528
Validation loss: 1.8818140798999416

Epoch: 386| Step: 0
Training loss: 0.629384458065033
Validation loss: 1.8470113674799602

Epoch: 6| Step: 1
Training loss: 0.705217719078064
Validation loss: 1.8371929302010486

Epoch: 6| Step: 2
Training loss: 1.06778085231781
Validation loss: 1.819234210957763

Epoch: 6| Step: 3
Training loss: 1.025996208190918
Validation loss: 1.7572044082867202

Epoch: 6| Step: 4
Training loss: 0.79327392578125
Validation loss: 1.7406748212793821

Epoch: 6| Step: 5
Training loss: 0.8320251703262329
Validation loss: 1.7154541400171095

Epoch: 6| Step: 6
Training loss: 1.1732916831970215
Validation loss: 1.7343475536633564

Epoch: 6| Step: 7
Training loss: 1.092987060546875
Validation loss: 1.713489079988131

Epoch: 6| Step: 8
Training loss: 0.6226261258125305
Validation loss: 1.727199872334798

Epoch: 6| Step: 9
Training loss: 1.0650420188903809
Validation loss: 1.7479687095970236

Epoch: 6| Step: 10
Training loss: 1.163853406906128
Validation loss: 1.7944745761091991

Epoch: 6| Step: 11
Training loss: 0.9824793338775635
Validation loss: 1.8372723902425458

Epoch: 6| Step: 12
Training loss: 0.9120912551879883
Validation loss: 1.8408843753158406

Epoch: 6| Step: 13
Training loss: 0.5328444242477417
Validation loss: 1.8655257148127402

Epoch: 387| Step: 0
Training loss: 1.0137144327163696
Validation loss: 1.8754664467227073

Epoch: 6| Step: 1
Training loss: 0.80191969871521
Validation loss: 1.8388679219830422

Epoch: 6| Step: 2
Training loss: 0.8098405599594116
Validation loss: 1.8067743637228524

Epoch: 6| Step: 3
Training loss: 0.30637630820274353
Validation loss: 1.773270631349215

Epoch: 6| Step: 4
Training loss: 0.6560840010643005
Validation loss: 1.7018452203401955

Epoch: 6| Step: 5
Training loss: 0.8583487272262573
Validation loss: 1.686422351867922

Epoch: 6| Step: 6
Training loss: 0.8809455037117004
Validation loss: 1.7155936623132357

Epoch: 6| Step: 7
Training loss: 1.53250253200531
Validation loss: 1.6953340281722367

Epoch: 6| Step: 8
Training loss: 1.1217002868652344
Validation loss: 1.6999855451686408

Epoch: 6| Step: 9
Training loss: 1.0822908878326416
Validation loss: 1.7421756918712328

Epoch: 6| Step: 10
Training loss: 0.8941236138343811
Validation loss: 1.77816758360914

Epoch: 6| Step: 11
Training loss: 1.019773244857788
Validation loss: 1.8147542809927335

Epoch: 6| Step: 12
Training loss: 0.9440191984176636
Validation loss: 1.8173122713642735

Epoch: 6| Step: 13
Training loss: 0.8173959255218506
Validation loss: 1.7862825880768478

Epoch: 388| Step: 0
Training loss: 0.850496768951416
Validation loss: 1.8254930998689385

Epoch: 6| Step: 1
Training loss: 0.9802940487861633
Validation loss: 1.7828494976925593

Epoch: 6| Step: 2
Training loss: 0.6556539535522461
Validation loss: 1.7586327746350279

Epoch: 6| Step: 3
Training loss: 0.8403059244155884
Validation loss: 1.8051832183714835

Epoch: 6| Step: 4
Training loss: 1.2146378755569458
Validation loss: 1.7636540500066613

Epoch: 6| Step: 5
Training loss: 0.5187935829162598
Validation loss: 1.7655589349808232

Epoch: 6| Step: 6
Training loss: 0.8320908546447754
Validation loss: 1.7550135594542309

Epoch: 6| Step: 7
Training loss: 0.6103969812393188
Validation loss: 1.7611401927086614

Epoch: 6| Step: 8
Training loss: 1.2270429134368896
Validation loss: 1.7475881204810193

Epoch: 6| Step: 9
Training loss: 0.43358874320983887
Validation loss: 1.6978814153261081

Epoch: 6| Step: 10
Training loss: 0.9038608074188232
Validation loss: 1.7176396103315457

Epoch: 6| Step: 11
Training loss: 0.9082847237586975
Validation loss: 1.745585923553795

Epoch: 6| Step: 12
Training loss: 1.2728257179260254
Validation loss: 1.7883477441726192

Epoch: 6| Step: 13
Training loss: 1.3748489618301392
Validation loss: 1.8156797629530712

Epoch: 389| Step: 0
Training loss: 0.7285659313201904
Validation loss: 1.8482102604322537

Epoch: 6| Step: 1
Training loss: 1.1783428192138672
Validation loss: 1.844872631052489

Epoch: 6| Step: 2
Training loss: 0.8202951550483704
Validation loss: 1.8186361007792975

Epoch: 6| Step: 3
Training loss: 1.0803158283233643
Validation loss: 1.7808462547999557

Epoch: 6| Step: 4
Training loss: 0.8480865955352783
Validation loss: 1.7753236409156554

Epoch: 6| Step: 5
Training loss: 1.4329521656036377
Validation loss: 1.73775698549004

Epoch: 6| Step: 6
Training loss: 0.6783151626586914
Validation loss: 1.690310142373526

Epoch: 6| Step: 7
Training loss: 0.8116236329078674
Validation loss: 1.7152850204898464

Epoch: 6| Step: 8
Training loss: 0.6997464895248413
Validation loss: 1.7174532849301574

Epoch: 6| Step: 9
Training loss: 0.9138914346694946
Validation loss: 1.7133499191653343

Epoch: 6| Step: 10
Training loss: 0.6389431953430176
Validation loss: 1.7278434807254421

Epoch: 6| Step: 11
Training loss: 0.8096207976341248
Validation loss: 1.7830383405890515

Epoch: 6| Step: 12
Training loss: 1.2779741287231445
Validation loss: 1.7921330108437488

Epoch: 6| Step: 13
Training loss: 0.6848552227020264
Validation loss: 1.8508031714347102

Epoch: 390| Step: 0
Training loss: 1.0766314268112183
Validation loss: 1.8810557985818515

Epoch: 6| Step: 1
Training loss: 0.7460115551948547
Validation loss: 1.90555699025431

Epoch: 6| Step: 2
Training loss: 1.339219093322754
Validation loss: 1.9021924054750832

Epoch: 6| Step: 3
Training loss: 0.772990345954895
Validation loss: 1.8526820751928514

Epoch: 6| Step: 4
Training loss: 0.7635353207588196
Validation loss: 1.8221222110973891

Epoch: 6| Step: 5
Training loss: 0.8391245007514954
Validation loss: 1.802249135509614

Epoch: 6| Step: 6
Training loss: 1.0173581838607788
Validation loss: 1.7574300817264024

Epoch: 6| Step: 7
Training loss: 0.6899275779724121
Validation loss: 1.745135393193973

Epoch: 6| Step: 8
Training loss: 0.8534952402114868
Validation loss: 1.7302971360503987

Epoch: 6| Step: 9
Training loss: 0.6696128845214844
Validation loss: 1.746531299365464

Epoch: 6| Step: 10
Training loss: 0.716389536857605
Validation loss: 1.7560793763847762

Epoch: 6| Step: 11
Training loss: 0.8132004141807556
Validation loss: 1.7267708483562674

Epoch: 6| Step: 12
Training loss: 0.9712571501731873
Validation loss: 1.719629168510437

Epoch: 6| Step: 13
Training loss: 1.2157549858093262
Validation loss: 1.698269533854659

Epoch: 391| Step: 0
Training loss: 0.7640426158905029
Validation loss: 1.6829984149625223

Epoch: 6| Step: 1
Training loss: 0.8592255115509033
Validation loss: 1.6998303346736456

Epoch: 6| Step: 2
Training loss: 1.031404733657837
Validation loss: 1.740771734586326

Epoch: 6| Step: 3
Training loss: 0.8012351393699646
Validation loss: 1.742174502341978

Epoch: 6| Step: 4
Training loss: 0.5204795598983765
Validation loss: 1.7344141442288634

Epoch: 6| Step: 5
Training loss: 1.0715689659118652
Validation loss: 1.7705609029339207

Epoch: 6| Step: 6
Training loss: 0.6453019380569458
Validation loss: 1.7385290720129525

Epoch: 6| Step: 7
Training loss: 1.277336835861206
Validation loss: 1.7761269923179381

Epoch: 6| Step: 8
Training loss: 0.559235692024231
Validation loss: 1.7727120563548098

Epoch: 6| Step: 9
Training loss: 0.6663377285003662
Validation loss: 1.80033907839047

Epoch: 6| Step: 10
Training loss: 1.1484365463256836
Validation loss: 1.8009675138740129

Epoch: 6| Step: 11
Training loss: 1.377002239227295
Validation loss: 1.8430255830928843

Epoch: 6| Step: 12
Training loss: 0.5041788816452026
Validation loss: 1.82258217693657

Epoch: 6| Step: 13
Training loss: 1.6013349294662476
Validation loss: 1.774247955891394

Epoch: 392| Step: 0
Training loss: 0.9991694688796997
Validation loss: 1.7511644260857695

Epoch: 6| Step: 1
Training loss: 0.8643859624862671
Validation loss: 1.7102294378383185

Epoch: 6| Step: 2
Training loss: 0.8266732096672058
Validation loss: 1.6804973233130671

Epoch: 6| Step: 3
Training loss: 1.053430199623108
Validation loss: 1.6508450713208926

Epoch: 6| Step: 4
Training loss: 0.8195773363113403
Validation loss: 1.6494346626343266

Epoch: 6| Step: 5
Training loss: 0.9529599547386169
Validation loss: 1.691673945355159

Epoch: 6| Step: 6
Training loss: 0.8770857453346252
Validation loss: 1.7414294083913167

Epoch: 6| Step: 7
Training loss: 1.1083658933639526
Validation loss: 1.7823041959475445

Epoch: 6| Step: 8
Training loss: 0.38723224401474
Validation loss: 1.8219411578229678

Epoch: 6| Step: 9
Training loss: 1.2522341012954712
Validation loss: 1.8730251020000828

Epoch: 6| Step: 10
Training loss: 0.8439405560493469
Validation loss: 1.8948852310898483

Epoch: 6| Step: 11
Training loss: 1.0006451606750488
Validation loss: 1.9105005956465198

Epoch: 6| Step: 12
Training loss: 0.8383394479751587
Validation loss: 1.865812929727698

Epoch: 6| Step: 13
Training loss: 0.7846118211746216
Validation loss: 1.8375944783610683

Epoch: 393| Step: 0
Training loss: 0.8608628511428833
Validation loss: 1.782361327960927

Epoch: 6| Step: 1
Training loss: 1.4095888137817383
Validation loss: 1.773029855502549

Epoch: 6| Step: 2
Training loss: 0.8956310749053955
Validation loss: 1.7286924277582476

Epoch: 6| Step: 3
Training loss: 0.7879807949066162
Validation loss: 1.7187753531240648

Epoch: 6| Step: 4
Training loss: 0.831506609916687
Validation loss: 1.7088450013950307

Epoch: 6| Step: 5
Training loss: 0.6562137007713318
Validation loss: 1.7482529917070944

Epoch: 6| Step: 6
Training loss: 1.2418828010559082
Validation loss: 1.7586567760795675

Epoch: 6| Step: 7
Training loss: 1.1143267154693604
Validation loss: 1.7427745570418656

Epoch: 6| Step: 8
Training loss: 0.9780093431472778
Validation loss: 1.8082065184911091

Epoch: 6| Step: 9
Training loss: 0.7815967798233032
Validation loss: 1.8085947703289729

Epoch: 6| Step: 10
Training loss: 0.27807220816612244
Validation loss: 1.8319977521896362

Epoch: 6| Step: 11
Training loss: 0.8955545425415039
Validation loss: 1.8390060688859673

Epoch: 6| Step: 12
Training loss: 0.8041967153549194
Validation loss: 1.8687679600972

Epoch: 6| Step: 13
Training loss: 0.7938727140426636
Validation loss: 1.844624678293864

Epoch: 394| Step: 0
Training loss: 0.9623715281486511
Validation loss: 1.8421076882270075

Epoch: 6| Step: 1
Training loss: 0.4842076301574707
Validation loss: 1.8351526747467697

Epoch: 6| Step: 2
Training loss: 0.9017320275306702
Validation loss: 1.8125734175405195

Epoch: 6| Step: 3
Training loss: 0.7972691059112549
Validation loss: 1.7889169800666072

Epoch: 6| Step: 4
Training loss: 0.7660928964614868
Validation loss: 1.7618050549619941

Epoch: 6| Step: 5
Training loss: 1.058213233947754
Validation loss: 1.7534876074842227

Epoch: 6| Step: 6
Training loss: 0.8474263548851013
Validation loss: 1.7354865804795296

Epoch: 6| Step: 7
Training loss: 0.8125898838043213
Validation loss: 1.7400585169433265

Epoch: 6| Step: 8
Training loss: 1.1502246856689453
Validation loss: 1.7518961634687198

Epoch: 6| Step: 9
Training loss: 0.933161735534668
Validation loss: 1.7098552309056765

Epoch: 6| Step: 10
Training loss: 0.6009043455123901
Validation loss: 1.6922988686510312

Epoch: 6| Step: 11
Training loss: 0.5785194635391235
Validation loss: 1.6578573039782944

Epoch: 6| Step: 12
Training loss: 0.9932612180709839
Validation loss: 1.6629503760286557

Epoch: 6| Step: 13
Training loss: 1.2847304344177246
Validation loss: 1.6707596073868454

Epoch: 395| Step: 0
Training loss: 0.8411669731140137
Validation loss: 1.6587069752395793

Epoch: 6| Step: 1
Training loss: 0.9021235108375549
Validation loss: 1.6509085060447775

Epoch: 6| Step: 2
Training loss: 1.024261474609375
Validation loss: 1.7192068343521447

Epoch: 6| Step: 3
Training loss: 0.6241201758384705
Validation loss: 1.7049100527199366

Epoch: 6| Step: 4
Training loss: 0.8549274206161499
Validation loss: 1.7506478383976927

Epoch: 6| Step: 5
Training loss: 0.6444171667098999
Validation loss: 1.7763828949261737

Epoch: 6| Step: 6
Training loss: 0.7670661211013794
Validation loss: 1.8040925994996102

Epoch: 6| Step: 7
Training loss: 0.9208879470825195
Validation loss: 1.828784978517922

Epoch: 6| Step: 8
Training loss: 0.7533649206161499
Validation loss: 1.8207532769890242

Epoch: 6| Step: 9
Training loss: 0.7581455111503601
Validation loss: 1.8315693204120924

Epoch: 6| Step: 10
Training loss: 0.8557127714157104
Validation loss: 1.8324773619251866

Epoch: 6| Step: 11
Training loss: 0.8996231555938721
Validation loss: 1.7839220980162263

Epoch: 6| Step: 12
Training loss: 1.3674390316009521
Validation loss: 1.737336984244726

Epoch: 6| Step: 13
Training loss: 0.9602510929107666
Validation loss: 1.6946208477020264

Epoch: 396| Step: 0
Training loss: 0.873882532119751
Validation loss: 1.6609459077158282

Epoch: 6| Step: 1
Training loss: 0.6627929210662842
Validation loss: 1.6635748827329246

Epoch: 6| Step: 2
Training loss: 1.0302605628967285
Validation loss: 1.6457472155171056

Epoch: 6| Step: 3
Training loss: 0.7407373785972595
Validation loss: 1.6608587003523303

Epoch: 6| Step: 4
Training loss: 0.7630709409713745
Validation loss: 1.652219344210881

Epoch: 6| Step: 5
Training loss: 1.0331398248672485
Validation loss: 1.6747431729429512

Epoch: 6| Step: 6
Training loss: 0.888885498046875
Validation loss: 1.691808387797366

Epoch: 6| Step: 7
Training loss: 0.9344407320022583
Validation loss: 1.7280616426980624

Epoch: 6| Step: 8
Training loss: 0.6659952402114868
Validation loss: 1.7649612272939375

Epoch: 6| Step: 9
Training loss: 1.124588966369629
Validation loss: 1.8272006819325108

Epoch: 6| Step: 10
Training loss: 0.7081500291824341
Validation loss: 1.8808707729462655

Epoch: 6| Step: 11
Training loss: 0.8344898819923401
Validation loss: 1.8931044301679056

Epoch: 6| Step: 12
Training loss: 0.9164604544639587
Validation loss: 1.8853182946482012

Epoch: 6| Step: 13
Training loss: 1.4286229610443115
Validation loss: 1.8586818274631296

Epoch: 397| Step: 0
Training loss: 1.0898703336715698
Validation loss: 1.7788235231112408

Epoch: 6| Step: 1
Training loss: 0.7602293491363525
Validation loss: 1.7651617039916336

Epoch: 6| Step: 2
Training loss: 0.7156201601028442
Validation loss: 1.6961107959029496

Epoch: 6| Step: 3
Training loss: 1.2901893854141235
Validation loss: 1.6802071845659645

Epoch: 6| Step: 4
Training loss: 0.6793856620788574
Validation loss: 1.6731805442481913

Epoch: 6| Step: 5
Training loss: 1.0553474426269531
Validation loss: 1.64262040199772

Epoch: 6| Step: 6
Training loss: 0.7837868332862854
Validation loss: 1.666040289786554

Epoch: 6| Step: 7
Training loss: 0.7970793843269348
Validation loss: 1.6661546807135306

Epoch: 6| Step: 8
Training loss: 0.5356966853141785
Validation loss: 1.6912514535329675

Epoch: 6| Step: 9
Training loss: 0.899395227432251
Validation loss: 1.7123385270436604

Epoch: 6| Step: 10
Training loss: 1.1044504642486572
Validation loss: 1.737647009152238

Epoch: 6| Step: 11
Training loss: 0.3420073091983795
Validation loss: 1.7509059841914842

Epoch: 6| Step: 12
Training loss: 0.8000439405441284
Validation loss: 1.766200170722059

Epoch: 6| Step: 13
Training loss: 1.535108208656311
Validation loss: 1.7821408702481178

Epoch: 398| Step: 0
Training loss: 0.8877030611038208
Validation loss: 1.7683469646720475

Epoch: 6| Step: 1
Training loss: 0.6182994842529297
Validation loss: 1.747391257234799

Epoch: 6| Step: 2
Training loss: 0.7508246302604675
Validation loss: 1.7084282354641986

Epoch: 6| Step: 3
Training loss: 0.5445927381515503
Validation loss: 1.7314442537164176

Epoch: 6| Step: 4
Training loss: 1.10236394405365
Validation loss: 1.7348727077566168

Epoch: 6| Step: 5
Training loss: 0.8326308131217957
Validation loss: 1.7230125678482877

Epoch: 6| Step: 6
Training loss: 1.070682168006897
Validation loss: 1.7225391223866453

Epoch: 6| Step: 7
Training loss: 1.089958667755127
Validation loss: 1.7092506449709657

Epoch: 6| Step: 8
Training loss: 0.9532923698425293
Validation loss: 1.7067430070651475

Epoch: 6| Step: 9
Training loss: 0.8634489178657532
Validation loss: 1.7298688939822617

Epoch: 6| Step: 10
Training loss: 0.49160459637641907
Validation loss: 1.7345432619894705

Epoch: 6| Step: 11
Training loss: 0.7294695377349854
Validation loss: 1.716344871828633

Epoch: 6| Step: 12
Training loss: 0.8448584079742432
Validation loss: 1.7241945933270197

Epoch: 6| Step: 13
Training loss: 0.6666896343231201
Validation loss: 1.72561760487095

Epoch: 399| Step: 0
Training loss: 0.8400588035583496
Validation loss: 1.7689316183008172

Epoch: 6| Step: 1
Training loss: 0.8104938864707947
Validation loss: 1.772007155162032

Epoch: 6| Step: 2
Training loss: 0.8485924601554871
Validation loss: 1.7891870583257368

Epoch: 6| Step: 3
Training loss: 1.2262593507766724
Validation loss: 1.7913586631897958

Epoch: 6| Step: 4
Training loss: 0.9451647996902466
Validation loss: 1.8044224131491877

Epoch: 6| Step: 5
Training loss: 1.235597848892212
Validation loss: 1.78943072852268

Epoch: 6| Step: 6
Training loss: 1.1216497421264648
Validation loss: 1.761966041339341

Epoch: 6| Step: 7
Training loss: 0.5612302422523499
Validation loss: 1.722668081201533

Epoch: 6| Step: 8
Training loss: 0.697541356086731
Validation loss: 1.7103348829412972

Epoch: 6| Step: 9
Training loss: 0.6638771295547485
Validation loss: 1.692983499137304

Epoch: 6| Step: 10
Training loss: 0.7670390605926514
Validation loss: 1.6803584842271702

Epoch: 6| Step: 11
Training loss: 0.4976617395877838
Validation loss: 1.6520446039015246

Epoch: 6| Step: 12
Training loss: 0.42741453647613525
Validation loss: 1.6465820625264158

Epoch: 6| Step: 13
Training loss: 1.0188082456588745
Validation loss: 1.6658744158283356

Epoch: 400| Step: 0
Training loss: 0.6814483404159546
Validation loss: 1.7006954813516268

Epoch: 6| Step: 1
Training loss: 0.7047714591026306
Validation loss: 1.7121785404861614

Epoch: 6| Step: 2
Training loss: 1.217705488204956
Validation loss: 1.763033842527738

Epoch: 6| Step: 3
Training loss: 0.93865966796875
Validation loss: 1.7902074295987365

Epoch: 6| Step: 4
Training loss: 0.883672297000885
Validation loss: 1.770485540871979

Epoch: 6| Step: 5
Training loss: 0.7378101348876953
Validation loss: 1.760154107565521

Epoch: 6| Step: 6
Training loss: 0.6854366064071655
Validation loss: 1.7692703367561422

Epoch: 6| Step: 7
Training loss: 0.7072188258171082
Validation loss: 1.7580442108133787

Epoch: 6| Step: 8
Training loss: 0.7019116878509521
Validation loss: 1.7695922915653517

Epoch: 6| Step: 9
Training loss: 0.7699350714683533
Validation loss: 1.7290462088841263

Epoch: 6| Step: 10
Training loss: 0.929703950881958
Validation loss: 1.7220869154058478

Epoch: 6| Step: 11
Training loss: 0.6459917426109314
Validation loss: 1.7196468499399

Epoch: 6| Step: 12
Training loss: 0.7490501403808594
Validation loss: 1.7113621029802548

Epoch: 6| Step: 13
Training loss: 1.7439048290252686
Validation loss: 1.6991411255251976

Epoch: 401| Step: 0
Training loss: 0.32093486189842224
Validation loss: 1.699260889842946

Epoch: 6| Step: 1
Training loss: 0.8183557987213135
Validation loss: 1.687335511689545

Epoch: 6| Step: 2
Training loss: 1.0149080753326416
Validation loss: 1.6872016588846843

Epoch: 6| Step: 3
Training loss: 0.7606798410415649
Validation loss: 1.7182804666539675

Epoch: 6| Step: 4
Training loss: 0.3530281186103821
Validation loss: 1.7129628927476945

Epoch: 6| Step: 5
Training loss: 0.781955361366272
Validation loss: 1.7168265709313013

Epoch: 6| Step: 6
Training loss: 0.5530933141708374
Validation loss: 1.7726427457665885

Epoch: 6| Step: 7
Training loss: 0.9125875234603882
Validation loss: 1.7781931841245262

Epoch: 6| Step: 8
Training loss: 1.2102389335632324
Validation loss: 1.7853854035818448

Epoch: 6| Step: 9
Training loss: 0.7373927235603333
Validation loss: 1.7352734893880866

Epoch: 6| Step: 10
Training loss: 0.8141865134239197
Validation loss: 1.7756070103696597

Epoch: 6| Step: 11
Training loss: 0.8928012847900391
Validation loss: 1.7390334554897842

Epoch: 6| Step: 12
Training loss: 1.3763865232467651
Validation loss: 1.7308774571264944

Epoch: 6| Step: 13
Training loss: 1.1171400547027588
Validation loss: 1.7169511305388583

Epoch: 402| Step: 0
Training loss: 1.142048954963684
Validation loss: 1.6874170610981603

Epoch: 6| Step: 1
Training loss: 0.6773391366004944
Validation loss: 1.677292549481956

Epoch: 6| Step: 2
Training loss: 1.387483835220337
Validation loss: 1.7030212097270514

Epoch: 6| Step: 3
Training loss: 0.5571068525314331
Validation loss: 1.7081474040144233

Epoch: 6| Step: 4
Training loss: 0.540651798248291
Validation loss: 1.7050586579948344

Epoch: 6| Step: 5
Training loss: 0.4767201542854309
Validation loss: 1.7050577658478931

Epoch: 6| Step: 6
Training loss: 1.0880401134490967
Validation loss: 1.7342949503211564

Epoch: 6| Step: 7
Training loss: 1.0255011320114136
Validation loss: 1.7821429237242667

Epoch: 6| Step: 8
Training loss: 1.2351405620574951
Validation loss: 1.7565588399928103

Epoch: 6| Step: 9
Training loss: 0.766373872756958
Validation loss: 1.779240104459947

Epoch: 6| Step: 10
Training loss: 0.7730857729911804
Validation loss: 1.8157439449782014

Epoch: 6| Step: 11
Training loss: 0.6264337301254272
Validation loss: 1.79765958170737

Epoch: 6| Step: 12
Training loss: 0.5034918785095215
Validation loss: 1.7814387800872966

Epoch: 6| Step: 13
Training loss: 0.6323426365852356
Validation loss: 1.780287346532268

Epoch: 403| Step: 0
Training loss: 1.2900049686431885
Validation loss: 1.7176369825998943

Epoch: 6| Step: 1
Training loss: 0.9291445016860962
Validation loss: 1.6743371448209208

Epoch: 6| Step: 2
Training loss: 0.8578763008117676
Validation loss: 1.6361702372950893

Epoch: 6| Step: 3
Training loss: 0.6045894622802734
Validation loss: 1.6215254081192838

Epoch: 6| Step: 4
Training loss: 0.7394849061965942
Validation loss: 1.6336433182480514

Epoch: 6| Step: 5
Training loss: 0.7804977297782898
Validation loss: 1.6468772337000857

Epoch: 6| Step: 6
Training loss: 1.0279935598373413
Validation loss: 1.6446114009426487

Epoch: 6| Step: 7
Training loss: 0.6374695301055908
Validation loss: 1.6668796398306405

Epoch: 6| Step: 8
Training loss: 0.6863450407981873
Validation loss: 1.6924719028575446

Epoch: 6| Step: 9
Training loss: 0.6330535411834717
Validation loss: 1.7272478790693386

Epoch: 6| Step: 10
Training loss: 1.049581527709961
Validation loss: 1.7423643514674196

Epoch: 6| Step: 11
Training loss: 0.8826636075973511
Validation loss: 1.8047592178467782

Epoch: 6| Step: 12
Training loss: 0.7057754397392273
Validation loss: 1.7914915559112385

Epoch: 6| Step: 13
Training loss: 1.0687718391418457
Validation loss: 1.8370085018937305

Epoch: 404| Step: 0
Training loss: 1.0003283023834229
Validation loss: 1.885604404634045

Epoch: 6| Step: 1
Training loss: 0.5358555316925049
Validation loss: 1.8920238902491908

Epoch: 6| Step: 2
Training loss: 1.0367069244384766
Validation loss: 1.8461383914434781

Epoch: 6| Step: 3
Training loss: 0.8873507976531982
Validation loss: 1.7953613663232455

Epoch: 6| Step: 4
Training loss: 1.2114425897598267
Validation loss: 1.7373072742134013

Epoch: 6| Step: 5
Training loss: 0.8352856636047363
Validation loss: 1.7194777175944338

Epoch: 6| Step: 6
Training loss: 0.8747223615646362
Validation loss: 1.7072891573752127

Epoch: 6| Step: 7
Training loss: 1.0435638427734375
Validation loss: 1.6492413384940035

Epoch: 6| Step: 8
Training loss: 0.7181830406188965
Validation loss: 1.643157462919912

Epoch: 6| Step: 9
Training loss: 0.8189593553543091
Validation loss: 1.6637292036446192

Epoch: 6| Step: 10
Training loss: 0.833222508430481
Validation loss: 1.6442241181609452

Epoch: 6| Step: 11
Training loss: 0.7682114839553833
Validation loss: 1.6247886816660564

Epoch: 6| Step: 12
Training loss: 0.7621384263038635
Validation loss: 1.6377567821933376

Epoch: 6| Step: 13
Training loss: 0.46660274267196655
Validation loss: 1.6928045147208757

Epoch: 405| Step: 0
Training loss: 0.661550760269165
Validation loss: 1.7346038177449217

Epoch: 6| Step: 1
Training loss: 0.25692540407180786
Validation loss: 1.7850793805173648

Epoch: 6| Step: 2
Training loss: 1.0278931856155396
Validation loss: 1.8404114707823722

Epoch: 6| Step: 3
Training loss: 0.6829546689987183
Validation loss: 1.8587825529036983

Epoch: 6| Step: 4
Training loss: 1.4413501024246216
Validation loss: 1.8916384725160496

Epoch: 6| Step: 5
Training loss: 1.4597400426864624
Validation loss: 1.8353884284214308

Epoch: 6| Step: 6
Training loss: 0.9545361399650574
Validation loss: 1.7536343964197303

Epoch: 6| Step: 7
Training loss: 0.6665744781494141
Validation loss: 1.7076042326547767

Epoch: 6| Step: 8
Training loss: 0.7883110046386719
Validation loss: 1.7115947482406453

Epoch: 6| Step: 9
Training loss: 0.6956669092178345
Validation loss: 1.6698919252682758

Epoch: 6| Step: 10
Training loss: 1.077126383781433
Validation loss: 1.6621718816859747

Epoch: 6| Step: 11
Training loss: 0.6663243770599365
Validation loss: 1.6432037122787968

Epoch: 6| Step: 12
Training loss: 0.6846996545791626
Validation loss: 1.6615821289759811

Epoch: 6| Step: 13
Training loss: 0.9341433048248291
Validation loss: 1.6789602938518728

Epoch: 406| Step: 0
Training loss: 0.8531057238578796
Validation loss: 1.6764849206452728

Epoch: 6| Step: 1
Training loss: 1.044137954711914
Validation loss: 1.7416040782005555

Epoch: 6| Step: 2
Training loss: 0.9027258157730103
Validation loss: 1.7570619019128944

Epoch: 6| Step: 3
Training loss: 1.0133464336395264
Validation loss: 1.7755422297344412

Epoch: 6| Step: 4
Training loss: 1.3555219173431396
Validation loss: 1.8056855868267756

Epoch: 6| Step: 5
Training loss: 0.8523906469345093
Validation loss: 1.7710472306897562

Epoch: 6| Step: 6
Training loss: 0.5349094867706299
Validation loss: 1.8261587260871806

Epoch: 6| Step: 7
Training loss: 0.7312361001968384
Validation loss: 1.7734277991838352

Epoch: 6| Step: 8
Training loss: 0.8659324049949646
Validation loss: 1.7692418200995332

Epoch: 6| Step: 9
Training loss: 0.5437816381454468
Validation loss: 1.7470974486361268

Epoch: 6| Step: 10
Training loss: 0.836823582649231
Validation loss: 1.7067468717534056

Epoch: 6| Step: 11
Training loss: 0.5507709383964539
Validation loss: 1.683766362487629

Epoch: 6| Step: 12
Training loss: 0.8153586387634277
Validation loss: 1.6598327493154874

Epoch: 6| Step: 13
Training loss: 0.4309776723384857
Validation loss: 1.675319174284576

Epoch: 407| Step: 0
Training loss: 0.48384296894073486
Validation loss: 1.652119774972239

Epoch: 6| Step: 1
Training loss: 1.1764421463012695
Validation loss: 1.6714956593769852

Epoch: 6| Step: 2
Training loss: 0.5641151666641235
Validation loss: 1.698468590295443

Epoch: 6| Step: 3
Training loss: 0.7177051305770874
Validation loss: 1.716325972669868

Epoch: 6| Step: 4
Training loss: 0.8386397957801819
Validation loss: 1.7104771483329035

Epoch: 6| Step: 5
Training loss: 0.7249228954315186
Validation loss: 1.7296453252915414

Epoch: 6| Step: 6
Training loss: 0.9520536065101624
Validation loss: 1.772629750672207

Epoch: 6| Step: 7
Training loss: 1.054543137550354
Validation loss: 1.79228045991672

Epoch: 6| Step: 8
Training loss: 1.0540292263031006
Validation loss: 1.787939046018867

Epoch: 6| Step: 9
Training loss: 0.7486056089401245
Validation loss: 1.7747367799922984

Epoch: 6| Step: 10
Training loss: 0.504569947719574
Validation loss: 1.759095645719959

Epoch: 6| Step: 11
Training loss: 0.6994833946228027
Validation loss: 1.743143468774775

Epoch: 6| Step: 12
Training loss: 0.8207000494003296
Validation loss: 1.7207495089500182

Epoch: 6| Step: 13
Training loss: 1.4248872995376587
Validation loss: 1.701282678111907

Epoch: 408| Step: 0
Training loss: 0.6866239309310913
Validation loss: 1.6959635198757212

Epoch: 6| Step: 1
Training loss: 0.6975824236869812
Validation loss: 1.706633242227698

Epoch: 6| Step: 2
Training loss: 0.8760672211647034
Validation loss: 1.6954757808357157

Epoch: 6| Step: 3
Training loss: 0.6092077493667603
Validation loss: 1.7263173416096678

Epoch: 6| Step: 4
Training loss: 0.9675151109695435
Validation loss: 1.7258024177243632

Epoch: 6| Step: 5
Training loss: 0.6534891128540039
Validation loss: 1.7376364943801716

Epoch: 6| Step: 6
Training loss: 1.159433364868164
Validation loss: 1.7651764013433968

Epoch: 6| Step: 7
Training loss: 0.680343508720398
Validation loss: 1.7857131163279216

Epoch: 6| Step: 8
Training loss: 0.8812136650085449
Validation loss: 1.760680490924466

Epoch: 6| Step: 9
Training loss: 0.9320483207702637
Validation loss: 1.7630118336728824

Epoch: 6| Step: 10
Training loss: 0.7199431657791138
Validation loss: 1.733578501209136

Epoch: 6| Step: 11
Training loss: 0.7714104652404785
Validation loss: 1.7060089060055312

Epoch: 6| Step: 12
Training loss: 0.6831668615341187
Validation loss: 1.7306549305556922

Epoch: 6| Step: 13
Training loss: 0.907944917678833
Validation loss: 1.6580917194325437

Epoch: 409| Step: 0
Training loss: 0.6439385414123535
Validation loss: 1.7012182525409165

Epoch: 6| Step: 1
Training loss: 0.3760182857513428
Validation loss: 1.6622007944250619

Epoch: 6| Step: 2
Training loss: 1.1687397956848145
Validation loss: 1.70118974613887

Epoch: 6| Step: 3
Training loss: 0.9475297927856445
Validation loss: 1.6895734853641962

Epoch: 6| Step: 4
Training loss: 0.33523139357566833
Validation loss: 1.7697864873434908

Epoch: 6| Step: 5
Training loss: 1.2011104822158813
Validation loss: 1.7498972441560479

Epoch: 6| Step: 6
Training loss: 0.9207946062088013
Validation loss: 1.7741566960529616

Epoch: 6| Step: 7
Training loss: 0.7580561637878418
Validation loss: 1.7708639521752634

Epoch: 6| Step: 8
Training loss: 0.4963005483150482
Validation loss: 1.7249062702219973

Epoch: 6| Step: 9
Training loss: 0.932304859161377
Validation loss: 1.7529937131430513

Epoch: 6| Step: 10
Training loss: 1.0027894973754883
Validation loss: 1.7261836080140964

Epoch: 6| Step: 11
Training loss: 0.7735372185707092
Validation loss: 1.7722794791703582

Epoch: 6| Step: 12
Training loss: 0.8706256151199341
Validation loss: 1.740798359276146

Epoch: 6| Step: 13
Training loss: 0.5730100274085999
Validation loss: 1.7521420383966098

Epoch: 410| Step: 0
Training loss: 0.8253880143165588
Validation loss: 1.7593008074709164

Epoch: 6| Step: 1
Training loss: 0.5049661993980408
Validation loss: 1.7634470885799778

Epoch: 6| Step: 2
Training loss: 0.6425334215164185
Validation loss: 1.7999544617950276

Epoch: 6| Step: 3
Training loss: 0.898828387260437
Validation loss: 1.7569179893821798

Epoch: 6| Step: 4
Training loss: 0.8686487674713135
Validation loss: 1.7673645275895313

Epoch: 6| Step: 5
Training loss: 1.5045011043548584
Validation loss: 1.8087228267423567

Epoch: 6| Step: 6
Training loss: 0.7989839315414429
Validation loss: 1.7497752046072355

Epoch: 6| Step: 7
Training loss: 0.7555555105209351
Validation loss: 1.7342219186085526

Epoch: 6| Step: 8
Training loss: 0.8340423703193665
Validation loss: 1.692897742794406

Epoch: 6| Step: 9
Training loss: 0.7085541486740112
Validation loss: 1.7017533292052567

Epoch: 6| Step: 10
Training loss: 0.6066755056381226
Validation loss: 1.7501120592958184

Epoch: 6| Step: 11
Training loss: 1.0943570137023926
Validation loss: 1.743496673081511

Epoch: 6| Step: 12
Training loss: 0.799221396446228
Validation loss: 1.7647510190163889

Epoch: 6| Step: 13
Training loss: 0.17072013020515442
Validation loss: 1.7284794199851252

Epoch: 411| Step: 0
Training loss: 0.9153847694396973
Validation loss: 1.7500090675969278

Epoch: 6| Step: 1
Training loss: 0.906166136264801
Validation loss: 1.7182393022762832

Epoch: 6| Step: 2
Training loss: 0.34808528423309326
Validation loss: 1.7127696384665787

Epoch: 6| Step: 3
Training loss: 0.6040208339691162
Validation loss: 1.7352818032746673

Epoch: 6| Step: 4
Training loss: 1.028285026550293
Validation loss: 1.7215459167316396

Epoch: 6| Step: 5
Training loss: 0.9017152786254883
Validation loss: 1.737454184921839

Epoch: 6| Step: 6
Training loss: 0.7362561225891113
Validation loss: 1.703774421445785

Epoch: 6| Step: 7
Training loss: 0.5807918906211853
Validation loss: 1.70507651118822

Epoch: 6| Step: 8
Training loss: 0.6693999171257019
Validation loss: 1.7052055815214753

Epoch: 6| Step: 9
Training loss: 0.6040486097335815
Validation loss: 1.7119441942502094

Epoch: 6| Step: 10
Training loss: 1.1181128025054932
Validation loss: 1.6926808523875412

Epoch: 6| Step: 11
Training loss: 0.8004751205444336
Validation loss: 1.6954601285278157

Epoch: 6| Step: 12
Training loss: 1.028867244720459
Validation loss: 1.668230132390094

Epoch: 6| Step: 13
Training loss: 1.1547951698303223
Validation loss: 1.6632650641984836

Epoch: 412| Step: 0
Training loss: 0.65959632396698
Validation loss: 1.6621057500121414

Epoch: 6| Step: 1
Training loss: 0.7764472365379333
Validation loss: 1.6380909591592767

Epoch: 6| Step: 2
Training loss: 0.6706640720367432
Validation loss: 1.6426283012154281

Epoch: 6| Step: 3
Training loss: 0.46158403158187866
Validation loss: 1.6730198847350253

Epoch: 6| Step: 4
Training loss: 0.68818598985672
Validation loss: 1.696869950140676

Epoch: 6| Step: 5
Training loss: 0.6441782712936401
Validation loss: 1.723844511534578

Epoch: 6| Step: 6
Training loss: 0.7097830176353455
Validation loss: 1.735427406526381

Epoch: 6| Step: 7
Training loss: 0.7277224659919739
Validation loss: 1.7230556600837297

Epoch: 6| Step: 8
Training loss: 0.8742008209228516
Validation loss: 1.750416785158137

Epoch: 6| Step: 9
Training loss: 1.1525213718414307
Validation loss: 1.7367190468695857

Epoch: 6| Step: 10
Training loss: 0.6555373072624207
Validation loss: 1.736254627986621

Epoch: 6| Step: 11
Training loss: 1.2288870811462402
Validation loss: 1.73538851481612

Epoch: 6| Step: 12
Training loss: 1.2333343029022217
Validation loss: 1.7570771517292145

Epoch: 6| Step: 13
Training loss: 0.29236674308776855
Validation loss: 1.7319606465678061

Epoch: 413| Step: 0
Training loss: 0.698468029499054
Validation loss: 1.7036374243356849

Epoch: 6| Step: 1
Training loss: 0.4256272315979004
Validation loss: 1.6674245865114274

Epoch: 6| Step: 2
Training loss: 0.856708288192749
Validation loss: 1.7109723693581038

Epoch: 6| Step: 3
Training loss: 0.5501810908317566
Validation loss: 1.6853599484248827

Epoch: 6| Step: 4
Training loss: 0.8297079801559448
Validation loss: 1.6856959891575638

Epoch: 6| Step: 5
Training loss: 1.0321691036224365
Validation loss: 1.7219467239995156

Epoch: 6| Step: 6
Training loss: 0.6605682969093323
Validation loss: 1.7289599577585857

Epoch: 6| Step: 7
Training loss: 1.012345790863037
Validation loss: 1.7445859729602773

Epoch: 6| Step: 8
Training loss: 0.8391070365905762
Validation loss: 1.7115690605614775

Epoch: 6| Step: 9
Training loss: 0.4843834638595581
Validation loss: 1.70406259388052

Epoch: 6| Step: 10
Training loss: 0.9974574446678162
Validation loss: 1.6895963325295398

Epoch: 6| Step: 11
Training loss: 0.8467212915420532
Validation loss: 1.669558548158215

Epoch: 6| Step: 12
Training loss: 0.7815465927124023
Validation loss: 1.6393545584012104

Epoch: 6| Step: 13
Training loss: 0.7252833247184753
Validation loss: 1.6167322833050963

Epoch: 414| Step: 0
Training loss: 0.7595008611679077
Validation loss: 1.6548655763749154

Epoch: 6| Step: 1
Training loss: 0.7672468423843384
Validation loss: 1.631208101908366

Epoch: 6| Step: 2
Training loss: 0.9062387943267822
Validation loss: 1.6427915916647962

Epoch: 6| Step: 3
Training loss: 0.8219509124755859
Validation loss: 1.672778174441348

Epoch: 6| Step: 4
Training loss: 1.1473617553710938
Validation loss: 1.649915966936337

Epoch: 6| Step: 5
Training loss: 0.49331605434417725
Validation loss: 1.6519197828026229

Epoch: 6| Step: 6
Training loss: 0.9501291513442993
Validation loss: 1.6526437010816348

Epoch: 6| Step: 7
Training loss: 0.3716958165168762
Validation loss: 1.6678946313037668

Epoch: 6| Step: 8
Training loss: 0.7461010217666626
Validation loss: 1.7118863572356522

Epoch: 6| Step: 9
Training loss: 0.5982537865638733
Validation loss: 1.735922077650665

Epoch: 6| Step: 10
Training loss: 0.6091699004173279
Validation loss: 1.697653446146237

Epoch: 6| Step: 11
Training loss: 0.9355558156967163
Validation loss: 1.7415118960924045

Epoch: 6| Step: 12
Training loss: 0.9973288774490356
Validation loss: 1.7325576723262828

Epoch: 6| Step: 13
Training loss: 0.944678008556366
Validation loss: 1.684607595525762

Epoch: 415| Step: 0
Training loss: 0.6981739401817322
Validation loss: 1.69936163579264

Epoch: 6| Step: 1
Training loss: 0.9422430992126465
Validation loss: 1.6801962557659353

Epoch: 6| Step: 2
Training loss: 0.5530738234519958
Validation loss: 1.6587251642698884

Epoch: 6| Step: 3
Training loss: 0.780052900314331
Validation loss: 1.6580837080555577

Epoch: 6| Step: 4
Training loss: 0.8069554567337036
Validation loss: 1.6409013053422332

Epoch: 6| Step: 5
Training loss: 1.2244116067886353
Validation loss: 1.6525987168794036

Epoch: 6| Step: 6
Training loss: 0.8323450088500977
Validation loss: 1.6465663756093671

Epoch: 6| Step: 7
Training loss: 0.8403639793395996
Validation loss: 1.6566982012923046

Epoch: 6| Step: 8
Training loss: 0.7959995269775391
Validation loss: 1.6647886947918964

Epoch: 6| Step: 9
Training loss: 0.2546934485435486
Validation loss: 1.7033715466017365

Epoch: 6| Step: 10
Training loss: 0.6202600598335266
Validation loss: 1.7017273236346502

Epoch: 6| Step: 11
Training loss: 0.7144441604614258
Validation loss: 1.689737694237822

Epoch: 6| Step: 12
Training loss: 0.792320191860199
Validation loss: 1.7138849112295336

Epoch: 6| Step: 13
Training loss: 0.7914568781852722
Validation loss: 1.7208413731667302

Epoch: 416| Step: 0
Training loss: 0.8163214921951294
Validation loss: 1.7274621045717629

Epoch: 6| Step: 1
Training loss: 1.010269045829773
Validation loss: 1.7417283340166974

Epoch: 6| Step: 2
Training loss: 0.6809132099151611
Validation loss: 1.7319174248685119

Epoch: 6| Step: 3
Training loss: 0.3258303701877594
Validation loss: 1.7514417838024836

Epoch: 6| Step: 4
Training loss: 0.9910632371902466
Validation loss: 1.7172575163584884

Epoch: 6| Step: 5
Training loss: 0.6213451623916626
Validation loss: 1.7028725916339504

Epoch: 6| Step: 6
Training loss: 0.7958964109420776
Validation loss: 1.6832900739485217

Epoch: 6| Step: 7
Training loss: 0.819164514541626
Validation loss: 1.6558141003372848

Epoch: 6| Step: 8
Training loss: 0.7550235986709595
Validation loss: 1.681653981567711

Epoch: 6| Step: 9
Training loss: 0.8795298337936401
Validation loss: 1.6774497519257248

Epoch: 6| Step: 10
Training loss: 0.41383808851242065
Validation loss: 1.671537773583525

Epoch: 6| Step: 11
Training loss: 0.6842430830001831
Validation loss: 1.6269575210027798

Epoch: 6| Step: 12
Training loss: 0.8121979832649231
Validation loss: 1.6373419851385138

Epoch: 6| Step: 13
Training loss: 0.9713588356971741
Validation loss: 1.668845691988545

Epoch: 417| Step: 0
Training loss: 0.42108154296875
Validation loss: 1.6824419959898917

Epoch: 6| Step: 1
Training loss: 0.7838850021362305
Validation loss: 1.6800188108157086

Epoch: 6| Step: 2
Training loss: 0.7315290570259094
Validation loss: 1.6881271434086624

Epoch: 6| Step: 3
Training loss: 0.5826709270477295
Validation loss: 1.6817870588712795

Epoch: 6| Step: 4
Training loss: 0.7266010642051697
Validation loss: 1.7122830178148003

Epoch: 6| Step: 5
Training loss: 0.8527028560638428
Validation loss: 1.7040779770061534

Epoch: 6| Step: 6
Training loss: 0.8378625512123108
Validation loss: 1.7619842367787515

Epoch: 6| Step: 7
Training loss: 0.8294036388397217
Validation loss: 1.743512422807755

Epoch: 6| Step: 8
Training loss: 1.0485143661499023
Validation loss: 1.7077947201267365

Epoch: 6| Step: 9
Training loss: 0.894680380821228
Validation loss: 1.7085498430395638

Epoch: 6| Step: 10
Training loss: 0.7439700365066528
Validation loss: 1.6539148079451693

Epoch: 6| Step: 11
Training loss: 0.9054476618766785
Validation loss: 1.6663789723509101

Epoch: 6| Step: 12
Training loss: 0.7146711945533752
Validation loss: 1.638847722802111

Epoch: 6| Step: 13
Training loss: 0.614790678024292
Validation loss: 1.6442960910899664

Epoch: 418| Step: 0
Training loss: 1.0433911085128784
Validation loss: 1.6086823312185143

Epoch: 6| Step: 1
Training loss: 0.9301185607910156
Validation loss: 1.6598531373085514

Epoch: 6| Step: 2
Training loss: 0.7293409109115601
Validation loss: 1.6421369967922088

Epoch: 6| Step: 3
Training loss: 0.7295554876327515
Validation loss: 1.6925327790680753

Epoch: 6| Step: 4
Training loss: 1.1035466194152832
Validation loss: 1.701563577498159

Epoch: 6| Step: 5
Training loss: 0.6419016122817993
Validation loss: 1.6833476379353514

Epoch: 6| Step: 6
Training loss: 0.8100519776344299
Validation loss: 1.703728279759807

Epoch: 6| Step: 7
Training loss: 0.9155428409576416
Validation loss: 1.6715998393233105

Epoch: 6| Step: 8
Training loss: 0.8296650648117065
Validation loss: 1.6731750157571608

Epoch: 6| Step: 9
Training loss: 0.7488943934440613
Validation loss: 1.6701436324786114

Epoch: 6| Step: 10
Training loss: 0.7431848049163818
Validation loss: 1.6996160937893776

Epoch: 6| Step: 11
Training loss: 0.6842138171195984
Validation loss: 1.7005289344377414

Epoch: 6| Step: 12
Training loss: 0.38268527388572693
Validation loss: 1.7079753850096016

Epoch: 6| Step: 13
Training loss: 0.21635174751281738
Validation loss: 1.7113140808638705

Epoch: 419| Step: 0
Training loss: 0.7843286991119385
Validation loss: 1.6901592118765718

Epoch: 6| Step: 1
Training loss: 0.5242094993591309
Validation loss: 1.7052169679313578

Epoch: 6| Step: 2
Training loss: 0.8375802040100098
Validation loss: 1.6885112882942281

Epoch: 6| Step: 3
Training loss: 0.680889904499054
Validation loss: 1.6617167239548059

Epoch: 6| Step: 4
Training loss: 0.6309282779693604
Validation loss: 1.7056895571370279

Epoch: 6| Step: 5
Training loss: 1.023585319519043
Validation loss: 1.675268700045924

Epoch: 6| Step: 6
Training loss: 0.6375249624252319
Validation loss: 1.675701774576659

Epoch: 6| Step: 7
Training loss: 0.7874904274940491
Validation loss: 1.674857799724866

Epoch: 6| Step: 8
Training loss: 0.9107997417449951
Validation loss: 1.6428608894348145

Epoch: 6| Step: 9
Training loss: 0.6272796392440796
Validation loss: 1.6401778831276843

Epoch: 6| Step: 10
Training loss: 0.7133503556251526
Validation loss: 1.6616541672778387

Epoch: 6| Step: 11
Training loss: 0.6662812232971191
Validation loss: 1.6663510901953584

Epoch: 6| Step: 12
Training loss: 0.6805523633956909
Validation loss: 1.7234863747832596

Epoch: 6| Step: 13
Training loss: 0.7626097202301025
Validation loss: 1.7174117539518623

Epoch: 420| Step: 0
Training loss: 0.8159529566764832
Validation loss: 1.738312772525254

Epoch: 6| Step: 1
Training loss: 0.34086501598358154
Validation loss: 1.7500042300070486

Epoch: 6| Step: 2
Training loss: 0.2645164132118225
Validation loss: 1.7446284268492012

Epoch: 6| Step: 3
Training loss: 1.2420597076416016
Validation loss: 1.7216023809166365

Epoch: 6| Step: 4
Training loss: 0.7901711463928223
Validation loss: 1.7203556350482407

Epoch: 6| Step: 5
Training loss: 0.687279462814331
Validation loss: 1.7270589041453537

Epoch: 6| Step: 6
Training loss: 1.2045824527740479
Validation loss: 1.6923153451693955

Epoch: 6| Step: 7
Training loss: 0.7155592441558838
Validation loss: 1.6983810778587096

Epoch: 6| Step: 8
Training loss: 0.5745722055435181
Validation loss: 1.687723425126845

Epoch: 6| Step: 9
Training loss: 0.8460021615028381
Validation loss: 1.7358239504598802

Epoch: 6| Step: 10
Training loss: 1.006988286972046
Validation loss: 1.741374683636491

Epoch: 6| Step: 11
Training loss: 0.49039125442504883
Validation loss: 1.7498862140922136

Epoch: 6| Step: 12
Training loss: 1.0630719661712646
Validation loss: 1.7413586775461833

Epoch: 6| Step: 13
Training loss: 0.2816072404384613
Validation loss: 1.70489699609818

Epoch: 421| Step: 0
Training loss: 0.9840198755264282
Validation loss: 1.7275788681481474

Epoch: 6| Step: 1
Training loss: 0.6177006959915161
Validation loss: 1.7119037823010517

Epoch: 6| Step: 2
Training loss: 0.6891794204711914
Validation loss: 1.7418738154954807

Epoch: 6| Step: 3
Training loss: 0.30018842220306396
Validation loss: 1.7414873594878821

Epoch: 6| Step: 4
Training loss: 0.5273759961128235
Validation loss: 1.7453208815666936

Epoch: 6| Step: 5
Training loss: 0.40294063091278076
Validation loss: 1.7607739586983957

Epoch: 6| Step: 6
Training loss: 0.6494528651237488
Validation loss: 1.7611742750290902

Epoch: 6| Step: 7
Training loss: 0.7799979448318481
Validation loss: 1.7761779395482873

Epoch: 6| Step: 8
Training loss: 0.9456352591514587
Validation loss: 1.7746710726009902

Epoch: 6| Step: 9
Training loss: 1.2645316123962402
Validation loss: 1.8094016352007467

Epoch: 6| Step: 10
Training loss: 0.9926201105117798
Validation loss: 1.768150883336221

Epoch: 6| Step: 11
Training loss: 0.5226815342903137
Validation loss: 1.7618546857628772

Epoch: 6| Step: 12
Training loss: 1.0036579370498657
Validation loss: 1.758482607462073

Epoch: 6| Step: 13
Training loss: 0.6536898612976074
Validation loss: 1.6909157999100224

Epoch: 422| Step: 0
Training loss: 0.47107386589050293
Validation loss: 1.6512758129386491

Epoch: 6| Step: 1
Training loss: 0.5649034976959229
Validation loss: 1.637831389263112

Epoch: 6| Step: 2
Training loss: 0.7425197958946228
Validation loss: 1.6277236477021249

Epoch: 6| Step: 3
Training loss: 1.104752540588379
Validation loss: 1.6039591143208165

Epoch: 6| Step: 4
Training loss: 0.8665709495544434
Validation loss: 1.6265020114119335

Epoch: 6| Step: 5
Training loss: 0.6857295632362366
Validation loss: 1.6171229090741885

Epoch: 6| Step: 6
Training loss: 0.9037257432937622
Validation loss: 1.6274681475854689

Epoch: 6| Step: 7
Training loss: 0.6980447173118591
Validation loss: 1.6540676477134868

Epoch: 6| Step: 8
Training loss: 1.1452765464782715
Validation loss: 1.728439570755087

Epoch: 6| Step: 9
Training loss: 0.5556196570396423
Validation loss: 1.777044455210368

Epoch: 6| Step: 10
Training loss: 0.8010401725769043
Validation loss: 1.7694051624626241

Epoch: 6| Step: 11
Training loss: 1.1182892322540283
Validation loss: 1.7743666530937277

Epoch: 6| Step: 12
Training loss: 0.47369709610939026
Validation loss: 1.7688363854603102

Epoch: 6| Step: 13
Training loss: 0.3507993817329407
Validation loss: 1.7364206557632775

Epoch: 423| Step: 0
Training loss: 0.8021100759506226
Validation loss: 1.728144117580947

Epoch: 6| Step: 1
Training loss: 0.5650335550308228
Validation loss: 1.6839720215848697

Epoch: 6| Step: 2
Training loss: 1.0983860492706299
Validation loss: 1.7050130982552805

Epoch: 6| Step: 3
Training loss: 0.5513887405395508
Validation loss: 1.7152501857408913

Epoch: 6| Step: 4
Training loss: 0.431031197309494
Validation loss: 1.6534082530647196

Epoch: 6| Step: 5
Training loss: 1.0955191850662231
Validation loss: 1.668163194451281

Epoch: 6| Step: 6
Training loss: 0.7158358693122864
Validation loss: 1.669282858089734

Epoch: 6| Step: 7
Training loss: 0.7599468231201172
Validation loss: 1.6752387721051452

Epoch: 6| Step: 8
Training loss: 0.6656279563903809
Validation loss: 1.6926587755962084

Epoch: 6| Step: 9
Training loss: 0.40861985087394714
Validation loss: 1.7111051287702335

Epoch: 6| Step: 10
Training loss: 0.7489298582077026
Validation loss: 1.7622115278756747

Epoch: 6| Step: 11
Training loss: 0.9733210802078247
Validation loss: 1.7733055391619283

Epoch: 6| Step: 12
Training loss: 0.9712334275245667
Validation loss: 1.8001199537707913

Epoch: 6| Step: 13
Training loss: 0.8214466571807861
Validation loss: 1.7995390520300916

Epoch: 424| Step: 0
Training loss: 1.0869768857955933
Validation loss: 1.7687212927367097

Epoch: 6| Step: 1
Training loss: 0.7569319009780884
Validation loss: 1.7336226124917307

Epoch: 6| Step: 2
Training loss: 0.947826087474823
Validation loss: 1.7257781118474982

Epoch: 6| Step: 3
Training loss: 0.5462340116500854
Validation loss: 1.723960934146758

Epoch: 6| Step: 4
Training loss: 0.5887265205383301
Validation loss: 1.7277593689580117

Epoch: 6| Step: 5
Training loss: 0.2866939902305603
Validation loss: 1.7284500291270595

Epoch: 6| Step: 6
Training loss: 0.6053534746170044
Validation loss: 1.7187296511024557

Epoch: 6| Step: 7
Training loss: 0.8782084584236145
Validation loss: 1.7435647672222507

Epoch: 6| Step: 8
Training loss: 0.7143205404281616
Validation loss: 1.6859221522526076

Epoch: 6| Step: 9
Training loss: 0.9243693351745605
Validation loss: 1.6955108296486638

Epoch: 6| Step: 10
Training loss: 0.7114662528038025
Validation loss: 1.7208272923705399

Epoch: 6| Step: 11
Training loss: 0.8560832738876343
Validation loss: 1.7153146254119052

Epoch: 6| Step: 12
Training loss: 0.8189246654510498
Validation loss: 1.6969775038380777

Epoch: 6| Step: 13
Training loss: 0.8137262463569641
Validation loss: 1.7125782261612594

Epoch: 425| Step: 0
Training loss: 0.7345671057701111
Validation loss: 1.6511976154901649

Epoch: 6| Step: 1
Training loss: 0.8373473882675171
Validation loss: 1.636819234458349

Epoch: 6| Step: 2
Training loss: 0.6132144927978516
Validation loss: 1.646780840812191

Epoch: 6| Step: 3
Training loss: 0.9943017959594727
Validation loss: 1.6702987019733717

Epoch: 6| Step: 4
Training loss: 0.9266228079795837
Validation loss: 1.6747769617265271

Epoch: 6| Step: 5
Training loss: 0.6815785765647888
Validation loss: 1.732050875181793

Epoch: 6| Step: 6
Training loss: 0.7898771166801453
Validation loss: 1.7688475437061761

Epoch: 6| Step: 7
Training loss: 0.4958668053150177
Validation loss: 1.8036639459671513

Epoch: 6| Step: 8
Training loss: 0.5759778022766113
Validation loss: 1.8354094246382355

Epoch: 6| Step: 9
Training loss: 0.7077323198318481
Validation loss: 1.822049392166958

Epoch: 6| Step: 10
Training loss: 0.5088685750961304
Validation loss: 1.81148112076585

Epoch: 6| Step: 11
Training loss: 1.1145557165145874
Validation loss: 1.8182446213178738

Epoch: 6| Step: 12
Training loss: 0.8308076858520508
Validation loss: 1.798833434299756

Epoch: 6| Step: 13
Training loss: 0.7324931025505066
Validation loss: 1.800728246729861

Epoch: 426| Step: 0
Training loss: 1.1987518072128296
Validation loss: 1.7426284718257126

Epoch: 6| Step: 1
Training loss: 0.7514906525611877
Validation loss: 1.6989009226522138

Epoch: 6| Step: 2
Training loss: 0.849757194519043
Validation loss: 1.6862131331556587

Epoch: 6| Step: 3
Training loss: 0.3931305706501007
Validation loss: 1.636188930080783

Epoch: 6| Step: 4
Training loss: 0.8407313823699951
Validation loss: 1.6496411523511332

Epoch: 6| Step: 5
Training loss: 0.7746742367744446
Validation loss: 1.6175504897230415

Epoch: 6| Step: 6
Training loss: 0.8418329358100891
Validation loss: 1.6701514413279872

Epoch: 6| Step: 7
Training loss: 0.4033781588077545
Validation loss: 1.6534894692000521

Epoch: 6| Step: 8
Training loss: 1.1650980710983276
Validation loss: 1.6849103396938694

Epoch: 6| Step: 9
Training loss: 0.7436059713363647
Validation loss: 1.6817152577061807

Epoch: 6| Step: 10
Training loss: 0.47722554206848145
Validation loss: 1.687968454053325

Epoch: 6| Step: 11
Training loss: 0.8223921060562134
Validation loss: 1.6780746803488782

Epoch: 6| Step: 12
Training loss: 0.41079607605934143
Validation loss: 1.7000360809346682

Epoch: 6| Step: 13
Training loss: 0.8474781513214111
Validation loss: 1.6955028913354362

Epoch: 427| Step: 0
Training loss: 0.5779486894607544
Validation loss: 1.7055262801467732

Epoch: 6| Step: 1
Training loss: 0.8359889388084412
Validation loss: 1.6597622068979407

Epoch: 6| Step: 2
Training loss: 0.44410642981529236
Validation loss: 1.6986530365482453

Epoch: 6| Step: 3
Training loss: 0.6682336330413818
Validation loss: 1.6970683874622468

Epoch: 6| Step: 4
Training loss: 0.609982967376709
Validation loss: 1.7032385026254961

Epoch: 6| Step: 5
Training loss: 1.1802005767822266
Validation loss: 1.7928043232169202

Epoch: 6| Step: 6
Training loss: 0.921821117401123
Validation loss: 1.7800757141523464

Epoch: 6| Step: 7
Training loss: 0.8131929636001587
Validation loss: 1.8192499068475538

Epoch: 6| Step: 8
Training loss: 0.9362208247184753
Validation loss: 1.7626848451552852

Epoch: 6| Step: 9
Training loss: 0.526015043258667
Validation loss: 1.7118321118816253

Epoch: 6| Step: 10
Training loss: 0.6764364242553711
Validation loss: 1.7404294603614396

Epoch: 6| Step: 11
Training loss: 0.6560229063034058
Validation loss: 1.6969887979568974

Epoch: 6| Step: 12
Training loss: 0.40582865476608276
Validation loss: 1.692869609402072

Epoch: 6| Step: 13
Training loss: 0.7158917188644409
Validation loss: 1.6973108258298648

Epoch: 428| Step: 0
Training loss: 0.6470897793769836
Validation loss: 1.7292042906566332

Epoch: 6| Step: 1
Training loss: 0.8971846103668213
Validation loss: 1.7308698302956038

Epoch: 6| Step: 2
Training loss: 0.7539610266685486
Validation loss: 1.728337255857324

Epoch: 6| Step: 3
Training loss: 0.77120041847229
Validation loss: 1.735746645158337

Epoch: 6| Step: 4
Training loss: 0.4466221332550049
Validation loss: 1.7320551987617248

Epoch: 6| Step: 5
Training loss: 0.6566143035888672
Validation loss: 1.74091556379872

Epoch: 6| Step: 6
Training loss: 0.384296178817749
Validation loss: 1.7501959441810526

Epoch: 6| Step: 7
Training loss: 0.5225040912628174
Validation loss: 1.730263138330111

Epoch: 6| Step: 8
Training loss: 0.7208641767501831
Validation loss: 1.7193853573132587

Epoch: 6| Step: 9
Training loss: 1.0520386695861816
Validation loss: 1.7075075513573104

Epoch: 6| Step: 10
Training loss: 0.7291312217712402
Validation loss: 1.6852986261408816

Epoch: 6| Step: 11
Training loss: 1.282224178314209
Validation loss: 1.6613233679084367

Epoch: 6| Step: 12
Training loss: 0.6874380707740784
Validation loss: 1.6515218224576724

Epoch: 6| Step: 13
Training loss: 0.45038753747940063
Validation loss: 1.6215182305664144

Epoch: 429| Step: 0
Training loss: 0.5592148303985596
Validation loss: 1.627014958730308

Epoch: 6| Step: 1
Training loss: 0.8717667460441589
Validation loss: 1.7008993779459307

Epoch: 6| Step: 2
Training loss: 0.5986979007720947
Validation loss: 1.7115837053586078

Epoch: 6| Step: 3
Training loss: 0.6525211930274963
Validation loss: 1.726415430345843

Epoch: 6| Step: 4
Training loss: 0.7871108055114746
Validation loss: 1.7477496734229467

Epoch: 6| Step: 5
Training loss: 0.7091072797775269
Validation loss: 1.7549127801772086

Epoch: 6| Step: 6
Training loss: 0.9259258508682251
Validation loss: 1.742546417379892

Epoch: 6| Step: 7
Training loss: 0.8322130441665649
Validation loss: 1.7180181985260339

Epoch: 6| Step: 8
Training loss: 0.6616610288619995
Validation loss: 1.7087359172041698

Epoch: 6| Step: 9
Training loss: 0.7034328579902649
Validation loss: 1.6593619444036996

Epoch: 6| Step: 10
Training loss: 0.9160652160644531
Validation loss: 1.6492664660176923

Epoch: 6| Step: 11
Training loss: 0.4410124719142914
Validation loss: 1.6568384478169103

Epoch: 6| Step: 12
Training loss: 0.6592945456504822
Validation loss: 1.672196893281834

Epoch: 6| Step: 13
Training loss: 0.48848989605903625
Validation loss: 1.7096331209264777

Epoch: 430| Step: 0
Training loss: 0.7655473947525024
Validation loss: 1.7816474886350735

Epoch: 6| Step: 1
Training loss: 0.57036954164505
Validation loss: 1.8039629305562666

Epoch: 6| Step: 2
Training loss: 0.8737159371376038
Validation loss: 1.8311138819622736

Epoch: 6| Step: 3
Training loss: 0.6569607257843018
Validation loss: 1.7962649817107825

Epoch: 6| Step: 4
Training loss: 0.8060743808746338
Validation loss: 1.7439905930590887

Epoch: 6| Step: 5
Training loss: 0.5348330140113831
Validation loss: 1.706517336189106

Epoch: 6| Step: 6
Training loss: 0.6824551224708557
Validation loss: 1.6523684160683745

Epoch: 6| Step: 7
Training loss: 0.8564085960388184
Validation loss: 1.6212553452419978

Epoch: 6| Step: 8
Training loss: 0.9850504994392395
Validation loss: 1.6037642725052372

Epoch: 6| Step: 9
Training loss: 0.7702652812004089
Validation loss: 1.6191436911142

Epoch: 6| Step: 10
Training loss: 0.8226791620254517
Validation loss: 1.618672941320686

Epoch: 6| Step: 11
Training loss: 0.8249498605728149
Validation loss: 1.6070259283947688

Epoch: 6| Step: 12
Training loss: 0.8625685572624207
Validation loss: 1.6246510449276175

Epoch: 6| Step: 13
Training loss: 0.5725300312042236
Validation loss: 1.6126187283505675

Epoch: 431| Step: 0
Training loss: 0.6705223321914673
Validation loss: 1.641660451889038

Epoch: 6| Step: 1
Training loss: 0.7048161029815674
Validation loss: 1.6952494216221634

Epoch: 6| Step: 2
Training loss: 0.5172147750854492
Validation loss: 1.7104940798974806

Epoch: 6| Step: 3
Training loss: 0.5739271640777588
Validation loss: 1.707247326450963

Epoch: 6| Step: 4
Training loss: 1.0461559295654297
Validation loss: 1.7216935106503066

Epoch: 6| Step: 5
Training loss: 0.5495616793632507
Validation loss: 1.7415226223648235

Epoch: 6| Step: 6
Training loss: 0.9313053488731384
Validation loss: 1.6780793961658274

Epoch: 6| Step: 7
Training loss: 0.36348238587379456
Validation loss: 1.6556515386027675

Epoch: 6| Step: 8
Training loss: 1.0665907859802246
Validation loss: 1.6508006857287498

Epoch: 6| Step: 9
Training loss: 1.0245529413223267
Validation loss: 1.605658782425747

Epoch: 6| Step: 10
Training loss: 0.7822981476783752
Validation loss: 1.595988599202966

Epoch: 6| Step: 11
Training loss: 0.4607163667678833
Validation loss: 1.581897093403724

Epoch: 6| Step: 12
Training loss: 0.6967867612838745
Validation loss: 1.6063766274400937

Epoch: 6| Step: 13
Training loss: 0.8524148464202881
Validation loss: 1.6268667892743183

Epoch: 432| Step: 0
Training loss: 0.7798551321029663
Validation loss: 1.6450669047653035

Epoch: 6| Step: 1
Training loss: 0.35682910680770874
Validation loss: 1.639924269850536

Epoch: 6| Step: 2
Training loss: 0.400546133518219
Validation loss: 1.672709031771588

Epoch: 6| Step: 3
Training loss: 0.6590379476547241
Validation loss: 1.675247864056659

Epoch: 6| Step: 4
Training loss: 0.9270161986351013
Validation loss: 1.7000159563556794

Epoch: 6| Step: 5
Training loss: 1.015118956565857
Validation loss: 1.6727151127271755

Epoch: 6| Step: 6
Training loss: 0.5466399788856506
Validation loss: 1.7382645760813067

Epoch: 6| Step: 7
Training loss: 0.7884132862091064
Validation loss: 1.7511012733623545

Epoch: 6| Step: 8
Training loss: 0.6091321706771851
Validation loss: 1.718219353306678

Epoch: 6| Step: 9
Training loss: 0.3515774607658386
Validation loss: 1.721481196341976

Epoch: 6| Step: 10
Training loss: 0.7079247236251831
Validation loss: 1.68348664622153

Epoch: 6| Step: 11
Training loss: 0.8376778364181519
Validation loss: 1.6567062421511578

Epoch: 6| Step: 12
Training loss: 1.2331522703170776
Validation loss: 1.6686191789565548

Epoch: 6| Step: 13
Training loss: 0.6776822209358215
Validation loss: 1.6389867490337742

Epoch: 433| Step: 0
Training loss: 0.689676821231842
Validation loss: 1.64989270189757

Epoch: 6| Step: 1
Training loss: 1.0529193878173828
Validation loss: 1.621228201414949

Epoch: 6| Step: 2
Training loss: 0.8606129884719849
Validation loss: 1.6481310180438462

Epoch: 6| Step: 3
Training loss: 0.48839977383613586
Validation loss: 1.6718657285936418

Epoch: 6| Step: 4
Training loss: 0.5844188332557678
Validation loss: 1.7017436860710062

Epoch: 6| Step: 5
Training loss: 0.5201451778411865
Validation loss: 1.6960559788570608

Epoch: 6| Step: 6
Training loss: 0.7378249764442444
Validation loss: 1.7275289617558962

Epoch: 6| Step: 7
Training loss: 0.5747432112693787
Validation loss: 1.7118668953577678

Epoch: 6| Step: 8
Training loss: 0.9567427635192871
Validation loss: 1.7006045438910042

Epoch: 6| Step: 9
Training loss: 0.9533123970031738
Validation loss: 1.7029769433441984

Epoch: 6| Step: 10
Training loss: 0.4048616886138916
Validation loss: 1.710659711591659

Epoch: 6| Step: 11
Training loss: 0.842709481716156
Validation loss: 1.6891511947877946

Epoch: 6| Step: 12
Training loss: 0.6082803606987
Validation loss: 1.6931750543655888

Epoch: 6| Step: 13
Training loss: 0.5395028591156006
Validation loss: 1.6339791782440678

Epoch: 434| Step: 0
Training loss: 0.6767402291297913
Validation loss: 1.6215794189001924

Epoch: 6| Step: 1
Training loss: 0.4569101631641388
Validation loss: 1.6308726674766951

Epoch: 6| Step: 2
Training loss: 0.49445176124572754
Validation loss: 1.6254216432571411

Epoch: 6| Step: 3
Training loss: 0.8200457096099854
Validation loss: 1.6280293797933927

Epoch: 6| Step: 4
Training loss: 0.49385297298431396
Validation loss: 1.6375649898282942

Epoch: 6| Step: 5
Training loss: 0.5308378338813782
Validation loss: 1.686119988400449

Epoch: 6| Step: 6
Training loss: 0.8217037916183472
Validation loss: 1.7188338977034374

Epoch: 6| Step: 7
Training loss: 1.132303237915039
Validation loss: 1.756103733534454

Epoch: 6| Step: 8
Training loss: 1.0784828662872314
Validation loss: 1.7677460152615783

Epoch: 6| Step: 9
Training loss: 0.5218066573143005
Validation loss: 1.7419793285349363

Epoch: 6| Step: 10
Training loss: 0.8712437152862549
Validation loss: 1.7262699578398017

Epoch: 6| Step: 11
Training loss: 0.5162656307220459
Validation loss: 1.7228897681800268

Epoch: 6| Step: 12
Training loss: 0.8007382154464722
Validation loss: 1.6909305280254734

Epoch: 6| Step: 13
Training loss: 1.0472782850265503
Validation loss: 1.6659088750039377

Epoch: 435| Step: 0
Training loss: 0.48864424228668213
Validation loss: 1.6723977699074695

Epoch: 6| Step: 1
Training loss: 0.8117436170578003
Validation loss: 1.6868150323949835

Epoch: 6| Step: 2
Training loss: 0.6559256315231323
Validation loss: 1.6649581283651373

Epoch: 6| Step: 3
Training loss: 0.8281605243682861
Validation loss: 1.676787768640826

Epoch: 6| Step: 4
Training loss: 0.6081294417381287
Validation loss: 1.6755035538827219

Epoch: 6| Step: 5
Training loss: 0.6364076733589172
Validation loss: 1.6739719119123233

Epoch: 6| Step: 6
Training loss: 0.9285486936569214
Validation loss: 1.7185439640475857

Epoch: 6| Step: 7
Training loss: 0.5925887823104858
Validation loss: 1.7730405087112098

Epoch: 6| Step: 8
Training loss: 0.7530567646026611
Validation loss: 1.806218263923481

Epoch: 6| Step: 9
Training loss: 0.6505873799324036
Validation loss: 1.7925617207763016

Epoch: 6| Step: 10
Training loss: 0.7067722082138062
Validation loss: 1.7629424654027468

Epoch: 6| Step: 11
Training loss: 1.1449530124664307
Validation loss: 1.7409686555144608

Epoch: 6| Step: 12
Training loss: 0.6683273315429688
Validation loss: 1.6874836208999797

Epoch: 6| Step: 13
Training loss: 0.878714919090271
Validation loss: 1.686056995904574

Epoch: 436| Step: 0
Training loss: 0.5466508865356445
Validation loss: 1.6644821269537813

Epoch: 6| Step: 1
Training loss: 0.8188780546188354
Validation loss: 1.6590656759918376

Epoch: 6| Step: 2
Training loss: 1.0821300745010376
Validation loss: 1.6739861657542567

Epoch: 6| Step: 3
Training loss: 0.3235616385936737
Validation loss: 1.6648926273469002

Epoch: 6| Step: 4
Training loss: 0.9505212903022766
Validation loss: 1.6565877199172974

Epoch: 6| Step: 5
Training loss: 0.7240849733352661
Validation loss: 1.6541919092978201

Epoch: 6| Step: 6
Training loss: 0.3557182848453522
Validation loss: 1.7068648710045764

Epoch: 6| Step: 7
Training loss: 0.7616128921508789
Validation loss: 1.7075821302270378

Epoch: 6| Step: 8
Training loss: 0.7316042184829712
Validation loss: 1.6995392384067658

Epoch: 6| Step: 9
Training loss: 1.1086628437042236
Validation loss: 1.7381634994219708

Epoch: 6| Step: 10
Training loss: 0.528431236743927
Validation loss: 1.7402686713844218

Epoch: 6| Step: 11
Training loss: 0.4870855212211609
Validation loss: 1.7590240765643377

Epoch: 6| Step: 12
Training loss: 1.0834152698516846
Validation loss: 1.7393034645306167

Epoch: 6| Step: 13
Training loss: 0.9212548732757568
Validation loss: 1.6957022220857683

Epoch: 437| Step: 0
Training loss: 0.9015311598777771
Validation loss: 1.7204793114815988

Epoch: 6| Step: 1
Training loss: 0.6151247024536133
Validation loss: 1.6745407901784426

Epoch: 6| Step: 2
Training loss: 0.43018072843551636
Validation loss: 1.6701781083178777

Epoch: 6| Step: 3
Training loss: 0.7389075756072998
Validation loss: 1.642401482469292

Epoch: 6| Step: 4
Training loss: 0.855904221534729
Validation loss: 1.618926400779396

Epoch: 6| Step: 5
Training loss: 0.714823842048645
Validation loss: 1.608554518991901

Epoch: 6| Step: 6
Training loss: 0.6750071048736572
Validation loss: 1.6465008874093332

Epoch: 6| Step: 7
Training loss: 0.7666350603103638
Validation loss: 1.6341384200639621

Epoch: 6| Step: 8
Training loss: 0.363406777381897
Validation loss: 1.6366358008435977

Epoch: 6| Step: 9
Training loss: 0.6493875980377197
Validation loss: 1.6765253159307665

Epoch: 6| Step: 10
Training loss: 0.5803282260894775
Validation loss: 1.6990603452087731

Epoch: 6| Step: 11
Training loss: 0.957705557346344
Validation loss: 1.703444734696419

Epoch: 6| Step: 12
Training loss: 0.7469285726547241
Validation loss: 1.719790042087596

Epoch: 6| Step: 13
Training loss: 0.7936882972717285
Validation loss: 1.6916749233840613

Epoch: 438| Step: 0
Training loss: 0.5950884819030762
Validation loss: 1.7316629425171883

Epoch: 6| Step: 1
Training loss: 0.6164335608482361
Validation loss: 1.740771544876919

Epoch: 6| Step: 2
Training loss: 0.8790043592453003
Validation loss: 1.7325409778984644

Epoch: 6| Step: 3
Training loss: 0.3983672559261322
Validation loss: 1.6803457775423605

Epoch: 6| Step: 4
Training loss: 0.9048088788986206
Validation loss: 1.686682753665473

Epoch: 6| Step: 5
Training loss: 0.4606603682041168
Validation loss: 1.6866813013630528

Epoch: 6| Step: 6
Training loss: 0.4807267189025879
Validation loss: 1.675332812852757

Epoch: 6| Step: 7
Training loss: 0.4591367244720459
Validation loss: 1.6703768212308165

Epoch: 6| Step: 8
Training loss: 0.8536460399627686
Validation loss: 1.6597869268027685

Epoch: 6| Step: 9
Training loss: 0.8629135489463806
Validation loss: 1.6767221484132993

Epoch: 6| Step: 10
Training loss: 0.6370363831520081
Validation loss: 1.6571229991092478

Epoch: 6| Step: 11
Training loss: 0.5543843507766724
Validation loss: 1.6828666117883497

Epoch: 6| Step: 12
Training loss: 0.8178203105926514
Validation loss: 1.6920673308833953

Epoch: 6| Step: 13
Training loss: 1.0718457698822021
Validation loss: 1.6815449101950533

Epoch: 439| Step: 0
Training loss: 0.793201208114624
Validation loss: 1.7464921269365536

Epoch: 6| Step: 1
Training loss: 0.46422210335731506
Validation loss: 1.7524678245667489

Epoch: 6| Step: 2
Training loss: 0.9005306363105774
Validation loss: 1.7791893930845364

Epoch: 6| Step: 3
Training loss: 0.7766618728637695
Validation loss: 1.7705322927044285

Epoch: 6| Step: 4
Training loss: 0.8018771409988403
Validation loss: 1.7794042941062682

Epoch: 6| Step: 5
Training loss: 0.5750722289085388
Validation loss: 1.754470286830779

Epoch: 6| Step: 6
Training loss: 0.5288776159286499
Validation loss: 1.7553641898657686

Epoch: 6| Step: 7
Training loss: 0.9580631256103516
Validation loss: 1.6645637712171

Epoch: 6| Step: 8
Training loss: 0.663724958896637
Validation loss: 1.6769803352253412

Epoch: 6| Step: 9
Training loss: 0.5070424675941467
Validation loss: 1.6788917421012797

Epoch: 6| Step: 10
Training loss: 0.49190202355384827
Validation loss: 1.6818065797128985

Epoch: 6| Step: 11
Training loss: 0.7221588492393494
Validation loss: 1.6758613330061718

Epoch: 6| Step: 12
Training loss: 0.9972426295280457
Validation loss: 1.646779493619037

Epoch: 6| Step: 13
Training loss: 0.4205566942691803
Validation loss: 1.6874377407053465

Epoch: 440| Step: 0
Training loss: 0.8224914073944092
Validation loss: 1.6850262559870237

Epoch: 6| Step: 1
Training loss: 0.7375282645225525
Validation loss: 1.6409028230174896

Epoch: 6| Step: 2
Training loss: 0.6857749819755554
Validation loss: 1.6381374007912093

Epoch: 6| Step: 3
Training loss: 0.6355842351913452
Validation loss: 1.6507622682920067

Epoch: 6| Step: 4
Training loss: 0.3966820538043976
Validation loss: 1.6811659028453212

Epoch: 6| Step: 5
Training loss: 0.6589481234550476
Validation loss: 1.7076886136044738

Epoch: 6| Step: 6
Training loss: 1.0554993152618408
Validation loss: 1.720384850296923

Epoch: 6| Step: 7
Training loss: 0.7332378029823303
Validation loss: 1.7333162933267572

Epoch: 6| Step: 8
Training loss: 0.6724162101745605
Validation loss: 1.7641071914344706

Epoch: 6| Step: 9
Training loss: 0.6164193153381348
Validation loss: 1.7226714857162968

Epoch: 6| Step: 10
Training loss: 0.858007550239563
Validation loss: 1.7305742732940181

Epoch: 6| Step: 11
Training loss: 0.6187878251075745
Validation loss: 1.7068116023976316

Epoch: 6| Step: 12
Training loss: 0.43369635939598083
Validation loss: 1.642595414192446

Epoch: 6| Step: 13
Training loss: 0.5189908742904663
Validation loss: 1.6100078257181312

Epoch: 441| Step: 0
Training loss: 0.8103638887405396
Validation loss: 1.590209775073554

Epoch: 6| Step: 1
Training loss: 0.6886728405952454
Validation loss: 1.5739135562732656

Epoch: 6| Step: 2
Training loss: 0.4470193088054657
Validation loss: 1.5558662196641326

Epoch: 6| Step: 3
Training loss: 0.9447226524353027
Validation loss: 1.5787289398972706

Epoch: 6| Step: 4
Training loss: 0.6301882266998291
Validation loss: 1.5976734161376953

Epoch: 6| Step: 5
Training loss: 0.41598638892173767
Validation loss: 1.6358606533337665

Epoch: 6| Step: 6
Training loss: 0.476162850856781
Validation loss: 1.6920660977722497

Epoch: 6| Step: 7
Training loss: 0.6932147741317749
Validation loss: 1.7344308937749555

Epoch: 6| Step: 8
Training loss: 0.740149974822998
Validation loss: 1.7439939578374226

Epoch: 6| Step: 9
Training loss: 1.1210193634033203
Validation loss: 1.7831937100297661

Epoch: 6| Step: 10
Training loss: 0.41353362798690796
Validation loss: 1.8358035343949513

Epoch: 6| Step: 11
Training loss: 1.0994267463684082
Validation loss: 1.8844857177426737

Epoch: 6| Step: 12
Training loss: 0.7245997190475464
Validation loss: 1.842127671805761

Epoch: 6| Step: 13
Training loss: 0.8735383749008179
Validation loss: 1.7897795836130779

Epoch: 442| Step: 0
Training loss: 0.7962499856948853
Validation loss: 1.7361790390424832

Epoch: 6| Step: 1
Training loss: 0.9939157366752625
Validation loss: 1.683837886779539

Epoch: 6| Step: 2
Training loss: 0.6810685992240906
Validation loss: 1.677611227958433

Epoch: 6| Step: 3
Training loss: 1.0112977027893066
Validation loss: 1.648389103592083

Epoch: 6| Step: 4
Training loss: 0.612367570400238
Validation loss: 1.5945866915487474

Epoch: 6| Step: 5
Training loss: 0.7627579569816589
Validation loss: 1.6037185115198935

Epoch: 6| Step: 6
Training loss: 0.5593749284744263
Validation loss: 1.610130892005018

Epoch: 6| Step: 7
Training loss: 0.8996274471282959
Validation loss: 1.5830109721870833

Epoch: 6| Step: 8
Training loss: 0.5385669469833374
Validation loss: 1.608165684566703

Epoch: 6| Step: 9
Training loss: 0.6354503631591797
Validation loss: 1.5907578276049705

Epoch: 6| Step: 10
Training loss: 0.736183762550354
Validation loss: 1.6674850615121986

Epoch: 6| Step: 11
Training loss: 0.581372082233429
Validation loss: 1.658657217538485

Epoch: 6| Step: 12
Training loss: 0.43792980909347534
Validation loss: 1.706877459761917

Epoch: 6| Step: 13
Training loss: 0.5498204827308655
Validation loss: 1.7074942575987948

Epoch: 443| Step: 0
Training loss: 0.612492561340332
Validation loss: 1.73285033113213

Epoch: 6| Step: 1
Training loss: 0.5931038856506348
Validation loss: 1.7259916836215603

Epoch: 6| Step: 2
Training loss: 0.7966388463973999
Validation loss: 1.7271624636906449

Epoch: 6| Step: 3
Training loss: 0.8188711404800415
Validation loss: 1.6836653319738244

Epoch: 6| Step: 4
Training loss: 0.621284008026123
Validation loss: 1.7043521045356669

Epoch: 6| Step: 5
Training loss: 0.8305317163467407
Validation loss: 1.6569027259785643

Epoch: 6| Step: 6
Training loss: 0.5500185489654541
Validation loss: 1.6464471586288945

Epoch: 6| Step: 7
Training loss: 0.6122348308563232
Validation loss: 1.6425792158290904

Epoch: 6| Step: 8
Training loss: 0.5736737251281738
Validation loss: 1.598784432616285

Epoch: 6| Step: 9
Training loss: 0.6006168127059937
Validation loss: 1.6192912081236481

Epoch: 6| Step: 10
Training loss: 0.7576256990432739
Validation loss: 1.621207957626671

Epoch: 6| Step: 11
Training loss: 0.8038854598999023
Validation loss: 1.6533877952124483

Epoch: 6| Step: 12
Training loss: 0.8166258335113525
Validation loss: 1.6848397754853772

Epoch: 6| Step: 13
Training loss: 0.7374836206436157
Validation loss: 1.7136394144386373

Epoch: 444| Step: 0
Training loss: 0.5925971269607544
Validation loss: 1.7006026685878795

Epoch: 6| Step: 1
Training loss: 0.587677001953125
Validation loss: 1.760037351039148

Epoch: 6| Step: 2
Training loss: 0.8619229793548584
Validation loss: 1.7760813646419074

Epoch: 6| Step: 3
Training loss: 0.6649088263511658
Validation loss: 1.7597208522981214

Epoch: 6| Step: 4
Training loss: 0.5493870973587036
Validation loss: 1.6995610485794723

Epoch: 6| Step: 5
Training loss: 0.7513306140899658
Validation loss: 1.6293996393039663

Epoch: 6| Step: 6
Training loss: 0.8701156377792358
Validation loss: 1.616332782212124

Epoch: 6| Step: 7
Training loss: 0.4479232430458069
Validation loss: 1.5731223449912122

Epoch: 6| Step: 8
Training loss: 0.7883861064910889
Validation loss: 1.561608341432387

Epoch: 6| Step: 9
Training loss: 0.6663212180137634
Validation loss: 1.5523272246442816

Epoch: 6| Step: 10
Training loss: 0.5689837336540222
Validation loss: 1.5718078190280544

Epoch: 6| Step: 11
Training loss: 0.8392125368118286
Validation loss: 1.616207895740386

Epoch: 6| Step: 12
Training loss: 0.7599485516548157
Validation loss: 1.6192993271735407

Epoch: 6| Step: 13
Training loss: 1.3148207664489746
Validation loss: 1.6801627970510913

Epoch: 445| Step: 0
Training loss: 0.8106465339660645
Validation loss: 1.686955448119871

Epoch: 6| Step: 1
Training loss: 0.332236111164093
Validation loss: 1.6963460573586084

Epoch: 6| Step: 2
Training loss: 0.7558251619338989
Validation loss: 1.6813848839011243

Epoch: 6| Step: 3
Training loss: 0.5073010921478271
Validation loss: 1.6577235165462698

Epoch: 6| Step: 4
Training loss: 0.9674327373504639
Validation loss: 1.6697884439140238

Epoch: 6| Step: 5
Training loss: 0.8083716630935669
Validation loss: 1.67624677893936

Epoch: 6| Step: 6
Training loss: 0.4001742899417877
Validation loss: 1.6619032723929292

Epoch: 6| Step: 7
Training loss: 0.46096736192703247
Validation loss: 1.6531867429774294

Epoch: 6| Step: 8
Training loss: 1.24696946144104
Validation loss: 1.6824779472043436

Epoch: 6| Step: 9
Training loss: 0.5493435263633728
Validation loss: 1.6593213850452053

Epoch: 6| Step: 10
Training loss: 0.6831544637680054
Validation loss: 1.6246365744580504

Epoch: 6| Step: 11
Training loss: 0.6954078674316406
Validation loss: 1.659954495327447

Epoch: 6| Step: 12
Training loss: 0.6462523937225342
Validation loss: 1.6359553362733574

Epoch: 6| Step: 13
Training loss: 0.5098742842674255
Validation loss: 1.6480513631656606

Epoch: 446| Step: 0
Training loss: 0.4520689845085144
Validation loss: 1.6288284178703063

Epoch: 6| Step: 1
Training loss: 0.8416942358016968
Validation loss: 1.6306281653783654

Epoch: 6| Step: 2
Training loss: 0.3931671380996704
Validation loss: 1.668960525143531

Epoch: 6| Step: 3
Training loss: 0.6526076793670654
Validation loss: 1.7226024468739827

Epoch: 6| Step: 4
Training loss: 0.8799386024475098
Validation loss: 1.760438557594053

Epoch: 6| Step: 5
Training loss: 0.8360142707824707
Validation loss: 1.751762810573783

Epoch: 6| Step: 6
Training loss: 0.6722594499588013
Validation loss: 1.7533517627305881

Epoch: 6| Step: 7
Training loss: 0.47957843542099
Validation loss: 1.7611972260218796

Epoch: 6| Step: 8
Training loss: 1.160536766052246
Validation loss: 1.761996482008247

Epoch: 6| Step: 9
Training loss: 0.617480456829071
Validation loss: 1.7142713480098273

Epoch: 6| Step: 10
Training loss: 0.22043384611606598
Validation loss: 1.7074508000445623

Epoch: 6| Step: 11
Training loss: 0.8423105478286743
Validation loss: 1.7076694093724734

Epoch: 6| Step: 12
Training loss: 0.6183493137359619
Validation loss: 1.6633709502476517

Epoch: 6| Step: 13
Training loss: 0.5880435705184937
Validation loss: 1.66804709101236

Epoch: 447| Step: 0
Training loss: 0.6089844107627869
Validation loss: 1.6338328366638513

Epoch: 6| Step: 1
Training loss: 0.6973257660865784
Validation loss: 1.6166719275136148

Epoch: 6| Step: 2
Training loss: 0.5301611423492432
Validation loss: 1.5859991991391746

Epoch: 6| Step: 3
Training loss: 0.9469338655471802
Validation loss: 1.6145690256549465

Epoch: 6| Step: 4
Training loss: 0.6544163227081299
Validation loss: 1.6055206406501032

Epoch: 6| Step: 5
Training loss: 0.7359355688095093
Validation loss: 1.5753136700199497

Epoch: 6| Step: 6
Training loss: 0.8105772137641907
Validation loss: 1.5834732478664768

Epoch: 6| Step: 7
Training loss: 0.6675406694412231
Validation loss: 1.668637534623505

Epoch: 6| Step: 8
Training loss: 1.0467100143432617
Validation loss: 1.6363618527689288

Epoch: 6| Step: 9
Training loss: 0.35450905561447144
Validation loss: 1.6520843275131718

Epoch: 6| Step: 10
Training loss: 0.43826189637184143
Validation loss: 1.6844022325290147

Epoch: 6| Step: 11
Training loss: 0.44772788882255554
Validation loss: 1.6979004926578973

Epoch: 6| Step: 12
Training loss: 0.7741913795471191
Validation loss: 1.7143362516997962

Epoch: 6| Step: 13
Training loss: 0.6611974239349365
Validation loss: 1.7010589684209516

Epoch: 448| Step: 0
Training loss: 0.6390969753265381
Validation loss: 1.7059657906973233

Epoch: 6| Step: 1
Training loss: 0.46745848655700684
Validation loss: 1.681143396644182

Epoch: 6| Step: 2
Training loss: 0.5581586360931396
Validation loss: 1.6917587749419674

Epoch: 6| Step: 3
Training loss: 0.8785282969474792
Validation loss: 1.6836065194940055

Epoch: 6| Step: 4
Training loss: 0.44052261114120483
Validation loss: 1.6587624472956504

Epoch: 6| Step: 5
Training loss: 0.7375486493110657
Validation loss: 1.6603690988274031

Epoch: 6| Step: 6
Training loss: 0.7639457583427429
Validation loss: 1.6127742977552517

Epoch: 6| Step: 7
Training loss: 0.5225420594215393
Validation loss: 1.605399897021632

Epoch: 6| Step: 8
Training loss: 0.535714328289032
Validation loss: 1.6073160966237385

Epoch: 6| Step: 9
Training loss: 0.5053810477256775
Validation loss: 1.6221283494785268

Epoch: 6| Step: 10
Training loss: 0.5353378653526306
Validation loss: 1.6470553195604714

Epoch: 6| Step: 11
Training loss: 1.125669002532959
Validation loss: 1.6685832418421263

Epoch: 6| Step: 12
Training loss: 0.7024824619293213
Validation loss: 1.6754619177951608

Epoch: 6| Step: 13
Training loss: 0.6814608573913574
Validation loss: 1.644599389004451

Epoch: 449| Step: 0
Training loss: 0.7781184315681458
Validation loss: 1.6551854123351395

Epoch: 6| Step: 1
Training loss: 0.6538891196250916
Validation loss: 1.6463170897576116

Epoch: 6| Step: 2
Training loss: 0.6477907299995422
Validation loss: 1.6320423567166893

Epoch: 6| Step: 3
Training loss: 0.918927788734436
Validation loss: 1.6192047570341377

Epoch: 6| Step: 4
Training loss: 0.9416025876998901
Validation loss: 1.5817006467491068

Epoch: 6| Step: 5
Training loss: 0.4194961190223694
Validation loss: 1.6157572218166885

Epoch: 6| Step: 6
Training loss: 0.7434890270233154
Validation loss: 1.6019619318746752

Epoch: 6| Step: 7
Training loss: 0.5150569081306458
Validation loss: 1.6501876705436296

Epoch: 6| Step: 8
Training loss: 0.40541186928749084
Validation loss: 1.6841888081642888

Epoch: 6| Step: 9
Training loss: 0.44208693504333496
Validation loss: 1.690893796182448

Epoch: 6| Step: 10
Training loss: 0.7588728666305542
Validation loss: 1.7007174812337404

Epoch: 6| Step: 11
Training loss: 0.5897080898284912
Validation loss: 1.6963186366583711

Epoch: 6| Step: 12
Training loss: 0.41715317964553833
Validation loss: 1.7230134638406898

Epoch: 6| Step: 13
Training loss: 0.7603104114532471
Validation loss: 1.6858480438109367

Epoch: 450| Step: 0
Training loss: 0.6784302592277527
Validation loss: 1.6836725511858541

Epoch: 6| Step: 1
Training loss: 0.8398170471191406
Validation loss: 1.6695325964240617

Epoch: 6| Step: 2
Training loss: 0.4709472060203552
Validation loss: 1.6523290667482602

Epoch: 6| Step: 3
Training loss: 0.8666987419128418
Validation loss: 1.6340964801849858

Epoch: 6| Step: 4
Training loss: 0.8696510791778564
Validation loss: 1.6298574811668807

Epoch: 6| Step: 5
Training loss: 0.6851166486740112
Validation loss: 1.631325662776988

Epoch: 6| Step: 6
Training loss: 0.6169857978820801
Validation loss: 1.6311242272776942

Epoch: 6| Step: 7
Training loss: 0.5105255246162415
Validation loss: 1.6225099012415896

Epoch: 6| Step: 8
Training loss: 0.8419159650802612
Validation loss: 1.6250239213307698

Epoch: 6| Step: 9
Training loss: 0.43973812460899353
Validation loss: 1.5942772870422692

Epoch: 6| Step: 10
Training loss: 0.5107867121696472
Validation loss: 1.6233712947496803

Epoch: 6| Step: 11
Training loss: 0.41519612073898315
Validation loss: 1.6249879970345447

Epoch: 6| Step: 12
Training loss: 0.34464725852012634
Validation loss: 1.7107870027583132

Epoch: 6| Step: 13
Training loss: 0.4676295816898346
Validation loss: 1.7220114008072884

Epoch: 451| Step: 0
Training loss: 0.4539165496826172
Validation loss: 1.7072179035473896

Epoch: 6| Step: 1
Training loss: 0.7158012986183167
Validation loss: 1.7113166265590216

Epoch: 6| Step: 2
Training loss: 0.8236923217773438
Validation loss: 1.6836203887898435

Epoch: 6| Step: 3
Training loss: 0.4648800492286682
Validation loss: 1.6486429834878573

Epoch: 6| Step: 4
Training loss: 0.6381056308746338
Validation loss: 1.6604774587897844

Epoch: 6| Step: 5
Training loss: 0.8418663740158081
Validation loss: 1.6621652085294005

Epoch: 6| Step: 6
Training loss: 0.43674057722091675
Validation loss: 1.7066683205225135

Epoch: 6| Step: 7
Training loss: 0.8364200592041016
Validation loss: 1.6836712635973448

Epoch: 6| Step: 8
Training loss: 0.7935968637466431
Validation loss: 1.683633715875687

Epoch: 6| Step: 9
Training loss: 0.6624885201454163
Validation loss: 1.6849294529166272

Epoch: 6| Step: 10
Training loss: 0.3821171522140503
Validation loss: 1.6801356936013827

Epoch: 6| Step: 11
Training loss: 0.5204220414161682
Validation loss: 1.6996602858266523

Epoch: 6| Step: 12
Training loss: 0.5053573250770569
Validation loss: 1.6725507333714476

Epoch: 6| Step: 13
Training loss: 0.7151313424110413
Validation loss: 1.6551916022454538

Epoch: 452| Step: 0
Training loss: 0.5980154275894165
Validation loss: 1.6469026329696819

Epoch: 6| Step: 1
Training loss: 0.7648590803146362
Validation loss: 1.6967091509090957

Epoch: 6| Step: 2
Training loss: 0.5415657758712769
Validation loss: 1.6960824048647316

Epoch: 6| Step: 3
Training loss: 0.5215206742286682
Validation loss: 1.6623630267317577

Epoch: 6| Step: 4
Training loss: 0.6085978746414185
Validation loss: 1.6722058698695192

Epoch: 6| Step: 5
Training loss: 0.5274726152420044
Validation loss: 1.6724062017215195

Epoch: 6| Step: 6
Training loss: 0.32856476306915283
Validation loss: 1.6871938384989256

Epoch: 6| Step: 7
Training loss: 0.8222877979278564
Validation loss: 1.653218138602472

Epoch: 6| Step: 8
Training loss: 0.4359029233455658
Validation loss: 1.7214378900425409

Epoch: 6| Step: 9
Training loss: 0.643211841583252
Validation loss: 1.6649608278787265

Epoch: 6| Step: 10
Training loss: 0.691636860370636
Validation loss: 1.6428608035528531

Epoch: 6| Step: 11
Training loss: 0.9628517031669617
Validation loss: 1.6366764563386158

Epoch: 6| Step: 12
Training loss: 0.7991622090339661
Validation loss: 1.6421373390382337

Epoch: 6| Step: 13
Training loss: 0.6333966851234436
Validation loss: 1.5883322479904338

Epoch: 453| Step: 0
Training loss: 0.8697583675384521
Validation loss: 1.6169444296949653

Epoch: 6| Step: 1
Training loss: 0.6758441925048828
Validation loss: 1.626971180720996

Epoch: 6| Step: 2
Training loss: 0.6776050925254822
Validation loss: 1.5692591718448106

Epoch: 6| Step: 3
Training loss: 0.2684323191642761
Validation loss: 1.5821920864043697

Epoch: 6| Step: 4
Training loss: 0.557046115398407
Validation loss: 1.6209847516911005

Epoch: 6| Step: 5
Training loss: 0.7256109714508057
Validation loss: 1.6072564407061505

Epoch: 6| Step: 6
Training loss: 0.7069850564002991
Validation loss: 1.6499331728104623

Epoch: 6| Step: 7
Training loss: 0.4871773421764374
Validation loss: 1.6381316582361858

Epoch: 6| Step: 8
Training loss: 0.87662672996521
Validation loss: 1.6732095056964504

Epoch: 6| Step: 9
Training loss: 0.8616737127304077
Validation loss: 1.6903212634466027

Epoch: 6| Step: 10
Training loss: 0.8201999664306641
Validation loss: 1.701170011233258

Epoch: 6| Step: 11
Training loss: 0.2613125443458557
Validation loss: 1.733570659032432

Epoch: 6| Step: 12
Training loss: 0.5335266590118408
Validation loss: 1.697762691846458

Epoch: 6| Step: 13
Training loss: 0.30840790271759033
Validation loss: 1.7088553802941435

Epoch: 454| Step: 0
Training loss: 0.6564257144927979
Validation loss: 1.6742351721691828

Epoch: 6| Step: 1
Training loss: 0.37496644258499146
Validation loss: 1.6231154280324136

Epoch: 6| Step: 2
Training loss: 0.5916604399681091
Validation loss: 1.6016074752294889

Epoch: 6| Step: 3
Training loss: 0.6595275402069092
Validation loss: 1.590663824030148

Epoch: 6| Step: 4
Training loss: 0.6979899406433105
Validation loss: 1.5988646117589806

Epoch: 6| Step: 5
Training loss: 0.6868902444839478
Validation loss: 1.5922700948612665

Epoch: 6| Step: 6
Training loss: 0.5999983549118042
Validation loss: 1.582248580071234

Epoch: 6| Step: 7
Training loss: 0.44319790601730347
Validation loss: 1.6494525606914232

Epoch: 6| Step: 8
Training loss: 0.7555655241012573
Validation loss: 1.632761986024918

Epoch: 6| Step: 9
Training loss: 0.6357234120368958
Validation loss: 1.6476010289243472

Epoch: 6| Step: 10
Training loss: 0.7397499084472656
Validation loss: 1.6282255598293838

Epoch: 6| Step: 11
Training loss: 0.9607410430908203
Validation loss: 1.6506285795601465

Epoch: 6| Step: 12
Training loss: 0.46807196736335754
Validation loss: 1.658051436947238

Epoch: 6| Step: 13
Training loss: 0.4253632724285126
Validation loss: 1.7000959022070772

Epoch: 455| Step: 0
Training loss: 0.7428179979324341
Validation loss: 1.720468472408992

Epoch: 6| Step: 1
Training loss: 0.5203879475593567
Validation loss: 1.7603899612221667

Epoch: 6| Step: 2
Training loss: 0.49410390853881836
Validation loss: 1.7450028119548675

Epoch: 6| Step: 3
Training loss: 0.7492247819900513
Validation loss: 1.7076483567555745

Epoch: 6| Step: 4
Training loss: 0.30102407932281494
Validation loss: 1.694956111651595

Epoch: 6| Step: 5
Training loss: 1.0406975746154785
Validation loss: 1.660003592891078

Epoch: 6| Step: 6
Training loss: 0.3751329481601715
Validation loss: 1.6704515846826697

Epoch: 6| Step: 7
Training loss: 0.5155034065246582
Validation loss: 1.6267615736171763

Epoch: 6| Step: 8
Training loss: 0.7015920281410217
Validation loss: 1.676854960380062

Epoch: 6| Step: 9
Training loss: 0.6356989741325378
Validation loss: 1.644899893832463

Epoch: 6| Step: 10
Training loss: 1.0676212310791016
Validation loss: 1.6393774555575462

Epoch: 6| Step: 11
Training loss: 0.459174782037735
Validation loss: 1.6434263965134979

Epoch: 6| Step: 12
Training loss: 0.5252554416656494
Validation loss: 1.6509119925960418

Epoch: 6| Step: 13
Training loss: 0.8104972839355469
Validation loss: 1.698772527838266

Epoch: 456| Step: 0
Training loss: 0.4131261110305786
Validation loss: 1.709907538147383

Epoch: 6| Step: 1
Training loss: 0.4586828947067261
Validation loss: 1.720251332047165

Epoch: 6| Step: 2
Training loss: 0.5446479320526123
Validation loss: 1.7509612203926168

Epoch: 6| Step: 3
Training loss: 0.5655683875083923
Validation loss: 1.792904725638769

Epoch: 6| Step: 4
Training loss: 0.8719362020492554
Validation loss: 1.7907218997196486

Epoch: 6| Step: 5
Training loss: 0.7248637676239014
Validation loss: 1.731925828482515

Epoch: 6| Step: 6
Training loss: 0.7341486215591431
Validation loss: 1.7675901459109398

Epoch: 6| Step: 7
Training loss: 0.7981059551239014
Validation loss: 1.7138717623167141

Epoch: 6| Step: 8
Training loss: 0.42881056666374207
Validation loss: 1.7122578915729318

Epoch: 6| Step: 9
Training loss: 0.6306369304656982
Validation loss: 1.6638879019726989

Epoch: 6| Step: 10
Training loss: 0.4932366609573364
Validation loss: 1.6588826294868224

Epoch: 6| Step: 11
Training loss: 0.7007548809051514
Validation loss: 1.6086379622900358

Epoch: 6| Step: 12
Training loss: 0.7645256519317627
Validation loss: 1.5869639265921809

Epoch: 6| Step: 13
Training loss: 0.7664074301719666
Validation loss: 1.5976514290737849

Epoch: 457| Step: 0
Training loss: 0.438026487827301
Validation loss: 1.6216433086702902

Epoch: 6| Step: 1
Training loss: 0.8384017944335938
Validation loss: 1.6035407486782278

Epoch: 6| Step: 2
Training loss: 0.649909496307373
Validation loss: 1.592496008001348

Epoch: 6| Step: 3
Training loss: 0.4058942198753357
Validation loss: 1.6222648851333126

Epoch: 6| Step: 4
Training loss: 0.7423351407051086
Validation loss: 1.6332274688187467

Epoch: 6| Step: 5
Training loss: 0.7303643226623535
Validation loss: 1.6490151830898818

Epoch: 6| Step: 6
Training loss: 0.3567533791065216
Validation loss: 1.6985518829796904

Epoch: 6| Step: 7
Training loss: 0.7226930260658264
Validation loss: 1.6996359889225294

Epoch: 6| Step: 8
Training loss: 0.621354341506958
Validation loss: 1.7146358425899217

Epoch: 6| Step: 9
Training loss: 0.51900315284729
Validation loss: 1.698328265579798

Epoch: 6| Step: 10
Training loss: 0.45261240005493164
Validation loss: 1.7149112788579797

Epoch: 6| Step: 11
Training loss: 0.7430678009986877
Validation loss: 1.685605397788427

Epoch: 6| Step: 12
Training loss: 0.6458707451820374
Validation loss: 1.6438444955374605

Epoch: 6| Step: 13
Training loss: 1.0181822776794434
Validation loss: 1.62121085838605

Epoch: 458| Step: 0
Training loss: 0.8458822965621948
Validation loss: 1.5890955732714744

Epoch: 6| Step: 1
Training loss: 0.45828884840011597
Validation loss: 1.5823899610068208

Epoch: 6| Step: 2
Training loss: 0.5722594857215881
Validation loss: 1.5714466994808567

Epoch: 6| Step: 3
Training loss: 0.6138229966163635
Validation loss: 1.5634489918267855

Epoch: 6| Step: 4
Training loss: 0.7151412963867188
Validation loss: 1.54988996700574

Epoch: 6| Step: 5
Training loss: 0.5644484758377075
Validation loss: 1.6080702786804528

Epoch: 6| Step: 6
Training loss: 0.532711386680603
Validation loss: 1.643665926430815

Epoch: 6| Step: 7
Training loss: 0.38334187865257263
Validation loss: 1.6852307511914162

Epoch: 6| Step: 8
Training loss: 1.2286759614944458
Validation loss: 1.682309796733241

Epoch: 6| Step: 9
Training loss: 0.3901098668575287
Validation loss: 1.6826213700796968

Epoch: 6| Step: 10
Training loss: 0.46959108114242554
Validation loss: 1.6791017465693976

Epoch: 6| Step: 11
Training loss: 0.41126373410224915
Validation loss: 1.721399454660313

Epoch: 6| Step: 12
Training loss: 0.8904631733894348
Validation loss: 1.758378327533763

Epoch: 6| Step: 13
Training loss: 0.790569007396698
Validation loss: 1.7641356068272744

Epoch: 459| Step: 0
Training loss: 0.2830502986907959
Validation loss: 1.7348749253057665

Epoch: 6| Step: 1
Training loss: 0.7038612365722656
Validation loss: 1.6856570628381544

Epoch: 6| Step: 2
Training loss: 0.6765890121459961
Validation loss: 1.6457828796038063

Epoch: 6| Step: 3
Training loss: 0.5870482325553894
Validation loss: 1.641192255481597

Epoch: 6| Step: 4
Training loss: 0.4207656979560852
Validation loss: 1.6221345675888883

Epoch: 6| Step: 5
Training loss: 1.1023716926574707
Validation loss: 1.621695823566888

Epoch: 6| Step: 6
Training loss: 0.7018023729324341
Validation loss: 1.635619330149825

Epoch: 6| Step: 7
Training loss: 0.6515233516693115
Validation loss: 1.6087232482048772

Epoch: 6| Step: 8
Training loss: 0.615658164024353
Validation loss: 1.6209296603356638

Epoch: 6| Step: 9
Training loss: 0.40834885835647583
Validation loss: 1.592917788413263

Epoch: 6| Step: 10
Training loss: 0.47341540455818176
Validation loss: 1.5890648954658098

Epoch: 6| Step: 11
Training loss: 0.5916681885719299
Validation loss: 1.61526862395707

Epoch: 6| Step: 12
Training loss: 0.7206096649169922
Validation loss: 1.6197652022043865

Epoch: 6| Step: 13
Training loss: 0.5623937249183655
Validation loss: 1.6362637601872927

Epoch: 460| Step: 0
Training loss: 0.4265497028827667
Validation loss: 1.6656589046601327

Epoch: 6| Step: 1
Training loss: 0.8549356460571289
Validation loss: 1.6511507752121135

Epoch: 6| Step: 2
Training loss: 0.5331822037696838
Validation loss: 1.6832338545912056

Epoch: 6| Step: 3
Training loss: 0.5965389013290405
Validation loss: 1.7118183400041314

Epoch: 6| Step: 4
Training loss: 0.3124884068965912
Validation loss: 1.675620763532577

Epoch: 6| Step: 5
Training loss: 0.5902483463287354
Validation loss: 1.6636698284456808

Epoch: 6| Step: 6
Training loss: 0.4706466794013977
Validation loss: 1.6166637507818078

Epoch: 6| Step: 7
Training loss: 0.7530419230461121
Validation loss: 1.6332738809688117

Epoch: 6| Step: 8
Training loss: 0.9388536214828491
Validation loss: 1.6169328715211602

Epoch: 6| Step: 9
Training loss: 0.6198700666427612
Validation loss: 1.6056213173815

Epoch: 6| Step: 10
Training loss: 0.5368609428405762
Validation loss: 1.625770127901467

Epoch: 6| Step: 11
Training loss: 0.5113551616668701
Validation loss: 1.6035817733374975

Epoch: 6| Step: 12
Training loss: 0.8647672533988953
Validation loss: 1.644754103434983

Epoch: 6| Step: 13
Training loss: 0.3103860318660736
Validation loss: 1.7012901677880237

Epoch: 461| Step: 0
Training loss: 0.4734705090522766
Validation loss: 1.6647027718123568

Epoch: 6| Step: 1
Training loss: 0.5990229845046997
Validation loss: 1.6887647618529618

Epoch: 6| Step: 2
Training loss: 0.6542235612869263
Validation loss: 1.7393633396394792

Epoch: 6| Step: 3
Training loss: 0.6167582869529724
Validation loss: 1.7212220879011257

Epoch: 6| Step: 4
Training loss: 0.8285176753997803
Validation loss: 1.7276400135409447

Epoch: 6| Step: 5
Training loss: 0.5645890235900879
Validation loss: 1.741923346314379

Epoch: 6| Step: 6
Training loss: 0.5665602684020996
Validation loss: 1.7359119153791858

Epoch: 6| Step: 7
Training loss: 0.5114335417747498
Validation loss: 1.7078571883581017

Epoch: 6| Step: 8
Training loss: 0.5561215281486511
Validation loss: 1.6519700737409695

Epoch: 6| Step: 9
Training loss: 0.6334395408630371
Validation loss: 1.6164227326711018

Epoch: 6| Step: 10
Training loss: 0.45085379481315613
Validation loss: 1.6313764484979774

Epoch: 6| Step: 11
Training loss: 0.6541431546211243
Validation loss: 1.6429435822271532

Epoch: 6| Step: 12
Training loss: 0.6405653357505798
Validation loss: 1.6800050773928243

Epoch: 6| Step: 13
Training loss: 0.8517434597015381
Validation loss: 1.7094690069075553

Epoch: 462| Step: 0
Training loss: 0.6508697271347046
Validation loss: 1.7251958744500273

Epoch: 6| Step: 1
Training loss: 0.472201943397522
Validation loss: 1.6999130095205

Epoch: 6| Step: 2
Training loss: 0.5791959166526794
Validation loss: 1.7271885038704

Epoch: 6| Step: 3
Training loss: 0.919119119644165
Validation loss: 1.6814254240323139

Epoch: 6| Step: 4
Training loss: 0.8711794018745422
Validation loss: 1.670642045236403

Epoch: 6| Step: 5
Training loss: 0.9459853768348694
Validation loss: 1.6512800429456977

Epoch: 6| Step: 6
Training loss: 0.4583638906478882
Validation loss: 1.6547792778220227

Epoch: 6| Step: 7
Training loss: 0.6391793489456177
Validation loss: 1.6575975918000745

Epoch: 6| Step: 8
Training loss: 0.6235271692276001
Validation loss: 1.6124241685354581

Epoch: 6| Step: 9
Training loss: 0.4318792521953583
Validation loss: 1.6214125361493839

Epoch: 6| Step: 10
Training loss: 0.2825268805027008
Validation loss: 1.620329758172394

Epoch: 6| Step: 11
Training loss: 0.5298431515693665
Validation loss: 1.6570804593383626

Epoch: 6| Step: 12
Training loss: 0.4246092140674591
Validation loss: 1.6573819447589178

Epoch: 6| Step: 13
Training loss: 0.5383177995681763
Validation loss: 1.684541420270038

Epoch: 463| Step: 0
Training loss: 0.3515773415565491
Validation loss: 1.679490566253662

Epoch: 6| Step: 1
Training loss: 0.7202516794204712
Validation loss: 1.6926045545967676

Epoch: 6| Step: 2
Training loss: 0.6147403717041016
Validation loss: 1.675331707923643

Epoch: 6| Step: 3
Training loss: 0.5853400826454163
Validation loss: 1.6156953406590286

Epoch: 6| Step: 4
Training loss: 0.4909272789955139
Validation loss: 1.613170087978404

Epoch: 6| Step: 5
Training loss: 0.8114711046218872
Validation loss: 1.5903220381788028

Epoch: 6| Step: 6
Training loss: 0.5396380424499512
Validation loss: 1.5984449258414648

Epoch: 6| Step: 7
Training loss: 0.5851742029190063
Validation loss: 1.6104126617472658

Epoch: 6| Step: 8
Training loss: 0.8335901498794556
Validation loss: 1.5945647057666574

Epoch: 6| Step: 9
Training loss: 0.7503003478050232
Validation loss: 1.628838812151263

Epoch: 6| Step: 10
Training loss: 0.3189725875854492
Validation loss: 1.6404294877923944

Epoch: 6| Step: 11
Training loss: 0.26297467947006226
Validation loss: 1.6237030477933987

Epoch: 6| Step: 12
Training loss: 0.7132393717765808
Validation loss: 1.608159315201544

Epoch: 6| Step: 13
Training loss: 0.837674617767334
Validation loss: 1.5987575361805577

Epoch: 464| Step: 0
Training loss: 0.5691111087799072
Validation loss: 1.5934539994885843

Epoch: 6| Step: 1
Training loss: 0.5030661821365356
Validation loss: 1.6009521022919686

Epoch: 6| Step: 2
Training loss: 0.582061767578125
Validation loss: 1.5866915872020106

Epoch: 6| Step: 3
Training loss: 0.6208263635635376
Validation loss: 1.6248813611204906

Epoch: 6| Step: 4
Training loss: 0.9583788514137268
Validation loss: 1.6049679851019254

Epoch: 6| Step: 5
Training loss: 0.5324957370758057
Validation loss: 1.6104179928379674

Epoch: 6| Step: 6
Training loss: 0.38011279702186584
Validation loss: 1.5738979001199045

Epoch: 6| Step: 7
Training loss: 0.6284350156784058
Validation loss: 1.584829202262304

Epoch: 6| Step: 8
Training loss: 0.7006605863571167
Validation loss: 1.6088233699080765

Epoch: 6| Step: 9
Training loss: 0.5140899419784546
Validation loss: 1.59025998269358

Epoch: 6| Step: 10
Training loss: 0.4351232647895813
Validation loss: 1.597509946874393

Epoch: 6| Step: 11
Training loss: 0.3913910984992981
Validation loss: 1.6305690350071076

Epoch: 6| Step: 12
Training loss: 0.7164006233215332
Validation loss: 1.6685195968997093

Epoch: 6| Step: 13
Training loss: 0.9578865766525269
Validation loss: 1.6623171670462495

Epoch: 465| Step: 0
Training loss: 0.9252315759658813
Validation loss: 1.707998635307435

Epoch: 6| Step: 1
Training loss: 0.7135228514671326
Validation loss: 1.7190205832963348

Epoch: 6| Step: 2
Training loss: 0.5710475444793701
Validation loss: 1.7241950112004434

Epoch: 6| Step: 3
Training loss: 0.3933030366897583
Validation loss: 1.72063063293375

Epoch: 6| Step: 4
Training loss: 0.2680756449699402
Validation loss: 1.7119248246633878

Epoch: 6| Step: 5
Training loss: 0.7652254700660706
Validation loss: 1.7059276949974798

Epoch: 6| Step: 6
Training loss: 0.4478345811367035
Validation loss: 1.7188303111701884

Epoch: 6| Step: 7
Training loss: 0.5657433867454529
Validation loss: 1.6917653827257053

Epoch: 6| Step: 8
Training loss: 1.1468665599822998
Validation loss: 1.637704441624303

Epoch: 6| Step: 9
Training loss: 0.5983014106750488
Validation loss: 1.6244049469629924

Epoch: 6| Step: 10
Training loss: 0.7788242101669312
Validation loss: 1.6315473523191226

Epoch: 6| Step: 11
Training loss: 0.4327159523963928
Validation loss: 1.593788949392175

Epoch: 6| Step: 12
Training loss: 0.5953434109687805
Validation loss: 1.552868007331766

Epoch: 6| Step: 13
Training loss: 0.43636375665664673
Validation loss: 1.5953769299291796

Epoch: 466| Step: 0
Training loss: 0.5640767216682434
Validation loss: 1.6179129744088778

Epoch: 6| Step: 1
Training loss: 0.6085329055786133
Validation loss: 1.6432348425670336

Epoch: 6| Step: 2
Training loss: 0.6653228402137756
Validation loss: 1.67883728396508

Epoch: 6| Step: 3
Training loss: 0.46753454208374023
Validation loss: 1.6713380121415662

Epoch: 6| Step: 4
Training loss: 0.8638020753860474
Validation loss: 1.705468952014882

Epoch: 6| Step: 5
Training loss: 0.5847386121749878
Validation loss: 1.7209347909496677

Epoch: 6| Step: 6
Training loss: 0.5821132659912109
Validation loss: 1.7547043677299254

Epoch: 6| Step: 7
Training loss: 0.590208888053894
Validation loss: 1.7742127590281989

Epoch: 6| Step: 8
Training loss: 0.4308592975139618
Validation loss: 1.7340387669942712

Epoch: 6| Step: 9
Training loss: 0.7909584045410156
Validation loss: 1.742241762017691

Epoch: 6| Step: 10
Training loss: 0.7832931280136108
Validation loss: 1.6552140597374208

Epoch: 6| Step: 11
Training loss: 0.4312572181224823
Validation loss: 1.5914071362505677

Epoch: 6| Step: 12
Training loss: 0.8015186786651611
Validation loss: 1.557742500817904

Epoch: 6| Step: 13
Training loss: 0.4573839008808136
Validation loss: 1.5667580609680505

Epoch: 467| Step: 0
Training loss: 0.57573401927948
Validation loss: 1.5426876070678874

Epoch: 6| Step: 1
Training loss: 0.7519883513450623
Validation loss: 1.5736141563743673

Epoch: 6| Step: 2
Training loss: 0.9774413704872131
Validation loss: 1.5742499040019127

Epoch: 6| Step: 3
Training loss: 0.6278860569000244
Validation loss: 1.6176875970696891

Epoch: 6| Step: 4
Training loss: 0.6071868538856506
Validation loss: 1.6554093348082675

Epoch: 6| Step: 5
Training loss: 0.44625696539878845
Validation loss: 1.6692008344076013

Epoch: 6| Step: 6
Training loss: 0.3353467285633087
Validation loss: 1.6543427628855552

Epoch: 6| Step: 7
Training loss: 0.5351964831352234
Validation loss: 1.6637312007206742

Epoch: 6| Step: 8
Training loss: 0.7965189218521118
Validation loss: 1.6597809125018377

Epoch: 6| Step: 9
Training loss: 0.3323234021663666
Validation loss: 1.6473019853714974

Epoch: 6| Step: 10
Training loss: 0.6995075941085815
Validation loss: 1.6368082159308976

Epoch: 6| Step: 11
Training loss: 0.40291643142700195
Validation loss: 1.6616044711041194

Epoch: 6| Step: 12
Training loss: 0.49830958247184753
Validation loss: 1.6099756328008508

Epoch: 6| Step: 13
Training loss: 0.4398413598537445
Validation loss: 1.622200276902927

Epoch: 468| Step: 0
Training loss: 0.2727982997894287
Validation loss: 1.599843930172664

Epoch: 6| Step: 1
Training loss: 0.6648998260498047
Validation loss: 1.6257653210752754

Epoch: 6| Step: 2
Training loss: 0.7709783911705017
Validation loss: 1.585640953433129

Epoch: 6| Step: 3
Training loss: 0.7196547985076904
Validation loss: 1.6162974783169326

Epoch: 6| Step: 4
Training loss: 0.8312545418739319
Validation loss: 1.6039969946748467

Epoch: 6| Step: 5
Training loss: 0.6704711318016052
Validation loss: 1.6009685288193405

Epoch: 6| Step: 6
Training loss: 0.3723472058773041
Validation loss: 1.6313501622087212

Epoch: 6| Step: 7
Training loss: 0.654529333114624
Validation loss: 1.6194302676826395

Epoch: 6| Step: 8
Training loss: 0.391931414604187
Validation loss: 1.6340785129095918

Epoch: 6| Step: 9
Training loss: 0.614272952079773
Validation loss: 1.6527949161426996

Epoch: 6| Step: 10
Training loss: 0.5833331346511841
Validation loss: 1.6769041912530058

Epoch: 6| Step: 11
Training loss: 0.36508169770240784
Validation loss: 1.6556692405413556

Epoch: 6| Step: 12
Training loss: 0.5122107267379761
Validation loss: 1.701925660974236

Epoch: 6| Step: 13
Training loss: 0.43727028369903564
Validation loss: 1.7061990358496224

Epoch: 469| Step: 0
Training loss: 0.689354658126831
Validation loss: 1.6691849488084034

Epoch: 6| Step: 1
Training loss: 0.7137548923492432
Validation loss: 1.6408464421508133

Epoch: 6| Step: 2
Training loss: 0.5068836212158203
Validation loss: 1.629830615494841

Epoch: 6| Step: 3
Training loss: 0.35477083921432495
Validation loss: 1.6353035921691566

Epoch: 6| Step: 4
Training loss: 0.6018376350402832
Validation loss: 1.6300634902010682

Epoch: 6| Step: 5
Training loss: 0.5052621960639954
Validation loss: 1.6254667338504587

Epoch: 6| Step: 6
Training loss: 0.4012405276298523
Validation loss: 1.631077971509708

Epoch: 6| Step: 7
Training loss: 0.5841271877288818
Validation loss: 1.5755113952903337

Epoch: 6| Step: 8
Training loss: 0.44932907819747925
Validation loss: 1.5857604575413529

Epoch: 6| Step: 9
Training loss: 0.8757119178771973
Validation loss: 1.5894005836979035

Epoch: 6| Step: 10
Training loss: 0.6906524896621704
Validation loss: 1.6128798518129575

Epoch: 6| Step: 11
Training loss: 0.5736911296844482
Validation loss: 1.632046079122892

Epoch: 6| Step: 12
Training loss: 0.5669510960578918
Validation loss: 1.6814919530704457

Epoch: 6| Step: 13
Training loss: 0.9047858715057373
Validation loss: 1.6971997291811052

Epoch: 470| Step: 0
Training loss: 0.43175825476646423
Validation loss: 1.6601962325393513

Epoch: 6| Step: 1
Training loss: 1.100843906402588
Validation loss: 1.6558116687241422

Epoch: 6| Step: 2
Training loss: 0.40355169773101807
Validation loss: 1.6138540737090572

Epoch: 6| Step: 3
Training loss: 0.5412893295288086
Validation loss: 1.6198941764011179

Epoch: 6| Step: 4
Training loss: 0.4585943818092346
Validation loss: 1.6097605048969228

Epoch: 6| Step: 5
Training loss: 0.7055261731147766
Validation loss: 1.572974956163796

Epoch: 6| Step: 6
Training loss: 0.7090984582901001
Validation loss: 1.61861236633793

Epoch: 6| Step: 7
Training loss: 0.3290209174156189
Validation loss: 1.5561517515490133

Epoch: 6| Step: 8
Training loss: 0.5823256969451904
Validation loss: 1.5623941524054414

Epoch: 6| Step: 9
Training loss: 0.6995502710342407
Validation loss: 1.5492012949400051

Epoch: 6| Step: 10
Training loss: 0.43854647874832153
Validation loss: 1.5722221815457909

Epoch: 6| Step: 11
Training loss: 0.47741419076919556
Validation loss: 1.6017580006712226

Epoch: 6| Step: 12
Training loss: 0.5363330245018005
Validation loss: 1.6026297166783323

Epoch: 6| Step: 13
Training loss: 0.4303028881549835
Validation loss: 1.6050656085373254

Epoch: 471| Step: 0
Training loss: 0.6925767064094543
Validation loss: 1.6455321286314277

Epoch: 6| Step: 1
Training loss: 0.4833435118198395
Validation loss: 1.6229153538262973

Epoch: 6| Step: 2
Training loss: 0.39380526542663574
Validation loss: 1.6147998404759232

Epoch: 6| Step: 3
Training loss: 0.5102952718734741
Validation loss: 1.5954427052569646

Epoch: 6| Step: 4
Training loss: 0.5646297931671143
Validation loss: 1.6097340519710253

Epoch: 6| Step: 5
Training loss: 0.542697548866272
Validation loss: 1.6128154070146623

Epoch: 6| Step: 6
Training loss: 0.7126206159591675
Validation loss: 1.5910689997416672

Epoch: 6| Step: 7
Training loss: 0.4405606687068939
Validation loss: 1.5846580536134782

Epoch: 6| Step: 8
Training loss: 0.32103174924850464
Validation loss: 1.5690193355724376

Epoch: 6| Step: 9
Training loss: 0.7596465349197388
Validation loss: 1.5530881215167303

Epoch: 6| Step: 10
Training loss: 0.533806562423706
Validation loss: 1.5889543346179429

Epoch: 6| Step: 11
Training loss: 0.5384927988052368
Validation loss: 1.555754444932425

Epoch: 6| Step: 12
Training loss: 0.7348471879959106
Validation loss: 1.5943720392001572

Epoch: 6| Step: 13
Training loss: 0.9086231589317322
Validation loss: 1.621245975135475

Epoch: 472| Step: 0
Training loss: 0.5519495010375977
Validation loss: 1.6528171082978607

Epoch: 6| Step: 1
Training loss: 0.2785848081111908
Validation loss: 1.6872458470764982

Epoch: 6| Step: 2
Training loss: 0.5357621908187866
Validation loss: 1.6470141218554588

Epoch: 6| Step: 3
Training loss: 0.24835732579231262
Validation loss: 1.6268489322354716

Epoch: 6| Step: 4
Training loss: 0.6273317337036133
Validation loss: 1.6226823432471162

Epoch: 6| Step: 5
Training loss: 0.33375224471092224
Validation loss: 1.5789896390771354

Epoch: 6| Step: 6
Training loss: 0.3944319784641266
Validation loss: 1.5937545991713

Epoch: 6| Step: 7
Training loss: 0.6694612503051758
Validation loss: 1.5662686773525771

Epoch: 6| Step: 8
Training loss: 0.8739445209503174
Validation loss: 1.5960688001366072

Epoch: 6| Step: 9
Training loss: 0.4220479428768158
Validation loss: 1.5799553907045754

Epoch: 6| Step: 10
Training loss: 0.6782252788543701
Validation loss: 1.6146486689967494

Epoch: 6| Step: 11
Training loss: 0.7999714612960815
Validation loss: 1.5895437245727868

Epoch: 6| Step: 12
Training loss: 0.552639365196228
Validation loss: 1.5679927026071856

Epoch: 6| Step: 13
Training loss: 0.6780403256416321
Validation loss: 1.5755752927513533

Epoch: 473| Step: 0
Training loss: 0.5975275039672852
Validation loss: 1.641191920926494

Epoch: 6| Step: 1
Training loss: 0.3556089997291565
Validation loss: 1.6338279901012298

Epoch: 6| Step: 2
Training loss: 0.5881956219673157
Validation loss: 1.639636149970434

Epoch: 6| Step: 3
Training loss: 0.5679323077201843
Validation loss: 1.6618910220361525

Epoch: 6| Step: 4
Training loss: 0.4236106276512146
Validation loss: 1.6401718931813394

Epoch: 6| Step: 5
Training loss: 0.7205804586410522
Validation loss: 1.633837825508528

Epoch: 6| Step: 6
Training loss: 0.7940680980682373
Validation loss: 1.6273038925663117

Epoch: 6| Step: 7
Training loss: 0.3627665638923645
Validation loss: 1.6221133547444497

Epoch: 6| Step: 8
Training loss: 0.5522110462188721
Validation loss: 1.6194097700939383

Epoch: 6| Step: 9
Training loss: 0.41467994451522827
Validation loss: 1.6177254094872424

Epoch: 6| Step: 10
Training loss: 0.5366885662078857
Validation loss: 1.598478381351758

Epoch: 6| Step: 11
Training loss: 0.6957679986953735
Validation loss: 1.6021054931866225

Epoch: 6| Step: 12
Training loss: 0.6234455108642578
Validation loss: 1.6505710578733874

Epoch: 6| Step: 13
Training loss: 0.36119306087493896
Validation loss: 1.6855747212645829

Epoch: 474| Step: 0
Training loss: 0.5395712852478027
Validation loss: 1.716164791455833

Epoch: 6| Step: 1
Training loss: 0.4099075198173523
Validation loss: 1.7386562401248562

Epoch: 6| Step: 2
Training loss: 0.6710873246192932
Validation loss: 1.7077069846532678

Epoch: 6| Step: 3
Training loss: 0.5510987043380737
Validation loss: 1.7226439304249261

Epoch: 6| Step: 4
Training loss: 0.49705934524536133
Validation loss: 1.698520746282352

Epoch: 6| Step: 5
Training loss: 0.7730153799057007
Validation loss: 1.7067542511929747

Epoch: 6| Step: 6
Training loss: 0.8519461154937744
Validation loss: 1.646664168245049

Epoch: 6| Step: 7
Training loss: 0.6174272298812866
Validation loss: 1.651874517881742

Epoch: 6| Step: 8
Training loss: 0.6137850284576416
Validation loss: 1.6406561251609557

Epoch: 6| Step: 9
Training loss: 0.4146251380443573
Validation loss: 1.589165561942644

Epoch: 6| Step: 10
Training loss: 0.45127779245376587
Validation loss: 1.5691554155401004

Epoch: 6| Step: 11
Training loss: 0.7262594699859619
Validation loss: 1.562295380459037

Epoch: 6| Step: 12
Training loss: 0.5324083566665649
Validation loss: 1.5505021848986227

Epoch: 6| Step: 13
Training loss: 0.6758438348770142
Validation loss: 1.5641139655984857

Epoch: 475| Step: 0
Training loss: 0.6017978191375732
Validation loss: 1.5908497379672142

Epoch: 6| Step: 1
Training loss: 0.6549514532089233
Validation loss: 1.619849822854483

Epoch: 6| Step: 2
Training loss: 0.4304971992969513
Validation loss: 1.6246927169061476

Epoch: 6| Step: 3
Training loss: 0.563812792301178
Validation loss: 1.674538944357185

Epoch: 6| Step: 4
Training loss: 0.569913923740387
Validation loss: 1.6671940601000221

Epoch: 6| Step: 5
Training loss: 0.5276705622673035
Validation loss: 1.6844672003099996

Epoch: 6| Step: 6
Training loss: 0.6897180676460266
Validation loss: 1.638337541651982

Epoch: 6| Step: 7
Training loss: 0.6737492084503174
Validation loss: 1.6768580764852545

Epoch: 6| Step: 8
Training loss: 0.2764083743095398
Validation loss: 1.655007367493004

Epoch: 6| Step: 9
Training loss: 0.7506542801856995
Validation loss: 1.6268775565649873

Epoch: 6| Step: 10
Training loss: 0.8776782155036926
Validation loss: 1.6258747321303173

Epoch: 6| Step: 11
Training loss: 0.28284215927124023
Validation loss: 1.64120182939755

Epoch: 6| Step: 12
Training loss: 0.718454897403717
Validation loss: 1.6385536591211955

Epoch: 6| Step: 13
Training loss: 0.11345226317644119
Validation loss: 1.6661344997344478

Epoch: 476| Step: 0
Training loss: 0.6706435084342957
Validation loss: 1.6772687050604052

Epoch: 6| Step: 1
Training loss: 0.4801817536354065
Validation loss: 1.6847750999594246

Epoch: 6| Step: 2
Training loss: 0.7971726655960083
Validation loss: 1.6663292659226285

Epoch: 6| Step: 3
Training loss: 0.7489900588989258
Validation loss: 1.6432417618331088

Epoch: 6| Step: 4
Training loss: 0.24345405399799347
Validation loss: 1.638970164842503

Epoch: 6| Step: 5
Training loss: 0.7192635536193848
Validation loss: 1.6222920981786584

Epoch: 6| Step: 6
Training loss: 0.4327242374420166
Validation loss: 1.6119129016835203

Epoch: 6| Step: 7
Training loss: 0.2937268912792206
Validation loss: 1.6026258160991054

Epoch: 6| Step: 8
Training loss: 0.3913044333457947
Validation loss: 1.6159622835856613

Epoch: 6| Step: 9
Training loss: 0.5193915963172913
Validation loss: 1.616927498130388

Epoch: 6| Step: 10
Training loss: 0.4416344165802002
Validation loss: 1.6245347479338288

Epoch: 6| Step: 11
Training loss: 0.6774147152900696
Validation loss: 1.617683510626516

Epoch: 6| Step: 12
Training loss: 0.6404939889907837
Validation loss: 1.650121307821684

Epoch: 6| Step: 13
Training loss: 0.7988914847373962
Validation loss: 1.675839715106513

Epoch: 477| Step: 0
Training loss: 0.851954996585846
Validation loss: 1.6948078499045423

Epoch: 6| Step: 1
Training loss: 0.5461631417274475
Validation loss: 1.7004684632824314

Epoch: 6| Step: 2
Training loss: 0.6374916434288025
Validation loss: 1.7201720565877936

Epoch: 6| Step: 3
Training loss: 0.21796002984046936
Validation loss: 1.7416989944314445

Epoch: 6| Step: 4
Training loss: 0.5333775877952576
Validation loss: 1.7184816727074244

Epoch: 6| Step: 5
Training loss: 0.5361083745956421
Validation loss: 1.7218424825258152

Epoch: 6| Step: 6
Training loss: 0.5151804089546204
Validation loss: 1.653572590120377

Epoch: 6| Step: 7
Training loss: 0.5407060384750366
Validation loss: 1.63090491935771

Epoch: 6| Step: 8
Training loss: 0.7672348022460938
Validation loss: 1.609924554824829

Epoch: 6| Step: 9
Training loss: 0.6424359083175659
Validation loss: 1.5715721089352843

Epoch: 6| Step: 10
Training loss: 0.48609232902526855
Validation loss: 1.5911900651070379

Epoch: 6| Step: 11
Training loss: 0.40521305799484253
Validation loss: 1.608240448018556

Epoch: 6| Step: 12
Training loss: 0.3851040303707123
Validation loss: 1.5822004361819195

Epoch: 6| Step: 13
Training loss: 0.8770879507064819
Validation loss: 1.600762257011988

Epoch: 478| Step: 0
Training loss: 0.6353133320808411
Validation loss: 1.6429905993964082

Epoch: 6| Step: 1
Training loss: 0.5186631083488464
Validation loss: 1.6242966549370879

Epoch: 6| Step: 2
Training loss: 0.4339156150817871
Validation loss: 1.6365404590483634

Epoch: 6| Step: 3
Training loss: 0.6027785539627075
Validation loss: 1.672667521302418

Epoch: 6| Step: 4
Training loss: 0.6639857292175293
Validation loss: 1.6732666069461453

Epoch: 6| Step: 5
Training loss: 0.41381436586380005
Validation loss: 1.688418347348449

Epoch: 6| Step: 6
Training loss: 0.6953116655349731
Validation loss: 1.709211213614351

Epoch: 6| Step: 7
Training loss: 0.6921688914299011
Validation loss: 1.6678057601374965

Epoch: 6| Step: 8
Training loss: 0.49809640645980835
Validation loss: 1.6934906692915066

Epoch: 6| Step: 9
Training loss: 0.5714914798736572
Validation loss: 1.6323841643589798

Epoch: 6| Step: 10
Training loss: 0.31586992740631104
Validation loss: 1.637152951250794

Epoch: 6| Step: 11
Training loss: 0.4249989688396454
Validation loss: 1.6443847994650564

Epoch: 6| Step: 12
Training loss: 0.8401634693145752
Validation loss: 1.6487848656151884

Epoch: 6| Step: 13
Training loss: 0.3095754384994507
Validation loss: 1.646666060211838

Epoch: 479| Step: 0
Training loss: 0.4451450705528259
Validation loss: 1.6276041538484636

Epoch: 6| Step: 1
Training loss: 0.5477266907691956
Validation loss: 1.641429017948848

Epoch: 6| Step: 2
Training loss: 0.6055395603179932
Validation loss: 1.6599349296221169

Epoch: 6| Step: 3
Training loss: 0.4373815357685089
Validation loss: 1.7189118708333662

Epoch: 6| Step: 4
Training loss: 0.45053789019584656
Validation loss: 1.6886573299284904

Epoch: 6| Step: 5
Training loss: 0.6057032346725464
Validation loss: 1.6341738995685373

Epoch: 6| Step: 6
Training loss: 0.3090081214904785
Validation loss: 1.6020224517391575

Epoch: 6| Step: 7
Training loss: 0.6576389074325562
Validation loss: 1.6136028535904423

Epoch: 6| Step: 8
Training loss: 0.5048226118087769
Validation loss: 1.5507568781093886

Epoch: 6| Step: 9
Training loss: 0.5381209850311279
Validation loss: 1.573089047144818

Epoch: 6| Step: 10
Training loss: 0.6172099113464355
Validation loss: 1.5625754376893402

Epoch: 6| Step: 11
Training loss: 0.4578373432159424
Validation loss: 1.5766856362742763

Epoch: 6| Step: 12
Training loss: 0.8773746490478516
Validation loss: 1.577148247790593

Epoch: 6| Step: 13
Training loss: 0.6125275492668152
Validation loss: 1.6227621980892715

Epoch: 480| Step: 0
Training loss: 0.2874242067337036
Validation loss: 1.6071220264639905

Epoch: 6| Step: 1
Training loss: 0.45895665884017944
Validation loss: 1.6689660702982256

Epoch: 6| Step: 2
Training loss: 0.3862777352333069
Validation loss: 1.6969255157696304

Epoch: 6| Step: 3
Training loss: 0.42353320121765137
Validation loss: 1.7175096158058412

Epoch: 6| Step: 4
Training loss: 0.8443858623504639
Validation loss: 1.681545449841407

Epoch: 6| Step: 5
Training loss: 0.6857893466949463
Validation loss: 1.677710194741526

Epoch: 6| Step: 6
Training loss: 0.9180493354797363
Validation loss: 1.6640542604589974

Epoch: 6| Step: 7
Training loss: 0.7926682233810425
Validation loss: 1.658188714775988

Epoch: 6| Step: 8
Training loss: 0.274125874042511
Validation loss: 1.6231746340310702

Epoch: 6| Step: 9
Training loss: 0.434404581785202
Validation loss: 1.6374332417723954

Epoch: 6| Step: 10
Training loss: 0.5649500489234924
Validation loss: 1.6072265102017311

Epoch: 6| Step: 11
Training loss: 0.4524040222167969
Validation loss: 1.5948119432695451

Epoch: 6| Step: 12
Training loss: 0.43994140625
Validation loss: 1.5979163505697762

Epoch: 6| Step: 13
Training loss: 0.26158472895622253
Validation loss: 1.6009742329197545

Epoch: 481| Step: 0
Training loss: 0.29824861884117126
Validation loss: 1.60477424821546

Epoch: 6| Step: 1
Training loss: 0.39092516899108887
Validation loss: 1.602970891101386

Epoch: 6| Step: 2
Training loss: 1.0025808811187744
Validation loss: 1.6263693391635854

Epoch: 6| Step: 3
Training loss: 0.47230470180511475
Validation loss: 1.6118366705474032

Epoch: 6| Step: 4
Training loss: 0.43533748388290405
Validation loss: 1.6704322817505046

Epoch: 6| Step: 5
Training loss: 0.29152798652648926
Validation loss: 1.6425786120917207

Epoch: 6| Step: 6
Training loss: 0.702605128288269
Validation loss: 1.6568904781854281

Epoch: 6| Step: 7
Training loss: 0.4320303201675415
Validation loss: 1.675278195770838

Epoch: 6| Step: 8
Training loss: 0.3520161211490631
Validation loss: 1.6692268515145907

Epoch: 6| Step: 9
Training loss: 0.4057632386684418
Validation loss: 1.6270291779630928

Epoch: 6| Step: 10
Training loss: 0.4998417794704437
Validation loss: 1.6246963906031784

Epoch: 6| Step: 11
Training loss: 0.6754071712493896
Validation loss: 1.5909446247162358

Epoch: 6| Step: 12
Training loss: 0.5795114636421204
Validation loss: 1.5947549061108661

Epoch: 6| Step: 13
Training loss: 0.7814038991928101
Validation loss: 1.5746243769122708

Epoch: 482| Step: 0
Training loss: 0.7473490238189697
Validation loss: 1.5841345428138651

Epoch: 6| Step: 1
Training loss: 0.6383197903633118
Validation loss: 1.5675883062424198

Epoch: 6| Step: 2
Training loss: 0.7863813638687134
Validation loss: 1.5584480095935125

Epoch: 6| Step: 3
Training loss: 0.3864211440086365
Validation loss: 1.5532705822298605

Epoch: 6| Step: 4
Training loss: 0.38349851965904236
Validation loss: 1.560816623831308

Epoch: 6| Step: 5
Training loss: 0.5471160411834717
Validation loss: 1.5955373343601023

Epoch: 6| Step: 6
Training loss: 0.7437044382095337
Validation loss: 1.620842843927363

Epoch: 6| Step: 7
Training loss: 0.38745713233947754
Validation loss: 1.6173790988101755

Epoch: 6| Step: 8
Training loss: 0.3714558482170105
Validation loss: 1.7030354315234768

Epoch: 6| Step: 9
Training loss: 0.7406752109527588
Validation loss: 1.7555121426941247

Epoch: 6| Step: 10
Training loss: 0.5112425684928894
Validation loss: 1.764610098254296

Epoch: 6| Step: 11
Training loss: 0.4860002100467682
Validation loss: 1.738081577003643

Epoch: 6| Step: 12
Training loss: 0.3651338815689087
Validation loss: 1.6846648531575357

Epoch: 6| Step: 13
Training loss: 0.42245855927467346
Validation loss: 1.6449631773015505

Epoch: 483| Step: 0
Training loss: 0.27282118797302246
Validation loss: 1.6094038409571494

Epoch: 6| Step: 1
Training loss: 0.5163747668266296
Validation loss: 1.5838111818477671

Epoch: 6| Step: 2
Training loss: 0.5727934837341309
Validation loss: 1.5640008936646164

Epoch: 6| Step: 3
Training loss: 0.47611600160598755
Validation loss: 1.5105415044292327

Epoch: 6| Step: 4
Training loss: 0.6195679903030396
Validation loss: 1.503341951677876

Epoch: 6| Step: 5
Training loss: 0.602057933807373
Validation loss: 1.491458228839341

Epoch: 6| Step: 6
Training loss: 0.2037201076745987
Validation loss: 1.5199136900645431

Epoch: 6| Step: 7
Training loss: 0.6247584819793701
Validation loss: 1.510983511965762

Epoch: 6| Step: 8
Training loss: 0.843348503112793
Validation loss: 1.6400230379514797

Epoch: 6| Step: 9
Training loss: 0.6289122104644775
Validation loss: 1.6936519069056357

Epoch: 6| Step: 10
Training loss: 0.7028368711471558
Validation loss: 1.665259612503872

Epoch: 6| Step: 11
Training loss: 0.5086192488670349
Validation loss: 1.6994105064740745

Epoch: 6| Step: 12
Training loss: 0.6220078468322754
Validation loss: 1.6738332138266614

Epoch: 6| Step: 13
Training loss: 0.9472754597663879
Validation loss: 1.673238447917405

Epoch: 484| Step: 0
Training loss: 0.25594162940979004
Validation loss: 1.6344064435651224

Epoch: 6| Step: 1
Training loss: 0.5946394205093384
Validation loss: 1.5955720434906662

Epoch: 6| Step: 2
Training loss: 0.47908100485801697
Validation loss: 1.5780609935842536

Epoch: 6| Step: 3
Training loss: 0.8566863536834717
Validation loss: 1.534522512907623

Epoch: 6| Step: 4
Training loss: 0.4734695553779602
Validation loss: 1.557668791022352

Epoch: 6| Step: 5
Training loss: 0.5494954586029053
Validation loss: 1.5327151449777747

Epoch: 6| Step: 6
Training loss: 0.8316310048103333
Validation loss: 1.5429883977418304

Epoch: 6| Step: 7
Training loss: 0.7384185194969177
Validation loss: 1.5447559484871485

Epoch: 6| Step: 8
Training loss: 0.3998391926288605
Validation loss: 1.5850237787410777

Epoch: 6| Step: 9
Training loss: 0.4256611466407776
Validation loss: 1.6138689671793292

Epoch: 6| Step: 10
Training loss: 0.5029354095458984
Validation loss: 1.6125735134206793

Epoch: 6| Step: 11
Training loss: 0.5386185646057129
Validation loss: 1.6736079979968328

Epoch: 6| Step: 12
Training loss: 0.5479978322982788
Validation loss: 1.734059372255879

Epoch: 6| Step: 13
Training loss: 0.6657317280769348
Validation loss: 1.7318119002926735

Epoch: 485| Step: 0
Training loss: 0.4985140562057495
Validation loss: 1.7217365528947564

Epoch: 6| Step: 1
Training loss: 0.5114051699638367
Validation loss: 1.7343352302428214

Epoch: 6| Step: 2
Training loss: 0.5158652067184448
Validation loss: 1.7109703953548143

Epoch: 6| Step: 3
Training loss: 0.6204462051391602
Validation loss: 1.6639941225769699

Epoch: 6| Step: 4
Training loss: 0.8046607375144958
Validation loss: 1.6901864082582536

Epoch: 6| Step: 5
Training loss: 0.5646884441375732
Validation loss: 1.664347735784387

Epoch: 6| Step: 6
Training loss: 0.5264320373535156
Validation loss: 1.6760863014446792

Epoch: 6| Step: 7
Training loss: 0.5266062021255493
Validation loss: 1.6499056418736775

Epoch: 6| Step: 8
Training loss: 0.2982386648654938
Validation loss: 1.6610873309514855

Epoch: 6| Step: 9
Training loss: 0.5387720465660095
Validation loss: 1.642281424614691

Epoch: 6| Step: 10
Training loss: 0.5134949684143066
Validation loss: 1.6519297310101089

Epoch: 6| Step: 11
Training loss: 0.53554368019104
Validation loss: 1.6555761855135682

Epoch: 6| Step: 12
Training loss: 0.5100927948951721
Validation loss: 1.6515431583568614

Epoch: 6| Step: 13
Training loss: 0.4927552044391632
Validation loss: 1.6950476913041965

Epoch: 486| Step: 0
Training loss: 0.5086303949356079
Validation loss: 1.6773263292927896

Epoch: 6| Step: 1
Training loss: 0.8478883504867554
Validation loss: 1.6647043894695979

Epoch: 6| Step: 2
Training loss: 0.2805074453353882
Validation loss: 1.6016619910476029

Epoch: 6| Step: 3
Training loss: 0.6060658693313599
Validation loss: 1.6072112385944655

Epoch: 6| Step: 4
Training loss: 0.555454432964325
Validation loss: 1.5819351160398094

Epoch: 6| Step: 5
Training loss: 0.33783674240112305
Validation loss: 1.6116445525999992

Epoch: 6| Step: 6
Training loss: 0.5179509520530701
Validation loss: 1.5913991107735583

Epoch: 6| Step: 7
Training loss: 0.3142368793487549
Validation loss: 1.639176304622363

Epoch: 6| Step: 8
Training loss: 0.5939720273017883
Validation loss: 1.62656089439187

Epoch: 6| Step: 9
Training loss: 0.4385395050048828
Validation loss: 1.6728677518906132

Epoch: 6| Step: 10
Training loss: 0.4691631495952606
Validation loss: 1.7264353844427294

Epoch: 6| Step: 11
Training loss: 0.776421070098877
Validation loss: 1.7826973648481472

Epoch: 6| Step: 12
Training loss: 0.7867015600204468
Validation loss: 1.7852250811874226

Epoch: 6| Step: 13
Training loss: 0.4526873826980591
Validation loss: 1.7759522840540896

Epoch: 487| Step: 0
Training loss: 0.40151041746139526
Validation loss: 1.7583478714830132

Epoch: 6| Step: 1
Training loss: 0.43647170066833496
Validation loss: 1.7614880531064925

Epoch: 6| Step: 2
Training loss: 0.5395132899284363
Validation loss: 1.6916150957025506

Epoch: 6| Step: 3
Training loss: 0.746895432472229
Validation loss: 1.7085480023455877

Epoch: 6| Step: 4
Training loss: 0.39245206117630005
Validation loss: 1.648323339800681

Epoch: 6| Step: 5
Training loss: 0.8743084669113159
Validation loss: 1.6121440754141858

Epoch: 6| Step: 6
Training loss: 0.6565552949905396
Validation loss: 1.5552957314316944

Epoch: 6| Step: 7
Training loss: 0.5329465866088867
Validation loss: 1.5228195164793281

Epoch: 6| Step: 8
Training loss: 0.366639107465744
Validation loss: 1.5363097831767092

Epoch: 6| Step: 9
Training loss: 0.679345965385437
Validation loss: 1.5410264717635287

Epoch: 6| Step: 10
Training loss: 0.6435086131095886
Validation loss: 1.5569326813502977

Epoch: 6| Step: 11
Training loss: 0.39504024386405945
Validation loss: 1.5971401776036909

Epoch: 6| Step: 12
Training loss: 0.3233562707901001
Validation loss: 1.5921027070732527

Epoch: 6| Step: 13
Training loss: 0.5429174304008484
Validation loss: 1.6342783345971057

Epoch: 488| Step: 0
Training loss: 0.533575177192688
Validation loss: 1.6893521739590553

Epoch: 6| Step: 1
Training loss: 0.5912739038467407
Validation loss: 1.677311965214309

Epoch: 6| Step: 2
Training loss: 0.42787355184555054
Validation loss: 1.6941271956248949

Epoch: 6| Step: 3
Training loss: 0.7382239103317261
Validation loss: 1.6889898443734774

Epoch: 6| Step: 4
Training loss: 0.2598338723182678
Validation loss: 1.657978755171581

Epoch: 6| Step: 5
Training loss: 0.5249759554862976
Validation loss: 1.5988422273307719

Epoch: 6| Step: 6
Training loss: 0.590936541557312
Validation loss: 1.5901999768390451

Epoch: 6| Step: 7
Training loss: 0.4844597578048706
Validation loss: 1.5843392315731253

Epoch: 6| Step: 8
Training loss: 0.29714977741241455
Validation loss: 1.5442960236662178

Epoch: 6| Step: 9
Training loss: 0.36270198225975037
Validation loss: 1.5669042461661882

Epoch: 6| Step: 10
Training loss: 0.5191826820373535
Validation loss: 1.5718894838004984

Epoch: 6| Step: 11
Training loss: 0.3126508593559265
Validation loss: 1.572267988676666

Epoch: 6| Step: 12
Training loss: 0.8935089111328125
Validation loss: 1.6001169373912196

Epoch: 6| Step: 13
Training loss: 0.8000630140304565
Validation loss: 1.6056882553203131

Epoch: 489| Step: 0
Training loss: 0.5377985835075378
Validation loss: 1.6009183929812523

Epoch: 6| Step: 1
Training loss: 0.697431206703186
Validation loss: 1.6172364219542472

Epoch: 6| Step: 2
Training loss: 0.5444374680519104
Validation loss: 1.6426570902588546

Epoch: 6| Step: 3
Training loss: 0.44941216707229614
Validation loss: 1.638974097467238

Epoch: 6| Step: 4
Training loss: 0.5488981008529663
Validation loss: 1.6574772634813864

Epoch: 6| Step: 5
Training loss: 0.5813188552856445
Validation loss: 1.6025936706091768

Epoch: 6| Step: 6
Training loss: 0.5621052980422974
Validation loss: 1.6041249203425583

Epoch: 6| Step: 7
Training loss: 0.4095892310142517
Validation loss: 1.5872833574971845

Epoch: 6| Step: 8
Training loss: 0.4885765314102173
Validation loss: 1.5733924014593965

Epoch: 6| Step: 9
Training loss: 0.340870201587677
Validation loss: 1.5987052122751872

Epoch: 6| Step: 10
Training loss: 0.5004570484161377
Validation loss: 1.5983377451537757

Epoch: 6| Step: 11
Training loss: 0.3580302894115448
Validation loss: 1.5650501187129686

Epoch: 6| Step: 12
Training loss: 0.5513600707054138
Validation loss: 1.5650610616130214

Epoch: 6| Step: 13
Training loss: 0.679114818572998
Validation loss: 1.5834214789893037

Epoch: 490| Step: 0
Training loss: 0.32578811049461365
Validation loss: 1.6302314932628343

Epoch: 6| Step: 1
Training loss: 0.6892052888870239
Validation loss: 1.60567593830888

Epoch: 6| Step: 2
Training loss: 0.4759056270122528
Validation loss: 1.677662846862629

Epoch: 6| Step: 3
Training loss: 0.627350389957428
Validation loss: 1.6657845435603973

Epoch: 6| Step: 4
Training loss: 0.3138312101364136
Validation loss: 1.6486134067658456

Epoch: 6| Step: 5
Training loss: 0.6070579886436462
Validation loss: 1.6435174096015193

Epoch: 6| Step: 6
Training loss: 0.44213688373565674
Validation loss: 1.6613658961429392

Epoch: 6| Step: 7
Training loss: 0.6469074487686157
Validation loss: 1.6318346044068694

Epoch: 6| Step: 8
Training loss: 0.4107400178909302
Validation loss: 1.6636711307751235

Epoch: 6| Step: 9
Training loss: 0.7440659999847412
Validation loss: 1.631591937875235

Epoch: 6| Step: 10
Training loss: 0.5439701676368713
Validation loss: 1.6705897700402044

Epoch: 6| Step: 11
Training loss: 0.497614324092865
Validation loss: 1.6912497384573824

Epoch: 6| Step: 12
Training loss: 0.44451069831848145
Validation loss: 1.716847676102833

Epoch: 6| Step: 13
Training loss: 0.40851274132728577
Validation loss: 1.7259396981167536

Epoch: 491| Step: 0
Training loss: 0.5542459487915039
Validation loss: 1.7538557808886293

Epoch: 6| Step: 1
Training loss: 0.3728904128074646
Validation loss: 1.7552353784602175

Epoch: 6| Step: 2
Training loss: 0.4401754140853882
Validation loss: 1.7063559293746948

Epoch: 6| Step: 3
Training loss: 0.591645359992981
Validation loss: 1.7205072269644788

Epoch: 6| Step: 4
Training loss: 0.8540589809417725
Validation loss: 1.7063617052570466

Epoch: 6| Step: 5
Training loss: 0.4320281445980072
Validation loss: 1.6682597962758874

Epoch: 6| Step: 6
Training loss: 0.4149470925331116
Validation loss: 1.6531626165554087

Epoch: 6| Step: 7
Training loss: 0.282256543636322
Validation loss: 1.6244139120142946

Epoch: 6| Step: 8
Training loss: 0.9851824045181274
Validation loss: 1.6202751667268815

Epoch: 6| Step: 9
Training loss: 0.1900824010372162
Validation loss: 1.6018441595057005

Epoch: 6| Step: 10
Training loss: 0.6471710801124573
Validation loss: 1.5627097263131091

Epoch: 6| Step: 11
Training loss: 0.6007398366928101
Validation loss: 1.556192216052804

Epoch: 6| Step: 12
Training loss: 0.3653567135334015
Validation loss: 1.547911100490119

Epoch: 6| Step: 13
Training loss: 0.18800657987594604
Validation loss: 1.516375155859096

Epoch: 492| Step: 0
Training loss: 0.7579858303070068
Validation loss: 1.55291614993926

Epoch: 6| Step: 1
Training loss: 0.31449973583221436
Validation loss: 1.548198703796633

Epoch: 6| Step: 2
Training loss: 0.5161939859390259
Validation loss: 1.6014167185752624

Epoch: 6| Step: 3
Training loss: 0.3482099771499634
Validation loss: 1.6230627926447059

Epoch: 6| Step: 4
Training loss: 0.31743985414505005
Validation loss: 1.6145063837369282

Epoch: 6| Step: 5
Training loss: 0.5763758420944214
Validation loss: 1.6375971750546527

Epoch: 6| Step: 6
Training loss: 0.4628123939037323
Validation loss: 1.646914372521062

Epoch: 6| Step: 7
Training loss: 0.5657733678817749
Validation loss: 1.667495640375281

Epoch: 6| Step: 8
Training loss: 0.6583338975906372
Validation loss: 1.6506501936143445

Epoch: 6| Step: 9
Training loss: 0.35135337710380554
Validation loss: 1.6251240545703518

Epoch: 6| Step: 10
Training loss: 0.3667301535606384
Validation loss: 1.6262973687982047

Epoch: 6| Step: 11
Training loss: 0.5750967264175415
Validation loss: 1.5914307281535158

Epoch: 6| Step: 12
Training loss: 0.4392130970954895
Validation loss: 1.5905388401400657

Epoch: 6| Step: 13
Training loss: 0.6413308382034302
Validation loss: 1.6115944949529504

Epoch: 493| Step: 0
Training loss: 0.36741745471954346
Validation loss: 1.5874625386730317

Epoch: 6| Step: 1
Training loss: 0.36813122034072876
Validation loss: 1.6126193602879841

Epoch: 6| Step: 2
Training loss: 0.543753981590271
Validation loss: 1.631348313823823

Epoch: 6| Step: 3
Training loss: 0.3517380356788635
Validation loss: 1.6272509803054154

Epoch: 6| Step: 4
Training loss: 0.568099856376648
Validation loss: 1.6304795511307255

Epoch: 6| Step: 5
Training loss: 0.4213280975818634
Validation loss: 1.6230020587162306

Epoch: 6| Step: 6
Training loss: 0.4035354256629944
Validation loss: 1.586171624481037

Epoch: 6| Step: 7
Training loss: 0.6065301895141602
Validation loss: 1.6061420479128439

Epoch: 6| Step: 8
Training loss: 0.6585545539855957
Validation loss: 1.629879605385565

Epoch: 6| Step: 9
Training loss: 0.8005927801132202
Validation loss: 1.6171854131965226

Epoch: 6| Step: 10
Training loss: 0.6191155910491943
Validation loss: 1.611457573470249

Epoch: 6| Step: 11
Training loss: 0.28833791613578796
Validation loss: 1.577226282447897

Epoch: 6| Step: 12
Training loss: 0.1402396708726883
Validation loss: 1.5976004574888496

Epoch: 6| Step: 13
Training loss: 0.7120524644851685
Validation loss: 1.5781835522702945

Epoch: 494| Step: 0
Training loss: 0.703029453754425
Validation loss: 1.5796800242957247

Epoch: 6| Step: 1
Training loss: 0.3353315591812134
Validation loss: 1.5627445020983297

Epoch: 6| Step: 2
Training loss: 0.5813731551170349
Validation loss: 1.5934624723208848

Epoch: 6| Step: 3
Training loss: 0.46865516901016235
Validation loss: 1.5818669283261864

Epoch: 6| Step: 4
Training loss: 0.36635252833366394
Validation loss: 1.5824072809629544

Epoch: 6| Step: 5
Training loss: 0.38674622774124146
Validation loss: 1.608710863256967

Epoch: 6| Step: 6
Training loss: 0.32094889879226685
Validation loss: 1.6429178868570635

Epoch: 6| Step: 7
Training loss: 0.8347254991531372
Validation loss: 1.639074811371424

Epoch: 6| Step: 8
Training loss: 0.2507033348083496
Validation loss: 1.6261671281629992

Epoch: 6| Step: 9
Training loss: 0.35367897152900696
Validation loss: 1.6463972804366902

Epoch: 6| Step: 10
Training loss: 0.48210299015045166
Validation loss: 1.640922281049913

Epoch: 6| Step: 11
Training loss: 0.48440033197402954
Validation loss: 1.642187181339469

Epoch: 6| Step: 12
Training loss: 0.4171886444091797
Validation loss: 1.6164273908061366

Epoch: 6| Step: 13
Training loss: 0.7805653810501099
Validation loss: 1.61668364719678

Epoch: 495| Step: 0
Training loss: 0.4795258343219757
Validation loss: 1.5663128809262348

Epoch: 6| Step: 1
Training loss: 0.38646936416625977
Validation loss: 1.5162018319611907

Epoch: 6| Step: 2
Training loss: 0.5262643098831177
Validation loss: 1.5291091761281412

Epoch: 6| Step: 3
Training loss: 0.3920629620552063
Validation loss: 1.49474383554151

Epoch: 6| Step: 4
Training loss: 0.5385409593582153
Validation loss: 1.49510694062838

Epoch: 6| Step: 5
Training loss: 0.42111700773239136
Validation loss: 1.5021281729462326

Epoch: 6| Step: 6
Training loss: 0.3493911623954773
Validation loss: 1.493272045607208

Epoch: 6| Step: 7
Training loss: 0.3855403959751129
Validation loss: 1.5360037883122761

Epoch: 6| Step: 8
Training loss: 0.32809919118881226
Validation loss: 1.5660546172049739

Epoch: 6| Step: 9
Training loss: 0.535067081451416
Validation loss: 1.5883720908113705

Epoch: 6| Step: 10
Training loss: 0.6117475032806396
Validation loss: 1.5803850414932414

Epoch: 6| Step: 11
Training loss: 0.5435596108436584
Validation loss: 1.5624031354022283

Epoch: 6| Step: 12
Training loss: 0.397005170583725
Validation loss: 1.571623997021747

Epoch: 6| Step: 13
Training loss: 0.6795456409454346
Validation loss: 1.591796076425942

Epoch: 496| Step: 0
Training loss: 0.3253290057182312
Validation loss: 1.6130138443362327

Epoch: 6| Step: 1
Training loss: 0.6171804070472717
Validation loss: 1.613275110080678

Epoch: 6| Step: 2
Training loss: 0.52008056640625
Validation loss: 1.5536347999367663

Epoch: 6| Step: 3
Training loss: 0.3121517598628998
Validation loss: 1.5827664380432458

Epoch: 6| Step: 4
Training loss: 0.4159182906150818
Validation loss: 1.5699459557892175

Epoch: 6| Step: 5
Training loss: 0.31856921315193176
Validation loss: 1.5883974605990994

Epoch: 6| Step: 6
Training loss: 0.4297724962234497
Validation loss: 1.5893044202558455

Epoch: 6| Step: 7
Training loss: 0.3860834538936615
Validation loss: 1.5951987184504026

Epoch: 6| Step: 8
Training loss: 0.48188892006874084
Validation loss: 1.5820427126781915

Epoch: 6| Step: 9
Training loss: 0.31484973430633545
Validation loss: 1.5967253459397184

Epoch: 6| Step: 10
Training loss: 0.5537205338478088
Validation loss: 1.5746743525228193

Epoch: 6| Step: 11
Training loss: 0.83486407995224
Validation loss: 1.543385592840051

Epoch: 6| Step: 12
Training loss: 0.5007383823394775
Validation loss: 1.5266371516771213

Epoch: 6| Step: 13
Training loss: 0.39126837253570557
Validation loss: 1.5376150326062274

Epoch: 497| Step: 0
Training loss: 0.574930727481842
Validation loss: 1.5815401551544026

Epoch: 6| Step: 1
Training loss: 0.42365360260009766
Validation loss: 1.554383526566208

Epoch: 6| Step: 2
Training loss: 0.8124977350234985
Validation loss: 1.5342846262839533

Epoch: 6| Step: 3
Training loss: 0.4084320068359375
Validation loss: 1.5430675373282483

Epoch: 6| Step: 4
Training loss: 0.4112837016582489
Validation loss: 1.5440165406914168

Epoch: 6| Step: 5
Training loss: 0.5420894622802734
Validation loss: 1.5621504386266072

Epoch: 6| Step: 6
Training loss: 0.4817359447479248
Validation loss: 1.5505771701053908

Epoch: 6| Step: 7
Training loss: 0.3078945279121399
Validation loss: 1.6131666937182028

Epoch: 6| Step: 8
Training loss: 0.23528897762298584
Validation loss: 1.6489234585915842

Epoch: 6| Step: 9
Training loss: 0.42040225863456726
Validation loss: 1.6393744432797996

Epoch: 6| Step: 10
Training loss: 0.3906496465206146
Validation loss: 1.6356625223672518

Epoch: 6| Step: 11
Training loss: 0.5497041344642639
Validation loss: 1.6520956382956555

Epoch: 6| Step: 12
Training loss: 0.35308945178985596
Validation loss: 1.6399933215110534

Epoch: 6| Step: 13
Training loss: 0.6086447238922119
Validation loss: 1.6361687080834502

Epoch: 498| Step: 0
Training loss: 0.5100445747375488
Validation loss: 1.6055771432897097

Epoch: 6| Step: 1
Training loss: 0.20271983742713928
Validation loss: 1.622108264635968

Epoch: 6| Step: 2
Training loss: 0.585780143737793
Validation loss: 1.6127244721176803

Epoch: 6| Step: 3
Training loss: 0.4634976387023926
Validation loss: 1.617735508949526

Epoch: 6| Step: 4
Training loss: 0.2901037633419037
Validation loss: 1.597407183339519

Epoch: 6| Step: 5
Training loss: 0.4509233832359314
Validation loss: 1.6042966560650898

Epoch: 6| Step: 6
Training loss: 0.358193039894104
Validation loss: 1.588746154180137

Epoch: 6| Step: 7
Training loss: 0.4306930899620056
Validation loss: 1.610211544139411

Epoch: 6| Step: 8
Training loss: 0.3906993567943573
Validation loss: 1.6209801499561598

Epoch: 6| Step: 9
Training loss: 0.4603876769542694
Validation loss: 1.615588568872021

Epoch: 6| Step: 10
Training loss: 0.9570415616035461
Validation loss: 1.6542865102009108

Epoch: 6| Step: 11
Training loss: 0.33979737758636475
Validation loss: 1.6448518832524617

Epoch: 6| Step: 12
Training loss: 0.4634801745414734
Validation loss: 1.6377413965040637

Epoch: 6| Step: 13
Training loss: 0.6665282249450684
Validation loss: 1.6350687075686712

Epoch: 499| Step: 0
Training loss: 0.2152862250804901
Validation loss: 1.610156225901778

Epoch: 6| Step: 1
Training loss: 0.3336256742477417
Validation loss: 1.6270754427038214

Epoch: 6| Step: 2
Training loss: 0.7061243653297424
Validation loss: 1.5999638290815457

Epoch: 6| Step: 3
Training loss: 0.4823142886161804
Validation loss: 1.5937515151116155

Epoch: 6| Step: 4
Training loss: 0.6070371270179749
Validation loss: 1.5575594171400993

Epoch: 6| Step: 5
Training loss: 0.5349818468093872
Validation loss: 1.5728589411704772

Epoch: 6| Step: 6
Training loss: 0.3809347152709961
Validation loss: 1.591543278386516

Epoch: 6| Step: 7
Training loss: 0.48527467250823975
Validation loss: 1.60151243722567

Epoch: 6| Step: 8
Training loss: 0.4647376239299774
Validation loss: 1.6026579872254403

Epoch: 6| Step: 9
Training loss: 0.5859377384185791
Validation loss: 1.6468649859069495

Epoch: 6| Step: 10
Training loss: 0.4567776024341583
Validation loss: 1.6564272167862102

Epoch: 6| Step: 11
Training loss: 0.5297454595565796
Validation loss: 1.6418522724541285

Epoch: 6| Step: 12
Training loss: 0.4979262053966522
Validation loss: 1.6662210033785911

Epoch: 6| Step: 13
Training loss: 0.5576989054679871
Validation loss: 1.6459878465180755

Epoch: 500| Step: 0
Training loss: 0.4529224634170532
Validation loss: 1.6349674335090063

Epoch: 6| Step: 1
Training loss: 0.35054507851600647
Validation loss: 1.6106876096417826

Epoch: 6| Step: 2
Training loss: 0.43925750255584717
Validation loss: 1.6147766087644844

Epoch: 6| Step: 3
Training loss: 0.21630758047103882
Validation loss: 1.5870566970558577

Epoch: 6| Step: 4
Training loss: 0.4542035162448883
Validation loss: 1.5383814425878628

Epoch: 6| Step: 5
Training loss: 0.6416012048721313
Validation loss: 1.5222238930322791

Epoch: 6| Step: 6
Training loss: 0.8606717586517334
Validation loss: 1.5487241603994881

Epoch: 6| Step: 7
Training loss: 0.5137219429016113
Validation loss: 1.5534004626735565

Epoch: 6| Step: 8
Training loss: 0.6457889080047607
Validation loss: 1.5696507769246255

Epoch: 6| Step: 9
Training loss: 0.44746100902557373
Validation loss: 1.5716156985170098

Epoch: 6| Step: 10
Training loss: 0.22723737359046936
Validation loss: 1.6082562913176834

Epoch: 6| Step: 11
Training loss: 0.49444782733917236
Validation loss: 1.5872288903882426

Epoch: 6| Step: 12
Training loss: 0.5331634283065796
Validation loss: 1.5888899385288198

Epoch: 6| Step: 13
Training loss: 0.36558881402015686
Validation loss: 1.623782951344726

Testing loss: 1.9936260382334392
