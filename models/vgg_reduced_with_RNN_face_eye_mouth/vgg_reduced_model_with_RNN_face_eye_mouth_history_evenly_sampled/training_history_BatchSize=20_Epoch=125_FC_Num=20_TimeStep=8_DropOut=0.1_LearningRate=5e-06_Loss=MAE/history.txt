Epoch: 1| Step: 0
Training loss: 5.560539245605469
Validation loss: 5.26755440619684

Epoch: 5| Step: 1
Training loss: 5.5705437660217285
Validation loss: 5.262928362815611

Epoch: 5| Step: 2
Training loss: 4.5614519119262695
Validation loss: 5.258331873083628

Epoch: 5| Step: 3
Training loss: 5.236105442047119
Validation loss: 5.253939561946417

Epoch: 5| Step: 4
Training loss: 5.631241798400879
Validation loss: 5.249562996689991

Epoch: 5| Step: 5
Training loss: 5.5226240158081055
Validation loss: 5.2449703421643985

Epoch: 5| Step: 6
Training loss: 4.148821830749512
Validation loss: 5.240812224726523

Epoch: 5| Step: 7
Training loss: 4.49497652053833
Validation loss: 5.236321674880161

Epoch: 5| Step: 8
Training loss: 5.236239433288574
Validation loss: 5.23198769169469

Epoch: 5| Step: 9
Training loss: 4.1924591064453125
Validation loss: 5.22736616032098

Epoch: 5| Step: 10
Training loss: 5.335416793823242
Validation loss: 5.22289656054589

Epoch: 2| Step: 0
Training loss: 5.419867515563965
Validation loss: 5.218576533820039

Epoch: 5| Step: 1
Training loss: 5.6265997886657715
Validation loss: 5.213350839512323

Epoch: 5| Step: 2
Training loss: 5.1214070320129395
Validation loss: 5.208795014248099

Epoch: 5| Step: 3
Training loss: 4.679302215576172
Validation loss: 5.203790680054696

Epoch: 5| Step: 4
Training loss: 5.1102495193481445
Validation loss: 5.198814115216655

Epoch: 5| Step: 5
Training loss: 5.288269519805908
Validation loss: 5.1936431238728185

Epoch: 5| Step: 6
Training loss: 3.157604217529297
Validation loss: 5.1881590145890435

Epoch: 5| Step: 7
Training loss: 5.36007022857666
Validation loss: 5.18251879497241

Epoch: 5| Step: 8
Training loss: 5.2672295570373535
Validation loss: 5.176550516518214

Epoch: 5| Step: 9
Training loss: 5.0770344734191895
Validation loss: 5.170200240227484

Epoch: 5| Step: 10
Training loss: 4.702090263366699
Validation loss: 5.163827373135474

Epoch: 3| Step: 0
Training loss: 5.536942481994629
Validation loss: 5.157097047375094

Epoch: 5| Step: 1
Training loss: 5.873417377471924
Validation loss: 5.149666304229408

Epoch: 5| Step: 2
Training loss: 4.635033130645752
Validation loss: 5.142044754438503

Epoch: 5| Step: 3
Training loss: 5.4483795166015625
Validation loss: 5.134286506201631

Epoch: 5| Step: 4
Training loss: 4.4027814865112305
Validation loss: 5.125673355594758

Epoch: 5| Step: 5
Training loss: 4.352281093597412
Validation loss: 5.116445592654649

Epoch: 5| Step: 6
Training loss: 4.539206504821777
Validation loss: 5.107589978043751

Epoch: 5| Step: 7
Training loss: 4.3418426513671875
Validation loss: 5.098512100917037

Epoch: 5| Step: 8
Training loss: 3.967423915863037
Validation loss: 5.088512948764268

Epoch: 5| Step: 9
Training loss: 5.206851482391357
Validation loss: 5.076864365608461

Epoch: 5| Step: 10
Training loss: 5.83065128326416
Validation loss: 5.065973625388197

Epoch: 4| Step: 0
Training loss: 4.614831447601318
Validation loss: 5.054339449892762

Epoch: 5| Step: 1
Training loss: 4.60322904586792
Validation loss: 5.042097086547523

Epoch: 5| Step: 2
Training loss: 5.263552665710449
Validation loss: 5.028947558454288

Epoch: 5| Step: 3
Training loss: 4.166861534118652
Validation loss: 5.015847126642863

Epoch: 5| Step: 4
Training loss: 5.133675575256348
Validation loss: 5.001613632325204

Epoch: 5| Step: 5
Training loss: 4.284908294677734
Validation loss: 4.987451589235696

Epoch: 5| Step: 6
Training loss: 3.932440996170044
Validation loss: 4.972893448286159

Epoch: 5| Step: 7
Training loss: 4.677246570587158
Validation loss: 4.956874939703172

Epoch: 5| Step: 8
Training loss: 4.796615123748779
Validation loss: 4.9415598120740665

Epoch: 5| Step: 9
Training loss: 5.268623352050781
Validation loss: 4.925198344774143

Epoch: 5| Step: 10
Training loss: 5.953480243682861
Validation loss: 4.907366152732603

Epoch: 5| Step: 0
Training loss: 4.6526994705200195
Validation loss: 4.8909302731995945

Epoch: 5| Step: 1
Training loss: 4.941771507263184
Validation loss: 4.8724072876796924

Epoch: 5| Step: 2
Training loss: 4.519679546356201
Validation loss: 4.854391749187182

Epoch: 5| Step: 3
Training loss: 4.455248832702637
Validation loss: 4.834067421574747

Epoch: 5| Step: 4
Training loss: 5.122137546539307
Validation loss: 4.8145258965030795

Epoch: 5| Step: 5
Training loss: 4.688137531280518
Validation loss: 4.7951399280178935

Epoch: 5| Step: 6
Training loss: 4.180440902709961
Validation loss: 4.775062002161498

Epoch: 5| Step: 7
Training loss: 4.501766204833984
Validation loss: 4.752990445783062

Epoch: 5| Step: 8
Training loss: 3.5697638988494873
Validation loss: 4.732571263467112

Epoch: 5| Step: 9
Training loss: 5.49680757522583
Validation loss: 4.712038824635167

Epoch: 5| Step: 10
Training loss: 4.190694332122803
Validation loss: 4.690756777281402

Epoch: 6| Step: 0
Training loss: 4.00844144821167
Validation loss: 4.6700599475573465

Epoch: 5| Step: 1
Training loss: 4.639874458312988
Validation loss: 4.648363687658823

Epoch: 5| Step: 2
Training loss: 4.382601737976074
Validation loss: 4.625831396349015

Epoch: 5| Step: 3
Training loss: 4.351162910461426
Validation loss: 4.602871674363331

Epoch: 5| Step: 4
Training loss: 4.509885787963867
Validation loss: 4.578720636265253

Epoch: 5| Step: 5
Training loss: 4.832169532775879
Validation loss: 4.553537943029917

Epoch: 5| Step: 6
Training loss: 3.089250326156616
Validation loss: 4.529607770263508

Epoch: 5| Step: 7
Training loss: 4.999142169952393
Validation loss: 4.505663164200321

Epoch: 5| Step: 8
Training loss: 4.046163082122803
Validation loss: 4.4806154415171635

Epoch: 5| Step: 9
Training loss: 4.029555320739746
Validation loss: 4.458209235181091

Epoch: 5| Step: 10
Training loss: 4.89642858505249
Validation loss: 4.434295690187844

Epoch: 7| Step: 0
Training loss: 4.425685882568359
Validation loss: 4.414147869233163

Epoch: 5| Step: 1
Training loss: 4.711562156677246
Validation loss: 4.393077717032484

Epoch: 5| Step: 2
Training loss: 4.65112829208374
Validation loss: 4.373230226578251

Epoch: 5| Step: 3
Training loss: 3.8182194232940674
Validation loss: 4.353302094244188

Epoch: 5| Step: 4
Training loss: 4.57668399810791
Validation loss: 4.334811236268731

Epoch: 5| Step: 5
Training loss: 3.423398494720459
Validation loss: 4.315327977621427

Epoch: 5| Step: 6
Training loss: 4.133297920227051
Validation loss: 4.296886403073547

Epoch: 5| Step: 7
Training loss: 4.722651958465576
Validation loss: 4.281315144672189

Epoch: 5| Step: 8
Training loss: 3.959451198577881
Validation loss: 4.262053607612528

Epoch: 5| Step: 9
Training loss: 3.2473437786102295
Validation loss: 4.246876824286677

Epoch: 5| Step: 10
Training loss: 3.551579236984253
Validation loss: 4.230603946152554

Epoch: 8| Step: 0
Training loss: 3.9282259941101074
Validation loss: 4.215217774914157

Epoch: 5| Step: 1
Training loss: 3.9312522411346436
Validation loss: 4.202210908295006

Epoch: 5| Step: 2
Training loss: 4.200463771820068
Validation loss: 4.187260668764832

Epoch: 5| Step: 3
Training loss: 3.155475378036499
Validation loss: 4.173351036605014

Epoch: 5| Step: 4
Training loss: 4.509727478027344
Validation loss: 4.16154150296283

Epoch: 5| Step: 5
Training loss: 4.712555408477783
Validation loss: 4.147814376379854

Epoch: 5| Step: 6
Training loss: 3.4216809272766113
Validation loss: 4.1343119631531415

Epoch: 5| Step: 7
Training loss: 4.086234092712402
Validation loss: 4.12192299032724

Epoch: 5| Step: 8
Training loss: 2.599541187286377
Validation loss: 4.108812747463103

Epoch: 5| Step: 9
Training loss: 4.394011974334717
Validation loss: 4.096080226282919

Epoch: 5| Step: 10
Training loss: 4.865657329559326
Validation loss: 4.083405876672396

Epoch: 9| Step: 0
Training loss: 4.258971214294434
Validation loss: 4.0727077145730295

Epoch: 5| Step: 1
Training loss: 4.042088985443115
Validation loss: 4.060165746237642

Epoch: 5| Step: 2
Training loss: 3.918827772140503
Validation loss: 4.048389993688112

Epoch: 5| Step: 3
Training loss: 4.847334861755371
Validation loss: 4.037672140265024

Epoch: 5| Step: 4
Training loss: 4.298851013183594
Validation loss: 4.024961040865991

Epoch: 5| Step: 5
Training loss: 3.7101898193359375
Validation loss: 4.013126116926952

Epoch: 5| Step: 6
Training loss: 2.5165278911590576
Validation loss: 4.003710526292042

Epoch: 5| Step: 7
Training loss: 4.059616565704346
Validation loss: 3.9912550475007746

Epoch: 5| Step: 8
Training loss: 2.9318575859069824
Validation loss: 3.9796321186968076

Epoch: 5| Step: 9
Training loss: 3.8496570587158203
Validation loss: 3.9685802972444923

Epoch: 5| Step: 10
Training loss: 4.039705276489258
Validation loss: 3.9565834614538375

Epoch: 10| Step: 0
Training loss: 3.7497360706329346
Validation loss: 3.943050040993639

Epoch: 5| Step: 1
Training loss: 3.0127291679382324
Validation loss: 3.930369148972214

Epoch: 5| Step: 2
Training loss: 3.382650852203369
Validation loss: 3.9198573225287983

Epoch: 5| Step: 3
Training loss: 3.7292943000793457
Validation loss: 3.908045143209478

Epoch: 5| Step: 4
Training loss: 3.493244171142578
Validation loss: 3.897679428900442

Epoch: 5| Step: 5
Training loss: 4.358903408050537
Validation loss: 3.884669521803497

Epoch: 5| Step: 6
Training loss: 4.348206520080566
Validation loss: 3.8743517783380326

Epoch: 5| Step: 7
Training loss: 3.7644131183624268
Validation loss: 3.8605990896942797

Epoch: 5| Step: 8
Training loss: 3.7933132648468018
Validation loss: 3.8505869732108167

Epoch: 5| Step: 9
Training loss: 3.148350238800049
Validation loss: 3.8392836457939556

Epoch: 5| Step: 10
Training loss: 4.59849739074707
Validation loss: 3.8301276494097967

Epoch: 11| Step: 0
Training loss: 3.277503490447998
Validation loss: 3.8152689933776855

Epoch: 5| Step: 1
Training loss: 3.499352216720581
Validation loss: 3.806180497651459

Epoch: 5| Step: 2
Training loss: 3.3112106323242188
Validation loss: 3.7951859504945817

Epoch: 5| Step: 3
Training loss: 3.883268356323242
Validation loss: 3.785430359584029

Epoch: 5| Step: 4
Training loss: 3.4991352558135986
Validation loss: 3.7754076014282885

Epoch: 5| Step: 5
Training loss: 3.636489152908325
Validation loss: 3.765877026383595

Epoch: 5| Step: 6
Training loss: 4.48166036605835
Validation loss: 3.756610765252062

Epoch: 5| Step: 7
Training loss: 2.6236460208892822
Validation loss: 3.7465317685117006

Epoch: 5| Step: 8
Training loss: 3.510906219482422
Validation loss: 3.736806608015491

Epoch: 5| Step: 9
Training loss: 4.8882246017456055
Validation loss: 3.726742103535642

Epoch: 5| Step: 10
Training loss: 3.5954806804656982
Validation loss: 3.7166394931013866

Epoch: 12| Step: 0
Training loss: 3.2124950885772705
Validation loss: 3.7071677484819965

Epoch: 5| Step: 1
Training loss: 3.299095869064331
Validation loss: 3.6971670273811585

Epoch: 5| Step: 2
Training loss: 4.417685508728027
Validation loss: 3.6874839157186527

Epoch: 5| Step: 3
Training loss: 2.5417606830596924
Validation loss: 3.6798287309626097

Epoch: 5| Step: 4
Training loss: 4.362594127655029
Validation loss: 3.671435643267888

Epoch: 5| Step: 5
Training loss: 3.419203996658325
Validation loss: 3.6636184902601343

Epoch: 5| Step: 6
Training loss: 4.072665214538574
Validation loss: 3.657232271727695

Epoch: 5| Step: 7
Training loss: 3.6075692176818848
Validation loss: 3.6483423786778606

Epoch: 5| Step: 8
Training loss: 3.7867374420166016
Validation loss: 3.64231813082131

Epoch: 5| Step: 9
Training loss: 2.7976582050323486
Validation loss: 3.6346944378268335

Epoch: 5| Step: 10
Training loss: 3.800621509552002
Validation loss: 3.625636536587951

Epoch: 13| Step: 0
Training loss: 3.036816358566284
Validation loss: 3.6184895961515364

Epoch: 5| Step: 1
Training loss: 4.568920135498047
Validation loss: 3.6086888313293457

Epoch: 5| Step: 2
Training loss: 3.0557522773742676
Validation loss: 3.5994487988051547

Epoch: 5| Step: 3
Training loss: 3.817781925201416
Validation loss: 3.5936452906618834

Epoch: 5| Step: 4
Training loss: 3.589573383331299
Validation loss: 3.584217699625159

Epoch: 5| Step: 5
Training loss: 3.078958511352539
Validation loss: 3.577926233250608

Epoch: 5| Step: 6
Training loss: 3.633207321166992
Validation loss: 3.571863030874601

Epoch: 5| Step: 7
Training loss: 3.4412379264831543
Validation loss: 3.5656085757799048

Epoch: 5| Step: 8
Training loss: 3.5108139514923096
Validation loss: 3.5612905768937964

Epoch: 5| Step: 9
Training loss: 3.1989967823028564
Validation loss: 3.5554108696599163

Epoch: 5| Step: 10
Training loss: 3.6559536457061768
Validation loss: 3.551012131475633

Epoch: 14| Step: 0
Training loss: 4.156927585601807
Validation loss: 3.54408012923374

Epoch: 5| Step: 1
Training loss: 2.7829785346984863
Validation loss: 3.5402771272966937

Epoch: 5| Step: 2
Training loss: 3.8128738403320312
Validation loss: 3.5357179462268786

Epoch: 5| Step: 3
Training loss: 3.0330557823181152
Validation loss: 3.528266978520219

Epoch: 5| Step: 4
Training loss: 3.4894192218780518
Validation loss: 3.5261842614860943

Epoch: 5| Step: 5
Training loss: 2.7010180950164795
Validation loss: 3.519045704154558

Epoch: 5| Step: 6
Training loss: 3.4999611377716064
Validation loss: 3.515054892468196

Epoch: 5| Step: 7
Training loss: 3.3284831047058105
Validation loss: 3.5135284341791624

Epoch: 5| Step: 8
Training loss: 3.0600314140319824
Validation loss: 3.5060895232744116

Epoch: 5| Step: 9
Training loss: 4.620584011077881
Validation loss: 3.5010657438667874

Epoch: 5| Step: 10
Training loss: 3.482910633087158
Validation loss: 3.4950705856405277

Epoch: 15| Step: 0
Training loss: 4.501317501068115
Validation loss: 3.490389762386199

Epoch: 5| Step: 1
Training loss: 2.4938135147094727
Validation loss: 3.485592293482955

Epoch: 5| Step: 2
Training loss: 3.4437663555145264
Validation loss: 3.4815562643030638

Epoch: 5| Step: 3
Training loss: 2.9183614253997803
Validation loss: 3.4771247063913653

Epoch: 5| Step: 4
Training loss: 3.496567964553833
Validation loss: 3.472369478594872

Epoch: 5| Step: 5
Training loss: 4.279019355773926
Validation loss: 3.4675866198796097

Epoch: 5| Step: 6
Training loss: 3.2750678062438965
Validation loss: 3.4616020776892222

Epoch: 5| Step: 7
Training loss: 2.7224373817443848
Validation loss: 3.457497542904269

Epoch: 5| Step: 8
Training loss: 3.5976386070251465
Validation loss: 3.453275465196179

Epoch: 5| Step: 9
Training loss: 3.9327659606933594
Validation loss: 3.448345817545409

Epoch: 5| Step: 10
Training loss: 2.7004590034484863
Validation loss: 3.4438316001687

Epoch: 16| Step: 0
Training loss: 3.6780788898468018
Validation loss: 3.44034392346618

Epoch: 5| Step: 1
Training loss: 3.1645407676696777
Validation loss: 3.4353997553548505

Epoch: 5| Step: 2
Training loss: 3.3324038982391357
Validation loss: 3.4331072504802416

Epoch: 5| Step: 3
Training loss: 3.8548684120178223
Validation loss: 3.426238142034059

Epoch: 5| Step: 4
Training loss: 3.5531070232391357
Validation loss: 3.423650380103819

Epoch: 5| Step: 5
Training loss: 3.674410581588745
Validation loss: 3.417363912828507

Epoch: 5| Step: 6
Training loss: 3.2611095905303955
Validation loss: 3.4124179886233423

Epoch: 5| Step: 7
Training loss: 3.6522011756896973
Validation loss: 3.406750161160705

Epoch: 5| Step: 8
Training loss: 2.8880910873413086
Validation loss: 3.403995749770954

Epoch: 5| Step: 9
Training loss: 3.3902904987335205
Validation loss: 3.4004350221285256

Epoch: 5| Step: 10
Training loss: 2.4430525302886963
Validation loss: 3.3946373155040126

Epoch: 17| Step: 0
Training loss: 3.614971160888672
Validation loss: 3.390072358551846

Epoch: 5| Step: 1
Training loss: 3.043147563934326
Validation loss: 3.388117377476026

Epoch: 5| Step: 2
Training loss: 3.3085243701934814
Validation loss: 3.3810462874750935

Epoch: 5| Step: 3
Training loss: 3.407029390335083
Validation loss: 3.3784429898826023

Epoch: 5| Step: 4
Training loss: 4.18065071105957
Validation loss: 3.375952228423088

Epoch: 5| Step: 5
Training loss: 3.250459671020508
Validation loss: 3.3709324380402923

Epoch: 5| Step: 6
Training loss: 2.8813204765319824
Validation loss: 3.3663988241585354

Epoch: 5| Step: 7
Training loss: 3.551180362701416
Validation loss: 3.361204952322027

Epoch: 5| Step: 8
Training loss: 2.860154867172241
Validation loss: 3.355599528999739

Epoch: 5| Step: 9
Training loss: 3.4106898307800293
Validation loss: 3.3521696547026276

Epoch: 5| Step: 10
Training loss: 3.0445396900177
Validation loss: 3.348349919883154

Epoch: 18| Step: 0
Training loss: 4.099493503570557
Validation loss: 3.345296344449443

Epoch: 5| Step: 1
Training loss: 3.611391067504883
Validation loss: 3.3422990511822444

Epoch: 5| Step: 2
Training loss: 2.873310089111328
Validation loss: 3.3350436815651516

Epoch: 5| Step: 3
Training loss: 2.2411465644836426
Validation loss: 3.3340057660174627

Epoch: 5| Step: 4
Training loss: 2.921438217163086
Validation loss: 3.329093053776731

Epoch: 5| Step: 5
Training loss: 3.9030582904815674
Validation loss: 3.326574615252915

Epoch: 5| Step: 6
Training loss: 3.3822085857391357
Validation loss: 3.3216150191522416

Epoch: 5| Step: 7
Training loss: 3.6205074787139893
Validation loss: 3.3167170093905542

Epoch: 5| Step: 8
Training loss: 3.5099291801452637
Validation loss: 3.31690840823676

Epoch: 5| Step: 9
Training loss: 3.209892749786377
Validation loss: 3.3130146457302954

Epoch: 5| Step: 10
Training loss: 2.7501718997955322
Validation loss: 3.306186424788608

Epoch: 19| Step: 0
Training loss: 3.5167953968048096
Validation loss: 3.3004120524211595

Epoch: 5| Step: 1
Training loss: 3.670095920562744
Validation loss: 3.300426603645407

Epoch: 5| Step: 2
Training loss: 2.893867015838623
Validation loss: 3.3012196556214364

Epoch: 5| Step: 3
Training loss: 2.6835269927978516
Validation loss: 3.299223376858619

Epoch: 5| Step: 4
Training loss: 3.765169620513916
Validation loss: 3.292442839632752

Epoch: 5| Step: 5
Training loss: 3.451636552810669
Validation loss: 3.2878408816552933

Epoch: 5| Step: 6
Training loss: 3.668907642364502
Validation loss: 3.2888218997627177

Epoch: 5| Step: 7
Training loss: 3.975156307220459
Validation loss: 3.288394361413935

Epoch: 5| Step: 8
Training loss: 2.370129108428955
Validation loss: 3.2785333279640443

Epoch: 5| Step: 9
Training loss: 2.362339496612549
Validation loss: 3.275896426170103

Epoch: 5| Step: 10
Training loss: 3.5625805854797363
Validation loss: 3.27167328967843

Epoch: 20| Step: 0
Training loss: 2.9018702507019043
Validation loss: 3.26744778438281

Epoch: 5| Step: 1
Training loss: 5.226492881774902
Validation loss: 3.2646198452159925

Epoch: 5| Step: 2
Training loss: 4.026736259460449
Validation loss: 3.26215446636241

Epoch: 5| Step: 3
Training loss: 3.1616873741149902
Validation loss: 3.2569807729413434

Epoch: 5| Step: 4
Training loss: 2.608424663543701
Validation loss: 3.253174025525329

Epoch: 5| Step: 5
Training loss: 2.7565956115722656
Validation loss: 3.249199018683485

Epoch: 5| Step: 6
Training loss: 3.164808511734009
Validation loss: 3.2471002276225756

Epoch: 5| Step: 7
Training loss: 2.6344046592712402
Validation loss: 3.2423088704386065

Epoch: 5| Step: 8
Training loss: 3.4821410179138184
Validation loss: 3.2400095539708293

Epoch: 5| Step: 9
Training loss: 2.7331302165985107
Validation loss: 3.233785001180505

Epoch: 5| Step: 10
Training loss: 2.7986562252044678
Validation loss: 3.2300554834386355

Epoch: 21| Step: 0
Training loss: 2.933366537094116
Validation loss: 3.2265822272146902

Epoch: 5| Step: 1
Training loss: 3.6376633644104004
Validation loss: 3.2245015508385113

Epoch: 5| Step: 2
Training loss: 3.469416379928589
Validation loss: 3.2203391751935406

Epoch: 5| Step: 3
Training loss: 3.4311611652374268
Validation loss: 3.2213835408610683

Epoch: 5| Step: 4
Training loss: 2.424705982208252
Validation loss: 3.2190423216871036

Epoch: 5| Step: 5
Training loss: 2.865917921066284
Validation loss: 3.2186052645406416

Epoch: 5| Step: 6
Training loss: 2.9957213401794434
Validation loss: 3.2145043624344694

Epoch: 5| Step: 7
Training loss: 3.9882595539093018
Validation loss: 3.212189925614224

Epoch: 5| Step: 8
Training loss: 3.0269038677215576
Validation loss: 3.2074672201628327

Epoch: 5| Step: 9
Training loss: 3.5961737632751465
Validation loss: 3.2029509211099274

Epoch: 5| Step: 10
Training loss: 2.8392930030822754
Validation loss: 3.2005980988984466

Epoch: 22| Step: 0
Training loss: 2.6619560718536377
Validation loss: 3.195374442685035

Epoch: 5| Step: 1
Training loss: 3.9507193565368652
Validation loss: 3.191675950122136

Epoch: 5| Step: 2
Training loss: 2.453449249267578
Validation loss: 3.192584196726481

Epoch: 5| Step: 3
Training loss: 3.4977059364318848
Validation loss: 3.1953353804926716

Epoch: 5| Step: 4
Training loss: 2.7248027324676514
Validation loss: 3.1892356923831406

Epoch: 5| Step: 5
Training loss: 3.7789528369903564
Validation loss: 3.1931831580336376

Epoch: 5| Step: 6
Training loss: 3.4941565990448
Validation loss: 3.191688945216517

Epoch: 5| Step: 7
Training loss: 4.453616142272949
Validation loss: 3.191497633534093

Epoch: 5| Step: 8
Training loss: 2.4580228328704834
Validation loss: 3.1851559736395396

Epoch: 5| Step: 9
Training loss: 2.7560837268829346
Validation loss: 3.178769414142896

Epoch: 5| Step: 10
Training loss: 2.7283873558044434
Validation loss: 3.171191002732964

Epoch: 23| Step: 0
Training loss: 3.100860595703125
Validation loss: 3.1715957221164497

Epoch: 5| Step: 1
Training loss: 3.360642910003662
Validation loss: 3.1657315736175864

Epoch: 5| Step: 2
Training loss: 3.353018283843994
Validation loss: 3.1640628896733767

Epoch: 5| Step: 3
Training loss: 2.9500463008880615
Validation loss: 3.165602368693198

Epoch: 5| Step: 4
Training loss: 2.961538553237915
Validation loss: 3.156413411581388

Epoch: 5| Step: 5
Training loss: 2.7701923847198486
Validation loss: 3.157227590519895

Epoch: 5| Step: 6
Training loss: 4.421647071838379
Validation loss: 3.1529563601298998

Epoch: 5| Step: 7
Training loss: 2.304138660430908
Validation loss: 3.152157886053926

Epoch: 5| Step: 8
Training loss: 3.1906142234802246
Validation loss: 3.1492709805888515

Epoch: 5| Step: 9
Training loss: 2.9314396381378174
Validation loss: 3.148136172243344

Epoch: 5| Step: 10
Training loss: 3.553466558456421
Validation loss: 3.1431083704835627

Epoch: 24| Step: 0
Training loss: 3.5991311073303223
Validation loss: 3.1450214565441175

Epoch: 5| Step: 1
Training loss: 2.8589255809783936
Validation loss: 3.1410599088156097

Epoch: 5| Step: 2
Training loss: 3.035860300064087
Validation loss: 3.1385388169237363

Epoch: 5| Step: 3
Training loss: 3.205233335494995
Validation loss: 3.1365263513339463

Epoch: 5| Step: 4
Training loss: 3.840247392654419
Validation loss: 3.1382992677791144

Epoch: 5| Step: 5
Training loss: 2.6988093852996826
Validation loss: 3.135941623359598

Epoch: 5| Step: 6
Training loss: 2.7549803256988525
Validation loss: 3.136888514282883

Epoch: 5| Step: 7
Training loss: 3.372746229171753
Validation loss: 3.135439119031352

Epoch: 5| Step: 8
Training loss: 2.3060946464538574
Validation loss: 3.1350804067427114

Epoch: 5| Step: 9
Training loss: 3.812861680984497
Validation loss: 3.133185532785231

Epoch: 5| Step: 10
Training loss: 3.198803186416626
Validation loss: 3.1298843147934123

Epoch: 25| Step: 0
Training loss: 2.567923069000244
Validation loss: 3.125774832182033

Epoch: 5| Step: 1
Training loss: 2.7940170764923096
Validation loss: 3.1209989773329867

Epoch: 5| Step: 2
Training loss: 2.900477886199951
Validation loss: 3.1213826440995738

Epoch: 5| Step: 3
Training loss: 3.8787503242492676
Validation loss: 3.1195865343975764

Epoch: 5| Step: 4
Training loss: 2.426764726638794
Validation loss: 3.118333073072536

Epoch: 5| Step: 5
Training loss: 4.232565879821777
Validation loss: 3.1162257886702016

Epoch: 5| Step: 6
Training loss: 2.8102869987487793
Validation loss: 3.117194139829246

Epoch: 5| Step: 7
Training loss: 4.191469669342041
Validation loss: 3.113645399770429

Epoch: 5| Step: 8
Training loss: 2.412034511566162
Validation loss: 3.1146390412443425

Epoch: 5| Step: 9
Training loss: 2.833495616912842
Validation loss: 3.1126381402374594

Epoch: 5| Step: 10
Training loss: 3.552365779876709
Validation loss: 3.1075333420948317

Epoch: 26| Step: 0
Training loss: 4.647122383117676
Validation loss: 3.108544936744116

Epoch: 5| Step: 1
Training loss: 2.9626126289367676
Validation loss: 3.1072307966088735

Epoch: 5| Step: 2
Training loss: 2.593916654586792
Validation loss: 3.101454319492463

Epoch: 5| Step: 3
Training loss: 3.1070263385772705
Validation loss: 3.100058909385435

Epoch: 5| Step: 4
Training loss: 2.5006802082061768
Validation loss: 3.0974281193107687

Epoch: 5| Step: 5
Training loss: 2.867952346801758
Validation loss: 3.0940158982430734

Epoch: 5| Step: 6
Training loss: 3.0031518936157227
Validation loss: 3.0952986645442184

Epoch: 5| Step: 7
Training loss: 3.108630895614624
Validation loss: 3.0928818666806785

Epoch: 5| Step: 8
Training loss: 2.8408572673797607
Validation loss: 3.088213102791899

Epoch: 5| Step: 9
Training loss: 3.885810375213623
Validation loss: 3.088576352724465

Epoch: 5| Step: 10
Training loss: 2.8380789756774902
Validation loss: 3.086987664622645

Epoch: 27| Step: 0
Training loss: 3.6687464714050293
Validation loss: 3.086413009192354

Epoch: 5| Step: 1
Training loss: 3.0212292671203613
Validation loss: 3.084387743344871

Epoch: 5| Step: 2
Training loss: 3.076286554336548
Validation loss: 3.0845190940364713

Epoch: 5| Step: 3
Training loss: 3.1016597747802734
Validation loss: 3.0818404177183747

Epoch: 5| Step: 4
Training loss: 3.113982677459717
Validation loss: 3.0954787808079876

Epoch: 5| Step: 5
Training loss: 2.5578112602233887
Validation loss: 3.0800439426975865

Epoch: 5| Step: 6
Training loss: 3.5213820934295654
Validation loss: 3.0745473779657835

Epoch: 5| Step: 7
Training loss: 3.7058653831481934
Validation loss: 3.0761755512606714

Epoch: 5| Step: 8
Training loss: 2.5981807708740234
Validation loss: 3.0763367247837845

Epoch: 5| Step: 9
Training loss: 2.6268887519836426
Validation loss: 3.073680980231172

Epoch: 5| Step: 10
Training loss: 3.294999122619629
Validation loss: 3.074583699626307

Epoch: 28| Step: 0
Training loss: 3.60503888130188
Validation loss: 3.073849924149052

Epoch: 5| Step: 1
Training loss: 3.074972629547119
Validation loss: 3.0805330455944104

Epoch: 5| Step: 2
Training loss: 2.760085344314575
Validation loss: 3.082860210890411

Epoch: 5| Step: 3
Training loss: 2.881600856781006
Validation loss: 3.082510309834634

Epoch: 5| Step: 4
Training loss: 4.590580940246582
Validation loss: 3.078339943321802

Epoch: 5| Step: 5
Training loss: 2.335574150085449
Validation loss: 3.0683922460002284

Epoch: 5| Step: 6
Training loss: 2.817622423171997
Validation loss: 3.0672669590160413

Epoch: 5| Step: 7
Training loss: 2.4286179542541504
Validation loss: 3.0642598957143803

Epoch: 5| Step: 8
Training loss: 3.237048387527466
Validation loss: 3.066829953142392

Epoch: 5| Step: 9
Training loss: 3.4317100048065186
Validation loss: 3.066012477362028

Epoch: 5| Step: 10
Training loss: 3.026670455932617
Validation loss: 3.06431177098264

Epoch: 29| Step: 0
Training loss: 2.516932964324951
Validation loss: 3.063120247215353

Epoch: 5| Step: 1
Training loss: 3.5055484771728516
Validation loss: 3.060824445498887

Epoch: 5| Step: 2
Training loss: 3.504986524581909
Validation loss: 3.05932250074161

Epoch: 5| Step: 3
Training loss: 3.0367469787597656
Validation loss: 3.0569032340921383

Epoch: 5| Step: 4
Training loss: 2.787374973297119
Validation loss: 3.0581188227540705

Epoch: 5| Step: 5
Training loss: 3.3460686206817627
Validation loss: 3.056281087219074

Epoch: 5| Step: 6
Training loss: 2.6321380138397217
Validation loss: 3.0546605381914365

Epoch: 5| Step: 7
Training loss: 3.8226444721221924
Validation loss: 3.053906322807394

Epoch: 5| Step: 8
Training loss: 2.3186144828796387
Validation loss: 3.055846539876794

Epoch: 5| Step: 9
Training loss: 3.3324966430664062
Validation loss: 3.05263009378987

Epoch: 5| Step: 10
Training loss: 3.348546028137207
Validation loss: 3.0512164664524857

Epoch: 30| Step: 0
Training loss: 2.516460657119751
Validation loss: 3.04877475512925

Epoch: 5| Step: 1
Training loss: 2.7776002883911133
Validation loss: 3.0451394101624847

Epoch: 5| Step: 2
Training loss: 3.395127058029175
Validation loss: 3.0442001614519345

Epoch: 5| Step: 3
Training loss: 2.628150701522827
Validation loss: 3.0418464035116215

Epoch: 5| Step: 4
Training loss: 3.6136844158172607
Validation loss: 3.0409534464600267

Epoch: 5| Step: 5
Training loss: 2.7106900215148926
Validation loss: 3.0405008023785007

Epoch: 5| Step: 6
Training loss: 3.343022108078003
Validation loss: 3.0387413322284655

Epoch: 5| Step: 7
Training loss: 3.3204493522644043
Validation loss: 3.038301319204351

Epoch: 5| Step: 8
Training loss: 2.421391010284424
Validation loss: 3.0371554820768294

Epoch: 5| Step: 9
Training loss: 3.697779893875122
Validation loss: 3.03556409189778

Epoch: 5| Step: 10
Training loss: 3.6709437370300293
Validation loss: 3.034210620387908

Epoch: 31| Step: 0
Training loss: 2.4114627838134766
Validation loss: 3.034500583525627

Epoch: 5| Step: 1
Training loss: 3.827849864959717
Validation loss: 3.032417405036188

Epoch: 5| Step: 2
Training loss: 3.3829169273376465
Validation loss: 3.031552327576504

Epoch: 5| Step: 3
Training loss: 2.501845121383667
Validation loss: 3.031027235010619

Epoch: 5| Step: 4
Training loss: 2.7274975776672363
Validation loss: 3.02942838463732

Epoch: 5| Step: 5
Training loss: 3.142575263977051
Validation loss: 3.028774553729642

Epoch: 5| Step: 6
Training loss: 2.9001338481903076
Validation loss: 3.02855069662935

Epoch: 5| Step: 7
Training loss: 2.805525541305542
Validation loss: 3.027288995763307

Epoch: 5| Step: 8
Training loss: 3.2790045738220215
Validation loss: 3.0245258987590833

Epoch: 5| Step: 9
Training loss: 3.420862913131714
Validation loss: 3.025671571813604

Epoch: 5| Step: 10
Training loss: 3.608309030532837
Validation loss: 3.0237821225197083

Epoch: 32| Step: 0
Training loss: 2.619223117828369
Validation loss: 3.023695609902823

Epoch: 5| Step: 1
Training loss: 3.073795795440674
Validation loss: 3.0214463921003443

Epoch: 5| Step: 2
Training loss: 3.3335342407226562
Validation loss: 3.0226698588299494

Epoch: 5| Step: 3
Training loss: 4.251513481140137
Validation loss: 3.021889809639223

Epoch: 5| Step: 4
Training loss: 2.4619333744049072
Validation loss: 3.0194294837213334

Epoch: 5| Step: 5
Training loss: 3.0823428630828857
Validation loss: 3.018242366852299

Epoch: 5| Step: 6
Training loss: 2.5316131114959717
Validation loss: 3.0257811366870837

Epoch: 5| Step: 7
Training loss: 3.434816837310791
Validation loss: 3.060958521340483

Epoch: 5| Step: 8
Training loss: 3.1354782581329346
Validation loss: 3.020820238256967

Epoch: 5| Step: 9
Training loss: 2.451772928237915
Validation loss: 3.0127715782452653

Epoch: 5| Step: 10
Training loss: 3.6169512271881104
Validation loss: 3.0142680906480357

Epoch: 33| Step: 0
Training loss: 3.1228957176208496
Validation loss: 3.016332459706132

Epoch: 5| Step: 1
Training loss: 3.546888828277588
Validation loss: 3.015388309314687

Epoch: 5| Step: 2
Training loss: 3.2278130054473877
Validation loss: 3.0139987084173385

Epoch: 5| Step: 3
Training loss: 2.7349915504455566
Validation loss: 3.014780185555899

Epoch: 5| Step: 4
Training loss: 2.298297882080078
Validation loss: 3.010931025269211

Epoch: 5| Step: 5
Training loss: 3.182361125946045
Validation loss: 3.013139024857552

Epoch: 5| Step: 6
Training loss: 2.719154119491577
Validation loss: 3.011579200785647

Epoch: 5| Step: 7
Training loss: 2.515244960784912
Validation loss: 3.008821448972148

Epoch: 5| Step: 8
Training loss: 4.418430328369141
Validation loss: 3.006611857362973

Epoch: 5| Step: 9
Training loss: 2.82246470451355
Validation loss: 3.008290183159613

Epoch: 5| Step: 10
Training loss: 3.2378947734832764
Validation loss: 3.0047921544762066

Epoch: 34| Step: 0
Training loss: 3.8474884033203125
Validation loss: 3.004531098950294

Epoch: 5| Step: 1
Training loss: 2.701054811477661
Validation loss: 3.0053285885882635

Epoch: 5| Step: 2
Training loss: 2.3328285217285156
Validation loss: 3.004348357518514

Epoch: 5| Step: 3
Training loss: 3.1479415893554688
Validation loss: 3.0036855641231743

Epoch: 5| Step: 4
Training loss: 3.423753261566162
Validation loss: 2.997771604086763

Epoch: 5| Step: 5
Training loss: 3.2638206481933594
Validation loss: 2.9949575393430647

Epoch: 5| Step: 6
Training loss: 2.5305988788604736
Validation loss: 2.995632145994453

Epoch: 5| Step: 7
Training loss: 2.6096978187561035
Validation loss: 2.991119618056923

Epoch: 5| Step: 8
Training loss: 3.3720126152038574
Validation loss: 2.9927712768636723

Epoch: 5| Step: 9
Training loss: 3.6822657585144043
Validation loss: 2.988976740068005

Epoch: 5| Step: 10
Training loss: 2.726499557495117
Validation loss: 2.9864010503215175

Epoch: 35| Step: 0
Training loss: 2.677402973175049
Validation loss: 2.9926248006923224

Epoch: 5| Step: 1
Training loss: 3.3280856609344482
Validation loss: 2.990278369636946

Epoch: 5| Step: 2
Training loss: 3.676684617996216
Validation loss: 2.9864751472268054

Epoch: 5| Step: 3
Training loss: 3.0493340492248535
Validation loss: 2.9854141230224283

Epoch: 5| Step: 4
Training loss: 3.9304840564727783
Validation loss: 2.983161582741686

Epoch: 5| Step: 5
Training loss: 2.6264326572418213
Validation loss: 2.9830292014665503

Epoch: 5| Step: 6
Training loss: 2.4431557655334473
Validation loss: 2.983504295349121

Epoch: 5| Step: 7
Training loss: 3.3292763233184814
Validation loss: 2.977765888296148

Epoch: 5| Step: 8
Training loss: 2.021559476852417
Validation loss: 2.9808907867759786

Epoch: 5| Step: 9
Training loss: 2.735286235809326
Validation loss: 2.976112860505299

Epoch: 5| Step: 10
Training loss: 3.910897731781006
Validation loss: 2.968888280212238

Epoch: 36| Step: 0
Training loss: 1.9877007007598877
Validation loss: 2.9688814583645073

Epoch: 5| Step: 1
Training loss: 3.419668197631836
Validation loss: 2.9696973164876304

Epoch: 5| Step: 2
Training loss: 2.6460933685302734
Validation loss: 2.9671852357925905

Epoch: 5| Step: 3
Training loss: 3.482513427734375
Validation loss: 2.9659197740657355

Epoch: 5| Step: 4
Training loss: 3.3631491661071777
Validation loss: 2.962754818700975

Epoch: 5| Step: 5
Training loss: 3.281838893890381
Validation loss: 2.961651479044268

Epoch: 5| Step: 6
Training loss: 2.9038174152374268
Validation loss: 2.9615674582860803

Epoch: 5| Step: 7
Training loss: 3.5063858032226562
Validation loss: 2.9610816586402153

Epoch: 5| Step: 8
Training loss: 2.503894090652466
Validation loss: 2.9642061982103574

Epoch: 5| Step: 9
Training loss: 2.703676700592041
Validation loss: 2.9604670642524638

Epoch: 5| Step: 10
Training loss: 3.743945837020874
Validation loss: 2.962969864568403

Epoch: 37| Step: 0
Training loss: 2.6451425552368164
Validation loss: 2.959951403320477

Epoch: 5| Step: 1
Training loss: 3.0608088970184326
Validation loss: 2.961489728702012

Epoch: 5| Step: 2
Training loss: 3.014927387237549
Validation loss: 2.957505997791085

Epoch: 5| Step: 3
Training loss: 3.5343775749206543
Validation loss: 2.955958386903168

Epoch: 5| Step: 4
Training loss: 2.5647177696228027
Validation loss: 2.954382665695683

Epoch: 5| Step: 5
Training loss: 3.1276767253875732
Validation loss: 2.9556020741821616

Epoch: 5| Step: 6
Training loss: 3.414670944213867
Validation loss: 2.953143512049029

Epoch: 5| Step: 7
Training loss: 2.579055070877075
Validation loss: 2.9530781212673394

Epoch: 5| Step: 8
Training loss: 4.33988094329834
Validation loss: 2.9533067390482914

Epoch: 5| Step: 9
Training loss: 2.7672669887542725
Validation loss: 2.9514126521284862

Epoch: 5| Step: 10
Training loss: 2.2189550399780273
Validation loss: 2.95079118205655

Epoch: 38| Step: 0
Training loss: 3.061073064804077
Validation loss: 2.9510910946835756

Epoch: 5| Step: 1
Training loss: 2.4061553478240967
Validation loss: 2.9491697101182837

Epoch: 5| Step: 2
Training loss: 3.2138423919677734
Validation loss: 2.950966283839236

Epoch: 5| Step: 3
Training loss: 3.900132417678833
Validation loss: 2.9493786545209986

Epoch: 5| Step: 4
Training loss: 2.895474910736084
Validation loss: 2.9482984235209804

Epoch: 5| Step: 5
Training loss: 3.187767267227173
Validation loss: 2.9497197469075522

Epoch: 5| Step: 6
Training loss: 2.2940027713775635
Validation loss: 2.944803701933994

Epoch: 5| Step: 7
Training loss: 2.923661231994629
Validation loss: 2.945449952156313

Epoch: 5| Step: 8
Training loss: 3.7108352184295654
Validation loss: 2.9435414703943397

Epoch: 5| Step: 9
Training loss: 3.1618854999542236
Validation loss: 2.9429785333653933

Epoch: 5| Step: 10
Training loss: 2.4824328422546387
Validation loss: 2.9415088417709514

Epoch: 39| Step: 0
Training loss: 2.622945785522461
Validation loss: 2.9404317845580397

Epoch: 5| Step: 1
Training loss: 2.8987834453582764
Validation loss: 2.9413306943831907

Epoch: 5| Step: 2
Training loss: 3.138291835784912
Validation loss: 2.9390980556447017

Epoch: 5| Step: 3
Training loss: 2.4570090770721436
Validation loss: 2.9388375820652133

Epoch: 5| Step: 4
Training loss: 2.721773624420166
Validation loss: 2.9381442326371388

Epoch: 5| Step: 5
Training loss: 4.033426284790039
Validation loss: 2.937621121765465

Epoch: 5| Step: 6
Training loss: 3.476551055908203
Validation loss: 2.9367609100957073

Epoch: 5| Step: 7
Training loss: 3.064220666885376
Validation loss: 2.936263507412326

Epoch: 5| Step: 8
Training loss: 3.2627780437469482
Validation loss: 2.93549487667699

Epoch: 5| Step: 9
Training loss: 2.1966373920440674
Validation loss: 2.9352426323839413

Epoch: 5| Step: 10
Training loss: 3.445591449737549
Validation loss: 2.934454112924555

Epoch: 40| Step: 0
Training loss: 3.775784969329834
Validation loss: 2.932128091012278

Epoch: 5| Step: 1
Training loss: 2.36344575881958
Validation loss: 2.9339729150136313

Epoch: 5| Step: 2
Training loss: 2.9893898963928223
Validation loss: 2.933164014611193

Epoch: 5| Step: 3
Training loss: 3.1968345642089844
Validation loss: 2.93380045634444

Epoch: 5| Step: 4
Training loss: 2.9967217445373535
Validation loss: 2.932892181540048

Epoch: 5| Step: 5
Training loss: 3.3221678733825684
Validation loss: 2.9307265896951

Epoch: 5| Step: 6
Training loss: 3.1936824321746826
Validation loss: 2.93127457557186

Epoch: 5| Step: 7
Training loss: 3.0373458862304688
Validation loss: 2.93034617875212

Epoch: 5| Step: 8
Training loss: 2.8966569900512695
Validation loss: 2.9297938321226384

Epoch: 5| Step: 9
Training loss: 2.62811017036438
Validation loss: 2.9294890537056872

Epoch: 5| Step: 10
Training loss: 2.7942705154418945
Validation loss: 2.9294452615963515

Epoch: 41| Step: 0
Training loss: 3.06809401512146
Validation loss: 2.9281922540357037

Epoch: 5| Step: 1
Training loss: 2.6243367195129395
Validation loss: 2.931081002758395

Epoch: 5| Step: 2
Training loss: 2.3166134357452393
Validation loss: 2.9362820912432928

Epoch: 5| Step: 3
Training loss: 3.1631171703338623
Validation loss: 2.92652734633415

Epoch: 5| Step: 4
Training loss: 2.04124116897583
Validation loss: 2.925419989452567

Epoch: 5| Step: 5
Training loss: 4.056122303009033
Validation loss: 2.9246383764410533

Epoch: 5| Step: 6
Training loss: 3.585379123687744
Validation loss: 2.9254974601089314

Epoch: 5| Step: 7
Training loss: 3.238865613937378
Validation loss: 2.9269997483940533

Epoch: 5| Step: 8
Training loss: 2.9204890727996826
Validation loss: 2.926160486795569

Epoch: 5| Step: 9
Training loss: 2.727539539337158
Validation loss: 2.926010803509784

Epoch: 5| Step: 10
Training loss: 3.531397819519043
Validation loss: 2.9264050683667584

Epoch: 42| Step: 0
Training loss: 3.2990975379943848
Validation loss: 2.9248648484547934

Epoch: 5| Step: 1
Training loss: 2.930899143218994
Validation loss: 2.9256781044826714

Epoch: 5| Step: 2
Training loss: 2.7253284454345703
Validation loss: 2.9239465703246412

Epoch: 5| Step: 3
Training loss: 3.2773890495300293
Validation loss: 2.9222504349165064

Epoch: 5| Step: 4
Training loss: 3.6235122680664062
Validation loss: 2.9212479745188067

Epoch: 5| Step: 5
Training loss: 2.627922296524048
Validation loss: 2.9202668384839128

Epoch: 5| Step: 6
Training loss: 2.279791831970215
Validation loss: 2.919148342583769

Epoch: 5| Step: 7
Training loss: 3.265115737915039
Validation loss: 2.919711559049545

Epoch: 5| Step: 8
Training loss: 2.641059637069702
Validation loss: 2.9201462781557472

Epoch: 5| Step: 9
Training loss: 3.097153902053833
Validation loss: 2.9190667880478727

Epoch: 5| Step: 10
Training loss: 3.4547505378723145
Validation loss: 2.918785341324345

Epoch: 43| Step: 0
Training loss: 2.5071427822113037
Validation loss: 2.9169403481227096

Epoch: 5| Step: 1
Training loss: 3.0252952575683594
Validation loss: 2.915829248325799

Epoch: 5| Step: 2
Training loss: 2.6988258361816406
Validation loss: 2.915605891135431

Epoch: 5| Step: 3
Training loss: 2.110264539718628
Validation loss: 2.914515003081291

Epoch: 5| Step: 4
Training loss: 2.3282320499420166
Validation loss: 2.91523245329498

Epoch: 5| Step: 5
Training loss: 3.708911180496216
Validation loss: 2.9140216330046296

Epoch: 5| Step: 6
Training loss: 3.71186900138855
Validation loss: 2.918543064466087

Epoch: 5| Step: 7
Training loss: 3.1014270782470703
Validation loss: 2.920613396552301

Epoch: 5| Step: 8
Training loss: 3.3393619060516357
Validation loss: 2.921835655807167

Epoch: 5| Step: 9
Training loss: 3.3824660778045654
Validation loss: 2.919328743411649

Epoch: 5| Step: 10
Training loss: 3.199404239654541
Validation loss: 2.935927785852904

Epoch: 44| Step: 0
Training loss: 3.1334424018859863
Validation loss: 3.019084798392429

Epoch: 5| Step: 1
Training loss: 3.8585917949676514
Validation loss: 2.9893545668612242

Epoch: 5| Step: 2
Training loss: 2.6475284099578857
Validation loss: 2.9422343084889073

Epoch: 5| Step: 3
Training loss: 2.6595592498779297
Validation loss: 2.910131175030944

Epoch: 5| Step: 4
Training loss: 2.9888617992401123
Validation loss: 2.911161394529445

Epoch: 5| Step: 5
Training loss: 3.054544448852539
Validation loss: 2.9152171150330575

Epoch: 5| Step: 6
Training loss: 2.587026596069336
Validation loss: 2.9243845631999354

Epoch: 5| Step: 7
Training loss: 3.3385238647460938
Validation loss: 2.938970337631882

Epoch: 5| Step: 8
Training loss: 2.793003559112549
Validation loss: 2.934304542438958

Epoch: 5| Step: 9
Training loss: 3.668285369873047
Validation loss: 2.9264128336342434

Epoch: 5| Step: 10
Training loss: 2.5348000526428223
Validation loss: 2.923565151870892

Epoch: 45| Step: 0
Training loss: 2.1321868896484375
Validation loss: 2.9242531509809595

Epoch: 5| Step: 1
Training loss: 2.7119979858398438
Validation loss: 2.923218542529691

Epoch: 5| Step: 2
Training loss: 2.916825771331787
Validation loss: 2.9231331168964343

Epoch: 5| Step: 3
Training loss: 3.403186082839966
Validation loss: 2.927928909178703

Epoch: 5| Step: 4
Training loss: 3.532442092895508
Validation loss: 2.927443773515763

Epoch: 5| Step: 5
Training loss: 3.2367477416992188
Validation loss: 2.9235022119296494

Epoch: 5| Step: 6
Training loss: 3.0259501934051514
Validation loss: 2.922388369037259

Epoch: 5| Step: 7
Training loss: 2.8080942630767822
Validation loss: 2.9192143255664456

Epoch: 5| Step: 8
Training loss: 2.8023829460144043
Validation loss: 2.915640607956917

Epoch: 5| Step: 9
Training loss: 3.3946475982666016
Validation loss: 2.918236901683192

Epoch: 5| Step: 10
Training loss: 3.209517002105713
Validation loss: 2.916422454259729

Epoch: 46| Step: 0
Training loss: 2.6574959754943848
Validation loss: 2.908877275323355

Epoch: 5| Step: 1
Training loss: 2.781205415725708
Validation loss: 2.907577891503611

Epoch: 5| Step: 2
Training loss: 3.1007180213928223
Validation loss: 2.9097477877011864

Epoch: 5| Step: 3
Training loss: 2.8640894889831543
Validation loss: 2.911059879487561

Epoch: 5| Step: 4
Training loss: 2.948577880859375
Validation loss: 2.910475492477417

Epoch: 5| Step: 5
Training loss: 3.4688472747802734
Validation loss: 2.9047390055912796

Epoch: 5| Step: 6
Training loss: 3.542558193206787
Validation loss: 2.903951193696709

Epoch: 5| Step: 7
Training loss: 2.572317123413086
Validation loss: 2.90209226710822

Epoch: 5| Step: 8
Training loss: 2.989426374435425
Validation loss: 2.8993087301972094

Epoch: 5| Step: 9
Training loss: 3.475848436355591
Validation loss: 2.9004086473936677

Epoch: 5| Step: 10
Training loss: 2.570068836212158
Validation loss: 2.89937787671243

Epoch: 47| Step: 0
Training loss: 3.5591087341308594
Validation loss: 2.8990883109390095

Epoch: 5| Step: 1
Training loss: 2.4184181690216064
Validation loss: 2.8969528444351687

Epoch: 5| Step: 2
Training loss: 2.75125789642334
Validation loss: 2.896643446337792

Epoch: 5| Step: 3
Training loss: 3.100263833999634
Validation loss: 2.8954668967954573

Epoch: 5| Step: 4
Training loss: 2.5249485969543457
Validation loss: 2.8960007749578005

Epoch: 5| Step: 5
Training loss: 2.791951894760132
Validation loss: 2.8946499260522986

Epoch: 5| Step: 6
Training loss: 3.056971549987793
Validation loss: 2.894054756369642

Epoch: 5| Step: 7
Training loss: 3.3024020195007324
Validation loss: 2.893396972328104

Epoch: 5| Step: 8
Training loss: 2.126277446746826
Validation loss: 2.8928838058184554

Epoch: 5| Step: 9
Training loss: 3.446784257888794
Validation loss: 2.892001759621405

Epoch: 5| Step: 10
Training loss: 4.012635231018066
Validation loss: 2.890764605614447

Epoch: 48| Step: 0
Training loss: 3.8769328594207764
Validation loss: 2.891260254767633

Epoch: 5| Step: 1
Training loss: 2.488051414489746
Validation loss: 2.8905664977206977

Epoch: 5| Step: 2
Training loss: 2.5954363346099854
Validation loss: 2.8874422709147134

Epoch: 5| Step: 3
Training loss: 2.467653751373291
Validation loss: 2.8885350945175334

Epoch: 5| Step: 4
Training loss: 3.7434897422790527
Validation loss: 2.8874558479555192

Epoch: 5| Step: 5
Training loss: 3.2922394275665283
Validation loss: 2.8861198732929845

Epoch: 5| Step: 6
Training loss: 2.827906847000122
Validation loss: 2.885021527608236

Epoch: 5| Step: 7
Training loss: 2.8206355571746826
Validation loss: 2.8851890769056094

Epoch: 5| Step: 8
Training loss: 3.110943555831909
Validation loss: 2.8854775480044785

Epoch: 5| Step: 9
Training loss: 2.3446993827819824
Validation loss: 2.8860063783584105

Epoch: 5| Step: 10
Training loss: 3.3733198642730713
Validation loss: 2.8841620927215903

Epoch: 49| Step: 0
Training loss: 3.0000252723693848
Validation loss: 2.883195374601631

Epoch: 5| Step: 1
Training loss: 3.721524715423584
Validation loss: 2.8809108195766324

Epoch: 5| Step: 2
Training loss: 3.239278793334961
Validation loss: 2.882282651880736

Epoch: 5| Step: 3
Training loss: 2.9977762699127197
Validation loss: 2.8834149427311395

Epoch: 5| Step: 4
Training loss: 3.4540791511535645
Validation loss: 2.8807241121927896

Epoch: 5| Step: 5
Training loss: 2.402416706085205
Validation loss: 2.8826359189966673

Epoch: 5| Step: 6
Training loss: 3.012589931488037
Validation loss: 2.880216985620478

Epoch: 5| Step: 7
Training loss: 2.6139707565307617
Validation loss: 2.880319692755258

Epoch: 5| Step: 8
Training loss: 2.8609955310821533
Validation loss: 2.8784514883513093

Epoch: 5| Step: 9
Training loss: 3.251256227493286
Validation loss: 2.887118693320982

Epoch: 5| Step: 10
Training loss: 2.2027535438537598
Validation loss: 2.8790706716557986

Epoch: 50| Step: 0
Training loss: 2.607112169265747
Validation loss: 2.8786141821133193

Epoch: 5| Step: 1
Training loss: 3.3621277809143066
Validation loss: 2.8767549196879068

Epoch: 5| Step: 2
Training loss: 2.9193034172058105
Validation loss: 2.876698229902534

Epoch: 5| Step: 3
Training loss: 2.9548544883728027
Validation loss: 2.880245970141503

Epoch: 5| Step: 4
Training loss: 3.3265366554260254
Validation loss: 2.8797899676907446

Epoch: 5| Step: 5
Training loss: 3.231222629547119
Validation loss: 2.8868062393639677

Epoch: 5| Step: 6
Training loss: 3.260441303253174
Validation loss: 2.8836438194397958

Epoch: 5| Step: 7
Training loss: 2.6005020141601562
Validation loss: 2.8833226798683085

Epoch: 5| Step: 8
Training loss: 2.574625015258789
Validation loss: 2.8781901636431293

Epoch: 5| Step: 9
Training loss: 3.003075361251831
Validation loss: 2.8771064281463623

Epoch: 5| Step: 10
Training loss: 2.9755539894104004
Validation loss: 2.8741555880474787

Epoch: 51| Step: 0
Training loss: 3.2425389289855957
Validation loss: 2.878223239734609

Epoch: 5| Step: 1
Training loss: 2.588479995727539
Validation loss: 2.875388612029373

Epoch: 5| Step: 2
Training loss: 2.8035426139831543
Validation loss: 2.8744696852981404

Epoch: 5| Step: 3
Training loss: 4.042397975921631
Validation loss: 2.875516729970132

Epoch: 5| Step: 4
Training loss: 2.289414167404175
Validation loss: 2.8726947410132295

Epoch: 5| Step: 5
Training loss: 2.7990212440490723
Validation loss: 2.8782736768004713

Epoch: 5| Step: 6
Training loss: 2.930495023727417
Validation loss: 2.880242475899317

Epoch: 5| Step: 7
Training loss: 2.6261043548583984
Validation loss: 2.8784985747388614

Epoch: 5| Step: 8
Training loss: 3.9877724647521973
Validation loss: 2.881595665408719

Epoch: 5| Step: 9
Training loss: 2.307871103286743
Validation loss: 2.877161920711558

Epoch: 5| Step: 10
Training loss: 3.1568219661712646
Validation loss: 2.8712862640298824

Epoch: 52| Step: 0
Training loss: 2.4487509727478027
Validation loss: 2.867262960762106

Epoch: 5| Step: 1
Training loss: 3.5674312114715576
Validation loss: 2.866109186603177

Epoch: 5| Step: 2
Training loss: 3.0590145587921143
Validation loss: 2.8667596514507006

Epoch: 5| Step: 3
Training loss: 3.3740906715393066
Validation loss: 2.8658319647594164

Epoch: 5| Step: 4
Training loss: 2.9996910095214844
Validation loss: 2.8675795908897155

Epoch: 5| Step: 5
Training loss: 3.2447891235351562
Validation loss: 2.8648494161585325

Epoch: 5| Step: 6
Training loss: 2.630908489227295
Validation loss: 2.8660017187877367

Epoch: 5| Step: 7
Training loss: 2.861950159072876
Validation loss: 2.862373541760188

Epoch: 5| Step: 8
Training loss: 3.0924787521362305
Validation loss: 2.8630389116143666

Epoch: 5| Step: 9
Training loss: 2.9280436038970947
Validation loss: 2.86384678399691

Epoch: 5| Step: 10
Training loss: 2.443441152572632
Validation loss: 2.8616076669385357

Epoch: 53| Step: 0
Training loss: 3.1138031482696533
Validation loss: 2.860950782734861

Epoch: 5| Step: 1
Training loss: 3.2597146034240723
Validation loss: 2.8582342183718117

Epoch: 5| Step: 2
Training loss: 3.557889223098755
Validation loss: 2.859127449732955

Epoch: 5| Step: 3
Training loss: 3.4387543201446533
Validation loss: 2.857900086269584

Epoch: 5| Step: 4
Training loss: 3.1343021392822266
Validation loss: 2.8556011133296515

Epoch: 5| Step: 5
Training loss: 2.3978171348571777
Validation loss: 2.856672179314398

Epoch: 5| Step: 6
Training loss: 2.6144187450408936
Validation loss: 2.8563173740140853

Epoch: 5| Step: 7
Training loss: 2.4625234603881836
Validation loss: 2.8610566149475756

Epoch: 5| Step: 8
Training loss: 3.0480151176452637
Validation loss: 2.874997159486176

Epoch: 5| Step: 9
Training loss: 2.626706600189209
Validation loss: 2.8526748585444626

Epoch: 5| Step: 10
Training loss: 3.081357955932617
Validation loss: 2.8575654875847603

Epoch: 54| Step: 0
Training loss: 3.0465807914733887
Validation loss: 2.8530787524356636

Epoch: 5| Step: 1
Training loss: 2.9304356575012207
Validation loss: 2.8540746422224146

Epoch: 5| Step: 2
Training loss: 2.925382137298584
Validation loss: 2.8568801008244997

Epoch: 5| Step: 3
Training loss: 3.0568816661834717
Validation loss: 2.858762005324005

Epoch: 5| Step: 4
Training loss: 2.6532607078552246
Validation loss: 2.854488811185283

Epoch: 5| Step: 5
Training loss: 2.8888635635375977
Validation loss: 2.8524030690552085

Epoch: 5| Step: 6
Training loss: 3.424237012863159
Validation loss: 2.8518722646979877

Epoch: 5| Step: 7
Training loss: 2.9502036571502686
Validation loss: 2.8579796693658315

Epoch: 5| Step: 8
Training loss: 3.281728744506836
Validation loss: 2.8537564559649398

Epoch: 5| Step: 9
Training loss: 2.7598705291748047
Validation loss: 2.85007732401612

Epoch: 5| Step: 10
Training loss: 2.630490779876709
Validation loss: 2.848502717992311

Epoch: 55| Step: 0
Training loss: 2.9292454719543457
Validation loss: 2.850744883219401

Epoch: 5| Step: 1
Training loss: 2.597236394882202
Validation loss: 2.846025400264289

Epoch: 5| Step: 2
Training loss: 2.716992139816284
Validation loss: 2.845842376832039

Epoch: 5| Step: 3
Training loss: 3.1405866146087646
Validation loss: 2.8413926478355163

Epoch: 5| Step: 4
Training loss: 2.7277579307556152
Validation loss: 2.839078608379569

Epoch: 5| Step: 5
Training loss: 2.659757137298584
Validation loss: 2.8421019687447497

Epoch: 5| Step: 6
Training loss: 3.060082197189331
Validation loss: 2.8376304513664654

Epoch: 5| Step: 7
Training loss: 3.649801254272461
Validation loss: 2.8389759191902737

Epoch: 5| Step: 8
Training loss: 2.9437267780303955
Validation loss: 2.8390003173582015

Epoch: 5| Step: 9
Training loss: 3.655569553375244
Validation loss: 2.8393323075386787

Epoch: 5| Step: 10
Training loss: 2.3408632278442383
Validation loss: 2.8388247823202484

Epoch: 56| Step: 0
Training loss: 3.1277174949645996
Validation loss: 2.8419804649968303

Epoch: 5| Step: 1
Training loss: 3.4153428077697754
Validation loss: 2.8441598415374756

Epoch: 5| Step: 2
Training loss: 3.0738415718078613
Validation loss: 2.84205691019694

Epoch: 5| Step: 3
Training loss: 2.733621835708618
Validation loss: 2.832808397149527

Epoch: 5| Step: 4
Training loss: 3.3330955505371094
Validation loss: 2.8336256216931086

Epoch: 5| Step: 5
Training loss: 2.663400173187256
Validation loss: 2.832005344411378

Epoch: 5| Step: 6
Training loss: 2.634253740310669
Validation loss: 2.8340752560605287

Epoch: 5| Step: 7
Training loss: 3.027360677719116
Validation loss: 2.832724740428309

Epoch: 5| Step: 8
Training loss: 2.9122939109802246
Validation loss: 2.827897943476195

Epoch: 5| Step: 9
Training loss: 2.832761287689209
Validation loss: 2.83376214068423

Epoch: 5| Step: 10
Training loss: 2.6740810871124268
Validation loss: 2.843225561162477

Epoch: 57| Step: 0
Training loss: 2.6154580116271973
Validation loss: 2.8406909947754233

Epoch: 5| Step: 1
Training loss: 2.980930805206299
Validation loss: 2.837986356468611

Epoch: 5| Step: 2
Training loss: 2.566373348236084
Validation loss: 2.8361122249275126

Epoch: 5| Step: 3
Training loss: 2.789954900741577
Validation loss: 2.8330925254411596

Epoch: 5| Step: 4
Training loss: 2.581644058227539
Validation loss: 2.830517533004925

Epoch: 5| Step: 5
Training loss: 2.873971462249756
Validation loss: 2.8263790889452864

Epoch: 5| Step: 6
Training loss: 3.149876832962036
Validation loss: 2.827708059741605

Epoch: 5| Step: 7
Training loss: 2.9663758277893066
Validation loss: 2.8290828351051576

Epoch: 5| Step: 8
Training loss: 3.1200289726257324
Validation loss: 2.8249189199939853

Epoch: 5| Step: 9
Training loss: 3.5366528034210205
Validation loss: 2.827683171918315

Epoch: 5| Step: 10
Training loss: 3.3076164722442627
Validation loss: 2.8260785174626175

Epoch: 58| Step: 0
Training loss: 3.47705078125
Validation loss: 2.8279225159716863

Epoch: 5| Step: 1
Training loss: 3.0386297702789307
Validation loss: 2.8264200225953133

Epoch: 5| Step: 2
Training loss: 3.264324188232422
Validation loss: 2.8331580392776

Epoch: 5| Step: 3
Training loss: 3.4460277557373047
Validation loss: 2.8307394289201304

Epoch: 5| Step: 4
Training loss: 3.0457265377044678
Validation loss: 2.8272686748094458

Epoch: 5| Step: 5
Training loss: 2.4521846771240234
Validation loss: 2.82413899770347

Epoch: 5| Step: 6
Training loss: 2.2479825019836426
Validation loss: 2.8260363763378513

Epoch: 5| Step: 7
Training loss: 3.1484010219573975
Validation loss: 2.8267136184118127

Epoch: 5| Step: 8
Training loss: 2.6672120094299316
Validation loss: 2.829066812351186

Epoch: 5| Step: 9
Training loss: 2.932603120803833
Validation loss: 2.8323158500015095

Epoch: 5| Step: 10
Training loss: 2.629192590713501
Validation loss: 2.834216945914812

Epoch: 59| Step: 0
Training loss: 2.6636691093444824
Validation loss: 2.839303324299474

Epoch: 5| Step: 1
Training loss: 2.9505395889282227
Validation loss: 2.8543846658481065

Epoch: 5| Step: 2
Training loss: 3.671342372894287
Validation loss: 2.84330677986145

Epoch: 5| Step: 3
Training loss: 3.826641082763672
Validation loss: 2.8266965343106176

Epoch: 5| Step: 4
Training loss: 3.0341930389404297
Validation loss: 2.840879968417588

Epoch: 5| Step: 5
Training loss: 3.8498337268829346
Validation loss: 2.8990842603868052

Epoch: 5| Step: 6
Training loss: 2.5975136756896973
Validation loss: 2.8702194767613567

Epoch: 5| Step: 7
Training loss: 3.2314391136169434
Validation loss: 2.8255034133952153

Epoch: 5| Step: 8
Training loss: 2.1478748321533203
Validation loss: 2.8214470699269283

Epoch: 5| Step: 9
Training loss: 2.0098869800567627
Validation loss: 2.822558759361185

Epoch: 5| Step: 10
Training loss: 2.455906391143799
Validation loss: 2.834940187392696

Epoch: 60| Step: 0
Training loss: 2.971381664276123
Validation loss: 2.849174996858002

Epoch: 5| Step: 1
Training loss: 2.5565576553344727
Validation loss: 2.8614949103324645

Epoch: 5| Step: 2
Training loss: 2.9329159259796143
Validation loss: 2.865292856770177

Epoch: 5| Step: 3
Training loss: 3.297337293624878
Validation loss: 2.8544715963384157

Epoch: 5| Step: 4
Training loss: 2.936269998550415
Validation loss: 2.8310185837489303

Epoch: 5| Step: 5
Training loss: 2.998464822769165
Validation loss: 2.8249515769302205

Epoch: 5| Step: 6
Training loss: 3.39849853515625
Validation loss: 2.8249468265041227

Epoch: 5| Step: 7
Training loss: 2.9729809761047363
Validation loss: 2.8288072206640757

Epoch: 5| Step: 8
Training loss: 2.517296314239502
Validation loss: 2.8495753247250795

Epoch: 5| Step: 9
Training loss: 2.850191354751587
Validation loss: 2.8539137430088495

Epoch: 5| Step: 10
Training loss: 3.1570494174957275
Validation loss: 2.834586202457387

Epoch: 61| Step: 0
Training loss: 2.637359142303467
Validation loss: 2.8240733864486858

Epoch: 5| Step: 1
Training loss: 3.374122142791748
Validation loss: 2.821612770839404

Epoch: 5| Step: 2
Training loss: 2.5024943351745605
Validation loss: 2.8230613995623846

Epoch: 5| Step: 3
Training loss: 3.292701005935669
Validation loss: 2.8200495294345322

Epoch: 5| Step: 4
Training loss: 3.3199946880340576
Validation loss: 2.818825808904504

Epoch: 5| Step: 5
Training loss: 2.6702868938446045
Validation loss: 2.8200622335557015

Epoch: 5| Step: 6
Training loss: 3.165592670440674
Validation loss: 2.817410158854659

Epoch: 5| Step: 7
Training loss: 2.95198130607605
Validation loss: 2.81611535626073

Epoch: 5| Step: 8
Training loss: 2.942866563796997
Validation loss: 2.8159267774192234

Epoch: 5| Step: 9
Training loss: 2.9735636711120605
Validation loss: 2.812046266371204

Epoch: 5| Step: 10
Training loss: 2.4928817749023438
Validation loss: 2.8156662756396877

Epoch: 62| Step: 0
Training loss: 2.2649409770965576
Validation loss: 2.814984703576693

Epoch: 5| Step: 1
Training loss: 3.5225112438201904
Validation loss: 2.8138313344729844

Epoch: 5| Step: 2
Training loss: 2.3682751655578613
Validation loss: 2.8136026884919856

Epoch: 5| Step: 3
Training loss: 3.210448741912842
Validation loss: 2.8143564039661038

Epoch: 5| Step: 4
Training loss: 3.7168586254119873
Validation loss: 2.8173635595588276

Epoch: 5| Step: 5
Training loss: 2.9897589683532715
Validation loss: 2.8213489132542766

Epoch: 5| Step: 6
Training loss: 2.733391046524048
Validation loss: 2.8214321469747894

Epoch: 5| Step: 7
Training loss: 2.7551217079162598
Validation loss: 2.814132869884532

Epoch: 5| Step: 8
Training loss: 2.995521306991577
Validation loss: 2.814386354979648

Epoch: 5| Step: 9
Training loss: 2.957998514175415
Validation loss: 2.814062344130649

Epoch: 5| Step: 10
Training loss: 2.7795748710632324
Validation loss: 2.81425138186383

Epoch: 63| Step: 0
Training loss: 3.000243663787842
Validation loss: 2.814448141282605

Epoch: 5| Step: 1
Training loss: 2.7604966163635254
Validation loss: 2.812942612555719

Epoch: 5| Step: 2
Training loss: 2.621607542037964
Validation loss: 2.8107667969119166

Epoch: 5| Step: 3
Training loss: 2.6753668785095215
Validation loss: 2.813467735885292

Epoch: 5| Step: 4
Training loss: 2.6805219650268555
Validation loss: 2.8104877651378675

Epoch: 5| Step: 5
Training loss: 3.225581407546997
Validation loss: 2.809244509666197

Epoch: 5| Step: 6
Training loss: 3.307631015777588
Validation loss: 2.813849933685795

Epoch: 5| Step: 7
Training loss: 2.6022629737854004
Validation loss: 2.81051903898998

Epoch: 5| Step: 8
Training loss: 3.0463266372680664
Validation loss: 2.8105266581299486

Epoch: 5| Step: 9
Training loss: 3.28627347946167
Validation loss: 2.811204674423382

Epoch: 5| Step: 10
Training loss: 3.1394832134246826
Validation loss: 2.8085985722080355

Epoch: 64| Step: 0
Training loss: 3.7579479217529297
Validation loss: 2.808359771646479

Epoch: 5| Step: 1
Training loss: 2.6645140647888184
Validation loss: 2.807451284059914

Epoch: 5| Step: 2
Training loss: 3.228177309036255
Validation loss: 2.8077304850342455

Epoch: 5| Step: 3
Training loss: 2.5441431999206543
Validation loss: 2.811435450789749

Epoch: 5| Step: 4
Training loss: 2.9030847549438477
Validation loss: 2.8086098394086285

Epoch: 5| Step: 5
Training loss: 3.4164955615997314
Validation loss: 2.8088816494070072

Epoch: 5| Step: 6
Training loss: 2.724224090576172
Validation loss: 2.8070930665539158

Epoch: 5| Step: 7
Training loss: 2.828569173812866
Validation loss: 2.8082324022887857

Epoch: 5| Step: 8
Training loss: 1.9512611627578735
Validation loss: 2.808516856162779

Epoch: 5| Step: 9
Training loss: 2.918269634246826
Validation loss: 2.8056052192564933

Epoch: 5| Step: 10
Training loss: 3.383629083633423
Validation loss: 2.8090367342836116

Epoch: 65| Step: 0
Training loss: 2.9167609214782715
Validation loss: 2.8076414549222557

Epoch: 5| Step: 1
Training loss: 3.337921142578125
Validation loss: 2.8198007511836227

Epoch: 5| Step: 2
Training loss: 2.4406769275665283
Validation loss: 2.807911842100082

Epoch: 5| Step: 3
Training loss: 2.800354480743408
Validation loss: 2.8102404507257606

Epoch: 5| Step: 4
Training loss: 3.059309482574463
Validation loss: 2.805677116558116

Epoch: 5| Step: 5
Training loss: 2.557805299758911
Validation loss: 2.8045758790867303

Epoch: 5| Step: 6
Training loss: 2.904616355895996
Validation loss: 2.804401320795859

Epoch: 5| Step: 7
Training loss: 3.436298370361328
Validation loss: 2.8056830206224994

Epoch: 5| Step: 8
Training loss: 2.315812826156616
Validation loss: 2.8049663677010486

Epoch: 5| Step: 9
Training loss: 3.4538826942443848
Validation loss: 2.807801454297958

Epoch: 5| Step: 10
Training loss: 3.0217604637145996
Validation loss: 2.80707872298456

Epoch: 66| Step: 0
Training loss: 3.2307944297790527
Validation loss: 2.807111901621665

Epoch: 5| Step: 1
Training loss: 2.6284842491149902
Validation loss: 2.806991884785314

Epoch: 5| Step: 2
Training loss: 3.475890636444092
Validation loss: 2.80634734963858

Epoch: 5| Step: 3
Training loss: 3.1117630004882812
Validation loss: 2.8057476576938423

Epoch: 5| Step: 4
Training loss: 2.2989795207977295
Validation loss: 2.808161279206635

Epoch: 5| Step: 5
Training loss: 2.8650619983673096
Validation loss: 2.807001618928807

Epoch: 5| Step: 6
Training loss: 2.9976019859313965
Validation loss: 2.8068610545127624

Epoch: 5| Step: 7
Training loss: 3.153646945953369
Validation loss: 2.8071611286491476

Epoch: 5| Step: 8
Training loss: 2.8102493286132812
Validation loss: 2.8031986144281205

Epoch: 5| Step: 9
Training loss: 2.8811838626861572
Validation loss: 2.8021742118302213

Epoch: 5| Step: 10
Training loss: 2.7566633224487305
Validation loss: 2.807084639867147

Epoch: 67| Step: 0
Training loss: 2.927272081375122
Validation loss: 2.807739967940956

Epoch: 5| Step: 1
Training loss: 2.5885913372039795
Validation loss: 2.8038979730298443

Epoch: 5| Step: 2
Training loss: 3.4609451293945312
Validation loss: 2.8031901159594135

Epoch: 5| Step: 3
Training loss: 3.440044403076172
Validation loss: 2.8060410432918097

Epoch: 5| Step: 4
Training loss: 2.351548671722412
Validation loss: 2.8048971135129213

Epoch: 5| Step: 5
Training loss: 3.4817986488342285
Validation loss: 2.8050250314897105

Epoch: 5| Step: 6
Training loss: 3.395425796508789
Validation loss: 2.8045558262896795

Epoch: 5| Step: 7
Training loss: 2.7697834968566895
Validation loss: 2.8092211343908824

Epoch: 5| Step: 8
Training loss: 2.692857265472412
Validation loss: 2.8239420126843195

Epoch: 5| Step: 9
Training loss: 2.3388216495513916
Validation loss: 2.8362467083879697

Epoch: 5| Step: 10
Training loss: 2.807645797729492
Validation loss: 2.8140604008910475

Epoch: 68| Step: 0
Training loss: 2.60748553276062
Validation loss: 2.8049809778890302

Epoch: 5| Step: 1
Training loss: 2.4532477855682373
Validation loss: 2.8018880121169554

Epoch: 5| Step: 2
Training loss: 2.929445266723633
Validation loss: 2.7987725375801005

Epoch: 5| Step: 3
Training loss: 3.347594738006592
Validation loss: 2.7987335112787064

Epoch: 5| Step: 4
Training loss: 2.951847553253174
Validation loss: 2.7982156943249445

Epoch: 5| Step: 5
Training loss: 3.5845470428466797
Validation loss: 2.7995971248995875

Epoch: 5| Step: 6
Training loss: 3.383275270462036
Validation loss: 2.795921374392766

Epoch: 5| Step: 7
Training loss: 2.4888453483581543
Validation loss: 2.799865404764811

Epoch: 5| Step: 8
Training loss: 2.888608455657959
Validation loss: 2.7978479887849543

Epoch: 5| Step: 9
Training loss: 2.603680372238159
Validation loss: 2.7946158224536526

Epoch: 5| Step: 10
Training loss: 2.935880184173584
Validation loss: 2.7936769454709944

Epoch: 69| Step: 0
Training loss: 3.176088809967041
Validation loss: 2.7959130220515753

Epoch: 5| Step: 1
Training loss: 3.0592846870422363
Validation loss: 2.7967639328331075

Epoch: 5| Step: 2
Training loss: 2.6991562843322754
Validation loss: 2.794614161214521

Epoch: 5| Step: 3
Training loss: 3.1954524517059326
Validation loss: 2.7982831719101116

Epoch: 5| Step: 4
Training loss: 2.6325364112854004
Validation loss: 2.800217851515739

Epoch: 5| Step: 5
Training loss: 3.223712921142578
Validation loss: 2.7987865427488923

Epoch: 5| Step: 6
Training loss: 2.1490399837493896
Validation loss: 2.799445649628998

Epoch: 5| Step: 7
Training loss: 3.444680690765381
Validation loss: 2.801436201218636

Epoch: 5| Step: 8
Training loss: 2.9654343128204346
Validation loss: 2.7997950225748043

Epoch: 5| Step: 9
Training loss: 2.672261953353882
Validation loss: 2.798698092019686

Epoch: 5| Step: 10
Training loss: 2.989626884460449
Validation loss: 2.795665964003532

Epoch: 70| Step: 0
Training loss: 3.025993824005127
Validation loss: 2.7943846051410963

Epoch: 5| Step: 1
Training loss: 2.695972442626953
Validation loss: 2.7960822274607997

Epoch: 5| Step: 2
Training loss: 2.245771646499634
Validation loss: 2.7932091195096254

Epoch: 5| Step: 3
Training loss: 2.9128403663635254
Validation loss: 2.798645216931579

Epoch: 5| Step: 4
Training loss: 3.194674015045166
Validation loss: 2.7964096018063125

Epoch: 5| Step: 5
Training loss: 2.811140775680542
Validation loss: 2.794245896800872

Epoch: 5| Step: 6
Training loss: 2.637234926223755
Validation loss: 2.795351225842712

Epoch: 5| Step: 7
Training loss: 2.981659412384033
Validation loss: 2.7936610560263357

Epoch: 5| Step: 8
Training loss: 3.1359262466430664
Validation loss: 2.7939160998149584

Epoch: 5| Step: 9
Training loss: 3.150139570236206
Validation loss: 2.790341613113239

Epoch: 5| Step: 10
Training loss: 3.4309139251708984
Validation loss: 2.791217319426998

Epoch: 71| Step: 0
Training loss: 2.9232001304626465
Validation loss: 2.791992264409219

Epoch: 5| Step: 1
Training loss: 3.7803146839141846
Validation loss: 2.7939691825579573

Epoch: 5| Step: 2
Training loss: 2.5522031784057617
Validation loss: 2.7922489489278486

Epoch: 5| Step: 3
Training loss: 2.7020938396453857
Validation loss: 2.794963777706187

Epoch: 5| Step: 4
Training loss: 2.9178833961486816
Validation loss: 2.791166990034042

Epoch: 5| Step: 5
Training loss: 3.343294858932495
Validation loss: 2.7876735938492643

Epoch: 5| Step: 6
Training loss: 3.0107414722442627
Validation loss: 2.7899825521694717

Epoch: 5| Step: 7
Training loss: 3.117642879486084
Validation loss: 2.7934272520003782

Epoch: 5| Step: 8
Training loss: 2.9328980445861816
Validation loss: 2.792608763581963

Epoch: 5| Step: 9
Training loss: 2.1831040382385254
Validation loss: 2.793426231671405

Epoch: 5| Step: 10
Training loss: 2.6153311729431152
Validation loss: 2.789356267580422

Epoch: 72| Step: 0
Training loss: 2.511958599090576
Validation loss: 2.7892124550316924

Epoch: 5| Step: 1
Training loss: 3.368091106414795
Validation loss: 2.78958987164241

Epoch: 5| Step: 2
Training loss: 2.3978636264801025
Validation loss: 2.7884017164989183

Epoch: 5| Step: 3
Training loss: 2.9748916625976562
Validation loss: 2.7890997445711525

Epoch: 5| Step: 4
Training loss: 2.931962013244629
Validation loss: 2.7869167840608986

Epoch: 5| Step: 5
Training loss: 2.822204351425171
Validation loss: 2.789882413802608

Epoch: 5| Step: 6
Training loss: 2.7913119792938232
Validation loss: 2.7923665251783145

Epoch: 5| Step: 7
Training loss: 3.241161346435547
Validation loss: 2.7905901016727572

Epoch: 5| Step: 8
Training loss: 2.897820234298706
Validation loss: 2.7901747329260713

Epoch: 5| Step: 9
Training loss: 2.997645854949951
Validation loss: 2.7910292251135713

Epoch: 5| Step: 10
Training loss: 3.242131471633911
Validation loss: 2.7881269531865276

Epoch: 73| Step: 0
Training loss: 2.110335111618042
Validation loss: 2.7865035354450183

Epoch: 5| Step: 1
Training loss: 3.0842137336730957
Validation loss: 2.7878561122443086

Epoch: 5| Step: 2
Training loss: 3.6159331798553467
Validation loss: 2.787193439340079

Epoch: 5| Step: 3
Training loss: 2.9455783367156982
Validation loss: 2.788733054232854

Epoch: 5| Step: 4
Training loss: 2.7540054321289062
Validation loss: 2.787089750330935

Epoch: 5| Step: 5
Training loss: 3.2541251182556152
Validation loss: 2.789570841737973

Epoch: 5| Step: 6
Training loss: 2.6319313049316406
Validation loss: 2.7901513525234756

Epoch: 5| Step: 7
Training loss: 2.5687694549560547
Validation loss: 2.7897356710126324

Epoch: 5| Step: 8
Training loss: 2.521022081375122
Validation loss: 2.7876380028263217

Epoch: 5| Step: 9
Training loss: 2.681859016418457
Validation loss: 2.787679497913648

Epoch: 5| Step: 10
Training loss: 4.083189964294434
Validation loss: 2.787415199382331

Epoch: 74| Step: 0
Training loss: 3.690530300140381
Validation loss: 2.785861874139437

Epoch: 5| Step: 1
Training loss: 3.2263572216033936
Validation loss: 2.7884452125077606

Epoch: 5| Step: 2
Training loss: 2.3193206787109375
Validation loss: 2.7872925137960785

Epoch: 5| Step: 3
Training loss: 3.2676327228546143
Validation loss: 2.7882381639172955

Epoch: 5| Step: 4
Training loss: 2.198079824447632
Validation loss: 2.787566013233636

Epoch: 5| Step: 5
Training loss: 2.588192939758301
Validation loss: 2.7864420337061726

Epoch: 5| Step: 6
Training loss: 2.8325464725494385
Validation loss: 2.7902908786650626

Epoch: 5| Step: 7
Training loss: 3.2548999786376953
Validation loss: 2.790922613554103

Epoch: 5| Step: 8
Training loss: 2.3478026390075684
Validation loss: 2.80127691453503

Epoch: 5| Step: 9
Training loss: 2.578429937362671
Validation loss: 2.7962178312322146

Epoch: 5| Step: 10
Training loss: 3.861851930618286
Validation loss: 2.802140889629241

Epoch: 75| Step: 0
Training loss: 2.8510990142822266
Validation loss: 2.793543800230949

Epoch: 5| Step: 1
Training loss: 3.107516050338745
Validation loss: 2.790651172719976

Epoch: 5| Step: 2
Training loss: 1.9735997915267944
Validation loss: 2.787012130983414

Epoch: 5| Step: 3
Training loss: 2.9096102714538574
Validation loss: 2.7836058575619935

Epoch: 5| Step: 4
Training loss: 2.8892319202423096
Validation loss: 2.7821068815005723

Epoch: 5| Step: 5
Training loss: 2.6719741821289062
Validation loss: 2.7833639755043933

Epoch: 5| Step: 6
Training loss: 2.7156035900115967
Validation loss: 2.779048001894387

Epoch: 5| Step: 7
Training loss: 3.1898128986358643
Validation loss: 2.779566193139681

Epoch: 5| Step: 8
Training loss: 3.001669406890869
Validation loss: 2.781284257929812

Epoch: 5| Step: 9
Training loss: 3.6106362342834473
Validation loss: 2.781665478983233

Epoch: 5| Step: 10
Training loss: 3.0968472957611084
Validation loss: 2.7813053695104455

Epoch: 76| Step: 0
Training loss: 2.7787063121795654
Validation loss: 2.7845849529389413

Epoch: 5| Step: 1
Training loss: 2.958251714706421
Validation loss: 2.7802686845102618

Epoch: 5| Step: 2
Training loss: 2.524399518966675
Validation loss: 2.77773017268027

Epoch: 5| Step: 3
Training loss: 2.624946117401123
Validation loss: 2.778077966423445

Epoch: 5| Step: 4
Training loss: 2.553978681564331
Validation loss: 2.774345172348843

Epoch: 5| Step: 5
Training loss: 3.22296404838562
Validation loss: 2.7783422726456837

Epoch: 5| Step: 6
Training loss: 4.000916957855225
Validation loss: 2.789333615251767

Epoch: 5| Step: 7
Training loss: 2.42264723777771
Validation loss: 2.7934857606887817

Epoch: 5| Step: 8
Training loss: 2.895644426345825
Validation loss: 2.7946500009106052

Epoch: 5| Step: 9
Training loss: 3.068803071975708
Validation loss: 2.806185701841949

Epoch: 5| Step: 10
Training loss: 2.933072328567505
Validation loss: 2.810958718740812

Epoch: 77| Step: 0
Training loss: 1.9744402170181274
Validation loss: 2.827280277846962

Epoch: 5| Step: 1
Training loss: 3.4413692951202393
Validation loss: 2.8407228787740073

Epoch: 5| Step: 2
Training loss: 2.4956202507019043
Validation loss: 2.8304121391747588

Epoch: 5| Step: 3
Training loss: 2.151953935623169
Validation loss: 2.8159111058840187

Epoch: 5| Step: 4
Training loss: 3.4923911094665527
Validation loss: 2.7997657842533563

Epoch: 5| Step: 5
Training loss: 3.2382760047912598
Validation loss: 2.789608527255315

Epoch: 5| Step: 6
Training loss: 3.3162522315979004
Validation loss: 2.789284611261019

Epoch: 5| Step: 7
Training loss: 2.544130802154541
Validation loss: 2.783174796770978

Epoch: 5| Step: 8
Training loss: 2.7639756202697754
Validation loss: 2.783120355298442

Epoch: 5| Step: 9
Training loss: 4.0390472412109375
Validation loss: 2.785407881582937

Epoch: 5| Step: 10
Training loss: 2.492260694503784
Validation loss: 2.7844635491730063

Epoch: 78| Step: 0
Training loss: 2.614572048187256
Validation loss: 2.7828984593832367

Epoch: 5| Step: 1
Training loss: 3.246366500854492
Validation loss: 2.7791150410970054

Epoch: 5| Step: 2
Training loss: 3.102220058441162
Validation loss: 2.780204180748232

Epoch: 5| Step: 3
Training loss: 2.416337251663208
Validation loss: 2.7840954924142487

Epoch: 5| Step: 4
Training loss: 2.621140241622925
Validation loss: 2.781910498936971

Epoch: 5| Step: 5
Training loss: 3.1755101680755615
Validation loss: 2.78719429046877

Epoch: 5| Step: 6
Training loss: 3.2134017944335938
Validation loss: 2.806201106758528

Epoch: 5| Step: 7
Training loss: 3.2749900817871094
Validation loss: 2.798797563839984

Epoch: 5| Step: 8
Training loss: 2.4579532146453857
Validation loss: 2.7928797660335416

Epoch: 5| Step: 9
Training loss: 3.4999969005584717
Validation loss: 2.789509524581253

Epoch: 5| Step: 10
Training loss: 2.2644476890563965
Validation loss: 2.786789009647985

Epoch: 79| Step: 0
Training loss: 2.2675187587738037
Validation loss: 2.7800051678893385

Epoch: 5| Step: 1
Training loss: 2.8023102283477783
Validation loss: 2.781297417097194

Epoch: 5| Step: 2
Training loss: 3.525285243988037
Validation loss: 2.7861149541793333

Epoch: 5| Step: 3
Training loss: 3.280778408050537
Validation loss: 2.7944551744768695

Epoch: 5| Step: 4
Training loss: 2.4502506256103516
Validation loss: 2.7963269936141146

Epoch: 5| Step: 5
Training loss: 3.334930896759033
Validation loss: 2.7964936840918755

Epoch: 5| Step: 6
Training loss: 3.0436878204345703
Validation loss: 2.7921459751744426

Epoch: 5| Step: 7
Training loss: 2.0270895957946777
Validation loss: 2.786032425459995

Epoch: 5| Step: 8
Training loss: 2.695685863494873
Validation loss: 2.7783046230193107

Epoch: 5| Step: 9
Training loss: 3.2048511505126953
Validation loss: 2.7810233767314623

Epoch: 5| Step: 10
Training loss: 3.3187155723571777
Validation loss: 2.7806898188847367

Epoch: 80| Step: 0
Training loss: 2.753786563873291
Validation loss: 2.787899527498471

Epoch: 5| Step: 1
Training loss: 2.945291519165039
Validation loss: 2.794836249402774

Epoch: 5| Step: 2
Training loss: 2.308229923248291
Validation loss: 2.7953826227495746

Epoch: 5| Step: 3
Training loss: 3.3933281898498535
Validation loss: 2.8060794466285297

Epoch: 5| Step: 4
Training loss: 2.900702714920044
Validation loss: 2.796310829859908

Epoch: 5| Step: 5
Training loss: 2.8864433765411377
Validation loss: 2.795306226258637

Epoch: 5| Step: 6
Training loss: 2.9884538650512695
Validation loss: 2.785946294825564

Epoch: 5| Step: 7
Training loss: 3.475252628326416
Validation loss: 2.7709629407493015

Epoch: 5| Step: 8
Training loss: 2.59260630607605
Validation loss: 2.770664850870768

Epoch: 5| Step: 9
Training loss: 2.7748491764068604
Validation loss: 2.772432896398729

Epoch: 5| Step: 10
Training loss: 2.857367753982544
Validation loss: 2.7771027652166222

Epoch: 81| Step: 0
Training loss: 2.0888099670410156
Validation loss: 2.7728681179784958

Epoch: 5| Step: 1
Training loss: 2.2456445693969727
Validation loss: 2.767121409857145

Epoch: 5| Step: 2
Training loss: 3.6217217445373535
Validation loss: 2.769867317650908

Epoch: 5| Step: 3
Training loss: 2.737189531326294
Validation loss: 2.7718253417681624

Epoch: 5| Step: 4
Training loss: 3.154550075531006
Validation loss: 2.7730608345359884

Epoch: 5| Step: 5
Training loss: 2.6509461402893066
Validation loss: 2.777795151997638

Epoch: 5| Step: 6
Training loss: 3.021172285079956
Validation loss: 2.7759332195405038

Epoch: 5| Step: 7
Training loss: 3.0675606727600098
Validation loss: 2.7764861737528155

Epoch: 5| Step: 8
Training loss: 2.809511423110962
Validation loss: 2.776257432917113

Epoch: 5| Step: 9
Training loss: 3.851762056350708
Validation loss: 2.7794211654252905

Epoch: 5| Step: 10
Training loss: 2.5111289024353027
Validation loss: 2.782067473216723

Epoch: 82| Step: 0
Training loss: 2.911545991897583
Validation loss: 2.7819590619815293

Epoch: 5| Step: 1
Training loss: 3.423574447631836
Validation loss: 2.7846224308013916

Epoch: 5| Step: 2
Training loss: 2.7857186794281006
Validation loss: 2.7885107276260213

Epoch: 5| Step: 3
Training loss: 2.729567289352417
Validation loss: 2.788661459440826

Epoch: 5| Step: 4
Training loss: 1.9358901977539062
Validation loss: 2.785681609184511

Epoch: 5| Step: 5
Training loss: 2.675863742828369
Validation loss: 2.782178371183334

Epoch: 5| Step: 6
Training loss: 3.192512035369873
Validation loss: 2.7820416906828522

Epoch: 5| Step: 7
Training loss: 3.402228593826294
Validation loss: 2.7814685401096138

Epoch: 5| Step: 8
Training loss: 3.0814719200134277
Validation loss: 2.7747844829354236

Epoch: 5| Step: 9
Training loss: 3.0595762729644775
Validation loss: 2.7689047372469338

Epoch: 5| Step: 10
Training loss: 2.5840206146240234
Validation loss: 2.770174023925617

Epoch: 83| Step: 0
Training loss: 2.293215274810791
Validation loss: 2.768682749040665

Epoch: 5| Step: 1
Training loss: 3.5524773597717285
Validation loss: 2.767450089095741

Epoch: 5| Step: 2
Training loss: 2.8583931922912598
Validation loss: 2.764676429892099

Epoch: 5| Step: 3
Training loss: 2.3004653453826904
Validation loss: 2.7694820434816423

Epoch: 5| Step: 4
Training loss: 2.850053071975708
Validation loss: 2.77074852553747

Epoch: 5| Step: 5
Training loss: 2.8405511379241943
Validation loss: 2.767843913006526

Epoch: 5| Step: 6
Training loss: 2.6362805366516113
Validation loss: 2.76715075841514

Epoch: 5| Step: 7
Training loss: 3.6576104164123535
Validation loss: 2.762230875671551

Epoch: 5| Step: 8
Training loss: 3.0690793991088867
Validation loss: 2.7644296846082135

Epoch: 5| Step: 9
Training loss: 3.016730546951294
Validation loss: 2.7615300199036956

Epoch: 5| Step: 10
Training loss: 2.6792733669281006
Validation loss: 2.7616453555322464

Epoch: 84| Step: 0
Training loss: 3.0712883472442627
Validation loss: 2.763514998138592

Epoch: 5| Step: 1
Training loss: 3.6503310203552246
Validation loss: 2.7652228801481185

Epoch: 5| Step: 2
Training loss: 2.227757692337036
Validation loss: 2.7662043597108577

Epoch: 5| Step: 3
Training loss: 3.042990207672119
Validation loss: 2.767398154863747

Epoch: 5| Step: 4
Training loss: 2.6694681644439697
Validation loss: 2.7668100736474477

Epoch: 5| Step: 5
Training loss: 3.0701053142547607
Validation loss: 2.774282160625663

Epoch: 5| Step: 6
Training loss: 3.346923828125
Validation loss: 2.7810998834589475

Epoch: 5| Step: 7
Training loss: 2.3995072841644287
Validation loss: 2.7783661734673286

Epoch: 5| Step: 8
Training loss: 2.7243199348449707
Validation loss: 2.7701585190270537

Epoch: 5| Step: 9
Training loss: 3.1409027576446533
Validation loss: 2.768394157450686

Epoch: 5| Step: 10
Training loss: 2.346381425857544
Validation loss: 2.7613426793006157

Epoch: 85| Step: 0
Training loss: 2.684650421142578
Validation loss: 2.763220217920119

Epoch: 5| Step: 1
Training loss: 2.3882932662963867
Validation loss: 2.762858908663514

Epoch: 5| Step: 2
Training loss: 2.6329941749572754
Validation loss: 2.769957470637496

Epoch: 5| Step: 3
Training loss: 2.282482147216797
Validation loss: 2.774178789507958

Epoch: 5| Step: 4
Training loss: 3.3250765800476074
Validation loss: 2.7755258493526007

Epoch: 5| Step: 5
Training loss: 2.8747830390930176
Validation loss: 2.806363721047678

Epoch: 5| Step: 6
Training loss: 3.318681001663208
Validation loss: 2.777964320234073

Epoch: 5| Step: 7
Training loss: 3.324282169342041
Validation loss: 2.7633708266801733

Epoch: 5| Step: 8
Training loss: 2.8412187099456787
Validation loss: 2.762241232779718

Epoch: 5| Step: 9
Training loss: 2.723634719848633
Validation loss: 2.760497770001811

Epoch: 5| Step: 10
Training loss: 3.401057481765747
Validation loss: 2.7586469855359805

Epoch: 86| Step: 0
Training loss: 3.1844420433044434
Validation loss: 2.7589674175426526

Epoch: 5| Step: 1
Training loss: 1.9124219417572021
Validation loss: 2.768351029324275

Epoch: 5| Step: 2
Training loss: 3.818875551223755
Validation loss: 2.761899548192178

Epoch: 5| Step: 3
Training loss: 2.7932345867156982
Validation loss: 2.7620336214701333

Epoch: 5| Step: 4
Training loss: 2.296220302581787
Validation loss: 2.7636498994724725

Epoch: 5| Step: 5
Training loss: 2.4338090419769287
Validation loss: 2.760960460990988

Epoch: 5| Step: 6
Training loss: 2.4612550735473633
Validation loss: 2.7601379732931814

Epoch: 5| Step: 7
Training loss: 3.522982120513916
Validation loss: 2.757178137379308

Epoch: 5| Step: 8
Training loss: 3.1466176509857178
Validation loss: 2.7584702302050847

Epoch: 5| Step: 9
Training loss: 2.8583099842071533
Validation loss: 2.7578271742789977

Epoch: 5| Step: 10
Training loss: 3.4016082286834717
Validation loss: 2.757886089304442

Epoch: 87| Step: 0
Training loss: 3.3490688800811768
Validation loss: 2.7548459473476616

Epoch: 5| Step: 1
Training loss: 2.235743522644043
Validation loss: 2.7510366465455744

Epoch: 5| Step: 2
Training loss: 2.582549810409546
Validation loss: 2.7540690334894324

Epoch: 5| Step: 3
Training loss: 2.0615978240966797
Validation loss: 2.7571298768443446

Epoch: 5| Step: 4
Training loss: 3.469127655029297
Validation loss: 2.765638061749038

Epoch: 5| Step: 5
Training loss: 3.425738573074341
Validation loss: 2.759516187893447

Epoch: 5| Step: 6
Training loss: 2.9184927940368652
Validation loss: 2.755531221307734

Epoch: 5| Step: 7
Training loss: 3.3894543647766113
Validation loss: 2.7523544321778

Epoch: 5| Step: 8
Training loss: 2.559810161590576
Validation loss: 2.7519663738948044

Epoch: 5| Step: 9
Training loss: 3.2962441444396973
Validation loss: 2.7537095828722884

Epoch: 5| Step: 10
Training loss: 2.3796236515045166
Validation loss: 2.749245923052552

Epoch: 88| Step: 0
Training loss: 3.177863597869873
Validation loss: 2.7519190721614386

Epoch: 5| Step: 1
Training loss: 3.016110897064209
Validation loss: 2.7525947734873784

Epoch: 5| Step: 2
Training loss: 2.7173690795898438
Validation loss: 2.747482169059015

Epoch: 5| Step: 3
Training loss: 2.9441821575164795
Validation loss: 2.7500169328463975

Epoch: 5| Step: 4
Training loss: 3.144740104675293
Validation loss: 2.749635324683241

Epoch: 5| Step: 5
Training loss: 2.575920820236206
Validation loss: 2.7471775188240954

Epoch: 5| Step: 6
Training loss: 2.0855584144592285
Validation loss: 2.7418596975265013

Epoch: 5| Step: 7
Training loss: 2.271930694580078
Validation loss: 2.746579388136505

Epoch: 5| Step: 8
Training loss: 3.1511363983154297
Validation loss: 2.7429793496285715

Epoch: 5| Step: 9
Training loss: 2.8818953037261963
Validation loss: 2.745195378539383

Epoch: 5| Step: 10
Training loss: 3.8081462383270264
Validation loss: 2.7467296302959485

Epoch: 89| Step: 0
Training loss: 3.249917507171631
Validation loss: 2.7427485655712824

Epoch: 5| Step: 1
Training loss: 2.514671802520752
Validation loss: 2.7452301953428533

Epoch: 5| Step: 2
Training loss: 2.6804070472717285
Validation loss: 2.742387648551695

Epoch: 5| Step: 3
Training loss: 2.519578456878662
Validation loss: 2.7456646939759612

Epoch: 5| Step: 4
Training loss: 2.936629056930542
Validation loss: 2.744611570912023

Epoch: 5| Step: 5
Training loss: 2.6604108810424805
Validation loss: 2.7446456442597094

Epoch: 5| Step: 6
Training loss: 3.600996494293213
Validation loss: 2.743386201961066

Epoch: 5| Step: 7
Training loss: 2.7554798126220703
Validation loss: 2.7419713261306926

Epoch: 5| Step: 8
Training loss: 3.0902163982391357
Validation loss: 2.7488632766149377

Epoch: 5| Step: 9
Training loss: 3.149806499481201
Validation loss: 2.7427686619502243

Epoch: 5| Step: 10
Training loss: 2.3698532581329346
Validation loss: 2.744610627492269

Epoch: 90| Step: 0
Training loss: 2.126955270767212
Validation loss: 2.7431321759377756

Epoch: 5| Step: 1
Training loss: 3.3398189544677734
Validation loss: 2.7422518012344197

Epoch: 5| Step: 2
Training loss: 2.7535622119903564
Validation loss: 2.7430594762166343

Epoch: 5| Step: 3
Training loss: 2.582209825515747
Validation loss: 2.7410018315879245

Epoch: 5| Step: 4
Training loss: 2.8616178035736084
Validation loss: 2.7408605980616745

Epoch: 5| Step: 5
Training loss: 2.573643684387207
Validation loss: 2.7404903673356578

Epoch: 5| Step: 6
Training loss: 3.272709369659424
Validation loss: 2.7406965301882837

Epoch: 5| Step: 7
Training loss: 2.923870086669922
Validation loss: 2.7411301700017785

Epoch: 5| Step: 8
Training loss: 3.254653215408325
Validation loss: 2.7450770049966793

Epoch: 5| Step: 9
Training loss: 2.845916509628296
Validation loss: 2.7394559383392334

Epoch: 5| Step: 10
Training loss: 3.042706251144409
Validation loss: 2.746365890708021

Epoch: 91| Step: 0
Training loss: 2.9180588722229004
Validation loss: 2.741830389986756

Epoch: 5| Step: 1
Training loss: 2.9466991424560547
Validation loss: 2.7422333353309223

Epoch: 5| Step: 2
Training loss: 3.241966724395752
Validation loss: 2.741552796415103

Epoch: 5| Step: 3
Training loss: 2.210645914077759
Validation loss: 2.741282537419309

Epoch: 5| Step: 4
Training loss: 3.305194854736328
Validation loss: 2.739349485725485

Epoch: 5| Step: 5
Training loss: 3.042181968688965
Validation loss: 2.7362268509403354

Epoch: 5| Step: 6
Training loss: 3.2568328380584717
Validation loss: 2.7367920465366815

Epoch: 5| Step: 7
Training loss: 2.3939881324768066
Validation loss: 2.7359560740891324

Epoch: 5| Step: 8
Training loss: 2.974165201187134
Validation loss: 2.7397028758961666

Epoch: 5| Step: 9
Training loss: 2.554532527923584
Validation loss: 2.740135774817518

Epoch: 5| Step: 10
Training loss: 2.6889750957489014
Validation loss: 2.7361509441047587

Epoch: 92| Step: 0
Training loss: 2.715348482131958
Validation loss: 2.737653842536352

Epoch: 5| Step: 1
Training loss: 2.6108028888702393
Validation loss: 2.735951964573194

Epoch: 5| Step: 2
Training loss: 3.374361038208008
Validation loss: 2.7372374778152793

Epoch: 5| Step: 3
Training loss: 3.2144055366516113
Validation loss: 2.734474951221097

Epoch: 5| Step: 4
Training loss: 2.669189453125
Validation loss: 2.7369043057964695

Epoch: 5| Step: 5
Training loss: 3.0458803176879883
Validation loss: 2.7335006190884497

Epoch: 5| Step: 6
Training loss: 3.1564650535583496
Validation loss: 2.7347188277911116

Epoch: 5| Step: 7
Training loss: 2.7262845039367676
Validation loss: 2.7389763298855034

Epoch: 5| Step: 8
Training loss: 2.95991587638855
Validation loss: 2.739778818622712

Epoch: 5| Step: 9
Training loss: 2.326463222503662
Validation loss: 2.7406304395327004

Epoch: 5| Step: 10
Training loss: 2.6492412090301514
Validation loss: 2.7466793880667737

Epoch: 93| Step: 0
Training loss: 2.8561558723449707
Validation loss: 2.7538206423482587

Epoch: 5| Step: 1
Training loss: 3.4390358924865723
Validation loss: 2.770369298996464

Epoch: 5| Step: 2
Training loss: 2.405290126800537
Validation loss: 2.7483486103755173

Epoch: 5| Step: 3
Training loss: 2.794013500213623
Validation loss: 2.7455844289513043

Epoch: 5| Step: 4
Training loss: 3.0875840187072754
Validation loss: 2.745749237716839

Epoch: 5| Step: 5
Training loss: 3.0952980518341064
Validation loss: 2.7398710712309806

Epoch: 5| Step: 6
Training loss: 2.8444511890411377
Validation loss: 2.7364212082278345

Epoch: 5| Step: 7
Training loss: 2.0110156536102295
Validation loss: 2.732904286794765

Epoch: 5| Step: 8
Training loss: 2.995349645614624
Validation loss: 2.7310928426763064

Epoch: 5| Step: 9
Training loss: 2.620229721069336
Validation loss: 2.7279245699605634

Epoch: 5| Step: 10
Training loss: 3.457019567489624
Validation loss: 2.7286742887189313

Epoch: 94| Step: 0
Training loss: 2.659085988998413
Validation loss: 2.7291163372737106

Epoch: 5| Step: 1
Training loss: 2.860910415649414
Validation loss: 2.731471202706778

Epoch: 5| Step: 2
Training loss: 2.6061034202575684
Validation loss: 2.730345085103025

Epoch: 5| Step: 3
Training loss: 2.5702896118164062
Validation loss: 2.7279218114832395

Epoch: 5| Step: 4
Training loss: 3.27522349357605
Validation loss: 2.731774389102895

Epoch: 5| Step: 5
Training loss: 2.745422601699829
Validation loss: 2.729018149837371

Epoch: 5| Step: 6
Training loss: 1.9853112697601318
Validation loss: 2.730393901948006

Epoch: 5| Step: 7
Training loss: 3.2091166973114014
Validation loss: 2.7288651492006037

Epoch: 5| Step: 8
Training loss: 2.883021831512451
Validation loss: 2.727721985950265

Epoch: 5| Step: 9
Training loss: 3.5912699699401855
Validation loss: 2.7285058652201006

Epoch: 5| Step: 10
Training loss: 3.152169704437256
Validation loss: 2.7285037348347325

Epoch: 95| Step: 0
Training loss: 2.8882017135620117
Validation loss: 2.7258959970166607

Epoch: 5| Step: 1
Training loss: 2.872455596923828
Validation loss: 2.7274743459557973

Epoch: 5| Step: 2
Training loss: 2.5636866092681885
Validation loss: 2.727308327151883

Epoch: 5| Step: 3
Training loss: 2.816073417663574
Validation loss: 2.7288956360150407

Epoch: 5| Step: 4
Training loss: 2.9709675312042236
Validation loss: 2.7283245055906233

Epoch: 5| Step: 5
Training loss: 2.689039945602417
Validation loss: 2.7268449670525006

Epoch: 5| Step: 6
Training loss: 2.4490280151367188
Validation loss: 2.726594325034849

Epoch: 5| Step: 7
Training loss: 2.9308152198791504
Validation loss: 2.727400323396088

Epoch: 5| Step: 8
Training loss: 3.0908641815185547
Validation loss: 2.729109602589761

Epoch: 5| Step: 9
Training loss: 3.0843639373779297
Validation loss: 2.7289102538939445

Epoch: 5| Step: 10
Training loss: 3.1513583660125732
Validation loss: 2.7229368609766804

Epoch: 96| Step: 0
Training loss: 3.0244662761688232
Validation loss: 2.72706026159307

Epoch: 5| Step: 1
Training loss: 3.419130802154541
Validation loss: 2.7237337622591244

Epoch: 5| Step: 2
Training loss: 3.754861354827881
Validation loss: 2.726480463499664

Epoch: 5| Step: 3
Training loss: 2.340430736541748
Validation loss: 2.7295649179848294

Epoch: 5| Step: 4
Training loss: 2.792217969894409
Validation loss: 2.734507022365447

Epoch: 5| Step: 5
Training loss: 2.632479667663574
Validation loss: 2.731173356374105

Epoch: 5| Step: 6
Training loss: 2.5037264823913574
Validation loss: 2.734991196663149

Epoch: 5| Step: 7
Training loss: 2.7562527656555176
Validation loss: 2.7351356373038342

Epoch: 5| Step: 8
Training loss: 1.954383134841919
Validation loss: 2.734579586213635

Epoch: 5| Step: 9
Training loss: 3.355832576751709
Validation loss: 2.735242061717536

Epoch: 5| Step: 10
Training loss: 2.8818161487579346
Validation loss: 2.732851125860727

Epoch: 97| Step: 0
Training loss: 2.6667773723602295
Validation loss: 2.7320125179906047

Epoch: 5| Step: 1
Training loss: 3.004487991333008
Validation loss: 2.7351642629151702

Epoch: 5| Step: 2
Training loss: 2.67958402633667
Validation loss: 2.7300920204449723

Epoch: 5| Step: 3
Training loss: 2.59816575050354
Validation loss: 2.731476435097315

Epoch: 5| Step: 4
Training loss: 3.087332248687744
Validation loss: 2.7281693079138316

Epoch: 5| Step: 5
Training loss: 3.0987000465393066
Validation loss: 2.732210551538775

Epoch: 5| Step: 6
Training loss: 2.733203887939453
Validation loss: 2.7277244701180408

Epoch: 5| Step: 7
Training loss: 2.817157745361328
Validation loss: 2.725812922241867

Epoch: 5| Step: 8
Training loss: 2.600987434387207
Validation loss: 2.7274263930577103

Epoch: 5| Step: 9
Training loss: 3.0812697410583496
Validation loss: 2.7266689039045766

Epoch: 5| Step: 10
Training loss: 3.080821990966797
Validation loss: 2.7251229311830256

Epoch: 98| Step: 0
Training loss: 2.753066062927246
Validation loss: 2.725196971688219

Epoch: 5| Step: 1
Training loss: 3.132803201675415
Validation loss: 2.7266394758737214

Epoch: 5| Step: 2
Training loss: 3.3813538551330566
Validation loss: 2.727950014093871

Epoch: 5| Step: 3
Training loss: 2.8075737953186035
Validation loss: 2.7251574557314635

Epoch: 5| Step: 4
Training loss: 3.3368964195251465
Validation loss: 2.7260634950412217

Epoch: 5| Step: 5
Training loss: 2.314011335372925
Validation loss: 2.7286131535806963

Epoch: 5| Step: 6
Training loss: 2.937577247619629
Validation loss: 2.7240874510939403

Epoch: 5| Step: 7
Training loss: 3.1839778423309326
Validation loss: 2.724748937032556

Epoch: 5| Step: 8
Training loss: 1.9709718227386475
Validation loss: 2.723668723978022

Epoch: 5| Step: 9
Training loss: 2.5872058868408203
Validation loss: 2.7230508788939445

Epoch: 5| Step: 10
Training loss: 3.0272910594940186
Validation loss: 2.7211529952223583

Epoch: 99| Step: 0
Training loss: 3.5002663135528564
Validation loss: 2.7287698074053695

Epoch: 5| Step: 1
Training loss: 2.2324516773223877
Validation loss: 2.7314644962228756

Epoch: 5| Step: 2
Training loss: 2.4904167652130127
Validation loss: 2.737950696740099

Epoch: 5| Step: 3
Training loss: 2.5703115463256836
Validation loss: 2.7344123804441063

Epoch: 5| Step: 4
Training loss: 3.0163745880126953
Validation loss: 2.7312860155618317

Epoch: 5| Step: 5
Training loss: 2.989518642425537
Validation loss: 2.736417132039224

Epoch: 5| Step: 6
Training loss: 2.9023733139038086
Validation loss: 2.7347703672224477

Epoch: 5| Step: 7
Training loss: 3.083728313446045
Validation loss: 2.7284147636864775

Epoch: 5| Step: 8
Training loss: 3.3994765281677246
Validation loss: 2.7208362215308735

Epoch: 5| Step: 9
Training loss: 2.5336005687713623
Validation loss: 2.71985532904184

Epoch: 5| Step: 10
Training loss: 2.6311209201812744
Validation loss: 2.720156285070604

Epoch: 100| Step: 0
Training loss: 3.4702038764953613
Validation loss: 2.721226102562361

Epoch: 5| Step: 1
Training loss: 2.431766986846924
Validation loss: 2.7166323533622165

Epoch: 5| Step: 2
Training loss: 2.8564629554748535
Validation loss: 2.7205897095382854

Epoch: 5| Step: 3
Training loss: 2.0922749042510986
Validation loss: 2.722006692681261

Epoch: 5| Step: 4
Training loss: 2.7641549110412598
Validation loss: 2.7177423764300603

Epoch: 5| Step: 5
Training loss: 3.0516083240509033
Validation loss: 2.7199358017213884

Epoch: 5| Step: 6
Training loss: 2.9149038791656494
Validation loss: 2.7194476204533733

Epoch: 5| Step: 7
Training loss: 3.240385055541992
Validation loss: 2.7215160721091816

Epoch: 5| Step: 8
Training loss: 3.095716953277588
Validation loss: 2.7212564688856884

Epoch: 5| Step: 9
Training loss: 2.3310210704803467
Validation loss: 2.7196579082037813

Epoch: 5| Step: 10
Training loss: 3.1780099868774414
Validation loss: 2.717043953557168

Epoch: 101| Step: 0
Training loss: 2.734614849090576
Validation loss: 2.718082066505186

Epoch: 5| Step: 1
Training loss: 2.872992992401123
Validation loss: 2.7185477108083744

Epoch: 5| Step: 2
Training loss: 3.351767063140869
Validation loss: 2.719402192741312

Epoch: 5| Step: 3
Training loss: 2.8182690143585205
Validation loss: 2.7204949496894755

Epoch: 5| Step: 4
Training loss: 3.0181527137756348
Validation loss: 2.722657072928644

Epoch: 5| Step: 5
Training loss: 2.8318259716033936
Validation loss: 2.7282307942708335

Epoch: 5| Step: 6
Training loss: 2.936227321624756
Validation loss: 2.730983687985328

Epoch: 5| Step: 7
Training loss: 2.4485421180725098
Validation loss: 2.730327970238142

Epoch: 5| Step: 8
Training loss: 2.4100122451782227
Validation loss: 2.7314579845756612

Epoch: 5| Step: 9
Training loss: 2.9870681762695312
Validation loss: 2.734563535259616

Epoch: 5| Step: 10
Training loss: 2.9749505519866943
Validation loss: 2.730863824967415

Epoch: 102| Step: 0
Training loss: 3.329399824142456
Validation loss: 2.72152518456982

Epoch: 5| Step: 1
Training loss: 3.1267242431640625
Validation loss: 2.7214746859765824

Epoch: 5| Step: 2
Training loss: 2.7434134483337402
Validation loss: 2.720380667717226

Epoch: 5| Step: 3
Training loss: 3.3415184020996094
Validation loss: 2.724826089797481

Epoch: 5| Step: 4
Training loss: 3.222440719604492
Validation loss: 2.7156036335934877

Epoch: 5| Step: 5
Training loss: 2.9465224742889404
Validation loss: 2.715410319707727

Epoch: 5| Step: 6
Training loss: 2.4597268104553223
Validation loss: 2.716137570719565

Epoch: 5| Step: 7
Training loss: 2.45265531539917
Validation loss: 2.716315254088371

Epoch: 5| Step: 8
Training loss: 3.0704545974731445
Validation loss: 2.7132033019937496

Epoch: 5| Step: 9
Training loss: 2.1773452758789062
Validation loss: 2.7127042995986117

Epoch: 5| Step: 10
Training loss: 2.36812424659729
Validation loss: 2.710389865342007

Epoch: 103| Step: 0
Training loss: 2.6646957397460938
Validation loss: 2.708457654522311

Epoch: 5| Step: 1
Training loss: 3.499258518218994
Validation loss: 2.7141367850765103

Epoch: 5| Step: 2
Training loss: 2.0152008533477783
Validation loss: 2.714845839367118

Epoch: 5| Step: 3
Training loss: 2.6346278190612793
Validation loss: 2.714969886246548

Epoch: 5| Step: 4
Training loss: 2.399393081665039
Validation loss: 2.7196286057913177

Epoch: 5| Step: 5
Training loss: 3.471705198287964
Validation loss: 2.7263303469586115

Epoch: 5| Step: 6
Training loss: 2.6553897857666016
Validation loss: 2.7347118777613484

Epoch: 5| Step: 7
Training loss: 2.968517780303955
Validation loss: 2.7336570832037155

Epoch: 5| Step: 8
Training loss: 3.729888916015625
Validation loss: 2.724455357879721

Epoch: 5| Step: 9
Training loss: 2.547269344329834
Validation loss: 2.7181401329655803

Epoch: 5| Step: 10
Training loss: 2.7347850799560547
Validation loss: 2.7109826662207164

Epoch: 104| Step: 0
Training loss: 2.9953525066375732
Validation loss: 2.710796438237672

Epoch: 5| Step: 1
Training loss: 2.852234363555908
Validation loss: 2.712150631412383

Epoch: 5| Step: 2
Training loss: 2.484889030456543
Validation loss: 2.717822320999638

Epoch: 5| Step: 3
Training loss: 3.606722354888916
Validation loss: 2.7174338653523433

Epoch: 5| Step: 4
Training loss: 2.7000973224639893
Validation loss: 2.7196588490598943

Epoch: 5| Step: 5
Training loss: 2.9253270626068115
Validation loss: 2.723934112056609

Epoch: 5| Step: 6
Training loss: 2.159055233001709
Validation loss: 2.721704372795679

Epoch: 5| Step: 7
Training loss: 2.985590696334839
Validation loss: 2.72340295391698

Epoch: 5| Step: 8
Training loss: 2.1218695640563965
Validation loss: 2.7153757797774447

Epoch: 5| Step: 9
Training loss: 2.703826427459717
Validation loss: 2.713944696610974

Epoch: 5| Step: 10
Training loss: 3.972762107849121
Validation loss: 2.7103345932499057

Epoch: 105| Step: 0
Training loss: 2.894570827484131
Validation loss: 2.70931823279268

Epoch: 5| Step: 1
Training loss: 2.727437973022461
Validation loss: 2.7107682356270413

Epoch: 5| Step: 2
Training loss: 1.7445255517959595
Validation loss: 2.7114561347551245

Epoch: 5| Step: 3
Training loss: 2.562892198562622
Validation loss: 2.71075265894654

Epoch: 5| Step: 4
Training loss: 3.150517702102661
Validation loss: 2.7168286974712084

Epoch: 5| Step: 5
Training loss: 3.0392658710479736
Validation loss: 2.7267958733343307

Epoch: 5| Step: 6
Training loss: 2.494019031524658
Validation loss: 2.7250271868962113

Epoch: 5| Step: 7
Training loss: 2.3106160163879395
Validation loss: 2.7203442101837485

Epoch: 5| Step: 8
Training loss: 3.5454928874969482
Validation loss: 2.718260875312231

Epoch: 5| Step: 9
Training loss: 3.4623024463653564
Validation loss: 2.720140916044994

Epoch: 5| Step: 10
Training loss: 3.5131309032440186
Validation loss: 2.715830228661978

Epoch: 106| Step: 0
Training loss: 2.9990103244781494
Validation loss: 2.7111959072851364

Epoch: 5| Step: 1
Training loss: 2.3014843463897705
Validation loss: 2.711580181634554

Epoch: 5| Step: 2
Training loss: 3.272240161895752
Validation loss: 2.711760974699451

Epoch: 5| Step: 3
Training loss: 2.9676733016967773
Validation loss: 2.713120598946848

Epoch: 5| Step: 4
Training loss: 3.4298527240753174
Validation loss: 2.7117933816807245

Epoch: 5| Step: 5
Training loss: 2.392163038253784
Validation loss: 2.7122930762588338

Epoch: 5| Step: 6
Training loss: 3.1340787410736084
Validation loss: 2.7150312213487524

Epoch: 5| Step: 7
Training loss: 2.887989044189453
Validation loss: 2.7146652488298315

Epoch: 5| Step: 8
Training loss: 2.4724841117858887
Validation loss: 2.7149199260178434

Epoch: 5| Step: 9
Training loss: 2.691189765930176
Validation loss: 2.7138545590062297

Epoch: 5| Step: 10
Training loss: 2.717437982559204
Validation loss: 2.7121270266912316

Epoch: 107| Step: 0
Training loss: 2.815784454345703
Validation loss: 2.7095084318550686

Epoch: 5| Step: 1
Training loss: 3.5639278888702393
Validation loss: 2.704283937331169

Epoch: 5| Step: 2
Training loss: 2.4206202030181885
Validation loss: 2.7056210092318955

Epoch: 5| Step: 3
Training loss: 2.1654701232910156
Validation loss: 2.7102493496351343

Epoch: 5| Step: 4
Training loss: 2.8827872276306152
Validation loss: 2.7149062233586467

Epoch: 5| Step: 5
Training loss: 3.3778107166290283
Validation loss: 2.7153353691101074

Epoch: 5| Step: 6
Training loss: 3.2075047492980957
Validation loss: 2.722475590244416

Epoch: 5| Step: 7
Training loss: 2.300962448120117
Validation loss: 2.7288206520900933

Epoch: 5| Step: 8
Training loss: 3.0591251850128174
Validation loss: 2.7259593830313733

Epoch: 5| Step: 9
Training loss: 2.72306752204895
Validation loss: 2.7248482652889785

Epoch: 5| Step: 10
Training loss: 2.7264654636383057
Validation loss: 2.722901108444378

Epoch: 108| Step: 0
Training loss: 2.488722085952759
Validation loss: 2.7178774572187856

Epoch: 5| Step: 1
Training loss: 2.644958019256592
Validation loss: 2.7078694835785897

Epoch: 5| Step: 2
Training loss: 2.7411062717437744
Validation loss: 2.703811337870936

Epoch: 5| Step: 3
Training loss: 2.1475110054016113
Validation loss: 2.702215233156758

Epoch: 5| Step: 4
Training loss: 2.2294559478759766
Validation loss: 2.700434430952995

Epoch: 5| Step: 5
Training loss: 3.204320192337036
Validation loss: 2.705623519036078

Epoch: 5| Step: 6
Training loss: 2.54559326171875
Validation loss: 2.7063886375837427

Epoch: 5| Step: 7
Training loss: 3.338535785675049
Validation loss: 2.7169995923196115

Epoch: 5| Step: 8
Training loss: 3.6003456115722656
Validation loss: 2.714793353952387

Epoch: 5| Step: 9
Training loss: 3.5394062995910645
Validation loss: 2.7105702866790113

Epoch: 5| Step: 10
Training loss: 2.6330721378326416
Validation loss: 2.702004781333349

Epoch: 109| Step: 0
Training loss: 2.3291242122650146
Validation loss: 2.701426798297513

Epoch: 5| Step: 1
Training loss: 3.083002805709839
Validation loss: 2.702945911756126

Epoch: 5| Step: 2
Training loss: 2.7979981899261475
Validation loss: 2.6992692306477535

Epoch: 5| Step: 3
Training loss: 2.9652042388916016
Validation loss: 2.703387862892561

Epoch: 5| Step: 4
Training loss: 3.1771457195281982
Validation loss: 2.7040012549328547

Epoch: 5| Step: 5
Training loss: 1.995112657546997
Validation loss: 2.707261129092145

Epoch: 5| Step: 6
Training loss: 3.9042506217956543
Validation loss: 2.7330275607365433

Epoch: 5| Step: 7
Training loss: 2.710578203201294
Validation loss: 2.7364318627183155

Epoch: 5| Step: 8
Training loss: 3.3034095764160156
Validation loss: 2.724125195575017

Epoch: 5| Step: 9
Training loss: 2.5663695335388184
Validation loss: 2.707740242763232

Epoch: 5| Step: 10
Training loss: 2.270387649536133
Validation loss: 2.7056281643529094

Epoch: 110| Step: 0
Training loss: 3.155622959136963
Validation loss: 2.702582900242139

Epoch: 5| Step: 1
Training loss: 2.7449100017547607
Validation loss: 2.7019184532985894

Epoch: 5| Step: 2
Training loss: 2.918485641479492
Validation loss: 2.6976941811141146

Epoch: 5| Step: 3
Training loss: 2.961477279663086
Validation loss: 2.70007223467673

Epoch: 5| Step: 4
Training loss: 3.3113131523132324
Validation loss: 2.705468100886191

Epoch: 5| Step: 5
Training loss: 2.510990858078003
Validation loss: 2.7057692004788305

Epoch: 5| Step: 6
Training loss: 2.074998140335083
Validation loss: 2.7058286179778395

Epoch: 5| Step: 7
Training loss: 2.834961414337158
Validation loss: 2.7099321119246946

Epoch: 5| Step: 8
Training loss: 3.2112503051757812
Validation loss: 2.7027891425676245

Epoch: 5| Step: 9
Training loss: 2.5452091693878174
Validation loss: 2.7006968810994136

Epoch: 5| Step: 10
Training loss: 2.946110963821411
Validation loss: 2.6999086231313725

Epoch: 111| Step: 0
Training loss: 2.709296703338623
Validation loss: 2.6968432728962233

Epoch: 5| Step: 1
Training loss: 2.914923906326294
Validation loss: 2.6953095851405973

Epoch: 5| Step: 2
Training loss: 3.2857704162597656
Validation loss: 2.69763175646464

Epoch: 5| Step: 3
Training loss: 2.375685930252075
Validation loss: 2.7039996680393013

Epoch: 5| Step: 4
Training loss: 2.5562705993652344
Validation loss: 2.7075017729113178

Epoch: 5| Step: 5
Training loss: 3.248866319656372
Validation loss: 2.7004149677932903

Epoch: 5| Step: 6
Training loss: 2.9526174068450928
Validation loss: 2.69813713976132

Epoch: 5| Step: 7
Training loss: 3.2117011547088623
Validation loss: 2.704296291515391

Epoch: 5| Step: 8
Training loss: 2.492978811264038
Validation loss: 2.701439690846269

Epoch: 5| Step: 9
Training loss: 3.1249783039093018
Validation loss: 2.706384294776506

Epoch: 5| Step: 10
Training loss: 2.168588638305664
Validation loss: 2.7083145597929597

Epoch: 112| Step: 0
Training loss: 2.8169431686401367
Validation loss: 2.713812735772902

Epoch: 5| Step: 1
Training loss: 2.3455557823181152
Validation loss: 2.721577418747769

Epoch: 5| Step: 2
Training loss: 3.1593666076660156
Validation loss: 2.7192870519494496

Epoch: 5| Step: 3
Training loss: 2.931149959564209
Validation loss: 2.7213068418605353

Epoch: 5| Step: 4
Training loss: 2.6168317794799805
Validation loss: 2.7145053314906296

Epoch: 5| Step: 5
Training loss: 3.314404249191284
Validation loss: 2.7217070005273305

Epoch: 5| Step: 6
Training loss: 2.9932706356048584
Validation loss: 2.7236923248537126

Epoch: 5| Step: 7
Training loss: 2.6395022869110107
Validation loss: 2.734874371559389

Epoch: 5| Step: 8
Training loss: 2.9409091472625732
Validation loss: 2.732637328486289

Epoch: 5| Step: 9
Training loss: 2.6535580158233643
Validation loss: 2.711824970860635

Epoch: 5| Step: 10
Training loss: 2.836428642272949
Validation loss: 2.699625269059212

Epoch: 113| Step: 0
Training loss: 2.555849552154541
Validation loss: 2.6959561173633864

Epoch: 5| Step: 1
Training loss: 2.7125003337860107
Validation loss: 2.696005149554181

Epoch: 5| Step: 2
Training loss: 3.782940626144409
Validation loss: 2.699700686239427

Epoch: 5| Step: 3
Training loss: 2.4494221210479736
Validation loss: 2.699075073324224

Epoch: 5| Step: 4
Training loss: 2.2053985595703125
Validation loss: 2.7028299198355725

Epoch: 5| Step: 5
Training loss: 2.8463029861450195
Validation loss: 2.706637369689121

Epoch: 5| Step: 6
Training loss: 3.3491806983947754
Validation loss: 2.7067495904942995

Epoch: 5| Step: 7
Training loss: 2.983027935028076
Validation loss: 2.7079216869928504

Epoch: 5| Step: 8
Training loss: 2.8480658531188965
Validation loss: 2.705607706500638

Epoch: 5| Step: 9
Training loss: 2.8355307579040527
Validation loss: 2.702570107675368

Epoch: 5| Step: 10
Training loss: 2.7004032135009766
Validation loss: 2.699411528084868

Epoch: 114| Step: 0
Training loss: 2.681568145751953
Validation loss: 2.7022057989592194

Epoch: 5| Step: 1
Training loss: 2.53981351852417
Validation loss: 2.709362400475369

Epoch: 5| Step: 2
Training loss: 2.418732166290283
Validation loss: 2.7049168002220894

Epoch: 5| Step: 3
Training loss: 3.5334293842315674
Validation loss: 2.7083379401955554

Epoch: 5| Step: 4
Training loss: 2.817159414291382
Validation loss: 2.707701321571104

Epoch: 5| Step: 5
Training loss: 2.7188990116119385
Validation loss: 2.708492389289282

Epoch: 5| Step: 6
Training loss: 3.828847885131836
Validation loss: 2.7015962831435667

Epoch: 5| Step: 7
Training loss: 2.1043198108673096
Validation loss: 2.7001565963991228

Epoch: 5| Step: 8
Training loss: 3.0675933361053467
Validation loss: 2.6977038255301853

Epoch: 5| Step: 9
Training loss: 2.816638946533203
Validation loss: 2.693022776675481

Epoch: 5| Step: 10
Training loss: 2.7508840560913086
Validation loss: 2.6960920620990056

Epoch: 115| Step: 0
Training loss: 3.533905029296875
Validation loss: 2.6939199355340775

Epoch: 5| Step: 1
Training loss: 2.9003634452819824
Validation loss: 2.694311834150745

Epoch: 5| Step: 2
Training loss: 3.628267288208008
Validation loss: 2.695555243440854

Epoch: 5| Step: 3
Training loss: 2.9362406730651855
Validation loss: 2.694845050893804

Epoch: 5| Step: 4
Training loss: 2.7863149642944336
Validation loss: 2.6915409129153014

Epoch: 5| Step: 5
Training loss: 2.640123128890991
Validation loss: 2.6904358863830566

Epoch: 5| Step: 6
Training loss: 2.6748063564300537
Validation loss: 2.688392416123421

Epoch: 5| Step: 7
Training loss: 3.535834550857544
Validation loss: 2.687903155562698

Epoch: 5| Step: 8
Training loss: 2.39231276512146
Validation loss: 2.689347528642224

Epoch: 5| Step: 9
Training loss: 1.7441275119781494
Validation loss: 2.692469127716557

Epoch: 5| Step: 10
Training loss: 2.3339381217956543
Validation loss: 2.69220374220161

Epoch: 116| Step: 0
Training loss: 2.967550039291382
Validation loss: 2.6881723224475818

Epoch: 5| Step: 1
Training loss: 2.394789934158325
Validation loss: 2.6896659917728876

Epoch: 5| Step: 2
Training loss: 2.3553364276885986
Validation loss: 2.689529449709

Epoch: 5| Step: 3
Training loss: 3.4015750885009766
Validation loss: 2.6897041464364655

Epoch: 5| Step: 4
Training loss: 2.880873680114746
Validation loss: 2.6853517255475445

Epoch: 5| Step: 5
Training loss: 2.2046680450439453
Validation loss: 2.6867025667621243

Epoch: 5| Step: 6
Training loss: 2.9096803665161133
Validation loss: 2.6902740155496905

Epoch: 5| Step: 7
Training loss: 3.272871732711792
Validation loss: 2.6874846643017185

Epoch: 5| Step: 8
Training loss: 2.9790775775909424
Validation loss: 2.6891514614064205

Epoch: 5| Step: 9
Training loss: 2.697955369949341
Validation loss: 2.690456464726438

Epoch: 5| Step: 10
Training loss: 3.0736637115478516
Validation loss: 2.687127149233254

Epoch: 117| Step: 0
Training loss: 3.0167994499206543
Validation loss: 2.6894953404703448

Epoch: 5| Step: 1
Training loss: 2.190936803817749
Validation loss: 2.688877095458328

Epoch: 5| Step: 2
Training loss: 3.2884058952331543
Validation loss: 2.6901540730589177

Epoch: 5| Step: 3
Training loss: 3.0944764614105225
Validation loss: 2.6914737378397295

Epoch: 5| Step: 4
Training loss: 2.6424622535705566
Validation loss: 2.6879593121108187

Epoch: 5| Step: 5
Training loss: 2.8324456214904785
Validation loss: 2.687205558182091

Epoch: 5| Step: 6
Training loss: 3.027360677719116
Validation loss: 2.6879060652948197

Epoch: 5| Step: 7
Training loss: 2.1253366470336914
Validation loss: 2.6895900413554203

Epoch: 5| Step: 8
Training loss: 3.180920124053955
Validation loss: 2.689503597956832

Epoch: 5| Step: 9
Training loss: 2.801602363586426
Validation loss: 2.686829831010552

Epoch: 5| Step: 10
Training loss: 2.892784357070923
Validation loss: 2.687273353658697

Epoch: 118| Step: 0
Training loss: 2.952302932739258
Validation loss: 2.6848042600898334

Epoch: 5| Step: 1
Training loss: 2.3633947372436523
Validation loss: 2.6818895955239572

Epoch: 5| Step: 2
Training loss: 3.532132625579834
Validation loss: 2.683889135237663

Epoch: 5| Step: 3
Training loss: 3.1006407737731934
Validation loss: 2.6827772278939523

Epoch: 5| Step: 4
Training loss: 2.672154188156128
Validation loss: 2.6806790392885924

Epoch: 5| Step: 5
Training loss: 2.4781546592712402
Validation loss: 2.6794541292293097

Epoch: 5| Step: 6
Training loss: 3.571885585784912
Validation loss: 2.683584100456648

Epoch: 5| Step: 7
Training loss: 2.486661434173584
Validation loss: 2.680703524620302

Epoch: 5| Step: 8
Training loss: 2.2159180641174316
Validation loss: 2.6840037094649447

Epoch: 5| Step: 9
Training loss: 3.1406333446502686
Validation loss: 2.6808777240014847

Epoch: 5| Step: 10
Training loss: 2.4587104320526123
Validation loss: 2.6842209087905062

Epoch: 119| Step: 0
Training loss: 2.5065646171569824
Validation loss: 2.6850337392540387

Epoch: 5| Step: 1
Training loss: 2.8487324714660645
Validation loss: 2.681653348348474

Epoch: 5| Step: 2
Training loss: 2.9702131748199463
Validation loss: 2.684509772126393

Epoch: 5| Step: 3
Training loss: 2.854715585708618
Validation loss: 2.6848995583031767

Epoch: 5| Step: 4
Training loss: 3.2966511249542236
Validation loss: 2.6856342438728578

Epoch: 5| Step: 5
Training loss: 3.1235287189483643
Validation loss: 2.6876921961384435

Epoch: 5| Step: 6
Training loss: 2.443258285522461
Validation loss: 2.682112027240056

Epoch: 5| Step: 7
Training loss: 2.804500102996826
Validation loss: 2.6840220702591764

Epoch: 5| Step: 8
Training loss: 2.7597968578338623
Validation loss: 2.6799172329646286

Epoch: 5| Step: 9
Training loss: 2.9135499000549316
Validation loss: 2.6768338680267334

Epoch: 5| Step: 10
Training loss: 2.4401798248291016
Validation loss: 2.6816348593722106

Epoch: 120| Step: 0
Training loss: 2.9000115394592285
Validation loss: 2.6774074749280046

Epoch: 5| Step: 1
Training loss: 2.7234222888946533
Validation loss: 2.6773276713586625

Epoch: 5| Step: 2
Training loss: 2.3315348625183105
Validation loss: 2.6785878519858084

Epoch: 5| Step: 3
Training loss: 2.428884983062744
Validation loss: 2.6804211293497393

Epoch: 5| Step: 4
Training loss: 2.741004467010498
Validation loss: 2.6788146111272995

Epoch: 5| Step: 5
Training loss: 3.4413483142852783
Validation loss: 2.6866765637551584

Epoch: 5| Step: 6
Training loss: 3.23521089553833
Validation loss: 2.692210635831279

Epoch: 5| Step: 7
Training loss: 3.0164475440979004
Validation loss: 2.681723504938105

Epoch: 5| Step: 8
Training loss: 2.5740866661071777
Validation loss: 2.686633938102312

Epoch: 5| Step: 9
Training loss: 3.0083835124969482
Validation loss: 2.6852022268438853

Epoch: 5| Step: 10
Training loss: 2.5427050590515137
Validation loss: 2.693971062219271

Epoch: 121| Step: 0
Training loss: 2.8522896766662598
Validation loss: 2.711296078979328

Epoch: 5| Step: 1
Training loss: 2.982104778289795
Validation loss: 2.7047241836465816

Epoch: 5| Step: 2
Training loss: 1.845597267150879
Validation loss: 2.7033027961689937

Epoch: 5| Step: 3
Training loss: 3.299685001373291
Validation loss: 2.696099627402521

Epoch: 5| Step: 4
Training loss: 3.2030246257781982
Validation loss: 2.693498091031146

Epoch: 5| Step: 5
Training loss: 2.6089324951171875
Validation loss: 2.7041803380494476

Epoch: 5| Step: 6
Training loss: 3.658442974090576
Validation loss: 2.703776959450014

Epoch: 5| Step: 7
Training loss: 2.1800894737243652
Validation loss: 2.7182947461323073

Epoch: 5| Step: 8
Training loss: 3.2015342712402344
Validation loss: 2.6983264005312355

Epoch: 5| Step: 9
Training loss: 2.7871029376983643
Validation loss: 2.6891849810077297

Epoch: 5| Step: 10
Training loss: 2.5685691833496094
Validation loss: 2.6830007055754304

Epoch: 122| Step: 0
Training loss: 2.613039493560791
Validation loss: 2.6767606196864957

Epoch: 5| Step: 1
Training loss: 2.611661434173584
Validation loss: 2.676456976962346

Epoch: 5| Step: 2
Training loss: 2.2537524700164795
Validation loss: 2.6830913917992705

Epoch: 5| Step: 3
Training loss: 2.678830623626709
Validation loss: 2.693376179664366

Epoch: 5| Step: 4
Training loss: 3.3662757873535156
Validation loss: 2.689794409659601

Epoch: 5| Step: 5
Training loss: 3.346468448638916
Validation loss: 2.6939360249427056

Epoch: 5| Step: 6
Training loss: 3.3582355976104736
Validation loss: 2.6875142692237772

Epoch: 5| Step: 7
Training loss: 3.098759651184082
Validation loss: 2.6847006018443773

Epoch: 5| Step: 8
Training loss: 2.4460277557373047
Validation loss: 2.6835337377363637

Epoch: 5| Step: 9
Training loss: 2.777818202972412
Validation loss: 2.6847772880267073

Epoch: 5| Step: 10
Training loss: 2.496488571166992
Validation loss: 2.679475986829368

Epoch: 123| Step: 0
Training loss: 2.401644229888916
Validation loss: 2.6816309831475698

Epoch: 5| Step: 1
Training loss: 2.5831079483032227
Validation loss: 2.679969567124562

Epoch: 5| Step: 2
Training loss: 2.992069959640503
Validation loss: 2.6810788851912304

Epoch: 5| Step: 3
Training loss: 2.7395200729370117
Validation loss: 2.6838591637149936

Epoch: 5| Step: 4
Training loss: 3.1218340396881104
Validation loss: 2.689708694334953

Epoch: 5| Step: 5
Training loss: 2.657978057861328
Validation loss: 2.6990671978201917

Epoch: 5| Step: 6
Training loss: 3.0468790531158447
Validation loss: 2.6891782886238507

Epoch: 5| Step: 7
Training loss: 2.121032953262329
Validation loss: 2.6871356912838515

Epoch: 5| Step: 8
Training loss: 3.0726821422576904
Validation loss: 2.683711790269421

Epoch: 5| Step: 9
Training loss: 3.1176211833953857
Validation loss: 2.68230531548941

Epoch: 5| Step: 10
Training loss: 3.249192476272583
Validation loss: 2.675532966531733

Epoch: 124| Step: 0
Training loss: 3.1816585063934326
Validation loss: 2.6731977308950117

Epoch: 5| Step: 1
Training loss: 3.1225719451904297
Validation loss: 2.6751784124682025

Epoch: 5| Step: 2
Training loss: 2.171281099319458
Validation loss: 2.6738521283672703

Epoch: 5| Step: 3
Training loss: 2.99070405960083
Validation loss: 2.674852809598369

Epoch: 5| Step: 4
Training loss: 2.672832489013672
Validation loss: 2.6740946538986696

Epoch: 5| Step: 5
Training loss: 3.3630454540252686
Validation loss: 2.677307628816174

Epoch: 5| Step: 6
Training loss: 2.263359308242798
Validation loss: 2.676931183825257

Epoch: 5| Step: 7
Training loss: 2.6021342277526855
Validation loss: 2.6739223900661675

Epoch: 5| Step: 8
Training loss: 3.228454113006592
Validation loss: 2.6741321202247375

Epoch: 5| Step: 9
Training loss: 2.48707914352417
Validation loss: 2.6762931885257846

Epoch: 5| Step: 10
Training loss: 2.935720682144165
Validation loss: 2.6800802894817886

Epoch: 125| Step: 0
Training loss: 2.549203395843506
Validation loss: 2.6747743493767193

Epoch: 5| Step: 1
Training loss: 2.380370616912842
Validation loss: 2.6753058792442403

Epoch: 5| Step: 2
Training loss: 2.548607349395752
Validation loss: 2.6740258791113414

Epoch: 5| Step: 3
Training loss: 2.9802029132843018
Validation loss: 2.675596373055571

Epoch: 5| Step: 4
Training loss: 2.105161666870117
Validation loss: 2.672447742954377

Epoch: 5| Step: 5
Training loss: 3.247807264328003
Validation loss: 2.6750998804646153

Epoch: 5| Step: 6
Training loss: 3.6915581226348877
Validation loss: 2.671527301111529

Epoch: 5| Step: 7
Training loss: 3.1742923259735107
Validation loss: 2.6724252700805664

Epoch: 5| Step: 8
Training loss: 2.2974934577941895
Validation loss: 2.669852441357028

Epoch: 5| Step: 9
Training loss: 3.631010055541992
Validation loss: 2.67018283695303

Epoch: 5| Step: 10
Training loss: 2.2624735832214355
Validation loss: 2.6651241779327393

Testing loss: 2.738532066345215
