Epoch: 1| Step: 0
Training loss: 5.08473840691417
Validation loss: 5.753493932362959

Epoch: 6| Step: 1
Training loss: 6.3096696910462295
Validation loss: 5.744620479599543

Epoch: 6| Step: 2
Training loss: 4.609277756521902
Validation loss: 5.737582825240204

Epoch: 6| Step: 3
Training loss: 6.987377229816479
Validation loss: 5.731384006962174

Epoch: 6| Step: 4
Training loss: 6.322251747358881
Validation loss: 5.725617304209208

Epoch: 6| Step: 5
Training loss: 5.37041721591517
Validation loss: 5.719447577921812

Epoch: 6| Step: 6
Training loss: 5.213977390288572
Validation loss: 5.713776886570388

Epoch: 6| Step: 7
Training loss: 5.364234789540754
Validation loss: 5.707625322811085

Epoch: 6| Step: 8
Training loss: 6.141956447077978
Validation loss: 5.7009821528666915

Epoch: 6| Step: 9
Training loss: 5.948378064575342
Validation loss: 5.694070310763453

Epoch: 6| Step: 10
Training loss: 5.885113391545456
Validation loss: 5.685840197268226

Epoch: 6| Step: 11
Training loss: 5.37205744195536
Validation loss: 5.677271255524345

Epoch: 6| Step: 12
Training loss: 5.818559011240254
Validation loss: 5.66830650552321

Epoch: 6| Step: 13
Training loss: 5.516589202029656
Validation loss: 5.657875901983367

Epoch: 2| Step: 0
Training loss: 6.13364314388706
Validation loss: 5.647349490006144

Epoch: 6| Step: 1
Training loss: 5.061416133189942
Validation loss: 5.6357240673976525

Epoch: 6| Step: 2
Training loss: 4.1666977436178305
Validation loss: 5.622581777024843

Epoch: 6| Step: 3
Training loss: 5.826060893491242
Validation loss: 5.608953385097627

Epoch: 6| Step: 4
Training loss: 5.564254312655758
Validation loss: 5.5939827010882395

Epoch: 6| Step: 5
Training loss: 5.047977669547093
Validation loss: 5.57764094066572

Epoch: 6| Step: 6
Training loss: 6.027800369025036
Validation loss: 5.559830645787403

Epoch: 6| Step: 7
Training loss: 5.941516682076929
Validation loss: 5.541192638260145

Epoch: 6| Step: 8
Training loss: 5.0045219953779485
Validation loss: 5.520560545014517

Epoch: 6| Step: 9
Training loss: 5.8906094578707435
Validation loss: 5.4981578639315885

Epoch: 6| Step: 10
Training loss: 5.735343830474313
Validation loss: 5.474236337436007

Epoch: 6| Step: 11
Training loss: 6.062464133874255
Validation loss: 5.449241245479302

Epoch: 6| Step: 12
Training loss: 5.695439090028323
Validation loss: 5.422472245784968

Epoch: 6| Step: 13
Training loss: 5.700230697514164
Validation loss: 5.393991696814959

Epoch: 3| Step: 0
Training loss: 4.88239373204246
Validation loss: 5.363492035568392

Epoch: 6| Step: 1
Training loss: 5.644736527138838
Validation loss: 5.33331721762304

Epoch: 6| Step: 2
Training loss: 4.716798492494546
Validation loss: 5.3009635422464925

Epoch: 6| Step: 3
Training loss: 5.14523637323163
Validation loss: 5.267876418181561

Epoch: 6| Step: 4
Training loss: 5.820564500102504
Validation loss: 5.233574789582912

Epoch: 6| Step: 5
Training loss: 6.021164124937435
Validation loss: 5.198908055731518

Epoch: 6| Step: 6
Training loss: 4.776938096023664
Validation loss: 5.164550345169789

Epoch: 6| Step: 7
Training loss: 5.560902569739621
Validation loss: 5.12822598646748

Epoch: 6| Step: 8
Training loss: 4.293057163983776
Validation loss: 5.092737738110258

Epoch: 6| Step: 9
Training loss: 5.4292315174990895
Validation loss: 5.058966210126358

Epoch: 6| Step: 10
Training loss: 6.166239886937721
Validation loss: 5.024735300341667

Epoch: 6| Step: 11
Training loss: 4.773355985903844
Validation loss: 4.989048889147139

Epoch: 6| Step: 12
Training loss: 4.252749731590258
Validation loss: 4.95393642100009

Epoch: 6| Step: 13
Training loss: 4.843740352497953
Validation loss: 4.922318808395785

Epoch: 4| Step: 0
Training loss: 5.021989153814966
Validation loss: 4.887094494465005

Epoch: 6| Step: 1
Training loss: 4.006458075917794
Validation loss: 4.853574246707649

Epoch: 6| Step: 2
Training loss: 5.072926275203725
Validation loss: 4.822089047586667

Epoch: 6| Step: 3
Training loss: 5.048528536203333
Validation loss: 4.790380686096836

Epoch: 6| Step: 4
Training loss: 5.6885559443227285
Validation loss: 4.757249769070881

Epoch: 6| Step: 5
Training loss: 5.3583324964333805
Validation loss: 4.725340903531123

Epoch: 6| Step: 6
Training loss: 4.095708713336674
Validation loss: 4.692945379871962

Epoch: 6| Step: 7
Training loss: 3.8501113726868064
Validation loss: 4.661182997874146

Epoch: 6| Step: 8
Training loss: 3.943427574168802
Validation loss: 4.62955738322083

Epoch: 6| Step: 9
Training loss: 5.571210235118284
Validation loss: 4.602263520226982

Epoch: 6| Step: 10
Training loss: 4.659614729774517
Validation loss: 4.573938144335844

Epoch: 6| Step: 11
Training loss: 4.8278148761392545
Validation loss: 4.548524237844299

Epoch: 6| Step: 12
Training loss: 4.527059577403239
Validation loss: 4.521396778588562

Epoch: 6| Step: 13
Training loss: 4.735244318651807
Validation loss: 4.498703761935665

Epoch: 5| Step: 0
Training loss: 4.846149465537973
Validation loss: 4.476772737576306

Epoch: 6| Step: 1
Training loss: 4.94387348083533
Validation loss: 4.459771869662608

Epoch: 6| Step: 2
Training loss: 3.8111287136678493
Validation loss: 4.438344153866148

Epoch: 6| Step: 3
Training loss: 4.484006221906444
Validation loss: 4.418262991129174

Epoch: 6| Step: 4
Training loss: 4.965745125260443
Validation loss: 4.402359990139851

Epoch: 6| Step: 5
Training loss: 3.7453778073024346
Validation loss: 4.3823072032407895

Epoch: 6| Step: 6
Training loss: 4.578704484843009
Validation loss: 4.3683493392080255

Epoch: 6| Step: 7
Training loss: 4.423686273250017
Validation loss: 4.3523211074311305

Epoch: 6| Step: 8
Training loss: 4.83263357073593
Validation loss: 4.3370377598821515

Epoch: 6| Step: 9
Training loss: 4.225154508214597
Validation loss: 4.321268366041122

Epoch: 6| Step: 10
Training loss: 4.619323133286607
Validation loss: 4.302149367243427

Epoch: 6| Step: 11
Training loss: 4.026943775224983
Validation loss: 4.288678940543378

Epoch: 6| Step: 12
Training loss: 4.461662594310416
Validation loss: 4.270656556623516

Epoch: 6| Step: 13
Training loss: 4.635715957866336
Validation loss: 4.257215172167766

Epoch: 6| Step: 0
Training loss: 4.393152561511031
Validation loss: 4.24322329240209

Epoch: 6| Step: 1
Training loss: 4.087528305655648
Validation loss: 4.232884375985975

Epoch: 6| Step: 2
Training loss: 4.983924390938804
Validation loss: 4.220268993909186

Epoch: 6| Step: 3
Training loss: 5.373707815582818
Validation loss: 4.210695841236447

Epoch: 6| Step: 4
Training loss: 4.319930157979897
Validation loss: 4.194317660912135

Epoch: 6| Step: 5
Training loss: 2.9914750727629196
Validation loss: 4.1807352425182795

Epoch: 6| Step: 6
Training loss: 4.781966810161519
Validation loss: 4.169968353125429

Epoch: 6| Step: 7
Training loss: 3.2185719264872237
Validation loss: 4.160405773979813

Epoch: 6| Step: 8
Training loss: 4.118544642606722
Validation loss: 4.147657118891457

Epoch: 6| Step: 9
Training loss: 3.4188008194795327
Validation loss: 4.139929668345697

Epoch: 6| Step: 10
Training loss: 5.240480784716271
Validation loss: 4.128444928563042

Epoch: 6| Step: 11
Training loss: 4.039333076194565
Validation loss: 4.119764172835238

Epoch: 6| Step: 12
Training loss: 4.268797201451381
Validation loss: 4.1111165397436

Epoch: 6| Step: 13
Training loss: 4.34679147186215
Validation loss: 4.102126582315013

Epoch: 7| Step: 0
Training loss: 4.050408076696539
Validation loss: 4.090609580468047

Epoch: 6| Step: 1
Training loss: 3.881620227890268
Validation loss: 4.082242521571141

Epoch: 6| Step: 2
Training loss: 4.291482544933823
Validation loss: 4.0746202852752536

Epoch: 6| Step: 3
Training loss: 4.448987678509055
Validation loss: 4.06438241515026

Epoch: 6| Step: 4
Training loss: 3.555162335215697
Validation loss: 4.054502808395607

Epoch: 6| Step: 5
Training loss: 4.702134138899599
Validation loss: 4.046042188715646

Epoch: 6| Step: 6
Training loss: 4.854158895374457
Validation loss: 4.034419331340751

Epoch: 6| Step: 7
Training loss: 4.326468360678505
Validation loss: 4.026104710533744

Epoch: 6| Step: 8
Training loss: 3.3840217103013708
Validation loss: 4.0255241025815405

Epoch: 6| Step: 9
Training loss: 4.135264024711983
Validation loss: 4.008652033422418

Epoch: 6| Step: 10
Training loss: 4.28367468120702
Validation loss: 3.995532339042086

Epoch: 6| Step: 11
Training loss: 4.450284353022164
Validation loss: 3.992845019615541

Epoch: 6| Step: 12
Training loss: 3.6995393156954646
Validation loss: 3.987372514372074

Epoch: 6| Step: 13
Training loss: 4.228802945636903
Validation loss: 3.9816552882091023

Epoch: 8| Step: 0
Training loss: 3.9371097916304723
Validation loss: 3.974054712472855

Epoch: 6| Step: 1
Training loss: 4.6484928929210065
Validation loss: 3.965754361473712

Epoch: 6| Step: 2
Training loss: 4.080423810675975
Validation loss: 3.9544253389835755

Epoch: 6| Step: 3
Training loss: 3.339706971340292
Validation loss: 3.946877708463683

Epoch: 6| Step: 4
Training loss: 4.044018300514054
Validation loss: 3.9421921531933934

Epoch: 6| Step: 5
Training loss: 4.665258921871911
Validation loss: 3.933569002434639

Epoch: 6| Step: 6
Training loss: 4.734139515273419
Validation loss: 3.924332335241982

Epoch: 6| Step: 7
Training loss: 4.556642717932438
Validation loss: 3.917560330566184

Epoch: 6| Step: 8
Training loss: 3.3485814065845014
Validation loss: 3.914537584658466

Epoch: 6| Step: 9
Training loss: 4.143943522035304
Validation loss: 3.898877059339607

Epoch: 6| Step: 10
Training loss: 3.138158332482057
Validation loss: 3.887700266091945

Epoch: 6| Step: 11
Training loss: 3.8718087376180916
Validation loss: 3.8828738185810843

Epoch: 6| Step: 12
Training loss: 3.4656353963243665
Validation loss: 3.875131536679939

Epoch: 6| Step: 13
Training loss: 5.0941510188913215
Validation loss: 3.8709100818954205

Epoch: 9| Step: 0
Training loss: 3.527306709644253
Validation loss: 3.8602913989978433

Epoch: 6| Step: 1
Training loss: 4.3340710721105475
Validation loss: 3.8527380045066613

Epoch: 6| Step: 2
Training loss: 3.9997041115995917
Validation loss: 3.8451750233286526

Epoch: 6| Step: 3
Training loss: 4.124194904712985
Validation loss: 3.8434378230990656

Epoch: 6| Step: 4
Training loss: 4.482059532263805
Validation loss: 3.833247727289355

Epoch: 6| Step: 5
Training loss: 3.8569889492027922
Validation loss: 3.821504585869002

Epoch: 6| Step: 6
Training loss: 4.517464550155768
Validation loss: 3.813848608304396

Epoch: 6| Step: 7
Training loss: 3.821636820722497
Validation loss: 3.806010632218908

Epoch: 6| Step: 8
Training loss: 4.175578213243885
Validation loss: 3.8004966298511746

Epoch: 6| Step: 9
Training loss: 3.5700918584380354
Validation loss: 3.792360243478002

Epoch: 6| Step: 10
Training loss: 4.399407884464308
Validation loss: 3.791648844195082

Epoch: 6| Step: 11
Training loss: 3.6096244164364766
Validation loss: 3.790098807092161

Epoch: 6| Step: 12
Training loss: 3.2736910992625914
Validation loss: 3.7814253004798495

Epoch: 6| Step: 13
Training loss: 3.7934295971482728
Validation loss: 3.7663844329991467

Epoch: 10| Step: 0
Training loss: 3.3752695611751817
Validation loss: 3.7605924033783373

Epoch: 6| Step: 1
Training loss: 3.588042395657028
Validation loss: 3.7633021890491327

Epoch: 6| Step: 2
Training loss: 4.562708183660038
Validation loss: 3.7652007704662447

Epoch: 6| Step: 3
Training loss: 4.746820891764425
Validation loss: 3.764547331422582

Epoch: 6| Step: 4
Training loss: 4.269486129536286
Validation loss: 3.752012140936541

Epoch: 6| Step: 5
Training loss: 4.069329023984708
Validation loss: 3.7428015608166367

Epoch: 6| Step: 6
Training loss: 3.6998732570900685
Validation loss: 3.739366598044471

Epoch: 6| Step: 7
Training loss: 3.6161626760552164
Validation loss: 3.739684989114908

Epoch: 6| Step: 8
Training loss: 3.591250138938362
Validation loss: 3.7313064501393365

Epoch: 6| Step: 9
Training loss: 4.868397080211847
Validation loss: 3.7183257602321778

Epoch: 6| Step: 10
Training loss: 3.4559474819572817
Validation loss: 3.7019052008724342

Epoch: 6| Step: 11
Training loss: 3.5039642227123053
Validation loss: 3.6917490726892828

Epoch: 6| Step: 12
Training loss: 3.1338783791124314
Validation loss: 3.6852396201521858

Epoch: 6| Step: 13
Training loss: 3.7953254457632237
Validation loss: 3.68057298496851

Epoch: 11| Step: 0
Training loss: 3.22667245007882
Validation loss: 3.679219281807472

Epoch: 6| Step: 1
Training loss: 3.1409656852297854
Validation loss: 3.6766042652040394

Epoch: 6| Step: 2
Training loss: 3.8503793752451183
Validation loss: 3.6842889474795086

Epoch: 6| Step: 3
Training loss: 4.1053674687197805
Validation loss: 3.6748385822182454

Epoch: 6| Step: 4
Training loss: 4.359258397228101
Validation loss: 3.6639712546846894

Epoch: 6| Step: 5
Training loss: 3.866000153108881
Validation loss: 3.654974470327006

Epoch: 6| Step: 6
Training loss: 3.896126163241511
Validation loss: 3.651110645019598

Epoch: 6| Step: 7
Training loss: 3.3087561701481802
Validation loss: 3.6387612648887195

Epoch: 6| Step: 8
Training loss: 3.2529283682168595
Validation loss: 3.632705960369318

Epoch: 6| Step: 9
Training loss: 4.4542532579065695
Validation loss: 3.631940644829659

Epoch: 6| Step: 10
Training loss: 4.7191877351551375
Validation loss: 3.6321676506942535

Epoch: 6| Step: 11
Training loss: 4.088748818108421
Validation loss: 3.6153500195306734

Epoch: 6| Step: 12
Training loss: 3.503680882175358
Validation loss: 3.608578270171155

Epoch: 6| Step: 13
Training loss: 3.312833949115781
Validation loss: 3.5990407782407976

Epoch: 12| Step: 0
Training loss: 3.6137259544752216
Validation loss: 3.5931655387125634

Epoch: 6| Step: 1
Training loss: 2.8637375201349227
Validation loss: 3.590198188743161

Epoch: 6| Step: 2
Training loss: 3.3839871875619587
Validation loss: 3.5882383314470823

Epoch: 6| Step: 3
Training loss: 3.021576380053234
Validation loss: 3.5900287038900016

Epoch: 6| Step: 4
Training loss: 3.6840434280304377
Validation loss: 3.6026679090494076

Epoch: 6| Step: 5
Training loss: 3.8190400358400436
Validation loss: 3.5659023647287063

Epoch: 6| Step: 6
Training loss: 4.493161197123353
Validation loss: 3.5644114155112336

Epoch: 6| Step: 7
Training loss: 4.07541423166627
Validation loss: 3.5617444414287647

Epoch: 6| Step: 8
Training loss: 4.716115456084296
Validation loss: 3.557066681115959

Epoch: 6| Step: 9
Training loss: 4.858402854112314
Validation loss: 3.5555445947999424

Epoch: 6| Step: 10
Training loss: 2.6340679492050034
Validation loss: 3.552586220936642

Epoch: 6| Step: 11
Training loss: 3.667065526480334
Validation loss: 3.5479879674518213

Epoch: 6| Step: 12
Training loss: 3.5847994592139685
Validation loss: 3.544378057576442

Epoch: 6| Step: 13
Training loss: 3.473951272037465
Validation loss: 3.5373107896659612

Epoch: 13| Step: 0
Training loss: 3.0926076918703136
Validation loss: 3.5327995313443465

Epoch: 6| Step: 1
Training loss: 4.014715069343365
Validation loss: 3.522093506895929

Epoch: 6| Step: 2
Training loss: 3.97435910798381
Validation loss: 3.5163546006794606

Epoch: 6| Step: 3
Training loss: 3.81008471917906
Validation loss: 3.5088309728779894

Epoch: 6| Step: 4
Training loss: 3.5220432948712124
Validation loss: 3.500314595107737

Epoch: 6| Step: 5
Training loss: 3.141346103763151
Validation loss: 3.495952904699281

Epoch: 6| Step: 6
Training loss: 3.5606092823144344
Validation loss: 3.4914495148974143

Epoch: 6| Step: 7
Training loss: 3.4837411894206096
Validation loss: 3.49044572033417

Epoch: 6| Step: 8
Training loss: 4.743143453508089
Validation loss: 3.4824146208125293

Epoch: 6| Step: 9
Training loss: 3.95405272201406
Validation loss: 3.4752006980074195

Epoch: 6| Step: 10
Training loss: 2.9881354003418865
Validation loss: 3.474127544314965

Epoch: 6| Step: 11
Training loss: 2.188605764746462
Validation loss: 3.4704307379878143

Epoch: 6| Step: 12
Training loss: 4.630973875640548
Validation loss: 3.4653153587852414

Epoch: 6| Step: 13
Training loss: 4.1671227523413625
Validation loss: 3.460425989991243

Epoch: 14| Step: 0
Training loss: 3.6796731158904765
Validation loss: 3.453061130467362

Epoch: 6| Step: 1
Training loss: 4.2612572969982345
Validation loss: 3.4518687726305273

Epoch: 6| Step: 2
Training loss: 4.004340201331306
Validation loss: 3.4483350670872994

Epoch: 6| Step: 3
Training loss: 3.730987672513965
Validation loss: 3.444478759457967

Epoch: 6| Step: 4
Training loss: 3.354559138933395
Validation loss: 3.4436984412666645

Epoch: 6| Step: 5
Training loss: 3.1145298845857203
Validation loss: 3.4360165106796794

Epoch: 6| Step: 6
Training loss: 3.4179070864973364
Validation loss: 3.4356775429018644

Epoch: 6| Step: 7
Training loss: 3.977827848856911
Validation loss: 3.4344504797377846

Epoch: 6| Step: 8
Training loss: 3.232074601341636
Validation loss: 3.430680680303824

Epoch: 6| Step: 9
Training loss: 3.308507132269009
Validation loss: 3.4256343332282913

Epoch: 6| Step: 10
Training loss: 3.1653206290118923
Validation loss: 3.423505029893936

Epoch: 6| Step: 11
Training loss: 3.625176524106463
Validation loss: 3.4188591090239804

Epoch: 6| Step: 12
Training loss: 4.080318869303637
Validation loss: 3.4198929830374474

Epoch: 6| Step: 13
Training loss: 4.275059143014226
Validation loss: 3.413832274914879

Epoch: 15| Step: 0
Training loss: 4.819168424931974
Validation loss: 3.4088400365552483

Epoch: 6| Step: 1
Training loss: 3.9006791330452457
Validation loss: 3.402369119999248

Epoch: 6| Step: 2
Training loss: 3.7999351947679365
Validation loss: 3.399322256548283

Epoch: 6| Step: 3
Training loss: 4.367178546712088
Validation loss: 3.3961984959097555

Epoch: 6| Step: 4
Training loss: 2.1092413965935726
Validation loss: 3.3938083395064957

Epoch: 6| Step: 5
Training loss: 3.266965891958652
Validation loss: 3.3912340069680176

Epoch: 6| Step: 6
Training loss: 3.8742630780825094
Validation loss: 3.3909018289975146

Epoch: 6| Step: 7
Training loss: 3.53013971479102
Validation loss: 3.386110383070181

Epoch: 6| Step: 8
Training loss: 2.928713542533853
Validation loss: 3.384281974814393

Epoch: 6| Step: 9
Training loss: 3.50014005108328
Validation loss: 3.3807258269870197

Epoch: 6| Step: 10
Training loss: 2.672565928574658
Validation loss: 3.37854413343337

Epoch: 6| Step: 11
Training loss: 3.288236174452354
Validation loss: 3.3739052777965517

Epoch: 6| Step: 12
Training loss: 3.9739756385889726
Validation loss: 3.374258629160218

Epoch: 6| Step: 13
Training loss: 3.8808352926089733
Validation loss: 3.3693931856111883

Epoch: 16| Step: 0
Training loss: 3.078437130976132
Validation loss: 3.369502655024599

Epoch: 6| Step: 1
Training loss: 3.680075201841796
Validation loss: 3.364359795492882

Epoch: 6| Step: 2
Training loss: 3.9839666419107256
Validation loss: 3.3637538225036514

Epoch: 6| Step: 3
Training loss: 2.947965767567196
Validation loss: 3.3581746487837942

Epoch: 6| Step: 4
Training loss: 3.810979946599214
Validation loss: 3.3530809381126003

Epoch: 6| Step: 5
Training loss: 4.164686775290465
Validation loss: 3.3533937856355753

Epoch: 6| Step: 6
Training loss: 3.29394429916787
Validation loss: 3.3497436867706734

Epoch: 6| Step: 7
Training loss: 3.520879861798852
Validation loss: 3.3495019771191927

Epoch: 6| Step: 8
Training loss: 3.269990476308597
Validation loss: 3.3476092753980264

Epoch: 6| Step: 9
Training loss: 3.279627516926316
Validation loss: 3.348974011836996

Epoch: 6| Step: 10
Training loss: 3.2753469501784034
Validation loss: 3.34229962129713

Epoch: 6| Step: 11
Training loss: 4.251680602844997
Validation loss: 3.3361767505856217

Epoch: 6| Step: 12
Training loss: 3.9740893874384087
Validation loss: 3.335255750439049

Epoch: 6| Step: 13
Training loss: 3.1734044188329906
Validation loss: 3.334173061877532

Epoch: 17| Step: 0
Training loss: 3.7536293269020713
Validation loss: 3.328734567039674

Epoch: 6| Step: 1
Training loss: 3.0602231027888758
Validation loss: 3.3281676001650538

Epoch: 6| Step: 2
Training loss: 4.394560763789781
Validation loss: 3.329433895724618

Epoch: 6| Step: 3
Training loss: 2.557466820793425
Validation loss: 3.325539873969824

Epoch: 6| Step: 4
Training loss: 3.1713582637411863
Validation loss: 3.325764907441058

Epoch: 6| Step: 5
Training loss: 2.790488853422758
Validation loss: 3.325555876160835

Epoch: 6| Step: 6
Training loss: 4.297896939908995
Validation loss: 3.3222198331735147

Epoch: 6| Step: 7
Training loss: 3.9523233799617765
Validation loss: 3.319430734137522

Epoch: 6| Step: 8
Training loss: 3.469292675560996
Validation loss: 3.3143503419682614

Epoch: 6| Step: 9
Training loss: 3.461174330347455
Validation loss: 3.315806289183741

Epoch: 6| Step: 10
Training loss: 3.6215588251434783
Validation loss: 3.317380200468393

Epoch: 6| Step: 11
Training loss: 3.726407285772779
Validation loss: 3.313145934217559

Epoch: 6| Step: 12
Training loss: 3.181947247253128
Validation loss: 3.310168799791081

Epoch: 6| Step: 13
Training loss: 4.114867278655201
Validation loss: 3.3108369503262325

Epoch: 18| Step: 0
Training loss: 3.0251753196668916
Validation loss: 3.317584193945207

Epoch: 6| Step: 1
Training loss: 3.174448256724173
Validation loss: 3.331794450199993

Epoch: 6| Step: 2
Training loss: 4.385568986121556
Validation loss: 3.3164213825594033

Epoch: 6| Step: 3
Training loss: 3.3545093874650016
Validation loss: 3.311466767139332

Epoch: 6| Step: 4
Training loss: 2.935477189323829
Validation loss: 3.31068903370099

Epoch: 6| Step: 5
Training loss: 3.8210907749873413
Validation loss: 3.31333958206913

Epoch: 6| Step: 6
Training loss: 3.1785870271547982
Validation loss: 3.321422207796957

Epoch: 6| Step: 7
Training loss: 3.3363830125976977
Validation loss: 3.312720686313176

Epoch: 6| Step: 8
Training loss: 3.5569095583215358
Validation loss: 3.313505320847042

Epoch: 6| Step: 9
Training loss: 3.2115368063354444
Validation loss: 3.3039666560597354

Epoch: 6| Step: 10
Training loss: 3.368457103445354
Validation loss: 3.302471645932431

Epoch: 6| Step: 11
Training loss: 4.462616452532862
Validation loss: 3.3014341346158895

Epoch: 6| Step: 12
Training loss: 4.398878058531303
Validation loss: 3.301852312537355

Epoch: 6| Step: 13
Training loss: 2.4605651573789458
Validation loss: 3.3007468927406807

Epoch: 19| Step: 0
Training loss: 3.0182028707039534
Validation loss: 3.2980469696465864

Epoch: 6| Step: 1
Training loss: 3.9393654900081545
Validation loss: 3.2960323642393603

Epoch: 6| Step: 2
Training loss: 4.266995946774503
Validation loss: 3.29611974067862

Epoch: 6| Step: 3
Training loss: 3.1273033808461963
Validation loss: 3.289979213735336

Epoch: 6| Step: 4
Training loss: 3.407018172412416
Validation loss: 3.289682043655959

Epoch: 6| Step: 5
Training loss: 2.9961965610415917
Validation loss: 3.284641049252958

Epoch: 6| Step: 6
Training loss: 3.332015508187463
Validation loss: 3.283356310364929

Epoch: 6| Step: 7
Training loss: 3.6772764045378876
Validation loss: 3.280491576315982

Epoch: 6| Step: 8
Training loss: 4.3603658883093335
Validation loss: 3.2798609749313283

Epoch: 6| Step: 9
Training loss: 3.205906251323165
Validation loss: 3.2799704217515036

Epoch: 6| Step: 10
Training loss: 3.7328815107325526
Validation loss: 3.277616019301748

Epoch: 6| Step: 11
Training loss: 3.389268313639872
Validation loss: 3.275201114321244

Epoch: 6| Step: 12
Training loss: 3.5195812429249758
Validation loss: 3.2708032665565048

Epoch: 6| Step: 13
Training loss: 2.6966658138687176
Validation loss: 3.2706382577814272

Epoch: 20| Step: 0
Training loss: 3.4355851822409518
Validation loss: 3.271835949954026

Epoch: 6| Step: 1
Training loss: 3.4193295282273426
Validation loss: 3.2696600704470336

Epoch: 6| Step: 2
Training loss: 3.489334203832467
Validation loss: 3.279003853132117

Epoch: 6| Step: 3
Training loss: 4.175624576837512
Validation loss: 3.277603435786939

Epoch: 6| Step: 4
Training loss: 3.5636923952775694
Validation loss: 3.282781557794756

Epoch: 6| Step: 5
Training loss: 3.2883359419175435
Validation loss: 3.2621599055877994

Epoch: 6| Step: 6
Training loss: 3.1676582156005746
Validation loss: 3.25905467037603

Epoch: 6| Step: 7
Training loss: 3.9675416082977906
Validation loss: 3.2628636834931477

Epoch: 6| Step: 8
Training loss: 3.4813594342055283
Validation loss: 3.2659536923319887

Epoch: 6| Step: 9
Training loss: 3.365813291306943
Validation loss: 3.263808303119773

Epoch: 6| Step: 10
Training loss: 2.517201279283408
Validation loss: 3.260764485234469

Epoch: 6| Step: 11
Training loss: 3.539645856395282
Validation loss: 3.259002384836239

Epoch: 6| Step: 12
Training loss: 3.430694501759709
Validation loss: 3.2586126892324776

Epoch: 6| Step: 13
Training loss: 4.422909026005321
Validation loss: 3.2561541127520077

Epoch: 21| Step: 0
Training loss: 3.33186753151421
Validation loss: 3.255799595580369

Epoch: 6| Step: 1
Training loss: 4.278583225094786
Validation loss: 3.2533311361110107

Epoch: 6| Step: 2
Training loss: 4.143533858103726
Validation loss: 3.2537650062774373

Epoch: 6| Step: 3
Training loss: 3.128106975979854
Validation loss: 3.2534876017387333

Epoch: 6| Step: 4
Training loss: 2.4650983240662945
Validation loss: 3.257940653837863

Epoch: 6| Step: 5
Training loss: 2.8216078892681082
Validation loss: 3.268614618744067

Epoch: 6| Step: 6
Training loss: 2.216567241857779
Validation loss: 3.267055342088321

Epoch: 6| Step: 7
Training loss: 3.5206045193028213
Validation loss: 3.2587988755945347

Epoch: 6| Step: 8
Training loss: 3.8732746343930504
Validation loss: 3.2436702180006605

Epoch: 6| Step: 9
Training loss: 4.055556716802655
Validation loss: 3.2555420842850316

Epoch: 6| Step: 10
Training loss: 4.055190802999345
Validation loss: 3.2478293844669133

Epoch: 6| Step: 11
Training loss: 3.347664938774095
Validation loss: 3.2508976661358804

Epoch: 6| Step: 12
Training loss: 3.430438469979235
Validation loss: 3.2511325295398747

Epoch: 6| Step: 13
Training loss: 3.756235279428895
Validation loss: 3.2543714151160823

Epoch: 22| Step: 0
Training loss: 4.315897170205641
Validation loss: 3.25296837047223

Epoch: 6| Step: 1
Training loss: 3.2175389946839825
Validation loss: 3.252208539875356

Epoch: 6| Step: 2
Training loss: 3.4840153393062843
Validation loss: 3.2514935746066125

Epoch: 6| Step: 3
Training loss: 3.6393123765313975
Validation loss: 3.246770077300187

Epoch: 6| Step: 4
Training loss: 3.3094399190988497
Validation loss: 3.2460544022523066

Epoch: 6| Step: 5
Training loss: 2.824450471481281
Validation loss: 3.241915141612056

Epoch: 6| Step: 6
Training loss: 3.9819600285085905
Validation loss: 3.239726471993947

Epoch: 6| Step: 7
Training loss: 3.5761313402263104
Validation loss: 3.237237300359212

Epoch: 6| Step: 8
Training loss: 3.075731770352665
Validation loss: 3.236621926107874

Epoch: 6| Step: 9
Training loss: 4.413290256701068
Validation loss: 3.2353572058535365

Epoch: 6| Step: 10
Training loss: 3.2053511164495103
Validation loss: 3.2295305082162655

Epoch: 6| Step: 11
Training loss: 2.5882792861152657
Validation loss: 3.2311519483601776

Epoch: 6| Step: 12
Training loss: 3.0816735276399787
Validation loss: 3.227772674140917

Epoch: 6| Step: 13
Training loss: 3.862364194389879
Validation loss: 3.2256523393405843

Epoch: 23| Step: 0
Training loss: 3.1528149031713975
Validation loss: 3.226108162983156

Epoch: 6| Step: 1
Training loss: 3.4812219149485664
Validation loss: 3.22546555425218

Epoch: 6| Step: 2
Training loss: 3.1336897004834436
Validation loss: 3.226302980899532

Epoch: 6| Step: 3
Training loss: 3.338545126275915
Validation loss: 3.223533682850358

Epoch: 6| Step: 4
Training loss: 2.8712902183522604
Validation loss: 3.222772603300836

Epoch: 6| Step: 5
Training loss: 3.7826991811526294
Validation loss: 3.2220147828356955

Epoch: 6| Step: 6
Training loss: 3.1669655374399057
Validation loss: 3.219289406120458

Epoch: 6| Step: 7
Training loss: 4.159850891081933
Validation loss: 3.2165480625688168

Epoch: 6| Step: 8
Training loss: 3.4014599919151074
Validation loss: 3.2171017004222313

Epoch: 6| Step: 9
Training loss: 3.6069911995048813
Validation loss: 3.2177731889256598

Epoch: 6| Step: 10
Training loss: 3.425356552610576
Validation loss: 3.2187194663476335

Epoch: 6| Step: 11
Training loss: 3.774761717899092
Validation loss: 3.22119289571515

Epoch: 6| Step: 12
Training loss: 3.512673457196745
Validation loss: 3.2194700478081626

Epoch: 6| Step: 13
Training loss: 3.741589588031225
Validation loss: 3.215224148788622

Epoch: 24| Step: 0
Training loss: 4.322701150815056
Validation loss: 3.2171533521075792

Epoch: 6| Step: 1
Training loss: 3.563824190018475
Validation loss: 3.213427344842023

Epoch: 6| Step: 2
Training loss: 2.919689973023543
Validation loss: 3.2116032990895027

Epoch: 6| Step: 3
Training loss: 3.650980747093774
Validation loss: 3.2142513292839805

Epoch: 6| Step: 4
Training loss: 3.2384424848185938
Validation loss: 3.2164424115657737

Epoch: 6| Step: 5
Training loss: 3.1998399217620785
Validation loss: 3.2207100882944006

Epoch: 6| Step: 6
Training loss: 3.1562717550302226
Validation loss: 3.2277521571522514

Epoch: 6| Step: 7
Training loss: 3.838870789674919
Validation loss: 3.228322323947605

Epoch: 6| Step: 8
Training loss: 3.11582576674952
Validation loss: 3.219710914167489

Epoch: 6| Step: 9
Training loss: 4.0138215642707245
Validation loss: 3.215971470155337

Epoch: 6| Step: 10
Training loss: 2.8453852384969847
Validation loss: 3.214778917584649

Epoch: 6| Step: 11
Training loss: 2.33993015543717
Validation loss: 3.20980255777372

Epoch: 6| Step: 12
Training loss: 3.9510227086586
Validation loss: 3.208439175719451

Epoch: 6| Step: 13
Training loss: 4.236139471796428
Validation loss: 3.208201076581994

Epoch: 25| Step: 0
Training loss: 3.031048640219256
Validation loss: 3.2054908784968066

Epoch: 6| Step: 1
Training loss: 3.2686910882896325
Validation loss: 3.2039380882135884

Epoch: 6| Step: 2
Training loss: 3.4892516628566717
Validation loss: 3.204827878008809

Epoch: 6| Step: 3
Training loss: 2.919604066630232
Validation loss: 3.207909795140534

Epoch: 6| Step: 4
Training loss: 3.371200542150815
Validation loss: 3.2025539270290815

Epoch: 6| Step: 5
Training loss: 4.158502871638164
Validation loss: 3.2031356071018418

Epoch: 6| Step: 6
Training loss: 3.9586121845738367
Validation loss: 3.2040682932634335

Epoch: 6| Step: 7
Training loss: 3.9759037693820294
Validation loss: 3.1992677351318473

Epoch: 6| Step: 8
Training loss: 3.3947984175465216
Validation loss: 3.198120512054869

Epoch: 6| Step: 9
Training loss: 3.827723018794066
Validation loss: 3.19466510745923

Epoch: 6| Step: 10
Training loss: 2.5757992513280397
Validation loss: 3.1937343329486096

Epoch: 6| Step: 11
Training loss: 3.0586632809585597
Validation loss: 3.1932913157905527

Epoch: 6| Step: 12
Training loss: 3.83251514548776
Validation loss: 3.2025424078303635

Epoch: 6| Step: 13
Training loss: 2.885766642768627
Validation loss: 3.2187095023870196

Epoch: 26| Step: 0
Training loss: 2.7398369868716874
Validation loss: 3.1914006446026724

Epoch: 6| Step: 1
Training loss: 3.96270676323109
Validation loss: 3.208020871985026

Epoch: 6| Step: 2
Training loss: 3.4470614537625557
Validation loss: 3.283983598846987

Epoch: 6| Step: 3
Training loss: 3.2505054080896434
Validation loss: 3.334312283420606

Epoch: 6| Step: 4
Training loss: 3.0192859939914904
Validation loss: 3.315263863977784

Epoch: 6| Step: 5
Training loss: 3.1499191092141214
Validation loss: 3.256294733235864

Epoch: 6| Step: 6
Training loss: 3.3347079939306763
Validation loss: 3.213991420716302

Epoch: 6| Step: 7
Training loss: 3.786772171440151
Validation loss: 3.1916116571635085

Epoch: 6| Step: 8
Training loss: 3.776638403032292
Validation loss: 3.192566560942127

Epoch: 6| Step: 9
Training loss: 3.311309312553468
Validation loss: 3.1963531278280146

Epoch: 6| Step: 10
Training loss: 4.0712737195006525
Validation loss: 3.2217147479041186

Epoch: 6| Step: 11
Training loss: 3.3992491005112675
Validation loss: 3.270136049080988

Epoch: 6| Step: 12
Training loss: 3.519089276234186
Validation loss: 3.2114238489948437

Epoch: 6| Step: 13
Training loss: 3.884067018042682
Validation loss: 3.199247804612185

Epoch: 27| Step: 0
Training loss: 3.72707736059442
Validation loss: 3.191178441870913

Epoch: 6| Step: 1
Training loss: 3.102110538060215
Validation loss: 3.1843534796037094

Epoch: 6| Step: 2
Training loss: 4.356947793994076
Validation loss: 3.1800994795624096

Epoch: 6| Step: 3
Training loss: 4.301420713416509
Validation loss: 3.2020458053161884

Epoch: 6| Step: 4
Training loss: 2.787339134877531
Validation loss: 3.178044270896026

Epoch: 6| Step: 5
Training loss: 3.014133064547473
Validation loss: 3.1705852581665908

Epoch: 6| Step: 6
Training loss: 3.128653107688596
Validation loss: 3.1696671539172336

Epoch: 6| Step: 7
Training loss: 3.8762362569290394
Validation loss: 3.1682104294152436

Epoch: 6| Step: 8
Training loss: 3.3132579584074335
Validation loss: 3.170385687066835

Epoch: 6| Step: 9
Training loss: 3.4529957466618524
Validation loss: 3.172787651256339

Epoch: 6| Step: 10
Training loss: 2.9018209199551337
Validation loss: 3.166842159196798

Epoch: 6| Step: 11
Training loss: 3.692224611668122
Validation loss: 3.167009750092426

Epoch: 6| Step: 12
Training loss: 2.7994211211581628
Validation loss: 3.1571668334758356

Epoch: 6| Step: 13
Training loss: 2.990918081944136
Validation loss: 3.152186896375259

Epoch: 28| Step: 0
Training loss: 2.3979214290126394
Validation loss: 3.154333376815331

Epoch: 6| Step: 1
Training loss: 3.0369872237292546
Validation loss: 3.151830793700862

Epoch: 6| Step: 2
Training loss: 3.9714905895710944
Validation loss: 3.147468979968452

Epoch: 6| Step: 3
Training loss: 4.494602357038984
Validation loss: 3.147127451004045

Epoch: 6| Step: 4
Training loss: 3.1194329074077487
Validation loss: 3.1450298684688844

Epoch: 6| Step: 5
Training loss: 3.6454747196210926
Validation loss: 3.1405619724793685

Epoch: 6| Step: 6
Training loss: 3.3880633684557724
Validation loss: 3.14374255877502

Epoch: 6| Step: 7
Training loss: 3.6154245649087877
Validation loss: 3.1389447082719037

Epoch: 6| Step: 8
Training loss: 2.796091406822022
Validation loss: 3.1410402094830476

Epoch: 6| Step: 9
Training loss: 2.8442154388165366
Validation loss: 3.140153286533078

Epoch: 6| Step: 10
Training loss: 2.844014417491053
Validation loss: 3.141430699156752

Epoch: 6| Step: 11
Training loss: 3.2814034562330376
Validation loss: 3.1410374083668575

Epoch: 6| Step: 12
Training loss: 4.176667279129004
Validation loss: 3.14364307751549

Epoch: 6| Step: 13
Training loss: 3.5321110038637973
Validation loss: 3.1501843578366477

Epoch: 29| Step: 0
Training loss: 3.850574420831433
Validation loss: 3.1358421675268353

Epoch: 6| Step: 1
Training loss: 3.258191276504053
Validation loss: 3.135045671302556

Epoch: 6| Step: 2
Training loss: 3.6631652123769882
Validation loss: 3.1351166483741326

Epoch: 6| Step: 3
Training loss: 3.7724360367172625
Validation loss: 3.131427073841207

Epoch: 6| Step: 4
Training loss: 3.1140292045777107
Validation loss: 3.1313892014174964

Epoch: 6| Step: 5
Training loss: 3.843635619407786
Validation loss: 3.129867593860305

Epoch: 6| Step: 6
Training loss: 3.4545011928223355
Validation loss: 3.1298533334854475

Epoch: 6| Step: 7
Training loss: 3.847297086266554
Validation loss: 3.12607736699823

Epoch: 6| Step: 8
Training loss: 2.8073070480878384
Validation loss: 3.127132588862617

Epoch: 6| Step: 9
Training loss: 2.623194664081662
Validation loss: 3.129976576690901

Epoch: 6| Step: 10
Training loss: 3.0160430460319327
Validation loss: 3.124567959360852

Epoch: 6| Step: 11
Training loss: 3.6630231932776165
Validation loss: 3.126708548486801

Epoch: 6| Step: 12
Training loss: 2.8747619862096334
Validation loss: 3.1282173412165646

Epoch: 6| Step: 13
Training loss: 3.493115602604526
Validation loss: 3.126974596865755

Epoch: 30| Step: 0
Training loss: 3.107055105338865
Validation loss: 3.1241406676392036

Epoch: 6| Step: 1
Training loss: 3.880582541357744
Validation loss: 3.1233880313441174

Epoch: 6| Step: 2
Training loss: 3.7416576416541147
Validation loss: 3.122735321463197

Epoch: 6| Step: 3
Training loss: 3.2592746737465657
Validation loss: 3.1203127337937473

Epoch: 6| Step: 4
Training loss: 2.500275978114384
Validation loss: 3.1238042779313506

Epoch: 6| Step: 5
Training loss: 3.2320535040760774
Validation loss: 3.120572459480359

Epoch: 6| Step: 6
Training loss: 4.089562757106378
Validation loss: 3.1225670644721935

Epoch: 6| Step: 7
Training loss: 3.0168275955297648
Validation loss: 3.12643670311785

Epoch: 6| Step: 8
Training loss: 3.495110229587584
Validation loss: 3.1228017856734933

Epoch: 6| Step: 9
Training loss: 3.088197291164422
Validation loss: 3.1227962443068518

Epoch: 6| Step: 10
Training loss: 3.799460704079686
Validation loss: 3.11875006201236

Epoch: 6| Step: 11
Training loss: 3.631316633811367
Validation loss: 3.1185164958477563

Epoch: 6| Step: 12
Training loss: 3.3208016068982396
Validation loss: 3.1153824498841654

Epoch: 6| Step: 13
Training loss: 2.5461957528914065
Validation loss: 3.114374112926996

Epoch: 31| Step: 0
Training loss: 2.6854914767013405
Validation loss: 3.1140958908252916

Epoch: 6| Step: 1
Training loss: 3.902912025963392
Validation loss: 3.1119958941044032

Epoch: 6| Step: 2
Training loss: 3.468894611815248
Validation loss: 3.1122228424660383

Epoch: 6| Step: 3
Training loss: 3.8989802959264184
Validation loss: 3.1121768003935806

Epoch: 6| Step: 4
Training loss: 3.2517265722041295
Validation loss: 3.1125197791021173

Epoch: 6| Step: 5
Training loss: 3.0940983123448222
Validation loss: 3.1124401158756334

Epoch: 6| Step: 6
Training loss: 3.160125317321957
Validation loss: 3.109384016581577

Epoch: 6| Step: 7
Training loss: 2.802763212367979
Validation loss: 3.1077910892988028

Epoch: 6| Step: 8
Training loss: 3.249442712981149
Validation loss: 3.107834678763007

Epoch: 6| Step: 9
Training loss: 3.2244881157167313
Validation loss: 3.1068244870792605

Epoch: 6| Step: 10
Training loss: 3.9129700497173947
Validation loss: 3.1048611821103282

Epoch: 6| Step: 11
Training loss: 3.6878680029394344
Validation loss: 3.1082101388788286

Epoch: 6| Step: 12
Training loss: 3.6245420758634586
Validation loss: 3.1059364586303557

Epoch: 6| Step: 13
Training loss: 2.806466561098356
Validation loss: 3.103143421923041

Epoch: 32| Step: 0
Training loss: 3.6193580129834437
Validation loss: 3.1022340322335857

Epoch: 6| Step: 1
Training loss: 2.153206820102969
Validation loss: 3.1045642462456473

Epoch: 6| Step: 2
Training loss: 4.238841498829281
Validation loss: 3.10385132932102

Epoch: 6| Step: 3
Training loss: 2.8238634067979786
Validation loss: 3.1051710796553227

Epoch: 6| Step: 4
Training loss: 3.0150272389663386
Validation loss: 3.103687904096903

Epoch: 6| Step: 5
Training loss: 3.7257488650072133
Validation loss: 3.1000868814237164

Epoch: 6| Step: 6
Training loss: 2.478835738291596
Validation loss: 3.1002279042699836

Epoch: 6| Step: 7
Training loss: 3.785949812808857
Validation loss: 3.1033060984606404

Epoch: 6| Step: 8
Training loss: 4.016918167112606
Validation loss: 3.102657757155693

Epoch: 6| Step: 9
Training loss: 2.945134084139391
Validation loss: 3.1029721197203535

Epoch: 6| Step: 10
Training loss: 3.3364813403764417
Validation loss: 3.103918523313456

Epoch: 6| Step: 11
Training loss: 3.2939681847708724
Validation loss: 3.099215541694949

Epoch: 6| Step: 12
Training loss: 3.82483590964603
Validation loss: 3.102050192415627

Epoch: 6| Step: 13
Training loss: 3.218418882060387
Validation loss: 3.0976971715637065

Epoch: 33| Step: 0
Training loss: 3.8698698971192664
Validation loss: 3.096145448287765

Epoch: 6| Step: 1
Training loss: 3.0990584327922632
Validation loss: 3.0959763821640656

Epoch: 6| Step: 2
Training loss: 3.7855510368005447
Validation loss: 3.0942314621024156

Epoch: 6| Step: 3
Training loss: 3.418650601631462
Validation loss: 3.095686181440225

Epoch: 6| Step: 4
Training loss: 3.205316454518711
Validation loss: 3.09358680106547

Epoch: 6| Step: 5
Training loss: 2.806263940177566
Validation loss: 3.0945003606781913

Epoch: 6| Step: 6
Training loss: 3.6301398834094694
Validation loss: 3.0961143977420122

Epoch: 6| Step: 7
Training loss: 3.09274583954177
Validation loss: 3.0947722047973962

Epoch: 6| Step: 8
Training loss: 3.756026194374468
Validation loss: 3.095571142485878

Epoch: 6| Step: 9
Training loss: 2.989990383885463
Validation loss: 3.0933696272271076

Epoch: 6| Step: 10
Training loss: 3.096573591144104
Validation loss: 3.089221549085617

Epoch: 6| Step: 11
Training loss: 3.4609660196959093
Validation loss: 3.08797074887026

Epoch: 6| Step: 12
Training loss: 3.3160229069340765
Validation loss: 3.0939343280390963

Epoch: 6| Step: 13
Training loss: 3.3390949681461333
Validation loss: 3.0876672651034918

Epoch: 34| Step: 0
Training loss: 3.5289454409196797
Validation loss: 3.0861619503484095

Epoch: 6| Step: 1
Training loss: 3.0732653059088357
Validation loss: 3.088661818335829

Epoch: 6| Step: 2
Training loss: 3.5490734664265227
Validation loss: 3.0875649624601773

Epoch: 6| Step: 3
Training loss: 3.249453865527919
Validation loss: 3.0869466456376666

Epoch: 6| Step: 4
Training loss: 2.820174787123227
Validation loss: 3.084801332463583

Epoch: 6| Step: 5
Training loss: 3.437167342302271
Validation loss: 3.078793643953513

Epoch: 6| Step: 6
Training loss: 3.6879204979062323
Validation loss: 3.0790417067554263

Epoch: 6| Step: 7
Training loss: 3.8104983218651993
Validation loss: 3.075197968511963

Epoch: 6| Step: 8
Training loss: 2.884984467198491
Validation loss: 3.075636140731949

Epoch: 6| Step: 9
Training loss: 3.4982024072503703
Validation loss: 3.078062771562262

Epoch: 6| Step: 10
Training loss: 2.8593328087200605
Validation loss: 3.0785860364238493

Epoch: 6| Step: 11
Training loss: 4.228169641590366
Validation loss: 3.0761301178774825

Epoch: 6| Step: 12
Training loss: 2.479685646253541
Validation loss: 3.0828769463029193

Epoch: 6| Step: 13
Training loss: 3.4088677662732842
Validation loss: 3.084470430030258

Epoch: 35| Step: 0
Training loss: 3.047874560600912
Validation loss: 3.090058194059927

Epoch: 6| Step: 1
Training loss: 3.2231613595630413
Validation loss: 3.0876446796363317

Epoch: 6| Step: 2
Training loss: 3.782005045515757
Validation loss: 3.0772511180963673

Epoch: 6| Step: 3
Training loss: 2.6518093913582295
Validation loss: 3.072503414630924

Epoch: 6| Step: 4
Training loss: 3.3931669911182176
Validation loss: 3.080882785371859

Epoch: 6| Step: 5
Training loss: 3.576874760253301
Validation loss: 3.1182240864340613

Epoch: 6| Step: 6
Training loss: 3.1033498384861056
Validation loss: 3.1285631027157987

Epoch: 6| Step: 7
Training loss: 3.902225710254907
Validation loss: 3.132978208529825

Epoch: 6| Step: 8
Training loss: 3.248916592115281
Validation loss: 3.130816265776118

Epoch: 6| Step: 9
Training loss: 3.654517260399132
Validation loss: 3.1299279175578376

Epoch: 6| Step: 10
Training loss: 3.798783564367506
Validation loss: 3.080847449517988

Epoch: 6| Step: 11
Training loss: 3.13936426469599
Validation loss: 3.0692198131721455

Epoch: 6| Step: 12
Training loss: 3.199760344591042
Validation loss: 3.0752347789676002

Epoch: 6| Step: 13
Training loss: 2.991547757674979
Validation loss: 3.107043878141416

Epoch: 36| Step: 0
Training loss: 2.241724265491882
Validation loss: 3.0930995296706247

Epoch: 6| Step: 1
Training loss: 3.536542319347824
Validation loss: 3.105501917747511

Epoch: 6| Step: 2
Training loss: 3.6959829226342884
Validation loss: 3.10293035064113

Epoch: 6| Step: 3
Training loss: 3.0686625543942916
Validation loss: 3.0882183600830317

Epoch: 6| Step: 4
Training loss: 3.312307676094309
Validation loss: 3.077483927513497

Epoch: 6| Step: 5
Training loss: 3.482704069863621
Validation loss: 3.0710153767493464

Epoch: 6| Step: 6
Training loss: 3.172662045403781
Validation loss: 3.0716023922470135

Epoch: 6| Step: 7
Training loss: 3.836288156428403
Validation loss: 3.071749883059574

Epoch: 6| Step: 8
Training loss: 2.7369894553201948
Validation loss: 3.0741674520545326

Epoch: 6| Step: 9
Training loss: 3.8411584817279394
Validation loss: 3.0778621105124753

Epoch: 6| Step: 10
Training loss: 2.925623809286135
Validation loss: 3.0727963671001697

Epoch: 6| Step: 11
Training loss: 3.6291848066528445
Validation loss: 3.0777293820789926

Epoch: 6| Step: 12
Training loss: 3.798042274918792
Validation loss: 3.0740791476005027

Epoch: 6| Step: 13
Training loss: 3.059762159092573
Validation loss: 3.075642820648819

Epoch: 37| Step: 0
Training loss: 2.6126840590475386
Validation loss: 3.0723994288857646

Epoch: 6| Step: 1
Training loss: 3.801818517929798
Validation loss: 3.0653852893067506

Epoch: 6| Step: 2
Training loss: 2.9695017615713075
Validation loss: 3.064256605882925

Epoch: 6| Step: 3
Training loss: 3.225042322162041
Validation loss: 3.063972214710884

Epoch: 6| Step: 4
Training loss: 3.1058572010392025
Validation loss: 3.0646315107660977

Epoch: 6| Step: 5
Training loss: 3.4877448102009962
Validation loss: 3.067533200601773

Epoch: 6| Step: 6
Training loss: 3.68852452415369
Validation loss: 3.064363377741301

Epoch: 6| Step: 7
Training loss: 3.5015195545182705
Validation loss: 3.07216305148152

Epoch: 6| Step: 8
Training loss: 3.5407592209292775
Validation loss: 3.0713975872819104

Epoch: 6| Step: 9
Training loss: 3.7370427390970375
Validation loss: 3.0722580949475016

Epoch: 6| Step: 10
Training loss: 3.038623454488717
Validation loss: 3.0634070085659952

Epoch: 6| Step: 11
Training loss: 3.4212110737546784
Validation loss: 3.060225280886046

Epoch: 6| Step: 12
Training loss: 3.4578037239442545
Validation loss: 3.0627281115729423

Epoch: 6| Step: 13
Training loss: 2.512064623712148
Validation loss: 3.060107770329371

Epoch: 38| Step: 0
Training loss: 3.6333122976084957
Validation loss: 3.060766337543276

Epoch: 6| Step: 1
Training loss: 3.5203914628398563
Validation loss: 3.063591865207248

Epoch: 6| Step: 2
Training loss: 3.8971770853945444
Validation loss: 3.0594559190634256

Epoch: 6| Step: 3
Training loss: 3.1463073642792083
Validation loss: 3.056949030618067

Epoch: 6| Step: 4
Training loss: 3.679990460341984
Validation loss: 3.056578032973099

Epoch: 6| Step: 5
Training loss: 2.8392489517450477
Validation loss: 3.053611733585077

Epoch: 6| Step: 6
Training loss: 3.05446895198057
Validation loss: 3.053005765503086

Epoch: 6| Step: 7
Training loss: 2.704048660438643
Validation loss: 3.0513827911374825

Epoch: 6| Step: 8
Training loss: 3.198001392414298
Validation loss: 3.051786651409436

Epoch: 6| Step: 9
Training loss: 3.0327096158106808
Validation loss: 3.051327599884352

Epoch: 6| Step: 10
Training loss: 2.885975330313434
Validation loss: 3.0511719061215663

Epoch: 6| Step: 11
Training loss: 4.1367773064493445
Validation loss: 3.052974712015545

Epoch: 6| Step: 12
Training loss: 3.136295807900352
Validation loss: 3.057723923744198

Epoch: 6| Step: 13
Training loss: 3.3691720446904507
Validation loss: 3.0543961595973776

Epoch: 39| Step: 0
Training loss: 3.210940024567514
Validation loss: 3.050004943502055

Epoch: 6| Step: 1
Training loss: 3.627775642338569
Validation loss: 3.0606114849464023

Epoch: 6| Step: 2
Training loss: 2.130380214730217
Validation loss: 3.0591131589218

Epoch: 6| Step: 3
Training loss: 3.1556394383052386
Validation loss: 3.060405883309901

Epoch: 6| Step: 4
Training loss: 3.084772358413966
Validation loss: 3.062166543653296

Epoch: 6| Step: 5
Training loss: 3.7419357055816755
Validation loss: 3.069174806588738

Epoch: 6| Step: 6
Training loss: 3.0396348272140354
Validation loss: 3.0697788815507163

Epoch: 6| Step: 7
Training loss: 3.867335831080472
Validation loss: 3.060175159964363

Epoch: 6| Step: 8
Training loss: 3.587787757524404
Validation loss: 3.047248581416672

Epoch: 6| Step: 9
Training loss: 2.991580911609781
Validation loss: 3.0454964732615495

Epoch: 6| Step: 10
Training loss: 3.9395012992065626
Validation loss: 3.046641199624767

Epoch: 6| Step: 11
Training loss: 3.5790633258104183
Validation loss: 3.0523879364584086

Epoch: 6| Step: 12
Training loss: 3.046838378686169
Validation loss: 3.0507502721879396

Epoch: 6| Step: 13
Training loss: 2.876893125116873
Validation loss: 3.0469743206032036

Epoch: 40| Step: 0
Training loss: 3.4659946254858047
Validation loss: 3.047221699339821

Epoch: 6| Step: 1
Training loss: 2.8769211362677636
Validation loss: 3.045898575533839

Epoch: 6| Step: 2
Training loss: 3.745088285212791
Validation loss: 3.0468956865902594

Epoch: 6| Step: 3
Training loss: 3.345832105155773
Validation loss: 3.0462802454774813

Epoch: 6| Step: 4
Training loss: 2.5358900703888327
Validation loss: 3.0488590895487153

Epoch: 6| Step: 5
Training loss: 3.2392382340850143
Validation loss: 3.0436431126153223

Epoch: 6| Step: 6
Training loss: 3.570856566262679
Validation loss: 3.048937896585246

Epoch: 6| Step: 7
Training loss: 3.872796570446479
Validation loss: 3.0462385339000337

Epoch: 6| Step: 8
Training loss: 3.252449726299691
Validation loss: 3.04741867343206

Epoch: 6| Step: 9
Training loss: 2.612832069282626
Validation loss: 3.0469211041643733

Epoch: 6| Step: 10
Training loss: 4.000308978545048
Validation loss: 3.0488936769772117

Epoch: 6| Step: 11
Training loss: 3.4064694955082344
Validation loss: 3.045302498888146

Epoch: 6| Step: 12
Training loss: 2.5995737900222236
Validation loss: 3.043686354811195

Epoch: 6| Step: 13
Training loss: 3.579241449346798
Validation loss: 3.0466731263063034

Epoch: 41| Step: 0
Training loss: 1.9255746107680485
Validation loss: 3.0422099279128116

Epoch: 6| Step: 1
Training loss: 2.8539393721986364
Validation loss: 3.0457389874053495

Epoch: 6| Step: 2
Training loss: 3.356349416499964
Validation loss: 3.044693469239018

Epoch: 6| Step: 3
Training loss: 3.8073193731313104
Validation loss: 3.0397324328095054

Epoch: 6| Step: 4
Training loss: 2.9488371545347913
Validation loss: 3.040192092535057

Epoch: 6| Step: 5
Training loss: 3.009715877569889
Validation loss: 3.038676386816452

Epoch: 6| Step: 6
Training loss: 2.996827037057538
Validation loss: 3.0371619336164004

Epoch: 6| Step: 7
Training loss: 3.4667908230580977
Validation loss: 3.0426505606423477

Epoch: 6| Step: 8
Training loss: 3.719014775443004
Validation loss: 3.044121120407433

Epoch: 6| Step: 9
Training loss: 2.4714446029489627
Validation loss: 3.0393777838698295

Epoch: 6| Step: 10
Training loss: 4.513243367262469
Validation loss: 3.038098915641359

Epoch: 6| Step: 11
Training loss: 3.3284169816718934
Validation loss: 3.033017876805054

Epoch: 6| Step: 12
Training loss: 3.7611719924479527
Validation loss: 3.0368640275234644

Epoch: 6| Step: 13
Training loss: 3.4156507206652518
Validation loss: 3.0366604777686916

Epoch: 42| Step: 0
Training loss: 2.658273801067232
Validation loss: 3.0363259879848257

Epoch: 6| Step: 1
Training loss: 2.7285961884692655
Validation loss: 3.0387086519672817

Epoch: 6| Step: 2
Training loss: 3.190097423727993
Validation loss: 3.038250635958603

Epoch: 6| Step: 3
Training loss: 3.259416729521865
Validation loss: 3.038446113503419

Epoch: 6| Step: 4
Training loss: 3.8275118589809294
Validation loss: 3.0385164750513276

Epoch: 6| Step: 5
Training loss: 3.558387926265075
Validation loss: 3.038191551632927

Epoch: 6| Step: 6
Training loss: 3.277389435114389
Validation loss: 3.0374313031406612

Epoch: 6| Step: 7
Training loss: 3.731458730306614
Validation loss: 3.0336505893240364

Epoch: 6| Step: 8
Training loss: 3.599046469610733
Validation loss: 3.0305211322404544

Epoch: 6| Step: 9
Training loss: 3.275248825288502
Validation loss: 3.030979866294115

Epoch: 6| Step: 10
Training loss: 2.7039092585500906
Validation loss: 3.02710183872385

Epoch: 6| Step: 11
Training loss: 3.6680784686398966
Validation loss: 3.0273767337861286

Epoch: 6| Step: 12
Training loss: 3.42737461386619
Validation loss: 3.0281369286762807

Epoch: 6| Step: 13
Training loss: 2.88246826763172
Validation loss: 3.028520901369787

Epoch: 43| Step: 0
Training loss: 2.4173748907874972
Validation loss: 3.0327837554236736

Epoch: 6| Step: 1
Training loss: 3.995720242732055
Validation loss: 3.0338997304530686

Epoch: 6| Step: 2
Training loss: 4.039415237105945
Validation loss: 3.0368723848312458

Epoch: 6| Step: 3
Training loss: 2.713392393920612
Validation loss: 3.0329789953246578

Epoch: 6| Step: 4
Training loss: 3.6460056082577244
Validation loss: 3.0289629880366613

Epoch: 6| Step: 5
Training loss: 3.4012268545645314
Validation loss: 3.027573588283845

Epoch: 6| Step: 6
Training loss: 3.191850572936655
Validation loss: 3.031048285831842

Epoch: 6| Step: 7
Training loss: 3.5797266145031967
Validation loss: 3.0346886012754872

Epoch: 6| Step: 8
Training loss: 3.5236624161687393
Validation loss: 3.027133631035179

Epoch: 6| Step: 9
Training loss: 3.0009876850591146
Validation loss: 3.0275994729050755

Epoch: 6| Step: 10
Training loss: 3.315867889165435
Validation loss: 3.02372529493562

Epoch: 6| Step: 11
Training loss: 2.9264119058082128
Validation loss: 3.0225757522798182

Epoch: 6| Step: 12
Training loss: 2.9434491240671514
Validation loss: 3.0256464129983414

Epoch: 6| Step: 13
Training loss: 2.9049310460007556
Validation loss: 3.0219602667380254

Epoch: 44| Step: 0
Training loss: 3.7627638714799323
Validation loss: 3.022833282136387

Epoch: 6| Step: 1
Training loss: 3.278074926352099
Validation loss: 3.022252033066209

Epoch: 6| Step: 2
Training loss: 3.217217237826985
Validation loss: 3.0216283163041955

Epoch: 6| Step: 3
Training loss: 2.8780073939182715
Validation loss: 3.0202542545926305

Epoch: 6| Step: 4
Training loss: 2.7992412424634465
Validation loss: 3.0208582610112056

Epoch: 6| Step: 5
Training loss: 2.7184234072202313
Validation loss: 3.020325307309264

Epoch: 6| Step: 6
Training loss: 3.6332449706878847
Validation loss: 3.020203299728379

Epoch: 6| Step: 7
Training loss: 3.613004106770031
Validation loss: 3.019603510875244

Epoch: 6| Step: 8
Training loss: 2.4728457120653387
Validation loss: 3.0167095349432445

Epoch: 6| Step: 9
Training loss: 3.66240467559396
Validation loss: 3.015914152474299

Epoch: 6| Step: 10
Training loss: 3.6201613129982078
Validation loss: 3.0179260272118777

Epoch: 6| Step: 11
Training loss: 3.8774776536308675
Validation loss: 3.017465024865507

Epoch: 6| Step: 12
Training loss: 3.3018112471644794
Validation loss: 3.016261007400226

Epoch: 6| Step: 13
Training loss: 2.541716236402404
Validation loss: 3.0140338593353615

Epoch: 45| Step: 0
Training loss: 3.5049834876004837
Validation loss: 3.0169127100227096

Epoch: 6| Step: 1
Training loss: 3.5855703394465226
Validation loss: 3.0170824559684126

Epoch: 6| Step: 2
Training loss: 2.9135388269411737
Validation loss: 3.0208460370830252

Epoch: 6| Step: 3
Training loss: 3.3906655023502577
Validation loss: 3.018669334928243

Epoch: 6| Step: 4
Training loss: 4.321903094616182
Validation loss: 3.018011105629972

Epoch: 6| Step: 5
Training loss: 2.581214117581256
Validation loss: 3.0155926000839703

Epoch: 6| Step: 6
Training loss: 3.1474544230366184
Validation loss: 3.013999069203816

Epoch: 6| Step: 7
Training loss: 2.417590479927834
Validation loss: 3.0151814517061997

Epoch: 6| Step: 8
Training loss: 3.413707164717752
Validation loss: 3.0099510386021895

Epoch: 6| Step: 9
Training loss: 3.2605716721288855
Validation loss: 3.0144437031596536

Epoch: 6| Step: 10
Training loss: 3.6918226864971664
Validation loss: 3.0124992635095693

Epoch: 6| Step: 11
Training loss: 3.2419523222780926
Validation loss: 3.0118190814159695

Epoch: 6| Step: 12
Training loss: 3.1352103705146823
Validation loss: 3.0153965830297795

Epoch: 6| Step: 13
Training loss: 2.771295284302164
Validation loss: 3.01154349025044

Epoch: 46| Step: 0
Training loss: 2.30264243216574
Validation loss: 3.011722248519539

Epoch: 6| Step: 1
Training loss: 3.3530996927833288
Validation loss: 3.0085607349397363

Epoch: 6| Step: 2
Training loss: 3.343707218074734
Validation loss: 3.0082044989773755

Epoch: 6| Step: 3
Training loss: 3.3969446871714934
Validation loss: 3.00818042718201

Epoch: 6| Step: 4
Training loss: 3.427869310467299
Validation loss: 3.0093545290038017

Epoch: 6| Step: 5
Training loss: 2.7705078985559117
Validation loss: 3.0096223685062085

Epoch: 6| Step: 6
Training loss: 3.4170125615640092
Validation loss: 3.010171890455557

Epoch: 6| Step: 7
Training loss: 3.7584329517185053
Validation loss: 3.0124848270897924

Epoch: 6| Step: 8
Training loss: 3.3000312630299575
Validation loss: 3.0116107437653654

Epoch: 6| Step: 9
Training loss: 3.701369758892107
Validation loss: 3.008553244836919

Epoch: 6| Step: 10
Training loss: 3.768051821690464
Validation loss: 3.0132091923262494

Epoch: 6| Step: 11
Training loss: 3.065286264166305
Validation loss: 3.0063311543568103

Epoch: 6| Step: 12
Training loss: 3.112808555414408
Validation loss: 3.007131479890538

Epoch: 6| Step: 13
Training loss: 2.84835074371618
Validation loss: 3.0068744357388812

Epoch: 47| Step: 0
Training loss: 3.2218066766045372
Validation loss: 3.0077925520662796

Epoch: 6| Step: 1
Training loss: 2.7240837656661228
Validation loss: 3.006448528461264

Epoch: 6| Step: 2
Training loss: 3.281591633768265
Validation loss: 3.0083840692085877

Epoch: 6| Step: 3
Training loss: 2.664540178090159
Validation loss: 3.0041644526816196

Epoch: 6| Step: 4
Training loss: 3.6590759572133424
Validation loss: 3.0084043217019065

Epoch: 6| Step: 5
Training loss: 3.177716968491048
Validation loss: 3.009393618598952

Epoch: 6| Step: 6
Training loss: 2.453699518462743
Validation loss: 3.006953536588448

Epoch: 6| Step: 7
Training loss: 3.791967917970558
Validation loss: 3.0069464645057504

Epoch: 6| Step: 8
Training loss: 2.6056204641572154
Validation loss: 3.0063553884833363

Epoch: 6| Step: 9
Training loss: 3.797146006515921
Validation loss: 3.006187003357839

Epoch: 6| Step: 10
Training loss: 2.610972663464543
Validation loss: 3.011729640511934

Epoch: 6| Step: 11
Training loss: 3.876315970156236
Validation loss: 3.0083014983669023

Epoch: 6| Step: 12
Training loss: 3.8793436132297994
Validation loss: 3.0044070384237447

Epoch: 6| Step: 13
Training loss: 3.839843253274383
Validation loss: 2.999894039443074

Epoch: 48| Step: 0
Training loss: 3.2399618207777783
Validation loss: 3.000163318263037

Epoch: 6| Step: 1
Training loss: 2.7385664721952314
Validation loss: 2.9994715512310375

Epoch: 6| Step: 2
Training loss: 3.274680400134105
Validation loss: 2.9994762742853345

Epoch: 6| Step: 3
Training loss: 2.838659068254963
Validation loss: 3.0026752770268614

Epoch: 6| Step: 4
Training loss: 3.547752507089876
Validation loss: 3.001447675264392

Epoch: 6| Step: 5
Training loss: 2.34011029236229
Validation loss: 3.0044663946314842

Epoch: 6| Step: 6
Training loss: 3.3453956903682225
Validation loss: 3.003918481414607

Epoch: 6| Step: 7
Training loss: 2.666801320093657
Validation loss: 3.0017736824860277

Epoch: 6| Step: 8
Training loss: 3.782489289787343
Validation loss: 2.9987673303551943

Epoch: 6| Step: 9
Training loss: 3.5941374196744214
Validation loss: 2.9959704244615963

Epoch: 6| Step: 10
Training loss: 3.820254335175186
Validation loss: 2.997487804033577

Epoch: 6| Step: 11
Training loss: 3.276971116097874
Validation loss: 2.993819631771701

Epoch: 6| Step: 12
Training loss: 3.256567408345053
Validation loss: 2.9936454016690495

Epoch: 6| Step: 13
Training loss: 4.0836642124773865
Validation loss: 2.9947087735567695

Epoch: 49| Step: 0
Training loss: 3.6492265587283987
Validation loss: 2.995703669819015

Epoch: 6| Step: 1
Training loss: 3.838601114062051
Validation loss: 2.995744781700646

Epoch: 6| Step: 2
Training loss: 2.5967239427758493
Validation loss: 2.992879504743252

Epoch: 6| Step: 3
Training loss: 3.894948739925278
Validation loss: 2.996972614283581

Epoch: 6| Step: 4
Training loss: 2.7675936314182747
Validation loss: 2.9976435031983484

Epoch: 6| Step: 5
Training loss: 3.313601328746284
Validation loss: 2.998891553886934

Epoch: 6| Step: 6
Training loss: 3.3130115617849127
Validation loss: 3.0037244456395653

Epoch: 6| Step: 7
Training loss: 2.3496499632820145
Validation loss: 3.0164513921832286

Epoch: 6| Step: 8
Training loss: 2.831322648419485
Validation loss: 3.0017068632086055

Epoch: 6| Step: 9
Training loss: 3.1748200072684822
Validation loss: 2.99750073814915

Epoch: 6| Step: 10
Training loss: 2.9222496730867245
Validation loss: 2.99434467562721

Epoch: 6| Step: 11
Training loss: 3.784506160312255
Validation loss: 2.988657474661254

Epoch: 6| Step: 12
Training loss: 3.7325930633491913
Validation loss: 2.9910731245750144

Epoch: 6| Step: 13
Training loss: 2.9323179922508786
Validation loss: 2.9872310892058

Epoch: 50| Step: 0
Training loss: 3.291705811344249
Validation loss: 2.9906728590770038

Epoch: 6| Step: 1
Training loss: 3.3280906138188397
Validation loss: 2.9890829597045108

Epoch: 6| Step: 2
Training loss: 2.7719437135869023
Validation loss: 2.9881091138051676

Epoch: 6| Step: 3
Training loss: 2.3915648763264237
Validation loss: 2.9900735144035724

Epoch: 6| Step: 4
Training loss: 3.786904890688839
Validation loss: 2.9904636088813072

Epoch: 6| Step: 5
Training loss: 3.9971171958144027
Validation loss: 2.9884931055592423

Epoch: 6| Step: 6
Training loss: 3.4688617585195347
Validation loss: 2.9863164361976495

Epoch: 6| Step: 7
Training loss: 3.0766452388768064
Validation loss: 2.9839327106002242

Epoch: 6| Step: 8
Training loss: 3.12991038770029
Validation loss: 2.983876264024783

Epoch: 6| Step: 9
Training loss: 2.753148357452484
Validation loss: 2.9835621970871506

Epoch: 6| Step: 10
Training loss: 1.857950899376684
Validation loss: 2.9852763221928638

Epoch: 6| Step: 11
Training loss: 3.761176556484725
Validation loss: 2.982521609086819

Epoch: 6| Step: 12
Training loss: 3.5403112772494083
Validation loss: 2.983577567400399

Epoch: 6| Step: 13
Training loss: 4.170735750127032
Validation loss: 2.9817531506535806

Epoch: 51| Step: 0
Training loss: 3.5303478607732703
Validation loss: 2.982927057574361

Epoch: 6| Step: 1
Training loss: 3.662210285068036
Validation loss: 2.985365577103001

Epoch: 6| Step: 2
Training loss: 3.4777698263524988
Validation loss: 2.984839709613177

Epoch: 6| Step: 3
Training loss: 2.816535512891616
Validation loss: 2.9834071920572676

Epoch: 6| Step: 4
Training loss: 3.086511795107923
Validation loss: 2.980165742728945

Epoch: 6| Step: 5
Training loss: 3.8495574746390417
Validation loss: 2.981913601225306

Epoch: 6| Step: 6
Training loss: 3.355132364768882
Validation loss: 2.981715387320622

Epoch: 6| Step: 7
Training loss: 3.0369751339404085
Validation loss: 2.978812669035897

Epoch: 6| Step: 8
Training loss: 2.9637128962620056
Validation loss: 2.9771771823223423

Epoch: 6| Step: 9
Training loss: 3.0688137444054115
Validation loss: 2.978754583167472

Epoch: 6| Step: 10
Training loss: 3.1514998846306734
Validation loss: 2.976995890749952

Epoch: 6| Step: 11
Training loss: 2.36146745672989
Validation loss: 2.9772178224153616

Epoch: 6| Step: 12
Training loss: 2.9930679977956918
Validation loss: 2.977548190735024

Epoch: 6| Step: 13
Training loss: 4.342504748230371
Validation loss: 2.976183978037032

Epoch: 52| Step: 0
Training loss: 2.533191454411243
Validation loss: 2.975884497259056

Epoch: 6| Step: 1
Training loss: 3.899809387635208
Validation loss: 2.9779040960394605

Epoch: 6| Step: 2
Training loss: 4.445000555426753
Validation loss: 2.975036639964013

Epoch: 6| Step: 3
Training loss: 3.321013971167826
Validation loss: 2.975424161754526

Epoch: 6| Step: 4
Training loss: 3.3442071619979523
Validation loss: 2.9737201305995344

Epoch: 6| Step: 5
Training loss: 3.468028637909701
Validation loss: 2.976006253472439

Epoch: 6| Step: 6
Training loss: 3.181112733888569
Validation loss: 2.9726815805211215

Epoch: 6| Step: 7
Training loss: 2.5195021043614623
Validation loss: 2.9731122327560344

Epoch: 6| Step: 8
Training loss: 3.2111546055518465
Validation loss: 2.9733545851264123

Epoch: 6| Step: 9
Training loss: 2.9986360946336172
Validation loss: 2.975722570610218

Epoch: 6| Step: 10
Training loss: 2.9557973890231475
Validation loss: 2.9708864358102747

Epoch: 6| Step: 11
Training loss: 3.5075490466037755
Validation loss: 2.973220101413714

Epoch: 6| Step: 12
Training loss: 2.8749258612320014
Validation loss: 2.9720448627698848

Epoch: 6| Step: 13
Training loss: 2.3343402415679084
Validation loss: 2.9721673783351217

Epoch: 53| Step: 0
Training loss: 3.0358945520556495
Validation loss: 2.9719075266129034

Epoch: 6| Step: 1
Training loss: 3.3014669394576015
Validation loss: 2.975755063472043

Epoch: 6| Step: 2
Training loss: 2.8589357132463795
Validation loss: 2.9765511750656697

Epoch: 6| Step: 3
Training loss: 3.4542068926988665
Validation loss: 2.9734475336635215

Epoch: 6| Step: 4
Training loss: 3.095093868724078
Validation loss: 2.993817275202945

Epoch: 6| Step: 5
Training loss: 2.6897155146149836
Validation loss: 2.9914258575891672

Epoch: 6| Step: 6
Training loss: 2.782946380016444
Validation loss: 3.0002801159347516

Epoch: 6| Step: 7
Training loss: 3.3701149236626704
Validation loss: 2.9995113046546105

Epoch: 6| Step: 8
Training loss: 3.730698950889821
Validation loss: 3.0088848689564154

Epoch: 6| Step: 9
Training loss: 3.681814433480184
Validation loss: 2.982352136175237

Epoch: 6| Step: 10
Training loss: 3.3479846984622994
Validation loss: 2.972865552348047

Epoch: 6| Step: 11
Training loss: 3.4089521137073495
Validation loss: 2.968702451263625

Epoch: 6| Step: 12
Training loss: 3.3116455415596833
Validation loss: 2.966545473835397

Epoch: 6| Step: 13
Training loss: 3.2689523492037544
Validation loss: 2.9677328857628984

Epoch: 54| Step: 0
Training loss: 3.730692687977516
Validation loss: 2.967410255806566

Epoch: 6| Step: 1
Training loss: 3.5744690187311936
Validation loss: 2.971557236374735

Epoch: 6| Step: 2
Training loss: 3.4438938671599213
Validation loss: 2.971260269411452

Epoch: 6| Step: 3
Training loss: 2.698069171694644
Validation loss: 2.9687190323549215

Epoch: 6| Step: 4
Training loss: 2.8913226961000738
Validation loss: 2.970066247237617

Epoch: 6| Step: 5
Training loss: 3.722428369902526
Validation loss: 2.9678580739903144

Epoch: 6| Step: 6
Training loss: 3.0619646499755993
Validation loss: 2.968416084029285

Epoch: 6| Step: 7
Training loss: 2.915405454884385
Validation loss: 2.968951766665673

Epoch: 6| Step: 8
Training loss: 3.309648546074818
Validation loss: 2.9677261253584963

Epoch: 6| Step: 9
Training loss: 3.975859274448084
Validation loss: 2.968427846772541

Epoch: 6| Step: 10
Training loss: 3.1375536727873805
Validation loss: 2.967197323489615

Epoch: 6| Step: 11
Training loss: 2.765345758683637
Validation loss: 2.9656218562974

Epoch: 6| Step: 12
Training loss: 3.0190066021205486
Validation loss: 2.963389304388589

Epoch: 6| Step: 13
Training loss: 2.700122643263778
Validation loss: 2.962975027189111

Epoch: 55| Step: 0
Training loss: 3.5683848980939294
Validation loss: 2.963152156852409

Epoch: 6| Step: 1
Training loss: 2.549787482587493
Validation loss: 2.9613132137242055

Epoch: 6| Step: 2
Training loss: 3.7810559183549572
Validation loss: 2.960464038377348

Epoch: 6| Step: 3
Training loss: 3.5058059220768403
Validation loss: 2.961279333075109

Epoch: 6| Step: 4
Training loss: 2.879877017362345
Validation loss: 2.9595999293334185

Epoch: 6| Step: 5
Training loss: 3.891788906053645
Validation loss: 2.9614405786769686

Epoch: 6| Step: 6
Training loss: 2.59369447947449
Validation loss: 2.9601238493325774

Epoch: 6| Step: 7
Training loss: 3.3224933956588654
Validation loss: 2.9605924434649067

Epoch: 6| Step: 8
Training loss: 3.1172098335861906
Validation loss: 2.95850729672751

Epoch: 6| Step: 9
Training loss: 2.834403639946263
Validation loss: 2.957025862678706

Epoch: 6| Step: 10
Training loss: 3.205269147072642
Validation loss: 2.9564410606161813

Epoch: 6| Step: 11
Training loss: 3.446202861586649
Validation loss: 2.9652810295850327

Epoch: 6| Step: 12
Training loss: 2.868439528342682
Validation loss: 2.9626740138983623

Epoch: 6| Step: 13
Training loss: 3.694601042893522
Validation loss: 2.9614490155188973

Epoch: 56| Step: 0
Training loss: 3.2902583397077807
Validation loss: 2.9637746772114686

Epoch: 6| Step: 1
Training loss: 3.228420803110711
Validation loss: 2.9641034198525764

Epoch: 6| Step: 2
Training loss: 3.414159428597592
Validation loss: 2.9697496165824635

Epoch: 6| Step: 3
Training loss: 3.585150871347635
Validation loss: 2.9722214855548033

Epoch: 6| Step: 4
Training loss: 3.095635196169153
Validation loss: 2.971667508006761

Epoch: 6| Step: 5
Training loss: 3.199639335811532
Validation loss: 2.9666289217092747

Epoch: 6| Step: 6
Training loss: 3.9353949354200135
Validation loss: 2.969667938924188

Epoch: 6| Step: 7
Training loss: 2.6217133973506526
Validation loss: 2.9701229191544503

Epoch: 6| Step: 8
Training loss: 3.5195618690572936
Validation loss: 2.9664038307238214

Epoch: 6| Step: 9
Training loss: 2.729970294385552
Validation loss: 2.962286454616145

Epoch: 6| Step: 10
Training loss: 3.232219917926278
Validation loss: 2.953817312120845

Epoch: 6| Step: 11
Training loss: 2.6791356355364084
Validation loss: 2.954596387356885

Epoch: 6| Step: 12
Training loss: 3.127017171228862
Validation loss: 2.9541131566077024

Epoch: 6| Step: 13
Training loss: 3.6397973949512554
Validation loss: 2.950536979057151

Epoch: 57| Step: 0
Training loss: 3.465028295580335
Validation loss: 2.953552111901826

Epoch: 6| Step: 1
Training loss: 3.358072853556772
Validation loss: 2.9559917530451147

Epoch: 6| Step: 2
Training loss: 2.4170884608351515
Validation loss: 2.9561579596494902

Epoch: 6| Step: 3
Training loss: 3.483825914030088
Validation loss: 2.955213280757653

Epoch: 6| Step: 4
Training loss: 2.8655057959270818
Validation loss: 2.9553706042124666

Epoch: 6| Step: 5
Training loss: 3.3844548350716175
Validation loss: 2.9552862737126495

Epoch: 6| Step: 6
Training loss: 3.5562422821014805
Validation loss: 2.9559913185432083

Epoch: 6| Step: 7
Training loss: 3.711614607223346
Validation loss: 2.9537964353965083

Epoch: 6| Step: 8
Training loss: 2.6894187287878553
Validation loss: 2.952951436916905

Epoch: 6| Step: 9
Training loss: 3.4891419240655677
Validation loss: 2.952346140853952

Epoch: 6| Step: 10
Training loss: 3.636562979176034
Validation loss: 2.95161510420153

Epoch: 6| Step: 11
Training loss: 2.624577806217349
Validation loss: 2.952135615571501

Epoch: 6| Step: 12
Training loss: 2.777498951799279
Validation loss: 2.9528585108520677

Epoch: 6| Step: 13
Training loss: 3.733057659620498
Validation loss: 2.9520558170281492

Epoch: 58| Step: 0
Training loss: 3.3551919132380794
Validation loss: 2.9509522717859262

Epoch: 6| Step: 1
Training loss: 3.0983037861083256
Validation loss: 2.948867119945504

Epoch: 6| Step: 2
Training loss: 3.9131850060378555
Validation loss: 2.949884222813184

Epoch: 6| Step: 3
Training loss: 2.883499518513329
Validation loss: 2.950340557793527

Epoch: 6| Step: 4
Training loss: 2.3668496674541113
Validation loss: 2.949880449331271

Epoch: 6| Step: 5
Training loss: 2.8296730483479666
Validation loss: 2.953626230864243

Epoch: 6| Step: 6
Training loss: 3.019585257339619
Validation loss: 2.960095426885891

Epoch: 6| Step: 7
Training loss: 3.2342549914518868
Validation loss: 2.9624919213321173

Epoch: 6| Step: 8
Training loss: 4.0027427806525875
Validation loss: 2.9545872905983854

Epoch: 6| Step: 9
Training loss: 3.6369529181624918
Validation loss: 2.9572033963635276

Epoch: 6| Step: 10
Training loss: 3.5197767368950963
Validation loss: 2.9514782202027887

Epoch: 6| Step: 11
Training loss: 3.0443279869037934
Validation loss: 2.9474910537689865

Epoch: 6| Step: 12
Training loss: 2.9412744500164933
Validation loss: 2.944326627934247

Epoch: 6| Step: 13
Training loss: 2.885919648731251
Validation loss: 2.944269381120031

Epoch: 59| Step: 0
Training loss: 3.0467994093688175
Validation loss: 2.9438874933077863

Epoch: 6| Step: 1
Training loss: 3.1249771117325866
Validation loss: 2.944087582649002

Epoch: 6| Step: 2
Training loss: 2.93988638184733
Validation loss: 2.943392164158748

Epoch: 6| Step: 3
Training loss: 3.4813646390109523
Validation loss: 2.9419783397976498

Epoch: 6| Step: 4
Training loss: 2.665631321746378
Validation loss: 2.940311631036895

Epoch: 6| Step: 5
Training loss: 3.4133730264183653
Validation loss: 2.9401995512617622

Epoch: 6| Step: 6
Training loss: 3.850053410345395
Validation loss: 2.9420126318114943

Epoch: 6| Step: 7
Training loss: 3.0254358592385824
Validation loss: 2.945875170514276

Epoch: 6| Step: 8
Training loss: 3.2865279120300706
Validation loss: 2.9406611055677945

Epoch: 6| Step: 9
Training loss: 2.8471803202039796
Validation loss: 2.940614627429579

Epoch: 6| Step: 10
Training loss: 3.6776547658836014
Validation loss: 2.9413223846223664

Epoch: 6| Step: 11
Training loss: 2.59333200418721
Validation loss: 2.94129448474768

Epoch: 6| Step: 12
Training loss: 3.5783462122872116
Validation loss: 2.944621020427317

Epoch: 6| Step: 13
Training loss: 3.466932765822605
Validation loss: 2.941265746118336

Epoch: 60| Step: 0
Training loss: 3.4090805192268876
Validation loss: 2.9398048921639637

Epoch: 6| Step: 1
Training loss: 2.3457265022123
Validation loss: 2.9405667981101384

Epoch: 6| Step: 2
Training loss: 2.4898148007441026
Validation loss: 2.9394517679360908

Epoch: 6| Step: 3
Training loss: 3.0593787655987423
Validation loss: 2.937877385550847

Epoch: 6| Step: 4
Training loss: 2.8552710259861387
Validation loss: 2.94080598923323

Epoch: 6| Step: 5
Training loss: 3.752337934945005
Validation loss: 2.9394000586247753

Epoch: 6| Step: 6
Training loss: 2.5657514087978295
Validation loss: 2.940269484241451

Epoch: 6| Step: 7
Training loss: 3.7700999409104696
Validation loss: 2.938819287031338

Epoch: 6| Step: 8
Training loss: 3.3724157541440274
Validation loss: 2.9383180675238347

Epoch: 6| Step: 9
Training loss: 3.814841880071347
Validation loss: 2.938024051291465

Epoch: 6| Step: 10
Training loss: 2.9257532176978187
Validation loss: 2.93728296354779

Epoch: 6| Step: 11
Training loss: 3.6426019499053286
Validation loss: 2.9370851714726807

Epoch: 6| Step: 12
Training loss: 3.4919998835403057
Validation loss: 2.9368799288675205

Epoch: 6| Step: 13
Training loss: 3.0676416326157177
Validation loss: 2.9381322012413817

Epoch: 61| Step: 0
Training loss: 2.3354660119711674
Validation loss: 2.936159542396773

Epoch: 6| Step: 1
Training loss: 3.33030808177797
Validation loss: 2.9336260995118573

Epoch: 6| Step: 2
Training loss: 3.027493065874143
Validation loss: 2.940031696080638

Epoch: 6| Step: 3
Training loss: 2.9665107714664654
Validation loss: 2.9405190674016533

Epoch: 6| Step: 4
Training loss: 3.435936867166125
Validation loss: 2.9454231832203326

Epoch: 6| Step: 5
Training loss: 3.5983121358987127
Validation loss: 2.9381766341802824

Epoch: 6| Step: 6
Training loss: 3.073827696846377
Validation loss: 2.9333697195350674

Epoch: 6| Step: 7
Training loss: 2.87655348892914
Validation loss: 2.9322393251637457

Epoch: 6| Step: 8
Training loss: 3.9012485070731433
Validation loss: 2.930820256271741

Epoch: 6| Step: 9
Training loss: 3.9556164033784
Validation loss: 2.931501601480554

Epoch: 6| Step: 10
Training loss: 3.0783827620501483
Validation loss: 2.930066739602169

Epoch: 6| Step: 11
Training loss: 3.0280869488446305
Validation loss: 2.9313398573121034

Epoch: 6| Step: 12
Training loss: 2.9711655276322677
Validation loss: 2.9308604422812263

Epoch: 6| Step: 13
Training loss: 3.0553961124627906
Validation loss: 2.9318476701639957

Epoch: 62| Step: 0
Training loss: 2.9524228507612635
Validation loss: 2.934552920819593

Epoch: 6| Step: 1
Training loss: 3.6656724853561946
Validation loss: 2.9405691136592536

Epoch: 6| Step: 2
Training loss: 3.33901199781028
Validation loss: 2.9414270438369923

Epoch: 6| Step: 3
Training loss: 2.6863692810358404
Validation loss: 2.9462286995497817

Epoch: 6| Step: 4
Training loss: 3.181706567763534
Validation loss: 2.937661860537617

Epoch: 6| Step: 5
Training loss: 3.5249109676290993
Validation loss: 2.9350552217763095

Epoch: 6| Step: 6
Training loss: 2.779938292058622
Validation loss: 2.92565481160599

Epoch: 6| Step: 7
Training loss: 2.950546834662205
Validation loss: 2.9251351700310497

Epoch: 6| Step: 8
Training loss: 3.0204928151401846
Validation loss: 2.926834713933975

Epoch: 6| Step: 9
Training loss: 3.7136374840629114
Validation loss: 2.9307911892552356

Epoch: 6| Step: 10
Training loss: 3.26035127584353
Validation loss: 2.9285975935246884

Epoch: 6| Step: 11
Training loss: 3.4678189514490656
Validation loss: 2.9289981932983644

Epoch: 6| Step: 12
Training loss: 2.609684086385017
Validation loss: 2.9263077652384695

Epoch: 6| Step: 13
Training loss: 3.8146692577096815
Validation loss: 2.9267052911498923

Epoch: 63| Step: 0
Training loss: 3.49645025897011
Validation loss: 2.926043267887877

Epoch: 6| Step: 1
Training loss: 3.473630341579104
Validation loss: 2.925840995620286

Epoch: 6| Step: 2
Training loss: 3.311769512891644
Validation loss: 2.923366064180577

Epoch: 6| Step: 3
Training loss: 3.132149718992152
Validation loss: 2.923977562859586

Epoch: 6| Step: 4
Training loss: 3.2601842502878875
Validation loss: 2.9232864537381307

Epoch: 6| Step: 5
Training loss: 2.751337766378332
Validation loss: 2.927175320204016

Epoch: 6| Step: 6
Training loss: 3.8368751638474268
Validation loss: 2.9251301744451195

Epoch: 6| Step: 7
Training loss: 2.158689915230061
Validation loss: 2.922403391875164

Epoch: 6| Step: 8
Training loss: 3.340458613677892
Validation loss: 2.926133744317621

Epoch: 6| Step: 9
Training loss: 3.4464011342998684
Validation loss: 2.9256584463392157

Epoch: 6| Step: 10
Training loss: 2.880541891933968
Validation loss: 2.9242963985352284

Epoch: 6| Step: 11
Training loss: 2.738257567212137
Validation loss: 2.9235404909913063

Epoch: 6| Step: 12
Training loss: 3.4239356398906335
Validation loss: 2.922826524622618

Epoch: 6| Step: 13
Training loss: 3.3843194366994354
Validation loss: 2.9191977445561044

Epoch: 64| Step: 0
Training loss: 3.0696992916986314
Validation loss: 2.919312036588371

Epoch: 6| Step: 1
Training loss: 2.79671456500181
Validation loss: 2.9203458114925205

Epoch: 6| Step: 2
Training loss: 3.39647735542331
Validation loss: 2.9222548139619375

Epoch: 6| Step: 3
Training loss: 3.0863644075258643
Validation loss: 2.9251968183648334

Epoch: 6| Step: 4
Training loss: 3.2243854853945195
Validation loss: 2.922074083081776

Epoch: 6| Step: 5
Training loss: 3.8991414812457736
Validation loss: 2.9335982645164806

Epoch: 6| Step: 6
Training loss: 3.063037591577118
Validation loss: 2.944958417014495

Epoch: 6| Step: 7
Training loss: 3.4209395571411783
Validation loss: 2.94050152171651

Epoch: 6| Step: 8
Training loss: 3.173631754742423
Validation loss: 2.924853944703489

Epoch: 6| Step: 9
Training loss: 3.777758791508056
Validation loss: 2.9276577257455942

Epoch: 6| Step: 10
Training loss: 2.6917770418226135
Validation loss: 2.9258858991018233

Epoch: 6| Step: 11
Training loss: 2.8160621125946363
Validation loss: 2.9229436112117386

Epoch: 6| Step: 12
Training loss: 3.1198367379339427
Validation loss: 2.927606435981322

Epoch: 6| Step: 13
Training loss: 3.178375348308681
Validation loss: 2.930564603597337

Epoch: 65| Step: 0
Training loss: 3.3762522599496236
Validation loss: 2.9282733779788868

Epoch: 6| Step: 1
Training loss: 3.6966841815319147
Validation loss: 2.9143260781732483

Epoch: 6| Step: 2
Training loss: 3.1321755996138543
Validation loss: 2.9169745556687974

Epoch: 6| Step: 3
Training loss: 3.0020946501589827
Validation loss: 2.916147458906867

Epoch: 6| Step: 4
Training loss: 2.8788224393117683
Validation loss: 2.9170166672867257

Epoch: 6| Step: 5
Training loss: 3.366086421353514
Validation loss: 2.9161632276217215

Epoch: 6| Step: 6
Training loss: 3.125874969061397
Validation loss: 2.9189479508409635

Epoch: 6| Step: 7
Training loss: 3.422078026448842
Validation loss: 2.917011852903885

Epoch: 6| Step: 8
Training loss: 3.3471910115568067
Validation loss: 2.9181205489396236

Epoch: 6| Step: 9
Training loss: 3.0319862651362883
Validation loss: 2.914962089974667

Epoch: 6| Step: 10
Training loss: 3.3869786498278445
Validation loss: 2.9150737778316644

Epoch: 6| Step: 11
Training loss: 2.7058030461984655
Validation loss: 2.913736668874196

Epoch: 6| Step: 12
Training loss: 3.5296808317880517
Validation loss: 2.9131056231134163

Epoch: 6| Step: 13
Training loss: 2.426552568502545
Validation loss: 2.9132725446229317

Epoch: 66| Step: 0
Training loss: 3.5638221830285097
Validation loss: 2.9119970047249186

Epoch: 6| Step: 1
Training loss: 3.2339185309684915
Validation loss: 2.9129387976492045

Epoch: 6| Step: 2
Training loss: 3.9306300949619275
Validation loss: 2.9130794489363727

Epoch: 6| Step: 3
Training loss: 2.9911438239797867
Validation loss: 2.913355482174045

Epoch: 6| Step: 4
Training loss: 3.0417876197769176
Validation loss: 2.9109971556976646

Epoch: 6| Step: 5
Training loss: 3.1568506254781887
Validation loss: 2.9090541992951744

Epoch: 6| Step: 6
Training loss: 3.1104357266379736
Validation loss: 2.9067793500883807

Epoch: 6| Step: 7
Training loss: 3.3681482064174473
Validation loss: 2.9068691534906845

Epoch: 6| Step: 8
Training loss: 2.4700451121670097
Validation loss: 2.9057314160098797

Epoch: 6| Step: 9
Training loss: 2.9550831272161067
Validation loss: 2.9042509315483005

Epoch: 6| Step: 10
Training loss: 2.663771000908671
Validation loss: 2.905460490803112

Epoch: 6| Step: 11
Training loss: 2.7479635848252046
Validation loss: 2.905256855214943

Epoch: 6| Step: 12
Training loss: 3.8574885031824864
Validation loss: 2.9059791734260787

Epoch: 6| Step: 13
Training loss: 3.592951677633934
Validation loss: 2.9082956981636174

Epoch: 67| Step: 0
Training loss: 2.895381663567373
Validation loss: 2.904796207175776

Epoch: 6| Step: 1
Training loss: 3.5228563324228257
Validation loss: 2.9042060960835503

Epoch: 6| Step: 2
Training loss: 3.4494926024231973
Validation loss: 2.904333469999907

Epoch: 6| Step: 3
Training loss: 3.3764472966486383
Validation loss: 2.9028658623812245

Epoch: 6| Step: 4
Training loss: 3.7234037115218395
Validation loss: 2.9024247156945324

Epoch: 6| Step: 5
Training loss: 2.383595022315602
Validation loss: 2.903519747778757

Epoch: 6| Step: 6
Training loss: 3.687794560451107
Validation loss: 2.902183739302346

Epoch: 6| Step: 7
Training loss: 2.9159953480122196
Validation loss: 2.9070046651667396

Epoch: 6| Step: 8
Training loss: 2.702970467268155
Validation loss: 2.903795928732403

Epoch: 6| Step: 9
Training loss: 2.8673192131701772
Validation loss: 2.9060089544162215

Epoch: 6| Step: 10
Training loss: 2.4548155189703635
Validation loss: 2.902936864304478

Epoch: 6| Step: 11
Training loss: 3.64190035898739
Validation loss: 2.902953209037252

Epoch: 6| Step: 12
Training loss: 3.4565309324134446
Validation loss: 2.903419338718119

Epoch: 6| Step: 13
Training loss: 3.2943687132918518
Validation loss: 2.90361359244183

Epoch: 68| Step: 0
Training loss: 2.441690706084804
Validation loss: 2.900615415524606

Epoch: 6| Step: 1
Training loss: 3.119349138889869
Validation loss: 2.899355026123371

Epoch: 6| Step: 2
Training loss: 3.5256520689500124
Validation loss: 2.9010605647513095

Epoch: 6| Step: 3
Training loss: 3.6279277159735557
Validation loss: 2.901101803658441

Epoch: 6| Step: 4
Training loss: 2.8276127303879077
Validation loss: 2.898552129480085

Epoch: 6| Step: 5
Training loss: 3.5119525632152855
Validation loss: 2.89968774611621

Epoch: 6| Step: 6
Training loss: 3.3639366229116607
Validation loss: 2.9128502823975424

Epoch: 6| Step: 7
Training loss: 3.3749328889178978
Validation loss: 2.9085075738991693

Epoch: 6| Step: 8
Training loss: 2.111696562260599
Validation loss: 2.9178063848155515

Epoch: 6| Step: 9
Training loss: 2.959490017131165
Validation loss: 2.925949163054576

Epoch: 6| Step: 10
Training loss: 3.248218488259856
Validation loss: 2.9252803941200014

Epoch: 6| Step: 11
Training loss: 3.546432534738213
Validation loss: 2.9023894268573174

Epoch: 6| Step: 12
Training loss: 3.423546926959844
Validation loss: 2.895703538057568

Epoch: 6| Step: 13
Training loss: 3.2481766501058664
Validation loss: 2.8943840579406976

Epoch: 69| Step: 0
Training loss: 3.3367961698610267
Validation loss: 2.8959915759434267

Epoch: 6| Step: 1
Training loss: 3.2434081204277607
Validation loss: 2.8960499045467984

Epoch: 6| Step: 2
Training loss: 3.1487750684127183
Validation loss: 2.892489211798621

Epoch: 6| Step: 3
Training loss: 3.158915838576191
Validation loss: 2.896331040241484

Epoch: 6| Step: 4
Training loss: 3.7922170190719267
Validation loss: 2.895194980049302

Epoch: 6| Step: 5
Training loss: 3.284296710299881
Validation loss: 2.8964121722438225

Epoch: 6| Step: 6
Training loss: 3.0964112828630506
Validation loss: 2.893197597431372

Epoch: 6| Step: 7
Training loss: 2.6911099164182932
Validation loss: 2.8965239221868844

Epoch: 6| Step: 8
Training loss: 3.1146802259872923
Validation loss: 2.891827187818911

Epoch: 6| Step: 9
Training loss: 2.746014047174164
Validation loss: 2.8927935863697565

Epoch: 6| Step: 10
Training loss: 2.9607072000847685
Validation loss: 2.8885349325892906

Epoch: 6| Step: 11
Training loss: 3.54160081390792
Validation loss: 2.893375900326957

Epoch: 6| Step: 12
Training loss: 3.214138393961833
Validation loss: 2.891856801613712

Epoch: 6| Step: 13
Training loss: 3.109891915605043
Validation loss: 2.889661014147765

Epoch: 70| Step: 0
Training loss: 2.417403985595195
Validation loss: 2.8917217059912876

Epoch: 6| Step: 1
Training loss: 3.1032089360343744
Validation loss: 2.890112928039264

Epoch: 6| Step: 2
Training loss: 3.2713066941021354
Validation loss: 2.892562892426941

Epoch: 6| Step: 3
Training loss: 3.2568425259959595
Validation loss: 2.8907954144983887

Epoch: 6| Step: 4
Training loss: 2.9605578981912313
Validation loss: 2.8897159955287957

Epoch: 6| Step: 5
Training loss: 3.265748528147365
Validation loss: 2.8876187350585534

Epoch: 6| Step: 6
Training loss: 3.594509542060144
Validation loss: 2.894158809997925

Epoch: 6| Step: 7
Training loss: 3.5081275849406732
Validation loss: 2.9069438136582906

Epoch: 6| Step: 8
Training loss: 3.6448198635554756
Validation loss: 2.9084040870972396

Epoch: 6| Step: 9
Training loss: 2.9900666133132856
Validation loss: 2.901755110326745

Epoch: 6| Step: 10
Training loss: 2.823459802907857
Validation loss: 2.8994815680554398

Epoch: 6| Step: 11
Training loss: 3.6802257622008194
Validation loss: 2.8946300375314857

Epoch: 6| Step: 12
Training loss: 2.964991549500747
Validation loss: 2.8883392422691876

Epoch: 6| Step: 13
Training loss: 2.3908200651881866
Validation loss: 2.88879224150419

Epoch: 71| Step: 0
Training loss: 3.8715068700631656
Validation loss: 2.886087399098899

Epoch: 6| Step: 1
Training loss: 3.8712000519508316
Validation loss: 2.887990892888422

Epoch: 6| Step: 2
Training loss: 2.8709524106898394
Validation loss: 2.883804921920431

Epoch: 6| Step: 3
Training loss: 2.4861746933216278
Validation loss: 2.886384574122493

Epoch: 6| Step: 4
Training loss: 3.1546626867987753
Validation loss: 2.883514763402219

Epoch: 6| Step: 5
Training loss: 2.778720348232553
Validation loss: 2.8851053829583964

Epoch: 6| Step: 6
Training loss: 3.084529043445829
Validation loss: 2.885604101247219

Epoch: 6| Step: 7
Training loss: 3.6888789815144096
Validation loss: 2.8843836048783436

Epoch: 6| Step: 8
Training loss: 3.166929100271659
Validation loss: 2.882371333081955

Epoch: 6| Step: 9
Training loss: 3.22567256449677
Validation loss: 2.884082532994559

Epoch: 6| Step: 10
Training loss: 3.058430361616146
Validation loss: 2.8845293155416125

Epoch: 6| Step: 11
Training loss: 3.136867419908436
Validation loss: 2.8824618480020847

Epoch: 6| Step: 12
Training loss: 2.441634950225683
Validation loss: 2.883120704216369

Epoch: 6| Step: 13
Training loss: 3.453472413413068
Validation loss: 2.881104459159302

Epoch: 72| Step: 0
Training loss: 2.662657873639962
Validation loss: 2.8803341386770667

Epoch: 6| Step: 1
Training loss: 3.435524667708215
Validation loss: 2.883527344575706

Epoch: 6| Step: 2
Training loss: 2.946693642983292
Validation loss: 2.88194223215969

Epoch: 6| Step: 3
Training loss: 3.0282845690308355
Validation loss: 2.8845785512747084

Epoch: 6| Step: 4
Training loss: 3.154333458088941
Validation loss: 2.8890075379857563

Epoch: 6| Step: 5
Training loss: 3.5217141548802737
Validation loss: 2.9143533477668884

Epoch: 6| Step: 6
Training loss: 3.8813690019875517
Validation loss: 2.91155222618949

Epoch: 6| Step: 7
Training loss: 3.8823664387894996
Validation loss: 2.9090738751784606

Epoch: 6| Step: 8
Training loss: 2.399001362776757
Validation loss: 2.8824744426651336

Epoch: 6| Step: 9
Training loss: 2.851200613809128
Validation loss: 2.8764317288318257

Epoch: 6| Step: 10
Training loss: 3.866564767963728
Validation loss: 2.8788396850144427

Epoch: 6| Step: 11
Training loss: 3.5036003123823614
Validation loss: 2.8799990644148648

Epoch: 6| Step: 12
Training loss: 2.08419281078944
Validation loss: 2.8842305707607485

Epoch: 6| Step: 13
Training loss: 2.360587408540636
Validation loss: 2.916042462076336

Epoch: 73| Step: 0
Training loss: 3.122512132240836
Validation loss: 2.9209510667732994

Epoch: 6| Step: 1
Training loss: 2.6222477971821543
Validation loss: 2.985917499202418

Epoch: 6| Step: 2
Training loss: 3.4260585068106826
Validation loss: 3.039621169096504

Epoch: 6| Step: 3
Training loss: 3.366030323837147
Validation loss: 2.998049281260527

Epoch: 6| Step: 4
Training loss: 3.115257947109094
Validation loss: 2.905165965104663

Epoch: 6| Step: 5
Training loss: 3.23554890287272
Validation loss: 2.880379497924531

Epoch: 6| Step: 6
Training loss: 3.964186800946425
Validation loss: 2.909030238547962

Epoch: 6| Step: 7
Training loss: 2.570460631209492
Validation loss: 2.9398547290837027

Epoch: 6| Step: 8
Training loss: 3.2074649345639803
Validation loss: 2.9670164200986657

Epoch: 6| Step: 9
Training loss: 3.3082602376734056
Validation loss: 3.0229033379618397

Epoch: 6| Step: 10
Training loss: 3.474403379529925
Validation loss: 2.980615007492321

Epoch: 6| Step: 11
Training loss: 3.1552766110998434
Validation loss: 2.9169551659804056

Epoch: 6| Step: 12
Training loss: 3.289670910594585
Validation loss: 2.887923275861873

Epoch: 6| Step: 13
Training loss: 2.7257453109195655
Validation loss: 2.883093988394292

Epoch: 74| Step: 0
Training loss: 3.4697030622533047
Validation loss: 2.8838821144482294

Epoch: 6| Step: 1
Training loss: 3.2891886272394784
Validation loss: 2.878033331221911

Epoch: 6| Step: 2
Training loss: 3.197134230796994
Validation loss: 2.8796626585105467

Epoch: 6| Step: 3
Training loss: 3.190061848677651
Validation loss: 2.8808166805529036

Epoch: 6| Step: 4
Training loss: 3.283080108353095
Validation loss: 2.882694147135332

Epoch: 6| Step: 5
Training loss: 3.013744657457158
Validation loss: 2.883255470182906

Epoch: 6| Step: 6
Training loss: 3.2140737100349144
Validation loss: 2.8870354898712587

Epoch: 6| Step: 7
Training loss: 2.8982841677349995
Validation loss: 2.8832347769688527

Epoch: 6| Step: 8
Training loss: 3.3146802816512895
Validation loss: 2.8826497492177934

Epoch: 6| Step: 9
Training loss: 2.6714814548780463
Validation loss: 2.8788492669051866

Epoch: 6| Step: 10
Training loss: 3.6239047533449216
Validation loss: 2.876964548824535

Epoch: 6| Step: 11
Training loss: 2.392744932004109
Validation loss: 2.8764294650375177

Epoch: 6| Step: 12
Training loss: 3.779806570927016
Validation loss: 2.873966446794206

Epoch: 6| Step: 13
Training loss: 2.633372352005204
Validation loss: 2.87500310044302

Epoch: 75| Step: 0
Training loss: 4.030969890946688
Validation loss: 2.8754120469473725

Epoch: 6| Step: 1
Training loss: 3.6864242277627426
Validation loss: 2.8755294023472935

Epoch: 6| Step: 2
Training loss: 3.217879983298641
Validation loss: 2.8756080597911393

Epoch: 6| Step: 3
Training loss: 2.9340147079587986
Validation loss: 2.875754117929778

Epoch: 6| Step: 4
Training loss: 3.2343163231581213
Validation loss: 2.8744731204498315

Epoch: 6| Step: 5
Training loss: 3.8391240513625617
Validation loss: 2.8746402599232463

Epoch: 6| Step: 6
Training loss: 2.727464062307997
Validation loss: 2.8725107410410406

Epoch: 6| Step: 7
Training loss: 3.289474932620163
Validation loss: 2.8762758481711304

Epoch: 6| Step: 8
Training loss: 3.0383023681848353
Validation loss: 2.880665260867856

Epoch: 6| Step: 9
Training loss: 3.280138681317721
Validation loss: 2.9010682334102476

Epoch: 6| Step: 10
Training loss: 2.742632272846219
Validation loss: 2.9230182791572217

Epoch: 6| Step: 11
Training loss: 2.5860385471666194
Validation loss: 2.936963704623807

Epoch: 6| Step: 12
Training loss: 2.8661701777872697
Validation loss: 2.932194544333189

Epoch: 6| Step: 13
Training loss: 1.9774977691483484
Validation loss: 2.908616398279126

Epoch: 76| Step: 0
Training loss: 3.621089536135628
Validation loss: 2.8987097210309845

Epoch: 6| Step: 1
Training loss: 3.1981287253251707
Validation loss: 2.890300500377243

Epoch: 6| Step: 2
Training loss: 2.595037026113623
Validation loss: 2.87508881919026

Epoch: 6| Step: 3
Training loss: 2.873825828610439
Validation loss: 2.8743005751580513

Epoch: 6| Step: 4
Training loss: 3.113021016462624
Validation loss: 2.8810581013731666

Epoch: 6| Step: 5
Training loss: 3.55483344480617
Validation loss: 2.889055766556887

Epoch: 6| Step: 6
Training loss: 2.531089495055918
Validation loss: 2.8988154641701454

Epoch: 6| Step: 7
Training loss: 3.213549069355373
Validation loss: 2.893652446113034

Epoch: 6| Step: 8
Training loss: 3.3945821005433205
Validation loss: 2.8817179457473636

Epoch: 6| Step: 9
Training loss: 3.3481587374484416
Validation loss: 2.8747175799346043

Epoch: 6| Step: 10
Training loss: 3.256722466867002
Validation loss: 2.8715610025996625

Epoch: 6| Step: 11
Training loss: 3.320247730296574
Validation loss: 2.8725240192358528

Epoch: 6| Step: 12
Training loss: 3.2952408198107275
Validation loss: 2.8698925200618146

Epoch: 6| Step: 13
Training loss: 2.7054279197632347
Validation loss: 2.8666739439627484

Epoch: 77| Step: 0
Training loss: 2.9238747673926646
Validation loss: 2.8698593145670657

Epoch: 6| Step: 1
Training loss: 3.128741656485454
Validation loss: 2.8680340399956377

Epoch: 6| Step: 2
Training loss: 3.4460409696139442
Validation loss: 2.8686288931958726

Epoch: 6| Step: 3
Training loss: 2.0553612130314067
Validation loss: 2.8636096072786654

Epoch: 6| Step: 4
Training loss: 2.9986454766818
Validation loss: 2.8698265339030207

Epoch: 6| Step: 5
Training loss: 3.471675429629949
Validation loss: 2.864522876865972

Epoch: 6| Step: 6
Training loss: 3.4482818748158617
Validation loss: 2.8680863575468734

Epoch: 6| Step: 7
Training loss: 3.2695922116665894
Validation loss: 2.868443140839589

Epoch: 6| Step: 8
Training loss: 3.1025409068101224
Validation loss: 2.8626824556852735

Epoch: 6| Step: 9
Training loss: 3.4025440179022235
Validation loss: 2.860790800316319

Epoch: 6| Step: 10
Training loss: 2.8729613996143972
Validation loss: 2.8664854462681104

Epoch: 6| Step: 11
Training loss: 2.90982934536595
Validation loss: 2.865199366282799

Epoch: 6| Step: 12
Training loss: 3.295086850308231
Validation loss: 2.873024912557032

Epoch: 6| Step: 13
Training loss: 3.868708024544474
Validation loss: 2.8685200997064553

Epoch: 78| Step: 0
Training loss: 3.4234424641519663
Validation loss: 2.8850675230750493

Epoch: 6| Step: 1
Training loss: 3.627192261864376
Validation loss: 2.8662078561682596

Epoch: 6| Step: 2
Training loss: 3.1293119055663556
Validation loss: 2.8562725380124343

Epoch: 6| Step: 3
Training loss: 2.60939692870651
Validation loss: 2.857227116963281

Epoch: 6| Step: 4
Training loss: 2.526506476881104
Validation loss: 2.856796342757133

Epoch: 6| Step: 5
Training loss: 2.973318660283627
Validation loss: 2.856332866936538

Epoch: 6| Step: 6
Training loss: 3.8612217982562966
Validation loss: 2.85719261847582

Epoch: 6| Step: 7
Training loss: 3.4087533413766082
Validation loss: 2.856188655569784

Epoch: 6| Step: 8
Training loss: 2.855724234573546
Validation loss: 2.858827445832303

Epoch: 6| Step: 9
Training loss: 3.3835501978732814
Validation loss: 2.857736380811667

Epoch: 6| Step: 10
Training loss: 2.3549085365238853
Validation loss: 2.862432920188777

Epoch: 6| Step: 11
Training loss: 4.0423740410275295
Validation loss: 2.856657473840756

Epoch: 6| Step: 12
Training loss: 2.355751438163505
Validation loss: 2.861977689859987

Epoch: 6| Step: 13
Training loss: 3.0449791903481573
Validation loss: 2.8625868661649316

Epoch: 79| Step: 0
Training loss: 3.300863736718956
Validation loss: 2.861137206198876

Epoch: 6| Step: 1
Training loss: 2.920161759847272
Validation loss: 2.8621275552787226

Epoch: 6| Step: 2
Training loss: 3.4917203518208364
Validation loss: 2.8585704377816468

Epoch: 6| Step: 3
Training loss: 2.829310553313702
Validation loss: 2.854847431546118

Epoch: 6| Step: 4
Training loss: 2.9950622613259226
Validation loss: 2.854855983146087

Epoch: 6| Step: 5
Training loss: 2.9112079947206437
Validation loss: 2.8541520539524883

Epoch: 6| Step: 6
Training loss: 3.099901345436727
Validation loss: 2.853362083578684

Epoch: 6| Step: 7
Training loss: 3.1552110227210464
Validation loss: 2.8530222061797055

Epoch: 6| Step: 8
Training loss: 2.77397386978923
Validation loss: 2.8537045499852898

Epoch: 6| Step: 9
Training loss: 3.5450797894407082
Validation loss: 2.8574875052409334

Epoch: 6| Step: 10
Training loss: 2.59407363159453
Validation loss: 2.8616211127961972

Epoch: 6| Step: 11
Training loss: 3.4691708970958515
Validation loss: 2.8727772142241417

Epoch: 6| Step: 12
Training loss: 3.469115641800031
Validation loss: 2.8675754523052257

Epoch: 6| Step: 13
Training loss: 3.658083594508417
Validation loss: 2.858081767475679

Epoch: 80| Step: 0
Training loss: 2.9739289736036167
Validation loss: 2.8518736373574027

Epoch: 6| Step: 1
Training loss: 3.1118844032490296
Validation loss: 2.8470313896564567

Epoch: 6| Step: 2
Training loss: 3.5788175087656207
Validation loss: 2.846912655999461

Epoch: 6| Step: 3
Training loss: 2.827360439751963
Validation loss: 2.845848791970811

Epoch: 6| Step: 4
Training loss: 2.721234206091169
Validation loss: 2.846406608297871

Epoch: 6| Step: 5
Training loss: 3.0058554091002914
Validation loss: 2.8438528728122066

Epoch: 6| Step: 6
Training loss: 2.87223981962177
Validation loss: 2.8460001651851297

Epoch: 6| Step: 7
Training loss: 3.025212833704264
Validation loss: 2.847307905989961

Epoch: 6| Step: 8
Training loss: 3.3219098007661603
Validation loss: 2.8457479885334296

Epoch: 6| Step: 9
Training loss: 2.855658445306441
Validation loss: 2.8467484345517367

Epoch: 6| Step: 10
Training loss: 3.6906437807953822
Validation loss: 2.845626615729046

Epoch: 6| Step: 11
Training loss: 3.3557940182223365
Validation loss: 2.8470965012443608

Epoch: 6| Step: 12
Training loss: 3.620753201269984
Validation loss: 2.8466795001809726

Epoch: 6| Step: 13
Training loss: 2.611727356618381
Validation loss: 2.850058624767075

Epoch: 81| Step: 0
Training loss: 3.8485708630988538
Validation loss: 2.857254370734063

Epoch: 6| Step: 1
Training loss: 2.784650031655254
Validation loss: 2.8479819394633914

Epoch: 6| Step: 2
Training loss: 2.518188023880366
Validation loss: 2.8432238187894914

Epoch: 6| Step: 3
Training loss: 3.2057997537997287
Validation loss: 2.8402752657682133

Epoch: 6| Step: 4
Training loss: 3.548468009384197
Validation loss: 2.84095945292382

Epoch: 6| Step: 5
Training loss: 2.9230652695010395
Validation loss: 2.8377208403869214

Epoch: 6| Step: 6
Training loss: 3.2710750676786176
Validation loss: 2.8414448786119264

Epoch: 6| Step: 7
Training loss: 2.6003752510999645
Validation loss: 2.8411531794630998

Epoch: 6| Step: 8
Training loss: 3.3019116153452317
Validation loss: 2.8408657431553546

Epoch: 6| Step: 9
Training loss: 3.1116687997634624
Validation loss: 2.840216965147226

Epoch: 6| Step: 10
Training loss: 2.607892374743373
Validation loss: 2.8389674324709633

Epoch: 6| Step: 11
Training loss: 3.2243378661816706
Validation loss: 2.8386534779565937

Epoch: 6| Step: 12
Training loss: 3.3772533100204294
Validation loss: 2.838828636009349

Epoch: 6| Step: 13
Training loss: 3.5020499356999797
Validation loss: 2.836974224748641

Epoch: 82| Step: 0
Training loss: 3.7124615240190404
Validation loss: 2.838884259619717

Epoch: 6| Step: 1
Training loss: 3.1945964132087377
Validation loss: 2.836699309302651

Epoch: 6| Step: 2
Training loss: 3.24773621578843
Validation loss: 2.8383329376639908

Epoch: 6| Step: 3
Training loss: 3.1561968204059494
Validation loss: 2.837115717938098

Epoch: 6| Step: 4
Training loss: 2.307760795163856
Validation loss: 2.8354428847961373

Epoch: 6| Step: 5
Training loss: 3.3289639127545185
Validation loss: 2.8351363200652964

Epoch: 6| Step: 6
Training loss: 2.3921311564322667
Validation loss: 2.830907864448105

Epoch: 6| Step: 7
Training loss: 3.9158166544682773
Validation loss: 2.8329404170024644

Epoch: 6| Step: 8
Training loss: 3.299233411123593
Validation loss: 2.83301242486486

Epoch: 6| Step: 9
Training loss: 2.1089433016365855
Validation loss: 2.8322327353402352

Epoch: 6| Step: 10
Training loss: 3.7390189564038927
Validation loss: 2.8317389532357145

Epoch: 6| Step: 11
Training loss: 2.996128763444367
Validation loss: 2.832690030803434

Epoch: 6| Step: 12
Training loss: 2.646427528362021
Validation loss: 2.838186424283629

Epoch: 6| Step: 13
Training loss: 3.2588691004274324
Validation loss: 2.8546270387373727

Epoch: 83| Step: 0
Training loss: 3.08663167751027
Validation loss: 2.8494487638104373

Epoch: 6| Step: 1
Training loss: 3.3797674062932335
Validation loss: 2.836913085630083

Epoch: 6| Step: 2
Training loss: 3.441877594796694
Validation loss: 2.8316592899590907

Epoch: 6| Step: 3
Training loss: 2.362958599165383
Validation loss: 2.8311798035569793

Epoch: 6| Step: 4
Training loss: 3.2744468280030055
Validation loss: 2.8348819064524506

Epoch: 6| Step: 5
Training loss: 3.1418638300730333
Validation loss: 2.8317836260856546

Epoch: 6| Step: 6
Training loss: 3.740020953033014
Validation loss: 2.831020050736262

Epoch: 6| Step: 7
Training loss: 3.0581197748971816
Validation loss: 2.8328020953816004

Epoch: 6| Step: 8
Training loss: 2.9222720279325154
Validation loss: 2.8306373175032142

Epoch: 6| Step: 9
Training loss: 3.017040493671588
Validation loss: 2.8311154867887005

Epoch: 6| Step: 10
Training loss: 2.714182030698044
Validation loss: 2.832030878855533

Epoch: 6| Step: 11
Training loss: 3.9031651637604656
Validation loss: 2.8319277214388796

Epoch: 6| Step: 12
Training loss: 2.0641150653391893
Validation loss: 2.832545644785904

Epoch: 6| Step: 13
Training loss: 3.304179700430474
Validation loss: 2.832274945629457

Epoch: 84| Step: 0
Training loss: 3.3046427694409215
Validation loss: 2.834642698272855

Epoch: 6| Step: 1
Training loss: 2.5629986533683486
Validation loss: 2.833675386193151

Epoch: 6| Step: 2
Training loss: 3.514224303215164
Validation loss: 2.8439249036520287

Epoch: 6| Step: 3
Training loss: 3.5090922376762244
Validation loss: 2.8314611346659033

Epoch: 6| Step: 4
Training loss: 3.368250561778893
Validation loss: 2.8340282299829265

Epoch: 6| Step: 5
Training loss: 3.128147981084805
Validation loss: 2.8364677560608405

Epoch: 6| Step: 6
Training loss: 3.25680680154696
Validation loss: 2.8433197734570834

Epoch: 6| Step: 7
Training loss: 3.041995009027584
Validation loss: 2.8448576790955418

Epoch: 6| Step: 8
Training loss: 2.6847053013760775
Validation loss: 2.8446579684570876

Epoch: 6| Step: 9
Training loss: 3.0642716868889637
Validation loss: 2.852092810145344

Epoch: 6| Step: 10
Training loss: 2.638899741791833
Validation loss: 2.855839346883512

Epoch: 6| Step: 11
Training loss: 3.323612216074823
Validation loss: 2.8385476061030768

Epoch: 6| Step: 12
Training loss: 3.051410448980834
Validation loss: 2.8227010777119674

Epoch: 6| Step: 13
Training loss: 3.346229845797835
Validation loss: 2.822993676397104

Epoch: 85| Step: 0
Training loss: 3.385501207127523
Validation loss: 2.825112902982121

Epoch: 6| Step: 1
Training loss: 2.591561002713641
Validation loss: 2.8299925838123845

Epoch: 6| Step: 2
Training loss: 2.9526646169433004
Validation loss: 2.8298280318212248

Epoch: 6| Step: 3
Training loss: 3.638776449030705
Validation loss: 2.847150646010019

Epoch: 6| Step: 4
Training loss: 3.255065198676032
Validation loss: 2.8518444641661396

Epoch: 6| Step: 5
Training loss: 3.2610520463829995
Validation loss: 2.878951556053969

Epoch: 6| Step: 6
Training loss: 2.889641341819186
Validation loss: 2.8305531608267125

Epoch: 6| Step: 7
Training loss: 3.2227015266705794
Validation loss: 2.828961277002734

Epoch: 6| Step: 8
Training loss: 2.5862255108919787
Validation loss: 2.825344265306749

Epoch: 6| Step: 9
Training loss: 3.4919673841773213
Validation loss: 2.8279502740799987

Epoch: 6| Step: 10
Training loss: 3.066617727580237
Validation loss: 2.828767529342673

Epoch: 6| Step: 11
Training loss: 2.9865882216381023
Validation loss: 2.8342360452499222

Epoch: 6| Step: 12
Training loss: 2.9823029200245754
Validation loss: 2.8466448693640376

Epoch: 6| Step: 13
Training loss: 3.700557285302007
Validation loss: 2.84342954016151

Epoch: 86| Step: 0
Training loss: 3.037430901389016
Validation loss: 2.850165221256139

Epoch: 6| Step: 1
Training loss: 2.6741002503735443
Validation loss: 2.8504042366273263

Epoch: 6| Step: 2
Training loss: 3.0428223874661233
Validation loss: 2.851437354056352

Epoch: 6| Step: 3
Training loss: 3.328504084099374
Validation loss: 2.8536504774668963

Epoch: 6| Step: 4
Training loss: 3.8390031983108095
Validation loss: 2.8540073138013784

Epoch: 6| Step: 5
Training loss: 2.7358984490727933
Validation loss: 2.8345981871504433

Epoch: 6| Step: 6
Training loss: 3.106927876794697
Validation loss: 2.83570779392006

Epoch: 6| Step: 7
Training loss: 2.070025269358732
Validation loss: 2.8287791078854085

Epoch: 6| Step: 8
Training loss: 3.0128765329916454
Validation loss: 2.8285867625331105

Epoch: 6| Step: 9
Training loss: 3.7379347940618497
Validation loss: 2.834560011722125

Epoch: 6| Step: 10
Training loss: 3.334689118909796
Validation loss: 2.8198459396019375

Epoch: 6| Step: 11
Training loss: 3.3725087896844723
Validation loss: 2.816325744303896

Epoch: 6| Step: 12
Training loss: 2.8501608552211164
Validation loss: 2.8181151437460934

Epoch: 6| Step: 13
Training loss: 3.48347235650124
Validation loss: 2.8199130189441717

Epoch: 87| Step: 0
Training loss: 3.440704793810334
Validation loss: 2.8195124001904985

Epoch: 6| Step: 1
Training loss: 3.0904865970614095
Validation loss: 2.8221058031529966

Epoch: 6| Step: 2
Training loss: 3.1514523745555474
Validation loss: 2.823992353771011

Epoch: 6| Step: 3
Training loss: 3.322183956732469
Validation loss: 2.8242714761707077

Epoch: 6| Step: 4
Training loss: 3.484296310288932
Validation loss: 2.823888609472415

Epoch: 6| Step: 5
Training loss: 3.7195314499891645
Validation loss: 2.823608130002113

Epoch: 6| Step: 6
Training loss: 2.998737864435978
Validation loss: 2.823556720679417

Epoch: 6| Step: 7
Training loss: 3.399815212164872
Validation loss: 2.825130450233051

Epoch: 6| Step: 8
Training loss: 3.0457018036281123
Validation loss: 2.8250993919692844

Epoch: 6| Step: 9
Training loss: 3.0868728186010146
Validation loss: 2.8236263094409146

Epoch: 6| Step: 10
Training loss: 2.493833661886935
Validation loss: 2.835585906375968

Epoch: 6| Step: 11
Training loss: 2.7971874893626585
Validation loss: 2.8602689164640083

Epoch: 6| Step: 12
Training loss: 2.7979918226731995
Validation loss: 2.8791685170937207

Epoch: 6| Step: 13
Training loss: 2.7799802303297354
Validation loss: 2.8718227996379415

Epoch: 88| Step: 0
Training loss: 3.5116542517453606
Validation loss: 2.8833553517748225

Epoch: 6| Step: 1
Training loss: 3.2173189111358154
Validation loss: 2.8843778250050534

Epoch: 6| Step: 2
Training loss: 3.605500755291993
Validation loss: 2.8851297236677884

Epoch: 6| Step: 3
Training loss: 2.7633791495537183
Validation loss: 2.881315466732497

Epoch: 6| Step: 4
Training loss: 2.7140285667709505
Validation loss: 2.8825052447046704

Epoch: 6| Step: 5
Training loss: 2.9310854412160174
Validation loss: 2.878007314639803

Epoch: 6| Step: 6
Training loss: 3.1415297690059822
Validation loss: 2.875147442561387

Epoch: 6| Step: 7
Training loss: 3.260827734305721
Validation loss: 2.8704467160433684

Epoch: 6| Step: 8
Training loss: 2.829862787809181
Validation loss: 2.8382369869231994

Epoch: 6| Step: 9
Training loss: 3.211814741974944
Validation loss: 2.818095638791085

Epoch: 6| Step: 10
Training loss: 2.7059797967014183
Validation loss: 2.8122421875697774

Epoch: 6| Step: 11
Training loss: 3.7593322345587494
Validation loss: 2.8092196664454336

Epoch: 6| Step: 12
Training loss: 3.405429566296425
Validation loss: 2.806972247979966

Epoch: 6| Step: 13
Training loss: 2.837200629620635
Validation loss: 2.8048998947403305

Epoch: 89| Step: 0
Training loss: 3.371527404121634
Validation loss: 2.806135051024822

Epoch: 6| Step: 1
Training loss: 3.129739448013392
Validation loss: 2.807671297398171

Epoch: 6| Step: 2
Training loss: 2.860956807178162
Validation loss: 2.8027742114127845

Epoch: 6| Step: 3
Training loss: 3.5724916047731052
Validation loss: 2.808959842148388

Epoch: 6| Step: 4
Training loss: 2.655983675900816
Validation loss: 2.810139372498227

Epoch: 6| Step: 5
Training loss: 3.011514184241005
Validation loss: 2.8053357163654877

Epoch: 6| Step: 6
Training loss: 2.742147331269631
Validation loss: 2.80671711554417

Epoch: 6| Step: 7
Training loss: 3.698956553785404
Validation loss: 2.8081534156581207

Epoch: 6| Step: 8
Training loss: 2.797332385294232
Validation loss: 2.8017925259914667

Epoch: 6| Step: 9
Training loss: 3.587571779390321
Validation loss: 2.8028485299813095

Epoch: 6| Step: 10
Training loss: 2.2691003912433603
Validation loss: 2.802244962535189

Epoch: 6| Step: 11
Training loss: 3.0050956048212862
Validation loss: 2.8033232992968933

Epoch: 6| Step: 12
Training loss: 3.2030373165875914
Validation loss: 2.7997693505194605

Epoch: 6| Step: 13
Training loss: 3.5627988723401907
Validation loss: 2.803217367041321

Epoch: 90| Step: 0
Training loss: 2.404357165673801
Validation loss: 2.804521051913815

Epoch: 6| Step: 1
Training loss: 2.676267794069291
Validation loss: 2.8007604371366757

Epoch: 6| Step: 2
Training loss: 2.507687479390766
Validation loss: 2.801590684323776

Epoch: 6| Step: 3
Training loss: 3.2510324452147303
Validation loss: 2.8021264591932336

Epoch: 6| Step: 4
Training loss: 2.9591327894401007
Validation loss: 2.8035284544962766

Epoch: 6| Step: 5
Training loss: 3.7750245857701303
Validation loss: 2.8004189730641285

Epoch: 6| Step: 6
Training loss: 3.8086205427743485
Validation loss: 2.800050066318671

Epoch: 6| Step: 7
Training loss: 2.2604508873477718
Validation loss: 2.799158363743817

Epoch: 6| Step: 8
Training loss: 4.2704355690422044
Validation loss: 2.8021328991044796

Epoch: 6| Step: 9
Training loss: 3.31059527066396
Validation loss: 2.797918503941598

Epoch: 6| Step: 10
Training loss: 2.889938685416829
Validation loss: 2.800672891073626

Epoch: 6| Step: 11
Training loss: 3.220380351662673
Validation loss: 2.8003743834789376

Epoch: 6| Step: 12
Training loss: 2.7163666549750336
Validation loss: 2.800800369359221

Epoch: 6| Step: 13
Training loss: 2.469600096542114
Validation loss: 2.7996946196508277

Epoch: 91| Step: 0
Training loss: 3.3272724044541926
Validation loss: 2.801771766390719

Epoch: 6| Step: 1
Training loss: 2.913718850170997
Validation loss: 2.8091643329173266

Epoch: 6| Step: 2
Training loss: 3.615464131593732
Validation loss: 2.815756535180945

Epoch: 6| Step: 3
Training loss: 2.9258571966319558
Validation loss: 2.823822712188163

Epoch: 6| Step: 4
Training loss: 3.461615020361787
Validation loss: 2.831722024535603

Epoch: 6| Step: 5
Training loss: 2.7564994993190357
Validation loss: 2.823982983369386

Epoch: 6| Step: 6
Training loss: 2.629031672893816
Validation loss: 2.8291802684186274

Epoch: 6| Step: 7
Training loss: 3.1565223802933
Validation loss: 2.8106884024716856

Epoch: 6| Step: 8
Training loss: 3.660187777095409
Validation loss: 2.802461885778892

Epoch: 6| Step: 9
Training loss: 3.3896750248795224
Validation loss: 2.7950224395064858

Epoch: 6| Step: 10
Training loss: 3.21796148326671
Validation loss: 2.7930576206200586

Epoch: 6| Step: 11
Training loss: 2.8167080234749315
Validation loss: 2.794632115545176

Epoch: 6| Step: 12
Training loss: 2.4280079620708404
Validation loss: 2.794213041117644

Epoch: 6| Step: 13
Training loss: 2.8925820813612377
Validation loss: 2.79236153587014

Epoch: 92| Step: 0
Training loss: 3.3189355485846934
Validation loss: 2.795700498510285

Epoch: 6| Step: 1
Training loss: 2.452044498089619
Validation loss: 2.7917420957608514

Epoch: 6| Step: 2
Training loss: 3.7845812538950705
Validation loss: 2.791800381123268

Epoch: 6| Step: 3
Training loss: 2.6638315945341002
Validation loss: 2.7925303859722654

Epoch: 6| Step: 4
Training loss: 2.8153128227566517
Validation loss: 2.792136287967281

Epoch: 6| Step: 5
Training loss: 1.9293373191720267
Validation loss: 2.7966139192554618

Epoch: 6| Step: 6
Training loss: 2.8125450130675254
Validation loss: 2.790027347996244

Epoch: 6| Step: 7
Training loss: 3.1845038300903115
Validation loss: 2.7907926522523487

Epoch: 6| Step: 8
Training loss: 2.5605574897877807
Validation loss: 2.789595746022508

Epoch: 6| Step: 9
Training loss: 3.904619777011245
Validation loss: 2.7887255941204

Epoch: 6| Step: 10
Training loss: 3.5618221240345114
Validation loss: 2.7886825858414213

Epoch: 6| Step: 11
Training loss: 2.8732782266853896
Validation loss: 2.790601697714982

Epoch: 6| Step: 12
Training loss: 3.6590713961407837
Validation loss: 2.7887216788721036

Epoch: 6| Step: 13
Training loss: 3.3959803325141977
Validation loss: 2.7875869472545127

Epoch: 93| Step: 0
Training loss: 3.2451805179740436
Validation loss: 2.791738824794917

Epoch: 6| Step: 1
Training loss: 3.330253386150489
Validation loss: 2.78806018958614

Epoch: 6| Step: 2
Training loss: 3.069356910374178
Validation loss: 2.7900332645205252

Epoch: 6| Step: 3
Training loss: 2.924265816646334
Validation loss: 2.7935042512956625

Epoch: 6| Step: 4
Training loss: 2.7501217208280284
Validation loss: 2.7876776972046597

Epoch: 6| Step: 5
Training loss: 2.865007699686459
Validation loss: 2.790285674971446

Epoch: 6| Step: 6
Training loss: 3.609389796371187
Validation loss: 2.790940546756984

Epoch: 6| Step: 7
Training loss: 3.450958538963701
Validation loss: 2.7875661020945217

Epoch: 6| Step: 8
Training loss: 3.197285907846477
Validation loss: 2.789141146387834

Epoch: 6| Step: 9
Training loss: 2.7729631045088365
Validation loss: 2.7872516639364284

Epoch: 6| Step: 10
Training loss: 3.2882714124347974
Validation loss: 2.7872008422998586

Epoch: 6| Step: 11
Training loss: 2.870252753369483
Validation loss: 2.7848263005921656

Epoch: 6| Step: 12
Training loss: 3.3379871941487105
Validation loss: 2.7876216919069474

Epoch: 6| Step: 13
Training loss: 1.975356989599258
Validation loss: 2.7831876042265544

Epoch: 94| Step: 0
Training loss: 2.187629041952797
Validation loss: 2.7870369823384658

Epoch: 6| Step: 1
Training loss: 3.7392005547408416
Validation loss: 2.7847524106042014

Epoch: 6| Step: 2
Training loss: 3.3514179474217745
Validation loss: 2.7848625976954557

Epoch: 6| Step: 3
Training loss: 3.057498662765847
Validation loss: 2.786250801780253

Epoch: 6| Step: 4
Training loss: 3.4866146536230365
Validation loss: 2.7845434138715555

Epoch: 6| Step: 5
Training loss: 2.9084600433758023
Validation loss: 2.7838618647340603

Epoch: 6| Step: 6
Training loss: 3.1979495035446823
Validation loss: 2.78347716523235

Epoch: 6| Step: 7
Training loss: 2.814335118400239
Validation loss: 2.78426318519062

Epoch: 6| Step: 8
Training loss: 3.5115917891485795
Validation loss: 2.7795831216405404

Epoch: 6| Step: 9
Training loss: 2.388122745004691
Validation loss: 2.779335033759634

Epoch: 6| Step: 10
Training loss: 2.731569256662344
Validation loss: 2.7830545936361686

Epoch: 6| Step: 11
Training loss: 3.5821396073952947
Validation loss: 2.783372292133282

Epoch: 6| Step: 12
Training loss: 2.8579141188919435
Validation loss: 2.779361145675237

Epoch: 6| Step: 13
Training loss: 3.0587970378643394
Validation loss: 2.7795675142466503

Epoch: 95| Step: 0
Training loss: 3.6725307447212545
Validation loss: 2.7819354881056837

Epoch: 6| Step: 1
Training loss: 3.732202512482039
Validation loss: 2.788088043150604

Epoch: 6| Step: 2
Training loss: 2.695347617100261
Validation loss: 2.802600936454355

Epoch: 6| Step: 3
Training loss: 3.200504179813687
Validation loss: 2.7908838775858666

Epoch: 6| Step: 4
Training loss: 2.6523642447891906
Validation loss: 2.788660331297124

Epoch: 6| Step: 5
Training loss: 2.909131826037144
Validation loss: 2.782944184804173

Epoch: 6| Step: 6
Training loss: 3.3881582261106304
Validation loss: 2.7907771433735085

Epoch: 6| Step: 7
Training loss: 2.4826999991720045
Validation loss: 2.7783248504844402

Epoch: 6| Step: 8
Training loss: 2.8784556974441067
Validation loss: 2.780125022565161

Epoch: 6| Step: 9
Training loss: 3.4055547442149168
Validation loss: 2.7785389282599944

Epoch: 6| Step: 10
Training loss: 3.1509333484201982
Validation loss: 2.778969078169362

Epoch: 6| Step: 11
Training loss: 3.1923530882965383
Validation loss: 2.783176367040451

Epoch: 6| Step: 12
Training loss: 2.505961367760681
Validation loss: 2.7796361697074374

Epoch: 6| Step: 13
Training loss: 3.1558597436737776
Validation loss: 2.7826273651805593

Epoch: 96| Step: 0
Training loss: 2.902127038353201
Validation loss: 2.7853786072136604

Epoch: 6| Step: 1
Training loss: 3.7115964926800835
Validation loss: 2.785569188139268

Epoch: 6| Step: 2
Training loss: 2.6850036737569614
Validation loss: 2.7841066367068708

Epoch: 6| Step: 3
Training loss: 3.059097268081068
Validation loss: 2.784422030327423

Epoch: 6| Step: 4
Training loss: 3.2718961086521356
Validation loss: 2.7832053844857954

Epoch: 6| Step: 5
Training loss: 2.9645775636539535
Validation loss: 2.789641622163664

Epoch: 6| Step: 6
Training loss: 3.582327161773745
Validation loss: 2.797171699743374

Epoch: 6| Step: 7
Training loss: 3.353872361312965
Validation loss: 2.780779607172707

Epoch: 6| Step: 8
Training loss: 2.903708053857366
Validation loss: 2.78256677139827

Epoch: 6| Step: 9
Training loss: 3.0885987214881006
Validation loss: 2.7832453309338154

Epoch: 6| Step: 10
Training loss: 2.955400185895146
Validation loss: 2.783775397005466

Epoch: 6| Step: 11
Training loss: 2.9850670775987047
Validation loss: 2.7852252803858186

Epoch: 6| Step: 12
Training loss: 2.9181395127096317
Validation loss: 2.787208852743122

Epoch: 6| Step: 13
Training loss: 2.861700394405198
Validation loss: 2.783430333688834

Epoch: 97| Step: 0
Training loss: 2.687987882109984
Validation loss: 2.7854355917910083

Epoch: 6| Step: 1
Training loss: 2.606878857020998
Validation loss: 2.7873394071219746

Epoch: 6| Step: 2
Training loss: 2.3658349733883326
Validation loss: 2.7842897379664184

Epoch: 6| Step: 3
Training loss: 3.1870095866800936
Validation loss: 2.785783977328691

Epoch: 6| Step: 4
Training loss: 3.6802796618303653
Validation loss: 2.7834835985558812

Epoch: 6| Step: 5
Training loss: 2.536457497807443
Validation loss: 2.7836249418755568

Epoch: 6| Step: 6
Training loss: 3.6928170873699506
Validation loss: 2.784720419600816

Epoch: 6| Step: 7
Training loss: 2.797694336632722
Validation loss: 2.78345134244968

Epoch: 6| Step: 8
Training loss: 2.988248697739366
Validation loss: 2.7816191729334845

Epoch: 6| Step: 9
Training loss: 3.56526130606748
Validation loss: 2.7816962307817708

Epoch: 6| Step: 10
Training loss: 2.9245915967345644
Validation loss: 2.7799006183601827

Epoch: 6| Step: 11
Training loss: 2.9857551618843012
Validation loss: 2.781444670411223

Epoch: 6| Step: 12
Training loss: 3.4615863682618873
Validation loss: 2.7772118552520215

Epoch: 6| Step: 13
Training loss: 3.8566237307185927
Validation loss: 2.775904162698751

Epoch: 98| Step: 0
Training loss: 2.909960111626502
Validation loss: 2.776545683953045

Epoch: 6| Step: 1
Training loss: 2.4967191148587333
Validation loss: 2.777265062151043

Epoch: 6| Step: 2
Training loss: 2.9635043731291613
Validation loss: 2.778603490489987

Epoch: 6| Step: 3
Training loss: 3.467624791106231
Validation loss: 2.774869647443177

Epoch: 6| Step: 4
Training loss: 3.506836889315173
Validation loss: 2.774152775290988

Epoch: 6| Step: 5
Training loss: 3.551718475904316
Validation loss: 2.7753330794643856

Epoch: 6| Step: 6
Training loss: 3.0909553004191848
Validation loss: 2.773949237611554

Epoch: 6| Step: 7
Training loss: 2.6444690420928363
Validation loss: 2.7732819100620256

Epoch: 6| Step: 8
Training loss: 3.356301680580775
Validation loss: 2.7720897338662294

Epoch: 6| Step: 9
Training loss: 2.9759011322334157
Validation loss: 2.7678853341221603

Epoch: 6| Step: 10
Training loss: 3.283028837952856
Validation loss: 2.767907851563553

Epoch: 6| Step: 11
Training loss: 2.670644376342102
Validation loss: 2.7695083213396345

Epoch: 6| Step: 12
Training loss: 3.3437671126168413
Validation loss: 2.769910501568594

Epoch: 6| Step: 13
Training loss: 2.5268845767496164
Validation loss: 2.7726588601510285

Epoch: 99| Step: 0
Training loss: 2.960198222044251
Validation loss: 2.775535521809006

Epoch: 6| Step: 1
Training loss: 3.280726654460353
Validation loss: 2.7730068558202583

Epoch: 6| Step: 2
Training loss: 3.0548796532334537
Validation loss: 2.7768883244697284

Epoch: 6| Step: 3
Training loss: 2.9737295050474
Validation loss: 2.7729411435383864

Epoch: 6| Step: 4
Training loss: 3.4098746236981823
Validation loss: 2.7771436088039683

Epoch: 6| Step: 5
Training loss: 3.2071674424872785
Validation loss: 2.770323139609321

Epoch: 6| Step: 6
Training loss: 2.7425230858803933
Validation loss: 2.7729065810526214

Epoch: 6| Step: 7
Training loss: 3.16661108537048
Validation loss: 2.7627746899817867

Epoch: 6| Step: 8
Training loss: 2.8643576978193783
Validation loss: 2.764120278542679

Epoch: 6| Step: 9
Training loss: 3.762903773545101
Validation loss: 2.7623415482287337

Epoch: 6| Step: 10
Training loss: 1.9744310911687457
Validation loss: 2.76044728282838

Epoch: 6| Step: 11
Training loss: 3.362153080057515
Validation loss: 2.76202762440254

Epoch: 6| Step: 12
Training loss: 2.9153593312338706
Validation loss: 2.759088025524231

Epoch: 6| Step: 13
Training loss: 3.1343101669710864
Validation loss: 2.7598621470055256

Epoch: 100| Step: 0
Training loss: 3.1890335881643566
Validation loss: 2.7594485541164917

Epoch: 6| Step: 1
Training loss: 2.6366648576668354
Validation loss: 2.7605286686735875

Epoch: 6| Step: 2
Training loss: 3.2544106118905973
Validation loss: 2.760634736455806

Epoch: 6| Step: 3
Training loss: 3.886341847303395
Validation loss: 2.7584196752374925

Epoch: 6| Step: 4
Training loss: 2.314390080233115
Validation loss: 2.75978622310978

Epoch: 6| Step: 5
Training loss: 3.062781963213675
Validation loss: 2.758619061138996

Epoch: 6| Step: 6
Training loss: 2.5015747832473845
Validation loss: 2.758379412949816

Epoch: 6| Step: 7
Training loss: 3.2516997367497686
Validation loss: 2.761355060451609

Epoch: 6| Step: 8
Training loss: 2.8097323893662036
Validation loss: 2.760267655260388

Epoch: 6| Step: 9
Training loss: 3.315922534474934
Validation loss: 2.7596044139816764

Epoch: 6| Step: 10
Training loss: 2.889143940678785
Validation loss: 2.7648634805632977

Epoch: 6| Step: 11
Training loss: 3.1619612887074027
Validation loss: 2.7672292937747227

Epoch: 6| Step: 12
Training loss: 3.3629542955008964
Validation loss: 2.761549401977292

Epoch: 6| Step: 13
Training loss: 3.08240501931933
Validation loss: 2.7625155684793827

Epoch: 101| Step: 0
Training loss: 3.586085231289376
Validation loss: 2.768269855545706

Epoch: 6| Step: 1
Training loss: 3.1373424171297875
Validation loss: 2.7759461074287843

Epoch: 6| Step: 2
Training loss: 3.5126422350990656
Validation loss: 2.7581842875985165

Epoch: 6| Step: 3
Training loss: 3.5619509089758807
Validation loss: 2.758888240958608

Epoch: 6| Step: 4
Training loss: 2.9254168091196986
Validation loss: 2.761950638769556

Epoch: 6| Step: 5
Training loss: 2.851193924168065
Validation loss: 2.763537460346273

Epoch: 6| Step: 6
Training loss: 2.8656380855881367
Validation loss: 2.7688368522917814

Epoch: 6| Step: 7
Training loss: 2.8190761402858566
Validation loss: 2.768630035741469

Epoch: 6| Step: 8
Training loss: 3.0097710116150695
Validation loss: 2.768366463500184

Epoch: 6| Step: 9
Training loss: 2.5271064847392526
Validation loss: 2.768584574436643

Epoch: 6| Step: 10
Training loss: 3.2411771004184353
Validation loss: 2.769969590599407

Epoch: 6| Step: 11
Training loss: 2.9257507730075702
Validation loss: 2.7722997674726324

Epoch: 6| Step: 12
Training loss: 2.635617898086123
Validation loss: 2.77551578043451

Epoch: 6| Step: 13
Training loss: 3.639254463475556
Validation loss: 2.772583610301958

Epoch: 102| Step: 0
Training loss: 3.453258667166895
Validation loss: 2.7725602343893683

Epoch: 6| Step: 1
Training loss: 3.2235885843584406
Validation loss: 2.769906784629836

Epoch: 6| Step: 2
Training loss: 2.854402147217871
Validation loss: 2.7691253235499533

Epoch: 6| Step: 3
Training loss: 3.095147481926425
Validation loss: 2.768445112578204

Epoch: 6| Step: 4
Training loss: 2.692807125047674
Validation loss: 2.7676167612009306

Epoch: 6| Step: 5
Training loss: 2.9444941590468696
Validation loss: 2.7672707835729904

Epoch: 6| Step: 6
Training loss: 2.38107186199306
Validation loss: 2.7612499042092935

Epoch: 6| Step: 7
Training loss: 3.6150234661686094
Validation loss: 2.7649027063871094

Epoch: 6| Step: 8
Training loss: 3.4496633171880884
Validation loss: 2.7643481051193466

Epoch: 6| Step: 9
Training loss: 2.444016183078462
Validation loss: 2.7635294949279077

Epoch: 6| Step: 10
Training loss: 3.4199570109916952
Validation loss: 2.767592384609121

Epoch: 6| Step: 11
Training loss: 3.043882651444395
Validation loss: 2.762684406292672

Epoch: 6| Step: 12
Training loss: 3.226150153830952
Validation loss: 2.7657883933427017

Epoch: 6| Step: 13
Training loss: 3.120021975024181
Validation loss: 2.7765052579317033

Epoch: 103| Step: 0
Training loss: 3.392379236622993
Validation loss: 2.760922932804739

Epoch: 6| Step: 1
Training loss: 2.658050555153845
Validation loss: 2.773939026279229

Epoch: 6| Step: 2
Training loss: 3.094587732814176
Validation loss: 2.7660207278162248

Epoch: 6| Step: 3
Training loss: 2.139437269396183
Validation loss: 2.763476262448976

Epoch: 6| Step: 4
Training loss: 3.6398046003022397
Validation loss: 2.7697936803149283

Epoch: 6| Step: 5
Training loss: 3.138238711991161
Validation loss: 2.7639066515205237

Epoch: 6| Step: 6
Training loss: 2.8375044768041846
Validation loss: 2.769006718418951

Epoch: 6| Step: 7
Training loss: 2.969751450127958
Validation loss: 2.764059834614733

Epoch: 6| Step: 8
Training loss: 3.6626192353404603
Validation loss: 2.7618077332218838

Epoch: 6| Step: 9
Training loss: 3.6879692425634785
Validation loss: 2.7646220836919952

Epoch: 6| Step: 10
Training loss: 2.9629446991604826
Validation loss: 2.7558396033766654

Epoch: 6| Step: 11
Training loss: 3.6331166129849675
Validation loss: 2.7556593540322925

Epoch: 6| Step: 12
Training loss: 1.7079839426666115
Validation loss: 2.75215629693366

Epoch: 6| Step: 13
Training loss: 2.663275907404256
Validation loss: 2.7526256540921055

Epoch: 104| Step: 0
Training loss: 3.0110584529700097
Validation loss: 2.755632080682748

Epoch: 6| Step: 1
Training loss: 3.241987475004482
Validation loss: 2.7527063333541295

Epoch: 6| Step: 2
Training loss: 2.4967651419409136
Validation loss: 2.747599909860931

Epoch: 6| Step: 3
Training loss: 3.3182850829952524
Validation loss: 2.7514115856335275

Epoch: 6| Step: 4
Training loss: 2.8189416655275896
Validation loss: 2.7489866643854857

Epoch: 6| Step: 5
Training loss: 3.193077294259677
Validation loss: 2.7521014346120785

Epoch: 6| Step: 6
Training loss: 3.449576232979029
Validation loss: 2.7502432050955927

Epoch: 6| Step: 7
Training loss: 3.6545627972291843
Validation loss: 2.747804988799789

Epoch: 6| Step: 8
Training loss: 2.80901553153025
Validation loss: 2.748646276167116

Epoch: 6| Step: 9
Training loss: 2.4810407804976093
Validation loss: 2.7465337226000983

Epoch: 6| Step: 10
Training loss: 2.9030015079443126
Validation loss: 2.749331197208519

Epoch: 6| Step: 11
Training loss: 2.799588043697948
Validation loss: 2.758447578095859

Epoch: 6| Step: 12
Training loss: 3.492446650846479
Validation loss: 2.7781219571362676

Epoch: 6| Step: 13
Training loss: 2.994781883334337
Validation loss: 2.790064124150652

Epoch: 105| Step: 0
Training loss: 2.8712498628901115
Validation loss: 2.7609489690781976

Epoch: 6| Step: 1
Training loss: 3.895453830669156
Validation loss: 2.7484405902791846

Epoch: 6| Step: 2
Training loss: 3.2414947137279086
Validation loss: 2.7459093192190407

Epoch: 6| Step: 3
Training loss: 3.1481595733119443
Validation loss: 2.7451082529488686

Epoch: 6| Step: 4
Training loss: 3.164148098764969
Validation loss: 2.7449085744402932

Epoch: 6| Step: 5
Training loss: 3.4248644168497693
Validation loss: 2.746315686290582

Epoch: 6| Step: 6
Training loss: 2.90461767152736
Validation loss: 2.746093394313984

Epoch: 6| Step: 7
Training loss: 2.762681418283151
Validation loss: 2.74956353677522

Epoch: 6| Step: 8
Training loss: 3.2680447753117434
Validation loss: 2.7480392578974717

Epoch: 6| Step: 9
Training loss: 2.6908448274598684
Validation loss: 2.746080651201918

Epoch: 6| Step: 10
Training loss: 2.417484462968196
Validation loss: 2.7462894888820664

Epoch: 6| Step: 11
Training loss: 2.910327962635424
Validation loss: 2.741693368569704

Epoch: 6| Step: 12
Training loss: 3.1523086564806206
Validation loss: 2.7428304412074844

Epoch: 6| Step: 13
Training loss: 2.900103889446045
Validation loss: 2.7423569658126876

Epoch: 106| Step: 0
Training loss: 2.5144238180930056
Validation loss: 2.7470286771878127

Epoch: 6| Step: 1
Training loss: 2.8278989754239556
Validation loss: 2.74679161900079

Epoch: 6| Step: 2
Training loss: 3.181814471155951
Validation loss: 2.762160578332781

Epoch: 6| Step: 3
Training loss: 2.59533532653361
Validation loss: 2.784210828392883

Epoch: 6| Step: 4
Training loss: 3.4355918443262117
Validation loss: 2.778243103805768

Epoch: 6| Step: 5
Training loss: 3.2490043582247137
Validation loss: 2.7500818730730376

Epoch: 6| Step: 6
Training loss: 3.08765589517387
Validation loss: 2.7436191619676396

Epoch: 6| Step: 7
Training loss: 2.8775683002336825
Validation loss: 2.7421768151340284

Epoch: 6| Step: 8
Training loss: 3.2482236262416135
Validation loss: 2.7460297584502507

Epoch: 6| Step: 9
Training loss: 3.3574093767946547
Validation loss: 2.750485423063638

Epoch: 6| Step: 10
Training loss: 2.9933095078344945
Validation loss: 2.750360375784382

Epoch: 6| Step: 11
Training loss: 3.226086006356643
Validation loss: 2.754812334073022

Epoch: 6| Step: 12
Training loss: 3.016925906709462
Validation loss: 2.7588190004040385

Epoch: 6| Step: 13
Training loss: 3.502956776318802
Validation loss: 2.7603154509630685

Epoch: 107| Step: 0
Training loss: 2.9172855992058757
Validation loss: 2.757884633542222

Epoch: 6| Step: 1
Training loss: 2.8201495094436453
Validation loss: 2.7550789923884262

Epoch: 6| Step: 2
Training loss: 3.0486152569726452
Validation loss: 2.755139789666526

Epoch: 6| Step: 3
Training loss: 3.374991805455185
Validation loss: 2.7551980435487686

Epoch: 6| Step: 4
Training loss: 3.18788324183911
Validation loss: 2.754438564007772

Epoch: 6| Step: 5
Training loss: 3.0637033395003863
Validation loss: 2.75299217770929

Epoch: 6| Step: 6
Training loss: 3.1696337970320165
Validation loss: 2.7547516049486114

Epoch: 6| Step: 7
Training loss: 2.78123216944776
Validation loss: 2.7541562617007673

Epoch: 6| Step: 8
Training loss: 2.933230604916056
Validation loss: 2.7514519126125196

Epoch: 6| Step: 9
Training loss: 3.4323760250454973
Validation loss: 2.7508787818739373

Epoch: 6| Step: 10
Training loss: 3.258289476052338
Validation loss: 2.750542023268873

Epoch: 6| Step: 11
Training loss: 2.698637130942571
Validation loss: 2.749315272615071

Epoch: 6| Step: 12
Training loss: 3.220244125684248
Validation loss: 2.7468166757782115

Epoch: 6| Step: 13
Training loss: 3.1762246060547907
Validation loss: 2.7475935735295143

Epoch: 108| Step: 0
Training loss: 3.2527187419876222
Validation loss: 2.745291694456146

Epoch: 6| Step: 1
Training loss: 2.4759780723697773
Validation loss: 2.7445450579155843

Epoch: 6| Step: 2
Training loss: 2.9126956792102296
Validation loss: 2.74661820606031

Epoch: 6| Step: 3
Training loss: 3.1943971400052513
Validation loss: 2.7442528547099303

Epoch: 6| Step: 4
Training loss: 3.064747199979188
Validation loss: 2.743953815983215

Epoch: 6| Step: 5
Training loss: 2.7758017335496157
Validation loss: 2.74424407895933

Epoch: 6| Step: 6
Training loss: 3.5334502260797596
Validation loss: 2.742641633289385

Epoch: 6| Step: 7
Training loss: 3.4374485358807356
Validation loss: 2.742536443775411

Epoch: 6| Step: 8
Training loss: 3.0447997239369813
Validation loss: 2.7396079267051983

Epoch: 6| Step: 9
Training loss: 2.7569412714002803
Validation loss: 2.737988013143339

Epoch: 6| Step: 10
Training loss: 3.5015420241567905
Validation loss: 2.7362852553520254

Epoch: 6| Step: 11
Training loss: 2.8744794954904647
Validation loss: 2.7384458301684846

Epoch: 6| Step: 12
Training loss: 3.031073181658331
Validation loss: 2.7375038324504284

Epoch: 6| Step: 13
Training loss: 2.8640398839379158
Validation loss: 2.73479843494117

Epoch: 109| Step: 0
Training loss: 3.7328702696221714
Validation loss: 2.735192064600513

Epoch: 6| Step: 1
Training loss: 2.9090511809692408
Validation loss: 2.7381129803608486

Epoch: 6| Step: 2
Training loss: 3.6111072165313325
Validation loss: 2.7330445993491663

Epoch: 6| Step: 3
Training loss: 2.723763589601898
Validation loss: 2.7363558849334777

Epoch: 6| Step: 4
Training loss: 2.694921227402671
Validation loss: 2.7354810267992513

Epoch: 6| Step: 5
Training loss: 3.0007858836469206
Validation loss: 2.737346604640581

Epoch: 6| Step: 6
Training loss: 2.9679429412868394
Validation loss: 2.748622646311486

Epoch: 6| Step: 7
Training loss: 3.0602349449169455
Validation loss: 2.739312973228944

Epoch: 6| Step: 8
Training loss: 2.7625280594587407
Validation loss: 2.747460791787962

Epoch: 6| Step: 9
Training loss: 3.17025324510875
Validation loss: 2.7404140013325287

Epoch: 6| Step: 10
Training loss: 3.5626988941017985
Validation loss: 2.7426214167859437

Epoch: 6| Step: 11
Training loss: 3.0163665017979735
Validation loss: 2.7471472205404197

Epoch: 6| Step: 12
Training loss: 2.4620048993431447
Validation loss: 2.7422045541901494

Epoch: 6| Step: 13
Training loss: 2.4783073560237905
Validation loss: 2.7353266921768933

Epoch: 110| Step: 0
Training loss: 3.622792328069515
Validation loss: 2.731743270181438

Epoch: 6| Step: 1
Training loss: 3.022866838405141
Validation loss: 2.736205540399295

Epoch: 6| Step: 2
Training loss: 2.8138799884584667
Validation loss: 2.7280185609113663

Epoch: 6| Step: 3
Training loss: 2.8481823261277026
Validation loss: 2.7321646151889363

Epoch: 6| Step: 4
Training loss: 2.7823077986999465
Validation loss: 2.7294653730850897

Epoch: 6| Step: 5
Training loss: 2.8795943660650765
Validation loss: 2.7256398907056707

Epoch: 6| Step: 6
Training loss: 3.4812676639896343
Validation loss: 2.733165739605491

Epoch: 6| Step: 7
Training loss: 2.77290962461002
Validation loss: 2.730186428441941

Epoch: 6| Step: 8
Training loss: 3.0439340336051868
Validation loss: 2.7310271983249486

Epoch: 6| Step: 9
Training loss: 3.229769316192014
Validation loss: 2.7268064341418605

Epoch: 6| Step: 10
Training loss: 3.094053311362732
Validation loss: 2.727404800602959

Epoch: 6| Step: 11
Training loss: 3.2397186807077794
Validation loss: 2.727383393959933

Epoch: 6| Step: 12
Training loss: 3.005684077236954
Validation loss: 2.7229905947101254

Epoch: 6| Step: 13
Training loss: 2.5610305480624653
Validation loss: 2.7213491534075884

Epoch: 111| Step: 0
Training loss: 3.9887547973106656
Validation loss: 2.7255300230111787

Epoch: 6| Step: 1
Training loss: 3.3628045607126507
Validation loss: 2.7285606377099763

Epoch: 6| Step: 2
Training loss: 2.581045634975139
Validation loss: 2.740921635639691

Epoch: 6| Step: 3
Training loss: 2.292068226629321
Validation loss: 2.7360451796566276

Epoch: 6| Step: 4
Training loss: 3.5494718078104124
Validation loss: 2.7512678838780755

Epoch: 6| Step: 5
Training loss: 2.4707417240067904
Validation loss: 2.739304631807574

Epoch: 6| Step: 6
Training loss: 3.1200432185089633
Validation loss: 2.729541157010541

Epoch: 6| Step: 7
Training loss: 3.0503993851619793
Validation loss: 2.7248531960935107

Epoch: 6| Step: 8
Training loss: 3.1408273811989047
Validation loss: 2.721843116492232

Epoch: 6| Step: 9
Training loss: 2.6847967702434694
Validation loss: 2.7221726281249303

Epoch: 6| Step: 10
Training loss: 3.1418363597854553
Validation loss: 2.72740831603631

Epoch: 6| Step: 11
Training loss: 2.849220798450902
Validation loss: 2.7275436257581562

Epoch: 6| Step: 12
Training loss: 3.053835386565115
Validation loss: 2.7232820490185454

Epoch: 6| Step: 13
Training loss: 3.068349273684439
Validation loss: 2.724714037215163

Epoch: 112| Step: 0
Training loss: 2.5836815343015704
Validation loss: 2.7257578415494605

Epoch: 6| Step: 1
Training loss: 3.0920218833454918
Validation loss: 2.7205097918446746

Epoch: 6| Step: 2
Training loss: 2.7650948571322482
Validation loss: 2.7179624826399533

Epoch: 6| Step: 3
Training loss: 2.907973240053657
Validation loss: 2.719604276879881

Epoch: 6| Step: 4
Training loss: 1.8239169473562307
Validation loss: 2.722876523569934

Epoch: 6| Step: 5
Training loss: 3.722169345903999
Validation loss: 2.720551230385674

Epoch: 6| Step: 6
Training loss: 2.953924484620391
Validation loss: 2.719664164792604

Epoch: 6| Step: 7
Training loss: 3.271297802515714
Validation loss: 2.7189594311188947

Epoch: 6| Step: 8
Training loss: 2.9360625625617818
Validation loss: 2.723983351998178

Epoch: 6| Step: 9
Training loss: 3.0225822559961366
Validation loss: 2.7207877952446964

Epoch: 6| Step: 10
Training loss: 2.886605432167775
Validation loss: 2.7227044366604294

Epoch: 6| Step: 11
Training loss: 2.7197342768068333
Validation loss: 2.7226820232276503

Epoch: 6| Step: 12
Training loss: 3.9129308103843936
Validation loss: 2.725636963666788

Epoch: 6| Step: 13
Training loss: 3.8912359164014054
Validation loss: 2.7245087586383385

Epoch: 113| Step: 0
Training loss: 2.5900324641958408
Validation loss: 2.7256490621365206

Epoch: 6| Step: 1
Training loss: 3.0826500487798136
Validation loss: 2.727949670656046

Epoch: 6| Step: 2
Training loss: 3.3330442939056057
Validation loss: 2.732479319414677

Epoch: 6| Step: 3
Training loss: 3.473205728902093
Validation loss: 2.7272639182319214

Epoch: 6| Step: 4
Training loss: 3.6124530564792274
Validation loss: 2.720931987434049

Epoch: 6| Step: 5
Training loss: 3.1685635423445433
Validation loss: 2.714736794015719

Epoch: 6| Step: 6
Training loss: 2.928014659125732
Validation loss: 2.715633192271515

Epoch: 6| Step: 7
Training loss: 2.526358882741472
Validation loss: 2.7118584881541836

Epoch: 6| Step: 8
Training loss: 2.726649504314528
Validation loss: 2.7151057177965723

Epoch: 6| Step: 9
Training loss: 2.738176765570791
Validation loss: 2.715588774327898

Epoch: 6| Step: 10
Training loss: 3.1251248144019494
Validation loss: 2.7136485510358708

Epoch: 6| Step: 11
Training loss: 3.1883364309271602
Validation loss: 2.718286744733504

Epoch: 6| Step: 12
Training loss: 3.0837521311579015
Validation loss: 2.7188011525770674

Epoch: 6| Step: 13
Training loss: 2.836018710904615
Validation loss: 2.713028655430706

Epoch: 114| Step: 0
Training loss: 2.8276200660422046
Validation loss: 2.7111321999039926

Epoch: 6| Step: 1
Training loss: 2.1524029012261026
Validation loss: 2.7136039626749024

Epoch: 6| Step: 2
Training loss: 3.4093599733463824
Validation loss: 2.711991218843194

Epoch: 6| Step: 3
Training loss: 3.6370817959985025
Validation loss: 2.7129443487487372

Epoch: 6| Step: 4
Training loss: 2.7900878560169415
Validation loss: 2.7147546023633433

Epoch: 6| Step: 5
Training loss: 3.185186107234509
Validation loss: 2.724206831733746

Epoch: 6| Step: 6
Training loss: 2.5104863538342697
Validation loss: 2.7264847339301514

Epoch: 6| Step: 7
Training loss: 3.079376121352007
Validation loss: 2.7187503828369746

Epoch: 6| Step: 8
Training loss: 3.4363671950486525
Validation loss: 2.736069909460804

Epoch: 6| Step: 9
Training loss: 3.437621652011095
Validation loss: 2.7372465960269925

Epoch: 6| Step: 10
Training loss: 3.1474974485452143
Validation loss: 2.729097200280024

Epoch: 6| Step: 11
Training loss: 2.848833842698739
Validation loss: 2.717624661958974

Epoch: 6| Step: 12
Training loss: 2.451638129522267
Validation loss: 2.7116070640073264

Epoch: 6| Step: 13
Training loss: 3.4259008127920687
Validation loss: 2.7082700477444273

Epoch: 115| Step: 0
Training loss: 3.254828753910896
Validation loss: 2.7106410147501916

Epoch: 6| Step: 1
Training loss: 2.9665705661710233
Validation loss: 2.7108315871542117

Epoch: 6| Step: 2
Training loss: 2.7811376999031805
Validation loss: 2.7114784916341104

Epoch: 6| Step: 3
Training loss: 2.7817306960385655
Validation loss: 2.7109078106624627

Epoch: 6| Step: 4
Training loss: 3.0252735171915943
Validation loss: 2.7101662679979617

Epoch: 6| Step: 5
Training loss: 3.124999694824204
Validation loss: 2.7101366042656636

Epoch: 6| Step: 6
Training loss: 3.435619602875741
Validation loss: 2.7114180787606874

Epoch: 6| Step: 7
Training loss: 2.5838968113647662
Validation loss: 2.712137800395608

Epoch: 6| Step: 8
Training loss: 3.209616730527925
Validation loss: 2.7082468124717742

Epoch: 6| Step: 9
Training loss: 2.9984164827135995
Validation loss: 2.7070113442967925

Epoch: 6| Step: 10
Training loss: 3.5586947815138115
Validation loss: 2.708694080594226

Epoch: 6| Step: 11
Training loss: 3.0965942255532113
Validation loss: 2.705396687913071

Epoch: 6| Step: 12
Training loss: 2.2066276248731946
Validation loss: 2.705953286472574

Epoch: 6| Step: 13
Training loss: 3.4925117768817495
Validation loss: 2.709155707692494

Epoch: 116| Step: 0
Training loss: 3.116213691827363
Validation loss: 2.7096673360491454

Epoch: 6| Step: 1
Training loss: 2.7528248063616876
Validation loss: 2.708589321814217

Epoch: 6| Step: 2
Training loss: 2.7224312775540613
Validation loss: 2.7139015600741248

Epoch: 6| Step: 3
Training loss: 3.1277743422145132
Validation loss: 2.7045159622001096

Epoch: 6| Step: 4
Training loss: 3.046790019097344
Validation loss: 2.705564120301434

Epoch: 6| Step: 5
Training loss: 3.0983368750010403
Validation loss: 2.7045409111045515

Epoch: 6| Step: 6
Training loss: 3.077275967535426
Validation loss: 2.7077573250487332

Epoch: 6| Step: 7
Training loss: 2.401005168866334
Validation loss: 2.709217760741917

Epoch: 6| Step: 8
Training loss: 2.723436197356078
Validation loss: 2.7119078460345247

Epoch: 6| Step: 9
Training loss: 3.421964461319862
Validation loss: 2.711722610378284

Epoch: 6| Step: 10
Training loss: 3.272655457373382
Validation loss: 2.7126949474827344

Epoch: 6| Step: 11
Training loss: 2.8103604125625123
Validation loss: 2.7138196922311213

Epoch: 6| Step: 12
Training loss: 3.595039202777466
Validation loss: 2.7129524083532446

Epoch: 6| Step: 13
Training loss: 3.3816706820546076
Validation loss: 2.7155603102487147

Epoch: 117| Step: 0
Training loss: 3.37725754574232
Validation loss: 2.7168286183989823

Epoch: 6| Step: 1
Training loss: 2.9594600484000746
Validation loss: 2.71303652863276

Epoch: 6| Step: 2
Training loss: 2.6270314485012918
Validation loss: 2.710861961061995

Epoch: 6| Step: 3
Training loss: 2.9565906675162426
Validation loss: 2.711952393274305

Epoch: 6| Step: 4
Training loss: 2.939187559380365
Validation loss: 2.7112486685741266

Epoch: 6| Step: 5
Training loss: 2.9890604835738754
Validation loss: 2.7118154198052915

Epoch: 6| Step: 6
Training loss: 3.0219495793698985
Validation loss: 2.7105542362047452

Epoch: 6| Step: 7
Training loss: 3.3473088229959225
Validation loss: 2.71216092293381

Epoch: 6| Step: 8
Training loss: 2.72193336468038
Validation loss: 2.7081549353015095

Epoch: 6| Step: 9
Training loss: 3.2244260055373495
Validation loss: 2.7086724068268375

Epoch: 6| Step: 10
Training loss: 2.7465585502468506
Validation loss: 2.7101186511127846

Epoch: 6| Step: 11
Training loss: 3.528256658322502
Validation loss: 2.7069335402787393

Epoch: 6| Step: 12
Training loss: 2.8535777874389274
Validation loss: 2.7102209018045684

Epoch: 6| Step: 13
Training loss: 3.36118796464753
Validation loss: 2.7051251094130726

Epoch: 118| Step: 0
Training loss: 2.769047230767858
Validation loss: 2.7066323428076804

Epoch: 6| Step: 1
Training loss: 2.9306227348385594
Validation loss: 2.704815240980103

Epoch: 6| Step: 2
Training loss: 2.82961676439146
Validation loss: 2.705384693134173

Epoch: 6| Step: 3
Training loss: 3.0009287350260547
Validation loss: 2.7043839329748427

Epoch: 6| Step: 4
Training loss: 3.002729763416031
Validation loss: 2.7019242007083655

Epoch: 6| Step: 5
Training loss: 3.2880733207639588
Validation loss: 2.704424364001694

Epoch: 6| Step: 6
Training loss: 2.434624173654603
Validation loss: 2.7038297922849606

Epoch: 6| Step: 7
Training loss: 3.3285398985809547
Validation loss: 2.7054590849222144

Epoch: 6| Step: 8
Training loss: 2.9039896717255673
Validation loss: 2.7087899541749176

Epoch: 6| Step: 9
Training loss: 2.641528274168191
Validation loss: 2.711299912561031

Epoch: 6| Step: 10
Training loss: 2.8171786070655274
Validation loss: 2.709090658150991

Epoch: 6| Step: 11
Training loss: 2.886166655277573
Validation loss: 2.709287581024818

Epoch: 6| Step: 12
Training loss: 3.7880319353991085
Validation loss: 2.718729926442916

Epoch: 6| Step: 13
Training loss: 3.839140570548905
Validation loss: 2.7213265319228115

Epoch: 119| Step: 0
Training loss: 3.015003832155136
Validation loss: 2.718401399846445

Epoch: 6| Step: 1
Training loss: 3.1409817772901127
Validation loss: 2.7109657639094

Epoch: 6| Step: 2
Training loss: 2.9496196954279124
Validation loss: 2.700830162998138

Epoch: 6| Step: 3
Training loss: 3.5168229838216387
Validation loss: 2.700143596669655

Epoch: 6| Step: 4
Training loss: 3.3028939071557035
Validation loss: 2.6942138677524743

Epoch: 6| Step: 5
Training loss: 2.6828509195250647
Validation loss: 2.695718037023836

Epoch: 6| Step: 6
Training loss: 3.0166559384262377
Validation loss: 2.69498769007691

Epoch: 6| Step: 7
Training loss: 3.1366947310918816
Validation loss: 2.6940986799924995

Epoch: 6| Step: 8
Training loss: 2.8884026309719975
Validation loss: 2.6960033423685825

Epoch: 6| Step: 9
Training loss: 2.3398737069633855
Validation loss: 2.7006301743038663

Epoch: 6| Step: 10
Training loss: 2.8475899394285626
Validation loss: 2.7079951041198824

Epoch: 6| Step: 11
Training loss: 3.58236403255833
Validation loss: 2.704942890401643

Epoch: 6| Step: 12
Training loss: 2.5727596054839372
Validation loss: 2.695637198506699

Epoch: 6| Step: 13
Training loss: 3.4008303581984416
Validation loss: 2.698084199636773

Epoch: 120| Step: 0
Training loss: 3.183689307902536
Validation loss: 2.6973305092103876

Epoch: 6| Step: 1
Training loss: 2.453836131437617
Validation loss: 2.6972714123391994

Epoch: 6| Step: 2
Training loss: 3.242808822478295
Validation loss: 2.7079460422454256

Epoch: 6| Step: 3
Training loss: 2.4865468446670933
Validation loss: 2.7042116732100396

Epoch: 6| Step: 4
Training loss: 2.751406743300168
Validation loss: 2.708427018342945

Epoch: 6| Step: 5
Training loss: 3.214569487987937
Validation loss: 2.7259431024903984

Epoch: 6| Step: 6
Training loss: 2.861020807941907
Validation loss: 2.7268941884199625

Epoch: 6| Step: 7
Training loss: 3.559569374785542
Validation loss: 2.7315256178087757

Epoch: 6| Step: 8
Training loss: 2.9945787083193895
Validation loss: 2.6987474446564184

Epoch: 6| Step: 9
Training loss: 2.921431727112862
Validation loss: 2.692159766815917

Epoch: 6| Step: 10
Training loss: 3.376469186378715
Validation loss: 2.68940751017424

Epoch: 6| Step: 11
Training loss: 3.258601616809013
Validation loss: 2.688074770203208

Epoch: 6| Step: 12
Training loss: 2.6151809515991307
Validation loss: 2.6888822972282327

Epoch: 6| Step: 13
Training loss: 3.334126537043045
Validation loss: 2.690488970858811

Epoch: 121| Step: 0
Training loss: 3.384682365401611
Validation loss: 2.691088637366507

Epoch: 6| Step: 1
Training loss: 2.54352672449931
Validation loss: 2.6912691605398935

Epoch: 6| Step: 2
Training loss: 2.569060139369031
Validation loss: 2.6918822005985703

Epoch: 6| Step: 3
Training loss: 3.1074605444246997
Validation loss: 2.6904373057172526

Epoch: 6| Step: 4
Training loss: 3.2212630155964312
Validation loss: 2.689726062851452

Epoch: 6| Step: 5
Training loss: 3.4723703547774543
Validation loss: 2.6898678447866105

Epoch: 6| Step: 6
Training loss: 3.091886633547859
Validation loss: 2.696468822992855

Epoch: 6| Step: 7
Training loss: 3.177436500473074
Validation loss: 2.694903589552597

Epoch: 6| Step: 8
Training loss: 3.570549153637984
Validation loss: 2.7007546024008793

Epoch: 6| Step: 9
Training loss: 2.9784917711647276
Validation loss: 2.700484601911195

Epoch: 6| Step: 10
Training loss: 3.102127292817741
Validation loss: 2.699659717511635

Epoch: 6| Step: 11
Training loss: 2.719297945776007
Validation loss: 2.698181388950019

Epoch: 6| Step: 12
Training loss: 2.2618136213101083
Validation loss: 2.6949997349353363

Epoch: 6| Step: 13
Training loss: 2.7185924089732003
Validation loss: 2.6925259655712477

Epoch: 122| Step: 0
Training loss: 3.208932960920291
Validation loss: 2.693812463922806

Epoch: 6| Step: 1
Training loss: 3.0634287768726858
Validation loss: 2.6922194291593486

Epoch: 6| Step: 2
Training loss: 2.7543437637278725
Validation loss: 2.697234502037489

Epoch: 6| Step: 3
Training loss: 2.7945054741732616
Validation loss: 2.6931994653489717

Epoch: 6| Step: 4
Training loss: 2.5997091570820023
Validation loss: 2.6936157221646133

Epoch: 6| Step: 5
Training loss: 3.4029020602480795
Validation loss: 2.7037602890324295

Epoch: 6| Step: 6
Training loss: 2.637342500729855
Validation loss: 2.7124694531779525

Epoch: 6| Step: 7
Training loss: 3.2541884795632936
Validation loss: 2.711856578557525

Epoch: 6| Step: 8
Training loss: 3.0463153031604477
Validation loss: 2.7146066501472195

Epoch: 6| Step: 9
Training loss: 3.670944030916979
Validation loss: 2.6944655980791308

Epoch: 6| Step: 10
Training loss: 3.2993874761681914
Validation loss: 2.686704269323544

Epoch: 6| Step: 11
Training loss: 1.9276688244775846
Validation loss: 2.6809470100757653

Epoch: 6| Step: 12
Training loss: 3.3714388674008453
Validation loss: 2.6838197408927726

Epoch: 6| Step: 13
Training loss: 2.690749754101406
Validation loss: 2.6822009695608657

Epoch: 123| Step: 0
Training loss: 2.469555976741471
Validation loss: 2.682247824728236

Epoch: 6| Step: 1
Training loss: 3.753282127934504
Validation loss: 2.685576834204837

Epoch: 6| Step: 2
Training loss: 3.1381442012780636
Validation loss: 2.692172386158386

Epoch: 6| Step: 3
Training loss: 3.001263670216941
Validation loss: 2.684247148140725

Epoch: 6| Step: 4
Training loss: 2.301020818650133
Validation loss: 2.681056615440135

Epoch: 6| Step: 5
Training loss: 2.7217984702282094
Validation loss: 2.685076768405954

Epoch: 6| Step: 6
Training loss: 3.1975483801360296
Validation loss: 2.684275499207588

Epoch: 6| Step: 7
Training loss: 2.949950111096624
Validation loss: 2.6823578567215227

Epoch: 6| Step: 8
Training loss: 3.21601588595438
Validation loss: 2.682570528483759

Epoch: 6| Step: 9
Training loss: 2.4666002788717067
Validation loss: 2.6813794376992375

Epoch: 6| Step: 10
Training loss: 3.217992600891825
Validation loss: 2.682201467053351

Epoch: 6| Step: 11
Training loss: 3.0768098296819293
Validation loss: 2.6802117227108098

Epoch: 6| Step: 12
Training loss: 3.4763922831837593
Validation loss: 2.6830992586319904

Epoch: 6| Step: 13
Training loss: 2.926534110204998
Validation loss: 2.679493668722751

Epoch: 124| Step: 0
Training loss: 2.4229036177209733
Validation loss: 2.680301324853486

Epoch: 6| Step: 1
Training loss: 3.310347235407447
Validation loss: 2.6794540297348357

Epoch: 6| Step: 2
Training loss: 3.2350865562686715
Validation loss: 2.6826542798067856

Epoch: 6| Step: 3
Training loss: 3.2669310080042355
Validation loss: 2.682530405515053

Epoch: 6| Step: 4
Training loss: 2.6529463025988025
Validation loss: 2.6809323288148907

Epoch: 6| Step: 5
Training loss: 3.351212489918819
Validation loss: 2.6826194753229116

Epoch: 6| Step: 6
Training loss: 3.1803283795363915
Validation loss: 2.6803172730666165

Epoch: 6| Step: 7
Training loss: 2.990664580112137
Validation loss: 2.681478121602805

Epoch: 6| Step: 8
Training loss: 3.0245277351397992
Validation loss: 2.68091504645903

Epoch: 6| Step: 9
Training loss: 3.5007999051053944
Validation loss: 2.6853959255063025

Epoch: 6| Step: 10
Training loss: 2.7356250630292216
Validation loss: 2.6841120225643857

Epoch: 6| Step: 11
Training loss: 2.55332084287505
Validation loss: 2.68261231750789

Epoch: 6| Step: 12
Training loss: 3.094967226954963
Validation loss: 2.677248691147328

Epoch: 6| Step: 13
Training loss: 2.317498758391837
Validation loss: 2.6762655448807924

Epoch: 125| Step: 0
Training loss: 3.4332307139742264
Validation loss: 2.6784523206051905

Epoch: 6| Step: 1
Training loss: 2.4878763920476743
Validation loss: 2.6766167239587655

Epoch: 6| Step: 2
Training loss: 2.954030216080582
Validation loss: 2.6756547004960725

Epoch: 6| Step: 3
Training loss: 2.994669947707614
Validation loss: 2.6773620664017654

Epoch: 6| Step: 4
Training loss: 3.2397875624347705
Validation loss: 2.677521771033701

Epoch: 6| Step: 5
Training loss: 2.953961773552077
Validation loss: 2.677673272607889

Epoch: 6| Step: 6
Training loss: 3.071353958972555
Validation loss: 2.676088388526955

Epoch: 6| Step: 7
Training loss: 2.5754730456746353
Validation loss: 2.6777016817890296

Epoch: 6| Step: 8
Training loss: 3.1595284836914845
Validation loss: 2.675140662985411

Epoch: 6| Step: 9
Training loss: 3.392265098945818
Validation loss: 2.6769695376701717

Epoch: 6| Step: 10
Training loss: 2.3771297542799092
Validation loss: 2.675958730381882

Epoch: 6| Step: 11
Training loss: 3.0229091133287964
Validation loss: 2.674163400639485

Epoch: 6| Step: 12
Training loss: 3.043330238427061
Validation loss: 2.6728200679714442

Epoch: 6| Step: 13
Training loss: 3.4764675856074505
Validation loss: 2.672295001546881

Epoch: 126| Step: 0
Training loss: 2.9746789454479305
Validation loss: 2.6738346160028708

Epoch: 6| Step: 1
Training loss: 2.7639329119764717
Validation loss: 2.6779396912650184

Epoch: 6| Step: 2
Training loss: 2.7204775528461083
Validation loss: 2.6749868031696544

Epoch: 6| Step: 3
Training loss: 3.492882576197069
Validation loss: 2.682047429221817

Epoch: 6| Step: 4
Training loss: 3.145886014450932
Validation loss: 2.677506179584135

Epoch: 6| Step: 5
Training loss: 3.362639929827227
Validation loss: 2.6843035997522677

Epoch: 6| Step: 6
Training loss: 3.02101278539362
Validation loss: 2.672576317158088

Epoch: 6| Step: 7
Training loss: 2.933592449650178
Validation loss: 2.6756485281779403

Epoch: 6| Step: 8
Training loss: 3.2416215149808467
Validation loss: 2.669527625160633

Epoch: 6| Step: 9
Training loss: 2.7423937249956483
Validation loss: 2.676139138023546

Epoch: 6| Step: 10
Training loss: 3.090130625065591
Validation loss: 2.6798829951769427

Epoch: 6| Step: 11
Training loss: 2.984715946554414
Validation loss: 2.686602784917983

Epoch: 6| Step: 12
Training loss: 2.0246827995621373
Validation loss: 2.6929808425766284

Epoch: 6| Step: 13
Training loss: 3.6356000152668475
Validation loss: 2.712194645075423

Epoch: 127| Step: 0
Training loss: 2.8668646773623805
Validation loss: 2.6890093701778546

Epoch: 6| Step: 1
Training loss: 2.8562294589917157
Validation loss: 2.6765145994118535

Epoch: 6| Step: 2
Training loss: 2.966556421295982
Validation loss: 2.669739698064015

Epoch: 6| Step: 3
Training loss: 3.096284386971727
Validation loss: 2.6708639539918537

Epoch: 6| Step: 4
Training loss: 2.6784953587947395
Validation loss: 2.669429778682367

Epoch: 6| Step: 5
Training loss: 1.9723199841024635
Validation loss: 2.6696836097274113

Epoch: 6| Step: 6
Training loss: 2.8238235555916047
Validation loss: 2.6719132095461213

Epoch: 6| Step: 7
Training loss: 3.0119248850297584
Validation loss: 2.6727928317533154

Epoch: 6| Step: 8
Training loss: 3.1528575530488046
Validation loss: 2.669508811172645

Epoch: 6| Step: 9
Training loss: 3.4798243618631823
Validation loss: 2.6731225002521044

Epoch: 6| Step: 10
Training loss: 3.120145460308132
Validation loss: 2.671546557478142

Epoch: 6| Step: 11
Training loss: 2.9713807345826
Validation loss: 2.672820701970822

Epoch: 6| Step: 12
Training loss: 3.569421702970964
Validation loss: 2.673305740322471

Epoch: 6| Step: 13
Training loss: 3.333995101723737
Validation loss: 2.6698712646609546

Epoch: 128| Step: 0
Training loss: 2.885605531609894
Validation loss: 2.6772630488439977

Epoch: 6| Step: 1
Training loss: 3.1893620755432543
Validation loss: 2.6713082893248505

Epoch: 6| Step: 2
Training loss: 3.1608107446664113
Validation loss: 2.6744899401862265

Epoch: 6| Step: 3
Training loss: 3.126273544204563
Validation loss: 2.667561796781727

Epoch: 6| Step: 4
Training loss: 2.550045731078331
Validation loss: 2.6687357807119234

Epoch: 6| Step: 5
Training loss: 2.824901619607562
Validation loss: 2.6683398424256852

Epoch: 6| Step: 6
Training loss: 3.1825939644653647
Validation loss: 2.665975907739191

Epoch: 6| Step: 7
Training loss: 2.870425690239773
Validation loss: 2.6661126563674378

Epoch: 6| Step: 8
Training loss: 2.4813529773934198
Validation loss: 2.669378906431229

Epoch: 6| Step: 9
Training loss: 3.3680336723184783
Validation loss: 2.666365574430513

Epoch: 6| Step: 10
Training loss: 2.7152695575751205
Validation loss: 2.6663526060403893

Epoch: 6| Step: 11
Training loss: 3.244146798327209
Validation loss: 2.667542860330306

Epoch: 6| Step: 12
Training loss: 2.4561733088277884
Validation loss: 2.6672723505933806

Epoch: 6| Step: 13
Training loss: 4.207632604493816
Validation loss: 2.6637567427619873

Epoch: 129| Step: 0
Training loss: 2.867417162602471
Validation loss: 2.6678966770182146

Epoch: 6| Step: 1
Training loss: 2.254738480486587
Validation loss: 2.6706956842874536

Epoch: 6| Step: 2
Training loss: 2.5882822337841005
Validation loss: 2.6723197859919536

Epoch: 6| Step: 3
Training loss: 3.5379941561463584
Validation loss: 2.6735066539479284

Epoch: 6| Step: 4
Training loss: 3.029374161600729
Validation loss: 2.6745357020784906

Epoch: 6| Step: 5
Training loss: 2.7055496190515345
Validation loss: 2.6794317415162943

Epoch: 6| Step: 6
Training loss: 2.8344147432310445
Validation loss: 2.676345228031805

Epoch: 6| Step: 7
Training loss: 3.0474195727280637
Validation loss: 2.67424330843751

Epoch: 6| Step: 8
Training loss: 3.59397887454779
Validation loss: 2.6704206199408667

Epoch: 6| Step: 9
Training loss: 3.0832690326756187
Validation loss: 2.667672691109196

Epoch: 6| Step: 10
Training loss: 3.103107365522574
Validation loss: 2.6647913963550054

Epoch: 6| Step: 11
Training loss: 3.0887864494565953
Validation loss: 2.6664734822972322

Epoch: 6| Step: 12
Training loss: 2.970991071782007
Validation loss: 2.661028809499677

Epoch: 6| Step: 13
Training loss: 3.031169615004135
Validation loss: 2.662478207704055

Epoch: 130| Step: 0
Training loss: 3.178157503905196
Validation loss: 2.6650981718935642

Epoch: 6| Step: 1
Training loss: 3.4970906290861254
Validation loss: 2.664246602791547

Epoch: 6| Step: 2
Training loss: 3.07020456061259
Validation loss: 2.6609508325212916

Epoch: 6| Step: 3
Training loss: 2.1221861441221304
Validation loss: 2.6631410991499576

Epoch: 6| Step: 4
Training loss: 1.8464607096834704
Validation loss: 2.6605585766866913

Epoch: 6| Step: 5
Training loss: 3.5786043204217357
Validation loss: 2.671019979533528

Epoch: 6| Step: 6
Training loss: 3.124446972550077
Validation loss: 2.6657993062263317

Epoch: 6| Step: 7
Training loss: 3.52661760698699
Validation loss: 2.6733808636633283

Epoch: 6| Step: 8
Training loss: 2.9063594346310717
Validation loss: 2.6964355991806035

Epoch: 6| Step: 9
Training loss: 3.1918123283380955
Validation loss: 2.6852761377995473

Epoch: 6| Step: 10
Training loss: 2.784638815561164
Validation loss: 2.681646751978354

Epoch: 6| Step: 11
Training loss: 3.02555737365277
Validation loss: 2.6761374385977326

Epoch: 6| Step: 12
Training loss: 2.958285873104024
Validation loss: 2.6911351658426526

Epoch: 6| Step: 13
Training loss: 2.423209136690765
Validation loss: 2.671588980504116

Epoch: 131| Step: 0
Training loss: 3.1076127622466294
Validation loss: 2.666763995750401

Epoch: 6| Step: 1
Training loss: 2.7092952976141365
Validation loss: 2.664134674783431

Epoch: 6| Step: 2
Training loss: 2.8334607114395434
Validation loss: 2.6608595613507733

Epoch: 6| Step: 3
Training loss: 2.017441869604948
Validation loss: 2.6651991506145287

Epoch: 6| Step: 4
Training loss: 3.2620723692574556
Validation loss: 2.6668239811158654

Epoch: 6| Step: 5
Training loss: 2.9112548393055326
Validation loss: 2.6593526469937583

Epoch: 6| Step: 6
Training loss: 2.973594487386442
Validation loss: 2.6591155875093984

Epoch: 6| Step: 7
Training loss: 2.8336320233448777
Validation loss: 2.6582701980644483

Epoch: 6| Step: 8
Training loss: 3.034188645333977
Validation loss: 2.658552511708145

Epoch: 6| Step: 9
Training loss: 3.132257807229039
Validation loss: 2.660172704471363

Epoch: 6| Step: 10
Training loss: 3.489521143724451
Validation loss: 2.6589978823748996

Epoch: 6| Step: 11
Training loss: 2.9255322094443077
Validation loss: 2.656410041634877

Epoch: 6| Step: 12
Training loss: 3.3912502011257946
Validation loss: 2.6612593551131685

Epoch: 6| Step: 13
Training loss: 3.00743009440038
Validation loss: 2.6592684182409076

Epoch: 132| Step: 0
Training loss: 3.17257457215643
Validation loss: 2.6571887196763035

Epoch: 6| Step: 1
Training loss: 2.7021597312964203
Validation loss: 2.6592882340054875

Epoch: 6| Step: 2
Training loss: 3.103143169123231
Validation loss: 2.6560445900333343

Epoch: 6| Step: 3
Training loss: 2.943801937738477
Validation loss: 2.6632074664324583

Epoch: 6| Step: 4
Training loss: 3.7642813536985047
Validation loss: 2.6589749261523954

Epoch: 6| Step: 5
Training loss: 2.68402593650168
Validation loss: 2.6560967726308427

Epoch: 6| Step: 6
Training loss: 3.1677447709046493
Validation loss: 2.656853884070585

Epoch: 6| Step: 7
Training loss: 3.0940015286008467
Validation loss: 2.6580711197492297

Epoch: 6| Step: 8
Training loss: 2.8487811175827455
Validation loss: 2.6616479593266646

Epoch: 6| Step: 9
Training loss: 2.4795047839319166
Validation loss: 2.6617736636025837

Epoch: 6| Step: 10
Training loss: 3.319877039459279
Validation loss: 2.6580616138759305

Epoch: 6| Step: 11
Training loss: 2.775719877466976
Validation loss: 2.6572813778739244

Epoch: 6| Step: 12
Training loss: 2.8067028912119203
Validation loss: 2.657621546158933

Epoch: 6| Step: 13
Training loss: 2.57884465201518
Validation loss: 2.6650323365205595

Epoch: 133| Step: 0
Training loss: 3.3181567565237566
Validation loss: 2.6613351749134555

Epoch: 6| Step: 1
Training loss: 3.655355360339644
Validation loss: 2.662670967859561

Epoch: 6| Step: 2
Training loss: 2.8165391528216754
Validation loss: 2.668617483515995

Epoch: 6| Step: 3
Training loss: 2.3622608850966933
Validation loss: 2.670875500056004

Epoch: 6| Step: 4
Training loss: 2.9996619034032825
Validation loss: 2.6823797459790493

Epoch: 6| Step: 5
Training loss: 2.9805708201518093
Validation loss: 2.6800713277537773

Epoch: 6| Step: 6
Training loss: 2.985457139274375
Validation loss: 2.6610881303202887

Epoch: 6| Step: 7
Training loss: 3.5265374260088347
Validation loss: 2.6588946877288095

Epoch: 6| Step: 8
Training loss: 2.3435218191333638
Validation loss: 2.6508083270229177

Epoch: 6| Step: 9
Training loss: 2.9539328787066736
Validation loss: 2.6485622844991394

Epoch: 6| Step: 10
Training loss: 2.666957322810835
Validation loss: 2.653699714424144

Epoch: 6| Step: 11
Training loss: 3.2270022778380363
Validation loss: 2.650776779976507

Epoch: 6| Step: 12
Training loss: 2.979351829341081
Validation loss: 2.651462055410344

Epoch: 6| Step: 13
Training loss: 2.3765216771218043
Validation loss: 2.6497881443040225

Epoch: 134| Step: 0
Training loss: 3.6187321637756686
Validation loss: 2.652378799047661

Epoch: 6| Step: 1
Training loss: 2.8334583554079376
Validation loss: 2.651878020157249

Epoch: 6| Step: 2
Training loss: 2.709914748339479
Validation loss: 2.653826986284734

Epoch: 6| Step: 3
Training loss: 3.591152944504758
Validation loss: 2.649517174538432

Epoch: 6| Step: 4
Training loss: 3.0716428713636645
Validation loss: 2.6513847117680633

Epoch: 6| Step: 5
Training loss: 2.908933979374971
Validation loss: 2.6591845560590595

Epoch: 6| Step: 6
Training loss: 2.5364985740232004
Validation loss: 2.6785467958269886

Epoch: 6| Step: 7
Training loss: 2.562968699692415
Validation loss: 2.6723715193627515

Epoch: 6| Step: 8
Training loss: 2.7769452330889934
Validation loss: 2.691134188449988

Epoch: 6| Step: 9
Training loss: 3.5334789701953087
Validation loss: 2.680410732814779

Epoch: 6| Step: 10
Training loss: 2.9089856142256827
Validation loss: 2.702688229889187

Epoch: 6| Step: 11
Training loss: 2.642950174174486
Validation loss: 2.6721218954309975

Epoch: 6| Step: 12
Training loss: 2.836309739581129
Validation loss: 2.6668512898287036

Epoch: 6| Step: 13
Training loss: 3.009631907112329
Validation loss: 2.6613993177719326

Epoch: 135| Step: 0
Training loss: 3.5154672544905066
Validation loss: 2.653844255705371

Epoch: 6| Step: 1
Training loss: 2.974940220849312
Validation loss: 2.6562396170541707

Epoch: 6| Step: 2
Training loss: 2.985201895833298
Validation loss: 2.65722487027429

Epoch: 6| Step: 3
Training loss: 2.502035075624105
Validation loss: 2.6535235837338442

Epoch: 6| Step: 4
Training loss: 2.530764686307468
Validation loss: 2.648887941299924

Epoch: 6| Step: 5
Training loss: 2.829006500279822
Validation loss: 2.645646338087929

Epoch: 6| Step: 6
Training loss: 2.256171240449015
Validation loss: 2.6494919058611455

Epoch: 6| Step: 7
Training loss: 2.9078801003233345
Validation loss: 2.652233809628732

Epoch: 6| Step: 8
Training loss: 2.5672755518258428
Validation loss: 2.663428641866652

Epoch: 6| Step: 9
Training loss: 3.2124919609236415
Validation loss: 2.6633797264019123

Epoch: 6| Step: 10
Training loss: 3.7132853900638345
Validation loss: 2.6814077359080133

Epoch: 6| Step: 11
Training loss: 2.880548182344907
Validation loss: 2.668637444085931

Epoch: 6| Step: 12
Training loss: 3.1176405651520263
Validation loss: 2.676588883689658

Epoch: 6| Step: 13
Training loss: 3.869764051514264
Validation loss: 2.655935173511399

Epoch: 136| Step: 0
Training loss: 3.698466400691105
Validation loss: 2.650409555353596

Epoch: 6| Step: 1
Training loss: 2.904332010022008
Validation loss: 2.6460949942223846

Epoch: 6| Step: 2
Training loss: 2.8140246179584274
Validation loss: 2.6447991955064953

Epoch: 6| Step: 3
Training loss: 2.792911897093999
Validation loss: 2.6481273093289945

Epoch: 6| Step: 4
Training loss: 2.8943627188728227
Validation loss: 2.647598549471994

Epoch: 6| Step: 5
Training loss: 3.7299154939871166
Validation loss: 2.649539759877844

Epoch: 6| Step: 6
Training loss: 2.4894744551298653
Validation loss: 2.651995401352382

Epoch: 6| Step: 7
Training loss: 2.970414989776145
Validation loss: 2.6540930216202665

Epoch: 6| Step: 8
Training loss: 2.977016144072839
Validation loss: 2.6473135753880164

Epoch: 6| Step: 9
Training loss: 2.7817781782645516
Validation loss: 2.650703015125006

Epoch: 6| Step: 10
Training loss: 2.983763627147839
Validation loss: 2.6527940865982296

Epoch: 6| Step: 11
Training loss: 2.6050090698845767
Validation loss: 2.6543123246193123

Epoch: 6| Step: 12
Training loss: 2.5972442070704265
Validation loss: 2.6524439897017014

Epoch: 6| Step: 13
Training loss: 3.394995619219059
Validation loss: 2.6497116641697005

Epoch: 137| Step: 0
Training loss: 2.5176935635566067
Validation loss: 2.653483637948475

Epoch: 6| Step: 1
Training loss: 3.6907838326949762
Validation loss: 2.658848994103608

Epoch: 6| Step: 2
Training loss: 3.0485359555314364
Validation loss: 2.6560205619884387

Epoch: 6| Step: 3
Training loss: 3.1191106614481274
Validation loss: 2.6488087765003545

Epoch: 6| Step: 4
Training loss: 3.2813816589099574
Validation loss: 2.6677835577639075

Epoch: 6| Step: 5
Training loss: 2.3434620998305657
Validation loss: 2.6561882364136666

Epoch: 6| Step: 6
Training loss: 3.3689099219019862
Validation loss: 2.664867917020886

Epoch: 6| Step: 7
Training loss: 3.146857004578248
Validation loss: 2.660803306058713

Epoch: 6| Step: 8
Training loss: 2.4353336586578234
Validation loss: 2.656233824283152

Epoch: 6| Step: 9
Training loss: 3.1146414931022477
Validation loss: 2.6579223599304194

Epoch: 6| Step: 10
Training loss: 1.6697476123210744
Validation loss: 2.651502559558985

Epoch: 6| Step: 11
Training loss: 2.886814554609471
Validation loss: 2.6563308838624526

Epoch: 6| Step: 12
Training loss: 3.3231698700072974
Validation loss: 2.6501484533107367

Epoch: 6| Step: 13
Training loss: 3.1883107070665058
Validation loss: 2.6445263699749044

Epoch: 138| Step: 0
Training loss: 3.116855842710452
Validation loss: 2.6400336331334735

Epoch: 6| Step: 1
Training loss: 3.1458999593049803
Validation loss: 2.6434817869271425

Epoch: 6| Step: 2
Training loss: 3.317355933205426
Validation loss: 2.63835890862628

Epoch: 6| Step: 3
Training loss: 3.0920675307446084
Validation loss: 2.634530409955444

Epoch: 6| Step: 4
Training loss: 2.8162446418775575
Validation loss: 2.634765471265175

Epoch: 6| Step: 5
Training loss: 2.783391406734507
Validation loss: 2.638496153887647

Epoch: 6| Step: 6
Training loss: 2.437247727862105
Validation loss: 2.6398038121833247

Epoch: 6| Step: 7
Training loss: 3.02066741136912
Validation loss: 2.6379191819151933

Epoch: 6| Step: 8
Training loss: 3.077366614468642
Validation loss: 2.640190633916602

Epoch: 6| Step: 9
Training loss: 2.7780271566559023
Validation loss: 2.6404436358260805

Epoch: 6| Step: 10
Training loss: 3.0979642582623823
Validation loss: 2.6415636336450063

Epoch: 6| Step: 11
Training loss: 2.527069973156849
Validation loss: 2.6468004999687347

Epoch: 6| Step: 12
Training loss: 3.354030598473002
Validation loss: 2.652485805867558

Epoch: 6| Step: 13
Training loss: 2.860874970782489
Validation loss: 2.650675894026163

Epoch: 139| Step: 0
Training loss: 3.5879605306710554
Validation loss: 2.6508186495214425

Epoch: 6| Step: 1
Training loss: 2.925810911794737
Validation loss: 2.6430444266205684

Epoch: 6| Step: 2
Training loss: 3.1573878588360804
Validation loss: 2.6390066763542284

Epoch: 6| Step: 3
Training loss: 2.533403587203732
Validation loss: 2.6384030798585263

Epoch: 6| Step: 4
Training loss: 2.855301420263984
Validation loss: 2.6340149574263414

Epoch: 6| Step: 5
Training loss: 3.1338844653306888
Validation loss: 2.632873944378328

Epoch: 6| Step: 6
Training loss: 2.645995327853852
Validation loss: 2.6327442311144353

Epoch: 6| Step: 7
Training loss: 2.683558212555819
Validation loss: 2.632886969588299

Epoch: 6| Step: 8
Training loss: 2.9937609327909063
Validation loss: 2.632241733811975

Epoch: 6| Step: 9
Training loss: 3.285654944126853
Validation loss: 2.633563847134054

Epoch: 6| Step: 10
Training loss: 3.0934229205849926
Validation loss: 2.6342558815151285

Epoch: 6| Step: 11
Training loss: 2.7789547482457952
Validation loss: 2.6324752358391312

Epoch: 6| Step: 12
Training loss: 2.597037013539627
Validation loss: 2.6336019544744107

Epoch: 6| Step: 13
Training loss: 3.390236265338222
Validation loss: 2.638898251539747

Epoch: 140| Step: 0
Training loss: 3.103531603955089
Validation loss: 2.6353109817556057

Epoch: 6| Step: 1
Training loss: 2.128828974729981
Validation loss: 2.6370468590578255

Epoch: 6| Step: 2
Training loss: 3.105259304061254
Validation loss: 2.6383293878504563

Epoch: 6| Step: 3
Training loss: 3.436769442521538
Validation loss: 2.6409282545387622

Epoch: 6| Step: 4
Training loss: 3.505260601286953
Validation loss: 2.6417853120470287

Epoch: 6| Step: 5
Training loss: 2.760436800517425
Validation loss: 2.634383110838014

Epoch: 6| Step: 6
Training loss: 2.3873302219601045
Validation loss: 2.6448111839536987

Epoch: 6| Step: 7
Training loss: 3.6012272544282884
Validation loss: 2.6380186966582087

Epoch: 6| Step: 8
Training loss: 3.1514396647324885
Validation loss: 2.63653635576864

Epoch: 6| Step: 9
Training loss: 2.48442854913545
Validation loss: 2.642702959170733

Epoch: 6| Step: 10
Training loss: 3.240832971945759
Validation loss: 2.645717757528975

Epoch: 6| Step: 11
Training loss: 2.1078313760216236
Validation loss: 2.6456990542616623

Epoch: 6| Step: 12
Training loss: 2.8773517112404288
Validation loss: 2.6465606723257205

Epoch: 6| Step: 13
Training loss: 3.3043062607924685
Validation loss: 2.643301801998425

Epoch: 141| Step: 0
Training loss: 2.4680009502303952
Validation loss: 2.6421803559161785

Epoch: 6| Step: 1
Training loss: 3.2291072388789854
Validation loss: 2.6412840155134907

Epoch: 6| Step: 2
Training loss: 3.083884799888669
Validation loss: 2.6347326574317966

Epoch: 6| Step: 3
Training loss: 2.727422540335746
Validation loss: 2.6348204600830454

Epoch: 6| Step: 4
Training loss: 2.7044115477795136
Validation loss: 2.6294057217056093

Epoch: 6| Step: 5
Training loss: 3.1688401309104495
Validation loss: 2.6308860874592943

Epoch: 6| Step: 6
Training loss: 2.877684293756223
Validation loss: 2.6293788362571773

Epoch: 6| Step: 7
Training loss: 2.36838604388101
Validation loss: 2.633130357888932

Epoch: 6| Step: 8
Training loss: 2.8374265014271254
Validation loss: 2.6350671410839315

Epoch: 6| Step: 9
Training loss: 2.9366291459710734
Validation loss: 2.643833633008044

Epoch: 6| Step: 10
Training loss: 2.608193958284073
Validation loss: 2.6466405630442673

Epoch: 6| Step: 11
Training loss: 3.6171488749540766
Validation loss: 2.650532124936347

Epoch: 6| Step: 12
Training loss: 3.365428775036511
Validation loss: 2.662445829784895

Epoch: 6| Step: 13
Training loss: 3.6002578854911236
Validation loss: 2.6430961617047686

Epoch: 142| Step: 0
Training loss: 2.444593622491472
Validation loss: 2.6364607835106133

Epoch: 6| Step: 1
Training loss: 3.171586949089488
Validation loss: 2.6317351856170186

Epoch: 6| Step: 2
Training loss: 3.1127420721941954
Validation loss: 2.6273091458737046

Epoch: 6| Step: 3
Training loss: 3.125070494810346
Validation loss: 2.6281080260567617

Epoch: 6| Step: 4
Training loss: 2.8817219312526494
Validation loss: 2.6313471900622085

Epoch: 6| Step: 5
Training loss: 2.6199113478476814
Validation loss: 2.629544571042751

Epoch: 6| Step: 6
Training loss: 3.7172439474700125
Validation loss: 2.6279633501132897

Epoch: 6| Step: 7
Training loss: 2.7650283773390525
Validation loss: 2.6319515865165997

Epoch: 6| Step: 8
Training loss: 3.0387196482276715
Validation loss: 2.6283096284717025

Epoch: 6| Step: 9
Training loss: 2.905165275034891
Validation loss: 2.630735554585062

Epoch: 6| Step: 10
Training loss: 2.959881838424724
Validation loss: 2.6308975809539725

Epoch: 6| Step: 11
Training loss: 2.8678135824975652
Validation loss: 2.6303980874729387

Epoch: 6| Step: 12
Training loss: 3.047303155013411
Validation loss: 2.6321166051084175

Epoch: 6| Step: 13
Training loss: 2.578031411061723
Validation loss: 2.6301273638481355

Epoch: 143| Step: 0
Training loss: 3.232529265587685
Validation loss: 2.6299362326155062

Epoch: 6| Step: 1
Training loss: 2.5093783899951805
Validation loss: 2.636096542881017

Epoch: 6| Step: 2
Training loss: 3.464747413577587
Validation loss: 2.6360513030893546

Epoch: 6| Step: 3
Training loss: 2.368754859456334
Validation loss: 2.650691244822703

Epoch: 6| Step: 4
Training loss: 3.6126616075528073
Validation loss: 2.6811421236947237

Epoch: 6| Step: 5
Training loss: 2.4482392659909773
Validation loss: 2.6898860446086035

Epoch: 6| Step: 6
Training loss: 3.325354627470204
Validation loss: 2.7090523966591378

Epoch: 6| Step: 7
Training loss: 2.570340327428201
Validation loss: 2.6705008710882705

Epoch: 6| Step: 8
Training loss: 2.6901916509376083
Validation loss: 2.666510255005291

Epoch: 6| Step: 9
Training loss: 2.478979237200602
Validation loss: 2.635087025986455

Epoch: 6| Step: 10
Training loss: 2.330821172223117
Validation loss: 2.630616136190102

Epoch: 6| Step: 11
Training loss: 3.507346209351306
Validation loss: 2.6272998663165055

Epoch: 6| Step: 12
Training loss: 3.228188610650347
Validation loss: 2.6241506529694556

Epoch: 6| Step: 13
Training loss: 3.6603058058759648
Validation loss: 2.625367366947379

Epoch: 144| Step: 0
Training loss: 3.2519585503426964
Validation loss: 2.6277259993465525

Epoch: 6| Step: 1
Training loss: 2.847199077563821
Validation loss: 2.6323265809618914

Epoch: 6| Step: 2
Training loss: 3.068975647751096
Validation loss: 2.6273574712482204

Epoch: 6| Step: 3
Training loss: 3.554866710798447
Validation loss: 2.62917323124263

Epoch: 6| Step: 4
Training loss: 2.610120472667102
Validation loss: 2.6235750015321573

Epoch: 6| Step: 5
Training loss: 3.2539579792650604
Validation loss: 2.6237614713447357

Epoch: 6| Step: 6
Training loss: 2.7535125667464664
Validation loss: 2.6210442968062786

Epoch: 6| Step: 7
Training loss: 2.6848627502198896
Validation loss: 2.6208144256516492

Epoch: 6| Step: 8
Training loss: 3.289921664201078
Validation loss: 2.6210751840105573

Epoch: 6| Step: 9
Training loss: 2.844139994613479
Validation loss: 2.6209103124114983

Epoch: 6| Step: 10
Training loss: 2.7089640445400147
Validation loss: 2.628112528822599

Epoch: 6| Step: 11
Training loss: 2.7776141457575423
Validation loss: 2.626719140869077

Epoch: 6| Step: 12
Training loss: 2.603756549330673
Validation loss: 2.6465764150835294

Epoch: 6| Step: 13
Training loss: 3.4233123686785234
Validation loss: 2.6344288385939554

Epoch: 145| Step: 0
Training loss: 2.7306516747056917
Validation loss: 2.634025336490362

Epoch: 6| Step: 1
Training loss: 2.9856829747861267
Validation loss: 2.646508386944445

Epoch: 6| Step: 2
Training loss: 2.6091387978739355
Validation loss: 2.65956039541148

Epoch: 6| Step: 3
Training loss: 3.6104878613202294
Validation loss: 2.6418153764501553

Epoch: 6| Step: 4
Training loss: 3.199922030214281
Validation loss: 2.6411141873671817

Epoch: 6| Step: 5
Training loss: 2.9507656461602587
Validation loss: 2.6267865728158344

Epoch: 6| Step: 6
Training loss: 2.6817905192425306
Validation loss: 2.6239936626305522

Epoch: 6| Step: 7
Training loss: 2.7945600764638385
Validation loss: 2.624238400352335

Epoch: 6| Step: 8
Training loss: 2.9468141972244988
Validation loss: 2.6225672180310253

Epoch: 6| Step: 9
Training loss: 2.6672600940195483
Validation loss: 2.620291750465439

Epoch: 6| Step: 10
Training loss: 2.650917624898556
Validation loss: 2.6307354503140137

Epoch: 6| Step: 11
Training loss: 3.162999254707203
Validation loss: 2.6331586917191

Epoch: 6| Step: 12
Training loss: 3.254679318993259
Validation loss: 2.6407579695669883

Epoch: 6| Step: 13
Training loss: 3.1186183618808743
Validation loss: 2.6458230493597754

Epoch: 146| Step: 0
Training loss: 2.29576073431949
Validation loss: 2.646693816371851

Epoch: 6| Step: 1
Training loss: 2.3159367566409275
Validation loss: 2.6335513645653053

Epoch: 6| Step: 2
Training loss: 3.315819570457374
Validation loss: 2.6302363383336265

Epoch: 6| Step: 3
Training loss: 2.9714715629653465
Validation loss: 2.6232210744265476

Epoch: 6| Step: 4
Training loss: 3.212315321783106
Validation loss: 2.624988941651787

Epoch: 6| Step: 5
Training loss: 1.9683350625327987
Validation loss: 2.620136224057314

Epoch: 6| Step: 6
Training loss: 3.3945570967801943
Validation loss: 2.623628971227376

Epoch: 6| Step: 7
Training loss: 2.6062731552010208
Validation loss: 2.6263658170709667

Epoch: 6| Step: 8
Training loss: 2.9008943165329826
Validation loss: 2.6243759625507472

Epoch: 6| Step: 9
Training loss: 2.968789351353093
Validation loss: 2.6265095990913854

Epoch: 6| Step: 10
Training loss: 3.4177211126809253
Validation loss: 2.624048765803766

Epoch: 6| Step: 11
Training loss: 3.120376982044125
Validation loss: 2.62124358764686

Epoch: 6| Step: 12
Training loss: 3.300249298389222
Validation loss: 2.617828830289748

Epoch: 6| Step: 13
Training loss: 3.2896617787441724
Validation loss: 2.6169399065383905

Epoch: 147| Step: 0
Training loss: 2.971619835137072
Validation loss: 2.617921199205109

Epoch: 6| Step: 1
Training loss: 3.1052956970749133
Validation loss: 2.6144306834629503

Epoch: 6| Step: 2
Training loss: 2.8047463243526547
Validation loss: 2.619106141302069

Epoch: 6| Step: 3
Training loss: 2.900362676106921
Validation loss: 2.618003732382289

Epoch: 6| Step: 4
Training loss: 3.225164152004212
Validation loss: 2.6132560547402695

Epoch: 6| Step: 5
Training loss: 2.756036202579124
Validation loss: 2.614177246941084

Epoch: 6| Step: 6
Training loss: 3.1643438520260374
Validation loss: 2.6169106760863268

Epoch: 6| Step: 7
Training loss: 2.752217352523195
Validation loss: 2.6232321881141565

Epoch: 6| Step: 8
Training loss: 3.0297904679269516
Validation loss: 2.625497333352693

Epoch: 6| Step: 9
Training loss: 2.541540069762524
Validation loss: 2.6342700453348864

Epoch: 6| Step: 10
Training loss: 2.8823365849858598
Validation loss: 2.636827506523181

Epoch: 6| Step: 11
Training loss: 3.023094295766136
Validation loss: 2.650084828485461

Epoch: 6| Step: 12
Training loss: 2.632093744620193
Validation loss: 2.6626653787538515

Epoch: 6| Step: 13
Training loss: 3.7488030112735964
Validation loss: 2.678780136532618

Epoch: 148| Step: 0
Training loss: 2.9419233417287405
Validation loss: 2.6436448784718705

Epoch: 6| Step: 1
Training loss: 3.112243555986939
Validation loss: 2.6344532659794826

Epoch: 6| Step: 2
Training loss: 2.8671226390185773
Validation loss: 2.620048360815835

Epoch: 6| Step: 3
Training loss: 3.105284026787876
Validation loss: 2.622284827370849

Epoch: 6| Step: 4
Training loss: 3.0290835789370414
Validation loss: 2.6191113721255395

Epoch: 6| Step: 5
Training loss: 3.2504963129055233
Validation loss: 2.6227956687953027

Epoch: 6| Step: 6
Training loss: 2.7006300508981167
Validation loss: 2.6184521120880144

Epoch: 6| Step: 7
Training loss: 3.1725126480559847
Validation loss: 2.6208270070333697

Epoch: 6| Step: 8
Training loss: 2.9758432876077165
Validation loss: 2.624552427341982

Epoch: 6| Step: 9
Training loss: 2.1307317064398044
Validation loss: 2.636900284813849

Epoch: 6| Step: 10
Training loss: 2.851727373765281
Validation loss: 2.6269152486272214

Epoch: 6| Step: 11
Training loss: 3.391069655553167
Validation loss: 2.6311589145637306

Epoch: 6| Step: 12
Training loss: 2.4589975612732227
Validation loss: 2.619863094531281

Epoch: 6| Step: 13
Training loss: 3.0847188740501763
Validation loss: 2.6182794978262702

Epoch: 149| Step: 0
Training loss: 2.9817125517411864
Validation loss: 2.623095411815923

Epoch: 6| Step: 1
Training loss: 2.9627609073656056
Validation loss: 2.617683768388612

Epoch: 6| Step: 2
Training loss: 2.4844653994829606
Validation loss: 2.6206123826126575

Epoch: 6| Step: 3
Training loss: 3.772372330413261
Validation loss: 2.6189683840405213

Epoch: 6| Step: 4
Training loss: 2.8026370573261277
Validation loss: 2.6120419783888713

Epoch: 6| Step: 5
Training loss: 3.0001090347820787
Validation loss: 2.617515756674203

Epoch: 6| Step: 6
Training loss: 2.659421754957221
Validation loss: 2.6126469222202338

Epoch: 6| Step: 7
Training loss: 2.9520720365672024
Validation loss: 2.6172984540963116

Epoch: 6| Step: 8
Training loss: 2.440497487115924
Validation loss: 2.620910484565705

Epoch: 6| Step: 9
Training loss: 2.5473135354155327
Validation loss: 2.6238390703683856

Epoch: 6| Step: 10
Training loss: 3.062682788609924
Validation loss: 2.6440755230569017

Epoch: 6| Step: 11
Training loss: 3.218984058351318
Validation loss: 2.6516179212500703

Epoch: 6| Step: 12
Training loss: 3.260152511539688
Validation loss: 2.667254218494885

Epoch: 6| Step: 13
Training loss: 2.7999725238269377
Validation loss: 2.6565289036680237

Epoch: 150| Step: 0
Training loss: 2.568825984675622
Validation loss: 2.6484493761482706

Epoch: 6| Step: 1
Training loss: 3.132052284145352
Validation loss: 2.6380237986312682

Epoch: 6| Step: 2
Training loss: 2.5301109859564113
Validation loss: 2.6202669919573145

Epoch: 6| Step: 3
Training loss: 3.2048543588097167
Validation loss: 2.610718906965579

Epoch: 6| Step: 4
Training loss: 2.926762374349965
Validation loss: 2.6066668568387024

Epoch: 6| Step: 5
Training loss: 2.893675642932612
Validation loss: 2.6099156146406215

Epoch: 6| Step: 6
Training loss: 2.888073924442031
Validation loss: 2.6075835075822416

Epoch: 6| Step: 7
Training loss: 2.892638458920907
Validation loss: 2.610061711359833

Epoch: 6| Step: 8
Training loss: 3.087721219805602
Validation loss: 2.6101456029222847

Epoch: 6| Step: 9
Training loss: 3.43519612181382
Validation loss: 2.607247177489831

Epoch: 6| Step: 10
Training loss: 2.6497909103533637
Validation loss: 2.6128202353266325

Epoch: 6| Step: 11
Training loss: 2.737072295477667
Validation loss: 2.613010575862947

Epoch: 6| Step: 12
Training loss: 2.8990862755202986
Validation loss: 2.6168033783861926

Epoch: 6| Step: 13
Training loss: 3.6161587201705254
Validation loss: 2.617090404205041

Epoch: 151| Step: 0
Training loss: 3.3405426900231627
Validation loss: 2.6099682048224615

Epoch: 6| Step: 1
Training loss: 2.6345285318870904
Validation loss: 2.6061461717500896

Epoch: 6| Step: 2
Training loss: 3.2717470160431574
Validation loss: 2.6047278887707135

Epoch: 6| Step: 3
Training loss: 2.919525344103606
Validation loss: 2.606310647442935

Epoch: 6| Step: 4
Training loss: 3.349908878738287
Validation loss: 2.603286573446416

Epoch: 6| Step: 5
Training loss: 2.6581006951816364
Validation loss: 2.6068341604807426

Epoch: 6| Step: 6
Training loss: 2.5124292392160763
Validation loss: 2.604120398982047

Epoch: 6| Step: 7
Training loss: 2.958380004801212
Validation loss: 2.606243513954071

Epoch: 6| Step: 8
Training loss: 2.798391517078199
Validation loss: 2.6121314196837027

Epoch: 6| Step: 9
Training loss: 3.312180701647513
Validation loss: 2.6206410131957694

Epoch: 6| Step: 10
Training loss: 3.078949638705633
Validation loss: 2.6224591908154253

Epoch: 6| Step: 11
Training loss: 3.005903792719252
Validation loss: 2.6516238169196877

Epoch: 6| Step: 12
Training loss: 2.5398113378910803
Validation loss: 2.6438393569515255

Epoch: 6| Step: 13
Training loss: 2.5794614160221174
Validation loss: 2.632031656710103

Epoch: 152| Step: 0
Training loss: 2.8535074368358737
Validation loss: 2.612991184228774

Epoch: 6| Step: 1
Training loss: 2.8067175019101165
Validation loss: 2.6080289683233278

Epoch: 6| Step: 2
Training loss: 3.180521187927455
Validation loss: 2.6020077491243763

Epoch: 6| Step: 3
Training loss: 3.061682611492116
Validation loss: 2.6042618584411237

Epoch: 6| Step: 4
Training loss: 2.9140641363308073
Validation loss: 2.6027275516029857

Epoch: 6| Step: 5
Training loss: 2.881415796371143
Validation loss: 2.601707671485199

Epoch: 6| Step: 6
Training loss: 3.214997409564409
Validation loss: 2.6000157235887262

Epoch: 6| Step: 7
Training loss: 2.3640792130045276
Validation loss: 2.6005460874794464

Epoch: 6| Step: 8
Training loss: 3.0212918339185846
Validation loss: 2.6085043639743573

Epoch: 6| Step: 9
Training loss: 3.0607721553774283
Validation loss: 2.6085401996002

Epoch: 6| Step: 10
Training loss: 2.6440219135097713
Validation loss: 2.6031599603535565

Epoch: 6| Step: 11
Training loss: 2.9786865985764703
Validation loss: 2.6044020492659548

Epoch: 6| Step: 12
Training loss: 2.758010122334561
Validation loss: 2.608156997358845

Epoch: 6| Step: 13
Training loss: 3.6005615697066666
Validation loss: 2.6030598535764207

Epoch: 153| Step: 0
Training loss: 3.209125239414332
Validation loss: 2.610239615785838

Epoch: 6| Step: 1
Training loss: 3.5949227451305585
Validation loss: 2.6042053462611756

Epoch: 6| Step: 2
Training loss: 2.727294736108696
Validation loss: 2.609752087176601

Epoch: 6| Step: 3
Training loss: 3.0023131989138907
Validation loss: 2.6073925712745125

Epoch: 6| Step: 4
Training loss: 2.782109674185541
Validation loss: 2.6074393622965046

Epoch: 6| Step: 5
Training loss: 3.0900224520660786
Validation loss: 2.6013888143085255

Epoch: 6| Step: 6
Training loss: 3.0702137239597858
Validation loss: 2.5991172908784352

Epoch: 6| Step: 7
Training loss: 2.536712310002749
Validation loss: 2.6000768564553414

Epoch: 6| Step: 8
Training loss: 2.5752430847389154
Validation loss: 2.5944536003246124

Epoch: 6| Step: 9
Training loss: 3.066000047737216
Validation loss: 2.6009077288835893

Epoch: 6| Step: 10
Training loss: 2.6489236661137867
Validation loss: 2.6101762684597336

Epoch: 6| Step: 11
Training loss: 2.8377454475082002
Validation loss: 2.619258968267419

Epoch: 6| Step: 12
Training loss: 3.2022519294136735
Validation loss: 2.6190480318669755

Epoch: 6| Step: 13
Training loss: 2.200024851745343
Validation loss: 2.6166277817558665

Epoch: 154| Step: 0
Training loss: 2.5977761147744576
Validation loss: 2.6155641088407053

Epoch: 6| Step: 1
Training loss: 3.130184450656126
Validation loss: 2.5999436926128223

Epoch: 6| Step: 2
Training loss: 3.3584458596535574
Validation loss: 2.601882017721078

Epoch: 6| Step: 3
Training loss: 3.277108912641962
Validation loss: 2.598290921314704

Epoch: 6| Step: 4
Training loss: 3.415214012667337
Validation loss: 2.609033350136959

Epoch: 6| Step: 5
Training loss: 2.6629045492521386
Validation loss: 2.6064527296464224

Epoch: 6| Step: 6
Training loss: 2.7873965291204943
Validation loss: 2.615631486305379

Epoch: 6| Step: 7
Training loss: 2.533471533703302
Validation loss: 2.6208333603049523

Epoch: 6| Step: 8
Training loss: 2.6489426572763115
Validation loss: 2.6219919063098125

Epoch: 6| Step: 9
Training loss: 2.8937694046325633
Validation loss: 2.639816540020528

Epoch: 6| Step: 10
Training loss: 3.260652836217766
Validation loss: 2.6347025482103223

Epoch: 6| Step: 11
Training loss: 2.998251723457655
Validation loss: 2.609241846941511

Epoch: 6| Step: 12
Training loss: 2.849649869593186
Validation loss: 2.5970022847145184

Epoch: 6| Step: 13
Training loss: 2.113066657095005
Validation loss: 2.599333048067494

Epoch: 155| Step: 0
Training loss: 2.7119350741612647
Validation loss: 2.6045170974396887

Epoch: 6| Step: 1
Training loss: 3.4465417031582377
Validation loss: 2.6066299450723682

Epoch: 6| Step: 2
Training loss: 2.4441525569195925
Validation loss: 2.609589736195345

Epoch: 6| Step: 3
Training loss: 2.7692554158964247
Validation loss: 2.61102260295447

Epoch: 6| Step: 4
Training loss: 2.5727357890891565
Validation loss: 2.6157854787014525

Epoch: 6| Step: 5
Training loss: 3.0556512663522417
Validation loss: 2.61227680463212

Epoch: 6| Step: 6
Training loss: 3.092298687462993
Validation loss: 2.6079352935502293

Epoch: 6| Step: 7
Training loss: 3.3881123457367797
Validation loss: 2.611068017192782

Epoch: 6| Step: 8
Training loss: 3.281286911529738
Validation loss: 2.625725826971144

Epoch: 6| Step: 9
Training loss: 3.131237823401739
Validation loss: 2.6339207916355423

Epoch: 6| Step: 10
Training loss: 2.74437015971741
Validation loss: 2.6472581304194334

Epoch: 6| Step: 11
Training loss: 2.7949486603909546
Validation loss: 2.6606635933991276

Epoch: 6| Step: 12
Training loss: 2.785601865155835
Validation loss: 2.690712836276307

Epoch: 6| Step: 13
Training loss: 3.2798777299281765
Validation loss: 2.678434396276856

Epoch: 156| Step: 0
Training loss: 2.2408939045921348
Validation loss: 2.6751435139857085

Epoch: 6| Step: 1
Training loss: 2.798850187865544
Validation loss: 2.6826830672270385

Epoch: 6| Step: 2
Training loss: 2.9711294175564182
Validation loss: 2.6778314374398215

Epoch: 6| Step: 3
Training loss: 3.0990475083458104
Validation loss: 2.6760768141808784

Epoch: 6| Step: 4
Training loss: 2.4968149877409442
Validation loss: 2.6613716140418187

Epoch: 6| Step: 5
Training loss: 3.2040902520944843
Validation loss: 2.627046597860275

Epoch: 6| Step: 6
Training loss: 2.5879943596544077
Validation loss: 2.6095246636886307

Epoch: 6| Step: 7
Training loss: 2.414803696704087
Validation loss: 2.605268391205436

Epoch: 6| Step: 8
Training loss: 3.5503583431717423
Validation loss: 2.5959643940923014

Epoch: 6| Step: 9
Training loss: 3.2749283702675545
Validation loss: 2.5913616866973497

Epoch: 6| Step: 10
Training loss: 2.7343275665528695
Validation loss: 2.5927070035836155

Epoch: 6| Step: 11
Training loss: 3.207298276984669
Validation loss: 2.5934420018650504

Epoch: 6| Step: 12
Training loss: 3.2101732073011298
Validation loss: 2.592408582688809

Epoch: 6| Step: 13
Training loss: 3.212985459989054
Validation loss: 2.592717482750182

Epoch: 157| Step: 0
Training loss: 3.2701026116466503
Validation loss: 2.5898661667788407

Epoch: 6| Step: 1
Training loss: 2.855097839228951
Validation loss: 2.587721970786311

Epoch: 6| Step: 2
Training loss: 2.81086395150488
Validation loss: 2.5875878481471895

Epoch: 6| Step: 3
Training loss: 2.46390182948546
Validation loss: 2.592267764020919

Epoch: 6| Step: 4
Training loss: 2.9596044111103215
Validation loss: 2.599111916249012

Epoch: 6| Step: 5
Training loss: 2.788751408513772
Validation loss: 2.618982744085968

Epoch: 6| Step: 6
Training loss: 3.3017380270129606
Validation loss: 2.6330525926055137

Epoch: 6| Step: 7
Training loss: 2.7995894062899715
Validation loss: 2.6582385259553702

Epoch: 6| Step: 8
Training loss: 3.6158642583366976
Validation loss: 2.629238392735735

Epoch: 6| Step: 9
Training loss: 2.9401257730686288
Validation loss: 2.618785196985513

Epoch: 6| Step: 10
Training loss: 2.407010045092819
Validation loss: 2.6058467841585236

Epoch: 6| Step: 11
Training loss: 3.028808711825425
Validation loss: 2.604797448991197

Epoch: 6| Step: 12
Training loss: 2.7552083717927887
Validation loss: 2.596739097166456

Epoch: 6| Step: 13
Training loss: 2.805966651392059
Validation loss: 2.59343834833339

Epoch: 158| Step: 0
Training loss: 3.138737808987768
Validation loss: 2.590811325761506

Epoch: 6| Step: 1
Training loss: 2.7303472008889904
Validation loss: 2.5870337253751234

Epoch: 6| Step: 2
Training loss: 3.3976039521943693
Validation loss: 2.589346147233383

Epoch: 6| Step: 3
Training loss: 3.017620948067908
Validation loss: 2.5889446887067393

Epoch: 6| Step: 4
Training loss: 2.92132416291091
Validation loss: 2.5905516685829117

Epoch: 6| Step: 5
Training loss: 2.42614871081434
Validation loss: 2.594400949110553

Epoch: 6| Step: 6
Training loss: 2.544373670599676
Validation loss: 2.5917038361492417

Epoch: 6| Step: 7
Training loss: 2.8364768448047095
Validation loss: 2.595388708014229

Epoch: 6| Step: 8
Training loss: 3.2678362646932357
Validation loss: 2.598888278807553

Epoch: 6| Step: 9
Training loss: 3.3794273724315413
Validation loss: 2.6013388258730017

Epoch: 6| Step: 10
Training loss: 2.0396411995347012
Validation loss: 2.5964363391152863

Epoch: 6| Step: 11
Training loss: 3.1007867799124758
Validation loss: 2.6025161993040657

Epoch: 6| Step: 12
Training loss: 3.0189238377782344
Validation loss: 2.6167115617621963

Epoch: 6| Step: 13
Training loss: 2.997984845144129
Validation loss: 2.6115108829194167

Epoch: 159| Step: 0
Training loss: 2.574918938258977
Validation loss: 2.620598104867024

Epoch: 6| Step: 1
Training loss: 2.9457096064877804
Validation loss: 2.620716756977999

Epoch: 6| Step: 2
Training loss: 2.753599845127498
Validation loss: 2.615510191308808

Epoch: 6| Step: 3
Training loss: 3.121689530706577
Validation loss: 2.6061648199916947

Epoch: 6| Step: 4
Training loss: 2.8768114105562668
Validation loss: 2.60927112498593

Epoch: 6| Step: 5
Training loss: 3.1095930626856836
Validation loss: 2.6100387804778045

Epoch: 6| Step: 6
Training loss: 3.312038173510832
Validation loss: 2.6126876503421865

Epoch: 6| Step: 7
Training loss: 3.327390061302725
Validation loss: 2.606211124992995

Epoch: 6| Step: 8
Training loss: 3.070124884932538
Validation loss: 2.596667761173413

Epoch: 6| Step: 9
Training loss: 3.2073778158034494
Validation loss: 2.599709919357242

Epoch: 6| Step: 10
Training loss: 2.3022688248645853
Validation loss: 2.600916654123753

Epoch: 6| Step: 11
Training loss: 2.6957184858980363
Validation loss: 2.601772601528483

Epoch: 6| Step: 12
Training loss: 2.9098091891414315
Validation loss: 2.612854853004683

Epoch: 6| Step: 13
Training loss: 2.3397292171207
Validation loss: 2.60291864494874

Epoch: 160| Step: 0
Training loss: 2.7285694507486142
Validation loss: 2.598856655404507

Epoch: 6| Step: 1
Training loss: 2.4146984460186904
Validation loss: 2.587371370149021

Epoch: 6| Step: 2
Training loss: 2.876381583588015
Validation loss: 2.582136221325254

Epoch: 6| Step: 3
Training loss: 2.566225646470613
Validation loss: 2.585697490212743

Epoch: 6| Step: 4
Training loss: 2.9162108655544663
Validation loss: 2.582307954093763

Epoch: 6| Step: 5
Training loss: 2.150894369357725
Validation loss: 2.579722188476102

Epoch: 6| Step: 6
Training loss: 2.9619968099634892
Validation loss: 2.5871458359207673

Epoch: 6| Step: 7
Training loss: 2.839326205311904
Validation loss: 2.5867338700038314

Epoch: 6| Step: 8
Training loss: 3.0391524039260602
Validation loss: 2.591868299555428

Epoch: 6| Step: 9
Training loss: 3.3469966919731338
Validation loss: 2.5937110432420925

Epoch: 6| Step: 10
Training loss: 3.2843171816018675
Validation loss: 2.6006733266228244

Epoch: 6| Step: 11
Training loss: 3.5079115957693277
Validation loss: 2.5957001047710886

Epoch: 6| Step: 12
Training loss: 3.230092627552399
Validation loss: 2.6099572694130053

Epoch: 6| Step: 13
Training loss: 2.7889452997795336
Validation loss: 2.6078871961277184

Epoch: 161| Step: 0
Training loss: 3.0088838328956538
Validation loss: 2.5943436124340336

Epoch: 6| Step: 1
Training loss: 2.511061705559949
Validation loss: 2.5911500603120956

Epoch: 6| Step: 2
Training loss: 2.7061345099987277
Validation loss: 2.5862862203418087

Epoch: 6| Step: 3
Training loss: 2.64608218807446
Validation loss: 2.58772288420602

Epoch: 6| Step: 4
Training loss: 3.3589017312886815
Validation loss: 2.5906285291108615

Epoch: 6| Step: 5
Training loss: 2.9699490986581916
Validation loss: 2.5907237880337104

Epoch: 6| Step: 6
Training loss: 2.845455622333519
Validation loss: 2.6003018567233656

Epoch: 6| Step: 7
Training loss: 2.801512384684481
Validation loss: 2.6010367569828254

Epoch: 6| Step: 8
Training loss: 3.2264826951768066
Validation loss: 2.606371916922982

Epoch: 6| Step: 9
Training loss: 2.730450675151414
Validation loss: 2.6066537842066224

Epoch: 6| Step: 10
Training loss: 2.8158337650108702
Validation loss: 2.6021850593902127

Epoch: 6| Step: 11
Training loss: 2.872406826649596
Validation loss: 2.597510166148516

Epoch: 6| Step: 12
Training loss: 3.5288647723341424
Validation loss: 2.588118659831121

Epoch: 6| Step: 13
Training loss: 2.7173583755156603
Validation loss: 2.584119080507041

Epoch: 162| Step: 0
Training loss: 2.9718855511691644
Validation loss: 2.5834804642531846

Epoch: 6| Step: 1
Training loss: 2.953127099091929
Validation loss: 2.5889475425368236

Epoch: 6| Step: 2
Training loss: 2.75214640342719
Validation loss: 2.5902704838135553

Epoch: 6| Step: 3
Training loss: 2.6050331403560905
Validation loss: 2.591230721499504

Epoch: 6| Step: 4
Training loss: 2.8753527549278184
Validation loss: 2.5912904381293034

Epoch: 6| Step: 5
Training loss: 2.404850342152679
Validation loss: 2.5855539253849575

Epoch: 6| Step: 6
Training loss: 2.4270498794629507
Validation loss: 2.590260179825648

Epoch: 6| Step: 7
Training loss: 3.140966899727781
Validation loss: 2.591022190246775

Epoch: 6| Step: 8
Training loss: 2.7531732111161684
Validation loss: 2.5843781658332317

Epoch: 6| Step: 9
Training loss: 3.251904149875206
Validation loss: 2.58940516528267

Epoch: 6| Step: 10
Training loss: 3.2267611167682526
Validation loss: 2.58957223380405

Epoch: 6| Step: 11
Training loss: 3.2937277284625646
Validation loss: 2.5851887269878655

Epoch: 6| Step: 12
Training loss: 3.0706178159064836
Validation loss: 2.598705051463134

Epoch: 6| Step: 13
Training loss: 3.232835486188822
Validation loss: 2.6059983080870412

Epoch: 163| Step: 0
Training loss: 2.6469757637381455
Validation loss: 2.6004513406770333

Epoch: 6| Step: 1
Training loss: 3.4301679617904646
Validation loss: 2.613527352327347

Epoch: 6| Step: 2
Training loss: 3.3535361003306203
Validation loss: 2.6386222528343044

Epoch: 6| Step: 3
Training loss: 2.595498104911205
Validation loss: 2.6253717045050244

Epoch: 6| Step: 4
Training loss: 2.4706528488894066
Validation loss: 2.6646415695297936

Epoch: 6| Step: 5
Training loss: 2.7006931722026626
Validation loss: 2.6203635131551546

Epoch: 6| Step: 6
Training loss: 2.9188075972761536
Validation loss: 2.5972025122567395

Epoch: 6| Step: 7
Training loss: 3.1781852603927043
Validation loss: 2.5977231435515167

Epoch: 6| Step: 8
Training loss: 2.9112335464058443
Validation loss: 2.593891293645256

Epoch: 6| Step: 9
Training loss: 2.8181727526678335
Validation loss: 2.580816716918879

Epoch: 6| Step: 10
Training loss: 3.0679685075379486
Validation loss: 2.576382253026698

Epoch: 6| Step: 11
Training loss: 3.1158799414368072
Validation loss: 2.5786300010454517

Epoch: 6| Step: 12
Training loss: 2.455288947012953
Validation loss: 2.579931071655531

Epoch: 6| Step: 13
Training loss: 3.0893410757256192
Validation loss: 2.5793316575061085

Epoch: 164| Step: 0
Training loss: 3.6197403206602643
Validation loss: 2.5834955316037744

Epoch: 6| Step: 1
Training loss: 2.622694183520724
Validation loss: 2.580741683535401

Epoch: 6| Step: 2
Training loss: 2.4327417538547915
Validation loss: 2.5770565221534847

Epoch: 6| Step: 3
Training loss: 2.942926143361114
Validation loss: 2.5835913298749733

Epoch: 6| Step: 4
Training loss: 3.488381310679951
Validation loss: 2.581633857944331

Epoch: 6| Step: 5
Training loss: 2.8080517666384095
Validation loss: 2.582896988332403

Epoch: 6| Step: 6
Training loss: 3.30279183633855
Validation loss: 2.5816049447123093

Epoch: 6| Step: 7
Training loss: 2.193217842787262
Validation loss: 2.587991225426602

Epoch: 6| Step: 8
Training loss: 3.1006036232271192
Validation loss: 2.5979496028693942

Epoch: 6| Step: 9
Training loss: 2.6058039185128763
Validation loss: 2.6027698572350078

Epoch: 6| Step: 10
Training loss: 2.788156399613123
Validation loss: 2.6330612599186694

Epoch: 6| Step: 11
Training loss: 2.437937379378618
Validation loss: 2.6269555169270875

Epoch: 6| Step: 12
Training loss: 3.329845001920721
Validation loss: 2.631229554164292

Epoch: 6| Step: 13
Training loss: 2.512559812222897
Validation loss: 2.6398222746165807

Epoch: 165| Step: 0
Training loss: 3.3954498136853473
Validation loss: 2.6397765499711854

Epoch: 6| Step: 1
Training loss: 2.421632619234698
Validation loss: 2.6873056556581245

Epoch: 6| Step: 2
Training loss: 2.7000731952777093
Validation loss: 2.6874522715034193

Epoch: 6| Step: 3
Training loss: 3.1446816734207674
Validation loss: 2.7128757074275898

Epoch: 6| Step: 4
Training loss: 2.9580861556974316
Validation loss: 2.707686852726553

Epoch: 6| Step: 5
Training loss: 3.0922533518837567
Validation loss: 2.622499552465436

Epoch: 6| Step: 6
Training loss: 2.8073709980378045
Validation loss: 2.5792425533287533

Epoch: 6| Step: 7
Training loss: 3.2866342601248864
Validation loss: 2.5794336502205204

Epoch: 6| Step: 8
Training loss: 2.9360179002928173
Validation loss: 2.5767132485694053

Epoch: 6| Step: 9
Training loss: 2.7507864954475068
Validation loss: 2.581001475401785

Epoch: 6| Step: 10
Training loss: 2.513685153786799
Validation loss: 2.596871084220152

Epoch: 6| Step: 11
Training loss: 3.0416728677207407
Validation loss: 2.6018852140401494

Epoch: 6| Step: 12
Training loss: 2.9818871798853244
Validation loss: 2.599271851351364

Epoch: 6| Step: 13
Training loss: 3.1438595640834848
Validation loss: 2.5881350274979393

Epoch: 166| Step: 0
Training loss: 2.737086929440489
Validation loss: 2.5789388327337646

Epoch: 6| Step: 1
Training loss: 3.154510925399815
Validation loss: 2.5852177022789777

Epoch: 6| Step: 2
Training loss: 3.2338495242298038
Validation loss: 2.5860960957327137

Epoch: 6| Step: 3
Training loss: 3.0287082673337364
Validation loss: 2.5945532551147004

Epoch: 6| Step: 4
Training loss: 2.79244524978064
Validation loss: 2.5997856132602166

Epoch: 6| Step: 5
Training loss: 3.648750634815753
Validation loss: 2.6182271108151682

Epoch: 6| Step: 6
Training loss: 3.1689862405870093
Validation loss: 2.6168323455250264

Epoch: 6| Step: 7
Training loss: 2.3439922970459692
Validation loss: 2.6186483587585703

Epoch: 6| Step: 8
Training loss: 2.7821073603643525
Validation loss: 2.601280415134185

Epoch: 6| Step: 9
Training loss: 2.4964131373324596
Validation loss: 2.589934894783831

Epoch: 6| Step: 10
Training loss: 3.220040516331875
Validation loss: 2.5808902591400744

Epoch: 6| Step: 11
Training loss: 2.4160677288237746
Validation loss: 2.578694226719472

Epoch: 6| Step: 12
Training loss: 3.0841515117095293
Validation loss: 2.5733729852889837

Epoch: 6| Step: 13
Training loss: 2.252725751531906
Validation loss: 2.5730759586842447

Epoch: 167| Step: 0
Training loss: 2.938148589259631
Validation loss: 2.569855713091187

Epoch: 6| Step: 1
Training loss: 2.684890899999004
Validation loss: 2.5689334430727038

Epoch: 6| Step: 2
Training loss: 2.7639739717287575
Validation loss: 2.5716130673814352

Epoch: 6| Step: 3
Training loss: 3.31315505550434
Validation loss: 2.571599637111825

Epoch: 6| Step: 4
Training loss: 3.5736394360609083
Validation loss: 2.5717226716900283

Epoch: 6| Step: 5
Training loss: 3.2889517359986473
Validation loss: 2.5697596661402415

Epoch: 6| Step: 6
Training loss: 3.2264696897593113
Validation loss: 2.576390181608386

Epoch: 6| Step: 7
Training loss: 2.2155776649659225
Validation loss: 2.5717810175870204

Epoch: 6| Step: 8
Training loss: 2.5514459138340957
Validation loss: 2.5744042448986266

Epoch: 6| Step: 9
Training loss: 2.9861389060291677
Validation loss: 2.5693931587405254

Epoch: 6| Step: 10
Training loss: 2.6753464839823438
Validation loss: 2.5690569241639176

Epoch: 6| Step: 11
Training loss: 2.6842364523042046
Validation loss: 2.5672815003846416

Epoch: 6| Step: 12
Training loss: 2.720584119178072
Validation loss: 2.5706163681755503

Epoch: 6| Step: 13
Training loss: 3.085096490918293
Validation loss: 2.5830388220489575

Epoch: 168| Step: 0
Training loss: 2.763975869433654
Validation loss: 2.594348095736653

Epoch: 6| Step: 1
Training loss: 3.487947420248892
Validation loss: 2.589140004430201

Epoch: 6| Step: 2
Training loss: 2.844280822173813
Validation loss: 2.58255061168231

Epoch: 6| Step: 3
Training loss: 2.7375086675358644
Validation loss: 2.5709329890897896

Epoch: 6| Step: 4
Training loss: 3.1640236181060053
Validation loss: 2.5634487125663314

Epoch: 6| Step: 5
Training loss: 2.7864593410787215
Validation loss: 2.5657785982671992

Epoch: 6| Step: 6
Training loss: 2.8726310921844225
Validation loss: 2.5648857373915153

Epoch: 6| Step: 7
Training loss: 2.7914187952331444
Validation loss: 2.566799703356294

Epoch: 6| Step: 8
Training loss: 3.1745491969348603
Validation loss: 2.5673734960823587

Epoch: 6| Step: 9
Training loss: 3.0518489048904844
Validation loss: 2.5701421791016417

Epoch: 6| Step: 10
Training loss: 2.793144252571612
Validation loss: 2.569346266532544

Epoch: 6| Step: 11
Training loss: 3.1584576732413603
Validation loss: 2.567985473950926

Epoch: 6| Step: 12
Training loss: 2.197537743566516
Validation loss: 2.5668413916465918

Epoch: 6| Step: 13
Training loss: 2.7953204731110524
Validation loss: 2.5662346164102083

Epoch: 169| Step: 0
Training loss: 2.7550753661714795
Validation loss: 2.570084491252369

Epoch: 6| Step: 1
Training loss: 2.3124987628005558
Validation loss: 2.5782564559142656

Epoch: 6| Step: 2
Training loss: 2.5729000899260934
Validation loss: 2.5830503329242824

Epoch: 6| Step: 3
Training loss: 2.8910311027022852
Validation loss: 2.6055431411616152

Epoch: 6| Step: 4
Training loss: 3.3198135539636944
Validation loss: 2.612824238528092

Epoch: 6| Step: 5
Training loss: 2.9839531565407804
Validation loss: 2.61828265552432

Epoch: 6| Step: 6
Training loss: 2.723529867071153
Validation loss: 2.6324516938414737

Epoch: 6| Step: 7
Training loss: 2.8443896234547563
Validation loss: 2.638245732683645

Epoch: 6| Step: 8
Training loss: 2.9198168681473957
Validation loss: 2.629270323500924

Epoch: 6| Step: 9
Training loss: 3.8115088002937627
Validation loss: 2.6208639741522806

Epoch: 6| Step: 10
Training loss: 2.9839828792827445
Validation loss: 2.5991863019475816

Epoch: 6| Step: 11
Training loss: 2.2017093736701896
Validation loss: 2.5891046399407935

Epoch: 6| Step: 12
Training loss: 3.281813218961492
Validation loss: 2.5774241857547455

Epoch: 6| Step: 13
Training loss: 2.632658277573417
Validation loss: 2.5711116037925996

Epoch: 170| Step: 0
Training loss: 2.439649563310324
Validation loss: 2.5693287614320792

Epoch: 6| Step: 1
Training loss: 2.7687246764943088
Validation loss: 2.56558834986675

Epoch: 6| Step: 2
Training loss: 2.896946937630761
Validation loss: 2.568478862282371

Epoch: 6| Step: 3
Training loss: 2.5530096020994253
Validation loss: 2.565371711303477

Epoch: 6| Step: 4
Training loss: 3.203367047352438
Validation loss: 2.5642730677420276

Epoch: 6| Step: 5
Training loss: 3.5056543996920984
Validation loss: 2.5703192065374907

Epoch: 6| Step: 6
Training loss: 2.6729489672149467
Validation loss: 2.5711713918608785

Epoch: 6| Step: 7
Training loss: 3.0315347124868444
Validation loss: 2.5680303095717942

Epoch: 6| Step: 8
Training loss: 3.434053670136068
Validation loss: 2.5721580127867822

Epoch: 6| Step: 9
Training loss: 2.6060915635799238
Validation loss: 2.5717072218500534

Epoch: 6| Step: 10
Training loss: 2.473355500241021
Validation loss: 2.5754074605420167

Epoch: 6| Step: 11
Training loss: 2.9359561840394703
Validation loss: 2.5728405193930914

Epoch: 6| Step: 12
Training loss: 3.1932915823270416
Validation loss: 2.5789998071516163

Epoch: 6| Step: 13
Training loss: 2.437338407980034
Validation loss: 2.587037014856662

Epoch: 171| Step: 0
Training loss: 2.355596586335906
Validation loss: 2.592107234561863

Epoch: 6| Step: 1
Training loss: 3.5471087811429225
Validation loss: 2.5792958881863144

Epoch: 6| Step: 2
Training loss: 3.5422482330944622
Validation loss: 2.5753800014292296

Epoch: 6| Step: 3
Training loss: 2.6761998204208894
Validation loss: 2.563850103192835

Epoch: 6| Step: 4
Training loss: 2.458659058883189
Validation loss: 2.5571224102417007

Epoch: 6| Step: 5
Training loss: 3.282179056066122
Validation loss: 2.5587027713055845

Epoch: 6| Step: 6
Training loss: 2.766069624338298
Validation loss: 2.5593564550360033

Epoch: 6| Step: 7
Training loss: 2.644733550815577
Validation loss: 2.565101215183244

Epoch: 6| Step: 8
Training loss: 2.8807388745985025
Validation loss: 2.563056391176764

Epoch: 6| Step: 9
Training loss: 2.5894358962529314
Validation loss: 2.5612540078318338

Epoch: 6| Step: 10
Training loss: 3.1943351911207474
Validation loss: 2.5633553663786746

Epoch: 6| Step: 11
Training loss: 3.1028966844664128
Validation loss: 2.567302059104854

Epoch: 6| Step: 12
Training loss: 2.940817400387497
Validation loss: 2.568528068944936

Epoch: 6| Step: 13
Training loss: 2.226666899793388
Validation loss: 2.5694550541070496

Epoch: 172| Step: 0
Training loss: 3.284357543085892
Validation loss: 2.5716573383250183

Epoch: 6| Step: 1
Training loss: 2.7408088196164386
Validation loss: 2.5888877698840824

Epoch: 6| Step: 2
Training loss: 2.9744718323215658
Validation loss: 2.5914088146620404

Epoch: 6| Step: 3
Training loss: 2.0864366941302777
Validation loss: 2.5890670599381678

Epoch: 6| Step: 4
Training loss: 2.9081409824308464
Validation loss: 2.6195263768756543

Epoch: 6| Step: 5
Training loss: 3.020107910047268
Validation loss: 2.6354517894036893

Epoch: 6| Step: 6
Training loss: 2.1552526406450183
Validation loss: 2.6011189349265726

Epoch: 6| Step: 7
Training loss: 1.8615360043855664
Validation loss: 2.5759902105509096

Epoch: 6| Step: 8
Training loss: 3.3493203797525233
Validation loss: 2.5683979726650343

Epoch: 6| Step: 9
Training loss: 2.894981277220802
Validation loss: 2.562942884296165

Epoch: 6| Step: 10
Training loss: 3.4129677420521536
Validation loss: 2.5623976424148465

Epoch: 6| Step: 11
Training loss: 2.964814800377438
Validation loss: 2.562831107937009

Epoch: 6| Step: 12
Training loss: 3.4159181907023606
Validation loss: 2.5638850730970377

Epoch: 6| Step: 13
Training loss: 3.1912502591543546
Validation loss: 2.559360015984343

Epoch: 173| Step: 0
Training loss: 2.7192841805276204
Validation loss: 2.56316426249077

Epoch: 6| Step: 1
Training loss: 2.9158072885849364
Validation loss: 2.564281743087202

Epoch: 6| Step: 2
Training loss: 2.8488530913074563
Validation loss: 2.5643004888307863

Epoch: 6| Step: 3
Training loss: 2.4514439162098958
Validation loss: 2.5618563788419726

Epoch: 6| Step: 4
Training loss: 2.6560891495415775
Validation loss: 2.562064174043023

Epoch: 6| Step: 5
Training loss: 2.3071156270285833
Validation loss: 2.5679544193938617

Epoch: 6| Step: 6
Training loss: 3.145721399871634
Validation loss: 2.563884461155312

Epoch: 6| Step: 7
Training loss: 3.0630134619187537
Validation loss: 2.5645286219612395

Epoch: 6| Step: 8
Training loss: 3.135000325861523
Validation loss: 2.5646261613202874

Epoch: 6| Step: 9
Training loss: 3.0415215827794455
Validation loss: 2.571799473915815

Epoch: 6| Step: 10
Training loss: 2.7909780383665743
Validation loss: 2.577147430804075

Epoch: 6| Step: 11
Training loss: 2.5219909490049313
Validation loss: 2.5859443028244695

Epoch: 6| Step: 12
Training loss: 3.0879381865012037
Validation loss: 2.5748584416895905

Epoch: 6| Step: 13
Training loss: 4.10413470312281
Validation loss: 2.5994954459315864

Epoch: 174| Step: 0
Training loss: 2.6121418611637917
Validation loss: 2.598988920109034

Epoch: 6| Step: 1
Training loss: 2.431330183810401
Validation loss: 2.589517783993574

Epoch: 6| Step: 2
Training loss: 2.9970088988494368
Validation loss: 2.601822780665566

Epoch: 6| Step: 3
Training loss: 3.225972784430115
Validation loss: 2.6102843944583483

Epoch: 6| Step: 4
Training loss: 3.1237401330005135
Validation loss: 2.6189215102290024

Epoch: 6| Step: 5
Training loss: 3.1242241468523653
Validation loss: 2.5908119244166032

Epoch: 6| Step: 6
Training loss: 2.5264517434873777
Validation loss: 2.5721306704823808

Epoch: 6| Step: 7
Training loss: 3.258465818035335
Validation loss: 2.5648509740395857

Epoch: 6| Step: 8
Training loss: 2.8492213005219766
Validation loss: 2.572584793337443

Epoch: 6| Step: 9
Training loss: 2.9684814331646017
Validation loss: 2.559400451181824

Epoch: 6| Step: 10
Training loss: 2.56633100007402
Validation loss: 2.5601127022820274

Epoch: 6| Step: 11
Training loss: 2.876088806967115
Validation loss: 2.5613677391875798

Epoch: 6| Step: 12
Training loss: 3.032440580963656
Validation loss: 2.5600431290953987

Epoch: 6| Step: 13
Training loss: 2.6892631424875915
Validation loss: 2.559585736943172

Epoch: 175| Step: 0
Training loss: 3.300254066397161
Validation loss: 2.566477701923081

Epoch: 6| Step: 1
Training loss: 2.559161081095788
Validation loss: 2.572559047033155

Epoch: 6| Step: 2
Training loss: 2.8333486294800996
Validation loss: 2.566324066341119

Epoch: 6| Step: 3
Training loss: 2.561985615531331
Validation loss: 2.5675878649818826

Epoch: 6| Step: 4
Training loss: 2.60724566717919
Validation loss: 2.5751929431777625

Epoch: 6| Step: 5
Training loss: 2.7893996262024205
Validation loss: 2.5829722409803946

Epoch: 6| Step: 6
Training loss: 3.2666922107657967
Validation loss: 2.584550938437507

Epoch: 6| Step: 7
Training loss: 2.5973639990675825
Validation loss: 2.5674075602559543

Epoch: 6| Step: 8
Training loss: 3.183003264353304
Validation loss: 2.574123998214569

Epoch: 6| Step: 9
Training loss: 2.6537593159667057
Validation loss: 2.579045511919794

Epoch: 6| Step: 10
Training loss: 3.375406311443703
Validation loss: 2.5710254633760345

Epoch: 6| Step: 11
Training loss: 2.883450569312563
Validation loss: 2.568350536253713

Epoch: 6| Step: 12
Training loss: 2.703898236588819
Validation loss: 2.5758857665512136

Epoch: 6| Step: 13
Training loss: 3.008800473140486
Validation loss: 2.5775920954804157

Epoch: 176| Step: 0
Training loss: 2.5481585679171843
Validation loss: 2.576297149588964

Epoch: 6| Step: 1
Training loss: 2.8329627037730725
Validation loss: 2.575612561944954

Epoch: 6| Step: 2
Training loss: 3.3768684019158077
Validation loss: 2.5793830971485003

Epoch: 6| Step: 3
Training loss: 2.673190322944767
Validation loss: 2.5675622822438986

Epoch: 6| Step: 4
Training loss: 3.21613983689134
Validation loss: 2.5701376560683307

Epoch: 6| Step: 5
Training loss: 3.108599695514938
Validation loss: 2.558033636149579

Epoch: 6| Step: 6
Training loss: 2.3773921163091125
Validation loss: 2.560349016592414

Epoch: 6| Step: 7
Training loss: 3.0823997596350545
Validation loss: 2.5650126376181834

Epoch: 6| Step: 8
Training loss: 2.299562400155354
Validation loss: 2.5606563963291564

Epoch: 6| Step: 9
Training loss: 2.8244680292012045
Validation loss: 2.5606183752883274

Epoch: 6| Step: 10
Training loss: 2.7240953186095758
Validation loss: 2.561588364298017

Epoch: 6| Step: 11
Training loss: 2.755228187955818
Validation loss: 2.557350595261984

Epoch: 6| Step: 12
Training loss: 3.4248269643023717
Validation loss: 2.566308078026657

Epoch: 6| Step: 13
Training loss: 2.947339723741319
Validation loss: 2.5594000805688144

Epoch: 177| Step: 0
Training loss: 2.562890185911504
Validation loss: 2.5669963744627937

Epoch: 6| Step: 1
Training loss: 2.795437917779725
Validation loss: 2.5728582417334227

Epoch: 6| Step: 2
Training loss: 2.4165037582560824
Validation loss: 2.562987593574919

Epoch: 6| Step: 3
Training loss: 2.8954444093500946
Validation loss: 2.558176843361635

Epoch: 6| Step: 4
Training loss: 3.1395942173098157
Validation loss: 2.5597850153957644

Epoch: 6| Step: 5
Training loss: 3.029642996576749
Validation loss: 2.564072487377055

Epoch: 6| Step: 6
Training loss: 2.981632270536409
Validation loss: 2.559306312751288

Epoch: 6| Step: 7
Training loss: 2.790487657266458
Validation loss: 2.5621638744131654

Epoch: 6| Step: 8
Training loss: 3.265878767894931
Validation loss: 2.570599686512514

Epoch: 6| Step: 9
Training loss: 2.916188791272817
Validation loss: 2.571332487576799

Epoch: 6| Step: 10
Training loss: 3.0299675184970174
Validation loss: 2.5877163634521843

Epoch: 6| Step: 11
Training loss: 3.108053415357407
Validation loss: 2.608150390082444

Epoch: 6| Step: 12
Training loss: 2.6928889338852615
Validation loss: 2.6254734133928697

Epoch: 6| Step: 13
Training loss: 2.6920353080962034
Validation loss: 2.618196594895634

Epoch: 178| Step: 0
Training loss: 2.8641192990928355
Validation loss: 2.6078865502745896

Epoch: 6| Step: 1
Training loss: 2.76473493316102
Validation loss: 2.5939502275546555

Epoch: 6| Step: 2
Training loss: 2.766836472168296
Validation loss: 2.5835697829661917

Epoch: 6| Step: 3
Training loss: 2.676465647248415
Validation loss: 2.5714614633582964

Epoch: 6| Step: 4
Training loss: 2.6308363564439365
Validation loss: 2.564068140105678

Epoch: 6| Step: 5
Training loss: 2.620564482645416
Validation loss: 2.559084014275401

Epoch: 6| Step: 6
Training loss: 2.803629471071306
Validation loss: 2.5634633476201882

Epoch: 6| Step: 7
Training loss: 3.043061515755453
Validation loss: 2.557345383469252

Epoch: 6| Step: 8
Training loss: 3.0862332359282005
Validation loss: 2.5549608851804617

Epoch: 6| Step: 9
Training loss: 2.063880458430646
Validation loss: 2.551854630938407

Epoch: 6| Step: 10
Training loss: 3.341336386349139
Validation loss: 2.5571755878978637

Epoch: 6| Step: 11
Training loss: 3.430193123009989
Validation loss: 2.5563333926937206

Epoch: 6| Step: 12
Training loss: 2.946544925654684
Validation loss: 2.5524439806549606

Epoch: 6| Step: 13
Training loss: 3.397727313321497
Validation loss: 2.5572650429268915

Epoch: 179| Step: 0
Training loss: 3.2117109643335606
Validation loss: 2.5652191038081638

Epoch: 6| Step: 1
Training loss: 2.506425230221796
Validation loss: 2.575626729743707

Epoch: 6| Step: 2
Training loss: 2.8395347794439627
Validation loss: 2.5797785493086836

Epoch: 6| Step: 3
Training loss: 2.2264468514373728
Validation loss: 2.5709347595530416

Epoch: 6| Step: 4
Training loss: 3.2138305402327934
Validation loss: 2.5887257285711907

Epoch: 6| Step: 5
Training loss: 1.7687097794236157
Validation loss: 2.5663539369007897

Epoch: 6| Step: 6
Training loss: 2.924812676063798
Validation loss: 2.5835850666091393

Epoch: 6| Step: 7
Training loss: 3.479177935614391
Validation loss: 2.5959062110352997

Epoch: 6| Step: 8
Training loss: 2.7217982950362622
Validation loss: 2.5789592448458367

Epoch: 6| Step: 9
Training loss: 2.572414107153839
Validation loss: 2.579885246438408

Epoch: 6| Step: 10
Training loss: 3.1126216634848376
Validation loss: 2.583542106467476

Epoch: 6| Step: 11
Training loss: 2.7935633313244583
Validation loss: 2.5772895570581054

Epoch: 6| Step: 12
Training loss: 3.5139663513517907
Validation loss: 2.586267295442583

Epoch: 6| Step: 13
Training loss: 3.1058598110202027
Validation loss: 2.576658488220591

Epoch: 180| Step: 0
Training loss: 2.1383539111524126
Validation loss: 2.5687733426116433

Epoch: 6| Step: 1
Training loss: 3.3669008633073596
Validation loss: 2.5705052950023384

Epoch: 6| Step: 2
Training loss: 3.5183856890704384
Validation loss: 2.561233976104986

Epoch: 6| Step: 3
Training loss: 2.764149072648795
Validation loss: 2.5659304311491105

Epoch: 6| Step: 4
Training loss: 2.996397716714755
Validation loss: 2.5629685996661955

Epoch: 6| Step: 5
Training loss: 2.725124821735119
Validation loss: 2.5876696913357238

Epoch: 6| Step: 6
Training loss: 3.2630219374540896
Validation loss: 2.59476514240155

Epoch: 6| Step: 7
Training loss: 2.6458311506447587
Validation loss: 2.596480791072503

Epoch: 6| Step: 8
Training loss: 2.4017241880829197
Validation loss: 2.5741974079728083

Epoch: 6| Step: 9
Training loss: 2.713433691257368
Validation loss: 2.5638140068880406

Epoch: 6| Step: 10
Training loss: 2.781371981913984
Validation loss: 2.5531469098168684

Epoch: 6| Step: 11
Training loss: 2.6756643450739483
Validation loss: 2.5473116604738757

Epoch: 6| Step: 12
Training loss: 3.2768667826530398
Validation loss: 2.5479762473831644

Epoch: 6| Step: 13
Training loss: 2.590734176267901
Validation loss: 2.5482716111033397

Epoch: 181| Step: 0
Training loss: 2.7796939397333094
Validation loss: 2.546542501975301

Epoch: 6| Step: 1
Training loss: 3.1048356088559697
Validation loss: 2.5443396577514967

Epoch: 6| Step: 2
Training loss: 3.0843003964508506
Validation loss: 2.5473379759538872

Epoch: 6| Step: 3
Training loss: 2.534792270011848
Validation loss: 2.5470636044934167

Epoch: 6| Step: 4
Training loss: 2.8098855476556466
Validation loss: 2.546340958866605

Epoch: 6| Step: 5
Training loss: 2.7090531981952393
Validation loss: 2.5466521730779905

Epoch: 6| Step: 6
Training loss: 3.271524311789817
Validation loss: 2.5512565792159463

Epoch: 6| Step: 7
Training loss: 2.5603448131919584
Validation loss: 2.5600113648244385

Epoch: 6| Step: 8
Training loss: 3.1484044832907467
Validation loss: 2.554933134072987

Epoch: 6| Step: 9
Training loss: 2.8551992140444216
Validation loss: 2.5728451567472823

Epoch: 6| Step: 10
Training loss: 2.5582210822646676
Validation loss: 2.5900110465934767

Epoch: 6| Step: 11
Training loss: 3.4718899648431423
Validation loss: 2.5938431146984473

Epoch: 6| Step: 12
Training loss: 2.3698721288638187
Validation loss: 2.606754863293803

Epoch: 6| Step: 13
Training loss: 2.680705775090993
Validation loss: 2.5968001580983224

Epoch: 182| Step: 0
Training loss: 2.998547202245894
Validation loss: 2.617551984095953

Epoch: 6| Step: 1
Training loss: 2.9564527704165364
Validation loss: 2.616854510538323

Epoch: 6| Step: 2
Training loss: 3.181353907958545
Validation loss: 2.627919255094786

Epoch: 6| Step: 3
Training loss: 2.684554237714469
Validation loss: 2.6189299110644457

Epoch: 6| Step: 4
Training loss: 2.7595581063057244
Validation loss: 2.577261734037956

Epoch: 6| Step: 5
Training loss: 2.667954630556068
Validation loss: 2.56515443880773

Epoch: 6| Step: 6
Training loss: 2.6721191294719335
Validation loss: 2.551513816936189

Epoch: 6| Step: 7
Training loss: 2.7783343859485385
Validation loss: 2.5459245732445277

Epoch: 6| Step: 8
Training loss: 2.7836634419228825
Validation loss: 2.5476542235240536

Epoch: 6| Step: 9
Training loss: 3.20568804659012
Validation loss: 2.547642538632496

Epoch: 6| Step: 10
Training loss: 2.986904011418059
Validation loss: 2.5532049115787876

Epoch: 6| Step: 11
Training loss: 2.430904365820795
Validation loss: 2.5494132450032834

Epoch: 6| Step: 12
Training loss: 2.8620336294271036
Validation loss: 2.550263082472054

Epoch: 6| Step: 13
Training loss: 3.742259875017764
Validation loss: 2.552247813894903

Epoch: 183| Step: 0
Training loss: 2.841509261111328
Validation loss: 2.5511892289857183

Epoch: 6| Step: 1
Training loss: 2.9429263053893546
Validation loss: 2.549726452070244

Epoch: 6| Step: 2
Training loss: 3.607849855754122
Validation loss: 2.5506835179066747

Epoch: 6| Step: 3
Training loss: 3.0521279463040782
Validation loss: 2.5524592558234795

Epoch: 6| Step: 4
Training loss: 2.690837650557483
Validation loss: 2.5575118458283

Epoch: 6| Step: 5
Training loss: 3.3824458463158398
Validation loss: 2.5664984788459964

Epoch: 6| Step: 6
Training loss: 2.5322316467963804
Validation loss: 2.56102901550168

Epoch: 6| Step: 7
Training loss: 2.5600484891114
Validation loss: 2.5777409709698484

Epoch: 6| Step: 8
Training loss: 2.710505382386834
Validation loss: 2.5926549808852895

Epoch: 6| Step: 9
Training loss: 2.2857718396604283
Validation loss: 2.5867747583561265

Epoch: 6| Step: 10
Training loss: 2.9264003368609
Validation loss: 2.5875588835446908

Epoch: 6| Step: 11
Training loss: 2.847116678240743
Validation loss: 2.5823801166219167

Epoch: 6| Step: 12
Training loss: 2.6864622019670508
Validation loss: 2.586607675654606

Epoch: 6| Step: 13
Training loss: 3.193790586329381
Validation loss: 2.583738159020471

Epoch: 184| Step: 0
Training loss: 2.6545749543903563
Validation loss: 2.571057222693364

Epoch: 6| Step: 1
Training loss: 3.0521273213798086
Validation loss: 2.5615269423921405

Epoch: 6| Step: 2
Training loss: 2.9557122094204287
Validation loss: 2.5462913546530297

Epoch: 6| Step: 3
Training loss: 3.2756360666648168
Validation loss: 2.5446807651665613

Epoch: 6| Step: 4
Training loss: 3.150371553820918
Validation loss: 2.548338631011625

Epoch: 6| Step: 5
Training loss: 2.546091064376796
Validation loss: 2.541665214552953

Epoch: 6| Step: 6
Training loss: 2.911683939937312
Validation loss: 2.539949428740274

Epoch: 6| Step: 7
Training loss: 3.030653904772885
Validation loss: 2.5434873452334945

Epoch: 6| Step: 8
Training loss: 3.5797456627545157
Validation loss: 2.5398917414897673

Epoch: 6| Step: 9
Training loss: 2.5352316729078117
Validation loss: 2.5426289474866333

Epoch: 6| Step: 10
Training loss: 2.898726374376488
Validation loss: 2.5470247096965593

Epoch: 6| Step: 11
Training loss: 2.396707911430515
Validation loss: 2.5455116232911803

Epoch: 6| Step: 12
Training loss: 2.476094198625882
Validation loss: 2.5495173697479494

Epoch: 6| Step: 13
Training loss: 1.983621168754657
Validation loss: 2.5545639806512987

Epoch: 185| Step: 0
Training loss: 2.3295871316433856
Validation loss: 2.5542505096317902

Epoch: 6| Step: 1
Training loss: 2.951648161227178
Validation loss: 2.554466786690419

Epoch: 6| Step: 2
Training loss: 3.4201569446446425
Validation loss: 2.5640015833405063

Epoch: 6| Step: 3
Training loss: 2.639850751241548
Validation loss: 2.557405845225602

Epoch: 6| Step: 4
Training loss: 3.1324537266801693
Validation loss: 2.547883559364146

Epoch: 6| Step: 5
Training loss: 3.1564232806993613
Validation loss: 2.540463478659103

Epoch: 6| Step: 6
Training loss: 2.7957309535497563
Validation loss: 2.539770883544675

Epoch: 6| Step: 7
Training loss: 2.94408506523468
Validation loss: 2.5365361475504855

Epoch: 6| Step: 8
Training loss: 3.1793956575796796
Validation loss: 2.533383819981566

Epoch: 6| Step: 9
Training loss: 2.909344410146483
Validation loss: 2.531683278699424

Epoch: 6| Step: 10
Training loss: 2.708806148241099
Validation loss: 2.539271977746731

Epoch: 6| Step: 11
Training loss: 2.1598899083868415
Validation loss: 2.5346638689129213

Epoch: 6| Step: 12
Training loss: 3.083460951217496
Validation loss: 2.5347504480528213

Epoch: 6| Step: 13
Training loss: 2.3543349236869093
Validation loss: 2.5369334472777028

Epoch: 186| Step: 0
Training loss: 3.279071629725196
Validation loss: 2.5433839301813097

Epoch: 6| Step: 1
Training loss: 2.625162210448061
Validation loss: 2.566824832267823

Epoch: 6| Step: 2
Training loss: 2.8671342808412374
Validation loss: 2.58494315135528

Epoch: 6| Step: 3
Training loss: 3.730519878576326
Validation loss: 2.5887213563494296

Epoch: 6| Step: 4
Training loss: 2.6142182316881324
Validation loss: 2.586385022680337

Epoch: 6| Step: 5
Training loss: 2.8131237609901234
Validation loss: 2.560314269743282

Epoch: 6| Step: 6
Training loss: 3.0673798588711505
Validation loss: 2.5511026439868294

Epoch: 6| Step: 7
Training loss: 2.4688998792517958
Validation loss: 2.5474365951948084

Epoch: 6| Step: 8
Training loss: 2.395247434763823
Validation loss: 2.5329596851366194

Epoch: 6| Step: 9
Training loss: 2.758994565078343
Validation loss: 2.535190465941987

Epoch: 6| Step: 10
Training loss: 2.9337608401565944
Validation loss: 2.535787819517707

Epoch: 6| Step: 11
Training loss: 2.805175738753807
Validation loss: 2.5320217890906505

Epoch: 6| Step: 12
Training loss: 2.901535311783633
Validation loss: 2.534981249613124

Epoch: 6| Step: 13
Training loss: 2.998733889117896
Validation loss: 2.5388293329776754

Epoch: 187| Step: 0
Training loss: 2.7003394090167925
Validation loss: 2.5423751850817595

Epoch: 6| Step: 1
Training loss: 3.067578833825367
Validation loss: 2.557020164235547

Epoch: 6| Step: 2
Training loss: 3.034517238123593
Validation loss: 2.559905247400849

Epoch: 6| Step: 3
Training loss: 3.004171808655492
Validation loss: 2.5577223454189464

Epoch: 6| Step: 4
Training loss: 2.7930889397216325
Validation loss: 2.5533655323806514

Epoch: 6| Step: 5
Training loss: 3.12626073201689
Validation loss: 2.550931165602905

Epoch: 6| Step: 6
Training loss: 2.5311669230073437
Validation loss: 2.5517084351537656

Epoch: 6| Step: 7
Training loss: 2.6711380148492063
Validation loss: 2.5492486623388144

Epoch: 6| Step: 8
Training loss: 2.470601027720054
Validation loss: 2.544474515513174

Epoch: 6| Step: 9
Training loss: 2.665687579977791
Validation loss: 2.5413671088712557

Epoch: 6| Step: 10
Training loss: 2.4878684379653246
Validation loss: 2.545259350912371

Epoch: 6| Step: 11
Training loss: 3.4209969844230557
Validation loss: 2.5547253980732902

Epoch: 6| Step: 12
Training loss: 2.923884226248683
Validation loss: 2.559046502828026

Epoch: 6| Step: 13
Training loss: 3.0041026037601406
Validation loss: 2.569649633410746

Epoch: 188| Step: 0
Training loss: 2.6489004445072846
Validation loss: 2.579677650473254

Epoch: 6| Step: 1
Training loss: 2.4718693208689504
Validation loss: 2.5758762997515396

Epoch: 6| Step: 2
Training loss: 3.374459965203721
Validation loss: 2.5605550258233256

Epoch: 6| Step: 3
Training loss: 2.033991562764871
Validation loss: 2.5544505063805203

Epoch: 6| Step: 4
Training loss: 3.6408293179657014
Validation loss: 2.5507185014814886

Epoch: 6| Step: 5
Training loss: 2.7603087973961213
Validation loss: 2.538335459625345

Epoch: 6| Step: 6
Training loss: 2.639383419167064
Validation loss: 2.537048951966581

Epoch: 6| Step: 7
Training loss: 3.0768778641753474
Validation loss: 2.5381584533213886

Epoch: 6| Step: 8
Training loss: 2.093404712958373
Validation loss: 2.535537703921963

Epoch: 6| Step: 9
Training loss: 2.617050486152362
Validation loss: 2.5434649954398876

Epoch: 6| Step: 10
Training loss: 2.8372651662573287
Validation loss: 2.534837761519144

Epoch: 6| Step: 11
Training loss: 3.4554624629454023
Validation loss: 2.537969433526231

Epoch: 6| Step: 12
Training loss: 2.988950726682058
Validation loss: 2.5500181134742994

Epoch: 6| Step: 13
Training loss: 3.1259455966816003
Validation loss: 2.547249793670005

Epoch: 189| Step: 0
Training loss: 2.9779283488654595
Validation loss: 2.5501837191108563

Epoch: 6| Step: 1
Training loss: 3.365172453679807
Validation loss: 2.5480142231418346

Epoch: 6| Step: 2
Training loss: 3.081606063233112
Validation loss: 2.54608411378665

Epoch: 6| Step: 3
Training loss: 2.5238830362051914
Validation loss: 2.5515912781817445

Epoch: 6| Step: 4
Training loss: 2.9276985436016174
Validation loss: 2.551069174077132

Epoch: 6| Step: 5
Training loss: 2.446646329637592
Validation loss: 2.553173901158178

Epoch: 6| Step: 6
Training loss: 2.5267984311950267
Validation loss: 2.549850312330857

Epoch: 6| Step: 7
Training loss: 2.956195990490464
Validation loss: 2.5580116730194145

Epoch: 6| Step: 8
Training loss: 2.4527772304620226
Validation loss: 2.5792122943019042

Epoch: 6| Step: 9
Training loss: 3.048245009499639
Validation loss: 2.5862173527496903

Epoch: 6| Step: 10
Training loss: 2.5822731631899547
Validation loss: 2.5936781518332475

Epoch: 6| Step: 11
Training loss: 3.06047567298119
Validation loss: 2.6172698868585704

Epoch: 6| Step: 12
Training loss: 3.200491664785632
Validation loss: 2.6334413094175786

Epoch: 6| Step: 13
Training loss: 2.694273463676305
Validation loss: 2.6226637014940137

Epoch: 190| Step: 0
Training loss: 2.6113664714134743
Validation loss: 2.6197299832993415

Epoch: 6| Step: 1
Training loss: 3.026574057900137
Validation loss: 2.6118057352564197

Epoch: 6| Step: 2
Training loss: 2.6942863833110633
Validation loss: 2.6271777146250805

Epoch: 6| Step: 3
Training loss: 3.0945424307698484
Validation loss: 2.6463226248344625

Epoch: 6| Step: 4
Training loss: 3.5016945415284884
Validation loss: 2.6685607375418394

Epoch: 6| Step: 5
Training loss: 2.986830734560307
Validation loss: 2.6218257693850604

Epoch: 6| Step: 6
Training loss: 3.439226306582721
Validation loss: 2.582653576126266

Epoch: 6| Step: 7
Training loss: 2.760918788706182
Validation loss: 2.548887048779721

Epoch: 6| Step: 8
Training loss: 2.561645737585058
Validation loss: 2.5420591521023717

Epoch: 6| Step: 9
Training loss: 2.9066657312490842
Validation loss: 2.5377963828298675

Epoch: 6| Step: 10
Training loss: 2.945878437421749
Validation loss: 2.5384010128497954

Epoch: 6| Step: 11
Training loss: 2.319354235125192
Validation loss: 2.5521461350174786

Epoch: 6| Step: 12
Training loss: 2.595668496847416
Validation loss: 2.5655485567905236

Epoch: 6| Step: 13
Training loss: 2.7336438754692653
Validation loss: 2.573584699814991

Epoch: 191| Step: 0
Training loss: 3.364223512161865
Validation loss: 2.5827450103842593

Epoch: 6| Step: 1
Training loss: 2.7192002723792474
Validation loss: 2.5726659788080153

Epoch: 6| Step: 2
Training loss: 2.7992330658844957
Validation loss: 2.5836229416716106

Epoch: 6| Step: 3
Training loss: 2.5846036945897835
Validation loss: 2.58262671321119

Epoch: 6| Step: 4
Training loss: 2.9170031398877914
Validation loss: 2.5736430149540914

Epoch: 6| Step: 5
Training loss: 2.960080145962271
Validation loss: 2.5712224982252927

Epoch: 6| Step: 6
Training loss: 3.2713709751801274
Validation loss: 2.5620083250914503

Epoch: 6| Step: 7
Training loss: 2.855745106486259
Validation loss: 2.5542597073046096

Epoch: 6| Step: 8
Training loss: 2.6877146790392117
Validation loss: 2.5415003424747513

Epoch: 6| Step: 9
Training loss: 2.368008210077745
Validation loss: 2.5298192852306904

Epoch: 6| Step: 10
Training loss: 2.4934157451058767
Validation loss: 2.5325258807817543

Epoch: 6| Step: 11
Training loss: 2.7396284807979114
Validation loss: 2.5347046758276948

Epoch: 6| Step: 12
Training loss: 3.494751264373662
Validation loss: 2.553277301230824

Epoch: 6| Step: 13
Training loss: 2.4702163397683994
Validation loss: 2.539690736048069

Epoch: 192| Step: 0
Training loss: 2.731135427485536
Validation loss: 2.539601335294557

Epoch: 6| Step: 1
Training loss: 3.080031216203116
Validation loss: 2.5457748663223017

Epoch: 6| Step: 2
Training loss: 2.912668666949218
Validation loss: 2.538522363704348

Epoch: 6| Step: 3
Training loss: 2.615502387195767
Validation loss: 2.5433087288722973

Epoch: 6| Step: 4
Training loss: 2.6180320174297163
Validation loss: 2.55034640289953

Epoch: 6| Step: 5
Training loss: 2.5391496379278364
Validation loss: 2.5513430816195903

Epoch: 6| Step: 6
Training loss: 3.2090285072379947
Validation loss: 2.546057345832533

Epoch: 6| Step: 7
Training loss: 2.8649935526883477
Validation loss: 2.547904496968848

Epoch: 6| Step: 8
Training loss: 3.1178803785279463
Validation loss: 2.536070500132

Epoch: 6| Step: 9
Training loss: 2.451367568756942
Validation loss: 2.5444929935911618

Epoch: 6| Step: 10
Training loss: 3.2137054615948046
Validation loss: 2.535097195166765

Epoch: 6| Step: 11
Training loss: 2.6109590576304638
Validation loss: 2.5411455614409175

Epoch: 6| Step: 12
Training loss: 3.0802482601532697
Validation loss: 2.538045914230507

Epoch: 6| Step: 13
Training loss: 2.628027124203964
Validation loss: 2.5551138023534206

Epoch: 193| Step: 0
Training loss: 3.336787738591496
Validation loss: 2.5436657515131014

Epoch: 6| Step: 1
Training loss: 3.011210001564645
Validation loss: 2.5419997987613585

Epoch: 6| Step: 2
Training loss: 2.8065169379496084
Validation loss: 2.545737726227464

Epoch: 6| Step: 3
Training loss: 2.5306473944820866
Validation loss: 2.541474686272478

Epoch: 6| Step: 4
Training loss: 2.7178225634483866
Validation loss: 2.534568886570318

Epoch: 6| Step: 5
Training loss: 2.3924949164421263
Validation loss: 2.5315741591346574

Epoch: 6| Step: 6
Training loss: 2.4406684432028034
Validation loss: 2.536262127789523

Epoch: 6| Step: 7
Training loss: 2.833335670769419
Validation loss: 2.5394977801649197

Epoch: 6| Step: 8
Training loss: 2.960982913673005
Validation loss: 2.545791977511456

Epoch: 6| Step: 9
Training loss: 2.3333309264397695
Validation loss: 2.5458091379288095

Epoch: 6| Step: 10
Training loss: 3.1789147940103906
Validation loss: 2.549638134202913

Epoch: 6| Step: 11
Training loss: 2.645396419304864
Validation loss: 2.5498489288886783

Epoch: 6| Step: 12
Training loss: 3.4852619496307513
Validation loss: 2.545642926450615

Epoch: 6| Step: 13
Training loss: 3.0318129498500426
Validation loss: 2.555639439770001

Epoch: 194| Step: 0
Training loss: 2.6326419763779794
Validation loss: 2.547558047986297

Epoch: 6| Step: 1
Training loss: 2.4191917075257243
Validation loss: 2.5582863714550754

Epoch: 6| Step: 2
Training loss: 3.857750431023438
Validation loss: 2.551911891044837

Epoch: 6| Step: 3
Training loss: 2.7674495906770327
Validation loss: 2.5549802045173893

Epoch: 6| Step: 4
Training loss: 2.865301774993305
Validation loss: 2.5503154964420798

Epoch: 6| Step: 5
Training loss: 2.463555968379525
Validation loss: 2.544203451673359

Epoch: 6| Step: 6
Training loss: 3.034020170764599
Validation loss: 2.538784107883454

Epoch: 6| Step: 7
Training loss: 3.0764704096211317
Validation loss: 2.5331432514358934

Epoch: 6| Step: 8
Training loss: 2.8062919766487457
Validation loss: 2.536579548041535

Epoch: 6| Step: 9
Training loss: 2.4451221721058105
Validation loss: 2.5360821685914443

Epoch: 6| Step: 10
Training loss: 2.869538136179799
Validation loss: 2.533873994296912

Epoch: 6| Step: 11
Training loss: 2.8448484206757123
Validation loss: 2.5318793928820917

Epoch: 6| Step: 12
Training loss: 2.0431295590540914
Validation loss: 2.530437531016042

Epoch: 6| Step: 13
Training loss: 3.6111715230208543
Validation loss: 2.544886404764009

Epoch: 195| Step: 0
Training loss: 3.0931662577145396
Validation loss: 2.538082486093616

Epoch: 6| Step: 1
Training loss: 2.1915968541773907
Validation loss: 2.5471186971419155

Epoch: 6| Step: 2
Training loss: 3.2192663871085587
Validation loss: 2.537205997126987

Epoch: 6| Step: 3
Training loss: 2.299060015784007
Validation loss: 2.540713005417032

Epoch: 6| Step: 4
Training loss: 3.5694604437074093
Validation loss: 2.5434664861713876

Epoch: 6| Step: 5
Training loss: 2.7491986234144465
Validation loss: 2.5483494143531704

Epoch: 6| Step: 6
Training loss: 2.629465754969092
Validation loss: 2.541544735984723

Epoch: 6| Step: 7
Training loss: 2.5760673866165464
Validation loss: 2.554024057178175

Epoch: 6| Step: 8
Training loss: 2.657766111441148
Validation loss: 2.5545390131313845

Epoch: 6| Step: 9
Training loss: 3.0717760630883717
Validation loss: 2.545356744372766

Epoch: 6| Step: 10
Training loss: 2.9905701890345244
Validation loss: 2.5520878992464677

Epoch: 6| Step: 11
Training loss: 2.822875657200151
Validation loss: 2.5543508592291824

Epoch: 6| Step: 12
Training loss: 2.938143071336316
Validation loss: 2.547804764853276

Epoch: 6| Step: 13
Training loss: 2.574669296361422
Validation loss: 2.546986507811041

Epoch: 196| Step: 0
Training loss: 3.1354096033432866
Validation loss: 2.5363925867116484

Epoch: 6| Step: 1
Training loss: 2.4290242654492182
Validation loss: 2.5357595755034628

Epoch: 6| Step: 2
Training loss: 3.0872637639036604
Validation loss: 2.5333735952864176

Epoch: 6| Step: 3
Training loss: 2.9034188539659485
Validation loss: 2.5357296185291838

Epoch: 6| Step: 4
Training loss: 3.1147858586802672
Validation loss: 2.5294937975052383

Epoch: 6| Step: 5
Training loss: 3.031827576658977
Validation loss: 2.5301220486202323

Epoch: 6| Step: 6
Training loss: 2.9199439210601685
Validation loss: 2.5304287877624994

Epoch: 6| Step: 7
Training loss: 3.016196241283079
Validation loss: 2.5266699830425066

Epoch: 6| Step: 8
Training loss: 1.7229830546506135
Validation loss: 2.530557610417469

Epoch: 6| Step: 9
Training loss: 2.4047644847620426
Validation loss: 2.5373644743453676

Epoch: 6| Step: 10
Training loss: 3.2460664272879893
Validation loss: 2.5456774274281324

Epoch: 6| Step: 11
Training loss: 2.683864352202426
Validation loss: 2.5640650956115607

Epoch: 6| Step: 12
Training loss: 2.9866025909578124
Validation loss: 2.631126471799429

Epoch: 6| Step: 13
Training loss: 2.9995094534039346
Validation loss: 2.690056173059285

Epoch: 197| Step: 0
Training loss: 3.2933514464288236
Validation loss: 2.66288774871234

Epoch: 6| Step: 1
Training loss: 2.910609759126406
Validation loss: 2.566829865011911

Epoch: 6| Step: 2
Training loss: 2.8097288254728197
Validation loss: 2.532727690187367

Epoch: 6| Step: 3
Training loss: 2.4712774159633293
Validation loss: 2.525844340370976

Epoch: 6| Step: 4
Training loss: 2.5949880563685284
Validation loss: 2.532184725500753

Epoch: 6| Step: 5
Training loss: 3.2226293204367265
Validation loss: 2.542229561999444

Epoch: 6| Step: 6
Training loss: 2.930008445961923
Validation loss: 2.546062166390854

Epoch: 6| Step: 7
Training loss: 2.677906122688922
Validation loss: 2.5432638041867257

Epoch: 6| Step: 8
Training loss: 2.8411167235359005
Validation loss: 2.551433097838956

Epoch: 6| Step: 9
Training loss: 3.013670925651989
Validation loss: 2.5379405966034216

Epoch: 6| Step: 10
Training loss: 3.32391908328175
Validation loss: 2.5433572341022135

Epoch: 6| Step: 11
Training loss: 2.8714212451399423
Validation loss: 2.535894561499694

Epoch: 6| Step: 12
Training loss: 3.2308606206453137
Validation loss: 2.532395378562429

Epoch: 6| Step: 13
Training loss: 2.67031993563595
Validation loss: 2.5247530235756073

Epoch: 198| Step: 0
Training loss: 3.04272773385624
Validation loss: 2.529506774825975

Epoch: 6| Step: 1
Training loss: 2.9241309611141877
Validation loss: 2.5276125131508986

Epoch: 6| Step: 2
Training loss: 3.0080109766090266
Validation loss: 2.5349529288539863

Epoch: 6| Step: 3
Training loss: 2.875272654997465
Validation loss: 2.537361134107256

Epoch: 6| Step: 4
Training loss: 2.687128706722646
Validation loss: 2.5539513433872614

Epoch: 6| Step: 5
Training loss: 3.175925839218898
Validation loss: 2.5726902482521203

Epoch: 6| Step: 6
Training loss: 2.843632119219286
Validation loss: 2.5767745611886004

Epoch: 6| Step: 7
Training loss: 3.1686470631991512
Validation loss: 2.5789690542128247

Epoch: 6| Step: 8
Training loss: 2.5916575988741735
Validation loss: 2.574531376974197

Epoch: 6| Step: 9
Training loss: 2.7368836148778266
Validation loss: 2.567127642275941

Epoch: 6| Step: 10
Training loss: 2.9258542631076674
Validation loss: 2.5476049256371134

Epoch: 6| Step: 11
Training loss: 2.5560477365623853
Validation loss: 2.5432149171470453

Epoch: 6| Step: 12
Training loss: 2.6620231272999004
Validation loss: 2.536951490179389

Epoch: 6| Step: 13
Training loss: 2.529655613736559
Validation loss: 2.5283981233509953

Epoch: 199| Step: 0
Training loss: 2.520056570719972
Validation loss: 2.5258119678922957

Epoch: 6| Step: 1
Training loss: 2.480453371015317
Validation loss: 2.5250222239150357

Epoch: 6| Step: 2
Training loss: 3.215574753853443
Validation loss: 2.5239998785639397

Epoch: 6| Step: 3
Training loss: 3.400565908122264
Validation loss: 2.524787973489164

Epoch: 6| Step: 4
Training loss: 2.8446331958266304
Validation loss: 2.521986366552925

Epoch: 6| Step: 5
Training loss: 2.796689331029536
Validation loss: 2.528889053185238

Epoch: 6| Step: 6
Training loss: 2.9355213725085685
Validation loss: 2.5323116750302086

Epoch: 6| Step: 7
Training loss: 2.936790867696564
Validation loss: 2.532319787151521

Epoch: 6| Step: 8
Training loss: 2.6517130982629453
Validation loss: 2.5367349871013176

Epoch: 6| Step: 9
Training loss: 3.3871413938451718
Validation loss: 2.53657297565682

Epoch: 6| Step: 10
Training loss: 1.7923879576159536
Validation loss: 2.546557783851825

Epoch: 6| Step: 11
Training loss: 2.5860402066674233
Validation loss: 2.53579523305174

Epoch: 6| Step: 12
Training loss: 2.9165843043732855
Validation loss: 2.5537129352370167

Epoch: 6| Step: 13
Training loss: 3.0613278072464585
Validation loss: 2.5360548396669818

Epoch: 200| Step: 0
Training loss: 2.4327209769044513
Validation loss: 2.54444426719425

Epoch: 6| Step: 1
Training loss: 2.763407707394549
Validation loss: 2.5452965735280273

Epoch: 6| Step: 2
Training loss: 3.3580931591041616
Validation loss: 2.5493162176964583

Epoch: 6| Step: 3
Training loss: 2.2653416949756426
Validation loss: 2.5446755223872732

Epoch: 6| Step: 4
Training loss: 3.248313466209174
Validation loss: 2.536869740812571

Epoch: 6| Step: 5
Training loss: 2.1324502826006686
Validation loss: 2.52927611176161

Epoch: 6| Step: 6
Training loss: 3.5077503768075706
Validation loss: 2.5218342565428675

Epoch: 6| Step: 7
Training loss: 2.697667251507034
Validation loss: 2.5172990718934276

Epoch: 6| Step: 8
Training loss: 2.7107264191958884
Validation loss: 2.5194049681139283

Epoch: 6| Step: 9
Training loss: 2.7014170636753785
Validation loss: 2.5135148801548737

Epoch: 6| Step: 10
Training loss: 2.736365329617478
Validation loss: 2.5193717405564664

Epoch: 6| Step: 11
Training loss: 3.211846216076146
Validation loss: 2.522712228668069

Epoch: 6| Step: 12
Training loss: 3.228229821599896
Validation loss: 2.5205909290750377

Epoch: 6| Step: 13
Training loss: 2.135402908901153
Validation loss: 2.522945412837788

Epoch: 201| Step: 0
Training loss: 3.067622046992321
Validation loss: 2.5245628284695685

Epoch: 6| Step: 1
Training loss: 2.50099600978382
Validation loss: 2.5418427018225045

Epoch: 6| Step: 2
Training loss: 2.688101501575001
Validation loss: 2.5472275574042222

Epoch: 6| Step: 3
Training loss: 3.0639760100020634
Validation loss: 2.540016744941343

Epoch: 6| Step: 4
Training loss: 2.581731504738832
Validation loss: 2.5389936570646707

Epoch: 6| Step: 5
Training loss: 2.7756850041528582
Validation loss: 2.538335170774137

Epoch: 6| Step: 6
Training loss: 3.0668991567415564
Validation loss: 2.5408111179983837

Epoch: 6| Step: 7
Training loss: 2.7464238235684877
Validation loss: 2.5347214824701467

Epoch: 6| Step: 8
Training loss: 3.559929974756652
Validation loss: 2.5323431676927357

Epoch: 6| Step: 9
Training loss: 2.7341662517974763
Validation loss: 2.5221804263088305

Epoch: 6| Step: 10
Training loss: 2.3739438971403723
Validation loss: 2.522734683052972

Epoch: 6| Step: 11
Training loss: 3.142759442358995
Validation loss: 2.524450239797915

Epoch: 6| Step: 12
Training loss: 2.5347493790052846
Validation loss: 2.5223825593149667

Epoch: 6| Step: 13
Training loss: 2.6291338749778705
Validation loss: 2.525381283607613

Epoch: 202| Step: 0
Training loss: 2.546569618686075
Validation loss: 2.5266800278809747

Epoch: 6| Step: 1
Training loss: 3.192065391501723
Validation loss: 2.525692761124971

Epoch: 6| Step: 2
Training loss: 2.3684588250834597
Validation loss: 2.5305076664184187

Epoch: 6| Step: 3
Training loss: 2.9230256288483507
Validation loss: 2.5297345874387243

Epoch: 6| Step: 4
Training loss: 2.8538481448754047
Validation loss: 2.5287210290174342

Epoch: 6| Step: 5
Training loss: 2.8678727747259223
Validation loss: 2.5380232397541596

Epoch: 6| Step: 6
Training loss: 2.632657100268239
Validation loss: 2.5366805471711285

Epoch: 6| Step: 7
Training loss: 2.4237201184009076
Validation loss: 2.5385128989522663

Epoch: 6| Step: 8
Training loss: 3.558139608739483
Validation loss: 2.5284187224451444

Epoch: 6| Step: 9
Training loss: 2.972208999493461
Validation loss: 2.54313656568718

Epoch: 6| Step: 10
Training loss: 3.028810758465392
Validation loss: 2.5325352423858973

Epoch: 6| Step: 11
Training loss: 2.931720811330502
Validation loss: 2.531230665644784

Epoch: 6| Step: 12
Training loss: 2.7808885660955593
Validation loss: 2.535128594573826

Epoch: 6| Step: 13
Training loss: 1.8477600584647988
Validation loss: 2.5290943833273554

Epoch: 203| Step: 0
Training loss: 2.8270573576650038
Validation loss: 2.5276484438511835

Epoch: 6| Step: 1
Training loss: 3.144206420043191
Validation loss: 2.5228932797472083

Epoch: 6| Step: 2
Training loss: 2.798013295663543
Validation loss: 2.52469939959795

Epoch: 6| Step: 3
Training loss: 3.1652233113699646
Validation loss: 2.5226152068837595

Epoch: 6| Step: 4
Training loss: 2.9610827568880356
Validation loss: 2.516300949055974

Epoch: 6| Step: 5
Training loss: 2.961242176977913
Validation loss: 2.5229660320644007

Epoch: 6| Step: 6
Training loss: 3.0436813440745696
Validation loss: 2.5244554504478693

Epoch: 6| Step: 7
Training loss: 2.6045399716159316
Validation loss: 2.527053299247166

Epoch: 6| Step: 8
Training loss: 2.265608899289503
Validation loss: 2.5269690099151565

Epoch: 6| Step: 9
Training loss: 2.261179805444235
Validation loss: 2.531534371150668

Epoch: 6| Step: 10
Training loss: 3.6877399948384717
Validation loss: 2.5355730825020237

Epoch: 6| Step: 11
Training loss: 2.6023210215885846
Validation loss: 2.5355797484745444

Epoch: 6| Step: 12
Training loss: 2.569541374875537
Validation loss: 2.5427831446546927

Epoch: 6| Step: 13
Training loss: 1.8570894571633723
Validation loss: 2.572504007912823

Epoch: 204| Step: 0
Training loss: 3.117205244506199
Validation loss: 2.572079988824374

Epoch: 6| Step: 1
Training loss: 2.613075601785561
Validation loss: 2.5703865841259166

Epoch: 6| Step: 2
Training loss: 2.550982947794627
Validation loss: 2.569447639911959

Epoch: 6| Step: 3
Training loss: 3.2963441538898497
Validation loss: 2.59135485060795

Epoch: 6| Step: 4
Training loss: 3.317303898871899
Validation loss: 2.576965398397245

Epoch: 6| Step: 5
Training loss: 2.880441574576853
Validation loss: 2.5688056786671614

Epoch: 6| Step: 6
Training loss: 2.2975656937099407
Validation loss: 2.556454216234486

Epoch: 6| Step: 7
Training loss: 3.044816480847175
Validation loss: 2.5393558041875517

Epoch: 6| Step: 8
Training loss: 2.700871051578705
Validation loss: 2.5403835175057012

Epoch: 6| Step: 9
Training loss: 2.5481094457934295
Validation loss: 2.5229622327823527

Epoch: 6| Step: 10
Training loss: 2.4562061179708676
Validation loss: 2.5237916696408544

Epoch: 6| Step: 11
Training loss: 2.6859374715950404
Validation loss: 2.523559695361314

Epoch: 6| Step: 12
Training loss: 3.348604048068351
Validation loss: 2.515792698417896

Epoch: 6| Step: 13
Training loss: 2.309515599576565
Validation loss: 2.5203481329454

Epoch: 205| Step: 0
Training loss: 2.881855462065341
Validation loss: 2.5250328956507224

Epoch: 6| Step: 1
Training loss: 3.2965978713872226
Validation loss: 2.525641024784143

Epoch: 6| Step: 2
Training loss: 3.403407879746836
Validation loss: 2.532247399748628

Epoch: 6| Step: 3
Training loss: 2.978668509139832
Validation loss: 2.5252826111369506

Epoch: 6| Step: 4
Training loss: 2.6514936160579556
Validation loss: 2.522972139964789

Epoch: 6| Step: 5
Training loss: 2.818431448857534
Validation loss: 2.5347790835926127

Epoch: 6| Step: 6
Training loss: 2.6450528372839597
Validation loss: 2.5336619069606123

Epoch: 6| Step: 7
Training loss: 2.857150520586908
Validation loss: 2.534318272349114

Epoch: 6| Step: 8
Training loss: 2.8109570827512353
Validation loss: 2.540414614425568

Epoch: 6| Step: 9
Training loss: 2.01454417503931
Validation loss: 2.5315598015066696

Epoch: 6| Step: 10
Training loss: 3.403277158532
Validation loss: 2.535061881745772

Epoch: 6| Step: 11
Training loss: 2.7731868147048675
Validation loss: 2.53361854755728

Epoch: 6| Step: 12
Training loss: 1.9715974591261065
Validation loss: 2.5269707335706255

Epoch: 6| Step: 13
Training loss: 2.4517371266827306
Validation loss: 2.5265376887935123

Epoch: 206| Step: 0
Training loss: 2.5546838602862545
Validation loss: 2.5268660257079416

Epoch: 6| Step: 1
Training loss: 3.0931967809013408
Validation loss: 2.5174504060128426

Epoch: 6| Step: 2
Training loss: 2.875108468041324
Validation loss: 2.5147801369462632

Epoch: 6| Step: 3
Training loss: 2.610454495930447
Validation loss: 2.5139702187561257

Epoch: 6| Step: 4
Training loss: 3.805708918455178
Validation loss: 2.524481274030646

Epoch: 6| Step: 5
Training loss: 2.8433242311440043
Validation loss: 2.521735250090726

Epoch: 6| Step: 6
Training loss: 2.800428722120855
Validation loss: 2.5166156041045444

Epoch: 6| Step: 7
Training loss: 2.170312442875663
Validation loss: 2.5234213466312045

Epoch: 6| Step: 8
Training loss: 2.42032696871684
Validation loss: 2.519222877673182

Epoch: 6| Step: 9
Training loss: 2.4325364266752616
Validation loss: 2.5297793926290506

Epoch: 6| Step: 10
Training loss: 3.163441086016888
Validation loss: 2.5255840080180314

Epoch: 6| Step: 11
Training loss: 2.917459507312251
Validation loss: 2.5354011523912603

Epoch: 6| Step: 12
Training loss: 2.785154623536736
Validation loss: 2.546674868372307

Epoch: 6| Step: 13
Training loss: 2.6382543090854527
Validation loss: 2.552012229131488

Epoch: 207| Step: 0
Training loss: 2.9074120608124026
Validation loss: 2.567949552578529

Epoch: 6| Step: 1
Training loss: 2.957307306301841
Validation loss: 2.5603671277825315

Epoch: 6| Step: 2
Training loss: 2.522713572115799
Validation loss: 2.5594403428510737

Epoch: 6| Step: 3
Training loss: 3.3941314426701377
Validation loss: 2.571217650557489

Epoch: 6| Step: 4
Training loss: 2.3574912527979914
Validation loss: 2.5807261222911713

Epoch: 6| Step: 5
Training loss: 2.5386781372237253
Validation loss: 2.587973497750597

Epoch: 6| Step: 6
Training loss: 3.157522417171635
Validation loss: 2.5834631085092776

Epoch: 6| Step: 7
Training loss: 2.98426427186396
Validation loss: 2.575557283493416

Epoch: 6| Step: 8
Training loss: 2.618092485791928
Validation loss: 2.5615178028403904

Epoch: 6| Step: 9
Training loss: 2.628100789034587
Validation loss: 2.5496170650374066

Epoch: 6| Step: 10
Training loss: 3.188674411214231
Validation loss: 2.5356487477930716

Epoch: 6| Step: 11
Training loss: 2.4965325150483917
Validation loss: 2.5180145849918616

Epoch: 6| Step: 12
Training loss: 2.8844591519033553
Validation loss: 2.517118239708829

Epoch: 6| Step: 13
Training loss: 2.802360312990109
Validation loss: 2.5128093195421375

Epoch: 208| Step: 0
Training loss: 2.6651911428300643
Validation loss: 2.5262599572078948

Epoch: 6| Step: 1
Training loss: 3.0740828720368603
Validation loss: 2.520296644944398

Epoch: 6| Step: 2
Training loss: 2.663879030236158
Validation loss: 2.5232936460392326

Epoch: 6| Step: 3
Training loss: 3.161089218352864
Validation loss: 2.535310119007413

Epoch: 6| Step: 4
Training loss: 2.4708903245534146
Validation loss: 2.5575641383084458

Epoch: 6| Step: 5
Training loss: 2.937386368521941
Validation loss: 2.5698608506310143

Epoch: 6| Step: 6
Training loss: 2.058210825910223
Validation loss: 2.548851307843796

Epoch: 6| Step: 7
Training loss: 3.003823704571314
Validation loss: 2.5444281615456483

Epoch: 6| Step: 8
Training loss: 3.1799875628630025
Validation loss: 2.5313244131015895

Epoch: 6| Step: 9
Training loss: 2.772419917443769
Validation loss: 2.5349758340660586

Epoch: 6| Step: 10
Training loss: 3.305211523907878
Validation loss: 2.5313766434644713

Epoch: 6| Step: 11
Training loss: 2.33701241043576
Validation loss: 2.5372310937849862

Epoch: 6| Step: 12
Training loss: 2.913323111730782
Validation loss: 2.5250691696711045

Epoch: 6| Step: 13
Training loss: 3.2495154973329834
Validation loss: 2.5277161961634014

Epoch: 209| Step: 0
Training loss: 2.664777821911036
Validation loss: 2.519298888004924

Epoch: 6| Step: 1
Training loss: 3.078632913113952
Validation loss: 2.5337060477546984

Epoch: 6| Step: 2
Training loss: 2.791073285328769
Validation loss: 2.5430870471583527

Epoch: 6| Step: 3
Training loss: 2.761705714172072
Validation loss: 2.5440692295049785

Epoch: 6| Step: 4
Training loss: 3.0175016424368977
Validation loss: 2.5448267214579663

Epoch: 6| Step: 5
Training loss: 2.5025761682463843
Validation loss: 2.532217677611886

Epoch: 6| Step: 6
Training loss: 2.9476773509734566
Validation loss: 2.5305644993073013

Epoch: 6| Step: 7
Training loss: 2.3107446761605965
Validation loss: 2.54275241646949

Epoch: 6| Step: 8
Training loss: 3.14034623004854
Validation loss: 2.5326985698829128

Epoch: 6| Step: 9
Training loss: 2.7765478611411543
Validation loss: 2.52673982631154

Epoch: 6| Step: 10
Training loss: 3.026170860242101
Validation loss: 2.523877436355159

Epoch: 6| Step: 11
Training loss: 2.790335741248562
Validation loss: 2.525378009746964

Epoch: 6| Step: 12
Training loss: 2.7039014109182715
Validation loss: 2.5129821750566976

Epoch: 6| Step: 13
Training loss: 3.042199406064192
Validation loss: 2.515616230741419

Epoch: 210| Step: 0
Training loss: 3.022077860921711
Validation loss: 2.5140281372703592

Epoch: 6| Step: 1
Training loss: 2.7173439862651105
Validation loss: 2.514105160698453

Epoch: 6| Step: 2
Training loss: 2.3293914422595385
Validation loss: 2.5139391159520863

Epoch: 6| Step: 3
Training loss: 3.1296873415462705
Validation loss: 2.5239347760783595

Epoch: 6| Step: 4
Training loss: 2.742722766073762
Validation loss: 2.5237634183500366

Epoch: 6| Step: 5
Training loss: 2.8441876085212487
Validation loss: 2.524512942568889

Epoch: 6| Step: 6
Training loss: 2.978552606071652
Validation loss: 2.528146384320498

Epoch: 6| Step: 7
Training loss: 2.8822394734518886
Validation loss: 2.5307862153034164

Epoch: 6| Step: 8
Training loss: 2.4427518752608863
Validation loss: 2.526430868077823

Epoch: 6| Step: 9
Training loss: 2.707457669843904
Validation loss: 2.526494155375328

Epoch: 6| Step: 10
Training loss: 2.293248642015611
Validation loss: 2.5247438463507628

Epoch: 6| Step: 11
Training loss: 3.054010106367915
Validation loss: 2.532045197695492

Epoch: 6| Step: 12
Training loss: 3.180182341140267
Validation loss: 2.5336121303996872

Epoch: 6| Step: 13
Training loss: 3.120062016579909
Validation loss: 2.5347464115616036

Epoch: 211| Step: 0
Training loss: 2.44615222296917
Validation loss: 2.5430926863635976

Epoch: 6| Step: 1
Training loss: 3.1010146726219943
Validation loss: 2.539488198916469

Epoch: 6| Step: 2
Training loss: 3.0025040983986813
Validation loss: 2.545677181202841

Epoch: 6| Step: 3
Training loss: 3.4554214781344306
Validation loss: 2.54062280412512

Epoch: 6| Step: 4
Training loss: 2.3875885672394133
Validation loss: 2.542190610386544

Epoch: 6| Step: 5
Training loss: 3.0695475239272563
Validation loss: 2.5434468636803174

Epoch: 6| Step: 6
Training loss: 2.935158465914871
Validation loss: 2.5669843152196665

Epoch: 6| Step: 7
Training loss: 2.9418273867467284
Validation loss: 2.559442330106241

Epoch: 6| Step: 8
Training loss: 2.7523814207168713
Validation loss: 2.53163009720782

Epoch: 6| Step: 9
Training loss: 2.290866804695967
Validation loss: 2.5262031685381343

Epoch: 6| Step: 10
Training loss: 2.1369541742876406
Validation loss: 2.5300209163611957

Epoch: 6| Step: 11
Training loss: 2.815409278861818
Validation loss: 2.521983382058853

Epoch: 6| Step: 12
Training loss: 3.057797149167443
Validation loss: 2.5251467360286743

Epoch: 6| Step: 13
Training loss: 2.9299604365050502
Validation loss: 2.510241136799812

Epoch: 212| Step: 0
Training loss: 2.4909797061689223
Validation loss: 2.513657610934743

Epoch: 6| Step: 1
Training loss: 2.871186422292641
Validation loss: 2.5085711835095297

Epoch: 6| Step: 2
Training loss: 3.1362485236251474
Validation loss: 2.5023945589840295

Epoch: 6| Step: 3
Training loss: 3.128357266426162
Validation loss: 2.512251059702437

Epoch: 6| Step: 4
Training loss: 2.56175574682847
Validation loss: 2.5198471640769498

Epoch: 6| Step: 5
Training loss: 2.8349394079659582
Validation loss: 2.5268424392593336

Epoch: 6| Step: 6
Training loss: 2.7167572084406544
Validation loss: 2.540996625250267

Epoch: 6| Step: 7
Training loss: 3.0298880437430666
Validation loss: 2.542815407942142

Epoch: 6| Step: 8
Training loss: 2.9568912770289546
Validation loss: 2.539669077620435

Epoch: 6| Step: 9
Training loss: 2.635470986591769
Validation loss: 2.5339293372915894

Epoch: 6| Step: 10
Training loss: 2.9115146001429744
Validation loss: 2.528873120154586

Epoch: 6| Step: 11
Training loss: 2.316465740501358
Validation loss: 2.526540364517214

Epoch: 6| Step: 12
Training loss: 2.85176031393288
Validation loss: 2.5214844024514083

Epoch: 6| Step: 13
Training loss: 2.9825373079535753
Validation loss: 2.5254963431553996

Epoch: 213| Step: 0
Training loss: 2.572777861481638
Validation loss: 2.5269982094337005

Epoch: 6| Step: 1
Training loss: 3.125129849597175
Validation loss: 2.526074347090642

Epoch: 6| Step: 2
Training loss: 2.721560373965756
Validation loss: 2.528680107291899

Epoch: 6| Step: 3
Training loss: 1.8330656275220636
Validation loss: 2.529474961547366

Epoch: 6| Step: 4
Training loss: 2.8875034282713514
Validation loss: 2.539899768335796

Epoch: 6| Step: 5
Training loss: 3.2279451746674974
Validation loss: 2.5323991879882946

Epoch: 6| Step: 6
Training loss: 2.40060128388711
Validation loss: 2.5315591331428244

Epoch: 6| Step: 7
Training loss: 2.6346064491912946
Validation loss: 2.5323816471695553

Epoch: 6| Step: 8
Training loss: 2.4438597047186765
Validation loss: 2.5267717901975306

Epoch: 6| Step: 9
Training loss: 2.5479867766978885
Validation loss: 2.5291284086080723

Epoch: 6| Step: 10
Training loss: 2.9052043387265996
Validation loss: 2.5336958992344734

Epoch: 6| Step: 11
Training loss: 3.7515184507123456
Validation loss: 2.532926930934035

Epoch: 6| Step: 12
Training loss: 3.2936350735442237
Validation loss: 2.5377709897142116

Epoch: 6| Step: 13
Training loss: 2.1549625699715795
Validation loss: 2.5337652488380886

Epoch: 214| Step: 0
Training loss: 2.9243135934747073
Validation loss: 2.537192434239202

Epoch: 6| Step: 1
Training loss: 2.154001251992488
Validation loss: 2.5236508092516616

Epoch: 6| Step: 2
Training loss: 2.5291811176454906
Validation loss: 2.516318688568975

Epoch: 6| Step: 3
Training loss: 3.207033331588088
Validation loss: 2.529771392954758

Epoch: 6| Step: 4
Training loss: 2.9823251445000243
Validation loss: 2.517126455792972

Epoch: 6| Step: 5
Training loss: 3.010427155965903
Validation loss: 2.512969710726757

Epoch: 6| Step: 6
Training loss: 3.144275877635061
Validation loss: 2.5162707512513673

Epoch: 6| Step: 7
Training loss: 2.8745076960462126
Validation loss: 2.508361223775955

Epoch: 6| Step: 8
Training loss: 2.92844765431491
Validation loss: 2.5087842903916817

Epoch: 6| Step: 9
Training loss: 2.420736919153027
Validation loss: 2.5086031826826574

Epoch: 6| Step: 10
Training loss: 2.75486351312032
Validation loss: 2.5181143567244386

Epoch: 6| Step: 11
Training loss: 3.1149015912573823
Validation loss: 2.5129087041932334

Epoch: 6| Step: 12
Training loss: 2.4330346703683357
Validation loss: 2.5260758247429833

Epoch: 6| Step: 13
Training loss: 2.4464098141043626
Validation loss: 2.524042956299288

Epoch: 215| Step: 0
Training loss: 2.6946254573290225
Validation loss: 2.531657884013271

Epoch: 6| Step: 1
Training loss: 2.2758788538705477
Validation loss: 2.539908450725286

Epoch: 6| Step: 2
Training loss: 3.026954832629132
Validation loss: 2.537585356775149

Epoch: 6| Step: 3
Training loss: 2.583418526834171
Validation loss: 2.5303020218821555

Epoch: 6| Step: 4
Training loss: 3.1134886247786384
Validation loss: 2.537690084019839

Epoch: 6| Step: 5
Training loss: 2.5312958701416246
Validation loss: 2.5360590792834405

Epoch: 6| Step: 6
Training loss: 2.992023832063057
Validation loss: 2.524457241828452

Epoch: 6| Step: 7
Training loss: 2.903288778524511
Validation loss: 2.5195367414791914

Epoch: 6| Step: 8
Training loss: 2.9658757802168245
Validation loss: 2.5214208607916735

Epoch: 6| Step: 9
Training loss: 2.7688801891985557
Validation loss: 2.519303537927618

Epoch: 6| Step: 10
Training loss: 2.743020477285241
Validation loss: 2.511307218138637

Epoch: 6| Step: 11
Training loss: 3.1501460208048417
Validation loss: 2.517820801838223

Epoch: 6| Step: 12
Training loss: 2.683424942948559
Validation loss: 2.5512097606240993

Epoch: 6| Step: 13
Training loss: 2.8952049470081844
Validation loss: 2.5389866274721538

Epoch: 216| Step: 0
Training loss: 3.043330551792418
Validation loss: 2.5265923401670087

Epoch: 6| Step: 1
Training loss: 3.0796136499818116
Validation loss: 2.5161235572359915

Epoch: 6| Step: 2
Training loss: 3.4582656639250136
Validation loss: 2.5067811898260968

Epoch: 6| Step: 3
Training loss: 2.4633041385612
Validation loss: 2.506969636492408

Epoch: 6| Step: 4
Training loss: 2.324848096253666
Validation loss: 2.509673792491386

Epoch: 6| Step: 5
Training loss: 2.223927648780805
Validation loss: 2.5046735394879294

Epoch: 6| Step: 6
Training loss: 2.732143690605998
Validation loss: 2.504643073550393

Epoch: 6| Step: 7
Training loss: 2.532429173223808
Validation loss: 2.512190985784097

Epoch: 6| Step: 8
Training loss: 2.610497878369878
Validation loss: 2.507305991786946

Epoch: 6| Step: 9
Training loss: 2.8147990684552187
Validation loss: 2.518225562148238

Epoch: 6| Step: 10
Training loss: 3.466181173318777
Validation loss: 2.5591239709831717

Epoch: 6| Step: 11
Training loss: 3.069294146678987
Validation loss: 2.562693678857086

Epoch: 6| Step: 12
Training loss: 2.7168042465976554
Validation loss: 2.592030805093406

Epoch: 6| Step: 13
Training loss: 2.360939568165871
Validation loss: 2.5784225128130918

Epoch: 217| Step: 0
Training loss: 2.9457871436599
Validation loss: 2.596108433914346

Epoch: 6| Step: 1
Training loss: 3.09061157100217
Validation loss: 2.6006635971500205

Epoch: 6| Step: 2
Training loss: 2.7534396594702244
Validation loss: 2.6067720324919716

Epoch: 6| Step: 3
Training loss: 2.9272339986848745
Validation loss: 2.58130815126585

Epoch: 6| Step: 4
Training loss: 3.124517632449182
Validation loss: 2.575047896684737

Epoch: 6| Step: 5
Training loss: 3.2018106881004194
Validation loss: 2.563675981506671

Epoch: 6| Step: 6
Training loss: 2.8839259698072373
Validation loss: 2.582175882380678

Epoch: 6| Step: 7
Training loss: 2.8241331475291926
Validation loss: 2.5610604793613163

Epoch: 6| Step: 8
Training loss: 1.7686854482133558
Validation loss: 2.553111746642633

Epoch: 6| Step: 9
Training loss: 3.0151765321890642
Validation loss: 2.5371818540653446

Epoch: 6| Step: 10
Training loss: 2.4135756510939257
Validation loss: 2.5201635227644683

Epoch: 6| Step: 11
Training loss: 2.890283512873787
Validation loss: 2.51860311471696

Epoch: 6| Step: 12
Training loss: 2.4035549181065634
Validation loss: 2.514191533159448

Epoch: 6| Step: 13
Training loss: 2.9097111918488925
Validation loss: 2.5081401298253065

Epoch: 218| Step: 0
Training loss: 2.8685166606874715
Validation loss: 2.5095155331102754

Epoch: 6| Step: 1
Training loss: 2.8465816945505007
Validation loss: 2.5158432361590886

Epoch: 6| Step: 2
Training loss: 2.9721165892783667
Validation loss: 2.5133847239631937

Epoch: 6| Step: 3
Training loss: 2.9957630119152565
Validation loss: 2.5147443241388214

Epoch: 6| Step: 4
Training loss: 2.386604168977567
Validation loss: 2.517366549766888

Epoch: 6| Step: 5
Training loss: 2.7739178308750043
Validation loss: 2.530809682946348

Epoch: 6| Step: 6
Training loss: 2.973462831245965
Validation loss: 2.556609475757881

Epoch: 6| Step: 7
Training loss: 2.4143141334518488
Validation loss: 2.5684011956820694

Epoch: 6| Step: 8
Training loss: 2.5860936789011038
Validation loss: 2.5747229146374226

Epoch: 6| Step: 9
Training loss: 3.0495232443986127
Validation loss: 2.5814924187507633

Epoch: 6| Step: 10
Training loss: 2.6641266666862298
Validation loss: 2.5763521633993616

Epoch: 6| Step: 11
Training loss: 2.6336345351463586
Validation loss: 2.5687815511640237

Epoch: 6| Step: 12
Training loss: 2.9189260360270155
Validation loss: 2.545791269582594

Epoch: 6| Step: 13
Training loss: 3.610854204934676
Validation loss: 2.5420131564850763

Epoch: 219| Step: 0
Training loss: 2.7860465532782634
Validation loss: 2.518677245459072

Epoch: 6| Step: 1
Training loss: 3.1524947081845887
Validation loss: 2.5101122866706618

Epoch: 6| Step: 2
Training loss: 2.5383186072233177
Validation loss: 2.5114699591204688

Epoch: 6| Step: 3
Training loss: 2.618661767023997
Validation loss: 2.507843000014206

Epoch: 6| Step: 4
Training loss: 3.127378855309774
Validation loss: 2.5101897335781373

Epoch: 6| Step: 5
Training loss: 2.9347056632159747
Validation loss: 2.5192941948255316

Epoch: 6| Step: 6
Training loss: 3.3206104818034277
Validation loss: 2.5074101975351577

Epoch: 6| Step: 7
Training loss: 3.0201666436102133
Validation loss: 2.516956222461673

Epoch: 6| Step: 8
Training loss: 2.3951939821627644
Validation loss: 2.509712851417878

Epoch: 6| Step: 9
Training loss: 2.8800543432936654
Validation loss: 2.518724334414225

Epoch: 6| Step: 10
Training loss: 2.884060886592168
Validation loss: 2.5202712555551363

Epoch: 6| Step: 11
Training loss: 2.2531208011836745
Validation loss: 2.5279305134451

Epoch: 6| Step: 12
Training loss: 2.5949633414558586
Validation loss: 2.5415393253449605

Epoch: 6| Step: 13
Training loss: 2.836339832697311
Validation loss: 2.5436744976446137

Epoch: 220| Step: 0
Training loss: 2.8189512227504645
Validation loss: 2.568239258277672

Epoch: 6| Step: 1
Training loss: 2.809106771969204
Validation loss: 2.563533836525761

Epoch: 6| Step: 2
Training loss: 2.88198369215217
Validation loss: 2.5916025637395586

Epoch: 6| Step: 3
Training loss: 2.5371555150911758
Validation loss: 2.5605811030774004

Epoch: 6| Step: 4
Training loss: 2.538867649524681
Validation loss: 2.5485317182503184

Epoch: 6| Step: 5
Training loss: 2.4081514450431025
Validation loss: 2.525199207873533

Epoch: 6| Step: 6
Training loss: 2.6620171265771266
Validation loss: 2.509397373736448

Epoch: 6| Step: 7
Training loss: 3.1028896154156214
Validation loss: 2.5092910570099107

Epoch: 6| Step: 8
Training loss: 3.480350102758134
Validation loss: 2.506110361639523

Epoch: 6| Step: 9
Training loss: 3.0018398682990517
Validation loss: 2.5103277770130337

Epoch: 6| Step: 10
Training loss: 2.8815175691433392
Validation loss: 2.5040404458321865

Epoch: 6| Step: 11
Training loss: 3.1976633541085113
Validation loss: 2.507812097228863

Epoch: 6| Step: 12
Training loss: 2.6687427922671896
Validation loss: 2.52475825847798

Epoch: 6| Step: 13
Training loss: 2.5733012994277833
Validation loss: 2.51756346047144

Epoch: 221| Step: 0
Training loss: 2.523753237974934
Validation loss: 2.5211002476688664

Epoch: 6| Step: 1
Training loss: 3.2549488828896544
Validation loss: 2.525244683368796

Epoch: 6| Step: 2
Training loss: 3.0768364857446953
Validation loss: 2.5080676895349434

Epoch: 6| Step: 3
Training loss: 2.536170791735264
Validation loss: 2.5112687546679453

Epoch: 6| Step: 4
Training loss: 3.2921348592915654
Validation loss: 2.5147006834078223

Epoch: 6| Step: 5
Training loss: 2.589382032660626
Validation loss: 2.5225074847650286

Epoch: 6| Step: 6
Training loss: 2.4484079287361507
Validation loss: 2.519423710953462

Epoch: 6| Step: 7
Training loss: 2.4261823190548126
Validation loss: 2.528737001530886

Epoch: 6| Step: 8
Training loss: 2.8991425265975397
Validation loss: 2.540694428206542

Epoch: 6| Step: 9
Training loss: 2.479231686634382
Validation loss: 2.5479887356587607

Epoch: 6| Step: 10
Training loss: 3.0652406846301505
Validation loss: 2.5533253128648483

Epoch: 6| Step: 11
Training loss: 2.932753441306916
Validation loss: 2.5603003015813095

Epoch: 6| Step: 12
Training loss: 2.720802672263552
Validation loss: 2.5620137360309707

Epoch: 6| Step: 13
Training loss: 2.9717634466917553
Validation loss: 2.5653375021746476

Epoch: 222| Step: 0
Training loss: 2.293821108180991
Validation loss: 2.564543371809798

Epoch: 6| Step: 1
Training loss: 3.0780552890067807
Validation loss: 2.5562338901468156

Epoch: 6| Step: 2
Training loss: 2.3467909349606177
Validation loss: 2.5480699985082094

Epoch: 6| Step: 3
Training loss: 3.146951708194922
Validation loss: 2.541718112445746

Epoch: 6| Step: 4
Training loss: 2.4847899276391696
Validation loss: 2.5340988532918205

Epoch: 6| Step: 5
Training loss: 2.5613831668191316
Validation loss: 2.5353444734241863

Epoch: 6| Step: 6
Training loss: 2.796444225702454
Validation loss: 2.535856363299101

Epoch: 6| Step: 7
Training loss: 2.4624912745906946
Validation loss: 2.526773258817988

Epoch: 6| Step: 8
Training loss: 2.8307750783576022
Validation loss: 2.5352153277267155

Epoch: 6| Step: 9
Training loss: 3.3653141483852256
Validation loss: 2.517493146734753

Epoch: 6| Step: 10
Training loss: 2.9283014299293657
Validation loss: 2.511569201811119

Epoch: 6| Step: 11
Training loss: 2.7497958194186767
Validation loss: 2.508243530266271

Epoch: 6| Step: 12
Training loss: 3.279244963807036
Validation loss: 2.4996199780471064

Epoch: 6| Step: 13
Training loss: 2.443550035339469
Validation loss: 2.4970717149163066

Epoch: 223| Step: 0
Training loss: 2.834964806070819
Validation loss: 2.5060062041408697

Epoch: 6| Step: 1
Training loss: 3.2344289581663106
Validation loss: 2.506769719395702

Epoch: 6| Step: 2
Training loss: 2.4271785624626734
Validation loss: 2.494900539571965

Epoch: 6| Step: 3
Training loss: 2.393011360648416
Validation loss: 2.509897244612691

Epoch: 6| Step: 4
Training loss: 2.9502935813036215
Validation loss: 2.5106755700423746

Epoch: 6| Step: 5
Training loss: 3.0157979806888835
Validation loss: 2.5001814345695488

Epoch: 6| Step: 6
Training loss: 2.5987136409650904
Validation loss: 2.5035880110874693

Epoch: 6| Step: 7
Training loss: 3.380507884494415
Validation loss: 2.5169793515425662

Epoch: 6| Step: 8
Training loss: 3.061541971883689
Validation loss: 2.5231112906145707

Epoch: 6| Step: 9
Training loss: 2.5098923469345618
Validation loss: 2.524228159231359

Epoch: 6| Step: 10
Training loss: 2.5874270848122407
Validation loss: 2.5463318518957747

Epoch: 6| Step: 11
Training loss: 2.4366692325493298
Validation loss: 2.5694296406196857

Epoch: 6| Step: 12
Training loss: 2.845710665366211
Validation loss: 2.5735290719853547

Epoch: 6| Step: 13
Training loss: 2.874696798507559
Validation loss: 2.5618730243729813

Epoch: 224| Step: 0
Training loss: 3.3508897653068628
Validation loss: 2.5449457834592866

Epoch: 6| Step: 1
Training loss: 3.238241197731803
Validation loss: 2.522671381214907

Epoch: 6| Step: 2
Training loss: 2.554498134675822
Validation loss: 2.502464739658952

Epoch: 6| Step: 3
Training loss: 3.2263490915729127
Validation loss: 2.498266067938534

Epoch: 6| Step: 4
Training loss: 2.9677684566735927
Validation loss: 2.4960879625043466

Epoch: 6| Step: 5
Training loss: 2.591447290619393
Validation loss: 2.4940441168585723

Epoch: 6| Step: 6
Training loss: 2.2424089807519025
Validation loss: 2.4943888606216555

Epoch: 6| Step: 7
Training loss: 2.3730729968984097
Validation loss: 2.4927681119184197

Epoch: 6| Step: 8
Training loss: 2.5668362470645425
Validation loss: 2.4977302163595962

Epoch: 6| Step: 9
Training loss: 2.403564341532025
Validation loss: 2.4962450315063784

Epoch: 6| Step: 10
Training loss: 3.0234140005849524
Validation loss: 2.5012467710740607

Epoch: 6| Step: 11
Training loss: 2.90356649566966
Validation loss: 2.5052826545713405

Epoch: 6| Step: 12
Training loss: 2.6462892354832404
Validation loss: 2.510148289142915

Epoch: 6| Step: 13
Training loss: 3.047206293337035
Validation loss: 2.509135236863233

Epoch: 225| Step: 0
Training loss: 2.6704280571573857
Validation loss: 2.4996952573586144

Epoch: 6| Step: 1
Training loss: 2.756290091225175
Validation loss: 2.498358064256117

Epoch: 6| Step: 2
Training loss: 3.0175910825975842
Validation loss: 2.4998065504476616

Epoch: 6| Step: 3
Training loss: 3.1507405455079005
Validation loss: 2.505283164171686

Epoch: 6| Step: 4
Training loss: 2.6747662700611405
Validation loss: 2.5007535762622757

Epoch: 6| Step: 5
Training loss: 2.5445800926479776
Validation loss: 2.506092678759692

Epoch: 6| Step: 6
Training loss: 2.3578688506716765
Validation loss: 2.516564582707947

Epoch: 6| Step: 7
Training loss: 2.9481794332299414
Validation loss: 2.5249096638510786

Epoch: 6| Step: 8
Training loss: 2.4258636116628933
Validation loss: 2.530929331417897

Epoch: 6| Step: 9
Training loss: 3.419048936456279
Validation loss: 2.5367512840879174

Epoch: 6| Step: 10
Training loss: 3.265640769810907
Validation loss: 2.542073587583873

Epoch: 6| Step: 11
Training loss: 2.298306388927563
Validation loss: 2.5327771612429624

Epoch: 6| Step: 12
Training loss: 2.5749201419632013
Validation loss: 2.522447126618948

Epoch: 6| Step: 13
Training loss: 2.7271080892171176
Validation loss: 2.513969750687271

Epoch: 226| Step: 0
Training loss: 1.9190682485867365
Validation loss: 2.5084992901636527

Epoch: 6| Step: 1
Training loss: 2.9357572214953356
Validation loss: 2.5167763109233445

Epoch: 6| Step: 2
Training loss: 2.7569818299323976
Validation loss: 2.518395492850607

Epoch: 6| Step: 3
Training loss: 3.0298087242863563
Validation loss: 2.517715499613645

Epoch: 6| Step: 4
Training loss: 3.0074931978448443
Validation loss: 2.5158688353106813

Epoch: 6| Step: 5
Training loss: 2.6648214830795194
Validation loss: 2.5088855036374906

Epoch: 6| Step: 6
Training loss: 2.9247466474833903
Validation loss: 2.5067995223611335

Epoch: 6| Step: 7
Training loss: 2.6740296359648963
Validation loss: 2.5101074026893713

Epoch: 6| Step: 8
Training loss: 2.7517138255942073
Validation loss: 2.508199068108438

Epoch: 6| Step: 9
Training loss: 2.905134417629771
Validation loss: 2.512283250788213

Epoch: 6| Step: 10
Training loss: 2.9293971210260623
Validation loss: 2.505327663752334

Epoch: 6| Step: 11
Training loss: 2.835906898186304
Validation loss: 2.5067657043235885

Epoch: 6| Step: 12
Training loss: 2.6502165543945213
Validation loss: 2.5164625673738015

Epoch: 6| Step: 13
Training loss: 2.914380258207345
Validation loss: 2.5286113233583247

Epoch: 227| Step: 0
Training loss: 2.913142736675985
Validation loss: 2.528663013120621

Epoch: 6| Step: 1
Training loss: 2.4903758768008224
Validation loss: 2.5493682830846516

Epoch: 6| Step: 2
Training loss: 2.6755759501533616
Validation loss: 2.5477755763869685

Epoch: 6| Step: 3
Training loss: 3.3100033834388243
Validation loss: 2.5664640070420144

Epoch: 6| Step: 4
Training loss: 2.8742613465495865
Validation loss: 2.6075349523975273

Epoch: 6| Step: 5
Training loss: 2.518637328550368
Validation loss: 2.577125488316347

Epoch: 6| Step: 6
Training loss: 3.0178571751031043
Validation loss: 2.557840586657858

Epoch: 6| Step: 7
Training loss: 2.32671984568962
Validation loss: 2.5588747417723754

Epoch: 6| Step: 8
Training loss: 2.960992576066759
Validation loss: 2.533208531180628

Epoch: 6| Step: 9
Training loss: 3.0514242005151067
Validation loss: 2.522135058196358

Epoch: 6| Step: 10
Training loss: 2.511483141347937
Validation loss: 2.5128160244773854

Epoch: 6| Step: 11
Training loss: 2.4070941385672993
Validation loss: 2.504881043965137

Epoch: 6| Step: 12
Training loss: 2.8163347169042923
Validation loss: 2.494501080569552

Epoch: 6| Step: 13
Training loss: 3.0907258945886738
Validation loss: 2.4996580761715372

Epoch: 228| Step: 0
Training loss: 2.8314489568400187
Validation loss: 2.502249132582729

Epoch: 6| Step: 1
Training loss: 2.5652853551602517
Validation loss: 2.4974239459460374

Epoch: 6| Step: 2
Training loss: 2.4521943288965424
Validation loss: 2.506637054981693

Epoch: 6| Step: 3
Training loss: 3.132446419881
Validation loss: 2.504180239480139

Epoch: 6| Step: 4
Training loss: 2.6678243349457826
Validation loss: 2.5007723558641164

Epoch: 6| Step: 5
Training loss: 2.570897740114241
Validation loss: 2.514135330470808

Epoch: 6| Step: 6
Training loss: 2.307490206084953
Validation loss: 2.5177462574255056

Epoch: 6| Step: 7
Training loss: 3.245621592936572
Validation loss: 2.5157037680743657

Epoch: 6| Step: 8
Training loss: 2.8293649895155775
Validation loss: 2.5156960558539065

Epoch: 6| Step: 9
Training loss: 2.8261413361666374
Validation loss: 2.508583462238973

Epoch: 6| Step: 10
Training loss: 3.1381416181478743
Validation loss: 2.4991385513896867

Epoch: 6| Step: 11
Training loss: 3.1712315099265114
Validation loss: 2.496806037420002

Epoch: 6| Step: 12
Training loss: 2.013884510020907
Validation loss: 2.503233921168486

Epoch: 6| Step: 13
Training loss: 3.3505986034717608
Validation loss: 2.5002577002820936

Epoch: 229| Step: 0
Training loss: 3.2591168104777064
Validation loss: 2.4982356685534475

Epoch: 6| Step: 1
Training loss: 2.009499045617379
Validation loss: 2.503106734122489

Epoch: 6| Step: 2
Training loss: 2.484915620534089
Validation loss: 2.511230891900709

Epoch: 6| Step: 3
Training loss: 3.2262879040045958
Validation loss: 2.5276120465941005

Epoch: 6| Step: 4
Training loss: 3.0743267035524675
Validation loss: 2.5189833382102673

Epoch: 6| Step: 5
Training loss: 2.742540820364792
Validation loss: 2.530259220417401

Epoch: 6| Step: 6
Training loss: 2.967298775384761
Validation loss: 2.532847579030223

Epoch: 6| Step: 7
Training loss: 2.4982658093441907
Validation loss: 2.5350580803662304

Epoch: 6| Step: 8
Training loss: 2.676285343996913
Validation loss: 2.531974382965481

Epoch: 6| Step: 9
Training loss: 2.874808263604763
Validation loss: 2.5485915702920203

Epoch: 6| Step: 10
Training loss: 2.153577613595749
Validation loss: 2.5553971872470624

Epoch: 6| Step: 11
Training loss: 2.517053328951318
Validation loss: 2.5541749758532464

Epoch: 6| Step: 12
Training loss: 2.8739351705567384
Validation loss: 2.5486897054862574

Epoch: 6| Step: 13
Training loss: 3.4982865090134494
Validation loss: 2.543378338996248

Epoch: 230| Step: 0
Training loss: 3.1779644020636373
Validation loss: 2.543591410196787

Epoch: 6| Step: 1
Training loss: 3.016021228118581
Validation loss: 2.5454760424310567

Epoch: 6| Step: 2
Training loss: 3.0253326233142452
Validation loss: 2.53380187085115

Epoch: 6| Step: 3
Training loss: 2.9496023976977632
Validation loss: 2.533220980937216

Epoch: 6| Step: 4
Training loss: 2.7587589876679286
Validation loss: 2.5410698126519873

Epoch: 6| Step: 5
Training loss: 2.8056979683547776
Validation loss: 2.5293731689349195

Epoch: 6| Step: 6
Training loss: 2.216086494795948
Validation loss: 2.5246033427117096

Epoch: 6| Step: 7
Training loss: 2.430615998984925
Validation loss: 2.5326349421331016

Epoch: 6| Step: 8
Training loss: 2.566727756004443
Validation loss: 2.5452129034637423

Epoch: 6| Step: 9
Training loss: 2.6402365494724918
Validation loss: 2.546216030796883

Epoch: 6| Step: 10
Training loss: 2.780644125792256
Validation loss: 2.5386840437293254

Epoch: 6| Step: 11
Training loss: 3.169151602732743
Validation loss: 2.5341711938785916

Epoch: 6| Step: 12
Training loss: 2.451009627971937
Validation loss: 2.5376480097764236

Epoch: 6| Step: 13
Training loss: 2.7319714254669414
Validation loss: 2.521241886067027

Epoch: 231| Step: 0
Training loss: 2.7210836808453434
Validation loss: 2.5213545061598133

Epoch: 6| Step: 1
Training loss: 2.9829235441900614
Validation loss: 2.50555706958934

Epoch: 6| Step: 2
Training loss: 2.6510561260036414
Validation loss: 2.5118798170611067

Epoch: 6| Step: 3
Training loss: 3.1954985846544837
Validation loss: 2.507049676582919

Epoch: 6| Step: 4
Training loss: 2.880594863386341
Validation loss: 2.5205590144529446

Epoch: 6| Step: 5
Training loss: 2.623792461398798
Validation loss: 2.5041701934556477

Epoch: 6| Step: 6
Training loss: 2.6088886835718084
Validation loss: 2.507015919184639

Epoch: 6| Step: 7
Training loss: 2.7471869559532114
Validation loss: 2.4953188590381217

Epoch: 6| Step: 8
Training loss: 2.0788976623977082
Validation loss: 2.489805072581174

Epoch: 6| Step: 9
Training loss: 2.453465723563641
Validation loss: 2.5078827171499616

Epoch: 6| Step: 10
Training loss: 3.111599687026705
Validation loss: 2.505392867047521

Epoch: 6| Step: 11
Training loss: 2.684914964718126
Validation loss: 2.5047647006943934

Epoch: 6| Step: 12
Training loss: 2.992749353152699
Validation loss: 2.5080109867413265

Epoch: 6| Step: 13
Training loss: 3.2239060076697434
Validation loss: 2.5259177942649353

Epoch: 232| Step: 0
Training loss: 2.5249208041320172
Validation loss: 2.541745510589762

Epoch: 6| Step: 1
Training loss: 2.6374980763794453
Validation loss: 2.5489863800001444

Epoch: 6| Step: 2
Training loss: 2.9056587848434625
Validation loss: 2.5399515412617117

Epoch: 6| Step: 3
Training loss: 2.9682584656818207
Validation loss: 2.556623756886189

Epoch: 6| Step: 4
Training loss: 1.9288455500888122
Validation loss: 2.533447191122544

Epoch: 6| Step: 5
Training loss: 3.3285539377525972
Validation loss: 2.523600688942927

Epoch: 6| Step: 6
Training loss: 2.903154426811555
Validation loss: 2.516991477215441

Epoch: 6| Step: 7
Training loss: 2.727419305966107
Validation loss: 2.507990992805505

Epoch: 6| Step: 8
Training loss: 2.7828902647621607
Validation loss: 2.510667283835134

Epoch: 6| Step: 9
Training loss: 3.1633363243654324
Validation loss: 2.510837700547668

Epoch: 6| Step: 10
Training loss: 2.5625786187741992
Validation loss: 2.5000276461477515

Epoch: 6| Step: 11
Training loss: 2.523895883410774
Validation loss: 2.497868370538872

Epoch: 6| Step: 12
Training loss: 3.2391836199861865
Validation loss: 2.496191283972894

Epoch: 6| Step: 13
Training loss: 2.2232101098971784
Validation loss: 2.4974163733408052

Epoch: 233| Step: 0
Training loss: 2.6847713724044584
Validation loss: 2.491440835422392

Epoch: 6| Step: 1
Training loss: 2.789023177353225
Validation loss: 2.50730551276055

Epoch: 6| Step: 2
Training loss: 3.144805100167893
Validation loss: 2.5071288326884416

Epoch: 6| Step: 3
Training loss: 2.7175023515650762
Validation loss: 2.520118855863605

Epoch: 6| Step: 4
Training loss: 3.0333729025247593
Validation loss: 2.523953195290334

Epoch: 6| Step: 5
Training loss: 2.9610239786287043
Validation loss: 2.5361059379961417

Epoch: 6| Step: 6
Training loss: 2.6820805043676783
Validation loss: 2.549503820066049

Epoch: 6| Step: 7
Training loss: 2.4276677902800827
Validation loss: 2.5525822483078024

Epoch: 6| Step: 8
Training loss: 2.4840056906618058
Validation loss: 2.569098394213353

Epoch: 6| Step: 9
Training loss: 2.8344882593374376
Validation loss: 2.591817492477157

Epoch: 6| Step: 10
Training loss: 2.9055210963244655
Validation loss: 2.588425927578753

Epoch: 6| Step: 11
Training loss: 2.388600208770071
Validation loss: 2.58015858435007

Epoch: 6| Step: 12
Training loss: 3.342678005183552
Validation loss: 2.556063954544926

Epoch: 6| Step: 13
Training loss: 2.4133237430564614
Validation loss: 2.5317704944133737

Epoch: 234| Step: 0
Training loss: 2.7250435431964926
Validation loss: 2.516344224812365

Epoch: 6| Step: 1
Training loss: 2.6516637365811326
Validation loss: 2.5045236873117482

Epoch: 6| Step: 2
Training loss: 2.9723193745961436
Validation loss: 2.503305038919919

Epoch: 6| Step: 3
Training loss: 1.8507607571202809
Validation loss: 2.50220800025694

Epoch: 6| Step: 4
Training loss: 3.052544117451746
Validation loss: 2.501642908661476

Epoch: 6| Step: 5
Training loss: 3.280752671109064
Validation loss: 2.512028928334433

Epoch: 6| Step: 6
Training loss: 3.2041131705062513
Validation loss: 2.5092086302241854

Epoch: 6| Step: 7
Training loss: 2.915482816673988
Validation loss: 2.5086729495209075

Epoch: 6| Step: 8
Training loss: 2.729444319794936
Validation loss: 2.4928030855347374

Epoch: 6| Step: 9
Training loss: 3.0221922525465748
Validation loss: 2.494440653173727

Epoch: 6| Step: 10
Training loss: 3.0536459783824816
Validation loss: 2.4896879856807477

Epoch: 6| Step: 11
Training loss: 2.35229561869557
Validation loss: 2.4946406416328877

Epoch: 6| Step: 12
Training loss: 2.2814473106023483
Validation loss: 2.4997782598622416

Epoch: 6| Step: 13
Training loss: 2.714495256409617
Validation loss: 2.5143366307870076

Epoch: 235| Step: 0
Training loss: 2.591699180112876
Validation loss: 2.513438525080083

Epoch: 6| Step: 1
Training loss: 2.325477477235879
Validation loss: 2.544510837806179

Epoch: 6| Step: 2
Training loss: 2.971562067638193
Validation loss: 2.5737287171432772

Epoch: 6| Step: 3
Training loss: 2.545067830558941
Validation loss: 2.575138810539377

Epoch: 6| Step: 4
Training loss: 2.7865976078961454
Validation loss: 2.6194560568433687

Epoch: 6| Step: 5
Training loss: 2.4418503502333166
Validation loss: 2.633825859369939

Epoch: 6| Step: 6
Training loss: 2.91631976289855
Validation loss: 2.6386571479801066

Epoch: 6| Step: 7
Training loss: 3.1113265924156615
Validation loss: 2.5702137500943407

Epoch: 6| Step: 8
Training loss: 3.02110101675773
Validation loss: 2.5657832184100413

Epoch: 6| Step: 9
Training loss: 3.313717312531074
Validation loss: 2.5552731032490517

Epoch: 6| Step: 10
Training loss: 2.294145272521578
Validation loss: 2.545079606847561

Epoch: 6| Step: 11
Training loss: 3.011260199365251
Validation loss: 2.550429237616019

Epoch: 6| Step: 12
Training loss: 2.84476964088349
Validation loss: 2.560843353642174

Epoch: 6| Step: 13
Training loss: 2.710289693600314
Validation loss: 2.565391396935346

Epoch: 236| Step: 0
Training loss: 2.8232028342228728
Validation loss: 2.5578136395503805

Epoch: 6| Step: 1
Training loss: 2.864524665000545
Validation loss: 2.5489204206152785

Epoch: 6| Step: 2
Training loss: 2.5499702788472165
Validation loss: 2.562493720198249

Epoch: 6| Step: 3
Training loss: 3.2281406044005867
Validation loss: 2.543085329385804

Epoch: 6| Step: 4
Training loss: 2.3889159033477556
Validation loss: 2.5407648122218682

Epoch: 6| Step: 5
Training loss: 2.102713344241325
Validation loss: 2.532025266983129

Epoch: 6| Step: 6
Training loss: 3.1982812497614534
Validation loss: 2.5411081176106034

Epoch: 6| Step: 7
Training loss: 2.847721554356651
Validation loss: 2.5329922693889695

Epoch: 6| Step: 8
Training loss: 1.9934467599273669
Validation loss: 2.5136765011659437

Epoch: 6| Step: 9
Training loss: 2.9676183852738265
Validation loss: 2.515607194449609

Epoch: 6| Step: 10
Training loss: 2.647646085258686
Validation loss: 2.5177046481980927

Epoch: 6| Step: 11
Training loss: 2.651837172749788
Validation loss: 2.51038047741636

Epoch: 6| Step: 12
Training loss: 3.2870028972096526
Validation loss: 2.5424790283606913

Epoch: 6| Step: 13
Training loss: 3.0453861609329054
Validation loss: 2.5371767786783472

Epoch: 237| Step: 0
Training loss: 2.9235831586800765
Validation loss: 2.5646247548605787

Epoch: 6| Step: 1
Training loss: 2.8306996128442767
Validation loss: 2.587255922211178

Epoch: 6| Step: 2
Training loss: 3.2367814551707994
Validation loss: 2.6087111803442444

Epoch: 6| Step: 3
Training loss: 2.5788719251232632
Validation loss: 2.570807272611668

Epoch: 6| Step: 4
Training loss: 2.628792883595303
Validation loss: 2.5230739439176824

Epoch: 6| Step: 5
Training loss: 2.214833846566263
Validation loss: 2.5013259007092503

Epoch: 6| Step: 6
Training loss: 2.850455793106532
Validation loss: 2.488614172800303

Epoch: 6| Step: 7
Training loss: 2.7539393213328967
Validation loss: 2.490662265331589

Epoch: 6| Step: 8
Training loss: 2.5881948155537438
Validation loss: 2.506512154731846

Epoch: 6| Step: 9
Training loss: 3.0413143180320734
Validation loss: 2.5179758131622343

Epoch: 6| Step: 10
Training loss: 2.9675026933614435
Validation loss: 2.5173367965442432

Epoch: 6| Step: 11
Training loss: 3.3639018940448886
Validation loss: 2.5128911528084794

Epoch: 6| Step: 12
Training loss: 2.5029466429756364
Validation loss: 2.5340048240333855

Epoch: 6| Step: 13
Training loss: 2.4331678382126363
Validation loss: 2.5252051337239707

Epoch: 238| Step: 0
Training loss: 2.53336217847096
Validation loss: 2.5340996535129405

Epoch: 6| Step: 1
Training loss: 3.015814582518357
Validation loss: 2.5335486136264485

Epoch: 6| Step: 2
Training loss: 2.548236038599397
Validation loss: 2.5463024658231137

Epoch: 6| Step: 3
Training loss: 2.930770633111068
Validation loss: 2.5534817204308737

Epoch: 6| Step: 4
Training loss: 2.9936357384779435
Validation loss: 2.557695760909464

Epoch: 6| Step: 5
Training loss: 2.6033784410946006
Validation loss: 2.5572390601779675

Epoch: 6| Step: 6
Training loss: 2.7821665764417887
Validation loss: 2.5610295240196645

Epoch: 6| Step: 7
Training loss: 2.2538643606646818
Validation loss: 2.5700579697784085

Epoch: 6| Step: 8
Training loss: 2.6161360265381055
Validation loss: 2.56346230954819

Epoch: 6| Step: 9
Training loss: 3.5183780995359135
Validation loss: 2.5830153197748498

Epoch: 6| Step: 10
Training loss: 2.997646362192938
Validation loss: 2.578508397167798

Epoch: 6| Step: 11
Training loss: 2.614195157804711
Validation loss: 2.5572210501424903

Epoch: 6| Step: 12
Training loss: 2.8719824836218044
Validation loss: 2.5482465608044214

Epoch: 6| Step: 13
Training loss: 2.6160558275104466
Validation loss: 2.538697505744334

Epoch: 239| Step: 0
Training loss: 2.68491345512954
Validation loss: 2.5406850623591684

Epoch: 6| Step: 1
Training loss: 3.2961213755619685
Validation loss: 2.5296906621174777

Epoch: 6| Step: 2
Training loss: 1.8318615409801762
Validation loss: 2.532998086425133

Epoch: 6| Step: 3
Training loss: 2.9555731419906106
Validation loss: 2.534061203158901

Epoch: 6| Step: 4
Training loss: 2.587071656970634
Validation loss: 2.5220290090576163

Epoch: 6| Step: 5
Training loss: 2.593441220942861
Validation loss: 2.5390985604652774

Epoch: 6| Step: 6
Training loss: 3.1158557618905034
Validation loss: 2.534578566320655

Epoch: 6| Step: 7
Training loss: 3.0351996105734775
Validation loss: 2.5340389826814627

Epoch: 6| Step: 8
Training loss: 2.8472262085263846
Validation loss: 2.5413438658247096

Epoch: 6| Step: 9
Training loss: 3.2769343014680192
Validation loss: 2.5330947439256772

Epoch: 6| Step: 10
Training loss: 2.773113392979058
Validation loss: 2.528306234503038

Epoch: 6| Step: 11
Training loss: 2.298456387212082
Validation loss: 2.5269288653525037

Epoch: 6| Step: 12
Training loss: 2.5729088931152866
Validation loss: 2.5218067142510434

Epoch: 6| Step: 13
Training loss: 2.7752700124434333
Validation loss: 2.523005184963503

Epoch: 240| Step: 0
Training loss: 2.1111460844567325
Validation loss: 2.5163834939855914

Epoch: 6| Step: 1
Training loss: 3.222408992645308
Validation loss: 2.521608343529256

Epoch: 6| Step: 2
Training loss: 3.384546976131751
Validation loss: 2.5252804650252316

Epoch: 6| Step: 3
Training loss: 2.5037658937723934
Validation loss: 2.521785235669951

Epoch: 6| Step: 4
Training loss: 2.5542981145575445
Validation loss: 2.5107170364061377

Epoch: 6| Step: 5
Training loss: 3.026919073035655
Validation loss: 2.523979193128196

Epoch: 6| Step: 6
Training loss: 2.8592102336834886
Validation loss: 2.5136187662906226

Epoch: 6| Step: 7
Training loss: 2.859442704863565
Validation loss: 2.5153621311278833

Epoch: 6| Step: 8
Training loss: 2.720814589649578
Validation loss: 2.5199927641603077

Epoch: 6| Step: 9
Training loss: 2.027473225069876
Validation loss: 2.5309678799966573

Epoch: 6| Step: 10
Training loss: 2.733959580608923
Validation loss: 2.5411102594347694

Epoch: 6| Step: 11
Training loss: 2.788232845571375
Validation loss: 2.5384377149273405

Epoch: 6| Step: 12
Training loss: 2.2651803468226523
Validation loss: 2.5335403769308575

Epoch: 6| Step: 13
Training loss: 3.6966795378708297
Validation loss: 2.537872072748237

Epoch: 241| Step: 0
Training loss: 2.6169584714971172
Validation loss: 2.5164295403730303

Epoch: 6| Step: 1
Training loss: 3.0066147041764624
Validation loss: 2.5170276654575585

Epoch: 6| Step: 2
Training loss: 2.9365965082777716
Validation loss: 2.510206867761891

Epoch: 6| Step: 3
Training loss: 2.7017544485708385
Validation loss: 2.515273289522564

Epoch: 6| Step: 4
Training loss: 3.0351402252834694
Validation loss: 2.50716549867565

Epoch: 6| Step: 5
Training loss: 2.579400504198518
Validation loss: 2.5053336069298933

Epoch: 6| Step: 6
Training loss: 2.357669643475547
Validation loss: 2.509548011609899

Epoch: 6| Step: 7
Training loss: 2.7441143862735777
Validation loss: 2.51448736528551

Epoch: 6| Step: 8
Training loss: 2.468958978620413
Validation loss: 2.527954417301397

Epoch: 6| Step: 9
Training loss: 2.8710673428313647
Validation loss: 2.518880902791614

Epoch: 6| Step: 10
Training loss: 3.0995183016708543
Validation loss: 2.5222272155763727

Epoch: 6| Step: 11
Training loss: 3.0291103401526702
Validation loss: 2.5257200600677945

Epoch: 6| Step: 12
Training loss: 2.3139964236575543
Validation loss: 2.5111667896255208

Epoch: 6| Step: 13
Training loss: 2.6651788872661344
Validation loss: 2.524840309115424

Epoch: 242| Step: 0
Training loss: 2.402914832242192
Validation loss: 2.514339835416525

Epoch: 6| Step: 1
Training loss: 2.7131896763887067
Validation loss: 2.522213759164238

Epoch: 6| Step: 2
Training loss: 3.6482939926775138
Validation loss: 2.5307586924354637

Epoch: 6| Step: 3
Training loss: 2.135034207465332
Validation loss: 2.5451177074165767

Epoch: 6| Step: 4
Training loss: 2.898536865505312
Validation loss: 2.557134225254925

Epoch: 6| Step: 5
Training loss: 2.6186047716316807
Validation loss: 2.5535562014943527

Epoch: 6| Step: 6
Training loss: 3.1418114693727297
Validation loss: 2.56603290357468

Epoch: 6| Step: 7
Training loss: 3.0056239501291313
Validation loss: 2.53874525285875

Epoch: 6| Step: 8
Training loss: 2.678475776054388
Validation loss: 2.5421944202609983

Epoch: 6| Step: 9
Training loss: 2.507985522044372
Validation loss: 2.5346096768081274

Epoch: 6| Step: 10
Training loss: 2.8689298818535436
Validation loss: 2.536781406355483

Epoch: 6| Step: 11
Training loss: 2.602077856941253
Validation loss: 2.527330767151596

Epoch: 6| Step: 12
Training loss: 2.5091273583464893
Validation loss: 2.5243302354822363

Epoch: 6| Step: 13
Training loss: 2.7030989805523826
Validation loss: 2.5217374932566354

Epoch: 243| Step: 0
Training loss: 2.818292375113181
Validation loss: 2.523045974175814

Epoch: 6| Step: 1
Training loss: 2.6961816243365195
Validation loss: 2.5332670835674027

Epoch: 6| Step: 2
Training loss: 2.848683029532521
Validation loss: 2.5278741983884063

Epoch: 6| Step: 3
Training loss: 2.4849616743544063
Validation loss: 2.5328522582299544

Epoch: 6| Step: 4
Training loss: 2.8931242165242006
Validation loss: 2.53060746630823

Epoch: 6| Step: 5
Training loss: 2.0175023761721094
Validation loss: 2.526545747411259

Epoch: 6| Step: 6
Training loss: 3.176664297684076
Validation loss: 2.518484252819675

Epoch: 6| Step: 7
Training loss: 2.7096604739119283
Validation loss: 2.5136723869791013

Epoch: 6| Step: 8
Training loss: 2.7440447916150883
Validation loss: 2.501749872179079

Epoch: 6| Step: 9
Training loss: 2.5082575798212905
Validation loss: 2.501186934063069

Epoch: 6| Step: 10
Training loss: 3.1102229356743427
Validation loss: 2.4985392394423247

Epoch: 6| Step: 11
Training loss: 2.266350149981096
Validation loss: 2.4968699518855226

Epoch: 6| Step: 12
Training loss: 3.5438657926718564
Validation loss: 2.507116414926509

Epoch: 6| Step: 13
Training loss: 2.2509512479935023
Validation loss: 2.5088719138459585

Epoch: 244| Step: 0
Training loss: 3.1249865722367764
Validation loss: 2.515163990076703

Epoch: 6| Step: 1
Training loss: 2.7954416704691956
Validation loss: 2.5188885971187185

Epoch: 6| Step: 2
Training loss: 2.0580043926284817
Validation loss: 2.510858823527606

Epoch: 6| Step: 3
Training loss: 2.758746715659506
Validation loss: 2.5038930155961845

Epoch: 6| Step: 4
Training loss: 2.856778325940683
Validation loss: 2.5201950024390625

Epoch: 6| Step: 5
Training loss: 2.7283190995740108
Validation loss: 2.530456376525216

Epoch: 6| Step: 6
Training loss: 2.7084525644515685
Validation loss: 2.5212859219763444

Epoch: 6| Step: 7
Training loss: 3.0035443032104014
Validation loss: 2.515212571252335

Epoch: 6| Step: 8
Training loss: 2.691782090474881
Validation loss: 2.5265669440305096

Epoch: 6| Step: 9
Training loss: 2.9978170399992825
Validation loss: 2.509217392247175

Epoch: 6| Step: 10
Training loss: 3.030718255349802
Validation loss: 2.509479111905472

Epoch: 6| Step: 11
Training loss: 2.909708242046444
Validation loss: 2.5118351651339172

Epoch: 6| Step: 12
Training loss: 2.263369470100897
Validation loss: 2.5180395155692494

Epoch: 6| Step: 13
Training loss: 1.8958529237286958
Validation loss: 2.5167175439675056

Epoch: 245| Step: 0
Training loss: 3.3050096864313097
Validation loss: 2.5256102179643873

Epoch: 6| Step: 1
Training loss: 2.7762163881399546
Validation loss: 2.520264451440174

Epoch: 6| Step: 2
Training loss: 2.9367679738970396
Validation loss: 2.5262279827865393

Epoch: 6| Step: 3
Training loss: 2.627956088304537
Validation loss: 2.5335803833426254

Epoch: 6| Step: 4
Training loss: 2.3736747256492485
Validation loss: 2.524159615549468

Epoch: 6| Step: 5
Training loss: 3.2116460830459106
Validation loss: 2.524156438621628

Epoch: 6| Step: 6
Training loss: 2.324806869853214
Validation loss: 2.5289153870198398

Epoch: 6| Step: 7
Training loss: 1.9660107159870661
Validation loss: 2.514784319661335

Epoch: 6| Step: 8
Training loss: 3.420551758366629
Validation loss: 2.5095037523610384

Epoch: 6| Step: 9
Training loss: 2.622217792931101
Validation loss: 2.506966495046715

Epoch: 6| Step: 10
Training loss: 2.843173964291166
Validation loss: 2.5124403940206674

Epoch: 6| Step: 11
Training loss: 2.4819035743100195
Validation loss: 2.5169033419515316

Epoch: 6| Step: 12
Training loss: 2.4223009288708424
Validation loss: 2.499190996900406

Epoch: 6| Step: 13
Training loss: 2.803381060384132
Validation loss: 2.505492460958633

Epoch: 246| Step: 0
Training loss: 2.455495964188348
Validation loss: 2.5129837736448764

Epoch: 6| Step: 1
Training loss: 3.363073539744266
Validation loss: 2.522947039661465

Epoch: 6| Step: 2
Training loss: 2.3635179133179225
Validation loss: 2.5342590422033853

Epoch: 6| Step: 3
Training loss: 2.201184222805318
Validation loss: 2.5287787303233573

Epoch: 6| Step: 4
Training loss: 3.0732805112104455
Validation loss: 2.55340837272734

Epoch: 6| Step: 5
Training loss: 2.9374334449533106
Validation loss: 2.5580029849283297

Epoch: 6| Step: 6
Training loss: 2.6979453675696217
Validation loss: 2.5633135668866713

Epoch: 6| Step: 7
Training loss: 2.7675506439675224
Validation loss: 2.5787386156850185

Epoch: 6| Step: 8
Training loss: 3.060923579341591
Validation loss: 2.576793576698692

Epoch: 6| Step: 9
Training loss: 2.4606474205896687
Validation loss: 2.5598794156321696

Epoch: 6| Step: 10
Training loss: 2.5051630112532917
Validation loss: 2.5665025243330586

Epoch: 6| Step: 11
Training loss: 3.0332504435801213
Validation loss: 2.5626927295062396

Epoch: 6| Step: 12
Training loss: 3.166660777304008
Validation loss: 2.549467600080455

Epoch: 6| Step: 13
Training loss: 2.521451658809346
Validation loss: 2.545666621690491

Epoch: 247| Step: 0
Training loss: 1.962206486906123
Validation loss: 2.5449179060168734

Epoch: 6| Step: 1
Training loss: 2.9084767660570794
Validation loss: 2.532462897584737

Epoch: 6| Step: 2
Training loss: 3.3023439579267144
Validation loss: 2.527814029236981

Epoch: 6| Step: 3
Training loss: 2.5790771575662825
Validation loss: 2.5348973022767636

Epoch: 6| Step: 4
Training loss: 3.089261584892509
Validation loss: 2.53008127722618

Epoch: 6| Step: 5
Training loss: 2.7693062974745457
Validation loss: 2.542055767608469

Epoch: 6| Step: 6
Training loss: 3.0559812962024586
Validation loss: 2.5300952632724805

Epoch: 6| Step: 7
Training loss: 3.024061665930539
Validation loss: 2.5364634448591197

Epoch: 6| Step: 8
Training loss: 2.780197115709112
Validation loss: 2.532771277401086

Epoch: 6| Step: 9
Training loss: 3.209657734244587
Validation loss: 2.5336486499007855

Epoch: 6| Step: 10
Training loss: 2.642296978415476
Validation loss: 2.5366998485784182

Epoch: 6| Step: 11
Training loss: 2.3084940880759035
Validation loss: 2.530354299690774

Epoch: 6| Step: 12
Training loss: 2.5864039804189054
Validation loss: 2.5321633673469077

Epoch: 6| Step: 13
Training loss: 2.317192883269834
Validation loss: 2.5288751952963504

Epoch: 248| Step: 0
Training loss: 3.0194282859628023
Validation loss: 2.531988582317459

Epoch: 6| Step: 1
Training loss: 2.530560246433117
Validation loss: 2.5214643852119094

Epoch: 6| Step: 2
Training loss: 3.4669883309809686
Validation loss: 2.533520556133977

Epoch: 6| Step: 3
Training loss: 2.316018598004185
Validation loss: 2.5244554027183237

Epoch: 6| Step: 4
Training loss: 3.3549372259825074
Validation loss: 2.520041566593186

Epoch: 6| Step: 5
Training loss: 2.737482713618634
Validation loss: 2.5230101669261646

Epoch: 6| Step: 6
Training loss: 2.870342296431149
Validation loss: 2.5252659416687555

Epoch: 6| Step: 7
Training loss: 2.694364607721691
Validation loss: 2.5279839238669033

Epoch: 6| Step: 8
Training loss: 2.3434309678699465
Validation loss: 2.5364623189228057

Epoch: 6| Step: 9
Training loss: 2.6779229496304997
Validation loss: 2.541176374630997

Epoch: 6| Step: 10
Training loss: 2.806320012839828
Validation loss: 2.5594048053798386

Epoch: 6| Step: 11
Training loss: 2.7441259417701027
Validation loss: 2.573843337542703

Epoch: 6| Step: 12
Training loss: 2.2766369725641793
Validation loss: 2.577108063910209

Epoch: 6| Step: 13
Training loss: 2.512291446969113
Validation loss: 2.5910078340413394

Epoch: 249| Step: 0
Training loss: 2.3895677210711574
Validation loss: 2.58471912510811

Epoch: 6| Step: 1
Training loss: 2.7220196410682056
Validation loss: 2.58397232261324

Epoch: 6| Step: 2
Training loss: 2.5055859149673383
Validation loss: 2.580694264411355

Epoch: 6| Step: 3
Training loss: 2.3838440710188324
Validation loss: 2.5686224103525963

Epoch: 6| Step: 4
Training loss: 2.879903840472993
Validation loss: 2.5583586564059506

Epoch: 6| Step: 5
Training loss: 1.8063348294834027
Validation loss: 2.545144259121615

Epoch: 6| Step: 6
Training loss: 2.876645819572623
Validation loss: 2.545139796923478

Epoch: 6| Step: 7
Training loss: 3.092100532160746
Validation loss: 2.521979326150145

Epoch: 6| Step: 8
Training loss: 3.3470200565080264
Validation loss: 2.5315920123841353

Epoch: 6| Step: 9
Training loss: 3.024989949359433
Validation loss: 2.530843043963093

Epoch: 6| Step: 10
Training loss: 3.514497160670129
Validation loss: 2.5320648052729413

Epoch: 6| Step: 11
Training loss: 2.585021902762615
Validation loss: 2.54220337314096

Epoch: 6| Step: 12
Training loss: 2.222539110901607
Validation loss: 2.5494449316583214

Epoch: 6| Step: 13
Training loss: 2.8369601168809107
Validation loss: 2.551490964736315

Epoch: 250| Step: 0
Training loss: 3.17722114305796
Validation loss: 2.5625711016491253

Epoch: 6| Step: 1
Training loss: 2.40685769866613
Validation loss: 2.5872062889336727

Epoch: 6| Step: 2
Training loss: 2.555482793085411
Validation loss: 2.592899205210885

Epoch: 6| Step: 3
Training loss: 2.718649939087872
Validation loss: 2.596659041493349

Epoch: 6| Step: 4
Training loss: 3.0569717959075318
Validation loss: 2.6006027531106466

Epoch: 6| Step: 5
Training loss: 3.001629228063672
Validation loss: 2.608289478466303

Epoch: 6| Step: 6
Training loss: 3.212501163705103
Validation loss: 2.590171321940919

Epoch: 6| Step: 7
Training loss: 2.8714737206049787
Validation loss: 2.5552606475643653

Epoch: 6| Step: 8
Training loss: 2.2170663812633626
Validation loss: 2.5415811838682436

Epoch: 6| Step: 9
Training loss: 2.4013943913033127
Validation loss: 2.5529085882199096

Epoch: 6| Step: 10
Training loss: 2.829631088259049
Validation loss: 2.5603644463572226

Epoch: 6| Step: 11
Training loss: 2.583156784751823
Validation loss: 2.562645351550453

Epoch: 6| Step: 12
Training loss: 2.85989158424882
Validation loss: 2.564925439801528

Epoch: 6| Step: 13
Training loss: 3.007652694618398
Validation loss: 2.5346607172882485

Testing loss: 2.722352727910376
