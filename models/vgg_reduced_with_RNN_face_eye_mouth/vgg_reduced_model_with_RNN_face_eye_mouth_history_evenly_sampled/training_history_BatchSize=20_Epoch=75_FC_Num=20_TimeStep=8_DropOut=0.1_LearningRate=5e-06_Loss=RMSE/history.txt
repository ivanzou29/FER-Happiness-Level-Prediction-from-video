Epoch: 1| Step: 0
Training loss: 4.593154764861481
Validation loss: 5.795855931296029

Epoch: 5| Step: 1
Training loss: 6.790608922427614
Validation loss: 5.791527921806425

Epoch: 5| Step: 2
Training loss: 5.445801109601947
Validation loss: 5.787753438263087

Epoch: 5| Step: 3
Training loss: 7.118906728410796
Validation loss: 5.783989579308583

Epoch: 5| Step: 4
Training loss: 6.191666866557485
Validation loss: 5.780683225050525

Epoch: 5| Step: 5
Training loss: 5.956149396817295
Validation loss: 5.776953832831451

Epoch: 5| Step: 6
Training loss: 5.210775530126606
Validation loss: 5.773512041501929

Epoch: 5| Step: 7
Training loss: 5.061717408526408
Validation loss: 5.770372227132455

Epoch: 5| Step: 8
Training loss: 4.115660990656865
Validation loss: 5.766852953423059

Epoch: 5| Step: 9
Training loss: 6.342021236791936
Validation loss: 5.763563253758088

Epoch: 5| Step: 10
Training loss: 6.449025031634052
Validation loss: 5.76002716733708

Epoch: 2| Step: 0
Training loss: 5.356816607032291
Validation loss: 5.7564881766231

Epoch: 5| Step: 1
Training loss: 5.919805240520448
Validation loss: 5.753158073029221

Epoch: 5| Step: 2
Training loss: 6.087878092904971
Validation loss: 5.748897992609537

Epoch: 5| Step: 3
Training loss: 5.110318064784872
Validation loss: 5.744538697717848

Epoch: 5| Step: 4
Training loss: 6.7120651700990095
Validation loss: 5.740635362330484

Epoch: 5| Step: 5
Training loss: 5.414625614711081
Validation loss: 5.7359115617653735

Epoch: 5| Step: 6
Training loss: 4.723158841962774
Validation loss: 5.731490502426488

Epoch: 5| Step: 7
Training loss: 5.7601282232635675
Validation loss: 5.726643722050622

Epoch: 5| Step: 8
Training loss: 6.0415690797838915
Validation loss: 5.721338158137932

Epoch: 5| Step: 9
Training loss: 6.865921407212547
Validation loss: 5.7162790252717945

Epoch: 5| Step: 10
Training loss: 4.9582331457621445
Validation loss: 5.7104000460774405

Epoch: 3| Step: 0
Training loss: 5.812079957941047
Validation loss: 5.704727745531542

Epoch: 5| Step: 1
Training loss: 5.188942214688177
Validation loss: 5.698151090067591

Epoch: 5| Step: 2
Training loss: 6.170892178471465
Validation loss: 5.692388547424105

Epoch: 5| Step: 3
Training loss: 5.831144558033993
Validation loss: 5.684976899097961

Epoch: 5| Step: 4
Training loss: 5.03756904649389
Validation loss: 5.677351808216076

Epoch: 5| Step: 5
Training loss: 5.696934849628193
Validation loss: 5.670192480591231

Epoch: 5| Step: 6
Training loss: 6.2147860521363185
Validation loss: 5.661840335522533

Epoch: 5| Step: 7
Training loss: 5.670671655880685
Validation loss: 5.653935999455936

Epoch: 5| Step: 8
Training loss: 5.7062217352377065
Validation loss: 5.645028516670005

Epoch: 5| Step: 9
Training loss: 5.220102466147583
Validation loss: 5.635771175721524

Epoch: 5| Step: 10
Training loss: 6.140827204745703
Validation loss: 5.6253524505781405

Epoch: 4| Step: 0
Training loss: 5.600433278352081
Validation loss: 5.615294065981241

Epoch: 5| Step: 1
Training loss: 5.50090539589262
Validation loss: 5.604636581316165

Epoch: 5| Step: 2
Training loss: 5.180109297435144
Validation loss: 5.592800950586567

Epoch: 5| Step: 3
Training loss: 6.0914208289071405
Validation loss: 5.58091786932393

Epoch: 5| Step: 4
Training loss: 5.414923793436127
Validation loss: 5.568260960255536

Epoch: 5| Step: 5
Training loss: 6.514802363948472
Validation loss: 5.554630510300834

Epoch: 5| Step: 6
Training loss: 5.423534304305227
Validation loss: 5.541141083847426

Epoch: 5| Step: 7
Training loss: 5.066980522038522
Validation loss: 5.527172456524521

Epoch: 5| Step: 8
Training loss: 4.424823115202469
Validation loss: 5.511799043090451

Epoch: 5| Step: 9
Training loss: 5.919710191386061
Validation loss: 5.49592993110417

Epoch: 5| Step: 10
Training loss: 6.175933816703413
Validation loss: 5.4802548535730375

Epoch: 5| Step: 0
Training loss: 5.981015051489385
Validation loss: 5.464522499930374

Epoch: 5| Step: 1
Training loss: 5.881072132692443
Validation loss: 5.44633752974882

Epoch: 5| Step: 2
Training loss: 4.869104586459091
Validation loss: 5.427439086104884

Epoch: 5| Step: 3
Training loss: 3.670647598630923
Validation loss: 5.40863608120887

Epoch: 5| Step: 4
Training loss: 5.707050299955372
Validation loss: 5.391006773415436

Epoch: 5| Step: 5
Training loss: 5.609171829157027
Validation loss: 5.37121112713876

Epoch: 5| Step: 6
Training loss: 6.003807131582608
Validation loss: 5.35125825928974

Epoch: 5| Step: 7
Training loss: 5.851650507307145
Validation loss: 5.3309731580738235

Epoch: 5| Step: 8
Training loss: 4.594618111930786
Validation loss: 5.30972678411347

Epoch: 5| Step: 9
Training loss: 5.636990461984645
Validation loss: 5.288147282206002

Epoch: 5| Step: 10
Training loss: 5.28783137588464
Validation loss: 5.268013036160708

Epoch: 6| Step: 0
Training loss: 5.522387630067157
Validation loss: 5.246346704152835

Epoch: 5| Step: 1
Training loss: 5.139627562807932
Validation loss: 5.223988905458473

Epoch: 5| Step: 2
Training loss: 6.605138119589735
Validation loss: 5.203198845136785

Epoch: 5| Step: 3
Training loss: 5.101607925656775
Validation loss: 5.180244696586399

Epoch: 5| Step: 4
Training loss: 5.814067998246359
Validation loss: 5.158405585991247

Epoch: 5| Step: 5
Training loss: 3.957377562662162
Validation loss: 5.1367865787031235

Epoch: 5| Step: 6
Training loss: 5.869917598841359
Validation loss: 5.115970479688115

Epoch: 5| Step: 7
Training loss: 4.646458924373341
Validation loss: 5.095234537629274

Epoch: 5| Step: 8
Training loss: 5.618496674628588
Validation loss: 5.07413275329409

Epoch: 5| Step: 9
Training loss: 4.1778708815064
Validation loss: 5.052623891460289

Epoch: 5| Step: 10
Training loss: 3.9053225217282965
Validation loss: 5.0324697481536615

Epoch: 7| Step: 0
Training loss: 5.629666067353127
Validation loss: 5.013206035856335

Epoch: 5| Step: 1
Training loss: 5.763028849995366
Validation loss: 4.99330244744614

Epoch: 5| Step: 2
Training loss: 4.964092639018713
Validation loss: 4.974139440514684

Epoch: 5| Step: 3
Training loss: 4.697078835943086
Validation loss: 4.95446203002618

Epoch: 5| Step: 4
Training loss: 4.599668051310983
Validation loss: 4.935482520046233

Epoch: 5| Step: 5
Training loss: 4.930715607864608
Validation loss: 4.913182954528253

Epoch: 5| Step: 6
Training loss: 6.0495230620739395
Validation loss: 4.89383817962161

Epoch: 5| Step: 7
Training loss: 4.63354095341433
Validation loss: 4.87272595211058

Epoch: 5| Step: 8
Training loss: 3.6893144443149275
Validation loss: 4.851717898157381

Epoch: 5| Step: 9
Training loss: 4.725879664002545
Validation loss: 4.834177859268632

Epoch: 5| Step: 10
Training loss: 4.759832144590577
Validation loss: 4.813316477316362

Epoch: 8| Step: 0
Training loss: 5.0299730279703665
Validation loss: 4.791992464621865

Epoch: 5| Step: 1
Training loss: 4.534707480084205
Validation loss: 4.771158778583607

Epoch: 5| Step: 2
Training loss: 5.90998036286114
Validation loss: 4.749282992207216

Epoch: 5| Step: 3
Training loss: 4.964217319781887
Validation loss: 4.725734460325672

Epoch: 5| Step: 4
Training loss: 4.374701353506665
Validation loss: 4.699508375883225

Epoch: 5| Step: 5
Training loss: 4.847385936888312
Validation loss: 4.673124307576337

Epoch: 5| Step: 6
Training loss: 3.5253173144212706
Validation loss: 4.647522247649012

Epoch: 5| Step: 7
Training loss: 4.2425536951321074
Validation loss: 4.624064252445237

Epoch: 5| Step: 8
Training loss: 4.058914715262134
Validation loss: 4.6025098675090135

Epoch: 5| Step: 9
Training loss: 4.423578480124911
Validation loss: 4.58126459763891

Epoch: 5| Step: 10
Training loss: 6.150528626091508
Validation loss: 4.560406244773733

Epoch: 9| Step: 0
Training loss: 5.022099104547177
Validation loss: 4.537309023505707

Epoch: 5| Step: 1
Training loss: 4.105577694275843
Validation loss: 4.5182250742018875

Epoch: 5| Step: 2
Training loss: 4.996050991802957
Validation loss: 4.498515635135763

Epoch: 5| Step: 3
Training loss: 4.7787957967429175
Validation loss: 4.476825819972356

Epoch: 5| Step: 4
Training loss: 3.9738502471077077
Validation loss: 4.455614194408347

Epoch: 5| Step: 5
Training loss: 4.745262393429379
Validation loss: 4.439886412493768

Epoch: 5| Step: 6
Training loss: 4.817433788278087
Validation loss: 4.420920875757837

Epoch: 5| Step: 7
Training loss: 4.5508569015305245
Validation loss: 4.403887399604751

Epoch: 5| Step: 8
Training loss: 4.654958251372561
Validation loss: 4.387666564683485

Epoch: 5| Step: 9
Training loss: 3.654392781469628
Validation loss: 4.369876244991102

Epoch: 5| Step: 10
Training loss: 4.547449449255073
Validation loss: 4.3577282334570215

Epoch: 10| Step: 0
Training loss: 4.3049263169632095
Validation loss: 4.342938834693134

Epoch: 5| Step: 1
Training loss: 3.4649376066240865
Validation loss: 4.32947902660928

Epoch: 5| Step: 2
Training loss: 3.866134099348535
Validation loss: 4.317859883855402

Epoch: 5| Step: 3
Training loss: 4.779435954313211
Validation loss: 4.304454330169072

Epoch: 5| Step: 4
Training loss: 4.461342387355716
Validation loss: 4.294773302723975

Epoch: 5| Step: 5
Training loss: 4.0337289684446
Validation loss: 4.28330893244847

Epoch: 5| Step: 6
Training loss: 5.317529250021019
Validation loss: 4.269439879725456

Epoch: 5| Step: 7
Training loss: 4.503428742371979
Validation loss: 4.257613325771214

Epoch: 5| Step: 8
Training loss: 4.7091974236334435
Validation loss: 4.24688397520621

Epoch: 5| Step: 9
Training loss: 4.30101584921575
Validation loss: 4.236037342261462

Epoch: 5| Step: 10
Training loss: 4.40459156615276
Validation loss: 4.222021586759192

Epoch: 11| Step: 0
Training loss: 4.863072402330405
Validation loss: 4.2108200598397785

Epoch: 5| Step: 1
Training loss: 4.020708836553555
Validation loss: 4.199323569818914

Epoch: 5| Step: 2
Training loss: 3.4758025635374286
Validation loss: 4.188855912396176

Epoch: 5| Step: 3
Training loss: 4.175032545865146
Validation loss: 4.177735334738733

Epoch: 5| Step: 4
Training loss: 4.501826445479084
Validation loss: 4.1668896662606265

Epoch: 5| Step: 5
Training loss: 4.804397499822815
Validation loss: 4.155156275000942

Epoch: 5| Step: 6
Training loss: 4.8244674309639235
Validation loss: 4.141606523142263

Epoch: 5| Step: 7
Training loss: 3.8511934238972008
Validation loss: 4.130775860300255

Epoch: 5| Step: 8
Training loss: 4.120692460468236
Validation loss: 4.118541664743836

Epoch: 5| Step: 9
Training loss: 4.249124549008113
Validation loss: 4.107119817279977

Epoch: 5| Step: 10
Training loss: 4.036161520925302
Validation loss: 4.092607243639842

Epoch: 12| Step: 0
Training loss: 4.123848263025685
Validation loss: 4.079001596234738

Epoch: 5| Step: 1
Training loss: 4.090919506175337
Validation loss: 4.064373165708349

Epoch: 5| Step: 2
Training loss: 2.9720148705460865
Validation loss: 4.050624354567498

Epoch: 5| Step: 3
Training loss: 3.7756571115695223
Validation loss: 4.036814749784331

Epoch: 5| Step: 4
Training loss: 5.359383541356167
Validation loss: 4.024690376631947

Epoch: 5| Step: 5
Training loss: 3.2605551465803493
Validation loss: 4.011254214067347

Epoch: 5| Step: 6
Training loss: 4.101489489677567
Validation loss: 3.996424950104558

Epoch: 5| Step: 7
Training loss: 4.143557104163507
Validation loss: 3.985044068265631

Epoch: 5| Step: 8
Training loss: 3.876169089881721
Validation loss: 3.973329896952923

Epoch: 5| Step: 9
Training loss: 4.773022522814647
Validation loss: 3.960804582458523

Epoch: 5| Step: 10
Training loss: 4.783078112201074
Validation loss: 3.9504228953553375

Epoch: 13| Step: 0
Training loss: 4.398685536412234
Validation loss: 3.940776488487141

Epoch: 5| Step: 1
Training loss: 3.955187594935645
Validation loss: 3.9290327687416973

Epoch: 5| Step: 2
Training loss: 3.867754407232068
Validation loss: 3.917205497700059

Epoch: 5| Step: 3
Training loss: 3.4502435460027163
Validation loss: 3.909446979880854

Epoch: 5| Step: 4
Training loss: 4.2746937246086985
Validation loss: 3.9009584639007193

Epoch: 5| Step: 5
Training loss: 3.644711276368258
Validation loss: 3.891393203562453

Epoch: 5| Step: 6
Training loss: 3.6127815849618763
Validation loss: 3.881962076919844

Epoch: 5| Step: 7
Training loss: 3.658895595039961
Validation loss: 3.8717502326954483

Epoch: 5| Step: 8
Training loss: 5.097194326233762
Validation loss: 3.8641491647091804

Epoch: 5| Step: 9
Training loss: 4.231429197948487
Validation loss: 3.855047838384988

Epoch: 5| Step: 10
Training loss: 4.128056636362634
Validation loss: 3.847921100348315

Epoch: 14| Step: 0
Training loss: 4.017996121379524
Validation loss: 3.839779511628147

Epoch: 5| Step: 1
Training loss: 4.68647327622796
Validation loss: 3.829933043232295

Epoch: 5| Step: 2
Training loss: 3.102251029280099
Validation loss: 3.8223855759915524

Epoch: 5| Step: 3
Training loss: 3.7083735231657684
Validation loss: 3.8149208184663634

Epoch: 5| Step: 4
Training loss: 3.5198631680509624
Validation loss: 3.8068486002410267

Epoch: 5| Step: 5
Training loss: 3.8281614963582333
Validation loss: 3.79928541928956

Epoch: 5| Step: 6
Training loss: 4.661225598313081
Validation loss: 3.794823927812277

Epoch: 5| Step: 7
Training loss: 4.658786978609405
Validation loss: 3.7858040434995233

Epoch: 5| Step: 8
Training loss: 3.889414894013422
Validation loss: 3.7768528605505005

Epoch: 5| Step: 9
Training loss: 3.584072184721308
Validation loss: 3.771772709659178

Epoch: 5| Step: 10
Training loss: 3.6648005736504827
Validation loss: 3.764709462117231

Epoch: 15| Step: 0
Training loss: 4.0346490295623045
Validation loss: 3.758172927560957

Epoch: 5| Step: 1
Training loss: 3.838481486800701
Validation loss: 3.752051715777172

Epoch: 5| Step: 2
Training loss: 4.180928782168788
Validation loss: 3.7464760428262593

Epoch: 5| Step: 3
Training loss: 4.4753970348321905
Validation loss: 3.743239386873387

Epoch: 5| Step: 4
Training loss: 3.8297252813473213
Validation loss: 3.7327818999096904

Epoch: 5| Step: 5
Training loss: 3.8512825699728728
Validation loss: 3.7294601093074777

Epoch: 5| Step: 6
Training loss: 4.044823085843974
Validation loss: 3.7247589005773687

Epoch: 5| Step: 7
Training loss: 3.657938510267424
Validation loss: 3.7217910009495334

Epoch: 5| Step: 8
Training loss: 3.996441450308896
Validation loss: 3.7152505514758447

Epoch: 5| Step: 9
Training loss: 3.7792808512660954
Validation loss: 3.7068933887716375

Epoch: 5| Step: 10
Training loss: 3.0581833916131127
Validation loss: 3.7036947699294367

Epoch: 16| Step: 0
Training loss: 3.780734444773202
Validation loss: 3.69905611075204

Epoch: 5| Step: 1
Training loss: 3.732509897452721
Validation loss: 3.69487267077008

Epoch: 5| Step: 2
Training loss: 4.683838902310045
Validation loss: 3.6895340762886173

Epoch: 5| Step: 3
Training loss: 4.087639361231045
Validation loss: 3.686174780620247

Epoch: 5| Step: 4
Training loss: 2.392259126533977
Validation loss: 3.6795804935862457

Epoch: 5| Step: 5
Training loss: 3.790210416282297
Validation loss: 3.673829429907844

Epoch: 5| Step: 6
Training loss: 3.974239607723058
Validation loss: 3.6703433027361263

Epoch: 5| Step: 7
Training loss: 4.174411188509339
Validation loss: 3.6679442735115884

Epoch: 5| Step: 8
Training loss: 4.575238356087544
Validation loss: 3.663324764714611

Epoch: 5| Step: 9
Training loss: 3.0691087998600537
Validation loss: 3.6582350950056983

Epoch: 5| Step: 10
Training loss: 3.689288206842145
Validation loss: 3.6537510714914

Epoch: 17| Step: 0
Training loss: 4.361563621958707
Validation loss: 3.650688943701269

Epoch: 5| Step: 1
Training loss: 4.069340038732334
Validation loss: 3.647194415926702

Epoch: 5| Step: 2
Training loss: 4.285744417175455
Validation loss: 3.644614545375896

Epoch: 5| Step: 3
Training loss: 3.2981177423949246
Validation loss: 3.639448269802483

Epoch: 5| Step: 4
Training loss: 3.9173215900199247
Validation loss: 3.6357942025439343

Epoch: 5| Step: 5
Training loss: 3.540975226431162
Validation loss: 3.6326282621663055

Epoch: 5| Step: 6
Training loss: 3.868227300630202
Validation loss: 3.6297245333827957

Epoch: 5| Step: 7
Training loss: 2.7206012955975254
Validation loss: 3.626008769979788

Epoch: 5| Step: 8
Training loss: 3.6957385601864514
Validation loss: 3.6226708139635275

Epoch: 5| Step: 9
Training loss: 4.4485855254777595
Validation loss: 3.6161343481388792

Epoch: 5| Step: 10
Training loss: 3.52000039685854
Validation loss: 3.61101398421538

Epoch: 18| Step: 0
Training loss: 4.372379499097815
Validation loss: 3.609289256278101

Epoch: 5| Step: 1
Training loss: 4.347785666733978
Validation loss: 3.610055820275655

Epoch: 5| Step: 2
Training loss: 3.8717763474083298
Validation loss: 3.609876963132448

Epoch: 5| Step: 3
Training loss: 3.257868997280643
Validation loss: 3.6057445513204374

Epoch: 5| Step: 4
Training loss: 3.6547239330313808
Validation loss: 3.597416426780552

Epoch: 5| Step: 5
Training loss: 3.384140353112653
Validation loss: 3.5907627810930673

Epoch: 5| Step: 6
Training loss: 3.7143474772841105
Validation loss: 3.5915326526133646

Epoch: 5| Step: 7
Training loss: 4.427075027757221
Validation loss: 3.586893994524612

Epoch: 5| Step: 8
Training loss: 3.4173318323982187
Validation loss: 3.582337226457851

Epoch: 5| Step: 9
Training loss: 3.4236706068033413
Validation loss: 3.5794335703286544

Epoch: 5| Step: 10
Training loss: 3.572851033993497
Validation loss: 3.574992588711615

Epoch: 19| Step: 0
Training loss: 3.7051667970494284
Validation loss: 3.5739483940917927

Epoch: 5| Step: 1
Training loss: 3.8401584127652644
Validation loss: 3.571673800813923

Epoch: 5| Step: 2
Training loss: 3.872236927964758
Validation loss: 3.5648133675924005

Epoch: 5| Step: 3
Training loss: 4.058059143161841
Validation loss: 3.566820827054858

Epoch: 5| Step: 4
Training loss: 3.2962793472019385
Validation loss: 3.5578540370750087

Epoch: 5| Step: 5
Training loss: 3.927651577555327
Validation loss: 3.5534634287043887

Epoch: 5| Step: 6
Training loss: 3.9659975374399794
Validation loss: 3.5518682338528196

Epoch: 5| Step: 7
Training loss: 3.980981675811811
Validation loss: 3.5462882509923337

Epoch: 5| Step: 8
Training loss: 3.176572881663818
Validation loss: 3.5434841991206496

Epoch: 5| Step: 9
Training loss: 3.6144388190117973
Validation loss: 3.538956655757544

Epoch: 5| Step: 10
Training loss: 3.8439267745888293
Validation loss: 3.5303571354330145

Epoch: 20| Step: 0
Training loss: 4.236970338380413
Validation loss: 3.529025110979629

Epoch: 5| Step: 1
Training loss: 3.735081561933018
Validation loss: 3.527731539840664

Epoch: 5| Step: 2
Training loss: 3.6103581662436226
Validation loss: 3.5211047068995267

Epoch: 5| Step: 3
Training loss: 3.5203063991881502
Validation loss: 3.524011669429629

Epoch: 5| Step: 4
Training loss: 3.406797312590984
Validation loss: 3.518551083812065

Epoch: 5| Step: 5
Training loss: 4.195779387282897
Validation loss: 3.5163577509550956

Epoch: 5| Step: 6
Training loss: 2.371460938027616
Validation loss: 3.508287751842864

Epoch: 5| Step: 7
Training loss: 4.427054347523063
Validation loss: 3.50507699933433

Epoch: 5| Step: 8
Training loss: 3.3635530262307616
Validation loss: 3.5021692430110143

Epoch: 5| Step: 9
Training loss: 3.827729122945805
Validation loss: 3.495265377623184

Epoch: 5| Step: 10
Training loss: 3.846403493115113
Validation loss: 3.492442171652735

Epoch: 21| Step: 0
Training loss: 4.058274169323512
Validation loss: 3.4882637571652677

Epoch: 5| Step: 1
Training loss: 4.077254746929888
Validation loss: 3.4873527135557865

Epoch: 5| Step: 2
Training loss: 2.79160148392679
Validation loss: 3.4854206076331877

Epoch: 5| Step: 3
Training loss: 3.693277907822093
Validation loss: 3.4876503162684576

Epoch: 5| Step: 4
Training loss: 3.5580739417366978
Validation loss: 3.483433898798455

Epoch: 5| Step: 5
Training loss: 3.578003060874248
Validation loss: 3.47046675285065

Epoch: 5| Step: 6
Training loss: 3.8610889165836544
Validation loss: 3.467415245838464

Epoch: 5| Step: 7
Training loss: 3.969505178136556
Validation loss: 3.4637533923316743

Epoch: 5| Step: 8
Training loss: 4.053589894640989
Validation loss: 3.4608918777755493

Epoch: 5| Step: 9
Training loss: 3.568066714958881
Validation loss: 3.4637841358691244

Epoch: 5| Step: 10
Training loss: 3.081269183302274
Validation loss: 3.4589569818340276

Epoch: 22| Step: 0
Training loss: 3.7158865282372204
Validation loss: 3.458053710007195

Epoch: 5| Step: 1
Training loss: 3.9329520708854724
Validation loss: 3.464385684875535

Epoch: 5| Step: 2
Training loss: 2.0176207841645137
Validation loss: 3.4542019646252187

Epoch: 5| Step: 3
Training loss: 3.993056350191931
Validation loss: 3.446269929740391

Epoch: 5| Step: 4
Training loss: 4.2118836084932525
Validation loss: 3.449897136108877

Epoch: 5| Step: 5
Training loss: 4.044461388488414
Validation loss: 3.4424861628822327

Epoch: 5| Step: 6
Training loss: 3.570997310213322
Validation loss: 3.43791343760748

Epoch: 5| Step: 7
Training loss: 3.8841851185724083
Validation loss: 3.43495891540206

Epoch: 5| Step: 8
Training loss: 2.8322848081534935
Validation loss: 3.4325855538929972

Epoch: 5| Step: 9
Training loss: 4.304809568581743
Validation loss: 3.426681467065569

Epoch: 5| Step: 10
Training loss: 3.0731523498844937
Validation loss: 3.430009042594071

Epoch: 23| Step: 0
Training loss: 4.1969700101663046
Validation loss: 3.4312425587583495

Epoch: 5| Step: 1
Training loss: 3.5220636027895247
Validation loss: 3.433176584266624

Epoch: 5| Step: 2
Training loss: 3.6639019050460133
Validation loss: 3.4355489315551084

Epoch: 5| Step: 3
Training loss: 3.2000062227188644
Validation loss: 3.4297374107183884

Epoch: 5| Step: 4
Training loss: 3.901176148130858
Validation loss: 3.4234984641017285

Epoch: 5| Step: 5
Training loss: 3.34031272406394
Validation loss: 3.4181859315000818

Epoch: 5| Step: 6
Training loss: 4.163958063301033
Validation loss: 3.4071996245129963

Epoch: 5| Step: 7
Training loss: 3.905913315568505
Validation loss: 3.4073939137913407

Epoch: 5| Step: 8
Training loss: 2.774648138884767
Validation loss: 3.409447538864556

Epoch: 5| Step: 9
Training loss: 3.3616196341401015
Validation loss: 3.4032049959926023

Epoch: 5| Step: 10
Training loss: 3.852559732398606
Validation loss: 3.398794078684314

Epoch: 24| Step: 0
Training loss: 3.264407866500764
Validation loss: 3.39986892293109

Epoch: 5| Step: 1
Training loss: 3.285167861899811
Validation loss: 3.3989311179434862

Epoch: 5| Step: 2
Training loss: 3.9944316729991503
Validation loss: 3.407963159647719

Epoch: 5| Step: 3
Training loss: 4.085744470299986
Validation loss: 3.3962107668258796

Epoch: 5| Step: 4
Training loss: 3.2870121815139197
Validation loss: 3.389736723979914

Epoch: 5| Step: 5
Training loss: 3.2845027241793545
Validation loss: 3.3829885150578587

Epoch: 5| Step: 6
Training loss: 3.9313263708316795
Validation loss: 3.381837561267984

Epoch: 5| Step: 7
Training loss: 3.18637992776558
Validation loss: 3.384580011594929

Epoch: 5| Step: 8
Training loss: 4.131652092230234
Validation loss: 3.3856163467067995

Epoch: 5| Step: 9
Training loss: 3.35474818778435
Validation loss: 3.377470970666342

Epoch: 5| Step: 10
Training loss: 3.820820094050631
Validation loss: 3.3793933398536447

Epoch: 25| Step: 0
Training loss: 3.0591359248669425
Validation loss: 3.3748318817548677

Epoch: 5| Step: 1
Training loss: 3.6805668972648355
Validation loss: 3.3706801861436317

Epoch: 5| Step: 2
Training loss: 4.5189937710466905
Validation loss: 3.3676598547363255

Epoch: 5| Step: 3
Training loss: 3.334373661459285
Validation loss: 3.367538119832849

Epoch: 5| Step: 4
Training loss: 3.7786022405478126
Validation loss: 3.361248586501955

Epoch: 5| Step: 5
Training loss: 3.307758608718267
Validation loss: 3.366041877613541

Epoch: 5| Step: 6
Training loss: 3.4357624170678105
Validation loss: 3.3725282352385455

Epoch: 5| Step: 7
Training loss: 2.575286967758854
Validation loss: 3.358006166093406

Epoch: 5| Step: 8
Training loss: 4.336691850906264
Validation loss: 3.353253391500065

Epoch: 5| Step: 9
Training loss: 3.4882093467008444
Validation loss: 3.352626581232155

Epoch: 5| Step: 10
Training loss: 3.599393708779408
Validation loss: 3.3469493634307295

Epoch: 26| Step: 0
Training loss: 4.058161840137965
Validation loss: 3.34921899053323

Epoch: 5| Step: 1
Training loss: 3.9280405404199454
Validation loss: 3.3452675317713587

Epoch: 5| Step: 2
Training loss: 4.355091027273134
Validation loss: 3.341143887731339

Epoch: 5| Step: 3
Training loss: 4.1942955787857485
Validation loss: 3.343647337027416

Epoch: 5| Step: 4
Training loss: 1.9351063370379755
Validation loss: 3.3454997732753817

Epoch: 5| Step: 5
Training loss: 3.2887394762323905
Validation loss: 3.3404856861942904

Epoch: 5| Step: 6
Training loss: 2.7450936505405488
Validation loss: 3.3396888952714705

Epoch: 5| Step: 7
Training loss: 3.6279575516258356
Validation loss: 3.3425284688281476

Epoch: 5| Step: 8
Training loss: 3.6247055986493417
Validation loss: 3.3368881994627193

Epoch: 5| Step: 9
Training loss: 3.354304403632229
Validation loss: 3.332484415356042

Epoch: 5| Step: 10
Training loss: 3.5304407863602663
Validation loss: 3.325801533045641

Epoch: 27| Step: 0
Training loss: 4.019302762046318
Validation loss: 3.325612654871669

Epoch: 5| Step: 1
Training loss: 3.772199534287264
Validation loss: 3.323237504931369

Epoch: 5| Step: 2
Training loss: 3.401418776973823
Validation loss: 3.3183127057050203

Epoch: 5| Step: 3
Training loss: 3.764855397197109
Validation loss: 3.3171813879157255

Epoch: 5| Step: 4
Training loss: 3.217534696900227
Validation loss: 3.316037394928251

Epoch: 5| Step: 5
Training loss: 3.606730363345643
Validation loss: 3.319312475412424

Epoch: 5| Step: 6
Training loss: 2.9696457966964536
Validation loss: 3.3195321651325775

Epoch: 5| Step: 7
Training loss: 3.615161831136694
Validation loss: 3.3160547062201435

Epoch: 5| Step: 8
Training loss: 3.535591225182073
Validation loss: 3.3137216913585483

Epoch: 5| Step: 9
Training loss: 3.689872366499238
Validation loss: 3.313289123451986

Epoch: 5| Step: 10
Training loss: 3.3685704907095095
Validation loss: 3.3134085581130472

Epoch: 28| Step: 0
Training loss: 3.903401915818874
Validation loss: 3.3155462970361707

Epoch: 5| Step: 1
Training loss: 3.321476990190103
Validation loss: 3.319152407772434

Epoch: 5| Step: 2
Training loss: 4.037565031207
Validation loss: 3.307936689196323

Epoch: 5| Step: 3
Training loss: 2.549270626549185
Validation loss: 3.301781843453641

Epoch: 5| Step: 4
Training loss: 3.0934605318532493
Validation loss: 3.2986009632091946

Epoch: 5| Step: 5
Training loss: 3.635994516408413
Validation loss: 3.3068995590774533

Epoch: 5| Step: 6
Training loss: 3.970132662000331
Validation loss: 3.3080341033206313

Epoch: 5| Step: 7
Training loss: 3.861401354144068
Validation loss: 3.304029949462079

Epoch: 5| Step: 8
Training loss: 3.591300992354719
Validation loss: 3.2988643626885725

Epoch: 5| Step: 9
Training loss: 3.48570082547986
Validation loss: 3.2949111253318315

Epoch: 5| Step: 10
Training loss: 3.2048022833196588
Validation loss: 3.294644398463194

Epoch: 29| Step: 0
Training loss: 4.027724979683058
Validation loss: 3.2917012116403144

Epoch: 5| Step: 1
Training loss: 3.7280805203005913
Validation loss: 3.2965230072985463

Epoch: 5| Step: 2
Training loss: 3.643126320176892
Validation loss: 3.2928240449439876

Epoch: 5| Step: 3
Training loss: 3.2802933524533158
Validation loss: 3.293482778812773

Epoch: 5| Step: 4
Training loss: 3.7717320475949747
Validation loss: 3.2897888165759985

Epoch: 5| Step: 5
Training loss: 3.7021146917151
Validation loss: 3.284080496335474

Epoch: 5| Step: 6
Training loss: 3.0510217862421944
Validation loss: 3.2863256525420095

Epoch: 5| Step: 7
Training loss: 3.405089154301643
Validation loss: 3.2882899146022786

Epoch: 5| Step: 8
Training loss: 3.4541645125201006
Validation loss: 3.292534623539066

Epoch: 5| Step: 9
Training loss: 3.151504726381554
Validation loss: 3.280801644581451

Epoch: 5| Step: 10
Training loss: 3.512634225907544
Validation loss: 3.2804765382496823

Epoch: 30| Step: 0
Training loss: 3.811434237242487
Validation loss: 3.279920733194596

Epoch: 5| Step: 1
Training loss: 3.500500506990176
Validation loss: 3.279192160551468

Epoch: 5| Step: 2
Training loss: 3.4545751780276155
Validation loss: 3.2779821668522433

Epoch: 5| Step: 3
Training loss: 3.3920307673192513
Validation loss: 3.282064832232166

Epoch: 5| Step: 4
Training loss: 3.3993705783989876
Validation loss: 3.279879365091227

Epoch: 5| Step: 5
Training loss: 3.4842213139190332
Validation loss: 3.2782977267497273

Epoch: 5| Step: 6
Training loss: 3.2320629462259394
Validation loss: 3.280481268570231

Epoch: 5| Step: 7
Training loss: 3.195645862901442
Validation loss: 3.280943708290186

Epoch: 5| Step: 8
Training loss: 3.629885045693085
Validation loss: 3.2743482815332774

Epoch: 5| Step: 9
Training loss: 3.8171750780887987
Validation loss: 3.2707362419554187

Epoch: 5| Step: 10
Training loss: 3.7940160717741906
Validation loss: 3.270389040499603

Epoch: 31| Step: 0
Training loss: 3.593740712029438
Validation loss: 3.2716633673801256

Epoch: 5| Step: 1
Training loss: 3.286832873750325
Validation loss: 3.265836684991761

Epoch: 5| Step: 2
Training loss: 2.813899899815059
Validation loss: 3.2665293707591925

Epoch: 5| Step: 3
Training loss: 2.7951845995928033
Validation loss: 3.266353031646946

Epoch: 5| Step: 4
Training loss: 4.190836929094207
Validation loss: 3.261913482136777

Epoch: 5| Step: 5
Training loss: 3.7435970319724543
Validation loss: 3.264489791200803

Epoch: 5| Step: 6
Training loss: 3.333147727249346
Validation loss: 3.2660549889702852

Epoch: 5| Step: 7
Training loss: 3.8020617062027595
Validation loss: 3.267772769212585

Epoch: 5| Step: 8
Training loss: 3.9163751831892317
Validation loss: 3.2634271784882127

Epoch: 5| Step: 9
Training loss: 3.6417719135453948
Validation loss: 3.256751579959211

Epoch: 5| Step: 10
Training loss: 3.1985418514192934
Validation loss: 3.2577282810664343

Epoch: 32| Step: 0
Training loss: 2.763059126252722
Validation loss: 3.257889345063992

Epoch: 5| Step: 1
Training loss: 3.071400534543046
Validation loss: 3.257232050083496

Epoch: 5| Step: 2
Training loss: 4.2264415561485125
Validation loss: 3.2543752577726326

Epoch: 5| Step: 3
Training loss: 3.6302649312507946
Validation loss: 3.2537047376915793

Epoch: 5| Step: 4
Training loss: 3.462940747134444
Validation loss: 3.255026134223932

Epoch: 5| Step: 5
Training loss: 3.444412632935446
Validation loss: 3.2523334714704206

Epoch: 5| Step: 6
Training loss: 3.330831510727681
Validation loss: 3.2511819294757114

Epoch: 5| Step: 7
Training loss: 4.037932069884407
Validation loss: 3.2522775843099128

Epoch: 5| Step: 8
Training loss: 3.485128825801721
Validation loss: 3.25155309731832

Epoch: 5| Step: 9
Training loss: 3.3392834645169738
Validation loss: 3.2501732233422267

Epoch: 5| Step: 10
Training loss: 3.527437971341608
Validation loss: 3.2506248040764523

Epoch: 33| Step: 0
Training loss: 3.2509115848023535
Validation loss: 3.249003285110782

Epoch: 5| Step: 1
Training loss: 4.232809192519587
Validation loss: 3.2465782595182247

Epoch: 5| Step: 2
Training loss: 3.046147186209772
Validation loss: 3.243172171184068

Epoch: 5| Step: 3
Training loss: 3.826703364254994
Validation loss: 3.2448075767048947

Epoch: 5| Step: 4
Training loss: 3.7922901996275176
Validation loss: 3.2424060299650828

Epoch: 5| Step: 5
Training loss: 3.2097441968867617
Validation loss: 3.245250299669052

Epoch: 5| Step: 6
Training loss: 3.6816757240949585
Validation loss: 3.241489691621725

Epoch: 5| Step: 7
Training loss: 3.157548391857808
Validation loss: 3.240172768414591

Epoch: 5| Step: 8
Training loss: 3.669039146557606
Validation loss: 3.2432877125913704

Epoch: 5| Step: 9
Training loss: 3.1057537212016366
Validation loss: 3.2453642583072595

Epoch: 5| Step: 10
Training loss: 3.2416918272269437
Validation loss: 3.254170717838713

Epoch: 34| Step: 0
Training loss: 3.4525898652531732
Validation loss: 3.2530138431033597

Epoch: 5| Step: 1
Training loss: 3.2257494329212397
Validation loss: 3.241621061823012

Epoch: 5| Step: 2
Training loss: 3.268075853781821
Validation loss: 3.2389505765038806

Epoch: 5| Step: 3
Training loss: 3.6705608207590843
Validation loss: 3.2427750147191516

Epoch: 5| Step: 4
Training loss: 3.907061683247924
Validation loss: 3.244749015833688

Epoch: 5| Step: 5
Training loss: 3.5871336693425513
Validation loss: 3.2467207286779356

Epoch: 5| Step: 6
Training loss: 3.3901728315379076
Validation loss: 3.2402755973127384

Epoch: 5| Step: 7
Training loss: 3.288688294061267
Validation loss: 3.2454688714369255

Epoch: 5| Step: 8
Training loss: 4.2319808892177315
Validation loss: 3.244988310758547

Epoch: 5| Step: 9
Training loss: 2.86754321144757
Validation loss: 3.2405479115434264

Epoch: 5| Step: 10
Training loss: 3.3533508224739066
Validation loss: 3.2373677558542

Epoch: 35| Step: 0
Training loss: 3.4881863810762717
Validation loss: 3.2343121626008333

Epoch: 5| Step: 1
Training loss: 3.3501464413191986
Validation loss: 3.2347523522298234

Epoch: 5| Step: 2
Training loss: 3.307710171550629
Validation loss: 3.233110661562388

Epoch: 5| Step: 3
Training loss: 3.838351047843265
Validation loss: 3.233993506982353

Epoch: 5| Step: 4
Training loss: 3.5569625113900316
Validation loss: 3.2315049744258366

Epoch: 5| Step: 5
Training loss: 3.8591215845839906
Validation loss: 3.2343882558030934

Epoch: 5| Step: 6
Training loss: 3.961784197056656
Validation loss: 3.2309264030867544

Epoch: 5| Step: 7
Training loss: 2.9490117890958936
Validation loss: 3.226807448116807

Epoch: 5| Step: 8
Training loss: 3.209803917145631
Validation loss: 3.228150745730691

Epoch: 5| Step: 9
Training loss: 3.3687614426568913
Validation loss: 3.2264623511464885

Epoch: 5| Step: 10
Training loss: 3.283194265631637
Validation loss: 3.2250018821011914

Epoch: 36| Step: 0
Training loss: 3.4152679061247113
Validation loss: 3.225536895841405

Epoch: 5| Step: 1
Training loss: 3.436804961250319
Validation loss: 3.227185407178371

Epoch: 5| Step: 2
Training loss: 3.4938762771633045
Validation loss: 3.225625604872021

Epoch: 5| Step: 3
Training loss: 3.527923502544681
Validation loss: 3.228861745886309

Epoch: 5| Step: 4
Training loss: 3.432348379188535
Validation loss: 3.22589750597227

Epoch: 5| Step: 5
Training loss: 3.6572723263575306
Validation loss: 3.2257709036170743

Epoch: 5| Step: 6
Training loss: 3.4107187338138814
Validation loss: 3.229458551516263

Epoch: 5| Step: 7
Training loss: 3.142277524807081
Validation loss: 3.2285704076465964

Epoch: 5| Step: 8
Training loss: 3.8049197272957747
Validation loss: 3.2269129265983185

Epoch: 5| Step: 9
Training loss: 3.395415547576269
Validation loss: 3.2277566748404194

Epoch: 5| Step: 10
Training loss: 3.530729137255026
Validation loss: 3.222797974533766

Epoch: 37| Step: 0
Training loss: 3.796209583136405
Validation loss: 3.221367819315266

Epoch: 5| Step: 1
Training loss: 3.064577915818755
Validation loss: 3.2201930935923504

Epoch: 5| Step: 2
Training loss: 3.435102424260612
Validation loss: 3.2187198486572584

Epoch: 5| Step: 3
Training loss: 3.3722319377806
Validation loss: 3.220475443724412

Epoch: 5| Step: 4
Training loss: 3.819110455022684
Validation loss: 3.2185314776112066

Epoch: 5| Step: 5
Training loss: 3.2420866065815077
Validation loss: 3.218398581847755

Epoch: 5| Step: 6
Training loss: 3.6900605185903625
Validation loss: 3.2174202330300727

Epoch: 5| Step: 7
Training loss: 3.4129092016562645
Validation loss: 3.2159688140204166

Epoch: 5| Step: 8
Training loss: 3.4900977519426637
Validation loss: 3.219358798215782

Epoch: 5| Step: 9
Training loss: 3.472731084199654
Validation loss: 3.2197793297759487

Epoch: 5| Step: 10
Training loss: 3.359094652410095
Validation loss: 3.2251978057488966

Epoch: 38| Step: 0
Training loss: 2.8261273320608686
Validation loss: 3.2208530410511544

Epoch: 5| Step: 1
Training loss: 3.6768995604731463
Validation loss: 3.219140032051549

Epoch: 5| Step: 2
Training loss: 2.9326958837884214
Validation loss: 3.217316907916756

Epoch: 5| Step: 3
Training loss: 3.3019428082878877
Validation loss: 3.2187363166012473

Epoch: 5| Step: 4
Training loss: 3.553615534194458
Validation loss: 3.2254862749498807

Epoch: 5| Step: 5
Training loss: 3.2678470626306324
Validation loss: 3.215289782311794

Epoch: 5| Step: 6
Training loss: 3.4968376859935977
Validation loss: 3.2150291874132453

Epoch: 5| Step: 7
Training loss: 3.8647390301676605
Validation loss: 3.2119509678880003

Epoch: 5| Step: 8
Training loss: 4.264415751215957
Validation loss: 3.2135855554957606

Epoch: 5| Step: 9
Training loss: 3.7227584648709824
Validation loss: 3.215744727819006

Epoch: 5| Step: 10
Training loss: 2.872566022122492
Validation loss: 3.2120334786860325

Epoch: 39| Step: 0
Training loss: 3.344565318877957
Validation loss: 3.208601262944641

Epoch: 5| Step: 1
Training loss: 3.6898591851552296
Validation loss: 3.211346280024363

Epoch: 5| Step: 2
Training loss: 2.960193228471773
Validation loss: 3.208718434300975

Epoch: 5| Step: 3
Training loss: 3.3729224698395943
Validation loss: 3.206611070089787

Epoch: 5| Step: 4
Training loss: 3.32055835486834
Validation loss: 3.205909824209918

Epoch: 5| Step: 5
Training loss: 3.4172959717330387
Validation loss: 3.2078832164899755

Epoch: 5| Step: 6
Training loss: 3.7170696148453346
Validation loss: 3.2056157082455616

Epoch: 5| Step: 7
Training loss: 3.8344992371122024
Validation loss: 3.205576896908045

Epoch: 5| Step: 8
Training loss: 3.386722129107311
Validation loss: 3.2051964489445104

Epoch: 5| Step: 9
Training loss: 3.5390236959793198
Validation loss: 3.203090837418013

Epoch: 5| Step: 10
Training loss: 3.4315436343543033
Validation loss: 3.20258288574342

Epoch: 40| Step: 0
Training loss: 2.307764617691797
Validation loss: 3.2031331348090792

Epoch: 5| Step: 1
Training loss: 3.5829423351028638
Validation loss: 3.2007646165026857

Epoch: 5| Step: 2
Training loss: 3.9820784588627913
Validation loss: 3.2042652468657966

Epoch: 5| Step: 3
Training loss: 3.8690600244791318
Validation loss: 3.2049633562307993

Epoch: 5| Step: 4
Training loss: 3.913645343288898
Validation loss: 3.2090040469229946

Epoch: 5| Step: 5
Training loss: 3.242902929584166
Validation loss: 3.2058593060361606

Epoch: 5| Step: 6
Training loss: 2.8186704975428154
Validation loss: 3.208341112408412

Epoch: 5| Step: 7
Training loss: 3.4925916467764755
Validation loss: 3.207107327809546

Epoch: 5| Step: 8
Training loss: 3.232003047120197
Validation loss: 3.198325476784233

Epoch: 5| Step: 9
Training loss: 3.757380407159872
Validation loss: 3.1976049704946012

Epoch: 5| Step: 10
Training loss: 3.438025417054177
Validation loss: 3.1957541539952463

Epoch: 41| Step: 0
Training loss: 3.792043744015984
Validation loss: 3.1959938076944505

Epoch: 5| Step: 1
Training loss: 3.889975865149463
Validation loss: 3.196721711917992

Epoch: 5| Step: 2
Training loss: 3.350963619051764
Validation loss: 3.197228242196547

Epoch: 5| Step: 3
Training loss: 3.280592498298528
Validation loss: 3.197723263109044

Epoch: 5| Step: 4
Training loss: 3.338266886067126
Validation loss: 3.198089731742975

Epoch: 5| Step: 5
Training loss: 3.24499228619098
Validation loss: 3.1999116712346685

Epoch: 5| Step: 6
Training loss: 3.20302198290896
Validation loss: 3.2015821597447176

Epoch: 5| Step: 7
Training loss: 3.7442437815895055
Validation loss: 3.1938216264051005

Epoch: 5| Step: 8
Training loss: 2.653016489638391
Validation loss: 3.192509805789196

Epoch: 5| Step: 9
Training loss: 3.900153445624167
Validation loss: 3.193309848051739

Epoch: 5| Step: 10
Training loss: 3.357444598890522
Validation loss: 3.1932315596749006

Epoch: 42| Step: 0
Training loss: 2.8636629232741004
Validation loss: 3.1957291115547384

Epoch: 5| Step: 1
Training loss: 3.603277563486322
Validation loss: 3.1864586902068397

Epoch: 5| Step: 2
Training loss: 2.751575625473335
Validation loss: 3.180867150684628

Epoch: 5| Step: 3
Training loss: 3.9252967042000044
Validation loss: 3.186837825885377

Epoch: 5| Step: 4
Training loss: 3.181902889263609
Validation loss: 3.185185650071902

Epoch: 5| Step: 5
Training loss: 3.686260079583183
Validation loss: 3.1912967092093436

Epoch: 5| Step: 6
Training loss: 4.118451787546235
Validation loss: 3.2042795409076144

Epoch: 5| Step: 7
Training loss: 3.72515535478688
Validation loss: 3.203900115128196

Epoch: 5| Step: 8
Training loss: 3.6961128384345785
Validation loss: 3.191462356448328

Epoch: 5| Step: 9
Training loss: 2.8034295366391206
Validation loss: 3.18234267121005

Epoch: 5| Step: 10
Training loss: 3.1798521556914663
Validation loss: 3.1832859720208395

Epoch: 43| Step: 0
Training loss: 3.3695316519008425
Validation loss: 3.1786552302208206

Epoch: 5| Step: 1
Training loss: 2.908774971061768
Validation loss: 3.1784201007435073

Epoch: 5| Step: 2
Training loss: 4.14049095080773
Validation loss: 3.17693368501138

Epoch: 5| Step: 3
Training loss: 3.809044694858116
Validation loss: 3.1778657137817206

Epoch: 5| Step: 4
Training loss: 3.398932620407302
Validation loss: 3.172589786333135

Epoch: 5| Step: 5
Training loss: 3.0017837943256303
Validation loss: 3.18036719429256

Epoch: 5| Step: 6
Training loss: 2.756817776075938
Validation loss: 3.1724133222871593

Epoch: 5| Step: 7
Training loss: 3.42757967955769
Validation loss: 3.1737914596724157

Epoch: 5| Step: 8
Training loss: 3.7395092771771856
Validation loss: 3.1677820306364937

Epoch: 5| Step: 9
Training loss: 3.787371763570125
Validation loss: 3.1693946600570246

Epoch: 5| Step: 10
Training loss: 3.1573834791754884
Validation loss: 3.170320972462904

Epoch: 44| Step: 0
Training loss: 3.4535094172337035
Validation loss: 3.1669083461493224

Epoch: 5| Step: 1
Training loss: 3.5005348341883717
Validation loss: 3.1710321347226564

Epoch: 5| Step: 2
Training loss: 3.9331821805930707
Validation loss: 3.1685206556378875

Epoch: 5| Step: 3
Training loss: 4.040143279754725
Validation loss: 3.1695111802455402

Epoch: 5| Step: 4
Training loss: 3.572935647422858
Validation loss: 3.17535857708818

Epoch: 5| Step: 5
Training loss: 3.3672837953893056
Validation loss: 3.1707703813692585

Epoch: 5| Step: 6
Training loss: 3.4753126319382366
Validation loss: 3.169692337558759

Epoch: 5| Step: 7
Training loss: 2.4467859673409946
Validation loss: 3.1707556678344018

Epoch: 5| Step: 8
Training loss: 3.327640265325054
Validation loss: 3.168268354576769

Epoch: 5| Step: 9
Training loss: 3.459221201219969
Validation loss: 3.1631013772433008

Epoch: 5| Step: 10
Training loss: 2.703592778121755
Validation loss: 3.163918055745766

Epoch: 45| Step: 0
Training loss: 3.316736067871681
Validation loss: 3.1631057830270954

Epoch: 5| Step: 1
Training loss: 3.3049095566186377
Validation loss: 3.1609201886370593

Epoch: 5| Step: 2
Training loss: 3.5708812702986674
Validation loss: 3.165458251635219

Epoch: 5| Step: 3
Training loss: 3.0598285467446753
Validation loss: 3.1648192227612886

Epoch: 5| Step: 4
Training loss: 3.648047742916028
Validation loss: 3.16818427349416

Epoch: 5| Step: 5
Training loss: 3.8317349598359747
Validation loss: 3.1612324018741176

Epoch: 5| Step: 6
Training loss: 4.058271114386791
Validation loss: 3.1590984368966124

Epoch: 5| Step: 7
Training loss: 3.15962310933665
Validation loss: 3.154196427808047

Epoch: 5| Step: 8
Training loss: 3.259009271805746
Validation loss: 3.155097370019716

Epoch: 5| Step: 9
Training loss: 3.3576936994565356
Validation loss: 3.1538202303882805

Epoch: 5| Step: 10
Training loss: 2.7579288620214975
Validation loss: 3.1556000529204242

Epoch: 46| Step: 0
Training loss: 3.4166964707974237
Validation loss: 3.15291071903885

Epoch: 5| Step: 1
Training loss: 3.4585146722398252
Validation loss: 3.150720137149376

Epoch: 5| Step: 2
Training loss: 3.1776695502761063
Validation loss: 3.153579404068679

Epoch: 5| Step: 3
Training loss: 3.769201329474107
Validation loss: 3.1566415935929637

Epoch: 5| Step: 4
Training loss: 3.597304601392915
Validation loss: 3.15828226543711

Epoch: 5| Step: 5
Training loss: 3.5362464867551147
Validation loss: 3.1521298956490877

Epoch: 5| Step: 6
Training loss: 2.7169579047521273
Validation loss: 3.1517443138008945

Epoch: 5| Step: 7
Training loss: 3.6677218710597055
Validation loss: 3.1485900947780876

Epoch: 5| Step: 8
Training loss: 2.3845693646526804
Validation loss: 3.149120772399526

Epoch: 5| Step: 9
Training loss: 3.9817715385574437
Validation loss: 3.148583326985767

Epoch: 5| Step: 10
Training loss: 3.5377957601212695
Validation loss: 3.1501678481000894

Epoch: 47| Step: 0
Training loss: 3.4405677284789045
Validation loss: 3.1522117983893665

Epoch: 5| Step: 1
Training loss: 3.4422675623437757
Validation loss: 3.155042623896294

Epoch: 5| Step: 2
Training loss: 3.5898031039422262
Validation loss: 3.1517252345448483

Epoch: 5| Step: 3
Training loss: 2.6965140939970547
Validation loss: 3.146966968041404

Epoch: 5| Step: 4
Training loss: 3.5797408674000937
Validation loss: 3.1466708883924963

Epoch: 5| Step: 5
Training loss: 3.783704481251202
Validation loss: 3.146039617944101

Epoch: 5| Step: 6
Training loss: 3.373429250773335
Validation loss: 3.1451275843414703

Epoch: 5| Step: 7
Training loss: 2.7221242201501346
Validation loss: 3.1482756392491686

Epoch: 5| Step: 8
Training loss: 3.779574566873258
Validation loss: 3.151275361413362

Epoch: 5| Step: 9
Training loss: 3.1791820827392003
Validation loss: 3.1497010563967764

Epoch: 5| Step: 10
Training loss: 3.8008168798111575
Validation loss: 3.1470821721176985

Epoch: 48| Step: 0
Training loss: 3.4453239873231825
Validation loss: 3.1477098747082852

Epoch: 5| Step: 1
Training loss: 3.50150048925736
Validation loss: 3.1474882120873815

Epoch: 5| Step: 2
Training loss: 3.9281653305811712
Validation loss: 3.1467507180644994

Epoch: 5| Step: 3
Training loss: 3.759451336295708
Validation loss: 3.1486237332258544

Epoch: 5| Step: 4
Training loss: 3.428554199947485
Validation loss: 3.147536788710185

Epoch: 5| Step: 5
Training loss: 3.460038251279512
Validation loss: 3.1445540774650627

Epoch: 5| Step: 6
Training loss: 2.639720061950253
Validation loss: 3.1445652612319286

Epoch: 5| Step: 7
Training loss: 3.386609349579268
Validation loss: 3.1438016295329483

Epoch: 5| Step: 8
Training loss: 4.011643629104359
Validation loss: 3.1426602415972074

Epoch: 5| Step: 9
Training loss: 2.940011432132422
Validation loss: 3.144729525460732

Epoch: 5| Step: 10
Training loss: 2.5661812368657624
Validation loss: 3.1394520467439833

Epoch: 49| Step: 0
Training loss: 4.009171937600599
Validation loss: 3.1422662268364014

Epoch: 5| Step: 1
Training loss: 3.825171627607297
Validation loss: 3.14207189505585

Epoch: 5| Step: 2
Training loss: 3.8539651491562097
Validation loss: 3.141530013820521

Epoch: 5| Step: 3
Training loss: 2.864259810240524
Validation loss: 3.1404579480191384

Epoch: 5| Step: 4
Training loss: 3.3813536848434524
Validation loss: 3.1416886186217687

Epoch: 5| Step: 5
Training loss: 3.4827996357696893
Validation loss: 3.1436052527712746

Epoch: 5| Step: 6
Training loss: 3.0272147464953534
Validation loss: 3.1439548293026616

Epoch: 5| Step: 7
Training loss: 3.358180485758137
Validation loss: 3.139856864839083

Epoch: 5| Step: 8
Training loss: 2.836389258686902
Validation loss: 3.144907832259891

Epoch: 5| Step: 9
Training loss: 2.928135493859181
Validation loss: 3.1426365014071016

Epoch: 5| Step: 10
Training loss: 3.6398043382897267
Validation loss: 3.14924836079211

Epoch: 50| Step: 0
Training loss: 3.3278215296831726
Validation loss: 3.153005961213686

Epoch: 5| Step: 1
Training loss: 3.210729142086005
Validation loss: 3.147039577567774

Epoch: 5| Step: 2
Training loss: 3.4170085146705524
Validation loss: 3.143416662122887

Epoch: 5| Step: 3
Training loss: 2.7087952342215096
Validation loss: 3.140413877480145

Epoch: 5| Step: 4
Training loss: 2.987349381101592
Validation loss: 3.141991915502099

Epoch: 5| Step: 5
Training loss: 3.81626593528042
Validation loss: 3.149567661608271

Epoch: 5| Step: 6
Training loss: 3.0621565022803794
Validation loss: 3.1462188755550415

Epoch: 5| Step: 7
Training loss: 3.279499422580757
Validation loss: 3.137897578730002

Epoch: 5| Step: 8
Training loss: 3.788993032546193
Validation loss: 3.133970492434254

Epoch: 5| Step: 9
Training loss: 4.199208530147447
Validation loss: 3.134685712558681

Epoch: 5| Step: 10
Training loss: 3.3820061196080657
Validation loss: 3.1349261691313175

Epoch: 51| Step: 0
Training loss: 3.5928956716346465
Validation loss: 3.1345962553795568

Epoch: 5| Step: 1
Training loss: 3.365408655437081
Validation loss: 3.1373837983421637

Epoch: 5| Step: 2
Training loss: 2.713328777218804
Validation loss: 3.1430663487467077

Epoch: 5| Step: 3
Training loss: 2.9366418112469006
Validation loss: 3.143906823586307

Epoch: 5| Step: 4
Training loss: 4.111577477221643
Validation loss: 3.142880470585237

Epoch: 5| Step: 5
Training loss: 3.1951893827041324
Validation loss: 3.140791522334453

Epoch: 5| Step: 6
Training loss: 3.2647324213789903
Validation loss: 3.1394341756524167

Epoch: 5| Step: 7
Training loss: 3.2667298706583563
Validation loss: 3.135945535364769

Epoch: 5| Step: 8
Training loss: 3.3699548948082363
Validation loss: 3.134806551183911

Epoch: 5| Step: 9
Training loss: 3.7954430411241806
Validation loss: 3.1330985238747724

Epoch: 5| Step: 10
Training loss: 3.613151127302259
Validation loss: 3.1325198652045474

Epoch: 52| Step: 0
Training loss: 3.2787957595267243
Validation loss: 3.13299796492142

Epoch: 5| Step: 1
Training loss: 3.8342521367989564
Validation loss: 3.1288615136710134

Epoch: 5| Step: 2
Training loss: 3.6211801331390054
Validation loss: 3.131229523098576

Epoch: 5| Step: 3
Training loss: 3.4423231100762517
Validation loss: 3.1283789335242256

Epoch: 5| Step: 4
Training loss: 3.6214599424214247
Validation loss: 3.1294198804643356

Epoch: 5| Step: 5
Training loss: 3.3111285843555263
Validation loss: 3.1288877099008303

Epoch: 5| Step: 6
Training loss: 3.1959371166130173
Validation loss: 3.129618295782511

Epoch: 5| Step: 7
Training loss: 3.048998596391264
Validation loss: 3.128156296120882

Epoch: 5| Step: 8
Training loss: 3.5812477577828252
Validation loss: 3.133093897516953

Epoch: 5| Step: 9
Training loss: 2.959016604609954
Validation loss: 3.1340455143146544

Epoch: 5| Step: 10
Training loss: 3.3668204193761397
Validation loss: 3.1311086798840027

Epoch: 53| Step: 0
Training loss: 3.847462667639783
Validation loss: 3.127610385860552

Epoch: 5| Step: 1
Training loss: 2.616888410644571
Validation loss: 3.1255544109153868

Epoch: 5| Step: 2
Training loss: 2.64746940270917
Validation loss: 3.1271448367334704

Epoch: 5| Step: 3
Training loss: 3.650865551468904
Validation loss: 3.1499524225723268

Epoch: 5| Step: 4
Training loss: 3.398695100689553
Validation loss: 3.13707796879844

Epoch: 5| Step: 5
Training loss: 3.3316462697989757
Validation loss: 3.1276575318770017

Epoch: 5| Step: 6
Training loss: 4.195686877717937
Validation loss: 3.1286061635024462

Epoch: 5| Step: 7
Training loss: 3.464939808508499
Validation loss: 3.1292589792856877

Epoch: 5| Step: 8
Training loss: 2.6555974719819684
Validation loss: 3.1265586460778105

Epoch: 5| Step: 9
Training loss: 4.022068894580129
Validation loss: 3.1227177898142373

Epoch: 5| Step: 10
Training loss: 2.940515147639286
Validation loss: 3.123373330989448

Epoch: 54| Step: 0
Training loss: 2.577457873409938
Validation loss: 3.1245124731934113

Epoch: 5| Step: 1
Training loss: 2.9371852300289962
Validation loss: 3.124943919345164

Epoch: 5| Step: 2
Training loss: 3.165068139281356
Validation loss: 3.1304944422769654

Epoch: 5| Step: 3
Training loss: 3.7758599318695145
Validation loss: 3.152413072215341

Epoch: 5| Step: 4
Training loss: 3.3172041401600714
Validation loss: 3.1280997278696643

Epoch: 5| Step: 5
Training loss: 3.707888730146044
Validation loss: 3.1249897864390173

Epoch: 5| Step: 6
Training loss: 3.7180182754863624
Validation loss: 3.1251471125933143

Epoch: 5| Step: 7
Training loss: 3.5473890562230324
Validation loss: 3.1266357570724095

Epoch: 5| Step: 8
Training loss: 3.476520529504382
Validation loss: 3.123660823227317

Epoch: 5| Step: 9
Training loss: 3.3349126094594945
Validation loss: 3.129685059431594

Epoch: 5| Step: 10
Training loss: 3.5973312446507113
Validation loss: 3.1308449127964773

Epoch: 55| Step: 0
Training loss: 3.703792463581248
Validation loss: 3.127714937614685

Epoch: 5| Step: 1
Training loss: 3.4198135367530886
Validation loss: 3.129133621927684

Epoch: 5| Step: 2
Training loss: 3.333299795617823
Validation loss: 3.124452504425003

Epoch: 5| Step: 3
Training loss: 3.0581380180613507
Validation loss: 3.128760700548804

Epoch: 5| Step: 4
Training loss: 3.5925792611549525
Validation loss: 3.1235430218951317

Epoch: 5| Step: 5
Training loss: 3.587120908053781
Validation loss: 3.1260636027070423

Epoch: 5| Step: 6
Training loss: 2.8678057677019635
Validation loss: 3.1231637362965987

Epoch: 5| Step: 7
Training loss: 3.4960902038215256
Validation loss: 3.120966798038631

Epoch: 5| Step: 8
Training loss: 3.0251042308662655
Validation loss: 3.1215639350722437

Epoch: 5| Step: 9
Training loss: 3.162384718652152
Validation loss: 3.121595997211127

Epoch: 5| Step: 10
Training loss: 3.9768231799226523
Validation loss: 3.1184845418009637

Epoch: 56| Step: 0
Training loss: 2.9610086799862816
Validation loss: 3.1231125527623496

Epoch: 5| Step: 1
Training loss: 3.210930371798657
Validation loss: 3.123473863289929

Epoch: 5| Step: 2
Training loss: 3.5340546129688333
Validation loss: 3.1177339344490584

Epoch: 5| Step: 3
Training loss: 3.2101302791314534
Validation loss: 3.1172510478272453

Epoch: 5| Step: 4
Training loss: 3.722106188456935
Validation loss: 3.1190291265163412

Epoch: 5| Step: 5
Training loss: 3.3622788764257625
Validation loss: 3.1197506645817534

Epoch: 5| Step: 6
Training loss: 2.905950059076998
Validation loss: 3.1163110090089337

Epoch: 5| Step: 7
Training loss: 3.6164710898776584
Validation loss: 3.1239638384782444

Epoch: 5| Step: 8
Training loss: 2.9193291818514195
Validation loss: 3.1215123163077965

Epoch: 5| Step: 9
Training loss: 3.458328676029118
Validation loss: 3.1315205412847624

Epoch: 5| Step: 10
Training loss: 4.226843410330468
Validation loss: 3.1239224682466586

Epoch: 57| Step: 0
Training loss: 4.008507502863465
Validation loss: 3.1146293195281203

Epoch: 5| Step: 1
Training loss: 4.603165300429809
Validation loss: 3.11689105410335

Epoch: 5| Step: 2
Training loss: 3.3756831855187683
Validation loss: 3.1135854005475556

Epoch: 5| Step: 3
Training loss: 3.280648748624733
Validation loss: 3.114632424246745

Epoch: 5| Step: 4
Training loss: 2.8469434979067354
Validation loss: 3.113989729242206

Epoch: 5| Step: 5
Training loss: 2.843472645407489
Validation loss: 3.114090431109151

Epoch: 5| Step: 6
Training loss: 3.699843614727182
Validation loss: 3.115120929467084

Epoch: 5| Step: 7
Training loss: 3.0932710835616923
Validation loss: 3.1162758149191836

Epoch: 5| Step: 8
Training loss: 2.982458967516556
Validation loss: 3.1157774230843054

Epoch: 5| Step: 9
Training loss: 3.0957243813347515
Validation loss: 3.1150259708358288

Epoch: 5| Step: 10
Training loss: 2.833501773390073
Validation loss: 3.1155918316023867

Epoch: 58| Step: 0
Training loss: 3.0540898901920106
Validation loss: 3.112171905695878

Epoch: 5| Step: 1
Training loss: 3.348147344010868
Validation loss: 3.1139536667068684

Epoch: 5| Step: 2
Training loss: 2.8748346364106827
Validation loss: 3.1133984317373637

Epoch: 5| Step: 3
Training loss: 3.789382260388128
Validation loss: 3.1138340277120444

Epoch: 5| Step: 4
Training loss: 4.034163021366264
Validation loss: 3.11486665860539

Epoch: 5| Step: 5
Training loss: 3.8535111703281397
Validation loss: 3.1139720158090887

Epoch: 5| Step: 6
Training loss: 3.5362470261260253
Validation loss: 3.1132350259488435

Epoch: 5| Step: 7
Training loss: 3.256109217787263
Validation loss: 3.1163598651275306

Epoch: 5| Step: 8
Training loss: 3.221117944878662
Validation loss: 3.1136585942101536

Epoch: 5| Step: 9
Training loss: 3.1145647913828474
Validation loss: 3.114665418687244

Epoch: 5| Step: 10
Training loss: 2.747319041741286
Validation loss: 3.117414106595617

Epoch: 59| Step: 0
Training loss: 2.9408246968777507
Validation loss: 3.1135835636029374

Epoch: 5| Step: 1
Training loss: 3.8036021225609926
Validation loss: 3.1130415418520174

Epoch: 5| Step: 2
Training loss: 3.54430777114504
Validation loss: 3.110493090865556

Epoch: 5| Step: 3
Training loss: 3.399574247518664
Validation loss: 3.109203731103001

Epoch: 5| Step: 4
Training loss: 4.09950515738185
Validation loss: 3.107112380164099

Epoch: 5| Step: 5
Training loss: 2.926612644203853
Validation loss: 3.109743836490835

Epoch: 5| Step: 6
Training loss: 3.416787602835181
Validation loss: 3.1066854338818684

Epoch: 5| Step: 7
Training loss: 2.781864569838783
Validation loss: 3.1098035786105793

Epoch: 5| Step: 8
Training loss: 3.323127397095492
Validation loss: 3.106041002062764

Epoch: 5| Step: 9
Training loss: 3.1072555296063973
Validation loss: 3.1058564020312978

Epoch: 5| Step: 10
Training loss: 3.569819243099819
Validation loss: 3.1062596140687333

Epoch: 60| Step: 0
Training loss: 2.847285661274937
Validation loss: 3.1087746013976143

Epoch: 5| Step: 1
Training loss: 3.37032672735827
Validation loss: 3.1066010014456715

Epoch: 5| Step: 2
Training loss: 3.1863583783005045
Validation loss: 3.111192930854022

Epoch: 5| Step: 3
Training loss: 3.6741346832657573
Validation loss: 3.109184760193151

Epoch: 5| Step: 4
Training loss: 3.16801104534998
Validation loss: 3.110694933655391

Epoch: 5| Step: 5
Training loss: 3.045333080897457
Validation loss: 3.108859621307134

Epoch: 5| Step: 6
Training loss: 3.379082788695608
Validation loss: 3.106594119072758

Epoch: 5| Step: 7
Training loss: 3.4902992690787897
Validation loss: 3.1095299387664905

Epoch: 5| Step: 8
Training loss: 3.6538833392332157
Validation loss: 3.1063987358439435

Epoch: 5| Step: 9
Training loss: 3.624287107677784
Validation loss: 3.1044202889392074

Epoch: 5| Step: 10
Training loss: 3.6136330593087482
Validation loss: 3.101658069190724

Epoch: 61| Step: 0
Training loss: 3.567491213835153
Validation loss: 3.1068928115818726

Epoch: 5| Step: 1
Training loss: 2.9920370596972163
Validation loss: 3.1020681565656836

Epoch: 5| Step: 2
Training loss: 3.3163300450424664
Validation loss: 3.101808361705746

Epoch: 5| Step: 3
Training loss: 3.4373856958978695
Validation loss: 3.1007743584798564

Epoch: 5| Step: 4
Training loss: 2.354072523907227
Validation loss: 3.1016047983097415

Epoch: 5| Step: 5
Training loss: 3.7754272522311494
Validation loss: 3.103332427802679

Epoch: 5| Step: 6
Training loss: 3.320677541973709
Validation loss: 3.100702801989691

Epoch: 5| Step: 7
Training loss: 3.353482210129463
Validation loss: 3.101049260332817

Epoch: 5| Step: 8
Training loss: 3.383971828352448
Validation loss: 3.102939587541868

Epoch: 5| Step: 9
Training loss: 3.6894244328721553
Validation loss: 3.100907282753606

Epoch: 5| Step: 10
Training loss: 3.7068659561656636
Validation loss: 3.1000878034813852

Epoch: 62| Step: 0
Training loss: 3.860255337902366
Validation loss: 3.099369729416217

Epoch: 5| Step: 1
Training loss: 2.9507153888247455
Validation loss: 3.101018410176812

Epoch: 5| Step: 2
Training loss: 2.816287732639827
Validation loss: 3.0995034120121785

Epoch: 5| Step: 3
Training loss: 3.2051873243699434
Validation loss: 3.098624823639304

Epoch: 5| Step: 4
Training loss: 3.8150333680059765
Validation loss: 3.0980592251479657

Epoch: 5| Step: 5
Training loss: 3.3031852319688
Validation loss: 3.09882819561778

Epoch: 5| Step: 6
Training loss: 3.093635634032752
Validation loss: 3.0971702280574167

Epoch: 5| Step: 7
Training loss: 3.0940886032841957
Validation loss: 3.097211343108591

Epoch: 5| Step: 8
Training loss: 3.201606949013142
Validation loss: 3.099517562234988

Epoch: 5| Step: 9
Training loss: 3.8237283175933325
Validation loss: 3.098491315774729

Epoch: 5| Step: 10
Training loss: 3.7179609471363673
Validation loss: 3.1047194994044554

Epoch: 63| Step: 0
Training loss: 3.9545898136054602
Validation loss: 3.1010011095838648

Epoch: 5| Step: 1
Training loss: 3.1109653412259486
Validation loss: 3.100352708802095

Epoch: 5| Step: 2
Training loss: 2.6796917706780836
Validation loss: 3.099613953739563

Epoch: 5| Step: 3
Training loss: 4.137413996698678
Validation loss: 3.0967731275009727

Epoch: 5| Step: 4
Training loss: 3.0267650026431827
Validation loss: 3.0978692520533517

Epoch: 5| Step: 5
Training loss: 2.7424132860048838
Validation loss: 3.10045698491211

Epoch: 5| Step: 6
Training loss: 3.8379495164851853
Validation loss: 3.0944277494462815

Epoch: 5| Step: 7
Training loss: 3.2918329961417094
Validation loss: 3.0969669607733565

Epoch: 5| Step: 8
Training loss: 4.011160301853204
Validation loss: 3.0960509294577117

Epoch: 5| Step: 9
Training loss: 3.1389899861156887
Validation loss: 3.0948538204737623

Epoch: 5| Step: 10
Training loss: 2.4265047183160915
Validation loss: 3.0956823919001875

Epoch: 64| Step: 0
Training loss: 3.2462111175288446
Validation loss: 3.092670828781077

Epoch: 5| Step: 1
Training loss: 3.342604111025114
Validation loss: 3.095022515539357

Epoch: 5| Step: 2
Training loss: 3.734336437840255
Validation loss: 3.096161655720942

Epoch: 5| Step: 3
Training loss: 3.286799796492278
Validation loss: 3.0948723084954133

Epoch: 5| Step: 4
Training loss: 3.0282124509672963
Validation loss: 3.098370090135017

Epoch: 5| Step: 5
Training loss: 3.4795082213968906
Validation loss: 3.0944420985138485

Epoch: 5| Step: 6
Training loss: 3.3002956778104173
Validation loss: 3.097658870201263

Epoch: 5| Step: 7
Training loss: 3.553899992180273
Validation loss: 3.102708213899027

Epoch: 5| Step: 8
Training loss: 3.318506804497924
Validation loss: 3.0970382923372846

Epoch: 5| Step: 9
Training loss: 3.285611115488514
Validation loss: 3.095320499264868

Epoch: 5| Step: 10
Training loss: 3.3429635807647284
Validation loss: 3.09708781255524

Epoch: 65| Step: 0
Training loss: 3.3111308885221216
Validation loss: 3.0963483869862847

Epoch: 5| Step: 1
Training loss: 3.562523825047114
Validation loss: 3.0948443506938363

Epoch: 5| Step: 2
Training loss: 3.132919347753205
Validation loss: 3.0926187252762256

Epoch: 5| Step: 3
Training loss: 2.384894590147691
Validation loss: 3.0930745785986566

Epoch: 5| Step: 4
Training loss: 3.791201021435888
Validation loss: 3.0894603803331773

Epoch: 5| Step: 5
Training loss: 3.918203755687234
Validation loss: 3.0922019501962557

Epoch: 5| Step: 6
Training loss: 2.9179594353829743
Validation loss: 3.0979753098294

Epoch: 5| Step: 7
Training loss: 3.17700982347506
Validation loss: 3.0902838060105844

Epoch: 5| Step: 8
Training loss: 3.566489010839781
Validation loss: 3.093595480807166

Epoch: 5| Step: 9
Training loss: 3.557776146771276
Validation loss: 3.095865982164616

Epoch: 5| Step: 10
Training loss: 3.3877479546933253
Validation loss: 3.096317669661402

Epoch: 66| Step: 0
Training loss: 3.0289206452577386
Validation loss: 3.0894993061033116

Epoch: 5| Step: 1
Training loss: 3.1815240228595205
Validation loss: 3.0911072122152112

Epoch: 5| Step: 2
Training loss: 2.9429601690958656
Validation loss: 3.098957644502407

Epoch: 5| Step: 3
Training loss: 3.8491169746683687
Validation loss: 3.1014181752203633

Epoch: 5| Step: 4
Training loss: 3.624656660986552
Validation loss: 3.0961527529869097

Epoch: 5| Step: 5
Training loss: 3.228831825533898
Validation loss: 3.0900778490351155

Epoch: 5| Step: 6
Training loss: 2.8865276268238764
Validation loss: 3.087661682269029

Epoch: 5| Step: 7
Training loss: 3.364524124301654
Validation loss: 3.088757137633406

Epoch: 5| Step: 8
Training loss: 3.9229175656088544
Validation loss: 3.08729257174542

Epoch: 5| Step: 9
Training loss: 3.559102094334399
Validation loss: 3.086884211346815

Epoch: 5| Step: 10
Training loss: 3.17145163430723
Validation loss: 3.0891672869758535

Epoch: 67| Step: 0
Training loss: 2.661088015677997
Validation loss: 3.089766335613364

Epoch: 5| Step: 1
Training loss: 3.5882752222250973
Validation loss: 3.0917558421742792

Epoch: 5| Step: 2
Training loss: 3.579519874514382
Validation loss: 3.0909572710747315

Epoch: 5| Step: 3
Training loss: 2.7323658564553446
Validation loss: 3.0913251702877016

Epoch: 5| Step: 4
Training loss: 2.9636124980665555
Validation loss: 3.091545709352741

Epoch: 5| Step: 5
Training loss: 3.646632007129642
Validation loss: 3.0914555130048464

Epoch: 5| Step: 6
Training loss: 3.7177706158053385
Validation loss: 3.0881912327860395

Epoch: 5| Step: 7
Training loss: 3.32470670854979
Validation loss: 3.089329496198596

Epoch: 5| Step: 8
Training loss: 3.7390783849204206
Validation loss: 3.0827025295110904

Epoch: 5| Step: 9
Training loss: 3.5944592646732705
Validation loss: 3.0846260778583505

Epoch: 5| Step: 10
Training loss: 3.1022024575429388
Validation loss: 3.084589859027174

Epoch: 68| Step: 0
Training loss: 3.4850092426106336
Validation loss: 3.081942445508688

Epoch: 5| Step: 1
Training loss: 3.174827667125002
Validation loss: 3.086006195562334

Epoch: 5| Step: 2
Training loss: 3.312807032912858
Validation loss: 3.082548817140899

Epoch: 5| Step: 3
Training loss: 3.2963983995798265
Validation loss: 3.08828615653008

Epoch: 5| Step: 4
Training loss: 3.8494172534583915
Validation loss: 3.0813230353820105

Epoch: 5| Step: 5
Training loss: 3.1286470112936766
Validation loss: 3.0819939825369187

Epoch: 5| Step: 6
Training loss: 3.2241075981397276
Validation loss: 3.079981358488637

Epoch: 5| Step: 7
Training loss: 3.6014209645030406
Validation loss: 3.0775659858401188

Epoch: 5| Step: 8
Training loss: 2.8691200167316384
Validation loss: 3.0792330712006555

Epoch: 5| Step: 9
Training loss: 3.753017356021308
Validation loss: 3.076471409587929

Epoch: 5| Step: 10
Training loss: 2.9729383938767753
Validation loss: 3.0754712503784867

Epoch: 69| Step: 0
Training loss: 3.5563486095627996
Validation loss: 3.0739956876859402

Epoch: 5| Step: 1
Training loss: 2.786382504200885
Validation loss: 3.072832345335738

Epoch: 5| Step: 2
Training loss: 2.853632262011346
Validation loss: 3.074716812768034

Epoch: 5| Step: 3
Training loss: 2.935705245384959
Validation loss: 3.06993166837423

Epoch: 5| Step: 4
Training loss: 3.503118352007449
Validation loss: 3.0705662089999595

Epoch: 5| Step: 5
Training loss: 3.212211263423796
Validation loss: 3.0716413540323795

Epoch: 5| Step: 6
Training loss: 3.6053110999525972
Validation loss: 3.07144358376483

Epoch: 5| Step: 7
Training loss: 3.7518635252103985
Validation loss: 3.0694391066229283

Epoch: 5| Step: 8
Training loss: 3.774143824211653
Validation loss: 3.0680959136249086

Epoch: 5| Step: 9
Training loss: 3.3896738994920237
Validation loss: 3.069378511198961

Epoch: 5| Step: 10
Training loss: 3.20127450477072
Validation loss: 3.069348951389934

Epoch: 70| Step: 0
Training loss: 4.04036327201813
Validation loss: 3.068354081212965

Epoch: 5| Step: 1
Training loss: 2.998594908685
Validation loss: 3.0706188111000654

Epoch: 5| Step: 2
Training loss: 3.146109882518934
Validation loss: 3.0698799981571954

Epoch: 5| Step: 3
Training loss: 3.2895168253428753
Validation loss: 3.065492736044463

Epoch: 5| Step: 4
Training loss: 3.5012102759333477
Validation loss: 3.0705999558003896

Epoch: 5| Step: 5
Training loss: 3.6423629083539084
Validation loss: 3.0660892646437263

Epoch: 5| Step: 6
Training loss: 3.56120142776716
Validation loss: 3.065558364028712

Epoch: 5| Step: 7
Training loss: 3.319528141500589
Validation loss: 3.062014410896078

Epoch: 5| Step: 8
Training loss: 2.841071240045843
Validation loss: 3.0652940221041916

Epoch: 5| Step: 9
Training loss: 3.156397296754402
Validation loss: 3.066472311557783

Epoch: 5| Step: 10
Training loss: 2.9613215617610456
Validation loss: 3.0648059714380573

Epoch: 71| Step: 0
Training loss: 3.1652888429284745
Validation loss: 3.0643381926880546

Epoch: 5| Step: 1
Training loss: 3.4635504165577133
Validation loss: 3.059915188021464

Epoch: 5| Step: 2
Training loss: 3.5229441768956473
Validation loss: 3.0654884843436268

Epoch: 5| Step: 3
Training loss: 3.5677081402780892
Validation loss: 3.068225693218945

Epoch: 5| Step: 4
Training loss: 2.7374092923120714
Validation loss: 3.068569543331752

Epoch: 5| Step: 5
Training loss: 3.1842985344298467
Validation loss: 3.0708397945302073

Epoch: 5| Step: 6
Training loss: 3.4477011775571564
Validation loss: 3.0755424903374617

Epoch: 5| Step: 7
Training loss: 3.4943303098841696
Validation loss: 3.0817419355861886

Epoch: 5| Step: 8
Training loss: 3.6244531416293273
Validation loss: 3.082449077555548

Epoch: 5| Step: 9
Training loss: 3.079277171490859
Validation loss: 3.0726880227120597

Epoch: 5| Step: 10
Training loss: 3.3020941476414167
Validation loss: 3.063446421037913

Epoch: 72| Step: 0
Training loss: 3.3149609331271432
Validation loss: 3.0587601452517763

Epoch: 5| Step: 1
Training loss: 2.750532445514083
Validation loss: 3.0560040410176748

Epoch: 5| Step: 2
Training loss: 2.9520662216160805
Validation loss: 3.0580839572185723

Epoch: 5| Step: 3
Training loss: 3.531720425489305
Validation loss: 3.05714052178925

Epoch: 5| Step: 4
Training loss: 2.5897659589266713
Validation loss: 3.0564099294456697

Epoch: 5| Step: 5
Training loss: 3.5345021354009405
Validation loss: 3.058203309288197

Epoch: 5| Step: 6
Training loss: 3.5246997948909073
Validation loss: 3.0593257523634447

Epoch: 5| Step: 7
Training loss: 3.4751223206432056
Validation loss: 3.0594513087138155

Epoch: 5| Step: 8
Training loss: 3.544411227855543
Validation loss: 3.059360838204767

Epoch: 5| Step: 9
Training loss: 3.909728919581174
Validation loss: 3.0584313565843417

Epoch: 5| Step: 10
Training loss: 3.301048204811357
Validation loss: 3.0539575480988113

Epoch: 73| Step: 0
Training loss: 2.763869078377206
Validation loss: 3.0585948647742076

Epoch: 5| Step: 1
Training loss: 2.6893696159080176
Validation loss: 3.0596060474222813

Epoch: 5| Step: 2
Training loss: 3.4518032392384406
Validation loss: 3.061090244082161

Epoch: 5| Step: 3
Training loss: 3.4577434603577064
Validation loss: 3.0570446225618393

Epoch: 5| Step: 4
Training loss: 2.911743714205348
Validation loss: 3.0588836631008482

Epoch: 5| Step: 5
Training loss: 3.724072534192802
Validation loss: 3.056531560323406

Epoch: 5| Step: 6
Training loss: 4.255170481905293
Validation loss: 3.059112424803986

Epoch: 5| Step: 7
Training loss: 3.3080917391896825
Validation loss: 3.0590197636423584

Epoch: 5| Step: 8
Training loss: 3.4991407702121307
Validation loss: 3.059632712601655

Epoch: 5| Step: 9
Training loss: 2.6480891806057367
Validation loss: 3.059332312030183

Epoch: 5| Step: 10
Training loss: 3.561537361588493
Validation loss: 3.0601420898766682

Epoch: 74| Step: 0
Training loss: 2.837113233918448
Validation loss: 3.057226714311284

Epoch: 5| Step: 1
Training loss: 3.183513167595956
Validation loss: 3.0621463553868553

Epoch: 5| Step: 2
Training loss: 3.314798385449957
Validation loss: 3.0743175724778116

Epoch: 5| Step: 3
Training loss: 3.2632273948340633
Validation loss: 3.077023130039228

Epoch: 5| Step: 4
Training loss: 3.1471217129774223
Validation loss: 3.065195116125423

Epoch: 5| Step: 5
Training loss: 3.8320156956472675
Validation loss: 3.0678839705418404

Epoch: 5| Step: 6
Training loss: 2.045592160845652
Validation loss: 3.0596573967894516

Epoch: 5| Step: 7
Training loss: 3.1060715192333825
Validation loss: 3.0536776034769915

Epoch: 5| Step: 8
Training loss: 3.8181930310633767
Validation loss: 3.055330647133532

Epoch: 5| Step: 9
Training loss: 3.6111694103001724
Validation loss: 3.0510995980357465

Epoch: 5| Step: 10
Training loss: 4.10070977929062
Validation loss: 3.051178997528569

Epoch: 75| Step: 0
Training loss: 2.97648560432171
Validation loss: 3.049552800507374

Epoch: 5| Step: 1
Training loss: 3.686852091103575
Validation loss: 3.0510200401888596

Epoch: 5| Step: 2
Training loss: 3.5936155874574953
Validation loss: 3.0484392608534727

Epoch: 5| Step: 3
Training loss: 3.3252688765265717
Validation loss: 3.0497316862770525

Epoch: 5| Step: 4
Training loss: 3.1633132612625317
Validation loss: 3.049522161616335

Epoch: 5| Step: 5
Training loss: 3.308429448215325
Validation loss: 3.0487379362797014

Epoch: 5| Step: 6
Training loss: 3.3121943782674155
Validation loss: 3.0501440558530306

Epoch: 5| Step: 7
Training loss: 2.704516102490945
Validation loss: 3.0471191392578345

Epoch: 5| Step: 8
Training loss: 3.2421961772756624
Validation loss: 3.047668818916472

Epoch: 5| Step: 9
Training loss: 3.5116949876229557
Validation loss: 3.045375316699787

Epoch: 5| Step: 10
Training loss: 3.6724357014552673
Validation loss: 3.0474054598913307

Testing loss: 3.2405453119439955
