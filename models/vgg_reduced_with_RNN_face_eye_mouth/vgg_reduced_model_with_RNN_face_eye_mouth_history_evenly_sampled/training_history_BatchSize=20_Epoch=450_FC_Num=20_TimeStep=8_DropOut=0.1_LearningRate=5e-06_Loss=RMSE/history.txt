Epoch: 1| Step: 0
Training loss: 5.567561043865873
Validation loss: 5.811922886029074

Epoch: 5| Step: 1
Training loss: 5.538414060356546
Validation loss: 5.807164358160567

Epoch: 5| Step: 2
Training loss: 6.082603550165532
Validation loss: 5.802066497710559

Epoch: 5| Step: 3
Training loss: 5.8673441900265475
Validation loss: 5.797573181886724

Epoch: 5| Step: 4
Training loss: 4.307228072533801
Validation loss: 5.793004029459973

Epoch: 5| Step: 5
Training loss: 5.886812063792598
Validation loss: 5.788529890553483

Epoch: 5| Step: 6
Training loss: 5.688364487227482
Validation loss: 5.784588866824822

Epoch: 5| Step: 7
Training loss: 6.1347957830164495
Validation loss: 5.780038606373026

Epoch: 5| Step: 8
Training loss: 6.354977748780872
Validation loss: 5.775611426084263

Epoch: 5| Step: 9
Training loss: 6.672072825301955
Validation loss: 5.771233778394836

Epoch: 5| Step: 10
Training loss: 5.598720452038416
Validation loss: 5.766199669726904

Epoch: 2| Step: 0
Training loss: 6.0336267403482715
Validation loss: 5.761313562872593

Epoch: 5| Step: 1
Training loss: 4.822899419480444
Validation loss: 5.756258158680055

Epoch: 5| Step: 2
Training loss: 5.2432072609798475
Validation loss: 5.7510004194282045

Epoch: 5| Step: 3
Training loss: 5.9786776919800655
Validation loss: 5.745398559530833

Epoch: 5| Step: 4
Training loss: 5.225572706165504
Validation loss: 5.7390728506428985

Epoch: 5| Step: 5
Training loss: 6.3023618358098625
Validation loss: 5.733311218301104

Epoch: 5| Step: 6
Training loss: 5.014512743873694
Validation loss: 5.727324313912038

Epoch: 5| Step: 7
Training loss: 6.656491557291643
Validation loss: 5.721008199210832

Epoch: 5| Step: 8
Training loss: 6.4371391121157595
Validation loss: 5.7135883367943165

Epoch: 5| Step: 9
Training loss: 4.831954474367324
Validation loss: 5.706513401783689

Epoch: 5| Step: 10
Training loss: 6.568186303659488
Validation loss: 5.69838681869994

Epoch: 3| Step: 0
Training loss: 6.820919328853161
Validation loss: 5.690870023812907

Epoch: 5| Step: 1
Training loss: 5.2359434596215335
Validation loss: 5.682040916082015

Epoch: 5| Step: 2
Training loss: 5.998029385252098
Validation loss: 5.6726831795827275

Epoch: 5| Step: 3
Training loss: 6.988719570344067
Validation loss: 5.663508033756311

Epoch: 5| Step: 4
Training loss: 5.345945743717887
Validation loss: 5.6531719035328

Epoch: 5| Step: 5
Training loss: 4.6954973282829275
Validation loss: 5.643324154064628

Epoch: 5| Step: 6
Training loss: 5.177649648024241
Validation loss: 5.632219224478338

Epoch: 5| Step: 7
Training loss: 5.496958498513064
Validation loss: 5.622285630521147

Epoch: 5| Step: 8
Training loss: 5.796382091367088
Validation loss: 5.609931405648519

Epoch: 5| Step: 9
Training loss: 5.555261939025166
Validation loss: 5.598698549837764

Epoch: 5| Step: 10
Training loss: 4.802023643845353
Validation loss: 5.585453669760865

Epoch: 4| Step: 0
Training loss: 5.8354776346802595
Validation loss: 5.573350184034838

Epoch: 5| Step: 1
Training loss: 4.925586475753619
Validation loss: 5.560112546258415

Epoch: 5| Step: 2
Training loss: 4.983203905821252
Validation loss: 5.546214758681873

Epoch: 5| Step: 3
Training loss: 6.072493035103206
Validation loss: 5.531808835926846

Epoch: 5| Step: 4
Training loss: 5.702989550510541
Validation loss: 5.518050267053061

Epoch: 5| Step: 5
Training loss: 5.632160461188166
Validation loss: 5.502624325634067

Epoch: 5| Step: 6
Training loss: 4.9536896874112974
Validation loss: 5.487430797832633

Epoch: 5| Step: 7
Training loss: 5.8013829391230205
Validation loss: 5.471396727084363

Epoch: 5| Step: 8
Training loss: 5.427818712236103
Validation loss: 5.456011713889573

Epoch: 5| Step: 9
Training loss: 5.2738329929820695
Validation loss: 5.439422940668481

Epoch: 5| Step: 10
Training loss: 6.262317269527991
Validation loss: 5.421551341924411

Epoch: 5| Step: 0
Training loss: 5.829296495447451
Validation loss: 5.403958364779889

Epoch: 5| Step: 1
Training loss: 5.400707248008035
Validation loss: 5.38552902915941

Epoch: 5| Step: 2
Training loss: 5.481480369815962
Validation loss: 5.367692777114341

Epoch: 5| Step: 3
Training loss: 4.910989015498972
Validation loss: 5.348756872178073

Epoch: 5| Step: 4
Training loss: 4.664437897110014
Validation loss: 5.328145639477435

Epoch: 5| Step: 5
Training loss: 5.419013859749595
Validation loss: 5.3095821621967865

Epoch: 5| Step: 6
Training loss: 4.513563695425823
Validation loss: 5.287509487056995

Epoch: 5| Step: 7
Training loss: 4.955563110627106
Validation loss: 5.266099911983796

Epoch: 5| Step: 8
Training loss: 5.948128272822567
Validation loss: 5.243953825081175

Epoch: 5| Step: 9
Training loss: 6.503324392140843
Validation loss: 5.22061681881918

Epoch: 5| Step: 10
Training loss: 4.828294078249034
Validation loss: 5.19510121705036

Epoch: 6| Step: 0
Training loss: 6.514869115514537
Validation loss: 5.169550190610026

Epoch: 5| Step: 1
Training loss: 5.2237426267025535
Validation loss: 5.142278374520786

Epoch: 5| Step: 2
Training loss: 5.058571503932745
Validation loss: 5.117018288090478

Epoch: 5| Step: 3
Training loss: 6.304933148482697
Validation loss: 5.090444319967841

Epoch: 5| Step: 4
Training loss: 5.298865200409365
Validation loss: 5.065251038300939

Epoch: 5| Step: 5
Training loss: 4.121613470634815
Validation loss: 5.039647589526812

Epoch: 5| Step: 6
Training loss: 4.458642372519944
Validation loss: 5.015673440658355

Epoch: 5| Step: 7
Training loss: 4.030393051025166
Validation loss: 4.989791748960877

Epoch: 5| Step: 8
Training loss: 4.3565879307592885
Validation loss: 4.967062370149892

Epoch: 5| Step: 9
Training loss: 4.82967611044334
Validation loss: 4.945031072322635

Epoch: 5| Step: 10
Training loss: 5.420865099513548
Validation loss: 4.922841564875195

Epoch: 7| Step: 0
Training loss: 4.784554530088627
Validation loss: 4.898637599030625

Epoch: 5| Step: 1
Training loss: 4.635204707525231
Validation loss: 4.876077377793859

Epoch: 5| Step: 2
Training loss: 4.868849958732996
Validation loss: 4.853618910793059

Epoch: 5| Step: 3
Training loss: 4.964872562736025
Validation loss: 4.832509151255042

Epoch: 5| Step: 4
Training loss: 4.993251060415824
Validation loss: 4.8106979492881505

Epoch: 5| Step: 5
Training loss: 4.653589704787362
Validation loss: 4.790897076810588

Epoch: 5| Step: 6
Training loss: 4.818794790571869
Validation loss: 4.770684172164996

Epoch: 5| Step: 7
Training loss: 5.094658706210228
Validation loss: 4.751365824704484

Epoch: 5| Step: 8
Training loss: 4.840397419021734
Validation loss: 4.731500677484159

Epoch: 5| Step: 9
Training loss: 4.769124331599962
Validation loss: 4.711782232063347

Epoch: 5| Step: 10
Training loss: 5.162308526356117
Validation loss: 4.692856303359133

Epoch: 8| Step: 0
Training loss: 5.442223963258014
Validation loss: 4.674744498541429

Epoch: 5| Step: 1
Training loss: 4.268849254699747
Validation loss: 4.657975071017394

Epoch: 5| Step: 2
Training loss: 4.547631059952675
Validation loss: 4.642430145775232

Epoch: 5| Step: 3
Training loss: 4.4579101551803575
Validation loss: 4.626925035949465

Epoch: 5| Step: 4
Training loss: 2.903170523065866
Validation loss: 4.612016950550625

Epoch: 5| Step: 5
Training loss: 5.491009907483062
Validation loss: 4.600634692590826

Epoch: 5| Step: 6
Training loss: 5.260626438100337
Validation loss: 4.588212576199444

Epoch: 5| Step: 7
Training loss: 4.027833659051147
Validation loss: 4.576869775862489

Epoch: 5| Step: 8
Training loss: 4.576253150286576
Validation loss: 4.566800725648975

Epoch: 5| Step: 9
Training loss: 5.097700213831015
Validation loss: 4.555994011379652

Epoch: 5| Step: 10
Training loss: 5.059713844983255
Validation loss: 4.5470963792690275

Epoch: 9| Step: 0
Training loss: 4.248085488330256
Validation loss: 4.538628334733742

Epoch: 5| Step: 1
Training loss: 4.556575743617593
Validation loss: 4.528542049696984

Epoch: 5| Step: 2
Training loss: 4.397592466769082
Validation loss: 4.521220986433201

Epoch: 5| Step: 3
Training loss: 3.295205656357125
Validation loss: 4.511350654608865

Epoch: 5| Step: 4
Training loss: 5.110116514008577
Validation loss: 4.505369678884652

Epoch: 5| Step: 5
Training loss: 5.09617641205906
Validation loss: 4.497090352663003

Epoch: 5| Step: 6
Training loss: 5.376240431904122
Validation loss: 4.489921586584602

Epoch: 5| Step: 7
Training loss: 4.945169214761217
Validation loss: 4.483513319006888

Epoch: 5| Step: 8
Training loss: 4.8899880868965555
Validation loss: 4.4755270400962734

Epoch: 5| Step: 9
Training loss: 3.484787989205644
Validation loss: 4.468478624195817

Epoch: 5| Step: 10
Training loss: 4.776516035588326
Validation loss: 4.462110230460428

Epoch: 10| Step: 0
Training loss: 4.366203838795672
Validation loss: 4.455866558569589

Epoch: 5| Step: 1
Training loss: 3.548828393729351
Validation loss: 4.44985841067501

Epoch: 5| Step: 2
Training loss: 5.1172376324476545
Validation loss: 4.444468040728398

Epoch: 5| Step: 3
Training loss: 4.508364004053132
Validation loss: 4.43849811943786

Epoch: 5| Step: 4
Training loss: 3.027893567763345
Validation loss: 4.434270505981919

Epoch: 5| Step: 5
Training loss: 4.865421372736111
Validation loss: 4.428769269680439

Epoch: 5| Step: 6
Training loss: 4.547368917479125
Validation loss: 4.425029771826436

Epoch: 5| Step: 7
Training loss: 5.409343562043069
Validation loss: 4.420469050036159

Epoch: 5| Step: 8
Training loss: 4.398681850658835
Validation loss: 4.415078940950434

Epoch: 5| Step: 9
Training loss: 4.756326377546142
Validation loss: 4.411166117195619

Epoch: 5| Step: 10
Training loss: 4.969509042787101
Validation loss: 4.407684727936062

Epoch: 11| Step: 0
Training loss: 4.470482763723295
Validation loss: 4.402798437297773

Epoch: 5| Step: 1
Training loss: 4.8579863008295785
Validation loss: 4.398629034009584

Epoch: 5| Step: 2
Training loss: 3.8554620713752947
Validation loss: 4.394281354902024

Epoch: 5| Step: 3
Training loss: 4.762710430472469
Validation loss: 4.391076082990091

Epoch: 5| Step: 4
Training loss: 4.597004470713484
Validation loss: 4.387442194130119

Epoch: 5| Step: 5
Training loss: 4.539483528504802
Validation loss: 4.383441992076201

Epoch: 5| Step: 6
Training loss: 3.8536646060595485
Validation loss: 4.379125058492696

Epoch: 5| Step: 7
Training loss: 4.734474508416917
Validation loss: 4.375547594528555

Epoch: 5| Step: 8
Training loss: 4.876095770905348
Validation loss: 4.3717352597357335

Epoch: 5| Step: 9
Training loss: 3.744218311090901
Validation loss: 4.368087133190232

Epoch: 5| Step: 10
Training loss: 5.084913768956139
Validation loss: 4.366046520560412

Epoch: 12| Step: 0
Training loss: 5.839536075716104
Validation loss: 4.360379815448465

Epoch: 5| Step: 1
Training loss: 3.7835700113708515
Validation loss: 4.357714128413279

Epoch: 5| Step: 2
Training loss: 5.240717902181821
Validation loss: 4.353942155630987

Epoch: 5| Step: 3
Training loss: 3.9964072066317593
Validation loss: 4.350465140381645

Epoch: 5| Step: 4
Training loss: 4.020909494788859
Validation loss: 4.344781164943445

Epoch: 5| Step: 5
Training loss: 4.496531103158292
Validation loss: 4.342469302877777

Epoch: 5| Step: 6
Training loss: 4.6066410556049995
Validation loss: 4.337792414710026

Epoch: 5| Step: 7
Training loss: 3.159794092350748
Validation loss: 4.335229673279013

Epoch: 5| Step: 8
Training loss: 3.987127931270807
Validation loss: 4.331091619638558

Epoch: 5| Step: 9
Training loss: 4.523401448002382
Validation loss: 4.325525651406918

Epoch: 5| Step: 10
Training loss: 4.899775223539437
Validation loss: 4.322513510620895

Epoch: 13| Step: 0
Training loss: 4.93590780734085
Validation loss: 4.318053571874349

Epoch: 5| Step: 1
Training loss: 4.171883686642408
Validation loss: 4.313891121805988

Epoch: 5| Step: 2
Training loss: 4.56124839860047
Validation loss: 4.3118539379447895

Epoch: 5| Step: 3
Training loss: 4.151410949950175
Validation loss: 4.305729956154039

Epoch: 5| Step: 4
Training loss: 4.722639893155607
Validation loss: 4.301288177978523

Epoch: 5| Step: 5
Training loss: 4.638872322971716
Validation loss: 4.296139448494542

Epoch: 5| Step: 6
Training loss: 4.2541452275905725
Validation loss: 4.291749631846588

Epoch: 5| Step: 7
Training loss: 4.848725353944416
Validation loss: 4.287046566647771

Epoch: 5| Step: 8
Training loss: 4.584833951416403
Validation loss: 4.282828512824512

Epoch: 5| Step: 9
Training loss: 3.779283248521946
Validation loss: 4.277286731929739

Epoch: 5| Step: 10
Training loss: 3.701173549842959
Validation loss: 4.272320935446188

Epoch: 14| Step: 0
Training loss: 3.707314226225322
Validation loss: 4.269666377964681

Epoch: 5| Step: 1
Training loss: 5.915055104738235
Validation loss: 4.261687037323074

Epoch: 5| Step: 2
Training loss: 4.418208351012771
Validation loss: 4.257904389522468

Epoch: 5| Step: 3
Training loss: 4.950908369467297
Validation loss: 4.2545735761130565

Epoch: 5| Step: 4
Training loss: 4.463002597063605
Validation loss: 4.247254605074598

Epoch: 5| Step: 5
Training loss: 4.691492237125704
Validation loss: 4.242945047146331

Epoch: 5| Step: 6
Training loss: 3.507750920560198
Validation loss: 4.239634198077181

Epoch: 5| Step: 7
Training loss: 4.210236952902409
Validation loss: 4.235690789383551

Epoch: 5| Step: 8
Training loss: 3.8187305006662555
Validation loss: 4.233838799701611

Epoch: 5| Step: 9
Training loss: 4.348014659109382
Validation loss: 4.228741919340252

Epoch: 5| Step: 10
Training loss: 3.3594698160674636
Validation loss: 4.222812907212825

Epoch: 15| Step: 0
Training loss: 3.6329109424665993
Validation loss: 4.214797360422692

Epoch: 5| Step: 1
Training loss: 5.1383819788287015
Validation loss: 4.211358440967091

Epoch: 5| Step: 2
Training loss: 4.05500242447222
Validation loss: 4.206312489748969

Epoch: 5| Step: 3
Training loss: 4.0057870011136405
Validation loss: 4.20224166622987

Epoch: 5| Step: 4
Training loss: 4.882520303757227
Validation loss: 4.196853672068351

Epoch: 5| Step: 5
Training loss: 3.609003221264652
Validation loss: 4.1898347274988055

Epoch: 5| Step: 6
Training loss: 3.846225964530302
Validation loss: 4.184165056381189

Epoch: 5| Step: 7
Training loss: 5.30062760289941
Validation loss: 4.180902703758475

Epoch: 5| Step: 8
Training loss: 4.208456182417853
Validation loss: 4.173935850702051

Epoch: 5| Step: 9
Training loss: 4.299014470915698
Validation loss: 4.169183456217444

Epoch: 5| Step: 10
Training loss: 4.148562786846926
Validation loss: 4.165423912200228

Epoch: 16| Step: 0
Training loss: 5.293798402747376
Validation loss: 4.159821708801041

Epoch: 5| Step: 1
Training loss: 4.456468257401104
Validation loss: 4.154548086232959

Epoch: 5| Step: 2
Training loss: 3.363872976674096
Validation loss: 4.1505133352748445

Epoch: 5| Step: 3
Training loss: 4.3957947402392925
Validation loss: 4.1458630972230965

Epoch: 5| Step: 4
Training loss: 4.42070266765428
Validation loss: 4.141459944613578

Epoch: 5| Step: 5
Training loss: 4.261227531340299
Validation loss: 4.135458684432817

Epoch: 5| Step: 6
Training loss: 3.4676320791908273
Validation loss: 4.130873820225481

Epoch: 5| Step: 7
Training loss: 4.299905935633691
Validation loss: 4.124220329725255

Epoch: 5| Step: 8
Training loss: 4.622541031683722
Validation loss: 4.120975689153588

Epoch: 5| Step: 9
Training loss: 4.063703622779233
Validation loss: 4.117605097224169

Epoch: 5| Step: 10
Training loss: 4.014122113965294
Validation loss: 4.1122090419976605

Epoch: 17| Step: 0
Training loss: 3.010787958569937
Validation loss: 4.106627002570329

Epoch: 5| Step: 1
Training loss: 3.7925580133314853
Validation loss: 4.101481604024944

Epoch: 5| Step: 2
Training loss: 5.072380502345156
Validation loss: 4.097038317938147

Epoch: 5| Step: 3
Training loss: 4.107272114111792
Validation loss: 4.092642322319956

Epoch: 5| Step: 4
Training loss: 3.2493030094155686
Validation loss: 4.087542846310619

Epoch: 5| Step: 5
Training loss: 4.685128998339224
Validation loss: 4.083380946036011

Epoch: 5| Step: 6
Training loss: 5.009611428548033
Validation loss: 4.077930741741386

Epoch: 5| Step: 7
Training loss: 4.253075776946976
Validation loss: 4.0753489533334335

Epoch: 5| Step: 8
Training loss: 4.532865670335129
Validation loss: 4.07260348332793

Epoch: 5| Step: 9
Training loss: 3.6994082312711423
Validation loss: 4.066400283475437

Epoch: 5| Step: 10
Training loss: 4.5695960893496705
Validation loss: 4.059140465686146

Epoch: 18| Step: 0
Training loss: 4.365342953417538
Validation loss: 4.056883038182879

Epoch: 5| Step: 1
Training loss: 4.108109776189962
Validation loss: 4.052535446904803

Epoch: 5| Step: 2
Training loss: 3.5638886806943546
Validation loss: 4.048011959937558

Epoch: 5| Step: 3
Training loss: 5.116727339460432
Validation loss: 4.041885285490167

Epoch: 5| Step: 4
Training loss: 4.127542348051796
Validation loss: 4.0385274596379945

Epoch: 5| Step: 5
Training loss: 4.458288578747634
Validation loss: 4.036465358615548

Epoch: 5| Step: 6
Training loss: 3.487235225347831
Validation loss: 4.033359673506513

Epoch: 5| Step: 7
Training loss: 3.8512706839486732
Validation loss: 4.028140657905345

Epoch: 5| Step: 8
Training loss: 4.3240551043165505
Validation loss: 4.020650288307156

Epoch: 5| Step: 9
Training loss: 4.096447703689441
Validation loss: 4.017054302832086

Epoch: 5| Step: 10
Training loss: 4.2948590352525455
Validation loss: 4.013286028293525

Epoch: 19| Step: 0
Training loss: 3.5266938651129185
Validation loss: 4.010757168891021

Epoch: 5| Step: 1
Training loss: 4.4093573685475365
Validation loss: 4.0070906186893165

Epoch: 5| Step: 2
Training loss: 4.584733483275871
Validation loss: 4.000600075061464

Epoch: 5| Step: 3
Training loss: 4.435028247420744
Validation loss: 3.9979011094721617

Epoch: 5| Step: 4
Training loss: 4.359784069488804
Validation loss: 3.9951831697285023

Epoch: 5| Step: 5
Training loss: 3.9794534842826517
Validation loss: 3.99020528088801

Epoch: 5| Step: 6
Training loss: 4.4490528427418985
Validation loss: 3.9828575440855563

Epoch: 5| Step: 7
Training loss: 3.869699729487926
Validation loss: 3.9807234269454552

Epoch: 5| Step: 8
Training loss: 3.529907916761834
Validation loss: 3.97711913849048

Epoch: 5| Step: 9
Training loss: 4.053053451294805
Validation loss: 3.9735736441660796

Epoch: 5| Step: 10
Training loss: 4.231019439501138
Validation loss: 3.9700789212590393

Epoch: 20| Step: 0
Training loss: 3.793538703878893
Validation loss: 3.9648970961587446

Epoch: 5| Step: 1
Training loss: 4.808403550576864
Validation loss: 3.96367347912816

Epoch: 5| Step: 2
Training loss: 4.5268145721796955
Validation loss: 3.9666576339551276

Epoch: 5| Step: 3
Training loss: 4.82780440664221
Validation loss: 3.9535366396721563

Epoch: 5| Step: 4
Training loss: 3.5136975239214623
Validation loss: 3.9506442964993145

Epoch: 5| Step: 5
Training loss: 3.7537442905764964
Validation loss: 3.949258694676419

Epoch: 5| Step: 6
Training loss: 4.120455463751521
Validation loss: 3.9480546734581554

Epoch: 5| Step: 7
Training loss: 3.73315345864439
Validation loss: 3.9438374880579623

Epoch: 5| Step: 8
Training loss: 4.260600389966583
Validation loss: 3.940041186422103

Epoch: 5| Step: 9
Training loss: 3.954485632704043
Validation loss: 3.933695108334078

Epoch: 5| Step: 10
Training loss: 3.5448258316018295
Validation loss: 3.9294416802946732

Epoch: 21| Step: 0
Training loss: 4.4059495755850016
Validation loss: 3.929959127654112

Epoch: 5| Step: 1
Training loss: 3.7276371779807196
Validation loss: 3.9264521960570704

Epoch: 5| Step: 2
Training loss: 3.7816512470314874
Validation loss: 3.9169038811148265

Epoch: 5| Step: 3
Training loss: 3.663869889327126
Validation loss: 3.9173808423080985

Epoch: 5| Step: 4
Training loss: 4.638594571724293
Validation loss: 3.9144957165147187

Epoch: 5| Step: 5
Training loss: 4.092127820745383
Validation loss: 3.9100588107317122

Epoch: 5| Step: 6
Training loss: 3.8714955387949472
Validation loss: 3.9071090337780108

Epoch: 5| Step: 7
Training loss: 4.334258983244759
Validation loss: 3.9031675781958444

Epoch: 5| Step: 8
Training loss: 3.6197033036605033
Validation loss: 3.900663885295569

Epoch: 5| Step: 9
Training loss: 4.179536905873496
Validation loss: 3.898865507781372

Epoch: 5| Step: 10
Training loss: 4.392398571043978
Validation loss: 3.8947683939280577

Epoch: 22| Step: 0
Training loss: 4.161997786001178
Validation loss: 3.892067860581714

Epoch: 5| Step: 1
Training loss: 3.791682833682516
Validation loss: 3.88833894830682

Epoch: 5| Step: 2
Training loss: 3.965091250356948
Validation loss: 3.8842916998119645

Epoch: 5| Step: 3
Training loss: 4.263701623593539
Validation loss: 3.882351849444697

Epoch: 5| Step: 4
Training loss: 4.335122961568558
Validation loss: 3.879998581144638

Epoch: 5| Step: 5
Training loss: 4.023537762327816
Validation loss: 3.8754910499628092

Epoch: 5| Step: 6
Training loss: 3.632483420284946
Validation loss: 3.872595915574827

Epoch: 5| Step: 7
Training loss: 3.2739270556601734
Validation loss: 3.869956915786412

Epoch: 5| Step: 8
Training loss: 4.684822436767277
Validation loss: 3.8651762998514765

Epoch: 5| Step: 9
Training loss: 4.569736333540597
Validation loss: 3.862565206891978

Epoch: 5| Step: 10
Training loss: 3.427127238787589
Validation loss: 3.8567742561538463

Epoch: 23| Step: 0
Training loss: 4.448231575007922
Validation loss: 3.856239857881936

Epoch: 5| Step: 1
Training loss: 3.848127152338707
Validation loss: 3.8495445244129494

Epoch: 5| Step: 2
Training loss: 3.8582595263370765
Validation loss: 3.8488283382532646

Epoch: 5| Step: 3
Training loss: 3.9056210431148943
Validation loss: 3.844985367216536

Epoch: 5| Step: 4
Training loss: 4.378922148513177
Validation loss: 3.844171553788267

Epoch: 5| Step: 5
Training loss: 4.325305226751683
Validation loss: 3.835890230644839

Epoch: 5| Step: 6
Training loss: 3.8216176056294837
Validation loss: 3.831943016846526

Epoch: 5| Step: 7
Training loss: 4.246501604721968
Validation loss: 3.8300008484308172

Epoch: 5| Step: 8
Training loss: 4.010962246861961
Validation loss: 3.8259104280108134

Epoch: 5| Step: 9
Training loss: 3.7613674803947035
Validation loss: 3.822401928751112

Epoch: 5| Step: 10
Training loss: 3.207245795151213
Validation loss: 3.819254326188942

Epoch: 24| Step: 0
Training loss: 4.179686815493518
Validation loss: 3.814618002956773

Epoch: 5| Step: 1
Training loss: 3.885772129738244
Validation loss: 3.809873704161416

Epoch: 5| Step: 2
Training loss: 2.8914354992314495
Validation loss: 3.8005960160056533

Epoch: 5| Step: 3
Training loss: 3.8725282722953183
Validation loss: 3.7989430961711697

Epoch: 5| Step: 4
Training loss: 3.681618995501782
Validation loss: 3.796960781527236

Epoch: 5| Step: 5
Training loss: 3.7248410901474154
Validation loss: 3.791828147120743

Epoch: 5| Step: 6
Training loss: 3.9723239936032724
Validation loss: 3.7887156994350155

Epoch: 5| Step: 7
Training loss: 3.715291057495595
Validation loss: 3.783875380692877

Epoch: 5| Step: 8
Training loss: 4.719392240157103
Validation loss: 3.780148063473109

Epoch: 5| Step: 9
Training loss: 3.609365752237206
Validation loss: 3.775920147947197

Epoch: 5| Step: 10
Training loss: 5.1350941688943825
Validation loss: 3.7720053730078202

Epoch: 25| Step: 0
Training loss: 3.722710175739077
Validation loss: 3.770061032884396

Epoch: 5| Step: 1
Training loss: 2.922345944562715
Validation loss: 3.7675724936089443

Epoch: 5| Step: 2
Training loss: 3.3695190570981284
Validation loss: 3.764470304570204

Epoch: 5| Step: 3
Training loss: 4.419771051130271
Validation loss: 3.7631969552762414

Epoch: 5| Step: 4
Training loss: 4.336258610012802
Validation loss: 3.753319041949614

Epoch: 5| Step: 5
Training loss: 4.27182841299979
Validation loss: 3.752557684873442

Epoch: 5| Step: 6
Training loss: 4.546822983486829
Validation loss: 3.7494375292433326

Epoch: 5| Step: 7
Training loss: 3.393197064114899
Validation loss: 3.7464287847458104

Epoch: 5| Step: 8
Training loss: 3.637194150670658
Validation loss: 3.7428051307864583

Epoch: 5| Step: 9
Training loss: 4.3313080138357485
Validation loss: 3.739535930103559

Epoch: 5| Step: 10
Training loss: 3.944111314475559
Validation loss: 3.734930859924469

Epoch: 26| Step: 0
Training loss: 3.7659619445741823
Validation loss: 3.7305339580537

Epoch: 5| Step: 1
Training loss: 4.78570289447787
Validation loss: 3.7305169909299734

Epoch: 5| Step: 2
Training loss: 3.7752106412009665
Validation loss: 3.728060506677784

Epoch: 5| Step: 3
Training loss: 3.610140104243272
Validation loss: 3.724794925843115

Epoch: 5| Step: 4
Training loss: 3.4211328825244625
Validation loss: 3.718147610270775

Epoch: 5| Step: 5
Training loss: 3.877602226439589
Validation loss: 3.7160412229629123

Epoch: 5| Step: 6
Training loss: 3.709478922852825
Validation loss: 3.711007436580126

Epoch: 5| Step: 7
Training loss: 4.267014944246601
Validation loss: 3.708000391224881

Epoch: 5| Step: 8
Training loss: 3.305527312071714
Validation loss: 3.7063995943160686

Epoch: 5| Step: 9
Training loss: 4.481513090404598
Validation loss: 3.708670753004427

Epoch: 5| Step: 10
Training loss: 3.6148227022414443
Validation loss: 3.7046334810722743

Epoch: 27| Step: 0
Training loss: 3.8799367651751506
Validation loss: 3.698019670261932

Epoch: 5| Step: 1
Training loss: 3.884704251809066
Validation loss: 3.694892791998231

Epoch: 5| Step: 2
Training loss: 3.863147328276293
Validation loss: 3.688558680622281

Epoch: 5| Step: 3
Training loss: 3.293135126329637
Validation loss: 3.6844065409580504

Epoch: 5| Step: 4
Training loss: 3.9388626405038343
Validation loss: 3.6843447665797004

Epoch: 5| Step: 5
Training loss: 4.572024919577142
Validation loss: 3.6828595512417093

Epoch: 5| Step: 6
Training loss: 4.242226166663099
Validation loss: 3.680755674081693

Epoch: 5| Step: 7
Training loss: 4.153735095493004
Validation loss: 3.676533455240611

Epoch: 5| Step: 8
Training loss: 3.1411458812357935
Validation loss: 3.6730548932700247

Epoch: 5| Step: 9
Training loss: 3.6837774334090874
Validation loss: 3.670916079648159

Epoch: 5| Step: 10
Training loss: 3.671947202581339
Validation loss: 3.6688658019584057

Epoch: 28| Step: 0
Training loss: 4.064288875225197
Validation loss: 3.6643733481273206

Epoch: 5| Step: 1
Training loss: 4.35597955419753
Validation loss: 3.6612323490591026

Epoch: 5| Step: 2
Training loss: 4.223729564462647
Validation loss: 3.6604400569210864

Epoch: 5| Step: 3
Training loss: 3.6887523011756578
Validation loss: 3.657034463852533

Epoch: 5| Step: 4
Training loss: 4.310922970113018
Validation loss: 3.6547677487317407

Epoch: 5| Step: 5
Training loss: 3.180157151087857
Validation loss: 3.652796072131479

Epoch: 5| Step: 6
Training loss: 3.708068380998935
Validation loss: 3.6486490763639634

Epoch: 5| Step: 7
Training loss: 4.135360653335365
Validation loss: 3.647877528927286

Epoch: 5| Step: 8
Training loss: 2.148941702199742
Validation loss: 3.6430349769316686

Epoch: 5| Step: 9
Training loss: 3.7824428978118783
Validation loss: 3.6423648565824513

Epoch: 5| Step: 10
Training loss: 4.213085299164629
Validation loss: 3.6468531580081094

Epoch: 29| Step: 0
Training loss: 3.709731249264893
Validation loss: 3.636988299085767

Epoch: 5| Step: 1
Training loss: 3.314981646594856
Validation loss: 3.638635525471146

Epoch: 5| Step: 2
Training loss: 4.826812862128162
Validation loss: 3.641111040509819

Epoch: 5| Step: 3
Training loss: 3.5036023538695895
Validation loss: 3.6368072010138675

Epoch: 5| Step: 4
Training loss: 3.9600511270170324
Validation loss: 3.6332656575952593

Epoch: 5| Step: 5
Training loss: 3.903181411909693
Validation loss: 3.6313357587869435

Epoch: 5| Step: 6
Training loss: 4.190316462981826
Validation loss: 3.6300763748122407

Epoch: 5| Step: 7
Training loss: 2.3940527781737386
Validation loss: 3.6264647543239175

Epoch: 5| Step: 8
Training loss: 3.543423893639406
Validation loss: 3.625680762651525

Epoch: 5| Step: 9
Training loss: 4.054875657965667
Validation loss: 3.6214395845034053

Epoch: 5| Step: 10
Training loss: 4.231918016270583
Validation loss: 3.620144675532005

Epoch: 30| Step: 0
Training loss: 4.670728664036454
Validation loss: 3.6147326636307553

Epoch: 5| Step: 1
Training loss: 3.6419558732503385
Validation loss: 3.6116096728775724

Epoch: 5| Step: 2
Training loss: 3.2670150791610713
Validation loss: 3.610753016915958

Epoch: 5| Step: 3
Training loss: 4.055876981867302
Validation loss: 3.608118604342935

Epoch: 5| Step: 4
Training loss: 3.7632713718454927
Validation loss: 3.6068079740570296

Epoch: 5| Step: 5
Training loss: 3.8113351511990685
Validation loss: 3.6031945775507377

Epoch: 5| Step: 6
Training loss: 3.5357046471226314
Validation loss: 3.6002855664479094

Epoch: 5| Step: 7
Training loss: 3.4923394701360877
Validation loss: 3.600536983871468

Epoch: 5| Step: 8
Training loss: 3.3333286921150957
Validation loss: 3.5992548387849412

Epoch: 5| Step: 9
Training loss: 3.466031770766378
Validation loss: 3.5958135842701973

Epoch: 5| Step: 10
Training loss: 4.64610444833086
Validation loss: 3.592602975210573

Epoch: 31| Step: 0
Training loss: 3.2602752232365293
Validation loss: 3.5892483016566894

Epoch: 5| Step: 1
Training loss: 3.940066152298063
Validation loss: 3.5883934630610788

Epoch: 5| Step: 2
Training loss: 3.9888763730966437
Validation loss: 3.5881033258985804

Epoch: 5| Step: 3
Training loss: 4.1441520208215925
Validation loss: 3.585774575741197

Epoch: 5| Step: 4
Training loss: 4.384590753751239
Validation loss: 3.5865773061777744

Epoch: 5| Step: 5
Training loss: 3.602114554439609
Validation loss: 3.5837040433030807

Epoch: 5| Step: 6
Training loss: 3.428901043442732
Validation loss: 3.5776736862415777

Epoch: 5| Step: 7
Training loss: 4.021055594248979
Validation loss: 3.575282507743841

Epoch: 5| Step: 8
Training loss: 4.061062837363952
Validation loss: 3.5758773379453084

Epoch: 5| Step: 9
Training loss: 3.219865920314044
Validation loss: 3.5703623778438036

Epoch: 5| Step: 10
Training loss: 3.2662293089464196
Validation loss: 3.568585806158505

Epoch: 32| Step: 0
Training loss: 4.16276510041703
Validation loss: 3.567857113544315

Epoch: 5| Step: 1
Training loss: 4.071740542436597
Validation loss: 3.5650897742354934

Epoch: 5| Step: 2
Training loss: 3.318979655507746
Validation loss: 3.561348201244748

Epoch: 5| Step: 3
Training loss: 3.815503297656642
Validation loss: 3.5608752189857453

Epoch: 5| Step: 4
Training loss: 4.233776993419101
Validation loss: 3.55952382547644

Epoch: 5| Step: 5
Training loss: 3.701893018053636
Validation loss: 3.558685489218248

Epoch: 5| Step: 6
Training loss: 3.8901390170481633
Validation loss: 3.55454395666517

Epoch: 5| Step: 7
Training loss: 3.4514452961423543
Validation loss: 3.5539921107986574

Epoch: 5| Step: 8
Training loss: 3.6636272895850346
Validation loss: 3.5528751138339074

Epoch: 5| Step: 9
Training loss: 3.4852515516524627
Validation loss: 3.546508705097422

Epoch: 5| Step: 10
Training loss: 3.407227122295024
Validation loss: 3.544421475427194

Epoch: 33| Step: 0
Training loss: 3.868444619890615
Validation loss: 3.5444185938431287

Epoch: 5| Step: 1
Training loss: 4.050813974599614
Validation loss: 3.5420342174426325

Epoch: 5| Step: 2
Training loss: 3.859057950112838
Validation loss: 3.5392063713498216

Epoch: 5| Step: 3
Training loss: 3.5512127000406744
Validation loss: 3.537470126586641

Epoch: 5| Step: 4
Training loss: 3.7254219789036567
Validation loss: 3.533829042249242

Epoch: 5| Step: 5
Training loss: 4.211359402783047
Validation loss: 3.5309523372516054

Epoch: 5| Step: 6
Training loss: 3.5146999922413613
Validation loss: 3.527873327717027

Epoch: 5| Step: 7
Training loss: 3.681421215693526
Validation loss: 3.525747036443367

Epoch: 5| Step: 8
Training loss: 3.4639375312229355
Validation loss: 3.5226868373537457

Epoch: 5| Step: 9
Training loss: 3.70948085103618
Validation loss: 3.51790207418155

Epoch: 5| Step: 10
Training loss: 3.3806997136982186
Validation loss: 3.5154718968678433

Epoch: 34| Step: 0
Training loss: 3.612211887789812
Validation loss: 3.511503123351218

Epoch: 5| Step: 1
Training loss: 3.8438234399742286
Validation loss: 3.510945034469449

Epoch: 5| Step: 2
Training loss: 3.5681771000586298
Validation loss: 3.507134607639826

Epoch: 5| Step: 3
Training loss: 3.30498443784527
Validation loss: 3.504327790920951

Epoch: 5| Step: 4
Training loss: 4.448729584473694
Validation loss: 3.502630537307168

Epoch: 5| Step: 5
Training loss: 3.9502977959125563
Validation loss: 3.499559758591947

Epoch: 5| Step: 6
Training loss: 3.3661447844438994
Validation loss: 3.4999908836820275

Epoch: 5| Step: 7
Training loss: 3.698285122993108
Validation loss: 3.4966823518472947

Epoch: 5| Step: 8
Training loss: 4.173033592705039
Validation loss: 3.4951756155205413

Epoch: 5| Step: 9
Training loss: 3.511724452946565
Validation loss: 3.494262592667283

Epoch: 5| Step: 10
Training loss: 3.1048511202835436
Validation loss: 3.4918929137725856

Epoch: 35| Step: 0
Training loss: 3.1191212098742183
Validation loss: 3.489024544601882

Epoch: 5| Step: 1
Training loss: 3.1345018507598605
Validation loss: 3.48510337709102

Epoch: 5| Step: 2
Training loss: 3.8694164287584125
Validation loss: 3.48462634635704

Epoch: 5| Step: 3
Training loss: 3.923711339219916
Validation loss: 3.4817477820435294

Epoch: 5| Step: 4
Training loss: 3.6652210738261792
Validation loss: 3.4785716374685025

Epoch: 5| Step: 5
Training loss: 3.436446288474024
Validation loss: 3.4767730173525666

Epoch: 5| Step: 6
Training loss: 3.995358993385069
Validation loss: 3.476594075613412

Epoch: 5| Step: 7
Training loss: 3.8027581996396718
Validation loss: 3.477233804208499

Epoch: 5| Step: 8
Training loss: 4.140451794726407
Validation loss: 3.4707379330464265

Epoch: 5| Step: 9
Training loss: 3.5052674030165503
Validation loss: 3.4692785674614175

Epoch: 5| Step: 10
Training loss: 3.905644484318897
Validation loss: 3.4657858722548944

Epoch: 36| Step: 0
Training loss: 4.431201602041985
Validation loss: 3.4655729165356823

Epoch: 5| Step: 1
Training loss: 3.919576145923981
Validation loss: 3.462473356574539

Epoch: 5| Step: 2
Training loss: 4.641795823076966
Validation loss: 3.462162667721903

Epoch: 5| Step: 3
Training loss: 3.7213081088284694
Validation loss: 3.459619152344202

Epoch: 5| Step: 4
Training loss: 2.4878455338994043
Validation loss: 3.460046213287031

Epoch: 5| Step: 5
Training loss: 2.9654193063195096
Validation loss: 3.4670421827255877

Epoch: 5| Step: 6
Training loss: 3.162974832343606
Validation loss: 3.459611502064209

Epoch: 5| Step: 7
Training loss: 3.8139495595348114
Validation loss: 3.4562359046466886

Epoch: 5| Step: 8
Training loss: 4.048559361180342
Validation loss: 3.4524964021350324

Epoch: 5| Step: 9
Training loss: 2.837724275170096
Validation loss: 3.4516340340768794

Epoch: 5| Step: 10
Training loss: 3.8014961660221047
Validation loss: 3.449546867016253

Epoch: 37| Step: 0
Training loss: 3.413925342729032
Validation loss: 3.4473643864216843

Epoch: 5| Step: 1
Training loss: 4.168004215450681
Validation loss: 3.446224318657883

Epoch: 5| Step: 2
Training loss: 3.416591938100976
Validation loss: 3.4444890289539427

Epoch: 5| Step: 3
Training loss: 3.740555122506781
Validation loss: 3.4452628059850308

Epoch: 5| Step: 4
Training loss: 3.3948776366889604
Validation loss: 3.4495260444842266

Epoch: 5| Step: 5
Training loss: 4.539783519003309
Validation loss: 3.4430937180003935

Epoch: 5| Step: 6
Training loss: 3.5231995766572757
Validation loss: 3.438198644317443

Epoch: 5| Step: 7
Training loss: 3.492405690453769
Validation loss: 3.437126270610201

Epoch: 5| Step: 8
Training loss: 3.5110054012942618
Validation loss: 3.4383356236532756

Epoch: 5| Step: 9
Training loss: 2.89942820601131
Validation loss: 3.4399564674896794

Epoch: 5| Step: 10
Training loss: 3.9878783139227396
Validation loss: 3.443028029500411

Epoch: 38| Step: 0
Training loss: 3.7837629558844252
Validation loss: 3.4363299006957706

Epoch: 5| Step: 1
Training loss: 4.1688120595725
Validation loss: 3.430917254459976

Epoch: 5| Step: 2
Training loss: 2.829262183425827
Validation loss: 3.4327626836999765

Epoch: 5| Step: 3
Training loss: 4.402477191300584
Validation loss: 3.4421802359153144

Epoch: 5| Step: 4
Training loss: 3.1091763993677253
Validation loss: 3.4307558323039156

Epoch: 5| Step: 5
Training loss: 3.3817046644226534
Validation loss: 3.433324936011137

Epoch: 5| Step: 6
Training loss: 3.378259991710857
Validation loss: 3.432953188079641

Epoch: 5| Step: 7
Training loss: 2.707866325217662
Validation loss: 3.427559250878596

Epoch: 5| Step: 8
Training loss: 3.8377386708547427
Validation loss: 3.4243888661845827

Epoch: 5| Step: 9
Training loss: 3.356134599516718
Validation loss: 3.42235623947021

Epoch: 5| Step: 10
Training loss: 4.881068243142464
Validation loss: 3.4220409059970374

Epoch: 39| Step: 0
Training loss: 2.560743241451379
Validation loss: 3.4209365205846147

Epoch: 5| Step: 1
Training loss: 3.8038830543135203
Validation loss: 3.421239467521027

Epoch: 5| Step: 2
Training loss: 2.761383597447739
Validation loss: 3.4215520351517665

Epoch: 5| Step: 3
Training loss: 3.4174867126608377
Validation loss: 3.4205857292013495

Epoch: 5| Step: 4
Training loss: 3.8657500090311347
Validation loss: 3.4160412041570845

Epoch: 5| Step: 5
Training loss: 3.8590158148661695
Validation loss: 3.413845892738726

Epoch: 5| Step: 6
Training loss: 3.8852376751754245
Validation loss: 3.4102551080942676

Epoch: 5| Step: 7
Training loss: 3.5331352400281273
Validation loss: 3.407139007620286

Epoch: 5| Step: 8
Training loss: 3.8369822895356136
Validation loss: 3.406557430329851

Epoch: 5| Step: 9
Training loss: 3.9035178433490896
Validation loss: 3.407570995123615

Epoch: 5| Step: 10
Training loss: 4.318145815685531
Validation loss: 3.4072771754235234

Epoch: 40| Step: 0
Training loss: 3.401986349716475
Validation loss: 3.403171824937072

Epoch: 5| Step: 1
Training loss: 3.937011325121291
Validation loss: 3.397822485165445

Epoch: 5| Step: 2
Training loss: 3.26868262722977
Validation loss: 3.396379402887466

Epoch: 5| Step: 3
Training loss: 4.515691736909526
Validation loss: 3.395095411840476

Epoch: 5| Step: 4
Training loss: 3.821453025647952
Validation loss: 3.3939962611342103

Epoch: 5| Step: 5
Training loss: 3.823738668075186
Validation loss: 3.39290370275437

Epoch: 5| Step: 6
Training loss: 3.80711835404984
Validation loss: 3.391990337199698

Epoch: 5| Step: 7
Training loss: 3.3277573360040997
Validation loss: 3.3894704130048376

Epoch: 5| Step: 8
Training loss: 3.4129286220898294
Validation loss: 3.3900214888172058

Epoch: 5| Step: 9
Training loss: 3.4199494818810066
Validation loss: 3.388477876339667

Epoch: 5| Step: 10
Training loss: 2.6540630537935535
Validation loss: 3.385859096699107

Epoch: 41| Step: 0
Training loss: 3.909730870967775
Validation loss: 3.384880530576792

Epoch: 5| Step: 1
Training loss: 2.992407887761266
Validation loss: 3.383604913885867

Epoch: 5| Step: 2
Training loss: 3.7178221755243754
Validation loss: 3.3828814114740684

Epoch: 5| Step: 3
Training loss: 4.073073023976194
Validation loss: 3.3816025085707664

Epoch: 5| Step: 4
Training loss: 3.7171428637652753
Validation loss: 3.380639794024544

Epoch: 5| Step: 5
Training loss: 2.591500559284754
Validation loss: 3.380544960492353

Epoch: 5| Step: 6
Training loss: 4.163791554637868
Validation loss: 3.378338732062473

Epoch: 5| Step: 7
Training loss: 3.8940600815160815
Validation loss: 3.374501603614169

Epoch: 5| Step: 8
Training loss: 2.582700426239795
Validation loss: 3.3741701686642616

Epoch: 5| Step: 9
Training loss: 4.102140491268847
Validation loss: 3.372738109492343

Epoch: 5| Step: 10
Training loss: 3.457933487048947
Validation loss: 3.3716144900320995

Epoch: 42| Step: 0
Training loss: 4.305174424451485
Validation loss: 3.369957721696104

Epoch: 5| Step: 1
Training loss: 3.1227246965814404
Validation loss: 3.3682446356985194

Epoch: 5| Step: 2
Training loss: 3.6813192778773463
Validation loss: 3.3672954986545367

Epoch: 5| Step: 3
Training loss: 3.296660936104397
Validation loss: 3.368394093649827

Epoch: 5| Step: 4
Training loss: 2.9711350347081527
Validation loss: 3.3651770778968952

Epoch: 5| Step: 5
Training loss: 3.8208097356624307
Validation loss: 3.367378186256772

Epoch: 5| Step: 6
Training loss: 2.708232750614364
Validation loss: 3.3617439878178415

Epoch: 5| Step: 7
Training loss: 3.9955068625270784
Validation loss: 3.3602480815289746

Epoch: 5| Step: 8
Training loss: 3.5248330475790857
Validation loss: 3.3572166352603006

Epoch: 5| Step: 9
Training loss: 3.652135898163203
Validation loss: 3.3587259225018853

Epoch: 5| Step: 10
Training loss: 4.232173107882981
Validation loss: 3.356378045810133

Epoch: 43| Step: 0
Training loss: 4.199184229509272
Validation loss: 3.356354480610544

Epoch: 5| Step: 1
Training loss: 3.1018289216197243
Validation loss: 3.3548374500175666

Epoch: 5| Step: 2
Training loss: 3.1038550064692263
Validation loss: 3.3541464469013342

Epoch: 5| Step: 3
Training loss: 3.268623836846969
Validation loss: 3.3505386688397425

Epoch: 5| Step: 4
Training loss: 3.988474692679585
Validation loss: 3.352237361833469

Epoch: 5| Step: 5
Training loss: 3.391813711467052
Validation loss: 3.3494441782112028

Epoch: 5| Step: 6
Training loss: 3.6520676125976723
Validation loss: 3.3491700155170006

Epoch: 5| Step: 7
Training loss: 3.489322178116448
Validation loss: 3.345902924509979

Epoch: 5| Step: 8
Training loss: 3.2323686209265015
Validation loss: 3.345007349415134

Epoch: 5| Step: 9
Training loss: 3.7167043749574216
Validation loss: 3.345775521691659

Epoch: 5| Step: 10
Training loss: 4.1567678487454955
Validation loss: 3.343879467958388

Epoch: 44| Step: 0
Training loss: 3.604928717047353
Validation loss: 3.34200371219936

Epoch: 5| Step: 1
Training loss: 3.6103157699994117
Validation loss: 3.339329935928222

Epoch: 5| Step: 2
Training loss: 3.5378988681396875
Validation loss: 3.3397865822555373

Epoch: 5| Step: 3
Training loss: 3.0379712025807555
Validation loss: 3.3400262694136003

Epoch: 5| Step: 4
Training loss: 4.198608694784956
Validation loss: 3.339044845759879

Epoch: 5| Step: 5
Training loss: 3.128693038781595
Validation loss: 3.341830837842663

Epoch: 5| Step: 6
Training loss: 3.4831820100711366
Validation loss: 3.337018777172531

Epoch: 5| Step: 7
Training loss: 3.8883594213058306
Validation loss: 3.3372905719416006

Epoch: 5| Step: 8
Training loss: 3.7291940158856947
Validation loss: 3.338607086103296

Epoch: 5| Step: 9
Training loss: 2.901147115675452
Validation loss: 3.3373778806279932

Epoch: 5| Step: 10
Training loss: 4.060650918204691
Validation loss: 3.341220818073322

Epoch: 45| Step: 0
Training loss: 4.103699220220588
Validation loss: 3.33779988266071

Epoch: 5| Step: 1
Training loss: 4.021260504028527
Validation loss: 3.3339618695293893

Epoch: 5| Step: 2
Training loss: 2.607624768996216
Validation loss: 3.3346318643337547

Epoch: 5| Step: 3
Training loss: 3.4053942804142556
Validation loss: 3.3363187731063215

Epoch: 5| Step: 4
Training loss: 4.0289105864881165
Validation loss: 3.33502081231723

Epoch: 5| Step: 5
Training loss: 3.5447100111017793
Validation loss: 3.332756758374124

Epoch: 5| Step: 6
Training loss: 3.458505434710049
Validation loss: 3.329334053861415

Epoch: 5| Step: 7
Training loss: 3.5928213495293346
Validation loss: 3.3301380244825665

Epoch: 5| Step: 8
Training loss: 3.2680573234619974
Validation loss: 3.3291187642751607

Epoch: 5| Step: 9
Training loss: 3.1606965422420914
Validation loss: 3.3286858436149362

Epoch: 5| Step: 10
Training loss: 3.8450521108918188
Validation loss: 3.328628927861523

Epoch: 46| Step: 0
Training loss: 2.9384316123701386
Validation loss: 3.332842538961884

Epoch: 5| Step: 1
Training loss: 3.157888761313959
Validation loss: 3.3273765727285727

Epoch: 5| Step: 2
Training loss: 4.153282081038769
Validation loss: 3.325544118512625

Epoch: 5| Step: 3
Training loss: 4.033306691315568
Validation loss: 3.3249548291624555

Epoch: 5| Step: 4
Training loss: 3.5463573733490024
Validation loss: 3.3240026941193377

Epoch: 5| Step: 5
Training loss: 3.1932763511760878
Validation loss: 3.323198442640468

Epoch: 5| Step: 6
Training loss: 2.878569501749751
Validation loss: 3.3232938233744758

Epoch: 5| Step: 7
Training loss: 3.666063750433319
Validation loss: 3.322103788170069

Epoch: 5| Step: 8
Training loss: 3.812473734780812
Validation loss: 3.323307150323331

Epoch: 5| Step: 9
Training loss: 4.0631856486452165
Validation loss: 3.321980764310393

Epoch: 5| Step: 10
Training loss: 3.449070271701599
Validation loss: 3.3202802782226457

Epoch: 47| Step: 0
Training loss: 4.220406666184968
Validation loss: 3.320242610343022

Epoch: 5| Step: 1
Training loss: 3.8185019854282816
Validation loss: 3.3197279270866704

Epoch: 5| Step: 2
Training loss: 2.734767427894751
Validation loss: 3.320494014596915

Epoch: 5| Step: 3
Training loss: 3.912174949915343
Validation loss: 3.318970174831946

Epoch: 5| Step: 4
Training loss: 3.074676285738868
Validation loss: 3.318130700926453

Epoch: 5| Step: 5
Training loss: 2.98612309731929
Validation loss: 3.317857450961397

Epoch: 5| Step: 6
Training loss: 3.2217266059689793
Validation loss: 3.3170289654934026

Epoch: 5| Step: 7
Training loss: 3.4602626030555097
Validation loss: 3.3161110368724525

Epoch: 5| Step: 8
Training loss: 4.299720737349049
Validation loss: 3.317625538539905

Epoch: 5| Step: 9
Training loss: 3.7893828895633943
Validation loss: 3.316243145444726

Epoch: 5| Step: 10
Training loss: 3.171227149384857
Validation loss: 3.3152276106771854

Epoch: 48| Step: 0
Training loss: 3.7883436012604426
Validation loss: 3.315833261447999

Epoch: 5| Step: 1
Training loss: 3.3973813575312644
Validation loss: 3.316482062068546

Epoch: 5| Step: 2
Training loss: 3.8989264844727765
Validation loss: 3.3145471872870047

Epoch: 5| Step: 3
Training loss: 3.6570551059191727
Validation loss: 3.3165433387584957

Epoch: 5| Step: 4
Training loss: 3.136308579093565
Validation loss: 3.3130027341515684

Epoch: 5| Step: 5
Training loss: 3.6229353977543224
Validation loss: 3.3115791113412496

Epoch: 5| Step: 6
Training loss: 3.138433346470697
Validation loss: 3.3120421009730747

Epoch: 5| Step: 7
Training loss: 3.593603910711034
Validation loss: 3.312036741541769

Epoch: 5| Step: 8
Training loss: 3.9617518203008046
Validation loss: 3.3147778920287436

Epoch: 5| Step: 9
Training loss: 3.1650819996219774
Validation loss: 3.311924271983576

Epoch: 5| Step: 10
Training loss: 3.6209782620051136
Validation loss: 3.310297315109173

Epoch: 49| Step: 0
Training loss: 3.422561924933555
Validation loss: 3.31153320270804

Epoch: 5| Step: 1
Training loss: 3.768989421267907
Validation loss: 3.3100381294584573

Epoch: 5| Step: 2
Training loss: 3.871845807449599
Validation loss: 3.307759537214392

Epoch: 5| Step: 3
Training loss: 3.5245103915382394
Validation loss: 3.3119196105681863

Epoch: 5| Step: 4
Training loss: 3.927585896815966
Validation loss: 3.3080655252698286

Epoch: 5| Step: 5
Training loss: 3.354747903508362
Validation loss: 3.308150919298659

Epoch: 5| Step: 6
Training loss: 3.2400398218980815
Validation loss: 3.3083631153728756

Epoch: 5| Step: 7
Training loss: 3.144045054125046
Validation loss: 3.306207143048052

Epoch: 5| Step: 8
Training loss: 3.4328408310857967
Validation loss: 3.3064053190818714

Epoch: 5| Step: 9
Training loss: 3.7145206539551867
Validation loss: 3.3102891586525565

Epoch: 5| Step: 10
Training loss: 3.5544009585746523
Validation loss: 3.3061230961240686

Epoch: 50| Step: 0
Training loss: 3.2135058895120623
Validation loss: 3.3071497893122594

Epoch: 5| Step: 1
Training loss: 3.2466723205339627
Validation loss: 3.3050561712498614

Epoch: 5| Step: 2
Training loss: 3.78153107914655
Validation loss: 3.3066796092129245

Epoch: 5| Step: 3
Training loss: 3.4932635738114817
Validation loss: 3.3062030721834508

Epoch: 5| Step: 4
Training loss: 3.7332014849632134
Validation loss: 3.3073377886866617

Epoch: 5| Step: 5
Training loss: 4.082927112744409
Validation loss: 3.308793992810096

Epoch: 5| Step: 6
Training loss: 3.201083393282198
Validation loss: 3.308475950074595

Epoch: 5| Step: 7
Training loss: 3.4710096267922776
Validation loss: 3.307289025994641

Epoch: 5| Step: 8
Training loss: 3.5538535680449
Validation loss: 3.3025485277471303

Epoch: 5| Step: 9
Training loss: 3.852702933381096
Validation loss: 3.306032020003006

Epoch: 5| Step: 10
Training loss: 3.1913013604435645
Validation loss: 3.309373091361008

Epoch: 51| Step: 0
Training loss: 3.5446774569233526
Validation loss: 3.314368720983743

Epoch: 5| Step: 1
Training loss: 3.338638820018156
Validation loss: 3.308883069917084

Epoch: 5| Step: 2
Training loss: 4.034181933285807
Validation loss: 3.304667302280379

Epoch: 5| Step: 3
Training loss: 3.321623419980814
Validation loss: 3.3051057921879385

Epoch: 5| Step: 4
Training loss: 3.7596754504202456
Validation loss: 3.3068782019232157

Epoch: 5| Step: 5
Training loss: 3.4144821781973107
Validation loss: 3.307034020161956

Epoch: 5| Step: 6
Training loss: 3.419297174883461
Validation loss: 3.309771290933717

Epoch: 5| Step: 7
Training loss: 3.762864236532225
Validation loss: 3.3072685651074893

Epoch: 5| Step: 8
Training loss: 3.344469795116891
Validation loss: 3.3110358728383296

Epoch: 5| Step: 9
Training loss: 3.767637103040838
Validation loss: 3.3077610903909664

Epoch: 5| Step: 10
Training loss: 3.203082126237458
Validation loss: 3.3045483259284065

Epoch: 52| Step: 0
Training loss: 3.0136941845921643
Validation loss: 3.3078658180718308

Epoch: 5| Step: 1
Training loss: 3.0091811199857044
Validation loss: 3.3143512902756656

Epoch: 5| Step: 2
Training loss: 3.4979926211070453
Validation loss: 3.3284463934761592

Epoch: 5| Step: 3
Training loss: 3.624825572059495
Validation loss: 3.3081312262945226

Epoch: 5| Step: 4
Training loss: 3.813228725141163
Validation loss: 3.2975305829709654

Epoch: 5| Step: 5
Training loss: 3.6518118241496267
Validation loss: 3.2999181760908924

Epoch: 5| Step: 6
Training loss: 4.538014801498894
Validation loss: 3.304227016241143

Epoch: 5| Step: 7
Training loss: 3.710741796854419
Validation loss: 3.304536469485027

Epoch: 5| Step: 8
Training loss: 3.6409945975716442
Validation loss: 3.3060737944247083

Epoch: 5| Step: 9
Training loss: 3.1803687113408223
Validation loss: 3.303100920328918

Epoch: 5| Step: 10
Training loss: 2.935176823503056
Validation loss: 3.303878000427021

Epoch: 53| Step: 0
Training loss: 4.0167512613043925
Validation loss: 3.3000883006702377

Epoch: 5| Step: 1
Training loss: 3.568086493654027
Validation loss: 3.2958338211756364

Epoch: 5| Step: 2
Training loss: 3.4933652662560046
Validation loss: 3.294787378688885

Epoch: 5| Step: 3
Training loss: 4.266295216206466
Validation loss: 3.2946294677932864

Epoch: 5| Step: 4
Training loss: 3.1487037413600047
Validation loss: 3.294806356245807

Epoch: 5| Step: 5
Training loss: 4.014057254156751
Validation loss: 3.2958015592094134

Epoch: 5| Step: 6
Training loss: 3.2551223295930423
Validation loss: 3.2935720147152963

Epoch: 5| Step: 7
Training loss: 3.6367900771737824
Validation loss: 3.2913819285042933

Epoch: 5| Step: 8
Training loss: 2.686638006320922
Validation loss: 3.2934113973795003

Epoch: 5| Step: 9
Training loss: 3.181597012103248
Validation loss: 3.2934886525993643

Epoch: 5| Step: 10
Training loss: 3.3277768235018605
Validation loss: 3.292516625637137

Epoch: 54| Step: 0
Training loss: 4.013474656803102
Validation loss: 3.2917797624238636

Epoch: 5| Step: 1
Training loss: 3.208000975068817
Validation loss: 3.291670423209333

Epoch: 5| Step: 2
Training loss: 3.3723533991005885
Validation loss: 3.291111184402128

Epoch: 5| Step: 3
Training loss: 3.891101486259024
Validation loss: 3.2903722308014194

Epoch: 5| Step: 4
Training loss: 4.061794278395912
Validation loss: 3.289669284974323

Epoch: 5| Step: 5
Training loss: 3.3262917210866414
Validation loss: 3.2906158569609048

Epoch: 5| Step: 6
Training loss: 3.3635482061863415
Validation loss: 3.2912554802754386

Epoch: 5| Step: 7
Training loss: 3.5796961104490506
Validation loss: 3.289455957037887

Epoch: 5| Step: 8
Training loss: 3.3604276205610777
Validation loss: 3.2908444151902896

Epoch: 5| Step: 9
Training loss: 3.5824365750519602
Validation loss: 3.290237268013039

Epoch: 5| Step: 10
Training loss: 2.8018839220376783
Validation loss: 3.2898953351132625

Epoch: 55| Step: 0
Training loss: 3.6830150679633022
Validation loss: 3.2873436531474076

Epoch: 5| Step: 1
Training loss: 2.9129741364629638
Validation loss: 3.2878450853022376

Epoch: 5| Step: 2
Training loss: 3.921943815927006
Validation loss: 3.286945733894269

Epoch: 5| Step: 3
Training loss: 3.121704347392901
Validation loss: 3.2869437153930403

Epoch: 5| Step: 4
Training loss: 3.3942695402656367
Validation loss: 3.2872091314305307

Epoch: 5| Step: 5
Training loss: 4.501518840902479
Validation loss: 3.286369569941375

Epoch: 5| Step: 6
Training loss: 3.141566652549277
Validation loss: 3.2862710970440734

Epoch: 5| Step: 7
Training loss: 3.8142613579067834
Validation loss: 3.287214200670307

Epoch: 5| Step: 8
Training loss: 3.858701577681356
Validation loss: 3.2851157672250837

Epoch: 5| Step: 9
Training loss: 3.1358442215667526
Validation loss: 3.284519870735533

Epoch: 5| Step: 10
Training loss: 2.859529918372064
Validation loss: 3.283569653579984

Epoch: 56| Step: 0
Training loss: 3.4585713377408003
Validation loss: 3.2838849958517904

Epoch: 5| Step: 1
Training loss: 3.384154725237264
Validation loss: 3.2833205620785013

Epoch: 5| Step: 2
Training loss: 3.864737796352827
Validation loss: 3.28436801819465

Epoch: 5| Step: 3
Training loss: 3.7335441654709887
Validation loss: 3.2856734563466086

Epoch: 5| Step: 4
Training loss: 4.003962937860898
Validation loss: 3.2834017119390895

Epoch: 5| Step: 5
Training loss: 3.4869614653628296
Validation loss: 3.290654464636665

Epoch: 5| Step: 6
Training loss: 3.700484094654379
Validation loss: 3.286003988728864

Epoch: 5| Step: 7
Training loss: 3.900427545440557
Validation loss: 3.2792125589606305

Epoch: 5| Step: 8
Training loss: 2.1618266209363917
Validation loss: 3.280269998754748

Epoch: 5| Step: 9
Training loss: 2.9011247624128407
Validation loss: 3.28029755316286

Epoch: 5| Step: 10
Training loss: 3.8134815640972324
Validation loss: 3.282813173035033

Epoch: 57| Step: 0
Training loss: 3.1492282830380085
Validation loss: 3.27971896124954

Epoch: 5| Step: 1
Training loss: 4.1670833887884
Validation loss: 3.2791198832413397

Epoch: 5| Step: 2
Training loss: 3.5491526008704017
Validation loss: 3.2790240728917346

Epoch: 5| Step: 3
Training loss: 3.7476447020339463
Validation loss: 3.2799593417031008

Epoch: 5| Step: 4
Training loss: 3.264578327563809
Validation loss: 3.279236221956972

Epoch: 5| Step: 5
Training loss: 3.771236306817746
Validation loss: 3.2789510350479047

Epoch: 5| Step: 6
Training loss: 3.378014525125374
Validation loss: 3.2770524701282526

Epoch: 5| Step: 7
Training loss: 2.7301713293062257
Validation loss: 3.2772123340829014

Epoch: 5| Step: 8
Training loss: 3.570759885040747
Validation loss: 3.2766574290253256

Epoch: 5| Step: 9
Training loss: 3.9923419362633963
Validation loss: 3.277548126567955

Epoch: 5| Step: 10
Training loss: 3.1338190378649755
Validation loss: 3.2755574386735673

Epoch: 58| Step: 0
Training loss: 3.4351925127702057
Validation loss: 3.2755425579666855

Epoch: 5| Step: 1
Training loss: 2.5419534511010813
Validation loss: 3.2773871134836363

Epoch: 5| Step: 2
Training loss: 3.956324311774317
Validation loss: 3.27611498639225

Epoch: 5| Step: 3
Training loss: 4.452295272892566
Validation loss: 3.277097500615171

Epoch: 5| Step: 4
Training loss: 2.286278395353902
Validation loss: 3.276754157447921

Epoch: 5| Step: 5
Training loss: 3.326495134165164
Validation loss: 3.276401506208176

Epoch: 5| Step: 6
Training loss: 3.771555682100371
Validation loss: 3.2768176948250898

Epoch: 5| Step: 7
Training loss: 3.5894796458696896
Validation loss: 3.275836350391927

Epoch: 5| Step: 8
Training loss: 3.1457838513522685
Validation loss: 3.2754862786518557

Epoch: 5| Step: 9
Training loss: 3.5479503463487547
Validation loss: 3.274814724904611

Epoch: 5| Step: 10
Training loss: 4.15920364863813
Validation loss: 3.2740086544647955

Epoch: 59| Step: 0
Training loss: 3.4235477626494553
Validation loss: 3.273755593507559

Epoch: 5| Step: 1
Training loss: 3.5204098839968583
Validation loss: 3.274742792508321

Epoch: 5| Step: 2
Training loss: 3.7116662524570962
Validation loss: 3.2740189183804786

Epoch: 5| Step: 3
Training loss: 3.371628808339973
Validation loss: 3.2729524298110118

Epoch: 5| Step: 4
Training loss: 3.1923417362664037
Validation loss: 3.2727150268210083

Epoch: 5| Step: 5
Training loss: 3.7361162667000585
Validation loss: 3.2722974648081253

Epoch: 5| Step: 6
Training loss: 2.9989738298770794
Validation loss: 3.270399613654224

Epoch: 5| Step: 7
Training loss: 3.6982918275896783
Validation loss: 3.2724072539014766

Epoch: 5| Step: 8
Training loss: 3.4944056351256436
Validation loss: 3.2721437233332935

Epoch: 5| Step: 9
Training loss: 3.3577097469209383
Validation loss: 3.27076968310153

Epoch: 5| Step: 10
Training loss: 4.141037024385208
Validation loss: 3.2701458093104714

Epoch: 60| Step: 0
Training loss: 3.986034092766429
Validation loss: 3.2712738140767788

Epoch: 5| Step: 1
Training loss: 3.390228529572461
Validation loss: 3.272257394867005

Epoch: 5| Step: 2
Training loss: 3.6481788429206814
Validation loss: 3.269353557052008

Epoch: 5| Step: 3
Training loss: 3.3366875620469396
Validation loss: 3.2687371813873867

Epoch: 5| Step: 4
Training loss: 3.55862738282508
Validation loss: 3.27361498536637

Epoch: 5| Step: 5
Training loss: 3.357888962064585
Validation loss: 3.271062976265242

Epoch: 5| Step: 6
Training loss: 3.867330775833884
Validation loss: 3.2714960448305344

Epoch: 5| Step: 7
Training loss: 3.059988899709477
Validation loss: 3.2667659809928176

Epoch: 5| Step: 8
Training loss: 3.177578613365248
Validation loss: 3.2686876420652613

Epoch: 5| Step: 9
Training loss: 3.572398438234664
Validation loss: 3.268309951814639

Epoch: 5| Step: 10
Training loss: 3.6062682681885376
Validation loss: 3.269487570613487

Epoch: 61| Step: 0
Training loss: 2.983942130287023
Validation loss: 3.267587160084583

Epoch: 5| Step: 1
Training loss: 3.4509712510659365
Validation loss: 3.2655505437655403

Epoch: 5| Step: 2
Training loss: 3.9317433494947744
Validation loss: 3.266512429570555

Epoch: 5| Step: 3
Training loss: 3.949007566335138
Validation loss: 3.266796993152962

Epoch: 5| Step: 4
Training loss: 3.164285534191649
Validation loss: 3.2686682211034093

Epoch: 5| Step: 5
Training loss: 3.6565845043047456
Validation loss: 3.2706825081013906

Epoch: 5| Step: 6
Training loss: 3.6069648919994632
Validation loss: 3.275707559960055

Epoch: 5| Step: 7
Training loss: 3.5238089693405326
Validation loss: 3.2730463970871733

Epoch: 5| Step: 8
Training loss: 3.4238856431010793
Validation loss: 3.2678052247393006

Epoch: 5| Step: 9
Training loss: 3.211107978100625
Validation loss: 3.2660839136942776

Epoch: 5| Step: 10
Training loss: 3.6018955962085197
Validation loss: 3.263071463799621

Epoch: 62| Step: 0
Training loss: 3.584705814437499
Validation loss: 3.261146249647203

Epoch: 5| Step: 1
Training loss: 3.3262491446819733
Validation loss: 3.2621560359510124

Epoch: 5| Step: 2
Training loss: 3.257753513451676
Validation loss: 3.2627502763449336

Epoch: 5| Step: 3
Training loss: 3.9414074598146063
Validation loss: 3.263379354391138

Epoch: 5| Step: 4
Training loss: 3.6138164721840687
Validation loss: 3.263431781907473

Epoch: 5| Step: 5
Training loss: 3.6547151914332754
Validation loss: 3.262161337446552

Epoch: 5| Step: 6
Training loss: 3.256645158158504
Validation loss: 3.2621327103685127

Epoch: 5| Step: 7
Training loss: 3.666986856063035
Validation loss: 3.2617369280588524

Epoch: 5| Step: 8
Training loss: 3.2340583093372572
Validation loss: 3.261643312488313

Epoch: 5| Step: 9
Training loss: 3.7070977513545746
Validation loss: 3.2606256260700546

Epoch: 5| Step: 10
Training loss: 3.189279097173524
Validation loss: 3.2615787516585732

Epoch: 63| Step: 0
Training loss: 3.245553569628398
Validation loss: 3.2625606364799946

Epoch: 5| Step: 1
Training loss: 3.432603712855843
Validation loss: 3.2626679732367694

Epoch: 5| Step: 2
Training loss: 4.302083357964147
Validation loss: 3.262971734675001

Epoch: 5| Step: 3
Training loss: 3.762010794738176
Validation loss: 3.2618244513846197

Epoch: 5| Step: 4
Training loss: 4.088820423253298
Validation loss: 3.266184930792735

Epoch: 5| Step: 5
Training loss: 4.059041590576919
Validation loss: 3.2635453036283746

Epoch: 5| Step: 6
Training loss: 2.815805315516351
Validation loss: 3.2608883586732547

Epoch: 5| Step: 7
Training loss: 2.9949280461757373
Validation loss: 3.2607079665768417

Epoch: 5| Step: 8
Training loss: 3.184084689427755
Validation loss: 3.2561566432028144

Epoch: 5| Step: 9
Training loss: 3.4316192261534004
Validation loss: 3.2608644021510402

Epoch: 5| Step: 10
Training loss: 2.7101486773369987
Validation loss: 3.2556483106348915

Epoch: 64| Step: 0
Training loss: 3.533859773920493
Validation loss: 3.2567210530837802

Epoch: 5| Step: 1
Training loss: 3.4195147173392324
Validation loss: 3.258354910875671

Epoch: 5| Step: 2
Training loss: 3.4644819240596756
Validation loss: 3.257664066030804

Epoch: 5| Step: 3
Training loss: 3.627403120433725
Validation loss: 3.261568431302279

Epoch: 5| Step: 4
Training loss: 3.7234281718288917
Validation loss: 3.255567607651772

Epoch: 5| Step: 5
Training loss: 3.493029465187136
Validation loss: 3.2558626930720935

Epoch: 5| Step: 6
Training loss: 4.124667529955113
Validation loss: 3.2547000419586105

Epoch: 5| Step: 7
Training loss: 3.058915824058707
Validation loss: 3.2560810642297424

Epoch: 5| Step: 8
Training loss: 3.543849646295926
Validation loss: 3.254977050965488

Epoch: 5| Step: 9
Training loss: 3.3224834929114313
Validation loss: 3.257852629569353

Epoch: 5| Step: 10
Training loss: 2.9619601051482354
Validation loss: 3.2664857281450854

Epoch: 65| Step: 0
Training loss: 3.939770967052165
Validation loss: 3.2660381191052585

Epoch: 5| Step: 1
Training loss: 3.6969813637092197
Validation loss: 3.265915542303551

Epoch: 5| Step: 2
Training loss: 3.6741893211514802
Validation loss: 3.260668339170217

Epoch: 5| Step: 3
Training loss: 3.3476170790171103
Validation loss: 3.262368827725367

Epoch: 5| Step: 4
Training loss: 3.9692744111350016
Validation loss: 3.266303339218525

Epoch: 5| Step: 5
Training loss: 3.537749529014385
Validation loss: 3.2716270258705036

Epoch: 5| Step: 6
Training loss: 3.3809263684418926
Validation loss: 3.2729146582287103

Epoch: 5| Step: 7
Training loss: 2.8193258741864478
Validation loss: 3.265090522611129

Epoch: 5| Step: 8
Training loss: 3.705996659418897
Validation loss: 3.2593561941910045

Epoch: 5| Step: 9
Training loss: 2.5703356895444225
Validation loss: 3.2545347736443175

Epoch: 5| Step: 10
Training loss: 3.657335821131649
Validation loss: 3.252238982984012

Epoch: 66| Step: 0
Training loss: 3.4297819015962356
Validation loss: 3.2526714240788532

Epoch: 5| Step: 1
Training loss: 3.655507460615653
Validation loss: 3.2575610139919826

Epoch: 5| Step: 2
Training loss: 3.4671679488907703
Validation loss: 3.2596886039570783

Epoch: 5| Step: 3
Training loss: 3.2452883679553843
Validation loss: 3.2636302648006144

Epoch: 5| Step: 4
Training loss: 3.678067443967754
Validation loss: 3.2636471675352587

Epoch: 5| Step: 5
Training loss: 3.244621668363353
Validation loss: 3.256918313994239

Epoch: 5| Step: 6
Training loss: 3.506195851280156
Validation loss: 3.251950619658513

Epoch: 5| Step: 7
Training loss: 3.4438242217163997
Validation loss: 3.2498188362712317

Epoch: 5| Step: 8
Training loss: 3.826285406806876
Validation loss: 3.2489293545981037

Epoch: 5| Step: 9
Training loss: 3.6829319477738918
Validation loss: 3.248341240393064

Epoch: 5| Step: 10
Training loss: 3.212870143836695
Validation loss: 3.249278055406313

Epoch: 67| Step: 0
Training loss: 2.806785882364545
Validation loss: 3.248377520418213

Epoch: 5| Step: 1
Training loss: 3.7500203449968943
Validation loss: 3.2517061598396357

Epoch: 5| Step: 2
Training loss: 4.24566204610268
Validation loss: 3.2573048681623784

Epoch: 5| Step: 3
Training loss: 3.6162791089898207
Validation loss: 3.256148478673391

Epoch: 5| Step: 4
Training loss: 3.8848217192484187
Validation loss: 3.25023712416428

Epoch: 5| Step: 5
Training loss: 3.3371251156460384
Validation loss: 3.253586531846521

Epoch: 5| Step: 6
Training loss: 4.027101259673521
Validation loss: 3.247946454851588

Epoch: 5| Step: 7
Training loss: 2.8594430383810923
Validation loss: 3.2483065557734925

Epoch: 5| Step: 8
Training loss: 3.145148364814343
Validation loss: 3.2465416466838946

Epoch: 5| Step: 9
Training loss: 3.9214693748779257
Validation loss: 3.2487285184059074

Epoch: 5| Step: 10
Training loss: 2.0379101065519243
Validation loss: 3.2431831381904934

Epoch: 68| Step: 0
Training loss: 3.6785299825251427
Validation loss: 3.2440172476597957

Epoch: 5| Step: 1
Training loss: 3.3553505145059455
Validation loss: 3.2439568121980784

Epoch: 5| Step: 2
Training loss: 3.5315647491348
Validation loss: 3.2475853967192476

Epoch: 5| Step: 3
Training loss: 3.008209123098974
Validation loss: 3.243900938780415

Epoch: 5| Step: 4
Training loss: 3.802892743355808
Validation loss: 3.2423040411322908

Epoch: 5| Step: 5
Training loss: 3.773525702983763
Validation loss: 3.243063240568872

Epoch: 5| Step: 6
Training loss: 3.8243401949402647
Validation loss: 3.2429476089490623

Epoch: 5| Step: 7
Training loss: 3.205368224131279
Validation loss: 3.2417028198031397

Epoch: 5| Step: 8
Training loss: 3.4752537696444175
Validation loss: 3.2423709466113486

Epoch: 5| Step: 9
Training loss: 3.027436679521265
Validation loss: 3.2424064695719927

Epoch: 5| Step: 10
Training loss: 3.577378374187513
Validation loss: 3.2419021316785686

Epoch: 69| Step: 0
Training loss: 4.029967111306603
Validation loss: 3.2402167773069768

Epoch: 5| Step: 1
Training loss: 3.4245714685259516
Validation loss: 3.245143149936471

Epoch: 5| Step: 2
Training loss: 3.8232393189245304
Validation loss: 3.240735664194418

Epoch: 5| Step: 3
Training loss: 3.292514900979029
Validation loss: 3.241782343259596

Epoch: 5| Step: 4
Training loss: 3.67630179567501
Validation loss: 3.2459442320237053

Epoch: 5| Step: 5
Training loss: 3.121797675625226
Validation loss: 3.2438967438886634

Epoch: 5| Step: 6
Training loss: 3.8100584373097655
Validation loss: 3.242966848365301

Epoch: 5| Step: 7
Training loss: 3.208697723569142
Validation loss: 3.2415214802362966

Epoch: 5| Step: 8
Training loss: 2.674991329571229
Validation loss: 3.2416176524607265

Epoch: 5| Step: 9
Training loss: 3.439203568459235
Validation loss: 3.2398634795619787

Epoch: 5| Step: 10
Training loss: 3.648354114829368
Validation loss: 3.2417359270031167

Epoch: 70| Step: 0
Training loss: 3.4537260473182174
Validation loss: 3.240483531683689

Epoch: 5| Step: 1
Training loss: 3.0222435301453405
Validation loss: 3.237662946488684

Epoch: 5| Step: 2
Training loss: 3.4269491399369856
Validation loss: 3.237049293321086

Epoch: 5| Step: 3
Training loss: 3.809946925076439
Validation loss: 3.236153831013941

Epoch: 5| Step: 4
Training loss: 2.9820414902009302
Validation loss: 3.2378208422846932

Epoch: 5| Step: 5
Training loss: 3.2179362925878903
Validation loss: 3.23697169929056

Epoch: 5| Step: 6
Training loss: 4.241012045078852
Validation loss: 3.237725195474469

Epoch: 5| Step: 7
Training loss: 3.9949866110108254
Validation loss: 3.2366223807577077

Epoch: 5| Step: 8
Training loss: 3.1830224396312836
Validation loss: 3.236606927379983

Epoch: 5| Step: 9
Training loss: 3.450015916649411
Validation loss: 3.236487853897368

Epoch: 5| Step: 10
Training loss: 3.256330779788795
Validation loss: 3.234709690019424

Epoch: 71| Step: 0
Training loss: 2.9938510821963344
Validation loss: 3.2380126262209528

Epoch: 5| Step: 1
Training loss: 4.2033337395889925
Validation loss: 3.23732181162758

Epoch: 5| Step: 2
Training loss: 3.668860703833786
Validation loss: 3.2366661963457157

Epoch: 5| Step: 3
Training loss: 3.2167230538546825
Validation loss: 3.2369605259137537

Epoch: 5| Step: 4
Training loss: 3.3416390574036896
Validation loss: 3.2373141222529727

Epoch: 5| Step: 5
Training loss: 2.963793984629363
Validation loss: 3.235492966664006

Epoch: 5| Step: 6
Training loss: 3.0652196835918954
Validation loss: 3.239902083531356

Epoch: 5| Step: 7
Training loss: 3.7612552852473042
Validation loss: 3.2463891137697383

Epoch: 5| Step: 8
Training loss: 3.9238995801420637
Validation loss: 3.2406049503122256

Epoch: 5| Step: 9
Training loss: 3.3647846047557586
Validation loss: 3.2373470066739207

Epoch: 5| Step: 10
Training loss: 3.538586312904077
Validation loss: 3.2352270734176285

Epoch: 72| Step: 0
Training loss: 3.572407114304308
Validation loss: 3.234933883432091

Epoch: 5| Step: 1
Training loss: 3.741132296754073
Validation loss: 3.2332842252135703

Epoch: 5| Step: 2
Training loss: 3.521121327436312
Validation loss: 3.233831153735834

Epoch: 5| Step: 3
Training loss: 3.684286754221107
Validation loss: 3.2319167230651344

Epoch: 5| Step: 4
Training loss: 3.3914492963138594
Validation loss: 3.2326477156283104

Epoch: 5| Step: 5
Training loss: 3.3831795367784094
Validation loss: 3.2325851721875445

Epoch: 5| Step: 6
Training loss: 3.879766916175834
Validation loss: 3.2308780693414865

Epoch: 5| Step: 7
Training loss: 3.404846042059669
Validation loss: 3.2315921710099107

Epoch: 5| Step: 8
Training loss: 2.9216063676854547
Validation loss: 3.2314418408344254

Epoch: 5| Step: 9
Training loss: 3.1297056246159847
Validation loss: 3.231829338512277

Epoch: 5| Step: 10
Training loss: 3.4975116603566963
Validation loss: 3.2325295733010693

Epoch: 73| Step: 0
Training loss: 3.307056777102192
Validation loss: 3.2327200327488983

Epoch: 5| Step: 1
Training loss: 3.3814552174340866
Validation loss: 3.231713384267886

Epoch: 5| Step: 2
Training loss: 3.6353310007460604
Validation loss: 3.22821104191151

Epoch: 5| Step: 3
Training loss: 3.370530878242192
Validation loss: 3.230079416027464

Epoch: 5| Step: 4
Training loss: 3.3949203356018542
Validation loss: 3.228330244383598

Epoch: 5| Step: 5
Training loss: 3.0083663628650306
Validation loss: 3.2288492169114256

Epoch: 5| Step: 6
Training loss: 3.453324394165409
Validation loss: 3.230950892627782

Epoch: 5| Step: 7
Training loss: 3.5839959500409133
Validation loss: 3.2313438107562016

Epoch: 5| Step: 8
Training loss: 3.9043534214186173
Validation loss: 3.22899043581118

Epoch: 5| Step: 9
Training loss: 3.703260717037688
Validation loss: 3.2279538965824925

Epoch: 5| Step: 10
Training loss: 3.3513773975964876
Validation loss: 3.230055067504189

Epoch: 74| Step: 0
Training loss: 3.4822937090829025
Validation loss: 3.228683336005709

Epoch: 5| Step: 1
Training loss: 3.9687055450112356
Validation loss: 3.229681229785835

Epoch: 5| Step: 2
Training loss: 3.7710299502093556
Validation loss: 3.227579442970945

Epoch: 5| Step: 3
Training loss: 3.0741675638011583
Validation loss: 3.2302924605551713

Epoch: 5| Step: 4
Training loss: 2.742385726676128
Validation loss: 3.2277370997345303

Epoch: 5| Step: 5
Training loss: 3.462825492680974
Validation loss: 3.227428698708776

Epoch: 5| Step: 6
Training loss: 3.1355317222463848
Validation loss: 3.2282961865297786

Epoch: 5| Step: 7
Training loss: 3.568213181614608
Validation loss: 3.227314515053567

Epoch: 5| Step: 8
Training loss: 3.408009066153274
Validation loss: 3.224995599788059

Epoch: 5| Step: 9
Training loss: 3.1978461706155303
Validation loss: 3.2245698159718

Epoch: 5| Step: 10
Training loss: 4.217885246658507
Validation loss: 3.226346998609184

Epoch: 75| Step: 0
Training loss: 3.298922657670826
Validation loss: 3.225780062157351

Epoch: 5| Step: 1
Training loss: 3.732485496661452
Validation loss: 3.2267595309588972

Epoch: 5| Step: 2
Training loss: 3.637751415255294
Validation loss: 3.225996898341143

Epoch: 5| Step: 3
Training loss: 3.5101979052621015
Validation loss: 3.2243037772883243

Epoch: 5| Step: 4
Training loss: 2.8542967346700903
Validation loss: 3.2241362893141514

Epoch: 5| Step: 5
Training loss: 3.5743069330395656
Validation loss: 3.2242582607310037

Epoch: 5| Step: 6
Training loss: 4.002343445002916
Validation loss: 3.225047171151467

Epoch: 5| Step: 7
Training loss: 3.5207998210207445
Validation loss: 3.223168287322296

Epoch: 5| Step: 8
Training loss: 3.168107073265255
Validation loss: 3.22300591693272

Epoch: 5| Step: 9
Training loss: 3.7312400779400505
Validation loss: 3.223780066667863

Epoch: 5| Step: 10
Training loss: 2.8078413633328836
Validation loss: 3.224783097293005

Epoch: 76| Step: 0
Training loss: 3.555133766415398
Validation loss: 3.2239101323543458

Epoch: 5| Step: 1
Training loss: 3.8115245634366133
Validation loss: 3.2252568980705627

Epoch: 5| Step: 2
Training loss: 3.5356822597269746
Validation loss: 3.224332944567279

Epoch: 5| Step: 3
Training loss: 3.1086500079827815
Validation loss: 3.225757100589163

Epoch: 5| Step: 4
Training loss: 2.861982980204371
Validation loss: 3.2245370492996517

Epoch: 5| Step: 5
Training loss: 3.3046641247511057
Validation loss: 3.2253978800189573

Epoch: 5| Step: 6
Training loss: 4.465912244673424
Validation loss: 3.2216904953120995

Epoch: 5| Step: 7
Training loss: 3.668652228071261
Validation loss: 3.223106108758144

Epoch: 5| Step: 8
Training loss: 2.8888610406495183
Validation loss: 3.220726410745108

Epoch: 5| Step: 9
Training loss: 3.2769903235666584
Validation loss: 3.220307279783582

Epoch: 5| Step: 10
Training loss: 3.303859886625288
Validation loss: 3.220275499884877

Epoch: 77| Step: 0
Training loss: 3.5161900045115804
Validation loss: 3.2174535701750826

Epoch: 5| Step: 1
Training loss: 2.5520884507316093
Validation loss: 3.2217851094668006

Epoch: 5| Step: 2
Training loss: 3.679036789556959
Validation loss: 3.219525530619537

Epoch: 5| Step: 3
Training loss: 2.3087578471514605
Validation loss: 3.2201612568382108

Epoch: 5| Step: 4
Training loss: 3.363522121120231
Validation loss: 3.2181424647686487

Epoch: 5| Step: 5
Training loss: 3.9921231199325136
Validation loss: 3.216679304534741

Epoch: 5| Step: 6
Training loss: 3.4937302426784407
Validation loss: 3.2196204560309862

Epoch: 5| Step: 7
Training loss: 3.2921987336939775
Validation loss: 3.2178877629301605

Epoch: 5| Step: 8
Training loss: 4.114679082730198
Validation loss: 3.2170713838164886

Epoch: 5| Step: 9
Training loss: 3.994078425363796
Validation loss: 3.218909651813778

Epoch: 5| Step: 10
Training loss: 3.279277099404339
Validation loss: 3.2183163162850197

Epoch: 78| Step: 0
Training loss: 3.134482226529635
Validation loss: 3.2185805989302425

Epoch: 5| Step: 1
Training loss: 3.2249345343990576
Validation loss: 3.217075534795395

Epoch: 5| Step: 2
Training loss: 3.0589448184136323
Validation loss: 3.2165358713872427

Epoch: 5| Step: 3
Training loss: 3.4111206508783347
Validation loss: 3.2174814067731408

Epoch: 5| Step: 4
Training loss: 4.01556325189636
Validation loss: 3.2173033714141415

Epoch: 5| Step: 5
Training loss: 4.128050629771045
Validation loss: 3.215579467235494

Epoch: 5| Step: 6
Training loss: 2.677169194805126
Validation loss: 3.2169040588082556

Epoch: 5| Step: 7
Training loss: 2.9076898761128933
Validation loss: 3.218722031007165

Epoch: 5| Step: 8
Training loss: 3.8973029861425834
Validation loss: 3.216771608256382

Epoch: 5| Step: 9
Training loss: 3.5729668764788514
Validation loss: 3.2149489128932545

Epoch: 5| Step: 10
Training loss: 3.736159149831695
Validation loss: 3.2180106961384265

Epoch: 79| Step: 0
Training loss: 3.111369351235422
Validation loss: 3.2191455700341987

Epoch: 5| Step: 1
Training loss: 3.508953495138184
Validation loss: 3.216115162828438

Epoch: 5| Step: 2
Training loss: 3.613480120160672
Validation loss: 3.212761519994568

Epoch: 5| Step: 3
Training loss: 4.287969064216615
Validation loss: 3.216051208982627

Epoch: 5| Step: 4
Training loss: 3.2874026788150954
Validation loss: 3.214885299474525

Epoch: 5| Step: 5
Training loss: 3.2597885908137227
Validation loss: 3.214567684027324

Epoch: 5| Step: 6
Training loss: 2.9505276030383962
Validation loss: 3.2116118610351236

Epoch: 5| Step: 7
Training loss: 3.5290021915834346
Validation loss: 3.2135465452420076

Epoch: 5| Step: 8
Training loss: 3.392652617291698
Validation loss: 3.2133012548285445

Epoch: 5| Step: 9
Training loss: 3.5294123906714687
Validation loss: 3.213625576811617

Epoch: 5| Step: 10
Training loss: 3.349170889667077
Validation loss: 3.212796039362846

Epoch: 80| Step: 0
Training loss: 3.20417269808264
Validation loss: 3.2107538439657772

Epoch: 5| Step: 1
Training loss: 3.4013360652107605
Validation loss: 3.210609626282786

Epoch: 5| Step: 2
Training loss: 3.047373100060792
Validation loss: 3.2123631056480213

Epoch: 5| Step: 3
Training loss: 3.5052634580149915
Validation loss: 3.209784253319613

Epoch: 5| Step: 4
Training loss: 3.710066458217379
Validation loss: 3.2131538092565894

Epoch: 5| Step: 5
Training loss: 3.9041515359548025
Validation loss: 3.210752015504608

Epoch: 5| Step: 6
Training loss: 3.6081850146204317
Validation loss: 3.215704732877216

Epoch: 5| Step: 7
Training loss: 3.170511789013323
Validation loss: 3.216563956624882

Epoch: 5| Step: 8
Training loss: 3.2097691547420353
Validation loss: 3.2136405264417514

Epoch: 5| Step: 9
Training loss: 3.7543106734542495
Validation loss: 3.2131938311628896

Epoch: 5| Step: 10
Training loss: 3.3630325633051172
Validation loss: 3.2097859481512785

Epoch: 81| Step: 0
Training loss: 3.077237228715393
Validation loss: 3.20793217480409

Epoch: 5| Step: 1
Training loss: 2.903199101909752
Validation loss: 3.2075393891918207

Epoch: 5| Step: 2
Training loss: 3.3518729255096544
Validation loss: 3.209939303550896

Epoch: 5| Step: 3
Training loss: 2.9499189139391473
Validation loss: 3.2104724315395377

Epoch: 5| Step: 4
Training loss: 4.32193398700877
Validation loss: 3.2135660209111174

Epoch: 5| Step: 5
Training loss: 3.483987145156007
Validation loss: 3.209321209677756

Epoch: 5| Step: 6
Training loss: 3.3807465409391853
Validation loss: 3.2098402190314346

Epoch: 5| Step: 7
Training loss: 3.488738334414839
Validation loss: 3.209044933044149

Epoch: 5| Step: 8
Training loss: 4.0307399220053455
Validation loss: 3.209286791928489

Epoch: 5| Step: 9
Training loss: 3.551152947404459
Validation loss: 3.2076184920434336

Epoch: 5| Step: 10
Training loss: 3.144648617277845
Validation loss: 3.21140464851811

Epoch: 82| Step: 0
Training loss: 3.3490602627079604
Validation loss: 3.209230321288742

Epoch: 5| Step: 1
Training loss: 3.1904654079057133
Validation loss: 3.2078358781675953

Epoch: 5| Step: 2
Training loss: 4.282712811795849
Validation loss: 3.2083103997878872

Epoch: 5| Step: 3
Training loss: 2.537372296507066
Validation loss: 3.204837485163719

Epoch: 5| Step: 4
Training loss: 4.180323129968216
Validation loss: 3.209539504480722

Epoch: 5| Step: 5
Training loss: 2.885788288813225
Validation loss: 3.20839367221005

Epoch: 5| Step: 6
Training loss: 2.919949799981435
Validation loss: 3.209208396430073

Epoch: 5| Step: 7
Training loss: 3.020112015118364
Validation loss: 3.206738034746259

Epoch: 5| Step: 8
Training loss: 3.7213392459827426
Validation loss: 3.2080861957827413

Epoch: 5| Step: 9
Training loss: 3.9241778539234984
Validation loss: 3.2120977838870193

Epoch: 5| Step: 10
Training loss: 3.4872033652758216
Validation loss: 3.2066109493673998

Epoch: 83| Step: 0
Training loss: 3.7780725669535506
Validation loss: 3.205796444687732

Epoch: 5| Step: 1
Training loss: 3.449853788954125
Validation loss: 3.202716454584154

Epoch: 5| Step: 2
Training loss: 3.299079194347813
Validation loss: 3.203791529640377

Epoch: 5| Step: 3
Training loss: 3.5681614646043966
Validation loss: 3.2004157725560543

Epoch: 5| Step: 4
Training loss: 3.9442681167185505
Validation loss: 3.2024491103999777

Epoch: 5| Step: 5
Training loss: 3.522128587341269
Validation loss: 3.203965755784155

Epoch: 5| Step: 6
Training loss: 3.9393984138801255
Validation loss: 3.201997246990371

Epoch: 5| Step: 7
Training loss: 3.326458437587867
Validation loss: 3.202267474127362

Epoch: 5| Step: 8
Training loss: 2.5738574224493114
Validation loss: 3.2003666023315684

Epoch: 5| Step: 9
Training loss: 3.0899428244427427
Validation loss: 3.202362016896749

Epoch: 5| Step: 10
Training loss: 3.155834057282945
Validation loss: 3.2023262650780495

Epoch: 84| Step: 0
Training loss: 3.7094329032460047
Validation loss: 3.2021832498086673

Epoch: 5| Step: 1
Training loss: 2.5544264540449695
Validation loss: 3.2007573927596895

Epoch: 5| Step: 2
Training loss: 3.458630483952272
Validation loss: 3.20010534495723

Epoch: 5| Step: 3
Training loss: 3.453733778924779
Validation loss: 3.2025247487142177

Epoch: 5| Step: 4
Training loss: 3.511493476202205
Validation loss: 3.20054308790951

Epoch: 5| Step: 5
Training loss: 3.7063960183313047
Validation loss: 3.1999182263175427

Epoch: 5| Step: 6
Training loss: 3.022440901337063
Validation loss: 3.2014190252677013

Epoch: 5| Step: 7
Training loss: 3.363815141186737
Validation loss: 3.200831136005101

Epoch: 5| Step: 8
Training loss: 3.4519321228196533
Validation loss: 3.2024440342668083

Epoch: 5| Step: 9
Training loss: 4.152339156570837
Validation loss: 3.201961086772072

Epoch: 5| Step: 10
Training loss: 3.2320946657461516
Validation loss: 3.201559088689083

Epoch: 85| Step: 0
Training loss: 3.0575874007951067
Validation loss: 3.2005420826521473

Epoch: 5| Step: 1
Training loss: 2.9961039357714734
Validation loss: 3.1998017317930807

Epoch: 5| Step: 2
Training loss: 3.877014620891372
Validation loss: 3.19804111815881

Epoch: 5| Step: 3
Training loss: 3.42327044178197
Validation loss: 3.1980336277341204

Epoch: 5| Step: 4
Training loss: 2.9470662933752996
Validation loss: 3.1978223398677654

Epoch: 5| Step: 5
Training loss: 3.218654594118517
Validation loss: 3.1990990013130434

Epoch: 5| Step: 6
Training loss: 3.8705475361207125
Validation loss: 3.1991480379622392

Epoch: 5| Step: 7
Training loss: 4.177001089806902
Validation loss: 3.1980856370846484

Epoch: 5| Step: 8
Training loss: 2.5945229355317885
Validation loss: 3.198806134486007

Epoch: 5| Step: 9
Training loss: 4.143961932946414
Validation loss: 3.1998118772122734

Epoch: 5| Step: 10
Training loss: 3.1092918806611753
Validation loss: 3.197351423704677

Epoch: 86| Step: 0
Training loss: 3.4951500668595283
Validation loss: 3.197005828652573

Epoch: 5| Step: 1
Training loss: 2.6639005102762194
Validation loss: 3.1977105568121527

Epoch: 5| Step: 2
Training loss: 3.873339143268301
Validation loss: 3.196081677124054

Epoch: 5| Step: 3
Training loss: 3.1795790745200043
Validation loss: 3.196129596208282

Epoch: 5| Step: 4
Training loss: 3.6192404933434896
Validation loss: 3.198858142496493

Epoch: 5| Step: 5
Training loss: 4.2259471395989525
Validation loss: 3.196251851148442

Epoch: 5| Step: 6
Training loss: 3.11736937640031
Validation loss: 3.1974306968198056

Epoch: 5| Step: 7
Training loss: 3.9356782119834506
Validation loss: 3.196287950833793

Epoch: 5| Step: 8
Training loss: 4.031446348627901
Validation loss: 3.1967804885770326

Epoch: 5| Step: 9
Training loss: 2.706352203765056
Validation loss: 3.1956764694058366

Epoch: 5| Step: 10
Training loss: 2.2484018159941455
Validation loss: 3.1940608616594752

Epoch: 87| Step: 0
Training loss: 2.655928827952276
Validation loss: 3.1929446999789897

Epoch: 5| Step: 1
Training loss: 3.369219598259209
Validation loss: 3.1917404594448917

Epoch: 5| Step: 2
Training loss: 3.0647009900654747
Validation loss: 3.1932486776940907

Epoch: 5| Step: 3
Training loss: 3.534885931481239
Validation loss: 3.194008838140873

Epoch: 5| Step: 4
Training loss: 4.233308664885809
Validation loss: 3.192549012065585

Epoch: 5| Step: 5
Training loss: 3.6262028770185832
Validation loss: 3.191785872664479

Epoch: 5| Step: 6
Training loss: 3.9954519642107362
Validation loss: 3.1932477520292335

Epoch: 5| Step: 7
Training loss: 2.9290692707074273
Validation loss: 3.1907656374804914

Epoch: 5| Step: 8
Training loss: 3.464635659971717
Validation loss: 3.191026890675411

Epoch: 5| Step: 9
Training loss: 3.4510269350489144
Validation loss: 3.19237701206997

Epoch: 5| Step: 10
Training loss: 3.1500657937581056
Validation loss: 3.1905022552538984

Epoch: 88| Step: 0
Training loss: 3.25976884314925
Validation loss: 3.1912190470560797

Epoch: 5| Step: 1
Training loss: 3.5289713841934938
Validation loss: 3.19033712789202

Epoch: 5| Step: 2
Training loss: 3.0459405493141283
Validation loss: 3.190344060232662

Epoch: 5| Step: 3
Training loss: 3.3217066811006286
Validation loss: 3.191833071527576

Epoch: 5| Step: 4
Training loss: 3.2371386823481756
Validation loss: 3.1903914829207585

Epoch: 5| Step: 5
Training loss: 2.9214043059625423
Validation loss: 3.1899413190524695

Epoch: 5| Step: 6
Training loss: 3.66132621834275
Validation loss: 3.189210320672254

Epoch: 5| Step: 7
Training loss: 3.7708888322037377
Validation loss: 3.1910125469094868

Epoch: 5| Step: 8
Training loss: 3.8951633441644224
Validation loss: 3.1910673186352088

Epoch: 5| Step: 9
Training loss: 3.5987484875828546
Validation loss: 3.190708679154163

Epoch: 5| Step: 10
Training loss: 3.4128267683700737
Validation loss: 3.1900877609316605

Epoch: 89| Step: 0
Training loss: 3.405489215408654
Validation loss: 3.1900918658557007

Epoch: 5| Step: 1
Training loss: 2.65700484377384
Validation loss: 3.190357549606709

Epoch: 5| Step: 2
Training loss: 3.0566166008440874
Validation loss: 3.190639989712698

Epoch: 5| Step: 3
Training loss: 3.6861956600971473
Validation loss: 3.188170251384268

Epoch: 5| Step: 4
Training loss: 3.993459360833158
Validation loss: 3.1899591000663836

Epoch: 5| Step: 5
Training loss: 3.899795693156791
Validation loss: 3.1909055780132736

Epoch: 5| Step: 6
Training loss: 3.2431600927313102
Validation loss: 3.1907193749369407

Epoch: 5| Step: 7
Training loss: 3.903132300755657
Validation loss: 3.1952898169274344

Epoch: 5| Step: 8
Training loss: 2.81077896018828
Validation loss: 3.190394228651597

Epoch: 5| Step: 9
Training loss: 3.1151719233552018
Validation loss: 3.1875701146996978

Epoch: 5| Step: 10
Training loss: 3.7331788769060528
Validation loss: 3.1865026774460588

Epoch: 90| Step: 0
Training loss: 3.537490866281964
Validation loss: 3.1869435573657356

Epoch: 5| Step: 1
Training loss: 3.5225234780974217
Validation loss: 3.185037234558064

Epoch: 5| Step: 2
Training loss: 2.9913470728897105
Validation loss: 3.1849337748881235

Epoch: 5| Step: 3
Training loss: 3.2896930878400523
Validation loss: 3.1854731199623867

Epoch: 5| Step: 4
Training loss: 4.119171880437962
Validation loss: 3.187340804999997

Epoch: 5| Step: 5
Training loss: 4.078149320449511
Validation loss: 3.1857148217723186

Epoch: 5| Step: 6
Training loss: 3.606451130089405
Validation loss: 3.184448657266315

Epoch: 5| Step: 7
Training loss: 2.7031711287779654
Validation loss: 3.186168018362395

Epoch: 5| Step: 8
Training loss: 3.672899208885647
Validation loss: 3.1837695154463947

Epoch: 5| Step: 9
Training loss: 3.237343720305788
Validation loss: 3.1874948606503946

Epoch: 5| Step: 10
Training loss: 2.474751577529227
Validation loss: 3.189728976753492

Epoch: 91| Step: 0
Training loss: 4.008869113657188
Validation loss: 3.1888707041009026

Epoch: 5| Step: 1
Training loss: 3.5010958727055
Validation loss: 3.184667315850983

Epoch: 5| Step: 2
Training loss: 2.971790082261832
Validation loss: 3.183585465409928

Epoch: 5| Step: 3
Training loss: 3.4996471227140185
Validation loss: 3.1819338132673103

Epoch: 5| Step: 4
Training loss: 3.6998727415727433
Validation loss: 3.183200900774163

Epoch: 5| Step: 5
Training loss: 3.3985026035430757
Validation loss: 3.1826508336148187

Epoch: 5| Step: 6
Training loss: 3.2157225954539497
Validation loss: 3.182040323219973

Epoch: 5| Step: 7
Training loss: 2.610782266655777
Validation loss: 3.1812398772922066

Epoch: 5| Step: 8
Training loss: 3.4658734190422664
Validation loss: 3.183518732121804

Epoch: 5| Step: 9
Training loss: 4.227281322451865
Validation loss: 3.180726533147494

Epoch: 5| Step: 10
Training loss: 2.6255926643892105
Validation loss: 3.1849106017473394

Epoch: 92| Step: 0
Training loss: 3.706375691178669
Validation loss: 3.180797705488532

Epoch: 5| Step: 1
Training loss: 3.5673798718506906
Validation loss: 3.181975470201598

Epoch: 5| Step: 2
Training loss: 3.171359015528058
Validation loss: 3.1811453716345945

Epoch: 5| Step: 3
Training loss: 2.744116819013732
Validation loss: 3.1811952862123327

Epoch: 5| Step: 4
Training loss: 3.38174865768653
Validation loss: 3.179856320589141

Epoch: 5| Step: 5
Training loss: 3.463578777066618
Validation loss: 3.180293990614432

Epoch: 5| Step: 6
Training loss: 3.851702147886718
Validation loss: 3.1796126753812604

Epoch: 5| Step: 7
Training loss: 3.552473581901752
Validation loss: 3.1783189543749355

Epoch: 5| Step: 8
Training loss: 3.5378450906069694
Validation loss: 3.1781379475758715

Epoch: 5| Step: 9
Training loss: 2.60194096375564
Validation loss: 3.177648095027804

Epoch: 5| Step: 10
Training loss: 3.9197918348120577
Validation loss: 3.1787879108492274

Epoch: 93| Step: 0
Training loss: 2.42969907898919
Validation loss: 3.1765837816092337

Epoch: 5| Step: 1
Training loss: 3.6881110768006073
Validation loss: 3.1770954671809926

Epoch: 5| Step: 2
Training loss: 3.39557999366046
Validation loss: 3.1759892837148556

Epoch: 5| Step: 3
Training loss: 3.615301377856952
Validation loss: 3.177395197131724

Epoch: 5| Step: 4
Training loss: 4.047587563955921
Validation loss: 3.177625497236172

Epoch: 5| Step: 5
Training loss: 3.494233831161489
Validation loss: 3.175296410975972

Epoch: 5| Step: 6
Training loss: 3.575879454311224
Validation loss: 3.1787333259507964

Epoch: 5| Step: 7
Training loss: 3.3796306913965455
Validation loss: 3.17627128876015

Epoch: 5| Step: 8
Training loss: 2.8355522629723056
Validation loss: 3.176910346190315

Epoch: 5| Step: 9
Training loss: 3.594180139424538
Validation loss: 3.180894780366222

Epoch: 5| Step: 10
Training loss: 3.300597922747338
Validation loss: 3.17812001572614

Epoch: 94| Step: 0
Training loss: 3.662287625870209
Validation loss: 3.1767683551185013

Epoch: 5| Step: 1
Training loss: 3.795085469566328
Validation loss: 3.1755014167184537

Epoch: 5| Step: 2
Training loss: 3.4265464354424213
Validation loss: 3.180136204369034

Epoch: 5| Step: 3
Training loss: 3.3524450460619386
Validation loss: 3.181068219199287

Epoch: 5| Step: 4
Training loss: 3.1257013678265104
Validation loss: 3.1770059421150156

Epoch: 5| Step: 5
Training loss: 3.4905058291454463
Validation loss: 3.1740477882266283

Epoch: 5| Step: 6
Training loss: 3.140386012459452
Validation loss: 3.1752261972245623

Epoch: 5| Step: 7
Training loss: 2.944562983575934
Validation loss: 3.1747177368042143

Epoch: 5| Step: 8
Training loss: 3.5130896348298077
Validation loss: 3.173235444041004

Epoch: 5| Step: 9
Training loss: 3.5914307117770097
Validation loss: 3.172800808845859

Epoch: 5| Step: 10
Training loss: 3.4825445593223954
Validation loss: 3.1734963526577356

Epoch: 95| Step: 0
Training loss: 3.5073951523894316
Validation loss: 3.1710865385084617

Epoch: 5| Step: 1
Training loss: 3.777237710184293
Validation loss: 3.1719502673939646

Epoch: 5| Step: 2
Training loss: 2.75876080253778
Validation loss: 3.1729869403907434

Epoch: 5| Step: 3
Training loss: 3.1764103077589496
Validation loss: 3.1714994461898645

Epoch: 5| Step: 4
Training loss: 3.956443147931296
Validation loss: 3.1761890709500706

Epoch: 5| Step: 5
Training loss: 3.7195667043212852
Validation loss: 3.1728459558342808

Epoch: 5| Step: 6
Training loss: 3.1973894080154293
Validation loss: 3.1761888110498253

Epoch: 5| Step: 7
Training loss: 2.953415629300172
Validation loss: 3.1764098331915416

Epoch: 5| Step: 8
Training loss: 3.3688482096834957
Validation loss: 3.1711016676624046

Epoch: 5| Step: 9
Training loss: 3.090904082839907
Validation loss: 3.169113050229149

Epoch: 5| Step: 10
Training loss: 3.9567360047647058
Validation loss: 3.168991210944883

Epoch: 96| Step: 0
Training loss: 2.8307105622064763
Validation loss: 3.174530784501355

Epoch: 5| Step: 1
Training loss: 2.997701718221922
Validation loss: 3.1847875620944017

Epoch: 5| Step: 2
Training loss: 3.9078098692154906
Validation loss: 3.2037501531697923

Epoch: 5| Step: 3
Training loss: 2.866192803658564
Validation loss: 3.1723403997392396

Epoch: 5| Step: 4
Training loss: 3.582263003041712
Validation loss: 3.1659295665799676

Epoch: 5| Step: 5
Training loss: 4.1045176296276065
Validation loss: 3.169495724813484

Epoch: 5| Step: 6
Training loss: 3.4686701310044126
Validation loss: 3.1690678023327443

Epoch: 5| Step: 7
Training loss: 3.4586805299565877
Validation loss: 3.1706497498753725

Epoch: 5| Step: 8
Training loss: 3.0402762139470627
Validation loss: 3.1754362315493796

Epoch: 5| Step: 9
Training loss: 3.951496014803113
Validation loss: 3.1778727007563554

Epoch: 5| Step: 10
Training loss: 3.1552228105946925
Validation loss: 3.178160427180515

Epoch: 97| Step: 0
Training loss: 3.1144025020774513
Validation loss: 3.176225317947389

Epoch: 5| Step: 1
Training loss: 3.1641203698411586
Validation loss: 3.172765894734311

Epoch: 5| Step: 2
Training loss: 3.580440255271665
Validation loss: 3.171605912097747

Epoch: 5| Step: 3
Training loss: 3.164441799458578
Validation loss: 3.1671434528194564

Epoch: 5| Step: 4
Training loss: 3.392463572340998
Validation loss: 3.168387742481902

Epoch: 5| Step: 5
Training loss: 3.3935357182473425
Validation loss: 3.1687125741126603

Epoch: 5| Step: 6
Training loss: 3.5689204400777808
Validation loss: 3.1647263936768426

Epoch: 5| Step: 7
Training loss: 2.8460176250906564
Validation loss: 3.166213839223459

Epoch: 5| Step: 8
Training loss: 3.2504646262588457
Validation loss: 3.1657490887803776

Epoch: 5| Step: 9
Training loss: 3.5672875074954096
Validation loss: 3.167367694591278

Epoch: 5| Step: 10
Training loss: 4.472168368587233
Validation loss: 3.1647236378274726

Epoch: 98| Step: 0
Training loss: 3.47897317009449
Validation loss: 3.166389066729297

Epoch: 5| Step: 1
Training loss: 3.5569389172087837
Validation loss: 3.1641231164932977

Epoch: 5| Step: 2
Training loss: 3.054766641747724
Validation loss: 3.1642442763198746

Epoch: 5| Step: 3
Training loss: 3.404649550991038
Validation loss: 3.1630148229334893

Epoch: 5| Step: 4
Training loss: 3.1688059724758677
Validation loss: 3.162306006780008

Epoch: 5| Step: 5
Training loss: 3.321230198316943
Validation loss: 3.162770353706336

Epoch: 5| Step: 6
Training loss: 3.2343042338272885
Validation loss: 3.162275884747252

Epoch: 5| Step: 7
Training loss: 2.9149662692439646
Validation loss: 3.162984540685289

Epoch: 5| Step: 8
Training loss: 4.113899322182865
Validation loss: 3.1628105170987846

Epoch: 5| Step: 9
Training loss: 3.358740884238261
Validation loss: 3.161633603309649

Epoch: 5| Step: 10
Training loss: 3.83408809916048
Validation loss: 3.1586344137400757

Epoch: 99| Step: 0
Training loss: 3.019715692135292
Validation loss: 3.1588678216227786

Epoch: 5| Step: 1
Training loss: 3.9090309924802207
Validation loss: 3.1586449291934127

Epoch: 5| Step: 2
Training loss: 3.715148078975892
Validation loss: 3.159957298835585

Epoch: 5| Step: 3
Training loss: 3.285293558088437
Validation loss: 3.1598847330113613

Epoch: 5| Step: 4
Training loss: 3.5614870203958002
Validation loss: 3.1594526298863026

Epoch: 5| Step: 5
Training loss: 3.309078248635233
Validation loss: 3.16032675314534

Epoch: 5| Step: 6
Training loss: 3.4365922596298435
Validation loss: 3.1568062461790607

Epoch: 5| Step: 7
Training loss: 3.4531798207345954
Validation loss: 3.1582963990727744

Epoch: 5| Step: 8
Training loss: 2.7131095342012963
Validation loss: 3.1574502330203096

Epoch: 5| Step: 9
Training loss: 3.4364675185046205
Validation loss: 3.155987685106028

Epoch: 5| Step: 10
Training loss: 3.509722421217812
Validation loss: 3.154821978678862

Epoch: 100| Step: 0
Training loss: 3.4166004515643738
Validation loss: 3.155959683840751

Epoch: 5| Step: 1
Training loss: 3.332315162288872
Validation loss: 3.1556712517184002

Epoch: 5| Step: 2
Training loss: 3.2609159109719736
Validation loss: 3.1555032690481513

Epoch: 5| Step: 3
Training loss: 3.2761146686872387
Validation loss: 3.1560942502673854

Epoch: 5| Step: 4
Training loss: 3.2608625373211746
Validation loss: 3.1555848900661414

Epoch: 5| Step: 5
Training loss: 3.982414092186792
Validation loss: 3.1563917453305774

Epoch: 5| Step: 6
Training loss: 3.5597510188613164
Validation loss: 3.1537343529297504

Epoch: 5| Step: 7
Training loss: 3.15797618836213
Validation loss: 3.1527081222673377

Epoch: 5| Step: 8
Training loss: 3.212642170769603
Validation loss: 3.1526716105795245

Epoch: 5| Step: 9
Training loss: 3.4612623626278802
Validation loss: 3.152625746141753

Epoch: 5| Step: 10
Training loss: 3.4628114470731663
Validation loss: 3.1536250790465976

Epoch: 101| Step: 0
Training loss: 3.7344052620782855
Validation loss: 3.1527648759155436

Epoch: 5| Step: 1
Training loss: 4.17648232465484
Validation loss: 3.1532390523812275

Epoch: 5| Step: 2
Training loss: 3.7260803294590996
Validation loss: 3.156706608124359

Epoch: 5| Step: 3
Training loss: 2.7654837879401613
Validation loss: 3.1544789409956593

Epoch: 5| Step: 4
Training loss: 3.7025357192001707
Validation loss: 3.151089564771018

Epoch: 5| Step: 5
Training loss: 3.05244382914381
Validation loss: 3.1516084065591383

Epoch: 5| Step: 6
Training loss: 3.352424848540576
Validation loss: 3.1500275431788127

Epoch: 5| Step: 7
Training loss: 3.5976293440650373
Validation loss: 3.1496779585664094

Epoch: 5| Step: 8
Training loss: 3.491169962609198
Validation loss: 3.1493654716897885

Epoch: 5| Step: 9
Training loss: 3.183804782355677
Validation loss: 3.150001415324638

Epoch: 5| Step: 10
Training loss: 1.8985461922130509
Validation loss: 3.1516402354461532

Epoch: 102| Step: 0
Training loss: 2.308712512477679
Validation loss: 3.149417642494527

Epoch: 5| Step: 1
Training loss: 3.363659065460527
Validation loss: 3.149565802509636

Epoch: 5| Step: 2
Training loss: 3.5027523118163195
Validation loss: 3.1482277922502435

Epoch: 5| Step: 3
Training loss: 3.5268054099334902
Validation loss: 3.1492616924347785

Epoch: 5| Step: 4
Training loss: 3.0296505513134235
Validation loss: 3.146436213960679

Epoch: 5| Step: 5
Training loss: 3.2256144684913632
Validation loss: 3.1481671392424406

Epoch: 5| Step: 6
Training loss: 3.1307561123215693
Validation loss: 3.14743991246488

Epoch: 5| Step: 7
Training loss: 3.636786274841362
Validation loss: 3.147519834218219

Epoch: 5| Step: 8
Training loss: 3.918383864435671
Validation loss: 3.1469947047328217

Epoch: 5| Step: 9
Training loss: 3.680860198906506
Validation loss: 3.1462103646205786

Epoch: 5| Step: 10
Training loss: 3.8300601972425907
Validation loss: 3.1455958477157973

Epoch: 103| Step: 0
Training loss: 2.8827914932436696
Validation loss: 3.144636897378123

Epoch: 5| Step: 1
Training loss: 2.996585333133772
Validation loss: 3.14545875627687

Epoch: 5| Step: 2
Training loss: 3.7087641405042375
Validation loss: 3.146028333483795

Epoch: 5| Step: 3
Training loss: 3.969711067197618
Validation loss: 3.1466034602097976

Epoch: 5| Step: 4
Training loss: 3.794923382816221
Validation loss: 3.146022552708338

Epoch: 5| Step: 5
Training loss: 2.8728038858836236
Validation loss: 3.146323329612963

Epoch: 5| Step: 6
Training loss: 3.163412898690675
Validation loss: 3.1436128679918043

Epoch: 5| Step: 7
Training loss: 3.0272810603388205
Validation loss: 3.1436300197038696

Epoch: 5| Step: 8
Training loss: 3.310314249063262
Validation loss: 3.1440922627321086

Epoch: 5| Step: 9
Training loss: 3.307151939664455
Validation loss: 3.1448708338331737

Epoch: 5| Step: 10
Training loss: 4.154538139077297
Validation loss: 3.1437382905806803

Epoch: 104| Step: 0
Training loss: 3.9905228400839214
Validation loss: 3.1443692974213073

Epoch: 5| Step: 1
Training loss: 3.1956488471929188
Validation loss: 3.14273936067347

Epoch: 5| Step: 2
Training loss: 2.9094434031507976
Validation loss: 3.1420971016070536

Epoch: 5| Step: 3
Training loss: 3.6359987129989713
Validation loss: 3.142320684834938

Epoch: 5| Step: 4
Training loss: 3.0347310950418436
Validation loss: 3.1446481998753772

Epoch: 5| Step: 5
Training loss: 2.966705099849848
Validation loss: 3.144811755442015

Epoch: 5| Step: 6
Training loss: 3.772214071208504
Validation loss: 3.1408325756886146

Epoch: 5| Step: 7
Training loss: 2.839656188731769
Validation loss: 3.142264841510511

Epoch: 5| Step: 8
Training loss: 3.1740848754322486
Validation loss: 3.1438184907288877

Epoch: 5| Step: 9
Training loss: 4.0666243524903525
Validation loss: 3.1419269342873215

Epoch: 5| Step: 10
Training loss: 3.4645437220367556
Validation loss: 3.1435779110580313

Epoch: 105| Step: 0
Training loss: 2.619417339502495
Validation loss: 3.144635313362171

Epoch: 5| Step: 1
Training loss: 3.121183277130402
Validation loss: 3.1431905419865926

Epoch: 5| Step: 2
Training loss: 2.8553186212778625
Validation loss: 3.143213080674712

Epoch: 5| Step: 3
Training loss: 3.089524437070116
Validation loss: 3.13983058866418

Epoch: 5| Step: 4
Training loss: 3.2192610547906177
Validation loss: 3.143058596803878

Epoch: 5| Step: 5
Training loss: 3.444731994302785
Validation loss: 3.140189746206234

Epoch: 5| Step: 6
Training loss: 3.1661297861704876
Validation loss: 3.1397325095233346

Epoch: 5| Step: 7
Training loss: 4.673426137774553
Validation loss: 3.1383498514842834

Epoch: 5| Step: 8
Training loss: 3.6990211377639506
Validation loss: 3.1394308488499107

Epoch: 5| Step: 9
Training loss: 3.424876808122866
Validation loss: 3.139304728260997

Epoch: 5| Step: 10
Training loss: 3.589749041315627
Validation loss: 3.1364616789603987

Epoch: 106| Step: 0
Training loss: 2.91471139673298
Validation loss: 3.1370681034655656

Epoch: 5| Step: 1
Training loss: 3.372057444362574
Validation loss: 3.137893336899017

Epoch: 5| Step: 2
Training loss: 3.264356887127332
Validation loss: 3.137243664489607

Epoch: 5| Step: 3
Training loss: 3.2981060315096853
Validation loss: 3.1376450016872415

Epoch: 5| Step: 4
Training loss: 3.5026824753337626
Validation loss: 3.1371750416271267

Epoch: 5| Step: 5
Training loss: 3.3899635337736216
Validation loss: 3.136265756482488

Epoch: 5| Step: 6
Training loss: 3.5788217724029634
Validation loss: 3.1353422191577747

Epoch: 5| Step: 7
Training loss: 3.296895393200035
Validation loss: 3.135696631388359

Epoch: 5| Step: 8
Training loss: 3.060654220207874
Validation loss: 3.1352442440959436

Epoch: 5| Step: 9
Training loss: 3.8658204407808294
Validation loss: 3.1347588404462976

Epoch: 5| Step: 10
Training loss: 3.670575500393549
Validation loss: 3.1348165708372315

Epoch: 107| Step: 0
Training loss: 3.5888443345360828
Validation loss: 3.1358451053144587

Epoch: 5| Step: 1
Training loss: 3.3432139029300276
Validation loss: 3.13431327509666

Epoch: 5| Step: 2
Training loss: 3.093228845338836
Validation loss: 3.1328950558635946

Epoch: 5| Step: 3
Training loss: 3.4041251458227637
Validation loss: 3.1357071371007583

Epoch: 5| Step: 4
Training loss: 3.8092724004733896
Validation loss: 3.1341349438608868

Epoch: 5| Step: 5
Training loss: 3.640996169132521
Validation loss: 3.135011043250118

Epoch: 5| Step: 6
Training loss: 2.9938018666913138
Validation loss: 3.1336791601923957

Epoch: 5| Step: 7
Training loss: 3.0978426594585513
Validation loss: 3.131618596825688

Epoch: 5| Step: 8
Training loss: 3.515555961778727
Validation loss: 3.131807735848763

Epoch: 5| Step: 9
Training loss: 3.081991797365119
Validation loss: 3.1339759796864057

Epoch: 5| Step: 10
Training loss: 3.5964427645204755
Validation loss: 3.1327929273801054

Epoch: 108| Step: 0
Training loss: 3.341871357750464
Validation loss: 3.133282839482339

Epoch: 5| Step: 1
Training loss: 3.9465740943911762
Validation loss: 3.1320451024616878

Epoch: 5| Step: 2
Training loss: 3.372436256117335
Validation loss: 3.134825393208695

Epoch: 5| Step: 3
Training loss: 3.409764987308767
Validation loss: 3.133754083515815

Epoch: 5| Step: 4
Training loss: 3.037032442253104
Validation loss: 3.133391438440491

Epoch: 5| Step: 5
Training loss: 3.972938310030451
Validation loss: 3.1324923244330196

Epoch: 5| Step: 6
Training loss: 3.49217862463043
Validation loss: 3.1304258254243678

Epoch: 5| Step: 7
Training loss: 3.449398740260616
Validation loss: 3.129913462517466

Epoch: 5| Step: 8
Training loss: 2.9798490547507805
Validation loss: 3.130454070644524

Epoch: 5| Step: 9
Training loss: 3.22282492456304
Validation loss: 3.1302113303259107

Epoch: 5| Step: 10
Training loss: 2.6970760160036824
Validation loss: 3.130514170121705

Epoch: 109| Step: 0
Training loss: 3.6627913427510754
Validation loss: 3.127856222503004

Epoch: 5| Step: 1
Training loss: 3.6114266249580727
Validation loss: 3.1292515503317304

Epoch: 5| Step: 2
Training loss: 3.661015722112336
Validation loss: 3.129434830944497

Epoch: 5| Step: 3
Training loss: 3.3703080518159974
Validation loss: 3.1294259180093054

Epoch: 5| Step: 4
Training loss: 2.9469840975132686
Validation loss: 3.128485164052797

Epoch: 5| Step: 5
Training loss: 3.090244349228626
Validation loss: 3.127696472419528

Epoch: 5| Step: 6
Training loss: 3.6412624079463085
Validation loss: 3.1280085939900317

Epoch: 5| Step: 7
Training loss: 3.444362794940653
Validation loss: 3.1274286295865243

Epoch: 5| Step: 8
Training loss: 3.2199047202472784
Validation loss: 3.129053223183105

Epoch: 5| Step: 9
Training loss: 2.8294393109360056
Validation loss: 3.12620224827267

Epoch: 5| Step: 10
Training loss: 3.62286932579612
Validation loss: 3.1317309863212626

Epoch: 110| Step: 0
Training loss: 2.9298289353880724
Validation loss: 3.126685944940802

Epoch: 5| Step: 1
Training loss: 2.533783857122197
Validation loss: 3.1324906368858954

Epoch: 5| Step: 2
Training loss: 3.367634683817035
Validation loss: 3.1293730641097013

Epoch: 5| Step: 3
Training loss: 4.127683518025042
Validation loss: 3.136265128705266

Epoch: 5| Step: 4
Training loss: 3.4007549233165735
Validation loss: 3.124271252065677

Epoch: 5| Step: 5
Training loss: 3.3828581703398037
Validation loss: 3.1247254626366834

Epoch: 5| Step: 6
Training loss: 3.7341042903317816
Validation loss: 3.125116029451657

Epoch: 5| Step: 7
Training loss: 2.906694603823639
Validation loss: 3.1259849751639233

Epoch: 5| Step: 8
Training loss: 3.4035104356417745
Validation loss: 3.125239819584393

Epoch: 5| Step: 9
Training loss: 3.140190891610635
Validation loss: 3.1228016296944188

Epoch: 5| Step: 10
Training loss: 4.027594513213341
Validation loss: 3.1251076242926077

Epoch: 111| Step: 0
Training loss: 3.6309100676430313
Validation loss: 3.123233418891356

Epoch: 5| Step: 1
Training loss: 3.6105891575948386
Validation loss: 3.125355936104476

Epoch: 5| Step: 2
Training loss: 3.7546358064481433
Validation loss: 3.121663931064852

Epoch: 5| Step: 3
Training loss: 3.051555149520717
Validation loss: 3.1238251296743136

Epoch: 5| Step: 4
Training loss: 4.0881766316276895
Validation loss: 3.1241334152505806

Epoch: 5| Step: 5
Training loss: 3.4183596316670855
Validation loss: 3.123104854720379

Epoch: 5| Step: 6
Training loss: 2.645352167146431
Validation loss: 3.123991800741762

Epoch: 5| Step: 7
Training loss: 3.2602616213332594
Validation loss: 3.125099208446546

Epoch: 5| Step: 8
Training loss: 3.0232807286349943
Validation loss: 3.1260903652752474

Epoch: 5| Step: 9
Training loss: 2.720736249405768
Validation loss: 3.1247189696908833

Epoch: 5| Step: 10
Training loss: 3.7137191466106243
Validation loss: 3.1272096463551913

Epoch: 112| Step: 0
Training loss: 3.417226342362906
Validation loss: 3.126394780129367

Epoch: 5| Step: 1
Training loss: 3.292806564807928
Validation loss: 3.122093799330834

Epoch: 5| Step: 2
Training loss: 3.2421489667326133
Validation loss: 3.120867369511223

Epoch: 5| Step: 3
Training loss: 3.73729664941486
Validation loss: 3.120924971610895

Epoch: 5| Step: 4
Training loss: 3.8083383327815814
Validation loss: 3.1197725015665467

Epoch: 5| Step: 5
Training loss: 3.014913049965544
Validation loss: 3.1221742450884196

Epoch: 5| Step: 6
Training loss: 2.902965864043236
Validation loss: 3.1216316971611784

Epoch: 5| Step: 7
Training loss: 3.8573930724794945
Validation loss: 3.120266140660846

Epoch: 5| Step: 8
Training loss: 3.9167762226988065
Validation loss: 3.121836188331494

Epoch: 5| Step: 9
Training loss: 3.387990886410252
Validation loss: 3.120340229249116

Epoch: 5| Step: 10
Training loss: 1.9244958638528098
Validation loss: 3.122490335762151

Epoch: 113| Step: 0
Training loss: 3.272711115614186
Validation loss: 3.1201944428964192

Epoch: 5| Step: 1
Training loss: 2.9658449113546057
Validation loss: 3.121666844829092

Epoch: 5| Step: 2
Training loss: 3.1593212632496535
Validation loss: 3.1198189566259904

Epoch: 5| Step: 3
Training loss: 3.747629815335032
Validation loss: 3.1219435497025696

Epoch: 5| Step: 4
Training loss: 3.7714990411094953
Validation loss: 3.118248890530306

Epoch: 5| Step: 5
Training loss: 4.182114511477343
Validation loss: 3.119984282971202

Epoch: 5| Step: 6
Training loss: 3.0605485888137354
Validation loss: 3.1220883609911145

Epoch: 5| Step: 7
Training loss: 2.87066522631127
Validation loss: 3.1187202476032376

Epoch: 5| Step: 8
Training loss: 2.6381482127780895
Validation loss: 3.1196479102061505

Epoch: 5| Step: 9
Training loss: 3.198043141468292
Validation loss: 3.1181608429061267

Epoch: 5| Step: 10
Training loss: 3.9756396708632313
Validation loss: 3.118206568062516

Epoch: 114| Step: 0
Training loss: 3.0182155096465357
Validation loss: 3.119653363483212

Epoch: 5| Step: 1
Training loss: 3.405526180531311
Validation loss: 3.118772895694915

Epoch: 5| Step: 2
Training loss: 3.2807549966095184
Validation loss: 3.119822906666972

Epoch: 5| Step: 3
Training loss: 3.5117202436297577
Validation loss: 3.122036799344834

Epoch: 5| Step: 4
Training loss: 3.4188287143606955
Validation loss: 3.120403640571758

Epoch: 5| Step: 5
Training loss: 3.4623268387114354
Validation loss: 3.121811169661757

Epoch: 5| Step: 6
Training loss: 3.832402295921983
Validation loss: 3.1230301536693137

Epoch: 5| Step: 7
Training loss: 2.9587281371107848
Validation loss: 3.122318638427

Epoch: 5| Step: 8
Training loss: 3.7133863219538874
Validation loss: 3.1218693727015983

Epoch: 5| Step: 9
Training loss: 3.235211103057675
Validation loss: 3.1182450281089316

Epoch: 5| Step: 10
Training loss: 3.0939485120181835
Validation loss: 3.1160285130114196

Epoch: 115| Step: 0
Training loss: 3.4947044638353586
Validation loss: 3.113018942010547

Epoch: 5| Step: 1
Training loss: 3.763492597775144
Validation loss: 3.112293279077161

Epoch: 5| Step: 2
Training loss: 3.5192552600151132
Validation loss: 3.115217503106488

Epoch: 5| Step: 3
Training loss: 3.5746535073274908
Validation loss: 3.1132018121271727

Epoch: 5| Step: 4
Training loss: 3.7956450554179524
Validation loss: 3.113520807950661

Epoch: 5| Step: 5
Training loss: 2.424684236556004
Validation loss: 3.113793392317962

Epoch: 5| Step: 6
Training loss: 3.3024487859781853
Validation loss: 3.1138046025890556

Epoch: 5| Step: 7
Training loss: 3.449613140364622
Validation loss: 3.112689061836419

Epoch: 5| Step: 8
Training loss: 3.2010595594047366
Validation loss: 3.110910449708191

Epoch: 5| Step: 9
Training loss: 3.6225328929137
Validation loss: 3.1118015659623106

Epoch: 5| Step: 10
Training loss: 2.4706435848495336
Validation loss: 3.1105056622265757

Epoch: 116| Step: 0
Training loss: 3.512516665164606
Validation loss: 3.1112209296169158

Epoch: 5| Step: 1
Training loss: 3.9236110781029145
Validation loss: 3.10978119183472

Epoch: 5| Step: 2
Training loss: 1.9818674298746064
Validation loss: 3.1106610300983277

Epoch: 5| Step: 3
Training loss: 3.5134522908561134
Validation loss: 3.109015659364598

Epoch: 5| Step: 4
Training loss: 2.764212468522721
Validation loss: 3.1097676340558293

Epoch: 5| Step: 5
Training loss: 3.58538468365292
Validation loss: 3.1099012719679755

Epoch: 5| Step: 6
Training loss: 3.361531403871073
Validation loss: 3.1092406122389558

Epoch: 5| Step: 7
Training loss: 3.6746869946523324
Validation loss: 3.1083345948697056

Epoch: 5| Step: 8
Training loss: 3.660576502104387
Validation loss: 3.11037880313511

Epoch: 5| Step: 9
Training loss: 3.1288638832376683
Validation loss: 3.1076921788231866

Epoch: 5| Step: 10
Training loss: 3.5082062837938817
Validation loss: 3.1097342496488087

Epoch: 117| Step: 0
Training loss: 3.4866348943727554
Validation loss: 3.1083869866989335

Epoch: 5| Step: 1
Training loss: 2.95094355994518
Validation loss: 3.108058341286179

Epoch: 5| Step: 2
Training loss: 3.2592909131857044
Validation loss: 3.107568410700307

Epoch: 5| Step: 3
Training loss: 3.9380754322830795
Validation loss: 3.10708514224501

Epoch: 5| Step: 4
Training loss: 3.215683745059857
Validation loss: 3.1077793293931344

Epoch: 5| Step: 5
Training loss: 3.2016015872831285
Validation loss: 3.108458838045568

Epoch: 5| Step: 6
Training loss: 3.2772669277349076
Validation loss: 3.1078440545176793

Epoch: 5| Step: 7
Training loss: 2.8472419510651483
Validation loss: 3.106489983774038

Epoch: 5| Step: 8
Training loss: 4.0443092961722735
Validation loss: 3.1065940976168958

Epoch: 5| Step: 9
Training loss: 2.999073998271289
Validation loss: 3.1068728974409168

Epoch: 5| Step: 10
Training loss: 3.5892284310113878
Validation loss: 3.111322021025204

Epoch: 118| Step: 0
Training loss: 3.318687130894703
Validation loss: 3.1070049106146365

Epoch: 5| Step: 1
Training loss: 2.96518276120934
Validation loss: 3.1120649815666988

Epoch: 5| Step: 2
Training loss: 3.4350220505452267
Validation loss: 3.1135139359335215

Epoch: 5| Step: 3
Training loss: 2.6544192119641234
Validation loss: 3.118425144383808

Epoch: 5| Step: 4
Training loss: 3.377805038671187
Validation loss: 3.1220643132832615

Epoch: 5| Step: 5
Training loss: 4.189979616174757
Validation loss: 3.1137151127747056

Epoch: 5| Step: 6
Training loss: 3.681836191340968
Validation loss: 3.104856510375015

Epoch: 5| Step: 7
Training loss: 3.5175577911856766
Validation loss: 3.104394982918592

Epoch: 5| Step: 8
Training loss: 3.0202770027802
Validation loss: 3.103278462820029

Epoch: 5| Step: 9
Training loss: 2.8700753202756153
Validation loss: 3.1045367597086715

Epoch: 5| Step: 10
Training loss: 3.7319755986060934
Validation loss: 3.104973296695192

Epoch: 119| Step: 0
Training loss: 3.692854791847613
Validation loss: 3.1064196936925192

Epoch: 5| Step: 1
Training loss: 3.118534265674585
Validation loss: 3.1059839039234083

Epoch: 5| Step: 2
Training loss: 3.2136112413752476
Validation loss: 3.1067844680035708

Epoch: 5| Step: 3
Training loss: 3.227006710777244
Validation loss: 3.1050403772389745

Epoch: 5| Step: 4
Training loss: 3.5749993811119984
Validation loss: 3.105149648561333

Epoch: 5| Step: 5
Training loss: 3.1653771200785688
Validation loss: 3.1045691744075263

Epoch: 5| Step: 6
Training loss: 3.791923402471358
Validation loss: 3.104733277400418

Epoch: 5| Step: 7
Training loss: 3.272008178682062
Validation loss: 3.1042433241497664

Epoch: 5| Step: 8
Training loss: 3.5011510318713235
Validation loss: 3.103445446807706

Epoch: 5| Step: 9
Training loss: 3.3968416522932583
Validation loss: 3.1012868765215327

Epoch: 5| Step: 10
Training loss: 2.861464107263658
Validation loss: 3.1019203238134443

Epoch: 120| Step: 0
Training loss: 3.811901608393154
Validation loss: 3.100226231410257

Epoch: 5| Step: 1
Training loss: 3.3504784882854968
Validation loss: 3.1015453123756713

Epoch: 5| Step: 2
Training loss: 3.7727795771705295
Validation loss: 3.1005539640290096

Epoch: 5| Step: 3
Training loss: 3.2834989560821066
Validation loss: 3.1002835827782067

Epoch: 5| Step: 4
Training loss: 3.464140157211973
Validation loss: 3.0995376485257906

Epoch: 5| Step: 5
Training loss: 2.703441094235271
Validation loss: 3.100389069280792

Epoch: 5| Step: 6
Training loss: 3.359581945388194
Validation loss: 3.1021415451164582

Epoch: 5| Step: 7
Training loss: 3.2471152487492136
Validation loss: 3.099998542892479

Epoch: 5| Step: 8
Training loss: 2.9853414997683694
Validation loss: 3.101506091437383

Epoch: 5| Step: 9
Training loss: 3.49021019310838
Validation loss: 3.100116733625046

Epoch: 5| Step: 10
Training loss: 3.330599442561286
Validation loss: 3.0997607088504453

Epoch: 121| Step: 0
Training loss: 3.824175856820227
Validation loss: 3.09945588406074

Epoch: 5| Step: 1
Training loss: 3.4066394268322915
Validation loss: 3.0992342295189617

Epoch: 5| Step: 2
Training loss: 2.5934280747250296
Validation loss: 3.0984965307686347

Epoch: 5| Step: 3
Training loss: 2.969088243991807
Validation loss: 3.0978423383665117

Epoch: 5| Step: 4
Training loss: 3.520864693466261
Validation loss: 3.09713851069039

Epoch: 5| Step: 5
Training loss: 4.051715798204981
Validation loss: 3.0961310657136867

Epoch: 5| Step: 6
Training loss: 3.3946072445913
Validation loss: 3.0958032913438576

Epoch: 5| Step: 7
Training loss: 3.3342934338390036
Validation loss: 3.0975466729532553

Epoch: 5| Step: 8
Training loss: 3.442639618080584
Validation loss: 3.0961743887720585

Epoch: 5| Step: 9
Training loss: 3.365659575076656
Validation loss: 3.0968371306603033

Epoch: 5| Step: 10
Training loss: 2.6041756184741973
Validation loss: 3.0949288619879365

Epoch: 122| Step: 0
Training loss: 2.8773402764793725
Validation loss: 3.094983998846596

Epoch: 5| Step: 1
Training loss: 3.540538623156854
Validation loss: 3.095786537968674

Epoch: 5| Step: 2
Training loss: 3.244312591863735
Validation loss: 3.0945846527203322

Epoch: 5| Step: 3
Training loss: 3.459024076917833
Validation loss: 3.0959711488481387

Epoch: 5| Step: 4
Training loss: 3.3240094595268417
Validation loss: 3.09315094296422

Epoch: 5| Step: 5
Training loss: 3.484552079563517
Validation loss: 3.0934927145501194

Epoch: 5| Step: 6
Training loss: 3.3563751311036314
Validation loss: 3.094758595348357

Epoch: 5| Step: 7
Training loss: 3.329086952703349
Validation loss: 3.09339205818565

Epoch: 5| Step: 8
Training loss: 2.788927603913484
Validation loss: 3.0932484843111503

Epoch: 5| Step: 9
Training loss: 2.974063334752004
Validation loss: 3.0942346568838364

Epoch: 5| Step: 10
Training loss: 4.413709238145576
Validation loss: 3.0925501981529093

Epoch: 123| Step: 0
Training loss: 3.4917512147510354
Validation loss: 3.092540829085798

Epoch: 5| Step: 1
Training loss: 2.6625671664796786
Validation loss: 3.091064434360471

Epoch: 5| Step: 2
Training loss: 3.280417781832713
Validation loss: 3.0917249714256716

Epoch: 5| Step: 3
Training loss: 2.3635748058252637
Validation loss: 3.092511809832664

Epoch: 5| Step: 4
Training loss: 3.965313241907291
Validation loss: 3.0921849708704516

Epoch: 5| Step: 5
Training loss: 3.7159211755364634
Validation loss: 3.0922632549010296

Epoch: 5| Step: 6
Training loss: 3.6364631931808256
Validation loss: 3.0936269245710717

Epoch: 5| Step: 7
Training loss: 3.35614852325642
Validation loss: 3.0919190332793094

Epoch: 5| Step: 8
Training loss: 3.3071256981404233
Validation loss: 3.0910233453663025

Epoch: 5| Step: 9
Training loss: 3.4822151092746614
Validation loss: 3.0938539111553705

Epoch: 5| Step: 10
Training loss: 3.261712609930598
Validation loss: 3.0912217372435267

Epoch: 124| Step: 0
Training loss: 3.624318025828273
Validation loss: 3.0907355296078314

Epoch: 5| Step: 1
Training loss: 3.905521660614408
Validation loss: 3.0917921768909506

Epoch: 5| Step: 2
Training loss: 2.473531414473289
Validation loss: 3.094167989993569

Epoch: 5| Step: 3
Training loss: 3.9347575491795164
Validation loss: 3.0917866910560297

Epoch: 5| Step: 4
Training loss: 2.218782451553504
Validation loss: 3.092621968145069

Epoch: 5| Step: 5
Training loss: 3.7395861669049735
Validation loss: 3.098240063137126

Epoch: 5| Step: 6
Training loss: 3.491248087651992
Validation loss: 3.0917186007195196

Epoch: 5| Step: 7
Training loss: 3.3956186113555478
Validation loss: 3.0881011327207357

Epoch: 5| Step: 8
Training loss: 3.3084911344033827
Validation loss: 3.0893033313198943

Epoch: 5| Step: 9
Training loss: 3.289500880078779
Validation loss: 3.0893625202245416

Epoch: 5| Step: 10
Training loss: 2.944801670773091
Validation loss: 3.0860444371906155

Epoch: 125| Step: 0
Training loss: 4.110505039343316
Validation loss: 3.086530132925359

Epoch: 5| Step: 1
Training loss: 3.871034254123081
Validation loss: 3.084012587529953

Epoch: 5| Step: 2
Training loss: 3.1717837466187606
Validation loss: 3.086711960302108

Epoch: 5| Step: 3
Training loss: 3.3002227130065536
Validation loss: 3.0870306107834153

Epoch: 5| Step: 4
Training loss: 3.1172466989503254
Validation loss: 3.085464783186059

Epoch: 5| Step: 5
Training loss: 2.913866460920129
Validation loss: 3.084833690264787

Epoch: 5| Step: 6
Training loss: 3.2368143069861386
Validation loss: 3.084775163250825

Epoch: 5| Step: 7
Training loss: 3.222270484723651
Validation loss: 3.085421924609157

Epoch: 5| Step: 8
Training loss: 3.6125836003011806
Validation loss: 3.08712315200245

Epoch: 5| Step: 9
Training loss: 2.917707275768135
Validation loss: 3.085136159787714

Epoch: 5| Step: 10
Training loss: 3.1184697394114633
Validation loss: 3.084779999199111

Epoch: 126| Step: 0
Training loss: 3.516552611997895
Validation loss: 3.08423122567911

Epoch: 5| Step: 1
Training loss: 2.6364882530907097
Validation loss: 3.0844992888946074

Epoch: 5| Step: 2
Training loss: 3.613787179529346
Validation loss: 3.084664035741008

Epoch: 5| Step: 3
Training loss: 2.7252299815430305
Validation loss: 3.08598058983826

Epoch: 5| Step: 4
Training loss: 3.4121778510766303
Validation loss: 3.0859829067650324

Epoch: 5| Step: 5
Training loss: 3.5047136990320076
Validation loss: 3.0834437541484836

Epoch: 5| Step: 6
Training loss: 3.780694463605361
Validation loss: 3.083800586980997

Epoch: 5| Step: 7
Training loss: 3.6401255514688695
Validation loss: 3.0844123208462686

Epoch: 5| Step: 8
Training loss: 3.220171864347849
Validation loss: 3.085119224671452

Epoch: 5| Step: 9
Training loss: 3.556753509757853
Validation loss: 3.082544291229581

Epoch: 5| Step: 10
Training loss: 2.8839066246037843
Validation loss: 3.083512092060183

Epoch: 127| Step: 0
Training loss: 3.0472701378896367
Validation loss: 3.0836845858602646

Epoch: 5| Step: 1
Training loss: 3.873862437967236
Validation loss: 3.083257935878963

Epoch: 5| Step: 2
Training loss: 3.4963564299885763
Validation loss: 3.0806687494856813

Epoch: 5| Step: 3
Training loss: 3.2135343793707047
Validation loss: 3.082234211392687

Epoch: 5| Step: 4
Training loss: 3.4267917652029847
Validation loss: 3.083574420867927

Epoch: 5| Step: 5
Training loss: 3.9575086571122196
Validation loss: 3.0842256499243534

Epoch: 5| Step: 6
Training loss: 3.5116087627902504
Validation loss: 3.0824543305021663

Epoch: 5| Step: 7
Training loss: 3.241104128814117
Validation loss: 3.079811120356566

Epoch: 5| Step: 8
Training loss: 3.261172823418609
Validation loss: 3.07996056283879

Epoch: 5| Step: 9
Training loss: 2.8139341300732528
Validation loss: 3.0809425213067234

Epoch: 5| Step: 10
Training loss: 2.5550584436290507
Validation loss: 3.0803343503833993

Epoch: 128| Step: 0
Training loss: 3.430145441647408
Validation loss: 3.0799842700681763

Epoch: 5| Step: 1
Training loss: 3.749962997253963
Validation loss: 3.077595175175429

Epoch: 5| Step: 2
Training loss: 3.112330579934263
Validation loss: 3.078676465751725

Epoch: 5| Step: 3
Training loss: 3.5787394300085538
Validation loss: 3.078650425175555

Epoch: 5| Step: 4
Training loss: 3.3529489490548854
Validation loss: 3.078330026122653

Epoch: 5| Step: 5
Training loss: 2.9906186605005627
Validation loss: 3.07969771016849

Epoch: 5| Step: 6
Training loss: 3.47015970813497
Validation loss: 3.079662268316065

Epoch: 5| Step: 7
Training loss: 3.2900670345631173
Validation loss: 3.076833312892118

Epoch: 5| Step: 8
Training loss: 3.6723636383230946
Validation loss: 3.079152421900167

Epoch: 5| Step: 9
Training loss: 2.8752126200463217
Validation loss: 3.076133378962061

Epoch: 5| Step: 10
Training loss: 3.054198555218253
Validation loss: 3.076810126306054

Epoch: 129| Step: 0
Training loss: 3.2357960403445505
Validation loss: 3.076803076476075

Epoch: 5| Step: 1
Training loss: 3.0640760764794357
Validation loss: 3.0782227784596845

Epoch: 5| Step: 2
Training loss: 3.539131079676663
Validation loss: 3.076555918940743

Epoch: 5| Step: 3
Training loss: 2.6313713498799896
Validation loss: 3.0767533489279097

Epoch: 5| Step: 4
Training loss: 3.724349094332141
Validation loss: 3.078031033874974

Epoch: 5| Step: 5
Training loss: 4.065919346750172
Validation loss: 3.07587454826965

Epoch: 5| Step: 6
Training loss: 3.015352226926267
Validation loss: 3.077630492559886

Epoch: 5| Step: 7
Training loss: 2.974470068912601
Validation loss: 3.0769961664897525

Epoch: 5| Step: 8
Training loss: 3.4093142384290394
Validation loss: 3.075787057136876

Epoch: 5| Step: 9
Training loss: 3.038587047581086
Validation loss: 3.077136948723596

Epoch: 5| Step: 10
Training loss: 3.81114572954782
Validation loss: 3.0751677985487076

Epoch: 130| Step: 0
Training loss: 2.830522058813046
Validation loss: 3.0742221306941753

Epoch: 5| Step: 1
Training loss: 3.456390907767784
Validation loss: 3.076157270697326

Epoch: 5| Step: 2
Training loss: 3.0735029965099536
Validation loss: 3.073984438988261

Epoch: 5| Step: 3
Training loss: 3.6701601609875016
Validation loss: 3.075433773383187

Epoch: 5| Step: 4
Training loss: 2.923443052204024
Validation loss: 3.073656500675737

Epoch: 5| Step: 5
Training loss: 3.1727160010667976
Validation loss: 3.0766908477731345

Epoch: 5| Step: 6
Training loss: 3.0725836277033953
Validation loss: 3.071312736499417

Epoch: 5| Step: 7
Training loss: 3.629944290490281
Validation loss: 3.073451521461477

Epoch: 5| Step: 8
Training loss: 3.428251552419256
Validation loss: 3.0722548063848745

Epoch: 5| Step: 9
Training loss: 3.6455560778599043
Validation loss: 3.0733586795209185

Epoch: 5| Step: 10
Training loss: 3.6885202580480376
Validation loss: 3.0715445287186736

Epoch: 131| Step: 0
Training loss: 2.1799095341521406
Validation loss: 3.0718212151643884

Epoch: 5| Step: 1
Training loss: 3.450819255471887
Validation loss: 3.0702542497748

Epoch: 5| Step: 2
Training loss: 3.313112598130439
Validation loss: 3.0758328796267786

Epoch: 5| Step: 3
Training loss: 2.5503779000402895
Validation loss: 3.07400243621761

Epoch: 5| Step: 4
Training loss: 3.162101835132302
Validation loss: 3.072169153984881

Epoch: 5| Step: 5
Training loss: 3.8260649451463236
Validation loss: 3.080367006448165

Epoch: 5| Step: 6
Training loss: 2.900329465895588
Validation loss: 3.085958712281521

Epoch: 5| Step: 7
Training loss: 3.9984225500557025
Validation loss: 3.0803552999737014

Epoch: 5| Step: 8
Training loss: 3.353310722618648
Validation loss: 3.0706409724413626

Epoch: 5| Step: 9
Training loss: 3.4073334816808436
Validation loss: 3.0732631136965396

Epoch: 5| Step: 10
Training loss: 4.135107200183187
Validation loss: 3.0701931151577364

Epoch: 132| Step: 0
Training loss: 4.042822970650766
Validation loss: 3.0689546305040873

Epoch: 5| Step: 1
Training loss: 3.3064349809613973
Validation loss: 3.0675166998327397

Epoch: 5| Step: 2
Training loss: 3.318712562594133
Validation loss: 3.067004313635787

Epoch: 5| Step: 3
Training loss: 3.2673808218973703
Validation loss: 3.0675799286199315

Epoch: 5| Step: 4
Training loss: 3.035937902084379
Validation loss: 3.064392310514036

Epoch: 5| Step: 5
Training loss: 3.4372688909349045
Validation loss: 3.0666313189635757

Epoch: 5| Step: 6
Training loss: 3.4798077813040504
Validation loss: 3.0673206787155727

Epoch: 5| Step: 7
Training loss: 3.172671964898134
Validation loss: 3.066814220787866

Epoch: 5| Step: 8
Training loss: 2.65972601146334
Validation loss: 3.0692616718263164

Epoch: 5| Step: 9
Training loss: 3.6474955811189447
Validation loss: 3.0644229680458617

Epoch: 5| Step: 10
Training loss: 2.988985504738051
Validation loss: 3.0656462616463473

Epoch: 133| Step: 0
Training loss: 2.9272004417442035
Validation loss: 3.067700900176705

Epoch: 5| Step: 1
Training loss: 2.939767489938186
Validation loss: 3.0620087176594737

Epoch: 5| Step: 2
Training loss: 3.0875255506438983
Validation loss: 3.0605074452920835

Epoch: 5| Step: 3
Training loss: 3.602067427915394
Validation loss: 3.060699745755521

Epoch: 5| Step: 4
Training loss: 3.213950421238738
Validation loss: 3.0605116268487498

Epoch: 5| Step: 5
Training loss: 3.4291573290661064
Validation loss: 3.0606409021484473

Epoch: 5| Step: 6
Training loss: 3.424379312004637
Validation loss: 3.0605156978299193

Epoch: 5| Step: 7
Training loss: 3.4339313362824027
Validation loss: 3.058648234323588

Epoch: 5| Step: 8
Training loss: 3.498436033411302
Validation loss: 3.0602114139201557

Epoch: 5| Step: 9
Training loss: 3.189672589854443
Validation loss: 3.061194438959132

Epoch: 5| Step: 10
Training loss: 3.7889226828665588
Validation loss: 3.058397186324452

Epoch: 134| Step: 0
Training loss: 2.719151960452597
Validation loss: 3.0607843689403023

Epoch: 5| Step: 1
Training loss: 3.765031696606635
Validation loss: 3.060527806872764

Epoch: 5| Step: 2
Training loss: 2.8636802405756954
Validation loss: 3.0608635490350626

Epoch: 5| Step: 3
Training loss: 3.416987721935493
Validation loss: 3.061366790931485

Epoch: 5| Step: 4
Training loss: 3.0785963597993526
Validation loss: 3.0579619613678135

Epoch: 5| Step: 5
Training loss: 3.437994626611901
Validation loss: 3.0562210406762054

Epoch: 5| Step: 6
Training loss: 3.736848530717872
Validation loss: 3.0565333636176404

Epoch: 5| Step: 7
Training loss: 3.5653760577399782
Validation loss: 3.0548183259040176

Epoch: 5| Step: 8
Training loss: 3.4141236742767296
Validation loss: 3.0582470070057086

Epoch: 5| Step: 9
Training loss: 2.7628074129728946
Validation loss: 3.059613865009317

Epoch: 5| Step: 10
Training loss: 3.600714130566468
Validation loss: 3.058674995021083

Epoch: 135| Step: 0
Training loss: 2.1949398498287955
Validation loss: 3.057532998183828

Epoch: 5| Step: 1
Training loss: 3.6303463676549526
Validation loss: 3.0586175474074735

Epoch: 5| Step: 2
Training loss: 3.5820574743877147
Validation loss: 3.0561309442986495

Epoch: 5| Step: 3
Training loss: 3.8157942250909316
Validation loss: 3.0581986970502304

Epoch: 5| Step: 4
Training loss: 3.1520334915957213
Validation loss: 3.054077146207802

Epoch: 5| Step: 5
Training loss: 3.680761743364215
Validation loss: 3.053638833936962

Epoch: 5| Step: 6
Training loss: 3.409536753313034
Validation loss: 3.0536997500829894

Epoch: 5| Step: 7
Training loss: 3.42613895162539
Validation loss: 3.0547203446364892

Epoch: 5| Step: 8
Training loss: 3.6033101175732516
Validation loss: 3.0516627622966626

Epoch: 5| Step: 9
Training loss: 2.901023513125334
Validation loss: 3.05370513307759

Epoch: 5| Step: 10
Training loss: 2.6147897241195293
Validation loss: 3.0541245644386854

Epoch: 136| Step: 0
Training loss: 2.850649000191016
Validation loss: 3.0550186325618642

Epoch: 5| Step: 1
Training loss: 3.1769515880513928
Validation loss: 3.054575687448972

Epoch: 5| Step: 2
Training loss: 3.6075848520389155
Validation loss: 3.0524514853432465

Epoch: 5| Step: 3
Training loss: 3.2672053989264915
Validation loss: 3.0525180966594836

Epoch: 5| Step: 4
Training loss: 3.0697503970689826
Validation loss: 3.050882781137029

Epoch: 5| Step: 5
Training loss: 3.1945844720934864
Validation loss: 3.0490298879636586

Epoch: 5| Step: 6
Training loss: 4.040074588729163
Validation loss: 3.0501529113293726

Epoch: 5| Step: 7
Training loss: 3.7916125339095244
Validation loss: 3.048682518034

Epoch: 5| Step: 8
Training loss: 3.207223939856808
Validation loss: 3.0498352008275975

Epoch: 5| Step: 9
Training loss: 2.800347160207442
Validation loss: 3.051506290038126

Epoch: 5| Step: 10
Training loss: 3.240690837253861
Validation loss: 3.048793888311702

Epoch: 137| Step: 0
Training loss: 2.959235434378127
Validation loss: 3.0482409725921196

Epoch: 5| Step: 1
Training loss: 3.6235640740175605
Validation loss: 3.049994490571596

Epoch: 5| Step: 2
Training loss: 3.8207460871185153
Validation loss: 3.0489766762920905

Epoch: 5| Step: 3
Training loss: 2.7779409032183677
Validation loss: 3.0483998528264804

Epoch: 5| Step: 4
Training loss: 4.005673676217497
Validation loss: 3.0464362052265552

Epoch: 5| Step: 5
Training loss: 3.2942189007712783
Validation loss: 3.049315403683669

Epoch: 5| Step: 6
Training loss: 3.3784828582279123
Validation loss: 3.057325377472963

Epoch: 5| Step: 7
Training loss: 2.9219794433204864
Validation loss: 3.045640586101922

Epoch: 5| Step: 8
Training loss: 3.19416501209811
Validation loss: 3.0461711061005743

Epoch: 5| Step: 9
Training loss: 2.6285901722772844
Validation loss: 3.0463515487011463

Epoch: 5| Step: 10
Training loss: 3.598249719898958
Validation loss: 3.048905681667822

Epoch: 138| Step: 0
Training loss: 3.244904558515099
Validation loss: 3.0499012993816463

Epoch: 5| Step: 1
Training loss: 4.247380066200553
Validation loss: 3.0516066108376325

Epoch: 5| Step: 2
Training loss: 3.2744354693324262
Validation loss: 3.05105625336575

Epoch: 5| Step: 3
Training loss: 3.2932541475802015
Validation loss: 3.0505322219784596

Epoch: 5| Step: 4
Training loss: 2.3228805151437033
Validation loss: 3.0476054664049546

Epoch: 5| Step: 5
Training loss: 3.0565155101191017
Validation loss: 3.04686806096627

Epoch: 5| Step: 6
Training loss: 2.7382674931113953
Validation loss: 3.0471410887047035

Epoch: 5| Step: 7
Training loss: 3.3560453725482526
Validation loss: 3.0480865265877655

Epoch: 5| Step: 8
Training loss: 3.512776352406507
Validation loss: 3.0466763541288695

Epoch: 5| Step: 9
Training loss: 3.4792666087767303
Validation loss: 3.048779728020734

Epoch: 5| Step: 10
Training loss: 3.6484483477739564
Validation loss: 3.047300819614283

Epoch: 139| Step: 0
Training loss: 3.4226024673091904
Validation loss: 3.049405255858201

Epoch: 5| Step: 1
Training loss: 3.835144831224089
Validation loss: 3.0471108655819186

Epoch: 5| Step: 2
Training loss: 3.524818707937775
Validation loss: 3.04447053155555

Epoch: 5| Step: 3
Training loss: 2.9824215552349207
Validation loss: 3.04335809917684

Epoch: 5| Step: 4
Training loss: 3.323538184961101
Validation loss: 3.043468205356311

Epoch: 5| Step: 5
Training loss: 3.4747582715163357
Validation loss: 3.0438994117187006

Epoch: 5| Step: 6
Training loss: 2.711267720538734
Validation loss: 3.0452648316133684

Epoch: 5| Step: 7
Training loss: 3.3088589216346547
Validation loss: 3.0437357601147594

Epoch: 5| Step: 8
Training loss: 3.162697580068507
Validation loss: 3.0452306912443485

Epoch: 5| Step: 9
Training loss: 3.3027729232947762
Validation loss: 3.044371903992439

Epoch: 5| Step: 10
Training loss: 3.243393712698742
Validation loss: 3.0429391147754785

Epoch: 140| Step: 0
Training loss: 3.269176833109169
Validation loss: 3.0452579621513225

Epoch: 5| Step: 1
Training loss: 3.165161092795621
Validation loss: 3.0432929881539024

Epoch: 5| Step: 2
Training loss: 3.565744495311907
Validation loss: 3.042224243501045

Epoch: 5| Step: 3
Training loss: 3.5732652736938695
Validation loss: 3.0428242528062266

Epoch: 5| Step: 4
Training loss: 2.9720188816030393
Validation loss: 3.04105364333234

Epoch: 5| Step: 5
Training loss: 2.409690082297848
Validation loss: 3.042120023332675

Epoch: 5| Step: 6
Training loss: 3.232777961410019
Validation loss: 3.0438625069885665

Epoch: 5| Step: 7
Training loss: 3.301339259184951
Validation loss: 3.046347781945276

Epoch: 5| Step: 8
Training loss: 3.748346218382684
Validation loss: 3.042808398221422

Epoch: 5| Step: 9
Training loss: 3.695992469730385
Validation loss: 3.0492628746319475

Epoch: 5| Step: 10
Training loss: 3.2480925317653235
Validation loss: 3.0438236225394206

Epoch: 141| Step: 0
Training loss: 3.6863331645847452
Validation loss: 3.044696814514577

Epoch: 5| Step: 1
Training loss: 3.646658289990983
Validation loss: 3.0394118955137746

Epoch: 5| Step: 2
Training loss: 3.1277650425954517
Validation loss: 3.0412899350980744

Epoch: 5| Step: 3
Training loss: 3.2334471030390857
Validation loss: 3.039234436892481

Epoch: 5| Step: 4
Training loss: 3.6662284126777727
Validation loss: 3.040856992935791

Epoch: 5| Step: 5
Training loss: 3.5020511611347254
Validation loss: 3.0397207503278696

Epoch: 5| Step: 6
Training loss: 2.7005551862355652
Validation loss: 3.0393869591822527

Epoch: 5| Step: 7
Training loss: 2.798926426930794
Validation loss: 3.0393985332958136

Epoch: 5| Step: 8
Training loss: 3.6720519976871597
Validation loss: 3.0408276136586188

Epoch: 5| Step: 9
Training loss: 3.447646822939185
Validation loss: 3.0434330188491927

Epoch: 5| Step: 10
Training loss: 2.5247969139689452
Validation loss: 3.041542573814471

Epoch: 142| Step: 0
Training loss: 3.183781118671459
Validation loss: 3.038959625752743

Epoch: 5| Step: 1
Training loss: 3.1073957882115253
Validation loss: 3.039130546933537

Epoch: 5| Step: 2
Training loss: 3.6462003396006515
Validation loss: 3.0363100420539966

Epoch: 5| Step: 3
Training loss: 3.0868870300441644
Validation loss: 3.0356342742025686

Epoch: 5| Step: 4
Training loss: 3.6781987703844945
Validation loss: 3.0366667714986866

Epoch: 5| Step: 5
Training loss: 3.0333199266689386
Validation loss: 3.03551328225756

Epoch: 5| Step: 6
Training loss: 2.827526977707174
Validation loss: 3.0362038457263316

Epoch: 5| Step: 7
Training loss: 3.683681515308508
Validation loss: 3.0395887862760644

Epoch: 5| Step: 8
Training loss: 2.835333305290121
Validation loss: 3.040347877212893

Epoch: 5| Step: 9
Training loss: 3.2271340812959894
Validation loss: 3.040129903087405

Epoch: 5| Step: 10
Training loss: 3.908292678805927
Validation loss: 3.042781336214022

Epoch: 143| Step: 0
Training loss: 3.6297811350771565
Validation loss: 3.0414482116354353

Epoch: 5| Step: 1
Training loss: 3.4389381868043416
Validation loss: 3.0410691614329552

Epoch: 5| Step: 2
Training loss: 3.4212800645326102
Validation loss: 3.0430267440929097

Epoch: 5| Step: 3
Training loss: 3.417923269786701
Validation loss: 3.041152816861189

Epoch: 5| Step: 4
Training loss: 2.7138248425200375
Validation loss: 3.0367286080740756

Epoch: 5| Step: 5
Training loss: 2.975220064631085
Validation loss: 3.0362198040358317

Epoch: 5| Step: 6
Training loss: 3.232748018620086
Validation loss: 3.0338047950794342

Epoch: 5| Step: 7
Training loss: 3.9826599020026214
Validation loss: 3.033517762028932

Epoch: 5| Step: 8
Training loss: 3.369992815683557
Validation loss: 3.0317746169259614

Epoch: 5| Step: 9
Training loss: 2.8437961113513417
Validation loss: 3.033724893541547

Epoch: 5| Step: 10
Training loss: 3.0588327365624477
Validation loss: 3.034148669464774

Epoch: 144| Step: 0
Training loss: 3.051697030644704
Validation loss: 3.0335430728142114

Epoch: 5| Step: 1
Training loss: 3.408809435234987
Validation loss: 3.033942616357394

Epoch: 5| Step: 2
Training loss: 3.230872427686047
Validation loss: 3.0333045007695976

Epoch: 5| Step: 3
Training loss: 2.7327978326786657
Validation loss: 3.033165902492409

Epoch: 5| Step: 4
Training loss: 3.5230999634783475
Validation loss: 3.0339492385095816

Epoch: 5| Step: 5
Training loss: 3.9301414151750222
Validation loss: 3.0335686580427956

Epoch: 5| Step: 6
Training loss: 3.040910252268803
Validation loss: 3.0317885040313866

Epoch: 5| Step: 7
Training loss: 3.0807618595988693
Validation loss: 3.0312938393121778

Epoch: 5| Step: 8
Training loss: 3.347062368695714
Validation loss: 3.031663926227791

Epoch: 5| Step: 9
Training loss: 3.152069798398673
Validation loss: 3.0314835142467764

Epoch: 5| Step: 10
Training loss: 3.7150733788535204
Validation loss: 3.030939668788854

Epoch: 145| Step: 0
Training loss: 3.6865381829175305
Validation loss: 3.0302435816716145

Epoch: 5| Step: 1
Training loss: 3.0536138106156
Validation loss: 3.02964382583864

Epoch: 5| Step: 2
Training loss: 3.1845125148082265
Validation loss: 3.0313769813854754

Epoch: 5| Step: 3
Training loss: 2.9801788389063555
Validation loss: 3.027172394506557

Epoch: 5| Step: 4
Training loss: 3.12295419485096
Validation loss: 3.0306134686257535

Epoch: 5| Step: 5
Training loss: 4.178240431087659
Validation loss: 3.029640249856662

Epoch: 5| Step: 6
Training loss: 3.2810388406293307
Validation loss: 3.0290794707902178

Epoch: 5| Step: 7
Training loss: 3.63760840395344
Validation loss: 3.0308090513396215

Epoch: 5| Step: 8
Training loss: 3.151937125261474
Validation loss: 3.0276802778342997

Epoch: 5| Step: 9
Training loss: 3.071411091574168
Validation loss: 3.030195534236045

Epoch: 5| Step: 10
Training loss: 2.5478202142391626
Validation loss: 3.029548535392404

Epoch: 146| Step: 0
Training loss: 2.2646472794372308
Validation loss: 3.0328857825528366

Epoch: 5| Step: 1
Training loss: 3.1595742122279202
Validation loss: 3.0317503458369126

Epoch: 5| Step: 2
Training loss: 3.3492252763560453
Validation loss: 3.029335377219477

Epoch: 5| Step: 3
Training loss: 3.710284944681141
Validation loss: 3.03350660662413

Epoch: 5| Step: 4
Training loss: 3.7670974068803695
Validation loss: 3.032351480723744

Epoch: 5| Step: 5
Training loss: 3.1785207196349887
Validation loss: 3.0369941186522156

Epoch: 5| Step: 6
Training loss: 3.173658499072922
Validation loss: 3.0339902842078925

Epoch: 5| Step: 7
Training loss: 3.0490888328936014
Validation loss: 3.0294551612176495

Epoch: 5| Step: 8
Training loss: 3.6019954131593366
Validation loss: 3.0258140210765565

Epoch: 5| Step: 9
Training loss: 3.5366198465865706
Validation loss: 3.025713730508343

Epoch: 5| Step: 10
Training loss: 3.1757854541408213
Validation loss: 3.025788505839098

Epoch: 147| Step: 0
Training loss: 3.446887290012725
Validation loss: 3.026449191758332

Epoch: 5| Step: 1
Training loss: 3.2888559018305092
Validation loss: 3.0266212209285905

Epoch: 5| Step: 2
Training loss: 2.096981117530984
Validation loss: 3.0236414422209195

Epoch: 5| Step: 3
Training loss: 3.5768507641723266
Validation loss: 3.024487756179789

Epoch: 5| Step: 4
Training loss: 3.6371232247296317
Validation loss: 3.023731039906062

Epoch: 5| Step: 5
Training loss: 3.247693050011766
Validation loss: 3.022966967309983

Epoch: 5| Step: 6
Training loss: 3.2355073430180363
Validation loss: 3.023186141585339

Epoch: 5| Step: 7
Training loss: 3.3376406179229634
Validation loss: 3.0240687005308877

Epoch: 5| Step: 8
Training loss: 3.1792699741228923
Validation loss: 3.022971011679023

Epoch: 5| Step: 9
Training loss: 3.2639316384692534
Validation loss: 3.022732027588251

Epoch: 5| Step: 10
Training loss: 3.7154745855918865
Validation loss: 3.0248457849404926

Epoch: 148| Step: 0
Training loss: 3.9008314469062686
Validation loss: 3.021399200927615

Epoch: 5| Step: 1
Training loss: 3.6195129433590307
Validation loss: 3.01895266085551

Epoch: 5| Step: 2
Training loss: 2.7512160126919207
Validation loss: 3.022815721493033

Epoch: 5| Step: 3
Training loss: 3.3827073431079153
Validation loss: 3.0214005754884097

Epoch: 5| Step: 4
Training loss: 3.2574178699084984
Validation loss: 3.021634350333562

Epoch: 5| Step: 5
Training loss: 3.405602909883883
Validation loss: 3.0218655925451214

Epoch: 5| Step: 6
Training loss: 3.4281884047591946
Validation loss: 3.0231069108666895

Epoch: 5| Step: 7
Training loss: 2.619554957673065
Validation loss: 3.0205635584001036

Epoch: 5| Step: 8
Training loss: 3.5669392817286045
Validation loss: 3.0199949954854652

Epoch: 5| Step: 9
Training loss: 3.0635265264793095
Validation loss: 3.0195137346788044

Epoch: 5| Step: 10
Training loss: 2.95148903072231
Validation loss: 3.019781352269761

Epoch: 149| Step: 0
Training loss: 3.3676656927793105
Validation loss: 3.0216026596668355

Epoch: 5| Step: 1
Training loss: 3.9862441521808343
Validation loss: 3.0195787845244846

Epoch: 5| Step: 2
Training loss: 3.3497340765781787
Validation loss: 3.020736038174398

Epoch: 5| Step: 3
Training loss: 3.1942517448206162
Validation loss: 3.023547780482875

Epoch: 5| Step: 4
Training loss: 3.6471901830147413
Validation loss: 3.0203313778935668

Epoch: 5| Step: 5
Training loss: 3.183538480875692
Validation loss: 3.02169839412701

Epoch: 5| Step: 6
Training loss: 3.0563908581560417
Validation loss: 3.023070759762225

Epoch: 5| Step: 7
Training loss: 3.6446352634122534
Validation loss: 3.027358928514021

Epoch: 5| Step: 8
Training loss: 3.0650221112248706
Validation loss: 3.029924846236842

Epoch: 5| Step: 9
Training loss: 2.2293082456698143
Validation loss: 3.0285405282375235

Epoch: 5| Step: 10
Training loss: 3.159997811135608
Validation loss: 3.0215984565051452

Epoch: 150| Step: 0
Training loss: 2.863583828497862
Validation loss: 3.0184133166415132

Epoch: 5| Step: 1
Training loss: 3.623001731735266
Validation loss: 3.0204345258828087

Epoch: 5| Step: 2
Training loss: 3.410468333013559
Validation loss: 3.0198883009824566

Epoch: 5| Step: 3
Training loss: 3.38160370335842
Validation loss: 3.0218765296282744

Epoch: 5| Step: 4
Training loss: 3.3933096246946595
Validation loss: 3.0158855536713736

Epoch: 5| Step: 5
Training loss: 3.0893497192657304
Validation loss: 3.015450336257142

Epoch: 5| Step: 6
Training loss: 2.7848160416888157
Validation loss: 3.0164314461363095

Epoch: 5| Step: 7
Training loss: 3.4111237262350356
Validation loss: 3.0156949155407897

Epoch: 5| Step: 8
Training loss: 3.4812754714006586
Validation loss: 3.016238584201942

Epoch: 5| Step: 9
Training loss: 3.5832610603555186
Validation loss: 3.0154249824280566

Epoch: 5| Step: 10
Training loss: 2.980336277568788
Validation loss: 3.0145073384331424

Epoch: 151| Step: 0
Training loss: 3.231968523485988
Validation loss: 3.015100371326153

Epoch: 5| Step: 1
Training loss: 3.406355689972626
Validation loss: 3.014497789740964

Epoch: 5| Step: 2
Training loss: 3.1829739019850245
Validation loss: 3.0143828509811725

Epoch: 5| Step: 3
Training loss: 3.7337218156280176
Validation loss: 3.016277095020105

Epoch: 5| Step: 4
Training loss: 3.2901731233353897
Validation loss: 3.0135422062643222

Epoch: 5| Step: 5
Training loss: 2.7852573456680623
Validation loss: 3.013590425637406

Epoch: 5| Step: 6
Training loss: 3.311405936889893
Validation loss: 3.0211184982678274

Epoch: 5| Step: 7
Training loss: 3.3281562338066366
Validation loss: 3.0175207156826462

Epoch: 5| Step: 8
Training loss: 3.1572776103590434
Validation loss: 3.0175106140989123

Epoch: 5| Step: 9
Training loss: 3.3113974409733666
Validation loss: 3.0177336498780396

Epoch: 5| Step: 10
Training loss: 3.3801920478479435
Validation loss: 3.0141610539867316

Epoch: 152| Step: 0
Training loss: 3.3733896722976655
Validation loss: 3.012456433163243

Epoch: 5| Step: 1
Training loss: 2.5566356824997585
Validation loss: 3.0121000085384937

Epoch: 5| Step: 2
Training loss: 3.0061453818915465
Validation loss: 3.012561637851371

Epoch: 5| Step: 3
Training loss: 3.1119273076331915
Validation loss: 3.0127642978919065

Epoch: 5| Step: 4
Training loss: 3.5083871893173386
Validation loss: 3.0103689298447476

Epoch: 5| Step: 5
Training loss: 3.5078182092972745
Validation loss: 3.0114403603679327

Epoch: 5| Step: 6
Training loss: 3.4760349516345994
Validation loss: 3.0109345296216117

Epoch: 5| Step: 7
Training loss: 2.995140272113109
Validation loss: 3.0130622622611294

Epoch: 5| Step: 8
Training loss: 3.291296845597839
Validation loss: 3.0108751238225473

Epoch: 5| Step: 9
Training loss: 3.6988757255408844
Validation loss: 3.011644207585063

Epoch: 5| Step: 10
Training loss: 3.467599488957788
Validation loss: 3.011493521911305

Epoch: 153| Step: 0
Training loss: 3.3714211880646925
Validation loss: 3.0101471368786346

Epoch: 5| Step: 1
Training loss: 3.094452903350951
Validation loss: 3.0113923806904523

Epoch: 5| Step: 2
Training loss: 2.964385347776551
Validation loss: 3.010636986503085

Epoch: 5| Step: 3
Training loss: 3.1160078756602587
Validation loss: 3.0075357988258573

Epoch: 5| Step: 4
Training loss: 3.622888805303478
Validation loss: 3.0121468917910375

Epoch: 5| Step: 5
Training loss: 3.118553072841224
Validation loss: 3.0132234295923355

Epoch: 5| Step: 6
Training loss: 3.6857091143245473
Validation loss: 3.011546151323445

Epoch: 5| Step: 7
Training loss: 3.647838731271271
Validation loss: 3.0132839920980214

Epoch: 5| Step: 8
Training loss: 2.868595453225773
Validation loss: 3.0154038265851058

Epoch: 5| Step: 9
Training loss: 3.380976154287305
Validation loss: 3.011390250701953

Epoch: 5| Step: 10
Training loss: 3.1224470773309227
Validation loss: 3.014408700039916

Epoch: 154| Step: 0
Training loss: 3.16440201809775
Validation loss: 3.0188374654041232

Epoch: 5| Step: 1
Training loss: 2.495394469976844
Validation loss: 3.015179586269779

Epoch: 5| Step: 2
Training loss: 3.0523343205458873
Validation loss: 3.0082322989938897

Epoch: 5| Step: 3
Training loss: 3.094852751894378
Validation loss: 3.0106864700711697

Epoch: 5| Step: 4
Training loss: 3.284205821985667
Validation loss: 3.0089301468489045

Epoch: 5| Step: 5
Training loss: 3.5665043862285244
Validation loss: 3.0077136727334004

Epoch: 5| Step: 6
Training loss: 3.095642589855686
Validation loss: 3.006512245984139

Epoch: 5| Step: 7
Training loss: 4.022162552092964
Validation loss: 3.0063599148258646

Epoch: 5| Step: 8
Training loss: 3.2617436025437914
Validation loss: 3.007027714444288

Epoch: 5| Step: 9
Training loss: 3.699597445059822
Validation loss: 3.007136132090224

Epoch: 5| Step: 10
Training loss: 3.0774708938771678
Validation loss: 3.0048631061855566

Epoch: 155| Step: 0
Training loss: 2.9507351040230247
Validation loss: 3.0065819479490012

Epoch: 5| Step: 1
Training loss: 3.5161660011258205
Validation loss: 3.0042839739320972

Epoch: 5| Step: 2
Training loss: 3.1616061247835794
Validation loss: 3.009008810263167

Epoch: 5| Step: 3
Training loss: 3.2244459696540524
Validation loss: 3.007758484126174

Epoch: 5| Step: 4
Training loss: 3.131333456240706
Validation loss: 3.006138996118728

Epoch: 5| Step: 5
Training loss: 3.266694254336999
Validation loss: 3.0062790263180057

Epoch: 5| Step: 6
Training loss: 3.210198458897489
Validation loss: 3.00766128993104

Epoch: 5| Step: 7
Training loss: 2.918022349323655
Validation loss: 3.007902586234712

Epoch: 5| Step: 8
Training loss: 3.7700281003516944
Validation loss: 3.0096914021866508

Epoch: 5| Step: 9
Training loss: 3.8104018394441748
Validation loss: 3.0087462483550063

Epoch: 5| Step: 10
Training loss: 2.902307112245619
Validation loss: 3.0073637042740824

Epoch: 156| Step: 0
Training loss: 2.288699905788993
Validation loss: 3.009922525379564

Epoch: 5| Step: 1
Training loss: 3.3133407101718544
Validation loss: 3.0047014861541013

Epoch: 5| Step: 2
Training loss: 3.0862409611473423
Validation loss: 3.0057684087374645

Epoch: 5| Step: 3
Training loss: 3.996017022761992
Validation loss: 3.0037520046177173

Epoch: 5| Step: 4
Training loss: 3.0187826277270773
Validation loss: 3.001964804156759

Epoch: 5| Step: 5
Training loss: 3.052626438880788
Validation loss: 3.0016444802399653

Epoch: 5| Step: 6
Training loss: 3.415947644629825
Validation loss: 3.0024113808207935

Epoch: 5| Step: 7
Training loss: 3.329577491693707
Validation loss: 3.003512776747692

Epoch: 5| Step: 8
Training loss: 3.6522560149890144
Validation loss: 3.002728285539771

Epoch: 5| Step: 9
Training loss: 3.024504401853476
Validation loss: 3.000460498769669

Epoch: 5| Step: 10
Training loss: 3.6240056745977376
Validation loss: 3.0011494000198184

Epoch: 157| Step: 0
Training loss: 3.424565341962695
Validation loss: 3.0025531422336367

Epoch: 5| Step: 1
Training loss: 2.82445080913077
Validation loss: 3.00466021696778

Epoch: 5| Step: 2
Training loss: 3.069048206267705
Validation loss: 2.999969234445527

Epoch: 5| Step: 3
Training loss: 3.152034853108379
Validation loss: 3.001190955807142

Epoch: 5| Step: 4
Training loss: 3.18620079340751
Validation loss: 3.000814428153873

Epoch: 5| Step: 5
Training loss: 3.589392366973401
Validation loss: 3.0035595413942087

Epoch: 5| Step: 6
Training loss: 3.2668641582139064
Validation loss: 3.0004989950776646

Epoch: 5| Step: 7
Training loss: 3.3642758129507557
Validation loss: 3.0003165724063448

Epoch: 5| Step: 8
Training loss: 3.081241327548251
Validation loss: 2.9989679725125993

Epoch: 5| Step: 9
Training loss: 3.4691354348429817
Validation loss: 3.0001511211001044

Epoch: 5| Step: 10
Training loss: 3.570090255664939
Validation loss: 2.998690064520111

Epoch: 158| Step: 0
Training loss: 2.696755727736223
Validation loss: 2.9990124820409716

Epoch: 5| Step: 1
Training loss: 2.921927058934212
Validation loss: 2.99902136540314

Epoch: 5| Step: 2
Training loss: 3.7144436304875894
Validation loss: 3.001411053161204

Epoch: 5| Step: 3
Training loss: 3.1355257913012036
Validation loss: 3.002413366899778

Epoch: 5| Step: 4
Training loss: 2.8403215806521898
Validation loss: 3.00122376916506

Epoch: 5| Step: 5
Training loss: 3.202445055738189
Validation loss: 3.0035793731946754

Epoch: 5| Step: 6
Training loss: 3.035877745899745
Validation loss: 3.0019119384445854

Epoch: 5| Step: 7
Training loss: 3.613920182107181
Validation loss: 2.9997601994345597

Epoch: 5| Step: 8
Training loss: 3.4245603293118783
Validation loss: 3.0003814924705563

Epoch: 5| Step: 9
Training loss: 3.6581601101148307
Validation loss: 2.998288864679427

Epoch: 5| Step: 10
Training loss: 3.6092154067124866
Validation loss: 2.998477026233477

Epoch: 159| Step: 0
Training loss: 2.6520530305396295
Validation loss: 2.9999526970391592

Epoch: 5| Step: 1
Training loss: 4.229709884759062
Validation loss: 2.9963505878938577

Epoch: 5| Step: 2
Training loss: 3.1910477884002306
Validation loss: 2.997358536785137

Epoch: 5| Step: 3
Training loss: 2.9246150749785844
Validation loss: 2.997311623215214

Epoch: 5| Step: 4
Training loss: 3.2886184066375197
Validation loss: 2.996830304881062

Epoch: 5| Step: 5
Training loss: 2.9863546306663813
Validation loss: 2.9944443054060175

Epoch: 5| Step: 6
Training loss: 2.9984099624903897
Validation loss: 2.995152123343699

Epoch: 5| Step: 7
Training loss: 3.3097652446557966
Validation loss: 2.9937560328793738

Epoch: 5| Step: 8
Training loss: 3.627084855998313
Validation loss: 2.993576908290634

Epoch: 5| Step: 9
Training loss: 3.134834835441192
Validation loss: 2.9959189966760134

Epoch: 5| Step: 10
Training loss: 3.3752098018286008
Validation loss: 2.996729661125032

Epoch: 160| Step: 0
Training loss: 3.6245766754270496
Validation loss: 2.992147938011014

Epoch: 5| Step: 1
Training loss: 3.5620328362657947
Validation loss: 2.996352476175263

Epoch: 5| Step: 2
Training loss: 2.9208097913140687
Validation loss: 2.9934036892071862

Epoch: 5| Step: 3
Training loss: 3.0496114326979256
Validation loss: 2.9935279066586076

Epoch: 5| Step: 4
Training loss: 3.009411354677216
Validation loss: 2.9934328650648325

Epoch: 5| Step: 5
Training loss: 3.2914666384669786
Validation loss: 2.9941082802894914

Epoch: 5| Step: 6
Training loss: 3.1309367436245217
Validation loss: 2.992086708643667

Epoch: 5| Step: 7
Training loss: 2.932963662984707
Validation loss: 2.994497443357141

Epoch: 5| Step: 8
Training loss: 3.4501638014234675
Validation loss: 2.9926111895982785

Epoch: 5| Step: 9
Training loss: 2.995079774128488
Validation loss: 2.9948688501770833

Epoch: 5| Step: 10
Training loss: 3.923286336024746
Validation loss: 2.993553018607249

Epoch: 161| Step: 0
Training loss: 3.0906763703153053
Validation loss: 2.995133096814713

Epoch: 5| Step: 1
Training loss: 3.2571160100246335
Validation loss: 2.9935988195597467

Epoch: 5| Step: 2
Training loss: 2.662217740423258
Validation loss: 2.993365299487555

Epoch: 5| Step: 3
Training loss: 3.168373618260273
Validation loss: 2.992622386081317

Epoch: 5| Step: 4
Training loss: 4.077771401696298
Validation loss: 2.992185388898087

Epoch: 5| Step: 5
Training loss: 2.822749218543396
Validation loss: 2.99172117761926

Epoch: 5| Step: 6
Training loss: 3.7464792890517167
Validation loss: 2.990022138666651

Epoch: 5| Step: 7
Training loss: 3.640292827858577
Validation loss: 2.991402140124913

Epoch: 5| Step: 8
Training loss: 3.0874197574952724
Validation loss: 2.9906780314896837

Epoch: 5| Step: 9
Training loss: 2.694922112098437
Validation loss: 2.990400155508553

Epoch: 5| Step: 10
Training loss: 3.37570027751079
Validation loss: 2.9899677366626696

Epoch: 162| Step: 0
Training loss: 3.030204356638866
Validation loss: 2.9871127445644774

Epoch: 5| Step: 1
Training loss: 2.712964270452426
Validation loss: 2.9903798085146125

Epoch: 5| Step: 2
Training loss: 2.8062007296512514
Validation loss: 2.990628384873807

Epoch: 5| Step: 3
Training loss: 3.3035413409302676
Validation loss: 2.9885704403002227

Epoch: 5| Step: 4
Training loss: 3.592622132159861
Validation loss: 3.0015397359079783

Epoch: 5| Step: 5
Training loss: 2.9768833578193843
Validation loss: 3.0034015011210964

Epoch: 5| Step: 6
Training loss: 3.4589719680572237
Validation loss: 3.013448849963165

Epoch: 5| Step: 7
Training loss: 3.456065449262702
Validation loss: 3.0084557516508794

Epoch: 5| Step: 8
Training loss: 3.838016731189957
Validation loss: 3.011786686096325

Epoch: 5| Step: 9
Training loss: 3.1894801851749346
Validation loss: 3.0013776576091047

Epoch: 5| Step: 10
Training loss: 3.435387534501316
Validation loss: 2.996620677905509

Epoch: 163| Step: 0
Training loss: 3.261551209675384
Validation loss: 2.9895535559363045

Epoch: 5| Step: 1
Training loss: 2.694720570899831
Validation loss: 2.988847478552595

Epoch: 5| Step: 2
Training loss: 2.919288673766061
Validation loss: 2.9921720274048043

Epoch: 5| Step: 3
Training loss: 2.9154394746980157
Validation loss: 3.0004686208345674

Epoch: 5| Step: 4
Training loss: 3.470931458355038
Validation loss: 2.989689955443456

Epoch: 5| Step: 5
Training loss: 3.6328594902034848
Validation loss: 2.9890112011969876

Epoch: 5| Step: 6
Training loss: 2.3961164445427325
Validation loss: 2.9854793368344037

Epoch: 5| Step: 7
Training loss: 3.2144361309400096
Validation loss: 2.9859659311485314

Epoch: 5| Step: 8
Training loss: 3.932015610998603
Validation loss: 2.984791261110522

Epoch: 5| Step: 9
Training loss: 3.6295842090743284
Validation loss: 2.9862237826209896

Epoch: 5| Step: 10
Training loss: 3.58803987062856
Validation loss: 2.9910384479323024

Epoch: 164| Step: 0
Training loss: 3.1774783696624675
Validation loss: 2.988703163641081

Epoch: 5| Step: 1
Training loss: 3.21451964662416
Validation loss: 2.988399567239946

Epoch: 5| Step: 2
Training loss: 3.383821614426759
Validation loss: 2.9912694988284816

Epoch: 5| Step: 3
Training loss: 3.077420381558877
Validation loss: 2.9870860756933855

Epoch: 5| Step: 4
Training loss: 3.8949849774091767
Validation loss: 2.9878795002249467

Epoch: 5| Step: 5
Training loss: 3.063780380714721
Validation loss: 2.9819592989645503

Epoch: 5| Step: 6
Training loss: 3.269735715026241
Validation loss: 2.984997862630973

Epoch: 5| Step: 7
Training loss: 3.149955137629676
Validation loss: 2.9844818388177674

Epoch: 5| Step: 8
Training loss: 3.027051712224528
Validation loss: 2.9833032476471324

Epoch: 5| Step: 9
Training loss: 3.25414481324605
Validation loss: 2.983366179982908

Epoch: 5| Step: 10
Training loss: 3.2844821088550127
Validation loss: 2.984786691752926

Epoch: 165| Step: 0
Training loss: 2.740085850644572
Validation loss: 2.983575293822604

Epoch: 5| Step: 1
Training loss: 2.584720198284133
Validation loss: 2.9866378770440862

Epoch: 5| Step: 2
Training loss: 3.2893080812228948
Validation loss: 2.986114324968775

Epoch: 5| Step: 3
Training loss: 3.032963848317384
Validation loss: 2.983577805412789

Epoch: 5| Step: 4
Training loss: 3.036275257242686
Validation loss: 2.9834669729321712

Epoch: 5| Step: 5
Training loss: 3.017882139823105
Validation loss: 2.980318170619007

Epoch: 5| Step: 6
Training loss: 3.258740043785885
Validation loss: 2.9826891273066223

Epoch: 5| Step: 7
Training loss: 3.701313203312591
Validation loss: 2.9831007535158642

Epoch: 5| Step: 8
Training loss: 3.707469982558163
Validation loss: 2.9833470387595704

Epoch: 5| Step: 9
Training loss: 3.550372176742009
Validation loss: 2.9823219587785457

Epoch: 5| Step: 10
Training loss: 3.7576121318479165
Validation loss: 2.9823960358080397

Epoch: 166| Step: 0
Training loss: 3.0905668278263687
Validation loss: 2.9826783103979455

Epoch: 5| Step: 1
Training loss: 3.1235403085021796
Validation loss: 2.979803952696514

Epoch: 5| Step: 2
Training loss: 3.1798709001066716
Validation loss: 2.98161040201973

Epoch: 5| Step: 3
Training loss: 3.061710333709168
Validation loss: 2.98117445130282

Epoch: 5| Step: 4
Training loss: 3.0658782698820355
Validation loss: 2.983430640532867

Epoch: 5| Step: 5
Training loss: 3.533520803936293
Validation loss: 2.9909792898072616

Epoch: 5| Step: 6
Training loss: 3.2003186842064584
Validation loss: 2.981518855851046

Epoch: 5| Step: 7
Training loss: 4.197832710934791
Validation loss: 2.9878743795966143

Epoch: 5| Step: 8
Training loss: 2.526290273066958
Validation loss: 2.9853487003183923

Epoch: 5| Step: 9
Training loss: 2.9121602985885398
Validation loss: 2.9776981904395567

Epoch: 5| Step: 10
Training loss: 3.7130122438244837
Validation loss: 2.9786701444060104

Epoch: 167| Step: 0
Training loss: 3.440065016464788
Validation loss: 2.9783093476476323

Epoch: 5| Step: 1
Training loss: 3.1824105714517863
Validation loss: 2.9777644499134226

Epoch: 5| Step: 2
Training loss: 3.5800544167757
Validation loss: 2.977123764503995

Epoch: 5| Step: 3
Training loss: 3.721589615111487
Validation loss: 2.977779456710658

Epoch: 5| Step: 4
Training loss: 2.9849555764015685
Validation loss: 2.9773315283747066

Epoch: 5| Step: 5
Training loss: 2.8554846140868313
Validation loss: 2.9769081236102677

Epoch: 5| Step: 6
Training loss: 3.359576409977898
Validation loss: 2.9779657848823438

Epoch: 5| Step: 7
Training loss: 2.399268487869998
Validation loss: 2.976356005458798

Epoch: 5| Step: 8
Training loss: 3.3271038655933616
Validation loss: 2.9749848192792268

Epoch: 5| Step: 9
Training loss: 3.967236448018301
Validation loss: 2.977008032082

Epoch: 5| Step: 10
Training loss: 2.501673424457705
Validation loss: 2.97750185875503

Epoch: 168| Step: 0
Training loss: 3.119646598657081
Validation loss: 2.9753934815619134

Epoch: 5| Step: 1
Training loss: 2.805570925512063
Validation loss: 2.9773430371886165

Epoch: 5| Step: 2
Training loss: 3.5583435707629936
Validation loss: 2.9774614877316927

Epoch: 5| Step: 3
Training loss: 3.0109051546775545
Validation loss: 2.9720018384552906

Epoch: 5| Step: 4
Training loss: 3.2824696045374
Validation loss: 2.9761939606126115

Epoch: 5| Step: 5
Training loss: 3.7015605470805975
Validation loss: 2.9739272305616917

Epoch: 5| Step: 6
Training loss: 2.441102031827277
Validation loss: 2.9735662661171545

Epoch: 5| Step: 7
Training loss: 3.126063356681267
Validation loss: 2.976217094665656

Epoch: 5| Step: 8
Training loss: 3.8044969953589547
Validation loss: 2.974104286334767

Epoch: 5| Step: 9
Training loss: 3.436525657590218
Validation loss: 2.9773292775809708

Epoch: 5| Step: 10
Training loss: 3.2265859977106697
Validation loss: 2.9753672625328202

Epoch: 169| Step: 0
Training loss: 3.2321191559534515
Validation loss: 2.974722136153121

Epoch: 5| Step: 1
Training loss: 2.6678805469326052
Validation loss: 2.97766977388383

Epoch: 5| Step: 2
Training loss: 3.34524502710666
Validation loss: 2.9769881601944825

Epoch: 5| Step: 3
Training loss: 3.049265075691363
Validation loss: 2.9739195118563364

Epoch: 5| Step: 4
Training loss: 3.699576307214824
Validation loss: 2.976021640412772

Epoch: 5| Step: 5
Training loss: 3.7308340482957494
Validation loss: 2.976340154692851

Epoch: 5| Step: 6
Training loss: 2.935304673609965
Validation loss: 2.970410702100547

Epoch: 5| Step: 7
Training loss: 2.7567693450268353
Validation loss: 2.9749303521262203

Epoch: 5| Step: 8
Training loss: 3.331819874184562
Validation loss: 2.975215575357183

Epoch: 5| Step: 9
Training loss: 3.3557758301806033
Validation loss: 2.970512261732698

Epoch: 5| Step: 10
Training loss: 3.49391339897522
Validation loss: 2.9812315011073447

Epoch: 170| Step: 0
Training loss: 2.809786441195005
Validation loss: 2.9806101676798886

Epoch: 5| Step: 1
Training loss: 3.019514036931452
Validation loss: 2.978885733480576

Epoch: 5| Step: 2
Training loss: 2.9304155996288053
Validation loss: 2.976550200959107

Epoch: 5| Step: 3
Training loss: 3.9213699076361883
Validation loss: 2.9718678318127574

Epoch: 5| Step: 4
Training loss: 3.2360145725445526
Validation loss: 2.9699070694712857

Epoch: 5| Step: 5
Training loss: 2.674274192812604
Validation loss: 2.9666899566685605

Epoch: 5| Step: 6
Training loss: 3.059198741102159
Validation loss: 2.970613030836335

Epoch: 5| Step: 7
Training loss: 3.203891122889719
Validation loss: 2.971011048497986

Epoch: 5| Step: 8
Training loss: 3.363428128144462
Validation loss: 2.9684244267727

Epoch: 5| Step: 9
Training loss: 3.3570436416620986
Validation loss: 2.9704672466197124

Epoch: 5| Step: 10
Training loss: 4.054328094018207
Validation loss: 2.971151623795045

Epoch: 171| Step: 0
Training loss: 2.9944809373728782
Validation loss: 2.9685357992878476

Epoch: 5| Step: 1
Training loss: 3.0915457839845515
Validation loss: 2.970423849917103

Epoch: 5| Step: 2
Training loss: 2.6510995634960315
Validation loss: 2.968086112314494

Epoch: 5| Step: 3
Training loss: 3.1215393741341817
Validation loss: 2.9692945308021597

Epoch: 5| Step: 4
Training loss: 3.0734822070734795
Validation loss: 2.96799685257037

Epoch: 5| Step: 5
Training loss: 3.0843340993718322
Validation loss: 2.9676781593891715

Epoch: 5| Step: 6
Training loss: 3.1696915651566315
Validation loss: 2.965741113831918

Epoch: 5| Step: 7
Training loss: 3.5544935236394406
Validation loss: 2.967254488236887

Epoch: 5| Step: 8
Training loss: 4.283290627312424
Validation loss: 2.966204884620762

Epoch: 5| Step: 9
Training loss: 3.5075707978915664
Validation loss: 2.9671990221013007

Epoch: 5| Step: 10
Training loss: 2.8406791455235667
Validation loss: 2.966814953866944

Epoch: 172| Step: 0
Training loss: 3.177354861470536
Validation loss: 2.967880541385613

Epoch: 5| Step: 1
Training loss: 3.604721438244413
Validation loss: 2.9655337222781157

Epoch: 5| Step: 2
Training loss: 2.8797998581325737
Validation loss: 2.971276412590319

Epoch: 5| Step: 3
Training loss: 2.9311095181700946
Validation loss: 2.9705825080765966

Epoch: 5| Step: 4
Training loss: 3.2541851093650442
Validation loss: 2.9670192870041068

Epoch: 5| Step: 5
Training loss: 2.60353055178462
Validation loss: 2.969069381140108

Epoch: 5| Step: 6
Training loss: 2.923463929962619
Validation loss: 2.9672072006523957

Epoch: 5| Step: 7
Training loss: 3.979913465047955
Validation loss: 2.9656131287673255

Epoch: 5| Step: 8
Training loss: 3.2475506282439714
Validation loss: 2.9656510435440095

Epoch: 5| Step: 9
Training loss: 3.537760985758987
Validation loss: 2.9645969030272488

Epoch: 5| Step: 10
Training loss: 3.3495894450937707
Validation loss: 2.963167007517818

Epoch: 173| Step: 0
Training loss: 3.8389638239871866
Validation loss: 2.9641814912396156

Epoch: 5| Step: 1
Training loss: 3.1174320899400816
Validation loss: 2.9632404681184448

Epoch: 5| Step: 2
Training loss: 2.923382701594663
Validation loss: 2.96158803729273

Epoch: 5| Step: 3
Training loss: 2.8324735309276523
Validation loss: 2.962427568534566

Epoch: 5| Step: 4
Training loss: 3.890505379059665
Validation loss: 2.963380532218668

Epoch: 5| Step: 5
Training loss: 3.2910761887046003
Validation loss: 2.9632512547601673

Epoch: 5| Step: 6
Training loss: 3.034281522369773
Validation loss: 2.961246810369283

Epoch: 5| Step: 7
Training loss: 3.207926208294282
Validation loss: 2.9633274851253986

Epoch: 5| Step: 8
Training loss: 3.475204373943183
Validation loss: 2.9646154812976304

Epoch: 5| Step: 9
Training loss: 3.0362958302971057
Validation loss: 2.9629932003233033

Epoch: 5| Step: 10
Training loss: 2.7193722067739476
Validation loss: 2.9627067035163113

Epoch: 174| Step: 0
Training loss: 3.1223484234024914
Validation loss: 2.9617929491570014

Epoch: 5| Step: 1
Training loss: 2.912340407030631
Validation loss: 2.9649046764452613

Epoch: 5| Step: 2
Training loss: 3.4328487486351418
Validation loss: 2.965802810175758

Epoch: 5| Step: 3
Training loss: 3.182324714717966
Validation loss: 2.961623963333292

Epoch: 5| Step: 4
Training loss: 3.243976439582132
Validation loss: 2.9638327167244016

Epoch: 5| Step: 5
Training loss: 3.3389237413863553
Validation loss: 2.960853396457297

Epoch: 5| Step: 6
Training loss: 3.084494260513326
Validation loss: 2.960354735007866

Epoch: 5| Step: 7
Training loss: 3.1258868675627514
Validation loss: 2.963718906343852

Epoch: 5| Step: 8
Training loss: 3.177224744974476
Validation loss: 2.960965021710998

Epoch: 5| Step: 9
Training loss: 3.2050854149920904
Validation loss: 2.962122860294319

Epoch: 5| Step: 10
Training loss: 3.834137224132569
Validation loss: 2.9612611260483854

Epoch: 175| Step: 0
Training loss: 2.213320899874836
Validation loss: 2.9597157967644248

Epoch: 5| Step: 1
Training loss: 2.7493352086473664
Validation loss: 2.961422273954206

Epoch: 5| Step: 2
Training loss: 3.7179582538364397
Validation loss: 2.961481932477079

Epoch: 5| Step: 3
Training loss: 2.7886382990497793
Validation loss: 2.960653452201175

Epoch: 5| Step: 4
Training loss: 3.188029376182999
Validation loss: 2.959208399917072

Epoch: 5| Step: 5
Training loss: 3.296076673421411
Validation loss: 2.9596256487849733

Epoch: 5| Step: 6
Training loss: 2.8724513159494975
Validation loss: 2.9657338993887326

Epoch: 5| Step: 7
Training loss: 4.319346866684398
Validation loss: 2.971978061729372

Epoch: 5| Step: 8
Training loss: 2.537299568265658
Validation loss: 2.9598012994220166

Epoch: 5| Step: 9
Training loss: 3.769733261466899
Validation loss: 2.959536178050654

Epoch: 5| Step: 10
Training loss: 3.680765500268762
Validation loss: 2.9560367405585644

Epoch: 176| Step: 0
Training loss: 2.629657065656848
Validation loss: 2.9588997913976027

Epoch: 5| Step: 1
Training loss: 2.7904649301993323
Validation loss: 2.9582306391841304

Epoch: 5| Step: 2
Training loss: 3.3403161501161907
Validation loss: 2.9584860622896936

Epoch: 5| Step: 3
Training loss: 2.938722721234483
Validation loss: 2.9564615752817827

Epoch: 5| Step: 4
Training loss: 3.1282700786045283
Validation loss: 2.9597726737946504

Epoch: 5| Step: 5
Training loss: 3.2709925586472353
Validation loss: 2.9611021991703548

Epoch: 5| Step: 6
Training loss: 2.974540444149623
Validation loss: 2.9590830242236836

Epoch: 5| Step: 7
Training loss: 3.3800377158594435
Validation loss: 2.957080130779209

Epoch: 5| Step: 8
Training loss: 3.880405470514723
Validation loss: 2.9566103348662516

Epoch: 5| Step: 9
Training loss: 3.647900821659367
Validation loss: 2.9576161329946298

Epoch: 5| Step: 10
Training loss: 3.4787073955332595
Validation loss: 2.956100107674422

Epoch: 177| Step: 0
Training loss: 3.712382531153974
Validation loss: 2.954980053480821

Epoch: 5| Step: 1
Training loss: 3.5355066621048934
Validation loss: 2.957174288720235

Epoch: 5| Step: 2
Training loss: 3.138262263253182
Validation loss: 2.9563145130774444

Epoch: 5| Step: 3
Training loss: 3.759962327443772
Validation loss: 2.957565776232993

Epoch: 5| Step: 4
Training loss: 3.295994645586572
Validation loss: 2.960026951381415

Epoch: 5| Step: 5
Training loss: 3.2114996870415795
Validation loss: 2.962145189442102

Epoch: 5| Step: 6
Training loss: 2.8772347099447484
Validation loss: 2.961010725004633

Epoch: 5| Step: 7
Training loss: 3.3524918412600697
Validation loss: 2.961183443438941

Epoch: 5| Step: 8
Training loss: 2.3311767034794806
Validation loss: 2.958510571349348

Epoch: 5| Step: 9
Training loss: 2.559550937665129
Validation loss: 2.957838251600391

Epoch: 5| Step: 10
Training loss: 3.5620713896325644
Validation loss: 2.954742046211988

Epoch: 178| Step: 0
Training loss: 2.722219599075957
Validation loss: 2.9547680665017215

Epoch: 5| Step: 1
Training loss: 3.411693178591626
Validation loss: 2.956754547119778

Epoch: 5| Step: 2
Training loss: 3.4046263018321046
Validation loss: 2.9536011205648847

Epoch: 5| Step: 3
Training loss: 3.3052853884382567
Validation loss: 2.950449907183691

Epoch: 5| Step: 4
Training loss: 3.866671811023666
Validation loss: 2.9525194269351305

Epoch: 5| Step: 5
Training loss: 3.32975521367863
Validation loss: 2.949733387540961

Epoch: 5| Step: 6
Training loss: 3.0521166976476457
Validation loss: 2.9508112016110104

Epoch: 5| Step: 7
Training loss: 3.341775043534402
Validation loss: 2.953359344242139

Epoch: 5| Step: 8
Training loss: 2.724394452768788
Validation loss: 2.95178946498135

Epoch: 5| Step: 9
Training loss: 2.4229820428514257
Validation loss: 2.9521805871661893

Epoch: 5| Step: 10
Training loss: 3.7832488774579214
Validation loss: 2.95370567625798

Epoch: 179| Step: 0
Training loss: 2.814891984808461
Validation loss: 2.950806901957159

Epoch: 5| Step: 1
Training loss: 3.357580939003986
Validation loss: 2.948849913431468

Epoch: 5| Step: 2
Training loss: 3.0456416837320237
Validation loss: 2.9512762526835705

Epoch: 5| Step: 3
Training loss: 2.8663132501436785
Validation loss: 2.9506328775704076

Epoch: 5| Step: 4
Training loss: 2.4551314391399433
Validation loss: 2.950421956333759

Epoch: 5| Step: 5
Training loss: 3.4927942487095285
Validation loss: 2.953334919168829

Epoch: 5| Step: 6
Training loss: 3.6054928201221186
Validation loss: 2.951056827505802

Epoch: 5| Step: 7
Training loss: 3.485076833614124
Validation loss: 2.9527347478509327

Epoch: 5| Step: 8
Training loss: 3.105671886781855
Validation loss: 2.9526339051693844

Epoch: 5| Step: 9
Training loss: 3.7412809098047335
Validation loss: 2.948702603757493

Epoch: 5| Step: 10
Training loss: 3.399693469647085
Validation loss: 2.9474338884212403

Epoch: 180| Step: 0
Training loss: 3.4491870917555496
Validation loss: 2.948138905894548

Epoch: 5| Step: 1
Training loss: 3.3318340426510673
Validation loss: 2.9494854497954077

Epoch: 5| Step: 2
Training loss: 2.5487158739649995
Validation loss: 2.9488174214309293

Epoch: 5| Step: 3
Training loss: 3.299371000512588
Validation loss: 2.9480165170209713

Epoch: 5| Step: 4
Training loss: 3.2642907150053766
Validation loss: 2.9495987950776503

Epoch: 5| Step: 5
Training loss: 3.6317290628601344
Validation loss: 2.9471739479753083

Epoch: 5| Step: 6
Training loss: 3.7345200514454917
Validation loss: 2.9468190446946534

Epoch: 5| Step: 7
Training loss: 2.7350590313498286
Validation loss: 2.9506025825509044

Epoch: 5| Step: 8
Training loss: 3.646935359975061
Validation loss: 2.951122020709898

Epoch: 5| Step: 9
Training loss: 2.9402720581088753
Validation loss: 2.94688850566507

Epoch: 5| Step: 10
Training loss: 2.620919643935743
Validation loss: 2.947702765689783

Epoch: 181| Step: 0
Training loss: 3.4502440988183234
Validation loss: 2.948198085391021

Epoch: 5| Step: 1
Training loss: 2.7320309428170404
Validation loss: 2.9462038673007482

Epoch: 5| Step: 2
Training loss: 3.416811746137753
Validation loss: 2.9447213217705954

Epoch: 5| Step: 3
Training loss: 3.310852360767143
Validation loss: 2.9486287374963696

Epoch: 5| Step: 4
Training loss: 2.904144837248613
Validation loss: 2.9453055436447224

Epoch: 5| Step: 5
Training loss: 2.7626320544134195
Validation loss: 2.9505495255503256

Epoch: 5| Step: 6
Training loss: 3.9583232009490317
Validation loss: 2.9463783551447906

Epoch: 5| Step: 7
Training loss: 2.803381740758423
Validation loss: 2.946583766159019

Epoch: 5| Step: 8
Training loss: 2.949620988712072
Validation loss: 2.94879494441451

Epoch: 5| Step: 9
Training loss: 3.8721893946458525
Validation loss: 2.9466090267418052

Epoch: 5| Step: 10
Training loss: 3.022954542438476
Validation loss: 2.9494697905649825

Epoch: 182| Step: 0
Training loss: 3.315578253989068
Validation loss: 2.944322932658872

Epoch: 5| Step: 1
Training loss: 3.077222662792904
Validation loss: 2.9454717953437175

Epoch: 5| Step: 2
Training loss: 3.272163088411188
Validation loss: 2.948537313263854

Epoch: 5| Step: 3
Training loss: 3.12924668725748
Validation loss: 2.9452746889819696

Epoch: 5| Step: 4
Training loss: 3.7335522116349726
Validation loss: 2.9442945387883146

Epoch: 5| Step: 5
Training loss: 3.3268301150647823
Validation loss: 2.9444180618843454

Epoch: 5| Step: 6
Training loss: 2.851345106225292
Validation loss: 2.943599906860476

Epoch: 5| Step: 7
Training loss: 3.2485983833961383
Validation loss: 2.944574912997389

Epoch: 5| Step: 8
Training loss: 3.5181818501725846
Validation loss: 2.941672451082506

Epoch: 5| Step: 9
Training loss: 3.1428400076361878
Validation loss: 2.943267090274881

Epoch: 5| Step: 10
Training loss: 2.6647656539169464
Validation loss: 2.941961410185049

Epoch: 183| Step: 0
Training loss: 3.567410748547543
Validation loss: 2.9438801486751736

Epoch: 5| Step: 1
Training loss: 2.722621397564321
Validation loss: 2.942266980453793

Epoch: 5| Step: 2
Training loss: 3.109009687730696
Validation loss: 2.9433359330447253

Epoch: 5| Step: 3
Training loss: 3.2735144121334354
Validation loss: 2.9424850877212565

Epoch: 5| Step: 4
Training loss: 2.9683601524973486
Validation loss: 2.9432296414592254

Epoch: 5| Step: 5
Training loss: 3.175270405465832
Validation loss: 2.9429274604936495

Epoch: 5| Step: 6
Training loss: 3.4868433125559166
Validation loss: 2.9455425448642396

Epoch: 5| Step: 7
Training loss: 3.0688168520356327
Validation loss: 2.9409596481726297

Epoch: 5| Step: 8
Training loss: 2.96760906581458
Validation loss: 2.9406246296239216

Epoch: 5| Step: 9
Training loss: 3.8857359290521982
Validation loss: 2.9420167831109274

Epoch: 5| Step: 10
Training loss: 3.023778142147616
Validation loss: 2.9454408623479393

Epoch: 184| Step: 0
Training loss: 3.3322025447342334
Validation loss: 2.9460013676292327

Epoch: 5| Step: 1
Training loss: 3.432895697938521
Validation loss: 2.9435447840627122

Epoch: 5| Step: 2
Training loss: 2.8994701427613716
Validation loss: 2.942943197220049

Epoch: 5| Step: 3
Training loss: 3.610104573814242
Validation loss: 2.9441940060902416

Epoch: 5| Step: 4
Training loss: 2.2735888243975726
Validation loss: 2.9461755307149122

Epoch: 5| Step: 5
Training loss: 2.435042976924431
Validation loss: 2.941079822052578

Epoch: 5| Step: 6
Training loss: 3.736788683920182
Validation loss: 2.9474825595784813

Epoch: 5| Step: 7
Training loss: 3.6363272123246517
Validation loss: 2.94177909174233

Epoch: 5| Step: 8
Training loss: 3.0741629104680928
Validation loss: 2.941024253662502

Epoch: 5| Step: 9
Training loss: 3.487429661195286
Validation loss: 2.940752806916763

Epoch: 5| Step: 10
Training loss: 3.1932070634548047
Validation loss: 2.9397361393730166

Epoch: 185| Step: 0
Training loss: 3.674034230495882
Validation loss: 2.940868041317983

Epoch: 5| Step: 1
Training loss: 4.088087985709977
Validation loss: 2.9378212190451745

Epoch: 5| Step: 2
Training loss: 3.4603055975579977
Validation loss: 2.937021840140929

Epoch: 5| Step: 3
Training loss: 3.481618706236051
Validation loss: 2.9412688403370346

Epoch: 5| Step: 4
Training loss: 2.7650392418503156
Validation loss: 2.938910792007499

Epoch: 5| Step: 5
Training loss: 3.036433713277699
Validation loss: 2.9396660471949687

Epoch: 5| Step: 6
Training loss: 3.3858565450654
Validation loss: 2.939594880654485

Epoch: 5| Step: 7
Training loss: 2.7899337818122087
Validation loss: 2.937212076173224

Epoch: 5| Step: 8
Training loss: 2.854250458835506
Validation loss: 2.9394053578920234

Epoch: 5| Step: 9
Training loss: 2.913365666830546
Validation loss: 2.9389976954570836

Epoch: 5| Step: 10
Training loss: 2.6205383712966754
Validation loss: 2.940031855652463

Epoch: 186| Step: 0
Training loss: 2.957700706501299
Validation loss: 2.9398068420547796

Epoch: 5| Step: 1
Training loss: 3.165880825178193
Validation loss: 2.937387949967144

Epoch: 5| Step: 2
Training loss: 3.011629293773188
Validation loss: 2.942907510053949

Epoch: 5| Step: 3
Training loss: 3.2056129283681454
Validation loss: 2.9445926181129893

Epoch: 5| Step: 4
Training loss: 3.4253142331062154
Validation loss: 2.941728313987291

Epoch: 5| Step: 5
Training loss: 3.3547312733211183
Validation loss: 2.942724528019924

Epoch: 5| Step: 6
Training loss: 3.4203901858022463
Validation loss: 2.944549251883113

Epoch: 5| Step: 7
Training loss: 2.9924254160982264
Validation loss: 2.9428825138838186

Epoch: 5| Step: 8
Training loss: 3.899318801858893
Validation loss: 2.9387684899759163

Epoch: 5| Step: 9
Training loss: 2.632759342732333
Validation loss: 2.9345766268740325

Epoch: 5| Step: 10
Training loss: 3.169108720748365
Validation loss: 2.93607663605642

Epoch: 187| Step: 0
Training loss: 3.1914658651772085
Validation loss: 2.9359688068127805

Epoch: 5| Step: 1
Training loss: 3.3091451102170835
Validation loss: 2.9355807504755798

Epoch: 5| Step: 2
Training loss: 3.004619221102461
Validation loss: 2.9378038370109802

Epoch: 5| Step: 3
Training loss: 3.173005602553044
Validation loss: 2.936769417749808

Epoch: 5| Step: 4
Training loss: 3.6020168588806127
Validation loss: 2.938715124664944

Epoch: 5| Step: 5
Training loss: 3.165843622429068
Validation loss: 2.940753570581393

Epoch: 5| Step: 6
Training loss: 3.016638867020067
Validation loss: 2.9406679587055176

Epoch: 5| Step: 7
Training loss: 3.710771737662947
Validation loss: 2.9349797926689276

Epoch: 5| Step: 8
Training loss: 2.5809584335178424
Validation loss: 2.9349362180158973

Epoch: 5| Step: 9
Training loss: 3.147638337819784
Validation loss: 2.9344540602448723

Epoch: 5| Step: 10
Training loss: 3.4334514011217263
Validation loss: 2.936243953370759

Epoch: 188| Step: 0
Training loss: 3.3804331245775607
Validation loss: 2.936602498778696

Epoch: 5| Step: 1
Training loss: 2.8399540644946955
Validation loss: 2.933289536329094

Epoch: 5| Step: 2
Training loss: 3.267239842116444
Validation loss: 2.9366100143869533

Epoch: 5| Step: 3
Training loss: 3.541282513297867
Validation loss: 2.944870762336789

Epoch: 5| Step: 4
Training loss: 3.913605988885784
Validation loss: 2.9384100086334684

Epoch: 5| Step: 5
Training loss: 2.7826145553656745
Validation loss: 2.9363057770765533

Epoch: 5| Step: 6
Training loss: 2.6781889615160512
Validation loss: 2.935019533907434

Epoch: 5| Step: 7
Training loss: 3.064128053733279
Validation loss: 2.932273203004575

Epoch: 5| Step: 8
Training loss: 2.989161622257902
Validation loss: 2.933016255819723

Epoch: 5| Step: 9
Training loss: 3.4193791732804453
Validation loss: 2.931095839776572

Epoch: 5| Step: 10
Training loss: 3.3540659982173797
Validation loss: 2.931505592761981

Epoch: 189| Step: 0
Training loss: 3.0335830676499564
Validation loss: 2.931993705450311

Epoch: 5| Step: 1
Training loss: 3.525911059230993
Validation loss: 2.9315137414656025

Epoch: 5| Step: 2
Training loss: 2.9374745144651593
Validation loss: 2.931637210180862

Epoch: 5| Step: 3
Training loss: 3.2929949595357466
Validation loss: 2.9348113008907433

Epoch: 5| Step: 4
Training loss: 2.5995227962667586
Validation loss: 2.935650753313386

Epoch: 5| Step: 5
Training loss: 3.7969943055297812
Validation loss: 2.9395677963814513

Epoch: 5| Step: 6
Training loss: 3.08608444443459
Validation loss: 2.9387026532675002

Epoch: 5| Step: 7
Training loss: 3.653276587507316
Validation loss: 2.9310955730127155

Epoch: 5| Step: 8
Training loss: 3.13100146984357
Validation loss: 2.9302419547721006

Epoch: 5| Step: 9
Training loss: 3.134963060858028
Validation loss: 2.92957997289513

Epoch: 5| Step: 10
Training loss: 2.9965665561076906
Validation loss: 2.928778748157264

Epoch: 190| Step: 0
Training loss: 2.8333073970131157
Validation loss: 2.9315296557712367

Epoch: 5| Step: 1
Training loss: 3.3806256632734577
Validation loss: 2.9349101406970526

Epoch: 5| Step: 2
Training loss: 3.523893271866205
Validation loss: 2.93665278463237

Epoch: 5| Step: 3
Training loss: 2.645876205777827
Validation loss: 2.9433957386653695

Epoch: 5| Step: 4
Training loss: 2.984305016461021
Validation loss: 2.93225847302448

Epoch: 5| Step: 5
Training loss: 2.6529558287335706
Validation loss: 2.9292574169082393

Epoch: 5| Step: 6
Training loss: 3.7353629237980814
Validation loss: 2.9314462476886254

Epoch: 5| Step: 7
Training loss: 3.130004232970474
Validation loss: 2.9301104750387443

Epoch: 5| Step: 8
Training loss: 3.772049231878455
Validation loss: 2.9289733357538417

Epoch: 5| Step: 9
Training loss: 3.2373932102810175
Validation loss: 2.9285338090204913

Epoch: 5| Step: 10
Training loss: 3.255671174777761
Validation loss: 2.928573096741741

Epoch: 191| Step: 0
Training loss: 3.6659607352210712
Validation loss: 2.9264139785074055

Epoch: 5| Step: 1
Training loss: 3.3883805823108264
Validation loss: 2.927715941849312

Epoch: 5| Step: 2
Training loss: 3.2297155754592786
Validation loss: 2.9287119415237384

Epoch: 5| Step: 3
Training loss: 2.991113056470677
Validation loss: 2.928484128732245

Epoch: 5| Step: 4
Training loss: 2.668068835055376
Validation loss: 2.927304593469107

Epoch: 5| Step: 5
Training loss: 3.576471871377284
Validation loss: 2.9282188631708697

Epoch: 5| Step: 6
Training loss: 2.9277259057999583
Validation loss: 2.925626804380439

Epoch: 5| Step: 7
Training loss: 3.3255189533671436
Validation loss: 2.9280069340854578

Epoch: 5| Step: 8
Training loss: 3.2223853164993663
Validation loss: 2.9269541723342916

Epoch: 5| Step: 9
Training loss: 2.6284595580462926
Validation loss: 2.928573968629042

Epoch: 5| Step: 10
Training loss: 3.5725082890686015
Validation loss: 2.9322741113858966

Epoch: 192| Step: 0
Training loss: 3.009444628709191
Validation loss: 2.927871059176453

Epoch: 5| Step: 1
Training loss: 3.4195725868799625
Validation loss: 2.9284013456385765

Epoch: 5| Step: 2
Training loss: 2.996187171325048
Validation loss: 2.927862912593091

Epoch: 5| Step: 3
Training loss: 3.0852366750188467
Validation loss: 2.928478611858056

Epoch: 5| Step: 4
Training loss: 3.5192545825462047
Validation loss: 2.9271955390145883

Epoch: 5| Step: 5
Training loss: 2.913908844443001
Validation loss: 2.9244912265187084

Epoch: 5| Step: 6
Training loss: 2.8116706473053448
Validation loss: 2.927248752196665

Epoch: 5| Step: 7
Training loss: 3.403352397400768
Validation loss: 2.9233064503873685

Epoch: 5| Step: 8
Training loss: 3.5455181198377965
Validation loss: 2.922560773620212

Epoch: 5| Step: 9
Training loss: 2.954886098044558
Validation loss: 2.9233341343218977

Epoch: 5| Step: 10
Training loss: 3.5663415374400027
Validation loss: 2.922204418080827

Epoch: 193| Step: 0
Training loss: 3.0501903787199165
Validation loss: 2.9237072648172533

Epoch: 5| Step: 1
Training loss: 3.4003963744297314
Validation loss: 2.9231949472839607

Epoch: 5| Step: 2
Training loss: 3.593393059294915
Validation loss: 2.9247003967875185

Epoch: 5| Step: 3
Training loss: 3.495749344724266
Validation loss: 2.9212040293377965

Epoch: 5| Step: 4
Training loss: 2.9713528115182783
Validation loss: 2.922090387447545

Epoch: 5| Step: 5
Training loss: 2.9161933696560784
Validation loss: 2.923918671727699

Epoch: 5| Step: 6
Training loss: 3.192096612190047
Validation loss: 2.923061721001314

Epoch: 5| Step: 7
Training loss: 3.079917114926058
Validation loss: 2.9231787648435845

Epoch: 5| Step: 8
Training loss: 2.9304924024513688
Validation loss: 2.919565985887222

Epoch: 5| Step: 9
Training loss: 3.7204979386910293
Validation loss: 2.9188513073119577

Epoch: 5| Step: 10
Training loss: 2.705974422105575
Validation loss: 2.9230595582210683

Epoch: 194| Step: 0
Training loss: 3.5204250542890714
Validation loss: 2.9243558562671113

Epoch: 5| Step: 1
Training loss: 3.3896165042341244
Validation loss: 2.92247809292172

Epoch: 5| Step: 2
Training loss: 2.966810054385638
Validation loss: 2.924008601045927

Epoch: 5| Step: 3
Training loss: 2.496218778198167
Validation loss: 2.920213097845512

Epoch: 5| Step: 4
Training loss: 3.0782018351768192
Validation loss: 2.9223836329202424

Epoch: 5| Step: 5
Training loss: 3.4288536222447235
Validation loss: 2.921229593633955

Epoch: 5| Step: 6
Training loss: 3.9764201620292434
Validation loss: 2.920217657628863

Epoch: 5| Step: 7
Training loss: 2.7729571719021138
Validation loss: 2.9245134524631418

Epoch: 5| Step: 8
Training loss: 3.3186869872122315
Validation loss: 2.9217499824728983

Epoch: 5| Step: 9
Training loss: 3.110153330859281
Validation loss: 2.9207452170555763

Epoch: 5| Step: 10
Training loss: 2.920254834433918
Validation loss: 2.9182364521430295

Epoch: 195| Step: 0
Training loss: 2.7973250554449893
Validation loss: 2.9183767532372187

Epoch: 5| Step: 1
Training loss: 2.939898222115263
Validation loss: 2.9197055074843536

Epoch: 5| Step: 2
Training loss: 2.5378260022543913
Validation loss: 2.917739931454829

Epoch: 5| Step: 3
Training loss: 3.1102658629775237
Validation loss: 2.917091116074297

Epoch: 5| Step: 4
Training loss: 3.0886757592634773
Validation loss: 2.918355996328456

Epoch: 5| Step: 5
Training loss: 3.6651443153268675
Validation loss: 2.9199816070580833

Epoch: 5| Step: 6
Training loss: 3.271383219051775
Validation loss: 2.9202532542449773

Epoch: 5| Step: 7
Training loss: 3.4842939837834703
Validation loss: 2.917126488952912

Epoch: 5| Step: 8
Training loss: 2.843323895735766
Validation loss: 2.91795067951043

Epoch: 5| Step: 9
Training loss: 3.806472766790327
Validation loss: 2.919942439036332

Epoch: 5| Step: 10
Training loss: 3.508746526191169
Validation loss: 2.922605788024885

Epoch: 196| Step: 0
Training loss: 3.1695898684825465
Validation loss: 2.918691565676642

Epoch: 5| Step: 1
Training loss: 2.891056832714527
Validation loss: 2.9179360265876877

Epoch: 5| Step: 2
Training loss: 3.5429377948792427
Validation loss: 2.9186099084750277

Epoch: 5| Step: 3
Training loss: 2.731649031831408
Validation loss: 2.9160186950207194

Epoch: 5| Step: 4
Training loss: 3.175773892740171
Validation loss: 2.915862949812241

Epoch: 5| Step: 5
Training loss: 3.4448115877802628
Validation loss: 2.913343878098746

Epoch: 5| Step: 6
Training loss: 3.378605082766829
Validation loss: 2.9176574700020472

Epoch: 5| Step: 7
Training loss: 3.38140628474669
Validation loss: 2.9132011381197684

Epoch: 5| Step: 8
Training loss: 3.263114584844247
Validation loss: 2.9175753629662524

Epoch: 5| Step: 9
Training loss: 3.1950858112685534
Validation loss: 2.9149942689624457

Epoch: 5| Step: 10
Training loss: 2.9057910515790724
Validation loss: 2.914581918505352

Epoch: 197| Step: 0
Training loss: 3.0586202530181565
Validation loss: 2.915852527700185

Epoch: 5| Step: 1
Training loss: 2.6463861763954064
Validation loss: 2.9166093343089465

Epoch: 5| Step: 2
Training loss: 3.4766205172037528
Validation loss: 2.9142478253381134

Epoch: 5| Step: 3
Training loss: 3.3639081310922734
Validation loss: 2.9161029716296953

Epoch: 5| Step: 4
Training loss: 3.207014448560968
Validation loss: 2.913258077608243

Epoch: 5| Step: 5
Training loss: 2.9051291652728533
Validation loss: 2.9128484447187

Epoch: 5| Step: 6
Training loss: 3.16492877922257
Validation loss: 2.9119447189622627

Epoch: 5| Step: 7
Training loss: 2.9944581661566594
Validation loss: 2.9137017264458795

Epoch: 5| Step: 8
Training loss: 3.616829708192179
Validation loss: 2.913757684808834

Epoch: 5| Step: 9
Training loss: 3.543428603572495
Validation loss: 2.9144643728433137

Epoch: 5| Step: 10
Training loss: 3.0937615596670875
Validation loss: 2.914648217818305

Epoch: 198| Step: 0
Training loss: 3.5122376802173947
Validation loss: 2.9113032576173317

Epoch: 5| Step: 1
Training loss: 2.219142073254951
Validation loss: 2.9135997879590065

Epoch: 5| Step: 2
Training loss: 2.9247901776038248
Validation loss: 2.9137560659027373

Epoch: 5| Step: 3
Training loss: 2.9308345736176578
Validation loss: 2.914764005789673

Epoch: 5| Step: 4
Training loss: 3.1122889067983204
Validation loss: 2.9128936787408417

Epoch: 5| Step: 5
Training loss: 3.647797162799787
Validation loss: 2.9119802388722302

Epoch: 5| Step: 6
Training loss: 3.2285581610174323
Validation loss: 2.9138576804312373

Epoch: 5| Step: 7
Training loss: 3.2181387015277183
Validation loss: 2.916922600822113

Epoch: 5| Step: 8
Training loss: 3.4695386935048784
Validation loss: 2.9128798294386042

Epoch: 5| Step: 9
Training loss: 3.489823533326894
Validation loss: 2.913854164709029

Epoch: 5| Step: 10
Training loss: 3.166457186010865
Validation loss: 2.9134029821081344

Epoch: 199| Step: 0
Training loss: 3.111411802959032
Validation loss: 2.9181022984128857

Epoch: 5| Step: 1
Training loss: 2.8785885515214216
Validation loss: 2.918607648409409

Epoch: 5| Step: 2
Training loss: 2.79102433819275
Validation loss: 2.917660158712703

Epoch: 5| Step: 3
Training loss: 3.0901783063978736
Validation loss: 2.9244358645153277

Epoch: 5| Step: 4
Training loss: 3.163591062486511
Validation loss: 2.9231500708728313

Epoch: 5| Step: 5
Training loss: 3.4184473716229933
Validation loss: 2.921750533500939

Epoch: 5| Step: 6
Training loss: 3.474915806690347
Validation loss: 2.922063957730059

Epoch: 5| Step: 7
Training loss: 3.1240730436726585
Validation loss: 2.9268841594507977

Epoch: 5| Step: 8
Training loss: 2.959428790367964
Validation loss: 2.9184108060541925

Epoch: 5| Step: 9
Training loss: 3.801773365223132
Validation loss: 2.909710183911953

Epoch: 5| Step: 10
Training loss: 3.242431190248844
Validation loss: 2.9066768971797785

Epoch: 200| Step: 0
Training loss: 3.337112827203236
Validation loss: 2.907498576085837

Epoch: 5| Step: 1
Training loss: 3.596382835249977
Validation loss: 2.907070642562626

Epoch: 5| Step: 2
Training loss: 3.1995931366713446
Validation loss: 2.9089701450176184

Epoch: 5| Step: 3
Training loss: 2.4991265678517234
Validation loss: 2.90795586914898

Epoch: 5| Step: 4
Training loss: 2.919746807042749
Validation loss: 2.906036001233252

Epoch: 5| Step: 5
Training loss: 3.4779653397731103
Validation loss: 2.9080335137492246

Epoch: 5| Step: 6
Training loss: 3.333720343693522
Validation loss: 2.9093430645924325

Epoch: 5| Step: 7
Training loss: 3.0604287753418524
Validation loss: 2.908030231655182

Epoch: 5| Step: 8
Training loss: 2.9776654140028938
Validation loss: 2.906532069259192

Epoch: 5| Step: 9
Training loss: 3.4282557251311534
Validation loss: 2.906128483760323

Epoch: 5| Step: 10
Training loss: 3.1779708539851805
Validation loss: 2.906695432882822

Epoch: 201| Step: 0
Training loss: 2.936283914979973
Validation loss: 2.906137337884291

Epoch: 5| Step: 1
Training loss: 3.234881964863497
Validation loss: 2.9047939443054465

Epoch: 5| Step: 2
Training loss: 3.5100365196132297
Validation loss: 2.9054927750232467

Epoch: 5| Step: 3
Training loss: 3.165725835943374
Validation loss: 2.9065754602683636

Epoch: 5| Step: 4
Training loss: 3.0766075770309795
Validation loss: 2.9082233655214704

Epoch: 5| Step: 5
Training loss: 2.987673389718222
Validation loss: 2.9085980793028625

Epoch: 5| Step: 6
Training loss: 3.2142993563407956
Validation loss: 2.9078400842699095

Epoch: 5| Step: 7
Training loss: 3.821649672321698
Validation loss: 2.912376854307211

Epoch: 5| Step: 8
Training loss: 3.2785427005576553
Validation loss: 2.9071683655493374

Epoch: 5| Step: 9
Training loss: 3.2362886379229554
Validation loss: 2.9036740290312393

Epoch: 5| Step: 10
Training loss: 2.3167133610179618
Validation loss: 2.905678609885847

Epoch: 202| Step: 0
Training loss: 3.647475840833007
Validation loss: 2.903081308179123

Epoch: 5| Step: 1
Training loss: 2.692070645072812
Validation loss: 2.9130452352309035

Epoch: 5| Step: 2
Training loss: 3.601754868142471
Validation loss: 2.9065844003498698

Epoch: 5| Step: 3
Training loss: 3.796704449374921
Validation loss: 2.908657079673123

Epoch: 5| Step: 4
Training loss: 2.7598515825862906
Validation loss: 2.9076602322483485

Epoch: 5| Step: 5
Training loss: 3.4644437986999566
Validation loss: 2.904489445079898

Epoch: 5| Step: 6
Training loss: 3.4339604968474364
Validation loss: 2.903378927415509

Epoch: 5| Step: 7
Training loss: 3.0341933599728157
Validation loss: 2.9012920224260537

Epoch: 5| Step: 8
Training loss: 2.5124476489026715
Validation loss: 2.9010157312340072

Epoch: 5| Step: 9
Training loss: 2.595718739665694
Validation loss: 2.900294250564303

Epoch: 5| Step: 10
Training loss: 3.2270860593590123
Validation loss: 2.9032173975557263

Epoch: 203| Step: 0
Training loss: 3.2205272323482803
Validation loss: 2.903001707524906

Epoch: 5| Step: 1
Training loss: 3.0158863646148903
Validation loss: 2.903931047950121

Epoch: 5| Step: 2
Training loss: 2.5277148391470967
Validation loss: 2.9019407097026564

Epoch: 5| Step: 3
Training loss: 3.1743093084758556
Validation loss: 2.9042993818843086

Epoch: 5| Step: 4
Training loss: 2.8094596536037053
Validation loss: 2.904028567611133

Epoch: 5| Step: 5
Training loss: 2.8802852976738422
Validation loss: 2.9035109218733157

Epoch: 5| Step: 6
Training loss: 3.55038453289512
Validation loss: 2.9049239461716065

Epoch: 5| Step: 7
Training loss: 2.7567245455488907
Validation loss: 2.9011980390447456

Epoch: 5| Step: 8
Training loss: 3.863508967986917
Validation loss: 2.904814221820059

Epoch: 5| Step: 9
Training loss: 3.75172549921987
Validation loss: 2.9013826698531324

Epoch: 5| Step: 10
Training loss: 3.2590364860091197
Validation loss: 2.8999736829956078

Epoch: 204| Step: 0
Training loss: 3.6638469836004726
Validation loss: 2.900376463200487

Epoch: 5| Step: 1
Training loss: 3.3848915670993818
Validation loss: 2.9008313695956662

Epoch: 5| Step: 2
Training loss: 3.3532022230885183
Validation loss: 2.899297068187629

Epoch: 5| Step: 3
Training loss: 3.330581832780668
Validation loss: 2.9021087420169214

Epoch: 5| Step: 4
Training loss: 3.0594708779325686
Validation loss: 2.9029153205202713

Epoch: 5| Step: 5
Training loss: 1.973141933364876
Validation loss: 2.9058484556356667

Epoch: 5| Step: 6
Training loss: 2.819315049741857
Validation loss: 2.9001041016018

Epoch: 5| Step: 7
Training loss: 3.375146509452014
Validation loss: 2.902350867623786

Epoch: 5| Step: 8
Training loss: 3.141292975450903
Validation loss: 2.898161934477376

Epoch: 5| Step: 9
Training loss: 3.045591739478406
Validation loss: 2.8970330380247282

Epoch: 5| Step: 10
Training loss: 3.6476063077624237
Validation loss: 2.899343285550391

Epoch: 205| Step: 0
Training loss: 2.8206810538708584
Validation loss: 2.8982036516031213

Epoch: 5| Step: 1
Training loss: 3.124568604256837
Validation loss: 2.8985950500232094

Epoch: 5| Step: 2
Training loss: 3.606775842472642
Validation loss: 2.8981591471812513

Epoch: 5| Step: 3
Training loss: 3.2008807996669852
Validation loss: 2.8963052915834235

Epoch: 5| Step: 4
Training loss: 3.6674680845488052
Validation loss: 2.894609770154679

Epoch: 5| Step: 5
Training loss: 2.993531724462557
Validation loss: 2.896019580299536

Epoch: 5| Step: 6
Training loss: 2.883625029727817
Validation loss: 2.899340130672247

Epoch: 5| Step: 7
Training loss: 3.038805011736197
Validation loss: 2.897646086002615

Epoch: 5| Step: 8
Training loss: 3.5608788532752187
Validation loss: 2.8947900512999234

Epoch: 5| Step: 9
Training loss: 3.00806962932999
Validation loss: 2.892967680082556

Epoch: 5| Step: 10
Training loss: 2.959412677851325
Validation loss: 2.8990302019821668

Epoch: 206| Step: 0
Training loss: 3.5618280145076686
Validation loss: 2.895709829174848

Epoch: 5| Step: 1
Training loss: 3.555782342340582
Validation loss: 2.8961442966484405

Epoch: 5| Step: 2
Training loss: 3.197160032808903
Validation loss: 2.8975266871703167

Epoch: 5| Step: 3
Training loss: 2.807339320489023
Validation loss: 2.8956508837207573

Epoch: 5| Step: 4
Training loss: 2.9656387891539278
Validation loss: 2.8945570055823606

Epoch: 5| Step: 5
Training loss: 3.274474059527135
Validation loss: 2.894914352153481

Epoch: 5| Step: 6
Training loss: 2.831271281383439
Validation loss: 2.892548978575235

Epoch: 5| Step: 7
Training loss: 2.906833385037598
Validation loss: 2.8916452121272656

Epoch: 5| Step: 8
Training loss: 3.559624029730138
Validation loss: 2.8949970593881087

Epoch: 5| Step: 9
Training loss: 3.0689863684964602
Validation loss: 2.8935438164665883

Epoch: 5| Step: 10
Training loss: 3.190943036495356
Validation loss: 2.893431374626536

Epoch: 207| Step: 0
Training loss: 3.0387325156747256
Validation loss: 2.8992141502577478

Epoch: 5| Step: 1
Training loss: 3.664523292961943
Validation loss: 2.9002739653140464

Epoch: 5| Step: 2
Training loss: 2.630983073633568
Validation loss: 2.900399236775743

Epoch: 5| Step: 3
Training loss: 3.0437701716136485
Validation loss: 2.8909444085395024

Epoch: 5| Step: 4
Training loss: 3.1574384510266365
Validation loss: 2.8965754268929187

Epoch: 5| Step: 5
Training loss: 3.786855027076393
Validation loss: 2.8905252206083394

Epoch: 5| Step: 6
Training loss: 3.3925008199489786
Validation loss: 2.8957352475929836

Epoch: 5| Step: 7
Training loss: 3.3968888185109485
Validation loss: 2.8930578590447844

Epoch: 5| Step: 8
Training loss: 2.4028615502054143
Validation loss: 2.894364671033835

Epoch: 5| Step: 9
Training loss: 2.995093784296812
Validation loss: 2.8987794495333334

Epoch: 5| Step: 10
Training loss: 3.2456687529678225
Validation loss: 2.889914000210529

Epoch: 208| Step: 0
Training loss: 3.1919073414177124
Validation loss: 2.8941736293637033

Epoch: 5| Step: 1
Training loss: 2.82979134211641
Validation loss: 2.891532543961305

Epoch: 5| Step: 2
Training loss: 3.40666784121001
Validation loss: 2.893431646634936

Epoch: 5| Step: 3
Training loss: 2.845661401279144
Validation loss: 2.8908272018152155

Epoch: 5| Step: 4
Training loss: 2.679563647374705
Validation loss: 2.8942547128932063

Epoch: 5| Step: 5
Training loss: 2.9950097223038084
Validation loss: 2.8906383493032624

Epoch: 5| Step: 6
Training loss: 3.240924488086013
Validation loss: 2.8904462187560167

Epoch: 5| Step: 7
Training loss: 3.4477667338952878
Validation loss: 2.888943434002609

Epoch: 5| Step: 8
Training loss: 3.354065003048947
Validation loss: 2.8910141354535352

Epoch: 5| Step: 9
Training loss: 3.6067906495065216
Validation loss: 2.8889009761662607

Epoch: 5| Step: 10
Training loss: 3.2722777722631764
Validation loss: 2.887936956340363

Epoch: 209| Step: 0
Training loss: 2.6320372212569545
Validation loss: 2.8917826694834874

Epoch: 5| Step: 1
Training loss: 2.955381308544473
Validation loss: 2.8917367754393215

Epoch: 5| Step: 2
Training loss: 3.2759555791188415
Validation loss: 2.891480180730187

Epoch: 5| Step: 3
Training loss: 3.5073021600330447
Validation loss: 2.8902114763056517

Epoch: 5| Step: 4
Training loss: 2.604956809654159
Validation loss: 2.8905108809844147

Epoch: 5| Step: 5
Training loss: 3.5984044989904196
Validation loss: 2.889334431181915

Epoch: 5| Step: 6
Training loss: 2.696232293238393
Validation loss: 2.889512072817879

Epoch: 5| Step: 7
Training loss: 3.3739628081111945
Validation loss: 2.8882362470836798

Epoch: 5| Step: 8
Training loss: 3.19680117226351
Validation loss: 2.8919721227573185

Epoch: 5| Step: 9
Training loss: 3.7584323173621064
Validation loss: 2.8936267489264544

Epoch: 5| Step: 10
Training loss: 3.1092625889993712
Validation loss: 2.8913807615703737

Epoch: 210| Step: 0
Training loss: 2.6924303650418455
Validation loss: 2.892277884852541

Epoch: 5| Step: 1
Training loss: 3.092288818549959
Validation loss: 2.8948063180474435

Epoch: 5| Step: 2
Training loss: 3.0996856776210113
Validation loss: 2.8953380667284687

Epoch: 5| Step: 3
Training loss: 2.63353015389461
Validation loss: 2.891058350827753

Epoch: 5| Step: 4
Training loss: 3.4093252875937163
Validation loss: 2.8927036987193353

Epoch: 5| Step: 5
Training loss: 3.032852535779506
Validation loss: 2.8934860743810455

Epoch: 5| Step: 6
Training loss: 3.817017177384232
Validation loss: 2.8935751660415736

Epoch: 5| Step: 7
Training loss: 3.5523871387913366
Validation loss: 2.887245405153114

Epoch: 5| Step: 8
Training loss: 3.1633321036794326
Validation loss: 2.885680248861102

Epoch: 5| Step: 9
Training loss: 3.0596674061457185
Validation loss: 2.8851981818671684

Epoch: 5| Step: 10
Training loss: 3.237660973276983
Validation loss: 2.883457307700896

Epoch: 211| Step: 0
Training loss: 2.721739254707856
Validation loss: 2.885978736980127

Epoch: 5| Step: 1
Training loss: 3.6423231102086695
Validation loss: 2.8855227062239255

Epoch: 5| Step: 2
Training loss: 3.134394752691218
Validation loss: 2.8844403222146955

Epoch: 5| Step: 3
Training loss: 3.3660709804637245
Validation loss: 2.8828809669835254

Epoch: 5| Step: 4
Training loss: 3.0919995220425767
Validation loss: 2.8836764856664208

Epoch: 5| Step: 5
Training loss: 3.09638356333072
Validation loss: 2.8832541400172946

Epoch: 5| Step: 6
Training loss: 2.8517139969388436
Validation loss: 2.8865617134356683

Epoch: 5| Step: 7
Training loss: 3.1408413485125095
Validation loss: 2.882668026767926

Epoch: 5| Step: 8
Training loss: 3.384155007043019
Validation loss: 2.885583320929382

Epoch: 5| Step: 9
Training loss: 3.221386320569916
Validation loss: 2.8843854784684915

Epoch: 5| Step: 10
Training loss: 3.1870495347002845
Validation loss: 2.883725721736391

Epoch: 212| Step: 0
Training loss: 3.210652062567683
Validation loss: 2.884967384412068

Epoch: 5| Step: 1
Training loss: 3.3956686030649132
Validation loss: 2.8910031998874577

Epoch: 5| Step: 2
Training loss: 3.0143482094589955
Validation loss: 2.888918992758776

Epoch: 5| Step: 3
Training loss: 2.911939568689017
Validation loss: 2.8952154080278034

Epoch: 5| Step: 4
Training loss: 2.8814220848742678
Validation loss: 2.8899112865725503

Epoch: 5| Step: 5
Training loss: 3.134428829746357
Validation loss: 2.8902583933247983

Epoch: 5| Step: 6
Training loss: 3.7661679458162443
Validation loss: 2.885564539444539

Epoch: 5| Step: 7
Training loss: 3.4401099267295803
Validation loss: 2.884238379273953

Epoch: 5| Step: 8
Training loss: 2.5269291108683203
Validation loss: 2.887501657918131

Epoch: 5| Step: 9
Training loss: 3.376301973487312
Validation loss: 2.889589606167379

Epoch: 5| Step: 10
Training loss: 3.067541527004559
Validation loss: 2.884477831266778

Epoch: 213| Step: 0
Training loss: 3.0019146849157283
Validation loss: 2.8831133755072584

Epoch: 5| Step: 1
Training loss: 3.0542335270480123
Validation loss: 2.8839293655606526

Epoch: 5| Step: 2
Training loss: 3.5447908571690565
Validation loss: 2.8810009348193524

Epoch: 5| Step: 3
Training loss: 3.113348487501273
Validation loss: 2.8798527114843933

Epoch: 5| Step: 4
Training loss: 3.038624709891545
Validation loss: 2.8783380338347553

Epoch: 5| Step: 5
Training loss: 3.033085218349867
Validation loss: 2.8810774834996367

Epoch: 5| Step: 6
Training loss: 2.9100710453130745
Validation loss: 2.8832765357987293

Epoch: 5| Step: 7
Training loss: 3.474516877545515
Validation loss: 2.8888159681029983

Epoch: 5| Step: 8
Training loss: 3.1040915836410736
Validation loss: 2.885719540784087

Epoch: 5| Step: 9
Training loss: 3.4993468083811226
Validation loss: 2.8908080464602515

Epoch: 5| Step: 10
Training loss: 3.0210156265152643
Validation loss: 2.8830322018278234

Epoch: 214| Step: 0
Training loss: 3.038551267953759
Validation loss: 2.8803643859684267

Epoch: 5| Step: 1
Training loss: 3.389854378737442
Validation loss: 2.8813601209887554

Epoch: 5| Step: 2
Training loss: 3.365639598534959
Validation loss: 2.8823055489998417

Epoch: 5| Step: 3
Training loss: 3.1381428337388164
Validation loss: 2.8785383120407513

Epoch: 5| Step: 4
Training loss: 2.8922538498285633
Validation loss: 2.8800120766462274

Epoch: 5| Step: 5
Training loss: 2.911098250958459
Validation loss: 2.8774814944646314

Epoch: 5| Step: 6
Training loss: 3.3614220348408317
Validation loss: 2.8774323814133917

Epoch: 5| Step: 7
Training loss: 2.9355186110790052
Validation loss: 2.8758252062160787

Epoch: 5| Step: 8
Training loss: 3.786155608125534
Validation loss: 2.8764808500557932

Epoch: 5| Step: 9
Training loss: 3.3563906165986412
Validation loss: 2.8801573266505143

Epoch: 5| Step: 10
Training loss: 2.400714700299706
Validation loss: 2.875407463365334

Epoch: 215| Step: 0
Training loss: 2.927864178712328
Validation loss: 2.876684203800666

Epoch: 5| Step: 1
Training loss: 3.4949585163672445
Validation loss: 2.8754452632107452

Epoch: 5| Step: 2
Training loss: 3.0153100041930547
Validation loss: 2.8759312577156635

Epoch: 5| Step: 3
Training loss: 3.3529469580546354
Validation loss: 2.878323806285301

Epoch: 5| Step: 4
Training loss: 3.016738290797054
Validation loss: 2.879473283877854

Epoch: 5| Step: 5
Training loss: 3.306327106463685
Validation loss: 2.8843964071275665

Epoch: 5| Step: 6
Training loss: 2.7506692245454247
Validation loss: 2.8790877495348077

Epoch: 5| Step: 7
Training loss: 3.4581400499373167
Validation loss: 2.8844559860783345

Epoch: 5| Step: 8
Training loss: 3.307926691721377
Validation loss: 2.8786269570452725

Epoch: 5| Step: 9
Training loss: 2.71585016052458
Validation loss: 2.875279484771995

Epoch: 5| Step: 10
Training loss: 3.4313358872856665
Validation loss: 2.879916881620321

Epoch: 216| Step: 0
Training loss: 2.8232956428969547
Validation loss: 2.883997612245088

Epoch: 5| Step: 1
Training loss: 2.9799289039477115
Validation loss: 2.8808567124554854

Epoch: 5| Step: 2
Training loss: 3.2937555244298133
Validation loss: 2.875435587952677

Epoch: 5| Step: 3
Training loss: 3.319156221000931
Validation loss: 2.8750782251973703

Epoch: 5| Step: 4
Training loss: 3.0124161008176364
Validation loss: 2.8724595268667743

Epoch: 5| Step: 5
Training loss: 3.0632600425058096
Validation loss: 2.8703974477936196

Epoch: 5| Step: 6
Training loss: 3.302672870047509
Validation loss: 2.8767552869265005

Epoch: 5| Step: 7
Training loss: 2.969723190611782
Validation loss: 2.8722776549062896

Epoch: 5| Step: 8
Training loss: 3.9196763885980443
Validation loss: 2.8736790765341684

Epoch: 5| Step: 9
Training loss: 2.775147160932469
Validation loss: 2.8724528001637823

Epoch: 5| Step: 10
Training loss: 3.256713974712231
Validation loss: 2.872360881852755

Epoch: 217| Step: 0
Training loss: 2.156351722860987
Validation loss: 2.869951181687211

Epoch: 5| Step: 1
Training loss: 3.1573553887941506
Validation loss: 2.877472282211953

Epoch: 5| Step: 2
Training loss: 2.966432811506626
Validation loss: 2.8717799029997737

Epoch: 5| Step: 3
Training loss: 2.912224975174527
Validation loss: 2.8735635244293674

Epoch: 5| Step: 4
Training loss: 3.7442895006998684
Validation loss: 2.8747803469047937

Epoch: 5| Step: 5
Training loss: 2.9575064313855703
Validation loss: 2.8717052070621043

Epoch: 5| Step: 6
Training loss: 3.1392638639857995
Validation loss: 2.8721602969582563

Epoch: 5| Step: 7
Training loss: 3.7322192493893893
Validation loss: 2.875537594668409

Epoch: 5| Step: 8
Training loss: 3.7866633734442487
Validation loss: 2.8781106625137114

Epoch: 5| Step: 9
Training loss: 2.731744863691552
Validation loss: 2.872440436447953

Epoch: 5| Step: 10
Training loss: 3.1527010160970566
Validation loss: 2.876277483716355

Epoch: 218| Step: 0
Training loss: 3.9478004995414455
Validation loss: 2.87369898302946

Epoch: 5| Step: 1
Training loss: 2.900092051130325
Validation loss: 2.8752683743433045

Epoch: 5| Step: 2
Training loss: 2.586075148131517
Validation loss: 2.868386791804779

Epoch: 5| Step: 3
Training loss: 2.5899103078445482
Validation loss: 2.869399800831664

Epoch: 5| Step: 4
Training loss: 3.419153672956867
Validation loss: 2.873091709521645

Epoch: 5| Step: 5
Training loss: 3.4463415014871996
Validation loss: 2.869686189908504

Epoch: 5| Step: 6
Training loss: 3.2996757868246296
Validation loss: 2.867192258560136

Epoch: 5| Step: 7
Training loss: 3.5824259267045155
Validation loss: 2.868009118878785

Epoch: 5| Step: 8
Training loss: 2.41248731856892
Validation loss: 2.865970442343022

Epoch: 5| Step: 9
Training loss: 3.2770508554590876
Validation loss: 2.868041228464068

Epoch: 5| Step: 10
Training loss: 2.9598583177216993
Validation loss: 2.8719319920034065

Epoch: 219| Step: 0
Training loss: 2.716076204767414
Validation loss: 2.8711109358698916

Epoch: 5| Step: 1
Training loss: 3.339408266107788
Validation loss: 2.8705532663249627

Epoch: 5| Step: 2
Training loss: 3.1056067861912284
Validation loss: 2.8685157401593413

Epoch: 5| Step: 3
Training loss: 2.8307803002271825
Validation loss: 2.8676436814295534

Epoch: 5| Step: 4
Training loss: 2.9288911678142617
Validation loss: 2.8668917402560723

Epoch: 5| Step: 5
Training loss: 2.8794085660931694
Validation loss: 2.8683685197794597

Epoch: 5| Step: 6
Training loss: 3.1616196986604064
Validation loss: 2.868651510398672

Epoch: 5| Step: 7
Training loss: 3.1782748296747934
Validation loss: 2.871153425520525

Epoch: 5| Step: 8
Training loss: 3.087724926126255
Validation loss: 2.8769818537827874

Epoch: 5| Step: 9
Training loss: 3.8419343955750134
Validation loss: 2.8768776357262182

Epoch: 5| Step: 10
Training loss: 3.6036037527333478
Validation loss: 2.8751983823809963

Epoch: 220| Step: 0
Training loss: 2.9424868520023235
Validation loss: 2.8730898562277525

Epoch: 5| Step: 1
Training loss: 2.512765052441384
Validation loss: 2.8770567219239584

Epoch: 5| Step: 2
Training loss: 2.823466304934
Validation loss: 2.866796777562232

Epoch: 5| Step: 3
Training loss: 3.1916695046142496
Validation loss: 2.8689304698342313

Epoch: 5| Step: 4
Training loss: 3.4982930516914523
Validation loss: 2.871243003887299

Epoch: 5| Step: 5
Training loss: 3.2485605133089903
Validation loss: 2.8744163384414567

Epoch: 5| Step: 6
Training loss: 2.994017994777546
Validation loss: 2.8721248861985016

Epoch: 5| Step: 7
Training loss: 2.968931172514598
Validation loss: 2.868322816862498

Epoch: 5| Step: 8
Training loss: 3.3912053468536536
Validation loss: 2.8709440222278

Epoch: 5| Step: 9
Training loss: 3.959601724421288
Validation loss: 2.8673117922158893

Epoch: 5| Step: 10
Training loss: 3.010696098972165
Validation loss: 2.8672388673539686

Epoch: 221| Step: 0
Training loss: 3.34306128708794
Validation loss: 2.867419664178964

Epoch: 5| Step: 1
Training loss: 2.6721823889164096
Validation loss: 2.8658552914828768

Epoch: 5| Step: 2
Training loss: 3.5318195255089977
Validation loss: 2.866594423400632

Epoch: 5| Step: 3
Training loss: 2.9057364061266204
Validation loss: 2.8831847251490155

Epoch: 5| Step: 4
Training loss: 3.3823752175692685
Validation loss: 2.912812136241985

Epoch: 5| Step: 5
Training loss: 3.1789222940005857
Validation loss: 2.879196861377901

Epoch: 5| Step: 6
Training loss: 3.4575335638771336
Validation loss: 2.8750188130480563

Epoch: 5| Step: 7
Training loss: 2.7559768576017163
Validation loss: 2.861094271211427

Epoch: 5| Step: 8
Training loss: 2.980462030525682
Validation loss: 2.8634419439149386

Epoch: 5| Step: 9
Training loss: 3.01978327598779
Validation loss: 2.8638730138166273

Epoch: 5| Step: 10
Training loss: 3.458465037461596
Validation loss: 2.869893023876219

Epoch: 222| Step: 0
Training loss: 3.02525160822878
Validation loss: 2.878689678850494

Epoch: 5| Step: 1
Training loss: 2.616567692028814
Validation loss: 2.8761102530933864

Epoch: 5| Step: 2
Training loss: 3.225818317299216
Validation loss: 2.889373778109811

Epoch: 5| Step: 3
Training loss: 3.415111808231134
Validation loss: 2.8739358895340192

Epoch: 5| Step: 4
Training loss: 3.0713893564705415
Validation loss: 2.8720799687461067

Epoch: 5| Step: 5
Training loss: 3.339091826449801
Validation loss: 2.8670707402352873

Epoch: 5| Step: 6
Training loss: 3.3846019214415715
Validation loss: 2.8635695213758092

Epoch: 5| Step: 7
Training loss: 3.0475204957768827
Validation loss: 2.8633832456303634

Epoch: 5| Step: 8
Training loss: 2.8330123569960963
Validation loss: 2.8642022851383584

Epoch: 5| Step: 9
Training loss: 2.9252640759845265
Validation loss: 2.863954093189263

Epoch: 5| Step: 10
Training loss: 3.849353334688293
Validation loss: 2.8664129511467156

Epoch: 223| Step: 0
Training loss: 2.44822641130986
Validation loss: 2.8618231458603987

Epoch: 5| Step: 1
Training loss: 3.5466261452915124
Validation loss: 2.8710320471737467

Epoch: 5| Step: 2
Training loss: 3.0160647056883456
Validation loss: 2.8692516939052846

Epoch: 5| Step: 3
Training loss: 3.017338873504843
Validation loss: 2.8669532120654124

Epoch: 5| Step: 4
Training loss: 3.3396361526307037
Validation loss: 2.8701467305367765

Epoch: 5| Step: 5
Training loss: 3.1182723296855457
Validation loss: 2.8721196627353045

Epoch: 5| Step: 6
Training loss: 3.1185090363704764
Validation loss: 2.8678104421001076

Epoch: 5| Step: 7
Training loss: 3.400574742152469
Validation loss: 2.863632347381597

Epoch: 5| Step: 8
Training loss: 3.56457378862546
Validation loss: 2.863288009889183

Epoch: 5| Step: 9
Training loss: 2.950432574351337
Validation loss: 2.8649701746432394

Epoch: 5| Step: 10
Training loss: 3.028114821158073
Validation loss: 2.864070255871513

Epoch: 224| Step: 0
Training loss: 2.428957814245651
Validation loss: 2.8620840224718602

Epoch: 5| Step: 1
Training loss: 3.092669982432535
Validation loss: 2.8651388276702816

Epoch: 5| Step: 2
Training loss: 2.9945608741176706
Validation loss: 2.860858367725029

Epoch: 5| Step: 3
Training loss: 3.3173938803815224
Validation loss: 2.8629398360360376

Epoch: 5| Step: 4
Training loss: 2.9797711237118585
Validation loss: 2.861193388887414

Epoch: 5| Step: 5
Training loss: 3.602710731161573
Validation loss: 2.8598405649629015

Epoch: 5| Step: 6
Training loss: 3.3697096722791504
Validation loss: 2.861181148550997

Epoch: 5| Step: 7
Training loss: 3.4668527174199695
Validation loss: 2.8614386988823224

Epoch: 5| Step: 8
Training loss: 2.9961042540762737
Validation loss: 2.8595367830572895

Epoch: 5| Step: 9
Training loss: 3.6525979346292834
Validation loss: 2.860015588483114

Epoch: 5| Step: 10
Training loss: 2.4285522949042035
Validation loss: 2.8594519769949565

Epoch: 225| Step: 0
Training loss: 3.368315965650789
Validation loss: 2.8566772548511716

Epoch: 5| Step: 1
Training loss: 2.85888467555702
Validation loss: 2.862122558099766

Epoch: 5| Step: 2
Training loss: 3.602176373973299
Validation loss: 2.8717628443267356

Epoch: 5| Step: 3
Training loss: 2.8773313275042387
Validation loss: 2.866991812797883

Epoch: 5| Step: 4
Training loss: 3.3880535166183146
Validation loss: 2.8733611284366805

Epoch: 5| Step: 5
Training loss: 2.659835459990872
Validation loss: 2.8688026732409004

Epoch: 5| Step: 6
Training loss: 3.2126914475685764
Validation loss: 2.865585444213572

Epoch: 5| Step: 7
Training loss: 3.379584977441901
Validation loss: 2.873930250106898

Epoch: 5| Step: 8
Training loss: 2.605460880387759
Validation loss: 2.8755931982387515

Epoch: 5| Step: 9
Training loss: 3.132418410326289
Validation loss: 2.8623924685120596

Epoch: 5| Step: 10
Training loss: 3.493377278053965
Validation loss: 2.8616448872966953

Epoch: 226| Step: 0
Training loss: 3.3023726921175998
Validation loss: 2.85995432073513

Epoch: 5| Step: 1
Training loss: 3.1167990841674245
Validation loss: 2.8570317381720955

Epoch: 5| Step: 2
Training loss: 3.3184401315401506
Validation loss: 2.853988049652209

Epoch: 5| Step: 3
Training loss: 3.208450876700194
Validation loss: 2.8546214662386

Epoch: 5| Step: 4
Training loss: 3.350380998268276
Validation loss: 2.858022535720363

Epoch: 5| Step: 5
Training loss: 3.510924320510282
Validation loss: 2.8565320862227663

Epoch: 5| Step: 6
Training loss: 2.878685786218066
Validation loss: 2.8563091451553193

Epoch: 5| Step: 7
Training loss: 3.00767853673874
Validation loss: 2.853939600362101

Epoch: 5| Step: 8
Training loss: 3.162089771306589
Validation loss: 2.8529359070943965

Epoch: 5| Step: 9
Training loss: 3.2905717952299702
Validation loss: 2.853726034970004

Epoch: 5| Step: 10
Training loss: 2.262857364651778
Validation loss: 2.8529276489728317

Epoch: 227| Step: 0
Training loss: 3.2214991116224265
Validation loss: 2.8549888390143203

Epoch: 5| Step: 1
Training loss: 3.8066348628259363
Validation loss: 2.8508036949182793

Epoch: 5| Step: 2
Training loss: 2.8070157304138883
Validation loss: 2.8534956414898955

Epoch: 5| Step: 3
Training loss: 3.0185494745284167
Validation loss: 2.85253264381769

Epoch: 5| Step: 4
Training loss: 3.382251155521766
Validation loss: 2.8521776255947833

Epoch: 5| Step: 5
Training loss: 3.331540642918817
Validation loss: 2.853717272464829

Epoch: 5| Step: 6
Training loss: 3.3703513449604277
Validation loss: 2.8502412902927547

Epoch: 5| Step: 7
Training loss: 2.3355182794612226
Validation loss: 2.8512587536818

Epoch: 5| Step: 8
Training loss: 3.3663562713404627
Validation loss: 2.8485762965808736

Epoch: 5| Step: 9
Training loss: 3.1742202281831102
Validation loss: 2.851095606213442

Epoch: 5| Step: 10
Training loss: 2.4553758536282313
Validation loss: 2.8501041015541326

Epoch: 228| Step: 0
Training loss: 2.785096155831788
Validation loss: 2.84683555247101

Epoch: 5| Step: 1
Training loss: 2.807361826022911
Validation loss: 2.849639248499672

Epoch: 5| Step: 2
Training loss: 2.799510630349472
Validation loss: 2.8469422417246304

Epoch: 5| Step: 3
Training loss: 3.2979832815807204
Validation loss: 2.8495495964724946

Epoch: 5| Step: 4
Training loss: 3.381512892228509
Validation loss: 2.845058293921401

Epoch: 5| Step: 5
Training loss: 2.849479855371326
Validation loss: 2.848000326080898

Epoch: 5| Step: 6
Training loss: 3.474516877545515
Validation loss: 2.8481753521668787

Epoch: 5| Step: 7
Training loss: 2.9054570910965327
Validation loss: 2.850162625381981

Epoch: 5| Step: 8
Training loss: 3.456645293162036
Validation loss: 2.8601092426855748

Epoch: 5| Step: 9
Training loss: 3.586111558999026
Validation loss: 2.8530198375477664

Epoch: 5| Step: 10
Training loss: 3.082144654173533
Validation loss: 2.856310571339862

Epoch: 229| Step: 0
Training loss: 3.0942232945160377
Validation loss: 2.8544166071669452

Epoch: 5| Step: 1
Training loss: 2.835497609220387
Validation loss: 2.859554660567526

Epoch: 5| Step: 2
Training loss: 2.8858185269090404
Validation loss: 2.848116458060899

Epoch: 5| Step: 3
Training loss: 3.847105716879975
Validation loss: 2.843981797305668

Epoch: 5| Step: 4
Training loss: 2.611076394204285
Validation loss: 2.8411454375128313

Epoch: 5| Step: 5
Training loss: 3.1033152665029937
Validation loss: 2.842499944693545

Epoch: 5| Step: 6
Training loss: 3.5860170176879334
Validation loss: 2.848353873167008

Epoch: 5| Step: 7
Training loss: 2.78509461493863
Validation loss: 2.8422991001377556

Epoch: 5| Step: 8
Training loss: 3.4287305465741604
Validation loss: 2.849406230315141

Epoch: 5| Step: 9
Training loss: 2.992525644343865
Validation loss: 2.8434151685956164

Epoch: 5| Step: 10
Training loss: 3.2517635255821036
Validation loss: 2.846898890945795

Epoch: 230| Step: 0
Training loss: 3.738539157688379
Validation loss: 2.8455245286933657

Epoch: 5| Step: 1
Training loss: 3.081832279798118
Validation loss: 2.8477158630164046

Epoch: 5| Step: 2
Training loss: 3.3205276240052917
Validation loss: 2.858568952637206

Epoch: 5| Step: 3
Training loss: 3.223646864792532
Validation loss: 2.8602065283734395

Epoch: 5| Step: 4
Training loss: 3.027993566851415
Validation loss: 2.8676099921668956

Epoch: 5| Step: 5
Training loss: 3.741016308196006
Validation loss: 2.857514841758198

Epoch: 5| Step: 6
Training loss: 3.3447882920854752
Validation loss: 2.8511726394960095

Epoch: 5| Step: 7
Training loss: 2.784521172279807
Validation loss: 2.84442213666707

Epoch: 5| Step: 8
Training loss: 2.617372420880797
Validation loss: 2.8420490766000066

Epoch: 5| Step: 9
Training loss: 2.6581246436625836
Validation loss: 2.844137523038349

Epoch: 5| Step: 10
Training loss: 2.7399046870172707
Validation loss: 2.8471967419046855

Epoch: 231| Step: 0
Training loss: 3.3240150541660105
Validation loss: 2.8472090828791896

Epoch: 5| Step: 1
Training loss: 3.5024265324622315
Validation loss: 2.845356729484471

Epoch: 5| Step: 2
Training loss: 3.576576530858987
Validation loss: 2.8483150873549232

Epoch: 5| Step: 3
Training loss: 3.1194721922334354
Validation loss: 2.8494879687392074

Epoch: 5| Step: 4
Training loss: 3.16392821980688
Validation loss: 2.847342033543254

Epoch: 5| Step: 5
Training loss: 3.096408202927268
Validation loss: 2.8456228301216666

Epoch: 5| Step: 6
Training loss: 2.9636549746412486
Validation loss: 2.8420574998327286

Epoch: 5| Step: 7
Training loss: 3.061999533106932
Validation loss: 2.8409888912936836

Epoch: 5| Step: 8
Training loss: 2.585012402975111
Validation loss: 2.839854812154797

Epoch: 5| Step: 9
Training loss: 3.082195553189412
Validation loss: 2.840877739838665

Epoch: 5| Step: 10
Training loss: 3.0184464770012878
Validation loss: 2.840627718448258

Epoch: 232| Step: 0
Training loss: 2.891366069754678
Validation loss: 2.8424728222828772

Epoch: 5| Step: 1
Training loss: 3.518752677740294
Validation loss: 2.8531446472159288

Epoch: 5| Step: 2
Training loss: 3.4805384841937337
Validation loss: 2.854839112502099

Epoch: 5| Step: 3
Training loss: 3.4140347058454585
Validation loss: 2.8567114230336843

Epoch: 5| Step: 4
Training loss: 2.716381400485365
Validation loss: 2.849287205130329

Epoch: 5| Step: 5
Training loss: 3.3709469229503797
Validation loss: 2.8487821290790465

Epoch: 5| Step: 6
Training loss: 3.1398461737887975
Validation loss: 2.8447727769773117

Epoch: 5| Step: 7
Training loss: 2.5314094587420737
Validation loss: 2.848191870741297

Epoch: 5| Step: 8
Training loss: 2.993782275828267
Validation loss: 2.8408481469054485

Epoch: 5| Step: 9
Training loss: 3.685300009120908
Validation loss: 2.8455000654238702

Epoch: 5| Step: 10
Training loss: 2.4696815761150956
Validation loss: 2.837626137386626

Epoch: 233| Step: 0
Training loss: 3.426269357286318
Validation loss: 2.8412831589657186

Epoch: 5| Step: 1
Training loss: 3.370561153203987
Validation loss: 2.8422690538811057

Epoch: 5| Step: 2
Training loss: 2.988032471517384
Validation loss: 2.8415905112591697

Epoch: 5| Step: 3
Training loss: 3.2237733326689155
Validation loss: 2.8405958549262156

Epoch: 5| Step: 4
Training loss: 2.894347562122381
Validation loss: 2.834668408336958

Epoch: 5| Step: 5
Training loss: 3.180135259570737
Validation loss: 2.8374860447619086

Epoch: 5| Step: 6
Training loss: 2.7569351313572765
Validation loss: 2.836760369886257

Epoch: 5| Step: 7
Training loss: 3.66046134792639
Validation loss: 2.8386217006491488

Epoch: 5| Step: 8
Training loss: 2.073332343924103
Validation loss: 2.8361391218269496

Epoch: 5| Step: 9
Training loss: 3.067110289400065
Validation loss: 2.8354550237694456

Epoch: 5| Step: 10
Training loss: 3.6460641987683826
Validation loss: 2.84189480019868

Epoch: 234| Step: 0
Training loss: 3.0791726435361126
Validation loss: 2.839827081759147

Epoch: 5| Step: 1
Training loss: 3.386723537067695
Validation loss: 2.8415130630255288

Epoch: 5| Step: 2
Training loss: 2.9595834660645304
Validation loss: 2.83539165298242

Epoch: 5| Step: 3
Training loss: 3.306353210107443
Validation loss: 2.836854673438949

Epoch: 5| Step: 4
Training loss: 2.617023702022166
Validation loss: 2.8328235615212845

Epoch: 5| Step: 5
Training loss: 3.252454857597259
Validation loss: 2.838264526915142

Epoch: 5| Step: 6
Training loss: 3.276180601989614
Validation loss: 2.834161064466916

Epoch: 5| Step: 7
Training loss: 3.259487535649761
Validation loss: 2.8370634139105175

Epoch: 5| Step: 8
Training loss: 3.2825518250859345
Validation loss: 2.8361534941059783

Epoch: 5| Step: 9
Training loss: 2.9525703030322825
Validation loss: 2.838027938019598

Epoch: 5| Step: 10
Training loss: 3.0322981133365716
Validation loss: 2.8390576606640754

Epoch: 235| Step: 0
Training loss: 3.413996156794257
Validation loss: 2.8384490912564053

Epoch: 5| Step: 1
Training loss: 3.282129514985234
Validation loss: 2.8457968403332705

Epoch: 5| Step: 2
Training loss: 3.2752278605391942
Validation loss: 2.8447572649944473

Epoch: 5| Step: 3
Training loss: 3.2028399084732726
Validation loss: 2.8375126162822184

Epoch: 5| Step: 4
Training loss: 3.093559182187451
Validation loss: 2.8508507011427855

Epoch: 5| Step: 5
Training loss: 3.2617937456292174
Validation loss: 2.843150967683849

Epoch: 5| Step: 6
Training loss: 2.738605561689355
Validation loss: 2.8514821255727036

Epoch: 5| Step: 7
Training loss: 3.0134775688737867
Validation loss: 2.845016282304243

Epoch: 5| Step: 8
Training loss: 2.7425569899417974
Validation loss: 2.8442796396262997

Epoch: 5| Step: 9
Training loss: 3.095526291282232
Validation loss: 2.853617090162219

Epoch: 5| Step: 10
Training loss: 3.303621882344271
Validation loss: 2.849907288107485

Epoch: 236| Step: 0
Training loss: 3.258223327054547
Validation loss: 2.8461863094833197

Epoch: 5| Step: 1
Training loss: 2.931692673172214
Validation loss: 2.8362200295775057

Epoch: 5| Step: 2
Training loss: 3.1573852914495735
Validation loss: 2.8428894403246043

Epoch: 5| Step: 3
Training loss: 2.590867520566182
Validation loss: 2.840234324309092

Epoch: 5| Step: 4
Training loss: 3.1794046562046026
Validation loss: 2.833068122853417

Epoch: 5| Step: 5
Training loss: 3.0411783810612905
Validation loss: 2.834010300903186

Epoch: 5| Step: 6
Training loss: 3.3638646132705126
Validation loss: 2.833904354190076

Epoch: 5| Step: 7
Training loss: 2.9055289737935346
Validation loss: 2.8338470885950167

Epoch: 5| Step: 8
Training loss: 3.2336079890473823
Validation loss: 2.8342276566619367

Epoch: 5| Step: 9
Training loss: 3.604076377017012
Validation loss: 2.831804408294414

Epoch: 5| Step: 10
Training loss: 3.0647794064767155
Validation loss: 2.8335930305938586

Epoch: 237| Step: 0
Training loss: 3.4431127328977875
Validation loss: 2.8310820999530124

Epoch: 5| Step: 1
Training loss: 3.054659557946452
Validation loss: 2.8348191821177102

Epoch: 5| Step: 2
Training loss: 3.051341065294558
Validation loss: 2.8308698457314865

Epoch: 5| Step: 3
Training loss: 2.4979894182578173
Validation loss: 2.830517100935723

Epoch: 5| Step: 4
Training loss: 3.3286555050979145
Validation loss: 2.8311678780627965

Epoch: 5| Step: 5
Training loss: 3.346054708933095
Validation loss: 2.8319728348831568

Epoch: 5| Step: 6
Training loss: 2.6299647655955254
Validation loss: 2.8307847658870577

Epoch: 5| Step: 7
Training loss: 3.3279477640875923
Validation loss: 2.8307894180991515

Epoch: 5| Step: 8
Training loss: 3.5423571343644635
Validation loss: 2.8319055704610956

Epoch: 5| Step: 9
Training loss: 3.1231937528977687
Validation loss: 2.8385023415580917

Epoch: 5| Step: 10
Training loss: 2.9072127849648344
Validation loss: 2.831229201914143

Epoch: 238| Step: 0
Training loss: 2.844482159944011
Validation loss: 2.839509300331155

Epoch: 5| Step: 1
Training loss: 3.581648644966618
Validation loss: 2.83501252795727

Epoch: 5| Step: 2
Training loss: 3.0483316705225403
Validation loss: 2.838029612769967

Epoch: 5| Step: 3
Training loss: 3.4742900150539553
Validation loss: 2.836201599130695

Epoch: 5| Step: 4
Training loss: 2.56612354039447
Validation loss: 2.8523352070102996

Epoch: 5| Step: 5
Training loss: 3.021172515418463
Validation loss: 2.837048990216058

Epoch: 5| Step: 6
Training loss: 3.3761669543326542
Validation loss: 2.832464936189469

Epoch: 5| Step: 7
Training loss: 3.2089919533062523
Validation loss: 2.8384125590515317

Epoch: 5| Step: 8
Training loss: 2.6009588600903175
Validation loss: 2.8259465142996145

Epoch: 5| Step: 9
Training loss: 3.2165558382486212
Validation loss: 2.8255363858988005

Epoch: 5| Step: 10
Training loss: 3.3022054816115918
Validation loss: 2.829066073123115

Epoch: 239| Step: 0
Training loss: 2.6797797629262945
Validation loss: 2.8221486908724684

Epoch: 5| Step: 1
Training loss: 3.03031560909666
Validation loss: 2.829158590687247

Epoch: 5| Step: 2
Training loss: 3.0092855438214783
Validation loss: 2.829436033716554

Epoch: 5| Step: 3
Training loss: 3.1020762596963474
Validation loss: 2.8273004827799344

Epoch: 5| Step: 4
Training loss: 3.2740479403127725
Validation loss: 2.830142110255839

Epoch: 5| Step: 5
Training loss: 2.269217018001226
Validation loss: 2.8319079060580807

Epoch: 5| Step: 6
Training loss: 2.9831652361292034
Validation loss: 2.8330440569611306

Epoch: 5| Step: 7
Training loss: 3.5172590061207742
Validation loss: 2.8362910439792604

Epoch: 5| Step: 8
Training loss: 3.4942671282211237
Validation loss: 2.831981197561263

Epoch: 5| Step: 9
Training loss: 3.506437240197777
Validation loss: 2.8332806268044743

Epoch: 5| Step: 10
Training loss: 3.3436998024853586
Validation loss: 2.834653484083734

Epoch: 240| Step: 0
Training loss: 2.687014691203721
Validation loss: 2.8246711885169207

Epoch: 5| Step: 1
Training loss: 2.9138605697252924
Validation loss: 2.8325013749487895

Epoch: 5| Step: 2
Training loss: 3.2759876014279223
Validation loss: 2.8252668716955367

Epoch: 5| Step: 3
Training loss: 3.3627043084113275
Validation loss: 2.8243948141310864

Epoch: 5| Step: 4
Training loss: 2.9334789919090403
Validation loss: 2.833064742148572

Epoch: 5| Step: 5
Training loss: 3.4817162192984763
Validation loss: 2.828249366412973

Epoch: 5| Step: 6
Training loss: 2.9481739340807662
Validation loss: 2.82784461163054

Epoch: 5| Step: 7
Training loss: 3.3027462138500114
Validation loss: 2.823604333941113

Epoch: 5| Step: 8
Training loss: 3.0595533246915076
Validation loss: 2.8218239663305416

Epoch: 5| Step: 9
Training loss: 3.6914678659292144
Validation loss: 2.8242963602285496

Epoch: 5| Step: 10
Training loss: 2.4172581135275046
Validation loss: 2.8209051766652085

Epoch: 241| Step: 0
Training loss: 2.9868522867639067
Validation loss: 2.8251884342429157

Epoch: 5| Step: 1
Training loss: 3.4046900265576188
Validation loss: 2.8251267324427474

Epoch: 5| Step: 2
Training loss: 2.979171450595527
Validation loss: 2.8259439805462443

Epoch: 5| Step: 3
Training loss: 2.711670790116032
Validation loss: 2.833577153417754

Epoch: 5| Step: 4
Training loss: 2.2488279468880203
Validation loss: 2.838739664864653

Epoch: 5| Step: 5
Training loss: 3.3970597905603737
Validation loss: 2.852609158387877

Epoch: 5| Step: 6
Training loss: 3.6005998429603334
Validation loss: 2.851692496795199

Epoch: 5| Step: 7
Training loss: 3.373795612333573
Validation loss: 2.8467038371421185

Epoch: 5| Step: 8
Training loss: 3.311991094687832
Validation loss: 2.821621539656558

Epoch: 5| Step: 9
Training loss: 3.3424657334002807
Validation loss: 2.8177512054945475

Epoch: 5| Step: 10
Training loss: 2.7591393928558565
Validation loss: 2.8210378902554605

Epoch: 242| Step: 0
Training loss: 2.964221270807827
Validation loss: 2.82154402303507

Epoch: 5| Step: 1
Training loss: 2.4664954985262972
Validation loss: 2.8222078925139766

Epoch: 5| Step: 2
Training loss: 3.23784550771023
Validation loss: 2.826233232873881

Epoch: 5| Step: 3
Training loss: 2.636206366592567
Validation loss: 2.829560628808813

Epoch: 5| Step: 4
Training loss: 3.1522676631248987
Validation loss: 2.8262592153667496

Epoch: 5| Step: 5
Training loss: 3.3932441404670493
Validation loss: 2.821831125339333

Epoch: 5| Step: 6
Training loss: 3.5695901553193927
Validation loss: 2.823392888643592

Epoch: 5| Step: 7
Training loss: 3.6667354895172695
Validation loss: 2.8214063466443293

Epoch: 5| Step: 8
Training loss: 2.891740738270893
Validation loss: 2.8191590227226637

Epoch: 5| Step: 9
Training loss: 2.6566219293839297
Validation loss: 2.8170074867476

Epoch: 5| Step: 10
Training loss: 3.6145996327907595
Validation loss: 2.817698823603708

Epoch: 243| Step: 0
Training loss: 2.88145485106323
Validation loss: 2.814908431851983

Epoch: 5| Step: 1
Training loss: 3.2553906849966396
Validation loss: 2.8180013470182863

Epoch: 5| Step: 2
Training loss: 3.0143716213611556
Validation loss: 2.8170645804874845

Epoch: 5| Step: 3
Training loss: 2.3274961300663066
Validation loss: 2.8220510879343745

Epoch: 5| Step: 4
Training loss: 3.391357342785458
Validation loss: 2.8314546437554133

Epoch: 5| Step: 5
Training loss: 3.189102966560227
Validation loss: 2.8333306436206227

Epoch: 5| Step: 6
Training loss: 3.7559638601479906
Validation loss: 2.8285692575694648

Epoch: 5| Step: 7
Training loss: 2.7979261245245772
Validation loss: 2.8342493905974107

Epoch: 5| Step: 8
Training loss: 2.858520046471443
Validation loss: 2.8265627975262815

Epoch: 5| Step: 9
Training loss: 3.601183029341251
Validation loss: 2.8251881402378864

Epoch: 5| Step: 10
Training loss: 3.0247348889913708
Validation loss: 2.8233577070578715

Epoch: 244| Step: 0
Training loss: 3.2527597887464936
Validation loss: 2.8333760070723857

Epoch: 5| Step: 1
Training loss: 2.146479265590484
Validation loss: 2.8689799071411395

Epoch: 5| Step: 2
Training loss: 3.2762241201532034
Validation loss: 2.863551973321296

Epoch: 5| Step: 3
Training loss: 2.792336559106024
Validation loss: 2.8332362119133463

Epoch: 5| Step: 4
Training loss: 3.2984307401543562
Validation loss: 2.816672211382057

Epoch: 5| Step: 5
Training loss: 2.823037139086142
Validation loss: 2.81606398521208

Epoch: 5| Step: 6
Training loss: 3.016916581510009
Validation loss: 2.8138737430691356

Epoch: 5| Step: 7
Training loss: 3.9335210162714547
Validation loss: 2.8142038323044107

Epoch: 5| Step: 8
Training loss: 2.964360254240187
Validation loss: 2.8199262584344265

Epoch: 5| Step: 9
Training loss: 3.038102417536064
Validation loss: 2.819273370149938

Epoch: 5| Step: 10
Training loss: 3.6463644603592487
Validation loss: 2.8303207967940915

Epoch: 245| Step: 0
Training loss: 2.4479970607677592
Validation loss: 2.821101267232373

Epoch: 5| Step: 1
Training loss: 3.2533578399089564
Validation loss: 2.8208387698154778

Epoch: 5| Step: 2
Training loss: 3.720021391161051
Validation loss: 2.81711405800201

Epoch: 5| Step: 3
Training loss: 3.5701893591147966
Validation loss: 2.816853064757416

Epoch: 5| Step: 4
Training loss: 2.8817924204080505
Validation loss: 2.8136649204282373

Epoch: 5| Step: 5
Training loss: 3.425544617504445
Validation loss: 2.8144373056311687

Epoch: 5| Step: 6
Training loss: 2.9058115638710236
Validation loss: 2.8142332626903643

Epoch: 5| Step: 7
Training loss: 2.6924601181604384
Validation loss: 2.8129928321147313

Epoch: 5| Step: 8
Training loss: 3.0144390086592017
Validation loss: 2.818452575109963

Epoch: 5| Step: 9
Training loss: 3.2596955563264007
Validation loss: 2.819408350106508

Epoch: 5| Step: 10
Training loss: 2.913089702321151
Validation loss: 2.8245067476542154

Epoch: 246| Step: 0
Training loss: 2.682064681340668
Validation loss: 2.828020624077005

Epoch: 5| Step: 1
Training loss: 3.0831663412975874
Validation loss: 2.8277226797961177

Epoch: 5| Step: 2
Training loss: 2.977145881253823
Validation loss: 2.8427294288464284

Epoch: 5| Step: 3
Training loss: 3.507089791050442
Validation loss: 2.8359309506321626

Epoch: 5| Step: 4
Training loss: 3.2118239466968292
Validation loss: 2.8384003080852254

Epoch: 5| Step: 5
Training loss: 3.4741777448934292
Validation loss: 2.8357239864334156

Epoch: 5| Step: 6
Training loss: 3.0660588353154954
Validation loss: 2.819217225030571

Epoch: 5| Step: 7
Training loss: 2.306840518103572
Validation loss: 2.814061886744069

Epoch: 5| Step: 8
Training loss: 3.4438094063012126
Validation loss: 2.8130235483224832

Epoch: 5| Step: 9
Training loss: 3.7036835454462858
Validation loss: 2.812003468535462

Epoch: 5| Step: 10
Training loss: 2.4612461441498055
Validation loss: 2.807915447355913

Epoch: 247| Step: 0
Training loss: 2.825670895202696
Validation loss: 2.8105036551712725

Epoch: 5| Step: 1
Training loss: 3.0665647040568835
Validation loss: 2.8105539769917676

Epoch: 5| Step: 2
Training loss: 3.1818609284340993
Validation loss: 2.8139799975291195

Epoch: 5| Step: 3
Training loss: 3.552876105268064
Validation loss: 2.811478088017953

Epoch: 5| Step: 4
Training loss: 2.8946432691718194
Validation loss: 2.8120819747346553

Epoch: 5| Step: 5
Training loss: 3.1033326293693206
Validation loss: 2.811342640678943

Epoch: 5| Step: 6
Training loss: 3.0256550859839955
Validation loss: 2.812982642213948

Epoch: 5| Step: 7
Training loss: 3.1633964685290477
Validation loss: 2.8106848142515584

Epoch: 5| Step: 8
Training loss: 3.244794344505483
Validation loss: 2.812627076225783

Epoch: 5| Step: 9
Training loss: 3.1029045218734645
Validation loss: 2.8098332276097073

Epoch: 5| Step: 10
Training loss: 3.1292226109962074
Validation loss: 2.810117494969306

Epoch: 248| Step: 0
Training loss: 3.582048688573623
Validation loss: 2.810174297187565

Epoch: 5| Step: 1
Training loss: 3.008925987329865
Validation loss: 2.814146952909324

Epoch: 5| Step: 2
Training loss: 3.0715283032317497
Validation loss: 2.8135970032864512

Epoch: 5| Step: 3
Training loss: 2.6302559322670627
Validation loss: 2.8162297947693333

Epoch: 5| Step: 4
Training loss: 3.532910791959009
Validation loss: 2.813159877065516

Epoch: 5| Step: 5
Training loss: 2.787095516948291
Validation loss: 2.813102176422021

Epoch: 5| Step: 6
Training loss: 3.254424824326846
Validation loss: 2.815403676089729

Epoch: 5| Step: 7
Training loss: 3.08847459245297
Validation loss: 2.812073341375349

Epoch: 5| Step: 8
Training loss: 3.0810263655096852
Validation loss: 2.8295600362711824

Epoch: 5| Step: 9
Training loss: 2.917547274666608
Validation loss: 2.81335997565319

Epoch: 5| Step: 10
Training loss: 3.2024297192237308
Validation loss: 2.819852879984124

Epoch: 249| Step: 0
Training loss: 3.1852305692040095
Validation loss: 2.8236740213992464

Epoch: 5| Step: 1
Training loss: 2.4405336331154457
Validation loss: 2.8285847042508334

Epoch: 5| Step: 2
Training loss: 3.0704255604978594
Validation loss: 2.822461281345942

Epoch: 5| Step: 3
Training loss: 3.4167457354320736
Validation loss: 2.8188609057460274

Epoch: 5| Step: 4
Training loss: 2.570293484417454
Validation loss: 2.818794437093919

Epoch: 5| Step: 5
Training loss: 3.8061975384684468
Validation loss: 2.8144035305666786

Epoch: 5| Step: 6
Training loss: 3.1227298883455172
Validation loss: 2.809041551898884

Epoch: 5| Step: 7
Training loss: 3.270594416030132
Validation loss: 2.811778432878592

Epoch: 5| Step: 8
Training loss: 3.3124356533494455
Validation loss: 2.8045665531963397

Epoch: 5| Step: 9
Training loss: 2.9835347695425534
Validation loss: 2.8074290529825654

Epoch: 5| Step: 10
Training loss: 2.7613772946015307
Validation loss: 2.8104181850043726

Epoch: 250| Step: 0
Training loss: 2.935152454998212
Validation loss: 2.8021080057784307

Epoch: 5| Step: 1
Training loss: 2.7996984966618625
Validation loss: 2.805362779740029

Epoch: 5| Step: 2
Training loss: 2.8740514766195107
Validation loss: 2.8064233633860747

Epoch: 5| Step: 3
Training loss: 2.8431449497987975
Validation loss: 2.8092573124429925

Epoch: 5| Step: 4
Training loss: 3.109004012936235
Validation loss: 2.8038944427169676

Epoch: 5| Step: 5
Training loss: 3.197006261672068
Validation loss: 2.803553273028936

Epoch: 5| Step: 6
Training loss: 2.3976162675623245
Validation loss: 2.803901115374401

Epoch: 5| Step: 7
Training loss: 2.816149060996673
Validation loss: 2.80327743672029

Epoch: 5| Step: 8
Training loss: 3.3395830376129747
Validation loss: 2.808929588950696

Epoch: 5| Step: 9
Training loss: 4.102560100033838
Validation loss: 2.805876993648503

Epoch: 5| Step: 10
Training loss: 3.518602932555031
Validation loss: 2.8066454889553043

Epoch: 251| Step: 0
Training loss: 3.43737473693112
Validation loss: 2.805986852791821

Epoch: 5| Step: 1
Training loss: 3.3933905648262273
Validation loss: 2.809707958448743

Epoch: 5| Step: 2
Training loss: 2.631679936529151
Validation loss: 2.809316447192816

Epoch: 5| Step: 3
Training loss: 2.819894775564785
Validation loss: 2.8153748489089483

Epoch: 5| Step: 4
Training loss: 3.17712734171087
Validation loss: 2.81793788849561

Epoch: 5| Step: 5
Training loss: 3.832778531159986
Validation loss: 2.821768334398854

Epoch: 5| Step: 6
Training loss: 3.1157209345243833
Validation loss: 2.807453022498625

Epoch: 5| Step: 7
Training loss: 2.9527327665588787
Validation loss: 2.80775633713148

Epoch: 5| Step: 8
Training loss: 2.9322654673262485
Validation loss: 2.804095994220013

Epoch: 5| Step: 9
Training loss: 3.3337332167773313
Validation loss: 2.8041494644496288

Epoch: 5| Step: 10
Training loss: 2.2400168302448695
Validation loss: 2.805853948100375

Epoch: 252| Step: 0
Training loss: 3.086163708085731
Validation loss: 2.8073447000996756

Epoch: 5| Step: 1
Training loss: 2.722858700552386
Validation loss: 2.806155538989217

Epoch: 5| Step: 2
Training loss: 2.702414887929214
Validation loss: 2.808651093270638

Epoch: 5| Step: 3
Training loss: 3.340737242280579
Validation loss: 2.802510151986088

Epoch: 5| Step: 4
Training loss: 3.4659294139192314
Validation loss: 2.802284787608521

Epoch: 5| Step: 5
Training loss: 3.745304474008401
Validation loss: 2.803577944120682

Epoch: 5| Step: 6
Training loss: 3.1691522045810268
Validation loss: 2.800481886129467

Epoch: 5| Step: 7
Training loss: 3.1918876219545265
Validation loss: 2.8024231408501525

Epoch: 5| Step: 8
Training loss: 2.946888954558357
Validation loss: 2.8004121149698498

Epoch: 5| Step: 9
Training loss: 3.0498741061383923
Validation loss: 2.799727245346139

Epoch: 5| Step: 10
Training loss: 2.52362551151138
Validation loss: 2.8066486466397094

Epoch: 253| Step: 0
Training loss: 3.2846188644338516
Validation loss: 2.799812875228646

Epoch: 5| Step: 1
Training loss: 2.58340855970885
Validation loss: 2.8014703807470296

Epoch: 5| Step: 2
Training loss: 3.66539865300644
Validation loss: 2.800203524391424

Epoch: 5| Step: 3
Training loss: 2.5602405169869837
Validation loss: 2.805953629264819

Epoch: 5| Step: 4
Training loss: 3.7280945897360933
Validation loss: 2.8179460180785108

Epoch: 5| Step: 5
Training loss: 2.9634752495177676
Validation loss: 2.811503893197563

Epoch: 5| Step: 6
Training loss: 2.8682061238722985
Validation loss: 2.811018610392504

Epoch: 5| Step: 7
Training loss: 2.4242296155316643
Validation loss: 2.8085976448484473

Epoch: 5| Step: 8
Training loss: 2.870410407093621
Validation loss: 2.810065920947008

Epoch: 5| Step: 9
Training loss: 3.273470857946456
Validation loss: 2.8042767682399194

Epoch: 5| Step: 10
Training loss: 3.6825735513938866
Validation loss: 2.807304903886863

Epoch: 254| Step: 0
Training loss: 3.0927256419972786
Validation loss: 2.800044462111724

Epoch: 5| Step: 1
Training loss: 3.2575728879489856
Validation loss: 2.793650871684379

Epoch: 5| Step: 2
Training loss: 3.3576408700938245
Validation loss: 2.8020713968446262

Epoch: 5| Step: 3
Training loss: 2.6474209525291093
Validation loss: 2.7997138581435954

Epoch: 5| Step: 4
Training loss: 2.7801451470884384
Validation loss: 2.796448185143506

Epoch: 5| Step: 5
Training loss: 3.0308740127038916
Validation loss: 2.796292623206166

Epoch: 5| Step: 6
Training loss: 3.0370815852325874
Validation loss: 2.79521381475879

Epoch: 5| Step: 7
Training loss: 3.3110696835525557
Validation loss: 2.796881693987095

Epoch: 5| Step: 8
Training loss: 2.924481050802673
Validation loss: 2.7988543893804443

Epoch: 5| Step: 9
Training loss: 3.408493982709017
Validation loss: 2.7996013719805544

Epoch: 5| Step: 10
Training loss: 3.2721115012255675
Validation loss: 2.795509806768611

Epoch: 255| Step: 0
Training loss: 3.2956756290429547
Validation loss: 2.7968809451192813

Epoch: 5| Step: 1
Training loss: 2.63245658845963
Validation loss: 2.7981528981508395

Epoch: 5| Step: 2
Training loss: 3.159840420665231
Validation loss: 2.797815013325283

Epoch: 5| Step: 3
Training loss: 2.999361447086862
Validation loss: 2.8001551854656777

Epoch: 5| Step: 4
Training loss: 3.2861612531272986
Validation loss: 2.7952866284753437

Epoch: 5| Step: 5
Training loss: 2.8816825492366775
Validation loss: 2.7966662656890424

Epoch: 5| Step: 6
Training loss: 3.069810666138865
Validation loss: 2.793472617481963

Epoch: 5| Step: 7
Training loss: 2.7996944090430835
Validation loss: 2.7961502809069847

Epoch: 5| Step: 8
Training loss: 3.242178381481906
Validation loss: 2.7952352834096774

Epoch: 5| Step: 9
Training loss: 3.4456933604682525
Validation loss: 2.802078445295511

Epoch: 5| Step: 10
Training loss: 3.261871663238228
Validation loss: 2.7974241818272234

Epoch: 256| Step: 0
Training loss: 2.8794883853752964
Validation loss: 2.8074225384694045

Epoch: 5| Step: 1
Training loss: 2.6605926917464298
Validation loss: 2.801733546289775

Epoch: 5| Step: 2
Training loss: 3.4690335819381666
Validation loss: 2.7925849350792413

Epoch: 5| Step: 3
Training loss: 3.1163673182322387
Validation loss: 2.799642980904722

Epoch: 5| Step: 4
Training loss: 2.8744086611096225
Validation loss: 2.801522226478062

Epoch: 5| Step: 5
Training loss: 3.9998359646541286
Validation loss: 2.7939381737956253

Epoch: 5| Step: 6
Training loss: 3.0687916801403503
Validation loss: 2.7955447794192154

Epoch: 5| Step: 7
Training loss: 2.9386323410228723
Validation loss: 2.7940484895157214

Epoch: 5| Step: 8
Training loss: 3.0968792435109833
Validation loss: 2.7994901844140765

Epoch: 5| Step: 9
Training loss: 2.6992750148181157
Validation loss: 2.795314034013351

Epoch: 5| Step: 10
Training loss: 3.078277739012673
Validation loss: 2.7931470023986416

Epoch: 257| Step: 0
Training loss: 2.838569869621694
Validation loss: 2.794244244511911

Epoch: 5| Step: 1
Training loss: 3.254882666000972
Validation loss: 2.7990418253026297

Epoch: 5| Step: 2
Training loss: 2.7950185229893845
Validation loss: 2.7997496023810755

Epoch: 5| Step: 3
Training loss: 3.0531253186072473
Validation loss: 2.802811857546472

Epoch: 5| Step: 4
Training loss: 3.2090922527325154
Validation loss: 2.8100451877992265

Epoch: 5| Step: 5
Training loss: 2.8870284517033813
Validation loss: 2.793518808970103

Epoch: 5| Step: 6
Training loss: 2.9391289921995742
Validation loss: 2.7937073966339674

Epoch: 5| Step: 7
Training loss: 3.072073783147397
Validation loss: 2.7932533734694927

Epoch: 5| Step: 8
Training loss: 3.9625551430508508
Validation loss: 2.791239359708225

Epoch: 5| Step: 9
Training loss: 2.9599209854817765
Validation loss: 2.791927050619739

Epoch: 5| Step: 10
Training loss: 2.9476797774786596
Validation loss: 2.787842986235172

Epoch: 258| Step: 0
Training loss: 2.9070248134985683
Validation loss: 2.7926573243769375

Epoch: 5| Step: 1
Training loss: 2.849525539323235
Validation loss: 2.791216688358947

Epoch: 5| Step: 2
Training loss: 3.1214096807012357
Validation loss: 2.795174663028322

Epoch: 5| Step: 3
Training loss: 3.166492423902177
Validation loss: 2.7995872543466205

Epoch: 5| Step: 4
Training loss: 2.8299261438013037
Validation loss: 2.7999173184022483

Epoch: 5| Step: 5
Training loss: 3.599506445006599
Validation loss: 2.7971026883093466

Epoch: 5| Step: 6
Training loss: 2.4746178534286485
Validation loss: 2.8040609014849194

Epoch: 5| Step: 7
Training loss: 3.1718016366977606
Validation loss: 2.816206060170659

Epoch: 5| Step: 8
Training loss: 3.7237220671426585
Validation loss: 2.80684115911525

Epoch: 5| Step: 9
Training loss: 2.617045931047524
Validation loss: 2.8056693018662786

Epoch: 5| Step: 10
Training loss: 3.5115351644865784
Validation loss: 2.7987412732754455

Epoch: 259| Step: 0
Training loss: 3.4247118195189694
Validation loss: 2.7925060450861676

Epoch: 5| Step: 1
Training loss: 3.138431067448274
Validation loss: 2.7888662250178977

Epoch: 5| Step: 2
Training loss: 3.149288242399514
Validation loss: 2.790168274375561

Epoch: 5| Step: 3
Training loss: 2.4455466843857745
Validation loss: 2.7875071543094014

Epoch: 5| Step: 4
Training loss: 3.29372888663255
Validation loss: 2.786978332436128

Epoch: 5| Step: 5
Training loss: 3.2300994182202682
Validation loss: 2.790489309101214

Epoch: 5| Step: 6
Training loss: 3.25423302446439
Validation loss: 2.7900887041049116

Epoch: 5| Step: 7
Training loss: 2.7786652630761544
Validation loss: 2.787754851053569

Epoch: 5| Step: 8
Training loss: 2.413930253539115
Validation loss: 2.7918792102503316

Epoch: 5| Step: 9
Training loss: 3.2860650473603528
Validation loss: 2.788222595524152

Epoch: 5| Step: 10
Training loss: 3.524698847899461
Validation loss: 2.788492701288242

Epoch: 260| Step: 0
Training loss: 2.9230722840461523
Validation loss: 2.7912612061032003

Epoch: 5| Step: 1
Training loss: 2.9732585201630495
Validation loss: 2.7924144779757927

Epoch: 5| Step: 2
Training loss: 3.017926222590201
Validation loss: 2.79290962251309

Epoch: 5| Step: 3
Training loss: 3.388643450439143
Validation loss: 2.7887754135432594

Epoch: 5| Step: 4
Training loss: 3.0673700652393516
Validation loss: 2.7902771367959147

Epoch: 5| Step: 5
Training loss: 3.224677840117736
Validation loss: 2.7965878767597783

Epoch: 5| Step: 6
Training loss: 2.4520786264828667
Validation loss: 2.797263028644945

Epoch: 5| Step: 7
Training loss: 3.390954067592982
Validation loss: 2.794690630508898

Epoch: 5| Step: 8
Training loss: 3.6864922649758216
Validation loss: 2.7889855353727

Epoch: 5| Step: 9
Training loss: 2.9095515704634836
Validation loss: 2.7923634675319113

Epoch: 5| Step: 10
Training loss: 2.8227785271397487
Validation loss: 2.7883924777462514

Epoch: 261| Step: 0
Training loss: 3.5098740396966006
Validation loss: 2.7868547036712847

Epoch: 5| Step: 1
Training loss: 3.4194412285832407
Validation loss: 2.7897870735833825

Epoch: 5| Step: 2
Training loss: 2.888263789633118
Validation loss: 2.787455338529981

Epoch: 5| Step: 3
Training loss: 2.3035338537081333
Validation loss: 2.7860803325692443

Epoch: 5| Step: 4
Training loss: 2.803461598543714
Validation loss: 2.784713995578906

Epoch: 5| Step: 5
Training loss: 3.3830532490471787
Validation loss: 2.7816543884258027

Epoch: 5| Step: 6
Training loss: 3.233565371993214
Validation loss: 2.7802015012489636

Epoch: 5| Step: 7
Training loss: 2.4891511124272965
Validation loss: 2.788018379293026

Epoch: 5| Step: 8
Training loss: 2.9611265580102635
Validation loss: 2.7836373565504595

Epoch: 5| Step: 9
Training loss: 3.1689240958939218
Validation loss: 2.7838540656750514

Epoch: 5| Step: 10
Training loss: 3.6772432085389855
Validation loss: 2.780182756613909

Epoch: 262| Step: 0
Training loss: 2.8239997578369556
Validation loss: 2.7799696842655597

Epoch: 5| Step: 1
Training loss: 2.823623446752253
Validation loss: 2.7794245533766264

Epoch: 5| Step: 2
Training loss: 2.808390178916329
Validation loss: 2.7803456060926286

Epoch: 5| Step: 3
Training loss: 3.5224291252981974
Validation loss: 2.7857369894673916

Epoch: 5| Step: 4
Training loss: 3.113251536381887
Validation loss: 2.7828190308900305

Epoch: 5| Step: 5
Training loss: 3.1844518710245993
Validation loss: 2.787299003364391

Epoch: 5| Step: 6
Training loss: 2.6864439197837475
Validation loss: 2.7861292294608107

Epoch: 5| Step: 7
Training loss: 3.1483854000807154
Validation loss: 2.7836528085069077

Epoch: 5| Step: 8
Training loss: 2.692469770143161
Validation loss: 2.7812386494435226

Epoch: 5| Step: 9
Training loss: 3.296006363973677
Validation loss: 2.781837037331458

Epoch: 5| Step: 10
Training loss: 3.8360173048120343
Validation loss: 2.7784479434839273

Epoch: 263| Step: 0
Training loss: 3.1138877134371
Validation loss: 2.7809021010788273

Epoch: 5| Step: 1
Training loss: 3.0871903978556787
Validation loss: 2.779803393107385

Epoch: 5| Step: 2
Training loss: 3.1006429928313484
Validation loss: 2.781847563414599

Epoch: 5| Step: 3
Training loss: 2.487879746171163
Validation loss: 2.783430602631448

Epoch: 5| Step: 4
Training loss: 2.915422628397614
Validation loss: 2.778406564308792

Epoch: 5| Step: 5
Training loss: 3.2492666150635596
Validation loss: 2.7826301991045974

Epoch: 5| Step: 6
Training loss: 2.8141373001146346
Validation loss: 2.7829987108586796

Epoch: 5| Step: 7
Training loss: 3.3561857476646235
Validation loss: 2.7815338308867124

Epoch: 5| Step: 8
Training loss: 3.2933081545877574
Validation loss: 2.7802457933383447

Epoch: 5| Step: 9
Training loss: 3.2072956008779627
Validation loss: 2.7850689654777923

Epoch: 5| Step: 10
Training loss: 3.324507058682165
Validation loss: 2.787484447086928

Epoch: 264| Step: 0
Training loss: 3.5848099674950356
Validation loss: 2.787550215671418

Epoch: 5| Step: 1
Training loss: 2.8034481615036655
Validation loss: 2.784918026985759

Epoch: 5| Step: 2
Training loss: 3.2242037300220328
Validation loss: 2.7827939684778586

Epoch: 5| Step: 3
Training loss: 2.544545049867112
Validation loss: 2.782943943450473

Epoch: 5| Step: 4
Training loss: 3.0624727520411716
Validation loss: 2.782991270484018

Epoch: 5| Step: 5
Training loss: 3.169371721118938
Validation loss: 2.7833648103885906

Epoch: 5| Step: 6
Training loss: 2.5783064344893907
Validation loss: 2.7773842856581945

Epoch: 5| Step: 7
Training loss: 3.199369732061939
Validation loss: 2.781707487310439

Epoch: 5| Step: 8
Training loss: 2.9911814459960624
Validation loss: 2.783558061927281

Epoch: 5| Step: 9
Training loss: 3.3390878279229206
Validation loss: 2.781604041470902

Epoch: 5| Step: 10
Training loss: 3.3407857715256193
Validation loss: 2.786688613614806

Epoch: 265| Step: 0
Training loss: 2.6475554040977753
Validation loss: 2.7831841058230555

Epoch: 5| Step: 1
Training loss: 3.3415346025989634
Validation loss: 2.7927406704963844

Epoch: 5| Step: 2
Training loss: 3.6712896651559594
Validation loss: 2.794837692243968

Epoch: 5| Step: 3
Training loss: 2.939715098116357
Validation loss: 2.7895382931788073

Epoch: 5| Step: 4
Training loss: 3.013900659150454
Validation loss: 2.7891835032812833

Epoch: 5| Step: 5
Training loss: 3.224962184004153
Validation loss: 2.7905175463209897

Epoch: 5| Step: 6
Training loss: 2.942508891050896
Validation loss: 2.777498805964757

Epoch: 5| Step: 7
Training loss: 3.3524998063351252
Validation loss: 2.779901723162581

Epoch: 5| Step: 8
Training loss: 2.743858849662522
Validation loss: 2.781874237853345

Epoch: 5| Step: 9
Training loss: 2.9971905905117295
Validation loss: 2.778099839466743

Epoch: 5| Step: 10
Training loss: 2.946937659073786
Validation loss: 2.7777512008325336

Epoch: 266| Step: 0
Training loss: 3.0922562817542047
Validation loss: 2.7780771882363284

Epoch: 5| Step: 1
Training loss: 2.587166024736484
Validation loss: 2.7727543822806715

Epoch: 5| Step: 2
Training loss: 2.975455811787974
Validation loss: 2.778259413471099

Epoch: 5| Step: 3
Training loss: 3.202319532397297
Validation loss: 2.7765119668656406

Epoch: 5| Step: 4
Training loss: 2.744176594237129
Validation loss: 2.777474101670875

Epoch: 5| Step: 5
Training loss: 2.8659459058151455
Validation loss: 2.7790112247921748

Epoch: 5| Step: 6
Training loss: 3.3228520274477282
Validation loss: 2.7770392867438614

Epoch: 5| Step: 7
Training loss: 3.1462876621276137
Validation loss: 2.7782301824227367

Epoch: 5| Step: 8
Training loss: 3.4603819390440846
Validation loss: 2.776148240039357

Epoch: 5| Step: 9
Training loss: 3.268252543128965
Validation loss: 2.778318216978453

Epoch: 5| Step: 10
Training loss: 3.2014317945214987
Validation loss: 2.780369514960546

Epoch: 267| Step: 0
Training loss: 3.4292493814077236
Validation loss: 2.7780528074584696

Epoch: 5| Step: 1
Training loss: 3.3429695715995718
Validation loss: 2.77290833304005

Epoch: 5| Step: 2
Training loss: 2.9100215599074137
Validation loss: 2.7761213771420525

Epoch: 5| Step: 3
Training loss: 3.1986582804235084
Validation loss: 2.7771992521569606

Epoch: 5| Step: 4
Training loss: 3.316085170843856
Validation loss: 2.7721147598836917

Epoch: 5| Step: 5
Training loss: 2.992638934869128
Validation loss: 2.7720665572476086

Epoch: 5| Step: 6
Training loss: 3.107905515081472
Validation loss: 2.776011650687977

Epoch: 5| Step: 7
Training loss: 3.379346662275205
Validation loss: 2.7752387416656945

Epoch: 5| Step: 8
Training loss: 2.5661474181574815
Validation loss: 2.776909850786246

Epoch: 5| Step: 9
Training loss: 2.6330484799544664
Validation loss: 2.772425457281225

Epoch: 5| Step: 10
Training loss: 2.925838780569643
Validation loss: 2.774566401224945

Epoch: 268| Step: 0
Training loss: 3.5016095683837984
Validation loss: 2.7795618585968813

Epoch: 5| Step: 1
Training loss: 3.581053222789106
Validation loss: 2.776784399967967

Epoch: 5| Step: 2
Training loss: 2.9399528813641065
Validation loss: 2.7822972319730557

Epoch: 5| Step: 3
Training loss: 2.7389192150913972
Validation loss: 2.7804985243279847

Epoch: 5| Step: 4
Training loss: 2.536285478053305
Validation loss: 2.789214315327257

Epoch: 5| Step: 5
Training loss: 3.4286509970105965
Validation loss: 2.79284896358503

Epoch: 5| Step: 6
Training loss: 3.5748993439275836
Validation loss: 2.8051161429219444

Epoch: 5| Step: 7
Training loss: 2.97761320858198
Validation loss: 2.7910316239661848

Epoch: 5| Step: 8
Training loss: 3.031210987587227
Validation loss: 2.794761023337129

Epoch: 5| Step: 9
Training loss: 3.193527357250341
Validation loss: 2.7818047123677108

Epoch: 5| Step: 10
Training loss: 1.8402598046278826
Validation loss: 2.776165354329135

Epoch: 269| Step: 0
Training loss: 3.1442118796474596
Validation loss: 2.7843130909041074

Epoch: 5| Step: 1
Training loss: 3.583559931014801
Validation loss: 2.775453949758977

Epoch: 5| Step: 2
Training loss: 2.632962729132661
Validation loss: 2.773048496768342

Epoch: 5| Step: 3
Training loss: 2.752583070864841
Validation loss: 2.7791622368704583

Epoch: 5| Step: 4
Training loss: 3.529695286769645
Validation loss: 2.770549193055769

Epoch: 5| Step: 5
Training loss: 3.3246880635955676
Validation loss: 2.7705705900399082

Epoch: 5| Step: 6
Training loss: 2.7939162134483873
Validation loss: 2.776328937162758

Epoch: 5| Step: 7
Training loss: 2.833097017942331
Validation loss: 2.7781526030320323

Epoch: 5| Step: 8
Training loss: 3.1128741181211543
Validation loss: 2.7757837922668043

Epoch: 5| Step: 9
Training loss: 3.2544239452088792
Validation loss: 2.7752619241240932

Epoch: 5| Step: 10
Training loss: 2.7599051427435217
Validation loss: 2.779738334902879

Epoch: 270| Step: 0
Training loss: 2.585951698471689
Validation loss: 2.7766544157006434

Epoch: 5| Step: 1
Training loss: 3.286638177383267
Validation loss: 2.7741841156043905

Epoch: 5| Step: 2
Training loss: 3.234096939002333
Validation loss: 2.770639430504461

Epoch: 5| Step: 3
Training loss: 3.109147413349752
Validation loss: 2.7761080270917757

Epoch: 5| Step: 4
Training loss: 3.2321648901810898
Validation loss: 2.772135417899719

Epoch: 5| Step: 5
Training loss: 3.3701883561106882
Validation loss: 2.7661440717738595

Epoch: 5| Step: 6
Training loss: 3.085860548387869
Validation loss: 2.7742385975963946

Epoch: 5| Step: 7
Training loss: 3.0747283939651116
Validation loss: 2.77268166105129

Epoch: 5| Step: 8
Training loss: 2.5664942245849454
Validation loss: 2.765858889613414

Epoch: 5| Step: 9
Training loss: 3.361309257600665
Validation loss: 2.7743918579805578

Epoch: 5| Step: 10
Training loss: 2.860827967965302
Validation loss: 2.765873805050361

Epoch: 271| Step: 0
Training loss: 2.7131877431620497
Validation loss: 2.77009082171441

Epoch: 5| Step: 1
Training loss: 2.851477551174744
Validation loss: 2.778034680460609

Epoch: 5| Step: 2
Training loss: 3.159590964100386
Validation loss: 2.7875751920969822

Epoch: 5| Step: 3
Training loss: 2.2357572534872823
Validation loss: 2.7811855701829247

Epoch: 5| Step: 4
Training loss: 2.627419492030778
Validation loss: 2.794438384000924

Epoch: 5| Step: 5
Training loss: 3.4254595650082265
Validation loss: 2.794138454326891

Epoch: 5| Step: 6
Training loss: 3.6154421061925444
Validation loss: 2.7920265403529436

Epoch: 5| Step: 7
Training loss: 3.139683824402055
Validation loss: 2.7770495328340257

Epoch: 5| Step: 8
Training loss: 3.372326957951753
Validation loss: 2.7724519236995886

Epoch: 5| Step: 9
Training loss: 3.454614654559756
Validation loss: 2.7654614319937156

Epoch: 5| Step: 10
Training loss: 3.0840115875145195
Validation loss: 2.7702331583799475

Epoch: 272| Step: 0
Training loss: 3.2097219129234205
Validation loss: 2.769778539783548

Epoch: 5| Step: 1
Training loss: 3.03853651658124
Validation loss: 2.7696687892820937

Epoch: 5| Step: 2
Training loss: 3.1588734214470526
Validation loss: 2.7743856170278685

Epoch: 5| Step: 3
Training loss: 3.325641690624374
Validation loss: 2.786440294445225

Epoch: 5| Step: 4
Training loss: 3.0049281967648414
Validation loss: 2.7899135726039934

Epoch: 5| Step: 5
Training loss: 2.893272383556242
Validation loss: 2.7801918246511934

Epoch: 5| Step: 6
Training loss: 3.4364761214862125
Validation loss: 2.78321598737242

Epoch: 5| Step: 7
Training loss: 3.037299343435833
Validation loss: 2.783416333900449

Epoch: 5| Step: 8
Training loss: 2.8947570959778917
Validation loss: 2.77336509248417

Epoch: 5| Step: 9
Training loss: 2.8513902586037485
Validation loss: 2.770840692861182

Epoch: 5| Step: 10
Training loss: 3.006930928032274
Validation loss: 2.76851661906117

Epoch: 273| Step: 0
Training loss: 3.170585482949088
Validation loss: 2.7643156656043

Epoch: 5| Step: 1
Training loss: 2.8158845669647423
Validation loss: 2.7741813109407714

Epoch: 5| Step: 2
Training loss: 3.069050226073391
Validation loss: 2.770339104462003

Epoch: 5| Step: 3
Training loss: 3.181852536201794
Validation loss: 2.7681747926798006

Epoch: 5| Step: 4
Training loss: 3.2842255679035786
Validation loss: 2.7694945603496146

Epoch: 5| Step: 5
Training loss: 3.0660216655226997
Validation loss: 2.7784203475935407

Epoch: 5| Step: 6
Training loss: 2.3414137322424344
Validation loss: 2.7701056116380123

Epoch: 5| Step: 7
Training loss: 3.039653651936429
Validation loss: 2.7725606292137837

Epoch: 5| Step: 8
Training loss: 3.1268915173896645
Validation loss: 2.7711018566283374

Epoch: 5| Step: 9
Training loss: 3.705344520849374
Validation loss: 2.77498565636124

Epoch: 5| Step: 10
Training loss: 2.861052974451824
Validation loss: 2.7693265663434508

Epoch: 274| Step: 0
Training loss: 3.3536249675043357
Validation loss: 2.778504047885306

Epoch: 5| Step: 1
Training loss: 3.3020010054440645
Validation loss: 2.7745829533324518

Epoch: 5| Step: 2
Training loss: 2.7038932987355966
Validation loss: 2.7710402235136797

Epoch: 5| Step: 3
Training loss: 3.4106288377077205
Validation loss: 2.7725920023183823

Epoch: 5| Step: 4
Training loss: 3.21125142217347
Validation loss: 2.768944789614331

Epoch: 5| Step: 5
Training loss: 3.072868855422325
Validation loss: 2.764087327166394

Epoch: 5| Step: 6
Training loss: 2.957080109972409
Validation loss: 2.7674747077512487

Epoch: 5| Step: 7
Training loss: 2.7757608487565615
Validation loss: 2.765288065301972

Epoch: 5| Step: 8
Training loss: 2.961484511281307
Validation loss: 2.761641540390267

Epoch: 5| Step: 9
Training loss: 3.2498623745462223
Validation loss: 2.7676477957485908

Epoch: 5| Step: 10
Training loss: 2.6659714468065836
Validation loss: 2.7633083803510456

Epoch: 275| Step: 0
Training loss: 2.691497934050443
Validation loss: 2.7658460280895305

Epoch: 5| Step: 1
Training loss: 3.015662316600397
Validation loss: 2.7636388403562058

Epoch: 5| Step: 2
Training loss: 3.421716834467148
Validation loss: 2.764785269257753

Epoch: 5| Step: 3
Training loss: 2.88564684302094
Validation loss: 2.760498204171478

Epoch: 5| Step: 4
Training loss: 3.2810834569899923
Validation loss: 2.7611659872788223

Epoch: 5| Step: 5
Training loss: 3.532434180551592
Validation loss: 2.766117848992227

Epoch: 5| Step: 6
Training loss: 2.7792017391647406
Validation loss: 2.763582967570751

Epoch: 5| Step: 7
Training loss: 3.1307414907820945
Validation loss: 2.7663181160122923

Epoch: 5| Step: 8
Training loss: 3.0578972619052585
Validation loss: 2.7623008753517446

Epoch: 5| Step: 9
Training loss: 3.0299900228506065
Validation loss: 2.760086292101161

Epoch: 5| Step: 10
Training loss: 2.8595697722256337
Validation loss: 2.7691812567035377

Epoch: 276| Step: 0
Training loss: 2.8468458490313404
Validation loss: 2.767959502102255

Epoch: 5| Step: 1
Training loss: 2.681739933094949
Validation loss: 2.7657106345839324

Epoch: 5| Step: 2
Training loss: 3.2400351124497444
Validation loss: 2.771455707980063

Epoch: 5| Step: 3
Training loss: 3.2861284593210396
Validation loss: 2.7819561413885827

Epoch: 5| Step: 4
Training loss: 3.3948013672285766
Validation loss: 2.7717159573135195

Epoch: 5| Step: 5
Training loss: 2.8925171304127906
Validation loss: 2.7747982557108126

Epoch: 5| Step: 6
Training loss: 3.6915030007575576
Validation loss: 2.7707823431698997

Epoch: 5| Step: 7
Training loss: 3.4187395894172785
Validation loss: 2.767350097440273

Epoch: 5| Step: 8
Training loss: 2.9701011393887318
Validation loss: 2.766344828059791

Epoch: 5| Step: 9
Training loss: 2.8663781294401156
Validation loss: 2.7654142184145942

Epoch: 5| Step: 10
Training loss: 2.0675940750288095
Validation loss: 2.76002155493793

Epoch: 277| Step: 0
Training loss: 3.3392192055859558
Validation loss: 2.761375164869423

Epoch: 5| Step: 1
Training loss: 3.0773081978620382
Validation loss: 2.7580599202821383

Epoch: 5| Step: 2
Training loss: 3.307040051278006
Validation loss: 2.762481282028374

Epoch: 5| Step: 3
Training loss: 2.9848114812928173
Validation loss: 2.759839710222702

Epoch: 5| Step: 4
Training loss: 3.6644473005979856
Validation loss: 2.7619865292185017

Epoch: 5| Step: 5
Training loss: 3.4713247555027897
Validation loss: 2.7612288825074414

Epoch: 5| Step: 6
Training loss: 2.9241267212989173
Validation loss: 2.7586037454336223

Epoch: 5| Step: 7
Training loss: 2.78995044582208
Validation loss: 2.759537283530561

Epoch: 5| Step: 8
Training loss: 2.8575640504188344
Validation loss: 2.7593781356320815

Epoch: 5| Step: 9
Training loss: 2.7570389048944897
Validation loss: 2.7569679924701336

Epoch: 5| Step: 10
Training loss: 2.347340389590323
Validation loss: 2.7619317220031445

Epoch: 278| Step: 0
Training loss: 3.0614583326410894
Validation loss: 2.7576649976813683

Epoch: 5| Step: 1
Training loss: 3.1722584760397683
Validation loss: 2.7562679443936036

Epoch: 5| Step: 2
Training loss: 3.3673986382016032
Validation loss: 2.762132384421955

Epoch: 5| Step: 3
Training loss: 2.771577023012084
Validation loss: 2.7625201871787026

Epoch: 5| Step: 4
Training loss: 3.2269579481110306
Validation loss: 2.7636387587245625

Epoch: 5| Step: 5
Training loss: 3.3777710170706077
Validation loss: 2.770714741482886

Epoch: 5| Step: 6
Training loss: 2.322215420602981
Validation loss: 2.770402627969707

Epoch: 5| Step: 7
Training loss: 3.383652369172654
Validation loss: 2.7699142259066103

Epoch: 5| Step: 8
Training loss: 3.1814242032362645
Validation loss: 2.772328409119601

Epoch: 5| Step: 9
Training loss: 2.5951345034748177
Validation loss: 2.765596319519983

Epoch: 5| Step: 10
Training loss: 3.1248388630330806
Validation loss: 2.76321327668396

Epoch: 279| Step: 0
Training loss: 2.73586594397074
Validation loss: 2.7555393445303005

Epoch: 5| Step: 1
Training loss: 2.9860710397638903
Validation loss: 2.7587378995918934

Epoch: 5| Step: 2
Training loss: 2.9246604004998518
Validation loss: 2.7588002563795406

Epoch: 5| Step: 3
Training loss: 3.3395112167697762
Validation loss: 2.7531319986636933

Epoch: 5| Step: 4
Training loss: 3.1988641451541566
Validation loss: 2.764422415297251

Epoch: 5| Step: 5
Training loss: 3.3080515231417937
Validation loss: 2.759318399845835

Epoch: 5| Step: 6
Training loss: 3.0381662964500897
Validation loss: 2.759661522955902

Epoch: 5| Step: 7
Training loss: 3.2506361118765565
Validation loss: 2.7649837580366268

Epoch: 5| Step: 8
Training loss: 2.5387274418349404
Validation loss: 2.7513978058789834

Epoch: 5| Step: 9
Training loss: 3.446052869624757
Validation loss: 2.755577902056023

Epoch: 5| Step: 10
Training loss: 2.8068354890056004
Validation loss: 2.756207702176739

Epoch: 280| Step: 0
Training loss: 3.0727996459058953
Validation loss: 2.757638290802589

Epoch: 5| Step: 1
Training loss: 2.724322604055999
Validation loss: 2.7558853251566413

Epoch: 5| Step: 2
Training loss: 3.170116670068037
Validation loss: 2.7559295633963234

Epoch: 5| Step: 3
Training loss: 2.8017224974083588
Validation loss: 2.7496390921589935

Epoch: 5| Step: 4
Training loss: 3.0069949934080134
Validation loss: 2.7535739171901787

Epoch: 5| Step: 5
Training loss: 3.1306752360755747
Validation loss: 2.7613647919179374

Epoch: 5| Step: 6
Training loss: 2.965247889379772
Validation loss: 2.7540965876522607

Epoch: 5| Step: 7
Training loss: 3.199916218614535
Validation loss: 2.7499098739696626

Epoch: 5| Step: 8
Training loss: 3.2588243262532397
Validation loss: 2.7542698564491785

Epoch: 5| Step: 9
Training loss: 3.371020478726459
Validation loss: 2.7554530188944373

Epoch: 5| Step: 10
Training loss: 2.9662056711182423
Validation loss: 2.751428380460468

Epoch: 281| Step: 0
Training loss: 2.9785820625274786
Validation loss: 2.753531653076966

Epoch: 5| Step: 1
Training loss: 2.7947849584028104
Validation loss: 2.75480013289097

Epoch: 5| Step: 2
Training loss: 3.0231476085386064
Validation loss: 2.760092250515205

Epoch: 5| Step: 3
Training loss: 3.3054759570741714
Validation loss: 2.7563712873112287

Epoch: 5| Step: 4
Training loss: 2.685377658021071
Validation loss: 2.7571205903322733

Epoch: 5| Step: 5
Training loss: 3.1540652730376446
Validation loss: 2.7570406214024183

Epoch: 5| Step: 6
Training loss: 3.3325994796385316
Validation loss: 2.7626730499833854

Epoch: 5| Step: 7
Training loss: 3.0522391807857443
Validation loss: 2.7688189918001758

Epoch: 5| Step: 8
Training loss: 2.9438411366473876
Validation loss: 2.756727131763489

Epoch: 5| Step: 9
Training loss: 3.1769598431377233
Validation loss: 2.7740873932709413

Epoch: 5| Step: 10
Training loss: 3.282286707273994
Validation loss: 2.762764813157665

Epoch: 282| Step: 0
Training loss: 2.9117003165711455
Validation loss: 2.7547461151864305

Epoch: 5| Step: 1
Training loss: 2.8441956558635355
Validation loss: 2.7505975262418367

Epoch: 5| Step: 2
Training loss: 2.7948399817666916
Validation loss: 2.7511430203273535

Epoch: 5| Step: 3
Training loss: 3.454996697828644
Validation loss: 2.754906804625819

Epoch: 5| Step: 4
Training loss: 3.082741620447212
Validation loss: 2.7503468247240543

Epoch: 5| Step: 5
Training loss: 3.172801817236614
Validation loss: 2.753198329933258

Epoch: 5| Step: 6
Training loss: 3.4221378033892416
Validation loss: 2.7527810201933507

Epoch: 5| Step: 7
Training loss: 2.887990710024276
Validation loss: 2.7548197509805576

Epoch: 5| Step: 8
Training loss: 3.3831667108957815
Validation loss: 2.752914162739692

Epoch: 5| Step: 9
Training loss: 2.801109305393004
Validation loss: 2.7512785092111773

Epoch: 5| Step: 10
Training loss: 2.883197541613277
Validation loss: 2.754304271180345

Epoch: 283| Step: 0
Training loss: 2.349201829784011
Validation loss: 2.7557040484921695

Epoch: 5| Step: 1
Training loss: 2.962258882005588
Validation loss: 2.7519816439769538

Epoch: 5| Step: 2
Training loss: 3.4138915414147193
Validation loss: 2.7514212991589733

Epoch: 5| Step: 3
Training loss: 3.227921539128322
Validation loss: 2.760281844899165

Epoch: 5| Step: 4
Training loss: 2.9727645232725104
Validation loss: 2.7598057732435035

Epoch: 5| Step: 5
Training loss: 3.104352412117639
Validation loss: 2.75862969300716

Epoch: 5| Step: 6
Training loss: 3.2799357370733735
Validation loss: 2.7584046479308366

Epoch: 5| Step: 7
Training loss: 2.9111596752157123
Validation loss: 2.7503272726018895

Epoch: 5| Step: 8
Training loss: 3.4067957729602267
Validation loss: 2.753646705467932

Epoch: 5| Step: 9
Training loss: 2.8588709986357936
Validation loss: 2.7558316868734276

Epoch: 5| Step: 10
Training loss: 3.126096456815114
Validation loss: 2.751282544832948

Epoch: 284| Step: 0
Training loss: 3.195813426553
Validation loss: 2.7495030740036053

Epoch: 5| Step: 1
Training loss: 2.6228478101237216
Validation loss: 2.7526287685037665

Epoch: 5| Step: 2
Training loss: 3.125465663547381
Validation loss: 2.7517912168661143

Epoch: 5| Step: 3
Training loss: 3.565042893203853
Validation loss: 2.7537863339966484

Epoch: 5| Step: 4
Training loss: 3.2023259352490725
Validation loss: 2.753400447245692

Epoch: 5| Step: 5
Training loss: 2.9670794153439854
Validation loss: 2.7497561440809006

Epoch: 5| Step: 6
Training loss: 3.532339012543407
Validation loss: 2.7551643815787874

Epoch: 5| Step: 7
Training loss: 2.998987980853167
Validation loss: 2.7483389005624086

Epoch: 5| Step: 8
Training loss: 2.9740402468720304
Validation loss: 2.7537428154089496

Epoch: 5| Step: 9
Training loss: 2.500086306035888
Validation loss: 2.7490395129933773

Epoch: 5| Step: 10
Training loss: 2.803763914919851
Validation loss: 2.7474866327863463

Epoch: 285| Step: 0
Training loss: 2.54832248860911
Validation loss: 2.7519060588191615

Epoch: 5| Step: 1
Training loss: 2.455095410949985
Validation loss: 2.746958277694291

Epoch: 5| Step: 2
Training loss: 2.5809539994667245
Validation loss: 2.753089448410324

Epoch: 5| Step: 3
Training loss: 3.5045072960752455
Validation loss: 2.7579437422633872

Epoch: 5| Step: 4
Training loss: 2.9450719112819757
Validation loss: 2.7580995468115104

Epoch: 5| Step: 5
Training loss: 2.968744057097259
Validation loss: 2.7681837815108796

Epoch: 5| Step: 6
Training loss: 2.764004334850749
Validation loss: 2.767421531243258

Epoch: 5| Step: 7
Training loss: 3.049572186092416
Validation loss: 2.7824624637890905

Epoch: 5| Step: 8
Training loss: 3.634929474955853
Validation loss: 2.7833102776899636

Epoch: 5| Step: 9
Training loss: 3.59042177745722
Validation loss: 2.7581111329464054

Epoch: 5| Step: 10
Training loss: 3.3996843528084293
Validation loss: 2.765509396567832

Epoch: 286| Step: 0
Training loss: 2.8749781068714655
Validation loss: 2.7472821394332825

Epoch: 5| Step: 1
Training loss: 3.161741106855877
Validation loss: 2.7488509114534216

Epoch: 5| Step: 2
Training loss: 3.1959524842837252
Validation loss: 2.7477410669586915

Epoch: 5| Step: 3
Training loss: 3.3884008469604976
Validation loss: 2.7521238785906426

Epoch: 5| Step: 4
Training loss: 3.4205694625753797
Validation loss: 2.7461744391227514

Epoch: 5| Step: 5
Training loss: 3.3065305940512593
Validation loss: 2.742358569982421

Epoch: 5| Step: 6
Training loss: 2.5807357977901586
Validation loss: 2.74662590457417

Epoch: 5| Step: 7
Training loss: 2.981644584726098
Validation loss: 2.74425120960915

Epoch: 5| Step: 8
Training loss: 2.8015041296303993
Validation loss: 2.7463647712197274

Epoch: 5| Step: 9
Training loss: 2.9242363022428575
Validation loss: 2.7449222560173143

Epoch: 5| Step: 10
Training loss: 2.8625457360224504
Validation loss: 2.7412728363362726

Epoch: 287| Step: 0
Training loss: 2.726903156324883
Validation loss: 2.7467190326681132

Epoch: 5| Step: 1
Training loss: 3.4813898411166306
Validation loss: 2.7461275558317477

Epoch: 5| Step: 2
Training loss: 2.927344114875211
Validation loss: 2.7447271481703814

Epoch: 5| Step: 3
Training loss: 3.0117105169715614
Validation loss: 2.746324107233168

Epoch: 5| Step: 4
Training loss: 3.64276060409212
Validation loss: 2.746014871530596

Epoch: 5| Step: 5
Training loss: 2.9103974312811323
Validation loss: 2.7453441678301607

Epoch: 5| Step: 6
Training loss: 2.873764104157259
Validation loss: 2.743385942371549

Epoch: 5| Step: 7
Training loss: 3.2526699249893425
Validation loss: 2.7488318131403453

Epoch: 5| Step: 8
Training loss: 3.23148471120021
Validation loss: 2.743719532558469

Epoch: 5| Step: 9
Training loss: 2.8232742777491353
Validation loss: 2.760257006946438

Epoch: 5| Step: 10
Training loss: 2.5143572533171077
Validation loss: 2.7580423246267007

Epoch: 288| Step: 0
Training loss: 3.002081149169071
Validation loss: 2.752825876398005

Epoch: 5| Step: 1
Training loss: 2.837575896336213
Validation loss: 2.7555173144731393

Epoch: 5| Step: 2
Training loss: 3.2761715780840004
Validation loss: 2.7495248501530876

Epoch: 5| Step: 3
Training loss: 2.846450696996976
Validation loss: 2.7487890536272013

Epoch: 5| Step: 4
Training loss: 3.3491921034283036
Validation loss: 2.7480476138531573

Epoch: 5| Step: 5
Training loss: 3.3895423672542613
Validation loss: 2.7416824695191444

Epoch: 5| Step: 6
Training loss: 3.5175561644754527
Validation loss: 2.747984332972235

Epoch: 5| Step: 7
Training loss: 2.610304067445769
Validation loss: 2.7531405458822342

Epoch: 5| Step: 8
Training loss: 2.565741465964979
Validation loss: 2.7485540490934497

Epoch: 5| Step: 9
Training loss: 3.0957326989912284
Validation loss: 2.7425144934197654

Epoch: 5| Step: 10
Training loss: 2.954917565501395
Validation loss: 2.7450933657012926

Epoch: 289| Step: 0
Training loss: 3.137213376999905
Validation loss: 2.7489738861912207

Epoch: 5| Step: 1
Training loss: 2.840701135133358
Validation loss: 2.744262030262461

Epoch: 5| Step: 2
Training loss: 3.788249575529123
Validation loss: 2.7477519242507027

Epoch: 5| Step: 3
Training loss: 2.366853394552035
Validation loss: 2.7494843242790448

Epoch: 5| Step: 4
Training loss: 3.0967688425848476
Validation loss: 2.7493462209586967

Epoch: 5| Step: 5
Training loss: 2.9007065931638145
Validation loss: 2.746741463693305

Epoch: 5| Step: 6
Training loss: 2.9635864325943038
Validation loss: 2.7511383853232227

Epoch: 5| Step: 7
Training loss: 3.1664071896973067
Validation loss: 2.744632212343783

Epoch: 5| Step: 8
Training loss: 3.1643803189628694
Validation loss: 2.746858258305844

Epoch: 5| Step: 9
Training loss: 3.2010838401657056
Validation loss: 2.74592147307995

Epoch: 5| Step: 10
Training loss: 2.752223329836026
Validation loss: 2.751235180181472

Epoch: 290| Step: 0
Training loss: 2.90720064755833
Validation loss: 2.743288400498578

Epoch: 5| Step: 1
Training loss: 3.730574457558277
Validation loss: 2.7426055822280033

Epoch: 5| Step: 2
Training loss: 2.7588329642524565
Validation loss: 2.7441878281043683

Epoch: 5| Step: 3
Training loss: 2.6605876735213316
Validation loss: 2.745500053368635

Epoch: 5| Step: 4
Training loss: 3.2578157200785944
Validation loss: 2.7379779851076593

Epoch: 5| Step: 5
Training loss: 2.881795564250403
Validation loss: 2.743189811268094

Epoch: 5| Step: 6
Training loss: 3.283164637406403
Validation loss: 2.741516068475955

Epoch: 5| Step: 7
Training loss: 2.694063378181133
Validation loss: 2.7383963243121454

Epoch: 5| Step: 8
Training loss: 3.3700632794605445
Validation loss: 2.742138537561792

Epoch: 5| Step: 9
Training loss: 3.0704145341764733
Validation loss: 2.740090692401105

Epoch: 5| Step: 10
Training loss: 2.72744780325311
Validation loss: 2.7412565965257323

Epoch: 291| Step: 0
Training loss: 3.275587736782867
Validation loss: 2.746393189539291

Epoch: 5| Step: 1
Training loss: 2.919172863276253
Validation loss: 2.7477287588036705

Epoch: 5| Step: 2
Training loss: 3.4990667733850027
Validation loss: 2.7422304484593996

Epoch: 5| Step: 3
Training loss: 3.317685512941328
Validation loss: 2.754577836895729

Epoch: 5| Step: 4
Training loss: 2.3986720861967794
Validation loss: 2.748697861017084

Epoch: 5| Step: 5
Training loss: 2.7590504750317986
Validation loss: 2.7450979716885295

Epoch: 5| Step: 6
Training loss: 3.2441501789537974
Validation loss: 2.7540932412577566

Epoch: 5| Step: 7
Training loss: 3.509871186721172
Validation loss: 2.752141180468606

Epoch: 5| Step: 8
Training loss: 2.69912388327095
Validation loss: 2.7404949652642685

Epoch: 5| Step: 9
Training loss: 2.5858218809712827
Validation loss: 2.7367964965849017

Epoch: 5| Step: 10
Training loss: 3.1433806974119927
Validation loss: 2.740041105860108

Epoch: 292| Step: 0
Training loss: 3.2169169419190875
Validation loss: 2.739462544556785

Epoch: 5| Step: 1
Training loss: 2.2632513832383863
Validation loss: 2.7404288064193083

Epoch: 5| Step: 2
Training loss: 2.614533858318757
Validation loss: 2.7388433752150148

Epoch: 5| Step: 3
Training loss: 2.9938708318802596
Validation loss: 2.7340461385531603

Epoch: 5| Step: 4
Training loss: 3.619824760157664
Validation loss: 2.746613659558782

Epoch: 5| Step: 5
Training loss: 3.1260972194868786
Validation loss: 2.740807097619684

Epoch: 5| Step: 6
Training loss: 2.978280120044068
Validation loss: 2.741576091164

Epoch: 5| Step: 7
Training loss: 3.469819050229134
Validation loss: 2.741650587490386

Epoch: 5| Step: 8
Training loss: 3.8053214858961586
Validation loss: 2.7373200319995132

Epoch: 5| Step: 9
Training loss: 2.3752147175953158
Validation loss: 2.7354890499933733

Epoch: 5| Step: 10
Training loss: 2.6225004557271876
Validation loss: 2.734522432023784

Epoch: 293| Step: 0
Training loss: 2.8630824000485515
Validation loss: 2.7356944576796276

Epoch: 5| Step: 1
Training loss: 2.57428487828805
Validation loss: 2.7379242600534863

Epoch: 5| Step: 2
Training loss: 3.2947644171772383
Validation loss: 2.7349530871434204

Epoch: 5| Step: 3
Training loss: 3.047487481007824
Validation loss: 2.7343422648965188

Epoch: 5| Step: 4
Training loss: 3.689835923845051
Validation loss: 2.736952459635639

Epoch: 5| Step: 5
Training loss: 2.5130734031330864
Validation loss: 2.7400971424495606

Epoch: 5| Step: 6
Training loss: 3.0168846543376704
Validation loss: 2.7410334528145164

Epoch: 5| Step: 7
Training loss: 2.643629001887667
Validation loss: 2.741041334428859

Epoch: 5| Step: 8
Training loss: 3.424668935103578
Validation loss: 2.7354308618559697

Epoch: 5| Step: 9
Training loss: 2.951450256507499
Validation loss: 2.7364856792630805

Epoch: 5| Step: 10
Training loss: 3.3402457725875596
Validation loss: 2.7360846602848206

Epoch: 294| Step: 0
Training loss: 2.4862842061493207
Validation loss: 2.7353818019065272

Epoch: 5| Step: 1
Training loss: 2.6704557341346087
Validation loss: 2.737402218761619

Epoch: 5| Step: 2
Training loss: 2.878015181012969
Validation loss: 2.739809763744342

Epoch: 5| Step: 3
Training loss: 2.9214519663682434
Validation loss: 2.7423683249221087

Epoch: 5| Step: 4
Training loss: 3.216892780664671
Validation loss: 2.736656457418991

Epoch: 5| Step: 5
Training loss: 3.228597151874448
Validation loss: 2.7357731932816916

Epoch: 5| Step: 6
Training loss: 2.5436661989997025
Validation loss: 2.7346325337301867

Epoch: 5| Step: 7
Training loss: 3.30008342521872
Validation loss: 2.7386526617431826

Epoch: 5| Step: 8
Training loss: 3.402235692932827
Validation loss: 2.7455630357535385

Epoch: 5| Step: 9
Training loss: 3.403464482016329
Validation loss: 2.7380569321891617

Epoch: 5| Step: 10
Training loss: 3.336268388476672
Validation loss: 2.738437325084657

Epoch: 295| Step: 0
Training loss: 3.2226830313754613
Validation loss: 2.7367585465607407

Epoch: 5| Step: 1
Training loss: 3.6264460080234047
Validation loss: 2.7396700348725345

Epoch: 5| Step: 2
Training loss: 3.5830456078512167
Validation loss: 2.737078367682567

Epoch: 5| Step: 3
Training loss: 2.010152558947131
Validation loss: 2.7371826486513497

Epoch: 5| Step: 4
Training loss: 2.3428956572759634
Validation loss: 2.7398230674979613

Epoch: 5| Step: 5
Training loss: 2.773030081898414
Validation loss: 2.7352838133943678

Epoch: 5| Step: 6
Training loss: 2.9643782701339556
Validation loss: 2.7362857669023666

Epoch: 5| Step: 7
Training loss: 3.3240579460868114
Validation loss: 2.7337130775248113

Epoch: 5| Step: 8
Training loss: 2.8850694211015435
Validation loss: 2.737132288233683

Epoch: 5| Step: 9
Training loss: 3.107532971576262
Validation loss: 2.735966797640166

Epoch: 5| Step: 10
Training loss: 3.3381928942642616
Validation loss: 2.7380873739172547

Epoch: 296| Step: 0
Training loss: 2.508555174572266
Validation loss: 2.7337181706413625

Epoch: 5| Step: 1
Training loss: 3.4956417196424026
Validation loss: 2.7412606721520705

Epoch: 5| Step: 2
Training loss: 3.126711567418728
Validation loss: 2.735132567297808

Epoch: 5| Step: 3
Training loss: 3.306810206815094
Validation loss: 2.739211225432456

Epoch: 5| Step: 4
Training loss: 3.187411886755089
Validation loss: 2.7381289186102333

Epoch: 5| Step: 5
Training loss: 2.8495655330974565
Validation loss: 2.736009667592952

Epoch: 5| Step: 6
Training loss: 2.9230200823767083
Validation loss: 2.733115583755855

Epoch: 5| Step: 7
Training loss: 3.1587694140472813
Validation loss: 2.7334394091345366

Epoch: 5| Step: 8
Training loss: 2.725455335319322
Validation loss: 2.7397583250125397

Epoch: 5| Step: 9
Training loss: 2.688811492287689
Validation loss: 2.741528185706389

Epoch: 5| Step: 10
Training loss: 3.436761811496747
Validation loss: 2.735229894831562

Epoch: 297| Step: 0
Training loss: 3.2470974799145442
Validation loss: 2.736315879809896

Epoch: 5| Step: 1
Training loss: 2.3638798231505636
Validation loss: 2.731683487542078

Epoch: 5| Step: 2
Training loss: 3.3128607211648538
Validation loss: 2.7321357767556

Epoch: 5| Step: 3
Training loss: 3.178998342901796
Validation loss: 2.726576863166514

Epoch: 5| Step: 4
Training loss: 2.7073525242254077
Validation loss: 2.728587614162339

Epoch: 5| Step: 5
Training loss: 3.534513737580464
Validation loss: 2.7243050125810764

Epoch: 5| Step: 6
Training loss: 2.8999695546097675
Validation loss: 2.733051694495949

Epoch: 5| Step: 7
Training loss: 3.406286956866601
Validation loss: 2.731157764035561

Epoch: 5| Step: 8
Training loss: 2.9098801449872327
Validation loss: 2.732180495245279

Epoch: 5| Step: 9
Training loss: 2.891008011470687
Validation loss: 2.730682975398384

Epoch: 5| Step: 10
Training loss: 2.815659930724856
Validation loss: 2.7320238375124

Epoch: 298| Step: 0
Training loss: 2.6461924712171943
Validation loss: 2.728522099592448

Epoch: 5| Step: 1
Training loss: 3.160076880666613
Validation loss: 2.736723084034295

Epoch: 5| Step: 2
Training loss: 3.0716399218312045
Validation loss: 2.7273322745099757

Epoch: 5| Step: 3
Training loss: 3.5731178130684262
Validation loss: 2.7380549893675417

Epoch: 5| Step: 4
Training loss: 3.3284389007539623
Validation loss: 2.7294526716259253

Epoch: 5| Step: 5
Training loss: 3.019744273341601
Validation loss: 2.7352252094299665

Epoch: 5| Step: 6
Training loss: 3.049805312900192
Validation loss: 2.730572248761192

Epoch: 5| Step: 7
Training loss: 2.5933832116057913
Validation loss: 2.7307448105803456

Epoch: 5| Step: 8
Training loss: 3.448545431255135
Validation loss: 2.7360128543275706

Epoch: 5| Step: 9
Training loss: 2.782835947545185
Validation loss: 2.732662872246594

Epoch: 5| Step: 10
Training loss: 2.5456664605607844
Validation loss: 2.732985923917937

Epoch: 299| Step: 0
Training loss: 2.6610081858718697
Validation loss: 2.7264209883009047

Epoch: 5| Step: 1
Training loss: 3.210164889084719
Validation loss: 2.728441675814967

Epoch: 5| Step: 2
Training loss: 2.8596064572902637
Validation loss: 2.729692047983333

Epoch: 5| Step: 3
Training loss: 3.322675801858034
Validation loss: 2.727492515890791

Epoch: 5| Step: 4
Training loss: 3.1803941995780134
Validation loss: 2.727484295287194

Epoch: 5| Step: 5
Training loss: 3.443295396544742
Validation loss: 2.7252455708809524

Epoch: 5| Step: 6
Training loss: 2.9624604105819095
Validation loss: 2.7292146344272084

Epoch: 5| Step: 7
Training loss: 2.9247034427906504
Validation loss: 2.7225147716133873

Epoch: 5| Step: 8
Training loss: 3.069224235111457
Validation loss: 2.7261749169808533

Epoch: 5| Step: 9
Training loss: 2.841726568342069
Validation loss: 2.7282260472128472

Epoch: 5| Step: 10
Training loss: 2.8685784980521807
Validation loss: 2.7242454572458374

Epoch: 300| Step: 0
Training loss: 3.1180146537274926
Validation loss: 2.727088558495626

Epoch: 5| Step: 1
Training loss: 3.3553348820975395
Validation loss: 2.72640522326559

Epoch: 5| Step: 2
Training loss: 2.779032905787367
Validation loss: 2.7320417996718263

Epoch: 5| Step: 3
Training loss: 3.10419849831733
Validation loss: 2.7328338817897246

Epoch: 5| Step: 4
Training loss: 2.913311654482331
Validation loss: 2.729732142668116

Epoch: 5| Step: 5
Training loss: 2.885976321667181
Validation loss: 2.722106938442473

Epoch: 5| Step: 6
Training loss: 3.0933817634682765
Validation loss: 2.7270348774328745

Epoch: 5| Step: 7
Training loss: 3.2942953277199956
Validation loss: 2.7256746499926714

Epoch: 5| Step: 8
Training loss: 3.085167742949519
Validation loss: 2.7245423806414526

Epoch: 5| Step: 9
Training loss: 3.0812287923767814
Validation loss: 2.7230320675208857

Epoch: 5| Step: 10
Training loss: 2.585290741498645
Validation loss: 2.735364731420717

Epoch: 301| Step: 0
Training loss: 3.3052236424205876
Validation loss: 2.7334121438626733

Epoch: 5| Step: 1
Training loss: 3.21311917405193
Validation loss: 2.7376828953541086

Epoch: 5| Step: 2
Training loss: 2.5640621540968973
Validation loss: 2.7325292139287676

Epoch: 5| Step: 3
Training loss: 3.4101207333667376
Validation loss: 2.745599595146217

Epoch: 5| Step: 4
Training loss: 2.772338047508692
Validation loss: 2.7471749887301415

Epoch: 5| Step: 5
Training loss: 3.10243700896445
Validation loss: 2.7420543115589635

Epoch: 5| Step: 6
Training loss: 3.055314645999585
Validation loss: 2.73806310145793

Epoch: 5| Step: 7
Training loss: 2.549509008672598
Validation loss: 2.738403313847001

Epoch: 5| Step: 8
Training loss: 3.15886828908675
Validation loss: 2.721661239674476

Epoch: 5| Step: 9
Training loss: 3.3512213117601632
Validation loss: 2.7221611338869485

Epoch: 5| Step: 10
Training loss: 2.752591819097902
Validation loss: 2.7230904688214372

Epoch: 302| Step: 0
Training loss: 3.360043765191743
Validation loss: 2.724793335671062

Epoch: 5| Step: 1
Training loss: 3.3283430574288118
Validation loss: 2.725137943179397

Epoch: 5| Step: 2
Training loss: 3.089995909752963
Validation loss: 2.7214084348798693

Epoch: 5| Step: 3
Training loss: 2.8610074745675256
Validation loss: 2.724529564959882

Epoch: 5| Step: 4
Training loss: 3.1355458652242363
Validation loss: 2.721483462540129

Epoch: 5| Step: 5
Training loss: 2.7822358173766744
Validation loss: 2.722415972496147

Epoch: 5| Step: 6
Training loss: 2.965919510555002
Validation loss: 2.725634697372794

Epoch: 5| Step: 7
Training loss: 2.730176743595464
Validation loss: 2.717763918773163

Epoch: 5| Step: 8
Training loss: 3.173943357283129
Validation loss: 2.715558009583599

Epoch: 5| Step: 9
Training loss: 3.2698045477360735
Validation loss: 2.724357277580063

Epoch: 5| Step: 10
Training loss: 2.5290707284578335
Validation loss: 2.722452541394068

Epoch: 303| Step: 0
Training loss: 2.960203376690877
Validation loss: 2.7215291812414244

Epoch: 5| Step: 1
Training loss: 2.5795504241883265
Validation loss: 2.717144696932478

Epoch: 5| Step: 2
Training loss: 2.9868901224785227
Validation loss: 2.722147100585576

Epoch: 5| Step: 3
Training loss: 3.354563403310639
Validation loss: 2.7202948684942303

Epoch: 5| Step: 4
Training loss: 2.3991289664200774
Validation loss: 2.719956496760645

Epoch: 5| Step: 5
Training loss: 3.3710764932024992
Validation loss: 2.730261724744791

Epoch: 5| Step: 6
Training loss: 3.2647036480150526
Validation loss: 2.7228584435159386

Epoch: 5| Step: 7
Training loss: 3.048948081550701
Validation loss: 2.728190377928357

Epoch: 5| Step: 8
Training loss: 2.6308859276511294
Validation loss: 2.7291791931731573

Epoch: 5| Step: 9
Training loss: 3.395862665030212
Validation loss: 2.733767151665047

Epoch: 5| Step: 10
Training loss: 3.2865237044630544
Validation loss: 2.7363833785137373

Epoch: 304| Step: 0
Training loss: 3.7366934885315235
Validation loss: 2.7280671015757756

Epoch: 5| Step: 1
Training loss: 2.987328949823833
Validation loss: 2.728680407100629

Epoch: 5| Step: 2
Training loss: 2.9568733767817656
Validation loss: 2.7198276800182937

Epoch: 5| Step: 3
Training loss: 2.9305921454854738
Validation loss: 2.715377245981847

Epoch: 5| Step: 4
Training loss: 2.856850765829005
Validation loss: 2.7217530226102467

Epoch: 5| Step: 5
Training loss: 2.8582271085376494
Validation loss: 2.724960073935155

Epoch: 5| Step: 6
Training loss: 3.2339571623032213
Validation loss: 2.722721151515063

Epoch: 5| Step: 7
Training loss: 2.9700266452197748
Validation loss: 2.7231894872929714

Epoch: 5| Step: 8
Training loss: 2.5170714206557845
Validation loss: 2.7253638774280873

Epoch: 5| Step: 9
Training loss: 3.2288703700485017
Validation loss: 2.7197713775662864

Epoch: 5| Step: 10
Training loss: 3.047829502934027
Validation loss: 2.7232158720922475

Epoch: 305| Step: 0
Training loss: 3.2715820297924876
Validation loss: 2.7239086416620837

Epoch: 5| Step: 1
Training loss: 3.195053127366482
Validation loss: 2.727800761243812

Epoch: 5| Step: 2
Training loss: 2.515339331666838
Validation loss: 2.72569029698238

Epoch: 5| Step: 3
Training loss: 3.1293984548681326
Validation loss: 2.736988114016419

Epoch: 5| Step: 4
Training loss: 2.752626032217633
Validation loss: 2.7308774869845327

Epoch: 5| Step: 5
Training loss: 2.827865167136407
Validation loss: 2.7344351006859893

Epoch: 5| Step: 6
Training loss: 2.832609383338815
Validation loss: 2.73056979456514

Epoch: 5| Step: 7
Training loss: 3.2934995610323843
Validation loss: 2.730258225192098

Epoch: 5| Step: 8
Training loss: 3.0964648732552598
Validation loss: 2.723342191178422

Epoch: 5| Step: 9
Training loss: 2.853958419293739
Validation loss: 2.7210952229728553

Epoch: 5| Step: 10
Training loss: 3.574408987850545
Validation loss: 2.7213258310334267

Epoch: 306| Step: 0
Training loss: 3.5287853180553292
Validation loss: 2.7206918695453153

Epoch: 5| Step: 1
Training loss: 3.1404728639107775
Validation loss: 2.719200312919309

Epoch: 5| Step: 2
Training loss: 3.4382208328468904
Validation loss: 2.7213131141932

Epoch: 5| Step: 3
Training loss: 2.8539261728213208
Validation loss: 2.728859903366226

Epoch: 5| Step: 4
Training loss: 2.91259925247494
Validation loss: 2.7235754497629476

Epoch: 5| Step: 5
Training loss: 3.1043799068933624
Validation loss: 2.7178976655724103

Epoch: 5| Step: 6
Training loss: 2.507319416758425
Validation loss: 2.713656680347464

Epoch: 5| Step: 7
Training loss: 2.8597955446589145
Validation loss: 2.7116735455120273

Epoch: 5| Step: 8
Training loss: 3.203406493680957
Validation loss: 2.7150477584943844

Epoch: 5| Step: 9
Training loss: 2.7554021141013676
Validation loss: 2.710825294441426

Epoch: 5| Step: 10
Training loss: 2.938983299246859
Validation loss: 2.717676207385795

Epoch: 307| Step: 0
Training loss: 3.081973850117028
Validation loss: 2.7134467690887063

Epoch: 5| Step: 1
Training loss: 2.4939841368475886
Validation loss: 2.715363072822771

Epoch: 5| Step: 2
Training loss: 3.3131658496651952
Validation loss: 2.713511749159969

Epoch: 5| Step: 3
Training loss: 2.348219005905289
Validation loss: 2.711601989867955

Epoch: 5| Step: 4
Training loss: 3.564609906654737
Validation loss: 2.71323316984487

Epoch: 5| Step: 5
Training loss: 3.1173338891554514
Validation loss: 2.7157101381656874

Epoch: 5| Step: 6
Training loss: 2.750867533393656
Validation loss: 2.7166915208696376

Epoch: 5| Step: 7
Training loss: 3.073561640580398
Validation loss: 2.7191104614599197

Epoch: 5| Step: 8
Training loss: 3.370827815770811
Validation loss: 2.72162241829687

Epoch: 5| Step: 9
Training loss: 3.10669857600883
Validation loss: 2.719245454374247

Epoch: 5| Step: 10
Training loss: 2.90344463843081
Validation loss: 2.714980343120693

Epoch: 308| Step: 0
Training loss: 2.7480378520196576
Validation loss: 2.714400574135721

Epoch: 5| Step: 1
Training loss: 3.714078645907795
Validation loss: 2.7126813273439763

Epoch: 5| Step: 2
Training loss: 3.0484575905423794
Validation loss: 2.71234236118762

Epoch: 5| Step: 3
Training loss: 2.9998458186902015
Validation loss: 2.713422162835064

Epoch: 5| Step: 4
Training loss: 2.279499165924114
Validation loss: 2.711750549401662

Epoch: 5| Step: 5
Training loss: 3.2092004240075434
Validation loss: 2.7212582188526233

Epoch: 5| Step: 6
Training loss: 3.242522073051481
Validation loss: 2.713364260163354

Epoch: 5| Step: 7
Training loss: 3.2722164234598616
Validation loss: 2.7124479797026564

Epoch: 5| Step: 8
Training loss: 2.7842463950652494
Validation loss: 2.7097520739222607

Epoch: 5| Step: 9
Training loss: 3.0480629194678963
Validation loss: 2.718582338626148

Epoch: 5| Step: 10
Training loss: 2.7161410737963654
Validation loss: 2.7101603672501433

Epoch: 309| Step: 0
Training loss: 2.9913622163733193
Validation loss: 2.7103731180761117

Epoch: 5| Step: 1
Training loss: 3.1475318382295128
Validation loss: 2.7245415432015463

Epoch: 5| Step: 2
Training loss: 3.4874005375286723
Validation loss: 2.730379231805652

Epoch: 5| Step: 3
Training loss: 3.182368617316274
Validation loss: 2.725762948589931

Epoch: 5| Step: 4
Training loss: 3.031887184107575
Validation loss: 2.7232639763638056

Epoch: 5| Step: 5
Training loss: 2.7821829441945476
Validation loss: 2.731892115780558

Epoch: 5| Step: 6
Training loss: 2.9236430158608444
Validation loss: 2.74397090590951

Epoch: 5| Step: 7
Training loss: 2.7485245301052585
Validation loss: 2.727265704240081

Epoch: 5| Step: 8
Training loss: 2.885257831337764
Validation loss: 2.7153978305415047

Epoch: 5| Step: 9
Training loss: 2.9634448383694596
Validation loss: 2.71487925186015

Epoch: 5| Step: 10
Training loss: 3.149972092035583
Validation loss: 2.7169281472143543

Epoch: 310| Step: 0
Training loss: 3.1030096334196604
Validation loss: 2.7068231567146337

Epoch: 5| Step: 1
Training loss: 3.1712680480226942
Validation loss: 2.7068569207299973

Epoch: 5| Step: 2
Training loss: 2.892984612833738
Validation loss: 2.71058396346343

Epoch: 5| Step: 3
Training loss: 3.5520308743329294
Validation loss: 2.705610979729061

Epoch: 5| Step: 4
Training loss: 2.7899712116027766
Validation loss: 2.71123564632942

Epoch: 5| Step: 5
Training loss: 3.079030015224886
Validation loss: 2.7076083731474605

Epoch: 5| Step: 6
Training loss: 2.921638519998757
Validation loss: 2.7123744034065798

Epoch: 5| Step: 7
Training loss: 3.404716216373706
Validation loss: 2.706720705685056

Epoch: 5| Step: 8
Training loss: 2.702249638820246
Validation loss: 2.704236291222623

Epoch: 5| Step: 9
Training loss: 2.8191104768375492
Validation loss: 2.705337343656317

Epoch: 5| Step: 10
Training loss: 2.6943900921070845
Validation loss: 2.702822170665792

Epoch: 311| Step: 0
Training loss: 3.1261196419536
Validation loss: 2.7148477538504165

Epoch: 5| Step: 1
Training loss: 3.2431542115835787
Validation loss: 2.70383201759593

Epoch: 5| Step: 2
Training loss: 3.0584543715249692
Validation loss: 2.7068756991175795

Epoch: 5| Step: 3
Training loss: 2.443911702691605
Validation loss: 2.711179110604852

Epoch: 5| Step: 4
Training loss: 3.188312800876876
Validation loss: 2.7174777556190635

Epoch: 5| Step: 5
Training loss: 2.756892669558843
Validation loss: 2.718834821589339

Epoch: 5| Step: 6
Training loss: 3.5677213719633247
Validation loss: 2.7273118975248076

Epoch: 5| Step: 7
Training loss: 3.3104110464852994
Validation loss: 2.725786994815613

Epoch: 5| Step: 8
Training loss: 2.628827438193421
Validation loss: 2.7123438687427632

Epoch: 5| Step: 9
Training loss: 2.629626873947196
Validation loss: 2.707850837482281

Epoch: 5| Step: 10
Training loss: 3.20782691294558
Validation loss: 2.7051857291599903

Epoch: 312| Step: 0
Training loss: 3.1967018296817464
Validation loss: 2.707418676997306

Epoch: 5| Step: 1
Training loss: 3.3187198903357684
Validation loss: 2.709813101979349

Epoch: 5| Step: 2
Training loss: 2.4019139843610224
Validation loss: 2.699935420702301

Epoch: 5| Step: 3
Training loss: 3.2245351411995893
Validation loss: 2.7052846230692964

Epoch: 5| Step: 4
Training loss: 2.5987204300747213
Validation loss: 2.705232391395122

Epoch: 5| Step: 5
Training loss: 3.143867602717705
Validation loss: 2.7045067494366717

Epoch: 5| Step: 6
Training loss: 2.6645361515627104
Validation loss: 2.7070293919259

Epoch: 5| Step: 7
Training loss: 3.12150928084952
Validation loss: 2.7090167266430214

Epoch: 5| Step: 8
Training loss: 3.2286303823468225
Validation loss: 2.7117617067791513

Epoch: 5| Step: 9
Training loss: 2.793294052706674
Validation loss: 2.713191028512691

Epoch: 5| Step: 10
Training loss: 3.5026921408948746
Validation loss: 2.718619412671289

Epoch: 313| Step: 0
Training loss: 2.5657382136281135
Validation loss: 2.7161844624185045

Epoch: 5| Step: 1
Training loss: 3.093157933156774
Validation loss: 2.7251594765856044

Epoch: 5| Step: 2
Training loss: 3.265735679101546
Validation loss: 2.7281254289202437

Epoch: 5| Step: 3
Training loss: 3.475776909353676
Validation loss: 2.7276000206074005

Epoch: 5| Step: 4
Training loss: 2.7620189023431094
Validation loss: 2.728843411186728

Epoch: 5| Step: 5
Training loss: 3.362254767001617
Validation loss: 2.711348356834543

Epoch: 5| Step: 6
Training loss: 3.0657767068731947
Validation loss: 2.7217711213100997

Epoch: 5| Step: 7
Training loss: 2.9275144935985358
Validation loss: 2.706760306222446

Epoch: 5| Step: 8
Training loss: 2.6668901846511277
Validation loss: 2.7107572784951506

Epoch: 5| Step: 9
Training loss: 3.528340989724563
Validation loss: 2.709092686093396

Epoch: 5| Step: 10
Training loss: 2.17350236040386
Validation loss: 2.71093605502241

Epoch: 314| Step: 0
Training loss: 3.182789931594171
Validation loss: 2.704211129047803

Epoch: 5| Step: 1
Training loss: 3.2887873228674596
Validation loss: 2.7109144672681236

Epoch: 5| Step: 2
Training loss: 3.0174238937122677
Validation loss: 2.7094023047132976

Epoch: 5| Step: 3
Training loss: 2.902558966932206
Validation loss: 2.7015880905601226

Epoch: 5| Step: 4
Training loss: 3.1474485145581705
Validation loss: 2.7053269614757864

Epoch: 5| Step: 5
Training loss: 3.070639401182152
Validation loss: 2.699819071703549

Epoch: 5| Step: 6
Training loss: 3.2683482519493707
Validation loss: 2.7043427742492727

Epoch: 5| Step: 7
Training loss: 2.998025562322454
Validation loss: 2.70545768913558

Epoch: 5| Step: 8
Training loss: 2.6174485716918414
Validation loss: 2.7071887725440607

Epoch: 5| Step: 9
Training loss: 2.45039098694925
Validation loss: 2.710826439689761

Epoch: 5| Step: 10
Training loss: 3.2364533606766157
Validation loss: 2.712353518021011

Epoch: 315| Step: 0
Training loss: 3.52264557796849
Validation loss: 2.7160258664206967

Epoch: 5| Step: 1
Training loss: 2.4549769317724084
Validation loss: 2.7148925266943507

Epoch: 5| Step: 2
Training loss: 2.861659070558266
Validation loss: 2.7112897253014183

Epoch: 5| Step: 3
Training loss: 3.007870681001823
Validation loss: 2.726442187174329

Epoch: 5| Step: 4
Training loss: 2.799760746952021
Validation loss: 2.7199179470098827

Epoch: 5| Step: 5
Training loss: 3.530014632197412
Validation loss: 2.723084473691373

Epoch: 5| Step: 6
Training loss: 3.36951934012792
Validation loss: 2.7140104107713863

Epoch: 5| Step: 7
Training loss: 3.1269551074029476
Validation loss: 2.71592145274245

Epoch: 5| Step: 8
Training loss: 2.7795590178552128
Validation loss: 2.725290815390816

Epoch: 5| Step: 9
Training loss: 2.9818096219445325
Validation loss: 2.7164188886785263

Epoch: 5| Step: 10
Training loss: 2.581105584268085
Validation loss: 2.7141598396958826

Epoch: 316| Step: 0
Training loss: 2.961759025523271
Validation loss: 2.7177095941356324

Epoch: 5| Step: 1
Training loss: 2.588142215806918
Validation loss: 2.723672650003883

Epoch: 5| Step: 2
Training loss: 2.8748080977372936
Validation loss: 2.7259784936539337

Epoch: 5| Step: 3
Training loss: 3.074438375652307
Validation loss: 2.7241967557913735

Epoch: 5| Step: 4
Training loss: 3.316941504536829
Validation loss: 2.7137833848730533

Epoch: 5| Step: 5
Training loss: 2.9476933658708835
Validation loss: 2.7075052322132467

Epoch: 5| Step: 6
Training loss: 3.191796044366019
Validation loss: 2.706487101775484

Epoch: 5| Step: 7
Training loss: 2.8741460444137386
Validation loss: 2.7053287809188467

Epoch: 5| Step: 8
Training loss: 3.2018459836861406
Validation loss: 2.70195568428142

Epoch: 5| Step: 9
Training loss: 3.017087275511227
Validation loss: 2.7046306807050398

Epoch: 5| Step: 10
Training loss: 3.2518303925319403
Validation loss: 2.7029530697375184

Epoch: 317| Step: 0
Training loss: 2.816602215979442
Validation loss: 2.705655974590296

Epoch: 5| Step: 1
Training loss: 2.9761512452219283
Validation loss: 2.7131521558604605

Epoch: 5| Step: 2
Training loss: 2.803616630113447
Validation loss: 2.7064788912539117

Epoch: 5| Step: 3
Training loss: 3.47709668802417
Validation loss: 2.70990694364167

Epoch: 5| Step: 4
Training loss: 2.69804363369281
Validation loss: 2.7117145802074556

Epoch: 5| Step: 5
Training loss: 2.6209630350870508
Validation loss: 2.7123767880561593

Epoch: 5| Step: 6
Training loss: 3.0142339947343517
Validation loss: 2.714106385592925

Epoch: 5| Step: 7
Training loss: 3.242785442320654
Validation loss: 2.708566108683557

Epoch: 5| Step: 8
Training loss: 3.581066671475721
Validation loss: 2.7104842423604514

Epoch: 5| Step: 9
Training loss: 2.68730677420153
Validation loss: 2.711023168394389

Epoch: 5| Step: 10
Training loss: 3.1976576875244906
Validation loss: 2.6993053943500636

Epoch: 318| Step: 0
Training loss: 3.0833769786598095
Validation loss: 2.712388715053247

Epoch: 5| Step: 1
Training loss: 2.7381356672694372
Validation loss: 2.702777831482316

Epoch: 5| Step: 2
Training loss: 2.859180548054297
Validation loss: 2.704723866654591

Epoch: 5| Step: 3
Training loss: 3.086423734191399
Validation loss: 2.698816762584755

Epoch: 5| Step: 4
Training loss: 2.684324562034107
Validation loss: 2.7011982062748743

Epoch: 5| Step: 5
Training loss: 3.4871835380454432
Validation loss: 2.6952091938544225

Epoch: 5| Step: 6
Training loss: 3.38035215631206
Validation loss: 2.7063105833342136

Epoch: 5| Step: 7
Training loss: 3.283764121232529
Validation loss: 2.6968055369469264

Epoch: 5| Step: 8
Training loss: 3.0619151277048124
Validation loss: 2.69866667503593

Epoch: 5| Step: 9
Training loss: 2.581308237670385
Validation loss: 2.7022118373624795

Epoch: 5| Step: 10
Training loss: 2.809317504837618
Validation loss: 2.703341454360868

Epoch: 319| Step: 0
Training loss: 3.281513312537575
Validation loss: 2.6988423312669503

Epoch: 5| Step: 1
Training loss: 3.086214849828864
Validation loss: 2.709216504100386

Epoch: 5| Step: 2
Training loss: 3.114659252113287
Validation loss: 2.710828250713184

Epoch: 5| Step: 3
Training loss: 3.6273335805270164
Validation loss: 2.722240607474632

Epoch: 5| Step: 4
Training loss: 2.215855389279989
Validation loss: 2.711480766450894

Epoch: 5| Step: 5
Training loss: 2.691627880875974
Validation loss: 2.715131444671589

Epoch: 5| Step: 6
Training loss: 2.4839025084119477
Validation loss: 2.7179117123255945

Epoch: 5| Step: 7
Training loss: 3.244920135126535
Validation loss: 2.726770540388957

Epoch: 5| Step: 8
Training loss: 2.833240582313056
Validation loss: 2.7341696966537485

Epoch: 5| Step: 9
Training loss: 3.369269981665255
Validation loss: 2.7259778729582766

Epoch: 5| Step: 10
Training loss: 3.0144497651776825
Validation loss: 2.7171380895562796

Epoch: 320| Step: 0
Training loss: 2.5128077494094017
Validation loss: 2.7010981737788056

Epoch: 5| Step: 1
Training loss: 3.082302299155439
Validation loss: 2.6979400767415616

Epoch: 5| Step: 2
Training loss: 3.2519586969734546
Validation loss: 2.69337466527528

Epoch: 5| Step: 3
Training loss: 2.6710976702429003
Validation loss: 2.6928081380103546

Epoch: 5| Step: 4
Training loss: 3.1806361777254804
Validation loss: 2.69633414161093

Epoch: 5| Step: 5
Training loss: 2.9072954491964618
Validation loss: 2.695478959997257

Epoch: 5| Step: 6
Training loss: 2.527541941399479
Validation loss: 2.690985401521329

Epoch: 5| Step: 7
Training loss: 3.36032900016946
Validation loss: 2.696229571980577

Epoch: 5| Step: 8
Training loss: 3.0971665446281014
Validation loss: 2.6923613997277904

Epoch: 5| Step: 9
Training loss: 3.235486268135964
Validation loss: 2.6933913061055925

Epoch: 5| Step: 10
Training loss: 3.295691110377235
Validation loss: 2.6946333362566213

Epoch: 321| Step: 0
Training loss: 3.2872413794610247
Validation loss: 2.701711611045734

Epoch: 5| Step: 1
Training loss: 3.511736945082869
Validation loss: 2.6982018149072946

Epoch: 5| Step: 2
Training loss: 2.9705254315384177
Validation loss: 2.7022184745948428

Epoch: 5| Step: 3
Training loss: 3.050344516495067
Validation loss: 2.697781198831528

Epoch: 5| Step: 4
Training loss: 2.651809661081877
Validation loss: 2.6950038938330403

Epoch: 5| Step: 5
Training loss: 2.45976699361389
Validation loss: 2.690311734352824

Epoch: 5| Step: 6
Training loss: 2.9051276880457593
Validation loss: 2.6918270079200672

Epoch: 5| Step: 7
Training loss: 2.402359331282042
Validation loss: 2.695742369321342

Epoch: 5| Step: 8
Training loss: 3.0116348353865656
Validation loss: 2.694478666169058

Epoch: 5| Step: 9
Training loss: 3.244030679014414
Validation loss: 2.6991684382431704

Epoch: 5| Step: 10
Training loss: 3.597216451894746
Validation loss: 2.692585798797322

Epoch: 322| Step: 0
Training loss: 3.449152530021542
Validation loss: 2.6964664147674853

Epoch: 5| Step: 1
Training loss: 3.191473933311127
Validation loss: 2.701084819761074

Epoch: 5| Step: 2
Training loss: 2.696182508618713
Validation loss: 2.6976166067067466

Epoch: 5| Step: 3
Training loss: 3.0612508600747024
Validation loss: 2.7071424934703576

Epoch: 5| Step: 4
Training loss: 2.8070857173605113
Validation loss: 2.7110348772319126

Epoch: 5| Step: 5
Training loss: 2.898558909708712
Validation loss: 2.708295732588967

Epoch: 5| Step: 6
Training loss: 3.236244582742258
Validation loss: 2.7128731030336755

Epoch: 5| Step: 7
Training loss: 2.822147353706953
Validation loss: 2.7038396511476765

Epoch: 5| Step: 8
Training loss: 2.9760599187643524
Validation loss: 2.6985823699676774

Epoch: 5| Step: 9
Training loss: 3.1871645881853383
Validation loss: 2.7025900994428995

Epoch: 5| Step: 10
Training loss: 2.7332947259207776
Validation loss: 2.6849948112917503

Epoch: 323| Step: 0
Training loss: 3.293999597694173
Validation loss: 2.692996230197731

Epoch: 5| Step: 1
Training loss: 2.572327910692366
Validation loss: 2.6918033697591577

Epoch: 5| Step: 2
Training loss: 3.068129678405191
Validation loss: 2.693843074454772

Epoch: 5| Step: 3
Training loss: 2.7976464427700467
Validation loss: 2.694343693104806

Epoch: 5| Step: 4
Training loss: 2.961144593578157
Validation loss: 2.6930969739147566

Epoch: 5| Step: 5
Training loss: 2.739130038240982
Validation loss: 2.6917869181623724

Epoch: 5| Step: 6
Training loss: 3.647703697368242
Validation loss: 2.689703145856712

Epoch: 5| Step: 7
Training loss: 3.2496035407410964
Validation loss: 2.6854095379717213

Epoch: 5| Step: 8
Training loss: 3.132763184423255
Validation loss: 2.688539346478913

Epoch: 5| Step: 9
Training loss: 2.6776358977948567
Validation loss: 2.69480923208602

Epoch: 5| Step: 10
Training loss: 2.8285908183689683
Validation loss: 2.6873347428821996

Epoch: 324| Step: 0
Training loss: 3.712139376712064
Validation loss: 2.6914607226375025

Epoch: 5| Step: 1
Training loss: 2.709352761147647
Validation loss: 2.693534907164262

Epoch: 5| Step: 2
Training loss: 3.230013205203058
Validation loss: 2.6877707120632066

Epoch: 5| Step: 3
Training loss: 3.1773848760535337
Validation loss: 2.690553417256188

Epoch: 5| Step: 4
Training loss: 2.9801807589401403
Validation loss: 2.698158477261053

Epoch: 5| Step: 5
Training loss: 2.5290457464615606
Validation loss: 2.6905648340437995

Epoch: 5| Step: 6
Training loss: 2.6675749860983324
Validation loss: 2.700927580965331

Epoch: 5| Step: 7
Training loss: 3.1575719501093222
Validation loss: 2.69455419059025

Epoch: 5| Step: 8
Training loss: 3.0331243638659537
Validation loss: 2.6959438911886697

Epoch: 5| Step: 9
Training loss: 2.760361744076381
Validation loss: 2.6957981731982876

Epoch: 5| Step: 10
Training loss: 2.978876130846949
Validation loss: 2.701470523076708

Epoch: 325| Step: 0
Training loss: 2.940098201902211
Validation loss: 2.6926539405214287

Epoch: 5| Step: 1
Training loss: 2.4516864616412657
Validation loss: 2.6848575672902224

Epoch: 5| Step: 2
Training loss: 2.9813834170511804
Validation loss: 2.6814733279386194

Epoch: 5| Step: 3
Training loss: 3.1519669280374587
Validation loss: 2.6857609274420677

Epoch: 5| Step: 4
Training loss: 3.5009182679072777
Validation loss: 2.6798224401877984

Epoch: 5| Step: 5
Training loss: 2.9875994933092813
Validation loss: 2.69061494270644

Epoch: 5| Step: 6
Training loss: 2.968343285257091
Validation loss: 2.6867105097536785

Epoch: 5| Step: 7
Training loss: 2.5485895856409675
Validation loss: 2.688683533726113

Epoch: 5| Step: 8
Training loss: 3.463156787263104
Validation loss: 2.6875283739862925

Epoch: 5| Step: 9
Training loss: 2.823726627004887
Validation loss: 2.6870845865678556

Epoch: 5| Step: 10
Training loss: 3.2307133241853645
Validation loss: 2.683539230877866

Epoch: 326| Step: 0
Training loss: 3.331000290434615
Validation loss: 2.6856754249689048

Epoch: 5| Step: 1
Training loss: 3.008226876387374
Validation loss: 2.6915340705482333

Epoch: 5| Step: 2
Training loss: 3.080284329456125
Validation loss: 2.69106544141748

Epoch: 5| Step: 3
Training loss: 2.6180388475104746
Validation loss: 2.698092342587647

Epoch: 5| Step: 4
Training loss: 3.4128452112442904
Validation loss: 2.7002784507182427

Epoch: 5| Step: 5
Training loss: 2.6526664346581557
Validation loss: 2.7215260387764615

Epoch: 5| Step: 6
Training loss: 3.1736499349017304
Validation loss: 2.723161493350529

Epoch: 5| Step: 7
Training loss: 2.7086701599381486
Validation loss: 2.7550992151833458

Epoch: 5| Step: 8
Training loss: 2.8040439217973483
Validation loss: 2.7466906550540946

Epoch: 5| Step: 9
Training loss: 3.1225616097156075
Validation loss: 2.7455204438299656

Epoch: 5| Step: 10
Training loss: 3.1415810719237736
Validation loss: 2.724089176997154

Epoch: 327| Step: 0
Training loss: 2.8025492643574332
Validation loss: 2.7076570217029374

Epoch: 5| Step: 1
Training loss: 3.5575436027680256
Validation loss: 2.70381875719965

Epoch: 5| Step: 2
Training loss: 3.0657950600089996
Validation loss: 2.6861163071229717

Epoch: 5| Step: 3
Training loss: 2.9277882841413536
Validation loss: 2.6824196437400634

Epoch: 5| Step: 4
Training loss: 2.860147340620513
Validation loss: 2.6839196627777344

Epoch: 5| Step: 5
Training loss: 2.7882128364291034
Validation loss: 2.6889687092797074

Epoch: 5| Step: 6
Training loss: 3.1748441883212455
Validation loss: 2.68835396159311

Epoch: 5| Step: 7
Training loss: 3.034477796296394
Validation loss: 2.6950616230841593

Epoch: 5| Step: 8
Training loss: 3.171901308147902
Validation loss: 2.686929348845909

Epoch: 5| Step: 9
Training loss: 3.0211759877165187
Validation loss: 2.6898577259906724

Epoch: 5| Step: 10
Training loss: 2.588602312223175
Validation loss: 2.6858466829993155

Epoch: 328| Step: 0
Training loss: 2.6513842727925576
Validation loss: 2.6857840250710168

Epoch: 5| Step: 1
Training loss: 3.3276160482322963
Validation loss: 2.684568537240289

Epoch: 5| Step: 2
Training loss: 2.415970033232418
Validation loss: 2.691363572583421

Epoch: 5| Step: 3
Training loss: 3.0105073028612725
Validation loss: 2.6958299051944423

Epoch: 5| Step: 4
Training loss: 3.0484058153626328
Validation loss: 2.7174715707488843

Epoch: 5| Step: 5
Training loss: 2.962638265867901
Validation loss: 2.7021077181524094

Epoch: 5| Step: 6
Training loss: 3.522487063901931
Validation loss: 2.7007655527102448

Epoch: 5| Step: 7
Training loss: 3.1298604169928086
Validation loss: 2.702170593371783

Epoch: 5| Step: 8
Training loss: 2.633669840964747
Validation loss: 2.714238377308755

Epoch: 5| Step: 9
Training loss: 2.9381951666111576
Validation loss: 2.697994492526775

Epoch: 5| Step: 10
Training loss: 3.343659872106018
Validation loss: 2.694271450270582

Epoch: 329| Step: 0
Training loss: 3.1414566077745327
Validation loss: 2.686208671817228

Epoch: 5| Step: 1
Training loss: 2.4127506778120424
Validation loss: 2.693504800432185

Epoch: 5| Step: 2
Training loss: 3.1895574773383717
Validation loss: 2.682244068507555

Epoch: 5| Step: 3
Training loss: 2.7802521705149035
Validation loss: 2.6886746767160603

Epoch: 5| Step: 4
Training loss: 2.8720317943056344
Validation loss: 2.6817063795857243

Epoch: 5| Step: 5
Training loss: 3.271739145863285
Validation loss: 2.6909136411015595

Epoch: 5| Step: 6
Training loss: 2.805689470685291
Validation loss: 2.6855007709263465

Epoch: 5| Step: 7
Training loss: 2.355553974994793
Validation loss: 2.6849716190309256

Epoch: 5| Step: 8
Training loss: 2.981322000141929
Validation loss: 2.6844224739405953

Epoch: 5| Step: 9
Training loss: 3.359936192678675
Validation loss: 2.681984129082003

Epoch: 5| Step: 10
Training loss: 3.757729765363916
Validation loss: 2.6854095542008625

Epoch: 330| Step: 0
Training loss: 1.8426655311709788
Validation loss: 2.6907898983742915

Epoch: 5| Step: 1
Training loss: 2.4625382318772293
Validation loss: 2.68988483326064

Epoch: 5| Step: 2
Training loss: 2.602031218773222
Validation loss: 2.6951217938202907

Epoch: 5| Step: 3
Training loss: 3.577488605259863
Validation loss: 2.694167061305595

Epoch: 5| Step: 4
Training loss: 2.9841781471398767
Validation loss: 2.698381295015973

Epoch: 5| Step: 5
Training loss: 2.828036227861555
Validation loss: 2.693833099066395

Epoch: 5| Step: 6
Training loss: 3.66129248701549
Validation loss: 2.706847063385816

Epoch: 5| Step: 7
Training loss: 3.48923676700902
Validation loss: 2.7074922184760415

Epoch: 5| Step: 8
Training loss: 3.17607792856233
Validation loss: 2.7018008351180383

Epoch: 5| Step: 9
Training loss: 2.4674340132805574
Validation loss: 2.7047120949522925

Epoch: 5| Step: 10
Training loss: 3.453359466463672
Validation loss: 2.7016915247617352

Epoch: 331| Step: 0
Training loss: 3.0012042489590285
Validation loss: 2.7188609879333008

Epoch: 5| Step: 1
Training loss: 2.8995104343616642
Validation loss: 2.690570579579581

Epoch: 5| Step: 2
Training loss: 2.604576404126798
Validation loss: 2.691754564204921

Epoch: 5| Step: 3
Training loss: 3.013568236076424
Validation loss: 2.6861519109350023

Epoch: 5| Step: 4
Training loss: 2.6115974509929196
Validation loss: 2.685396676823782

Epoch: 5| Step: 5
Training loss: 3.2523217344581257
Validation loss: 2.6841737520120605

Epoch: 5| Step: 6
Training loss: 3.493658451525496
Validation loss: 2.6784327222359017

Epoch: 5| Step: 7
Training loss: 2.8909954761534387
Validation loss: 2.6821866101006235

Epoch: 5| Step: 8
Training loss: 2.8234026350983616
Validation loss: 2.6807017269410225

Epoch: 5| Step: 9
Training loss: 3.1295084665467034
Validation loss: 2.683897577847314

Epoch: 5| Step: 10
Training loss: 3.260403049103368
Validation loss: 2.686676431485109

Epoch: 332| Step: 0
Training loss: 3.098204209494666
Validation loss: 2.684753831159492

Epoch: 5| Step: 1
Training loss: 2.6393615589346107
Validation loss: 2.6829449837752546

Epoch: 5| Step: 2
Training loss: 2.9298108697982683
Validation loss: 2.686011086773141

Epoch: 5| Step: 3
Training loss: 3.1425483849198725
Validation loss: 2.692423572281074

Epoch: 5| Step: 4
Training loss: 3.1544504606571704
Validation loss: 2.684445202996626

Epoch: 5| Step: 5
Training loss: 3.0198109091366825
Validation loss: 2.6920837266930544

Epoch: 5| Step: 6
Training loss: 3.055295605631797
Validation loss: 2.692471516389471

Epoch: 5| Step: 7
Training loss: 3.3012897167539403
Validation loss: 2.695459313278292

Epoch: 5| Step: 8
Training loss: 2.637376491312435
Validation loss: 2.6848315655994663

Epoch: 5| Step: 9
Training loss: 2.502255471369829
Validation loss: 2.68779021229833

Epoch: 5| Step: 10
Training loss: 3.447935597962252
Validation loss: 2.691174194575415

Epoch: 333| Step: 0
Training loss: 2.761609367999413
Validation loss: 2.685407247752513

Epoch: 5| Step: 1
Training loss: 3.1297292400896235
Validation loss: 2.693007602358607

Epoch: 5| Step: 2
Training loss: 3.013772820631954
Validation loss: 2.7052466043630616

Epoch: 5| Step: 3
Training loss: 3.04909852885801
Validation loss: 2.6960835042943825

Epoch: 5| Step: 4
Training loss: 3.4118840929851126
Validation loss: 2.702714202069843

Epoch: 5| Step: 5
Training loss: 2.8324706690347887
Validation loss: 2.706268147587684

Epoch: 5| Step: 6
Training loss: 3.2871134367547694
Validation loss: 2.702906176560732

Epoch: 5| Step: 7
Training loss: 2.493540525123534
Validation loss: 2.7030148507135854

Epoch: 5| Step: 8
Training loss: 2.674530672631678
Validation loss: 2.710853398752551

Epoch: 5| Step: 9
Training loss: 3.213885288425174
Validation loss: 2.694620464427882

Epoch: 5| Step: 10
Training loss: 3.022416920872946
Validation loss: 2.688252676790181

Epoch: 334| Step: 0
Training loss: 3.5138630838832965
Validation loss: 2.684126604293814

Epoch: 5| Step: 1
Training loss: 3.109904028586188
Validation loss: 2.6832742247214108

Epoch: 5| Step: 2
Training loss: 3.151587640210988
Validation loss: 2.6835988169133858

Epoch: 5| Step: 3
Training loss: 2.1254426831665607
Validation loss: 2.674854623690931

Epoch: 5| Step: 4
Training loss: 3.4097047137613523
Validation loss: 2.680801971604119

Epoch: 5| Step: 5
Training loss: 3.1626996908356033
Validation loss: 2.677601902222132

Epoch: 5| Step: 6
Training loss: 3.48781398877407
Validation loss: 2.680223727800289

Epoch: 5| Step: 7
Training loss: 2.8328569984202407
Validation loss: 2.6787531618892784

Epoch: 5| Step: 8
Training loss: 3.134029465985371
Validation loss: 2.6800318288382345

Epoch: 5| Step: 9
Training loss: 2.3658742755689857
Validation loss: 2.679625828889354

Epoch: 5| Step: 10
Training loss: 2.247128031228508
Validation loss: 2.6797264170678083

Epoch: 335| Step: 0
Training loss: 2.986451709652596
Validation loss: 2.6801702807784618

Epoch: 5| Step: 1
Training loss: 2.903323104554241
Validation loss: 2.6851331806164214

Epoch: 5| Step: 2
Training loss: 2.3695926345133755
Validation loss: 2.681570761256549

Epoch: 5| Step: 3
Training loss: 3.0280222273984614
Validation loss: 2.692083789544101

Epoch: 5| Step: 4
Training loss: 3.69817578477982
Validation loss: 2.6953507862816766

Epoch: 5| Step: 5
Training loss: 3.08879247014833
Validation loss: 2.6976715687963813

Epoch: 5| Step: 6
Training loss: 3.445618077435001
Validation loss: 2.691384614185099

Epoch: 5| Step: 7
Training loss: 2.590914359688155
Validation loss: 2.699157041700261

Epoch: 5| Step: 8
Training loss: 2.5070734093611096
Validation loss: 2.684041840615411

Epoch: 5| Step: 9
Training loss: 2.820429918375742
Validation loss: 2.6947142453213

Epoch: 5| Step: 10
Training loss: 3.3572030076548742
Validation loss: 2.698744150272141

Epoch: 336| Step: 0
Training loss: 2.729997629716564
Validation loss: 2.6933175461732946

Epoch: 5| Step: 1
Training loss: 2.8698149655337306
Validation loss: 2.6930656980628345

Epoch: 5| Step: 2
Training loss: 3.100898729301285
Validation loss: 2.688578939242476

Epoch: 5| Step: 3
Training loss: 2.7422829635827073
Validation loss: 2.701752139944925

Epoch: 5| Step: 4
Training loss: 3.0509805260120855
Validation loss: 2.7047396817628515

Epoch: 5| Step: 5
Training loss: 2.9408550176544375
Validation loss: 2.704152684058893

Epoch: 5| Step: 6
Training loss: 3.2456054320205543
Validation loss: 2.707717246761853

Epoch: 5| Step: 7
Training loss: 3.0311480632827834
Validation loss: 2.6983312735713456

Epoch: 5| Step: 8
Training loss: 3.2794512950353125
Validation loss: 2.6970674745643266

Epoch: 5| Step: 9
Training loss: 3.202174050198726
Validation loss: 2.689864022960839

Epoch: 5| Step: 10
Training loss: 2.7336573939779187
Validation loss: 2.689085664071581

Epoch: 337| Step: 0
Training loss: 2.658990411259813
Validation loss: 2.6833190925488783

Epoch: 5| Step: 1
Training loss: 2.821892715685756
Validation loss: 2.685540948796003

Epoch: 5| Step: 2
Training loss: 3.137092083558061
Validation loss: 2.6745902892281626

Epoch: 5| Step: 3
Training loss: 2.7218359610454725
Validation loss: 2.6782826525126042

Epoch: 5| Step: 4
Training loss: 2.875555565270816
Validation loss: 2.6705987704785965

Epoch: 5| Step: 5
Training loss: 3.220696314520543
Validation loss: 2.6790164808259784

Epoch: 5| Step: 6
Training loss: 3.1534544395541455
Validation loss: 2.6759456753165103

Epoch: 5| Step: 7
Training loss: 3.2618335086941426
Validation loss: 2.6786689497954406

Epoch: 5| Step: 8
Training loss: 2.9202904305968684
Validation loss: 2.6866916242974286

Epoch: 5| Step: 9
Training loss: 2.914491678086967
Validation loss: 2.6787277153622933

Epoch: 5| Step: 10
Training loss: 3.2374267923333453
Validation loss: 2.68949490049735

Epoch: 338| Step: 0
Training loss: 3.1378842061586285
Validation loss: 2.6878913352183003

Epoch: 5| Step: 1
Training loss: 3.309171768014191
Validation loss: 2.687038140604578

Epoch: 5| Step: 2
Training loss: 2.7379268574722144
Validation loss: 2.6792975404201105

Epoch: 5| Step: 3
Training loss: 2.6688333788673457
Validation loss: 2.6810982463847326

Epoch: 5| Step: 4
Training loss: 3.436173755386865
Validation loss: 2.6788903674185005

Epoch: 5| Step: 5
Training loss: 3.351454086150838
Validation loss: 2.6680261975128037

Epoch: 5| Step: 6
Training loss: 3.2247405369202253
Validation loss: 2.6728832360146417

Epoch: 5| Step: 7
Training loss: 2.957847412032306
Validation loss: 2.6831851021234687

Epoch: 5| Step: 8
Training loss: 2.3823877174842214
Validation loss: 2.6646312250549746

Epoch: 5| Step: 9
Training loss: 2.8767502474292037
Validation loss: 2.6682863917948128

Epoch: 5| Step: 10
Training loss: 2.6171524273244655
Validation loss: 2.6712359619078865

Epoch: 339| Step: 0
Training loss: 2.898622080228683
Validation loss: 2.6678042030078366

Epoch: 5| Step: 1
Training loss: 2.9458002551720273
Validation loss: 2.6711316852511366

Epoch: 5| Step: 2
Training loss: 2.5043604969873745
Validation loss: 2.6675340359595343

Epoch: 5| Step: 3
Training loss: 2.9401131228008426
Validation loss: 2.6721901205555665

Epoch: 5| Step: 4
Training loss: 3.447619022917854
Validation loss: 2.6759903115546053

Epoch: 5| Step: 5
Training loss: 3.631533292924242
Validation loss: 2.6768980316834394

Epoch: 5| Step: 6
Training loss: 2.7259465699644636
Validation loss: 2.6747995732576135

Epoch: 5| Step: 7
Training loss: 2.9363173681125305
Validation loss: 2.6746670274888023

Epoch: 5| Step: 8
Training loss: 3.048732719419334
Validation loss: 2.6815276457518813

Epoch: 5| Step: 9
Training loss: 2.8710014068908327
Validation loss: 2.677854217652422

Epoch: 5| Step: 10
Training loss: 2.777451396417307
Validation loss: 2.6732135061724853

Epoch: 340| Step: 0
Training loss: 3.5251796162613185
Validation loss: 2.6703960799554647

Epoch: 5| Step: 1
Training loss: 3.4217426152509507
Validation loss: 2.6802206708166283

Epoch: 5| Step: 2
Training loss: 2.663230878063219
Validation loss: 2.6717282859245883

Epoch: 5| Step: 3
Training loss: 3.055866765058813
Validation loss: 2.6792269749616358

Epoch: 5| Step: 4
Training loss: 2.5324280434691766
Validation loss: 2.6781634751677474

Epoch: 5| Step: 5
Training loss: 2.977037927500646
Validation loss: 2.6851510487710457

Epoch: 5| Step: 6
Training loss: 2.863679074991375
Validation loss: 2.670484861371331

Epoch: 5| Step: 7
Training loss: 2.9773858000589337
Validation loss: 2.674701740403579

Epoch: 5| Step: 8
Training loss: 2.826592298764981
Validation loss: 2.6666321162579973

Epoch: 5| Step: 9
Training loss: 2.7140408652875747
Validation loss: 2.6769085518962794

Epoch: 5| Step: 10
Training loss: 3.248944771458992
Validation loss: 2.670272767963217

Epoch: 341| Step: 0
Training loss: 3.0016557574740235
Validation loss: 2.68132240726768

Epoch: 5| Step: 1
Training loss: 3.112703162001068
Validation loss: 2.677294034356351

Epoch: 5| Step: 2
Training loss: 2.8359882781051486
Validation loss: 2.6661500821379627

Epoch: 5| Step: 3
Training loss: 3.6195013501591227
Validation loss: 2.673684249841386

Epoch: 5| Step: 4
Training loss: 2.4849935277474624
Validation loss: 2.6687022692771367

Epoch: 5| Step: 5
Training loss: 2.7697280361924013
Validation loss: 2.6671928558294873

Epoch: 5| Step: 6
Training loss: 3.075501849153323
Validation loss: 2.6713566882138218

Epoch: 5| Step: 7
Training loss: 2.874245088399045
Validation loss: 2.675712431389522

Epoch: 5| Step: 8
Training loss: 3.1168145360564607
Validation loss: 2.6761587110394514

Epoch: 5| Step: 9
Training loss: 3.1972860569845776
Validation loss: 2.672623666716358

Epoch: 5| Step: 10
Training loss: 2.598221016202364
Validation loss: 2.66398135191473

Epoch: 342| Step: 0
Training loss: 2.9999949137326674
Validation loss: 2.671276456059144

Epoch: 5| Step: 1
Training loss: 3.105199415895151
Validation loss: 2.6771676406299294

Epoch: 5| Step: 2
Training loss: 2.7850772370289913
Validation loss: 2.6736236493841625

Epoch: 5| Step: 3
Training loss: 3.4897444199157346
Validation loss: 2.671877128150705

Epoch: 5| Step: 4
Training loss: 3.1367448969567135
Validation loss: 2.664952598894712

Epoch: 5| Step: 5
Training loss: 2.5721590314023564
Validation loss: 2.673562545097326

Epoch: 5| Step: 6
Training loss: 2.978031306679299
Validation loss: 2.6718136743736163

Epoch: 5| Step: 7
Training loss: 2.5410648842566372
Validation loss: 2.6703219709411594

Epoch: 5| Step: 8
Training loss: 2.892950658615455
Validation loss: 2.6757726147162555

Epoch: 5| Step: 9
Training loss: 3.2123154702234364
Validation loss: 2.684005745562951

Epoch: 5| Step: 10
Training loss: 3.0655379505611355
Validation loss: 2.681869645355465

Epoch: 343| Step: 0
Training loss: 3.0315734061530706
Validation loss: 2.690352290144804

Epoch: 5| Step: 1
Training loss: 3.071953798294333
Validation loss: 2.6761140488710344

Epoch: 5| Step: 2
Training loss: 3.2583016227356363
Validation loss: 2.675871975801309

Epoch: 5| Step: 3
Training loss: 2.459745669514942
Validation loss: 2.6677233143286383

Epoch: 5| Step: 4
Training loss: 3.1199195763419603
Validation loss: 2.679719780570516

Epoch: 5| Step: 5
Training loss: 2.9163737195354558
Validation loss: 2.6748425504164883

Epoch: 5| Step: 6
Training loss: 3.4496942799326433
Validation loss: 2.669706405208938

Epoch: 5| Step: 7
Training loss: 2.9158731925299066
Validation loss: 2.6791546412369853

Epoch: 5| Step: 8
Training loss: 2.9348232979034687
Validation loss: 2.689577696536579

Epoch: 5| Step: 9
Training loss: 2.593743197880294
Validation loss: 2.6776066118607025

Epoch: 5| Step: 10
Training loss: 3.032802695367089
Validation loss: 2.6802799743382817

Epoch: 344| Step: 0
Training loss: 3.226679986842171
Validation loss: 2.67320503617564

Epoch: 5| Step: 1
Training loss: 2.908447911174302
Validation loss: 2.6712436161499253

Epoch: 5| Step: 2
Training loss: 2.7638931455424984
Validation loss: 2.6822687180124105

Epoch: 5| Step: 3
Training loss: 2.6445909321528904
Validation loss: 2.6831867636449496

Epoch: 5| Step: 4
Training loss: 3.127896911658986
Validation loss: 2.6946284304222012

Epoch: 5| Step: 5
Training loss: 3.1857796308571436
Validation loss: 2.6963002020888736

Epoch: 5| Step: 6
Training loss: 2.372806741000868
Validation loss: 2.6746162716260815

Epoch: 5| Step: 7
Training loss: 2.9322184705435204
Validation loss: 2.676338410729818

Epoch: 5| Step: 8
Training loss: 3.3759665341458662
Validation loss: 2.6794133874429344

Epoch: 5| Step: 9
Training loss: 3.066161944139283
Validation loss: 2.6761694746044578

Epoch: 5| Step: 10
Training loss: 3.129968431941244
Validation loss: 2.6793275608911893

Epoch: 345| Step: 0
Training loss: 2.4796814157066387
Validation loss: 2.6795595439218474

Epoch: 5| Step: 1
Training loss: 3.5168441354045665
Validation loss: 2.677946607880703

Epoch: 5| Step: 2
Training loss: 3.2376939634449293
Validation loss: 2.6794943939490734

Epoch: 5| Step: 3
Training loss: 2.6136098521098
Validation loss: 2.6784686569366576

Epoch: 5| Step: 4
Training loss: 3.2508357514000252
Validation loss: 2.6884831468672057

Epoch: 5| Step: 5
Training loss: 2.5808991274537076
Validation loss: 2.690954451716762

Epoch: 5| Step: 6
Training loss: 2.6942175368715735
Validation loss: 2.683910249409995

Epoch: 5| Step: 7
Training loss: 3.22883226857691
Validation loss: 2.67955926359714

Epoch: 5| Step: 8
Training loss: 2.8507602346936247
Validation loss: 2.683929286252481

Epoch: 5| Step: 9
Training loss: 3.284121900510039
Validation loss: 2.664181263109955

Epoch: 5| Step: 10
Training loss: 2.8553523550041993
Validation loss: 2.6792494485988594

Epoch: 346| Step: 0
Training loss: 2.803115446654916
Validation loss: 2.6665561999877374

Epoch: 5| Step: 1
Training loss: 3.170566683638423
Validation loss: 2.674290641901668

Epoch: 5| Step: 2
Training loss: 2.893068013251136
Validation loss: 2.669309372442371

Epoch: 5| Step: 3
Training loss: 2.3091899792547443
Validation loss: 2.670392604671327

Epoch: 5| Step: 4
Training loss: 3.0943217664318405
Validation loss: 2.6733033898670535

Epoch: 5| Step: 5
Training loss: 3.6577382767425366
Validation loss: 2.688197534522328

Epoch: 5| Step: 6
Training loss: 2.890756305083647
Validation loss: 2.6763846027117513

Epoch: 5| Step: 7
Training loss: 2.5765321376994117
Validation loss: 2.6783569021109606

Epoch: 5| Step: 8
Training loss: 3.3998387747293006
Validation loss: 2.6785221838538398

Epoch: 5| Step: 9
Training loss: 2.8698279256774346
Validation loss: 2.669389467801977

Epoch: 5| Step: 10
Training loss: 2.9791069469379488
Validation loss: 2.6702624837062303

Epoch: 347| Step: 0
Training loss: 1.91324208641235
Validation loss: 2.6658222998489567

Epoch: 5| Step: 1
Training loss: 2.9016150153958744
Validation loss: 2.670778443989874

Epoch: 5| Step: 2
Training loss: 3.204317196673796
Validation loss: 2.664656572410475

Epoch: 5| Step: 3
Training loss: 3.5048968255588493
Validation loss: 2.667167684444668

Epoch: 5| Step: 4
Training loss: 3.0288189450114307
Validation loss: 2.6627868922209315

Epoch: 5| Step: 5
Training loss: 2.936866529622581
Validation loss: 2.669460147334015

Epoch: 5| Step: 6
Training loss: 2.958095021566449
Validation loss: 2.6822926093694313

Epoch: 5| Step: 7
Training loss: 2.9663223781186923
Validation loss: 2.6936841033655803

Epoch: 5| Step: 8
Training loss: 3.084672808739218
Validation loss: 2.716765491699505

Epoch: 5| Step: 9
Training loss: 3.0670944316345197
Validation loss: 2.7075517370646365

Epoch: 5| Step: 10
Training loss: 3.1837239057462283
Validation loss: 2.6917990325817134

Epoch: 348| Step: 0
Training loss: 2.856211428726161
Validation loss: 2.6889305256682388

Epoch: 5| Step: 1
Training loss: 3.1028925352429004
Validation loss: 2.6885180165679587

Epoch: 5| Step: 2
Training loss: 3.3147816986886087
Validation loss: 2.6900246693436456

Epoch: 5| Step: 3
Training loss: 3.0112856938268395
Validation loss: 2.682007607172345

Epoch: 5| Step: 4
Training loss: 2.890194092671035
Validation loss: 2.6902254159464793

Epoch: 5| Step: 5
Training loss: 3.0544322656017315
Validation loss: 2.6949671417780485

Epoch: 5| Step: 6
Training loss: 2.808020945832254
Validation loss: 2.6968775816674673

Epoch: 5| Step: 7
Training loss: 2.55915474601842
Validation loss: 2.6945617034323104

Epoch: 5| Step: 8
Training loss: 2.951762697570066
Validation loss: 2.6835694030802686

Epoch: 5| Step: 9
Training loss: 3.3379994793726366
Validation loss: 2.6846725927888193

Epoch: 5| Step: 10
Training loss: 2.924396426535515
Validation loss: 2.6791445987189157

Epoch: 349| Step: 0
Training loss: 3.350601449750961
Validation loss: 2.682701266099376

Epoch: 5| Step: 1
Training loss: 3.107893854594423
Validation loss: 2.67191247746468

Epoch: 5| Step: 2
Training loss: 3.106155799343053
Validation loss: 2.6687035843819373

Epoch: 5| Step: 3
Training loss: 2.3696215110866214
Validation loss: 2.6660104188924953

Epoch: 5| Step: 4
Training loss: 3.5216308834089203
Validation loss: 2.6684993943523483

Epoch: 5| Step: 5
Training loss: 3.020550909761647
Validation loss: 2.670204254786491

Epoch: 5| Step: 6
Training loss: 3.1211646385879543
Validation loss: 2.665804263671987

Epoch: 5| Step: 7
Training loss: 2.1127692146984813
Validation loss: 2.667997004037871

Epoch: 5| Step: 8
Training loss: 2.947953474446298
Validation loss: 2.6741446058450946

Epoch: 5| Step: 9
Training loss: 3.0734504020664466
Validation loss: 2.6668993947035915

Epoch: 5| Step: 10
Training loss: 2.7660063572256828
Validation loss: 2.688847844135359

Epoch: 350| Step: 0
Training loss: 3.0136620650561334
Validation loss: 2.707905980952515

Epoch: 5| Step: 1
Training loss: 2.9533565369922283
Validation loss: 2.70384162898405

Epoch: 5| Step: 2
Training loss: 3.1026321987909107
Validation loss: 2.719192721546539

Epoch: 5| Step: 3
Training loss: 2.866682876127088
Validation loss: 2.727363150832494

Epoch: 5| Step: 4
Training loss: 2.900457043641867
Validation loss: 2.7117493487660327

Epoch: 5| Step: 5
Training loss: 3.1974365337834687
Validation loss: 2.6970253724582305

Epoch: 5| Step: 6
Training loss: 2.797262495252491
Validation loss: 2.6843532474992657

Epoch: 5| Step: 7
Training loss: 2.778403894008606
Validation loss: 2.6857804809275296

Epoch: 5| Step: 8
Training loss: 3.3590604413049556
Validation loss: 2.684408683612798

Epoch: 5| Step: 9
Training loss: 2.941899515361442
Validation loss: 2.6796553491525468

Epoch: 5| Step: 10
Training loss: 2.921474000882019
Validation loss: 2.6803122726415256

Epoch: 351| Step: 0
Training loss: 2.7044140162341295
Validation loss: 2.671416263362702

Epoch: 5| Step: 1
Training loss: 2.800882547799858
Validation loss: 2.6727895494998095

Epoch: 5| Step: 2
Training loss: 2.9540452280269025
Validation loss: 2.670717934062714

Epoch: 5| Step: 3
Training loss: 3.274221394710069
Validation loss: 2.6713690718622614

Epoch: 5| Step: 4
Training loss: 3.054348119434388
Validation loss: 2.673603960004673

Epoch: 5| Step: 5
Training loss: 3.2006177067613035
Validation loss: 2.67265473191425

Epoch: 5| Step: 6
Training loss: 3.1735432564465085
Validation loss: 2.686244513949073

Epoch: 5| Step: 7
Training loss: 2.9885662267098354
Validation loss: 2.686735950806807

Epoch: 5| Step: 8
Training loss: 2.9334954094181973
Validation loss: 2.6777062591306677

Epoch: 5| Step: 9
Training loss: 2.5861518517478963
Validation loss: 2.6793310523338634

Epoch: 5| Step: 10
Training loss: 3.086456332472686
Validation loss: 2.691062427234551

Epoch: 352| Step: 0
Training loss: 2.525206804776763
Validation loss: 2.6829349726444964

Epoch: 5| Step: 1
Training loss: 2.903594249500929
Validation loss: 2.6875455022090153

Epoch: 5| Step: 2
Training loss: 3.134993785505204
Validation loss: 2.6909202985796465

Epoch: 5| Step: 3
Training loss: 2.7485540229771948
Validation loss: 2.673186408225846

Epoch: 5| Step: 4
Training loss: 3.158658760905755
Validation loss: 2.6632121620591236

Epoch: 5| Step: 5
Training loss: 2.990391124800344
Validation loss: 2.6553533991646407

Epoch: 5| Step: 6
Training loss: 3.146746538678723
Validation loss: 2.662991372975835

Epoch: 5| Step: 7
Training loss: 3.163875922836188
Validation loss: 2.6638674480727897

Epoch: 5| Step: 8
Training loss: 3.2617576368378027
Validation loss: 2.665999386411279

Epoch: 5| Step: 9
Training loss: 3.027356665799061
Validation loss: 2.666618903050231

Epoch: 5| Step: 10
Training loss: 2.6211328631465993
Validation loss: 2.6688059377018076

Epoch: 353| Step: 0
Training loss: 3.337203560569132
Validation loss: 2.671536722425422

Epoch: 5| Step: 1
Training loss: 2.8990245954530125
Validation loss: 2.678887380686762

Epoch: 5| Step: 2
Training loss: 2.5318753447258158
Validation loss: 2.6757563069552788

Epoch: 5| Step: 3
Training loss: 3.358905564266528
Validation loss: 2.6847467649750816

Epoch: 5| Step: 4
Training loss: 2.93374881258381
Validation loss: 2.692568706445879

Epoch: 5| Step: 5
Training loss: 2.225813890393896
Validation loss: 2.674020813826306

Epoch: 5| Step: 6
Training loss: 2.823538417310939
Validation loss: 2.664231146309802

Epoch: 5| Step: 7
Training loss: 3.1795318340466134
Validation loss: 2.658486130436184

Epoch: 5| Step: 8
Training loss: 3.2412310924633214
Validation loss: 2.6585998400665245

Epoch: 5| Step: 9
Training loss: 2.9485470442645494
Validation loss: 2.651179387062144

Epoch: 5| Step: 10
Training loss: 3.0916750336265624
Validation loss: 2.6595644882720073

Epoch: 354| Step: 0
Training loss: 2.890682240512228
Validation loss: 2.661319521386145

Epoch: 5| Step: 1
Training loss: 3.453213375565938
Validation loss: 2.6559299669494014

Epoch: 5| Step: 2
Training loss: 3.0632628444438765
Validation loss: 2.6506600827675317

Epoch: 5| Step: 3
Training loss: 3.107740423058106
Validation loss: 2.654094700388109

Epoch: 5| Step: 4
Training loss: 2.995467258489014
Validation loss: 2.6600347180390376

Epoch: 5| Step: 5
Training loss: 3.0463909058038423
Validation loss: 2.663059406516953

Epoch: 5| Step: 6
Training loss: 2.173316312656959
Validation loss: 2.6632817618653593

Epoch: 5| Step: 7
Training loss: 3.0451547314647267
Validation loss: 2.6576686296841134

Epoch: 5| Step: 8
Training loss: 2.85295041940463
Validation loss: 2.663791747506614

Epoch: 5| Step: 9
Training loss: 3.0500376401986284
Validation loss: 2.6571401071040404

Epoch: 5| Step: 10
Training loss: 2.9880034273937337
Validation loss: 2.6608782216432765

Epoch: 355| Step: 0
Training loss: 2.7110126056216255
Validation loss: 2.6649467115487133

Epoch: 5| Step: 1
Training loss: 3.051431388792449
Validation loss: 2.669422178302303

Epoch: 5| Step: 2
Training loss: 3.5173537687421867
Validation loss: 2.669768552720226

Epoch: 5| Step: 3
Training loss: 2.9658376764185475
Validation loss: 2.677522830950245

Epoch: 5| Step: 4
Training loss: 2.9258539371603427
Validation loss: 2.6817092264737425

Epoch: 5| Step: 5
Training loss: 3.200082217590795
Validation loss: 2.6837597351571674

Epoch: 5| Step: 6
Training loss: 3.4555867943641334
Validation loss: 2.6828050892413793

Epoch: 5| Step: 7
Training loss: 2.50287081872099
Validation loss: 2.6765536861716233

Epoch: 5| Step: 8
Training loss: 2.8359881099672277
Validation loss: 2.6714502205743074

Epoch: 5| Step: 9
Training loss: 3.1437656773807654
Validation loss: 2.6633579745701783

Epoch: 5| Step: 10
Training loss: 2.0233560788773515
Validation loss: 2.65663328451676

Epoch: 356| Step: 0
Training loss: 3.054533425272337
Validation loss: 2.6549979920145326

Epoch: 5| Step: 1
Training loss: 2.4527296974804598
Validation loss: 2.656325370206665

Epoch: 5| Step: 2
Training loss: 2.6811987171737424
Validation loss: 2.655038758929229

Epoch: 5| Step: 3
Training loss: 3.509176621982715
Validation loss: 2.660342684363943

Epoch: 5| Step: 4
Training loss: 2.7091727985401475
Validation loss: 2.6562877809176917

Epoch: 5| Step: 5
Training loss: 3.508066146957703
Validation loss: 2.650347798819924

Epoch: 5| Step: 6
Training loss: 3.065426731989257
Validation loss: 2.6442733912550604

Epoch: 5| Step: 7
Training loss: 2.883837179214649
Validation loss: 2.6536859320531

Epoch: 5| Step: 8
Training loss: 2.6335158498101303
Validation loss: 2.652611892138803

Epoch: 5| Step: 9
Training loss: 3.236966481673699
Validation loss: 2.65143806512201

Epoch: 5| Step: 10
Training loss: 2.811851257101881
Validation loss: 2.6567085541076443

Epoch: 357| Step: 0
Training loss: 2.9259106514483295
Validation loss: 2.659695508533183

Epoch: 5| Step: 1
Training loss: 2.748874520694548
Validation loss: 2.6689599588417474

Epoch: 5| Step: 2
Training loss: 2.9227561234105033
Validation loss: 2.6782606991392752

Epoch: 5| Step: 3
Training loss: 2.643816852851596
Validation loss: 2.6697402540537145

Epoch: 5| Step: 4
Training loss: 2.4542161980786497
Validation loss: 2.673654401883536

Epoch: 5| Step: 5
Training loss: 3.010819475268933
Validation loss: 2.678255380911099

Epoch: 5| Step: 6
Training loss: 3.456571352265951
Validation loss: 2.6866546602509374

Epoch: 5| Step: 7
Training loss: 3.431051135249983
Validation loss: 2.676704674587824

Epoch: 5| Step: 8
Training loss: 3.1539488609294852
Validation loss: 2.6658453057748543

Epoch: 5| Step: 9
Training loss: 2.7045619430797068
Validation loss: 2.6582591971100453

Epoch: 5| Step: 10
Training loss: 3.1732197433732647
Validation loss: 2.6450183279467594

Epoch: 358| Step: 0
Training loss: 2.6392661667104886
Validation loss: 2.653216930847952

Epoch: 5| Step: 1
Training loss: 2.7068795826357213
Validation loss: 2.6502827239489206

Epoch: 5| Step: 2
Training loss: 3.286783112661268
Validation loss: 2.6616271122213884

Epoch: 5| Step: 3
Training loss: 2.934443242881163
Validation loss: 2.6608930906271566

Epoch: 5| Step: 4
Training loss: 3.1495482045076066
Validation loss: 2.6540527386009627

Epoch: 5| Step: 5
Training loss: 2.9678592349394752
Validation loss: 2.6666838359536404

Epoch: 5| Step: 6
Training loss: 3.325386460869735
Validation loss: 2.6656243183564197

Epoch: 5| Step: 7
Training loss: 2.5546600620301203
Validation loss: 2.672730346431062

Epoch: 5| Step: 8
Training loss: 3.3247772715837143
Validation loss: 2.666479080726712

Epoch: 5| Step: 9
Training loss: 3.036205370635086
Validation loss: 2.6734018636437424

Epoch: 5| Step: 10
Training loss: 2.730142947775685
Validation loss: 2.6727820756918685

Epoch: 359| Step: 0
Training loss: 2.8850629752705323
Validation loss: 2.680898089120816

Epoch: 5| Step: 1
Training loss: 3.033085847197492
Validation loss: 2.6744348889562914

Epoch: 5| Step: 2
Training loss: 2.625377809492974
Validation loss: 2.6801344205455906

Epoch: 5| Step: 3
Training loss: 2.8113482342184093
Validation loss: 2.6938558438877225

Epoch: 5| Step: 4
Training loss: 3.335935498846736
Validation loss: 2.683895975032696

Epoch: 5| Step: 5
Training loss: 3.2624271194677847
Validation loss: 2.6656151058218875

Epoch: 5| Step: 6
Training loss: 3.0506934081263792
Validation loss: 2.6616756515119606

Epoch: 5| Step: 7
Training loss: 3.0400655704253077
Validation loss: 2.6618707321014856

Epoch: 5| Step: 8
Training loss: 2.8294295363482136
Validation loss: 2.6488854588463595

Epoch: 5| Step: 9
Training loss: 2.8278530264058346
Validation loss: 2.6480336405419638

Epoch: 5| Step: 10
Training loss: 2.986621909600913
Validation loss: 2.646932738964335

Epoch: 360| Step: 0
Training loss: 3.0814468351869215
Validation loss: 2.648017767035978

Epoch: 5| Step: 1
Training loss: 3.036825656211292
Validation loss: 2.6475610677065577

Epoch: 5| Step: 2
Training loss: 3.038190309551998
Validation loss: 2.653175999698532

Epoch: 5| Step: 3
Training loss: 2.7070152205175666
Validation loss: 2.6555801656936806

Epoch: 5| Step: 4
Training loss: 2.7058675447288065
Validation loss: 2.649196142337513

Epoch: 5| Step: 5
Training loss: 2.747556294219426
Validation loss: 2.647884063146912

Epoch: 5| Step: 6
Training loss: 2.0919048092703894
Validation loss: 2.64446689382418

Epoch: 5| Step: 7
Training loss: 3.374101165891939
Validation loss: 2.645080517604972

Epoch: 5| Step: 8
Training loss: 3.429431393039585
Validation loss: 2.6468026134116003

Epoch: 5| Step: 9
Training loss: 3.1881007208139907
Validation loss: 2.64925518427126

Epoch: 5| Step: 10
Training loss: 3.1003061820151268
Validation loss: 2.647606223151449

Epoch: 361| Step: 0
Training loss: 2.8007428580277076
Validation loss: 2.6463128839760386

Epoch: 5| Step: 1
Training loss: 2.895006972124997
Validation loss: 2.6563719671382438

Epoch: 5| Step: 2
Training loss: 2.934384581008886
Validation loss: 2.650624335899262

Epoch: 5| Step: 3
Training loss: 2.7690096042421035
Validation loss: 2.6492708403769956

Epoch: 5| Step: 4
Training loss: 2.536913434715114
Validation loss: 2.6583497484520513

Epoch: 5| Step: 5
Training loss: 3.194905971044901
Validation loss: 2.6714696686447246

Epoch: 5| Step: 6
Training loss: 3.760555162635643
Validation loss: 2.6718245552317725

Epoch: 5| Step: 7
Training loss: 2.53350145969985
Validation loss: 2.6726533736706957

Epoch: 5| Step: 8
Training loss: 3.1008350662709123
Validation loss: 2.659177645594755

Epoch: 5| Step: 9
Training loss: 2.982255432640728
Validation loss: 2.668412088859842

Epoch: 5| Step: 10
Training loss: 3.0686417321647865
Validation loss: 2.6701314270062344

Epoch: 362| Step: 0
Training loss: 2.930544796442306
Validation loss: 2.686672991573142

Epoch: 5| Step: 1
Training loss: 3.1839130639327515
Validation loss: 2.6920503030603857

Epoch: 5| Step: 2
Training loss: 2.9660029501099685
Validation loss: 2.6908837260711476

Epoch: 5| Step: 3
Training loss: 3.1344592553753827
Validation loss: 2.6940379792037703

Epoch: 5| Step: 4
Training loss: 2.7793844588547465
Validation loss: 2.7065880632006887

Epoch: 5| Step: 5
Training loss: 3.177891029290175
Validation loss: 2.7148145689288294

Epoch: 5| Step: 6
Training loss: 3.1410453856649587
Validation loss: 2.7067985792772964

Epoch: 5| Step: 7
Training loss: 2.5410644151253634
Validation loss: 2.715030272167057

Epoch: 5| Step: 8
Training loss: 3.231108411863314
Validation loss: 2.708559647436916

Epoch: 5| Step: 9
Training loss: 3.3668232519415766
Validation loss: 2.7090207693883155

Epoch: 5| Step: 10
Training loss: 2.381217547818822
Validation loss: 2.6988854926515167

Epoch: 363| Step: 0
Training loss: 2.8961035696130226
Validation loss: 2.703281567579913

Epoch: 5| Step: 1
Training loss: 3.3249951183311937
Validation loss: 2.7013435399680867

Epoch: 5| Step: 2
Training loss: 2.881636713187412
Validation loss: 2.7099554525488183

Epoch: 5| Step: 3
Training loss: 3.404997849204663
Validation loss: 2.714631441150742

Epoch: 5| Step: 4
Training loss: 2.9055148599796388
Validation loss: 2.7120529829842113

Epoch: 5| Step: 5
Training loss: 2.496269494497771
Validation loss: 2.7039535592702566

Epoch: 5| Step: 6
Training loss: 2.8923648031780305
Validation loss: 2.6945031171705054

Epoch: 5| Step: 7
Training loss: 2.4351414738470836
Validation loss: 2.703679621755247

Epoch: 5| Step: 8
Training loss: 2.8676388252796023
Validation loss: 2.699229567873996

Epoch: 5| Step: 9
Training loss: 3.2169127915324647
Validation loss: 2.68603985921457

Epoch: 5| Step: 10
Training loss: 3.572866248543383
Validation loss: 2.686982234941339

Epoch: 364| Step: 0
Training loss: 3.2466519056085157
Validation loss: 2.697636075208096

Epoch: 5| Step: 1
Training loss: 2.8887383980148718
Validation loss: 2.683107238767156

Epoch: 5| Step: 2
Training loss: 2.864195382406485
Validation loss: 2.671628905071882

Epoch: 5| Step: 3
Training loss: 3.0104209785474545
Validation loss: 2.6767916588520486

Epoch: 5| Step: 4
Training loss: 2.8616450736361103
Validation loss: 2.6822552683378023

Epoch: 5| Step: 5
Training loss: 3.289745124057821
Validation loss: 2.671660155518425

Epoch: 5| Step: 6
Training loss: 2.443219053537135
Validation loss: 2.6689555624502566

Epoch: 5| Step: 7
Training loss: 3.457491638217615
Validation loss: 2.6594701860479812

Epoch: 5| Step: 8
Training loss: 2.8897418348373747
Validation loss: 2.666664647638674

Epoch: 5| Step: 9
Training loss: 2.929315894401267
Validation loss: 2.6560921879697514

Epoch: 5| Step: 10
Training loss: 2.728445981993056
Validation loss: 2.6520777006226175

Epoch: 365| Step: 0
Training loss: 3.2615263556655756
Validation loss: 2.645377669186947

Epoch: 5| Step: 1
Training loss: 3.1197282193482265
Validation loss: 2.6491780510287715

Epoch: 5| Step: 2
Training loss: 3.0865578329729417
Validation loss: 2.636986044670475

Epoch: 5| Step: 3
Training loss: 3.229807406609419
Validation loss: 2.6429836542077396

Epoch: 5| Step: 4
Training loss: 2.693031030991031
Validation loss: 2.6446952015890086

Epoch: 5| Step: 5
Training loss: 2.8345168577652817
Validation loss: 2.6480883180199166

Epoch: 5| Step: 6
Training loss: 2.4316867073319184
Validation loss: 2.639540067213357

Epoch: 5| Step: 7
Training loss: 2.7543372716498893
Validation loss: 2.641104941754133

Epoch: 5| Step: 8
Training loss: 3.0908510131275437
Validation loss: 2.6404727989740757

Epoch: 5| Step: 9
Training loss: 2.902898352966609
Validation loss: 2.6377778567542074

Epoch: 5| Step: 10
Training loss: 3.1289928105223863
Validation loss: 2.6411040856232875

Epoch: 366| Step: 0
Training loss: 3.335901050234489
Validation loss: 2.6494600688230925

Epoch: 5| Step: 1
Training loss: 3.068327516891821
Validation loss: 2.64698960574481

Epoch: 5| Step: 2
Training loss: 2.493525991680316
Validation loss: 2.644436058802844

Epoch: 5| Step: 3
Training loss: 3.19194483793967
Validation loss: 2.654604069489897

Epoch: 5| Step: 4
Training loss: 2.185218056768578
Validation loss: 2.6515075495360163

Epoch: 5| Step: 5
Training loss: 3.311182011805998
Validation loss: 2.659056529272485

Epoch: 5| Step: 6
Training loss: 2.6577924849862735
Validation loss: 2.650400512405067

Epoch: 5| Step: 7
Training loss: 2.696660067059426
Validation loss: 2.653568379763822

Epoch: 5| Step: 8
Training loss: 3.1588045867442207
Validation loss: 2.6521612307505404

Epoch: 5| Step: 9
Training loss: 3.2974929592008233
Validation loss: 2.65834975134517

Epoch: 5| Step: 10
Training loss: 3.0100935572281804
Validation loss: 2.6520347566857576

Epoch: 367| Step: 0
Training loss: 2.4813095469980526
Validation loss: 2.650019972562064

Epoch: 5| Step: 1
Training loss: 2.6726582589318943
Validation loss: 2.6590912073576325

Epoch: 5| Step: 2
Training loss: 2.992094750622731
Validation loss: 2.6742993739983434

Epoch: 5| Step: 3
Training loss: 3.254026266497276
Validation loss: 2.687802825449484

Epoch: 5| Step: 4
Training loss: 3.258518206594826
Validation loss: 2.70847327073563

Epoch: 5| Step: 5
Training loss: 3.217135719004884
Validation loss: 2.7183235757189297

Epoch: 5| Step: 6
Training loss: 3.4930925327279416
Validation loss: 2.707702516557086

Epoch: 5| Step: 7
Training loss: 3.1989747491181615
Validation loss: 2.6474224476672434

Epoch: 5| Step: 8
Training loss: 2.5349932649060225
Validation loss: 2.636745096832351

Epoch: 5| Step: 9
Training loss: 2.804507704048368
Validation loss: 2.6386434760089252

Epoch: 5| Step: 10
Training loss: 2.5530507855502274
Validation loss: 2.6347771687083217

Epoch: 368| Step: 0
Training loss: 3.152062234515878
Validation loss: 2.638545557869087

Epoch: 5| Step: 1
Training loss: 3.2576781320648895
Validation loss: 2.639300403520909

Epoch: 5| Step: 2
Training loss: 2.806118230975773
Validation loss: 2.6414118273696974

Epoch: 5| Step: 3
Training loss: 2.9960808585833316
Validation loss: 2.6445317376142494

Epoch: 5| Step: 4
Training loss: 3.3952192129564063
Validation loss: 2.649898307073432

Epoch: 5| Step: 5
Training loss: 2.942961303280249
Validation loss: 2.6414193918798183

Epoch: 5| Step: 6
Training loss: 2.390349627822508
Validation loss: 2.6360839949900403

Epoch: 5| Step: 7
Training loss: 2.573623148389118
Validation loss: 2.6328149985823144

Epoch: 5| Step: 8
Training loss: 3.4751751478226867
Validation loss: 2.6324741159093716

Epoch: 5| Step: 9
Training loss: 2.920455506212949
Validation loss: 2.637748512193572

Epoch: 5| Step: 10
Training loss: 2.7077545917039902
Validation loss: 2.6318125709657547

Epoch: 369| Step: 0
Training loss: 2.9073807352259506
Validation loss: 2.634227182856415

Epoch: 5| Step: 1
Training loss: 3.526867062284091
Validation loss: 2.639604131712157

Epoch: 5| Step: 2
Training loss: 2.6830322033474028
Validation loss: 2.637031182875214

Epoch: 5| Step: 3
Training loss: 3.341101908029575
Validation loss: 2.662693173005505

Epoch: 5| Step: 4
Training loss: 2.687377926915065
Validation loss: 2.666368546344366

Epoch: 5| Step: 5
Training loss: 3.037635919489055
Validation loss: 2.6670897081613325

Epoch: 5| Step: 6
Training loss: 2.7275992884339484
Validation loss: 2.669801761739872

Epoch: 5| Step: 7
Training loss: 2.911998191466137
Validation loss: 2.681688548705928

Epoch: 5| Step: 8
Training loss: 3.1036821708380717
Validation loss: 2.674518055359561

Epoch: 5| Step: 9
Training loss: 2.5499319441446446
Validation loss: 2.6801156494497747

Epoch: 5| Step: 10
Training loss: 3.070480225619108
Validation loss: 2.649744056435247

Epoch: 370| Step: 0
Training loss: 3.0421247964675473
Validation loss: 2.6373863730725713

Epoch: 5| Step: 1
Training loss: 2.9353949938358253
Validation loss: 2.641191967656841

Epoch: 5| Step: 2
Training loss: 3.018307930305653
Validation loss: 2.6358349800603347

Epoch: 5| Step: 3
Training loss: 3.030289487952981
Validation loss: 2.6359569649576065

Epoch: 5| Step: 4
Training loss: 2.6307605025326404
Validation loss: 2.636707371330548

Epoch: 5| Step: 5
Training loss: 3.5403748493763594
Validation loss: 2.6366794606650013

Epoch: 5| Step: 6
Training loss: 2.326327968071776
Validation loss: 2.6381107522275316

Epoch: 5| Step: 7
Training loss: 3.0638666023219305
Validation loss: 2.6352430003738165

Epoch: 5| Step: 8
Training loss: 2.9910969552128193
Validation loss: 2.64161940387735

Epoch: 5| Step: 9
Training loss: 3.3027970337972574
Validation loss: 2.639657991229556

Epoch: 5| Step: 10
Training loss: 2.7676520381471827
Validation loss: 2.6413996361755783

Epoch: 371| Step: 0
Training loss: 2.6392246122014518
Validation loss: 2.6339494352341934

Epoch: 5| Step: 1
Training loss: 2.634995548743989
Validation loss: 2.6336130292224893

Epoch: 5| Step: 2
Training loss: 3.379160682933196
Validation loss: 2.6392792254538135

Epoch: 5| Step: 3
Training loss: 2.9604757547801523
Validation loss: 2.642664100279087

Epoch: 5| Step: 4
Training loss: 3.3685764360038197
Validation loss: 2.653419408084854

Epoch: 5| Step: 5
Training loss: 3.0708131648884702
Validation loss: 2.6602083133952963

Epoch: 5| Step: 6
Training loss: 2.766532447347503
Validation loss: 2.666862173630195

Epoch: 5| Step: 7
Training loss: 2.7851142184602384
Validation loss: 2.6734352720584122

Epoch: 5| Step: 8
Training loss: 2.944263220754207
Validation loss: 2.6798605182430295

Epoch: 5| Step: 9
Training loss: 3.3055193780652155
Validation loss: 2.6819296895565334

Epoch: 5| Step: 10
Training loss: 2.6006872405928725
Validation loss: 2.663247168185922

Epoch: 372| Step: 0
Training loss: 3.1176258821011653
Validation loss: 2.6747009563691146

Epoch: 5| Step: 1
Training loss: 2.846492911700696
Validation loss: 2.6652869489824655

Epoch: 5| Step: 2
Training loss: 3.3903985716985527
Validation loss: 2.6522755740131707

Epoch: 5| Step: 3
Training loss: 3.1847743928494543
Validation loss: 2.6494034960083512

Epoch: 5| Step: 4
Training loss: 3.2465549696782556
Validation loss: 2.6450749674134353

Epoch: 5| Step: 5
Training loss: 2.6778248354979035
Validation loss: 2.6477676625284094

Epoch: 5| Step: 6
Training loss: 2.52351525721313
Validation loss: 2.637381015191875

Epoch: 5| Step: 7
Training loss: 2.695575911324587
Validation loss: 2.639982146837917

Epoch: 5| Step: 8
Training loss: 2.959133595144216
Validation loss: 2.6475075084036734

Epoch: 5| Step: 9
Training loss: 2.955332097789949
Validation loss: 2.6521112442593986

Epoch: 5| Step: 10
Training loss: 2.8841893492825066
Validation loss: 2.6524186619195267

Epoch: 373| Step: 0
Training loss: 2.980442032000576
Validation loss: 2.6635978316826914

Epoch: 5| Step: 1
Training loss: 2.7358933946854984
Validation loss: 2.6703508135453484

Epoch: 5| Step: 2
Training loss: 2.9652737794402952
Validation loss: 2.6760252913519262

Epoch: 5| Step: 3
Training loss: 2.8595981198169005
Validation loss: 2.6845221327382762

Epoch: 5| Step: 4
Training loss: 3.8643951507294703
Validation loss: 2.683843686262792

Epoch: 5| Step: 5
Training loss: 3.003101970413617
Validation loss: 2.6790439140552897

Epoch: 5| Step: 6
Training loss: 3.0112514900276675
Validation loss: 2.6754788662543016

Epoch: 5| Step: 7
Training loss: 2.3771603446162635
Validation loss: 2.674987306316513

Epoch: 5| Step: 8
Training loss: 3.028158754961745
Validation loss: 2.6742471152002247

Epoch: 5| Step: 9
Training loss: 2.4343642581022027
Validation loss: 2.653739756459963

Epoch: 5| Step: 10
Training loss: 3.1167063712244616
Validation loss: 2.6468329443271403

Epoch: 374| Step: 0
Training loss: 2.6606007567312218
Validation loss: 2.648092192393081

Epoch: 5| Step: 1
Training loss: 2.940083118742936
Validation loss: 2.6499878110119655

Epoch: 5| Step: 2
Training loss: 3.48355092794205
Validation loss: 2.653784478320601

Epoch: 5| Step: 3
Training loss: 2.425620548251086
Validation loss: 2.6462781304710328

Epoch: 5| Step: 4
Training loss: 2.815390902492563
Validation loss: 2.651029113924193

Epoch: 5| Step: 5
Training loss: 2.571403295150536
Validation loss: 2.6440592563765937

Epoch: 5| Step: 6
Training loss: 2.855373897620913
Validation loss: 2.6482988667858134

Epoch: 5| Step: 7
Training loss: 3.3024973003136733
Validation loss: 2.6445198865267594

Epoch: 5| Step: 8
Training loss: 3.1476503055428324
Validation loss: 2.6457789554939506

Epoch: 5| Step: 9
Training loss: 3.407879500887013
Validation loss: 2.6337755638261893

Epoch: 5| Step: 10
Training loss: 2.7682534351642785
Validation loss: 2.64818885820152

Epoch: 375| Step: 0
Training loss: 3.368322760785432
Validation loss: 2.640993880241202

Epoch: 5| Step: 1
Training loss: 3.0816913219048105
Validation loss: 2.6467978441183413

Epoch: 5| Step: 2
Training loss: 3.199013951492056
Validation loss: 2.6496940494997046

Epoch: 5| Step: 3
Training loss: 2.807422972222853
Validation loss: 2.6544559913416537

Epoch: 5| Step: 4
Training loss: 2.760561861262297
Validation loss: 2.6613842868965683

Epoch: 5| Step: 5
Training loss: 3.179103188403851
Validation loss: 2.671162903124869

Epoch: 5| Step: 6
Training loss: 2.716730178683472
Validation loss: 2.671038145575593

Epoch: 5| Step: 7
Training loss: 2.5783264081484263
Validation loss: 2.668345123731463

Epoch: 5| Step: 8
Training loss: 3.0489214944563447
Validation loss: 2.6844330897707165

Epoch: 5| Step: 9
Training loss: 2.7021118205697996
Validation loss: 2.7022818557376342

Epoch: 5| Step: 10
Training loss: 3.0397744411311347
Validation loss: 2.6871997010138085

Epoch: 376| Step: 0
Training loss: 3.567122956676615
Validation loss: 2.6662598082920925

Epoch: 5| Step: 1
Training loss: 3.2817578603906536
Validation loss: 2.662407800199883

Epoch: 5| Step: 2
Training loss: 2.0390579398970203
Validation loss: 2.665687725197256

Epoch: 5| Step: 3
Training loss: 2.9357442275540113
Validation loss: 2.668008140681918

Epoch: 5| Step: 4
Training loss: 2.7109353892733137
Validation loss: 2.654025866172052

Epoch: 5| Step: 5
Training loss: 2.5316458498526067
Validation loss: 2.6573980061999882

Epoch: 5| Step: 6
Training loss: 3.3349450665343436
Validation loss: 2.656506398980509

Epoch: 5| Step: 7
Training loss: 3.355828830996053
Validation loss: 2.649885129422113

Epoch: 5| Step: 8
Training loss: 3.0443723132490295
Validation loss: 2.6404937985325017

Epoch: 5| Step: 9
Training loss: 2.954022306529791
Validation loss: 2.632853308582595

Epoch: 5| Step: 10
Training loss: 2.6068575473403306
Validation loss: 2.6228872333429787

Epoch: 377| Step: 0
Training loss: 2.6313284021870493
Validation loss: 2.6217545459045293

Epoch: 5| Step: 1
Training loss: 2.9574509679320413
Validation loss: 2.620821520415849

Epoch: 5| Step: 2
Training loss: 2.9186126938080563
Validation loss: 2.615730575846042

Epoch: 5| Step: 3
Training loss: 3.0805982538796974
Validation loss: 2.6172266303834797

Epoch: 5| Step: 4
Training loss: 2.762903631075354
Validation loss: 2.6273197739025256

Epoch: 5| Step: 5
Training loss: 3.2122557966577974
Validation loss: 2.633777081311071

Epoch: 5| Step: 6
Training loss: 3.493161468888819
Validation loss: 2.6312004288705535

Epoch: 5| Step: 7
Training loss: 2.8781684333763007
Validation loss: 2.6351115406668475

Epoch: 5| Step: 8
Training loss: 2.8672508627727016
Validation loss: 2.6439630552950018

Epoch: 5| Step: 9
Training loss: 2.8895515717014746
Validation loss: 2.635864166965613

Epoch: 5| Step: 10
Training loss: 2.676016826422781
Validation loss: 2.63678995915144

Epoch: 378| Step: 0
Training loss: 2.7833756456947
Validation loss: 2.634611158816745

Epoch: 5| Step: 1
Training loss: 2.972704051130948
Validation loss: 2.6351184597622943

Epoch: 5| Step: 2
Training loss: 2.731751409460978
Validation loss: 2.641436166885022

Epoch: 5| Step: 3
Training loss: 2.8696881856567535
Validation loss: 2.6446970549894213

Epoch: 5| Step: 4
Training loss: 2.98895136481517
Validation loss: 2.640797434122843

Epoch: 5| Step: 5
Training loss: 2.6568048234320885
Validation loss: 2.6482802911358747

Epoch: 5| Step: 6
Training loss: 3.3867899921320284
Validation loss: 2.6437743507260087

Epoch: 5| Step: 7
Training loss: 3.1102769013311504
Validation loss: 2.6530894441955573

Epoch: 5| Step: 8
Training loss: 2.9350075394437742
Validation loss: 2.6268705636325174

Epoch: 5| Step: 9
Training loss: 3.5016654003297774
Validation loss: 2.621293408723069

Epoch: 5| Step: 10
Training loss: 2.3276725175720183
Validation loss: 2.623743098155014

Epoch: 379| Step: 0
Training loss: 2.916100492475243
Validation loss: 2.628086708048095

Epoch: 5| Step: 1
Training loss: 3.0371574177269296
Validation loss: 2.618626037603685

Epoch: 5| Step: 2
Training loss: 3.1760836336477043
Validation loss: 2.619851166102442

Epoch: 5| Step: 3
Training loss: 3.105831561697484
Validation loss: 2.6204930654201877

Epoch: 5| Step: 4
Training loss: 2.4876623896208034
Validation loss: 2.6180987663841537

Epoch: 5| Step: 5
Training loss: 2.961266491813033
Validation loss: 2.6214832425904464

Epoch: 5| Step: 6
Training loss: 3.3823217868589674
Validation loss: 2.6159743196916545

Epoch: 5| Step: 7
Training loss: 2.704628057945072
Validation loss: 2.6194410182192303

Epoch: 5| Step: 8
Training loss: 2.6653228194942353
Validation loss: 2.615211469867678

Epoch: 5| Step: 9
Training loss: 3.049474614653324
Validation loss: 2.6186285467851054

Epoch: 5| Step: 10
Training loss: 2.9592792628430935
Validation loss: 2.6207910342159577

Epoch: 380| Step: 0
Training loss: 3.0894275100385045
Validation loss: 2.627594343082281

Epoch: 5| Step: 1
Training loss: 2.6142503341436742
Validation loss: 2.6195866473099088

Epoch: 5| Step: 2
Training loss: 3.0595152965948147
Validation loss: 2.628479748473346

Epoch: 5| Step: 3
Training loss: 2.4630886787808866
Validation loss: 2.63789883049351

Epoch: 5| Step: 4
Training loss: 3.258389867762063
Validation loss: 2.6359136494548814

Epoch: 5| Step: 5
Training loss: 2.8417066002628664
Validation loss: 2.6529841498906315

Epoch: 5| Step: 6
Training loss: 2.764917056752154
Validation loss: 2.6638387200483096

Epoch: 5| Step: 7
Training loss: 3.4237676812084805
Validation loss: 2.665643381440743

Epoch: 5| Step: 8
Training loss: 2.817602488186207
Validation loss: 2.664623296861427

Epoch: 5| Step: 9
Training loss: 3.033046229542503
Validation loss: 2.6755569362787854

Epoch: 5| Step: 10
Training loss: 3.061239021876609
Validation loss: 2.644359868864605

Epoch: 381| Step: 0
Training loss: 2.856268023344308
Validation loss: 2.6324281633197084

Epoch: 5| Step: 1
Training loss: 3.2374088230328852
Validation loss: 2.624856908817397

Epoch: 5| Step: 2
Training loss: 3.437533569172026
Validation loss: 2.6181495736083407

Epoch: 5| Step: 3
Training loss: 3.3026582877194386
Validation loss: 2.6133422756146714

Epoch: 5| Step: 4
Training loss: 2.366682747889225
Validation loss: 2.616811766427924

Epoch: 5| Step: 5
Training loss: 2.576727285951028
Validation loss: 2.6173122885004787

Epoch: 5| Step: 6
Training loss: 2.8264973208544464
Validation loss: 2.618164391502759

Epoch: 5| Step: 7
Training loss: 2.4836403582274373
Validation loss: 2.6137700250934404

Epoch: 5| Step: 8
Training loss: 3.3244551362779737
Validation loss: 2.6189915421444434

Epoch: 5| Step: 9
Training loss: 2.711033888100929
Validation loss: 2.618711305348514

Epoch: 5| Step: 10
Training loss: 3.1979175944539233
Validation loss: 2.620646427800893

Epoch: 382| Step: 0
Training loss: 3.0627696638689654
Validation loss: 2.6179829774162124

Epoch: 5| Step: 1
Training loss: 2.657258414540582
Validation loss: 2.6167032860672332

Epoch: 5| Step: 2
Training loss: 3.224054798332585
Validation loss: 2.613618391647135

Epoch: 5| Step: 3
Training loss: 3.4534820786283555
Validation loss: 2.620627275602706

Epoch: 5| Step: 4
Training loss: 2.5615378643739266
Validation loss: 2.6199761271537874

Epoch: 5| Step: 5
Training loss: 2.7321659429093077
Validation loss: 2.6182686656691065

Epoch: 5| Step: 6
Training loss: 3.348470332936614
Validation loss: 2.624746010520216

Epoch: 5| Step: 7
Training loss: 2.310256178716466
Validation loss: 2.6441806446834515

Epoch: 5| Step: 8
Training loss: 2.8336597890339257
Validation loss: 2.6358804122479444

Epoch: 5| Step: 9
Training loss: 2.7270565951566272
Validation loss: 2.6400101488262635

Epoch: 5| Step: 10
Training loss: 3.366332899362607
Validation loss: 2.6551000761339103

Epoch: 383| Step: 0
Training loss: 2.992257777252786
Validation loss: 2.6647399699158862

Epoch: 5| Step: 1
Training loss: 2.6672427528705516
Validation loss: 2.652233932386519

Epoch: 5| Step: 2
Training loss: 2.7982145543323935
Validation loss: 2.647170615377463

Epoch: 5| Step: 3
Training loss: 3.051225578588562
Validation loss: 2.660036457147172

Epoch: 5| Step: 4
Training loss: 2.8675696510695867
Validation loss: 2.6353279123792044

Epoch: 5| Step: 5
Training loss: 3.1563475943102968
Validation loss: 2.637373468260181

Epoch: 5| Step: 6
Training loss: 2.9764522822441757
Validation loss: 2.6202145977193716

Epoch: 5| Step: 7
Training loss: 2.8976478837777746
Validation loss: 2.62676099861543

Epoch: 5| Step: 8
Training loss: 3.492111717272322
Validation loss: 2.6089822582781044

Epoch: 5| Step: 9
Training loss: 2.645175421509712
Validation loss: 2.6277461944343385

Epoch: 5| Step: 10
Training loss: 2.872981482409276
Validation loss: 2.6229848563829363

Epoch: 384| Step: 0
Training loss: 2.8250795268790077
Validation loss: 2.6234891208646918

Epoch: 5| Step: 1
Training loss: 2.3468534140984656
Validation loss: 2.618307370621969

Epoch: 5| Step: 2
Training loss: 2.9336161809437047
Validation loss: 2.617333922486209

Epoch: 5| Step: 3
Training loss: 3.1880100814487626
Validation loss: 2.6289879478207325

Epoch: 5| Step: 4
Training loss: 3.140557587312883
Validation loss: 2.624512799586393

Epoch: 5| Step: 5
Training loss: 3.23728067840833
Validation loss: 2.63033414377559

Epoch: 5| Step: 6
Training loss: 2.8106751349729957
Validation loss: 2.6325835999369516

Epoch: 5| Step: 7
Training loss: 3.172607187034067
Validation loss: 2.631607581810205

Epoch: 5| Step: 8
Training loss: 2.963358913120993
Validation loss: 2.656933830012216

Epoch: 5| Step: 9
Training loss: 2.632375165799755
Validation loss: 2.635167118624558

Epoch: 5| Step: 10
Training loss: 3.0461647183921534
Validation loss: 2.641525965313958

Epoch: 385| Step: 0
Training loss: 2.1372790395290124
Validation loss: 2.6477842540175014

Epoch: 5| Step: 1
Training loss: 2.5964686841334226
Validation loss: 2.6453261841761897

Epoch: 5| Step: 2
Training loss: 3.118150758222087
Validation loss: 2.641644238361603

Epoch: 5| Step: 3
Training loss: 2.6209770438168833
Validation loss: 2.645552968105383

Epoch: 5| Step: 4
Training loss: 2.9502187486138807
Validation loss: 2.645216420245929

Epoch: 5| Step: 5
Training loss: 3.131211173603002
Validation loss: 2.647507332169004

Epoch: 5| Step: 6
Training loss: 3.0871347929525847
Validation loss: 2.651393690444951

Epoch: 5| Step: 7
Training loss: 3.335605006208962
Validation loss: 2.6233753258957564

Epoch: 5| Step: 8
Training loss: 2.6034040834953855
Validation loss: 2.648303638216058

Epoch: 5| Step: 9
Training loss: 3.2216127867977993
Validation loss: 2.6412432245979116

Epoch: 5| Step: 10
Training loss: 3.4049957485984668
Validation loss: 2.6444663441540763

Epoch: 386| Step: 0
Training loss: 2.4124456132678094
Validation loss: 2.630799533351513

Epoch: 5| Step: 1
Training loss: 2.8785617161546035
Validation loss: 2.6403182006165564

Epoch: 5| Step: 2
Training loss: 2.6929368316290465
Validation loss: 2.634835116114482

Epoch: 5| Step: 3
Training loss: 3.4072261426536716
Validation loss: 2.6334973528997025

Epoch: 5| Step: 4
Training loss: 2.717000639656
Validation loss: 2.6343513821793048

Epoch: 5| Step: 5
Training loss: 2.970211913900515
Validation loss: 2.620650561871276

Epoch: 5| Step: 6
Training loss: 3.3402302122441463
Validation loss: 2.635732391977153

Epoch: 5| Step: 7
Training loss: 2.7316976464101197
Validation loss: 2.6371222094000077

Epoch: 5| Step: 8
Training loss: 3.027826479909945
Validation loss: 2.6413376107479283

Epoch: 5| Step: 9
Training loss: 2.984313484876075
Validation loss: 2.653791727414569

Epoch: 5| Step: 10
Training loss: 3.05754170649008
Validation loss: 2.6548216442412476

Epoch: 387| Step: 0
Training loss: 3.1875730019979787
Validation loss: 2.6636562791310894

Epoch: 5| Step: 1
Training loss: 2.711844960239967
Validation loss: 2.6556704579630197

Epoch: 5| Step: 2
Training loss: 3.268388518847145
Validation loss: 2.6560816190892975

Epoch: 5| Step: 3
Training loss: 2.8078287114613123
Validation loss: 2.6523391491860937

Epoch: 5| Step: 4
Training loss: 2.7873564131495243
Validation loss: 2.655456331744599

Epoch: 5| Step: 5
Training loss: 2.6304402969856318
Validation loss: 2.6526647685165763

Epoch: 5| Step: 6
Training loss: 3.6420155763245874
Validation loss: 2.6590565196313185

Epoch: 5| Step: 7
Training loss: 2.160071152292231
Validation loss: 2.658704957289346

Epoch: 5| Step: 8
Training loss: 3.574249967845226
Validation loss: 2.6578536113409665

Epoch: 5| Step: 9
Training loss: 3.143883073238927
Validation loss: 2.649837507063247

Epoch: 5| Step: 10
Training loss: 1.7057369397012976
Validation loss: 2.635740576799906

Epoch: 388| Step: 0
Training loss: 3.3086882918900997
Validation loss: 2.6354836516983253

Epoch: 5| Step: 1
Training loss: 2.7107047824847403
Validation loss: 2.618585535969714

Epoch: 5| Step: 2
Training loss: 2.9687826054438933
Validation loss: 2.6278668407531245

Epoch: 5| Step: 3
Training loss: 2.5153277677664345
Validation loss: 2.6225247234386293

Epoch: 5| Step: 4
Training loss: 2.7990426129759745
Validation loss: 2.630116637995288

Epoch: 5| Step: 5
Training loss: 3.2778951297018706
Validation loss: 2.628840048514306

Epoch: 5| Step: 6
Training loss: 2.5500857469690175
Validation loss: 2.6182342938596896

Epoch: 5| Step: 7
Training loss: 3.289840207610967
Validation loss: 2.6277582723885167

Epoch: 5| Step: 8
Training loss: 2.5250845337871355
Validation loss: 2.639256983589423

Epoch: 5| Step: 9
Training loss: 2.935301262180061
Validation loss: 2.6330635148563952

Epoch: 5| Step: 10
Training loss: 3.3671951470874593
Validation loss: 2.621183956810488

Epoch: 389| Step: 0
Training loss: 1.9890152751054129
Validation loss: 2.6258680780466643

Epoch: 5| Step: 1
Training loss: 3.518783303572415
Validation loss: 2.618258578592464

Epoch: 5| Step: 2
Training loss: 2.7415296846932815
Validation loss: 2.627806199270791

Epoch: 5| Step: 3
Training loss: 3.281214105318921
Validation loss: 2.615554077984079

Epoch: 5| Step: 4
Training loss: 2.620884166360002
Validation loss: 2.6242255534864807

Epoch: 5| Step: 5
Training loss: 2.5403927179548416
Validation loss: 2.6288956790941866

Epoch: 5| Step: 6
Training loss: 3.0180123322312653
Validation loss: 2.6193150832357714

Epoch: 5| Step: 7
Training loss: 3.0233248904053194
Validation loss: 2.6248379582610277

Epoch: 5| Step: 8
Training loss: 2.7105941335140207
Validation loss: 2.640217118940201

Epoch: 5| Step: 9
Training loss: 3.485331040672282
Validation loss: 2.6253482716483463

Epoch: 5| Step: 10
Training loss: 3.106822744331782
Validation loss: 2.633866121782877

Epoch: 390| Step: 0
Training loss: 2.9702687444378784
Validation loss: 2.6344277029514878

Epoch: 5| Step: 1
Training loss: 2.6692521455932465
Validation loss: 2.6216312772573573

Epoch: 5| Step: 2
Training loss: 3.0720815439726503
Validation loss: 2.635584451422828

Epoch: 5| Step: 3
Training loss: 3.0342353199357506
Validation loss: 2.624351309977451

Epoch: 5| Step: 4
Training loss: 2.1238793054545693
Validation loss: 2.623587369359653

Epoch: 5| Step: 5
Training loss: 2.998143416350746
Validation loss: 2.6249720361473123

Epoch: 5| Step: 6
Training loss: 3.0735796369490687
Validation loss: 2.6242157174172913

Epoch: 5| Step: 7
Training loss: 3.105124323716341
Validation loss: 2.629169268535544

Epoch: 5| Step: 8
Training loss: 2.9808856477555654
Validation loss: 2.6368649658595236

Epoch: 5| Step: 9
Training loss: 2.578692194650889
Validation loss: 2.6408416199015274

Epoch: 5| Step: 10
Training loss: 3.5943136022050295
Validation loss: 2.636428633528458

Epoch: 391| Step: 0
Training loss: 2.7197078902803824
Validation loss: 2.64905633816268

Epoch: 5| Step: 1
Training loss: 2.699740192487713
Validation loss: 2.6528036519351663

Epoch: 5| Step: 2
Training loss: 2.9473178826028996
Validation loss: 2.6584444616914293

Epoch: 5| Step: 3
Training loss: 2.732910287109721
Validation loss: 2.6690408196479614

Epoch: 5| Step: 4
Training loss: 2.819907542397172
Validation loss: 2.6753041607871046

Epoch: 5| Step: 5
Training loss: 2.917387101343336
Validation loss: 2.691944868006935

Epoch: 5| Step: 6
Training loss: 3.35193665734578
Validation loss: 2.715016840317467

Epoch: 5| Step: 7
Training loss: 2.9005796839686644
Validation loss: 2.7003661205612475

Epoch: 5| Step: 8
Training loss: 3.593637879322656
Validation loss: 2.685738526427621

Epoch: 5| Step: 9
Training loss: 2.636850130552063
Validation loss: 2.6652093284017173

Epoch: 5| Step: 10
Training loss: 2.8979016243064075
Validation loss: 2.6324658780809593

Epoch: 392| Step: 0
Training loss: 2.9159165280591277
Validation loss: 2.6295305601839387

Epoch: 5| Step: 1
Training loss: 2.7865102507606165
Validation loss: 2.6181694900610597

Epoch: 5| Step: 2
Training loss: 2.300380600661106
Validation loss: 2.615051563595085

Epoch: 5| Step: 3
Training loss: 3.1199018472735793
Validation loss: 2.6304885940745923

Epoch: 5| Step: 4
Training loss: 2.916198929111804
Validation loss: 2.626724182806986

Epoch: 5| Step: 5
Training loss: 3.142668860852146
Validation loss: 2.6168295201458625

Epoch: 5| Step: 6
Training loss: 2.7417567422866878
Validation loss: 2.616823113068079

Epoch: 5| Step: 7
Training loss: 3.274407946236459
Validation loss: 2.620781136835896

Epoch: 5| Step: 8
Training loss: 2.985910869262049
Validation loss: 2.617771489668877

Epoch: 5| Step: 9
Training loss: 3.1298147113788506
Validation loss: 2.628732716473787

Epoch: 5| Step: 10
Training loss: 2.961255703135997
Validation loss: 2.623889920813254

Epoch: 393| Step: 0
Training loss: 2.9588546472696886
Validation loss: 2.6298675079111793

Epoch: 5| Step: 1
Training loss: 2.9723498553702803
Validation loss: 2.6282380052005583

Epoch: 5| Step: 2
Training loss: 2.923802357205258
Validation loss: 2.64422938886016

Epoch: 5| Step: 3
Training loss: 3.028895299230994
Validation loss: 2.642499816028679

Epoch: 5| Step: 4
Training loss: 2.733141462833451
Validation loss: 2.6403503372209074

Epoch: 5| Step: 5
Training loss: 2.732246486005706
Validation loss: 2.6607886379423125

Epoch: 5| Step: 6
Training loss: 3.0919091498881577
Validation loss: 2.6763909088712707

Epoch: 5| Step: 7
Training loss: 2.7277671098554457
Validation loss: 2.6661000079113304

Epoch: 5| Step: 8
Training loss: 3.58541487332258
Validation loss: 2.6640290808627203

Epoch: 5| Step: 9
Training loss: 2.8921402542484245
Validation loss: 2.657815106106871

Epoch: 5| Step: 10
Training loss: 2.460869875993004
Validation loss: 2.6502893122779723

Epoch: 394| Step: 0
Training loss: 2.5949855757001887
Validation loss: 2.637259739683574

Epoch: 5| Step: 1
Training loss: 2.7648326363708007
Validation loss: 2.6374854160860717

Epoch: 5| Step: 2
Training loss: 3.074262800470614
Validation loss: 2.623903151830943

Epoch: 5| Step: 3
Training loss: 2.8677306115591876
Validation loss: 2.6200289439706967

Epoch: 5| Step: 4
Training loss: 3.2915098096599076
Validation loss: 2.6119461463985028

Epoch: 5| Step: 5
Training loss: 2.491297260913745
Validation loss: 2.6136784304965204

Epoch: 5| Step: 6
Training loss: 3.2856516062047656
Validation loss: 2.6079764756735226

Epoch: 5| Step: 7
Training loss: 3.0009176122484487
Validation loss: 2.6120646193296304

Epoch: 5| Step: 8
Training loss: 2.6175964946867922
Validation loss: 2.612241303889498

Epoch: 5| Step: 9
Training loss: 2.8211825817133485
Validation loss: 2.6173808923126023

Epoch: 5| Step: 10
Training loss: 3.436975751261318
Validation loss: 2.6105428008994784

Epoch: 395| Step: 0
Training loss: 3.1121606664786845
Validation loss: 2.6202203781513185

Epoch: 5| Step: 1
Training loss: 2.7209316576667923
Validation loss: 2.6259838083051674

Epoch: 5| Step: 2
Training loss: 2.7686950540364847
Validation loss: 2.6269023777676197

Epoch: 5| Step: 3
Training loss: 2.9421943328178424
Validation loss: 2.644686646074243

Epoch: 5| Step: 4
Training loss: 2.847670818024722
Validation loss: 2.6396000049882122

Epoch: 5| Step: 5
Training loss: 2.735019629650353
Validation loss: 2.6327505429689952

Epoch: 5| Step: 6
Training loss: 2.7757087970772214
Validation loss: 2.627082790461128

Epoch: 5| Step: 7
Training loss: 3.039679535739364
Validation loss: 2.62629807074079

Epoch: 5| Step: 8
Training loss: 3.2014237514830897
Validation loss: 2.6166114933641746

Epoch: 5| Step: 9
Training loss: 3.126441623042087
Validation loss: 2.6130124556615737

Epoch: 5| Step: 10
Training loss: 3.0018328789657405
Validation loss: 2.62590289372663

Epoch: 396| Step: 0
Training loss: 2.446098908059826
Validation loss: 2.620805134836673

Epoch: 5| Step: 1
Training loss: 2.987659185150845
Validation loss: 2.6219749795260823

Epoch: 5| Step: 2
Training loss: 3.075374555648749
Validation loss: 2.629944587543931

Epoch: 5| Step: 3
Training loss: 2.8974123887384478
Validation loss: 2.6345645020153388

Epoch: 5| Step: 4
Training loss: 3.0298486990340106
Validation loss: 2.628600517169767

Epoch: 5| Step: 5
Training loss: 3.1345598099783554
Validation loss: 2.628367545826049

Epoch: 5| Step: 6
Training loss: 2.9512335962068272
Validation loss: 2.6554588437760334

Epoch: 5| Step: 7
Training loss: 2.6763923337058935
Validation loss: 2.654419358765866

Epoch: 5| Step: 8
Training loss: 3.1112767830136905
Validation loss: 2.6497893546323685

Epoch: 5| Step: 9
Training loss: 2.8480642939500407
Validation loss: 2.6351070304030606

Epoch: 5| Step: 10
Training loss: 3.0561652548182505
Validation loss: 2.651742442973617

Epoch: 397| Step: 0
Training loss: 2.33727519540389
Validation loss: 2.634479684123965

Epoch: 5| Step: 1
Training loss: 3.429765496203458
Validation loss: 2.6261508233563653

Epoch: 5| Step: 2
Training loss: 2.919787635396696
Validation loss: 2.6202336291661723

Epoch: 5| Step: 3
Training loss: 2.4723984040002587
Validation loss: 2.6243713551995733

Epoch: 5| Step: 4
Training loss: 3.103464768354945
Validation loss: 2.6263957954088415

Epoch: 5| Step: 5
Training loss: 2.870590311144388
Validation loss: 2.6299300163599746

Epoch: 5| Step: 6
Training loss: 3.2372624137040025
Validation loss: 2.6281709421456334

Epoch: 5| Step: 7
Training loss: 3.4571493182521644
Validation loss: 2.626662398392577

Epoch: 5| Step: 8
Training loss: 2.6066592583546973
Validation loss: 2.6418548397661676

Epoch: 5| Step: 9
Training loss: 2.7453476827035552
Validation loss: 2.641914103016543

Epoch: 5| Step: 10
Training loss: 2.8224393903308296
Validation loss: 2.6467971079959516

Epoch: 398| Step: 0
Training loss: 3.1865900274129424
Validation loss: 2.6341913521582083

Epoch: 5| Step: 1
Training loss: 3.058501923060814
Validation loss: 2.6258036715806297

Epoch: 5| Step: 2
Training loss: 2.8498965060533066
Validation loss: 2.6265458615590496

Epoch: 5| Step: 3
Training loss: 2.557314673875126
Validation loss: 2.627240907674394

Epoch: 5| Step: 4
Training loss: 3.4049073819239166
Validation loss: 2.628588797116455

Epoch: 5| Step: 5
Training loss: 3.153464721888809
Validation loss: 2.6311493124357774

Epoch: 5| Step: 6
Training loss: 2.5167738855861113
Validation loss: 2.622043739994332

Epoch: 5| Step: 7
Training loss: 3.0855154787082406
Validation loss: 2.6376903576243658

Epoch: 5| Step: 8
Training loss: 2.6467157129056016
Validation loss: 2.62790575553609

Epoch: 5| Step: 9
Training loss: 2.332613107242831
Validation loss: 2.629954956352389

Epoch: 5| Step: 10
Training loss: 3.315095856030104
Validation loss: 2.6259540410196966

Epoch: 399| Step: 0
Training loss: 2.839874981022389
Validation loss: 2.635613818618779

Epoch: 5| Step: 1
Training loss: 2.890783852001339
Validation loss: 2.6341556085633684

Epoch: 5| Step: 2
Training loss: 2.932781406699105
Validation loss: 2.6320970678818907

Epoch: 5| Step: 3
Training loss: 3.535722044458725
Validation loss: 2.6283166425293354

Epoch: 5| Step: 4
Training loss: 2.968469867539872
Validation loss: 2.630706124648587

Epoch: 5| Step: 5
Training loss: 2.890504246844379
Validation loss: 2.621730717938258

Epoch: 5| Step: 6
Training loss: 2.7654881847614052
Validation loss: 2.6187634947150067

Epoch: 5| Step: 7
Training loss: 2.986198786747079
Validation loss: 2.621731957842698

Epoch: 5| Step: 8
Training loss: 2.419632494898734
Validation loss: 2.6296222831079366

Epoch: 5| Step: 9
Training loss: 3.009289188290518
Validation loss: 2.6250603332461444

Epoch: 5| Step: 10
Training loss: 2.867201303557968
Validation loss: 2.628668770788293

Epoch: 400| Step: 0
Training loss: 2.969664583371653
Validation loss: 2.644874949211206

Epoch: 5| Step: 1
Training loss: 2.6168684579910053
Validation loss: 2.644727337351929

Epoch: 5| Step: 2
Training loss: 2.9820736305157496
Validation loss: 2.645198305595339

Epoch: 5| Step: 3
Training loss: 2.9024833963923045
Validation loss: 2.644303812259715

Epoch: 5| Step: 4
Training loss: 2.9608940181710017
Validation loss: 2.6523785844748993

Epoch: 5| Step: 5
Training loss: 2.4052619391726786
Validation loss: 2.6426144657677417

Epoch: 5| Step: 6
Training loss: 3.435741043892994
Validation loss: 2.6451955618802883

Epoch: 5| Step: 7
Training loss: 2.931821976350744
Validation loss: 2.6435683738318176

Epoch: 5| Step: 8
Training loss: 3.3188132817041573
Validation loss: 2.624324299482292

Epoch: 5| Step: 9
Training loss: 2.7500127445272424
Validation loss: 2.61860854375505

Epoch: 5| Step: 10
Training loss: 2.832930554950969
Validation loss: 2.614682024648999

Epoch: 401| Step: 0
Training loss: 2.58252585517223
Validation loss: 2.6150030559033404

Epoch: 5| Step: 1
Training loss: 3.159373635613423
Validation loss: 2.5957259780832214

Epoch: 5| Step: 2
Training loss: 2.662824594832611
Validation loss: 2.6062695471984054

Epoch: 5| Step: 3
Training loss: 2.755624740853214
Validation loss: 2.6027383400920336

Epoch: 5| Step: 4
Training loss: 3.4605018220942716
Validation loss: 2.6087168192030723

Epoch: 5| Step: 5
Training loss: 2.8490440639356684
Validation loss: 2.6039783736216275

Epoch: 5| Step: 6
Training loss: 2.589299439642848
Validation loss: 2.6133758632271604

Epoch: 5| Step: 7
Training loss: 2.8325624165135044
Validation loss: 2.6132590066095673

Epoch: 5| Step: 8
Training loss: 3.072103429394264
Validation loss: 2.6041723225850038

Epoch: 5| Step: 9
Training loss: 3.1616693182253606
Validation loss: 2.610387980682236

Epoch: 5| Step: 10
Training loss: 3.003438885944171
Validation loss: 2.6205812013634606

Epoch: 402| Step: 0
Training loss: 2.6059521365392246
Validation loss: 2.6189862836733493

Epoch: 5| Step: 1
Training loss: 2.9849820942557335
Validation loss: 2.6324819222968077

Epoch: 5| Step: 2
Training loss: 3.0687831340795704
Validation loss: 2.6528522666617107

Epoch: 5| Step: 3
Training loss: 2.3727957887034687
Validation loss: 2.659437309761284

Epoch: 5| Step: 4
Training loss: 2.0502297668091263
Validation loss: 2.6597586730957072

Epoch: 5| Step: 5
Training loss: 2.9190023243742282
Validation loss: 2.6560617861579328

Epoch: 5| Step: 6
Training loss: 3.2274434731968062
Validation loss: 2.657628377710879

Epoch: 5| Step: 7
Training loss: 3.5552830459220957
Validation loss: 2.650760879376192

Epoch: 5| Step: 8
Training loss: 2.7670766178189963
Validation loss: 2.639451416289749

Epoch: 5| Step: 9
Training loss: 3.16699007959381
Validation loss: 2.6439325498901844

Epoch: 5| Step: 10
Training loss: 3.280936525902248
Validation loss: 2.6184302836933133

Epoch: 403| Step: 0
Training loss: 3.027676865493288
Validation loss: 2.609003514247992

Epoch: 5| Step: 1
Training loss: 3.127475825886414
Validation loss: 2.6058685359584475

Epoch: 5| Step: 2
Training loss: 3.258493914797669
Validation loss: 2.61099924947406

Epoch: 5| Step: 3
Training loss: 2.700760617672538
Validation loss: 2.6026776341900315

Epoch: 5| Step: 4
Training loss: 2.587807063067183
Validation loss: 2.6036374088751333

Epoch: 5| Step: 5
Training loss: 3.190384999065276
Validation loss: 2.60998155650926

Epoch: 5| Step: 6
Training loss: 2.7807567030381675
Validation loss: 2.6189175153687625

Epoch: 5| Step: 7
Training loss: 2.6225474571683347
Validation loss: 2.602971291796136

Epoch: 5| Step: 8
Training loss: 3.071012849016305
Validation loss: 2.6162251010221045

Epoch: 5| Step: 9
Training loss: 3.209084526073347
Validation loss: 2.6145320590373404

Epoch: 5| Step: 10
Training loss: 2.4117175320646016
Validation loss: 2.613894719782844

Epoch: 404| Step: 0
Training loss: 3.377356801304516
Validation loss: 2.626877062339424

Epoch: 5| Step: 1
Training loss: 3.2066366159639634
Validation loss: 2.633666540129271

Epoch: 5| Step: 2
Training loss: 2.4668723583376426
Validation loss: 2.6252133760781167

Epoch: 5| Step: 3
Training loss: 3.14790494972605
Validation loss: 2.6360089373695907

Epoch: 5| Step: 4
Training loss: 2.7100682692708844
Validation loss: 2.6325673216507255

Epoch: 5| Step: 5
Training loss: 3.296345889765755
Validation loss: 2.631778658535555

Epoch: 5| Step: 6
Training loss: 2.8696921735756855
Validation loss: 2.639491774517461

Epoch: 5| Step: 7
Training loss: 2.424546276000979
Validation loss: 2.6196295536119476

Epoch: 5| Step: 8
Training loss: 2.837406839194189
Validation loss: 2.6103813328943644

Epoch: 5| Step: 9
Training loss: 2.872049227173111
Validation loss: 2.61027874621815

Epoch: 5| Step: 10
Training loss: 2.7925611932208936
Validation loss: 2.607000813213761

Epoch: 405| Step: 0
Training loss: 2.742208801360686
Validation loss: 2.6172039023509677

Epoch: 5| Step: 1
Training loss: 2.6860101695546366
Validation loss: 2.6297560342028565

Epoch: 5| Step: 2
Training loss: 2.8090158710350512
Validation loss: 2.6501132025737646

Epoch: 5| Step: 3
Training loss: 2.9073451450139745
Validation loss: 2.6359125815602678

Epoch: 5| Step: 4
Training loss: 2.9089543055843174
Validation loss: 2.639324254504786

Epoch: 5| Step: 5
Training loss: 2.520597483633496
Validation loss: 2.630847777559041

Epoch: 5| Step: 6
Training loss: 2.776129820797541
Validation loss: 2.6392210473030935

Epoch: 5| Step: 7
Training loss: 3.602467321900212
Validation loss: 2.641241757021703

Epoch: 5| Step: 8
Training loss: 3.1190706076792294
Validation loss: 2.6292479267638225

Epoch: 5| Step: 9
Training loss: 3.1858933831603258
Validation loss: 2.6188104849110876

Epoch: 5| Step: 10
Training loss: 2.712192387871503
Validation loss: 2.6384981204649733

Epoch: 406| Step: 0
Training loss: 3.2525750742523165
Validation loss: 2.623822874619643

Epoch: 5| Step: 1
Training loss: 2.9148174054650746
Validation loss: 2.631742775992804

Epoch: 5| Step: 2
Training loss: 3.516895115620092
Validation loss: 2.6555920736137457

Epoch: 5| Step: 3
Training loss: 2.6837468221616296
Validation loss: 2.631702384655166

Epoch: 5| Step: 4
Training loss: 3.3314955572550677
Validation loss: 2.629096085115661

Epoch: 5| Step: 5
Training loss: 2.2675577272849803
Validation loss: 2.611003112115845

Epoch: 5| Step: 6
Training loss: 2.5689106280742737
Validation loss: 2.615055070270262

Epoch: 5| Step: 7
Training loss: 2.975397477724894
Validation loss: 2.6210303637499157

Epoch: 5| Step: 8
Training loss: 2.597777583221321
Validation loss: 2.624852863412995

Epoch: 5| Step: 9
Training loss: 3.058898364959732
Validation loss: 2.62215750280381

Epoch: 5| Step: 10
Training loss: 2.675744539552007
Validation loss: 2.627258615311975

Epoch: 407| Step: 0
Training loss: 2.7683723726071077
Validation loss: 2.63899037357242

Epoch: 5| Step: 1
Training loss: 2.944361849492115
Validation loss: 2.648966877271057

Epoch: 5| Step: 2
Training loss: 2.7122282533718787
Validation loss: 2.643735073154806

Epoch: 5| Step: 3
Training loss: 3.4288078692062443
Validation loss: 2.6405670136348607

Epoch: 5| Step: 4
Training loss: 2.5838172725931363
Validation loss: 2.6723524232107185

Epoch: 5| Step: 5
Training loss: 2.9928884457116207
Validation loss: 2.6703308024197097

Epoch: 5| Step: 6
Training loss: 2.9818096219445325
Validation loss: 2.6700208460324433

Epoch: 5| Step: 7
Training loss: 3.030089638016754
Validation loss: 2.6395210695887674

Epoch: 5| Step: 8
Training loss: 2.671301439974386
Validation loss: 2.6156128325375176

Epoch: 5| Step: 9
Training loss: 3.0369938181392495
Validation loss: 2.601230995248469

Epoch: 5| Step: 10
Training loss: 2.842935969621575
Validation loss: 2.609953804019042

Epoch: 408| Step: 0
Training loss: 2.473027639836939
Validation loss: 2.5974086058997545

Epoch: 5| Step: 1
Training loss: 3.137079163554175
Validation loss: 2.5965170804498796

Epoch: 5| Step: 2
Training loss: 3.5986566633368366
Validation loss: 2.5889918596783463

Epoch: 5| Step: 3
Training loss: 3.00538501627817
Validation loss: 2.5985295163502493

Epoch: 5| Step: 4
Training loss: 2.784740786174775
Validation loss: 2.606524912201394

Epoch: 5| Step: 5
Training loss: 2.7757794015944275
Validation loss: 2.6118387939441314

Epoch: 5| Step: 6
Training loss: 3.0698592843974097
Validation loss: 2.6132222095399444

Epoch: 5| Step: 7
Training loss: 2.811528271124058
Validation loss: 2.6176971091229553

Epoch: 5| Step: 8
Training loss: 2.36133701016732
Validation loss: 2.6458067071873455

Epoch: 5| Step: 9
Training loss: 3.044382650749102
Validation loss: 2.635971287889873

Epoch: 5| Step: 10
Training loss: 2.959012253633107
Validation loss: 2.6530091794809905

Epoch: 409| Step: 0
Training loss: 3.26478923707369
Validation loss: 2.632888219818116

Epoch: 5| Step: 1
Training loss: 3.392363774847267
Validation loss: 2.6265196661929298

Epoch: 5| Step: 2
Training loss: 2.885147596315803
Validation loss: 2.6166898129016016

Epoch: 5| Step: 3
Training loss: 2.725322102399754
Validation loss: 2.60070453265084

Epoch: 5| Step: 4
Training loss: 2.9787394255059434
Validation loss: 2.6084954548682937

Epoch: 5| Step: 5
Training loss: 2.4787997660832697
Validation loss: 2.6040539493572683

Epoch: 5| Step: 6
Training loss: 2.37740064058357
Validation loss: 2.6191467073173293

Epoch: 5| Step: 7
Training loss: 3.1462581086688908
Validation loss: 2.6264388579232287

Epoch: 5| Step: 8
Training loss: 3.0106194415762797
Validation loss: 2.6255478255563935

Epoch: 5| Step: 9
Training loss: 2.96145504577719
Validation loss: 2.622730814464014

Epoch: 5| Step: 10
Training loss: 2.8094621146234804
Validation loss: 2.6156725149133964

Epoch: 410| Step: 0
Training loss: 3.1750585055029616
Validation loss: 2.613516251811855

Epoch: 5| Step: 1
Training loss: 2.8206163068384242
Validation loss: 2.6196285397540118

Epoch: 5| Step: 2
Training loss: 3.2256842427023393
Validation loss: 2.6102393211415342

Epoch: 5| Step: 3
Training loss: 2.7181412464743095
Validation loss: 2.6124401338256114

Epoch: 5| Step: 4
Training loss: 2.758233230095893
Validation loss: 2.613919380254279

Epoch: 5| Step: 5
Training loss: 2.959304560595418
Validation loss: 2.625061053978733

Epoch: 5| Step: 6
Training loss: 2.460587734010949
Validation loss: 2.6505381042672083

Epoch: 5| Step: 7
Training loss: 2.975096013419147
Validation loss: 2.6640783808719037

Epoch: 5| Step: 8
Training loss: 2.6015346399596826
Validation loss: 2.695220195229434

Epoch: 5| Step: 9
Training loss: 3.149965128629914
Validation loss: 2.733567422191531

Epoch: 5| Step: 10
Training loss: 3.2570223135858756
Validation loss: 2.6908102422932223

Epoch: 411| Step: 0
Training loss: 3.1871545641847083
Validation loss: 2.675490580208972

Epoch: 5| Step: 1
Training loss: 3.0819718387809876
Validation loss: 2.6394107961671915

Epoch: 5| Step: 2
Training loss: 2.74884190883219
Validation loss: 2.6079736259552324

Epoch: 5| Step: 3
Training loss: 2.790512349246132
Validation loss: 2.5976053853914447

Epoch: 5| Step: 4
Training loss: 3.1624304058876174
Validation loss: 2.600088110480704

Epoch: 5| Step: 5
Training loss: 2.8413585626325504
Validation loss: 2.5958204351619036

Epoch: 5| Step: 6
Training loss: 2.4871946444542403
Validation loss: 2.5914457859395363

Epoch: 5| Step: 7
Training loss: 3.2456398105999638
Validation loss: 2.5945106435745213

Epoch: 5| Step: 8
Training loss: 2.8062978387845865
Validation loss: 2.5926675189533688

Epoch: 5| Step: 9
Training loss: 2.5855564170853818
Validation loss: 2.594266845667911

Epoch: 5| Step: 10
Training loss: 3.3109468381641114
Validation loss: 2.59243140548078

Epoch: 412| Step: 0
Training loss: 3.1768150007821254
Validation loss: 2.5941957015944634

Epoch: 5| Step: 1
Training loss: 2.6715540107523457
Validation loss: 2.596071430287967

Epoch: 5| Step: 2
Training loss: 3.0514071673555416
Validation loss: 2.5956124089465487

Epoch: 5| Step: 3
Training loss: 2.6359721165109917
Validation loss: 2.595935443947817

Epoch: 5| Step: 4
Training loss: 2.799697730233796
Validation loss: 2.6003520898744275

Epoch: 5| Step: 5
Training loss: 3.1927905588104584
Validation loss: 2.606704853843884

Epoch: 5| Step: 6
Training loss: 3.2265001341770816
Validation loss: 2.6101927335301522

Epoch: 5| Step: 7
Training loss: 2.896023549663835
Validation loss: 2.625349060656549

Epoch: 5| Step: 8
Training loss: 2.905592485107669
Validation loss: 2.6181817022770977

Epoch: 5| Step: 9
Training loss: 2.897173747405607
Validation loss: 2.6419896269944565

Epoch: 5| Step: 10
Training loss: 2.5592489320962013
Validation loss: 2.6441527266128926

Epoch: 413| Step: 0
Training loss: 2.5304596220336486
Validation loss: 2.670640677716296

Epoch: 5| Step: 1
Training loss: 2.903300275326081
Validation loss: 2.6890980289965967

Epoch: 5| Step: 2
Training loss: 3.010277944006317
Validation loss: 2.7039136151752965

Epoch: 5| Step: 3
Training loss: 3.1313112233890403
Validation loss: 2.709157289885012

Epoch: 5| Step: 4
Training loss: 2.7873981542755932
Validation loss: 2.7106036575573023

Epoch: 5| Step: 5
Training loss: 3.025182727938025
Validation loss: 2.6846963553262833

Epoch: 5| Step: 6
Training loss: 2.6525755655956473
Validation loss: 2.678353996143804

Epoch: 5| Step: 7
Training loss: 2.7761625415091715
Validation loss: 2.6576425944595203

Epoch: 5| Step: 8
Training loss: 2.9193505790406067
Validation loss: 2.6331331969325973

Epoch: 5| Step: 9
Training loss: 2.8826725623428984
Validation loss: 2.6121629363579624

Epoch: 5| Step: 10
Training loss: 3.432490773810249
Validation loss: 2.5980171697378043

Epoch: 414| Step: 0
Training loss: 3.490673991707309
Validation loss: 2.601009565484147

Epoch: 5| Step: 1
Training loss: 3.129591048949845
Validation loss: 2.596172255833003

Epoch: 5| Step: 2
Training loss: 2.773645011768116
Validation loss: 2.5953054744260893

Epoch: 5| Step: 3
Training loss: 3.015910555112739
Validation loss: 2.5879932184947863

Epoch: 5| Step: 4
Training loss: 2.803057353586676
Validation loss: 2.584487144974379

Epoch: 5| Step: 5
Training loss: 3.168459251051484
Validation loss: 2.5853772365830947

Epoch: 5| Step: 6
Training loss: 2.6067819102862075
Validation loss: 2.5883657818623362

Epoch: 5| Step: 7
Training loss: 2.9786875590744595
Validation loss: 2.583073705857845

Epoch: 5| Step: 8
Training loss: 2.740467977864623
Validation loss: 2.592135663727515

Epoch: 5| Step: 9
Training loss: 2.7961569775458983
Validation loss: 2.5908293249344725

Epoch: 5| Step: 10
Training loss: 2.4963545924143298
Validation loss: 2.591884204381666

Epoch: 415| Step: 0
Training loss: 3.34200448083035
Validation loss: 2.597753739607436

Epoch: 5| Step: 1
Training loss: 2.9730043144823495
Validation loss: 2.6193083328251925

Epoch: 5| Step: 2
Training loss: 2.2825850669159125
Validation loss: 2.6394395598746883

Epoch: 5| Step: 3
Training loss: 2.7609350233601213
Validation loss: 2.637606281743499

Epoch: 5| Step: 4
Training loss: 2.613849937246934
Validation loss: 2.655168536842348

Epoch: 5| Step: 5
Training loss: 2.8402289086085823
Validation loss: 2.6647503149306173

Epoch: 5| Step: 6
Training loss: 2.585931783710166
Validation loss: 2.643796900762743

Epoch: 5| Step: 7
Training loss: 3.248566237885371
Validation loss: 2.67647936835035

Epoch: 5| Step: 8
Training loss: 3.1144752271043323
Validation loss: 2.684791673125187

Epoch: 5| Step: 9
Training loss: 2.8397416591002935
Validation loss: 2.6924145923659513

Epoch: 5| Step: 10
Training loss: 3.3558093643058733
Validation loss: 2.6932327681094583

Epoch: 416| Step: 0
Training loss: 2.4263554629045894
Validation loss: 2.6505924225139905

Epoch: 5| Step: 1
Training loss: 3.3169660870782427
Validation loss: 2.6020055096392425

Epoch: 5| Step: 2
Training loss: 3.2736635699083854
Validation loss: 2.589528955208042

Epoch: 5| Step: 3
Training loss: 3.260847621788607
Validation loss: 2.5904521404173835

Epoch: 5| Step: 4
Training loss: 2.717634300977167
Validation loss: 2.5841657294493476

Epoch: 5| Step: 5
Training loss: 2.276191642469832
Validation loss: 2.584593080361061

Epoch: 5| Step: 6
Training loss: 2.7471466867493746
Validation loss: 2.5842078459093725

Epoch: 5| Step: 7
Training loss: 3.185125476275869
Validation loss: 2.5858554721124474

Epoch: 5| Step: 8
Training loss: 2.6825841256608447
Validation loss: 2.584530544697676

Epoch: 5| Step: 9
Training loss: 3.1352479367569903
Validation loss: 2.585170410874313

Epoch: 5| Step: 10
Training loss: 2.9177149569077483
Validation loss: 2.5880181515291953

Epoch: 417| Step: 0
Training loss: 2.926632847630379
Validation loss: 2.5798271558734363

Epoch: 5| Step: 1
Training loss: 3.2270579846648495
Validation loss: 2.584530777798238

Epoch: 5| Step: 2
Training loss: 2.7580678675699013
Validation loss: 2.585617832329558

Epoch: 5| Step: 3
Training loss: 2.558382308027301
Validation loss: 2.5800076558637914

Epoch: 5| Step: 4
Training loss: 2.7255502477733202
Validation loss: 2.5804730047079403

Epoch: 5| Step: 5
Training loss: 2.8348151053496515
Validation loss: 2.576230762477909

Epoch: 5| Step: 6
Training loss: 2.992653434472061
Validation loss: 2.588312476910147

Epoch: 5| Step: 7
Training loss: 2.5810969014058776
Validation loss: 2.606664353845835

Epoch: 5| Step: 8
Training loss: 3.313330780069249
Validation loss: 2.608376622272434

Epoch: 5| Step: 9
Training loss: 3.0869794028299076
Validation loss: 2.617160028648039

Epoch: 5| Step: 10
Training loss: 3.018436524600037
Validation loss: 2.635967770137457

Epoch: 418| Step: 0
Training loss: 2.6988754827066
Validation loss: 2.643256988128418

Epoch: 5| Step: 1
Training loss: 3.357756326737194
Validation loss: 2.6650152867792305

Epoch: 5| Step: 2
Training loss: 3.0675290912967963
Validation loss: 2.672685038023633

Epoch: 5| Step: 3
Training loss: 2.6378684920934914
Validation loss: 2.656958876428202

Epoch: 5| Step: 4
Training loss: 3.0885567281440482
Validation loss: 2.633067006306249

Epoch: 5| Step: 5
Training loss: 3.168913863721069
Validation loss: 2.612452921379641

Epoch: 5| Step: 6
Training loss: 2.7153762404943826
Validation loss: 2.6080998706987812

Epoch: 5| Step: 7
Training loss: 2.8900335583173917
Validation loss: 2.595490806594457

Epoch: 5| Step: 8
Training loss: 3.0491099450346457
Validation loss: 2.5954105119026054

Epoch: 5| Step: 9
Training loss: 2.9400390041125517
Validation loss: 2.5983386783831266

Epoch: 5| Step: 10
Training loss: 2.213286321535235
Validation loss: 2.5930765431375633

Epoch: 419| Step: 0
Training loss: 3.280280705745148
Validation loss: 2.595060606224312

Epoch: 5| Step: 1
Training loss: 3.0962400337831943
Validation loss: 2.585586241948241

Epoch: 5| Step: 2
Training loss: 3.2370553083152283
Validation loss: 2.5883544734023416

Epoch: 5| Step: 3
Training loss: 3.3696724557598245
Validation loss: 2.5874750077170767

Epoch: 5| Step: 4
Training loss: 2.6768155291798315
Validation loss: 2.591027175001111

Epoch: 5| Step: 5
Training loss: 2.910953612188283
Validation loss: 2.588067174899967

Epoch: 5| Step: 6
Training loss: 3.11975145181371
Validation loss: 2.5897836436457946

Epoch: 5| Step: 7
Training loss: 3.0020987798614174
Validation loss: 2.5949247832719604

Epoch: 5| Step: 8
Training loss: 2.3154693304084715
Validation loss: 2.5932977299131514

Epoch: 5| Step: 9
Training loss: 2.3638610633002344
Validation loss: 2.6050398401722012

Epoch: 5| Step: 10
Training loss: 2.283021004284862
Validation loss: 2.6163408717607357

Epoch: 420| Step: 0
Training loss: 3.1160879083947934
Validation loss: 2.6296987040855746

Epoch: 5| Step: 1
Training loss: 2.930482151343574
Validation loss: 2.638259017057597

Epoch: 5| Step: 2
Training loss: 2.5276999362609156
Validation loss: 2.6416800038787844

Epoch: 5| Step: 3
Training loss: 2.9134630502007837
Validation loss: 2.6644660101139745

Epoch: 5| Step: 4
Training loss: 2.829683833169905
Validation loss: 2.651043381535196

Epoch: 5| Step: 5
Training loss: 2.5846166089556313
Validation loss: 2.6590428050367563

Epoch: 5| Step: 6
Training loss: 3.3086333829809664
Validation loss: 2.664101436499939

Epoch: 5| Step: 7
Training loss: 3.161467215427614
Validation loss: 2.6620144165688595

Epoch: 5| Step: 8
Training loss: 3.075163215089319
Validation loss: 2.6802522285530723

Epoch: 5| Step: 9
Training loss: 2.4940096612420435
Validation loss: 2.6599904275013047

Epoch: 5| Step: 10
Training loss: 2.850798538502661
Validation loss: 2.6472993593367233

Epoch: 421| Step: 0
Training loss: 2.6636338770100547
Validation loss: 2.651405702254283

Epoch: 5| Step: 1
Training loss: 2.6312897124204504
Validation loss: 2.631447863274349

Epoch: 5| Step: 2
Training loss: 2.9597606886960617
Validation loss: 2.6329011962727553

Epoch: 5| Step: 3
Training loss: 3.019806645753065
Validation loss: 2.6210376721338196

Epoch: 5| Step: 4
Training loss: 2.877139746471752
Validation loss: 2.610880643756098

Epoch: 5| Step: 5
Training loss: 2.9669358984975487
Validation loss: 2.600280997928711

Epoch: 5| Step: 6
Training loss: 3.2948722360757765
Validation loss: 2.605254044129522

Epoch: 5| Step: 7
Training loss: 3.2169874976724206
Validation loss: 2.6014342853692543

Epoch: 5| Step: 8
Training loss: 2.433592182483444
Validation loss: 2.608542266401441

Epoch: 5| Step: 9
Training loss: 2.879263660289531
Validation loss: 2.6098241421326485

Epoch: 5| Step: 10
Training loss: 2.920357702894288
Validation loss: 2.6191427539105527

Epoch: 422| Step: 0
Training loss: 3.2193148219253827
Validation loss: 2.6269532401560665

Epoch: 5| Step: 1
Training loss: 2.9375792147730087
Validation loss: 2.6352159828302

Epoch: 5| Step: 2
Training loss: 2.935581798434561
Validation loss: 2.6368283348752337

Epoch: 5| Step: 3
Training loss: 2.6122543073412943
Validation loss: 2.644749558414271

Epoch: 5| Step: 4
Training loss: 3.0094832895033337
Validation loss: 2.6190534673845773

Epoch: 5| Step: 5
Training loss: 2.6180327459725126
Validation loss: 2.645160253861227

Epoch: 5| Step: 6
Training loss: 3.1579399494648834
Validation loss: 2.6375369695869764

Epoch: 5| Step: 7
Training loss: 2.8533226120233395
Validation loss: 2.642894321442566

Epoch: 5| Step: 8
Training loss: 2.8023480617637846
Validation loss: 2.637234403138414

Epoch: 5| Step: 9
Training loss: 2.827888436724314
Validation loss: 2.6238857263849904

Epoch: 5| Step: 10
Training loss: 2.871619683706239
Validation loss: 2.644821570084716

Epoch: 423| Step: 0
Training loss: 2.379279747818168
Validation loss: 2.62856559580163

Epoch: 5| Step: 1
Training loss: 3.008274904847828
Validation loss: 2.64071126215553

Epoch: 5| Step: 2
Training loss: 2.988747474353446
Validation loss: 2.627431377318242

Epoch: 5| Step: 3
Training loss: 2.452865781269752
Validation loss: 2.6422159890126355

Epoch: 5| Step: 4
Training loss: 2.1582121835924144
Validation loss: 2.6387731198224045

Epoch: 5| Step: 5
Training loss: 2.957515460221422
Validation loss: 2.6204887657675817

Epoch: 5| Step: 6
Training loss: 3.3573696094681145
Validation loss: 2.617129447879681

Epoch: 5| Step: 7
Training loss: 3.3231504989830962
Validation loss: 2.610496146032296

Epoch: 5| Step: 8
Training loss: 2.9687267101779713
Validation loss: 2.61877953477485

Epoch: 5| Step: 9
Training loss: 3.249225377422085
Validation loss: 2.5990563613212747

Epoch: 5| Step: 10
Training loss: 2.7225506404934454
Validation loss: 2.6119435179242956

Epoch: 424| Step: 0
Training loss: 2.510479421081865
Validation loss: 2.594438867855096

Epoch: 5| Step: 1
Training loss: 3.072641047816687
Validation loss: 2.6021099086821704

Epoch: 5| Step: 2
Training loss: 2.858387093738167
Validation loss: 2.6079373972024023

Epoch: 5| Step: 3
Training loss: 3.2719732027518758
Validation loss: 2.6073799752121194

Epoch: 5| Step: 4
Training loss: 3.074567413916118
Validation loss: 2.614037955976099

Epoch: 5| Step: 5
Training loss: 2.5480380532853095
Validation loss: 2.6023267107439056

Epoch: 5| Step: 6
Training loss: 2.6357168597106533
Validation loss: 2.61918836014245

Epoch: 5| Step: 7
Training loss: 3.0889908376590567
Validation loss: 2.6334936021025386

Epoch: 5| Step: 8
Training loss: 3.008344806286464
Validation loss: 2.6341062185978585

Epoch: 5| Step: 9
Training loss: 2.938500092077197
Validation loss: 2.6426554790125825

Epoch: 5| Step: 10
Training loss: 2.7151700708784237
Validation loss: 2.6768844152009184

Epoch: 425| Step: 0
Training loss: 2.6241219278129604
Validation loss: 2.69904424666821

Epoch: 5| Step: 1
Training loss: 3.059948072055197
Validation loss: 2.7196483681309815

Epoch: 5| Step: 2
Training loss: 2.9114633377023087
Validation loss: 2.6824190951570412

Epoch: 5| Step: 3
Training loss: 2.7125287841113446
Validation loss: 2.698969571208642

Epoch: 5| Step: 4
Training loss: 3.005267128900898
Validation loss: 2.6731696070924515

Epoch: 5| Step: 5
Training loss: 2.3035823952719037
Validation loss: 2.6723602972961698

Epoch: 5| Step: 6
Training loss: 3.2135566368970254
Validation loss: 2.665638608830074

Epoch: 5| Step: 7
Training loss: 2.361873491160064
Validation loss: 2.638324936530726

Epoch: 5| Step: 8
Training loss: 3.1261628085625435
Validation loss: 2.6346039289543826

Epoch: 5| Step: 9
Training loss: 3.2650055366223816
Validation loss: 2.625189804114008

Epoch: 5| Step: 10
Training loss: 3.3230365663778625
Validation loss: 2.626077506031141

Epoch: 426| Step: 0
Training loss: 2.756847699120323
Validation loss: 2.6216381155628574

Epoch: 5| Step: 1
Training loss: 2.914282578244913
Validation loss: 2.6161482727446144

Epoch: 5| Step: 2
Training loss: 2.92192689574151
Validation loss: 2.609534275636022

Epoch: 5| Step: 3
Training loss: 2.9970125582472944
Validation loss: 2.6068761624658014

Epoch: 5| Step: 4
Training loss: 2.4282376296385064
Validation loss: 2.6083173223803016

Epoch: 5| Step: 5
Training loss: 3.1656289826468806
Validation loss: 2.6018159415168083

Epoch: 5| Step: 6
Training loss: 2.713768088668357
Validation loss: 2.602558381300728

Epoch: 5| Step: 7
Training loss: 3.0977476859337667
Validation loss: 2.612123400355261

Epoch: 5| Step: 8
Training loss: 2.6526670638099534
Validation loss: 2.6106878540284963

Epoch: 5| Step: 9
Training loss: 2.6718651843866668
Validation loss: 2.6229335231520032

Epoch: 5| Step: 10
Training loss: 3.4851470228841372
Validation loss: 2.628064984064353

Epoch: 427| Step: 0
Training loss: 2.993940751085148
Validation loss: 2.618469188922816

Epoch: 5| Step: 1
Training loss: 2.7655571535915677
Validation loss: 2.6373110769369545

Epoch: 5| Step: 2
Training loss: 2.965663067942168
Validation loss: 2.613136098506786

Epoch: 5| Step: 3
Training loss: 3.0311982455210518
Validation loss: 2.6211403536534825

Epoch: 5| Step: 4
Training loss: 3.3367714476035784
Validation loss: 2.643988210038557

Epoch: 5| Step: 5
Training loss: 2.128929768003699
Validation loss: 2.63838098607563

Epoch: 5| Step: 6
Training loss: 2.6749228778310132
Validation loss: 2.63320729333201

Epoch: 5| Step: 7
Training loss: 2.827323842248665
Validation loss: 2.6508162568833056

Epoch: 5| Step: 8
Training loss: 2.861191136332547
Validation loss: 2.657700294115579

Epoch: 5| Step: 9
Training loss: 2.9382060399632235
Validation loss: 2.6456603760047965

Epoch: 5| Step: 10
Training loss: 3.250311469778509
Validation loss: 2.636136604315855

Epoch: 428| Step: 0
Training loss: 3.2199439639789618
Validation loss: 2.6453657705265483

Epoch: 5| Step: 1
Training loss: 1.985973165148313
Validation loss: 2.6401973542397594

Epoch: 5| Step: 2
Training loss: 2.6479383690337603
Validation loss: 2.634429656022678

Epoch: 5| Step: 3
Training loss: 3.1052304350381954
Validation loss: 2.625281579091659

Epoch: 5| Step: 4
Training loss: 3.23870971937318
Validation loss: 2.6140740266275646

Epoch: 5| Step: 5
Training loss: 3.2433518123067615
Validation loss: 2.6377041783801736

Epoch: 5| Step: 6
Training loss: 2.5080589102073167
Validation loss: 2.6243802485083476

Epoch: 5| Step: 7
Training loss: 3.444432844805584
Validation loss: 2.604399392506563

Epoch: 5| Step: 8
Training loss: 2.2874253182649276
Validation loss: 2.60953836050646

Epoch: 5| Step: 9
Training loss: 2.602123852901203
Validation loss: 2.6046229130583756

Epoch: 5| Step: 10
Training loss: 3.268417551556227
Validation loss: 2.605156391384022

Epoch: 429| Step: 0
Training loss: 3.6018120602680916
Validation loss: 2.6138450401526128

Epoch: 5| Step: 1
Training loss: 2.554137004370981
Validation loss: 2.6103352899431926

Epoch: 5| Step: 2
Training loss: 2.7776879635172227
Validation loss: 2.619645532587515

Epoch: 5| Step: 3
Training loss: 2.8830362868868558
Validation loss: 2.6066037619987394

Epoch: 5| Step: 4
Training loss: 3.345156792585361
Validation loss: 2.611186256045943

Epoch: 5| Step: 5
Training loss: 2.9888751069436186
Validation loss: 2.618404577942927

Epoch: 5| Step: 6
Training loss: 2.748730019448639
Validation loss: 2.623365753912065

Epoch: 5| Step: 7
Training loss: 2.641178501964974
Validation loss: 2.6531189698368993

Epoch: 5| Step: 8
Training loss: 2.5342705682764857
Validation loss: 2.6591588972064057

Epoch: 5| Step: 9
Training loss: 2.4251314973081026
Validation loss: 2.681553695731581

Epoch: 5| Step: 10
Training loss: 3.091130853031221
Validation loss: 2.691848877319774

Epoch: 430| Step: 0
Training loss: 2.4609921403904313
Validation loss: 2.6900845629688726

Epoch: 5| Step: 1
Training loss: 2.442637580112596
Validation loss: 2.6883259186439856

Epoch: 5| Step: 2
Training loss: 3.074125683549994
Validation loss: 2.659649963612552

Epoch: 5| Step: 3
Training loss: 2.9047969344004994
Validation loss: 2.648118447366217

Epoch: 5| Step: 4
Training loss: 2.8883479867230726
Validation loss: 2.6325790327562513

Epoch: 5| Step: 5
Training loss: 1.7514560636497587
Validation loss: 2.6220155265778096

Epoch: 5| Step: 6
Training loss: 3.1354619188729034
Validation loss: 2.617515312018638

Epoch: 5| Step: 7
Training loss: 3.133176863260312
Validation loss: 2.6055084174822776

Epoch: 5| Step: 8
Training loss: 3.3440926634712627
Validation loss: 2.6070483399293383

Epoch: 5| Step: 9
Training loss: 3.463299567382616
Validation loss: 2.598040668528616

Epoch: 5| Step: 10
Training loss: 2.64804263251753
Validation loss: 2.6034993028239497

Epoch: 431| Step: 0
Training loss: 2.8352175973208324
Validation loss: 2.590369757682899

Epoch: 5| Step: 1
Training loss: 2.8115343767425687
Validation loss: 2.5957404025131363

Epoch: 5| Step: 2
Training loss: 2.3745978165458332
Validation loss: 2.5981899411781457

Epoch: 5| Step: 3
Training loss: 2.842437105716004
Validation loss: 2.6033865907574985

Epoch: 5| Step: 4
Training loss: 3.11265245546828
Validation loss: 2.6007804489648314

Epoch: 5| Step: 5
Training loss: 3.4699586704222396
Validation loss: 2.6259157445899244

Epoch: 5| Step: 6
Training loss: 2.693211629575988
Validation loss: 2.61309708248094

Epoch: 5| Step: 7
Training loss: 2.457287312614677
Validation loss: 2.612712421309751

Epoch: 5| Step: 8
Training loss: 3.087544392255034
Validation loss: 2.6321011703316346

Epoch: 5| Step: 9
Training loss: 3.092218347427378
Validation loss: 2.6478497824120306

Epoch: 5| Step: 10
Training loss: 2.7806601595397384
Validation loss: 2.638505975100112

Epoch: 432| Step: 0
Training loss: 2.8717729452801737
Validation loss: 2.6618864324681057

Epoch: 5| Step: 1
Training loss: 2.8917559086846523
Validation loss: 2.6526814540461214

Epoch: 5| Step: 2
Training loss: 3.1958672897610514
Validation loss: 2.6725358052913664

Epoch: 5| Step: 3
Training loss: 3.0045281251405758
Validation loss: 2.691421620905378

Epoch: 5| Step: 4
Training loss: 2.4740217876662216
Validation loss: 2.6801324022573523

Epoch: 5| Step: 5
Training loss: 2.822864170688995
Validation loss: 2.649376737050623

Epoch: 5| Step: 6
Training loss: 2.7617576844574745
Validation loss: 2.6647678974190856

Epoch: 5| Step: 7
Training loss: 3.005893957423709
Validation loss: 2.6788526028645383

Epoch: 5| Step: 8
Training loss: 2.885668489964183
Validation loss: 2.67392740206377

Epoch: 5| Step: 9
Training loss: 2.8288986243877647
Validation loss: 2.6563052051653817

Epoch: 5| Step: 10
Training loss: 3.0182327301206224
Validation loss: 2.647445872517511

Epoch: 433| Step: 0
Training loss: 3.023740925706271
Validation loss: 2.642280806541827

Epoch: 5| Step: 1
Training loss: 2.575930036714241
Validation loss: 2.6381767502298463

Epoch: 5| Step: 2
Training loss: 3.0094832895033337
Validation loss: 2.637494248651858

Epoch: 5| Step: 3
Training loss: 3.334784064901577
Validation loss: 2.6453642587202877

Epoch: 5| Step: 4
Training loss: 2.508517537582435
Validation loss: 2.629802565748228

Epoch: 5| Step: 5
Training loss: 3.2155375328809663
Validation loss: 2.6305749907897478

Epoch: 5| Step: 6
Training loss: 2.7440187257455864
Validation loss: 2.613607427370474

Epoch: 5| Step: 7
Training loss: 3.3341168118650453
Validation loss: 2.620352182823985

Epoch: 5| Step: 8
Training loss: 2.874886220256194
Validation loss: 2.6237996761067848

Epoch: 5| Step: 9
Training loss: 2.571715183785178
Validation loss: 2.6197104642775577

Epoch: 5| Step: 10
Training loss: 2.26860429280139
Validation loss: 2.6213762533227065

Epoch: 434| Step: 0
Training loss: 2.90390428610246
Validation loss: 2.646879666720176

Epoch: 5| Step: 1
Training loss: 2.912674233132585
Validation loss: 2.6408579714422076

Epoch: 5| Step: 2
Training loss: 3.0011567428825043
Validation loss: 2.6452643283486355

Epoch: 5| Step: 3
Training loss: 2.7893428714995143
Validation loss: 2.6237851948858832

Epoch: 5| Step: 4
Training loss: 2.9226259296784973
Validation loss: 2.635308900927376

Epoch: 5| Step: 5
Training loss: 3.29419849100204
Validation loss: 2.642715792364681

Epoch: 5| Step: 6
Training loss: 2.624436090843493
Validation loss: 2.631173620220531

Epoch: 5| Step: 7
Training loss: 3.1223885878393225
Validation loss: 2.67072706948128

Epoch: 5| Step: 8
Training loss: 2.218434700927172
Validation loss: 2.6738619758382387

Epoch: 5| Step: 9
Training loss: 3.0339950245041307
Validation loss: 2.6792134181585894

Epoch: 5| Step: 10
Training loss: 2.725696415235667
Validation loss: 2.657374117736688

Epoch: 435| Step: 0
Training loss: 2.8143193612220814
Validation loss: 2.636118560504672

Epoch: 5| Step: 1
Training loss: 2.679993814916733
Validation loss: 2.627652672312075

Epoch: 5| Step: 2
Training loss: 2.937434094278123
Validation loss: 2.6092683926181546

Epoch: 5| Step: 3
Training loss: 3.0694785502185002
Validation loss: 2.5991774977552993

Epoch: 5| Step: 4
Training loss: 3.2442061792556447
Validation loss: 2.5875371095987307

Epoch: 5| Step: 5
Training loss: 3.3054010869825157
Validation loss: 2.6019240976763394

Epoch: 5| Step: 6
Training loss: 2.774179021002442
Validation loss: 2.5928706410515967

Epoch: 5| Step: 7
Training loss: 2.6681008257366114
Validation loss: 2.5967313412887356

Epoch: 5| Step: 8
Training loss: 2.5437824219083214
Validation loss: 2.6003307355799903

Epoch: 5| Step: 9
Training loss: 2.89272632000315
Validation loss: 2.6086599460657265

Epoch: 5| Step: 10
Training loss: 2.667424918693851
Validation loss: 2.630015342614935

Epoch: 436| Step: 0
Training loss: 2.3660183779791955
Validation loss: 2.6358754092212964

Epoch: 5| Step: 1
Training loss: 3.0685940269719882
Validation loss: 2.6468148659229183

Epoch: 5| Step: 2
Training loss: 3.1189862179025125
Validation loss: 2.6827009732020985

Epoch: 5| Step: 3
Training loss: 2.9078594386408327
Validation loss: 2.6936700263965427

Epoch: 5| Step: 4
Training loss: 3.107516706303613
Validation loss: 2.7331973116554926

Epoch: 5| Step: 5
Training loss: 3.322459381750782
Validation loss: 2.7441596588034023

Epoch: 5| Step: 6
Training loss: 2.950642182878472
Validation loss: 2.7031378147348564

Epoch: 5| Step: 7
Training loss: 2.756322528464405
Validation loss: 2.6574695526089958

Epoch: 5| Step: 8
Training loss: 2.2428147771025695
Validation loss: 2.629370457106017

Epoch: 5| Step: 9
Training loss: 3.0191500128226085
Validation loss: 2.6105441934226925

Epoch: 5| Step: 10
Training loss: 2.744950513688966
Validation loss: 2.5919069902490373

Epoch: 437| Step: 0
Training loss: 3.028259690067594
Validation loss: 2.586111759482824

Epoch: 5| Step: 1
Training loss: 2.560329820873962
Validation loss: 2.578819527894058

Epoch: 5| Step: 2
Training loss: 3.131488015880552
Validation loss: 2.5760965262024444

Epoch: 5| Step: 3
Training loss: 2.837650506821576
Validation loss: 2.5897938832062977

Epoch: 5| Step: 4
Training loss: 2.970548065171664
Validation loss: 2.5702559355846435

Epoch: 5| Step: 5
Training loss: 2.489471103154966
Validation loss: 2.569916523945168

Epoch: 5| Step: 6
Training loss: 3.2851463798528897
Validation loss: 2.5721460445219173

Epoch: 5| Step: 7
Training loss: 3.1665802157463734
Validation loss: 2.5699537285968197

Epoch: 5| Step: 8
Training loss: 3.407190455526655
Validation loss: 2.584131472489531

Epoch: 5| Step: 9
Training loss: 2.4541471259262635
Validation loss: 2.598347747617939

Epoch: 5| Step: 10
Training loss: 2.197044476718262
Validation loss: 2.607133629384838

Epoch: 438| Step: 0
Training loss: 2.5861742539373704
Validation loss: 2.6056258342164247

Epoch: 5| Step: 1
Training loss: 2.9493587637501086
Validation loss: 2.620216317761219

Epoch: 5| Step: 2
Training loss: 2.8919757058586035
Validation loss: 2.641883681665387

Epoch: 5| Step: 3
Training loss: 2.812443541913799
Validation loss: 2.6374292687750662

Epoch: 5| Step: 4
Training loss: 2.635129910475111
Validation loss: 2.635413629044619

Epoch: 5| Step: 5
Training loss: 3.3341146666013732
Validation loss: 2.6608923217929896

Epoch: 5| Step: 6
Training loss: 2.7381806838088383
Validation loss: 2.670225311432111

Epoch: 5| Step: 7
Training loss: 3.1613737008059424
Validation loss: 2.6641884502358253

Epoch: 5| Step: 8
Training loss: 2.811268600463395
Validation loss: 2.6492022117769896

Epoch: 5| Step: 9
Training loss: 2.846300930259431
Validation loss: 2.6456383709289253

Epoch: 5| Step: 10
Training loss: 2.859760529422793
Validation loss: 2.6388151458240663

Epoch: 439| Step: 0
Training loss: 2.581301033309879
Validation loss: 2.6411151978306457

Epoch: 5| Step: 1
Training loss: 2.7414314988528954
Validation loss: 2.642269117091326

Epoch: 5| Step: 2
Training loss: 2.991130751812511
Validation loss: 2.6289079253481447

Epoch: 5| Step: 3
Training loss: 3.3047654163022084
Validation loss: 2.6344806572345862

Epoch: 5| Step: 4
Training loss: 2.737232219541091
Validation loss: 2.611167293654844

Epoch: 5| Step: 5
Training loss: 3.3169678121620274
Validation loss: 2.6167874339790584

Epoch: 5| Step: 6
Training loss: 2.6749468539653845
Validation loss: 2.609471506543854

Epoch: 5| Step: 7
Training loss: 3.0215380318037894
Validation loss: 2.6130970510865836

Epoch: 5| Step: 8
Training loss: 2.508626930399922
Validation loss: 2.621850280946352

Epoch: 5| Step: 9
Training loss: 2.712735681798538
Validation loss: 2.613717821353062

Epoch: 5| Step: 10
Training loss: 2.813038668440301
Validation loss: 2.6256265590781327

Epoch: 440| Step: 0
Training loss: 3.343651030314679
Validation loss: 2.6181124770976867

Epoch: 5| Step: 1
Training loss: 2.8369505362866154
Validation loss: 2.5991830658155064

Epoch: 5| Step: 2
Training loss: 2.563861485237574
Validation loss: 2.5920427458319346

Epoch: 5| Step: 3
Training loss: 2.7226331318512775
Validation loss: 2.6061080879029634

Epoch: 5| Step: 4
Training loss: 2.050224766388408
Validation loss: 2.5966464901180446

Epoch: 5| Step: 5
Training loss: 3.257010747744823
Validation loss: 2.5934104870196695

Epoch: 5| Step: 6
Training loss: 2.9065568003174613
Validation loss: 2.5901137362389206

Epoch: 5| Step: 7
Training loss: 2.9777107326905625
Validation loss: 2.594564427374202

Epoch: 5| Step: 8
Training loss: 3.1340700893099105
Validation loss: 2.5925437384726213

Epoch: 5| Step: 9
Training loss: 2.900264030802068
Validation loss: 2.5988563811715544

Epoch: 5| Step: 10
Training loss: 2.652995910020214
Validation loss: 2.6211986294278264

Epoch: 441| Step: 0
Training loss: 3.3499478805814733
Validation loss: 2.63710417524904

Epoch: 5| Step: 1
Training loss: 2.7683443827200924
Validation loss: 2.646356878852363

Epoch: 5| Step: 2
Training loss: 2.9535801450989863
Validation loss: 2.6496213265506396

Epoch: 5| Step: 3
Training loss: 3.2818464917739294
Validation loss: 2.649401765886473

Epoch: 5| Step: 4
Training loss: 2.441763450431628
Validation loss: 2.63270968215769

Epoch: 5| Step: 5
Training loss: 3.1839117160519375
Validation loss: 2.6648399386165824

Epoch: 5| Step: 6
Training loss: 2.7211569293275057
Validation loss: 2.642700794915163

Epoch: 5| Step: 7
Training loss: 2.550581031874638
Validation loss: 2.6228993278073087

Epoch: 5| Step: 8
Training loss: 3.0264158734285727
Validation loss: 2.651136232273748

Epoch: 5| Step: 9
Training loss: 1.93697405413816
Validation loss: 2.62108339406341

Epoch: 5| Step: 10
Training loss: 3.0631007948134865
Validation loss: 2.6165018720550863

Epoch: 442| Step: 0
Training loss: 2.6713452622702865
Validation loss: 2.61950098624948

Epoch: 5| Step: 1
Training loss: 2.7882802170708545
Validation loss: 2.610755812964291

Epoch: 5| Step: 2
Training loss: 2.752566440483743
Validation loss: 2.6380032264437663

Epoch: 5| Step: 3
Training loss: 3.019756432115305
Validation loss: 2.6274708664120396

Epoch: 5| Step: 4
Training loss: 3.069019151992677
Validation loss: 2.6589896235568187

Epoch: 5| Step: 5
Training loss: 2.786343058165463
Validation loss: 2.6271442205216515

Epoch: 5| Step: 6
Training loss: 2.932322057608293
Validation loss: 2.602270465878132

Epoch: 5| Step: 7
Training loss: 3.1017634329100265
Validation loss: 2.6072746810178558

Epoch: 5| Step: 8
Training loss: 2.6944384055927504
Validation loss: 2.6139505448570715

Epoch: 5| Step: 9
Training loss: 3.0755427804153594
Validation loss: 2.606721344775006

Epoch: 5| Step: 10
Training loss: 2.525885466370396
Validation loss: 2.6094799117677003

Epoch: 443| Step: 0
Training loss: 2.771988525130176
Validation loss: 2.631298927244101

Epoch: 5| Step: 1
Training loss: 2.6075318731186843
Validation loss: 2.6214115516283867

Epoch: 5| Step: 2
Training loss: 3.5086170115068214
Validation loss: 2.6321880371324458

Epoch: 5| Step: 3
Training loss: 3.1040622429063682
Validation loss: 2.648685810668073

Epoch: 5| Step: 4
Training loss: 2.7431608466906656
Validation loss: 2.651694737955455

Epoch: 5| Step: 5
Training loss: 2.856019599687017
Validation loss: 2.6667330686187687

Epoch: 5| Step: 6
Training loss: 2.701004519625812
Validation loss: 2.66616341882404

Epoch: 5| Step: 7
Training loss: 2.498130099033919
Validation loss: 2.6322943327639248

Epoch: 5| Step: 8
Training loss: 2.366590468653075
Validation loss: 2.6218826233798236

Epoch: 5| Step: 9
Training loss: 3.1777717386498083
Validation loss: 2.631086616645412

Epoch: 5| Step: 10
Training loss: 2.961786073056883
Validation loss: 2.613457126414374

Epoch: 444| Step: 0
Training loss: 3.547551430886543
Validation loss: 2.6127564884227965

Epoch: 5| Step: 1
Training loss: 2.615120142406924
Validation loss: 2.5968222620978763

Epoch: 5| Step: 2
Training loss: 3.3497646818496207
Validation loss: 2.592768151563092

Epoch: 5| Step: 3
Training loss: 3.1829123300169186
Validation loss: 2.586501667167393

Epoch: 5| Step: 4
Training loss: 2.7912297737287335
Validation loss: 2.594698449238713

Epoch: 5| Step: 5
Training loss: 3.108019202537572
Validation loss: 2.5904621130999717

Epoch: 5| Step: 6
Training loss: 2.8130234972870496
Validation loss: 2.605626364531309

Epoch: 5| Step: 7
Training loss: 2.428411608734559
Validation loss: 2.6205086331363527

Epoch: 5| Step: 8
Training loss: 2.5650322660383575
Validation loss: 2.6259255201076486

Epoch: 5| Step: 9
Training loss: 2.691320055285906
Validation loss: 2.6489070972463993

Epoch: 5| Step: 10
Training loss: 2.088617667498369
Validation loss: 2.684936264053701

Epoch: 445| Step: 0
Training loss: 3.034916027484826
Validation loss: 2.68265239624784

Epoch: 5| Step: 1
Training loss: 3.1747513681215493
Validation loss: 2.679342519810881

Epoch: 5| Step: 2
Training loss: 2.5435661868105166
Validation loss: 2.6572248461547594

Epoch: 5| Step: 3
Training loss: 2.9247541471008955
Validation loss: 2.656155387066857

Epoch: 5| Step: 4
Training loss: 2.318178679214229
Validation loss: 2.6499916758361084

Epoch: 5| Step: 5
Training loss: 2.723214353610536
Validation loss: 2.6363350430807393

Epoch: 5| Step: 6
Training loss: 3.375839976581436
Validation loss: 2.645985506342423

Epoch: 5| Step: 7
Training loss: 2.804322285370319
Validation loss: 2.6261761711661307

Epoch: 5| Step: 8
Training loss: 2.7752806650454995
Validation loss: 2.6082382590023685

Epoch: 5| Step: 9
Training loss: 2.6678180791665373
Validation loss: 2.607246586541566

Epoch: 5| Step: 10
Training loss: 3.059776028932347
Validation loss: 2.6010865324195738

Epoch: 446| Step: 0
Training loss: 2.944604277521224
Validation loss: 2.589404755401929

Epoch: 5| Step: 1
Training loss: 2.844736116905943
Validation loss: 2.613652445545758

Epoch: 5| Step: 2
Training loss: 2.7198233404011227
Validation loss: 2.6243061549161704

Epoch: 5| Step: 3
Training loss: 3.115389427224815
Validation loss: 2.6098537790576777

Epoch: 5| Step: 4
Training loss: 3.2924477016782108
Validation loss: 2.617033066017216

Epoch: 5| Step: 5
Training loss: 2.8096710388563526
Validation loss: 2.6237094610293035

Epoch: 5| Step: 6
Training loss: 2.918464506183438
Validation loss: 2.622537072758201

Epoch: 5| Step: 7
Training loss: 2.4929779616819
Validation loss: 2.6379787920858506

Epoch: 5| Step: 8
Training loss: 2.7568767570259967
Validation loss: 2.6355641486033767

Epoch: 5| Step: 9
Training loss: 2.675824464323714
Validation loss: 2.6543862982289905

Epoch: 5| Step: 10
Training loss: 2.7319300592721776
Validation loss: 2.6551610414347806

Epoch: 447| Step: 0
Training loss: 2.8318286902236736
Validation loss: 2.6407408873629232

Epoch: 5| Step: 1
Training loss: 2.91680386538477
Validation loss: 2.6732254822725867

Epoch: 5| Step: 2
Training loss: 2.9158934703671506
Validation loss: 2.7159077930922817

Epoch: 5| Step: 3
Training loss: 2.643881871607199
Validation loss: 2.704821628238494

Epoch: 5| Step: 4
Training loss: 3.1169736401615453
Validation loss: 2.6908158367725084

Epoch: 5| Step: 5
Training loss: 2.9324061279361895
Validation loss: 2.648930563648531

Epoch: 5| Step: 6
Training loss: 3.025497956708509
Validation loss: 2.617208099651493

Epoch: 5| Step: 7
Training loss: 2.3446185727813074
Validation loss: 2.618594206132888

Epoch: 5| Step: 8
Training loss: 3.126082881226576
Validation loss: 2.599475279892392

Epoch: 5| Step: 9
Training loss: 2.443342103599778
Validation loss: 2.5883838490488866

Epoch: 5| Step: 10
Training loss: 3.1460929072994435
Validation loss: 2.5859159295151795

Epoch: 448| Step: 0
Training loss: 2.7388563654139757
Validation loss: 2.5843039411690176

Epoch: 5| Step: 1
Training loss: 3.0517982809816795
Validation loss: 2.5790174583398233

Epoch: 5| Step: 2
Training loss: 2.787862995273229
Validation loss: 2.5830214236377107

Epoch: 5| Step: 3
Training loss: 3.196186272646375
Validation loss: 2.5812460534652737

Epoch: 5| Step: 4
Training loss: 2.130307357712491
Validation loss: 2.5913756635255973

Epoch: 5| Step: 5
Training loss: 3.6550067842057876
Validation loss: 2.6003247817821484

Epoch: 5| Step: 6
Training loss: 2.936965893826318
Validation loss: 2.612889423128814

Epoch: 5| Step: 7
Training loss: 2.818501067746894
Validation loss: 2.626406199701849

Epoch: 5| Step: 8
Training loss: 2.501655983831108
Validation loss: 2.6124139030012845

Epoch: 5| Step: 9
Training loss: 2.9045858233028063
Validation loss: 2.626917740619782

Epoch: 5| Step: 10
Training loss: 2.626572455864441
Validation loss: 2.5936182361497084

Epoch: 449| Step: 0
Training loss: 2.850534248471501
Validation loss: 2.611093893352926

Epoch: 5| Step: 1
Training loss: 2.6694277436572764
Validation loss: 2.6104604570689824

Epoch: 5| Step: 2
Training loss: 2.416374309438463
Validation loss: 2.6049216884345787

Epoch: 5| Step: 3
Training loss: 3.239927087599192
Validation loss: 2.596432228695072

Epoch: 5| Step: 4
Training loss: 2.4932327231169364
Validation loss: 2.621743292967143

Epoch: 5| Step: 5
Training loss: 3.178817442532172
Validation loss: 2.653815721542513

Epoch: 5| Step: 6
Training loss: 2.063264416153285
Validation loss: 2.6813966730820993

Epoch: 5| Step: 7
Training loss: 2.964211940668079
Validation loss: 2.7001104038322037

Epoch: 5| Step: 8
Training loss: 2.9232711312415907
Validation loss: 2.699290090182408

Epoch: 5| Step: 9
Training loss: 3.1924730289906162
Validation loss: 2.6821973064649396

Epoch: 5| Step: 10
Training loss: 3.3259419189813735
Validation loss: 2.651176672744515

Epoch: 450| Step: 0
Training loss: 3.1429017577782177
Validation loss: 2.6560464451661883

Epoch: 5| Step: 1
Training loss: 2.666607399122925
Validation loss: 2.6518606596267587

Epoch: 5| Step: 2
Training loss: 2.4090069916506125
Validation loss: 2.673436020983616

Epoch: 5| Step: 3
Training loss: 3.0836704860250284
Validation loss: 2.6793397785285986

Epoch: 5| Step: 4
Training loss: 2.969260884546942
Validation loss: 2.654403205696477

Epoch: 5| Step: 5
Training loss: 2.812762947506374
Validation loss: 2.653318826482506

Epoch: 5| Step: 6
Training loss: 2.984950145004781
Validation loss: 2.6404280079667224

Epoch: 5| Step: 7
Training loss: 2.613177333071441
Validation loss: 2.6154434208899295

Epoch: 5| Step: 8
Training loss: 2.9554161589438444
Validation loss: 2.5960709187589064

Epoch: 5| Step: 9
Training loss: 2.549136415742487
Validation loss: 2.581060588410073

Epoch: 5| Step: 10
Training loss: 3.2797255108117707
Validation loss: 2.5792482695344425

Testing loss: 2.788434154635748
