Epoch: 1| Step: 0
Training loss: 3.832501173019409
Validation loss: 5.2249557382317

Epoch: 5| Step: 1
Training loss: 5.708517551422119
Validation loss: 5.218631539293515

Epoch: 5| Step: 2
Training loss: 5.819674015045166
Validation loss: 5.212602241064912

Epoch: 5| Step: 3
Training loss: 4.969369888305664
Validation loss: 5.206474258053687

Epoch: 5| Step: 4
Training loss: 4.674921989440918
Validation loss: 5.199712184167677

Epoch: 5| Step: 5
Training loss: 5.193750858306885
Validation loss: 5.193083496503933

Epoch: 5| Step: 6
Training loss: 4.318795680999756
Validation loss: 5.186694468221357

Epoch: 5| Step: 7
Training loss: 5.23790979385376
Validation loss: 5.180363532035582

Epoch: 5| Step: 8
Training loss: 5.0026726722717285
Validation loss: 5.173795638545867

Epoch: 5| Step: 9
Training loss: 4.945679187774658
Validation loss: 5.167033236513856

Epoch: 5| Step: 10
Training loss: 5.193395137786865
Validation loss: 5.1598501871990905

Epoch: 2| Step: 0
Training loss: 5.322786808013916
Validation loss: 5.152940370703257

Epoch: 5| Step: 1
Training loss: 5.152148246765137
Validation loss: 5.14549917815834

Epoch: 5| Step: 2
Training loss: 5.268398761749268
Validation loss: 5.1376192800460325

Epoch: 5| Step: 3
Training loss: 5.291201591491699
Validation loss: 5.129127610114313

Epoch: 5| Step: 4
Training loss: 3.8746776580810547
Validation loss: 5.120572525967834

Epoch: 5| Step: 5
Training loss: 4.987496376037598
Validation loss: 5.111445888396232

Epoch: 5| Step: 6
Training loss: 4.916256904602051
Validation loss: 5.102150265888501

Epoch: 5| Step: 7
Training loss: 5.933104515075684
Validation loss: 5.092465287895613

Epoch: 5| Step: 8
Training loss: 3.6586265563964844
Validation loss: 5.08170372439969

Epoch: 5| Step: 9
Training loss: 4.290416717529297
Validation loss: 5.070854243411813

Epoch: 5| Step: 10
Training loss: 5.298973560333252
Validation loss: 5.058994262449203

Epoch: 3| Step: 0
Training loss: 4.746150016784668
Validation loss: 5.047136188835226

Epoch: 5| Step: 1
Training loss: 4.853705406188965
Validation loss: 5.034013225186255

Epoch: 5| Step: 2
Training loss: 4.89379358291626
Validation loss: 5.021050058385377

Epoch: 5| Step: 3
Training loss: 5.034592628479004
Validation loss: 5.006213972645421

Epoch: 5| Step: 4
Training loss: 4.903449058532715
Validation loss: 4.991452196592926

Epoch: 5| Step: 5
Training loss: 4.339366912841797
Validation loss: 4.975982025105466

Epoch: 5| Step: 6
Training loss: 3.9406814575195312
Validation loss: 4.95976750568677

Epoch: 5| Step: 7
Training loss: 5.889353275299072
Validation loss: 4.9434209023752524

Epoch: 5| Step: 8
Training loss: 4.9440178871154785
Validation loss: 4.926417991679202

Epoch: 5| Step: 9
Training loss: 4.492657661437988
Validation loss: 4.906599721600933

Epoch: 5| Step: 10
Training loss: 4.2957024574279785
Validation loss: 4.887651894682197

Epoch: 4| Step: 0
Training loss: 4.928126335144043
Validation loss: 4.867944032915177

Epoch: 5| Step: 1
Training loss: 5.007121562957764
Validation loss: 4.847096043248331

Epoch: 5| Step: 2
Training loss: 4.5804338455200195
Validation loss: 4.824788190985239

Epoch: 5| Step: 3
Training loss: 4.50963020324707
Validation loss: 4.803623330208563

Epoch: 5| Step: 4
Training loss: 4.371881484985352
Validation loss: 4.780633429045318

Epoch: 5| Step: 5
Training loss: 5.271824359893799
Validation loss: 4.7554658510351695

Epoch: 5| Step: 6
Training loss: 3.544943332672119
Validation loss: 4.733274531620805

Epoch: 5| Step: 7
Training loss: 4.914460182189941
Validation loss: 4.707688700768255

Epoch: 5| Step: 8
Training loss: 4.079437255859375
Validation loss: 4.6833872487468104

Epoch: 5| Step: 9
Training loss: 3.5130774974823
Validation loss: 4.656843000842679

Epoch: 5| Step: 10
Training loss: 5.340907096862793
Validation loss: 4.631023217273015

Epoch: 5| Step: 0
Training loss: 4.709036827087402
Validation loss: 4.605224347883655

Epoch: 5| Step: 1
Training loss: 4.900491237640381
Validation loss: 4.5793029672356065

Epoch: 5| Step: 2
Training loss: 5.375688076019287
Validation loss: 4.551668474751134

Epoch: 5| Step: 3
Training loss: 4.0810136795043945
Validation loss: 4.526654125541769

Epoch: 5| Step: 4
Training loss: 4.114211559295654
Validation loss: 4.497956791231709

Epoch: 5| Step: 5
Training loss: 3.6198582649230957
Validation loss: 4.472084178719469

Epoch: 5| Step: 6
Training loss: 4.343630313873291
Validation loss: 4.44544299956291

Epoch: 5| Step: 7
Training loss: 3.988481044769287
Validation loss: 4.419380100824499

Epoch: 5| Step: 8
Training loss: 4.401958465576172
Validation loss: 4.394644573170652

Epoch: 5| Step: 9
Training loss: 3.9888815879821777
Validation loss: 4.369331298335906

Epoch: 5| Step: 10
Training loss: 3.229858875274658
Validation loss: 4.34414953313848

Epoch: 6| Step: 0
Training loss: 4.082380771636963
Validation loss: 4.319527128691314

Epoch: 5| Step: 1
Training loss: 3.5210342407226562
Validation loss: 4.295404798241072

Epoch: 5| Step: 2
Training loss: 3.2350502014160156
Validation loss: 4.27193998008646

Epoch: 5| Step: 3
Training loss: 4.550108432769775
Validation loss: 4.249918117318102

Epoch: 5| Step: 4
Training loss: 3.3705222606658936
Validation loss: 4.2268982138685

Epoch: 5| Step: 5
Training loss: 4.402519226074219
Validation loss: 4.20663502395794

Epoch: 5| Step: 6
Training loss: 2.699676036834717
Validation loss: 4.184989565162248

Epoch: 5| Step: 7
Training loss: 5.5345258712768555
Validation loss: 4.1644739848311225

Epoch: 5| Step: 8
Training loss: 4.299656391143799
Validation loss: 4.14479939142863

Epoch: 5| Step: 9
Training loss: 4.848525524139404
Validation loss: 4.126594543457031

Epoch: 5| Step: 10
Training loss: 3.6776230335235596
Validation loss: 4.106395900890392

Epoch: 7| Step: 0
Training loss: 3.9357082843780518
Validation loss: 4.0891403485369935

Epoch: 5| Step: 1
Training loss: 3.753201961517334
Validation loss: 4.070168372123472

Epoch: 5| Step: 2
Training loss: 4.152182102203369
Validation loss: 4.0515410720661125

Epoch: 5| Step: 3
Training loss: 3.8946728706359863
Validation loss: 4.0347998706243375

Epoch: 5| Step: 4
Training loss: 3.2987418174743652
Validation loss: 4.018976273075227

Epoch: 5| Step: 5
Training loss: 3.2071502208709717
Validation loss: 4.00189850407262

Epoch: 5| Step: 6
Training loss: 4.922421455383301
Validation loss: 3.9850109520778862

Epoch: 5| Step: 7
Training loss: 3.0483028888702393
Validation loss: 3.9702556107633855

Epoch: 5| Step: 8
Training loss: 3.656193494796753
Validation loss: 3.952385348658408

Epoch: 5| Step: 9
Training loss: 4.730367660522461
Validation loss: 3.9386385640790387

Epoch: 5| Step: 10
Training loss: 3.709113121032715
Validation loss: 3.9217102501982

Epoch: 8| Step: 0
Training loss: 2.9209165573120117
Validation loss: 3.9046577228012906

Epoch: 5| Step: 1
Training loss: 3.9875736236572266
Validation loss: 3.890666969360844

Epoch: 5| Step: 2
Training loss: 4.870734691619873
Validation loss: 3.8751907758815314

Epoch: 5| Step: 3
Training loss: 2.84399151802063
Validation loss: 3.860600830406271

Epoch: 5| Step: 4
Training loss: 5.015193939208984
Validation loss: 3.847679297129313

Epoch: 5| Step: 5
Training loss: 2.609344482421875
Validation loss: 3.8339578464467037

Epoch: 5| Step: 6
Training loss: 3.4379372596740723
Validation loss: 3.819026680402858

Epoch: 5| Step: 7
Training loss: 3.792560577392578
Validation loss: 3.8060606756517963

Epoch: 5| Step: 8
Training loss: 3.774078369140625
Validation loss: 3.789845933196365

Epoch: 5| Step: 9
Training loss: 3.638936996459961
Validation loss: 3.777485837218582

Epoch: 5| Step: 10
Training loss: 3.874307632446289
Validation loss: 3.7629664380063295

Epoch: 9| Step: 0
Training loss: 2.9695372581481934
Validation loss: 3.7495465842626428

Epoch: 5| Step: 1
Training loss: 4.0350446701049805
Validation loss: 3.7360990739637807

Epoch: 5| Step: 2
Training loss: 4.362395286560059
Validation loss: 3.721042868911579

Epoch: 5| Step: 3
Training loss: 3.4088501930236816
Validation loss: 3.7083036207383677

Epoch: 5| Step: 4
Training loss: 2.3966853618621826
Validation loss: 3.6946398827337448

Epoch: 5| Step: 5
Training loss: 3.705246686935425
Validation loss: 3.679539954790505

Epoch: 5| Step: 6
Training loss: 3.5548224449157715
Validation loss: 3.6663955770513064

Epoch: 5| Step: 7
Training loss: 3.180346965789795
Validation loss: 3.651568115398448

Epoch: 5| Step: 8
Training loss: 4.343771457672119
Validation loss: 3.6388334176873647

Epoch: 5| Step: 9
Training loss: 3.68269681930542
Validation loss: 3.6223190138416905

Epoch: 5| Step: 10
Training loss: 3.8114700317382812
Validation loss: 3.609772205352783

Epoch: 10| Step: 0
Training loss: 2.640986680984497
Validation loss: 3.594967967720442

Epoch: 5| Step: 1
Training loss: 3.843806028366089
Validation loss: 3.5821020654452744

Epoch: 5| Step: 2
Training loss: 3.296588182449341
Validation loss: 3.5693471149731706

Epoch: 5| Step: 3
Training loss: 2.946580171585083
Validation loss: 3.5593796519822973

Epoch: 5| Step: 4
Training loss: 4.753666877746582
Validation loss: 3.5462001369845484

Epoch: 5| Step: 5
Training loss: 2.9870147705078125
Validation loss: 3.5345580782941592

Epoch: 5| Step: 6
Training loss: 3.38578724861145
Validation loss: 3.5224349011657057

Epoch: 5| Step: 7
Training loss: 3.359422206878662
Validation loss: 3.510399497965331

Epoch: 5| Step: 8
Training loss: 3.7256920337677
Validation loss: 3.4996147258307344

Epoch: 5| Step: 9
Training loss: 3.6217594146728516
Validation loss: 3.488199567282072

Epoch: 5| Step: 10
Training loss: 3.5022215843200684
Validation loss: 3.476925537150393

Epoch: 11| Step: 0
Training loss: 4.05823278427124
Validation loss: 3.4657864647526897

Epoch: 5| Step: 1
Training loss: 4.088551998138428
Validation loss: 3.4560254543058333

Epoch: 5| Step: 2
Training loss: 2.8475260734558105
Validation loss: 3.4414199552228375

Epoch: 5| Step: 3
Training loss: 3.4324164390563965
Validation loss: 3.432292348595076

Epoch: 5| Step: 4
Training loss: 3.21661114692688
Validation loss: 3.4239059545660533

Epoch: 5| Step: 5
Training loss: 3.4469032287597656
Validation loss: 3.4137931844239593

Epoch: 5| Step: 6
Training loss: 3.8599562644958496
Validation loss: 3.4036782608237317

Epoch: 5| Step: 7
Training loss: 3.3131988048553467
Validation loss: 3.3942267510198776

Epoch: 5| Step: 8
Training loss: 3.0824484825134277
Validation loss: 3.387240361141902

Epoch: 5| Step: 9
Training loss: 3.3630943298339844
Validation loss: 3.376387096220447

Epoch: 5| Step: 10
Training loss: 2.0824391841888428
Validation loss: 3.3694170726242887

Epoch: 12| Step: 0
Training loss: 4.1269636154174805
Validation loss: 3.3616559044007333

Epoch: 5| Step: 1
Training loss: 2.9921982288360596
Validation loss: 3.3519527912139893

Epoch: 5| Step: 2
Training loss: 3.3981316089630127
Validation loss: 3.346355374141406

Epoch: 5| Step: 3
Training loss: 3.1783947944641113
Validation loss: 3.3390672283787883

Epoch: 5| Step: 4
Training loss: 3.157431125640869
Validation loss: 3.329294071402601

Epoch: 5| Step: 5
Training loss: 3.2492878437042236
Validation loss: 3.3214503052414104

Epoch: 5| Step: 6
Training loss: 2.9466664791107178
Validation loss: 3.312576670800486

Epoch: 5| Step: 7
Training loss: 3.143296718597412
Validation loss: 3.3052778859292307

Epoch: 5| Step: 8
Training loss: 3.7619967460632324
Validation loss: 3.296210217219527

Epoch: 5| Step: 9
Training loss: 3.1468100547790527
Validation loss: 3.2878688150836575

Epoch: 5| Step: 10
Training loss: 3.0487234592437744
Validation loss: 3.2789701364373647

Epoch: 13| Step: 0
Training loss: 2.9746174812316895
Validation loss: 3.270246862083353

Epoch: 5| Step: 1
Training loss: 3.1023690700531006
Validation loss: 3.2637527681166127

Epoch: 5| Step: 2
Training loss: 3.5674381256103516
Validation loss: 3.2523247247101157

Epoch: 5| Step: 3
Training loss: 2.8920819759368896
Validation loss: 3.246012523610105

Epoch: 5| Step: 4
Training loss: 3.251201629638672
Validation loss: 3.2395799775277414

Epoch: 5| Step: 5
Training loss: 3.277207851409912
Validation loss: 3.2292021884713122

Epoch: 5| Step: 6
Training loss: 2.488060712814331
Validation loss: 3.217434206316548

Epoch: 5| Step: 7
Training loss: 4.744976043701172
Validation loss: 3.212021094496532

Epoch: 5| Step: 8
Training loss: 2.628267526626587
Validation loss: 3.204620263909781

Epoch: 5| Step: 9
Training loss: 3.4051451683044434
Validation loss: 3.197427508651569

Epoch: 5| Step: 10
Training loss: 3.0770363807678223
Validation loss: 3.1903729618236585

Epoch: 14| Step: 0
Training loss: 3.5359268188476562
Validation loss: 3.1868160155511673

Epoch: 5| Step: 1
Training loss: 2.868910074234009
Validation loss: 3.1784139294778146

Epoch: 5| Step: 2
Training loss: 3.918374538421631
Validation loss: 3.1705109970543974

Epoch: 5| Step: 3
Training loss: 3.049492120742798
Validation loss: 3.1654344733043382

Epoch: 5| Step: 4
Training loss: 3.3667540550231934
Validation loss: 3.160285606179186

Epoch: 5| Step: 5
Training loss: 2.870400905609131
Validation loss: 3.1545336143944853

Epoch: 5| Step: 6
Training loss: 2.9557242393493652
Validation loss: 3.1461928736779

Epoch: 5| Step: 7
Training loss: 3.942450761795044
Validation loss: 3.141440829923076

Epoch: 5| Step: 8
Training loss: 3.2184479236602783
Validation loss: 3.132755110340734

Epoch: 5| Step: 9
Training loss: 2.3242809772491455
Validation loss: 3.1292388003359557

Epoch: 5| Step: 10
Training loss: 2.6957807540893555
Validation loss: 3.1259024117582586

Epoch: 15| Step: 0
Training loss: 2.8189525604248047
Validation loss: 3.120203541171166

Epoch: 5| Step: 1
Training loss: 4.249755382537842
Validation loss: 3.1075840611611643

Epoch: 5| Step: 2
Training loss: 2.6798694133758545
Validation loss: 3.1083436371177755

Epoch: 5| Step: 3
Training loss: 3.193453311920166
Validation loss: 3.1032526595618135

Epoch: 5| Step: 4
Training loss: 3.1898176670074463
Validation loss: 3.1002234002595306

Epoch: 5| Step: 5
Training loss: 2.8564841747283936
Validation loss: 3.090709770879438

Epoch: 5| Step: 6
Training loss: 2.7734503746032715
Validation loss: 3.0894773390985306

Epoch: 5| Step: 7
Training loss: 3.581035614013672
Validation loss: 3.0804718514924407

Epoch: 5| Step: 8
Training loss: 2.6391215324401855
Validation loss: 3.077110957073909

Epoch: 5| Step: 9
Training loss: 3.6567864418029785
Validation loss: 3.0729073503965973

Epoch: 5| Step: 10
Training loss: 2.65116286277771
Validation loss: 3.0657848799100487

Epoch: 16| Step: 0
Training loss: 3.0025076866149902
Validation loss: 3.0594400359738256

Epoch: 5| Step: 1
Training loss: 1.9800714254379272
Validation loss: 3.057467811851091

Epoch: 5| Step: 2
Training loss: 2.9101309776306152
Validation loss: 3.0535498126860587

Epoch: 5| Step: 3
Training loss: 3.2315127849578857
Validation loss: 3.050658254213231

Epoch: 5| Step: 4
Training loss: 3.027228832244873
Validation loss: 3.042509155888711

Epoch: 5| Step: 5
Training loss: 3.325432538986206
Validation loss: 3.044284236046576

Epoch: 5| Step: 6
Training loss: 4.1551032066345215
Validation loss: 3.0596702714120187

Epoch: 5| Step: 7
Training loss: 2.9463906288146973
Validation loss: 3.032668282908778

Epoch: 5| Step: 8
Training loss: 2.827920913696289
Validation loss: 3.0264722275477585

Epoch: 5| Step: 9
Training loss: 3.8499817848205566
Validation loss: 3.0278114195792907

Epoch: 5| Step: 10
Training loss: 2.667494773864746
Validation loss: 3.025185000511908

Epoch: 17| Step: 0
Training loss: 2.4828453063964844
Validation loss: 3.02293312165045

Epoch: 5| Step: 1
Training loss: 3.8831284046173096
Validation loss: 3.017471767240955

Epoch: 5| Step: 2
Training loss: 2.8575894832611084
Validation loss: 3.0091513664491716

Epoch: 5| Step: 3
Training loss: 3.4453272819519043
Validation loss: 3.0061227531843286

Epoch: 5| Step: 4
Training loss: 3.767052173614502
Validation loss: 3.001763515574958

Epoch: 5| Step: 5
Training loss: 2.687486410140991
Validation loss: 2.9989744950366277

Epoch: 5| Step: 6
Training loss: 2.420318126678467
Validation loss: 2.9927601916815645

Epoch: 5| Step: 7
Training loss: 2.9037814140319824
Validation loss: 2.9931456811966433

Epoch: 5| Step: 8
Training loss: 3.4371814727783203
Validation loss: 2.990267138327322

Epoch: 5| Step: 9
Training loss: 2.441763401031494
Validation loss: 2.9845263906704482

Epoch: 5| Step: 10
Training loss: 3.433295965194702
Validation loss: 2.9796576423029744

Epoch: 18| Step: 0
Training loss: 3.6081085205078125
Validation loss: 2.9752242872791905

Epoch: 5| Step: 1
Training loss: 3.0869007110595703
Validation loss: 2.9722080487076954

Epoch: 5| Step: 2
Training loss: 2.8658387660980225
Validation loss: 2.967122003596316

Epoch: 5| Step: 3
Training loss: 3.0765061378479004
Validation loss: 2.965941700884091

Epoch: 5| Step: 4
Training loss: 3.0889294147491455
Validation loss: 2.9570427453646095

Epoch: 5| Step: 5
Training loss: 3.4719367027282715
Validation loss: 2.9596291742017193

Epoch: 5| Step: 6
Training loss: 3.67619252204895
Validation loss: 2.957421887305475

Epoch: 5| Step: 7
Training loss: 3.0579566955566406
Validation loss: 2.958418789730277

Epoch: 5| Step: 8
Training loss: 1.7509702444076538
Validation loss: 2.9571816767415693

Epoch: 5| Step: 9
Training loss: 3.0151712894439697
Validation loss: 2.9505724214738414

Epoch: 5| Step: 10
Training loss: 2.6786272525787354
Validation loss: 2.9484788884398756

Epoch: 19| Step: 0
Training loss: 2.6734399795532227
Validation loss: 2.943439781024892

Epoch: 5| Step: 1
Training loss: 2.4534146785736084
Validation loss: 2.939323643202423

Epoch: 5| Step: 2
Training loss: 2.393068313598633
Validation loss: 2.935421892391738

Epoch: 5| Step: 3
Training loss: 3.0909812450408936
Validation loss: 2.9339796138066117

Epoch: 5| Step: 4
Training loss: 4.265026092529297
Validation loss: 2.9329541780615367

Epoch: 5| Step: 5
Training loss: 2.943739414215088
Validation loss: 2.9282131451432423

Epoch: 5| Step: 6
Training loss: 3.7252469062805176
Validation loss: 2.930701571126138

Epoch: 5| Step: 7
Training loss: 3.2594172954559326
Validation loss: 2.9306283714950725

Epoch: 5| Step: 8
Training loss: 2.0802087783813477
Validation loss: 2.9237937850336873

Epoch: 5| Step: 9
Training loss: 3.504848003387451
Validation loss: 2.922026772652903

Epoch: 5| Step: 10
Training loss: 2.7488210201263428
Validation loss: 2.9230786010783207

Epoch: 20| Step: 0
Training loss: 3.148618221282959
Validation loss: 2.9234351214542182

Epoch: 5| Step: 1
Training loss: 1.9936023950576782
Validation loss: 2.9241266865884104

Epoch: 5| Step: 2
Training loss: 2.549560070037842
Validation loss: 2.924892610119235

Epoch: 5| Step: 3
Training loss: 3.786710023880005
Validation loss: 2.922936636914489

Epoch: 5| Step: 4
Training loss: 3.137263774871826
Validation loss: 2.9119188683007353

Epoch: 5| Step: 5
Training loss: 3.2667336463928223
Validation loss: 2.9120103697622977

Epoch: 5| Step: 6
Training loss: 2.564465045928955
Validation loss: 2.9048355061520814

Epoch: 5| Step: 7
Training loss: 3.714351177215576
Validation loss: 2.906177359242593

Epoch: 5| Step: 8
Training loss: 4.074093818664551
Validation loss: 2.899142754975186

Epoch: 5| Step: 9
Training loss: 2.0680222511291504
Validation loss: 2.899623634994671

Epoch: 5| Step: 10
Training loss: 2.668304681777954
Validation loss: 2.8951389379398798

Epoch: 21| Step: 0
Training loss: 2.9788689613342285
Validation loss: 2.8917845192775933

Epoch: 5| Step: 1
Training loss: 3.3564839363098145
Validation loss: 2.89046472631475

Epoch: 5| Step: 2
Training loss: 2.5397677421569824
Validation loss: 2.886886155733498

Epoch: 5| Step: 3
Training loss: 3.252042770385742
Validation loss: 2.8839494669309227

Epoch: 5| Step: 4
Training loss: 3.571075439453125
Validation loss: 2.8836983583306752

Epoch: 5| Step: 5
Training loss: 2.2714428901672363
Validation loss: 2.8845539016108357

Epoch: 5| Step: 6
Training loss: 3.667370557785034
Validation loss: 2.8807101813695764

Epoch: 5| Step: 7
Training loss: 3.0407700538635254
Validation loss: 2.878061568865212

Epoch: 5| Step: 8
Training loss: 2.626490354537964
Validation loss: 2.874968105746854

Epoch: 5| Step: 9
Training loss: 2.825059413909912
Validation loss: 2.874844217813143

Epoch: 5| Step: 10
Training loss: 2.652472496032715
Validation loss: 2.8742788222528275

Epoch: 22| Step: 0
Training loss: 2.7784032821655273
Validation loss: 2.87168260030849

Epoch: 5| Step: 1
Training loss: 3.923283100128174
Validation loss: 2.869305685002317

Epoch: 5| Step: 2
Training loss: 2.533504009246826
Validation loss: 2.867231766382853

Epoch: 5| Step: 3
Training loss: 2.5129637718200684
Validation loss: 2.866838016817647

Epoch: 5| Step: 4
Training loss: 2.372302293777466
Validation loss: 2.8639202784466486

Epoch: 5| Step: 5
Training loss: 2.6248486042022705
Validation loss: 2.8659698373527935

Epoch: 5| Step: 6
Training loss: 3.0697579383850098
Validation loss: 2.861299730116321

Epoch: 5| Step: 7
Training loss: 2.709824323654175
Validation loss: 2.8603562437078005

Epoch: 5| Step: 8
Training loss: 3.8444900512695312
Validation loss: 2.860687909587737

Epoch: 5| Step: 9
Training loss: 2.6172313690185547
Validation loss: 2.8591636919206187

Epoch: 5| Step: 10
Training loss: 3.8464298248291016
Validation loss: 2.8546721371271278

Epoch: 23| Step: 0
Training loss: 3.1258997917175293
Validation loss: 2.8540027218480266

Epoch: 5| Step: 1
Training loss: 2.6926188468933105
Validation loss: 2.854356053054974

Epoch: 5| Step: 2
Training loss: 3.725755214691162
Validation loss: 2.8520558213674896

Epoch: 5| Step: 3
Training loss: 2.848069429397583
Validation loss: 2.8503538844405965

Epoch: 5| Step: 4
Training loss: 3.0582144260406494
Validation loss: 2.8515040541207917

Epoch: 5| Step: 5
Training loss: 2.342113494873047
Validation loss: 2.8461528978040143

Epoch: 5| Step: 6
Training loss: 2.8062984943389893
Validation loss: 2.843416239625664

Epoch: 5| Step: 7
Training loss: 2.8884501457214355
Validation loss: 2.8432270737104517

Epoch: 5| Step: 8
Training loss: 2.6410841941833496
Validation loss: 2.847422771556403

Epoch: 5| Step: 9
Training loss: 3.0414788722991943
Validation loss: 2.8553646200446674

Epoch: 5| Step: 10
Training loss: 3.483271598815918
Validation loss: 2.850215112009356

Epoch: 24| Step: 0
Training loss: 3.583301544189453
Validation loss: 2.85897486184233

Epoch: 5| Step: 1
Training loss: 2.9934792518615723
Validation loss: 2.837828684878606

Epoch: 5| Step: 2
Training loss: 2.31062388420105
Validation loss: 2.8366367073469263

Epoch: 5| Step: 3
Training loss: 3.2914817333221436
Validation loss: 2.8383250133965605

Epoch: 5| Step: 4
Training loss: 2.45593523979187
Validation loss: 2.8376019385553177

Epoch: 5| Step: 5
Training loss: 3.4621918201446533
Validation loss: 2.8415479967671056

Epoch: 5| Step: 6
Training loss: 2.7790064811706543
Validation loss: 2.8398860731432514

Epoch: 5| Step: 7
Training loss: 2.6770212650299072
Validation loss: 2.8428520387218845

Epoch: 5| Step: 8
Training loss: 2.646376848220825
Validation loss: 2.8375012848966863

Epoch: 5| Step: 9
Training loss: 3.0797953605651855
Validation loss: 2.83552994010269

Epoch: 5| Step: 10
Training loss: 3.3065171241760254
Validation loss: 2.83268912120532

Epoch: 25| Step: 0
Training loss: 3.158324718475342
Validation loss: 2.8317158863108647

Epoch: 5| Step: 1
Training loss: 3.235541582107544
Validation loss: 2.8325581986417054

Epoch: 5| Step: 2
Training loss: 3.097102403640747
Validation loss: 2.8302471945362706

Epoch: 5| Step: 3
Training loss: 3.3496947288513184
Validation loss: 2.828700165594778

Epoch: 5| Step: 4
Training loss: 2.592628002166748
Validation loss: 2.8313049603534

Epoch: 5| Step: 5
Training loss: 2.9636616706848145
Validation loss: 2.8267212170426563

Epoch: 5| Step: 6
Training loss: 3.115027666091919
Validation loss: 2.8257853061922136

Epoch: 5| Step: 7
Training loss: 2.746445894241333
Validation loss: 2.825623955777896

Epoch: 5| Step: 8
Training loss: 2.712477922439575
Validation loss: 2.8208029141990085

Epoch: 5| Step: 9
Training loss: 2.506746530532837
Validation loss: 2.820274083845077

Epoch: 5| Step: 10
Training loss: 2.9566433429718018
Validation loss: 2.8162333606391825

Epoch: 26| Step: 0
Training loss: 2.7483363151550293
Validation loss: 2.817651633293398

Epoch: 5| Step: 1
Training loss: 3.2777507305145264
Validation loss: 2.81135307845249

Epoch: 5| Step: 2
Training loss: 2.7905163764953613
Validation loss: 2.8141428809012137

Epoch: 5| Step: 3
Training loss: 2.311737298965454
Validation loss: 2.8126851127993677

Epoch: 5| Step: 4
Training loss: 2.8770251274108887
Validation loss: 2.8113109014367543

Epoch: 5| Step: 5
Training loss: 3.195664882659912
Validation loss: 2.8132645237830376

Epoch: 5| Step: 6
Training loss: 2.8702964782714844
Validation loss: 2.8090140691367527

Epoch: 5| Step: 7
Training loss: 3.5030364990234375
Validation loss: 2.809900317140805

Epoch: 5| Step: 8
Training loss: 2.746793746948242
Validation loss: 2.805756704781645

Epoch: 5| Step: 9
Training loss: 3.1297354698181152
Validation loss: 2.8043564237574095

Epoch: 5| Step: 10
Training loss: 2.86859130859375
Validation loss: 2.8039203177216234

Epoch: 27| Step: 0
Training loss: 2.428375482559204
Validation loss: 2.8028642926164853

Epoch: 5| Step: 1
Training loss: 2.9268500804901123
Validation loss: 2.7998724906675276

Epoch: 5| Step: 2
Training loss: 2.8971853256225586
Validation loss: 2.799015998840332

Epoch: 5| Step: 3
Training loss: 3.2534568309783936
Validation loss: 2.797048509761851

Epoch: 5| Step: 4
Training loss: 2.6276774406433105
Validation loss: 2.7960444317069104

Epoch: 5| Step: 5
Training loss: 2.6663525104522705
Validation loss: 2.7978040197844147

Epoch: 5| Step: 6
Training loss: 3.193061113357544
Validation loss: 2.7946460298312608

Epoch: 5| Step: 7
Training loss: 3.2389073371887207
Validation loss: 2.794083974694693

Epoch: 5| Step: 8
Training loss: 3.1557953357696533
Validation loss: 2.795193713198426

Epoch: 5| Step: 9
Training loss: 2.673809051513672
Validation loss: 2.792577141074724

Epoch: 5| Step: 10
Training loss: 3.230815887451172
Validation loss: 2.792802200522474

Epoch: 28| Step: 0
Training loss: 2.5475802421569824
Validation loss: 2.7913234208219793

Epoch: 5| Step: 1
Training loss: 2.5656845569610596
Validation loss: 2.7875392129344325

Epoch: 5| Step: 2
Training loss: 3.5716636180877686
Validation loss: 2.789336335274481

Epoch: 5| Step: 3
Training loss: 3.0185840129852295
Validation loss: 2.785594606912264

Epoch: 5| Step: 4
Training loss: 2.558690309524536
Validation loss: 2.7854350331009075

Epoch: 5| Step: 5
Training loss: 2.59865403175354
Validation loss: 2.785169309185397

Epoch: 5| Step: 6
Training loss: 3.4482502937316895
Validation loss: 2.78163178249072

Epoch: 5| Step: 7
Training loss: 3.8259291648864746
Validation loss: 2.779097395558511

Epoch: 5| Step: 8
Training loss: 2.581206798553467
Validation loss: 2.780540948273033

Epoch: 5| Step: 9
Training loss: 3.196547508239746
Validation loss: 2.7830738482936734

Epoch: 5| Step: 10
Training loss: 2.1095917224884033
Validation loss: 2.7811859423114407

Epoch: 29| Step: 0
Training loss: 3.0457711219787598
Validation loss: 2.782918458343834

Epoch: 5| Step: 1
Training loss: 3.011359691619873
Validation loss: 2.7815521353034565

Epoch: 5| Step: 2
Training loss: 2.4089202880859375
Validation loss: 2.7824725848372265

Epoch: 5| Step: 3
Training loss: 2.9833874702453613
Validation loss: 2.7843948410403345

Epoch: 5| Step: 4
Training loss: 2.9760098457336426
Validation loss: 2.784662469740837

Epoch: 5| Step: 5
Training loss: 3.1536993980407715
Validation loss: 2.783961775482342

Epoch: 5| Step: 6
Training loss: 2.9349775314331055
Validation loss: 2.7799966950570383

Epoch: 5| Step: 7
Training loss: 2.9519143104553223
Validation loss: 2.7734953921328307

Epoch: 5| Step: 8
Training loss: 3.2974724769592285
Validation loss: 2.7727815489615164

Epoch: 5| Step: 9
Training loss: 3.225543975830078
Validation loss: 2.7720830696885304

Epoch: 5| Step: 10
Training loss: 1.9748777151107788
Validation loss: 2.7704724637410973

Epoch: 30| Step: 0
Training loss: 2.9832706451416016
Validation loss: 2.771374694762691

Epoch: 5| Step: 1
Training loss: 3.1026949882507324
Validation loss: 2.768793377825009

Epoch: 5| Step: 2
Training loss: 2.9516093730926514
Validation loss: 2.7706954786854405

Epoch: 5| Step: 3
Training loss: 3.1690032482147217
Validation loss: 2.7695261611733386

Epoch: 5| Step: 4
Training loss: 3.0567047595977783
Validation loss: 2.7700551043274584

Epoch: 5| Step: 5
Training loss: 1.9111392498016357
Validation loss: 2.7657104512696624

Epoch: 5| Step: 6
Training loss: 3.55281400680542
Validation loss: 2.765878149258193

Epoch: 5| Step: 7
Training loss: 3.050987958908081
Validation loss: 2.7675202097944034

Epoch: 5| Step: 8
Training loss: 3.1850008964538574
Validation loss: 2.769137279961699

Epoch: 5| Step: 9
Training loss: 2.492370128631592
Validation loss: 2.7746587055985645

Epoch: 5| Step: 10
Training loss: 2.513678550720215
Validation loss: 2.7682659446552234

Epoch: 31| Step: 0
Training loss: 3.262199878692627
Validation loss: 2.7646824518839517

Epoch: 5| Step: 1
Training loss: 3.1479554176330566
Validation loss: 2.7648805623413413

Epoch: 5| Step: 2
Training loss: 3.364321231842041
Validation loss: 2.7627746161594184

Epoch: 5| Step: 3
Training loss: 3.2082009315490723
Validation loss: 2.754565674771545

Epoch: 5| Step: 4
Training loss: 2.2863712310791016
Validation loss: 2.755854111845775

Epoch: 5| Step: 5
Training loss: 3.096858024597168
Validation loss: 2.754804618896977

Epoch: 5| Step: 6
Training loss: 2.9244494438171387
Validation loss: 2.75306732936572

Epoch: 5| Step: 7
Training loss: 2.2808802127838135
Validation loss: 2.752622424915273

Epoch: 5| Step: 8
Training loss: 2.2651126384735107
Validation loss: 2.7524073098295476

Epoch: 5| Step: 9
Training loss: 3.1449992656707764
Validation loss: 2.753384659367223

Epoch: 5| Step: 10
Training loss: 2.9971511363983154
Validation loss: 2.756559015602194

Epoch: 32| Step: 0
Training loss: 3.406059980392456
Validation loss: 2.7507654056754163

Epoch: 5| Step: 1
Training loss: 2.4024157524108887
Validation loss: 2.7528918327823764

Epoch: 5| Step: 2
Training loss: 2.557460308074951
Validation loss: 2.7493487558057232

Epoch: 5| Step: 3
Training loss: 2.911297559738159
Validation loss: 2.7485166826555805

Epoch: 5| Step: 4
Training loss: 3.0410759449005127
Validation loss: 2.7468580148553334

Epoch: 5| Step: 5
Training loss: 2.7824716567993164
Validation loss: 2.7427167943728867

Epoch: 5| Step: 6
Training loss: 2.76796293258667
Validation loss: 2.7428797393716793

Epoch: 5| Step: 7
Training loss: 4.345167636871338
Validation loss: 2.7457508656286422

Epoch: 5| Step: 8
Training loss: 2.0387887954711914
Validation loss: 2.7479592574540006

Epoch: 5| Step: 9
Training loss: 3.1039834022521973
Validation loss: 2.7430125257020355

Epoch: 5| Step: 10
Training loss: 2.465108871459961
Validation loss: 2.7431106182836715

Epoch: 33| Step: 0
Training loss: 2.971682071685791
Validation loss: 2.739903450012207

Epoch: 5| Step: 1
Training loss: 2.816035032272339
Validation loss: 2.7392980898580244

Epoch: 5| Step: 2
Training loss: 2.9688360691070557
Validation loss: 2.740768317253359

Epoch: 5| Step: 3
Training loss: 2.6810503005981445
Validation loss: 2.7351192710220174

Epoch: 5| Step: 4
Training loss: 2.9962379932403564
Validation loss: 2.732797194552678

Epoch: 5| Step: 5
Training loss: 2.4660987854003906
Validation loss: 2.7367902724973616

Epoch: 5| Step: 6
Training loss: 2.9008870124816895
Validation loss: 2.7333565578665784

Epoch: 5| Step: 7
Training loss: 3.23516583442688
Validation loss: 2.7295559836972143

Epoch: 5| Step: 8
Training loss: 2.6560142040252686
Validation loss: 2.727358130998509

Epoch: 5| Step: 9
Training loss: 3.614539623260498
Validation loss: 2.727458938475578

Epoch: 5| Step: 10
Training loss: 2.3951728343963623
Validation loss: 2.730351217331425

Epoch: 34| Step: 0
Training loss: 2.3111257553100586
Validation loss: 2.734809419160248

Epoch: 5| Step: 1
Training loss: 3.5160775184631348
Validation loss: 2.728782246189733

Epoch: 5| Step: 2
Training loss: 3.2846622467041016
Validation loss: 2.7238503092078754

Epoch: 5| Step: 3
Training loss: 3.0664639472961426
Validation loss: 2.718007887563398

Epoch: 5| Step: 4
Training loss: 2.362110137939453
Validation loss: 2.7179338573127665

Epoch: 5| Step: 5
Training loss: 2.062389612197876
Validation loss: 2.719523060706354

Epoch: 5| Step: 6
Training loss: 3.132913827896118
Validation loss: 2.716094752793671

Epoch: 5| Step: 7
Training loss: 3.3649280071258545
Validation loss: 2.7214917649504957

Epoch: 5| Step: 8
Training loss: 2.8762259483337402
Validation loss: 2.7179208365819787

Epoch: 5| Step: 9
Training loss: 3.0491230487823486
Validation loss: 2.719323109554988

Epoch: 5| Step: 10
Training loss: 2.624504804611206
Validation loss: 2.718077410933792

Epoch: 35| Step: 0
Training loss: 3.2392215728759766
Validation loss: 2.7163248856862388

Epoch: 5| Step: 1
Training loss: 2.653883457183838
Validation loss: 2.7173777190587853

Epoch: 5| Step: 2
Training loss: 3.6861329078674316
Validation loss: 2.7185684609156784

Epoch: 5| Step: 3
Training loss: 2.737064838409424
Validation loss: 2.713643122744817

Epoch: 5| Step: 4
Training loss: 2.7826685905456543
Validation loss: 2.716614889842208

Epoch: 5| Step: 5
Training loss: 3.2199409008026123
Validation loss: 2.714162585555866

Epoch: 5| Step: 6
Training loss: 1.6074960231781006
Validation loss: 2.711582306892641

Epoch: 5| Step: 7
Training loss: 2.5023512840270996
Validation loss: 2.708685959539106

Epoch: 5| Step: 8
Training loss: 2.94880747795105
Validation loss: 2.7111084845758255

Epoch: 5| Step: 9
Training loss: 3.2953267097473145
Validation loss: 2.709768118396882

Epoch: 5| Step: 10
Training loss: 2.9843454360961914
Validation loss: 2.7073888035230738

Epoch: 36| Step: 0
Training loss: 2.616481304168701
Validation loss: 2.7040314289831344

Epoch: 5| Step: 1
Training loss: 2.511277437210083
Validation loss: 2.7026373391510337

Epoch: 5| Step: 2
Training loss: 3.2106094360351562
Validation loss: 2.7018311049348567

Epoch: 5| Step: 3
Training loss: 3.1147971153259277
Validation loss: 2.7029601707253406

Epoch: 5| Step: 4
Training loss: 2.499197244644165
Validation loss: 2.6997990813306583

Epoch: 5| Step: 5
Training loss: 3.20487904548645
Validation loss: 2.6978540369259414

Epoch: 5| Step: 6
Training loss: 2.7458279132843018
Validation loss: 2.698818478533017

Epoch: 5| Step: 7
Training loss: 3.2161993980407715
Validation loss: 2.699164149581745

Epoch: 5| Step: 8
Training loss: 3.0519442558288574
Validation loss: 2.6984484349527667

Epoch: 5| Step: 9
Training loss: 2.785245418548584
Validation loss: 2.6972430277896184

Epoch: 5| Step: 10
Training loss: 2.556580066680908
Validation loss: 2.6952671889335877

Epoch: 37| Step: 0
Training loss: 2.2157154083251953
Validation loss: 2.694607262970299

Epoch: 5| Step: 1
Training loss: 2.9582111835479736
Validation loss: 2.6958891781427528

Epoch: 5| Step: 2
Training loss: 3.314152479171753
Validation loss: 2.6919382541410384

Epoch: 5| Step: 3
Training loss: 2.6010537147521973
Validation loss: 2.68969722460675

Epoch: 5| Step: 4
Training loss: 2.9312400817871094
Validation loss: 2.6939972421174407

Epoch: 5| Step: 5
Training loss: 2.488180637359619
Validation loss: 2.688492492962909

Epoch: 5| Step: 6
Training loss: 2.556609630584717
Validation loss: 2.69325594235492

Epoch: 5| Step: 7
Training loss: 2.918677806854248
Validation loss: 2.696668712041711

Epoch: 5| Step: 8
Training loss: 3.445394992828369
Validation loss: 2.693560787426528

Epoch: 5| Step: 9
Training loss: 3.4902732372283936
Validation loss: 2.6922615010251283

Epoch: 5| Step: 10
Training loss: 2.5374011993408203
Validation loss: 2.6948406004136607

Epoch: 38| Step: 0
Training loss: 3.3504557609558105
Validation loss: 2.6902940914195073

Epoch: 5| Step: 1
Training loss: 2.9960741996765137
Validation loss: 2.691500617611793

Epoch: 5| Step: 2
Training loss: 1.8266899585723877
Validation loss: 2.6907195686012186

Epoch: 5| Step: 3
Training loss: 3.698922634124756
Validation loss: 2.690515689952399

Epoch: 5| Step: 4
Training loss: 2.5605685710906982
Validation loss: 2.693118877308343

Epoch: 5| Step: 5
Training loss: 3.0802645683288574
Validation loss: 2.699495546279415

Epoch: 5| Step: 6
Training loss: 2.5832996368408203
Validation loss: 2.6963671433028353

Epoch: 5| Step: 7
Training loss: 2.0021250247955322
Validation loss: 2.6948017099852204

Epoch: 5| Step: 8
Training loss: 3.5679335594177246
Validation loss: 2.686292363751319

Epoch: 5| Step: 9
Training loss: 3.3635311126708984
Validation loss: 2.6821889467136835

Epoch: 5| Step: 10
Training loss: 2.3044536113739014
Validation loss: 2.6795511835364887

Epoch: 39| Step: 0
Training loss: 2.9515278339385986
Validation loss: 2.683896851795976

Epoch: 5| Step: 1
Training loss: 3.458340883255005
Validation loss: 2.680279037003876

Epoch: 5| Step: 2
Training loss: 2.8325929641723633
Validation loss: 2.682372329055622

Epoch: 5| Step: 3
Training loss: 2.7656233310699463
Validation loss: 2.676288999536986

Epoch: 5| Step: 4
Training loss: 2.984143018722534
Validation loss: 2.6734625729181434

Epoch: 5| Step: 5
Training loss: 2.195436716079712
Validation loss: 2.673112197588849

Epoch: 5| Step: 6
Training loss: 3.381603956222534
Validation loss: 2.6732789188302974

Epoch: 5| Step: 7
Training loss: 2.495300769805908
Validation loss: 2.667355875815115

Epoch: 5| Step: 8
Training loss: 2.86043119430542
Validation loss: 2.662719424052905

Epoch: 5| Step: 9
Training loss: 2.6745142936706543
Validation loss: 2.665173658760645

Epoch: 5| Step: 10
Training loss: 2.796680212020874
Validation loss: 2.6637667148343978

Epoch: 40| Step: 0
Training loss: 2.7151074409484863
Validation loss: 2.6622708920509583

Epoch: 5| Step: 1
Training loss: 3.1748318672180176
Validation loss: 2.6651491580470914

Epoch: 5| Step: 2
Training loss: 3.026474714279175
Validation loss: 2.663260680372997

Epoch: 5| Step: 3
Training loss: 3.29609751701355
Validation loss: 2.6636826684398036

Epoch: 5| Step: 4
Training loss: 3.2068610191345215
Validation loss: 2.6644325179438435

Epoch: 5| Step: 5
Training loss: 2.9189910888671875
Validation loss: 2.665424439214891

Epoch: 5| Step: 6
Training loss: 2.9025416374206543
Validation loss: 2.663119252010058

Epoch: 5| Step: 7
Training loss: 3.205798625946045
Validation loss: 2.6627853942173783

Epoch: 5| Step: 8
Training loss: 2.295342206954956
Validation loss: 2.660638798949539

Epoch: 5| Step: 9
Training loss: 2.5607717037200928
Validation loss: 2.656247954214773

Epoch: 5| Step: 10
Training loss: 1.822659969329834
Validation loss: 2.654938546560144

Epoch: 41| Step: 0
Training loss: 3.546846389770508
Validation loss: 2.6623757705893567

Epoch: 5| Step: 1
Training loss: 2.8309884071350098
Validation loss: 2.6589455502007597

Epoch: 5| Step: 2
Training loss: 2.837714195251465
Validation loss: 2.6601511893733853

Epoch: 5| Step: 3
Training loss: 2.0790457725524902
Validation loss: 2.6563898953058387

Epoch: 5| Step: 4
Training loss: 2.6954331398010254
Validation loss: 2.6482949513261036

Epoch: 5| Step: 5
Training loss: 2.4817709922790527
Validation loss: 2.6532605540367866

Epoch: 5| Step: 6
Training loss: 2.306692600250244
Validation loss: 2.653007279160202

Epoch: 5| Step: 7
Training loss: 3.358048915863037
Validation loss: 2.6595507693547074

Epoch: 5| Step: 8
Training loss: 2.631647825241089
Validation loss: 2.6623888143929104

Epoch: 5| Step: 9
Training loss: 3.1982789039611816
Validation loss: 2.6568820681623233

Epoch: 5| Step: 10
Training loss: 3.340823173522949
Validation loss: 2.650024398680656

Epoch: 42| Step: 0
Training loss: 3.6583354473114014
Validation loss: 2.649511206534601

Epoch: 5| Step: 1
Training loss: 2.4936342239379883
Validation loss: 2.64868926489225

Epoch: 5| Step: 2
Training loss: 2.1634631156921387
Validation loss: 2.648976807953209

Epoch: 5| Step: 3
Training loss: 1.8887100219726562
Validation loss: 2.6480943285008913

Epoch: 5| Step: 4
Training loss: 2.8922266960144043
Validation loss: 2.64825988072221

Epoch: 5| Step: 5
Training loss: 3.096813678741455
Validation loss: 2.6487392328118764

Epoch: 5| Step: 6
Training loss: 3.322312831878662
Validation loss: 2.647522034183625

Epoch: 5| Step: 7
Training loss: 2.227409601211548
Validation loss: 2.6460783661052747

Epoch: 5| Step: 8
Training loss: 3.125004529953003
Validation loss: 2.6421985831311954

Epoch: 5| Step: 9
Training loss: 2.5756237506866455
Validation loss: 2.642509409176406

Epoch: 5| Step: 10
Training loss: 3.847532272338867
Validation loss: 2.6428543136965845

Epoch: 43| Step: 0
Training loss: 2.6777377128601074
Validation loss: 2.635642638770483

Epoch: 5| Step: 1
Training loss: 3.352367401123047
Validation loss: 2.6380871495892926

Epoch: 5| Step: 2
Training loss: 3.4372124671936035
Validation loss: 2.635335906859367

Epoch: 5| Step: 3
Training loss: 2.0225062370300293
Validation loss: 2.6303336312693935

Epoch: 5| Step: 4
Training loss: 2.9978015422821045
Validation loss: 2.6297865170304493

Epoch: 5| Step: 5
Training loss: 2.2226028442382812
Validation loss: 2.629519652294856

Epoch: 5| Step: 6
Training loss: 2.623436450958252
Validation loss: 2.6251816236844627

Epoch: 5| Step: 7
Training loss: 2.5659146308898926
Validation loss: 2.6308854164615756

Epoch: 5| Step: 8
Training loss: 3.0906383991241455
Validation loss: 2.6281403431328396

Epoch: 5| Step: 9
Training loss: 2.643474578857422
Validation loss: 2.62664395506664

Epoch: 5| Step: 10
Training loss: 3.476073980331421
Validation loss: 2.6233755619295183

Epoch: 44| Step: 0
Training loss: 2.8277950286865234
Validation loss: 2.6246666651900097

Epoch: 5| Step: 1
Training loss: 2.8780975341796875
Validation loss: 2.624050327526626

Epoch: 5| Step: 2
Training loss: 2.646191120147705
Validation loss: 2.624487884583012

Epoch: 5| Step: 3
Training loss: 2.3144383430480957
Validation loss: 2.624219386808334

Epoch: 5| Step: 4
Training loss: 3.999182939529419
Validation loss: 2.62043668377784

Epoch: 5| Step: 5
Training loss: 2.2289302349090576
Validation loss: 2.624503122862949

Epoch: 5| Step: 6
Training loss: 2.553898334503174
Validation loss: 2.625703562972366

Epoch: 5| Step: 7
Training loss: 2.626922130584717
Validation loss: 2.6212693901472193

Epoch: 5| Step: 8
Training loss: 3.4506633281707764
Validation loss: 2.624450960466939

Epoch: 5| Step: 9
Training loss: 2.1520676612854004
Validation loss: 2.624621065714026

Epoch: 5| Step: 10
Training loss: 3.3752827644348145
Validation loss: 2.6210850720764487

Epoch: 45| Step: 0
Training loss: 2.940929651260376
Validation loss: 2.627876140738046

Epoch: 5| Step: 1
Training loss: 3.6880595684051514
Validation loss: 2.6267610057707755

Epoch: 5| Step: 2
Training loss: 2.210422992706299
Validation loss: 2.623804651280885

Epoch: 5| Step: 3
Training loss: 2.620699405670166
Validation loss: 2.6216064704361783

Epoch: 5| Step: 4
Training loss: 3.5898070335388184
Validation loss: 2.621179983180056

Epoch: 5| Step: 5
Training loss: 3.0226495265960693
Validation loss: 2.6212021432897097

Epoch: 5| Step: 6
Training loss: 2.2420287132263184
Validation loss: 2.6218817592948995

Epoch: 5| Step: 7
Training loss: 2.7774291038513184
Validation loss: 2.62295558375697

Epoch: 5| Step: 8
Training loss: 2.078355312347412
Validation loss: 2.6253444866467546

Epoch: 5| Step: 9
Training loss: 3.030837059020996
Validation loss: 2.627219864117202

Epoch: 5| Step: 10
Training loss: 2.728231430053711
Validation loss: 2.627792964699448

Epoch: 46| Step: 0
Training loss: 2.7338614463806152
Validation loss: 2.6278457615965154

Epoch: 5| Step: 1
Training loss: 2.55326247215271
Validation loss: 2.6229284860754527

Epoch: 5| Step: 2
Training loss: 3.603105068206787
Validation loss: 2.616502167076193

Epoch: 5| Step: 3
Training loss: 2.8826546669006348
Validation loss: 2.621188896958546

Epoch: 5| Step: 4
Training loss: 2.4502768516540527
Validation loss: 2.626559231870918

Epoch: 5| Step: 5
Training loss: 3.2517776489257812
Validation loss: 2.632708385426511

Epoch: 5| Step: 6
Training loss: 1.9103714227676392
Validation loss: 2.6466876563205513

Epoch: 5| Step: 7
Training loss: 2.538621187210083
Validation loss: 2.6398908938131025

Epoch: 5| Step: 8
Training loss: 3.678117275238037
Validation loss: 2.6224906265094714

Epoch: 5| Step: 9
Training loss: 2.790754795074463
Validation loss: 2.6178893222603747

Epoch: 5| Step: 10
Training loss: 2.5265684127807617
Validation loss: 2.612415067611202

Epoch: 47| Step: 0
Training loss: 2.43021559715271
Validation loss: 2.6110647852702806

Epoch: 5| Step: 1
Training loss: 2.690450429916382
Validation loss: 2.6101427026974258

Epoch: 5| Step: 2
Training loss: 3.2523436546325684
Validation loss: 2.6109660876694547

Epoch: 5| Step: 3
Training loss: 2.533024311065674
Validation loss: 2.609327244502242

Epoch: 5| Step: 4
Training loss: 3.3177947998046875
Validation loss: 2.611109636163199

Epoch: 5| Step: 5
Training loss: 2.942185878753662
Validation loss: 2.6090656711209204

Epoch: 5| Step: 6
Training loss: 2.92879581451416
Validation loss: 2.618644129845404

Epoch: 5| Step: 7
Training loss: 2.7887394428253174
Validation loss: 2.6110800414957027

Epoch: 5| Step: 8
Training loss: 2.541541576385498
Validation loss: 2.614376809007378

Epoch: 5| Step: 9
Training loss: 2.373852491378784
Validation loss: 2.615678310394287

Epoch: 5| Step: 10
Training loss: 3.178459405899048
Validation loss: 2.6173796602474746

Epoch: 48| Step: 0
Training loss: 2.518071174621582
Validation loss: 2.617100815619192

Epoch: 5| Step: 1
Training loss: 3.0041792392730713
Validation loss: 2.6136668266788607

Epoch: 5| Step: 2
Training loss: 2.3130030632019043
Validation loss: 2.606047720037481

Epoch: 5| Step: 3
Training loss: 2.6184628009796143
Validation loss: 2.61097316844489

Epoch: 5| Step: 4
Training loss: 2.8949503898620605
Validation loss: 2.611166695112823

Epoch: 5| Step: 5
Training loss: 2.576387882232666
Validation loss: 2.616196204257268

Epoch: 5| Step: 6
Training loss: 2.4040722846984863
Validation loss: 2.6249271362058577

Epoch: 5| Step: 7
Training loss: 3.443747043609619
Validation loss: 2.614063086048249

Epoch: 5| Step: 8
Training loss: 3.469506025314331
Validation loss: 2.6071608861287436

Epoch: 5| Step: 9
Training loss: 2.552917003631592
Validation loss: 2.605080658389676

Epoch: 5| Step: 10
Training loss: 3.1456804275512695
Validation loss: 2.6040079773113294

Epoch: 49| Step: 0
Training loss: 3.1671407222747803
Validation loss: 2.6047599418188936

Epoch: 5| Step: 1
Training loss: 3.1682534217834473
Validation loss: 2.609039386113485

Epoch: 5| Step: 2
Training loss: 3.009593963623047
Validation loss: 2.614248557757306

Epoch: 5| Step: 3
Training loss: 2.873946189880371
Validation loss: 2.610056451571885

Epoch: 5| Step: 4
Training loss: 2.386915683746338
Validation loss: 2.6060883383597098

Epoch: 5| Step: 5
Training loss: 2.4207732677459717
Validation loss: 2.605500041797597

Epoch: 5| Step: 6
Training loss: 2.4712438583374023
Validation loss: 2.602000387766028

Epoch: 5| Step: 7
Training loss: 2.8665621280670166
Validation loss: 2.6001253307506604

Epoch: 5| Step: 8
Training loss: 2.8920445442199707
Validation loss: 2.6025292668291318

Epoch: 5| Step: 9
Training loss: 3.048983573913574
Validation loss: 2.6018090555744786

Epoch: 5| Step: 10
Training loss: 2.470937728881836
Validation loss: 2.596759255214404

Epoch: 50| Step: 0
Training loss: 3.0228171348571777
Validation loss: 2.5994631910836823

Epoch: 5| Step: 1
Training loss: 3.2586846351623535
Validation loss: 2.5960975590572564

Epoch: 5| Step: 2
Training loss: 2.1159393787384033
Validation loss: 2.6016173619095997

Epoch: 5| Step: 3
Training loss: 3.1696829795837402
Validation loss: 2.600709269123693

Epoch: 5| Step: 4
Training loss: 2.117710590362549
Validation loss: 2.5919381649263444

Epoch: 5| Step: 5
Training loss: 2.4762234687805176
Validation loss: 2.5978548116581415

Epoch: 5| Step: 6
Training loss: 3.2366104125976562
Validation loss: 2.5980179053480907

Epoch: 5| Step: 7
Training loss: 2.4993557929992676
Validation loss: 2.599707249672182

Epoch: 5| Step: 8
Training loss: 2.7403371334075928
Validation loss: 2.5962013403574624

Epoch: 5| Step: 9
Training loss: 2.975525140762329
Validation loss: 2.5965616626124226

Epoch: 5| Step: 10
Training loss: 3.207005023956299
Validation loss: 2.5957439227770736

Epoch: 51| Step: 0
Training loss: 3.1435279846191406
Validation loss: 2.5943995521914576

Epoch: 5| Step: 1
Training loss: 2.4942710399627686
Validation loss: 2.5965708225004134

Epoch: 5| Step: 2
Training loss: 2.9688663482666016
Validation loss: 2.597404746599095

Epoch: 5| Step: 3
Training loss: 3.386300563812256
Validation loss: 2.6018645481396745

Epoch: 5| Step: 4
Training loss: 2.6768136024475098
Validation loss: 2.6004799771052536

Epoch: 5| Step: 5
Training loss: 2.7460060119628906
Validation loss: 2.6069641574736564

Epoch: 5| Step: 6
Training loss: 2.7914347648620605
Validation loss: 2.6084456136149745

Epoch: 5| Step: 7
Training loss: 2.5357847213745117
Validation loss: 2.612705058948968

Epoch: 5| Step: 8
Training loss: 2.062260866165161
Validation loss: 2.6145569150165846

Epoch: 5| Step: 9
Training loss: 2.708061695098877
Validation loss: 2.616074280072284

Epoch: 5| Step: 10
Training loss: 3.24597430229187
Validation loss: 2.615012388075552

Epoch: 52| Step: 0
Training loss: 2.998189926147461
Validation loss: 2.61076714915614

Epoch: 5| Step: 1
Training loss: 3.130009174346924
Validation loss: 2.6008013089497886

Epoch: 5| Step: 2
Training loss: 2.561704635620117
Validation loss: 2.604313546611417

Epoch: 5| Step: 3
Training loss: 2.5404582023620605
Validation loss: 2.601424845316077

Epoch: 5| Step: 4
Training loss: 3.534911632537842
Validation loss: 2.5979394502537225

Epoch: 5| Step: 5
Training loss: 3.310662031173706
Validation loss: 2.5999753936644523

Epoch: 5| Step: 6
Training loss: 2.2251651287078857
Validation loss: 2.6057707084122526

Epoch: 5| Step: 7
Training loss: 3.1536953449249268
Validation loss: 2.604135267196163

Epoch: 5| Step: 8
Training loss: 2.8082175254821777
Validation loss: 2.612706022877847

Epoch: 5| Step: 9
Training loss: 2.2437872886657715
Validation loss: 2.6136290232340493

Epoch: 5| Step: 10
Training loss: 2.047126054763794
Validation loss: 2.6057666681146108

Epoch: 53| Step: 0
Training loss: 3.112490177154541
Validation loss: 2.591711098147977

Epoch: 5| Step: 1
Training loss: 3.0137410163879395
Validation loss: 2.5956148947438886

Epoch: 5| Step: 2
Training loss: 2.3699593544006348
Validation loss: 2.5939628180637153

Epoch: 5| Step: 3
Training loss: 3.008944034576416
Validation loss: 2.5943289444010746

Epoch: 5| Step: 4
Training loss: 2.7236123085021973
Validation loss: 2.5959857202345327

Epoch: 5| Step: 5
Training loss: 2.9776530265808105
Validation loss: 2.591440257205758

Epoch: 5| Step: 6
Training loss: 2.8397674560546875
Validation loss: 2.590132903027278

Epoch: 5| Step: 7
Training loss: 2.625194549560547
Validation loss: 2.5964275585707797

Epoch: 5| Step: 8
Training loss: 2.5713772773742676
Validation loss: 2.59621230248482

Epoch: 5| Step: 9
Training loss: 3.0804922580718994
Validation loss: 2.589376062475225

Epoch: 5| Step: 10
Training loss: 2.1896612644195557
Validation loss: 2.5989382933544856

Epoch: 54| Step: 0
Training loss: 2.6951711177825928
Validation loss: 2.5970884651266117

Epoch: 5| Step: 1
Training loss: 2.686555862426758
Validation loss: 2.5921929087690128

Epoch: 5| Step: 2
Training loss: 3.022993803024292
Validation loss: 2.5947417033615934

Epoch: 5| Step: 3
Training loss: 2.8584580421447754
Validation loss: 2.593092185194774

Epoch: 5| Step: 4
Training loss: 2.7708826065063477
Validation loss: 2.5960675183162896

Epoch: 5| Step: 5
Training loss: 2.8146603107452393
Validation loss: 2.591593696225074

Epoch: 5| Step: 6
Training loss: 3.5619614124298096
Validation loss: 2.5931675254657702

Epoch: 5| Step: 7
Training loss: 2.684225559234619
Validation loss: 2.5880607815199

Epoch: 5| Step: 8
Training loss: 2.2792820930480957
Validation loss: 2.5864568987200336

Epoch: 5| Step: 9
Training loss: 2.0808639526367188
Validation loss: 2.5858319062058643

Epoch: 5| Step: 10
Training loss: 3.2013070583343506
Validation loss: 2.5875026743899108

Epoch: 55| Step: 0
Training loss: 2.641270875930786
Validation loss: 2.587792588818458

Epoch: 5| Step: 1
Training loss: 3.386064052581787
Validation loss: 2.5893884858777447

Epoch: 5| Step: 2
Training loss: 3.4037654399871826
Validation loss: 2.58693015959955

Epoch: 5| Step: 3
Training loss: 2.8318397998809814
Validation loss: 2.59341666775365

Epoch: 5| Step: 4
Training loss: 2.7200710773468018
Validation loss: 2.592907233904767

Epoch: 5| Step: 5
Training loss: 2.289193630218506
Validation loss: 2.5881242162437847

Epoch: 5| Step: 6
Training loss: 2.837761163711548
Validation loss: 2.590455698710616

Epoch: 5| Step: 7
Training loss: 2.1882433891296387
Validation loss: 2.589662528807117

Epoch: 5| Step: 8
Training loss: 2.974863052368164
Validation loss: 2.5845501730518956

Epoch: 5| Step: 9
Training loss: 2.0822267532348633
Validation loss: 2.586599624285134

Epoch: 5| Step: 10
Training loss: 3.2577950954437256
Validation loss: 2.58708510603956

Epoch: 56| Step: 0
Training loss: 2.7510147094726562
Validation loss: 2.58839145270727

Epoch: 5| Step: 1
Training loss: 2.385627508163452
Validation loss: 2.5983963217786563

Epoch: 5| Step: 2
Training loss: 1.8269277811050415
Validation loss: 2.599025441754249

Epoch: 5| Step: 3
Training loss: 2.636949300765991
Validation loss: 2.603537941491732

Epoch: 5| Step: 4
Training loss: 2.5682976245880127
Validation loss: 2.6012499870792514

Epoch: 5| Step: 5
Training loss: 3.626598358154297
Validation loss: 2.594315790360974

Epoch: 5| Step: 6
Training loss: 2.8877816200256348
Validation loss: 2.597433497828822

Epoch: 5| Step: 7
Training loss: 3.178439140319824
Validation loss: 2.5924769806605514

Epoch: 5| Step: 8
Training loss: 3.2974154949188232
Validation loss: 2.5922265770614787

Epoch: 5| Step: 9
Training loss: 2.234363079071045
Validation loss: 2.5873862210140435

Epoch: 5| Step: 10
Training loss: 3.204388380050659
Validation loss: 2.5839045227214856

Epoch: 57| Step: 0
Training loss: 2.6234755516052246
Validation loss: 2.583118536139047

Epoch: 5| Step: 1
Training loss: 2.967700481414795
Validation loss: 2.5861179751734578

Epoch: 5| Step: 2
Training loss: 2.1352643966674805
Validation loss: 2.5851446864425496

Epoch: 5| Step: 3
Training loss: 2.5614805221557617
Validation loss: 2.5808151716827066

Epoch: 5| Step: 4
Training loss: 3.202723741531372
Validation loss: 2.5749012372827016

Epoch: 5| Step: 5
Training loss: 3.094175338745117
Validation loss: 2.582246982923118

Epoch: 5| Step: 6
Training loss: 2.527613639831543
Validation loss: 2.5801308360151065

Epoch: 5| Step: 7
Training loss: 3.3441944122314453
Validation loss: 2.5787377024209626

Epoch: 5| Step: 8
Training loss: 2.4077606201171875
Validation loss: 2.5821954511827037

Epoch: 5| Step: 9
Training loss: 2.735546588897705
Validation loss: 2.5917423566182456

Epoch: 5| Step: 10
Training loss: 2.9375340938568115
Validation loss: 2.5866564384070774

Epoch: 58| Step: 0
Training loss: 3.485852003097534
Validation loss: 2.5900933998887257

Epoch: 5| Step: 1
Training loss: 3.1009678840637207
Validation loss: 2.581630499132218

Epoch: 5| Step: 2
Training loss: 2.9092164039611816
Validation loss: 2.5786419760796333

Epoch: 5| Step: 3
Training loss: 2.6937403678894043
Validation loss: 2.5759914100811048

Epoch: 5| Step: 4
Training loss: 2.4707159996032715
Validation loss: 2.5754657278778734

Epoch: 5| Step: 5
Training loss: 2.397453546524048
Validation loss: 2.5737381237809376

Epoch: 5| Step: 6
Training loss: 2.5976459980010986
Validation loss: 2.576166496481947

Epoch: 5| Step: 7
Training loss: 2.830641508102417
Validation loss: 2.573451162666403

Epoch: 5| Step: 8
Training loss: 2.8856735229492188
Validation loss: 2.5735625297792497

Epoch: 5| Step: 9
Training loss: 2.450279474258423
Validation loss: 2.579188592972294

Epoch: 5| Step: 10
Training loss: 2.6309452056884766
Validation loss: 2.570647883158858

Epoch: 59| Step: 0
Training loss: 2.789951801300049
Validation loss: 2.578621200335923

Epoch: 5| Step: 1
Training loss: 2.5377001762390137
Validation loss: 2.5744831485133015

Epoch: 5| Step: 2
Training loss: 3.7567317485809326
Validation loss: 2.575146316200174

Epoch: 5| Step: 3
Training loss: 2.628842353820801
Validation loss: 2.572246338731499

Epoch: 5| Step: 4
Training loss: 3.001540184020996
Validation loss: 2.571848366850166

Epoch: 5| Step: 5
Training loss: 2.3328745365142822
Validation loss: 2.571696755706623

Epoch: 5| Step: 6
Training loss: 2.543531656265259
Validation loss: 2.5695656473918627

Epoch: 5| Step: 7
Training loss: 2.429769992828369
Validation loss: 2.5721355253650295

Epoch: 5| Step: 8
Training loss: 2.7772669792175293
Validation loss: 2.575298447762766

Epoch: 5| Step: 9
Training loss: 3.018822431564331
Validation loss: 2.589645424196797

Epoch: 5| Step: 10
Training loss: 2.6088547706604004
Validation loss: 2.5774238673589562

Epoch: 60| Step: 0
Training loss: 3.12528657913208
Validation loss: 2.5720668274869203

Epoch: 5| Step: 1
Training loss: 1.89862060546875
Validation loss: 2.5746419686143116

Epoch: 5| Step: 2
Training loss: 2.9239883422851562
Validation loss: 2.578938017609299

Epoch: 5| Step: 3
Training loss: 3.148571014404297
Validation loss: 2.5773255440496627

Epoch: 5| Step: 4
Training loss: 2.8376622200012207
Validation loss: 2.578998881001626

Epoch: 5| Step: 5
Training loss: 2.908552885055542
Validation loss: 2.579690812736429

Epoch: 5| Step: 6
Training loss: 2.3222382068634033
Validation loss: 2.5753941484676894

Epoch: 5| Step: 7
Training loss: 2.566507339477539
Validation loss: 2.573700125499438

Epoch: 5| Step: 8
Training loss: 3.3433799743652344
Validation loss: 2.5729510297057447

Epoch: 5| Step: 9
Training loss: 2.8760344982147217
Validation loss: 2.5724899743192937

Epoch: 5| Step: 10
Training loss: 2.4149272441864014
Validation loss: 2.56796081091768

Epoch: 61| Step: 0
Training loss: 3.1600301265716553
Validation loss: 2.572396578327302

Epoch: 5| Step: 1
Training loss: 3.0941085815429688
Validation loss: 2.574465033828571

Epoch: 5| Step: 2
Training loss: 2.943023681640625
Validation loss: 2.5759206535995647

Epoch: 5| Step: 3
Training loss: 2.665938138961792
Validation loss: 2.574069315387357

Epoch: 5| Step: 4
Training loss: 2.9412271976470947
Validation loss: 2.5745088438833914

Epoch: 5| Step: 5
Training loss: 2.7849221229553223
Validation loss: 2.575730364809754

Epoch: 5| Step: 6
Training loss: 2.891695499420166
Validation loss: 2.5734144154415337

Epoch: 5| Step: 7
Training loss: 1.6244548559188843
Validation loss: 2.580636873040148

Epoch: 5| Step: 8
Training loss: 2.800812244415283
Validation loss: 2.5868114656017673

Epoch: 5| Step: 9
Training loss: 2.494837999343872
Validation loss: 2.5920043196729434

Epoch: 5| Step: 10
Training loss: 3.0459132194519043
Validation loss: 2.578370855700585

Epoch: 62| Step: 0
Training loss: 2.9738264083862305
Validation loss: 2.5688939837999243

Epoch: 5| Step: 1
Training loss: 2.8251495361328125
Validation loss: 2.565527746754308

Epoch: 5| Step: 2
Training loss: 2.7603583335876465
Validation loss: 2.5701312762434765

Epoch: 5| Step: 3
Training loss: 1.9510129690170288
Validation loss: 2.571415150037376

Epoch: 5| Step: 4
Training loss: 3.7512409687042236
Validation loss: 2.574807413162724

Epoch: 5| Step: 5
Training loss: 3.070333957672119
Validation loss: 2.5692724489396617

Epoch: 5| Step: 6
Training loss: 2.964928150177002
Validation loss: 2.570521298275199

Epoch: 5| Step: 7
Training loss: 2.445962429046631
Validation loss: 2.5681204565109743

Epoch: 5| Step: 8
Training loss: 2.820460796356201
Validation loss: 2.5646483513616745

Epoch: 5| Step: 9
Training loss: 2.446823835372925
Validation loss: 2.565455549506731

Epoch: 5| Step: 10
Training loss: 2.311554431915283
Validation loss: 2.566570492200954

Epoch: 63| Step: 0
Training loss: 2.8428337574005127
Validation loss: 2.5642497616429485

Epoch: 5| Step: 1
Training loss: 2.6777148246765137
Validation loss: 2.566167357147381

Epoch: 5| Step: 2
Training loss: 2.71744441986084
Validation loss: 2.566593849530784

Epoch: 5| Step: 3
Training loss: 2.441375255584717
Validation loss: 2.564262846464752

Epoch: 5| Step: 4
Training loss: 2.9981415271759033
Validation loss: 2.5643639179968063

Epoch: 5| Step: 5
Training loss: 3.4417178630828857
Validation loss: 2.5710329112186225

Epoch: 5| Step: 6
Training loss: 2.6055893898010254
Validation loss: 2.572669208690684

Epoch: 5| Step: 7
Training loss: 2.8002798557281494
Validation loss: 2.568681993792134

Epoch: 5| Step: 8
Training loss: 2.587864398956299
Validation loss: 2.575459752031552

Epoch: 5| Step: 9
Training loss: 2.5061521530151367
Validation loss: 2.5600392203177176

Epoch: 5| Step: 10
Training loss: 2.782144546508789
Validation loss: 2.561196268245738

Epoch: 64| Step: 0
Training loss: 1.9180351495742798
Validation loss: 2.564094876730314

Epoch: 5| Step: 1
Training loss: 3.2932662963867188
Validation loss: 2.5626895812249955

Epoch: 5| Step: 2
Training loss: 3.424269437789917
Validation loss: 2.563254743494013

Epoch: 5| Step: 3
Training loss: 2.9285366535186768
Validation loss: 2.5678772516148065

Epoch: 5| Step: 4
Training loss: 2.8193917274475098
Validation loss: 2.5626549336218063

Epoch: 5| Step: 5
Training loss: 2.3111672401428223
Validation loss: 2.5702636934095815

Epoch: 5| Step: 6
Training loss: 2.368650436401367
Validation loss: 2.5697370703502367

Epoch: 5| Step: 7
Training loss: 2.5368309020996094
Validation loss: 2.568944843866492

Epoch: 5| Step: 8
Training loss: 2.3225839138031006
Validation loss: 2.562995277425294

Epoch: 5| Step: 9
Training loss: 3.804914951324463
Validation loss: 2.5626532646917526

Epoch: 5| Step: 10
Training loss: 2.5416550636291504
Validation loss: 2.5589849948883057

Epoch: 65| Step: 0
Training loss: 2.4130859375
Validation loss: 2.5588597687341834

Epoch: 5| Step: 1
Training loss: 2.8698275089263916
Validation loss: 2.554599892708563

Epoch: 5| Step: 2
Training loss: 3.0221314430236816
Validation loss: 2.5569251045103996

Epoch: 5| Step: 3
Training loss: 2.454317569732666
Validation loss: 2.554749163248206

Epoch: 5| Step: 4
Training loss: 3.3056137561798096
Validation loss: 2.5570521969949045

Epoch: 5| Step: 5
Training loss: 2.7133548259735107
Validation loss: 2.5514096572834957

Epoch: 5| Step: 6
Training loss: 3.2632954120635986
Validation loss: 2.5562317038095124

Epoch: 5| Step: 7
Training loss: 3.4306693077087402
Validation loss: 2.5580642248994563

Epoch: 5| Step: 8
Training loss: 2.6772589683532715
Validation loss: 2.5594512493379655

Epoch: 5| Step: 9
Training loss: 2.2673192024230957
Validation loss: 2.5568200695899224

Epoch: 5| Step: 10
Training loss: 1.7888727188110352
Validation loss: 2.548788724407073

Epoch: 66| Step: 0
Training loss: 2.5615062713623047
Validation loss: 2.5513884764845653

Epoch: 5| Step: 1
Training loss: 3.3132216930389404
Validation loss: 2.5524855198398715

Epoch: 5| Step: 2
Training loss: 2.7035489082336426
Validation loss: 2.5549858513698784

Epoch: 5| Step: 3
Training loss: 3.287217617034912
Validation loss: 2.5505311514741633

Epoch: 5| Step: 4
Training loss: 2.7185535430908203
Validation loss: 2.5498247787516606

Epoch: 5| Step: 5
Training loss: 3.0894901752471924
Validation loss: 2.5620450024963706

Epoch: 5| Step: 6
Training loss: 2.2003448009490967
Validation loss: 2.5664399516197944

Epoch: 5| Step: 7
Training loss: 2.5871434211730957
Validation loss: 2.5684530119742117

Epoch: 5| Step: 8
Training loss: 2.444495677947998
Validation loss: 2.582793217833324

Epoch: 5| Step: 9
Training loss: 2.783113479614258
Validation loss: 2.5972355488807923

Epoch: 5| Step: 10
Training loss: 2.646728754043579
Validation loss: 2.581959924390239

Epoch: 67| Step: 0
Training loss: 3.460118055343628
Validation loss: 2.556477895347021

Epoch: 5| Step: 1
Training loss: 3.1334593296051025
Validation loss: 2.5520420061644686

Epoch: 5| Step: 2
Training loss: 2.6373019218444824
Validation loss: 2.544762349897815

Epoch: 5| Step: 3
Training loss: 3.0354878902435303
Validation loss: 2.5483584711628575

Epoch: 5| Step: 4
Training loss: 2.822443962097168
Validation loss: 2.5603389534898984

Epoch: 5| Step: 5
Training loss: 2.0815703868865967
Validation loss: 2.5627660110432613

Epoch: 5| Step: 6
Training loss: 2.308481216430664
Validation loss: 2.560319305748068

Epoch: 5| Step: 7
Training loss: 2.321254014968872
Validation loss: 2.551299895009687

Epoch: 5| Step: 8
Training loss: 2.903235673904419
Validation loss: 2.55029268674953

Epoch: 5| Step: 9
Training loss: 3.106226682662964
Validation loss: 2.5466661991611605

Epoch: 5| Step: 10
Training loss: 2.421576738357544
Validation loss: 2.5486816590832126

Epoch: 68| Step: 0
Training loss: 3.616760730743408
Validation loss: 2.5521580121850453

Epoch: 5| Step: 1
Training loss: 2.1175849437713623
Validation loss: 2.5523645800928914

Epoch: 5| Step: 2
Training loss: 2.360630989074707
Validation loss: 2.557768762752574

Epoch: 5| Step: 3
Training loss: 3.220444440841675
Validation loss: 2.5644102814376994

Epoch: 5| Step: 4
Training loss: 3.213066816329956
Validation loss: 2.556625686666017

Epoch: 5| Step: 5
Training loss: 2.6501948833465576
Validation loss: 2.555714168856221

Epoch: 5| Step: 6
Training loss: 2.919347047805786
Validation loss: 2.5591132487020185

Epoch: 5| Step: 7
Training loss: 2.6783230304718018
Validation loss: 2.5594188885022233

Epoch: 5| Step: 8
Training loss: 2.7696995735168457
Validation loss: 2.556134085501394

Epoch: 5| Step: 9
Training loss: 2.6476566791534424
Validation loss: 2.554946186721966

Epoch: 5| Step: 10
Training loss: 1.9928532838821411
Validation loss: 2.5514282129144155

Epoch: 69| Step: 0
Training loss: 2.7085306644439697
Validation loss: 2.5500411448940152

Epoch: 5| Step: 1
Training loss: 2.392786741256714
Validation loss: 2.5554112824060584

Epoch: 5| Step: 2
Training loss: 3.291877269744873
Validation loss: 2.5650940659225627

Epoch: 5| Step: 3
Training loss: 2.9319682121276855
Validation loss: 2.5671339983581216

Epoch: 5| Step: 4
Training loss: 3.0708069801330566
Validation loss: 2.5608108043670654

Epoch: 5| Step: 5
Training loss: 2.9838414192199707
Validation loss: 2.55291643193973

Epoch: 5| Step: 6
Training loss: 2.306246280670166
Validation loss: 2.5458437691452684

Epoch: 5| Step: 7
Training loss: 2.4262332916259766
Validation loss: 2.549027012240502

Epoch: 5| Step: 8
Training loss: 2.7766857147216797
Validation loss: 2.548826486833634

Epoch: 5| Step: 9
Training loss: 2.7984726428985596
Validation loss: 2.5543907278327533

Epoch: 5| Step: 10
Training loss: 2.5347907543182373
Validation loss: 2.5592732916596117

Epoch: 70| Step: 0
Training loss: 2.519242763519287
Validation loss: 2.5542684524290022

Epoch: 5| Step: 1
Training loss: 3.082883358001709
Validation loss: 2.5611960452090026

Epoch: 5| Step: 2
Training loss: 2.332355499267578
Validation loss: 2.553519287417012

Epoch: 5| Step: 3
Training loss: 2.872251033782959
Validation loss: 2.54757700427886

Epoch: 5| Step: 4
Training loss: 2.5556271076202393
Validation loss: 2.5414282737239713

Epoch: 5| Step: 5
Training loss: 2.4107441902160645
Validation loss: 2.5448810849138486

Epoch: 5| Step: 6
Training loss: 3.261798143386841
Validation loss: 2.5570888647469143

Epoch: 5| Step: 7
Training loss: 2.489900588989258
Validation loss: 2.586020226119667

Epoch: 5| Step: 8
Training loss: 3.210111141204834
Validation loss: 2.6019842009390555

Epoch: 5| Step: 9
Training loss: 2.7536959648132324
Validation loss: 2.6085732034457627

Epoch: 5| Step: 10
Training loss: 2.953640937805176
Validation loss: 2.5958071524097073

Epoch: 71| Step: 0
Training loss: 2.3772709369659424
Validation loss: 2.584011088135422

Epoch: 5| Step: 1
Training loss: 2.672041416168213
Validation loss: 2.550854577813097

Epoch: 5| Step: 2
Training loss: 3.1535701751708984
Validation loss: 2.546373357055008

Epoch: 5| Step: 3
Training loss: 2.5647010803222656
Validation loss: 2.5570837015746744

Epoch: 5| Step: 4
Training loss: 2.8849687576293945
Validation loss: 2.5921058167693434

Epoch: 5| Step: 5
Training loss: 2.743317127227783
Validation loss: 2.611447316344066

Epoch: 5| Step: 6
Training loss: 1.9618403911590576
Validation loss: 2.6043879216717136

Epoch: 5| Step: 7
Training loss: 2.999276876449585
Validation loss: 2.600535341488418

Epoch: 5| Step: 8
Training loss: 2.6810696125030518
Validation loss: 2.568760274558939

Epoch: 5| Step: 9
Training loss: 2.724574089050293
Validation loss: 2.553823668469665

Epoch: 5| Step: 10
Training loss: 3.704429864883423
Validation loss: 2.5346732113950994

Epoch: 72| Step: 0
Training loss: 2.763309955596924
Validation loss: 2.534446813726938

Epoch: 5| Step: 1
Training loss: 3.3252601623535156
Validation loss: 2.541426361248057

Epoch: 5| Step: 2
Training loss: 2.779517650604248
Validation loss: 2.5460445727071455

Epoch: 5| Step: 3
Training loss: 1.9122161865234375
Validation loss: 2.540255654242731

Epoch: 5| Step: 4
Training loss: 3.2454276084899902
Validation loss: 2.5409501765363958

Epoch: 5| Step: 5
Training loss: 2.6185173988342285
Validation loss: 2.5420268786850797

Epoch: 5| Step: 6
Training loss: 2.8623733520507812
Validation loss: 2.5409647239151822

Epoch: 5| Step: 7
Training loss: 2.476754903793335
Validation loss: 2.537933590591595

Epoch: 5| Step: 8
Training loss: 2.8574907779693604
Validation loss: 2.539534271404307

Epoch: 5| Step: 9
Training loss: 2.720140218734741
Validation loss: 2.5373232621018604

Epoch: 5| Step: 10
Training loss: 2.616724967956543
Validation loss: 2.5337414023696736

Epoch: 73| Step: 0
Training loss: 2.8004117012023926
Validation loss: 2.533381485169934

Epoch: 5| Step: 1
Training loss: 2.0122551918029785
Validation loss: 2.5412686819671304

Epoch: 5| Step: 2
Training loss: 3.338165283203125
Validation loss: 2.552361193523612

Epoch: 5| Step: 3
Training loss: 2.8731017112731934
Validation loss: 2.549948112938994

Epoch: 5| Step: 4
Training loss: 1.9711402654647827
Validation loss: 2.5597098078778995

Epoch: 5| Step: 5
Training loss: 2.6740221977233887
Validation loss: 2.550001129027336

Epoch: 5| Step: 6
Training loss: 2.9032788276672363
Validation loss: 2.5441581997820126

Epoch: 5| Step: 7
Training loss: 3.2076163291931152
Validation loss: 2.5380004221393215

Epoch: 5| Step: 8
Training loss: 2.9117538928985596
Validation loss: 2.5421772669720393

Epoch: 5| Step: 9
Training loss: 2.9937405586242676
Validation loss: 2.5309480338968258

Epoch: 5| Step: 10
Training loss: 2.392193078994751
Validation loss: 2.530233851043127

Epoch: 74| Step: 0
Training loss: 3.0003602504730225
Validation loss: 2.532884295268725

Epoch: 5| Step: 1
Training loss: 2.723332166671753
Validation loss: 2.5306882217366207

Epoch: 5| Step: 2
Training loss: 3.1115336418151855
Validation loss: 2.5296552181243896

Epoch: 5| Step: 3
Training loss: 2.1525988578796387
Validation loss: 2.532847750571466

Epoch: 5| Step: 4
Training loss: 2.7484066486358643
Validation loss: 2.53194680008837

Epoch: 5| Step: 5
Training loss: 3.121372699737549
Validation loss: 2.5307314472813762

Epoch: 5| Step: 6
Training loss: 2.634971857070923
Validation loss: 2.5288230988287155

Epoch: 5| Step: 7
Training loss: 2.522132158279419
Validation loss: 2.5344678330165085

Epoch: 5| Step: 8
Training loss: 2.7700932025909424
Validation loss: 2.528450817190191

Epoch: 5| Step: 9
Training loss: 2.4847640991210938
Validation loss: 2.529780803188201

Epoch: 5| Step: 10
Training loss: 2.8657820224761963
Validation loss: 2.5291458509301625

Epoch: 75| Step: 0
Training loss: 3.7257964611053467
Validation loss: 2.528136712248607

Epoch: 5| Step: 1
Training loss: 2.1397218704223633
Validation loss: 2.5272343133085515

Epoch: 5| Step: 2
Training loss: 3.871325969696045
Validation loss: 2.529525392798967

Epoch: 5| Step: 3
Training loss: 3.065051555633545
Validation loss: 2.5383451754047024

Epoch: 5| Step: 4
Training loss: 1.8897063732147217
Validation loss: 2.540604809279083

Epoch: 5| Step: 5
Training loss: 2.162522315979004
Validation loss: 2.549399645097794

Epoch: 5| Step: 6
Training loss: 2.619779348373413
Validation loss: 2.545687098656931

Epoch: 5| Step: 7
Training loss: 2.592580795288086
Validation loss: 2.5420478133745092

Epoch: 5| Step: 8
Training loss: 2.1482176780700684
Validation loss: 2.533013518138598

Epoch: 5| Step: 9
Training loss: 2.9567859172821045
Validation loss: 2.5306179561922626

Epoch: 5| Step: 10
Training loss: 2.961397171020508
Validation loss: 2.532675125265634

Testing loss: 2.6603591442108154
