Epoch: 1| Step: 0
Training loss: 4.976838827321492
Validation loss: 5.732566905871636

Epoch: 6| Step: 1
Training loss: 6.608630992957181
Validation loss: 5.722570287197487

Epoch: 6| Step: 2
Training loss: 5.826361422599684
Validation loss: 5.7126469826733555

Epoch: 6| Step: 3
Training loss: 5.889189122701802
Validation loss: 5.702206066817611

Epoch: 6| Step: 4
Training loss: 4.973965576592676
Validation loss: 5.691185661343549

Epoch: 6| Step: 5
Training loss: 6.449890656246745
Validation loss: 5.679153959192528

Epoch: 6| Step: 6
Training loss: 5.702915637210208
Validation loss: 5.666654012522361

Epoch: 6| Step: 7
Training loss: 4.869923809794975
Validation loss: 5.652633652187568

Epoch: 6| Step: 8
Training loss: 6.671914165301469
Validation loss: 5.6379010395209725

Epoch: 6| Step: 9
Training loss: 4.903610588618306
Validation loss: 5.621818937353291

Epoch: 6| Step: 10
Training loss: 6.211363119261054
Validation loss: 5.6040011200533035

Epoch: 6| Step: 11
Training loss: 5.314015250933911
Validation loss: 5.58540912782237

Epoch: 6| Step: 12
Training loss: 5.683599790589573
Validation loss: 5.565228626124155

Epoch: 6| Step: 13
Training loss: 4.701573518364249
Validation loss: 5.543244920414901

Epoch: 2| Step: 0
Training loss: 6.222122581380457
Validation loss: 5.5195201547989265

Epoch: 6| Step: 1
Training loss: 4.809369542922505
Validation loss: 5.493876657222067

Epoch: 6| Step: 2
Training loss: 5.596654042238618
Validation loss: 5.466063819667901

Epoch: 6| Step: 3
Training loss: 6.372010670817624
Validation loss: 5.436813069706786

Epoch: 6| Step: 4
Training loss: 4.021907182044539
Validation loss: 5.4047504132765205

Epoch: 6| Step: 5
Training loss: 5.458616797776768
Validation loss: 5.372438906657793

Epoch: 6| Step: 6
Training loss: 4.388865270966884
Validation loss: 5.337625704105905

Epoch: 6| Step: 7
Training loss: 4.436452822634423
Validation loss: 5.301377444940202

Epoch: 6| Step: 8
Training loss: 6.137638987037693
Validation loss: 5.265131406330445

Epoch: 6| Step: 9
Training loss: 4.207045077812118
Validation loss: 5.225106890817994

Epoch: 6| Step: 10
Training loss: 5.914819061788061
Validation loss: 5.187848325169844

Epoch: 6| Step: 11
Training loss: 5.993207901832694
Validation loss: 5.14723826604268

Epoch: 6| Step: 12
Training loss: 4.940275932976347
Validation loss: 5.105139153233071

Epoch: 6| Step: 13
Training loss: 6.131084300688455
Validation loss: 5.065429641950526

Epoch: 3| Step: 0
Training loss: 4.118382550116194
Validation loss: 5.024888746988806

Epoch: 6| Step: 1
Training loss: 4.923734767683978
Validation loss: 4.986653020344474

Epoch: 6| Step: 2
Training loss: 5.284961908324082
Validation loss: 4.949298018250571

Epoch: 6| Step: 3
Training loss: 5.406562928420848
Validation loss: 4.913748709366797

Epoch: 6| Step: 4
Training loss: 4.445320652315679
Validation loss: 4.879544662122886

Epoch: 6| Step: 5
Training loss: 4.257553568674941
Validation loss: 4.847751603371967

Epoch: 6| Step: 6
Training loss: 5.4625952391538375
Validation loss: 4.819977328424548

Epoch: 6| Step: 7
Training loss: 5.190562619564202
Validation loss: 4.792906167040904

Epoch: 6| Step: 8
Training loss: 5.3047412538122405
Validation loss: 4.767468507650245

Epoch: 6| Step: 9
Training loss: 5.219605701214169
Validation loss: 4.741610909719565

Epoch: 6| Step: 10
Training loss: 4.3757249503999605
Validation loss: 4.7186029643959175

Epoch: 6| Step: 11
Training loss: 5.007664337584931
Validation loss: 4.693853715187383

Epoch: 6| Step: 12
Training loss: 5.380387910379893
Validation loss: 4.666962580520663

Epoch: 6| Step: 13
Training loss: 2.675354593607749
Validation loss: 4.640065107161075

Epoch: 4| Step: 0
Training loss: 4.410044666159236
Validation loss: 4.610872346178912

Epoch: 6| Step: 1
Training loss: 5.9913140049457745
Validation loss: 4.581505474549831

Epoch: 6| Step: 2
Training loss: 4.805116215629246
Validation loss: 4.554739703620787

Epoch: 6| Step: 3
Training loss: 5.216811682459798
Validation loss: 4.531338517085049

Epoch: 6| Step: 4
Training loss: 3.9062512207029343
Validation loss: 4.511917117425878

Epoch: 6| Step: 5
Training loss: 4.0243850332989055
Validation loss: 4.495837153601983

Epoch: 6| Step: 6
Training loss: 4.633158318669822
Validation loss: 4.481885116681755

Epoch: 6| Step: 7
Training loss: 3.6687021385593197
Validation loss: 4.466036195634145

Epoch: 6| Step: 8
Training loss: 4.5138269560388
Validation loss: 4.451100862429364

Epoch: 6| Step: 9
Training loss: 4.739367380217834
Validation loss: 4.432168140147866

Epoch: 6| Step: 10
Training loss: 3.724553300328417
Validation loss: 4.412457791577145

Epoch: 6| Step: 11
Training loss: 4.405608001905648
Validation loss: 4.390934574402386

Epoch: 6| Step: 12
Training loss: 4.105521944900974
Validation loss: 4.37522789146256

Epoch: 6| Step: 13
Training loss: 6.002313167996086
Validation loss: 4.36405739638091

Epoch: 5| Step: 0
Training loss: 4.3977874221254805
Validation loss: 4.351422777077733

Epoch: 6| Step: 1
Training loss: 3.1311904627456406
Validation loss: 4.33850117412779

Epoch: 6| Step: 2
Training loss: 3.830328357853866
Validation loss: 4.326170852191756

Epoch: 6| Step: 3
Training loss: 4.868076592274607
Validation loss: 4.310874757552212

Epoch: 6| Step: 4
Training loss: 5.077953723073092
Validation loss: 4.2978425781051115

Epoch: 6| Step: 5
Training loss: 4.347069658737932
Validation loss: 4.283976820101145

Epoch: 6| Step: 6
Training loss: 4.172876130756426
Validation loss: 4.2722007685282755

Epoch: 6| Step: 7
Training loss: 4.593369033482809
Validation loss: 4.256595794400975

Epoch: 6| Step: 8
Training loss: 5.080470649663742
Validation loss: 4.239849448163507

Epoch: 6| Step: 9
Training loss: 4.911210777648444
Validation loss: 4.225490900131697

Epoch: 6| Step: 10
Training loss: 4.6026081652262585
Validation loss: 4.208137696912193

Epoch: 6| Step: 11
Training loss: 4.496263011990963
Validation loss: 4.191145679907642

Epoch: 6| Step: 12
Training loss: 3.565273610619401
Validation loss: 4.175128035497621

Epoch: 6| Step: 13
Training loss: 3.3046903858217305
Validation loss: 4.160302081073129

Epoch: 6| Step: 0
Training loss: 4.008015945357167
Validation loss: 4.147085478829341

Epoch: 6| Step: 1
Training loss: 4.698174288411096
Validation loss: 4.1321745150802744

Epoch: 6| Step: 2
Training loss: 4.324057971477515
Validation loss: 4.1173029435071955

Epoch: 6| Step: 3
Training loss: 4.048084210933438
Validation loss: 4.102918835058336

Epoch: 6| Step: 4
Training loss: 5.839307432521763
Validation loss: 4.085494519040609

Epoch: 6| Step: 5
Training loss: 3.37093716254409
Validation loss: 4.0696000925211155

Epoch: 6| Step: 6
Training loss: 3.6183945555378423
Validation loss: 4.053103215196229

Epoch: 6| Step: 7
Training loss: 3.7328513640420073
Validation loss: 4.038953854919748

Epoch: 6| Step: 8
Training loss: 3.6753310800489296
Validation loss: 4.021168907699654

Epoch: 6| Step: 9
Training loss: 3.7513303304357075
Validation loss: 4.007023210037428

Epoch: 6| Step: 10
Training loss: 3.665355332285543
Validation loss: 3.9917840591039218

Epoch: 6| Step: 11
Training loss: 4.179757319072232
Validation loss: 3.979024604400836

Epoch: 6| Step: 12
Training loss: 4.349573197747508
Validation loss: 3.96235450070422

Epoch: 6| Step: 13
Training loss: 5.263336499345893
Validation loss: 3.945989194685234

Epoch: 7| Step: 0
Training loss: 3.6497362590243436
Validation loss: 3.9299661858870008

Epoch: 6| Step: 1
Training loss: 4.213455155297505
Validation loss: 3.915152260675025

Epoch: 6| Step: 2
Training loss: 3.751460490335314
Validation loss: 3.898572950266275

Epoch: 6| Step: 3
Training loss: 3.882987250649749
Validation loss: 3.8849504408786895

Epoch: 6| Step: 4
Training loss: 3.200744637635368
Validation loss: 3.876107338504875

Epoch: 6| Step: 5
Training loss: 4.366688489980739
Validation loss: 3.861403246300141

Epoch: 6| Step: 6
Training loss: 3.6608594220994095
Validation loss: 3.8476119790185823

Epoch: 6| Step: 7
Training loss: 5.093735022025525
Validation loss: 3.837190277159081

Epoch: 6| Step: 8
Training loss: 4.316881911362124
Validation loss: 3.8263985587120213

Epoch: 6| Step: 9
Training loss: 3.859623827615619
Validation loss: 3.8132808053187794

Epoch: 6| Step: 10
Training loss: 3.628945932489573
Validation loss: 3.803866251265534

Epoch: 6| Step: 11
Training loss: 3.8332853452470688
Validation loss: 3.7943581732173337

Epoch: 6| Step: 12
Training loss: 4.723510765847594
Validation loss: 3.781747347135684

Epoch: 6| Step: 13
Training loss: 3.175663982257954
Validation loss: 3.7669458814131183

Epoch: 8| Step: 0
Training loss: 3.250020247176264
Validation loss: 3.756863937368056

Epoch: 6| Step: 1
Training loss: 3.9552435343497656
Validation loss: 3.744065005155736

Epoch: 6| Step: 2
Training loss: 4.35667417806276
Validation loss: 3.7299156781885214

Epoch: 6| Step: 3
Training loss: 3.2441053486191618
Validation loss: 3.721099293437991

Epoch: 6| Step: 4
Training loss: 3.942935038423043
Validation loss: 3.7112540914290766

Epoch: 6| Step: 5
Training loss: 2.769997798216458
Validation loss: 3.698984105346272

Epoch: 6| Step: 6
Training loss: 4.188710052108497
Validation loss: 3.695020198459039

Epoch: 6| Step: 7
Training loss: 4.372840784488872
Validation loss: 3.680027343239126

Epoch: 6| Step: 8
Training loss: 4.1967752701874605
Validation loss: 3.6705937768684858

Epoch: 6| Step: 9
Training loss: 3.892311557919794
Validation loss: 3.664833914532669

Epoch: 6| Step: 10
Training loss: 4.211174160282087
Validation loss: 3.658771389792077

Epoch: 6| Step: 11
Training loss: 3.5233217884356978
Validation loss: 3.6468741009304595

Epoch: 6| Step: 12
Training loss: 3.190866823961294
Validation loss: 3.640186353630511

Epoch: 6| Step: 13
Training loss: 5.171327129745024
Validation loss: 3.636551846390732

Epoch: 9| Step: 0
Training loss: 3.951581088045385
Validation loss: 3.6319783615425236

Epoch: 6| Step: 1
Training loss: 3.1742388556348544
Validation loss: 3.6256135429110525

Epoch: 6| Step: 2
Training loss: 3.971459972869055
Validation loss: 3.618177580141499

Epoch: 6| Step: 3
Training loss: 3.6751425631112453
Validation loss: 3.613163078612881

Epoch: 6| Step: 4
Training loss: 4.84170745114577
Validation loss: 3.609427608097187

Epoch: 6| Step: 5
Training loss: 3.409721355520131
Validation loss: 3.5985874541551905

Epoch: 6| Step: 6
Training loss: 3.762331460111811
Validation loss: 3.5904440920077483

Epoch: 6| Step: 7
Training loss: 4.234111482085067
Validation loss: 3.582722309632173

Epoch: 6| Step: 8
Training loss: 4.066367084120343
Validation loss: 3.5794129547639

Epoch: 6| Step: 9
Training loss: 3.8926325142023104
Validation loss: 3.5685360514740045

Epoch: 6| Step: 10
Training loss: 2.4310630510722206
Validation loss: 3.567322471212998

Epoch: 6| Step: 11
Training loss: 3.6682562994649723
Validation loss: 3.5621429621376377

Epoch: 6| Step: 12
Training loss: 3.8661511198091016
Validation loss: 3.5567921808941207

Epoch: 6| Step: 13
Training loss: 3.4861507253097415
Validation loss: 3.5514130131119557

Epoch: 10| Step: 0
Training loss: 4.0088422318718235
Validation loss: 3.548176460036507

Epoch: 6| Step: 1
Training loss: 3.7543350594054936
Validation loss: 3.5462406153635704

Epoch: 6| Step: 2
Training loss: 4.571814656983865
Validation loss: 3.543130791808657

Epoch: 6| Step: 3
Training loss: 2.9430938378168987
Validation loss: 3.5350821353637834

Epoch: 6| Step: 4
Training loss: 3.3311630495328868
Validation loss: 3.5310875843219045

Epoch: 6| Step: 5
Training loss: 3.5803769949922217
Validation loss: 3.5262019325366936

Epoch: 6| Step: 6
Training loss: 4.547582197741438
Validation loss: 3.5223201552304366

Epoch: 6| Step: 7
Training loss: 3.5396860007128566
Validation loss: 3.5140600048638806

Epoch: 6| Step: 8
Training loss: 4.147550728771077
Validation loss: 3.507696530262949

Epoch: 6| Step: 9
Training loss: 3.8984874041770796
Validation loss: 3.5014215474293997

Epoch: 6| Step: 10
Training loss: 3.6173174775007277
Validation loss: 3.499296170324212

Epoch: 6| Step: 11
Training loss: 3.672395190463102
Validation loss: 3.4938566785776666

Epoch: 6| Step: 12
Training loss: 3.132903823092259
Validation loss: 3.4889237073224204

Epoch: 6| Step: 13
Training loss: 2.429542757978937
Validation loss: 3.494566982620643

Epoch: 11| Step: 0
Training loss: 4.228170543800349
Validation loss: 3.4989244944492466

Epoch: 6| Step: 1
Training loss: 2.9683731643029168
Validation loss: 3.476705040751237

Epoch: 6| Step: 2
Training loss: 4.148352900502726
Validation loss: 3.4821783884122746

Epoch: 6| Step: 3
Training loss: 4.73298851333214
Validation loss: 3.4741880653281636

Epoch: 6| Step: 4
Training loss: 2.4428983721524395
Validation loss: 3.469709599720796

Epoch: 6| Step: 5
Training loss: 3.6995232042909145
Validation loss: 3.4700210549892923

Epoch: 6| Step: 6
Training loss: 4.278247086403988
Validation loss: 3.4667157408299047

Epoch: 6| Step: 7
Training loss: 3.0664267764042283
Validation loss: 3.463515038873295

Epoch: 6| Step: 8
Training loss: 4.006657067624324
Validation loss: 3.4667888589847506

Epoch: 6| Step: 9
Training loss: 2.988695143415989
Validation loss: 3.462613977801423

Epoch: 6| Step: 10
Training loss: 3.159017426039695
Validation loss: 3.4599707253691423

Epoch: 6| Step: 11
Training loss: 3.116015680090024
Validation loss: 3.452039790223129

Epoch: 6| Step: 12
Training loss: 4.4841238343615855
Validation loss: 3.444087075681928

Epoch: 6| Step: 13
Training loss: 3.2127576435245455
Validation loss: 3.4382201334458693

Epoch: 12| Step: 0
Training loss: 2.7985066177974205
Validation loss: 3.434832949136872

Epoch: 6| Step: 1
Training loss: 4.016329336181225
Validation loss: 3.433581181126514

Epoch: 6| Step: 2
Training loss: 2.8387373457256624
Validation loss: 3.4246754252910008

Epoch: 6| Step: 3
Training loss: 4.086689458620654
Validation loss: 3.4223749905504883

Epoch: 6| Step: 4
Training loss: 3.628221330177082
Validation loss: 3.41847515239815

Epoch: 6| Step: 5
Training loss: 2.893001424969066
Validation loss: 3.416475763897804

Epoch: 6| Step: 6
Training loss: 3.491523013805382
Validation loss: 3.4141839554126654

Epoch: 6| Step: 7
Training loss: 4.529645964743599
Validation loss: 3.415070905181594

Epoch: 6| Step: 8
Training loss: 3.9102292963878207
Validation loss: 3.4052157533297063

Epoch: 6| Step: 9
Training loss: 4.098172194415824
Validation loss: 3.404728903852332

Epoch: 6| Step: 10
Training loss: 3.9116905471946164
Validation loss: 3.402532190251962

Epoch: 6| Step: 11
Training loss: 3.7857651668532704
Validation loss: 3.3976017700533063

Epoch: 6| Step: 12
Training loss: 3.5726660519149926
Validation loss: 3.394798807212808

Epoch: 6| Step: 13
Training loss: 2.0378758276939055
Validation loss: 3.393385114785024

Epoch: 13| Step: 0
Training loss: 4.482048467902588
Validation loss: 3.3902643801231944

Epoch: 6| Step: 1
Training loss: 3.23938396531369
Validation loss: 3.3872941730674615

Epoch: 6| Step: 2
Training loss: 2.6695310785228217
Validation loss: 3.3841933748289486

Epoch: 6| Step: 3
Training loss: 3.5906470129601558
Validation loss: 3.3817851970108794

Epoch: 6| Step: 4
Training loss: 4.488518372489499
Validation loss: 3.3785818592609638

Epoch: 6| Step: 5
Training loss: 3.1513236095724184
Validation loss: 3.374620661653814

Epoch: 6| Step: 6
Training loss: 3.578653488110279
Validation loss: 3.372672248649278

Epoch: 6| Step: 7
Training loss: 2.852831247338941
Validation loss: 3.370313587856304

Epoch: 6| Step: 8
Training loss: 2.647063852754191
Validation loss: 3.3610606614487266

Epoch: 6| Step: 9
Training loss: 4.049237007513586
Validation loss: 3.358665329917484

Epoch: 6| Step: 10
Training loss: 3.4615056452051483
Validation loss: 3.356712803177186

Epoch: 6| Step: 11
Training loss: 3.406714731413605
Validation loss: 3.3533982762549215

Epoch: 6| Step: 12
Training loss: 4.232049169532396
Validation loss: 3.3531328905105626

Epoch: 6| Step: 13
Training loss: 4.096585987642685
Validation loss: 3.3488020844753144

Epoch: 14| Step: 0
Training loss: 3.8231285653215403
Validation loss: 3.344027218210818

Epoch: 6| Step: 1
Training loss: 2.8644592443234616
Validation loss: 3.3403099687908746

Epoch: 6| Step: 2
Training loss: 3.592986979545106
Validation loss: 3.337489386426398

Epoch: 6| Step: 3
Training loss: 3.4258110366970436
Validation loss: 3.333028872234268

Epoch: 6| Step: 4
Training loss: 2.539467365557672
Validation loss: 3.3306926301414346

Epoch: 6| Step: 5
Training loss: 4.144585554250739
Validation loss: 3.32907529531487

Epoch: 6| Step: 6
Training loss: 3.703473682324991
Validation loss: 3.3256754792690786

Epoch: 6| Step: 7
Training loss: 3.7437928007860273
Validation loss: 3.3230400920181182

Epoch: 6| Step: 8
Training loss: 3.5922686633630665
Validation loss: 3.319417593972356

Epoch: 6| Step: 9
Training loss: 3.308633815338141
Validation loss: 3.317966236278598

Epoch: 6| Step: 10
Training loss: 3.324893008927203
Validation loss: 3.3145969693288384

Epoch: 6| Step: 11
Training loss: 3.431317126897745
Validation loss: 3.3154096170825826

Epoch: 6| Step: 12
Training loss: 4.4460607344803
Validation loss: 3.3117309717787515

Epoch: 6| Step: 13
Training loss: 3.5226729212620453
Validation loss: 3.3096869998969045

Epoch: 15| Step: 0
Training loss: 3.1427010274483327
Validation loss: 3.3074709142755148

Epoch: 6| Step: 1
Training loss: 3.7328855984006624
Validation loss: 3.30183642529107

Epoch: 6| Step: 2
Training loss: 3.7802203329145856
Validation loss: 3.301558778235218

Epoch: 6| Step: 3
Training loss: 3.3373727324148135
Validation loss: 3.299542329634948

Epoch: 6| Step: 4
Training loss: 2.6078286528729913
Validation loss: 3.2973737403101677

Epoch: 6| Step: 5
Training loss: 3.4789571337316425
Validation loss: 3.2987171417851617

Epoch: 6| Step: 6
Training loss: 4.14561397924271
Validation loss: 3.296528416059824

Epoch: 6| Step: 7
Training loss: 3.740412727266911
Validation loss: 3.293932059772217

Epoch: 6| Step: 8
Training loss: 2.9807183197444465
Validation loss: 3.295068331844638

Epoch: 6| Step: 9
Training loss: 4.252772380665691
Validation loss: 3.2929315349969315

Epoch: 6| Step: 10
Training loss: 3.181652464824118
Validation loss: 3.288521889205078

Epoch: 6| Step: 11
Training loss: 4.225667072431435
Validation loss: 3.2828162576990754

Epoch: 6| Step: 12
Training loss: 3.078967758450966
Validation loss: 3.2812438808526694

Epoch: 6| Step: 13
Training loss: 3.2545767616482695
Validation loss: 3.2822258126750734

Epoch: 16| Step: 0
Training loss: 3.9539762643382415
Validation loss: 3.281307664121347

Epoch: 6| Step: 1
Training loss: 3.4994524118670856
Validation loss: 3.2796458208468966

Epoch: 6| Step: 2
Training loss: 3.57254753022446
Validation loss: 3.2754118336903058

Epoch: 6| Step: 3
Training loss: 3.36732160473779
Validation loss: 3.2728253666743585

Epoch: 6| Step: 4
Training loss: 3.8528541735832604
Validation loss: 3.2719784632684887

Epoch: 6| Step: 5
Training loss: 3.264618933085342
Validation loss: 3.269055167622233

Epoch: 6| Step: 6
Training loss: 3.2853980593415457
Validation loss: 3.267022594265083

Epoch: 6| Step: 7
Training loss: 3.774423411210932
Validation loss: 3.267048126028949

Epoch: 6| Step: 8
Training loss: 2.777841944483212
Validation loss: 3.2669664443987187

Epoch: 6| Step: 9
Training loss: 3.195606022343277
Validation loss: 3.263171292008034

Epoch: 6| Step: 10
Training loss: 4.041635781920629
Validation loss: 3.262144829381537

Epoch: 6| Step: 11
Training loss: 3.815941679838761
Validation loss: 3.261083465068324

Epoch: 6| Step: 12
Training loss: 2.8459940010913667
Validation loss: 3.260855430202633

Epoch: 6| Step: 13
Training loss: 3.872523470093916
Validation loss: 3.2637001437424358

Epoch: 17| Step: 0
Training loss: 4.30783027255073
Validation loss: 3.2553068050462084

Epoch: 6| Step: 1
Training loss: 2.22101252001755
Validation loss: 3.25381072305137

Epoch: 6| Step: 2
Training loss: 2.8574280494315554
Validation loss: 3.2550652380552836

Epoch: 6| Step: 3
Training loss: 3.37161494852912
Validation loss: 3.258124105760793

Epoch: 6| Step: 4
Training loss: 2.8995436539538564
Validation loss: 3.2515320838613793

Epoch: 6| Step: 5
Training loss: 3.459905397301546
Validation loss: 3.2490433167547423

Epoch: 6| Step: 6
Training loss: 2.887665424314805
Validation loss: 3.245742473404482

Epoch: 6| Step: 7
Training loss: 3.6132557801044887
Validation loss: 3.2468322069527944

Epoch: 6| Step: 8
Training loss: 3.323762425302247
Validation loss: 3.2429164256347134

Epoch: 6| Step: 9
Training loss: 4.096909097606723
Validation loss: 3.2457214365457294

Epoch: 6| Step: 10
Training loss: 3.902166811241404
Validation loss: 3.243266579184342

Epoch: 6| Step: 11
Training loss: 4.209299310288323
Validation loss: 3.242327981399338

Epoch: 6| Step: 12
Training loss: 3.8194961143620705
Validation loss: 3.240338862597549

Epoch: 6| Step: 13
Training loss: 3.2061049579138343
Validation loss: 3.238185626289198

Epoch: 18| Step: 0
Training loss: 3.850345442496075
Validation loss: 3.238090159680731

Epoch: 6| Step: 1
Training loss: 2.6370620617064096
Validation loss: 3.23584944083029

Epoch: 6| Step: 2
Training loss: 3.2606711161392083
Validation loss: 3.2343535642273724

Epoch: 6| Step: 3
Training loss: 2.5974115471561863
Validation loss: 3.2326975304735783

Epoch: 6| Step: 4
Training loss: 3.9308252829902663
Validation loss: 3.233083689828636

Epoch: 6| Step: 5
Training loss: 3.2001543365453426
Validation loss: 3.2308023941641735

Epoch: 6| Step: 6
Training loss: 3.968880238235841
Validation loss: 3.2309168766813197

Epoch: 6| Step: 7
Training loss: 2.818767938324209
Validation loss: 3.2270062897277243

Epoch: 6| Step: 8
Training loss: 3.412361052761964
Validation loss: 3.2278921310659765

Epoch: 6| Step: 9
Training loss: 3.8744134766707603
Validation loss: 3.224934842837108

Epoch: 6| Step: 10
Training loss: 3.279867116981069
Validation loss: 3.224449208742814

Epoch: 6| Step: 11
Training loss: 3.3056197779068404
Validation loss: 3.223030020429174

Epoch: 6| Step: 12
Training loss: 4.944817637291031
Validation loss: 3.2223373781357

Epoch: 6| Step: 13
Training loss: 2.3963717532878857
Validation loss: 3.2211105781552876

Epoch: 19| Step: 0
Training loss: 3.1922231350112686
Validation loss: 3.217841146204496

Epoch: 6| Step: 1
Training loss: 3.2987705946174986
Validation loss: 3.2176975935503904

Epoch: 6| Step: 2
Training loss: 3.612912116913249
Validation loss: 3.2154998458685284

Epoch: 6| Step: 3
Training loss: 3.4031322804943214
Validation loss: 3.215036615914567

Epoch: 6| Step: 4
Training loss: 2.9947919143455515
Validation loss: 3.212898728699907

Epoch: 6| Step: 5
Training loss: 3.028826659236487
Validation loss: 3.2118584537926176

Epoch: 6| Step: 6
Training loss: 4.110439612274135
Validation loss: 3.2107250108483343

Epoch: 6| Step: 7
Training loss: 3.5526214967551133
Validation loss: 3.2070053531406066

Epoch: 6| Step: 8
Training loss: 3.743818528912586
Validation loss: 3.2121987517085886

Epoch: 6| Step: 9
Training loss: 3.383925045743472
Validation loss: 3.2103290948034924

Epoch: 6| Step: 10
Training loss: 3.3557353330148283
Validation loss: 3.20945559401043

Epoch: 6| Step: 11
Training loss: 3.459223682433303
Validation loss: 3.2136404067811672

Epoch: 6| Step: 12
Training loss: 4.174508510144581
Validation loss: 3.216345677870287

Epoch: 6| Step: 13
Training loss: 2.579264903213411
Validation loss: 3.2108857259679846

Epoch: 20| Step: 0
Training loss: 3.9140659111449705
Validation loss: 3.202659906516142

Epoch: 6| Step: 1
Training loss: 2.487188892941661
Validation loss: 3.2028337003527896

Epoch: 6| Step: 2
Training loss: 3.7339679065177163
Validation loss: 3.207139201422833

Epoch: 6| Step: 3
Training loss: 3.2909750553879236
Validation loss: 3.2087766460656475

Epoch: 6| Step: 4
Training loss: 3.741089725547187
Validation loss: 3.207673873748294

Epoch: 6| Step: 5
Training loss: 4.078544741255255
Validation loss: 3.2021020279720904

Epoch: 6| Step: 6
Training loss: 3.3920999298670584
Validation loss: 3.2014578677926293

Epoch: 6| Step: 7
Training loss: 3.7278751004952646
Validation loss: 3.1992998214691153

Epoch: 6| Step: 8
Training loss: 2.8169342688873544
Validation loss: 3.1999156545987786

Epoch: 6| Step: 9
Training loss: 3.0456318201982495
Validation loss: 3.200666100992276

Epoch: 6| Step: 10
Training loss: 3.53646681292514
Validation loss: 3.2045947808860347

Epoch: 6| Step: 11
Training loss: 2.2139403100173185
Validation loss: 3.202400062656978

Epoch: 6| Step: 12
Training loss: 3.686393830503162
Validation loss: 3.2008823806772386

Epoch: 6| Step: 13
Training loss: 4.6509887874569
Validation loss: 3.1969931844574586

Epoch: 21| Step: 0
Training loss: 3.213761250532971
Validation loss: 3.1931784307705713

Epoch: 6| Step: 1
Training loss: 3.35624456707108
Validation loss: 3.1891301824412803

Epoch: 6| Step: 2
Training loss: 3.190029860688605
Validation loss: 3.1898881819611065

Epoch: 6| Step: 3
Training loss: 4.060942131060388
Validation loss: 3.191242935950923

Epoch: 6| Step: 4
Training loss: 3.9487832090521615
Validation loss: 3.189218836627585

Epoch: 6| Step: 5
Training loss: 3.4143943363475215
Validation loss: 3.1953452903624977

Epoch: 6| Step: 6
Training loss: 3.7850736091339754
Validation loss: 3.1853561124445786

Epoch: 6| Step: 7
Training loss: 3.965974573189489
Validation loss: 3.1846595725965683

Epoch: 6| Step: 8
Training loss: 3.655189034182822
Validation loss: 3.18504924205314

Epoch: 6| Step: 9
Training loss: 2.8898113033373796
Validation loss: 3.1818733974972133

Epoch: 6| Step: 10
Training loss: 3.29223349475279
Validation loss: 3.179541006445358

Epoch: 6| Step: 11
Training loss: 2.729416018056167
Validation loss: 3.1797803808931886

Epoch: 6| Step: 12
Training loss: 2.8170084104564754
Validation loss: 3.179782791525898

Epoch: 6| Step: 13
Training loss: 3.7396288827373
Validation loss: 3.1980181834875943

Epoch: 22| Step: 0
Training loss: 4.392837781342871
Validation loss: 3.1872240253086788

Epoch: 6| Step: 1
Training loss: 3.2257274073483884
Validation loss: 3.187209352339427

Epoch: 6| Step: 2
Training loss: 2.502364375719905
Validation loss: 3.215865860795549

Epoch: 6| Step: 3
Training loss: 3.743288774052473
Validation loss: 3.278185591771219

Epoch: 6| Step: 4
Training loss: 3.3514077033017036
Validation loss: 3.2209182478664866

Epoch: 6| Step: 5
Training loss: 3.0760952991460964
Validation loss: 3.194925253020374

Epoch: 6| Step: 6
Training loss: 3.7608115428313287
Validation loss: 3.181864070681283

Epoch: 6| Step: 7
Training loss: 3.1718380178917025
Validation loss: 3.183456524840067

Epoch: 6| Step: 8
Training loss: 3.4956359904577026
Validation loss: 3.193174694308373

Epoch: 6| Step: 9
Training loss: 3.6896991960687937
Validation loss: 3.200234160264672

Epoch: 6| Step: 10
Training loss: 3.460730828514642
Validation loss: 3.2054622115782854

Epoch: 6| Step: 11
Training loss: 3.064183920516992
Validation loss: 3.211124681478475

Epoch: 6| Step: 12
Training loss: 3.729304234757258
Validation loss: 3.209686812571913

Epoch: 6| Step: 13
Training loss: 3.4850051378516
Validation loss: 3.206083640181738

Epoch: 23| Step: 0
Training loss: 2.5453082923549957
Validation loss: 3.198301987867426

Epoch: 6| Step: 1
Training loss: 3.5916913314173065
Validation loss: 3.1898530594635592

Epoch: 6| Step: 2
Training loss: 4.191688378785302
Validation loss: 3.1754795173247694

Epoch: 6| Step: 3
Training loss: 3.0655874143079305
Validation loss: 3.16527256667148

Epoch: 6| Step: 4
Training loss: 3.4890945016270596
Validation loss: 3.16420217692133

Epoch: 6| Step: 5
Training loss: 3.7717652969399085
Validation loss: 3.1665331294773513

Epoch: 6| Step: 6
Training loss: 3.2044110949428863
Validation loss: 3.1658684599404867

Epoch: 6| Step: 7
Training loss: 3.085120293298317
Validation loss: 3.162649217663685

Epoch: 6| Step: 8
Training loss: 3.654246767761759
Validation loss: 3.160402537299897

Epoch: 6| Step: 9
Training loss: 3.1739899297697503
Validation loss: 3.157799128501121

Epoch: 6| Step: 10
Training loss: 3.451117436876113
Validation loss: 3.1545512865958987

Epoch: 6| Step: 11
Training loss: 3.9949869690874724
Validation loss: 3.1520624508594444

Epoch: 6| Step: 12
Training loss: 3.1359538550679797
Validation loss: 3.149997188165142

Epoch: 6| Step: 13
Training loss: 3.3693813602852374
Validation loss: 3.150250836991512

Epoch: 24| Step: 0
Training loss: 3.184602205595817
Validation loss: 3.1472998133837837

Epoch: 6| Step: 1
Training loss: 4.4961130521278765
Validation loss: 3.146458423045837

Epoch: 6| Step: 2
Training loss: 3.286663711990153
Validation loss: 3.143180596333299

Epoch: 6| Step: 3
Training loss: 2.7991663747705746
Validation loss: 3.1491028723269108

Epoch: 6| Step: 4
Training loss: 2.8522667420188723
Validation loss: 3.146000435073274

Epoch: 6| Step: 5
Training loss: 3.210687409474398
Validation loss: 3.1440685227548246

Epoch: 6| Step: 6
Training loss: 3.4625236372708947
Validation loss: 3.144895814156938

Epoch: 6| Step: 7
Training loss: 4.03727662026581
Validation loss: 3.1389898979111406

Epoch: 6| Step: 8
Training loss: 3.6709048024269775
Validation loss: 3.1382444131609524

Epoch: 6| Step: 9
Training loss: 3.13128335596162
Validation loss: 3.1360661938339223

Epoch: 6| Step: 10
Training loss: 2.7680174398809974
Validation loss: 3.1359915824418887

Epoch: 6| Step: 11
Training loss: 3.672723550348258
Validation loss: 3.1350598639015868

Epoch: 6| Step: 12
Training loss: 3.7218417610586765
Validation loss: 3.135114171505989

Epoch: 6| Step: 13
Training loss: 2.6166563491455896
Validation loss: 3.1363567289016165

Epoch: 25| Step: 0
Training loss: 2.5667932413110597
Validation loss: 3.1338431540740563

Epoch: 6| Step: 1
Training loss: 3.120514358768639
Validation loss: 3.129118504512773

Epoch: 6| Step: 2
Training loss: 3.258236937466922
Validation loss: 3.129796928602091

Epoch: 6| Step: 3
Training loss: 3.1376933368827427
Validation loss: 3.1277836713127805

Epoch: 6| Step: 4
Training loss: 3.917662284328226
Validation loss: 3.1300935527464375

Epoch: 6| Step: 5
Training loss: 3.2296568139643456
Validation loss: 3.128153427739162

Epoch: 6| Step: 6
Training loss: 3.7754362195335935
Validation loss: 3.12711163620231

Epoch: 6| Step: 7
Training loss: 3.275297305757307
Validation loss: 3.125614972054709

Epoch: 6| Step: 8
Training loss: 3.812644330403917
Validation loss: 3.1275058306112795

Epoch: 6| Step: 9
Training loss: 3.238386679337739
Validation loss: 3.127233597112083

Epoch: 6| Step: 10
Training loss: 2.967414475247385
Validation loss: 3.126356517101254

Epoch: 6| Step: 11
Training loss: 3.7780446740533744
Validation loss: 3.130267973437414

Epoch: 6| Step: 12
Training loss: 3.9272470347370034
Validation loss: 3.124450243102055

Epoch: 6| Step: 13
Training loss: 3.1748602588569224
Validation loss: 3.1221552873012994

Epoch: 26| Step: 0
Training loss: 4.045957247679321
Validation loss: 3.1251710250159714

Epoch: 6| Step: 1
Training loss: 3.570710208035722
Validation loss: 3.1252093616208017

Epoch: 6| Step: 2
Training loss: 2.647253621482119
Validation loss: 3.1234884966897343

Epoch: 6| Step: 3
Training loss: 2.788769618452239
Validation loss: 3.126273831215334

Epoch: 6| Step: 4
Training loss: 3.3961573877157445
Validation loss: 3.1257740218890793

Epoch: 6| Step: 5
Training loss: 3.6537607962950953
Validation loss: 3.122640469593791

Epoch: 6| Step: 6
Training loss: 2.5820319887007264
Validation loss: 3.120843713266311

Epoch: 6| Step: 7
Training loss: 3.7491629620022406
Validation loss: 3.1176602189191662

Epoch: 6| Step: 8
Training loss: 3.294208334027105
Validation loss: 3.1187480743939524

Epoch: 6| Step: 9
Training loss: 4.223434898722839
Validation loss: 3.1161376441848962

Epoch: 6| Step: 10
Training loss: 3.480136500126005
Validation loss: 3.1182248526755862

Epoch: 6| Step: 11
Training loss: 3.442270748397551
Validation loss: 3.113976331388943

Epoch: 6| Step: 12
Training loss: 3.063791586548149
Validation loss: 3.1166513644857226

Epoch: 6| Step: 13
Training loss: 2.8768815227851454
Validation loss: 3.113982132137944

Epoch: 27| Step: 0
Training loss: 3.540340369720358
Validation loss: 3.114338358593653

Epoch: 6| Step: 1
Training loss: 3.7675020596828284
Validation loss: 3.1112525034220684

Epoch: 6| Step: 2
Training loss: 3.3862611314063247
Validation loss: 3.113214513363677

Epoch: 6| Step: 3
Training loss: 3.147205651346164
Validation loss: 3.1126181021177173

Epoch: 6| Step: 4
Training loss: 3.1159948682338783
Validation loss: 3.1126025915092352

Epoch: 6| Step: 5
Training loss: 3.8520351529998127
Validation loss: 3.1112719248033667

Epoch: 6| Step: 6
Training loss: 3.2670714173020388
Validation loss: 3.108289710920951

Epoch: 6| Step: 7
Training loss: 2.8815832644546906
Validation loss: 3.1090577029048094

Epoch: 6| Step: 8
Training loss: 3.3275872454250583
Validation loss: 3.114658506394894

Epoch: 6| Step: 9
Training loss: 3.354423244606303
Validation loss: 3.1158401637291853

Epoch: 6| Step: 10
Training loss: 3.2492510592887496
Validation loss: 3.1095459989400855

Epoch: 6| Step: 11
Training loss: 3.935432981447511
Validation loss: 3.1095655414542303

Epoch: 6| Step: 12
Training loss: 3.337446313776278
Validation loss: 3.1074684181707624

Epoch: 6| Step: 13
Training loss: 2.814232864602881
Validation loss: 3.109529397929632

Epoch: 28| Step: 0
Training loss: 3.0214405019641175
Validation loss: 3.104346211844424

Epoch: 6| Step: 1
Training loss: 3.5549603367992475
Validation loss: 3.103584481616592

Epoch: 6| Step: 2
Training loss: 3.673053179083046
Validation loss: 3.1043007565596965

Epoch: 6| Step: 3
Training loss: 3.083529148241774
Validation loss: 3.103708833994831

Epoch: 6| Step: 4
Training loss: 2.983512234429536
Validation loss: 3.1039487342839145

Epoch: 6| Step: 5
Training loss: 3.703122167143563
Validation loss: 3.105847020276413

Epoch: 6| Step: 6
Training loss: 3.081044008747342
Validation loss: 3.1042580936234416

Epoch: 6| Step: 7
Training loss: 2.948904422405119
Validation loss: 3.10302082151219

Epoch: 6| Step: 8
Training loss: 3.6882737204699674
Validation loss: 3.1047420589211367

Epoch: 6| Step: 9
Training loss: 3.6852785304899327
Validation loss: 3.1039600181025913

Epoch: 6| Step: 10
Training loss: 3.2051367420180656
Validation loss: 3.1013209536466553

Epoch: 6| Step: 11
Training loss: 4.013518615915198
Validation loss: 3.101917703079499

Epoch: 6| Step: 12
Training loss: 2.9683760558075196
Validation loss: 3.1021413583478044

Epoch: 6| Step: 13
Training loss: 3.5342436397571086
Validation loss: 3.0989404192674117

Epoch: 29| Step: 0
Training loss: 2.36685923701805
Validation loss: 3.0984530664261376

Epoch: 6| Step: 1
Training loss: 3.598753655111478
Validation loss: 3.1002246883762137

Epoch: 6| Step: 2
Training loss: 2.798401144484847
Validation loss: 3.0992257789836035

Epoch: 6| Step: 3
Training loss: 3.689513610376352
Validation loss: 3.0965851833210483

Epoch: 6| Step: 4
Training loss: 3.3559041390260287
Validation loss: 3.096706270213032

Epoch: 6| Step: 5
Training loss: 3.902090558915883
Validation loss: 3.095207070940367

Epoch: 6| Step: 6
Training loss: 3.045373634754256
Validation loss: 3.094115271228293

Epoch: 6| Step: 7
Training loss: 3.3576499590756423
Validation loss: 3.094734710533626

Epoch: 6| Step: 8
Training loss: 3.4393598207017138
Validation loss: 3.093587079507056

Epoch: 6| Step: 9
Training loss: 2.2989371248784267
Validation loss: 3.092805255997286

Epoch: 6| Step: 10
Training loss: 4.367145353874784
Validation loss: 3.092824329863202

Epoch: 6| Step: 11
Training loss: 3.286036315680146
Validation loss: 3.0919842794510837

Epoch: 6| Step: 12
Training loss: 3.8682526942083295
Validation loss: 3.093596730475819

Epoch: 6| Step: 13
Training loss: 3.07675496705853
Validation loss: 3.0899495696729304

Epoch: 30| Step: 0
Training loss: 2.7773699323275816
Validation loss: 3.091259673848405

Epoch: 6| Step: 1
Training loss: 2.9241020976348584
Validation loss: 3.0929873162278705

Epoch: 6| Step: 2
Training loss: 2.805770622378171
Validation loss: 3.092624169845495

Epoch: 6| Step: 3
Training loss: 3.5768426321305857
Validation loss: 3.1001812912628655

Epoch: 6| Step: 4
Training loss: 4.227063387314069
Validation loss: 3.093198551217043

Epoch: 6| Step: 5
Training loss: 3.5210322186578553
Validation loss: 3.090426042690229

Epoch: 6| Step: 6
Training loss: 4.027281471163101
Validation loss: 3.0936339194889038

Epoch: 6| Step: 7
Training loss: 2.5768703297626625
Validation loss: 3.087843756844018

Epoch: 6| Step: 8
Training loss: 2.7656494829204097
Validation loss: 3.086908401898429

Epoch: 6| Step: 9
Training loss: 4.014393896052196
Validation loss: 3.0839966213262664

Epoch: 6| Step: 10
Training loss: 2.797739843564674
Validation loss: 3.082494116541506

Epoch: 6| Step: 11
Training loss: 3.5723052692664177
Validation loss: 3.08399675266727

Epoch: 6| Step: 12
Training loss: 3.6776742145238788
Validation loss: 3.0823138061065896

Epoch: 6| Step: 13
Training loss: 3.152471868282104
Validation loss: 3.081463550882728

Epoch: 31| Step: 0
Training loss: 3.599314221655417
Validation loss: 3.0810952387983312

Epoch: 6| Step: 1
Training loss: 2.860086654737479
Validation loss: 3.0811493701556687

Epoch: 6| Step: 2
Training loss: 3.7537543259124777
Validation loss: 3.0833396285197066

Epoch: 6| Step: 3
Training loss: 4.399733032450484
Validation loss: 3.071372777925194

Epoch: 6| Step: 4
Training loss: 3.079908444914026
Validation loss: 3.0635550688296718

Epoch: 6| Step: 5
Training loss: 3.271122006516809
Validation loss: 3.0638967798132577

Epoch: 6| Step: 6
Training loss: 3.0787424155733123
Validation loss: 3.064573358347889

Epoch: 6| Step: 7
Training loss: 3.146307212724667
Validation loss: 3.0635840376877232

Epoch: 6| Step: 8
Training loss: 3.0790727579528046
Validation loss: 3.0678876389907677

Epoch: 6| Step: 9
Training loss: 3.0931076770173287
Validation loss: 3.0564373908200535

Epoch: 6| Step: 10
Training loss: 3.651466043852685
Validation loss: 3.0563845287128637

Epoch: 6| Step: 11
Training loss: 2.9035862025594072
Validation loss: 3.0548848159585535

Epoch: 6| Step: 12
Training loss: 3.3855858550221516
Validation loss: 3.062345476167695

Epoch: 6| Step: 13
Training loss: 3.183618763082336
Validation loss: 3.0705665872133108

Epoch: 32| Step: 0
Training loss: 2.595782299570813
Validation loss: 3.07706373613401

Epoch: 6| Step: 1
Training loss: 4.119471226064463
Validation loss: 3.0929635230002828

Epoch: 6| Step: 2
Training loss: 3.271704895785967
Validation loss: 3.0810715817203356

Epoch: 6| Step: 3
Training loss: 3.673990103087907
Validation loss: 3.0691308351157573

Epoch: 6| Step: 4
Training loss: 3.363493342252799
Validation loss: 3.0548329214467507

Epoch: 6| Step: 5
Training loss: 3.400690704198928
Validation loss: 3.052859618810318

Epoch: 6| Step: 6
Training loss: 3.3270739117900825
Validation loss: 3.050710211655974

Epoch: 6| Step: 7
Training loss: 2.931858245274785
Validation loss: 3.0526336159289973

Epoch: 6| Step: 8
Training loss: 2.9917702645416973
Validation loss: 3.0671782247712462

Epoch: 6| Step: 9
Training loss: 2.8183827230711684
Validation loss: 3.0690995505185072

Epoch: 6| Step: 10
Training loss: 3.74075270763815
Validation loss: 3.0446047200011828

Epoch: 6| Step: 11
Training loss: 3.194833285858007
Validation loss: 3.047243359482644

Epoch: 6| Step: 12
Training loss: 2.8885257831021685
Validation loss: 3.0549049380830886

Epoch: 6| Step: 13
Training loss: 4.488272538272115
Validation loss: 3.064249800749163

Epoch: 33| Step: 0
Training loss: 3.2831011682005244
Validation loss: 3.099966109345605

Epoch: 6| Step: 1
Training loss: 3.4936225553958047
Validation loss: 3.0728018267686315

Epoch: 6| Step: 2
Training loss: 2.7651109810435806
Validation loss: 3.056495952173658

Epoch: 6| Step: 3
Training loss: 3.35170021752312
Validation loss: 3.0582974856091014

Epoch: 6| Step: 4
Training loss: 4.157975605858699
Validation loss: 3.064372162008952

Epoch: 6| Step: 5
Training loss: 3.40286058251627
Validation loss: 3.060222070705368

Epoch: 6| Step: 6
Training loss: 3.9266503430099
Validation loss: 3.052811132066537

Epoch: 6| Step: 7
Training loss: 2.792558375801136
Validation loss: 3.054319239241113

Epoch: 6| Step: 8
Training loss: 3.2417903794819853
Validation loss: 3.0605288757096076

Epoch: 6| Step: 9
Training loss: 3.3296619860039907
Validation loss: 3.0707103925758483

Epoch: 6| Step: 10
Training loss: 3.5765212017056465
Validation loss: 3.053326035236636

Epoch: 6| Step: 11
Training loss: 2.5359779754247866
Validation loss: 3.039046209067961

Epoch: 6| Step: 12
Training loss: 2.8180955960348673
Validation loss: 3.0365242319901853

Epoch: 6| Step: 13
Training loss: 3.9284317710130074
Validation loss: 3.0376050962565126

Epoch: 34| Step: 0
Training loss: 2.275447101465152
Validation loss: 3.0398600246487475

Epoch: 6| Step: 1
Training loss: 3.370794148132887
Validation loss: 3.037097667234569

Epoch: 6| Step: 2
Training loss: 3.412439444986276
Validation loss: 3.0396358283345997

Epoch: 6| Step: 3
Training loss: 3.549973936388216
Validation loss: 3.0382553527320835

Epoch: 6| Step: 4
Training loss: 2.9344096058845333
Validation loss: 3.0359534176232965

Epoch: 6| Step: 5
Training loss: 3.519092392736474
Validation loss: 3.0372045185459466

Epoch: 6| Step: 6
Training loss: 3.8303352047917287
Validation loss: 3.033705160780907

Epoch: 6| Step: 7
Training loss: 2.930496958487767
Validation loss: 3.0321644574062145

Epoch: 6| Step: 8
Training loss: 3.4497680917831217
Validation loss: 3.030898266281294

Epoch: 6| Step: 9
Training loss: 3.3541271294263733
Validation loss: 3.0285407745671953

Epoch: 6| Step: 10
Training loss: 3.731784065402367
Validation loss: 3.027063516434335

Epoch: 6| Step: 11
Training loss: 3.113908079982229
Validation loss: 3.024601692195173

Epoch: 6| Step: 12
Training loss: 3.3760271275501608
Validation loss: 3.0247532334981426

Epoch: 6| Step: 13
Training loss: 3.3211401771704874
Validation loss: 3.027194176087298

Epoch: 35| Step: 0
Training loss: 2.955934832751499
Validation loss: 3.0257886007326262

Epoch: 6| Step: 1
Training loss: 3.034573021505919
Validation loss: 3.0211999491796986

Epoch: 6| Step: 2
Training loss: 3.2393473123187424
Validation loss: 3.021984181262766

Epoch: 6| Step: 3
Training loss: 3.0948416585275282
Validation loss: 3.0261493881345847

Epoch: 6| Step: 4
Training loss: 4.147270886311064
Validation loss: 3.0268020413029273

Epoch: 6| Step: 5
Training loss: 3.6407709051536705
Validation loss: 3.0271085461332534

Epoch: 6| Step: 6
Training loss: 2.9806389716299453
Validation loss: 3.0295603687993338

Epoch: 6| Step: 7
Training loss: 2.781833201779793
Validation loss: 3.030765320899615

Epoch: 6| Step: 8
Training loss: 3.7356057154141893
Validation loss: 3.0316954043300948

Epoch: 6| Step: 9
Training loss: 3.5539181054790303
Validation loss: 3.032747165139986

Epoch: 6| Step: 10
Training loss: 2.711554641175892
Validation loss: 3.0251788492332436

Epoch: 6| Step: 11
Training loss: 3.5868023928472104
Validation loss: 3.0227318698378562

Epoch: 6| Step: 12
Training loss: 3.078853617762523
Validation loss: 3.018235068475735

Epoch: 6| Step: 13
Training loss: 3.577614826996025
Validation loss: 3.018256645300869

Epoch: 36| Step: 0
Training loss: 3.446782012819564
Validation loss: 3.0168835343482203

Epoch: 6| Step: 1
Training loss: 2.209340303787964
Validation loss: 3.0201940882058946

Epoch: 6| Step: 2
Training loss: 3.5799867542384094
Validation loss: 3.0200573771496484

Epoch: 6| Step: 3
Training loss: 2.912662773331706
Validation loss: 3.016085635048458

Epoch: 6| Step: 4
Training loss: 3.6727036859937807
Validation loss: 3.01718660634156

Epoch: 6| Step: 5
Training loss: 3.1414283749764884
Validation loss: 3.0157472820632942

Epoch: 6| Step: 6
Training loss: 3.599959606367892
Validation loss: 3.0099021630069545

Epoch: 6| Step: 7
Training loss: 2.7883689723347063
Validation loss: 3.004722436646732

Epoch: 6| Step: 8
Training loss: 3.5294608926158797
Validation loss: 3.0083921579511284

Epoch: 6| Step: 9
Training loss: 3.576694385768375
Validation loss: 3.0083044298947077

Epoch: 6| Step: 10
Training loss: 3.1068043265998098
Validation loss: 3.008062323796235

Epoch: 6| Step: 11
Training loss: 3.234094432511345
Validation loss: 3.0041123851840803

Epoch: 6| Step: 12
Training loss: 3.1631002587762396
Validation loss: 3.004594837307386

Epoch: 6| Step: 13
Training loss: 4.268616909113825
Validation loss: 3.001667121781085

Epoch: 37| Step: 0
Training loss: 3.476892759945316
Validation loss: 3.000906303194664

Epoch: 6| Step: 1
Training loss: 3.5157038022852314
Validation loss: 3.001363520462458

Epoch: 6| Step: 2
Training loss: 3.6385252304135474
Validation loss: 3.000675749129089

Epoch: 6| Step: 3
Training loss: 2.8588401419268417
Validation loss: 2.999269326420142

Epoch: 6| Step: 4
Training loss: 2.728404911883443
Validation loss: 3.0009715940685684

Epoch: 6| Step: 5
Training loss: 2.884536517116589
Validation loss: 3.0065537600496275

Epoch: 6| Step: 6
Training loss: 3.592776091922776
Validation loss: 3.009184423805757

Epoch: 6| Step: 7
Training loss: 3.0421095921866494
Validation loss: 3.0209998458667453

Epoch: 6| Step: 8
Training loss: 3.1446149542430817
Validation loss: 3.0217245029988398

Epoch: 6| Step: 9
Training loss: 4.012865120030527
Validation loss: 3.019766875955155

Epoch: 6| Step: 10
Training loss: 3.890448018533612
Validation loss: 3.0114906190265014

Epoch: 6| Step: 11
Training loss: 2.5496831285654515
Validation loss: 3.0034479252203163

Epoch: 6| Step: 12
Training loss: 3.0045333624396955
Validation loss: 3.000851360816307

Epoch: 6| Step: 13
Training loss: 3.544109728550369
Validation loss: 2.999991167390461

Epoch: 38| Step: 0
Training loss: 3.4222007840243327
Validation loss: 2.996435339499254

Epoch: 6| Step: 1
Training loss: 3.5382045354294727
Validation loss: 2.9964271295008884

Epoch: 6| Step: 2
Training loss: 2.6956999127145402
Validation loss: 2.99632882679789

Epoch: 6| Step: 3
Training loss: 3.3181231292817057
Validation loss: 2.996482672746947

Epoch: 6| Step: 4
Training loss: 2.894845551635228
Validation loss: 2.9942954562486506

Epoch: 6| Step: 5
Training loss: 3.4704492204537507
Validation loss: 2.992532321310146

Epoch: 6| Step: 6
Training loss: 4.16589635722091
Validation loss: 2.991958248249841

Epoch: 6| Step: 7
Training loss: 3.427420525161572
Validation loss: 2.9926453785746734

Epoch: 6| Step: 8
Training loss: 3.695161780092272
Validation loss: 2.9923204133140935

Epoch: 6| Step: 9
Training loss: 3.3962197269217897
Validation loss: 2.99279521608732

Epoch: 6| Step: 10
Training loss: 2.6639724671484686
Validation loss: 2.9926715987106727

Epoch: 6| Step: 11
Training loss: 2.9732869064515404
Validation loss: 2.991311893775744

Epoch: 6| Step: 12
Training loss: 3.0137753521403923
Validation loss: 2.9883164613598154

Epoch: 6| Step: 13
Training loss: 2.684024426413074
Validation loss: 2.9901928735663783

Epoch: 39| Step: 0
Training loss: 2.620486966661702
Validation loss: 2.9910982922736227

Epoch: 6| Step: 1
Training loss: 3.6107106565484446
Validation loss: 2.9976859841734322

Epoch: 6| Step: 2
Training loss: 2.7869238253703217
Validation loss: 3.014090957421779

Epoch: 6| Step: 3
Training loss: 4.012063907680984
Validation loss: 3.0813515210426683

Epoch: 6| Step: 4
Training loss: 4.067344711143571
Validation loss: 3.0789242240885555

Epoch: 6| Step: 5
Training loss: 3.5679929448045162
Validation loss: 3.060589048276442

Epoch: 6| Step: 6
Training loss: 2.745020172239577
Validation loss: 3.060013317958786

Epoch: 6| Step: 7
Training loss: 3.339779644624177
Validation loss: 3.054575828447808

Epoch: 6| Step: 8
Training loss: 3.415022167396369
Validation loss: 3.042085648787449

Epoch: 6| Step: 9
Training loss: 2.814931538970672
Validation loss: 3.026888921565141

Epoch: 6| Step: 10
Training loss: 3.114769937460175
Validation loss: 3.0125111451655746

Epoch: 6| Step: 11
Training loss: 3.5894258440612266
Validation loss: 2.996729404481186

Epoch: 6| Step: 12
Training loss: 3.5307603344646195
Validation loss: 2.9882048240334558

Epoch: 6| Step: 13
Training loss: 2.3163696080312275
Validation loss: 2.9909233070754286

Epoch: 40| Step: 0
Training loss: 3.1685439785828864
Validation loss: 2.9884466550281372

Epoch: 6| Step: 1
Training loss: 3.3200710792286316
Validation loss: 2.987400537634549

Epoch: 6| Step: 2
Training loss: 2.508743826227047
Validation loss: 2.9871913603058298

Epoch: 6| Step: 3
Training loss: 3.2739095779916894
Validation loss: 2.9890853963381456

Epoch: 6| Step: 4
Training loss: 3.4640321006697117
Validation loss: 2.9905615686023808

Epoch: 6| Step: 5
Training loss: 2.6240571463165603
Validation loss: 2.9953077804454042

Epoch: 6| Step: 6
Training loss: 3.5999813291277443
Validation loss: 3.0001295225834514

Epoch: 6| Step: 7
Training loss: 3.1268181661518546
Validation loss: 3.0070184224905354

Epoch: 6| Step: 8
Training loss: 3.2617342463142367
Validation loss: 3.0196048675754867

Epoch: 6| Step: 9
Training loss: 3.9038675596019643
Validation loss: 3.0317952348956205

Epoch: 6| Step: 10
Training loss: 3.3034626740335526
Validation loss: 3.021190524314932

Epoch: 6| Step: 11
Training loss: 2.64558135106816
Validation loss: 3.0034422481483625

Epoch: 6| Step: 12
Training loss: 3.7330042665642655
Validation loss: 2.9941267079810787

Epoch: 6| Step: 13
Training loss: 3.861941206426759
Validation loss: 2.986752793421472

Epoch: 41| Step: 0
Training loss: 2.5763963857463423
Validation loss: 2.9843180102882667

Epoch: 6| Step: 1
Training loss: 3.4629757220402846
Validation loss: 2.981668360030701

Epoch: 6| Step: 2
Training loss: 3.8097787118962914
Validation loss: 2.9817517096681847

Epoch: 6| Step: 3
Training loss: 2.1883198972678377
Validation loss: 2.980278362468708

Epoch: 6| Step: 4
Training loss: 2.6196233999971255
Validation loss: 2.9809028516759253

Epoch: 6| Step: 5
Training loss: 3.6581482483454053
Validation loss: 2.982624590564308

Epoch: 6| Step: 6
Training loss: 3.849553882464063
Validation loss: 2.981779774367046

Epoch: 6| Step: 7
Training loss: 3.5613121595544706
Validation loss: 2.9777108997135926

Epoch: 6| Step: 8
Training loss: 3.1641441805622166
Validation loss: 2.980617885400874

Epoch: 6| Step: 9
Training loss: 3.4509653095457202
Validation loss: 2.9773442598790854

Epoch: 6| Step: 10
Training loss: 3.4606426449243703
Validation loss: 2.976880810439681

Epoch: 6| Step: 11
Training loss: 2.800046177892007
Validation loss: 2.9762592242456036

Epoch: 6| Step: 12
Training loss: 3.5789580728825494
Validation loss: 2.975639990312574

Epoch: 6| Step: 13
Training loss: 2.9519111520272574
Validation loss: 2.9739197221943403

Epoch: 42| Step: 0
Training loss: 2.807156806683729
Validation loss: 2.9751849912445016

Epoch: 6| Step: 1
Training loss: 3.274891095862319
Validation loss: 2.9750283950411576

Epoch: 6| Step: 2
Training loss: 3.1138318196025043
Validation loss: 2.97253799262543

Epoch: 6| Step: 3
Training loss: 3.590649801754598
Validation loss: 2.973193769233321

Epoch: 6| Step: 4
Training loss: 3.0942101955117383
Validation loss: 2.9746097748942466

Epoch: 6| Step: 5
Training loss: 3.2129488026647612
Validation loss: 2.97304285415461

Epoch: 6| Step: 6
Training loss: 3.9593220864533545
Validation loss: 2.972878732424955

Epoch: 6| Step: 7
Training loss: 2.705933010927145
Validation loss: 2.9726891730811453

Epoch: 6| Step: 8
Training loss: 3.3709945929344447
Validation loss: 2.973430063302193

Epoch: 6| Step: 9
Training loss: 2.829006668832685
Validation loss: 2.9732505789895445

Epoch: 6| Step: 10
Training loss: 3.5225307879649037
Validation loss: 2.9792551858907044

Epoch: 6| Step: 11
Training loss: 3.456932626815329
Validation loss: 2.9769095514390678

Epoch: 6| Step: 12
Training loss: 3.50368550943829
Validation loss: 2.9746806216892065

Epoch: 6| Step: 13
Training loss: 2.6284855907060467
Validation loss: 2.971586120311509

Epoch: 43| Step: 0
Training loss: 3.509312638147354
Validation loss: 2.971890136912077

Epoch: 6| Step: 1
Training loss: 3.338611969031553
Validation loss: 2.968865460243051

Epoch: 6| Step: 2
Training loss: 3.785850563578295
Validation loss: 2.9694444320212994

Epoch: 6| Step: 3
Training loss: 3.6213040419401907
Validation loss: 2.968890562329762

Epoch: 6| Step: 4
Training loss: 2.949498447519331
Validation loss: 2.96913072511954

Epoch: 6| Step: 5
Training loss: 3.599702234669375
Validation loss: 2.967588949573914

Epoch: 6| Step: 6
Training loss: 2.6555647022119944
Validation loss: 2.96748562427589

Epoch: 6| Step: 7
Training loss: 2.935773626264118
Validation loss: 2.966464619694219

Epoch: 6| Step: 8
Training loss: 3.2131352015572467
Validation loss: 2.966586731413009

Epoch: 6| Step: 9
Training loss: 3.301392845059071
Validation loss: 2.9669556977340426

Epoch: 6| Step: 10
Training loss: 2.819175427594518
Validation loss: 2.9665898683550336

Epoch: 6| Step: 11
Training loss: 2.90177162250828
Validation loss: 2.9655593133296394

Epoch: 6| Step: 12
Training loss: 3.3926909872112714
Validation loss: 2.963853938805341

Epoch: 6| Step: 13
Training loss: 3.3381269001915173
Validation loss: 2.9629339719693393

Epoch: 44| Step: 0
Training loss: 3.71296318581287
Validation loss: 2.9637531310537266

Epoch: 6| Step: 1
Training loss: 3.3361684821965394
Validation loss: 2.9658996222859693

Epoch: 6| Step: 2
Training loss: 3.0173559409505617
Validation loss: 2.96433751887696

Epoch: 6| Step: 3
Training loss: 3.1559792581899204
Validation loss: 2.965633557509782

Epoch: 6| Step: 4
Training loss: 2.9440278912238926
Validation loss: 2.9643877900090287

Epoch: 6| Step: 5
Training loss: 2.993986460479925
Validation loss: 2.9612634756277125

Epoch: 6| Step: 6
Training loss: 3.2643669662069974
Validation loss: 2.9646494076999534

Epoch: 6| Step: 7
Training loss: 3.12103172116475
Validation loss: 2.964077515244902

Epoch: 6| Step: 8
Training loss: 2.957077529928049
Validation loss: 2.9647404327931777

Epoch: 6| Step: 9
Training loss: 3.2939081085302617
Validation loss: 2.969545309878981

Epoch: 6| Step: 10
Training loss: 3.774320321442654
Validation loss: 2.9664088587811692

Epoch: 6| Step: 11
Training loss: 3.495056748700333
Validation loss: 2.963758204262861

Epoch: 6| Step: 12
Training loss: 3.3809355358622635
Validation loss: 2.961690238779287

Epoch: 6| Step: 13
Training loss: 2.5169480913801436
Validation loss: 2.9589070545611387

Epoch: 45| Step: 0
Training loss: 3.8222828408049954
Validation loss: 2.957882665866229

Epoch: 6| Step: 1
Training loss: 3.129778755826808
Validation loss: 2.9559849389030695

Epoch: 6| Step: 2
Training loss: 2.112180073907482
Validation loss: 2.9568693521157035

Epoch: 6| Step: 3
Training loss: 3.230110637553296
Validation loss: 2.9560724157866063

Epoch: 6| Step: 4
Training loss: 3.629675776396599
Validation loss: 2.957628467431735

Epoch: 6| Step: 5
Training loss: 2.60111661188644
Validation loss: 2.9584043830220934

Epoch: 6| Step: 6
Training loss: 3.4861183081996296
Validation loss: 2.95578702185442

Epoch: 6| Step: 7
Training loss: 3.031427437219784
Validation loss: 2.9565465113156426

Epoch: 6| Step: 8
Training loss: 3.08402302906824
Validation loss: 2.9538374353590213

Epoch: 6| Step: 9
Training loss: 3.4579715462921063
Validation loss: 2.9522418635194025

Epoch: 6| Step: 10
Training loss: 2.853070087886311
Validation loss: 2.951917585631846

Epoch: 6| Step: 11
Training loss: 3.4978194937614346
Validation loss: 2.950733442849757

Epoch: 6| Step: 12
Training loss: 3.76689107670889
Validation loss: 2.951251396887037

Epoch: 6| Step: 13
Training loss: 3.319138119519179
Validation loss: 2.9522800854812097

Epoch: 46| Step: 0
Training loss: 3.0975472622299156
Validation loss: 2.9503868045143684

Epoch: 6| Step: 1
Training loss: 3.4339525818614116
Validation loss: 2.9506631800983847

Epoch: 6| Step: 2
Training loss: 2.5053776124056446
Validation loss: 2.9527423743369474

Epoch: 6| Step: 3
Training loss: 3.2954789953012416
Validation loss: 2.9537744684170035

Epoch: 6| Step: 4
Training loss: 3.1850651435837336
Validation loss: 2.953152436524327

Epoch: 6| Step: 5
Training loss: 2.8762617245086606
Validation loss: 2.9512652355126634

Epoch: 6| Step: 6
Training loss: 3.272703539155387
Validation loss: 2.9493277854677924

Epoch: 6| Step: 7
Training loss: 3.567497362270864
Validation loss: 2.9502412269481915

Epoch: 6| Step: 8
Training loss: 3.451645063636281
Validation loss: 2.9503321726031384

Epoch: 6| Step: 9
Training loss: 3.374638008201971
Validation loss: 2.9464648190865517

Epoch: 6| Step: 10
Training loss: 3.1247509666396818
Validation loss: 2.9472638105194977

Epoch: 6| Step: 11
Training loss: 3.614244487318384
Validation loss: 2.9450505564689258

Epoch: 6| Step: 12
Training loss: 3.4257454777832295
Validation loss: 2.9469086466392027

Epoch: 6| Step: 13
Training loss: 2.566434212681806
Validation loss: 2.944118168495057

Epoch: 47| Step: 0
Training loss: 3.3944827867566807
Validation loss: 2.9451270159427163

Epoch: 6| Step: 1
Training loss: 2.393692840610852
Validation loss: 2.943993052307547

Epoch: 6| Step: 2
Training loss: 3.8895075775162904
Validation loss: 2.944319428934487

Epoch: 6| Step: 3
Training loss: 3.1782863819779834
Validation loss: 2.943210166911215

Epoch: 6| Step: 4
Training loss: 3.7204732027876686
Validation loss: 2.942791919934987

Epoch: 6| Step: 5
Training loss: 4.1363676244543095
Validation loss: 2.942252534019677

Epoch: 6| Step: 6
Training loss: 2.5620619236582045
Validation loss: 2.942780701123758

Epoch: 6| Step: 7
Training loss: 3.1348818368256524
Validation loss: 2.940899418172532

Epoch: 6| Step: 8
Training loss: 2.7546783879865604
Validation loss: 2.9393446625690913

Epoch: 6| Step: 9
Training loss: 2.9202399753567985
Validation loss: 2.9416616088448153

Epoch: 6| Step: 10
Training loss: 3.174608377649191
Validation loss: 2.9414313580734666

Epoch: 6| Step: 11
Training loss: 3.6363712722524753
Validation loss: 2.94068394203323

Epoch: 6| Step: 12
Training loss: 3.171663775246432
Validation loss: 2.94097322054266

Epoch: 6| Step: 13
Training loss: 1.9321104583360833
Validation loss: 2.9381868985787554

Epoch: 48| Step: 0
Training loss: 2.711631576117218
Validation loss: 2.943491558038257

Epoch: 6| Step: 1
Training loss: 3.504628526971232
Validation loss: 2.946234390280296

Epoch: 6| Step: 2
Training loss: 3.223356931403434
Validation loss: 2.9524144575917015

Epoch: 6| Step: 3
Training loss: 3.936523074105354
Validation loss: 2.9590041373374136

Epoch: 6| Step: 4
Training loss: 3.2349325243178795
Validation loss: 2.9487220046467217

Epoch: 6| Step: 5
Training loss: 3.1175169806488285
Validation loss: 2.9442398312733347

Epoch: 6| Step: 6
Training loss: 3.3457062604881687
Validation loss: 2.9431224488417786

Epoch: 6| Step: 7
Training loss: 3.12391659076036
Validation loss: 2.94366795803687

Epoch: 6| Step: 8
Training loss: 3.775318758813864
Validation loss: 2.935628495107039

Epoch: 6| Step: 9
Training loss: 2.6468418231853015
Validation loss: 2.9342833872654834

Epoch: 6| Step: 10
Training loss: 3.0312477976997476
Validation loss: 2.934321303220695

Epoch: 6| Step: 11
Training loss: 3.2831168540680697
Validation loss: 2.9318274939290005

Epoch: 6| Step: 12
Training loss: 2.8569736089986284
Validation loss: 2.9368859048237597

Epoch: 6| Step: 13
Training loss: 3.0201816425897037
Validation loss: 2.9417997138820184

Epoch: 49| Step: 0
Training loss: 2.7156498213183466
Validation loss: 2.9582050410635103

Epoch: 6| Step: 1
Training loss: 3.085624582384501
Validation loss: 2.94200974663751

Epoch: 6| Step: 2
Training loss: 2.2640734391247657
Validation loss: 2.935417873889706

Epoch: 6| Step: 3
Training loss: 3.032872660382674
Validation loss: 2.930989421811441

Epoch: 6| Step: 4
Training loss: 3.5127600631281948
Validation loss: 2.9275379772995835

Epoch: 6| Step: 5
Training loss: 3.434283329414499
Validation loss: 2.9263246373574074

Epoch: 6| Step: 6
Training loss: 3.416382723539078
Validation loss: 2.9223847259648372

Epoch: 6| Step: 7
Training loss: 3.5007930946958457
Validation loss: 2.9229718590283102

Epoch: 6| Step: 8
Training loss: 3.7152306067461964
Validation loss: 2.9246959518086224

Epoch: 6| Step: 9
Training loss: 3.093983651017515
Validation loss: 2.9226784752152195

Epoch: 6| Step: 10
Training loss: 3.140654454638775
Validation loss: 2.9271186164063927

Epoch: 6| Step: 11
Training loss: 3.3462904076742466
Validation loss: 2.9265579425337913

Epoch: 6| Step: 12
Training loss: 3.562903398127663
Validation loss: 2.9260783853546837

Epoch: 6| Step: 13
Training loss: 2.6058743688729273
Validation loss: 2.9240808526976165

Epoch: 50| Step: 0
Training loss: 3.1650954079372102
Validation loss: 2.920284181898665

Epoch: 6| Step: 1
Training loss: 2.982684710299546
Validation loss: 2.9234486206732027

Epoch: 6| Step: 2
Training loss: 3.0147112316812046
Validation loss: 2.921731917820931

Epoch: 6| Step: 3
Training loss: 3.236198758824342
Validation loss: 2.9186974260400147

Epoch: 6| Step: 4
Training loss: 2.8528504689765715
Validation loss: 2.9177398717073637

Epoch: 6| Step: 5
Training loss: 2.9684007941206545
Validation loss: 2.921646029349491

Epoch: 6| Step: 6
Training loss: 3.0849830406872782
Validation loss: 2.9202103948053892

Epoch: 6| Step: 7
Training loss: 3.9939580824347174
Validation loss: 2.9156500496366538

Epoch: 6| Step: 8
Training loss: 3.3913624045124156
Validation loss: 2.918066826666924

Epoch: 6| Step: 9
Training loss: 3.322477465137673
Validation loss: 2.91629456345338

Epoch: 6| Step: 10
Training loss: 2.743378383348464
Validation loss: 2.91695542085431

Epoch: 6| Step: 11
Training loss: 3.280105536554063
Validation loss: 2.923927876175583

Epoch: 6| Step: 12
Training loss: 3.6259960253147194
Validation loss: 2.927310026730742

Epoch: 6| Step: 13
Training loss: 2.873672178723851
Validation loss: 2.9233040597768225

Testing loss: 3.1148163605169286
