Epoch: 1| Step: 0
Training loss: 5.50361705098755
Validation loss: 5.7613660803653515

Epoch: 5| Step: 1
Training loss: 5.623328744780532
Validation loss: 5.751429023099483

Epoch: 5| Step: 2
Training loss: 5.928409081762379
Validation loss: 5.740433468076529

Epoch: 5| Step: 3
Training loss: 5.397719516292274
Validation loss: 5.729142484045218

Epoch: 5| Step: 4
Training loss: 6.460637557275936
Validation loss: 5.717943797829425

Epoch: 5| Step: 5
Training loss: 5.621423559209113
Validation loss: 5.706154340577402

Epoch: 5| Step: 6
Training loss: 4.76844699041936
Validation loss: 5.693787566577815

Epoch: 5| Step: 7
Training loss: 6.017568299144039
Validation loss: 5.6817948138519965

Epoch: 5| Step: 8
Training loss: 5.9535921168852575
Validation loss: 5.668136240843068

Epoch: 5| Step: 9
Training loss: 6.133425464491013
Validation loss: 5.654100300453217

Epoch: 5| Step: 10
Training loss: 5.534991017569514
Validation loss: 5.638406445807916

Epoch: 2| Step: 0
Training loss: 6.031519750383611
Validation loss: 5.622063395038957

Epoch: 5| Step: 1
Training loss: 6.350071055097349
Validation loss: 5.604391272004321

Epoch: 5| Step: 2
Training loss: 6.396498986147434
Validation loss: 5.585931570421556

Epoch: 5| Step: 3
Training loss: 5.0780419915090595
Validation loss: 5.565086748643515

Epoch: 5| Step: 4
Training loss: 5.178952080027078
Validation loss: 5.543395268816547

Epoch: 5| Step: 5
Training loss: 5.212639983788056
Validation loss: 5.519852384353415

Epoch: 5| Step: 6
Training loss: 4.785724216930764
Validation loss: 5.496070832440722

Epoch: 5| Step: 7
Training loss: 5.55286696333085
Validation loss: 5.470658870917712

Epoch: 5| Step: 8
Training loss: 5.643168290787924
Validation loss: 5.44366855016242

Epoch: 5| Step: 9
Training loss: 5.676622993867213
Validation loss: 5.415993415635483

Epoch: 5| Step: 10
Training loss: 4.884714082844827
Validation loss: 5.386494629471348

Epoch: 3| Step: 0
Training loss: 4.919755945743023
Validation loss: 5.35612943588771

Epoch: 5| Step: 1
Training loss: 4.949682152301648
Validation loss: 5.326599210564869

Epoch: 5| Step: 2
Training loss: 5.648521243328038
Validation loss: 5.293653103526559

Epoch: 5| Step: 3
Training loss: 5.420279936089214
Validation loss: 5.262187020547861

Epoch: 5| Step: 4
Training loss: 4.971067643805212
Validation loss: 5.230917757971616

Epoch: 5| Step: 5
Training loss: 5.121260232205233
Validation loss: 5.197614958898614

Epoch: 5| Step: 6
Training loss: 4.715983002700783
Validation loss: 5.1665562959619455

Epoch: 5| Step: 7
Training loss: 6.133836872052371
Validation loss: 5.13385453797732

Epoch: 5| Step: 8
Training loss: 5.0116059074275086
Validation loss: 5.102234530908623

Epoch: 5| Step: 9
Training loss: 5.495794248791418
Validation loss: 5.069878329588317

Epoch: 5| Step: 10
Training loss: 5.1697639697740385
Validation loss: 5.038099250071188

Epoch: 4| Step: 0
Training loss: 5.856169370505341
Validation loss: 5.008539461100281

Epoch: 5| Step: 1
Training loss: 5.076492563636553
Validation loss: 4.976367283814888

Epoch: 5| Step: 2
Training loss: 3.9901390120304265
Validation loss: 4.945424789975774

Epoch: 5| Step: 3
Training loss: 5.396304823062556
Validation loss: 4.914285129237335

Epoch: 5| Step: 4
Training loss: 5.313576981826543
Validation loss: 4.883611903227734

Epoch: 5| Step: 5
Training loss: 5.023748266595189
Validation loss: 4.852659869442388

Epoch: 5| Step: 6
Training loss: 4.917702301782315
Validation loss: 4.821628625090577

Epoch: 5| Step: 7
Training loss: 4.906755554976622
Validation loss: 4.789625182199551

Epoch: 5| Step: 8
Training loss: 5.023557100904191
Validation loss: 4.757948967983822

Epoch: 5| Step: 9
Training loss: 4.166137407385502
Validation loss: 4.7265355626620655

Epoch: 5| Step: 10
Training loss: 4.188688422706402
Validation loss: 4.701020376261579

Epoch: 5| Step: 0
Training loss: 5.110350349494649
Validation loss: 4.673963686139697

Epoch: 5| Step: 1
Training loss: 4.88568938686365
Validation loss: 4.647708722704016

Epoch: 5| Step: 2
Training loss: 4.773996273619432
Validation loss: 4.620067126478922

Epoch: 5| Step: 3
Training loss: 4.348649369950794
Validation loss: 4.591215098233624

Epoch: 5| Step: 4
Training loss: 4.885360663227891
Validation loss: 4.564886494166528

Epoch: 5| Step: 5
Training loss: 4.76710282222095
Validation loss: 4.53629520152569

Epoch: 5| Step: 6
Training loss: 5.546530613483845
Validation loss: 4.508926818887232

Epoch: 5| Step: 7
Training loss: 4.627827166878537
Validation loss: 4.479959500260856

Epoch: 5| Step: 8
Training loss: 4.415803117122575
Validation loss: 4.454141949959804

Epoch: 5| Step: 9
Training loss: 3.720748492587583
Validation loss: 4.428940183118644

Epoch: 5| Step: 10
Training loss: 3.5127383439729427
Validation loss: 4.408783668789965

Epoch: 6| Step: 0
Training loss: 4.839398010270145
Validation loss: 4.3897268379243295

Epoch: 5| Step: 1
Training loss: 4.049972468153068
Validation loss: 4.37161105578292

Epoch: 5| Step: 2
Training loss: 4.9039375055012
Validation loss: 4.353147610119489

Epoch: 5| Step: 3
Training loss: 3.515996481024638
Validation loss: 4.332033072704187

Epoch: 5| Step: 4
Training loss: 3.3669624695959235
Validation loss: 4.313826017224006

Epoch: 5| Step: 5
Training loss: 3.3272812897694717
Validation loss: 4.298690655121705

Epoch: 5| Step: 6
Training loss: 5.286472244119116
Validation loss: 4.283413264963353

Epoch: 5| Step: 7
Training loss: 4.894253003613412
Validation loss: 4.270403756607998

Epoch: 5| Step: 8
Training loss: 4.479759047023039
Validation loss: 4.2569102931235125

Epoch: 5| Step: 9
Training loss: 4.798831900881197
Validation loss: 4.244651036663646

Epoch: 5| Step: 10
Training loss: 4.661386818221783
Validation loss: 4.232919845043907

Epoch: 7| Step: 0
Training loss: 3.600622886176367
Validation loss: 4.221446279746369

Epoch: 5| Step: 1
Training loss: 4.466136034481172
Validation loss: 4.211859066910156

Epoch: 5| Step: 2
Training loss: 4.197470566337951
Validation loss: 4.197764299117587

Epoch: 5| Step: 3
Training loss: 4.245152570051821
Validation loss: 4.185667383544337

Epoch: 5| Step: 4
Training loss: 4.715088086564502
Validation loss: 4.169583225641632

Epoch: 5| Step: 5
Training loss: 4.332365416975024
Validation loss: 4.152355399012358

Epoch: 5| Step: 6
Training loss: 4.644055469677805
Validation loss: 4.1359866922022075

Epoch: 5| Step: 7
Training loss: 4.431364303857883
Validation loss: 4.114644274163609

Epoch: 5| Step: 8
Training loss: 4.563532882202489
Validation loss: 4.10075963754347

Epoch: 5| Step: 9
Training loss: 4.306331258375319
Validation loss: 4.086009872179251

Epoch: 5| Step: 10
Training loss: 3.287511754468203
Validation loss: 4.073618693836887

Epoch: 8| Step: 0
Training loss: 3.978301681586548
Validation loss: 4.062366614033292

Epoch: 5| Step: 1
Training loss: 4.041413971122771
Validation loss: 4.048260983137507

Epoch: 5| Step: 2
Training loss: 3.927391276272136
Validation loss: 4.03358519661086

Epoch: 5| Step: 3
Training loss: 4.449546688007641
Validation loss: 4.015942872792603

Epoch: 5| Step: 4
Training loss: 3.901957358169818
Validation loss: 3.9981514597100607

Epoch: 5| Step: 5
Training loss: 4.083941407892099
Validation loss: 3.9797762495299653

Epoch: 5| Step: 6
Training loss: 4.521298128251041
Validation loss: 3.9648975332497796

Epoch: 5| Step: 7
Training loss: 4.399462511005428
Validation loss: 3.9450684570938277

Epoch: 5| Step: 8
Training loss: 3.67281300352832
Validation loss: 3.9294631878656663

Epoch: 5| Step: 9
Training loss: 4.081644812001393
Validation loss: 3.913290579948143

Epoch: 5| Step: 10
Training loss: 4.395347146481827
Validation loss: 3.8992138411273425

Epoch: 9| Step: 0
Training loss: 3.688765745009788
Validation loss: 3.883930908754181

Epoch: 5| Step: 1
Training loss: 3.5292928217498862
Validation loss: 3.870634654798907

Epoch: 5| Step: 2
Training loss: 3.849740299531948
Validation loss: 3.8600828456516005

Epoch: 5| Step: 3
Training loss: 4.595028031256417
Validation loss: 3.8473815863243477

Epoch: 5| Step: 4
Training loss: 3.825810445059117
Validation loss: 3.831776420937104

Epoch: 5| Step: 5
Training loss: 3.4723489322854557
Validation loss: 3.82183110615533

Epoch: 5| Step: 6
Training loss: 4.96846247386936
Validation loss: 3.811075304460042

Epoch: 5| Step: 7
Training loss: 3.8284371385020695
Validation loss: 3.8001873490457774

Epoch: 5| Step: 8
Training loss: 3.3990281567351452
Validation loss: 3.7916125298527166

Epoch: 5| Step: 9
Training loss: 4.2649023540807764
Validation loss: 3.785002285776792

Epoch: 5| Step: 10
Training loss: 4.239804098893847
Validation loss: 3.775347168916479

Epoch: 10| Step: 0
Training loss: 4.241036330916802
Validation loss: 3.7640067590647126

Epoch: 5| Step: 1
Training loss: 3.4160639223465386
Validation loss: 3.7555361678270733

Epoch: 5| Step: 2
Training loss: 3.424144810742753
Validation loss: 3.746588349370263

Epoch: 5| Step: 3
Training loss: 4.786211219803841
Validation loss: 3.7349863120519537

Epoch: 5| Step: 4
Training loss: 3.494570881008857
Validation loss: 3.7245075165377615

Epoch: 5| Step: 5
Training loss: 4.036448357682565
Validation loss: 3.7133303622440486

Epoch: 5| Step: 6
Training loss: 4.49283431994108
Validation loss: 3.7050813466069963

Epoch: 5| Step: 7
Training loss: 3.5777062583340813
Validation loss: 3.6937425893897977

Epoch: 5| Step: 8
Training loss: 3.113133751260113
Validation loss: 3.678925201278216

Epoch: 5| Step: 9
Training loss: 4.394871948598739
Validation loss: 3.668814705795897

Epoch: 5| Step: 10
Training loss: 3.4255312542406173
Validation loss: 3.657953996061791

Epoch: 11| Step: 0
Training loss: 2.8255237397678505
Validation loss: 3.647127719227315

Epoch: 5| Step: 1
Training loss: 3.799218604409248
Validation loss: 3.6326004536279775

Epoch: 5| Step: 2
Training loss: 4.034082171910553
Validation loss: 3.621388650272261

Epoch: 5| Step: 3
Training loss: 3.8841716145356595
Validation loss: 3.6048801836614563

Epoch: 5| Step: 4
Training loss: 3.8742822782273776
Validation loss: 3.602364615897632

Epoch: 5| Step: 5
Training loss: 3.695983180664237
Validation loss: 3.582137390955297

Epoch: 5| Step: 6
Training loss: 4.273206742941409
Validation loss: 3.573921278829736

Epoch: 5| Step: 7
Training loss: 3.842489020208433
Validation loss: 3.5649654461782623

Epoch: 5| Step: 8
Training loss: 4.076534735810613
Validation loss: 3.5536740998319343

Epoch: 5| Step: 9
Training loss: 3.504627166378384
Validation loss: 3.542717797336967

Epoch: 5| Step: 10
Training loss: 3.6123172278185276
Validation loss: 3.5364646990700632

Epoch: 12| Step: 0
Training loss: 3.448988702690843
Validation loss: 3.5313703781635866

Epoch: 5| Step: 1
Training loss: 3.307302175590259
Validation loss: 3.520327403127649

Epoch: 5| Step: 2
Training loss: 3.5446634666060612
Validation loss: 3.5121515592199075

Epoch: 5| Step: 3
Training loss: 4.316812321821065
Validation loss: 3.505970687668987

Epoch: 5| Step: 4
Training loss: 4.391574309003438
Validation loss: 3.49786451561112

Epoch: 5| Step: 5
Training loss: 3.746833990666424
Validation loss: 3.4897869696575325

Epoch: 5| Step: 6
Training loss: 4.076687497335028
Validation loss: 3.4806100915085993

Epoch: 5| Step: 7
Training loss: 3.1844908029690298
Validation loss: 3.4754351615146373

Epoch: 5| Step: 8
Training loss: 3.1019585113997437
Validation loss: 3.47168142579647

Epoch: 5| Step: 9
Training loss: 3.952655749307569
Validation loss: 3.4636981261069324

Epoch: 5| Step: 10
Training loss: 3.3546253783146947
Validation loss: 3.4544579999163982

Epoch: 13| Step: 0
Training loss: 3.77620972708801
Validation loss: 3.450305951192269

Epoch: 5| Step: 1
Training loss: 3.415161654219414
Validation loss: 3.4419079080731727

Epoch: 5| Step: 2
Training loss: 3.469193438804577
Validation loss: 3.440666050313207

Epoch: 5| Step: 3
Training loss: 3.6990397006150224
Validation loss: 3.431736698529036

Epoch: 5| Step: 4
Training loss: 3.50606175425622
Validation loss: 3.426242305639245

Epoch: 5| Step: 5
Training loss: 3.8265659193628814
Validation loss: 3.4230088966996988

Epoch: 5| Step: 6
Training loss: 3.759635498965692
Validation loss: 3.4193969780269278

Epoch: 5| Step: 7
Training loss: 3.8412366884337947
Validation loss: 3.41692128847161

Epoch: 5| Step: 8
Training loss: 3.362550308248263
Validation loss: 3.4103814386784475

Epoch: 5| Step: 9
Training loss: 4.089421670406303
Validation loss: 3.40564700996089

Epoch: 5| Step: 10
Training loss: 3.174757676376409
Validation loss: 3.3971850384193196

Epoch: 14| Step: 0
Training loss: 3.903422072064545
Validation loss: 3.3920717713454276

Epoch: 5| Step: 1
Training loss: 3.720015622998318
Validation loss: 3.3882858156223037

Epoch: 5| Step: 2
Training loss: 3.693472857978587
Validation loss: 3.385467109903867

Epoch: 5| Step: 3
Training loss: 4.043850626570503
Validation loss: 3.3800565302922867

Epoch: 5| Step: 4
Training loss: 3.626117139536939
Validation loss: 3.375628224145627

Epoch: 5| Step: 5
Training loss: 3.7897011130248797
Validation loss: 3.369876898849927

Epoch: 5| Step: 6
Training loss: 3.1350296812462433
Validation loss: 3.3662404288144017

Epoch: 5| Step: 7
Training loss: 3.5446863353653013
Validation loss: 3.3616959594012896

Epoch: 5| Step: 8
Training loss: 3.167259127423745
Validation loss: 3.362644462990831

Epoch: 5| Step: 9
Training loss: 3.430416229617457
Validation loss: 3.3574506524601455

Epoch: 5| Step: 10
Training loss: 3.413820026787143
Validation loss: 3.34654363254883

Epoch: 15| Step: 0
Training loss: 3.5176578324186907
Validation loss: 3.3414206201400183

Epoch: 5| Step: 1
Training loss: 3.8410756801944745
Validation loss: 3.3364321276731124

Epoch: 5| Step: 2
Training loss: 3.0427647180675343
Validation loss: 3.3342897509461604

Epoch: 5| Step: 3
Training loss: 4.058765514216071
Validation loss: 3.3319186490094737

Epoch: 5| Step: 4
Training loss: 4.060834572615272
Validation loss: 3.3280842279947374

Epoch: 5| Step: 5
Training loss: 3.2328562833569223
Validation loss: 3.3224243196381216

Epoch: 5| Step: 6
Training loss: 3.3587136260754447
Validation loss: 3.3191665553919685

Epoch: 5| Step: 7
Training loss: 3.358423284520254
Validation loss: 3.3175396032717694

Epoch: 5| Step: 8
Training loss: 3.343491446222699
Validation loss: 3.323061629972924

Epoch: 5| Step: 9
Training loss: 3.235128858496845
Validation loss: 3.3110994972113783

Epoch: 5| Step: 10
Training loss: 4.012399053046527
Validation loss: 3.3096372896261195

Epoch: 16| Step: 0
Training loss: 3.8656898141544946
Validation loss: 3.305090990997532

Epoch: 5| Step: 1
Training loss: 3.6333332960029625
Validation loss: 3.2993133987859133

Epoch: 5| Step: 2
Training loss: 3.618450957544308
Validation loss: 3.297671265976588

Epoch: 5| Step: 3
Training loss: 3.378347785089487
Validation loss: 3.2992804513147713

Epoch: 5| Step: 4
Training loss: 3.703068728763852
Validation loss: 3.2946311921225977

Epoch: 5| Step: 5
Training loss: 3.111897274626389
Validation loss: 3.2862316265510056

Epoch: 5| Step: 6
Training loss: 3.295293202531364
Validation loss: 3.282874131706599

Epoch: 5| Step: 7
Training loss: 2.8130329898617936
Validation loss: 3.2821551112256193

Epoch: 5| Step: 8
Training loss: 3.781544571428866
Validation loss: 3.278412117805099

Epoch: 5| Step: 9
Training loss: 3.4406199774848387
Validation loss: 3.276737680652613

Epoch: 5| Step: 10
Training loss: 4.112750969275713
Validation loss: 3.2749158656662125

Epoch: 17| Step: 0
Training loss: 3.628271928255071
Validation loss: 3.2723039500975526

Epoch: 5| Step: 1
Training loss: 3.183932383495048
Validation loss: 3.270937720762903

Epoch: 5| Step: 2
Training loss: 2.9403755236210336
Validation loss: 3.2679096058666772

Epoch: 5| Step: 3
Training loss: 3.1881680256060956
Validation loss: 3.262812095420878

Epoch: 5| Step: 4
Training loss: 3.7456622148635406
Validation loss: 3.259798654133482

Epoch: 5| Step: 5
Training loss: 3.4940025170092803
Validation loss: 3.258777312550915

Epoch: 5| Step: 6
Training loss: 4.05121488834315
Validation loss: 3.2586766920434806

Epoch: 5| Step: 7
Training loss: 3.326380456016928
Validation loss: 3.2540853789079542

Epoch: 5| Step: 8
Training loss: 4.468242483063243
Validation loss: 3.2596390293589272

Epoch: 5| Step: 9
Training loss: 3.0748502865453413
Validation loss: 3.24527893584637

Epoch: 5| Step: 10
Training loss: 3.1188762937366277
Validation loss: 3.2483864321257236

Epoch: 18| Step: 0
Training loss: 3.778806543207949
Validation loss: 3.2472779238872604

Epoch: 5| Step: 1
Training loss: 3.6544205743026787
Validation loss: 3.2472228971016093

Epoch: 5| Step: 2
Training loss: 3.8816314067579483
Validation loss: 3.244688091495834

Epoch: 5| Step: 3
Training loss: 3.4155524383124765
Validation loss: 3.242482762606654

Epoch: 5| Step: 4
Training loss: 3.410322502077519
Validation loss: 3.2401867861618334

Epoch: 5| Step: 5
Training loss: 3.4114427095400024
Validation loss: 3.2320614994467016

Epoch: 5| Step: 6
Training loss: 3.4163940289896186
Validation loss: 3.23513354655957

Epoch: 5| Step: 7
Training loss: 3.3995612029614444
Validation loss: 3.2304570351268316

Epoch: 5| Step: 8
Training loss: 2.8025365035225964
Validation loss: 3.231379099515151

Epoch: 5| Step: 9
Training loss: 2.9712553996934563
Validation loss: 3.228246517388091

Epoch: 5| Step: 10
Training loss: 4.1641509027025565
Validation loss: 3.232491537166994

Epoch: 19| Step: 0
Training loss: 3.7452932701842587
Validation loss: 3.22374505099211

Epoch: 5| Step: 1
Training loss: 3.2657202017746862
Validation loss: 3.2200150473392184

Epoch: 5| Step: 2
Training loss: 3.238033713162308
Validation loss: 3.22056129116546

Epoch: 5| Step: 3
Training loss: 3.808408824637099
Validation loss: 3.2188248912853137

Epoch: 5| Step: 4
Training loss: 3.43242881551058
Validation loss: 3.220055183004543

Epoch: 5| Step: 5
Training loss: 3.4806089019814115
Validation loss: 3.2179827143466695

Epoch: 5| Step: 6
Training loss: 3.8517860827441703
Validation loss: 3.2127095168155764

Epoch: 5| Step: 7
Training loss: 3.4318725299148967
Validation loss: 3.2107045733601254

Epoch: 5| Step: 8
Training loss: 3.0215198832856176
Validation loss: 3.2085627434008317

Epoch: 5| Step: 9
Training loss: 3.357928723240529
Validation loss: 3.205133105880865

Epoch: 5| Step: 10
Training loss: 3.4365732504293294
Validation loss: 3.2037613367444386

Epoch: 20| Step: 0
Training loss: 3.4756640012569955
Validation loss: 3.200384187644516

Epoch: 5| Step: 1
Training loss: 3.3016009695444977
Validation loss: 3.1963499757630633

Epoch: 5| Step: 2
Training loss: 3.417276576119187
Validation loss: 3.194810373095226

Epoch: 5| Step: 3
Training loss: 3.5719078723265905
Validation loss: 3.192869917864005

Epoch: 5| Step: 4
Training loss: 4.0513290579290295
Validation loss: 3.1961597753736184

Epoch: 5| Step: 5
Training loss: 3.443485805118306
Validation loss: 3.1900659801549067

Epoch: 5| Step: 6
Training loss: 3.1414250355964985
Validation loss: 3.1869506965838443

Epoch: 5| Step: 7
Training loss: 3.404225298883592
Validation loss: 3.187236220825731

Epoch: 5| Step: 8
Training loss: 3.3529244881127043
Validation loss: 3.188146600803496

Epoch: 5| Step: 9
Training loss: 3.7686443965660326
Validation loss: 3.185840101301801

Epoch: 5| Step: 10
Training loss: 2.7382613982652373
Validation loss: 3.181017831971411

Epoch: 21| Step: 0
Training loss: 3.3759327765095133
Validation loss: 3.1785998139297194

Epoch: 5| Step: 1
Training loss: 3.263039181173891
Validation loss: 3.1765935694152114

Epoch: 5| Step: 2
Training loss: 2.6968834763058873
Validation loss: 3.1757747435806145

Epoch: 5| Step: 3
Training loss: 4.011106806571062
Validation loss: 3.1737250729625313

Epoch: 5| Step: 4
Training loss: 2.346297443704855
Validation loss: 3.175172893805773

Epoch: 5| Step: 5
Training loss: 3.3526097508841723
Validation loss: 3.1716442952720625

Epoch: 5| Step: 6
Training loss: 3.9130072170457155
Validation loss: 3.169188234376209

Epoch: 5| Step: 7
Training loss: 3.570531925996196
Validation loss: 3.1696978640702707

Epoch: 5| Step: 8
Training loss: 3.4079002092732624
Validation loss: 3.1682548561166013

Epoch: 5| Step: 9
Training loss: 3.771968326504392
Validation loss: 3.1647214231014007

Epoch: 5| Step: 10
Training loss: 3.7364438762372703
Validation loss: 3.1646684312270903

Epoch: 22| Step: 0
Training loss: 4.01895276829173
Validation loss: 3.1643500773277706

Epoch: 5| Step: 1
Training loss: 4.098870023998421
Validation loss: 3.1631322986485273

Epoch: 5| Step: 2
Training loss: 3.059024473533236
Validation loss: 3.162598806913984

Epoch: 5| Step: 3
Training loss: 3.4138133222139992
Validation loss: 3.1618570245066193

Epoch: 5| Step: 4
Training loss: 2.9721008664210347
Validation loss: 3.1582053313092646

Epoch: 5| Step: 5
Training loss: 3.77146907666984
Validation loss: 3.159681188680614

Epoch: 5| Step: 6
Training loss: 3.2744092568653222
Validation loss: 3.158660327338084

Epoch: 5| Step: 7
Training loss: 3.143383731323402
Validation loss: 3.1528124963129516

Epoch: 5| Step: 8
Training loss: 2.965399206346918
Validation loss: 3.1514498495154153

Epoch: 5| Step: 9
Training loss: 3.4380534333431267
Validation loss: 3.1486812647722418

Epoch: 5| Step: 10
Training loss: 3.2223904956711555
Validation loss: 3.1515283786181443

Epoch: 23| Step: 0
Training loss: 3.5144262007745897
Validation loss: 3.1483720117995504

Epoch: 5| Step: 1
Training loss: 3.498902966370833
Validation loss: 3.1477947144351788

Epoch: 5| Step: 2
Training loss: 3.4423908466218305
Validation loss: 3.1467683691869444

Epoch: 5| Step: 3
Training loss: 2.6804186654811075
Validation loss: 3.1446376066387387

Epoch: 5| Step: 4
Training loss: 3.508291776747752
Validation loss: 3.1422994679477605

Epoch: 5| Step: 5
Training loss: 2.894221197863613
Validation loss: 3.1388227295050677

Epoch: 5| Step: 6
Training loss: 3.1444207023949424
Validation loss: 3.140023858989705

Epoch: 5| Step: 7
Training loss: 3.9297806897499066
Validation loss: 3.139912003103894

Epoch: 5| Step: 8
Training loss: 3.8267745146578935
Validation loss: 3.135829123422238

Epoch: 5| Step: 9
Training loss: 3.750028482964746
Validation loss: 3.1312211294376104

Epoch: 5| Step: 10
Training loss: 2.9924877205376066
Validation loss: 3.1330312536357545

Epoch: 24| Step: 0
Training loss: 3.3890841450402327
Validation loss: 3.130970909081788

Epoch: 5| Step: 1
Training loss: 3.2987266511369047
Validation loss: 3.128937948497361

Epoch: 5| Step: 2
Training loss: 3.7208758777152564
Validation loss: 3.1270634178245653

Epoch: 5| Step: 3
Training loss: 4.020575770428514
Validation loss: 3.125803352379904

Epoch: 5| Step: 4
Training loss: 3.7123504197527053
Validation loss: 3.121967043235185

Epoch: 5| Step: 5
Training loss: 3.13763558752098
Validation loss: 3.122334660736315

Epoch: 5| Step: 6
Training loss: 2.9407611357323944
Validation loss: 3.119421880085838

Epoch: 5| Step: 7
Training loss: 3.1348978080094727
Validation loss: 3.114988558229773

Epoch: 5| Step: 8
Training loss: 3.007561690537319
Validation loss: 3.1166280620246605

Epoch: 5| Step: 9
Training loss: 3.3061403368122138
Validation loss: 3.1150329251082463

Epoch: 5| Step: 10
Training loss: 3.4894268551184275
Validation loss: 3.114880655087254

Epoch: 25| Step: 0
Training loss: 4.000295151311641
Validation loss: 3.1100144495801647

Epoch: 5| Step: 1
Training loss: 3.3450471732743416
Validation loss: 3.1122126742893674

Epoch: 5| Step: 2
Training loss: 3.023696139211934
Validation loss: 3.113480935054234

Epoch: 5| Step: 3
Training loss: 3.0430004034979157
Validation loss: 3.1126417385155034

Epoch: 5| Step: 4
Training loss: 3.096889713687376
Validation loss: 3.1164426561095837

Epoch: 5| Step: 5
Training loss: 3.413250370457852
Validation loss: 3.1170730941971456

Epoch: 5| Step: 6
Training loss: 4.071600009301281
Validation loss: 3.1090669232505923

Epoch: 5| Step: 7
Training loss: 3.472569055824973
Validation loss: 3.1070309891334067

Epoch: 5| Step: 8
Training loss: 3.738589793260682
Validation loss: 3.105777649218839

Epoch: 5| Step: 9
Training loss: 3.0278175032534262
Validation loss: 3.1028838401973764

Epoch: 5| Step: 10
Training loss: 2.5257365144023924
Validation loss: 3.1146996210569196

Epoch: 26| Step: 0
Training loss: 3.8807018537954905
Validation loss: 3.1082807959117513

Epoch: 5| Step: 1
Training loss: 3.121512641535294
Validation loss: 3.102813913761979

Epoch: 5| Step: 2
Training loss: 3.305874370156453
Validation loss: 3.100510683975328

Epoch: 5| Step: 3
Training loss: 3.259023464187472
Validation loss: 3.096302181721603

Epoch: 5| Step: 4
Training loss: 3.0178309461241803
Validation loss: 3.0961844870760546

Epoch: 5| Step: 5
Training loss: 4.052860973173283
Validation loss: 3.0983563343153646

Epoch: 5| Step: 6
Training loss: 3.6878520991443753
Validation loss: 3.0938853970380222

Epoch: 5| Step: 7
Training loss: 3.0402079877476553
Validation loss: 3.0957164793747736

Epoch: 5| Step: 8
Training loss: 3.3684263848902507
Validation loss: 3.0947678723783936

Epoch: 5| Step: 9
Training loss: 3.080854570808984
Validation loss: 3.0944873456921242

Epoch: 5| Step: 10
Training loss: 3.0403122869509733
Validation loss: 3.096155260195475

Epoch: 27| Step: 0
Training loss: 3.2727906673726332
Validation loss: 3.0925985550862016

Epoch: 5| Step: 1
Training loss: 3.915743955858738
Validation loss: 3.0902945756119635

Epoch: 5| Step: 2
Training loss: 3.6462230946329877
Validation loss: 3.08814558287971

Epoch: 5| Step: 3
Training loss: 3.8045467530835952
Validation loss: 3.0922688899482704

Epoch: 5| Step: 4
Training loss: 2.4665739875428323
Validation loss: 3.090942559138647

Epoch: 5| Step: 5
Training loss: 3.1673675230002654
Validation loss: 3.088227516467391

Epoch: 5| Step: 6
Training loss: 3.644571416537437
Validation loss: 3.0868272006887785

Epoch: 5| Step: 7
Training loss: 2.7204843886407235
Validation loss: 3.083203522250788

Epoch: 5| Step: 8
Training loss: 3.1688023609898957
Validation loss: 3.082293261573372

Epoch: 5| Step: 9
Training loss: 3.8190964711748427
Validation loss: 3.086281794839284

Epoch: 5| Step: 10
Training loss: 2.8673286922937313
Validation loss: 3.07776473457346

Epoch: 28| Step: 0
Training loss: 3.895721896340642
Validation loss: 3.0792097178555684

Epoch: 5| Step: 1
Training loss: 2.784161447540875
Validation loss: 3.0793414250743094

Epoch: 5| Step: 2
Training loss: 3.170022658498754
Validation loss: 3.079269209008311

Epoch: 5| Step: 3
Training loss: 3.3595223327975408
Validation loss: 3.0788813036087697

Epoch: 5| Step: 4
Training loss: 3.4054799740652957
Validation loss: 3.079503356839538

Epoch: 5| Step: 5
Training loss: 3.1736436244450115
Validation loss: 3.077331237406811

Epoch: 5| Step: 6
Training loss: 3.2920143491077685
Validation loss: 3.078986226126898

Epoch: 5| Step: 7
Training loss: 3.1245199216200534
Validation loss: 3.096698458512006

Epoch: 5| Step: 8
Training loss: 3.540469127971343
Validation loss: 3.114576491920683

Epoch: 5| Step: 9
Training loss: 3.963195518319865
Validation loss: 3.1024132353234504

Epoch: 5| Step: 10
Training loss: 2.924742245525029
Validation loss: 3.077112849646876

Epoch: 29| Step: 0
Training loss: 3.4323903341201913
Validation loss: 3.0937790109536425

Epoch: 5| Step: 1
Training loss: 2.78906198709948
Validation loss: 3.133132461199857

Epoch: 5| Step: 2
Training loss: 3.634500615842911
Validation loss: 3.1287565815281466

Epoch: 5| Step: 3
Training loss: 3.825978327281486
Validation loss: 3.1355752858150385

Epoch: 5| Step: 4
Training loss: 3.5018285334518815
Validation loss: 3.1215137092010825

Epoch: 5| Step: 5
Training loss: 2.6005114932547966
Validation loss: 3.098839794251901

Epoch: 5| Step: 6
Training loss: 3.1170969402572224
Validation loss: 3.083837049512858

Epoch: 5| Step: 7
Training loss: 3.1168052037366003
Validation loss: 3.0828661100417203

Epoch: 5| Step: 8
Training loss: 3.6970277962665072
Validation loss: 3.08197125068538

Epoch: 5| Step: 9
Training loss: 3.6860480602026913
Validation loss: 3.0798627787853867

Epoch: 5| Step: 10
Training loss: 3.4983797410198236
Validation loss: 3.0820508097686594

Epoch: 30| Step: 0
Training loss: 4.159153433271504
Validation loss: 3.0782711397672857

Epoch: 5| Step: 1
Training loss: 3.7061299553868614
Validation loss: 3.0746768944070024

Epoch: 5| Step: 2
Training loss: 3.0432899707101844
Validation loss: 3.0678539768380286

Epoch: 5| Step: 3
Training loss: 3.1384692028723062
Validation loss: 3.0733200106088336

Epoch: 5| Step: 4
Training loss: 3.2151612951180986
Validation loss: 3.069943713554377

Epoch: 5| Step: 5
Training loss: 3.1735274797508666
Validation loss: 3.071646683884731

Epoch: 5| Step: 6
Training loss: 3.476080906118462
Validation loss: 3.063045529297618

Epoch: 5| Step: 7
Training loss: 3.714704476843449
Validation loss: 3.056501211141184

Epoch: 5| Step: 8
Training loss: 3.0719699414193307
Validation loss: 3.0566791702749967

Epoch: 5| Step: 9
Training loss: 2.820849169447683
Validation loss: 3.055754187744371

Epoch: 5| Step: 10
Training loss: 2.9238579696936235
Validation loss: 3.0573287843939845

Epoch: 31| Step: 0
Training loss: 2.700278663383525
Validation loss: 3.056411923213503

Epoch: 5| Step: 1
Training loss: 2.7439475646611515
Validation loss: 3.0592422771133423

Epoch: 5| Step: 2
Training loss: 3.2672728255088517
Validation loss: 3.0592274143347047

Epoch: 5| Step: 3
Training loss: 3.4534185638612764
Validation loss: 3.0590595150613002

Epoch: 5| Step: 4
Training loss: 3.5924290095079807
Validation loss: 3.0589644914415346

Epoch: 5| Step: 5
Training loss: 3.069119520140304
Validation loss: 3.0532115690617907

Epoch: 5| Step: 6
Training loss: 3.2333407752616683
Validation loss: 3.053262667444298

Epoch: 5| Step: 7
Training loss: 3.515499536606757
Validation loss: 3.052023556977985

Epoch: 5| Step: 8
Training loss: 3.5900198775992336
Validation loss: 3.0502331540865124

Epoch: 5| Step: 9
Training loss: 3.3909802228777806
Validation loss: 3.0489126438117657

Epoch: 5| Step: 10
Training loss: 3.9502712398064506
Validation loss: 3.048162263601517

Epoch: 32| Step: 0
Training loss: 2.9647697670693614
Validation loss: 3.047403154855755

Epoch: 5| Step: 1
Training loss: 2.92791775974615
Validation loss: 3.047588751748258

Epoch: 5| Step: 2
Training loss: 3.2734153582932546
Validation loss: 3.0484489084259896

Epoch: 5| Step: 3
Training loss: 3.4602515787380517
Validation loss: 3.052101091244121

Epoch: 5| Step: 4
Training loss: 3.5054789302194362
Validation loss: 3.049910925518149

Epoch: 5| Step: 5
Training loss: 3.5345415286928232
Validation loss: 3.0477627496105093

Epoch: 5| Step: 6
Training loss: 2.8231030973877353
Validation loss: 3.0456728448142107

Epoch: 5| Step: 7
Training loss: 4.355265988133512
Validation loss: 3.0463505287489445

Epoch: 5| Step: 8
Training loss: 2.498272298822717
Validation loss: 3.043764733989323

Epoch: 5| Step: 9
Training loss: 3.27781802941157
Validation loss: 3.0440490356098895

Epoch: 5| Step: 10
Training loss: 3.568604576234385
Validation loss: 3.044802334053667

Epoch: 33| Step: 0
Training loss: 3.0196176296971173
Validation loss: 3.0409990191231016

Epoch: 5| Step: 1
Training loss: 2.711279855707104
Validation loss: 3.044467200346462

Epoch: 5| Step: 2
Training loss: 3.533300024151494
Validation loss: 3.041024919294505

Epoch: 5| Step: 3
Training loss: 3.801910828461236
Validation loss: 3.0408786073639518

Epoch: 5| Step: 4
Training loss: 3.4890682618451923
Validation loss: 3.039850686312071

Epoch: 5| Step: 5
Training loss: 3.1324448976290276
Validation loss: 3.0401044270471624

Epoch: 5| Step: 6
Training loss: 3.3629236684729533
Validation loss: 3.039189602038517

Epoch: 5| Step: 7
Training loss: 3.9327078828472732
Validation loss: 3.0386397746850236

Epoch: 5| Step: 8
Training loss: 2.8596606502746096
Validation loss: 3.0368143998365587

Epoch: 5| Step: 9
Training loss: 3.2359128972273625
Validation loss: 3.038935976415446

Epoch: 5| Step: 10
Training loss: 3.1128756499435886
Validation loss: 3.038267013847256

Epoch: 34| Step: 0
Training loss: 3.6093192488422905
Validation loss: 3.040651638930833

Epoch: 5| Step: 1
Training loss: 3.133125727113327
Validation loss: 3.0426043454250635

Epoch: 5| Step: 2
Training loss: 3.617066877755613
Validation loss: 3.043596961323113

Epoch: 5| Step: 3
Training loss: 2.551168368583469
Validation loss: 3.0437307368254296

Epoch: 5| Step: 4
Training loss: 4.0439298657562395
Validation loss: 3.047300713612695

Epoch: 5| Step: 5
Training loss: 3.5213569537661757
Validation loss: 3.044908432560944

Epoch: 5| Step: 6
Training loss: 3.4557654870699106
Validation loss: 3.0414686333794436

Epoch: 5| Step: 7
Training loss: 3.2394491742352765
Validation loss: 3.0361154469935

Epoch: 5| Step: 8
Training loss: 2.628301088872721
Validation loss: 3.034337041414732

Epoch: 5| Step: 9
Training loss: 3.2492705773716577
Validation loss: 3.033294171154094

Epoch: 5| Step: 10
Training loss: 2.9757686167053476
Validation loss: 3.034212382367731

Epoch: 35| Step: 0
Training loss: 3.498982145261168
Validation loss: 3.0334593495081044

Epoch: 5| Step: 1
Training loss: 3.093941730761846
Validation loss: 3.032419761946986

Epoch: 5| Step: 2
Training loss: 2.791964519799952
Validation loss: 3.0304694600608286

Epoch: 5| Step: 3
Training loss: 3.291955251155512
Validation loss: 3.031321727807716

Epoch: 5| Step: 4
Training loss: 3.134520257871893
Validation loss: 3.0283991240805537

Epoch: 5| Step: 5
Training loss: 3.524719005233883
Validation loss: 3.0313642171829986

Epoch: 5| Step: 6
Training loss: 3.643065195526957
Validation loss: 3.028837875044781

Epoch: 5| Step: 7
Training loss: 2.610811945728894
Validation loss: 3.0288245110375405

Epoch: 5| Step: 8
Training loss: 3.202304790899192
Validation loss: 3.0283725004919546

Epoch: 5| Step: 9
Training loss: 3.550489827064001
Validation loss: 3.0277417670522504

Epoch: 5| Step: 10
Training loss: 3.838799490825448
Validation loss: 3.0323268135149677

Epoch: 36| Step: 0
Training loss: 3.317738547354736
Validation loss: 3.0342924113202487

Epoch: 5| Step: 1
Training loss: 3.368202428248078
Validation loss: 3.037286787282287

Epoch: 5| Step: 2
Training loss: 2.8816198347473385
Validation loss: 3.0327031109888067

Epoch: 5| Step: 3
Training loss: 3.6488852379342185
Validation loss: 3.0342922034775186

Epoch: 5| Step: 4
Training loss: 3.4079498809030437
Validation loss: 3.0285328852357902

Epoch: 5| Step: 5
Training loss: 3.939980588371365
Validation loss: 3.029633211269299

Epoch: 5| Step: 6
Training loss: 2.4913105632580854
Validation loss: 3.024570417432129

Epoch: 5| Step: 7
Training loss: 2.9462995822960187
Validation loss: 3.0235486758562264

Epoch: 5| Step: 8
Training loss: 3.738582268118261
Validation loss: 3.0226674518608703

Epoch: 5| Step: 9
Training loss: 3.353111496015591
Validation loss: 3.025664853654369

Epoch: 5| Step: 10
Training loss: 2.8352656974280572
Validation loss: 3.0197340348724864

Epoch: 37| Step: 0
Training loss: 3.262942147530336
Validation loss: 3.0238227476907302

Epoch: 5| Step: 1
Training loss: 3.317327328797126
Validation loss: 3.02060929861911

Epoch: 5| Step: 2
Training loss: 3.677897347897622
Validation loss: 3.0196580959294277

Epoch: 5| Step: 3
Training loss: 3.765079189648113
Validation loss: 3.013937947765995

Epoch: 5| Step: 4
Training loss: 3.08880667275926
Validation loss: 3.0135146398373664

Epoch: 5| Step: 5
Training loss: 3.1223168107257355
Validation loss: 3.011643686624386

Epoch: 5| Step: 6
Training loss: 3.5315578630317535
Validation loss: 3.0129211876139177

Epoch: 5| Step: 7
Training loss: 2.6899048447353056
Validation loss: 3.014278671771635

Epoch: 5| Step: 8
Training loss: 3.083191241177766
Validation loss: 3.0135179423092917

Epoch: 5| Step: 9
Training loss: 3.5855953410682218
Validation loss: 3.01954630477462

Epoch: 5| Step: 10
Training loss: 2.737422269649505
Validation loss: 3.0241818487016245

Epoch: 38| Step: 0
Training loss: 3.1968406996094125
Validation loss: 3.0350604197189788

Epoch: 5| Step: 1
Training loss: 3.498756460256769
Validation loss: 3.0428861538143877

Epoch: 5| Step: 2
Training loss: 3.221484605907822
Validation loss: 3.023725050757178

Epoch: 5| Step: 3
Training loss: 2.2665089954439233
Validation loss: 3.013238801748411

Epoch: 5| Step: 4
Training loss: 3.459228369164745
Validation loss: 3.013912559098641

Epoch: 5| Step: 5
Training loss: 3.3945267548877025
Validation loss: 3.008532458212713

Epoch: 5| Step: 6
Training loss: 3.4935331546863937
Validation loss: 3.006949878205129

Epoch: 5| Step: 7
Training loss: 3.331708671097667
Validation loss: 3.006541005573565

Epoch: 5| Step: 8
Training loss: 3.2962466540589057
Validation loss: 3.0084022322058317

Epoch: 5| Step: 9
Training loss: 3.12878646335546
Validation loss: 3.007949230643175

Epoch: 5| Step: 10
Training loss: 3.6974466947539453
Validation loss: 3.0075928608788147

Epoch: 39| Step: 0
Training loss: 2.7352481864725844
Validation loss: 3.0067841703440994

Epoch: 5| Step: 1
Training loss: 3.374405419992767
Validation loss: 3.0070407328503297

Epoch: 5| Step: 2
Training loss: 3.5042407366302317
Validation loss: 3.0064522292375804

Epoch: 5| Step: 3
Training loss: 2.9804660302146013
Validation loss: 3.0038495489081973

Epoch: 5| Step: 4
Training loss: 3.7692132212830725
Validation loss: 3.0018785057641706

Epoch: 5| Step: 5
Training loss: 3.434312903525788
Validation loss: 3.002524243694826

Epoch: 5| Step: 6
Training loss: 3.363497169998133
Validation loss: 2.9998081104887833

Epoch: 5| Step: 7
Training loss: 2.845799137503922
Validation loss: 3.000792082608779

Epoch: 5| Step: 8
Training loss: 3.5484927349083395
Validation loss: 3.00067845572272

Epoch: 5| Step: 9
Training loss: 2.767377309035171
Validation loss: 3.000206871830251

Epoch: 5| Step: 10
Training loss: 3.577488072106865
Validation loss: 3.001047698328088

Epoch: 40| Step: 0
Training loss: 3.5878924856248577
Validation loss: 3.006234707948114

Epoch: 5| Step: 1
Training loss: 2.695690891407812
Validation loss: 3.010047779005889

Epoch: 5| Step: 2
Training loss: 3.3484098104879827
Validation loss: 3.0147193867841486

Epoch: 5| Step: 3
Training loss: 3.3456216012761786
Validation loss: 3.011143882082834

Epoch: 5| Step: 4
Training loss: 2.983885080758121
Validation loss: 3.0186319756692783

Epoch: 5| Step: 5
Training loss: 3.3889718662241197
Validation loss: 3.0086662760896816

Epoch: 5| Step: 6
Training loss: 3.5483989382571424
Validation loss: 3.0063589938675

Epoch: 5| Step: 7
Training loss: 3.5388660502699065
Validation loss: 2.9957787783128627

Epoch: 5| Step: 8
Training loss: 2.809177895018722
Validation loss: 2.9976371908228328

Epoch: 5| Step: 9
Training loss: 3.443988848536356
Validation loss: 2.996214625082732

Epoch: 5| Step: 10
Training loss: 3.194054540160136
Validation loss: 2.998695960043844

Epoch: 41| Step: 0
Training loss: 3.070609585509616
Validation loss: 2.996588028022612

Epoch: 5| Step: 1
Training loss: 2.8731718470546657
Validation loss: 2.9990585099156677

Epoch: 5| Step: 2
Training loss: 3.795245036581342
Validation loss: 2.9988517708759597

Epoch: 5| Step: 3
Training loss: 3.4407053481585255
Validation loss: 3.0013675162139983

Epoch: 5| Step: 4
Training loss: 3.1068766155710663
Validation loss: 3.000008692438255

Epoch: 5| Step: 5
Training loss: 3.3808748893888687
Validation loss: 2.998058661724668

Epoch: 5| Step: 6
Training loss: 3.322401829999332
Validation loss: 2.9986658565027144

Epoch: 5| Step: 7
Training loss: 2.9054574193320675
Validation loss: 2.9972703780112284

Epoch: 5| Step: 8
Training loss: 3.5902545681434215
Validation loss: 2.9952191624568205

Epoch: 5| Step: 9
Training loss: 3.186730983941643
Validation loss: 2.9938122101152014

Epoch: 5| Step: 10
Training loss: 3.21436314565248
Validation loss: 2.991288051137715

Epoch: 42| Step: 0
Training loss: 3.11858655849132
Validation loss: 2.9920912985548855

Epoch: 5| Step: 1
Training loss: 3.2148654051708383
Validation loss: 2.9923804504818325

Epoch: 5| Step: 2
Training loss: 3.265509790459884
Validation loss: 2.991529101569451

Epoch: 5| Step: 3
Training loss: 3.397715945759929
Validation loss: 2.9916193507925937

Epoch: 5| Step: 4
Training loss: 3.6811419485714247
Validation loss: 2.9901363574046336

Epoch: 5| Step: 5
Training loss: 3.3972606506697227
Validation loss: 2.9901453091475005

Epoch: 5| Step: 6
Training loss: 2.5921116445892403
Validation loss: 2.9945170740591878

Epoch: 5| Step: 7
Training loss: 2.939881029381792
Validation loss: 2.9898606047041127

Epoch: 5| Step: 8
Training loss: 3.526621528101055
Validation loss: 2.9896865374711687

Epoch: 5| Step: 9
Training loss: 3.5182555804989373
Validation loss: 2.9872350523690936

Epoch: 5| Step: 10
Training loss: 3.122672473062687
Validation loss: 2.9884090723587993

Epoch: 43| Step: 0
Training loss: 2.974236167493983
Validation loss: 2.9861643402425138

Epoch: 5| Step: 1
Training loss: 3.1005877829718917
Validation loss: 2.985445790547043

Epoch: 5| Step: 2
Training loss: 3.207024410486769
Validation loss: 2.9841800121967887

Epoch: 5| Step: 3
Training loss: 3.56635744828159
Validation loss: 2.9850964740648327

Epoch: 5| Step: 4
Training loss: 3.478614595816212
Validation loss: 2.990471457195913

Epoch: 5| Step: 5
Training loss: 3.4369708954480873
Validation loss: 2.988765350106259

Epoch: 5| Step: 6
Training loss: 3.3635287841726593
Validation loss: 2.987362811363889

Epoch: 5| Step: 7
Training loss: 3.04142735902882
Validation loss: 2.983563216163367

Epoch: 5| Step: 8
Training loss: 3.130765403055963
Validation loss: 2.983362302767251

Epoch: 5| Step: 9
Training loss: 3.4536509393822925
Validation loss: 2.9858674557533624

Epoch: 5| Step: 10
Training loss: 3.046088640512514
Validation loss: 2.983194383215528

Epoch: 44| Step: 0
Training loss: 2.990271530070031
Validation loss: 2.9814679758770986

Epoch: 5| Step: 1
Training loss: 3.3175241048895843
Validation loss: 2.98244852540778

Epoch: 5| Step: 2
Training loss: 3.1700009978380046
Validation loss: 2.9834491728443315

Epoch: 5| Step: 3
Training loss: 3.182201394623285
Validation loss: 2.9835803393413527

Epoch: 5| Step: 4
Training loss: 3.118905647995956
Validation loss: 2.9826061347847213

Epoch: 5| Step: 5
Training loss: 3.9875714812852414
Validation loss: 2.983884914080691

Epoch: 5| Step: 6
Training loss: 3.1018788827337236
Validation loss: 2.9834989827481024

Epoch: 5| Step: 7
Training loss: 2.7332306129258575
Validation loss: 2.9827254592837984

Epoch: 5| Step: 8
Training loss: 3.56344618696803
Validation loss: 2.983010260318198

Epoch: 5| Step: 9
Training loss: 3.3124496168227613
Validation loss: 2.9832385299774686

Epoch: 5| Step: 10
Training loss: 3.163641856925205
Validation loss: 2.9800502592050724

Epoch: 45| Step: 0
Training loss: 3.12822313030943
Validation loss: 2.98226614792781

Epoch: 5| Step: 1
Training loss: 3.2332645297513385
Validation loss: 2.978739833452193

Epoch: 5| Step: 2
Training loss: 2.9147388808485526
Validation loss: 2.9810233270776454

Epoch: 5| Step: 3
Training loss: 3.6035267403283853
Validation loss: 2.976668664965364

Epoch: 5| Step: 4
Training loss: 2.7634579201633724
Validation loss: 2.9802474277331568

Epoch: 5| Step: 5
Training loss: 2.9806776860948565
Validation loss: 2.9798992113152454

Epoch: 5| Step: 6
Training loss: 3.0156937823579897
Validation loss: 2.977850369283023

Epoch: 5| Step: 7
Training loss: 3.0990988990682524
Validation loss: 2.9827380852534833

Epoch: 5| Step: 8
Training loss: 3.84325349904033
Validation loss: 2.9793277894541745

Epoch: 5| Step: 9
Training loss: 2.9484538924383674
Validation loss: 2.9755566012967183

Epoch: 5| Step: 10
Training loss: 4.085767344912449
Validation loss: 2.9728564166336513

Epoch: 46| Step: 0
Training loss: 3.14108819534956
Validation loss: 2.9750005320652546

Epoch: 5| Step: 1
Training loss: 3.252602635493451
Validation loss: 2.9776898392409312

Epoch: 5| Step: 2
Training loss: 3.1447256466503077
Validation loss: 2.9735560824614593

Epoch: 5| Step: 3
Training loss: 2.943528502730476
Validation loss: 2.973285469985278

Epoch: 5| Step: 4
Training loss: 3.3039539866811034
Validation loss: 2.9753302315302053

Epoch: 5| Step: 5
Training loss: 2.9607390888338063
Validation loss: 2.9754273427988585

Epoch: 5| Step: 6
Training loss: 2.774199818895956
Validation loss: 2.9744278295256055

Epoch: 5| Step: 7
Training loss: 3.429884364011166
Validation loss: 2.9726912721566765

Epoch: 5| Step: 8
Training loss: 3.687767277745711
Validation loss: 2.9728510933466863

Epoch: 5| Step: 9
Training loss: 3.6202464012463715
Validation loss: 2.9736292389932864

Epoch: 5| Step: 10
Training loss: 3.34252137045352
Validation loss: 2.9711476141558273

Epoch: 47| Step: 0
Training loss: 3.5635263403449846
Validation loss: 2.970755743532777

Epoch: 5| Step: 1
Training loss: 2.451659621386991
Validation loss: 2.971647081060801

Epoch: 5| Step: 2
Training loss: 3.6013926302554546
Validation loss: 2.9710998889383515

Epoch: 5| Step: 3
Training loss: 3.8269801082129007
Validation loss: 2.9703603917891805

Epoch: 5| Step: 4
Training loss: 3.118579983711678
Validation loss: 2.9715251401941614

Epoch: 5| Step: 5
Training loss: 2.863847080751469
Validation loss: 2.967035636434212

Epoch: 5| Step: 6
Training loss: 3.263633595395647
Validation loss: 2.9677107377360876

Epoch: 5| Step: 7
Training loss: 2.9624779551526834
Validation loss: 2.968913511513104

Epoch: 5| Step: 8
Training loss: 3.3330703313705077
Validation loss: 2.968311156915255

Epoch: 5| Step: 9
Training loss: 2.6117953650681938
Validation loss: 2.964929602818836

Epoch: 5| Step: 10
Training loss: 3.8238859411730726
Validation loss: 2.968750254744911

Epoch: 48| Step: 0
Training loss: 3.030985240581928
Validation loss: 2.9663124910956356

Epoch: 5| Step: 1
Training loss: 3.2374646453694425
Validation loss: 2.9638943792720545

Epoch: 5| Step: 2
Training loss: 3.5366894174096326
Validation loss: 2.96610686638794

Epoch: 5| Step: 3
Training loss: 3.111801504173972
Validation loss: 2.967769932090958

Epoch: 5| Step: 4
Training loss: 3.9100703974091453
Validation loss: 2.973253781328513

Epoch: 5| Step: 5
Training loss: 3.5863193815586154
Validation loss: 2.975782395590293

Epoch: 5| Step: 6
Training loss: 3.034057261118372
Validation loss: 2.9707195853273882

Epoch: 5| Step: 7
Training loss: 3.0501400399499143
Validation loss: 2.969341489872788

Epoch: 5| Step: 8
Training loss: 3.600956201720791
Validation loss: 2.9623951527626717

Epoch: 5| Step: 9
Training loss: 2.4501276839324153
Validation loss: 2.9590412582918253

Epoch: 5| Step: 10
Training loss: 2.7039835013106326
Validation loss: 2.958444065226783

Epoch: 49| Step: 0
Training loss: 2.9635014768712313
Validation loss: 2.9594059642768342

Epoch: 5| Step: 1
Training loss: 2.6693522718458302
Validation loss: 2.9591867208834985

Epoch: 5| Step: 2
Training loss: 3.2749774378807452
Validation loss: 2.9592584029934663

Epoch: 5| Step: 3
Training loss: 3.3094536070452865
Validation loss: 2.9607560461518694

Epoch: 5| Step: 4
Training loss: 2.7683556648316734
Validation loss: 2.9582406364128815

Epoch: 5| Step: 5
Training loss: 3.729628479278442
Validation loss: 2.9577524295689197

Epoch: 5| Step: 6
Training loss: 3.1870052477264053
Validation loss: 2.9551345456202593

Epoch: 5| Step: 7
Training loss: 3.460951139883887
Validation loss: 2.9545154543764167

Epoch: 5| Step: 8
Training loss: 3.2883974250106838
Validation loss: 2.954229822387255

Epoch: 5| Step: 9
Training loss: 3.499013898082168
Validation loss: 2.953421585686441

Epoch: 5| Step: 10
Training loss: 3.290494702142318
Validation loss: 2.9521478765146556

Epoch: 50| Step: 0
Training loss: 3.3884372948795387
Validation loss: 2.9542284755823642

Epoch: 5| Step: 1
Training loss: 2.8507540458202882
Validation loss: 2.953364457006457

Epoch: 5| Step: 2
Training loss: 3.2971383663042073
Validation loss: 2.951236828516731

Epoch: 5| Step: 3
Training loss: 2.998422207775947
Validation loss: 2.9539109604752474

Epoch: 5| Step: 4
Training loss: 3.5566592606166774
Validation loss: 2.9520410485466555

Epoch: 5| Step: 5
Training loss: 3.5554508269966156
Validation loss: 2.955256492235671

Epoch: 5| Step: 6
Training loss: 2.915895432731013
Validation loss: 2.9554197952422046

Epoch: 5| Step: 7
Training loss: 3.4238189331558018
Validation loss: 2.958129865994222

Epoch: 5| Step: 8
Training loss: 2.9269896432310847
Validation loss: 2.9552363890702398

Epoch: 5| Step: 9
Training loss: 3.5679865299364035
Validation loss: 2.952899247756904

Epoch: 5| Step: 10
Training loss: 2.8280512341737327
Validation loss: 2.9503853716702317

Epoch: 51| Step: 0
Training loss: 4.080085137170853
Validation loss: 2.950943182906418

Epoch: 5| Step: 1
Training loss: 3.0250124907432747
Validation loss: 2.94969880895681

Epoch: 5| Step: 2
Training loss: 2.9493694342714094
Validation loss: 2.949885072758467

Epoch: 5| Step: 3
Training loss: 3.0138133245118026
Validation loss: 2.9480719162206865

Epoch: 5| Step: 4
Training loss: 3.1276055726940966
Validation loss: 2.9497851868678344

Epoch: 5| Step: 5
Training loss: 3.173003198082842
Validation loss: 2.948288290620131

Epoch: 5| Step: 6
Training loss: 3.0267607490548443
Validation loss: 2.947106188267141

Epoch: 5| Step: 7
Training loss: 3.178742739376247
Validation loss: 2.9487729697355762

Epoch: 5| Step: 8
Training loss: 3.4876771341822
Validation loss: 2.9482221756346

Epoch: 5| Step: 9
Training loss: 3.1549465396178555
Validation loss: 2.9519858497593736

Epoch: 5| Step: 10
Training loss: 3.0527414039926275
Validation loss: 2.9539477609672673

Epoch: 52| Step: 0
Training loss: 3.260468861382504
Validation loss: 2.955810908873656

Epoch: 5| Step: 1
Training loss: 2.9988599836399583
Validation loss: 2.9476340614370558

Epoch: 5| Step: 2
Training loss: 2.779963420791929
Validation loss: 2.9515403640806332

Epoch: 5| Step: 3
Training loss: 3.512530919274919
Validation loss: 2.949295975868519

Epoch: 5| Step: 4
Training loss: 2.8661621921429923
Validation loss: 2.9492840690200377

Epoch: 5| Step: 5
Training loss: 3.6366906907651426
Validation loss: 2.9447539164251313

Epoch: 5| Step: 6
Training loss: 3.5114532811662165
Validation loss: 2.9456278418711124

Epoch: 5| Step: 7
Training loss: 3.446306219406854
Validation loss: 2.9463158021990563

Epoch: 5| Step: 8
Training loss: 2.944544684505204
Validation loss: 2.9514125015372654

Epoch: 5| Step: 9
Training loss: 2.907639530209045
Validation loss: 2.9506313822889423

Epoch: 5| Step: 10
Training loss: 3.4425954333716144
Validation loss: 2.964542313335055

Epoch: 53| Step: 0
Training loss: 2.929084084994033
Validation loss: 2.9387528168215122

Epoch: 5| Step: 1
Training loss: 3.051370131625428
Validation loss: 2.940459490983393

Epoch: 5| Step: 2
Training loss: 2.978639533795595
Validation loss: 2.9425671191376486

Epoch: 5| Step: 3
Training loss: 3.853112580092957
Validation loss: 2.940059332396439

Epoch: 5| Step: 4
Training loss: 3.445966109301227
Validation loss: 2.939559533954048

Epoch: 5| Step: 5
Training loss: 3.1560356142865404
Validation loss: 2.941431783395831

Epoch: 5| Step: 6
Training loss: 2.9966585305866915
Validation loss: 2.941392346686893

Epoch: 5| Step: 7
Training loss: 2.760964729075505
Validation loss: 2.941132967076449

Epoch: 5| Step: 8
Training loss: 3.2490453051469537
Validation loss: 2.9399609979343575

Epoch: 5| Step: 9
Training loss: 3.4245812153085433
Validation loss: 2.937099547309767

Epoch: 5| Step: 10
Training loss: 3.4940700705128696
Validation loss: 2.9386848795154665

Epoch: 54| Step: 0
Training loss: 3.1666234331358627
Validation loss: 2.9405375275289924

Epoch: 5| Step: 1
Training loss: 2.453939800646408
Validation loss: 2.9423822627219813

Epoch: 5| Step: 2
Training loss: 2.711315733278528
Validation loss: 2.9381185581595535

Epoch: 5| Step: 3
Training loss: 3.3996121185302184
Validation loss: 2.948125192596722

Epoch: 5| Step: 4
Training loss: 3.5707824531292416
Validation loss: 2.946682410316669

Epoch: 5| Step: 5
Training loss: 3.023152340396062
Validation loss: 2.9466430238695756

Epoch: 5| Step: 6
Training loss: 3.2186814087901747
Validation loss: 2.946110655309494

Epoch: 5| Step: 7
Training loss: 3.269538979652228
Validation loss: 2.947321234893282

Epoch: 5| Step: 8
Training loss: 3.559117501634625
Validation loss: 2.949719359214852

Epoch: 5| Step: 9
Training loss: 2.823672335410692
Validation loss: 2.9424832154040432

Epoch: 5| Step: 10
Training loss: 4.039156707904602
Validation loss: 2.943128184776123

Epoch: 55| Step: 0
Training loss: 2.9821948331638595
Validation loss: 2.93195064514727

Epoch: 5| Step: 1
Training loss: 3.1734245536686623
Validation loss: 2.9339745022406296

Epoch: 5| Step: 2
Training loss: 3.1949452233432067
Validation loss: 2.9372386305547615

Epoch: 5| Step: 3
Training loss: 3.6459848136313555
Validation loss: 2.939062378092275

Epoch: 5| Step: 4
Training loss: 3.2239932714160155
Validation loss: 2.947956502510406

Epoch: 5| Step: 5
Training loss: 3.398498113683593
Validation loss: 2.949178509898471

Epoch: 5| Step: 6
Training loss: 2.9765762769325197
Validation loss: 2.939391606465619

Epoch: 5| Step: 7
Training loss: 3.1624478965357237
Validation loss: 2.9343807037241123

Epoch: 5| Step: 8
Training loss: 3.2973409748269074
Validation loss: 2.9316405812763486

Epoch: 5| Step: 9
Training loss: 2.933218575169058
Validation loss: 2.9294265458027713

Epoch: 5| Step: 10
Training loss: 3.4128611391009094
Validation loss: 2.929879466996997

Epoch: 56| Step: 0
Training loss: 3.3014292425152716
Validation loss: 2.930357864962512

Epoch: 5| Step: 1
Training loss: 2.8924548156954577
Validation loss: 2.9314736072634675

Epoch: 5| Step: 2
Training loss: 3.3806228422728224
Validation loss: 2.933924591650568

Epoch: 5| Step: 3
Training loss: 3.9819200320220465
Validation loss: 2.9317330990635555

Epoch: 5| Step: 4
Training loss: 2.776256922713661
Validation loss: 2.936712361455693

Epoch: 5| Step: 5
Training loss: 3.1858417461050363
Validation loss: 2.9376763435098336

Epoch: 5| Step: 6
Training loss: 3.1243932516439044
Validation loss: 2.9302733246753405

Epoch: 5| Step: 7
Training loss: 3.312726139050899
Validation loss: 2.924328762353643

Epoch: 5| Step: 8
Training loss: 2.886528122405952
Validation loss: 2.926056571256063

Epoch: 5| Step: 9
Training loss: 3.1952680290876945
Validation loss: 2.9238354595032954

Epoch: 5| Step: 10
Training loss: 3.1203173840312144
Validation loss: 2.924516862013004

Epoch: 57| Step: 0
Training loss: 3.4694459234240798
Validation loss: 2.923842348571105

Epoch: 5| Step: 1
Training loss: 3.746242420798556
Validation loss: 2.923269032635622

Epoch: 5| Step: 2
Training loss: 2.9177553234154736
Validation loss: 2.9218514892095495

Epoch: 5| Step: 3
Training loss: 2.5282431745788787
Validation loss: 2.9219599534835083

Epoch: 5| Step: 4
Training loss: 3.163014933162224
Validation loss: 2.9219188124270783

Epoch: 5| Step: 5
Training loss: 3.049456006925069
Validation loss: 2.921144380198615

Epoch: 5| Step: 6
Training loss: 3.5664765767812763
Validation loss: 2.9219031519836283

Epoch: 5| Step: 7
Training loss: 3.4355689433540078
Validation loss: 2.9208309863160973

Epoch: 5| Step: 8
Training loss: 3.2413807060465394
Validation loss: 2.918831770238246

Epoch: 5| Step: 9
Training loss: 2.7950265412955617
Validation loss: 2.919278248077007

Epoch: 5| Step: 10
Training loss: 3.1675242383792765
Validation loss: 2.9181785169298804

Epoch: 58| Step: 0
Training loss: 2.765201255965365
Validation loss: 2.918220957300745

Epoch: 5| Step: 1
Training loss: 2.6772697373938876
Validation loss: 2.918879068632878

Epoch: 5| Step: 2
Training loss: 3.340906092466048
Validation loss: 2.942656431503606

Epoch: 5| Step: 3
Training loss: 2.7828951481193154
Validation loss: 2.9759648732174124

Epoch: 5| Step: 4
Training loss: 3.6487864423436807
Validation loss: 2.9728045105140852

Epoch: 5| Step: 5
Training loss: 3.3356686200096513
Validation loss: 2.927519395793997

Epoch: 5| Step: 6
Training loss: 3.614327999774455
Validation loss: 2.9168534642419424

Epoch: 5| Step: 7
Training loss: 3.036621054492784
Validation loss: 2.913754121454552

Epoch: 5| Step: 8
Training loss: 3.663234462589758
Validation loss: 2.918722286779217

Epoch: 5| Step: 9
Training loss: 2.7632503336308556
Validation loss: 2.922568548143478

Epoch: 5| Step: 10
Training loss: 3.4585532765748654
Validation loss: 2.923261038976441

Epoch: 59| Step: 0
Training loss: 3.7465893812342377
Validation loss: 2.9206908882576865

Epoch: 5| Step: 1
Training loss: 3.1903844012224414
Validation loss: 2.920047274563796

Epoch: 5| Step: 2
Training loss: 3.659498157595095
Validation loss: 2.9174111358110837

Epoch: 5| Step: 3
Training loss: 3.4005295902014216
Validation loss: 2.9144463175700457

Epoch: 5| Step: 4
Training loss: 2.8132058847253814
Validation loss: 2.9124436307315658

Epoch: 5| Step: 5
Training loss: 2.887223505430866
Validation loss: 2.9134590350819787

Epoch: 5| Step: 6
Training loss: 3.2710106350088224
Validation loss: 2.9123727109337194

Epoch: 5| Step: 7
Training loss: 2.884706944699811
Validation loss: 2.9113529572293744

Epoch: 5| Step: 8
Training loss: 3.0328398006100734
Validation loss: 2.909267401509485

Epoch: 5| Step: 9
Training loss: 2.9158033637372474
Validation loss: 2.909584771453153

Epoch: 5| Step: 10
Training loss: 3.2253210159335697
Validation loss: 2.9118427691495143

Epoch: 60| Step: 0
Training loss: 2.64608218807446
Validation loss: 2.9103964191775717

Epoch: 5| Step: 1
Training loss: 3.608920510481848
Validation loss: 2.9105846441262817

Epoch: 5| Step: 2
Training loss: 3.1783669468729707
Validation loss: 2.909243179919041

Epoch: 5| Step: 3
Training loss: 2.9870167169757647
Validation loss: 2.907678805766857

Epoch: 5| Step: 4
Training loss: 3.3006726128572073
Validation loss: 2.9078523706472152

Epoch: 5| Step: 5
Training loss: 3.008731533195139
Validation loss: 2.907078450575053

Epoch: 5| Step: 6
Training loss: 3.6512393362796556
Validation loss: 2.9072711309328487

Epoch: 5| Step: 7
Training loss: 3.029928804322824
Validation loss: 2.9062390053239318

Epoch: 5| Step: 8
Training loss: 3.308016207571121
Validation loss: 2.905396523064423

Epoch: 5| Step: 9
Training loss: 3.2471277309303006
Validation loss: 2.9139078837073757

Epoch: 5| Step: 10
Training loss: 2.9902713706071973
Validation loss: 2.9077504360493798

Epoch: 61| Step: 0
Training loss: 2.967143698354458
Validation loss: 2.911874517752821

Epoch: 5| Step: 1
Training loss: 3.2423844243189173
Validation loss: 2.9081749267859505

Epoch: 5| Step: 2
Training loss: 3.815941679838761
Validation loss: 2.9157641729992623

Epoch: 5| Step: 3
Training loss: 3.058954950784692
Validation loss: 2.908904415168155

Epoch: 5| Step: 4
Training loss: 3.220867756556393
Validation loss: 2.9046920241748757

Epoch: 5| Step: 5
Training loss: 2.870783159752297
Validation loss: 2.903433633131444

Epoch: 5| Step: 6
Training loss: 2.8093289618703285
Validation loss: 2.9027387371526667

Epoch: 5| Step: 7
Training loss: 2.953836345274241
Validation loss: 2.9012461595171914

Epoch: 5| Step: 8
Training loss: 3.2377692210074853
Validation loss: 2.901711723216392

Epoch: 5| Step: 9
Training loss: 3.4738892296242994
Validation loss: 2.8992622921626587

Epoch: 5| Step: 10
Training loss: 3.261435417615435
Validation loss: 2.9001567900029923

Epoch: 62| Step: 0
Training loss: 3.3618980691447704
Validation loss: 2.898830756746539

Epoch: 5| Step: 1
Training loss: 3.0398969509829135
Validation loss: 2.899053770509474

Epoch: 5| Step: 2
Training loss: 3.1283340978714653
Validation loss: 2.89756201930424

Epoch: 5| Step: 3
Training loss: 3.154075251018421
Validation loss: 2.8966401956837147

Epoch: 5| Step: 4
Training loss: 3.846578658191878
Validation loss: 2.895989176948534

Epoch: 5| Step: 5
Training loss: 3.4213756736946204
Validation loss: 2.8962909203868703

Epoch: 5| Step: 6
Training loss: 3.006789630509776
Validation loss: 2.896170856680218

Epoch: 5| Step: 7
Training loss: 2.816575551863551
Validation loss: 2.8948580720520436

Epoch: 5| Step: 8
Training loss: 3.067853957618165
Validation loss: 2.893932048293098

Epoch: 5| Step: 9
Training loss: 2.7966555717105717
Validation loss: 2.894748415165528

Epoch: 5| Step: 10
Training loss: 3.2354094836631635
Validation loss: 2.8937539515342854

Epoch: 63| Step: 0
Training loss: 3.0072017693679043
Validation loss: 2.894088128639857

Epoch: 5| Step: 1
Training loss: 3.57437483649963
Validation loss: 2.8954589175582557

Epoch: 5| Step: 2
Training loss: 2.4901235997113877
Validation loss: 2.8941154737686237

Epoch: 5| Step: 3
Training loss: 3.254808390144522
Validation loss: 2.894018804435998

Epoch: 5| Step: 4
Training loss: 3.3515462808283254
Validation loss: 2.892802939480761

Epoch: 5| Step: 5
Training loss: 3.0689204897010502
Validation loss: 2.8925247969057137

Epoch: 5| Step: 6
Training loss: 3.6188474599202696
Validation loss: 2.8908962292123808

Epoch: 5| Step: 7
Training loss: 3.386166220607604
Validation loss: 2.8906091620342003

Epoch: 5| Step: 8
Training loss: 3.251028485053972
Validation loss: 2.890616055790423

Epoch: 5| Step: 9
Training loss: 2.816991060150012
Validation loss: 2.890506614027912

Epoch: 5| Step: 10
Training loss: 2.903404237193089
Validation loss: 2.8906584565084246

Epoch: 64| Step: 0
Training loss: 3.413178143872523
Validation loss: 2.8898638635854854

Epoch: 5| Step: 1
Training loss: 3.466641309229715
Validation loss: 2.89168778304481

Epoch: 5| Step: 2
Training loss: 3.0279173473733416
Validation loss: 2.8929804762465645

Epoch: 5| Step: 3
Training loss: 3.2627901613252455
Validation loss: 2.889394449539145

Epoch: 5| Step: 4
Training loss: 2.4517629936514203
Validation loss: 2.889871365017422

Epoch: 5| Step: 5
Training loss: 2.6676553343831255
Validation loss: 2.8958935483838193

Epoch: 5| Step: 6
Training loss: 2.993962570639394
Validation loss: 2.9036853208008484

Epoch: 5| Step: 7
Training loss: 3.5835757654078497
Validation loss: 2.916385859201663

Epoch: 5| Step: 8
Training loss: 3.3214500004652816
Validation loss: 2.9232245055271475

Epoch: 5| Step: 9
Training loss: 2.973588714523185
Validation loss: 2.912186790897497

Epoch: 5| Step: 10
Training loss: 3.6408437245689904
Validation loss: 2.888889651013135

Epoch: 65| Step: 0
Training loss: 3.037704360429446
Validation loss: 2.884509061626619

Epoch: 5| Step: 1
Training loss: 3.7779098765022368
Validation loss: 2.885669496526213

Epoch: 5| Step: 2
Training loss: 3.5677646753173593
Validation loss: 2.8842903051268416

Epoch: 5| Step: 3
Training loss: 3.4191875617101384
Validation loss: 2.883664531015039

Epoch: 5| Step: 4
Training loss: 3.023668068465326
Validation loss: 2.8833884907580596

Epoch: 5| Step: 5
Training loss: 3.3899189438033237
Validation loss: 2.8848044201722804

Epoch: 5| Step: 6
Training loss: 2.5031918177455403
Validation loss: 2.88303058167438

Epoch: 5| Step: 7
Training loss: 2.955487310566554
Validation loss: 2.8826389615669163

Epoch: 5| Step: 8
Training loss: 3.0427089281526687
Validation loss: 2.8822087637454468

Epoch: 5| Step: 9
Training loss: 3.0126087343212027
Validation loss: 2.8808527239734367

Epoch: 5| Step: 10
Training loss: 2.928055860747405
Validation loss: 2.8820353063762982

Epoch: 66| Step: 0
Training loss: 3.4636002538023423
Validation loss: 2.8811232278976653

Epoch: 5| Step: 1
Training loss: 2.8235924581660172
Validation loss: 2.8835280167080852

Epoch: 5| Step: 2
Training loss: 3.137798042883315
Validation loss: 2.8858282330947267

Epoch: 5| Step: 3
Training loss: 2.8093096121879033
Validation loss: 2.8862976835489627

Epoch: 5| Step: 4
Training loss: 2.9991652598955847
Validation loss: 2.8820429616128456

Epoch: 5| Step: 5
Training loss: 3.14005437573045
Validation loss: 2.884299352502224

Epoch: 5| Step: 6
Training loss: 3.291541680647081
Validation loss: 2.887880314778932

Epoch: 5| Step: 7
Training loss: 3.2017097137697474
Validation loss: 2.8788482713161647

Epoch: 5| Step: 8
Training loss: 3.6100160764299263
Validation loss: 2.8788040376074187

Epoch: 5| Step: 9
Training loss: 2.9026471848342963
Validation loss: 2.8763200467826078

Epoch: 5| Step: 10
Training loss: 3.385163580408706
Validation loss: 2.876108785919603

Epoch: 67| Step: 0
Training loss: 3.467329129476211
Validation loss: 2.874206472693061

Epoch: 5| Step: 1
Training loss: 2.9127285847170072
Validation loss: 2.87326777323607

Epoch: 5| Step: 2
Training loss: 3.3570846912017824
Validation loss: 2.8733289284086223

Epoch: 5| Step: 3
Training loss: 2.6658147603475406
Validation loss: 2.8741669359661537

Epoch: 5| Step: 4
Training loss: 3.593502401032395
Validation loss: 2.8764527169722602

Epoch: 5| Step: 5
Training loss: 2.9745923828922094
Validation loss: 2.876675487165377

Epoch: 5| Step: 6
Training loss: 2.5587316577814883
Validation loss: 2.8754726590284263

Epoch: 5| Step: 7
Training loss: 2.607891277679867
Validation loss: 2.874940301775581

Epoch: 5| Step: 8
Training loss: 3.4017351659531383
Validation loss: 2.8727201398960625

Epoch: 5| Step: 9
Training loss: 3.4369051331875964
Validation loss: 2.8696714960129572

Epoch: 5| Step: 10
Training loss: 3.645366936778761
Validation loss: 2.8698255557299706

Epoch: 68| Step: 0
Training loss: 2.849480692080326
Validation loss: 2.870308362856561

Epoch: 5| Step: 1
Training loss: 3.143491888352224
Validation loss: 2.8681754471437158

Epoch: 5| Step: 2
Training loss: 3.669860417052923
Validation loss: 2.8668841107349783

Epoch: 5| Step: 3
Training loss: 3.2617605606414544
Validation loss: 2.869231720815315

Epoch: 5| Step: 4
Training loss: 2.9775565182232673
Validation loss: 2.8675573467610405

Epoch: 5| Step: 5
Training loss: 2.7767766059582417
Validation loss: 2.866301852737074

Epoch: 5| Step: 6
Training loss: 3.2463527167590533
Validation loss: 2.865844721502703

Epoch: 5| Step: 7
Training loss: 3.7733913758422624
Validation loss: 2.8733407395885555

Epoch: 5| Step: 8
Training loss: 3.4977946826839212
Validation loss: 2.880683226180534

Epoch: 5| Step: 9
Training loss: 2.7686053236110135
Validation loss: 2.8728656648772213

Epoch: 5| Step: 10
Training loss: 2.4742002562978125
Validation loss: 2.867107488483645

Epoch: 69| Step: 0
Training loss: 3.388143730231429
Validation loss: 2.8689815825884915

Epoch: 5| Step: 1
Training loss: 3.1096272581895548
Validation loss: 2.8650963150365625

Epoch: 5| Step: 2
Training loss: 3.321487470183713
Validation loss: 2.881413670839748

Epoch: 5| Step: 3
Training loss: 3.3443728428382595
Validation loss: 2.881839897933735

Epoch: 5| Step: 4
Training loss: 3.209102653975095
Validation loss: 2.861837537856265

Epoch: 5| Step: 5
Training loss: 2.9688079828322045
Validation loss: 2.863387366779487

Epoch: 5| Step: 6
Training loss: 3.0548897990877366
Validation loss: 2.8631806412649317

Epoch: 5| Step: 7
Training loss: 2.991143186314416
Validation loss: 2.864169097811236

Epoch: 5| Step: 8
Training loss: 2.993275576532002
Validation loss: 2.8664552671701817

Epoch: 5| Step: 9
Training loss: 3.3414999263066467
Validation loss: 2.8724987550926246

Epoch: 5| Step: 10
Training loss: 2.861755880728863
Validation loss: 2.8857219252183772

Epoch: 70| Step: 0
Training loss: 3.4559223702683615
Validation loss: 2.8944340436395835

Epoch: 5| Step: 1
Training loss: 2.750405975199273
Validation loss: 2.8736043871408223

Epoch: 5| Step: 2
Training loss: 3.50301408413455
Validation loss: 2.870165654891584

Epoch: 5| Step: 3
Training loss: 3.626704768817497
Validation loss: 2.872000662136684

Epoch: 5| Step: 4
Training loss: 2.5622225355332113
Validation loss: 2.875800778730398

Epoch: 5| Step: 5
Training loss: 2.9270828265170454
Validation loss: 2.8718374298579397

Epoch: 5| Step: 6
Training loss: 3.0570262336641054
Validation loss: 2.8693002384596076

Epoch: 5| Step: 7
Training loss: 3.4896133801129854
Validation loss: 2.870074348439976

Epoch: 5| Step: 8
Training loss: 2.9143910567961866
Validation loss: 2.866041843070242

Epoch: 5| Step: 9
Training loss: 2.776936905003666
Validation loss: 2.8648896573562044

Epoch: 5| Step: 10
Training loss: 3.4896054547116386
Validation loss: 2.873060675391211

Epoch: 71| Step: 0
Training loss: 3.3742656615295776
Validation loss: 2.8706076536355565

Epoch: 5| Step: 1
Training loss: 2.619193330443553
Validation loss: 2.884057761219399

Epoch: 5| Step: 2
Training loss: 3.2459389182576386
Validation loss: 2.904453141557264

Epoch: 5| Step: 3
Training loss: 3.5507874273701767
Validation loss: 2.872546419245391

Epoch: 5| Step: 4
Training loss: 2.970021989272176
Validation loss: 2.853674449533527

Epoch: 5| Step: 5
Training loss: 3.6259046280822447
Validation loss: 2.857852034627606

Epoch: 5| Step: 6
Training loss: 3.6436774428195497
Validation loss: 2.863451395585359

Epoch: 5| Step: 7
Training loss: 2.8506931599717236
Validation loss: 2.8689789751452026

Epoch: 5| Step: 8
Training loss: 2.6872009288364906
Validation loss: 2.8733623828832275

Epoch: 5| Step: 9
Training loss: 3.170171872362346
Validation loss: 2.8840966272467616

Epoch: 5| Step: 10
Training loss: 2.8891355233998284
Validation loss: 2.891255419453107

Epoch: 72| Step: 0
Training loss: 3.6708553115816067
Validation loss: 2.885839055906333

Epoch: 5| Step: 1
Training loss: 2.637061067188722
Validation loss: 2.8737877924734883

Epoch: 5| Step: 2
Training loss: 3.2583370381079746
Validation loss: 2.869175626728803

Epoch: 5| Step: 3
Training loss: 2.610498700345981
Validation loss: 2.862653603099802

Epoch: 5| Step: 4
Training loss: 3.396267463378038
Validation loss: 2.8584347322128796

Epoch: 5| Step: 5
Training loss: 3.0378994714353804
Validation loss: 2.8544136738689128

Epoch: 5| Step: 6
Training loss: 3.1498883787693264
Validation loss: 2.857353574058905

Epoch: 5| Step: 7
Training loss: 3.5237051783888083
Validation loss: 2.8583219864191127

Epoch: 5| Step: 8
Training loss: 3.1584419721641743
Validation loss: 2.8648864654317903

Epoch: 5| Step: 9
Training loss: 2.960664681218435
Validation loss: 2.890613609763788

Epoch: 5| Step: 10
Training loss: 3.2114691004210183
Validation loss: 2.908180723715104

Epoch: 73| Step: 0
Training loss: 2.8209422245917875
Validation loss: 2.89922592849217

Epoch: 5| Step: 1
Training loss: 3.3717389776672375
Validation loss: 2.881218365270539

Epoch: 5| Step: 2
Training loss: 3.667395013660004
Validation loss: 2.885381002188337

Epoch: 5| Step: 3
Training loss: 3.3244448090732712
Validation loss: 2.8550505931438743

Epoch: 5| Step: 4
Training loss: 3.449338882790805
Validation loss: 2.8491944998803094

Epoch: 5| Step: 5
Training loss: 3.4185922980330514
Validation loss: 2.8464064641924893

Epoch: 5| Step: 6
Training loss: 2.4549813020075706
Validation loss: 2.8476446635867516

Epoch: 5| Step: 7
Training loss: 2.6724772527456375
Validation loss: 2.8470772470627597

Epoch: 5| Step: 8
Training loss: 3.3531422126662416
Validation loss: 2.8504974826248533

Epoch: 5| Step: 9
Training loss: 3.1564909588076864
Validation loss: 2.8558537295366806

Epoch: 5| Step: 10
Training loss: 2.7460342769775643
Validation loss: 2.8704740550736814

Epoch: 74| Step: 0
Training loss: 4.08335967282474
Validation loss: 2.897240927326829

Epoch: 5| Step: 1
Training loss: 2.9673354141626866
Validation loss: 2.8531295752069985

Epoch: 5| Step: 2
Training loss: 2.304971761468455
Validation loss: 2.847821002434926

Epoch: 5| Step: 3
Training loss: 3.303270978778569
Validation loss: 2.8454503291907884

Epoch: 5| Step: 4
Training loss: 2.857730246518246
Validation loss: 2.8434787509544415

Epoch: 5| Step: 5
Training loss: 3.7344396098784487
Validation loss: 2.8405019752195546

Epoch: 5| Step: 6
Training loss: 3.642325597605487
Validation loss: 2.8383480828257572

Epoch: 5| Step: 7
Training loss: 2.696811867126364
Validation loss: 2.8403937118744453

Epoch: 5| Step: 8
Training loss: 2.6465259056070227
Validation loss: 2.844660107032976

Epoch: 5| Step: 9
Training loss: 2.9994092995522026
Validation loss: 2.8748587314590757

Epoch: 5| Step: 10
Training loss: 3.0584180447715896
Validation loss: 2.871754734079015

Epoch: 75| Step: 0
Training loss: 2.592789437627185
Validation loss: 2.851912684900783

Epoch: 5| Step: 1
Training loss: 3.3627678349689645
Validation loss: 2.8417764401135455

Epoch: 5| Step: 2
Training loss: 2.6116670147526975
Validation loss: 2.838037968440698

Epoch: 5| Step: 3
Training loss: 2.629767856288138
Validation loss: 2.8383405572223186

Epoch: 5| Step: 4
Training loss: 3.1709739269578954
Validation loss: 2.8381589973465866

Epoch: 5| Step: 5
Training loss: 3.442957620449095
Validation loss: 2.840544543670213

Epoch: 5| Step: 6
Training loss: 3.2798967749937282
Validation loss: 2.8414599115508357

Epoch: 5| Step: 7
Training loss: 3.720202250571365
Validation loss: 2.8435468388156186

Epoch: 5| Step: 8
Training loss: 3.06592057384873
Validation loss: 2.8447308377446565

Epoch: 5| Step: 9
Training loss: 3.6172389115373136
Validation loss: 2.844445065315411

Epoch: 5| Step: 10
Training loss: 2.7766247125717425
Validation loss: 2.84494592544554

Epoch: 76| Step: 0
Training loss: 3.5372723563448467
Validation loss: 2.8452967390732695

Epoch: 5| Step: 1
Training loss: 3.2772152753889507
Validation loss: 2.8440944467984983

Epoch: 5| Step: 2
Training loss: 3.6918937240133523
Validation loss: 2.843792480165888

Epoch: 5| Step: 3
Training loss: 2.8472560187921023
Validation loss: 2.841491473065493

Epoch: 5| Step: 4
Training loss: 2.885112392940258
Validation loss: 2.8394974612821575

Epoch: 5| Step: 5
Training loss: 2.938414411055499
Validation loss: 2.838694531623134

Epoch: 5| Step: 6
Training loss: 2.9227371983660952
Validation loss: 2.83689031931482

Epoch: 5| Step: 7
Training loss: 3.0677019431150727
Validation loss: 2.837933322051835

Epoch: 5| Step: 8
Training loss: 3.5310482541408703
Validation loss: 2.8341182300784373

Epoch: 5| Step: 9
Training loss: 2.9291311320667726
Validation loss: 2.8342685320251593

Epoch: 5| Step: 10
Training loss: 2.7047880492315604
Validation loss: 2.8335449735677067

Epoch: 77| Step: 0
Training loss: 3.5432719612967087
Validation loss: 2.834078958170812

Epoch: 5| Step: 1
Training loss: 3.073028217597011
Validation loss: 2.831684138065788

Epoch: 5| Step: 2
Training loss: 3.318648192717385
Validation loss: 2.8305141954018267

Epoch: 5| Step: 3
Training loss: 3.457811308531765
Validation loss: 2.8306365205081128

Epoch: 5| Step: 4
Training loss: 2.620897447765109
Validation loss: 2.8298320297101442

Epoch: 5| Step: 5
Training loss: 2.557770062131243
Validation loss: 2.830997014715158

Epoch: 5| Step: 6
Training loss: 2.981912765567611
Validation loss: 2.8297064653982322

Epoch: 5| Step: 7
Training loss: 3.4299936353440916
Validation loss: 2.829891255421983

Epoch: 5| Step: 8
Training loss: 2.6536851055819346
Validation loss: 2.8314592224338107

Epoch: 5| Step: 9
Training loss: 3.1467059274691884
Validation loss: 2.8287777013523767

Epoch: 5| Step: 10
Training loss: 3.5213868798899854
Validation loss: 2.826755476493108

Epoch: 78| Step: 0
Training loss: 3.703015547152895
Validation loss: 2.8264766284196385

Epoch: 5| Step: 1
Training loss: 3.0830429215315602
Validation loss: 2.829283083827646

Epoch: 5| Step: 2
Training loss: 2.8881923027261975
Validation loss: 2.830894660921384

Epoch: 5| Step: 3
Training loss: 3.367077606602901
Validation loss: 2.839637303905731

Epoch: 5| Step: 4
Training loss: 3.062073502717948
Validation loss: 2.8453561960977845

Epoch: 5| Step: 5
Training loss: 2.9969627582322333
Validation loss: 2.8486687474665797

Epoch: 5| Step: 6
Training loss: 3.198309129786058
Validation loss: 2.8449077708236667

Epoch: 5| Step: 7
Training loss: 2.7238870955440206
Validation loss: 2.8303611543245593

Epoch: 5| Step: 8
Training loss: 3.0046749247636453
Validation loss: 2.8245464630610644

Epoch: 5| Step: 9
Training loss: 3.5551438258783095
Validation loss: 2.823880661317068

Epoch: 5| Step: 10
Training loss: 2.622431452085303
Validation loss: 2.8226166608009824

Epoch: 79| Step: 0
Training loss: 2.9916813275359635
Validation loss: 2.8221750725098294

Epoch: 5| Step: 1
Training loss: 2.8063302927063796
Validation loss: 2.8230771376089834

Epoch: 5| Step: 2
Training loss: 2.761000220078042
Validation loss: 2.82264987983699

Epoch: 5| Step: 3
Training loss: 3.186577158459592
Validation loss: 2.820949382203118

Epoch: 5| Step: 4
Training loss: 3.1375368032538615
Validation loss: 2.8228490332703666

Epoch: 5| Step: 5
Training loss: 3.767921095959412
Validation loss: 2.823987395323647

Epoch: 5| Step: 6
Training loss: 2.5490007013235405
Validation loss: 2.830996035803491

Epoch: 5| Step: 7
Training loss: 3.0340825640232763
Validation loss: 2.845841349261034

Epoch: 5| Step: 8
Training loss: 3.0945498270672824
Validation loss: 2.856741192651645

Epoch: 5| Step: 9
Training loss: 3.6098752686569697
Validation loss: 2.8458964133219666

Epoch: 5| Step: 10
Training loss: 3.330423626917303
Validation loss: 2.8335219684784407

Epoch: 80| Step: 0
Training loss: 3.4872323538511303
Validation loss: 2.8206785153876406

Epoch: 5| Step: 1
Training loss: 2.6217912408228314
Validation loss: 2.818497785085572

Epoch: 5| Step: 2
Training loss: 2.6800147209901892
Validation loss: 2.8168372124508845

Epoch: 5| Step: 3
Training loss: 3.6911144322898335
Validation loss: 2.8206577684504466

Epoch: 5| Step: 4
Training loss: 2.891140618603337
Validation loss: 2.8199390105784863

Epoch: 5| Step: 5
Training loss: 3.668739570979773
Validation loss: 2.819205339868464

Epoch: 5| Step: 6
Training loss: 3.1961277898608955
Validation loss: 2.8205678023955607

Epoch: 5| Step: 7
Training loss: 3.076701033356544
Validation loss: 2.819750723543133

Epoch: 5| Step: 8
Training loss: 3.105834325229523
Validation loss: 2.8196917103380796

Epoch: 5| Step: 9
Training loss: 2.6430749306364243
Validation loss: 2.8209180834234058

Epoch: 5| Step: 10
Training loss: 3.0241403477409037
Validation loss: 2.8211338852691914

Epoch: 81| Step: 0
Training loss: 3.121306258165511
Validation loss: 2.8205612673292855

Epoch: 5| Step: 1
Training loss: 3.34977592743725
Validation loss: 2.8203401386660043

Epoch: 5| Step: 2
Training loss: 3.193916444864346
Validation loss: 2.8219398074006286

Epoch: 5| Step: 3
Training loss: 3.1296812471659643
Validation loss: 2.820978882166524

Epoch: 5| Step: 4
Training loss: 2.893513818581614
Validation loss: 2.819541826083053

Epoch: 5| Step: 5
Training loss: 3.435211251993856
Validation loss: 2.8196299100744997

Epoch: 5| Step: 6
Training loss: 3.1807970365299414
Validation loss: 2.8193448050435332

Epoch: 5| Step: 7
Training loss: 3.0292184845394026
Validation loss: 2.818707442962247

Epoch: 5| Step: 8
Training loss: 3.119387966183324
Validation loss: 2.81654663382345

Epoch: 5| Step: 9
Training loss: 2.8616039156231365
Validation loss: 2.81516610027989

Epoch: 5| Step: 10
Training loss: 3.009254486427978
Validation loss: 2.8137366252649136

Epoch: 82| Step: 0
Training loss: 3.4830809786219006
Validation loss: 2.81615816433757

Epoch: 5| Step: 1
Training loss: 2.651401717661888
Validation loss: 2.8133035275351475

Epoch: 5| Step: 2
Training loss: 3.53191848774013
Validation loss: 2.8176287195001666

Epoch: 5| Step: 3
Training loss: 2.7689711161684754
Validation loss: 2.824358207245836

Epoch: 5| Step: 4
Training loss: 3.3639559008217303
Validation loss: 2.834049268012234

Epoch: 5| Step: 5
Training loss: 3.218752666583392
Validation loss: 2.841498551847732

Epoch: 5| Step: 6
Training loss: 3.5833550090282067
Validation loss: 2.838495772819485

Epoch: 5| Step: 7
Training loss: 2.6906481202446964
Validation loss: 2.829030014213336

Epoch: 5| Step: 8
Training loss: 3.1503385573812612
Validation loss: 2.8165963070256077

Epoch: 5| Step: 9
Training loss: 2.779569053592255
Validation loss: 2.812573933968395

Epoch: 5| Step: 10
Training loss: 2.8945108225072036
Validation loss: 2.811402109993343

Epoch: 83| Step: 0
Training loss: 3.0186534163225787
Validation loss: 2.8112525497851957

Epoch: 5| Step: 1
Training loss: 3.7342397753122287
Validation loss: 2.8122604158689755

Epoch: 5| Step: 2
Training loss: 3.1096231179467626
Validation loss: 2.8110539153999814

Epoch: 5| Step: 3
Training loss: 2.585866967475362
Validation loss: 2.8137425402241756

Epoch: 5| Step: 4
Training loss: 3.2982167772308317
Validation loss: 2.8118462617453583

Epoch: 5| Step: 5
Training loss: 3.3684187405979853
Validation loss: 2.811024412511647

Epoch: 5| Step: 6
Training loss: 2.911769261189443
Validation loss: 2.8115595030103715

Epoch: 5| Step: 7
Training loss: 3.0183738079197444
Validation loss: 2.810393646023596

Epoch: 5| Step: 8
Training loss: 2.6964065763790854
Validation loss: 2.8093590382980294

Epoch: 5| Step: 9
Training loss: 2.9118642416004272
Validation loss: 2.8080686253183065

Epoch: 5| Step: 10
Training loss: 3.536745504518654
Validation loss: 2.807404410254818

Epoch: 84| Step: 0
Training loss: 3.0415615603607082
Validation loss: 2.805081170792776

Epoch: 5| Step: 1
Training loss: 2.9022259489362985
Validation loss: 2.8057822629284304

Epoch: 5| Step: 2
Training loss: 3.6222271014949747
Validation loss: 2.805585423316007

Epoch: 5| Step: 3
Training loss: 3.381020157030433
Validation loss: 2.8023762334665165

Epoch: 5| Step: 4
Training loss: 3.206950513076676
Validation loss: 2.801322926850632

Epoch: 5| Step: 5
Training loss: 2.9856174938290416
Validation loss: 2.8012531327104555

Epoch: 5| Step: 6
Training loss: 2.967376391207345
Validation loss: 2.8019613183082948

Epoch: 5| Step: 7
Training loss: 2.8399256887250535
Validation loss: 2.799618104814667

Epoch: 5| Step: 8
Training loss: 3.196559373595062
Validation loss: 2.7990414690177534

Epoch: 5| Step: 9
Training loss: 3.0693101484360423
Validation loss: 2.7994457691410695

Epoch: 5| Step: 10
Training loss: 2.8458190768672766
Validation loss: 2.802548566400729

Epoch: 85| Step: 0
Training loss: 2.3532856555824284
Validation loss: 2.8072758218578864

Epoch: 5| Step: 1
Training loss: 3.8614840902919227
Validation loss: 2.8193218177525297

Epoch: 5| Step: 2
Training loss: 2.532506842646341
Validation loss: 2.7981709992647006

Epoch: 5| Step: 3
Training loss: 2.778782382077989
Validation loss: 2.78963996155609

Epoch: 5| Step: 4
Training loss: 2.858841309484054
Validation loss: 2.787184468142691

Epoch: 5| Step: 5
Training loss: 2.7187946359763044
Validation loss: 2.78530872648263

Epoch: 5| Step: 6
Training loss: 3.5630611847691713
Validation loss: 2.784426302410927

Epoch: 5| Step: 7
Training loss: 3.255236881385234
Validation loss: 2.7810572923498085

Epoch: 5| Step: 8
Training loss: 3.184222462363353
Validation loss: 2.7795590713497256

Epoch: 5| Step: 9
Training loss: 3.177323946153629
Validation loss: 2.7782652812361848

Epoch: 5| Step: 10
Training loss: 3.5244702096611715
Validation loss: 2.776887198157884

Epoch: 86| Step: 0
Training loss: 2.876338149754545
Validation loss: 2.7759530762989297

Epoch: 5| Step: 1
Training loss: 3.4816322650978115
Validation loss: 2.776503814760889

Epoch: 5| Step: 2
Training loss: 3.1431130949057757
Validation loss: 2.775833207632527

Epoch: 5| Step: 3
Training loss: 3.1358022526655387
Validation loss: 2.7719736897623144

Epoch: 5| Step: 4
Training loss: 3.0751442976178978
Validation loss: 2.775200114581981

Epoch: 5| Step: 5
Training loss: 2.8919189856065337
Validation loss: 2.772128918474261

Epoch: 5| Step: 6
Training loss: 3.1407160959269853
Validation loss: 2.7722971476991733

Epoch: 5| Step: 7
Training loss: 2.8963386771662463
Validation loss: 2.774299816827758

Epoch: 5| Step: 8
Training loss: 3.2141090193123354
Validation loss: 2.7756561948702596

Epoch: 5| Step: 9
Training loss: 2.9315189587928163
Validation loss: 2.7747305338187136

Epoch: 5| Step: 10
Training loss: 3.0954329411867074
Validation loss: 2.771377357099595

Epoch: 87| Step: 0
Training loss: 3.3943775699713217
Validation loss: 2.7704434724660025

Epoch: 5| Step: 1
Training loss: 2.877061850881699
Validation loss: 2.7716080169153345

Epoch: 5| Step: 2
Training loss: 2.905681431436291
Validation loss: 2.771222943851198

Epoch: 5| Step: 3
Training loss: 3.2571010773352604
Validation loss: 2.7661629421246365

Epoch: 5| Step: 4
Training loss: 3.1450404163668635
Validation loss: 2.7658369871699082

Epoch: 5| Step: 5
Training loss: 3.5590769066042984
Validation loss: 2.76684163866331

Epoch: 5| Step: 6
Training loss: 2.985206208638402
Validation loss: 2.7655269326630645

Epoch: 5| Step: 7
Training loss: 2.7757470199402676
Validation loss: 2.7646244260568125

Epoch: 5| Step: 8
Training loss: 2.3215955275978213
Validation loss: 2.7638916011764083

Epoch: 5| Step: 9
Training loss: 3.7023886419288545
Validation loss: 2.7634478175678714

Epoch: 5| Step: 10
Training loss: 2.6436706675357033
Validation loss: 2.763206628239177

Epoch: 88| Step: 0
Training loss: 2.3674252834433376
Validation loss: 2.76406092441645

Epoch: 5| Step: 1
Training loss: 3.1781719073019445
Validation loss: 2.7667815025100952

Epoch: 5| Step: 2
Training loss: 3.2985582438911525
Validation loss: 2.765684790521426

Epoch: 5| Step: 3
Training loss: 3.052540524625346
Validation loss: 2.766086299581349

Epoch: 5| Step: 4
Training loss: 3.240743513156573
Validation loss: 2.7704779092968748

Epoch: 5| Step: 5
Training loss: 3.003563671643113
Validation loss: 2.7684591982605697

Epoch: 5| Step: 6
Training loss: 2.9398842733014634
Validation loss: 2.7687107616082933

Epoch: 5| Step: 7
Training loss: 3.1714671206248677
Validation loss: 2.7653110984850695

Epoch: 5| Step: 8
Training loss: 3.150183257570012
Validation loss: 2.7645455226928664

Epoch: 5| Step: 9
Training loss: 2.7969392737137295
Validation loss: 2.761701342890496

Epoch: 5| Step: 10
Training loss: 3.5973847956764455
Validation loss: 2.75878575618022

Epoch: 89| Step: 0
Training loss: 3.5921022037502635
Validation loss: 2.758248302949826

Epoch: 5| Step: 1
Training loss: 3.087592576835912
Validation loss: 2.7593882057452657

Epoch: 5| Step: 2
Training loss: 2.8615570914148747
Validation loss: 2.7596721336220296

Epoch: 5| Step: 3
Training loss: 3.1180619086578676
Validation loss: 2.760236671478277

Epoch: 5| Step: 4
Training loss: 3.0603281221679532
Validation loss: 2.759540436592271

Epoch: 5| Step: 5
Training loss: 2.1863670685070136
Validation loss: 2.760195275636713

Epoch: 5| Step: 6
Training loss: 3.1090633677064323
Validation loss: 2.76043962286058

Epoch: 5| Step: 7
Training loss: 2.8367525300935554
Validation loss: 2.7595608059901506

Epoch: 5| Step: 8
Training loss: 3.6452352124003116
Validation loss: 2.755654597775304

Epoch: 5| Step: 9
Training loss: 2.8194203326150022
Validation loss: 2.7575422785154324

Epoch: 5| Step: 10
Training loss: 3.3530867518423766
Validation loss: 2.7570931715058276

Epoch: 90| Step: 0
Training loss: 3.144046267433527
Validation loss: 2.756483232961279

Epoch: 5| Step: 1
Training loss: 3.199992811671766
Validation loss: 2.7570615829837255

Epoch: 5| Step: 2
Training loss: 3.2503645765784905
Validation loss: 2.7591284131272698

Epoch: 5| Step: 3
Training loss: 2.6815542942050934
Validation loss: 2.7659820813703475

Epoch: 5| Step: 4
Training loss: 3.136689258403545
Validation loss: 2.7647894066336582

Epoch: 5| Step: 5
Training loss: 3.0494267659798324
Validation loss: 2.76583470144575

Epoch: 5| Step: 6
Training loss: 2.7814527287694735
Validation loss: 2.758802889898976

Epoch: 5| Step: 7
Training loss: 2.8934004372697992
Validation loss: 2.759770440590621

Epoch: 5| Step: 8
Training loss: 2.6421870740893545
Validation loss: 2.757422856732333

Epoch: 5| Step: 9
Training loss: 3.467698633820771
Validation loss: 2.7534243070407127

Epoch: 5| Step: 10
Training loss: 3.4653720388458646
Validation loss: 2.753357449559298

Epoch: 91| Step: 0
Training loss: 3.4130701504016145
Validation loss: 2.7524816031139845

Epoch: 5| Step: 1
Training loss: 3.344542792624908
Validation loss: 2.752122036056259

Epoch: 5| Step: 2
Training loss: 3.07635819128224
Validation loss: 2.750736889223716

Epoch: 5| Step: 3
Training loss: 3.5297470270129887
Validation loss: 2.75100346637997

Epoch: 5| Step: 4
Training loss: 2.3598462575199384
Validation loss: 2.7532530428326933

Epoch: 5| Step: 5
Training loss: 3.366207537802896
Validation loss: 2.7577651461733113

Epoch: 5| Step: 6
Training loss: 3.2118791744741735
Validation loss: 2.755690846526079

Epoch: 5| Step: 7
Training loss: 2.5677687281275747
Validation loss: 2.769189839556481

Epoch: 5| Step: 8
Training loss: 3.0547627393427397
Validation loss: 2.7725763500222134

Epoch: 5| Step: 9
Training loss: 3.004674607366792
Validation loss: 2.7708984630725815

Epoch: 5| Step: 10
Training loss: 2.52359480707079
Validation loss: 2.769776579412815

Epoch: 92| Step: 0
Training loss: 3.097511701831158
Validation loss: 2.7674978598336195

Epoch: 5| Step: 1
Training loss: 2.5812058045526984
Validation loss: 2.757732388450859

Epoch: 5| Step: 2
Training loss: 3.0312805174245065
Validation loss: 2.7534903854710864

Epoch: 5| Step: 3
Training loss: 3.1033487629191026
Validation loss: 2.74797932133884

Epoch: 5| Step: 4
Training loss: 3.3290767831011654
Validation loss: 2.7465973892566433

Epoch: 5| Step: 5
Training loss: 2.7988538507954988
Validation loss: 2.7447601432988082

Epoch: 5| Step: 6
Training loss: 2.7926434094002497
Validation loss: 2.746483743667743

Epoch: 5| Step: 7
Training loss: 3.11649599746993
Validation loss: 2.7491554257273796

Epoch: 5| Step: 8
Training loss: 3.3310124582763696
Validation loss: 2.7479787168076113

Epoch: 5| Step: 9
Training loss: 3.499118830247953
Validation loss: 2.746015527841372

Epoch: 5| Step: 10
Training loss: 2.8707615666676762
Validation loss: 2.74497267711596

Epoch: 93| Step: 0
Training loss: 3.0727814897881
Validation loss: 2.745250465473375

Epoch: 5| Step: 1
Training loss: 2.8667929895054742
Validation loss: 2.743167047470475

Epoch: 5| Step: 2
Training loss: 3.0837805827417615
Validation loss: 2.7485355885702263

Epoch: 5| Step: 3
Training loss: 2.925139373327971
Validation loss: 2.743340908452703

Epoch: 5| Step: 4
Training loss: 2.882875850157171
Validation loss: 2.742684402649

Epoch: 5| Step: 5
Training loss: 3.2173823441673157
Validation loss: 2.743474140025751

Epoch: 5| Step: 6
Training loss: 3.686295393402025
Validation loss: 2.744780876432825

Epoch: 5| Step: 7
Training loss: 3.3195377657730534
Validation loss: 2.744383356357103

Epoch: 5| Step: 8
Training loss: 2.557254539784806
Validation loss: 2.7438214532725094

Epoch: 5| Step: 9
Training loss: 2.5315709793594876
Validation loss: 2.7417029949685965

Epoch: 5| Step: 10
Training loss: 3.373630811091863
Validation loss: 2.7485525987082036

Epoch: 94| Step: 0
Training loss: 3.8538504530948443
Validation loss: 2.746386987642316

Epoch: 5| Step: 1
Training loss: 3.0549025984250724
Validation loss: 2.7413113139692338

Epoch: 5| Step: 2
Training loss: 2.878422234477861
Validation loss: 2.7404776703090765

Epoch: 5| Step: 3
Training loss: 2.749857378642528
Validation loss: 2.739537512913345

Epoch: 5| Step: 4
Training loss: 2.8064861002879775
Validation loss: 2.7403381074018895

Epoch: 5| Step: 5
Training loss: 3.1231267273542946
Validation loss: 2.7403590505703743

Epoch: 5| Step: 6
Training loss: 3.159637295393245
Validation loss: 2.739014452826688

Epoch: 5| Step: 7
Training loss: 2.9721305472554866
Validation loss: 2.744465007461107

Epoch: 5| Step: 8
Training loss: 3.313001198908586
Validation loss: 2.744516306603285

Epoch: 5| Step: 9
Training loss: 2.564757864307439
Validation loss: 2.7405041852044323

Epoch: 5| Step: 10
Training loss: 2.992167101758147
Validation loss: 2.7384735723793914

Epoch: 95| Step: 0
Training loss: 3.2802824501215873
Validation loss: 2.736302280745341

Epoch: 5| Step: 1
Training loss: 2.9595464090819332
Validation loss: 2.7375733227550665

Epoch: 5| Step: 2
Training loss: 2.7567192698867777
Validation loss: 2.7387366132519073

Epoch: 5| Step: 3
Training loss: 2.654462594423144
Validation loss: 2.741795403873255

Epoch: 5| Step: 4
Training loss: 2.819277586694833
Validation loss: 2.743231897348425

Epoch: 5| Step: 5
Training loss: 3.064468374025954
Validation loss: 2.746121878923264

Epoch: 5| Step: 6
Training loss: 3.276422200544103
Validation loss: 2.7433837902621403

Epoch: 5| Step: 7
Training loss: 2.9475953339228025
Validation loss: 2.7372850974765357

Epoch: 5| Step: 8
Training loss: 3.255911805497911
Validation loss: 2.74006970484506

Epoch: 5| Step: 9
Training loss: 3.633058601165072
Validation loss: 2.742705865594531

Epoch: 5| Step: 10
Training loss: 2.8048608242873345
Validation loss: 2.744987159690156

Epoch: 96| Step: 0
Training loss: 2.7765838398969347
Validation loss: 2.760631069247153

Epoch: 5| Step: 1
Training loss: 3.2881918001595087
Validation loss: 2.7677322219627314

Epoch: 5| Step: 2
Training loss: 2.6460324510356243
Validation loss: 2.77270735945678

Epoch: 5| Step: 3
Training loss: 2.9347602566959754
Validation loss: 2.772423132603661

Epoch: 5| Step: 4
Training loss: 2.845945579657244
Validation loss: 2.776868889987113

Epoch: 5| Step: 5
Training loss: 3.4893820329745924
Validation loss: 2.7712986793050067

Epoch: 5| Step: 6
Training loss: 3.144250248265596
Validation loss: 2.743336260266514

Epoch: 5| Step: 7
Training loss: 3.241476914083099
Validation loss: 2.7404954049333856

Epoch: 5| Step: 8
Training loss: 2.89170248209149
Validation loss: 2.7336602646009465

Epoch: 5| Step: 9
Training loss: 3.1512835112941975
Validation loss: 2.735456394762132

Epoch: 5| Step: 10
Training loss: 3.178444359261599
Validation loss: 2.734135999884668

Epoch: 97| Step: 0
Training loss: 2.8883440245621075
Validation loss: 2.7345807107405338

Epoch: 5| Step: 1
Training loss: 2.9095438677726877
Validation loss: 2.7340605674237803

Epoch: 5| Step: 2
Training loss: 3.3000688314484234
Validation loss: 2.7325080200596403

Epoch: 5| Step: 3
Training loss: 2.786142738985121
Validation loss: 2.732802649823536

Epoch: 5| Step: 4
Training loss: 2.8417092850547894
Validation loss: 2.730923932717116

Epoch: 5| Step: 5
Training loss: 3.2222706327053765
Validation loss: 2.731619776889472

Epoch: 5| Step: 6
Training loss: 2.9829225850560555
Validation loss: 2.7316621087979933

Epoch: 5| Step: 7
Training loss: 2.706263665920226
Validation loss: 2.7333270740162243

Epoch: 5| Step: 8
Training loss: 2.9639986263585993
Validation loss: 2.7312302223361105

Epoch: 5| Step: 9
Training loss: 3.6872616707029167
Validation loss: 2.730998995597053

Epoch: 5| Step: 10
Training loss: 3.1927600916555963
Validation loss: 2.7317048670573265

Epoch: 98| Step: 0
Training loss: 3.2260920664260544
Validation loss: 2.7292166718391413

Epoch: 5| Step: 1
Training loss: 2.6066781001153267
Validation loss: 2.7314782794181003

Epoch: 5| Step: 2
Training loss: 2.4064072396562617
Validation loss: 2.7342352231069214

Epoch: 5| Step: 3
Training loss: 2.9667849813578253
Validation loss: 2.7324544201342578

Epoch: 5| Step: 4
Training loss: 3.9923639127867068
Validation loss: 2.7358156324065743

Epoch: 5| Step: 5
Training loss: 3.0542530424039347
Validation loss: 2.7364869393083593

Epoch: 5| Step: 6
Training loss: 3.2805695327718
Validation loss: 2.731457789762719

Epoch: 5| Step: 7
Training loss: 2.6756474148213067
Validation loss: 2.732985249469588

Epoch: 5| Step: 8
Training loss: 3.0345173952613216
Validation loss: 2.7298085094298568

Epoch: 5| Step: 9
Training loss: 3.2095029276133085
Validation loss: 2.728619130198108

Epoch: 5| Step: 10
Training loss: 2.7578790672848705
Validation loss: 2.72501701898332

Epoch: 99| Step: 0
Training loss: 3.345914336317007
Validation loss: 2.7254805779056186

Epoch: 5| Step: 1
Training loss: 2.9564901887449277
Validation loss: 2.726504242649547

Epoch: 5| Step: 2
Training loss: 3.0224667747823277
Validation loss: 2.723313029626465

Epoch: 5| Step: 3
Training loss: 3.0280715166059364
Validation loss: 2.7242273213445176

Epoch: 5| Step: 4
Training loss: 3.056137326275713
Validation loss: 2.722948889660131

Epoch: 5| Step: 5
Training loss: 3.0972041104352126
Validation loss: 2.7239538359098545

Epoch: 5| Step: 6
Training loss: 3.3872520440487017
Validation loss: 2.7228520552579822

Epoch: 5| Step: 7
Training loss: 3.0741683393559844
Validation loss: 2.7235674903077056

Epoch: 5| Step: 8
Training loss: 3.0834632708689513
Validation loss: 2.721504900518567

Epoch: 5| Step: 9
Training loss: 2.6129133709672976
Validation loss: 2.7212393941618944

Epoch: 5| Step: 10
Training loss: 2.7261090707711912
Validation loss: 2.7205787574142186

Epoch: 100| Step: 0
Training loss: 3.626729223913253
Validation loss: 2.723768647673764

Epoch: 5| Step: 1
Training loss: 3.062831782838924
Validation loss: 2.722241840210939

Epoch: 5| Step: 2
Training loss: 2.6090699891323186
Validation loss: 2.7228687823877373

Epoch: 5| Step: 3
Training loss: 3.6284815413473495
Validation loss: 2.7233380491989783

Epoch: 5| Step: 4
Training loss: 2.3812790235617958
Validation loss: 2.7311899769313714

Epoch: 5| Step: 5
Training loss: 2.8538446360739655
Validation loss: 2.726354843371265

Epoch: 5| Step: 6
Training loss: 3.0475777622531606
Validation loss: 2.7301073711456465

Epoch: 5| Step: 7
Training loss: 2.798625206629172
Validation loss: 2.7397155474035864

Epoch: 5| Step: 8
Training loss: 3.263452418657697
Validation loss: 2.7462547244679087

Epoch: 5| Step: 9
Training loss: 3.049096183062997
Validation loss: 2.757896937273621

Epoch: 5| Step: 10
Training loss: 2.9342056631804683
Validation loss: 2.7482508776860266

Epoch: 101| Step: 0
Training loss: 2.9619066569722787
Validation loss: 2.733285597027454

Epoch: 5| Step: 1
Training loss: 3.280043752657599
Validation loss: 2.7250941881661332

Epoch: 5| Step: 2
Training loss: 3.249641692143818
Validation loss: 2.7220349653071403

Epoch: 5| Step: 3
Training loss: 3.0344262540124514
Validation loss: 2.72534321293207

Epoch: 5| Step: 4
Training loss: 3.474847469138301
Validation loss: 2.719479008730232

Epoch: 5| Step: 5
Training loss: 3.6223559767036217
Validation loss: 2.72394905676184

Epoch: 5| Step: 6
Training loss: 2.475362589314519
Validation loss: 2.71776408479227

Epoch: 5| Step: 7
Training loss: 2.796593593314154
Validation loss: 2.719181847330092

Epoch: 5| Step: 8
Training loss: 2.82687274333114
Validation loss: 2.7200418745020034

Epoch: 5| Step: 9
Training loss: 2.4769985645399375
Validation loss: 2.7173899793331846

Epoch: 5| Step: 10
Training loss: 3.0363611605991827
Validation loss: 2.7165699630618576

Epoch: 102| Step: 0
Training loss: 3.1503144909527268
Validation loss: 2.71387955854063

Epoch: 5| Step: 1
Training loss: 3.417487410303798
Validation loss: 2.714573391448275

Epoch: 5| Step: 2
Training loss: 3.1712420353471806
Validation loss: 2.7140603803309142

Epoch: 5| Step: 3
Training loss: 3.444962602697506
Validation loss: 2.7120957119926374

Epoch: 5| Step: 4
Training loss: 2.6622449654230564
Validation loss: 2.7121315258375005

Epoch: 5| Step: 5
Training loss: 2.970914031899362
Validation loss: 2.712386284101285

Epoch: 5| Step: 6
Training loss: 3.139083711847741
Validation loss: 2.712988571860175

Epoch: 5| Step: 7
Training loss: 3.0138239250467307
Validation loss: 2.721443223720208

Epoch: 5| Step: 8
Training loss: 2.4394371942346615
Validation loss: 2.720534010302951

Epoch: 5| Step: 9
Training loss: 3.1414060617791693
Validation loss: 2.7196573618138222

Epoch: 5| Step: 10
Training loss: 2.6116083147467846
Validation loss: 2.7226740649269257

Epoch: 103| Step: 0
Training loss: 2.997216841023395
Validation loss: 2.727746259620593

Epoch: 5| Step: 1
Training loss: 2.7477252395120964
Validation loss: 2.725100733917908

Epoch: 5| Step: 2
Training loss: 3.0326951504880038
Validation loss: 2.7261446074214253

Epoch: 5| Step: 3
Training loss: 3.540950717741442
Validation loss: 2.7257209266734863

Epoch: 5| Step: 4
Training loss: 3.2477601475874605
Validation loss: 2.7126524745760325

Epoch: 5| Step: 5
Training loss: 2.8305404211789194
Validation loss: 2.71041145740064

Epoch: 5| Step: 6
Training loss: 2.6967021511023894
Validation loss: 2.7109822939232737

Epoch: 5| Step: 7
Training loss: 2.192752309133201
Validation loss: 2.7134093739952387

Epoch: 5| Step: 8
Training loss: 2.9879561901940668
Validation loss: 2.7113163800235616

Epoch: 5| Step: 9
Training loss: 3.3965391272002945
Validation loss: 2.7138361056728355

Epoch: 5| Step: 10
Training loss: 3.604531345035883
Validation loss: 2.712637239094476

Epoch: 104| Step: 0
Training loss: 3.417716787588043
Validation loss: 2.713626421802122

Epoch: 5| Step: 1
Training loss: 3.0896161136615925
Validation loss: 2.7116549345988528

Epoch: 5| Step: 2
Training loss: 3.654810695520737
Validation loss: 2.716408615387089

Epoch: 5| Step: 3
Training loss: 3.124097159619742
Validation loss: 2.713906611021412

Epoch: 5| Step: 4
Training loss: 3.5886806392842936
Validation loss: 2.709071102576214

Epoch: 5| Step: 5
Training loss: 2.4443719292009103
Validation loss: 2.706969557848778

Epoch: 5| Step: 6
Training loss: 2.6794566063347083
Validation loss: 2.708182577917951

Epoch: 5| Step: 7
Training loss: 2.840413074540567
Validation loss: 2.7091461851829606

Epoch: 5| Step: 8
Training loss: 2.696401182701441
Validation loss: 2.7093576720189927

Epoch: 5| Step: 9
Training loss: 3.1214533707281107
Validation loss: 2.705522458372791

Epoch: 5| Step: 10
Training loss: 2.2881091739843913
Validation loss: 2.704517903521296

Epoch: 105| Step: 0
Training loss: 2.6310261175815954
Validation loss: 2.70426987139277

Epoch: 5| Step: 1
Training loss: 2.8182546446778964
Validation loss: 2.7079386351732566

Epoch: 5| Step: 2
Training loss: 3.490961256368973
Validation loss: 2.707499525454785

Epoch: 5| Step: 3
Training loss: 2.6124500726190902
Validation loss: 2.705917095261267

Epoch: 5| Step: 4
Training loss: 3.4098893068755243
Validation loss: 2.707007314650206

Epoch: 5| Step: 5
Training loss: 2.8669044292528705
Validation loss: 2.705686689902053

Epoch: 5| Step: 6
Training loss: 3.201352852714841
Validation loss: 2.7050151979483745

Epoch: 5| Step: 7
Training loss: 2.7034848365083293
Validation loss: 2.702033603171466

Epoch: 5| Step: 8
Training loss: 3.1010584962230348
Validation loss: 2.7005959603185667

Epoch: 5| Step: 9
Training loss: 3.31167995450855
Validation loss: 2.706554520317077

Epoch: 5| Step: 10
Training loss: 3.010333859757849
Validation loss: 2.7046981170852162

Epoch: 106| Step: 0
Training loss: 2.924254402271475
Validation loss: 2.7032866649236706

Epoch: 5| Step: 1
Training loss: 3.2676443764764493
Validation loss: 2.7060009539173473

Epoch: 5| Step: 2
Training loss: 3.6421478099125095
Validation loss: 2.7044298696500877

Epoch: 5| Step: 3
Training loss: 2.8241838846125487
Validation loss: 2.7012647603130295

Epoch: 5| Step: 4
Training loss: 3.0255107227816915
Validation loss: 2.703994596875671

Epoch: 5| Step: 5
Training loss: 3.0698825836094183
Validation loss: 2.704534247342951

Epoch: 5| Step: 6
Training loss: 3.0410896346164287
Validation loss: 2.6987088626805833

Epoch: 5| Step: 7
Training loss: 2.7762144988021684
Validation loss: 2.6983207342719697

Epoch: 5| Step: 8
Training loss: 2.8722301906899013
Validation loss: 2.69692177640758

Epoch: 5| Step: 9
Training loss: 2.4815731923894147
Validation loss: 2.6985221262916945

Epoch: 5| Step: 10
Training loss: 3.2347174569136654
Validation loss: 2.700271573265879

Epoch: 107| Step: 0
Training loss: 2.96790855931086
Validation loss: 2.7006347270227984

Epoch: 5| Step: 1
Training loss: 3.4819905286174797
Validation loss: 2.7057644861893886

Epoch: 5| Step: 2
Training loss: 3.2888306742175577
Validation loss: 2.7059380549581564

Epoch: 5| Step: 3
Training loss: 2.9114577692039276
Validation loss: 2.7048330160790353

Epoch: 5| Step: 4
Training loss: 3.14615353266277
Validation loss: 2.7012027751197496

Epoch: 5| Step: 5
Training loss: 2.3936332773779374
Validation loss: 2.6988725988324913

Epoch: 5| Step: 6
Training loss: 3.158555199338081
Validation loss: 2.699396923124231

Epoch: 5| Step: 7
Training loss: 2.5245799971153056
Validation loss: 2.6980987362596225

Epoch: 5| Step: 8
Training loss: 3.2110601619856958
Validation loss: 2.6942182210247116

Epoch: 5| Step: 9
Training loss: 2.8762600666717137
Validation loss: 2.6965869897735932

Epoch: 5| Step: 10
Training loss: 3.132500459346753
Validation loss: 2.697406367211254

Epoch: 108| Step: 0
Training loss: 2.602158486772703
Validation loss: 2.696855562925921

Epoch: 5| Step: 1
Training loss: 2.8918876570834153
Validation loss: 2.699211506084195

Epoch: 5| Step: 2
Training loss: 3.7936334783768606
Validation loss: 2.6983653044058

Epoch: 5| Step: 3
Training loss: 2.830197244247336
Validation loss: 2.6980212880992345

Epoch: 5| Step: 4
Training loss: 3.0732452906522307
Validation loss: 2.698621494291527

Epoch: 5| Step: 5
Training loss: 2.3372198049121073
Validation loss: 2.6970669432186076

Epoch: 5| Step: 6
Training loss: 3.077747457364869
Validation loss: 2.69581525838744

Epoch: 5| Step: 7
Training loss: 3.3727948084105432
Validation loss: 2.6924275028293456

Epoch: 5| Step: 8
Training loss: 3.1112757101870296
Validation loss: 2.693590166685159

Epoch: 5| Step: 9
Training loss: 2.9796171759161694
Validation loss: 2.6937440517190363

Epoch: 5| Step: 10
Training loss: 2.8625502336250546
Validation loss: 2.692880290628427

Epoch: 109| Step: 0
Training loss: 3.5623622666888357
Validation loss: 2.690857674953372

Epoch: 5| Step: 1
Training loss: 2.8597101734268415
Validation loss: 2.6917400752279272

Epoch: 5| Step: 2
Training loss: 3.0433177037863133
Validation loss: 2.6911108376144344

Epoch: 5| Step: 3
Training loss: 2.6325142801881034
Validation loss: 2.688436750812403

Epoch: 5| Step: 4
Training loss: 3.015288655395036
Validation loss: 2.6902545549838055

Epoch: 5| Step: 5
Training loss: 3.2837173631060517
Validation loss: 2.6876654329581484

Epoch: 5| Step: 6
Training loss: 2.5813887773574407
Validation loss: 2.6894493197428786

Epoch: 5| Step: 7
Training loss: 3.2413237742580288
Validation loss: 2.68913887193235

Epoch: 5| Step: 8
Training loss: 3.3982675794894495
Validation loss: 2.690661041089649

Epoch: 5| Step: 9
Training loss: 2.918639651056589
Validation loss: 2.690386228469277

Epoch: 5| Step: 10
Training loss: 2.304039608681149
Validation loss: 2.6897892379825707

Epoch: 110| Step: 0
Training loss: 2.983883642520608
Validation loss: 2.6950959548885556

Epoch: 5| Step: 1
Training loss: 2.77680554117844
Validation loss: 2.6999915898783424

Epoch: 5| Step: 2
Training loss: 3.1784440592172207
Validation loss: 2.695634044878561

Epoch: 5| Step: 3
Training loss: 3.0008956843661303
Validation loss: 2.705300608790629

Epoch: 5| Step: 4
Training loss: 2.891155792166032
Validation loss: 2.69115359429579

Epoch: 5| Step: 5
Training loss: 2.7521695335532033
Validation loss: 2.6864619901165945

Epoch: 5| Step: 6
Training loss: 2.6965762506643443
Validation loss: 2.686656075348351

Epoch: 5| Step: 7
Training loss: 3.212045742825576
Validation loss: 2.685386158359942

Epoch: 5| Step: 8
Training loss: 3.0643003193459277
Validation loss: 2.6868489729635403

Epoch: 5| Step: 9
Training loss: 3.364488409413841
Validation loss: 2.687767414239886

Epoch: 5| Step: 10
Training loss: 3.2119171801349267
Validation loss: 2.6886140317774907

Epoch: 111| Step: 0
Training loss: 2.9556960766434277
Validation loss: 2.686099657490425

Epoch: 5| Step: 1
Training loss: 2.7132623471371304
Validation loss: 2.691359499504717

Epoch: 5| Step: 2
Training loss: 3.0159671569574003
Validation loss: 2.6857757827586606

Epoch: 5| Step: 3
Training loss: 2.9161675343992295
Validation loss: 2.687060958207421

Epoch: 5| Step: 4
Training loss: 2.413828421790022
Validation loss: 2.688991715478076

Epoch: 5| Step: 5
Training loss: 3.0479753121404984
Validation loss: 2.6902900897356234

Epoch: 5| Step: 6
Training loss: 3.016293150256807
Validation loss: 2.6937273702410147

Epoch: 5| Step: 7
Training loss: 3.0527128193216893
Validation loss: 2.699277456628252

Epoch: 5| Step: 8
Training loss: 3.142719234809685
Validation loss: 2.69802736362571

Epoch: 5| Step: 9
Training loss: 3.1906410149630977
Validation loss: 2.6952223201656196

Epoch: 5| Step: 10
Training loss: 3.6581887867611425
Validation loss: 2.69320652458624

Epoch: 112| Step: 0
Training loss: 2.6468170519974334
Validation loss: 2.686891261243827

Epoch: 5| Step: 1
Training loss: 2.6783150141464764
Validation loss: 2.683145611305476

Epoch: 5| Step: 2
Training loss: 2.6510098998159397
Validation loss: 2.681912675544351

Epoch: 5| Step: 3
Training loss: 2.86083080149034
Validation loss: 2.6820548666966024

Epoch: 5| Step: 4
Training loss: 2.782008207033449
Validation loss: 2.6822343262038024

Epoch: 5| Step: 5
Training loss: 2.9566325998619454
Validation loss: 2.682008660536779

Epoch: 5| Step: 6
Training loss: 2.532527930660188
Validation loss: 2.6833808182637244

Epoch: 5| Step: 7
Training loss: 3.59104963934043
Validation loss: 2.682430297123654

Epoch: 5| Step: 8
Training loss: 3.6099718269242107
Validation loss: 2.685347776787012

Epoch: 5| Step: 9
Training loss: 3.6083161093026925
Validation loss: 2.680515815306671

Epoch: 5| Step: 10
Training loss: 2.894239979862616
Validation loss: 2.6841011867417848

Epoch: 113| Step: 0
Training loss: 3.0015021378158284
Validation loss: 2.682708236376216

Epoch: 5| Step: 1
Training loss: 2.8135023238364156
Validation loss: 2.6766590034131914

Epoch: 5| Step: 2
Training loss: 3.2444507466723866
Validation loss: 2.682747374325902

Epoch: 5| Step: 3
Training loss: 2.1703116738940564
Validation loss: 2.680932831802166

Epoch: 5| Step: 4
Training loss: 2.8683451048901123
Validation loss: 2.6779375057064794

Epoch: 5| Step: 5
Training loss: 3.0269904342716982
Validation loss: 2.679432574876074

Epoch: 5| Step: 6
Training loss: 3.582957639886181
Validation loss: 2.6779981454389157

Epoch: 5| Step: 7
Training loss: 3.0159194091026618
Validation loss: 2.680724476068262

Epoch: 5| Step: 8
Training loss: 3.439377566736433
Validation loss: 2.680715779245457

Epoch: 5| Step: 9
Training loss: 2.575463788384679
Validation loss: 2.6813253520865494

Epoch: 5| Step: 10
Training loss: 3.1255738303716334
Validation loss: 2.6818961183473466

Epoch: 114| Step: 0
Training loss: 2.7770249067047446
Validation loss: 2.6838138519496306

Epoch: 5| Step: 1
Training loss: 3.0268915047787326
Validation loss: 2.700208326276207

Epoch: 5| Step: 2
Training loss: 3.719456966101458
Validation loss: 2.699156633289213

Epoch: 5| Step: 3
Training loss: 3.2459797569485134
Validation loss: 2.680151863849231

Epoch: 5| Step: 4
Training loss: 2.735514289022369
Validation loss: 2.673367545721873

Epoch: 5| Step: 5
Training loss: 2.7751560098594164
Validation loss: 2.6768652382339666

Epoch: 5| Step: 6
Training loss: 2.6694826715038764
Validation loss: 2.6790671528467427

Epoch: 5| Step: 7
Training loss: 3.061665168170704
Validation loss: 2.6826982654536464

Epoch: 5| Step: 8
Training loss: 2.929601724004733
Validation loss: 2.6863575725281073

Epoch: 5| Step: 9
Training loss: 3.08505475902956
Validation loss: 2.6836264287483793

Epoch: 5| Step: 10
Training loss: 3.0108563763113003
Validation loss: 2.687701991074789

Epoch: 115| Step: 0
Training loss: 2.829200497978832
Validation loss: 2.6862091699990343

Epoch: 5| Step: 1
Training loss: 2.773304594911938
Validation loss: 2.687530743479613

Epoch: 5| Step: 2
Training loss: 3.011442139585418
Validation loss: 2.684078088003104

Epoch: 5| Step: 3
Training loss: 3.0783626251672116
Validation loss: 2.6806977007806063

Epoch: 5| Step: 4
Training loss: 2.9678457388774353
Validation loss: 2.6755400590043896

Epoch: 5| Step: 5
Training loss: 2.4563134726362783
Validation loss: 2.6764060456050145

Epoch: 5| Step: 6
Training loss: 3.315239834862433
Validation loss: 2.674304393335334

Epoch: 5| Step: 7
Training loss: 2.8844098883571894
Validation loss: 2.6721013104099924

Epoch: 5| Step: 8
Training loss: 2.8672523595141826
Validation loss: 2.6739518195186154

Epoch: 5| Step: 9
Training loss: 3.652201310098454
Validation loss: 2.6761213198638374

Epoch: 5| Step: 10
Training loss: 3.1052021799897798
Validation loss: 2.6802776768665604

Epoch: 116| Step: 0
Training loss: 3.5804025655976566
Validation loss: 2.6923985520358644

Epoch: 5| Step: 1
Training loss: 3.320976783273853
Validation loss: 2.696334461075491

Epoch: 5| Step: 2
Training loss: 3.5716049559497405
Validation loss: 2.6832737623004763

Epoch: 5| Step: 3
Training loss: 2.3177318671814033
Validation loss: 2.6756044697537216

Epoch: 5| Step: 4
Training loss: 2.5693407627757807
Validation loss: 2.6707908485571905

Epoch: 5| Step: 5
Training loss: 2.5597954410543675
Validation loss: 2.67464409792211

Epoch: 5| Step: 6
Training loss: 2.6812301955125233
Validation loss: 2.6729158807402533

Epoch: 5| Step: 7
Training loss: 3.1135442184755995
Validation loss: 2.6740073054094657

Epoch: 5| Step: 8
Training loss: 2.773041172991655
Validation loss: 2.674997870461942

Epoch: 5| Step: 9
Training loss: 2.8817449314247923
Validation loss: 2.6787517474021527

Epoch: 5| Step: 10
Training loss: 3.56307122185095
Validation loss: 2.6768617694331227

Epoch: 117| Step: 0
Training loss: 3.5063640773119347
Validation loss: 2.677544023448254

Epoch: 5| Step: 1
Training loss: 2.7428618468658663
Validation loss: 2.6745944568574416

Epoch: 5| Step: 2
Training loss: 3.1913826426796694
Validation loss: 2.6759016102882174

Epoch: 5| Step: 3
Training loss: 3.0388619717140632
Validation loss: 2.675049469622354

Epoch: 5| Step: 4
Training loss: 3.1037663621966645
Validation loss: 2.6724120979929245

Epoch: 5| Step: 5
Training loss: 2.055106580805891
Validation loss: 2.6762713508102776

Epoch: 5| Step: 6
Training loss: 2.8879959935506574
Validation loss: 2.6785417987964104

Epoch: 5| Step: 7
Training loss: 2.75424231244043
Validation loss: 2.6678486670008046

Epoch: 5| Step: 8
Training loss: 3.4657511076758594
Validation loss: 2.664669069936087

Epoch: 5| Step: 9
Training loss: 3.149383327127157
Validation loss: 2.6687264617222333

Epoch: 5| Step: 10
Training loss: 2.9281929781747036
Validation loss: 2.6683257162984813

Epoch: 118| Step: 0
Training loss: 2.506232028050091
Validation loss: 2.666559724496375

Epoch: 5| Step: 1
Training loss: 3.3581455553690525
Validation loss: 2.6701126326347113

Epoch: 5| Step: 2
Training loss: 3.168120167755457
Validation loss: 2.6695452904632933

Epoch: 5| Step: 3
Training loss: 3.297008782876939
Validation loss: 2.6716535738307274

Epoch: 5| Step: 4
Training loss: 2.914973303278382
Validation loss: 2.667979186271596

Epoch: 5| Step: 5
Training loss: 3.0022661868620015
Validation loss: 2.667165441038753

Epoch: 5| Step: 6
Training loss: 3.05185796710653
Validation loss: 2.6691685855629825

Epoch: 5| Step: 7
Training loss: 3.3087417587448575
Validation loss: 2.666893254031294

Epoch: 5| Step: 8
Training loss: 2.972541877060181
Validation loss: 2.6672493089184646

Epoch: 5| Step: 9
Training loss: 2.8513752078903742
Validation loss: 2.666864248103482

Epoch: 5| Step: 10
Training loss: 2.315591446894699
Validation loss: 2.669056756383781

Epoch: 119| Step: 0
Training loss: 3.0855743580835475
Validation loss: 2.669999763770203

Epoch: 5| Step: 1
Training loss: 3.3387300831933704
Validation loss: 2.6915013135036276

Epoch: 5| Step: 2
Training loss: 2.7876299430085254
Validation loss: 2.706325544672548

Epoch: 5| Step: 3
Training loss: 3.3335607133242595
Validation loss: 2.721519738763832

Epoch: 5| Step: 4
Training loss: 3.337279431773328
Validation loss: 2.7230839963775293

Epoch: 5| Step: 5
Training loss: 2.9015796831368896
Validation loss: 2.682287280975844

Epoch: 5| Step: 6
Training loss: 3.0199037546648677
Validation loss: 2.6650717186588935

Epoch: 5| Step: 7
Training loss: 2.6613596520291525
Validation loss: 2.665586887127497

Epoch: 5| Step: 8
Training loss: 2.6389990320699
Validation loss: 2.6660794937072225

Epoch: 5| Step: 9
Training loss: 2.5940669222326327
Validation loss: 2.673550788175087

Epoch: 5| Step: 10
Training loss: 3.318665722137885
Validation loss: 2.674866876135058

Epoch: 120| Step: 0
Training loss: 3.268736019068153
Validation loss: 2.6764126979820393

Epoch: 5| Step: 1
Training loss: 2.808118331632968
Validation loss: 2.67738150791516

Epoch: 5| Step: 2
Training loss: 2.8346993762282566
Validation loss: 2.6791074271996798

Epoch: 5| Step: 3
Training loss: 3.3453422391835526
Validation loss: 2.6762592887166416

Epoch: 5| Step: 4
Training loss: 2.5633668131268568
Validation loss: 2.67658758682622

Epoch: 5| Step: 5
Training loss: 2.6211374111490224
Validation loss: 2.6757998273105943

Epoch: 5| Step: 6
Training loss: 3.0995844531724948
Validation loss: 2.6759001090274883

Epoch: 5| Step: 7
Training loss: 3.3858328851963515
Validation loss: 2.668462307039892

Epoch: 5| Step: 8
Training loss: 2.562799947908156
Validation loss: 2.667757174401028

Epoch: 5| Step: 9
Training loss: 3.0543799672360556
Validation loss: 2.664281326865751

Epoch: 5| Step: 10
Training loss: 3.4552307612730386
Validation loss: 2.6627055025920683

Epoch: 121| Step: 0
Training loss: 2.68280133093418
Validation loss: 2.6686452935886322

Epoch: 5| Step: 1
Training loss: 3.3834774782139534
Validation loss: 2.673036631876328

Epoch: 5| Step: 2
Training loss: 3.458483650586909
Validation loss: 2.6781173138676833

Epoch: 5| Step: 3
Training loss: 2.436450438848859
Validation loss: 2.6933861176955265

Epoch: 5| Step: 4
Training loss: 3.315295065841982
Validation loss: 2.705579338760364

Epoch: 5| Step: 5
Training loss: 3.0614327887297588
Validation loss: 2.719746190390929

Epoch: 5| Step: 6
Training loss: 3.016819218384014
Validation loss: 2.733771343486888

Epoch: 5| Step: 7
Training loss: 3.019695637757213
Validation loss: 2.708975053460925

Epoch: 5| Step: 8
Training loss: 2.607008997771053
Validation loss: 2.696516923350161

Epoch: 5| Step: 9
Training loss: 3.0947227104839548
Validation loss: 2.68191977500511

Epoch: 5| Step: 10
Training loss: 2.6774448986777153
Validation loss: 2.6659538741790043

Epoch: 122| Step: 0
Training loss: 2.7620408276379296
Validation loss: 2.6649153102263967

Epoch: 5| Step: 1
Training loss: 2.639320457594105
Validation loss: 2.663459512078335

Epoch: 5| Step: 2
Training loss: 3.1149456787271426
Validation loss: 2.660140784207525

Epoch: 5| Step: 3
Training loss: 3.0689469035388544
Validation loss: 2.6599040388083797

Epoch: 5| Step: 4
Training loss: 3.182605950568917
Validation loss: 2.659451108115065

Epoch: 5| Step: 5
Training loss: 3.276602951185761
Validation loss: 2.6626700840017645

Epoch: 5| Step: 6
Training loss: 2.9396468089221286
Validation loss: 2.6603132234768396

Epoch: 5| Step: 7
Training loss: 3.304547246026406
Validation loss: 2.6583363706365852

Epoch: 5| Step: 8
Training loss: 2.541268854329296
Validation loss: 2.658834566861224

Epoch: 5| Step: 9
Training loss: 3.0523119809343013
Validation loss: 2.659318813908784

Epoch: 5| Step: 10
Training loss: 2.918940411713852
Validation loss: 2.6587687991263733

Epoch: 123| Step: 0
Training loss: 2.808400875679187
Validation loss: 2.659024949444552

Epoch: 5| Step: 1
Training loss: 2.638662026229538
Validation loss: 2.659392674285925

Epoch: 5| Step: 2
Training loss: 2.8295237417456915
Validation loss: 2.6633337266223447

Epoch: 5| Step: 3
Training loss: 2.965615957264434
Validation loss: 2.669266004620538

Epoch: 5| Step: 4
Training loss: 2.606853248799941
Validation loss: 2.6738962250945963

Epoch: 5| Step: 5
Training loss: 2.723910815746564
Validation loss: 2.6766103306931455

Epoch: 5| Step: 6
Training loss: 3.2577167743917395
Validation loss: 2.6727202740191274

Epoch: 5| Step: 7
Training loss: 3.721069253844483
Validation loss: 2.668494965498753

Epoch: 5| Step: 8
Training loss: 2.8175168539387663
Validation loss: 2.657577209133616

Epoch: 5| Step: 9
Training loss: 2.9565487345758186
Validation loss: 2.655643300712805

Epoch: 5| Step: 10
Training loss: 3.4199380487553013
Validation loss: 2.6561498093454405

Epoch: 124| Step: 0
Training loss: 3.1755929588438736
Validation loss: 2.658360042149176

Epoch: 5| Step: 1
Training loss: 2.2352484216389032
Validation loss: 2.65735896762025

Epoch: 5| Step: 2
Training loss: 3.0371026238369496
Validation loss: 2.6638128461796344

Epoch: 5| Step: 3
Training loss: 3.4482326458820833
Validation loss: 2.6533459650115065

Epoch: 5| Step: 4
Training loss: 2.8119838664865875
Validation loss: 2.654552712240164

Epoch: 5| Step: 5
Training loss: 2.522907685679404
Validation loss: 2.651315913556968

Epoch: 5| Step: 6
Training loss: 2.765185391245101
Validation loss: 2.657752130713144

Epoch: 5| Step: 7
Training loss: 3.0928593133700417
Validation loss: 2.6625494731732195

Epoch: 5| Step: 8
Training loss: 2.698649587949732
Validation loss: 2.680554833202111

Epoch: 5| Step: 9
Training loss: 3.4909533340276675
Validation loss: 2.686373872238042

Epoch: 5| Step: 10
Training loss: 3.407490775528958
Validation loss: 2.6904287203326644

Epoch: 125| Step: 0
Training loss: 3.400196400748002
Validation loss: 2.6936474475116965

Epoch: 5| Step: 1
Training loss: 2.6272743000399
Validation loss: 2.6709148325117615

Epoch: 5| Step: 2
Training loss: 3.250551617099733
Validation loss: 2.6637429772982855

Epoch: 5| Step: 3
Training loss: 2.9222638692494893
Validation loss: 2.6567987240788673

Epoch: 5| Step: 4
Training loss: 2.866256022058109
Validation loss: 2.654848546275424

Epoch: 5| Step: 5
Training loss: 3.042504565346019
Validation loss: 2.6540844490694178

Epoch: 5| Step: 6
Training loss: 3.075542935456983
Validation loss: 2.6522649628596877

Epoch: 5| Step: 7
Training loss: 2.4534300596235874
Validation loss: 2.6559777097946577

Epoch: 5| Step: 8
Training loss: 2.922714683929519
Validation loss: 2.6532325819347715

Epoch: 5| Step: 9
Training loss: 3.0145530574379342
Validation loss: 2.6542585634967573

Epoch: 5| Step: 10
Training loss: 3.2119790868303983
Validation loss: 2.6541870116665316

Testing loss: 2.874006311565286
