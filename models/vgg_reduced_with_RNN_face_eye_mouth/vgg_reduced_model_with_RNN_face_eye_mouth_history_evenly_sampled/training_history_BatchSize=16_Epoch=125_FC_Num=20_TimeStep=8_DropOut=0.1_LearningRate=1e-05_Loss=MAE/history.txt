Epoch: 1| Step: 0
Training loss: 4.785734176635742
Validation loss: 5.224014497572376

Epoch: 6| Step: 1
Training loss: 4.374928951263428
Validation loss: 5.213542876705047

Epoch: 6| Step: 2
Training loss: 3.9840331077575684
Validation loss: 5.203036362125028

Epoch: 6| Step: 3
Training loss: 5.681948661804199
Validation loss: 5.192023031173214

Epoch: 6| Step: 4
Training loss: 4.594980239868164
Validation loss: 5.180723354380618

Epoch: 6| Step: 5
Training loss: 6.712118625640869
Validation loss: 5.168765626927858

Epoch: 6| Step: 6
Training loss: 5.223527431488037
Validation loss: 5.155930298630909

Epoch: 6| Step: 7
Training loss: 5.057648181915283
Validation loss: 5.142230095401887

Epoch: 6| Step: 8
Training loss: 4.918249607086182
Validation loss: 5.127696021910636

Epoch: 6| Step: 9
Training loss: 3.79103684425354
Validation loss: 5.112056921887142

Epoch: 6| Step: 10
Training loss: 5.340945243835449
Validation loss: 5.095315482026788

Epoch: 6| Step: 11
Training loss: 4.785799980163574
Validation loss: 5.077873081289312

Epoch: 6| Step: 12
Training loss: 4.616110801696777
Validation loss: 5.058626754309541

Epoch: 6| Step: 13
Training loss: 5.528836250305176
Validation loss: 5.03822458944013

Epoch: 2| Step: 0
Training loss: 4.471765518188477
Validation loss: 5.015560591092673

Epoch: 6| Step: 1
Training loss: 4.411381721496582
Validation loss: 4.992465470426826

Epoch: 6| Step: 2
Training loss: 4.846249103546143
Validation loss: 4.9661668244228565

Epoch: 6| Step: 3
Training loss: 5.24009370803833
Validation loss: 4.938361542199248

Epoch: 6| Step: 4
Training loss: 4.602725505828857
Validation loss: 4.909274521694388

Epoch: 6| Step: 5
Training loss: 6.142178535461426
Validation loss: 4.87693956846832

Epoch: 6| Step: 6
Training loss: 4.098410606384277
Validation loss: 4.8424695435390674

Epoch: 6| Step: 7
Training loss: 3.7883591651916504
Validation loss: 4.805528645874352

Epoch: 6| Step: 8
Training loss: 4.869405746459961
Validation loss: 4.767342203406877

Epoch: 6| Step: 9
Training loss: 4.063382148742676
Validation loss: 4.725433682882658

Epoch: 6| Step: 10
Training loss: 3.133607864379883
Validation loss: 4.681692871996152

Epoch: 6| Step: 11
Training loss: 4.034730434417725
Validation loss: 4.63849510172362

Epoch: 6| Step: 12
Training loss: 5.27777624130249
Validation loss: 4.590939947353896

Epoch: 6| Step: 13
Training loss: 6.004754543304443
Validation loss: 4.542079171826763

Epoch: 3| Step: 0
Training loss: 3.9381847381591797
Validation loss: 4.49379482576924

Epoch: 6| Step: 1
Training loss: 3.631812810897827
Validation loss: 4.445434478021437

Epoch: 6| Step: 2
Training loss: 4.313833236694336
Validation loss: 4.396258620805638

Epoch: 6| Step: 3
Training loss: 3.250049114227295
Validation loss: 4.347859213429112

Epoch: 6| Step: 4
Training loss: 3.6530585289001465
Validation loss: 4.300710670409664

Epoch: 6| Step: 5
Training loss: 3.451951503753662
Validation loss: 4.257281516187934

Epoch: 6| Step: 6
Training loss: 4.858783721923828
Validation loss: 4.2160007364006455

Epoch: 6| Step: 7
Training loss: 5.041049003601074
Validation loss: 4.173384835643153

Epoch: 6| Step: 8
Training loss: 4.613589763641357
Validation loss: 4.134228255159112

Epoch: 6| Step: 9
Training loss: 4.421553134918213
Validation loss: 4.093298445465744

Epoch: 6| Step: 10
Training loss: 3.9830472469329834
Validation loss: 4.05532823070403

Epoch: 6| Step: 11
Training loss: 4.193174839019775
Validation loss: 4.015568958815708

Epoch: 6| Step: 12
Training loss: 3.9704079627990723
Validation loss: 3.9807864337839107

Epoch: 6| Step: 13
Training loss: 2.1928091049194336
Validation loss: 3.948839300422258

Epoch: 4| Step: 0
Training loss: 3.9981021881103516
Validation loss: 3.9232206447150118

Epoch: 6| Step: 1
Training loss: 3.918546676635742
Validation loss: 3.8993414755790465

Epoch: 6| Step: 2
Training loss: 3.7365996837615967
Validation loss: 3.879533521590694

Epoch: 6| Step: 3
Training loss: 3.607834815979004
Validation loss: 3.857450285265523

Epoch: 6| Step: 4
Training loss: 4.627752780914307
Validation loss: 3.8372674065251506

Epoch: 6| Step: 5
Training loss: 4.248530387878418
Validation loss: 3.8148434597958802

Epoch: 6| Step: 6
Training loss: 3.321587562561035
Validation loss: 3.7943345423667663

Epoch: 6| Step: 7
Training loss: 2.782313346862793
Validation loss: 3.774395742724019

Epoch: 6| Step: 8
Training loss: 3.9725050926208496
Validation loss: 3.7566465921299432

Epoch: 6| Step: 9
Training loss: 3.723737955093384
Validation loss: 3.7440812177555536

Epoch: 6| Step: 10
Training loss: 4.252884864807129
Validation loss: 3.729885701210268

Epoch: 6| Step: 11
Training loss: 2.0911319255828857
Validation loss: 3.715572157213765

Epoch: 6| Step: 12
Training loss: 3.972536087036133
Validation loss: 3.7015966881987867

Epoch: 6| Step: 13
Training loss: 2.918074607849121
Validation loss: 3.6823245633033013

Epoch: 5| Step: 0
Training loss: 3.4614458084106445
Validation loss: 3.6649209043031097

Epoch: 6| Step: 1
Training loss: 3.6944046020507812
Validation loss: 3.650151555256177

Epoch: 6| Step: 2
Training loss: 3.1406517028808594
Validation loss: 3.637177949310631

Epoch: 6| Step: 3
Training loss: 3.097278594970703
Validation loss: 3.6247789039406726

Epoch: 6| Step: 4
Training loss: 3.979314088821411
Validation loss: 3.6108346498140724

Epoch: 6| Step: 5
Training loss: 2.728332042694092
Validation loss: 3.5984209532378824

Epoch: 6| Step: 6
Training loss: 4.113527297973633
Validation loss: 3.5821415096200924

Epoch: 6| Step: 7
Training loss: 2.570345878601074
Validation loss: 3.57044235608911

Epoch: 6| Step: 8
Training loss: 4.286593914031982
Validation loss: 3.559415894169961

Epoch: 6| Step: 9
Training loss: 2.989363193511963
Validation loss: 3.5444537388381137

Epoch: 6| Step: 10
Training loss: 4.298606872558594
Validation loss: 3.5363828905167116

Epoch: 6| Step: 11
Training loss: 3.5733954906463623
Validation loss: 3.5253342633606284

Epoch: 6| Step: 12
Training loss: 3.3581929206848145
Validation loss: 3.514129284889467

Epoch: 6| Step: 13
Training loss: 3.8963117599487305
Validation loss: 3.4954543831527873

Epoch: 6| Step: 0
Training loss: 4.018340587615967
Validation loss: 3.48159501629491

Epoch: 6| Step: 1
Training loss: 2.8637197017669678
Validation loss: 3.4755676228513

Epoch: 6| Step: 2
Training loss: 4.48072624206543
Validation loss: 3.472340896565427

Epoch: 6| Step: 3
Training loss: 2.945902109146118
Validation loss: 3.4567886347411783

Epoch: 6| Step: 4
Training loss: 3.445054054260254
Validation loss: 3.441433652754753

Epoch: 6| Step: 5
Training loss: 2.9918384552001953
Validation loss: 3.434536398098033

Epoch: 6| Step: 6
Training loss: 3.0619115829467773
Validation loss: 3.432632815453314

Epoch: 6| Step: 7
Training loss: 3.5084104537963867
Validation loss: 3.4286339052261843

Epoch: 6| Step: 8
Training loss: 3.9061896800994873
Validation loss: 3.4137560270165883

Epoch: 6| Step: 9
Training loss: 3.0295357704162598
Validation loss: 3.401541745790871

Epoch: 6| Step: 10
Training loss: 2.578117847442627
Validation loss: 3.3955363868385233

Epoch: 6| Step: 11
Training loss: 4.162647247314453
Validation loss: 3.3909067517967633

Epoch: 6| Step: 12
Training loss: 2.9706621170043945
Validation loss: 3.3863967464816187

Epoch: 6| Step: 13
Training loss: 3.148343086242676
Validation loss: 3.379596928114532

Epoch: 7| Step: 0
Training loss: 2.9568185806274414
Validation loss: 3.370790135475897

Epoch: 6| Step: 1
Training loss: 3.9157321453094482
Validation loss: 3.3611551510390414

Epoch: 6| Step: 2
Training loss: 2.5662593841552734
Validation loss: 3.3550776922574608

Epoch: 6| Step: 3
Training loss: 4.08327579498291
Validation loss: 3.34757169600456

Epoch: 6| Step: 4
Training loss: 3.0958924293518066
Validation loss: 3.3421156355129775

Epoch: 6| Step: 5
Training loss: 3.0157573223114014
Validation loss: 3.3364392608724613

Epoch: 6| Step: 6
Training loss: 3.0412824153900146
Validation loss: 3.326794065454955

Epoch: 6| Step: 7
Training loss: 3.184995412826538
Validation loss: 3.323513359151861

Epoch: 6| Step: 8
Training loss: 2.933267593383789
Validation loss: 3.3173943360646567

Epoch: 6| Step: 9
Training loss: 3.8612945079803467
Validation loss: 3.312984343497984

Epoch: 6| Step: 10
Training loss: 3.2593350410461426
Validation loss: 3.3088856717591644

Epoch: 6| Step: 11
Training loss: 3.421797513961792
Validation loss: 3.30550564489057

Epoch: 6| Step: 12
Training loss: 3.0795531272888184
Validation loss: 3.2998471439525647

Epoch: 6| Step: 13
Training loss: 4.043850898742676
Validation loss: 3.2967811348617717

Epoch: 8| Step: 0
Training loss: 4.3607869148254395
Validation loss: 3.2891633613135225

Epoch: 6| Step: 1
Training loss: 3.1105875968933105
Validation loss: 3.280959877916562

Epoch: 6| Step: 2
Training loss: 4.385056018829346
Validation loss: 3.276156897185951

Epoch: 6| Step: 3
Training loss: 2.8892953395843506
Validation loss: 3.2697468316683205

Epoch: 6| Step: 4
Training loss: 3.3566031455993652
Validation loss: 3.266201501251549

Epoch: 6| Step: 5
Training loss: 2.807765483856201
Validation loss: 3.262032754959599

Epoch: 6| Step: 6
Training loss: 3.1083483695983887
Validation loss: 3.260737742147138

Epoch: 6| Step: 7
Training loss: 3.163331985473633
Validation loss: 3.2512538843257452

Epoch: 6| Step: 8
Training loss: 3.2515225410461426
Validation loss: 3.244527345062584

Epoch: 6| Step: 9
Training loss: 2.940244436264038
Validation loss: 3.239633790908321

Epoch: 6| Step: 10
Training loss: 3.209099292755127
Validation loss: 3.2383588616565993

Epoch: 6| Step: 11
Training loss: 2.4601948261260986
Validation loss: 3.23544967046348

Epoch: 6| Step: 12
Training loss: 3.0319089889526367
Validation loss: 3.237391733354138

Epoch: 6| Step: 13
Training loss: 3.411431074142456
Validation loss: 3.235785138222479

Epoch: 9| Step: 0
Training loss: 3.1121609210968018
Validation loss: 3.224910725829422

Epoch: 6| Step: 1
Training loss: 3.3733551502227783
Validation loss: 3.221809592298282

Epoch: 6| Step: 2
Training loss: 2.501065731048584
Validation loss: 3.2171454967991

Epoch: 6| Step: 3
Training loss: 3.96370792388916
Validation loss: 3.2157193383862896

Epoch: 6| Step: 4
Training loss: 2.8004298210144043
Validation loss: 3.211625076109363

Epoch: 6| Step: 5
Training loss: 2.5618348121643066
Validation loss: 3.208263986854143

Epoch: 6| Step: 6
Training loss: 2.362797260284424
Validation loss: 3.2053025768649195

Epoch: 6| Step: 7
Training loss: 2.2409701347351074
Validation loss: 3.2010367147384153

Epoch: 6| Step: 8
Training loss: 3.2037622928619385
Validation loss: 3.198589083968952

Epoch: 6| Step: 9
Training loss: 4.678408622741699
Validation loss: 3.194414366957962

Epoch: 6| Step: 10
Training loss: 4.013058185577393
Validation loss: 3.1907018025716147

Epoch: 6| Step: 11
Training loss: 3.879023313522339
Validation loss: 3.1874953675013717

Epoch: 6| Step: 12
Training loss: 2.8651633262634277
Validation loss: 3.184165390588904

Epoch: 6| Step: 13
Training loss: 3.323500633239746
Validation loss: 3.1812512413147958

Epoch: 10| Step: 0
Training loss: 3.8287124633789062
Validation loss: 3.1799037430876043

Epoch: 6| Step: 1
Training loss: 2.6119799613952637
Validation loss: 3.1758691880010788

Epoch: 6| Step: 2
Training loss: 3.6240015029907227
Validation loss: 3.173022136893324

Epoch: 6| Step: 3
Training loss: 3.1986613273620605
Validation loss: 3.1707619364543627

Epoch: 6| Step: 4
Training loss: 3.1763787269592285
Validation loss: 3.1659412614760862

Epoch: 6| Step: 5
Training loss: 3.5140702724456787
Validation loss: 3.1641141265951176

Epoch: 6| Step: 6
Training loss: 3.457897424697876
Validation loss: 3.1600160419300036

Epoch: 6| Step: 7
Training loss: 3.5015926361083984
Validation loss: 3.1562871061345583

Epoch: 6| Step: 8
Training loss: 2.4608964920043945
Validation loss: 3.153087462148359

Epoch: 6| Step: 9
Training loss: 2.745997667312622
Validation loss: 3.149532643697595

Epoch: 6| Step: 10
Training loss: 3.5307745933532715
Validation loss: 3.149350212466332

Epoch: 6| Step: 11
Training loss: 3.2155067920684814
Validation loss: 3.1428553545346825

Epoch: 6| Step: 12
Training loss: 2.3221030235290527
Validation loss: 3.138602097829183

Epoch: 6| Step: 13
Training loss: 3.1877284049987793
Validation loss: 3.134091600295036

Epoch: 11| Step: 0
Training loss: 2.863736391067505
Validation loss: 3.1408811897359867

Epoch: 6| Step: 1
Training loss: 3.4888932704925537
Validation loss: 3.1435151433431976

Epoch: 6| Step: 2
Training loss: 3.8382012844085693
Validation loss: 3.1259383719454528

Epoch: 6| Step: 3
Training loss: 4.181414604187012
Validation loss: 3.119515783043318

Epoch: 6| Step: 4
Training loss: 3.8383231163024902
Validation loss: 3.1206023436720653

Epoch: 6| Step: 5
Training loss: 1.9315452575683594
Validation loss: 3.116769185630224

Epoch: 6| Step: 6
Training loss: 3.330801010131836
Validation loss: 3.1167553778617614

Epoch: 6| Step: 7
Training loss: 2.2255585193634033
Validation loss: 3.1169587719825005

Epoch: 6| Step: 8
Training loss: 3.464660167694092
Validation loss: 3.1204010696821314

Epoch: 6| Step: 9
Training loss: 2.6593751907348633
Validation loss: 3.110908518555344

Epoch: 6| Step: 10
Training loss: 3.0998871326446533
Validation loss: 3.1041742858066352

Epoch: 6| Step: 11
Training loss: 2.9441633224487305
Validation loss: 3.1004939258739515

Epoch: 6| Step: 12
Training loss: 3.82344388961792
Validation loss: 3.09392705527685

Epoch: 6| Step: 13
Training loss: 1.5521817207336426
Validation loss: 3.0903040619306665

Epoch: 12| Step: 0
Training loss: 2.3631510734558105
Validation loss: 3.090823850324077

Epoch: 6| Step: 1
Training loss: 2.9775800704956055
Validation loss: 3.091584608119021

Epoch: 6| Step: 2
Training loss: 2.8781332969665527
Validation loss: 3.1086302726499495

Epoch: 6| Step: 3
Training loss: 3.488243579864502
Validation loss: 3.146412585371284

Epoch: 6| Step: 4
Training loss: 3.837639570236206
Validation loss: 3.089553961189844

Epoch: 6| Step: 5
Training loss: 2.948499917984009
Validation loss: 3.0774930882197555

Epoch: 6| Step: 6
Training loss: 2.651552677154541
Validation loss: 3.0912946347267396

Epoch: 6| Step: 7
Training loss: 2.621488571166992
Validation loss: 3.1107811594522126

Epoch: 6| Step: 8
Training loss: 2.8003058433532715
Validation loss: 3.1180941827835573

Epoch: 6| Step: 9
Training loss: 2.780658721923828
Validation loss: 3.104362667247813

Epoch: 6| Step: 10
Training loss: 4.444174289703369
Validation loss: 3.0850819926108084

Epoch: 6| Step: 11
Training loss: 3.6800665855407715
Validation loss: 3.081894851499988

Epoch: 6| Step: 12
Training loss: 3.0747785568237305
Validation loss: 3.082958459854126

Epoch: 6| Step: 13
Training loss: 3.218353271484375
Validation loss: 3.0787285861148628

Epoch: 13| Step: 0
Training loss: 3.3932058811187744
Validation loss: 3.08211709350668

Epoch: 6| Step: 1
Training loss: 2.8942694664001465
Validation loss: 3.0662686901707805

Epoch: 6| Step: 2
Training loss: 2.6321277618408203
Validation loss: 3.0578616562710015

Epoch: 6| Step: 3
Training loss: 2.7718210220336914
Validation loss: 3.0502336973785074

Epoch: 6| Step: 4
Training loss: 2.883111000061035
Validation loss: 3.047171628603371

Epoch: 6| Step: 5
Training loss: 2.6165177822113037
Validation loss: 3.047298403196437

Epoch: 6| Step: 6
Training loss: 3.1882190704345703
Validation loss: 3.054932704535864

Epoch: 6| Step: 7
Training loss: 3.5231237411499023
Validation loss: 3.053447897716235

Epoch: 6| Step: 8
Training loss: 3.3228940963745117
Validation loss: 3.0529217899486585

Epoch: 6| Step: 9
Training loss: 3.169877529144287
Validation loss: 3.0429311055009083

Epoch: 6| Step: 10
Training loss: 3.3689684867858887
Validation loss: 3.0371198679811213

Epoch: 6| Step: 11
Training loss: 3.466442108154297
Validation loss: 3.027488705932453

Epoch: 6| Step: 12
Training loss: 2.8608272075653076
Validation loss: 3.0202349975544918

Epoch: 6| Step: 13
Training loss: 3.1354708671569824
Validation loss: 3.01238981370003

Epoch: 14| Step: 0
Training loss: 2.6376614570617676
Validation loss: 3.007320081034014

Epoch: 6| Step: 1
Training loss: 3.792893648147583
Validation loss: 3.0028648376464844

Epoch: 6| Step: 2
Training loss: 2.5556821823120117
Validation loss: 3.0012445424192693

Epoch: 6| Step: 3
Training loss: 3.6607065200805664
Validation loss: 3.0021496126728673

Epoch: 6| Step: 4
Training loss: 3.154818058013916
Validation loss: 3.000476142411591

Epoch: 6| Step: 5
Training loss: 2.296344757080078
Validation loss: 2.996114105306646

Epoch: 6| Step: 6
Training loss: 4.111682891845703
Validation loss: 2.9977021627528693

Epoch: 6| Step: 7
Training loss: 3.7290542125701904
Validation loss: 2.9863624316389843

Epoch: 6| Step: 8
Training loss: 2.6850218772888184
Validation loss: 2.982782381837086

Epoch: 6| Step: 9
Training loss: 3.7531630992889404
Validation loss: 2.981587717610021

Epoch: 6| Step: 10
Training loss: 2.336779832839966
Validation loss: 2.9782573792242233

Epoch: 6| Step: 11
Training loss: 2.3006863594055176
Validation loss: 2.974901427504837

Epoch: 6| Step: 12
Training loss: 2.3610634803771973
Validation loss: 2.9734002108215005

Epoch: 6| Step: 13
Training loss: 3.7271482944488525
Validation loss: 2.9737328713940037

Epoch: 15| Step: 0
Training loss: 3.063748836517334
Validation loss: 2.976785362407725

Epoch: 6| Step: 1
Training loss: 3.3962056636810303
Validation loss: 2.9772233475920973

Epoch: 6| Step: 2
Training loss: 2.7026405334472656
Validation loss: 2.9751841560486825

Epoch: 6| Step: 3
Training loss: 2.5416250228881836
Validation loss: 2.974056702788158

Epoch: 6| Step: 4
Training loss: 2.0362541675567627
Validation loss: 2.9638114744617092

Epoch: 6| Step: 5
Training loss: 2.862841844558716
Validation loss: 2.960074693925919

Epoch: 6| Step: 6
Training loss: 3.121814727783203
Validation loss: 2.9577509459628852

Epoch: 6| Step: 7
Training loss: 3.651921272277832
Validation loss: 2.95008320705865

Epoch: 6| Step: 8
Training loss: 3.994452476501465
Validation loss: 2.9462215387693016

Epoch: 6| Step: 9
Training loss: 3.754106044769287
Validation loss: 2.9431730649804555

Epoch: 6| Step: 10
Training loss: 2.6453447341918945
Validation loss: 2.940699964441279

Epoch: 6| Step: 11
Training loss: 2.4038267135620117
Validation loss: 2.9377386005975867

Epoch: 6| Step: 12
Training loss: 3.2697606086730957
Validation loss: 2.9348308142795356

Epoch: 6| Step: 13
Training loss: 2.9158668518066406
Validation loss: 2.9335530573321926

Epoch: 16| Step: 0
Training loss: 3.053161144256592
Validation loss: 2.9310047498313327

Epoch: 6| Step: 1
Training loss: 3.5218334197998047
Validation loss: 2.9251745029162337

Epoch: 6| Step: 2
Training loss: 2.8184995651245117
Validation loss: 2.9239078285873576

Epoch: 6| Step: 3
Training loss: 2.3944904804229736
Validation loss: 2.927625702273461

Epoch: 6| Step: 4
Training loss: 3.436600685119629
Validation loss: 2.946513427201138

Epoch: 6| Step: 5
Training loss: 3.1074037551879883
Validation loss: 2.945582269340433

Epoch: 6| Step: 6
Training loss: 3.236037015914917
Validation loss: 2.920943885721186

Epoch: 6| Step: 7
Training loss: 3.123945713043213
Validation loss: 2.9110170051615727

Epoch: 6| Step: 8
Training loss: 3.362013339996338
Validation loss: 2.913148034003473

Epoch: 6| Step: 9
Training loss: 2.9643964767456055
Validation loss: 2.9123257719060427

Epoch: 6| Step: 10
Training loss: 3.1079397201538086
Validation loss: 2.9184401060945246

Epoch: 6| Step: 11
Training loss: 2.168370008468628
Validation loss: 2.919338198118312

Epoch: 6| Step: 12
Training loss: 3.371986150741577
Validation loss: 2.920849618091378

Epoch: 6| Step: 13
Training loss: 2.002763509750366
Validation loss: 2.9106927840940413

Epoch: 17| Step: 0
Training loss: 2.0285885334014893
Validation loss: 2.9074799399222098

Epoch: 6| Step: 1
Training loss: 3.2510294914245605
Validation loss: 2.9035064020464496

Epoch: 6| Step: 2
Training loss: 4.370776176452637
Validation loss: 2.9033141751443186

Epoch: 6| Step: 3
Training loss: 2.9424593448638916
Validation loss: 2.89990472537215

Epoch: 6| Step: 4
Training loss: 3.901993751525879
Validation loss: 2.898659970170708

Epoch: 6| Step: 5
Training loss: 2.6004438400268555
Validation loss: 2.9003735742261334

Epoch: 6| Step: 6
Training loss: 3.5380630493164062
Validation loss: 2.903878419629989

Epoch: 6| Step: 7
Training loss: 2.961068868637085
Validation loss: 2.9027524302082677

Epoch: 6| Step: 8
Training loss: 2.3846030235290527
Validation loss: 2.8969866716733543

Epoch: 6| Step: 9
Training loss: 3.4601998329162598
Validation loss: 2.895111673621721

Epoch: 6| Step: 10
Training loss: 2.87052059173584
Validation loss: 2.895608030339723

Epoch: 6| Step: 11
Training loss: 2.7409353256225586
Validation loss: 2.8887079736237884

Epoch: 6| Step: 12
Training loss: 1.728302001953125
Validation loss: 2.8846740979020313

Epoch: 6| Step: 13
Training loss: 3.13942813873291
Validation loss: 2.8823218038005214

Epoch: 18| Step: 0
Training loss: 3.4729928970336914
Validation loss: 2.8813622613107004

Epoch: 6| Step: 1
Training loss: 3.095367670059204
Validation loss: 2.879386371181857

Epoch: 6| Step: 2
Training loss: 3.3924636840820312
Validation loss: 2.877349658678937

Epoch: 6| Step: 3
Training loss: 1.9650797843933105
Validation loss: 2.873279530514953

Epoch: 6| Step: 4
Training loss: 3.465317487716675
Validation loss: 2.868027869091239

Epoch: 6| Step: 5
Training loss: 3.5404117107391357
Validation loss: 2.871512064369776

Epoch: 6| Step: 6
Training loss: 3.090799331665039
Validation loss: 2.8850627355678107

Epoch: 6| Step: 7
Training loss: 2.2808890342712402
Validation loss: 2.8720586146077802

Epoch: 6| Step: 8
Training loss: 2.666011333465576
Validation loss: 2.8784123825770553

Epoch: 6| Step: 9
Training loss: 2.819120168685913
Validation loss: 2.8755868788688415

Epoch: 6| Step: 10
Training loss: 2.5451388359069824
Validation loss: 2.8711718948938514

Epoch: 6| Step: 11
Training loss: 3.579775333404541
Validation loss: 2.866771521106843

Epoch: 6| Step: 12
Training loss: 2.8998517990112305
Validation loss: 2.8643781831187587

Epoch: 6| Step: 13
Training loss: 2.6125779151916504
Validation loss: 2.8623063718118975

Epoch: 19| Step: 0
Training loss: 3.810386896133423
Validation loss: 2.8614129148503786

Epoch: 6| Step: 1
Training loss: 3.014586925506592
Validation loss: 2.8581660383491108

Epoch: 6| Step: 2
Training loss: 3.1666266918182373
Validation loss: 2.858550569062592

Epoch: 6| Step: 3
Training loss: 2.6733765602111816
Validation loss: 2.8573733786100983

Epoch: 6| Step: 4
Training loss: 3.3488855361938477
Validation loss: 2.853617227205666

Epoch: 6| Step: 5
Training loss: 2.980018138885498
Validation loss: 2.8498387131639706

Epoch: 6| Step: 6
Training loss: 2.2312145233154297
Validation loss: 2.8534210522969565

Epoch: 6| Step: 7
Training loss: 2.722538709640503
Validation loss: 2.877046323591663

Epoch: 6| Step: 8
Training loss: 2.382049798965454
Validation loss: 2.860036337247459

Epoch: 6| Step: 9
Training loss: 3.284806251525879
Validation loss: 2.8634479738050893

Epoch: 6| Step: 10
Training loss: 3.0769853591918945
Validation loss: 2.857795210294826

Epoch: 6| Step: 11
Training loss: 3.079709053039551
Validation loss: 2.8505506130956833

Epoch: 6| Step: 12
Training loss: 2.875051259994507
Validation loss: 2.8435906492253786

Epoch: 6| Step: 13
Training loss: 2.6335530281066895
Validation loss: 2.8409601462784635

Epoch: 20| Step: 0
Training loss: 3.032552719116211
Validation loss: 2.8427816898592058

Epoch: 6| Step: 1
Training loss: 3.332942485809326
Validation loss: 2.842397807746805

Epoch: 6| Step: 2
Training loss: 3.171663999557495
Validation loss: 2.8413212581347396

Epoch: 6| Step: 3
Training loss: 2.5239975452423096
Validation loss: 2.851032487807735

Epoch: 6| Step: 4
Training loss: 3.385693073272705
Validation loss: 2.858363256659559

Epoch: 6| Step: 5
Training loss: 2.0293774604797363
Validation loss: 2.8680611502739692

Epoch: 6| Step: 6
Training loss: 3.345932722091675
Validation loss: 2.869037825574157

Epoch: 6| Step: 7
Training loss: 3.1632370948791504
Validation loss: 2.8546448907544537

Epoch: 6| Step: 8
Training loss: 3.0811824798583984
Validation loss: 2.842898307308074

Epoch: 6| Step: 9
Training loss: 2.205986261367798
Validation loss: 2.8392914546433317

Epoch: 6| Step: 10
Training loss: 2.441277503967285
Validation loss: 2.8406362969388246

Epoch: 6| Step: 11
Training loss: 3.7915077209472656
Validation loss: 2.842534383138021

Epoch: 6| Step: 12
Training loss: 3.593174457550049
Validation loss: 2.846487970762355

Epoch: 6| Step: 13
Training loss: 1.802308201789856
Validation loss: 2.843232359937442

Epoch: 21| Step: 0
Training loss: 3.1413912773132324
Validation loss: 2.8434431809251026

Epoch: 6| Step: 1
Training loss: 2.587017774581909
Validation loss: 2.839549623509889

Epoch: 6| Step: 2
Training loss: 2.898303270339966
Validation loss: 2.8326201746540685

Epoch: 6| Step: 3
Training loss: 3.2073092460632324
Validation loss: 2.8304170280374508

Epoch: 6| Step: 4
Training loss: 2.806528091430664
Validation loss: 2.8270904633306686

Epoch: 6| Step: 5
Training loss: 3.377737045288086
Validation loss: 2.8269432513944563

Epoch: 6| Step: 6
Training loss: 2.259472370147705
Validation loss: 2.828331780690019

Epoch: 6| Step: 7
Training loss: 2.711393356323242
Validation loss: 2.8251387893512683

Epoch: 6| Step: 8
Training loss: 3.0936808586120605
Validation loss: 2.8289778206938054

Epoch: 6| Step: 9
Training loss: 2.75968074798584
Validation loss: 2.8263800016013523

Epoch: 6| Step: 10
Training loss: 3.259945869445801
Validation loss: 2.826610234475905

Epoch: 6| Step: 11
Training loss: 3.2429943084716797
Validation loss: 2.835757332463418

Epoch: 6| Step: 12
Training loss: 3.032923698425293
Validation loss: 2.8549279320624565

Epoch: 6| Step: 13
Training loss: 2.7363529205322266
Validation loss: 2.8506612444436676

Epoch: 22| Step: 0
Training loss: 2.7717783451080322
Validation loss: 2.833349650905978

Epoch: 6| Step: 1
Training loss: 1.9015216827392578
Validation loss: 2.8268263288723525

Epoch: 6| Step: 2
Training loss: 2.696913957595825
Validation loss: 2.8280231824485202

Epoch: 6| Step: 3
Training loss: 4.026284217834473
Validation loss: 2.8245465550371396

Epoch: 6| Step: 4
Training loss: 2.9570441246032715
Validation loss: 2.8191140185120287

Epoch: 6| Step: 5
Training loss: 2.974269390106201
Validation loss: 2.8153360351439445

Epoch: 6| Step: 6
Training loss: 2.5550851821899414
Validation loss: 2.817113696887929

Epoch: 6| Step: 7
Training loss: 2.8148374557495117
Validation loss: 2.8148983806692143

Epoch: 6| Step: 8
Training loss: 2.2547101974487305
Validation loss: 2.8169549485688568

Epoch: 6| Step: 9
Training loss: 3.3848209381103516
Validation loss: 2.8169622780174337

Epoch: 6| Step: 10
Training loss: 3.0108590126037598
Validation loss: 2.814425404353808

Epoch: 6| Step: 11
Training loss: 3.39984393119812
Validation loss: 2.8120564183881207

Epoch: 6| Step: 12
Training loss: 3.488351821899414
Validation loss: 2.80897182033908

Epoch: 6| Step: 13
Training loss: 2.642348289489746
Validation loss: 2.808468882755567

Epoch: 23| Step: 0
Training loss: 3.2659549713134766
Validation loss: 2.8086845541513092

Epoch: 6| Step: 1
Training loss: 2.296067714691162
Validation loss: 2.8110063306746946

Epoch: 6| Step: 2
Training loss: 3.561490774154663
Validation loss: 2.8109525172941145

Epoch: 6| Step: 3
Training loss: 3.502882957458496
Validation loss: 2.8173614266098186

Epoch: 6| Step: 4
Training loss: 2.6392734050750732
Validation loss: 2.8205521209265596

Epoch: 6| Step: 5
Training loss: 2.716404676437378
Validation loss: 2.818990392069663

Epoch: 6| Step: 6
Training loss: 3.2206296920776367
Validation loss: 2.8245106076681488

Epoch: 6| Step: 7
Training loss: 2.5209543704986572
Validation loss: 2.8369557652422177

Epoch: 6| Step: 8
Training loss: 2.799365997314453
Validation loss: 2.8362482798996793

Epoch: 6| Step: 9
Training loss: 2.5664961338043213
Validation loss: 2.8343898711665982

Epoch: 6| Step: 10
Training loss: 3.429137706756592
Validation loss: 2.815434717362927

Epoch: 6| Step: 11
Training loss: 3.0383048057556152
Validation loss: 2.803454663163872

Epoch: 6| Step: 12
Training loss: 2.3962817192077637
Validation loss: 2.8047684059348157

Epoch: 6| Step: 13
Training loss: 2.9052751064300537
Validation loss: 2.8060245283188356

Epoch: 24| Step: 0
Training loss: 1.992855191230774
Validation loss: 2.8281932261682328

Epoch: 6| Step: 1
Training loss: 3.2823686599731445
Validation loss: 2.8558135827382407

Epoch: 6| Step: 2
Training loss: 3.3471570014953613
Validation loss: 2.8573378747509373

Epoch: 6| Step: 3
Training loss: 3.0768110752105713
Validation loss: 2.862819210175545

Epoch: 6| Step: 4
Training loss: 2.3827452659606934
Validation loss: 2.8603363190927813

Epoch: 6| Step: 5
Training loss: 3.310396194458008
Validation loss: 2.847700806074245

Epoch: 6| Step: 6
Training loss: 3.3424148559570312
Validation loss: 2.8396086641537246

Epoch: 6| Step: 7
Training loss: 3.3583288192749023
Validation loss: 2.8275752580294045

Epoch: 6| Step: 8
Training loss: 2.39251971244812
Validation loss: 2.8115107961880264

Epoch: 6| Step: 9
Training loss: 2.8488481044769287
Validation loss: 2.7965605976761028

Epoch: 6| Step: 10
Training loss: 3.5191173553466797
Validation loss: 2.808018543386972

Epoch: 6| Step: 11
Training loss: 2.187284469604492
Validation loss: 2.836470624451996

Epoch: 6| Step: 12
Training loss: 3.057147979736328
Validation loss: 2.8855548392059984

Epoch: 6| Step: 13
Training loss: 3.5050599575042725
Validation loss: 2.8983594755972586

Epoch: 25| Step: 0
Training loss: 2.381481170654297
Validation loss: 2.8606442379695114

Epoch: 6| Step: 1
Training loss: 2.3633241653442383
Validation loss: 2.8435840863053516

Epoch: 6| Step: 2
Training loss: 3.458526611328125
Validation loss: 2.825271024498888

Epoch: 6| Step: 3
Training loss: 3.39052414894104
Validation loss: 2.79408767402813

Epoch: 6| Step: 4
Training loss: 2.3192498683929443
Validation loss: 2.79184789042319

Epoch: 6| Step: 5
Training loss: 2.699272632598877
Validation loss: 2.799596542953163

Epoch: 6| Step: 6
Training loss: 3.8683836460113525
Validation loss: 2.8050151230186544

Epoch: 6| Step: 7
Training loss: 3.1082143783569336
Validation loss: 2.8053886172592

Epoch: 6| Step: 8
Training loss: 3.11806583404541
Validation loss: 2.810464917972524

Epoch: 6| Step: 9
Training loss: 2.4301536083221436
Validation loss: 2.798858324686686

Epoch: 6| Step: 10
Training loss: 2.4747674465179443
Validation loss: 2.790957527775918

Epoch: 6| Step: 11
Training loss: 3.2970306873321533
Validation loss: 2.7898682189244095

Epoch: 6| Step: 12
Training loss: 2.34476637840271
Validation loss: 2.8021430071964057

Epoch: 6| Step: 13
Training loss: 3.9956703186035156
Validation loss: 2.835923392285583

Epoch: 26| Step: 0
Training loss: 3.3082313537597656
Validation loss: 2.8505310550812752

Epoch: 6| Step: 1
Training loss: 2.799159049987793
Validation loss: 2.8778018336142264

Epoch: 6| Step: 2
Training loss: 3.4667646884918213
Validation loss: 2.882320239979734

Epoch: 6| Step: 3
Training loss: 2.5317704677581787
Validation loss: 2.8400607467979513

Epoch: 6| Step: 4
Training loss: 3.034693717956543
Validation loss: 2.794710925830308

Epoch: 6| Step: 5
Training loss: 2.859821319580078
Validation loss: 2.7849659817193144

Epoch: 6| Step: 6
Training loss: 3.218285083770752
Validation loss: 2.781039494340138

Epoch: 6| Step: 7
Training loss: 2.70377516746521
Validation loss: 2.7883606264668126

Epoch: 6| Step: 8
Training loss: 2.8466033935546875
Validation loss: 2.799716659771499

Epoch: 6| Step: 9
Training loss: 2.8638839721679688
Validation loss: 2.809224308177989

Epoch: 6| Step: 10
Training loss: 2.199988603591919
Validation loss: 2.790004937879501

Epoch: 6| Step: 11
Training loss: 2.7802319526672363
Validation loss: 2.784627970828805

Epoch: 6| Step: 12
Training loss: 3.3038010597229004
Validation loss: 2.7836224212441394

Epoch: 6| Step: 13
Training loss: 2.8209943771362305
Validation loss: 2.7799183450719362

Epoch: 27| Step: 0
Training loss: 2.9728572368621826
Validation loss: 2.79039793117072

Epoch: 6| Step: 1
Training loss: 3.1962313652038574
Validation loss: 2.789176117989325

Epoch: 6| Step: 2
Training loss: 2.275045394897461
Validation loss: 2.795799181025515

Epoch: 6| Step: 3
Training loss: 2.844648599624634
Validation loss: 2.7884050646135883

Epoch: 6| Step: 4
Training loss: 3.6075615882873535
Validation loss: 2.7816828502121793

Epoch: 6| Step: 5
Training loss: 2.8267650604248047
Validation loss: 2.7783744001901276

Epoch: 6| Step: 6
Training loss: 1.7792606353759766
Validation loss: 2.7742333104533534

Epoch: 6| Step: 7
Training loss: 2.5025954246520996
Validation loss: 2.7699765518147457

Epoch: 6| Step: 8
Training loss: 3.427117347717285
Validation loss: 2.768323632978624

Epoch: 6| Step: 9
Training loss: 2.6422576904296875
Validation loss: 2.767590022856189

Epoch: 6| Step: 10
Training loss: 3.047020196914673
Validation loss: 2.7685925627267487

Epoch: 6| Step: 11
Training loss: 2.6801843643188477
Validation loss: 2.764498402995448

Epoch: 6| Step: 12
Training loss: 3.0770421028137207
Validation loss: 2.7674637533003286

Epoch: 6| Step: 13
Training loss: 4.248046398162842
Validation loss: 2.7667779691757692

Epoch: 28| Step: 0
Training loss: 2.970000743865967
Validation loss: 2.766150064365838

Epoch: 6| Step: 1
Training loss: 2.9035823345184326
Validation loss: 2.7667764284277476

Epoch: 6| Step: 2
Training loss: 2.1204090118408203
Validation loss: 2.7631491486744215

Epoch: 6| Step: 3
Training loss: 3.2302844524383545
Validation loss: 2.7619610294218986

Epoch: 6| Step: 4
Training loss: 2.6870265007019043
Validation loss: 2.762584270969514

Epoch: 6| Step: 5
Training loss: 3.5942506790161133
Validation loss: 2.7622370181545133

Epoch: 6| Step: 6
Training loss: 3.4706530570983887
Validation loss: 2.7625367487630537

Epoch: 6| Step: 7
Training loss: 2.637775182723999
Validation loss: 2.764233286662768

Epoch: 6| Step: 8
Training loss: 3.0653018951416016
Validation loss: 2.7535216628864245

Epoch: 6| Step: 9
Training loss: 2.7187674045562744
Validation loss: 2.753629287083944

Epoch: 6| Step: 10
Training loss: 2.2844395637512207
Validation loss: 2.7545747141684256

Epoch: 6| Step: 11
Training loss: 3.192580461502075
Validation loss: 2.7510453321600474

Epoch: 6| Step: 12
Training loss: 2.9195785522460938
Validation loss: 2.753183436650102

Epoch: 6| Step: 13
Training loss: 2.367300271987915
Validation loss: 2.7478992990268174

Epoch: 29| Step: 0
Training loss: 3.377375841140747
Validation loss: 2.7507162222298245

Epoch: 6| Step: 1
Training loss: 2.8432557582855225
Validation loss: 2.753012244419385

Epoch: 6| Step: 2
Training loss: 2.5449154376983643
Validation loss: 2.7540196526435112

Epoch: 6| Step: 3
Training loss: 2.9322261810302734
Validation loss: 2.751097171537338

Epoch: 6| Step: 4
Training loss: 3.3447091579437256
Validation loss: 2.752215075236495

Epoch: 6| Step: 5
Training loss: 2.4824106693267822
Validation loss: 2.7470805337352138

Epoch: 6| Step: 6
Training loss: 2.2311527729034424
Validation loss: 2.750444007176225

Epoch: 6| Step: 7
Training loss: 2.628190040588379
Validation loss: 2.75340558380209

Epoch: 6| Step: 8
Training loss: 2.9259679317474365
Validation loss: 2.7531975007826284

Epoch: 6| Step: 9
Training loss: 2.6769819259643555
Validation loss: 2.755342206647319

Epoch: 6| Step: 10
Training loss: 2.3763210773468018
Validation loss: 2.7640714312112458

Epoch: 6| Step: 11
Training loss: 3.5447864532470703
Validation loss: 2.758511312546269

Epoch: 6| Step: 12
Training loss: 3.557901620864868
Validation loss: 2.7525178540137505

Epoch: 6| Step: 13
Training loss: 2.669031858444214
Validation loss: 2.7575219164612474

Epoch: 30| Step: 0
Training loss: 3.3489060401916504
Validation loss: 2.771565603953536

Epoch: 6| Step: 1
Training loss: 2.7714295387268066
Validation loss: 2.7657229618359636

Epoch: 6| Step: 2
Training loss: 3.3105969429016113
Validation loss: 2.7583735373712357

Epoch: 6| Step: 3
Training loss: 3.052063465118408
Validation loss: 2.7514300756557013

Epoch: 6| Step: 4
Training loss: 2.552711009979248
Validation loss: 2.7474839123346473

Epoch: 6| Step: 5
Training loss: 2.982875347137451
Validation loss: 2.744776774478215

Epoch: 6| Step: 6
Training loss: 2.490708827972412
Validation loss: 2.7404773850594797

Epoch: 6| Step: 7
Training loss: 2.5583736896514893
Validation loss: 2.7419765303211827

Epoch: 6| Step: 8
Training loss: 2.6343913078308105
Validation loss: 2.7426949649728756

Epoch: 6| Step: 9
Training loss: 2.684567928314209
Validation loss: 2.7449143086710284

Epoch: 6| Step: 10
Training loss: 3.2233662605285645
Validation loss: 2.7427418206327703

Epoch: 6| Step: 11
Training loss: 3.164638042449951
Validation loss: 2.736848246666693

Epoch: 6| Step: 12
Training loss: 2.786928176879883
Validation loss: 2.7364661206481276

Epoch: 6| Step: 13
Training loss: 2.613361358642578
Validation loss: 2.7394138074690297

Epoch: 31| Step: 0
Training loss: 2.7718281745910645
Validation loss: 2.759244559913553

Epoch: 6| Step: 1
Training loss: 2.80253005027771
Validation loss: 2.7659028576266382

Epoch: 6| Step: 2
Training loss: 3.3338701725006104
Validation loss: 2.7629395223432973

Epoch: 6| Step: 3
Training loss: 3.223323106765747
Validation loss: 2.798957032542075

Epoch: 6| Step: 4
Training loss: 2.895538330078125
Validation loss: 2.7926817478672152

Epoch: 6| Step: 5
Training loss: 2.4289135932922363
Validation loss: 2.7775545145875666

Epoch: 6| Step: 6
Training loss: 3.6980648040771484
Validation loss: 2.758823820339736

Epoch: 6| Step: 7
Training loss: 4.128511905670166
Validation loss: 2.7396313913406862

Epoch: 6| Step: 8
Training loss: 3.2749109268188477
Validation loss: 2.7319782292971047

Epoch: 6| Step: 9
Training loss: 2.144336223602295
Validation loss: 2.7297372741083943

Epoch: 6| Step: 10
Training loss: 2.481201648712158
Validation loss: 2.734920435054328

Epoch: 6| Step: 11
Training loss: 2.0152623653411865
Validation loss: 2.733464697355865

Epoch: 6| Step: 12
Training loss: 2.4955458641052246
Validation loss: 2.732764915753436

Epoch: 6| Step: 13
Training loss: 2.4146475791931152
Validation loss: 2.737701533943094

Epoch: 32| Step: 0
Training loss: 2.0721888542175293
Validation loss: 2.7660007989534767

Epoch: 6| Step: 1
Training loss: 2.8048369884490967
Validation loss: 2.8109203615496234

Epoch: 6| Step: 2
Training loss: 2.174043893814087
Validation loss: 2.828988952021445

Epoch: 6| Step: 3
Training loss: 3.26414155960083
Validation loss: 2.8244904215617845

Epoch: 6| Step: 4
Training loss: 2.8849003314971924
Validation loss: 2.7637764382106003

Epoch: 6| Step: 5
Training loss: 2.9000651836395264
Validation loss: 2.744043832184166

Epoch: 6| Step: 6
Training loss: 3.8874359130859375
Validation loss: 2.7358260769997873

Epoch: 6| Step: 7
Training loss: 2.5911080837249756
Validation loss: 2.731928707450949

Epoch: 6| Step: 8
Training loss: 2.971393346786499
Validation loss: 2.738277724994126

Epoch: 6| Step: 9
Training loss: 3.6374731063842773
Validation loss: 2.743924064020957

Epoch: 6| Step: 10
Training loss: 2.6592230796813965
Validation loss: 2.7502025993921424

Epoch: 6| Step: 11
Training loss: 2.8864846229553223
Validation loss: 2.74552918505925

Epoch: 6| Step: 12
Training loss: 2.8255062103271484
Validation loss: 2.7541509494986585

Epoch: 6| Step: 13
Training loss: 2.8906664848327637
Validation loss: 2.7501717434134534

Epoch: 33| Step: 0
Training loss: 3.1456706523895264
Validation loss: 2.7479355130144345

Epoch: 6| Step: 1
Training loss: 3.420640468597412
Validation loss: 2.7458545238740983

Epoch: 6| Step: 2
Training loss: 3.370051383972168
Validation loss: 2.7536010793460313

Epoch: 6| Step: 3
Training loss: 2.7930731773376465
Validation loss: 2.7596278472613265

Epoch: 6| Step: 4
Training loss: 2.381094455718994
Validation loss: 2.747116255503829

Epoch: 6| Step: 5
Training loss: 3.0601534843444824
Validation loss: 2.7407547171397875

Epoch: 6| Step: 6
Training loss: 1.9310511350631714
Validation loss: 2.7356538362400507

Epoch: 6| Step: 7
Training loss: 3.412348747253418
Validation loss: 2.7349379088288996

Epoch: 6| Step: 8
Training loss: 2.547515869140625
Validation loss: 2.7286831409700456

Epoch: 6| Step: 9
Training loss: 2.6629323959350586
Validation loss: 2.7260428808068715

Epoch: 6| Step: 10
Training loss: 2.724376916885376
Validation loss: 2.7303404295316307

Epoch: 6| Step: 11
Training loss: 3.0397238731384277
Validation loss: 2.729491159480105

Epoch: 6| Step: 12
Training loss: 2.2602672576904297
Validation loss: 2.7235832342537503

Epoch: 6| Step: 13
Training loss: 3.6300647258758545
Validation loss: 2.724788793953516

Epoch: 34| Step: 0
Training loss: 3.5718400478363037
Validation loss: 2.725140243448237

Epoch: 6| Step: 1
Training loss: 3.615299940109253
Validation loss: 2.7246365290816112

Epoch: 6| Step: 2
Training loss: 2.7828497886657715
Validation loss: 2.7347664704886814

Epoch: 6| Step: 3
Training loss: 3.3881607055664062
Validation loss: 2.7373232226217947

Epoch: 6| Step: 4
Training loss: 2.4025135040283203
Validation loss: 2.744082094520651

Epoch: 6| Step: 5
Training loss: 1.8052648305892944
Validation loss: 2.7349561106774116

Epoch: 6| Step: 6
Training loss: 2.5599355697631836
Validation loss: 2.745821196545837

Epoch: 6| Step: 7
Training loss: 2.621887683868408
Validation loss: 2.74830763570724

Epoch: 6| Step: 8
Training loss: 3.1497092247009277
Validation loss: 2.742067019144694

Epoch: 6| Step: 9
Training loss: 3.131559371948242
Validation loss: 2.7340378248563377

Epoch: 6| Step: 10
Training loss: 3.2091548442840576
Validation loss: 2.729345744655978

Epoch: 6| Step: 11
Training loss: 2.6451234817504883
Validation loss: 2.728071612696494

Epoch: 6| Step: 12
Training loss: 2.353376865386963
Validation loss: 2.7261063732126707

Epoch: 6| Step: 13
Training loss: 2.4513020515441895
Validation loss: 2.720822029216315

Epoch: 35| Step: 0
Training loss: 3.593273878097534
Validation loss: 2.7186401633806128

Epoch: 6| Step: 1
Training loss: 3.5050907135009766
Validation loss: 2.7164041175637195

Epoch: 6| Step: 2
Training loss: 2.824131965637207
Validation loss: 2.713335757614464

Epoch: 6| Step: 3
Training loss: 2.647608757019043
Validation loss: 2.711868211787234

Epoch: 6| Step: 4
Training loss: 3.2631301879882812
Validation loss: 2.711513655160063

Epoch: 6| Step: 5
Training loss: 2.8298611640930176
Validation loss: 2.7070413686895884

Epoch: 6| Step: 6
Training loss: 2.2675366401672363
Validation loss: 2.7075806971519225

Epoch: 6| Step: 7
Training loss: 1.6869971752166748
Validation loss: 2.7076243456973823

Epoch: 6| Step: 8
Training loss: 2.916675567626953
Validation loss: 2.7051195636872323

Epoch: 6| Step: 9
Training loss: 3.2703278064727783
Validation loss: 2.707155196897445

Epoch: 6| Step: 10
Training loss: 2.7641634941101074
Validation loss: 2.7067009684860066

Epoch: 6| Step: 11
Training loss: 2.4191622734069824
Validation loss: 2.707483873572401

Epoch: 6| Step: 12
Training loss: 3.3098392486572266
Validation loss: 2.7093840491387153

Epoch: 6| Step: 13
Training loss: 2.096900463104248
Validation loss: 2.7053969854949624

Epoch: 36| Step: 0
Training loss: 2.7840466499328613
Validation loss: 2.703409343637446

Epoch: 6| Step: 1
Training loss: 2.7425527572631836
Validation loss: 2.701160874418033

Epoch: 6| Step: 2
Training loss: 2.0650601387023926
Validation loss: 2.704353683738298

Epoch: 6| Step: 3
Training loss: 2.62705659866333
Validation loss: 2.7023878969171995

Epoch: 6| Step: 4
Training loss: 1.9408080577850342
Validation loss: 2.70150407924447

Epoch: 6| Step: 5
Training loss: 3.2147388458251953
Validation loss: 2.7075119762010473

Epoch: 6| Step: 6
Training loss: 3.269252300262451
Validation loss: 2.711020085119432

Epoch: 6| Step: 7
Training loss: 3.158419132232666
Validation loss: 2.720036191325034

Epoch: 6| Step: 8
Training loss: 2.762356996536255
Validation loss: 2.7398512799252748

Epoch: 6| Step: 9
Training loss: 2.2775702476501465
Validation loss: 2.7399610011808333

Epoch: 6| Step: 10
Training loss: 3.8851046562194824
Validation loss: 2.742453331588417

Epoch: 6| Step: 11
Training loss: 2.6215176582336426
Validation loss: 2.7373932330839095

Epoch: 6| Step: 12
Training loss: 3.2908055782318115
Validation loss: 2.719119535979404

Epoch: 6| Step: 13
Training loss: 3.26031756401062
Validation loss: 2.705279065716651

Epoch: 37| Step: 0
Training loss: 3.5837042331695557
Validation loss: 2.693748120338686

Epoch: 6| Step: 1
Training loss: 2.882917881011963
Validation loss: 2.6899184385935464

Epoch: 6| Step: 2
Training loss: 2.5232346057891846
Validation loss: 2.698747886124478

Epoch: 6| Step: 3
Training loss: 2.8375191688537598
Validation loss: 2.7085441004845405

Epoch: 6| Step: 4
Training loss: 3.2321596145629883
Validation loss: 2.71296864427546

Epoch: 6| Step: 5
Training loss: 2.6638317108154297
Validation loss: 2.701240103731873

Epoch: 6| Step: 6
Training loss: 1.5211474895477295
Validation loss: 2.688913622210103

Epoch: 6| Step: 7
Training loss: 2.0039498805999756
Validation loss: 2.6879423920826246

Epoch: 6| Step: 8
Training loss: 2.896728754043579
Validation loss: 2.6806475423997447

Epoch: 6| Step: 9
Training loss: 2.8039515018463135
Validation loss: 2.6752900231269097

Epoch: 6| Step: 10
Training loss: 3.7971606254577637
Validation loss: 2.6753046128057663

Epoch: 6| Step: 11
Training loss: 3.675767421722412
Validation loss: 2.692050838983187

Epoch: 6| Step: 12
Training loss: 2.6266238689422607
Validation loss: 2.706964356924898

Epoch: 6| Step: 13
Training loss: 2.3885340690612793
Validation loss: 2.715675469367735

Epoch: 38| Step: 0
Training loss: 3.022679567337036
Validation loss: 2.689678494648267

Epoch: 6| Step: 1
Training loss: 2.736381769180298
Validation loss: 2.6824214894284486

Epoch: 6| Step: 2
Training loss: 2.781496047973633
Validation loss: 2.6746919308939288

Epoch: 6| Step: 3
Training loss: 3.077914237976074
Validation loss: 2.675045972229332

Epoch: 6| Step: 4
Training loss: 2.9603867530822754
Validation loss: 2.6689117698259253

Epoch: 6| Step: 5
Training loss: 3.549302816390991
Validation loss: 2.66243681856381

Epoch: 6| Step: 6
Training loss: 2.8428115844726562
Validation loss: 2.6666433298459618

Epoch: 6| Step: 7
Training loss: 2.507395029067993
Validation loss: 2.6672581652159333

Epoch: 6| Step: 8
Training loss: 3.076409339904785
Validation loss: 2.6683633173665693

Epoch: 6| Step: 9
Training loss: 2.5793724060058594
Validation loss: 2.6669278760110178

Epoch: 6| Step: 10
Training loss: 2.4381227493286133
Validation loss: 2.6679305568818124

Epoch: 6| Step: 11
Training loss: 2.7607333660125732
Validation loss: 2.6682730695252777

Epoch: 6| Step: 12
Training loss: 2.294010639190674
Validation loss: 2.6626136020947526

Epoch: 6| Step: 13
Training loss: 2.6700265407562256
Validation loss: 2.664917563879362

Epoch: 39| Step: 0
Training loss: 3.3944649696350098
Validation loss: 2.664248876674201

Epoch: 6| Step: 1
Training loss: 2.809900999069214
Validation loss: 2.657633868596887

Epoch: 6| Step: 2
Training loss: 1.84952712059021
Validation loss: 2.660765932452294

Epoch: 6| Step: 3
Training loss: 3.403249740600586
Validation loss: 2.660544582592544

Epoch: 6| Step: 4
Training loss: 2.8274612426757812
Validation loss: 2.654041044173702

Epoch: 6| Step: 5
Training loss: 2.2867274284362793
Validation loss: 2.649879042820264

Epoch: 6| Step: 6
Training loss: 2.5712499618530273
Validation loss: 2.652220533740136

Epoch: 6| Step: 7
Training loss: 2.8816981315612793
Validation loss: 2.6510017046364407

Epoch: 6| Step: 8
Training loss: 3.0092883110046387
Validation loss: 2.6512011238323745

Epoch: 6| Step: 9
Training loss: 2.903136730194092
Validation loss: 2.656728934216243

Epoch: 6| Step: 10
Training loss: 2.661074161529541
Validation loss: 2.6544992898100164

Epoch: 6| Step: 11
Training loss: 2.6019558906555176
Validation loss: 2.657276940602128

Epoch: 6| Step: 12
Training loss: 2.8097434043884277
Validation loss: 2.6534251730929137

Epoch: 6| Step: 13
Training loss: 3.790463447570801
Validation loss: 2.651360704052833

Epoch: 40| Step: 0
Training loss: 2.7055535316467285
Validation loss: 2.650215636017502

Epoch: 6| Step: 1
Training loss: 3.3402979373931885
Validation loss: 2.6476641854932232

Epoch: 6| Step: 2
Training loss: 2.618515729904175
Validation loss: 2.645443385647189

Epoch: 6| Step: 3
Training loss: 2.325735569000244
Validation loss: 2.6488654408403622

Epoch: 6| Step: 4
Training loss: 2.897871732711792
Validation loss: 2.6476670465161725

Epoch: 6| Step: 5
Training loss: 2.0467119216918945
Validation loss: 2.6501012438087055

Epoch: 6| Step: 6
Training loss: 2.9244613647460938
Validation loss: 2.6470901812276533

Epoch: 6| Step: 7
Training loss: 3.7153472900390625
Validation loss: 2.6465424055694253

Epoch: 6| Step: 8
Training loss: 2.511096239089966
Validation loss: 2.647542579199678

Epoch: 6| Step: 9
Training loss: 2.6882529258728027
Validation loss: 2.6526839194759244

Epoch: 6| Step: 10
Training loss: 3.245218276977539
Validation loss: 2.6567820733593357

Epoch: 6| Step: 11
Training loss: 2.077821731567383
Validation loss: 2.6502647246083906

Epoch: 6| Step: 12
Training loss: 3.9080545902252197
Validation loss: 2.6441522003501974

Epoch: 6| Step: 13
Training loss: 1.6472058296203613
Validation loss: 2.641754150390625

Epoch: 41| Step: 0
Training loss: 2.4895083904266357
Validation loss: 2.6399929754195677

Epoch: 6| Step: 1
Training loss: 3.1707229614257812
Validation loss: 2.6338005578646095

Epoch: 6| Step: 2
Training loss: 3.2129666805267334
Validation loss: 2.6354880256037556

Epoch: 6| Step: 3
Training loss: 3.087062358856201
Validation loss: 2.6356154564888246

Epoch: 6| Step: 4
Training loss: 2.3103878498077393
Validation loss: 2.6316958140301447

Epoch: 6| Step: 5
Training loss: 2.557875633239746
Validation loss: 2.6304177571368474

Epoch: 6| Step: 6
Training loss: 2.46645188331604
Validation loss: 2.6298585950687365

Epoch: 6| Step: 7
Training loss: 2.457974433898926
Validation loss: 2.629771517169091

Epoch: 6| Step: 8
Training loss: 2.0353803634643555
Validation loss: 2.6240799093759186

Epoch: 6| Step: 9
Training loss: 2.7669286727905273
Validation loss: 2.6303400736983105

Epoch: 6| Step: 10
Training loss: 2.9730989933013916
Validation loss: 2.6304937639544086

Epoch: 6| Step: 11
Training loss: 3.6024227142333984
Validation loss: 2.635193665822347

Epoch: 6| Step: 12
Training loss: 2.896022319793701
Validation loss: 2.639655156802106

Epoch: 6| Step: 13
Training loss: 3.1107845306396484
Validation loss: 2.64721603034645

Epoch: 42| Step: 0
Training loss: 2.7773995399475098
Validation loss: 2.6368237131385395

Epoch: 6| Step: 1
Training loss: 1.541223406791687
Validation loss: 2.626683786351194

Epoch: 6| Step: 2
Training loss: 3.192018747329712
Validation loss: 2.622631903617613

Epoch: 6| Step: 3
Training loss: 2.7220299243927
Validation loss: 2.621551018889232

Epoch: 6| Step: 4
Training loss: 2.6096363067626953
Validation loss: 2.6233556680781867

Epoch: 6| Step: 5
Training loss: 2.0703201293945312
Validation loss: 2.6245162179393153

Epoch: 6| Step: 6
Training loss: 3.214482545852661
Validation loss: 2.6261844917010237

Epoch: 6| Step: 7
Training loss: 3.174619674682617
Validation loss: 2.6259510594029583

Epoch: 6| Step: 8
Training loss: 2.8632583618164062
Validation loss: 2.6273500586068756

Epoch: 6| Step: 9
Training loss: 2.0360074043273926
Validation loss: 2.623940549870973

Epoch: 6| Step: 10
Training loss: 3.354663372039795
Validation loss: 2.6196731675055718

Epoch: 6| Step: 11
Training loss: 3.6206746101379395
Validation loss: 2.620437575924781

Epoch: 6| Step: 12
Training loss: 2.860609531402588
Validation loss: 2.6150076004766647

Epoch: 6| Step: 13
Training loss: 2.9069161415100098
Validation loss: 2.613250151757271

Epoch: 43| Step: 0
Training loss: 2.519274950027466
Validation loss: 2.615650492329751

Epoch: 6| Step: 1
Training loss: 3.2087345123291016
Validation loss: 2.615142627428937

Epoch: 6| Step: 2
Training loss: 3.4377622604370117
Validation loss: 2.6195920898068334

Epoch: 6| Step: 3
Training loss: 3.037825584411621
Validation loss: 2.621279372963854

Epoch: 6| Step: 4
Training loss: 2.268429756164551
Validation loss: 2.625894446526804

Epoch: 6| Step: 5
Training loss: 2.492265224456787
Validation loss: 2.6267114557245725

Epoch: 6| Step: 6
Training loss: 2.80306339263916
Validation loss: 2.6228025856838433

Epoch: 6| Step: 7
Training loss: 2.264059543609619
Validation loss: 2.6254161224570325

Epoch: 6| Step: 8
Training loss: 2.320452928543091
Validation loss: 2.6323782244036273

Epoch: 6| Step: 9
Training loss: 3.386922836303711
Validation loss: 2.6299977558915333

Epoch: 6| Step: 10
Training loss: 2.454256057739258
Validation loss: 2.6198698013059554

Epoch: 6| Step: 11
Training loss: 2.895512104034424
Validation loss: 2.6132141569609284

Epoch: 6| Step: 12
Training loss: 2.7119293212890625
Validation loss: 2.6131525372946136

Epoch: 6| Step: 13
Training loss: 3.1027684211730957
Validation loss: 2.6079982378149547

Epoch: 44| Step: 0
Training loss: 1.9276351928710938
Validation loss: 2.6084550939580446

Epoch: 6| Step: 1
Training loss: 2.589446544647217
Validation loss: 2.6086568447851364

Epoch: 6| Step: 2
Training loss: 2.678118944168091
Validation loss: 2.610345886599633

Epoch: 6| Step: 3
Training loss: 3.296421766281128
Validation loss: 2.608704936119818

Epoch: 6| Step: 4
Training loss: 2.69183611869812
Validation loss: 2.6136219168222077

Epoch: 6| Step: 5
Training loss: 2.4194653034210205
Validation loss: 2.6208313818900817

Epoch: 6| Step: 6
Training loss: 3.59311580657959
Validation loss: 2.631202479844452

Epoch: 6| Step: 7
Training loss: 2.4766855239868164
Validation loss: 2.633137669614566

Epoch: 6| Step: 8
Training loss: 2.1559252738952637
Validation loss: 2.6381207050815707

Epoch: 6| Step: 9
Training loss: 2.213320255279541
Validation loss: 2.633984773389755

Epoch: 6| Step: 10
Training loss: 2.822465419769287
Validation loss: 2.625303529923962

Epoch: 6| Step: 11
Training loss: 3.262380599975586
Validation loss: 2.623519612896827

Epoch: 6| Step: 12
Training loss: 3.9648711681365967
Validation loss: 2.6189278146272064

Epoch: 6| Step: 13
Training loss: 2.574469566345215
Validation loss: 2.617143415635632

Epoch: 45| Step: 0
Training loss: 3.404204845428467
Validation loss: 2.610643809841525

Epoch: 6| Step: 1
Training loss: 3.4033761024475098
Validation loss: 2.6032101492727957

Epoch: 6| Step: 2
Training loss: 2.0001537799835205
Validation loss: 2.5971986709102506

Epoch: 6| Step: 3
Training loss: 2.55315899848938
Validation loss: 2.595197316138975

Epoch: 6| Step: 4
Training loss: 2.4051966667175293
Validation loss: 2.5947648325274066

Epoch: 6| Step: 5
Training loss: 2.8581418991088867
Validation loss: 2.594031731287638

Epoch: 6| Step: 6
Training loss: 3.767441511154175
Validation loss: 2.591969597724176

Epoch: 6| Step: 7
Training loss: 2.5482442378997803
Validation loss: 2.5875450052240843

Epoch: 6| Step: 8
Training loss: 2.9579029083251953
Validation loss: 2.5888906037935646

Epoch: 6| Step: 9
Training loss: 2.0565245151519775
Validation loss: 2.5839160732043687

Epoch: 6| Step: 10
Training loss: 2.975832462310791
Validation loss: 2.5822093153512604

Epoch: 6| Step: 11
Training loss: 2.257246494293213
Validation loss: 2.580707009120654

Epoch: 6| Step: 12
Training loss: 2.464355945587158
Validation loss: 2.5791621656828028

Epoch: 6| Step: 13
Training loss: 2.994419574737549
Validation loss: 2.581112474523565

Epoch: 46| Step: 0
Training loss: 2.7144765853881836
Validation loss: 2.5813975436713106

Epoch: 6| Step: 1
Training loss: 2.9868276119232178
Validation loss: 2.587195741233005

Epoch: 6| Step: 2
Training loss: 3.134922981262207
Validation loss: 2.586445795592441

Epoch: 6| Step: 3
Training loss: 2.171051025390625
Validation loss: 2.5911930350847143

Epoch: 6| Step: 4
Training loss: 2.4488534927368164
Validation loss: 2.592496079783286

Epoch: 6| Step: 5
Training loss: 2.1647911071777344
Validation loss: 2.5808747378728722

Epoch: 6| Step: 6
Training loss: 2.336106061935425
Validation loss: 2.5838776890949537

Epoch: 6| Step: 7
Training loss: 3.1068954467773438
Validation loss: 2.5882763093517673

Epoch: 6| Step: 8
Training loss: 2.9848251342773438
Validation loss: 2.5842132593995784

Epoch: 6| Step: 9
Training loss: 3.0251479148864746
Validation loss: 2.5808000590211604

Epoch: 6| Step: 10
Training loss: 2.8652124404907227
Validation loss: 2.577591044928438

Epoch: 6| Step: 11
Training loss: 3.361884593963623
Validation loss: 2.5740031452589136

Epoch: 6| Step: 12
Training loss: 2.725100517272949
Validation loss: 2.5731685520500265

Epoch: 6| Step: 13
Training loss: 2.100977897644043
Validation loss: 2.569712220981557

Epoch: 47| Step: 0
Training loss: 2.478954315185547
Validation loss: 2.5705913959010953

Epoch: 6| Step: 1
Training loss: 2.711947202682495
Validation loss: 2.5734667367832635

Epoch: 6| Step: 2
Training loss: 1.8077703714370728
Validation loss: 2.573100889882734

Epoch: 6| Step: 3
Training loss: 3.227877140045166
Validation loss: 2.5739278921516995

Epoch: 6| Step: 4
Training loss: 3.271265983581543
Validation loss: 2.5791068333451466

Epoch: 6| Step: 5
Training loss: 2.8380255699157715
Validation loss: 2.5820572299342

Epoch: 6| Step: 6
Training loss: 2.431969404220581
Validation loss: 2.577578377980058

Epoch: 6| Step: 7
Training loss: 3.267815351486206
Validation loss: 2.580488125483195

Epoch: 6| Step: 8
Training loss: 3.2228543758392334
Validation loss: 2.579666640168877

Epoch: 6| Step: 9
Training loss: 2.5065526962280273
Validation loss: 2.5845830055975143

Epoch: 6| Step: 10
Training loss: 2.5356438159942627
Validation loss: 2.584092655489522

Epoch: 6| Step: 11
Training loss: 2.9955906867980957
Validation loss: 2.596379236508441

Epoch: 6| Step: 12
Training loss: 2.260685443878174
Validation loss: 2.596613825008433

Epoch: 6| Step: 13
Training loss: 2.8006467819213867
Validation loss: 2.5829527147354616

Epoch: 48| Step: 0
Training loss: 2.452698230743408
Validation loss: 2.57473240616501

Epoch: 6| Step: 1
Training loss: 2.2799184322357178
Validation loss: 2.570175437517064

Epoch: 6| Step: 2
Training loss: 2.9956164360046387
Validation loss: 2.564104052000148

Epoch: 6| Step: 3
Training loss: 2.775479793548584
Validation loss: 2.5642550914518294

Epoch: 6| Step: 4
Training loss: 2.21897554397583
Validation loss: 2.5580994698309127

Epoch: 6| Step: 5
Training loss: 2.7394750118255615
Validation loss: 2.5590802828470864

Epoch: 6| Step: 6
Training loss: 3.041149616241455
Validation loss: 2.5590236674072924

Epoch: 6| Step: 7
Training loss: 3.783032178878784
Validation loss: 2.559786089005009

Epoch: 6| Step: 8
Training loss: 3.0602259635925293
Validation loss: 2.560185663161739

Epoch: 6| Step: 9
Training loss: 2.6544551849365234
Validation loss: 2.555165941997241

Epoch: 6| Step: 10
Training loss: 2.134766101837158
Validation loss: 2.555687827448691

Epoch: 6| Step: 11
Training loss: 2.671909809112549
Validation loss: 2.553783655166626

Epoch: 6| Step: 12
Training loss: 2.8355414867401123
Validation loss: 2.5545994184350453

Epoch: 6| Step: 13
Training loss: 2.430319309234619
Validation loss: 2.552551487440704

Epoch: 49| Step: 0
Training loss: 2.643270254135132
Validation loss: 2.5540256192607265

Epoch: 6| Step: 1
Training loss: 3.3530306816101074
Validation loss: 2.5577483279730684

Epoch: 6| Step: 2
Training loss: 2.4257869720458984
Validation loss: 2.5608284191418718

Epoch: 6| Step: 3
Training loss: 2.260190486907959
Validation loss: 2.5599773391600578

Epoch: 6| Step: 4
Training loss: 2.5259456634521484
Validation loss: 2.569138801226052

Epoch: 6| Step: 5
Training loss: 3.383650302886963
Validation loss: 2.565964183499736

Epoch: 6| Step: 6
Training loss: 2.590193033218384
Validation loss: 2.5562596756924867

Epoch: 6| Step: 7
Training loss: 2.9824962615966797
Validation loss: 2.548027051392422

Epoch: 6| Step: 8
Training loss: 2.9220969676971436
Validation loss: 2.545665612784765

Epoch: 6| Step: 9
Training loss: 2.7477264404296875
Validation loss: 2.5476012153010212

Epoch: 6| Step: 10
Training loss: 3.0540103912353516
Validation loss: 2.546807240414363

Epoch: 6| Step: 11
Training loss: 2.6351194381713867
Validation loss: 2.5455082206315893

Epoch: 6| Step: 12
Training loss: 2.2236688137054443
Validation loss: 2.547735926925495

Epoch: 6| Step: 13
Training loss: 2.263599395751953
Validation loss: 2.5414690253555134

Epoch: 50| Step: 0
Training loss: 2.050238609313965
Validation loss: 2.543951578037713

Epoch: 6| Step: 1
Training loss: 2.961711883544922
Validation loss: 2.548202032683998

Epoch: 6| Step: 2
Training loss: 3.2697434425354004
Validation loss: 2.548814394140756

Epoch: 6| Step: 3
Training loss: 2.5649445056915283
Validation loss: 2.5516176505755355

Epoch: 6| Step: 4
Training loss: 2.3202168941497803
Validation loss: 2.55617021488887

Epoch: 6| Step: 5
Training loss: 2.9278106689453125
Validation loss: 2.5532949688614055

Epoch: 6| Step: 6
Training loss: 2.736898899078369
Validation loss: 2.5543645069163334

Epoch: 6| Step: 7
Training loss: 3.7356042861938477
Validation loss: 2.561825483076034

Epoch: 6| Step: 8
Training loss: 2.241152286529541
Validation loss: 2.5568948689327446

Epoch: 6| Step: 9
Training loss: 2.521775245666504
Validation loss: 2.554435945326282

Epoch: 6| Step: 10
Training loss: 3.129512310028076
Validation loss: 2.5567066566918486

Epoch: 6| Step: 11
Training loss: 2.660723924636841
Validation loss: 2.553001783227408

Epoch: 6| Step: 12
Training loss: 1.996279001235962
Validation loss: 2.5469431979681856

Epoch: 6| Step: 13
Training loss: 3.165174722671509
Validation loss: 2.548508651794926

Epoch: 51| Step: 0
Training loss: 2.499492645263672
Validation loss: 2.542699021677817

Epoch: 6| Step: 1
Training loss: 3.654707431793213
Validation loss: 2.5412472422404955

Epoch: 6| Step: 2
Training loss: 2.3879189491271973
Validation loss: 2.538503146940662

Epoch: 6| Step: 3
Training loss: 3.397336959838867
Validation loss: 2.5441409387896137

Epoch: 6| Step: 4
Training loss: 2.9218785762786865
Validation loss: 2.5419974737269904

Epoch: 6| Step: 5
Training loss: 3.105196952819824
Validation loss: 2.5443738327231458

Epoch: 6| Step: 6
Training loss: 2.918989419937134
Validation loss: 2.5428645174990416

Epoch: 6| Step: 7
Training loss: 2.6009316444396973
Validation loss: 2.5399162564226376

Epoch: 6| Step: 8
Training loss: 1.607269525527954
Validation loss: 2.537655830383301

Epoch: 6| Step: 9
Training loss: 2.6428909301757812
Validation loss: 2.5376820666815645

Epoch: 6| Step: 10
Training loss: 2.501619815826416
Validation loss: 2.5352455903125066

Epoch: 6| Step: 11
Training loss: 2.2100489139556885
Validation loss: 2.531552363467473

Epoch: 6| Step: 12
Training loss: 3.176967144012451
Validation loss: 2.5309405301206853

Epoch: 6| Step: 13
Training loss: 2.2936949729919434
Validation loss: 2.529299610404558

Epoch: 52| Step: 0
Training loss: 2.2443246841430664
Validation loss: 2.5358732951584684

Epoch: 6| Step: 1
Training loss: 3.0749905109405518
Validation loss: 2.53391388539345

Epoch: 6| Step: 2
Training loss: 3.1270222663879395
Validation loss: 2.538716845614936

Epoch: 6| Step: 3
Training loss: 2.3568508625030518
Validation loss: 2.543146517968947

Epoch: 6| Step: 4
Training loss: 2.232163667678833
Validation loss: 2.538494410053376

Epoch: 6| Step: 5
Training loss: 2.447195529937744
Validation loss: 2.5377551714579263

Epoch: 6| Step: 6
Training loss: 2.027771472930908
Validation loss: 2.535591422870595

Epoch: 6| Step: 7
Training loss: 2.6250863075256348
Validation loss: 2.5361030999050347

Epoch: 6| Step: 8
Training loss: 3.0785531997680664
Validation loss: 2.530861998117098

Epoch: 6| Step: 9
Training loss: 3.1534037590026855
Validation loss: 2.5298362085896153

Epoch: 6| Step: 10
Training loss: 2.6803789138793945
Validation loss: 2.5290978377865208

Epoch: 6| Step: 11
Training loss: 2.8280043601989746
Validation loss: 2.5313214409735894

Epoch: 6| Step: 12
Training loss: 3.2511746883392334
Validation loss: 2.53382174686719

Epoch: 6| Step: 13
Training loss: 2.7940239906311035
Validation loss: 2.5371954300070323

Epoch: 53| Step: 0
Training loss: 2.9836723804473877
Validation loss: 2.537274109419956

Epoch: 6| Step: 1
Training loss: 2.9340720176696777
Validation loss: 2.535482906526135

Epoch: 6| Step: 2
Training loss: 2.370209217071533
Validation loss: 2.535914751791185

Epoch: 6| Step: 3
Training loss: 2.896172046661377
Validation loss: 2.533774429751981

Epoch: 6| Step: 4
Training loss: 3.154449462890625
Validation loss: 2.533723231284849

Epoch: 6| Step: 5
Training loss: 2.1064343452453613
Validation loss: 2.533532045220816

Epoch: 6| Step: 6
Training loss: 2.6736559867858887
Validation loss: 2.5295495910029255

Epoch: 6| Step: 7
Training loss: 2.6273207664489746
Validation loss: 2.526957027373775

Epoch: 6| Step: 8
Training loss: 2.008047580718994
Validation loss: 2.526597635720366

Epoch: 6| Step: 9
Training loss: 4.079786777496338
Validation loss: 2.529302789318946

Epoch: 6| Step: 10
Training loss: 2.7695200443267822
Validation loss: 2.534044396492743

Epoch: 6| Step: 11
Training loss: 1.8251217603683472
Validation loss: 2.532896803271386

Epoch: 6| Step: 12
Training loss: 2.789537191390991
Validation loss: 2.530622572027227

Epoch: 6| Step: 13
Training loss: 2.8497776985168457
Validation loss: 2.531823577419404

Epoch: 54| Step: 0
Training loss: 2.455444097518921
Validation loss: 2.5279170261916293

Epoch: 6| Step: 1
Training loss: 3.2287960052490234
Validation loss: 2.5270075157124507

Epoch: 6| Step: 2
Training loss: 2.500971555709839
Validation loss: 2.524922752893099

Epoch: 6| Step: 3
Training loss: 3.8290092945098877
Validation loss: 2.5281164466693835

Epoch: 6| Step: 4
Training loss: 2.8913002014160156
Validation loss: 2.5282178950566117

Epoch: 6| Step: 5
Training loss: 2.4775302410125732
Validation loss: 2.5297792368037726

Epoch: 6| Step: 6
Training loss: 1.8932064771652222
Validation loss: 2.5285299849766556

Epoch: 6| Step: 7
Training loss: 1.9683737754821777
Validation loss: 2.5275215615508375

Epoch: 6| Step: 8
Training loss: 2.6249852180480957
Validation loss: 2.5265760806299027

Epoch: 6| Step: 9
Training loss: 2.494182825088501
Validation loss: 2.5251270878699517

Epoch: 6| Step: 10
Training loss: 2.2485532760620117
Validation loss: 2.530898501796107

Epoch: 6| Step: 11
Training loss: 3.254326581954956
Validation loss: 2.5328598894098753

Epoch: 6| Step: 12
Training loss: 3.0502657890319824
Validation loss: 2.5255600201186312

Epoch: 6| Step: 13
Training loss: 3.271611213684082
Validation loss: 2.5216987773936284

Epoch: 55| Step: 0
Training loss: 2.83119797706604
Validation loss: 2.521211093471896

Epoch: 6| Step: 1
Training loss: 2.771958112716675
Validation loss: 2.5193403074818272

Epoch: 6| Step: 2
Training loss: 2.5973896980285645
Validation loss: 2.523211702223747

Epoch: 6| Step: 3
Training loss: 2.4601473808288574
Validation loss: 2.5285662169097574

Epoch: 6| Step: 4
Training loss: 2.3833529949188232
Validation loss: 2.526341954867045

Epoch: 6| Step: 5
Training loss: 2.594532012939453
Validation loss: 2.5281054922329482

Epoch: 6| Step: 6
Training loss: 2.6508402824401855
Validation loss: 2.5226371801027687

Epoch: 6| Step: 7
Training loss: 3.027311086654663
Validation loss: 2.5204253299261934

Epoch: 6| Step: 8
Training loss: 1.7641650438308716
Validation loss: 2.51995115382697

Epoch: 6| Step: 9
Training loss: 2.823598861694336
Validation loss: 2.5184469838296213

Epoch: 6| Step: 10
Training loss: 2.961308002471924
Validation loss: 2.521870482352472

Epoch: 6| Step: 11
Training loss: 3.598829746246338
Validation loss: 2.5191835741842947

Epoch: 6| Step: 12
Training loss: 3.190624237060547
Validation loss: 2.518964577746648

Epoch: 6| Step: 13
Training loss: 1.812540888786316
Validation loss: 2.519013422791676

Epoch: 56| Step: 0
Training loss: 2.5435125827789307
Validation loss: 2.5205707344957577

Epoch: 6| Step: 1
Training loss: 2.6512792110443115
Validation loss: 2.521663360698249

Epoch: 6| Step: 2
Training loss: 2.8465232849121094
Validation loss: 2.521669667254212

Epoch: 6| Step: 3
Training loss: 2.219425678253174
Validation loss: 2.529588991595853

Epoch: 6| Step: 4
Training loss: 2.406567096710205
Validation loss: 2.5346741419966503

Epoch: 6| Step: 5
Training loss: 2.86124324798584
Validation loss: 2.5444231648598947

Epoch: 6| Step: 6
Training loss: 3.1180367469787598
Validation loss: 2.5308564196350756

Epoch: 6| Step: 7
Training loss: 2.9627296924591064
Validation loss: 2.528762530255061

Epoch: 6| Step: 8
Training loss: 2.8704445362091064
Validation loss: 2.522929932481499

Epoch: 6| Step: 9
Training loss: 3.050642490386963
Validation loss: 2.5193784775272494

Epoch: 6| Step: 10
Training loss: 2.7296605110168457
Validation loss: 2.5161351362864175

Epoch: 6| Step: 11
Training loss: 2.0991976261138916
Validation loss: 2.522254482392342

Epoch: 6| Step: 12
Training loss: 2.8074519634246826
Validation loss: 2.525581452154344

Epoch: 6| Step: 13
Training loss: 2.8392105102539062
Validation loss: 2.5270810434895177

Epoch: 57| Step: 0
Training loss: 2.9647393226623535
Validation loss: 2.518868238695206

Epoch: 6| Step: 1
Training loss: 2.617475986480713
Validation loss: 2.516943957215996

Epoch: 6| Step: 2
Training loss: 3.068751811981201
Validation loss: 2.5145797242400465

Epoch: 6| Step: 3
Training loss: 2.6073672771453857
Validation loss: 2.509878412369759

Epoch: 6| Step: 4
Training loss: 2.847235679626465
Validation loss: 2.5093337207712154

Epoch: 6| Step: 5
Training loss: 2.8719725608825684
Validation loss: 2.510087787464101

Epoch: 6| Step: 6
Training loss: 2.439126491546631
Validation loss: 2.510660722691526

Epoch: 6| Step: 7
Training loss: 3.182934284210205
Validation loss: 2.507373550886749

Epoch: 6| Step: 8
Training loss: 2.644099712371826
Validation loss: 2.5104482532829366

Epoch: 6| Step: 9
Training loss: 2.6764490604400635
Validation loss: 2.5163659600801367

Epoch: 6| Step: 10
Training loss: 2.789879322052002
Validation loss: 2.5187678849825295

Epoch: 6| Step: 11
Training loss: 1.551900863647461
Validation loss: 2.5209943056106567

Epoch: 6| Step: 12
Training loss: 2.7399048805236816
Validation loss: 2.517277697081207

Epoch: 6| Step: 13
Training loss: 2.860836982727051
Validation loss: 2.510048971381239

Epoch: 58| Step: 0
Training loss: 2.250131368637085
Validation loss: 2.5141904713005148

Epoch: 6| Step: 1
Training loss: 2.2641923427581787
Validation loss: 2.5187869815416235

Epoch: 6| Step: 2
Training loss: 2.996516227722168
Validation loss: 2.5267030526232976

Epoch: 6| Step: 3
Training loss: 3.208221197128296
Validation loss: 2.5195078183245916

Epoch: 6| Step: 4
Training loss: 2.68806529045105
Validation loss: 2.5121400433201946

Epoch: 6| Step: 5
Training loss: 2.7438080310821533
Validation loss: 2.50940018059105

Epoch: 6| Step: 6
Training loss: 3.2988572120666504
Validation loss: 2.505811745120633

Epoch: 6| Step: 7
Training loss: 2.5686697959899902
Validation loss: 2.5064905023062103

Epoch: 6| Step: 8
Training loss: 2.834658622741699
Validation loss: 2.5058961427339943

Epoch: 6| Step: 9
Training loss: 2.9264349937438965
Validation loss: 2.5050421504564184

Epoch: 6| Step: 10
Training loss: 2.255296230316162
Validation loss: 2.5013810742285942

Epoch: 6| Step: 11
Training loss: 2.3108835220336914
Validation loss: 2.501347513609035

Epoch: 6| Step: 12
Training loss: 2.8414652347564697
Validation loss: 2.501386022055021

Epoch: 6| Step: 13
Training loss: 2.405635356903076
Validation loss: 2.5004962785269624

Epoch: 59| Step: 0
Training loss: 2.396256685256958
Validation loss: 2.5001237623153196

Epoch: 6| Step: 1
Training loss: 3.008408308029175
Validation loss: 2.500070746226977

Epoch: 6| Step: 2
Training loss: 2.5652801990509033
Validation loss: 2.4983764515128186

Epoch: 6| Step: 3
Training loss: 3.7859997749328613
Validation loss: 2.4987548781979467

Epoch: 6| Step: 4
Training loss: 2.037034749984741
Validation loss: 2.499476150799823

Epoch: 6| Step: 5
Training loss: 2.406153440475464
Validation loss: 2.503908521385603

Epoch: 6| Step: 6
Training loss: 3.328373908996582
Validation loss: 2.504870722370763

Epoch: 6| Step: 7
Training loss: 2.268519639968872
Validation loss: 2.503607537156792

Epoch: 6| Step: 8
Training loss: 2.9376449584960938
Validation loss: 2.509219302926012

Epoch: 6| Step: 9
Training loss: 3.0065531730651855
Validation loss: 2.511352341662171

Epoch: 6| Step: 10
Training loss: 1.989502191543579
Validation loss: 2.519223866924163

Epoch: 6| Step: 11
Training loss: 2.34639310836792
Validation loss: 2.526754735618509

Epoch: 6| Step: 12
Training loss: 2.5965614318847656
Validation loss: 2.52879657283906

Epoch: 6| Step: 13
Training loss: 3.3123674392700195
Validation loss: 2.522055169587494

Epoch: 60| Step: 0
Training loss: 2.7605509757995605
Validation loss: 2.5088036162878877

Epoch: 6| Step: 1
Training loss: 3.8134775161743164
Validation loss: 2.498441937149212

Epoch: 6| Step: 2
Training loss: 1.8888596296310425
Validation loss: 2.498353765856835

Epoch: 6| Step: 3
Training loss: 2.5986056327819824
Validation loss: 2.495847907117618

Epoch: 6| Step: 4
Training loss: 2.902421712875366
Validation loss: 2.4953468640645347

Epoch: 6| Step: 5
Training loss: 3.7796947956085205
Validation loss: 2.4977823483046664

Epoch: 6| Step: 6
Training loss: 1.941590428352356
Validation loss: 2.5033999181562856

Epoch: 6| Step: 7
Training loss: 2.1617119312286377
Validation loss: 2.5031175433948474

Epoch: 6| Step: 8
Training loss: 2.407274007797241
Validation loss: 2.4998812470384824

Epoch: 6| Step: 9
Training loss: 2.4974172115325928
Validation loss: 2.4951621178657777

Epoch: 6| Step: 10
Training loss: 2.0542895793914795
Validation loss: 2.4946463031153523

Epoch: 6| Step: 11
Training loss: 3.1041550636291504
Validation loss: 2.493784469942893

Epoch: 6| Step: 12
Training loss: 3.3071656227111816
Validation loss: 2.492449078508603

Epoch: 6| Step: 13
Training loss: 2.474177598953247
Validation loss: 2.4939997209015714

Epoch: 61| Step: 0
Training loss: 2.348146915435791
Validation loss: 2.494614360153034

Epoch: 6| Step: 1
Training loss: 3.042933464050293
Validation loss: 2.5055091329800185

Epoch: 6| Step: 2
Training loss: 3.2071480751037598
Validation loss: 2.510456895315519

Epoch: 6| Step: 3
Training loss: 2.602024555206299
Validation loss: 2.53480290853849

Epoch: 6| Step: 4
Training loss: 2.3970022201538086
Validation loss: 2.5516347116039646

Epoch: 6| Step: 5
Training loss: 2.330578327178955
Validation loss: 2.555228087209886

Epoch: 6| Step: 6
Training loss: 2.957383871078491
Validation loss: 2.531505097625076

Epoch: 6| Step: 7
Training loss: 3.7277517318725586
Validation loss: 2.5075603095434045

Epoch: 6| Step: 8
Training loss: 2.1529300212860107
Validation loss: 2.49313525999746

Epoch: 6| Step: 9
Training loss: 3.2642040252685547
Validation loss: 2.4881516784750004

Epoch: 6| Step: 10
Training loss: 1.8553818464279175
Validation loss: 2.489466109583455

Epoch: 6| Step: 11
Training loss: 2.179792881011963
Validation loss: 2.4861025528241227

Epoch: 6| Step: 12
Training loss: 3.238591194152832
Validation loss: 2.4892164379037838

Epoch: 6| Step: 13
Training loss: 2.2541306018829346
Validation loss: 2.4848680880761917

Epoch: 62| Step: 0
Training loss: 2.2250914573669434
Validation loss: 2.4855505317770024

Epoch: 6| Step: 1
Training loss: 2.700493097305298
Validation loss: 2.4835895517820954

Epoch: 6| Step: 2
Training loss: 3.540614604949951
Validation loss: 2.483399744956724

Epoch: 6| Step: 3
Training loss: 2.5557351112365723
Validation loss: 2.487544923700312

Epoch: 6| Step: 4
Training loss: 2.8593297004699707
Validation loss: 2.486727701720371

Epoch: 6| Step: 5
Training loss: 2.156480550765991
Validation loss: 2.485649267832438

Epoch: 6| Step: 6
Training loss: 2.6735286712646484
Validation loss: 2.4908095918675905

Epoch: 6| Step: 7
Training loss: 2.5563321113586426
Validation loss: 2.4900753100713096

Epoch: 6| Step: 8
Training loss: 2.629502534866333
Validation loss: 2.4901207147106046

Epoch: 6| Step: 9
Training loss: 3.361778736114502
Validation loss: 2.4878729825378745

Epoch: 6| Step: 10
Training loss: 3.032740592956543
Validation loss: 2.4887639220042894

Epoch: 6| Step: 11
Training loss: 2.4845752716064453
Validation loss: 2.485936609647607

Epoch: 6| Step: 12
Training loss: 2.081026554107666
Validation loss: 2.4838438469876527

Epoch: 6| Step: 13
Training loss: 2.776047706604004
Validation loss: 2.484083678132744

Epoch: 63| Step: 0
Training loss: 1.91166090965271
Validation loss: 2.4823728684456117

Epoch: 6| Step: 1
Training loss: 3.4622440338134766
Validation loss: 2.4845714748546643

Epoch: 6| Step: 2
Training loss: 3.093320369720459
Validation loss: 2.4821485652718493

Epoch: 6| Step: 3
Training loss: 2.3369007110595703
Validation loss: 2.4833834581477667

Epoch: 6| Step: 4
Training loss: 2.78456449508667
Validation loss: 2.4805547011795865

Epoch: 6| Step: 5
Training loss: 3.09818696975708
Validation loss: 2.484115473685726

Epoch: 6| Step: 6
Training loss: 3.2406508922576904
Validation loss: 2.485926397385136

Epoch: 6| Step: 7
Training loss: 3.0509026050567627
Validation loss: 2.486154105073662

Epoch: 6| Step: 8
Training loss: 2.2767562866210938
Validation loss: 2.486111758857645

Epoch: 6| Step: 9
Training loss: 2.203958034515381
Validation loss: 2.4865328111956195

Epoch: 6| Step: 10
Training loss: 2.5612528324127197
Validation loss: 2.4820467067021195

Epoch: 6| Step: 11
Training loss: 3.0445120334625244
Validation loss: 2.48321258893577

Epoch: 6| Step: 12
Training loss: 2.361760139465332
Validation loss: 2.483243224441364

Epoch: 6| Step: 13
Training loss: 1.62045156955719
Validation loss: 2.4891111030373523

Epoch: 64| Step: 0
Training loss: 2.9991114139556885
Validation loss: 2.4912993420836744

Epoch: 6| Step: 1
Training loss: 3.3374814987182617
Validation loss: 2.492352993257584

Epoch: 6| Step: 2
Training loss: 3.065138101577759
Validation loss: 2.4963335324359197

Epoch: 6| Step: 3
Training loss: 2.2465147972106934
Validation loss: 2.4967784317590858

Epoch: 6| Step: 4
Training loss: 2.7855560779571533
Validation loss: 2.4921046918438328

Epoch: 6| Step: 5
Training loss: 1.8233520984649658
Validation loss: 2.491501236474642

Epoch: 6| Step: 6
Training loss: 2.0621323585510254
Validation loss: 2.4848489658806914

Epoch: 6| Step: 7
Training loss: 3.672168254852295
Validation loss: 2.4811455024186

Epoch: 6| Step: 8
Training loss: 1.8451085090637207
Validation loss: 2.48386622500676

Epoch: 6| Step: 9
Training loss: 2.379542112350464
Validation loss: 2.4841642866852465

Epoch: 6| Step: 10
Training loss: 3.6128315925598145
Validation loss: 2.4837965273088023

Epoch: 6| Step: 11
Training loss: 2.2920212745666504
Validation loss: 2.485439287718906

Epoch: 6| Step: 12
Training loss: 3.0216548442840576
Validation loss: 2.485626256594094

Epoch: 6| Step: 13
Training loss: 1.992805004119873
Validation loss: 2.491600774949597

Epoch: 65| Step: 0
Training loss: 3.216780424118042
Validation loss: 2.489858929828931

Epoch: 6| Step: 1
Training loss: 3.214601755142212
Validation loss: 2.4879644301629837

Epoch: 6| Step: 2
Training loss: 2.274657964706421
Validation loss: 2.482957770747523

Epoch: 6| Step: 3
Training loss: 2.649308204650879
Validation loss: 2.478131845433225

Epoch: 6| Step: 4
Training loss: 2.743685245513916
Validation loss: 2.473199644396382

Epoch: 6| Step: 5
Training loss: 2.943918466567993
Validation loss: 2.4768828781702186

Epoch: 6| Step: 6
Training loss: 2.801028251647949
Validation loss: 2.4766169850544264

Epoch: 6| Step: 7
Training loss: 2.2451300621032715
Validation loss: 2.475533591803684

Epoch: 6| Step: 8
Training loss: 2.140204906463623
Validation loss: 2.475660780424713

Epoch: 6| Step: 9
Training loss: 2.6750495433807373
Validation loss: 2.4775491094076507

Epoch: 6| Step: 10
Training loss: 2.7555551528930664
Validation loss: 2.4816678647072083

Epoch: 6| Step: 11
Training loss: 2.615705966949463
Validation loss: 2.474050719250915

Epoch: 6| Step: 12
Training loss: 2.506089210510254
Validation loss: 2.476290141382525

Epoch: 6| Step: 13
Training loss: 2.6072986125946045
Validation loss: 2.4790735424205823

Epoch: 66| Step: 0
Training loss: 3.25860595703125
Validation loss: 2.478189404292773

Epoch: 6| Step: 1
Training loss: 2.8725180625915527
Validation loss: 2.476561056670322

Epoch: 6| Step: 2
Training loss: 3.4328665733337402
Validation loss: 2.4750796415472545

Epoch: 6| Step: 3
Training loss: 2.4980568885803223
Validation loss: 2.477091266262916

Epoch: 6| Step: 4
Training loss: 2.6570467948913574
Validation loss: 2.4793855092858754

Epoch: 6| Step: 5
Training loss: 2.8517746925354004
Validation loss: 2.4778772297725884

Epoch: 6| Step: 6
Training loss: 2.6389198303222656
Validation loss: 2.48080631994432

Epoch: 6| Step: 7
Training loss: 2.004380226135254
Validation loss: 2.487127547623009

Epoch: 6| Step: 8
Training loss: 3.3173136711120605
Validation loss: 2.48750195195598

Epoch: 6| Step: 9
Training loss: 2.2594456672668457
Validation loss: 2.4944179955349175

Epoch: 6| Step: 10
Training loss: 2.2926578521728516
Validation loss: 2.48868824589637

Epoch: 6| Step: 11
Training loss: 2.6364924907684326
Validation loss: 2.4869191518393894

Epoch: 6| Step: 12
Training loss: 2.5504648685455322
Validation loss: 2.4784013481550318

Epoch: 6| Step: 13
Training loss: 1.6996722221374512
Validation loss: 2.476092561598747

Epoch: 67| Step: 0
Training loss: 2.772641897201538
Validation loss: 2.467194805863083

Epoch: 6| Step: 1
Training loss: 2.1547741889953613
Validation loss: 2.4690851678130445

Epoch: 6| Step: 2
Training loss: 2.197920322418213
Validation loss: 2.4706181300583707

Epoch: 6| Step: 3
Training loss: 2.5703468322753906
Validation loss: 2.4702126672191005

Epoch: 6| Step: 4
Training loss: 2.8916537761688232
Validation loss: 2.4699819472528275

Epoch: 6| Step: 5
Training loss: 2.2613296508789062
Validation loss: 2.472403774979294

Epoch: 6| Step: 6
Training loss: 2.403995990753174
Validation loss: 2.468686931876726

Epoch: 6| Step: 7
Training loss: 2.582085132598877
Validation loss: 2.4693517813118557

Epoch: 6| Step: 8
Training loss: 3.5242395401000977
Validation loss: 2.4709199910522788

Epoch: 6| Step: 9
Training loss: 3.0972561836242676
Validation loss: 2.4691639638716176

Epoch: 6| Step: 10
Training loss: 1.9816176891326904
Validation loss: 2.4702386984261135

Epoch: 6| Step: 11
Training loss: 2.9452219009399414
Validation loss: 2.4767173567125873

Epoch: 6| Step: 12
Training loss: 3.4306888580322266
Validation loss: 2.4796026470840618

Epoch: 6| Step: 13
Training loss: 2.4655921459198
Validation loss: 2.4850489785594325

Epoch: 68| Step: 0
Training loss: 2.3846750259399414
Validation loss: 2.4908649511234735

Epoch: 6| Step: 1
Training loss: 2.8554069995880127
Validation loss: 2.486815260302636

Epoch: 6| Step: 2
Training loss: 2.7724483013153076
Validation loss: 2.477960737802649

Epoch: 6| Step: 3
Training loss: 2.333390712738037
Validation loss: 2.468047190737981

Epoch: 6| Step: 4
Training loss: 3.131796360015869
Validation loss: 2.4659558085985083

Epoch: 6| Step: 5
Training loss: 2.490231990814209
Validation loss: 2.468611717224121

Epoch: 6| Step: 6
Training loss: 3.7661852836608887
Validation loss: 2.466633412145799

Epoch: 6| Step: 7
Training loss: 2.2296695709228516
Validation loss: 2.463801017371557

Epoch: 6| Step: 8
Training loss: 2.875744342803955
Validation loss: 2.4634804802556194

Epoch: 6| Step: 9
Training loss: 1.6037049293518066
Validation loss: 2.4632907529031076

Epoch: 6| Step: 10
Training loss: 2.6584365367889404
Validation loss: 2.4780574152546544

Epoch: 6| Step: 11
Training loss: 3.3339622020721436
Validation loss: 2.4952542756193425

Epoch: 6| Step: 12
Training loss: 2.347623586654663
Validation loss: 2.506375922951647

Epoch: 6| Step: 13
Training loss: 2.824871301651001
Validation loss: 2.4964670186401694

Epoch: 69| Step: 0
Training loss: 3.3181512355804443
Validation loss: 2.497060580920148

Epoch: 6| Step: 1
Training loss: 3.4402174949645996
Validation loss: 2.4808147415038078

Epoch: 6| Step: 2
Training loss: 3.699277400970459
Validation loss: 2.4737207966466106

Epoch: 6| Step: 3
Training loss: 2.7334063053131104
Validation loss: 2.465573497997817

Epoch: 6| Step: 4
Training loss: 2.14009428024292
Validation loss: 2.462261410169704

Epoch: 6| Step: 5
Training loss: 3.114900588989258
Validation loss: 2.4616907027459916

Epoch: 6| Step: 6
Training loss: 2.7806153297424316
Validation loss: 2.4621251911245365

Epoch: 6| Step: 7
Training loss: 2.1458072662353516
Validation loss: 2.4626072863096833

Epoch: 6| Step: 8
Training loss: 1.932261347770691
Validation loss: 2.4674484165765906

Epoch: 6| Step: 9
Training loss: 2.3998472690582275
Validation loss: 2.4639689742877917

Epoch: 6| Step: 10
Training loss: 2.2500996589660645
Validation loss: 2.467753884612873

Epoch: 6| Step: 11
Training loss: 2.138856887817383
Validation loss: 2.466453226663733

Epoch: 6| Step: 12
Training loss: 2.5933218002319336
Validation loss: 2.469141132088118

Epoch: 6| Step: 13
Training loss: 2.6678526401519775
Validation loss: 2.4805331999255764

Epoch: 70| Step: 0
Training loss: 2.8145103454589844
Validation loss: 2.4727021109673286

Epoch: 6| Step: 1
Training loss: 2.8517212867736816
Validation loss: 2.4728192719080115

Epoch: 6| Step: 2
Training loss: 2.9344606399536133
Validation loss: 2.476873343990695

Epoch: 6| Step: 3
Training loss: 2.382072687149048
Validation loss: 2.4701624121717227

Epoch: 6| Step: 4
Training loss: 2.345227003097534
Validation loss: 2.468446623894476

Epoch: 6| Step: 5
Training loss: 2.737751007080078
Validation loss: 2.466918396693404

Epoch: 6| Step: 6
Training loss: 3.0797247886657715
Validation loss: 2.4637798929727204

Epoch: 6| Step: 7
Training loss: 2.481165885925293
Validation loss: 2.4578621925846225

Epoch: 6| Step: 8
Training loss: 2.8597493171691895
Validation loss: 2.460550526136993

Epoch: 6| Step: 9
Training loss: 2.6006548404693604
Validation loss: 2.459839082533313

Epoch: 6| Step: 10
Training loss: 2.4550328254699707
Validation loss: 2.4617009265448457

Epoch: 6| Step: 11
Training loss: 2.77138614654541
Validation loss: 2.461626660439276

Epoch: 6| Step: 12
Training loss: 2.3587281703948975
Validation loss: 2.4668390417611725

Epoch: 6| Step: 13
Training loss: 2.521091938018799
Validation loss: 2.463913525304487

Epoch: 71| Step: 0
Training loss: 2.881808042526245
Validation loss: 2.4676534257909304

Epoch: 6| Step: 1
Training loss: 2.7111592292785645
Validation loss: 2.4647472648210424

Epoch: 6| Step: 2
Training loss: 2.978212833404541
Validation loss: 2.4704598585764566

Epoch: 6| Step: 3
Training loss: 2.274616241455078
Validation loss: 2.4731392091320408

Epoch: 6| Step: 4
Training loss: 1.9473564624786377
Validation loss: 2.483951458366968

Epoch: 6| Step: 5
Training loss: 2.9335427284240723
Validation loss: 2.4825930928671234

Epoch: 6| Step: 6
Training loss: 3.5188679695129395
Validation loss: 2.474303453199325

Epoch: 6| Step: 7
Training loss: 1.5285053253173828
Validation loss: 2.4622443465776342

Epoch: 6| Step: 8
Training loss: 2.8380136489868164
Validation loss: 2.452857881463984

Epoch: 6| Step: 9
Training loss: 3.2114949226379395
Validation loss: 2.4583511121811403

Epoch: 6| Step: 10
Training loss: 2.1851279735565186
Validation loss: 2.456918047320458

Epoch: 6| Step: 11
Training loss: 2.4837536811828613
Validation loss: 2.4591493427112536

Epoch: 6| Step: 12
Training loss: 3.335663318634033
Validation loss: 2.459990111730432

Epoch: 6| Step: 13
Training loss: 2.4223685264587402
Validation loss: 2.4615295061501126

Epoch: 72| Step: 0
Training loss: 2.955160617828369
Validation loss: 2.461731074958719

Epoch: 6| Step: 1
Training loss: 2.4513096809387207
Validation loss: 2.4579738032433296

Epoch: 6| Step: 2
Training loss: 3.005819082260132
Validation loss: 2.4536778567939677

Epoch: 6| Step: 3
Training loss: 2.290806293487549
Validation loss: 2.456731173299974

Epoch: 6| Step: 4
Training loss: 2.8020787239074707
Validation loss: 2.45626111056215

Epoch: 6| Step: 5
Training loss: 2.5707895755767822
Validation loss: 2.4698778044792915

Epoch: 6| Step: 6
Training loss: 3.077162742614746
Validation loss: 2.485818645005585

Epoch: 6| Step: 7
Training loss: 1.8351569175720215
Validation loss: 2.483593181897235

Epoch: 6| Step: 8
Training loss: 1.7905707359313965
Validation loss: 2.476628383000692

Epoch: 6| Step: 9
Training loss: 2.898348808288574
Validation loss: 2.4627865975902927

Epoch: 6| Step: 10
Training loss: 2.7873287200927734
Validation loss: 2.45424771693445

Epoch: 6| Step: 11
Training loss: 3.5367088317871094
Validation loss: 2.4521902889333744

Epoch: 6| Step: 12
Training loss: 2.788517475128174
Validation loss: 2.457112853245069

Epoch: 6| Step: 13
Training loss: 2.548191785812378
Validation loss: 2.457279292486047

Epoch: 73| Step: 0
Training loss: 2.5104198455810547
Validation loss: 2.4560107261903825

Epoch: 6| Step: 1
Training loss: 2.5399599075317383
Validation loss: 2.4580610875160462

Epoch: 6| Step: 2
Training loss: 2.338869333267212
Validation loss: 2.4565614269625757

Epoch: 6| Step: 3
Training loss: 3.1636223793029785
Validation loss: 2.453084466277912

Epoch: 6| Step: 4
Training loss: 2.9490392208099365
Validation loss: 2.4530751935897337

Epoch: 6| Step: 5
Training loss: 1.765042781829834
Validation loss: 2.454260315946353

Epoch: 6| Step: 6
Training loss: 2.826943874359131
Validation loss: 2.4576294165785595

Epoch: 6| Step: 7
Training loss: 2.854705572128296
Validation loss: 2.466424321615568

Epoch: 6| Step: 8
Training loss: 2.4802327156066895
Validation loss: 2.4741557003349386

Epoch: 6| Step: 9
Training loss: 2.913248062133789
Validation loss: 2.478858999026719

Epoch: 6| Step: 10
Training loss: 2.370387315750122
Validation loss: 2.503476324901786

Epoch: 6| Step: 11
Training loss: 2.715655565261841
Validation loss: 2.533022757499449

Epoch: 6| Step: 12
Training loss: 3.1211204528808594
Validation loss: 2.5432933248499388

Epoch: 6| Step: 13
Training loss: 3.0822761058807373
Validation loss: 2.52469220981803

Epoch: 74| Step: 0
Training loss: 2.4692723751068115
Validation loss: 2.496963180521483

Epoch: 6| Step: 1
Training loss: 2.6153759956359863
Validation loss: 2.4851624042757097

Epoch: 6| Step: 2
Training loss: 2.350039482116699
Validation loss: 2.482937500041018

Epoch: 6| Step: 3
Training loss: 3.164335250854492
Validation loss: 2.4711027786295903

Epoch: 6| Step: 4
Training loss: 2.3898324966430664
Validation loss: 2.46638382891173

Epoch: 6| Step: 5
Training loss: 3.1661601066589355
Validation loss: 2.4646175343503236

Epoch: 6| Step: 6
Training loss: 2.9936084747314453
Validation loss: 2.4532310937040593

Epoch: 6| Step: 7
Training loss: 2.9510951042175293
Validation loss: 2.454310114665698

Epoch: 6| Step: 8
Training loss: 2.612595558166504
Validation loss: 2.4516659013686644

Epoch: 6| Step: 9
Training loss: 2.496171474456787
Validation loss: 2.4510713443961194

Epoch: 6| Step: 10
Training loss: 2.5607688426971436
Validation loss: 2.4508674606200187

Epoch: 6| Step: 11
Training loss: 2.021000385284424
Validation loss: 2.4522161176127772

Epoch: 6| Step: 12
Training loss: 2.7169878482818604
Validation loss: 2.448315671695176

Epoch: 6| Step: 13
Training loss: 2.4675912857055664
Validation loss: 2.4489024018728607

Epoch: 75| Step: 0
Training loss: 3.2213637828826904
Validation loss: 2.442147207516496

Epoch: 6| Step: 1
Training loss: 2.379462242126465
Validation loss: 2.4400103733103764

Epoch: 6| Step: 2
Training loss: 2.698512077331543
Validation loss: 2.442678210555866

Epoch: 6| Step: 3
Training loss: 3.4334120750427246
Validation loss: 2.4403661720214354

Epoch: 6| Step: 4
Training loss: 3.1626431941986084
Validation loss: 2.438243040474512

Epoch: 6| Step: 5
Training loss: 2.4219160079956055
Validation loss: 2.4392335414886475

Epoch: 6| Step: 6
Training loss: 2.3993852138519287
Validation loss: 2.4395959531107256

Epoch: 6| Step: 7
Training loss: 2.4090044498443604
Validation loss: 2.44244872882802

Epoch: 6| Step: 8
Training loss: 2.3027169704437256
Validation loss: 2.4380623935371317

Epoch: 6| Step: 9
Training loss: 2.145925283432007
Validation loss: 2.441494587929018

Epoch: 6| Step: 10
Training loss: 2.4579713344573975
Validation loss: 2.4449444714412896

Epoch: 6| Step: 11
Training loss: 2.503303289413452
Validation loss: 2.447075669483472

Epoch: 6| Step: 12
Training loss: 2.6543335914611816
Validation loss: 2.439145234323317

Epoch: 6| Step: 13
Training loss: 3.174454689025879
Validation loss: 2.44758318572916

Epoch: 76| Step: 0
Training loss: 2.6712398529052734
Validation loss: 2.447288110692014

Epoch: 6| Step: 1
Training loss: 2.2418432235717773
Validation loss: 2.4514947578471196

Epoch: 6| Step: 2
Training loss: 2.5742034912109375
Validation loss: 2.450372744632024

Epoch: 6| Step: 3
Training loss: 2.3551416397094727
Validation loss: 2.442199922377063

Epoch: 6| Step: 4
Training loss: 2.0379738807678223
Validation loss: 2.4381400128846527

Epoch: 6| Step: 5
Training loss: 2.9068961143493652
Validation loss: 2.4366855313701015

Epoch: 6| Step: 6
Training loss: 2.6432721614837646
Validation loss: 2.43639366344739

Epoch: 6| Step: 7
Training loss: 3.3870761394500732
Validation loss: 2.43887206174994

Epoch: 6| Step: 8
Training loss: 2.4412078857421875
Validation loss: 2.4429954046844156

Epoch: 6| Step: 9
Training loss: 3.1081490516662598
Validation loss: 2.4406841365239953

Epoch: 6| Step: 10
Training loss: 2.378955602645874
Validation loss: 2.4392539942136375

Epoch: 6| Step: 11
Training loss: 3.1813135147094727
Validation loss: 2.44136623156968

Epoch: 6| Step: 12
Training loss: 2.5194597244262695
Validation loss: 2.437019791654361

Epoch: 6| Step: 13
Training loss: 2.793231964111328
Validation loss: 2.437330335699102

Epoch: 77| Step: 0
Training loss: 3.0577287673950195
Validation loss: 2.4324379351831253

Epoch: 6| Step: 1
Training loss: 2.0485291481018066
Validation loss: 2.4354707964005007

Epoch: 6| Step: 2
Training loss: 2.7736313343048096
Validation loss: 2.445540681962044

Epoch: 6| Step: 3
Training loss: 2.3601605892181396
Validation loss: 2.466126072791315

Epoch: 6| Step: 4
Training loss: 2.0856239795684814
Validation loss: 2.478136049803867

Epoch: 6| Step: 5
Training loss: 2.6715004444122314
Validation loss: 2.472839727196642

Epoch: 6| Step: 6
Training loss: 3.0794765949249268
Validation loss: 2.471352018335814

Epoch: 6| Step: 7
Training loss: 3.007617950439453
Validation loss: 2.453359839736774

Epoch: 6| Step: 8
Training loss: 2.6210765838623047
Validation loss: 2.441041536228631

Epoch: 6| Step: 9
Training loss: 3.0700876712799072
Validation loss: 2.433993431829637

Epoch: 6| Step: 10
Training loss: 2.796555280685425
Validation loss: 2.428369842549806

Epoch: 6| Step: 11
Training loss: 2.018636703491211
Validation loss: 2.429966111336985

Epoch: 6| Step: 12
Training loss: 2.8953866958618164
Validation loss: 2.4321009805125575

Epoch: 6| Step: 13
Training loss: 2.8373939990997314
Validation loss: 2.431642896385603

Epoch: 78| Step: 0
Training loss: 2.5570805072784424
Validation loss: 2.44001583386493

Epoch: 6| Step: 1
Training loss: 1.0869015455245972
Validation loss: 2.4418014198221187

Epoch: 6| Step: 2
Training loss: 2.2996692657470703
Validation loss: 2.4545905154238463

Epoch: 6| Step: 3
Training loss: 2.706651210784912
Validation loss: 2.4715891704764417

Epoch: 6| Step: 4
Training loss: 2.753704786300659
Validation loss: 2.4788970331991873

Epoch: 6| Step: 5
Training loss: 2.503600597381592
Validation loss: 2.4716293657979658

Epoch: 6| Step: 6
Training loss: 3.201697826385498
Validation loss: 2.462533284259099

Epoch: 6| Step: 7
Training loss: 2.744772434234619
Validation loss: 2.4687264555244037

Epoch: 6| Step: 8
Training loss: 2.4989352226257324
Validation loss: 2.455139337047454

Epoch: 6| Step: 9
Training loss: 2.739589214324951
Validation loss: 2.447770095640613

Epoch: 6| Step: 10
Training loss: 3.5358641147613525
Validation loss: 2.438221905821113

Epoch: 6| Step: 11
Training loss: 2.528930425643921
Validation loss: 2.4291951912705616

Epoch: 6| Step: 12
Training loss: 2.8327856063842773
Validation loss: 2.4324367379629486

Epoch: 6| Step: 13
Training loss: 3.525387763977051
Validation loss: 2.4302043248248357

Epoch: 79| Step: 0
Training loss: 2.5482616424560547
Validation loss: 2.4405189380850842

Epoch: 6| Step: 1
Training loss: 2.892058849334717
Validation loss: 2.4400969397637153

Epoch: 6| Step: 2
Training loss: 3.1182429790496826
Validation loss: 2.442255994325043

Epoch: 6| Step: 3
Training loss: 2.9794442653656006
Validation loss: 2.444565183372908

Epoch: 6| Step: 4
Training loss: 2.8444881439208984
Validation loss: 2.435615162695608

Epoch: 6| Step: 5
Training loss: 3.54761004447937
Validation loss: 2.434470981679937

Epoch: 6| Step: 6
Training loss: 2.6084718704223633
Validation loss: 2.431089037208147

Epoch: 6| Step: 7
Training loss: 2.8261513710021973
Validation loss: 2.4294727284421205

Epoch: 6| Step: 8
Training loss: 2.140073776245117
Validation loss: 2.4223990696732716

Epoch: 6| Step: 9
Training loss: 1.4023170471191406
Validation loss: 2.42101966181109

Epoch: 6| Step: 10
Training loss: 2.5732474327087402
Validation loss: 2.4239789465422272

Epoch: 6| Step: 11
Training loss: 2.851710557937622
Validation loss: 2.4291598873753704

Epoch: 6| Step: 12
Training loss: 2.418903112411499
Validation loss: 2.4330083477881645

Epoch: 6| Step: 13
Training loss: 2.373934745788574
Validation loss: 2.4443574643904165

Epoch: 80| Step: 0
Training loss: 2.0801751613616943
Validation loss: 2.4546318002926406

Epoch: 6| Step: 1
Training loss: 2.2359237670898438
Validation loss: 2.458114198459092

Epoch: 6| Step: 2
Training loss: 3.565810441970825
Validation loss: 2.4607500491603727

Epoch: 6| Step: 3
Training loss: 2.7698302268981934
Validation loss: 2.465030872693626

Epoch: 6| Step: 4
Training loss: 3.125352621078491
Validation loss: 2.4575190441582793

Epoch: 6| Step: 5
Training loss: 3.1035165786743164
Validation loss: 2.4529179270549486

Epoch: 6| Step: 6
Training loss: 2.62821626663208
Validation loss: 2.4379222521217923

Epoch: 6| Step: 7
Training loss: 1.8760762214660645
Validation loss: 2.432681324661419

Epoch: 6| Step: 8
Training loss: 1.9953031539916992
Validation loss: 2.4281426604076097

Epoch: 6| Step: 9
Training loss: 2.7919769287109375
Validation loss: 2.4241387254448346

Epoch: 6| Step: 10
Training loss: 2.7054684162139893
Validation loss: 2.4238211570247525

Epoch: 6| Step: 11
Training loss: 2.559032440185547
Validation loss: 2.4250583020589684

Epoch: 6| Step: 12
Training loss: 2.6687676906585693
Validation loss: 2.4256702417968423

Epoch: 6| Step: 13
Training loss: 3.1859593391418457
Validation loss: 2.421444618573753

Epoch: 81| Step: 0
Training loss: 2.576890707015991
Validation loss: 2.4239855274077384

Epoch: 6| Step: 1
Training loss: 3.102358818054199
Validation loss: 2.4242673048409085

Epoch: 6| Step: 2
Training loss: 2.914485216140747
Validation loss: 2.4256418546040854

Epoch: 6| Step: 3
Training loss: 3.3123011589050293
Validation loss: 2.423867003892058

Epoch: 6| Step: 4
Training loss: 2.4942541122436523
Validation loss: 2.424413809212305

Epoch: 6| Step: 5
Training loss: 2.559925079345703
Validation loss: 2.4286178311994

Epoch: 6| Step: 6
Training loss: 2.987679958343506
Validation loss: 2.424076364886376

Epoch: 6| Step: 7
Training loss: 2.455812454223633
Validation loss: 2.426791694856459

Epoch: 6| Step: 8
Training loss: 2.7966790199279785
Validation loss: 2.422535224627423

Epoch: 6| Step: 9
Training loss: 2.42527437210083
Validation loss: 2.4230279768666914

Epoch: 6| Step: 10
Training loss: 2.5834553241729736
Validation loss: 2.4232406154755624

Epoch: 6| Step: 11
Training loss: 2.325103521347046
Validation loss: 2.427989403406779

Epoch: 6| Step: 12
Training loss: 1.7153236865997314
Validation loss: 2.4291883771137526

Epoch: 6| Step: 13
Training loss: 2.907026767730713
Validation loss: 2.4376502498503654

Epoch: 82| Step: 0
Training loss: 3.0005154609680176
Validation loss: 2.4417663389636624

Epoch: 6| Step: 1
Training loss: 2.425248861312866
Validation loss: 2.4609354003783195

Epoch: 6| Step: 2
Training loss: 2.502629280090332
Validation loss: 2.4570694661909536

Epoch: 6| Step: 3
Training loss: 2.9996519088745117
Validation loss: 2.4653641408489597

Epoch: 6| Step: 4
Training loss: 2.250732421875
Validation loss: 2.460320959809006

Epoch: 6| Step: 5
Training loss: 2.851036787033081
Validation loss: 2.437221791154595

Epoch: 6| Step: 6
Training loss: 3.077223777770996
Validation loss: 2.42075091279963

Epoch: 6| Step: 7
Training loss: 2.408360481262207
Validation loss: 2.4161442633598083

Epoch: 6| Step: 8
Training loss: 2.0751612186431885
Validation loss: 2.4130504490226827

Epoch: 6| Step: 9
Training loss: 2.622814655303955
Validation loss: 2.4165005965899398

Epoch: 6| Step: 10
Training loss: 2.3222110271453857
Validation loss: 2.4138709934808875

Epoch: 6| Step: 11
Training loss: 2.742335557937622
Validation loss: 2.414740603457215

Epoch: 6| Step: 12
Training loss: 3.116466522216797
Validation loss: 2.424983855216734

Epoch: 6| Step: 13
Training loss: 2.6770710945129395
Validation loss: 2.429634840257706

Epoch: 83| Step: 0
Training loss: 3.1911730766296387
Validation loss: 2.42914516182356

Epoch: 6| Step: 1
Training loss: 2.2231674194335938
Validation loss: 2.4238907406407018

Epoch: 6| Step: 2
Training loss: 3.058330535888672
Validation loss: 2.42232160927147

Epoch: 6| Step: 3
Training loss: 2.7324910163879395
Validation loss: 2.424766416190773

Epoch: 6| Step: 4
Training loss: 1.6358277797698975
Validation loss: 2.422465293638168

Epoch: 6| Step: 5
Training loss: 2.3000845909118652
Validation loss: 2.42222079923076

Epoch: 6| Step: 6
Training loss: 2.3983118534088135
Validation loss: 2.4238416123133835

Epoch: 6| Step: 7
Training loss: 3.5826632976531982
Validation loss: 2.4202548919185514

Epoch: 6| Step: 8
Training loss: 2.6603927612304688
Validation loss: 2.4063846988062703

Epoch: 6| Step: 9
Training loss: 2.4132819175720215
Validation loss: 2.4042533905275407

Epoch: 6| Step: 10
Training loss: 2.33536434173584
Validation loss: 2.4049871711320776

Epoch: 6| Step: 11
Training loss: 2.707934856414795
Validation loss: 2.404479388267763

Epoch: 6| Step: 12
Training loss: 2.8361411094665527
Validation loss: 2.4026034826873452

Epoch: 6| Step: 13
Training loss: 2.804023504257202
Validation loss: 2.403172887781615

Epoch: 84| Step: 0
Training loss: 3.45365047454834
Validation loss: 2.403413987928821

Epoch: 6| Step: 1
Training loss: 2.5320851802825928
Validation loss: 2.405315681170392

Epoch: 6| Step: 2
Training loss: 3.05846905708313
Validation loss: 2.4048722046677784

Epoch: 6| Step: 3
Training loss: 2.6857967376708984
Validation loss: 2.4149059159781343

Epoch: 6| Step: 4
Training loss: 2.4399499893188477
Validation loss: 2.414254552574568

Epoch: 6| Step: 5
Training loss: 2.1998867988586426
Validation loss: 2.409091185497981

Epoch: 6| Step: 6
Training loss: 2.4684231281280518
Validation loss: 2.4192857921764417

Epoch: 6| Step: 7
Training loss: 2.545321464538574
Validation loss: 2.4178982447552424

Epoch: 6| Step: 8
Training loss: 2.6385610103607178
Validation loss: 2.4269227955930974

Epoch: 6| Step: 9
Training loss: 2.4608774185180664
Validation loss: 2.421802729688665

Epoch: 6| Step: 10
Training loss: 3.0404748916625977
Validation loss: 2.446476185193626

Epoch: 6| Step: 11
Training loss: 2.1778504848480225
Validation loss: 2.4361458132343907

Epoch: 6| Step: 12
Training loss: 3.0525739192962646
Validation loss: 2.4215975602467856

Epoch: 6| Step: 13
Training loss: 1.8760089874267578
Validation loss: 2.4173951148986816

Epoch: 85| Step: 0
Training loss: 2.7099971771240234
Validation loss: 2.4059642386692826

Epoch: 6| Step: 1
Training loss: 3.442448139190674
Validation loss: 2.4049556819341515

Epoch: 6| Step: 2
Training loss: 2.8527941703796387
Validation loss: 2.413778071762413

Epoch: 6| Step: 3
Training loss: 2.771400213241577
Validation loss: 2.4137789895457606

Epoch: 6| Step: 4
Training loss: 2.772082805633545
Validation loss: 2.4335704106156544

Epoch: 6| Step: 5
Training loss: 2.9945437908172607
Validation loss: 2.421416862036592

Epoch: 6| Step: 6
Training loss: 3.08227276802063
Validation loss: 2.410936955482729

Epoch: 6| Step: 7
Training loss: 2.590393304824829
Validation loss: 2.4122058422334733

Epoch: 6| Step: 8
Training loss: 2.682507038116455
Validation loss: 2.4125209957040767

Epoch: 6| Step: 9
Training loss: 2.9521703720092773
Validation loss: 2.4185833956605647

Epoch: 6| Step: 10
Training loss: 1.6717731952667236
Validation loss: 2.4286291906910558

Epoch: 6| Step: 11
Training loss: 1.9859418869018555
Validation loss: 2.4209854128540202

Epoch: 6| Step: 12
Training loss: 1.7032294273376465
Validation loss: 2.409816534288468

Epoch: 6| Step: 13
Training loss: 2.7898168563842773
Validation loss: 2.404985781638853

Epoch: 86| Step: 0
Training loss: 3.4070398807525635
Validation loss: 2.4024544813299693

Epoch: 6| Step: 1
Training loss: 2.9175329208374023
Validation loss: 2.402571814034575

Epoch: 6| Step: 2
Training loss: 2.6799869537353516
Validation loss: 2.4035090759236324

Epoch: 6| Step: 3
Training loss: 2.2358179092407227
Validation loss: 2.401782730574249

Epoch: 6| Step: 4
Training loss: 2.5426297187805176
Validation loss: 2.4026649177715345

Epoch: 6| Step: 5
Training loss: 2.729534149169922
Validation loss: 2.4042896686061734

Epoch: 6| Step: 6
Training loss: 2.971083164215088
Validation loss: 2.403370339383361

Epoch: 6| Step: 7
Training loss: 2.901899814605713
Validation loss: 2.40644435985114

Epoch: 6| Step: 8
Training loss: 2.41768479347229
Validation loss: 2.4212896362427743

Epoch: 6| Step: 9
Training loss: 2.4895241260528564
Validation loss: 2.4253810503149547

Epoch: 6| Step: 10
Training loss: 1.9207603931427002
Validation loss: 2.4303786549516904

Epoch: 6| Step: 11
Training loss: 2.73553466796875
Validation loss: 2.4291610589591404

Epoch: 6| Step: 12
Training loss: 1.9541373252868652
Validation loss: 2.4296602997728574

Epoch: 6| Step: 13
Training loss: 3.2098448276519775
Validation loss: 2.4176237275523524

Epoch: 87| Step: 0
Training loss: 2.642996311187744
Validation loss: 2.4015582287183372

Epoch: 6| Step: 1
Training loss: 2.4829354286193848
Validation loss: 2.397259094381845

Epoch: 6| Step: 2
Training loss: 3.1376280784606934
Validation loss: 2.3944526513417563

Epoch: 6| Step: 3
Training loss: 2.61466646194458
Validation loss: 2.3971934651815765

Epoch: 6| Step: 4
Training loss: 2.8008666038513184
Validation loss: 2.399615292908043

Epoch: 6| Step: 5
Training loss: 2.5863661766052246
Validation loss: 2.403392690484242

Epoch: 6| Step: 6
Training loss: 3.4245376586914062
Validation loss: 2.4107849905567784

Epoch: 6| Step: 7
Training loss: 2.412055730819702
Validation loss: 2.4105340537204536

Epoch: 6| Step: 8
Training loss: 2.6040267944335938
Validation loss: 2.4125714866063928

Epoch: 6| Step: 9
Training loss: 2.1635050773620605
Validation loss: 2.4091918571020967

Epoch: 6| Step: 10
Training loss: 3.3712358474731445
Validation loss: 2.4058547225049747

Epoch: 6| Step: 11
Training loss: 2.030181646347046
Validation loss: 2.4018144633180354

Epoch: 6| Step: 12
Training loss: 2.6001498699188232
Validation loss: 2.396132246140511

Epoch: 6| Step: 13
Training loss: 1.8940486907958984
Validation loss: 2.3935531980247906

Epoch: 88| Step: 0
Training loss: 2.356309413909912
Validation loss: 2.389581316260881

Epoch: 6| Step: 1
Training loss: 2.3477463722229004
Validation loss: 2.392829515600717

Epoch: 6| Step: 2
Training loss: 2.641232967376709
Validation loss: 2.4288785816520773

Epoch: 6| Step: 3
Training loss: 3.231139659881592
Validation loss: 2.456407795670212

Epoch: 6| Step: 4
Training loss: 2.205007553100586
Validation loss: 2.490057811942152

Epoch: 6| Step: 5
Training loss: 2.58803653717041
Validation loss: 2.481745289218041

Epoch: 6| Step: 6
Training loss: 2.7681925296783447
Validation loss: 2.462438711556055

Epoch: 6| Step: 7
Training loss: 3.278266429901123
Validation loss: 2.467656385514044

Epoch: 6| Step: 8
Training loss: 2.43498158454895
Validation loss: 2.459533650388

Epoch: 6| Step: 9
Training loss: 3.1878271102905273
Validation loss: 2.433713483554061

Epoch: 6| Step: 10
Training loss: 3.0387983322143555
Validation loss: 2.4346676154803206

Epoch: 6| Step: 11
Training loss: 1.9151852130889893
Validation loss: 2.415256548953313

Epoch: 6| Step: 12
Training loss: 2.356597423553467
Validation loss: 2.397139771010286

Epoch: 6| Step: 13
Training loss: 2.7724461555480957
Validation loss: 2.394494520720615

Epoch: 89| Step: 0
Training loss: 2.308978319168091
Validation loss: 2.3869162682564027

Epoch: 6| Step: 1
Training loss: 3.1451120376586914
Validation loss: 2.392894962782501

Epoch: 6| Step: 2
Training loss: 2.6511926651000977
Validation loss: 2.395379322831349

Epoch: 6| Step: 3
Training loss: 2.137725353240967
Validation loss: 2.3960854263715845

Epoch: 6| Step: 4
Training loss: 2.6327154636383057
Validation loss: 2.4010170941711753

Epoch: 6| Step: 5
Training loss: 2.550999164581299
Validation loss: 2.3946649156590945

Epoch: 6| Step: 6
Training loss: 3.61112904548645
Validation loss: 2.393251226794335

Epoch: 6| Step: 7
Training loss: 2.2935872077941895
Validation loss: 2.39448001692372

Epoch: 6| Step: 8
Training loss: 1.7518367767333984
Validation loss: 2.394349164860223

Epoch: 6| Step: 9
Training loss: 3.1864705085754395
Validation loss: 2.388772761949929

Epoch: 6| Step: 10
Training loss: 2.360989570617676
Validation loss: 2.3868133098848405

Epoch: 6| Step: 11
Training loss: 2.882697582244873
Validation loss: 2.3885831243248394

Epoch: 6| Step: 12
Training loss: 2.9404444694519043
Validation loss: 2.3926950167584162

Epoch: 6| Step: 13
Training loss: 2.108534574508667
Validation loss: 2.3926000595092773

Epoch: 90| Step: 0
Training loss: 3.0439929962158203
Validation loss: 2.4020176984930552

Epoch: 6| Step: 1
Training loss: 2.456552028656006
Validation loss: 2.412519811302103

Epoch: 6| Step: 2
Training loss: 2.609008312225342
Validation loss: 2.4181635431064072

Epoch: 6| Step: 3
Training loss: 2.5055365562438965
Validation loss: 2.415822708478538

Epoch: 6| Step: 4
Training loss: 1.5227878093719482
Validation loss: 2.427479472211612

Epoch: 6| Step: 5
Training loss: 2.674604654312134
Validation loss: 2.4294570569069154

Epoch: 6| Step: 6
Training loss: 2.553847312927246
Validation loss: 2.4462137401744886

Epoch: 6| Step: 7
Training loss: 3.424438238143921
Validation loss: 2.4676003020296813

Epoch: 6| Step: 8
Training loss: 2.2963876724243164
Validation loss: 2.463091188861478

Epoch: 6| Step: 9
Training loss: 2.8400726318359375
Validation loss: 2.4468855191302556

Epoch: 6| Step: 10
Training loss: 2.705709457397461
Validation loss: 2.436862361046576

Epoch: 6| Step: 11
Training loss: 2.4451842308044434
Validation loss: 2.41840011073697

Epoch: 6| Step: 12
Training loss: 2.550840377807617
Validation loss: 2.408519096271966

Epoch: 6| Step: 13
Training loss: 3.844867706298828
Validation loss: 2.395537830168201

Epoch: 91| Step: 0
Training loss: 2.6075832843780518
Validation loss: 2.3858747328481367

Epoch: 6| Step: 1
Training loss: 2.6258487701416016
Validation loss: 2.3858436384508686

Epoch: 6| Step: 2
Training loss: 2.2182705402374268
Validation loss: 2.396472446380123

Epoch: 6| Step: 3
Training loss: 2.8592007160186768
Validation loss: 2.4003717591685634

Epoch: 6| Step: 4
Training loss: 2.4850916862487793
Validation loss: 2.409075531908261

Epoch: 6| Step: 5
Training loss: 2.8990583419799805
Validation loss: 2.4108294248580933

Epoch: 6| Step: 6
Training loss: 2.34348726272583
Validation loss: 2.4044022149937128

Epoch: 6| Step: 7
Training loss: 3.154592990875244
Validation loss: 2.392555785435502

Epoch: 6| Step: 8
Training loss: 2.7347464561462402
Validation loss: 2.3861300842736357

Epoch: 6| Step: 9
Training loss: 2.2528586387634277
Validation loss: 2.379980589753838

Epoch: 6| Step: 10
Training loss: 3.605740547180176
Validation loss: 2.37726015685707

Epoch: 6| Step: 11
Training loss: 3.0079212188720703
Validation loss: 2.385725693036151

Epoch: 6| Step: 12
Training loss: 1.5432860851287842
Validation loss: 2.3963726592320267

Epoch: 6| Step: 13
Training loss: 2.6844213008880615
Validation loss: 2.412514632748019

Epoch: 92| Step: 0
Training loss: 1.8257595300674438
Validation loss: 2.4245065950578257

Epoch: 6| Step: 1
Training loss: 3.0453743934631348
Validation loss: 2.438199991820961

Epoch: 6| Step: 2
Training loss: 2.4053211212158203
Validation loss: 2.431681389449745

Epoch: 6| Step: 3
Training loss: 2.5395264625549316
Validation loss: 2.423661688322662

Epoch: 6| Step: 4
Training loss: 2.3487401008605957
Validation loss: 2.4174275603345645

Epoch: 6| Step: 5
Training loss: 1.7383310794830322
Validation loss: 2.398883124833466

Epoch: 6| Step: 6
Training loss: 2.3865299224853516
Validation loss: 2.391048644178657

Epoch: 6| Step: 7
Training loss: 2.3338751792907715
Validation loss: 2.3930642656100694

Epoch: 6| Step: 8
Training loss: 3.30867862701416
Validation loss: 2.3865203575421403

Epoch: 6| Step: 9
Training loss: 2.981175422668457
Validation loss: 2.3899665173663887

Epoch: 6| Step: 10
Training loss: 3.006493091583252
Validation loss: 2.386242628097534

Epoch: 6| Step: 11
Training loss: 2.1923341751098633
Validation loss: 2.386515981407576

Epoch: 6| Step: 12
Training loss: 3.8389892578125
Validation loss: 2.3856161281626713

Epoch: 6| Step: 13
Training loss: 2.797503709793091
Validation loss: 2.3927817139574277

Epoch: 93| Step: 0
Training loss: 2.6350603103637695
Validation loss: 2.393005032693186

Epoch: 6| Step: 1
Training loss: 2.6968774795532227
Validation loss: 2.3878283295580136

Epoch: 6| Step: 2
Training loss: 2.9052484035491943
Validation loss: 2.389062662278452

Epoch: 6| Step: 3
Training loss: 2.289114236831665
Validation loss: 2.390510748791438

Epoch: 6| Step: 4
Training loss: 2.409423828125
Validation loss: 2.3839349285248788

Epoch: 6| Step: 5
Training loss: 2.6749138832092285
Validation loss: 2.3896631886882167

Epoch: 6| Step: 6
Training loss: 2.2008254528045654
Validation loss: 2.3868251539045766

Epoch: 6| Step: 7
Training loss: 2.8422436714172363
Validation loss: 2.387612460761942

Epoch: 6| Step: 8
Training loss: 2.87856125831604
Validation loss: 2.400486921751371

Epoch: 6| Step: 9
Training loss: 2.644519329071045
Validation loss: 2.409469137909592

Epoch: 6| Step: 10
Training loss: 2.0940699577331543
Validation loss: 2.4153519881668912

Epoch: 6| Step: 11
Training loss: 2.1937429904937744
Validation loss: 2.41843504546791

Epoch: 6| Step: 12
Training loss: 3.154493570327759
Validation loss: 2.424881919737785

Epoch: 6| Step: 13
Training loss: 3.302720785140991
Validation loss: 2.4190948611946514

Epoch: 94| Step: 0
Training loss: 3.0234498977661133
Validation loss: 2.4113550493794103

Epoch: 6| Step: 1
Training loss: 1.9586074352264404
Validation loss: 2.389555408108619

Epoch: 6| Step: 2
Training loss: 2.54189395904541
Validation loss: 2.3851538473559963

Epoch: 6| Step: 3
Training loss: 3.180274486541748
Validation loss: 2.3797336637332873

Epoch: 6| Step: 4
Training loss: 2.2362308502197266
Validation loss: 2.3751447508412022

Epoch: 6| Step: 5
Training loss: 2.5774166584014893
Validation loss: 2.375629994177049

Epoch: 6| Step: 6
Training loss: 2.3295998573303223
Validation loss: 2.3790272461470736

Epoch: 6| Step: 7
Training loss: 2.3641724586486816
Validation loss: 2.374166844993509

Epoch: 6| Step: 8
Training loss: 2.3687968254089355
Validation loss: 2.3730119377054195

Epoch: 6| Step: 9
Training loss: 3.142469882965088
Validation loss: 2.3753466529230916

Epoch: 6| Step: 10
Training loss: 3.1868135929107666
Validation loss: 2.3744328304003646

Epoch: 6| Step: 11
Training loss: 2.961000442504883
Validation loss: 2.399246120965609

Epoch: 6| Step: 12
Training loss: 2.0278568267822266
Validation loss: 2.4067735492542224

Epoch: 6| Step: 13
Training loss: 2.661134719848633
Validation loss: 2.4137120426342054

Epoch: 95| Step: 0
Training loss: 2.5206356048583984
Validation loss: 2.4021022499248548

Epoch: 6| Step: 1
Training loss: 2.2333571910858154
Validation loss: 2.3851074352059314

Epoch: 6| Step: 2
Training loss: 2.30061936378479
Validation loss: 2.375674968124718

Epoch: 6| Step: 3
Training loss: 2.710728645324707
Validation loss: 2.3737496740074566

Epoch: 6| Step: 4
Training loss: 2.591353178024292
Validation loss: 2.366544977311165

Epoch: 6| Step: 5
Training loss: 2.6789228916168213
Validation loss: 2.36632610905555

Epoch: 6| Step: 6
Training loss: 1.93583345413208
Validation loss: 2.362979042914606

Epoch: 6| Step: 7
Training loss: 3.0560455322265625
Validation loss: 2.363965660013178

Epoch: 6| Step: 8
Training loss: 2.5682733058929443
Validation loss: 2.3603429614856677

Epoch: 6| Step: 9
Training loss: 3.307277202606201
Validation loss: 2.363580596062445

Epoch: 6| Step: 10
Training loss: 2.3661060333251953
Validation loss: 2.3610615345739547

Epoch: 6| Step: 11
Training loss: 3.3414793014526367
Validation loss: 2.3667415149750246

Epoch: 6| Step: 12
Training loss: 2.380098819732666
Validation loss: 2.36664233925522

Epoch: 6| Step: 13
Training loss: 2.5709729194641113
Validation loss: 2.3635331405106412

Epoch: 96| Step: 0
Training loss: 2.4181482791900635
Validation loss: 2.367376599260556

Epoch: 6| Step: 1
Training loss: 2.2368831634521484
Validation loss: 2.362272965010776

Epoch: 6| Step: 2
Training loss: 3.2411279678344727
Validation loss: 2.3595089117685952

Epoch: 6| Step: 3
Training loss: 3.0501041412353516
Validation loss: 2.3597123289621003

Epoch: 6| Step: 4
Training loss: 1.9360358715057373
Validation loss: 2.3633153028385614

Epoch: 6| Step: 5
Training loss: 1.9777333736419678
Validation loss: 2.367461073783136

Epoch: 6| Step: 6
Training loss: 2.9403414726257324
Validation loss: 2.372807025909424

Epoch: 6| Step: 7
Training loss: 3.072143077850342
Validation loss: 2.3875043994636944

Epoch: 6| Step: 8
Training loss: 3.099351406097412
Validation loss: 2.3989822403077157

Epoch: 6| Step: 9
Training loss: 3.046571731567383
Validation loss: 2.3929890304483394

Epoch: 6| Step: 10
Training loss: 2.3454055786132812
Validation loss: 2.39760773669007

Epoch: 6| Step: 11
Training loss: 1.9917315244674683
Validation loss: 2.3965214452435895

Epoch: 6| Step: 12
Training loss: 2.7733798027038574
Validation loss: 2.3975173350303405

Epoch: 6| Step: 13
Training loss: 2.2259929180145264
Validation loss: 2.392968011158769

Epoch: 97| Step: 0
Training loss: 2.298424482345581
Validation loss: 2.374822465322351

Epoch: 6| Step: 1
Training loss: 2.6239917278289795
Validation loss: 2.3641524776335685

Epoch: 6| Step: 2
Training loss: 2.820444107055664
Validation loss: 2.360524849225116

Epoch: 6| Step: 3
Training loss: 2.978438377380371
Validation loss: 2.3613004940812305

Epoch: 6| Step: 4
Training loss: 3.01873517036438
Validation loss: 2.3600743483471613

Epoch: 6| Step: 5
Training loss: 2.68924880027771
Validation loss: 2.355139003005079

Epoch: 6| Step: 6
Training loss: 2.9794905185699463
Validation loss: 2.3598230064556165

Epoch: 6| Step: 7
Training loss: 2.0629959106445312
Validation loss: 2.3658156984595844

Epoch: 6| Step: 8
Training loss: 2.926948308944702
Validation loss: 2.372248770088278

Epoch: 6| Step: 9
Training loss: 2.3952605724334717
Validation loss: 2.364893961978215

Epoch: 6| Step: 10
Training loss: 2.009784698486328
Validation loss: 2.3626167722927627

Epoch: 6| Step: 11
Training loss: 2.7687504291534424
Validation loss: 2.3599198928443332

Epoch: 6| Step: 12
Training loss: 2.848367691040039
Validation loss: 2.358579299783194

Epoch: 6| Step: 13
Training loss: 1.9373316764831543
Validation loss: 2.357184092203776

Epoch: 98| Step: 0
Training loss: 2.300931215286255
Validation loss: 2.3588732275911557

Epoch: 6| Step: 1
Training loss: 2.7478692531585693
Validation loss: 2.360926030784525

Epoch: 6| Step: 2
Training loss: 2.5220835208892822
Validation loss: 2.375025118550947

Epoch: 6| Step: 3
Training loss: 1.753635048866272
Validation loss: 2.3821252264002317

Epoch: 6| Step: 4
Training loss: 2.974921226501465
Validation loss: 2.3883983319805515

Epoch: 6| Step: 5
Training loss: 3.1299591064453125
Validation loss: 2.3997455694342174

Epoch: 6| Step: 6
Training loss: 2.6431407928466797
Validation loss: 2.3968009487275155

Epoch: 6| Step: 7
Training loss: 2.677030563354492
Validation loss: 2.3912166126312746

Epoch: 6| Step: 8
Training loss: 2.1275510787963867
Validation loss: 2.3817667397119666

Epoch: 6| Step: 9
Training loss: 2.7059736251831055
Validation loss: 2.3728518588568575

Epoch: 6| Step: 10
Training loss: 2.378929853439331
Validation loss: 2.35338754551385

Epoch: 6| Step: 11
Training loss: 2.523696184158325
Validation loss: 2.3596153387459378

Epoch: 6| Step: 12
Training loss: 2.748170852661133
Validation loss: 2.3649851096573697

Epoch: 6| Step: 13
Training loss: 3.6825056076049805
Validation loss: 2.3723030141604844

Epoch: 99| Step: 0
Training loss: 2.971651554107666
Validation loss: 2.368004083633423

Epoch: 6| Step: 1
Training loss: 2.0276007652282715
Validation loss: 2.381764814417849

Epoch: 6| Step: 2
Training loss: 3.031693458557129
Validation loss: 2.395585454920287

Epoch: 6| Step: 3
Training loss: 2.294569492340088
Validation loss: 2.417410123732782

Epoch: 6| Step: 4
Training loss: 2.3260130882263184
Validation loss: 2.4268364996038456

Epoch: 6| Step: 5
Training loss: 2.960019588470459
Validation loss: 2.4334812330943283

Epoch: 6| Step: 6
Training loss: 3.022042989730835
Validation loss: 2.421959679613831

Epoch: 6| Step: 7
Training loss: 2.2489421367645264
Validation loss: 2.4022639669397825

Epoch: 6| Step: 8
Training loss: 3.306488275527954
Validation loss: 2.400686474256618

Epoch: 6| Step: 9
Training loss: 2.293593168258667
Validation loss: 2.3791822336053334

Epoch: 6| Step: 10
Training loss: 3.3193976879119873
Validation loss: 2.3632435516644548

Epoch: 6| Step: 11
Training loss: 2.6036767959594727
Validation loss: 2.359520576333487

Epoch: 6| Step: 12
Training loss: 2.0375795364379883
Validation loss: 2.3509441011695453

Epoch: 6| Step: 13
Training loss: 1.779824137687683
Validation loss: 2.340353186412524

Epoch: 100| Step: 0
Training loss: 1.950136423110962
Validation loss: 2.3378753687745784

Epoch: 6| Step: 1
Training loss: 3.57149076461792
Validation loss: 2.342985996636011

Epoch: 6| Step: 2
Training loss: 2.1404175758361816
Validation loss: 2.348731143500215

Epoch: 6| Step: 3
Training loss: 2.5964579582214355
Validation loss: 2.3513306699773318

Epoch: 6| Step: 4
Training loss: 2.2612128257751465
Validation loss: 2.356052288445093

Epoch: 6| Step: 5
Training loss: 2.979886531829834
Validation loss: 2.3589557665650562

Epoch: 6| Step: 6
Training loss: 2.4951677322387695
Validation loss: 2.3579286836808726

Epoch: 6| Step: 7
Training loss: 3.4790568351745605
Validation loss: 2.3595470613048923

Epoch: 6| Step: 8
Training loss: 2.3225831985473633
Validation loss: 2.365077041810559

Epoch: 6| Step: 9
Training loss: 2.478710174560547
Validation loss: 2.3609354239638134

Epoch: 6| Step: 10
Training loss: 2.229527473449707
Validation loss: 2.3529029328336

Epoch: 6| Step: 11
Training loss: 3.0364303588867188
Validation loss: 2.351286521521948

Epoch: 6| Step: 12
Training loss: 2.5860776901245117
Validation loss: 2.3450331200835524

Epoch: 6| Step: 13
Training loss: 2.536187171936035
Validation loss: 2.349729038053943

Epoch: 101| Step: 0
Training loss: 2.7970471382141113
Validation loss: 2.3632397882400022

Epoch: 6| Step: 1
Training loss: 1.9528380632400513
Validation loss: 2.3784346990687872

Epoch: 6| Step: 2
Training loss: 2.2819361686706543
Validation loss: 2.380444775345505

Epoch: 6| Step: 3
Training loss: 2.526395797729492
Validation loss: 2.3810240504562215

Epoch: 6| Step: 4
Training loss: 2.6677823066711426
Validation loss: 2.3650107742637716

Epoch: 6| Step: 5
Training loss: 1.9776546955108643
Validation loss: 2.357057297101585

Epoch: 6| Step: 6
Training loss: 2.5720431804656982
Validation loss: 2.343392208058347

Epoch: 6| Step: 7
Training loss: 2.508674144744873
Validation loss: 2.3456464352146273

Epoch: 6| Step: 8
Training loss: 2.719895839691162
Validation loss: 2.3457934907687608

Epoch: 6| Step: 9
Training loss: 3.2041378021240234
Validation loss: 2.349166311243529

Epoch: 6| Step: 10
Training loss: 2.645327091217041
Validation loss: 2.3478585917462587

Epoch: 6| Step: 11
Training loss: 3.483341693878174
Validation loss: 2.361470055836503

Epoch: 6| Step: 12
Training loss: 2.3384952545166016
Validation loss: 2.3708502502851587

Epoch: 6| Step: 13
Training loss: 2.6439661979675293
Validation loss: 2.393491586049398

Epoch: 102| Step: 0
Training loss: 1.9396414756774902
Validation loss: 2.416484385408381

Epoch: 6| Step: 1
Training loss: 2.994706153869629
Validation loss: 2.4304154201220443

Epoch: 6| Step: 2
Training loss: 2.408684253692627
Validation loss: 2.425839859952209

Epoch: 6| Step: 3
Training loss: 2.668595790863037
Validation loss: 2.432529636608657

Epoch: 6| Step: 4
Training loss: 2.957282781600952
Validation loss: 2.41915496190389

Epoch: 6| Step: 5
Training loss: 2.8428385257720947
Validation loss: 2.439212042798278

Epoch: 6| Step: 6
Training loss: 2.106797695159912
Validation loss: 2.4263188736413115

Epoch: 6| Step: 7
Training loss: 3.1384410858154297
Validation loss: 2.4259178253912155

Epoch: 6| Step: 8
Training loss: 2.3872640132904053
Validation loss: 2.4150959137947328

Epoch: 6| Step: 9
Training loss: 2.254916191101074
Validation loss: 2.39006313713648

Epoch: 6| Step: 10
Training loss: 3.1123762130737305
Validation loss: 2.3767211078315653

Epoch: 6| Step: 11
Training loss: 2.490438938140869
Validation loss: 2.3643847998752388

Epoch: 6| Step: 12
Training loss: 2.873307228088379
Validation loss: 2.357014330484534

Epoch: 6| Step: 13
Training loss: 2.110630989074707
Validation loss: 2.342755757352357

Epoch: 103| Step: 0
Training loss: 3.0128660202026367
Validation loss: 2.3404934790826615

Epoch: 6| Step: 1
Training loss: 2.33767032623291
Validation loss: 2.3396491978758123

Epoch: 6| Step: 2
Training loss: 2.358146905899048
Validation loss: 2.3433563465713174

Epoch: 6| Step: 3
Training loss: 2.7514548301696777
Validation loss: 2.3479957529293594

Epoch: 6| Step: 4
Training loss: 3.161518096923828
Validation loss: 2.357642389112903

Epoch: 6| Step: 5
Training loss: 1.8367109298706055
Validation loss: 2.3566754197561615

Epoch: 6| Step: 6
Training loss: 3.7469382286071777
Validation loss: 2.354852895582876

Epoch: 6| Step: 7
Training loss: 1.9498329162597656
Validation loss: 2.3461157737239713

Epoch: 6| Step: 8
Training loss: 1.558465600013733
Validation loss: 2.3405666043681483

Epoch: 6| Step: 9
Training loss: 2.687767267227173
Validation loss: 2.350208536271126

Epoch: 6| Step: 10
Training loss: 2.983673572540283
Validation loss: 2.3605639447448072

Epoch: 6| Step: 11
Training loss: 2.5770022869110107
Validation loss: 2.3609112719053864

Epoch: 6| Step: 12
Training loss: 2.5235447883605957
Validation loss: 2.3651411507719304

Epoch: 6| Step: 13
Training loss: 2.9275569915771484
Validation loss: 2.360809641499673

Epoch: 104| Step: 0
Training loss: 2.759228467941284
Validation loss: 2.3521204763843166

Epoch: 6| Step: 1
Training loss: 2.703937530517578
Validation loss: 2.3321572196099067

Epoch: 6| Step: 2
Training loss: 2.65529203414917
Validation loss: 2.328398322546354

Epoch: 6| Step: 3
Training loss: 3.0104966163635254
Validation loss: 2.322413798301451

Epoch: 6| Step: 4
Training loss: 2.6353232860565186
Validation loss: 2.3239236211264007

Epoch: 6| Step: 5
Training loss: 3.1385326385498047
Validation loss: 2.3231318099524385

Epoch: 6| Step: 6
Training loss: 2.276801824569702
Validation loss: 2.3219841295673

Epoch: 6| Step: 7
Training loss: 2.4542949199676514
Validation loss: 2.324902501157535

Epoch: 6| Step: 8
Training loss: 2.1756014823913574
Validation loss: 2.326240155004686

Epoch: 6| Step: 9
Training loss: 2.0615780353546143
Validation loss: 2.325548302742743

Epoch: 6| Step: 10
Training loss: 2.1483404636383057
Validation loss: 2.3276780984734975

Epoch: 6| Step: 11
Training loss: 2.8166279792785645
Validation loss: 2.322996744545557

Epoch: 6| Step: 12
Training loss: 2.543121337890625
Validation loss: 2.3257525531194543

Epoch: 6| Step: 13
Training loss: 3.1318864822387695
Validation loss: 2.3253516381786716

Epoch: 105| Step: 0
Training loss: 2.848911762237549
Validation loss: 2.3280634662156463

Epoch: 6| Step: 1
Training loss: 2.987987756729126
Validation loss: 2.3524803218021186

Epoch: 6| Step: 2
Training loss: 2.392401695251465
Validation loss: 2.3831801055580057

Epoch: 6| Step: 3
Training loss: 2.75492000579834
Validation loss: 2.4167567991441294

Epoch: 6| Step: 4
Training loss: 2.8608009815216064
Validation loss: 2.4340893683894986

Epoch: 6| Step: 5
Training loss: 2.666867971420288
Validation loss: 2.417821445772725

Epoch: 6| Step: 6
Training loss: 1.979735016822815
Validation loss: 2.422457984698716

Epoch: 6| Step: 7
Training loss: 2.869281530380249
Validation loss: 2.4181262575170046

Epoch: 6| Step: 8
Training loss: 2.8979549407958984
Validation loss: 2.3881048515278804

Epoch: 6| Step: 9
Training loss: 2.2085886001586914
Validation loss: 2.386037926520071

Epoch: 6| Step: 10
Training loss: 1.781775951385498
Validation loss: 2.363040772817468

Epoch: 6| Step: 11
Training loss: 2.4048595428466797
Validation loss: 2.3427150941664174

Epoch: 6| Step: 12
Training loss: 2.933035373687744
Validation loss: 2.3303760943874234

Epoch: 6| Step: 13
Training loss: 2.8554158210754395
Validation loss: 2.3376212581511466

Epoch: 106| Step: 0
Training loss: 2.7781431674957275
Validation loss: 2.3454603097772084

Epoch: 6| Step: 1
Training loss: 2.393183469772339
Validation loss: 2.347407883213412

Epoch: 6| Step: 2
Training loss: 2.7682509422302246
Validation loss: 2.3454108122856385

Epoch: 6| Step: 3
Training loss: 3.290764570236206
Validation loss: 2.3474061694196475

Epoch: 6| Step: 4
Training loss: 2.5486769676208496
Validation loss: 2.346339976915749

Epoch: 6| Step: 5
Training loss: 2.36799693107605
Validation loss: 2.3438497768935336

Epoch: 6| Step: 6
Training loss: 2.385958671569824
Validation loss: 2.347997309059225

Epoch: 6| Step: 7
Training loss: 2.7059326171875
Validation loss: 2.3527086883462887

Epoch: 6| Step: 8
Training loss: 2.5944876670837402
Validation loss: 2.3542697045110885

Epoch: 6| Step: 9
Training loss: 3.211408853530884
Validation loss: 2.3617457882050545

Epoch: 6| Step: 10
Training loss: 2.387345790863037
Validation loss: 2.3841463006952757

Epoch: 6| Step: 11
Training loss: 2.7908761501312256
Validation loss: 2.399057408814789

Epoch: 6| Step: 12
Training loss: 1.8429831266403198
Validation loss: 2.4029602107181343

Epoch: 6| Step: 13
Training loss: 2.1181602478027344
Validation loss: 2.4097909337730816

Epoch: 107| Step: 0
Training loss: 2.1017184257507324
Validation loss: 2.4111411648411907

Epoch: 6| Step: 1
Training loss: 1.9776527881622314
Validation loss: 2.401279882718158

Epoch: 6| Step: 2
Training loss: 3.6971845626831055
Validation loss: 2.4144769073814474

Epoch: 6| Step: 3
Training loss: 2.7340810298919678
Validation loss: 2.411809067572317

Epoch: 6| Step: 4
Training loss: 2.2855143547058105
Validation loss: 2.402737348310409

Epoch: 6| Step: 5
Training loss: 2.8377792835235596
Validation loss: 2.413278747630376

Epoch: 6| Step: 6
Training loss: 2.672598361968994
Validation loss: 2.396398590457055

Epoch: 6| Step: 7
Training loss: 2.441129207611084
Validation loss: 2.383351654134771

Epoch: 6| Step: 8
Training loss: 2.0685079097747803
Validation loss: 2.3819408160383984

Epoch: 6| Step: 9
Training loss: 2.643684148788452
Validation loss: 2.378225431647352

Epoch: 6| Step: 10
Training loss: 2.3798723220825195
Validation loss: 2.3793570008329166

Epoch: 6| Step: 11
Training loss: 2.396836042404175
Validation loss: 2.377018379908736

Epoch: 6| Step: 12
Training loss: 2.680279493331909
Validation loss: 2.380922127795476

Epoch: 6| Step: 13
Training loss: 4.096124172210693
Validation loss: 2.375423587778563

Epoch: 108| Step: 0
Training loss: 2.4739322662353516
Validation loss: 2.3703428776033464

Epoch: 6| Step: 1
Training loss: 2.2470719814300537
Validation loss: 2.3599945499051

Epoch: 6| Step: 2
Training loss: 2.6437089443206787
Validation loss: 2.364240187470631

Epoch: 6| Step: 3
Training loss: 2.8079638481140137
Validation loss: 2.356975773329376

Epoch: 6| Step: 4
Training loss: 3.539008140563965
Validation loss: 2.350836025771274

Epoch: 6| Step: 5
Training loss: 2.056974411010742
Validation loss: 2.354526855612314

Epoch: 6| Step: 6
Training loss: 1.719067931175232
Validation loss: 2.3569656982216785

Epoch: 6| Step: 7
Training loss: 2.4567856788635254
Validation loss: 2.3620350822325675

Epoch: 6| Step: 8
Training loss: 2.994457960128784
Validation loss: 2.367294949869956

Epoch: 6| Step: 9
Training loss: 2.468369722366333
Validation loss: 2.375766005567325

Epoch: 6| Step: 10
Training loss: 2.413642168045044
Validation loss: 2.361866053714547

Epoch: 6| Step: 11
Training loss: 3.1001386642456055
Validation loss: 2.3647052831547235

Epoch: 6| Step: 12
Training loss: 2.5293941497802734
Validation loss: 2.3685439068783998

Epoch: 6| Step: 13
Training loss: 2.72343373298645
Validation loss: 2.384443995773151

Epoch: 109| Step: 0
Training loss: 2.4014124870300293
Validation loss: 2.36946096984289

Epoch: 6| Step: 1
Training loss: 2.113279104232788
Validation loss: 2.3873431990223546

Epoch: 6| Step: 2
Training loss: 2.483142614364624
Validation loss: 2.3933762363208237

Epoch: 6| Step: 3
Training loss: 2.182511806488037
Validation loss: 2.3895223909808743

Epoch: 6| Step: 4
Training loss: 3.304544687271118
Validation loss: 2.3927426594559864

Epoch: 6| Step: 5
Training loss: 2.893932580947876
Validation loss: 2.369360908385246

Epoch: 6| Step: 6
Training loss: 2.2940781116485596
Validation loss: 2.3642090212914253

Epoch: 6| Step: 7
Training loss: 2.96586275100708
Validation loss: 2.338293716471682

Epoch: 6| Step: 8
Training loss: 2.611771821975708
Validation loss: 2.327635060074509

Epoch: 6| Step: 9
Training loss: 2.708743095397949
Validation loss: 2.305857959614005

Epoch: 6| Step: 10
Training loss: 2.3155148029327393
Validation loss: 2.298908022142226

Epoch: 6| Step: 11
Training loss: 2.8572945594787598
Validation loss: 2.301590819512644

Epoch: 6| Step: 12
Training loss: 2.294201374053955
Validation loss: 2.3042779558448383

Epoch: 6| Step: 13
Training loss: 2.6639649868011475
Validation loss: 2.302797414923227

Epoch: 110| Step: 0
Training loss: 2.7853498458862305
Validation loss: 2.3026553302682857

Epoch: 6| Step: 1
Training loss: 2.529359817504883
Validation loss: 2.295416021859774

Epoch: 6| Step: 2
Training loss: 2.0232622623443604
Validation loss: 2.292169006921912

Epoch: 6| Step: 3
Training loss: 2.02524733543396
Validation loss: 2.2961392351376113

Epoch: 6| Step: 4
Training loss: 2.551182746887207
Validation loss: 2.3005898075719036

Epoch: 6| Step: 5
Training loss: 2.785937547683716
Validation loss: 2.322972213068316

Epoch: 6| Step: 6
Training loss: 1.5605649948120117
Validation loss: 2.345635760215021

Epoch: 6| Step: 7
Training loss: 3.123049259185791
Validation loss: 2.3663445877772507

Epoch: 6| Step: 8
Training loss: 2.9089672565460205
Validation loss: 2.366783362562938

Epoch: 6| Step: 9
Training loss: 3.625222682952881
Validation loss: 2.3727519127630416

Epoch: 6| Step: 10
Training loss: 2.607797861099243
Validation loss: 2.365994845667193

Epoch: 6| Step: 11
Training loss: 2.5560340881347656
Validation loss: 2.3567316711589856

Epoch: 6| Step: 12
Training loss: 1.99201238155365
Validation loss: 2.35690128162343

Epoch: 6| Step: 13
Training loss: 3.2185323238372803
Validation loss: 2.3325891930569886

Epoch: 111| Step: 0
Training loss: 2.91390061378479
Validation loss: 2.3016912373163367

Epoch: 6| Step: 1
Training loss: 1.922109842300415
Validation loss: 2.292014960319765

Epoch: 6| Step: 2
Training loss: 2.711289405822754
Validation loss: 2.293444618102043

Epoch: 6| Step: 3
Training loss: 2.3219268321990967
Validation loss: 2.298225933505643

Epoch: 6| Step: 4
Training loss: 2.824207305908203
Validation loss: 2.3012120723724365

Epoch: 6| Step: 5
Training loss: 2.867428779602051
Validation loss: 2.3071502690674155

Epoch: 6| Step: 6
Training loss: 2.652679204940796
Validation loss: 2.2994632233855543

Epoch: 6| Step: 7
Training loss: 2.9997832775115967
Validation loss: 2.301272552500489

Epoch: 6| Step: 8
Training loss: 2.8186867237091064
Validation loss: 2.312504321016291

Epoch: 6| Step: 9
Training loss: 2.2431533336639404
Validation loss: 2.3192463792780393

Epoch: 6| Step: 10
Training loss: 2.435972213745117
Validation loss: 2.3042869055142967

Epoch: 6| Step: 11
Training loss: 2.30629301071167
Validation loss: 2.323993831552485

Epoch: 6| Step: 12
Training loss: 2.4236204624176025
Validation loss: 2.325511481172295

Epoch: 6| Step: 13
Training loss: 2.536073684692383
Validation loss: 2.3149773484917096

Epoch: 112| Step: 0
Training loss: 1.8639862537384033
Validation loss: 2.3182507509826333

Epoch: 6| Step: 1
Training loss: 2.7276573181152344
Validation loss: 2.331969970016069

Epoch: 6| Step: 2
Training loss: 2.5450024604797363
Validation loss: 2.332092423592844

Epoch: 6| Step: 3
Training loss: 2.458080768585205
Validation loss: 2.340624204245947

Epoch: 6| Step: 4
Training loss: 2.1733317375183105
Validation loss: 2.3527717128876717

Epoch: 6| Step: 5
Training loss: 3.070678472518921
Validation loss: 2.3680052731626775

Epoch: 6| Step: 6
Training loss: 2.0405023097991943
Validation loss: 2.375652490123626

Epoch: 6| Step: 7
Training loss: 2.5520901679992676
Validation loss: 2.363942002737394

Epoch: 6| Step: 8
Training loss: 2.95266056060791
Validation loss: 2.332800821591449

Epoch: 6| Step: 9
Training loss: 2.3304271697998047
Validation loss: 2.320807364679152

Epoch: 6| Step: 10
Training loss: 2.807685613632202
Validation loss: 2.310351733238466

Epoch: 6| Step: 11
Training loss: 2.6551003456115723
Validation loss: 2.3147445468492407

Epoch: 6| Step: 12
Training loss: 3.374728202819824
Validation loss: 2.30855284455002

Epoch: 6| Step: 13
Training loss: 2.2905561923980713
Validation loss: 2.30541669553326

Epoch: 113| Step: 0
Training loss: 2.918144702911377
Validation loss: 2.305282026208857

Epoch: 6| Step: 1
Training loss: 3.012864589691162
Validation loss: 2.307137550846223

Epoch: 6| Step: 2
Training loss: 2.4768905639648438
Validation loss: 2.3010931040651057

Epoch: 6| Step: 3
Training loss: 2.6276259422302246
Validation loss: 2.297832945341705

Epoch: 6| Step: 4
Training loss: 1.8323110342025757
Validation loss: 2.300945064072968

Epoch: 6| Step: 5
Training loss: 2.5827999114990234
Validation loss: 2.3088733996114423

Epoch: 6| Step: 6
Training loss: 2.619649648666382
Validation loss: 2.321308059077109

Epoch: 6| Step: 7
Training loss: 2.9174909591674805
Validation loss: 2.3290656766583844

Epoch: 6| Step: 8
Training loss: 3.1114792823791504
Validation loss: 2.345322052637736

Epoch: 6| Step: 9
Training loss: 2.2543234825134277
Validation loss: 2.3571879479192916

Epoch: 6| Step: 10
Training loss: 2.154381275177002
Validation loss: 2.343043374758895

Epoch: 6| Step: 11
Training loss: 2.418010711669922
Validation loss: 2.3308792934622815

Epoch: 6| Step: 12
Training loss: 2.4565632343292236
Validation loss: 2.3145859523486068

Epoch: 6| Step: 13
Training loss: 2.4633805751800537
Validation loss: 2.3139500566708144

Epoch: 114| Step: 0
Training loss: 2.530271053314209
Validation loss: 2.30404241623417

Epoch: 6| Step: 1
Training loss: 2.0205535888671875
Validation loss: 2.2951968664764077

Epoch: 6| Step: 2
Training loss: 2.4428441524505615
Validation loss: 2.3059277380666425

Epoch: 6| Step: 3
Training loss: 2.901554584503174
Validation loss: 2.3026756522476033

Epoch: 6| Step: 4
Training loss: 2.6050078868865967
Validation loss: 2.305752477338237

Epoch: 6| Step: 5
Training loss: 3.012373924255371
Validation loss: 2.3188001571163053

Epoch: 6| Step: 6
Training loss: 2.703639030456543
Validation loss: 2.3206304529661774

Epoch: 6| Step: 7
Training loss: 2.391899585723877
Validation loss: 2.3131836357937066

Epoch: 6| Step: 8
Training loss: 2.9385786056518555
Validation loss: 2.2998120118212957

Epoch: 6| Step: 9
Training loss: 2.437505006790161
Validation loss: 2.287280721049155

Epoch: 6| Step: 10
Training loss: 2.3430583477020264
Validation loss: 2.282136727404851

Epoch: 6| Step: 11
Training loss: 3.074471950531006
Validation loss: 2.284591469713437

Epoch: 6| Step: 12
Training loss: 2.044262409210205
Validation loss: 2.2869275616061304

Epoch: 6| Step: 13
Training loss: 2.1411402225494385
Validation loss: 2.2900361604588007

Epoch: 115| Step: 0
Training loss: 2.2095017433166504
Validation loss: 2.287899455716533

Epoch: 6| Step: 1
Training loss: 2.048790454864502
Validation loss: 2.2824783325195312

Epoch: 6| Step: 2
Training loss: 2.6507444381713867
Validation loss: 2.2832232893154187

Epoch: 6| Step: 3
Training loss: 2.7881672382354736
Validation loss: 2.2803700841883177

Epoch: 6| Step: 4
Training loss: 2.882772445678711
Validation loss: 2.2944844743256927

Epoch: 6| Step: 5
Training loss: 2.119074583053589
Validation loss: 2.2970406714306084

Epoch: 6| Step: 6
Training loss: 2.932936191558838
Validation loss: 2.293850624433128

Epoch: 6| Step: 7
Training loss: 2.612387180328369
Validation loss: 2.301030812724944

Epoch: 6| Step: 8
Training loss: 2.397308349609375
Validation loss: 2.2951546458787817

Epoch: 6| Step: 9
Training loss: 2.4262843132019043
Validation loss: 2.288783779708288

Epoch: 6| Step: 10
Training loss: 2.4429402351379395
Validation loss: 2.2922174763935868

Epoch: 6| Step: 11
Training loss: 2.9341413974761963
Validation loss: 2.3029080744712584

Epoch: 6| Step: 12
Training loss: 2.157003402709961
Validation loss: 2.2986891833684777

Epoch: 6| Step: 13
Training loss: 3.3209125995635986
Validation loss: 2.2972597934866466

Epoch: 116| Step: 0
Training loss: 2.8230881690979004
Validation loss: 2.2868328837938208

Epoch: 6| Step: 1
Training loss: 1.934889316558838
Validation loss: 2.2908917088662424

Epoch: 6| Step: 2
Training loss: 2.7757623195648193
Validation loss: 2.2932883424143635

Epoch: 6| Step: 3
Training loss: 2.075960159301758
Validation loss: 2.29071137725666

Epoch: 6| Step: 4
Training loss: 2.8504462242126465
Validation loss: 2.2959928397209413

Epoch: 6| Step: 5
Training loss: 3.1563644409179688
Validation loss: 2.2822272264829246

Epoch: 6| Step: 6
Training loss: 2.636376142501831
Validation loss: 2.2901770094389557

Epoch: 6| Step: 7
Training loss: 2.7212510108947754
Validation loss: 2.2844724450060117

Epoch: 6| Step: 8
Training loss: 2.9086616039276123
Validation loss: 2.2822001980197046

Epoch: 6| Step: 9
Training loss: 1.655550241470337
Validation loss: 2.2877482291190856

Epoch: 6| Step: 10
Training loss: 2.5343379974365234
Validation loss: 2.2886783358871297

Epoch: 6| Step: 11
Training loss: 2.7956790924072266
Validation loss: 2.289467703911566

Epoch: 6| Step: 12
Training loss: 2.272487163543701
Validation loss: 2.2958089049144457

Epoch: 6| Step: 13
Training loss: 2.4255361557006836
Validation loss: 2.291519682894471

Epoch: 117| Step: 0
Training loss: 2.879088878631592
Validation loss: 2.2922725933854298

Epoch: 6| Step: 1
Training loss: 2.2254767417907715
Validation loss: 2.3058744963779243

Epoch: 6| Step: 2
Training loss: 2.684495210647583
Validation loss: 2.306181482089463

Epoch: 6| Step: 3
Training loss: 2.8336825370788574
Validation loss: 2.327691647314256

Epoch: 6| Step: 4
Training loss: 2.1812291145324707
Validation loss: 2.326282711439235

Epoch: 6| Step: 5
Training loss: 2.074094533920288
Validation loss: 2.3290224741863947

Epoch: 6| Step: 6
Training loss: 2.6786985397338867
Validation loss: 2.3220540579929145

Epoch: 6| Step: 7
Training loss: 2.168381690979004
Validation loss: 2.306217828104573

Epoch: 6| Step: 8
Training loss: 3.027909755706787
Validation loss: 2.28293433753393

Epoch: 6| Step: 9
Training loss: 2.926032543182373
Validation loss: 2.264324398450954

Epoch: 6| Step: 10
Training loss: 3.063436985015869
Validation loss: 2.2637662169753865

Epoch: 6| Step: 11
Training loss: 1.7465965747833252
Validation loss: 2.2658503478573215

Epoch: 6| Step: 12
Training loss: 2.5112714767456055
Validation loss: 2.263843946559455

Epoch: 6| Step: 13
Training loss: 2.6429834365844727
Validation loss: 2.262440517384519

Epoch: 118| Step: 0
Training loss: 2.5691113471984863
Validation loss: 2.262900149950417

Epoch: 6| Step: 1
Training loss: 2.844473361968994
Validation loss: 2.269467556348411

Epoch: 6| Step: 2
Training loss: 2.3689539432525635
Validation loss: 2.2702174519979827

Epoch: 6| Step: 3
Training loss: 2.1937036514282227
Validation loss: 2.2719556311125397

Epoch: 6| Step: 4
Training loss: 2.1674067974090576
Validation loss: 2.2700440793909054

Epoch: 6| Step: 5
Training loss: 2.2267673015594482
Validation loss: 2.2748717159353276

Epoch: 6| Step: 6
Training loss: 2.693338632583618
Validation loss: 2.2854523530570408

Epoch: 6| Step: 7
Training loss: 2.9157814979553223
Validation loss: 2.2913117742025726

Epoch: 6| Step: 8
Training loss: 3.11514949798584
Validation loss: 2.297911233799432

Epoch: 6| Step: 9
Training loss: 2.0413482189178467
Validation loss: 2.312854723263812

Epoch: 6| Step: 10
Training loss: 3.131516933441162
Validation loss: 2.3045599909238916

Epoch: 6| Step: 11
Training loss: 2.6043906211853027
Validation loss: 2.3007902842695995

Epoch: 6| Step: 12
Training loss: 2.396153211593628
Validation loss: 2.3090204577292166

Epoch: 6| Step: 13
Training loss: 1.9919798374176025
Validation loss: 2.3089731252321632

Epoch: 119| Step: 0
Training loss: 1.8234364986419678
Validation loss: 2.308530886967977

Epoch: 6| Step: 1
Training loss: 2.7780709266662598
Validation loss: 2.3108963069095405

Epoch: 6| Step: 2
Training loss: 2.1354141235351562
Validation loss: 2.3396604958400933

Epoch: 6| Step: 3
Training loss: 2.4173927307128906
Validation loss: 2.3614839558960288

Epoch: 6| Step: 4
Training loss: 3.1243410110473633
Validation loss: 2.3893172958845734

Epoch: 6| Step: 5
Training loss: 2.412275791168213
Validation loss: 2.40988923657325

Epoch: 6| Step: 6
Training loss: 2.9004220962524414
Validation loss: 2.387245080804312

Epoch: 6| Step: 7
Training loss: 2.4500269889831543
Validation loss: 2.3610552690362416

Epoch: 6| Step: 8
Training loss: 3.1786789894104004
Validation loss: 2.334335224602812

Epoch: 6| Step: 9
Training loss: 2.9774343967437744
Validation loss: 2.321443388538976

Epoch: 6| Step: 10
Training loss: 2.8622512817382812
Validation loss: 2.309702996284731

Epoch: 6| Step: 11
Training loss: 1.8894704580307007
Validation loss: 2.307887195259012

Epoch: 6| Step: 12
Training loss: 2.7254281044006348
Validation loss: 2.302944270513391

Epoch: 6| Step: 13
Training loss: 1.7474644184112549
Validation loss: 2.305642456136724

Epoch: 120| Step: 0
Training loss: 2.669218063354492
Validation loss: 2.2949220339457193

Epoch: 6| Step: 1
Training loss: 2.5639657974243164
Validation loss: 2.2893329205051547

Epoch: 6| Step: 2
Training loss: 2.9526867866516113
Validation loss: 2.278841516023041

Epoch: 6| Step: 3
Training loss: 2.2766733169555664
Validation loss: 2.278243854481687

Epoch: 6| Step: 4
Training loss: 1.7271873950958252
Validation loss: 2.272566770994535

Epoch: 6| Step: 5
Training loss: 2.313671588897705
Validation loss: 2.2815376661157094

Epoch: 6| Step: 6
Training loss: 2.7888622283935547
Validation loss: 2.283650105999362

Epoch: 6| Step: 7
Training loss: 2.223851203918457
Validation loss: 2.2995204643536638

Epoch: 6| Step: 8
Training loss: 2.1556034088134766
Validation loss: 2.2913898011689544

Epoch: 6| Step: 9
Training loss: 2.2078347206115723
Validation loss: 2.2995394583671325

Epoch: 6| Step: 10
Training loss: 3.0689480304718018
Validation loss: 2.300240291062222

Epoch: 6| Step: 11
Training loss: 2.8103318214416504
Validation loss: 2.307134776987055

Epoch: 6| Step: 12
Training loss: 3.06203293800354
Validation loss: 2.2954802231122087

Epoch: 6| Step: 13
Training loss: 2.9109647274017334
Validation loss: 2.3050474197633806

Epoch: 121| Step: 0
Training loss: 2.9582316875457764
Validation loss: 2.293590289290233

Epoch: 6| Step: 1
Training loss: 2.921966552734375
Validation loss: 2.29575668099106

Epoch: 6| Step: 2
Training loss: 2.391164779663086
Validation loss: 2.283385548540341

Epoch: 6| Step: 3
Training loss: 2.157130241394043
Validation loss: 2.2651783368920766

Epoch: 6| Step: 4
Training loss: 2.028174877166748
Validation loss: 2.2612486680348716

Epoch: 6| Step: 5
Training loss: 2.8692071437835693
Validation loss: 2.2549053417739047

Epoch: 6| Step: 6
Training loss: 3.2086305618286133
Validation loss: 2.252304461694533

Epoch: 6| Step: 7
Training loss: 2.7418763637542725
Validation loss: 2.2555162445191415

Epoch: 6| Step: 8
Training loss: 3.2717697620391846
Validation loss: 2.266859431420603

Epoch: 6| Step: 9
Training loss: 2.5935299396514893
Validation loss: 2.2696050418320524

Epoch: 6| Step: 10
Training loss: 1.720328688621521
Validation loss: 2.26429045584894

Epoch: 6| Step: 11
Training loss: 1.4823986291885376
Validation loss: 2.2636623767114457

Epoch: 6| Step: 12
Training loss: 3.07963228225708
Validation loss: 2.2810345542046333

Epoch: 6| Step: 13
Training loss: 2.0120701789855957
Validation loss: 2.2987232874798518

Epoch: 122| Step: 0
Training loss: 2.354785680770874
Validation loss: 2.3189436722827215

Epoch: 6| Step: 1
Training loss: 2.9314095973968506
Validation loss: 2.3589573893495785

Epoch: 6| Step: 2
Training loss: 2.376241683959961
Validation loss: 2.396466350042692

Epoch: 6| Step: 3
Training loss: 1.4574421644210815
Validation loss: 2.4109094860733196

Epoch: 6| Step: 4
Training loss: 3.661226749420166
Validation loss: 2.4127380771021687

Epoch: 6| Step: 5
Training loss: 2.1448957920074463
Validation loss: 2.405207282753401

Epoch: 6| Step: 6
Training loss: 2.8717944622039795
Validation loss: 2.3883478180054696

Epoch: 6| Step: 7
Training loss: 2.3238420486450195
Validation loss: 2.3839149834007345

Epoch: 6| Step: 8
Training loss: 3.0189590454101562
Validation loss: 2.3617410916154102

Epoch: 6| Step: 9
Training loss: 3.2555527687072754
Validation loss: 2.356596880061652

Epoch: 6| Step: 10
Training loss: 2.60749888420105
Validation loss: 2.3512753004668863

Epoch: 6| Step: 11
Training loss: 2.4475581645965576
Validation loss: 2.3388928264699955

Epoch: 6| Step: 12
Training loss: 2.250818967819214
Validation loss: 2.3290431986572924

Epoch: 6| Step: 13
Training loss: 1.8726319074630737
Validation loss: 2.3092079111324844

Epoch: 123| Step: 0
Training loss: 2.302537202835083
Validation loss: 2.3034750159068773

Epoch: 6| Step: 1
Training loss: 2.4028818607330322
Validation loss: 2.295171614616148

Epoch: 6| Step: 2
Training loss: 2.952901840209961
Validation loss: 2.2941741584449686

Epoch: 6| Step: 3
Training loss: 2.201673746109009
Validation loss: 2.300434753458987

Epoch: 6| Step: 4
Training loss: 3.208597421646118
Validation loss: 2.291850574554936

Epoch: 6| Step: 5
Training loss: 2.8419265747070312
Validation loss: 2.2734138504151375

Epoch: 6| Step: 6
Training loss: 2.7278060913085938
Validation loss: 2.2639154695695445

Epoch: 6| Step: 7
Training loss: 2.16194224357605
Validation loss: 2.2631770692845827

Epoch: 6| Step: 8
Training loss: 2.756188154220581
Validation loss: 2.260777291431222

Epoch: 6| Step: 9
Training loss: 2.4280548095703125
Validation loss: 2.244992302310082

Epoch: 6| Step: 10
Training loss: 2.266716957092285
Validation loss: 2.241101946882022

Epoch: 6| Step: 11
Training loss: 2.488861083984375
Validation loss: 2.2352958956072406

Epoch: 6| Step: 12
Training loss: 2.2966649532318115
Validation loss: 2.2323030630747476

Epoch: 6| Step: 13
Training loss: 2.1923000812530518
Validation loss: 2.2298121272876696

Epoch: 124| Step: 0
Training loss: 2.5912485122680664
Validation loss: 2.2422615917780067

Epoch: 6| Step: 1
Training loss: 1.6198737621307373
Validation loss: 2.2442743034772974

Epoch: 6| Step: 2
Training loss: 2.764836549758911
Validation loss: 2.2474102153572986

Epoch: 6| Step: 3
Training loss: 2.140808343887329
Validation loss: 2.245433594590874

Epoch: 6| Step: 4
Training loss: 2.33463191986084
Validation loss: 2.2379586670988347

Epoch: 6| Step: 5
Training loss: 3.323269844055176
Validation loss: 2.2472308117856263

Epoch: 6| Step: 6
Training loss: 2.9997057914733887
Validation loss: 2.268316691921603

Epoch: 6| Step: 7
Training loss: 2.834176540374756
Validation loss: 2.272054415877147

Epoch: 6| Step: 8
Training loss: 2.3678383827209473
Validation loss: 2.2589965892094437

Epoch: 6| Step: 9
Training loss: 2.462545394897461
Validation loss: 2.264043786192453

Epoch: 6| Step: 10
Training loss: 2.477229118347168
Validation loss: 2.2532877434966383

Epoch: 6| Step: 11
Training loss: 2.84126353263855
Validation loss: 2.2505374108591387

Epoch: 6| Step: 12
Training loss: 2.8407273292541504
Validation loss: 2.248795770829724

Epoch: 6| Step: 13
Training loss: 1.5306137800216675
Validation loss: 2.250044409946729

Epoch: 125| Step: 0
Training loss: 3.2779786586761475
Validation loss: 2.250369089905934

Epoch: 6| Step: 1
Training loss: 1.799102544784546
Validation loss: 2.2549409315150273

Epoch: 6| Step: 2
Training loss: 2.368251085281372
Validation loss: 2.2705492998964045

Epoch: 6| Step: 3
Training loss: 2.595231294631958
Validation loss: 2.271136535111294

Epoch: 6| Step: 4
Training loss: 2.3954315185546875
Validation loss: 2.2860443002434185

Epoch: 6| Step: 5
Training loss: 2.8596839904785156
Validation loss: 2.287606364937239

Epoch: 6| Step: 6
Training loss: 2.39048433303833
Validation loss: 2.278475715268043

Epoch: 6| Step: 7
Training loss: 2.037841796875
Validation loss: 2.2716624070239324

Epoch: 6| Step: 8
Training loss: 3.0166826248168945
Validation loss: 2.2570656832828315

Epoch: 6| Step: 9
Training loss: 2.5210280418395996
Validation loss: 2.2582604833828506

Epoch: 6| Step: 10
Training loss: 2.227985382080078
Validation loss: 2.2505315196129585

Epoch: 6| Step: 11
Training loss: 2.7809133529663086
Validation loss: 2.255386755030642

Epoch: 6| Step: 12
Training loss: 2.8950142860412598
Validation loss: 2.2640441630476262

Epoch: 6| Step: 13
Training loss: 1.829009771347046
Validation loss: 2.2736256173861924

Testing loss: 2.4538342687818737
