Epoch: 1| Step: 0
Training loss: 4.879619268355018
Validation loss: 5.811980839255325

Epoch: 6| Step: 1
Training loss: 6.351306042062641
Validation loss: 5.8052470984282385

Epoch: 6| Step: 2
Training loss: 5.849986293157186
Validation loss: 5.798584141049481

Epoch: 6| Step: 3
Training loss: 4.90928682263866
Validation loss: 5.79184086235849

Epoch: 6| Step: 4
Training loss: 5.739199570728176
Validation loss: 5.785828438306041

Epoch: 6| Step: 5
Training loss: 6.63094768212553
Validation loss: 5.779665603970806

Epoch: 6| Step: 6
Training loss: 5.800456377687287
Validation loss: 5.77312082642755

Epoch: 6| Step: 7
Training loss: 5.440858877765421
Validation loss: 5.766960084842995

Epoch: 6| Step: 8
Training loss: 5.405112439026188
Validation loss: 5.760797756774195

Epoch: 6| Step: 9
Training loss: 7.292958811756753
Validation loss: 5.754944507404069

Epoch: 6| Step: 10
Training loss: 6.65701905585082
Validation loss: 5.7482033339544785

Epoch: 6| Step: 11
Training loss: 4.987193300382577
Validation loss: 5.742051541474917

Epoch: 6| Step: 12
Training loss: 5.2353157678372035
Validation loss: 5.735427652979502

Epoch: 6| Step: 13
Training loss: 5.267585728929439
Validation loss: 5.72902061775924

Epoch: 2| Step: 0
Training loss: 5.876557164087082
Validation loss: 5.722209269467179

Epoch: 6| Step: 1
Training loss: 5.749395919249195
Validation loss: 5.71448044965153

Epoch: 6| Step: 2
Training loss: 5.449809555785958
Validation loss: 5.707383777074925

Epoch: 6| Step: 3
Training loss: 5.819794374484316
Validation loss: 5.6992220894862236

Epoch: 6| Step: 4
Training loss: 5.617970800631492
Validation loss: 5.691241227780709

Epoch: 6| Step: 5
Training loss: 4.615679861064238
Validation loss: 5.682801179068969

Epoch: 6| Step: 6
Training loss: 6.828313270609517
Validation loss: 5.674281490120409

Epoch: 6| Step: 7
Training loss: 5.417356515629338
Validation loss: 5.664520622173336

Epoch: 6| Step: 8
Training loss: 4.289026034396442
Validation loss: 5.655225435389759

Epoch: 6| Step: 9
Training loss: 6.233134593277299
Validation loss: 5.645854493867282

Epoch: 6| Step: 10
Training loss: 5.716049140222423
Validation loss: 5.635137105421141

Epoch: 6| Step: 11
Training loss: 6.000841081795522
Validation loss: 5.6244394695327795

Epoch: 6| Step: 12
Training loss: 6.086729730207654
Validation loss: 5.6124930487086635

Epoch: 6| Step: 13
Training loss: 5.694714675735485
Validation loss: 5.6000690746002615

Epoch: 3| Step: 0
Training loss: 6.147636157773908
Validation loss: 5.587368193061413

Epoch: 6| Step: 1
Training loss: 4.829073420829276
Validation loss: 5.573919272281086

Epoch: 6| Step: 2
Training loss: 6.787285013464802
Validation loss: 5.559804222822132

Epoch: 6| Step: 3
Training loss: 5.757859539114164
Validation loss: 5.5458694621150535

Epoch: 6| Step: 4
Training loss: 5.995167375507673
Validation loss: 5.530546593786505

Epoch: 6| Step: 5
Training loss: 4.732532306284797
Validation loss: 5.515677240967852

Epoch: 6| Step: 6
Training loss: 5.02648890058703
Validation loss: 5.5001800093740325

Epoch: 6| Step: 7
Training loss: 5.022391535193974
Validation loss: 5.4837321364595635

Epoch: 6| Step: 8
Training loss: 4.7865891907424665
Validation loss: 5.467466969263889

Epoch: 6| Step: 9
Training loss: 5.05689748949277
Validation loss: 5.451089072941417

Epoch: 6| Step: 10
Training loss: 4.8443036162956865
Validation loss: 5.432548130466381

Epoch: 6| Step: 11
Training loss: 6.058547156896919
Validation loss: 5.415467631085549

Epoch: 6| Step: 12
Training loss: 5.310222002694003
Validation loss: 5.3980689552412695

Epoch: 6| Step: 13
Training loss: 7.235219424175524
Validation loss: 5.380562881976157

Epoch: 4| Step: 0
Training loss: 5.258589484519515
Validation loss: 5.360736948562301

Epoch: 6| Step: 1
Training loss: 5.43497224128604
Validation loss: 5.342451800352758

Epoch: 6| Step: 2
Training loss: 5.156506341284288
Validation loss: 5.323874350716172

Epoch: 6| Step: 3
Training loss: 5.398307301873789
Validation loss: 5.304621097138759

Epoch: 6| Step: 4
Training loss: 3.9100411290495876
Validation loss: 5.284764918616508

Epoch: 6| Step: 5
Training loss: 5.474903241700391
Validation loss: 5.266003521795123

Epoch: 6| Step: 6
Training loss: 5.169989389080323
Validation loss: 5.246962512896666

Epoch: 6| Step: 7
Training loss: 4.9681831852285105
Validation loss: 5.228689367637179

Epoch: 6| Step: 8
Training loss: 5.477072350554001
Validation loss: 5.209976534960364

Epoch: 6| Step: 9
Training loss: 5.431866061934418
Validation loss: 5.1898447453744625

Epoch: 6| Step: 10
Training loss: 5.191716514254209
Validation loss: 5.17269585899865

Epoch: 6| Step: 11
Training loss: 5.6539558268259595
Validation loss: 5.15310745209903

Epoch: 6| Step: 12
Training loss: 6.3698865540850935
Validation loss: 5.134925327393328

Epoch: 6| Step: 13
Training loss: 4.387893424368154
Validation loss: 5.115847547024719

Epoch: 5| Step: 0
Training loss: 5.332562072936306
Validation loss: 5.095841553692596

Epoch: 6| Step: 1
Training loss: 4.9270031568309225
Validation loss: 5.078976722895389

Epoch: 6| Step: 2
Training loss: 5.313823579948656
Validation loss: 5.061075866832128

Epoch: 6| Step: 3
Training loss: 5.082814841587994
Validation loss: 5.041803783049532

Epoch: 6| Step: 4
Training loss: 4.7318450916308965
Validation loss: 5.024265682445503

Epoch: 6| Step: 5
Training loss: 4.296860351537531
Validation loss: 5.005109821636725

Epoch: 6| Step: 6
Training loss: 6.255539842175176
Validation loss: 4.989215929872738

Epoch: 6| Step: 7
Training loss: 5.422103305374252
Validation loss: 4.970341063495444

Epoch: 6| Step: 8
Training loss: 4.997595017919596
Validation loss: 4.95177828998997

Epoch: 6| Step: 9
Training loss: 4.135244191350098
Validation loss: 4.9320986763120445

Epoch: 6| Step: 10
Training loss: 6.133658070191188
Validation loss: 4.9149097677541205

Epoch: 6| Step: 11
Training loss: 4.493462794520745
Validation loss: 4.898368834837113

Epoch: 6| Step: 12
Training loss: 4.714641272772789
Validation loss: 4.878750263344095

Epoch: 6| Step: 13
Training loss: 3.736903782880598
Validation loss: 4.86233186811519

Epoch: 6| Step: 0
Training loss: 4.871879557080734
Validation loss: 4.84496847725452

Epoch: 6| Step: 1
Training loss: 4.388624285247648
Validation loss: 4.829758389547283

Epoch: 6| Step: 2
Training loss: 3.3626000825530156
Validation loss: 4.81283806160946

Epoch: 6| Step: 3
Training loss: 4.776777581690548
Validation loss: 4.797117676534815

Epoch: 6| Step: 4
Training loss: 5.363371223867482
Validation loss: 4.782126700001877

Epoch: 6| Step: 5
Training loss: 4.98633960045683
Validation loss: 4.767721516596842

Epoch: 6| Step: 6
Training loss: 5.47893147513755
Validation loss: 4.749618923010803

Epoch: 6| Step: 7
Training loss: 5.172366761399341
Validation loss: 4.732155772124848

Epoch: 6| Step: 8
Training loss: 5.361898912295784
Validation loss: 4.714194877785309

Epoch: 6| Step: 9
Training loss: 5.734364356257152
Validation loss: 4.695523546097788

Epoch: 6| Step: 10
Training loss: 4.208619111181012
Validation loss: 4.678702480626759

Epoch: 6| Step: 11
Training loss: 3.593706744389816
Validation loss: 4.660521712748398

Epoch: 6| Step: 12
Training loss: 4.689222705904603
Validation loss: 4.644585397914355

Epoch: 6| Step: 13
Training loss: 4.956724188923426
Validation loss: 4.625220333705571

Epoch: 7| Step: 0
Training loss: 5.014445608878842
Validation loss: 4.610950143133407

Epoch: 6| Step: 1
Training loss: 4.779734252820745
Validation loss: 4.594050431279126

Epoch: 6| Step: 2
Training loss: 4.460583674466711
Validation loss: 4.577264681622351

Epoch: 6| Step: 3
Training loss: 5.0448307585896774
Validation loss: 4.563077430747665

Epoch: 6| Step: 4
Training loss: 4.335435113068688
Validation loss: 4.544467629418006

Epoch: 6| Step: 5
Training loss: 4.953855250104636
Validation loss: 4.528519088327376

Epoch: 6| Step: 6
Training loss: 3.379693617619001
Validation loss: 4.511680833777685

Epoch: 6| Step: 7
Training loss: 4.204240275186934
Validation loss: 4.496832691177651

Epoch: 6| Step: 8
Training loss: 4.921536291668978
Validation loss: 4.482322834724195

Epoch: 6| Step: 9
Training loss: 5.208867567002103
Validation loss: 4.465235055141457

Epoch: 6| Step: 10
Training loss: 3.8038212536153124
Validation loss: 4.447717320035874

Epoch: 6| Step: 11
Training loss: 4.982715103092287
Validation loss: 4.4303055265357605

Epoch: 6| Step: 12
Training loss: 4.695488797906937
Validation loss: 4.413465354690097

Epoch: 6| Step: 13
Training loss: 4.152785843777912
Validation loss: 4.394170310744859

Epoch: 8| Step: 0
Training loss: 3.690712257019142
Validation loss: 4.376727059513425

Epoch: 6| Step: 1
Training loss: 5.447032596586546
Validation loss: 4.358371155195772

Epoch: 6| Step: 2
Training loss: 3.8422856216343124
Validation loss: 4.343635768278063

Epoch: 6| Step: 3
Training loss: 5.226953511800767
Validation loss: 4.328385203664942

Epoch: 6| Step: 4
Training loss: 4.3376958357605275
Validation loss: 4.310165148915429

Epoch: 6| Step: 5
Training loss: 3.994900074880017
Validation loss: 4.292756113291096

Epoch: 6| Step: 6
Training loss: 5.075193151547308
Validation loss: 4.277002428579095

Epoch: 6| Step: 7
Training loss: 3.7717810997577454
Validation loss: 4.264565622774345

Epoch: 6| Step: 8
Training loss: 4.866623749391322
Validation loss: 4.2484795204867565

Epoch: 6| Step: 9
Training loss: 4.252470532583755
Validation loss: 4.235707883955274

Epoch: 6| Step: 10
Training loss: 4.277185891778849
Validation loss: 4.224510891821086

Epoch: 6| Step: 11
Training loss: 4.271711206540076
Validation loss: 4.21263772500712

Epoch: 6| Step: 12
Training loss: 3.8475022028569095
Validation loss: 4.203830425428893

Epoch: 6| Step: 13
Training loss: 4.0938177903947
Validation loss: 4.191712524721647

Epoch: 9| Step: 0
Training loss: 4.56937423595432
Validation loss: 4.182484281890764

Epoch: 6| Step: 1
Training loss: 4.641730899240799
Validation loss: 4.171217567291972

Epoch: 6| Step: 2
Training loss: 4.327295327109355
Validation loss: 4.16228257581778

Epoch: 6| Step: 3
Training loss: 4.435008679438445
Validation loss: 4.154964416279667

Epoch: 6| Step: 4
Training loss: 3.5171611227353874
Validation loss: 4.143642790245826

Epoch: 6| Step: 5
Training loss: 4.809171640361267
Validation loss: 4.134513736363011

Epoch: 6| Step: 6
Training loss: 3.5934065944962503
Validation loss: 4.1235066044570585

Epoch: 6| Step: 7
Training loss: 3.5146966005053004
Validation loss: 4.1165183640230865

Epoch: 6| Step: 8
Training loss: 3.8949717556635752
Validation loss: 4.10576377606249

Epoch: 6| Step: 9
Training loss: 3.9811195388091023
Validation loss: 4.098865306847429

Epoch: 6| Step: 10
Training loss: 4.285257510411946
Validation loss: 4.09171877331344

Epoch: 6| Step: 11
Training loss: 4.558860267621422
Validation loss: 4.0837730730121615

Epoch: 6| Step: 12
Training loss: 4.647848652960859
Validation loss: 4.0752201172111535

Epoch: 6| Step: 13
Training loss: 4.75208577991218
Validation loss: 4.067937685376457

Epoch: 10| Step: 0
Training loss: 3.8779503450249337
Validation loss: 4.058441320635423

Epoch: 6| Step: 1
Training loss: 4.372590627718015
Validation loss: 4.051715107264167

Epoch: 6| Step: 2
Training loss: 4.27967527066754
Validation loss: 4.042014813733752

Epoch: 6| Step: 3
Training loss: 5.036669353599682
Validation loss: 4.035716042861067

Epoch: 6| Step: 4
Training loss: 3.860026316182455
Validation loss: 4.027479697543503

Epoch: 6| Step: 5
Training loss: 3.363407713033286
Validation loss: 4.019832161056817

Epoch: 6| Step: 6
Training loss: 4.176750163476454
Validation loss: 4.012551583095357

Epoch: 6| Step: 7
Training loss: 4.957050873557494
Validation loss: 4.0037388952432025

Epoch: 6| Step: 8
Training loss: 3.7907794012086655
Validation loss: 3.9958719235615745

Epoch: 6| Step: 9
Training loss: 3.957350210607104
Validation loss: 3.9912840985340745

Epoch: 6| Step: 10
Training loss: 4.28018086024541
Validation loss: 3.9835974008301367

Epoch: 6| Step: 11
Training loss: 4.408923481101371
Validation loss: 3.97834658095096

Epoch: 6| Step: 12
Training loss: 3.6560941483626888
Validation loss: 3.9729803288726995

Epoch: 6| Step: 13
Training loss: 3.646952488197766
Validation loss: 3.9654418216200846

Epoch: 11| Step: 0
Training loss: 3.3556752257941027
Validation loss: 3.95791767228497

Epoch: 6| Step: 1
Training loss: 4.0632706131343905
Validation loss: 3.9535368212360136

Epoch: 6| Step: 2
Training loss: 4.49908141191348
Validation loss: 3.9480961909159062

Epoch: 6| Step: 3
Training loss: 4.416754571771634
Validation loss: 3.9434617721259606

Epoch: 6| Step: 4
Training loss: 4.648732716137686
Validation loss: 3.9386955460659587

Epoch: 6| Step: 5
Training loss: 4.303637257034649
Validation loss: 3.932043197964877

Epoch: 6| Step: 6
Training loss: 4.3204129364314445
Validation loss: 3.927717605740798

Epoch: 6| Step: 7
Training loss: 3.986385541294004
Validation loss: 3.9226179763694566

Epoch: 6| Step: 8
Training loss: 4.528943546885841
Validation loss: 3.918594403475119

Epoch: 6| Step: 9
Training loss: 3.6504789273362177
Validation loss: 3.9156727944745753

Epoch: 6| Step: 10
Training loss: 3.3624664985661186
Validation loss: 3.9108915871886225

Epoch: 6| Step: 11
Training loss: 4.635012742635089
Validation loss: 3.905802756024546

Epoch: 6| Step: 12
Training loss: 3.9714814646179217
Validation loss: 3.8980326415072044

Epoch: 6| Step: 13
Training loss: 1.8642951557941356
Validation loss: 3.8959615248815442

Epoch: 12| Step: 0
Training loss: 4.302831232242229
Validation loss: 3.8916267679838508

Epoch: 6| Step: 1
Training loss: 3.9486107664808463
Validation loss: 3.887685984273114

Epoch: 6| Step: 2
Training loss: 4.696023338194892
Validation loss: 3.8811278198619727

Epoch: 6| Step: 3
Training loss: 4.932608003821138
Validation loss: 3.876964838389394

Epoch: 6| Step: 4
Training loss: 2.8415220147360274
Validation loss: 3.8730344282681304

Epoch: 6| Step: 5
Training loss: 4.184299441532149
Validation loss: 3.866621650041959

Epoch: 6| Step: 6
Training loss: 4.265845436297118
Validation loss: 3.8660558724330367

Epoch: 6| Step: 7
Training loss: 3.9032672938605906
Validation loss: 3.8605025468857552

Epoch: 6| Step: 8
Training loss: 3.029759620724885
Validation loss: 3.8556334245758035

Epoch: 6| Step: 9
Training loss: 4.26773857321379
Validation loss: 3.8523762933213126

Epoch: 6| Step: 10
Training loss: 4.418289078517572
Validation loss: 3.8490443510285703

Epoch: 6| Step: 11
Training loss: 3.1182889976047776
Validation loss: 3.8467286716635627

Epoch: 6| Step: 12
Training loss: 3.6673626383701783
Validation loss: 3.8411514805550113

Epoch: 6| Step: 13
Training loss: 4.336710543067244
Validation loss: 3.835818487418454

Epoch: 13| Step: 0
Training loss: 4.11793444696453
Validation loss: 3.828705755618661

Epoch: 6| Step: 1
Training loss: 3.8484914425079135
Validation loss: 3.8252486934479446

Epoch: 6| Step: 2
Training loss: 3.976708310195129
Validation loss: 3.8210209813781266

Epoch: 6| Step: 3
Training loss: 2.8882824452784415
Validation loss: 3.818295509700805

Epoch: 6| Step: 4
Training loss: 3.9575857694661103
Validation loss: 3.811856018257709

Epoch: 6| Step: 5
Training loss: 3.836441908107332
Validation loss: 3.8102670105101515

Epoch: 6| Step: 6
Training loss: 3.847053410896327
Validation loss: 3.804025781526872

Epoch: 6| Step: 7
Training loss: 4.105551445706149
Validation loss: 3.8015839823483937

Epoch: 6| Step: 8
Training loss: 4.187596106493921
Validation loss: 3.7967598014508095

Epoch: 6| Step: 9
Training loss: 4.926734680786876
Validation loss: 3.7937106713086735

Epoch: 6| Step: 10
Training loss: 4.243479045594592
Validation loss: 3.7919528523680412

Epoch: 6| Step: 11
Training loss: 3.689375190456979
Validation loss: 3.7875297454518257

Epoch: 6| Step: 12
Training loss: 3.2665984970557367
Validation loss: 3.7881591071761638

Epoch: 6| Step: 13
Training loss: 4.676380447326197
Validation loss: 3.7828595986473967

Epoch: 14| Step: 0
Training loss: 4.237322130099211
Validation loss: 3.776684205150701

Epoch: 6| Step: 1
Training loss: 3.9164506703872397
Validation loss: 3.7725242549609304

Epoch: 6| Step: 2
Training loss: 4.664957187533819
Validation loss: 3.7703799746455378

Epoch: 6| Step: 3
Training loss: 4.257831762427759
Validation loss: 3.766512991815593

Epoch: 6| Step: 4
Training loss: 2.81191620595789
Validation loss: 3.7661422206124873

Epoch: 6| Step: 5
Training loss: 2.866001476322068
Validation loss: 3.7636184162820365

Epoch: 6| Step: 6
Training loss: 3.9643333068897264
Validation loss: 3.761341862763467

Epoch: 6| Step: 7
Training loss: 4.490919700514554
Validation loss: 3.7590746745663

Epoch: 6| Step: 8
Training loss: 3.088653373735217
Validation loss: 3.7546074977260946

Epoch: 6| Step: 9
Training loss: 4.0049431774666076
Validation loss: 3.7497181256638434

Epoch: 6| Step: 10
Training loss: 3.051050699328519
Validation loss: 3.7469865442791694

Epoch: 6| Step: 11
Training loss: 3.4682582472287464
Validation loss: 3.742514239685604

Epoch: 6| Step: 12
Training loss: 5.3809051013256735
Validation loss: 3.7400170596092686

Epoch: 6| Step: 13
Training loss: 4.0200712176794635
Validation loss: 3.735229868023448

Epoch: 15| Step: 0
Training loss: 3.5598241561151496
Validation loss: 3.732451261380437

Epoch: 6| Step: 1
Training loss: 2.975575681492827
Validation loss: 3.727705370783181

Epoch: 6| Step: 2
Training loss: 4.040090168239427
Validation loss: 3.7296245062685704

Epoch: 6| Step: 3
Training loss: 4.999267905998564
Validation loss: 3.7260874312580627

Epoch: 6| Step: 4
Training loss: 4.103636938205605
Validation loss: 3.723256939419464

Epoch: 6| Step: 5
Training loss: 3.709811969526645
Validation loss: 3.7231420768462073

Epoch: 6| Step: 6
Training loss: 4.779178345102522
Validation loss: 3.7154757847944655

Epoch: 6| Step: 7
Training loss: 4.234262387513154
Validation loss: 3.7138847994846995

Epoch: 6| Step: 8
Training loss: 3.665431175733699
Validation loss: 3.7105165829413522

Epoch: 6| Step: 9
Training loss: 3.1241182227629936
Validation loss: 3.7066013088544647

Epoch: 6| Step: 10
Training loss: 3.720935339702384
Validation loss: 3.7048854531393554

Epoch: 6| Step: 11
Training loss: 3.878607762464365
Validation loss: 3.7035348635191334

Epoch: 6| Step: 12
Training loss: 3.2479241417355715
Validation loss: 3.7004624311975785

Epoch: 6| Step: 13
Training loss: 4.126018514024891
Validation loss: 3.697567251850832

Epoch: 16| Step: 0
Training loss: 3.934002730957697
Validation loss: 3.6958482521263685

Epoch: 6| Step: 1
Training loss: 3.5169889389788267
Validation loss: 3.694716819126886

Epoch: 6| Step: 2
Training loss: 3.3365224999815752
Validation loss: 3.6924686456786358

Epoch: 6| Step: 3
Training loss: 2.8610821406637386
Validation loss: 3.692381662730388

Epoch: 6| Step: 4
Training loss: 3.9095959790756503
Validation loss: 3.6890655247793855

Epoch: 6| Step: 5
Training loss: 4.68730305575855
Validation loss: 3.6854940902422157

Epoch: 6| Step: 6
Training loss: 3.4152570158055147
Validation loss: 3.68343932814499

Epoch: 6| Step: 7
Training loss: 3.9668709218839817
Validation loss: 3.6844499730558704

Epoch: 6| Step: 8
Training loss: 3.898300260218964
Validation loss: 3.681379594664396

Epoch: 6| Step: 9
Training loss: 4.530330801500097
Validation loss: 3.6742997373546853

Epoch: 6| Step: 10
Training loss: 3.721962574938217
Validation loss: 3.6769465575840194

Epoch: 6| Step: 11
Training loss: 3.4900715197036414
Validation loss: 3.6777102074816845

Epoch: 6| Step: 12
Training loss: 4.478424909815008
Validation loss: 3.6753591560787733

Epoch: 6| Step: 13
Training loss: 4.146622140242609
Validation loss: 3.6739271710724783

Epoch: 17| Step: 0
Training loss: 3.38803958325643
Validation loss: 3.6716265962456056

Epoch: 6| Step: 1
Training loss: 3.9480982246354546
Validation loss: 3.670875760000944

Epoch: 6| Step: 2
Training loss: 3.9894845550234317
Validation loss: 3.667376552076415

Epoch: 6| Step: 3
Training loss: 3.365947309130343
Validation loss: 3.666728785949763

Epoch: 6| Step: 4
Training loss: 4.70125017786368
Validation loss: 3.665197072803862

Epoch: 6| Step: 5
Training loss: 3.7774566033910872
Validation loss: 3.657764010212606

Epoch: 6| Step: 6
Training loss: 3.7620584526651806
Validation loss: 3.6562561015472674

Epoch: 6| Step: 7
Training loss: 3.460931162257882
Validation loss: 3.654990591530286

Epoch: 6| Step: 8
Training loss: 4.330708417844663
Validation loss: 3.653130178303041

Epoch: 6| Step: 9
Training loss: 3.959790667578588
Validation loss: 3.652135501557743

Epoch: 6| Step: 10
Training loss: 3.8740735330845353
Validation loss: 3.6492892170119697

Epoch: 6| Step: 11
Training loss: 3.3096460968012544
Validation loss: 3.64599156799551

Epoch: 6| Step: 12
Training loss: 4.324482069811267
Validation loss: 3.6450101822639227

Epoch: 6| Step: 13
Training loss: 2.979950986113475
Validation loss: 3.6423484613058337

Epoch: 18| Step: 0
Training loss: 3.8659029590092615
Validation loss: 3.6405563252951225

Epoch: 6| Step: 1
Training loss: 2.9596287394005096
Validation loss: 3.6372232223931698

Epoch: 6| Step: 2
Training loss: 4.031522283303959
Validation loss: 3.6399199783560454

Epoch: 6| Step: 3
Training loss: 2.96243385208901
Validation loss: 3.639523526101283

Epoch: 6| Step: 4
Training loss: 4.239186161317138
Validation loss: 3.6381301031363273

Epoch: 6| Step: 5
Training loss: 3.327121637100382
Validation loss: 3.631468035345554

Epoch: 6| Step: 6
Training loss: 2.949474844013549
Validation loss: 3.6280781311776584

Epoch: 6| Step: 7
Training loss: 4.235622320828682
Validation loss: 3.626795195864725

Epoch: 6| Step: 8
Training loss: 4.6634985296853
Validation loss: 3.624144747801125

Epoch: 6| Step: 9
Training loss: 3.7262393963294045
Validation loss: 3.623553805471967

Epoch: 6| Step: 10
Training loss: 4.400498986126948
Validation loss: 3.6192063060226287

Epoch: 6| Step: 11
Training loss: 4.481833345759317
Validation loss: 3.6171361727818048

Epoch: 6| Step: 12
Training loss: 3.2167990985021913
Validation loss: 3.615067721919564

Epoch: 6| Step: 13
Training loss: 3.8505377653989674
Validation loss: 3.6160266010612023

Epoch: 19| Step: 0
Training loss: 1.7736004321836394
Validation loss: 3.609652707374565

Epoch: 6| Step: 1
Training loss: 4.392402696307934
Validation loss: 3.610554639842707

Epoch: 6| Step: 2
Training loss: 3.727238303911558
Validation loss: 3.59732594110028

Epoch: 6| Step: 3
Training loss: 4.415352583876106
Validation loss: 3.5714960420625377

Epoch: 6| Step: 4
Training loss: 3.989458976912383
Validation loss: 3.560353540455323

Epoch: 6| Step: 5
Training loss: 4.268837190913284
Validation loss: 3.5683926858844726

Epoch: 6| Step: 6
Training loss: 3.6926857643173077
Validation loss: 3.560012219320363

Epoch: 6| Step: 7
Training loss: 3.5576974722017805
Validation loss: 3.551836087405991

Epoch: 6| Step: 8
Training loss: 4.356187755955512
Validation loss: 3.5479449039512603

Epoch: 6| Step: 9
Training loss: 3.1793497641963997
Validation loss: 3.558881766246047

Epoch: 6| Step: 10
Training loss: 3.1582132408909573
Validation loss: 3.5489303577121727

Epoch: 6| Step: 11
Training loss: 3.8418266632678395
Validation loss: 3.5490237054633176

Epoch: 6| Step: 12
Training loss: 3.921515338105548
Validation loss: 3.545664433392847

Epoch: 6| Step: 13
Training loss: 3.5219274021098763
Validation loss: 3.5409241541614245

Epoch: 20| Step: 0
Training loss: 3.25580621137047
Validation loss: 3.5363822620860907

Epoch: 6| Step: 1
Training loss: 3.70663118766253
Validation loss: 3.5329142141012855

Epoch: 6| Step: 2
Training loss: 3.7076261181772283
Validation loss: 3.5314039276112115

Epoch: 6| Step: 3
Training loss: 2.9663778364474904
Validation loss: 3.5297815941686594

Epoch: 6| Step: 4
Training loss: 2.3077585223064028
Validation loss: 3.5279740596090385

Epoch: 6| Step: 5
Training loss: 3.068042799500664
Validation loss: 3.52503571059862

Epoch: 6| Step: 6
Training loss: 4.048924225523763
Validation loss: 3.523982206451208

Epoch: 6| Step: 7
Training loss: 3.3592015421243113
Validation loss: 3.525485678070746

Epoch: 6| Step: 8
Training loss: 4.639766934888326
Validation loss: 3.5286753295397

Epoch: 6| Step: 9
Training loss: 3.488243521457502
Validation loss: 3.5220001092205346

Epoch: 6| Step: 10
Training loss: 3.87326921756837
Validation loss: 3.517300384086558

Epoch: 6| Step: 11
Training loss: 4.215521813579738
Validation loss: 3.516379793327781

Epoch: 6| Step: 12
Training loss: 4.285457576147836
Validation loss: 3.517155800341152

Epoch: 6| Step: 13
Training loss: 5.142485215347097
Validation loss: 3.5119633099036336

Epoch: 21| Step: 0
Training loss: 3.5769092876651287
Validation loss: 3.5125303791816753

Epoch: 6| Step: 1
Training loss: 3.591612470414128
Validation loss: 3.512498712055903

Epoch: 6| Step: 2
Training loss: 3.4936752393226884
Validation loss: 3.5105022608522636

Epoch: 6| Step: 3
Training loss: 2.884161904709603
Validation loss: 3.505263604288766

Epoch: 6| Step: 4
Training loss: 3.48337968372615
Validation loss: 3.504118345157001

Epoch: 6| Step: 5
Training loss: 3.4701892513148915
Validation loss: 3.5000505809967164

Epoch: 6| Step: 6
Training loss: 4.0583192881211225
Validation loss: 3.4981609558179327

Epoch: 6| Step: 7
Training loss: 3.944312605348483
Validation loss: 3.4996157389828237

Epoch: 6| Step: 8
Training loss: 3.958287181919824
Validation loss: 3.496335723453823

Epoch: 6| Step: 9
Training loss: 2.7919452205629005
Validation loss: 3.4961650409168032

Epoch: 6| Step: 10
Training loss: 3.719781171658738
Validation loss: 3.495411248225256

Epoch: 6| Step: 11
Training loss: 4.354541135805008
Validation loss: 3.494421034224658

Epoch: 6| Step: 12
Training loss: 4.463621170718733
Validation loss: 3.4906974300899125

Epoch: 6| Step: 13
Training loss: 3.8724069841023816
Validation loss: 3.4922895761401263

Epoch: 22| Step: 0
Training loss: 4.5610098299549096
Validation loss: 3.489142533906494

Epoch: 6| Step: 1
Training loss: 4.382368367857349
Validation loss: 3.4895832108907934

Epoch: 6| Step: 2
Training loss: 3.093357408062656
Validation loss: 3.4867213426980186

Epoch: 6| Step: 3
Training loss: 3.2197896519069156
Validation loss: 3.487129975288603

Epoch: 6| Step: 4
Training loss: 4.261749407328434
Validation loss: 3.4824273609048255

Epoch: 6| Step: 5
Training loss: 3.8059680201619672
Validation loss: 3.4851908888050134

Epoch: 6| Step: 6
Training loss: 3.4344539671437144
Validation loss: 3.4830314245350764

Epoch: 6| Step: 7
Training loss: 4.0385555340234705
Validation loss: 3.49738142615487

Epoch: 6| Step: 8
Training loss: 2.4028861573263933
Validation loss: 3.4765790163970327

Epoch: 6| Step: 9
Training loss: 2.8164446824159155
Validation loss: 3.4798080214744482

Epoch: 6| Step: 10
Training loss: 4.054327388346853
Validation loss: 3.4795529585404115

Epoch: 6| Step: 11
Training loss: 4.121875851438028
Validation loss: 3.4820670705483736

Epoch: 6| Step: 12
Training loss: 3.557110641736311
Validation loss: 3.479989694580785

Epoch: 6| Step: 13
Training loss: 3.0319497785309193
Validation loss: 3.4813730883347107

Epoch: 23| Step: 0
Training loss: 3.8605228832857663
Validation loss: 3.4769981598917425

Epoch: 6| Step: 1
Training loss: 3.059452798573101
Validation loss: 3.474493325584388

Epoch: 6| Step: 2
Training loss: 3.1778886285164094
Validation loss: 3.4751173086219205

Epoch: 6| Step: 3
Training loss: 4.017770394493828
Validation loss: 3.473089800882065

Epoch: 6| Step: 4
Training loss: 3.547988918343046
Validation loss: 3.4717802059801874

Epoch: 6| Step: 5
Training loss: 3.754023872620692
Validation loss: 3.4688131719644284

Epoch: 6| Step: 6
Training loss: 3.8618926820783908
Validation loss: 3.4661811215457052

Epoch: 6| Step: 7
Training loss: 3.7163275514088303
Validation loss: 3.4647556681305014

Epoch: 6| Step: 8
Training loss: 2.550544201992657
Validation loss: 3.4643458690208377

Epoch: 6| Step: 9
Training loss: 4.780750522828339
Validation loss: 3.461885393621246

Epoch: 6| Step: 10
Training loss: 3.31625297560632
Validation loss: 3.4577426714865886

Epoch: 6| Step: 11
Training loss: 3.307213938042476
Validation loss: 3.455894314868963

Epoch: 6| Step: 12
Training loss: 3.327837434622066
Validation loss: 3.455048783540246

Epoch: 6| Step: 13
Training loss: 5.27852799733065
Validation loss: 3.45335165978277

Epoch: 24| Step: 0
Training loss: 3.475432137164969
Validation loss: 3.4508727800799264

Epoch: 6| Step: 1
Training loss: 2.5849091020610317
Validation loss: 3.4489323926353057

Epoch: 6| Step: 2
Training loss: 3.495388535280912
Validation loss: 3.44799983233452

Epoch: 6| Step: 3
Training loss: 4.5299672382845815
Validation loss: 3.4479237401389264

Epoch: 6| Step: 4
Training loss: 4.497806226261757
Validation loss: 3.445311017761961

Epoch: 6| Step: 5
Training loss: 2.8011196894978583
Validation loss: 3.443373359984622

Epoch: 6| Step: 6
Training loss: 3.434863102168651
Validation loss: 3.443423575617579

Epoch: 6| Step: 7
Training loss: 2.991649927997427
Validation loss: 3.4432066949407365

Epoch: 6| Step: 8
Training loss: 3.765171387762267
Validation loss: 3.440011044973646

Epoch: 6| Step: 9
Training loss: 3.167908542122073
Validation loss: 3.4393568868726376

Epoch: 6| Step: 10
Training loss: 4.094685687810239
Validation loss: 3.439574523088866

Epoch: 6| Step: 11
Training loss: 3.979919335779498
Validation loss: 3.435226970175817

Epoch: 6| Step: 12
Training loss: 3.77608938603558
Validation loss: 3.43551947852398

Epoch: 6| Step: 13
Training loss: 4.378148281299627
Validation loss: 3.4351237133452224

Epoch: 25| Step: 0
Training loss: 4.134479150591969
Validation loss: 3.4324150891714953

Epoch: 6| Step: 1
Training loss: 2.9662897456319914
Validation loss: 3.4316555168570235

Epoch: 6| Step: 2
Training loss: 2.0107732532356137
Validation loss: 3.432901333185863

Epoch: 6| Step: 3
Training loss: 3.9116026559237316
Validation loss: 3.4303977167977484

Epoch: 6| Step: 4
Training loss: 3.4138905636857713
Validation loss: 3.4287078495054777

Epoch: 6| Step: 5
Training loss: 3.3320538608369694
Validation loss: 3.4277045915542175

Epoch: 6| Step: 6
Training loss: 3.417530663889213
Validation loss: 3.4267867797487193

Epoch: 6| Step: 7
Training loss: 4.755097715575146
Validation loss: 3.424511985601271

Epoch: 6| Step: 8
Training loss: 3.4233587523212825
Validation loss: 3.4240267050397177

Epoch: 6| Step: 9
Training loss: 3.5323535916386266
Validation loss: 3.4234188903119165

Epoch: 6| Step: 10
Training loss: 4.17998274001067
Validation loss: 3.4218397908017826

Epoch: 6| Step: 11
Training loss: 2.5032449643537684
Validation loss: 3.422058341796838

Epoch: 6| Step: 12
Training loss: 5.000286666281756
Validation loss: 3.419560714670045

Epoch: 6| Step: 13
Training loss: 3.062558231967898
Validation loss: 3.4187674248082165

Epoch: 26| Step: 0
Training loss: 3.2268469733573255
Validation loss: 3.4178912301597077

Epoch: 6| Step: 1
Training loss: 3.3675340089163903
Validation loss: 3.4178530696389946

Epoch: 6| Step: 2
Training loss: 3.894608384940121
Validation loss: 3.415754351503525

Epoch: 6| Step: 3
Training loss: 3.385578390317865
Validation loss: 3.416008039171608

Epoch: 6| Step: 4
Training loss: 3.9473763987811936
Validation loss: 3.4159784791960197

Epoch: 6| Step: 5
Training loss: 4.168633162249498
Validation loss: 3.411667535274793

Epoch: 6| Step: 6
Training loss: 3.6555862476357754
Validation loss: 3.4127994366464423

Epoch: 6| Step: 7
Training loss: 3.7871558357210025
Validation loss: 3.4131125451077637

Epoch: 6| Step: 8
Training loss: 3.2586352729575436
Validation loss: 3.411815991221409

Epoch: 6| Step: 9
Training loss: 3.8543643935063647
Validation loss: 3.409385638530905

Epoch: 6| Step: 10
Training loss: 3.0226586100040866
Validation loss: 3.408179987337504

Epoch: 6| Step: 11
Training loss: 3.2585304987605284
Validation loss: 3.4085769194004305

Epoch: 6| Step: 12
Training loss: 3.6101048379822913
Validation loss: 3.406435663861255

Epoch: 6| Step: 13
Training loss: 4.639248525012543
Validation loss: 3.404856253400133

Epoch: 27| Step: 0
Training loss: 3.68149400818801
Validation loss: 3.404654680302173

Epoch: 6| Step: 1
Training loss: 3.4664374538596534
Validation loss: 3.4020660736538573

Epoch: 6| Step: 2
Training loss: 3.1510818016501756
Validation loss: 3.4047578446800637

Epoch: 6| Step: 3
Training loss: 3.928600487044235
Validation loss: 3.405100430994885

Epoch: 6| Step: 4
Training loss: 2.660358796551999
Validation loss: 3.41257342716663

Epoch: 6| Step: 5
Training loss: 3.86859758659224
Validation loss: 3.4101779338789706

Epoch: 6| Step: 6
Training loss: 3.805908508516109
Validation loss: 3.39763230782805

Epoch: 6| Step: 7
Training loss: 3.6695778011937112
Validation loss: 3.394326471655716

Epoch: 6| Step: 8
Training loss: 4.124280462220614
Validation loss: 3.3963115321971653

Epoch: 6| Step: 9
Training loss: 3.754687875913553
Validation loss: 3.400432778211961

Epoch: 6| Step: 10
Training loss: 2.9140791905311225
Validation loss: 3.4027067663537442

Epoch: 6| Step: 11
Training loss: 3.8873630315563954
Validation loss: 3.4035206419505792

Epoch: 6| Step: 12
Training loss: 4.112087964226581
Validation loss: 3.4023880882261466

Epoch: 6| Step: 13
Training loss: 3.2760638714853028
Validation loss: 3.3994024185288696

Epoch: 28| Step: 0
Training loss: 3.7412811647105553
Validation loss: 3.3977859674032387

Epoch: 6| Step: 1
Training loss: 3.1583082078992835
Validation loss: 3.3925069348955703

Epoch: 6| Step: 2
Training loss: 3.649434314944139
Validation loss: 3.3902142361296974

Epoch: 6| Step: 3
Training loss: 4.106195300244497
Validation loss: 3.3900930759488985

Epoch: 6| Step: 4
Training loss: 3.5548715397069355
Validation loss: 3.3870542371220593

Epoch: 6| Step: 5
Training loss: 3.6399766074466453
Validation loss: 3.389134599248584

Epoch: 6| Step: 6
Training loss: 3.36779850419106
Validation loss: 3.3851164552967923

Epoch: 6| Step: 7
Training loss: 2.895170854128849
Validation loss: 3.3864870172502246

Epoch: 6| Step: 8
Training loss: 3.6854218915115564
Validation loss: 3.3850778738020266

Epoch: 6| Step: 9
Training loss: 4.260803404076907
Validation loss: 3.3808102206085984

Epoch: 6| Step: 10
Training loss: 4.086867042553592
Validation loss: 3.376994872353069

Epoch: 6| Step: 11
Training loss: 3.3382955967304486
Validation loss: 3.37431193530929

Epoch: 6| Step: 12
Training loss: 3.319874454100819
Validation loss: 3.3724803064317217

Epoch: 6| Step: 13
Training loss: 3.4657665172195142
Validation loss: 3.3720266080730594

Epoch: 29| Step: 0
Training loss: 4.551631995317809
Validation loss: 3.372068819354586

Epoch: 6| Step: 1
Training loss: 3.5148254841747266
Validation loss: 3.3695743539726553

Epoch: 6| Step: 2
Training loss: 3.294512729533919
Validation loss: 3.3688196924367064

Epoch: 6| Step: 3
Training loss: 3.37019712828073
Validation loss: 3.366860865443459

Epoch: 6| Step: 4
Training loss: 4.256712605211813
Validation loss: 3.3642802478958953

Epoch: 6| Step: 5
Training loss: 2.9276148267161783
Validation loss: 3.3642353205644357

Epoch: 6| Step: 6
Training loss: 3.29920334881262
Validation loss: 3.363193150220014

Epoch: 6| Step: 7
Training loss: 4.197167240514563
Validation loss: 3.3651550278662614

Epoch: 6| Step: 8
Training loss: 3.514766740941011
Validation loss: 3.362845632935827

Epoch: 6| Step: 9
Training loss: 3.849494920768117
Validation loss: 3.3618360985746416

Epoch: 6| Step: 10
Training loss: 2.8807752900864476
Validation loss: 3.3614998364993354

Epoch: 6| Step: 11
Training loss: 3.95772239922856
Validation loss: 3.363506156264863

Epoch: 6| Step: 12
Training loss: 2.8285736233976584
Validation loss: 3.3643339620851047

Epoch: 6| Step: 13
Training loss: 3.2893467868622066
Validation loss: 3.3644163247162617

Epoch: 30| Step: 0
Training loss: 3.188233833362335
Validation loss: 3.3656821031963267

Epoch: 6| Step: 1
Training loss: 3.704490828231021
Validation loss: 3.3620034819178395

Epoch: 6| Step: 2
Training loss: 3.195434120307305
Validation loss: 3.357263072250542

Epoch: 6| Step: 3
Training loss: 2.859654147170714
Validation loss: 3.354448004905382

Epoch: 6| Step: 4
Training loss: 3.9677879789528636
Validation loss: 3.354583421356021

Epoch: 6| Step: 5
Training loss: 3.951199028461134
Validation loss: 3.3550917528616226

Epoch: 6| Step: 6
Training loss: 4.808785528453831
Validation loss: 3.3615836077463532

Epoch: 6| Step: 7
Training loss: 3.6561755311343207
Validation loss: 3.3522567651438377

Epoch: 6| Step: 8
Training loss: 3.4348403351614114
Validation loss: 3.3484899479471046

Epoch: 6| Step: 9
Training loss: 2.8984172645541104
Validation loss: 3.3471067115885127

Epoch: 6| Step: 10
Training loss: 3.7088556814741955
Validation loss: 3.346876812125289

Epoch: 6| Step: 11
Training loss: 3.167563378378163
Validation loss: 3.3448608105146627

Epoch: 6| Step: 12
Training loss: 3.9919918482664736
Validation loss: 3.343828059502361

Epoch: 6| Step: 13
Training loss: 2.82725891002857
Validation loss: 3.343630587991318

Epoch: 31| Step: 0
Training loss: 3.030244326167369
Validation loss: 3.342037330818327

Epoch: 6| Step: 1
Training loss: 3.074789806098064
Validation loss: 3.341737871871857

Epoch: 6| Step: 2
Training loss: 3.6461652913420024
Validation loss: 3.3408478547805758

Epoch: 6| Step: 3
Training loss: 4.185401276705245
Validation loss: 3.341135940087604

Epoch: 6| Step: 4
Training loss: 3.4837841679129715
Validation loss: 3.3415994645130627

Epoch: 6| Step: 5
Training loss: 3.871430137022644
Validation loss: 3.338960456059531

Epoch: 6| Step: 6
Training loss: 3.738820769502058
Validation loss: 3.3379207751258066

Epoch: 6| Step: 7
Training loss: 3.124016874162768
Validation loss: 3.339793493773932

Epoch: 6| Step: 8
Training loss: 2.7505515152420776
Validation loss: 3.340253677834388

Epoch: 6| Step: 9
Training loss: 3.6846995954078046
Validation loss: 3.3344583648339388

Epoch: 6| Step: 10
Training loss: 3.122046486361228
Validation loss: 3.335863358160575

Epoch: 6| Step: 11
Training loss: 4.228975689464304
Validation loss: 3.3332791267622555

Epoch: 6| Step: 12
Training loss: 4.000231259336618
Validation loss: 3.3330486288822674

Epoch: 6| Step: 13
Training loss: 3.8359622371831574
Validation loss: 3.3309708426882843

Epoch: 32| Step: 0
Training loss: 3.737619690270357
Validation loss: 3.332428734586801

Epoch: 6| Step: 1
Training loss: 3.9073567767995248
Validation loss: 3.33280248927044

Epoch: 6| Step: 2
Training loss: 3.8653534210207705
Validation loss: 3.3280156824496347

Epoch: 6| Step: 3
Training loss: 3.1794847428444233
Validation loss: 3.3250695302649382

Epoch: 6| Step: 4
Training loss: 3.431111728682432
Validation loss: 3.3277755477583444

Epoch: 6| Step: 5
Training loss: 3.633826592120092
Validation loss: 3.3263368973224154

Epoch: 6| Step: 6
Training loss: 3.821134077166248
Validation loss: 3.3261897825130284

Epoch: 6| Step: 7
Training loss: 4.054716194654005
Validation loss: 3.3229747783465617

Epoch: 6| Step: 8
Training loss: 3.6329369308327117
Validation loss: 3.3245506860766505

Epoch: 6| Step: 9
Training loss: 3.41729611126943
Validation loss: 3.3278099217877

Epoch: 6| Step: 10
Training loss: 3.12384133793473
Validation loss: 3.3181456587371327

Epoch: 6| Step: 11
Training loss: 3.5198256425590335
Validation loss: 3.323181637598647

Epoch: 6| Step: 12
Training loss: 2.6984715621379967
Validation loss: 3.3203506573698904

Epoch: 6| Step: 13
Training loss: 3.650862416843279
Validation loss: 3.325222953361188

Epoch: 33| Step: 0
Training loss: 3.3245780562372365
Validation loss: 3.3364504565086484

Epoch: 6| Step: 1
Training loss: 2.830065488293475
Validation loss: 3.317769514226046

Epoch: 6| Step: 2
Training loss: 3.1533857889900028
Validation loss: 3.3161512464030887

Epoch: 6| Step: 3
Training loss: 3.9971410547963497
Validation loss: 3.316922520686376

Epoch: 6| Step: 4
Training loss: 3.925296096810002
Validation loss: 3.3168198984257478

Epoch: 6| Step: 5
Training loss: 4.263959510596672
Validation loss: 3.3170989808245297

Epoch: 6| Step: 6
Training loss: 4.101727117232238
Validation loss: 3.31662287958108

Epoch: 6| Step: 7
Training loss: 2.290580792800631
Validation loss: 3.3175794346164076

Epoch: 6| Step: 8
Training loss: 3.870699310993807
Validation loss: 3.3121399191332546

Epoch: 6| Step: 9
Training loss: 3.368856702257708
Validation loss: 3.3135070044057104

Epoch: 6| Step: 10
Training loss: 3.454011138862713
Validation loss: 3.31755078499736

Epoch: 6| Step: 11
Training loss: 3.8549094369346437
Validation loss: 3.3175819437162377

Epoch: 6| Step: 12
Training loss: 3.1927571046639804
Validation loss: 3.3142460767761657

Epoch: 6| Step: 13
Training loss: 3.6537065054581688
Validation loss: 3.315108538506818

Epoch: 34| Step: 0
Training loss: 3.2153561671574185
Validation loss: 3.310369292721718

Epoch: 6| Step: 1
Training loss: 3.340037486385658
Validation loss: 3.312234545562121

Epoch: 6| Step: 2
Training loss: 3.051505458316237
Validation loss: 3.3109218578517616

Epoch: 6| Step: 3
Training loss: 4.473000379092028
Validation loss: 3.308846151671507

Epoch: 6| Step: 4
Training loss: 3.6594016031003536
Validation loss: 3.3085344243903263

Epoch: 6| Step: 5
Training loss: 4.135300923736796
Validation loss: 3.3069273962762673

Epoch: 6| Step: 6
Training loss: 3.3045258899608996
Validation loss: 3.3074584334947406

Epoch: 6| Step: 7
Training loss: 3.7460698195599047
Validation loss: 3.307292252161764

Epoch: 6| Step: 8
Training loss: 3.0825006202517686
Validation loss: 3.3057854430769424

Epoch: 6| Step: 9
Training loss: 3.659243540108753
Validation loss: 3.309106823635831

Epoch: 6| Step: 10
Training loss: 3.5014580005881566
Validation loss: 3.3046090419197283

Epoch: 6| Step: 11
Training loss: 3.3762961830276894
Validation loss: 3.3020694078021307

Epoch: 6| Step: 12
Training loss: 3.0947276410636335
Validation loss: 3.3020093702595736

Epoch: 6| Step: 13
Training loss: 3.9008522276300908
Validation loss: 3.3015198213005874

Epoch: 35| Step: 0
Training loss: 3.882788675338753
Validation loss: 3.302286526058369

Epoch: 6| Step: 1
Training loss: 3.7606715629323504
Validation loss: 3.302427073222305

Epoch: 6| Step: 2
Training loss: 3.536102336930261
Validation loss: 3.3064120003162953

Epoch: 6| Step: 3
Training loss: 2.940770215980127
Validation loss: 3.314383499305923

Epoch: 6| Step: 4
Training loss: 3.443634662669867
Validation loss: 3.3182843907635147

Epoch: 6| Step: 5
Training loss: 3.9216072629446557
Validation loss: 3.309120545498319

Epoch: 6| Step: 6
Training loss: 3.803092105068105
Validation loss: 3.3012273174553344

Epoch: 6| Step: 7
Training loss: 3.2493584806679414
Validation loss: 3.3024314390735663

Epoch: 6| Step: 8
Training loss: 4.171976952610745
Validation loss: 3.2998689044357916

Epoch: 6| Step: 9
Training loss: 2.325208949882572
Validation loss: 3.298762969209709

Epoch: 6| Step: 10
Training loss: 4.073298261609055
Validation loss: 3.298335580909657

Epoch: 6| Step: 11
Training loss: 3.213284936147366
Validation loss: 3.299080818439656

Epoch: 6| Step: 12
Training loss: 3.4299586021661024
Validation loss: 3.2966427142142622

Epoch: 6| Step: 13
Training loss: 3.365165227089932
Validation loss: 3.2941973438923666

Epoch: 36| Step: 0
Training loss: 3.141187626940104
Validation loss: 3.2966482324278816

Epoch: 6| Step: 1
Training loss: 4.577168752121817
Validation loss: 3.295505796318075

Epoch: 6| Step: 2
Training loss: 4.022605439600692
Validation loss: 3.293862750592911

Epoch: 6| Step: 3
Training loss: 2.9385920990289036
Validation loss: 3.2943817090181637

Epoch: 6| Step: 4
Training loss: 3.608874529865849
Validation loss: 3.2929049824011347

Epoch: 6| Step: 5
Training loss: 4.064647165824065
Validation loss: 3.2918684822127537

Epoch: 6| Step: 6
Training loss: 3.59420547916062
Validation loss: 3.289083225355547

Epoch: 6| Step: 7
Training loss: 4.0429074195227415
Validation loss: 3.293219612149772

Epoch: 6| Step: 8
Training loss: 3.7472172902907963
Validation loss: 3.292552647037007

Epoch: 6| Step: 9
Training loss: 2.6258044145646804
Validation loss: 3.2971670059057536

Epoch: 6| Step: 10
Training loss: 3.532370060544182
Validation loss: 3.2987881099849945

Epoch: 6| Step: 11
Training loss: 3.1393393546831323
Validation loss: 3.2956821336703066

Epoch: 6| Step: 12
Training loss: 2.686991177673962
Validation loss: 3.3061347320863606

Epoch: 6| Step: 13
Training loss: 2.9019750512363207
Validation loss: 3.298471519626771

Epoch: 37| Step: 0
Training loss: 3.236108140484743
Validation loss: 3.2972060033842197

Epoch: 6| Step: 1
Training loss: 3.213043487529976
Validation loss: 3.300577566405082

Epoch: 6| Step: 2
Training loss: 3.9144010416450103
Validation loss: 3.318779359852984

Epoch: 6| Step: 3
Training loss: 3.7025264465500234
Validation loss: 3.3189886047341473

Epoch: 6| Step: 4
Training loss: 3.9781663579356676
Validation loss: 3.3143874100662223

Epoch: 6| Step: 5
Training loss: 3.3884470048767765
Validation loss: 3.2953191135122903

Epoch: 6| Step: 6
Training loss: 3.492501263956157
Validation loss: 3.2932896992961074

Epoch: 6| Step: 7
Training loss: 2.9182357563791124
Validation loss: 3.299611255349474

Epoch: 6| Step: 8
Training loss: 3.050347486619112
Validation loss: 3.2990614909177878

Epoch: 6| Step: 9
Training loss: 4.157801976525695
Validation loss: 3.298377594266076

Epoch: 6| Step: 10
Training loss: 3.959286196946497
Validation loss: 3.288452639066835

Epoch: 6| Step: 11
Training loss: 3.7808121356758044
Validation loss: 3.2873223046369744

Epoch: 6| Step: 12
Training loss: 3.251374467566713
Validation loss: 3.2869916770804704

Epoch: 6| Step: 13
Training loss: 2.851366679117531
Validation loss: 3.2892430377013877

Epoch: 38| Step: 0
Training loss: 3.595800461661215
Validation loss: 3.2880746836419923

Epoch: 6| Step: 1
Training loss: 3.2191527772018382
Validation loss: 3.290814595645982

Epoch: 6| Step: 2
Training loss: 3.931037322145465
Validation loss: 3.2909638908669856

Epoch: 6| Step: 3
Training loss: 3.140330438417456
Validation loss: 3.2894977159555987

Epoch: 6| Step: 4
Training loss: 3.6995059327873117
Validation loss: 3.2880137364003996

Epoch: 6| Step: 5
Training loss: 3.99755355407837
Validation loss: 3.2855033625286825

Epoch: 6| Step: 6
Training loss: 3.2762292142148275
Validation loss: 3.2879380530883764

Epoch: 6| Step: 7
Training loss: 3.383385589897604
Validation loss: 3.285158946961035

Epoch: 6| Step: 8
Training loss: 2.9738789473770355
Validation loss: 3.284318482031825

Epoch: 6| Step: 9
Training loss: 3.143661776872729
Validation loss: 3.284159693072967

Epoch: 6| Step: 10
Training loss: 4.280907387494237
Validation loss: 3.2831862261206717

Epoch: 6| Step: 11
Training loss: 3.593104827022673
Validation loss: 3.284348994373271

Epoch: 6| Step: 12
Training loss: 3.3110855249473135
Validation loss: 3.2815459446577946

Epoch: 6| Step: 13
Training loss: 3.689181057787247
Validation loss: 3.2801753740124733

Epoch: 39| Step: 0
Training loss: 3.127789587431845
Validation loss: 3.2846592378206165

Epoch: 6| Step: 1
Training loss: 3.8720179743073735
Validation loss: 3.279455052020469

Epoch: 6| Step: 2
Training loss: 3.9367934304504835
Validation loss: 3.2794328805863935

Epoch: 6| Step: 3
Training loss: 3.9196132506106762
Validation loss: 3.280500921248088

Epoch: 6| Step: 4
Training loss: 3.2958745658857733
Validation loss: 3.276147478218407

Epoch: 6| Step: 5
Training loss: 4.059032427492607
Validation loss: 3.2762023994863494

Epoch: 6| Step: 6
Training loss: 3.5255903953527024
Validation loss: 3.276853964686028

Epoch: 6| Step: 7
Training loss: 2.963341534677949
Validation loss: 3.27634011255549

Epoch: 6| Step: 8
Training loss: 3.7605822976673835
Validation loss: 3.279379326753832

Epoch: 6| Step: 9
Training loss: 3.3261996865579793
Validation loss: 3.2879911377066326

Epoch: 6| Step: 10
Training loss: 2.9213747626494646
Validation loss: 3.29502910366566

Epoch: 6| Step: 11
Training loss: 3.5516442319273906
Validation loss: 3.290139783566578

Epoch: 6| Step: 12
Training loss: 3.8374077801387405
Validation loss: 3.275108351704147

Epoch: 6| Step: 13
Training loss: 2.4108575082044403
Validation loss: 3.2736568476801113

Epoch: 40| Step: 0
Training loss: 3.352223862349175
Validation loss: 3.278258932885433

Epoch: 6| Step: 1
Training loss: 4.201805162781416
Validation loss: 3.287751530071064

Epoch: 6| Step: 2
Training loss: 3.920253950573522
Validation loss: 3.2947451047958354

Epoch: 6| Step: 3
Training loss: 3.1489366462272823
Validation loss: 3.299197732302109

Epoch: 6| Step: 4
Training loss: 4.30308234166628
Validation loss: 3.2973706000687897

Epoch: 6| Step: 5
Training loss: 2.9260563434591713
Validation loss: 3.288411149092581

Epoch: 6| Step: 6
Training loss: 4.036150179349583
Validation loss: 3.28614010991287

Epoch: 6| Step: 7
Training loss: 3.2159141714495245
Validation loss: 3.2806723403099247

Epoch: 6| Step: 8
Training loss: 2.729506250662564
Validation loss: 3.2757868503432013

Epoch: 6| Step: 9
Training loss: 3.6179169481655107
Validation loss: 3.276428843548453

Epoch: 6| Step: 10
Training loss: 3.2416574067781934
Validation loss: 3.283482310132885

Epoch: 6| Step: 11
Training loss: 3.4744262990168324
Validation loss: 3.2869941978301926

Epoch: 6| Step: 12
Training loss: 3.692378679993059
Validation loss: 3.2816313225613207

Epoch: 6| Step: 13
Training loss: 2.937619957605106
Validation loss: 3.2780854043317404

Epoch: 41| Step: 0
Training loss: 4.60066957990857
Validation loss: 3.2703668812891538

Epoch: 6| Step: 1
Training loss: 3.4047884824149284
Validation loss: 3.27003455507906

Epoch: 6| Step: 2
Training loss: 3.0505120894988615
Validation loss: 3.270440021477944

Epoch: 6| Step: 3
Training loss: 3.4561697538417593
Validation loss: 3.2689856752794677

Epoch: 6| Step: 4
Training loss: 3.49260106720774
Validation loss: 3.2708290533243276

Epoch: 6| Step: 5
Training loss: 2.6469214497243287
Validation loss: 3.2678212413484156

Epoch: 6| Step: 6
Training loss: 3.1424206207616585
Validation loss: 3.2680045904698476

Epoch: 6| Step: 7
Training loss: 3.6052884834827434
Validation loss: 3.266509999751434

Epoch: 6| Step: 8
Training loss: 4.014203365433498
Validation loss: 3.2663155408663025

Epoch: 6| Step: 9
Training loss: 3.5088903049946363
Validation loss: 3.26585238313198

Epoch: 6| Step: 10
Training loss: 3.130298699943298
Validation loss: 3.2631703209709624

Epoch: 6| Step: 11
Training loss: 4.128130793946421
Validation loss: 3.2628814701812088

Epoch: 6| Step: 12
Training loss: 3.0546313034312904
Validation loss: 3.262261253230102

Epoch: 6| Step: 13
Training loss: 3.499857899642211
Validation loss: 3.2640081462543304

Epoch: 42| Step: 0
Training loss: 4.685274129723286
Validation loss: 3.26305805582451

Epoch: 6| Step: 1
Training loss: 3.1688973116067976
Validation loss: 3.2599535904185486

Epoch: 6| Step: 2
Training loss: 3.8650941057086676
Validation loss: 3.2614358153550547

Epoch: 6| Step: 3
Training loss: 3.1187752334705334
Validation loss: 3.262404323104234

Epoch: 6| Step: 4
Training loss: 3.309648113850203
Validation loss: 3.2606752407043023

Epoch: 6| Step: 5
Training loss: 2.546796738996016
Validation loss: 3.258089421421877

Epoch: 6| Step: 6
Training loss: 2.3077571792532194
Validation loss: 3.264182938387721

Epoch: 6| Step: 7
Training loss: 3.1456161996713403
Validation loss: 3.2642085748274026

Epoch: 6| Step: 8
Training loss: 3.3505742676858854
Validation loss: 3.2691606772823127

Epoch: 6| Step: 9
Training loss: 4.086919079484675
Validation loss: 3.271586557481296

Epoch: 6| Step: 10
Training loss: 3.283270949208354
Validation loss: 3.273573575167696

Epoch: 6| Step: 11
Training loss: 3.2819094040737706
Validation loss: 3.2705891830735507

Epoch: 6| Step: 12
Training loss: 4.447608073456253
Validation loss: 3.2717544270335397

Epoch: 6| Step: 13
Training loss: 3.8592157369640727
Validation loss: 3.268290975715305

Epoch: 43| Step: 0
Training loss: 3.9817620778990697
Validation loss: 3.260261682666978

Epoch: 6| Step: 1
Training loss: 3.9044680994376644
Validation loss: 3.2567500276453747

Epoch: 6| Step: 2
Training loss: 3.9008732527203525
Validation loss: 3.254766816285789

Epoch: 6| Step: 3
Training loss: 3.68012871496414
Validation loss: 3.257188098721104

Epoch: 6| Step: 4
Training loss: 2.640325224524389
Validation loss: 3.2567537997981977

Epoch: 6| Step: 5
Training loss: 3.3206473866043216
Validation loss: 3.2550591232394095

Epoch: 6| Step: 6
Training loss: 3.432980288405906
Validation loss: 3.2550524744273512

Epoch: 6| Step: 7
Training loss: 3.681082880083515
Validation loss: 3.256610801292263

Epoch: 6| Step: 8
Training loss: 3.3966841460711925
Validation loss: 3.2545201378965305

Epoch: 6| Step: 9
Training loss: 3.8783288009173362
Validation loss: 3.25570243750866

Epoch: 6| Step: 10
Training loss: 3.8732546905920553
Validation loss: 3.2560205975835657

Epoch: 6| Step: 11
Training loss: 2.9651817963368026
Validation loss: 3.2572266177832643

Epoch: 6| Step: 12
Training loss: 2.869291526196787
Validation loss: 3.25774219337038

Epoch: 6| Step: 13
Training loss: 2.919637547559397
Validation loss: 3.2539495145611554

Epoch: 44| Step: 0
Training loss: 3.6069440044967025
Validation loss: 3.2557027524809965

Epoch: 6| Step: 1
Training loss: 3.5121725126575134
Validation loss: 3.2551545788992446

Epoch: 6| Step: 2
Training loss: 3.273990994002365
Validation loss: 3.254185377216365

Epoch: 6| Step: 3
Training loss: 3.998582827337105
Validation loss: 3.252664649008463

Epoch: 6| Step: 4
Training loss: 3.1466566780977065
Validation loss: 3.253496664921732

Epoch: 6| Step: 5
Training loss: 3.295163546542404
Validation loss: 3.2531280656576542

Epoch: 6| Step: 6
Training loss: 3.9623966576611234
Validation loss: 3.2529573229699613

Epoch: 6| Step: 7
Training loss: 3.085655643773803
Validation loss: 3.2519361701544773

Epoch: 6| Step: 8
Training loss: 4.075202450082115
Validation loss: 3.255795447515639

Epoch: 6| Step: 9
Training loss: 3.7260012413919688
Validation loss: 3.251085010332457

Epoch: 6| Step: 10
Training loss: 2.75278661165981
Validation loss: 3.2547126880304176

Epoch: 6| Step: 11
Training loss: 3.3493087055288946
Validation loss: 3.2522783568047138

Epoch: 6| Step: 12
Training loss: 3.2229206508487733
Validation loss: 3.258951666243049

Epoch: 6| Step: 13
Training loss: 3.912405306611666
Validation loss: 3.257474866697121

Epoch: 45| Step: 0
Training loss: 3.9267266041488638
Validation loss: 3.252737086201269

Epoch: 6| Step: 1
Training loss: 3.175251333546522
Validation loss: 3.2510974646554023

Epoch: 6| Step: 2
Training loss: 3.5607758750240546
Validation loss: 3.2472098926438178

Epoch: 6| Step: 3
Training loss: 2.8772623863182307
Validation loss: 3.2468138838585707

Epoch: 6| Step: 4
Training loss: 3.242084547499458
Validation loss: 3.2482279797079685

Epoch: 6| Step: 5
Training loss: 3.96758199009731
Validation loss: 3.2494193608317086

Epoch: 6| Step: 6
Training loss: 4.2703502598924
Validation loss: 3.2457335023074783

Epoch: 6| Step: 7
Training loss: 3.4224616118368765
Validation loss: 3.2450842585778834

Epoch: 6| Step: 8
Training loss: 2.688852723809341
Validation loss: 3.2461233201242385

Epoch: 6| Step: 9
Training loss: 3.035082095699673
Validation loss: 3.2453671652824285

Epoch: 6| Step: 10
Training loss: 3.687990317640193
Validation loss: 3.243345033577121

Epoch: 6| Step: 11
Training loss: 3.1521815904698247
Validation loss: 3.245282351631729

Epoch: 6| Step: 12
Training loss: 3.84895245556346
Validation loss: 3.241902122189174

Epoch: 6| Step: 13
Training loss: 3.822234935763997
Validation loss: 3.241622380172069

Epoch: 46| Step: 0
Training loss: 3.4939768599828622
Validation loss: 3.2464846553632567

Epoch: 6| Step: 1
Training loss: 4.008888144900678
Validation loss: 3.244551083011011

Epoch: 6| Step: 2
Training loss: 3.203605206477497
Validation loss: 3.2453390259693777

Epoch: 6| Step: 3
Training loss: 3.653229990446556
Validation loss: 3.2459102879028396

Epoch: 6| Step: 4
Training loss: 3.4946629841171513
Validation loss: 3.251366742039851

Epoch: 6| Step: 5
Training loss: 2.5096535268010522
Validation loss: 3.2460225616760363

Epoch: 6| Step: 6
Training loss: 3.736521084275107
Validation loss: 3.2435932052058263

Epoch: 6| Step: 7
Training loss: 2.940938681919524
Validation loss: 3.2400244686914896

Epoch: 6| Step: 8
Training loss: 2.9924215917425556
Validation loss: 3.240050195003592

Epoch: 6| Step: 9
Training loss: 3.243210523135291
Validation loss: 3.2444166225708493

Epoch: 6| Step: 10
Training loss: 2.798043289405946
Validation loss: 3.2458497068191816

Epoch: 6| Step: 11
Training loss: 4.108618605009555
Validation loss: 3.2461473309427737

Epoch: 6| Step: 12
Training loss: 3.969290268536792
Validation loss: 3.247995073691992

Epoch: 6| Step: 13
Training loss: 4.707789949552385
Validation loss: 3.2422282072443087

Epoch: 47| Step: 0
Training loss: 2.9609107668029657
Validation loss: 3.2397434662069964

Epoch: 6| Step: 1
Training loss: 3.2783059127532277
Validation loss: 3.2398753416255053

Epoch: 6| Step: 2
Training loss: 4.201106043911234
Validation loss: 3.2386888355167023

Epoch: 6| Step: 3
Training loss: 2.400351987299644
Validation loss: 3.237239942211161

Epoch: 6| Step: 4
Training loss: 3.7369312172537175
Validation loss: 3.235338632352943

Epoch: 6| Step: 5
Training loss: 3.2114149049653324
Validation loss: 3.2355815707052824

Epoch: 6| Step: 6
Training loss: 4.373751216865363
Validation loss: 3.2378148105017432

Epoch: 6| Step: 7
Training loss: 2.056493161558082
Validation loss: 3.239403720119882

Epoch: 6| Step: 8
Training loss: 4.351180931360648
Validation loss: 3.248704047664488

Epoch: 6| Step: 9
Training loss: 3.331645411057355
Validation loss: 3.2523829887416826

Epoch: 6| Step: 10
Training loss: 3.404448986758706
Validation loss: 3.233401946707886

Epoch: 6| Step: 11
Training loss: 4.078495403437324
Validation loss: 3.2345203559009006

Epoch: 6| Step: 12
Training loss: 3.6444408409622904
Validation loss: 3.2344823843926185

Epoch: 6| Step: 13
Training loss: 2.2838106807337053
Validation loss: 3.2392162717396524

Epoch: 48| Step: 0
Training loss: 3.890812268020711
Validation loss: 3.2388245302889653

Epoch: 6| Step: 1
Training loss: 3.8659583402106947
Validation loss: 3.2370070898437793

Epoch: 6| Step: 2
Training loss: 3.9429629742100305
Validation loss: 3.239970377413553

Epoch: 6| Step: 3
Training loss: 3.4185825341753486
Validation loss: 3.2427644542679284

Epoch: 6| Step: 4
Training loss: 3.5288172080828333
Validation loss: 3.2353337417359906

Epoch: 6| Step: 5
Training loss: 3.0706606757298394
Validation loss: 3.2341844382595246

Epoch: 6| Step: 6
Training loss: 3.2585837642760866
Validation loss: 3.2325660022347407

Epoch: 6| Step: 7
Training loss: 3.183705034241733
Validation loss: 3.234167016913675

Epoch: 6| Step: 8
Training loss: 3.209467270517408
Validation loss: 3.231755824254703

Epoch: 6| Step: 9
Training loss: 2.6566186985613682
Validation loss: 3.2318975380422037

Epoch: 6| Step: 10
Training loss: 4.314787769248024
Validation loss: 3.231201514128658

Epoch: 6| Step: 11
Training loss: 2.673077764336813
Validation loss: 3.2337389603911424

Epoch: 6| Step: 12
Training loss: 4.159992569403248
Validation loss: 3.2313750644935664

Epoch: 6| Step: 13
Training loss: 2.7870490663094465
Validation loss: 3.2303511930279853

Epoch: 49| Step: 0
Training loss: 4.1774570110855445
Validation loss: 3.229503656614022

Epoch: 6| Step: 1
Training loss: 3.361858922264289
Validation loss: 3.2263614475004383

Epoch: 6| Step: 2
Training loss: 3.826012974662736
Validation loss: 3.2250454827500747

Epoch: 6| Step: 3
Training loss: 3.0138854706994365
Validation loss: 3.2242191283498527

Epoch: 6| Step: 4
Training loss: 2.36998158347141
Validation loss: 3.225220044784991

Epoch: 6| Step: 5
Training loss: 3.05336036048266
Validation loss: 3.2239784190928082

Epoch: 6| Step: 6
Training loss: 4.3504385190021
Validation loss: 3.2230909819114406

Epoch: 6| Step: 7
Training loss: 3.7177509921423186
Validation loss: 3.2218801250571967

Epoch: 6| Step: 8
Training loss: 3.1032954450589667
Validation loss: 3.2220582695490814

Epoch: 6| Step: 9
Training loss: 3.596290552827517
Validation loss: 3.221637318489793

Epoch: 6| Step: 10
Training loss: 3.4660925781071925
Validation loss: 3.2210455885355653

Epoch: 6| Step: 11
Training loss: 3.0971951808993934
Validation loss: 3.21790704422564

Epoch: 6| Step: 12
Training loss: 3.6478822600119862
Validation loss: 3.2203444615485126

Epoch: 6| Step: 13
Training loss: 3.3100075611592854
Validation loss: 3.2187812039847685

Epoch: 50| Step: 0
Training loss: 3.411698210147554
Validation loss: 3.2179354799820645

Epoch: 6| Step: 1
Training loss: 4.08389703920844
Validation loss: 3.21963600606794

Epoch: 6| Step: 2
Training loss: 2.8701452647805796
Validation loss: 3.2225169301176795

Epoch: 6| Step: 3
Training loss: 3.1065681095070725
Validation loss: 3.2216495603931192

Epoch: 6| Step: 4
Training loss: 3.3324007319140843
Validation loss: 3.2188347879869488

Epoch: 6| Step: 5
Training loss: 3.867554433349565
Validation loss: 3.2174791869296135

Epoch: 6| Step: 6
Training loss: 3.079816479355351
Validation loss: 3.2195760031658915

Epoch: 6| Step: 7
Training loss: 3.6072738278364924
Validation loss: 3.218270930125163

Epoch: 6| Step: 8
Training loss: 3.655147549303275
Validation loss: 3.218851951436471

Epoch: 6| Step: 9
Training loss: 3.469876355653462
Validation loss: 3.216378896232396

Epoch: 6| Step: 10
Training loss: 3.8986610853030865
Validation loss: 3.215307526000589

Epoch: 6| Step: 11
Training loss: 3.3838464156845838
Validation loss: 3.216836390947526

Epoch: 6| Step: 12
Training loss: 2.949527224140721
Validation loss: 3.217016195768028

Epoch: 6| Step: 13
Training loss: 3.7240543522049014
Validation loss: 3.2146905392474645

Epoch: 51| Step: 0
Training loss: 3.4054332068825084
Validation loss: 3.215462435869642

Epoch: 6| Step: 1
Training loss: 2.9990336133212256
Validation loss: 3.2176123541149573

Epoch: 6| Step: 2
Training loss: 2.868297891998181
Validation loss: 3.2146215886770344

Epoch: 6| Step: 3
Training loss: 3.9659128936804993
Validation loss: 3.2182959763928496

Epoch: 6| Step: 4
Training loss: 4.014169867220418
Validation loss: 3.215945797546928

Epoch: 6| Step: 5
Training loss: 4.093675219602658
Validation loss: 3.2154278893160178

Epoch: 6| Step: 6
Training loss: 2.9195508229960034
Validation loss: 3.2160197026967454

Epoch: 6| Step: 7
Training loss: 3.2059953436005606
Validation loss: 3.2216061326197365

Epoch: 6| Step: 8
Training loss: 3.3363279877941663
Validation loss: 3.2172152879336227

Epoch: 6| Step: 9
Training loss: 3.242924691463617
Validation loss: 3.2187449232906262

Epoch: 6| Step: 10
Training loss: 4.083992781555193
Validation loss: 3.215897032179755

Epoch: 6| Step: 11
Training loss: 2.688671655085437
Validation loss: 3.215118746915825

Epoch: 6| Step: 12
Training loss: 3.6782816086246295
Validation loss: 3.212956179324622

Epoch: 6| Step: 13
Training loss: 3.6379232573297506
Validation loss: 3.2114449205317666

Epoch: 52| Step: 0
Training loss: 3.7641399826872988
Validation loss: 3.212686283083969

Epoch: 6| Step: 1
Training loss: 3.477993308536351
Validation loss: 3.2126885477338347

Epoch: 6| Step: 2
Training loss: 3.170391619105383
Validation loss: 3.2112130541702224

Epoch: 6| Step: 3
Training loss: 3.692763499864319
Validation loss: 3.2117769905260523

Epoch: 6| Step: 4
Training loss: 3.4429598363904215
Validation loss: 3.2101737056267745

Epoch: 6| Step: 5
Training loss: 4.419320706603278
Validation loss: 3.209902597063281

Epoch: 6| Step: 6
Training loss: 3.621313259216125
Validation loss: 3.206160607241472

Epoch: 6| Step: 7
Training loss: 3.556909022083899
Validation loss: 3.2076071269030626

Epoch: 6| Step: 8
Training loss: 2.538483726853541
Validation loss: 3.2079305669003157

Epoch: 6| Step: 9
Training loss: 2.8926760433502507
Validation loss: 3.2056598100864764

Epoch: 6| Step: 10
Training loss: 3.220939114023287
Validation loss: 3.209614639432964

Epoch: 6| Step: 11
Training loss: 3.576505202754783
Validation loss: 3.2057473098104055

Epoch: 6| Step: 12
Training loss: 3.9735171305199684
Validation loss: 3.2098878328863796

Epoch: 6| Step: 13
Training loss: 1.7242472042610297
Validation loss: 3.2105176724203037

Epoch: 53| Step: 0
Training loss: 4.0910535478614465
Validation loss: 3.2135843317457105

Epoch: 6| Step: 1
Training loss: 2.704446811203072
Validation loss: 3.208567785084911

Epoch: 6| Step: 2
Training loss: 4.5299651330275506
Validation loss: 3.210604519134781

Epoch: 6| Step: 3
Training loss: 3.179173683435405
Validation loss: 3.2105267171662097

Epoch: 6| Step: 4
Training loss: 2.8108975401789866
Validation loss: 3.2080315476070473

Epoch: 6| Step: 5
Training loss: 3.821546733541997
Validation loss: 3.2087890456902324

Epoch: 6| Step: 6
Training loss: 2.776037410615923
Validation loss: 3.208325030589511

Epoch: 6| Step: 7
Training loss: 3.971534413067227
Validation loss: 3.2063187942715703

Epoch: 6| Step: 8
Training loss: 3.2563136469794927
Validation loss: 3.2063991361385957

Epoch: 6| Step: 9
Training loss: 3.7400505319537305
Validation loss: 3.2069567827754963

Epoch: 6| Step: 10
Training loss: 2.47357093320994
Validation loss: 3.2089830743991516

Epoch: 6| Step: 11
Training loss: 3.842723926579077
Validation loss: 3.2046977522182423

Epoch: 6| Step: 12
Training loss: 3.595272106754431
Validation loss: 3.207436589814646

Epoch: 6| Step: 13
Training loss: 2.412810856058099
Validation loss: 3.205761266168988

Epoch: 54| Step: 0
Training loss: 3.0145487866182985
Validation loss: 3.2036214928418363

Epoch: 6| Step: 1
Training loss: 3.1934480707292447
Validation loss: 3.206815774342775

Epoch: 6| Step: 2
Training loss: 3.8906818676817836
Validation loss: 3.205333747940149

Epoch: 6| Step: 3
Training loss: 2.8130718073787664
Validation loss: 3.2051963097725475

Epoch: 6| Step: 4
Training loss: 4.315766355283664
Validation loss: 3.2090988306036694

Epoch: 6| Step: 5
Training loss: 3.32620886145393
Validation loss: 3.205554449617086

Epoch: 6| Step: 6
Training loss: 3.2136869145258578
Validation loss: 3.2074174078311954

Epoch: 6| Step: 7
Training loss: 2.9806920839080755
Validation loss: 3.206096362071172

Epoch: 6| Step: 8
Training loss: 3.1805154908019935
Validation loss: 3.2096369656751658

Epoch: 6| Step: 9
Training loss: 3.5065560926353854
Validation loss: 3.210152726369658

Epoch: 6| Step: 10
Training loss: 3.108160040339742
Validation loss: 3.210845611417549

Epoch: 6| Step: 11
Training loss: 4.32869961776737
Validation loss: 3.20855070884494

Epoch: 6| Step: 12
Training loss: 3.374440747302531
Validation loss: 3.207962863874622

Epoch: 6| Step: 13
Training loss: 3.9062667235970134
Validation loss: 3.204424789110611

Epoch: 55| Step: 0
Training loss: 2.7490664544813725
Validation loss: 3.206934737651228

Epoch: 6| Step: 1
Training loss: 3.393429207437319
Validation loss: 3.2056044543656115

Epoch: 6| Step: 2
Training loss: 3.499997683933037
Validation loss: 3.205106616984788

Epoch: 6| Step: 3
Training loss: 2.903268576891471
Validation loss: 3.2064925033254945

Epoch: 6| Step: 4
Training loss: 3.340751801128112
Validation loss: 3.2035760713479573

Epoch: 6| Step: 5
Training loss: 3.281077643817766
Validation loss: 3.203776098747133

Epoch: 6| Step: 6
Training loss: 4.301479244846783
Validation loss: 3.2027110979134266

Epoch: 6| Step: 7
Training loss: 3.0137225064606175
Validation loss: 3.1987741714278086

Epoch: 6| Step: 8
Training loss: 3.397147519182799
Validation loss: 3.19985431248495

Epoch: 6| Step: 9
Training loss: 3.853721029276039
Validation loss: 3.200094175042521

Epoch: 6| Step: 10
Training loss: 3.3996038430489004
Validation loss: 3.1998532196831904

Epoch: 6| Step: 11
Training loss: 3.0636096423218384
Validation loss: 3.200176642269872

Epoch: 6| Step: 12
Training loss: 3.544326471606291
Validation loss: 3.1976593775593725

Epoch: 6| Step: 13
Training loss: 4.712534265368317
Validation loss: 3.1986818116061486

Epoch: 56| Step: 0
Training loss: 3.31576219107702
Validation loss: 3.1964256052151856

Epoch: 6| Step: 1
Training loss: 3.663859477650945
Validation loss: 3.1971003746620252

Epoch: 6| Step: 2
Training loss: 4.084114207644539
Validation loss: 3.1993316959400615

Epoch: 6| Step: 3
Training loss: 3.3311740716293414
Validation loss: 3.1960753812789537

Epoch: 6| Step: 4
Training loss: 3.1301373787368543
Validation loss: 3.1948417884300024

Epoch: 6| Step: 5
Training loss: 2.2774823573546126
Validation loss: 3.1962764555729706

Epoch: 6| Step: 6
Training loss: 3.9709998534526045
Validation loss: 3.1954185014348804

Epoch: 6| Step: 7
Training loss: 3.7722914319687813
Validation loss: 3.1934146459489625

Epoch: 6| Step: 8
Training loss: 3.6260290329576184
Validation loss: 3.193921779362517

Epoch: 6| Step: 9
Training loss: 4.168093220962412
Validation loss: 3.1939199171854136

Epoch: 6| Step: 10
Training loss: 3.335998963408458
Validation loss: 3.192947339939188

Epoch: 6| Step: 11
Training loss: 3.363419054777015
Validation loss: 3.194340789763448

Epoch: 6| Step: 12
Training loss: 1.983987304781474
Validation loss: 3.1933014537953115

Epoch: 6| Step: 13
Training loss: 3.5024261240278087
Validation loss: 3.1997260707721797

Epoch: 57| Step: 0
Training loss: 3.7408279147200596
Validation loss: 3.2057336572789064

Epoch: 6| Step: 1
Training loss: 3.101241779800831
Validation loss: 3.2058800622935544

Epoch: 6| Step: 2
Training loss: 2.567371854472145
Validation loss: 3.1982021388082904

Epoch: 6| Step: 3
Training loss: 3.699540475713884
Validation loss: 3.197753615633586

Epoch: 6| Step: 4
Training loss: 4.006605892471568
Validation loss: 3.2000514673636915

Epoch: 6| Step: 5
Training loss: 2.7810864346873774
Validation loss: 3.1952702836176994

Epoch: 6| Step: 6
Training loss: 2.3998410967038444
Validation loss: 3.193480305449916

Epoch: 6| Step: 7
Training loss: 4.09162649742241
Validation loss: 3.1926162873207655

Epoch: 6| Step: 8
Training loss: 3.3001513359741597
Validation loss: 3.191073523938651

Epoch: 6| Step: 9
Training loss: 3.728579569088924
Validation loss: 3.1931178969754836

Epoch: 6| Step: 10
Training loss: 4.066799764070629
Validation loss: 3.1919360079925494

Epoch: 6| Step: 11
Training loss: 3.3737707371903003
Validation loss: 3.189089713043038

Epoch: 6| Step: 12
Training loss: 3.0350918364102815
Validation loss: 3.1929171906288163

Epoch: 6| Step: 13
Training loss: 3.936116777905178
Validation loss: 3.19089686409692

Epoch: 58| Step: 0
Training loss: 4.38157377910475
Validation loss: 3.1921807476701076

Epoch: 6| Step: 1
Training loss: 3.690827500927341
Validation loss: 3.1890147062780905

Epoch: 6| Step: 2
Training loss: 3.3496048196033166
Validation loss: 3.190898266070132

Epoch: 6| Step: 3
Training loss: 3.4659204713091647
Validation loss: 3.1907332781154074

Epoch: 6| Step: 4
Training loss: 3.59104963934043
Validation loss: 3.1894362132788174

Epoch: 6| Step: 5
Training loss: 3.2940062566163912
Validation loss: 3.188782852231368

Epoch: 6| Step: 6
Training loss: 4.1889841666433485
Validation loss: 3.1882756958446707

Epoch: 6| Step: 7
Training loss: 3.2074525953611936
Validation loss: 3.191867134530487

Epoch: 6| Step: 8
Training loss: 3.278194930764392
Validation loss: 3.1908965668303146

Epoch: 6| Step: 9
Training loss: 3.0777417249285572
Validation loss: 3.1955698820621405

Epoch: 6| Step: 10
Training loss: 2.959929523660011
Validation loss: 3.1961080210385395

Epoch: 6| Step: 11
Training loss: 2.9226667178123824
Validation loss: 3.1924517800340864

Epoch: 6| Step: 12
Training loss: 2.81418542164555
Validation loss: 3.192524109101475

Epoch: 6| Step: 13
Training loss: 3.6441887043436996
Validation loss: 3.1955408533763316

Epoch: 59| Step: 0
Training loss: 3.316562824125246
Validation loss: 3.1904919347930605

Epoch: 6| Step: 1
Training loss: 3.450432327382992
Validation loss: 3.19048117798322

Epoch: 6| Step: 2
Training loss: 3.140953540224004
Validation loss: 3.1912224861617897

Epoch: 6| Step: 3
Training loss: 4.124137557065672
Validation loss: 3.190720870993843

Epoch: 6| Step: 4
Training loss: 3.5191128531829583
Validation loss: 3.189846041668621

Epoch: 6| Step: 5
Training loss: 3.5988628339817206
Validation loss: 3.1866974404379524

Epoch: 6| Step: 6
Training loss: 2.8454983545277472
Validation loss: 3.1895093493979876

Epoch: 6| Step: 7
Training loss: 3.2550640267492903
Validation loss: 3.191426431919388

Epoch: 6| Step: 8
Training loss: 3.7792257139618313
Validation loss: 3.1889662164259804

Epoch: 6| Step: 9
Training loss: 3.8077883763854232
Validation loss: 3.192004720945956

Epoch: 6| Step: 10
Training loss: 2.906648670047494
Validation loss: 3.1882308903758583

Epoch: 6| Step: 11
Training loss: 3.6936960697271206
Validation loss: 3.1892175327891925

Epoch: 6| Step: 12
Training loss: 3.524877148374509
Validation loss: 3.1838173871332343

Epoch: 6| Step: 13
Training loss: 2.349496738844786
Validation loss: 3.1873139084395703

Epoch: 60| Step: 0
Training loss: 3.4926741088197626
Validation loss: 3.18632355803471

Epoch: 6| Step: 1
Training loss: 4.252055848983065
Validation loss: 3.187223590960159

Epoch: 6| Step: 2
Training loss: 3.6196884177140176
Validation loss: 3.1849642420514708

Epoch: 6| Step: 3
Training loss: 3.912201033312172
Validation loss: 3.185732001104363

Epoch: 6| Step: 4
Training loss: 2.7871004784808955
Validation loss: 3.1855069419364948

Epoch: 6| Step: 5
Training loss: 3.2055028509622097
Validation loss: 3.1868063589994984

Epoch: 6| Step: 6
Training loss: 3.57881817495929
Validation loss: 3.1857692202585035

Epoch: 6| Step: 7
Training loss: 2.9239031438689214
Validation loss: 3.186525859122038

Epoch: 6| Step: 8
Training loss: 3.6856498602794767
Validation loss: 3.185077838350623

Epoch: 6| Step: 9
Training loss: 2.7268193951886603
Validation loss: 3.1858083388904017

Epoch: 6| Step: 10
Training loss: 3.322260314470697
Validation loss: 3.1908885840064647

Epoch: 6| Step: 11
Training loss: 3.777250965324055
Validation loss: 3.196503754410796

Epoch: 6| Step: 12
Training loss: 3.235533575896247
Validation loss: 3.1882477425551037

Epoch: 6| Step: 13
Training loss: 3.071811455722313
Validation loss: 3.1804764457116605

Epoch: 61| Step: 0
Training loss: 3.1275898691952206
Validation loss: 3.1836051251708803

Epoch: 6| Step: 1
Training loss: 2.7587607161154333
Validation loss: 3.18111056764394

Epoch: 6| Step: 2
Training loss: 3.627685867269507
Validation loss: 3.1799871243013498

Epoch: 6| Step: 3
Training loss: 3.3789367321601933
Validation loss: 3.185942547425462

Epoch: 6| Step: 4
Training loss: 3.6882835460898913
Validation loss: 3.1837299433800896

Epoch: 6| Step: 5
Training loss: 4.124302660635303
Validation loss: 3.186480314619987

Epoch: 6| Step: 6
Training loss: 3.4113213819819137
Validation loss: 3.1828689423515732

Epoch: 6| Step: 7
Training loss: 2.638737291588262
Validation loss: 3.1823309999045133

Epoch: 6| Step: 8
Training loss: 3.1895434243570624
Validation loss: 3.1815354328272103

Epoch: 6| Step: 9
Training loss: 3.6735642463628917
Validation loss: 3.1758244261321535

Epoch: 6| Step: 10
Training loss: 3.273136826137457
Validation loss: 3.1767053547056148

Epoch: 6| Step: 11
Training loss: 3.4512551885370355
Validation loss: 3.1758200977283724

Epoch: 6| Step: 12
Training loss: 3.7303866871700353
Validation loss: 3.1761133357644864

Epoch: 6| Step: 13
Training loss: 3.8981332908690214
Validation loss: 3.177691400692946

Epoch: 62| Step: 0
Training loss: 3.380267659486164
Validation loss: 3.1746834671848303

Epoch: 6| Step: 1
Training loss: 3.44741846885844
Validation loss: 3.177693346602268

Epoch: 6| Step: 2
Training loss: 3.8909340854415637
Validation loss: 3.1763595028169997

Epoch: 6| Step: 3
Training loss: 3.1378386174188186
Validation loss: 3.1762915038907837

Epoch: 6| Step: 4
Training loss: 3.6989770506193063
Validation loss: 3.173851691651546

Epoch: 6| Step: 5
Training loss: 3.2145088178923413
Validation loss: 3.1757164289999293

Epoch: 6| Step: 6
Training loss: 3.885532708092827
Validation loss: 3.176293952684504

Epoch: 6| Step: 7
Training loss: 3.9394505831285183
Validation loss: 3.1835446928014113

Epoch: 6| Step: 8
Training loss: 3.232316251106622
Validation loss: 3.1801365139274598

Epoch: 6| Step: 9
Training loss: 2.9989412346781212
Validation loss: 3.180779556511493

Epoch: 6| Step: 10
Training loss: 3.4065047702529143
Validation loss: 3.178275395917696

Epoch: 6| Step: 11
Training loss: 3.0757641718910875
Validation loss: 3.1743269371903153

Epoch: 6| Step: 12
Training loss: 2.919537756925114
Validation loss: 3.1713997427092173

Epoch: 6| Step: 13
Training loss: 3.658926611711437
Validation loss: 3.1734665121423737

Epoch: 63| Step: 0
Training loss: 3.722635114996077
Validation loss: 3.173857938691133

Epoch: 6| Step: 1
Training loss: 3.9482233470209644
Validation loss: 3.17254733707877

Epoch: 6| Step: 2
Training loss: 3.224204765272858
Validation loss: 3.1726229828510197

Epoch: 6| Step: 3
Training loss: 3.3862757761591347
Validation loss: 3.1712886119353185

Epoch: 6| Step: 4
Training loss: 3.9747451796516544
Validation loss: 3.172517352688044

Epoch: 6| Step: 5
Training loss: 3.725880302509125
Validation loss: 3.1735782427866743

Epoch: 6| Step: 6
Training loss: 2.519822877078495
Validation loss: 3.1728573590337352

Epoch: 6| Step: 7
Training loss: 2.7322108832829834
Validation loss: 3.173990422468436

Epoch: 6| Step: 8
Training loss: 3.661301864095182
Validation loss: 3.1702318690546027

Epoch: 6| Step: 9
Training loss: 4.139542808903907
Validation loss: 3.169960289887539

Epoch: 6| Step: 10
Training loss: 2.8902812031616594
Validation loss: 3.175858175693663

Epoch: 6| Step: 11
Training loss: 3.091650819009503
Validation loss: 3.1721691959186256

Epoch: 6| Step: 12
Training loss: 3.4526997990564987
Validation loss: 3.1733341349435884

Epoch: 6| Step: 13
Training loss: 2.666625191445474
Validation loss: 3.1735977011965795

Epoch: 64| Step: 0
Training loss: 2.878695890487084
Validation loss: 3.1726352312618618

Epoch: 6| Step: 1
Training loss: 3.726468322971413
Validation loss: 3.172586214709083

Epoch: 6| Step: 2
Training loss: 3.7896083792511885
Validation loss: 3.169827060212659

Epoch: 6| Step: 3
Training loss: 3.5414830029306064
Validation loss: 3.1696526876093167

Epoch: 6| Step: 4
Training loss: 3.8361875992488765
Validation loss: 3.1719587359349117

Epoch: 6| Step: 5
Training loss: 3.743157693054847
Validation loss: 3.169849569640295

Epoch: 6| Step: 6
Training loss: 2.909906855400099
Validation loss: 3.168471574623129

Epoch: 6| Step: 7
Training loss: 3.6882719104844948
Validation loss: 3.167866635468839

Epoch: 6| Step: 8
Training loss: 3.2834636668818797
Validation loss: 3.1656456652266227

Epoch: 6| Step: 9
Training loss: 3.1633565232847536
Validation loss: 3.176480360555857

Epoch: 6| Step: 10
Training loss: 3.750279988326835
Validation loss: 3.172341607074487

Epoch: 6| Step: 11
Training loss: 3.304173062010866
Validation loss: 3.172695234701346

Epoch: 6| Step: 12
Training loss: 2.9927442545626537
Validation loss: 3.1747501310173596

Epoch: 6| Step: 13
Training loss: 2.8220102372825284
Validation loss: 3.170977353256375

Epoch: 65| Step: 0
Training loss: 3.627037528046601
Validation loss: 3.1661282185754

Epoch: 6| Step: 1
Training loss: 3.3012602509321747
Validation loss: 3.168962540674419

Epoch: 6| Step: 2
Training loss: 2.867768854975311
Validation loss: 3.1661882473584897

Epoch: 6| Step: 3
Training loss: 3.5355560245296482
Validation loss: 3.1656908972507436

Epoch: 6| Step: 4
Training loss: 3.794667799410871
Validation loss: 3.1665741000762364

Epoch: 6| Step: 5
Training loss: 3.0169954496607923
Validation loss: 3.1658189482998673

Epoch: 6| Step: 6
Training loss: 3.486561452713806
Validation loss: 3.1648140060780796

Epoch: 6| Step: 7
Training loss: 3.7771100797440886
Validation loss: 3.167514631361871

Epoch: 6| Step: 8
Training loss: 2.8704044267099325
Validation loss: 3.1681901433017017

Epoch: 6| Step: 9
Training loss: 2.960620873262937
Validation loss: 3.1682143555359774

Epoch: 6| Step: 10
Training loss: 3.907652092119624
Validation loss: 3.1647391214250447

Epoch: 6| Step: 11
Training loss: 2.938179911392668
Validation loss: 3.162522433368897

Epoch: 6| Step: 12
Training loss: 3.999532195392659
Validation loss: 3.1633413408800624

Epoch: 6| Step: 13
Training loss: 3.5962978453464958
Validation loss: 3.1638621884786633

Epoch: 66| Step: 0
Training loss: 4.298551918872583
Validation loss: 3.1655026149189895

Epoch: 6| Step: 1
Training loss: 4.57800792765733
Validation loss: 3.1641328561511792

Epoch: 6| Step: 2
Training loss: 3.105995066445406
Validation loss: 3.16305057250422

Epoch: 6| Step: 3
Training loss: 2.455829951354426
Validation loss: 3.168305653463702

Epoch: 6| Step: 4
Training loss: 3.466341299291492
Validation loss: 3.1671901447229187

Epoch: 6| Step: 5
Training loss: 3.522960419085193
Validation loss: 3.171235246374008

Epoch: 6| Step: 6
Training loss: 2.7349115335777467
Validation loss: 3.1708614634059393

Epoch: 6| Step: 7
Training loss: 3.319380039102805
Validation loss: 3.1685268193330276

Epoch: 6| Step: 8
Training loss: 3.048999847522205
Validation loss: 3.1656085220716434

Epoch: 6| Step: 9
Training loss: 4.111329516775299
Validation loss: 3.163023143571116

Epoch: 6| Step: 10
Training loss: 3.0457611395494317
Validation loss: 3.1614329351632913

Epoch: 6| Step: 11
Training loss: 2.855216582679638
Validation loss: 3.1596163594970363

Epoch: 6| Step: 12
Training loss: 3.469207733470804
Validation loss: 3.159751454967516

Epoch: 6| Step: 13
Training loss: 2.8637175390234537
Validation loss: 3.1603613844840885

Epoch: 67| Step: 0
Training loss: 2.987122394527907
Validation loss: 3.1586270554991307

Epoch: 6| Step: 1
Training loss: 3.606258219109595
Validation loss: 3.159737441428832

Epoch: 6| Step: 2
Training loss: 2.260995910775807
Validation loss: 3.1589575361057363

Epoch: 6| Step: 3
Training loss: 3.930758563499097
Validation loss: 3.16094602023537

Epoch: 6| Step: 4
Training loss: 2.6665339039496736
Validation loss: 3.1591711652274697

Epoch: 6| Step: 5
Training loss: 3.685920635733
Validation loss: 3.159141683602702

Epoch: 6| Step: 6
Training loss: 3.0104106828218717
Validation loss: 3.1598350229509653

Epoch: 6| Step: 7
Training loss: 3.5994408703099183
Validation loss: 3.158604954701062

Epoch: 6| Step: 8
Training loss: 4.067425368362309
Validation loss: 3.158508059990344

Epoch: 6| Step: 9
Training loss: 3.6364963680665126
Validation loss: 3.1596604859372515

Epoch: 6| Step: 10
Training loss: 3.4463864683209686
Validation loss: 3.1576357487651205

Epoch: 6| Step: 11
Training loss: 3.967229356578744
Validation loss: 3.1572890576071537

Epoch: 6| Step: 12
Training loss: 2.728480323120771
Validation loss: 3.159556749486891

Epoch: 6| Step: 13
Training loss: 3.7883111267736846
Validation loss: 3.1713253530857424

Epoch: 68| Step: 0
Training loss: 3.6284245067584244
Validation loss: 3.1849935232876967

Epoch: 6| Step: 1
Training loss: 3.9376468933800806
Validation loss: 3.1825559034542206

Epoch: 6| Step: 2
Training loss: 4.0072661207730285
Validation loss: 3.1611997653345685

Epoch: 6| Step: 3
Training loss: 3.1761550964805565
Validation loss: 3.153010644541049

Epoch: 6| Step: 4
Training loss: 2.8857834969547502
Validation loss: 3.1553246160799886

Epoch: 6| Step: 5
Training loss: 2.6952304108876177
Validation loss: 3.1526956590147424

Epoch: 6| Step: 6
Training loss: 3.937413290370907
Validation loss: 3.150637093083249

Epoch: 6| Step: 7
Training loss: 3.4113726811418763
Validation loss: 3.153667782186974

Epoch: 6| Step: 8
Training loss: 2.8466262524465984
Validation loss: 3.152727115073407

Epoch: 6| Step: 9
Training loss: 3.1901404719979185
Validation loss: 3.154944631683773

Epoch: 6| Step: 10
Training loss: 3.250758449380055
Validation loss: 3.1551216469757777

Epoch: 6| Step: 11
Training loss: 2.7361757289100272
Validation loss: 3.156961635961352

Epoch: 6| Step: 12
Training loss: 3.9185656685193546
Validation loss: 3.1582671316946174

Epoch: 6| Step: 13
Training loss: 3.944045061538817
Validation loss: 3.1530666260260394

Epoch: 69| Step: 0
Training loss: 3.2896293097374056
Validation loss: 3.154903978112213

Epoch: 6| Step: 1
Training loss: 3.0313343154349695
Validation loss: 3.150791997873848

Epoch: 6| Step: 2
Training loss: 3.311051249834155
Validation loss: 3.1525593593535146

Epoch: 6| Step: 3
Training loss: 3.672261968472278
Validation loss: 3.151147586618959

Epoch: 6| Step: 4
Training loss: 2.811727120910886
Validation loss: 3.150612192455715

Epoch: 6| Step: 5
Training loss: 3.6024156995515506
Validation loss: 3.1474866189178394

Epoch: 6| Step: 6
Training loss: 3.354735821756589
Validation loss: 3.1494239152081858

Epoch: 6| Step: 7
Training loss: 3.527805234813888
Validation loss: 3.14645205968395

Epoch: 6| Step: 8
Training loss: 4.05565359847705
Validation loss: 3.148491795888305

Epoch: 6| Step: 9
Training loss: 3.6957308187677897
Validation loss: 3.1460424276445615

Epoch: 6| Step: 10
Training loss: 2.2401734986552153
Validation loss: 3.144677587482492

Epoch: 6| Step: 11
Training loss: 3.2323286429152818
Validation loss: 3.140064408029906

Epoch: 6| Step: 12
Training loss: 3.951840399295486
Validation loss: 3.1457953127170413

Epoch: 6| Step: 13
Training loss: 3.4999457763831243
Validation loss: 3.1471795000646705

Epoch: 70| Step: 0
Training loss: 2.862871544059077
Validation loss: 3.144899976438042

Epoch: 6| Step: 1
Training loss: 2.3758927725219876
Validation loss: 3.1442035516272333

Epoch: 6| Step: 2
Training loss: 3.674522711452798
Validation loss: 3.144420960029173

Epoch: 6| Step: 3
Training loss: 3.9971217290319316
Validation loss: 3.139227959495565

Epoch: 6| Step: 4
Training loss: 3.292504183941082
Validation loss: 3.1406786016205066

Epoch: 6| Step: 5
Training loss: 3.814146092993971
Validation loss: 3.136860443757433

Epoch: 6| Step: 6
Training loss: 2.4209470878658403
Validation loss: 3.1397438337580414

Epoch: 6| Step: 7
Training loss: 2.875819545533356
Validation loss: 3.138855399426435

Epoch: 6| Step: 8
Training loss: 3.9453614486830473
Validation loss: 3.140077655384036

Epoch: 6| Step: 9
Training loss: 3.3908239912715485
Validation loss: 3.141603037881613

Epoch: 6| Step: 10
Training loss: 3.955291154563796
Validation loss: 3.138639024289123

Epoch: 6| Step: 11
Training loss: 3.4732964765481027
Validation loss: 3.141671547704083

Epoch: 6| Step: 12
Training loss: 3.3655866105379353
Validation loss: 3.1435414156533423

Epoch: 6| Step: 13
Training loss: 3.7331632938716917
Validation loss: 3.149951283159073

Epoch: 71| Step: 0
Training loss: 3.6553250960649675
Validation loss: 3.1525751417725716

Epoch: 6| Step: 1
Training loss: 3.7311593100614324
Validation loss: 3.156979113057179

Epoch: 6| Step: 2
Training loss: 2.6948137347056664
Validation loss: 3.148173560212136

Epoch: 6| Step: 3
Training loss: 3.5330074291955538
Validation loss: 3.1474078374700283

Epoch: 6| Step: 4
Training loss: 3.330026289460937
Validation loss: 3.1491150380049495

Epoch: 6| Step: 5
Training loss: 3.378279611329444
Validation loss: 3.1435884189745886

Epoch: 6| Step: 6
Training loss: 2.8176063805901603
Validation loss: 3.145463295986064

Epoch: 6| Step: 7
Training loss: 3.0165727934448814
Validation loss: 3.140571598273832

Epoch: 6| Step: 8
Training loss: 3.556698274433248
Validation loss: 3.1440345762735866

Epoch: 6| Step: 9
Training loss: 3.94899500846016
Validation loss: 3.1441726022473424

Epoch: 6| Step: 10
Training loss: 2.790948993803137
Validation loss: 3.146299485062998

Epoch: 6| Step: 11
Training loss: 3.905074530169897
Validation loss: 3.1357012326494527

Epoch: 6| Step: 12
Training loss: 3.741848287160501
Validation loss: 3.138518631364517

Epoch: 6| Step: 13
Training loss: 2.787080974474256
Validation loss: 3.136121540982383

Epoch: 72| Step: 0
Training loss: 3.5215443602333494
Validation loss: 3.1351837773791376

Epoch: 6| Step: 1
Training loss: 2.8501335848905733
Validation loss: 3.137218878192063

Epoch: 6| Step: 2
Training loss: 3.481771959386894
Validation loss: 3.136135905282201

Epoch: 6| Step: 3
Training loss: 3.5993340936009814
Validation loss: 3.135418213095199

Epoch: 6| Step: 4
Training loss: 3.5402522834494086
Validation loss: 3.1362764531985037

Epoch: 6| Step: 5
Training loss: 2.177530623000564
Validation loss: 3.135081417623213

Epoch: 6| Step: 6
Training loss: 2.5169480913801436
Validation loss: 3.1364151835047704

Epoch: 6| Step: 7
Training loss: 3.678280571537693
Validation loss: 3.1334274613527042

Epoch: 6| Step: 8
Training loss: 3.8600473165823863
Validation loss: 3.1358086114774273

Epoch: 6| Step: 9
Training loss: 3.409313259387404
Validation loss: 3.134755008181051

Epoch: 6| Step: 10
Training loss: 4.219623842514218
Validation loss: 3.1311667305677506

Epoch: 6| Step: 11
Training loss: 3.2226920570927393
Validation loss: 3.1345716607914964

Epoch: 6| Step: 12
Training loss: 3.6343292679537544
Validation loss: 3.1316315737403078

Epoch: 6| Step: 13
Training loss: 3.163048701878316
Validation loss: 3.1341120715907693

Epoch: 73| Step: 0
Training loss: 3.260180447504857
Validation loss: 3.1328083200227104

Epoch: 6| Step: 1
Training loss: 3.873963248090848
Validation loss: 3.132234775563974

Epoch: 6| Step: 2
Training loss: 3.3696621256264474
Validation loss: 3.132167508873215

Epoch: 6| Step: 3
Training loss: 2.304508111728819
Validation loss: 3.1381772752865116

Epoch: 6| Step: 4
Training loss: 3.7550687230471733
Validation loss: 3.1371757444029265

Epoch: 6| Step: 5
Training loss: 3.3086492360404236
Validation loss: 3.141090621801857

Epoch: 6| Step: 6
Training loss: 2.7666202629364895
Validation loss: 3.1450407750273786

Epoch: 6| Step: 7
Training loss: 3.5994836595908617
Validation loss: 3.1591465720695027

Epoch: 6| Step: 8
Training loss: 2.752365135610041
Validation loss: 3.185214753814054

Epoch: 6| Step: 9
Training loss: 3.847481133982983
Validation loss: 3.179412258248894

Epoch: 6| Step: 10
Training loss: 3.5713981463634985
Validation loss: 3.154506632766386

Epoch: 6| Step: 11
Training loss: 3.7655849850376524
Validation loss: 3.135132058227884

Epoch: 6| Step: 12
Training loss: 3.2771569290837745
Validation loss: 3.1334665175465473

Epoch: 6| Step: 13
Training loss: 3.789145557240455
Validation loss: 3.1319610164406324

Epoch: 74| Step: 0
Training loss: 3.410042427671613
Validation loss: 3.1307140752115226

Epoch: 6| Step: 1
Training loss: 3.6094711753285056
Validation loss: 3.130175395709905

Epoch: 6| Step: 2
Training loss: 3.4226276841459438
Validation loss: 3.127386895319058

Epoch: 6| Step: 3
Training loss: 3.4762328945316545
Validation loss: 3.1294422537289623

Epoch: 6| Step: 4
Training loss: 2.619926636229273
Validation loss: 3.1309946058982123

Epoch: 6| Step: 5
Training loss: 3.4704720286561264
Validation loss: 3.128336360484413

Epoch: 6| Step: 6
Training loss: 2.523579501948577
Validation loss: 3.1296149855777804

Epoch: 6| Step: 7
Training loss: 3.321730654174025
Validation loss: 3.1311341261625256

Epoch: 6| Step: 8
Training loss: 3.5007031960480868
Validation loss: 3.1251299906940893

Epoch: 6| Step: 9
Training loss: 2.6503587803793445
Validation loss: 3.125019483608092

Epoch: 6| Step: 10
Training loss: 4.142458873077284
Validation loss: 3.128509572947744

Epoch: 6| Step: 11
Training loss: 3.2745269200745577
Validation loss: 3.1269272913380024

Epoch: 6| Step: 12
Training loss: 3.7996584889392837
Validation loss: 3.1257105554797167

Epoch: 6| Step: 13
Training loss: 4.169245316163065
Validation loss: 3.123324856264365

Epoch: 75| Step: 0
Training loss: 3.736733174839527
Validation loss: 3.126098944928549

Epoch: 6| Step: 1
Training loss: 3.774742516837461
Validation loss: 3.1267141337545485

Epoch: 6| Step: 2
Training loss: 3.7665540886543485
Validation loss: 3.1273836065249365

Epoch: 6| Step: 3
Training loss: 3.0070003849862768
Validation loss: 3.131542404257371

Epoch: 6| Step: 4
Training loss: 3.216271047690084
Validation loss: 3.1293673885580606

Epoch: 6| Step: 5
Training loss: 3.210271538868867
Validation loss: 3.1305680996331784

Epoch: 6| Step: 6
Training loss: 2.8316277999261223
Validation loss: 3.1338318355127424

Epoch: 6| Step: 7
Training loss: 3.219557577505494
Validation loss: 3.1315319950913283

Epoch: 6| Step: 8
Training loss: 2.906057700081189
Validation loss: 3.1349183046517135

Epoch: 6| Step: 9
Training loss: 3.973895004521132
Validation loss: 3.13035788516738

Epoch: 6| Step: 10
Training loss: 3.693803991449207
Validation loss: 3.1292865763680062

Epoch: 6| Step: 11
Training loss: 3.2029228332732775
Validation loss: 3.1329976474323478

Epoch: 6| Step: 12
Training loss: 2.6595078180767997
Validation loss: 3.1268580157333883

Epoch: 6| Step: 13
Training loss: 4.214625171724618
Validation loss: 3.131317071440113

Epoch: 76| Step: 0
Training loss: 3.264046173274001
Validation loss: 3.126930641281589

Epoch: 6| Step: 1
Training loss: 4.500075869450486
Validation loss: 3.1294496691230353

Epoch: 6| Step: 2
Training loss: 3.5898001816589016
Validation loss: 3.120748230508607

Epoch: 6| Step: 3
Training loss: 3.233345052035879
Validation loss: 3.123326683375744

Epoch: 6| Step: 4
Training loss: 2.9994415717140526
Validation loss: 3.118904475869369

Epoch: 6| Step: 5
Training loss: 3.275742040536418
Validation loss: 3.1211798824138577

Epoch: 6| Step: 6
Training loss: 3.2845523746406924
Validation loss: 3.121289603073315

Epoch: 6| Step: 7
Training loss: 3.065058981995347
Validation loss: 3.122105174405162

Epoch: 6| Step: 8
Training loss: 3.93446838898297
Validation loss: 3.1195645912306578

Epoch: 6| Step: 9
Training loss: 3.1727380940679306
Validation loss: 3.120409186187296

Epoch: 6| Step: 10
Training loss: 3.227207368782342
Validation loss: 3.1214745699771527

Epoch: 6| Step: 11
Training loss: 2.7636943047897224
Validation loss: 3.120065566163599

Epoch: 6| Step: 12
Training loss: 3.0997752077370024
Validation loss: 3.121905021897176

Epoch: 6| Step: 13
Training loss: 3.7677706228768453
Validation loss: 3.1232016821967687

Epoch: 77| Step: 0
Training loss: 3.174364738290044
Validation loss: 3.121239908310085

Epoch: 6| Step: 1
Training loss: 3.5516373847555114
Validation loss: 3.122275763524937

Epoch: 6| Step: 2
Training loss: 3.6750194315493934
Validation loss: 3.11935559123647

Epoch: 6| Step: 3
Training loss: 4.285073236932366
Validation loss: 3.122183517020349

Epoch: 6| Step: 4
Training loss: 2.830378861965002
Validation loss: 3.1235474801932557

Epoch: 6| Step: 5
Training loss: 1.8196958880957521
Validation loss: 3.122345261492369

Epoch: 6| Step: 6
Training loss: 3.0467410327118642
Validation loss: 3.1244262496755404

Epoch: 6| Step: 7
Training loss: 3.455084611488753
Validation loss: 3.13626629107393

Epoch: 6| Step: 8
Training loss: 3.436754596694089
Validation loss: 3.1372679668343886

Epoch: 6| Step: 9
Training loss: 3.603971589970359
Validation loss: 3.138274134394638

Epoch: 6| Step: 10
Training loss: 3.6128882282029298
Validation loss: 3.132562776668215

Epoch: 6| Step: 11
Training loss: 3.391734280173954
Validation loss: 3.1367078177744387

Epoch: 6| Step: 12
Training loss: 3.3348469794310955
Validation loss: 3.1349189981201895

Epoch: 6| Step: 13
Training loss: 3.6973814384429926
Validation loss: 3.1307354213819654

Epoch: 78| Step: 0
Training loss: 2.2864811113362733
Validation loss: 3.1237711633573486

Epoch: 6| Step: 1
Training loss: 3.80926826959665
Validation loss: 3.122426889638976

Epoch: 6| Step: 2
Training loss: 3.28665616769513
Validation loss: 3.1190972379202377

Epoch: 6| Step: 3
Training loss: 3.5160759530657257
Validation loss: 3.1196170952314812

Epoch: 6| Step: 4
Training loss: 3.982573696683053
Validation loss: 3.1192590528422435

Epoch: 6| Step: 5
Training loss: 2.951963488924178
Validation loss: 3.1185570696988987

Epoch: 6| Step: 6
Training loss: 3.276570789361236
Validation loss: 3.119153157398689

Epoch: 6| Step: 7
Training loss: 3.61037943021602
Validation loss: 3.1237190656664113

Epoch: 6| Step: 8
Training loss: 3.52775130341242
Validation loss: 3.133101261719674

Epoch: 6| Step: 9
Training loss: 3.372066918710282
Validation loss: 3.1224593468648614

Epoch: 6| Step: 10
Training loss: 3.925310552666564
Validation loss: 3.119441715759251

Epoch: 6| Step: 11
Training loss: 2.5297937796158037
Validation loss: 3.118578037087589

Epoch: 6| Step: 12
Training loss: 3.6293222375775347
Validation loss: 3.115883553378242

Epoch: 6| Step: 13
Training loss: 2.8939981111152564
Validation loss: 3.1134944692529065

Epoch: 79| Step: 0
Training loss: 3.7053037262052047
Validation loss: 3.1159397164719254

Epoch: 6| Step: 1
Training loss: 3.2999004926995528
Validation loss: 3.113110359059421

Epoch: 6| Step: 2
Training loss: 3.3628107997952736
Validation loss: 3.1110337906876833

Epoch: 6| Step: 3
Training loss: 3.427650907103405
Validation loss: 3.1160625144853125

Epoch: 6| Step: 4
Training loss: 3.348859359362388
Validation loss: 3.114447292169525

Epoch: 6| Step: 5
Training loss: 3.1799109378074877
Validation loss: 3.1145308970266297

Epoch: 6| Step: 6
Training loss: 4.038954358894443
Validation loss: 3.11168659221775

Epoch: 6| Step: 7
Training loss: 3.153647530153901
Validation loss: 3.110954453647454

Epoch: 6| Step: 8
Training loss: 2.5397460017525315
Validation loss: 3.1108619983420307

Epoch: 6| Step: 9
Training loss: 1.643862481855745
Validation loss: 3.1108217328811487

Epoch: 6| Step: 10
Training loss: 3.2255989464807304
Validation loss: 3.113204508179762

Epoch: 6| Step: 11
Training loss: 4.406776342676697
Validation loss: 3.1152209002056512

Epoch: 6| Step: 12
Training loss: 3.8370776065139265
Validation loss: 3.111298554228726

Epoch: 6| Step: 13
Training loss: 3.1226455974611897
Validation loss: 3.110964205662851

Epoch: 80| Step: 0
Training loss: 3.3398820127559685
Validation loss: 3.1134741395254686

Epoch: 6| Step: 1
Training loss: 3.406638586994861
Validation loss: 3.11221675507327

Epoch: 6| Step: 2
Training loss: 2.9999518390604423
Validation loss: 3.11221528223545

Epoch: 6| Step: 3
Training loss: 4.277325467283986
Validation loss: 3.1131517428606132

Epoch: 6| Step: 4
Training loss: 2.64115223333092
Validation loss: 3.114109143274986

Epoch: 6| Step: 5
Training loss: 3.810533735681793
Validation loss: 3.116186638764599

Epoch: 6| Step: 6
Training loss: 3.6400675203537607
Validation loss: 3.118722001375722

Epoch: 6| Step: 7
Training loss: 3.639130248654863
Validation loss: 3.1263159132694938

Epoch: 6| Step: 8
Training loss: 3.007261706366949
Validation loss: 3.1517606908293945

Epoch: 6| Step: 9
Training loss: 2.824912422645643
Validation loss: 3.1716808900430196

Epoch: 6| Step: 10
Training loss: 3.6364719786543227
Validation loss: 3.1486179653575936

Epoch: 6| Step: 11
Training loss: 3.8653407147290886
Validation loss: 3.119976108849752

Epoch: 6| Step: 12
Training loss: 2.8514897585435253
Validation loss: 3.1092832983301406

Epoch: 6| Step: 13
Training loss: 2.3577614628935137
Validation loss: 3.107898059831709

Epoch: 81| Step: 0
Training loss: 3.0019674207735405
Validation loss: 3.1069468070263

Epoch: 6| Step: 1
Training loss: 3.844018197976184
Validation loss: 3.1070292250488984

Epoch: 6| Step: 2
Training loss: 3.3919704598004228
Validation loss: 3.1088281864766802

Epoch: 6| Step: 3
Training loss: 3.3661765154082075
Validation loss: 3.110819035587585

Epoch: 6| Step: 4
Training loss: 3.486668400760995
Validation loss: 3.111940511651432

Epoch: 6| Step: 5
Training loss: 2.4484232168748696
Validation loss: 3.1150791924338317

Epoch: 6| Step: 6
Training loss: 3.392497306041168
Validation loss: 3.1137745629894806

Epoch: 6| Step: 7
Training loss: 3.1743725494597625
Validation loss: 3.1124972026529205

Epoch: 6| Step: 8
Training loss: 3.2048933404799196
Validation loss: 3.11183565810906

Epoch: 6| Step: 9
Training loss: 3.223594649122781
Validation loss: 3.1121045554553586

Epoch: 6| Step: 10
Training loss: 3.39170082006356
Validation loss: 3.1083605484162953

Epoch: 6| Step: 11
Training loss: 3.4055575445631594
Validation loss: 3.111084879585386

Epoch: 6| Step: 12
Training loss: 3.9234021621625805
Validation loss: 3.1117705983169444

Epoch: 6| Step: 13
Training loss: 3.993007866763556
Validation loss: 3.1127136020117296

Epoch: 82| Step: 0
Training loss: 4.5130178983854545
Validation loss: 3.109510366348336

Epoch: 6| Step: 1
Training loss: 2.9970214680668725
Validation loss: 3.104467491499121

Epoch: 6| Step: 2
Training loss: 3.0214297703331883
Validation loss: 3.1082694543731297

Epoch: 6| Step: 3
Training loss: 3.8419362572818785
Validation loss: 3.106014467876278

Epoch: 6| Step: 4
Training loss: 3.4197376839944233
Validation loss: 3.1058713091077284

Epoch: 6| Step: 5
Training loss: 3.2518798086705267
Validation loss: 3.1046217206123243

Epoch: 6| Step: 6
Training loss: 2.9835338106050413
Validation loss: 3.1032937878965794

Epoch: 6| Step: 7
Training loss: 3.1382894609423175
Validation loss: 3.1037143400568463

Epoch: 6| Step: 8
Training loss: 3.128263676605777
Validation loss: 3.10298057988155

Epoch: 6| Step: 9
Training loss: 2.5926069935393636
Validation loss: 3.104194175750833

Epoch: 6| Step: 10
Training loss: 3.2439770275483193
Validation loss: 3.1020666648600774

Epoch: 6| Step: 11
Training loss: 2.395546329280392
Validation loss: 3.102374853358253

Epoch: 6| Step: 12
Training loss: 4.068140662252963
Validation loss: 3.105442181204818

Epoch: 6| Step: 13
Training loss: 4.2273936697177295
Validation loss: 3.1018569718469675

Epoch: 83| Step: 0
Training loss: 4.234166439311404
Validation loss: 3.1047290843909794

Epoch: 6| Step: 1
Training loss: 3.2184418465962494
Validation loss: 3.1021600930059

Epoch: 6| Step: 2
Training loss: 3.3365277878107067
Validation loss: 3.1037626634680016

Epoch: 6| Step: 3
Training loss: 3.396368690525577
Validation loss: 3.099456166937829

Epoch: 6| Step: 4
Training loss: 3.1590811240903554
Validation loss: 3.1006524614376336

Epoch: 6| Step: 5
Training loss: 3.016400963759613
Validation loss: 3.104242035822853

Epoch: 6| Step: 6
Training loss: 3.0669801600174917
Validation loss: 3.1024145987801526

Epoch: 6| Step: 7
Training loss: 3.4776547891267797
Validation loss: 3.097030594878731

Epoch: 6| Step: 8
Training loss: 2.8181034640777165
Validation loss: 3.0999770661153097

Epoch: 6| Step: 9
Training loss: 3.4062814973547315
Validation loss: 3.104529829819323

Epoch: 6| Step: 10
Training loss: 3.4258438852776036
Validation loss: 3.106087341427272

Epoch: 6| Step: 11
Training loss: 2.7092190003500844
Validation loss: 3.103732394519303

Epoch: 6| Step: 12
Training loss: 4.066542975832419
Validation loss: 3.1046450198800786

Epoch: 6| Step: 13
Training loss: 3.4670421073035613
Validation loss: 3.1000665853350937

Epoch: 84| Step: 0
Training loss: 2.5972149237418574
Validation loss: 3.0984284464005354

Epoch: 6| Step: 1
Training loss: 3.04442368714557
Validation loss: 3.098581127781014

Epoch: 6| Step: 2
Training loss: 2.9015731096458897
Validation loss: 3.099328222800447

Epoch: 6| Step: 3
Training loss: 3.4202708486196647
Validation loss: 3.099611411282772

Epoch: 6| Step: 4
Training loss: 4.059381314948899
Validation loss: 3.1003445804944962

Epoch: 6| Step: 5
Training loss: 2.961898124493469
Validation loss: 3.0952536536691935

Epoch: 6| Step: 6
Training loss: 4.015631887229624
Validation loss: 3.0961195082692443

Epoch: 6| Step: 7
Training loss: 3.3962493516839243
Validation loss: 3.0944582419637916

Epoch: 6| Step: 8
Training loss: 3.546324027535607
Validation loss: 3.09621065507625

Epoch: 6| Step: 9
Training loss: 3.567271734472085
Validation loss: 3.0960439863707534

Epoch: 6| Step: 10
Training loss: 2.92981493863452
Validation loss: 3.097518853504918

Epoch: 6| Step: 11
Training loss: 3.482806344452557
Validation loss: 3.095458002447303

Epoch: 6| Step: 12
Training loss: 3.700817306565168
Validation loss: 3.098610914235761

Epoch: 6| Step: 13
Training loss: 2.7848435235709648
Validation loss: 3.0969332562613503

Epoch: 85| Step: 0
Training loss: 4.051535496619905
Validation loss: 3.09524215009794

Epoch: 6| Step: 1
Training loss: 2.125983739796107
Validation loss: 3.096178184333934

Epoch: 6| Step: 2
Training loss: 3.421610643461172
Validation loss: 3.0980917721641763

Epoch: 6| Step: 3
Training loss: 3.2140088764440784
Validation loss: 3.097671838757954

Epoch: 6| Step: 4
Training loss: 3.8852175473214685
Validation loss: 3.0965693042960742

Epoch: 6| Step: 5
Training loss: 3.6708019230711497
Validation loss: 3.095934318309045

Epoch: 6| Step: 6
Training loss: 3.8298941125002224
Validation loss: 3.0945640214801577

Epoch: 6| Step: 7
Training loss: 3.670862975561954
Validation loss: 3.0956647012456555

Epoch: 6| Step: 8
Training loss: 2.8558037140015897
Validation loss: 3.09948428743841

Epoch: 6| Step: 9
Training loss: 2.816799691875585
Validation loss: 3.0999025809851912

Epoch: 6| Step: 10
Training loss: 3.3445760116664927
Validation loss: 3.0986051881301853

Epoch: 6| Step: 11
Training loss: 3.7357823740535343
Validation loss: 3.0946581284428283

Epoch: 6| Step: 12
Training loss: 2.6166608138130316
Validation loss: 3.0968661590519844

Epoch: 6| Step: 13
Training loss: 3.018707597328119
Validation loss: 3.091044806393084

Epoch: 86| Step: 0
Training loss: 2.66606713549139
Validation loss: 3.09149510359478

Epoch: 6| Step: 1
Training loss: 3.2080785641931597
Validation loss: 3.0911888276246553

Epoch: 6| Step: 2
Training loss: 3.431568368618912
Validation loss: 3.0928656792398805

Epoch: 6| Step: 3
Training loss: 3.340364970978959
Validation loss: 3.0926300620390745

Epoch: 6| Step: 4
Training loss: 2.8184114003286824
Validation loss: 3.096160456767925

Epoch: 6| Step: 5
Training loss: 3.625408938788796
Validation loss: 3.09382463905652

Epoch: 6| Step: 6
Training loss: 3.0075562999652954
Validation loss: 3.0940512001649245

Epoch: 6| Step: 7
Training loss: 3.3244359161768484
Validation loss: 3.0935014973168475

Epoch: 6| Step: 8
Training loss: 3.791819908203389
Validation loss: 3.092858739778001

Epoch: 6| Step: 9
Training loss: 3.5866183962167715
Validation loss: 3.095832048705511

Epoch: 6| Step: 10
Training loss: 3.8607381660385287
Validation loss: 3.096997103799415

Epoch: 6| Step: 11
Training loss: 3.25279409171195
Validation loss: 3.1043452588444853

Epoch: 6| Step: 12
Training loss: 3.1858926348031824
Validation loss: 3.1056754115390417

Epoch: 6| Step: 13
Training loss: 3.8139048004991563
Validation loss: 3.1038818349824995

Epoch: 87| Step: 0
Training loss: 3.0952950674968944
Validation loss: 3.096418793919403

Epoch: 6| Step: 1
Training loss: 3.7572611128655224
Validation loss: 3.0923847257400263

Epoch: 6| Step: 2
Training loss: 3.1617171272215225
Validation loss: 3.0909791505750537

Epoch: 6| Step: 3
Training loss: 3.537845225388775
Validation loss: 3.091840992598803

Epoch: 6| Step: 4
Training loss: 3.287276192941013
Validation loss: 3.0868063066493017

Epoch: 6| Step: 5
Training loss: 2.7723651370930815
Validation loss: 3.086730454732227

Epoch: 6| Step: 6
Training loss: 2.9698206526939437
Validation loss: 3.089892977315951

Epoch: 6| Step: 7
Training loss: 3.607258229656536
Validation loss: 3.0886523536418364

Epoch: 6| Step: 8
Training loss: 3.4566194967977153
Validation loss: 3.0890554568534254

Epoch: 6| Step: 9
Training loss: 3.5723510531748053
Validation loss: 3.0903906956698908

Epoch: 6| Step: 10
Training loss: 3.344724994297078
Validation loss: 3.090298570857406

Epoch: 6| Step: 11
Training loss: 4.148017704012693
Validation loss: 3.090255117308335

Epoch: 6| Step: 12
Training loss: 2.519334794303078
Validation loss: 3.0961807676979944

Epoch: 6| Step: 13
Training loss: 3.478638447087688
Validation loss: 3.0956724625545298

Epoch: 88| Step: 0
Training loss: 3.269290309035871
Validation loss: 3.0958826398806094

Epoch: 6| Step: 1
Training loss: 3.3196900266695
Validation loss: 3.0977816944072347

Epoch: 6| Step: 2
Training loss: 3.848132976296333
Validation loss: 3.096113624372445

Epoch: 6| Step: 3
Training loss: 3.4725764708478675
Validation loss: 3.0872560030457206

Epoch: 6| Step: 4
Training loss: 3.1515056342090157
Validation loss: 3.0856893584784424

Epoch: 6| Step: 5
Training loss: 3.5672296281784
Validation loss: 3.0859100070578642

Epoch: 6| Step: 6
Training loss: 3.1698104077271023
Validation loss: 3.084421883329077

Epoch: 6| Step: 7
Training loss: 2.97554507351125
Validation loss: 3.086396116833515

Epoch: 6| Step: 8
Training loss: 3.4833766721618167
Validation loss: 3.0850751763144713

Epoch: 6| Step: 9
Training loss: 3.1149236350702623
Validation loss: 3.0857194072916143

Epoch: 6| Step: 10
Training loss: 2.7596330118140346
Validation loss: 3.088088466831988

Epoch: 6| Step: 11
Training loss: 3.386533597925095
Validation loss: 3.085959823816338

Epoch: 6| Step: 12
Training loss: 3.563604618614082
Validation loss: 3.084093617628073

Epoch: 6| Step: 13
Training loss: 3.921862841583494
Validation loss: 3.0830994799752003

Epoch: 89| Step: 0
Training loss: 3.0591513562700436
Validation loss: 3.084941335518434

Epoch: 6| Step: 1
Training loss: 3.704988163814609
Validation loss: 3.081340909877814

Epoch: 6| Step: 2
Training loss: 3.2993227292585
Validation loss: 3.0827111068397413

Epoch: 6| Step: 3
Training loss: 3.6386684677755117
Validation loss: 3.083089152552998

Epoch: 6| Step: 4
Training loss: 3.4750742952377114
Validation loss: 3.0817434013590597

Epoch: 6| Step: 5
Training loss: 3.6691869108386834
Validation loss: 3.0817927073228533

Epoch: 6| Step: 6
Training loss: 2.9305574880134593
Validation loss: 3.0870631445250516

Epoch: 6| Step: 7
Training loss: 3.4240062469265005
Validation loss: 3.0823091941822844

Epoch: 6| Step: 8
Training loss: 3.7296058495625
Validation loss: 3.0813405088592627

Epoch: 6| Step: 9
Training loss: 2.8011784185466904
Validation loss: 3.0796760468674695

Epoch: 6| Step: 10
Training loss: 3.2943373038882267
Validation loss: 3.086895110738564

Epoch: 6| Step: 11
Training loss: 2.9829694224065064
Validation loss: 3.0889667414294344

Epoch: 6| Step: 12
Training loss: 2.9638206918202252
Validation loss: 3.0904970208742575

Epoch: 6| Step: 13
Training loss: 3.8939258713291203
Validation loss: 3.095815339375182

Epoch: 90| Step: 0
Training loss: 3.5404447504610057
Validation loss: 3.0897758549751884

Epoch: 6| Step: 1
Training loss: 2.5780071809607996
Validation loss: 3.0864421215382407

Epoch: 6| Step: 2
Training loss: 3.3327584406693114
Validation loss: 3.083778843598013

Epoch: 6| Step: 3
Training loss: 3.807600782016145
Validation loss: 3.0828313898421595

Epoch: 6| Step: 4
Training loss: 3.291821842318466
Validation loss: 3.078420846881496

Epoch: 6| Step: 5
Training loss: 3.0246916936968873
Validation loss: 3.076659647548142

Epoch: 6| Step: 6
Training loss: 3.36689916380756
Validation loss: 3.0787571141970895

Epoch: 6| Step: 7
Training loss: 3.4202562100103346
Validation loss: 3.0788315488422824

Epoch: 6| Step: 8
Training loss: 3.299515521003022
Validation loss: 3.0790949733462205

Epoch: 6| Step: 9
Training loss: 3.2959116029829643
Validation loss: 3.0783057664931324

Epoch: 6| Step: 10
Training loss: 3.5130246188079974
Validation loss: 3.0746889276679017

Epoch: 6| Step: 11
Training loss: 3.3437448661978695
Validation loss: 3.077294353725159

Epoch: 6| Step: 12
Training loss: 3.5136585754855307
Validation loss: 3.077188195500156

Epoch: 6| Step: 13
Training loss: 3.3527908030666658
Validation loss: 3.0775228481587984

Epoch: 91| Step: 0
Training loss: 3.2337455689908974
Validation loss: 3.0761247649575805

Epoch: 6| Step: 1
Training loss: 3.018127035936975
Validation loss: 3.0756437258622924

Epoch: 6| Step: 2
Training loss: 3.6732312883256046
Validation loss: 3.0758379530063444

Epoch: 6| Step: 3
Training loss: 3.1813105909052113
Validation loss: 3.075157316105341

Epoch: 6| Step: 4
Training loss: 3.5235319611263782
Validation loss: 3.075845951876104

Epoch: 6| Step: 5
Training loss: 3.4730610220018923
Validation loss: 3.0841757602687645

Epoch: 6| Step: 6
Training loss: 3.4058036861773604
Validation loss: 3.0898228365332447

Epoch: 6| Step: 7
Training loss: 2.4080332303970162
Validation loss: 3.0935842561413622

Epoch: 6| Step: 8
Training loss: 3.320416042732955
Validation loss: 3.095515761006261

Epoch: 6| Step: 9
Training loss: 3.543609325704889
Validation loss: 3.101118193205833

Epoch: 6| Step: 10
Training loss: 3.984594720504197
Validation loss: 3.106301802201204

Epoch: 6| Step: 11
Training loss: 2.808944489248009
Validation loss: 3.079061905805566

Epoch: 6| Step: 12
Training loss: 3.8009041965276684
Validation loss: 3.0774208938837027

Epoch: 6| Step: 13
Training loss: 2.974082574515069
Validation loss: 3.0756739269985003

Epoch: 92| Step: 0
Training loss: 3.311078324322728
Validation loss: 3.075618956591638

Epoch: 6| Step: 1
Training loss: 3.132540645837999
Validation loss: 3.0791805130202654

Epoch: 6| Step: 2
Training loss: 2.8547385726393992
Validation loss: 3.082897876120505

Epoch: 6| Step: 3
Training loss: 3.1845631252793782
Validation loss: 3.0806467784505176

Epoch: 6| Step: 4
Training loss: 4.334571857011226
Validation loss: 3.0852408945195253

Epoch: 6| Step: 5
Training loss: 3.4878961536364934
Validation loss: 3.0846227185399666

Epoch: 6| Step: 6
Training loss: 2.3122071776704405
Validation loss: 3.087382521031505

Epoch: 6| Step: 7
Training loss: 3.4255007690998998
Validation loss: 3.078480150085177

Epoch: 6| Step: 8
Training loss: 3.3084594266933625
Validation loss: 3.0779940702923123

Epoch: 6| Step: 9
Training loss: 3.6890263388839464
Validation loss: 3.0767511741990106

Epoch: 6| Step: 10
Training loss: 3.405129624642815
Validation loss: 3.075164568119238

Epoch: 6| Step: 11
Training loss: 3.086169424878546
Validation loss: 3.0746120047028134

Epoch: 6| Step: 12
Training loss: 3.416480284158458
Validation loss: 3.0747175148116046

Epoch: 6| Step: 13
Training loss: 3.592381888659969
Validation loss: 3.0733812606993376

Epoch: 93| Step: 0
Training loss: 3.5467308788175362
Validation loss: 3.070599873980293

Epoch: 6| Step: 1
Training loss: 4.115593560054552
Validation loss: 3.073192367296658

Epoch: 6| Step: 2
Training loss: 3.325007308148835
Validation loss: 3.0730014450756302

Epoch: 6| Step: 3
Training loss: 3.376861906391623
Validation loss: 3.070787912515037

Epoch: 6| Step: 4
Training loss: 3.198059095427137
Validation loss: 3.0706280650491014

Epoch: 6| Step: 5
Training loss: 3.7112021903957277
Validation loss: 3.071435782932696

Epoch: 6| Step: 6
Training loss: 3.2204215144659187
Validation loss: 3.076270864742724

Epoch: 6| Step: 7
Training loss: 3.144981892204615
Validation loss: 3.0731803949117005

Epoch: 6| Step: 8
Training loss: 3.1573399842853775
Validation loss: 3.077787863991015

Epoch: 6| Step: 9
Training loss: 3.261253241482195
Validation loss: 3.0770079099056846

Epoch: 6| Step: 10
Training loss: 2.5176468773947174
Validation loss: 3.0778186637958274

Epoch: 6| Step: 11
Training loss: 3.4467880998933493
Validation loss: 3.077894204765694

Epoch: 6| Step: 12
Training loss: 3.032909450327642
Validation loss: 3.0772507090469956

Epoch: 6| Step: 13
Training loss: 3.5267843180924423
Validation loss: 3.0724703545811747

Epoch: 94| Step: 0
Training loss: 3.6229697494317907
Validation loss: 3.069142669603255

Epoch: 6| Step: 1
Training loss: 3.146615611109363
Validation loss: 3.068583430173037

Epoch: 6| Step: 2
Training loss: 2.740039299174913
Validation loss: 3.0692892370512395

Epoch: 6| Step: 3
Training loss: 3.006092243456923
Validation loss: 3.0677221725393777

Epoch: 6| Step: 4
Training loss: 2.611995180993067
Validation loss: 3.0681997185215963

Epoch: 6| Step: 5
Training loss: 2.872608849012735
Validation loss: 3.0668906823107576

Epoch: 6| Step: 6
Training loss: 3.6489113738864005
Validation loss: 3.0680389908571626

Epoch: 6| Step: 7
Training loss: 4.146081632657887
Validation loss: 3.0680298510961874

Epoch: 6| Step: 8
Training loss: 4.4370645658667085
Validation loss: 3.0683794421798547

Epoch: 6| Step: 9
Training loss: 3.2889449218610585
Validation loss: 3.0653762269382825

Epoch: 6| Step: 10
Training loss: 2.282969310265153
Validation loss: 3.0681516989681845

Epoch: 6| Step: 11
Training loss: 2.800327833602161
Validation loss: 3.0673120357832095

Epoch: 6| Step: 12
Training loss: 3.5893932968967235
Validation loss: 3.0665827582072214

Epoch: 6| Step: 13
Training loss: 4.0583392624286265
Validation loss: 3.0659232713423057

Epoch: 95| Step: 0
Training loss: 3.4919744849043006
Validation loss: 3.0666395274344

Epoch: 6| Step: 1
Training loss: 3.4344581323199574
Validation loss: 3.0678933188106696

Epoch: 6| Step: 2
Training loss: 2.9897243630421473
Validation loss: 3.068439800003503

Epoch: 6| Step: 3
Training loss: 3.4290058961975007
Validation loss: 3.0670255364981873

Epoch: 6| Step: 4
Training loss: 3.363657080799759
Validation loss: 3.0653828238366976

Epoch: 6| Step: 5
Training loss: 3.1475065383661427
Validation loss: 3.063462711088095

Epoch: 6| Step: 6
Training loss: 3.4985712404912497
Validation loss: 3.065521360441762

Epoch: 6| Step: 7
Training loss: 3.762653618905064
Validation loss: 3.0642339465861936

Epoch: 6| Step: 8
Training loss: 3.1982816970364936
Validation loss: 3.0647199502508524

Epoch: 6| Step: 9
Training loss: 2.7505152826458463
Validation loss: 3.06535253719847

Epoch: 6| Step: 10
Training loss: 3.2861132231492642
Validation loss: 3.063801957262789

Epoch: 6| Step: 11
Training loss: 2.79585443556014
Validation loss: 3.0623026556772173

Epoch: 6| Step: 12
Training loss: 3.7417104014762588
Validation loss: 3.062985132134834

Epoch: 6| Step: 13
Training loss: 3.7730396763959697
Validation loss: 3.064626651388973

Epoch: 96| Step: 0
Training loss: 3.4813954567783663
Validation loss: 3.0641595221167024

Epoch: 6| Step: 1
Training loss: 2.8853264162200447
Validation loss: 3.061249501732566

Epoch: 6| Step: 2
Training loss: 2.710560797207409
Validation loss: 3.065544963576836

Epoch: 6| Step: 3
Training loss: 3.1883581165786916
Validation loss: 3.0646214590661507

Epoch: 6| Step: 4
Training loss: 3.550317379370849
Validation loss: 3.062797446556981

Epoch: 6| Step: 5
Training loss: 3.8194765139688025
Validation loss: 3.0636403679350246

Epoch: 6| Step: 6
Training loss: 3.870230539044671
Validation loss: 3.064262104192404

Epoch: 6| Step: 7
Training loss: 3.130189782382287
Validation loss: 3.061968794377645

Epoch: 6| Step: 8
Training loss: 3.234981461579447
Validation loss: 3.061477937599204

Epoch: 6| Step: 9
Training loss: 3.533318647917933
Validation loss: 3.064656483442847

Epoch: 6| Step: 10
Training loss: 3.3751049731848473
Validation loss: 3.063786400340909

Epoch: 6| Step: 11
Training loss: 3.4568665546044404
Validation loss: 3.0612192495718515

Epoch: 6| Step: 12
Training loss: 2.9401807524462953
Validation loss: 3.061671483347796

Epoch: 6| Step: 13
Training loss: 3.1251649431567663
Validation loss: 3.0603724731005606

Epoch: 97| Step: 0
Training loss: 3.3991068564506506
Validation loss: 3.0610817611071726

Epoch: 6| Step: 1
Training loss: 3.5289292262766936
Validation loss: 3.063083457491076

Epoch: 6| Step: 2
Training loss: 2.7456685546921613
Validation loss: 3.061830143920229

Epoch: 6| Step: 3
Training loss: 3.2866541365358186
Validation loss: 3.05983299063421

Epoch: 6| Step: 4
Training loss: 4.018321516055738
Validation loss: 3.0597510256393923

Epoch: 6| Step: 5
Training loss: 3.2401488731466968
Validation loss: 3.0581600988340827

Epoch: 6| Step: 6
Training loss: 2.9411512368185617
Validation loss: 3.059836130844869

Epoch: 6| Step: 7
Training loss: 3.4563246872404694
Validation loss: 3.0581025979557888

Epoch: 6| Step: 8
Training loss: 3.6945167636405833
Validation loss: 3.056719773210154

Epoch: 6| Step: 9
Training loss: 2.6763110005367907
Validation loss: 3.056554870545287

Epoch: 6| Step: 10
Training loss: 3.241218440457194
Validation loss: 3.0580170337219736

Epoch: 6| Step: 11
Training loss: 2.876011214508985
Validation loss: 3.0547763012276525

Epoch: 6| Step: 12
Training loss: 3.3030701776175753
Validation loss: 3.0557330879501396

Epoch: 6| Step: 13
Training loss: 4.269289112815926
Validation loss: 3.0576716841942764

Epoch: 98| Step: 0
Training loss: 3.3053054412192253
Validation loss: 3.0602973968079596

Epoch: 6| Step: 1
Training loss: 3.569753390217281
Validation loss: 3.0603167444886825

Epoch: 6| Step: 2
Training loss: 3.4231645775652764
Validation loss: 3.057827183668298

Epoch: 6| Step: 3
Training loss: 3.0895662629231895
Validation loss: 3.0583763076173978

Epoch: 6| Step: 4
Training loss: 3.607561456760874
Validation loss: 3.0598408176954446

Epoch: 6| Step: 5
Training loss: 3.8654371828109966
Validation loss: 3.0565239898309784

Epoch: 6| Step: 6
Training loss: 3.0312819331738563
Validation loss: 3.064270831859984

Epoch: 6| Step: 7
Training loss: 3.443584536473421
Validation loss: 3.059930923808781

Epoch: 6| Step: 8
Training loss: 3.551039750328155
Validation loss: 3.0645725360281766

Epoch: 6| Step: 9
Training loss: 3.308786289778441
Validation loss: 3.065066502969151

Epoch: 6| Step: 10
Training loss: 3.0341776444815296
Validation loss: 3.0703190437085803

Epoch: 6| Step: 11
Training loss: 3.180307388803836
Validation loss: 3.0693963516851155

Epoch: 6| Step: 12
Training loss: 3.1615201555436414
Validation loss: 3.063965642386666

Epoch: 6| Step: 13
Training loss: 2.492875437722079
Validation loss: 3.0565063644173316

Epoch: 99| Step: 0
Training loss: 3.2252256565841515
Validation loss: 3.0565489641652084

Epoch: 6| Step: 1
Training loss: 3.900323873912413
Validation loss: 3.054614898303113

Epoch: 6| Step: 2
Training loss: 3.265036790065085
Validation loss: 3.0557709147858647

Epoch: 6| Step: 3
Training loss: 3.801373113202171
Validation loss: 3.0560839934083974

Epoch: 6| Step: 4
Training loss: 3.6132305739689605
Validation loss: 3.054381531751595

Epoch: 6| Step: 5
Training loss: 3.5874130770158104
Validation loss: 3.0574907844309394

Epoch: 6| Step: 6
Training loss: 3.101534057794258
Validation loss: 3.056951513792226

Epoch: 6| Step: 7
Training loss: 2.9621608491711426
Validation loss: 3.05675442936632

Epoch: 6| Step: 8
Training loss: 3.6874764651824443
Validation loss: 3.055155905512634

Epoch: 6| Step: 9
Training loss: 3.079214610000563
Validation loss: 3.054222014188593

Epoch: 6| Step: 10
Training loss: 2.6043945111101605
Validation loss: 3.0529410836066493

Epoch: 6| Step: 11
Training loss: 2.764366510125064
Validation loss: 3.0558306978159986

Epoch: 6| Step: 12
Training loss: 3.0945994434388484
Validation loss: 3.052690064260972

Epoch: 6| Step: 13
Training loss: 3.7765490101205206
Validation loss: 3.052959323287788

Epoch: 100| Step: 0
Training loss: 3.543510689972408
Validation loss: 3.0543643170005685

Epoch: 6| Step: 1
Training loss: 3.44558514059072
Validation loss: 3.0533023493996168

Epoch: 6| Step: 2
Training loss: 3.0879102364869797
Validation loss: 3.055183235509733

Epoch: 6| Step: 3
Training loss: 2.981825133694075
Validation loss: 3.0540352406043354

Epoch: 6| Step: 4
Training loss: 3.1344155945055516
Validation loss: 3.056787874088279

Epoch: 6| Step: 5
Training loss: 3.146003482756048
Validation loss: 3.0584578115551198

Epoch: 6| Step: 6
Training loss: 4.0625607999506785
Validation loss: 3.0580493664291617

Epoch: 6| Step: 7
Training loss: 3.20471137236469
Validation loss: 3.0540522188142374

Epoch: 6| Step: 8
Training loss: 3.249076125070619
Validation loss: 3.057725520923753

Epoch: 6| Step: 9
Training loss: 3.4638539720815
Validation loss: 3.0589489937256067

Epoch: 6| Step: 10
Training loss: 3.2411419389028975
Validation loss: 3.0554660098496096

Epoch: 6| Step: 11
Training loss: 2.7414532409275894
Validation loss: 3.0578375176012447

Epoch: 6| Step: 12
Training loss: 3.3177799394786027
Validation loss: 3.0549632862918688

Epoch: 6| Step: 13
Training loss: 3.918839697290396
Validation loss: 3.0471879792573486

Epoch: 101| Step: 0
Training loss: 3.986269033200558
Validation loss: 3.057660372927614

Epoch: 6| Step: 1
Training loss: 3.1786318814573957
Validation loss: 3.0566321137405548

Epoch: 6| Step: 2
Training loss: 3.2032735650569673
Validation loss: 3.0494953037850574

Epoch: 6| Step: 3
Training loss: 2.86908411810421
Validation loss: 3.049733554116041

Epoch: 6| Step: 4
Training loss: 2.463858672077041
Validation loss: 3.0482369659561206

Epoch: 6| Step: 5
Training loss: 2.5469626195146797
Validation loss: 3.051239500675712

Epoch: 6| Step: 6
Training loss: 3.046920071782016
Validation loss: 3.051921272504051

Epoch: 6| Step: 7
Training loss: 3.610783421899026
Validation loss: 3.048760530799158

Epoch: 6| Step: 8
Training loss: 3.676476764449373
Validation loss: 3.04899107614178

Epoch: 6| Step: 9
Training loss: 3.9248874235105706
Validation loss: 3.048534735324963

Epoch: 6| Step: 10
Training loss: 3.424345056883654
Validation loss: 3.049070900491085

Epoch: 6| Step: 11
Training loss: 3.427714064665611
Validation loss: 3.048765550846433

Epoch: 6| Step: 12
Training loss: 3.6159734480566614
Validation loss: 3.050416544969813

Epoch: 6| Step: 13
Training loss: 2.8126623318766795
Validation loss: 3.0473507324920264

Epoch: 102| Step: 0
Training loss: 3.4054344670844765
Validation loss: 3.0482919162910007

Epoch: 6| Step: 1
Training loss: 2.8241122108297874
Validation loss: 3.0480144918346657

Epoch: 6| Step: 2
Training loss: 4.045660005910389
Validation loss: 3.046435019522961

Epoch: 6| Step: 3
Training loss: 3.7741567111893
Validation loss: 3.047699586632969

Epoch: 6| Step: 4
Training loss: 3.2292776437373414
Validation loss: 3.0449595995588226

Epoch: 6| Step: 5
Training loss: 3.166095749101797
Validation loss: 3.044381372457984

Epoch: 6| Step: 6
Training loss: 3.61776419011667
Validation loss: 3.0444368184735198

Epoch: 6| Step: 7
Training loss: 3.0843965570224072
Validation loss: 3.0452153408338525

Epoch: 6| Step: 8
Training loss: 2.8362349257020254
Validation loss: 3.044260265834781

Epoch: 6| Step: 9
Training loss: 2.8187494146849708
Validation loss: 3.045295382011164

Epoch: 6| Step: 10
Training loss: 3.0026559199394396
Validation loss: 3.0413594132164534

Epoch: 6| Step: 11
Training loss: 3.5493537207098416
Validation loss: 3.044514572895845

Epoch: 6| Step: 12
Training loss: 2.9912128504523756
Validation loss: 3.0432147568840606

Epoch: 6| Step: 13
Training loss: 4.110129631578413
Validation loss: 3.0435446603962637

Epoch: 103| Step: 0
Training loss: 3.4965950888794906
Validation loss: 3.0525237714837186

Epoch: 6| Step: 1
Training loss: 3.3824864466043914
Validation loss: 3.0519419131297596

Epoch: 6| Step: 2
Training loss: 3.6163257865994622
Validation loss: 3.052771676343669

Epoch: 6| Step: 3
Training loss: 3.513798896397768
Validation loss: 3.0512206482892394

Epoch: 6| Step: 4
Training loss: 3.1945373042518748
Validation loss: 3.0473491946525466

Epoch: 6| Step: 5
Training loss: 3.0433689388046044
Validation loss: 3.043625200350263

Epoch: 6| Step: 6
Training loss: 2.9631928482768553
Validation loss: 3.042211884638936

Epoch: 6| Step: 7
Training loss: 3.746982377576149
Validation loss: 3.0444270798738584

Epoch: 6| Step: 8
Training loss: 2.839940464309122
Validation loss: 3.041601180044368

Epoch: 6| Step: 9
Training loss: 3.1392874075570227
Validation loss: 3.039417713736768

Epoch: 6| Step: 10
Training loss: 3.705669060347194
Validation loss: 3.0450967105481848

Epoch: 6| Step: 11
Training loss: 2.935649207610065
Validation loss: 3.044252908199972

Epoch: 6| Step: 12
Training loss: 3.0095745523588637
Validation loss: 3.0441583672842416

Epoch: 6| Step: 13
Training loss: 3.748081225008697
Validation loss: 3.0500608840586585

Epoch: 104| Step: 0
Training loss: 3.523124325657283
Validation loss: 3.0490238022084775

Epoch: 6| Step: 1
Training loss: 3.18579265270824
Validation loss: 3.066154526185618

Epoch: 6| Step: 2
Training loss: 3.2769265892599617
Validation loss: 3.0817974048703554

Epoch: 6| Step: 3
Training loss: 3.652726652096223
Validation loss: 3.0880374906081656

Epoch: 6| Step: 4
Training loss: 3.649949081274756
Validation loss: 3.071042976319985

Epoch: 6| Step: 5
Training loss: 3.930343300188474
Validation loss: 3.055228230037166

Epoch: 6| Step: 6
Training loss: 2.7567634640557994
Validation loss: 3.0416174421205793

Epoch: 6| Step: 7
Training loss: 3.1511155469235774
Validation loss: 3.0388353638653403

Epoch: 6| Step: 8
Training loss: 2.8824624776920746
Validation loss: 3.039533433162508

Epoch: 6| Step: 9
Training loss: 3.5265747448696367
Validation loss: 3.04359516384112

Epoch: 6| Step: 10
Training loss: 3.8268036722342047
Validation loss: 3.041595241254736

Epoch: 6| Step: 11
Training loss: 3.127258552726817
Validation loss: 3.0454091254599494

Epoch: 6| Step: 12
Training loss: 2.7924612157684563
Validation loss: 3.041116357620631

Epoch: 6| Step: 13
Training loss: 2.6941677150218877
Validation loss: 3.042324213102839

Epoch: 105| Step: 0
Training loss: 3.616894176610956
Validation loss: 3.042127209998996

Epoch: 6| Step: 1
Training loss: 3.6072500339756304
Validation loss: 3.042556157835643

Epoch: 6| Step: 2
Training loss: 2.593396266118087
Validation loss: 3.0422050992938643

Epoch: 6| Step: 3
Training loss: 2.868794918331958
Validation loss: 3.0399597818982786

Epoch: 6| Step: 4
Training loss: 2.98677342090666
Validation loss: 3.039027851296418

Epoch: 6| Step: 5
Training loss: 3.8365855864025753
Validation loss: 3.0392903125169055

Epoch: 6| Step: 6
Training loss: 3.2396749665444804
Validation loss: 3.039670751801622

Epoch: 6| Step: 7
Training loss: 3.643250922282851
Validation loss: 3.0365765288848943

Epoch: 6| Step: 8
Training loss: 2.8070723826035437
Validation loss: 3.0376962417144746

Epoch: 6| Step: 9
Training loss: 3.357140085978654
Validation loss: 3.0372796381181613

Epoch: 6| Step: 10
Training loss: 3.142646404731353
Validation loss: 3.034848287302776

Epoch: 6| Step: 11
Training loss: 3.8106747619973595
Validation loss: 3.033978623554614

Epoch: 6| Step: 12
Training loss: 3.714445042598868
Validation loss: 3.038046089702899

Epoch: 6| Step: 13
Training loss: 2.3407543111001807
Validation loss: 3.037056935339081

Epoch: 106| Step: 0
Training loss: 2.91433084597222
Validation loss: 3.039122227046711

Epoch: 6| Step: 1
Training loss: 3.4409287432094153
Validation loss: 3.0387169476766926

Epoch: 6| Step: 2
Training loss: 3.732942953021803
Validation loss: 3.0368823224000203

Epoch: 6| Step: 3
Training loss: 3.2101020561465745
Validation loss: 3.0376286293611496

Epoch: 6| Step: 4
Training loss: 3.810955047254216
Validation loss: 3.0375254837385715

Epoch: 6| Step: 5
Training loss: 3.5251146879544817
Validation loss: 3.0331733411140647

Epoch: 6| Step: 6
Training loss: 3.55413103044778
Validation loss: 3.033599264537978

Epoch: 6| Step: 7
Training loss: 3.162962771847584
Validation loss: 3.0318432096277643

Epoch: 6| Step: 8
Training loss: 2.377643118320263
Validation loss: 3.032934537967287

Epoch: 6| Step: 9
Training loss: 3.1724573361870068
Validation loss: 3.0306026172119096

Epoch: 6| Step: 10
Training loss: 3.9615316754169756
Validation loss: 3.0334988079576815

Epoch: 6| Step: 11
Training loss: 3.3822714568954817
Validation loss: 3.0314627529288205

Epoch: 6| Step: 12
Training loss: 2.90672970986316
Validation loss: 3.0346571381702607

Epoch: 6| Step: 13
Training loss: 2.264969408616053
Validation loss: 3.033008334828767

Epoch: 107| Step: 0
Training loss: 3.179744785551997
Validation loss: 3.037050743712243

Epoch: 6| Step: 1
Training loss: 4.146386625599474
Validation loss: 3.0329790899932156

Epoch: 6| Step: 2
Training loss: 3.1407321892661244
Validation loss: 3.03306834253279

Epoch: 6| Step: 3
Training loss: 3.0302893305960117
Validation loss: 3.037061913955023

Epoch: 6| Step: 4
Training loss: 3.248186926193614
Validation loss: 3.0294331166327386

Epoch: 6| Step: 5
Training loss: 2.85049025351145
Validation loss: 3.032899971406005

Epoch: 6| Step: 6
Training loss: 3.547761109026191
Validation loss: 3.028980852435645

Epoch: 6| Step: 7
Training loss: 3.2046902437537774
Validation loss: 3.029701313442825

Epoch: 6| Step: 8
Training loss: 3.2734000629478417
Validation loss: 3.0303684902718597

Epoch: 6| Step: 9
Training loss: 3.534254163435371
Validation loss: 3.0264422550229395

Epoch: 6| Step: 10
Training loss: 3.0311121958447576
Validation loss: 3.030217904916318

Epoch: 6| Step: 11
Training loss: 3.186705546387975
Validation loss: 3.027212729263495

Epoch: 6| Step: 12
Training loss: 3.7067458080057847
Validation loss: 3.0262132999490055

Epoch: 6| Step: 13
Training loss: 2.714717285723552
Validation loss: 3.0282095420982533

Epoch: 108| Step: 0
Training loss: 3.601452740964117
Validation loss: 3.0264511900163167

Epoch: 6| Step: 1
Training loss: 3.528036630366805
Validation loss: 3.027551568103253

Epoch: 6| Step: 2
Training loss: 2.76442757239343
Validation loss: 3.0294533434974844

Epoch: 6| Step: 3
Training loss: 3.2933860505346844
Validation loss: 3.0314549997451867

Epoch: 6| Step: 4
Training loss: 3.5668073347166205
Validation loss: 3.02900324139695

Epoch: 6| Step: 5
Training loss: 3.0737896902183115
Validation loss: 3.029685826810324

Epoch: 6| Step: 6
Training loss: 2.9557860964139313
Validation loss: 3.026976915589003

Epoch: 6| Step: 7
Training loss: 2.947633188229756
Validation loss: 3.0296469300685076

Epoch: 6| Step: 8
Training loss: 3.952479373846699
Validation loss: 3.0280517791761596

Epoch: 6| Step: 9
Training loss: 3.398113226492171
Validation loss: 3.0279283167836986

Epoch: 6| Step: 10
Training loss: 2.8923661220629757
Validation loss: 3.027783765621034

Epoch: 6| Step: 11
Training loss: 3.2809219923015345
Validation loss: 3.0301898455154266

Epoch: 6| Step: 12
Training loss: 3.552726590408596
Validation loss: 3.0274751376546343

Epoch: 6| Step: 13
Training loss: 3.124127685868076
Validation loss: 3.0294978790200227

Epoch: 109| Step: 0
Training loss: 3.16130371385994
Validation loss: 3.030105383170849

Epoch: 6| Step: 1
Training loss: 3.3196365925087705
Validation loss: 3.033770328007459

Epoch: 6| Step: 2
Training loss: 3.548574166666523
Validation loss: 3.0337841037288342

Epoch: 6| Step: 3
Training loss: 2.9982825767485926
Validation loss: 3.031958428412417

Epoch: 6| Step: 4
Training loss: 2.3630504148628724
Validation loss: 3.035680331202881

Epoch: 6| Step: 5
Training loss: 3.02150126121453
Validation loss: 3.035866035917911

Epoch: 6| Step: 6
Training loss: 3.086214077301284
Validation loss: 3.038402615323615

Epoch: 6| Step: 7
Training loss: 3.3825336720213737
Validation loss: 3.0357671499195025

Epoch: 6| Step: 8
Training loss: 3.627722671373255
Validation loss: 3.029009299667561

Epoch: 6| Step: 9
Training loss: 2.405106309852921
Validation loss: 3.0278939318334097

Epoch: 6| Step: 10
Training loss: 3.726360323557872
Validation loss: 3.025374204521057

Epoch: 6| Step: 11
Training loss: 3.532997441670679
Validation loss: 3.0276751110574045

Epoch: 6| Step: 12
Training loss: 3.906693456273669
Validation loss: 3.02664001647812

Epoch: 6| Step: 13
Training loss: 3.9434926283051515
Validation loss: 3.0224494037026752

Epoch: 110| Step: 0
Training loss: 3.0808480702808634
Validation loss: 3.023982591251152

Epoch: 6| Step: 1
Training loss: 3.3293580828953537
Validation loss: 3.025630037967611

Epoch: 6| Step: 2
Training loss: 2.706338020285253
Validation loss: 3.025430590334499

Epoch: 6| Step: 3
Training loss: 2.7616058283358673
Validation loss: 3.023251288792345

Epoch: 6| Step: 4
Training loss: 3.850067157902746
Validation loss: 3.0259810352963465

Epoch: 6| Step: 5
Training loss: 3.1041902033449045
Validation loss: 3.0251785551734915

Epoch: 6| Step: 6
Training loss: 3.5361849979320383
Validation loss: 3.0280266316094897

Epoch: 6| Step: 7
Training loss: 3.6834130349030043
Validation loss: 3.0262337389407774

Epoch: 6| Step: 8
Training loss: 3.4317972215888544
Validation loss: 3.029521576647298

Epoch: 6| Step: 9
Training loss: 3.3836465912918183
Validation loss: 3.0400195098686997

Epoch: 6| Step: 10
Training loss: 2.5119418079293436
Validation loss: 3.042047929882668

Epoch: 6| Step: 11
Training loss: 3.6924076074445193
Validation loss: 3.046785573012475

Epoch: 6| Step: 12
Training loss: 3.9473919817572716
Validation loss: 3.0306188283368716

Epoch: 6| Step: 13
Training loss: 2.2843532618624662
Validation loss: 3.0212526725545326

Epoch: 111| Step: 0
Training loss: 2.950072795163729
Validation loss: 3.023318339105103

Epoch: 6| Step: 1
Training loss: 3.912470267185908
Validation loss: 3.022033991411992

Epoch: 6| Step: 2
Training loss: 3.3076563996974464
Validation loss: 3.021941492982422

Epoch: 6| Step: 3
Training loss: 3.4754731603998423
Validation loss: 3.0258993250488304

Epoch: 6| Step: 4
Training loss: 2.8359728093747116
Validation loss: 3.0276165604103737

Epoch: 6| Step: 5
Training loss: 3.8913518387567585
Validation loss: 3.027578966077891

Epoch: 6| Step: 6
Training loss: 3.31634701158077
Validation loss: 3.0266033061794517

Epoch: 6| Step: 7
Training loss: 2.1532979466667266
Validation loss: 3.0297905373108023

Epoch: 6| Step: 8
Training loss: 3.228038385638069
Validation loss: 3.0283620795577675

Epoch: 6| Step: 9
Training loss: 2.8855886763843084
Validation loss: 3.026943932951276

Epoch: 6| Step: 10
Training loss: 3.3371897006713
Validation loss: 3.0239729970269065

Epoch: 6| Step: 11
Training loss: 3.2080968464147963
Validation loss: 3.0236685975285633

Epoch: 6| Step: 12
Training loss: 3.7286722860700348
Validation loss: 3.022531082532401

Epoch: 6| Step: 13
Training loss: 3.7291977239981327
Validation loss: 3.0252324023764015

Epoch: 112| Step: 0
Training loss: 3.0927298048607517
Validation loss: 3.0245611632679292

Epoch: 6| Step: 1
Training loss: 3.6578850635890316
Validation loss: 3.027674775750045

Epoch: 6| Step: 2
Training loss: 2.905669615844663
Validation loss: 3.021084091816982

Epoch: 6| Step: 3
Training loss: 2.9831802613042924
Validation loss: 3.0267833450098127

Epoch: 6| Step: 4
Training loss: 3.740501454033204
Validation loss: 3.0251694893057706

Epoch: 6| Step: 5
Training loss: 3.814686507797331
Validation loss: 3.024430727227447

Epoch: 6| Step: 6
Training loss: 3.732620146159743
Validation loss: 3.022375818091336

Epoch: 6| Step: 7
Training loss: 3.003840848808522
Validation loss: 3.0218595513422106

Epoch: 6| Step: 8
Training loss: 3.009019327189735
Validation loss: 3.0217080659911937

Epoch: 6| Step: 9
Training loss: 2.784418251737758
Validation loss: 3.023536040553583

Epoch: 6| Step: 10
Training loss: 2.6904878198120743
Validation loss: 3.0226063080899204

Epoch: 6| Step: 11
Training loss: 3.795062978872793
Validation loss: 3.029104227918624

Epoch: 6| Step: 12
Training loss: 3.3142738630994306
Validation loss: 3.0302682514562758

Epoch: 6| Step: 13
Training loss: 3.2138605109035026
Validation loss: 3.0288070850080544

Epoch: 113| Step: 0
Training loss: 3.4107250250545267
Validation loss: 3.0339028468058316

Epoch: 6| Step: 1
Training loss: 3.204886942757409
Validation loss: 3.038646826157116

Epoch: 6| Step: 2
Training loss: 3.8840788037038263
Validation loss: 3.043016693480194

Epoch: 6| Step: 3
Training loss: 3.2604758812805392
Validation loss: 3.0267295016830285

Epoch: 6| Step: 4
Training loss: 3.107415890403178
Validation loss: 3.0156476997967614

Epoch: 6| Step: 5
Training loss: 2.838595739193739
Validation loss: 3.02010100118983

Epoch: 6| Step: 6
Training loss: 2.845461152418334
Validation loss: 3.0179532271506733

Epoch: 6| Step: 7
Training loss: 3.664729531418676
Validation loss: 3.0204430372913

Epoch: 6| Step: 8
Training loss: 3.1441542500131856
Validation loss: 3.0210133132246653

Epoch: 6| Step: 9
Training loss: 3.417253691944012
Validation loss: 3.020604540711251

Epoch: 6| Step: 10
Training loss: 3.4390373260256077
Validation loss: 3.0226877926980498

Epoch: 6| Step: 11
Training loss: 3.024087525508889
Validation loss: 3.0202816949969775

Epoch: 6| Step: 12
Training loss: 3.6406371808155265
Validation loss: 3.0200345916548934

Epoch: 6| Step: 13
Training loss: 3.006114292055752
Validation loss: 3.0199508656665888

Epoch: 114| Step: 0
Training loss: 4.148128979376246
Validation loss: 3.0158351395879297

Epoch: 6| Step: 1
Training loss: 3.1991644960677452
Validation loss: 3.014435185867654

Epoch: 6| Step: 2
Training loss: 2.777941933125957
Validation loss: 3.015506604978923

Epoch: 6| Step: 3
Training loss: 2.3395050262181947
Validation loss: 3.017340684928891

Epoch: 6| Step: 4
Training loss: 3.7412832039565025
Validation loss: 3.017572871261129

Epoch: 6| Step: 5
Training loss: 3.194423561212216
Validation loss: 3.0183152687975086

Epoch: 6| Step: 6
Training loss: 3.663334300347971
Validation loss: 3.018697683154931

Epoch: 6| Step: 7
Training loss: 2.779832714591304
Validation loss: 3.0196709427241126

Epoch: 6| Step: 8
Training loss: 2.195466168547151
Validation loss: 3.0208556217195968

Epoch: 6| Step: 9
Training loss: 3.5292058108582314
Validation loss: 3.02062697732989

Epoch: 6| Step: 10
Training loss: 3.0370170554698643
Validation loss: 3.0245297897623167

Epoch: 6| Step: 11
Training loss: 4.174090193793475
Validation loss: 3.0242950316325152

Epoch: 6| Step: 12
Training loss: 3.367802043869184
Validation loss: 3.0189967568628497

Epoch: 6| Step: 13
Training loss: 3.2659868103807543
Validation loss: 3.011583377155784

Epoch: 115| Step: 0
Training loss: 3.276385961896656
Validation loss: 3.0150792591202547

Epoch: 6| Step: 1
Training loss: 3.630779000757792
Validation loss: 3.0173010117745096

Epoch: 6| Step: 2
Training loss: 3.0136272553202046
Validation loss: 3.0141638862571885

Epoch: 6| Step: 3
Training loss: 2.6035723096968266
Validation loss: 3.0137000745827627

Epoch: 6| Step: 4
Training loss: 2.1835070543360855
Validation loss: 3.0162725597614783

Epoch: 6| Step: 5
Training loss: 3.6997528818447796
Validation loss: 3.016351925802947

Epoch: 6| Step: 6
Training loss: 3.183885656910709
Validation loss: 3.0160460541851806

Epoch: 6| Step: 7
Training loss: 3.202658865901945
Validation loss: 3.0192176483965376

Epoch: 6| Step: 8
Training loss: 3.757461119023605
Validation loss: 3.0222200214465236

Epoch: 6| Step: 9
Training loss: 3.143829381103598
Validation loss: 3.0212891390030525

Epoch: 6| Step: 10
Training loss: 3.389245943809176
Validation loss: 3.0219882447619937

Epoch: 6| Step: 11
Training loss: 3.76354517819962
Validation loss: 3.026806174562251

Epoch: 6| Step: 12
Training loss: 3.7338055930709815
Validation loss: 3.0245554978542937

Epoch: 6| Step: 13
Training loss: 2.8543146099721026
Validation loss: 3.0189633656263974

Epoch: 116| Step: 0
Training loss: 2.751028388811159
Validation loss: 3.016998483206126

Epoch: 6| Step: 1
Training loss: 3.457316206917478
Validation loss: 3.011916032915975

Epoch: 6| Step: 2
Training loss: 2.452402287829988
Validation loss: 3.011731160788176

Epoch: 6| Step: 3
Training loss: 3.138392931560848
Validation loss: 3.011718693819361

Epoch: 6| Step: 4
Training loss: 3.7343221365407144
Validation loss: 3.013861018969811

Epoch: 6| Step: 5
Training loss: 3.2151199166580415
Validation loss: 3.0122328662137927

Epoch: 6| Step: 6
Training loss: 3.0616143950802486
Validation loss: 3.0124806724789206

Epoch: 6| Step: 7
Training loss: 2.899491850958442
Validation loss: 3.01098352043062

Epoch: 6| Step: 8
Training loss: 3.3669283384350828
Validation loss: 3.011900448025504

Epoch: 6| Step: 9
Training loss: 3.151498522886898
Validation loss: 3.010370879164466

Epoch: 6| Step: 10
Training loss: 3.0534014323884784
Validation loss: 3.011915844808275

Epoch: 6| Step: 11
Training loss: 4.045882055353933
Validation loss: 3.014610996946152

Epoch: 6| Step: 12
Training loss: 4.194823280949799
Validation loss: 3.018351898137172

Epoch: 6| Step: 13
Training loss: 2.7876340483179116
Validation loss: 3.016047145585617

Epoch: 117| Step: 0
Training loss: 2.8344911191932063
Validation loss: 3.0218214077514443

Epoch: 6| Step: 1
Training loss: 2.5833146084342693
Validation loss: 3.01866947930275

Epoch: 6| Step: 2
Training loss: 2.8747223429740716
Validation loss: 3.0225711976344716

Epoch: 6| Step: 3
Training loss: 3.8523478297357223
Validation loss: 3.014774429325402

Epoch: 6| Step: 4
Training loss: 2.6771975145345244
Validation loss: 3.0099614261821994

Epoch: 6| Step: 5
Training loss: 2.994339530096175
Validation loss: 3.00974492511279

Epoch: 6| Step: 6
Training loss: 4.037700607937743
Validation loss: 3.0082832597683993

Epoch: 6| Step: 7
Training loss: 3.0080796160306984
Validation loss: 3.011605012703661

Epoch: 6| Step: 8
Training loss: 3.989020776885331
Validation loss: 3.0121080251710572

Epoch: 6| Step: 9
Training loss: 3.3987391546258037
Validation loss: 3.0103279086775694

Epoch: 6| Step: 10
Training loss: 3.351984170917291
Validation loss: 3.0087698486968004

Epoch: 6| Step: 11
Training loss: 3.626350808857826
Validation loss: 3.009338501492622

Epoch: 6| Step: 12
Training loss: 3.1400194485784914
Validation loss: 3.0099802261118387

Epoch: 6| Step: 13
Training loss: 2.953824722307047
Validation loss: 3.0092007860957497

Epoch: 118| Step: 0
Training loss: 3.03412185383006
Validation loss: 3.010447088145278

Epoch: 6| Step: 1
Training loss: 2.990931314468564
Validation loss: 3.008825451658529

Epoch: 6| Step: 2
Training loss: 3.00935241120319
Validation loss: 3.0102905004012417

Epoch: 6| Step: 3
Training loss: 3.6158988090636184
Validation loss: 3.0105390966992256

Epoch: 6| Step: 4
Training loss: 2.9583484129901945
Validation loss: 3.0094005094440814

Epoch: 6| Step: 5
Training loss: 3.7584715203864008
Validation loss: 3.0085670866004834

Epoch: 6| Step: 6
Training loss: 3.4295946252017733
Validation loss: 3.0098946115102096

Epoch: 6| Step: 7
Training loss: 3.477104230528049
Validation loss: 3.008503216607111

Epoch: 6| Step: 8
Training loss: 3.1420973936996512
Validation loss: 3.0089228621487294

Epoch: 6| Step: 9
Training loss: 3.352662232845174
Validation loss: 3.0136158136158784

Epoch: 6| Step: 10
Training loss: 2.884685290541044
Validation loss: 3.0183171034176848

Epoch: 6| Step: 11
Training loss: 2.9541443372419685
Validation loss: 3.017586693740118

Epoch: 6| Step: 12
Training loss: 3.601232285990607
Validation loss: 3.0163544406983123

Epoch: 6| Step: 13
Training loss: 3.821087530423915
Validation loss: 3.0132519872999897

Epoch: 119| Step: 0
Training loss: 3.1832150848422396
Validation loss: 3.0093012052953116

Epoch: 6| Step: 1
Training loss: 3.8941253481196103
Validation loss: 3.0061608294701756

Epoch: 6| Step: 2
Training loss: 3.012751816477824
Validation loss: 3.0037743964213393

Epoch: 6| Step: 3
Training loss: 2.7286694974116483
Validation loss: 3.0036440255766386

Epoch: 6| Step: 4
Training loss: 3.4430818494584634
Validation loss: 3.0052152818310964

Epoch: 6| Step: 5
Training loss: 3.6257532586774377
Validation loss: 3.005138670598968

Epoch: 6| Step: 6
Training loss: 3.0673913624622164
Validation loss: 3.0056593284939

Epoch: 6| Step: 7
Training loss: 2.3644227857043894
Validation loss: 3.005911533343721

Epoch: 6| Step: 8
Training loss: 3.330583550812144
Validation loss: 3.005436947425967

Epoch: 6| Step: 9
Training loss: 2.9296577146923406
Validation loss: 3.0056257037895016

Epoch: 6| Step: 10
Training loss: 3.5211555890259816
Validation loss: 3.006298560474593

Epoch: 6| Step: 11
Training loss: 3.7561127750256564
Validation loss: 3.0032595936639037

Epoch: 6| Step: 12
Training loss: 3.045399156788798
Validation loss: 3.004886006722882

Epoch: 6| Step: 13
Training loss: 3.8403629173205696
Validation loss: 3.0015811564685464

Epoch: 120| Step: 0
Training loss: 2.845816563509843
Validation loss: 3.0029041135592545

Epoch: 6| Step: 1
Training loss: 3.960614614474583
Validation loss: 3.000843180840164

Epoch: 6| Step: 2
Training loss: 3.391359030028617
Validation loss: 3.0016427208373138

Epoch: 6| Step: 3
Training loss: 3.427854008774112
Validation loss: 3.004265437876864

Epoch: 6| Step: 4
Training loss: 3.3612337869442532
Validation loss: 3.0066419109466485

Epoch: 6| Step: 5
Training loss: 3.0412348262159035
Validation loss: 3.004296080930091

Epoch: 6| Step: 6
Training loss: 3.0614580211312594
Validation loss: 3.0111931632085596

Epoch: 6| Step: 7
Training loss: 2.6786007470842446
Validation loss: 3.001835461536543

Epoch: 6| Step: 8
Training loss: 3.796257439770284
Validation loss: 3.003588012597857

Epoch: 6| Step: 9
Training loss: 2.9796040531789965
Validation loss: 3.0036138606697693

Epoch: 6| Step: 10
Training loss: 3.321109020958113
Validation loss: 3.002164318059289

Epoch: 6| Step: 11
Training loss: 3.4449933308618492
Validation loss: 3.0065126245810907

Epoch: 6| Step: 12
Training loss: 3.432481188406522
Validation loss: 3.0015982110235

Epoch: 6| Step: 13
Training loss: 2.414785826132431
Validation loss: 2.9961508152013288

Epoch: 121| Step: 0
Training loss: 2.6527840834493297
Validation loss: 3.0030318188851117

Epoch: 6| Step: 1
Training loss: 2.60850629222916
Validation loss: 2.99999924287137

Epoch: 6| Step: 2
Training loss: 3.482248795124004
Validation loss: 2.9998704615692686

Epoch: 6| Step: 3
Training loss: 3.5048243107753425
Validation loss: 3.003058557860701

Epoch: 6| Step: 4
Training loss: 2.6392871243885874
Validation loss: 3.0028984670469243

Epoch: 6| Step: 5
Training loss: 2.831183028955356
Validation loss: 3.0031418533401197

Epoch: 6| Step: 6
Training loss: 2.897596211452946
Validation loss: 3.0075431167198254

Epoch: 6| Step: 7
Training loss: 2.4034633601653317
Validation loss: 3.003244896009207

Epoch: 6| Step: 8
Training loss: 3.8653493500774974
Validation loss: 3.008732058920388

Epoch: 6| Step: 9
Training loss: 3.269373736125138
Validation loss: 3.017150110700783

Epoch: 6| Step: 10
Training loss: 3.85497177925121
Validation loss: 3.0150863061750517

Epoch: 6| Step: 11
Training loss: 3.6895337719481174
Validation loss: 3.0070149943755644

Epoch: 6| Step: 12
Training loss: 3.9232267808557073
Validation loss: 2.9957448732670393

Epoch: 6| Step: 13
Training loss: 3.8709284403559368
Validation loss: 2.998077968970474

Epoch: 122| Step: 0
Training loss: 3.045538193318693
Validation loss: 2.9984841054671074

Epoch: 6| Step: 1
Training loss: 2.8919237672986298
Validation loss: 2.995376591141154

Epoch: 6| Step: 2
Training loss: 3.260516976630396
Validation loss: 2.9976587696676273

Epoch: 6| Step: 3
Training loss: 3.471373244870133
Validation loss: 2.998566226775644

Epoch: 6| Step: 4
Training loss: 3.186561595934951
Validation loss: 2.998523276924425

Epoch: 6| Step: 5
Training loss: 3.2693406280770163
Validation loss: 2.9978226481932904

Epoch: 6| Step: 6
Training loss: 2.9807794291508762
Validation loss: 2.9968436738350603

Epoch: 6| Step: 7
Training loss: 3.9076929707876067
Validation loss: 2.9968574636073884

Epoch: 6| Step: 8
Training loss: 3.0907504250096394
Validation loss: 2.996833035478509

Epoch: 6| Step: 9
Training loss: 3.280678835612612
Validation loss: 2.9981543801158375

Epoch: 6| Step: 10
Training loss: 3.032065999422426
Validation loss: 2.995801060274103

Epoch: 6| Step: 11
Training loss: 3.8527632073974374
Validation loss: 2.9971562480973564

Epoch: 6| Step: 12
Training loss: 3.444579723395177
Validation loss: 2.9950514608573378

Epoch: 6| Step: 13
Training loss: 2.595022050473531
Validation loss: 2.9959689030332908

Epoch: 123| Step: 0
Training loss: 2.6125508244147415
Validation loss: 2.99895745111171

Epoch: 6| Step: 1
Training loss: 3.0276795428688685
Validation loss: 2.994835712096482

Epoch: 6| Step: 2
Training loss: 4.0604775896716365
Validation loss: 2.9963194439128085

Epoch: 6| Step: 3
Training loss: 3.429729904573063
Validation loss: 2.9972129167190955

Epoch: 6| Step: 4
Training loss: 3.2542904630420866
Validation loss: 2.998633128860685

Epoch: 6| Step: 5
Training loss: 3.9244280404462906
Validation loss: 2.9941656025217824

Epoch: 6| Step: 6
Training loss: 2.8589307095916285
Validation loss: 2.995436080076319

Epoch: 6| Step: 7
Training loss: 2.846700290716607
Validation loss: 2.9961496361226683

Epoch: 6| Step: 8
Training loss: 3.493109323244926
Validation loss: 2.9984079925696525

Epoch: 6| Step: 9
Training loss: 3.144587204713731
Validation loss: 2.993462992969528

Epoch: 6| Step: 10
Training loss: 3.3913320340373474
Validation loss: 2.9983090810486863

Epoch: 6| Step: 11
Training loss: 3.0181235601311536
Validation loss: 3.0020576362944422

Epoch: 6| Step: 12
Training loss: 3.160507201522253
Validation loss: 3.0007560095287893

Epoch: 6| Step: 13
Training loss: 3.164455662542573
Validation loss: 2.9970616645733528

Epoch: 124| Step: 0
Training loss: 3.775170727841726
Validation loss: 2.995597120832464

Epoch: 6| Step: 1
Training loss: 4.0743957071470085
Validation loss: 2.999616355703

Epoch: 6| Step: 2
Training loss: 4.008016183298907
Validation loss: 2.99603241045618

Epoch: 6| Step: 3
Training loss: 3.2279874227626215
Validation loss: 2.997591335261866

Epoch: 6| Step: 4
Training loss: 2.3273023137466073
Validation loss: 2.9938715237676226

Epoch: 6| Step: 5
Training loss: 3.1198428515447634
Validation loss: 2.9922912840118046

Epoch: 6| Step: 6
Training loss: 2.8638337605355866
Validation loss: 2.99317258122231

Epoch: 6| Step: 7
Training loss: 3.3787545407145108
Validation loss: 2.991635509224402

Epoch: 6| Step: 8
Training loss: 3.1361312981192238
Validation loss: 2.992652726026829

Epoch: 6| Step: 9
Training loss: 2.6647168919125703
Validation loss: 2.990104629557691

Epoch: 6| Step: 10
Training loss: 2.9801877990534344
Validation loss: 2.994457595118972

Epoch: 6| Step: 11
Training loss: 2.7968178855136427
Validation loss: 2.9885964748729195

Epoch: 6| Step: 12
Training loss: 3.8725175596840145
Validation loss: 2.9897449820299418

Epoch: 6| Step: 13
Training loss: 2.6404158831075457
Validation loss: 2.9928822920531757

Epoch: 125| Step: 0
Training loss: 2.7625738004604914
Validation loss: 2.9918795923898247

Epoch: 6| Step: 1
Training loss: 2.7686590588792193
Validation loss: 2.9903733444958185

Epoch: 6| Step: 2
Training loss: 3.4152302087180066
Validation loss: 2.989958213777285

Epoch: 6| Step: 3
Training loss: 3.14170431692969
Validation loss: 2.9898041542882314

Epoch: 6| Step: 4
Training loss: 3.664305331189073
Validation loss: 2.9877702748392894

Epoch: 6| Step: 5
Training loss: 3.2788286266723268
Validation loss: 2.9905019175485528

Epoch: 6| Step: 6
Training loss: 3.2142518844035233
Validation loss: 2.990520300596728

Epoch: 6| Step: 7
Training loss: 2.9073895917086987
Validation loss: 2.9923210558690356

Epoch: 6| Step: 8
Training loss: 3.0543312586990643
Validation loss: 2.9985595769245266

Epoch: 6| Step: 9
Training loss: 4.1681680390353435
Validation loss: 2.998154792260959

Epoch: 6| Step: 10
Training loss: 3.5388240102280037
Validation loss: 2.9990111331216665

Epoch: 6| Step: 11
Training loss: 2.9233959135913388
Validation loss: 2.9923262794072256

Epoch: 6| Step: 12
Training loss: 3.324589243592483
Validation loss: 2.989924004363004

Epoch: 6| Step: 13
Training loss: 3.2239357367706107
Validation loss: 2.986255888224615

Epoch: 126| Step: 0
Training loss: 3.7334371370689117
Validation loss: 2.9878385074957574

Epoch: 6| Step: 1
Training loss: 3.3966559289444946
Validation loss: 2.990071915382331

Epoch: 6| Step: 2
Training loss: 3.674751226607539
Validation loss: 2.9886598627477907

Epoch: 6| Step: 3
Training loss: 2.763295890115745
Validation loss: 2.9880415042063095

Epoch: 6| Step: 4
Training loss: 3.628090691876575
Validation loss: 2.989447182228417

Epoch: 6| Step: 5
Training loss: 2.8776156924377965
Validation loss: 2.9891551358789057

Epoch: 6| Step: 6
Training loss: 2.9493972421152215
Validation loss: 2.986304033105877

Epoch: 6| Step: 7
Training loss: 2.7646290338145905
Validation loss: 2.9847621691280213

Epoch: 6| Step: 8
Training loss: 3.7252765732056727
Validation loss: 2.986575496921161

Epoch: 6| Step: 9
Training loss: 3.9870979130272692
Validation loss: 2.9876454541764677

Epoch: 6| Step: 10
Training loss: 3.0001443192418757
Validation loss: 2.9829820456247327

Epoch: 6| Step: 11
Training loss: 2.9499944007949708
Validation loss: 2.984976235200963

Epoch: 6| Step: 12
Training loss: 2.39341782140057
Validation loss: 2.986412012447683

Epoch: 6| Step: 13
Training loss: 3.561866570091413
Validation loss: 2.9843379244256747

Epoch: 127| Step: 0
Training loss: 2.8294812738689057
Validation loss: 2.9856068395138697

Epoch: 6| Step: 1
Training loss: 2.4669663951674035
Validation loss: 2.9848508356172943

Epoch: 6| Step: 2
Training loss: 3.248822952748904
Validation loss: 2.9843169519540638

Epoch: 6| Step: 3
Training loss: 3.4891636534402166
Validation loss: 2.9867199880277413

Epoch: 6| Step: 4
Training loss: 3.2499953049845893
Validation loss: 2.9907986051464364

Epoch: 6| Step: 5
Training loss: 3.760999188870112
Validation loss: 2.990629843869957

Epoch: 6| Step: 6
Training loss: 3.3874902253520185
Validation loss: 2.985955394841651

Epoch: 6| Step: 7
Training loss: 2.890218180304169
Validation loss: 2.9886730503723395

Epoch: 6| Step: 8
Training loss: 2.9924176080335347
Validation loss: 2.9825520973382025

Epoch: 6| Step: 9
Training loss: 3.2177261650074627
Validation loss: 2.984391625445079

Epoch: 6| Step: 10
Training loss: 3.512390276189494
Validation loss: 2.9899991139974342

Epoch: 6| Step: 11
Training loss: 3.996534515266178
Validation loss: 2.9989482273312973

Epoch: 6| Step: 12
Training loss: 2.872612334894306
Validation loss: 2.983300291552018

Epoch: 6| Step: 13
Training loss: 3.5495975481174025
Validation loss: 2.984978514582476

Epoch: 128| Step: 0
Training loss: 2.5355673810746437
Validation loss: 2.9855320736251434

Epoch: 6| Step: 1
Training loss: 3.195247136499095
Validation loss: 2.9810586542650253

Epoch: 6| Step: 2
Training loss: 3.3910600936816144
Validation loss: 2.9833583164137187

Epoch: 6| Step: 3
Training loss: 3.625181522428448
Validation loss: 2.981626181347712

Epoch: 6| Step: 4
Training loss: 3.2359963006940333
Validation loss: 2.981415504269018

Epoch: 6| Step: 5
Training loss: 3.4274701921431476
Validation loss: 2.9791054375504396

Epoch: 6| Step: 6
Training loss: 2.8156577291502227
Validation loss: 2.980119556394294

Epoch: 6| Step: 7
Training loss: 2.558248482041555
Validation loss: 2.9815440233741533

Epoch: 6| Step: 8
Training loss: 3.6342189240337706
Validation loss: 2.9805857560519375

Epoch: 6| Step: 9
Training loss: 3.5457896449934774
Validation loss: 2.978744608312584

Epoch: 6| Step: 10
Training loss: 3.654874363525945
Validation loss: 2.980951411536147

Epoch: 6| Step: 11
Training loss: 3.432026059298516
Validation loss: 2.977899896626909

Epoch: 6| Step: 12
Training loss: 3.413677132721735
Validation loss: 2.9811336750982242

Epoch: 6| Step: 13
Training loss: 2.5784605790417117
Validation loss: 2.97930848030582

Epoch: 129| Step: 0
Training loss: 2.837543127597634
Validation loss: 2.979601784312795

Epoch: 6| Step: 1
Training loss: 2.888221525070551
Validation loss: 2.979672832474315

Epoch: 6| Step: 2
Training loss: 3.5694925046885633
Validation loss: 2.9836698099569343

Epoch: 6| Step: 3
Training loss: 3.438468380555091
Validation loss: 2.982181577347701

Epoch: 6| Step: 4
Training loss: 3.065832232549134
Validation loss: 2.9843465748615294

Epoch: 6| Step: 5
Training loss: 3.1964433156713876
Validation loss: 2.9805151924040767

Epoch: 6| Step: 6
Training loss: 2.9806901642036645
Validation loss: 2.980465897751871

Epoch: 6| Step: 7
Training loss: 2.977053303941956
Validation loss: 2.979774375826169

Epoch: 6| Step: 8
Training loss: 3.294691474606051
Validation loss: 2.978815257794754

Epoch: 6| Step: 9
Training loss: 3.865309133862049
Validation loss: 2.978785214972073

Epoch: 6| Step: 10
Training loss: 3.651344856302066
Validation loss: 2.9785282843078855

Epoch: 6| Step: 11
Training loss: 3.1581611512555536
Validation loss: 2.978695874770803

Epoch: 6| Step: 12
Training loss: 3.3931279239301158
Validation loss: 2.9754409630065606

Epoch: 6| Step: 13
Training loss: 3.012697528362232
Validation loss: 2.9793234483486155

Epoch: 130| Step: 0
Training loss: 3.2407833873627148
Validation loss: 2.9761840073241266

Epoch: 6| Step: 1
Training loss: 3.6275897805101422
Validation loss: 2.9767819053164044

Epoch: 6| Step: 2
Training loss: 2.657002241542159
Validation loss: 2.9789617625605733

Epoch: 6| Step: 3
Training loss: 3.1182270658957574
Validation loss: 2.977617585758765

Epoch: 6| Step: 4
Training loss: 3.0460470003746183
Validation loss: 2.9748652928788224

Epoch: 6| Step: 5
Training loss: 3.008464633545481
Validation loss: 2.973658174359839

Epoch: 6| Step: 6
Training loss: 3.077469964210087
Validation loss: 2.9778332424273577

Epoch: 6| Step: 7
Training loss: 3.6159170074053635
Validation loss: 2.975645551564907

Epoch: 6| Step: 8
Training loss: 3.2794123272001023
Validation loss: 2.9768070715503994

Epoch: 6| Step: 9
Training loss: 3.5699399924911615
Validation loss: 2.978372411325955

Epoch: 6| Step: 10
Training loss: 3.4828353696254526
Validation loss: 2.979253240305984

Epoch: 6| Step: 11
Training loss: 3.0799516399104405
Validation loss: 2.977060096556061

Epoch: 6| Step: 12
Training loss: 3.6529575750068335
Validation loss: 2.979134031450191

Epoch: 6| Step: 13
Training loss: 2.548944767296321
Validation loss: 2.980835034766654

Epoch: 131| Step: 0
Training loss: 2.64338179023972
Validation loss: 2.9816419924050965

Epoch: 6| Step: 1
Training loss: 3.2046656927280943
Validation loss: 2.9973440223096794

Epoch: 6| Step: 2
Training loss: 3.257781030882558
Validation loss: 3.0041813457938744

Epoch: 6| Step: 3
Training loss: 2.654545854423559
Validation loss: 2.976577897845244

Epoch: 6| Step: 4
Training loss: 3.4505028068023615
Validation loss: 2.9771952567096904

Epoch: 6| Step: 5
Training loss: 3.6282439351199054
Validation loss: 2.975840947816931

Epoch: 6| Step: 6
Training loss: 3.518285533002664
Validation loss: 2.973143180510429

Epoch: 6| Step: 7
Training loss: 3.510420409671286
Validation loss: 2.9740024321509644

Epoch: 6| Step: 8
Training loss: 3.0061699680136043
Validation loss: 2.971949968304352

Epoch: 6| Step: 9
Training loss: 3.05092004125715
Validation loss: 2.971868998096608

Epoch: 6| Step: 10
Training loss: 2.7053240171973676
Validation loss: 2.9710010459191376

Epoch: 6| Step: 11
Training loss: 3.8258959450179106
Validation loss: 2.9739092156204654

Epoch: 6| Step: 12
Training loss: 3.46059552089708
Validation loss: 2.9717077765786937

Epoch: 6| Step: 13
Training loss: 3.420456823211713
Validation loss: 2.9728019570521425

Epoch: 132| Step: 0
Training loss: 3.0778384002639982
Validation loss: 2.9739843706850615

Epoch: 6| Step: 1
Training loss: 2.710051202044012
Validation loss: 2.972155292270964

Epoch: 6| Step: 2
Training loss: 3.1181353129546863
Validation loss: 2.9709286668694825

Epoch: 6| Step: 3
Training loss: 2.852338962138203
Validation loss: 2.972729728786355

Epoch: 6| Step: 4
Training loss: 3.385718385993999
Validation loss: 2.9715511092861027

Epoch: 6| Step: 5
Training loss: 2.989466612837892
Validation loss: 2.973548719722192

Epoch: 6| Step: 6
Training loss: 2.7751145141617894
Validation loss: 2.9698030427335667

Epoch: 6| Step: 7
Training loss: 3.9403044386460633
Validation loss: 2.971148952428524

Epoch: 6| Step: 8
Training loss: 3.4239208776833236
Validation loss: 2.9713723000571517

Epoch: 6| Step: 9
Training loss: 4.20912213376648
Validation loss: 2.974943017211368

Epoch: 6| Step: 10
Training loss: 2.947797703224104
Validation loss: 2.9709437522036763

Epoch: 6| Step: 11
Training loss: 3.30544523024751
Validation loss: 2.9752444289484212

Epoch: 6| Step: 12
Training loss: 2.9706312142019606
Validation loss: 2.975864211251483

Epoch: 6| Step: 13
Training loss: 3.62298567481161
Validation loss: 2.9716832288434976

Epoch: 133| Step: 0
Training loss: 3.9005099427793675
Validation loss: 2.972438365143728

Epoch: 6| Step: 1
Training loss: 3.7738640901466547
Validation loss: 2.9697814375865947

Epoch: 6| Step: 2
Training loss: 3.2957715542706314
Validation loss: 2.9699765964217253

Epoch: 6| Step: 3
Training loss: 3.504377760786558
Validation loss: 2.9673914427640025

Epoch: 6| Step: 4
Training loss: 2.814531567424811
Validation loss: 2.970176073610631

Epoch: 6| Step: 5
Training loss: 2.5073030613913825
Validation loss: 2.966793891224589

Epoch: 6| Step: 6
Training loss: 2.625427029707333
Validation loss: 2.967855097328412

Epoch: 6| Step: 7
Training loss: 2.8387044224173046
Validation loss: 2.9704341910300815

Epoch: 6| Step: 8
Training loss: 3.0205190210045028
Validation loss: 2.967611859582131

Epoch: 6| Step: 9
Training loss: 4.036412445135667
Validation loss: 2.9659557359220465

Epoch: 6| Step: 10
Training loss: 2.3112860921596856
Validation loss: 2.964739920884826

Epoch: 6| Step: 11
Training loss: 3.609230732202014
Validation loss: 2.966885040622978

Epoch: 6| Step: 12
Training loss: 3.4509655858957244
Validation loss: 2.967120093518334

Epoch: 6| Step: 13
Training loss: 3.110821104913837
Validation loss: 2.970476029794213

Epoch: 134| Step: 0
Training loss: 3.3337099021556984
Validation loss: 2.9657365168522953

Epoch: 6| Step: 1
Training loss: 3.5350871885519406
Validation loss: 2.973387431499561

Epoch: 6| Step: 2
Training loss: 3.8082067361459058
Validation loss: 2.9681245957896034

Epoch: 6| Step: 3
Training loss: 3.243435906581559
Validation loss: 2.9712698052003996

Epoch: 6| Step: 4
Training loss: 2.662736131826275
Validation loss: 2.9776525702249117

Epoch: 6| Step: 5
Training loss: 4.1377057995279545
Validation loss: 2.9848639301340887

Epoch: 6| Step: 6
Training loss: 4.062281206548141
Validation loss: 2.9803255613644803

Epoch: 6| Step: 7
Training loss: 2.2885627070764722
Validation loss: 2.9801885354084097

Epoch: 6| Step: 8
Training loss: 2.801589827821784
Validation loss: 2.9844469198030867

Epoch: 6| Step: 9
Training loss: 3.38794739643861
Validation loss: 2.97309620215651

Epoch: 6| Step: 10
Training loss: 2.7705235606873093
Validation loss: 2.9751177350768456

Epoch: 6| Step: 11
Training loss: 3.418059987621559
Validation loss: 2.9686640227755814

Epoch: 6| Step: 12
Training loss: 2.512663430739246
Validation loss: 2.9688432973505154

Epoch: 6| Step: 13
Training loss: 2.438308581706594
Validation loss: 2.964826792715058

Epoch: 135| Step: 0
Training loss: 3.889912122503641
Validation loss: 2.964016313185603

Epoch: 6| Step: 1
Training loss: 3.248850986133796
Validation loss: 2.9629756432293837

Epoch: 6| Step: 2
Training loss: 3.841540313981848
Validation loss: 2.961402152046601

Epoch: 6| Step: 3
Training loss: 3.057395261778098
Validation loss: 2.967927056386629

Epoch: 6| Step: 4
Training loss: 3.5335581839890837
Validation loss: 2.962578545827119

Epoch: 6| Step: 5
Training loss: 3.0400718444566417
Validation loss: 2.9635800762244053

Epoch: 6| Step: 6
Training loss: 2.6299859787019675
Validation loss: 2.9641136351194146

Epoch: 6| Step: 7
Training loss: 2.9073382565355272
Validation loss: 2.962410104146671

Epoch: 6| Step: 8
Training loss: 3.478970977091968
Validation loss: 2.96280928174606

Epoch: 6| Step: 9
Training loss: 2.838343920804622
Validation loss: 2.962322201699618

Epoch: 6| Step: 10
Training loss: 2.874551489302016
Validation loss: 2.9676166039704746

Epoch: 6| Step: 11
Training loss: 3.1612693231549422
Validation loss: 2.9615378129910925

Epoch: 6| Step: 12
Training loss: 3.6005182634930586
Validation loss: 2.964697240215127

Epoch: 6| Step: 13
Training loss: 2.844823613657315
Validation loss: 2.9605186262008685

Epoch: 136| Step: 0
Training loss: 4.184075848666879
Validation loss: 2.9602849474324233

Epoch: 6| Step: 1
Training loss: 2.042612894549822
Validation loss: 2.962087867238554

Epoch: 6| Step: 2
Training loss: 3.6761129393802108
Validation loss: 2.963753719252332

Epoch: 6| Step: 3
Training loss: 2.994825669247639
Validation loss: 2.9615300308316033

Epoch: 6| Step: 4
Training loss: 3.1018684293979812
Validation loss: 2.9635507742901517

Epoch: 6| Step: 5
Training loss: 3.2068439015390022
Validation loss: 2.9675154929514242

Epoch: 6| Step: 6
Training loss: 2.4869099286146237
Validation loss: 2.9663932733312617

Epoch: 6| Step: 7
Training loss: 3.5520099322807357
Validation loss: 2.9693695268207936

Epoch: 6| Step: 8
Training loss: 2.7737034629847743
Validation loss: 2.9706431424983957

Epoch: 6| Step: 9
Training loss: 2.6968421023452023
Validation loss: 2.972795904967761

Epoch: 6| Step: 10
Training loss: 3.6684182636066316
Validation loss: 2.9790536119135775

Epoch: 6| Step: 11
Training loss: 3.517209115760571
Validation loss: 2.979782084527394

Epoch: 6| Step: 12
Training loss: 3.4429336604924234
Validation loss: 2.984069042288695

Epoch: 6| Step: 13
Training loss: 3.4668047149999377
Validation loss: 2.9667776052709818

Epoch: 137| Step: 0
Training loss: 3.9063337393368034
Validation loss: 2.9645010091444757

Epoch: 6| Step: 1
Training loss: 3.255397129941724
Validation loss: 2.9631915920619605

Epoch: 6| Step: 2
Training loss: 3.2988570343611885
Validation loss: 2.9596723749440166

Epoch: 6| Step: 3
Training loss: 2.6206865747679453
Validation loss: 2.958465092861989

Epoch: 6| Step: 4
Training loss: 3.855417794274468
Validation loss: 2.956521502124799

Epoch: 6| Step: 5
Training loss: 2.6821174836623007
Validation loss: 2.9605137414118903

Epoch: 6| Step: 6
Training loss: 2.932618325684511
Validation loss: 2.957899307609979

Epoch: 6| Step: 7
Training loss: 3.5034394394485813
Validation loss: 2.95590700141558

Epoch: 6| Step: 8
Training loss: 2.703546303788736
Validation loss: 2.9596772204107302

Epoch: 6| Step: 9
Training loss: 3.4039365979396514
Validation loss: 2.9608018453183247

Epoch: 6| Step: 10
Training loss: 2.814385100263329
Validation loss: 2.9607371284839927

Epoch: 6| Step: 11
Training loss: 3.0846966143884917
Validation loss: 2.9601234509456074

Epoch: 6| Step: 12
Training loss: 3.5646995312947607
Validation loss: 2.9625995302716754

Epoch: 6| Step: 13
Training loss: 3.455326259020183
Validation loss: 2.961854033569174

Epoch: 138| Step: 0
Training loss: 3.829706853897827
Validation loss: 2.96351383352662

Epoch: 6| Step: 1
Training loss: 2.9829019636003267
Validation loss: 2.959726003788082

Epoch: 6| Step: 2
Training loss: 3.9589176482875787
Validation loss: 2.9605911463142225

Epoch: 6| Step: 3
Training loss: 2.668589306176633
Validation loss: 2.9628253584858184

Epoch: 6| Step: 4
Training loss: 2.956597441243131
Validation loss: 2.9591128382302627

Epoch: 6| Step: 5
Training loss: 3.277359754411906
Validation loss: 2.9591296298649636

Epoch: 6| Step: 6
Training loss: 3.1252963116355
Validation loss: 2.9608505564837517

Epoch: 6| Step: 7
Training loss: 3.425583454194037
Validation loss: 2.9571841161362467

Epoch: 6| Step: 8
Training loss: 2.903742210716018
Validation loss: 2.9540938822464144

Epoch: 6| Step: 9
Training loss: 3.470527811941151
Validation loss: 2.959169287616411

Epoch: 6| Step: 10
Training loss: 2.81310011501192
Validation loss: 2.958604217587639

Epoch: 6| Step: 11
Training loss: 2.8698342395723957
Validation loss: 2.9604831205895437

Epoch: 6| Step: 12
Training loss: 3.113764286261166
Validation loss: 2.9637132336158003

Epoch: 6| Step: 13
Training loss: 3.915696220024251
Validation loss: 2.963187755931362

Epoch: 139| Step: 0
Training loss: 3.3292992181533614
Validation loss: 2.970930083765474

Epoch: 6| Step: 1
Training loss: 3.108394142217422
Validation loss: 2.971904894743987

Epoch: 6| Step: 2
Training loss: 2.9352744579499976
Validation loss: 2.9712295557145376

Epoch: 6| Step: 3
Training loss: 4.016203486116526
Validation loss: 2.9615170322424067

Epoch: 6| Step: 4
Training loss: 3.9331786647925986
Validation loss: 2.9621610889043857

Epoch: 6| Step: 5
Training loss: 2.861780041104157
Validation loss: 2.9543566319041794

Epoch: 6| Step: 6
Training loss: 3.4000201168587143
Validation loss: 2.9542950462330473

Epoch: 6| Step: 7
Training loss: 2.6385356153520925
Validation loss: 2.9532486129631663

Epoch: 6| Step: 8
Training loss: 2.4420469862333096
Validation loss: 2.95456309606929

Epoch: 6| Step: 9
Training loss: 2.743575915677244
Validation loss: 2.9537835763579245

Epoch: 6| Step: 10
Training loss: 4.012690202714865
Validation loss: 2.9532557450569343

Epoch: 6| Step: 11
Training loss: 3.0251704333504703
Validation loss: 2.9503989058937043

Epoch: 6| Step: 12
Training loss: 2.8630953906680183
Validation loss: 2.9508661773764944

Epoch: 6| Step: 13
Training loss: 3.605184922045408
Validation loss: 2.953126041733154

Epoch: 140| Step: 0
Training loss: 3.1843377677380533
Validation loss: 2.9510651776259005

Epoch: 6| Step: 1
Training loss: 3.6507410786412677
Validation loss: 2.953394056178942

Epoch: 6| Step: 2
Training loss: 3.1853395508005176
Validation loss: 2.951796668343832

Epoch: 6| Step: 3
Training loss: 3.330556062202178
Validation loss: 2.9482241443059265

Epoch: 6| Step: 4
Training loss: 2.632695860500503
Validation loss: 2.9486982393005623

Epoch: 6| Step: 5
Training loss: 3.354658923940209
Validation loss: 2.9486481310467454

Epoch: 6| Step: 6
Training loss: 3.206445824069521
Validation loss: 2.9476790643124633

Epoch: 6| Step: 7
Training loss: 2.8409114546332495
Validation loss: 2.9482527090224413

Epoch: 6| Step: 8
Training loss: 3.2578930010100504
Validation loss: 2.9491568075541106

Epoch: 6| Step: 9
Training loss: 2.9541262589360247
Validation loss: 2.9483098863188415

Epoch: 6| Step: 10
Training loss: 3.150998723181463
Validation loss: 2.9501936788299483

Epoch: 6| Step: 11
Training loss: 3.7049664132144136
Validation loss: 2.954392881905063

Epoch: 6| Step: 12
Training loss: 3.4218043489870342
Validation loss: 2.954383897326315

Epoch: 6| Step: 13
Training loss: 3.2943145789256185
Validation loss: 2.9581107824679935

Epoch: 141| Step: 0
Training loss: 2.7773698464842878
Validation loss: 2.966504708275577

Epoch: 6| Step: 1
Training loss: 3.546515223871779
Validation loss: 2.964236754381499

Epoch: 6| Step: 2
Training loss: 2.6871509768934883
Validation loss: 2.9662288649216215

Epoch: 6| Step: 3
Training loss: 3.108632061250789
Validation loss: 2.95983502895812

Epoch: 6| Step: 4
Training loss: 2.2611287719553386
Validation loss: 2.9536279711311413

Epoch: 6| Step: 5
Training loss: 3.1020704185024
Validation loss: 2.950146185560573

Epoch: 6| Step: 6
Training loss: 4.10095256811663
Validation loss: 2.9479278444809975

Epoch: 6| Step: 7
Training loss: 3.166788466938696
Validation loss: 2.949316661056701

Epoch: 6| Step: 8
Training loss: 2.983328910554417
Validation loss: 2.947717239334551

Epoch: 6| Step: 9
Training loss: 3.744649248593934
Validation loss: 2.9465271974679257

Epoch: 6| Step: 10
Training loss: 3.6293719006277665
Validation loss: 2.944960858817734

Epoch: 6| Step: 11
Training loss: 3.1305047951116123
Validation loss: 2.944743297084519

Epoch: 6| Step: 12
Training loss: 3.5266766936574885
Validation loss: 2.944986578151696

Epoch: 6| Step: 13
Training loss: 2.7937368337163098
Validation loss: 2.9445624942788244

Epoch: 142| Step: 0
Training loss: 2.9578362884612766
Validation loss: 2.9425510118694462

Epoch: 6| Step: 1
Training loss: 3.3760882848251454
Validation loss: 2.941672859811688

Epoch: 6| Step: 2
Training loss: 3.3507342259884547
Validation loss: 2.9411181943031353

Epoch: 6| Step: 3
Training loss: 2.8661116158792095
Validation loss: 2.941185793864887

Epoch: 6| Step: 4
Training loss: 3.2898638331285603
Validation loss: 2.943223268127503

Epoch: 6| Step: 5
Training loss: 3.2369380507411534
Validation loss: 2.9434458535924364

Epoch: 6| Step: 6
Training loss: 3.490917956456573
Validation loss: 2.9528888313450947

Epoch: 6| Step: 7
Training loss: 3.576905954917902
Validation loss: 2.947638220474648

Epoch: 6| Step: 8
Training loss: 3.5816293405676882
Validation loss: 2.9449399706707755

Epoch: 6| Step: 9
Training loss: 2.559184558010467
Validation loss: 2.9432786051193944

Epoch: 6| Step: 10
Training loss: 3.2159533156047857
Validation loss: 2.9397423850950326

Epoch: 6| Step: 11
Training loss: 2.609317253524572
Validation loss: 2.9437328228304454

Epoch: 6| Step: 12
Training loss: 3.099123209352614
Validation loss: 2.938784719604302

Epoch: 6| Step: 13
Training loss: 4.133108319546381
Validation loss: 2.9390448507512708

Epoch: 143| Step: 0
Training loss: 3.5580199330689832
Validation loss: 2.9393434868688364

Epoch: 6| Step: 1
Training loss: 3.1583800729264033
Validation loss: 2.9399766921156876

Epoch: 6| Step: 2
Training loss: 3.4454441175168045
Validation loss: 2.9395211535666768

Epoch: 6| Step: 3
Training loss: 3.104425372580391
Validation loss: 2.9400609472826083

Epoch: 6| Step: 4
Training loss: 3.3007116186257557
Validation loss: 2.937991519842555

Epoch: 6| Step: 5
Training loss: 3.476417109846121
Validation loss: 2.9416258059077283

Epoch: 6| Step: 6
Training loss: 2.7883848761586574
Validation loss: 2.9390333856121016

Epoch: 6| Step: 7
Training loss: 3.36783021957438
Validation loss: 2.9409156094539446

Epoch: 6| Step: 8
Training loss: 2.9361246013862767
Validation loss: 2.9381649763139426

Epoch: 6| Step: 9
Training loss: 2.7295821555499082
Validation loss: 2.9398994882833818

Epoch: 6| Step: 10
Training loss: 3.1041309090076
Validation loss: 2.938480678662845

Epoch: 6| Step: 11
Training loss: 3.0308467950767572
Validation loss: 2.945289963159753

Epoch: 6| Step: 12
Training loss: 3.6167123700841795
Validation loss: 2.95674650092687

Epoch: 6| Step: 13
Training loss: 3.583893236877656
Validation loss: 2.9433875862755077

Epoch: 144| Step: 0
Training loss: 3.203988456648131
Validation loss: 2.9433409839596147

Epoch: 6| Step: 1
Training loss: 2.4999607083093967
Validation loss: 2.9440589313687973

Epoch: 6| Step: 2
Training loss: 3.5370772901119345
Validation loss: 2.945280385037471

Epoch: 6| Step: 3
Training loss: 3.2561903466674775
Validation loss: 2.9459808392975213

Epoch: 6| Step: 4
Training loss: 3.684691313155308
Validation loss: 2.9476262095198904

Epoch: 6| Step: 5
Training loss: 3.0961285319890517
Validation loss: 2.9397455227761204

Epoch: 6| Step: 6
Training loss: 2.9066440766299557
Validation loss: 2.9380924619680235

Epoch: 6| Step: 7
Training loss: 2.3623581778126534
Validation loss: 2.93995258139589

Epoch: 6| Step: 8
Training loss: 3.557906820448389
Validation loss: 2.9401352197522637

Epoch: 6| Step: 9
Training loss: 3.8477346964163663
Validation loss: 2.940841749846859

Epoch: 6| Step: 10
Training loss: 3.3500147804959033
Validation loss: 2.94316710608362

Epoch: 6| Step: 11
Training loss: 2.395803191506782
Validation loss: 2.9449285807140106

Epoch: 6| Step: 12
Training loss: 3.083433269908799
Validation loss: 2.9451208565003535

Epoch: 6| Step: 13
Training loss: 4.381432082981354
Validation loss: 2.9419295462079047

Epoch: 145| Step: 0
Training loss: 2.6374879520376115
Validation loss: 2.9400899418373467

Epoch: 6| Step: 1
Training loss: 3.270120984560374
Validation loss: 2.941949947697983

Epoch: 6| Step: 2
Training loss: 3.0421105326598377
Validation loss: 2.943629646893414

Epoch: 6| Step: 3
Training loss: 3.433267380411189
Validation loss: 2.9412021448213976

Epoch: 6| Step: 4
Training loss: 2.6561237080788254
Validation loss: 2.942390610449739

Epoch: 6| Step: 5
Training loss: 3.4586293810018724
Validation loss: 2.9419080413574865

Epoch: 6| Step: 6
Training loss: 3.4949459642590783
Validation loss: 2.9423653816115873

Epoch: 6| Step: 7
Training loss: 3.1269304035226178
Validation loss: 2.94286943118668

Epoch: 6| Step: 8
Training loss: 2.594803377908878
Validation loss: 2.9422733027068686

Epoch: 6| Step: 9
Training loss: 3.636104281886712
Validation loss: 2.940676856165928

Epoch: 6| Step: 10
Training loss: 3.2341576839546056
Validation loss: 2.9442433768874765

Epoch: 6| Step: 11
Training loss: 3.834001413813705
Validation loss: 2.9455810417488903

Epoch: 6| Step: 12
Training loss: 3.8185856510639797
Validation loss: 2.948645856619214

Epoch: 6| Step: 13
Training loss: 1.8215695735305193
Validation loss: 2.943071268307662

Epoch: 146| Step: 0
Training loss: 3.4805942431430283
Validation loss: 2.9521802293899713

Epoch: 6| Step: 1
Training loss: 3.13703629916017
Validation loss: 2.9462912360721814

Epoch: 6| Step: 2
Training loss: 3.093052949310957
Validation loss: 2.943665148511898

Epoch: 6| Step: 3
Training loss: 2.7959368959926993
Validation loss: 2.938166100133923

Epoch: 6| Step: 4
Training loss: 3.1838202085867646
Validation loss: 2.9356707513225246

Epoch: 6| Step: 5
Training loss: 2.184220498751055
Validation loss: 2.9360429706221427

Epoch: 6| Step: 6
Training loss: 2.7842474226404046
Validation loss: 2.933049172843069

Epoch: 6| Step: 7
Training loss: 3.925186522115661
Validation loss: 2.93665630972554

Epoch: 6| Step: 8
Training loss: 3.3128851900527283
Validation loss: 2.934489341766595

Epoch: 6| Step: 9
Training loss: 3.4776935923350076
Validation loss: 2.936154530642611

Epoch: 6| Step: 10
Training loss: 3.0637413156138074
Validation loss: 2.9327070240414517

Epoch: 6| Step: 11
Training loss: 3.8289897331285454
Validation loss: 2.933544659646576

Epoch: 6| Step: 12
Training loss: 3.512626352447231
Validation loss: 2.9333777712949947

Epoch: 6| Step: 13
Training loss: 2.6087828552487546
Validation loss: 2.9349407898647

Epoch: 147| Step: 0
Training loss: 3.871611066909739
Validation loss: 2.9338718298511686

Epoch: 6| Step: 1
Training loss: 3.0169676326726207
Validation loss: 2.9338950940227573

Epoch: 6| Step: 2
Training loss: 3.1601058522132424
Validation loss: 2.9319638718721075

Epoch: 6| Step: 3
Training loss: 3.1435590864271026
Validation loss: 2.9320913112423854

Epoch: 6| Step: 4
Training loss: 2.6201490356921076
Validation loss: 2.9326777746678445

Epoch: 6| Step: 5
Training loss: 2.9577687400809083
Validation loss: 2.934854548956684

Epoch: 6| Step: 6
Training loss: 3.1014768651099125
Validation loss: 2.9316534639847887

Epoch: 6| Step: 7
Training loss: 3.8763993720558263
Validation loss: 2.9308383033937466

Epoch: 6| Step: 8
Training loss: 3.5233278786127697
Validation loss: 2.932308464429848

Epoch: 6| Step: 9
Training loss: 2.842795914115884
Validation loss: 2.9367366838444076

Epoch: 6| Step: 10
Training loss: 2.5047712572625263
Validation loss: 2.9321493457674923

Epoch: 6| Step: 11
Training loss: 3.5567724129122205
Validation loss: 2.936486113956257

Epoch: 6| Step: 12
Training loss: 3.18151922679309
Validation loss: 2.9338143362175697

Epoch: 6| Step: 13
Training loss: 3.4300518841614553
Validation loss: 2.9320614209503795

Epoch: 148| Step: 0
Training loss: 3.090150530953966
Validation loss: 2.9351283867523286

Epoch: 6| Step: 1
Training loss: 3.479958784802041
Validation loss: 2.934855685399995

Epoch: 6| Step: 2
Training loss: 2.988165719784712
Validation loss: 2.934233062553312

Epoch: 6| Step: 3
Training loss: 2.8492485795840485
Validation loss: 2.932089277530078

Epoch: 6| Step: 4
Training loss: 3.3322135633923082
Validation loss: 2.938060135456181

Epoch: 6| Step: 5
Training loss: 3.7766525440900356
Validation loss: 2.932293297487726

Epoch: 6| Step: 6
Training loss: 2.8454497570803037
Validation loss: 2.936585738964119

Epoch: 6| Step: 7
Training loss: 3.2906371490457116
Validation loss: 2.9352357123478017

Epoch: 6| Step: 8
Training loss: 2.8270047324228367
Validation loss: 2.932456664092219

Epoch: 6| Step: 9
Training loss: 3.5821020687178766
Validation loss: 2.9318611588011696

Epoch: 6| Step: 10
Training loss: 2.7458815513008594
Validation loss: 2.9274170452165196

Epoch: 6| Step: 11
Training loss: 3.1570297637686737
Validation loss: 2.92748970577282

Epoch: 6| Step: 12
Training loss: 3.3936855021999013
Validation loss: 2.928124689924776

Epoch: 6| Step: 13
Training loss: 3.662423424034155
Validation loss: 2.931481854876805

Epoch: 149| Step: 0
Training loss: 3.0225374523331943
Validation loss: 2.9284146304154257

Epoch: 6| Step: 1
Training loss: 2.9912874546408115
Validation loss: 2.929911791019539

Epoch: 6| Step: 2
Training loss: 4.030416239784418
Validation loss: 2.9320983216809635

Epoch: 6| Step: 3
Training loss: 3.2337775669168902
Validation loss: 2.9295856084572125

Epoch: 6| Step: 4
Training loss: 2.932928545794515
Validation loss: 2.93000177525813

Epoch: 6| Step: 5
Training loss: 3.354230481285094
Validation loss: 2.9286926881924966

Epoch: 6| Step: 6
Training loss: 3.500959401108566
Validation loss: 2.931036168907742

Epoch: 6| Step: 7
Training loss: 2.9283423018458388
Validation loss: 2.9332288918775022

Epoch: 6| Step: 8
Training loss: 3.054983919791249
Validation loss: 2.928750972132718

Epoch: 6| Step: 9
Training loss: 2.2730626587058333
Validation loss: 2.9357275274605565

Epoch: 6| Step: 10
Training loss: 3.4054470690785092
Validation loss: 2.9354110705027434

Epoch: 6| Step: 11
Training loss: 3.2328130663967602
Validation loss: 2.9473935761124412

Epoch: 6| Step: 12
Training loss: 3.427287937228982
Validation loss: 2.9566042981950966

Epoch: 6| Step: 13
Training loss: 3.3946502278397634
Validation loss: 2.9698705245710006

Epoch: 150| Step: 0
Training loss: 3.2349992969635992
Validation loss: 2.945118273813438

Epoch: 6| Step: 1
Training loss: 3.1306388334675774
Validation loss: 2.932478867693438

Epoch: 6| Step: 2
Training loss: 3.5412668937498277
Validation loss: 2.929008782198152

Epoch: 6| Step: 3
Training loss: 2.8936609769437927
Validation loss: 2.9282469173945604

Epoch: 6| Step: 4
Training loss: 2.5908919064622666
Validation loss: 2.926482202430359

Epoch: 6| Step: 5
Training loss: 3.8050894084356237
Validation loss: 2.922845241214897

Epoch: 6| Step: 6
Training loss: 3.1975726875591306
Validation loss: 2.9230422173315005

Epoch: 6| Step: 7
Training loss: 3.4337687268768895
Validation loss: 2.9284937381533136

Epoch: 6| Step: 8
Training loss: 2.809625385740423
Validation loss: 2.9240098714643765

Epoch: 6| Step: 9
Training loss: 2.925609140465185
Validation loss: 2.9253491755504037

Epoch: 6| Step: 10
Training loss: 2.8226910227627378
Validation loss: 2.9245743403154125

Epoch: 6| Step: 11
Training loss: 4.010165648428009
Validation loss: 2.926523261814623

Epoch: 6| Step: 12
Training loss: 2.9440758332457837
Validation loss: 2.9261865518987116

Epoch: 6| Step: 13
Training loss: 3.361416786172725
Validation loss: 2.9252378633647536

Epoch: 151| Step: 0
Training loss: 2.585096147472044
Validation loss: 2.9255781744653286

Epoch: 6| Step: 1
Training loss: 3.702316517839419
Validation loss: 2.923616072301608

Epoch: 6| Step: 2
Training loss: 3.4186401405326983
Validation loss: 2.923757909680703

Epoch: 6| Step: 3
Training loss: 3.379754426375529
Validation loss: 2.925158785890726

Epoch: 6| Step: 4
Training loss: 2.486753273070227
Validation loss: 2.923992178492458

Epoch: 6| Step: 5
Training loss: 3.173914211572883
Validation loss: 2.9239812093221613

Epoch: 6| Step: 6
Training loss: 3.294284182233741
Validation loss: 2.924717562178987

Epoch: 6| Step: 7
Training loss: 3.2726484636007873
Validation loss: 2.925446737506948

Epoch: 6| Step: 8
Training loss: 3.2670833853830388
Validation loss: 2.9279406150500953

Epoch: 6| Step: 9
Training loss: 3.734581211413938
Validation loss: 2.9258461994055285

Epoch: 6| Step: 10
Training loss: 3.0534721747180447
Validation loss: 2.9285100628040035

Epoch: 6| Step: 11
Training loss: 3.1715655998074257
Validation loss: 2.9259550684615

Epoch: 6| Step: 12
Training loss: 2.6551558092164425
Validation loss: 2.926020393382887

Epoch: 6| Step: 13
Training loss: 3.66663184293914
Validation loss: 2.927133023675177

Epoch: 152| Step: 0
Training loss: 3.2853204094221797
Validation loss: 2.9272345872153216

Epoch: 6| Step: 1
Training loss: 2.4922905305713527
Validation loss: 2.9232857118196467

Epoch: 6| Step: 2
Training loss: 2.9627702420748423
Validation loss: 2.924949570396301

Epoch: 6| Step: 3
Training loss: 2.8947312341298077
Validation loss: 2.924918169689999

Epoch: 6| Step: 4
Training loss: 2.4781329353272814
Validation loss: 2.9254615271980686

Epoch: 6| Step: 5
Training loss: 2.750964949112423
Validation loss: 2.929526564030048

Epoch: 6| Step: 6
Training loss: 3.5459918968766475
Validation loss: 2.931693998849479

Epoch: 6| Step: 7
Training loss: 2.9974414723642266
Validation loss: 2.941842509763611

Epoch: 6| Step: 8
Training loss: 3.6477175539330733
Validation loss: 2.9412868651857553

Epoch: 6| Step: 9
Training loss: 3.893702136582892
Validation loss: 2.9294676671835105

Epoch: 6| Step: 10
Training loss: 2.9724276601396347
Validation loss: 2.9273724314489176

Epoch: 6| Step: 11
Training loss: 4.183959603007028
Validation loss: 2.9243096879337003

Epoch: 6| Step: 12
Training loss: 3.397475533976262
Validation loss: 2.921779809787163

Epoch: 6| Step: 13
Training loss: 2.619165748970663
Validation loss: 2.920205128303336

Epoch: 153| Step: 0
Training loss: 3.5168822350503013
Validation loss: 2.9225113040801562

Epoch: 6| Step: 1
Training loss: 3.165298333593441
Validation loss: 2.9210516253334142

Epoch: 6| Step: 2
Training loss: 3.8724088311591855
Validation loss: 2.920973703634221

Epoch: 6| Step: 3
Training loss: 3.42955194088058
Validation loss: 2.9230188001263904

Epoch: 6| Step: 4
Training loss: 3.630125040259958
Validation loss: 2.9212265343550974

Epoch: 6| Step: 5
Training loss: 3.886705500134451
Validation loss: 2.9214636602133344

Epoch: 6| Step: 6
Training loss: 3.208976202296729
Validation loss: 2.9194616151655497

Epoch: 6| Step: 7
Training loss: 1.958214012190305
Validation loss: 2.920105244690639

Epoch: 6| Step: 8
Training loss: 3.201394707009487
Validation loss: 2.917304730975929

Epoch: 6| Step: 9
Training loss: 2.8883471612733196
Validation loss: 2.9206643221117567

Epoch: 6| Step: 10
Training loss: 2.8519445712038722
Validation loss: 2.9204752510006244

Epoch: 6| Step: 11
Training loss: 3.047296582913025
Validation loss: 2.9223005454212085

Epoch: 6| Step: 12
Training loss: 2.791116252176986
Validation loss: 2.920720656168354

Epoch: 6| Step: 13
Training loss: 2.7733237659613326
Validation loss: 2.9213395974159053

Epoch: 154| Step: 0
Training loss: 3.498266471985946
Validation loss: 2.919844885445702

Epoch: 6| Step: 1
Training loss: 3.144466498993662
Validation loss: 2.924835558261069

Epoch: 6| Step: 2
Training loss: 3.4563535209176823
Validation loss: 2.921203033264743

Epoch: 6| Step: 3
Training loss: 2.974100050525313
Validation loss: 2.9240204661540927

Epoch: 6| Step: 4
Training loss: 3.342909377485292
Validation loss: 2.924051245245934

Epoch: 6| Step: 5
Training loss: 2.3060075503223216
Validation loss: 2.9336314249389304

Epoch: 6| Step: 6
Training loss: 2.969643066998715
Validation loss: 2.9514205414250787

Epoch: 6| Step: 7
Training loss: 3.408236003378305
Validation loss: 2.936690680471647

Epoch: 6| Step: 8
Training loss: 3.0498135994406295
Validation loss: 2.9232723046361637

Epoch: 6| Step: 9
Training loss: 3.469000317588653
Validation loss: 2.925020660293769

Epoch: 6| Step: 10
Training loss: 2.631959771408326
Validation loss: 2.921127691420781

Epoch: 6| Step: 11
Training loss: 2.8016975638346078
Validation loss: 2.9182879505112247

Epoch: 6| Step: 12
Training loss: 3.892146169350384
Validation loss: 2.9151132293685587

Epoch: 6| Step: 13
Training loss: 3.8542636893492555
Validation loss: 2.9155666128510687

Epoch: 155| Step: 0
Training loss: 2.758057926485299
Validation loss: 2.9125558385417176

Epoch: 6| Step: 1
Training loss: 3.203696893020411
Validation loss: 2.9114604116884375

Epoch: 6| Step: 2
Training loss: 2.516870794375638
Validation loss: 2.9153969428341875

Epoch: 6| Step: 3
Training loss: 2.5495738140821436
Validation loss: 2.9116767764517486

Epoch: 6| Step: 4
Training loss: 3.870873499820335
Validation loss: 2.9165042635681755

Epoch: 6| Step: 5
Training loss: 3.0682861785608204
Validation loss: 2.9171431760144237

Epoch: 6| Step: 6
Training loss: 4.186332425991539
Validation loss: 2.92008851222288

Epoch: 6| Step: 7
Training loss: 2.407046892065168
Validation loss: 2.922985819262113

Epoch: 6| Step: 8
Training loss: 3.4368941726885125
Validation loss: 2.9200812306415673

Epoch: 6| Step: 9
Training loss: 3.018891142078854
Validation loss: 2.912872249962907

Epoch: 6| Step: 10
Training loss: 3.0373169266902624
Validation loss: 2.9130599347559842

Epoch: 6| Step: 11
Training loss: 4.02959769046453
Validation loss: 2.909427618281817

Epoch: 6| Step: 12
Training loss: 3.0926594979702733
Validation loss: 2.9084338079993883

Epoch: 6| Step: 13
Training loss: 2.9380891898934167
Validation loss: 2.905310411984042

Epoch: 156| Step: 0
Training loss: 3.48167075006426
Validation loss: 2.909967200049243

Epoch: 6| Step: 1
Training loss: 2.7503849973811993
Validation loss: 2.907306686779187

Epoch: 6| Step: 2
Training loss: 3.7945632490254386
Validation loss: 2.9098198408221907

Epoch: 6| Step: 3
Training loss: 2.9061612351510755
Validation loss: 2.9077882148374936

Epoch: 6| Step: 4
Training loss: 3.5447280368405663
Validation loss: 2.9092277526161894

Epoch: 6| Step: 5
Training loss: 2.071787298081053
Validation loss: 2.9075867737282453

Epoch: 6| Step: 6
Training loss: 2.866022772518176
Validation loss: 2.9079314329838883

Epoch: 6| Step: 7
Training loss: 3.506049513907316
Validation loss: 2.9063239218856993

Epoch: 6| Step: 8
Training loss: 3.337399450494814
Validation loss: 2.907944917949797

Epoch: 6| Step: 9
Training loss: 3.604000697788929
Validation loss: 2.9091258917671694

Epoch: 6| Step: 10
Training loss: 3.3937501348843204
Validation loss: 2.9080898421219303

Epoch: 6| Step: 11
Training loss: 3.7228488932316255
Validation loss: 2.908206337258881

Epoch: 6| Step: 12
Training loss: 2.942607254497894
Validation loss: 2.905704707799494

Epoch: 6| Step: 13
Training loss: 1.3731021354483663
Validation loss: 2.90299099197045

Epoch: 157| Step: 0
Training loss: 3.2494239296579615
Validation loss: 2.9068709817206755

Epoch: 6| Step: 1
Training loss: 3.1460710818826554
Validation loss: 2.9087687575574703

Epoch: 6| Step: 2
Training loss: 3.621442693627436
Validation loss: 2.906897303519087

Epoch: 6| Step: 3
Training loss: 3.4647783791483358
Validation loss: 2.912465256313821

Epoch: 6| Step: 4
Training loss: 2.2646153798390394
Validation loss: 2.9084543845086888

Epoch: 6| Step: 5
Training loss: 3.7419346861366383
Validation loss: 2.910765884058691

Epoch: 6| Step: 6
Training loss: 2.916927616616678
Validation loss: 2.9138140820086664

Epoch: 6| Step: 7
Training loss: 3.6458969255986715
Validation loss: 2.9155172031361216

Epoch: 6| Step: 8
Training loss: 3.780360598040973
Validation loss: 2.9134640225221693

Epoch: 6| Step: 9
Training loss: 2.7391060146219934
Validation loss: 2.920280054133682

Epoch: 6| Step: 10
Training loss: 3.136343091462687
Validation loss: 2.919944676119416

Epoch: 6| Step: 11
Training loss: 2.7748399224376543
Validation loss: 2.922813918769223

Epoch: 6| Step: 12
Training loss: 2.431512374253411
Validation loss: 2.919625496927729

Epoch: 6| Step: 13
Training loss: 3.568278528392783
Validation loss: 2.918034325749207

Epoch: 158| Step: 0
Training loss: 3.436634162751588
Validation loss: 2.921719849504222

Epoch: 6| Step: 1
Training loss: 3.362664320096622
Validation loss: 2.9243334112753576

Epoch: 6| Step: 2
Training loss: 2.919163389154181
Validation loss: 2.9166235526512354

Epoch: 6| Step: 3
Training loss: 3.261440242366677
Validation loss: 2.9079825778417905

Epoch: 6| Step: 4
Training loss: 3.8357137393367506
Validation loss: 2.90570727875775

Epoch: 6| Step: 5
Training loss: 3.2698997736511926
Validation loss: 2.901200523864562

Epoch: 6| Step: 6
Training loss: 3.0534489064505728
Validation loss: 2.9043125730032724

Epoch: 6| Step: 7
Training loss: 2.9278358406262743
Validation loss: 2.905008481108819

Epoch: 6| Step: 8
Training loss: 2.4637886122528245
Validation loss: 2.9040785391432644

Epoch: 6| Step: 9
Training loss: 3.068530315297282
Validation loss: 2.905991789671053

Epoch: 6| Step: 10
Training loss: 3.030557612360058
Validation loss: 2.9051287699337762

Epoch: 6| Step: 11
Training loss: 3.313980203674162
Validation loss: 2.9059846306799453

Epoch: 6| Step: 12
Training loss: 3.2563033965376653
Validation loss: 2.905286677140701

Epoch: 6| Step: 13
Training loss: 3.7222394199511775
Validation loss: 2.9058684417141296

Epoch: 159| Step: 0
Training loss: 3.0244312476808335
Validation loss: 2.9045541653766787

Epoch: 6| Step: 1
Training loss: 2.60252467969173
Validation loss: 2.8996043132981995

Epoch: 6| Step: 2
Training loss: 3.196916918885269
Validation loss: 2.9045602254937357

Epoch: 6| Step: 3
Training loss: 3.030371469822996
Validation loss: 2.902077915715532

Epoch: 6| Step: 4
Training loss: 3.5658477312442036
Validation loss: 2.9009402035626444

Epoch: 6| Step: 5
Training loss: 3.5740325045396353
Validation loss: 2.901997698307273

Epoch: 6| Step: 6
Training loss: 2.7973008497598864
Validation loss: 2.9002908280072996

Epoch: 6| Step: 7
Training loss: 2.693172943545441
Validation loss: 2.906620006932816

Epoch: 6| Step: 8
Training loss: 3.1808096290473333
Validation loss: 2.903457067022653

Epoch: 6| Step: 9
Training loss: 3.1027147281182703
Validation loss: 2.9059133891560327

Epoch: 6| Step: 10
Training loss: 3.0245387710908966
Validation loss: 2.9042735626377207

Epoch: 6| Step: 11
Training loss: 3.924610172035104
Validation loss: 2.9080121514204342

Epoch: 6| Step: 12
Training loss: 3.2772264789246774
Validation loss: 2.909130326167854

Epoch: 6| Step: 13
Training loss: 3.6477374236322957
Validation loss: 2.9126015233641653

Epoch: 160| Step: 0
Training loss: 2.8378042587296712
Validation loss: 2.9072767868122975

Epoch: 6| Step: 1
Training loss: 3.199969416710619
Validation loss: 2.914215068940952

Epoch: 6| Step: 2
Training loss: 3.3744250620226466
Validation loss: 2.908981469547057

Epoch: 6| Step: 3
Training loss: 2.847553936830124
Validation loss: 2.9036794747253682

Epoch: 6| Step: 4
Training loss: 3.0807547397578614
Validation loss: 2.90303800447175

Epoch: 6| Step: 5
Training loss: 2.639985949594504
Validation loss: 2.9068414221080867

Epoch: 6| Step: 6
Training loss: 3.2796564501437095
Validation loss: 2.8989848807538863

Epoch: 6| Step: 7
Training loss: 2.9743820574460886
Validation loss: 2.902621017035632

Epoch: 6| Step: 8
Training loss: 2.796589927423749
Validation loss: 2.9025548987505854

Epoch: 6| Step: 9
Training loss: 3.868683373489167
Validation loss: 2.90199476451623

Epoch: 6| Step: 10
Training loss: 2.7030898957371052
Validation loss: 2.905473861061387

Epoch: 6| Step: 11
Training loss: 3.537055046216185
Validation loss: 2.9037109938633296

Epoch: 6| Step: 12
Training loss: 3.579298068659083
Validation loss: 2.9033212096309406

Epoch: 6| Step: 13
Training loss: 3.9948665341652476
Validation loss: 2.9039421202238844

Epoch: 161| Step: 0
Training loss: 2.92046824162945
Validation loss: 2.9012270614660864

Epoch: 6| Step: 1
Training loss: 2.4295116495849016
Validation loss: 2.9018931789573124

Epoch: 6| Step: 2
Training loss: 3.3638714173970388
Validation loss: 2.9049715424943505

Epoch: 6| Step: 3
Training loss: 3.9255872688004607
Validation loss: 2.901236252192441

Epoch: 6| Step: 4
Training loss: 2.962665627271926
Validation loss: 2.8993333611127143

Epoch: 6| Step: 5
Training loss: 3.0044954314912116
Validation loss: 2.9007713448346153

Epoch: 6| Step: 6
Training loss: 3.9121242452444545
Validation loss: 2.8980849436137897

Epoch: 6| Step: 7
Training loss: 2.961347164107442
Validation loss: 2.8991052170066167

Epoch: 6| Step: 8
Training loss: 3.0838108895749645
Validation loss: 2.898870859137438

Epoch: 6| Step: 9
Training loss: 2.6242890076290655
Validation loss: 2.898059944761706

Epoch: 6| Step: 10
Training loss: 3.187530068648388
Validation loss: 2.899172139063421

Epoch: 6| Step: 11
Training loss: 3.1182177378033695
Validation loss: 2.898519522956883

Epoch: 6| Step: 12
Training loss: 3.5011905280240594
Validation loss: 2.900971255813366

Epoch: 6| Step: 13
Training loss: 3.3571811343390765
Validation loss: 2.8977149828145574

Epoch: 162| Step: 0
Training loss: 2.4579614476532
Validation loss: 2.897420086518711

Epoch: 6| Step: 1
Training loss: 2.9440039199201777
Validation loss: 2.9054399310322983

Epoch: 6| Step: 2
Training loss: 3.5192224703703334
Validation loss: 2.9034874230783028

Epoch: 6| Step: 3
Training loss: 3.274239016347071
Validation loss: 2.900951928835426

Epoch: 6| Step: 4
Training loss: 3.1321921935470205
Validation loss: 2.897191305954529

Epoch: 6| Step: 5
Training loss: 3.5842092168062494
Validation loss: 2.9016460021132033

Epoch: 6| Step: 6
Training loss: 3.491985135967697
Validation loss: 2.905610711862595

Epoch: 6| Step: 7
Training loss: 3.1678725673688928
Validation loss: 2.900326792939655

Epoch: 6| Step: 8
Training loss: 3.454265423426306
Validation loss: 2.898744403748259

Epoch: 6| Step: 9
Training loss: 2.592775184645127
Validation loss: 2.894016704991965

Epoch: 6| Step: 10
Training loss: 3.315959779051402
Validation loss: 2.9010717522557203

Epoch: 6| Step: 11
Training loss: 3.337329725858187
Validation loss: 2.8984970910550527

Epoch: 6| Step: 12
Training loss: 3.3531486119330434
Validation loss: 2.898189944398933

Epoch: 6| Step: 13
Training loss: 2.423305851738099
Validation loss: 2.8997066483094596

Epoch: 163| Step: 0
Training loss: 2.882566198563204
Validation loss: 2.899947305426177

Epoch: 6| Step: 1
Training loss: 2.7415095955824955
Validation loss: 2.8952327216671705

Epoch: 6| Step: 2
Training loss: 3.1318787208158962
Validation loss: 2.8968602479412455

Epoch: 6| Step: 3
Training loss: 3.7262446429890104
Validation loss: 2.8981347018336527

Epoch: 6| Step: 4
Training loss: 3.149626173816512
Validation loss: 2.902220569415126

Epoch: 6| Step: 5
Training loss: 2.6018165258159134
Validation loss: 2.8990381289238116

Epoch: 6| Step: 6
Training loss: 3.284093877809616
Validation loss: 2.8990708374984093

Epoch: 6| Step: 7
Training loss: 2.9956390155135666
Validation loss: 2.8996108744539906

Epoch: 6| Step: 8
Training loss: 3.0353823151714137
Validation loss: 2.8988815412822064

Epoch: 6| Step: 9
Training loss: 3.289632208768896
Validation loss: 2.902447389287998

Epoch: 6| Step: 10
Training loss: 3.4301204190928254
Validation loss: 2.9056286367560737

Epoch: 6| Step: 11
Training loss: 3.1744470550356656
Validation loss: 2.9055608355027926

Epoch: 6| Step: 12
Training loss: 3.2890722134190744
Validation loss: 2.9040115474148283

Epoch: 6| Step: 13
Training loss: 4.0365712139794265
Validation loss: 2.9059845442249848

Epoch: 164| Step: 0
Training loss: 3.277008512353769
Validation loss: 2.9044497980444426

Epoch: 6| Step: 1
Training loss: 3.109969805849944
Validation loss: 2.90483789521565

Epoch: 6| Step: 2
Training loss: 3.517529459208398
Validation loss: 2.897486529014736

Epoch: 6| Step: 3
Training loss: 3.078251405240837
Validation loss: 2.8962307501848787

Epoch: 6| Step: 4
Training loss: 3.15102460031643
Validation loss: 2.895772576699902

Epoch: 6| Step: 5
Training loss: 3.4759183479789058
Validation loss: 2.8958480674054243

Epoch: 6| Step: 6
Training loss: 2.6787876586830284
Validation loss: 2.8930351171795774

Epoch: 6| Step: 7
Training loss: 3.3256775359312947
Validation loss: 2.897520994563541

Epoch: 6| Step: 8
Training loss: 2.6812665640935127
Validation loss: 2.893862778818903

Epoch: 6| Step: 9
Training loss: 3.140573225970556
Validation loss: 2.891208774870072

Epoch: 6| Step: 10
Training loss: 3.83374333607754
Validation loss: 2.893533943016661

Epoch: 6| Step: 11
Training loss: 3.1663245133383104
Validation loss: 2.894157741725111

Epoch: 6| Step: 12
Training loss: 2.90149784211245
Validation loss: 2.8954043878871203

Epoch: 6| Step: 13
Training loss: 2.950389745796241
Validation loss: 2.894641908813193

Epoch: 165| Step: 0
Training loss: 3.3595038810670093
Validation loss: 2.8968375969905673

Epoch: 6| Step: 1
Training loss: 3.734822649441111
Validation loss: 2.896965392228887

Epoch: 6| Step: 2
Training loss: 3.362865533069358
Validation loss: 2.8969382279824285

Epoch: 6| Step: 3
Training loss: 3.4685105249718964
Validation loss: 2.893730349586835

Epoch: 6| Step: 4
Training loss: 2.5498108587990234
Validation loss: 2.8920381984379335

Epoch: 6| Step: 5
Training loss: 2.9019934544243005
Validation loss: 2.89400334824021

Epoch: 6| Step: 6
Training loss: 3.102201688996682
Validation loss: 2.8943495940101993

Epoch: 6| Step: 7
Training loss: 3.3691918587590006
Validation loss: 2.896693067453595

Epoch: 6| Step: 8
Training loss: 2.6846106322567844
Validation loss: 2.8960608741694345

Epoch: 6| Step: 9
Training loss: 3.787823220741289
Validation loss: 2.898532834132697

Epoch: 6| Step: 10
Training loss: 2.8213510899312495
Validation loss: 2.896935268713715

Epoch: 6| Step: 11
Training loss: 2.218401491974784
Validation loss: 2.8946434799564975

Epoch: 6| Step: 12
Training loss: 3.710544798300556
Validation loss: 2.8931687372553414

Epoch: 6| Step: 13
Training loss: 2.908977746117145
Validation loss: 2.8947750615103445

Epoch: 166| Step: 0
Training loss: 3.2428272029870198
Validation loss: 2.8967915440837824

Epoch: 6| Step: 1
Training loss: 2.488885491752955
Validation loss: 2.891720652775958

Epoch: 6| Step: 2
Training loss: 3.35787802765866
Validation loss: 2.8923124922416377

Epoch: 6| Step: 3
Training loss: 3.130251629742077
Validation loss: 2.892944528984101

Epoch: 6| Step: 4
Training loss: 2.7016046912371996
Validation loss: 2.8944444764455026

Epoch: 6| Step: 5
Training loss: 3.4772482206463606
Validation loss: 2.901248752982719

Epoch: 6| Step: 6
Training loss: 3.6762523774856306
Validation loss: 2.900534436446906

Epoch: 6| Step: 7
Training loss: 3.338929596658251
Validation loss: 2.8991345026707735

Epoch: 6| Step: 8
Training loss: 2.4562468861179174
Validation loss: 2.910648770886644

Epoch: 6| Step: 9
Training loss: 2.9028415176069764
Validation loss: 2.907371644164723

Epoch: 6| Step: 10
Training loss: 3.4343508080002705
Validation loss: 2.908872575980995

Epoch: 6| Step: 11
Training loss: 2.646251935710388
Validation loss: 2.911627225005474

Epoch: 6| Step: 12
Training loss: 3.8072939488742876
Validation loss: 2.9061143984404714

Epoch: 6| Step: 13
Training loss: 3.7057559168107694
Validation loss: 2.8941423022157777

Epoch: 167| Step: 0
Training loss: 3.5079050710311024
Validation loss: 2.8920600944999055

Epoch: 6| Step: 1
Training loss: 2.7712586346579084
Validation loss: 2.88646047377763

Epoch: 6| Step: 2
Training loss: 3.572720506508584
Validation loss: 2.8896137219064517

Epoch: 6| Step: 3
Training loss: 3.554363663562923
Validation loss: 2.8904675122356434

Epoch: 6| Step: 4
Training loss: 3.109225628969506
Validation loss: 2.889288404196554

Epoch: 6| Step: 5
Training loss: 3.189900410691054
Validation loss: 2.8891055276598525

Epoch: 6| Step: 6
Training loss: 2.938752576923417
Validation loss: 2.889184319496154

Epoch: 6| Step: 7
Training loss: 2.183212874877585
Validation loss: 2.8908175416791533

Epoch: 6| Step: 8
Training loss: 4.031342734519612
Validation loss: 2.8913705331663273

Epoch: 6| Step: 9
Training loss: 3.3930731166850645
Validation loss: 2.8897629223666583

Epoch: 6| Step: 10
Training loss: 2.5005889198924844
Validation loss: 2.889344823841358

Epoch: 6| Step: 11
Training loss: 3.3666462120215344
Validation loss: 2.887136644989351

Epoch: 6| Step: 12
Training loss: 2.882253701240651
Validation loss: 2.8906034708814947

Epoch: 6| Step: 13
Training loss: 2.8797000116830915
Validation loss: 2.8891639819739763

Epoch: 168| Step: 0
Training loss: 3.1761627531172816
Validation loss: 2.890655653108403

Epoch: 6| Step: 1
Training loss: 4.018281644164103
Validation loss: 2.892636346067333

Epoch: 6| Step: 2
Training loss: 2.521309442457721
Validation loss: 2.8886573983779944

Epoch: 6| Step: 3
Training loss: 2.9237860483570586
Validation loss: 2.88629387223411

Epoch: 6| Step: 4
Training loss: 3.559536420663412
Validation loss: 2.886429498120294

Epoch: 6| Step: 5
Training loss: 2.467725420455635
Validation loss: 2.8873869182474907

Epoch: 6| Step: 6
Training loss: 2.7572461808424036
Validation loss: 2.888243236152514

Epoch: 6| Step: 7
Training loss: 3.2517322912067588
Validation loss: 2.887344116107138

Epoch: 6| Step: 8
Training loss: 3.3357629663340767
Validation loss: 2.8849085251562383

Epoch: 6| Step: 9
Training loss: 2.871342862279542
Validation loss: 2.8828066378302433

Epoch: 6| Step: 10
Training loss: 3.238616668300578
Validation loss: 2.8865405083776383

Epoch: 6| Step: 11
Training loss: 3.517288831541604
Validation loss: 2.892091760658304

Epoch: 6| Step: 12
Training loss: 3.115844896337073
Validation loss: 2.8925505056545284

Epoch: 6| Step: 13
Training loss: 3.4752956182308057
Validation loss: 2.913707903034932

Epoch: 169| Step: 0
Training loss: 2.6739902266079114
Validation loss: 2.91600647382227

Epoch: 6| Step: 1
Training loss: 2.609630275277519
Validation loss: 2.9079373132689446

Epoch: 6| Step: 2
Training loss: 3.245757635276104
Validation loss: 2.904287961419888

Epoch: 6| Step: 3
Training loss: 2.826768244081837
Validation loss: 2.8920274254188607

Epoch: 6| Step: 4
Training loss: 3.96960055631044
Validation loss: 2.8885143703876794

Epoch: 6| Step: 5
Training loss: 2.9044109801790565
Validation loss: 2.885235926303207

Epoch: 6| Step: 6
Training loss: 3.0609690673820484
Validation loss: 2.8863638234047957

Epoch: 6| Step: 7
Training loss: 3.7399278799029
Validation loss: 2.885384765841956

Epoch: 6| Step: 8
Training loss: 3.540047279085292
Validation loss: 2.880852218516148

Epoch: 6| Step: 9
Training loss: 2.755657358963735
Validation loss: 2.8808874837381095

Epoch: 6| Step: 10
Training loss: 3.390501521099083
Validation loss: 2.8819040006931376

Epoch: 6| Step: 11
Training loss: 2.652606754437786
Validation loss: 2.880454198543752

Epoch: 6| Step: 12
Training loss: 3.6341918951667918
Validation loss: 2.8832862096413097

Epoch: 6| Step: 13
Training loss: 2.961670475322083
Validation loss: 2.8794518289671465

Epoch: 170| Step: 0
Training loss: 3.2624711134059265
Validation loss: 2.881882536301805

Epoch: 6| Step: 1
Training loss: 2.8344176031609893
Validation loss: 2.8806453063975463

Epoch: 6| Step: 2
Training loss: 2.1703251859597628
Validation loss: 2.882881961179876

Epoch: 6| Step: 3
Training loss: 3.697684109677756
Validation loss: 2.8835961999898143

Epoch: 6| Step: 4
Training loss: 3.17469324146904
Validation loss: 2.8798705278625585

Epoch: 6| Step: 5
Training loss: 3.4637288360885257
Validation loss: 2.8833852143972294

Epoch: 6| Step: 6
Training loss: 3.271810996988091
Validation loss: 2.885768530563187

Epoch: 6| Step: 7
Training loss: 4.238749254114687
Validation loss: 2.8983962373367236

Epoch: 6| Step: 8
Training loss: 2.886944876810211
Validation loss: 2.8895590331325556

Epoch: 6| Step: 9
Training loss: 3.192126338781744
Validation loss: 2.8995379458555455

Epoch: 6| Step: 10
Training loss: 3.1255843569854
Validation loss: 2.9056506200982093

Epoch: 6| Step: 11
Training loss: 2.9437980502149292
Validation loss: 2.892548117100084

Epoch: 6| Step: 12
Training loss: 3.014665045660034
Validation loss: 2.889737696269706

Epoch: 6| Step: 13
Training loss: 2.1602829521781817
Validation loss: 2.894556137619424

Epoch: 171| Step: 0
Training loss: 3.4748396472845795
Validation loss: 2.887281601840399

Epoch: 6| Step: 1
Training loss: 3.2131148703563306
Validation loss: 2.8814629473542404

Epoch: 6| Step: 2
Training loss: 3.669949420299767
Validation loss: 2.8800929215382953

Epoch: 6| Step: 3
Training loss: 3.016813528234011
Validation loss: 2.8780076896536646

Epoch: 6| Step: 4
Training loss: 2.9068612717160978
Validation loss: 2.8766880118061366

Epoch: 6| Step: 5
Training loss: 3.004889318677958
Validation loss: 2.877408163581739

Epoch: 6| Step: 6
Training loss: 2.9147594937651613
Validation loss: 2.87481251908302

Epoch: 6| Step: 7
Training loss: 3.2399450429329177
Validation loss: 2.879109731620895

Epoch: 6| Step: 8
Training loss: 3.3514930700122063
Validation loss: 2.8777896513779537

Epoch: 6| Step: 9
Training loss: 3.38764069887875
Validation loss: 2.8774608826766355

Epoch: 6| Step: 10
Training loss: 3.268389394208979
Validation loss: 2.8777316582153007

Epoch: 6| Step: 11
Training loss: 3.694827541926036
Validation loss: 2.8757552750540447

Epoch: 6| Step: 12
Training loss: 2.5644166802912998
Validation loss: 2.877075510830523

Epoch: 6| Step: 13
Training loss: 1.712738413121045
Validation loss: 2.8770205213447673

Epoch: 172| Step: 0
Training loss: 2.8072679810005456
Validation loss: 2.8750618058133526

Epoch: 6| Step: 1
Training loss: 2.828020462717487
Validation loss: 2.8787574789178345

Epoch: 6| Step: 2
Training loss: 2.725030244431949
Validation loss: 2.8798173098518642

Epoch: 6| Step: 3
Training loss: 3.3292389201001145
Validation loss: 2.8862409121122217

Epoch: 6| Step: 4
Training loss: 2.922478108711584
Validation loss: 2.9049723023277143

Epoch: 6| Step: 5
Training loss: 3.6660408584140907
Validation loss: 2.8944004740001574

Epoch: 6| Step: 6
Training loss: 3.2308409913445972
Validation loss: 2.9085657898872115

Epoch: 6| Step: 7
Training loss: 2.9729924456734245
Validation loss: 2.8839862865042707

Epoch: 6| Step: 8
Training loss: 3.6743026175509548
Validation loss: 2.8779856412497273

Epoch: 6| Step: 9
Training loss: 3.1758528697816732
Validation loss: 2.872096022250352

Epoch: 6| Step: 10
Training loss: 3.697778375036648
Validation loss: 2.8749306979393747

Epoch: 6| Step: 11
Training loss: 3.1072380352006284
Validation loss: 2.8788255579009947

Epoch: 6| Step: 12
Training loss: 2.963880379912979
Validation loss: 2.876861615142269

Epoch: 6| Step: 13
Training loss: 3.026285097154234
Validation loss: 2.8790333416584786

Epoch: 173| Step: 0
Training loss: 3.972608957975023
Validation loss: 2.879434394619956

Epoch: 6| Step: 1
Training loss: 3.065055248266621
Validation loss: 2.8794795285462866

Epoch: 6| Step: 2
Training loss: 3.7745849886507856
Validation loss: 2.876805008602093

Epoch: 6| Step: 3
Training loss: 3.1105632715920035
Validation loss: 2.877416976002242

Epoch: 6| Step: 4
Training loss: 3.5883860487431467
Validation loss: 2.8773182871119114

Epoch: 6| Step: 5
Training loss: 2.5328165552011512
Validation loss: 2.875062600301835

Epoch: 6| Step: 6
Training loss: 2.790392646642498
Validation loss: 2.8781479325041746

Epoch: 6| Step: 7
Training loss: 3.5082675834046038
Validation loss: 2.8719375568010004

Epoch: 6| Step: 8
Training loss: 2.446289647267894
Validation loss: 2.880620526423171

Epoch: 6| Step: 9
Training loss: 3.182337750706281
Validation loss: 2.8838108140640517

Epoch: 6| Step: 10
Training loss: 2.9291547367147834
Validation loss: 2.8865976797923008

Epoch: 6| Step: 11
Training loss: 2.788383764604018
Validation loss: 2.895304848468082

Epoch: 6| Step: 12
Training loss: 3.413694453533081
Validation loss: 2.9093851465668386

Epoch: 6| Step: 13
Training loss: 2.679113387729516
Validation loss: 2.934376068972972

Epoch: 174| Step: 0
Training loss: 3.3020145798193195
Validation loss: 2.9515636522803765

Epoch: 6| Step: 1
Training loss: 2.626966284963552
Validation loss: 2.9592715319205

Epoch: 6| Step: 2
Training loss: 2.741148401300608
Validation loss: 2.953999256412403

Epoch: 6| Step: 3
Training loss: 3.24060608316637
Validation loss: 2.9178601751428004

Epoch: 6| Step: 4
Training loss: 2.8097805014844517
Validation loss: 2.898373681533833

Epoch: 6| Step: 5
Training loss: 3.6771440077720703
Validation loss: 2.886832486982191

Epoch: 6| Step: 6
Training loss: 3.074586334937018
Validation loss: 2.8774543226891027

Epoch: 6| Step: 7
Training loss: 3.571504690176554
Validation loss: 2.8729612729029914

Epoch: 6| Step: 8
Training loss: 3.130659243350134
Validation loss: 2.8732552140570102

Epoch: 6| Step: 9
Training loss: 2.8942086764632298
Validation loss: 2.8744785037391294

Epoch: 6| Step: 10
Training loss: 3.8150638651970463
Validation loss: 2.877183152165912

Epoch: 6| Step: 11
Training loss: 3.124706712311392
Validation loss: 2.882832301631212

Epoch: 6| Step: 12
Training loss: 2.932546781799296
Validation loss: 2.894815933876874

Epoch: 6| Step: 13
Training loss: 3.4536380990753455
Validation loss: 2.892503603656301

Epoch: 175| Step: 0
Training loss: 3.731468442212729
Validation loss: 2.8822591589434334

Epoch: 6| Step: 1
Training loss: 2.6616871555648913
Validation loss: 2.8741547767479023

Epoch: 6| Step: 2
Training loss: 3.33520413987856
Validation loss: 2.8730801203922005

Epoch: 6| Step: 3
Training loss: 3.4861356794311424
Validation loss: 2.8744678388231977

Epoch: 6| Step: 4
Training loss: 2.954183883150524
Validation loss: 2.8746063922453877

Epoch: 6| Step: 5
Training loss: 3.353102963562695
Validation loss: 2.8724006165853884

Epoch: 6| Step: 6
Training loss: 2.691660477323079
Validation loss: 2.874945366738486

Epoch: 6| Step: 7
Training loss: 2.5201501367137573
Validation loss: 2.875579504502814

Epoch: 6| Step: 8
Training loss: 3.5933551073800616
Validation loss: 2.8714985527292662

Epoch: 6| Step: 9
Training loss: 3.5198104696833714
Validation loss: 2.871276480880191

Epoch: 6| Step: 10
Training loss: 2.6761055631472055
Validation loss: 2.8720649961058675

Epoch: 6| Step: 11
Training loss: 3.5548021905862464
Validation loss: 2.8704601216766688

Epoch: 6| Step: 12
Training loss: 2.782805618543218
Validation loss: 2.8699177392586703

Epoch: 6| Step: 13
Training loss: 3.0864177088789586
Validation loss: 2.8703976791145114

Epoch: 176| Step: 0
Training loss: 2.3344264421833563
Validation loss: 2.86915183689375

Epoch: 6| Step: 1
Training loss: 3.1652261736962584
Validation loss: 2.870893484663269

Epoch: 6| Step: 2
Training loss: 3.056835151308122
Validation loss: 2.8754142865786547

Epoch: 6| Step: 3
Training loss: 3.380495753752354
Validation loss: 2.8855609661510364

Epoch: 6| Step: 4
Training loss: 2.488073894298803
Validation loss: 2.9132269064033602

Epoch: 6| Step: 5
Training loss: 3.537458784854039
Validation loss: 2.941489906430389

Epoch: 6| Step: 6
Training loss: 3.912771046180272
Validation loss: 2.9781345363964786

Epoch: 6| Step: 7
Training loss: 3.80274540958851
Validation loss: 2.9641983622698507

Epoch: 6| Step: 8
Training loss: 2.7132793062940688
Validation loss: 2.957443235697556

Epoch: 6| Step: 9
Training loss: 3.027077703783577
Validation loss: 2.947710918321169

Epoch: 6| Step: 10
Training loss: 3.219265794629224
Validation loss: 2.9387609820686453

Epoch: 6| Step: 11
Training loss: 3.1580136347857453
Validation loss: 2.9312822169384876

Epoch: 6| Step: 12
Training loss: 4.007960028656548
Validation loss: 2.925660919585074

Epoch: 6| Step: 13
Training loss: 2.0507353277968545
Validation loss: 2.9263774336093493

Epoch: 177| Step: 0
Training loss: 2.6125994649688398
Validation loss: 2.928115424249764

Epoch: 6| Step: 1
Training loss: 3.7082034027539925
Validation loss: 2.924123760613682

Epoch: 6| Step: 2
Training loss: 3.2537935564875267
Validation loss: 2.930767011715839

Epoch: 6| Step: 3
Training loss: 3.4142295394991637
Validation loss: 2.9305039709907788

Epoch: 6| Step: 4
Training loss: 3.466521500947069
Validation loss: 2.9276864473408954

Epoch: 6| Step: 5
Training loss: 2.791334920121823
Validation loss: 2.9280052643953938

Epoch: 6| Step: 6
Training loss: 3.645285835937093
Validation loss: 2.9269002215531623

Epoch: 6| Step: 7
Training loss: 2.9013749118985865
Validation loss: 2.924429528245549

Epoch: 6| Step: 8
Training loss: 3.4542759146782935
Validation loss: 2.9245236469133613

Epoch: 6| Step: 9
Training loss: 2.6117250744249256
Validation loss: 2.927782263347012

Epoch: 6| Step: 10
Training loss: 2.902807514417599
Validation loss: 2.929779339188323

Epoch: 6| Step: 11
Training loss: 3.060006196757506
Validation loss: 2.926502596851217

Epoch: 6| Step: 12
Training loss: 3.2066703714149734
Validation loss: 2.9255909839732386

Epoch: 6| Step: 13
Training loss: 4.013322340695692
Validation loss: 2.924794270955027

Epoch: 178| Step: 0
Training loss: 3.9670023036187545
Validation loss: 2.922369047841443

Epoch: 6| Step: 1
Training loss: 4.267450298428858
Validation loss: 2.9253865894805644

Epoch: 6| Step: 2
Training loss: 2.6256606769203685
Validation loss: 2.922126140223878

Epoch: 6| Step: 3
Training loss: 3.2639173213360624
Validation loss: 2.9246030606348774

Epoch: 6| Step: 4
Training loss: 3.4337901123281345
Validation loss: 2.9259390414748103

Epoch: 6| Step: 5
Training loss: 2.9054789186788477
Validation loss: 2.922502275875496

Epoch: 6| Step: 6
Training loss: 2.291199503590354
Validation loss: 2.9195281452471966

Epoch: 6| Step: 7
Training loss: 3.3980047542365877
Validation loss: 2.9207901093507065

Epoch: 6| Step: 8
Training loss: 3.114620978256552
Validation loss: 2.9230734803234837

Epoch: 6| Step: 9
Training loss: 3.417177363739539
Validation loss: 2.9238930064385915

Epoch: 6| Step: 10
Training loss: 2.500868265055678
Validation loss: 2.9202672459104284

Epoch: 6| Step: 11
Training loss: 2.47551717267661
Validation loss: 2.921059629426995

Epoch: 6| Step: 12
Training loss: 3.085823153538146
Validation loss: 2.920743056070927

Epoch: 6| Step: 13
Training loss: 3.7254465539539265
Validation loss: 2.9206405891560023

Epoch: 179| Step: 0
Training loss: 2.971870147989927
Validation loss: 2.926619308616988

Epoch: 6| Step: 1
Training loss: 3.7249522058889863
Validation loss: 2.937651555906535

Epoch: 6| Step: 2
Training loss: 2.839248279965682
Validation loss: 2.9456888515847433

Epoch: 6| Step: 3
Training loss: 3.756662680604902
Validation loss: 2.950929357539369

Epoch: 6| Step: 4
Training loss: 3.3369635047185833
Validation loss: 2.947857560949752

Epoch: 6| Step: 5
Training loss: 2.7501768575498438
Validation loss: 2.9413906828519534

Epoch: 6| Step: 6
Training loss: 3.5701530304067446
Validation loss: 2.9312572309575944

Epoch: 6| Step: 7
Training loss: 3.1409001016406632
Validation loss: 2.923710780090226

Epoch: 6| Step: 8
Training loss: 2.785867180313896
Validation loss: 2.9258512121691913

Epoch: 6| Step: 9
Training loss: 2.6421159677054677
Validation loss: 2.9194147503482415

Epoch: 6| Step: 10
Training loss: 3.3315606807957465
Validation loss: 2.9208583163016453

Epoch: 6| Step: 11
Training loss: 2.5656617360615526
Validation loss: 2.9210746598618837

Epoch: 6| Step: 12
Training loss: 3.325693594503481
Validation loss: 2.9198662665637505

Epoch: 6| Step: 13
Training loss: 4.154157527708193
Validation loss: 2.9173699850892887

Epoch: 180| Step: 0
Training loss: 2.7526391976592635
Validation loss: 2.9144814639396945

Epoch: 6| Step: 1
Training loss: 3.6094711753285056
Validation loss: 2.9127600235368756

Epoch: 6| Step: 2
Training loss: 3.6689794933279387
Validation loss: 2.9137246114345743

Epoch: 6| Step: 3
Training loss: 3.4874812081216944
Validation loss: 2.913888971579699

Epoch: 6| Step: 4
Training loss: 3.43744562279434
Validation loss: 2.913178476062705

Epoch: 6| Step: 5
Training loss: 3.0698776131256946
Validation loss: 2.9143009125102486

Epoch: 6| Step: 6
Training loss: 2.7742307576226075
Validation loss: 2.9147029882024285

Epoch: 6| Step: 7
Training loss: 3.9078296366624334
Validation loss: 2.915547987583118

Epoch: 6| Step: 8
Training loss: 2.9760910021188978
Validation loss: 2.9149894688287854

Epoch: 6| Step: 9
Training loss: 2.9681720371820717
Validation loss: 2.915220678013903

Epoch: 6| Step: 10
Training loss: 3.138614751347009
Validation loss: 2.9114366081085135

Epoch: 6| Step: 11
Training loss: 3.193335931441087
Validation loss: 2.914861690727144

Epoch: 6| Step: 12
Training loss: 2.766217787839917
Validation loss: 2.9184068732881694

Epoch: 6| Step: 13
Training loss: 2.5122822415703645
Validation loss: 2.92247678938044

Epoch: 181| Step: 0
Training loss: 3.0586584481403563
Validation loss: 2.922011058096943

Epoch: 6| Step: 1
Training loss: 2.7443030909980095
Validation loss: 2.919896927895483

Epoch: 6| Step: 2
Training loss: 3.976904474029599
Validation loss: 2.9213628648570418

Epoch: 6| Step: 3
Training loss: 3.431822926646058
Validation loss: 2.919614673795421

Epoch: 6| Step: 4
Training loss: 3.070143833332346
Validation loss: 2.9201299134706677

Epoch: 6| Step: 5
Training loss: 2.4982578883402033
Validation loss: 2.9215321085464856

Epoch: 6| Step: 6
Training loss: 2.0235939701808623
Validation loss: 2.917937300528609

Epoch: 6| Step: 7
Training loss: 3.240918308620922
Validation loss: 2.921000087924029

Epoch: 6| Step: 8
Training loss: 2.8516083178039975
Validation loss: 2.9187578137993144

Epoch: 6| Step: 9
Training loss: 4.131243056206343
Validation loss: 2.9216822052314115

Epoch: 6| Step: 10
Training loss: 2.433945338046821
Validation loss: 2.917553522197046

Epoch: 6| Step: 11
Training loss: 3.486260558256326
Validation loss: 2.92054975031562

Epoch: 6| Step: 12
Training loss: 3.222892983729108
Validation loss: 2.921105671847257

Epoch: 6| Step: 13
Training loss: 4.3608188220734645
Validation loss: 2.9230169206025063

Epoch: 182| Step: 0
Training loss: 2.734999579895099
Validation loss: 2.9198539446951073

Epoch: 6| Step: 1
Training loss: 3.3536633573949977
Validation loss: 2.9229708530328864

Epoch: 6| Step: 2
Training loss: 3.2126443971473053
Validation loss: 2.92042517554329

Epoch: 6| Step: 3
Training loss: 3.4561602341099253
Validation loss: 2.920284505834037

Epoch: 6| Step: 4
Training loss: 3.3959693803429034
Validation loss: 2.9171537411564303

Epoch: 6| Step: 5
Training loss: 2.741453762735263
Validation loss: 2.9138872718048616

Epoch: 6| Step: 6
Training loss: 2.9712921501639613
Validation loss: 2.912410677992924

Epoch: 6| Step: 7
Training loss: 3.2913004675508124
Validation loss: 2.911139353837161

Epoch: 6| Step: 8
Training loss: 3.600561304838442
Validation loss: 2.911202765650171

Epoch: 6| Step: 9
Training loss: 2.887618362180679
Validation loss: 2.909454447397509

Epoch: 6| Step: 10
Training loss: 3.4211132299021503
Validation loss: 2.90823883517569

Epoch: 6| Step: 11
Training loss: 2.8279541975680016
Validation loss: 2.909027839730447

Epoch: 6| Step: 12
Training loss: 3.2497624530543363
Validation loss: 2.9056115959340625

Epoch: 6| Step: 13
Training loss: 3.5613437583206147
Validation loss: 2.89683720936971

Epoch: 183| Step: 0
Training loss: 1.6603775415473594
Validation loss: 2.850956824700351

Epoch: 6| Step: 1
Training loss: 3.270962819899523
Validation loss: 2.85456552062191

Epoch: 6| Step: 2
Training loss: 3.130766012283485
Validation loss: 2.8572176752094833

Epoch: 6| Step: 3
Training loss: 3.0615768598309505
Validation loss: 2.853382207284961

Epoch: 6| Step: 4
Training loss: 3.564970799309127
Validation loss: 2.8554959837437415

Epoch: 6| Step: 5
Training loss: 3.305489372922992
Validation loss: 2.8689916629526797

Epoch: 6| Step: 6
Training loss: 3.1741398584888407
Validation loss: 2.8587670404175354

Epoch: 6| Step: 7
Training loss: 3.1335711618891846
Validation loss: 2.8555692964740373

Epoch: 6| Step: 8
Training loss: 3.5187263880965665
Validation loss: 2.859090128183115

Epoch: 6| Step: 9
Training loss: 3.2410933889030136
Validation loss: 2.860662749426026

Epoch: 6| Step: 10
Training loss: 2.861367120574718
Validation loss: 2.868721445829659

Epoch: 6| Step: 11
Training loss: 2.52554809362597
Validation loss: 2.877917735700768

Epoch: 6| Step: 12
Training loss: 3.9051624462612886
Validation loss: 2.8857704903147265

Epoch: 6| Step: 13
Training loss: 3.2966529807593212
Validation loss: 2.8885558824892104

Epoch: 184| Step: 0
Training loss: 2.8497977871014224
Validation loss: 2.9204893267502863

Epoch: 6| Step: 1
Training loss: 2.78383079545167
Validation loss: 2.9176950941527067

Epoch: 6| Step: 2
Training loss: 3.6419667403301337
Validation loss: 2.917674408837814

Epoch: 6| Step: 3
Training loss: 3.319975281588905
Validation loss: 2.9237447690281906

Epoch: 6| Step: 4
Training loss: 3.3449318481710044
Validation loss: 2.91566006625163

Epoch: 6| Step: 5
Training loss: 2.7224399475256202
Validation loss: 2.901119690135253

Epoch: 6| Step: 6
Training loss: 3.0326629177273547
Validation loss: 2.89511691497698

Epoch: 6| Step: 7
Training loss: 2.94077994478587
Validation loss: 2.888226045711168

Epoch: 6| Step: 8
Training loss: 3.79478202244073
Validation loss: 2.8955621410154344

Epoch: 6| Step: 9
Training loss: 2.8922591255671177
Validation loss: 2.872423236220013

Epoch: 6| Step: 10
Training loss: 3.346933151010636
Validation loss: 2.8679591079440643

Epoch: 6| Step: 11
Training loss: 3.1904060729536226
Validation loss: 2.8572579560996703

Epoch: 6| Step: 12
Training loss: 3.4893648145589524
Validation loss: 2.847353187214859

Epoch: 6| Step: 13
Training loss: 2.8749011478844664
Validation loss: 2.8488661702084297

Epoch: 185| Step: 0
Training loss: 3.3615003383215853
Validation loss: 2.8470289223923406

Epoch: 6| Step: 1
Training loss: 3.204772823096241
Validation loss: 2.84325663927303

Epoch: 6| Step: 2
Training loss: 2.5862386015340775
Validation loss: 2.8468036395612604

Epoch: 6| Step: 3
Training loss: 3.42846338067784
Validation loss: 2.847243661813946

Epoch: 6| Step: 4
Training loss: 3.11505252702001
Validation loss: 2.846935128751849

Epoch: 6| Step: 5
Training loss: 3.2138238635601626
Validation loss: 2.845578293451089

Epoch: 6| Step: 6
Training loss: 3.51229144254405
Validation loss: 2.8489674608167204

Epoch: 6| Step: 7
Training loss: 3.1292271824524684
Validation loss: 2.8462233120632283

Epoch: 6| Step: 8
Training loss: 2.4749419388559417
Validation loss: 2.848816898146136

Epoch: 6| Step: 9
Training loss: 3.476483359132571
Validation loss: 2.8570895933864544

Epoch: 6| Step: 10
Training loss: 2.768038800866163
Validation loss: 2.852150086916871

Epoch: 6| Step: 11
Training loss: 2.758987219791601
Validation loss: 2.8523115814081392

Epoch: 6| Step: 12
Training loss: 3.6166672795964674
Validation loss: 2.851477851459741

Epoch: 6| Step: 13
Training loss: 3.174506387862464
Validation loss: 2.851698516420245

Epoch: 186| Step: 0
Training loss: 2.8519286874252625
Validation loss: 2.848586452753637

Epoch: 6| Step: 1
Training loss: 3.465367360423421
Validation loss: 2.857918151945312

Epoch: 6| Step: 2
Training loss: 2.2889991725455174
Validation loss: 2.853847117208456

Epoch: 6| Step: 3
Training loss: 3.021580325318775
Validation loss: 2.857970491419761

Epoch: 6| Step: 4
Training loss: 3.4177728738516735
Validation loss: 2.8643045621271894

Epoch: 6| Step: 5
Training loss: 3.4262180028212517
Validation loss: 2.8579283744901436

Epoch: 6| Step: 6
Training loss: 3.1948167187770173
Validation loss: 2.857791064970685

Epoch: 6| Step: 7
Training loss: 3.318789287557298
Validation loss: 2.8609680072359547

Epoch: 6| Step: 8
Training loss: 2.9928267869213
Validation loss: 2.8618287195648824

Epoch: 6| Step: 9
Training loss: 3.411908550499297
Validation loss: 2.866270771028539

Epoch: 6| Step: 10
Training loss: 2.9417401817004265
Validation loss: 2.86673347271769

Epoch: 6| Step: 11
Training loss: 3.4529614992400908
Validation loss: 2.8654937520488906

Epoch: 6| Step: 12
Training loss: 2.940158371584769
Validation loss: 2.855885126593558

Epoch: 6| Step: 13
Training loss: 3.087030685524383
Validation loss: 2.85020226662328

Epoch: 187| Step: 0
Training loss: 3.305967691696342
Validation loss: 2.8484609609564533

Epoch: 6| Step: 1
Training loss: 3.327816084731671
Validation loss: 2.844692860478153

Epoch: 6| Step: 2
Training loss: 2.705609012661388
Validation loss: 2.8448486342487107

Epoch: 6| Step: 3
Training loss: 3.625664091118141
Validation loss: 2.8452803397441464

Epoch: 6| Step: 4
Training loss: 2.44796423899641
Validation loss: 2.843068380702441

Epoch: 6| Step: 5
Training loss: 2.4243639554280842
Validation loss: 2.8434365005173774

Epoch: 6| Step: 6
Training loss: 3.2254024757185102
Validation loss: 2.8456095273024364

Epoch: 6| Step: 7
Training loss: 2.0113254792326987
Validation loss: 2.8470958376197286

Epoch: 6| Step: 8
Training loss: 3.629705072197025
Validation loss: 2.846302836123183

Epoch: 6| Step: 9
Training loss: 2.900555353592296
Validation loss: 2.8431006367090883

Epoch: 6| Step: 10
Training loss: 3.1613429308739844
Validation loss: 2.845309949650297

Epoch: 6| Step: 11
Training loss: 3.3967280857072475
Validation loss: 2.8463437146118946

Epoch: 6| Step: 12
Training loss: 3.893127127068245
Validation loss: 2.8436684320113486

Epoch: 6| Step: 13
Training loss: 3.5195737914500262
Validation loss: 2.8432719682927012

Epoch: 188| Step: 0
Training loss: 2.433447378786874
Validation loss: 2.8448645638655248

Epoch: 6| Step: 1
Training loss: 3.3970665281988928
Validation loss: 2.8429069472896464

Epoch: 6| Step: 2
Training loss: 2.53098220350504
Validation loss: 2.8456170679166646

Epoch: 6| Step: 3
Training loss: 3.780951622153791
Validation loss: 2.845989664688895

Epoch: 6| Step: 4
Training loss: 3.6008869456071437
Validation loss: 2.849138862505318

Epoch: 6| Step: 5
Training loss: 3.3657350881665984
Validation loss: 2.84833902332075

Epoch: 6| Step: 6
Training loss: 2.775438043885905
Validation loss: 2.850381210211699

Epoch: 6| Step: 7
Training loss: 2.9308298554091166
Validation loss: 2.8457143733812633

Epoch: 6| Step: 8
Training loss: 3.6302767527776463
Validation loss: 2.8463594079911103

Epoch: 6| Step: 9
Training loss: 3.325758258147784
Validation loss: 2.8474932706567673

Epoch: 6| Step: 10
Training loss: 3.3602742255794764
Validation loss: 2.845617938194153

Epoch: 6| Step: 11
Training loss: 3.29446887399823
Validation loss: 2.845956301012419

Epoch: 6| Step: 12
Training loss: 2.268187973985677
Validation loss: 2.850493683700165

Epoch: 6| Step: 13
Training loss: 2.5258794253968393
Validation loss: 2.8465421019564707

Epoch: 189| Step: 0
Training loss: 3.3718221326188833
Validation loss: 2.844293233485051

Epoch: 6| Step: 1
Training loss: 3.0286311211834107
Validation loss: 2.840325445532071

Epoch: 6| Step: 2
Training loss: 2.9662387867943476
Validation loss: 2.842288328908761

Epoch: 6| Step: 3
Training loss: 2.9074059925314377
Validation loss: 2.842886839610391

Epoch: 6| Step: 4
Training loss: 2.8223933524297857
Validation loss: 2.840631638865975

Epoch: 6| Step: 5
Training loss: 3.590187761927439
Validation loss: 2.8435392187829933

Epoch: 6| Step: 6
Training loss: 2.777106724321243
Validation loss: 2.8415855708892366

Epoch: 6| Step: 7
Training loss: 3.388502168390988
Validation loss: 2.8502140288268993

Epoch: 6| Step: 8
Training loss: 3.0041945062441706
Validation loss: 2.861275476009601

Epoch: 6| Step: 9
Training loss: 3.078160009814387
Validation loss: 2.8736049108235266

Epoch: 6| Step: 10
Training loss: 2.8197786877411772
Validation loss: 2.88749662918571

Epoch: 6| Step: 11
Training loss: 3.100778014473778
Validation loss: 2.891800069277707

Epoch: 6| Step: 12
Training loss: 3.083172991595826
Validation loss: 2.8955736348515377

Epoch: 6| Step: 13
Training loss: 4.419085913681697
Validation loss: 2.8834583719362725

Epoch: 190| Step: 0
Training loss: 3.3417686224879657
Validation loss: 2.86951289667202

Epoch: 6| Step: 1
Training loss: 3.082088184676908
Validation loss: 2.8629798188248

Epoch: 6| Step: 2
Training loss: 2.98085989329089
Validation loss: 2.855046116950487

Epoch: 6| Step: 3
Training loss: 3.512438334402259
Validation loss: 2.8547353127889497

Epoch: 6| Step: 4
Training loss: 3.339559192693171
Validation loss: 2.846526901323343

Epoch: 6| Step: 5
Training loss: 2.698292729349297
Validation loss: 2.8501427325963373

Epoch: 6| Step: 6
Training loss: 3.5562681603261326
Validation loss: 2.8492476312365795

Epoch: 6| Step: 7
Training loss: 2.377510450562815
Validation loss: 2.8548573310332337

Epoch: 6| Step: 8
Training loss: 3.320751636861122
Validation loss: 2.851387849056411

Epoch: 6| Step: 9
Training loss: 3.624762691754207
Validation loss: 2.857915116391438

Epoch: 6| Step: 10
Training loss: 2.7023966254437406
Validation loss: 2.8568211992622947

Epoch: 6| Step: 11
Training loss: 3.1826522464699862
Validation loss: 2.8556282271966738

Epoch: 6| Step: 12
Training loss: 3.024482172001092
Validation loss: 2.860848342937238

Epoch: 6| Step: 13
Training loss: 2.816440111186876
Validation loss: 2.8493999998132837

Epoch: 191| Step: 0
Training loss: 3.748500015354449
Validation loss: 2.8409986143801285

Epoch: 6| Step: 1
Training loss: 3.218199155023132
Validation loss: 2.8385688057164975

Epoch: 6| Step: 2
Training loss: 3.0839420095847205
Validation loss: 2.8394761927621297

Epoch: 6| Step: 3
Training loss: 3.2171951538409895
Validation loss: 2.838923119192248

Epoch: 6| Step: 4
Training loss: 3.176865883978673
Validation loss: 2.839082699562965

Epoch: 6| Step: 5
Training loss: 2.2656017433814437
Validation loss: 2.8378134796043577

Epoch: 6| Step: 6
Training loss: 2.806931302090552
Validation loss: 2.8377367259984014

Epoch: 6| Step: 7
Training loss: 3.0748104316150373
Validation loss: 2.838023087199846

Epoch: 6| Step: 8
Training loss: 3.578369398807408
Validation loss: 2.8346508034617535

Epoch: 6| Step: 9
Training loss: 2.8479372155416263
Validation loss: 2.8327682279620725

Epoch: 6| Step: 10
Training loss: 2.6757742108997284
Validation loss: 2.8308847288040284

Epoch: 6| Step: 11
Training loss: 2.9431879693579943
Validation loss: 2.8321119845335496

Epoch: 6| Step: 12
Training loss: 3.7174545724500763
Validation loss: 2.8323555102938105

Epoch: 6| Step: 13
Training loss: 3.476776870804739
Validation loss: 2.8287826133396896

Epoch: 192| Step: 0
Training loss: 1.7998174707266121
Validation loss: 2.8324624544268135

Epoch: 6| Step: 1
Training loss: 3.611194762866778
Validation loss: 2.8397965688030746

Epoch: 6| Step: 2
Training loss: 2.968441756458566
Validation loss: 2.861789556491492

Epoch: 6| Step: 3
Training loss: 3.3901501863682695
Validation loss: 2.848585154097499

Epoch: 6| Step: 4
Training loss: 3.4693073821518077
Validation loss: 2.842942280117994

Epoch: 6| Step: 5
Training loss: 2.220221340555015
Validation loss: 2.84428575425692

Epoch: 6| Step: 6
Training loss: 3.576892490587492
Validation loss: 2.83796332297485

Epoch: 6| Step: 7
Training loss: 3.0076793294383077
Validation loss: 2.8356793340722724

Epoch: 6| Step: 8
Training loss: 3.1946916420055316
Validation loss: 2.8325872150653457

Epoch: 6| Step: 9
Training loss: 3.1985384225879616
Validation loss: 2.8342209758041004

Epoch: 6| Step: 10
Training loss: 3.260388131468747
Validation loss: 2.832706340118747

Epoch: 6| Step: 11
Training loss: 3.4254191956539555
Validation loss: 2.8326094539323705

Epoch: 6| Step: 12
Training loss: 3.3358949037642
Validation loss: 2.837264098248657

Epoch: 6| Step: 13
Training loss: 2.7734381017549965
Validation loss: 2.8331196002825454

Epoch: 193| Step: 0
Training loss: 3.3382474598066083
Validation loss: 2.833735955553728

Epoch: 6| Step: 1
Training loss: 3.141391338017952
Validation loss: 2.832612967317091

Epoch: 6| Step: 2
Training loss: 3.3219687964474187
Validation loss: 2.8291940363151005

Epoch: 6| Step: 3
Training loss: 2.2693167238729615
Validation loss: 2.8273577504019833

Epoch: 6| Step: 4
Training loss: 2.862089275895034
Validation loss: 2.8269011929901757

Epoch: 6| Step: 5
Training loss: 2.977197934706296
Validation loss: 2.827530761248515

Epoch: 6| Step: 6
Training loss: 3.3792827418499973
Validation loss: 2.8275055973847714

Epoch: 6| Step: 7
Training loss: 2.629888795887642
Validation loss: 2.8274601216149424

Epoch: 6| Step: 8
Training loss: 2.571669292914219
Validation loss: 2.8272384045207923

Epoch: 6| Step: 9
Training loss: 3.157362033853163
Validation loss: 2.8243828318502637

Epoch: 6| Step: 10
Training loss: 3.1964519679498773
Validation loss: 2.8255688674508637

Epoch: 6| Step: 11
Training loss: 3.9712422873158255
Validation loss: 2.824502914679924

Epoch: 6| Step: 12
Training loss: 3.4550303730271374
Validation loss: 2.825132418472996

Epoch: 6| Step: 13
Training loss: 3.402302265461787
Validation loss: 2.827693766960334

Epoch: 194| Step: 0
Training loss: 2.4651491003228405
Validation loss: 2.824825889187014

Epoch: 6| Step: 1
Training loss: 2.7564908499812355
Validation loss: 2.8228345097000207

Epoch: 6| Step: 2
Training loss: 2.6756985616785665
Validation loss: 2.8236636376185276

Epoch: 6| Step: 3
Training loss: 3.4238204651315485
Validation loss: 2.826372130851579

Epoch: 6| Step: 4
Training loss: 3.426383893063006
Validation loss: 2.8300806776984535

Epoch: 6| Step: 5
Training loss: 3.315574514739937
Validation loss: 2.826153852538238

Epoch: 6| Step: 6
Training loss: 2.9273077900217417
Validation loss: 2.8304150467988043

Epoch: 6| Step: 7
Training loss: 3.5017069332731436
Validation loss: 2.8303816680044545

Epoch: 6| Step: 8
Training loss: 3.05797787990516
Validation loss: 2.8367538929086438

Epoch: 6| Step: 9
Training loss: 2.6973331561739844
Validation loss: 2.834923570885374

Epoch: 6| Step: 10
Training loss: 3.5740785331529885
Validation loss: 2.8244959566792027

Epoch: 6| Step: 11
Training loss: 3.4736647970396315
Validation loss: 2.8238985366915625

Epoch: 6| Step: 12
Training loss: 3.1554231977090845
Validation loss: 2.825014847079273

Epoch: 6| Step: 13
Training loss: 3.161292250333177
Validation loss: 2.8242795984151927

Epoch: 195| Step: 0
Training loss: 2.91522913429743
Validation loss: 2.8218312888697783

Epoch: 6| Step: 1
Training loss: 2.828736971405004
Validation loss: 2.8210263658178634

Epoch: 6| Step: 2
Training loss: 2.933513452317333
Validation loss: 2.8235970940823303

Epoch: 6| Step: 3
Training loss: 3.5978842133937943
Validation loss: 2.82209416271102

Epoch: 6| Step: 4
Training loss: 3.703268828999108
Validation loss: 2.823380775898117

Epoch: 6| Step: 5
Training loss: 2.649178190379255
Validation loss: 2.8232780370244024

Epoch: 6| Step: 6
Training loss: 3.0207989043981374
Validation loss: 2.8243625677834174

Epoch: 6| Step: 7
Training loss: 3.074747779240571
Validation loss: 2.827079632777431

Epoch: 6| Step: 8
Training loss: 2.5841384576485718
Validation loss: 2.826797102900531

Epoch: 6| Step: 9
Training loss: 3.0947660068683813
Validation loss: 2.8262956579412952

Epoch: 6| Step: 10
Training loss: 3.335104344693016
Validation loss: 2.822132988221699

Epoch: 6| Step: 11
Training loss: 3.272105526385979
Validation loss: 2.825212014435562

Epoch: 6| Step: 12
Training loss: 3.601028369676344
Validation loss: 2.825453703239604

Epoch: 6| Step: 13
Training loss: 2.9577150549456994
Validation loss: 2.8244594654696225

Epoch: 196| Step: 0
Training loss: 3.1046189015013694
Validation loss: 2.8217853019181134

Epoch: 6| Step: 1
Training loss: 3.4188737641131772
Validation loss: 2.8205894089074537

Epoch: 6| Step: 2
Training loss: 3.1034366508792326
Validation loss: 2.8230313888999996

Epoch: 6| Step: 3
Training loss: 2.986168447333407
Validation loss: 2.8251817320095483

Epoch: 6| Step: 4
Training loss: 3.296068716666167
Validation loss: 2.8186249610854843

Epoch: 6| Step: 5
Training loss: 3.7628205172362503
Validation loss: 2.8242360536348214

Epoch: 6| Step: 6
Training loss: 2.9463926403942886
Validation loss: 2.8212867108428026

Epoch: 6| Step: 7
Training loss: 2.4397439653486344
Validation loss: 2.8202692943848744

Epoch: 6| Step: 8
Training loss: 2.7323600974744355
Validation loss: 2.8259474468799466

Epoch: 6| Step: 9
Training loss: 3.2342224085098907
Validation loss: 2.8307879509822835

Epoch: 6| Step: 10
Training loss: 3.156704105153842
Validation loss: 2.837172598591798

Epoch: 6| Step: 11
Training loss: 2.3628538643765964
Validation loss: 2.853103262347181

Epoch: 6| Step: 12
Training loss: 3.548373405788108
Validation loss: 2.8668201711162924

Epoch: 6| Step: 13
Training loss: 3.669734509503277
Validation loss: 2.8700450020643014

Epoch: 197| Step: 0
Training loss: 3.5704409786955775
Validation loss: 2.8595803761582634

Epoch: 6| Step: 1
Training loss: 3.2517050158730427
Validation loss: 2.8446806662985034

Epoch: 6| Step: 2
Training loss: 3.6110856927482478
Validation loss: 2.8404699442194214

Epoch: 6| Step: 3
Training loss: 3.164937668317646
Validation loss: 2.8485631209514377

Epoch: 6| Step: 4
Training loss: 3.30541392609751
Validation loss: 2.835179694266555

Epoch: 6| Step: 5
Training loss: 2.9436114430469114
Validation loss: 2.8269488197502035

Epoch: 6| Step: 6
Training loss: 3.226744565837845
Validation loss: 2.829635928097224

Epoch: 6| Step: 7
Training loss: 2.9453005196001367
Validation loss: 2.8184058844795685

Epoch: 6| Step: 8
Training loss: 2.4222185444974054
Validation loss: 2.8194452158433854

Epoch: 6| Step: 9
Training loss: 3.770436485582151
Validation loss: 2.8202235164903775

Epoch: 6| Step: 10
Training loss: 2.919685073487332
Validation loss: 2.8199962376944936

Epoch: 6| Step: 11
Training loss: 2.816913955788136
Validation loss: 2.821968095120232

Epoch: 6| Step: 12
Training loss: 2.4758486516173264
Validation loss: 2.821849320768765

Epoch: 6| Step: 13
Training loss: 3.0043476708035954
Validation loss: 2.8220788962540033

Epoch: 198| Step: 0
Training loss: 3.5213752344602693
Validation loss: 2.8180095300924566

Epoch: 6| Step: 1
Training loss: 3.049333411994714
Validation loss: 2.8178228327320154

Epoch: 6| Step: 2
Training loss: 3.1052820305501743
Validation loss: 2.817659065814099

Epoch: 6| Step: 3
Training loss: 3.0858905257500733
Validation loss: 2.818494255924773

Epoch: 6| Step: 4
Training loss: 2.715386952457183
Validation loss: 2.81620727635409

Epoch: 6| Step: 5
Training loss: 2.8964917831686283
Validation loss: 2.816965622851348

Epoch: 6| Step: 6
Training loss: 2.834374872142448
Validation loss: 2.8200150440518494

Epoch: 6| Step: 7
Training loss: 3.1948334351105983
Validation loss: 2.837939395252152

Epoch: 6| Step: 8
Training loss: 2.585055566777085
Validation loss: 2.832186405852471

Epoch: 6| Step: 9
Training loss: 3.613496087363133
Validation loss: 2.8277293125444514

Epoch: 6| Step: 10
Training loss: 3.5857715443624367
Validation loss: 2.830345807009383

Epoch: 6| Step: 11
Training loss: 2.6389962313944224
Validation loss: 2.831452304162881

Epoch: 6| Step: 12
Training loss: 3.640994859498504
Validation loss: 2.835702627231303

Epoch: 6| Step: 13
Training loss: 2.946242774951283
Validation loss: 2.8360528947587738

Epoch: 199| Step: 0
Training loss: 3.273992013510236
Validation loss: 2.8316344325807745

Epoch: 6| Step: 1
Training loss: 3.0498267327793536
Validation loss: 2.832828386855418

Epoch: 6| Step: 2
Training loss: 2.196040999879245
Validation loss: 2.834562197711132

Epoch: 6| Step: 3
Training loss: 3.6237563268916153
Validation loss: 2.833624117899521

Epoch: 6| Step: 4
Training loss: 3.0631397124137374
Validation loss: 2.8289789499075964

Epoch: 6| Step: 5
Training loss: 3.2413237742580288
Validation loss: 2.828562152774655

Epoch: 6| Step: 6
Training loss: 2.730661890187159
Validation loss: 2.8265955439096495

Epoch: 6| Step: 7
Training loss: 2.9443260584929623
Validation loss: 2.8287275985945786

Epoch: 6| Step: 8
Training loss: 3.4452015000366076
Validation loss: 2.8226843254982055

Epoch: 6| Step: 9
Training loss: 2.938102822641021
Validation loss: 2.823971922587909

Epoch: 6| Step: 10
Training loss: 3.154747936015637
Validation loss: 2.825325212227719

Epoch: 6| Step: 11
Training loss: 3.2449111712366348
Validation loss: 2.8158737347540375

Epoch: 6| Step: 12
Training loss: 3.3371216863177153
Validation loss: 2.8214422076829475

Epoch: 6| Step: 13
Training loss: 3.368286803042287
Validation loss: 2.816602330663266

Epoch: 200| Step: 0
Training loss: 3.3903825383138577
Validation loss: 2.815028675682037

Epoch: 6| Step: 1
Training loss: 2.8348840695852595
Validation loss: 2.8148298328046013

Epoch: 6| Step: 2
Training loss: 3.226264995316926
Validation loss: 2.81404776513097

Epoch: 6| Step: 3
Training loss: 3.1148449501894477
Validation loss: 2.8144081807081704

Epoch: 6| Step: 4
Training loss: 2.694856024525229
Validation loss: 2.8143182180079545

Epoch: 6| Step: 5
Training loss: 3.5672630459124974
Validation loss: 2.8152748657125484

Epoch: 6| Step: 6
Training loss: 4.087605764904711
Validation loss: 2.8147330822385777

Epoch: 6| Step: 7
Training loss: 3.3688051803117833
Validation loss: 2.814877102332474

Epoch: 6| Step: 8
Training loss: 2.2433329457608133
Validation loss: 2.817299189876036

Epoch: 6| Step: 9
Training loss: 3.30162739940428
Validation loss: 2.8145701866589454

Epoch: 6| Step: 10
Training loss: 2.7776398105266824
Validation loss: 2.818475516734569

Epoch: 6| Step: 11
Training loss: 2.897850779248984
Validation loss: 2.8187296667344013

Epoch: 6| Step: 12
Training loss: 2.6777669625000122
Validation loss: 2.821743903208692

Epoch: 6| Step: 13
Training loss: 3.0885394366011307
Validation loss: 2.8361719854272787

Epoch: 201| Step: 0
Training loss: 2.9886747213381755
Validation loss: 2.8350625983152344

Epoch: 6| Step: 1
Training loss: 3.794797729409159
Validation loss: 2.845738967236351

Epoch: 6| Step: 2
Training loss: 2.909379812005117
Validation loss: 2.8415687116768438

Epoch: 6| Step: 3
Training loss: 2.494676644388726
Validation loss: 2.8281300472798483

Epoch: 6| Step: 4
Training loss: 3.538200761920221
Validation loss: 2.8291636995535017

Epoch: 6| Step: 5
Training loss: 3.1749616365292694
Validation loss: 2.8208773708615555

Epoch: 6| Step: 6
Training loss: 3.4780785844555666
Validation loss: 2.818561780374512

Epoch: 6| Step: 7
Training loss: 2.9043952191549782
Validation loss: 2.8203571565903727

Epoch: 6| Step: 8
Training loss: 2.9411134612122045
Validation loss: 2.819407233506522

Epoch: 6| Step: 9
Training loss: 2.7951246357324684
Validation loss: 2.8209053220733185

Epoch: 6| Step: 10
Training loss: 2.853161674339012
Validation loss: 2.8148433534924973

Epoch: 6| Step: 11
Training loss: 3.1603282603449228
Validation loss: 2.81501610073768

Epoch: 6| Step: 12
Training loss: 3.1702533955185466
Validation loss: 2.8164171420595263

Epoch: 6| Step: 13
Training loss: 3.293282237126296
Validation loss: 2.815743207799844

Epoch: 202| Step: 0
Training loss: 3.237851251230923
Validation loss: 2.815207949957369

Epoch: 6| Step: 1
Training loss: 3.164435621325495
Validation loss: 2.8167028874660964

Epoch: 6| Step: 2
Training loss: 3.311130744511756
Validation loss: 2.811837079711708

Epoch: 6| Step: 3
Training loss: 3.061972436423296
Validation loss: 2.8141911097412344

Epoch: 6| Step: 4
Training loss: 3.719291327049263
Validation loss: 2.8119036572096845

Epoch: 6| Step: 5
Training loss: 2.279937784784978
Validation loss: 2.8127250800086703

Epoch: 6| Step: 6
Training loss: 3.261682494184726
Validation loss: 2.8097735763682756

Epoch: 6| Step: 7
Training loss: 2.4670677730991115
Validation loss: 2.8117170239825033

Epoch: 6| Step: 8
Training loss: 2.7019956136762477
Validation loss: 2.8127094842517866

Epoch: 6| Step: 9
Training loss: 3.9723007058049955
Validation loss: 2.8111609020403994

Epoch: 6| Step: 10
Training loss: 2.9957057099798146
Validation loss: 2.814336127701973

Epoch: 6| Step: 11
Training loss: 3.025423408069638
Validation loss: 2.811228575276146

Epoch: 6| Step: 12
Training loss: 2.7561830023756095
Validation loss: 2.8115553177461927

Epoch: 6| Step: 13
Training loss: 3.4238384309777863
Validation loss: 2.8185658406309284

Epoch: 203| Step: 0
Training loss: 2.206284874486451
Validation loss: 2.8244468363007544

Epoch: 6| Step: 1
Training loss: 3.9009365717843916
Validation loss: 2.818055148362296

Epoch: 6| Step: 2
Training loss: 3.5037889407794416
Validation loss: 2.816318343730367

Epoch: 6| Step: 3
Training loss: 2.4322860902862558
Validation loss: 2.817289562441234

Epoch: 6| Step: 4
Training loss: 3.2056089120968037
Validation loss: 2.8132557772984494

Epoch: 6| Step: 5
Training loss: 3.489558585159833
Validation loss: 2.8109304955060206

Epoch: 6| Step: 6
Training loss: 3.4374807183851983
Validation loss: 2.8082915993636623

Epoch: 6| Step: 7
Training loss: 3.1964680790267272
Validation loss: 2.808863785203969

Epoch: 6| Step: 8
Training loss: 2.74226548825732
Validation loss: 2.807288164816988

Epoch: 6| Step: 9
Training loss: 2.6438908893388553
Validation loss: 2.8064936391451076

Epoch: 6| Step: 10
Training loss: 3.357780468460891
Validation loss: 2.8079825925873814

Epoch: 6| Step: 11
Training loss: 3.3733768091930907
Validation loss: 2.808503222232748

Epoch: 6| Step: 12
Training loss: 2.690542317713926
Validation loss: 2.8075434581176446

Epoch: 6| Step: 13
Training loss: 2.892010825689586
Validation loss: 2.8077224917430557

Epoch: 204| Step: 0
Training loss: 3.3619165077349065
Validation loss: 2.8070452206373977

Epoch: 6| Step: 1
Training loss: 3.6006171916022156
Validation loss: 2.807501303344187

Epoch: 6| Step: 2
Training loss: 2.892240165836835
Validation loss: 2.811378258039785

Epoch: 6| Step: 3
Training loss: 2.6278150087621994
Validation loss: 2.812938494664417

Epoch: 6| Step: 4
Training loss: 2.861975649321561
Validation loss: 2.83558559898346

Epoch: 6| Step: 5
Training loss: 3.728876255313577
Validation loss: 2.853363609168675

Epoch: 6| Step: 6
Training loss: 2.5015204574416385
Validation loss: 2.85508637550072

Epoch: 6| Step: 7
Training loss: 3.3165244361118686
Validation loss: 2.8754499118165247

Epoch: 6| Step: 8
Training loss: 2.976016016978569
Validation loss: 2.832740915991066

Epoch: 6| Step: 9
Training loss: 3.1274500588409775
Validation loss: 2.8164682957632627

Epoch: 6| Step: 10
Training loss: 3.02610326147286
Validation loss: 2.806710621300092

Epoch: 6| Step: 11
Training loss: 2.9924861270898475
Validation loss: 2.8019233862596997

Epoch: 6| Step: 12
Training loss: 2.888076566130312
Validation loss: 2.80789134027036

Epoch: 6| Step: 13
Training loss: 3.8546861590571364
Validation loss: 2.810954401419987

Epoch: 205| Step: 0
Training loss: 3.304249980272211
Validation loss: 2.8129427772103024

Epoch: 6| Step: 1
Training loss: 2.446795906357321
Validation loss: 2.8153789529166002

Epoch: 6| Step: 2
Training loss: 3.4105044052840503
Validation loss: 2.8122363369133914

Epoch: 6| Step: 3
Training loss: 3.0628110766555907
Validation loss: 2.8182331630830904

Epoch: 6| Step: 4
Training loss: 3.20822675123332
Validation loss: 2.8126610822591718

Epoch: 6| Step: 5
Training loss: 2.846917201712365
Validation loss: 2.814116923098437

Epoch: 6| Step: 6
Training loss: 3.0738083057683268
Validation loss: 2.81340208364799

Epoch: 6| Step: 7
Training loss: 3.052420553037373
Validation loss: 2.810546653347515

Epoch: 6| Step: 8
Training loss: 2.8996181499724085
Validation loss: 2.806774277031391

Epoch: 6| Step: 9
Training loss: 3.3346098998539695
Validation loss: 2.810561250448938

Epoch: 6| Step: 10
Training loss: 3.0520679529907015
Validation loss: 2.8032871259951495

Epoch: 6| Step: 11
Training loss: 2.9961074371224194
Validation loss: 2.81069384590415

Epoch: 6| Step: 12
Training loss: 3.6759792035399763
Validation loss: 2.8073515179720023

Epoch: 6| Step: 13
Training loss: 3.4020869862213114
Validation loss: 2.8073076754580866

Epoch: 206| Step: 0
Training loss: 3.5416751337885155
Validation loss: 2.80763384060337

Epoch: 6| Step: 1
Training loss: 3.337065387673926
Validation loss: 2.8029812305380983

Epoch: 6| Step: 2
Training loss: 2.9978770055703325
Validation loss: 2.804431448509716

Epoch: 6| Step: 3
Training loss: 2.8962338031156203
Validation loss: 2.8048462103155645

Epoch: 6| Step: 4
Training loss: 2.65642358549309
Validation loss: 2.8043595587698578

Epoch: 6| Step: 5
Training loss: 3.2661630287664694
Validation loss: 2.8027879297451417

Epoch: 6| Step: 6
Training loss: 2.643259032633509
Validation loss: 2.8025644638537734

Epoch: 6| Step: 7
Training loss: 3.2948881553457614
Validation loss: 2.804550699085547

Epoch: 6| Step: 8
Training loss: 2.787211682928676
Validation loss: 2.8016206251262767

Epoch: 6| Step: 9
Training loss: 3.7092592319333275
Validation loss: 2.803930812073203

Epoch: 6| Step: 10
Training loss: 2.7621608094368293
Validation loss: 2.8019347838612902

Epoch: 6| Step: 11
Training loss: 3.6338664833192906
Validation loss: 2.8010798753164337

Epoch: 6| Step: 12
Training loss: 2.187925460856842
Validation loss: 2.8079564519337548

Epoch: 6| Step: 13
Training loss: 3.663704340170956
Validation loss: 2.8107955890866987

Epoch: 207| Step: 0
Training loss: 3.566138835127742
Validation loss: 2.812039181456172

Epoch: 6| Step: 1
Training loss: 2.901125255501374
Validation loss: 2.819665751882963

Epoch: 6| Step: 2
Training loss: 3.280963994231773
Validation loss: 2.822955176940618

Epoch: 6| Step: 3
Training loss: 3.3777612763832754
Validation loss: 2.822887673123336

Epoch: 6| Step: 4
Training loss: 3.4535335799623037
Validation loss: 2.835875099142181

Epoch: 6| Step: 5
Training loss: 3.380060146631807
Validation loss: 2.820595621248885

Epoch: 6| Step: 6
Training loss: 2.65930986873781
Validation loss: 2.8042511086490474

Epoch: 6| Step: 7
Training loss: 2.849110005936544
Validation loss: 2.8051077467627246

Epoch: 6| Step: 8
Training loss: 3.390218121423404
Validation loss: 2.799671975564859

Epoch: 6| Step: 9
Training loss: 3.3792363176485805
Validation loss: 2.802881750069765

Epoch: 6| Step: 10
Training loss: 3.0066725911704464
Validation loss: 2.799237591030435

Epoch: 6| Step: 11
Training loss: 2.818505466452497
Validation loss: 2.797135645773118

Epoch: 6| Step: 12
Training loss: 2.5728510695112163
Validation loss: 2.800403703791578

Epoch: 6| Step: 13
Training loss: 2.3268866605873786
Validation loss: 2.8006880485775754

Epoch: 208| Step: 0
Training loss: 2.775269754718683
Validation loss: 2.796975587773151

Epoch: 6| Step: 1
Training loss: 2.969792714961168
Validation loss: 2.8015302435565124

Epoch: 6| Step: 2
Training loss: 3.292155861215956
Validation loss: 2.804407900185842

Epoch: 6| Step: 3
Training loss: 3.585458095975409
Validation loss: 2.798983524953074

Epoch: 6| Step: 4
Training loss: 2.733503017353397
Validation loss: 2.8015733465129053

Epoch: 6| Step: 5
Training loss: 3.0065444453139136
Validation loss: 2.795354810740824

Epoch: 6| Step: 6
Training loss: 3.5213503185278086
Validation loss: 2.800215433442385

Epoch: 6| Step: 7
Training loss: 3.631237188897703
Validation loss: 2.801663434793682

Epoch: 6| Step: 8
Training loss: 3.075481848452156
Validation loss: 2.800009134566295

Epoch: 6| Step: 9
Training loss: 3.3095744907671323
Validation loss: 2.79704807424511

Epoch: 6| Step: 10
Training loss: 2.8226362889162386
Validation loss: 2.8008645767922

Epoch: 6| Step: 11
Training loss: 2.5920727373855112
Validation loss: 2.8045904310877474

Epoch: 6| Step: 12
Training loss: 2.720319448393176
Validation loss: 2.8050123749755147

Epoch: 6| Step: 13
Training loss: 3.380742027498422
Validation loss: 2.810211884327684

Epoch: 209| Step: 0
Training loss: 3.160402342617807
Validation loss: 2.8179918529849464

Epoch: 6| Step: 1
Training loss: 2.847358175200454
Validation loss: 2.8207982705939996

Epoch: 6| Step: 2
Training loss: 3.4646258882412098
Validation loss: 2.808858851161414

Epoch: 6| Step: 3
Training loss: 2.775847427605706
Validation loss: 2.8063473764038056

Epoch: 6| Step: 4
Training loss: 3.8304244628437405
Validation loss: 2.8159207714466183

Epoch: 6| Step: 5
Training loss: 2.9484454827536677
Validation loss: 2.8122010886845246

Epoch: 6| Step: 6
Training loss: 3.137554432674143
Validation loss: 2.8111709571927292

Epoch: 6| Step: 7
Training loss: 2.424262561949262
Validation loss: 2.8168076008532488

Epoch: 6| Step: 8
Training loss: 3.0229065894693514
Validation loss: 2.814054308035418

Epoch: 6| Step: 9
Training loss: 3.589114707663385
Validation loss: 2.8102604598666066

Epoch: 6| Step: 10
Training loss: 3.429503833484412
Validation loss: 2.8041514373596375

Epoch: 6| Step: 11
Training loss: 3.136852522832401
Validation loss: 2.8149215773959413

Epoch: 6| Step: 12
Training loss: 2.679713301909764
Validation loss: 2.80178174726874

Epoch: 6| Step: 13
Training loss: 2.3456329919651977
Validation loss: 2.8075186894684614

Epoch: 210| Step: 0
Training loss: 3.001316417513673
Validation loss: 2.7992608320866936

Epoch: 6| Step: 1
Training loss: 3.1510301994346266
Validation loss: 2.798791244169154

Epoch: 6| Step: 2
Training loss: 2.8762474670796885
Validation loss: 2.7987453824382174

Epoch: 6| Step: 3
Training loss: 3.162045888752357
Validation loss: 2.798031519539128

Epoch: 6| Step: 4
Training loss: 3.5909003860139856
Validation loss: 2.795035727190005

Epoch: 6| Step: 5
Training loss: 2.5694947956638963
Validation loss: 2.7977834548252836

Epoch: 6| Step: 6
Training loss: 3.4396402805234465
Validation loss: 2.793631482235428

Epoch: 6| Step: 7
Training loss: 2.848997535412607
Validation loss: 2.7970686342690536

Epoch: 6| Step: 8
Training loss: 3.4167973718220885
Validation loss: 2.796763470299845

Epoch: 6| Step: 9
Training loss: 2.14006358114605
Validation loss: 2.803594862621564

Epoch: 6| Step: 10
Training loss: 3.3468419690465643
Validation loss: 2.802819705381781

Epoch: 6| Step: 11
Training loss: 2.847242955905093
Validation loss: 2.813073164350876

Epoch: 6| Step: 12
Training loss: 3.1734630198652307
Validation loss: 2.824611728102184

Epoch: 6| Step: 13
Training loss: 3.9401364658172304
Validation loss: 2.8341238293225657

Epoch: 211| Step: 0
Training loss: 3.423530352407079
Validation loss: 2.8144510645793845

Epoch: 6| Step: 1
Training loss: 2.75903189611577
Validation loss: 2.8061068302670904

Epoch: 6| Step: 2
Training loss: 2.858995089280887
Validation loss: 2.798922722878594

Epoch: 6| Step: 3
Training loss: 3.0459092394706664
Validation loss: 2.792703850183398

Epoch: 6| Step: 4
Training loss: 3.199359150135792
Validation loss: 2.794376752757078

Epoch: 6| Step: 5
Training loss: 3.41332580858633
Validation loss: 2.7969294478744113

Epoch: 6| Step: 6
Training loss: 3.328442768812285
Validation loss: 2.7971252927041648

Epoch: 6| Step: 7
Training loss: 3.3348581323374735
Validation loss: 2.7936609724245067

Epoch: 6| Step: 8
Training loss: 2.8957134926421375
Validation loss: 2.795082239546646

Epoch: 6| Step: 9
Training loss: 3.257938666153338
Validation loss: 2.794221850767522

Epoch: 6| Step: 10
Training loss: 2.620519356248331
Validation loss: 2.7948002129673126

Epoch: 6| Step: 11
Training loss: 3.2859431536558295
Validation loss: 2.7915937542443023

Epoch: 6| Step: 12
Training loss: 2.4910344532743625
Validation loss: 2.7953349195272432

Epoch: 6| Step: 13
Training loss: 3.46010798379494
Validation loss: 2.7967457203201547

Epoch: 212| Step: 0
Training loss: 3.176325339692743
Validation loss: 2.7967951988870308

Epoch: 6| Step: 1
Training loss: 2.82312885533294
Validation loss: 2.7938632245568034

Epoch: 6| Step: 2
Training loss: 3.881733489214145
Validation loss: 2.7933520890938413

Epoch: 6| Step: 3
Training loss: 2.52045200290547
Validation loss: 2.7956745896412243

Epoch: 6| Step: 4
Training loss: 3.491318562589349
Validation loss: 2.793033686355637

Epoch: 6| Step: 5
Training loss: 3.02931859729881
Validation loss: 2.791436575411712

Epoch: 6| Step: 6
Training loss: 1.582897260077834
Validation loss: 2.792925467436521

Epoch: 6| Step: 7
Training loss: 3.102982126502275
Validation loss: 2.790903763779926

Epoch: 6| Step: 8
Training loss: 3.2890181368556526
Validation loss: 2.7944319291095057

Epoch: 6| Step: 9
Training loss: 2.691168299815552
Validation loss: 2.7913203244231117

Epoch: 6| Step: 10
Training loss: 3.576150807642069
Validation loss: 2.7910960689821938

Epoch: 6| Step: 11
Training loss: 3.762141218853719
Validation loss: 2.7901985251842674

Epoch: 6| Step: 12
Training loss: 2.8219378323915665
Validation loss: 2.790864538725612

Epoch: 6| Step: 13
Training loss: 3.1026409589912523
Validation loss: 2.7897786855070583

Epoch: 213| Step: 0
Training loss: 3.4581808646422942
Validation loss: 2.7906311721512105

Epoch: 6| Step: 1
Training loss: 3.106629352700221
Validation loss: 2.792110544350175

Epoch: 6| Step: 2
Training loss: 3.716609050036141
Validation loss: 2.7894119306226286

Epoch: 6| Step: 3
Training loss: 2.781879568102653
Validation loss: 2.790136980375531

Epoch: 6| Step: 4
Training loss: 3.2667272432380803
Validation loss: 2.794123471402993

Epoch: 6| Step: 5
Training loss: 2.621312958011754
Validation loss: 2.793201748725245

Epoch: 6| Step: 6
Training loss: 3.5976880597127927
Validation loss: 2.7946764142227134

Epoch: 6| Step: 7
Training loss: 2.958540054047572
Validation loss: 2.800058138883934

Epoch: 6| Step: 8
Training loss: 2.8930282912178065
Validation loss: 2.8067839113063076

Epoch: 6| Step: 9
Training loss: 2.895758611872271
Validation loss: 2.8135798323998107

Epoch: 6| Step: 10
Training loss: 3.1842985344298467
Validation loss: 2.8179287672503497

Epoch: 6| Step: 11
Training loss: 3.189613389650767
Validation loss: 2.799978650065885

Epoch: 6| Step: 12
Training loss: 3.0756395248693362
Validation loss: 2.7927581549376885

Epoch: 6| Step: 13
Training loss: 1.5946301292701155
Validation loss: 2.7958245457921205

Epoch: 214| Step: 0
Training loss: 2.9883098127209298
Validation loss: 2.7900373662936224

Epoch: 6| Step: 1
Training loss: 2.374904028308672
Validation loss: 2.7879622291150534

Epoch: 6| Step: 2
Training loss: 3.044672243114711
Validation loss: 2.791194729561673

Epoch: 6| Step: 3
Training loss: 2.873983286331837
Validation loss: 2.7912704493931444

Epoch: 6| Step: 4
Training loss: 2.766094965255445
Validation loss: 2.787694271702444

Epoch: 6| Step: 5
Training loss: 3.15401356844986
Validation loss: 2.7900844122074533

Epoch: 6| Step: 6
Training loss: 2.73074832734676
Validation loss: 2.791751607436198

Epoch: 6| Step: 7
Training loss: 3.5049015872651226
Validation loss: 2.7907752087765227

Epoch: 6| Step: 8
Training loss: 3.2907545218195744
Validation loss: 2.7903355593346597

Epoch: 6| Step: 9
Training loss: 3.5138211518109546
Validation loss: 2.7908850450964864

Epoch: 6| Step: 10
Training loss: 3.290038337831992
Validation loss: 2.7942138631815445

Epoch: 6| Step: 11
Training loss: 2.61512187462237
Validation loss: 2.793460534683874

Epoch: 6| Step: 12
Training loss: 3.2419151099808685
Validation loss: 2.7888568965429616

Epoch: 6| Step: 13
Training loss: 4.119494376405474
Validation loss: 2.7899539724963818

Epoch: 215| Step: 0
Training loss: 2.9675525057099676
Validation loss: 2.787469231580892

Epoch: 6| Step: 1
Training loss: 3.464458663511048
Validation loss: 2.7902055733072952

Epoch: 6| Step: 2
Training loss: 2.7041955492762697
Validation loss: 2.792665950746394

Epoch: 6| Step: 3
Training loss: 2.947712130690499
Validation loss: 2.795564018042122

Epoch: 6| Step: 4
Training loss: 3.636974682186719
Validation loss: 2.799333362869951

Epoch: 6| Step: 5
Training loss: 2.84348572561519
Validation loss: 2.795600467345163

Epoch: 6| Step: 6
Training loss: 3.6237305358595577
Validation loss: 2.807269233931933

Epoch: 6| Step: 7
Training loss: 2.632555487791524
Validation loss: 2.796473919998584

Epoch: 6| Step: 8
Training loss: 2.565637296212731
Validation loss: 2.7979408534391057

Epoch: 6| Step: 9
Training loss: 3.1591967433368806
Validation loss: 2.7925228874523103

Epoch: 6| Step: 10
Training loss: 2.7194826739278826
Validation loss: 2.7898826635254514

Epoch: 6| Step: 11
Training loss: 2.9720386159244128
Validation loss: 2.7869354351749287

Epoch: 6| Step: 12
Training loss: 3.665629037788164
Validation loss: 2.78758665296233

Epoch: 6| Step: 13
Training loss: 3.1282972107395266
Validation loss: 2.788701054551371

Epoch: 216| Step: 0
Training loss: 3.540572023458342
Validation loss: 2.787018625861201

Epoch: 6| Step: 1
Training loss: 3.064949146240924
Validation loss: 2.7845477170715025

Epoch: 6| Step: 2
Training loss: 3.0170212117563078
Validation loss: 2.7844903055393497

Epoch: 6| Step: 3
Training loss: 2.70507741990063
Validation loss: 2.7870117803249483

Epoch: 6| Step: 4
Training loss: 3.649052766141905
Validation loss: 2.7858789960516264

Epoch: 6| Step: 5
Training loss: 3.353023752921934
Validation loss: 2.7859734796608167

Epoch: 6| Step: 6
Training loss: 3.3955931939401856
Validation loss: 2.787102938087963

Epoch: 6| Step: 7
Training loss: 2.478502350178694
Validation loss: 2.7887996454241173

Epoch: 6| Step: 8
Training loss: 2.8958048830532994
Validation loss: 2.786019086023596

Epoch: 6| Step: 9
Training loss: 2.854229074802896
Validation loss: 2.7880714866252623

Epoch: 6| Step: 10
Training loss: 3.302674313838865
Validation loss: 2.7877547825428

Epoch: 6| Step: 11
Training loss: 2.5847540507086992
Validation loss: 2.7913960261531483

Epoch: 6| Step: 12
Training loss: 3.071078061859733
Validation loss: 2.790712424589086

Epoch: 6| Step: 13
Training loss: 3.188257463997894
Validation loss: 2.79474338172416

Epoch: 217| Step: 0
Training loss: 3.0979440947402104
Validation loss: 2.791213457189897

Epoch: 6| Step: 1
Training loss: 2.871744053691434
Validation loss: 2.8010614113457715

Epoch: 6| Step: 2
Training loss: 3.0984364473511357
Validation loss: 2.807847814788495

Epoch: 6| Step: 3
Training loss: 3.0739618797544632
Validation loss: 2.7925194980559285

Epoch: 6| Step: 4
Training loss: 2.739643188132135
Validation loss: 2.802949533560878

Epoch: 6| Step: 5
Training loss: 2.5729829313777293
Validation loss: 2.7950595709344874

Epoch: 6| Step: 6
Training loss: 3.1619154438871373
Validation loss: 2.8006958547653737

Epoch: 6| Step: 7
Training loss: 2.8721149730355435
Validation loss: 2.796073317917783

Epoch: 6| Step: 8
Training loss: 2.8410220633498993
Validation loss: 2.7900185094813277

Epoch: 6| Step: 9
Training loss: 2.959909225309167
Validation loss: 2.79288178766108

Epoch: 6| Step: 10
Training loss: 3.607387110899425
Validation loss: 2.7881117614937443

Epoch: 6| Step: 11
Training loss: 3.337737622892192
Validation loss: 2.7886403399312125

Epoch: 6| Step: 12
Training loss: 3.617626056491596
Validation loss: 2.7847832099982424

Epoch: 6| Step: 13
Training loss: 3.355121563501326
Validation loss: 2.783151384760357

Epoch: 218| Step: 0
Training loss: 2.89140944275864
Validation loss: 2.783483141730535

Epoch: 6| Step: 1
Training loss: 3.354724877073304
Validation loss: 2.7892149228697707

Epoch: 6| Step: 2
Training loss: 3.035862196195999
Validation loss: 2.785588375096148

Epoch: 6| Step: 3
Training loss: 3.522265863265213
Validation loss: 2.7880857113033777

Epoch: 6| Step: 4
Training loss: 3.4107613742177083
Validation loss: 2.784642534930869

Epoch: 6| Step: 5
Training loss: 2.7392717384895566
Validation loss: 2.7860976241687574

Epoch: 6| Step: 6
Training loss: 3.3032595748699083
Validation loss: 2.7822585674354987

Epoch: 6| Step: 7
Training loss: 2.569795875458247
Validation loss: 2.779396967182739

Epoch: 6| Step: 8
Training loss: 2.9332935164379066
Validation loss: 2.7834551076154903

Epoch: 6| Step: 9
Training loss: 2.8246281539467892
Validation loss: 2.7825774504237977

Epoch: 6| Step: 10
Training loss: 3.222861617509389
Validation loss: 2.7820180431840753

Epoch: 6| Step: 11
Training loss: 2.839828973912728
Validation loss: 2.7830089838305963

Epoch: 6| Step: 12
Training loss: 3.4644945865412087
Validation loss: 2.789688692211843

Epoch: 6| Step: 13
Training loss: 2.8727628877427205
Validation loss: 2.780935068932292

Epoch: 219| Step: 0
Training loss: 2.7537689391189217
Validation loss: 2.7865807113171326

Epoch: 6| Step: 1
Training loss: 3.2320987966375014
Validation loss: 2.781554721252954

Epoch: 6| Step: 2
Training loss: 2.9695260087759587
Validation loss: 2.7887996380700124

Epoch: 6| Step: 3
Training loss: 2.7483087020458097
Validation loss: 2.786481350073499

Epoch: 6| Step: 4
Training loss: 3.040056943611081
Validation loss: 2.7814505250048276

Epoch: 6| Step: 5
Training loss: 2.9345503262110584
Validation loss: 2.7827633119720936

Epoch: 6| Step: 6
Training loss: 2.7861494992435367
Validation loss: 2.7811925038018206

Epoch: 6| Step: 7
Training loss: 2.716065846646412
Validation loss: 2.7847349955760796

Epoch: 6| Step: 8
Training loss: 3.121666312664913
Validation loss: 2.7819215342436965

Epoch: 6| Step: 9
Training loss: 3.5520637638451644
Validation loss: 2.7782139233379195

Epoch: 6| Step: 10
Training loss: 3.499001769356227
Validation loss: 2.778139582489498

Epoch: 6| Step: 11
Training loss: 3.5324121773960107
Validation loss: 2.7797501490244967

Epoch: 6| Step: 12
Training loss: 3.22036258338359
Validation loss: 2.7822404024176732

Epoch: 6| Step: 13
Training loss: 2.8320142442916145
Validation loss: 2.781426453992979

Epoch: 220| Step: 0
Training loss: 3.227088423532634
Validation loss: 2.78868792330197

Epoch: 6| Step: 1
Training loss: 3.2599905952364763
Validation loss: 2.800525601155803

Epoch: 6| Step: 2
Training loss: 3.208878128233902
Validation loss: 2.798884364949909

Epoch: 6| Step: 3
Training loss: 2.637321798804002
Validation loss: 2.815497877302729

Epoch: 6| Step: 4
Training loss: 3.30507114789736
Validation loss: 2.809075047372658

Epoch: 6| Step: 5
Training loss: 3.2406627332795215
Validation loss: 2.8236418094922695

Epoch: 6| Step: 6
Training loss: 3.3515455694593497
Validation loss: 2.7999932024619802

Epoch: 6| Step: 7
Training loss: 2.7443434888037967
Validation loss: 2.7944321841495574

Epoch: 6| Step: 8
Training loss: 3.013867434314438
Validation loss: 2.790210012944938

Epoch: 6| Step: 9
Training loss: 2.5247236346088147
Validation loss: 2.781421114580019

Epoch: 6| Step: 10
Training loss: 3.242967185523442
Validation loss: 2.78150352824038

Epoch: 6| Step: 11
Training loss: 2.769843381179197
Validation loss: 2.778147341300646

Epoch: 6| Step: 12
Training loss: 3.106890888990753
Validation loss: 2.779169984063329

Epoch: 6| Step: 13
Training loss: 3.72225594544831
Validation loss: 2.7780421811743694

Epoch: 221| Step: 0
Training loss: 3.0122587558499725
Validation loss: 2.775339349693031

Epoch: 6| Step: 1
Training loss: 3.09988580924112
Validation loss: 2.778986172780834

Epoch: 6| Step: 2
Training loss: 3.2756481490238865
Validation loss: 2.7773937265094264

Epoch: 6| Step: 3
Training loss: 2.9319971364672157
Validation loss: 2.7747429254621574

Epoch: 6| Step: 4
Training loss: 3.4833167141117882
Validation loss: 2.7778906338507228

Epoch: 6| Step: 5
Training loss: 3.2775835170041816
Validation loss: 2.7774108257403087

Epoch: 6| Step: 6
Training loss: 2.6027358333211996
Validation loss: 2.776409472420303

Epoch: 6| Step: 7
Training loss: 2.9368977030680066
Validation loss: 2.7721469592437393

Epoch: 6| Step: 8
Training loss: 3.501606844851467
Validation loss: 2.775389628322733

Epoch: 6| Step: 9
Training loss: 3.3647959418583886
Validation loss: 2.7757092681124447

Epoch: 6| Step: 10
Training loss: 3.3680598640195853
Validation loss: 2.7787038521390715

Epoch: 6| Step: 11
Training loss: 2.8576783529909084
Validation loss: 2.7789047306199435

Epoch: 6| Step: 12
Training loss: 2.5320403195706898
Validation loss: 2.7775039295514934

Epoch: 6| Step: 13
Training loss: 2.442282069468665
Validation loss: 2.7810327699248125

Epoch: 222| Step: 0
Training loss: 3.6352915191241695
Validation loss: 2.7776939090933697

Epoch: 6| Step: 1
Training loss: 2.9589440874938884
Validation loss: 2.7804706694183308

Epoch: 6| Step: 2
Training loss: 2.9993996019381837
Validation loss: 2.7777375028281486

Epoch: 6| Step: 3
Training loss: 2.6783424315884568
Validation loss: 2.774583010618797

Epoch: 6| Step: 4
Training loss: 4.038379131775877
Validation loss: 2.7775851792729944

Epoch: 6| Step: 5
Training loss: 2.685965077523265
Validation loss: 2.778301246056157

Epoch: 6| Step: 6
Training loss: 3.5558672278283057
Validation loss: 2.77757428445917

Epoch: 6| Step: 7
Training loss: 2.248353991836566
Validation loss: 2.7833633965640856

Epoch: 6| Step: 8
Training loss: 2.7427501481622674
Validation loss: 2.7743810642837596

Epoch: 6| Step: 9
Training loss: 2.656259065500385
Validation loss: 2.7789167051160057

Epoch: 6| Step: 10
Training loss: 2.6086247444882047
Validation loss: 2.7795644171065357

Epoch: 6| Step: 11
Training loss: 3.317846050827583
Validation loss: 2.774913355760564

Epoch: 6| Step: 12
Training loss: 3.246698610069007
Validation loss: 2.777256259636592

Epoch: 6| Step: 13
Training loss: 3.4099042696673902
Validation loss: 2.778742633487445

Epoch: 223| Step: 0
Training loss: 3.198815549750514
Validation loss: 2.7805240665858566

Epoch: 6| Step: 1
Training loss: 2.939643402531234
Validation loss: 2.773499593771903

Epoch: 6| Step: 2
Training loss: 3.41273036081449
Validation loss: 2.7748402679716544

Epoch: 6| Step: 3
Training loss: 3.3099323613842135
Validation loss: 2.7744162820181413

Epoch: 6| Step: 4
Training loss: 2.781859513263023
Validation loss: 2.7718480747314187

Epoch: 6| Step: 5
Training loss: 2.8010863240404715
Validation loss: 2.774100630597544

Epoch: 6| Step: 6
Training loss: 2.6921669116259697
Validation loss: 2.7761101085827584

Epoch: 6| Step: 7
Training loss: 3.349476981257467
Validation loss: 2.775811249050624

Epoch: 6| Step: 8
Training loss: 3.4666928901658656
Validation loss: 2.7710577653147044

Epoch: 6| Step: 9
Training loss: 2.9287534318253408
Validation loss: 2.7725797360592743

Epoch: 6| Step: 10
Training loss: 2.9485687145799417
Validation loss: 2.7729136888448855

Epoch: 6| Step: 11
Training loss: 2.707311134126503
Validation loss: 2.7730096829351822

Epoch: 6| Step: 12
Training loss: 2.8860880120089067
Validation loss: 2.7721917480814398

Epoch: 6| Step: 13
Training loss: 3.7800241800574303
Validation loss: 2.7795717495202203

Epoch: 224| Step: 0
Training loss: 2.7213523073813675
Validation loss: 2.7831632811121785

Epoch: 6| Step: 1
Training loss: 3.161886187305705
Validation loss: 2.7954584630509105

Epoch: 6| Step: 2
Training loss: 3.3259651446875926
Validation loss: 2.804445728241329

Epoch: 6| Step: 3
Training loss: 3.0044611503894036
Validation loss: 2.796751410885714

Epoch: 6| Step: 4
Training loss: 3.3269242820550984
Validation loss: 2.804788408107465

Epoch: 6| Step: 5
Training loss: 2.624370317775168
Validation loss: 2.7843276883472705

Epoch: 6| Step: 6
Training loss: 3.3742238317841307
Validation loss: 2.7814095905194947

Epoch: 6| Step: 7
Training loss: 3.274454546051558
Validation loss: 2.774667763547718

Epoch: 6| Step: 8
Training loss: 2.814112222370966
Validation loss: 2.7711999348274254

Epoch: 6| Step: 9
Training loss: 3.3983850233915396
Validation loss: 2.7702234173483338

Epoch: 6| Step: 10
Training loss: 3.1741314458424434
Validation loss: 2.7724226841274544

Epoch: 6| Step: 11
Training loss: 2.738293265453756
Validation loss: 2.7675396031239696

Epoch: 6| Step: 12
Training loss: 3.03261433208953
Validation loss: 2.7689854834083287

Epoch: 6| Step: 13
Training loss: 3.1206003880537776
Validation loss: 2.776448011580781

Epoch: 225| Step: 0
Training loss: 2.735936792396441
Validation loss: 2.7726789787653336

Epoch: 6| Step: 1
Training loss: 3.5137163872944837
Validation loss: 2.7695559372069125

Epoch: 6| Step: 2
Training loss: 3.5925207274707724
Validation loss: 2.77381742637535

Epoch: 6| Step: 3
Training loss: 3.7293487305480735
Validation loss: 2.775188294023434

Epoch: 6| Step: 4
Training loss: 2.5869165509083447
Validation loss: 2.777926339582809

Epoch: 6| Step: 5
Training loss: 2.960283594722242
Validation loss: 2.7712556762450684

Epoch: 6| Step: 6
Training loss: 3.0338482290490894
Validation loss: 2.772941019652651

Epoch: 6| Step: 7
Training loss: 2.6430824176409766
Validation loss: 2.7812243851370138

Epoch: 6| Step: 8
Training loss: 3.0334918983292183
Validation loss: 2.7868085341937383

Epoch: 6| Step: 9
Training loss: 2.7046647289602355
Validation loss: 2.786669798539801

Epoch: 6| Step: 10
Training loss: 3.1267615884499187
Validation loss: 2.7891814995627806

Epoch: 6| Step: 11
Training loss: 2.9230200823767083
Validation loss: 2.7887702343650864

Epoch: 6| Step: 12
Training loss: 3.6262406166478613
Validation loss: 2.7850318195954475

Epoch: 6| Step: 13
Training loss: 1.9129864217472712
Validation loss: 2.7906759876903595

Epoch: 226| Step: 0
Training loss: 3.285096157762672
Validation loss: 2.7872807415089156

Epoch: 6| Step: 1
Training loss: 2.4734032152008334
Validation loss: 2.7926360837678272

Epoch: 6| Step: 2
Training loss: 3.5585221954421056
Validation loss: 2.7930775106124295

Epoch: 6| Step: 3
Training loss: 3.6530980274780824
Validation loss: 2.7797796518302618

Epoch: 6| Step: 4
Training loss: 3.2760017202556786
Validation loss: 2.7698293312282822

Epoch: 6| Step: 5
Training loss: 3.4407265519097985
Validation loss: 2.7706061772889643

Epoch: 6| Step: 6
Training loss: 3.0364395236986197
Validation loss: 2.764554521469712

Epoch: 6| Step: 7
Training loss: 3.9277948330286057
Validation loss: 2.769969712767014

Epoch: 6| Step: 8
Training loss: 1.9223746293837323
Validation loss: 2.765892916379137

Epoch: 6| Step: 9
Training loss: 2.7411169152193438
Validation loss: 2.7631631522486257

Epoch: 6| Step: 10
Training loss: 2.3632475543181513
Validation loss: 2.7627032455254867

Epoch: 6| Step: 11
Training loss: 2.7548343474334924
Validation loss: 2.7661284330387663

Epoch: 6| Step: 12
Training loss: 3.085708957369811
Validation loss: 2.7643907816201474

Epoch: 6| Step: 13
Training loss: 2.845660898579982
Validation loss: 2.766080375395797

Epoch: 227| Step: 0
Training loss: 3.07472017457142
Validation loss: 2.762213685349128

Epoch: 6| Step: 1
Training loss: 3.1932996458481355
Validation loss: 2.765295096260557

Epoch: 6| Step: 2
Training loss: 3.3312761316473307
Validation loss: 2.7622941495361504

Epoch: 6| Step: 3
Training loss: 3.134729269892381
Validation loss: 2.764120744132943

Epoch: 6| Step: 4
Training loss: 3.192485724815291
Validation loss: 2.763744374139604

Epoch: 6| Step: 5
Training loss: 2.779287781904925
Validation loss: 2.762915208199085

Epoch: 6| Step: 6
Training loss: 2.9862923579447376
Validation loss: 2.7659190319229126

Epoch: 6| Step: 7
Training loss: 2.773040313218571
Validation loss: 2.7663028684182516

Epoch: 6| Step: 8
Training loss: 2.486381727960824
Validation loss: 2.7654086654588297

Epoch: 6| Step: 9
Training loss: 3.072785679670959
Validation loss: 2.762250801182854

Epoch: 6| Step: 10
Training loss: 2.991249993368516
Validation loss: 2.7696104759930678

Epoch: 6| Step: 11
Training loss: 3.1494329880729808
Validation loss: 2.7704835085379864

Epoch: 6| Step: 12
Training loss: 4.066215342090475
Validation loss: 2.7733860166497886

Epoch: 6| Step: 13
Training loss: 1.9311217256185287
Validation loss: 2.775198650409557

Epoch: 228| Step: 0
Training loss: 3.428980309083592
Validation loss: 2.7679736810213966

Epoch: 6| Step: 1
Training loss: 2.7538650401393596
Validation loss: 2.77439730055295

Epoch: 6| Step: 2
Training loss: 2.5186639283574115
Validation loss: 2.7796806285146327

Epoch: 6| Step: 3
Training loss: 3.031326450288351
Validation loss: 2.779355709133567

Epoch: 6| Step: 4
Training loss: 2.5835459734453186
Validation loss: 2.7843299800670787

Epoch: 6| Step: 5
Training loss: 3.0966244069785906
Validation loss: 2.7878524643152662

Epoch: 6| Step: 6
Training loss: 3.838324214136574
Validation loss: 2.8044598579829314

Epoch: 6| Step: 7
Training loss: 3.4212049411737553
Validation loss: 2.789929374815068

Epoch: 6| Step: 8
Training loss: 3.4114460641577242
Validation loss: 2.7774335977833386

Epoch: 6| Step: 9
Training loss: 2.8678699481585253
Validation loss: 2.768314141285397

Epoch: 6| Step: 10
Training loss: 3.0970638521661984
Validation loss: 2.7726474060027204

Epoch: 6| Step: 11
Training loss: 2.5048519734943726
Validation loss: 2.7662730346768685

Epoch: 6| Step: 12
Training loss: 3.4384147120608795
Validation loss: 2.7700763149076764

Epoch: 6| Step: 13
Training loss: 2.62467191553241
Validation loss: 2.7687852685816736

Epoch: 229| Step: 0
Training loss: 3.303673554833949
Validation loss: 2.7655538080867976

Epoch: 6| Step: 1
Training loss: 3.169967303182648
Validation loss: 2.765971622815386

Epoch: 6| Step: 2
Training loss: 3.038360750036651
Validation loss: 2.764431892068458

Epoch: 6| Step: 3
Training loss: 2.538664613505877
Validation loss: 2.765537266828344

Epoch: 6| Step: 4
Training loss: 3.532993122732259
Validation loss: 2.763902286502497

Epoch: 6| Step: 5
Training loss: 3.6071741569488394
Validation loss: 2.766141750158528

Epoch: 6| Step: 6
Training loss: 2.7498275529371536
Validation loss: 2.7587798646393678

Epoch: 6| Step: 7
Training loss: 2.7872251982437835
Validation loss: 2.7614447590968667

Epoch: 6| Step: 8
Training loss: 2.844412254939464
Validation loss: 2.7598780906282228

Epoch: 6| Step: 9
Training loss: 3.288399890110732
Validation loss: 2.7652791940683024

Epoch: 6| Step: 10
Training loss: 3.0688327009008107
Validation loss: 2.7634511535621686

Epoch: 6| Step: 11
Training loss: 3.223089459519003
Validation loss: 2.7592688829008964

Epoch: 6| Step: 12
Training loss: 3.0098139457611235
Validation loss: 2.7568201232119245

Epoch: 6| Step: 13
Training loss: 2.284752234584201
Validation loss: 2.7582237822176623

Epoch: 230| Step: 0
Training loss: 3.5575574083983934
Validation loss: 2.7612328385956135

Epoch: 6| Step: 1
Training loss: 2.7458858058548548
Validation loss: 2.7610211952382597

Epoch: 6| Step: 2
Training loss: 3.105845839919885
Validation loss: 2.7620839175470078

Epoch: 6| Step: 3
Training loss: 3.0058022655393493
Validation loss: 2.7710017590186804

Epoch: 6| Step: 4
Training loss: 3.085283813775947
Validation loss: 2.7739402184812487

Epoch: 6| Step: 5
Training loss: 2.9727165627094405
Validation loss: 2.7794825860573167

Epoch: 6| Step: 6
Training loss: 3.254476398831953
Validation loss: 2.783385421749887

Epoch: 6| Step: 7
Training loss: 3.1335918570117847
Validation loss: 2.7955172926913714

Epoch: 6| Step: 8
Training loss: 3.2425583960481306
Validation loss: 2.793770335581498

Epoch: 6| Step: 9
Training loss: 2.588368083166275
Validation loss: 2.7849195072207267

Epoch: 6| Step: 10
Training loss: 2.852608768351931
Validation loss: 2.7783726031401415

Epoch: 6| Step: 11
Training loss: 3.2532024744429417
Validation loss: 2.7690282087949467

Epoch: 6| Step: 12
Training loss: 2.7863535828672794
Validation loss: 2.763412815360433

Epoch: 6| Step: 13
Training loss: 3.4546147925887976
Validation loss: 2.7587540049008354

Epoch: 231| Step: 0
Training loss: 3.2015287562277375
Validation loss: 2.7574300988034786

Epoch: 6| Step: 1
Training loss: 2.7091019542345576
Validation loss: 2.758159617581231

Epoch: 6| Step: 2
Training loss: 3.118529066925586
Validation loss: 2.7591812003485843

Epoch: 6| Step: 3
Training loss: 3.3044791370113624
Validation loss: 2.7587365716501013

Epoch: 6| Step: 4
Training loss: 3.0556283267824877
Validation loss: 2.7601086665063157

Epoch: 6| Step: 5
Training loss: 2.9311905324145844
Validation loss: 2.7632780309201785

Epoch: 6| Step: 6
Training loss: 2.690496504104518
Validation loss: 2.759729232834368

Epoch: 6| Step: 7
Training loss: 3.4185688647277157
Validation loss: 2.763334497127226

Epoch: 6| Step: 8
Training loss: 3.172022924121505
Validation loss: 2.7619952365292137

Epoch: 6| Step: 9
Training loss: 2.8465798519157195
Validation loss: 2.7675065766679623

Epoch: 6| Step: 10
Training loss: 2.9085880842007668
Validation loss: 2.7628612257455147

Epoch: 6| Step: 11
Training loss: 3.1544834140856106
Validation loss: 2.7567630939373418

Epoch: 6| Step: 12
Training loss: 3.1271162878066785
Validation loss: 2.761028883304887

Epoch: 6| Step: 13
Training loss: 3.3593061573160523
Validation loss: 2.7539994325787887

Epoch: 232| Step: 0
Training loss: 3.4645554208615557
Validation loss: 2.756443415786163

Epoch: 6| Step: 1
Training loss: 3.4639879135202896
Validation loss: 2.7609062672323503

Epoch: 6| Step: 2
Training loss: 3.253617547497822
Validation loss: 2.761929300313536

Epoch: 6| Step: 3
Training loss: 2.788655740264029
Validation loss: 2.7639864449871268

Epoch: 6| Step: 4
Training loss: 2.6298657688363427
Validation loss: 2.7668957565628576

Epoch: 6| Step: 5
Training loss: 2.33253511899164
Validation loss: 2.785945641763383

Epoch: 6| Step: 6
Training loss: 3.5039642227123053
Validation loss: 2.7915549007174807

Epoch: 6| Step: 7
Training loss: 3.32257677849205
Validation loss: 2.7887879376645714

Epoch: 6| Step: 8
Training loss: 2.9644294218070026
Validation loss: 2.8022078476408487

Epoch: 6| Step: 9
Training loss: 2.9193912496014494
Validation loss: 2.7770614193221093

Epoch: 6| Step: 10
Training loss: 2.7550136639209457
Validation loss: 2.764860349334798

Epoch: 6| Step: 11
Training loss: 3.1222717582902977
Validation loss: 2.756354379369158

Epoch: 6| Step: 12
Training loss: 3.1055518181205315
Validation loss: 2.754535376917677

Epoch: 6| Step: 13
Training loss: 3.139724830184541
Validation loss: 2.753552216820702

Epoch: 233| Step: 0
Training loss: 2.9305630202195814
Validation loss: 2.7573323034374346

Epoch: 6| Step: 1
Training loss: 2.8857656513428487
Validation loss: 2.7547455298220944

Epoch: 6| Step: 2
Training loss: 3.30602394297492
Validation loss: 2.7603227890003676

Epoch: 6| Step: 3
Training loss: 2.944843609062447
Validation loss: 2.7617962285005984

Epoch: 6| Step: 4
Training loss: 3.297767554498931
Validation loss: 2.761337534998783

Epoch: 6| Step: 5
Training loss: 3.3572480321485387
Validation loss: 2.7611458618400806

Epoch: 6| Step: 6
Training loss: 3.0344278254364863
Validation loss: 2.7635449660843032

Epoch: 6| Step: 7
Training loss: 2.5019988652142118
Validation loss: 2.762236203548105

Epoch: 6| Step: 8
Training loss: 2.510693377892444
Validation loss: 2.75901972753162

Epoch: 6| Step: 9
Training loss: 3.734539586993134
Validation loss: 2.7632118887319748

Epoch: 6| Step: 10
Training loss: 2.6139068538937114
Validation loss: 2.7636525340301943

Epoch: 6| Step: 11
Training loss: 3.53316209726041
Validation loss: 2.7614377907478436

Epoch: 6| Step: 12
Training loss: 3.133752087416256
Validation loss: 2.760856071198193

Epoch: 6| Step: 13
Training loss: 3.0968921772531472
Validation loss: 2.7587123693575473

Epoch: 234| Step: 0
Training loss: 3.304159785131638
Validation loss: 2.7566424828907037

Epoch: 6| Step: 1
Training loss: 2.536295818368095
Validation loss: 2.7542030064618865

Epoch: 6| Step: 2
Training loss: 3.6007869655028273
Validation loss: 2.758621715741096

Epoch: 6| Step: 3
Training loss: 3.0407821379436264
Validation loss: 2.7606356511677648

Epoch: 6| Step: 4
Training loss: 2.509051910921577
Validation loss: 2.7556871466895516

Epoch: 6| Step: 5
Training loss: 2.7881246747801507
Validation loss: 2.757815364071686

Epoch: 6| Step: 6
Training loss: 4.22445925350181
Validation loss: 2.7581650587229913

Epoch: 6| Step: 7
Training loss: 3.0186924330630522
Validation loss: 2.7642173051170023

Epoch: 6| Step: 8
Training loss: 3.1982244453229254
Validation loss: 2.7645767400884136

Epoch: 6| Step: 9
Training loss: 2.963313214033875
Validation loss: 2.769219568738872

Epoch: 6| Step: 10
Training loss: 2.751142524585427
Validation loss: 2.7642745144758663

Epoch: 6| Step: 11
Training loss: 2.3740816850628947
Validation loss: 2.7648255829097947

Epoch: 6| Step: 12
Training loss: 3.2076381243893666
Validation loss: 2.7676430373998997

Epoch: 6| Step: 13
Training loss: 2.814251502688724
Validation loss: 2.7722149060829353

Epoch: 235| Step: 0
Training loss: 2.5183873144996025
Validation loss: 2.770687476615391

Epoch: 6| Step: 1
Training loss: 3.142481013493322
Validation loss: 2.781490544582602

Epoch: 6| Step: 2
Training loss: 3.201212093154161
Validation loss: 2.777620148715405

Epoch: 6| Step: 3
Training loss: 3.4534102792403187
Validation loss: 2.785597135635592

Epoch: 6| Step: 4
Training loss: 2.774821277396164
Validation loss: 2.777183589826185

Epoch: 6| Step: 5
Training loss: 2.7649161082228613
Validation loss: 2.7732870127828266

Epoch: 6| Step: 6
Training loss: 3.025631288594009
Validation loss: 2.7706897472329164

Epoch: 6| Step: 7
Training loss: 3.196546693949826
Validation loss: 2.7766205697489617

Epoch: 6| Step: 8
Training loss: 3.427784454762368
Validation loss: 2.7755259647216923

Epoch: 6| Step: 9
Training loss: 3.6128128655457146
Validation loss: 2.7704571038205743

Epoch: 6| Step: 10
Training loss: 3.11946561932041
Validation loss: 2.756530112176613

Epoch: 6| Step: 11
Training loss: 2.7351669472575377
Validation loss: 2.7582995734586824

Epoch: 6| Step: 12
Training loss: 2.3312374533962497
Validation loss: 2.7560313079086582

Epoch: 6| Step: 13
Training loss: 3.4552681602716753
Validation loss: 2.7459753927018515

Epoch: 236| Step: 0
Training loss: 2.947176962922527
Validation loss: 2.7497206683099686

Epoch: 6| Step: 1
Training loss: 3.2733530111038642
Validation loss: 2.749946287941328

Epoch: 6| Step: 2
Training loss: 2.674035877212501
Validation loss: 2.7485285576451375

Epoch: 6| Step: 3
Training loss: 2.572731896894731
Validation loss: 2.7479225591947634

Epoch: 6| Step: 4
Training loss: 2.9108056899086026
Validation loss: 2.7482987340558633

Epoch: 6| Step: 5
Training loss: 2.0001867922338916
Validation loss: 2.7454499921221798

Epoch: 6| Step: 6
Training loss: 2.7242202098023136
Validation loss: 2.747790337279744

Epoch: 6| Step: 7
Training loss: 4.062648124928777
Validation loss: 2.753128928586453

Epoch: 6| Step: 8
Training loss: 3.265712317070536
Validation loss: 2.7494990441616127

Epoch: 6| Step: 9
Training loss: 2.7681223482974957
Validation loss: 2.748710969727111

Epoch: 6| Step: 10
Training loss: 2.8807709864618585
Validation loss: 2.7483127373644183

Epoch: 6| Step: 11
Training loss: 3.764829939488184
Validation loss: 2.747593265623183

Epoch: 6| Step: 12
Training loss: 3.4175108510244874
Validation loss: 2.7488063690345315

Epoch: 6| Step: 13
Training loss: 3.052414148171576
Validation loss: 2.751405725822073

Epoch: 237| Step: 0
Training loss: 3.0282803175769133
Validation loss: 2.748163165429947

Epoch: 6| Step: 1
Training loss: 3.379482824271474
Validation loss: 2.7600368623113236

Epoch: 6| Step: 2
Training loss: 3.488048720859466
Validation loss: 2.764412475734622

Epoch: 6| Step: 3
Training loss: 3.007984344725756
Validation loss: 2.7594743590365503

Epoch: 6| Step: 4
Training loss: 3.321776159472172
Validation loss: 2.755367432096422

Epoch: 6| Step: 5
Training loss: 2.910834849048056
Validation loss: 2.756057986640855

Epoch: 6| Step: 6
Training loss: 3.241927612183708
Validation loss: 2.7538364364023917

Epoch: 6| Step: 7
Training loss: 2.3615807334253556
Validation loss: 2.7584567529007264

Epoch: 6| Step: 8
Training loss: 2.640556379701968
Validation loss: 2.7521524069762213

Epoch: 6| Step: 9
Training loss: 3.3099312088839468
Validation loss: 2.7522122330939376

Epoch: 6| Step: 10
Training loss: 2.639465257933765
Validation loss: 2.760954538431777

Epoch: 6| Step: 11
Training loss: 3.3955578058406215
Validation loss: 2.7650424832084393

Epoch: 6| Step: 12
Training loss: 3.089680779520101
Validation loss: 2.764796839429683

Epoch: 6| Step: 13
Training loss: 2.539900421383329
Validation loss: 2.768183362909462

Epoch: 238| Step: 0
Training loss: 3.1421558198322943
Validation loss: 2.768474091353979

Epoch: 6| Step: 1
Training loss: 3.7627466368076945
Validation loss: 2.7634299500771413

Epoch: 6| Step: 2
Training loss: 2.6215734369766235
Validation loss: 2.754988206187116

Epoch: 6| Step: 3
Training loss: 2.2922335068155832
Validation loss: 2.7450869591449614

Epoch: 6| Step: 4
Training loss: 2.777034178916706
Validation loss: 2.7475134868631006

Epoch: 6| Step: 5
Training loss: 2.866908254719534
Validation loss: 2.7441982940101557

Epoch: 6| Step: 6
Training loss: 3.04531131624969
Validation loss: 2.743471009614969

Epoch: 6| Step: 7
Training loss: 3.528235169710313
Validation loss: 2.741421972029276

Epoch: 6| Step: 8
Training loss: 2.899640021508445
Validation loss: 2.744341939041155

Epoch: 6| Step: 9
Training loss: 3.139348012453914
Validation loss: 2.7428974337781615

Epoch: 6| Step: 10
Training loss: 3.3881006644380744
Validation loss: 2.7399345056526507

Epoch: 6| Step: 11
Training loss: 3.335236451146844
Validation loss: 2.7461250753948026

Epoch: 6| Step: 12
Training loss: 3.291559644158411
Validation loss: 2.740145041115926

Epoch: 6| Step: 13
Training loss: 1.676431027507614
Validation loss: 2.740757803717697

Epoch: 239| Step: 0
Training loss: 2.5192879492810705
Validation loss: 2.743145874109397

Epoch: 6| Step: 1
Training loss: 3.1947514943890205
Validation loss: 2.742759773656211

Epoch: 6| Step: 2
Training loss: 3.4343347021208355
Validation loss: 2.7444899369575135

Epoch: 6| Step: 3
Training loss: 2.942869594960316
Validation loss: 2.746106371689168

Epoch: 6| Step: 4
Training loss: 1.9845532915413922
Validation loss: 2.7434483752370538

Epoch: 6| Step: 5
Training loss: 3.686547625127605
Validation loss: 2.7434749371118663

Epoch: 6| Step: 6
Training loss: 2.4724238619445478
Validation loss: 2.744080181942889

Epoch: 6| Step: 7
Training loss: 3.577678535959462
Validation loss: 2.7392352808851026

Epoch: 6| Step: 8
Training loss: 3.1069665523677172
Validation loss: 2.743217279344857

Epoch: 6| Step: 9
Training loss: 2.7886288944281996
Validation loss: 2.7399976636863013

Epoch: 6| Step: 10
Training loss: 2.9767057129056473
Validation loss: 2.7404597989901736

Epoch: 6| Step: 11
Training loss: 3.2598642159484035
Validation loss: 2.745843546647004

Epoch: 6| Step: 12
Training loss: 3.0782321969357596
Validation loss: 2.748662125358079

Epoch: 6| Step: 13
Training loss: 3.4735860019776057
Validation loss: 2.7457259367151727

Epoch: 240| Step: 0
Training loss: 3.238238547196578
Validation loss: 2.7496356256597285

Epoch: 6| Step: 1
Training loss: 2.9677403389483703
Validation loss: 2.7522592074124153

Epoch: 6| Step: 2
Training loss: 3.1018392213613817
Validation loss: 2.752632192117304

Epoch: 6| Step: 3
Training loss: 2.9613605287663725
Validation loss: 2.751193621875925

Epoch: 6| Step: 4
Training loss: 2.386936908247698
Validation loss: 2.7506043449681186

Epoch: 6| Step: 5
Training loss: 3.342081099105473
Validation loss: 2.7490243253009035

Epoch: 6| Step: 6
Training loss: 2.683244129933304
Validation loss: 2.7534899031865026

Epoch: 6| Step: 7
Training loss: 2.7259459577256697
Validation loss: 2.7551410272230714

Epoch: 6| Step: 8
Training loss: 2.3400274596274087
Validation loss: 2.766058458023304

Epoch: 6| Step: 9
Training loss: 3.7381177206754646
Validation loss: 2.7557935347765357

Epoch: 6| Step: 10
Training loss: 3.0933885459521613
Validation loss: 2.744707886662831

Epoch: 6| Step: 11
Training loss: 3.0098977527171122
Validation loss: 2.7489791067743345

Epoch: 6| Step: 12
Training loss: 3.1250004577636386
Validation loss: 2.751010895420246

Epoch: 6| Step: 13
Training loss: 4.120749161763526
Validation loss: 2.7484674536902918

Epoch: 241| Step: 0
Training loss: 2.4288639745901306
Validation loss: 2.7434027433448054

Epoch: 6| Step: 1
Training loss: 3.3853707804382256
Validation loss: 2.7439967424022433

Epoch: 6| Step: 2
Training loss: 3.0287071652597097
Validation loss: 2.7437471896784666

Epoch: 6| Step: 3
Training loss: 3.4017531082656083
Validation loss: 2.7500296429838453

Epoch: 6| Step: 4
Training loss: 2.8261833480675898
Validation loss: 2.766328734508356

Epoch: 6| Step: 5
Training loss: 3.621071100421344
Validation loss: 2.7789314858904532

Epoch: 6| Step: 6
Training loss: 3.135397740979703
Validation loss: 2.7744662364151127

Epoch: 6| Step: 7
Training loss: 2.9626881600031503
Validation loss: 2.775580012125007

Epoch: 6| Step: 8
Training loss: 2.719110749963827
Validation loss: 2.7580261352232247

Epoch: 6| Step: 9
Training loss: 2.920191478721884
Validation loss: 2.772362586734894

Epoch: 6| Step: 10
Training loss: 3.3693948047234916
Validation loss: 2.7692120385735084

Epoch: 6| Step: 11
Training loss: 3.139360467450701
Validation loss: 2.7617584298534825

Epoch: 6| Step: 12
Training loss: 2.9071217531808644
Validation loss: 2.7560133123389012

Epoch: 6| Step: 13
Training loss: 2.49224891706503
Validation loss: 2.754627507035858

Epoch: 242| Step: 0
Training loss: 2.750908268144115
Validation loss: 2.766282649680534

Epoch: 6| Step: 1
Training loss: 2.7675636522645575
Validation loss: 2.7633101811000635

Epoch: 6| Step: 2
Training loss: 3.718972079273521
Validation loss: 2.7687931573072264

Epoch: 6| Step: 3
Training loss: 2.4248247456882828
Validation loss: 2.774530356576399

Epoch: 6| Step: 4
Training loss: 2.905825183952886
Validation loss: 2.778963841508079

Epoch: 6| Step: 5
Training loss: 3.3768000570789325
Validation loss: 2.800254612654163

Epoch: 6| Step: 6
Training loss: 3.1851217335862803
Validation loss: 2.7832075555431866

Epoch: 6| Step: 7
Training loss: 3.0227895431727383
Validation loss: 2.7628836314960608

Epoch: 6| Step: 8
Training loss: 3.290706413979061
Validation loss: 2.7594187503226877

Epoch: 6| Step: 9
Training loss: 3.0944169992005612
Validation loss: 2.746638416479919

Epoch: 6| Step: 10
Training loss: 3.171189107163676
Validation loss: 2.7403549953537905

Epoch: 6| Step: 11
Training loss: 3.0602251284192943
Validation loss: 2.741950464569659

Epoch: 6| Step: 12
Training loss: 2.9833205991789336
Validation loss: 2.734324060015379

Epoch: 6| Step: 13
Training loss: 2.847754540859832
Validation loss: 2.7341415844744734

Epoch: 243| Step: 0
Training loss: 2.943171605915577
Validation loss: 2.7341767063696585

Epoch: 6| Step: 1
Training loss: 2.940895877244044
Validation loss: 2.7300207484185295

Epoch: 6| Step: 2
Training loss: 3.448129484095241
Validation loss: 2.7317803767658617

Epoch: 6| Step: 3
Training loss: 2.728155419528555
Validation loss: 2.73343150372493

Epoch: 6| Step: 4
Training loss: 3.0274149437193243
Validation loss: 2.7323351342441526

Epoch: 6| Step: 5
Training loss: 3.0282459908043724
Validation loss: 2.732285561768085

Epoch: 6| Step: 6
Training loss: 3.4005521662518854
Validation loss: 2.7320207746812457

Epoch: 6| Step: 7
Training loss: 2.6971351542258932
Validation loss: 2.732646884291416

Epoch: 6| Step: 8
Training loss: 2.09559766178747
Validation loss: 2.7365979193847605

Epoch: 6| Step: 9
Training loss: 2.9939321506332126
Validation loss: 2.742871915929281

Epoch: 6| Step: 10
Training loss: 3.2165063241581864
Validation loss: 2.7435248484450594

Epoch: 6| Step: 11
Training loss: 3.039232891572126
Validation loss: 2.7470510142277016

Epoch: 6| Step: 12
Training loss: 3.486561452713806
Validation loss: 2.7547221058403006

Epoch: 6| Step: 13
Training loss: 3.6967223625241235
Validation loss: 2.7387452419028104

Epoch: 244| Step: 0
Training loss: 2.986752506736878
Validation loss: 2.7397881957690693

Epoch: 6| Step: 1
Training loss: 2.425103183399477
Validation loss: 2.743394436786039

Epoch: 6| Step: 2
Training loss: 3.239999202681078
Validation loss: 2.7335589778942553

Epoch: 6| Step: 3
Training loss: 2.7384291757197867
Validation loss: 2.733219796435596

Epoch: 6| Step: 4
Training loss: 3.700482290641263
Validation loss: 2.7380262242106594

Epoch: 6| Step: 5
Training loss: 2.6515197822398253
Validation loss: 2.736233128245622

Epoch: 6| Step: 6
Training loss: 2.7341455853816137
Validation loss: 2.736650661564943

Epoch: 6| Step: 7
Training loss: 3.016164148391786
Validation loss: 2.7310526719604784

Epoch: 6| Step: 8
Training loss: 2.953760149434233
Validation loss: 2.7324945484041656

Epoch: 6| Step: 9
Training loss: 3.175104310732673
Validation loss: 2.7302949388164643

Epoch: 6| Step: 10
Training loss: 3.452854335758293
Validation loss: 2.7315659868461757

Epoch: 6| Step: 11
Training loss: 3.2307627681346154
Validation loss: 2.732781310792261

Epoch: 6| Step: 12
Training loss: 3.090169665175411
Validation loss: 2.73242684573891

Epoch: 6| Step: 13
Training loss: 3.120539419053882
Validation loss: 2.7284098495374143

Epoch: 245| Step: 0
Training loss: 2.5781390565431197
Validation loss: 2.7415674003551227

Epoch: 6| Step: 1
Training loss: 3.653874334620478
Validation loss: 2.7449624046872594

Epoch: 6| Step: 2
Training loss: 2.6239064073037266
Validation loss: 2.7374011249023242

Epoch: 6| Step: 3
Training loss: 3.132803824167772
Validation loss: 2.745738700147082

Epoch: 6| Step: 4
Training loss: 2.762832007156437
Validation loss: 2.7557346087868995

Epoch: 6| Step: 5
Training loss: 2.5894414206605862
Validation loss: 2.7587653884939125

Epoch: 6| Step: 6
Training loss: 2.724745617813379
Validation loss: 2.770830508932382

Epoch: 6| Step: 7
Training loss: 3.0609600321401413
Validation loss: 2.772079295579915

Epoch: 6| Step: 8
Training loss: 2.8088984848044993
Validation loss: 2.769169099390742

Epoch: 6| Step: 9
Training loss: 2.3683385285283163
Validation loss: 2.762548994250612

Epoch: 6| Step: 10
Training loss: 3.536592880783246
Validation loss: 2.7602719833029865

Epoch: 6| Step: 11
Training loss: 4.2552955397498815
Validation loss: 2.7622279383114803

Epoch: 6| Step: 12
Training loss: 2.889845294441497
Validation loss: 2.764133439320919

Epoch: 6| Step: 13
Training loss: 3.2686498039454333
Validation loss: 2.752721871393596

Epoch: 246| Step: 0
Training loss: 3.609070207681897
Validation loss: 2.7563902385179313

Epoch: 6| Step: 1
Training loss: 3.2430359982525503
Validation loss: 2.751478468967162

Epoch: 6| Step: 2
Training loss: 3.463410262672184
Validation loss: 2.740578647058351

Epoch: 6| Step: 3
Training loss: 2.479831595702013
Validation loss: 2.7379063636403815

Epoch: 6| Step: 4
Training loss: 2.8353936801028166
Validation loss: 2.737942450359883

Epoch: 6| Step: 5
Training loss: 2.7902031283796576
Validation loss: 2.730829898909261

Epoch: 6| Step: 6
Training loss: 3.463356154595808
Validation loss: 2.7301414162445052

Epoch: 6| Step: 7
Training loss: 2.0164246857963155
Validation loss: 2.7235446491022857

Epoch: 6| Step: 8
Training loss: 2.9885874472925744
Validation loss: 2.7249267553228793

Epoch: 6| Step: 9
Training loss: 3.1381449610218324
Validation loss: 2.721994353201152

Epoch: 6| Step: 10
Training loss: 3.3234205352249777
Validation loss: 2.7235965107684144

Epoch: 6| Step: 11
Training loss: 2.9089175871672035
Validation loss: 2.721591790519948

Epoch: 6| Step: 12
Training loss: 2.879362197029427
Validation loss: 2.7277076451474476

Epoch: 6| Step: 13
Training loss: 3.116979912368523
Validation loss: 2.7262267897343087

Epoch: 247| Step: 0
Training loss: 2.4366915413577916
Validation loss: 2.741104974805165

Epoch: 6| Step: 1
Training loss: 2.9361903741010846
Validation loss: 2.744737175832185

Epoch: 6| Step: 2
Training loss: 3.2925109907124686
Validation loss: 2.743505096325498

Epoch: 6| Step: 3
Training loss: 3.564334597772483
Validation loss: 2.7396901917451055

Epoch: 6| Step: 4
Training loss: 2.891163378917516
Validation loss: 2.7321548313242965

Epoch: 6| Step: 5
Training loss: 2.701947611799981
Validation loss: 2.730597250640416

Epoch: 6| Step: 6
Training loss: 3.364130389232385
Validation loss: 2.7237414936050555

Epoch: 6| Step: 7
Training loss: 3.805101313401395
Validation loss: 2.718820249682198

Epoch: 6| Step: 8
Training loss: 3.1713701419529237
Validation loss: 2.71786200033994

Epoch: 6| Step: 9
Training loss: 3.62344458522984
Validation loss: 2.7160955919225422

Epoch: 6| Step: 10
Training loss: 2.6939661173852714
Validation loss: 2.716929533333872

Epoch: 6| Step: 11
Training loss: 2.6050926291604966
Validation loss: 2.710547609925881

Epoch: 6| Step: 12
Training loss: 2.3687680447578066
Validation loss: 2.7144499500144

Epoch: 6| Step: 13
Training loss: 2.2473649383460574
Validation loss: 2.7110142169908737

Epoch: 248| Step: 0
Training loss: 3.360063775002272
Validation loss: 2.714140447214588

Epoch: 6| Step: 1
Training loss: 2.7944209238338713
Validation loss: 2.723120512998526

Epoch: 6| Step: 2
Training loss: 3.117393391246304
Validation loss: 2.7277247926876025

Epoch: 6| Step: 3
Training loss: 3.199042421355999
Validation loss: 2.7309759846813586

Epoch: 6| Step: 4
Training loss: 3.4231278029133128
Validation loss: 2.727409172335031

Epoch: 6| Step: 5
Training loss: 3.5225988772980945
Validation loss: 2.730497897096121

Epoch: 6| Step: 6
Training loss: 3.0788141244087295
Validation loss: 2.737151475672378

Epoch: 6| Step: 7
Training loss: 2.9627229244523012
Validation loss: 2.7455412095061473

Epoch: 6| Step: 8
Training loss: 2.8538857389058134
Validation loss: 2.7264659293407703

Epoch: 6| Step: 9
Training loss: 3.363154640428687
Validation loss: 2.724823766576999

Epoch: 6| Step: 10
Training loss: 3.0037144871333634
Validation loss: 2.7114865470864538

Epoch: 6| Step: 11
Training loss: 2.430180931890639
Validation loss: 2.71111466279053

Epoch: 6| Step: 12
Training loss: 2.655077507195198
Validation loss: 2.714262899657898

Epoch: 6| Step: 13
Training loss: 1.828563800544666
Validation loss: 2.7105048196259753

Epoch: 249| Step: 0
Training loss: 3.4589867185286387
Validation loss: 2.708491174217594

Epoch: 6| Step: 1
Training loss: 2.864136447149581
Validation loss: 2.7086046075126076

Epoch: 6| Step: 2
Training loss: 3.2491550814459647
Validation loss: 2.7048855312696456

Epoch: 6| Step: 3
Training loss: 2.783536164284714
Validation loss: 2.707956526095916

Epoch: 6| Step: 4
Training loss: 2.7800882892173595
Validation loss: 2.7102510612145165

Epoch: 6| Step: 5
Training loss: 3.6341538444793775
Validation loss: 2.7104326660953233

Epoch: 6| Step: 6
Training loss: 2.715035718538873
Validation loss: 2.712682434951487

Epoch: 6| Step: 7
Training loss: 3.4824900639180703
Validation loss: 2.7257795562808007

Epoch: 6| Step: 8
Training loss: 3.201067454396301
Validation loss: 2.7290078090063794

Epoch: 6| Step: 9
Training loss: 2.7574915712699832
Validation loss: 2.7184318843874307

Epoch: 6| Step: 10
Training loss: 2.6156573477035754
Validation loss: 2.721384605256719

Epoch: 6| Step: 11
Training loss: 2.4784806101003807
Validation loss: 2.7217584621228523

Epoch: 6| Step: 12
Training loss: 3.235000476159086
Validation loss: 2.723136189727036

Epoch: 6| Step: 13
Training loss: 2.775609415169907
Validation loss: 2.736815283586483

Epoch: 250| Step: 0
Training loss: 3.1570034827333076
Validation loss: 2.725998788443164

Epoch: 6| Step: 1
Training loss: 3.14410723558181
Validation loss: 2.7241650474317995

Epoch: 6| Step: 2
Training loss: 3.549159721540284
Validation loss: 2.732511966128471

Epoch: 6| Step: 3
Training loss: 2.771677753780331
Validation loss: 2.721040097119343

Epoch: 6| Step: 4
Training loss: 2.9983441233445216
Validation loss: 2.7195301419390567

Epoch: 6| Step: 5
Training loss: 3.3982280096620734
Validation loss: 2.7236555428398197

Epoch: 6| Step: 6
Training loss: 2.9584705876133763
Validation loss: 2.713508707948214

Epoch: 6| Step: 7
Training loss: 3.1531713597620152
Validation loss: 2.708497450583388

Epoch: 6| Step: 8
Training loss: 2.6515881188166017
Validation loss: 2.7000811917088794

Epoch: 6| Step: 9
Training loss: 3.4282999555650244
Validation loss: 2.704801152752165

Epoch: 6| Step: 10
Training loss: 2.649235517965679
Validation loss: 2.706387164356542

Epoch: 6| Step: 11
Training loss: 2.7205585296173522
Validation loss: 2.7051650687882023

Epoch: 6| Step: 12
Training loss: 3.1006620623036905
Validation loss: 2.7050263319295165

Epoch: 6| Step: 13
Training loss: 2.142023785078846
Validation loss: 2.7025068691768506

Epoch: 251| Step: 0
Training loss: 3.3877641412995674
Validation loss: 2.701610349716084

Epoch: 6| Step: 1
Training loss: 2.966599820130422
Validation loss: 2.701664744715258

Epoch: 6| Step: 2
Training loss: 3.2685568757928887
Validation loss: 2.7027395688362317

Epoch: 6| Step: 3
Training loss: 2.9059576072042352
Validation loss: 2.69609332634836

Epoch: 6| Step: 4
Training loss: 3.0459976889488183
Validation loss: 2.7048207098163064

Epoch: 6| Step: 5
Training loss: 3.6406855107464553
Validation loss: 2.7007412903491863

Epoch: 6| Step: 6
Training loss: 3.0852564579292023
Validation loss: 2.7080559379436253

Epoch: 6| Step: 7
Training loss: 3.1986029734480157
Validation loss: 2.6976629522668407

Epoch: 6| Step: 8
Training loss: 2.5810605069635018
Validation loss: 2.7072095311078823

Epoch: 6| Step: 9
Training loss: 2.6699359840405372
Validation loss: 2.704688667979611

Epoch: 6| Step: 10
Training loss: 2.4505222386765917
Validation loss: 2.7052261074541004

Epoch: 6| Step: 11
Training loss: 2.837112897775935
Validation loss: 2.7084924226769767

Epoch: 6| Step: 12
Training loss: 3.0453351164321
Validation loss: 2.7026175893414917

Epoch: 6| Step: 13
Training loss: 2.982041810006764
Validation loss: 2.71061607375732

Epoch: 252| Step: 0
Training loss: 2.5768634830858668
Validation loss: 2.7148430814319493

Epoch: 6| Step: 1
Training loss: 3.514772574608591
Validation loss: 2.7254426904226827

Epoch: 6| Step: 2
Training loss: 3.452814010494115
Validation loss: 2.756861584611922

Epoch: 6| Step: 3
Training loss: 3.100907186851894
Validation loss: 2.7547908230670206

Epoch: 6| Step: 4
Training loss: 2.7201755338015197
Validation loss: 2.758200001118937

Epoch: 6| Step: 5
Training loss: 2.4304004861925352
Validation loss: 2.7471933548127163

Epoch: 6| Step: 6
Training loss: 3.378318285639604
Validation loss: 2.739119847789717

Epoch: 6| Step: 7
Training loss: 2.9483492548462173
Validation loss: 2.7418967116990784

Epoch: 6| Step: 8
Training loss: 2.625842277183139
Validation loss: 2.747330198372437

Epoch: 6| Step: 9
Training loss: 3.596429638504604
Validation loss: 2.713226731523162

Epoch: 6| Step: 10
Training loss: 2.9194168929971593
Validation loss: 2.7245792390336794

Epoch: 6| Step: 11
Training loss: 2.518708797146224
Validation loss: 2.710789556019466

Epoch: 6| Step: 12
Training loss: 2.9657129111891862
Validation loss: 2.699187487145205

Epoch: 6| Step: 13
Training loss: 3.4365786618182836
Validation loss: 2.6930808833886695

Epoch: 253| Step: 0
Training loss: 2.986413708714787
Validation loss: 2.6959375180813123

Epoch: 6| Step: 1
Training loss: 2.015014319357149
Validation loss: 2.695470722602048

Epoch: 6| Step: 2
Training loss: 3.5805016499688542
Validation loss: 2.695003321176418

Epoch: 6| Step: 3
Training loss: 3.2501440749878627
Validation loss: 2.696079853879606

Epoch: 6| Step: 4
Training loss: 2.57593457196944
Validation loss: 2.6969924748886394

Epoch: 6| Step: 5
Training loss: 2.8931606409362574
Validation loss: 2.6948130840000593

Epoch: 6| Step: 6
Training loss: 2.6694980332359646
Validation loss: 2.7015342757284073

Epoch: 6| Step: 7
Training loss: 2.742798479054577
Validation loss: 2.696940613040466

Epoch: 6| Step: 8
Training loss: 2.9093781730396904
Validation loss: 2.689899036781567

Epoch: 6| Step: 9
Training loss: 3.3593659156853914
Validation loss: 2.693537463632144

Epoch: 6| Step: 10
Training loss: 3.312227921738175
Validation loss: 2.690040506542151

Epoch: 6| Step: 11
Training loss: 3.2572830465211045
Validation loss: 2.693724051634796

Epoch: 6| Step: 12
Training loss: 2.9945247276866094
Validation loss: 2.6966498206914835

Epoch: 6| Step: 13
Training loss: 3.70661356334474
Validation loss: 2.687835173562273

Epoch: 254| Step: 0
Training loss: 3.177709765769799
Validation loss: 2.6924570426965064

Epoch: 6| Step: 1
Training loss: 3.5844875221583337
Validation loss: 2.6945484411802205

Epoch: 6| Step: 2
Training loss: 2.9757790322870115
Validation loss: 2.7028878415161635

Epoch: 6| Step: 3
Training loss: 3.117273468132379
Validation loss: 2.714775300241965

Epoch: 6| Step: 4
Training loss: 2.971395498395618
Validation loss: 2.7484544977237557

Epoch: 6| Step: 5
Training loss: 2.8920372065027773
Validation loss: 2.7655706143638477

Epoch: 6| Step: 6
Training loss: 2.9436613357052765
Validation loss: 2.775480395611321

Epoch: 6| Step: 7
Training loss: 3.186469117057305
Validation loss: 2.799354837475112

Epoch: 6| Step: 8
Training loss: 2.526964492288739
Validation loss: 2.7965373925504537

Epoch: 6| Step: 9
Training loss: 2.803032091657238
Validation loss: 2.820296868026526

Epoch: 6| Step: 10
Training loss: 3.561667629510169
Validation loss: 2.82098582794034

Epoch: 6| Step: 11
Training loss: 2.9795773274257984
Validation loss: 2.799911758794723

Epoch: 6| Step: 12
Training loss: 3.0719044370589335
Validation loss: 2.7730564676631237

Epoch: 6| Step: 13
Training loss: 2.2162867022044797
Validation loss: 2.7686825390268988

Epoch: 255| Step: 0
Training loss: 2.151870703248347
Validation loss: 2.7664208944472715

Epoch: 6| Step: 1
Training loss: 3.3951172492970856
Validation loss: 2.7677690155583226

Epoch: 6| Step: 2
Training loss: 2.396250967583737
Validation loss: 2.7672566112429453

Epoch: 6| Step: 3
Training loss: 3.279552783716347
Validation loss: 2.7745564139197247

Epoch: 6| Step: 4
Training loss: 3.591883829961238
Validation loss: 2.7753932298452906

Epoch: 6| Step: 5
Training loss: 3.075083978017965
Validation loss: 2.771133150960555

Epoch: 6| Step: 6
Training loss: 2.943744920211912
Validation loss: 2.7750087060545114

Epoch: 6| Step: 7
Training loss: 3.2473573944990135
Validation loss: 2.776428480756785

Epoch: 6| Step: 8
Training loss: 3.173464522441572
Validation loss: 2.7706059330098736

Epoch: 6| Step: 9
Training loss: 3.335217579116665
Validation loss: 2.765165181024616

Epoch: 6| Step: 10
Training loss: 2.4469415765233253
Validation loss: 2.7718268411408484

Epoch: 6| Step: 11
Training loss: 3.1505407686633364
Validation loss: 2.772241770305999

Epoch: 6| Step: 12
Training loss: 3.461224752866528
Validation loss: 2.774798454349656

Epoch: 6| Step: 13
Training loss: 3.0825609494113717
Validation loss: 2.77166824258739

Epoch: 256| Step: 0
Training loss: 3.050992247725109
Validation loss: 2.769875245981632

Epoch: 6| Step: 1
Training loss: 3.414244902253422
Validation loss: 2.767152994834459

Epoch: 6| Step: 2
Training loss: 3.1438418183464925
Validation loss: 2.7713818713011995

Epoch: 6| Step: 3
Training loss: 3.2049189312422492
Validation loss: 2.7677276777256905

Epoch: 6| Step: 4
Training loss: 3.2922080033455483
Validation loss: 2.76582093886231

Epoch: 6| Step: 5
Training loss: 2.6438297485155395
Validation loss: 2.7626535136444277

Epoch: 6| Step: 6
Training loss: 2.865880850349658
Validation loss: 2.761331111818661

Epoch: 6| Step: 7
Training loss: 3.095197396831744
Validation loss: 2.756909386360512

Epoch: 6| Step: 8
Training loss: 3.214871041424256
Validation loss: 2.764457922187131

Epoch: 6| Step: 9
Training loss: 2.697131441550539
Validation loss: 2.761550843679861

Epoch: 6| Step: 10
Training loss: 3.566759206932026
Validation loss: 2.7582022987467414

Epoch: 6| Step: 11
Training loss: 2.3501450838795472
Validation loss: 2.760246046523865

Epoch: 6| Step: 12
Training loss: 3.1537231301437996
Validation loss: 2.7573816245845357

Epoch: 6| Step: 13
Training loss: 3.087049066764698
Validation loss: 2.75519273704942

Epoch: 257| Step: 0
Training loss: 2.6350287552771974
Validation loss: 2.7587538664388838

Epoch: 6| Step: 1
Training loss: 3.3872690776648366
Validation loss: 2.755227634329683

Epoch: 6| Step: 2
Training loss: 2.4670276669797513
Validation loss: 2.753875210471535

Epoch: 6| Step: 3
Training loss: 2.8655319215390667
Validation loss: 2.7544373596419347

Epoch: 6| Step: 4
Training loss: 3.3664136382345244
Validation loss: 2.751737172702902

Epoch: 6| Step: 5
Training loss: 3.2192535006584158
Validation loss: 2.74516670943299

Epoch: 6| Step: 6
Training loss: 4.03304918932931
Validation loss: 2.7474729145253476

Epoch: 6| Step: 7
Training loss: 2.742201237222981
Validation loss: 2.745650040220898

Epoch: 6| Step: 8
Training loss: 2.872694666867304
Validation loss: 2.738558535715682

Epoch: 6| Step: 9
Training loss: 3.58613748761507
Validation loss: 2.7296445632137494

Epoch: 6| Step: 10
Training loss: 2.6634538688008975
Validation loss: 2.7343175288429196

Epoch: 6| Step: 11
Training loss: 3.051720468521513
Validation loss: 2.718001186515196

Epoch: 6| Step: 12
Training loss: 2.7142361406947653
Validation loss: 2.7043066951506

Epoch: 6| Step: 13
Training loss: 2.5466554699230546
Validation loss: 2.707948482863694

Epoch: 258| Step: 0
Training loss: 2.6105311225302827
Validation loss: 2.6951656635051804

Epoch: 6| Step: 1
Training loss: 3.15598137345033
Validation loss: 2.6838802582288714

Epoch: 6| Step: 2
Training loss: 3.2233729080037783
Validation loss: 2.6861511455128855

Epoch: 6| Step: 3
Training loss: 2.072382859806761
Validation loss: 2.6896728380123927

Epoch: 6| Step: 4
Training loss: 3.341218649748874
Validation loss: 2.694765928354422

Epoch: 6| Step: 5
Training loss: 3.146945495725016
Validation loss: 2.6937862174819447

Epoch: 6| Step: 6
Training loss: 2.7256363222009057
Validation loss: 2.7056695154458184

Epoch: 6| Step: 7
Training loss: 3.1080169012133023
Validation loss: 2.6949170826467035

Epoch: 6| Step: 8
Training loss: 3.2028747460834497
Validation loss: 2.705997820893881

Epoch: 6| Step: 9
Training loss: 3.0985597156423124
Validation loss: 2.7059579846626494

Epoch: 6| Step: 10
Training loss: 3.356344870251197
Validation loss: 2.7026931585614804

Epoch: 6| Step: 11
Training loss: 3.287071078208282
Validation loss: 2.6907100274977425

Epoch: 6| Step: 12
Training loss: 2.8130373123628933
Validation loss: 2.687984387605616

Epoch: 6| Step: 13
Training loss: 2.5064355034800854
Validation loss: 2.6830663059259385

Epoch: 259| Step: 0
Training loss: 3.1643310432914706
Validation loss: 2.682957021544373

Epoch: 6| Step: 1
Training loss: 3.5341558062971123
Validation loss: 2.6866914678086555

Epoch: 6| Step: 2
Training loss: 2.83429731538042
Validation loss: 2.684739987149911

Epoch: 6| Step: 3
Training loss: 3.0415667338916483
Validation loss: 2.683504154615338

Epoch: 6| Step: 4
Training loss: 2.81172898638601
Validation loss: 2.682472410403526

Epoch: 6| Step: 5
Training loss: 3.114901285092216
Validation loss: 2.6849576462893094

Epoch: 6| Step: 6
Training loss: 2.9101387177009634
Validation loss: 2.680259574403918

Epoch: 6| Step: 7
Training loss: 2.6643358017688765
Validation loss: 2.6844943925989684

Epoch: 6| Step: 8
Training loss: 2.751673795928438
Validation loss: 2.686794423047228

Epoch: 6| Step: 9
Training loss: 2.6218522590314803
Validation loss: 2.685619884225695

Epoch: 6| Step: 10
Training loss: 3.073472898325001
Validation loss: 2.690320615513687

Epoch: 6| Step: 11
Training loss: 2.971894857217933
Validation loss: 2.6951875391059508

Epoch: 6| Step: 12
Training loss: 3.2171872984268695
Validation loss: 2.700768298823687

Epoch: 6| Step: 13
Training loss: 3.4595856448225564
Validation loss: 2.700207180322069

Epoch: 260| Step: 0
Training loss: 2.7481627829589397
Validation loss: 2.7122469723583364

Epoch: 6| Step: 1
Training loss: 2.799242349706677
Validation loss: 2.7073470756541824

Epoch: 6| Step: 2
Training loss: 2.5664265020723955
Validation loss: 2.6989469269491577

Epoch: 6| Step: 3
Training loss: 2.7654236111350894
Validation loss: 2.694441507338793

Epoch: 6| Step: 4
Training loss: 2.8270712728296994
Validation loss: 2.6909841954316307

Epoch: 6| Step: 5
Training loss: 3.288721207333548
Validation loss: 2.690367552724257

Epoch: 6| Step: 6
Training loss: 3.7104882540571524
Validation loss: 2.6820736146619426

Epoch: 6| Step: 7
Training loss: 3.3227172759851795
Validation loss: 2.6796827949753603

Epoch: 6| Step: 8
Training loss: 2.6596496368499176
Validation loss: 2.678736632058048

Epoch: 6| Step: 9
Training loss: 3.4071341950614067
Validation loss: 2.6835461497792754

Epoch: 6| Step: 10
Training loss: 3.18635164406278
Validation loss: 2.6781444432883665

Epoch: 6| Step: 11
Training loss: 3.276127185928365
Validation loss: 2.6787773171562965

Epoch: 6| Step: 12
Training loss: 2.923220564328392
Validation loss: 2.681448449314844

Epoch: 6| Step: 13
Training loss: 1.5763945959868264
Validation loss: 2.682243898378351

Epoch: 261| Step: 0
Training loss: 3.174112367079599
Validation loss: 2.678142261725904

Epoch: 6| Step: 1
Training loss: 3.2504900049403007
Validation loss: 2.6875832218793163

Epoch: 6| Step: 2
Training loss: 2.9461179891604288
Validation loss: 2.682089577188466

Epoch: 6| Step: 3
Training loss: 3.0195249332889946
Validation loss: 2.685654548641822

Epoch: 6| Step: 4
Training loss: 3.268406901396413
Validation loss: 2.689282889763322

Epoch: 6| Step: 5
Training loss: 2.7119123041946045
Validation loss: 2.702073167087963

Epoch: 6| Step: 6
Training loss: 2.703966395677176
Validation loss: 2.694512490677423

Epoch: 6| Step: 7
Training loss: 2.1993549094728357
Validation loss: 2.6975090855141866

Epoch: 6| Step: 8
Training loss: 3.057508488017143
Validation loss: 2.7022384469115592

Epoch: 6| Step: 9
Training loss: 3.3030223935159553
Validation loss: 2.7059547720072405

Epoch: 6| Step: 10
Training loss: 2.790462965068292
Validation loss: 2.7349006506198767

Epoch: 6| Step: 11
Training loss: 3.4580258765148773
Validation loss: 2.718911974830508

Epoch: 6| Step: 12
Training loss: 2.625292897913527
Validation loss: 2.7054833912038765

Epoch: 6| Step: 13
Training loss: 3.596167108126077
Validation loss: 2.7234995892599745

Epoch: 262| Step: 0
Training loss: 3.227036115786486
Validation loss: 2.703858560000648

Epoch: 6| Step: 1
Training loss: 2.845216980555766
Validation loss: 2.716680569641163

Epoch: 6| Step: 2
Training loss: 2.472149693095469
Validation loss: 2.7091003076608455

Epoch: 6| Step: 3
Training loss: 2.8923235877204307
Validation loss: 2.7131633981835352

Epoch: 6| Step: 4
Training loss: 2.473268068622975
Validation loss: 2.720060648103275

Epoch: 6| Step: 5
Training loss: 3.4269758553546295
Validation loss: 2.733987343962512

Epoch: 6| Step: 6
Training loss: 2.9900112754073334
Validation loss: 2.721344977307053

Epoch: 6| Step: 7
Training loss: 3.0041408571218344
Validation loss: 2.7026610082035134

Epoch: 6| Step: 8
Training loss: 2.6493100329742214
Validation loss: 2.6868864052003416

Epoch: 6| Step: 9
Training loss: 3.344843605388275
Validation loss: 2.681229884765891

Epoch: 6| Step: 10
Training loss: 3.1489681430924223
Validation loss: 2.6767338075725813

Epoch: 6| Step: 11
Training loss: 3.4417714716461214
Validation loss: 2.680565110488409

Epoch: 6| Step: 12
Training loss: 3.150069426725144
Validation loss: 2.6835223192594966

Epoch: 6| Step: 13
Training loss: 2.9084303685772337
Validation loss: 2.680616108045729

Epoch: 263| Step: 0
Training loss: 3.0272924012782303
Validation loss: 2.6844495434604414

Epoch: 6| Step: 1
Training loss: 3.007676951338977
Validation loss: 2.6837066308056943

Epoch: 6| Step: 2
Training loss: 3.335822288792859
Validation loss: 2.682308789461517

Epoch: 6| Step: 3
Training loss: 3.210226532497919
Validation loss: 2.6827368932550097

Epoch: 6| Step: 4
Training loss: 3.161198428854443
Validation loss: 2.682491451715764

Epoch: 6| Step: 5
Training loss: 2.9114156775628235
Validation loss: 2.681393835423088

Epoch: 6| Step: 6
Training loss: 2.9744718323215658
Validation loss: 2.680098368523466

Epoch: 6| Step: 7
Training loss: 2.939603985435202
Validation loss: 2.677434912941666

Epoch: 6| Step: 8
Training loss: 3.213784248350578
Validation loss: 2.679402914379924

Epoch: 6| Step: 9
Training loss: 2.5015986099829743
Validation loss: 2.676264556310122

Epoch: 6| Step: 10
Training loss: 2.9603402937062855
Validation loss: 2.6757035668934086

Epoch: 6| Step: 11
Training loss: 2.4604328909739293
Validation loss: 2.670656340924728

Epoch: 6| Step: 12
Training loss: 3.3687440323644093
Validation loss: 2.67035925515398

Epoch: 6| Step: 13
Training loss: 3.3239114800887553
Validation loss: 2.66962212044567

Epoch: 264| Step: 0
Training loss: 3.668401365595314
Validation loss: 2.6671920897724415

Epoch: 6| Step: 1
Training loss: 2.883866280343177
Validation loss: 2.6730240248154216

Epoch: 6| Step: 2
Training loss: 3.115874126120023
Validation loss: 2.670030248838633

Epoch: 6| Step: 3
Training loss: 2.600569801982425
Validation loss: 2.6703165351367097

Epoch: 6| Step: 4
Training loss: 2.597909005854084
Validation loss: 2.669619118543239

Epoch: 6| Step: 5
Training loss: 2.5938464227241664
Validation loss: 2.6798668415738494

Epoch: 6| Step: 6
Training loss: 2.3274422482906894
Validation loss: 2.6793286717617693

Epoch: 6| Step: 7
Training loss: 3.334444162926017
Validation loss: 2.686804124007995

Epoch: 6| Step: 8
Training loss: 2.994156869146248
Validation loss: 2.7066327965020154

Epoch: 6| Step: 9
Training loss: 3.2069769795480405
Validation loss: 2.7043809023534857

Epoch: 6| Step: 10
Training loss: 3.4046527722475246
Validation loss: 2.7071303179746637

Epoch: 6| Step: 11
Training loss: 3.0794656225565844
Validation loss: 2.702612960282218

Epoch: 6| Step: 12
Training loss: 3.1630918167686177
Validation loss: 2.699433490458808

Epoch: 6| Step: 13
Training loss: 2.70352134665402
Validation loss: 2.695097948653852

Epoch: 265| Step: 0
Training loss: 2.820761013559581
Validation loss: 2.696865874103574

Epoch: 6| Step: 1
Training loss: 2.3785353999475625
Validation loss: 2.687966475338186

Epoch: 6| Step: 2
Training loss: 3.265497962634447
Validation loss: 2.698456723510924

Epoch: 6| Step: 3
Training loss: 3.0988437834439884
Validation loss: 2.7004774653424737

Epoch: 6| Step: 4
Training loss: 2.3221565907566677
Validation loss: 2.702897924810165

Epoch: 6| Step: 5
Training loss: 3.533451710523378
Validation loss: 2.6969229646326585

Epoch: 6| Step: 6
Training loss: 2.9015267661117465
Validation loss: 2.6931368699704383

Epoch: 6| Step: 7
Training loss: 3.0829383665860024
Validation loss: 2.6936323272430345

Epoch: 6| Step: 8
Training loss: 3.081993189819654
Validation loss: 2.687891405797569

Epoch: 6| Step: 9
Training loss: 3.5382537254497706
Validation loss: 2.699179025520983

Epoch: 6| Step: 10
Training loss: 3.1958701246415915
Validation loss: 2.68782637289209

Epoch: 6| Step: 11
Training loss: 2.9209687974746172
Validation loss: 2.6946597052609143

Epoch: 6| Step: 12
Training loss: 2.9908646729674
Validation loss: 2.6870096002008936

Epoch: 6| Step: 13
Training loss: 2.1681776891152507
Validation loss: 2.6823674427913167

Epoch: 266| Step: 0
Training loss: 2.6545247477665614
Validation loss: 2.6708923444157073

Epoch: 6| Step: 1
Training loss: 2.8556505972469965
Validation loss: 2.6702039542778078

Epoch: 6| Step: 2
Training loss: 3.125618530095877
Validation loss: 2.6648007579670394

Epoch: 6| Step: 3
Training loss: 3.1829589210805302
Validation loss: 2.6631126376448266

Epoch: 6| Step: 4
Training loss: 2.749135488391344
Validation loss: 2.667459370734748

Epoch: 6| Step: 5
Training loss: 3.1168148420336883
Validation loss: 2.666962405951328

Epoch: 6| Step: 6
Training loss: 3.362175488323331
Validation loss: 2.6698805047585847

Epoch: 6| Step: 7
Training loss: 2.8112408680510965
Validation loss: 2.6734555878987485

Epoch: 6| Step: 8
Training loss: 2.849338615370933
Validation loss: 2.6657284161491734

Epoch: 6| Step: 9
Training loss: 3.333810454236322
Validation loss: 2.6689309225446434

Epoch: 6| Step: 10
Training loss: 3.5230153712712324
Validation loss: 2.6728772481636955

Epoch: 6| Step: 11
Training loss: 2.5808560788962227
Validation loss: 2.681900360176941

Epoch: 6| Step: 12
Training loss: 2.579531476705168
Validation loss: 2.6920210810872325

Epoch: 6| Step: 13
Training loss: 3.01299079917417
Validation loss: 2.680070592161445

Epoch: 267| Step: 0
Training loss: 3.3525895543550663
Validation loss: 2.679478850335076

Epoch: 6| Step: 1
Training loss: 2.5716930264769977
Validation loss: 2.6807055054057845

Epoch: 6| Step: 2
Training loss: 2.929109643532145
Validation loss: 2.679670321549602

Epoch: 6| Step: 3
Training loss: 2.715321889802474
Validation loss: 2.6825809232394127

Epoch: 6| Step: 4
Training loss: 3.0163522742677897
Validation loss: 2.681518426667684

Epoch: 6| Step: 5
Training loss: 3.3532281040292156
Validation loss: 2.6682608713902507

Epoch: 6| Step: 6
Training loss: 2.5366612744200947
Validation loss: 2.6743349280714623

Epoch: 6| Step: 7
Training loss: 3.2359541571615282
Validation loss: 2.6641495159698643

Epoch: 6| Step: 8
Training loss: 3.155383604883838
Validation loss: 2.6651924086868433

Epoch: 6| Step: 9
Training loss: 2.9225794305115005
Validation loss: 2.6640524535169687

Epoch: 6| Step: 10
Training loss: 2.632038127089654
Validation loss: 2.6619756151884704

Epoch: 6| Step: 11
Training loss: 3.2029929529279872
Validation loss: 2.6635358342340627

Epoch: 6| Step: 12
Training loss: 3.075922143880967
Validation loss: 2.659783608091891

Epoch: 6| Step: 13
Training loss: 3.1787851913850282
Validation loss: 2.6642621313510895

Epoch: 268| Step: 0
Training loss: 3.455185357516636
Validation loss: 2.6623140204556854

Epoch: 6| Step: 1
Training loss: 2.8934434501800186
Validation loss: 2.67334537074185

Epoch: 6| Step: 2
Training loss: 3.0254379081602076
Validation loss: 2.6643069334997254

Epoch: 6| Step: 3
Training loss: 2.501169503368878
Validation loss: 2.6624451885005356

Epoch: 6| Step: 4
Training loss: 2.9566809825987868
Validation loss: 2.6584759992342457

Epoch: 6| Step: 5
Training loss: 3.7721520044841887
Validation loss: 2.66266896618119

Epoch: 6| Step: 6
Training loss: 2.4885718446937375
Validation loss: 2.6676284375292094

Epoch: 6| Step: 7
Training loss: 2.5782336587838364
Validation loss: 2.6691741965884273

Epoch: 6| Step: 8
Training loss: 2.6572917914804877
Validation loss: 2.667069960933472

Epoch: 6| Step: 9
Training loss: 2.824075571232337
Validation loss: 2.6698357222020306

Epoch: 6| Step: 10
Training loss: 3.2154930450976393
Validation loss: 2.671216515974854

Epoch: 6| Step: 11
Training loss: 3.2843292320249344
Validation loss: 2.669601496942991

Epoch: 6| Step: 12
Training loss: 2.619388030995291
Validation loss: 2.6735505628359695

Epoch: 6| Step: 13
Training loss: 3.456136227713213
Validation loss: 2.674940826647833

Epoch: 269| Step: 0
Training loss: 3.078644994198775
Validation loss: 2.679920851394735

Epoch: 6| Step: 1
Training loss: 2.886982205025904
Validation loss: 2.6772100291663268

Epoch: 6| Step: 2
Training loss: 3.131155436719245
Validation loss: 2.6831882121010198

Epoch: 6| Step: 3
Training loss: 3.074891846778479
Validation loss: 2.6825214240194555

Epoch: 6| Step: 4
Training loss: 3.7309644120154224
Validation loss: 2.6994354249884496

Epoch: 6| Step: 5
Training loss: 3.3099421576202794
Validation loss: 2.6778024456412557

Epoch: 6| Step: 6
Training loss: 2.402628563845878
Validation loss: 2.6740797381038917

Epoch: 6| Step: 7
Training loss: 2.5603786154253423
Validation loss: 2.6598951572895158

Epoch: 6| Step: 8
Training loss: 3.0449528817977076
Validation loss: 2.6575962426397988

Epoch: 6| Step: 9
Training loss: 2.3373649598959747
Validation loss: 2.660907179136726

Epoch: 6| Step: 10
Training loss: 3.4090999614710986
Validation loss: 2.659974402713846

Epoch: 6| Step: 11
Training loss: 3.0179369666795686
Validation loss: 2.663225715605031

Epoch: 6| Step: 12
Training loss: 2.997413951157278
Validation loss: 2.662478409908344

Epoch: 6| Step: 13
Training loss: 2.560073820480299
Validation loss: 2.662204871236887

Epoch: 270| Step: 0
Training loss: 2.984674888043402
Validation loss: 2.6594350087433876

Epoch: 6| Step: 1
Training loss: 3.3062154786123097
Validation loss: 2.6608816264966575

Epoch: 6| Step: 2
Training loss: 2.1763639097951626
Validation loss: 2.666325601819215

Epoch: 6| Step: 3
Training loss: 3.17817265747707
Validation loss: 2.6630161804718337

Epoch: 6| Step: 4
Training loss: 3.1711276071136187
Validation loss: 2.6698143388856486

Epoch: 6| Step: 5
Training loss: 3.1158230120792387
Validation loss: 2.668166992786215

Epoch: 6| Step: 6
Training loss: 2.914035173139715
Validation loss: 2.6669156114705665

Epoch: 6| Step: 7
Training loss: 2.9307104333948075
Validation loss: 2.6728931754531295

Epoch: 6| Step: 8
Training loss: 3.095767201623919
Validation loss: 2.6879007527654153

Epoch: 6| Step: 9
Training loss: 3.3581750900307052
Validation loss: 2.6905268121989234

Epoch: 6| Step: 10
Training loss: 2.634892850141363
Validation loss: 2.702149923228939

Epoch: 6| Step: 11
Training loss: 3.0073795155580454
Validation loss: 2.701980589461508

Epoch: 6| Step: 12
Training loss: 2.823672335410692
Validation loss: 2.7082752710623152

Epoch: 6| Step: 13
Training loss: 3.111950598336879
Validation loss: 2.6903299769115963

Epoch: 271| Step: 0
Training loss: 3.1972253572029
Validation loss: 2.6827728754183644

Epoch: 6| Step: 1
Training loss: 2.3663118965126193
Validation loss: 2.669879174390061

Epoch: 6| Step: 2
Training loss: 3.0904861341855687
Validation loss: 2.668880327994475

Epoch: 6| Step: 3
Training loss: 3.3410195584219946
Validation loss: 2.6670942743985977

Epoch: 6| Step: 4
Training loss: 2.8856028876594495
Validation loss: 2.6644295093904034

Epoch: 6| Step: 5
Training loss: 3.310687450923913
Validation loss: 2.668032923631852

Epoch: 6| Step: 6
Training loss: 3.5612496306612327
Validation loss: 2.662192976525021

Epoch: 6| Step: 7
Training loss: 2.9188373299385115
Validation loss: 2.664882051857258

Epoch: 6| Step: 8
Training loss: 2.330277440003163
Validation loss: 2.6603869059191894

Epoch: 6| Step: 9
Training loss: 2.2628544145212612
Validation loss: 2.6622718251855693

Epoch: 6| Step: 10
Training loss: 2.9492305528013
Validation loss: 2.6620710131800505

Epoch: 6| Step: 11
Training loss: 3.4376155487060456
Validation loss: 2.663183477985007

Epoch: 6| Step: 12
Training loss: 3.2305770911208427
Validation loss: 2.6647770359187892

Epoch: 6| Step: 13
Training loss: 2.18523584083829
Validation loss: 2.6612874568949882

Epoch: 272| Step: 0
Training loss: 2.8968651303284707
Validation loss: 2.6629152739696944

Epoch: 6| Step: 1
Training loss: 2.7563073046343303
Validation loss: 2.659139567341757

Epoch: 6| Step: 2
Training loss: 3.2974377192587183
Validation loss: 2.6617393431189895

Epoch: 6| Step: 3
Training loss: 2.5987804303536706
Validation loss: 2.656954740958733

Epoch: 6| Step: 4
Training loss: 3.4362255161338715
Validation loss: 2.661020197634732

Epoch: 6| Step: 5
Training loss: 3.404739464918661
Validation loss: 2.6613222638907823

Epoch: 6| Step: 6
Training loss: 2.6433088218575524
Validation loss: 2.6586703657705724

Epoch: 6| Step: 7
Training loss: 3.2840484311601688
Validation loss: 2.658916376764165

Epoch: 6| Step: 8
Training loss: 2.587379998266998
Validation loss: 2.6617531102763827

Epoch: 6| Step: 9
Training loss: 3.185083408191797
Validation loss: 2.658891699747815

Epoch: 6| Step: 10
Training loss: 2.3587817526228125
Validation loss: 2.660406973532197

Epoch: 6| Step: 11
Training loss: 2.8961475302490673
Validation loss: 2.6610519984862115

Epoch: 6| Step: 12
Training loss: 3.3409626118389975
Validation loss: 2.6635571842185213

Epoch: 6| Step: 13
Training loss: 2.883668519164082
Validation loss: 2.6620324909428397

Epoch: 273| Step: 0
Training loss: 3.3682784505981926
Validation loss: 2.671663016949833

Epoch: 6| Step: 1
Training loss: 3.1290516337361574
Validation loss: 2.6681809343155636

Epoch: 6| Step: 2
Training loss: 3.1532129462598064
Validation loss: 2.6721007654650744

Epoch: 6| Step: 3
Training loss: 3.4203440407265457
Validation loss: 2.6995890195581507

Epoch: 6| Step: 4
Training loss: 3.063468001611803
Validation loss: 2.6852604892204295

Epoch: 6| Step: 5
Training loss: 2.7882910764889277
Validation loss: 2.671895482180823

Epoch: 6| Step: 6
Training loss: 3.2722827267481662
Validation loss: 2.6713050801035605

Epoch: 6| Step: 7
Training loss: 2.7269114623516177
Validation loss: 2.6712082123973944

Epoch: 6| Step: 8
Training loss: 2.2720328379796606
Validation loss: 2.6679253440505017

Epoch: 6| Step: 9
Training loss: 3.2687347061645533
Validation loss: 2.6599492160286493

Epoch: 6| Step: 10
Training loss: 2.222785503470746
Validation loss: 2.6591630899849363

Epoch: 6| Step: 11
Training loss: 2.56914458945167
Validation loss: 2.655138139903188

Epoch: 6| Step: 12
Training loss: 3.143297415400362
Validation loss: 2.6571596560526776

Epoch: 6| Step: 13
Training loss: 3.164505539005499
Validation loss: 2.6582536122300864

Epoch: 274| Step: 0
Training loss: 2.5165260549341335
Validation loss: 2.6525877653466154

Epoch: 6| Step: 1
Training loss: 2.3392812215081755
Validation loss: 2.657572489080808

Epoch: 6| Step: 2
Training loss: 3.584187664534268
Validation loss: 2.6568580254865273

Epoch: 6| Step: 3
Training loss: 2.687654357735621
Validation loss: 2.6580971102690385

Epoch: 6| Step: 4
Training loss: 2.720467912593741
Validation loss: 2.6566116965023316

Epoch: 6| Step: 5
Training loss: 2.962714555270342
Validation loss: 2.658043111275062

Epoch: 6| Step: 6
Training loss: 2.8799155962020064
Validation loss: 2.657770861052167

Epoch: 6| Step: 7
Training loss: 2.9672939544592496
Validation loss: 2.660986302897914

Epoch: 6| Step: 8
Training loss: 3.54477067945472
Validation loss: 2.6661612976511773

Epoch: 6| Step: 9
Training loss: 3.2106782014941646
Validation loss: 2.665894650089985

Epoch: 6| Step: 10
Training loss: 3.1797294895108363
Validation loss: 2.6719654487480065

Epoch: 6| Step: 11
Training loss: 3.0828352001686574
Validation loss: 2.6645990560985715

Epoch: 6| Step: 12
Training loss: 3.0629732972916814
Validation loss: 2.684412830268674

Epoch: 6| Step: 13
Training loss: 2.691253967849209
Validation loss: 2.675684302896901

Epoch: 275| Step: 0
Training loss: 2.3868791741681514
Validation loss: 2.6840644544581145

Epoch: 6| Step: 1
Training loss: 2.9656772170780816
Validation loss: 2.679911886982012

Epoch: 6| Step: 2
Training loss: 3.075648516987731
Validation loss: 2.7082257456901258

Epoch: 6| Step: 3
Training loss: 2.799904147278573
Validation loss: 2.7010838231899394

Epoch: 6| Step: 4
Training loss: 2.540834342711955
Validation loss: 2.698954654106186

Epoch: 6| Step: 5
Training loss: 3.418230179734172
Validation loss: 2.691573677360335

Epoch: 6| Step: 6
Training loss: 3.3879627376250236
Validation loss: 2.677186712011289

Epoch: 6| Step: 7
Training loss: 2.7536858220182414
Validation loss: 2.6749369365337783

Epoch: 6| Step: 8
Training loss: 3.3332770501789244
Validation loss: 2.6846845932092607

Epoch: 6| Step: 9
Training loss: 2.420920103775576
Validation loss: 2.676611649574809

Epoch: 6| Step: 10
Training loss: 3.3871937630943285
Validation loss: 2.6731397063953364

Epoch: 6| Step: 11
Training loss: 3.1514632686487998
Validation loss: 2.6667517709675117

Epoch: 6| Step: 12
Training loss: 2.9236696005372202
Validation loss: 2.667899381531839

Epoch: 6| Step: 13
Training loss: 2.9888532502493126
Validation loss: 2.67081879629793

Epoch: 276| Step: 0
Training loss: 3.6335439294332996
Validation loss: 2.656813035970523

Epoch: 6| Step: 1
Training loss: 2.966367227108271
Validation loss: 2.652235824015637

Epoch: 6| Step: 2
Training loss: 2.6507655351545676
Validation loss: 2.649799541298837

Epoch: 6| Step: 3
Training loss: 2.5915729624335677
Validation loss: 2.6534431273265646

Epoch: 6| Step: 4
Training loss: 3.1684190686415286
Validation loss: 2.6509079246180947

Epoch: 6| Step: 5
Training loss: 2.4908446517828415
Validation loss: 2.655358602995321

Epoch: 6| Step: 6
Training loss: 2.9722686795637476
Validation loss: 2.6519329083838334

Epoch: 6| Step: 7
Training loss: 3.110765002692672
Validation loss: 2.654517517092372

Epoch: 6| Step: 8
Training loss: 3.196086164981604
Validation loss: 2.6555586077335245

Epoch: 6| Step: 9
Training loss: 2.776387969001981
Validation loss: 2.6534278668448676

Epoch: 6| Step: 10
Training loss: 3.1134425256710196
Validation loss: 2.6606071663050455

Epoch: 6| Step: 11
Training loss: 2.7358792772094516
Validation loss: 2.6662623659126212

Epoch: 6| Step: 12
Training loss: 3.1593193011557528
Validation loss: 2.6587122286443505

Epoch: 6| Step: 13
Training loss: 3.1066353388122225
Validation loss: 2.663191642937485

Epoch: 277| Step: 0
Training loss: 3.3753472608710537
Validation loss: 2.65840717913502

Epoch: 6| Step: 1
Training loss: 3.0439727263062153
Validation loss: 2.6530408202868525

Epoch: 6| Step: 2
Training loss: 3.100926254699547
Validation loss: 2.6569625101555125

Epoch: 6| Step: 3
Training loss: 2.656488385442742
Validation loss: 2.647871311156526

Epoch: 6| Step: 4
Training loss: 2.3585399640506255
Validation loss: 2.6527415336468456

Epoch: 6| Step: 5
Training loss: 2.751427799980781
Validation loss: 2.652453828858858

Epoch: 6| Step: 6
Training loss: 2.514733387521417
Validation loss: 2.655560420728898

Epoch: 6| Step: 7
Training loss: 3.1868461985538783
Validation loss: 2.666956155840375

Epoch: 6| Step: 8
Training loss: 2.2003895978148122
Validation loss: 2.660825520046356

Epoch: 6| Step: 9
Training loss: 3.372983259298048
Validation loss: 2.674122681773413

Epoch: 6| Step: 10
Training loss: 3.220010158925587
Validation loss: 2.666425894691345

Epoch: 6| Step: 11
Training loss: 3.5747888996246875
Validation loss: 2.676103550442223

Epoch: 6| Step: 12
Training loss: 3.3099605975153983
Validation loss: 2.661961171184421

Epoch: 6| Step: 13
Training loss: 2.5968497264747703
Validation loss: 2.6637911546664235

Epoch: 278| Step: 0
Training loss: 2.7555525816453588
Validation loss: 2.6553770866491253

Epoch: 6| Step: 1
Training loss: 2.7969093533755713
Validation loss: 2.6528602150548055

Epoch: 6| Step: 2
Training loss: 2.7607339832573974
Validation loss: 2.653931439592392

Epoch: 6| Step: 3
Training loss: 2.7499779787048872
Validation loss: 2.6566470057602123

Epoch: 6| Step: 4
Training loss: 3.361003534226062
Validation loss: 2.6485392407298938

Epoch: 6| Step: 5
Training loss: 2.9304940296080386
Validation loss: 2.65175982071313

Epoch: 6| Step: 6
Training loss: 3.061769203652213
Validation loss: 2.6515355806372085

Epoch: 6| Step: 7
Training loss: 3.0712367406612437
Validation loss: 2.651929307399879

Epoch: 6| Step: 8
Training loss: 3.0352030668244177
Validation loss: 2.663435540338926

Epoch: 6| Step: 9
Training loss: 3.3381794670045326
Validation loss: 2.6556539504965215

Epoch: 6| Step: 10
Training loss: 2.2379982121914703
Validation loss: 2.6637513455306943

Epoch: 6| Step: 11
Training loss: 3.2892838718461808
Validation loss: 2.657745294656335

Epoch: 6| Step: 12
Training loss: 3.278995575050563
Validation loss: 2.6674528421134167

Epoch: 6| Step: 13
Training loss: 2.7130909921957267
Validation loss: 2.653170617660995

Epoch: 279| Step: 0
Training loss: 2.7733243677410067
Validation loss: 2.659518028247758

Epoch: 6| Step: 1
Training loss: 3.1203215100841684
Validation loss: 2.671018710679775

Epoch: 6| Step: 2
Training loss: 2.9138543512289323
Validation loss: 2.6872164191976973

Epoch: 6| Step: 3
Training loss: 3.170539161246561
Validation loss: 2.681400433358097

Epoch: 6| Step: 4
Training loss: 2.208209184239818
Validation loss: 2.6758327219597575

Epoch: 6| Step: 5
Training loss: 2.7157688677818093
Validation loss: 2.670471082589245

Epoch: 6| Step: 6
Training loss: 3.0053926319927857
Validation loss: 2.667150788687387

Epoch: 6| Step: 7
Training loss: 2.9365914745713932
Validation loss: 2.666103896495832

Epoch: 6| Step: 8
Training loss: 3.0673145674018354
Validation loss: 2.6705053182148317

Epoch: 6| Step: 9
Training loss: 2.717604998935058
Validation loss: 2.662302063158825

Epoch: 6| Step: 10
Training loss: 3.062383221326602
Validation loss: 2.6628396426093186

Epoch: 6| Step: 11
Training loss: 3.2720706972258475
Validation loss: 2.656576657944831

Epoch: 6| Step: 12
Training loss: 3.3225143492010645
Validation loss: 2.668477069396826

Epoch: 6| Step: 13
Training loss: 3.3639133758731687
Validation loss: 2.6635321266997116

Epoch: 280| Step: 0
Training loss: 3.060761717441361
Validation loss: 2.6677505590598023

Epoch: 6| Step: 1
Training loss: 2.9151530743512275
Validation loss: 2.6692489252559506

Epoch: 6| Step: 2
Training loss: 2.6254215810205377
Validation loss: 2.652827995165871

Epoch: 6| Step: 3
Training loss: 2.7716429156281492
Validation loss: 2.6685729871812263

Epoch: 6| Step: 4
Training loss: 3.1921597995387097
Validation loss: 2.666601848070887

Epoch: 6| Step: 5
Training loss: 3.3202972770790735
Validation loss: 2.6559781451152658

Epoch: 6| Step: 6
Training loss: 3.0225693197954535
Validation loss: 2.660238043349628

Epoch: 6| Step: 7
Training loss: 2.873978142959848
Validation loss: 2.670714567667012

Epoch: 6| Step: 8
Training loss: 3.3978815435157017
Validation loss: 2.670279447140644

Epoch: 6| Step: 9
Training loss: 2.695632782855651
Validation loss: 2.672264197907481

Epoch: 6| Step: 10
Training loss: 3.448019957747971
Validation loss: 2.666728571460374

Epoch: 6| Step: 11
Training loss: 2.4326069945340447
Validation loss: 2.6718271689339566

Epoch: 6| Step: 12
Training loss: 2.765176682854523
Validation loss: 2.6567192189204594

Epoch: 6| Step: 13
Training loss: 2.871740566755894
Validation loss: 2.659127706158737

Epoch: 281| Step: 0
Training loss: 2.7132688496243413
Validation loss: 2.657214036723957

Epoch: 6| Step: 1
Training loss: 2.9540818697690727
Validation loss: 2.6572980440627085

Epoch: 6| Step: 2
Training loss: 3.625666589943916
Validation loss: 2.6587645121964765

Epoch: 6| Step: 3
Training loss: 2.7967113255181073
Validation loss: 2.6433728958802636

Epoch: 6| Step: 4
Training loss: 3.4501386476382723
Validation loss: 2.646106815972256

Epoch: 6| Step: 5
Training loss: 2.6773869284183287
Validation loss: 2.64895002414223

Epoch: 6| Step: 6
Training loss: 3.136676488760293
Validation loss: 2.6453894146764045

Epoch: 6| Step: 7
Training loss: 2.7233785057134603
Validation loss: 2.646224185779854

Epoch: 6| Step: 8
Training loss: 2.6160982968472513
Validation loss: 2.6500330944010875

Epoch: 6| Step: 9
Training loss: 3.209585234563757
Validation loss: 2.6480452425856846

Epoch: 6| Step: 10
Training loss: 3.3020927035963923
Validation loss: 2.649984468587542

Epoch: 6| Step: 11
Training loss: 3.025769657553074
Validation loss: 2.6505901515383625

Epoch: 6| Step: 12
Training loss: 2.5649711045093224
Validation loss: 2.6526513340038025

Epoch: 6| Step: 13
Training loss: 2.3691633684115465
Validation loss: 2.654571884287446

Epoch: 282| Step: 0
Training loss: 3.074007795335147
Validation loss: 2.6668775946761634

Epoch: 6| Step: 1
Training loss: 3.197231322834472
Validation loss: 2.6832411232066664

Epoch: 6| Step: 2
Training loss: 2.6317987952504347
Validation loss: 2.6766018235555733

Epoch: 6| Step: 3
Training loss: 2.8280915316292705
Validation loss: 2.6888644214520796

Epoch: 6| Step: 4
Training loss: 2.3928171715722546
Validation loss: 2.699722768443003

Epoch: 6| Step: 5
Training loss: 3.0279045914468283
Validation loss: 2.7131269667647593

Epoch: 6| Step: 6
Training loss: 3.081645830275503
Validation loss: 2.694387654431004

Epoch: 6| Step: 7
Training loss: 3.1104061391404874
Validation loss: 2.671785125823218

Epoch: 6| Step: 8
Training loss: 3.4222041280964453
Validation loss: 2.652072048592602

Epoch: 6| Step: 9
Training loss: 3.082598383834733
Validation loss: 2.650065026130717

Epoch: 6| Step: 10
Training loss: 2.9592384959464004
Validation loss: 2.6517073729466416

Epoch: 6| Step: 11
Training loss: 3.221557577871155
Validation loss: 2.6501682569768037

Epoch: 6| Step: 12
Training loss: 2.4768464801079113
Validation loss: 2.652455878839758

Epoch: 6| Step: 13
Training loss: 3.010947914283689
Validation loss: 2.6508419858504872

Epoch: 283| Step: 0
Training loss: 2.748537021242594
Validation loss: 2.654569252629876

Epoch: 6| Step: 1
Training loss: 2.9925543258949565
Validation loss: 2.6460489003257313

Epoch: 6| Step: 2
Training loss: 3.077881314463781
Validation loss: 2.6488620268864205

Epoch: 6| Step: 3
Training loss: 2.8733502505955753
Validation loss: 2.6480249215494176

Epoch: 6| Step: 4
Training loss: 3.2239136988067028
Validation loss: 2.653479901876703

Epoch: 6| Step: 5
Training loss: 3.1476600008800406
Validation loss: 2.6562217812242634

Epoch: 6| Step: 6
Training loss: 2.876378931158973
Validation loss: 2.666369737608808

Epoch: 6| Step: 7
Training loss: 3.3485124843957648
Validation loss: 2.6636527940910386

Epoch: 6| Step: 8
Training loss: 2.8782143246585083
Validation loss: 2.660062476651974

Epoch: 6| Step: 9
Training loss: 2.9544574617740933
Validation loss: 2.66435315798919

Epoch: 6| Step: 10
Training loss: 3.331830035414126
Validation loss: 2.6543302814531895

Epoch: 6| Step: 11
Training loss: 2.7844328081186025
Validation loss: 2.6476176663333284

Epoch: 6| Step: 12
Training loss: 2.4150334353136524
Validation loss: 2.642108170376812

Epoch: 6| Step: 13
Training loss: 2.772662847085963
Validation loss: 2.6463993763132763

Epoch: 284| Step: 0
Training loss: 2.7597998355761764
Validation loss: 2.6469082892145757

Epoch: 6| Step: 1
Training loss: 3.071119673140877
Validation loss: 2.6487054558901684

Epoch: 6| Step: 2
Training loss: 2.715730942041304
Validation loss: 2.655659306263564

Epoch: 6| Step: 3
Training loss: 3.153431757815014
Validation loss: 2.6621339470755037

Epoch: 6| Step: 4
Training loss: 3.052697511573652
Validation loss: 2.6705581479758584

Epoch: 6| Step: 5
Training loss: 3.046482158669376
Validation loss: 2.674846775158238

Epoch: 6| Step: 6
Training loss: 3.0728840626856586
Validation loss: 2.668867462117696

Epoch: 6| Step: 7
Training loss: 2.285243262566155
Validation loss: 2.6688251658551234

Epoch: 6| Step: 8
Training loss: 2.973770393984737
Validation loss: 2.6732934298971744

Epoch: 6| Step: 9
Training loss: 3.335528239175675
Validation loss: 2.6680586537633317

Epoch: 6| Step: 10
Training loss: 3.231874245529367
Validation loss: 2.660938347398858

Epoch: 6| Step: 11
Training loss: 2.7957433190520495
Validation loss: 2.6586285620224737

Epoch: 6| Step: 12
Training loss: 2.9894497051790188
Validation loss: 2.65675515203816

Epoch: 6| Step: 13
Training loss: 2.9948479600121383
Validation loss: 2.6602472060834836

Epoch: 285| Step: 0
Training loss: 3.0307978656641965
Validation loss: 2.657590718104151

Epoch: 6| Step: 1
Training loss: 3.116193493370166
Validation loss: 2.6605600519155246

Epoch: 6| Step: 2
Training loss: 3.2138889976185663
Validation loss: 2.663646915421598

Epoch: 6| Step: 3
Training loss: 2.81629365862629
Validation loss: 2.6557553423690066

Epoch: 6| Step: 4
Training loss: 2.7950277355094073
Validation loss: 2.653338435469531

Epoch: 6| Step: 5
Training loss: 2.8514327346330157
Validation loss: 2.6628380271195153

Epoch: 6| Step: 6
Training loss: 2.5327635584438113
Validation loss: 2.6579490579323886

Epoch: 6| Step: 7
Training loss: 2.8309300458721305
Validation loss: 2.657976984449939

Epoch: 6| Step: 8
Training loss: 3.233503141237393
Validation loss: 2.670176118194257

Epoch: 6| Step: 9
Training loss: 2.8534476123931842
Validation loss: 2.649479866023305

Epoch: 6| Step: 10
Training loss: 3.306940559713542
Validation loss: 2.658970824671194

Epoch: 6| Step: 11
Training loss: 3.1050470797644456
Validation loss: 2.6561956893512795

Epoch: 6| Step: 12
Training loss: 3.0960847926196755
Validation loss: 2.66458037568174

Epoch: 6| Step: 13
Training loss: 2.599563426264424
Validation loss: 2.6590713284216623

Epoch: 286| Step: 0
Training loss: 3.2914760550506332
Validation loss: 2.662180045587872

Epoch: 6| Step: 1
Training loss: 3.3934830253224866
Validation loss: 2.6514966984269064

Epoch: 6| Step: 2
Training loss: 2.944265164209524
Validation loss: 2.6516716643668077

Epoch: 6| Step: 3
Training loss: 2.075731318644624
Validation loss: 2.648899771877072

Epoch: 6| Step: 4
Training loss: 3.27519466607834
Validation loss: 2.655467219771439

Epoch: 6| Step: 5
Training loss: 2.21399253890823
Validation loss: 2.6523404927019043

Epoch: 6| Step: 6
Training loss: 2.3351901590814923
Validation loss: 2.645140302213655

Epoch: 6| Step: 7
Training loss: 3.5444397485503285
Validation loss: 2.6479790374506824

Epoch: 6| Step: 8
Training loss: 2.714967486079708
Validation loss: 2.6623583344469255

Epoch: 6| Step: 9
Training loss: 3.1709799419768383
Validation loss: 2.656215873561774

Epoch: 6| Step: 10
Training loss: 3.5003866254615303
Validation loss: 2.662601250989832

Epoch: 6| Step: 11
Training loss: 3.078271387947139
Validation loss: 2.6434461602254635

Epoch: 6| Step: 12
Training loss: 2.961281145027851
Validation loss: 2.6508371735352116

Epoch: 6| Step: 13
Training loss: 2.3443662723306598
Validation loss: 2.641329442298404

Epoch: 287| Step: 0
Training loss: 2.611835165165037
Validation loss: 2.6399687915056154

Epoch: 6| Step: 1
Training loss: 2.7728202885234934
Validation loss: 2.642827411070547

Epoch: 6| Step: 2
Training loss: 3.0883356361222742
Validation loss: 2.6404603471250403

Epoch: 6| Step: 3
Training loss: 3.211309629534836
Validation loss: 2.6370003814568816

Epoch: 6| Step: 4
Training loss: 3.499070452822217
Validation loss: 2.639740835386882

Epoch: 6| Step: 5
Training loss: 3.1749141771626888
Validation loss: 2.6432832183880124

Epoch: 6| Step: 6
Training loss: 2.8708559106419758
Validation loss: 2.6335818802188524

Epoch: 6| Step: 7
Training loss: 2.2089606299840057
Validation loss: 2.6459215217474448

Epoch: 6| Step: 8
Training loss: 2.385232865583376
Validation loss: 2.6430936825408877

Epoch: 6| Step: 9
Training loss: 2.96532346842632
Validation loss: 2.6554817589538433

Epoch: 6| Step: 10
Training loss: 3.375499405822566
Validation loss: 2.659608113571115

Epoch: 6| Step: 11
Training loss: 2.988713172165585
Validation loss: 2.659012240759814

Epoch: 6| Step: 12
Training loss: 3.166211714605342
Validation loss: 2.6641055608756505

Epoch: 6| Step: 13
Training loss: 3.1113813052089596
Validation loss: 2.6749744554368946

Epoch: 288| Step: 0
Training loss: 2.6021602276165106
Validation loss: 2.656375922078152

Epoch: 6| Step: 1
Training loss: 2.793700393133931
Validation loss: 2.641939048263101

Epoch: 6| Step: 2
Training loss: 3.2666653522826166
Validation loss: 2.6409810124707356

Epoch: 6| Step: 3
Training loss: 3.237316618332087
Validation loss: 2.6376290925103394

Epoch: 6| Step: 4
Training loss: 2.93130977219925
Validation loss: 2.6405885269996556

Epoch: 6| Step: 5
Training loss: 2.595821977797684
Validation loss: 2.6386462430537225

Epoch: 6| Step: 6
Training loss: 3.1476977215172557
Validation loss: 2.6311203275350246

Epoch: 6| Step: 7
Training loss: 3.6065416981687433
Validation loss: 2.6325122224690545

Epoch: 6| Step: 8
Training loss: 2.3261419465696456
Validation loss: 2.633561218819887

Epoch: 6| Step: 9
Training loss: 3.335752245295233
Validation loss: 2.632607181654768

Epoch: 6| Step: 10
Training loss: 2.2157034576255437
Validation loss: 2.6360292382220667

Epoch: 6| Step: 11
Training loss: 3.3576780779573423
Validation loss: 2.6319965227487296

Epoch: 6| Step: 12
Training loss: 3.135547842194553
Validation loss: 2.6341872091688394

Epoch: 6| Step: 13
Training loss: 2.4240908422727427
Validation loss: 2.6356212431668182

Epoch: 289| Step: 0
Training loss: 2.75369240221349
Validation loss: 2.6327409622260816

Epoch: 6| Step: 1
Training loss: 3.0890928723275293
Validation loss: 2.636645919055245

Epoch: 6| Step: 2
Training loss: 2.543846529691989
Validation loss: 2.6436185111874204

Epoch: 6| Step: 3
Training loss: 2.958216561891773
Validation loss: 2.6507649925933623

Epoch: 6| Step: 4
Training loss: 2.7346867846798717
Validation loss: 2.64972318146504

Epoch: 6| Step: 5
Training loss: 3.2232638809259075
Validation loss: 2.6594035211329823

Epoch: 6| Step: 6
Training loss: 3.2808401669279372
Validation loss: 2.6596590454771425

Epoch: 6| Step: 7
Training loss: 3.0618886532063487
Validation loss: 2.66299820519258

Epoch: 6| Step: 8
Training loss: 2.504041171195521
Validation loss: 2.651398128526218

Epoch: 6| Step: 9
Training loss: 3.54629646321927
Validation loss: 2.6447338668197347

Epoch: 6| Step: 10
Training loss: 2.7568983772928095
Validation loss: 2.6432123315916476

Epoch: 6| Step: 11
Training loss: 3.1939828806438055
Validation loss: 2.6393275958593727

Epoch: 6| Step: 12
Training loss: 2.658970415872533
Validation loss: 2.6346344956650887

Epoch: 6| Step: 13
Training loss: 3.209196709395092
Validation loss: 2.6388013328299986

Epoch: 290| Step: 0
Training loss: 2.778066978234881
Validation loss: 2.631698811515479

Epoch: 6| Step: 1
Training loss: 3.423405274622975
Validation loss: 2.63822153087191

Epoch: 6| Step: 2
Training loss: 2.8928141784168595
Validation loss: 2.6298985654105085

Epoch: 6| Step: 3
Training loss: 3.385734582303255
Validation loss: 2.6339576382502963

Epoch: 6| Step: 4
Training loss: 2.932392956535342
Validation loss: 2.636146786362405

Epoch: 6| Step: 5
Training loss: 3.0062852821738226
Validation loss: 2.634185667589737

Epoch: 6| Step: 6
Training loss: 3.015586734192938
Validation loss: 2.6466185574002465

Epoch: 6| Step: 7
Training loss: 2.6416299025166485
Validation loss: 2.6347601508670975

Epoch: 6| Step: 8
Training loss: 3.622721646664483
Validation loss: 2.647921582939815

Epoch: 6| Step: 9
Training loss: 2.108946580118949
Validation loss: 2.6461998147378436

Epoch: 6| Step: 10
Training loss: 2.920608327545768
Validation loss: 2.6491143980582867

Epoch: 6| Step: 11
Training loss: 2.920970103444204
Validation loss: 2.653642564430378

Epoch: 6| Step: 12
Training loss: 2.9160777632779915
Validation loss: 2.6589048221562805

Epoch: 6| Step: 13
Training loss: 2.55794100989116
Validation loss: 2.6492889765326497

Epoch: 291| Step: 0
Training loss: 2.7815404161708654
Validation loss: 2.647189123275907

Epoch: 6| Step: 1
Training loss: 2.5426765895197136
Validation loss: 2.6564693565445254

Epoch: 6| Step: 2
Training loss: 3.4583300548369404
Validation loss: 2.664179822603214

Epoch: 6| Step: 3
Training loss: 2.6082313452658386
Validation loss: 2.6625583419866645

Epoch: 6| Step: 4
Training loss: 3.188829780397061
Validation loss: 2.654512340585863

Epoch: 6| Step: 5
Training loss: 2.3438372786483574
Validation loss: 2.6431927919979024

Epoch: 6| Step: 6
Training loss: 2.637478822017454
Validation loss: 2.637908320586718

Epoch: 6| Step: 7
Training loss: 2.900656290442424
Validation loss: 2.635171654079738

Epoch: 6| Step: 8
Training loss: 3.714808835929515
Validation loss: 2.637827575470163

Epoch: 6| Step: 9
Training loss: 2.86165590459377
Validation loss: 2.6306257110281255

Epoch: 6| Step: 10
Training loss: 3.466910759573103
Validation loss: 2.6378528285685965

Epoch: 6| Step: 11
Training loss: 2.8997914732578454
Validation loss: 2.6355150671254126

Epoch: 6| Step: 12
Training loss: 3.1623031434319313
Validation loss: 2.638509542907855

Epoch: 6| Step: 13
Training loss: 2.447368598348614
Validation loss: 2.631731960285157

Epoch: 292| Step: 0
Training loss: 2.7185169865517955
Validation loss: 2.6364845240512276

Epoch: 6| Step: 1
Training loss: 2.1634692539175324
Validation loss: 2.636859326916393

Epoch: 6| Step: 2
Training loss: 2.9526421692136933
Validation loss: 2.6418976260411235

Epoch: 6| Step: 3
Training loss: 3.0392248899717393
Validation loss: 2.641708442039617

Epoch: 6| Step: 4
Training loss: 2.934808512587184
Validation loss: 2.648142144385799

Epoch: 6| Step: 5
Training loss: 2.7682662679076593
Validation loss: 2.6500516626016406

Epoch: 6| Step: 6
Training loss: 2.5334034930937435
Validation loss: 2.670318379394458

Epoch: 6| Step: 7
Training loss: 3.6430682059726993
Validation loss: 2.6835206990248524

Epoch: 6| Step: 8
Training loss: 3.1420863153753498
Validation loss: 2.674654856080419

Epoch: 6| Step: 9
Training loss: 3.070180797906849
Validation loss: 2.688065810093847

Epoch: 6| Step: 10
Training loss: 3.0112367632722643
Validation loss: 2.6714423629993345

Epoch: 6| Step: 11
Training loss: 3.5971279025548797
Validation loss: 2.6896390593945267

Epoch: 6| Step: 12
Training loss: 2.8099443480387127
Validation loss: 2.6678733140191064

Epoch: 6| Step: 13
Training loss: 2.7351746180161953
Validation loss: 2.6601175294537565

Epoch: 293| Step: 0
Training loss: 3.265893368439722
Validation loss: 2.6482217337629854

Epoch: 6| Step: 1
Training loss: 2.8057558367995714
Validation loss: 2.6323877406216316

Epoch: 6| Step: 2
Training loss: 2.9553351634018687
Validation loss: 2.634410137896397

Epoch: 6| Step: 3
Training loss: 2.7256083308153896
Validation loss: 2.6315224961787322

Epoch: 6| Step: 4
Training loss: 3.173148364705564
Validation loss: 2.6271688678672063

Epoch: 6| Step: 5
Training loss: 2.9244980079721055
Validation loss: 2.6277939069078435

Epoch: 6| Step: 6
Training loss: 2.6599688358919282
Validation loss: 2.6316027888754605

Epoch: 6| Step: 7
Training loss: 3.3891577292640966
Validation loss: 2.6307158843146703

Epoch: 6| Step: 8
Training loss: 3.0873352748156613
Validation loss: 2.62744745227671

Epoch: 6| Step: 9
Training loss: 2.6341125719581626
Validation loss: 2.621791070682098

Epoch: 6| Step: 10
Training loss: 2.9255581249929734
Validation loss: 2.624686142791851

Epoch: 6| Step: 11
Training loss: 2.3775056370809735
Validation loss: 2.6232070552027986

Epoch: 6| Step: 12
Training loss: 3.432113866682175
Validation loss: 2.6237181225656663

Epoch: 6| Step: 13
Training loss: 3.04839815068426
Validation loss: 2.6390258991688547

Epoch: 294| Step: 0
Training loss: 3.049567338867051
Validation loss: 2.6380442647325903

Epoch: 6| Step: 1
Training loss: 2.741749611694609
Validation loss: 2.6353592489215805

Epoch: 6| Step: 2
Training loss: 2.778057366181873
Validation loss: 2.6519261027617245

Epoch: 6| Step: 3
Training loss: 2.3966652351909215
Validation loss: 2.66758926420005

Epoch: 6| Step: 4
Training loss: 2.5208679911435214
Validation loss: 2.673877624970611

Epoch: 6| Step: 5
Training loss: 2.973574442674252
Validation loss: 2.701728688255053

Epoch: 6| Step: 6
Training loss: 2.986705728712542
Validation loss: 2.7025548364562026

Epoch: 6| Step: 7
Training loss: 2.8195554610153883
Validation loss: 2.6871240433485886

Epoch: 6| Step: 8
Training loss: 3.541793746164315
Validation loss: 2.708046885851169

Epoch: 6| Step: 9
Training loss: 2.935649857329526
Validation loss: 2.6950710973817524

Epoch: 6| Step: 10
Training loss: 3.3534755271154006
Validation loss: 2.7049287412337315

Epoch: 6| Step: 11
Training loss: 2.6018053462692956
Validation loss: 2.6886277547668933

Epoch: 6| Step: 12
Training loss: 3.214925475257926
Validation loss: 2.6730047539759183

Epoch: 6| Step: 13
Training loss: 3.7343257118707345
Validation loss: 2.6511502382204926

Epoch: 295| Step: 0
Training loss: 3.109725855676178
Validation loss: 2.623883609139013

Epoch: 6| Step: 1
Training loss: 3.4850148524401607
Validation loss: 2.627246416014407

Epoch: 6| Step: 2
Training loss: 2.9754463566191482
Validation loss: 2.6310303016009264

Epoch: 6| Step: 3
Training loss: 3.1285282816340936
Validation loss: 2.6296998290968374

Epoch: 6| Step: 4
Training loss: 2.870466389525576
Validation loss: 2.626564026766663

Epoch: 6| Step: 5
Training loss: 3.1987396738557257
Validation loss: 2.6339375822785187

Epoch: 6| Step: 6
Training loss: 2.8444692519549903
Validation loss: 2.6267608932106388

Epoch: 6| Step: 7
Training loss: 2.4782825357361524
Validation loss: 2.6292861902597777

Epoch: 6| Step: 8
Training loss: 2.9287083324638297
Validation loss: 2.6273183336763863

Epoch: 6| Step: 9
Training loss: 2.633211100031036
Validation loss: 2.6319167310411333

Epoch: 6| Step: 10
Training loss: 2.4098623334574616
Validation loss: 2.6305509815373447

Epoch: 6| Step: 11
Training loss: 3.0840239567599244
Validation loss: 2.6248803294571927

Epoch: 6| Step: 12
Training loss: 3.4760460630729537
Validation loss: 2.6279625472571295

Epoch: 6| Step: 13
Training loss: 2.768279358967127
Validation loss: 2.6339933699322593

Epoch: 296| Step: 0
Training loss: 2.9916704891538153
Validation loss: 2.6366469808189765

Epoch: 6| Step: 1
Training loss: 3.1582484197818714
Validation loss: 2.6465474320437026

Epoch: 6| Step: 2
Training loss: 3.2309088816520477
Validation loss: 2.643614601165364

Epoch: 6| Step: 3
Training loss: 2.9459956259762987
Validation loss: 2.65388961046298

Epoch: 6| Step: 4
Training loss: 3.186546482256542
Validation loss: 2.6574618746112275

Epoch: 6| Step: 5
Training loss: 3.344966061224632
Validation loss: 2.660833842536129

Epoch: 6| Step: 6
Training loss: 2.466745262783996
Validation loss: 2.6729113613743527

Epoch: 6| Step: 7
Training loss: 3.2990062026387323
Validation loss: 2.6657383966905326

Epoch: 6| Step: 8
Training loss: 2.4565323412579447
Validation loss: 2.6690604879405875

Epoch: 6| Step: 9
Training loss: 3.0765400015345943
Validation loss: 2.6609322459592004

Epoch: 6| Step: 10
Training loss: 2.323031595121158
Validation loss: 2.6593904773409314

Epoch: 6| Step: 11
Training loss: 3.2502750867185477
Validation loss: 2.635839609681992

Epoch: 6| Step: 12
Training loss: 2.7613291162059244
Validation loss: 2.630308922779645

Epoch: 6| Step: 13
Training loss: 2.5903332738127323
Validation loss: 2.63635774037737

Epoch: 297| Step: 0
Training loss: 2.910508512132259
Validation loss: 2.629245182004729

Epoch: 6| Step: 1
Training loss: 2.805829933858575
Validation loss: 2.6351030357583243

Epoch: 6| Step: 2
Training loss: 2.7536188070290026
Validation loss: 2.625326838462278

Epoch: 6| Step: 3
Training loss: 3.115084060342984
Validation loss: 2.6264179480405794

Epoch: 6| Step: 4
Training loss: 2.452769842983423
Validation loss: 2.624475403267599

Epoch: 6| Step: 5
Training loss: 2.843001717850377
Validation loss: 2.6291493164486415

Epoch: 6| Step: 6
Training loss: 3.230895303704683
Validation loss: 2.6309786586049873

Epoch: 6| Step: 7
Training loss: 2.680331316865541
Validation loss: 2.629129185768649

Epoch: 6| Step: 8
Training loss: 3.4795542670489947
Validation loss: 2.63666103261886

Epoch: 6| Step: 9
Training loss: 3.2611918315035124
Validation loss: 2.641407096870834

Epoch: 6| Step: 10
Training loss: 3.294561505467103
Validation loss: 2.6491513536634512

Epoch: 6| Step: 11
Training loss: 3.105136148167617
Validation loss: 2.643506360498428

Epoch: 6| Step: 12
Training loss: 2.5480573285239445
Validation loss: 2.676367887749059

Epoch: 6| Step: 13
Training loss: 2.720562823772773
Validation loss: 2.6754178618322944

Epoch: 298| Step: 0
Training loss: 2.599717961199484
Validation loss: 2.663883902717423

Epoch: 6| Step: 1
Training loss: 3.503232008620837
Validation loss: 2.6322892537730818

Epoch: 6| Step: 2
Training loss: 2.657619527172484
Validation loss: 2.62431123079645

Epoch: 6| Step: 3
Training loss: 3.0555929027548356
Validation loss: 2.629341602747724

Epoch: 6| Step: 4
Training loss: 2.4578654172600243
Validation loss: 2.621117648309522

Epoch: 6| Step: 5
Training loss: 3.223546870304328
Validation loss: 2.6236174967017685

Epoch: 6| Step: 6
Training loss: 2.8734534706555563
Validation loss: 2.6165362029362838

Epoch: 6| Step: 7
Training loss: 3.4093708825020967
Validation loss: 2.626471810514018

Epoch: 6| Step: 8
Training loss: 2.9955309323067003
Validation loss: 2.625465891796192

Epoch: 6| Step: 9
Training loss: 2.7187657849083795
Validation loss: 2.622046084580504

Epoch: 6| Step: 10
Training loss: 3.058579874798908
Validation loss: 2.624206835273972

Epoch: 6| Step: 11
Training loss: 2.782584566680326
Validation loss: 2.6212917255742325

Epoch: 6| Step: 12
Training loss: 3.2271563927835736
Validation loss: 2.6229947180812694

Epoch: 6| Step: 13
Training loss: 2.7126659852323365
Validation loss: 2.620450448165079

Epoch: 299| Step: 0
Training loss: 2.555025690774474
Validation loss: 2.6262318640310247

Epoch: 6| Step: 1
Training loss: 3.311090853399425
Validation loss: 2.6300642352785273

Epoch: 6| Step: 2
Training loss: 1.985288454808156
Validation loss: 2.6373203611237255

Epoch: 6| Step: 3
Training loss: 2.9480210859768725
Validation loss: 2.6272867646187965

Epoch: 6| Step: 4
Training loss: 3.5336299741728134
Validation loss: 2.6408193271250147

Epoch: 6| Step: 5
Training loss: 2.477678787447455
Validation loss: 2.650367178296223

Epoch: 6| Step: 6
Training loss: 3.4343471980683438
Validation loss: 2.651361531054606

Epoch: 6| Step: 7
Training loss: 3.0569981570052662
Validation loss: 2.639096075630874

Epoch: 6| Step: 8
Training loss: 3.1025324537130587
Validation loss: 2.6321100613857777

Epoch: 6| Step: 9
Training loss: 3.0906266909634215
Validation loss: 2.6284752677939247

Epoch: 6| Step: 10
Training loss: 2.78604561194266
Validation loss: 2.6375673438753693

Epoch: 6| Step: 11
Training loss: 2.742306611606913
Validation loss: 2.6320087672373473

Epoch: 6| Step: 12
Training loss: 3.1904385055452824
Validation loss: 2.6285986212106205

Epoch: 6| Step: 13
Training loss: 2.8137605173599893
Validation loss: 2.6349627630720636

Epoch: 300| Step: 0
Training loss: 2.997742439245851
Validation loss: 2.62959055160057

Epoch: 6| Step: 1
Training loss: 2.6417316172063
Validation loss: 2.6257923471498756

Epoch: 6| Step: 2
Training loss: 2.9116326804780566
Validation loss: 2.6337067222390864

Epoch: 6| Step: 3
Training loss: 3.040023847787577
Validation loss: 2.642810842784958

Epoch: 6| Step: 4
Training loss: 3.316815426300287
Validation loss: 2.6410062703616632

Epoch: 6| Step: 5
Training loss: 2.528581130630316
Validation loss: 2.646610606244721

Epoch: 6| Step: 6
Training loss: 3.437853153467956
Validation loss: 2.6463784807722197

Epoch: 6| Step: 7
Training loss: 3.0667007596428992
Validation loss: 2.646666758801714

Epoch: 6| Step: 8
Training loss: 2.890272954174707
Validation loss: 2.6352041073589088

Epoch: 6| Step: 9
Training loss: 2.576982464637056
Validation loss: 2.633040922551965

Epoch: 6| Step: 10
Training loss: 3.314182070347095
Validation loss: 2.6329142232952885

Epoch: 6| Step: 11
Training loss: 2.3949057953530706
Validation loss: 2.6314293956683246

Epoch: 6| Step: 12
Training loss: 2.8805240138489303
Validation loss: 2.628761660897415

Epoch: 6| Step: 13
Training loss: 3.3472789075456353
Validation loss: 2.620572518208759

Epoch: 301| Step: 0
Training loss: 2.857901438418384
Validation loss: 2.624583465686766

Epoch: 6| Step: 1
Training loss: 2.834909804589679
Validation loss: 2.634726833916414

Epoch: 6| Step: 2
Training loss: 3.0860784184597145
Validation loss: 2.6279636535011557

Epoch: 6| Step: 3
Training loss: 2.797763448928824
Validation loss: 2.6335573488658635

Epoch: 6| Step: 4
Training loss: 3.3142456637156528
Validation loss: 2.6356162756377786

Epoch: 6| Step: 5
Training loss: 3.025706620087659
Validation loss: 2.63711966337539

Epoch: 6| Step: 6
Training loss: 2.905899847122882
Validation loss: 2.6271154568609223

Epoch: 6| Step: 7
Training loss: 3.249390911834493
Validation loss: 2.6272273285179577

Epoch: 6| Step: 8
Training loss: 3.468569914121021
Validation loss: 2.6356680252171776

Epoch: 6| Step: 9
Training loss: 2.8880187786474507
Validation loss: 2.6309378004817834

Epoch: 6| Step: 10
Training loss: 1.5575779255190834
Validation loss: 2.639732429885581

Epoch: 6| Step: 11
Training loss: 3.300314027121102
Validation loss: 2.6457317330526764

Epoch: 6| Step: 12
Training loss: 3.01289742408558
Validation loss: 2.6585134842957046

Epoch: 6| Step: 13
Training loss: 2.082283505730208
Validation loss: 2.655771892644191

Epoch: 302| Step: 0
Training loss: 2.689489825627857
Validation loss: 2.6676580497125144

Epoch: 6| Step: 1
Training loss: 3.2548451620328414
Validation loss: 2.679306637017177

Epoch: 6| Step: 2
Training loss: 3.1534099831919615
Validation loss: 2.6600927778072463

Epoch: 6| Step: 3
Training loss: 2.930199336799691
Validation loss: 2.63976847963423

Epoch: 6| Step: 4
Training loss: 3.1754970071424418
Validation loss: 2.631022518189358

Epoch: 6| Step: 5
Training loss: 3.061247900529471
Validation loss: 2.6298658136779727

Epoch: 6| Step: 6
Training loss: 2.996332629054723
Validation loss: 2.629112828563506

Epoch: 6| Step: 7
Training loss: 2.402347918250957
Validation loss: 2.625435403867719

Epoch: 6| Step: 8
Training loss: 3.2970436378486
Validation loss: 2.6255807873773476

Epoch: 6| Step: 9
Training loss: 2.91920683918531
Validation loss: 2.6173455283842113

Epoch: 6| Step: 10
Training loss: 2.7239351484334375
Validation loss: 2.6207796675833666

Epoch: 6| Step: 11
Training loss: 3.2198020919257497
Validation loss: 2.6193165415649

Epoch: 6| Step: 12
Training loss: 3.101325422397713
Validation loss: 2.626326626652347

Epoch: 6| Step: 13
Training loss: 1.8050740145991666
Validation loss: 2.6198838394955537

Epoch: 303| Step: 0
Training loss: 2.6323732637942827
Validation loss: 2.6200589928572287

Epoch: 6| Step: 1
Training loss: 3.2358648582125977
Validation loss: 2.6246775796826287

Epoch: 6| Step: 2
Training loss: 2.5904072742517887
Validation loss: 2.61962819723435

Epoch: 6| Step: 3
Training loss: 3.4756095351650442
Validation loss: 2.6244057745988196

Epoch: 6| Step: 4
Training loss: 2.512901205796355
Validation loss: 2.6211829983244286

Epoch: 6| Step: 5
Training loss: 2.641218400902483
Validation loss: 2.625883886283402

Epoch: 6| Step: 6
Training loss: 3.195614378456565
Validation loss: 2.6276723752694244

Epoch: 6| Step: 7
Training loss: 3.093484578162165
Validation loss: 2.6302069184063828

Epoch: 6| Step: 8
Training loss: 2.9038090453300685
Validation loss: 2.63532815946978

Epoch: 6| Step: 9
Training loss: 3.260897047507535
Validation loss: 2.626077253189039

Epoch: 6| Step: 10
Training loss: 3.041893275629075
Validation loss: 2.636778063545641

Epoch: 6| Step: 11
Training loss: 2.6111388498099943
Validation loss: 2.6358848453262196

Epoch: 6| Step: 12
Training loss: 2.7186807207071997
Validation loss: 2.6403783586069705

Epoch: 6| Step: 13
Training loss: 3.460627901511124
Validation loss: 2.6360977857535395

Epoch: 304| Step: 0
Training loss: 2.995032966954543
Validation loss: 2.638122695271267

Epoch: 6| Step: 1
Training loss: 3.0643084110787555
Validation loss: 2.6299485003434264

Epoch: 6| Step: 2
Training loss: 2.212353795280204
Validation loss: 2.6363570392641957

Epoch: 6| Step: 3
Training loss: 2.852102233809232
Validation loss: 2.6364544912348276

Epoch: 6| Step: 4
Training loss: 3.1150868156667197
Validation loss: 2.6456274841191036

Epoch: 6| Step: 5
Training loss: 1.7933200334152672
Validation loss: 2.645361361089206

Epoch: 6| Step: 6
Training loss: 3.3522450567905038
Validation loss: 2.639066283332228

Epoch: 6| Step: 7
Training loss: 3.309787431327905
Validation loss: 2.6358435652787597

Epoch: 6| Step: 8
Training loss: 3.26914313962705
Validation loss: 2.6407536300996126

Epoch: 6| Step: 9
Training loss: 2.824298862782531
Validation loss: 2.6310331857836426

Epoch: 6| Step: 10
Training loss: 3.4621301666947324
Validation loss: 2.6432550086037176

Epoch: 6| Step: 11
Training loss: 2.631120358714328
Validation loss: 2.630437768858682

Epoch: 6| Step: 12
Training loss: 3.2295738373693377
Validation loss: 2.6443053809029617

Epoch: 6| Step: 13
Training loss: 2.4936957982035963
Validation loss: 2.64074712962239

Epoch: 305| Step: 0
Training loss: 2.8354838194919374
Validation loss: 2.639028409354243

Epoch: 6| Step: 1
Training loss: 2.450296313992899
Validation loss: 2.630033494581729

Epoch: 6| Step: 2
Training loss: 3.3916423343719777
Validation loss: 2.6370365492440304

Epoch: 6| Step: 3
Training loss: 3.1023855198373216
Validation loss: 2.6260809052419014

Epoch: 6| Step: 4
Training loss: 2.910280775439808
Validation loss: 2.6374651682383528

Epoch: 6| Step: 5
Training loss: 2.662268787069497
Validation loss: 2.6330557564410038

Epoch: 6| Step: 6
Training loss: 2.874902474781006
Validation loss: 2.637238491764037

Epoch: 6| Step: 7
Training loss: 2.589603648843867
Validation loss: 2.6472851383670704

Epoch: 6| Step: 8
Training loss: 2.664514408209341
Validation loss: 2.6536604581710024

Epoch: 6| Step: 9
Training loss: 3.2355851567780896
Validation loss: 2.6605132305862527

Epoch: 6| Step: 10
Training loss: 3.103485817883136
Validation loss: 2.6586506104886345

Epoch: 6| Step: 11
Training loss: 3.377334070202847
Validation loss: 2.6490536129598823

Epoch: 6| Step: 12
Training loss: 2.995186122403233
Validation loss: 2.6614817452595516

Epoch: 6| Step: 13
Training loss: 3.0579964357783203
Validation loss: 2.649280354568253

Epoch: 306| Step: 0
Training loss: 3.1669242821023267
Validation loss: 2.6408420761617535

Epoch: 6| Step: 1
Training loss: 2.588210014931242
Validation loss: 2.6414695447910104

Epoch: 6| Step: 2
Training loss: 2.720071756313989
Validation loss: 2.6376707382470648

Epoch: 6| Step: 3
Training loss: 2.778409385929351
Validation loss: 2.631022153767671

Epoch: 6| Step: 4
Training loss: 3.0952674920219687
Validation loss: 2.6354762958274107

Epoch: 6| Step: 5
Training loss: 2.809486300392783
Validation loss: 2.6236663082808884

Epoch: 6| Step: 6
Training loss: 3.238225588993139
Validation loss: 2.6306645538150866

Epoch: 6| Step: 7
Training loss: 2.6697389865122614
Validation loss: 2.636339138935702

Epoch: 6| Step: 8
Training loss: 3.6041795734034765
Validation loss: 2.630865701121097

Epoch: 6| Step: 9
Training loss: 2.8608868047034246
Validation loss: 2.6371584464812567

Epoch: 6| Step: 10
Training loss: 3.3273867652478986
Validation loss: 2.6491522933208294

Epoch: 6| Step: 11
Training loss: 2.9053879966909615
Validation loss: 2.6511438154529396

Epoch: 6| Step: 12
Training loss: 2.741403494806609
Validation loss: 2.649831838645275

Epoch: 6| Step: 13
Training loss: 2.27667215956346
Validation loss: 2.6498973270477317

Epoch: 307| Step: 0
Training loss: 3.4984020945234153
Validation loss: 2.6638878185960646

Epoch: 6| Step: 1
Training loss: 3.0947019095144594
Validation loss: 2.6576063333042597

Epoch: 6| Step: 2
Training loss: 2.558304119461048
Validation loss: 2.6533135973948245

Epoch: 6| Step: 3
Training loss: 2.7892828675306665
Validation loss: 2.665473962234519

Epoch: 6| Step: 4
Training loss: 2.861306793862468
Validation loss: 2.6613083105141255

Epoch: 6| Step: 5
Training loss: 3.3619820348292535
Validation loss: 2.650050539458477

Epoch: 6| Step: 6
Training loss: 3.080310955451639
Validation loss: 2.6552571959732125

Epoch: 6| Step: 7
Training loss: 2.7759728247222073
Validation loss: 2.648325819590832

Epoch: 6| Step: 8
Training loss: 3.344844460741446
Validation loss: 2.6384992708731647

Epoch: 6| Step: 9
Training loss: 2.9484580972717227
Validation loss: 2.6445685536845422

Epoch: 6| Step: 10
Training loss: 2.9658831758340236
Validation loss: 2.636651852092155

Epoch: 6| Step: 11
Training loss: 2.473305760030263
Validation loss: 2.644016465328159

Epoch: 6| Step: 12
Training loss: 2.442082621152269
Validation loss: 2.6320025320130687

Epoch: 6| Step: 13
Training loss: 2.804191949361007
Validation loss: 2.6386866223404453

Epoch: 308| Step: 0
Training loss: 2.928638158430074
Validation loss: 2.634609078408855

Epoch: 6| Step: 1
Training loss: 3.8777753673887245
Validation loss: 2.633278769759473

Epoch: 6| Step: 2
Training loss: 2.8425169566646002
Validation loss: 2.6339340374771765

Epoch: 6| Step: 3
Training loss: 1.645323791175347
Validation loss: 2.634276774922987

Epoch: 6| Step: 4
Training loss: 1.8614888717232667
Validation loss: 2.6371902521881236

Epoch: 6| Step: 5
Training loss: 3.3876249339583433
Validation loss: 2.6500894467563922

Epoch: 6| Step: 6
Training loss: 2.873071936232896
Validation loss: 2.667214449512617

Epoch: 6| Step: 7
Training loss: 2.9156978814766394
Validation loss: 2.6634576909844836

Epoch: 6| Step: 8
Training loss: 3.1760954941871318
Validation loss: 2.6614462814859285

Epoch: 6| Step: 9
Training loss: 2.9395014660684478
Validation loss: 2.6620984650259225

Epoch: 6| Step: 10
Training loss: 3.056287731725644
Validation loss: 2.6440162122623225

Epoch: 6| Step: 11
Training loss: 3.1704164355421605
Validation loss: 2.6309150759151088

Epoch: 6| Step: 12
Training loss: 3.1560112891243084
Validation loss: 2.6278404497832177

Epoch: 6| Step: 13
Training loss: 2.7032030568401644
Validation loss: 2.6210300194572373

Epoch: 309| Step: 0
Training loss: 2.287436679318063
Validation loss: 2.6161763446318367

Epoch: 6| Step: 1
Training loss: 2.9212479351984775
Validation loss: 2.6121380424075626

Epoch: 6| Step: 2
Training loss: 2.9655694890027453
Validation loss: 2.6181782174146506

Epoch: 6| Step: 3
Training loss: 3.1538106726677815
Validation loss: 2.623685788101861

Epoch: 6| Step: 4
Training loss: 2.9996051528489622
Validation loss: 2.6202867915425045

Epoch: 6| Step: 5
Training loss: 3.357783734680767
Validation loss: 2.6155248134212448

Epoch: 6| Step: 6
Training loss: 3.2246013897728205
Validation loss: 2.6224134801642824

Epoch: 6| Step: 7
Training loss: 2.6746931773545652
Validation loss: 2.617332017386211

Epoch: 6| Step: 8
Training loss: 2.940328332122723
Validation loss: 2.6186377229477977

Epoch: 6| Step: 9
Training loss: 3.4795182254147847
Validation loss: 2.6192643377701224

Epoch: 6| Step: 10
Training loss: 2.3271419830809044
Validation loss: 2.617179634279551

Epoch: 6| Step: 11
Training loss: 2.9459401076703777
Validation loss: 2.623698107528751

Epoch: 6| Step: 12
Training loss: 2.8817560177731356
Validation loss: 2.6350945687648166

Epoch: 6| Step: 13
Training loss: 2.952976768043145
Validation loss: 2.6577667345628173

Epoch: 310| Step: 0
Training loss: 3.7758015874200113
Validation loss: 2.6870282859276826

Epoch: 6| Step: 1
Training loss: 2.483927176558287
Validation loss: 2.693688106308794

Epoch: 6| Step: 2
Training loss: 2.998561991323192
Validation loss: 2.7020913254982744

Epoch: 6| Step: 3
Training loss: 3.060382500222555
Validation loss: 2.6894162084406354

Epoch: 6| Step: 4
Training loss: 2.7385144100426477
Validation loss: 2.66447153771317

Epoch: 6| Step: 5
Training loss: 2.8898035480294526
Validation loss: 2.701504493488767

Epoch: 6| Step: 6
Training loss: 2.419054912106305
Validation loss: 2.651584535734242

Epoch: 6| Step: 7
Training loss: 2.8367473192176242
Validation loss: 2.6360761501573275

Epoch: 6| Step: 8
Training loss: 2.455072686698432
Validation loss: 2.626833607847884

Epoch: 6| Step: 9
Training loss: 3.326907942768444
Validation loss: 2.627520518675474

Epoch: 6| Step: 10
Training loss: 2.7608203424834543
Validation loss: 2.6216529274298273

Epoch: 6| Step: 11
Training loss: 3.1827497802906892
Validation loss: 2.618336722557141

Epoch: 6| Step: 12
Training loss: 3.2732691027314704
Validation loss: 2.6184961619099476

Epoch: 6| Step: 13
Training loss: 2.541432750339759
Validation loss: 2.616869286783002

Epoch: 311| Step: 0
Training loss: 3.3225454922353785
Validation loss: 2.615058031872892

Epoch: 6| Step: 1
Training loss: 2.6326954982579833
Validation loss: 2.613259409805813

Epoch: 6| Step: 2
Training loss: 2.97032412908486
Validation loss: 2.617499653042779

Epoch: 6| Step: 3
Training loss: 2.9351911195984046
Validation loss: 2.6088632336347963

Epoch: 6| Step: 4
Training loss: 2.8567739861655537
Validation loss: 2.602766404925784

Epoch: 6| Step: 5
Training loss: 2.946784585028903
Validation loss: 2.6105046270118977

Epoch: 6| Step: 6
Training loss: 3.097866209979321
Validation loss: 2.6042509463218644

Epoch: 6| Step: 7
Training loss: 2.9657854235785397
Validation loss: 2.6157876368043995

Epoch: 6| Step: 8
Training loss: 2.9217762649907972
Validation loss: 2.617593159871078

Epoch: 6| Step: 9
Training loss: 3.1224095097937723
Validation loss: 2.6263323370164966

Epoch: 6| Step: 10
Training loss: 2.8353107695152224
Validation loss: 2.635657349147075

Epoch: 6| Step: 11
Training loss: 3.2286101487221464
Validation loss: 2.6459308183529875

Epoch: 6| Step: 12
Training loss: 2.6008390503290575
Validation loss: 2.6546834013972687

Epoch: 6| Step: 13
Training loss: 2.664980464527321
Validation loss: 2.6971176325585398

Epoch: 312| Step: 0
Training loss: 2.473926573432377
Validation loss: 2.686040596035467

Epoch: 6| Step: 1
Training loss: 2.749741628820525
Validation loss: 2.6945300616335985

Epoch: 6| Step: 2
Training loss: 3.5954984972413144
Validation loss: 2.6663670839439484

Epoch: 6| Step: 3
Training loss: 3.552424186096225
Validation loss: 2.652662127235466

Epoch: 6| Step: 4
Training loss: 2.807268830290833
Validation loss: 2.6368202827377925

Epoch: 6| Step: 5
Training loss: 2.6652013408476027
Validation loss: 2.6263849928217713

Epoch: 6| Step: 6
Training loss: 2.4230919518429714
Validation loss: 2.621472659354777

Epoch: 6| Step: 7
Training loss: 3.2602328085120305
Validation loss: 2.6145494164132934

Epoch: 6| Step: 8
Training loss: 2.084272198522587
Validation loss: 2.6129012342050673

Epoch: 6| Step: 9
Training loss: 2.5670654750806086
Validation loss: 2.6136350302267446

Epoch: 6| Step: 10
Training loss: 3.4284354251044786
Validation loss: 2.605861371952853

Epoch: 6| Step: 11
Training loss: 2.830455683763055
Validation loss: 2.6116530238160105

Epoch: 6| Step: 12
Training loss: 3.2270338993378402
Validation loss: 2.616550567511918

Epoch: 6| Step: 13
Training loss: 3.2745100280915715
Validation loss: 2.6149462788012072

Epoch: 313| Step: 0
Training loss: 2.887094351938826
Validation loss: 2.621652138287114

Epoch: 6| Step: 1
Training loss: 2.921483957163361
Validation loss: 2.6199936206774095

Epoch: 6| Step: 2
Training loss: 2.7719023418260695
Validation loss: 2.6367065303007364

Epoch: 6| Step: 3
Training loss: 3.546309505873704
Validation loss: 2.636052118069897

Epoch: 6| Step: 4
Training loss: 2.8293671804243785
Validation loss: 2.6352489608899465

Epoch: 6| Step: 5
Training loss: 3.3612224378267936
Validation loss: 2.6391606259146143

Epoch: 6| Step: 6
Training loss: 3.158131557920567
Validation loss: 2.6450643806803384

Epoch: 6| Step: 7
Training loss: 3.2719291908418207
Validation loss: 2.6513711208979913

Epoch: 6| Step: 8
Training loss: 2.2230766984798835
Validation loss: 2.640957876341298

Epoch: 6| Step: 9
Training loss: 2.8490899222400414
Validation loss: 2.634827889785596

Epoch: 6| Step: 10
Training loss: 2.8051312023900183
Validation loss: 2.6322390876207007

Epoch: 6| Step: 11
Training loss: 2.6090497939247834
Validation loss: 2.6358410452520973

Epoch: 6| Step: 12
Training loss: 3.032844202896913
Validation loss: 2.6269555301017102

Epoch: 6| Step: 13
Training loss: 2.455729177454075
Validation loss: 2.6263178160729796

Epoch: 314| Step: 0
Training loss: 2.5432286283539476
Validation loss: 2.6203109828966524

Epoch: 6| Step: 1
Training loss: 3.194804778485195
Validation loss: 2.622121372253951

Epoch: 6| Step: 2
Training loss: 2.815927070561955
Validation loss: 2.6270340433377894

Epoch: 6| Step: 3
Training loss: 3.1791075381425378
Validation loss: 2.61521406564898

Epoch: 6| Step: 4
Training loss: 2.6333619401882884
Validation loss: 2.6216631803962747

Epoch: 6| Step: 5
Training loss: 2.7531491368390735
Validation loss: 2.624701709079563

Epoch: 6| Step: 6
Training loss: 2.3563838971288598
Validation loss: 2.6185541582761007

Epoch: 6| Step: 7
Training loss: 3.0337388350977212
Validation loss: 2.625620358981931

Epoch: 6| Step: 8
Training loss: 3.471078314651352
Validation loss: 2.6231396543809105

Epoch: 6| Step: 9
Training loss: 2.4695622520347214
Validation loss: 2.6218231234369043

Epoch: 6| Step: 10
Training loss: 3.252300035456428
Validation loss: 2.628599891035262

Epoch: 6| Step: 11
Training loss: 2.61932832072377
Validation loss: 2.629477832824525

Epoch: 6| Step: 12
Training loss: 3.3831172391787314
Validation loss: 2.625295698560048

Epoch: 6| Step: 13
Training loss: 3.2377729028394393
Validation loss: 2.6358064357344078

Epoch: 315| Step: 0
Training loss: 2.905341549884346
Validation loss: 2.6260323015765596

Epoch: 6| Step: 1
Training loss: 2.9832536278276405
Validation loss: 2.6368873115114493

Epoch: 6| Step: 2
Training loss: 2.883145444918653
Validation loss: 2.6263393260948655

Epoch: 6| Step: 3
Training loss: 2.478219137051354
Validation loss: 2.6307772100508973

Epoch: 6| Step: 4
Training loss: 3.382666745470663
Validation loss: 2.624288664740794

Epoch: 6| Step: 5
Training loss: 2.2553033845412553
Validation loss: 2.6248301017927576

Epoch: 6| Step: 6
Training loss: 2.920088604405792
Validation loss: 2.624547522867023

Epoch: 6| Step: 7
Training loss: 3.367935416229876
Validation loss: 2.6184771222407597

Epoch: 6| Step: 8
Training loss: 2.941484549038782
Validation loss: 2.624017039194729

Epoch: 6| Step: 9
Training loss: 3.093748612837047
Validation loss: 2.622806456842515

Epoch: 6| Step: 10
Training loss: 3.6359867789318736
Validation loss: 2.627900918778934

Epoch: 6| Step: 11
Training loss: 2.9181489901558417
Validation loss: 2.627330384324697

Epoch: 6| Step: 12
Training loss: 2.4896359192044266
Validation loss: 2.620153828053221

Epoch: 6| Step: 13
Training loss: 2.2690957680771895
Validation loss: 2.627985344179492

Epoch: 316| Step: 0
Training loss: 2.9446594971470272
Validation loss: 2.630279546549512

Epoch: 6| Step: 1
Training loss: 2.4679741907980546
Validation loss: 2.6255554904518554

Epoch: 6| Step: 2
Training loss: 3.1039356598035654
Validation loss: 2.626401498789876

Epoch: 6| Step: 3
Training loss: 2.192117667360425
Validation loss: 2.6260083201046913

Epoch: 6| Step: 4
Training loss: 3.208234628587484
Validation loss: 2.6277414520172813

Epoch: 6| Step: 5
Training loss: 2.7162227065026903
Validation loss: 2.62023814595302

Epoch: 6| Step: 6
Training loss: 3.4200396906908668
Validation loss: 2.6292598427877514

Epoch: 6| Step: 7
Training loss: 2.731880663375203
Validation loss: 2.63552968524887

Epoch: 6| Step: 8
Training loss: 2.68318255299018
Validation loss: 2.640785876928734

Epoch: 6| Step: 9
Training loss: 2.954357717458243
Validation loss: 2.643204548166099

Epoch: 6| Step: 10
Training loss: 3.6075703126184306
Validation loss: 2.642555293894734

Epoch: 6| Step: 11
Training loss: 2.4841739405240055
Validation loss: 2.645116892321231

Epoch: 6| Step: 12
Training loss: 3.1186437431994487
Validation loss: 2.645423014047265

Epoch: 6| Step: 13
Training loss: 3.3747872179560434
Validation loss: 2.6249518812450217

Epoch: 317| Step: 0
Training loss: 2.9297903627775517
Validation loss: 2.6285938091353303

Epoch: 6| Step: 1
Training loss: 2.5870225364490853
Validation loss: 2.6163832130106646

Epoch: 6| Step: 2
Training loss: 2.787120495608946
Validation loss: 2.621717602099312

Epoch: 6| Step: 3
Training loss: 3.2426198648078506
Validation loss: 2.605354479873708

Epoch: 6| Step: 4
Training loss: 3.0412802951619295
Validation loss: 2.609008471525607

Epoch: 6| Step: 5
Training loss: 3.3307897081557183
Validation loss: 2.6057947266713364

Epoch: 6| Step: 6
Training loss: 2.906520379727869
Validation loss: 2.5967092335534403

Epoch: 6| Step: 7
Training loss: 3.269564501959046
Validation loss: 2.602643230825168

Epoch: 6| Step: 8
Training loss: 2.603757098733544
Validation loss: 2.6017069620198243

Epoch: 6| Step: 9
Training loss: 3.226509001429209
Validation loss: 2.599356812101423

Epoch: 6| Step: 10
Training loss: 2.8446189475010417
Validation loss: 2.6092344947100856

Epoch: 6| Step: 11
Training loss: 2.583074177284265
Validation loss: 2.6130490810506517

Epoch: 6| Step: 12
Training loss: 2.776526565619765
Validation loss: 2.6163994606905967

Epoch: 6| Step: 13
Training loss: 2.8762965388638184
Validation loss: 2.6147059158699513

Epoch: 318| Step: 0
Training loss: 3.102778352581606
Validation loss: 2.623969093907773

Epoch: 6| Step: 1
Training loss: 2.9565471217585406
Validation loss: 2.6215994490278707

Epoch: 6| Step: 2
Training loss: 2.8810063521829243
Validation loss: 2.65091791405447

Epoch: 6| Step: 3
Training loss: 2.331554370472776
Validation loss: 2.6391457316287577

Epoch: 6| Step: 4
Training loss: 2.762509762845977
Validation loss: 2.6441981118702076

Epoch: 6| Step: 5
Training loss: 2.4856840319742015
Validation loss: 2.6478401817516017

Epoch: 6| Step: 6
Training loss: 3.494232057128917
Validation loss: 2.651003279431117

Epoch: 6| Step: 7
Training loss: 3.1090221108932226
Validation loss: 2.6457806356613136

Epoch: 6| Step: 8
Training loss: 3.396783114737303
Validation loss: 2.623851414478955

Epoch: 6| Step: 9
Training loss: 1.9909415144633635
Validation loss: 2.6259752123295677

Epoch: 6| Step: 10
Training loss: 2.640073549373171
Validation loss: 2.6158300056302153

Epoch: 6| Step: 11
Training loss: 2.8322605645306558
Validation loss: 2.6224908424254387

Epoch: 6| Step: 12
Training loss: 3.2647750697564932
Validation loss: 2.6174274342557333

Epoch: 6| Step: 13
Training loss: 3.74700401154042
Validation loss: 2.6232483875097556

Epoch: 319| Step: 0
Training loss: 2.3971021084575397
Validation loss: 2.6231253454344334

Epoch: 6| Step: 1
Training loss: 2.421470066796885
Validation loss: 2.6215029567112187

Epoch: 6| Step: 2
Training loss: 2.4427810582205027
Validation loss: 2.6139492208397743

Epoch: 6| Step: 3
Training loss: 3.3169137591104136
Validation loss: 2.6241246632765693

Epoch: 6| Step: 4
Training loss: 3.309303180610494
Validation loss: 2.628892971999293

Epoch: 6| Step: 5
Training loss: 3.1942289049345134
Validation loss: 2.6248782061767777

Epoch: 6| Step: 6
Training loss: 2.8850694211015435
Validation loss: 2.622361758392068

Epoch: 6| Step: 7
Training loss: 2.4859040551180653
Validation loss: 2.615149950665166

Epoch: 6| Step: 8
Training loss: 2.516134175014525
Validation loss: 2.623650736827204

Epoch: 6| Step: 9
Training loss: 2.989963910449592
Validation loss: 2.629560864141579

Epoch: 6| Step: 10
Training loss: 2.9619596221871083
Validation loss: 2.6337394690371085

Epoch: 6| Step: 11
Training loss: 2.981064803091253
Validation loss: 2.6520498081676966

Epoch: 6| Step: 12
Training loss: 3.4715229669707037
Validation loss: 2.666427663762525

Epoch: 6| Step: 13
Training loss: 3.692751232735576
Validation loss: 2.6506109916322513

Epoch: 320| Step: 0
Training loss: 3.239686888647514
Validation loss: 2.65911507461069

Epoch: 6| Step: 1
Training loss: 2.9943487663608814
Validation loss: 2.664493374744871

Epoch: 6| Step: 2
Training loss: 2.7902576439688436
Validation loss: 2.688785648968601

Epoch: 6| Step: 3
Training loss: 3.1623228965896133
Validation loss: 2.7197974646773373

Epoch: 6| Step: 4
Training loss: 2.70745617282439
Validation loss: 2.676139415832624

Epoch: 6| Step: 5
Training loss: 3.58975342480217
Validation loss: 2.646988293411012

Epoch: 6| Step: 6
Training loss: 2.554047203900307
Validation loss: 2.6226788594650605

Epoch: 6| Step: 7
Training loss: 2.636770471136245
Validation loss: 2.6149702862327224

Epoch: 6| Step: 8
Training loss: 3.4196614112336428
Validation loss: 2.5970428810966326

Epoch: 6| Step: 9
Training loss: 2.779548381649907
Validation loss: 2.598344398950721

Epoch: 6| Step: 10
Training loss: 2.9331707808219716
Validation loss: 2.5990480708377635

Epoch: 6| Step: 11
Training loss: 2.4840297819001576
Validation loss: 2.591154892455699

Epoch: 6| Step: 12
Training loss: 2.709060678871978
Validation loss: 2.6003815054729156

Epoch: 6| Step: 13
Training loss: 2.789997873613101
Validation loss: 2.6008558120615928

Epoch: 321| Step: 0
Training loss: 3.1811271239047305
Validation loss: 2.6009203188352514

Epoch: 6| Step: 1
Training loss: 3.4512252069485627
Validation loss: 2.602421274998005

Epoch: 6| Step: 2
Training loss: 3.1467341129165294
Validation loss: 2.6043007627027883

Epoch: 6| Step: 3
Training loss: 2.4056253984965834
Validation loss: 2.6049356151417875

Epoch: 6| Step: 4
Training loss: 3.3439909946192627
Validation loss: 2.6184339209558387

Epoch: 6| Step: 5
Training loss: 2.054428490388298
Validation loss: 2.621571460636917

Epoch: 6| Step: 6
Training loss: 3.063822713648181
Validation loss: 2.628304402298944

Epoch: 6| Step: 7
Training loss: 2.785961232750191
Validation loss: 2.6281058156407267

Epoch: 6| Step: 8
Training loss: 2.1526700584232894
Validation loss: 2.6415717528454383

Epoch: 6| Step: 9
Training loss: 3.125392431414301
Validation loss: 2.646835434517157

Epoch: 6| Step: 10
Training loss: 2.9990759062082324
Validation loss: 2.648773374369913

Epoch: 6| Step: 11
Training loss: 3.2371397134623487
Validation loss: 2.6762511463895353

Epoch: 6| Step: 12
Training loss: 2.5330444380351946
Validation loss: 2.68177342500358

Epoch: 6| Step: 13
Training loss: 3.346619275151409
Validation loss: 2.6630566186305287

Epoch: 322| Step: 0
Training loss: 3.1945720831392364
Validation loss: 2.6723222975207253

Epoch: 6| Step: 1
Training loss: 2.957643795693557
Validation loss: 2.669319787145554

Epoch: 6| Step: 2
Training loss: 2.5355179209827154
Validation loss: 2.6649408492013915

Epoch: 6| Step: 3
Training loss: 3.2656451503004216
Validation loss: 2.6663423624290474

Epoch: 6| Step: 4
Training loss: 2.821247738290944
Validation loss: 2.6540705909390807

Epoch: 6| Step: 5
Training loss: 3.5466305820761446
Validation loss: 2.69071707611628

Epoch: 6| Step: 6
Training loss: 3.5600264143231732
Validation loss: 2.6897878998285263

Epoch: 6| Step: 7
Training loss: 2.687591196331509
Validation loss: 2.677647491252084

Epoch: 6| Step: 8
Training loss: 2.246241078727893
Validation loss: 2.67221604954122

Epoch: 6| Step: 9
Training loss: 2.6729853592745316
Validation loss: 2.6594853443807636

Epoch: 6| Step: 10
Training loss: 2.5856745375880266
Validation loss: 2.6432761412384167

Epoch: 6| Step: 11
Training loss: 2.577255564808793
Validation loss: 2.634448526878096

Epoch: 6| Step: 12
Training loss: 3.2794321019803143
Validation loss: 2.6344086382926384

Epoch: 6| Step: 13
Training loss: 2.923361007692828
Validation loss: 2.6201611966093226

Epoch: 323| Step: 0
Training loss: 3.1940319974439517
Validation loss: 2.6141766791341037

Epoch: 6| Step: 1
Training loss: 2.7059289578841437
Validation loss: 2.607375127909386

Epoch: 6| Step: 2
Training loss: 3.283597560520035
Validation loss: 2.6046900538683295

Epoch: 6| Step: 3
Training loss: 3.202668096938543
Validation loss: 2.604353365860878

Epoch: 6| Step: 4
Training loss: 2.7065163214822308
Validation loss: 2.598639397608707

Epoch: 6| Step: 5
Training loss: 2.3155159743121883
Validation loss: 2.6102774046242634

Epoch: 6| Step: 6
Training loss: 3.580376062727115
Validation loss: 2.605430947503198

Epoch: 6| Step: 7
Training loss: 2.882144840325558
Validation loss: 2.606633815172315

Epoch: 6| Step: 8
Training loss: 3.1176538716071374
Validation loss: 2.605558827718085

Epoch: 6| Step: 9
Training loss: 2.4787876469864334
Validation loss: 2.622284108808126

Epoch: 6| Step: 10
Training loss: 3.138371356471086
Validation loss: 2.6453757348587645

Epoch: 6| Step: 11
Training loss: 2.5094855601276644
Validation loss: 2.648617071085551

Epoch: 6| Step: 12
Training loss: 3.1588234560554156
Validation loss: 2.6468918762587212

Epoch: 6| Step: 13
Training loss: 2.0001249274337334
Validation loss: 2.6642340869260734

Epoch: 324| Step: 0
Training loss: 2.6153682022097544
Validation loss: 2.6800266896557923

Epoch: 6| Step: 1
Training loss: 2.495777760833229
Validation loss: 2.72822695023855

Epoch: 6| Step: 2
Training loss: 2.7130662107392403
Validation loss: 2.7427020743992245

Epoch: 6| Step: 3
Training loss: 2.6273390022119236
Validation loss: 2.773629932928958

Epoch: 6| Step: 4
Training loss: 2.1721072724549675
Validation loss: 2.7769640420438106

Epoch: 6| Step: 5
Training loss: 3.5288136947888447
Validation loss: 2.7240742360507677

Epoch: 6| Step: 6
Training loss: 3.360453729647829
Validation loss: 2.671038587079807

Epoch: 6| Step: 7
Training loss: 3.234173902074133
Validation loss: 2.623901531909307

Epoch: 6| Step: 8
Training loss: 3.3461933656444907
Validation loss: 2.6127275771600784

Epoch: 6| Step: 9
Training loss: 2.579552457568494
Validation loss: 2.603899737716385

Epoch: 6| Step: 10
Training loss: 3.065977652172802
Validation loss: 2.6056226867609316

Epoch: 6| Step: 11
Training loss: 3.5070033170250925
Validation loss: 2.6060257357673273

Epoch: 6| Step: 12
Training loss: 3.3664470663936004
Validation loss: 2.6083550879595943

Epoch: 6| Step: 13
Training loss: 2.7018743719999847
Validation loss: 2.6027580573118043

Epoch: 325| Step: 0
Training loss: 3.5688655266710367
Validation loss: 2.601913369855029

Epoch: 6| Step: 1
Training loss: 3.1631673417859374
Validation loss: 2.6005491829165326

Epoch: 6| Step: 2
Training loss: 2.9345314772284734
Validation loss: 2.5947509506605755

Epoch: 6| Step: 3
Training loss: 3.0907527391902465
Validation loss: 2.592692177636241

Epoch: 6| Step: 4
Training loss: 2.8273291548188584
Validation loss: 2.596811262444618

Epoch: 6| Step: 5
Training loss: 2.769841057111208
Validation loss: 2.590626207054503

Epoch: 6| Step: 6
Training loss: 3.079719246788266
Validation loss: 2.5960759313443518

Epoch: 6| Step: 7
Training loss: 3.1539739579290953
Validation loss: 2.5954413574639044

Epoch: 6| Step: 8
Training loss: 2.8855005979667894
Validation loss: 2.6016720087861147

Epoch: 6| Step: 9
Training loss: 2.437240782428105
Validation loss: 2.621347168182649

Epoch: 6| Step: 10
Training loss: 2.332520502292686
Validation loss: 2.6313361749510893

Epoch: 6| Step: 11
Training loss: 2.954520405483099
Validation loss: 2.673386562701675

Epoch: 6| Step: 12
Training loss: 2.810862933660005
Validation loss: 2.7180807600418575

Epoch: 6| Step: 13
Training loss: 3.318401046769686
Validation loss: 2.7106934826772684

Epoch: 326| Step: 0
Training loss: 3.4628259057862234
Validation loss: 2.727008129104372

Epoch: 6| Step: 1
Training loss: 2.540294735546414
Validation loss: 2.721647721864989

Epoch: 6| Step: 2
Training loss: 2.4604749456787784
Validation loss: 2.7369806075738006

Epoch: 6| Step: 3
Training loss: 3.2522800957056037
Validation loss: 2.71887307931007

Epoch: 6| Step: 4
Training loss: 3.2460505623819293
Validation loss: 2.6736079067137686

Epoch: 6| Step: 5
Training loss: 3.6666551214094176
Validation loss: 2.632503967230748

Epoch: 6| Step: 6
Training loss: 3.2368372883269116
Validation loss: 2.6145025575092546

Epoch: 6| Step: 7
Training loss: 2.8301958963913934
Validation loss: 2.596431595790493

Epoch: 6| Step: 8
Training loss: 2.5661704595235957
Validation loss: 2.5995383288173626

Epoch: 6| Step: 9
Training loss: 2.97578432018375
Validation loss: 2.5973999054858115

Epoch: 6| Step: 10
Training loss: 2.943493835577545
Validation loss: 2.5955563978622593

Epoch: 6| Step: 11
Training loss: 2.4337144457429614
Validation loss: 2.5992622990972722

Epoch: 6| Step: 12
Training loss: 2.7306437293047954
Validation loss: 2.598545909205581

Epoch: 6| Step: 13
Training loss: 2.219964675450446
Validation loss: 2.5939825907248006

Epoch: 327| Step: 0
Training loss: 2.997521489235761
Validation loss: 2.6029520617460533

Epoch: 6| Step: 1
Training loss: 2.857847545778058
Validation loss: 2.596807698554866

Epoch: 6| Step: 2
Training loss: 2.5679625926279046
Validation loss: 2.6041184221946634

Epoch: 6| Step: 3
Training loss: 2.30193192572407
Validation loss: 2.608477190368627

Epoch: 6| Step: 4
Training loss: 2.8037682517108573
Validation loss: 2.6051035899106094

Epoch: 6| Step: 5
Training loss: 2.770217358568565
Validation loss: 2.6011334349078683

Epoch: 6| Step: 6
Training loss: 2.956658726638173
Validation loss: 2.5908279584266065

Epoch: 6| Step: 7
Training loss: 3.0502346198722305
Validation loss: 2.5951751794549636

Epoch: 6| Step: 8
Training loss: 3.155790087740447
Validation loss: 2.5938406408419774

Epoch: 6| Step: 9
Training loss: 2.8572713482438306
Validation loss: 2.593913524230576

Epoch: 6| Step: 10
Training loss: 3.332441226472429
Validation loss: 2.592580704442843

Epoch: 6| Step: 11
Training loss: 3.396680636491084
Validation loss: 2.595584093913705

Epoch: 6| Step: 12
Training loss: 3.2054890166424577
Validation loss: 2.60034070586865

Epoch: 6| Step: 13
Training loss: 2.6385478139495224
Validation loss: 2.5992330631624787

Epoch: 328| Step: 0
Training loss: 2.9018767893824915
Validation loss: 2.5960577819075916

Epoch: 6| Step: 1
Training loss: 3.012357532725533
Validation loss: 2.6023964543442144

Epoch: 6| Step: 2
Training loss: 2.9904226970111294
Validation loss: 2.6052216458191544

Epoch: 6| Step: 3
Training loss: 2.3814446197035712
Validation loss: 2.6033679575733704

Epoch: 6| Step: 4
Training loss: 3.473834872971139
Validation loss: 2.609950786529394

Epoch: 6| Step: 5
Training loss: 1.9384707818317461
Validation loss: 2.6041839566220806

Epoch: 6| Step: 6
Training loss: 3.0209745878320704
Validation loss: 2.5969524206302332

Epoch: 6| Step: 7
Training loss: 3.4144705871128527
Validation loss: 2.6049564071411124

Epoch: 6| Step: 8
Training loss: 2.9444177214491476
Validation loss: 2.6065362957534113

Epoch: 6| Step: 9
Training loss: 2.7847886451500656
Validation loss: 2.6058849042895216

Epoch: 6| Step: 10
Training loss: 2.9078002404677585
Validation loss: 2.6091027719894906

Epoch: 6| Step: 11
Training loss: 2.738692183413149
Validation loss: 2.619433924609427

Epoch: 6| Step: 12
Training loss: 3.1457818808147837
Validation loss: 2.6188323855139792

Epoch: 6| Step: 13
Training loss: 3.1697231566544644
Validation loss: 2.617543590591027

Epoch: 329| Step: 0
Training loss: 2.7821983692137264
Validation loss: 2.624982200948958

Epoch: 6| Step: 1
Training loss: 3.2574838888804836
Validation loss: 2.620823023881268

Epoch: 6| Step: 2
Training loss: 2.5319680031537013
Validation loss: 2.608304373508207

Epoch: 6| Step: 3
Training loss: 2.2922311145505
Validation loss: 2.6006875668777805

Epoch: 6| Step: 4
Training loss: 2.481642557987353
Validation loss: 2.604504434317997

Epoch: 6| Step: 5
Training loss: 3.0341946172086023
Validation loss: 2.5945297425239056

Epoch: 6| Step: 6
Training loss: 2.503949478895069
Validation loss: 2.598693270570244

Epoch: 6| Step: 7
Training loss: 2.842176568008714
Validation loss: 2.5956768030634345

Epoch: 6| Step: 8
Training loss: 3.429096005817606
Validation loss: 2.601570684914113

Epoch: 6| Step: 9
Training loss: 3.0811504850895512
Validation loss: 2.6015979779577494

Epoch: 6| Step: 10
Training loss: 3.443427091160943
Validation loss: 2.6002849257875025

Epoch: 6| Step: 11
Training loss: 3.10311950498711
Validation loss: 2.6057263992721635

Epoch: 6| Step: 12
Training loss: 3.0631797191913877
Validation loss: 2.6031055662782427

Epoch: 6| Step: 13
Training loss: 2.8129526409850567
Validation loss: 2.6192315235355705

Epoch: 330| Step: 0
Training loss: 3.378304453272959
Validation loss: 2.642609716079131

Epoch: 6| Step: 1
Training loss: 2.93648998671503
Validation loss: 2.666696260529041

Epoch: 6| Step: 2
Training loss: 3.0061520439573846
Validation loss: 2.6717713820529077

Epoch: 6| Step: 3
Training loss: 2.8991275593122103
Validation loss: 2.681586945226096

Epoch: 6| Step: 4
Training loss: 3.0020287329857247
Validation loss: 2.6812599065488487

Epoch: 6| Step: 5
Training loss: 2.5373050182578107
Validation loss: 2.6736539493050424

Epoch: 6| Step: 6
Training loss: 3.151539072338323
Validation loss: 2.6679289724505537

Epoch: 6| Step: 7
Training loss: 3.226941398190168
Validation loss: 2.6472408742021996

Epoch: 6| Step: 8
Training loss: 2.7014413342019865
Validation loss: 2.64265620367734

Epoch: 6| Step: 9
Training loss: 3.2296627196905536
Validation loss: 2.6656996600944933

Epoch: 6| Step: 10
Training loss: 2.533269382807352
Validation loss: 2.6374084683832084

Epoch: 6| Step: 11
Training loss: 2.859978283886393
Validation loss: 2.63133501264276

Epoch: 6| Step: 12
Training loss: 2.566229362720691
Validation loss: 2.63280915329815

Epoch: 6| Step: 13
Training loss: 2.7286151493738235
Validation loss: 2.631170054157458

Epoch: 331| Step: 0
Training loss: 2.925897287835792
Validation loss: 2.6286301745132077

Epoch: 6| Step: 1
Training loss: 2.3451592849609124
Validation loss: 2.626117111151729

Epoch: 6| Step: 2
Training loss: 3.151042910909276
Validation loss: 2.643457353749286

Epoch: 6| Step: 3
Training loss: 2.4924757261634296
Validation loss: 2.644689121806152

Epoch: 6| Step: 4
Training loss: 2.8555617623894602
Validation loss: 2.6571483215006295

Epoch: 6| Step: 5
Training loss: 3.29608000078609
Validation loss: 2.663578122090446

Epoch: 6| Step: 6
Training loss: 2.735974873756457
Validation loss: 2.6606921408402466

Epoch: 6| Step: 7
Training loss: 2.8874786574330464
Validation loss: 2.661731140964505

Epoch: 6| Step: 8
Training loss: 2.3982958425631753
Validation loss: 2.66016819429489

Epoch: 6| Step: 9
Training loss: 3.590934247410564
Validation loss: 2.6892656524921117

Epoch: 6| Step: 10
Training loss: 3.1602064960950615
Validation loss: 2.6761954799882166

Epoch: 6| Step: 11
Training loss: 3.0895887961739112
Validation loss: 2.6830162062977143

Epoch: 6| Step: 12
Training loss: 2.5139697772009773
Validation loss: 2.6846300957623637

Epoch: 6| Step: 13
Training loss: 3.4108930667878643
Validation loss: 2.6439508516239107

Epoch: 332| Step: 0
Training loss: 2.9638950202049834
Validation loss: 2.6261013043189254

Epoch: 6| Step: 1
Training loss: 3.271676620983877
Validation loss: 2.6119278451747876

Epoch: 6| Step: 2
Training loss: 3.847497865157003
Validation loss: 2.5949993996413308

Epoch: 6| Step: 3
Training loss: 1.8526640243090473
Validation loss: 2.602489609381127

Epoch: 6| Step: 4
Training loss: 2.429505957785157
Validation loss: 2.5919885140820558

Epoch: 6| Step: 5
Training loss: 2.737686854565304
Validation loss: 2.5883245259251018

Epoch: 6| Step: 6
Training loss: 3.1676434633302417
Validation loss: 2.5860847847827193

Epoch: 6| Step: 7
Training loss: 3.142731979899869
Validation loss: 2.5921322180244077

Epoch: 6| Step: 8
Training loss: 3.015293399585436
Validation loss: 2.5923588067671313

Epoch: 6| Step: 9
Training loss: 3.682221724490271
Validation loss: 2.5905677467567836

Epoch: 6| Step: 10
Training loss: 2.901445909662839
Validation loss: 2.586772976435441

Epoch: 6| Step: 11
Training loss: 2.0989741726286346
Validation loss: 2.587142445008712

Epoch: 6| Step: 12
Training loss: 2.6146486636405557
Validation loss: 2.5816434674806263

Epoch: 6| Step: 13
Training loss: 2.913308380974498
Validation loss: 2.586572532254995

Epoch: 333| Step: 0
Training loss: 2.8851550335937053
Validation loss: 2.58635001106117

Epoch: 6| Step: 1
Training loss: 3.1918855304891642
Validation loss: 2.592467063775045

Epoch: 6| Step: 2
Training loss: 2.769815406157203
Validation loss: 2.5903504014227616

Epoch: 6| Step: 3
Training loss: 3.037232463341743
Validation loss: 2.597252136126052

Epoch: 6| Step: 4
Training loss: 2.9931091004843684
Validation loss: 2.5980154300649465

Epoch: 6| Step: 5
Training loss: 2.721555117742636
Validation loss: 2.6121842685132224

Epoch: 6| Step: 6
Training loss: 2.7380448482844546
Validation loss: 2.6143269289160886

Epoch: 6| Step: 7
Training loss: 2.3258938947570176
Validation loss: 2.607894028202014

Epoch: 6| Step: 8
Training loss: 2.707019624230988
Validation loss: 2.611065940608769

Epoch: 6| Step: 9
Training loss: 3.4777703747926134
Validation loss: 2.6219969514714396

Epoch: 6| Step: 10
Training loss: 3.385882035572633
Validation loss: 2.6353998585338916

Epoch: 6| Step: 11
Training loss: 2.8862365402495986
Validation loss: 2.6405327796548237

Epoch: 6| Step: 12
Training loss: 2.5681352756913896
Validation loss: 2.662075468129448

Epoch: 6| Step: 13
Training loss: 3.185763914759073
Validation loss: 2.669456933970168

Epoch: 334| Step: 0
Training loss: 2.6245967918624635
Validation loss: 2.6959257151455955

Epoch: 6| Step: 1
Training loss: 3.2337514672499057
Validation loss: 2.690559260957652

Epoch: 6| Step: 2
Training loss: 2.7723455294203627
Validation loss: 2.6724949944780025

Epoch: 6| Step: 3
Training loss: 3.0079580296571145
Validation loss: 2.641345492850713

Epoch: 6| Step: 4
Training loss: 2.521493074031276
Validation loss: 2.6259555151872616

Epoch: 6| Step: 5
Training loss: 3.4907999375646783
Validation loss: 2.615930346965604

Epoch: 6| Step: 6
Training loss: 2.0990746957283513
Validation loss: 2.6137140500181175

Epoch: 6| Step: 7
Training loss: 2.9906186605005627
Validation loss: 2.609184597634466

Epoch: 6| Step: 8
Training loss: 3.205488719129549
Validation loss: 2.6186720747771655

Epoch: 6| Step: 9
Training loss: 3.1994053526547246
Validation loss: 2.6144857754066058

Epoch: 6| Step: 10
Training loss: 3.080282471819942
Validation loss: 2.6143717768260806

Epoch: 6| Step: 11
Training loss: 2.3972862040130742
Validation loss: 2.6127856927415944

Epoch: 6| Step: 12
Training loss: 3.202882338845631
Validation loss: 2.615783217689779

Epoch: 6| Step: 13
Training loss: 2.735438287266522
Validation loss: 2.6210862754983073

Epoch: 335| Step: 0
Training loss: 3.211902928064845
Validation loss: 2.643213965865627

Epoch: 6| Step: 1
Training loss: 2.9104493678410064
Validation loss: 2.6706057022667813

Epoch: 6| Step: 2
Training loss: 2.9243868062807667
Validation loss: 2.6926075030328627

Epoch: 6| Step: 3
Training loss: 2.8215750195813487
Validation loss: 2.7048436352089875

Epoch: 6| Step: 4
Training loss: 3.1993224857265923
Validation loss: 2.722437744958075

Epoch: 6| Step: 5
Training loss: 2.5434444234575455
Validation loss: 2.7364139241139696

Epoch: 6| Step: 6
Training loss: 3.4533837683196964
Validation loss: 2.709541643500262

Epoch: 6| Step: 7
Training loss: 3.1205866357518275
Validation loss: 2.6461089551588532

Epoch: 6| Step: 8
Training loss: 3.15788332535539
Validation loss: 2.6274573401567864

Epoch: 6| Step: 9
Training loss: 2.7511572570282437
Validation loss: 2.604218344555078

Epoch: 6| Step: 10
Training loss: 2.7533163534599914
Validation loss: 2.599171564247961

Epoch: 6| Step: 11
Training loss: 2.4610099660709595
Validation loss: 2.6085238783975475

Epoch: 6| Step: 12
Training loss: 2.4845454319488645
Validation loss: 2.596089832429513

Epoch: 6| Step: 13
Training loss: 2.9726966724830497
Validation loss: 2.606711630008433

Epoch: 336| Step: 0
Training loss: 3.3294801057609886
Validation loss: 2.5919998793831738

Epoch: 6| Step: 1
Training loss: 2.8849619887044495
Validation loss: 2.5874898863460962

Epoch: 6| Step: 2
Training loss: 3.137507471326466
Validation loss: 2.5794691771149876

Epoch: 6| Step: 3
Training loss: 3.1129237487845844
Validation loss: 2.5874883209087

Epoch: 6| Step: 4
Training loss: 1.554735039218996
Validation loss: 2.5870017975163875

Epoch: 6| Step: 5
Training loss: 2.6827838236320947
Validation loss: 2.592126601439405

Epoch: 6| Step: 6
Training loss: 3.240622710445114
Validation loss: 2.5857720397254296

Epoch: 6| Step: 7
Training loss: 2.866557953865341
Validation loss: 2.5973626705432866

Epoch: 6| Step: 8
Training loss: 2.912837775949183
Validation loss: 2.5969808870809192

Epoch: 6| Step: 9
Training loss: 2.999493079272726
Validation loss: 2.609704095931838

Epoch: 6| Step: 10
Training loss: 2.955628156686518
Validation loss: 2.605054525974997

Epoch: 6| Step: 11
Training loss: 2.6193275925413264
Validation loss: 2.603693669504645

Epoch: 6| Step: 12
Training loss: 2.9503284918011574
Validation loss: 2.622088458849975

Epoch: 6| Step: 13
Training loss: 3.6346280063197294
Validation loss: 2.6116619378565313

Epoch: 337| Step: 0
Training loss: 3.100970848401629
Validation loss: 2.611396620959286

Epoch: 6| Step: 1
Training loss: 2.930022279049273
Validation loss: 2.611481995170671

Epoch: 6| Step: 2
Training loss: 2.429565426620869
Validation loss: 2.6156965127390626

Epoch: 6| Step: 3
Training loss: 2.9855092075341996
Validation loss: 2.6172073894902668

Epoch: 6| Step: 4
Training loss: 3.2714887476649883
Validation loss: 2.6204682359297227

Epoch: 6| Step: 5
Training loss: 2.3504389616687598
Validation loss: 2.5965003020630846

Epoch: 6| Step: 6
Training loss: 2.955343714828839
Validation loss: 2.6074669390115552

Epoch: 6| Step: 7
Training loss: 3.390682378186741
Validation loss: 2.598577922133378

Epoch: 6| Step: 8
Training loss: 3.2034670763415223
Validation loss: 2.600409311814937

Epoch: 6| Step: 9
Training loss: 2.6979665763882896
Validation loss: 2.601165949186006

Epoch: 6| Step: 10
Training loss: 2.8992086448894225
Validation loss: 2.6166213634068303

Epoch: 6| Step: 11
Training loss: 2.4990596910226923
Validation loss: 2.6098652757875525

Epoch: 6| Step: 12
Training loss: 2.750959055732811
Validation loss: 2.619621247500742

Epoch: 6| Step: 13
Training loss: 3.309476804383134
Validation loss: 2.626205770959979

Epoch: 338| Step: 0
Training loss: 3.0500021512383553
Validation loss: 2.624684878887673

Epoch: 6| Step: 1
Training loss: 2.9812226748063932
Validation loss: 2.6345384282218536

Epoch: 6| Step: 2
Training loss: 3.166594220052164
Validation loss: 2.6521020166841476

Epoch: 6| Step: 3
Training loss: 3.1978451268315347
Validation loss: 2.6624202668766994

Epoch: 6| Step: 4
Training loss: 2.6496006034875728
Validation loss: 2.6904415736246574

Epoch: 6| Step: 5
Training loss: 2.5006585207529937
Validation loss: 2.702011012579466

Epoch: 6| Step: 6
Training loss: 3.6221690469152805
Validation loss: 2.721149269928125

Epoch: 6| Step: 7
Training loss: 3.052717349150778
Validation loss: 2.660948891208547

Epoch: 6| Step: 8
Training loss: 2.5383713001493446
Validation loss: 2.6356431256676154

Epoch: 6| Step: 9
Training loss: 2.7052447877077
Validation loss: 2.6204411614403975

Epoch: 6| Step: 10
Training loss: 2.5875991138880723
Validation loss: 2.6088640050273226

Epoch: 6| Step: 11
Training loss: 2.2875996885830086
Validation loss: 2.6024013897288225

Epoch: 6| Step: 12
Training loss: 2.8214115949399377
Validation loss: 2.6036230833357594

Epoch: 6| Step: 13
Training loss: 3.62444169579277
Validation loss: 2.6068081043552214

Epoch: 339| Step: 0
Training loss: 2.955999358119043
Validation loss: 2.603681017147498

Epoch: 6| Step: 1
Training loss: 2.638024669367018
Validation loss: 2.603476216656375

Epoch: 6| Step: 2
Training loss: 3.381908269467228
Validation loss: 2.604191505231637

Epoch: 6| Step: 3
Training loss: 3.56344618696803
Validation loss: 2.604544987588134

Epoch: 6| Step: 4
Training loss: 3.0282735467305666
Validation loss: 2.6042727016068064

Epoch: 6| Step: 5
Training loss: 3.151351905031506
Validation loss: 2.611578706567513

Epoch: 6| Step: 6
Training loss: 2.466451323190707
Validation loss: 2.616409382484361

Epoch: 6| Step: 7
Training loss: 2.9963911920986597
Validation loss: 2.616844977401359

Epoch: 6| Step: 8
Training loss: 2.787396272516971
Validation loss: 2.6301556208610144

Epoch: 6| Step: 9
Training loss: 2.7085932289037213
Validation loss: 2.618128404622611

Epoch: 6| Step: 10
Training loss: 2.9872946313474906
Validation loss: 2.6101956574345055

Epoch: 6| Step: 11
Training loss: 2.4568059238766122
Validation loss: 2.6004039930924923

Epoch: 6| Step: 12
Training loss: 2.6242213229603717
Validation loss: 2.6119547728398897

Epoch: 6| Step: 13
Training loss: 3.0412727693143617
Validation loss: 2.602715791872439

Epoch: 340| Step: 0
Training loss: 3.2417456636062254
Validation loss: 2.609298998707316

Epoch: 6| Step: 1
Training loss: 2.830598371350584
Validation loss: 2.6105001783310358

Epoch: 6| Step: 2
Training loss: 3.2473027701096364
Validation loss: 2.617010381365553

Epoch: 6| Step: 3
Training loss: 3.028930248355326
Validation loss: 2.6130540296722504

Epoch: 6| Step: 4
Training loss: 3.2843314098075185
Validation loss: 2.6138600869434527

Epoch: 6| Step: 5
Training loss: 2.38742459562571
Validation loss: 2.615248036032803

Epoch: 6| Step: 6
Training loss: 2.6387409960702928
Validation loss: 2.6256228624556086

Epoch: 6| Step: 7
Training loss: 2.644671347666929
Validation loss: 2.625616261540241

Epoch: 6| Step: 8
Training loss: 2.3496715762561093
Validation loss: 2.6304946491781847

Epoch: 6| Step: 9
Training loss: 3.324300511718505
Validation loss: 2.641736883776064

Epoch: 6| Step: 10
Training loss: 3.422267386178351
Validation loss: 2.638276568148236

Epoch: 6| Step: 11
Training loss: 2.574754858847809
Validation loss: 2.6461028534345434

Epoch: 6| Step: 12
Training loss: 2.6847262595665415
Validation loss: 2.6460661255623847

Epoch: 6| Step: 13
Training loss: 2.5944709235543466
Validation loss: 2.639765340839474

Epoch: 341| Step: 0
Training loss: 2.3179295695008206
Validation loss: 2.6405259601844446

Epoch: 6| Step: 1
Training loss: 3.220354883765542
Validation loss: 2.639574036295846

Epoch: 6| Step: 2
Training loss: 2.7974085804964837
Validation loss: 2.641366625233591

Epoch: 6| Step: 3
Training loss: 2.944480070062558
Validation loss: 2.628536828188566

Epoch: 6| Step: 4
Training loss: 2.230524332987387
Validation loss: 2.6349394738863703

Epoch: 6| Step: 5
Training loss: 3.0317151214211426
Validation loss: 2.6343151823920565

Epoch: 6| Step: 6
Training loss: 3.0450790981298312
Validation loss: 2.6384012715916643

Epoch: 6| Step: 7
Training loss: 2.7494921648850728
Validation loss: 2.6375789637706326

Epoch: 6| Step: 8
Training loss: 3.1731851812715113
Validation loss: 2.635419172831922

Epoch: 6| Step: 9
Training loss: 3.3666630666228836
Validation loss: 2.624829886921341

Epoch: 6| Step: 10
Training loss: 2.64539047099262
Validation loss: 2.6321182316619414

Epoch: 6| Step: 11
Training loss: 2.979873537798128
Validation loss: 2.6298458249581182

Epoch: 6| Step: 12
Training loss: 2.999934195750468
Validation loss: 2.6365747312943175

Epoch: 6| Step: 13
Training loss: 2.8874831161996237
Validation loss: 2.631870298241032

Epoch: 342| Step: 0
Training loss: 3.3620986188395388
Validation loss: 2.634728169871874

Epoch: 6| Step: 1
Training loss: 2.797458864784019
Validation loss: 2.6251699887740365

Epoch: 6| Step: 2
Training loss: 2.918661216676148
Validation loss: 2.624326194621943

Epoch: 6| Step: 3
Training loss: 3.1959759086493427
Validation loss: 2.6128465994351964

Epoch: 6| Step: 4
Training loss: 2.899796570844706
Validation loss: 2.614889729880128

Epoch: 6| Step: 5
Training loss: 2.51671894052881
Validation loss: 2.6189922684625917

Epoch: 6| Step: 6
Training loss: 3.143568491009225
Validation loss: 2.616850206866672

Epoch: 6| Step: 7
Training loss: 3.0643080998586574
Validation loss: 2.623219074895974

Epoch: 6| Step: 8
Training loss: 2.8643938221522176
Validation loss: 2.6294231641940278

Epoch: 6| Step: 9
Training loss: 2.2309892518089396
Validation loss: 2.637017983700231

Epoch: 6| Step: 10
Training loss: 2.4186839092205017
Validation loss: 2.636516170642212

Epoch: 6| Step: 11
Training loss: 3.1545700285656224
Validation loss: 2.63036299991622

Epoch: 6| Step: 12
Training loss: 2.7492897677104096
Validation loss: 2.6185903448984527

Epoch: 6| Step: 13
Training loss: 3.2667713252319057
Validation loss: 2.6122317715821692

Epoch: 343| Step: 0
Training loss: 2.7600526005805017
Validation loss: 2.619025453743526

Epoch: 6| Step: 1
Training loss: 3.523733460711271
Validation loss: 2.6135303298843673

Epoch: 6| Step: 2
Training loss: 3.0282653587101103
Validation loss: 2.622087696236502

Epoch: 6| Step: 3
Training loss: 3.2657612311316035
Validation loss: 2.6062543124801647

Epoch: 6| Step: 4
Training loss: 3.2398612995836027
Validation loss: 2.604783504813788

Epoch: 6| Step: 5
Training loss: 2.0801248894391082
Validation loss: 2.6081073214749106

Epoch: 6| Step: 6
Training loss: 2.5509616384937845
Validation loss: 2.603640923046201

Epoch: 6| Step: 7
Training loss: 3.115838927918362
Validation loss: 2.6035738969726743

Epoch: 6| Step: 8
Training loss: 2.741780133976842
Validation loss: 2.6067741016785706

Epoch: 6| Step: 9
Training loss: 2.530477994764729
Validation loss: 2.6053023830293456

Epoch: 6| Step: 10
Training loss: 2.9456518164955336
Validation loss: 2.6089598789898956

Epoch: 6| Step: 11
Training loss: 3.130651932362722
Validation loss: 2.6146143805325677

Epoch: 6| Step: 12
Training loss: 2.8116625916685716
Validation loss: 2.5997608354843535

Epoch: 6| Step: 13
Training loss: 2.3381018164779586
Validation loss: 2.605457131539361

Epoch: 344| Step: 0
Training loss: 2.6497315252807963
Validation loss: 2.6247125088272414

Epoch: 6| Step: 1
Training loss: 3.6699364272595996
Validation loss: 2.6273384977462513

Epoch: 6| Step: 2
Training loss: 2.8508296495146386
Validation loss: 2.6299398637129667

Epoch: 6| Step: 3
Training loss: 2.5284402582353676
Validation loss: 2.61583037902872

Epoch: 6| Step: 4
Training loss: 2.662922813978657
Validation loss: 2.618850317401734

Epoch: 6| Step: 5
Training loss: 3.007745281310586
Validation loss: 2.6203654405099543

Epoch: 6| Step: 6
Training loss: 2.017413506526894
Validation loss: 2.624742896736573

Epoch: 6| Step: 7
Training loss: 2.7735496820676757
Validation loss: 2.6442994398314137

Epoch: 6| Step: 8
Training loss: 2.457465541283678
Validation loss: 2.624456877806782

Epoch: 6| Step: 9
Training loss: 3.281294177529986
Validation loss: 2.6315982370406323

Epoch: 6| Step: 10
Training loss: 3.674673888600325
Validation loss: 2.6312685692568207

Epoch: 6| Step: 11
Training loss: 2.1195169281748094
Validation loss: 2.620060596563759

Epoch: 6| Step: 12
Training loss: 3.133738392830082
Validation loss: 2.62900777241432

Epoch: 6| Step: 13
Training loss: 3.4772443809872526
Validation loss: 2.623072274306016

Epoch: 345| Step: 0
Training loss: 2.873411486094606
Validation loss: 2.6116274437569897

Epoch: 6| Step: 1
Training loss: 2.3024173223871087
Validation loss: 2.6011655096201185

Epoch: 6| Step: 2
Training loss: 2.8884273938864067
Validation loss: 2.601396103962078

Epoch: 6| Step: 3
Training loss: 2.126392805628952
Validation loss: 2.5931802334607985

Epoch: 6| Step: 4
Training loss: 2.8658474069397486
Validation loss: 2.589987194829243

Epoch: 6| Step: 5
Training loss: 3.708404511758008
Validation loss: 2.5936406104214162

Epoch: 6| Step: 6
Training loss: 3.3422264835176065
Validation loss: 2.5973226605214363

Epoch: 6| Step: 7
Training loss: 2.748357021938351
Validation loss: 2.596237729165358

Epoch: 6| Step: 8
Training loss: 2.7535450367054177
Validation loss: 2.6050778028471084

Epoch: 6| Step: 9
Training loss: 2.557306189926354
Validation loss: 2.6053813682234717

Epoch: 6| Step: 10
Training loss: 3.013780098712983
Validation loss: 2.617465928336616

Epoch: 6| Step: 11
Training loss: 2.8731481143999997
Validation loss: 2.620004455487783

Epoch: 6| Step: 12
Training loss: 3.366656976314485
Validation loss: 2.632309640773306

Epoch: 6| Step: 13
Training loss: 2.712871642077214
Validation loss: 2.6297107009313154

Epoch: 346| Step: 0
Training loss: 2.8069090479244805
Validation loss: 2.611594502153766

Epoch: 6| Step: 1
Training loss: 2.8571932447622506
Validation loss: 2.63475986869499

Epoch: 6| Step: 2
Training loss: 2.686303338062266
Validation loss: 2.6243963421555967

Epoch: 6| Step: 3
Training loss: 3.180147854708585
Validation loss: 2.6187236706933876

Epoch: 6| Step: 4
Training loss: 2.5678675191462332
Validation loss: 2.6162482206955113

Epoch: 6| Step: 5
Training loss: 2.078611618087924
Validation loss: 2.6146272417758016

Epoch: 6| Step: 6
Training loss: 2.7980513842529193
Validation loss: 2.607843050665982

Epoch: 6| Step: 7
Training loss: 3.0407252139350174
Validation loss: 2.590375808587598

Epoch: 6| Step: 8
Training loss: 2.788886313122712
Validation loss: 2.613835839318302

Epoch: 6| Step: 9
Training loss: 2.8979238378864323
Validation loss: 2.61456927890691

Epoch: 6| Step: 10
Training loss: 3.0979791884194254
Validation loss: 2.611385841734082

Epoch: 6| Step: 11
Training loss: 3.356613088392956
Validation loss: 2.629488656828972

Epoch: 6| Step: 12
Training loss: 3.010018151821014
Validation loss: 2.6436956902704574

Epoch: 6| Step: 13
Training loss: 3.4573006217881175
Validation loss: 2.641873888535801

Epoch: 347| Step: 0
Training loss: 2.876697536699221
Validation loss: 2.6426180493711047

Epoch: 6| Step: 1
Training loss: 3.4684544342862176
Validation loss: 2.6450555365629405

Epoch: 6| Step: 2
Training loss: 2.453186617520832
Validation loss: 2.6346525029338568

Epoch: 6| Step: 3
Training loss: 2.442557248212848
Validation loss: 2.64235469396607

Epoch: 6| Step: 4
Training loss: 2.5440760485540554
Validation loss: 2.6510129392304282

Epoch: 6| Step: 5
Training loss: 3.1383971857863933
Validation loss: 2.6400670035241163

Epoch: 6| Step: 6
Training loss: 3.4497762469281437
Validation loss: 2.655676090750476

Epoch: 6| Step: 7
Training loss: 2.998840584827818
Validation loss: 2.6553622263615697

Epoch: 6| Step: 8
Training loss: 2.212292690586402
Validation loss: 2.647492989338867

Epoch: 6| Step: 9
Training loss: 2.7895627040731767
Validation loss: 2.645217454340532

Epoch: 6| Step: 10
Training loss: 2.9478046589163447
Validation loss: 2.6453483827641597

Epoch: 6| Step: 11
Training loss: 3.104688323221928
Validation loss: 2.6293008405763527

Epoch: 6| Step: 12
Training loss: 3.3949725848567187
Validation loss: 2.609790217061984

Epoch: 6| Step: 13
Training loss: 2.0641372424561744
Validation loss: 2.6050636357957826

Epoch: 348| Step: 0
Training loss: 2.518657112775258
Validation loss: 2.600266169813932

Epoch: 6| Step: 1
Training loss: 3.408459567940001
Validation loss: 2.5952712795563917

Epoch: 6| Step: 2
Training loss: 2.8280590745186505
Validation loss: 2.5895588115370973

Epoch: 6| Step: 3
Training loss: 2.827644012183544
Validation loss: 2.592529606758031

Epoch: 6| Step: 4
Training loss: 3.0475359859954896
Validation loss: 2.5932810883742987

Epoch: 6| Step: 5
Training loss: 2.4558308250984853
Validation loss: 2.589749023455245

Epoch: 6| Step: 6
Training loss: 2.715086650273551
Validation loss: 2.598897404324058

Epoch: 6| Step: 7
Training loss: 2.714430962885317
Validation loss: 2.5967365233944295

Epoch: 6| Step: 8
Training loss: 3.006324776653335
Validation loss: 2.596189212602003

Epoch: 6| Step: 9
Training loss: 3.33462219752033
Validation loss: 2.600527837141238

Epoch: 6| Step: 10
Training loss: 2.8525101432653384
Validation loss: 2.5987676090629055

Epoch: 6| Step: 11
Training loss: 2.7690509331214814
Validation loss: 2.6005152236013966

Epoch: 6| Step: 12
Training loss: 2.628414476489065
Validation loss: 2.621417838448956

Epoch: 6| Step: 13
Training loss: 3.623944490601294
Validation loss: 2.6299090533262635

Epoch: 349| Step: 0
Training loss: 3.0419672638926816
Validation loss: 2.656275477519414

Epoch: 6| Step: 1
Training loss: 3.591053622885145
Validation loss: 2.7158192212756815

Epoch: 6| Step: 2
Training loss: 2.76191056811532
Validation loss: 2.7017973281156658

Epoch: 6| Step: 3
Training loss: 2.8951723364362985
Validation loss: 2.7170119556923917

Epoch: 6| Step: 4
Training loss: 2.526098212693992
Validation loss: 2.704027870972544

Epoch: 6| Step: 5
Training loss: 2.481128995236527
Validation loss: 2.6777622339958316

Epoch: 6| Step: 6
Training loss: 2.1149330664249786
Validation loss: 2.659405211008389

Epoch: 6| Step: 7
Training loss: 2.965882532737608
Validation loss: 2.63756312745906

Epoch: 6| Step: 8
Training loss: 3.155575821890546
Validation loss: 2.6291291750426464

Epoch: 6| Step: 9
Training loss: 2.7001381838723764
Validation loss: 2.6232113562636568

Epoch: 6| Step: 10
Training loss: 2.593705142449079
Validation loss: 2.60774016555156

Epoch: 6| Step: 11
Training loss: 3.2093323642532203
Validation loss: 2.616193780270654

Epoch: 6| Step: 12
Training loss: 3.0301763461826514
Validation loss: 2.6085802223302874

Epoch: 6| Step: 13
Training loss: 3.228020216357375
Validation loss: 2.6172675908873693

Epoch: 350| Step: 0
Training loss: 3.1774621622997623
Validation loss: 2.621426516847725

Epoch: 6| Step: 1
Training loss: 3.1569587742624354
Validation loss: 2.6076196281913515

Epoch: 6| Step: 2
Training loss: 2.8140549493886415
Validation loss: 2.621119776592379

Epoch: 6| Step: 3
Training loss: 2.945027385642629
Validation loss: 2.623112047944491

Epoch: 6| Step: 4
Training loss: 2.911431400581674
Validation loss: 2.6321204046190023

Epoch: 6| Step: 5
Training loss: 2.033670245331835
Validation loss: 2.624115435960233

Epoch: 6| Step: 6
Training loss: 2.427936769551402
Validation loss: 2.6499650805079007

Epoch: 6| Step: 7
Training loss: 3.073229154226415
Validation loss: 2.6455048152134526

Epoch: 6| Step: 8
Training loss: 3.115858363496266
Validation loss: 2.667177707659358

Epoch: 6| Step: 9
Training loss: 2.5433242479047906
Validation loss: 2.667518785932604

Epoch: 6| Step: 10
Training loss: 3.0985492511089525
Validation loss: 2.6752068935731352

Epoch: 6| Step: 11
Training loss: 3.042266960654126
Validation loss: 2.6770706460552445

Epoch: 6| Step: 12
Training loss: 3.2684349127012537
Validation loss: 2.667075328379813

Epoch: 6| Step: 13
Training loss: 2.405264318141462
Validation loss: 2.6325630835927147

Testing loss: 2.7954433838166524
