Epoch: 1| Step: 0
Training loss: 5.485348701477051
Validation loss: 5.109883385319864

Epoch: 6| Step: 1
Training loss: 4.925210952758789
Validation loss: 5.097594779024842

Epoch: 6| Step: 2
Training loss: 4.761227607727051
Validation loss: 5.086384578417706

Epoch: 6| Step: 3
Training loss: 5.535214424133301
Validation loss: 5.076217589839812

Epoch: 6| Step: 4
Training loss: 5.64238977432251
Validation loss: 5.06537534857309

Epoch: 6| Step: 5
Training loss: 4.967641830444336
Validation loss: 5.053695322364889

Epoch: 6| Step: 6
Training loss: 5.131980895996094
Validation loss: 5.041892046569496

Epoch: 6| Step: 7
Training loss: 4.119325637817383
Validation loss: 5.028894127056163

Epoch: 6| Step: 8
Training loss: 4.932900905609131
Validation loss: 5.015891259716403

Epoch: 6| Step: 9
Training loss: 3.867248773574829
Validation loss: 5.001288931856873

Epoch: 6| Step: 10
Training loss: 5.363724708557129
Validation loss: 4.986194169649514

Epoch: 6| Step: 11
Training loss: 3.8931469917297363
Validation loss: 4.969709386107742

Epoch: 6| Step: 12
Training loss: 5.084334373474121
Validation loss: 4.952482192747055

Epoch: 6| Step: 13
Training loss: 3.147350549697876
Validation loss: 4.934162252692766

Epoch: 2| Step: 0
Training loss: 4.655660629272461
Validation loss: 4.914168409121934

Epoch: 6| Step: 1
Training loss: 4.610351085662842
Validation loss: 4.892293889035461

Epoch: 6| Step: 2
Training loss: 3.674755573272705
Validation loss: 4.869056604241812

Epoch: 6| Step: 3
Training loss: 4.930715560913086
Validation loss: 4.843984598754554

Epoch: 6| Step: 4
Training loss: 4.230446815490723
Validation loss: 4.816866228657384

Epoch: 6| Step: 5
Training loss: 4.829374313354492
Validation loss: 4.7893946606625795

Epoch: 6| Step: 6
Training loss: 3.9522528648376465
Validation loss: 4.7594109094271095

Epoch: 6| Step: 7
Training loss: 4.131505966186523
Validation loss: 4.727199713389079

Epoch: 6| Step: 8
Training loss: 4.532290935516357
Validation loss: 4.69379533234463

Epoch: 6| Step: 9
Training loss: 5.323760032653809
Validation loss: 4.659330004005022

Epoch: 6| Step: 10
Training loss: 4.138700485229492
Validation loss: 4.622335341668898

Epoch: 6| Step: 11
Training loss: 4.882261276245117
Validation loss: 4.583762686739686

Epoch: 6| Step: 12
Training loss: 4.6362762451171875
Validation loss: 4.544389934949978

Epoch: 6| Step: 13
Training loss: 4.907524108886719
Validation loss: 4.502960256350938

Epoch: 3| Step: 0
Training loss: 4.838791847229004
Validation loss: 4.461569770689933

Epoch: 6| Step: 1
Training loss: 2.803976058959961
Validation loss: 4.417783239836334

Epoch: 6| Step: 2
Training loss: 5.38953971862793
Validation loss: 4.375274981221845

Epoch: 6| Step: 3
Training loss: 4.159109115600586
Validation loss: 4.333145618438721

Epoch: 6| Step: 4
Training loss: 2.7715110778808594
Validation loss: 4.292659164756857

Epoch: 6| Step: 5
Training loss: 4.053135395050049
Validation loss: 4.252837260564168

Epoch: 6| Step: 6
Training loss: 4.846909046173096
Validation loss: 4.214603608654391

Epoch: 6| Step: 7
Training loss: 4.985036849975586
Validation loss: 4.178759569762855

Epoch: 6| Step: 8
Training loss: 4.394207954406738
Validation loss: 4.141395358629124

Epoch: 6| Step: 9
Training loss: 1.9775282144546509
Validation loss: 4.108431047008883

Epoch: 6| Step: 10
Training loss: 4.379755973815918
Validation loss: 4.075308610034245

Epoch: 6| Step: 11
Training loss: 4.888805866241455
Validation loss: 4.042780999214418

Epoch: 6| Step: 12
Training loss: 3.4402735233306885
Validation loss: 4.009621292032222

Epoch: 6| Step: 13
Training loss: 3.0982143878936768
Validation loss: 3.981667641670473

Epoch: 4| Step: 0
Training loss: 4.115467071533203
Validation loss: 3.9546537655656055

Epoch: 6| Step: 1
Training loss: 3.5038881301879883
Validation loss: 3.928818279697049

Epoch: 6| Step: 2
Training loss: 4.0406646728515625
Validation loss: 3.9004949036464898

Epoch: 6| Step: 3
Training loss: 3.3292770385742188
Validation loss: 3.875441981900123

Epoch: 6| Step: 4
Training loss: 4.492724418640137
Validation loss: 3.8494746249209166

Epoch: 6| Step: 5
Training loss: 2.9007461071014404
Validation loss: 3.8236620605632825

Epoch: 6| Step: 6
Training loss: 3.2759456634521484
Validation loss: 3.795409212830246

Epoch: 6| Step: 7
Training loss: 4.486582279205322
Validation loss: 3.7720928012683825

Epoch: 6| Step: 8
Training loss: 3.8910012245178223
Validation loss: 3.74619117347143

Epoch: 6| Step: 9
Training loss: 2.9053733348846436
Validation loss: 3.728434342210011

Epoch: 6| Step: 10
Training loss: 2.8214008808135986
Validation loss: 3.709646189084617

Epoch: 6| Step: 11
Training loss: 4.800411224365234
Validation loss: 3.6928356001454015

Epoch: 6| Step: 12
Training loss: 3.8135077953338623
Validation loss: 3.6729203449782504

Epoch: 6| Step: 13
Training loss: 2.901609182357788
Validation loss: 3.6554406996696227

Epoch: 5| Step: 0
Training loss: 4.469966888427734
Validation loss: 3.6417033595423542

Epoch: 6| Step: 1
Training loss: 2.616082191467285
Validation loss: 3.6233481412292807

Epoch: 6| Step: 2
Training loss: 3.854032516479492
Validation loss: 3.6052112374254452

Epoch: 6| Step: 3
Training loss: 3.615894317626953
Validation loss: 3.5935787821328766

Epoch: 6| Step: 4
Training loss: 2.9511640071868896
Validation loss: 3.5796939608871297

Epoch: 6| Step: 5
Training loss: 3.73063063621521
Validation loss: 3.5640067310743433

Epoch: 6| Step: 6
Training loss: 2.522963285446167
Validation loss: 3.55328776503122

Epoch: 6| Step: 7
Training loss: 4.548458099365234
Validation loss: 3.5439073578003915

Epoch: 6| Step: 8
Training loss: 2.825181007385254
Validation loss: 3.5324487429793163

Epoch: 6| Step: 9
Training loss: 2.7925965785980225
Validation loss: 3.5266268894236577

Epoch: 6| Step: 10
Training loss: 4.1045331954956055
Validation loss: 3.5167902361962105

Epoch: 6| Step: 11
Training loss: 2.8096160888671875
Validation loss: 3.5064550010106896

Epoch: 6| Step: 12
Training loss: 3.972045660018921
Validation loss: 3.4944011677977858

Epoch: 6| Step: 13
Training loss: 4.3972344398498535
Validation loss: 3.485880523599604

Epoch: 6| Step: 0
Training loss: 3.691211223602295
Validation loss: 3.477525236786053

Epoch: 6| Step: 1
Training loss: 3.7614645957946777
Validation loss: 3.4709733634866695

Epoch: 6| Step: 2
Training loss: 2.930753231048584
Validation loss: 3.463466751960016

Epoch: 6| Step: 3
Training loss: 4.061373710632324
Validation loss: 3.4539803945890037

Epoch: 6| Step: 4
Training loss: 2.893603801727295
Validation loss: 3.445512053787067

Epoch: 6| Step: 5
Training loss: 2.932187080383301
Validation loss: 3.4405718490641606

Epoch: 6| Step: 6
Training loss: 3.487224817276001
Validation loss: 3.4312111536661782

Epoch: 6| Step: 7
Training loss: 3.8739359378814697
Validation loss: 3.424004667548723

Epoch: 6| Step: 8
Training loss: 2.853541851043701
Validation loss: 3.4180519503931843

Epoch: 6| Step: 9
Training loss: 3.0309221744537354
Validation loss: 3.4114332455460743

Epoch: 6| Step: 10
Training loss: 3.353107452392578
Validation loss: 3.406625155479677

Epoch: 6| Step: 11
Training loss: 3.4914002418518066
Validation loss: 3.3999241628954486

Epoch: 6| Step: 12
Training loss: 3.2517051696777344
Validation loss: 3.3879931870327202

Epoch: 6| Step: 13
Training loss: 3.9156014919281006
Validation loss: 3.3804024163112847

Epoch: 7| Step: 0
Training loss: 3.3253135681152344
Validation loss: 3.383023779879334

Epoch: 6| Step: 1
Training loss: 4.036223888397217
Validation loss: 3.384485388314852

Epoch: 6| Step: 2
Training loss: 3.7177517414093018
Validation loss: 3.3693719628036662

Epoch: 6| Step: 3
Training loss: 3.054027557373047
Validation loss: 3.359793519461027

Epoch: 6| Step: 4
Training loss: 3.1695446968078613
Validation loss: 3.3576813872142504

Epoch: 6| Step: 5
Training loss: 3.5012574195861816
Validation loss: 3.3517790661063245

Epoch: 6| Step: 6
Training loss: 3.2480239868164062
Validation loss: 3.351113624470208

Epoch: 6| Step: 7
Training loss: 2.3319787979125977
Validation loss: 3.34355164599675

Epoch: 6| Step: 8
Training loss: 4.164450168609619
Validation loss: 3.3347585431991087

Epoch: 6| Step: 9
Training loss: 3.877147674560547
Validation loss: 3.3229009900041806

Epoch: 6| Step: 10
Training loss: 3.6574010848999023
Validation loss: 3.3130650827961583

Epoch: 6| Step: 11
Training loss: 2.102032423019409
Validation loss: 3.306195787204209

Epoch: 6| Step: 12
Training loss: 3.599043846130371
Validation loss: 3.3133054292330177

Epoch: 6| Step: 13
Training loss: 1.9043025970458984
Validation loss: 3.312066311477333

Epoch: 8| Step: 0
Training loss: 3.044339656829834
Validation loss: 3.3141685737076627

Epoch: 6| Step: 1
Training loss: 3.243220806121826
Validation loss: 3.29552903995719

Epoch: 6| Step: 2
Training loss: 3.649441719055176
Validation loss: 3.2803157119340796

Epoch: 6| Step: 3
Training loss: 2.1834912300109863
Validation loss: 3.2717063144970964

Epoch: 6| Step: 4
Training loss: 3.1081888675689697
Validation loss: 3.274329685395764

Epoch: 6| Step: 5
Training loss: 4.475716590881348
Validation loss: 3.2722299944969917

Epoch: 6| Step: 6
Training loss: 3.254328966140747
Validation loss: 3.2659589244473364

Epoch: 6| Step: 7
Training loss: 3.014137029647827
Validation loss: 3.2510270713478007

Epoch: 6| Step: 8
Training loss: 2.397507429122925
Validation loss: 3.245966975406934

Epoch: 6| Step: 9
Training loss: 3.617736339569092
Validation loss: 3.2537546439837386

Epoch: 6| Step: 10
Training loss: 3.4598488807678223
Validation loss: 3.2467729199317192

Epoch: 6| Step: 11
Training loss: 2.802252769470215
Validation loss: 3.2338657199695544

Epoch: 6| Step: 12
Training loss: 3.317004680633545
Validation loss: 3.2265235582987466

Epoch: 6| Step: 13
Training loss: 4.337942123413086
Validation loss: 3.2207013637788835

Epoch: 9| Step: 0
Training loss: 2.447899341583252
Validation loss: 3.2158478511277067

Epoch: 6| Step: 1
Training loss: 2.7852962017059326
Validation loss: 3.2102899013027066

Epoch: 6| Step: 2
Training loss: 2.5371527671813965
Validation loss: 3.2083702061765935

Epoch: 6| Step: 3
Training loss: 3.8090906143188477
Validation loss: 3.2017524319310344

Epoch: 6| Step: 4
Training loss: 3.267131805419922
Validation loss: 3.1995239309085313

Epoch: 6| Step: 5
Training loss: 3.4381752014160156
Validation loss: 3.192693487290413

Epoch: 6| Step: 6
Training loss: 2.791189670562744
Validation loss: 3.1862180566274994

Epoch: 6| Step: 7
Training loss: 3.286921739578247
Validation loss: 3.1831510348986556

Epoch: 6| Step: 8
Training loss: 4.138587951660156
Validation loss: 3.187498741252448

Epoch: 6| Step: 9
Training loss: 3.6622109413146973
Validation loss: 3.180868125730945

Epoch: 6| Step: 10
Training loss: 2.532296895980835
Validation loss: 3.1688328737853677

Epoch: 6| Step: 11
Training loss: 4.073702812194824
Validation loss: 3.1643687858376452

Epoch: 6| Step: 12
Training loss: 2.640528917312622
Validation loss: 3.1663623599595923

Epoch: 6| Step: 13
Training loss: 3.29561185836792
Validation loss: 3.1603225405498216

Epoch: 10| Step: 0
Training loss: 3.175814628601074
Validation loss: 3.158017440508771

Epoch: 6| Step: 1
Training loss: 3.160576105117798
Validation loss: 3.1534572468009046

Epoch: 6| Step: 2
Training loss: 3.0877327919006348
Validation loss: 3.140535416141633

Epoch: 6| Step: 3
Training loss: 3.4998369216918945
Validation loss: 3.13647880605472

Epoch: 6| Step: 4
Training loss: 3.47849702835083
Validation loss: 3.1353150311336724

Epoch: 6| Step: 5
Training loss: 4.083189010620117
Validation loss: 3.1364969566304195

Epoch: 6| Step: 6
Training loss: 2.763699769973755
Validation loss: 3.1297415507737028

Epoch: 6| Step: 7
Training loss: 3.1895713806152344
Validation loss: 3.12432453965628

Epoch: 6| Step: 8
Training loss: 3.223386526107788
Validation loss: 3.117686197321902

Epoch: 6| Step: 9
Training loss: 2.377699851989746
Validation loss: 3.113429202828356

Epoch: 6| Step: 10
Training loss: 2.510605812072754
Validation loss: 3.107851546297791

Epoch: 6| Step: 11
Training loss: 3.5442357063293457
Validation loss: 3.1051662096413235

Epoch: 6| Step: 12
Training loss: 2.7688424587249756
Validation loss: 3.1009290551626556

Epoch: 6| Step: 13
Training loss: 3.2312052249908447
Validation loss: 3.096331411792386

Epoch: 11| Step: 0
Training loss: 2.7175698280334473
Validation loss: 3.0923610066854827

Epoch: 6| Step: 1
Training loss: 3.930598258972168
Validation loss: 3.0889718173652567

Epoch: 6| Step: 2
Training loss: 3.3052022457122803
Validation loss: 3.0883952853500203

Epoch: 6| Step: 3
Training loss: 3.246088981628418
Validation loss: 3.0820301066162767

Epoch: 6| Step: 4
Training loss: 3.562570095062256
Validation loss: 3.0763439414321736

Epoch: 6| Step: 5
Training loss: 3.1920623779296875
Validation loss: 3.073862409078947

Epoch: 6| Step: 6
Training loss: 2.5330605506896973
Validation loss: 3.0702242851257324

Epoch: 6| Step: 7
Training loss: 3.7288665771484375
Validation loss: 3.0682644587691112

Epoch: 6| Step: 8
Training loss: 2.9288368225097656
Validation loss: 3.0662533826725458

Epoch: 6| Step: 9
Training loss: 2.4423341751098633
Validation loss: 3.0583343428950154

Epoch: 6| Step: 10
Training loss: 3.10554838180542
Validation loss: 3.0592470579249884

Epoch: 6| Step: 11
Training loss: 2.98976993560791
Validation loss: 3.0525632032784085

Epoch: 6| Step: 12
Training loss: 2.678468704223633
Validation loss: 3.0537903026867936

Epoch: 6| Step: 13
Training loss: 3.250621795654297
Validation loss: 3.062546158349642

Epoch: 12| Step: 0
Training loss: 2.5673253536224365
Validation loss: 3.0429263576384513

Epoch: 6| Step: 1
Training loss: 2.974468231201172
Validation loss: 3.0363249522383495

Epoch: 6| Step: 2
Training loss: 3.254906177520752
Validation loss: 3.036738093181323

Epoch: 6| Step: 3
Training loss: 3.7301270961761475
Validation loss: 3.0372672952631468

Epoch: 6| Step: 4
Training loss: 3.3498458862304688
Validation loss: 3.0390193231644167

Epoch: 6| Step: 5
Training loss: 2.6918530464172363
Validation loss: 3.037921451753186

Epoch: 6| Step: 6
Training loss: 2.3618783950805664
Validation loss: 3.033165988101754

Epoch: 6| Step: 7
Training loss: 4.715686798095703
Validation loss: 3.0312124606101745

Epoch: 6| Step: 8
Training loss: 3.07531476020813
Validation loss: 3.021355939167802

Epoch: 6| Step: 9
Training loss: 2.455688714981079
Validation loss: 3.0152762192551807

Epoch: 6| Step: 10
Training loss: 2.6732397079467773
Validation loss: 3.010260292278823

Epoch: 6| Step: 11
Training loss: 2.95208477973938
Validation loss: 3.0089511999519925

Epoch: 6| Step: 12
Training loss: 2.8743209838867188
Validation loss: 3.008480082276047

Epoch: 6| Step: 13
Training loss: 3.829502582550049
Validation loss: 3.0045991251545567

Epoch: 13| Step: 0
Training loss: 3.945751190185547
Validation loss: 2.996417312211888

Epoch: 6| Step: 1
Training loss: 4.575533390045166
Validation loss: 2.990288493453815

Epoch: 6| Step: 2
Training loss: 2.696864366531372
Validation loss: 2.99186029741841

Epoch: 6| Step: 3
Training loss: 1.9602925777435303
Validation loss: 2.989860201394686

Epoch: 6| Step: 4
Training loss: 3.290217876434326
Validation loss: 2.9911489127784647

Epoch: 6| Step: 5
Training loss: 2.0149765014648438
Validation loss: 2.9887503065088743

Epoch: 6| Step: 6
Training loss: 2.89048433303833
Validation loss: 2.9872131014382965

Epoch: 6| Step: 7
Training loss: 2.6952030658721924
Validation loss: 2.979054630443614

Epoch: 6| Step: 8
Training loss: 2.8129754066467285
Validation loss: 2.9736625122767624

Epoch: 6| Step: 9
Training loss: 3.688795804977417
Validation loss: 2.968450738537696

Epoch: 6| Step: 10
Training loss: 2.683209180831909
Validation loss: 2.9654288266294744

Epoch: 6| Step: 11
Training loss: 3.6361899375915527
Validation loss: 2.9672628269400647

Epoch: 6| Step: 12
Training loss: 2.97521710395813
Validation loss: 2.9592575309097127

Epoch: 6| Step: 13
Training loss: 2.7420523166656494
Validation loss: 2.955273997399115

Epoch: 14| Step: 0
Training loss: 3.104883909225464
Validation loss: 2.9535017808278403

Epoch: 6| Step: 1
Training loss: 2.1455748081207275
Validation loss: 2.9548895102675243

Epoch: 6| Step: 2
Training loss: 2.9492697715759277
Validation loss: 2.9519402596258346

Epoch: 6| Step: 3
Training loss: 3.0248751640319824
Validation loss: 2.9482230883772655

Epoch: 6| Step: 4
Training loss: 3.4452357292175293
Validation loss: 2.9418074213048464

Epoch: 6| Step: 5
Training loss: 2.513014316558838
Validation loss: 2.9353535816233647

Epoch: 6| Step: 6
Training loss: 3.827414035797119
Validation loss: 2.9313106767592894

Epoch: 6| Step: 7
Training loss: 3.1376757621765137
Validation loss: 2.929421909393803

Epoch: 6| Step: 8
Training loss: 2.6814866065979004
Validation loss: 2.9265214550879692

Epoch: 6| Step: 9
Training loss: 3.2077155113220215
Validation loss: 2.9293158695261967

Epoch: 6| Step: 10
Training loss: 2.9463155269622803
Validation loss: 2.920538753591558

Epoch: 6| Step: 11
Training loss: 3.1264870166778564
Validation loss: 2.914841382734237

Epoch: 6| Step: 12
Training loss: 2.873076915740967
Validation loss: 2.9145908637713362

Epoch: 6| Step: 13
Training loss: 3.5584611892700195
Validation loss: 2.912386081551993

Epoch: 15| Step: 0
Training loss: 2.6967854499816895
Validation loss: 2.909944498410789

Epoch: 6| Step: 1
Training loss: 2.411881446838379
Validation loss: 2.909925304433351

Epoch: 6| Step: 2
Training loss: 3.434965133666992
Validation loss: 2.914561064012589

Epoch: 6| Step: 3
Training loss: 2.758136749267578
Validation loss: 2.909132029420586

Epoch: 6| Step: 4
Training loss: 2.887007236480713
Validation loss: 2.895835650864468

Epoch: 6| Step: 5
Training loss: 3.022502899169922
Validation loss: 2.897420665269257

Epoch: 6| Step: 6
Training loss: 3.5823326110839844
Validation loss: 2.890530211951143

Epoch: 6| Step: 7
Training loss: 3.622011184692383
Validation loss: 2.8868706790349816

Epoch: 6| Step: 8
Training loss: 2.640141010284424
Validation loss: 2.8823602455918507

Epoch: 6| Step: 9
Training loss: 3.111480474472046
Validation loss: 2.878884461618239

Epoch: 6| Step: 10
Training loss: 3.335639715194702
Validation loss: 2.876162862264982

Epoch: 6| Step: 11
Training loss: 2.1487019062042236
Validation loss: 2.872705659558696

Epoch: 6| Step: 12
Training loss: 2.652276039123535
Validation loss: 2.870611913742558

Epoch: 6| Step: 13
Training loss: 3.9587457180023193
Validation loss: 2.865727919404225

Epoch: 16| Step: 0
Training loss: 3.313009738922119
Validation loss: 2.8633746844466015

Epoch: 6| Step: 1
Training loss: 1.6670598983764648
Validation loss: 2.864848231756559

Epoch: 6| Step: 2
Training loss: 3.0365829467773438
Validation loss: 2.8608144201258177

Epoch: 6| Step: 3
Training loss: 3.0494332313537598
Validation loss: 2.854723556067354

Epoch: 6| Step: 4
Training loss: 2.661224603652954
Validation loss: 2.8497728045268724

Epoch: 6| Step: 5
Training loss: 3.1788580417633057
Validation loss: 2.844212729443786

Epoch: 6| Step: 6
Training loss: 3.453707695007324
Validation loss: 2.845969587244013

Epoch: 6| Step: 7
Training loss: 2.330918788909912
Validation loss: 2.8475528301731234

Epoch: 6| Step: 8
Training loss: 2.5886306762695312
Validation loss: 2.8497025992280696

Epoch: 6| Step: 9
Training loss: 3.1168456077575684
Validation loss: 2.8499180501507175

Epoch: 6| Step: 10
Training loss: 2.7957749366760254
Validation loss: 2.84329879155723

Epoch: 6| Step: 11
Training loss: 3.846633195877075
Validation loss: 2.8375797887002268

Epoch: 6| Step: 12
Training loss: 2.709561824798584
Validation loss: 2.82692878477035

Epoch: 6| Step: 13
Training loss: 4.348129749298096
Validation loss: 2.822178797055316

Epoch: 17| Step: 0
Training loss: 3.005031108856201
Validation loss: 2.8183609952208815

Epoch: 6| Step: 1
Training loss: 2.939358711242676
Validation loss: 2.813181564372073

Epoch: 6| Step: 2
Training loss: 3.164572238922119
Validation loss: 2.812968131034605

Epoch: 6| Step: 3
Training loss: 3.2488558292388916
Validation loss: 2.8124365140033025

Epoch: 6| Step: 4
Training loss: 3.0837903022766113
Validation loss: 2.802676457230763

Epoch: 6| Step: 5
Training loss: 3.064089775085449
Validation loss: 2.795392072328957

Epoch: 6| Step: 6
Training loss: 1.9957419633865356
Validation loss: 2.798610500110093

Epoch: 6| Step: 7
Training loss: 3.209815263748169
Validation loss: 2.8008885255423923

Epoch: 6| Step: 8
Training loss: 2.945434093475342
Validation loss: 2.8036002420609996

Epoch: 6| Step: 9
Training loss: 3.4675235748291016
Validation loss: 2.819214005624094

Epoch: 6| Step: 10
Training loss: 3.077073812484741
Validation loss: 2.7933312795495473

Epoch: 6| Step: 11
Training loss: 2.7062010765075684
Validation loss: 2.781696040143249

Epoch: 6| Step: 12
Training loss: 2.5537712574005127
Validation loss: 2.7806928183442805

Epoch: 6| Step: 13
Training loss: 2.3438470363616943
Validation loss: 2.7799416767653597

Epoch: 18| Step: 0
Training loss: 2.519033193588257
Validation loss: 2.8089470337795954

Epoch: 6| Step: 1
Training loss: 3.5807344913482666
Validation loss: 2.785985541600053

Epoch: 6| Step: 2
Training loss: 3.6439056396484375
Validation loss: 2.773839881343226

Epoch: 6| Step: 3
Training loss: 2.8465795516967773
Validation loss: 2.777654552972445

Epoch: 6| Step: 4
Training loss: 2.3829808235168457
Validation loss: 2.781555529563658

Epoch: 6| Step: 5
Training loss: 2.7276039123535156
Validation loss: 2.800180865872291

Epoch: 6| Step: 6
Training loss: 3.0597503185272217
Validation loss: 2.7933017797367548

Epoch: 6| Step: 7
Training loss: 2.805819511413574
Validation loss: 2.784959649526945

Epoch: 6| Step: 8
Training loss: 2.694330930709839
Validation loss: 2.778794821872506

Epoch: 6| Step: 9
Training loss: 2.8991141319274902
Validation loss: 2.7715287875103694

Epoch: 6| Step: 10
Training loss: 2.991267681121826
Validation loss: 2.7655830434573594

Epoch: 6| Step: 11
Training loss: 3.0876896381378174
Validation loss: 2.7598720289045766

Epoch: 6| Step: 12
Training loss: 2.5454933643341064
Validation loss: 2.7562236119342107

Epoch: 6| Step: 13
Training loss: 3.111017942428589
Validation loss: 2.750397087425314

Epoch: 19| Step: 0
Training loss: 2.707676410675049
Validation loss: 2.749428641411566

Epoch: 6| Step: 1
Training loss: 3.1815452575683594
Validation loss: 2.7408074768640662

Epoch: 6| Step: 2
Training loss: 3.29264497756958
Validation loss: 2.7370894211594776

Epoch: 6| Step: 3
Training loss: 3.466818332672119
Validation loss: 2.7365030832188104

Epoch: 6| Step: 4
Training loss: 2.7004666328430176
Validation loss: 2.7288239079137004

Epoch: 6| Step: 5
Training loss: 1.799889326095581
Validation loss: 2.729922689417357

Epoch: 6| Step: 6
Training loss: 2.4424004554748535
Validation loss: 2.733550217843825

Epoch: 6| Step: 7
Training loss: 3.242550849914551
Validation loss: 2.72324768189461

Epoch: 6| Step: 8
Training loss: 2.7006542682647705
Validation loss: 2.7223246610292824

Epoch: 6| Step: 9
Training loss: 3.193295478820801
Validation loss: 2.7265440546056277

Epoch: 6| Step: 10
Training loss: 2.878051996231079
Validation loss: 2.7302935354171263

Epoch: 6| Step: 11
Training loss: 2.979872465133667
Validation loss: 2.7377523940096617

Epoch: 6| Step: 12
Training loss: 3.1886255741119385
Validation loss: 2.740020787844094

Epoch: 6| Step: 13
Training loss: 2.4640820026397705
Validation loss: 2.7325388154675885

Epoch: 20| Step: 0
Training loss: 2.617036819458008
Validation loss: 2.7179396485769622

Epoch: 6| Step: 1
Training loss: 3.0465354919433594
Validation loss: 2.7100773908758677

Epoch: 6| Step: 2
Training loss: 2.1386423110961914
Validation loss: 2.7077929691601823

Epoch: 6| Step: 3
Training loss: 3.251569986343384
Validation loss: 2.7036725680033364

Epoch: 6| Step: 4
Training loss: 2.4713988304138184
Validation loss: 2.7010347817533757

Epoch: 6| Step: 5
Training loss: 2.3765039443969727
Validation loss: 2.698265296156688

Epoch: 6| Step: 6
Training loss: 3.024883270263672
Validation loss: 2.7038620671918316

Epoch: 6| Step: 7
Training loss: 3.398378610610962
Validation loss: 2.700906535630585

Epoch: 6| Step: 8
Training loss: 2.7755980491638184
Validation loss: 2.698830771189864

Epoch: 6| Step: 9
Training loss: 2.703850269317627
Validation loss: 2.6930832503944315

Epoch: 6| Step: 10
Training loss: 3.0947327613830566
Validation loss: 2.686714779946112

Epoch: 6| Step: 11
Training loss: 3.0018067359924316
Validation loss: 2.7134864714837845

Epoch: 6| Step: 12
Training loss: 2.6463327407836914
Validation loss: 2.70553905476806

Epoch: 6| Step: 13
Training loss: 4.159433364868164
Validation loss: 2.7022285717789845

Epoch: 21| Step: 0
Training loss: 3.2285661697387695
Validation loss: 2.671690410183322

Epoch: 6| Step: 1
Training loss: 2.165736198425293
Validation loss: 2.686524009191862

Epoch: 6| Step: 2
Training loss: 2.267521858215332
Validation loss: 2.710828504254741

Epoch: 6| Step: 3
Training loss: 2.7245049476623535
Validation loss: 2.6972265371712307

Epoch: 6| Step: 4
Training loss: 2.5751593112945557
Validation loss: 2.698686038294146

Epoch: 6| Step: 5
Training loss: 2.792177200317383
Validation loss: 2.6934066434060373

Epoch: 6| Step: 6
Training loss: 3.2617077827453613
Validation loss: 2.68960912253267

Epoch: 6| Step: 7
Training loss: 3.017421245574951
Validation loss: 2.689077061991538

Epoch: 6| Step: 8
Training loss: 2.726808547973633
Validation loss: 2.684725074357884

Epoch: 6| Step: 9
Training loss: 3.1675267219543457
Validation loss: 2.687203771324568

Epoch: 6| Step: 10
Training loss: 3.0773236751556396
Validation loss: 2.6861191923900316

Epoch: 6| Step: 11
Training loss: 3.2285711765289307
Validation loss: 2.683829358828965

Epoch: 6| Step: 12
Training loss: 2.492056369781494
Validation loss: 2.682110701837847

Epoch: 6| Step: 13
Training loss: 3.70885968208313
Validation loss: 2.6769765525735836

Epoch: 22| Step: 0
Training loss: 2.780754566192627
Validation loss: 2.6671522278939523

Epoch: 6| Step: 1
Training loss: 2.1984012126922607
Validation loss: 2.664181714416832

Epoch: 6| Step: 2
Training loss: 2.997664451599121
Validation loss: 2.6628941541076987

Epoch: 6| Step: 3
Training loss: 2.3927013874053955
Validation loss: 2.65958212524332

Epoch: 6| Step: 4
Training loss: 2.6673293113708496
Validation loss: 2.656989179631715

Epoch: 6| Step: 5
Training loss: 3.642132043838501
Validation loss: 2.654516350838446

Epoch: 6| Step: 6
Training loss: 2.692441701889038
Validation loss: 2.653153242603425

Epoch: 6| Step: 7
Training loss: 2.748868942260742
Validation loss: 2.6574656424983853

Epoch: 6| Step: 8
Training loss: 3.9257943630218506
Validation loss: 2.661271031184863

Epoch: 6| Step: 9
Training loss: 3.1438050270080566
Validation loss: 2.657619727555142

Epoch: 6| Step: 10
Training loss: 2.263362169265747
Validation loss: 2.6359465840042278

Epoch: 6| Step: 11
Training loss: 3.383579730987549
Validation loss: 2.639501661382696

Epoch: 6| Step: 12
Training loss: 1.9504287242889404
Validation loss: 2.6440773369163595

Epoch: 6| Step: 13
Training loss: 2.9493069648742676
Validation loss: 2.651446919287405

Epoch: 23| Step: 0
Training loss: 3.165855884552002
Validation loss: 2.6541385676271174

Epoch: 6| Step: 1
Training loss: 2.0741374492645264
Validation loss: 2.6436347653788905

Epoch: 6| Step: 2
Training loss: 3.1326000690460205
Validation loss: 2.65743653492261

Epoch: 6| Step: 3
Training loss: 3.5898854732513428
Validation loss: 2.658945611728135

Epoch: 6| Step: 4
Training loss: 3.0306315422058105
Validation loss: 2.6317588244715044

Epoch: 6| Step: 5
Training loss: 2.5902156829833984
Validation loss: 2.6342750672371156

Epoch: 6| Step: 6
Training loss: 2.330578327178955
Validation loss: 2.6700536640741492

Epoch: 6| Step: 7
Training loss: 2.641223907470703
Validation loss: 2.6637884032341743

Epoch: 6| Step: 8
Training loss: 3.697561740875244
Validation loss: 2.6266977069198445

Epoch: 6| Step: 9
Training loss: 3.0328922271728516
Validation loss: 2.624928543644567

Epoch: 6| Step: 10
Training loss: 2.3487908840179443
Validation loss: 2.633494923191686

Epoch: 6| Step: 11
Training loss: 2.9080517292022705
Validation loss: 2.649611847375029

Epoch: 6| Step: 12
Training loss: 2.181450128555298
Validation loss: 2.6496722159847135

Epoch: 6| Step: 13
Training loss: 2.8988020420074463
Validation loss: 2.6549638599477787

Epoch: 24| Step: 0
Training loss: 3.0026636123657227
Validation loss: 2.654784947313288

Epoch: 6| Step: 1
Training loss: 2.977527141571045
Validation loss: 2.649359236481369

Epoch: 6| Step: 2
Training loss: 2.4923672676086426
Validation loss: 2.6409220849314043

Epoch: 6| Step: 3
Training loss: 3.5967159271240234
Validation loss: 2.6363119668858026

Epoch: 6| Step: 4
Training loss: 2.49576473236084
Validation loss: 2.634675920650523

Epoch: 6| Step: 5
Training loss: 2.9316747188568115
Validation loss: 2.626373121815343

Epoch: 6| Step: 6
Training loss: 3.543954372406006
Validation loss: 2.6211532546627905

Epoch: 6| Step: 7
Training loss: 2.8395187854766846
Validation loss: 2.6222950540563112

Epoch: 6| Step: 8
Training loss: 3.35300874710083
Validation loss: 2.615117283277614

Epoch: 6| Step: 9
Training loss: 2.200944185256958
Validation loss: 2.6194569449270926

Epoch: 6| Step: 10
Training loss: 2.315798282623291
Validation loss: 2.6072632625538814

Epoch: 6| Step: 11
Training loss: 2.660076141357422
Validation loss: 2.6010747776236585

Epoch: 6| Step: 12
Training loss: 2.558434009552002
Validation loss: 2.5942548808231147

Epoch: 6| Step: 13
Training loss: 2.155637502670288
Validation loss: 2.5951290284433672

Epoch: 25| Step: 0
Training loss: 2.976719856262207
Validation loss: 2.5870482203780965

Epoch: 6| Step: 1
Training loss: 2.764944314956665
Validation loss: 2.584412233803862

Epoch: 6| Step: 2
Training loss: 2.397000312805176
Validation loss: 2.5805555030863774

Epoch: 6| Step: 3
Training loss: 2.6179404258728027
Validation loss: 2.581157494616765

Epoch: 6| Step: 4
Training loss: 3.3257694244384766
Validation loss: 2.5832526042897213

Epoch: 6| Step: 5
Training loss: 2.955507516860962
Validation loss: 2.630853401717319

Epoch: 6| Step: 6
Training loss: 2.913332939147949
Validation loss: 2.7134094135735625

Epoch: 6| Step: 7
Training loss: 2.5874147415161133
Validation loss: 2.6553409894307456

Epoch: 6| Step: 8
Training loss: 2.093937635421753
Validation loss: 2.5851403820899224

Epoch: 6| Step: 9
Training loss: 2.97991681098938
Validation loss: 2.581918062702302

Epoch: 6| Step: 10
Training loss: 2.9097414016723633
Validation loss: 2.613341749355357

Epoch: 6| Step: 11
Training loss: 3.567734956741333
Validation loss: 2.6283740279495076

Epoch: 6| Step: 12
Training loss: 2.572579860687256
Validation loss: 2.632574506985244

Epoch: 6| Step: 13
Training loss: 2.3569517135620117
Validation loss: 2.6143589199230237

Epoch: 26| Step: 0
Training loss: 2.701796531677246
Validation loss: 2.5797092171125513

Epoch: 6| Step: 1
Training loss: 3.42195463180542
Validation loss: 2.5676891521740983

Epoch: 6| Step: 2
Training loss: 2.94960618019104
Validation loss: 2.564288672580514

Epoch: 6| Step: 3
Training loss: 3.2530603408813477
Validation loss: 2.58011535931659

Epoch: 6| Step: 4
Training loss: 3.191561222076416
Validation loss: 2.615309141015494

Epoch: 6| Step: 5
Training loss: 2.9367432594299316
Validation loss: 2.5972186109071136

Epoch: 6| Step: 6
Training loss: 2.8398170471191406
Validation loss: 2.6295428173516386

Epoch: 6| Step: 7
Training loss: 2.2406539916992188
Validation loss: 2.6009121633345083

Epoch: 6| Step: 8
Training loss: 2.741424322128296
Validation loss: 2.606489812174151

Epoch: 6| Step: 9
Training loss: 2.3596606254577637
Validation loss: 2.631893798869143

Epoch: 6| Step: 10
Training loss: 3.0813405513763428
Validation loss: 2.5678291577164845

Epoch: 6| Step: 11
Training loss: 2.0052075386047363
Validation loss: 2.5490344288528606

Epoch: 6| Step: 12
Training loss: 2.430791139602661
Validation loss: 2.5486176539492864

Epoch: 6| Step: 13
Training loss: 2.767688512802124
Validation loss: 2.5527963407578005

Epoch: 27| Step: 0
Training loss: 3.19378662109375
Validation loss: 2.557974869205106

Epoch: 6| Step: 1
Training loss: 3.059737205505371
Validation loss: 2.5598730348771617

Epoch: 6| Step: 2
Training loss: 2.6662979125976562
Validation loss: 2.5733247495466665

Epoch: 6| Step: 3
Training loss: 2.702988386154175
Validation loss: 2.5815430994956725

Epoch: 6| Step: 4
Training loss: 3.1396119594573975
Validation loss: 2.586463387294482

Epoch: 6| Step: 5
Training loss: 2.5920753479003906
Validation loss: 2.612796983411235

Epoch: 6| Step: 6
Training loss: 2.3172454833984375
Validation loss: 2.5698179967941774

Epoch: 6| Step: 7
Training loss: 2.7608096599578857
Validation loss: 2.541174178482384

Epoch: 6| Step: 8
Training loss: 3.3451132774353027
Validation loss: 2.5353461593709965

Epoch: 6| Step: 9
Training loss: 3.0189647674560547
Validation loss: 2.534093374847084

Epoch: 6| Step: 10
Training loss: 1.9133789539337158
Validation loss: 2.5396870848953084

Epoch: 6| Step: 11
Training loss: 2.253732204437256
Validation loss: 2.5438881330592658

Epoch: 6| Step: 12
Training loss: 2.963094472885132
Validation loss: 2.5462583752088648

Epoch: 6| Step: 13
Training loss: 2.4919774532318115
Validation loss: 2.5453208954103532

Epoch: 28| Step: 0
Training loss: 3.3465185165405273
Validation loss: 2.5433793375569005

Epoch: 6| Step: 1
Training loss: 3.1984779834747314
Validation loss: 2.543878775770946

Epoch: 6| Step: 2
Training loss: 1.982102870941162
Validation loss: 2.534232585660873

Epoch: 6| Step: 3
Training loss: 2.5201945304870605
Validation loss: 2.53363198618735

Epoch: 6| Step: 4
Training loss: 2.4748542308807373
Validation loss: 2.5332239135619132

Epoch: 6| Step: 5
Training loss: 1.9762693643569946
Validation loss: 2.5395067020129134

Epoch: 6| Step: 6
Training loss: 3.2255351543426514
Validation loss: 2.5395088093255156

Epoch: 6| Step: 7
Training loss: 2.923191785812378
Validation loss: 2.536602198436696

Epoch: 6| Step: 8
Training loss: 2.3717451095581055
Validation loss: 2.5376225107459613

Epoch: 6| Step: 9
Training loss: 2.1502623558044434
Validation loss: 2.5285422032879246

Epoch: 6| Step: 10
Training loss: 3.162353515625
Validation loss: 2.5286776070953696

Epoch: 6| Step: 11
Training loss: 3.5807948112487793
Validation loss: 2.532714233603529

Epoch: 6| Step: 12
Training loss: 3.2698540687561035
Validation loss: 2.5332246647086194

Epoch: 6| Step: 13
Training loss: 1.842214584350586
Validation loss: 2.526980274467058

Epoch: 29| Step: 0
Training loss: 3.224940299987793
Validation loss: 2.523020185450072

Epoch: 6| Step: 1
Training loss: 2.827220916748047
Validation loss: 2.51974997469174

Epoch: 6| Step: 2
Training loss: 2.873196840286255
Validation loss: 2.528082823240629

Epoch: 6| Step: 3
Training loss: 2.338992118835449
Validation loss: 2.5422880495748212

Epoch: 6| Step: 4
Training loss: 2.609926700592041
Validation loss: 2.5385796434135846

Epoch: 6| Step: 5
Training loss: 2.3191943168640137
Validation loss: 2.516049390198082

Epoch: 6| Step: 6
Training loss: 2.3861594200134277
Validation loss: 2.5175211609050794

Epoch: 6| Step: 7
Training loss: 2.427323341369629
Validation loss: 2.5218658652356876

Epoch: 6| Step: 8
Training loss: 2.9798526763916016
Validation loss: 2.524869398404193

Epoch: 6| Step: 9
Training loss: 2.3534743785858154
Validation loss: 2.5255424489257154

Epoch: 6| Step: 10
Training loss: 2.550887107849121
Validation loss: 2.5135354329180974

Epoch: 6| Step: 11
Training loss: 2.909533739089966
Validation loss: 2.5146212577819824

Epoch: 6| Step: 12
Training loss: 3.176342487335205
Validation loss: 2.5044073135622087

Epoch: 6| Step: 13
Training loss: 3.761756420135498
Validation loss: 2.5160872038974555

Epoch: 30| Step: 0
Training loss: 2.3131957054138184
Validation loss: 2.5197001605905514

Epoch: 6| Step: 1
Training loss: 3.0708303451538086
Validation loss: 2.51777603549342

Epoch: 6| Step: 2
Training loss: 3.2543375492095947
Validation loss: 2.530406798085859

Epoch: 6| Step: 3
Training loss: 2.456361770629883
Validation loss: 2.5221152408148653

Epoch: 6| Step: 4
Training loss: 3.5942940711975098
Validation loss: 2.51690008050652

Epoch: 6| Step: 5
Training loss: 2.854950428009033
Validation loss: 2.5070471045791463

Epoch: 6| Step: 6
Training loss: 2.0198042392730713
Validation loss: 2.5066811525693504

Epoch: 6| Step: 7
Training loss: 2.7210936546325684
Validation loss: 2.508222287701022

Epoch: 6| Step: 8
Training loss: 3.086270332336426
Validation loss: 2.5208445646429576

Epoch: 6| Step: 9
Training loss: 2.3680403232574463
Validation loss: 2.5113940802953576

Epoch: 6| Step: 10
Training loss: 3.0378494262695312
Validation loss: 2.5500895028473227

Epoch: 6| Step: 11
Training loss: 2.6533679962158203
Validation loss: 2.532920704093031

Epoch: 6| Step: 12
Training loss: 2.0091264247894287
Validation loss: 2.517344544010778

Epoch: 6| Step: 13
Training loss: 2.7072503566741943
Validation loss: 2.5031033869712584

Epoch: 31| Step: 0
Training loss: 3.2082834243774414
Validation loss: 2.501915362573439

Epoch: 6| Step: 1
Training loss: 2.4791321754455566
Validation loss: 2.4995118289865474

Epoch: 6| Step: 2
Training loss: 2.6709465980529785
Validation loss: 2.501922797131282

Epoch: 6| Step: 3
Training loss: 3.019435405731201
Validation loss: 2.5008359532202444

Epoch: 6| Step: 4
Training loss: 2.7459895610809326
Validation loss: 2.5127091741049163

Epoch: 6| Step: 5
Training loss: 2.3558950424194336
Validation loss: 2.5122101588915755

Epoch: 6| Step: 6
Training loss: 2.468266010284424
Validation loss: 2.5299275639236614

Epoch: 6| Step: 7
Training loss: 2.8994998931884766
Validation loss: 2.533517873415383

Epoch: 6| Step: 8
Training loss: 2.9975547790527344
Validation loss: 2.528736683630174

Epoch: 6| Step: 9
Training loss: 2.0662777423858643
Validation loss: 2.50346899929867

Epoch: 6| Step: 10
Training loss: 2.69002628326416
Validation loss: 2.4991384654916744

Epoch: 6| Step: 11
Training loss: 3.571350574493408
Validation loss: 2.5016874164663334

Epoch: 6| Step: 12
Training loss: 1.8332395553588867
Validation loss: 2.510400113239083

Epoch: 6| Step: 13
Training loss: 3.404452085494995
Validation loss: 2.511683597359606

Epoch: 32| Step: 0
Training loss: 2.5059783458709717
Validation loss: 2.511126074739682

Epoch: 6| Step: 1
Training loss: 2.7838521003723145
Validation loss: 2.507437934157669

Epoch: 6| Step: 2
Training loss: 3.1963093280792236
Validation loss: 2.5067968060893397

Epoch: 6| Step: 3
Training loss: 3.0246963500976562
Validation loss: 2.507640936041391

Epoch: 6| Step: 4
Training loss: 2.5807652473449707
Validation loss: 2.49945253966957

Epoch: 6| Step: 5
Training loss: 2.522730827331543
Validation loss: 2.4971792902997745

Epoch: 6| Step: 6
Training loss: 3.4820778369903564
Validation loss: 2.4913864879197973

Epoch: 6| Step: 7
Training loss: 2.5494563579559326
Validation loss: 2.482990167474234

Epoch: 6| Step: 8
Training loss: 2.337045192718506
Validation loss: 2.4803872403278144

Epoch: 6| Step: 9
Training loss: 2.785287857055664
Validation loss: 2.482085725312592

Epoch: 6| Step: 10
Training loss: 2.9537363052368164
Validation loss: 2.479693588390145

Epoch: 6| Step: 11
Training loss: 2.1062817573547363
Validation loss: 2.4860591529518046

Epoch: 6| Step: 12
Training loss: 2.7867321968078613
Validation loss: 2.5047324934313373

Epoch: 6| Step: 13
Training loss: 2.0263547897338867
Validation loss: 2.5051378062976304

Epoch: 33| Step: 0
Training loss: 2.991363048553467
Validation loss: 2.4963105699067474

Epoch: 6| Step: 1
Training loss: 2.4473154544830322
Validation loss: 2.4843737438160884

Epoch: 6| Step: 2
Training loss: 2.8809566497802734
Validation loss: 2.4911977450052896

Epoch: 6| Step: 3
Training loss: 3.28216552734375
Validation loss: 2.4929872969145417

Epoch: 6| Step: 4
Training loss: 2.9272336959838867
Validation loss: 2.4917224376432356

Epoch: 6| Step: 5
Training loss: 2.2596309185028076
Validation loss: 2.4899209673686693

Epoch: 6| Step: 6
Training loss: 2.63198184967041
Validation loss: 2.488196990823233

Epoch: 6| Step: 7
Training loss: 3.4467358589172363
Validation loss: 2.5017908696205384

Epoch: 6| Step: 8
Training loss: 2.2111964225769043
Validation loss: 2.5095209024285756

Epoch: 6| Step: 9
Training loss: 2.8061606884002686
Validation loss: 2.5027752460971957

Epoch: 6| Step: 10
Training loss: 1.8693326711654663
Validation loss: 2.5065818781493814

Epoch: 6| Step: 11
Training loss: 2.989025354385376
Validation loss: 2.500166787896105

Epoch: 6| Step: 12
Training loss: 2.7565441131591797
Validation loss: 2.492573594534269

Epoch: 6| Step: 13
Training loss: 2.3792309761047363
Validation loss: 2.486873798472907

Epoch: 34| Step: 0
Training loss: 2.544508934020996
Validation loss: 2.4850608148882465

Epoch: 6| Step: 1
Training loss: 2.775045871734619
Validation loss: 2.485342574375932

Epoch: 6| Step: 2
Training loss: 3.4540953636169434
Validation loss: 2.479984991012081

Epoch: 6| Step: 3
Training loss: 2.5504355430603027
Validation loss: 2.480381247817829

Epoch: 6| Step: 4
Training loss: 3.4364542961120605
Validation loss: 2.485988332379249

Epoch: 6| Step: 5
Training loss: 1.6167277097702026
Validation loss: 2.4943698811274704

Epoch: 6| Step: 6
Training loss: 3.0390195846557617
Validation loss: 2.4916925737934728

Epoch: 6| Step: 7
Training loss: 2.9903101921081543
Validation loss: 2.4845985033178843

Epoch: 6| Step: 8
Training loss: 2.541881561279297
Validation loss: 2.471497284468784

Epoch: 6| Step: 9
Training loss: 2.189232110977173
Validation loss: 2.4694034540525047

Epoch: 6| Step: 10
Training loss: 2.427323579788208
Validation loss: 2.465532746366275

Epoch: 6| Step: 11
Training loss: 2.80374813079834
Validation loss: 2.4706454277038574

Epoch: 6| Step: 12
Training loss: 2.82517671585083
Validation loss: 2.4682323650647233

Epoch: 6| Step: 13
Training loss: 2.526027202606201
Validation loss: 2.469462989478983

Epoch: 35| Step: 0
Training loss: 2.2955322265625
Validation loss: 2.467466923498338

Epoch: 6| Step: 1
Training loss: 2.6056394577026367
Validation loss: 2.4659156837771015

Epoch: 6| Step: 2
Training loss: 2.345346450805664
Validation loss: 2.467527074198569

Epoch: 6| Step: 3
Training loss: 2.83086895942688
Validation loss: 2.4654711549000075

Epoch: 6| Step: 4
Training loss: 3.3948466777801514
Validation loss: 2.461363446327948

Epoch: 6| Step: 5
Training loss: 3.571596145629883
Validation loss: 2.460275847424743

Epoch: 6| Step: 6
Training loss: 3.375917673110962
Validation loss: 2.4684820764808246

Epoch: 6| Step: 7
Training loss: 2.45585298538208
Validation loss: 2.478139995246805

Epoch: 6| Step: 8
Training loss: 2.6255528926849365
Validation loss: 2.4807725209061817

Epoch: 6| Step: 9
Training loss: 2.561005115509033
Validation loss: 2.490917859538909

Epoch: 6| Step: 10
Training loss: 1.914759874343872
Validation loss: 2.490409699819421

Epoch: 6| Step: 11
Training loss: 1.9653605222702026
Validation loss: 2.4812495887920423

Epoch: 6| Step: 12
Training loss: 3.070158004760742
Validation loss: 2.461022828214912

Epoch: 6| Step: 13
Training loss: 2.6517210006713867
Validation loss: 2.4591886740858837

Epoch: 36| Step: 0
Training loss: 2.563323974609375
Validation loss: 2.4572576656136462

Epoch: 6| Step: 1
Training loss: 3.328042984008789
Validation loss: 2.4598610452426377

Epoch: 6| Step: 2
Training loss: 2.608642101287842
Validation loss: 2.458383952417681

Epoch: 6| Step: 3
Training loss: 2.595292568206787
Validation loss: 2.459284290190666

Epoch: 6| Step: 4
Training loss: 2.8381457328796387
Validation loss: 2.4622882617417203

Epoch: 6| Step: 5
Training loss: 2.0604476928710938
Validation loss: 2.463994731185257

Epoch: 6| Step: 6
Training loss: 2.713567018508911
Validation loss: 2.469223996644379

Epoch: 6| Step: 7
Training loss: 2.6463370323181152
Validation loss: 2.486538282004736

Epoch: 6| Step: 8
Training loss: 2.7798807621002197
Validation loss: 2.484134384380874

Epoch: 6| Step: 9
Training loss: 2.6397812366485596
Validation loss: 2.4916064508499636

Epoch: 6| Step: 10
Training loss: 2.5031588077545166
Validation loss: 2.527104236746347

Epoch: 6| Step: 11
Training loss: 3.1711668968200684
Validation loss: 2.543017630935997

Epoch: 6| Step: 12
Training loss: 2.7010738849639893
Validation loss: 2.5441756222837713

Epoch: 6| Step: 13
Training loss: 2.68624210357666
Validation loss: 2.481301630696943

Epoch: 37| Step: 0
Training loss: 3.0757522583007812
Validation loss: 2.4647185956278155

Epoch: 6| Step: 1
Training loss: 2.1499667167663574
Validation loss: 2.4753359979198826

Epoch: 6| Step: 2
Training loss: 3.057741165161133
Validation loss: 2.493987109071465

Epoch: 6| Step: 3
Training loss: 2.8604984283447266
Validation loss: 2.521045443832233

Epoch: 6| Step: 4
Training loss: 2.8513238430023193
Validation loss: 2.525304348238053

Epoch: 6| Step: 5
Training loss: 2.9018993377685547
Validation loss: 2.5026404652544247

Epoch: 6| Step: 6
Training loss: 2.5207600593566895
Validation loss: 2.478741035666517

Epoch: 6| Step: 7
Training loss: 2.9528675079345703
Validation loss: 2.4558863768013577

Epoch: 6| Step: 8
Training loss: 2.7061514854431152
Validation loss: 2.452537839130689

Epoch: 6| Step: 9
Training loss: 1.8844670057296753
Validation loss: 2.4685428732184955

Epoch: 6| Step: 10
Training loss: 3.01224422454834
Validation loss: 2.5107174893861175

Epoch: 6| Step: 11
Training loss: 1.821392297744751
Validation loss: 2.567586721912507

Epoch: 6| Step: 12
Training loss: 3.101529121398926
Validation loss: 2.5561634955867643

Epoch: 6| Step: 13
Training loss: 3.577850341796875
Validation loss: 2.5290359015105874

Epoch: 38| Step: 0
Training loss: 3.3713550567626953
Validation loss: 2.4725716421681065

Epoch: 6| Step: 1
Training loss: 2.2963993549346924
Validation loss: 2.452614471476565

Epoch: 6| Step: 2
Training loss: 2.3619797229766846
Validation loss: 2.4498484775584233

Epoch: 6| Step: 3
Training loss: 2.064143657684326
Validation loss: 2.4528100285478818

Epoch: 6| Step: 4
Training loss: 3.4604623317718506
Validation loss: 2.452920722705062

Epoch: 6| Step: 5
Training loss: 2.2143712043762207
Validation loss: 2.463421347320721

Epoch: 6| Step: 6
Training loss: 2.8654472827911377
Validation loss: 2.4574619159903577

Epoch: 6| Step: 7
Training loss: 3.484768867492676
Validation loss: 2.459734912841551

Epoch: 6| Step: 8
Training loss: 2.757030725479126
Validation loss: 2.458166850510464

Epoch: 6| Step: 9
Training loss: 3.4900848865509033
Validation loss: 2.460077303712086

Epoch: 6| Step: 10
Training loss: 2.9429450035095215
Validation loss: 2.4534025294806368

Epoch: 6| Step: 11
Training loss: 1.8966612815856934
Validation loss: 2.456111127330411

Epoch: 6| Step: 12
Training loss: 2.2883105278015137
Validation loss: 2.4517634504584858

Epoch: 6| Step: 13
Training loss: 1.8260332345962524
Validation loss: 2.4527711355558006

Epoch: 39| Step: 0
Training loss: 2.8142480850219727
Validation loss: 2.4638840921463503

Epoch: 6| Step: 1
Training loss: 2.6358582973480225
Validation loss: 2.470505460616081

Epoch: 6| Step: 2
Training loss: 2.5326273441314697
Validation loss: 2.486299491697742

Epoch: 6| Step: 3
Training loss: 2.134873151779175
Validation loss: 2.4973132635957453

Epoch: 6| Step: 4
Training loss: 2.7630362510681152
Validation loss: 2.489971204470563

Epoch: 6| Step: 5
Training loss: 2.9879417419433594
Validation loss: 2.4775194865401073

Epoch: 6| Step: 6
Training loss: 2.491292953491211
Validation loss: 2.4692810837940504

Epoch: 6| Step: 7
Training loss: 2.699816942214966
Validation loss: 2.4582725135228967

Epoch: 6| Step: 8
Training loss: 2.418600559234619
Validation loss: 2.4531798183277087

Epoch: 6| Step: 9
Training loss: 2.5387492179870605
Validation loss: 2.442060657726821

Epoch: 6| Step: 10
Training loss: 3.2727444171905518
Validation loss: 2.4439796478517595

Epoch: 6| Step: 11
Training loss: 1.9824111461639404
Validation loss: 2.4423932747174333

Epoch: 6| Step: 12
Training loss: 3.110044002532959
Validation loss: 2.447812493129443

Epoch: 6| Step: 13
Training loss: 3.6057679653167725
Validation loss: 2.448987217359645

Epoch: 40| Step: 0
Training loss: 3.0726723670959473
Validation loss: 2.445579146826139

Epoch: 6| Step: 1
Training loss: 1.9471209049224854
Validation loss: 2.4469384301093315

Epoch: 6| Step: 2
Training loss: 2.29575514793396
Validation loss: 2.4432261477234545

Epoch: 6| Step: 3
Training loss: 2.550330877304077
Validation loss: 2.4454533105255454

Epoch: 6| Step: 4
Training loss: 2.320547342300415
Validation loss: 2.4535541047332106

Epoch: 6| Step: 5
Training loss: 2.743936538696289
Validation loss: 2.4501376946767173

Epoch: 6| Step: 6
Training loss: 3.0390524864196777
Validation loss: 2.4568153709493656

Epoch: 6| Step: 7
Training loss: 3.061953544616699
Validation loss: 2.4571950435638428

Epoch: 6| Step: 8
Training loss: 2.621532917022705
Validation loss: 2.463674806779431

Epoch: 6| Step: 9
Training loss: 3.0280556678771973
Validation loss: 2.46465911147415

Epoch: 6| Step: 10
Training loss: 2.343228340148926
Validation loss: 2.4560467555958736

Epoch: 6| Step: 11
Training loss: 2.9760165214538574
Validation loss: 2.4512556111940773

Epoch: 6| Step: 12
Training loss: 2.9246649742126465
Validation loss: 2.4513112011776177

Epoch: 6| Step: 13
Training loss: 2.4173896312713623
Validation loss: 2.4395945072174072

Epoch: 41| Step: 0
Training loss: 2.479722738265991
Validation loss: 2.4416467348734536

Epoch: 6| Step: 1
Training loss: 2.007108688354492
Validation loss: 2.434959186020718

Epoch: 6| Step: 2
Training loss: 2.4726455211639404
Validation loss: 2.4407486428496656

Epoch: 6| Step: 3
Training loss: 2.774590015411377
Validation loss: 2.4376273642304125

Epoch: 6| Step: 4
Training loss: 3.0728766918182373
Validation loss: 2.4606857171622654

Epoch: 6| Step: 5
Training loss: 2.76897931098938
Validation loss: 2.4556211143411617

Epoch: 6| Step: 6
Training loss: 3.503969430923462
Validation loss: 2.446877110388971

Epoch: 6| Step: 7
Training loss: 2.783690929412842
Validation loss: 2.433574976459626

Epoch: 6| Step: 8
Training loss: 2.118096351623535
Validation loss: 2.4366754844624507

Epoch: 6| Step: 9
Training loss: 3.1188831329345703
Validation loss: 2.4270849689360587

Epoch: 6| Step: 10
Training loss: 2.7693228721618652
Validation loss: 2.4223216400351575

Epoch: 6| Step: 11
Training loss: 2.2660117149353027
Validation loss: 2.421650622480659

Epoch: 6| Step: 12
Training loss: 2.3107035160064697
Validation loss: 2.417577564075429

Epoch: 6| Step: 13
Training loss: 3.1661601066589355
Validation loss: 2.42950782468242

Epoch: 42| Step: 0
Training loss: 2.9663305282592773
Validation loss: 2.4180077686104724

Epoch: 6| Step: 1
Training loss: 2.705031633377075
Validation loss: 2.42471601886134

Epoch: 6| Step: 2
Training loss: 2.511960983276367
Validation loss: 2.4162042192233506

Epoch: 6| Step: 3
Training loss: 2.5059008598327637
Validation loss: 2.4204367745307183

Epoch: 6| Step: 4
Training loss: 3.4057602882385254
Validation loss: 2.4195479910860778

Epoch: 6| Step: 5
Training loss: 2.4977731704711914
Validation loss: 2.4335713796718146

Epoch: 6| Step: 6
Training loss: 2.135615587234497
Validation loss: 2.438761152246947

Epoch: 6| Step: 7
Training loss: 2.4985249042510986
Validation loss: 2.446042888907976

Epoch: 6| Step: 8
Training loss: 2.5013437271118164
Validation loss: 2.460629577277809

Epoch: 6| Step: 9
Training loss: 2.4006035327911377
Validation loss: 2.470669005506782

Epoch: 6| Step: 10
Training loss: 2.405531644821167
Validation loss: 2.458353275893837

Epoch: 6| Step: 11
Training loss: 2.934778928756714
Validation loss: 2.4382171656495784

Epoch: 6| Step: 12
Training loss: 2.561237335205078
Validation loss: 2.431394338607788

Epoch: 6| Step: 13
Training loss: 3.6662118434906006
Validation loss: 2.426066690875638

Epoch: 43| Step: 0
Training loss: 1.3114641904830933
Validation loss: 2.4199137098045758

Epoch: 6| Step: 1
Training loss: 2.615083694458008
Validation loss: 2.418393244025528

Epoch: 6| Step: 2
Training loss: 2.8058977127075195
Validation loss: 2.420916744457778

Epoch: 6| Step: 3
Training loss: 2.8765225410461426
Validation loss: 2.418148479154033

Epoch: 6| Step: 4
Training loss: 2.7804298400878906
Validation loss: 2.4162021862563265

Epoch: 6| Step: 5
Training loss: 2.9999537467956543
Validation loss: 2.417857995597265

Epoch: 6| Step: 6
Training loss: 3.4717912673950195
Validation loss: 2.4287434931724303

Epoch: 6| Step: 7
Training loss: 1.9713348150253296
Validation loss: 2.4212398298325075

Epoch: 6| Step: 8
Training loss: 2.219179153442383
Validation loss: 2.42229567035552

Epoch: 6| Step: 9
Training loss: 3.503164768218994
Validation loss: 2.416630934643489

Epoch: 6| Step: 10
Training loss: 2.577523946762085
Validation loss: 2.4145874695111345

Epoch: 6| Step: 11
Training loss: 2.5886242389678955
Validation loss: 2.4125322500864663

Epoch: 6| Step: 12
Training loss: 3.054421901702881
Validation loss: 2.4111729360395864

Epoch: 6| Step: 13
Training loss: 2.253441333770752
Validation loss: 2.4123440327182895

Epoch: 44| Step: 0
Training loss: 1.9813507795333862
Validation loss: 2.412351753122063

Epoch: 6| Step: 1
Training loss: 3.0547056198120117
Validation loss: 2.405919305739864

Epoch: 6| Step: 2
Training loss: 2.763206958770752
Validation loss: 2.4066519506515993

Epoch: 6| Step: 3
Training loss: 2.979386329650879
Validation loss: 2.407794721664921

Epoch: 6| Step: 4
Training loss: 2.5452260971069336
Validation loss: 2.402679184431671

Epoch: 6| Step: 5
Training loss: 2.6444811820983887
Validation loss: 2.409814962776758

Epoch: 6| Step: 6
Training loss: 2.768498659133911
Validation loss: 2.4150365347503335

Epoch: 6| Step: 7
Training loss: 2.181201696395874
Validation loss: 2.4293059738733436

Epoch: 6| Step: 8
Training loss: 3.107232093811035
Validation loss: 2.4550439260339223

Epoch: 6| Step: 9
Training loss: 2.6327266693115234
Validation loss: 2.501970583392728

Epoch: 6| Step: 10
Training loss: 2.26826810836792
Validation loss: 2.4800257452072634

Epoch: 6| Step: 11
Training loss: 2.9949722290039062
Validation loss: 2.4574775977801253

Epoch: 6| Step: 12
Training loss: 2.990067720413208
Validation loss: 2.446920458988477

Epoch: 6| Step: 13
Training loss: 2.130039691925049
Validation loss: 2.404071628406484

Epoch: 45| Step: 0
Training loss: 2.1704113483428955
Validation loss: 2.4008061014195925

Epoch: 6| Step: 1
Training loss: 3.6991758346557617
Validation loss: 2.413344831876857

Epoch: 6| Step: 2
Training loss: 2.6777114868164062
Validation loss: 2.44353961688216

Epoch: 6| Step: 3
Training loss: 2.9250640869140625
Validation loss: 2.4296379114991877

Epoch: 6| Step: 4
Training loss: 2.7568001747131348
Validation loss: 2.417371888314524

Epoch: 6| Step: 5
Training loss: 2.711024522781372
Validation loss: 2.4064154830030215

Epoch: 6| Step: 6
Training loss: 2.187127113342285
Validation loss: 2.401716541218501

Epoch: 6| Step: 7
Training loss: 2.0568602085113525
Validation loss: 2.4083756605784097

Epoch: 6| Step: 8
Training loss: 2.900636911392212
Validation loss: 2.428111227609778

Epoch: 6| Step: 9
Training loss: 2.8302626609802246
Validation loss: 2.4720444730533067

Epoch: 6| Step: 10
Training loss: 3.547424554824829
Validation loss: 2.5119139148342993

Epoch: 6| Step: 11
Training loss: 2.127002716064453
Validation loss: 2.5338285994786087

Epoch: 6| Step: 12
Training loss: 2.659712314605713
Validation loss: 2.5629129666154102

Epoch: 6| Step: 13
Training loss: 2.069819450378418
Validation loss: 2.515058550783383

Epoch: 46| Step: 0
Training loss: 2.1785457134246826
Validation loss: 2.4495395511709233

Epoch: 6| Step: 1
Training loss: 2.6782894134521484
Validation loss: 2.4047185887572584

Epoch: 6| Step: 2
Training loss: 1.896942138671875
Validation loss: 2.4024031136625554

Epoch: 6| Step: 3
Training loss: 2.801117420196533
Validation loss: 2.4122209318222536

Epoch: 6| Step: 4
Training loss: 2.7429676055908203
Validation loss: 2.419044940702377

Epoch: 6| Step: 5
Training loss: 2.9517033100128174
Validation loss: 2.424654268449353

Epoch: 6| Step: 6
Training loss: 3.149733066558838
Validation loss: 2.423637282463812

Epoch: 6| Step: 7
Training loss: 2.6351356506347656
Validation loss: 2.424074319101149

Epoch: 6| Step: 8
Training loss: 2.4732778072357178
Validation loss: 2.4254376965184368

Epoch: 6| Step: 9
Training loss: 2.509925365447998
Validation loss: 2.4182436927672355

Epoch: 6| Step: 10
Training loss: 2.728311538696289
Validation loss: 2.4045871662837204

Epoch: 6| Step: 11
Training loss: 2.8320231437683105
Validation loss: 2.3969751993815103

Epoch: 6| Step: 12
Training loss: 2.6250061988830566
Validation loss: 2.3958699600670927

Epoch: 6| Step: 13
Training loss: 3.3237621784210205
Validation loss: 2.3883662326361543

Epoch: 47| Step: 0
Training loss: 2.3870389461517334
Validation loss: 2.389343520646454

Epoch: 6| Step: 1
Training loss: 2.2180895805358887
Validation loss: 2.395854283404607

Epoch: 6| Step: 2
Training loss: 2.0641844272613525
Validation loss: 2.4125703355317474

Epoch: 6| Step: 3
Training loss: 2.2994635105133057
Validation loss: 2.412827730178833

Epoch: 6| Step: 4
Training loss: 3.044651508331299
Validation loss: 2.431483608420177

Epoch: 6| Step: 5
Training loss: 3.6108896732330322
Validation loss: 2.425523428506749

Epoch: 6| Step: 6
Training loss: 2.217331886291504
Validation loss: 2.4460709274456067

Epoch: 6| Step: 7
Training loss: 3.0506131649017334
Validation loss: 2.4514516784298803

Epoch: 6| Step: 8
Training loss: 2.9704337120056152
Validation loss: 2.4298311869303384

Epoch: 6| Step: 9
Training loss: 2.61063289642334
Validation loss: 2.417590974479593

Epoch: 6| Step: 10
Training loss: 2.7042038440704346
Validation loss: 2.399251727647679

Epoch: 6| Step: 11
Training loss: 2.4391510486602783
Validation loss: 2.4026348488305205

Epoch: 6| Step: 12
Training loss: 2.533322334289551
Validation loss: 2.3908178908850557

Epoch: 6| Step: 13
Training loss: 3.015019416809082
Validation loss: 2.3844229252107683

Epoch: 48| Step: 0
Training loss: 2.541303873062134
Validation loss: 2.3866022325331167

Epoch: 6| Step: 1
Training loss: 2.8860583305358887
Validation loss: 2.3801315138416905

Epoch: 6| Step: 2
Training loss: 2.29913067817688
Validation loss: 2.381019666630735

Epoch: 6| Step: 3
Training loss: 2.1831016540527344
Validation loss: 2.3778677191785587

Epoch: 6| Step: 4
Training loss: 3.301637649536133
Validation loss: 2.378736993317963

Epoch: 6| Step: 5
Training loss: 1.8082307577133179
Validation loss: 2.3817585206800893

Epoch: 6| Step: 6
Training loss: 3.104172706604004
Validation loss: 2.38393057802672

Epoch: 6| Step: 7
Training loss: 3.803272247314453
Validation loss: 2.3919532888679096

Epoch: 6| Step: 8
Training loss: 2.180455207824707
Validation loss: 2.3890300566150295

Epoch: 6| Step: 9
Training loss: 2.74996018409729
Validation loss: 2.396830020412322

Epoch: 6| Step: 10
Training loss: 2.4202370643615723
Validation loss: 2.403594216992778

Epoch: 6| Step: 11
Training loss: 2.2480814456939697
Validation loss: 2.4041857219511464

Epoch: 6| Step: 12
Training loss: 2.665501117706299
Validation loss: 2.4131993657799176

Epoch: 6| Step: 13
Training loss: 2.669985055923462
Validation loss: 2.410391535810245

Epoch: 49| Step: 0
Training loss: 2.326138973236084
Validation loss: 2.4182286903422368

Epoch: 6| Step: 1
Training loss: 2.452629566192627
Validation loss: 2.4182936914505495

Epoch: 6| Step: 2
Training loss: 3.043774127960205
Validation loss: 2.416339551248858

Epoch: 6| Step: 3
Training loss: 3.023839235305786
Validation loss: 2.405867725290278

Epoch: 6| Step: 4
Training loss: 2.220104932785034
Validation loss: 2.394301317071402

Epoch: 6| Step: 5
Training loss: 2.9512410163879395
Validation loss: 2.386325825927078

Epoch: 6| Step: 6
Training loss: 2.4886510372161865
Validation loss: 2.379749241695609

Epoch: 6| Step: 7
Training loss: 2.980550765991211
Validation loss: 2.3816514912471978

Epoch: 6| Step: 8
Training loss: 2.145181655883789
Validation loss: 2.3869611204311414

Epoch: 6| Step: 9
Training loss: 2.999204158782959
Validation loss: 2.3857930860211773

Epoch: 6| Step: 10
Training loss: 2.7782607078552246
Validation loss: 2.384675748886601

Epoch: 6| Step: 11
Training loss: 2.921323776245117
Validation loss: 2.389085460734624

Epoch: 6| Step: 12
Training loss: 2.2656707763671875
Validation loss: 2.392232664169804

Epoch: 6| Step: 13
Training loss: 1.9051508903503418
Validation loss: 2.398833792696717

Epoch: 50| Step: 0
Training loss: 2.643406629562378
Validation loss: 2.4031787841550765

Epoch: 6| Step: 1
Training loss: 2.542142629623413
Validation loss: 2.417671170285953

Epoch: 6| Step: 2
Training loss: 2.516960620880127
Validation loss: 2.426537731642364

Epoch: 6| Step: 3
Training loss: 3.0428905487060547
Validation loss: 2.4215494381484164

Epoch: 6| Step: 4
Training loss: 2.654522180557251
Validation loss: 2.4185348992706626

Epoch: 6| Step: 5
Training loss: 2.999222755432129
Validation loss: 2.3978013838491132

Epoch: 6| Step: 6
Training loss: 2.225162982940674
Validation loss: 2.389044092547509

Epoch: 6| Step: 7
Training loss: 3.4357564449310303
Validation loss: 2.3801530868776384

Epoch: 6| Step: 8
Training loss: 2.525662422180176
Validation loss: 2.3720051088640766

Epoch: 6| Step: 9
Training loss: 2.110973596572876
Validation loss: 2.374383247026833

Epoch: 6| Step: 10
Training loss: 1.8934314250946045
Validation loss: 2.372786311693089

Epoch: 6| Step: 11
Training loss: 2.5228264331817627
Validation loss: 2.3705232040856474

Epoch: 6| Step: 12
Training loss: 2.5540781021118164
Validation loss: 2.376773582991733

Epoch: 6| Step: 13
Training loss: 3.451425075531006
Validation loss: 2.3838391919289865

Epoch: 51| Step: 0
Training loss: 1.983823299407959
Validation loss: 2.3986801255133843

Epoch: 6| Step: 1
Training loss: 2.606130599975586
Validation loss: 2.408245542997955

Epoch: 6| Step: 2
Training loss: 2.9835691452026367
Validation loss: 2.4304890683902207

Epoch: 6| Step: 3
Training loss: 3.3496243953704834
Validation loss: 2.440127557323825

Epoch: 6| Step: 4
Training loss: 2.6283462047576904
Validation loss: 2.4563427612345707

Epoch: 6| Step: 5
Training loss: 2.901095390319824
Validation loss: 2.441557030523977

Epoch: 6| Step: 6
Training loss: 2.375967502593994
Validation loss: 2.4340661635962864

Epoch: 6| Step: 7
Training loss: 3.0996665954589844
Validation loss: 2.40940749004323

Epoch: 6| Step: 8
Training loss: 2.7852909564971924
Validation loss: 2.3910509745279946

Epoch: 6| Step: 9
Training loss: 2.609262466430664
Validation loss: 2.3752232290083364

Epoch: 6| Step: 10
Training loss: 2.0772902965545654
Validation loss: 2.370363140618929

Epoch: 6| Step: 11
Training loss: 2.0074267387390137
Validation loss: 2.3648678307892173

Epoch: 6| Step: 12
Training loss: 2.888869285583496
Validation loss: 2.3675061361764067

Epoch: 6| Step: 13
Training loss: 2.341952323913574
Validation loss: 2.3652005272526897

Epoch: 52| Step: 0
Training loss: 2.166952610015869
Validation loss: 2.364729537758776

Epoch: 6| Step: 1
Training loss: 2.060037851333618
Validation loss: 2.3659627053045456

Epoch: 6| Step: 2
Training loss: 2.3627829551696777
Validation loss: 2.3670964138482207

Epoch: 6| Step: 3
Training loss: 2.6485891342163086
Validation loss: 2.3735530607161985

Epoch: 6| Step: 4
Training loss: 2.1491305828094482
Validation loss: 2.380748300142186

Epoch: 6| Step: 5
Training loss: 2.7228450775146484
Validation loss: 2.411007865782707

Epoch: 6| Step: 6
Training loss: 2.8905019760131836
Validation loss: 2.4364554215502996

Epoch: 6| Step: 7
Training loss: 3.1876277923583984
Validation loss: 2.4451197616515623

Epoch: 6| Step: 8
Training loss: 3.290783166885376
Validation loss: 2.4124365698906685

Epoch: 6| Step: 9
Training loss: 2.990513324737549
Validation loss: 2.3964268187040925

Epoch: 6| Step: 10
Training loss: 2.5660767555236816
Validation loss: 2.378430692098474

Epoch: 6| Step: 11
Training loss: 2.7804360389709473
Validation loss: 2.3693803792358725

Epoch: 6| Step: 12
Training loss: 2.8887298107147217
Validation loss: 2.3686417802687614

Epoch: 6| Step: 13
Training loss: 2.118729591369629
Validation loss: 2.370196355286465

Epoch: 53| Step: 0
Training loss: 2.8356308937072754
Validation loss: 2.3709955971728087

Epoch: 6| Step: 1
Training loss: 3.2828359603881836
Validation loss: 2.377207886788153

Epoch: 6| Step: 2
Training loss: 2.637707471847534
Validation loss: 2.3743214325238298

Epoch: 6| Step: 3
Training loss: 2.5459165573120117
Validation loss: 2.3667153081586285

Epoch: 6| Step: 4
Training loss: 3.0354974269866943
Validation loss: 2.367828974159815

Epoch: 6| Step: 5
Training loss: 2.668816328048706
Validation loss: 2.364902998811455

Epoch: 6| Step: 6
Training loss: 2.739075183868408
Validation loss: 2.3625325695160897

Epoch: 6| Step: 7
Training loss: 2.0044643878936768
Validation loss: 2.3738578750241186

Epoch: 6| Step: 8
Training loss: 2.6084787845611572
Validation loss: 2.369547692678308

Epoch: 6| Step: 9
Training loss: 1.8268240690231323
Validation loss: 2.375055969402354

Epoch: 6| Step: 10
Training loss: 2.8189921379089355
Validation loss: 2.375469156490859

Epoch: 6| Step: 11
Training loss: 3.1568846702575684
Validation loss: 2.3943120817984305

Epoch: 6| Step: 12
Training loss: 2.314770460128784
Validation loss: 2.406560972172727

Epoch: 6| Step: 13
Training loss: 2.2654922008514404
Validation loss: 2.42267349971238

Epoch: 54| Step: 0
Training loss: 2.7018721103668213
Validation loss: 2.4141180720380557

Epoch: 6| Step: 1
Training loss: 2.6689910888671875
Validation loss: 2.399322848166189

Epoch: 6| Step: 2
Training loss: 2.409147024154663
Validation loss: 2.396176261286582

Epoch: 6| Step: 3
Training loss: 2.7724430561065674
Validation loss: 2.3866464578977196

Epoch: 6| Step: 4
Training loss: 2.5470898151397705
Validation loss: 2.383388552614438

Epoch: 6| Step: 5
Training loss: 2.2909035682678223
Validation loss: 2.37556351512991

Epoch: 6| Step: 6
Training loss: 2.4371283054351807
Validation loss: 2.359310491110689

Epoch: 6| Step: 7
Training loss: 2.3777108192443848
Validation loss: 2.3598763442808584

Epoch: 6| Step: 8
Training loss: 3.4205098152160645
Validation loss: 2.3532897682600122

Epoch: 6| Step: 9
Training loss: 2.545612335205078
Validation loss: 2.35350142499452

Epoch: 6| Step: 10
Training loss: 2.7001023292541504
Validation loss: 2.355940447058729

Epoch: 6| Step: 11
Training loss: 2.498918294906616
Validation loss: 2.360127946381928

Epoch: 6| Step: 12
Training loss: 2.6714911460876465
Validation loss: 2.3600348272631244

Epoch: 6| Step: 13
Training loss: 2.771786689758301
Validation loss: 2.3595093193874566

Epoch: 55| Step: 0
Training loss: 2.6583662033081055
Validation loss: 2.3627332384868334

Epoch: 6| Step: 1
Training loss: 2.6440842151641846
Validation loss: 2.3677291536843903

Epoch: 6| Step: 2
Training loss: 2.355567455291748
Validation loss: 2.3574571224950973

Epoch: 6| Step: 3
Training loss: 2.198495626449585
Validation loss: 2.3795997942647626

Epoch: 6| Step: 4
Training loss: 3.037275791168213
Validation loss: 2.371884484444895

Epoch: 6| Step: 5
Training loss: 2.0478110313415527
Validation loss: 2.377896055098503

Epoch: 6| Step: 6
Training loss: 2.697274923324585
Validation loss: 2.370033658960814

Epoch: 6| Step: 7
Training loss: 3.0612592697143555
Validation loss: 2.369408763864989

Epoch: 6| Step: 8
Training loss: 3.1366498470306396
Validation loss: 2.358051294921547

Epoch: 6| Step: 9
Training loss: 2.5315423011779785
Validation loss: 2.3584012805774646

Epoch: 6| Step: 10
Training loss: 3.026949405670166
Validation loss: 2.361112120330975

Epoch: 6| Step: 11
Training loss: 3.1366615295410156
Validation loss: 2.361148267663935

Epoch: 6| Step: 12
Training loss: 1.8875877857208252
Validation loss: 2.364730796506328

Epoch: 6| Step: 13
Training loss: 1.9058347940444946
Validation loss: 2.381703704916021

Epoch: 56| Step: 0
Training loss: 3.239658832550049
Validation loss: 2.386193480542911

Epoch: 6| Step: 1
Training loss: 2.2065720558166504
Validation loss: 2.3890705134278987

Epoch: 6| Step: 2
Training loss: 1.9420374631881714
Validation loss: 2.390460903926562

Epoch: 6| Step: 3
Training loss: 2.882079601287842
Validation loss: 2.4052257076386483

Epoch: 6| Step: 4
Training loss: 2.504793167114258
Validation loss: 2.3976085775641987

Epoch: 6| Step: 5
Training loss: 2.192349433898926
Validation loss: 2.378058059241182

Epoch: 6| Step: 6
Training loss: 2.655651807785034
Validation loss: 2.369644198366391

Epoch: 6| Step: 7
Training loss: 2.3781869411468506
Validation loss: 2.3650942669119885

Epoch: 6| Step: 8
Training loss: 2.646561622619629
Validation loss: 2.363905575967604

Epoch: 6| Step: 9
Training loss: 2.609468936920166
Validation loss: 2.3674337530648835

Epoch: 6| Step: 10
Training loss: 2.816368818283081
Validation loss: 2.362571398417155

Epoch: 6| Step: 11
Training loss: 2.920562744140625
Validation loss: 2.35562648055374

Epoch: 6| Step: 12
Training loss: 2.614551305770874
Validation loss: 2.355511583307738

Epoch: 6| Step: 13
Training loss: 3.0585875511169434
Validation loss: 2.3647747116704143

Epoch: 57| Step: 0
Training loss: 2.014801263809204
Validation loss: 2.3800539662761073

Epoch: 6| Step: 1
Training loss: 2.4206042289733887
Validation loss: 2.377015306103614

Epoch: 6| Step: 2
Training loss: 2.1780033111572266
Validation loss: 2.3896138514241865

Epoch: 6| Step: 3
Training loss: 2.5752813816070557
Validation loss: 2.408752179914905

Epoch: 6| Step: 4
Training loss: 2.7850513458251953
Validation loss: 2.435177287747783

Epoch: 6| Step: 5
Training loss: 1.9540594816207886
Validation loss: 2.477228508200697

Epoch: 6| Step: 6
Training loss: 2.84220552444458
Validation loss: 2.484549589054559

Epoch: 6| Step: 7
Training loss: 2.3335657119750977
Validation loss: 2.462055249880719

Epoch: 6| Step: 8
Training loss: 3.03666353225708
Validation loss: 2.4279627005259194

Epoch: 6| Step: 9
Training loss: 3.058206796646118
Validation loss: 2.411994218826294

Epoch: 6| Step: 10
Training loss: 3.0707449913024902
Validation loss: 2.4053818961625457

Epoch: 6| Step: 11
Training loss: 2.750307083129883
Validation loss: 2.393470774414719

Epoch: 6| Step: 12
Training loss: 3.5079193115234375
Validation loss: 2.381028623991115

Epoch: 6| Step: 13
Training loss: 1.899333119392395
Validation loss: 2.365134918561546

Epoch: 58| Step: 0
Training loss: 2.6032748222351074
Validation loss: 2.355770273875165

Epoch: 6| Step: 1
Training loss: 2.7774364948272705
Validation loss: 2.3481700112742763

Epoch: 6| Step: 2
Training loss: 2.6895511150360107
Validation loss: 2.350593718149329

Epoch: 6| Step: 3
Training loss: 2.225477457046509
Validation loss: 2.3491633207567277

Epoch: 6| Step: 4
Training loss: 2.942437171936035
Validation loss: 2.347518128733481

Epoch: 6| Step: 5
Training loss: 3.0082895755767822
Validation loss: 2.348309904016474

Epoch: 6| Step: 6
Training loss: 2.9485926628112793
Validation loss: 2.34577081793098

Epoch: 6| Step: 7
Training loss: 2.82177734375
Validation loss: 2.3515165262324835

Epoch: 6| Step: 8
Training loss: 2.746638298034668
Validation loss: 2.350783230156027

Epoch: 6| Step: 9
Training loss: 2.758026599884033
Validation loss: 2.3598863783703057

Epoch: 6| Step: 10
Training loss: 1.7562224864959717
Validation loss: 2.3781162923382175

Epoch: 6| Step: 11
Training loss: 2.396458148956299
Validation loss: 2.3973337732335573

Epoch: 6| Step: 12
Training loss: 2.114588499069214
Validation loss: 2.404013918292138

Epoch: 6| Step: 13
Training loss: 3.112271785736084
Validation loss: 2.4049388388151764

Epoch: 59| Step: 0
Training loss: 2.4626426696777344
Validation loss: 2.389680785517539

Epoch: 6| Step: 1
Training loss: 2.71842098236084
Validation loss: 2.374005683006779

Epoch: 6| Step: 2
Training loss: 1.948746919631958
Validation loss: 2.355683477975989

Epoch: 6| Step: 3
Training loss: 2.598339319229126
Validation loss: 2.347204626247447

Epoch: 6| Step: 4
Training loss: 2.4339194297790527
Validation loss: 2.343455952982749

Epoch: 6| Step: 5
Training loss: 2.8250021934509277
Validation loss: 2.35120952129364

Epoch: 6| Step: 6
Training loss: 2.1945152282714844
Validation loss: 2.3478560857875372

Epoch: 6| Step: 7
Training loss: 2.3885369300842285
Validation loss: 2.353195318611719

Epoch: 6| Step: 8
Training loss: 2.369408130645752
Validation loss: 2.3582843965099705

Epoch: 6| Step: 9
Training loss: 3.6007080078125
Validation loss: 2.351201998290195

Epoch: 6| Step: 10
Training loss: 2.5104992389678955
Validation loss: 2.3426309657353226

Epoch: 6| Step: 11
Training loss: 2.4959568977355957
Validation loss: 2.342388553004111

Epoch: 6| Step: 12
Training loss: 3.271120548248291
Validation loss: 2.356642428264823

Epoch: 6| Step: 13
Training loss: 2.710561752319336
Validation loss: 2.3730296422076482

Epoch: 60| Step: 0
Training loss: 2.7692902088165283
Validation loss: 2.372227043233892

Epoch: 6| Step: 1
Training loss: 2.8861656188964844
Validation loss: 2.361893105250533

Epoch: 6| Step: 2
Training loss: 2.2944257259368896
Validation loss: 2.343987721268849

Epoch: 6| Step: 3
Training loss: 2.594451427459717
Validation loss: 2.3379925143334175

Epoch: 6| Step: 4
Training loss: 2.8025994300842285
Validation loss: 2.3383753068985476

Epoch: 6| Step: 5
Training loss: 2.324988842010498
Validation loss: 2.325825442550003

Epoch: 6| Step: 6
Training loss: 1.9551819562911987
Validation loss: 2.3314909627360683

Epoch: 6| Step: 7
Training loss: 3.3434152603149414
Validation loss: 2.330136069687464

Epoch: 6| Step: 8
Training loss: 2.491325855255127
Validation loss: 2.333234433204897

Epoch: 6| Step: 9
Training loss: 1.8209229707717896
Validation loss: 2.3330880057427192

Epoch: 6| Step: 10
Training loss: 2.3081488609313965
Validation loss: 2.3282782018825574

Epoch: 6| Step: 11
Training loss: 2.7113609313964844
Validation loss: 2.325696578589819

Epoch: 6| Step: 12
Training loss: 3.0565385818481445
Validation loss: 2.3317932198124547

Epoch: 6| Step: 13
Training loss: 3.3628857135772705
Validation loss: 2.3367179696277907

Epoch: 61| Step: 0
Training loss: 2.7964305877685547
Validation loss: 2.349158372930301

Epoch: 6| Step: 1
Training loss: 1.5378506183624268
Validation loss: 2.3673880100250244

Epoch: 6| Step: 2
Training loss: 2.5385656356811523
Validation loss: 2.385940005702357

Epoch: 6| Step: 3
Training loss: 2.5363407135009766
Validation loss: 2.4015050908570648

Epoch: 6| Step: 4
Training loss: 2.4335055351257324
Validation loss: 2.4244228947547173

Epoch: 6| Step: 5
Training loss: 3.545072555541992
Validation loss: 2.427802360186013

Epoch: 6| Step: 6
Training loss: 2.371311902999878
Validation loss: 2.404650794562473

Epoch: 6| Step: 7
Training loss: 2.8095953464508057
Validation loss: 2.386094848314921

Epoch: 6| Step: 8
Training loss: 2.3623175621032715
Validation loss: 2.3666624305068806

Epoch: 6| Step: 9
Training loss: 2.2742316722869873
Validation loss: 2.352621127200383

Epoch: 6| Step: 10
Training loss: 2.981940269470215
Validation loss: 2.3335640250995593

Epoch: 6| Step: 11
Training loss: 3.6340551376342773
Validation loss: 2.3261669271735737

Epoch: 6| Step: 12
Training loss: 2.122551441192627
Validation loss: 2.3221879338705413

Epoch: 6| Step: 13
Training loss: 2.2198374271392822
Validation loss: 2.3220947365606985

Epoch: 62| Step: 0
Training loss: 2.8710060119628906
Validation loss: 2.322301938969602

Epoch: 6| Step: 1
Training loss: 2.279491901397705
Validation loss: 2.32370594240004

Epoch: 6| Step: 2
Training loss: 3.1511216163635254
Validation loss: 2.3216284936474216

Epoch: 6| Step: 3
Training loss: 2.618865966796875
Validation loss: 2.323041259601552

Epoch: 6| Step: 4
Training loss: 2.900311231613159
Validation loss: 2.322304371864565

Epoch: 6| Step: 5
Training loss: 2.0507097244262695
Validation loss: 2.3192656937465874

Epoch: 6| Step: 6
Training loss: 2.5937881469726562
Validation loss: 2.326892796383109

Epoch: 6| Step: 7
Training loss: 3.210659980773926
Validation loss: 2.329219100295856

Epoch: 6| Step: 8
Training loss: 2.193760633468628
Validation loss: 2.3390087927541425

Epoch: 6| Step: 9
Training loss: 2.2729740142822266
Validation loss: 2.351426334791286

Epoch: 6| Step: 10
Training loss: 2.3150718212127686
Validation loss: 2.3656288449482252

Epoch: 6| Step: 11
Training loss: 3.3784518241882324
Validation loss: 2.3663010187046503

Epoch: 6| Step: 12
Training loss: 1.6408904790878296
Validation loss: 2.354757837069932

Epoch: 6| Step: 13
Training loss: 3.132462501525879
Validation loss: 2.3481841753887873

Epoch: 63| Step: 0
Training loss: 2.947033405303955
Validation loss: 2.3634631274848856

Epoch: 6| Step: 1
Training loss: 2.3604788780212402
Validation loss: 2.3550041798622376

Epoch: 6| Step: 2
Training loss: 2.431696891784668
Validation loss: 2.345563687304015

Epoch: 6| Step: 3
Training loss: 1.885582685470581
Validation loss: 2.3433211259944464

Epoch: 6| Step: 4
Training loss: 2.854527473449707
Validation loss: 2.335666484730218

Epoch: 6| Step: 5
Training loss: 2.0719962120056152
Validation loss: 2.330629038554366

Epoch: 6| Step: 6
Training loss: 3.03942608833313
Validation loss: 2.325983473049697

Epoch: 6| Step: 7
Training loss: 2.4459028244018555
Validation loss: 2.324385012349775

Epoch: 6| Step: 8
Training loss: 2.6075167655944824
Validation loss: 2.3199252928456953

Epoch: 6| Step: 9
Training loss: 3.1680376529693604
Validation loss: 2.324138964376142

Epoch: 6| Step: 10
Training loss: 2.886141300201416
Validation loss: 2.32724715048267

Epoch: 6| Step: 11
Training loss: 2.874943971633911
Validation loss: 2.332637386937295

Epoch: 6| Step: 12
Training loss: 2.2760610580444336
Validation loss: 2.3411380731931297

Epoch: 6| Step: 13
Training loss: 2.3448376655578613
Validation loss: 2.350762108320831

Epoch: 64| Step: 0
Training loss: 2.2081496715545654
Validation loss: 2.3576575145926526

Epoch: 6| Step: 1
Training loss: 3.13196063041687
Validation loss: 2.34358581419914

Epoch: 6| Step: 2
Training loss: 2.302969455718994
Validation loss: 2.3359054109101653

Epoch: 6| Step: 3
Training loss: 2.381035804748535
Validation loss: 2.349661127213509

Epoch: 6| Step: 4
Training loss: 2.095700740814209
Validation loss: 2.3646964488490934

Epoch: 6| Step: 5
Training loss: 2.263516902923584
Validation loss: 2.3732375534631873

Epoch: 6| Step: 6
Training loss: 2.858185291290283
Validation loss: 2.358589667145924

Epoch: 6| Step: 7
Training loss: 1.6687445640563965
Validation loss: 2.368631696188322

Epoch: 6| Step: 8
Training loss: 2.7337112426757812
Validation loss: 2.350067587308986

Epoch: 6| Step: 9
Training loss: 3.4164159297943115
Validation loss: 2.339359519302204

Epoch: 6| Step: 10
Training loss: 2.5013768672943115
Validation loss: 2.323838448011747

Epoch: 6| Step: 11
Training loss: 2.9840950965881348
Validation loss: 2.3138093974000666

Epoch: 6| Step: 12
Training loss: 3.0088467597961426
Validation loss: 2.3155290849747194

Epoch: 6| Step: 13
Training loss: 2.679706573486328
Validation loss: 2.310917172380673

Epoch: 65| Step: 0
Training loss: 1.8239409923553467
Validation loss: 2.3111314824832383

Epoch: 6| Step: 1
Training loss: 2.841461420059204
Validation loss: 2.309884545623615

Epoch: 6| Step: 2
Training loss: 2.552381992340088
Validation loss: 2.3132149891186784

Epoch: 6| Step: 3
Training loss: 2.834275722503662
Validation loss: 2.3151315745487007

Epoch: 6| Step: 4
Training loss: 2.6195669174194336
Validation loss: 2.3046938885924635

Epoch: 6| Step: 5
Training loss: 2.7253408432006836
Validation loss: 2.3118977392873457

Epoch: 6| Step: 6
Training loss: 2.433344602584839
Validation loss: 2.31125521403487

Epoch: 6| Step: 7
Training loss: 2.603087902069092
Validation loss: 2.310015606623824

Epoch: 6| Step: 8
Training loss: 2.5810203552246094
Validation loss: 2.3174294810141287

Epoch: 6| Step: 9
Training loss: 2.534672260284424
Validation loss: 2.327547839892808

Epoch: 6| Step: 10
Training loss: 2.152780532836914
Validation loss: 2.343321713068152

Epoch: 6| Step: 11
Training loss: 3.04927921295166
Validation loss: 2.3587112478030625

Epoch: 6| Step: 12
Training loss: 2.9725310802459717
Validation loss: 2.372312807267712

Epoch: 6| Step: 13
Training loss: 2.634678363800049
Validation loss: 2.358546554401357

Epoch: 66| Step: 0
Training loss: 1.5297019481658936
Validation loss: 2.350246890898674

Epoch: 6| Step: 1
Training loss: 2.508514642715454
Validation loss: 2.332076952021609

Epoch: 6| Step: 2
Training loss: 1.8498090505599976
Validation loss: 2.312534160511468

Epoch: 6| Step: 3
Training loss: 2.722379446029663
Validation loss: 2.314728993241505

Epoch: 6| Step: 4
Training loss: 2.675168037414551
Validation loss: 2.324114373935166

Epoch: 6| Step: 5
Training loss: 2.451495409011841
Validation loss: 2.315579737386396

Epoch: 6| Step: 6
Training loss: 3.365067958831787
Validation loss: 2.321862264346051

Epoch: 6| Step: 7
Training loss: 2.3435420989990234
Validation loss: 2.3193654783310427

Epoch: 6| Step: 8
Training loss: 2.8210902214050293
Validation loss: 2.325971631593602

Epoch: 6| Step: 9
Training loss: 2.78821063041687
Validation loss: 2.341713402860908

Epoch: 6| Step: 10
Training loss: 2.245594024658203
Validation loss: 2.3427579377287175

Epoch: 6| Step: 11
Training loss: 3.4349608421325684
Validation loss: 2.349093134685229

Epoch: 6| Step: 12
Training loss: 2.697622060775757
Validation loss: 2.3571347216124177

Epoch: 6| Step: 13
Training loss: 2.798821449279785
Validation loss: 2.3390724376965593

Epoch: 67| Step: 0
Training loss: 2.898477792739868
Validation loss: 2.3353384412744993

Epoch: 6| Step: 1
Training loss: 2.1659963130950928
Validation loss: 2.315037060809392

Epoch: 6| Step: 2
Training loss: 1.9487311840057373
Validation loss: 2.307497565464307

Epoch: 6| Step: 3
Training loss: 2.7008304595947266
Validation loss: 2.3080409829334547

Epoch: 6| Step: 4
Training loss: 3.273599147796631
Validation loss: 2.3018832322089904

Epoch: 6| Step: 5
Training loss: 2.2002573013305664
Validation loss: 2.3046685188047347

Epoch: 6| Step: 6
Training loss: 2.043165922164917
Validation loss: 2.307736978735975

Epoch: 6| Step: 7
Training loss: 2.8692471981048584
Validation loss: 2.3077076404325423

Epoch: 6| Step: 8
Training loss: 2.3368072509765625
Validation loss: 2.3104441140287664

Epoch: 6| Step: 9
Training loss: 2.8105390071868896
Validation loss: 2.310310068950858

Epoch: 6| Step: 10
Training loss: 1.9936367273330688
Validation loss: 2.3174762905284925

Epoch: 6| Step: 11
Training loss: 2.348351240158081
Validation loss: 2.318782029613372

Epoch: 6| Step: 12
Training loss: 3.7844293117523193
Validation loss: 2.3332282958492154

Epoch: 6| Step: 13
Training loss: 2.665898323059082
Validation loss: 2.3319058392637517

Epoch: 68| Step: 0
Training loss: 2.8541414737701416
Validation loss: 2.3206087594391196

Epoch: 6| Step: 1
Training loss: 2.8965001106262207
Validation loss: 2.3099674101798766

Epoch: 6| Step: 2
Training loss: 2.6516788005828857
Validation loss: 2.3055264539616083

Epoch: 6| Step: 3
Training loss: 3.2865824699401855
Validation loss: 2.3073242043936126

Epoch: 6| Step: 4
Training loss: 2.2586917877197266
Validation loss: 2.301411049340361

Epoch: 6| Step: 5
Training loss: 2.565324544906616
Validation loss: 2.3052776500742924

Epoch: 6| Step: 6
Training loss: 2.032731056213379
Validation loss: 2.29818388723558

Epoch: 6| Step: 7
Training loss: 2.2149133682250977
Validation loss: 2.3105662715050483

Epoch: 6| Step: 8
Training loss: 2.508258819580078
Validation loss: 2.315409024556478

Epoch: 6| Step: 9
Training loss: 2.1055679321289062
Validation loss: 2.3152578748682493

Epoch: 6| Step: 10
Training loss: 2.9176409244537354
Validation loss: 2.3183730648409937

Epoch: 6| Step: 11
Training loss: 2.9143381118774414
Validation loss: 2.32199437643892

Epoch: 6| Step: 12
Training loss: 2.5904135704040527
Validation loss: 2.324694105373916

Epoch: 6| Step: 13
Training loss: 1.786882996559143
Validation loss: 2.320117081365278

Epoch: 69| Step: 0
Training loss: 2.2841062545776367
Validation loss: 2.3068769490847023

Epoch: 6| Step: 1
Training loss: 3.006044387817383
Validation loss: 2.3159717693123767

Epoch: 6| Step: 2
Training loss: 2.8166089057922363
Validation loss: 2.307560129832196

Epoch: 6| Step: 3
Training loss: 3.023292064666748
Validation loss: 2.3022711789736183

Epoch: 6| Step: 4
Training loss: 2.4101006984710693
Validation loss: 2.298320124226232

Epoch: 6| Step: 5
Training loss: 2.038051128387451
Validation loss: 2.2887199207018782

Epoch: 6| Step: 6
Training loss: 2.410557985305786
Validation loss: 2.2961571857493412

Epoch: 6| Step: 7
Training loss: 3.0761537551879883
Validation loss: 2.295717654689666

Epoch: 6| Step: 8
Training loss: 2.925161838531494
Validation loss: 2.2911284585152902

Epoch: 6| Step: 9
Training loss: 2.8004252910614014
Validation loss: 2.2907778011855258

Epoch: 6| Step: 10
Training loss: 2.2443432807922363
Validation loss: 2.2905947380168463

Epoch: 6| Step: 11
Training loss: 2.355287551879883
Validation loss: 2.290885160046239

Epoch: 6| Step: 12
Training loss: 2.1338882446289062
Validation loss: 2.2909817285435174

Epoch: 6| Step: 13
Training loss: 2.4362025260925293
Validation loss: 2.2991175933550765

Epoch: 70| Step: 0
Training loss: 2.1967508792877197
Validation loss: 2.3124880970165296

Epoch: 6| Step: 1
Training loss: 3.0989468097686768
Validation loss: 2.323793808619181

Epoch: 6| Step: 2
Training loss: 3.1119565963745117
Validation loss: 2.3334471820503153

Epoch: 6| Step: 3
Training loss: 2.9937939643859863
Validation loss: 2.3414255701085573

Epoch: 6| Step: 4
Training loss: 2.2007908821105957
Validation loss: 2.3428280891910678

Epoch: 6| Step: 5
Training loss: 2.327360153198242
Validation loss: 2.334196711099276

Epoch: 6| Step: 6
Training loss: 2.0586960315704346
Validation loss: 2.3480206279344458

Epoch: 6| Step: 7
Training loss: 2.765718936920166
Validation loss: 2.400760394270702

Epoch: 6| Step: 8
Training loss: 2.7211780548095703
Validation loss: 2.460740291944114

Epoch: 6| Step: 9
Training loss: 2.822554588317871
Validation loss: 2.5264200113152944

Epoch: 6| Step: 10
Training loss: 2.6266160011291504
Validation loss: 2.50822570759763

Epoch: 6| Step: 11
Training loss: 2.6352827548980713
Validation loss: 2.5207690449171167

Epoch: 6| Step: 12
Training loss: 2.571335792541504
Validation loss: 2.4544193795932236

Epoch: 6| Step: 13
Training loss: 2.431983709335327
Validation loss: 2.378224653582419

Epoch: 71| Step: 0
Training loss: 3.185330629348755
Validation loss: 2.3427701996218775

Epoch: 6| Step: 1
Training loss: 2.4690473079681396
Validation loss: 2.319337183429349

Epoch: 6| Step: 2
Training loss: 2.69826340675354
Validation loss: 2.3234338311738867

Epoch: 6| Step: 3
Training loss: 2.1184329986572266
Validation loss: 2.361570913304565

Epoch: 6| Step: 4
Training loss: 2.382260322570801
Validation loss: 2.3918058615858837

Epoch: 6| Step: 5
Training loss: 2.7667713165283203
Validation loss: 2.424361490434216

Epoch: 6| Step: 6
Training loss: 2.7525458335876465
Validation loss: 2.4202169269643803

Epoch: 6| Step: 7
Training loss: 2.4277071952819824
Validation loss: 2.37691088902053

Epoch: 6| Step: 8
Training loss: 2.5648996829986572
Validation loss: 2.359398083020282

Epoch: 6| Step: 9
Training loss: 2.4810686111450195
Validation loss: 2.335230419712682

Epoch: 6| Step: 10
Training loss: 3.188532590866089
Validation loss: 2.333667749999672

Epoch: 6| Step: 11
Training loss: 1.9472503662109375
Validation loss: 2.3294280190621652

Epoch: 6| Step: 12
Training loss: 2.969320774078369
Validation loss: 2.3265439848746023

Epoch: 6| Step: 13
Training loss: 2.8974499702453613
Validation loss: 2.332259237125356

Epoch: 72| Step: 0
Training loss: 2.7074694633483887
Validation loss: 2.338520872977472

Epoch: 6| Step: 1
Training loss: 2.396967887878418
Validation loss: 2.341949814109392

Epoch: 6| Step: 2
Training loss: 2.806195020675659
Validation loss: 2.3496079701249317

Epoch: 6| Step: 3
Training loss: 2.38091778755188
Validation loss: 2.372040735777988

Epoch: 6| Step: 4
Training loss: 2.7929277420043945
Validation loss: 2.3828598581334597

Epoch: 6| Step: 5
Training loss: 2.582291603088379
Validation loss: 2.403552004086074

Epoch: 6| Step: 6
Training loss: 2.5836992263793945
Validation loss: 2.41041632621519

Epoch: 6| Step: 7
Training loss: 2.677588701248169
Validation loss: 2.3965582693776777

Epoch: 6| Step: 8
Training loss: 2.370296001434326
Validation loss: 2.3725748779953166

Epoch: 6| Step: 9
Training loss: 2.963167190551758
Validation loss: 2.354411271310622

Epoch: 6| Step: 10
Training loss: 2.776761054992676
Validation loss: 2.3171568839780745

Epoch: 6| Step: 11
Training loss: 1.8636362552642822
Validation loss: 2.315982694266945

Epoch: 6| Step: 12
Training loss: 2.731287956237793
Validation loss: 2.304853449585617

Epoch: 6| Step: 13
Training loss: 2.6792373657226562
Validation loss: 2.295189198627267

Epoch: 73| Step: 0
Training loss: 2.9174351692199707
Validation loss: 2.2948275817337858

Epoch: 6| Step: 1
Training loss: 2.58585262298584
Validation loss: 2.300684400784072

Epoch: 6| Step: 2
Training loss: 2.365819215774536
Validation loss: 2.333152383886358

Epoch: 6| Step: 3
Training loss: 2.616122245788574
Validation loss: 2.3577551495644355

Epoch: 6| Step: 4
Training loss: 2.0459957122802734
Validation loss: 2.383659578138782

Epoch: 6| Step: 5
Training loss: 3.030299663543701
Validation loss: 2.3783889291107014

Epoch: 6| Step: 6
Training loss: 3.2087016105651855
Validation loss: 2.3448863208934827

Epoch: 6| Step: 7
Training loss: 2.667100429534912
Validation loss: 2.3248855157565047

Epoch: 6| Step: 8
Training loss: 2.9540624618530273
Validation loss: 2.303577576914141

Epoch: 6| Step: 9
Training loss: 2.7214980125427246
Validation loss: 2.2948828179349183

Epoch: 6| Step: 10
Training loss: 1.593864917755127
Validation loss: 2.2929932455862723

Epoch: 6| Step: 11
Training loss: 1.743529200553894
Validation loss: 2.2918215208156134

Epoch: 6| Step: 12
Training loss: 3.1207005977630615
Validation loss: 2.3037483845987627

Epoch: 6| Step: 13
Training loss: 3.0180296897888184
Validation loss: 2.3169857494292723

Epoch: 74| Step: 0
Training loss: 2.992619037628174
Validation loss: 2.343139022909185

Epoch: 6| Step: 1
Training loss: 3.025664806365967
Validation loss: 2.367092288950438

Epoch: 6| Step: 2
Training loss: 2.2661054134368896
Validation loss: 2.390668951055055

Epoch: 6| Step: 3
Training loss: 2.739508867263794
Validation loss: 2.402480104918121

Epoch: 6| Step: 4
Training loss: 2.431082010269165
Validation loss: 2.390269874244608

Epoch: 6| Step: 5
Training loss: 2.240800619125366
Validation loss: 2.3770765053328646

Epoch: 6| Step: 6
Training loss: 3.169426441192627
Validation loss: 2.370490220285231

Epoch: 6| Step: 7
Training loss: 2.238041400909424
Validation loss: 2.3518342100163943

Epoch: 6| Step: 8
Training loss: 2.1575851440429688
Validation loss: 2.3256176415310112

Epoch: 6| Step: 9
Training loss: 2.645064353942871
Validation loss: 2.3015346040007887

Epoch: 6| Step: 10
Training loss: 2.306666851043701
Validation loss: 2.2869240135274906

Epoch: 6| Step: 11
Training loss: 2.1898670196533203
Validation loss: 2.276270781793902

Epoch: 6| Step: 12
Training loss: 2.3567285537719727
Validation loss: 2.2710365890174784

Epoch: 6| Step: 13
Training loss: 3.689258575439453
Validation loss: 2.2743995984395347

Epoch: 75| Step: 0
Training loss: 1.9327445030212402
Validation loss: 2.2728003558292182

Epoch: 6| Step: 1
Training loss: 1.8408522605895996
Validation loss: 2.264652572652345

Epoch: 6| Step: 2
Training loss: 2.15427565574646
Validation loss: 2.277774715936312

Epoch: 6| Step: 3
Training loss: 2.6161067485809326
Validation loss: 2.2974793628979753

Epoch: 6| Step: 4
Training loss: 2.270134210586548
Validation loss: 2.3179333645810365

Epoch: 6| Step: 5
Training loss: 3.1315383911132812
Validation loss: 2.333774633305047

Epoch: 6| Step: 6
Training loss: 3.089439868927002
Validation loss: 2.336797688596992

Epoch: 6| Step: 7
Training loss: 2.863097667694092
Validation loss: 2.349199177116476

Epoch: 6| Step: 8
Training loss: 3.095017194747925
Validation loss: 2.356690995154842

Epoch: 6| Step: 9
Training loss: 1.9420907497406006
Validation loss: 2.358556802554797

Epoch: 6| Step: 10
Training loss: 2.8664331436157227
Validation loss: 2.3509080076730378

Epoch: 6| Step: 11
Training loss: 2.3655953407287598
Validation loss: 2.331455167903695

Epoch: 6| Step: 12
Training loss: 2.9827520847320557
Validation loss: 2.3152966114782516

Epoch: 6| Step: 13
Training loss: 2.782658100128174
Validation loss: 2.2937540956722793

Epoch: 76| Step: 0
Training loss: 3.028454303741455
Validation loss: 2.2847002475492415

Epoch: 6| Step: 1
Training loss: 2.2095143795013428
Validation loss: 2.2673912458522345

Epoch: 6| Step: 2
Training loss: 2.31068754196167
Validation loss: 2.2637007057025866

Epoch: 6| Step: 3
Training loss: 2.7024827003479004
Validation loss: 2.2497153282165527

Epoch: 6| Step: 4
Training loss: 1.4809668064117432
Validation loss: 2.2508055445968465

Epoch: 6| Step: 5
Training loss: 2.685516595840454
Validation loss: 2.2471346855163574

Epoch: 6| Step: 6
Training loss: 2.559239387512207
Validation loss: 2.2508298261191255

Epoch: 6| Step: 7
Training loss: 2.5925662517547607
Validation loss: 2.254740197171447

Epoch: 6| Step: 8
Training loss: 3.408599615097046
Validation loss: 2.2542220136170745

Epoch: 6| Step: 9
Training loss: 2.035783290863037
Validation loss: 2.258322410686042

Epoch: 6| Step: 10
Training loss: 2.3123087882995605
Validation loss: 2.2693912393303326

Epoch: 6| Step: 11
Training loss: 3.1451051235198975
Validation loss: 2.290865013676305

Epoch: 6| Step: 12
Training loss: 2.5819091796875
Validation loss: 2.31235433137545

Epoch: 6| Step: 13
Training loss: 2.5601956844329834
Validation loss: 2.326522942512266

Epoch: 77| Step: 0
Training loss: 3.116102695465088
Validation loss: 2.379558901632986

Epoch: 6| Step: 1
Training loss: 2.612863779067993
Validation loss: 2.4045123592499764

Epoch: 6| Step: 2
Training loss: 1.97248375415802
Validation loss: 2.4131070900988836

Epoch: 6| Step: 3
Training loss: 3.0488147735595703
Validation loss: 2.404883115522323

Epoch: 6| Step: 4
Training loss: 2.4153571128845215
Validation loss: 2.3750406337040726

Epoch: 6| Step: 5
Training loss: 1.9165925979614258
Validation loss: 2.3421759656680528

Epoch: 6| Step: 6
Training loss: 2.0409960746765137
Validation loss: 2.3103692967404603

Epoch: 6| Step: 7
Training loss: 3.2558956146240234
Validation loss: 2.2861527063513316

Epoch: 6| Step: 8
Training loss: 3.096705913543701
Validation loss: 2.2652095466531734

Epoch: 6| Step: 9
Training loss: 2.210023880004883
Validation loss: 2.252728933929115

Epoch: 6| Step: 10
Training loss: 2.7379276752471924
Validation loss: 2.255020485129408

Epoch: 6| Step: 11
Training loss: 2.597101926803589
Validation loss: 2.2547017451255553

Epoch: 6| Step: 12
Training loss: 2.3387789726257324
Validation loss: 2.247720415874194

Epoch: 6| Step: 13
Training loss: 2.8429887294769287
Validation loss: 2.2464587688446045

Epoch: 78| Step: 0
Training loss: 2.632380962371826
Validation loss: 2.245671251768707

Epoch: 6| Step: 1
Training loss: 2.812722682952881
Validation loss: 2.2503918704166206

Epoch: 6| Step: 2
Training loss: 1.9613028764724731
Validation loss: 2.247405280349075

Epoch: 6| Step: 3
Training loss: 3.3299336433410645
Validation loss: 2.253411723721412

Epoch: 6| Step: 4
Training loss: 1.893576741218567
Validation loss: 2.2524808991339897

Epoch: 6| Step: 5
Training loss: 2.0392990112304688
Validation loss: 2.253135447861046

Epoch: 6| Step: 6
Training loss: 2.13236141204834
Validation loss: 2.2505309671484013

Epoch: 6| Step: 7
Training loss: 2.598451614379883
Validation loss: 2.2520692374116633

Epoch: 6| Step: 8
Training loss: 2.420994281768799
Validation loss: 2.2534379882197224

Epoch: 6| Step: 9
Training loss: 2.776679515838623
Validation loss: 2.266556129660658

Epoch: 6| Step: 10
Training loss: 2.545461416244507
Validation loss: 2.2605956985104467

Epoch: 6| Step: 11
Training loss: 2.5858235359191895
Validation loss: 2.270641403813516

Epoch: 6| Step: 12
Training loss: 3.1769299507141113
Validation loss: 2.2746052357458297

Epoch: 6| Step: 13
Training loss: 2.8617544174194336
Validation loss: 2.2724253464770574

Epoch: 79| Step: 0
Training loss: 3.082292079925537
Validation loss: 2.276446048931409

Epoch: 6| Step: 1
Training loss: 2.8449478149414062
Validation loss: 2.272076496513941

Epoch: 6| Step: 2
Training loss: 2.5772812366485596
Validation loss: 2.278426544640654

Epoch: 6| Step: 3
Training loss: 2.737212657928467
Validation loss: 2.2716678970603534

Epoch: 6| Step: 4
Training loss: 2.525784492492676
Validation loss: 2.2691305170777025

Epoch: 6| Step: 5
Training loss: 2.3432140350341797
Validation loss: 2.2744622666348695

Epoch: 6| Step: 6
Training loss: 2.3119606971740723
Validation loss: 2.286159256453155

Epoch: 6| Step: 7
Training loss: 3.1179566383361816
Validation loss: 2.280687911536104

Epoch: 6| Step: 8
Training loss: 1.8084176778793335
Validation loss: 2.2823582515921643

Epoch: 6| Step: 9
Training loss: 2.4826126098632812
Validation loss: 2.279237352391725

Epoch: 6| Step: 10
Training loss: 2.051541328430176
Validation loss: 2.290583710516653

Epoch: 6| Step: 11
Training loss: 2.0653295516967773
Validation loss: 2.281379589470484

Epoch: 6| Step: 12
Training loss: 2.5361099243164062
Validation loss: 2.2658719683206208

Epoch: 6| Step: 13
Training loss: 3.4797043800354004
Validation loss: 2.257777924178749

Epoch: 80| Step: 0
Training loss: 2.1618752479553223
Validation loss: 2.2490406933651177

Epoch: 6| Step: 1
Training loss: 2.862126111984253
Validation loss: 2.2430054910721315

Epoch: 6| Step: 2
Training loss: 2.3273730278015137
Validation loss: 2.248525604124992

Epoch: 6| Step: 3
Training loss: 2.802029609680176
Validation loss: 2.2500696387342227

Epoch: 6| Step: 4
Training loss: 2.3307595252990723
Validation loss: 2.248750901991321

Epoch: 6| Step: 5
Training loss: 2.885556221008301
Validation loss: 2.254365172437442

Epoch: 6| Step: 6
Training loss: 2.6534180641174316
Validation loss: 2.248668191253498

Epoch: 6| Step: 7
Training loss: 2.747237205505371
Validation loss: 2.2415366121517715

Epoch: 6| Step: 8
Training loss: 2.2043750286102295
Validation loss: 2.25314712396232

Epoch: 6| Step: 9
Training loss: 2.4090232849121094
Validation loss: 2.2540910269624446

Epoch: 6| Step: 10
Training loss: 2.75344181060791
Validation loss: 2.273629779456764

Epoch: 6| Step: 11
Training loss: 2.684067726135254
Validation loss: 2.265899024983888

Epoch: 6| Step: 12
Training loss: 2.043090343475342
Validation loss: 2.280216245241063

Epoch: 6| Step: 13
Training loss: 2.6947007179260254
Validation loss: 2.2962853165083033

Epoch: 81| Step: 0
Training loss: 2.5908079147338867
Validation loss: 2.3048684045832646

Epoch: 6| Step: 1
Training loss: 2.3507401943206787
Validation loss: 2.2893438364869807

Epoch: 6| Step: 2
Training loss: 1.994119644165039
Validation loss: 2.2890704242132043

Epoch: 6| Step: 3
Training loss: 2.1972899436950684
Validation loss: 2.285105700133949

Epoch: 6| Step: 4
Training loss: 2.5811147689819336
Validation loss: 2.2882740036133797

Epoch: 6| Step: 5
Training loss: 2.8078453540802
Validation loss: 2.2975927681051274

Epoch: 6| Step: 6
Training loss: 2.528977155685425
Validation loss: 2.2797214446529264

Epoch: 6| Step: 7
Training loss: 3.261202335357666
Validation loss: 2.2544108193407775

Epoch: 6| Step: 8
Training loss: 2.1659584045410156
Validation loss: 2.2529730078994588

Epoch: 6| Step: 9
Training loss: 2.053576946258545
Validation loss: 2.2433044051611297

Epoch: 6| Step: 10
Training loss: 2.4662530422210693
Validation loss: 2.2435601347236225

Epoch: 6| Step: 11
Training loss: 2.7441773414611816
Validation loss: 2.2338063716888428

Epoch: 6| Step: 12
Training loss: 3.1208441257476807
Validation loss: 2.2391970055077666

Epoch: 6| Step: 13
Training loss: 2.626249074935913
Validation loss: 2.2352409875521095

Epoch: 82| Step: 0
Training loss: 2.6815829277038574
Validation loss: 2.23286041649439

Epoch: 6| Step: 1
Training loss: 2.6978678703308105
Validation loss: 2.2372826965906287

Epoch: 6| Step: 2
Training loss: 2.3597686290740967
Validation loss: 2.2412990677741265

Epoch: 6| Step: 3
Training loss: 1.942510724067688
Validation loss: 2.244512996365947

Epoch: 6| Step: 4
Training loss: 2.660855293273926
Validation loss: 2.255206077329574

Epoch: 6| Step: 5
Training loss: 2.937459945678711
Validation loss: 2.2576495601284887

Epoch: 6| Step: 6
Training loss: 3.1383068561553955
Validation loss: 2.257395778932879

Epoch: 6| Step: 7
Training loss: 1.7832648754119873
Validation loss: 2.252867364114331

Epoch: 6| Step: 8
Training loss: 2.4555320739746094
Validation loss: 2.254144867261251

Epoch: 6| Step: 9
Training loss: 2.515134334564209
Validation loss: 2.2650593634574645

Epoch: 6| Step: 10
Training loss: 2.9204463958740234
Validation loss: 2.250904134524766

Epoch: 6| Step: 11
Training loss: 2.449063777923584
Validation loss: 2.260436714336436

Epoch: 6| Step: 12
Training loss: 2.6049747467041016
Validation loss: 2.2613300149158766

Epoch: 6| Step: 13
Training loss: 2.0320775508880615
Validation loss: 2.2668111093582644

Epoch: 83| Step: 0
Training loss: 3.1836962699890137
Validation loss: 2.2565700597660516

Epoch: 6| Step: 1
Training loss: 2.674121618270874
Validation loss: 2.247096589816514

Epoch: 6| Step: 2
Training loss: 1.6542693376541138
Validation loss: 2.246054789071442

Epoch: 6| Step: 3
Training loss: 2.272017240524292
Validation loss: 2.23420117234671

Epoch: 6| Step: 4
Training loss: 2.5811009407043457
Validation loss: 2.24281979632634

Epoch: 6| Step: 5
Training loss: 2.6194956302642822
Validation loss: 2.2455906791071736

Epoch: 6| Step: 6
Training loss: 2.2221641540527344
Validation loss: 2.251298894164383

Epoch: 6| Step: 7
Training loss: 2.609715461730957
Validation loss: 2.2500967594885055

Epoch: 6| Step: 8
Training loss: 2.3948171138763428
Validation loss: 2.2442013922558037

Epoch: 6| Step: 9
Training loss: 2.390889883041382
Validation loss: 2.2474351365079164

Epoch: 6| Step: 10
Training loss: 2.181380033493042
Validation loss: 2.2519975426376506

Epoch: 6| Step: 11
Training loss: 2.7173397541046143
Validation loss: 2.242716666190855

Epoch: 6| Step: 12
Training loss: 3.0409088134765625
Validation loss: 2.2430607759824364

Epoch: 6| Step: 13
Training loss: 2.883307456970215
Validation loss: 2.2351525034955753

Epoch: 84| Step: 0
Training loss: 2.0721559524536133
Validation loss: 2.230050353593724

Epoch: 6| Step: 1
Training loss: 1.5100243091583252
Validation loss: 2.228992704422243

Epoch: 6| Step: 2
Training loss: 2.986812114715576
Validation loss: 2.2258233895865818

Epoch: 6| Step: 3
Training loss: 2.2753162384033203
Validation loss: 2.220869243785899

Epoch: 6| Step: 4
Training loss: 2.8518857955932617
Validation loss: 2.227175040911603

Epoch: 6| Step: 5
Training loss: 2.1822285652160645
Validation loss: 2.2275664870456984

Epoch: 6| Step: 6
Training loss: 2.3282084465026855
Validation loss: 2.228186268960276

Epoch: 6| Step: 7
Training loss: 2.885251998901367
Validation loss: 2.228678416180354

Epoch: 6| Step: 8
Training loss: 2.8987271785736084
Validation loss: 2.224357533198531

Epoch: 6| Step: 9
Training loss: 2.5996923446655273
Validation loss: 2.2376540143002748

Epoch: 6| Step: 10
Training loss: 2.54559326171875
Validation loss: 2.2644895904807636

Epoch: 6| Step: 11
Training loss: 2.68863582611084
Validation loss: 2.2917481827479538

Epoch: 6| Step: 12
Training loss: 2.8518290519714355
Validation loss: 2.2991715913177817

Epoch: 6| Step: 13
Training loss: 2.693633556365967
Validation loss: 2.2936252137666107

Epoch: 85| Step: 0
Training loss: 1.731300950050354
Validation loss: 2.3021216879608812

Epoch: 6| Step: 1
Training loss: 2.264328956604004
Validation loss: 2.2814861061752483

Epoch: 6| Step: 2
Training loss: 2.0586671829223633
Validation loss: 2.2593087098931752

Epoch: 6| Step: 3
Training loss: 2.2902727127075195
Validation loss: 2.2624034650864138

Epoch: 6| Step: 4
Training loss: 2.2646164894104004
Validation loss: 2.2509789210493847

Epoch: 6| Step: 5
Training loss: 2.3851308822631836
Validation loss: 2.2525995956954135

Epoch: 6| Step: 6
Training loss: 3.245029926300049
Validation loss: 2.246177968158517

Epoch: 6| Step: 7
Training loss: 2.8035998344421387
Validation loss: 2.2424563566843667

Epoch: 6| Step: 8
Training loss: 2.6724064350128174
Validation loss: 2.2472548869348343

Epoch: 6| Step: 9
Training loss: 2.426180839538574
Validation loss: 2.2384883203814105

Epoch: 6| Step: 10
Training loss: 2.935698986053467
Validation loss: 2.254929873251146

Epoch: 6| Step: 11
Training loss: 3.029301404953003
Validation loss: 2.2512791579769504

Epoch: 6| Step: 12
Training loss: 2.808666944503784
Validation loss: 2.2475226899628997

Epoch: 6| Step: 13
Training loss: 2.102180004119873
Validation loss: 2.2377060562051754

Epoch: 86| Step: 0
Training loss: 2.703197717666626
Validation loss: 2.248761292426817

Epoch: 6| Step: 1
Training loss: 2.9542150497436523
Validation loss: 2.2507585889549664

Epoch: 6| Step: 2
Training loss: 2.2820041179656982
Validation loss: 2.266820446137459

Epoch: 6| Step: 3
Training loss: 2.385775566101074
Validation loss: 2.266406346392888

Epoch: 6| Step: 4
Training loss: 2.169118642807007
Validation loss: 2.2555981925738755

Epoch: 6| Step: 5
Training loss: 3.007645845413208
Validation loss: 2.2652328193828626

Epoch: 6| Step: 6
Training loss: 2.9062905311584473
Validation loss: 2.2524456875298613

Epoch: 6| Step: 7
Training loss: 2.125251293182373
Validation loss: 2.241750406962569

Epoch: 6| Step: 8
Training loss: 2.117157459259033
Validation loss: 2.2305140931119203

Epoch: 6| Step: 9
Training loss: 2.9767963886260986
Validation loss: 2.2297162086732927

Epoch: 6| Step: 10
Training loss: 2.23852801322937
Validation loss: 2.220691737308297

Epoch: 6| Step: 11
Training loss: 2.460078716278076
Validation loss: 2.211739642645723

Epoch: 6| Step: 12
Training loss: 2.7579128742218018
Validation loss: 2.2172457248933855

Epoch: 6| Step: 13
Training loss: 1.9295226335525513
Validation loss: 2.2177131868177846

Epoch: 87| Step: 0
Training loss: 2.0805015563964844
Validation loss: 2.2210882658599527

Epoch: 6| Step: 1
Training loss: 1.786468505859375
Validation loss: 2.2247638856211016

Epoch: 6| Step: 2
Training loss: 2.5356554985046387
Validation loss: 2.2377426906298568

Epoch: 6| Step: 3
Training loss: 2.6046359539031982
Validation loss: 2.2365955050273607

Epoch: 6| Step: 4
Training loss: 2.1827635765075684
Validation loss: 2.236270466158467

Epoch: 6| Step: 5
Training loss: 2.865971088409424
Validation loss: 2.256086628924134

Epoch: 6| Step: 6
Training loss: 2.469695806503296
Validation loss: 2.2525585236087924

Epoch: 6| Step: 7
Training loss: 2.3993663787841797
Validation loss: 2.2473876143014557

Epoch: 6| Step: 8
Training loss: 3.108238458633423
Validation loss: 2.2496040559584096

Epoch: 6| Step: 9
Training loss: 1.8986451625823975
Validation loss: 2.2601421879183863

Epoch: 6| Step: 10
Training loss: 2.724742889404297
Validation loss: 2.266308225611205

Epoch: 6| Step: 11
Training loss: 2.8937387466430664
Validation loss: 2.275903176235896

Epoch: 6| Step: 12
Training loss: 3.009222984313965
Validation loss: 2.289341890683738

Epoch: 6| Step: 13
Training loss: 2.7249555587768555
Validation loss: 2.2925689220428467

Epoch: 88| Step: 0
Training loss: 2.5149240493774414
Validation loss: 2.297199933759628

Epoch: 6| Step: 1
Training loss: 2.264380693435669
Validation loss: 2.272506542103265

Epoch: 6| Step: 2
Training loss: 1.6306753158569336
Validation loss: 2.235723708265571

Epoch: 6| Step: 3
Training loss: 2.8529679775238037
Validation loss: 2.231658427946029

Epoch: 6| Step: 4
Training loss: 2.6336700916290283
Validation loss: 2.2251823256092687

Epoch: 6| Step: 5
Training loss: 2.7580816745758057
Validation loss: 2.2218277736376693

Epoch: 6| Step: 6
Training loss: 2.5258469581604004
Validation loss: 2.231969943610571

Epoch: 6| Step: 7
Training loss: 2.7372775077819824
Validation loss: 2.2401637338822886

Epoch: 6| Step: 8
Training loss: 2.709907054901123
Validation loss: 2.2462741046823482

Epoch: 6| Step: 9
Training loss: 2.557079792022705
Validation loss: 2.2435418892932195

Epoch: 6| Step: 10
Training loss: 2.0584611892700195
Validation loss: 2.279620282111629

Epoch: 6| Step: 11
Training loss: 2.6937570571899414
Validation loss: 2.2833446046357513

Epoch: 6| Step: 12
Training loss: 2.6928043365478516
Validation loss: 2.285932760084829

Epoch: 6| Step: 13
Training loss: 2.750796318054199
Validation loss: 2.2979527583686252

Epoch: 89| Step: 0
Training loss: 1.9917266368865967
Validation loss: 2.287725422971992

Epoch: 6| Step: 1
Training loss: 2.5883290767669678
Validation loss: 2.2707850189619165

Epoch: 6| Step: 2
Training loss: 2.4603357315063477
Validation loss: 2.2644058478775846

Epoch: 6| Step: 3
Training loss: 2.427699565887451
Validation loss: 2.2589532175371723

Epoch: 6| Step: 4
Training loss: 2.6080026626586914
Validation loss: 2.2510300759346253

Epoch: 6| Step: 5
Training loss: 2.5581722259521484
Validation loss: 2.259394835400325

Epoch: 6| Step: 6
Training loss: 3.710477113723755
Validation loss: 2.2554815892250306

Epoch: 6| Step: 7
Training loss: 2.3980703353881836
Validation loss: 2.25641538763559

Epoch: 6| Step: 8
Training loss: 2.1312379837036133
Validation loss: 2.241245254393547

Epoch: 6| Step: 9
Training loss: 2.3906095027923584
Validation loss: 2.2353531852845223

Epoch: 6| Step: 10
Training loss: 3.2069263458251953
Validation loss: 2.2276038226260932

Epoch: 6| Step: 11
Training loss: 1.8070716857910156
Validation loss: 2.2102074674380723

Epoch: 6| Step: 12
Training loss: 2.516240119934082
Validation loss: 2.213000305237309

Epoch: 6| Step: 13
Training loss: 2.2973058223724365
Validation loss: 2.215281589056856

Epoch: 90| Step: 0
Training loss: 2.87233304977417
Validation loss: 2.2176632727346113

Epoch: 6| Step: 1
Training loss: 2.2941277027130127
Validation loss: 2.239025262094313

Epoch: 6| Step: 2
Training loss: 3.0036673545837402
Validation loss: 2.241033605349961

Epoch: 6| Step: 3
Training loss: 2.2865920066833496
Validation loss: 2.24092609395263

Epoch: 6| Step: 4
Training loss: 2.3810973167419434
Validation loss: 2.2356276435236775

Epoch: 6| Step: 5
Training loss: 2.2991886138916016
Validation loss: 2.2470126152038574

Epoch: 6| Step: 6
Training loss: 2.2021849155426025
Validation loss: 2.2364621508506035

Epoch: 6| Step: 7
Training loss: 2.5602011680603027
Validation loss: 2.2195949221170075

Epoch: 6| Step: 8
Training loss: 2.715596914291382
Validation loss: 2.1988942520592802

Epoch: 6| Step: 9
Training loss: 2.6140880584716797
Validation loss: 2.2005302700945126

Epoch: 6| Step: 10
Training loss: 2.5116543769836426
Validation loss: 2.205551255133844

Epoch: 6| Step: 11
Training loss: 2.5943002700805664
Validation loss: 2.2065364801755516

Epoch: 6| Step: 12
Training loss: 2.2615866661071777
Validation loss: 2.210298915063181

Epoch: 6| Step: 13
Training loss: 2.680746078491211
Validation loss: 2.2143633006721415

Epoch: 91| Step: 0
Training loss: 2.8443613052368164
Validation loss: 2.212626603341872

Epoch: 6| Step: 1
Training loss: 2.499934673309326
Validation loss: 2.2117463286205004

Epoch: 6| Step: 2
Training loss: 2.1893081665039062
Validation loss: 2.219681837225473

Epoch: 6| Step: 3
Training loss: 2.0953991413116455
Validation loss: 2.2242631681503786

Epoch: 6| Step: 4
Training loss: 2.7521560192108154
Validation loss: 2.243207057317098

Epoch: 6| Step: 5
Training loss: 2.3924341201782227
Validation loss: 2.245109796524048

Epoch: 6| Step: 6
Training loss: 2.3768537044525146
Validation loss: 2.2624072080017417

Epoch: 6| Step: 7
Training loss: 2.289098024368286
Validation loss: 2.2581893705552623

Epoch: 6| Step: 8
Training loss: 3.0176780223846436
Validation loss: 2.2666372740140526

Epoch: 6| Step: 9
Training loss: 1.7856351137161255
Validation loss: 2.283424650469134

Epoch: 6| Step: 10
Training loss: 2.5209264755249023
Validation loss: 2.312492416751

Epoch: 6| Step: 11
Training loss: 2.7937259674072266
Validation loss: 2.3135105204838577

Epoch: 6| Step: 12
Training loss: 3.004199981689453
Validation loss: 2.2729549331049763

Epoch: 6| Step: 13
Training loss: 2.552658796310425
Validation loss: 2.2298047440026396

Epoch: 92| Step: 0
Training loss: 2.2329537868499756
Validation loss: 2.2116060641504105

Epoch: 6| Step: 1
Training loss: 3.016228199005127
Validation loss: 2.212274205300116

Epoch: 6| Step: 2
Training loss: 2.370171546936035
Validation loss: 2.207765240823069

Epoch: 6| Step: 3
Training loss: 1.8648436069488525
Validation loss: 2.218606956543461

Epoch: 6| Step: 4
Training loss: 3.363952398300171
Validation loss: 2.220129697553573

Epoch: 6| Step: 5
Training loss: 2.4987356662750244
Validation loss: 2.214513576158913

Epoch: 6| Step: 6
Training loss: 2.611626386642456
Validation loss: 2.2123779199456655

Epoch: 6| Step: 7
Training loss: 3.1204986572265625
Validation loss: 2.2138065907262985

Epoch: 6| Step: 8
Training loss: 2.178333282470703
Validation loss: 2.2170813827104467

Epoch: 6| Step: 9
Training loss: 2.165853261947632
Validation loss: 2.209976757726362

Epoch: 6| Step: 10
Training loss: 3.1228339672088623
Validation loss: 2.2102212495701288

Epoch: 6| Step: 11
Training loss: 1.9336564540863037
Validation loss: 2.226762976697696

Epoch: 6| Step: 12
Training loss: 2.448275089263916
Validation loss: 2.234847112368512

Epoch: 6| Step: 13
Training loss: 1.968729853630066
Validation loss: 2.2567364643978816

Epoch: 93| Step: 0
Training loss: 2.2284634113311768
Validation loss: 2.2722120618307464

Epoch: 6| Step: 1
Training loss: 2.1292669773101807
Validation loss: 2.2709751321423437

Epoch: 6| Step: 2
Training loss: 2.0491294860839844
Validation loss: 2.238659389557377

Epoch: 6| Step: 3
Training loss: 2.40993595123291
Validation loss: 2.2155114553307973

Epoch: 6| Step: 4
Training loss: 2.2372829914093018
Validation loss: 2.1950110414976716

Epoch: 6| Step: 5
Training loss: 2.5045764446258545
Validation loss: 2.1993194139131935

Epoch: 6| Step: 6
Training loss: 2.5216612815856934
Validation loss: 2.192556212025304

Epoch: 6| Step: 7
Training loss: 2.5869557857513428
Validation loss: 2.196018326667047

Epoch: 6| Step: 8
Training loss: 2.5716965198516846
Validation loss: 2.202238949396277

Epoch: 6| Step: 9
Training loss: 2.7875142097473145
Validation loss: 2.200109194683772

Epoch: 6| Step: 10
Training loss: 2.5357179641723633
Validation loss: 2.2168024701456868

Epoch: 6| Step: 11
Training loss: 2.576573371887207
Validation loss: 2.2279674519774733

Epoch: 6| Step: 12
Training loss: 3.4540252685546875
Validation loss: 2.2454021438475578

Epoch: 6| Step: 13
Training loss: 2.733625650405884
Validation loss: 2.2395871326487553

Epoch: 94| Step: 0
Training loss: 2.598064422607422
Validation loss: 2.2385607022111134

Epoch: 6| Step: 1
Training loss: 1.9482905864715576
Validation loss: 2.238391204546857

Epoch: 6| Step: 2
Training loss: 3.38004207611084
Validation loss: 2.2391979643093642

Epoch: 6| Step: 3
Training loss: 2.237942934036255
Validation loss: 2.2451437621988277

Epoch: 6| Step: 4
Training loss: 2.074490785598755
Validation loss: 2.255026573775917

Epoch: 6| Step: 5
Training loss: 3.254812717437744
Validation loss: 2.2563550882442023

Epoch: 6| Step: 6
Training loss: 2.586838960647583
Validation loss: 2.272477198672551

Epoch: 6| Step: 7
Training loss: 1.883871078491211
Validation loss: 2.262522274448026

Epoch: 6| Step: 8
Training loss: 2.923112154006958
Validation loss: 2.2322429431382047

Epoch: 6| Step: 9
Training loss: 2.7113542556762695
Validation loss: 2.2162045855675974

Epoch: 6| Step: 10
Training loss: 2.3485336303710938
Validation loss: 2.2073891085963093

Epoch: 6| Step: 11
Training loss: 2.4945268630981445
Validation loss: 2.207496468738843

Epoch: 6| Step: 12
Training loss: 2.085480213165283
Validation loss: 2.2031203303285825

Epoch: 6| Step: 13
Training loss: 2.487112283706665
Validation loss: 2.202331127658967

Epoch: 95| Step: 0
Training loss: 2.4453630447387695
Validation loss: 2.2116212896121445

Epoch: 6| Step: 1
Training loss: 2.6827731132507324
Validation loss: 2.193736428855568

Epoch: 6| Step: 2
Training loss: 3.2070064544677734
Validation loss: 2.2001819841323362

Epoch: 6| Step: 3
Training loss: 2.9038453102111816
Validation loss: 2.2031610627328195

Epoch: 6| Step: 4
Training loss: 2.9161953926086426
Validation loss: 2.204166098307538

Epoch: 6| Step: 5
Training loss: 1.8996533155441284
Validation loss: 2.2081998471290833

Epoch: 6| Step: 6
Training loss: 2.961005449295044
Validation loss: 2.204679112280569

Epoch: 6| Step: 7
Training loss: 2.7883520126342773
Validation loss: 2.215717490001391

Epoch: 6| Step: 8
Training loss: 2.9547760486602783
Validation loss: 2.2191117681482786

Epoch: 6| Step: 9
Training loss: 1.5111011266708374
Validation loss: 2.2213368031286422

Epoch: 6| Step: 10
Training loss: 2.3851239681243896
Validation loss: 2.2327205340067544

Epoch: 6| Step: 11
Training loss: 2.2376317977905273
Validation loss: 2.244527309171615

Epoch: 6| Step: 12
Training loss: 1.3924388885498047
Validation loss: 2.261374532535512

Epoch: 6| Step: 13
Training loss: 2.4540724754333496
Validation loss: 2.2540781754319386

Epoch: 96| Step: 0
Training loss: 2.580162525177002
Validation loss: 2.2591782487848753

Epoch: 6| Step: 1
Training loss: 2.592907428741455
Validation loss: 2.2612418666962655

Epoch: 6| Step: 2
Training loss: 2.496577739715576
Validation loss: 2.2518050683441984

Epoch: 6| Step: 3
Training loss: 2.7235584259033203
Validation loss: 2.233716616066553

Epoch: 6| Step: 4
Training loss: 2.5963706970214844
Validation loss: 2.207925522199241

Epoch: 6| Step: 5
Training loss: 2.523557662963867
Validation loss: 2.195458414734051

Epoch: 6| Step: 6
Training loss: 2.2830052375793457
Validation loss: 2.1879227943317865

Epoch: 6| Step: 7
Training loss: 2.6789321899414062
Validation loss: 2.192593789869739

Epoch: 6| Step: 8
Training loss: 2.4351401329040527
Validation loss: 2.1830111652292232

Epoch: 6| Step: 9
Training loss: 2.4006190299987793
Validation loss: 2.1913968773298365

Epoch: 6| Step: 10
Training loss: 2.7611446380615234
Validation loss: 2.197834578893518

Epoch: 6| Step: 11
Training loss: 2.0095157623291016
Validation loss: 2.190918402005267

Epoch: 6| Step: 12
Training loss: 2.1795578002929688
Validation loss: 2.200484888527983

Epoch: 6| Step: 13
Training loss: 2.8726158142089844
Validation loss: 2.205847591482183

Epoch: 97| Step: 0
Training loss: 1.871294379234314
Validation loss: 2.201160405271797

Epoch: 6| Step: 1
Training loss: 2.78053879737854
Validation loss: 2.2030713199287333

Epoch: 6| Step: 2
Training loss: 2.129197597503662
Validation loss: 2.185305039087931

Epoch: 6| Step: 3
Training loss: 2.1349031925201416
Validation loss: 2.1896269065077587

Epoch: 6| Step: 4
Training loss: 2.4736666679382324
Validation loss: 2.195029568928544

Epoch: 6| Step: 5
Training loss: 2.7350027561187744
Validation loss: 2.2056175636988815

Epoch: 6| Step: 6
Training loss: 2.9318182468414307
Validation loss: 2.21126038541076

Epoch: 6| Step: 7
Training loss: 2.3188014030456543
Validation loss: 2.231574135441934

Epoch: 6| Step: 8
Training loss: 2.9015889167785645
Validation loss: 2.2531581130079044

Epoch: 6| Step: 9
Training loss: 2.1577882766723633
Validation loss: 2.252772041546401

Epoch: 6| Step: 10
Training loss: 2.709841251373291
Validation loss: 2.252166008436552

Epoch: 6| Step: 11
Training loss: 2.4788763523101807
Validation loss: 2.2483225714775825

Epoch: 6| Step: 12
Training loss: 2.833141326904297
Validation loss: 2.2308963985853296

Epoch: 6| Step: 13
Training loss: 2.4556124210357666
Validation loss: 2.2206542594458467

Epoch: 98| Step: 0
Training loss: 2.7937142848968506
Validation loss: 2.2120533040774766

Epoch: 6| Step: 1
Training loss: 2.9885129928588867
Validation loss: 2.2034644798565934

Epoch: 6| Step: 2
Training loss: 2.4083361625671387
Validation loss: 2.1945071207579745

Epoch: 6| Step: 3
Training loss: 2.345053195953369
Validation loss: 2.2034799181005007

Epoch: 6| Step: 4
Training loss: 2.5976619720458984
Validation loss: 2.2074455035630094

Epoch: 6| Step: 5
Training loss: 2.6380386352539062
Validation loss: 2.218887395756219

Epoch: 6| Step: 6
Training loss: 2.146838665008545
Validation loss: 2.21914848204582

Epoch: 6| Step: 7
Training loss: 2.304115056991577
Validation loss: 2.23280668258667

Epoch: 6| Step: 8
Training loss: 2.2756145000457764
Validation loss: 2.2309417365699686

Epoch: 6| Step: 9
Training loss: 2.378997802734375
Validation loss: 2.220864816378522

Epoch: 6| Step: 10
Training loss: 2.628901481628418
Validation loss: 2.21268541325805

Epoch: 6| Step: 11
Training loss: 2.3821587562561035
Validation loss: 2.209544731724647

Epoch: 6| Step: 12
Training loss: 2.204110860824585
Validation loss: 2.212191420216714

Epoch: 6| Step: 13
Training loss: 2.7729177474975586
Validation loss: 2.215318159390521

Epoch: 99| Step: 0
Training loss: 3.1493191719055176
Validation loss: 2.2203234998128747

Epoch: 6| Step: 1
Training loss: 1.0101189613342285
Validation loss: 2.231465842134209

Epoch: 6| Step: 2
Training loss: 2.7846617698669434
Validation loss: 2.234571995273713

Epoch: 6| Step: 3
Training loss: 2.596107006072998
Validation loss: 2.2395059216407036

Epoch: 6| Step: 4
Training loss: 3.086782455444336
Validation loss: 2.23913759826332

Epoch: 6| Step: 5
Training loss: 2.421529769897461
Validation loss: 2.2343751256183912

Epoch: 6| Step: 6
Training loss: 2.895094394683838
Validation loss: 2.2240627119618077

Epoch: 6| Step: 7
Training loss: 2.0910515785217285
Validation loss: 2.228727263789023

Epoch: 6| Step: 8
Training loss: 2.539430618286133
Validation loss: 2.221372135223881

Epoch: 6| Step: 9
Training loss: 2.7935914993286133
Validation loss: 2.2024775012846916

Epoch: 6| Step: 10
Training loss: 1.6192268133163452
Validation loss: 2.19369416083059

Epoch: 6| Step: 11
Training loss: 2.2605395317077637
Validation loss: 2.1850551533442673

Epoch: 6| Step: 12
Training loss: 2.5707101821899414
Validation loss: 2.1921017990317395

Epoch: 6| Step: 13
Training loss: 3.2967958450317383
Validation loss: 2.195555748478059

Epoch: 100| Step: 0
Training loss: 2.7121152877807617
Validation loss: 2.19034166489878

Epoch: 6| Step: 1
Training loss: 2.746634006500244
Validation loss: 2.191381421140445

Epoch: 6| Step: 2
Training loss: 2.462067127227783
Validation loss: 2.1920658516627487

Epoch: 6| Step: 3
Training loss: 1.4847996234893799
Validation loss: 2.2025596941671064

Epoch: 6| Step: 4
Training loss: 2.673882007598877
Validation loss: 2.197255116637035

Epoch: 6| Step: 5
Training loss: 2.626391887664795
Validation loss: 2.194268047168691

Epoch: 6| Step: 6
Training loss: 2.907376766204834
Validation loss: 2.1946131388346353

Epoch: 6| Step: 7
Training loss: 3.1269495487213135
Validation loss: 2.1825820566505514

Epoch: 6| Step: 8
Training loss: 2.061739206314087
Validation loss: 2.1814811075887373

Epoch: 6| Step: 9
Training loss: 1.9211902618408203
Validation loss: 2.178135892396332

Epoch: 6| Step: 10
Training loss: 1.951785922050476
Validation loss: 2.1805253054506037

Epoch: 6| Step: 11
Training loss: 2.927762508392334
Validation loss: 2.1800141001260407

Epoch: 6| Step: 12
Training loss: 2.46848464012146
Validation loss: 2.1829711967898953

Epoch: 6| Step: 13
Training loss: 2.6544570922851562
Validation loss: 2.1896409616675427

Epoch: 101| Step: 0
Training loss: 1.9603288173675537
Validation loss: 2.18415399776992

Epoch: 6| Step: 1
Training loss: 2.9542362689971924
Validation loss: 2.1872152051618023

Epoch: 6| Step: 2
Training loss: 2.9980480670928955
Validation loss: 2.188477511047035

Epoch: 6| Step: 3
Training loss: 1.7921597957611084
Validation loss: 2.1862379145878617

Epoch: 6| Step: 4
Training loss: 2.221641778945923
Validation loss: 2.194602756090062

Epoch: 6| Step: 5
Training loss: 2.3974556922912598
Validation loss: 2.1880306287478377

Epoch: 6| Step: 6
Training loss: 2.8935935497283936
Validation loss: 2.1940729566799697

Epoch: 6| Step: 7
Training loss: 2.3882651329040527
Validation loss: 2.195267908034786

Epoch: 6| Step: 8
Training loss: 2.8735713958740234
Validation loss: 2.2031922750575568

Epoch: 6| Step: 9
Training loss: 2.54140567779541
Validation loss: 2.2001759390677176

Epoch: 6| Step: 10
Training loss: 2.093179941177368
Validation loss: 2.194830289451025

Epoch: 6| Step: 11
Training loss: 3.1708035469055176
Validation loss: 2.1875264695895615

Epoch: 6| Step: 12
Training loss: 1.749630331993103
Validation loss: 2.183461643034412

Epoch: 6| Step: 13
Training loss: 2.4855716228485107
Validation loss: 2.1893015112928165

Epoch: 102| Step: 0
Training loss: 2.565363883972168
Validation loss: 2.18606355497914

Epoch: 6| Step: 1
Training loss: 1.9392019510269165
Validation loss: 2.1938575775392595

Epoch: 6| Step: 2
Training loss: 2.755159378051758
Validation loss: 2.1896886671743085

Epoch: 6| Step: 3
Training loss: 2.324634075164795
Validation loss: 2.18261444440452

Epoch: 6| Step: 4
Training loss: 3.147512197494507
Validation loss: 2.2132072576912503

Epoch: 6| Step: 5
Training loss: 2.402073383331299
Validation loss: 2.2074223923426803

Epoch: 6| Step: 6
Training loss: 2.7746992111206055
Validation loss: 2.209148955601518

Epoch: 6| Step: 7
Training loss: 2.781054735183716
Validation loss: 2.1975216442538845

Epoch: 6| Step: 8
Training loss: 2.069962978363037
Validation loss: 2.1864948490614533

Epoch: 6| Step: 9
Training loss: 2.3367044925689697
Validation loss: 2.1873964558365526

Epoch: 6| Step: 10
Training loss: 2.673666477203369
Validation loss: 2.1721447180676203

Epoch: 6| Step: 11
Training loss: 2.1007213592529297
Validation loss: 2.1672479567989225

Epoch: 6| Step: 12
Training loss: 2.2953078746795654
Validation loss: 2.1846806938930223

Epoch: 6| Step: 13
Training loss: 2.3403091430664062
Validation loss: 2.180421652332429

Epoch: 103| Step: 0
Training loss: 2.1311392784118652
Validation loss: 2.1825887451889696

Epoch: 6| Step: 1
Training loss: 2.4777722358703613
Validation loss: 2.187723569972541

Epoch: 6| Step: 2
Training loss: 2.5214314460754395
Validation loss: 2.1928328570499214

Epoch: 6| Step: 3
Training loss: 2.7595767974853516
Validation loss: 2.20466620691361

Epoch: 6| Step: 4
Training loss: 3.0695087909698486
Validation loss: 2.1962192263654483

Epoch: 6| Step: 5
Training loss: 2.627821922302246
Validation loss: 2.1868557494173766

Epoch: 6| Step: 6
Training loss: 2.6410138607025146
Validation loss: 2.1896889120019893

Epoch: 6| Step: 7
Training loss: 2.354623794555664
Validation loss: 2.191098085013769

Epoch: 6| Step: 8
Training loss: 2.3450117111206055
Validation loss: 2.1850615803913405

Epoch: 6| Step: 9
Training loss: 2.682445526123047
Validation loss: 2.1825750053569837

Epoch: 6| Step: 10
Training loss: 2.040046215057373
Validation loss: 2.1931106736583095

Epoch: 6| Step: 11
Training loss: 1.8581805229187012
Validation loss: 2.1977681524010113

Epoch: 6| Step: 12
Training loss: 2.1288907527923584
Validation loss: 2.2037353566897813

Epoch: 6| Step: 13
Training loss: 3.238898754119873
Validation loss: 2.188413543085898

Epoch: 104| Step: 0
Training loss: 2.792433261871338
Validation loss: 2.1676107991126274

Epoch: 6| Step: 1
Training loss: 3.020237445831299
Validation loss: 2.15652492097629

Epoch: 6| Step: 2
Training loss: 2.9110865592956543
Validation loss: 2.163659626437772

Epoch: 6| Step: 3
Training loss: 2.235356092453003
Validation loss: 2.167720957468915

Epoch: 6| Step: 4
Training loss: 1.8793156147003174
Validation loss: 2.178342637195382

Epoch: 6| Step: 5
Training loss: 1.7849273681640625
Validation loss: 2.1812405816970335

Epoch: 6| Step: 6
Training loss: 2.6407294273376465
Validation loss: 2.1808418689235562

Epoch: 6| Step: 7
Training loss: 2.1484029293060303
Validation loss: 2.1836338171394925

Epoch: 6| Step: 8
Training loss: 2.9642629623413086
Validation loss: 2.1657012047306186

Epoch: 6| Step: 9
Training loss: 3.3162832260131836
Validation loss: 2.1661419445468533

Epoch: 6| Step: 10
Training loss: 2.005101442337036
Validation loss: 2.1696310017698552

Epoch: 6| Step: 11
Training loss: 2.2006900310516357
Validation loss: 2.1846258512107273

Epoch: 6| Step: 12
Training loss: 2.1663639545440674
Validation loss: 2.1832330226898193

Epoch: 6| Step: 13
Training loss: 3.187488317489624
Validation loss: 2.222377105425763

Epoch: 105| Step: 0
Training loss: 2.0809178352355957
Validation loss: 2.2398868760754986

Epoch: 6| Step: 1
Training loss: 2.4845874309539795
Validation loss: 2.295915595946773

Epoch: 6| Step: 2
Training loss: 2.845720052719116
Validation loss: 2.3205374030656714

Epoch: 6| Step: 3
Training loss: 2.5816521644592285
Validation loss: 2.3427482830580844

Epoch: 6| Step: 4
Training loss: 1.5954792499542236
Validation loss: 2.3318321525409655

Epoch: 6| Step: 5
Training loss: 2.4409420490264893
Validation loss: 2.326302077180596

Epoch: 6| Step: 6
Training loss: 2.9735734462738037
Validation loss: 2.2932561648789274

Epoch: 6| Step: 7
Training loss: 2.775364875793457
Validation loss: 2.2803656824173464

Epoch: 6| Step: 8
Training loss: 2.461115598678589
Validation loss: 2.255911814269199

Epoch: 6| Step: 9
Training loss: 2.5086374282836914
Validation loss: 2.2246270384839786

Epoch: 6| Step: 10
Training loss: 3.1485042572021484
Validation loss: 2.203803652076311

Epoch: 6| Step: 11
Training loss: 2.274609327316284
Validation loss: 2.1813714581151165

Epoch: 6| Step: 12
Training loss: 2.251697301864624
Validation loss: 2.163425326347351

Epoch: 6| Step: 13
Training loss: 2.1275699138641357
Validation loss: 2.1645762946016047

Epoch: 106| Step: 0
Training loss: 2.1818315982818604
Validation loss: 2.1643987035238617

Epoch: 6| Step: 1
Training loss: 2.35856294631958
Validation loss: 2.155502683372908

Epoch: 6| Step: 2
Training loss: 2.823713779449463
Validation loss: 2.159454535412532

Epoch: 6| Step: 3
Training loss: 2.845475196838379
Validation loss: 2.1578883753027966

Epoch: 6| Step: 4
Training loss: 1.8555305004119873
Validation loss: 2.1550007097182737

Epoch: 6| Step: 5
Training loss: 2.708892822265625
Validation loss: 2.155102679806371

Epoch: 6| Step: 6
Training loss: 2.083237648010254
Validation loss: 2.1612770326675905

Epoch: 6| Step: 7
Training loss: 2.307748794555664
Validation loss: 2.1461090118654313

Epoch: 6| Step: 8
Training loss: 3.5798377990722656
Validation loss: 2.160682805122868

Epoch: 6| Step: 9
Training loss: 2.907787561416626
Validation loss: 2.1562912259050595

Epoch: 6| Step: 10
Training loss: 2.679439067840576
Validation loss: 2.1547465760220765

Epoch: 6| Step: 11
Training loss: 1.8138072490692139
Validation loss: 2.1551345394503687

Epoch: 6| Step: 12
Training loss: 2.0177717208862305
Validation loss: 2.17486967579011

Epoch: 6| Step: 13
Training loss: 1.9733657836914062
Validation loss: 2.2076621927240843

Epoch: 107| Step: 0
Training loss: 2.498034715652466
Validation loss: 2.2454608332726265

Epoch: 6| Step: 1
Training loss: 2.2299952507019043
Validation loss: 2.2482800560612834

Epoch: 6| Step: 2
Training loss: 2.901175022125244
Validation loss: 2.2612793753224034

Epoch: 6| Step: 3
Training loss: 3.088517189025879
Validation loss: 2.2200561800310687

Epoch: 6| Step: 4
Training loss: 2.5737404823303223
Validation loss: 2.177827558209819

Epoch: 6| Step: 5
Training loss: 1.8763822317123413
Validation loss: 2.1536548727302143

Epoch: 6| Step: 6
Training loss: 2.289895534515381
Validation loss: 2.144805900512203

Epoch: 6| Step: 7
Training loss: 2.5659704208374023
Validation loss: 2.148552917665051

Epoch: 6| Step: 8
Training loss: 2.937739849090576
Validation loss: 2.1484772979572253

Epoch: 6| Step: 9
Training loss: 2.1315009593963623
Validation loss: 2.1519235692998415

Epoch: 6| Step: 10
Training loss: 2.3799660205841064
Validation loss: 2.1550687436134583

Epoch: 6| Step: 11
Training loss: 2.813717842102051
Validation loss: 2.162615878607637

Epoch: 6| Step: 12
Training loss: 1.849884271621704
Validation loss: 2.165722830321199

Epoch: 6| Step: 13
Training loss: 2.598647117614746
Validation loss: 2.1728092752477175

Epoch: 108| Step: 0
Training loss: 2.6380395889282227
Validation loss: 2.186332328345186

Epoch: 6| Step: 1
Training loss: 2.3200345039367676
Validation loss: 2.190256400774884

Epoch: 6| Step: 2
Training loss: 2.3761844635009766
Validation loss: 2.2163467458499375

Epoch: 6| Step: 3
Training loss: 1.8719457387924194
Validation loss: 2.2262298317365747

Epoch: 6| Step: 4
Training loss: 1.778982162475586
Validation loss: 2.234639690768334

Epoch: 6| Step: 5
Training loss: 2.4697494506835938
Validation loss: 2.231971207485404

Epoch: 6| Step: 6
Training loss: 3.1457436084747314
Validation loss: 2.240793458877071

Epoch: 6| Step: 7
Training loss: 2.837265729904175
Validation loss: 2.2372151895235945

Epoch: 6| Step: 8
Training loss: 2.5535964965820312
Validation loss: 2.2119045975387737

Epoch: 6| Step: 9
Training loss: 2.156869649887085
Validation loss: 2.18683631702136

Epoch: 6| Step: 10
Training loss: 2.488381862640381
Validation loss: 2.178839760441934

Epoch: 6| Step: 11
Training loss: 3.018066883087158
Validation loss: 2.1754683474058747

Epoch: 6| Step: 12
Training loss: 1.9802930355072021
Validation loss: 2.1663509286859983

Epoch: 6| Step: 13
Training loss: 2.8506052494049072
Validation loss: 2.1703672332148396

Epoch: 109| Step: 0
Training loss: 3.6352932453155518
Validation loss: 2.1579535686841576

Epoch: 6| Step: 1
Training loss: 2.155167818069458
Validation loss: 2.1457384529934136

Epoch: 6| Step: 2
Training loss: 2.481520175933838
Validation loss: 2.1573697085021646

Epoch: 6| Step: 3
Training loss: 2.4752464294433594
Validation loss: 2.151900468334075

Epoch: 6| Step: 4
Training loss: 3.0276737213134766
Validation loss: 2.1751426137903684

Epoch: 6| Step: 5
Training loss: 1.8826673030853271
Validation loss: 2.175284083171557

Epoch: 6| Step: 6
Training loss: 2.4487669467926025
Validation loss: 2.189147537754428

Epoch: 6| Step: 7
Training loss: 2.420100212097168
Validation loss: 2.221476506161433

Epoch: 6| Step: 8
Training loss: 2.5590503215789795
Validation loss: 2.245666967925205

Epoch: 6| Step: 9
Training loss: 2.878755807876587
Validation loss: 2.2416287186325237

Epoch: 6| Step: 10
Training loss: 2.5582275390625
Validation loss: 2.254303314352548

Epoch: 6| Step: 11
Training loss: 2.1796140670776367
Validation loss: 2.2082636894718295

Epoch: 6| Step: 12
Training loss: 1.5532112121582031
Validation loss: 2.1668196083396993

Epoch: 6| Step: 13
Training loss: 2.203766107559204
Validation loss: 2.138829834999577

Epoch: 110| Step: 0
Training loss: 1.6238170862197876
Validation loss: 2.1346070202448035

Epoch: 6| Step: 1
Training loss: 2.384639024734497
Validation loss: 2.1339782412334154

Epoch: 6| Step: 2
Training loss: 2.541745662689209
Validation loss: 2.1397072230615923

Epoch: 6| Step: 3
Training loss: 2.730713367462158
Validation loss: 2.1421169055405485

Epoch: 6| Step: 4
Training loss: 2.7468225955963135
Validation loss: 2.1412508667156263

Epoch: 6| Step: 5
Training loss: 2.695113182067871
Validation loss: 2.1658264975393973

Epoch: 6| Step: 6
Training loss: 2.132753849029541
Validation loss: 2.180259725098969

Epoch: 6| Step: 7
Training loss: 2.5346803665161133
Validation loss: 2.2198280416509157

Epoch: 6| Step: 8
Training loss: 2.7655251026153564
Validation loss: 2.2317043645407564

Epoch: 6| Step: 9
Training loss: 1.9808439016342163
Validation loss: 2.2895290838774813

Epoch: 6| Step: 10
Training loss: 3.0612659454345703
Validation loss: 2.260929920340097

Epoch: 6| Step: 11
Training loss: 2.343531847000122
Validation loss: 2.246765454610189

Epoch: 6| Step: 12
Training loss: 2.4238381385803223
Validation loss: 2.2198061840508574

Epoch: 6| Step: 13
Training loss: 3.039051055908203
Validation loss: 2.2164465201798307

Epoch: 111| Step: 0
Training loss: 2.6634087562561035
Validation loss: 2.190146243700417

Epoch: 6| Step: 1
Training loss: 2.749854803085327
Validation loss: 2.191319914274318

Epoch: 6| Step: 2
Training loss: 2.316133975982666
Validation loss: 2.1663325755826888

Epoch: 6| Step: 3
Training loss: 2.216557025909424
Validation loss: 2.178665345714938

Epoch: 6| Step: 4
Training loss: 2.4966747760772705
Validation loss: 2.188391416303573

Epoch: 6| Step: 5
Training loss: 2.2355458736419678
Validation loss: 2.18082340814734

Epoch: 6| Step: 6
Training loss: 2.573309898376465
Validation loss: 2.211535576851137

Epoch: 6| Step: 7
Training loss: 2.0150980949401855
Validation loss: 2.2288752089264574

Epoch: 6| Step: 8
Training loss: 1.5379433631896973
Validation loss: 2.223307942831388

Epoch: 6| Step: 9
Training loss: 2.5839715003967285
Validation loss: 2.2011869210068897

Epoch: 6| Step: 10
Training loss: 3.090726852416992
Validation loss: 2.172808413864464

Epoch: 6| Step: 11
Training loss: 2.5650317668914795
Validation loss: 2.1501786067921627

Epoch: 6| Step: 12
Training loss: 2.9497928619384766
Validation loss: 2.1451812380103656

Epoch: 6| Step: 13
Training loss: 2.1814701557159424
Validation loss: 2.133656046723807

Epoch: 112| Step: 0
Training loss: 2.8150224685668945
Validation loss: 2.138295045462988

Epoch: 6| Step: 1
Training loss: 1.9647549390792847
Validation loss: 2.1370632674104426

Epoch: 6| Step: 2
Training loss: 2.6791253089904785
Validation loss: 2.1426012541658137

Epoch: 6| Step: 3
Training loss: 2.464019775390625
Validation loss: 2.1686708786154307

Epoch: 6| Step: 4
Training loss: 2.276050567626953
Validation loss: 2.17904326223558

Epoch: 6| Step: 5
Training loss: 2.6221628189086914
Validation loss: 2.227840259510984

Epoch: 6| Step: 6
Training loss: 2.6745781898498535
Validation loss: 2.2595567575065036

Epoch: 6| Step: 7
Training loss: 2.2937428951263428
Validation loss: 2.276038392897575

Epoch: 6| Step: 8
Training loss: 2.0867984294891357
Validation loss: 2.275065609203872

Epoch: 6| Step: 9
Training loss: 1.9990767240524292
Validation loss: 2.278718399745162

Epoch: 6| Step: 10
Training loss: 2.4923744201660156
Validation loss: 2.244203144504178

Epoch: 6| Step: 11
Training loss: 3.077482223510742
Validation loss: 2.2244933061702277

Epoch: 6| Step: 12
Training loss: 2.318175792694092
Validation loss: 2.182523822271696

Epoch: 6| Step: 13
Training loss: 2.3945047855377197
Validation loss: 2.1547430702435073

Epoch: 113| Step: 0
Training loss: 1.9789685010910034
Validation loss: 2.1388148953837733

Epoch: 6| Step: 1
Training loss: 2.145730972290039
Validation loss: 2.1443225619613484

Epoch: 6| Step: 2
Training loss: 3.2462902069091797
Validation loss: 2.14175255708797

Epoch: 6| Step: 3
Training loss: 3.0659728050231934
Validation loss: 2.1391539483942013

Epoch: 6| Step: 4
Training loss: 1.8357311487197876
Validation loss: 2.1412794859178605

Epoch: 6| Step: 5
Training loss: 2.236974000930786
Validation loss: 2.1368668361376693

Epoch: 6| Step: 6
Training loss: 2.255742311477661
Validation loss: 2.1502005502741826

Epoch: 6| Step: 7
Training loss: 2.3402047157287598
Validation loss: 2.1460731824239097

Epoch: 6| Step: 8
Training loss: 3.478027105331421
Validation loss: 2.1600770386316444

Epoch: 6| Step: 9
Training loss: 2.3394954204559326
Validation loss: 2.165577109142016

Epoch: 6| Step: 10
Training loss: 2.501943349838257
Validation loss: 2.18270859923414

Epoch: 6| Step: 11
Training loss: 2.7358224391937256
Validation loss: 2.17250919342041

Epoch: 6| Step: 12
Training loss: 2.039045810699463
Validation loss: 2.185173810169261

Epoch: 6| Step: 13
Training loss: 2.0966272354125977
Validation loss: 2.173962723824286

Epoch: 114| Step: 0
Training loss: 2.2399404048919678
Validation loss: 2.172027882709298

Epoch: 6| Step: 1
Training loss: 2.152570962905884
Validation loss: 2.152080612797891

Epoch: 6| Step: 2
Training loss: 2.3793060779571533
Validation loss: 2.130186393696775

Epoch: 6| Step: 3
Training loss: 2.438063859939575
Validation loss: 2.1260557533592306

Epoch: 6| Step: 4
Training loss: 2.833127498626709
Validation loss: 2.126782777488873

Epoch: 6| Step: 5
Training loss: 2.0108487606048584
Validation loss: 2.120189303992897

Epoch: 6| Step: 6
Training loss: 2.7164249420166016
Validation loss: 2.115574141984345

Epoch: 6| Step: 7
Training loss: 2.538940906524658
Validation loss: 2.1132945783676638

Epoch: 6| Step: 8
Training loss: 2.748591899871826
Validation loss: 2.1121475235108407

Epoch: 6| Step: 9
Training loss: 2.7086353302001953
Validation loss: 2.113163904477191

Epoch: 6| Step: 10
Training loss: 2.6639862060546875
Validation loss: 2.125221170404906

Epoch: 6| Step: 11
Training loss: 2.1372222900390625
Validation loss: 2.1177909502419094

Epoch: 6| Step: 12
Training loss: 2.2423174381256104
Validation loss: 2.1307141447579987

Epoch: 6| Step: 13
Training loss: 2.3081254959106445
Validation loss: 2.146532643225885

Epoch: 115| Step: 0
Training loss: 2.588925361633301
Validation loss: 2.1599758542994016

Epoch: 6| Step: 1
Training loss: 2.2286877632141113
Validation loss: 2.156222762600068

Epoch: 6| Step: 2
Training loss: 2.0222320556640625
Validation loss: 2.1518099948924077

Epoch: 6| Step: 3
Training loss: 2.7555558681488037
Validation loss: 2.158777920148706

Epoch: 6| Step: 4
Training loss: 2.7666430473327637
Validation loss: 2.1424500967866633

Epoch: 6| Step: 5
Training loss: 2.657677173614502
Validation loss: 2.135932094307356

Epoch: 6| Step: 6
Training loss: 2.3233165740966797
Validation loss: 2.1266749725546887

Epoch: 6| Step: 7
Training loss: 2.6339612007141113
Validation loss: 2.1253076625126663

Epoch: 6| Step: 8
Training loss: 2.0255985260009766
Validation loss: 2.122510851070445

Epoch: 6| Step: 9
Training loss: 2.246945381164551
Validation loss: 2.120689804835986

Epoch: 6| Step: 10
Training loss: 2.6526591777801514
Validation loss: 2.129405742050499

Epoch: 6| Step: 11
Training loss: 2.2067296504974365
Validation loss: 2.152412132550311

Epoch: 6| Step: 12
Training loss: 2.346515417098999
Validation loss: 2.165035378548407

Epoch: 6| Step: 13
Training loss: 2.565871238708496
Validation loss: 2.1762389239444526

Epoch: 116| Step: 0
Training loss: 2.0913503170013428
Validation loss: 2.1984452714202223

Epoch: 6| Step: 1
Training loss: 2.2014174461364746
Validation loss: 2.2305483638599353

Epoch: 6| Step: 2
Training loss: 1.9774324893951416
Validation loss: 2.2588922016082273

Epoch: 6| Step: 3
Training loss: 2.718590021133423
Validation loss: 2.2614399758718347

Epoch: 6| Step: 4
Training loss: 2.169708251953125
Validation loss: 2.2475867220150527

Epoch: 6| Step: 5
Training loss: 3.278507709503174
Validation loss: 2.2225265964385

Epoch: 6| Step: 6
Training loss: 2.723039388656616
Validation loss: 2.207319454480243

Epoch: 6| Step: 7
Training loss: 2.8292274475097656
Validation loss: 2.1863298326410274

Epoch: 6| Step: 8
Training loss: 2.0898988246917725
Validation loss: 2.1632013218377226

Epoch: 6| Step: 9
Training loss: 2.5666215419769287
Validation loss: 2.1514216930635515

Epoch: 6| Step: 10
Training loss: 2.0589613914489746
Validation loss: 2.136148679640985

Epoch: 6| Step: 11
Training loss: 2.0617568492889404
Validation loss: 2.1213238059833484

Epoch: 6| Step: 12
Training loss: 2.3784518241882324
Validation loss: 2.122591651895995

Epoch: 6| Step: 13
Training loss: 2.8584537506103516
Validation loss: 2.127997403503746

Epoch: 117| Step: 0
Training loss: 2.5898008346557617
Validation loss: 2.1194489438046693

Epoch: 6| Step: 1
Training loss: 2.470172882080078
Validation loss: 2.122336756798529

Epoch: 6| Step: 2
Training loss: 1.6929727792739868
Validation loss: 2.1238893001310286

Epoch: 6| Step: 3
Training loss: 2.6719117164611816
Validation loss: 2.118124709334425

Epoch: 6| Step: 4
Training loss: 2.6851789951324463
Validation loss: 2.1185452732988583

Epoch: 6| Step: 5
Training loss: 2.5328776836395264
Validation loss: 2.1273367135755477

Epoch: 6| Step: 6
Training loss: 2.6169283390045166
Validation loss: 2.155181313073763

Epoch: 6| Step: 7
Training loss: 2.109078884124756
Validation loss: 2.1688507808152067

Epoch: 6| Step: 8
Training loss: 1.8538830280303955
Validation loss: 2.2088345686594644

Epoch: 6| Step: 9
Training loss: 2.6901750564575195
Validation loss: 2.265855722529914

Epoch: 6| Step: 10
Training loss: 2.8593080043792725
Validation loss: 2.2639541113248436

Epoch: 6| Step: 11
Training loss: 2.7679619789123535
Validation loss: 2.243561348607463

Epoch: 6| Step: 12
Training loss: 2.2068960666656494
Validation loss: 2.192071271199052

Epoch: 6| Step: 13
Training loss: 2.8228559494018555
Validation loss: 2.1666777082668838

Epoch: 118| Step: 0
Training loss: 2.4769370555877686
Validation loss: 2.138010278824837

Epoch: 6| Step: 1
Training loss: 2.2084944248199463
Validation loss: 2.1189519128491803

Epoch: 6| Step: 2
Training loss: 3.304185390472412
Validation loss: 2.1215359011004047

Epoch: 6| Step: 3
Training loss: 2.652514934539795
Validation loss: 2.1262871270538657

Epoch: 6| Step: 4
Training loss: 1.8271830081939697
Validation loss: 2.130251060249985

Epoch: 6| Step: 5
Training loss: 2.512606143951416
Validation loss: 2.131295863018241

Epoch: 6| Step: 6
Training loss: 2.734828233718872
Validation loss: 2.132409285473567

Epoch: 6| Step: 7
Training loss: 2.983893394470215
Validation loss: 2.1454116400851997

Epoch: 6| Step: 8
Training loss: 2.6135897636413574
Validation loss: 2.1353491121722805

Epoch: 6| Step: 9
Training loss: 2.522041082382202
Validation loss: 2.12843592064355

Epoch: 6| Step: 10
Training loss: 1.84011971950531
Validation loss: 2.128051914194579

Epoch: 6| Step: 11
Training loss: 1.8432174921035767
Validation loss: 2.126733487652194

Epoch: 6| Step: 12
Training loss: 2.343492269515991
Validation loss: 2.1340351168827345

Epoch: 6| Step: 13
Training loss: 2.2638790607452393
Validation loss: 2.145588255697681

Epoch: 119| Step: 0
Training loss: 2.2382407188415527
Validation loss: 2.17060334708101

Epoch: 6| Step: 1
Training loss: 2.11136531829834
Validation loss: 2.1915296123873804

Epoch: 6| Step: 2
Training loss: 2.2957065105438232
Validation loss: 2.2089173178518973

Epoch: 6| Step: 3
Training loss: 2.2423648834228516
Validation loss: 2.240248905715122

Epoch: 6| Step: 4
Training loss: 2.695106029510498
Validation loss: 2.237857449439264

Epoch: 6| Step: 5
Training loss: 1.9682197570800781
Validation loss: 2.239006519317627

Epoch: 6| Step: 6
Training loss: 2.872514486312866
Validation loss: 2.2275631863583802

Epoch: 6| Step: 7
Training loss: 2.7089614868164062
Validation loss: 2.1947801933493665

Epoch: 6| Step: 8
Training loss: 2.6464524269104004
Validation loss: 2.171879832462598

Epoch: 6| Step: 9
Training loss: 2.40291166305542
Validation loss: 2.1626728170661518

Epoch: 6| Step: 10
Training loss: 2.649993658065796
Validation loss: 2.1508102083718903

Epoch: 6| Step: 11
Training loss: 2.063838243484497
Validation loss: 2.1545909758537047

Epoch: 6| Step: 12
Training loss: 2.6751174926757812
Validation loss: 2.1502762276639222

Epoch: 6| Step: 13
Training loss: 2.803398370742798
Validation loss: 2.1387166643655426

Epoch: 120| Step: 0
Training loss: 1.9721647500991821
Validation loss: 2.139304784036452

Epoch: 6| Step: 1
Training loss: 2.0854709148406982
Validation loss: 2.1299600139740975

Epoch: 6| Step: 2
Training loss: 2.7990803718566895
Validation loss: 2.131601059308616

Epoch: 6| Step: 3
Training loss: 2.5421102046966553
Validation loss: 2.1217962734160887

Epoch: 6| Step: 4
Training loss: 1.7688446044921875
Validation loss: 2.120622709233274

Epoch: 6| Step: 5
Training loss: 2.410292148590088
Validation loss: 2.129559155433409

Epoch: 6| Step: 6
Training loss: 2.11667537689209
Validation loss: 2.1289387710632814

Epoch: 6| Step: 7
Training loss: 2.7897539138793945
Validation loss: 2.126982796576715

Epoch: 6| Step: 8
Training loss: 1.9605282545089722
Validation loss: 2.143846450313445

Epoch: 6| Step: 9
Training loss: 2.566279411315918
Validation loss: 2.166337146553942

Epoch: 6| Step: 10
Training loss: 2.8140194416046143
Validation loss: 2.1749225918964674

Epoch: 6| Step: 11
Training loss: 2.5809857845306396
Validation loss: 2.1704436784149497

Epoch: 6| Step: 12
Training loss: 3.3692636489868164
Validation loss: 2.1949949802890902

Epoch: 6| Step: 13
Training loss: 1.8100337982177734
Validation loss: 2.2002982221623903

Epoch: 121| Step: 0
Training loss: 2.911193370819092
Validation loss: 2.2146089948633665

Epoch: 6| Step: 1
Training loss: 2.6158666610717773
Validation loss: 2.252862302205896

Epoch: 6| Step: 2
Training loss: 2.5489745140075684
Validation loss: 2.2688052218447448

Epoch: 6| Step: 3
Training loss: 2.747675895690918
Validation loss: 2.21922815486949

Epoch: 6| Step: 4
Training loss: 2.0458431243896484
Validation loss: 2.189893496933804

Epoch: 6| Step: 5
Training loss: 3.3464605808258057
Validation loss: 2.1545554079035276

Epoch: 6| Step: 6
Training loss: 2.1524033546447754
Validation loss: 2.114528517569265

Epoch: 6| Step: 7
Training loss: 2.994263172149658
Validation loss: 2.116054460566531

Epoch: 6| Step: 8
Training loss: 2.0591177940368652
Validation loss: 2.1144852458789782

Epoch: 6| Step: 9
Training loss: 2.4374136924743652
Validation loss: 2.119990305234027

Epoch: 6| Step: 10
Training loss: 2.828239679336548
Validation loss: 2.1313775829089585

Epoch: 6| Step: 11
Training loss: 1.6863290071487427
Validation loss: 2.140875462562807

Epoch: 6| Step: 12
Training loss: 2.175542116165161
Validation loss: 2.1271258451605357

Epoch: 6| Step: 13
Training loss: 1.6808555126190186
Validation loss: 2.1310922663698912

Epoch: 122| Step: 0
Training loss: 1.7863988876342773
Validation loss: 2.123086901121242

Epoch: 6| Step: 1
Training loss: 2.119640827178955
Validation loss: 2.1193904799799763

Epoch: 6| Step: 2
Training loss: 2.384023904800415
Validation loss: 2.1159725881391958

Epoch: 6| Step: 3
Training loss: 3.016289472579956
Validation loss: 2.105394555676368

Epoch: 6| Step: 4
Training loss: 2.3265557289123535
Validation loss: 2.1224640338651595

Epoch: 6| Step: 5
Training loss: 2.2058587074279785
Validation loss: 2.16230147628374

Epoch: 6| Step: 6
Training loss: 2.3711414337158203
Validation loss: 2.187088184459235

Epoch: 6| Step: 7
Training loss: 2.2886252403259277
Validation loss: 2.212328008426133

Epoch: 6| Step: 8
Training loss: 2.482567071914673
Validation loss: 2.2257374307160736

Epoch: 6| Step: 9
Training loss: 2.3321566581726074
Validation loss: 2.211341440036733

Epoch: 6| Step: 10
Training loss: 2.802053928375244
Validation loss: 2.224894344165761

Epoch: 6| Step: 11
Training loss: 2.349440336227417
Validation loss: 2.1854698786171536

Epoch: 6| Step: 12
Training loss: 2.945079803466797
Validation loss: 2.1580091907132055

Epoch: 6| Step: 13
Training loss: 2.5241589546203613
Validation loss: 2.1318289541429087

Epoch: 123| Step: 0
Training loss: 2.931732177734375
Validation loss: 2.1210723589825373

Epoch: 6| Step: 1
Training loss: 2.5186209678649902
Validation loss: 2.111510399849184

Epoch: 6| Step: 2
Training loss: 2.536187171936035
Validation loss: 2.1050510098857265

Epoch: 6| Step: 3
Training loss: 2.4277875423431396
Validation loss: 2.1131468293487385

Epoch: 6| Step: 4
Training loss: 2.348949909210205
Validation loss: 2.113722329498619

Epoch: 6| Step: 5
Training loss: 2.6622910499572754
Validation loss: 2.1252464761016188

Epoch: 6| Step: 6
Training loss: 2.4697675704956055
Validation loss: 2.13678769142397

Epoch: 6| Step: 7
Training loss: 2.2179269790649414
Validation loss: 2.1404018658463673

Epoch: 6| Step: 8
Training loss: 2.028872489929199
Validation loss: 2.1414229818569717

Epoch: 6| Step: 9
Training loss: 2.5584700107574463
Validation loss: 2.144217993623467

Epoch: 6| Step: 10
Training loss: 2.543984889984131
Validation loss: 2.12000701760733

Epoch: 6| Step: 11
Training loss: 2.6587908267974854
Validation loss: 2.1264379793597805

Epoch: 6| Step: 12
Training loss: 1.7412168979644775
Validation loss: 2.1285408953184723

Epoch: 6| Step: 13
Training loss: 2.096459150314331
Validation loss: 2.1248374523655063

Epoch: 124| Step: 0
Training loss: 2.614881753921509
Validation loss: 2.130781394179149

Epoch: 6| Step: 1
Training loss: 2.7576286792755127
Validation loss: 2.114885127672585

Epoch: 6| Step: 2
Training loss: 2.6062235832214355
Validation loss: 2.1186726452201925

Epoch: 6| Step: 3
Training loss: 1.5948213338851929
Validation loss: 2.1294759486311223

Epoch: 6| Step: 4
Training loss: 1.7459641695022583
Validation loss: 2.141063449203327

Epoch: 6| Step: 5
Training loss: 2.510899066925049
Validation loss: 2.1518110152213805

Epoch: 6| Step: 6
Training loss: 2.5108988285064697
Validation loss: 2.1396186633776595

Epoch: 6| Step: 7
Training loss: 2.597172260284424
Validation loss: 2.127517507922265

Epoch: 6| Step: 8
Training loss: 2.3168437480926514
Validation loss: 2.1299532126354914

Epoch: 6| Step: 9
Training loss: 3.4893460273742676
Validation loss: 2.110356941018053

Epoch: 6| Step: 10
Training loss: 2.2988357543945312
Validation loss: 2.1076173551620974

Epoch: 6| Step: 11
Training loss: 2.092744827270508
Validation loss: 2.100585922118156

Epoch: 6| Step: 12
Training loss: 1.9092589616775513
Validation loss: 2.106462956756674

Epoch: 6| Step: 13
Training loss: 2.742321014404297
Validation loss: 2.113051293998636

Epoch: 125| Step: 0
Training loss: 2.6411871910095215
Validation loss: 2.1029626605331257

Epoch: 6| Step: 1
Training loss: 2.911794900894165
Validation loss: 2.118789254978139

Epoch: 6| Step: 2
Training loss: 2.50099778175354
Validation loss: 2.121842804775443

Epoch: 6| Step: 3
Training loss: 2.2279200553894043
Validation loss: 2.128514028364612

Epoch: 6| Step: 4
Training loss: 2.862363815307617
Validation loss: 2.1402271973189486

Epoch: 6| Step: 5
Training loss: 2.1812891960144043
Validation loss: 2.1643141303011166

Epoch: 6| Step: 6
Training loss: 2.0854241847991943
Validation loss: 2.1738602474171627

Epoch: 6| Step: 7
Training loss: 2.05893611907959
Validation loss: 2.1873291756517146

Epoch: 6| Step: 8
Training loss: 2.4755337238311768
Validation loss: 2.1799704541442213

Epoch: 6| Step: 9
Training loss: 2.267035484313965
Validation loss: 2.1752785944169566

Epoch: 6| Step: 10
Training loss: 2.1532175540924072
Validation loss: 2.174356081152475

Epoch: 6| Step: 11
Training loss: 2.0462288856506348
Validation loss: 2.1500459294165335

Epoch: 6| Step: 12
Training loss: 2.7058353424072266
Validation loss: 2.142389328249039

Epoch: 6| Step: 13
Training loss: 2.348202705383301
Validation loss: 2.1172543007840394

Epoch: 126| Step: 0
Training loss: 2.2582645416259766
Validation loss: 2.1259836407117945

Epoch: 6| Step: 1
Training loss: 2.241917610168457
Validation loss: 2.123588756848407

Epoch: 6| Step: 2
Training loss: 1.8856480121612549
Validation loss: 2.1294294531627367

Epoch: 6| Step: 3
Training loss: 2.1240663528442383
Validation loss: 2.1177718716283

Epoch: 6| Step: 4
Training loss: 2.824321985244751
Validation loss: 2.124451632140785

Epoch: 6| Step: 5
Training loss: 3.050034999847412
Validation loss: 2.1254791816075644

Epoch: 6| Step: 6
Training loss: 2.2282705307006836
Validation loss: 2.137671541142207

Epoch: 6| Step: 7
Training loss: 2.573596477508545
Validation loss: 2.133576011144987

Epoch: 6| Step: 8
Training loss: 2.244511604309082
Validation loss: 2.1458732799817155

Epoch: 6| Step: 9
Training loss: 2.412806510925293
Validation loss: 2.1390710210287445

Epoch: 6| Step: 10
Training loss: 3.021669864654541
Validation loss: 2.147796033531107

Epoch: 6| Step: 11
Training loss: 2.1268551349639893
Validation loss: 2.1380593469066005

Epoch: 6| Step: 12
Training loss: 2.1853153705596924
Validation loss: 2.132771502258957

Epoch: 6| Step: 13
Training loss: 1.972658395767212
Validation loss: 2.1083632989596297

Epoch: 127| Step: 0
Training loss: 2.381253719329834
Validation loss: 2.103021942159181

Epoch: 6| Step: 1
Training loss: 2.74556040763855
Validation loss: 2.1096632019166024

Epoch: 6| Step: 2
Training loss: 2.5494766235351562
Validation loss: 2.0984690599544074

Epoch: 6| Step: 3
Training loss: 2.3354320526123047
Validation loss: 2.1123822555747083

Epoch: 6| Step: 4
Training loss: 2.2635231018066406
Validation loss: 2.1088572881555043

Epoch: 6| Step: 5
Training loss: 2.4605133533477783
Validation loss: 2.0986734205676663

Epoch: 6| Step: 6
Training loss: 2.7899117469787598
Validation loss: 2.095549524471324

Epoch: 6| Step: 7
Training loss: 2.5866518020629883
Validation loss: 2.092646029687697

Epoch: 6| Step: 8
Training loss: 2.1498661041259766
Validation loss: 2.081733654904109

Epoch: 6| Step: 9
Training loss: 2.473552703857422
Validation loss: 2.0968544457548406

Epoch: 6| Step: 10
Training loss: 2.4393956661224365
Validation loss: 2.1083172495647142

Epoch: 6| Step: 11
Training loss: 1.942763090133667
Validation loss: 2.1365749669331375

Epoch: 6| Step: 12
Training loss: 1.989611268043518
Validation loss: 2.207919446370935

Epoch: 6| Step: 13
Training loss: 2.787745237350464
Validation loss: 2.315073800343339

Epoch: 128| Step: 0
Training loss: 2.6255571842193604
Validation loss: 2.367922265042541

Epoch: 6| Step: 1
Training loss: 2.118797779083252
Validation loss: 2.439663343532111

Epoch: 6| Step: 2
Training loss: 3.3096225261688232
Validation loss: 2.434497825561031

Epoch: 6| Step: 3
Training loss: 2.502607822418213
Validation loss: 2.398747403134582

Epoch: 6| Step: 4
Training loss: 2.346339464187622
Validation loss: 2.2790515179275186

Epoch: 6| Step: 5
Training loss: 1.4274317026138306
Validation loss: 2.182158198407901

Epoch: 6| Step: 6
Training loss: 1.9725139141082764
Validation loss: 2.1382068434069232

Epoch: 6| Step: 7
Training loss: 2.3541948795318604
Validation loss: 2.104417008738364

Epoch: 6| Step: 8
Training loss: 2.500882625579834
Validation loss: 2.1051485256482194

Epoch: 6| Step: 9
Training loss: 2.2277162075042725
Validation loss: 2.1023791502880793

Epoch: 6| Step: 10
Training loss: 2.952674388885498
Validation loss: 2.1081659255489225

Epoch: 6| Step: 11
Training loss: 2.5800528526306152
Validation loss: 2.1169493493213447

Epoch: 6| Step: 12
Training loss: 2.7238411903381348
Validation loss: 2.124226627811309

Epoch: 6| Step: 13
Training loss: 3.365614891052246
Validation loss: 2.130240608287114

Epoch: 129| Step: 0
Training loss: 2.389370918273926
Validation loss: 2.123563766479492

Epoch: 6| Step: 1
Training loss: 2.5802130699157715
Validation loss: 2.1234622334921234

Epoch: 6| Step: 2
Training loss: 2.615544557571411
Validation loss: 2.1279483238855996

Epoch: 6| Step: 3
Training loss: 2.1332132816314697
Validation loss: 2.1360929858299995

Epoch: 6| Step: 4
Training loss: 2.153097629547119
Validation loss: 2.1530480282281035

Epoch: 6| Step: 5
Training loss: 2.554884672164917
Validation loss: 2.1524020318062074

Epoch: 6| Step: 6
Training loss: 2.1130306720733643
Validation loss: 2.164271952003561

Epoch: 6| Step: 7
Training loss: 2.863506317138672
Validation loss: 2.1803995588774323

Epoch: 6| Step: 8
Training loss: 2.2962160110473633
Validation loss: 2.186940936632054

Epoch: 6| Step: 9
Training loss: 2.1271963119506836
Validation loss: 2.1939089144429853

Epoch: 6| Step: 10
Training loss: 2.4191341400146484
Validation loss: 2.1817493836085

Epoch: 6| Step: 11
Training loss: 2.1819701194763184
Validation loss: 2.1751566202409807

Epoch: 6| Step: 12
Training loss: 2.7862820625305176
Validation loss: 2.1798275721970426

Epoch: 6| Step: 13
Training loss: 2.4608888626098633
Validation loss: 2.194491245413339

Epoch: 130| Step: 0
Training loss: 2.695510149002075
Validation loss: 2.202754234754911

Epoch: 6| Step: 1
Training loss: 2.711724281311035
Validation loss: 2.2014628892303794

Epoch: 6| Step: 2
Training loss: 2.188589334487915
Validation loss: 2.2183410916277158

Epoch: 6| Step: 3
Training loss: 2.4377379417419434
Validation loss: 2.190964524463941

Epoch: 6| Step: 4
Training loss: 2.2919533252716064
Validation loss: 2.1655991359423568

Epoch: 6| Step: 5
Training loss: 1.4216718673706055
Validation loss: 2.1448019960875153

Epoch: 6| Step: 6
Training loss: 3.089111804962158
Validation loss: 2.138887761741556

Epoch: 6| Step: 7
Training loss: 2.4942145347595215
Validation loss: 2.1073689230026735

Epoch: 6| Step: 8
Training loss: 2.9831557273864746
Validation loss: 2.09630242470772

Epoch: 6| Step: 9
Training loss: 2.874655246734619
Validation loss: 2.093137069415021

Epoch: 6| Step: 10
Training loss: 2.0435097217559814
Validation loss: 2.0988477250581146

Epoch: 6| Step: 11
Training loss: 1.869275689125061
Validation loss: 2.0908880913129417

Epoch: 6| Step: 12
Training loss: 2.3539657592773438
Validation loss: 2.1047593855088755

Epoch: 6| Step: 13
Training loss: 1.7833722829818726
Validation loss: 2.1123020751501924

Epoch: 131| Step: 0
Training loss: 2.8650012016296387
Validation loss: 2.128796664617395

Epoch: 6| Step: 1
Training loss: 2.9558398723602295
Validation loss: 2.12262023392544

Epoch: 6| Step: 2
Training loss: 2.348964214324951
Validation loss: 2.115717023931524

Epoch: 6| Step: 3
Training loss: 2.4340977668762207
Validation loss: 2.1127224301779144

Epoch: 6| Step: 4
Training loss: 2.6813480854034424
Validation loss: 2.102264235096593

Epoch: 6| Step: 5
Training loss: 2.1399731636047363
Validation loss: 2.0956687568336405

Epoch: 6| Step: 6
Training loss: 2.407228708267212
Validation loss: 2.104215827039493

Epoch: 6| Step: 7
Training loss: 2.5271859169006348
Validation loss: 2.0898444344920497

Epoch: 6| Step: 8
Training loss: 2.2018322944641113
Validation loss: 2.090729287875596

Epoch: 6| Step: 9
Training loss: 2.20330810546875
Validation loss: 2.090557872608144

Epoch: 6| Step: 10
Training loss: 2.248542308807373
Validation loss: 2.099242905134796

Epoch: 6| Step: 11
Training loss: 1.7567253112792969
Validation loss: 2.123021556485084

Epoch: 6| Step: 12
Training loss: 1.7717955112457275
Validation loss: 2.136518073338334

Epoch: 6| Step: 13
Training loss: 3.1565539836883545
Validation loss: 2.146657666852397

Epoch: 132| Step: 0
Training loss: 3.396357774734497
Validation loss: 2.1406262356747865

Epoch: 6| Step: 1
Training loss: 1.4115524291992188
Validation loss: 2.1485221578228857

Epoch: 6| Step: 2
Training loss: 1.9540444612503052
Validation loss: 2.1631385241785357

Epoch: 6| Step: 3
Training loss: 2.3653855323791504
Validation loss: 2.170155199625159

Epoch: 6| Step: 4
Training loss: 2.95475697517395
Validation loss: 2.1885187254157117

Epoch: 6| Step: 5
Training loss: 2.6614880561828613
Validation loss: 2.1780292859641452

Epoch: 6| Step: 6
Training loss: 2.375650405883789
Validation loss: 2.1836960033703874

Epoch: 6| Step: 7
Training loss: 2.431368112564087
Validation loss: 2.1775725374939623

Epoch: 6| Step: 8
Training loss: 2.459139347076416
Validation loss: 2.1562540531158447

Epoch: 6| Step: 9
Training loss: 2.0738396644592285
Validation loss: 2.170196989531158

Epoch: 6| Step: 10
Training loss: 2.4370779991149902
Validation loss: 2.157177294454267

Epoch: 6| Step: 11
Training loss: 2.5711758136749268
Validation loss: 2.138131146789879

Epoch: 6| Step: 12
Training loss: 1.9250209331512451
Validation loss: 2.122205658625531

Epoch: 6| Step: 13
Training loss: 2.1712818145751953
Validation loss: 2.114283054105697

Epoch: 133| Step: 0
Training loss: 2.531982183456421
Validation loss: 2.112262923230407

Epoch: 6| Step: 1
Training loss: 2.8769712448120117
Validation loss: 2.12066142020687

Epoch: 6| Step: 2
Training loss: 3.2786614894866943
Validation loss: 2.136216466144849

Epoch: 6| Step: 3
Training loss: 1.5025725364685059
Validation loss: 2.128281976587029

Epoch: 6| Step: 4
Training loss: 1.4991490840911865
Validation loss: 2.1381442367389636

Epoch: 6| Step: 5
Training loss: 1.9214684963226318
Validation loss: 2.1768786189376668

Epoch: 6| Step: 6
Training loss: 2.342461347579956
Validation loss: 2.173504114151001

Epoch: 6| Step: 7
Training loss: 2.8466873168945312
Validation loss: 2.1641856983143795

Epoch: 6| Step: 8
Training loss: 2.017094612121582
Validation loss: 2.1588540128482285

Epoch: 6| Step: 9
Training loss: 2.540585994720459
Validation loss: 2.140024633817775

Epoch: 6| Step: 10
Training loss: 2.645467519760132
Validation loss: 2.1379885981159825

Epoch: 6| Step: 11
Training loss: 2.6456494331359863
Validation loss: 2.1291333334420317

Epoch: 6| Step: 12
Training loss: 2.3965914249420166
Validation loss: 2.124228694105661

Epoch: 6| Step: 13
Training loss: 2.0245583057403564
Validation loss: 2.119021673356333

Epoch: 134| Step: 0
Training loss: 2.5602827072143555
Validation loss: 2.121861755207021

Epoch: 6| Step: 1
Training loss: 2.2432355880737305
Validation loss: 2.115702704716754

Epoch: 6| Step: 2
Training loss: 2.3412208557128906
Validation loss: 2.1199475667809926

Epoch: 6| Step: 3
Training loss: 2.2466092109680176
Validation loss: 2.121256248925322

Epoch: 6| Step: 4
Training loss: 2.2435154914855957
Validation loss: 2.1214768220019597

Epoch: 6| Step: 5
Training loss: 1.752170443534851
Validation loss: 2.135573992165186

Epoch: 6| Step: 6
Training loss: 3.11746883392334
Validation loss: 2.1560632977434384

Epoch: 6| Step: 7
Training loss: 1.8339545726776123
Validation loss: 2.1703519923712618

Epoch: 6| Step: 8
Training loss: 2.5288596153259277
Validation loss: 2.164682665178853

Epoch: 6| Step: 9
Training loss: 2.741777181625366
Validation loss: 2.1883124471992574

Epoch: 6| Step: 10
Training loss: 2.6270804405212402
Validation loss: 2.2041801406491186

Epoch: 6| Step: 11
Training loss: 2.082042694091797
Validation loss: 2.1960154374440513

Epoch: 6| Step: 12
Training loss: 2.7521209716796875
Validation loss: 2.175613587902438

Epoch: 6| Step: 13
Training loss: 1.9579579830169678
Validation loss: 2.1622123846443753

Epoch: 135| Step: 0
Training loss: 3.244957208633423
Validation loss: 2.1379351231359665

Epoch: 6| Step: 1
Training loss: 2.3600401878356934
Validation loss: 2.1094722158165387

Epoch: 6| Step: 2
Training loss: 2.1248998641967773
Validation loss: 2.098492478811613

Epoch: 6| Step: 3
Training loss: 2.6874618530273438
Validation loss: 2.0774828028935257

Epoch: 6| Step: 4
Training loss: 2.298032283782959
Validation loss: 2.0693489005488734

Epoch: 6| Step: 5
Training loss: 2.372331142425537
Validation loss: 2.0690289235884145

Epoch: 6| Step: 6
Training loss: 2.167609214782715
Validation loss: 2.0617362068545435

Epoch: 6| Step: 7
Training loss: 2.5946481227874756
Validation loss: 2.0750796128344793

Epoch: 6| Step: 8
Training loss: 1.5574508905410767
Validation loss: 2.065423744981007

Epoch: 6| Step: 9
Training loss: 2.22672700881958
Validation loss: 2.069246874060682

Epoch: 6| Step: 10
Training loss: 2.509213924407959
Validation loss: 2.0704503777206584

Epoch: 6| Step: 11
Training loss: 2.396071434020996
Validation loss: 2.0820368746275544

Epoch: 6| Step: 12
Training loss: 2.6006598472595215
Validation loss: 2.097761756630354

Epoch: 6| Step: 13
Training loss: 1.4388558864593506
Validation loss: 2.1660479960903043

Epoch: 136| Step: 0
Training loss: 2.5061075687408447
Validation loss: 2.1913662341333207

Epoch: 6| Step: 1
Training loss: 2.5211262702941895
Validation loss: 2.2141354289106143

Epoch: 6| Step: 2
Training loss: 1.8185070753097534
Validation loss: 2.2180413251282065

Epoch: 6| Step: 3
Training loss: 2.9722249507904053
Validation loss: 2.2197812911002868

Epoch: 6| Step: 4
Training loss: 2.424503803253174
Validation loss: 2.202465323991673

Epoch: 6| Step: 5
Training loss: 2.1871325969696045
Validation loss: 2.158669033358174

Epoch: 6| Step: 6
Training loss: 1.9230384826660156
Validation loss: 2.092582457809038

Epoch: 6| Step: 7
Training loss: 2.1879987716674805
Validation loss: 2.0915679111275622

Epoch: 6| Step: 8
Training loss: 2.114995241165161
Validation loss: 2.0784116419412757

Epoch: 6| Step: 9
Training loss: 2.4747180938720703
Validation loss: 2.0771313021259923

Epoch: 6| Step: 10
Training loss: 2.4087603092193604
Validation loss: 2.0846223779903945

Epoch: 6| Step: 11
Training loss: 2.8758175373077393
Validation loss: 2.096164139368201

Epoch: 6| Step: 12
Training loss: 2.4078688621520996
Validation loss: 2.101011740264072

Epoch: 6| Step: 13
Training loss: 2.551774024963379
Validation loss: 2.1010245494945075

Epoch: 137| Step: 0
Training loss: 2.244626045227051
Validation loss: 2.1269227381675475

Epoch: 6| Step: 1
Training loss: 2.6482608318328857
Validation loss: 2.154269790136686

Epoch: 6| Step: 2
Training loss: 2.260235548019409
Validation loss: 2.2121912305073073

Epoch: 6| Step: 3
Training loss: 2.0219173431396484
Validation loss: 2.216914819132897

Epoch: 6| Step: 4
Training loss: 2.183995485305786
Validation loss: 2.1935140907123523

Epoch: 6| Step: 5
Training loss: 2.091524124145508
Validation loss: 2.1752748463743474

Epoch: 6| Step: 6
Training loss: 2.208232879638672
Validation loss: 2.1786025724103375

Epoch: 6| Step: 7
Training loss: 2.4154224395751953
Validation loss: 2.1915414102615847

Epoch: 6| Step: 8
Training loss: 2.535367488861084
Validation loss: 2.184087485395452

Epoch: 6| Step: 9
Training loss: 2.2940378189086914
Validation loss: 2.1686782913823284

Epoch: 6| Step: 10
Training loss: 2.830432176589966
Validation loss: 2.1474120719458467

Epoch: 6| Step: 11
Training loss: 2.247450351715088
Validation loss: 2.1175929525847077

Epoch: 6| Step: 12
Training loss: 2.245927572250366
Validation loss: 2.110665226495394

Epoch: 6| Step: 13
Training loss: 3.269066333770752
Validation loss: 2.12071317754766

Epoch: 138| Step: 0
Training loss: 2.48966646194458
Validation loss: 2.0966513708073604

Epoch: 6| Step: 1
Training loss: 2.042747974395752
Validation loss: 2.092262770539971

Epoch: 6| Step: 2
Training loss: 2.7795045375823975
Validation loss: 2.086637258529663

Epoch: 6| Step: 3
Training loss: 2.876804828643799
Validation loss: 2.0816108808722547

Epoch: 6| Step: 4
Training loss: 2.0636487007141113
Validation loss: 2.0800038717126332

Epoch: 6| Step: 5
Training loss: 2.320396900177002
Validation loss: 2.079955441977388

Epoch: 6| Step: 6
Training loss: 1.7689342498779297
Validation loss: 2.0868798148247505

Epoch: 6| Step: 7
Training loss: 1.6454781293869019
Validation loss: 2.0820650772381852

Epoch: 6| Step: 8
Training loss: 2.2791059017181396
Validation loss: 2.082103685666156

Epoch: 6| Step: 9
Training loss: 2.427985191345215
Validation loss: 2.0885429536142657

Epoch: 6| Step: 10
Training loss: 2.51220440864563
Validation loss: 2.083314940493594

Epoch: 6| Step: 11
Training loss: 2.0887584686279297
Validation loss: 2.086690882200836

Epoch: 6| Step: 12
Training loss: 3.012378215789795
Validation loss: 2.099417996662919

Epoch: 6| Step: 13
Training loss: 2.7867188453674316
Validation loss: 2.120307469880709

Epoch: 139| Step: 0
Training loss: 2.3628475666046143
Validation loss: 2.1499925787730882

Epoch: 6| Step: 1
Training loss: 2.489628314971924
Validation loss: 2.1654689619618077

Epoch: 6| Step: 2
Training loss: 2.0155415534973145
Validation loss: 2.1696067343476

Epoch: 6| Step: 3
Training loss: 2.844771385192871
Validation loss: 2.169083563230371

Epoch: 6| Step: 4
Training loss: 1.762946605682373
Validation loss: 2.1383473744956394

Epoch: 6| Step: 5
Training loss: 2.1788182258605957
Validation loss: 2.1210016332646853

Epoch: 6| Step: 6
Training loss: 2.524038314819336
Validation loss: 2.110420269350852

Epoch: 6| Step: 7
Training loss: 2.8621249198913574
Validation loss: 2.0857471266100482

Epoch: 6| Step: 8
Training loss: 2.248532772064209
Validation loss: 2.097637261113813

Epoch: 6| Step: 9
Training loss: 1.8440048694610596
Validation loss: 2.1105771205758534

Epoch: 6| Step: 10
Training loss: 2.843371868133545
Validation loss: 2.096988885633407

Epoch: 6| Step: 11
Training loss: 2.2947683334350586
Validation loss: 2.091008158140285

Epoch: 6| Step: 12
Training loss: 2.3480072021484375
Validation loss: 2.085618039613129

Epoch: 6| Step: 13
Training loss: 2.189997673034668
Validation loss: 2.093564409081654

Epoch: 140| Step: 0
Training loss: 1.7087458372116089
Validation loss: 2.10323279775599

Epoch: 6| Step: 1
Training loss: 3.388181686401367
Validation loss: 2.0941069459402435

Epoch: 6| Step: 2
Training loss: 2.144897937774658
Validation loss: 2.1058026257381646

Epoch: 6| Step: 3
Training loss: 1.906904697418213
Validation loss: 2.1089429316982145

Epoch: 6| Step: 4
Training loss: 1.799081802368164
Validation loss: 2.1171498965191584

Epoch: 6| Step: 5
Training loss: 2.381678581237793
Validation loss: 2.1239867825661936

Epoch: 6| Step: 6
Training loss: 2.6946611404418945
Validation loss: 2.1394427437936105

Epoch: 6| Step: 7
Training loss: 1.7188143730163574
Validation loss: 2.1318328713858

Epoch: 6| Step: 8
Training loss: 2.9309239387512207
Validation loss: 2.1097877563968783

Epoch: 6| Step: 9
Training loss: 2.6485326290130615
Validation loss: 2.1139714769137803

Epoch: 6| Step: 10
Training loss: 2.468766689300537
Validation loss: 2.115156650543213

Epoch: 6| Step: 11
Training loss: 2.39040470123291
Validation loss: 2.113662096761888

Epoch: 6| Step: 12
Training loss: 2.473449468612671
Validation loss: 2.1036447119969193

Epoch: 6| Step: 13
Training loss: 1.7860503196716309
Validation loss: 2.1257144046086136

Epoch: 141| Step: 0
Training loss: 1.5250804424285889
Validation loss: 2.1199601863020208

Epoch: 6| Step: 1
Training loss: 2.928287982940674
Validation loss: 2.11212500961878

Epoch: 6| Step: 2
Training loss: 2.2242236137390137
Validation loss: 2.111170289336994

Epoch: 6| Step: 3
Training loss: 2.6950037479400635
Validation loss: 2.1200407935727026

Epoch: 6| Step: 4
Training loss: 1.7108060121536255
Validation loss: 2.1089456824846167

Epoch: 6| Step: 5
Training loss: 2.9267561435699463
Validation loss: 2.1087520481437765

Epoch: 6| Step: 6
Training loss: 3.1063766479492188
Validation loss: 2.1051689219731156

Epoch: 6| Step: 7
Training loss: 2.3085079193115234
Validation loss: 2.096840038094469

Epoch: 6| Step: 8
Training loss: 1.9985953569412231
Validation loss: 2.076867095885738

Epoch: 6| Step: 9
Training loss: 2.4607086181640625
Validation loss: 2.0579074582745953

Epoch: 6| Step: 10
Training loss: 2.5077781677246094
Validation loss: 2.0681185440350602

Epoch: 6| Step: 11
Training loss: 1.9376598596572876
Validation loss: 2.0701766308917793

Epoch: 6| Step: 12
Training loss: 2.082207441329956
Validation loss: 2.075813093493062

Epoch: 6| Step: 13
Training loss: 2.076554536819458
Validation loss: 2.08036208152771

Epoch: 142| Step: 0
Training loss: 1.928512692451477
Validation loss: 2.095260863663048

Epoch: 6| Step: 1
Training loss: 2.2361679077148438
Validation loss: 2.141095861311882

Epoch: 6| Step: 2
Training loss: 3.065772533416748
Validation loss: 2.223605627654701

Epoch: 6| Step: 3
Training loss: 2.4036526679992676
Validation loss: 2.2823360812279487

Epoch: 6| Step: 4
Training loss: 2.3140628337860107
Validation loss: 2.2954506835629864

Epoch: 6| Step: 5
Training loss: 2.4259042739868164
Validation loss: 2.255154240515924

Epoch: 6| Step: 6
Training loss: 2.447573661804199
Validation loss: 2.2038594599693053

Epoch: 6| Step: 7
Training loss: 1.7100839614868164
Validation loss: 2.1309591544571744

Epoch: 6| Step: 8
Training loss: 2.1429147720336914
Validation loss: 2.0967115445803572

Epoch: 6| Step: 9
Training loss: 2.6340298652648926
Validation loss: 2.0851382081226637

Epoch: 6| Step: 10
Training loss: 2.5358808040618896
Validation loss: 2.0713892341941915

Epoch: 6| Step: 11
Training loss: 2.3147737979888916
Validation loss: 2.056592120919176

Epoch: 6| Step: 12
Training loss: 2.4992990493774414
Validation loss: 2.0714402044973066

Epoch: 6| Step: 13
Training loss: 2.2324166297912598
Validation loss: 2.074140271832866

Epoch: 143| Step: 0
Training loss: 2.191344976425171
Validation loss: 2.0808605468401344

Epoch: 6| Step: 1
Training loss: 2.368877410888672
Validation loss: 2.0884295637889574

Epoch: 6| Step: 2
Training loss: 2.037229299545288
Validation loss: 2.0942554031648943

Epoch: 6| Step: 3
Training loss: 2.105921506881714
Validation loss: 2.098254544760591

Epoch: 6| Step: 4
Training loss: 2.809657573699951
Validation loss: 2.0985309795666764

Epoch: 6| Step: 5
Training loss: 2.7927300930023193
Validation loss: 2.1101024868667766

Epoch: 6| Step: 6
Training loss: 2.2733497619628906
Validation loss: 2.1019501763005413

Epoch: 6| Step: 7
Training loss: 2.338961124420166
Validation loss: 2.1042500260055705

Epoch: 6| Step: 8
Training loss: 2.3099536895751953
Validation loss: 2.1164224686161166

Epoch: 6| Step: 9
Training loss: 1.5586273670196533
Validation loss: 2.127086111294326

Epoch: 6| Step: 10
Training loss: 2.568636178970337
Validation loss: 2.1455981962142454

Epoch: 6| Step: 11
Training loss: 2.5413575172424316
Validation loss: 2.1735166580446306

Epoch: 6| Step: 12
Training loss: 2.4912352561950684
Validation loss: 2.1742752931451284

Epoch: 6| Step: 13
Training loss: 1.6537443399429321
Validation loss: 2.1773649069570724

Epoch: 144| Step: 0
Training loss: 1.7528367042541504
Validation loss: 2.1530344255508913

Epoch: 6| Step: 1
Training loss: 2.564154863357544
Validation loss: 2.14016160913693

Epoch: 6| Step: 2
Training loss: 2.1065614223480225
Validation loss: 2.1371317037972073

Epoch: 6| Step: 3
Training loss: 2.087700366973877
Validation loss: 2.1389804091504825

Epoch: 6| Step: 4
Training loss: 2.100956439971924
Validation loss: 2.1620186759579565

Epoch: 6| Step: 5
Training loss: 2.6882972717285156
Validation loss: 2.161015397758894

Epoch: 6| Step: 6
Training loss: 2.4741525650024414
Validation loss: 2.1337909160121793

Epoch: 6| Step: 7
Training loss: 2.3595831394195557
Validation loss: 2.110994641498853

Epoch: 6| Step: 8
Training loss: 2.710059642791748
Validation loss: 2.086307869162611

Epoch: 6| Step: 9
Training loss: 1.4521229267120361
Validation loss: 2.097528766560298

Epoch: 6| Step: 10
Training loss: 2.935220718383789
Validation loss: 2.0901167828549623

Epoch: 6| Step: 11
Training loss: 2.3138132095336914
Validation loss: 2.0959313659257788

Epoch: 6| Step: 12
Training loss: 2.8345091342926025
Validation loss: 2.1010799010594687

Epoch: 6| Step: 13
Training loss: 1.8985791206359863
Validation loss: 2.0832334026213615

Epoch: 145| Step: 0
Training loss: 2.5479068756103516
Validation loss: 2.0861806382415113

Epoch: 6| Step: 1
Training loss: 2.2231996059417725
Validation loss: 2.0891116165345713

Epoch: 6| Step: 2
Training loss: 2.092470169067383
Validation loss: 2.077587881395894

Epoch: 6| Step: 3
Training loss: 2.399298667907715
Validation loss: 2.0875826804868636

Epoch: 6| Step: 4
Training loss: 2.6792540550231934
Validation loss: 2.0808765311394968

Epoch: 6| Step: 5
Training loss: 1.7635574340820312
Validation loss: 2.099022150039673

Epoch: 6| Step: 6
Training loss: 2.340557098388672
Validation loss: 2.117190378968434

Epoch: 6| Step: 7
Training loss: 2.2353675365448
Validation loss: 2.1343114491431945

Epoch: 6| Step: 8
Training loss: 2.0547549724578857
Validation loss: 2.154695354482179

Epoch: 6| Step: 9
Training loss: 1.8327970504760742
Validation loss: 2.1603452800422587

Epoch: 6| Step: 10
Training loss: 2.3952057361602783
Validation loss: 2.1834866205851235

Epoch: 6| Step: 11
Training loss: 2.7817466259002686
Validation loss: 2.148332688116258

Epoch: 6| Step: 12
Training loss: 2.4201269149780273
Validation loss: 2.1423567341219996

Epoch: 6| Step: 13
Training loss: 2.9409115314483643
Validation loss: 2.117128910556916

Epoch: 146| Step: 0
Training loss: 2.7611007690429688
Validation loss: 2.0872755717205744

Epoch: 6| Step: 1
Training loss: 2.849709987640381
Validation loss: 2.0679715115536927

Epoch: 6| Step: 2
Training loss: 1.4039846658706665
Validation loss: 2.073293347512522

Epoch: 6| Step: 3
Training loss: 1.7516967058181763
Validation loss: 2.0607223946561097

Epoch: 6| Step: 4
Training loss: 1.8727812767028809
Validation loss: 2.06568326744982

Epoch: 6| Step: 5
Training loss: 3.159853935241699
Validation loss: 2.070371049706654

Epoch: 6| Step: 6
Training loss: 2.1442947387695312
Validation loss: 2.080054945843194

Epoch: 6| Step: 7
Training loss: 2.7019052505493164
Validation loss: 2.0782128277645318

Epoch: 6| Step: 8
Training loss: 2.364706039428711
Validation loss: 2.085182955188136

Epoch: 6| Step: 9
Training loss: 2.484903335571289
Validation loss: 2.0745668667618946

Epoch: 6| Step: 10
Training loss: 2.430567741394043
Validation loss: 2.105249238270585

Epoch: 6| Step: 11
Training loss: 2.329616069793701
Validation loss: 2.0922744556139876

Epoch: 6| Step: 12
Training loss: 1.9082870483398438
Validation loss: 2.0836820538325975

Epoch: 6| Step: 13
Training loss: 2.0367040634155273
Validation loss: 2.068972326094104

Epoch: 147| Step: 0
Training loss: 2.5101215839385986
Validation loss: 2.0819674845664733

Epoch: 6| Step: 1
Training loss: 3.0179660320281982
Validation loss: 2.0769351707991732

Epoch: 6| Step: 2
Training loss: 1.921903371810913
Validation loss: 2.073980153247874

Epoch: 6| Step: 3
Training loss: 2.1486425399780273
Validation loss: 2.075121371976791

Epoch: 6| Step: 4
Training loss: 2.879251480102539
Validation loss: 2.0895250125597884

Epoch: 6| Step: 5
Training loss: 2.185107469558716
Validation loss: 2.0955926141431256

Epoch: 6| Step: 6
Training loss: 2.270267963409424
Validation loss: 2.0958811390784478

Epoch: 6| Step: 7
Training loss: 1.8291563987731934
Validation loss: 2.0935653345559233

Epoch: 6| Step: 8
Training loss: 1.9498183727264404
Validation loss: 2.087660203697861

Epoch: 6| Step: 9
Training loss: 2.2500133514404297
Validation loss: 2.102367813869189

Epoch: 6| Step: 10
Training loss: 2.4221510887145996
Validation loss: 2.098692412017494

Epoch: 6| Step: 11
Training loss: 2.326528549194336
Validation loss: 2.088250752418272

Epoch: 6| Step: 12
Training loss: 2.2000885009765625
Validation loss: 2.0938334759845527

Epoch: 6| Step: 13
Training loss: 2.2088937759399414
Validation loss: 2.0849202115048646

Epoch: 148| Step: 0
Training loss: 2.7230732440948486
Validation loss: 2.0858130147380214

Epoch: 6| Step: 1
Training loss: 2.057288646697998
Validation loss: 2.0886157802356187

Epoch: 6| Step: 2
Training loss: 2.4845807552337646
Validation loss: 2.0917835171504686

Epoch: 6| Step: 3
Training loss: 2.7173690795898438
Validation loss: 2.0924200422020367

Epoch: 6| Step: 4
Training loss: 2.043964147567749
Validation loss: 2.0988173279710995

Epoch: 6| Step: 5
Training loss: 2.7799510955810547
Validation loss: 2.1254881299952024

Epoch: 6| Step: 6
Training loss: 3.101468563079834
Validation loss: 2.1250498756285636

Epoch: 6| Step: 7
Training loss: 2.166940212249756
Validation loss: 2.128740241450648

Epoch: 6| Step: 8
Training loss: 1.9435946941375732
Validation loss: 2.1227479057927288

Epoch: 6| Step: 9
Training loss: 2.063014030456543
Validation loss: 2.10726071429509

Epoch: 6| Step: 10
Training loss: 2.5046286582946777
Validation loss: 2.0946912188683786

Epoch: 6| Step: 11
Training loss: 1.6780236959457397
Validation loss: 2.095141298027449

Epoch: 6| Step: 12
Training loss: 1.687779426574707
Validation loss: 2.0884717959229664

Epoch: 6| Step: 13
Training loss: 2.0966551303863525
Validation loss: 2.077540059243479

Epoch: 149| Step: 0
Training loss: 2.149937391281128
Validation loss: 2.068246687612226

Epoch: 6| Step: 1
Training loss: 2.232116937637329
Validation loss: 2.0809532339854906

Epoch: 6| Step: 2
Training loss: 2.4190151691436768
Validation loss: 2.0677600214558263

Epoch: 6| Step: 3
Training loss: 2.4058430194854736
Validation loss: 2.0784374795934206

Epoch: 6| Step: 4
Training loss: 2.3133485317230225
Validation loss: 2.0859039034894717

Epoch: 6| Step: 5
Training loss: 2.7073583602905273
Validation loss: 2.068022858711981

Epoch: 6| Step: 6
Training loss: 2.2639317512512207
Validation loss: 2.0728247665589854

Epoch: 6| Step: 7
Training loss: 2.327277183532715
Validation loss: 2.0650060407577024

Epoch: 6| Step: 8
Training loss: 2.4336366653442383
Validation loss: 2.0793044797835813

Epoch: 6| Step: 9
Training loss: 1.7780449390411377
Validation loss: 2.1020598065468574

Epoch: 6| Step: 10
Training loss: 2.719770669937134
Validation loss: 2.1131533602232575

Epoch: 6| Step: 11
Training loss: 2.038393020629883
Validation loss: 2.1237688218393633

Epoch: 6| Step: 12
Training loss: 2.0797276496887207
Validation loss: 2.116448748496271

Epoch: 6| Step: 13
Training loss: 2.2352845668792725
Validation loss: 2.117280626809725

Epoch: 150| Step: 0
Training loss: 2.096634864807129
Validation loss: 2.1118977069854736

Epoch: 6| Step: 1
Training loss: 2.970755100250244
Validation loss: 2.102833399208643

Epoch: 6| Step: 2
Training loss: 2.421189069747925
Validation loss: 2.0883304226783013

Epoch: 6| Step: 3
Training loss: 1.6633297204971313
Validation loss: 2.10044668310432

Epoch: 6| Step: 4
Training loss: 2.460556983947754
Validation loss: 2.105597713942169

Epoch: 6| Step: 5
Training loss: 3.3130345344543457
Validation loss: 2.1087535812008764

Epoch: 6| Step: 6
Training loss: 1.6041343212127686
Validation loss: 2.0960159276121404

Epoch: 6| Step: 7
Training loss: 1.518681526184082
Validation loss: 2.1038425250719954

Epoch: 6| Step: 8
Training loss: 2.1737513542175293
Validation loss: 2.1003212275043612

Epoch: 6| Step: 9
Training loss: 2.3683390617370605
Validation loss: 2.0839521679826962

Epoch: 6| Step: 10
Training loss: 2.3716020584106445
Validation loss: 2.0930551610967165

Epoch: 6| Step: 11
Training loss: 2.5804195404052734
Validation loss: 2.0887696973739134

Epoch: 6| Step: 12
Training loss: 2.4467761516571045
Validation loss: 2.0913526691416258

Epoch: 6| Step: 13
Training loss: 1.8049006462097168
Validation loss: 2.0859960996976463

Epoch: 151| Step: 0
Training loss: 1.754868507385254
Validation loss: 2.0919449637013097

Epoch: 6| Step: 1
Training loss: 2.2823598384857178
Validation loss: 2.1194238816538165

Epoch: 6| Step: 2
Training loss: 2.0068717002868652
Validation loss: 2.099303783908967

Epoch: 6| Step: 3
Training loss: 2.380431652069092
Validation loss: 2.0958465453117125

Epoch: 6| Step: 4
Training loss: 2.2361791133880615
Validation loss: 2.1020228555125575

Epoch: 6| Step: 5
Training loss: 2.6119072437286377
Validation loss: 2.108898949879472

Epoch: 6| Step: 6
Training loss: 1.9181246757507324
Validation loss: 2.0975258722100207

Epoch: 6| Step: 7
Training loss: 2.83243465423584
Validation loss: 2.0969955357172156

Epoch: 6| Step: 8
Training loss: 2.74316143989563
Validation loss: 2.0930708787774526

Epoch: 6| Step: 9
Training loss: 1.9672538042068481
Validation loss: 2.0987807781465593

Epoch: 6| Step: 10
Training loss: 2.794461250305176
Validation loss: 2.110891161426421

Epoch: 6| Step: 11
Training loss: 1.9160611629486084
Validation loss: 2.0884636679003314

Epoch: 6| Step: 12
Training loss: 2.1147778034210205
Validation loss: 2.094406081784156

Epoch: 6| Step: 13
Training loss: 2.5972177982330322
Validation loss: 2.094821942749844

Epoch: 152| Step: 0
Training loss: 2.442455291748047
Validation loss: 2.0834444081911476

Epoch: 6| Step: 1
Training loss: 2.5503945350646973
Validation loss: 2.086558029215823

Epoch: 6| Step: 2
Training loss: 2.6542210578918457
Validation loss: 2.0934593754429973

Epoch: 6| Step: 3
Training loss: 2.512742042541504
Validation loss: 2.0749074694930867

Epoch: 6| Step: 4
Training loss: 2.6934986114501953
Validation loss: 2.075202703475952

Epoch: 6| Step: 5
Training loss: 2.0614562034606934
Validation loss: 2.0699444163230156

Epoch: 6| Step: 6
Training loss: 1.76604425907135
Validation loss: 2.068892155924151

Epoch: 6| Step: 7
Training loss: 2.54832124710083
Validation loss: 2.0749588063968125

Epoch: 6| Step: 8
Training loss: 2.1832399368286133
Validation loss: 2.087852959991783

Epoch: 6| Step: 9
Training loss: 2.7684245109558105
Validation loss: 2.093819228551721

Epoch: 6| Step: 10
Training loss: 1.6561447381973267
Validation loss: 2.10733219885057

Epoch: 6| Step: 11
Training loss: 1.978209376335144
Validation loss: 2.1238978498725483

Epoch: 6| Step: 12
Training loss: 1.6956274509429932
Validation loss: 2.1368574429583806

Epoch: 6| Step: 13
Training loss: 2.181584358215332
Validation loss: 2.1417322158813477

Epoch: 153| Step: 0
Training loss: 2.4897348880767822
Validation loss: 2.112947784444337

Epoch: 6| Step: 1
Training loss: 2.0384764671325684
Validation loss: 2.0736972593492076

Epoch: 6| Step: 2
Training loss: 1.8559377193450928
Validation loss: 2.0738385826028805

Epoch: 6| Step: 3
Training loss: 2.187671184539795
Validation loss: 2.07171134538548

Epoch: 6| Step: 4
Training loss: 2.5147104263305664
Validation loss: 2.0779530796953427

Epoch: 6| Step: 5
Training loss: 2.3698606491088867
Validation loss: 2.076461935556063

Epoch: 6| Step: 6
Training loss: 2.724771022796631
Validation loss: 2.070935219846746

Epoch: 6| Step: 7
Training loss: 2.1248512268066406
Validation loss: 2.0972355886172225

Epoch: 6| Step: 8
Training loss: 1.8053083419799805
Validation loss: 2.0912451872261624

Epoch: 6| Step: 9
Training loss: 2.1433815956115723
Validation loss: 2.1008379228653444

Epoch: 6| Step: 10
Training loss: 2.122640371322632
Validation loss: 2.1247093087883404

Epoch: 6| Step: 11
Training loss: 2.9785218238830566
Validation loss: 2.1336610881231164

Epoch: 6| Step: 12
Training loss: 2.187626838684082
Validation loss: 2.160868352459323

Epoch: 6| Step: 13
Training loss: 2.1266655921936035
Validation loss: 2.1513728531458045

Epoch: 154| Step: 0
Training loss: 2.8187255859375
Validation loss: 2.1184913137907624

Epoch: 6| Step: 1
Training loss: 3.027092456817627
Validation loss: 2.0991533879310853

Epoch: 6| Step: 2
Training loss: 2.2725486755371094
Validation loss: 2.0712354055014988

Epoch: 6| Step: 3
Training loss: 1.9624358415603638
Validation loss: 2.0652995724831857

Epoch: 6| Step: 4
Training loss: 1.840734601020813
Validation loss: 2.0625925858815513

Epoch: 6| Step: 5
Training loss: 1.8607556819915771
Validation loss: 2.0650645097096763

Epoch: 6| Step: 6
Training loss: 2.3648366928100586
Validation loss: 2.0522441799922655

Epoch: 6| Step: 7
Training loss: 3.361354351043701
Validation loss: 2.045560985483149

Epoch: 6| Step: 8
Training loss: 2.060473918914795
Validation loss: 2.059106748591187

Epoch: 6| Step: 9
Training loss: 1.9151341915130615
Validation loss: 2.0603846747388124

Epoch: 6| Step: 10
Training loss: 2.5236382484436035
Validation loss: 2.0714411966262327

Epoch: 6| Step: 11
Training loss: 2.219733953475952
Validation loss: 2.086567199358376

Epoch: 6| Step: 12
Training loss: 1.4626352787017822
Validation loss: 2.0899813944293606

Epoch: 6| Step: 13
Training loss: 2.017179250717163
Validation loss: 2.1290414769162416

Epoch: 155| Step: 0
Training loss: 1.3885700702667236
Validation loss: 2.1291866379399456

Epoch: 6| Step: 1
Training loss: 1.988673448562622
Validation loss: 2.1468872818895566

Epoch: 6| Step: 2
Training loss: 2.072861909866333
Validation loss: 2.1311825449748705

Epoch: 6| Step: 3
Training loss: 2.7711708545684814
Validation loss: 2.1297572838362826

Epoch: 6| Step: 4
Training loss: 2.146930694580078
Validation loss: 2.1540959112105833

Epoch: 6| Step: 5
Training loss: 2.138857841491699
Validation loss: 2.117254795566682

Epoch: 6| Step: 6
Training loss: 2.4612936973571777
Validation loss: 2.0803794066111245

Epoch: 6| Step: 7
Training loss: 2.362666606903076
Validation loss: 2.0654250011649182

Epoch: 6| Step: 8
Training loss: 2.704604148864746
Validation loss: 2.064039517474431

Epoch: 6| Step: 9
Training loss: 2.9168667793273926
Validation loss: 2.062020783783287

Epoch: 6| Step: 10
Training loss: 2.008915424346924
Validation loss: 2.0595672579221826

Epoch: 6| Step: 11
Training loss: 1.9204741716384888
Validation loss: 2.0521038783493863

Epoch: 6| Step: 12
Training loss: 2.379714012145996
Validation loss: 2.0633686332292456

Epoch: 6| Step: 13
Training loss: 2.3901541233062744
Validation loss: 2.064973813231273

Epoch: 156| Step: 0
Training loss: 2.441260576248169
Validation loss: 2.0655911481508644

Epoch: 6| Step: 1
Training loss: 2.523739814758301
Validation loss: 2.070015025395219

Epoch: 6| Step: 2
Training loss: 2.4295220375061035
Validation loss: 2.0571864830550326

Epoch: 6| Step: 3
Training loss: 1.9257630109786987
Validation loss: 2.0796303838811894

Epoch: 6| Step: 4
Training loss: 1.407372236251831
Validation loss: 2.0729450564230643

Epoch: 6| Step: 5
Training loss: 2.3862109184265137
Validation loss: 2.0874875976193334

Epoch: 6| Step: 6
Training loss: 2.438235282897949
Validation loss: 2.096921031193067

Epoch: 6| Step: 7
Training loss: 2.3363804817199707
Validation loss: 2.0974253428879606

Epoch: 6| Step: 8
Training loss: 2.3862743377685547
Validation loss: 2.1275418727628645

Epoch: 6| Step: 9
Training loss: 1.9988024234771729
Validation loss: 2.119890266849149

Epoch: 6| Step: 10
Training loss: 2.693829298019409
Validation loss: 2.1575948115318053

Epoch: 6| Step: 11
Training loss: 2.423309326171875
Validation loss: 2.1700645185286

Epoch: 6| Step: 12
Training loss: 2.0030789375305176
Validation loss: 2.159546168901587

Epoch: 6| Step: 13
Training loss: 2.0944454669952393
Validation loss: 2.159874657148956

Epoch: 157| Step: 0
Training loss: 2.4691169261932373
Validation loss: 2.1758456640346076

Epoch: 6| Step: 1
Training loss: 1.0679168701171875
Validation loss: 2.14158824951418

Epoch: 6| Step: 2
Training loss: 2.8551149368286133
Validation loss: 2.129639264075987

Epoch: 6| Step: 3
Training loss: 2.2283360958099365
Validation loss: 2.136558376332765

Epoch: 6| Step: 4
Training loss: 2.4423470497131348
Validation loss: 2.113865416537049

Epoch: 6| Step: 5
Training loss: 2.5302841663360596
Validation loss: 2.1110093234687723

Epoch: 6| Step: 6
Training loss: 2.658698081970215
Validation loss: 2.111309612950971

Epoch: 6| Step: 7
Training loss: 1.8726553916931152
Validation loss: 2.102938646911293

Epoch: 6| Step: 8
Training loss: 1.7139537334442139
Validation loss: 2.0980559651569655

Epoch: 6| Step: 9
Training loss: 1.89159095287323
Validation loss: 2.0982259319674585

Epoch: 6| Step: 10
Training loss: 2.700331687927246
Validation loss: 2.099822352009435

Epoch: 6| Step: 11
Training loss: 2.9011800289154053
Validation loss: 2.105620727744154

Epoch: 6| Step: 12
Training loss: 2.4243383407592773
Validation loss: 2.118457948007891

Epoch: 6| Step: 13
Training loss: 2.080338954925537
Validation loss: 2.129916734592889

Epoch: 158| Step: 0
Training loss: 1.4989148378372192
Validation loss: 2.1106945724897486

Epoch: 6| Step: 1
Training loss: 2.2605981826782227
Validation loss: 2.116875357525323

Epoch: 6| Step: 2
Training loss: 2.4338741302490234
Validation loss: 2.1436183119332917

Epoch: 6| Step: 3
Training loss: 2.4298787117004395
Validation loss: 2.16137126440643

Epoch: 6| Step: 4
Training loss: 2.090137481689453
Validation loss: 2.1659573944666053

Epoch: 6| Step: 5
Training loss: 2.1286468505859375
Validation loss: 2.163843031852476

Epoch: 6| Step: 6
Training loss: 2.0024123191833496
Validation loss: 2.145047782569803

Epoch: 6| Step: 7
Training loss: 2.315545082092285
Validation loss: 2.1078894112699773

Epoch: 6| Step: 8
Training loss: 2.7973999977111816
Validation loss: 2.0992565719030236

Epoch: 6| Step: 9
Training loss: 2.456164836883545
Validation loss: 2.0881372369745725

Epoch: 6| Step: 10
Training loss: 2.580833911895752
Validation loss: 2.096273165877147

Epoch: 6| Step: 11
Training loss: 2.515195608139038
Validation loss: 2.082566706083154

Epoch: 6| Step: 12
Training loss: 2.1383979320526123
Validation loss: 2.08082010669093

Epoch: 6| Step: 13
Training loss: 1.8436976671218872
Validation loss: 2.0848006740693124

Epoch: 159| Step: 0
Training loss: 2.2348766326904297
Validation loss: 2.0668140534431703

Epoch: 6| Step: 1
Training loss: 2.9099173545837402
Validation loss: 2.062018531624989

Epoch: 6| Step: 2
Training loss: 2.0560808181762695
Validation loss: 2.063738904973512

Epoch: 6| Step: 3
Training loss: 1.55611252784729
Validation loss: 2.0514719152963288

Epoch: 6| Step: 4
Training loss: 1.6261320114135742
Validation loss: 2.0577924431011243

Epoch: 6| Step: 5
Training loss: 2.3984532356262207
Validation loss: 2.065274719269045

Epoch: 6| Step: 6
Training loss: 2.595111846923828
Validation loss: 2.0678296371172835

Epoch: 6| Step: 7
Training loss: 2.247974395751953
Validation loss: 2.1090715495488976

Epoch: 6| Step: 8
Training loss: 1.7899925708770752
Validation loss: 2.114895528362643

Epoch: 6| Step: 9
Training loss: 1.865419864654541
Validation loss: 2.109167170780961

Epoch: 6| Step: 10
Training loss: 2.2373993396759033
Validation loss: 2.0850116001662387

Epoch: 6| Step: 11
Training loss: 2.9732460975646973
Validation loss: 2.078096837125799

Epoch: 6| Step: 12
Training loss: 2.0626473426818848
Validation loss: 2.06681030027328

Epoch: 6| Step: 13
Training loss: 3.0858070850372314
Validation loss: 2.075601077848865

Epoch: 160| Step: 0
Training loss: 1.6980421543121338
Validation loss: 2.068517282444944

Epoch: 6| Step: 1
Training loss: 2.322181224822998
Validation loss: 2.0659462739062566

Epoch: 6| Step: 2
Training loss: 1.742575764656067
Validation loss: 2.073359884241576

Epoch: 6| Step: 3
Training loss: 2.707742214202881
Validation loss: 2.083617309088348

Epoch: 6| Step: 4
Training loss: 2.1680798530578613
Validation loss: 2.063204878120012

Epoch: 6| Step: 5
Training loss: 1.525652527809143
Validation loss: 2.0753292524686424

Epoch: 6| Step: 6
Training loss: 1.8330408334732056
Validation loss: 2.083565823493465

Epoch: 6| Step: 7
Training loss: 2.555668830871582
Validation loss: 2.106583918294599

Epoch: 6| Step: 8
Training loss: 2.2024447917938232
Validation loss: 2.132203951958687

Epoch: 6| Step: 9
Training loss: 2.7532148361206055
Validation loss: 2.1556455319927585

Epoch: 6| Step: 10
Training loss: 2.481201171875
Validation loss: 2.127585049598448

Epoch: 6| Step: 11
Training loss: 2.881044626235962
Validation loss: 2.1149022861193587

Epoch: 6| Step: 12
Training loss: 2.1299328804016113
Validation loss: 2.0980434430542814

Epoch: 6| Step: 13
Training loss: 2.45099139213562
Validation loss: 2.086838037736954

Epoch: 161| Step: 0
Training loss: 1.816899299621582
Validation loss: 2.0657488428136355

Epoch: 6| Step: 1
Training loss: 2.3603410720825195
Validation loss: 2.0619918812987623

Epoch: 6| Step: 2
Training loss: 2.978226661682129
Validation loss: 2.0572204013024606

Epoch: 6| Step: 3
Training loss: 2.2396130561828613
Validation loss: 2.0613214226179224

Epoch: 6| Step: 4
Training loss: 2.0807061195373535
Validation loss: 2.078500807926219

Epoch: 6| Step: 5
Training loss: 2.0512146949768066
Validation loss: 2.084365306362029

Epoch: 6| Step: 6
Training loss: 1.917876958847046
Validation loss: 2.079131234076715

Epoch: 6| Step: 7
Training loss: 2.137032985687256
Validation loss: 2.0925459913028184

Epoch: 6| Step: 8
Training loss: 2.087775230407715
Validation loss: 2.070200732959214

Epoch: 6| Step: 9
Training loss: 2.943671226501465
Validation loss: 2.099239185292234

Epoch: 6| Step: 10
Training loss: 2.0330963134765625
Validation loss: 2.1139180660247803

Epoch: 6| Step: 11
Training loss: 2.196643352508545
Validation loss: 2.157274866616854

Epoch: 6| Step: 12
Training loss: 1.6831154823303223
Validation loss: 2.191799722692018

Epoch: 6| Step: 13
Training loss: 2.795060157775879
Validation loss: 2.2159613486259215

Epoch: 162| Step: 0
Training loss: 2.2276811599731445
Validation loss: 2.155379564531388

Epoch: 6| Step: 1
Training loss: 2.016850709915161
Validation loss: 2.1161761053146853

Epoch: 6| Step: 2
Training loss: 2.6370158195495605
Validation loss: 2.095783943771034

Epoch: 6| Step: 3
Training loss: 2.0463027954101562
Validation loss: 2.06731604888875

Epoch: 6| Step: 4
Training loss: 2.7391462326049805
Validation loss: 2.0736861767307406

Epoch: 6| Step: 5
Training loss: 1.5689506530761719
Validation loss: 2.053786511062294

Epoch: 6| Step: 6
Training loss: 2.4296457767486572
Validation loss: 2.0633382284513084

Epoch: 6| Step: 7
Training loss: 2.240729331970215
Validation loss: 2.0838460819695586

Epoch: 6| Step: 8
Training loss: 2.3313567638397217
Validation loss: 2.1149538652871245

Epoch: 6| Step: 9
Training loss: 2.464444160461426
Validation loss: 2.1854353181777464

Epoch: 6| Step: 10
Training loss: 2.286118984222412
Validation loss: 2.238420847923525

Epoch: 6| Step: 11
Training loss: 2.3303160667419434
Validation loss: 2.207102273100166

Epoch: 6| Step: 12
Training loss: 1.8252604007720947
Validation loss: 2.158559883794477

Epoch: 6| Step: 13
Training loss: 2.619755983352661
Validation loss: 2.1219869018882833

Epoch: 163| Step: 0
Training loss: 2.8696608543395996
Validation loss: 2.0781008146142446

Epoch: 6| Step: 1
Training loss: 2.3719778060913086
Validation loss: 2.0646510790753108

Epoch: 6| Step: 2
Training loss: 2.491567611694336
Validation loss: 2.0734449804470105

Epoch: 6| Step: 3
Training loss: 2.2363336086273193
Validation loss: 2.0736212704771306

Epoch: 6| Step: 4
Training loss: 2.343350648880005
Validation loss: 2.0988453844542145

Epoch: 6| Step: 5
Training loss: 2.0654640197753906
Validation loss: 2.1336776005324496

Epoch: 6| Step: 6
Training loss: 1.948049545288086
Validation loss: 2.1528324978325957

Epoch: 6| Step: 7
Training loss: 1.9918789863586426
Validation loss: 2.184217991367463

Epoch: 6| Step: 8
Training loss: 2.431222915649414
Validation loss: 2.205156877476682

Epoch: 6| Step: 9
Training loss: 2.0597124099731445
Validation loss: 2.2150621747457855

Epoch: 6| Step: 10
Training loss: 2.256107807159424
Validation loss: 2.1916140587099138

Epoch: 6| Step: 11
Training loss: 2.0664303302764893
Validation loss: 2.139698677165534

Epoch: 6| Step: 12
Training loss: 1.8187141418457031
Validation loss: 2.104890525981944

Epoch: 6| Step: 13
Training loss: 2.3880207538604736
Validation loss: 2.08683152608974

Epoch: 164| Step: 0
Training loss: 2.4804563522338867
Validation loss: 2.079179277984045

Epoch: 6| Step: 1
Training loss: 2.008075714111328
Validation loss: 2.0646925921081216

Epoch: 6| Step: 2
Training loss: 2.4992148876190186
Validation loss: 2.0816393231832855

Epoch: 6| Step: 3
Training loss: 1.9696303606033325
Validation loss: 2.1055834754820792

Epoch: 6| Step: 4
Training loss: 3.0209884643554688
Validation loss: 2.1060764712672078

Epoch: 6| Step: 5
Training loss: 2.150580644607544
Validation loss: 2.1117411198154574

Epoch: 6| Step: 6
Training loss: 2.32409930229187
Validation loss: 2.1178936855767363

Epoch: 6| Step: 7
Training loss: 2.0133955478668213
Validation loss: 2.10837387013179

Epoch: 6| Step: 8
Training loss: 1.7426912784576416
Validation loss: 2.0988680073010024

Epoch: 6| Step: 9
Training loss: 1.918505311012268
Validation loss: 2.0974358512509252

Epoch: 6| Step: 10
Training loss: 2.790315866470337
Validation loss: 2.096122496871538

Epoch: 6| Step: 11
Training loss: 2.6272220611572266
Validation loss: 2.0971206388165875

Epoch: 6| Step: 12
Training loss: 1.9597127437591553
Validation loss: 2.0892830446202266

Epoch: 6| Step: 13
Training loss: 2.434434652328491
Validation loss: 2.1141087162879204

Epoch: 165| Step: 0
Training loss: 1.8295533657073975
Validation loss: 2.1090634920263804

Epoch: 6| Step: 1
Training loss: 2.3557546138763428
Validation loss: 2.1085607005703833

Epoch: 6| Step: 2
Training loss: 2.2793846130371094
Validation loss: 2.098481596157115

Epoch: 6| Step: 3
Training loss: 2.321901798248291
Validation loss: 2.1001294312938565

Epoch: 6| Step: 4
Training loss: 1.9302539825439453
Validation loss: 2.1015828091611146

Epoch: 6| Step: 5
Training loss: 2.602789878845215
Validation loss: 2.108169755628032

Epoch: 6| Step: 6
Training loss: 2.168867588043213
Validation loss: 2.09792060236777

Epoch: 6| Step: 7
Training loss: 2.646073341369629
Validation loss: 2.092399792004657

Epoch: 6| Step: 8
Training loss: 1.7394789457321167
Validation loss: 2.082652930290468

Epoch: 6| Step: 9
Training loss: 2.021390914916992
Validation loss: 2.1070602196519093

Epoch: 6| Step: 10
Training loss: 2.0756678581237793
Validation loss: 2.100891690100393

Epoch: 6| Step: 11
Training loss: 2.9276177883148193
Validation loss: 2.0945146006922566

Epoch: 6| Step: 12
Training loss: 1.462648630142212
Validation loss: 2.078584255710725

Epoch: 6| Step: 13
Training loss: 2.5412492752075195
Validation loss: 2.0868314619987243

Epoch: 166| Step: 0
Training loss: 2.0318689346313477
Validation loss: 2.0993307867357807

Epoch: 6| Step: 1
Training loss: 2.8674068450927734
Validation loss: 2.08241537053098

Epoch: 6| Step: 2
Training loss: 2.266164779663086
Validation loss: 2.0939256042562504

Epoch: 6| Step: 3
Training loss: 1.8638458251953125
Validation loss: 2.085883217473184

Epoch: 6| Step: 4
Training loss: 1.9877665042877197
Validation loss: 2.075194722862654

Epoch: 6| Step: 5
Training loss: 2.1206042766571045
Validation loss: 2.0640475570514636

Epoch: 6| Step: 6
Training loss: 2.8543999195098877
Validation loss: 2.0679935896268455

Epoch: 6| Step: 7
Training loss: 2.685934543609619
Validation loss: 2.079644098076769

Epoch: 6| Step: 8
Training loss: 2.0967042446136475
Validation loss: 2.1003090386749594

Epoch: 6| Step: 9
Training loss: 2.4264681339263916
Validation loss: 2.1136878716048373

Epoch: 6| Step: 10
Training loss: 1.4477300643920898
Validation loss: 2.1119170496540685

Epoch: 6| Step: 11
Training loss: 2.278866767883301
Validation loss: 2.1219539078333045

Epoch: 6| Step: 12
Training loss: 1.475538969039917
Validation loss: 2.122458032382432

Epoch: 6| Step: 13
Training loss: 2.210963010787964
Validation loss: 2.130361742870782

Epoch: 167| Step: 0
Training loss: 2.462538719177246
Validation loss: 2.111639695782815

Epoch: 6| Step: 1
Training loss: 2.424422264099121
Validation loss: 2.1014478078452488

Epoch: 6| Step: 2
Training loss: 2.245088815689087
Validation loss: 2.1221502211786087

Epoch: 6| Step: 3
Training loss: 2.174839496612549
Validation loss: 2.1364311761753534

Epoch: 6| Step: 4
Training loss: 2.506406307220459
Validation loss: 2.1098744215503817

Epoch: 6| Step: 5
Training loss: 1.7503948211669922
Validation loss: 2.0800178948269097

Epoch: 6| Step: 6
Training loss: 3.0244927406311035
Validation loss: 2.077191839935959

Epoch: 6| Step: 7
Training loss: 2.1744298934936523
Validation loss: 2.0661876855358

Epoch: 6| Step: 8
Training loss: 1.9944592714309692
Validation loss: 2.051719142544654

Epoch: 6| Step: 9
Training loss: 1.8584511280059814
Validation loss: 2.0629403591156006

Epoch: 6| Step: 10
Training loss: 1.401827335357666
Validation loss: 2.0630958875020347

Epoch: 6| Step: 11
Training loss: 2.5180091857910156
Validation loss: 2.0750838210505824

Epoch: 6| Step: 12
Training loss: 2.3918678760528564
Validation loss: 2.1034839768563547

Epoch: 6| Step: 13
Training loss: 2.0224854946136475
Validation loss: 2.1463192098884174

Epoch: 168| Step: 0
Training loss: 2.1722729206085205
Validation loss: 2.1868065121353313

Epoch: 6| Step: 1
Training loss: 2.8817691802978516
Validation loss: 2.198994251989549

Epoch: 6| Step: 2
Training loss: 3.1558914184570312
Validation loss: 2.1295988046994774

Epoch: 6| Step: 3
Training loss: 1.8683841228485107
Validation loss: 2.087916499824934

Epoch: 6| Step: 4
Training loss: 2.432727813720703
Validation loss: 2.076340124171267

Epoch: 6| Step: 5
Training loss: 1.707607626914978
Validation loss: 2.0826297959973736

Epoch: 6| Step: 6
Training loss: 2.134121894836426
Validation loss: 2.0855551099264495

Epoch: 6| Step: 7
Training loss: 2.592390537261963
Validation loss: 2.0953883458209295

Epoch: 6| Step: 8
Training loss: 1.9794576168060303
Validation loss: 2.105300866147523

Epoch: 6| Step: 9
Training loss: 2.0668630599975586
Validation loss: 2.103556776559481

Epoch: 6| Step: 10
Training loss: 2.011336326599121
Validation loss: 2.1099690519353396

Epoch: 6| Step: 11
Training loss: 1.7564382553100586
Validation loss: 2.108421723047892

Epoch: 6| Step: 12
Training loss: 1.836721658706665
Validation loss: 2.1261939976804998

Epoch: 6| Step: 13
Training loss: 2.1627252101898193
Validation loss: 2.1490297009868007

Epoch: 169| Step: 0
Training loss: 2.553584098815918
Validation loss: 2.1397924884673087

Epoch: 6| Step: 1
Training loss: 1.9382578134536743
Validation loss: 2.107542064882094

Epoch: 6| Step: 2
Training loss: 2.1585206985473633
Validation loss: 2.127140647621565

Epoch: 6| Step: 3
Training loss: 1.6127933263778687
Validation loss: 2.123304900302682

Epoch: 6| Step: 4
Training loss: 1.9087550640106201
Validation loss: 2.1390637607984644

Epoch: 6| Step: 5
Training loss: 2.2879021167755127
Validation loss: 2.1473348832899526

Epoch: 6| Step: 6
Training loss: 2.230015277862549
Validation loss: 2.141315834496611

Epoch: 6| Step: 7
Training loss: 2.3340888023376465
Validation loss: 2.085957378469488

Epoch: 6| Step: 8
Training loss: 2.05606746673584
Validation loss: 2.079735081682923

Epoch: 6| Step: 9
Training loss: 1.70077645778656
Validation loss: 2.0521482293323805

Epoch: 6| Step: 10
Training loss: 3.017306327819824
Validation loss: 2.056267969069942

Epoch: 6| Step: 11
Training loss: 2.0237770080566406
Validation loss: 2.053685618985084

Epoch: 6| Step: 12
Training loss: 2.428995370864868
Validation loss: 2.0507744582750465

Epoch: 6| Step: 13
Training loss: 2.111234426498413
Validation loss: 2.0588623349384596

Epoch: 170| Step: 0
Training loss: 1.9889954328536987
Validation loss: 2.0604221359375985

Epoch: 6| Step: 1
Training loss: 2.3593251705169678
Validation loss: 2.0569495693329842

Epoch: 6| Step: 2
Training loss: 2.252737045288086
Validation loss: 2.0619435771819083

Epoch: 6| Step: 3
Training loss: 2.377882719039917
Validation loss: 2.068754021839429

Epoch: 6| Step: 4
Training loss: 2.1673669815063477
Validation loss: 2.073329387172576

Epoch: 6| Step: 5
Training loss: 1.205673098564148
Validation loss: 2.0820504619229223

Epoch: 6| Step: 6
Training loss: 1.6076234579086304
Validation loss: 2.0929551098936345

Epoch: 6| Step: 7
Training loss: 2.5120301246643066
Validation loss: 2.1029056182471653

Epoch: 6| Step: 8
Training loss: 2.3670427799224854
Validation loss: 2.1044917773174983

Epoch: 6| Step: 9
Training loss: 2.385728120803833
Validation loss: 2.127854367738129

Epoch: 6| Step: 10
Training loss: 2.914243698120117
Validation loss: 2.124692911742836

Epoch: 6| Step: 11
Training loss: 2.8853096961975098
Validation loss: 2.1236063434231665

Epoch: 6| Step: 12
Training loss: 1.2708631753921509
Validation loss: 2.113369894284074

Epoch: 6| Step: 13
Training loss: 2.4435806274414062
Validation loss: 2.1139340221240954

Epoch: 171| Step: 0
Training loss: 2.258715867996216
Validation loss: 2.1041541843004126

Epoch: 6| Step: 1
Training loss: 1.9589810371398926
Validation loss: 2.083856216040991

Epoch: 6| Step: 2
Training loss: 2.1081252098083496
Validation loss: 2.0885007125075146

Epoch: 6| Step: 3
Training loss: 2.492556571960449
Validation loss: 2.0647375199102584

Epoch: 6| Step: 4
Training loss: 2.4041218757629395
Validation loss: 2.0648934559155534

Epoch: 6| Step: 5
Training loss: 2.375908374786377
Validation loss: 2.085575608796971

Epoch: 6| Step: 6
Training loss: 2.00421142578125
Validation loss: 2.0843757967795096

Epoch: 6| Step: 7
Training loss: 2.956331253051758
Validation loss: 2.150639563478449

Epoch: 6| Step: 8
Training loss: 2.1807003021240234
Validation loss: 2.193878727574502

Epoch: 6| Step: 9
Training loss: 1.593587875366211
Validation loss: 2.1657069575402046

Epoch: 6| Step: 10
Training loss: 1.2821751832962036
Validation loss: 2.136347322053807

Epoch: 6| Step: 11
Training loss: 2.6056079864501953
Validation loss: 2.116125291393649

Epoch: 6| Step: 12
Training loss: 1.678846836090088
Validation loss: 2.0956843232595794

Epoch: 6| Step: 13
Training loss: 2.8178582191467285
Validation loss: 2.1013149164056264

Epoch: 172| Step: 0
Training loss: 2.129092216491699
Validation loss: 2.1115995094340336

Epoch: 6| Step: 1
Training loss: 2.1931259632110596
Validation loss: 2.105661963903776

Epoch: 6| Step: 2
Training loss: 2.541958808898926
Validation loss: 2.096377234305105

Epoch: 6| Step: 3
Training loss: 2.016713857650757
Validation loss: 2.0944282060028403

Epoch: 6| Step: 4
Training loss: 2.9028515815734863
Validation loss: 2.0796872005667737

Epoch: 6| Step: 5
Training loss: 2.148193359375
Validation loss: 2.075011690457662

Epoch: 6| Step: 6
Training loss: 1.8524878025054932
Validation loss: 2.0873480202049337

Epoch: 6| Step: 7
Training loss: 2.09114408493042
Validation loss: 2.0965445810748684

Epoch: 6| Step: 8
Training loss: 2.277388572692871
Validation loss: 2.1092373119887484

Epoch: 6| Step: 9
Training loss: 1.7591474056243896
Validation loss: 2.115815375440864

Epoch: 6| Step: 10
Training loss: 1.8568990230560303
Validation loss: 2.0851045347029165

Epoch: 6| Step: 11
Training loss: 2.2970452308654785
Validation loss: 2.082800263999611

Epoch: 6| Step: 12
Training loss: 2.512995481491089
Validation loss: 2.084209261402007

Epoch: 6| Step: 13
Training loss: 2.701474666595459
Validation loss: 2.094336639168442

Epoch: 173| Step: 0
Training loss: 1.9272968769073486
Validation loss: 2.1331836280002388

Epoch: 6| Step: 1
Training loss: 1.6932477951049805
Validation loss: 2.164224632324711

Epoch: 6| Step: 2
Training loss: 2.3056631088256836
Validation loss: 2.1847913675410773

Epoch: 6| Step: 3
Training loss: 2.2156128883361816
Validation loss: 2.173279780213551

Epoch: 6| Step: 4
Training loss: 2.1136348247528076
Validation loss: 2.118434416350498

Epoch: 6| Step: 5
Training loss: 2.1460559368133545
Validation loss: 2.1037526463949554

Epoch: 6| Step: 6
Training loss: 2.553805351257324
Validation loss: 2.061227189597263

Epoch: 6| Step: 7
Training loss: 2.1093626022338867
Validation loss: 2.0524655195974533

Epoch: 6| Step: 8
Training loss: 2.144010066986084
Validation loss: 2.061296715531298

Epoch: 6| Step: 9
Training loss: 1.7877024412155151
Validation loss: 2.04800667301301

Epoch: 6| Step: 10
Training loss: 2.136655807495117
Validation loss: 2.050296929574782

Epoch: 6| Step: 11
Training loss: 2.2955732345581055
Validation loss: 2.0472864873947634

Epoch: 6| Step: 12
Training loss: 2.4501004219055176
Validation loss: 2.038279098849143

Epoch: 6| Step: 13
Training loss: 3.0219125747680664
Validation loss: 2.0537470233055855

Epoch: 174| Step: 0
Training loss: 1.9638044834136963
Validation loss: 2.083516777202647

Epoch: 6| Step: 1
Training loss: 1.5602264404296875
Validation loss: 2.117196270214614

Epoch: 6| Step: 2
Training loss: 2.9172911643981934
Validation loss: 2.14601396488887

Epoch: 6| Step: 3
Training loss: 1.4833767414093018
Validation loss: 2.144751400075933

Epoch: 6| Step: 4
Training loss: 1.9474997520446777
Validation loss: 2.1355754739494732

Epoch: 6| Step: 5
Training loss: 2.4806361198425293
Validation loss: 2.142346182177144

Epoch: 6| Step: 6
Training loss: 2.299910545349121
Validation loss: 2.1445474880997852

Epoch: 6| Step: 7
Training loss: 1.7692677974700928
Validation loss: 2.1543139283375075

Epoch: 6| Step: 8
Training loss: 2.414564609527588
Validation loss: 2.1503550519225416

Epoch: 6| Step: 9
Training loss: 1.9528509378433228
Validation loss: 2.1601105377238285

Epoch: 6| Step: 10
Training loss: 2.293466567993164
Validation loss: 2.1581465890330653

Epoch: 6| Step: 11
Training loss: 2.270775318145752
Validation loss: 2.155066990083264

Epoch: 6| Step: 12
Training loss: 2.483675003051758
Validation loss: 2.148772998522687

Epoch: 6| Step: 13
Training loss: 2.5742058753967285
Validation loss: 2.1236902795812136

Epoch: 175| Step: 0
Training loss: 2.351949453353882
Validation loss: 2.1135990978569112

Epoch: 6| Step: 1
Training loss: 2.338167428970337
Validation loss: 2.0994603582607803

Epoch: 6| Step: 2
Training loss: 2.0456647872924805
Validation loss: 2.0896444371951524

Epoch: 6| Step: 3
Training loss: 3.0096375942230225
Validation loss: 2.092045996778755

Epoch: 6| Step: 4
Training loss: 1.2281328439712524
Validation loss: 2.087941849103538

Epoch: 6| Step: 5
Training loss: 2.126523494720459
Validation loss: 2.090373709637632

Epoch: 6| Step: 6
Training loss: 2.6752116680145264
Validation loss: 2.097661720809116

Epoch: 6| Step: 7
Training loss: 1.8010244369506836
Validation loss: 2.1078708710209018

Epoch: 6| Step: 8
Training loss: 2.4707529544830322
Validation loss: 2.1167806733039116

Epoch: 6| Step: 9
Training loss: 1.8455984592437744
Validation loss: 2.1324765579674834

Epoch: 6| Step: 10
Training loss: 1.3321475982666016
Validation loss: 2.151767570485351

Epoch: 6| Step: 11
Training loss: 2.466071844100952
Validation loss: 2.1575004477654733

Epoch: 6| Step: 12
Training loss: 1.92900550365448
Validation loss: 2.1306117426964546

Epoch: 6| Step: 13
Training loss: 2.5509026050567627
Validation loss: 2.1065250878692954

Epoch: 176| Step: 0
Training loss: 2.507047653198242
Validation loss: 2.0744514439695623

Epoch: 6| Step: 1
Training loss: 1.6085786819458008
Validation loss: 2.062013958090095

Epoch: 6| Step: 2
Training loss: 1.2960381507873535
Validation loss: 2.0584261212297665

Epoch: 6| Step: 3
Training loss: 1.9770164489746094
Validation loss: 2.0528004425828175

Epoch: 6| Step: 4
Training loss: 2.002898931503296
Validation loss: 2.039382191114528

Epoch: 6| Step: 5
Training loss: 2.6037516593933105
Validation loss: 2.0372358124743224

Epoch: 6| Step: 6
Training loss: 1.82914400100708
Validation loss: 2.057365802026564

Epoch: 6| Step: 7
Training loss: 2.0548503398895264
Validation loss: 2.0753929012565204

Epoch: 6| Step: 8
Training loss: 2.3222532272338867
Validation loss: 2.0755803456870456

Epoch: 6| Step: 9
Training loss: 2.6297199726104736
Validation loss: 2.100816426738616

Epoch: 6| Step: 10
Training loss: 2.1917967796325684
Validation loss: 2.099331530191565

Epoch: 6| Step: 11
Training loss: 2.2043769359588623
Validation loss: 2.119888836337674

Epoch: 6| Step: 12
Training loss: 2.302858591079712
Validation loss: 2.148263433928131

Epoch: 6| Step: 13
Training loss: 2.6836206912994385
Validation loss: 2.1428204249310236

Epoch: 177| Step: 0
Training loss: 2.424339771270752
Validation loss: 2.1505170265833535

Epoch: 6| Step: 1
Training loss: 1.8086727857589722
Validation loss: 2.12404998143514

Epoch: 6| Step: 2
Training loss: 2.1234936714172363
Validation loss: 2.0813431124533377

Epoch: 6| Step: 3
Training loss: 2.1327004432678223
Validation loss: 2.0753255326260804

Epoch: 6| Step: 4
Training loss: 2.064499616622925
Validation loss: 2.0824052287686254

Epoch: 6| Step: 5
Training loss: 2.6496777534484863
Validation loss: 2.0747806949000203

Epoch: 6| Step: 6
Training loss: 1.8098828792572021
Validation loss: 2.0658416030227498

Epoch: 6| Step: 7
Training loss: 2.277912139892578
Validation loss: 2.085345172112988

Epoch: 6| Step: 8
Training loss: 2.243311882019043
Validation loss: 2.077873709381268

Epoch: 6| Step: 9
Training loss: 2.2658753395080566
Validation loss: 2.089428124889251

Epoch: 6| Step: 10
Training loss: 2.632341146469116
Validation loss: 2.117189052284405

Epoch: 6| Step: 11
Training loss: 1.7419847249984741
Validation loss: 2.1075363107906875

Epoch: 6| Step: 12
Training loss: 1.827435851097107
Validation loss: 2.1317480046262025

Epoch: 6| Step: 13
Training loss: 1.2613328695297241
Validation loss: 2.142059636372392

Epoch: 178| Step: 0
Training loss: 1.6624350547790527
Validation loss: 2.160886460734952

Epoch: 6| Step: 1
Training loss: 1.961539626121521
Validation loss: 2.1688810010110178

Epoch: 6| Step: 2
Training loss: 1.6604506969451904
Validation loss: 2.183718922317669

Epoch: 6| Step: 3
Training loss: 1.946388840675354
Validation loss: 2.15669390719424

Epoch: 6| Step: 4
Training loss: 3.04323148727417
Validation loss: 2.142987358954645

Epoch: 6| Step: 5
Training loss: 2.1253929138183594
Validation loss: 2.128079045203424

Epoch: 6| Step: 6
Training loss: 1.4267802238464355
Validation loss: 2.138896014100762

Epoch: 6| Step: 7
Training loss: 2.538081645965576
Validation loss: 2.125996870379294

Epoch: 6| Step: 8
Training loss: 2.293067216873169
Validation loss: 2.109159246567757

Epoch: 6| Step: 9
Training loss: 2.0975725650787354
Validation loss: 2.1199747990536433

Epoch: 6| Step: 10
Training loss: 3.2321205139160156
Validation loss: 2.1096283133311937

Epoch: 6| Step: 11
Training loss: 1.6130460500717163
Validation loss: 2.1097842326728244

Epoch: 6| Step: 12
Training loss: 1.8685204982757568
Validation loss: 2.102010880747149

Epoch: 6| Step: 13
Training loss: 1.9506416320800781
Validation loss: 2.1039351981173278

Epoch: 179| Step: 0
Training loss: 2.245887279510498
Validation loss: 2.117074094792848

Epoch: 6| Step: 1
Training loss: 1.6587103605270386
Validation loss: 2.1393601855924054

Epoch: 6| Step: 2
Training loss: 2.1753530502319336
Validation loss: 2.171001318962343

Epoch: 6| Step: 3
Training loss: 1.7561767101287842
Validation loss: 2.1663294787048013

Epoch: 6| Step: 4
Training loss: 2.223264217376709
Validation loss: 2.169154272284559

Epoch: 6| Step: 5
Training loss: 2.3944759368896484
Validation loss: 2.178812348714439

Epoch: 6| Step: 6
Training loss: 1.9946072101593018
Validation loss: 2.1635420809509935

Epoch: 6| Step: 7
Training loss: 2.0467352867126465
Validation loss: 2.130409150995234

Epoch: 6| Step: 8
Training loss: 2.0523548126220703
Validation loss: 2.125002878968434

Epoch: 6| Step: 9
Training loss: 2.3597540855407715
Validation loss: 2.1275467539346344

Epoch: 6| Step: 10
Training loss: 2.0604634284973145
Validation loss: 2.1127175797698317

Epoch: 6| Step: 11
Training loss: 2.4853785037994385
Validation loss: 2.1174044019432476

Epoch: 6| Step: 12
Training loss: 2.0290253162384033
Validation loss: 2.099980585036739

Epoch: 6| Step: 13
Training loss: 2.029405355453491
Validation loss: 2.0868303980878604

Epoch: 180| Step: 0
Training loss: 1.8761121034622192
Validation loss: 2.0928451515013173

Epoch: 6| Step: 1
Training loss: 2.4299139976501465
Validation loss: 2.0880009025655766

Epoch: 6| Step: 2
Training loss: 1.9016026258468628
Validation loss: 2.083231255572329

Epoch: 6| Step: 3
Training loss: 2.085278034210205
Validation loss: 2.100842747637021

Epoch: 6| Step: 4
Training loss: 2.0025243759155273
Validation loss: 2.092165499605158

Epoch: 6| Step: 5
Training loss: 2.197632312774658
Validation loss: 2.0719838014212986

Epoch: 6| Step: 6
Training loss: 1.9635813236236572
Validation loss: 2.0748670178074993

Epoch: 6| Step: 7
Training loss: 2.067030906677246
Validation loss: 2.069677923315315

Epoch: 6| Step: 8
Training loss: 2.54996919631958
Validation loss: 2.077922849244969

Epoch: 6| Step: 9
Training loss: 2.4037866592407227
Validation loss: 2.065886071933213

Epoch: 6| Step: 10
Training loss: 1.2307013273239136
Validation loss: 2.070890445863047

Epoch: 6| Step: 11
Training loss: 1.8631072044372559
Validation loss: 2.0778679873353694

Epoch: 6| Step: 12
Training loss: 2.038674831390381
Validation loss: 2.1078112484306417

Epoch: 6| Step: 13
Training loss: 2.7904179096221924
Validation loss: 2.133875985299387

Epoch: 181| Step: 0
Training loss: 2.445207118988037
Validation loss: 2.191645781199137

Epoch: 6| Step: 1
Training loss: 2.055124282836914
Validation loss: 2.2083820578872517

Epoch: 6| Step: 2
Training loss: 2.3901431560516357
Validation loss: 2.222890966682024

Epoch: 6| Step: 3
Training loss: 1.573119878768921
Validation loss: 2.1921530820990123

Epoch: 6| Step: 4
Training loss: 2.7476861476898193
Validation loss: 2.1828495763963267

Epoch: 6| Step: 5
Training loss: 1.8188958168029785
Validation loss: 2.156518054264848

Epoch: 6| Step: 6
Training loss: 1.9918487071990967
Validation loss: 2.116694019686791

Epoch: 6| Step: 7
Training loss: 2.1190614700317383
Validation loss: 2.0976103762144684

Epoch: 6| Step: 8
Training loss: 1.6351338624954224
Validation loss: 2.0959475117345012

Epoch: 6| Step: 9
Training loss: 1.7658398151397705
Validation loss: 2.0941546963107203

Epoch: 6| Step: 10
Training loss: 2.5830438137054443
Validation loss: 2.0838595795375046

Epoch: 6| Step: 11
Training loss: 2.67915678024292
Validation loss: 2.0927533372755973

Epoch: 6| Step: 12
Training loss: 1.9095276594161987
Validation loss: 2.0901419193513933

Epoch: 6| Step: 13
Training loss: 1.2866864204406738
Validation loss: 2.094806002032372

Epoch: 182| Step: 0
Training loss: 1.9217063188552856
Validation loss: 2.1134017872554

Epoch: 6| Step: 1
Training loss: 2.2782888412475586
Validation loss: 2.1246792142109205

Epoch: 6| Step: 2
Training loss: 2.3519463539123535
Validation loss: 2.1264011757348174

Epoch: 6| Step: 3
Training loss: 2.24485445022583
Validation loss: 2.1432852847601778

Epoch: 6| Step: 4
Training loss: 2.1965951919555664
Validation loss: 2.143417391725766

Epoch: 6| Step: 5
Training loss: 1.8681323528289795
Validation loss: 2.158047799141176

Epoch: 6| Step: 6
Training loss: 2.3803205490112305
Validation loss: 2.1701957948746218

Epoch: 6| Step: 7
Training loss: 2.515664577484131
Validation loss: 2.1582202462739843

Epoch: 6| Step: 8
Training loss: 1.242560863494873
Validation loss: 2.1313117832265873

Epoch: 6| Step: 9
Training loss: 2.3512353897094727
Validation loss: 2.131725077987999

Epoch: 6| Step: 10
Training loss: 1.949571132659912
Validation loss: 2.1218887670065767

Epoch: 6| Step: 11
Training loss: 1.9491841793060303
Validation loss: 2.122660829174903

Epoch: 6| Step: 12
Training loss: 1.5467092990875244
Validation loss: 2.1141404849226757

Epoch: 6| Step: 13
Training loss: 2.0018231868743896
Validation loss: 2.1053275754374843

Epoch: 183| Step: 0
Training loss: 2.5350499153137207
Validation loss: 2.1190067965497255

Epoch: 6| Step: 1
Training loss: 1.6706223487854004
Validation loss: 2.1143823003256195

Epoch: 6| Step: 2
Training loss: 2.2518296241760254
Validation loss: 2.0951392368603776

Epoch: 6| Step: 3
Training loss: 2.3479232788085938
Validation loss: 2.091759738101754

Epoch: 6| Step: 4
Training loss: 1.8923494815826416
Validation loss: 2.0749129069748746

Epoch: 6| Step: 5
Training loss: 2.025087833404541
Validation loss: 2.085481111721326

Epoch: 6| Step: 6
Training loss: 1.533440351486206
Validation loss: 2.077007983320503

Epoch: 6| Step: 7
Training loss: 2.533773422241211
Validation loss: 2.0838110652021182

Epoch: 6| Step: 8
Training loss: 1.9676181077957153
Validation loss: 2.087774145987726

Epoch: 6| Step: 9
Training loss: 2.0695815086364746
Validation loss: 2.085242408578114

Epoch: 6| Step: 10
Training loss: 2.021496295928955
Validation loss: 2.0921421512480705

Epoch: 6| Step: 11
Training loss: 1.7607271671295166
Validation loss: 2.1107852933227376

Epoch: 6| Step: 12
Training loss: 1.9207435846328735
Validation loss: 2.139733769560373

Epoch: 6| Step: 13
Training loss: 2.142082452774048
Validation loss: 2.1714593697619695

Epoch: 184| Step: 0
Training loss: 1.9398086071014404
Validation loss: 2.1947076807739916

Epoch: 6| Step: 1
Training loss: 2.252923011779785
Validation loss: 2.169511579698132

Epoch: 6| Step: 2
Training loss: 1.7803726196289062
Validation loss: 2.1578765043648342

Epoch: 6| Step: 3
Training loss: 2.085890531539917
Validation loss: 2.1358335492431477

Epoch: 6| Step: 4
Training loss: 2.014094114303589
Validation loss: 2.1047498564566336

Epoch: 6| Step: 5
Training loss: 1.8622472286224365
Validation loss: 2.084335429694063

Epoch: 6| Step: 6
Training loss: 2.47485613822937
Validation loss: 2.0695539623178463

Epoch: 6| Step: 7
Training loss: 2.1852433681488037
Validation loss: 2.079761928127658

Epoch: 6| Step: 8
Training loss: 2.6741714477539062
Validation loss: 2.104436828244117

Epoch: 6| Step: 9
Training loss: 1.606735110282898
Validation loss: 2.085308623570268

Epoch: 6| Step: 10
Training loss: 2.1040616035461426
Validation loss: 2.0864362601310975

Epoch: 6| Step: 11
Training loss: 2.5563290119171143
Validation loss: 2.1013363689504643

Epoch: 6| Step: 12
Training loss: 1.4487433433532715
Validation loss: 2.094254414240519

Epoch: 6| Step: 13
Training loss: 1.894364833831787
Validation loss: 2.117903686338855

Epoch: 185| Step: 0
Training loss: 1.5149905681610107
Validation loss: 2.1288676236265447

Epoch: 6| Step: 1
Training loss: 2.8464694023132324
Validation loss: 2.172091140541979

Epoch: 6| Step: 2
Training loss: 2.4554243087768555
Validation loss: 2.207742214202881

Epoch: 6| Step: 3
Training loss: 1.6993745565414429
Validation loss: 2.2000722116039646

Epoch: 6| Step: 4
Training loss: 2.286602020263672
Validation loss: 2.1842310031255088

Epoch: 6| Step: 5
Training loss: 2.548443555831909
Validation loss: 2.1584276537741385

Epoch: 6| Step: 6
Training loss: 2.023998498916626
Validation loss: 2.105008139405199

Epoch: 6| Step: 7
Training loss: 1.6330986022949219
Validation loss: 2.1202532937449794

Epoch: 6| Step: 8
Training loss: 1.9025506973266602
Validation loss: 2.109631689645911

Epoch: 6| Step: 9
Training loss: 2.2879621982574463
Validation loss: 2.11019084658674

Epoch: 6| Step: 10
Training loss: 1.747645616531372
Validation loss: 2.107516440012122

Epoch: 6| Step: 11
Training loss: 2.5451979637145996
Validation loss: 2.124527067266485

Epoch: 6| Step: 12
Training loss: 1.7207872867584229
Validation loss: 2.1272718701311337

Epoch: 6| Step: 13
Training loss: 1.4115900993347168
Validation loss: 2.1154529894551923

Epoch: 186| Step: 0
Training loss: 1.9245885610580444
Validation loss: 2.1062166613917195

Epoch: 6| Step: 1
Training loss: 1.3404581546783447
Validation loss: 2.1089073586207565

Epoch: 6| Step: 2
Training loss: 1.829297661781311
Validation loss: 2.099744942880446

Epoch: 6| Step: 3
Training loss: 2.7963128089904785
Validation loss: 2.094184842160953

Epoch: 6| Step: 4
Training loss: 1.8398301601409912
Validation loss: 2.1172888150779148

Epoch: 6| Step: 5
Training loss: 2.0419578552246094
Validation loss: 2.121962429374777

Epoch: 6| Step: 6
Training loss: 1.6858303546905518
Validation loss: 2.1166782250968357

Epoch: 6| Step: 7
Training loss: 1.8858073949813843
Validation loss: 2.108098247999786

Epoch: 6| Step: 8
Training loss: 2.2603418827056885
Validation loss: 2.1269398402142268

Epoch: 6| Step: 9
Training loss: 2.268601417541504
Validation loss: 2.117524572598037

Epoch: 6| Step: 10
Training loss: 2.002148389816284
Validation loss: 2.085213433029831

Epoch: 6| Step: 11
Training loss: 1.7195627689361572
Validation loss: 2.0612828885355303

Epoch: 6| Step: 12
Training loss: 2.6295664310455322
Validation loss: 2.0671476215444584

Epoch: 6| Step: 13
Training loss: 2.358072280883789
Validation loss: 2.081944086218393

Epoch: 187| Step: 0
Training loss: 1.6481859683990479
Validation loss: 2.0984886897507535

Epoch: 6| Step: 1
Training loss: 2.0403764247894287
Validation loss: 2.0935672611318608

Epoch: 6| Step: 2
Training loss: 2.344021797180176
Validation loss: 2.0816947747302312

Epoch: 6| Step: 3
Training loss: 2.058711051940918
Validation loss: 2.057790799807477

Epoch: 6| Step: 4
Training loss: 2.38230037689209
Validation loss: 2.0766022538626068

Epoch: 6| Step: 5
Training loss: 2.4243435859680176
Validation loss: 2.0942800839742026

Epoch: 6| Step: 6
Training loss: 1.9226895570755005
Validation loss: 2.1203455335350445

Epoch: 6| Step: 7
Training loss: 2.1317615509033203
Validation loss: 2.1354498888856623

Epoch: 6| Step: 8
Training loss: 1.8768516778945923
Validation loss: 2.130698755223264

Epoch: 6| Step: 9
Training loss: 1.6864756345748901
Validation loss: 2.140073977490907

Epoch: 6| Step: 10
Training loss: 2.552471160888672
Validation loss: 2.146179945238175

Epoch: 6| Step: 11
Training loss: 1.1803826093673706
Validation loss: 2.132838911907647

Epoch: 6| Step: 12
Training loss: 2.4483814239501953
Validation loss: 2.140526133198892

Epoch: 6| Step: 13
Training loss: 2.196835994720459
Validation loss: 2.1134830354362406

Epoch: 188| Step: 0
Training loss: 2.0424869060516357
Validation loss: 2.1020776699948054

Epoch: 6| Step: 1
Training loss: 1.8618545532226562
Validation loss: 2.085206106144895

Epoch: 6| Step: 2
Training loss: 2.6717114448547363
Validation loss: 2.0606882213264384

Epoch: 6| Step: 3
Training loss: 2.4523723125457764
Validation loss: 2.062972835315171

Epoch: 6| Step: 4
Training loss: 1.861873984336853
Validation loss: 2.063321631441834

Epoch: 6| Step: 5
Training loss: 1.595786452293396
Validation loss: 2.049379430791383

Epoch: 6| Step: 6
Training loss: 2.250572681427002
Validation loss: 2.0619432016085555

Epoch: 6| Step: 7
Training loss: 1.7720867395401
Validation loss: 2.0751817598137805

Epoch: 6| Step: 8
Training loss: 1.8069111108779907
Validation loss: 2.088351306094918

Epoch: 6| Step: 9
Training loss: 1.8788418769836426
Validation loss: 2.08143473440601

Epoch: 6| Step: 10
Training loss: 2.2425451278686523
Validation loss: 2.102867134155766

Epoch: 6| Step: 11
Training loss: 2.475900888442993
Validation loss: 2.102548319806335

Epoch: 6| Step: 12
Training loss: 1.597973108291626
Validation loss: 2.0853599579103532

Epoch: 6| Step: 13
Training loss: 2.2056498527526855
Validation loss: 2.087510629366803

Epoch: 189| Step: 0
Training loss: 2.23065185546875
Validation loss: 2.087554213821247

Epoch: 6| Step: 1
Training loss: 2.3498342037200928
Validation loss: 2.0924745452019478

Epoch: 6| Step: 2
Training loss: 1.177045464515686
Validation loss: 2.0991196632385254

Epoch: 6| Step: 3
Training loss: 1.3941948413848877
Validation loss: 2.0947834086674515

Epoch: 6| Step: 4
Training loss: 1.7478413581848145
Validation loss: 2.1079040547852874

Epoch: 6| Step: 5
Training loss: 2.20298433303833
Validation loss: 2.0945781956436815

Epoch: 6| Step: 6
Training loss: 1.7273459434509277
Validation loss: 2.0873407817655996

Epoch: 6| Step: 7
Training loss: 2.2904934883117676
Validation loss: 2.1045760646943124

Epoch: 6| Step: 8
Training loss: 2.4381628036499023
Validation loss: 2.12526023516091

Epoch: 6| Step: 9
Training loss: 2.1731762886047363
Validation loss: 2.122102161889435

Epoch: 6| Step: 10
Training loss: 1.8192095756530762
Validation loss: 2.112132454431185

Epoch: 6| Step: 11
Training loss: 2.3109540939331055
Validation loss: 2.1213752531236216

Epoch: 6| Step: 12
Training loss: 2.541240692138672
Validation loss: 2.1071165184820853

Epoch: 6| Step: 13
Training loss: 1.3879519701004028
Validation loss: 2.0953782809677945

Epoch: 190| Step: 0
Training loss: 2.317507743835449
Validation loss: 2.124585226017942

Epoch: 6| Step: 1
Training loss: 1.5588290691375732
Validation loss: 2.120506481457782

Epoch: 6| Step: 2
Training loss: 1.9179441928863525
Validation loss: 2.1341009011832615

Epoch: 6| Step: 3
Training loss: 2.262205123901367
Validation loss: 2.138863323837198

Epoch: 6| Step: 4
Training loss: 1.8326953649520874
Validation loss: 2.119913742106448

Epoch: 6| Step: 5
Training loss: 1.9097740650177002
Validation loss: 2.0896454857241724

Epoch: 6| Step: 6
Training loss: 2.5248937606811523
Validation loss: 2.0991055580877487

Epoch: 6| Step: 7
Training loss: 2.614633560180664
Validation loss: 2.083907595244787

Epoch: 6| Step: 8
Training loss: 1.769983172416687
Validation loss: 2.0794795149116108

Epoch: 6| Step: 9
Training loss: 1.8009114265441895
Validation loss: 2.0665516135513142

Epoch: 6| Step: 10
Training loss: 2.247558116912842
Validation loss: 2.0589395351307367

Epoch: 6| Step: 11
Training loss: 2.047574758529663
Validation loss: 2.0746515797030542

Epoch: 6| Step: 12
Training loss: 1.5293242931365967
Validation loss: 2.075180016538148

Epoch: 6| Step: 13
Training loss: 1.6211812496185303
Validation loss: 2.0862210181451615

Epoch: 191| Step: 0
Training loss: 1.445852518081665
Validation loss: 2.1074870837632047

Epoch: 6| Step: 1
Training loss: 1.976625919342041
Validation loss: 2.0985520937109507

Epoch: 6| Step: 2
Training loss: 2.1650023460388184
Validation loss: 2.0870607668353665

Epoch: 6| Step: 3
Training loss: 1.7993906736373901
Validation loss: 2.095541971986012

Epoch: 6| Step: 4
Training loss: 1.6166715621948242
Validation loss: 2.1092377708804224

Epoch: 6| Step: 5
Training loss: 1.7301137447357178
Validation loss: 2.1057253524821293

Epoch: 6| Step: 6
Training loss: 2.173098087310791
Validation loss: 2.120803948371641

Epoch: 6| Step: 7
Training loss: 2.1919379234313965
Validation loss: 2.0982624177009828

Epoch: 6| Step: 8
Training loss: 2.1858601570129395
Validation loss: 2.0971868781633276

Epoch: 6| Step: 9
Training loss: 3.0228915214538574
Validation loss: 2.1031512573201168

Epoch: 6| Step: 10
Training loss: 1.6261415481567383
Validation loss: 2.084785701126181

Epoch: 6| Step: 11
Training loss: 1.9307026863098145
Validation loss: 2.0913795630137124

Epoch: 6| Step: 12
Training loss: 2.1165108680725098
Validation loss: 2.0869054230310584

Epoch: 6| Step: 13
Training loss: 1.5378696918487549
Validation loss: 2.0877186021497174

Epoch: 192| Step: 0
Training loss: 1.8582545518875122
Validation loss: 2.0794949608464397

Epoch: 6| Step: 1
Training loss: 1.9574055671691895
Validation loss: 2.0777124345943494

Epoch: 6| Step: 2
Training loss: 1.4223906993865967
Validation loss: 2.0856644286904285

Epoch: 6| Step: 3
Training loss: 2.4583122730255127
Validation loss: 2.0932040124811153

Epoch: 6| Step: 4
Training loss: 1.6911886930465698
Validation loss: 2.0950108241009455

Epoch: 6| Step: 5
Training loss: 2.459195852279663
Validation loss: 2.119238463781213

Epoch: 6| Step: 6
Training loss: 2.53886079788208
Validation loss: 2.134616659533593

Epoch: 6| Step: 7
Training loss: 1.855316162109375
Validation loss: 2.1199749900448706

Epoch: 6| Step: 8
Training loss: 1.3559850454330444
Validation loss: 2.0955922475425144

Epoch: 6| Step: 9
Training loss: 2.1971986293792725
Validation loss: 2.1009686326467865

Epoch: 6| Step: 10
Training loss: 1.9669711589813232
Validation loss: 2.0941525518253283

Epoch: 6| Step: 11
Training loss: 1.755763292312622
Validation loss: 2.091798177329443

Epoch: 6| Step: 12
Training loss: 2.130129337310791
Validation loss: 2.0953253392250306

Epoch: 6| Step: 13
Training loss: 2.2909257411956787
Validation loss: 2.0993875406121694

Epoch: 193| Step: 0
Training loss: 2.001461982727051
Validation loss: 2.1015252797834334

Epoch: 6| Step: 1
Training loss: 1.650540828704834
Validation loss: 2.0934016730195735

Epoch: 6| Step: 2
Training loss: 2.270768404006958
Validation loss: 2.0768495246928227

Epoch: 6| Step: 3
Training loss: 2.3535714149475098
Validation loss: 2.074882052278006

Epoch: 6| Step: 4
Training loss: 1.3130254745483398
Validation loss: 2.075618988724165

Epoch: 6| Step: 5
Training loss: 2.3960418701171875
Validation loss: 2.0743918521429903

Epoch: 6| Step: 6
Training loss: 1.9078978300094604
Validation loss: 2.0989378626628588

Epoch: 6| Step: 7
Training loss: 1.6463565826416016
Validation loss: 2.10392060331119

Epoch: 6| Step: 8
Training loss: 1.9418872594833374
Validation loss: 2.1089146265419583

Epoch: 6| Step: 9
Training loss: 1.8167002201080322
Validation loss: 2.113380196273968

Epoch: 6| Step: 10
Training loss: 2.292403221130371
Validation loss: 2.096837612890428

Epoch: 6| Step: 11
Training loss: 1.6687304973602295
Validation loss: 2.1124396888158654

Epoch: 6| Step: 12
Training loss: 2.018185615539551
Validation loss: 2.1052644586050384

Epoch: 6| Step: 13
Training loss: 2.364222526550293
Validation loss: 2.108880284012005

Epoch: 194| Step: 0
Training loss: 2.2953290939331055
Validation loss: 2.097999603517594

Epoch: 6| Step: 1
Training loss: 1.724031925201416
Validation loss: 2.088798979277252

Epoch: 6| Step: 2
Training loss: 1.7596304416656494
Validation loss: 2.0805281490407963

Epoch: 6| Step: 3
Training loss: 1.304337739944458
Validation loss: 2.080742753962035

Epoch: 6| Step: 4
Training loss: 1.9687600135803223
Validation loss: 2.083151299466369

Epoch: 6| Step: 5
Training loss: 1.6570930480957031
Validation loss: 2.122504508623513

Epoch: 6| Step: 6
Training loss: 2.2532427310943604
Validation loss: 2.0965275982374787

Epoch: 6| Step: 7
Training loss: 2.7380895614624023
Validation loss: 2.099244717628725

Epoch: 6| Step: 8
Training loss: 1.6579786539077759
Validation loss: 2.098564645295502

Epoch: 6| Step: 9
Training loss: 1.2890727519989014
Validation loss: 2.117987617369621

Epoch: 6| Step: 10
Training loss: 2.437211513519287
Validation loss: 2.11862374121143

Epoch: 6| Step: 11
Training loss: 1.818975567817688
Validation loss: 2.1044972404356925

Epoch: 6| Step: 12
Training loss: 1.9050800800323486
Validation loss: 2.079029562652752

Epoch: 6| Step: 13
Training loss: 3.0303306579589844
Validation loss: 2.0850689962346065

Epoch: 195| Step: 0
Training loss: 1.9454758167266846
Validation loss: 2.0777714073017077

Epoch: 6| Step: 1
Training loss: 2.4632821083068848
Validation loss: 2.071935128140193

Epoch: 6| Step: 2
Training loss: 2.1338894367218018
Validation loss: 2.0647513353696434

Epoch: 6| Step: 3
Training loss: 1.7647161483764648
Validation loss: 2.0576435776167017

Epoch: 6| Step: 4
Training loss: 1.8006728887557983
Validation loss: 2.0716993911291963

Epoch: 6| Step: 5
Training loss: 1.9770814180374146
Validation loss: 2.071135691417161

Epoch: 6| Step: 6
Training loss: 2.722978115081787
Validation loss: 2.078552431957696

Epoch: 6| Step: 7
Training loss: 2.5002832412719727
Validation loss: 2.084414851280951

Epoch: 6| Step: 8
Training loss: 1.8310768604278564
Validation loss: 2.072472841508927

Epoch: 6| Step: 9
Training loss: 1.93290376663208
Validation loss: 2.0920096392272622

Epoch: 6| Step: 10
Training loss: 1.0191829204559326
Validation loss: 2.079064925511678

Epoch: 6| Step: 11
Training loss: 1.8410334587097168
Validation loss: 2.0863929512680217

Epoch: 6| Step: 12
Training loss: 1.49522864818573
Validation loss: 2.1046106610246884

Epoch: 6| Step: 13
Training loss: 1.9995697736740112
Validation loss: 2.1101336120277323

Epoch: 196| Step: 0
Training loss: 1.5887207984924316
Validation loss: 2.1115098050845567

Epoch: 6| Step: 1
Training loss: 1.5319063663482666
Validation loss: 2.1327970284287647

Epoch: 6| Step: 2
Training loss: 2.4476842880249023
Validation loss: 2.14963165790804

Epoch: 6| Step: 3
Training loss: 1.4926605224609375
Validation loss: 2.1577941063911683

Epoch: 6| Step: 4
Training loss: 2.6601192951202393
Validation loss: 2.184758124812957

Epoch: 6| Step: 5
Training loss: 1.798896312713623
Validation loss: 2.1870248112627255

Epoch: 6| Step: 6
Training loss: 1.631272554397583
Validation loss: 2.1984948650483163

Epoch: 6| Step: 7
Training loss: 2.6236042976379395
Validation loss: 2.1682941349603797

Epoch: 6| Step: 8
Training loss: 1.8342514038085938
Validation loss: 2.167232095554311

Epoch: 6| Step: 9
Training loss: 1.3299403190612793
Validation loss: 2.153325024471488

Epoch: 6| Step: 10
Training loss: 1.916121244430542
Validation loss: 2.124106744284271

Epoch: 6| Step: 11
Training loss: 1.8778687715530396
Validation loss: 2.118257781510712

Epoch: 6| Step: 12
Training loss: 2.413465976715088
Validation loss: 2.0973432858784995

Epoch: 6| Step: 13
Training loss: 2.313603401184082
Validation loss: 2.1055861224410353

Epoch: 197| Step: 0
Training loss: 1.9086170196533203
Validation loss: 2.0820167808122534

Epoch: 6| Step: 1
Training loss: 1.9447059631347656
Validation loss: 2.0779828640722458

Epoch: 6| Step: 2
Training loss: 2.119537591934204
Validation loss: 2.0647133191426597

Epoch: 6| Step: 3
Training loss: 1.7414796352386475
Validation loss: 2.045394398832834

Epoch: 6| Step: 4
Training loss: 2.589759349822998
Validation loss: 2.0608770026955554

Epoch: 6| Step: 5
Training loss: 1.528132677078247
Validation loss: 2.0586204580081406

Epoch: 6| Step: 6
Training loss: 1.4017958641052246
Validation loss: 2.085565731089602

Epoch: 6| Step: 7
Training loss: 2.371053695678711
Validation loss: 2.07296815482519

Epoch: 6| Step: 8
Training loss: 1.851473093032837
Validation loss: 2.08250758981192

Epoch: 6| Step: 9
Training loss: 1.8655043840408325
Validation loss: 2.0896467060171147

Epoch: 6| Step: 10
Training loss: 2.43874454498291
Validation loss: 2.0978677093341784

Epoch: 6| Step: 11
Training loss: 1.4584598541259766
Validation loss: 2.102491154465624

Epoch: 6| Step: 12
Training loss: 2.120330333709717
Validation loss: 2.114798563782887

Epoch: 6| Step: 13
Training loss: 1.6901297569274902
Validation loss: 2.1233470952639015

Epoch: 198| Step: 0
Training loss: 1.2101819515228271
Validation loss: 2.108472620287249

Epoch: 6| Step: 1
Training loss: 1.7326536178588867
Validation loss: 2.116004623392577

Epoch: 6| Step: 2
Training loss: 1.8897106647491455
Validation loss: 2.1151659514314387

Epoch: 6| Step: 3
Training loss: 2.3331832885742188
Validation loss: 2.1088347152997087

Epoch: 6| Step: 4
Training loss: 1.8621394634246826
Validation loss: 2.0929735078606555

Epoch: 6| Step: 5
Training loss: 2.0959787368774414
Validation loss: 2.115497807020782

Epoch: 6| Step: 6
Training loss: 2.0513339042663574
Validation loss: 2.132233891435849

Epoch: 6| Step: 7
Training loss: 1.9476145505905151
Validation loss: 2.111230306727912

Epoch: 6| Step: 8
Training loss: 1.6044474840164185
Validation loss: 2.1408610061932634

Epoch: 6| Step: 9
Training loss: 2.6172165870666504
Validation loss: 2.121742138298609

Epoch: 6| Step: 10
Training loss: 1.588761806488037
Validation loss: 2.0667009712547384

Epoch: 6| Step: 11
Training loss: 1.8478753566741943
Validation loss: 2.0571092174899195

Epoch: 6| Step: 12
Training loss: 2.2104392051696777
Validation loss: 2.0601133890049432

Epoch: 6| Step: 13
Training loss: 2.3928956985473633
Validation loss: 2.0702338744235296

Epoch: 199| Step: 0
Training loss: 1.9448364973068237
Validation loss: 2.0740832654378747

Epoch: 6| Step: 1
Training loss: 1.9507277011871338
Validation loss: 2.0853771035389235

Epoch: 6| Step: 2
Training loss: 2.1386098861694336
Validation loss: 2.0873853609126103

Epoch: 6| Step: 3
Training loss: 2.5521042346954346
Validation loss: 2.083230515962006

Epoch: 6| Step: 4
Training loss: 1.7078335285186768
Validation loss: 2.071823598236166

Epoch: 6| Step: 5
Training loss: 1.714583396911621
Validation loss: 2.0826449753135763

Epoch: 6| Step: 6
Training loss: 1.7908273935317993
Validation loss: 2.065827920872678

Epoch: 6| Step: 7
Training loss: 2.0022683143615723
Validation loss: 2.064004744252851

Epoch: 6| Step: 8
Training loss: 1.757620096206665
Validation loss: 2.052788770327004

Epoch: 6| Step: 9
Training loss: 2.03098464012146
Validation loss: 2.0566142964106735

Epoch: 6| Step: 10
Training loss: 1.8816206455230713
Validation loss: 2.071560985298567

Epoch: 6| Step: 11
Training loss: 2.150632381439209
Validation loss: 2.063628399243919

Epoch: 6| Step: 12
Training loss: 1.9667881727218628
Validation loss: 2.0940511636836554

Epoch: 6| Step: 13
Training loss: 1.4782135486602783
Validation loss: 2.1208667985854612

Epoch: 200| Step: 0
Training loss: 1.7292543649673462
Validation loss: 2.1495953272747736

Epoch: 6| Step: 1
Training loss: 2.140533924102783
Validation loss: 2.1464749536206646

Epoch: 6| Step: 2
Training loss: 1.9310773611068726
Validation loss: 2.132839141353484

Epoch: 6| Step: 3
Training loss: 2.048187732696533
Validation loss: 2.129931087134987

Epoch: 6| Step: 4
Training loss: 1.4971060752868652
Validation loss: 2.1331772124895485

Epoch: 6| Step: 5
Training loss: 2.0618038177490234
Validation loss: 2.1229954586234143

Epoch: 6| Step: 6
Training loss: 1.3089277744293213
Validation loss: 2.118784971134637

Epoch: 6| Step: 7
Training loss: 3.2057907581329346
Validation loss: 2.123675310483543

Epoch: 6| Step: 8
Training loss: 1.1796298027038574
Validation loss: 2.106406227234871

Epoch: 6| Step: 9
Training loss: 2.1034183502197266
Validation loss: 2.115601234538581

Epoch: 6| Step: 10
Training loss: 2.1169791221618652
Validation loss: 2.085765787350234

Epoch: 6| Step: 11
Training loss: 1.935908317565918
Validation loss: 2.0615867466054936

Epoch: 6| Step: 12
Training loss: 2.00809383392334
Validation loss: 2.0614786737708637

Epoch: 6| Step: 13
Training loss: 1.7694170475006104
Validation loss: 2.057324165939003

Epoch: 201| Step: 0
Training loss: 1.479400873184204
Validation loss: 2.0665607836938675

Epoch: 6| Step: 1
Training loss: 1.7432941198349
Validation loss: 2.0788054479065763

Epoch: 6| Step: 2
Training loss: 1.7969048023223877
Validation loss: 2.0962388489836004

Epoch: 6| Step: 3
Training loss: 2.0639493465423584
Validation loss: 2.152948433353055

Epoch: 6| Step: 4
Training loss: 0.7798759937286377
Validation loss: 2.1272766256845124

Epoch: 6| Step: 5
Training loss: 1.8265125751495361
Validation loss: 2.095883454045942

Epoch: 6| Step: 6
Training loss: 2.673572063446045
Validation loss: 2.078167848689582

Epoch: 6| Step: 7
Training loss: 2.5336172580718994
Validation loss: 2.0578375606126684

Epoch: 6| Step: 8
Training loss: 1.8323454856872559
Validation loss: 2.066911176968646

Epoch: 6| Step: 9
Training loss: 1.6021544933319092
Validation loss: 2.0621446306987474

Epoch: 6| Step: 10
Training loss: 1.9123704433441162
Validation loss: 2.0620518345986643

Epoch: 6| Step: 11
Training loss: 2.2068257331848145
Validation loss: 2.0747318831823205

Epoch: 6| Step: 12
Training loss: 2.540440320968628
Validation loss: 2.063162244776244

Epoch: 6| Step: 13
Training loss: 2.1292762756347656
Validation loss: 2.061513508519819

Epoch: 202| Step: 0
Training loss: 1.5446044206619263
Validation loss: 2.065169608721169

Epoch: 6| Step: 1
Training loss: 2.394631862640381
Validation loss: 2.096529952941402

Epoch: 6| Step: 2
Training loss: 1.153897762298584
Validation loss: 2.1003089899657876

Epoch: 6| Step: 3
Training loss: 1.6651889085769653
Validation loss: 2.1171869744536695

Epoch: 6| Step: 4
Training loss: 2.357024669647217
Validation loss: 2.109121093185999

Epoch: 6| Step: 5
Training loss: 1.811263918876648
Validation loss: 2.088570520442019

Epoch: 6| Step: 6
Training loss: 1.42842698097229
Validation loss: 2.07401321523933

Epoch: 6| Step: 7
Training loss: 2.7231979370117188
Validation loss: 2.098501979663808

Epoch: 6| Step: 8
Training loss: 2.0388379096984863
Validation loss: 2.0999658492303666

Epoch: 6| Step: 9
Training loss: 2.1807639598846436
Validation loss: 2.111238423214164

Epoch: 6| Step: 10
Training loss: 1.8554142713546753
Validation loss: 2.132854761615876

Epoch: 6| Step: 11
Training loss: 1.432232141494751
Validation loss: 2.1101956662311347

Epoch: 6| Step: 12
Training loss: 2.059375286102295
Validation loss: 2.1400532158472205

Epoch: 6| Step: 13
Training loss: 2.706740379333496
Validation loss: 2.1216671236099733

Epoch: 203| Step: 0
Training loss: 1.5805484056472778
Validation loss: 2.102952867425898

Epoch: 6| Step: 1
Training loss: 1.819930911064148
Validation loss: 2.0972266056204356

Epoch: 6| Step: 2
Training loss: 1.294533371925354
Validation loss: 2.0998560036382368

Epoch: 6| Step: 3
Training loss: 2.18345308303833
Validation loss: 2.069721926925003

Epoch: 6| Step: 4
Training loss: 1.419569969177246
Validation loss: 2.070978673555518

Epoch: 6| Step: 5
Training loss: 2.0716896057128906
Validation loss: 2.068587041670276

Epoch: 6| Step: 6
Training loss: 1.426398754119873
Validation loss: 2.037452531117265

Epoch: 6| Step: 7
Training loss: 2.259525775909424
Validation loss: 2.0419473109706754

Epoch: 6| Step: 8
Training loss: 1.1386687755584717
Validation loss: 2.05589339810033

Epoch: 6| Step: 9
Training loss: 2.2816176414489746
Validation loss: 2.05081610269444

Epoch: 6| Step: 10
Training loss: 2.620302200317383
Validation loss: 2.0604640258255826

Epoch: 6| Step: 11
Training loss: 2.725686550140381
Validation loss: 2.06847644364962

Epoch: 6| Step: 12
Training loss: 2.040745258331299
Validation loss: 2.10937641256599

Epoch: 6| Step: 13
Training loss: 2.0933644771575928
Validation loss: 2.1091457874544206

Epoch: 204| Step: 0
Training loss: 1.9550331830978394
Validation loss: 2.117649891043222

Epoch: 6| Step: 1
Training loss: 1.7239763736724854
Validation loss: 2.111641440340268

Epoch: 6| Step: 2
Training loss: 1.3907701969146729
Validation loss: 2.127010137804093

Epoch: 6| Step: 3
Training loss: 1.20845627784729
Validation loss: 2.098594452745171

Epoch: 6| Step: 4
Training loss: 1.8814940452575684
Validation loss: 2.0949977367155013

Epoch: 6| Step: 5
Training loss: 2.1000499725341797
Validation loss: 2.0786560068848314

Epoch: 6| Step: 6
Training loss: 1.8503882884979248
Validation loss: 2.1103097187575472

Epoch: 6| Step: 7
Training loss: 2.109288215637207
Validation loss: 2.128398951663766

Epoch: 6| Step: 8
Training loss: 2.473994731903076
Validation loss: 2.14032494637274

Epoch: 6| Step: 9
Training loss: 2.0325968265533447
Validation loss: 2.1949009997870332

Epoch: 6| Step: 10
Training loss: 2.428497791290283
Validation loss: 2.1770577302543064

Epoch: 6| Step: 11
Training loss: 2.2368898391723633
Validation loss: 2.151206458768537

Epoch: 6| Step: 12
Training loss: 1.6363416910171509
Validation loss: 2.114152982670774

Epoch: 6| Step: 13
Training loss: 1.0896676778793335
Validation loss: 2.085406885352186

Epoch: 205| Step: 0
Training loss: 1.579744577407837
Validation loss: 2.0869811965573217

Epoch: 6| Step: 1
Training loss: 1.6719470024108887
Validation loss: 2.0745469421468754

Epoch: 6| Step: 2
Training loss: 1.799573540687561
Validation loss: 2.0824808279673257

Epoch: 6| Step: 3
Training loss: 2.143411874771118
Validation loss: 2.0581193508640414

Epoch: 6| Step: 4
Training loss: 1.5437662601470947
Validation loss: 2.039925621401879

Epoch: 6| Step: 5
Training loss: 1.0881210565567017
Validation loss: 2.064908758286507

Epoch: 6| Step: 6
Training loss: 1.8438276052474976
Validation loss: 2.0972414478178947

Epoch: 6| Step: 7
Training loss: 2.316798448562622
Validation loss: 2.157775127759544

Epoch: 6| Step: 8
Training loss: 2.6152420043945312
Validation loss: 2.167889259194815

Epoch: 6| Step: 9
Training loss: 1.9691178798675537
Validation loss: 2.157404015141149

Epoch: 6| Step: 10
Training loss: 2.3340959548950195
Validation loss: 2.131158185261552

Epoch: 6| Step: 11
Training loss: 2.9527602195739746
Validation loss: 2.1225224105260705

Epoch: 6| Step: 12
Training loss: 1.5031039714813232
Validation loss: 2.109530073340221

Epoch: 6| Step: 13
Training loss: 1.5556720495224
Validation loss: 2.0906165056331183

Epoch: 206| Step: 0
Training loss: 1.2369041442871094
Validation loss: 2.063629356763696

Epoch: 6| Step: 1
Training loss: 1.5098872184753418
Validation loss: 2.065614846444899

Epoch: 6| Step: 2
Training loss: 1.7550584077835083
Validation loss: 2.078419090599142

Epoch: 6| Step: 3
Training loss: 2.1487784385681152
Validation loss: 2.0611226815049366

Epoch: 6| Step: 4
Training loss: 2.5583887100219727
Validation loss: 2.0379412302406887

Epoch: 6| Step: 5
Training loss: 1.8474026918411255
Validation loss: 2.0315892901471866

Epoch: 6| Step: 6
Training loss: 1.0856260061264038
Validation loss: 2.031052763744067

Epoch: 6| Step: 7
Training loss: 2.0717239379882812
Validation loss: 2.0347751930195797

Epoch: 6| Step: 8
Training loss: 1.665530800819397
Validation loss: 2.070106589665977

Epoch: 6| Step: 9
Training loss: 1.9071416854858398
Validation loss: 2.1264658948426605

Epoch: 6| Step: 10
Training loss: 2.513096809387207
Validation loss: 2.1822231713161675

Epoch: 6| Step: 11
Training loss: 2.138759136199951
Validation loss: 2.167001937025337

Epoch: 6| Step: 12
Training loss: 2.346904993057251
Validation loss: 2.167486939378964

Epoch: 6| Step: 13
Training loss: 1.861073613166809
Validation loss: 2.145312722011279

Epoch: 207| Step: 0
Training loss: 1.5441750288009644
Validation loss: 2.128796439017019

Epoch: 6| Step: 1
Training loss: 1.387222409248352
Validation loss: 2.1217541271640408

Epoch: 6| Step: 2
Training loss: 2.012343168258667
Validation loss: 2.1173267851593676

Epoch: 6| Step: 3
Training loss: 1.644591212272644
Validation loss: 2.1515806387829524

Epoch: 6| Step: 4
Training loss: 2.4139761924743652
Validation loss: 2.1305799227888866

Epoch: 6| Step: 5
Training loss: 2.108729362487793
Validation loss: 2.1422741131115983

Epoch: 6| Step: 6
Training loss: 2.309166431427002
Validation loss: 2.1180513776758665

Epoch: 6| Step: 7
Training loss: 1.6107227802276611
Validation loss: 2.1138128798495055

Epoch: 6| Step: 8
Training loss: 1.6639710664749146
Validation loss: 2.1293001098017537

Epoch: 6| Step: 9
Training loss: 1.9304999113082886
Validation loss: 2.1407320858329855

Epoch: 6| Step: 10
Training loss: 1.9437575340270996
Validation loss: 2.13313994356381

Epoch: 6| Step: 11
Training loss: 1.482857346534729
Validation loss: 2.127671690397365

Epoch: 6| Step: 12
Training loss: 1.8926453590393066
Validation loss: 2.0981836908607074

Epoch: 6| Step: 13
Training loss: 2.864389181137085
Validation loss: 2.067940160792361

Epoch: 208| Step: 0
Training loss: 1.8029959201812744
Validation loss: 2.036905739897041

Epoch: 6| Step: 1
Training loss: 1.3047070503234863
Validation loss: 2.0335129999345347

Epoch: 6| Step: 2
Training loss: 2.044647216796875
Validation loss: 2.027335778359444

Epoch: 6| Step: 3
Training loss: 2.1349844932556152
Validation loss: 2.0347827839595016

Epoch: 6| Step: 4
Training loss: 2.111450433731079
Validation loss: 2.0260545669063443

Epoch: 6| Step: 5
Training loss: 2.554060459136963
Validation loss: 2.0351905848390315

Epoch: 6| Step: 6
Training loss: 2.045745611190796
Validation loss: 2.01621764193299

Epoch: 6| Step: 7
Training loss: 2.462189197540283
Validation loss: 2.0526270148574666

Epoch: 6| Step: 8
Training loss: 1.8032004833221436
Validation loss: 2.085864390096357

Epoch: 6| Step: 9
Training loss: 1.2345049381256104
Validation loss: 2.12394799981066

Epoch: 6| Step: 10
Training loss: 1.60844886302948
Validation loss: 2.145258926576184

Epoch: 6| Step: 11
Training loss: 1.5860414505004883
Validation loss: 2.180020134936097

Epoch: 6| Step: 12
Training loss: 1.7303626537322998
Validation loss: 2.132905820364593

Epoch: 6| Step: 13
Training loss: 2.175936698913574
Validation loss: 2.0744626829701085

Epoch: 209| Step: 0
Training loss: 2.3642377853393555
Validation loss: 2.0585569374022947

Epoch: 6| Step: 1
Training loss: 1.5545909404754639
Validation loss: 2.0662230573674685

Epoch: 6| Step: 2
Training loss: 1.4855728149414062
Validation loss: 2.092243799599268

Epoch: 6| Step: 3
Training loss: 2.4100375175476074
Validation loss: 2.1047996397941344

Epoch: 6| Step: 4
Training loss: 1.6837589740753174
Validation loss: 2.119755141196712

Epoch: 6| Step: 5
Training loss: 2.027831554412842
Validation loss: 2.10987506117872

Epoch: 6| Step: 6
Training loss: 1.0805253982543945
Validation loss: 2.1297362440375873

Epoch: 6| Step: 7
Training loss: 1.9051899909973145
Validation loss: 2.139090099642354

Epoch: 6| Step: 8
Training loss: 1.9679588079452515
Validation loss: 2.1739114023024038

Epoch: 6| Step: 9
Training loss: 1.7003521919250488
Validation loss: 2.205958307430308

Epoch: 6| Step: 10
Training loss: 2.6128525733947754
Validation loss: 2.213192142466063

Epoch: 6| Step: 11
Training loss: 1.0263805389404297
Validation loss: 2.2020443280537925

Epoch: 6| Step: 12
Training loss: 2.5937705039978027
Validation loss: 2.17624331033358

Epoch: 6| Step: 13
Training loss: 2.1463747024536133
Validation loss: 2.131784895414947

Epoch: 210| Step: 0
Training loss: 2.184274673461914
Validation loss: 2.0912143286838325

Epoch: 6| Step: 1
Training loss: 1.9602117538452148
Validation loss: 2.064677312809934

Epoch: 6| Step: 2
Training loss: 2.298218011856079
Validation loss: 2.0576835729742564

Epoch: 6| Step: 3
Training loss: 1.6647149324417114
Validation loss: 2.06427905636449

Epoch: 6| Step: 4
Training loss: 2.1562228202819824
Validation loss: 2.081595766928888

Epoch: 6| Step: 5
Training loss: 1.8270033597946167
Validation loss: 2.0870645981962963

Epoch: 6| Step: 6
Training loss: 1.8389986753463745
Validation loss: 2.1049562628551195

Epoch: 6| Step: 7
Training loss: 1.8877803087234497
Validation loss: 2.0735055733752508

Epoch: 6| Step: 8
Training loss: 1.5227142572402954
Validation loss: 2.0691340559272358

Epoch: 6| Step: 9
Training loss: 1.8494503498077393
Validation loss: 2.0948493813955658

Epoch: 6| Step: 10
Training loss: 2.3364696502685547
Validation loss: 2.151045440345682

Epoch: 6| Step: 11
Training loss: 2.1320695877075195
Validation loss: 2.1990941032286613

Epoch: 6| Step: 12
Training loss: 1.4338520765304565
Validation loss: 2.210354084609657

Epoch: 6| Step: 13
Training loss: 1.3131667375564575
Validation loss: 2.207331580500449

Epoch: 211| Step: 0
Training loss: 1.8301506042480469
Validation loss: 2.1637876059419368

Epoch: 6| Step: 1
Training loss: 2.1593761444091797
Validation loss: 2.129367002876856

Epoch: 6| Step: 2
Training loss: 1.8097991943359375
Validation loss: 2.122913537486907

Epoch: 6| Step: 3
Training loss: 2.130671977996826
Validation loss: 2.1302359796339467

Epoch: 6| Step: 4
Training loss: 2.5575404167175293
Validation loss: 2.1323085113238265

Epoch: 6| Step: 5
Training loss: 1.8863106966018677
Validation loss: 2.138010319843087

Epoch: 6| Step: 6
Training loss: 1.6285309791564941
Validation loss: 2.0988872820331204

Epoch: 6| Step: 7
Training loss: 1.3070251941680908
Validation loss: 2.082135215882332

Epoch: 6| Step: 8
Training loss: 1.9477707147598267
Validation loss: 2.0715081012377174

Epoch: 6| Step: 9
Training loss: 1.3410239219665527
Validation loss: 2.058382611120901

Epoch: 6| Step: 10
Training loss: 1.990437626838684
Validation loss: 2.0395202944355626

Epoch: 6| Step: 11
Training loss: 0.9361496567726135
Validation loss: 2.0689595989001694

Epoch: 6| Step: 12
Training loss: 2.49704647064209
Validation loss: 2.0990963469269457

Epoch: 6| Step: 13
Training loss: 2.1963932514190674
Validation loss: 2.1173883407346663

Epoch: 212| Step: 0
Training loss: 2.119626522064209
Validation loss: 2.1649330905688706

Epoch: 6| Step: 1
Training loss: 2.2599411010742188
Validation loss: 2.2168636886022424

Epoch: 6| Step: 2
Training loss: 1.7428277730941772
Validation loss: 2.2007943302072506

Epoch: 6| Step: 3
Training loss: 1.182939887046814
Validation loss: 2.1400234724885676

Epoch: 6| Step: 4
Training loss: 1.6728265285491943
Validation loss: 2.0684813991669686

Epoch: 6| Step: 5
Training loss: 2.131171464920044
Validation loss: 2.0635997390234344

Epoch: 6| Step: 6
Training loss: 2.259429454803467
Validation loss: 2.058946865861134

Epoch: 6| Step: 7
Training loss: 1.4133119583129883
Validation loss: 2.065527036625852

Epoch: 6| Step: 8
Training loss: 2.3319573402404785
Validation loss: 2.0894214568599576

Epoch: 6| Step: 9
Training loss: 1.2609962224960327
Validation loss: 2.0899238932517266

Epoch: 6| Step: 10
Training loss: 2.706777572631836
Validation loss: 2.094770441773117

Epoch: 6| Step: 11
Training loss: 2.030872344970703
Validation loss: 2.0872649377392185

Epoch: 6| Step: 12
Training loss: 1.6837408542633057
Validation loss: 2.0918460481910297

Epoch: 6| Step: 13
Training loss: 0.9139604568481445
Validation loss: 2.067836981947704

Epoch: 213| Step: 0
Training loss: 2.69909930229187
Validation loss: 2.074558965621456

Epoch: 6| Step: 1
Training loss: 1.390287160873413
Validation loss: 2.0594748091954056

Epoch: 6| Step: 2
Training loss: 1.6619956493377686
Validation loss: 2.039669441920455

Epoch: 6| Step: 3
Training loss: 2.6935157775878906
Validation loss: 2.0586108981922107

Epoch: 6| Step: 4
Training loss: 2.1422247886657715
Validation loss: 2.067061972874467

Epoch: 6| Step: 5
Training loss: 1.9139766693115234
Validation loss: 2.068995391168902

Epoch: 6| Step: 6
Training loss: 1.4140100479125977
Validation loss: 2.100430929532615

Epoch: 6| Step: 7
Training loss: 1.9687211513519287
Validation loss: 2.0828390852097542

Epoch: 6| Step: 8
Training loss: 2.235508680343628
Validation loss: 2.1140842719744612

Epoch: 6| Step: 9
Training loss: 1.2102478742599487
Validation loss: 2.1082090946935836

Epoch: 6| Step: 10
Training loss: 1.810208797454834
Validation loss: 2.1128180065462665

Epoch: 6| Step: 11
Training loss: 1.39772367477417
Validation loss: 2.1209326431315434

Epoch: 6| Step: 12
Training loss: 0.9905824065208435
Validation loss: 2.1299170063387964

Epoch: 6| Step: 13
Training loss: 1.5765914916992188
Validation loss: 2.0996367726274716

Epoch: 214| Step: 0
Training loss: 1.3767337799072266
Validation loss: 2.103578867450837

Epoch: 6| Step: 1
Training loss: 1.9368622303009033
Validation loss: 2.119486002511876

Epoch: 6| Step: 2
Training loss: 1.727122187614441
Validation loss: 2.1168013093292073

Epoch: 6| Step: 3
Training loss: 1.1213573217391968
Validation loss: 2.1264237178269254

Epoch: 6| Step: 4
Training loss: 1.6302518844604492
Validation loss: 2.134034679782006

Epoch: 6| Step: 5
Training loss: 2.0529942512512207
Validation loss: 2.144693197742585

Epoch: 6| Step: 6
Training loss: 1.4565824270248413
Validation loss: 2.1524010499318442

Epoch: 6| Step: 7
Training loss: 2.23038649559021
Validation loss: 2.1242103525387344

Epoch: 6| Step: 8
Training loss: 2.354266405105591
Validation loss: 2.1059481738716044

Epoch: 6| Step: 9
Training loss: 1.7928030490875244
Validation loss: 2.109398462439096

Epoch: 6| Step: 10
Training loss: 1.6647028923034668
Validation loss: 2.085836072121897

Epoch: 6| Step: 11
Training loss: 1.7202386856079102
Validation loss: 2.0776832719003

Epoch: 6| Step: 12
Training loss: 2.485072612762451
Validation loss: 2.077288878861294

Epoch: 6| Step: 13
Training loss: 1.5450963973999023
Validation loss: 2.0674913544808664

Epoch: 215| Step: 0
Training loss: 2.393141984939575
Validation loss: 2.05176051457723

Epoch: 6| Step: 1
Training loss: 1.9280353784561157
Validation loss: 2.0335734198170323

Epoch: 6| Step: 2
Training loss: 1.415584921836853
Validation loss: 2.040548873204057

Epoch: 6| Step: 3
Training loss: 1.3883649110794067
Validation loss: 2.0573766116173036

Epoch: 6| Step: 4
Training loss: 1.9026073217391968
Validation loss: 2.054827614497113

Epoch: 6| Step: 5
Training loss: 1.7637939453125
Validation loss: 2.0638181073691255

Epoch: 6| Step: 6
Training loss: 1.0915141105651855
Validation loss: 2.093575128944971

Epoch: 6| Step: 7
Training loss: 2.442981481552124
Validation loss: 2.117942366548764

Epoch: 6| Step: 8
Training loss: 2.547290086746216
Validation loss: 2.1332765958642446

Epoch: 6| Step: 9
Training loss: 1.7002756595611572
Validation loss: 2.1235499638383106

Epoch: 6| Step: 10
Training loss: 1.375403881072998
Validation loss: 2.1438459273307555

Epoch: 6| Step: 11
Training loss: 1.5700074434280396
Validation loss: 2.130525617189305

Epoch: 6| Step: 12
Training loss: 1.547877311706543
Validation loss: 2.1124672889709473

Epoch: 6| Step: 13
Training loss: 1.86110258102417
Validation loss: 2.1059770225196757

Epoch: 216| Step: 0
Training loss: 1.803163766860962
Validation loss: 2.1179220894331574

Epoch: 6| Step: 1
Training loss: 1.1765187978744507
Validation loss: 2.102119484255391

Epoch: 6| Step: 2
Training loss: 1.649324655532837
Validation loss: 2.0956880354112193

Epoch: 6| Step: 3
Training loss: 2.3488800525665283
Validation loss: 2.0892942285024994

Epoch: 6| Step: 4
Training loss: 1.3613364696502686
Validation loss: 2.0664982052259546

Epoch: 6| Step: 5
Training loss: 1.1884815692901611
Validation loss: 2.0792278423104236

Epoch: 6| Step: 6
Training loss: 2.3424434661865234
Validation loss: 2.0852855508045485

Epoch: 6| Step: 7
Training loss: 1.2158918380737305
Validation loss: 2.062279628169152

Epoch: 6| Step: 8
Training loss: 1.9419091939926147
Validation loss: 2.083517292494415

Epoch: 6| Step: 9
Training loss: 2.394719123840332
Validation loss: 2.094256088297854

Epoch: 6| Step: 10
Training loss: 1.7171545028686523
Validation loss: 2.1171306897235174

Epoch: 6| Step: 11
Training loss: 1.90211021900177
Validation loss: 2.118245506799349

Epoch: 6| Step: 12
Training loss: 1.6322959661483765
Validation loss: 2.1346132575824694

Epoch: 6| Step: 13
Training loss: 2.1721608638763428
Validation loss: 2.148844329259729

Epoch: 217| Step: 0
Training loss: 2.129650831222534
Validation loss: 2.119858944287864

Epoch: 6| Step: 1
Training loss: 2.0313005447387695
Validation loss: 2.1046102457149054

Epoch: 6| Step: 2
Training loss: 1.5839252471923828
Validation loss: 2.0938122657037552

Epoch: 6| Step: 3
Training loss: 1.9385440349578857
Validation loss: 2.07381502274544

Epoch: 6| Step: 4
Training loss: 1.8671029806137085
Validation loss: 2.073793101054366

Epoch: 6| Step: 5
Training loss: 1.2291861772537231
Validation loss: 2.0627987589887393

Epoch: 6| Step: 6
Training loss: 2.5182981491088867
Validation loss: 2.068472235433517

Epoch: 6| Step: 7
Training loss: 1.5254597663879395
Validation loss: 2.0709056572247575

Epoch: 6| Step: 8
Training loss: 2.029075860977173
Validation loss: 2.0481569459361415

Epoch: 6| Step: 9
Training loss: 1.743513822555542
Validation loss: 2.0525749344979562

Epoch: 6| Step: 10
Training loss: 1.1375465393066406
Validation loss: 2.0701319786810104

Epoch: 6| Step: 11
Training loss: 1.1824111938476562
Validation loss: 2.0662686465888895

Epoch: 6| Step: 12
Training loss: 1.6227433681488037
Validation loss: 2.067928247554328

Epoch: 6| Step: 13
Training loss: 1.954783320426941
Validation loss: 2.0565097498637375

Epoch: 218| Step: 0
Training loss: 1.7653781175613403
Validation loss: 2.0976559705631708

Epoch: 6| Step: 1
Training loss: 2.26568603515625
Validation loss: 2.093490090421451

Epoch: 6| Step: 2
Training loss: 1.9603936672210693
Validation loss: 2.116575902508151

Epoch: 6| Step: 3
Training loss: 2.1028831005096436
Validation loss: 2.106994967306814

Epoch: 6| Step: 4
Training loss: 1.2485030889511108
Validation loss: 2.0947638301439184

Epoch: 6| Step: 5
Training loss: 1.3546805381774902
Validation loss: 2.101393779118856

Epoch: 6| Step: 6
Training loss: 1.8398418426513672
Validation loss: 2.097132530263675

Epoch: 6| Step: 7
Training loss: 1.9424608945846558
Validation loss: 2.098925135468924

Epoch: 6| Step: 8
Training loss: 1.5324262380599976
Validation loss: 2.100673161527162

Epoch: 6| Step: 9
Training loss: 1.4664478302001953
Validation loss: 2.10561470062502

Epoch: 6| Step: 10
Training loss: 1.1706146001815796
Validation loss: 2.1224667487605924

Epoch: 6| Step: 11
Training loss: 2.0816187858581543
Validation loss: 2.1197285767524474

Epoch: 6| Step: 12
Training loss: 1.993952751159668
Validation loss: 2.096986405311092

Epoch: 6| Step: 13
Training loss: 1.4883615970611572
Validation loss: 2.06640411320553

Epoch: 219| Step: 0
Training loss: 2.3820226192474365
Validation loss: 2.0876413314573226

Epoch: 6| Step: 1
Training loss: 1.1277415752410889
Validation loss: 2.0649009750735376

Epoch: 6| Step: 2
Training loss: 1.8715734481811523
Validation loss: 2.0799621279521654

Epoch: 6| Step: 3
Training loss: 1.8340044021606445
Validation loss: 2.0817008608131

Epoch: 6| Step: 4
Training loss: 1.7711516618728638
Validation loss: 2.075641829480407

Epoch: 6| Step: 5
Training loss: 1.956196665763855
Validation loss: 2.094342031786519

Epoch: 6| Step: 6
Training loss: 0.8801411390304565
Validation loss: 2.144166318319177

Epoch: 6| Step: 7
Training loss: 1.5486271381378174
Validation loss: 2.1523447075197772

Epoch: 6| Step: 8
Training loss: 1.9793182611465454
Validation loss: 2.155639838146907

Epoch: 6| Step: 9
Training loss: 1.6428005695343018
Validation loss: 2.1470654292773177

Epoch: 6| Step: 10
Training loss: 2.1330513954162598
Validation loss: 2.133499586454002

Epoch: 6| Step: 11
Training loss: 1.8582227230072021
Validation loss: 2.1307664712270102

Epoch: 6| Step: 12
Training loss: 2.2117128372192383
Validation loss: 2.1181083750981156

Epoch: 6| Step: 13
Training loss: 1.3121055364608765
Validation loss: 2.119913531887916

Epoch: 220| Step: 0
Training loss: 2.040179967880249
Validation loss: 2.108905376926545

Epoch: 6| Step: 1
Training loss: 1.891761064529419
Validation loss: 2.091621684771712

Epoch: 6| Step: 2
Training loss: 2.00618577003479
Validation loss: 2.065994688259658

Epoch: 6| Step: 3
Training loss: 1.679061770439148
Validation loss: 2.0511862642021588

Epoch: 6| Step: 4
Training loss: 2.478402614593506
Validation loss: 2.050680968069261

Epoch: 6| Step: 5
Training loss: 1.9008827209472656
Validation loss: 2.054691022442233

Epoch: 6| Step: 6
Training loss: 1.5015463829040527
Validation loss: 2.0613667093297487

Epoch: 6| Step: 7
Training loss: 1.7918369770050049
Validation loss: 2.0709007170892533

Epoch: 6| Step: 8
Training loss: 1.1101895570755005
Validation loss: 2.0541616357782835

Epoch: 6| Step: 9
Training loss: 1.710221529006958
Validation loss: 2.0537870981359996

Epoch: 6| Step: 10
Training loss: 1.3684544563293457
Validation loss: 2.062996642563933

Epoch: 6| Step: 11
Training loss: 2.0064492225646973
Validation loss: 2.0711404661978445

Epoch: 6| Step: 12
Training loss: 1.198272943496704
Validation loss: 2.1110567892751386

Epoch: 6| Step: 13
Training loss: 1.5358874797821045
Validation loss: 2.1226387100835002

Epoch: 221| Step: 0
Training loss: 2.3887813091278076
Validation loss: 2.134940221745481

Epoch: 6| Step: 1
Training loss: 0.8384391069412231
Validation loss: 2.131962558274628

Epoch: 6| Step: 2
Training loss: 2.015270709991455
Validation loss: 2.0927771663153045

Epoch: 6| Step: 3
Training loss: 1.6052278280258179
Validation loss: 2.087730687151673

Epoch: 6| Step: 4
Training loss: 2.3673717975616455
Validation loss: 2.0808258620641564

Epoch: 6| Step: 5
Training loss: 1.0331958532333374
Validation loss: 2.0699484168842273

Epoch: 6| Step: 6
Training loss: 1.8526691198349
Validation loss: 2.046273451979442

Epoch: 6| Step: 7
Training loss: 1.9595754146575928
Validation loss: 2.052457688957132

Epoch: 6| Step: 8
Training loss: 1.9390575885772705
Validation loss: 2.0732417670629357

Epoch: 6| Step: 9
Training loss: 1.4408831596374512
Validation loss: 2.0797410088200725

Epoch: 6| Step: 10
Training loss: 1.1973692178726196
Validation loss: 2.126221000507314

Epoch: 6| Step: 11
Training loss: 2.0935797691345215
Validation loss: 2.163911588730351

Epoch: 6| Step: 12
Training loss: 2.015821695327759
Validation loss: 2.149298611507621

Epoch: 6| Step: 13
Training loss: 1.4067022800445557
Validation loss: 2.120353688475906

Epoch: 222| Step: 0
Training loss: 1.2014944553375244
Validation loss: 2.1294269920677267

Epoch: 6| Step: 1
Training loss: 2.1089344024658203
Validation loss: 2.1322120492176344

Epoch: 6| Step: 2
Training loss: 1.5630347728729248
Validation loss: 2.1279883333431777

Epoch: 6| Step: 3
Training loss: 2.364847421646118
Validation loss: 2.11891015883415

Epoch: 6| Step: 4
Training loss: 1.8600120544433594
Validation loss: 2.121207494889536

Epoch: 6| Step: 5
Training loss: 0.9756232500076294
Validation loss: 2.113044910533454

Epoch: 6| Step: 6
Training loss: 1.285773515701294
Validation loss: 2.157831968799714

Epoch: 6| Step: 7
Training loss: 2.4175267219543457
Validation loss: 2.1322501884993685

Epoch: 6| Step: 8
Training loss: 1.4087554216384888
Validation loss: 2.1386195228945826

Epoch: 6| Step: 9
Training loss: 2.002717971801758
Validation loss: 2.098960727773687

Epoch: 6| Step: 10
Training loss: 1.9471683502197266
Validation loss: 2.084145056304111

Epoch: 6| Step: 11
Training loss: 1.7433035373687744
Validation loss: 2.068993645329629

Epoch: 6| Step: 12
Training loss: 2.0334372520446777
Validation loss: 2.0996414230715845

Epoch: 6| Step: 13
Training loss: 0.7778671979904175
Validation loss: 2.1045897455625635

Epoch: 223| Step: 0
Training loss: 1.790092945098877
Validation loss: 2.1057944246517715

Epoch: 6| Step: 1
Training loss: 1.3399776220321655
Validation loss: 2.1300820278865036

Epoch: 6| Step: 2
Training loss: 1.8889535665512085
Validation loss: 2.1122756799062095

Epoch: 6| Step: 3
Training loss: 2.061999559402466
Validation loss: 2.0841465278338362

Epoch: 6| Step: 4
Training loss: 1.3338087797164917
Validation loss: 2.0599762124399983

Epoch: 6| Step: 5
Training loss: 1.8944694995880127
Validation loss: 2.0439486298509824

Epoch: 6| Step: 6
Training loss: 1.6033070087432861
Validation loss: 2.070540407652496

Epoch: 6| Step: 7
Training loss: 1.6422747373580933
Validation loss: 2.0751979171588855

Epoch: 6| Step: 8
Training loss: 1.3361414670944214
Validation loss: 2.079755626698976

Epoch: 6| Step: 9
Training loss: 1.5684573650360107
Validation loss: 2.0810037120696037

Epoch: 6| Step: 10
Training loss: 1.6675466299057007
Validation loss: 2.0498945841225247

Epoch: 6| Step: 11
Training loss: 1.8439440727233887
Validation loss: 2.0508016847795054

Epoch: 6| Step: 12
Training loss: 2.0806026458740234
Validation loss: 2.0490521589914956

Epoch: 6| Step: 13
Training loss: 2.230994701385498
Validation loss: 2.039932556049798

Epoch: 224| Step: 0
Training loss: 1.1966578960418701
Validation loss: 2.046042114175776

Epoch: 6| Step: 1
Training loss: 2.2783002853393555
Validation loss: 2.046853491055068

Epoch: 6| Step: 2
Training loss: 1.7599413394927979
Validation loss: 2.0828637628145117

Epoch: 6| Step: 3
Training loss: 1.8221107721328735
Validation loss: 2.0725067379654094

Epoch: 6| Step: 4
Training loss: 2.169908046722412
Validation loss: 2.0555175530013217

Epoch: 6| Step: 5
Training loss: 1.4329166412353516
Validation loss: 2.0769462918722503

Epoch: 6| Step: 6
Training loss: 1.3954987525939941
Validation loss: 2.0894307308299567

Epoch: 6| Step: 7
Training loss: 1.4890742301940918
Validation loss: 2.124021994170322

Epoch: 6| Step: 8
Training loss: 1.967897891998291
Validation loss: 2.1421156301293323

Epoch: 6| Step: 9
Training loss: 2.098012924194336
Validation loss: 2.142005701218882

Epoch: 6| Step: 10
Training loss: 1.3086941242218018
Validation loss: 2.1331720967446604

Epoch: 6| Step: 11
Training loss: 1.6978940963745117
Validation loss: 2.1329209125170143

Epoch: 6| Step: 12
Training loss: 1.5917128324508667
Validation loss: 2.132599840882004

Epoch: 6| Step: 13
Training loss: 1.5592821836471558
Validation loss: 2.1271124475745746

Epoch: 225| Step: 0
Training loss: 1.5693999528884888
Validation loss: 2.130498209307271

Epoch: 6| Step: 1
Training loss: 1.566771149635315
Validation loss: 2.1079496465703493

Epoch: 6| Step: 2
Training loss: 1.7564233541488647
Validation loss: 2.1051836654704106

Epoch: 6| Step: 3
Training loss: 1.594438076019287
Validation loss: 2.0883572037502

Epoch: 6| Step: 4
Training loss: 1.5685539245605469
Validation loss: 2.0853534488267798

Epoch: 6| Step: 5
Training loss: 2.4833569526672363
Validation loss: 2.061841418666224

Epoch: 6| Step: 6
Training loss: 1.7378504276275635
Validation loss: 2.0646369021425963

Epoch: 6| Step: 7
Training loss: 1.734729290008545
Validation loss: 2.0569366050022904

Epoch: 6| Step: 8
Training loss: 1.7265255451202393
Validation loss: 2.0734625606126684

Epoch: 6| Step: 9
Training loss: 2.113940954208374
Validation loss: 2.0813039605335524

Epoch: 6| Step: 10
Training loss: 1.0611755847930908
Validation loss: 2.09791838225498

Epoch: 6| Step: 11
Training loss: 1.3293414115905762
Validation loss: 2.096725417721656

Epoch: 6| Step: 12
Training loss: 1.5903187990188599
Validation loss: 2.108377687392696

Epoch: 6| Step: 13
Training loss: 1.96312415599823
Validation loss: 2.14435653532705

Epoch: 226| Step: 0
Training loss: 1.659959077835083
Validation loss: 2.123070210538885

Epoch: 6| Step: 1
Training loss: 1.70698082447052
Validation loss: 2.12137064754322

Epoch: 6| Step: 2
Training loss: 1.7639507055282593
Validation loss: 2.1030232265431392

Epoch: 6| Step: 3
Training loss: 1.1733760833740234
Validation loss: 2.0761843368571293

Epoch: 6| Step: 4
Training loss: 2.1731162071228027
Validation loss: 2.0606950380468882

Epoch: 6| Step: 5
Training loss: 1.6977028846740723
Validation loss: 2.0703412525115477

Epoch: 6| Step: 6
Training loss: 1.734792709350586
Validation loss: 2.076116583680594

Epoch: 6| Step: 7
Training loss: 1.9722949266433716
Validation loss: 2.079013386080342

Epoch: 6| Step: 8
Training loss: 1.5173330307006836
Validation loss: 2.0718413040202153

Epoch: 6| Step: 9
Training loss: 1.3266994953155518
Validation loss: 2.0738344602687384

Epoch: 6| Step: 10
Training loss: 2.47967267036438
Validation loss: 2.0867385941167034

Epoch: 6| Step: 11
Training loss: 1.3935387134552002
Validation loss: 2.086576384882773

Epoch: 6| Step: 12
Training loss: 1.288782000541687
Validation loss: 2.060250042587198

Epoch: 6| Step: 13
Training loss: 1.3853033781051636
Validation loss: 2.0839823394693355

Epoch: 227| Step: 0
Training loss: 1.1277477741241455
Validation loss: 2.070780882271387

Epoch: 6| Step: 1
Training loss: 1.361141324043274
Validation loss: 2.0829303649164017

Epoch: 6| Step: 2
Training loss: 1.979604959487915
Validation loss: 2.08835163680456

Epoch: 6| Step: 3
Training loss: 0.9003151059150696
Validation loss: 2.1091137675828833

Epoch: 6| Step: 4
Training loss: 1.5126487016677856
Validation loss: 2.0934966635960404

Epoch: 6| Step: 5
Training loss: 1.4740108251571655
Validation loss: 2.090651927455779

Epoch: 6| Step: 6
Training loss: 2.437196969985962
Validation loss: 2.0577167054658294

Epoch: 6| Step: 7
Training loss: 1.5993150472640991
Validation loss: 2.0654994941526845

Epoch: 6| Step: 8
Training loss: 1.938362717628479
Validation loss: 2.0927644083576817

Epoch: 6| Step: 9
Training loss: 1.7887065410614014
Validation loss: 2.0966276994315525

Epoch: 6| Step: 10
Training loss: 1.786158800125122
Validation loss: 2.102695923979564

Epoch: 6| Step: 11
Training loss: 2.129092216491699
Validation loss: 2.1150397651938984

Epoch: 6| Step: 12
Training loss: 1.5579438209533691
Validation loss: 2.1040369887505808

Epoch: 6| Step: 13
Training loss: 1.6472265720367432
Validation loss: 2.1516922776417067

Epoch: 228| Step: 0
Training loss: 0.9843847155570984
Validation loss: 2.128093418254647

Epoch: 6| Step: 1
Training loss: 2.300604820251465
Validation loss: 2.11500205532197

Epoch: 6| Step: 2
Training loss: 2.0107474327087402
Validation loss: 2.119839399091659

Epoch: 6| Step: 3
Training loss: 1.993390679359436
Validation loss: 2.1328850574390863

Epoch: 6| Step: 4
Training loss: 1.8759695291519165
Validation loss: 2.0915605586062194

Epoch: 6| Step: 5
Training loss: 1.2550950050354004
Validation loss: 2.133929116751558

Epoch: 6| Step: 6
Training loss: 1.4310057163238525
Validation loss: 2.0902903772169545

Epoch: 6| Step: 7
Training loss: 2.0836403369903564
Validation loss: 2.0752760235981276

Epoch: 6| Step: 8
Training loss: 1.5542089939117432
Validation loss: 2.05310534661816

Epoch: 6| Step: 9
Training loss: 1.4783856868743896
Validation loss: 2.0629354112891742

Epoch: 6| Step: 10
Training loss: 1.0424599647521973
Validation loss: 2.0581489378406155

Epoch: 6| Step: 11
Training loss: 2.084531784057617
Validation loss: 2.048368333488382

Epoch: 6| Step: 12
Training loss: 1.2502212524414062
Validation loss: 2.025432131623709

Epoch: 6| Step: 13
Training loss: 1.6305404901504517
Validation loss: 2.008110983397371

Epoch: 229| Step: 0
Training loss: 1.8414138555526733
Validation loss: 1.992914189574539

Epoch: 6| Step: 1
Training loss: 1.7876713275909424
Validation loss: 2.0071667035420737

Epoch: 6| Step: 2
Training loss: 1.2182186841964722
Validation loss: 2.006623004072456

Epoch: 6| Step: 3
Training loss: 1.5101912021636963
Validation loss: 2.012732526307465

Epoch: 6| Step: 4
Training loss: 1.9050062894821167
Validation loss: 2.0605859346287225

Epoch: 6| Step: 5
Training loss: 1.4064527750015259
Validation loss: 2.0698004640558714

Epoch: 6| Step: 6
Training loss: 1.1811869144439697
Validation loss: 2.0815417561479794

Epoch: 6| Step: 7
Training loss: 1.6973778009414673
Validation loss: 2.0936250840463946

Epoch: 6| Step: 8
Training loss: 2.2938387393951416
Validation loss: 2.0870915048865863

Epoch: 6| Step: 9
Training loss: 1.6677005290985107
Validation loss: 2.0797328666974138

Epoch: 6| Step: 10
Training loss: 1.467269778251648
Validation loss: 2.087899819497139

Epoch: 6| Step: 11
Training loss: 1.9585912227630615
Validation loss: 2.07246446353133

Epoch: 6| Step: 12
Training loss: 1.9339523315429688
Validation loss: 2.108686852198775

Epoch: 6| Step: 13
Training loss: 0.7352919578552246
Validation loss: 2.09674378877045

Epoch: 230| Step: 0
Training loss: 1.7618370056152344
Validation loss: 2.0843845977578113

Epoch: 6| Step: 1
Training loss: 1.957460641860962
Validation loss: 2.0672838713533137

Epoch: 6| Step: 2
Training loss: 1.4691777229309082
Validation loss: 2.0638456985514653

Epoch: 6| Step: 3
Training loss: 1.5876268148422241
Validation loss: 2.042873785059939

Epoch: 6| Step: 4
Training loss: 1.1555025577545166
Validation loss: 2.0300834230197373

Epoch: 6| Step: 5
Training loss: 2.1098079681396484
Validation loss: 2.027886994423405

Epoch: 6| Step: 6
Training loss: 1.669399619102478
Validation loss: 2.0226575828367666

Epoch: 6| Step: 7
Training loss: 1.7647172212600708
Validation loss: 2.0324046624604093

Epoch: 6| Step: 8
Training loss: 1.4043893814086914
Validation loss: 2.029527759039274

Epoch: 6| Step: 9
Training loss: 1.2780673503875732
Validation loss: 2.0630832128627326

Epoch: 6| Step: 10
Training loss: 1.0648444890975952
Validation loss: 2.075401388188844

Epoch: 6| Step: 11
Training loss: 1.8291854858398438
Validation loss: 2.0958205012864966

Epoch: 6| Step: 12
Training loss: 1.9476356506347656
Validation loss: 2.111830670346496

Epoch: 6| Step: 13
Training loss: 1.8541169166564941
Validation loss: 2.0800281891258816

Epoch: 231| Step: 0
Training loss: 1.5479750633239746
Validation loss: 2.0925510711567377

Epoch: 6| Step: 1
Training loss: 1.5133404731750488
Validation loss: 2.0809454417997792

Epoch: 6| Step: 2
Training loss: 2.0233044624328613
Validation loss: 2.0744054881475305

Epoch: 6| Step: 3
Training loss: 2.400848865509033
Validation loss: 2.060885780601091

Epoch: 6| Step: 4
Training loss: 1.2894680500030518
Validation loss: 2.0582456178562616

Epoch: 6| Step: 5
Training loss: 1.5079429149627686
Validation loss: 2.063787296254148

Epoch: 6| Step: 6
Training loss: 2.084658145904541
Validation loss: 2.0541780302601476

Epoch: 6| Step: 7
Training loss: 1.2745600938796997
Validation loss: 2.070880315637076

Epoch: 6| Step: 8
Training loss: 1.5563464164733887
Validation loss: 2.062435246283008

Epoch: 6| Step: 9
Training loss: 0.8923382759094238
Validation loss: 2.071368714814545

Epoch: 6| Step: 10
Training loss: 1.6936514377593994
Validation loss: 2.078176563785922

Epoch: 6| Step: 11
Training loss: 1.648687481880188
Validation loss: 2.0872022823620866

Epoch: 6| Step: 12
Training loss: 1.623694658279419
Validation loss: 2.1120689838163313

Epoch: 6| Step: 13
Training loss: 1.2791802883148193
Validation loss: 2.0968255458339566

Epoch: 232| Step: 0
Training loss: 1.4130535125732422
Validation loss: 2.0775557615423716

Epoch: 6| Step: 1
Training loss: 1.3457194566726685
Validation loss: 2.0855855198316675

Epoch: 6| Step: 2
Training loss: 1.49552583694458
Validation loss: 2.0563943514259915

Epoch: 6| Step: 3
Training loss: 1.3091864585876465
Validation loss: 2.0496507178070726

Epoch: 6| Step: 4
Training loss: 1.7598258256912231
Validation loss: 2.054660576646046

Epoch: 6| Step: 5
Training loss: 1.4276154041290283
Validation loss: 2.0538444211406093

Epoch: 6| Step: 6
Training loss: 1.3750977516174316
Validation loss: 2.058771989678824

Epoch: 6| Step: 7
Training loss: 1.7452411651611328
Validation loss: 2.056127791763634

Epoch: 6| Step: 8
Training loss: 1.1014057397842407
Validation loss: 2.0411855892468522

Epoch: 6| Step: 9
Training loss: 1.888224482536316
Validation loss: 2.053070914360785

Epoch: 6| Step: 10
Training loss: 1.7674808502197266
Validation loss: 2.065328787731868

Epoch: 6| Step: 11
Training loss: 1.6375818252563477
Validation loss: 2.0776314850776427

Epoch: 6| Step: 12
Training loss: 2.172625780105591
Validation loss: 2.086820443471273

Epoch: 6| Step: 13
Training loss: 2.4476349353790283
Validation loss: 2.0837971087424987

Epoch: 233| Step: 0
Training loss: 1.945765733718872
Validation loss: 2.073952364665206

Epoch: 6| Step: 1
Training loss: 1.7310067415237427
Validation loss: 2.0771409285965787

Epoch: 6| Step: 2
Training loss: 1.3394125699996948
Validation loss: 2.0724222903610556

Epoch: 6| Step: 3
Training loss: 1.6566832065582275
Validation loss: 2.0939482796576714

Epoch: 6| Step: 4
Training loss: 1.2182285785675049
Validation loss: 2.093311240596156

Epoch: 6| Step: 5
Training loss: 1.0390187501907349
Validation loss: 2.094681353979213

Epoch: 6| Step: 6
Training loss: 1.7995413541793823
Validation loss: 2.114426218053346

Epoch: 6| Step: 7
Training loss: 1.2381739616394043
Validation loss: 2.105795171953017

Epoch: 6| Step: 8
Training loss: 1.1338640451431274
Validation loss: 2.081552918239306

Epoch: 6| Step: 9
Training loss: 2.177196979522705
Validation loss: 2.1011157599828576

Epoch: 6| Step: 10
Training loss: 1.8599894046783447
Validation loss: 2.1112547151504026

Epoch: 6| Step: 11
Training loss: 1.8520817756652832
Validation loss: 2.117962698782644

Epoch: 6| Step: 12
Training loss: 1.4346187114715576
Validation loss: 2.1026008180392686

Epoch: 6| Step: 13
Training loss: 2.065479278564453
Validation loss: 2.0817835100235476

Epoch: 234| Step: 0
Training loss: 1.5383555889129639
Validation loss: 2.067379028566422

Epoch: 6| Step: 1
Training loss: 1.5043245553970337
Validation loss: 2.0489093244716687

Epoch: 6| Step: 2
Training loss: 1.925087332725525
Validation loss: 2.02290415763855

Epoch: 6| Step: 3
Training loss: 1.8062760829925537
Validation loss: 2.028088977259974

Epoch: 6| Step: 4
Training loss: 1.8731892108917236
Validation loss: 2.003588837961997

Epoch: 6| Step: 5
Training loss: 1.4454180002212524
Validation loss: 2.0076906142696256

Epoch: 6| Step: 6
Training loss: 1.4589686393737793
Validation loss: 2.0299264718127508

Epoch: 6| Step: 7
Training loss: 1.191145896911621
Validation loss: 2.027786383064844

Epoch: 6| Step: 8
Training loss: 1.8885369300842285
Validation loss: 2.020174818654214

Epoch: 6| Step: 9
Training loss: 1.6719138622283936
Validation loss: 2.038803278758962

Epoch: 6| Step: 10
Training loss: 1.3577553033828735
Validation loss: 2.0505193728272633

Epoch: 6| Step: 11
Training loss: 1.394416093826294
Validation loss: 2.0522906113696355

Epoch: 6| Step: 12
Training loss: 1.4389346837997437
Validation loss: 2.0843282553457443

Epoch: 6| Step: 13
Training loss: 1.5641348361968994
Validation loss: 2.091604076406007

Epoch: 235| Step: 0
Training loss: 1.8125338554382324
Validation loss: 2.1279481944217475

Epoch: 6| Step: 1
Training loss: 1.275761604309082
Validation loss: 2.1747742327310706

Epoch: 6| Step: 2
Training loss: 1.1480371952056885
Validation loss: 2.167681958085747

Epoch: 6| Step: 3
Training loss: 2.404244899749756
Validation loss: 2.145912088373656

Epoch: 6| Step: 4
Training loss: 1.6107457876205444
Validation loss: 2.125974673096852

Epoch: 6| Step: 5
Training loss: 1.684241533279419
Validation loss: 2.149261925810127

Epoch: 6| Step: 6
Training loss: 1.0747472047805786
Validation loss: 2.119376476093005

Epoch: 6| Step: 7
Training loss: 1.3768727779388428
Validation loss: 2.10004489139844

Epoch: 6| Step: 8
Training loss: 2.0940957069396973
Validation loss: 2.0699495115587787

Epoch: 6| Step: 9
Training loss: 1.6842854022979736
Validation loss: 2.0336587275228193

Epoch: 6| Step: 10
Training loss: 1.5106232166290283
Validation loss: 2.0432007492229505

Epoch: 6| Step: 11
Training loss: 1.2198891639709473
Validation loss: 2.02793284129071

Epoch: 6| Step: 12
Training loss: 1.4154822826385498
Validation loss: 2.008414528703177

Epoch: 6| Step: 13
Training loss: 1.7669099569320679
Validation loss: 2.0239488181247505

Epoch: 236| Step: 0
Training loss: 1.68003511428833
Validation loss: 2.0169978936513266

Epoch: 6| Step: 1
Training loss: 1.2155442237854004
Validation loss: 2.052258176188315

Epoch: 6| Step: 2
Training loss: 1.44657564163208
Validation loss: 2.0710636825971704

Epoch: 6| Step: 3
Training loss: 1.203954815864563
Validation loss: 2.1151669794513333

Epoch: 6| Step: 4
Training loss: 2.80900502204895
Validation loss: 2.1171345787663616

Epoch: 6| Step: 5
Training loss: 1.6608011722564697
Validation loss: 2.123145777692077

Epoch: 6| Step: 6
Training loss: 1.884737253189087
Validation loss: 2.125147376009213

Epoch: 6| Step: 7
Training loss: 2.3229222297668457
Validation loss: 2.1346359201656875

Epoch: 6| Step: 8
Training loss: 1.7870898246765137
Validation loss: 2.1201485792795816

Epoch: 6| Step: 9
Training loss: 0.6616800427436829
Validation loss: 2.1027998937073575

Epoch: 6| Step: 10
Training loss: 1.0403257608413696
Validation loss: 2.084220349147756

Epoch: 6| Step: 11
Training loss: 1.6349632740020752
Validation loss: 2.0774790484418153

Epoch: 6| Step: 12
Training loss: 1.6629250049591064
Validation loss: 2.0554424857580536

Epoch: 6| Step: 13
Training loss: 0.8268007040023804
Validation loss: 2.0750671099591

Epoch: 237| Step: 0
Training loss: 1.4676728248596191
Validation loss: 2.078416011666739

Epoch: 6| Step: 1
Training loss: 2.009540557861328
Validation loss: 2.10275500564165

Epoch: 6| Step: 2
Training loss: 1.2162890434265137
Validation loss: 2.0854811899123655

Epoch: 6| Step: 3
Training loss: 0.8189995884895325
Validation loss: 2.068386044553531

Epoch: 6| Step: 4
Training loss: 0.8242826461791992
Validation loss: 2.0857969560930805

Epoch: 6| Step: 5
Training loss: 1.9544806480407715
Validation loss: 2.0695559286302134

Epoch: 6| Step: 6
Training loss: 1.3463661670684814
Validation loss: 2.0751746123836887

Epoch: 6| Step: 7
Training loss: 0.9497306942939758
Validation loss: 2.060894949461824

Epoch: 6| Step: 8
Training loss: 2.054656744003296
Validation loss: 2.082427006895824

Epoch: 6| Step: 9
Training loss: 1.568585753440857
Validation loss: 2.0823138657436577

Epoch: 6| Step: 10
Training loss: 1.6661677360534668
Validation loss: 2.0828352205214964

Epoch: 6| Step: 11
Training loss: 1.91947340965271
Validation loss: 2.142623997503711

Epoch: 6| Step: 12
Training loss: 2.1963589191436768
Validation loss: 2.174756580783475

Epoch: 6| Step: 13
Training loss: 2.1971421241760254
Validation loss: 2.156969816453995

Epoch: 238| Step: 0
Training loss: 1.8796712160110474
Validation loss: 2.1365693987056775

Epoch: 6| Step: 1
Training loss: 1.4622184038162231
Validation loss: 2.117614943494079

Epoch: 6| Step: 2
Training loss: 1.5101547241210938
Validation loss: 2.1604204741857385

Epoch: 6| Step: 3
Training loss: 1.825209379196167
Validation loss: 2.1409648951663764

Epoch: 6| Step: 4
Training loss: 0.9895247220993042
Validation loss: 2.1445433580747215

Epoch: 6| Step: 5
Training loss: 1.417161226272583
Validation loss: 2.1230017728702997

Epoch: 6| Step: 6
Training loss: 1.7378387451171875
Validation loss: 2.1231951200833885

Epoch: 6| Step: 7
Training loss: 2.661640167236328
Validation loss: 2.1193691120352796

Epoch: 6| Step: 8
Training loss: 1.880648136138916
Validation loss: 2.154102370303164

Epoch: 6| Step: 9
Training loss: 1.0841400623321533
Validation loss: 2.124051491419474

Epoch: 6| Step: 10
Training loss: 1.4889476299285889
Validation loss: 2.0962164402008057

Epoch: 6| Step: 11
Training loss: 1.2784515619277954
Validation loss: 2.0642815764232347

Epoch: 6| Step: 12
Training loss: 1.4977977275848389
Validation loss: 2.0744789274789954

Epoch: 6| Step: 13
Training loss: 1.3657057285308838
Validation loss: 2.0323869464217976

Epoch: 239| Step: 0
Training loss: 1.6687448024749756
Validation loss: 2.0597644570053264

Epoch: 6| Step: 1
Training loss: 1.1886284351348877
Validation loss: 2.0869396117425736

Epoch: 6| Step: 2
Training loss: 1.9455480575561523
Validation loss: 2.132132407157652

Epoch: 6| Step: 3
Training loss: 1.842649221420288
Validation loss: 2.1596825020287627

Epoch: 6| Step: 4
Training loss: 1.3692656755447388
Validation loss: 2.163561690238214

Epoch: 6| Step: 5
Training loss: 1.6368358135223389
Validation loss: 2.17037292193341

Epoch: 6| Step: 6
Training loss: 1.347481608390808
Validation loss: 2.170317743414192

Epoch: 6| Step: 7
Training loss: 2.065563201904297
Validation loss: 2.194131148758755

Epoch: 6| Step: 8
Training loss: 1.798818826675415
Validation loss: 2.205336801467403

Epoch: 6| Step: 9
Training loss: 1.1661877632141113
Validation loss: 2.154635303763933

Epoch: 6| Step: 10
Training loss: 1.3389015197753906
Validation loss: 2.1491865599027244

Epoch: 6| Step: 11
Training loss: 0.9143288135528564
Validation loss: 2.116019069507558

Epoch: 6| Step: 12
Training loss: 2.053565740585327
Validation loss: 2.1205453026679253

Epoch: 6| Step: 13
Training loss: 0.8989747166633606
Validation loss: 2.102590061003162

Epoch: 240| Step: 0
Training loss: 1.4123514890670776
Validation loss: 2.0834315617879233

Epoch: 6| Step: 1
Training loss: 1.3699452877044678
Validation loss: 2.0810757760078675

Epoch: 6| Step: 2
Training loss: 1.6298601627349854
Validation loss: 2.0618987352617326

Epoch: 6| Step: 3
Training loss: 2.0747523307800293
Validation loss: 2.0742095772938063

Epoch: 6| Step: 4
Training loss: 2.1994450092315674
Validation loss: 2.0605549427770797

Epoch: 6| Step: 5
Training loss: 1.3769010305404663
Validation loss: 2.0642096560488463

Epoch: 6| Step: 6
Training loss: 1.0655574798583984
Validation loss: 2.035194690509509

Epoch: 6| Step: 7
Training loss: 1.307662010192871
Validation loss: 2.034937991890856

Epoch: 6| Step: 8
Training loss: 1.3166773319244385
Validation loss: 2.0208934737790014

Epoch: 6| Step: 9
Training loss: 1.6261754035949707
Validation loss: 2.043949706580049

Epoch: 6| Step: 10
Training loss: 1.2866427898406982
Validation loss: 2.037053023615191

Epoch: 6| Step: 11
Training loss: 2.098757743835449
Validation loss: 2.090517350422439

Epoch: 6| Step: 12
Training loss: 1.3095884323120117
Validation loss: 2.142081137626402

Epoch: 6| Step: 13
Training loss: 1.3728002309799194
Validation loss: 2.20742803747936

Epoch: 241| Step: 0
Training loss: 1.0538978576660156
Validation loss: 2.1931078305808445

Epoch: 6| Step: 1
Training loss: 0.9281449913978577
Validation loss: 2.171706853374358

Epoch: 6| Step: 2
Training loss: 1.702535629272461
Validation loss: 2.1470444920242473

Epoch: 6| Step: 3
Training loss: 2.138523578643799
Validation loss: 2.1357947908422

Epoch: 6| Step: 4
Training loss: 1.3759900331497192
Validation loss: 2.1180979872262604

Epoch: 6| Step: 5
Training loss: 1.5056049823760986
Validation loss: 2.0953849823244157

Epoch: 6| Step: 6
Training loss: 2.427093267440796
Validation loss: 2.1055074994282057

Epoch: 6| Step: 7
Training loss: 1.5310331583023071
Validation loss: 2.0422880470111804

Epoch: 6| Step: 8
Training loss: 1.0536730289459229
Validation loss: 2.0530092126579693

Epoch: 6| Step: 9
Training loss: 1.0419142246246338
Validation loss: 2.061225514258108

Epoch: 6| Step: 10
Training loss: 1.5316684246063232
Validation loss: 2.1082670150264615

Epoch: 6| Step: 11
Training loss: 1.1950448751449585
Validation loss: 2.1474586750871394

Epoch: 6| Step: 12
Training loss: 2.1535468101501465
Validation loss: 2.1250410900321057

Epoch: 6| Step: 13
Training loss: 1.9210169315338135
Validation loss: 2.1064386906162387

Epoch: 242| Step: 0
Training loss: 1.0106736421585083
Validation loss: 2.067239753661617

Epoch: 6| Step: 1
Training loss: 1.2603918313980103
Validation loss: 2.0559579313442273

Epoch: 6| Step: 2
Training loss: 1.376950979232788
Validation loss: 2.0436807896501277

Epoch: 6| Step: 3
Training loss: 1.9496670961380005
Validation loss: 2.0555001484450472

Epoch: 6| Step: 4
Training loss: 1.2261788845062256
Validation loss: 2.081687319663263

Epoch: 6| Step: 5
Training loss: 2.1696763038635254
Validation loss: 2.04922152591008

Epoch: 6| Step: 6
Training loss: 1.4426804780960083
Validation loss: 2.103601501834008

Epoch: 6| Step: 7
Training loss: 1.7627665996551514
Validation loss: 2.132562252783006

Epoch: 6| Step: 8
Training loss: 1.8894835710525513
Validation loss: 2.1816272017776326

Epoch: 6| Step: 9
Training loss: 1.4237552881240845
Validation loss: 2.1906899008699643

Epoch: 6| Step: 10
Training loss: 1.0253772735595703
Validation loss: 2.1873458329067437

Epoch: 6| Step: 11
Training loss: 1.5285494327545166
Validation loss: 2.1928778797067623

Epoch: 6| Step: 12
Training loss: 1.527056097984314
Validation loss: 2.1643717519698606

Epoch: 6| Step: 13
Training loss: 2.284935474395752
Validation loss: 2.100575262500394

Epoch: 243| Step: 0
Training loss: 1.4687066078186035
Validation loss: 2.06980207145855

Epoch: 6| Step: 1
Training loss: 1.6215811967849731
Validation loss: 2.0464158993895336

Epoch: 6| Step: 2
Training loss: 1.4751139879226685
Validation loss: 2.037369267914885

Epoch: 6| Step: 3
Training loss: 1.6178715229034424
Validation loss: 1.9843378092653008

Epoch: 6| Step: 4
Training loss: 1.7480809688568115
Validation loss: 2.0011856363665674

Epoch: 6| Step: 5
Training loss: 1.1489753723144531
Validation loss: 2.0027486406346804

Epoch: 6| Step: 6
Training loss: 1.6810951232910156
Validation loss: 1.9804446697235107

Epoch: 6| Step: 7
Training loss: 1.4470900297164917
Validation loss: 1.9935490777415614

Epoch: 6| Step: 8
Training loss: 1.580064296722412
Validation loss: 2.00432728311067

Epoch: 6| Step: 9
Training loss: 1.446230411529541
Validation loss: 2.032646891891315

Epoch: 6| Step: 10
Training loss: 1.5426528453826904
Validation loss: 2.0739092519206386

Epoch: 6| Step: 11
Training loss: 1.806025505065918
Validation loss: 2.1057890025518273

Epoch: 6| Step: 12
Training loss: 1.4758565425872803
Validation loss: 2.102413818400393

Epoch: 6| Step: 13
Training loss: 1.0331676006317139
Validation loss: 2.140801142620784

Epoch: 244| Step: 0
Training loss: 1.6344289779663086
Validation loss: 2.1475501983396468

Epoch: 6| Step: 1
Training loss: 2.3510665893554688
Validation loss: 2.1349687166111444

Epoch: 6| Step: 2
Training loss: 1.5941505432128906
Validation loss: 2.1149767624434603

Epoch: 6| Step: 3
Training loss: 1.2677900791168213
Validation loss: 2.0549318867345012

Epoch: 6| Step: 4
Training loss: 1.3741061687469482
Validation loss: 2.0459931332577943

Epoch: 6| Step: 5
Training loss: 1.7360566854476929
Validation loss: 2.0330045697509602

Epoch: 6| Step: 6
Training loss: 1.5669997930526733
Validation loss: 2.0330724203458397

Epoch: 6| Step: 7
Training loss: 1.441544532775879
Validation loss: 2.031066098520833

Epoch: 6| Step: 8
Training loss: 1.5161036252975464
Validation loss: 2.0702242466711227

Epoch: 6| Step: 9
Training loss: 1.7358872890472412
Validation loss: 2.0710689842060046

Epoch: 6| Step: 10
Training loss: 1.5093129873275757
Validation loss: 2.083925385628977

Epoch: 6| Step: 11
Training loss: 1.332884669303894
Validation loss: 2.1324290178155385

Epoch: 6| Step: 12
Training loss: 0.9521963000297546
Validation loss: 2.0926024157513856

Epoch: 6| Step: 13
Training loss: 1.437849521636963
Validation loss: 2.1017790622608636

Epoch: 245| Step: 0
Training loss: 2.3550920486450195
Validation loss: 2.0828016945110854

Epoch: 6| Step: 1
Training loss: 1.9649457931518555
Validation loss: 2.091737772828789

Epoch: 6| Step: 2
Training loss: 1.5129716396331787
Validation loss: 2.1173002732697355

Epoch: 6| Step: 3
Training loss: 1.2317800521850586
Validation loss: 2.1133742896459435

Epoch: 6| Step: 4
Training loss: 1.0723568201065063
Validation loss: 2.1103343194530857

Epoch: 6| Step: 5
Training loss: 1.2541537284851074
Validation loss: 2.13773883927253

Epoch: 6| Step: 6
Training loss: 1.827820897102356
Validation loss: 2.1736753115089993

Epoch: 6| Step: 7
Training loss: 1.4224789142608643
Validation loss: 2.2144757701504614

Epoch: 6| Step: 8
Training loss: 1.1198772192001343
Validation loss: 2.176662900114572

Epoch: 6| Step: 9
Training loss: 0.7969115972518921
Validation loss: 2.1552372991397815

Epoch: 6| Step: 10
Training loss: 1.0082404613494873
Validation loss: 2.107286783956712

Epoch: 6| Step: 11
Training loss: 1.4238083362579346
Validation loss: 2.0886788727134786

Epoch: 6| Step: 12
Training loss: 2.363363265991211
Validation loss: 2.0332623835532897

Epoch: 6| Step: 13
Training loss: 1.8894343376159668
Validation loss: 2.051710505639353

Epoch: 246| Step: 0
Training loss: 1.7163619995117188
Validation loss: 2.0257668930997133

Epoch: 6| Step: 1
Training loss: 1.4113123416900635
Validation loss: 2.0001859639280584

Epoch: 6| Step: 2
Training loss: 1.6981887817382812
Validation loss: 2.026226394919939

Epoch: 6| Step: 3
Training loss: 1.1345479488372803
Validation loss: 2.0136865800426853

Epoch: 6| Step: 4
Training loss: 2.000142812728882
Validation loss: 2.009971933980142

Epoch: 6| Step: 5
Training loss: 1.3614593744277954
Validation loss: 2.0507794490424534

Epoch: 6| Step: 6
Training loss: 1.0952389240264893
Validation loss: 2.1423242899679367

Epoch: 6| Step: 7
Training loss: 2.5300960540771484
Validation loss: 2.158397779669813

Epoch: 6| Step: 8
Training loss: 2.1004157066345215
Validation loss: 2.261932989602448

Epoch: 6| Step: 9
Training loss: 1.2974953651428223
Validation loss: 2.301217443199568

Epoch: 6| Step: 10
Training loss: 1.656738519668579
Validation loss: 2.28186708881009

Epoch: 6| Step: 11
Training loss: 1.0675569772720337
Validation loss: 2.2160462858856365

Epoch: 6| Step: 12
Training loss: 0.7844578623771667
Validation loss: 2.199704175354332

Epoch: 6| Step: 13
Training loss: 1.5689501762390137
Validation loss: 2.1197583162656395

Epoch: 247| Step: 0
Training loss: 2.0462355613708496
Validation loss: 2.1181781343234483

Epoch: 6| Step: 1
Training loss: 1.5040339231491089
Validation loss: 2.111831242038358

Epoch: 6| Step: 2
Training loss: 1.16452157497406
Validation loss: 2.0862414862519953

Epoch: 6| Step: 3
Training loss: 1.5590364933013916
Validation loss: 2.075167896927044

Epoch: 6| Step: 4
Training loss: 1.1425012350082397
Validation loss: 2.0532317469196935

Epoch: 6| Step: 5
Training loss: 1.2230174541473389
Validation loss: 2.076458984805692

Epoch: 6| Step: 6
Training loss: 1.2014461755752563
Validation loss: 2.1407130700285717

Epoch: 6| Step: 7
Training loss: 1.35648775100708
Validation loss: 2.168289492207189

Epoch: 6| Step: 8
Training loss: 2.104480743408203
Validation loss: 2.2110252841826408

Epoch: 6| Step: 9
Training loss: 1.1126790046691895
Validation loss: 2.2607413286803872

Epoch: 6| Step: 10
Training loss: 1.5114924907684326
Validation loss: 2.2946239030489357

Epoch: 6| Step: 11
Training loss: 1.1246435642242432
Validation loss: 2.3134351340673303

Epoch: 6| Step: 12
Training loss: 2.5587515830993652
Validation loss: 2.2455125675406507

Epoch: 6| Step: 13
Training loss: 1.7495226860046387
Validation loss: 2.1665595141790246

Epoch: 248| Step: 0
Training loss: 1.2500401735305786
Validation loss: 2.1208657141654723

Epoch: 6| Step: 1
Training loss: 1.2295793294906616
Validation loss: 2.0914123135228313

Epoch: 6| Step: 2
Training loss: 1.1633201837539673
Validation loss: 2.063221957093926

Epoch: 6| Step: 3
Training loss: 2.0587987899780273
Validation loss: 2.0570844091394895

Epoch: 6| Step: 4
Training loss: 2.037480592727661
Validation loss: 2.017655364928707

Epoch: 6| Step: 5
Training loss: 0.9977478384971619
Validation loss: 2.0363445538346485

Epoch: 6| Step: 6
Training loss: 1.3892624378204346
Validation loss: 2.0317496151052494

Epoch: 6| Step: 7
Training loss: 0.8987842798233032
Validation loss: 2.0634661900099887

Epoch: 6| Step: 8
Training loss: 1.9300410747528076
Validation loss: 2.0806017383452384

Epoch: 6| Step: 9
Training loss: 0.9619143009185791
Validation loss: 2.1363925510837185

Epoch: 6| Step: 10
Training loss: 1.6303904056549072
Validation loss: 2.1746187453628867

Epoch: 6| Step: 11
Training loss: 1.137331247329712
Validation loss: 2.1980271698326193

Epoch: 6| Step: 12
Training loss: 2.293247699737549
Validation loss: 2.2213772445596676

Epoch: 6| Step: 13
Training loss: 1.956442952156067
Validation loss: 2.195020673095539

Epoch: 249| Step: 0
Training loss: 1.2984768152236938
Validation loss: 2.1668346825466362

Epoch: 6| Step: 1
Training loss: 0.896569013595581
Validation loss: 2.146927470801979

Epoch: 6| Step: 2
Training loss: 1.2189477682113647
Validation loss: 2.1553319628520677

Epoch: 6| Step: 3
Training loss: 1.52083158493042
Validation loss: 2.1219217879797823

Epoch: 6| Step: 4
Training loss: 1.4560190439224243
Validation loss: 2.1335284402293544

Epoch: 6| Step: 5
Training loss: 1.543210506439209
Validation loss: 2.0910027462949037

Epoch: 6| Step: 6
Training loss: 1.5412843227386475
Validation loss: 2.091412236613612

Epoch: 6| Step: 7
Training loss: 1.6620359420776367
Validation loss: 2.0903339168076873

Epoch: 6| Step: 8
Training loss: 1.9309430122375488
Validation loss: 2.0723287520870084

Epoch: 6| Step: 9
Training loss: 1.7920777797698975
Validation loss: 2.070885137845111

Epoch: 6| Step: 10
Training loss: 1.2046939134597778
Validation loss: 2.0853542025371263

Epoch: 6| Step: 11
Training loss: 1.3829673528671265
Validation loss: 2.0924472616564844

Epoch: 6| Step: 12
Training loss: 1.3878055810928345
Validation loss: 2.1397283025967178

Epoch: 6| Step: 13
Training loss: 1.8163999319076538
Validation loss: 2.1277977676801783

Epoch: 250| Step: 0
Training loss: 1.2630887031555176
Validation loss: 2.1676729315070697

Epoch: 6| Step: 1
Training loss: 2.169919490814209
Validation loss: 2.165588632706673

Epoch: 6| Step: 2
Training loss: 1.0049443244934082
Validation loss: 2.1932587931233067

Epoch: 6| Step: 3
Training loss: 1.5518295764923096
Validation loss: 2.2088248473341747

Epoch: 6| Step: 4
Training loss: 1.620506763458252
Validation loss: 2.1474273153530654

Epoch: 6| Step: 5
Training loss: 1.296005368232727
Validation loss: 2.1377351873664447

Epoch: 6| Step: 6
Training loss: 1.027637004852295
Validation loss: 2.1059054174730854

Epoch: 6| Step: 7
Training loss: 1.3671996593475342
Validation loss: 2.1144972308989494

Epoch: 6| Step: 8
Training loss: 1.1739161014556885
Validation loss: 2.067210030812089

Epoch: 6| Step: 9
Training loss: 1.7851264476776123
Validation loss: 2.0740322220710015

Epoch: 6| Step: 10
Training loss: 1.9601309299468994
Validation loss: 2.090295330170662

Epoch: 6| Step: 11
Training loss: 1.258498191833496
Validation loss: 2.1156944523575487

Epoch: 6| Step: 12
Training loss: 1.3412038087844849
Validation loss: 2.1726785141934633

Epoch: 6| Step: 13
Training loss: 1.6238211393356323
Validation loss: 2.184175145241522

Epoch: 251| Step: 0
Training loss: 1.5550997257232666
Validation loss: 2.183459622885591

Epoch: 6| Step: 1
Training loss: 1.4909577369689941
Validation loss: 2.1334664975443194

Epoch: 6| Step: 2
Training loss: 0.9846221208572388
Validation loss: 2.104693797326857

Epoch: 6| Step: 3
Training loss: 1.370168685913086
Validation loss: 2.0399345902986425

Epoch: 6| Step: 4
Training loss: 1.217895746231079
Validation loss: 2.0358642185887983

Epoch: 6| Step: 5
Training loss: 1.7106738090515137
Validation loss: 2.0144649692761

Epoch: 6| Step: 6
Training loss: 1.5047988891601562
Validation loss: 2.0257076947919783

Epoch: 6| Step: 7
Training loss: 2.21553897857666
Validation loss: 2.014092650464786

Epoch: 6| Step: 8
Training loss: 1.0442771911621094
Validation loss: 2.034210343514719

Epoch: 6| Step: 9
Training loss: 1.7874445915222168
Validation loss: 2.039078217680736

Epoch: 6| Step: 10
Training loss: 1.4649085998535156
Validation loss: 2.0387885852526595

Epoch: 6| Step: 11
Training loss: 1.5179532766342163
Validation loss: 2.0631248476684734

Epoch: 6| Step: 12
Training loss: 1.1597259044647217
Validation loss: 2.1443455962724585

Epoch: 6| Step: 13
Training loss: 1.1379914283752441
Validation loss: 2.15196495158698

Epoch: 252| Step: 0
Training loss: 1.337761640548706
Validation loss: 2.216753558446002

Epoch: 6| Step: 1
Training loss: 0.9968104958534241
Validation loss: 2.2549361516070623

Epoch: 6| Step: 2
Training loss: 1.23146390914917
Validation loss: 2.2444098636668217

Epoch: 6| Step: 3
Training loss: 1.044744849205017
Validation loss: 2.212972830700618

Epoch: 6| Step: 4
Training loss: 1.7899366617202759
Validation loss: 2.195114020378359

Epoch: 6| Step: 5
Training loss: 1.194068193435669
Validation loss: 2.0946975907971783

Epoch: 6| Step: 6
Training loss: 1.7155992984771729
Validation loss: 2.047504445557953

Epoch: 6| Step: 7
Training loss: 1.887169599533081
Validation loss: 2.006327654725762

Epoch: 6| Step: 8
Training loss: 1.7839850187301636
Validation loss: 2.016752735260994

Epoch: 6| Step: 9
Training loss: 1.8481647968292236
Validation loss: 1.9706886840123001

Epoch: 6| Step: 10
Training loss: 1.9055885076522827
Validation loss: 1.999794226820751

Epoch: 6| Step: 11
Training loss: 1.5121631622314453
Validation loss: 1.9931702536921347

Epoch: 6| Step: 12
Training loss: 0.9078575968742371
Validation loss: 1.979544621641918

Epoch: 6| Step: 13
Training loss: 0.8156483769416809
Validation loss: 1.9967705895823817

Epoch: 253| Step: 0
Training loss: 0.702768862247467
Validation loss: 2.01284610584218

Epoch: 6| Step: 1
Training loss: 1.4467960596084595
Validation loss: 2.1031026045481362

Epoch: 6| Step: 2
Training loss: 1.564638376235962
Validation loss: 2.1253355985046714

Epoch: 6| Step: 3
Training loss: 1.6281545162200928
Validation loss: 2.133960582876718

Epoch: 6| Step: 4
Training loss: 1.7820847034454346
Validation loss: 2.1469434076739895

Epoch: 6| Step: 5
Training loss: 1.4665193557739258
Validation loss: 2.0809670058629846

Epoch: 6| Step: 6
Training loss: 2.0283541679382324
Validation loss: 2.062559517480994

Epoch: 6| Step: 7
Training loss: 1.168339729309082
Validation loss: 2.088714486809187

Epoch: 6| Step: 8
Training loss: 1.4494036436080933
Validation loss: 2.094971958027091

Epoch: 6| Step: 9
Training loss: 0.6294234991073608
Validation loss: 2.091248499449863

Epoch: 6| Step: 10
Training loss: 1.5510146617889404
Validation loss: 2.113039994752535

Epoch: 6| Step: 11
Training loss: 1.3714754581451416
Validation loss: 2.1239726133244012

Epoch: 6| Step: 12
Training loss: 1.2846015691757202
Validation loss: 2.145994040273851

Epoch: 6| Step: 13
Training loss: 2.2735066413879395
Validation loss: 2.1396305766156924

Epoch: 254| Step: 0
Training loss: 1.3054654598236084
Validation loss: 2.1136115725322435

Epoch: 6| Step: 1
Training loss: 0.6614853739738464
Validation loss: 2.1382605388600338

Epoch: 6| Step: 2
Training loss: 1.707037329673767
Validation loss: 2.1343148780125443

Epoch: 6| Step: 3
Training loss: 1.2288516759872437
Validation loss: 2.143756115308372

Epoch: 6| Step: 4
Training loss: 1.134751796722412
Validation loss: 2.1559213489614506

Epoch: 6| Step: 5
Training loss: 2.1504292488098145
Validation loss: 2.1591084387994584

Epoch: 6| Step: 6
Training loss: 1.300051212310791
Validation loss: 2.1361897017366145

Epoch: 6| Step: 7
Training loss: 0.956079363822937
Validation loss: 2.11634031034285

Epoch: 6| Step: 8
Training loss: 2.0186514854431152
Validation loss: 2.0901782128118698

Epoch: 6| Step: 9
Training loss: 1.5607566833496094
Validation loss: 2.095505929762317

Epoch: 6| Step: 10
Training loss: 1.8147271871566772
Validation loss: 2.1180123808563396

Epoch: 6| Step: 11
Training loss: 1.0114127397537231
Validation loss: 2.1086447367104153

Epoch: 6| Step: 12
Training loss: 1.464080572128296
Validation loss: 2.1327732147709018

Epoch: 6| Step: 13
Training loss: 1.4406561851501465
Validation loss: 2.0828328414629866

Epoch: 255| Step: 0
Training loss: 1.304485559463501
Validation loss: 2.1028868998250654

Epoch: 6| Step: 1
Training loss: 1.0566942691802979
Validation loss: 2.1533482741284113

Epoch: 6| Step: 2
Training loss: 2.041813611984253
Validation loss: 2.1273956606465

Epoch: 6| Step: 3
Training loss: 1.6004388332366943
Validation loss: 2.1399703769273657

Epoch: 6| Step: 4
Training loss: 1.709908127784729
Validation loss: 2.1285929910598265

Epoch: 6| Step: 5
Training loss: 0.8884799480438232
Validation loss: 2.1327955402353758

Epoch: 6| Step: 6
Training loss: 1.1076858043670654
Validation loss: 2.120961011096995

Epoch: 6| Step: 7
Training loss: 1.2366106510162354
Validation loss: 2.1225065133904897

Epoch: 6| Step: 8
Training loss: 1.7023744583129883
Validation loss: 2.1089568740578106

Epoch: 6| Step: 9
Training loss: 1.4401116371154785
Validation loss: 2.078583541736808

Epoch: 6| Step: 10
Training loss: 1.2072863578796387
Validation loss: 2.1341270656995874

Epoch: 6| Step: 11
Training loss: 0.9937149286270142
Validation loss: 2.1169138249530586

Epoch: 6| Step: 12
Training loss: 1.627099871635437
Validation loss: 2.0932569016692457

Epoch: 6| Step: 13
Training loss: 1.231454610824585
Validation loss: 2.055157769110895

Epoch: 256| Step: 0
Training loss: 1.47731614112854
Validation loss: 2.02830514343836

Epoch: 6| Step: 1
Training loss: 1.2984437942504883
Validation loss: 2.0434412443509666

Epoch: 6| Step: 2
Training loss: 2.1005430221557617
Validation loss: 2.081045868576214

Epoch: 6| Step: 3
Training loss: 1.1136645078659058
Validation loss: 2.01388039640201

Epoch: 6| Step: 4
Training loss: 1.9247286319732666
Validation loss: 2.0555387594366588

Epoch: 6| Step: 5
Training loss: 1.2041351795196533
Validation loss: 2.0514661419776177

Epoch: 6| Step: 6
Training loss: 1.415548324584961
Validation loss: 2.0659068246041574

Epoch: 6| Step: 7
Training loss: 1.107352375984192
Validation loss: 2.080033822726178

Epoch: 6| Step: 8
Training loss: 1.5237889289855957
Validation loss: 2.131740623904813

Epoch: 6| Step: 9
Training loss: 1.276149868965149
Validation loss: 2.1565277832810597

Epoch: 6| Step: 10
Training loss: 1.26454496383667
Validation loss: 2.142928232428848

Epoch: 6| Step: 11
Training loss: 1.1033025979995728
Validation loss: 2.1163307377087173

Epoch: 6| Step: 12
Training loss: 0.9807212352752686
Validation loss: 2.1116874397441907

Epoch: 6| Step: 13
Training loss: 1.2831873893737793
Validation loss: 2.060563983455781

Epoch: 257| Step: 0
Training loss: 1.3444809913635254
Validation loss: 2.0475759275497927

Epoch: 6| Step: 1
Training loss: 1.6491022109985352
Validation loss: 2.020878768736316

Epoch: 6| Step: 2
Training loss: 0.96354079246521
Validation loss: 2.0045913944962206

Epoch: 6| Step: 3
Training loss: 1.420325756072998
Validation loss: 2.0244424125199676

Epoch: 6| Step: 4
Training loss: 1.526491641998291
Validation loss: 2.0431512350677163

Epoch: 6| Step: 5
Training loss: 1.6786415576934814
Validation loss: 2.057472654568252

Epoch: 6| Step: 6
Training loss: 0.8976510763168335
Validation loss: 2.068950658203453

Epoch: 6| Step: 7
Training loss: 0.9761065244674683
Validation loss: 2.081439164377028

Epoch: 6| Step: 8
Training loss: 1.503043293952942
Validation loss: 2.107201587769293

Epoch: 6| Step: 9
Training loss: 1.4124977588653564
Validation loss: 2.1279122470527567

Epoch: 6| Step: 10
Training loss: 1.5610170364379883
Validation loss: 2.1842061037658365

Epoch: 6| Step: 11
Training loss: 0.9741443395614624
Validation loss: 2.198347262156907

Epoch: 6| Step: 12
Training loss: 1.5123729705810547
Validation loss: 2.1890654269085137

Epoch: 6| Step: 13
Training loss: 1.9463040828704834
Validation loss: 2.2051545689182896

Epoch: 258| Step: 0
Training loss: 1.2176177501678467
Validation loss: 2.1476019454258743

Epoch: 6| Step: 1
Training loss: 1.0848814249038696
Validation loss: 2.1191999925080167

Epoch: 6| Step: 2
Training loss: 1.2461485862731934
Validation loss: 2.083605020276962

Epoch: 6| Step: 3
Training loss: 1.4292900562286377
Validation loss: 2.080427687655213

Epoch: 6| Step: 4
Training loss: 0.9777425527572632
Validation loss: 2.088339691521019

Epoch: 6| Step: 5
Training loss: 1.0183334350585938
Validation loss: 2.0667532656782415

Epoch: 6| Step: 6
Training loss: 1.2648217678070068
Validation loss: 2.0372011059073993

Epoch: 6| Step: 7
Training loss: 1.7970829010009766
Validation loss: 2.0511888457882788

Epoch: 6| Step: 8
Training loss: 1.5454204082489014
Validation loss: 2.0479941586012482

Epoch: 6| Step: 9
Training loss: 1.1844682693481445
Validation loss: 2.043056580328172

Epoch: 6| Step: 10
Training loss: 1.3475911617279053
Validation loss: 2.049796950432562

Epoch: 6| Step: 11
Training loss: 1.477061152458191
Validation loss: 2.0857062134691464

Epoch: 6| Step: 12
Training loss: 1.9434995651245117
Validation loss: 2.115668095568175

Epoch: 6| Step: 13
Training loss: 1.4263931512832642
Validation loss: 2.1211864179180515

Epoch: 259| Step: 0
Training loss: 1.9194968938827515
Validation loss: 2.1523015986206713

Epoch: 6| Step: 1
Training loss: 1.6343311071395874
Validation loss: 2.2230761845906577

Epoch: 6| Step: 2
Training loss: 1.5431807041168213
Validation loss: 2.1794848967623968

Epoch: 6| Step: 3
Training loss: 0.8710344433784485
Validation loss: 2.16483231770095

Epoch: 6| Step: 4
Training loss: 0.9858628511428833
Validation loss: 2.1361321044224564

Epoch: 6| Step: 5
Training loss: 1.1211931705474854
Validation loss: 2.116078390870043

Epoch: 6| Step: 6
Training loss: 1.3310444355010986
Validation loss: 2.112694894113848

Epoch: 6| Step: 7
Training loss: 1.2534894943237305
Validation loss: 2.1442018196146977

Epoch: 6| Step: 8
Training loss: 1.9837301969528198
Validation loss: 2.122938544519486

Epoch: 6| Step: 9
Training loss: 1.1769747734069824
Validation loss: 2.1106818927231656

Epoch: 6| Step: 10
Training loss: 0.9258333444595337
Validation loss: 2.127711493481872

Epoch: 6| Step: 11
Training loss: 1.1453709602355957
Validation loss: 2.0871573417417464

Epoch: 6| Step: 12
Training loss: 1.1352653503417969
Validation loss: 2.0770518959209485

Epoch: 6| Step: 13
Training loss: 1.802182912826538
Validation loss: 2.084898799978277

Epoch: 260| Step: 0
Training loss: 1.5944242477416992
Validation loss: 2.104618218637282

Epoch: 6| Step: 1
Training loss: 1.3009815216064453
Validation loss: 2.0751670073437434

Epoch: 6| Step: 2
Training loss: 1.0707106590270996
Validation loss: 2.098038263218377

Epoch: 6| Step: 3
Training loss: 1.781233310699463
Validation loss: 2.0730100870132446

Epoch: 6| Step: 4
Training loss: 1.4864065647125244
Validation loss: 2.0797067406356975

Epoch: 6| Step: 5
Training loss: 0.8098564743995667
Validation loss: 2.112213888475972

Epoch: 6| Step: 6
Training loss: 1.2893345355987549
Validation loss: 2.1129308464706584

Epoch: 6| Step: 7
Training loss: 1.7367221117019653
Validation loss: 2.1131753344689646

Epoch: 6| Step: 8
Training loss: 1.3317015171051025
Validation loss: 2.135463155725951

Epoch: 6| Step: 9
Training loss: 1.0084593296051025
Validation loss: 2.149291599950483

Epoch: 6| Step: 10
Training loss: 1.099076509475708
Validation loss: 2.190658692390688

Epoch: 6| Step: 11
Training loss: 1.6554244756698608
Validation loss: 2.1599232535208426

Epoch: 6| Step: 12
Training loss: 1.089165449142456
Validation loss: 2.123013319507722

Epoch: 6| Step: 13
Training loss: 1.556653380393982
Validation loss: 2.0970959868482364

Epoch: 261| Step: 0
Training loss: 2.027928590774536
Validation loss: 2.056463964523808

Epoch: 6| Step: 1
Training loss: 1.4433197975158691
Validation loss: 2.069010849921934

Epoch: 6| Step: 2
Training loss: 0.8505052924156189
Validation loss: 2.0677426399723178

Epoch: 6| Step: 3
Training loss: 1.7629551887512207
Validation loss: 2.0958678927472842

Epoch: 6| Step: 4
Training loss: 0.7849477529525757
Validation loss: 2.0288723322653

Epoch: 6| Step: 5
Training loss: 1.1039390563964844
Validation loss: 2.023850694779427

Epoch: 6| Step: 6
Training loss: 0.8931589722633362
Validation loss: 2.0309261352785173

Epoch: 6| Step: 7
Training loss: 1.2839471101760864
Validation loss: 2.0434255625611994

Epoch: 6| Step: 8
Training loss: 1.9198276996612549
Validation loss: 2.0619872590546966

Epoch: 6| Step: 9
Training loss: 1.3453145027160645
Validation loss: 2.0901415937690326

Epoch: 6| Step: 10
Training loss: 1.9130984544754028
Validation loss: 2.0910959128410584

Epoch: 6| Step: 11
Training loss: 1.0800875425338745
Validation loss: 2.151611210197531

Epoch: 6| Step: 12
Training loss: 1.0647120475769043
Validation loss: 2.1862454850186586

Epoch: 6| Step: 13
Training loss: 0.5618622303009033
Validation loss: 2.21621730250697

Epoch: 262| Step: 0
Training loss: 1.0808727741241455
Validation loss: 2.198940569354642

Epoch: 6| Step: 1
Training loss: 1.4220541715621948
Validation loss: 2.1829445567182315

Epoch: 6| Step: 2
Training loss: 0.8535350561141968
Validation loss: 2.162373346667136

Epoch: 6| Step: 3
Training loss: 1.553330898284912
Validation loss: 2.154224713643392

Epoch: 6| Step: 4
Training loss: 0.9984825253486633
Validation loss: 2.112929246758902

Epoch: 6| Step: 5
Training loss: 0.8110551834106445
Validation loss: 2.14277228488717

Epoch: 6| Step: 6
Training loss: 1.3905613422393799
Validation loss: 2.1173711694696897

Epoch: 6| Step: 7
Training loss: 1.7475948333740234
Validation loss: 2.0743484099706015

Epoch: 6| Step: 8
Training loss: 1.7540531158447266
Validation loss: 2.0511196505638862

Epoch: 6| Step: 9
Training loss: 1.509958028793335
Validation loss: 2.074202045317619

Epoch: 6| Step: 10
Training loss: 1.2792294025421143
Validation loss: 2.039114697005159

Epoch: 6| Step: 11
Training loss: 1.1188359260559082
Validation loss: 2.0335873301311205

Epoch: 6| Step: 12
Training loss: 1.7399392127990723
Validation loss: 2.070942545449862

Epoch: 6| Step: 13
Training loss: 0.6570294499397278
Validation loss: 2.07921859013137

Epoch: 263| Step: 0
Training loss: 1.7086989879608154
Validation loss: 2.148855624660369

Epoch: 6| Step: 1
Training loss: 1.0709494352340698
Validation loss: 2.1876597917208107

Epoch: 6| Step: 2
Training loss: 1.1857792139053345
Validation loss: 2.2098166083776825

Epoch: 6| Step: 3
Training loss: 1.1719746589660645
Validation loss: 2.284990931069979

Epoch: 6| Step: 4
Training loss: 1.6806352138519287
Validation loss: 2.257923468466728

Epoch: 6| Step: 5
Training loss: 1.6118278503417969
Validation loss: 2.2362288762164373

Epoch: 6| Step: 6
Training loss: 1.3013583421707153
Validation loss: 2.2010021132807576

Epoch: 6| Step: 7
Training loss: 1.0921598672866821
Validation loss: 2.12867493783274

Epoch: 6| Step: 8
Training loss: 1.3770270347595215
Validation loss: 2.095690914379653

Epoch: 6| Step: 9
Training loss: 0.9214123487472534
Validation loss: 2.044538341542726

Epoch: 6| Step: 10
Training loss: 1.5676252841949463
Validation loss: 2.0159691187643234

Epoch: 6| Step: 11
Training loss: 1.8546619415283203
Validation loss: 2.028678767142757

Epoch: 6| Step: 12
Training loss: 0.8597245216369629
Validation loss: 2.004918545804998

Epoch: 6| Step: 13
Training loss: 0.911600649356842
Validation loss: 2.0457239509910665

Epoch: 264| Step: 0
Training loss: 1.5508296489715576
Validation loss: 2.0314522968825472

Epoch: 6| Step: 1
Training loss: 1.067239761352539
Validation loss: 2.064892763732582

Epoch: 6| Step: 2
Training loss: 1.7907369136810303
Validation loss: 2.0610478180710987

Epoch: 6| Step: 3
Training loss: 0.703643262386322
Validation loss: 2.042497606687648

Epoch: 6| Step: 4
Training loss: 0.9286973476409912
Validation loss: 2.0843484581157727

Epoch: 6| Step: 5
Training loss: 1.2529919147491455
Validation loss: 2.118654699735744

Epoch: 6| Step: 6
Training loss: 1.671413779258728
Validation loss: 2.1759163013068576

Epoch: 6| Step: 7
Training loss: 0.9658072590827942
Validation loss: 2.168413605741275

Epoch: 6| Step: 8
Training loss: 1.5458457469940186
Validation loss: 2.1957470986150924

Epoch: 6| Step: 9
Training loss: 1.3753750324249268
Validation loss: 2.2078130706664054

Epoch: 6| Step: 10
Training loss: 1.4818546772003174
Validation loss: 2.220733634887203

Epoch: 6| Step: 11
Training loss: 1.3198970556259155
Validation loss: 2.1969746953697613

Epoch: 6| Step: 12
Training loss: 1.2986137866973877
Validation loss: 2.180924798852654

Epoch: 6| Step: 13
Training loss: 1.2698545455932617
Validation loss: 2.139509480486634

Epoch: 265| Step: 0
Training loss: 1.0078022480010986
Validation loss: 2.141815634183986

Epoch: 6| Step: 1
Training loss: 1.0687373876571655
Validation loss: 2.19148511527687

Epoch: 6| Step: 2
Training loss: 1.1470915079116821
Validation loss: 2.158205824513589

Epoch: 6| Step: 3
Training loss: 1.7633376121520996
Validation loss: 2.1400778473064466

Epoch: 6| Step: 4
Training loss: 1.5657933950424194
Validation loss: 2.101811747397146

Epoch: 6| Step: 5
Training loss: 1.0976996421813965
Validation loss: 2.108265830624488

Epoch: 6| Step: 6
Training loss: 1.6614923477172852
Validation loss: 2.0461486001168527

Epoch: 6| Step: 7
Training loss: 1.5845977067947388
Validation loss: 2.0306792566853185

Epoch: 6| Step: 8
Training loss: 0.5297145843505859
Validation loss: 2.0169678772649458

Epoch: 6| Step: 9
Training loss: 1.4971888065338135
Validation loss: 2.022403273531186

Epoch: 6| Step: 10
Training loss: 1.317073941230774
Validation loss: 2.024469062846194

Epoch: 6| Step: 11
Training loss: 1.2985931634902954
Validation loss: 2.06975225223008

Epoch: 6| Step: 12
Training loss: 1.5647401809692383
Validation loss: 2.0738996421137164

Epoch: 6| Step: 13
Training loss: 1.0013880729675293
Validation loss: 2.126857893441313

Epoch: 266| Step: 0
Training loss: 1.4013822078704834
Validation loss: 2.1807975281951246

Epoch: 6| Step: 1
Training loss: 1.2626934051513672
Validation loss: 2.155119166579298

Epoch: 6| Step: 2
Training loss: 1.588106393814087
Validation loss: 2.155141374116303

Epoch: 6| Step: 3
Training loss: 1.1515965461730957
Validation loss: 2.1723907583503315

Epoch: 6| Step: 4
Training loss: 1.2193788290023804
Validation loss: 2.1498987828531573

Epoch: 6| Step: 5
Training loss: 1.3434441089630127
Validation loss: 2.123140455574118

Epoch: 6| Step: 6
Training loss: 1.1379523277282715
Validation loss: 2.109402718082551

Epoch: 6| Step: 7
Training loss: 1.7368425130844116
Validation loss: 2.143704709186349

Epoch: 6| Step: 8
Training loss: 1.2396141290664673
Validation loss: 2.126999625595667

Epoch: 6| Step: 9
Training loss: 1.6701974868774414
Validation loss: 2.1543870382411505

Epoch: 6| Step: 10
Training loss: 1.0079810619354248
Validation loss: 2.138423737659249

Epoch: 6| Step: 11
Training loss: 1.2290568351745605
Validation loss: 2.1406940849878455

Epoch: 6| Step: 12
Training loss: 0.7801353931427002
Validation loss: 2.1456095531422603

Epoch: 6| Step: 13
Training loss: 1.1649516820907593
Validation loss: 2.1410661640987603

Epoch: 267| Step: 0
Training loss: 0.7498504519462585
Validation loss: 2.0960107400853145

Epoch: 6| Step: 1
Training loss: 1.3350777626037598
Validation loss: 2.057916348980319

Epoch: 6| Step: 2
Training loss: 0.9969077706336975
Validation loss: 2.0574808915456138

Epoch: 6| Step: 3
Training loss: 1.540123462677002
Validation loss: 2.0791691798035816

Epoch: 6| Step: 4
Training loss: 1.2280633449554443
Validation loss: 2.092343307310535

Epoch: 6| Step: 5
Training loss: 1.2805143594741821
Validation loss: 2.1250891377848964

Epoch: 6| Step: 6
Training loss: 1.513809084892273
Validation loss: 2.154101365356035

Epoch: 6| Step: 7
Training loss: 1.5030028820037842
Validation loss: 2.1716626459552395

Epoch: 6| Step: 8
Training loss: 1.774659276008606
Validation loss: 2.155172259576859

Epoch: 6| Step: 9
Training loss: 1.1451157331466675
Validation loss: 2.20990151487371

Epoch: 6| Step: 10
Training loss: 1.2342705726623535
Validation loss: 2.1811396844925417

Epoch: 6| Step: 11
Training loss: 1.520696997642517
Validation loss: 2.1637254376565256

Epoch: 6| Step: 12
Training loss: 0.9709064960479736
Validation loss: 2.141403723788518

Epoch: 6| Step: 13
Training loss: 0.836794912815094
Validation loss: 2.0949177126730643

Epoch: 268| Step: 0
Training loss: 1.4041390419006348
Validation loss: 2.097410264835563

Epoch: 6| Step: 1
Training loss: 1.3503016233444214
Validation loss: 2.0995036607147544

Epoch: 6| Step: 2
Training loss: 1.6624947786331177
Validation loss: 2.1030784524897093

Epoch: 6| Step: 3
Training loss: 0.9860365986824036
Validation loss: 2.1197988551150084

Epoch: 6| Step: 4
Training loss: 0.9453061819076538
Validation loss: 2.0715294884097193

Epoch: 6| Step: 5
Training loss: 1.6779866218566895
Validation loss: 2.0911541267107894

Epoch: 6| Step: 6
Training loss: 1.7632747888565063
Validation loss: 2.083802979479554

Epoch: 6| Step: 7
Training loss: 1.3293662071228027
Validation loss: 2.0792902861872027

Epoch: 6| Step: 8
Training loss: 1.4021092653274536
Validation loss: 2.1101047813251452

Epoch: 6| Step: 9
Training loss: 1.066899299621582
Validation loss: 2.079677460014179

Epoch: 6| Step: 10
Training loss: 1.2236213684082031
Validation loss: 2.1375177188586165

Epoch: 6| Step: 11
Training loss: 0.7593488693237305
Validation loss: 2.1564177415704213

Epoch: 6| Step: 12
Training loss: 0.9179657101631165
Validation loss: 2.153601792550856

Epoch: 6| Step: 13
Training loss: 1.1299493312835693
Validation loss: 2.100240156214724

Epoch: 269| Step: 0
Training loss: 1.2105908393859863
Validation loss: 2.099633191221504

Epoch: 6| Step: 1
Training loss: 1.946930170059204
Validation loss: 2.0842582615472938

Epoch: 6| Step: 2
Training loss: 1.0226460695266724
Validation loss: 2.081682171872867

Epoch: 6| Step: 3
Training loss: 1.5053596496582031
Validation loss: 2.1153561017846547

Epoch: 6| Step: 4
Training loss: 1.2995983362197876
Validation loss: 2.088002784277803

Epoch: 6| Step: 5
Training loss: 1.722396969795227
Validation loss: 2.1135770761838524

Epoch: 6| Step: 6
Training loss: 0.8534209728240967
Validation loss: 2.112500995718023

Epoch: 6| Step: 7
Training loss: 0.7693259716033936
Validation loss: 2.041310418036676

Epoch: 6| Step: 8
Training loss: 1.2741140127182007
Validation loss: 1.9990732490375478

Epoch: 6| Step: 9
Training loss: 1.4783648252487183
Validation loss: 2.0277491743846605

Epoch: 6| Step: 10
Training loss: 1.3005239963531494
Validation loss: 2.0420844324173464

Epoch: 6| Step: 11
Training loss: 1.1887969970703125
Validation loss: 2.063760454936694

Epoch: 6| Step: 12
Training loss: 1.0466053485870361
Validation loss: 2.108279860147866

Epoch: 6| Step: 13
Training loss: 1.5234371423721313
Validation loss: 2.1330896641618464

Epoch: 270| Step: 0
Training loss: 0.9011831879615784
Validation loss: 2.138211777133326

Epoch: 6| Step: 1
Training loss: 0.9672415852546692
Validation loss: 2.1365346870114728

Epoch: 6| Step: 2
Training loss: 1.2586307525634766
Validation loss: 2.1552237515808432

Epoch: 6| Step: 3
Training loss: 1.179324746131897
Validation loss: 2.1940131661712483

Epoch: 6| Step: 4
Training loss: 1.7184133529663086
Validation loss: 2.1220967333803893

Epoch: 6| Step: 5
Training loss: 1.5488393306732178
Validation loss: 2.132468710663498

Epoch: 6| Step: 6
Training loss: 1.2174047231674194
Validation loss: 2.031926001271894

Epoch: 6| Step: 7
Training loss: 1.533656120300293
Validation loss: 2.016452702142859

Epoch: 6| Step: 8
Training loss: 1.464615821838379
Validation loss: 1.9680995915525703

Epoch: 6| Step: 9
Training loss: 1.238086223602295
Validation loss: 2.0053932718051377

Epoch: 6| Step: 10
Training loss: 1.4681743383407593
Validation loss: 1.9886189340263285

Epoch: 6| Step: 11
Training loss: 1.4572057723999023
Validation loss: 1.9936969933971282

Epoch: 6| Step: 12
Training loss: 1.4728761911392212
Validation loss: 2.0078073470823226

Epoch: 6| Step: 13
Training loss: 0.5216538906097412
Validation loss: 2.0374726608235347

Epoch: 271| Step: 0
Training loss: 1.179945945739746
Validation loss: 2.0842613135614703

Epoch: 6| Step: 1
Training loss: 1.3626705408096313
Validation loss: 2.1800325609022573

Epoch: 6| Step: 2
Training loss: 1.46974778175354
Validation loss: 2.203579769339613

Epoch: 6| Step: 3
Training loss: 1.1617308855056763
Validation loss: 2.2501331375491236

Epoch: 6| Step: 4
Training loss: 1.0551364421844482
Validation loss: 2.214195739838385

Epoch: 6| Step: 5
Training loss: 1.274008870124817
Validation loss: 2.1913894709720405

Epoch: 6| Step: 6
Training loss: 1.1052780151367188
Validation loss: 2.160076742531151

Epoch: 6| Step: 7
Training loss: 1.7033629417419434
Validation loss: 2.1618574024528585

Epoch: 6| Step: 8
Training loss: 0.6994574069976807
Validation loss: 2.1218715534415296

Epoch: 6| Step: 9
Training loss: 0.7916449308395386
Validation loss: 2.085426712548861

Epoch: 6| Step: 10
Training loss: 1.638636589050293
Validation loss: 2.098534212317518

Epoch: 6| Step: 11
Training loss: 1.2818559408187866
Validation loss: 2.108715440637322

Epoch: 6| Step: 12
Training loss: 1.943694829940796
Validation loss: 2.099610859347928

Epoch: 6| Step: 13
Training loss: 0.9844725131988525
Validation loss: 2.1092742873776342

Epoch: 272| Step: 0
Training loss: 1.6553924083709717
Validation loss: 2.108506029652011

Epoch: 6| Step: 1
Training loss: 1.560001015663147
Validation loss: 2.1530033952446392

Epoch: 6| Step: 2
Training loss: 1.8038716316223145
Validation loss: 2.1636309392990603

Epoch: 6| Step: 3
Training loss: 0.8675450682640076
Validation loss: 2.150562991378128

Epoch: 6| Step: 4
Training loss: 0.9433325529098511
Validation loss: 2.1468062939182406

Epoch: 6| Step: 5
Training loss: 0.7255091071128845
Validation loss: 2.100006377825173

Epoch: 6| Step: 6
Training loss: 1.4400155544281006
Validation loss: 2.0963156031024073

Epoch: 6| Step: 7
Training loss: 1.2419147491455078
Validation loss: 2.0746462755305792

Epoch: 6| Step: 8
Training loss: 1.236729383468628
Validation loss: 2.066396887584399

Epoch: 6| Step: 9
Training loss: 1.5537331104278564
Validation loss: 2.0788849489663237

Epoch: 6| Step: 10
Training loss: 1.3353214263916016
Validation loss: 2.0838369195179274

Epoch: 6| Step: 11
Training loss: 0.940047562122345
Validation loss: 2.078859131823304

Epoch: 6| Step: 12
Training loss: 1.1079399585723877
Validation loss: 2.0741564945508073

Epoch: 6| Step: 13
Training loss: 0.7446102499961853
Validation loss: 2.1166423520734234

Epoch: 273| Step: 0
Training loss: 1.5076615810394287
Validation loss: 2.155133847267397

Epoch: 6| Step: 1
Training loss: 1.3691413402557373
Validation loss: 2.186173790244646

Epoch: 6| Step: 2
Training loss: 1.4392207860946655
Validation loss: 2.1847133764656643

Epoch: 6| Step: 3
Training loss: 1.453479528427124
Validation loss: 2.1718367145907496

Epoch: 6| Step: 4
Training loss: 0.8367820978164673
Validation loss: 2.178868139943769

Epoch: 6| Step: 5
Training loss: 1.3276398181915283
Validation loss: 2.1721600101840113

Epoch: 6| Step: 6
Training loss: 1.3951637744903564
Validation loss: 2.151113315295148

Epoch: 6| Step: 7
Training loss: 1.2706341743469238
Validation loss: 2.153826959671513

Epoch: 6| Step: 8
Training loss: 1.3449785709381104
Validation loss: 2.1242986622677056

Epoch: 6| Step: 9
Training loss: 1.4606096744537354
Validation loss: 2.065203025776853

Epoch: 6| Step: 10
Training loss: 0.7563351392745972
Validation loss: 2.025140316255631

Epoch: 6| Step: 11
Training loss: 1.131561517715454
Validation loss: 2.01805539284983

Epoch: 6| Step: 12
Training loss: 1.1458525657653809
Validation loss: 1.9998209681562198

Epoch: 6| Step: 13
Training loss: 1.2063473463058472
Validation loss: 2.001934894951441

Epoch: 274| Step: 0
Training loss: 0.8327091932296753
Validation loss: 1.977787043458672

Epoch: 6| Step: 1
Training loss: 1.4091219902038574
Validation loss: 2.0325895509412213

Epoch: 6| Step: 2
Training loss: 1.4905365705490112
Validation loss: 2.055104148003363

Epoch: 6| Step: 3
Training loss: 1.4165219068527222
Validation loss: 2.078952953379641

Epoch: 6| Step: 4
Training loss: 1.1466667652130127
Validation loss: 2.1511950210858415

Epoch: 6| Step: 5
Training loss: 1.2859742641448975
Validation loss: 2.1172557389864357

Epoch: 6| Step: 6
Training loss: 1.2956068515777588
Validation loss: 2.1254936238770843

Epoch: 6| Step: 7
Training loss: 1.395021677017212
Validation loss: 2.1296078248690535

Epoch: 6| Step: 8
Training loss: 0.7534424662590027
Validation loss: 2.139929800905207

Epoch: 6| Step: 9
Training loss: 1.1855683326721191
Validation loss: 2.128335763049382

Epoch: 6| Step: 10
Training loss: 0.9478701949119568
Validation loss: 2.1037324936159196

Epoch: 6| Step: 11
Training loss: 2.136537551879883
Validation loss: 2.0828400222204064

Epoch: 6| Step: 12
Training loss: 0.8243356943130493
Validation loss: 2.0747950102693293

Epoch: 6| Step: 13
Training loss: 0.7735129594802856
Validation loss: 2.0913002414088093

Epoch: 275| Step: 0
Training loss: 1.2485816478729248
Validation loss: 2.0922586148785007

Epoch: 6| Step: 1
Training loss: 0.7889757752418518
Validation loss: 2.138959491124717

Epoch: 6| Step: 2
Training loss: 1.0480819940567017
Validation loss: 2.1457621846147763

Epoch: 6| Step: 3
Training loss: 1.1122174263000488
Validation loss: 2.1179606504337762

Epoch: 6| Step: 4
Training loss: 1.4421844482421875
Validation loss: 2.1352089053841046

Epoch: 6| Step: 5
Training loss: 1.3726937770843506
Validation loss: 2.112004356999551

Epoch: 6| Step: 6
Training loss: 1.518937349319458
Validation loss: 2.096356379088535

Epoch: 6| Step: 7
Training loss: 0.6674661636352539
Validation loss: 2.0653434504744825

Epoch: 6| Step: 8
Training loss: 1.8333771228790283
Validation loss: 2.0691758560877975

Epoch: 6| Step: 9
Training loss: 1.3721961975097656
Validation loss: 2.025507688522339

Epoch: 6| Step: 10
Training loss: 0.6998180150985718
Validation loss: 2.0098363481542116

Epoch: 6| Step: 11
Training loss: 2.060084342956543
Validation loss: 2.0040728994595107

Epoch: 6| Step: 12
Training loss: 0.6742846369743347
Validation loss: 2.007264170595395

Epoch: 6| Step: 13
Training loss: 1.1212252378463745
Validation loss: 1.9645694173792356

Epoch: 276| Step: 0
Training loss: 1.1057432889938354
Validation loss: 2.00883363908337

Epoch: 6| Step: 1
Training loss: 1.0589735507965088
Validation loss: 2.0295173378400904

Epoch: 6| Step: 2
Training loss: 1.141603946685791
Validation loss: 2.0640487593989216

Epoch: 6| Step: 3
Training loss: 1.2221729755401611
Validation loss: 2.1127215636673795

Epoch: 6| Step: 4
Training loss: 1.5271426439285278
Validation loss: 2.160518071984732

Epoch: 6| Step: 5
Training loss: 1.2110869884490967
Validation loss: 2.1575236884496545

Epoch: 6| Step: 6
Training loss: 1.2631299495697021
Validation loss: 2.114444234037912

Epoch: 6| Step: 7
Training loss: 1.5772866010665894
Validation loss: 2.112736407146659

Epoch: 6| Step: 8
Training loss: 1.338358759880066
Validation loss: 2.0987957203260033

Epoch: 6| Step: 9
Training loss: 1.5591018199920654
Validation loss: 2.1176427718131774

Epoch: 6| Step: 10
Training loss: 1.0880767107009888
Validation loss: 2.0728155092526506

Epoch: 6| Step: 11
Training loss: 0.8132860660552979
Validation loss: 2.047532009822066

Epoch: 6| Step: 12
Training loss: 0.9818378686904907
Validation loss: 2.0240378213185135

Epoch: 6| Step: 13
Training loss: 1.5113797187805176
Validation loss: 1.9947729931082776

Epoch: 277| Step: 0
Training loss: 1.2044832706451416
Validation loss: 1.9855621245599562

Epoch: 6| Step: 1
Training loss: 1.1652277708053589
Validation loss: 1.9913956554987098

Epoch: 6| Step: 2
Training loss: 1.3716535568237305
Validation loss: 2.0205861804305867

Epoch: 6| Step: 3
Training loss: 0.7364356517791748
Validation loss: 2.0285525475778887

Epoch: 6| Step: 4
Training loss: 1.1499879360198975
Validation loss: 2.043315622114366

Epoch: 6| Step: 5
Training loss: 1.2965419292449951
Validation loss: 2.054163258562806

Epoch: 6| Step: 6
Training loss: 1.4846861362457275
Validation loss: 2.056220867300546

Epoch: 6| Step: 7
Training loss: 1.2903048992156982
Validation loss: 2.1033214394764235

Epoch: 6| Step: 8
Training loss: 1.1851699352264404
Validation loss: 2.1040949924017793

Epoch: 6| Step: 9
Training loss: 0.8773497939109802
Validation loss: 2.112669637126307

Epoch: 6| Step: 10
Training loss: 1.9341659545898438
Validation loss: 2.1000295851820256

Epoch: 6| Step: 11
Training loss: 1.4062882661819458
Validation loss: 2.103696048900645

Epoch: 6| Step: 12
Training loss: 0.7834594249725342
Validation loss: 2.103418131028452

Epoch: 6| Step: 13
Training loss: 0.8425588607788086
Validation loss: 2.0855798785404494

Epoch: 278| Step: 0
Training loss: 0.6957741975784302
Validation loss: 2.0833839934359313

Epoch: 6| Step: 1
Training loss: 1.544822335243225
Validation loss: 2.1269646408737346

Epoch: 6| Step: 2
Training loss: 1.4444186687469482
Validation loss: 2.096011802714358

Epoch: 6| Step: 3
Training loss: 1.5055643320083618
Validation loss: 2.0984007722587994

Epoch: 6| Step: 4
Training loss: 1.1356585025787354
Validation loss: 2.1320441563924155

Epoch: 6| Step: 5
Training loss: 1.07582426071167
Validation loss: 2.1153006681831936

Epoch: 6| Step: 6
Training loss: 0.8985984921455383
Validation loss: 2.1120209386271815

Epoch: 6| Step: 7
Training loss: 1.3555378913879395
Validation loss: 2.1314707058732227

Epoch: 6| Step: 8
Training loss: 0.9706088304519653
Validation loss: 2.1179783728814896

Epoch: 6| Step: 9
Training loss: 1.2042876482009888
Validation loss: 2.0665775370854202

Epoch: 6| Step: 10
Training loss: 1.2780265808105469
Validation loss: 2.069563309351603

Epoch: 6| Step: 11
Training loss: 1.3634840250015259
Validation loss: 2.0942372506664646

Epoch: 6| Step: 12
Training loss: 1.0572742223739624
Validation loss: 2.0594881170539447

Epoch: 6| Step: 13
Training loss: 1.242193579673767
Validation loss: 2.1196799867896625

Epoch: 279| Step: 0
Training loss: 1.3377892971038818
Validation loss: 2.0895918953803276

Epoch: 6| Step: 1
Training loss: 1.4653294086456299
Validation loss: 2.136279757304858

Epoch: 6| Step: 2
Training loss: 0.9309756755828857
Validation loss: 2.1165324923812703

Epoch: 6| Step: 3
Training loss: 1.388451337814331
Validation loss: 2.090315495767901

Epoch: 6| Step: 4
Training loss: 1.3426038026809692
Validation loss: 2.063221426420314

Epoch: 6| Step: 5
Training loss: 1.0174092054367065
Validation loss: 2.0709489737787554

Epoch: 6| Step: 6
Training loss: 0.6785097122192383
Validation loss: 2.0520015647334438

Epoch: 6| Step: 7
Training loss: 1.406604290008545
Validation loss: 2.0847964825168734

Epoch: 6| Step: 8
Training loss: 0.8264256119728088
Validation loss: 2.099095457343645

Epoch: 6| Step: 9
Training loss: 1.1152753829956055
Validation loss: 2.0612715572439213

Epoch: 6| Step: 10
Training loss: 1.326816201210022
Validation loss: 2.05250725694882

Epoch: 6| Step: 11
Training loss: 0.9894613027572632
Validation loss: 2.0784944475338025

Epoch: 6| Step: 12
Training loss: 1.2129915952682495
Validation loss: 2.0751958431736117

Epoch: 6| Step: 13
Training loss: 2.0704619884490967
Validation loss: 2.1407998966914352

Epoch: 280| Step: 0
Training loss: 1.3895057439804077
Validation loss: 2.148312228982167

Epoch: 6| Step: 1
Training loss: 2.0092356204986572
Validation loss: 2.193254292652171

Epoch: 6| Step: 2
Training loss: 0.7301087379455566
Validation loss: 2.198260291930168

Epoch: 6| Step: 3
Training loss: 0.8324106931686401
Validation loss: 2.175458977299352

Epoch: 6| Step: 4
Training loss: 1.159300446510315
Validation loss: 2.1463004901844966

Epoch: 6| Step: 5
Training loss: 1.565016746520996
Validation loss: 2.1024274710685975

Epoch: 6| Step: 6
Training loss: 1.09818696975708
Validation loss: 2.0771881265024983

Epoch: 6| Step: 7
Training loss: 0.9458780884742737
Validation loss: 2.011085228253436

Epoch: 6| Step: 8
Training loss: 1.8332409858703613
Validation loss: 2.0387956301371255

Epoch: 6| Step: 9
Training loss: 0.6730291843414307
Validation loss: 2.012427160816808

Epoch: 6| Step: 10
Training loss: 1.4356091022491455
Validation loss: 1.9993896894557501

Epoch: 6| Step: 11
Training loss: 1.1034249067306519
Validation loss: 2.0379781620476836

Epoch: 6| Step: 12
Training loss: 1.4338593482971191
Validation loss: 2.042457583130047

Epoch: 6| Step: 13
Training loss: 0.5249694585800171
Validation loss: 2.0744797439985376

Epoch: 281| Step: 0
Training loss: 0.9491492509841919
Validation loss: 2.1146642290135866

Epoch: 6| Step: 1
Training loss: 1.6732584238052368
Validation loss: 2.1168074941122406

Epoch: 6| Step: 2
Training loss: 1.01337730884552
Validation loss: 2.0960600504311184

Epoch: 6| Step: 3
Training loss: 2.052833080291748
Validation loss: 2.112353353090184

Epoch: 6| Step: 4
Training loss: 0.9019545912742615
Validation loss: 2.1384412947521416

Epoch: 6| Step: 5
Training loss: 0.7496356964111328
Validation loss: 2.108712960315007

Epoch: 6| Step: 6
Training loss: 0.5821667909622192
Validation loss: 2.1081163742208995

Epoch: 6| Step: 7
Training loss: 1.2432193756103516
Validation loss: 2.1159159009174635

Epoch: 6| Step: 8
Training loss: 1.0852322578430176
Validation loss: 2.1175761658658265

Epoch: 6| Step: 9
Training loss: 1.1623010635375977
Validation loss: 2.075054666047455

Epoch: 6| Step: 10
Training loss: 1.3276584148406982
Validation loss: 2.0947520476515575

Epoch: 6| Step: 11
Training loss: 0.7969080209732056
Validation loss: 2.1112315680391047

Epoch: 6| Step: 12
Training loss: 1.7030969858169556
Validation loss: 2.0566999194442586

Epoch: 6| Step: 13
Training loss: 1.199304461479187
Validation loss: 2.041586414460213

Epoch: 282| Step: 0
Training loss: 1.4324822425842285
Validation loss: 2.0084403355916343

Epoch: 6| Step: 1
Training loss: 1.060578465461731
Validation loss: 2.0188010046558995

Epoch: 6| Step: 2
Training loss: 1.8676137924194336
Validation loss: 2.0081481190137964

Epoch: 6| Step: 3
Training loss: 1.5260354280471802
Validation loss: 2.023323848683347

Epoch: 6| Step: 4
Training loss: 0.9937530755996704
Validation loss: 2.0360857338033695

Epoch: 6| Step: 5
Training loss: 1.5284284353256226
Validation loss: 2.051012060975516

Epoch: 6| Step: 6
Training loss: 1.6266322135925293
Validation loss: 2.0560564892266386

Epoch: 6| Step: 7
Training loss: 0.564120888710022
Validation loss: 2.0805897174342984

Epoch: 6| Step: 8
Training loss: 0.7660775184631348
Validation loss: 2.0885950083373697

Epoch: 6| Step: 9
Training loss: 0.8204740285873413
Validation loss: 2.103182356844666

Epoch: 6| Step: 10
Training loss: 1.0279749631881714
Validation loss: 2.1031259529052244

Epoch: 6| Step: 11
Training loss: 1.141723394393921
Validation loss: 2.08364523354397

Epoch: 6| Step: 12
Training loss: 0.8810468912124634
Validation loss: 2.0319113718566073

Epoch: 6| Step: 13
Training loss: 1.037067174911499
Validation loss: 2.030796918817746

Epoch: 283| Step: 0
Training loss: 1.216406226158142
Validation loss: 1.9954314347236388

Epoch: 6| Step: 1
Training loss: 1.3112566471099854
Validation loss: 2.0071721807602914

Epoch: 6| Step: 2
Training loss: 1.1169931888580322
Validation loss: 2.009996335993531

Epoch: 6| Step: 3
Training loss: 1.177483081817627
Validation loss: 2.0131205525449527

Epoch: 6| Step: 4
Training loss: 1.6109387874603271
Validation loss: 2.0253644374109085

Epoch: 6| Step: 5
Training loss: 1.368005633354187
Validation loss: 2.044571127942813

Epoch: 6| Step: 6
Training loss: 1.2869296073913574
Validation loss: 2.0633997994084514

Epoch: 6| Step: 7
Training loss: 1.143789529800415
Validation loss: 2.0652864876613823

Epoch: 6| Step: 8
Training loss: 0.7103625535964966
Validation loss: 2.0633847841652493

Epoch: 6| Step: 9
Training loss: 1.1712265014648438
Validation loss: 2.0520544295669882

Epoch: 6| Step: 10
Training loss: 1.045222282409668
Validation loss: 2.017018202812441

Epoch: 6| Step: 11
Training loss: 1.141597032546997
Validation loss: 1.9953793184731596

Epoch: 6| Step: 12
Training loss: 0.9114874601364136
Validation loss: 1.9740829544682656

Epoch: 6| Step: 13
Training loss: 0.8951214551925659
Validation loss: 1.9525933470777286

Epoch: 284| Step: 0
Training loss: 1.5030760765075684
Validation loss: 1.9843193074708343

Epoch: 6| Step: 1
Training loss: 1.0986618995666504
Validation loss: 1.9591421645174745

Epoch: 6| Step: 2
Training loss: 0.8333505392074585
Validation loss: 2.0188227520194104

Epoch: 6| Step: 3
Training loss: 0.9203807711601257
Validation loss: 2.0134546987472044

Epoch: 6| Step: 4
Training loss: 1.1880221366882324
Validation loss: 2.079579378968926

Epoch: 6| Step: 5
Training loss: 1.712127923965454
Validation loss: 2.1464064864702124

Epoch: 6| Step: 6
Training loss: 1.1332043409347534
Validation loss: 2.1241679806863107

Epoch: 6| Step: 7
Training loss: 0.5898694396018982
Validation loss: 2.107723803930385

Epoch: 6| Step: 8
Training loss: 1.528944969177246
Validation loss: 2.1261822651791316

Epoch: 6| Step: 9
Training loss: 1.342561960220337
Validation loss: 2.0810870778176094

Epoch: 6| Step: 10
Training loss: 1.3085496425628662
Validation loss: 2.0364397289932414

Epoch: 6| Step: 11
Training loss: 0.9674932360649109
Validation loss: 2.0431901075506724

Epoch: 6| Step: 12
Training loss: 1.3549308776855469
Validation loss: 2.01363347166328

Epoch: 6| Step: 13
Training loss: 1.1010957956314087
Validation loss: 1.9937620650055587

Epoch: 285| Step: 0
Training loss: 1.3516236543655396
Validation loss: 1.9978531816954255

Epoch: 6| Step: 1
Training loss: 0.5930821895599365
Validation loss: 2.0050261982025637

Epoch: 6| Step: 2
Training loss: 1.5391483306884766
Validation loss: 2.006173400468724

Epoch: 6| Step: 3
Training loss: 1.637662410736084
Validation loss: 2.0450704597657725

Epoch: 6| Step: 4
Training loss: 0.5937103629112244
Validation loss: 2.042100921753914

Epoch: 6| Step: 5
Training loss: 1.2083981037139893
Validation loss: 2.0775268180395967

Epoch: 6| Step: 6
Training loss: 1.1269049644470215
Validation loss: 2.0981361225087154

Epoch: 6| Step: 7
Training loss: 1.2489012479782104
Validation loss: 2.1174652191900436

Epoch: 6| Step: 8
Training loss: 0.96796715259552
Validation loss: 2.153102531228014

Epoch: 6| Step: 9
Training loss: 0.9970898628234863
Validation loss: 2.1375273658383276

Epoch: 6| Step: 10
Training loss: 0.9272905588150024
Validation loss: 2.139324875288112

Epoch: 6| Step: 11
Training loss: 1.3735532760620117
Validation loss: 2.1243031755570443

Epoch: 6| Step: 12
Training loss: 1.936758279800415
Validation loss: 2.0969612470237156

Epoch: 6| Step: 13
Training loss: 0.7270839214324951
Validation loss: 2.0824056645875335

Epoch: 286| Step: 0
Training loss: 1.0304641723632812
Validation loss: 2.0570852756500244

Epoch: 6| Step: 1
Training loss: 1.4184458255767822
Validation loss: 2.0493766082230436

Epoch: 6| Step: 2
Training loss: 0.8154412508010864
Validation loss: 2.060045273073258

Epoch: 6| Step: 3
Training loss: 0.9651743173599243
Validation loss: 2.054746468861898

Epoch: 6| Step: 4
Training loss: 1.0920579433441162
Validation loss: 2.0816124139293546

Epoch: 6| Step: 5
Training loss: 1.0376200675964355
Validation loss: 2.0669413894735356

Epoch: 6| Step: 6
Training loss: 1.0327295064926147
Validation loss: 2.0544478995825655

Epoch: 6| Step: 7
Training loss: 0.9770093560218811
Validation loss: 2.0286696521184777

Epoch: 6| Step: 8
Training loss: 1.259734869003296
Validation loss: 2.043087626016268

Epoch: 6| Step: 9
Training loss: 1.219186544418335
Validation loss: 2.066808592888617

Epoch: 6| Step: 10
Training loss: 1.17830491065979
Validation loss: 2.047671265499566

Epoch: 6| Step: 11
Training loss: 1.0282437801361084
Validation loss: 2.073394254971576

Epoch: 6| Step: 12
Training loss: 1.3671150207519531
Validation loss: 2.0654147850569857

Epoch: 6| Step: 13
Training loss: 1.5709697008132935
Validation loss: 2.0845894839174006

Epoch: 287| Step: 0
Training loss: 1.2085764408111572
Validation loss: 2.1304641218595606

Epoch: 6| Step: 1
Training loss: 0.919799268245697
Validation loss: 2.1733321297553276

Epoch: 6| Step: 2
Training loss: 0.9920448064804077
Validation loss: 2.126930150934445

Epoch: 6| Step: 3
Training loss: 1.6181259155273438
Validation loss: 2.0842511538536317

Epoch: 6| Step: 4
Training loss: 1.216348648071289
Validation loss: 2.0791820800432594

Epoch: 6| Step: 5
Training loss: 1.1459157466888428
Validation loss: 2.0684153623478387

Epoch: 6| Step: 6
Training loss: 0.8351131677627563
Validation loss: 2.032785306694687

Epoch: 6| Step: 7
Training loss: 1.5062007904052734
Validation loss: 2.038576924672691

Epoch: 6| Step: 8
Training loss: 1.638126254081726
Validation loss: 1.9875806505962084

Epoch: 6| Step: 9
Training loss: 0.9349628686904907
Validation loss: 1.995798687781057

Epoch: 6| Step: 10
Training loss: 1.1613733768463135
Validation loss: 1.9813929898764497

Epoch: 6| Step: 11
Training loss: 0.5679430365562439
Validation loss: 2.0066560852912163

Epoch: 6| Step: 12
Training loss: 1.1195178031921387
Validation loss: 2.0200973890161

Epoch: 6| Step: 13
Training loss: 1.2325092554092407
Validation loss: 2.0206252092956216

Epoch: 288| Step: 0
Training loss: 0.7545983791351318
Validation loss: 2.055788693889495

Epoch: 6| Step: 1
Training loss: 0.9729716777801514
Validation loss: 2.0636686855746853

Epoch: 6| Step: 2
Training loss: 1.2286722660064697
Validation loss: 2.094305525543869

Epoch: 6| Step: 3
Training loss: 1.124232530593872
Validation loss: 2.064201020425366

Epoch: 6| Step: 4
Training loss: 1.6842732429504395
Validation loss: 2.085210620716054

Epoch: 6| Step: 5
Training loss: 1.194243311882019
Validation loss: 2.054194426023832

Epoch: 6| Step: 6
Training loss: 1.384949803352356
Validation loss: 2.0610874070916125

Epoch: 6| Step: 7
Training loss: 0.9835798740386963
Validation loss: 2.0535959453992945

Epoch: 6| Step: 8
Training loss: 0.9391515254974365
Validation loss: 2.051635247404857

Epoch: 6| Step: 9
Training loss: 1.0886614322662354
Validation loss: 2.044447486118604

Epoch: 6| Step: 10
Training loss: 1.0277202129364014
Validation loss: 1.9729030721931047

Epoch: 6| Step: 11
Training loss: 1.0762739181518555
Validation loss: 2.006588534642291

Epoch: 6| Step: 12
Training loss: 1.0907530784606934
Validation loss: 1.984972635904948

Epoch: 6| Step: 13
Training loss: 1.3491429090499878
Validation loss: 1.9974606498595207

Epoch: 289| Step: 0
Training loss: 1.0664002895355225
Validation loss: 2.035977550732192

Epoch: 6| Step: 1
Training loss: 1.0605881214141846
Validation loss: 2.0810039812518704

Epoch: 6| Step: 2
Training loss: 1.759023904800415
Validation loss: 2.121614756122712

Epoch: 6| Step: 3
Training loss: 0.8483926057815552
Validation loss: 2.1603595441387546

Epoch: 6| Step: 4
Training loss: 0.8044660091400146
Validation loss: 2.1382389863332114

Epoch: 6| Step: 5
Training loss: 1.8111560344696045
Validation loss: 2.1348600028663554

Epoch: 6| Step: 6
Training loss: 1.0878249406814575
Validation loss: 2.1128860365959907

Epoch: 6| Step: 7
Training loss: 1.147680401802063
Validation loss: 2.117130333377469

Epoch: 6| Step: 8
Training loss: 1.2015035152435303
Validation loss: 2.040858266174152

Epoch: 6| Step: 9
Training loss: 1.1268759965896606
Validation loss: 2.0149266796727336

Epoch: 6| Step: 10
Training loss: 0.8922504782676697
Validation loss: 1.9960445537362048

Epoch: 6| Step: 11
Training loss: 1.1283681392669678
Validation loss: 2.0051297756933395

Epoch: 6| Step: 12
Training loss: 0.8159492015838623
Validation loss: 2.0097709727543656

Epoch: 6| Step: 13
Training loss: 1.0743505954742432
Validation loss: 1.976341506486298

Epoch: 290| Step: 0
Training loss: 0.7751545906066895
Validation loss: 2.001691687491632

Epoch: 6| Step: 1
Training loss: 0.8578760027885437
Validation loss: 2.041660084519335

Epoch: 6| Step: 2
Training loss: 1.333359956741333
Validation loss: 2.0440036019971295

Epoch: 6| Step: 3
Training loss: 0.8739215135574341
Validation loss: 2.066091740003196

Epoch: 6| Step: 4
Training loss: 1.339979648590088
Validation loss: 2.078328106992988

Epoch: 6| Step: 5
Training loss: 0.988989531993866
Validation loss: 2.060944959681521

Epoch: 6| Step: 6
Training loss: 1.2737846374511719
Validation loss: 2.0774176864213842

Epoch: 6| Step: 7
Training loss: 0.896405041217804
Validation loss: 2.048472732625982

Epoch: 6| Step: 8
Training loss: 0.992117166519165
Validation loss: 2.024049053909958

Epoch: 6| Step: 9
Training loss: 1.2875664234161377
Validation loss: 2.0423321647028767

Epoch: 6| Step: 10
Training loss: 1.2199589014053345
Validation loss: 2.0218695312417965

Epoch: 6| Step: 11
Training loss: 0.9957471489906311
Validation loss: 2.0608863907475627

Epoch: 6| Step: 12
Training loss: 1.4856946468353271
Validation loss: 2.0141378371946272

Epoch: 6| Step: 13
Training loss: 1.3050799369812012
Validation loss: 2.0521605937711653

Epoch: 291| Step: 0
Training loss: 1.0356308221817017
Validation loss: 2.0374404076606996

Epoch: 6| Step: 1
Training loss: 1.1196095943450928
Validation loss: 2.0403210757881083

Epoch: 6| Step: 2
Training loss: 1.3964760303497314
Validation loss: 2.03735787125044

Epoch: 6| Step: 3
Training loss: 1.0872023105621338
Validation loss: 2.076194191491732

Epoch: 6| Step: 4
Training loss: 0.7303066253662109
Validation loss: 2.0487174910883748

Epoch: 6| Step: 5
Training loss: 1.2935054302215576
Validation loss: 2.0884112132492887

Epoch: 6| Step: 6
Training loss: 0.8861039876937866
Validation loss: 2.0719221791913434

Epoch: 6| Step: 7
Training loss: 1.7210710048675537
Validation loss: 2.059485593149739

Epoch: 6| Step: 8
Training loss: 1.1990375518798828
Validation loss: 2.0894248126655497

Epoch: 6| Step: 9
Training loss: 1.0803534984588623
Validation loss: 2.0934448549824376

Epoch: 6| Step: 10
Training loss: 0.9331798553466797
Validation loss: 2.070012874500726

Epoch: 6| Step: 11
Training loss: 1.2725979089736938
Validation loss: 2.0637921671713553

Epoch: 6| Step: 12
Training loss: 1.2158383131027222
Validation loss: 2.062408199874304

Epoch: 6| Step: 13
Training loss: 0.3979722559452057
Validation loss: 2.0035151230391635

Epoch: 292| Step: 0
Training loss: 1.2073720693588257
Validation loss: 2.031995193932646

Epoch: 6| Step: 1
Training loss: 1.2469357252120972
Validation loss: 2.0316872007103375

Epoch: 6| Step: 2
Training loss: 1.6545915603637695
Validation loss: 2.0532156344382995

Epoch: 6| Step: 3
Training loss: 0.8011908531188965
Validation loss: 2.0598043087990052

Epoch: 6| Step: 4
Training loss: 1.1834018230438232
Validation loss: 2.0806389931709535

Epoch: 6| Step: 5
Training loss: 0.9693054556846619
Validation loss: 2.1131517912751887

Epoch: 6| Step: 6
Training loss: 1.1835347414016724
Validation loss: 2.112965340255409

Epoch: 6| Step: 7
Training loss: 1.0518929958343506
Validation loss: 2.130329739662909

Epoch: 6| Step: 8
Training loss: 1.1725680828094482
Validation loss: 2.0911654913297264

Epoch: 6| Step: 9
Training loss: 0.8794698715209961
Validation loss: 2.0704370737075806

Epoch: 6| Step: 10
Training loss: 0.8892956972122192
Validation loss: 2.0909734592642835

Epoch: 6| Step: 11
Training loss: 1.1661949157714844
Validation loss: 2.105276534634252

Epoch: 6| Step: 12
Training loss: 0.8545563220977783
Validation loss: 2.071128535014327

Epoch: 6| Step: 13
Training loss: 1.4861401319503784
Validation loss: 2.0704440557828514

Epoch: 293| Step: 0
Training loss: 0.9180680513381958
Validation loss: 2.0587130759351995

Epoch: 6| Step: 1
Training loss: 0.49000537395477295
Validation loss: 2.0385029315948486

Epoch: 6| Step: 2
Training loss: 0.8655117750167847
Validation loss: 2.023094715610627

Epoch: 6| Step: 3
Training loss: 1.237673044204712
Validation loss: 1.9731061484224053

Epoch: 6| Step: 4
Training loss: 0.9950525760650635
Validation loss: 1.9668774207433064

Epoch: 6| Step: 5
Training loss: 1.2849944829940796
Validation loss: 1.9606380501101095

Epoch: 6| Step: 6
Training loss: 1.4072463512420654
Validation loss: 1.9810910173641738

Epoch: 6| Step: 7
Training loss: 0.897739589214325
Validation loss: 2.016329260282619

Epoch: 6| Step: 8
Training loss: 1.4755840301513672
Validation loss: 2.04192288332088

Epoch: 6| Step: 9
Training loss: 1.1861588954925537
Validation loss: 2.0310157191368843

Epoch: 6| Step: 10
Training loss: 1.041114330291748
Validation loss: 2.070821859503305

Epoch: 6| Step: 11
Training loss: 0.8403793573379517
Validation loss: 2.0809488565691057

Epoch: 6| Step: 12
Training loss: 1.4440345764160156
Validation loss: 2.029834642205187

Epoch: 6| Step: 13
Training loss: 1.4396593570709229
Validation loss: 2.051675773436023

Epoch: 294| Step: 0
Training loss: 1.4538449048995972
Validation loss: 2.02295696479018

Epoch: 6| Step: 1
Training loss: 1.250152349472046
Validation loss: 2.053794671130437

Epoch: 6| Step: 2
Training loss: 0.6860311627388
Validation loss: 2.0416404611320904

Epoch: 6| Step: 3
Training loss: 0.9834871888160706
Validation loss: 2.037865969442552

Epoch: 6| Step: 4
Training loss: 1.268986463546753
Validation loss: 2.0387644075578257

Epoch: 6| Step: 5
Training loss: 0.9340912103652954
Validation loss: 2.072898131544872

Epoch: 6| Step: 6
Training loss: 1.6776338815689087
Validation loss: 2.0603799409763788

Epoch: 6| Step: 7
Training loss: 0.6266871690750122
Validation loss: 2.0661865511248187

Epoch: 6| Step: 8
Training loss: 0.615881085395813
Validation loss: 2.069848596408803

Epoch: 6| Step: 9
Training loss: 1.2350797653198242
Validation loss: 2.0908506583142024

Epoch: 6| Step: 10
Training loss: 1.0144500732421875
Validation loss: 2.1001885565378333

Epoch: 6| Step: 11
Training loss: 1.2505221366882324
Validation loss: 2.123103295603106

Epoch: 6| Step: 12
Training loss: 1.5533761978149414
Validation loss: 2.0500188566023305

Epoch: 6| Step: 13
Training loss: 0.8140349388122559
Validation loss: 1.9856206217119772

Epoch: 295| Step: 0
Training loss: 1.336925745010376
Validation loss: 1.979846477508545

Epoch: 6| Step: 1
Training loss: 1.0905685424804688
Validation loss: 1.92179016400409

Epoch: 6| Step: 2
Training loss: 0.9826952219009399
Validation loss: 2.0010732886611775

Epoch: 6| Step: 3
Training loss: 1.323561429977417
Validation loss: 2.002585849454326

Epoch: 6| Step: 4
Training loss: 0.8705506324768066
Validation loss: 1.9993108677607712

Epoch: 6| Step: 5
Training loss: 0.7168260812759399
Validation loss: 2.039927245468222

Epoch: 6| Step: 6
Training loss: 1.737362265586853
Validation loss: 2.076872620531308

Epoch: 6| Step: 7
Training loss: 1.2569007873535156
Validation loss: 2.1079476905125443

Epoch: 6| Step: 8
Training loss: 0.9842309951782227
Validation loss: 2.1086495819912163

Epoch: 6| Step: 9
Training loss: 1.1204464435577393
Validation loss: 2.1087306468717513

Epoch: 6| Step: 10
Training loss: 0.8191378116607666
Validation loss: 2.106783720754808

Epoch: 6| Step: 11
Training loss: 0.8164143562316895
Validation loss: 2.132092273363503

Epoch: 6| Step: 12
Training loss: 1.0777325630187988
Validation loss: 2.1488065617058867

Epoch: 6| Step: 13
Training loss: 1.3847960233688354
Validation loss: 2.0734063117734847

Epoch: 296| Step: 0
Training loss: 1.0988293886184692
Validation loss: 2.047960832554807

Epoch: 6| Step: 1
Training loss: 1.306474208831787
Validation loss: 2.0622737125683854

Epoch: 6| Step: 2
Training loss: 1.2761448621749878
Validation loss: 2.0200801011054748

Epoch: 6| Step: 3
Training loss: 1.292338490486145
Validation loss: 1.9822788007797734

Epoch: 6| Step: 4
Training loss: 0.7587307691574097
Validation loss: 1.9744652830144411

Epoch: 6| Step: 5
Training loss: 1.0573652982711792
Validation loss: 1.9570548585666123

Epoch: 6| Step: 6
Training loss: 1.0587047338485718
Validation loss: 1.9673840973966865

Epoch: 6| Step: 7
Training loss: 1.1241499185562134
Validation loss: 2.000152349472046

Epoch: 6| Step: 8
Training loss: 1.280111312866211
Validation loss: 2.056065837542216

Epoch: 6| Step: 9
Training loss: 0.8744369745254517
Validation loss: 2.1096975393192743

Epoch: 6| Step: 10
Training loss: 1.3881943225860596
Validation loss: 2.1764321404118694

Epoch: 6| Step: 11
Training loss: 0.9722081422805786
Validation loss: 2.1909664805217455

Epoch: 6| Step: 12
Training loss: 1.1921968460083008
Validation loss: 2.168219780409208

Epoch: 6| Step: 13
Training loss: 0.3987397849559784
Validation loss: 2.1400936483055033

Epoch: 297| Step: 0
Training loss: 0.9408745169639587
Validation loss: 2.0540369120977258

Epoch: 6| Step: 1
Training loss: 1.3127117156982422
Validation loss: 2.0147686209729923

Epoch: 6| Step: 2
Training loss: 1.033690094947815
Validation loss: 1.9359566191191315

Epoch: 6| Step: 3
Training loss: 0.7828039526939392
Validation loss: 1.9201985559155863

Epoch: 6| Step: 4
Training loss: 1.1005252599716187
Validation loss: 1.9008198630425237

Epoch: 6| Step: 5
Training loss: 1.240772008895874
Validation loss: 1.929163618754315

Epoch: 6| Step: 6
Training loss: 0.974963366985321
Validation loss: 1.936549453325169

Epoch: 6| Step: 7
Training loss: 1.1770637035369873
Validation loss: 2.002958172111101

Epoch: 6| Step: 8
Training loss: 1.0553175210952759
Validation loss: 2.0744231618860716

Epoch: 6| Step: 9
Training loss: 1.2593082189559937
Validation loss: 2.103575398845057

Epoch: 6| Step: 10
Training loss: 1.4908640384674072
Validation loss: 2.1085177749715824

Epoch: 6| Step: 11
Training loss: 1.1395397186279297
Validation loss: 2.136170679523099

Epoch: 6| Step: 12
Training loss: 1.1377596855163574
Validation loss: 2.1489806303413967

Epoch: 6| Step: 13
Training loss: 0.9151538014411926
Validation loss: 2.123995288725822

Epoch: 298| Step: 0
Training loss: 1.275471806526184
Validation loss: 2.0990735433434926

Epoch: 6| Step: 1
Training loss: 0.6122944355010986
Validation loss: 2.0427605067529986

Epoch: 6| Step: 2
Training loss: 0.9463279247283936
Validation loss: 2.023684417047808

Epoch: 6| Step: 3
Training loss: 1.4072651863098145
Validation loss: 2.0156708378945627

Epoch: 6| Step: 4
Training loss: 1.0715337991714478
Validation loss: 2.0139791478392897

Epoch: 6| Step: 5
Training loss: 0.9836609959602356
Validation loss: 2.0311439575687533

Epoch: 6| Step: 6
Training loss: 1.2593622207641602
Validation loss: 2.0154870222973567

Epoch: 6| Step: 7
Training loss: 1.0125350952148438
Validation loss: 2.030922899964035

Epoch: 6| Step: 8
Training loss: 0.8228905200958252
Validation loss: 2.0391546321171585

Epoch: 6| Step: 9
Training loss: 1.5082995891571045
Validation loss: 2.051177586278608

Epoch: 6| Step: 10
Training loss: 1.3033082485198975
Validation loss: 2.0730489864144275

Epoch: 6| Step: 11
Training loss: 1.0089191198349
Validation loss: 2.059586235271987

Epoch: 6| Step: 12
Training loss: 0.8870512247085571
Validation loss: 2.021712028852073

Epoch: 6| Step: 13
Training loss: 0.6643878221511841
Validation loss: 2.0074503126964776

Epoch: 299| Step: 0
Training loss: 0.7003619074821472
Validation loss: 2.004693514557295

Epoch: 6| Step: 1
Training loss: 0.9747258424758911
Validation loss: 1.9828087309355378

Epoch: 6| Step: 2
Training loss: 1.6385996341705322
Validation loss: 1.988291601980886

Epoch: 6| Step: 3
Training loss: 1.0899860858917236
Validation loss: 1.9958022063778293

Epoch: 6| Step: 4
Training loss: 1.4667441844940186
Validation loss: 1.9755670152684695

Epoch: 6| Step: 5
Training loss: 0.9597389698028564
Validation loss: 1.9909468312417307

Epoch: 6| Step: 6
Training loss: 1.2947663068771362
Validation loss: 2.0333161892429477

Epoch: 6| Step: 7
Training loss: 0.5062629580497742
Validation loss: 2.073455406773475

Epoch: 6| Step: 8
Training loss: 0.9669734239578247
Validation loss: 2.0610076663314656

Epoch: 6| Step: 9
Training loss: 0.9936395883560181
Validation loss: 2.01400246671451

Epoch: 6| Step: 10
Training loss: 0.9750947952270508
Validation loss: 2.0660841259905087

Epoch: 6| Step: 11
Training loss: 1.3415133953094482
Validation loss: 2.0126550735965854

Epoch: 6| Step: 12
Training loss: 0.6597429513931274
Validation loss: 2.0219241393509733

Epoch: 6| Step: 13
Training loss: 1.4805643558502197
Validation loss: 2.0294992564826884

Epoch: 300| Step: 0
Training loss: 1.1946895122528076
Validation loss: 2.01607406908466

Epoch: 6| Step: 1
Training loss: 1.097218632698059
Validation loss: 2.041555998145893

Epoch: 6| Step: 2
Training loss: 1.0681030750274658
Validation loss: 2.062132614915089

Epoch: 6| Step: 3
Training loss: 1.2312310934066772
Validation loss: 2.0392413267525296

Epoch: 6| Step: 4
Training loss: 1.000779390335083
Validation loss: 2.0476238419932704

Epoch: 6| Step: 5
Training loss: 1.2232568264007568
Validation loss: 2.025448760678691

Epoch: 6| Step: 6
Training loss: 0.8170285224914551
Validation loss: 2.052187422270416

Epoch: 6| Step: 7
Training loss: 0.9193793535232544
Validation loss: 2.0855483060242026

Epoch: 6| Step: 8
Training loss: 0.8796966075897217
Validation loss: 2.0866703474393455

Epoch: 6| Step: 9
Training loss: 0.8370317816734314
Validation loss: 2.0784287132242674

Epoch: 6| Step: 10
Training loss: 0.6308870911598206
Validation loss: 2.0499630205092894

Epoch: 6| Step: 11
Training loss: 1.0854709148406982
Validation loss: 2.0417016334431146

Epoch: 6| Step: 12
Training loss: 1.630336046218872
Validation loss: 2.0546014155111005

Epoch: 6| Step: 13
Training loss: 0.6602164506912231
Validation loss: 2.044960429591517

Epoch: 301| Step: 0
Training loss: 1.214972972869873
Validation loss: 2.0012657232182

Epoch: 6| Step: 1
Training loss: 0.8532055616378784
Validation loss: 2.0109273361903366

Epoch: 6| Step: 2
Training loss: 0.9952206015586853
Validation loss: 2.0193612370439755

Epoch: 6| Step: 3
Training loss: 1.041501760482788
Validation loss: 2.0075190118564072

Epoch: 6| Step: 4
Training loss: 1.013033151626587
Validation loss: 1.9938825304790209

Epoch: 6| Step: 5
Training loss: 1.043358564376831
Validation loss: 1.957282966183078

Epoch: 6| Step: 6
Training loss: 0.9487856030464172
Validation loss: 1.9602612872277536

Epoch: 6| Step: 7
Training loss: 1.183335542678833
Validation loss: 1.9394378469836326

Epoch: 6| Step: 8
Training loss: 0.6551378965377808
Validation loss: 1.9390399097114481

Epoch: 6| Step: 9
Training loss: 1.212429165840149
Validation loss: 1.975480402669599

Epoch: 6| Step: 10
Training loss: 1.400496482849121
Validation loss: 2.0261234442392984

Epoch: 6| Step: 11
Training loss: 0.757111668586731
Validation loss: 1.9995778824693413

Epoch: 6| Step: 12
Training loss: 1.348100185394287
Validation loss: 2.004231309378019

Epoch: 6| Step: 13
Training loss: 0.9722915291786194
Validation loss: 2.0573556987188195

Epoch: 302| Step: 0
Training loss: 0.6279021501541138
Validation loss: 2.0385922206345426

Epoch: 6| Step: 1
Training loss: 1.2511603832244873
Validation loss: 1.9974103461029709

Epoch: 6| Step: 2
Training loss: 0.7002258896827698
Validation loss: 1.9933683256949148

Epoch: 6| Step: 3
Training loss: 1.1195627450942993
Validation loss: 1.994200683409168

Epoch: 6| Step: 4
Training loss: 0.7845491766929626
Validation loss: 1.9752086054894231

Epoch: 6| Step: 5
Training loss: 1.1981346607208252
Validation loss: 1.9650478016945623

Epoch: 6| Step: 6
Training loss: 1.2157056331634521
Validation loss: 1.9803222584468063

Epoch: 6| Step: 7
Training loss: 0.8893881440162659
Validation loss: 1.9648343811752975

Epoch: 6| Step: 8
Training loss: 0.8806822299957275
Validation loss: 2.0278576779109176

Epoch: 6| Step: 9
Training loss: 1.869337797164917
Validation loss: 2.045134250835706

Epoch: 6| Step: 10
Training loss: 0.8243284225463867
Validation loss: 1.9904990426955684

Epoch: 6| Step: 11
Training loss: 0.7515865564346313
Validation loss: 2.045603172753447

Epoch: 6| Step: 12
Training loss: 1.253663182258606
Validation loss: 2.0576349663478073

Epoch: 6| Step: 13
Training loss: 0.9699856638908386
Validation loss: 2.079766860572241

Epoch: 303| Step: 0
Training loss: 0.9045815467834473
Validation loss: 2.0351519430837324

Epoch: 6| Step: 1
Training loss: 1.226825475692749
Validation loss: 2.0268439695399296

Epoch: 6| Step: 2
Training loss: 1.3423240184783936
Validation loss: 2.012784960449383

Epoch: 6| Step: 3
Training loss: 0.817340075969696
Validation loss: 1.975999580916538

Epoch: 6| Step: 4
Training loss: 1.1512848138809204
Validation loss: 1.9665432437773673

Epoch: 6| Step: 5
Training loss: 0.674675703048706
Validation loss: 1.9753360504745154

Epoch: 6| Step: 6
Training loss: 1.062114953994751
Validation loss: 1.9854735661578435

Epoch: 6| Step: 7
Training loss: 1.2315616607666016
Validation loss: 2.044225227448248

Epoch: 6| Step: 8
Training loss: 1.094454050064087
Validation loss: 2.0131336271121936

Epoch: 6| Step: 9
Training loss: 0.8036661148071289
Validation loss: 2.0675889420252975

Epoch: 6| Step: 10
Training loss: 0.968416154384613
Validation loss: 2.0513224242835917

Epoch: 6| Step: 11
Training loss: 1.153537631034851
Validation loss: 2.0244507328156502

Epoch: 6| Step: 12
Training loss: 0.8794727921485901
Validation loss: 2.005870742182578

Epoch: 6| Step: 13
Training loss: 0.8839300870895386
Validation loss: 1.9874415782190138

Epoch: 304| Step: 0
Training loss: 0.946544885635376
Validation loss: 1.9921842339218303

Epoch: 6| Step: 1
Training loss: 0.8549277782440186
Validation loss: 1.9434582443647488

Epoch: 6| Step: 2
Training loss: 0.696019172668457
Validation loss: 1.8852128636452459

Epoch: 6| Step: 3
Training loss: 1.1159119606018066
Validation loss: 1.9104930867430985

Epoch: 6| Step: 4
Training loss: 0.9771145582199097
Validation loss: 1.9636905347147295

Epoch: 6| Step: 5
Training loss: 0.7498139142990112
Validation loss: 1.9889413079907816

Epoch: 6| Step: 6
Training loss: 1.0423822402954102
Validation loss: 2.0530011679536555

Epoch: 6| Step: 7
Training loss: 1.183577537536621
Validation loss: 2.099620247399935

Epoch: 6| Step: 8
Training loss: 1.5523574352264404
Validation loss: 2.0808252160267164

Epoch: 6| Step: 9
Training loss: 1.1960452795028687
Validation loss: 2.0712625698376725

Epoch: 6| Step: 10
Training loss: 0.8191806674003601
Validation loss: 2.068800644208026

Epoch: 6| Step: 11
Training loss: 1.4679380655288696
Validation loss: 2.019679994993312

Epoch: 6| Step: 12
Training loss: 1.2673639059066772
Validation loss: 2.0481075843175254

Epoch: 6| Step: 13
Training loss: 0.45789533853530884
Validation loss: 2.060875113292407

Epoch: 305| Step: 0
Training loss: 1.2248167991638184
Validation loss: 2.0849538105790333

Epoch: 6| Step: 1
Training loss: 0.6895852088928223
Validation loss: 2.0668342010949248

Epoch: 6| Step: 2
Training loss: 1.1459836959838867
Validation loss: 2.0824538225768716

Epoch: 6| Step: 3
Training loss: 1.3045434951782227
Validation loss: 2.094664899251794

Epoch: 6| Step: 4
Training loss: 0.8704977035522461
Validation loss: 2.0943229980366205

Epoch: 6| Step: 5
Training loss: 0.8218027353286743
Validation loss: 2.071875295331401

Epoch: 6| Step: 6
Training loss: 1.2632254362106323
Validation loss: 2.012506866967806

Epoch: 6| Step: 7
Training loss: 0.9631384611129761
Validation loss: 2.01472460069964

Epoch: 6| Step: 8
Training loss: 1.5961410999298096
Validation loss: 1.9601572892999137

Epoch: 6| Step: 9
Training loss: 0.6955779790878296
Validation loss: 1.9603177142399613

Epoch: 6| Step: 10
Training loss: 1.2024985551834106
Validation loss: 1.9258072581342471

Epoch: 6| Step: 11
Training loss: 0.8562523722648621
Validation loss: 1.8961440235055902

Epoch: 6| Step: 12
Training loss: 1.0316660404205322
Validation loss: 1.9185601152399534

Epoch: 6| Step: 13
Training loss: 1.2569187879562378
Validation loss: 1.9162379105885823

Epoch: 306| Step: 0
Training loss: 0.8872599601745605
Validation loss: 1.9428773336513068

Epoch: 6| Step: 1
Training loss: 1.7472913265228271
Validation loss: 1.911175061297673

Epoch: 6| Step: 2
Training loss: 0.8581457734107971
Validation loss: 1.9630355027414137

Epoch: 6| Step: 3
Training loss: 0.8579365611076355
Validation loss: 2.0277948507698635

Epoch: 6| Step: 4
Training loss: 0.9780228137969971
Validation loss: 2.0319033694523636

Epoch: 6| Step: 5
Training loss: 0.9066311120986938
Validation loss: 2.094798395710607

Epoch: 6| Step: 6
Training loss: 1.1705340147018433
Validation loss: 2.1011107326835714

Epoch: 6| Step: 7
Training loss: 1.0057753324508667
Validation loss: 2.118051805803853

Epoch: 6| Step: 8
Training loss: 1.4129234552383423
Validation loss: 2.0989598381903862

Epoch: 6| Step: 9
Training loss: 1.1103101968765259
Validation loss: 2.068714495628111

Epoch: 6| Step: 10
Training loss: 0.8726550340652466
Validation loss: 2.0611148547100764

Epoch: 6| Step: 11
Training loss: 0.8670680522918701
Validation loss: 2.045318772715907

Epoch: 6| Step: 12
Training loss: 1.1197185516357422
Validation loss: 2.0001963902545232

Epoch: 6| Step: 13
Training loss: 0.6134158372879028
Validation loss: 1.9555137920123276

Epoch: 307| Step: 0
Training loss: 1.1686655282974243
Validation loss: 1.9687237431926112

Epoch: 6| Step: 1
Training loss: 0.6489477157592773
Validation loss: 1.9295963561663063

Epoch: 6| Step: 2
Training loss: 0.7786051034927368
Validation loss: 1.8982539740941857

Epoch: 6| Step: 3
Training loss: 1.3766157627105713
Validation loss: 1.896185246847009

Epoch: 6| Step: 4
Training loss: 0.9390541315078735
Validation loss: 1.9366700315988192

Epoch: 6| Step: 5
Training loss: 1.142496109008789
Validation loss: 1.9191082805715582

Epoch: 6| Step: 6
Training loss: 1.121523380279541
Validation loss: 1.9820478936677337

Epoch: 6| Step: 7
Training loss: 1.4214706420898438
Validation loss: 1.9908151998314807

Epoch: 6| Step: 8
Training loss: 0.7658373713493347
Validation loss: 2.044287040669431

Epoch: 6| Step: 9
Training loss: 1.3209748268127441
Validation loss: 2.0518837334007345

Epoch: 6| Step: 10
Training loss: 0.7771469354629517
Validation loss: 2.1026628786517727

Epoch: 6| Step: 11
Training loss: 0.7344022989273071
Validation loss: 2.1044735318870953

Epoch: 6| Step: 12
Training loss: 0.9823249578475952
Validation loss: 2.1369376362011

Epoch: 6| Step: 13
Training loss: 0.9583629965782166
Validation loss: 2.0921678209817536

Epoch: 308| Step: 0
Training loss: 1.284427523612976
Validation loss: 2.0881429128749396

Epoch: 6| Step: 1
Training loss: 1.0096042156219482
Validation loss: 2.0654568620907363

Epoch: 6| Step: 2
Training loss: 1.2221624851226807
Validation loss: 2.0546352401856454

Epoch: 6| Step: 3
Training loss: 1.3345905542373657
Validation loss: 2.063832615011482

Epoch: 6| Step: 4
Training loss: 0.8657466173171997
Validation loss: 2.0426052103760424

Epoch: 6| Step: 5
Training loss: 0.933635950088501
Validation loss: 2.046057144800822

Epoch: 6| Step: 6
Training loss: 0.8584924936294556
Validation loss: 2.0558637470327397

Epoch: 6| Step: 7
Training loss: 0.7836252450942993
Validation loss: 2.075267254665334

Epoch: 6| Step: 8
Training loss: 0.5803318023681641
Validation loss: 2.0489933054934264

Epoch: 6| Step: 9
Training loss: 0.7681624889373779
Validation loss: 2.012610594431559

Epoch: 6| Step: 10
Training loss: 1.5454003810882568
Validation loss: 1.9529385028346893

Epoch: 6| Step: 11
Training loss: 0.5386894941329956
Validation loss: 1.922272987263177

Epoch: 6| Step: 12
Training loss: 0.9621249437332153
Validation loss: 1.9085514494167861

Epoch: 6| Step: 13
Training loss: 1.1029033660888672
Validation loss: 1.902285168247838

Epoch: 309| Step: 0
Training loss: 0.9016134738922119
Validation loss: 1.9117496321278233

Epoch: 6| Step: 1
Training loss: 1.061957597732544
Validation loss: 1.8919215586877638

Epoch: 6| Step: 2
Training loss: 0.8689316511154175
Validation loss: 1.9353838120737383

Epoch: 6| Step: 3
Training loss: 1.0407466888427734
Validation loss: 1.9762628360461163

Epoch: 6| Step: 4
Training loss: 1.0291452407836914
Validation loss: 1.9648201081060594

Epoch: 6| Step: 5
Training loss: 1.106934905052185
Validation loss: 2.0239501319905764

Epoch: 6| Step: 6
Training loss: 1.5794610977172852
Validation loss: 2.0148326171341764

Epoch: 6| Step: 7
Training loss: 1.3309621810913086
Validation loss: 2.0188705895536687

Epoch: 6| Step: 8
Training loss: 0.4292669892311096
Validation loss: 2.016859890312277

Epoch: 6| Step: 9
Training loss: 0.7911088466644287
Validation loss: 1.9785650161004835

Epoch: 6| Step: 10
Training loss: 0.9475477933883667
Validation loss: 1.9966386402806928

Epoch: 6| Step: 11
Training loss: 0.8640024662017822
Validation loss: 2.016976652606841

Epoch: 6| Step: 12
Training loss: 1.0792315006256104
Validation loss: 2.0015111943726898

Epoch: 6| Step: 13
Training loss: 0.7666206955909729
Validation loss: 1.997094564540412

Epoch: 310| Step: 0
Training loss: 1.660799264907837
Validation loss: 2.041071004765008

Epoch: 6| Step: 1
Training loss: 0.8626399040222168
Validation loss: 2.0180921298201366

Epoch: 6| Step: 2
Training loss: 0.8753493428230286
Validation loss: 2.0684632383367068

Epoch: 6| Step: 3
Training loss: 0.4635160565376282
Validation loss: 2.059678690407866

Epoch: 6| Step: 4
Training loss: 1.0941188335418701
Validation loss: 2.032368488209222

Epoch: 6| Step: 5
Training loss: 1.4484498500823975
Validation loss: 1.9973311924165296

Epoch: 6| Step: 6
Training loss: 1.0978498458862305
Validation loss: 2.0284335626068937

Epoch: 6| Step: 7
Training loss: 1.0997357368469238
Validation loss: 2.034076277927686

Epoch: 6| Step: 8
Training loss: 1.1867280006408691
Validation loss: 1.9733546715910717

Epoch: 6| Step: 9
Training loss: 0.8285512924194336
Validation loss: 1.9817165687520018

Epoch: 6| Step: 10
Training loss: 0.37591904401779175
Validation loss: 1.9509311452988656

Epoch: 6| Step: 11
Training loss: 0.8609640598297119
Validation loss: 1.9682421184355212

Epoch: 6| Step: 12
Training loss: 0.8827811479568481
Validation loss: 1.9148943885680167

Epoch: 6| Step: 13
Training loss: 0.7366838455200195
Validation loss: 1.9462145631031325

Epoch: 311| Step: 0
Training loss: 1.0104212760925293
Validation loss: 1.9997842029858661

Epoch: 6| Step: 1
Training loss: 1.7132065296173096
Validation loss: 1.9984708204064319

Epoch: 6| Step: 2
Training loss: 1.351966381072998
Validation loss: 1.9668696465030793

Epoch: 6| Step: 3
Training loss: 0.9152832627296448
Validation loss: 1.996839786088595

Epoch: 6| Step: 4
Training loss: 0.7379612922668457
Validation loss: 2.0238478773383686

Epoch: 6| Step: 5
Training loss: 0.9981418251991272
Validation loss: 1.9719451653060092

Epoch: 6| Step: 6
Training loss: 0.7837232351303101
Validation loss: 1.9910156188472625

Epoch: 6| Step: 7
Training loss: 0.9004358053207397
Validation loss: 1.9740326801935832

Epoch: 6| Step: 8
Training loss: 0.9211427569389343
Validation loss: 1.9858406474513393

Epoch: 6| Step: 9
Training loss: 1.0185174942016602
Validation loss: 1.9960034021767237

Epoch: 6| Step: 10
Training loss: 0.6243927478790283
Validation loss: 1.9933755384978427

Epoch: 6| Step: 11
Training loss: 1.248680591583252
Validation loss: 2.0136170823086976

Epoch: 6| Step: 12
Training loss: 0.7652891874313354
Validation loss: 2.042942685465659

Epoch: 6| Step: 13
Training loss: 0.7359840869903564
Validation loss: 2.0305902650279384

Epoch: 312| Step: 0
Training loss: 1.2401466369628906
Validation loss: 2.029588927504837

Epoch: 6| Step: 1
Training loss: 0.49320274591445923
Validation loss: 2.036874019971458

Epoch: 6| Step: 2
Training loss: 1.080543041229248
Validation loss: 1.9828147849728983

Epoch: 6| Step: 3
Training loss: 0.8069998621940613
Validation loss: 1.9461881319681804

Epoch: 6| Step: 4
Training loss: 1.0349351167678833
Validation loss: 1.9892450609514791

Epoch: 6| Step: 5
Training loss: 1.030867576599121
Validation loss: 1.9565649776048557

Epoch: 6| Step: 6
Training loss: 0.9367932081222534
Validation loss: 1.9942582166323097

Epoch: 6| Step: 7
Training loss: 0.3508424460887909
Validation loss: 2.0301354982519664

Epoch: 6| Step: 8
Training loss: 0.7796012163162231
Validation loss: 1.9969756282785887

Epoch: 6| Step: 9
Training loss: 1.3962184190750122
Validation loss: 2.0081330230159145

Epoch: 6| Step: 10
Training loss: 0.7627791166305542
Validation loss: 2.0008522310564594

Epoch: 6| Step: 11
Training loss: 1.2734322547912598
Validation loss: 1.979433959530246

Epoch: 6| Step: 12
Training loss: 1.3936172723770142
Validation loss: 1.9912059563462452

Epoch: 6| Step: 13
Training loss: 1.1556237936019897
Validation loss: 1.9773593512914514

Epoch: 313| Step: 0
Training loss: 0.49972203373908997
Validation loss: 1.986803408591978

Epoch: 6| Step: 1
Training loss: 1.0317438840866089
Validation loss: 1.9643738756897628

Epoch: 6| Step: 2
Training loss: 0.735634446144104
Validation loss: 2.0071447690327964

Epoch: 6| Step: 3
Training loss: 0.5792347192764282
Validation loss: 1.9616338181239303

Epoch: 6| Step: 4
Training loss: 0.8363966941833496
Validation loss: 2.044011257028067

Epoch: 6| Step: 5
Training loss: 1.127986192703247
Validation loss: 2.0250404111800657

Epoch: 6| Step: 6
Training loss: 1.0351769924163818
Validation loss: 1.99373641321736

Epoch: 6| Step: 7
Training loss: 0.8823594450950623
Validation loss: 2.0162865205477645

Epoch: 6| Step: 8
Training loss: 1.0051233768463135
Validation loss: 1.9609043585356845

Epoch: 6| Step: 9
Training loss: 1.001667857170105
Validation loss: 1.984886525779642

Epoch: 6| Step: 10
Training loss: 1.4686723947525024
Validation loss: 1.9546989112771966

Epoch: 6| Step: 11
Training loss: 0.9742993712425232
Validation loss: 1.9513900818363312

Epoch: 6| Step: 12
Training loss: 1.2015888690948486
Validation loss: 1.9979262685263028

Epoch: 6| Step: 13
Training loss: 1.1095337867736816
Validation loss: 1.984564224878947

Epoch: 314| Step: 0
Training loss: 1.3291515111923218
Validation loss: 1.9990323640966927

Epoch: 6| Step: 1
Training loss: 0.9869737029075623
Validation loss: 1.9824146275879235

Epoch: 6| Step: 2
Training loss: 0.7881165742874146
Validation loss: 2.0193541485776185

Epoch: 6| Step: 3
Training loss: 1.0009467601776123
Validation loss: 2.017036179060577

Epoch: 6| Step: 4
Training loss: 0.7733368277549744
Validation loss: 1.9978666549087853

Epoch: 6| Step: 5
Training loss: 0.7502725124359131
Validation loss: 2.0412082364482265

Epoch: 6| Step: 6
Training loss: 0.9155179262161255
Validation loss: 2.016083807073614

Epoch: 6| Step: 7
Training loss: 1.1340117454528809
Validation loss: 1.9799684760391072

Epoch: 6| Step: 8
Training loss: 1.4010406732559204
Validation loss: 2.019625304847635

Epoch: 6| Step: 9
Training loss: 0.6890857219696045
Validation loss: 2.019992187458982

Epoch: 6| Step: 10
Training loss: 0.6560283303260803
Validation loss: 2.036144665492478

Epoch: 6| Step: 11
Training loss: 0.6560207605361938
Validation loss: 2.0229652081766436

Epoch: 6| Step: 12
Training loss: 1.2039216756820679
Validation loss: 1.993165285356583

Epoch: 6| Step: 13
Training loss: 1.0536872148513794
Validation loss: 2.030452844917133

Epoch: 315| Step: 0
Training loss: 0.6066910028457642
Validation loss: 2.0119060444575485

Epoch: 6| Step: 1
Training loss: 1.2088119983673096
Validation loss: 2.0364653743723387

Epoch: 6| Step: 2
Training loss: 1.1177566051483154
Validation loss: 2.0705044372107393

Epoch: 6| Step: 3
Training loss: 1.3512403964996338
Validation loss: 2.044899812308691

Epoch: 6| Step: 4
Training loss: 1.160576581954956
Validation loss: 1.9725511176611787

Epoch: 6| Step: 5
Training loss: 0.8898913264274597
Validation loss: 1.9723223011980775

Epoch: 6| Step: 6
Training loss: 0.5354921221733093
Validation loss: 1.939372157537809

Epoch: 6| Step: 7
Training loss: 0.512458324432373
Validation loss: 1.9621339280118224

Epoch: 6| Step: 8
Training loss: 0.9809770584106445
Validation loss: 1.9496959409406107

Epoch: 6| Step: 9
Training loss: 0.9687122106552124
Validation loss: 1.9852206527545888

Epoch: 6| Step: 10
Training loss: 1.051189661026001
Validation loss: 1.9483991515251897

Epoch: 6| Step: 11
Training loss: 0.8999004364013672
Validation loss: 1.9560921781806535

Epoch: 6| Step: 12
Training loss: 1.006943702697754
Validation loss: 1.9420587862691572

Epoch: 6| Step: 13
Training loss: 1.0868487358093262
Validation loss: 1.9257338572573919

Epoch: 316| Step: 0
Training loss: 1.0222675800323486
Validation loss: 1.9274925057606032

Epoch: 6| Step: 1
Training loss: 0.9710246920585632
Validation loss: 1.9726402246823875

Epoch: 6| Step: 2
Training loss: 1.1898393630981445
Validation loss: 2.004834754492647

Epoch: 6| Step: 3
Training loss: 0.6030087471008301
Validation loss: 1.9547413574751986

Epoch: 6| Step: 4
Training loss: 0.8224474191665649
Validation loss: 1.9836915692975443

Epoch: 6| Step: 5
Training loss: 1.0872523784637451
Validation loss: 1.962376876543927

Epoch: 6| Step: 6
Training loss: 0.7521785497665405
Validation loss: 1.9400668400590138

Epoch: 6| Step: 7
Training loss: 1.2918092012405396
Validation loss: 1.9486692208115772

Epoch: 6| Step: 8
Training loss: 1.2560334205627441
Validation loss: 1.9584120909372966

Epoch: 6| Step: 9
Training loss: 1.3143738508224487
Validation loss: 1.9345533270989694

Epoch: 6| Step: 10
Training loss: 0.9021661281585693
Validation loss: 1.9373939114232217

Epoch: 6| Step: 11
Training loss: 0.46879205107688904
Validation loss: 1.9874812505578483

Epoch: 6| Step: 12
Training loss: 0.5416380763053894
Validation loss: 1.986437471964026

Epoch: 6| Step: 13
Training loss: 1.0658113956451416
Validation loss: 2.0559057356208883

Epoch: 317| Step: 0
Training loss: 0.6845175623893738
Validation loss: 2.0483819951293287

Epoch: 6| Step: 1
Training loss: 1.057603120803833
Validation loss: 2.0677098253721833

Epoch: 6| Step: 2
Training loss: 0.6110002398490906
Validation loss: 2.09248597134826

Epoch: 6| Step: 3
Training loss: 1.002076506614685
Validation loss: 2.053917092661704

Epoch: 6| Step: 4
Training loss: 0.8530486822128296
Validation loss: 2.062684666725897

Epoch: 6| Step: 5
Training loss: 0.9516971111297607
Validation loss: 2.0116804799725934

Epoch: 6| Step: 6
Training loss: 1.2701454162597656
Validation loss: 1.9931954337704567

Epoch: 6| Step: 7
Training loss: 1.1736055612564087
Validation loss: 2.035528670075119

Epoch: 6| Step: 8
Training loss: 0.9402542114257812
Validation loss: 2.0185048246896393

Epoch: 6| Step: 9
Training loss: 1.3563233613967896
Validation loss: 1.9985732340043592

Epoch: 6| Step: 10
Training loss: 0.6962554454803467
Validation loss: 2.015221770091723

Epoch: 6| Step: 11
Training loss: 0.75778728723526
Validation loss: 2.0055170136113323

Epoch: 6| Step: 12
Training loss: 0.9480882883071899
Validation loss: 2.0352276909735894

Epoch: 6| Step: 13
Training loss: 1.5444916486740112
Validation loss: 1.9688303521884385

Epoch: 318| Step: 0
Training loss: 0.8634363412857056
Validation loss: 1.9879002699287989

Epoch: 6| Step: 1
Training loss: 0.6310707330703735
Validation loss: 1.9741946445998324

Epoch: 6| Step: 2
Training loss: 0.8379656672477722
Validation loss: 1.9756512347088064

Epoch: 6| Step: 3
Training loss: 1.175589919090271
Validation loss: 2.0160013027088617

Epoch: 6| Step: 4
Training loss: 1.185269832611084
Validation loss: 2.0349444240652104

Epoch: 6| Step: 5
Training loss: 1.0652687549591064
Validation loss: 2.0418799628493605

Epoch: 6| Step: 6
Training loss: 1.2964165210723877
Validation loss: 1.9935536076945644

Epoch: 6| Step: 7
Training loss: 1.3970426321029663
Validation loss: 1.9960590408694359

Epoch: 6| Step: 8
Training loss: 1.0384106636047363
Validation loss: 1.9558511549426663

Epoch: 6| Step: 9
Training loss: 0.8977510929107666
Validation loss: 1.9563188706674883

Epoch: 6| Step: 10
Training loss: 0.864513099193573
Validation loss: 1.9699820844076013

Epoch: 6| Step: 11
Training loss: 0.6117026209831238
Validation loss: 1.966907016692623

Epoch: 6| Step: 12
Training loss: 0.6955901384353638
Validation loss: 1.9904978582935948

Epoch: 6| Step: 13
Training loss: 1.0632798671722412
Validation loss: 2.0179128569941365

Epoch: 319| Step: 0
Training loss: 0.9562081098556519
Validation loss: 2.0243576495878157

Epoch: 6| Step: 1
Training loss: 1.2006628513336182
Validation loss: 2.0351454596365652

Epoch: 6| Step: 2
Training loss: 0.8018244504928589
Validation loss: 2.00757913051113

Epoch: 6| Step: 3
Training loss: 0.32556283473968506
Validation loss: 2.0189086160352154

Epoch: 6| Step: 4
Training loss: 0.6127774715423584
Validation loss: 1.9925641782822148

Epoch: 6| Step: 5
Training loss: 0.7649345397949219
Validation loss: 1.9400845804522115

Epoch: 6| Step: 6
Training loss: 0.6158704161643982
Validation loss: 1.9475700252799577

Epoch: 6| Step: 7
Training loss: 0.8942224979400635
Validation loss: 1.9523543491158435

Epoch: 6| Step: 8
Training loss: 1.3476760387420654
Validation loss: 1.9386432670777844

Epoch: 6| Step: 9
Training loss: 1.162226676940918
Validation loss: 1.9561197373174852

Epoch: 6| Step: 10
Training loss: 1.1667027473449707
Validation loss: 1.9529747116950251

Epoch: 6| Step: 11
Training loss: 1.4590158462524414
Validation loss: 2.0294494244360153

Epoch: 6| Step: 12
Training loss: 0.8231906890869141
Validation loss: 2.0138747743380967

Epoch: 6| Step: 13
Training loss: 1.2207175493240356
Validation loss: 2.0519273575916084

Epoch: 320| Step: 0
Training loss: 1.2310757637023926
Validation loss: 2.0439078295102684

Epoch: 6| Step: 1
Training loss: 0.9294426441192627
Validation loss: 2.058243828435098

Epoch: 6| Step: 2
Training loss: 0.8062928318977356
Validation loss: 2.044123367596698

Epoch: 6| Step: 3
Training loss: 0.6148345470428467
Validation loss: 2.03844512790762

Epoch: 6| Step: 4
Training loss: 0.9925974607467651
Validation loss: 1.9794807203354374

Epoch: 6| Step: 5
Training loss: 0.8528270721435547
Validation loss: 1.959378206601707

Epoch: 6| Step: 6
Training loss: 0.39567410945892334
Validation loss: 1.9304239288453133

Epoch: 6| Step: 7
Training loss: 0.7425042390823364
Validation loss: 1.941092022003666

Epoch: 6| Step: 8
Training loss: 1.321040391921997
Validation loss: 1.924197409742622

Epoch: 6| Step: 9
Training loss: 0.7541208863258362
Validation loss: 1.9389829994529806

Epoch: 6| Step: 10
Training loss: 1.2157700061798096
Validation loss: 1.9375535147164458

Epoch: 6| Step: 11
Training loss: 0.8831484317779541
Validation loss: 1.996368496648727

Epoch: 6| Step: 12
Training loss: 1.0126707553863525
Validation loss: 1.9598096391206146

Epoch: 6| Step: 13
Training loss: 1.3424913883209229
Validation loss: 1.9760706860532042

Epoch: 321| Step: 0
Training loss: 1.0855140686035156
Validation loss: 1.9672997510561379

Epoch: 6| Step: 1
Training loss: 0.42455536127090454
Validation loss: 1.935823925079838

Epoch: 6| Step: 2
Training loss: 1.3472660779953003
Validation loss: 1.9303115285852903

Epoch: 6| Step: 3
Training loss: 1.2670536041259766
Validation loss: 1.9091226439322195

Epoch: 6| Step: 4
Training loss: 0.7702921628952026
Validation loss: 1.9339127643134004

Epoch: 6| Step: 5
Training loss: 1.3859226703643799
Validation loss: 1.919717668205179

Epoch: 6| Step: 6
Training loss: 0.42942747473716736
Validation loss: 1.8905003250286143

Epoch: 6| Step: 7
Training loss: 0.8980646133422852
Validation loss: 1.9020559915932276

Epoch: 6| Step: 8
Training loss: 0.7826812267303467
Validation loss: 1.9288162377572828

Epoch: 6| Step: 9
Training loss: 0.9845127463340759
Validation loss: 1.9014724070026028

Epoch: 6| Step: 10
Training loss: 0.7486509084701538
Validation loss: 1.9063022521234327

Epoch: 6| Step: 11
Training loss: 0.541126012802124
Validation loss: 1.928448454026253

Epoch: 6| Step: 12
Training loss: 1.5001643896102905
Validation loss: 1.9087364237795594

Epoch: 6| Step: 13
Training loss: 0.9956629276275635
Validation loss: 1.9029069728748773

Epoch: 322| Step: 0
Training loss: 1.0503573417663574
Validation loss: 1.9510988471328572

Epoch: 6| Step: 1
Training loss: 0.7621681094169617
Validation loss: 1.945428225301927

Epoch: 6| Step: 2
Training loss: 0.6171866655349731
Validation loss: 1.9111472291331137

Epoch: 6| Step: 3
Training loss: 0.9625166654586792
Validation loss: 1.907197867670367

Epoch: 6| Step: 4
Training loss: 1.0247623920440674
Validation loss: 1.9570152503187939

Epoch: 6| Step: 5
Training loss: 0.6538114547729492
Validation loss: 1.9686047146397252

Epoch: 6| Step: 6
Training loss: 1.0912504196166992
Validation loss: 2.034719205671741

Epoch: 6| Step: 7
Training loss: 0.9364572763442993
Validation loss: 2.0034415029710337

Epoch: 6| Step: 8
Training loss: 1.230017900466919
Validation loss: 2.059022949587914

Epoch: 6| Step: 9
Training loss: 1.1884434223175049
Validation loss: 2.048794557971339

Epoch: 6| Step: 10
Training loss: 0.8970919847488403
Validation loss: 2.0208188667092273

Epoch: 6| Step: 11
Training loss: 1.20363450050354
Validation loss: 2.0354811991414716

Epoch: 6| Step: 12
Training loss: 0.8931200504302979
Validation loss: 2.0146550273382537

Epoch: 6| Step: 13
Training loss: 1.0605432987213135
Validation loss: 1.9836341565655125

Epoch: 323| Step: 0
Training loss: 0.8292655944824219
Validation loss: 1.9892060167046004

Epoch: 6| Step: 1
Training loss: 0.40003663301467896
Validation loss: 1.9863304963675879

Epoch: 6| Step: 2
Training loss: 1.0474214553833008
Validation loss: 2.005628337142288

Epoch: 6| Step: 3
Training loss: 1.8513286113739014
Validation loss: 1.9310187639728669

Epoch: 6| Step: 4
Training loss: 1.0467324256896973
Validation loss: 1.9224700389369842

Epoch: 6| Step: 5
Training loss: 1.0241601467132568
Validation loss: 1.889405865823069

Epoch: 6| Step: 6
Training loss: 1.3729249238967896
Validation loss: 1.9088915278834682

Epoch: 6| Step: 7
Training loss: 0.6219989061355591
Validation loss: 1.9433739839061615

Epoch: 6| Step: 8
Training loss: 0.8014206886291504
Validation loss: 1.9528752988384617

Epoch: 6| Step: 9
Training loss: 0.7739019393920898
Validation loss: 1.9580074599994126

Epoch: 6| Step: 10
Training loss: 0.7162725925445557
Validation loss: 1.962555326441283

Epoch: 6| Step: 11
Training loss: 0.8801188468933105
Validation loss: 1.9700752919720066

Epoch: 6| Step: 12
Training loss: 0.8059465289115906
Validation loss: 1.993044707082933

Epoch: 6| Step: 13
Training loss: 0.8315090537071228
Validation loss: 2.024743054502754

Epoch: 324| Step: 0
Training loss: 0.7332102656364441
Validation loss: 2.035395722235403

Epoch: 6| Step: 1
Training loss: 0.91452956199646
Validation loss: 2.04040184584997

Epoch: 6| Step: 2
Training loss: 0.9374048709869385
Validation loss: 2.026883388078341

Epoch: 6| Step: 3
Training loss: 1.049431562423706
Validation loss: 2.0213378091012277

Epoch: 6| Step: 4
Training loss: 0.6491107940673828
Validation loss: 1.9899038191764586

Epoch: 6| Step: 5
Training loss: 1.0069137811660767
Validation loss: 1.973052159432442

Epoch: 6| Step: 6
Training loss: 1.247055172920227
Validation loss: 1.9239286953403103

Epoch: 6| Step: 7
Training loss: 0.8927686214447021
Validation loss: 1.9304630448741298

Epoch: 6| Step: 8
Training loss: 0.869314432144165
Validation loss: 1.94343356163271

Epoch: 6| Step: 9
Training loss: 1.1292389631271362
Validation loss: 1.9113468175293298

Epoch: 6| Step: 10
Training loss: 0.49715179204940796
Validation loss: 1.9116262761495446

Epoch: 6| Step: 11
Training loss: 0.6979482173919678
Validation loss: 1.9972207982053038

Epoch: 6| Step: 12
Training loss: 1.275402307510376
Validation loss: 1.9548736618411156

Epoch: 6| Step: 13
Training loss: 0.6219684481620789
Validation loss: 1.9868873626955095

Epoch: 325| Step: 0
Training loss: 0.9099742770195007
Validation loss: 1.9717667410450597

Epoch: 6| Step: 1
Training loss: 0.6761744022369385
Validation loss: 2.01036161504766

Epoch: 6| Step: 2
Training loss: 0.5548115372657776
Validation loss: 2.0124887702285603

Epoch: 6| Step: 3
Training loss: 1.0949628353118896
Validation loss: 2.004915907818784

Epoch: 6| Step: 4
Training loss: 0.9032700657844543
Validation loss: 1.94586528501203

Epoch: 6| Step: 5
Training loss: 1.0385758876800537
Validation loss: 1.9857621103204706

Epoch: 6| Step: 6
Training loss: 1.3323911428451538
Validation loss: 2.0013669754869197

Epoch: 6| Step: 7
Training loss: 1.2563440799713135
Validation loss: 1.990732007129218

Epoch: 6| Step: 8
Training loss: 0.5079654455184937
Validation loss: 1.9725206180285382

Epoch: 6| Step: 9
Training loss: 0.8572909832000732
Validation loss: 1.9783088455918014

Epoch: 6| Step: 10
Training loss: 0.7503608465194702
Validation loss: 1.9686286500705186

Epoch: 6| Step: 11
Training loss: 0.6344181299209595
Validation loss: 1.9944183980264971

Epoch: 6| Step: 12
Training loss: 0.9225559830665588
Validation loss: 1.9892891735158942

Epoch: 6| Step: 13
Training loss: 0.8764886856079102
Validation loss: 1.9937656015478156

Epoch: 326| Step: 0
Training loss: 1.1595820188522339
Validation loss: 1.9971167182409635

Epoch: 6| Step: 1
Training loss: 0.8609383702278137
Validation loss: 1.9842484433163878

Epoch: 6| Step: 2
Training loss: 1.2251520156860352
Validation loss: 1.9667872972385858

Epoch: 6| Step: 3
Training loss: 1.4282914400100708
Validation loss: 1.9778108071255427

Epoch: 6| Step: 4
Training loss: 0.5208967924118042
Validation loss: 1.9050952516576296

Epoch: 6| Step: 5
Training loss: 0.8544826507568359
Validation loss: 1.9083731853833763

Epoch: 6| Step: 6
Training loss: 0.6845439672470093
Validation loss: 1.9214213586622668

Epoch: 6| Step: 7
Training loss: 0.591610312461853
Validation loss: 1.9182127303974603

Epoch: 6| Step: 8
Training loss: 0.8059205412864685
Validation loss: 1.9454879401832499

Epoch: 6| Step: 9
Training loss: 1.0587495565414429
Validation loss: 1.890547690852996

Epoch: 6| Step: 10
Training loss: 0.8953460454940796
Validation loss: 1.9393670764020694

Epoch: 6| Step: 11
Training loss: 0.7847746014595032
Validation loss: 1.9204440360428185

Epoch: 6| Step: 12
Training loss: 0.7643657922744751
Validation loss: 1.9652370701554

Epoch: 6| Step: 13
Training loss: 0.9059355854988098
Validation loss: 1.9873375097910564

Epoch: 327| Step: 0
Training loss: 1.0073909759521484
Validation loss: 1.974844713364878

Epoch: 6| Step: 1
Training loss: 1.0745898485183716
Validation loss: 1.9671975553676646

Epoch: 6| Step: 2
Training loss: 1.0631799697875977
Validation loss: 1.9670874239296041

Epoch: 6| Step: 3
Training loss: 0.7146811485290527
Validation loss: 1.9560403875125352

Epoch: 6| Step: 4
Training loss: 1.065061092376709
Validation loss: 1.9221656207115418

Epoch: 6| Step: 5
Training loss: 0.7587787508964539
Validation loss: 1.886723123570924

Epoch: 6| Step: 6
Training loss: 0.7950167059898376
Validation loss: 1.9028122130260672

Epoch: 6| Step: 7
Training loss: 0.5712963342666626
Validation loss: 1.8685431288134666

Epoch: 6| Step: 8
Training loss: 0.7199980020523071
Validation loss: 1.8916743878395326

Epoch: 6| Step: 9
Training loss: 0.8664689064025879
Validation loss: 1.904217145776236

Epoch: 6| Step: 10
Training loss: 1.065323829650879
Validation loss: 1.9551246243138467

Epoch: 6| Step: 11
Training loss: 0.9639781713485718
Validation loss: 2.002785554496191

Epoch: 6| Step: 12
Training loss: 1.0412176847457886
Validation loss: 2.052189668019613

Epoch: 6| Step: 13
Training loss: 0.8180108070373535
Validation loss: 2.058711685160155

Epoch: 328| Step: 0
Training loss: 0.5033290982246399
Validation loss: 2.061520175267291

Epoch: 6| Step: 1
Training loss: 0.9004979133605957
Validation loss: 2.0064273342009513

Epoch: 6| Step: 2
Training loss: 0.7794821262359619
Validation loss: 2.0438854527729813

Epoch: 6| Step: 3
Training loss: 1.4305639266967773
Validation loss: 2.001703639184275

Epoch: 6| Step: 4
Training loss: 0.5156084895133972
Validation loss: 1.9946561962045648

Epoch: 6| Step: 5
Training loss: 0.6279981732368469
Validation loss: 2.0352183042034024

Epoch: 6| Step: 6
Training loss: 0.779852032661438
Validation loss: 1.9924118557283956

Epoch: 6| Step: 7
Training loss: 0.9567167162895203
Validation loss: 1.9579591789553243

Epoch: 6| Step: 8
Training loss: 1.3810840845108032
Validation loss: 1.9952476268173547

Epoch: 6| Step: 9
Training loss: 1.028120994567871
Validation loss: 1.9269294546496483

Epoch: 6| Step: 10
Training loss: 0.6392900347709656
Validation loss: 1.9314181907202608

Epoch: 6| Step: 11
Training loss: 1.573073148727417
Validation loss: 1.9126840278666506

Epoch: 6| Step: 12
Training loss: 0.40066081285476685
Validation loss: 1.9238576517310193

Epoch: 6| Step: 13
Training loss: 0.42267313599586487
Validation loss: 1.904837421191636

Epoch: 329| Step: 0
Training loss: 0.6761414408683777
Validation loss: 1.910574000368836

Epoch: 6| Step: 1
Training loss: 1.5031471252441406
Validation loss: 1.9512986585658083

Epoch: 6| Step: 2
Training loss: 0.9010457992553711
Validation loss: 1.974633893659038

Epoch: 6| Step: 3
Training loss: 0.9374006986618042
Validation loss: 1.9877920868576213

Epoch: 6| Step: 4
Training loss: 0.8663649559020996
Validation loss: 1.9764556474583124

Epoch: 6| Step: 5
Training loss: 0.7291237115859985
Validation loss: 2.0035468916739188

Epoch: 6| Step: 6
Training loss: 1.124485969543457
Validation loss: 2.0146923424095236

Epoch: 6| Step: 7
Training loss: 0.8325328230857849
Validation loss: 1.993677875047089

Epoch: 6| Step: 8
Training loss: 0.5188179612159729
Validation loss: 1.9928768104122532

Epoch: 6| Step: 9
Training loss: 1.1636228561401367
Validation loss: 1.9564453671055455

Epoch: 6| Step: 10
Training loss: 0.769040048122406
Validation loss: 1.9234470218740485

Epoch: 6| Step: 11
Training loss: 0.8863400220870972
Validation loss: 1.8870777135254235

Epoch: 6| Step: 12
Training loss: 0.5865045785903931
Validation loss: 1.8702535924091135

Epoch: 6| Step: 13
Training loss: 0.6869523525238037
Validation loss: 1.892530752766517

Epoch: 330| Step: 0
Training loss: 1.0000860691070557
Validation loss: 1.944041302127223

Epoch: 6| Step: 1
Training loss: 0.9863792657852173
Validation loss: 1.9728498612680743

Epoch: 6| Step: 2
Training loss: 0.880005955696106
Validation loss: 2.014938853120291

Epoch: 6| Step: 3
Training loss: 1.2514193058013916
Validation loss: 2.0084888601815827

Epoch: 6| Step: 4
Training loss: 0.7656456232070923
Validation loss: 2.0447316836285334

Epoch: 6| Step: 5
Training loss: 0.373136967420578
Validation loss: 2.0107564592874176

Epoch: 6| Step: 6
Training loss: 0.6918721199035645
Validation loss: 1.9391819789845457

Epoch: 6| Step: 7
Training loss: 0.756358802318573
Validation loss: 1.9519229165969356

Epoch: 6| Step: 8
Training loss: 1.2404266595840454
Validation loss: 1.8841707526996572

Epoch: 6| Step: 9
Training loss: 0.7896773815155029
Validation loss: 1.8977755423515075

Epoch: 6| Step: 10
Training loss: 0.8315699696540833
Validation loss: 1.8687065980767692

Epoch: 6| Step: 11
Training loss: 1.288383960723877
Validation loss: 1.844207320162045

Epoch: 6| Step: 12
Training loss: 0.6892040371894836
Validation loss: 1.90314047439124

Epoch: 6| Step: 13
Training loss: 0.3621789515018463
Validation loss: 1.9092070838456512

Epoch: 331| Step: 0
Training loss: 0.8350679278373718
Validation loss: 1.9502165266262588

Epoch: 6| Step: 1
Training loss: 1.1347877979278564
Validation loss: 1.9192640807038994

Epoch: 6| Step: 2
Training loss: 0.5496219992637634
Validation loss: 1.9388289143962245

Epoch: 6| Step: 3
Training loss: 0.9457652568817139
Validation loss: 1.9718501670386201

Epoch: 6| Step: 4
Training loss: 0.8235269784927368
Validation loss: 1.9851575884767758

Epoch: 6| Step: 5
Training loss: 0.7812467813491821
Validation loss: 1.931349754333496

Epoch: 6| Step: 6
Training loss: 0.5237484574317932
Validation loss: 1.9478415878870154

Epoch: 6| Step: 7
Training loss: 0.8032554388046265
Validation loss: 1.917215504953938

Epoch: 6| Step: 8
Training loss: 0.6887914538383484
Validation loss: 1.9015670553330453

Epoch: 6| Step: 9
Training loss: 0.7884219884872437
Validation loss: 1.9132302050949426

Epoch: 6| Step: 10
Training loss: 1.0489882230758667
Validation loss: 1.8605688425802416

Epoch: 6| Step: 11
Training loss: 1.0888694524765015
Validation loss: 1.9007550670254616

Epoch: 6| Step: 12
Training loss: 1.3001277446746826
Validation loss: 1.8888905074006768

Epoch: 6| Step: 13
Training loss: 0.6606357097625732
Validation loss: 1.9228967415389193

Epoch: 332| Step: 0
Training loss: 0.8157413005828857
Validation loss: 1.9168742395216418

Epoch: 6| Step: 1
Training loss: 0.7108581066131592
Validation loss: 1.9274449758632208

Epoch: 6| Step: 2
Training loss: 0.5269495844841003
Validation loss: 1.950941877980386

Epoch: 6| Step: 3
Training loss: 0.9173470735549927
Validation loss: 1.9436950747684767

Epoch: 6| Step: 4
Training loss: 0.8289164304733276
Validation loss: 1.9526896989473732

Epoch: 6| Step: 5
Training loss: 0.9256030321121216
Validation loss: 1.968500303965743

Epoch: 6| Step: 6
Training loss: 0.8997796773910522
Validation loss: 1.9613409990905433

Epoch: 6| Step: 7
Training loss: 0.9209930896759033
Validation loss: 1.9743589714009275

Epoch: 6| Step: 8
Training loss: 1.2848917245864868
Validation loss: 1.981599260401982

Epoch: 6| Step: 9
Training loss: 0.6640496253967285
Validation loss: 1.9605042114052722

Epoch: 6| Step: 10
Training loss: 0.9547742605209351
Validation loss: 1.9258120598331574

Epoch: 6| Step: 11
Training loss: 1.0413802862167358
Validation loss: 1.9327154044182069

Epoch: 6| Step: 12
Training loss: 0.8541784882545471
Validation loss: 1.9260464188873128

Epoch: 6| Step: 13
Training loss: 0.5033199787139893
Validation loss: 1.8776870376320296

Epoch: 333| Step: 0
Training loss: 0.45211654901504517
Validation loss: 1.8918117835957518

Epoch: 6| Step: 1
Training loss: 1.3079330921173096
Validation loss: 1.917255881012127

Epoch: 6| Step: 2
Training loss: 0.8170475363731384
Validation loss: 1.913423199807444

Epoch: 6| Step: 3
Training loss: 0.8249806761741638
Validation loss: 1.9236424917815833

Epoch: 6| Step: 4
Training loss: 0.7080198526382446
Validation loss: 1.9874950801172564

Epoch: 6| Step: 5
Training loss: 0.8323243260383606
Validation loss: 1.9417783880746493

Epoch: 6| Step: 6
Training loss: 0.9669512510299683
Validation loss: 1.979807940862512

Epoch: 6| Step: 7
Training loss: 1.3993057012557983
Validation loss: 1.948058884630921

Epoch: 6| Step: 8
Training loss: 0.3670680522918701
Validation loss: 2.001149756934053

Epoch: 6| Step: 9
Training loss: 1.3130054473876953
Validation loss: 1.9536452652305685

Epoch: 6| Step: 10
Training loss: 0.4071565270423889
Validation loss: 1.913764335775888

Epoch: 6| Step: 11
Training loss: 0.7242641448974609
Validation loss: 1.899293844417859

Epoch: 6| Step: 12
Training loss: 0.9837779998779297
Validation loss: 1.885990652986752

Epoch: 6| Step: 13
Training loss: 0.6858664751052856
Validation loss: 1.8746644425135788

Epoch: 334| Step: 0
Training loss: 0.6609501838684082
Validation loss: 1.9112384075759559

Epoch: 6| Step: 1
Training loss: 0.8595545291900635
Validation loss: 1.9244491156711374

Epoch: 6| Step: 2
Training loss: 0.8763817548751831
Validation loss: 1.9278993132293865

Epoch: 6| Step: 3
Training loss: 0.7796987295150757
Validation loss: 1.9406097563364173

Epoch: 6| Step: 4
Training loss: 0.7294450402259827
Validation loss: 1.9262961238943122

Epoch: 6| Step: 5
Training loss: 0.8867394924163818
Validation loss: 1.9495518810005599

Epoch: 6| Step: 6
Training loss: 0.6025987267494202
Validation loss: 2.00270870167722

Epoch: 6| Step: 7
Training loss: 0.726953387260437
Validation loss: 2.001268361204414

Epoch: 6| Step: 8
Training loss: 1.0917718410491943
Validation loss: 1.978648115229863

Epoch: 6| Step: 9
Training loss: 0.999064564704895
Validation loss: 1.98773104657409

Epoch: 6| Step: 10
Training loss: 1.2181410789489746
Validation loss: 1.954241660333449

Epoch: 6| Step: 11
Training loss: 0.6552783846855164
Validation loss: 1.9620375787058184

Epoch: 6| Step: 12
Training loss: 0.6153693199157715
Validation loss: 1.9170669842791814

Epoch: 6| Step: 13
Training loss: 1.1891714334487915
Validation loss: 1.9419467551733858

Epoch: 335| Step: 0
Training loss: 0.7786107063293457
Validation loss: 1.9220402856026926

Epoch: 6| Step: 1
Training loss: 0.8236345052719116
Validation loss: 1.905986680779406

Epoch: 6| Step: 2
Training loss: 0.5098741054534912
Validation loss: 1.9285220830671248

Epoch: 6| Step: 3
Training loss: 1.0216336250305176
Validation loss: 1.9449807533653833

Epoch: 6| Step: 4
Training loss: 0.38833242654800415
Validation loss: 1.9370741382721932

Epoch: 6| Step: 5
Training loss: 0.9104785323143005
Validation loss: 1.9730827795561923

Epoch: 6| Step: 6
Training loss: 1.4378247261047363
Validation loss: 1.9376722587052213

Epoch: 6| Step: 7
Training loss: 0.9509800672531128
Validation loss: 2.0253091114823536

Epoch: 6| Step: 8
Training loss: 1.1434402465820312
Validation loss: 2.0071090088095715

Epoch: 6| Step: 9
Training loss: 0.5969812870025635
Validation loss: 1.9731287033327165

Epoch: 6| Step: 10
Training loss: 0.39718306064605713
Validation loss: 1.96706566374789

Epoch: 6| Step: 11
Training loss: 0.7510550022125244
Validation loss: 1.962786138698619

Epoch: 6| Step: 12
Training loss: 1.4535472393035889
Validation loss: 1.9280505898178264

Epoch: 6| Step: 13
Training loss: 0.40324342250823975
Validation loss: 1.8733026571171258

Epoch: 336| Step: 0
Training loss: 0.7126752138137817
Validation loss: 1.9371809574865526

Epoch: 6| Step: 1
Training loss: 0.6976705193519592
Validation loss: 1.9229250723315823

Epoch: 6| Step: 2
Training loss: 0.6779640913009644
Validation loss: 1.905925387977272

Epoch: 6| Step: 3
Training loss: 0.7641234993934631
Validation loss: 1.943760020758516

Epoch: 6| Step: 4
Training loss: 0.6581602692604065
Validation loss: 1.9404601666235155

Epoch: 6| Step: 5
Training loss: 0.9404996633529663
Validation loss: 1.970552759785806

Epoch: 6| Step: 6
Training loss: 0.4716908037662506
Validation loss: 1.964688789459967

Epoch: 6| Step: 7
Training loss: 0.6525229215621948
Validation loss: 1.984716478214469

Epoch: 6| Step: 8
Training loss: 1.192992925643921
Validation loss: 1.9953702534398725

Epoch: 6| Step: 9
Training loss: 1.0307221412658691
Validation loss: 2.0185970234614548

Epoch: 6| Step: 10
Training loss: 0.8141120672225952
Validation loss: 2.024962276540777

Epoch: 6| Step: 11
Training loss: 1.4183822870254517
Validation loss: 2.0107399494417253

Epoch: 6| Step: 12
Training loss: 1.0034587383270264
Validation loss: 1.996518386307583

Epoch: 6| Step: 13
Training loss: 0.49454084038734436
Validation loss: 1.937821477972051

Epoch: 337| Step: 0
Training loss: 0.7496734261512756
Validation loss: 1.9644568197188839

Epoch: 6| Step: 1
Training loss: 0.794599711894989
Validation loss: 1.9177915357774304

Epoch: 6| Step: 2
Training loss: 0.7846630811691284
Validation loss: 1.9379299379164172

Epoch: 6| Step: 3
Training loss: 0.8517340421676636
Validation loss: 1.919414920191611

Epoch: 6| Step: 4
Training loss: 0.9150461554527283
Validation loss: 1.8957585391177927

Epoch: 6| Step: 5
Training loss: 1.2893260717391968
Validation loss: 1.9127633699806788

Epoch: 6| Step: 6
Training loss: 1.0306029319763184
Validation loss: 1.9230419230717484

Epoch: 6| Step: 7
Training loss: 0.3764899969100952
Validation loss: 1.9339093251894879

Epoch: 6| Step: 8
Training loss: 0.6465179920196533
Validation loss: 1.9382431942929503

Epoch: 6| Step: 9
Training loss: 0.49141252040863037
Validation loss: 1.9628662883594472

Epoch: 6| Step: 10
Training loss: 0.8114519715309143
Validation loss: 1.9336167958474928

Epoch: 6| Step: 11
Training loss: 0.9225778579711914
Validation loss: 1.9791651118186213

Epoch: 6| Step: 12
Training loss: 0.8802206516265869
Validation loss: 1.9710224956594489

Epoch: 6| Step: 13
Training loss: 0.5439721345901489
Validation loss: 1.9592449126705047

Epoch: 338| Step: 0
Training loss: 0.9263307452201843
Validation loss: 1.9486351167002032

Epoch: 6| Step: 1
Training loss: 1.0778093338012695
Validation loss: 1.895591087238763

Epoch: 6| Step: 2
Training loss: 0.6933249235153198
Validation loss: 1.9518195275337464

Epoch: 6| Step: 3
Training loss: 0.7968531250953674
Validation loss: 1.907405863526047

Epoch: 6| Step: 4
Training loss: 0.7146621346473694
Validation loss: 1.8946254061114403

Epoch: 6| Step: 5
Training loss: 0.8887012004852295
Validation loss: 1.9225897058363883

Epoch: 6| Step: 6
Training loss: 0.857513427734375
Validation loss: 1.9343050891353237

Epoch: 6| Step: 7
Training loss: 0.9910494685173035
Validation loss: 1.9152610699335735

Epoch: 6| Step: 8
Training loss: 0.8267303109169006
Validation loss: 1.9219887512986378

Epoch: 6| Step: 9
Training loss: 0.6339573264122009
Validation loss: 1.9289491522696711

Epoch: 6| Step: 10
Training loss: 0.9304707646369934
Validation loss: 1.9217368877062233

Epoch: 6| Step: 11
Training loss: 0.5390445590019226
Validation loss: 1.9062461007025935

Epoch: 6| Step: 12
Training loss: 0.8692465424537659
Validation loss: 1.9254953553599696

Epoch: 6| Step: 13
Training loss: 0.9041580557823181
Validation loss: 1.9305774857920985

Epoch: 339| Step: 0
Training loss: 0.7188979387283325
Validation loss: 1.9478371399705128

Epoch: 6| Step: 1
Training loss: 0.675098717212677
Validation loss: 1.9408586255965694

Epoch: 6| Step: 2
Training loss: 0.9983334541320801
Validation loss: 1.9471132960370792

Epoch: 6| Step: 3
Training loss: 0.49343544244766235
Validation loss: 1.989146783787717

Epoch: 6| Step: 4
Training loss: 1.1139270067214966
Validation loss: 1.9799605672077467

Epoch: 6| Step: 5
Training loss: 0.9064585566520691
Validation loss: 1.9473403064153527

Epoch: 6| Step: 6
Training loss: 0.8078108429908752
Validation loss: 1.979594015306042

Epoch: 6| Step: 7
Training loss: 0.8982911705970764
Validation loss: 1.9281493925279187

Epoch: 6| Step: 8
Training loss: 0.697003960609436
Validation loss: 1.926171930887366

Epoch: 6| Step: 9
Training loss: 0.4318942129611969
Validation loss: 1.956572381399011

Epoch: 6| Step: 10
Training loss: 0.6353657245635986
Validation loss: 1.9458917597288727

Epoch: 6| Step: 11
Training loss: 1.447771430015564
Validation loss: 1.963445645506664

Epoch: 6| Step: 12
Training loss: 0.71247398853302
Validation loss: 1.954523850512761

Epoch: 6| Step: 13
Training loss: 0.8146435618400574
Validation loss: 1.9640203945098385

Epoch: 340| Step: 0
Training loss: 0.8384028673171997
Validation loss: 1.9722348579796412

Epoch: 6| Step: 1
Training loss: 0.8728074431419373
Validation loss: 1.953608871788107

Epoch: 6| Step: 2
Training loss: 0.8146977424621582
Validation loss: 1.9349055956768733

Epoch: 6| Step: 3
Training loss: 0.720279335975647
Validation loss: 1.941130507376886

Epoch: 6| Step: 4
Training loss: 0.6642407178878784
Validation loss: 1.9257294516409598

Epoch: 6| Step: 5
Training loss: 0.7956850528717041
Validation loss: 1.9394605159759521

Epoch: 6| Step: 6
Training loss: 1.050704002380371
Validation loss: 1.9097162010849162

Epoch: 6| Step: 7
Training loss: 1.316819667816162
Validation loss: 1.9172886879213396

Epoch: 6| Step: 8
Training loss: 0.5127423405647278
Validation loss: 1.9620818937978437

Epoch: 6| Step: 9
Training loss: 0.5535227060317993
Validation loss: 1.9475690587874381

Epoch: 6| Step: 10
Training loss: 0.9636969566345215
Validation loss: 1.9637119398322156

Epoch: 6| Step: 11
Training loss: 0.496391624212265
Validation loss: 1.948021235004548

Epoch: 6| Step: 12
Training loss: 1.0127272605895996
Validation loss: 1.893335291134414

Epoch: 6| Step: 13
Training loss: 0.8516424298286438
Validation loss: 1.9140186976361018

Epoch: 341| Step: 0
Training loss: 0.8295153975486755
Validation loss: 1.9360766974828576

Epoch: 6| Step: 1
Training loss: 0.8950101733207703
Validation loss: 1.9345447068573327

Epoch: 6| Step: 2
Training loss: 0.634784460067749
Validation loss: 1.9362346792733798

Epoch: 6| Step: 3
Training loss: 0.7563309669494629
Validation loss: 1.9379326746027956

Epoch: 6| Step: 4
Training loss: 0.6834245920181274
Validation loss: 1.9224710618295977

Epoch: 6| Step: 5
Training loss: 1.0774097442626953
Validation loss: 1.9519918144390147

Epoch: 6| Step: 6
Training loss: 1.1706678867340088
Validation loss: 1.9195464772562827

Epoch: 6| Step: 7
Training loss: 0.5629256367683411
Validation loss: 1.8926718670834777

Epoch: 6| Step: 8
Training loss: 0.5587925910949707
Validation loss: 1.9448376188996017

Epoch: 6| Step: 9
Training loss: 1.2184453010559082
Validation loss: 1.9114402442850091

Epoch: 6| Step: 10
Training loss: 0.6055840849876404
Validation loss: 1.9395978796866633

Epoch: 6| Step: 11
Training loss: 0.9728296995162964
Validation loss: 1.9205249227503294

Epoch: 6| Step: 12
Training loss: 0.46046924591064453
Validation loss: 1.945020979450595

Epoch: 6| Step: 13
Training loss: 0.4470905661582947
Validation loss: 1.9413347244262695

Epoch: 342| Step: 0
Training loss: 0.802812933921814
Validation loss: 1.924676490086381

Epoch: 6| Step: 1
Training loss: 0.7802301645278931
Validation loss: 1.9098597239422541

Epoch: 6| Step: 2
Training loss: 1.1270763874053955
Validation loss: 1.9183097283045452

Epoch: 6| Step: 3
Training loss: 0.6456736326217651
Validation loss: 1.9337807060569845

Epoch: 6| Step: 4
Training loss: 0.7326302528381348
Validation loss: 1.9792644259750203

Epoch: 6| Step: 5
Training loss: 0.5502160787582397
Validation loss: 1.9399982588265532

Epoch: 6| Step: 6
Training loss: 0.752830445766449
Validation loss: 1.9704265107390702

Epoch: 6| Step: 7
Training loss: 0.9600123167037964
Validation loss: 1.9846328817388064

Epoch: 6| Step: 8
Training loss: 0.8850730657577515
Validation loss: 1.9778400082742014

Epoch: 6| Step: 9
Training loss: 0.3293311595916748
Validation loss: 1.9905151462042203

Epoch: 6| Step: 10
Training loss: 0.8644673228263855
Validation loss: 1.992618627445672

Epoch: 6| Step: 11
Training loss: 0.8110994100570679
Validation loss: 1.9617435983432236

Epoch: 6| Step: 12
Training loss: 1.0062114000320435
Validation loss: 1.9443712183224258

Epoch: 6| Step: 13
Training loss: 0.8982300162315369
Validation loss: 1.9457665502384145

Epoch: 343| Step: 0
Training loss: 0.8224548101425171
Validation loss: 1.9182890563882806

Epoch: 6| Step: 1
Training loss: 0.4910529851913452
Validation loss: 1.917471698535386

Epoch: 6| Step: 2
Training loss: 0.6583994626998901
Validation loss: 1.8958819617507279

Epoch: 6| Step: 3
Training loss: 0.7755148410797119
Validation loss: 1.8325124914928148

Epoch: 6| Step: 4
Training loss: 0.6744046211242676
Validation loss: 1.8734083310250313

Epoch: 6| Step: 5
Training loss: 0.9338055849075317
Validation loss: 1.910713598292361

Epoch: 6| Step: 6
Training loss: 1.0145807266235352
Validation loss: 1.8824480220835695

Epoch: 6| Step: 7
Training loss: 0.8022772669792175
Validation loss: 1.9461718067046134

Epoch: 6| Step: 8
Training loss: 0.8503198623657227
Validation loss: 1.980633266510502

Epoch: 6| Step: 9
Training loss: 0.821852445602417
Validation loss: 1.9680525666923934

Epoch: 6| Step: 10
Training loss: 1.239658236503601
Validation loss: 1.98466577452998

Epoch: 6| Step: 11
Training loss: 0.6189590692520142
Validation loss: 1.9740643039826424

Epoch: 6| Step: 12
Training loss: 0.6395138502120972
Validation loss: 1.9612426450175624

Epoch: 6| Step: 13
Training loss: 1.0027501583099365
Validation loss: 1.9593572693486367

Epoch: 344| Step: 0
Training loss: 1.064009428024292
Validation loss: 1.9828273647574968

Epoch: 6| Step: 1
Training loss: 0.8740237951278687
Validation loss: 1.9958058416202504

Epoch: 6| Step: 2
Training loss: 0.8606716394424438
Validation loss: 1.9814032021389212

Epoch: 6| Step: 3
Training loss: 0.7897124290466309
Validation loss: 2.020416182856406

Epoch: 6| Step: 4
Training loss: 0.7123844027519226
Validation loss: 1.9942360642135784

Epoch: 6| Step: 5
Training loss: 0.724911093711853
Validation loss: 1.991075441401492

Epoch: 6| Step: 6
Training loss: 0.9193382263183594
Validation loss: 1.9874271679950017

Epoch: 6| Step: 7
Training loss: 1.0232365131378174
Validation loss: 1.9877224929871098

Epoch: 6| Step: 8
Training loss: 0.6709054112434387
Validation loss: 1.9963275104440668

Epoch: 6| Step: 9
Training loss: 0.9016658067703247
Validation loss: 1.9957820779533797

Epoch: 6| Step: 10
Training loss: 0.7932583093643188
Validation loss: 1.9500032791527369

Epoch: 6| Step: 11
Training loss: 0.6124696731567383
Validation loss: 1.955045243745209

Epoch: 6| Step: 12
Training loss: 0.31187304854393005
Validation loss: 1.9176049975938694

Epoch: 6| Step: 13
Training loss: 0.9360940456390381
Validation loss: 1.9175598595732002

Epoch: 345| Step: 0
Training loss: 0.6747399568557739
Validation loss: 1.9301904478380758

Epoch: 6| Step: 1
Training loss: 0.7802366018295288
Validation loss: 1.915370568152397

Epoch: 6| Step: 2
Training loss: 0.6480310559272766
Validation loss: 1.9789828690149451

Epoch: 6| Step: 3
Training loss: 0.6897196173667908
Validation loss: 1.9846566646329817

Epoch: 6| Step: 4
Training loss: 0.9788333773612976
Validation loss: 1.9813583051004717

Epoch: 6| Step: 5
Training loss: 0.6341009736061096
Validation loss: 1.9878776996366438

Epoch: 6| Step: 6
Training loss: 0.7233115434646606
Validation loss: 1.9663184099299933

Epoch: 6| Step: 7
Training loss: 0.49016237258911133
Validation loss: 1.9357307008517686

Epoch: 6| Step: 8
Training loss: 0.9655832052230835
Validation loss: 1.9479198289173905

Epoch: 6| Step: 9
Training loss: 0.6353264451026917
Validation loss: 1.9121738249255764

Epoch: 6| Step: 10
Training loss: 0.938999593257904
Validation loss: 1.9022752008130472

Epoch: 6| Step: 11
Training loss: 0.9164251089096069
Validation loss: 1.860127825890818

Epoch: 6| Step: 12
Training loss: 1.5314595699310303
Validation loss: 1.8717045873724005

Epoch: 6| Step: 13
Training loss: 0.5301673412322998
Validation loss: 1.7995853872709378

Epoch: 346| Step: 0
Training loss: 1.1918883323669434
Validation loss: 1.8185385145166868

Epoch: 6| Step: 1
Training loss: 0.4947258234024048
Validation loss: 1.8604991025822137

Epoch: 6| Step: 2
Training loss: 0.7779089212417603
Validation loss: 1.8673186776458577

Epoch: 6| Step: 3
Training loss: 0.8832396268844604
Validation loss: 1.9072222389200681

Epoch: 6| Step: 4
Training loss: 0.8205066919326782
Validation loss: 1.9219914572213286

Epoch: 6| Step: 5
Training loss: 0.6288484930992126
Validation loss: 1.976030384340594

Epoch: 6| Step: 6
Training loss: 1.0049233436584473
Validation loss: 1.984159069676553

Epoch: 6| Step: 7
Training loss: 0.6567989587783813
Validation loss: 1.9979675021222842

Epoch: 6| Step: 8
Training loss: 0.6164316534996033
Validation loss: 2.0369676774547947

Epoch: 6| Step: 9
Training loss: 0.7312745451927185
Validation loss: 2.011842220060287

Epoch: 6| Step: 10
Training loss: 0.8632901906967163
Validation loss: 1.9877217661949895

Epoch: 6| Step: 11
Training loss: 0.5737550258636475
Validation loss: 1.9555247150441653

Epoch: 6| Step: 12
Training loss: 0.7630259990692139
Validation loss: 1.9647751623584377

Epoch: 6| Step: 13
Training loss: 1.2217392921447754
Validation loss: 1.8969990566212644

Epoch: 347| Step: 0
Training loss: 1.0180158615112305
Validation loss: 1.857500219857821

Epoch: 6| Step: 1
Training loss: 0.5784503221511841
Validation loss: 1.8962272277442358

Epoch: 6| Step: 2
Training loss: 0.9666744470596313
Validation loss: 1.8824494833587317

Epoch: 6| Step: 3
Training loss: 0.7734165191650391
Validation loss: 1.9050035117774882

Epoch: 6| Step: 4
Training loss: 0.695766806602478
Validation loss: 1.8865440994180658

Epoch: 6| Step: 5
Training loss: 0.8966434001922607
Validation loss: 1.9509135971787155

Epoch: 6| Step: 6
Training loss: 0.6867399215698242
Validation loss: 1.9782794406337123

Epoch: 6| Step: 7
Training loss: 0.8622366786003113
Validation loss: 2.000287732770366

Epoch: 6| Step: 8
Training loss: 0.5335564613342285
Validation loss: 2.003451528087739

Epoch: 6| Step: 9
Training loss: 0.9788419008255005
Validation loss: 1.95411297839175

Epoch: 6| Step: 10
Training loss: 0.4974629878997803
Validation loss: 1.9499626416032032

Epoch: 6| Step: 11
Training loss: 0.5992850065231323
Validation loss: 1.9119575805561517

Epoch: 6| Step: 12
Training loss: 0.8522067070007324
Validation loss: 1.9300185967517156

Epoch: 6| Step: 13
Training loss: 1.2060753107070923
Validation loss: 1.9261196762002923

Epoch: 348| Step: 0
Training loss: 0.7669274210929871
Validation loss: 1.9355394301875946

Epoch: 6| Step: 1
Training loss: 0.5161702632904053
Validation loss: 1.8973781652348016

Epoch: 6| Step: 2
Training loss: 0.700719952583313
Validation loss: 1.9149598178043161

Epoch: 6| Step: 3
Training loss: 0.769455075263977
Validation loss: 1.9001657373161727

Epoch: 6| Step: 4
Training loss: 0.9080192446708679
Validation loss: 1.8989989155082292

Epoch: 6| Step: 5
Training loss: 0.8991544842720032
Validation loss: 1.9227296870241883

Epoch: 6| Step: 6
Training loss: 0.7597261667251587
Validation loss: 1.9249398913434757

Epoch: 6| Step: 7
Training loss: 0.9912125468254089
Validation loss: 1.9241489492436892

Epoch: 6| Step: 8
Training loss: 1.1864643096923828
Validation loss: 1.9376818031393073

Epoch: 6| Step: 9
Training loss: 0.37224364280700684
Validation loss: 1.9026551438916115

Epoch: 6| Step: 10
Training loss: 0.8904610872268677
Validation loss: 1.8877993488824496

Epoch: 6| Step: 11
Training loss: 0.7598055601119995
Validation loss: 1.8794110180229269

Epoch: 6| Step: 12
Training loss: 0.7688149809837341
Validation loss: 1.8812592875572942

Epoch: 6| Step: 13
Training loss: 0.3631713390350342
Validation loss: 1.9139010137127292

Epoch: 349| Step: 0
Training loss: 1.0027683973312378
Validation loss: 1.938829319451445

Epoch: 6| Step: 1
Training loss: 0.6648897528648376
Validation loss: 1.9198214161780573

Epoch: 6| Step: 2
Training loss: 1.0046802759170532
Validation loss: 1.956635062412549

Epoch: 6| Step: 3
Training loss: 0.6404303908348083
Validation loss: 1.9598124693798762

Epoch: 6| Step: 4
Training loss: 0.6221314072608948
Validation loss: 1.9620119781904324

Epoch: 6| Step: 5
Training loss: 0.7490638494491577
Validation loss: 1.9281169304283716

Epoch: 6| Step: 6
Training loss: 1.0547142028808594
Validation loss: 1.9392731292273409

Epoch: 6| Step: 7
Training loss: 0.5370115041732788
Validation loss: 1.9132082103401102

Epoch: 6| Step: 8
Training loss: 0.79234778881073
Validation loss: 1.9328176283067273

Epoch: 6| Step: 9
Training loss: 0.5448211431503296
Validation loss: 1.9262175252360683

Epoch: 6| Step: 10
Training loss: 0.7646865844726562
Validation loss: 1.9098856128672117

Epoch: 6| Step: 11
Training loss: 0.6710635423660278
Validation loss: 1.8901274947709934

Epoch: 6| Step: 12
Training loss: 0.9725555181503296
Validation loss: 1.8666460872978292

Epoch: 6| Step: 13
Training loss: 0.519102156162262
Validation loss: 1.8535572303238737

Epoch: 350| Step: 0
Training loss: 0.946516752243042
Validation loss: 1.8735977193360687

Epoch: 6| Step: 1
Training loss: 0.5530982613563538
Validation loss: 1.9104278600344093

Epoch: 6| Step: 2
Training loss: 0.7447509765625
Validation loss: 1.9193524211965582

Epoch: 6| Step: 3
Training loss: 0.7558490037918091
Validation loss: 1.892232830806445

Epoch: 6| Step: 4
Training loss: 0.7379443645477295
Validation loss: 1.9248688759342316

Epoch: 6| Step: 5
Training loss: 0.8959593772888184
Validation loss: 1.9322174223520423

Epoch: 6| Step: 6
Training loss: 0.6931071281433105
Validation loss: 1.8903118205326859

Epoch: 6| Step: 7
Training loss: 0.5150671005249023
Validation loss: 1.9117280680646178

Epoch: 6| Step: 8
Training loss: 0.960891604423523
Validation loss: 1.9085185194528231

Epoch: 6| Step: 9
Training loss: 0.774982213973999
Validation loss: 1.9333250176522039

Epoch: 6| Step: 10
Training loss: 0.637082040309906
Validation loss: 1.9315039739813855

Epoch: 6| Step: 11
Training loss: 0.9375113248825073
Validation loss: 1.9370041893374534

Epoch: 6| Step: 12
Training loss: 0.841171145439148
Validation loss: 1.9297451203869236

Epoch: 6| Step: 13
Training loss: 0.4910992383956909
Validation loss: 1.9410230600705711

Epoch: 351| Step: 0
Training loss: 0.719623327255249
Validation loss: 1.9245465763153569

Epoch: 6| Step: 1
Training loss: 0.8807847499847412
Validation loss: 1.9628703568571357

Epoch: 6| Step: 2
Training loss: 0.5319294929504395
Validation loss: 1.928193235910067

Epoch: 6| Step: 3
Training loss: 0.6288406848907471
Validation loss: 1.8565403056401077

Epoch: 6| Step: 4
Training loss: 0.7852126359939575
Validation loss: 1.9280807074680124

Epoch: 6| Step: 5
Training loss: 0.8756877779960632
Validation loss: 1.887483186619256

Epoch: 6| Step: 6
Training loss: 1.1294238567352295
Validation loss: 1.849849142054076

Epoch: 6| Step: 7
Training loss: 0.652780294418335
Validation loss: 1.9009150382011168

Epoch: 6| Step: 8
Training loss: 0.543056309223175
Validation loss: 1.898103719116539

Epoch: 6| Step: 9
Training loss: 0.6381767988204956
Validation loss: 1.9112606407493673

Epoch: 6| Step: 10
Training loss: 0.6743514537811279
Validation loss: 1.934234647340672

Epoch: 6| Step: 11
Training loss: 1.3135147094726562
Validation loss: 1.8906513311529671

Epoch: 6| Step: 12
Training loss: 0.7293320298194885
Validation loss: 1.9618709420645108

Epoch: 6| Step: 13
Training loss: 0.2478880137205124
Validation loss: 1.922638907227465

Epoch: 352| Step: 0
Training loss: 0.49614372849464417
Validation loss: 1.8951876112209853

Epoch: 6| Step: 1
Training loss: 0.9178058505058289
Validation loss: 1.9208803561425978

Epoch: 6| Step: 2
Training loss: 0.6864549517631531
Validation loss: 1.9308017735840173

Epoch: 6| Step: 3
Training loss: 0.3571435809135437
Validation loss: 1.9682410699065014

Epoch: 6| Step: 4
Training loss: 1.0303817987442017
Validation loss: 1.9134924616864932

Epoch: 6| Step: 5
Training loss: 0.7153483033180237
Validation loss: 1.9248729085409513

Epoch: 6| Step: 6
Training loss: 1.5588282346725464
Validation loss: 1.9249850293641448

Epoch: 6| Step: 7
Training loss: 0.636576235294342
Validation loss: 1.950593609963694

Epoch: 6| Step: 8
Training loss: 0.6964613795280457
Validation loss: 1.938010246522965

Epoch: 6| Step: 9
Training loss: 0.6411054730415344
Validation loss: 1.890897589345132

Epoch: 6| Step: 10
Training loss: 0.6337876319885254
Validation loss: 1.8896884815667265

Epoch: 6| Step: 11
Training loss: 0.8602063655853271
Validation loss: 1.900155459680865

Epoch: 6| Step: 12
Training loss: 0.8469236493110657
Validation loss: 1.8757686422717186

Epoch: 6| Step: 13
Training loss: 0.4755324125289917
Validation loss: 1.8746459125190653

Epoch: 353| Step: 0
Training loss: 0.8308811187744141
Validation loss: 1.8838306908966393

Epoch: 6| Step: 1
Training loss: 1.2064051628112793
Validation loss: 1.9307106848685973

Epoch: 6| Step: 2
Training loss: 0.42520180344581604
Validation loss: 1.9819677901524368

Epoch: 6| Step: 3
Training loss: 0.6320106387138367
Validation loss: 1.9576679224609046

Epoch: 6| Step: 4
Training loss: 0.6767178773880005
Validation loss: 1.992354073832112

Epoch: 6| Step: 5
Training loss: 0.8167051672935486
Validation loss: 1.9699989505993423

Epoch: 6| Step: 6
Training loss: 1.1749012470245361
Validation loss: 1.9890114415076472

Epoch: 6| Step: 7
Training loss: 0.6059630513191223
Validation loss: 1.954886390316871

Epoch: 6| Step: 8
Training loss: 0.7898792028427124
Validation loss: 1.9177463029020576

Epoch: 6| Step: 9
Training loss: 0.44735750555992126
Validation loss: 1.9291954501982658

Epoch: 6| Step: 10
Training loss: 0.7186779975891113
Validation loss: 1.9069863762906802

Epoch: 6| Step: 11
Training loss: 0.9084435105323792
Validation loss: 1.9257957717423797

Epoch: 6| Step: 12
Training loss: 0.6115764379501343
Validation loss: 1.8810944762281192

Epoch: 6| Step: 13
Training loss: 0.4211031198501587
Validation loss: 1.9071680743207213

Epoch: 354| Step: 0
Training loss: 0.5171933174133301
Validation loss: 1.8810340678820046

Epoch: 6| Step: 1
Training loss: 0.48380330204963684
Validation loss: 1.8800933976327219

Epoch: 6| Step: 2
Training loss: 0.6138345003128052
Validation loss: 1.8656872472455424

Epoch: 6| Step: 3
Training loss: 0.662299394607544
Validation loss: 1.8837396483267508

Epoch: 6| Step: 4
Training loss: 0.865612268447876
Validation loss: 1.9056512386568132

Epoch: 6| Step: 5
Training loss: 0.9838967323303223
Validation loss: 1.9246726548799904

Epoch: 6| Step: 6
Training loss: 0.8730509877204895
Validation loss: 1.9454071855032316

Epoch: 6| Step: 7
Training loss: 1.0411655902862549
Validation loss: 2.0189926137206373

Epoch: 6| Step: 8
Training loss: 0.5847039222717285
Validation loss: 1.9850825571244763

Epoch: 6| Step: 9
Training loss: 0.6992071866989136
Validation loss: 1.9375427794712845

Epoch: 6| Step: 10
Training loss: 0.9636468887329102
Validation loss: 1.9374974414866457

Epoch: 6| Step: 11
Training loss: 0.7252237796783447
Validation loss: 1.9435784970560381

Epoch: 6| Step: 12
Training loss: 0.5759320259094238
Validation loss: 1.8705823485569288

Epoch: 6| Step: 13
Training loss: 0.9549453258514404
Validation loss: 1.850494747520775

Epoch: 355| Step: 0
Training loss: 0.8475781083106995
Validation loss: 1.8775806273183515

Epoch: 6| Step: 1
Training loss: 1.042540192604065
Validation loss: 1.8386929676096926

Epoch: 6| Step: 2
Training loss: 0.6879532337188721
Validation loss: 1.832375890465193

Epoch: 6| Step: 3
Training loss: 1.1179336309432983
Validation loss: 1.8101671485490696

Epoch: 6| Step: 4
Training loss: 0.6007047891616821
Validation loss: 1.8563438935946392

Epoch: 6| Step: 5
Training loss: 0.702241063117981
Validation loss: 1.8592264280524304

Epoch: 6| Step: 6
Training loss: 0.3540007174015045
Validation loss: 1.8850550856641544

Epoch: 6| Step: 7
Training loss: 0.33050698041915894
Validation loss: 1.9206971635100663

Epoch: 6| Step: 8
Training loss: 0.8754806518554688
Validation loss: 1.9860279201179423

Epoch: 6| Step: 9
Training loss: 0.5432495474815369
Validation loss: 2.008405791815891

Epoch: 6| Step: 10
Training loss: 0.7767505049705505
Validation loss: 1.9701486274760256

Epoch: 6| Step: 11
Training loss: 1.1213617324829102
Validation loss: 1.9738353067828762

Epoch: 6| Step: 12
Training loss: 0.9112845659255981
Validation loss: 1.9703012717667447

Epoch: 6| Step: 13
Training loss: 0.6099978685379028
Validation loss: 1.9682926042105562

Epoch: 356| Step: 0
Training loss: 0.7914258241653442
Validation loss: 1.9226776041010374

Epoch: 6| Step: 1
Training loss: 1.0137114524841309
Validation loss: 1.8686682754947292

Epoch: 6| Step: 2
Training loss: 0.7567886710166931
Validation loss: 1.8542095640654206

Epoch: 6| Step: 3
Training loss: 0.5392055511474609
Validation loss: 1.8730818430582683

Epoch: 6| Step: 4
Training loss: 0.9867415428161621
Validation loss: 1.820523827306686

Epoch: 6| Step: 5
Training loss: 0.9525642395019531
Validation loss: 1.8620117197754562

Epoch: 6| Step: 6
Training loss: 0.7437028884887695
Validation loss: 1.8591465847466582

Epoch: 6| Step: 7
Training loss: 0.7587907314300537
Validation loss: 1.8779368695392404

Epoch: 6| Step: 8
Training loss: 0.8658706545829773
Validation loss: 1.8498295878851285

Epoch: 6| Step: 9
Training loss: 0.508112907409668
Validation loss: 1.8539580119553434

Epoch: 6| Step: 10
Training loss: 0.5768928527832031
Validation loss: 1.8721021862440212

Epoch: 6| Step: 11
Training loss: 0.5742285847663879
Validation loss: 1.8897791998360747

Epoch: 6| Step: 12
Training loss: 0.7291254997253418
Validation loss: 1.9303866387695394

Epoch: 6| Step: 13
Training loss: 0.3367394804954529
Validation loss: 1.9307888336079095

Epoch: 357| Step: 0
Training loss: 1.1149582862854004
Validation loss: 1.9877173208421277

Epoch: 6| Step: 1
Training loss: 0.7669934630393982
Validation loss: 2.008185061075354

Epoch: 6| Step: 2
Training loss: 0.8797614574432373
Validation loss: 2.0231878988204466

Epoch: 6| Step: 3
Training loss: 0.8174877762794495
Validation loss: 1.9930904296136671

Epoch: 6| Step: 4
Training loss: 0.8200833201408386
Validation loss: 2.009494632802984

Epoch: 6| Step: 5
Training loss: 0.8922514319419861
Validation loss: 1.9352197980368009

Epoch: 6| Step: 6
Training loss: 0.20101889967918396
Validation loss: 1.929065917127876

Epoch: 6| Step: 7
Training loss: 0.4713953137397766
Validation loss: 1.8338986039161682

Epoch: 6| Step: 8
Training loss: 0.5379904508590698
Validation loss: 1.8522192573034635

Epoch: 6| Step: 9
Training loss: 1.1701486110687256
Validation loss: 1.8340569132117814

Epoch: 6| Step: 10
Training loss: 0.37771305441856384
Validation loss: 1.8235282654403357

Epoch: 6| Step: 11
Training loss: 1.0814504623413086
Validation loss: 1.8420032929348689

Epoch: 6| Step: 12
Training loss: 0.9963376522064209
Validation loss: 1.863399153114647

Epoch: 6| Step: 13
Training loss: 0.4779714047908783
Validation loss: 1.880632968359096

Epoch: 358| Step: 0
Training loss: 0.9182899594306946
Validation loss: 1.8965740460221485

Epoch: 6| Step: 1
Training loss: 0.7877116799354553
Validation loss: 1.917960327158692

Epoch: 6| Step: 2
Training loss: 0.8689316511154175
Validation loss: 1.920648149264756

Epoch: 6| Step: 3
Training loss: 0.5373778343200684
Validation loss: 1.9460391959836405

Epoch: 6| Step: 4
Training loss: 0.6043525338172913
Validation loss: 1.9109156413744854

Epoch: 6| Step: 5
Training loss: 0.9986076951026917
Validation loss: 1.9533299733233709

Epoch: 6| Step: 6
Training loss: 0.7806576490402222
Validation loss: 1.962666444880988

Epoch: 6| Step: 7
Training loss: 0.5005497336387634
Validation loss: 1.9234028618822816

Epoch: 6| Step: 8
Training loss: 0.6210852861404419
Validation loss: 1.9039760456290296

Epoch: 6| Step: 9
Training loss: 0.8825895190238953
Validation loss: 1.8957155750643822

Epoch: 6| Step: 10
Training loss: 0.65735924243927
Validation loss: 1.9443158744483866

Epoch: 6| Step: 11
Training loss: 0.7931598424911499
Validation loss: 1.9095332007254324

Epoch: 6| Step: 12
Training loss: 0.6894558072090149
Validation loss: 1.918420018688325

Epoch: 6| Step: 13
Training loss: 0.7712181806564331
Validation loss: 1.9448468608240927

Epoch: 359| Step: 0
Training loss: 0.5346354842185974
Validation loss: 1.9276555725323257

Epoch: 6| Step: 1
Training loss: 0.8663289546966553
Validation loss: 1.9394202245179044

Epoch: 6| Step: 2
Training loss: 0.5720966458320618
Validation loss: 1.9678587887876777

Epoch: 6| Step: 3
Training loss: 0.5865834951400757
Validation loss: 1.9637440096947454

Epoch: 6| Step: 4
Training loss: 0.8917057514190674
Validation loss: 1.9519415888735043

Epoch: 6| Step: 5
Training loss: 0.8993800282478333
Validation loss: 1.9322735391637331

Epoch: 6| Step: 6
Training loss: 0.9569391012191772
Validation loss: 1.9125995405258671

Epoch: 6| Step: 7
Training loss: 0.48466622829437256
Validation loss: 1.9348919417268486

Epoch: 6| Step: 8
Training loss: 0.7826311588287354
Validation loss: 1.8826616284667805

Epoch: 6| Step: 9
Training loss: 0.6000980138778687
Validation loss: 1.898166960285556

Epoch: 6| Step: 10
Training loss: 0.5900170207023621
Validation loss: 1.8996864031719904

Epoch: 6| Step: 11
Training loss: 0.6705503463745117
Validation loss: 1.9260239537044237

Epoch: 6| Step: 12
Training loss: 0.7689889669418335
Validation loss: 1.9010684105657762

Epoch: 6| Step: 13
Training loss: 0.9412446618080139
Validation loss: 1.8710153307966007

Epoch: 360| Step: 0
Training loss: 0.613664984703064
Validation loss: 1.901897963657174

Epoch: 6| Step: 1
Training loss: 0.6105089783668518
Validation loss: 1.887982004432268

Epoch: 6| Step: 2
Training loss: 0.4573434889316559
Validation loss: 1.8755957131744714

Epoch: 6| Step: 3
Training loss: 0.749885618686676
Validation loss: 1.852834399028491

Epoch: 6| Step: 4
Training loss: 0.8238544464111328
Validation loss: 1.8842835913422287

Epoch: 6| Step: 5
Training loss: 0.7923869490623474
Validation loss: 1.918450076092956

Epoch: 6| Step: 6
Training loss: 0.888587236404419
Validation loss: 1.8741016541757891

Epoch: 6| Step: 7
Training loss: 0.5014676451683044
Validation loss: 1.9067466079547841

Epoch: 6| Step: 8
Training loss: 1.0186762809753418
Validation loss: 1.934456802183582

Epoch: 6| Step: 9
Training loss: 0.5735954642295837
Validation loss: 1.9139509354868243

Epoch: 6| Step: 10
Training loss: 0.8195968866348267
Validation loss: 1.9525174299875896

Epoch: 6| Step: 11
Training loss: 0.5067861080169678
Validation loss: 1.9782416666707685

Epoch: 6| Step: 12
Training loss: 0.8688175678253174
Validation loss: 1.9472406615493119

Epoch: 6| Step: 13
Training loss: 0.8254007697105408
Validation loss: 1.934963865946698

Epoch: 361| Step: 0
Training loss: 0.9334352016448975
Validation loss: 1.9412825748484621

Epoch: 6| Step: 1
Training loss: 0.9934550523757935
Validation loss: 1.924377982334424

Epoch: 6| Step: 2
Training loss: 0.7118432521820068
Validation loss: 1.941338732678403

Epoch: 6| Step: 3
Training loss: 0.6277607679367065
Validation loss: 1.9355690838188253

Epoch: 6| Step: 4
Training loss: 0.43589985370635986
Validation loss: 1.9317467674132316

Epoch: 6| Step: 5
Training loss: 0.8903266191482544
Validation loss: 1.914081613222758

Epoch: 6| Step: 6
Training loss: 0.6352840065956116
Validation loss: 1.891504890175276

Epoch: 6| Step: 7
Training loss: 0.6236066222190857
Validation loss: 1.9131959202469035

Epoch: 6| Step: 8
Training loss: 0.3828594386577606
Validation loss: 1.905686855316162

Epoch: 6| Step: 9
Training loss: 0.43336230516433716
Validation loss: 1.936031376161883

Epoch: 6| Step: 10
Training loss: 0.9103628396987915
Validation loss: 1.9382669220688522

Epoch: 6| Step: 11
Training loss: 0.9580429792404175
Validation loss: 1.9159591069785498

Epoch: 6| Step: 12
Training loss: 0.7990738153457642
Validation loss: 1.929047622988301

Epoch: 6| Step: 13
Training loss: 0.5400254726409912
Validation loss: 1.9597957416247296

Epoch: 362| Step: 0
Training loss: 0.7100681066513062
Validation loss: 1.8901084917847828

Epoch: 6| Step: 1
Training loss: 0.8398463129997253
Validation loss: 1.887018516499509

Epoch: 6| Step: 2
Training loss: 0.7803530097007751
Validation loss: 1.8588286907442155

Epoch: 6| Step: 3
Training loss: 0.24254930019378662
Validation loss: 1.8389643187163978

Epoch: 6| Step: 4
Training loss: 1.255476951599121
Validation loss: 1.8632781454311904

Epoch: 6| Step: 5
Training loss: 0.5744882822036743
Validation loss: 1.8765331340092484

Epoch: 6| Step: 6
Training loss: 0.9453212022781372
Validation loss: 1.85208095530028

Epoch: 6| Step: 7
Training loss: 0.5160670280456543
Validation loss: 1.8875670227953183

Epoch: 6| Step: 8
Training loss: 1.122018814086914
Validation loss: 1.901290693590718

Epoch: 6| Step: 9
Training loss: 0.6058018207550049
Validation loss: 1.9035536473797214

Epoch: 6| Step: 10
Training loss: 0.5304481983184814
Validation loss: 1.9233501316398702

Epoch: 6| Step: 11
Training loss: 0.6448580026626587
Validation loss: 1.9327573160971365

Epoch: 6| Step: 12
Training loss: 0.4819425344467163
Validation loss: 1.906993091747325

Epoch: 6| Step: 13
Training loss: 0.8542933464050293
Validation loss: 1.8969230549309843

Epoch: 363| Step: 0
Training loss: 0.7031343579292297
Validation loss: 1.9486553720248643

Epoch: 6| Step: 1
Training loss: 0.6317630410194397
Validation loss: 1.9114576949868152

Epoch: 6| Step: 2
Training loss: 0.5159658789634705
Validation loss: 1.9091029782449045

Epoch: 6| Step: 3
Training loss: 1.1570887565612793
Validation loss: 1.8917526096426032

Epoch: 6| Step: 4
Training loss: 0.7760125398635864
Validation loss: 1.8761696405308221

Epoch: 6| Step: 5
Training loss: 0.5299159288406372
Validation loss: 1.8596373399098713

Epoch: 6| Step: 6
Training loss: 0.699149489402771
Validation loss: 1.8562487991907264

Epoch: 6| Step: 7
Training loss: 0.8519843220710754
Validation loss: 1.8408911830635482

Epoch: 6| Step: 8
Training loss: 0.5781685709953308
Validation loss: 1.871452573807009

Epoch: 6| Step: 9
Training loss: 0.4289894104003906
Validation loss: 1.8927376103657547

Epoch: 6| Step: 10
Training loss: 0.9433951377868652
Validation loss: 1.869255277418321

Epoch: 6| Step: 11
Training loss: 0.7954075336456299
Validation loss: 1.9266299957870154

Epoch: 6| Step: 12
Training loss: 0.6274232864379883
Validation loss: 1.9016194958840646

Epoch: 6| Step: 13
Training loss: 0.5722179412841797
Validation loss: 1.8748980465755667

Epoch: 364| Step: 0
Training loss: 0.6072413921356201
Validation loss: 1.8976345421165548

Epoch: 6| Step: 1
Training loss: 0.5828790068626404
Validation loss: 1.8500868633229246

Epoch: 6| Step: 2
Training loss: 0.7577536106109619
Validation loss: 1.8236554181703957

Epoch: 6| Step: 3
Training loss: 0.6709246635437012
Validation loss: 1.8275323452488068

Epoch: 6| Step: 4
Training loss: 0.33028939366340637
Validation loss: 1.8484273533667288

Epoch: 6| Step: 5
Training loss: 0.793358325958252
Validation loss: 1.8467677408649075

Epoch: 6| Step: 6
Training loss: 0.9472142457962036
Validation loss: 1.8420490975021033

Epoch: 6| Step: 7
Training loss: 0.6439505815505981
Validation loss: 1.8423080034153436

Epoch: 6| Step: 8
Training loss: 1.1831419467926025
Validation loss: 1.8637834646368538

Epoch: 6| Step: 9
Training loss: 0.6385078430175781
Validation loss: 1.9079564450889506

Epoch: 6| Step: 10
Training loss: 0.8357797265052795
Validation loss: 1.9035087836686002

Epoch: 6| Step: 11
Training loss: 0.5475138425827026
Validation loss: 1.9849463214156449

Epoch: 6| Step: 12
Training loss: 0.7388132214546204
Validation loss: 1.9442690418612572

Epoch: 6| Step: 13
Training loss: 0.4755212068557739
Validation loss: 1.9883732731624315

Epoch: 365| Step: 0
Training loss: 0.5471762418746948
Validation loss: 1.9460178959754206

Epoch: 6| Step: 1
Training loss: 0.7580059170722961
Validation loss: 1.905256917399745

Epoch: 6| Step: 2
Training loss: 0.6347085237503052
Validation loss: 1.8885051550403718

Epoch: 6| Step: 3
Training loss: 0.6654291749000549
Validation loss: 1.9116878278793827

Epoch: 6| Step: 4
Training loss: 0.6689348220825195
Validation loss: 1.8845599851300638

Epoch: 6| Step: 5
Training loss: 0.391080379486084
Validation loss: 1.8605825208848523

Epoch: 6| Step: 6
Training loss: 0.739033579826355
Validation loss: 1.8597204326301493

Epoch: 6| Step: 7
Training loss: 1.039998173713684
Validation loss: 1.8572759743659728

Epoch: 6| Step: 8
Training loss: 0.8812929391860962
Validation loss: 1.8680679285398094

Epoch: 6| Step: 9
Training loss: 0.6106488108634949
Validation loss: 1.925259692694551

Epoch: 6| Step: 10
Training loss: 0.817631721496582
Validation loss: 1.8718460285535423

Epoch: 6| Step: 11
Training loss: 0.79057776927948
Validation loss: 1.9011040605524534

Epoch: 6| Step: 12
Training loss: 0.7903921604156494
Validation loss: 1.8922072995093562

Epoch: 6| Step: 13
Training loss: 0.854725182056427
Validation loss: 1.8823998371760051

Epoch: 366| Step: 0
Training loss: 0.9167795181274414
Validation loss: 1.8750197720784012

Epoch: 6| Step: 1
Training loss: 0.5634546875953674
Validation loss: 1.900280842217066

Epoch: 6| Step: 2
Training loss: 0.31328392028808594
Validation loss: 1.8586697911703458

Epoch: 6| Step: 3
Training loss: 0.5037137866020203
Validation loss: 1.866724964111082

Epoch: 6| Step: 4
Training loss: 0.6095853447914124
Validation loss: 1.887102219366258

Epoch: 6| Step: 5
Training loss: 0.7356715202331543
Validation loss: 1.9139395734315277

Epoch: 6| Step: 6
Training loss: 0.9408894777297974
Validation loss: 1.9039646246099984

Epoch: 6| Step: 7
Training loss: 0.7363212704658508
Validation loss: 1.9294789145069737

Epoch: 6| Step: 8
Training loss: 0.6381938457489014
Validation loss: 1.918385398003363

Epoch: 6| Step: 9
Training loss: 0.7007634043693542
Validation loss: 1.8885511736715994

Epoch: 6| Step: 10
Training loss: 0.9376078248023987
Validation loss: 1.8716335758086173

Epoch: 6| Step: 11
Training loss: 0.6895768642425537
Validation loss: 1.8495109100495615

Epoch: 6| Step: 12
Training loss: 0.55433189868927
Validation loss: 1.8551801866100681

Epoch: 6| Step: 13
Training loss: 0.7317553758621216
Validation loss: 1.8225864312982047

Epoch: 367| Step: 0
Training loss: 0.7744815349578857
Validation loss: 1.8071396953316146

Epoch: 6| Step: 1
Training loss: 0.3084639310836792
Validation loss: 1.8493379726204822

Epoch: 6| Step: 2
Training loss: 1.017002820968628
Validation loss: 1.8373209994326356

Epoch: 6| Step: 3
Training loss: 0.7146915197372437
Validation loss: 1.809672865816342

Epoch: 6| Step: 4
Training loss: 0.5631208419799805
Validation loss: 1.8351312093837286

Epoch: 6| Step: 5
Training loss: 0.5073305368423462
Validation loss: 1.849175541631637

Epoch: 6| Step: 6
Training loss: 1.2383484840393066
Validation loss: 1.9347300132115681

Epoch: 6| Step: 7
Training loss: 0.4883233904838562
Validation loss: 1.9317999937201058

Epoch: 6| Step: 8
Training loss: 1.1535248756408691
Validation loss: 1.940231055341741

Epoch: 6| Step: 9
Training loss: 0.5701559782028198
Validation loss: 1.930366749404579

Epoch: 6| Step: 10
Training loss: 0.6733839511871338
Validation loss: 1.9773474380534182

Epoch: 6| Step: 11
Training loss: 0.6886605024337769
Validation loss: 1.9358142255454935

Epoch: 6| Step: 12
Training loss: 0.7577928304672241
Validation loss: 1.941509109671398

Epoch: 6| Step: 13
Training loss: 0.1852819323539734
Validation loss: 1.9198191909379856

Epoch: 368| Step: 0
Training loss: 0.5632180571556091
Validation loss: 1.8775637367720246

Epoch: 6| Step: 1
Training loss: 0.5219864845275879
Validation loss: 1.8466653798216133

Epoch: 6| Step: 2
Training loss: 0.4910992980003357
Validation loss: 1.7889662942578715

Epoch: 6| Step: 3
Training loss: 0.8154160976409912
Validation loss: 1.7725455607137373

Epoch: 6| Step: 4
Training loss: 0.7548189163208008
Validation loss: 1.8358072273192867

Epoch: 6| Step: 5
Training loss: 0.8349521160125732
Validation loss: 1.82384907045672

Epoch: 6| Step: 6
Training loss: 0.6122622489929199
Validation loss: 1.7951153632133239

Epoch: 6| Step: 7
Training loss: 0.5811150074005127
Validation loss: 1.8741569031951248

Epoch: 6| Step: 8
Training loss: 1.0683010816574097
Validation loss: 1.9117331812458653

Epoch: 6| Step: 9
Training loss: 0.6321545243263245
Validation loss: 1.934139370918274

Epoch: 6| Step: 10
Training loss: 0.9034081697463989
Validation loss: 1.8879715857967254

Epoch: 6| Step: 11
Training loss: 0.7583687901496887
Validation loss: 1.886083665714469

Epoch: 6| Step: 12
Training loss: 0.6177141666412354
Validation loss: 1.8290513971800446

Epoch: 6| Step: 13
Training loss: 0.8079502582550049
Validation loss: 1.8391127099273026

Epoch: 369| Step: 0
Training loss: 0.8724921345710754
Validation loss: 1.8240379697533065

Epoch: 6| Step: 1
Training loss: 0.9052180051803589
Validation loss: 1.867158870543203

Epoch: 6| Step: 2
Training loss: 0.6897437572479248
Validation loss: 1.8435990925758117

Epoch: 6| Step: 3
Training loss: 0.9856632947921753
Validation loss: 1.856645473869898

Epoch: 6| Step: 4
Training loss: 0.8079361319541931
Validation loss: 1.8571840973310574

Epoch: 6| Step: 5
Training loss: 0.8783603310585022
Validation loss: 1.8531116529177594

Epoch: 6| Step: 6
Training loss: 0.611668586730957
Validation loss: 1.8759419456604989

Epoch: 6| Step: 7
Training loss: 0.7332357168197632
Validation loss: 1.8955954851642731

Epoch: 6| Step: 8
Training loss: 0.3379622995853424
Validation loss: 1.8860009690766693

Epoch: 6| Step: 9
Training loss: 0.47088760137557983
Validation loss: 1.8324409889918503

Epoch: 6| Step: 10
Training loss: 0.578805685043335
Validation loss: 1.868814545293008

Epoch: 6| Step: 11
Training loss: 0.5279570817947388
Validation loss: 1.8748022458886588

Epoch: 6| Step: 12
Training loss: 0.5077903270721436
Validation loss: 1.8278494816954418

Epoch: 6| Step: 13
Training loss: 0.4689927101135254
Validation loss: 1.9040674881268573

Epoch: 370| Step: 0
Training loss: 0.4551719129085541
Validation loss: 1.86461438158507

Epoch: 6| Step: 1
Training loss: 0.522223949432373
Validation loss: 1.87105518515392

Epoch: 6| Step: 2
Training loss: 0.5546926259994507
Validation loss: 1.8619731318566106

Epoch: 6| Step: 3
Training loss: 0.42713814973831177
Validation loss: 1.8068953137243948

Epoch: 6| Step: 4
Training loss: 1.057512640953064
Validation loss: 1.8458058526439052

Epoch: 6| Step: 5
Training loss: 0.4948350787162781
Validation loss: 1.8583272131540443

Epoch: 6| Step: 6
Training loss: 0.3861374855041504
Validation loss: 1.8996944760763517

Epoch: 6| Step: 7
Training loss: 0.931018590927124
Validation loss: 1.9205265237439064

Epoch: 6| Step: 8
Training loss: 0.5583372116088867
Validation loss: 1.9154989386117587

Epoch: 6| Step: 9
Training loss: 0.5351327657699585
Validation loss: 1.888532910295712

Epoch: 6| Step: 10
Training loss: 1.1830631494522095
Validation loss: 1.9069550780839817

Epoch: 6| Step: 11
Training loss: 0.943546712398529
Validation loss: 1.8877643744150798

Epoch: 6| Step: 12
Training loss: 0.6325691938400269
Validation loss: 1.8757942222779798

Epoch: 6| Step: 13
Training loss: 0.7924589514732361
Validation loss: 1.8744508720213366

Epoch: 371| Step: 0
Training loss: 1.0300848484039307
Validation loss: 1.8744439207097536

Epoch: 6| Step: 1
Training loss: 0.49313026666641235
Validation loss: 1.82205242495383

Epoch: 6| Step: 2
Training loss: 0.6367228627204895
Validation loss: 1.837018971802086

Epoch: 6| Step: 3
Training loss: 0.4927412271499634
Validation loss: 1.8235987386395853

Epoch: 6| Step: 4
Training loss: 0.5939441919326782
Validation loss: 1.7586655168123142

Epoch: 6| Step: 5
Training loss: 0.5824044942855835
Validation loss: 1.8073681913396364

Epoch: 6| Step: 6
Training loss: 0.6639046669006348
Validation loss: 1.8320556968771002

Epoch: 6| Step: 7
Training loss: 0.8252935409545898
Validation loss: 1.8100305616214711

Epoch: 6| Step: 8
Training loss: 0.6036643981933594
Validation loss: 1.8686200264961488

Epoch: 6| Step: 9
Training loss: 0.6944705843925476
Validation loss: 1.8805763977830128

Epoch: 6| Step: 10
Training loss: 0.45503801107406616
Validation loss: 1.894002955446961

Epoch: 6| Step: 11
Training loss: 0.822530210018158
Validation loss: 1.959093233590485

Epoch: 6| Step: 12
Training loss: 0.7918184399604797
Validation loss: 1.9824034449874715

Epoch: 6| Step: 13
Training loss: 0.4923924207687378
Validation loss: 1.9519269389490927

Epoch: 372| Step: 0
Training loss: 0.7165908217430115
Validation loss: 1.9310561777443014

Epoch: 6| Step: 1
Training loss: 0.7526360750198364
Validation loss: 1.9103044079196068

Epoch: 6| Step: 2
Training loss: 0.6254986524581909
Validation loss: 1.8815006581685876

Epoch: 6| Step: 3
Training loss: 0.8192998170852661
Validation loss: 1.8696753030182214

Epoch: 6| Step: 4
Training loss: 0.6474766731262207
Validation loss: 1.8703447490610101

Epoch: 6| Step: 5
Training loss: 0.39387404918670654
Validation loss: 1.841965352335284

Epoch: 6| Step: 6
Training loss: 0.8020229339599609
Validation loss: 1.8392473574607604

Epoch: 6| Step: 7
Training loss: 0.614490270614624
Validation loss: 1.8533251029188915

Epoch: 6| Step: 8
Training loss: 0.7653734683990479
Validation loss: 1.8670580387115479

Epoch: 6| Step: 9
Training loss: 0.47090500593185425
Validation loss: 1.9181294454041349

Epoch: 6| Step: 10
Training loss: 0.7540876865386963
Validation loss: 1.9459717863349504

Epoch: 6| Step: 11
Training loss: 0.5143956542015076
Validation loss: 1.9221657681208786

Epoch: 6| Step: 12
Training loss: 0.6926342248916626
Validation loss: 1.9285501228865756

Epoch: 6| Step: 13
Training loss: 0.694203794002533
Validation loss: 1.926891860141549

Epoch: 373| Step: 0
Training loss: 0.9857017993927002
Validation loss: 1.9270089416093723

Epoch: 6| Step: 1
Training loss: 0.788145899772644
Validation loss: 1.9152034674921343

Epoch: 6| Step: 2
Training loss: 0.6594586372375488
Validation loss: 1.9032983138997068

Epoch: 6| Step: 3
Training loss: 0.567815363407135
Validation loss: 1.8784037892536452

Epoch: 6| Step: 4
Training loss: 0.613409161567688
Validation loss: 1.8473330954069733

Epoch: 6| Step: 5
Training loss: 0.7198764085769653
Validation loss: 1.8438155984365812

Epoch: 6| Step: 6
Training loss: 0.3834682106971741
Validation loss: 1.8382853795123357

Epoch: 6| Step: 7
Training loss: 0.5053178071975708
Validation loss: 1.8401645768073298

Epoch: 6| Step: 8
Training loss: 0.6080922484397888
Validation loss: 1.8411440951849825

Epoch: 6| Step: 9
Training loss: 0.8248165249824524
Validation loss: 1.8691044058851016

Epoch: 6| Step: 10
Training loss: 0.5643507242202759
Validation loss: 1.8678206128458823

Epoch: 6| Step: 11
Training loss: 0.6591668128967285
Validation loss: 1.8841568013673187

Epoch: 6| Step: 12
Training loss: 0.6649721264839172
Validation loss: 1.851776692175096

Epoch: 6| Step: 13
Training loss: 0.5518467426300049
Validation loss: 1.8731547517161216

Epoch: 374| Step: 0
Training loss: 0.5990622043609619
Validation loss: 1.8794556458791096

Epoch: 6| Step: 1
Training loss: 0.5530269742012024
Validation loss: 1.9065812095519035

Epoch: 6| Step: 2
Training loss: 1.1058790683746338
Validation loss: 1.8839150192917034

Epoch: 6| Step: 3
Training loss: 0.41101065278053284
Validation loss: 1.942089790939003

Epoch: 6| Step: 4
Training loss: 0.5843636989593506
Validation loss: 1.9094275889858123

Epoch: 6| Step: 5
Training loss: 0.6634940505027771
Validation loss: 1.9345242002958893

Epoch: 6| Step: 6
Training loss: 0.7009854316711426
Validation loss: 1.9682154450365292

Epoch: 6| Step: 7
Training loss: 1.1603862047195435
Validation loss: 1.9376875726125573

Epoch: 6| Step: 8
Training loss: 0.5307076573371887
Validation loss: 1.9816162252938876

Epoch: 6| Step: 9
Training loss: 0.530940592288971
Validation loss: 1.91955735862896

Epoch: 6| Step: 10
Training loss: 0.6640335321426392
Validation loss: 1.9210909720390075

Epoch: 6| Step: 11
Training loss: 0.6316435933113098
Validation loss: 1.8787133828286202

Epoch: 6| Step: 12
Training loss: 0.6522493958473206
Validation loss: 1.8520188587968067

Epoch: 6| Step: 13
Training loss: 0.48321977257728577
Validation loss: 1.865267019118032

Epoch: 375| Step: 0
Training loss: 0.5967881679534912
Validation loss: 1.8467652861789992

Epoch: 6| Step: 1
Training loss: 0.9115620851516724
Validation loss: 1.855941076432505

Epoch: 6| Step: 2
Training loss: 0.3654952347278595
Validation loss: 1.843529688414707

Epoch: 6| Step: 3
Training loss: 0.7136183381080627
Validation loss: 1.8473223614436325

Epoch: 6| Step: 4
Training loss: 0.4410857558250427
Validation loss: 1.8912854169004707

Epoch: 6| Step: 5
Training loss: 0.5439144968986511
Validation loss: 1.8455618030281478

Epoch: 6| Step: 6
Training loss: 0.7936221361160278
Validation loss: 1.8778977060830722

Epoch: 6| Step: 7
Training loss: 0.7933474183082581
Validation loss: 1.9166306731521443

Epoch: 6| Step: 8
Training loss: 0.44357141852378845
Validation loss: 1.9509175182670675

Epoch: 6| Step: 9
Training loss: 0.5736536979675293
Validation loss: 1.929008387750195

Epoch: 6| Step: 10
Training loss: 0.4693000018596649
Validation loss: 1.9571130044998661

Epoch: 6| Step: 11
Training loss: 0.7968418598175049
Validation loss: 1.9372195953963904

Epoch: 6| Step: 12
Training loss: 0.8596237897872925
Validation loss: 1.8985353157084475

Epoch: 6| Step: 13
Training loss: 0.6318411231040955
Validation loss: 1.8638715897836993

Epoch: 376| Step: 0
Training loss: 0.5102232694625854
Validation loss: 1.8790714497207313

Epoch: 6| Step: 1
Training loss: 0.4690549373626709
Validation loss: 1.851071749964068

Epoch: 6| Step: 2
Training loss: 0.660226583480835
Validation loss: 1.8535611501304052

Epoch: 6| Step: 3
Training loss: 0.6922423839569092
Validation loss: 1.8245872707777127

Epoch: 6| Step: 4
Training loss: 0.3299141526222229
Validation loss: 1.8388622717190815

Epoch: 6| Step: 5
Training loss: 0.9945580959320068
Validation loss: 1.8320508977418304

Epoch: 6| Step: 6
Training loss: 0.6089308261871338
Validation loss: 1.8542077220896238

Epoch: 6| Step: 7
Training loss: 0.4087655544281006
Validation loss: 1.8771382890721804

Epoch: 6| Step: 8
Training loss: 0.9479289054870605
Validation loss: 1.8657538506292528

Epoch: 6| Step: 9
Training loss: 0.7643869519233704
Validation loss: 1.903322910749784

Epoch: 6| Step: 10
Training loss: 0.5184100866317749
Validation loss: 1.855191155146527

Epoch: 6| Step: 11
Training loss: 0.8151078820228577
Validation loss: 1.8712230997700845

Epoch: 6| Step: 12
Training loss: 0.5961147546768188
Validation loss: 1.859389059005245

Epoch: 6| Step: 13
Training loss: 0.9132828116416931
Validation loss: 1.867935420364462

Epoch: 377| Step: 0
Training loss: 0.8299716711044312
Validation loss: 1.8684377221650974

Epoch: 6| Step: 1
Training loss: 0.5636642575263977
Validation loss: 1.8785040199115712

Epoch: 6| Step: 2
Training loss: 0.8430156707763672
Validation loss: 1.8662239172125374

Epoch: 6| Step: 3
Training loss: 0.5626447200775146
Validation loss: 1.8885768280234387

Epoch: 6| Step: 4
Training loss: 0.4323044419288635
Validation loss: 1.9435572496024511

Epoch: 6| Step: 5
Training loss: 0.5089907050132751
Validation loss: 1.9106493867853636

Epoch: 6| Step: 6
Training loss: 0.6262969970703125
Validation loss: 1.8818537804388231

Epoch: 6| Step: 7
Training loss: 0.9035474061965942
Validation loss: 1.8888826318966445

Epoch: 6| Step: 8
Training loss: 0.5312150716781616
Validation loss: 1.9082488193306872

Epoch: 6| Step: 9
Training loss: 0.7642772197723389
Validation loss: 1.8623889774404547

Epoch: 6| Step: 10
Training loss: 0.5825038552284241
Validation loss: 1.8704856006048058

Epoch: 6| Step: 11
Training loss: 0.5499708652496338
Validation loss: 1.8608461182604554

Epoch: 6| Step: 12
Training loss: 0.7144482731819153
Validation loss: 1.8123484196201447

Epoch: 6| Step: 13
Training loss: 0.9057257771492004
Validation loss: 1.7981355344095538

Epoch: 378| Step: 0
Training loss: 0.6316516399383545
Validation loss: 1.7794295485301683

Epoch: 6| Step: 1
Training loss: 0.7161899209022522
Validation loss: 1.74732542550692

Epoch: 6| Step: 2
Training loss: 1.1758383512496948
Validation loss: 1.7516284783681233

Epoch: 6| Step: 3
Training loss: 0.5967129468917847
Validation loss: 1.7529442823061379

Epoch: 6| Step: 4
Training loss: 0.30661070346832275
Validation loss: 1.778042700982863

Epoch: 6| Step: 5
Training loss: 0.7698315382003784
Validation loss: 1.7318673121031893

Epoch: 6| Step: 6
Training loss: 0.485394150018692
Validation loss: 1.7550908327102661

Epoch: 6| Step: 7
Training loss: 0.7675065994262695
Validation loss: 1.7718855898867372

Epoch: 6| Step: 8
Training loss: 0.5019782781600952
Validation loss: 1.7956083500257103

Epoch: 6| Step: 9
Training loss: 0.46227046847343445
Validation loss: 1.8468017526852187

Epoch: 6| Step: 10
Training loss: 0.440512478351593
Validation loss: 1.8821121095329203

Epoch: 6| Step: 11
Training loss: 0.8918232321739197
Validation loss: 1.9429188582205004

Epoch: 6| Step: 12
Training loss: 0.8631945848464966
Validation loss: 1.8704920917428949

Epoch: 6| Step: 13
Training loss: 0.4781269431114197
Validation loss: 1.9534740319816015

Epoch: 379| Step: 0
Training loss: 1.0460058450698853
Validation loss: 1.9225982594233688

Epoch: 6| Step: 1
Training loss: 0.8217950463294983
Validation loss: 1.9261627601039024

Epoch: 6| Step: 2
Training loss: 0.36018699407577515
Validation loss: 1.85962051217274

Epoch: 6| Step: 3
Training loss: 0.6905961036682129
Validation loss: 1.8526144053346367

Epoch: 6| Step: 4
Training loss: 0.22884275019168854
Validation loss: 1.840649160005713

Epoch: 6| Step: 5
Training loss: 1.0280876159667969
Validation loss: 1.8092854304980206

Epoch: 6| Step: 6
Training loss: 0.6284602880477905
Validation loss: 1.8130873069968274

Epoch: 6| Step: 7
Training loss: 0.7227530479431152
Validation loss: 1.7872126256265948

Epoch: 6| Step: 8
Training loss: 0.3415866494178772
Validation loss: 1.8007571133234168

Epoch: 6| Step: 9
Training loss: 0.8278069496154785
Validation loss: 1.8515747580476987

Epoch: 6| Step: 10
Training loss: 0.25240641832351685
Validation loss: 1.8776832549802718

Epoch: 6| Step: 11
Training loss: 0.7043593525886536
Validation loss: 1.8484842802888604

Epoch: 6| Step: 12
Training loss: 0.6205604076385498
Validation loss: 1.8673108880237868

Epoch: 6| Step: 13
Training loss: 0.7148078680038452
Validation loss: 1.8766679020338162

Epoch: 380| Step: 0
Training loss: 0.4971790909767151
Validation loss: 1.8772507713687034

Epoch: 6| Step: 1
Training loss: 0.6397935152053833
Validation loss: 1.906249015561996

Epoch: 6| Step: 2
Training loss: 0.877617359161377
Validation loss: 1.9283444817348192

Epoch: 6| Step: 3
Training loss: 0.762609601020813
Validation loss: 1.8992369303139307

Epoch: 6| Step: 4
Training loss: 0.2927267551422119
Validation loss: 1.8887076980324202

Epoch: 6| Step: 5
Training loss: 0.4903792142868042
Validation loss: 1.8767114057335803

Epoch: 6| Step: 6
Training loss: 0.5244844555854797
Validation loss: 1.840815621037637

Epoch: 6| Step: 7
Training loss: 0.6456494331359863
Validation loss: 1.8744497735013244

Epoch: 6| Step: 8
Training loss: 1.0460264682769775
Validation loss: 1.8705650529553812

Epoch: 6| Step: 9
Training loss: 0.6080361008644104
Validation loss: 1.860132481462212

Epoch: 6| Step: 10
Training loss: 0.6259720325469971
Validation loss: 1.8331144266231085

Epoch: 6| Step: 11
Training loss: 0.44012635946273804
Validation loss: 1.8405000881482196

Epoch: 6| Step: 12
Training loss: 0.7346664071083069
Validation loss: 1.8619577884674072

Epoch: 6| Step: 13
Training loss: 0.4259052276611328
Validation loss: 1.8328366382147676

Epoch: 381| Step: 0
Training loss: 0.7817788124084473
Validation loss: 1.8259620230684999

Epoch: 6| Step: 1
Training loss: 0.45611050724983215
Validation loss: 1.8335383387022122

Epoch: 6| Step: 2
Training loss: 0.6257980465888977
Validation loss: 1.8376212171328965

Epoch: 6| Step: 3
Training loss: 0.5238508582115173
Validation loss: 1.852517452291263

Epoch: 6| Step: 4
Training loss: 0.5969244241714478
Validation loss: 1.8359357874880555

Epoch: 6| Step: 5
Training loss: 0.46042802929878235
Validation loss: 1.8641512419587822

Epoch: 6| Step: 6
Training loss: 0.7300516366958618
Validation loss: 1.8699956311974475

Epoch: 6| Step: 7
Training loss: 0.7281061410903931
Validation loss: 1.9281201439519082

Epoch: 6| Step: 8
Training loss: 0.5967068076133728
Validation loss: 1.840272948306094

Epoch: 6| Step: 9
Training loss: 0.6621716618537903
Validation loss: 1.865237901287694

Epoch: 6| Step: 10
Training loss: 0.6862326264381409
Validation loss: 1.8635999361673992

Epoch: 6| Step: 11
Training loss: 0.7881224155426025
Validation loss: 1.7783808605645293

Epoch: 6| Step: 12
Training loss: 0.613933801651001
Validation loss: 1.7712122573647449

Epoch: 6| Step: 13
Training loss: 0.5207865834236145
Validation loss: 1.7969522732560352

Epoch: 382| Step: 0
Training loss: 0.50700843334198
Validation loss: 1.8087745456285373

Epoch: 6| Step: 1
Training loss: 0.4851749539375305
Validation loss: 1.8159454471321517

Epoch: 6| Step: 2
Training loss: 0.917955756187439
Validation loss: 1.8486047239713772

Epoch: 6| Step: 3
Training loss: 0.6252967119216919
Validation loss: 1.8619793730397378

Epoch: 6| Step: 4
Training loss: 0.6629979014396667
Validation loss: 1.850670664541183

Epoch: 6| Step: 5
Training loss: 0.48200029134750366
Validation loss: 1.8832903421053322

Epoch: 6| Step: 6
Training loss: 0.5336840748786926
Validation loss: 1.8471922592450214

Epoch: 6| Step: 7
Training loss: 0.793759822845459
Validation loss: 1.8808698654174805

Epoch: 6| Step: 8
Training loss: 0.6157523989677429
Validation loss: 1.88498842588035

Epoch: 6| Step: 9
Training loss: 0.2634827792644501
Validation loss: 1.9017470716148295

Epoch: 6| Step: 10
Training loss: 0.890418529510498
Validation loss: 1.8655198697120912

Epoch: 6| Step: 11
Training loss: 0.3655168414115906
Validation loss: 1.8966938564854283

Epoch: 6| Step: 12
Training loss: 0.5110164284706116
Validation loss: 1.842261601519841

Epoch: 6| Step: 13
Training loss: 0.9381589889526367
Validation loss: 1.8139878895974928

Epoch: 383| Step: 0
Training loss: 0.48930835723876953
Validation loss: 1.8255816967256608

Epoch: 6| Step: 1
Training loss: 0.7254701852798462
Validation loss: 1.8007729130406533

Epoch: 6| Step: 2
Training loss: 0.5949358344078064
Validation loss: 1.8088191401573919

Epoch: 6| Step: 3
Training loss: 0.6164816617965698
Validation loss: 1.812624454498291

Epoch: 6| Step: 4
Training loss: 0.2857464551925659
Validation loss: 1.802630796227404

Epoch: 6| Step: 5
Training loss: 0.6781727075576782
Validation loss: 1.8157892842446604

Epoch: 6| Step: 6
Training loss: 0.6805182695388794
Validation loss: 1.850494505256735

Epoch: 6| Step: 7
Training loss: 0.6611064076423645
Validation loss: 1.8759342906295613

Epoch: 6| Step: 8
Training loss: 0.7270753383636475
Validation loss: 1.8109404540831042

Epoch: 6| Step: 9
Training loss: 0.7786942720413208
Validation loss: 1.866291042297117

Epoch: 6| Step: 10
Training loss: 0.6871670484542847
Validation loss: 1.834543885723237

Epoch: 6| Step: 11
Training loss: 0.48246124386787415
Validation loss: 1.8371227249022453

Epoch: 6| Step: 12
Training loss: 0.245557501912117
Validation loss: 1.830227933904176

Epoch: 6| Step: 13
Training loss: 1.1170719861984253
Validation loss: 1.8537025438841952

Epoch: 384| Step: 0
Training loss: 0.8175803422927856
Validation loss: 1.838955577983651

Epoch: 6| Step: 1
Training loss: 0.3862157464027405
Validation loss: 1.8947927054538523

Epoch: 6| Step: 2
Training loss: 0.42594045400619507
Validation loss: 1.8997957539814774

Epoch: 6| Step: 3
Training loss: 0.7051910758018494
Validation loss: 1.9045055335567844

Epoch: 6| Step: 4
Training loss: 0.7064338326454163
Validation loss: 1.9158509162164503

Epoch: 6| Step: 5
Training loss: 0.8527182936668396
Validation loss: 1.900056771052781

Epoch: 6| Step: 6
Training loss: 0.7337489724159241
Validation loss: 1.8844746671697146

Epoch: 6| Step: 7
Training loss: 0.6570430397987366
Validation loss: 1.8235082216160272

Epoch: 6| Step: 8
Training loss: 0.5729993581771851
Validation loss: 1.8200316685502247

Epoch: 6| Step: 9
Training loss: 0.933677613735199
Validation loss: 1.796885859581732

Epoch: 6| Step: 10
Training loss: 0.5841097831726074
Validation loss: 1.7865722153776435

Epoch: 6| Step: 11
Training loss: 0.5959463715553284
Validation loss: 1.809849621147238

Epoch: 6| Step: 12
Training loss: 0.20229199528694153
Validation loss: 1.7955191455861574

Epoch: 6| Step: 13
Training loss: 0.47014209628105164
Validation loss: 1.8187294160166094

Epoch: 385| Step: 0
Training loss: 0.779918909072876
Validation loss: 1.829723793973205

Epoch: 6| Step: 1
Training loss: 0.5430138111114502
Validation loss: 1.8172134353268532

Epoch: 6| Step: 2
Training loss: 1.0376973152160645
Validation loss: 1.8212812844143118

Epoch: 6| Step: 3
Training loss: 0.728687047958374
Validation loss: 1.8287995592240365

Epoch: 6| Step: 4
Training loss: 0.8820058107376099
Validation loss: 1.8237623617213259

Epoch: 6| Step: 5
Training loss: 0.5154306292533875
Validation loss: 1.830072852873033

Epoch: 6| Step: 6
Training loss: 0.47880518436431885
Validation loss: 1.8262636469256492

Epoch: 6| Step: 7
Training loss: 0.5031791925430298
Validation loss: 1.821529096172702

Epoch: 6| Step: 8
Training loss: 0.3679455816745758
Validation loss: 1.8159187570694955

Epoch: 6| Step: 9
Training loss: 0.22478869557380676
Validation loss: 1.831522705734417

Epoch: 6| Step: 10
Training loss: 0.573409378528595
Validation loss: 1.8386121488386584

Epoch: 6| Step: 11
Training loss: 0.6633762121200562
Validation loss: 1.8751867227656867

Epoch: 6| Step: 12
Training loss: 0.6550018191337585
Validation loss: 1.8585678249277093

Epoch: 6| Step: 13
Training loss: 0.3922915756702423
Validation loss: 1.8811840177864156

Epoch: 386| Step: 0
Training loss: 0.5871126055717468
Validation loss: 1.852303530580254

Epoch: 6| Step: 1
Training loss: 0.6710258722305298
Validation loss: 1.8616832148644231

Epoch: 6| Step: 2
Training loss: 0.5311530828475952
Validation loss: 1.8226937914407382

Epoch: 6| Step: 3
Training loss: 0.3394652307033539
Validation loss: 1.8360010141967444

Epoch: 6| Step: 4
Training loss: 0.36462831497192383
Validation loss: 1.8502824383397256

Epoch: 6| Step: 5
Training loss: 0.5073031187057495
Validation loss: 1.8373787800470989

Epoch: 6| Step: 6
Training loss: 0.6348803043365479
Validation loss: 1.8173573222211612

Epoch: 6| Step: 7
Training loss: 0.6687928438186646
Validation loss: 1.8680921587892758

Epoch: 6| Step: 8
Training loss: 0.7180923223495483
Validation loss: 1.8421473836386075

Epoch: 6| Step: 9
Training loss: 0.5071518421173096
Validation loss: 1.8438978361827072

Epoch: 6| Step: 10
Training loss: 0.5642355680465698
Validation loss: 1.839245464212151

Epoch: 6| Step: 11
Training loss: 0.8090378046035767
Validation loss: 1.8253784859052269

Epoch: 6| Step: 12
Training loss: 0.7153860330581665
Validation loss: 1.845647055615661

Epoch: 6| Step: 13
Training loss: 0.6114965677261353
Validation loss: 1.8859828902829079

Epoch: 387| Step: 0
Training loss: 0.8363685607910156
Validation loss: 1.9021646386833602

Epoch: 6| Step: 1
Training loss: 0.5818914771080017
Validation loss: 1.8787770091846425

Epoch: 6| Step: 2
Training loss: 0.557361900806427
Validation loss: 1.8547552170292023

Epoch: 6| Step: 3
Training loss: 0.6111257076263428
Validation loss: 1.8332328283658592

Epoch: 6| Step: 4
Training loss: 0.6804665327072144
Validation loss: 1.8189018554584955

Epoch: 6| Step: 5
Training loss: 0.6478167176246643
Validation loss: 1.8247016091500559

Epoch: 6| Step: 6
Training loss: 0.44556307792663574
Validation loss: 1.7697887984655236

Epoch: 6| Step: 7
Training loss: 0.4710531234741211
Validation loss: 1.8306904838931175

Epoch: 6| Step: 8
Training loss: 0.4668203592300415
Validation loss: 1.86179954390372

Epoch: 6| Step: 9
Training loss: 0.922059178352356
Validation loss: 1.8703238118079402

Epoch: 6| Step: 10
Training loss: 0.5566527843475342
Validation loss: 1.8748528111365534

Epoch: 6| Step: 11
Training loss: 0.722084641456604
Validation loss: 1.8776501686342302

Epoch: 6| Step: 12
Training loss: 0.7663670778274536
Validation loss: 1.9291261473009664

Epoch: 6| Step: 13
Training loss: 0.43588313460350037
Validation loss: 1.8828919702960598

Epoch: 388| Step: 0
Training loss: 0.7191056609153748
Validation loss: 1.9186960651028542

Epoch: 6| Step: 1
Training loss: 0.5868592262268066
Validation loss: 1.910082673513761

Epoch: 6| Step: 2
Training loss: 0.730621337890625
Validation loss: 1.8646019299825032

Epoch: 6| Step: 3
Training loss: 0.7246191501617432
Validation loss: 1.8164204756418865

Epoch: 6| Step: 4
Training loss: 0.7030884027481079
Validation loss: 1.7965980242657404

Epoch: 6| Step: 5
Training loss: 0.5588132739067078
Validation loss: 1.8139740677290066

Epoch: 6| Step: 6
Training loss: 0.6353894472122192
Validation loss: 1.7519689939355338

Epoch: 6| Step: 7
Training loss: 0.5313879251480103
Validation loss: 1.7749615177031486

Epoch: 6| Step: 8
Training loss: 0.6954292058944702
Validation loss: 1.7643518473512383

Epoch: 6| Step: 9
Training loss: 0.7931495308876038
Validation loss: 1.7792884124222623

Epoch: 6| Step: 10
Training loss: 0.44667208194732666
Validation loss: 1.7639802643047866

Epoch: 6| Step: 11
Training loss: 0.5766568183898926
Validation loss: 1.7917533202837872

Epoch: 6| Step: 12
Training loss: 0.32932257652282715
Validation loss: 1.7716173753943494

Epoch: 6| Step: 13
Training loss: 0.7781841158866882
Validation loss: 1.8181244827085925

Epoch: 389| Step: 0
Training loss: 0.3833271265029907
Validation loss: 1.800014990632252

Epoch: 6| Step: 1
Training loss: 0.8219772577285767
Validation loss: 1.829191557822689

Epoch: 6| Step: 2
Training loss: 0.5692617893218994
Validation loss: 1.8316106885992072

Epoch: 6| Step: 3
Training loss: 0.33888500928878784
Validation loss: 1.8341873794473627

Epoch: 6| Step: 4
Training loss: 0.7295533418655396
Validation loss: 1.8687497531214068

Epoch: 6| Step: 5
Training loss: 0.5273534655570984
Validation loss: 1.865279079765402

Epoch: 6| Step: 6
Training loss: 0.6659529209136963
Validation loss: 1.8707166705080258

Epoch: 6| Step: 7
Training loss: 0.6870983242988586
Validation loss: 1.8587214536564325

Epoch: 6| Step: 8
Training loss: 0.68403160572052
Validation loss: 1.8604591969520814

Epoch: 6| Step: 9
Training loss: 0.48094654083251953
Validation loss: 1.853265772583664

Epoch: 6| Step: 10
Training loss: 0.7855391502380371
Validation loss: 1.872207119900693

Epoch: 6| Step: 11
Training loss: 0.3720347285270691
Validation loss: 1.8019142984062113

Epoch: 6| Step: 12
Training loss: 0.913933515548706
Validation loss: 1.8367498510627336

Epoch: 6| Step: 13
Training loss: 0.41407403349876404
Validation loss: 1.78901630960485

Epoch: 390| Step: 0
Training loss: 0.6750401258468628
Validation loss: 1.785974282090382

Epoch: 6| Step: 1
Training loss: 0.6763067841529846
Validation loss: 1.7733272826799782

Epoch: 6| Step: 2
Training loss: 0.26547712087631226
Validation loss: 1.7396653211244972

Epoch: 6| Step: 3
Training loss: 0.8710210919380188
Validation loss: 1.767172844179215

Epoch: 6| Step: 4
Training loss: 0.4599476754665375
Validation loss: 1.7977589945639334

Epoch: 6| Step: 5
Training loss: 0.5485244989395142
Validation loss: 1.81811519463857

Epoch: 6| Step: 6
Training loss: 0.37654781341552734
Validation loss: 1.7858971254799956

Epoch: 6| Step: 7
Training loss: 0.7120649218559265
Validation loss: 1.7952729630213913

Epoch: 6| Step: 8
Training loss: 0.531855583190918
Validation loss: 1.849075658347017

Epoch: 6| Step: 9
Training loss: 0.9044016599655151
Validation loss: 1.8735936726293256

Epoch: 6| Step: 10
Training loss: 0.6368806958198547
Validation loss: 1.8842755774016022

Epoch: 6| Step: 11
Training loss: 0.4701489806175232
Validation loss: 1.9353910453857914

Epoch: 6| Step: 12
Training loss: 0.7858304977416992
Validation loss: 1.9345744207341184

Epoch: 6| Step: 13
Training loss: 0.1813347190618515
Validation loss: 1.9195992677442488

Epoch: 391| Step: 0
Training loss: 0.5913311243057251
Validation loss: 1.944090526591065

Epoch: 6| Step: 1
Training loss: 0.6667811870574951
Validation loss: 1.91491453109249

Epoch: 6| Step: 2
Training loss: 0.6899637579917908
Validation loss: 1.8844148958882978

Epoch: 6| Step: 3
Training loss: 0.4488605558872223
Validation loss: 1.9004636682489866

Epoch: 6| Step: 4
Training loss: 0.6310055255889893
Validation loss: 1.8814399280855734

Epoch: 6| Step: 5
Training loss: 0.9997721910476685
Validation loss: 1.8476897196103168

Epoch: 6| Step: 6
Training loss: 0.2823691964149475
Validation loss: 1.7924822581711637

Epoch: 6| Step: 7
Training loss: 0.5047690272331238
Validation loss: 1.8413114201638006

Epoch: 6| Step: 8
Training loss: 0.512768030166626
Validation loss: 1.8268468444065382

Epoch: 6| Step: 9
Training loss: 0.4740220010280609
Validation loss: 1.8270368319685741

Epoch: 6| Step: 10
Training loss: 0.8709834218025208
Validation loss: 1.8545622530803885

Epoch: 6| Step: 11
Training loss: 0.6166196465492249
Validation loss: 1.78868055599992

Epoch: 6| Step: 12
Training loss: 0.5975887775421143
Validation loss: 1.7922782449312107

Epoch: 6| Step: 13
Training loss: 0.17650674283504486
Validation loss: 1.8159964520444152

Epoch: 392| Step: 0
Training loss: 0.5267000794410706
Validation loss: 1.7967352354398338

Epoch: 6| Step: 1
Training loss: 0.7922883033752441
Validation loss: 1.798069341208345

Epoch: 6| Step: 2
Training loss: 0.6163639426231384
Validation loss: 1.7877834381595734

Epoch: 6| Step: 3
Training loss: 0.7440659403800964
Validation loss: 1.7930030156207342

Epoch: 6| Step: 4
Training loss: 0.6620514392852783
Validation loss: 1.8304230410565612

Epoch: 6| Step: 5
Training loss: 0.4863376021385193
Validation loss: 1.857678573618653

Epoch: 6| Step: 6
Training loss: 0.3472028374671936
Validation loss: 1.8790597672103553

Epoch: 6| Step: 7
Training loss: 0.6098189353942871
Validation loss: 1.8838883817836802

Epoch: 6| Step: 8
Training loss: 0.7405025959014893
Validation loss: 1.8735294290768203

Epoch: 6| Step: 9
Training loss: 0.7138664722442627
Validation loss: 1.8501393269467097

Epoch: 6| Step: 10
Training loss: 0.24722187221050262
Validation loss: 1.8602852436804003

Epoch: 6| Step: 11
Training loss: 0.976398766040802
Validation loss: 1.9130415147350681

Epoch: 6| Step: 12
Training loss: 0.21631596982479095
Validation loss: 1.8479710599427581

Epoch: 6| Step: 13
Training loss: 0.34874555468559265
Validation loss: 1.8798639389776415

Epoch: 393| Step: 0
Training loss: 0.661342203617096
Validation loss: 1.8533638215834094

Epoch: 6| Step: 1
Training loss: 0.32370638847351074
Validation loss: 1.8512073998810143

Epoch: 6| Step: 2
Training loss: 0.5750802159309387
Validation loss: 1.8337861363605787

Epoch: 6| Step: 3
Training loss: 0.5485238432884216
Validation loss: 1.8521550945056382

Epoch: 6| Step: 4
Training loss: 0.6703622341156006
Validation loss: 1.8435268132917342

Epoch: 6| Step: 5
Training loss: 0.40552759170532227
Validation loss: 1.8140271555992864

Epoch: 6| Step: 6
Training loss: 0.7520328760147095
Validation loss: 1.8205787571527625

Epoch: 6| Step: 7
Training loss: 0.5857411026954651
Validation loss: 1.8181745493283836

Epoch: 6| Step: 8
Training loss: 0.7068338394165039
Validation loss: 1.806621386158851

Epoch: 6| Step: 9
Training loss: 0.5950149297714233
Validation loss: 1.7984971897576445

Epoch: 6| Step: 10
Training loss: 0.6501009464263916
Validation loss: 1.7976924655258015

Epoch: 6| Step: 11
Training loss: 0.343112587928772
Validation loss: 1.8408419573178856

Epoch: 6| Step: 12
Training loss: 0.7001796364784241
Validation loss: 1.799285698962468

Epoch: 6| Step: 13
Training loss: 0.3562833368778229
Validation loss: 1.8017640806013537

Epoch: 394| Step: 0
Training loss: 0.527671217918396
Validation loss: 1.8164928241442608

Epoch: 6| Step: 1
Training loss: 0.6295348405838013
Validation loss: 1.7941909285001858

Epoch: 6| Step: 2
Training loss: 0.5502374172210693
Validation loss: 1.776925080565996

Epoch: 6| Step: 3
Training loss: 0.4794245958328247
Validation loss: 1.7941497154133295

Epoch: 6| Step: 4
Training loss: 0.7313312888145447
Validation loss: 1.8121045533046927

Epoch: 6| Step: 5
Training loss: 0.6457767486572266
Validation loss: 1.8118506118815432

Epoch: 6| Step: 6
Training loss: 0.5211352705955505
Validation loss: 1.824465799075301

Epoch: 6| Step: 7
Training loss: 0.34371042251586914
Validation loss: 1.8843417347118419

Epoch: 6| Step: 8
Training loss: 0.6570825576782227
Validation loss: 1.885019242122609

Epoch: 6| Step: 9
Training loss: 0.4939051568508148
Validation loss: 1.8436382265501126

Epoch: 6| Step: 10
Training loss: 0.3178502321243286
Validation loss: 1.8522715055814354

Epoch: 6| Step: 11
Training loss: 0.48786166310310364
Validation loss: 1.8275862739932152

Epoch: 6| Step: 12
Training loss: 0.9723193645477295
Validation loss: 1.7931918623626872

Epoch: 6| Step: 13
Training loss: 0.7242767810821533
Validation loss: 1.7873258718880274

Epoch: 395| Step: 0
Training loss: 0.561815619468689
Validation loss: 1.7459029125910934

Epoch: 6| Step: 1
Training loss: 0.46183812618255615
Validation loss: 1.7665685581904587

Epoch: 6| Step: 2
Training loss: 0.7618544697761536
Validation loss: 1.7872802551074694

Epoch: 6| Step: 3
Training loss: 0.5188303589820862
Validation loss: 1.7886864805734286

Epoch: 6| Step: 4
Training loss: 1.0660266876220703
Validation loss: 1.8019650238816456

Epoch: 6| Step: 5
Training loss: 0.2563868463039398
Validation loss: 1.8080020014957716

Epoch: 6| Step: 6
Training loss: 0.4165668487548828
Validation loss: 1.8152394051192908

Epoch: 6| Step: 7
Training loss: 0.4888157844543457
Validation loss: 1.8399806125189668

Epoch: 6| Step: 8
Training loss: 0.6833018064498901
Validation loss: 1.8419948124116468

Epoch: 6| Step: 9
Training loss: 0.4405120313167572
Validation loss: 1.8303907045754053

Epoch: 6| Step: 10
Training loss: 0.6066564321517944
Validation loss: 1.835475290975263

Epoch: 6| Step: 11
Training loss: 0.8561415076255798
Validation loss: 1.8678314301275438

Epoch: 6| Step: 12
Training loss: 0.3927125930786133
Validation loss: 1.8079188587845012

Epoch: 6| Step: 13
Training loss: 0.4618705213069916
Validation loss: 1.8105284603693153

Epoch: 396| Step: 0
Training loss: 0.6480919718742371
Validation loss: 1.7879755843070246

Epoch: 6| Step: 1
Training loss: 0.6131060123443604
Validation loss: 1.7728394795489568

Epoch: 6| Step: 2
Training loss: 0.9067851305007935
Validation loss: 1.7512163372449978

Epoch: 6| Step: 3
Training loss: 0.5529582500457764
Validation loss: 1.800577340587493

Epoch: 6| Step: 4
Training loss: 0.668426513671875
Validation loss: 1.7703852333048338

Epoch: 6| Step: 5
Training loss: 0.4570310115814209
Validation loss: 1.7918587884595316

Epoch: 6| Step: 6
Training loss: 0.6715133190155029
Validation loss: 1.7855843523497223

Epoch: 6| Step: 7
Training loss: 0.4649471342563629
Validation loss: 1.808786274284445

Epoch: 6| Step: 8
Training loss: 0.5015314817428589
Validation loss: 1.7905512368807228

Epoch: 6| Step: 9
Training loss: 0.5109037756919861
Validation loss: 1.8015078139561478

Epoch: 6| Step: 10
Training loss: 0.7417288422584534
Validation loss: 1.8531215652342765

Epoch: 6| Step: 11
Training loss: 0.35542625188827515
Validation loss: 1.8593360134350356

Epoch: 6| Step: 12
Training loss: 0.4646395146846771
Validation loss: 1.852357026069395

Epoch: 6| Step: 13
Training loss: 0.5886476039886475
Validation loss: 1.8761006119430705

Epoch: 397| Step: 0
Training loss: 1.1681721210479736
Validation loss: 1.8955329900146813

Epoch: 6| Step: 1
Training loss: 0.5111828446388245
Validation loss: 1.8904537488055486

Epoch: 6| Step: 2
Training loss: 0.3853597640991211
Validation loss: 1.9211872957086051

Epoch: 6| Step: 3
Training loss: 0.6336106061935425
Validation loss: 1.88443753539875

Epoch: 6| Step: 4
Training loss: 0.5175268650054932
Validation loss: 1.8558605281255578

Epoch: 6| Step: 5
Training loss: 0.5110336542129517
Validation loss: 1.844833295832398

Epoch: 6| Step: 6
Training loss: 0.6998665928840637
Validation loss: 1.8408733490974671

Epoch: 6| Step: 7
Training loss: 0.5610073208808899
Validation loss: 1.829774780939984

Epoch: 6| Step: 8
Training loss: 0.6290950775146484
Validation loss: 1.837629718165244

Epoch: 6| Step: 9
Training loss: 0.574827253818512
Validation loss: 1.8106350744924238

Epoch: 6| Step: 10
Training loss: 0.41488033533096313
Validation loss: 1.779467225074768

Epoch: 6| Step: 11
Training loss: 0.5010490417480469
Validation loss: 1.8181417552373742

Epoch: 6| Step: 12
Training loss: 0.6509101986885071
Validation loss: 1.8131526849603141

Epoch: 6| Step: 13
Training loss: 0.4056658446788788
Validation loss: 1.782174547513326

Epoch: 398| Step: 0
Training loss: 0.6197586059570312
Validation loss: 1.8189320333542363

Epoch: 6| Step: 1
Training loss: 0.6637204885482788
Validation loss: 1.73957916485366

Epoch: 6| Step: 2
Training loss: 0.4674740433692932
Validation loss: 1.7690790186646164

Epoch: 6| Step: 3
Training loss: 0.5623618364334106
Validation loss: 1.7759099750108616

Epoch: 6| Step: 4
Training loss: 0.5108360648155212
Validation loss: 1.785614162363032

Epoch: 6| Step: 5
Training loss: 0.426946222782135
Validation loss: 1.7929807504018147

Epoch: 6| Step: 6
Training loss: 0.6073054075241089
Validation loss: 1.7968742629533172

Epoch: 6| Step: 7
Training loss: 0.5180175304412842
Validation loss: 1.7888493742994083

Epoch: 6| Step: 8
Training loss: 0.8335143327713013
Validation loss: 1.8010909826524797

Epoch: 6| Step: 9
Training loss: 0.43918150663375854
Validation loss: 1.8007428594814834

Epoch: 6| Step: 10
Training loss: 0.698223352432251
Validation loss: 1.799616180440431

Epoch: 6| Step: 11
Training loss: 0.41968217492103577
Validation loss: 1.810946620920653

Epoch: 6| Step: 12
Training loss: 0.48643699288368225
Validation loss: 1.8146255285509172

Epoch: 6| Step: 13
Training loss: 0.4201805889606476
Validation loss: 1.808580795923869

Epoch: 399| Step: 0
Training loss: 0.6598207950592041
Validation loss: 1.79026367843792

Epoch: 6| Step: 1
Training loss: 0.5564295053482056
Validation loss: 1.7940745533153575

Epoch: 6| Step: 2
Training loss: 0.5398976802825928
Validation loss: 1.7869962441023959

Epoch: 6| Step: 3
Training loss: 0.3982376158237457
Validation loss: 1.8087475376744424

Epoch: 6| Step: 4
Training loss: 0.5449807643890381
Validation loss: 1.756871574668474

Epoch: 6| Step: 5
Training loss: 0.9164966940879822
Validation loss: 1.7965285342226747

Epoch: 6| Step: 6
Training loss: 0.4567369520664215
Validation loss: 1.810976610388807

Epoch: 6| Step: 7
Training loss: 0.6675616502761841
Validation loss: 1.7986733605784755

Epoch: 6| Step: 8
Training loss: 0.6408859491348267
Validation loss: 1.7953523230809036

Epoch: 6| Step: 9
Training loss: 0.541024923324585
Validation loss: 1.8272616119794949

Epoch: 6| Step: 10
Training loss: 0.47516900300979614
Validation loss: 1.857440060184848

Epoch: 6| Step: 11
Training loss: 0.7006835341453552
Validation loss: 1.8320533626823015

Epoch: 6| Step: 12
Training loss: 0.4081292152404785
Validation loss: 1.8561176933268064

Epoch: 6| Step: 13
Training loss: 0.35863542556762695
Validation loss: 1.8638615954306819

Epoch: 400| Step: 0
Training loss: 0.6604098081588745
Validation loss: 1.848642324888578

Epoch: 6| Step: 1
Training loss: 0.6205534338951111
Validation loss: 1.8299869363025953

Epoch: 6| Step: 2
Training loss: 0.4345680773258209
Validation loss: 1.7895707084286598

Epoch: 6| Step: 3
Training loss: 0.7233280539512634
Validation loss: 1.8662586212158203

Epoch: 6| Step: 4
Training loss: 0.41252318024635315
Validation loss: 1.824560889633753

Epoch: 6| Step: 5
Training loss: 0.5233714580535889
Validation loss: 1.809151921221005

Epoch: 6| Step: 6
Training loss: 0.36168354749679565
Validation loss: 1.7825578412702006

Epoch: 6| Step: 7
Training loss: 0.4246099889278412
Validation loss: 1.7736601111709431

Epoch: 6| Step: 8
Training loss: 0.6584696173667908
Validation loss: 1.7219838429522771

Epoch: 6| Step: 9
Training loss: 0.6330918073654175
Validation loss: 1.7627099303789036

Epoch: 6| Step: 10
Training loss: 0.5067379474639893
Validation loss: 1.7229945685273858

Epoch: 6| Step: 11
Training loss: 0.4937041103839874
Validation loss: 1.7449885722129577

Epoch: 6| Step: 12
Training loss: 0.5613086819648743
Validation loss: 1.7363447297003962

Epoch: 6| Step: 13
Training loss: 0.9213560819625854
Validation loss: 1.73935188657494

Epoch: 401| Step: 0
Training loss: 0.7400846481323242
Validation loss: 1.7862203787731867

Epoch: 6| Step: 1
Training loss: 0.43305593729019165
Validation loss: 1.791542237804782

Epoch: 6| Step: 2
Training loss: 0.48336827754974365
Validation loss: 1.7817354240725118

Epoch: 6| Step: 3
Training loss: 0.42592501640319824
Validation loss: 1.7847338017596994

Epoch: 6| Step: 4
Training loss: 0.6333897113800049
Validation loss: 1.8257637293108049

Epoch: 6| Step: 5
Training loss: 0.38135579228401184
Validation loss: 1.8341274056383359

Epoch: 6| Step: 6
Training loss: 0.7114278078079224
Validation loss: 1.8427472665745726

Epoch: 6| Step: 7
Training loss: 0.44100141525268555
Validation loss: 1.8502622060878302

Epoch: 6| Step: 8
Training loss: 1.0238940715789795
Validation loss: 1.8520031039432814

Epoch: 6| Step: 9
Training loss: 0.4888365566730499
Validation loss: 1.888615305705737

Epoch: 6| Step: 10
Training loss: 0.6692193150520325
Validation loss: 1.8306504308536489

Epoch: 6| Step: 11
Training loss: 0.34317880868911743
Validation loss: 1.874836988346551

Epoch: 6| Step: 12
Training loss: 0.518831729888916
Validation loss: 1.8649871733880812

Epoch: 6| Step: 13
Training loss: 0.23744498193264008
Validation loss: 1.889052637161747

Epoch: 402| Step: 0
Training loss: 0.4238782525062561
Validation loss: 1.8722390461993474

Epoch: 6| Step: 1
Training loss: 0.4227532148361206
Validation loss: 1.8795860787873626

Epoch: 6| Step: 2
Training loss: 0.6950976848602295
Validation loss: 1.854632503242903

Epoch: 6| Step: 3
Training loss: 0.6071107387542725
Validation loss: 1.8480017595393683

Epoch: 6| Step: 4
Training loss: 0.3469095826148987
Validation loss: 1.8355069391189083

Epoch: 6| Step: 5
Training loss: 0.40665537118911743
Validation loss: 1.79039825418944

Epoch: 6| Step: 6
Training loss: 0.44356441497802734
Validation loss: 1.7773185109579435

Epoch: 6| Step: 7
Training loss: 0.4373208284378052
Validation loss: 1.7898020718687324

Epoch: 6| Step: 8
Training loss: 0.7485537528991699
Validation loss: 1.7645968724322576

Epoch: 6| Step: 9
Training loss: 0.5933639407157898
Validation loss: 1.763845210434288

Epoch: 6| Step: 10
Training loss: 0.6547706127166748
Validation loss: 1.780297146048597

Epoch: 6| Step: 11
Training loss: 0.6186915636062622
Validation loss: 1.7839582479128273

Epoch: 6| Step: 12
Training loss: 0.5716259479522705
Validation loss: 1.7615655942629742

Epoch: 6| Step: 13
Training loss: 0.2923750579357147
Validation loss: 1.7476191405327088

Epoch: 403| Step: 0
Training loss: 0.7739962339401245
Validation loss: 1.7798195372345627

Epoch: 6| Step: 1
Training loss: 0.5080611705780029
Validation loss: 1.7840972126171153

Epoch: 6| Step: 2
Training loss: 0.5805749893188477
Validation loss: 1.7935641504103137

Epoch: 6| Step: 3
Training loss: 0.6872130632400513
Validation loss: 1.7885324262803601

Epoch: 6| Step: 4
Training loss: 0.8303568959236145
Validation loss: 1.7486061537137596

Epoch: 6| Step: 5
Training loss: 0.5862320065498352
Validation loss: 1.8096431634759391

Epoch: 6| Step: 6
Training loss: 0.47758805751800537
Validation loss: 1.8271452739674559

Epoch: 6| Step: 7
Training loss: 0.4652034640312195
Validation loss: 1.8457190477719871

Epoch: 6| Step: 8
Training loss: 0.2602371573448181
Validation loss: 1.814343704972216

Epoch: 6| Step: 9
Training loss: 0.2615259289741516
Validation loss: 1.8201142959697272

Epoch: 6| Step: 10
Training loss: 0.6440290212631226
Validation loss: 1.8226577645988875

Epoch: 6| Step: 11
Training loss: 0.5771653652191162
Validation loss: 1.8163295189539592

Epoch: 6| Step: 12
Training loss: 0.44579797983169556
Validation loss: 1.795558862788703

Epoch: 6| Step: 13
Training loss: 0.4280577301979065
Validation loss: 1.8076724237011326

Epoch: 404| Step: 0
Training loss: 0.4833276569843292
Validation loss: 1.777018420157894

Epoch: 6| Step: 1
Training loss: 0.6829869747161865
Validation loss: 1.7218799437246015

Epoch: 6| Step: 2
Training loss: 0.30982092022895813
Validation loss: 1.7556534300568283

Epoch: 6| Step: 3
Training loss: 0.4157152473926544
Validation loss: 1.7391321812906573

Epoch: 6| Step: 4
Training loss: 0.5051999092102051
Validation loss: 1.7651128422829412

Epoch: 6| Step: 5
Training loss: 0.8344931602478027
Validation loss: 1.786464419416202

Epoch: 6| Step: 6
Training loss: 0.512026846408844
Validation loss: 1.7782716648553007

Epoch: 6| Step: 7
Training loss: 0.6274067759513855
Validation loss: 1.751105067550495

Epoch: 6| Step: 8
Training loss: 0.4002434015274048
Validation loss: 1.7984243746726745

Epoch: 6| Step: 9
Training loss: 0.7015857696533203
Validation loss: 1.7683052157842984

Epoch: 6| Step: 10
Training loss: 0.661244809627533
Validation loss: 1.7597244401131906

Epoch: 6| Step: 11
Training loss: 0.7206954956054688
Validation loss: 1.8041414599264822

Epoch: 6| Step: 12
Training loss: 0.23356758058071136
Validation loss: 1.7817995048338366

Epoch: 6| Step: 13
Training loss: 0.23872153460979462
Validation loss: 1.7449758770645305

Epoch: 405| Step: 0
Training loss: 0.4083242416381836
Validation loss: 1.74901714376224

Epoch: 6| Step: 1
Training loss: 0.23917986452579498
Validation loss: 1.7863136158194592

Epoch: 6| Step: 2
Training loss: 0.6649158000946045
Validation loss: 1.7913266561364616

Epoch: 6| Step: 3
Training loss: 0.7217481732368469
Validation loss: 1.7613102133556078

Epoch: 6| Step: 4
Training loss: 0.4089191257953644
Validation loss: 1.7949644045163227

Epoch: 6| Step: 5
Training loss: 0.623985230922699
Validation loss: 1.8007202558620001

Epoch: 6| Step: 6
Training loss: 0.3157421946525574
Validation loss: 1.8032679070708573

Epoch: 6| Step: 7
Training loss: 0.6091959476470947
Validation loss: 1.798992415910126

Epoch: 6| Step: 8
Training loss: 0.4631807208061218
Validation loss: 1.8019116668290989

Epoch: 6| Step: 9
Training loss: 0.37816622853279114
Validation loss: 1.8136118688891012

Epoch: 6| Step: 10
Training loss: 0.5253286361694336
Validation loss: 1.8281466217451199

Epoch: 6| Step: 11
Training loss: 1.0044556856155396
Validation loss: 1.8661054206150833

Epoch: 6| Step: 12
Training loss: 0.5620179772377014
Validation loss: 1.813794675693717

Epoch: 6| Step: 13
Training loss: 0.4991466701030731
Validation loss: 1.826459910279961

Epoch: 406| Step: 0
Training loss: 0.63341224193573
Validation loss: 1.7887342693985149

Epoch: 6| Step: 1
Training loss: 0.5489312410354614
Validation loss: 1.8010971097535984

Epoch: 6| Step: 2
Training loss: 0.5299556255340576
Validation loss: 1.7363806052874493

Epoch: 6| Step: 3
Training loss: 0.7575349807739258
Validation loss: 1.7486713804224485

Epoch: 6| Step: 4
Training loss: 0.17901259660720825
Validation loss: 1.7888950199209235

Epoch: 6| Step: 5
Training loss: 0.6515718102455139
Validation loss: 1.752339236197933

Epoch: 6| Step: 6
Training loss: 0.4126196503639221
Validation loss: 1.7448112554447626

Epoch: 6| Step: 7
Training loss: 0.463187038898468
Validation loss: 1.7652736658691077

Epoch: 6| Step: 8
Training loss: 0.2725830376148224
Validation loss: 1.7575873328793434

Epoch: 6| Step: 9
Training loss: 0.2772789001464844
Validation loss: 1.7902516857270272

Epoch: 6| Step: 10
Training loss: 0.6076000332832336
Validation loss: 1.8299912970553163

Epoch: 6| Step: 11
Training loss: 0.7784042358398438
Validation loss: 1.840619271801364

Epoch: 6| Step: 12
Training loss: 0.4518622159957886
Validation loss: 1.8567530275672994

Epoch: 6| Step: 13
Training loss: 0.8984458446502686
Validation loss: 1.8562321598811815

Epoch: 407| Step: 0
Training loss: 0.819609522819519
Validation loss: 1.8131769318734445

Epoch: 6| Step: 1
Training loss: 0.5049625635147095
Validation loss: 1.778948349337424

Epoch: 6| Step: 2
Training loss: 0.5723714828491211
Validation loss: 1.811852139811362

Epoch: 6| Step: 3
Training loss: 0.5060442090034485
Validation loss: 1.7398025585759072

Epoch: 6| Step: 4
Training loss: 0.4042576551437378
Validation loss: 1.7420910173846829

Epoch: 6| Step: 5
Training loss: 0.7366966009140015
Validation loss: 1.7661119661023539

Epoch: 6| Step: 6
Training loss: 0.23163199424743652
Validation loss: 1.7383710825315086

Epoch: 6| Step: 7
Training loss: 0.6403084993362427
Validation loss: 1.7213620998526131

Epoch: 6| Step: 8
Training loss: 0.6930512189865112
Validation loss: 1.735747770596576

Epoch: 6| Step: 9
Training loss: 0.3782094717025757
Validation loss: 1.7242947009301954

Epoch: 6| Step: 10
Training loss: 0.49804040789604187
Validation loss: 1.7173499458579606

Epoch: 6| Step: 11
Training loss: 0.42538678646087646
Validation loss: 1.731462522219586

Epoch: 6| Step: 12
Training loss: 0.32035115361213684
Validation loss: 1.7620163809868596

Epoch: 6| Step: 13
Training loss: 0.4260309338569641
Validation loss: 1.8088253441677298

Epoch: 408| Step: 0
Training loss: 0.7160991430282593
Validation loss: 1.8275073048888997

Epoch: 6| Step: 1
Training loss: 0.4004364609718323
Validation loss: 1.8073399015652236

Epoch: 6| Step: 2
Training loss: 0.4415220618247986
Validation loss: 1.7967182474751626

Epoch: 6| Step: 3
Training loss: 0.42819613218307495
Validation loss: 1.8202467015994492

Epoch: 6| Step: 4
Training loss: 0.36195626854896545
Validation loss: 1.822801297710788

Epoch: 6| Step: 5
Training loss: 0.5553696751594543
Validation loss: 1.822751215709153

Epoch: 6| Step: 6
Training loss: 0.32164430618286133
Validation loss: 1.7924721356361144

Epoch: 6| Step: 7
Training loss: 0.5497918725013733
Validation loss: 1.8196628785902453

Epoch: 6| Step: 8
Training loss: 0.7518872022628784
Validation loss: 1.76755533295293

Epoch: 6| Step: 9
Training loss: 0.7121854424476624
Validation loss: 1.7719308765985633

Epoch: 6| Step: 10
Training loss: 0.5986708998680115
Validation loss: 1.7664242649591098

Epoch: 6| Step: 11
Training loss: 0.44108325242996216
Validation loss: 1.7686951916704896

Epoch: 6| Step: 12
Training loss: 0.6020330190658569
Validation loss: 1.7274056314140238

Epoch: 6| Step: 13
Training loss: 0.3368029296398163
Validation loss: 1.6952643343197402

Epoch: 409| Step: 0
Training loss: 0.5505111217498779
Validation loss: 1.6846902678089757

Epoch: 6| Step: 1
Training loss: 0.5104562044143677
Validation loss: 1.7065871505327121

Epoch: 6| Step: 2
Training loss: 0.6379048228263855
Validation loss: 1.720026300799462

Epoch: 6| Step: 3
Training loss: 0.5080749988555908
Validation loss: 1.7169960865410425

Epoch: 6| Step: 4
Training loss: 0.3559609651565552
Validation loss: 1.7246301353618663

Epoch: 6| Step: 5
Training loss: 0.339596688747406
Validation loss: 1.8065582885537097

Epoch: 6| Step: 6
Training loss: 0.8331174850463867
Validation loss: 1.8284463587627615

Epoch: 6| Step: 7
Training loss: 0.4591265320777893
Validation loss: 1.788262906894889

Epoch: 6| Step: 8
Training loss: 0.7385871410369873
Validation loss: 1.8459557128208939

Epoch: 6| Step: 9
Training loss: 0.3877299726009369
Validation loss: 1.8501973229069864

Epoch: 6| Step: 10
Training loss: 0.5218605995178223
Validation loss: 1.809381974640713

Epoch: 6| Step: 11
Training loss: 0.6020947098731995
Validation loss: 1.7998088790524391

Epoch: 6| Step: 12
Training loss: 0.32392245531082153
Validation loss: 1.7653236030250468

Epoch: 6| Step: 13
Training loss: 0.6036689281463623
Validation loss: 1.7715038099596578

Epoch: 410| Step: 0
Training loss: 0.23360759019851685
Validation loss: 1.7512432887989988

Epoch: 6| Step: 1
Training loss: 0.6263303756713867
Validation loss: 1.7287821372350056

Epoch: 6| Step: 2
Training loss: 0.6976313591003418
Validation loss: 1.7009856418896747

Epoch: 6| Step: 3
Training loss: 0.5236765146255493
Validation loss: 1.7425813290380663

Epoch: 6| Step: 4
Training loss: 0.40594956278800964
Validation loss: 1.7826284964879353

Epoch: 6| Step: 5
Training loss: 0.606218695640564
Validation loss: 1.778824306303455

Epoch: 6| Step: 6
Training loss: 0.5375643968582153
Validation loss: 1.7414928508061234

Epoch: 6| Step: 7
Training loss: 0.3510892987251282
Validation loss: 1.741877632756387

Epoch: 6| Step: 8
Training loss: 0.4739890992641449
Validation loss: 1.7775486464141517

Epoch: 6| Step: 9
Training loss: 0.601580798625946
Validation loss: 1.761321213937575

Epoch: 6| Step: 10
Training loss: 0.6164264678955078
Validation loss: 1.757475878602715

Epoch: 6| Step: 11
Training loss: 0.5823603272438049
Validation loss: 1.811714954273675

Epoch: 6| Step: 12
Training loss: 0.5196880102157593
Validation loss: 1.8323199120900964

Epoch: 6| Step: 13
Training loss: 0.3409520387649536
Validation loss: 1.860400528036138

Epoch: 411| Step: 0
Training loss: 0.6493295431137085
Validation loss: 1.8288438691887805

Epoch: 6| Step: 1
Training loss: 0.48435962200164795
Validation loss: 1.86297280685876

Epoch: 6| Step: 2
Training loss: 0.37594717741012573
Validation loss: 1.8464467602391397

Epoch: 6| Step: 3
Training loss: 0.5474340319633484
Validation loss: 1.8061848487905277

Epoch: 6| Step: 4
Training loss: 0.5819609761238098
Validation loss: 1.8268797910341652

Epoch: 6| Step: 5
Training loss: 0.37260791659355164
Validation loss: 1.7569740741483626

Epoch: 6| Step: 6
Training loss: 0.22514958679676056
Validation loss: 1.7408469312934465

Epoch: 6| Step: 7
Training loss: 0.4973781108856201
Validation loss: 1.7914491212496193

Epoch: 6| Step: 8
Training loss: 0.6129531860351562
Validation loss: 1.7916518103691839

Epoch: 6| Step: 9
Training loss: 0.7213051319122314
Validation loss: 1.752311683470203

Epoch: 6| Step: 10
Training loss: 0.6361628770828247
Validation loss: 1.763924555111957

Epoch: 6| Step: 11
Training loss: 0.43255355954170227
Validation loss: 1.7316119850322764

Epoch: 6| Step: 12
Training loss: 0.47512081265449524
Validation loss: 1.7247831975260088

Epoch: 6| Step: 13
Training loss: 0.39940622448921204
Validation loss: 1.762259260300667

Epoch: 412| Step: 0
Training loss: 0.730611264705658
Validation loss: 1.7798268692467802

Epoch: 6| Step: 1
Training loss: 0.5443204641342163
Validation loss: 1.7901405583145797

Epoch: 6| Step: 2
Training loss: 0.20801065862178802
Validation loss: 1.7968160285744617

Epoch: 6| Step: 3
Training loss: 0.582436740398407
Validation loss: 1.7912214353520384

Epoch: 6| Step: 4
Training loss: 0.4855656921863556
Validation loss: 1.780793692476006

Epoch: 6| Step: 5
Training loss: 0.3295026421546936
Validation loss: 1.7847482978656728

Epoch: 6| Step: 6
Training loss: 0.5544323921203613
Validation loss: 1.7737446190208517

Epoch: 6| Step: 7
Training loss: 0.34409311413764954
Validation loss: 1.7902956701094104

Epoch: 6| Step: 8
Training loss: 0.5878010988235474
Validation loss: 1.7950421776822818

Epoch: 6| Step: 9
Training loss: 0.8113772869110107
Validation loss: 1.8246501197097122

Epoch: 6| Step: 10
Training loss: 0.6600314974784851
Validation loss: 1.8198776514299455

Epoch: 6| Step: 11
Training loss: 0.5584529042243958
Validation loss: 1.8044284620592672

Epoch: 6| Step: 12
Training loss: 0.4557812809944153
Validation loss: 1.8293468708633094

Epoch: 6| Step: 13
Training loss: 0.5078958868980408
Validation loss: 1.822866024509553

Epoch: 413| Step: 0
Training loss: 0.4010621905326843
Validation loss: 1.7990148118747178

Epoch: 6| Step: 1
Training loss: 0.7423262000083923
Validation loss: 1.7900496900722545

Epoch: 6| Step: 2
Training loss: 0.6930776238441467
Validation loss: 1.7601577851080126

Epoch: 6| Step: 3
Training loss: 0.2935989499092102
Validation loss: 1.7554711654622068

Epoch: 6| Step: 4
Training loss: 0.6073559522628784
Validation loss: 1.8021311093402166

Epoch: 6| Step: 5
Training loss: 0.3483175039291382
Validation loss: 1.7453350123538767

Epoch: 6| Step: 6
Training loss: 0.46425604820251465
Validation loss: 1.7824173550451956

Epoch: 6| Step: 7
Training loss: 0.535378098487854
Validation loss: 1.7847660985044254

Epoch: 6| Step: 8
Training loss: 0.8598703742027283
Validation loss: 1.798187353277719

Epoch: 6| Step: 9
Training loss: 0.3246404528617859
Validation loss: 1.8243107975170176

Epoch: 6| Step: 10
Training loss: 0.5295864939689636
Validation loss: 1.7994825942541963

Epoch: 6| Step: 11
Training loss: 0.4859999418258667
Validation loss: 1.7788653630082325

Epoch: 6| Step: 12
Training loss: 0.416123628616333
Validation loss: 1.8142428090495448

Epoch: 6| Step: 13
Training loss: 0.06981592625379562
Validation loss: 1.8135502787046536

Epoch: 414| Step: 0
Training loss: 0.31394755840301514
Validation loss: 1.8357755432846725

Epoch: 6| Step: 1
Training loss: 0.5564979314804077
Validation loss: 1.868867956182008

Epoch: 6| Step: 2
Training loss: 0.6083520650863647
Validation loss: 1.7890485512313021

Epoch: 6| Step: 3
Training loss: 0.34303930401802063
Validation loss: 1.7806929772899998

Epoch: 6| Step: 4
Training loss: 0.6510412693023682
Validation loss: 1.7732419121649958

Epoch: 6| Step: 5
Training loss: 0.7010965347290039
Validation loss: 1.7530941450467674

Epoch: 6| Step: 6
Training loss: 0.3881639242172241
Validation loss: 1.7610818122022895

Epoch: 6| Step: 7
Training loss: 0.4333048462867737
Validation loss: 1.7650732276260213

Epoch: 6| Step: 8
Training loss: 0.6573811769485474
Validation loss: 1.7555633655158422

Epoch: 6| Step: 9
Training loss: 0.4524780511856079
Validation loss: 1.738750930755369

Epoch: 6| Step: 10
Training loss: 0.6301762461662292
Validation loss: 1.7378322975609892

Epoch: 6| Step: 11
Training loss: 0.7678909301757812
Validation loss: 1.750664431561706

Epoch: 6| Step: 12
Training loss: 0.5622274875640869
Validation loss: 1.7429284152164255

Epoch: 6| Step: 13
Training loss: 0.3023010492324829
Validation loss: 1.765886160635179

Epoch: 415| Step: 0
Training loss: 0.43535375595092773
Validation loss: 1.6884931313094271

Epoch: 6| Step: 1
Training loss: 0.4646950364112854
Validation loss: 1.7399865978507585

Epoch: 6| Step: 2
Training loss: 0.5703748464584351
Validation loss: 1.7209325426368303

Epoch: 6| Step: 3
Training loss: 0.45185309648513794
Validation loss: 1.7753845286625687

Epoch: 6| Step: 4
Training loss: 0.31785303354263306
Validation loss: 1.7563205021683888

Epoch: 6| Step: 5
Training loss: 0.5683045387268066
Validation loss: 1.7441889855169481

Epoch: 6| Step: 6
Training loss: 0.7339866161346436
Validation loss: 1.7758588034619567

Epoch: 6| Step: 7
Training loss: 0.4276159703731537
Validation loss: 1.7984654070228658

Epoch: 6| Step: 8
Training loss: 0.6403307914733887
Validation loss: 1.7952630801867413

Epoch: 6| Step: 9
Training loss: 0.5969372987747192
Validation loss: 1.8170730567747546

Epoch: 6| Step: 10
Training loss: 0.6906454563140869
Validation loss: 1.8155044330063688

Epoch: 6| Step: 11
Training loss: 0.5165410041809082
Validation loss: 1.8167803781006926

Epoch: 6| Step: 12
Training loss: 0.5625438690185547
Validation loss: 1.7837500649113809

Epoch: 6| Step: 13
Training loss: 0.27187612652778625
Validation loss: 1.7844781696155507

Epoch: 416| Step: 0
Training loss: 0.4951840043067932
Validation loss: 1.7712545907625588

Epoch: 6| Step: 1
Training loss: 0.2437572330236435
Validation loss: 1.7606656525724678

Epoch: 6| Step: 2
Training loss: 0.3604193925857544
Validation loss: 1.7683760889114872

Epoch: 6| Step: 3
Training loss: 0.7769119143486023
Validation loss: 1.7912225351538709

Epoch: 6| Step: 4
Training loss: 0.4079369306564331
Validation loss: 1.7575880878715104

Epoch: 6| Step: 5
Training loss: 0.4952501058578491
Validation loss: 1.7873046500708467

Epoch: 6| Step: 6
Training loss: 0.4751352071762085
Validation loss: 1.8277778356306014

Epoch: 6| Step: 7
Training loss: 0.7728546857833862
Validation loss: 1.8206649800782562

Epoch: 6| Step: 8
Training loss: 0.7759179472923279
Validation loss: 1.8417396212136874

Epoch: 6| Step: 9
Training loss: 0.6425938010215759
Validation loss: 1.787369506333464

Epoch: 6| Step: 10
Training loss: 0.4282706379890442
Validation loss: 1.8125729765943301

Epoch: 6| Step: 11
Training loss: 0.34580421447753906
Validation loss: 1.8198260645712576

Epoch: 6| Step: 12
Training loss: 0.3202599287033081
Validation loss: 1.782027748323256

Epoch: 6| Step: 13
Training loss: 0.19505245983600616
Validation loss: 1.811967501076319

Epoch: 417| Step: 0
Training loss: 0.4302739202976227
Validation loss: 1.7863661345615183

Epoch: 6| Step: 1
Training loss: 0.585134744644165
Validation loss: 1.791723616661564

Epoch: 6| Step: 2
Training loss: 0.500103235244751
Validation loss: 1.7269648749341246

Epoch: 6| Step: 3
Training loss: 0.4608076810836792
Validation loss: 1.771697675028155

Epoch: 6| Step: 4
Training loss: 0.5406769514083862
Validation loss: 1.7301084585087274

Epoch: 6| Step: 5
Training loss: 0.3211328685283661
Validation loss: 1.777898826906758

Epoch: 6| Step: 6
Training loss: 0.4282369017601013
Validation loss: 1.8212771800256544

Epoch: 6| Step: 7
Training loss: 0.43567633628845215
Validation loss: 1.7878128174812562

Epoch: 6| Step: 8
Training loss: 0.8717346787452698
Validation loss: 1.8082235756740774

Epoch: 6| Step: 9
Training loss: 0.32687586545944214
Validation loss: 1.7991189687482771

Epoch: 6| Step: 10
Training loss: 0.3802761435508728
Validation loss: 1.8209992941989694

Epoch: 6| Step: 11
Training loss: 0.5716272592544556
Validation loss: 1.7951987020431026

Epoch: 6| Step: 12
Training loss: 0.47540825605392456
Validation loss: 1.78307262287345

Epoch: 6| Step: 13
Training loss: 0.39466592669487
Validation loss: 1.815506003236258

Epoch: 418| Step: 0
Training loss: 0.46214887499809265
Validation loss: 1.8095793518968808

Epoch: 6| Step: 1
Training loss: 0.5864399671554565
Validation loss: 1.7326854928847282

Epoch: 6| Step: 2
Training loss: 0.8087992668151855
Validation loss: 1.829567265766923

Epoch: 6| Step: 3
Training loss: 0.4382568597793579
Validation loss: 1.7593241878735122

Epoch: 6| Step: 4
Training loss: 0.3984885811805725
Validation loss: 1.8227162899509552

Epoch: 6| Step: 5
Training loss: 0.4135773181915283
Validation loss: 1.8230854106205765

Epoch: 6| Step: 6
Training loss: 0.2206251472234726
Validation loss: 1.8131252629782564

Epoch: 6| Step: 7
Training loss: 0.5574824810028076
Validation loss: 1.8135091553452194

Epoch: 6| Step: 8
Training loss: 0.3486121892929077
Validation loss: 1.7684607364798104

Epoch: 6| Step: 9
Training loss: 0.3184475302696228
Validation loss: 1.8021681821474465

Epoch: 6| Step: 10
Training loss: 0.5601391792297363
Validation loss: 1.7639399690012778

Epoch: 6| Step: 11
Training loss: 0.5738034248352051
Validation loss: 1.78199553233321

Epoch: 6| Step: 12
Training loss: 0.6500641107559204
Validation loss: 1.7974002361297607

Epoch: 6| Step: 13
Training loss: 0.1173204705119133
Validation loss: 1.7881796462561494

Epoch: 419| Step: 0
Training loss: 0.2798885107040405
Validation loss: 1.8102682034174602

Epoch: 6| Step: 1
Training loss: 0.8421236276626587
Validation loss: 1.811676130499891

Epoch: 6| Step: 2
Training loss: 0.3624168336391449
Validation loss: 1.7911248489092755

Epoch: 6| Step: 3
Training loss: 0.6279327869415283
Validation loss: 1.8067680481941468

Epoch: 6| Step: 4
Training loss: 0.2758451998233795
Validation loss: 1.7912405652384604

Epoch: 6| Step: 5
Training loss: 0.41943109035491943
Validation loss: 1.7750677908620527

Epoch: 6| Step: 6
Training loss: 0.4547952711582184
Validation loss: 1.7593716882890271

Epoch: 6| Step: 7
Training loss: 0.44336116313934326
Validation loss: 1.766242673320155

Epoch: 6| Step: 8
Training loss: 0.5597855448722839
Validation loss: 1.811798172612344

Epoch: 6| Step: 9
Training loss: 0.3687356114387512
Validation loss: 1.7845094152676162

Epoch: 6| Step: 10
Training loss: 0.4461400508880615
Validation loss: 1.8095831101940525

Epoch: 6| Step: 11
Training loss: 0.6596456170082092
Validation loss: 1.7908595646581342

Epoch: 6| Step: 12
Training loss: 0.6464253067970276
Validation loss: 1.8043368221611105

Epoch: 6| Step: 13
Training loss: 0.4259693920612335
Validation loss: 1.7190264963334607

Epoch: 420| Step: 0
Training loss: 0.2807985246181488
Validation loss: 1.715092634641996

Epoch: 6| Step: 1
Training loss: 0.30409204959869385
Validation loss: 1.7664133297499789

Epoch: 6| Step: 2
Training loss: 0.5970873832702637
Validation loss: 1.7511291298815

Epoch: 6| Step: 3
Training loss: 0.4974413514137268
Validation loss: 1.7428082868617067

Epoch: 6| Step: 4
Training loss: 0.3760482668876648
Validation loss: 1.7502244723740445

Epoch: 6| Step: 5
Training loss: 0.4220140278339386
Validation loss: 1.7808516756180794

Epoch: 6| Step: 6
Training loss: 0.29764166474342346
Validation loss: 1.7679408134952668

Epoch: 6| Step: 7
Training loss: 0.5704979300498962
Validation loss: 1.8057018800448346

Epoch: 6| Step: 8
Training loss: 0.4301152229309082
Validation loss: 1.825680717345207

Epoch: 6| Step: 9
Training loss: 0.461794376373291
Validation loss: 1.7666834528728197

Epoch: 6| Step: 10
Training loss: 0.5798056125640869
Validation loss: 1.8122450472206197

Epoch: 6| Step: 11
Training loss: 0.588655948638916
Validation loss: 1.827516568604336

Epoch: 6| Step: 12
Training loss: 0.709976077079773
Validation loss: 1.7978164021686842

Epoch: 6| Step: 13
Training loss: 0.5938066840171814
Validation loss: 1.8205751462649273

Epoch: 421| Step: 0
Training loss: 0.41085436940193176
Validation loss: 1.7630527814229329

Epoch: 6| Step: 1
Training loss: 0.5201183557510376
Validation loss: 1.8135008042858494

Epoch: 6| Step: 2
Training loss: 0.5270660519599915
Validation loss: 1.7937099523441766

Epoch: 6| Step: 3
Training loss: 0.2700067460536957
Validation loss: 1.8241119628311486

Epoch: 6| Step: 4
Training loss: 0.4406101107597351
Validation loss: 1.8177414888976722

Epoch: 6| Step: 5
Training loss: 0.33870211243629456
Validation loss: 1.7928002201100832

Epoch: 6| Step: 6
Training loss: 0.47437411546707153
Validation loss: 1.809199228081652

Epoch: 6| Step: 7
Training loss: 0.4786710739135742
Validation loss: 1.803497124743718

Epoch: 6| Step: 8
Training loss: 0.874873161315918
Validation loss: 1.7897583310322096

Epoch: 6| Step: 9
Training loss: 0.3826957941055298
Validation loss: 1.7611801829389346

Epoch: 6| Step: 10
Training loss: 0.27054116129875183
Validation loss: 1.7809985735083138

Epoch: 6| Step: 11
Training loss: 0.3372291922569275
Validation loss: 1.7592459776068246

Epoch: 6| Step: 12
Training loss: 0.7172366976737976
Validation loss: 1.7827556620361984

Epoch: 6| Step: 13
Training loss: 0.40125012397766113
Validation loss: 1.7993468443552654

Epoch: 422| Step: 0
Training loss: 0.4252541661262512
Validation loss: 1.802599605693612

Epoch: 6| Step: 1
Training loss: 0.4339277446269989
Validation loss: 1.7824530473319433

Epoch: 6| Step: 2
Training loss: 0.4598393738269806
Validation loss: 1.776488821993592

Epoch: 6| Step: 3
Training loss: 0.5034738779067993
Validation loss: 1.8172651490857523

Epoch: 6| Step: 4
Training loss: 0.35561466217041016
Validation loss: 1.8051085267015683

Epoch: 6| Step: 5
Training loss: 0.372111439704895
Validation loss: 1.7829036084554528

Epoch: 6| Step: 6
Training loss: 0.37903156876564026
Validation loss: 1.8124075243549962

Epoch: 6| Step: 7
Training loss: 0.6876956820487976
Validation loss: 1.8165631871069632

Epoch: 6| Step: 8
Training loss: 0.5361236333847046
Validation loss: 1.8141549825668335

Epoch: 6| Step: 9
Training loss: 0.34984898567199707
Validation loss: 1.7945002650701871

Epoch: 6| Step: 10
Training loss: 0.4523683190345764
Validation loss: 1.8137601190997708

Epoch: 6| Step: 11
Training loss: 0.45575404167175293
Validation loss: 1.8137483801893008

Epoch: 6| Step: 12
Training loss: 0.5848239660263062
Validation loss: 1.7761856458520378

Epoch: 6| Step: 13
Training loss: 0.1602170169353485
Validation loss: 1.7798320337008404

Epoch: 423| Step: 0
Training loss: 0.4989445209503174
Validation loss: 1.7697597690807876

Epoch: 6| Step: 1
Training loss: 0.3040432631969452
Validation loss: 1.7367485800097067

Epoch: 6| Step: 2
Training loss: 0.6289067268371582
Validation loss: 1.7154558345835695

Epoch: 6| Step: 3
Training loss: 0.496263712644577
Validation loss: 1.696838084087577

Epoch: 6| Step: 4
Training loss: 0.4155648648738861
Validation loss: 1.7065403435819892

Epoch: 6| Step: 5
Training loss: 0.38574448227882385
Validation loss: 1.7000196595345773

Epoch: 6| Step: 6
Training loss: 0.1986704170703888
Validation loss: 1.7722960031160744

Epoch: 6| Step: 7
Training loss: 0.38693296909332275
Validation loss: 1.742051007927105

Epoch: 6| Step: 8
Training loss: 0.7216091752052307
Validation loss: 1.7904467082792712

Epoch: 6| Step: 9
Training loss: 0.3120229244232178
Validation loss: 1.786033400925257

Epoch: 6| Step: 10
Training loss: 0.6288867592811584
Validation loss: 1.761973891206967

Epoch: 6| Step: 11
Training loss: 0.4619848132133484
Validation loss: 1.7790767902969031

Epoch: 6| Step: 12
Training loss: 0.7353340983390808
Validation loss: 1.7629635667288175

Epoch: 6| Step: 13
Training loss: 0.33115777373313904
Validation loss: 1.7196483105741522

Epoch: 424| Step: 0
Training loss: 0.4118451476097107
Validation loss: 1.7572115287985852

Epoch: 6| Step: 1
Training loss: 0.29667481780052185
Validation loss: 1.7090268083797988

Epoch: 6| Step: 2
Training loss: 0.5620118379592896
Validation loss: 1.6971726186813847

Epoch: 6| Step: 3
Training loss: 0.39666813611984253
Validation loss: 1.7068389128613215

Epoch: 6| Step: 4
Training loss: 0.506354570388794
Validation loss: 1.6766871483095231

Epoch: 6| Step: 5
Training loss: 0.7510560750961304
Validation loss: 1.7264688271348194

Epoch: 6| Step: 6
Training loss: 0.5679634809494019
Validation loss: 1.7537403850145237

Epoch: 6| Step: 7
Training loss: 0.635065495967865
Validation loss: 1.7678041099220194

Epoch: 6| Step: 8
Training loss: 0.3275415599346161
Validation loss: 1.772468456657984

Epoch: 6| Step: 9
Training loss: 0.5381858944892883
Validation loss: 1.7377257142015683

Epoch: 6| Step: 10
Training loss: 0.5231525301933289
Validation loss: 1.736092645634887

Epoch: 6| Step: 11
Training loss: 0.4078940749168396
Validation loss: 1.7264205819817

Epoch: 6| Step: 12
Training loss: 0.2880585193634033
Validation loss: 1.7572413016391057

Epoch: 6| Step: 13
Training loss: 0.18519672751426697
Validation loss: 1.7372279090266074

Epoch: 425| Step: 0
Training loss: 0.48505496978759766
Validation loss: 1.7837263781537291

Epoch: 6| Step: 1
Training loss: 0.38467228412628174
Validation loss: 1.8158039982600878

Epoch: 6| Step: 2
Training loss: 0.4358774423599243
Validation loss: 1.8132488599387548

Epoch: 6| Step: 3
Training loss: 0.318890780210495
Validation loss: 1.8778884487767373

Epoch: 6| Step: 4
Training loss: 0.20985251665115356
Validation loss: 1.8473354411381546

Epoch: 6| Step: 5
Training loss: 0.7292822599411011
Validation loss: 1.8377080668685257

Epoch: 6| Step: 6
Training loss: 0.6088733673095703
Validation loss: 1.7997227714907738

Epoch: 6| Step: 7
Training loss: 0.2823801636695862
Validation loss: 1.7886488988835325

Epoch: 6| Step: 8
Training loss: 0.2886528968811035
Validation loss: 1.8227241090548936

Epoch: 6| Step: 9
Training loss: 0.7836858034133911
Validation loss: 1.783001608746026

Epoch: 6| Step: 10
Training loss: 0.43310457468032837
Validation loss: 1.7097131718871414

Epoch: 6| Step: 11
Training loss: 0.3419090211391449
Validation loss: 1.7250886796623148

Epoch: 6| Step: 12
Training loss: 0.5935508012771606
Validation loss: 1.7226946046275478

Epoch: 6| Step: 13
Training loss: 0.5164320468902588
Validation loss: 1.715444395619054

Epoch: 426| Step: 0
Training loss: 0.6381904482841492
Validation loss: 1.7211314311591528

Epoch: 6| Step: 1
Training loss: 0.40462327003479004
Validation loss: 1.7703206436608427

Epoch: 6| Step: 2
Training loss: 0.5846189856529236
Validation loss: 1.7633134626573133

Epoch: 6| Step: 3
Training loss: 0.5322527289390564
Validation loss: 1.7670118488291258

Epoch: 6| Step: 4
Training loss: 0.5275745391845703
Validation loss: 1.8150803837724911

Epoch: 6| Step: 5
Training loss: 0.5332807898521423
Validation loss: 1.8214037879820792

Epoch: 6| Step: 6
Training loss: 0.184105783700943
Validation loss: 1.8022610384930846

Epoch: 6| Step: 7
Training loss: 0.4074767827987671
Validation loss: 1.8274804328077583

Epoch: 6| Step: 8
Training loss: 0.4320618212223053
Validation loss: 1.8319245961404615

Epoch: 6| Step: 9
Training loss: 0.38281136751174927
Validation loss: 1.8523006234117734

Epoch: 6| Step: 10
Training loss: 0.36704742908477783
Validation loss: 1.8361677726109822

Epoch: 6| Step: 11
Training loss: 0.7417835593223572
Validation loss: 1.7980026878336424

Epoch: 6| Step: 12
Training loss: 0.2167510837316513
Validation loss: 1.7560887285458144

Epoch: 6| Step: 13
Training loss: 0.5967209935188293
Validation loss: 1.7514398251810381

Epoch: 427| Step: 0
Training loss: 0.2816270589828491
Validation loss: 1.7313361257635138

Epoch: 6| Step: 1
Training loss: 0.27892357110977173
Validation loss: 1.6881564535120481

Epoch: 6| Step: 2
Training loss: 0.5702944397926331
Validation loss: 1.7308608293533325

Epoch: 6| Step: 3
Training loss: 1.0146815776824951
Validation loss: 1.6895174454617243

Epoch: 6| Step: 4
Training loss: 0.4810415506362915
Validation loss: 1.7346857952815231

Epoch: 6| Step: 5
Training loss: 0.2968395948410034
Validation loss: 1.7223817481789538

Epoch: 6| Step: 6
Training loss: 0.5325227975845337
Validation loss: 1.6999000413443452

Epoch: 6| Step: 7
Training loss: 0.31372687220573425
Validation loss: 1.7295805638836277

Epoch: 6| Step: 8
Training loss: 0.5865277051925659
Validation loss: 1.7481558553634151

Epoch: 6| Step: 9
Training loss: 0.4773190915584564
Validation loss: 1.7298919257297312

Epoch: 6| Step: 10
Training loss: 0.19069769978523254
Validation loss: 1.716894967581636

Epoch: 6| Step: 11
Training loss: 0.3417181074619293
Validation loss: 1.7049086645085325

Epoch: 6| Step: 12
Training loss: 0.44469279050827026
Validation loss: 1.7458048200094571

Epoch: 6| Step: 13
Training loss: 0.1973133236169815
Validation loss: 1.738395598626906

Epoch: 428| Step: 0
Training loss: 0.25068002939224243
Validation loss: 1.7586315998467066

Epoch: 6| Step: 1
Training loss: 0.3087877631187439
Validation loss: 1.6946035597914009

Epoch: 6| Step: 2
Training loss: 0.46839243173599243
Validation loss: 1.679375252416057

Epoch: 6| Step: 3
Training loss: 0.7930725812911987
Validation loss: 1.6925447448607414

Epoch: 6| Step: 4
Training loss: 0.353019654750824
Validation loss: 1.6795478879764516

Epoch: 6| Step: 5
Training loss: 0.3075603246688843
Validation loss: 1.7302471540307487

Epoch: 6| Step: 6
Training loss: 0.5826792120933533
Validation loss: 1.6882554459315475

Epoch: 6| Step: 7
Training loss: 0.41529542207717896
Validation loss: 1.6756540216425413

Epoch: 6| Step: 8
Training loss: 0.3380226790904999
Validation loss: 1.687648944957282

Epoch: 6| Step: 9
Training loss: 0.3037510812282562
Validation loss: 1.7118192718875023

Epoch: 6| Step: 10
Training loss: 0.4102528989315033
Validation loss: 1.6692563910638132

Epoch: 6| Step: 11
Training loss: 0.5085796117782593
Validation loss: 1.7251477613244006

Epoch: 6| Step: 12
Training loss: 0.8261107206344604
Validation loss: 1.721507268567239

Epoch: 6| Step: 13
Training loss: 0.4117642045021057
Validation loss: 1.6941516002019246

Epoch: 429| Step: 0
Training loss: 0.26281335949897766
Validation loss: 1.7420907853752055

Epoch: 6| Step: 1
Training loss: 0.7173851728439331
Validation loss: 1.746704081053375

Epoch: 6| Step: 2
Training loss: 0.44747209548950195
Validation loss: 1.7760075702462146

Epoch: 6| Step: 3
Training loss: 0.49141475558280945
Validation loss: 1.7788566440664313

Epoch: 6| Step: 4
Training loss: 0.497297465801239
Validation loss: 1.798186062484659

Epoch: 6| Step: 5
Training loss: 0.3466462790966034
Validation loss: 1.7343427212007585

Epoch: 6| Step: 6
Training loss: 0.39241528511047363
Validation loss: 1.7274819099774925

Epoch: 6| Step: 7
Training loss: 0.6175183057785034
Validation loss: 1.7257284208010601

Epoch: 6| Step: 8
Training loss: 0.30472660064697266
Validation loss: 1.691872158358174

Epoch: 6| Step: 9
Training loss: 0.4140639901161194
Validation loss: 1.7057178994660736

Epoch: 6| Step: 10
Training loss: 0.31819748878479004
Validation loss: 1.7138314477859005

Epoch: 6| Step: 11
Training loss: 0.45956963300704956
Validation loss: 1.7079796483439784

Epoch: 6| Step: 12
Training loss: 0.788735032081604
Validation loss: 1.742429397439444

Epoch: 6| Step: 13
Training loss: 0.29998642206192017
Validation loss: 1.7398339702237038

Epoch: 430| Step: 0
Training loss: 0.4122794270515442
Validation loss: 1.7483562833519393

Epoch: 6| Step: 1
Training loss: 0.42072203755378723
Validation loss: 1.779930668492471

Epoch: 6| Step: 2
Training loss: 0.2604820728302002
Validation loss: 1.7795566499874156

Epoch: 6| Step: 3
Training loss: 0.5955315828323364
Validation loss: 1.7531828995673888

Epoch: 6| Step: 4
Training loss: 0.873089075088501
Validation loss: 1.7787315217397546

Epoch: 6| Step: 5
Training loss: 0.5864986181259155
Validation loss: 1.7397301158597391

Epoch: 6| Step: 6
Training loss: 0.5933213233947754
Validation loss: 1.7410385172854188

Epoch: 6| Step: 7
Training loss: 0.3263816833496094
Validation loss: 1.7705597851866035

Epoch: 6| Step: 8
Training loss: 0.5855265259742737
Validation loss: 1.7438275493601316

Epoch: 6| Step: 9
Training loss: 0.505000114440918
Validation loss: 1.7374143356918006

Epoch: 6| Step: 10
Training loss: 0.2326250970363617
Validation loss: 1.7124589143260833

Epoch: 6| Step: 11
Training loss: 0.18561366200447083
Validation loss: 1.7316120465596516

Epoch: 6| Step: 12
Training loss: 0.3756406307220459
Validation loss: 1.7569922747150544

Epoch: 6| Step: 13
Training loss: 0.22133098542690277
Validation loss: 1.7918543597703338

Epoch: 431| Step: 0
Training loss: 0.5807664394378662
Validation loss: 1.833981055085377

Epoch: 6| Step: 1
Training loss: 0.6598745584487915
Validation loss: 1.8179616928100586

Epoch: 6| Step: 2
Training loss: 0.4158884286880493
Validation loss: 1.79286842320555

Epoch: 6| Step: 3
Training loss: 0.3060821294784546
Validation loss: 1.7907106620009228

Epoch: 6| Step: 4
Training loss: 0.2278311550617218
Validation loss: 1.7693406766460789

Epoch: 6| Step: 5
Training loss: 0.2534019947052002
Validation loss: 1.7764148148157264

Epoch: 6| Step: 6
Training loss: 0.5159244537353516
Validation loss: 1.7706213612710275

Epoch: 6| Step: 7
Training loss: 0.6903014183044434
Validation loss: 1.7393165365342171

Epoch: 6| Step: 8
Training loss: 0.36312735080718994
Validation loss: 1.7790866923588577

Epoch: 6| Step: 9
Training loss: 0.4726918339729309
Validation loss: 1.7939021125916512

Epoch: 6| Step: 10
Training loss: 0.5876071453094482
Validation loss: 1.7404414030813402

Epoch: 6| Step: 11
Training loss: 0.5738012194633484
Validation loss: 1.7588478493434128

Epoch: 6| Step: 12
Training loss: 0.4452299177646637
Validation loss: 1.7309460563044394

Epoch: 6| Step: 13
Training loss: 0.1640705019235611
Validation loss: 1.7496138362474338

Epoch: 432| Step: 0
Training loss: 0.32827484607696533
Validation loss: 1.7329927836695025

Epoch: 6| Step: 1
Training loss: 0.4862704575061798
Validation loss: 1.708367383608254

Epoch: 6| Step: 2
Training loss: 0.6651347279548645
Validation loss: 1.7278590650968655

Epoch: 6| Step: 3
Training loss: 0.43530911207199097
Validation loss: 1.733610446735095

Epoch: 6| Step: 4
Training loss: 0.2773968279361725
Validation loss: 1.7385750637259534

Epoch: 6| Step: 5
Training loss: 0.29439395666122437
Validation loss: 1.7227760809724049

Epoch: 6| Step: 6
Training loss: 0.3820941150188446
Validation loss: 1.7455894652233328

Epoch: 6| Step: 7
Training loss: 0.3003993630409241
Validation loss: 1.7496804755221131

Epoch: 6| Step: 8
Training loss: 0.5146207809448242
Validation loss: 1.7663771542169715

Epoch: 6| Step: 9
Training loss: 0.7326884269714355
Validation loss: 1.8009314165320447

Epoch: 6| Step: 10
Training loss: 0.4415097236633301
Validation loss: 1.739032377478897

Epoch: 6| Step: 11
Training loss: 0.45321857929229736
Validation loss: 1.7313154218017415

Epoch: 6| Step: 12
Training loss: 0.4265836775302887
Validation loss: 1.6864934377772833

Epoch: 6| Step: 13
Training loss: 0.24150602519512177
Validation loss: 1.7297993706118675

Epoch: 433| Step: 0
Training loss: 0.2849956452846527
Validation loss: 1.709381672643846

Epoch: 6| Step: 1
Training loss: 0.3362448215484619
Validation loss: 1.699622417009005

Epoch: 6| Step: 2
Training loss: 0.4571196436882019
Validation loss: 1.7110564042163152

Epoch: 6| Step: 3
Training loss: 0.5556701421737671
Validation loss: 1.7071542150230818

Epoch: 6| Step: 4
Training loss: 0.41897544264793396
Validation loss: 1.660896070541874

Epoch: 6| Step: 5
Training loss: 0.16783472895622253
Validation loss: 1.717287963436496

Epoch: 6| Step: 6
Training loss: 0.5117412805557251
Validation loss: 1.6959530435582644

Epoch: 6| Step: 7
Training loss: 0.4084029197692871
Validation loss: 1.7438181548990228

Epoch: 6| Step: 8
Training loss: 0.4428580105304718
Validation loss: 1.7009689654073408

Epoch: 6| Step: 9
Training loss: 0.37388303875923157
Validation loss: 1.7218349172223

Epoch: 6| Step: 10
Training loss: 0.523457407951355
Validation loss: 1.7064196140535417

Epoch: 6| Step: 11
Training loss: 0.53874671459198
Validation loss: 1.728443593107244

Epoch: 6| Step: 12
Training loss: 0.5964699983596802
Validation loss: 1.7224351821407196

Epoch: 6| Step: 13
Training loss: 0.21769554913043976
Validation loss: 1.702911506416977

Epoch: 434| Step: 0
Training loss: 0.30473750829696655
Validation loss: 1.714421458141778

Epoch: 6| Step: 1
Training loss: 0.3318464756011963
Validation loss: 1.7493099974047752

Epoch: 6| Step: 2
Training loss: 0.2934892475605011
Validation loss: 1.6826120230459398

Epoch: 6| Step: 3
Training loss: 0.5425602793693542
Validation loss: 1.7296265684148318

Epoch: 6| Step: 4
Training loss: 0.7054692506790161
Validation loss: 1.7064453042963499

Epoch: 6| Step: 5
Training loss: 0.535064697265625
Validation loss: 1.7173869686741983

Epoch: 6| Step: 6
Training loss: 0.3599551022052765
Validation loss: 1.691288807058847

Epoch: 6| Step: 7
Training loss: 0.3913303017616272
Validation loss: 1.7556389070326281

Epoch: 6| Step: 8
Training loss: 0.4946974515914917
Validation loss: 1.7131263940565047

Epoch: 6| Step: 9
Training loss: 0.5727602243423462
Validation loss: 1.7590350156189294

Epoch: 6| Step: 10
Training loss: 0.35423558950424194
Validation loss: 1.767143077747796

Epoch: 6| Step: 11
Training loss: 0.45261305570602417
Validation loss: 1.7593330798610565

Epoch: 6| Step: 12
Training loss: 0.41128119826316833
Validation loss: 1.7703185619846467

Epoch: 6| Step: 13
Training loss: 0.3734399974346161
Validation loss: 1.7893694216205227

Epoch: 435| Step: 0
Training loss: 0.5008738040924072
Validation loss: 1.797834333553109

Epoch: 6| Step: 1
Training loss: 0.3968750536441803
Validation loss: 1.7639721593549174

Epoch: 6| Step: 2
Training loss: 0.2393580824136734
Validation loss: 1.77489306593454

Epoch: 6| Step: 3
Training loss: 0.4822424650192261
Validation loss: 1.7710982727748092

Epoch: 6| Step: 4
Training loss: 0.33414334058761597
Validation loss: 1.7964519108495405

Epoch: 6| Step: 5
Training loss: 0.2961699962615967
Validation loss: 1.7679448730202132

Epoch: 6| Step: 6
Training loss: 0.3634621500968933
Validation loss: 1.7801150596269997

Epoch: 6| Step: 7
Training loss: 0.5865864753723145
Validation loss: 1.7032944476732643

Epoch: 6| Step: 8
Training loss: 0.3209976851940155
Validation loss: 1.698602855846446

Epoch: 6| Step: 9
Training loss: 0.6751547455787659
Validation loss: 1.7233359877781202

Epoch: 6| Step: 10
Training loss: 0.5192338228225708
Validation loss: 1.6548516750335693

Epoch: 6| Step: 11
Training loss: 0.431352436542511
Validation loss: 1.729442725899399

Epoch: 6| Step: 12
Training loss: 0.39976054430007935
Validation loss: 1.7144629698927685

Epoch: 6| Step: 13
Training loss: 0.38259801268577576
Validation loss: 1.70982777431447

Epoch: 436| Step: 0
Training loss: 0.32785969972610474
Validation loss: 1.7176962975532777

Epoch: 6| Step: 1
Training loss: 0.2394820749759674
Validation loss: 1.7579264179352792

Epoch: 6| Step: 2
Training loss: 0.5195552706718445
Validation loss: 1.8007222055107035

Epoch: 6| Step: 3
Training loss: 0.6287291646003723
Validation loss: 1.7568894201709377

Epoch: 6| Step: 4
Training loss: 0.3759390711784363
Validation loss: 1.7315479863074519

Epoch: 6| Step: 5
Training loss: 0.38965362310409546
Validation loss: 1.733773369942942

Epoch: 6| Step: 6
Training loss: 0.6628764271736145
Validation loss: 1.7510317576828824

Epoch: 6| Step: 7
Training loss: 0.37818479537963867
Validation loss: 1.7566400907372917

Epoch: 6| Step: 8
Training loss: 0.3699110746383667
Validation loss: 1.8001280497479182

Epoch: 6| Step: 9
Training loss: 0.6042627096176147
Validation loss: 1.8239589019488263

Epoch: 6| Step: 10
Training loss: 0.32839393615722656
Validation loss: 1.7945869212509484

Epoch: 6| Step: 11
Training loss: 0.2836817502975464
Validation loss: 1.791900445056218

Epoch: 6| Step: 12
Training loss: 0.4731842875480652
Validation loss: 1.827859651657843

Epoch: 6| Step: 13
Training loss: 0.6832743883132935
Validation loss: 1.8123177430963004

Epoch: 437| Step: 0
Training loss: 0.4491215944290161
Validation loss: 1.8050367422001337

Epoch: 6| Step: 1
Training loss: 0.6986719369888306
Validation loss: 1.7672192999111709

Epoch: 6| Step: 2
Training loss: 0.1764775514602661
Validation loss: 1.732319107619665

Epoch: 6| Step: 3
Training loss: 0.3302145004272461
Validation loss: 1.7611120670072493

Epoch: 6| Step: 4
Training loss: 0.6330171227455139
Validation loss: 1.7436195150498421

Epoch: 6| Step: 5
Training loss: 0.3610023558139801
Validation loss: 1.7322939775323356

Epoch: 6| Step: 6
Training loss: 0.4860820174217224
Validation loss: 1.7357669376557874

Epoch: 6| Step: 7
Training loss: 0.3411361575126648
Validation loss: 1.7305281425035128

Epoch: 6| Step: 8
Training loss: 0.3835715651512146
Validation loss: 1.775613756589992

Epoch: 6| Step: 9
Training loss: 0.3960600197315216
Validation loss: 1.7141905305206135

Epoch: 6| Step: 10
Training loss: 0.5056737661361694
Validation loss: 1.7024366765893915

Epoch: 6| Step: 11
Training loss: 0.45620936155319214
Validation loss: 1.6715569803791661

Epoch: 6| Step: 12
Training loss: 0.3755981922149658
Validation loss: 1.6995397242166663

Epoch: 6| Step: 13
Training loss: 0.10545836389064789
Validation loss: 1.7150524136840657

Epoch: 438| Step: 0
Training loss: 0.21359509229660034
Validation loss: 1.7438697199667654

Epoch: 6| Step: 1
Training loss: 0.4521733820438385
Validation loss: 1.7177080890183807

Epoch: 6| Step: 2
Training loss: 0.5560407638549805
Validation loss: 1.7648051502884075

Epoch: 6| Step: 3
Training loss: 0.6569401621818542
Validation loss: 1.765532470518543

Epoch: 6| Step: 4
Training loss: 0.44712507724761963
Validation loss: 1.7693818666601693

Epoch: 6| Step: 5
Training loss: 0.30568867921829224
Validation loss: 1.7777306033718971

Epoch: 6| Step: 6
Training loss: 0.40408578515052795
Validation loss: 1.7461636450982863

Epoch: 6| Step: 7
Training loss: 0.573654294013977
Validation loss: 1.7795027814885622

Epoch: 6| Step: 8
Training loss: 0.36981722712516785
Validation loss: 1.7549401919047039

Epoch: 6| Step: 9
Training loss: 0.42909008264541626
Validation loss: 1.7669800199488157

Epoch: 6| Step: 10
Training loss: 0.179071307182312
Validation loss: 1.7252468626986268

Epoch: 6| Step: 11
Training loss: 0.4899570941925049
Validation loss: 1.7375562921647103

Epoch: 6| Step: 12
Training loss: 0.30962803959846497
Validation loss: 1.7311962009758077

Epoch: 6| Step: 13
Training loss: 0.45641449093818665
Validation loss: 1.7542028683488087

Epoch: 439| Step: 0
Training loss: 0.4884302020072937
Validation loss: 1.7129502860448693

Epoch: 6| Step: 1
Training loss: 0.4915311932563782
Validation loss: 1.7810077846691172

Epoch: 6| Step: 2
Training loss: 0.3000282645225525
Validation loss: 1.7812175558459373

Epoch: 6| Step: 3
Training loss: 0.6250617504119873
Validation loss: 1.8016926998733191

Epoch: 6| Step: 4
Training loss: 0.4912613034248352
Validation loss: 1.8306942934631019

Epoch: 6| Step: 5
Training loss: 0.19862087070941925
Validation loss: 1.8266500939605057

Epoch: 6| Step: 6
Training loss: 0.3374928832054138
Validation loss: 1.8156790374427714

Epoch: 6| Step: 7
Training loss: 0.4191462993621826
Validation loss: 1.7845208414139286

Epoch: 6| Step: 8
Training loss: 0.42249438166618347
Validation loss: 1.71810197061108

Epoch: 6| Step: 9
Training loss: 0.2368258535861969
Validation loss: 1.7122630585906327

Epoch: 6| Step: 10
Training loss: 0.49776673316955566
Validation loss: 1.6927815470644223

Epoch: 6| Step: 11
Training loss: 0.4401947557926178
Validation loss: 1.7012203329352922

Epoch: 6| Step: 12
Training loss: 0.5377545952796936
Validation loss: 1.6745169290932276

Epoch: 6| Step: 13
Training loss: 0.5354297161102295
Validation loss: 1.6345063717134538

Epoch: 440| Step: 0
Training loss: 0.47685086727142334
Validation loss: 1.684065285549369

Epoch: 6| Step: 1
Training loss: 0.18914197385311127
Validation loss: 1.6564835604800974

Epoch: 6| Step: 2
Training loss: 0.37767958641052246
Validation loss: 1.6785650637841993

Epoch: 6| Step: 3
Training loss: 0.40926826000213623
Validation loss: 1.6998931156691683

Epoch: 6| Step: 4
Training loss: 0.3011385202407837
Validation loss: 1.6891135977160545

Epoch: 6| Step: 5
Training loss: 0.671770453453064
Validation loss: 1.7230436385318797

Epoch: 6| Step: 6
Training loss: 0.35541439056396484
Validation loss: 1.7864835441753428

Epoch: 6| Step: 7
Training loss: 0.45212051272392273
Validation loss: 1.7805530653204968

Epoch: 6| Step: 8
Training loss: 0.6304624676704407
Validation loss: 1.799001060506349

Epoch: 6| Step: 9
Training loss: 0.35820332169532776
Validation loss: 1.7979850346042263

Epoch: 6| Step: 10
Training loss: 0.5196566581726074
Validation loss: 1.796292269101707

Epoch: 6| Step: 11
Training loss: 0.536112368106842
Validation loss: 1.7827989157810007

Epoch: 6| Step: 12
Training loss: 0.5222104787826538
Validation loss: 1.8001596568733134

Epoch: 6| Step: 13
Training loss: 0.5218974947929382
Validation loss: 1.7837724454941288

Epoch: 441| Step: 0
Training loss: 0.7406954169273376
Validation loss: 1.7815056039441017

Epoch: 6| Step: 1
Training loss: 0.37140658497810364
Validation loss: 1.7641967060745403

Epoch: 6| Step: 2
Training loss: 0.31849440932273865
Validation loss: 1.77617415817835

Epoch: 6| Step: 3
Training loss: 0.4400697946548462
Validation loss: 1.684954753486059

Epoch: 6| Step: 4
Training loss: 0.38291943073272705
Validation loss: 1.77552447524122

Epoch: 6| Step: 5
Training loss: 0.4557651877403259
Validation loss: 1.7130074693310646

Epoch: 6| Step: 6
Training loss: 0.5862545967102051
Validation loss: 1.7026180682643768

Epoch: 6| Step: 7
Training loss: 0.26905179023742676
Validation loss: 1.686906651784015

Epoch: 6| Step: 8
Training loss: 0.5263832807540894
Validation loss: 1.6281575156796364

Epoch: 6| Step: 9
Training loss: 0.31033873558044434
Validation loss: 1.6913391851609754

Epoch: 6| Step: 10
Training loss: 0.4068535268306732
Validation loss: 1.6715961579353578

Epoch: 6| Step: 11
Training loss: 0.4255392551422119
Validation loss: 1.699554345941031

Epoch: 6| Step: 12
Training loss: 0.5884100794792175
Validation loss: 1.728191711569345

Epoch: 6| Step: 13
Training loss: 0.33053314685821533
Validation loss: 1.6981119161011071

Epoch: 442| Step: 0
Training loss: 0.4844437837600708
Validation loss: 1.7353563641989103

Epoch: 6| Step: 1
Training loss: 0.42387571930885315
Validation loss: 1.7212367467982794

Epoch: 6| Step: 2
Training loss: 0.3582283854484558
Validation loss: 1.7635597131585563

Epoch: 6| Step: 3
Training loss: 0.34123122692108154
Validation loss: 1.7557020905197307

Epoch: 6| Step: 4
Training loss: 0.3927675187587738
Validation loss: 1.7711843470091462

Epoch: 6| Step: 5
Training loss: 0.2610815763473511
Validation loss: 1.7893936339245047

Epoch: 6| Step: 6
Training loss: 0.37856027483940125
Validation loss: 1.7680318611924366

Epoch: 6| Step: 7
Training loss: 0.4681735038757324
Validation loss: 1.789397023057425

Epoch: 6| Step: 8
Training loss: 0.6286373138427734
Validation loss: 1.7696803705666655

Epoch: 6| Step: 9
Training loss: 0.5826083421707153
Validation loss: 1.742807146041624

Epoch: 6| Step: 10
Training loss: 0.4443117678165436
Validation loss: 1.7379671296765726

Epoch: 6| Step: 11
Training loss: 0.36781781911849976
Validation loss: 1.7191638279986639

Epoch: 6| Step: 12
Training loss: 0.48765110969543457
Validation loss: 1.6682097104287916

Epoch: 6| Step: 13
Training loss: 0.19094045460224152
Validation loss: 1.6782189466620003

Epoch: 443| Step: 0
Training loss: 0.4701007008552551
Validation loss: 1.6671727972645913

Epoch: 6| Step: 1
Training loss: 0.4142734408378601
Validation loss: 1.6555617765713764

Epoch: 6| Step: 2
Training loss: 0.41364195942878723
Validation loss: 1.6352608870434504

Epoch: 6| Step: 3
Training loss: 0.5238209962844849
Validation loss: 1.674978615776185

Epoch: 6| Step: 4
Training loss: 0.5790676474571228
Validation loss: 1.693072739467826

Epoch: 6| Step: 5
Training loss: 0.300648957490921
Validation loss: 1.6975993033378356

Epoch: 6| Step: 6
Training loss: 0.4973773956298828
Validation loss: 1.7127321868814447

Epoch: 6| Step: 7
Training loss: 0.2999057173728943
Validation loss: 1.7247021723819036

Epoch: 6| Step: 8
Training loss: 0.37461739778518677
Validation loss: 1.7373114978113482

Epoch: 6| Step: 9
Training loss: 0.25092336535453796
Validation loss: 1.7288961154158398

Epoch: 6| Step: 10
Training loss: 0.4237653613090515
Validation loss: 1.743541899547782

Epoch: 6| Step: 11
Training loss: 0.3628566563129425
Validation loss: 1.7218138184598697

Epoch: 6| Step: 12
Training loss: 0.24345695972442627
Validation loss: 1.7184621326385006

Epoch: 6| Step: 13
Training loss: 0.6113956570625305
Validation loss: 1.6936690474069247

Epoch: 444| Step: 0
Training loss: 0.6310986280441284
Validation loss: 1.707981304455829

Epoch: 6| Step: 1
Training loss: 0.3905925750732422
Validation loss: 1.7224233445300852

Epoch: 6| Step: 2
Training loss: 0.40897107124328613
Validation loss: 1.6940082401357672

Epoch: 6| Step: 3
Training loss: 0.3268201947212219
Validation loss: 1.686589708892248

Epoch: 6| Step: 4
Training loss: 0.35681474208831787
Validation loss: 1.638070990962367

Epoch: 6| Step: 5
Training loss: 0.435812771320343
Validation loss: 1.6659934661721671

Epoch: 6| Step: 6
Training loss: 0.5665555000305176
Validation loss: 1.6569784995048278

Epoch: 6| Step: 7
Training loss: 0.27221328020095825
Validation loss: 1.7222860833649993

Epoch: 6| Step: 8
Training loss: 0.2971232533454895
Validation loss: 1.6940046151479085

Epoch: 6| Step: 9
Training loss: 0.305303692817688
Validation loss: 1.677655320013723

Epoch: 6| Step: 10
Training loss: 0.5284368991851807
Validation loss: 1.708247302680887

Epoch: 6| Step: 11
Training loss: 0.510498583316803
Validation loss: 1.7159350097820323

Epoch: 6| Step: 12
Training loss: 0.2416977733373642
Validation loss: 1.6829135815302532

Epoch: 6| Step: 13
Training loss: 0.45490729808807373
Validation loss: 1.7259265991949266

Epoch: 445| Step: 0
Training loss: 0.35732775926589966
Validation loss: 1.7099182234015515

Epoch: 6| Step: 1
Training loss: 0.6032032370567322
Validation loss: 1.6908750162329724

Epoch: 6| Step: 2
Training loss: 0.4363131523132324
Validation loss: 1.7184135067847468

Epoch: 6| Step: 3
Training loss: 0.2386067509651184
Validation loss: 1.690838147235173

Epoch: 6| Step: 4
Training loss: 0.16312751173973083
Validation loss: 1.6770767050404702

Epoch: 6| Step: 5
Training loss: 0.5513627529144287
Validation loss: 1.7108098755600631

Epoch: 6| Step: 6
Training loss: 0.36094367504119873
Validation loss: 1.7220508449821061

Epoch: 6| Step: 7
Training loss: 0.5368447303771973
Validation loss: 1.7565929723042313

Epoch: 6| Step: 8
Training loss: 0.45206308364868164
Validation loss: 1.7249300595252746

Epoch: 6| Step: 9
Training loss: 0.3878483772277832
Validation loss: 1.751800399954601

Epoch: 6| Step: 10
Training loss: 0.3376361131668091
Validation loss: 1.739159405872386

Epoch: 6| Step: 11
Training loss: 0.3393564224243164
Validation loss: 1.7829358885365147

Epoch: 6| Step: 12
Training loss: 0.6021472811698914
Validation loss: 1.7604796245533934

Epoch: 6| Step: 13
Training loss: 0.18726937472820282
Validation loss: 1.8054410257647115

Epoch: 446| Step: 0
Training loss: 0.4353457987308502
Validation loss: 1.7658594885180074

Epoch: 6| Step: 1
Training loss: 0.3825153410434723
Validation loss: 1.7359326911228958

Epoch: 6| Step: 2
Training loss: 0.3832366168498993
Validation loss: 1.7052669935328986

Epoch: 6| Step: 3
Training loss: 0.3206356167793274
Validation loss: 1.740391287752377

Epoch: 6| Step: 4
Training loss: 0.3835921883583069
Validation loss: 1.6965619466638053

Epoch: 6| Step: 5
Training loss: 0.4126794636249542
Validation loss: 1.7253234976081437

Epoch: 6| Step: 6
Training loss: 0.5383408069610596
Validation loss: 1.6634538455676007

Epoch: 6| Step: 7
Training loss: 0.48814481496810913
Validation loss: 1.6848436850373463

Epoch: 6| Step: 8
Training loss: 0.49977779388427734
Validation loss: 1.6798485748229488

Epoch: 6| Step: 9
Training loss: 0.5066269040107727
Validation loss: 1.6773661772410076

Epoch: 6| Step: 10
Training loss: 0.19099128246307373
Validation loss: 1.6783159407236243

Epoch: 6| Step: 11
Training loss: 0.27961164712905884
Validation loss: 1.6524649422655824

Epoch: 6| Step: 12
Training loss: 0.5809521675109863
Validation loss: 1.6651299102332002

Epoch: 6| Step: 13
Training loss: 0.1184408962726593
Validation loss: 1.6568462515390048

Epoch: 447| Step: 0
Training loss: 0.3193192183971405
Validation loss: 1.6626081697402462

Epoch: 6| Step: 1
Training loss: 0.5659710168838501
Validation loss: 1.698417894301876

Epoch: 6| Step: 2
Training loss: 0.6644443869590759
Validation loss: 1.6913343398801741

Epoch: 6| Step: 3
Training loss: 0.4627748727798462
Validation loss: 1.6805154738887664

Epoch: 6| Step: 4
Training loss: 0.3884921371936798
Validation loss: 1.718031180802212

Epoch: 6| Step: 5
Training loss: 0.49001288414001465
Validation loss: 1.763037132960494

Epoch: 6| Step: 6
Training loss: 0.3690555989742279
Validation loss: 1.713515438059325

Epoch: 6| Step: 7
Training loss: 0.4049033224582672
Validation loss: 1.7511414609929568

Epoch: 6| Step: 8
Training loss: 0.23986591398715973
Validation loss: 1.7326491084150089

Epoch: 6| Step: 9
Training loss: 0.20842859148979187
Validation loss: 1.7141466845748246

Epoch: 6| Step: 10
Training loss: 0.39673614501953125
Validation loss: 1.7108733243839715

Epoch: 6| Step: 11
Training loss: 0.33832022547721863
Validation loss: 1.6928322520307315

Epoch: 6| Step: 12
Training loss: 0.29816097021102905
Validation loss: 1.6915020840142363

Epoch: 6| Step: 13
Training loss: 0.4588468372821808
Validation loss: 1.6734283098610498

Epoch: 448| Step: 0
Training loss: 0.4499019980430603
Validation loss: 1.6484384805925432

Epoch: 6| Step: 1
Training loss: 0.3736506700515747
Validation loss: 1.703299201944823

Epoch: 6| Step: 2
Training loss: 0.30642834305763245
Validation loss: 1.6806088532170942

Epoch: 6| Step: 3
Training loss: 0.43480703234672546
Validation loss: 1.669159548897897

Epoch: 6| Step: 4
Training loss: 0.21457242965698242
Validation loss: 1.6777126302001297

Epoch: 6| Step: 5
Training loss: 0.41780105233192444
Validation loss: 1.7009581506893199

Epoch: 6| Step: 6
Training loss: 0.5319080352783203
Validation loss: 1.6921047523457518

Epoch: 6| Step: 7
Training loss: 0.3394559621810913
Validation loss: 1.7065399731359174

Epoch: 6| Step: 8
Training loss: 0.32599204778671265
Validation loss: 1.720297913397512

Epoch: 6| Step: 9
Training loss: 0.3200263977050781
Validation loss: 1.6982809433373072

Epoch: 6| Step: 10
Training loss: 0.4370265305042267
Validation loss: 1.6806928598752586

Epoch: 6| Step: 11
Training loss: 0.30747008323669434
Validation loss: 1.6865591515776932

Epoch: 6| Step: 12
Training loss: 0.3853338360786438
Validation loss: 1.7035442731713737

Epoch: 6| Step: 13
Training loss: 1.0053718090057373
Validation loss: 1.7070163052569154

Epoch: 449| Step: 0
Training loss: 0.493008553981781
Validation loss: 1.7228861034557383

Epoch: 6| Step: 1
Training loss: 0.1891084909439087
Validation loss: 1.731237401244461

Epoch: 6| Step: 2
Training loss: 0.32497653365135193
Validation loss: 1.731228046519782

Epoch: 6| Step: 3
Training loss: 0.4031825065612793
Validation loss: 1.7539087059677287

Epoch: 6| Step: 4
Training loss: 0.3264106810092926
Validation loss: 1.7266556268097253

Epoch: 6| Step: 5
Training loss: 0.6572616100311279
Validation loss: 1.7460300819848174

Epoch: 6| Step: 6
Training loss: 0.24098114669322968
Validation loss: 1.7449081520880423

Epoch: 6| Step: 7
Training loss: 0.3280513286590576
Validation loss: 1.7579351855862526

Epoch: 6| Step: 8
Training loss: 0.5400054454803467
Validation loss: 1.6959163847789969

Epoch: 6| Step: 9
Training loss: 0.3923887014389038
Validation loss: 1.756225121918545

Epoch: 6| Step: 10
Training loss: 0.4661533236503601
Validation loss: 1.685032932989059

Epoch: 6| Step: 11
Training loss: 0.4193854033946991
Validation loss: 1.7026023877564298

Epoch: 6| Step: 12
Training loss: 0.33619582653045654
Validation loss: 1.7240764582028953

Epoch: 6| Step: 13
Training loss: 0.5793132781982422
Validation loss: 1.721637124656349

Epoch: 450| Step: 0
Training loss: 0.4206010699272156
Validation loss: 1.7509980368357834

Epoch: 6| Step: 1
Training loss: 0.41494208574295044
Validation loss: 1.6928371126933763

Epoch: 6| Step: 2
Training loss: 0.6178377866744995
Validation loss: 1.7235777929265013

Epoch: 6| Step: 3
Training loss: 0.34359028935432434
Validation loss: 1.6902458219118015

Epoch: 6| Step: 4
Training loss: 0.3839106559753418
Validation loss: 1.6900080916702107

Epoch: 6| Step: 5
Training loss: 0.5069375038146973
Validation loss: 1.7292805076927267

Epoch: 6| Step: 6
Training loss: 0.35430389642715454
Validation loss: 1.7197566865592875

Epoch: 6| Step: 7
Training loss: 0.5656284093856812
Validation loss: 1.7262819390143118

Epoch: 6| Step: 8
Training loss: 0.3872680962085724
Validation loss: 1.7684520880381267

Epoch: 6| Step: 9
Training loss: 0.44796013832092285
Validation loss: 1.7537489603924494

Epoch: 6| Step: 10
Training loss: 0.3581593632698059
Validation loss: 1.7401434298484557

Epoch: 6| Step: 11
Training loss: 0.29163336753845215
Validation loss: 1.7644443076143983

Epoch: 6| Step: 12
Training loss: 0.38571467995643616
Validation loss: 1.7407023227342995

Epoch: 6| Step: 13
Training loss: 0.49964872002601624
Validation loss: 1.7579485447176042

Testing loss: 2.0204879336886936
