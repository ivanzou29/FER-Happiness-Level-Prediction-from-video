Epoch: 1| Step: 0
Training loss: 5.436685084520893
Validation loss: 5.7837525170459445

Epoch: 6| Step: 1
Training loss: 5.573811548940767
Validation loss: 5.775906432831986

Epoch: 6| Step: 2
Training loss: 5.834440435074274
Validation loss: 5.7687933510880285

Epoch: 6| Step: 3
Training loss: 5.418552226997018
Validation loss: 5.761472215642657

Epoch: 6| Step: 4
Training loss: 5.388725498951654
Validation loss: 5.754454516861722

Epoch: 6| Step: 5
Training loss: 5.773310637983743
Validation loss: 5.747662172878391

Epoch: 6| Step: 6
Training loss: 6.3420801830774725
Validation loss: 5.740121789113067

Epoch: 6| Step: 7
Training loss: 5.03996327946925
Validation loss: 5.732369167466192

Epoch: 6| Step: 8
Training loss: 5.744945128654407
Validation loss: 5.7250586507103325

Epoch: 6| Step: 9
Training loss: 5.133683454455181
Validation loss: 5.716486714690063

Epoch: 6| Step: 10
Training loss: 6.482283877805795
Validation loss: 5.708354725658026

Epoch: 6| Step: 11
Training loss: 6.70734718924991
Validation loss: 5.698885842343661

Epoch: 6| Step: 12
Training loss: 5.437823757311023
Validation loss: 5.68858155473133

Epoch: 6| Step: 13
Training loss: 6.44986847736015
Validation loss: 5.6774523525267275

Epoch: 2| Step: 0
Training loss: 5.243901298077092
Validation loss: 5.665634619864262

Epoch: 6| Step: 1
Training loss: 5.913412927710468
Validation loss: 5.654028352475169

Epoch: 6| Step: 2
Training loss: 5.469690558068654
Validation loss: 5.640821131545815

Epoch: 6| Step: 3
Training loss: 5.876287441008606
Validation loss: 5.6269683128657935

Epoch: 6| Step: 4
Training loss: 5.019488311465178
Validation loss: 5.611967366798142

Epoch: 6| Step: 5
Training loss: 5.711076434698519
Validation loss: 5.596058183056739

Epoch: 6| Step: 6
Training loss: 5.228732492525656
Validation loss: 5.579157687418321

Epoch: 6| Step: 7
Training loss: 5.052157917324243
Validation loss: 5.561315244642585

Epoch: 6| Step: 8
Training loss: 6.397909252080055
Validation loss: 5.54313343198351

Epoch: 6| Step: 9
Training loss: 5.312433219938731
Validation loss: 5.5212985467505495

Epoch: 6| Step: 10
Training loss: 6.032417144901985
Validation loss: 5.501754016801543

Epoch: 6| Step: 11
Training loss: 5.48946168633254
Validation loss: 5.478524031146518

Epoch: 6| Step: 12
Training loss: 5.121744377886514
Validation loss: 5.45612485097196

Epoch: 6| Step: 13
Training loss: 6.847512521666171
Validation loss: 5.431484651343643

Epoch: 3| Step: 0
Training loss: 5.411844346858023
Validation loss: 5.405621192066345

Epoch: 6| Step: 1
Training loss: 6.011027057754981
Validation loss: 5.380735852518972

Epoch: 6| Step: 2
Training loss: 4.423669457695417
Validation loss: 5.354088020856353

Epoch: 6| Step: 3
Training loss: 6.076094339649147
Validation loss: 5.326838901227173

Epoch: 6| Step: 4
Training loss: 5.8348719429667275
Validation loss: 5.297100763509605

Epoch: 6| Step: 5
Training loss: 4.587522268631025
Validation loss: 5.26845228694851

Epoch: 6| Step: 6
Training loss: 5.059401517613587
Validation loss: 5.2369409841049315

Epoch: 6| Step: 7
Training loss: 5.1976109518637115
Validation loss: 5.209001901682774

Epoch: 6| Step: 8
Training loss: 5.09971522115834
Validation loss: 5.176848000423646

Epoch: 6| Step: 9
Training loss: 4.913644842644657
Validation loss: 5.145444763240862

Epoch: 6| Step: 10
Training loss: 5.761965368133034
Validation loss: 5.113414905202971

Epoch: 6| Step: 11
Training loss: 4.555341565655111
Validation loss: 5.0806011110796385

Epoch: 6| Step: 12
Training loss: 5.3100849720968375
Validation loss: 5.049230266444174

Epoch: 6| Step: 13
Training loss: 5.468578226934007
Validation loss: 5.014881192223819

Epoch: 4| Step: 0
Training loss: 5.174110137062142
Validation loss: 4.980986760333333

Epoch: 6| Step: 1
Training loss: 4.810378164228436
Validation loss: 4.946358166390601

Epoch: 6| Step: 2
Training loss: 4.782736752797254
Validation loss: 4.910446755822529

Epoch: 6| Step: 3
Training loss: 5.204994392795089
Validation loss: 4.8758090693825435

Epoch: 6| Step: 4
Training loss: 4.4650846801793
Validation loss: 4.837763470661557

Epoch: 6| Step: 5
Training loss: 5.642650631511045
Validation loss: 4.8021149512709655

Epoch: 6| Step: 6
Training loss: 4.778613591583444
Validation loss: 4.768623195129868

Epoch: 6| Step: 7
Training loss: 3.9512708333813906
Validation loss: 4.737858107261895

Epoch: 6| Step: 8
Training loss: 4.920804152481592
Validation loss: 4.710044358645956

Epoch: 6| Step: 9
Training loss: 4.347347608443302
Validation loss: 4.683723522145713

Epoch: 6| Step: 10
Training loss: 5.323970304697224
Validation loss: 4.6587988404454235

Epoch: 6| Step: 11
Training loss: 5.369973249599668
Validation loss: 4.632314798075835

Epoch: 6| Step: 12
Training loss: 3.6318589138238666
Validation loss: 4.604795237166948

Epoch: 6| Step: 13
Training loss: 5.326986689083139
Validation loss: 4.582270861372236

Epoch: 5| Step: 0
Training loss: 5.857932765211485
Validation loss: 4.559695141494064

Epoch: 6| Step: 1
Training loss: 5.553548403662848
Validation loss: 4.540891265983462

Epoch: 6| Step: 2
Training loss: 4.82928749089115
Validation loss: 4.523816413983632

Epoch: 6| Step: 3
Training loss: 5.114191334212056
Validation loss: 4.5073002901563575

Epoch: 6| Step: 4
Training loss: 5.143256073571496
Validation loss: 4.48933996346026

Epoch: 6| Step: 5
Training loss: 3.6927331547873616
Validation loss: 4.461574372708756

Epoch: 6| Step: 6
Training loss: 3.6541196697581055
Validation loss: 4.439207394157862

Epoch: 6| Step: 7
Training loss: 4.333625465718516
Validation loss: 4.422927133537952

Epoch: 6| Step: 8
Training loss: 4.103073568377678
Validation loss: 4.402080455477984

Epoch: 6| Step: 9
Training loss: 4.7703129957981645
Validation loss: 4.384868759563717

Epoch: 6| Step: 10
Training loss: 2.620074692309368
Validation loss: 4.371313709615817

Epoch: 6| Step: 11
Training loss: 4.796641589521785
Validation loss: 4.351241590834398

Epoch: 6| Step: 12
Training loss: 3.823367529674302
Validation loss: 4.333239948758906

Epoch: 6| Step: 13
Training loss: 4.294374272303824
Validation loss: 4.307485322417631

Epoch: 6| Step: 0
Training loss: 4.337924481379585
Validation loss: 4.287435878452483

Epoch: 6| Step: 1
Training loss: 5.1802604438967705
Validation loss: 4.2674255645688834

Epoch: 6| Step: 2
Training loss: 3.7631435211491207
Validation loss: 4.245814110889935

Epoch: 6| Step: 3
Training loss: 4.605287142239405
Validation loss: 4.2421934585953975

Epoch: 6| Step: 4
Training loss: 4.398061299200856
Validation loss: 4.223605426901319

Epoch: 6| Step: 5
Training loss: 4.756955926267159
Validation loss: 4.21182172837016

Epoch: 6| Step: 6
Training loss: 5.092713045692982
Validation loss: 4.196787528900835

Epoch: 6| Step: 7
Training loss: 3.7962755271598496
Validation loss: 4.190986881061172

Epoch: 6| Step: 8
Training loss: 3.4128330557247537
Validation loss: 4.183087091307844

Epoch: 6| Step: 9
Training loss: 3.7214978748475884
Validation loss: 4.1817467424839005

Epoch: 6| Step: 10
Training loss: 4.767231654760075
Validation loss: 4.165305448521749

Epoch: 6| Step: 11
Training loss: 3.7149587587349555
Validation loss: 4.148324972204344

Epoch: 6| Step: 12
Training loss: 3.7817866677525087
Validation loss: 4.137127197549711

Epoch: 6| Step: 13
Training loss: 5.226474550245627
Validation loss: 4.127964146800751

Epoch: 7| Step: 0
Training loss: 4.880017168608935
Validation loss: 4.12811843816775

Epoch: 6| Step: 1
Training loss: 4.324392754586804
Validation loss: 4.110488878510012

Epoch: 6| Step: 2
Training loss: 4.4056735913014275
Validation loss: 4.098371467034766

Epoch: 6| Step: 3
Training loss: 3.512452453074265
Validation loss: 4.090063994913627

Epoch: 6| Step: 4
Training loss: 3.2008632210869963
Validation loss: 4.086515909560626

Epoch: 6| Step: 5
Training loss: 4.53231735812549
Validation loss: 4.082967723394522

Epoch: 6| Step: 6
Training loss: 5.029294599514048
Validation loss: 4.076147711307158

Epoch: 6| Step: 7
Training loss: 3.873214556459042
Validation loss: 4.062656666501193

Epoch: 6| Step: 8
Training loss: 4.736506319135028
Validation loss: 4.048457122247448

Epoch: 6| Step: 9
Training loss: 3.8912465774810276
Validation loss: 4.034569603017052

Epoch: 6| Step: 10
Training loss: 3.6141820825962365
Validation loss: 4.042711868515203

Epoch: 6| Step: 11
Training loss: 4.187628900622185
Validation loss: 4.037371476880757

Epoch: 6| Step: 12
Training loss: 4.105396970634999
Validation loss: 4.020195644503123

Epoch: 6| Step: 13
Training loss: 4.25098318059587
Validation loss: 3.997476934382741

Epoch: 8| Step: 0
Training loss: 3.676495441128371
Validation loss: 3.986200137966015

Epoch: 6| Step: 1
Training loss: 3.1279748108866707
Validation loss: 3.980175954423358

Epoch: 6| Step: 2
Training loss: 4.418285193270378
Validation loss: 3.9729989345125163

Epoch: 6| Step: 3
Training loss: 4.037959466542771
Validation loss: 3.970693987906927

Epoch: 6| Step: 4
Training loss: 4.354757509192353
Validation loss: 3.961787740533318

Epoch: 6| Step: 5
Training loss: 4.210594602081299
Validation loss: 3.9505628435853835

Epoch: 6| Step: 6
Training loss: 4.199881397570902
Validation loss: 3.9385965620291468

Epoch: 6| Step: 7
Training loss: 4.138055659204197
Validation loss: 3.9226499938238533

Epoch: 6| Step: 8
Training loss: 4.3012278201111425
Validation loss: 3.9120884653432997

Epoch: 6| Step: 9
Training loss: 4.496163746332854
Validation loss: 3.8948263385118715

Epoch: 6| Step: 10
Training loss: 5.200765905462191
Validation loss: 3.883690324035575

Epoch: 6| Step: 11
Training loss: 3.677182780677981
Validation loss: 3.886442420796663

Epoch: 6| Step: 12
Training loss: 3.910878849237481
Validation loss: 3.8779878136124775

Epoch: 6| Step: 13
Training loss: 1.6745696411686732
Validation loss: 3.8521017319334443

Epoch: 9| Step: 0
Training loss: 3.927156456115614
Validation loss: 3.860937854201123

Epoch: 6| Step: 1
Training loss: 4.0687571535765406
Validation loss: 3.83436356263726

Epoch: 6| Step: 2
Training loss: 3.631722497976288
Validation loss: 3.82948121086245

Epoch: 6| Step: 3
Training loss: 3.770434209168937
Validation loss: 3.821121140639706

Epoch: 6| Step: 4
Training loss: 4.782033419783857
Validation loss: 3.8171711854539585

Epoch: 6| Step: 5
Training loss: 3.915161100461374
Validation loss: 3.8082948676063

Epoch: 6| Step: 6
Training loss: 3.834845175670369
Validation loss: 3.8004422509568223

Epoch: 6| Step: 7
Training loss: 4.248562738074544
Validation loss: 3.781193894753384

Epoch: 6| Step: 8
Training loss: 3.9134898728141794
Validation loss: 3.7763372060207505

Epoch: 6| Step: 9
Training loss: 3.839294580595101
Validation loss: 3.7678338252427945

Epoch: 6| Step: 10
Training loss: 3.57936014904034
Validation loss: 3.7625560390703643

Epoch: 6| Step: 11
Training loss: 3.638438865912336
Validation loss: 3.7596881646992024

Epoch: 6| Step: 12
Training loss: 4.303125115244303
Validation loss: 3.7474584628606893

Epoch: 6| Step: 13
Training loss: 3.920434330019894
Validation loss: 3.7445187273306466

Epoch: 10| Step: 0
Training loss: 4.116455939661425
Validation loss: 3.734405770082588

Epoch: 6| Step: 1
Training loss: 3.9895694158060664
Validation loss: 3.7238595091327142

Epoch: 6| Step: 2
Training loss: 3.9538875040462798
Validation loss: 3.717035772785761

Epoch: 6| Step: 3
Training loss: 3.326705414948351
Validation loss: 3.712468498568387

Epoch: 6| Step: 4
Training loss: 3.2772468488915107
Validation loss: 3.7023998073269024

Epoch: 6| Step: 5
Training loss: 3.2454887772035357
Validation loss: 3.700933319195363

Epoch: 6| Step: 6
Training loss: 5.127316951376524
Validation loss: 3.6936775688611503

Epoch: 6| Step: 7
Training loss: 3.8541011220496504
Validation loss: 3.688473872692241

Epoch: 6| Step: 8
Training loss: 2.905023951998009
Validation loss: 3.684934860933625

Epoch: 6| Step: 9
Training loss: 3.214640540262719
Validation loss: 3.6766139546622347

Epoch: 6| Step: 10
Training loss: 3.5987614726406765
Validation loss: 3.668671057788277

Epoch: 6| Step: 11
Training loss: 4.243578378974058
Validation loss: 3.6674346194200265

Epoch: 6| Step: 12
Training loss: 4.898790264660134
Validation loss: 3.6686472107103323

Epoch: 6| Step: 13
Training loss: 3.6965726030614614
Validation loss: 3.6523889419175246

Epoch: 11| Step: 0
Training loss: 4.349585476121479
Validation loss: 3.651321945022257

Epoch: 6| Step: 1
Training loss: 4.049254435919829
Validation loss: 3.6466130115879336

Epoch: 6| Step: 2
Training loss: 3.4493766221479643
Validation loss: 3.6389662426416916

Epoch: 6| Step: 3
Training loss: 4.210192329562189
Validation loss: 3.6398288166569053

Epoch: 6| Step: 4
Training loss: 4.482487829716294
Validation loss: 3.6376831923081445

Epoch: 6| Step: 5
Training loss: 4.27967527066754
Validation loss: 3.6331520552587726

Epoch: 6| Step: 6
Training loss: 3.667479916174985
Validation loss: 3.6218463304017696

Epoch: 6| Step: 7
Training loss: 3.1549403428907663
Validation loss: 3.6167643724443934

Epoch: 6| Step: 8
Training loss: 3.548519207153541
Validation loss: 3.6160664078762483

Epoch: 6| Step: 9
Training loss: 3.4725290968179188
Validation loss: 3.613786411952473

Epoch: 6| Step: 10
Training loss: 3.252034357562748
Validation loss: 3.608676968798735

Epoch: 6| Step: 11
Training loss: 4.679702988027375
Validation loss: 3.603092514139385

Epoch: 6| Step: 12
Training loss: 3.2136404721956207
Validation loss: 3.6010846136884096

Epoch: 6| Step: 13
Training loss: 2.449520500126911
Validation loss: 3.6003353323907445

Epoch: 12| Step: 0
Training loss: 3.692675046497246
Validation loss: 3.604472405158245

Epoch: 6| Step: 1
Training loss: 3.966045870140079
Validation loss: 3.5940213008733317

Epoch: 6| Step: 2
Training loss: 4.2403259126894
Validation loss: 3.6083617759011215

Epoch: 6| Step: 3
Training loss: 4.1393428328823845
Validation loss: 3.617927433950478

Epoch: 6| Step: 4
Training loss: 3.3580252841363367
Validation loss: 3.59139934061054

Epoch: 6| Step: 5
Training loss: 3.718783851277126
Validation loss: 3.581237415149226

Epoch: 6| Step: 6
Training loss: 3.620944154811784
Validation loss: 3.584747233443957

Epoch: 6| Step: 7
Training loss: 4.236867248645112
Validation loss: 3.5958884220088225

Epoch: 6| Step: 8
Training loss: 3.025124249389298
Validation loss: 3.5908416207763065

Epoch: 6| Step: 9
Training loss: 3.314225808903543
Validation loss: 3.5833853803452476

Epoch: 6| Step: 10
Training loss: 4.4720502284578165
Validation loss: 3.5789787326132005

Epoch: 6| Step: 11
Training loss: 3.7228488932316255
Validation loss: 3.5750277194523177

Epoch: 6| Step: 12
Training loss: 4.1430016948117325
Validation loss: 3.571214349594827

Epoch: 6| Step: 13
Training loss: 2.3285160632325854
Validation loss: 3.569970228032501

Epoch: 13| Step: 0
Training loss: 4.316552069086706
Validation loss: 3.5679928873236704

Epoch: 6| Step: 1
Training loss: 4.207831828132828
Validation loss: 3.5664158478083556

Epoch: 6| Step: 2
Training loss: 3.581486751060579
Validation loss: 3.555684084667098

Epoch: 6| Step: 3
Training loss: 3.291360156761723
Validation loss: 3.5543022357165577

Epoch: 6| Step: 4
Training loss: 2.937628235960085
Validation loss: 3.551898792123334

Epoch: 6| Step: 5
Training loss: 3.9836425107944353
Validation loss: 3.5541834810511257

Epoch: 6| Step: 6
Training loss: 4.0980090633979085
Validation loss: 3.550944698324448

Epoch: 6| Step: 7
Training loss: 4.182202760631085
Validation loss: 3.5461552174957336

Epoch: 6| Step: 8
Training loss: 3.3511278275186145
Validation loss: 3.54601757373486

Epoch: 6| Step: 9
Training loss: 3.8584808672936926
Validation loss: 3.542073039146321

Epoch: 6| Step: 10
Training loss: 3.7339394287443572
Validation loss: 3.54226652828441

Epoch: 6| Step: 11
Training loss: 3.957674808268169
Validation loss: 3.54071869779534

Epoch: 6| Step: 12
Training loss: 3.58281337307147
Validation loss: 3.5385216566784385

Epoch: 6| Step: 13
Training loss: 2.6686802553448277
Validation loss: 3.535377203921558

Epoch: 14| Step: 0
Training loss: 4.156549658047459
Validation loss: 3.5317272633667414

Epoch: 6| Step: 1
Training loss: 3.1394450689869577
Validation loss: 3.531435934825822

Epoch: 6| Step: 2
Training loss: 4.0253693026182
Validation loss: 3.527883600799853

Epoch: 6| Step: 3
Training loss: 3.4443393985221484
Validation loss: 3.5256961405954055

Epoch: 6| Step: 4
Training loss: 3.4928618255815644
Validation loss: 3.523420555693006

Epoch: 6| Step: 5
Training loss: 3.4611976129680353
Validation loss: 3.5234234602708265

Epoch: 6| Step: 6
Training loss: 4.059559623625272
Validation loss: 3.523934769810895

Epoch: 6| Step: 7
Training loss: 2.282968683663795
Validation loss: 3.5231147729089893

Epoch: 6| Step: 8
Training loss: 3.659054194330264
Validation loss: 3.5203133582771953

Epoch: 6| Step: 9
Training loss: 3.7542740942303845
Validation loss: 3.5208894846856498

Epoch: 6| Step: 10
Training loss: 4.115743481575101
Validation loss: 3.5202444090898988

Epoch: 6| Step: 11
Training loss: 4.556764943519501
Validation loss: 3.514446347000486

Epoch: 6| Step: 12
Training loss: 3.6940860446973134
Validation loss: 3.510419267490539

Epoch: 6| Step: 13
Training loss: 3.9696286648060917
Validation loss: 3.5106394225345303

Epoch: 15| Step: 0
Training loss: 4.351231122369097
Validation loss: 3.509775709312045

Epoch: 6| Step: 1
Training loss: 3.783768752889346
Validation loss: 3.5090300611593057

Epoch: 6| Step: 2
Training loss: 4.001529639547452
Validation loss: 3.5050574823944203

Epoch: 6| Step: 3
Training loss: 3.7405640459312908
Validation loss: 3.5027596065883535

Epoch: 6| Step: 4
Training loss: 4.418295769768619
Validation loss: 3.504581303849408

Epoch: 6| Step: 5
Training loss: 4.015847522789423
Validation loss: 3.503114136008701

Epoch: 6| Step: 6
Training loss: 3.3303066499667113
Validation loss: 3.497892804585914

Epoch: 6| Step: 7
Training loss: 2.5685333309079064
Validation loss: 3.4988526501439257

Epoch: 6| Step: 8
Training loss: 3.5178009759016624
Validation loss: 3.4979695174350147

Epoch: 6| Step: 9
Training loss: 3.854140094287446
Validation loss: 3.498999953780368

Epoch: 6| Step: 10
Training loss: 3.506939547863722
Validation loss: 3.497405322432976

Epoch: 6| Step: 11
Training loss: 3.4033353041725043
Validation loss: 3.4973168797323404

Epoch: 6| Step: 12
Training loss: 3.6223821724314806
Validation loss: 3.499031929171874

Epoch: 6| Step: 13
Training loss: 3.3195614672205966
Validation loss: 3.4893293297783177

Epoch: 16| Step: 0
Training loss: 3.9611431121127993
Validation loss: 3.4924407064809357

Epoch: 6| Step: 1
Training loss: 3.912448816909185
Validation loss: 3.4930953230799613

Epoch: 6| Step: 2
Training loss: 2.9749376562943115
Validation loss: 3.4974636917043354

Epoch: 6| Step: 3
Training loss: 3.4653992836510765
Validation loss: 3.4988659326664764

Epoch: 6| Step: 4
Training loss: 3.3751701029543613
Validation loss: 3.4971929623625715

Epoch: 6| Step: 5
Training loss: 3.8690226814668054
Validation loss: 3.4838736907545

Epoch: 6| Step: 6
Training loss: 3.1812359462944735
Validation loss: 3.4835511060364803

Epoch: 6| Step: 7
Training loss: 4.437041138041087
Validation loss: 3.489254015445519

Epoch: 6| Step: 8
Training loss: 3.9588674218433875
Validation loss: 3.4939438918067407

Epoch: 6| Step: 9
Training loss: 4.000030517461711
Validation loss: 3.486133960108134

Epoch: 6| Step: 10
Training loss: 2.3826176798238587
Validation loss: 3.487338712334352

Epoch: 6| Step: 11
Training loss: 4.194759396369787
Validation loss: 3.4845082894734487

Epoch: 6| Step: 12
Training loss: 4.171683660684177
Validation loss: 3.482061665062559

Epoch: 6| Step: 13
Training loss: 3.2007245256845906
Validation loss: 3.4835871795379725

Epoch: 17| Step: 0
Training loss: 4.1269653724528395
Validation loss: 3.4835854942813183

Epoch: 6| Step: 1
Training loss: 3.1076363921673416
Validation loss: 3.4816794578308525

Epoch: 6| Step: 2
Training loss: 3.729308326346394
Validation loss: 3.480439000915055

Epoch: 6| Step: 3
Training loss: 3.7624173887188
Validation loss: 3.476484593579343

Epoch: 6| Step: 4
Training loss: 4.076441625672401
Validation loss: 3.469845745888409

Epoch: 6| Step: 5
Training loss: 3.823962755373015
Validation loss: 3.4687860190101123

Epoch: 6| Step: 6
Training loss: 3.594388689424
Validation loss: 3.468917814535773

Epoch: 6| Step: 7
Training loss: 3.336377724539112
Validation loss: 3.4669312943069186

Epoch: 6| Step: 8
Training loss: 3.2837899686067566
Validation loss: 3.464177495547513

Epoch: 6| Step: 9
Training loss: 3.0100948245298076
Validation loss: 3.460629494235408

Epoch: 6| Step: 10
Training loss: 3.5751367609501417
Validation loss: 3.461723064965412

Epoch: 6| Step: 11
Training loss: 3.679724431915578
Validation loss: 3.4569315782011967

Epoch: 6| Step: 12
Training loss: 4.054299161391951
Validation loss: 3.456890983092733

Epoch: 6| Step: 13
Training loss: 4.532953823323141
Validation loss: 3.4550541570884095

Epoch: 18| Step: 0
Training loss: 3.513913971648493
Validation loss: 3.453186030162459

Epoch: 6| Step: 1
Training loss: 3.29472736718416
Validation loss: 3.4510914134796353

Epoch: 6| Step: 2
Training loss: 3.8338250522089323
Validation loss: 3.4522523183280747

Epoch: 6| Step: 3
Training loss: 3.816264061050675
Validation loss: 3.4468271628236247

Epoch: 6| Step: 4
Training loss: 4.44871393543362
Validation loss: 3.454964146457204

Epoch: 6| Step: 5
Training loss: 3.9769608273762707
Validation loss: 3.442958125290692

Epoch: 6| Step: 6
Training loss: 3.144347153481378
Validation loss: 3.4400650790641314

Epoch: 6| Step: 7
Training loss: 3.188056897152242
Validation loss: 3.4398586753862803

Epoch: 6| Step: 8
Training loss: 3.767199934848308
Validation loss: 3.4393333639727177

Epoch: 6| Step: 9
Training loss: 3.1592821720722317
Validation loss: 3.4388052631548343

Epoch: 6| Step: 10
Training loss: 3.1686792670487045
Validation loss: 3.4415550202105236

Epoch: 6| Step: 11
Training loss: 4.144092648063316
Validation loss: 3.437252385533297

Epoch: 6| Step: 12
Training loss: 3.9376786206617598
Validation loss: 3.4321120545646098

Epoch: 6| Step: 13
Training loss: 3.4715629375586947
Validation loss: 3.4258064973181255

Epoch: 19| Step: 0
Training loss: 2.212699161337294
Validation loss: 3.427418550494858

Epoch: 6| Step: 1
Training loss: 3.7342593123261185
Validation loss: 3.437362439935406

Epoch: 6| Step: 2
Training loss: 3.6166124319296484
Validation loss: 3.4247584252447445

Epoch: 6| Step: 3
Training loss: 2.9650626321645706
Validation loss: 3.42765953520526

Epoch: 6| Step: 4
Training loss: 3.311979000937193
Validation loss: 3.42616210269264

Epoch: 6| Step: 5
Training loss: 4.368349524658035
Validation loss: 3.4209249843429315

Epoch: 6| Step: 6
Training loss: 3.845228205581943
Validation loss: 3.417416273993643

Epoch: 6| Step: 7
Training loss: 3.8011528374529693
Validation loss: 3.417509015410617

Epoch: 6| Step: 8
Training loss: 4.076270840242672
Validation loss: 3.418627264713426

Epoch: 6| Step: 9
Training loss: 3.9493230698387967
Validation loss: 3.4144713349259406

Epoch: 6| Step: 10
Training loss: 2.874303650489928
Validation loss: 3.414509222406411

Epoch: 6| Step: 11
Training loss: 4.2755026003209915
Validation loss: 3.413332810037359

Epoch: 6| Step: 12
Training loss: 3.6297921699740043
Validation loss: 3.407358841614106

Epoch: 6| Step: 13
Training loss: 3.8018742055294794
Validation loss: 3.403960128962882

Epoch: 20| Step: 0
Training loss: 3.5869102072961176
Validation loss: 3.402889594983169

Epoch: 6| Step: 1
Training loss: 4.471648443362402
Validation loss: 3.400404307209423

Epoch: 6| Step: 2
Training loss: 3.8478830338464145
Validation loss: 3.3978640417504944

Epoch: 6| Step: 3
Training loss: 3.651016271541867
Validation loss: 3.3962337052280858

Epoch: 6| Step: 4
Training loss: 3.3319342220082975
Validation loss: 3.396024006474909

Epoch: 6| Step: 5
Training loss: 2.565952208605399
Validation loss: 3.390784196975723

Epoch: 6| Step: 6
Training loss: 3.1768636325270325
Validation loss: 3.3926634184626536

Epoch: 6| Step: 7
Training loss: 3.4996544803642538
Validation loss: 3.3886608220411563

Epoch: 6| Step: 8
Training loss: 3.6029828429818105
Validation loss: 3.3914806469050074

Epoch: 6| Step: 9
Training loss: 4.049174829885531
Validation loss: 3.387002730101646

Epoch: 6| Step: 10
Training loss: 3.130577907653581
Validation loss: 3.381573413541614

Epoch: 6| Step: 11
Training loss: 4.172371252598076
Validation loss: 3.37741656972384

Epoch: 6| Step: 12
Training loss: 3.816077758020823
Validation loss: 3.3743958823154534

Epoch: 6| Step: 13
Training loss: 3.0641269643986813
Validation loss: 3.372995871567336

Epoch: 21| Step: 0
Training loss: 3.94586334915319
Validation loss: 3.370524703649971

Epoch: 6| Step: 1
Training loss: 4.028095756051719
Validation loss: 3.3708877531907206

Epoch: 6| Step: 2
Training loss: 3.335578988529683
Validation loss: 3.3650239512255746

Epoch: 6| Step: 3
Training loss: 3.6983160671835615
Validation loss: 3.3647490244434715

Epoch: 6| Step: 4
Training loss: 4.2718313152141825
Validation loss: 3.359498424890717

Epoch: 6| Step: 5
Training loss: 3.5881604055316694
Validation loss: 3.3602008358726367

Epoch: 6| Step: 6
Training loss: 2.9723354171478107
Validation loss: 3.3582427489856213

Epoch: 6| Step: 7
Training loss: 3.3247091467283805
Validation loss: 3.3617035289937234

Epoch: 6| Step: 8
Training loss: 3.4047952047593903
Validation loss: 3.3609072282348653

Epoch: 6| Step: 9
Training loss: 3.977137076306331
Validation loss: 3.354083052087063

Epoch: 6| Step: 10
Training loss: 3.395169776413095
Validation loss: 3.34992304263417

Epoch: 6| Step: 11
Training loss: 3.1914576476124363
Validation loss: 3.347549138674713

Epoch: 6| Step: 12
Training loss: 3.755904317935083
Validation loss: 3.351310295393059

Epoch: 6| Step: 13
Training loss: 2.723785910367472
Validation loss: 3.3465208101234767

Epoch: 22| Step: 0
Training loss: 2.847329035877274
Validation loss: 3.3466288598167266

Epoch: 6| Step: 1
Training loss: 3.29895228891368
Validation loss: 3.3484158666102126

Epoch: 6| Step: 2
Training loss: 4.1289164128895735
Validation loss: 3.3485456104643894

Epoch: 6| Step: 3
Training loss: 3.1358472627696523
Validation loss: 3.343369851915938

Epoch: 6| Step: 4
Training loss: 3.15865906282956
Validation loss: 3.3400515739404195

Epoch: 6| Step: 5
Training loss: 3.957448171058129
Validation loss: 3.3369327805023494

Epoch: 6| Step: 6
Training loss: 2.0015441178989777
Validation loss: 3.3361845648092197

Epoch: 6| Step: 7
Training loss: 2.887664268411927
Validation loss: 3.335769440441492

Epoch: 6| Step: 8
Training loss: 3.6914685117930466
Validation loss: 3.334933703288569

Epoch: 6| Step: 9
Training loss: 3.6856129877400243
Validation loss: 3.3339283401871973

Epoch: 6| Step: 10
Training loss: 4.3469336389882445
Validation loss: 3.331634207382951

Epoch: 6| Step: 11
Training loss: 3.6623226500396115
Validation loss: 3.3328685118518093

Epoch: 6| Step: 12
Training loss: 4.47350181349486
Validation loss: 3.3302739706318434

Epoch: 6| Step: 13
Training loss: 4.159207088024617
Validation loss: 3.3261878602770736

Epoch: 23| Step: 0
Training loss: 3.363969225195005
Validation loss: 3.3287087066840635

Epoch: 6| Step: 1
Training loss: 3.9297714679460944
Validation loss: 3.3270610899942623

Epoch: 6| Step: 2
Training loss: 2.874502885382746
Validation loss: 3.326807562737628

Epoch: 6| Step: 3
Training loss: 3.6192180956697593
Validation loss: 3.328033969821835

Epoch: 6| Step: 4
Training loss: 3.9357797407068396
Validation loss: 3.323636170775759

Epoch: 6| Step: 5
Training loss: 2.826433719297178
Validation loss: 3.3219133877977036

Epoch: 6| Step: 6
Training loss: 3.580688624296997
Validation loss: 3.322549345550236

Epoch: 6| Step: 7
Training loss: 3.0605552882582194
Validation loss: 3.3169965124162646

Epoch: 6| Step: 8
Training loss: 3.7552558941767886
Validation loss: 3.319107904592629

Epoch: 6| Step: 9
Training loss: 4.341453768635031
Validation loss: 3.316210624378467

Epoch: 6| Step: 10
Training loss: 3.675992953520985
Validation loss: 3.317531701084156

Epoch: 6| Step: 11
Training loss: 4.018290662840882
Validation loss: 3.317500089054422

Epoch: 6| Step: 12
Training loss: 3.50882385219672
Validation loss: 3.3189972048052097

Epoch: 6| Step: 13
Training loss: 2.421673870964212
Validation loss: 3.3134787257677165

Epoch: 24| Step: 0
Training loss: 3.230296046150626
Validation loss: 3.31110109992215

Epoch: 6| Step: 1
Training loss: 1.6134036112419468
Validation loss: 3.316489707029739

Epoch: 6| Step: 2
Training loss: 3.542073095600258
Validation loss: 3.3180680087324586

Epoch: 6| Step: 3
Training loss: 3.782027992100564
Validation loss: 3.322269713222094

Epoch: 6| Step: 4
Training loss: 3.681241430198137
Validation loss: 3.3165487558379865

Epoch: 6| Step: 5
Training loss: 3.5850049636785175
Validation loss: 3.310130627282108

Epoch: 6| Step: 6
Training loss: 4.095686359944228
Validation loss: 3.3096466328220626

Epoch: 6| Step: 7
Training loss: 3.774323606209092
Validation loss: 3.3096142235466113

Epoch: 6| Step: 8
Training loss: 3.983034633998289
Validation loss: 3.310467180444794

Epoch: 6| Step: 9
Training loss: 3.3345005058257304
Validation loss: 3.3138243213715435

Epoch: 6| Step: 10
Training loss: 4.454587890196396
Validation loss: 3.3171973129574868

Epoch: 6| Step: 11
Training loss: 2.9842550043877583
Validation loss: 3.3123190395638074

Epoch: 6| Step: 12
Training loss: 3.255178580593196
Validation loss: 3.311055464945817

Epoch: 6| Step: 13
Training loss: 3.7240913562980316
Validation loss: 3.3063711613797655

Epoch: 25| Step: 0
Training loss: 3.238945574198058
Validation loss: 3.3042780104807563

Epoch: 6| Step: 1
Training loss: 3.444731302177524
Validation loss: 3.303349626958177

Epoch: 6| Step: 2
Training loss: 3.4267395836559182
Validation loss: 3.299970204892208

Epoch: 6| Step: 3
Training loss: 3.405109459550244
Validation loss: 3.298717946925845

Epoch: 6| Step: 4
Training loss: 3.660125764864375
Validation loss: 3.2993872042164227

Epoch: 6| Step: 5
Training loss: 3.169773852828648
Validation loss: 3.296288759369843

Epoch: 6| Step: 6
Training loss: 3.7212336605022114
Validation loss: 3.2975883293442014

Epoch: 6| Step: 7
Training loss: 3.606587840738987
Validation loss: 3.295325085160865

Epoch: 6| Step: 8
Training loss: 3.8049034355031166
Validation loss: 3.294432343614174

Epoch: 6| Step: 9
Training loss: 3.440964496157779
Validation loss: 3.2984433499162233

Epoch: 6| Step: 10
Training loss: 3.7067554560210993
Validation loss: 3.294190321144383

Epoch: 6| Step: 11
Training loss: 3.4418128960851018
Validation loss: 3.29448266149827

Epoch: 6| Step: 12
Training loss: 3.4842244616093483
Validation loss: 3.2922964811054936

Epoch: 6| Step: 13
Training loss: 4.19005495385889
Validation loss: 3.28973970492321

Epoch: 26| Step: 0
Training loss: 2.992285505238569
Validation loss: 3.2974263091705636

Epoch: 6| Step: 1
Training loss: 3.1247109851704247
Validation loss: 3.2960333520400735

Epoch: 6| Step: 2
Training loss: 3.68227831430276
Validation loss: 3.313612296302698

Epoch: 6| Step: 3
Training loss: 3.186072235476285
Validation loss: 3.2847683234056246

Epoch: 6| Step: 4
Training loss: 2.769778909088361
Validation loss: 3.285537496854017

Epoch: 6| Step: 5
Training loss: 4.664445053079545
Validation loss: 3.2876914478411945

Epoch: 6| Step: 6
Training loss: 3.1315012634947226
Validation loss: 3.286837956049945

Epoch: 6| Step: 7
Training loss: 3.03568344741673
Validation loss: 3.287633103430015

Epoch: 6| Step: 8
Training loss: 4.183736903771611
Validation loss: 3.2888266177016057

Epoch: 6| Step: 9
Training loss: 3.9569037549642023
Validation loss: 3.289831012330994

Epoch: 6| Step: 10
Training loss: 3.6139720359526786
Validation loss: 3.2852296633609823

Epoch: 6| Step: 11
Training loss: 2.9664930900057325
Validation loss: 3.2859654730870527

Epoch: 6| Step: 12
Training loss: 4.004542870501522
Validation loss: 3.2837564937668606

Epoch: 6| Step: 13
Training loss: 3.5895856529991432
Validation loss: 3.278983562882212

Epoch: 27| Step: 0
Training loss: 3.285231871760791
Validation loss: 3.276587761480019

Epoch: 6| Step: 1
Training loss: 4.266399383120275
Validation loss: 3.2754327009914976

Epoch: 6| Step: 2
Training loss: 2.8251244239075706
Validation loss: 3.275110754792234

Epoch: 6| Step: 3
Training loss: 3.8673904519819375
Validation loss: 3.275538518648849

Epoch: 6| Step: 4
Training loss: 3.4599828501370045
Validation loss: 3.275499245982615

Epoch: 6| Step: 5
Training loss: 1.8879065397899248
Validation loss: 3.2743808167275144

Epoch: 6| Step: 6
Training loss: 2.9480603905319076
Validation loss: 3.2714115810239033

Epoch: 6| Step: 7
Training loss: 4.206047318493951
Validation loss: 3.2704116902746296

Epoch: 6| Step: 8
Training loss: 3.80345080444727
Validation loss: 3.269627653718208

Epoch: 6| Step: 9
Training loss: 3.5585106715398354
Validation loss: 3.265106386082361

Epoch: 6| Step: 10
Training loss: 3.9762920894751623
Validation loss: 3.267751152413407

Epoch: 6| Step: 11
Training loss: 3.9414891214420216
Validation loss: 3.265062755854801

Epoch: 6| Step: 12
Training loss: 3.463877374350682
Validation loss: 3.26493495537987

Epoch: 6| Step: 13
Training loss: 2.502170383570625
Validation loss: 3.2666910508580718

Epoch: 28| Step: 0
Training loss: 3.2366024584806774
Validation loss: 3.2647096450388755

Epoch: 6| Step: 1
Training loss: 3.166756093285037
Validation loss: 3.2664234229236953

Epoch: 6| Step: 2
Training loss: 3.8579819362013805
Validation loss: 3.267044227655315

Epoch: 6| Step: 3
Training loss: 4.392721198411929
Validation loss: 3.2661411768278437

Epoch: 6| Step: 4
Training loss: 3.254692504703155
Validation loss: 3.26145530925325

Epoch: 6| Step: 5
Training loss: 3.5308292104447756
Validation loss: 3.258036106907249

Epoch: 6| Step: 6
Training loss: 3.68752275880159
Validation loss: 3.2568032168007375

Epoch: 6| Step: 7
Training loss: 3.0706490290979045
Validation loss: 3.267416598640909

Epoch: 6| Step: 8
Training loss: 3.7936025575144114
Validation loss: 3.3263278615077754

Epoch: 6| Step: 9
Training loss: 3.292788897724175
Validation loss: 3.319701211963341

Epoch: 6| Step: 10
Training loss: 3.3818363604984576
Validation loss: 3.262162343362314

Epoch: 6| Step: 11
Training loss: 2.470161517341109
Validation loss: 3.2615832586493183

Epoch: 6| Step: 12
Training loss: 3.83713912012547
Validation loss: 3.2693840804590963

Epoch: 6| Step: 13
Training loss: 4.044511848861498
Validation loss: 3.280699349807058

Epoch: 29| Step: 0
Training loss: 3.914906667714946
Validation loss: 3.283049201591573

Epoch: 6| Step: 1
Training loss: 3.1193413428002446
Validation loss: 3.257136998475987

Epoch: 6| Step: 2
Training loss: 3.633799429112128
Validation loss: 3.3048889405961677

Epoch: 6| Step: 3
Training loss: 3.785619937615602
Validation loss: 3.359631561456381

Epoch: 6| Step: 4
Training loss: 3.30456109853564
Validation loss: 3.302341695760367

Epoch: 6| Step: 5
Training loss: 2.2124587577812185
Validation loss: 3.2863749228657313

Epoch: 6| Step: 6
Training loss: 3.808339835285894
Validation loss: 3.3203215645383466

Epoch: 6| Step: 7
Training loss: 3.5486985950838372
Validation loss: 3.2989007989217187

Epoch: 6| Step: 8
Training loss: 4.133443340765464
Validation loss: 3.2854197348199423

Epoch: 6| Step: 9
Training loss: 3.946679088233611
Validation loss: 3.2749106709273406

Epoch: 6| Step: 10
Training loss: 2.318644839470151
Validation loss: 3.267142291368852

Epoch: 6| Step: 11
Training loss: 3.9195794306153346
Validation loss: 3.2656426601734108

Epoch: 6| Step: 12
Training loss: 3.8135605884628925
Validation loss: 3.264407802888954

Epoch: 6| Step: 13
Training loss: 3.2568434044610806
Validation loss: 3.2685355355608645

Epoch: 30| Step: 0
Training loss: 2.848618918964662
Validation loss: 3.2790326839602284

Epoch: 6| Step: 1
Training loss: 2.990004417900981
Validation loss: 3.2640223655965905

Epoch: 6| Step: 2
Training loss: 3.3959727502455253
Validation loss: 3.257326121415811

Epoch: 6| Step: 3
Training loss: 3.73579181943915
Validation loss: 3.2529169990318514

Epoch: 6| Step: 4
Training loss: 3.6928647344025802
Validation loss: 3.2577643117574264

Epoch: 6| Step: 5
Training loss: 3.5405278487988365
Validation loss: 3.264568264842552

Epoch: 6| Step: 6
Training loss: 3.5393545943892395
Validation loss: 3.251007603839811

Epoch: 6| Step: 7
Training loss: 3.186454900810602
Validation loss: 3.2499785363409117

Epoch: 6| Step: 8
Training loss: 3.6892419353763257
Validation loss: 3.2461133091802297

Epoch: 6| Step: 9
Training loss: 3.6669780136626873
Validation loss: 3.2431069817862817

Epoch: 6| Step: 10
Training loss: 4.741252876198397
Validation loss: 3.243937489745948

Epoch: 6| Step: 11
Training loss: 3.1172958011026584
Validation loss: 3.2418900801254007

Epoch: 6| Step: 12
Training loss: 3.5258907734727067
Validation loss: 3.2418282780445953

Epoch: 6| Step: 13
Training loss: 2.461698868458473
Validation loss: 3.2409247965843457

Epoch: 31| Step: 0
Training loss: 4.0146582957568695
Validation loss: 3.2408720761660943

Epoch: 6| Step: 1
Training loss: 3.7202537765899044
Validation loss: 3.2412587944578277

Epoch: 6| Step: 2
Training loss: 3.063069504704295
Validation loss: 3.2385685838994998

Epoch: 6| Step: 3
Training loss: 3.4223568372411335
Validation loss: 3.2360570971360763

Epoch: 6| Step: 4
Training loss: 2.927535179441517
Validation loss: 3.2338826817044195

Epoch: 6| Step: 5
Training loss: 3.3664772364386297
Validation loss: 3.2326265047314173

Epoch: 6| Step: 6
Training loss: 3.3746575075786627
Validation loss: 3.2342539166147795

Epoch: 6| Step: 7
Training loss: 2.7521064666846167
Validation loss: 3.2330050887185378

Epoch: 6| Step: 8
Training loss: 2.4694303709796515
Validation loss: 3.2253076266876843

Epoch: 6| Step: 9
Training loss: 3.549109742197077
Validation loss: 3.228089597077242

Epoch: 6| Step: 10
Training loss: 2.9118282149126897
Validation loss: 3.2262855249413747

Epoch: 6| Step: 11
Training loss: 4.5647656811579
Validation loss: 3.2236478063814205

Epoch: 6| Step: 12
Training loss: 4.0538192730871145
Validation loss: 3.225335370860294

Epoch: 6| Step: 13
Training loss: 4.303648558481163
Validation loss: 3.2232006288642947

Epoch: 32| Step: 0
Training loss: 2.6813563719236604
Validation loss: 3.223786843594973

Epoch: 6| Step: 1
Training loss: 3.429226577130383
Validation loss: 3.22265071009523

Epoch: 6| Step: 2
Training loss: 4.046181637784847
Validation loss: 3.2195292476478587

Epoch: 6| Step: 3
Training loss: 2.7257498593106866
Validation loss: 3.218599914307614

Epoch: 6| Step: 4
Training loss: 3.8269115782551344
Validation loss: 3.2203236950292657

Epoch: 6| Step: 5
Training loss: 3.2115139409011664
Validation loss: 3.2208896195595655

Epoch: 6| Step: 6
Training loss: 3.1958683341910166
Validation loss: 3.2207552410884475

Epoch: 6| Step: 7
Training loss: 3.9568044554176653
Validation loss: 3.216196632590205

Epoch: 6| Step: 8
Training loss: 2.709478507875169
Validation loss: 3.2139642350900104

Epoch: 6| Step: 9
Training loss: 3.309055192604106
Validation loss: 3.214632493588118

Epoch: 6| Step: 10
Training loss: 4.017353086794166
Validation loss: 3.2111543532717257

Epoch: 6| Step: 11
Training loss: 4.035547139676693
Validation loss: 3.2124363446631414

Epoch: 6| Step: 12
Training loss: 3.2202983206224407
Validation loss: 3.2124806162167694

Epoch: 6| Step: 13
Training loss: 3.935705351182698
Validation loss: 3.2085491547843388

Epoch: 33| Step: 0
Training loss: 3.3915673981057126
Validation loss: 3.210783686061476

Epoch: 6| Step: 1
Training loss: 3.1674178052442836
Validation loss: 3.2118521094539703

Epoch: 6| Step: 2
Training loss: 3.671094705987852
Validation loss: 3.2098292515156244

Epoch: 6| Step: 3
Training loss: 3.730401387030867
Validation loss: 3.208624396820523

Epoch: 6| Step: 4
Training loss: 3.5557115358338636
Validation loss: 3.2066123296797215

Epoch: 6| Step: 5
Training loss: 3.7302706201475697
Validation loss: 3.2078987522965843

Epoch: 6| Step: 6
Training loss: 2.5602639840035333
Validation loss: 3.2096857638525513

Epoch: 6| Step: 7
Training loss: 4.050935924376406
Validation loss: 3.2085508462733987

Epoch: 6| Step: 8
Training loss: 2.127562268395945
Validation loss: 3.2077294063463677

Epoch: 6| Step: 9
Training loss: 3.7846502983577457
Validation loss: 3.203776535652725

Epoch: 6| Step: 10
Training loss: 3.5913513139560584
Validation loss: 3.2055753582003725

Epoch: 6| Step: 11
Training loss: 3.4425425217827343
Validation loss: 3.204799897905975

Epoch: 6| Step: 12
Training loss: 3.63549508754381
Validation loss: 3.2044665608808565

Epoch: 6| Step: 13
Training loss: 3.5640029413915415
Validation loss: 3.2050007623967187

Epoch: 34| Step: 0
Training loss: 2.461371295782228
Validation loss: 3.203475131855619

Epoch: 6| Step: 1
Training loss: 3.266200402777814
Validation loss: 3.2055364120156415

Epoch: 6| Step: 2
Training loss: 3.6963960055120486
Validation loss: 3.2152439420025023

Epoch: 6| Step: 3
Training loss: 3.688332415231716
Validation loss: 3.199281492182349

Epoch: 6| Step: 4
Training loss: 4.206572866305898
Validation loss: 3.1983511184944895

Epoch: 6| Step: 5
Training loss: 2.51967337747141
Validation loss: 3.1977243887070155

Epoch: 6| Step: 6
Training loss: 4.080729737938031
Validation loss: 3.2073024573977857

Epoch: 6| Step: 7
Training loss: 2.731453866573574
Validation loss: 3.202501276988491

Epoch: 6| Step: 8
Training loss: 3.3655132193673416
Validation loss: 3.200974540852495

Epoch: 6| Step: 9
Training loss: 4.3655074544058055
Validation loss: 3.1958062437607078

Epoch: 6| Step: 10
Training loss: 4.006577091284195
Validation loss: 3.2006535024950744

Epoch: 6| Step: 11
Training loss: 2.891420821880077
Validation loss: 3.195100601318415

Epoch: 6| Step: 12
Training loss: 3.1479294890052767
Validation loss: 3.1948017821710892

Epoch: 6| Step: 13
Training loss: 2.9908557448066055
Validation loss: 3.199534837948963

Epoch: 35| Step: 0
Training loss: 3.061969633304406
Validation loss: 3.1987409577837385

Epoch: 6| Step: 1
Training loss: 2.7043343192757434
Validation loss: 3.1982478658736424

Epoch: 6| Step: 2
Training loss: 3.911991995594596
Validation loss: 3.2049089483735256

Epoch: 6| Step: 3
Training loss: 3.6088243204781
Validation loss: 3.209641484899196

Epoch: 6| Step: 4
Training loss: 3.3128011314701524
Validation loss: 3.205030481285925

Epoch: 6| Step: 5
Training loss: 4.087930751116968
Validation loss: 3.2073734212772416

Epoch: 6| Step: 6
Training loss: 3.5028308591787782
Validation loss: 3.1934393926507822

Epoch: 6| Step: 7
Training loss: 3.409389344070708
Validation loss: 3.192925842827545

Epoch: 6| Step: 8
Training loss: 3.2920853231874907
Validation loss: 3.197185053617542

Epoch: 6| Step: 9
Training loss: 3.3947291695124044
Validation loss: 3.207269899588924

Epoch: 6| Step: 10
Training loss: 2.8902947314492953
Validation loss: 3.2129677960334893

Epoch: 6| Step: 11
Training loss: 3.595368791957663
Validation loss: 3.2133206434266945

Epoch: 6| Step: 12
Training loss: 3.410763051862041
Validation loss: 3.1998881202541454

Epoch: 6| Step: 13
Training loss: 4.322287689166458
Validation loss: 3.1951978682817024

Epoch: 36| Step: 0
Training loss: 3.1317529575166145
Validation loss: 3.1915865749900982

Epoch: 6| Step: 1
Training loss: 3.139047102940244
Validation loss: 3.1914397922091235

Epoch: 6| Step: 2
Training loss: 4.210754050821975
Validation loss: 3.185772246795325

Epoch: 6| Step: 3
Training loss: 3.4658285674563567
Validation loss: 3.185765689965842

Epoch: 6| Step: 4
Training loss: 3.899258513755184
Validation loss: 3.186098588931146

Epoch: 6| Step: 5
Training loss: 3.4481924048551695
Validation loss: 3.181872893127942

Epoch: 6| Step: 6
Training loss: 3.2420207153072673
Validation loss: 3.1855137600475887

Epoch: 6| Step: 7
Training loss: 3.386568939521076
Validation loss: 3.185452248439838

Epoch: 6| Step: 8
Training loss: 3.7828277574977567
Validation loss: 3.1832182805172615

Epoch: 6| Step: 9
Training loss: 3.4273167369326676
Validation loss: 3.1813674024128793

Epoch: 6| Step: 10
Training loss: 3.605903045518784
Validation loss: 3.1810323062320074

Epoch: 6| Step: 11
Training loss: 3.2488586182176338
Validation loss: 3.180812064691065

Epoch: 6| Step: 12
Training loss: 2.802003388995695
Validation loss: 3.180517907325896

Epoch: 6| Step: 13
Training loss: 2.8685823212863495
Validation loss: 3.1788252411475324

Epoch: 37| Step: 0
Training loss: 3.4229384907827556
Validation loss: 3.1801321768821906

Epoch: 6| Step: 1
Training loss: 3.476230836971155
Validation loss: 3.1785438111203868

Epoch: 6| Step: 2
Training loss: 3.805801635792835
Validation loss: 3.1807393492029434

Epoch: 6| Step: 3
Training loss: 3.3473182249393663
Validation loss: 3.1810683658740997

Epoch: 6| Step: 4
Training loss: 3.9491763692783466
Validation loss: 3.1805279119410086

Epoch: 6| Step: 5
Training loss: 2.932151632991128
Validation loss: 3.180353290938755

Epoch: 6| Step: 6
Training loss: 3.077463146642915
Validation loss: 3.178329820907872

Epoch: 6| Step: 7
Training loss: 3.382720029769636
Validation loss: 3.1798962746284567

Epoch: 6| Step: 8
Training loss: 3.03728003313735
Validation loss: 3.1784283778261813

Epoch: 6| Step: 9
Training loss: 3.839855919757546
Validation loss: 3.1779785175408866

Epoch: 6| Step: 10
Training loss: 3.569294924311224
Validation loss: 3.1785960070991166

Epoch: 6| Step: 11
Training loss: 2.9332211761996163
Validation loss: 3.1767156900967017

Epoch: 6| Step: 12
Training loss: 3.615571091364603
Validation loss: 3.1774228876636754

Epoch: 6| Step: 13
Training loss: 3.5062140750234545
Validation loss: 3.175097554240425

Epoch: 38| Step: 0
Training loss: 2.8997592431463843
Validation loss: 3.1758728567095944

Epoch: 6| Step: 1
Training loss: 3.629815684701804
Validation loss: 3.175194989089361

Epoch: 6| Step: 2
Training loss: 3.767099938468733
Validation loss: 3.1761101216404626

Epoch: 6| Step: 3
Training loss: 3.095171515129468
Validation loss: 3.173810073485679

Epoch: 6| Step: 4
Training loss: 3.7399002125121386
Validation loss: 3.172668511340325

Epoch: 6| Step: 5
Training loss: 3.1647879063320232
Validation loss: 3.1720168545059777

Epoch: 6| Step: 6
Training loss: 2.9807160801088934
Validation loss: 3.177153822616011

Epoch: 6| Step: 7
Training loss: 3.509275815110718
Validation loss: 3.1819177865141017

Epoch: 6| Step: 8
Training loss: 3.2026125614297976
Validation loss: 3.1800866117528086

Epoch: 6| Step: 9
Training loss: 3.4345728115216954
Validation loss: 3.1761539164237926

Epoch: 6| Step: 10
Training loss: 3.1918148680326737
Validation loss: 3.174423239219989

Epoch: 6| Step: 11
Training loss: 4.303618864420988
Validation loss: 3.170308618074094

Epoch: 6| Step: 12
Training loss: 3.1415595187290015
Validation loss: 3.169970468541618

Epoch: 6| Step: 13
Training loss: 3.7668108200800927
Validation loss: 3.167948268120487

Epoch: 39| Step: 0
Training loss: 3.694755657412403
Validation loss: 3.1674783494329857

Epoch: 6| Step: 1
Training loss: 3.4378575919295575
Validation loss: 3.16837844069866

Epoch: 6| Step: 2
Training loss: 3.545158878527029
Validation loss: 3.169749987342918

Epoch: 6| Step: 3
Training loss: 4.0979206301746425
Validation loss: 3.16928877103186

Epoch: 6| Step: 4
Training loss: 2.450778300387231
Validation loss: 3.1652974864162777

Epoch: 6| Step: 5
Training loss: 3.2712622359283485
Validation loss: 3.165258842423779

Epoch: 6| Step: 6
Training loss: 3.9957313410551185
Validation loss: 3.1641070132996445

Epoch: 6| Step: 7
Training loss: 3.6070779203750543
Validation loss: 3.163865712420684

Epoch: 6| Step: 8
Training loss: 3.1960922819333284
Validation loss: 3.1617946634727465

Epoch: 6| Step: 9
Training loss: 2.657937624507295
Validation loss: 3.163740853576265

Epoch: 6| Step: 10
Training loss: 2.995675466849763
Validation loss: 3.1655982305912134

Epoch: 6| Step: 11
Training loss: 3.8073189974046104
Validation loss: 3.1620856575963576

Epoch: 6| Step: 12
Training loss: 2.9911970685586904
Validation loss: 3.1619774295841716

Epoch: 6| Step: 13
Training loss: 3.9870712432428204
Validation loss: 3.163170092507475

Epoch: 40| Step: 0
Training loss: 3.6013638985711567
Validation loss: 3.158665046109328

Epoch: 6| Step: 1
Training loss: 2.9012498398517397
Validation loss: 3.1558523578423956

Epoch: 6| Step: 2
Training loss: 4.030420972167874
Validation loss: 3.1586428774003887

Epoch: 6| Step: 3
Training loss: 3.7273406489880467
Validation loss: 3.158488028111267

Epoch: 6| Step: 4
Training loss: 2.976416396512707
Validation loss: 3.1584845476810726

Epoch: 6| Step: 5
Training loss: 3.450762186306508
Validation loss: 3.1565796086967235

Epoch: 6| Step: 6
Training loss: 3.0835164677300972
Validation loss: 3.158426235294888

Epoch: 6| Step: 7
Training loss: 3.5268485396516627
Validation loss: 3.1589173545645246

Epoch: 6| Step: 8
Training loss: 3.996759771217585
Validation loss: 3.15737058699138

Epoch: 6| Step: 9
Training loss: 3.661784621017158
Validation loss: 3.1554000491447436

Epoch: 6| Step: 10
Training loss: 4.067375192257267
Validation loss: 3.1532070843448397

Epoch: 6| Step: 11
Training loss: 2.1414546055085113
Validation loss: 3.1533553963866914

Epoch: 6| Step: 12
Training loss: 3.0540227532579047
Validation loss: 3.1535370322245715

Epoch: 6| Step: 13
Training loss: 2.7344194681093983
Validation loss: 3.1540329134712706

Epoch: 41| Step: 0
Training loss: 2.9064431075062194
Validation loss: 3.152193527931204

Epoch: 6| Step: 1
Training loss: 2.9364750474064185
Validation loss: 3.1526162303379732

Epoch: 6| Step: 2
Training loss: 4.472486521069945
Validation loss: 3.15531708437408

Epoch: 6| Step: 3
Training loss: 3.1744680845188706
Validation loss: 3.154690648379717

Epoch: 6| Step: 4
Training loss: 4.540736298532706
Validation loss: 3.159775264534728

Epoch: 6| Step: 5
Training loss: 3.5528119515478895
Validation loss: 3.1565974241391506

Epoch: 6| Step: 6
Training loss: 3.7373059633849404
Validation loss: 3.1576785040224973

Epoch: 6| Step: 7
Training loss: 3.227271789472495
Validation loss: 3.154595830895753

Epoch: 6| Step: 8
Training loss: 2.7852831112083596
Validation loss: 3.1490508257491467

Epoch: 6| Step: 9
Training loss: 3.2002817327933
Validation loss: 3.1489027799071243

Epoch: 6| Step: 10
Training loss: 2.921875489586774
Validation loss: 3.1502064867863844

Epoch: 6| Step: 11
Training loss: 2.948708435774718
Validation loss: 3.147105008776193

Epoch: 6| Step: 12
Training loss: 3.1863287475480573
Validation loss: 3.147729299192413

Epoch: 6| Step: 13
Training loss: 3.6763265693729843
Validation loss: 3.1467808485831945

Epoch: 42| Step: 0
Training loss: 3.782947127898187
Validation loss: 3.1474799448644815

Epoch: 6| Step: 1
Training loss: 2.9598547734899707
Validation loss: 3.1481763158912455

Epoch: 6| Step: 2
Training loss: 3.238447638310538
Validation loss: 3.1511117833647724

Epoch: 6| Step: 3
Training loss: 2.7691914466975978
Validation loss: 3.149742416863963

Epoch: 6| Step: 4
Training loss: 3.6369567203206916
Validation loss: 3.14997178114052

Epoch: 6| Step: 5
Training loss: 3.410055152469429
Validation loss: 3.1494650041855135

Epoch: 6| Step: 6
Training loss: 3.8407833156748517
Validation loss: 3.1517018115417104

Epoch: 6| Step: 7
Training loss: 2.9818147392316514
Validation loss: 3.1507494567311918

Epoch: 6| Step: 8
Training loss: 3.606348130925613
Validation loss: 3.1684246968958836

Epoch: 6| Step: 9
Training loss: 2.746689885035157
Validation loss: 3.1536934252542363

Epoch: 6| Step: 10
Training loss: 3.7716990508069963
Validation loss: 3.152379926364226

Epoch: 6| Step: 11
Training loss: 2.989476821189405
Validation loss: 3.1415665799218124

Epoch: 6| Step: 12
Training loss: 3.682837690834508
Validation loss: 3.141787652594665

Epoch: 6| Step: 13
Training loss: 4.290371498793111
Validation loss: 3.1449811292215495

Epoch: 43| Step: 0
Training loss: 2.600214520187685
Validation loss: 3.1487655751671797

Epoch: 6| Step: 1
Training loss: 3.5437753720190988
Validation loss: 3.1504815711926617

Epoch: 6| Step: 2
Training loss: 3.5405827976819313
Validation loss: 3.143109171687368

Epoch: 6| Step: 3
Training loss: 3.3852228823243964
Validation loss: 3.1463373866010125

Epoch: 6| Step: 4
Training loss: 3.420565977502161
Validation loss: 3.143088679520608

Epoch: 6| Step: 5
Training loss: 3.3118294091082316
Validation loss: 3.139046518187354

Epoch: 6| Step: 6
Training loss: 3.2137395879219977
Validation loss: 3.13876068838838

Epoch: 6| Step: 7
Training loss: 2.9249385338218206
Validation loss: 3.13883225363901

Epoch: 6| Step: 8
Training loss: 2.734412841535027
Validation loss: 3.1392851046556616

Epoch: 6| Step: 9
Training loss: 3.9105069577675025
Validation loss: 3.1418542474039026

Epoch: 6| Step: 10
Training loss: 3.80744912186792
Validation loss: 3.1385890038698636

Epoch: 6| Step: 11
Training loss: 3.418172426967153
Validation loss: 3.1389364128303585

Epoch: 6| Step: 12
Training loss: 3.82211716665255
Validation loss: 3.143566184719924

Epoch: 6| Step: 13
Training loss: 3.9953068380722248
Validation loss: 3.1452110232956074

Epoch: 44| Step: 0
Training loss: 3.715644244760993
Validation loss: 3.1369053062832752

Epoch: 6| Step: 1
Training loss: 3.61001198172232
Validation loss: 3.1402090384180616

Epoch: 6| Step: 2
Training loss: 3.1681791675457527
Validation loss: 3.1485102140343

Epoch: 6| Step: 3
Training loss: 2.8122700915144963
Validation loss: 3.1850681313498064

Epoch: 6| Step: 4
Training loss: 3.0836530124487225
Validation loss: 3.191466886949179

Epoch: 6| Step: 5
Training loss: 3.8795707571384175
Validation loss: 3.186512478229348

Epoch: 6| Step: 6
Training loss: 3.5911825545630167
Validation loss: 3.176653568297331

Epoch: 6| Step: 7
Training loss: 2.510932383980135
Validation loss: 3.155243073641821

Epoch: 6| Step: 8
Training loss: 3.26301068514712
Validation loss: 3.155197840530614

Epoch: 6| Step: 9
Training loss: 3.0118811893815125
Validation loss: 3.2034448543494185

Epoch: 6| Step: 10
Training loss: 3.476262934776255
Validation loss: 3.2364216632799288

Epoch: 6| Step: 11
Training loss: 4.112334487506311
Validation loss: 3.219709698319205

Epoch: 6| Step: 12
Training loss: 4.001847794032347
Validation loss: 3.1534906739036472

Epoch: 6| Step: 13
Training loss: 3.6144549139041695
Validation loss: 3.159513480063003

Epoch: 45| Step: 0
Training loss: 2.368879160718921
Validation loss: 3.1464119726524746

Epoch: 6| Step: 1
Training loss: 3.8071452824552403
Validation loss: 3.1473477152171454

Epoch: 6| Step: 2
Training loss: 3.9513061922996013
Validation loss: 3.14447775807809

Epoch: 6| Step: 3
Training loss: 3.7330003067617343
Validation loss: 3.1440441408817943

Epoch: 6| Step: 4
Training loss: 2.9537888845369538
Validation loss: 3.1391709782608666

Epoch: 6| Step: 5
Training loss: 3.5602084368860636
Validation loss: 3.1334027324113376

Epoch: 6| Step: 6
Training loss: 3.3295451255085657
Validation loss: 3.136767731231532

Epoch: 6| Step: 7
Training loss: 3.8944714999804733
Validation loss: 3.1420875522854943

Epoch: 6| Step: 8
Training loss: 3.3133543820035594
Validation loss: 3.1448858037912633

Epoch: 6| Step: 9
Training loss: 3.851959641353123
Validation loss: 3.148177099272396

Epoch: 6| Step: 10
Training loss: 2.8104221721922324
Validation loss: 3.1412985160168616

Epoch: 6| Step: 11
Training loss: 2.856458500236651
Validation loss: 3.1417517867386193

Epoch: 6| Step: 12
Training loss: 3.444221721818003
Validation loss: 3.1499175498291017

Epoch: 6| Step: 13
Training loss: 3.194615220374748
Validation loss: 3.1426346741016875

Epoch: 46| Step: 0
Training loss: 3.5348692045065473
Validation loss: 3.1366492615561308

Epoch: 6| Step: 1
Training loss: 3.4276019383247265
Validation loss: 3.1359841694370547

Epoch: 6| Step: 2
Training loss: 3.036015804928136
Validation loss: 3.1280739921894103

Epoch: 6| Step: 3
Training loss: 2.8712790915942272
Validation loss: 3.130247950842786

Epoch: 6| Step: 4
Training loss: 3.6594757457126934
Validation loss: 3.1325837125090135

Epoch: 6| Step: 5
Training loss: 3.7721040948478826
Validation loss: 3.1216201421495695

Epoch: 6| Step: 6
Training loss: 3.130187954362912
Validation loss: 3.1248420363669314

Epoch: 6| Step: 7
Training loss: 3.5787822003236682
Validation loss: 3.127823198775377

Epoch: 6| Step: 8
Training loss: 2.556139985121151
Validation loss: 3.128888250668934

Epoch: 6| Step: 9
Training loss: 3.838244705756089
Validation loss: 3.1353102354470446

Epoch: 6| Step: 10
Training loss: 3.394162631021135
Validation loss: 3.1405915256643357

Epoch: 6| Step: 11
Training loss: 3.4290668038852514
Validation loss: 3.1391356835780955

Epoch: 6| Step: 12
Training loss: 3.7347752823438967
Validation loss: 3.1366569222705842

Epoch: 6| Step: 13
Training loss: 3.293870325080334
Validation loss: 3.1287772994833993

Epoch: 47| Step: 0
Training loss: 2.671097134690931
Validation loss: 3.1264403504224267

Epoch: 6| Step: 1
Training loss: 3.829636131511749
Validation loss: 3.1324397072352896

Epoch: 6| Step: 2
Training loss: 3.0465453923279475
Validation loss: 3.128593365783832

Epoch: 6| Step: 3
Training loss: 3.5500562743978583
Validation loss: 3.129275791857654

Epoch: 6| Step: 4
Training loss: 3.55714603124095
Validation loss: 3.12588343448726

Epoch: 6| Step: 5
Training loss: 2.9620370559486573
Validation loss: 3.1237268032297036

Epoch: 6| Step: 6
Training loss: 3.314854055330655
Validation loss: 3.1241550230191337

Epoch: 6| Step: 7
Training loss: 3.9520701331583608
Validation loss: 3.1217954452274945

Epoch: 6| Step: 8
Training loss: 3.1016432129473506
Validation loss: 3.123403504808529

Epoch: 6| Step: 9
Training loss: 3.4566930228258244
Validation loss: 3.1217550120120685

Epoch: 6| Step: 10
Training loss: 3.918236248891078
Validation loss: 3.119902198141826

Epoch: 6| Step: 11
Training loss: 3.5919989258864398
Validation loss: 3.1223484250446147

Epoch: 6| Step: 12
Training loss: 2.9593640175185603
Validation loss: 3.1202034610776472

Epoch: 6| Step: 13
Training loss: 3.0306743586496174
Validation loss: 3.119135864516368

Epoch: 48| Step: 0
Training loss: 3.617682602286811
Validation loss: 3.1161688933942577

Epoch: 6| Step: 1
Training loss: 3.0762952604223273
Validation loss: 3.1152592111300144

Epoch: 6| Step: 2
Training loss: 3.5083882766251153
Validation loss: 3.1191737928434002

Epoch: 6| Step: 3
Training loss: 4.025728451223242
Validation loss: 3.116486886299818

Epoch: 6| Step: 4
Training loss: 3.5366248352376486
Validation loss: 3.1162628777150614

Epoch: 6| Step: 5
Training loss: 3.4289091091530857
Validation loss: 3.118598146116221

Epoch: 6| Step: 6
Training loss: 3.1342115821720284
Validation loss: 3.1171761966245124

Epoch: 6| Step: 7
Training loss: 2.7006167201961624
Validation loss: 3.1126058316777803

Epoch: 6| Step: 8
Training loss: 3.860795350431701
Validation loss: 3.111435901688381

Epoch: 6| Step: 9
Training loss: 3.5761462741437557
Validation loss: 3.1100072268981815

Epoch: 6| Step: 10
Training loss: 2.815223477235177
Validation loss: 3.109278128637126

Epoch: 6| Step: 11
Training loss: 3.068047772956933
Validation loss: 3.1085656223091984

Epoch: 6| Step: 12
Training loss: 3.314987112627252
Validation loss: 3.107876106417686

Epoch: 6| Step: 13
Training loss: 3.3423949731433806
Validation loss: 3.1093554991619046

Epoch: 49| Step: 0
Training loss: 2.258557259506656
Validation loss: 3.105946726592117

Epoch: 6| Step: 1
Training loss: 2.59995144285196
Validation loss: 3.1068073945790493

Epoch: 6| Step: 2
Training loss: 3.6991594545472104
Validation loss: 3.1073320866867817

Epoch: 6| Step: 3
Training loss: 3.0045846240066836
Validation loss: 3.1051638151601435

Epoch: 6| Step: 4
Training loss: 4.207325931241745
Validation loss: 3.106881950989291

Epoch: 6| Step: 5
Training loss: 3.2644648339131286
Validation loss: 3.1039485988315896

Epoch: 6| Step: 6
Training loss: 4.263258504640855
Validation loss: 3.104233930912942

Epoch: 6| Step: 7
Training loss: 3.358746988900655
Validation loss: 3.10640695477058

Epoch: 6| Step: 8
Training loss: 3.267462400586364
Validation loss: 3.1051757872438737

Epoch: 6| Step: 9
Training loss: 3.888567154306301
Validation loss: 3.105239328258186

Epoch: 6| Step: 10
Training loss: 3.346196500673289
Validation loss: 3.104286986554109

Epoch: 6| Step: 11
Training loss: 3.106495199369549
Validation loss: 3.1045107015268334

Epoch: 6| Step: 12
Training loss: 2.935508864836253
Validation loss: 3.106070556858426

Epoch: 6| Step: 13
Training loss: 3.3058194145087194
Validation loss: 3.101674371798516

Epoch: 50| Step: 0
Training loss: 2.101019920447144
Validation loss: 3.103463221974746

Epoch: 6| Step: 1
Training loss: 2.6793736755068838
Validation loss: 3.09944675009455

Epoch: 6| Step: 2
Training loss: 3.5279986511798795
Validation loss: 3.099485812644454

Epoch: 6| Step: 3
Training loss: 3.0401639143772723
Validation loss: 3.1007855782005715

Epoch: 6| Step: 4
Training loss: 3.5353611333498427
Validation loss: 3.0985152990478544

Epoch: 6| Step: 5
Training loss: 3.5599489949890897
Validation loss: 3.095717385343541

Epoch: 6| Step: 6
Training loss: 2.9688508669131064
Validation loss: 3.1000003614236897

Epoch: 6| Step: 7
Training loss: 3.663087109062396
Validation loss: 3.098953298080516

Epoch: 6| Step: 8
Training loss: 3.5359715317231752
Validation loss: 3.0969909401232707

Epoch: 6| Step: 9
Training loss: 3.59688716458833
Validation loss: 3.0970595395082587

Epoch: 6| Step: 10
Training loss: 3.8296455944419088
Validation loss: 3.0985853274551585

Epoch: 6| Step: 11
Training loss: 3.223261070138367
Validation loss: 3.1007464257833828

Epoch: 6| Step: 12
Training loss: 3.2678174411765144
Validation loss: 3.0990126021402147

Epoch: 6| Step: 13
Training loss: 4.49605769085779
Validation loss: 3.0948329665419823

Epoch: 51| Step: 0
Training loss: 3.0651101647347767
Validation loss: 3.098305315205229

Epoch: 6| Step: 1
Training loss: 3.43649249484329
Validation loss: 3.102877813799381

Epoch: 6| Step: 2
Training loss: 2.7464579399050923
Validation loss: 3.1028393582634837

Epoch: 6| Step: 3
Training loss: 3.1572031527028037
Validation loss: 3.1012015084718096

Epoch: 6| Step: 4
Training loss: 3.9737744103396233
Validation loss: 3.106164057703469

Epoch: 6| Step: 5
Training loss: 3.662649439344058
Validation loss: 3.0995634648219577

Epoch: 6| Step: 6
Training loss: 3.7077153723237073
Validation loss: 3.0989151843155356

Epoch: 6| Step: 7
Training loss: 3.241613130364369
Validation loss: 3.0960614339005237

Epoch: 6| Step: 8
Training loss: 3.8517605806062893
Validation loss: 3.091841923748887

Epoch: 6| Step: 9
Training loss: 2.6679619583780685
Validation loss: 3.09336159908238

Epoch: 6| Step: 10
Training loss: 3.368213895416364
Validation loss: 3.0913376877393697

Epoch: 6| Step: 11
Training loss: 3.089973688106175
Validation loss: 3.090939492000519

Epoch: 6| Step: 12
Training loss: 3.866940885444648
Validation loss: 3.0890881393996605

Epoch: 6| Step: 13
Training loss: 2.3309008543972403
Validation loss: 3.0894081878311774

Epoch: 52| Step: 0
Training loss: 3.2583745018845285
Validation loss: 3.0907934900508733

Epoch: 6| Step: 1
Training loss: 3.5784978547376975
Validation loss: 3.0954429624025006

Epoch: 6| Step: 2
Training loss: 2.7800607603280403
Validation loss: 3.094290934538743

Epoch: 6| Step: 3
Training loss: 3.8664003746371933
Validation loss: 3.0921633950535825

Epoch: 6| Step: 4
Training loss: 3.4964398942644648
Validation loss: 3.0892461080491587

Epoch: 6| Step: 5
Training loss: 3.391313052352315
Validation loss: 3.090295508057583

Epoch: 6| Step: 6
Training loss: 3.027215219045695
Validation loss: 3.086699955640099

Epoch: 6| Step: 7
Training loss: 3.819722822429076
Validation loss: 3.0899308306735835

Epoch: 6| Step: 8
Training loss: 3.087926605034293
Validation loss: 3.0887916235670745

Epoch: 6| Step: 9
Training loss: 4.145937178699368
Validation loss: 3.0911933143404617

Epoch: 6| Step: 10
Training loss: 2.953355406799952
Validation loss: 3.0904147509331703

Epoch: 6| Step: 11
Training loss: 2.995132152717748
Validation loss: 3.094708178813812

Epoch: 6| Step: 12
Training loss: 3.1012141034448546
Validation loss: 3.092313666529215

Epoch: 6| Step: 13
Training loss: 2.977059710769063
Validation loss: 3.092993466332174

Epoch: 53| Step: 0
Training loss: 2.4569489627516496
Validation loss: 3.0941031005791553

Epoch: 6| Step: 1
Training loss: 3.525920525878252
Validation loss: 3.094277287347007

Epoch: 6| Step: 2
Training loss: 2.965870313879216
Validation loss: 3.0935202246314373

Epoch: 6| Step: 3
Training loss: 3.3470872998689973
Validation loss: 3.0909615864410553

Epoch: 6| Step: 4
Training loss: 3.3302847431776894
Validation loss: 3.094362037820056

Epoch: 6| Step: 5
Training loss: 3.8551323308138126
Validation loss: 3.0918975169636327

Epoch: 6| Step: 6
Training loss: 3.5318551684328923
Validation loss: 3.087831434449095

Epoch: 6| Step: 7
Training loss: 3.519119899136992
Validation loss: 3.0891506544599796

Epoch: 6| Step: 8
Training loss: 3.1849826521228857
Validation loss: 3.0911349483767996

Epoch: 6| Step: 9
Training loss: 3.72330919845896
Validation loss: 3.0855733943007126

Epoch: 6| Step: 10
Training loss: 3.1690876557014076
Validation loss: 3.087726023740971

Epoch: 6| Step: 11
Training loss: 3.695950152684412
Validation loss: 3.090710469869095

Epoch: 6| Step: 12
Training loss: 2.9721685703778964
Validation loss: 3.09071456245384

Epoch: 6| Step: 13
Training loss: 3.358779499590242
Validation loss: 3.0896181208509828

Epoch: 54| Step: 0
Training loss: 3.165338856906244
Validation loss: 3.0867297504376547

Epoch: 6| Step: 1
Training loss: 3.076173115079115
Validation loss: 3.093508338377071

Epoch: 6| Step: 2
Training loss: 3.8139463088962797
Validation loss: 3.095429328571868

Epoch: 6| Step: 3
Training loss: 3.6556712939702476
Validation loss: 3.100834525571041

Epoch: 6| Step: 4
Training loss: 4.112013749244354
Validation loss: 3.0990151517062223

Epoch: 6| Step: 5
Training loss: 3.00292254191223
Validation loss: 3.085399733998493

Epoch: 6| Step: 6
Training loss: 2.308385126333882
Validation loss: 3.0878406135669776

Epoch: 6| Step: 7
Training loss: 3.928158168607167
Validation loss: 3.0840009771894827

Epoch: 6| Step: 8
Training loss: 3.3830853852116727
Validation loss: 3.078936579633639

Epoch: 6| Step: 9
Training loss: 3.256197082909605
Validation loss: 3.0781848402564007

Epoch: 6| Step: 10
Training loss: 3.02166427934836
Validation loss: 3.0786800730436408

Epoch: 6| Step: 11
Training loss: 2.7123406816095232
Validation loss: 3.0774384453309644

Epoch: 6| Step: 12
Training loss: 2.8767565461310776
Validation loss: 3.0792818337462817

Epoch: 6| Step: 13
Training loss: 4.388764445368833
Validation loss: 3.077926062137344

Epoch: 55| Step: 0
Training loss: 2.1609603737194925
Validation loss: 3.0786413752077024

Epoch: 6| Step: 1
Training loss: 2.8450879313685964
Validation loss: 3.077128554141649

Epoch: 6| Step: 2
Training loss: 3.6552567396259
Validation loss: 3.0751256151251107

Epoch: 6| Step: 3
Training loss: 3.2690473082145397
Validation loss: 3.075655261892801

Epoch: 6| Step: 4
Training loss: 3.410964782577774
Validation loss: 3.076398677821619

Epoch: 6| Step: 5
Training loss: 3.4675675859857304
Validation loss: 3.0740039173565377

Epoch: 6| Step: 6
Training loss: 3.053892534624804
Validation loss: 3.0739198032136277

Epoch: 6| Step: 7
Training loss: 3.8750633726783037
Validation loss: 3.0766134932326903

Epoch: 6| Step: 8
Training loss: 3.8225914646180925
Validation loss: 3.077281337613798

Epoch: 6| Step: 9
Training loss: 3.6038572733536633
Validation loss: 3.078583419142459

Epoch: 6| Step: 10
Training loss: 3.264921851865907
Validation loss: 3.076582553871725

Epoch: 6| Step: 11
Training loss: 2.8493048104462306
Validation loss: 3.0747492716932707

Epoch: 6| Step: 12
Training loss: 3.6793290467824527
Validation loss: 3.073337971689578

Epoch: 6| Step: 13
Training loss: 3.3857764106739494
Validation loss: 3.075870555959034

Epoch: 56| Step: 0
Training loss: 2.619303107288804
Validation loss: 3.0707781022024765

Epoch: 6| Step: 1
Training loss: 3.695955055293821
Validation loss: 3.0758887721884864

Epoch: 6| Step: 2
Training loss: 3.4597635796980097
Validation loss: 3.0719555257729905

Epoch: 6| Step: 3
Training loss: 4.13059317811035
Validation loss: 3.0707274522397476

Epoch: 6| Step: 4
Training loss: 3.358679695032446
Validation loss: 3.071582922019213

Epoch: 6| Step: 5
Training loss: 3.6777382646520853
Validation loss: 3.069347510601935

Epoch: 6| Step: 6
Training loss: 3.153711185465944
Validation loss: 3.0686520104640045

Epoch: 6| Step: 7
Training loss: 3.3759278328942632
Validation loss: 3.068752027219831

Epoch: 6| Step: 8
Training loss: 3.0995759920126544
Validation loss: 3.06768732188906

Epoch: 6| Step: 9
Training loss: 3.334304016558974
Validation loss: 3.0669978405917346

Epoch: 6| Step: 10
Training loss: 3.4700007202851264
Validation loss: 3.0668362190310416

Epoch: 6| Step: 11
Training loss: 2.6811509654288708
Validation loss: 3.066603514162404

Epoch: 6| Step: 12
Training loss: 2.620082154041549
Validation loss: 3.065728612573401

Epoch: 6| Step: 13
Training loss: 3.780506281578719
Validation loss: 3.067563479917227

Epoch: 57| Step: 0
Training loss: 3.458966040279965
Validation loss: 3.0667821259407337

Epoch: 6| Step: 1
Training loss: 3.1989613337468037
Validation loss: 3.066232380360527

Epoch: 6| Step: 2
Training loss: 2.8974039954802477
Validation loss: 3.0663531392142427

Epoch: 6| Step: 3
Training loss: 3.47889586592109
Validation loss: 3.064286149559252

Epoch: 6| Step: 4
Training loss: 3.4421086714865994
Validation loss: 3.064037838448632

Epoch: 6| Step: 5
Training loss: 3.002649726533054
Validation loss: 3.064365825626417

Epoch: 6| Step: 6
Training loss: 3.05238259229509
Validation loss: 3.0638878101025218

Epoch: 6| Step: 7
Training loss: 3.4909437725573205
Validation loss: 3.063795724295128

Epoch: 6| Step: 8
Training loss: 3.425133116425459
Validation loss: 3.0650898352677816

Epoch: 6| Step: 9
Training loss: 4.039077375078388
Validation loss: 3.06177695040632

Epoch: 6| Step: 10
Training loss: 2.8536499743783454
Validation loss: 3.0608104777592913

Epoch: 6| Step: 11
Training loss: 3.544364948503976
Validation loss: 3.0634469649894096

Epoch: 6| Step: 12
Training loss: 3.549420086412582
Validation loss: 3.061749935484036

Epoch: 6| Step: 13
Training loss: 2.60525717726999
Validation loss: 3.0633883858794553

Epoch: 58| Step: 0
Training loss: 3.8740118674203328
Validation loss: 3.061602426823475

Epoch: 6| Step: 1
Training loss: 3.7849090778914722
Validation loss: 3.058806360264937

Epoch: 6| Step: 2
Training loss: 3.955408213463161
Validation loss: 3.0610039719092126

Epoch: 6| Step: 3
Training loss: 3.6078575214073227
Validation loss: 3.0615748618904015

Epoch: 6| Step: 4
Training loss: 3.1652895961568923
Validation loss: 3.05883908608299

Epoch: 6| Step: 5
Training loss: 3.144859685390733
Validation loss: 3.057341643956326

Epoch: 6| Step: 6
Training loss: 3.464318959297138
Validation loss: 3.058231502300796

Epoch: 6| Step: 7
Training loss: 2.529044992284251
Validation loss: 3.056759035396699

Epoch: 6| Step: 8
Training loss: 2.824601734411124
Validation loss: 3.0569682535705263

Epoch: 6| Step: 9
Training loss: 2.894380511478588
Validation loss: 3.0563773235661262

Epoch: 6| Step: 10
Training loss: 2.890393057100735
Validation loss: 3.0546371942162924

Epoch: 6| Step: 11
Training loss: 2.8176036728314577
Validation loss: 3.054997519295782

Epoch: 6| Step: 12
Training loss: 3.605793418607525
Validation loss: 3.0572181124426323

Epoch: 6| Step: 13
Training loss: 3.664361156663246
Validation loss: 3.0551285970883515

Epoch: 59| Step: 0
Training loss: 2.296614859245351
Validation loss: 3.0546643803062548

Epoch: 6| Step: 1
Training loss: 3.6602492671778486
Validation loss: 3.0551928550735075

Epoch: 6| Step: 2
Training loss: 3.2293999044212196
Validation loss: 3.0551250089795547

Epoch: 6| Step: 3
Training loss: 2.837946576842181
Validation loss: 3.0513061056831456

Epoch: 6| Step: 4
Training loss: 3.0263374083421133
Validation loss: 3.0512122395394994

Epoch: 6| Step: 5
Training loss: 3.9963488604571973
Validation loss: 3.051425538026619

Epoch: 6| Step: 6
Training loss: 3.3322613581886618
Validation loss: 3.051187828155717

Epoch: 6| Step: 7
Training loss: 3.662618844769817
Validation loss: 3.052486885357538

Epoch: 6| Step: 8
Training loss: 3.352503504399254
Validation loss: 3.050378918994011

Epoch: 6| Step: 9
Training loss: 3.4723483829890514
Validation loss: 3.050289915787755

Epoch: 6| Step: 10
Training loss: 3.2952438586100907
Validation loss: 3.050286674139434

Epoch: 6| Step: 11
Training loss: 2.7309859717786464
Validation loss: 3.0534478989441878

Epoch: 6| Step: 12
Training loss: 3.078958621156819
Validation loss: 3.051852590934147

Epoch: 6| Step: 13
Training loss: 4.456192619735436
Validation loss: 3.0513126271387643

Epoch: 60| Step: 0
Training loss: 3.469755559661059
Validation loss: 3.053927363893425

Epoch: 6| Step: 1
Training loss: 3.629645823495195
Validation loss: 3.050119308123181

Epoch: 6| Step: 2
Training loss: 2.86780826178798
Validation loss: 3.046717341119568

Epoch: 6| Step: 3
Training loss: 3.934961136234608
Validation loss: 3.0468492850245803

Epoch: 6| Step: 4
Training loss: 2.2766656667652234
Validation loss: 3.048372919510099

Epoch: 6| Step: 5
Training loss: 3.233550772942384
Validation loss: 3.0474958428314958

Epoch: 6| Step: 6
Training loss: 3.173580819691884
Validation loss: 3.0476737221556793

Epoch: 6| Step: 7
Training loss: 3.51781954617289
Validation loss: 3.04750074046042

Epoch: 6| Step: 8
Training loss: 2.936418374772931
Validation loss: 3.045191199601777

Epoch: 6| Step: 9
Training loss: 4.177368889970756
Validation loss: 3.044986142947461

Epoch: 6| Step: 10
Training loss: 3.6431780200973716
Validation loss: 3.0457622876385324

Epoch: 6| Step: 11
Training loss: 2.7028216594214904
Validation loss: 3.045327380046295

Epoch: 6| Step: 12
Training loss: 3.077517531815273
Validation loss: 3.0432052291894047

Epoch: 6| Step: 13
Training loss: 3.2160703004109004
Validation loss: 3.044343693786227

Epoch: 61| Step: 0
Training loss: 3.3716197570413806
Validation loss: 3.042831931524854

Epoch: 6| Step: 1
Training loss: 4.025261267481202
Validation loss: 3.0429772918938074

Epoch: 6| Step: 2
Training loss: 2.894825620521896
Validation loss: 3.0422117346401647

Epoch: 6| Step: 3
Training loss: 2.8948839309958507
Validation loss: 3.0454933047967505

Epoch: 6| Step: 4
Training loss: 2.9472953941505184
Validation loss: 3.043970395931737

Epoch: 6| Step: 5
Training loss: 2.968192279026653
Validation loss: 3.0421986526964124

Epoch: 6| Step: 6
Training loss: 2.810813228453471
Validation loss: 3.049384646823444

Epoch: 6| Step: 7
Training loss: 3.6117079820251687
Validation loss: 3.0420106605362998

Epoch: 6| Step: 8
Training loss: 3.446992702324792
Validation loss: 3.0391248521619967

Epoch: 6| Step: 9
Training loss: 3.777173453657011
Validation loss: 3.0398436030553566

Epoch: 6| Step: 10
Training loss: 2.9803333976679327
Validation loss: 3.038337386292853

Epoch: 6| Step: 11
Training loss: 3.6923935311683223
Validation loss: 3.0387231527816585

Epoch: 6| Step: 12
Training loss: 3.4284160925099725
Validation loss: 3.0419918621982642

Epoch: 6| Step: 13
Training loss: 3.079376431049241
Validation loss: 3.04503129151861

Epoch: 62| Step: 0
Training loss: 3.649781594208728
Validation loss: 3.0422735048568605

Epoch: 6| Step: 1
Training loss: 3.6967311337774422
Validation loss: 3.0406606873038897

Epoch: 6| Step: 2
Training loss: 3.6643019477996677
Validation loss: 3.039117535237973

Epoch: 6| Step: 3
Training loss: 3.5134597553137668
Validation loss: 3.036498363504489

Epoch: 6| Step: 4
Training loss: 2.9422594836520837
Validation loss: 3.0345334435426112

Epoch: 6| Step: 5
Training loss: 2.7412459884593328
Validation loss: 3.0351306435234466

Epoch: 6| Step: 6
Training loss: 3.7432704306322435
Validation loss: 3.033657469013748

Epoch: 6| Step: 7
Training loss: 2.8498024721459245
Validation loss: 3.033850544383322

Epoch: 6| Step: 8
Training loss: 2.6882151162378047
Validation loss: 3.0335355531244956

Epoch: 6| Step: 9
Training loss: 3.162712807713838
Validation loss: 3.0328141720395094

Epoch: 6| Step: 10
Training loss: 3.3517814511359774
Validation loss: 3.0352934043278212

Epoch: 6| Step: 11
Training loss: 3.1288023132510743
Validation loss: 3.0359785240191215

Epoch: 6| Step: 12
Training loss: 3.8089416657996162
Validation loss: 3.030586109081488

Epoch: 6| Step: 13
Training loss: 2.7420882943404177
Validation loss: 3.032252389646817

Epoch: 63| Step: 0
Training loss: 2.8667939874925845
Validation loss: 3.035291828284246

Epoch: 6| Step: 1
Training loss: 3.7787232587135016
Validation loss: 3.0319133202352355

Epoch: 6| Step: 2
Training loss: 3.05564720902591
Validation loss: 3.0313133636540095

Epoch: 6| Step: 3
Training loss: 3.8670977341223103
Validation loss: 3.0358968252960037

Epoch: 6| Step: 4
Training loss: 4.000736883953258
Validation loss: 3.029225534246036

Epoch: 6| Step: 5
Training loss: 2.7877760198810675
Validation loss: 3.0305433144117004

Epoch: 6| Step: 6
Training loss: 2.9983541424382416
Validation loss: 3.0302779044277734

Epoch: 6| Step: 7
Training loss: 3.1676023673577514
Validation loss: 3.0278526883433927

Epoch: 6| Step: 8
Training loss: 3.1952699691068474
Validation loss: 3.0281884484811648

Epoch: 6| Step: 9
Training loss: 3.2067531971614036
Validation loss: 3.030619463617659

Epoch: 6| Step: 10
Training loss: 3.195429195893985
Validation loss: 3.0276250880386133

Epoch: 6| Step: 11
Training loss: 2.969174003438551
Validation loss: 3.028498002632329

Epoch: 6| Step: 12
Training loss: 3.722313463854617
Validation loss: 3.0283473310386877

Epoch: 6| Step: 13
Training loss: 2.953039097419584
Validation loss: 3.0273398511995793

Epoch: 64| Step: 0
Training loss: 3.8877197203532354
Validation loss: 3.02613963219416

Epoch: 6| Step: 1
Training loss: 2.5529257389598703
Validation loss: 3.027025656076582

Epoch: 6| Step: 2
Training loss: 3.3286854446689285
Validation loss: 3.0253523801785946

Epoch: 6| Step: 3
Training loss: 3.3365563705257983
Validation loss: 3.025109463050808

Epoch: 6| Step: 4
Training loss: 2.5810689128320625
Validation loss: 3.024620685069224

Epoch: 6| Step: 5
Training loss: 3.259916874580517
Validation loss: 3.0309617066455004

Epoch: 6| Step: 6
Training loss: 3.156239122428657
Validation loss: 3.0367312057111646

Epoch: 6| Step: 7
Training loss: 3.3243117000077764
Validation loss: 3.034651731524984

Epoch: 6| Step: 8
Training loss: 3.3415134829246735
Validation loss: 3.029330741339854

Epoch: 6| Step: 9
Training loss: 3.0514526409916383
Validation loss: 3.0321174905143304

Epoch: 6| Step: 10
Training loss: 3.3191024909175137
Validation loss: 3.022055701444264

Epoch: 6| Step: 11
Training loss: 3.1675706041712264
Validation loss: 3.024231195413757

Epoch: 6| Step: 12
Training loss: 4.187287965786787
Validation loss: 3.022894192336147

Epoch: 6| Step: 13
Training loss: 3.355647374329175
Validation loss: 3.0198643460903676

Epoch: 65| Step: 0
Training loss: 2.968716912336173
Validation loss: 3.0194379073634927

Epoch: 6| Step: 1
Training loss: 2.953822785141402
Validation loss: 3.0209635032186646

Epoch: 6| Step: 2
Training loss: 3.6239635695927395
Validation loss: 3.020289453096281

Epoch: 6| Step: 3
Training loss: 2.828599752969656
Validation loss: 3.020701204719373

Epoch: 6| Step: 4
Training loss: 4.105438319419214
Validation loss: 3.022478717341676

Epoch: 6| Step: 5
Training loss: 3.779347343009283
Validation loss: 3.020280445550675

Epoch: 6| Step: 6
Training loss: 3.0674013114791587
Validation loss: 3.0197192527031014

Epoch: 6| Step: 7
Training loss: 3.005582066683642
Validation loss: 3.0202463334297858

Epoch: 6| Step: 8
Training loss: 3.7958273364514166
Validation loss: 3.0198024265084724

Epoch: 6| Step: 9
Training loss: 2.530357486060652
Validation loss: 3.0189455005433414

Epoch: 6| Step: 10
Training loss: 3.286958216128583
Validation loss: 3.0194424463581524

Epoch: 6| Step: 11
Training loss: 3.2208662760942817
Validation loss: 3.017361878169599

Epoch: 6| Step: 12
Training loss: 3.3449214416311177
Validation loss: 3.0164918592467402

Epoch: 6| Step: 13
Training loss: 3.1536042861448723
Validation loss: 3.0159171225044514

Epoch: 66| Step: 0
Training loss: 3.2959969603330057
Validation loss: 3.0161207530035425

Epoch: 6| Step: 1
Training loss: 3.346842966362733
Validation loss: 3.0156667779673176

Epoch: 6| Step: 2
Training loss: 2.5188420735608905
Validation loss: 3.0134601187525343

Epoch: 6| Step: 3
Training loss: 3.4878426988461695
Validation loss: 3.018379466250684

Epoch: 6| Step: 4
Training loss: 3.2486895340051336
Validation loss: 3.0154023659728852

Epoch: 6| Step: 5
Training loss: 3.4013233077936924
Validation loss: 3.016425338806975

Epoch: 6| Step: 6
Training loss: 3.0953055430319187
Validation loss: 3.016401958992914

Epoch: 6| Step: 7
Training loss: 3.2184504397352813
Validation loss: 3.01675711732821

Epoch: 6| Step: 8
Training loss: 2.797678485729799
Validation loss: 3.0137805801749464

Epoch: 6| Step: 9
Training loss: 3.434051448447728
Validation loss: 3.013673280306721

Epoch: 6| Step: 10
Training loss: 3.219639923623909
Validation loss: 3.015585182705358

Epoch: 6| Step: 11
Training loss: 3.4457340458346497
Validation loss: 3.013083373284757

Epoch: 6| Step: 12
Training loss: 3.4283661610600693
Validation loss: 3.013628386728012

Epoch: 6| Step: 13
Training loss: 4.305702269867619
Validation loss: 3.0086633525832216

Epoch: 67| Step: 0
Training loss: 3.0416885444864596
Validation loss: 3.0098905180561646

Epoch: 6| Step: 1
Training loss: 3.401109789194806
Validation loss: 3.0105950740204532

Epoch: 6| Step: 2
Training loss: 3.6809397386977576
Validation loss: 3.009667422353159

Epoch: 6| Step: 3
Training loss: 3.2187858505474654
Validation loss: 3.011528327367319

Epoch: 6| Step: 4
Training loss: 3.5487735725203087
Validation loss: 3.01030960571068

Epoch: 6| Step: 5
Training loss: 3.489718185020713
Validation loss: 3.01134001761078

Epoch: 6| Step: 6
Training loss: 2.9498405154808727
Validation loss: 3.0093165387056597

Epoch: 6| Step: 7
Training loss: 3.313382301147812
Validation loss: 3.0102523575495117

Epoch: 6| Step: 8
Training loss: 2.563398250291907
Validation loss: 3.0107096413715397

Epoch: 6| Step: 9
Training loss: 3.542969019173777
Validation loss: 3.0106548072209836

Epoch: 6| Step: 10
Training loss: 3.1232084097725568
Validation loss: 3.0096639197414254

Epoch: 6| Step: 11
Training loss: 1.7403568520137112
Validation loss: 3.0089050294690756

Epoch: 6| Step: 12
Training loss: 3.7251649551222688
Validation loss: 3.0070545398015702

Epoch: 6| Step: 13
Training loss: 4.469034465992351
Validation loss: 3.0073757443169287

Epoch: 68| Step: 0
Training loss: 2.460663310928282
Validation loss: 3.0094642930972717

Epoch: 6| Step: 1
Training loss: 4.329992889680376
Validation loss: 3.008124052100389

Epoch: 6| Step: 2
Training loss: 2.9637096784238834
Validation loss: 3.006463017741987

Epoch: 6| Step: 3
Training loss: 3.4444685613820196
Validation loss: 3.006606022310242

Epoch: 6| Step: 4
Training loss: 3.189979785388767
Validation loss: 3.0055941172753364

Epoch: 6| Step: 5
Training loss: 3.578166978081748
Validation loss: 3.0048803997674307

Epoch: 6| Step: 6
Training loss: 3.232188789745827
Validation loss: 3.005507096554184

Epoch: 6| Step: 7
Training loss: 3.555129474369226
Validation loss: 3.002957482564891

Epoch: 6| Step: 8
Training loss: 3.2304637313859144
Validation loss: 3.0021921185023213

Epoch: 6| Step: 9
Training loss: 2.8952480978063972
Validation loss: 3.000535418986075

Epoch: 6| Step: 10
Training loss: 3.1119444692212297
Validation loss: 2.9992781577364287

Epoch: 6| Step: 11
Training loss: 2.5986671259125953
Validation loss: 2.998704612661443

Epoch: 6| Step: 12
Training loss: 3.559807546321248
Validation loss: 3.001524737725048

Epoch: 6| Step: 13
Training loss: 3.3482517349328673
Validation loss: 2.9985083388910603

Epoch: 69| Step: 0
Training loss: 2.3360885520245995
Validation loss: 3.003545248930887

Epoch: 6| Step: 1
Training loss: 3.066765597724136
Validation loss: 3.0023116081192422

Epoch: 6| Step: 2
Training loss: 4.079957046282684
Validation loss: 3.0030962269553996

Epoch: 6| Step: 3
Training loss: 3.611906674773105
Validation loss: 2.9984259423985407

Epoch: 6| Step: 4
Training loss: 3.3251495671871725
Validation loss: 2.9986554845094786

Epoch: 6| Step: 5
Training loss: 3.3453064620468194
Validation loss: 2.9997981697471814

Epoch: 6| Step: 6
Training loss: 3.091311177451633
Validation loss: 2.996713347087557

Epoch: 6| Step: 7
Training loss: 3.189791435431209
Validation loss: 2.9967271199222547

Epoch: 6| Step: 8
Training loss: 3.2048217745307377
Validation loss: 2.9957062371352317

Epoch: 6| Step: 9
Training loss: 3.0259573438301617
Validation loss: 2.996680338907063

Epoch: 6| Step: 10
Training loss: 2.5096086861194693
Validation loss: 2.9958777712346776

Epoch: 6| Step: 11
Training loss: 3.160079596760393
Validation loss: 2.9971230497709516

Epoch: 6| Step: 12
Training loss: 3.772943879058681
Validation loss: 2.9966082952200734

Epoch: 6| Step: 13
Training loss: 3.934621818623846
Validation loss: 2.9921865121347206

Epoch: 70| Step: 0
Training loss: 3.575792110160753
Validation loss: 2.990077063970458

Epoch: 6| Step: 1
Training loss: 3.0141194592794642
Validation loss: 2.9899859579438863

Epoch: 6| Step: 2
Training loss: 3.249381373289696
Validation loss: 2.991238094966909

Epoch: 6| Step: 3
Training loss: 3.5580797043997383
Validation loss: 2.992677458118964

Epoch: 6| Step: 4
Training loss: 2.8927409907306125
Validation loss: 2.991836415444992

Epoch: 6| Step: 5
Training loss: 3.2051724472904914
Validation loss: 2.9900218728730894

Epoch: 6| Step: 6
Training loss: 3.711909823275993
Validation loss: 2.9936429978632586

Epoch: 6| Step: 7
Training loss: 3.653031195748848
Validation loss: 2.9925060314188583

Epoch: 6| Step: 8
Training loss: 2.911973137742112
Validation loss: 2.9896999623794906

Epoch: 6| Step: 9
Training loss: 3.658798763991502
Validation loss: 2.9960574012993595

Epoch: 6| Step: 10
Training loss: 2.613911232045976
Validation loss: 2.9871629525267687

Epoch: 6| Step: 11
Training loss: 3.264187437070459
Validation loss: 2.9852761882260532

Epoch: 6| Step: 12
Training loss: 3.4118121169976368
Validation loss: 2.9869082342196496

Epoch: 6| Step: 13
Training loss: 2.2247700218759774
Validation loss: 2.9839393131473986

Epoch: 71| Step: 0
Training loss: 2.897002901054091
Validation loss: 2.982964799551991

Epoch: 6| Step: 1
Training loss: 2.6888566252539152
Validation loss: 2.9835951733920143

Epoch: 6| Step: 2
Training loss: 3.0195839940210707
Validation loss: 2.99113207343076

Epoch: 6| Step: 3
Training loss: 3.425519004536313
Validation loss: 2.9833408886219224

Epoch: 6| Step: 4
Training loss: 3.131474768210338
Validation loss: 2.985443702156684

Epoch: 6| Step: 5
Training loss: 3.6728059927627044
Validation loss: 2.990516176336612

Epoch: 6| Step: 6
Training loss: 4.099136652414264
Validation loss: 3.0170823692981434

Epoch: 6| Step: 7
Training loss: 3.212995403401672
Validation loss: 2.982461496378691

Epoch: 6| Step: 8
Training loss: 3.300027217174767
Validation loss: 2.9830782168429417

Epoch: 6| Step: 9
Training loss: 3.0746150264268826
Validation loss: 2.9839992577651038

Epoch: 6| Step: 10
Training loss: 2.826888261857132
Validation loss: 2.984752443679706

Epoch: 6| Step: 11
Training loss: 3.54210136588179
Validation loss: 2.984517202375575

Epoch: 6| Step: 12
Training loss: 3.571884643862063
Validation loss: 2.9840823386894004

Epoch: 6| Step: 13
Training loss: 2.6829066389449108
Validation loss: 2.985075464840473

Epoch: 72| Step: 0
Training loss: 3.299997595583878
Validation loss: 2.985056124165564

Epoch: 6| Step: 1
Training loss: 2.698625645707716
Validation loss: 2.984767632646464

Epoch: 6| Step: 2
Training loss: 3.6068013581270737
Validation loss: 2.9840945929407217

Epoch: 6| Step: 3
Training loss: 3.2659730862631604
Validation loss: 2.98345932616837

Epoch: 6| Step: 4
Training loss: 3.625570712709778
Validation loss: 2.984311783979058

Epoch: 6| Step: 5
Training loss: 3.473532189688579
Validation loss: 2.9826888625786143

Epoch: 6| Step: 6
Training loss: 3.3338084518062763
Validation loss: 2.979931675841455

Epoch: 6| Step: 7
Training loss: 4.240867226639426
Validation loss: 2.9797290799208374

Epoch: 6| Step: 8
Training loss: 2.243699471162422
Validation loss: 2.978422480861155

Epoch: 6| Step: 9
Training loss: 3.002156118604366
Validation loss: 2.9785754394980613

Epoch: 6| Step: 10
Training loss: 3.0666592438925875
Validation loss: 2.9789951495096774

Epoch: 6| Step: 11
Training loss: 3.2573606328654345
Validation loss: 2.9766257858578804

Epoch: 6| Step: 12
Training loss: 3.0448501509953823
Validation loss: 2.9772771239576477

Epoch: 6| Step: 13
Training loss: 2.849771684569626
Validation loss: 2.998597634255769

Epoch: 73| Step: 0
Training loss: 3.5494923618189866
Validation loss: 2.994452426666462

Epoch: 6| Step: 1
Training loss: 3.051586557694866
Validation loss: 3.0007170295427517

Epoch: 6| Step: 2
Training loss: 3.591216280520309
Validation loss: 3.0043693430989324

Epoch: 6| Step: 3
Training loss: 3.6768137082819625
Validation loss: 2.9840484631202298

Epoch: 6| Step: 4
Training loss: 3.161550923750753
Validation loss: 2.973854559803688

Epoch: 6| Step: 5
Training loss: 2.838368952451689
Validation loss: 2.9742880219088668

Epoch: 6| Step: 6
Training loss: 3.4906170277175774
Validation loss: 2.9738970564648004

Epoch: 6| Step: 7
Training loss: 3.3937464817654126
Validation loss: 2.974394844670452

Epoch: 6| Step: 8
Training loss: 3.532455643620385
Validation loss: 2.973517355455678

Epoch: 6| Step: 9
Training loss: 2.604213978655509
Validation loss: 2.974422318572122

Epoch: 6| Step: 10
Training loss: 3.073728258103355
Validation loss: 2.9724817677962303

Epoch: 6| Step: 11
Training loss: 2.922941941260548
Validation loss: 2.9734511108373165

Epoch: 6| Step: 12
Training loss: 2.825939282255698
Validation loss: 2.972542999095118

Epoch: 6| Step: 13
Training loss: 3.925550463521058
Validation loss: 2.9736433269474403

Epoch: 74| Step: 0
Training loss: 2.7010362967601926
Validation loss: 2.973351407037771

Epoch: 6| Step: 1
Training loss: 2.9477129395162454
Validation loss: 2.974036650580686

Epoch: 6| Step: 2
Training loss: 3.40902624820307
Validation loss: 2.9700573307875073

Epoch: 6| Step: 3
Training loss: 3.1458907132673533
Validation loss: 2.9713319113246284

Epoch: 6| Step: 4
Training loss: 3.5063659811981984
Validation loss: 2.9679664411089006

Epoch: 6| Step: 5
Training loss: 2.8242926159243824
Validation loss: 2.968519535844871

Epoch: 6| Step: 6
Training loss: 3.500946325706247
Validation loss: 2.9695497429768

Epoch: 6| Step: 7
Training loss: 3.8444548170014716
Validation loss: 2.98186779445809

Epoch: 6| Step: 8
Training loss: 3.1971806146113
Validation loss: 2.989265591083103

Epoch: 6| Step: 9
Training loss: 3.272240321942803
Validation loss: 2.9946331485493194

Epoch: 6| Step: 10
Training loss: 3.770431806286831
Validation loss: 2.9951077943996007

Epoch: 6| Step: 11
Training loss: 3.2146656084358227
Validation loss: 2.994341435056699

Epoch: 6| Step: 12
Training loss: 2.868188833896689
Validation loss: 2.986495312961176

Epoch: 6| Step: 13
Training loss: 2.9770241527045314
Validation loss: 2.97202591344724

Epoch: 75| Step: 0
Training loss: 3.2303279306331594
Validation loss: 2.9668392014277187

Epoch: 6| Step: 1
Training loss: 3.159779605181398
Validation loss: 2.9637363759944213

Epoch: 6| Step: 2
Training loss: 3.5135035917177704
Validation loss: 2.9646332457301914

Epoch: 6| Step: 3
Training loss: 3.987102577231334
Validation loss: 2.9669058563557806

Epoch: 6| Step: 4
Training loss: 3.7532428707064494
Validation loss: 2.9632518361372395

Epoch: 6| Step: 5
Training loss: 3.356284205654881
Validation loss: 2.9647217843991345

Epoch: 6| Step: 6
Training loss: 2.8043199898765723
Validation loss: 2.962470491323865

Epoch: 6| Step: 7
Training loss: 3.3298902531315338
Validation loss: 2.964709069596371

Epoch: 6| Step: 8
Training loss: 3.0544951785685366
Validation loss: 2.961642679707604

Epoch: 6| Step: 9
Training loss: 2.742140549477875
Validation loss: 2.961889957248894

Epoch: 6| Step: 10
Training loss: 3.5323423873393196
Validation loss: 2.9606728778199676

Epoch: 6| Step: 11
Training loss: 3.1095108692637394
Validation loss: 2.9613887399626395

Epoch: 6| Step: 12
Training loss: 2.8050218983167707
Validation loss: 2.9613076255561457

Epoch: 6| Step: 13
Training loss: 2.2713076128289464
Validation loss: 2.9614939227290438

Epoch: 76| Step: 0
Training loss: 3.45736558235017
Validation loss: 2.959870966748721

Epoch: 6| Step: 1
Training loss: 2.136162331502632
Validation loss: 2.9588220554567224

Epoch: 6| Step: 2
Training loss: 3.6165952918631845
Validation loss: 2.9582308003741127

Epoch: 6| Step: 3
Training loss: 2.6085428521422456
Validation loss: 2.9610580197725227

Epoch: 6| Step: 4
Training loss: 3.4760629359299435
Validation loss: 2.960460933046555

Epoch: 6| Step: 5
Training loss: 4.169398340598198
Validation loss: 2.9617479547289465

Epoch: 6| Step: 6
Training loss: 2.944447195503661
Validation loss: 2.9627392093312426

Epoch: 6| Step: 7
Training loss: 2.445043579524489
Validation loss: 2.9661859239183817

Epoch: 6| Step: 8
Training loss: 3.353883024428958
Validation loss: 2.9652412028497515

Epoch: 6| Step: 9
Training loss: 3.641755677509524
Validation loss: 2.9721611964384773

Epoch: 6| Step: 10
Training loss: 3.4922318765095026
Validation loss: 2.9765387063053383

Epoch: 6| Step: 11
Training loss: 3.314474992561923
Validation loss: 2.9794538018068804

Epoch: 6| Step: 12
Training loss: 3.042397676877166
Validation loss: 2.9807026052768255

Epoch: 6| Step: 13
Training loss: 2.906547285072329
Validation loss: 2.9645443585101177

Epoch: 77| Step: 0
Training loss: 3.5839923577908372
Validation loss: 2.9546288019235303

Epoch: 6| Step: 1
Training loss: 4.015719995228517
Validation loss: 2.956506204463318

Epoch: 6| Step: 2
Training loss: 3.342335339344316
Validation loss: 2.9523877635764015

Epoch: 6| Step: 3
Training loss: 3.3450095398086885
Validation loss: 2.9568664753691336

Epoch: 6| Step: 4
Training loss: 3.120589386217066
Validation loss: 2.953719895692155

Epoch: 6| Step: 5
Training loss: 2.2365803538845466
Validation loss: 2.953693324571602

Epoch: 6| Step: 6
Training loss: 3.2019173183023684
Validation loss: 2.955609055272702

Epoch: 6| Step: 7
Training loss: 3.2284039652877916
Validation loss: 2.958721288546775

Epoch: 6| Step: 8
Training loss: 3.0354908644580054
Validation loss: 2.95395183821452

Epoch: 6| Step: 9
Training loss: 2.9928806388549174
Validation loss: 2.956059054971535

Epoch: 6| Step: 10
Training loss: 2.9507700092969147
Validation loss: 2.9547616026632086

Epoch: 6| Step: 11
Training loss: 3.320483681249075
Validation loss: 2.956237678681664

Epoch: 6| Step: 12
Training loss: 2.960798355899448
Validation loss: 2.954834766415982

Epoch: 6| Step: 13
Training loss: 3.9524535562584266
Validation loss: 2.955453415176253

Epoch: 78| Step: 0
Training loss: 3.505179387615943
Validation loss: 2.952451852425661

Epoch: 6| Step: 1
Training loss: 3.4371452842108594
Validation loss: 2.9551489099944765

Epoch: 6| Step: 2
Training loss: 3.623174273366594
Validation loss: 2.9521839582496887

Epoch: 6| Step: 3
Training loss: 3.2961639071328883
Validation loss: 2.952534043678797

Epoch: 6| Step: 4
Training loss: 2.343056741545967
Validation loss: 2.9527878011830877

Epoch: 6| Step: 5
Training loss: 2.903025325053647
Validation loss: 2.9528133716006586

Epoch: 6| Step: 6
Training loss: 2.652674523741322
Validation loss: 2.97413796571858

Epoch: 6| Step: 7
Training loss: 3.486720095699802
Validation loss: 2.954122989000208

Epoch: 6| Step: 8
Training loss: 3.215832619595718
Validation loss: 2.946448198897769

Epoch: 6| Step: 9
Training loss: 3.224158918132001
Validation loss: 2.9452417649734226

Epoch: 6| Step: 10
Training loss: 3.5350750487048486
Validation loss: 2.9438040042895635

Epoch: 6| Step: 11
Training loss: 3.2105480988218558
Validation loss: 2.9465191511885673

Epoch: 6| Step: 12
Training loss: 3.349769948775109
Validation loss: 2.946614625384743

Epoch: 6| Step: 13
Training loss: 3.2830002249451256
Validation loss: 2.9467638481370693

Epoch: 79| Step: 0
Training loss: 3.4365510497700718
Validation loss: 2.9461340821480806

Epoch: 6| Step: 1
Training loss: 4.05281673485591
Validation loss: 2.9458408033680032

Epoch: 6| Step: 2
Training loss: 2.930285746210318
Validation loss: 2.9462720271377534

Epoch: 6| Step: 3
Training loss: 3.739294411098315
Validation loss: 2.95142318026853

Epoch: 6| Step: 4
Training loss: 2.594470004605442
Validation loss: 2.9640245601980584

Epoch: 6| Step: 5
Training loss: 2.606527453686473
Validation loss: 2.967628919302926

Epoch: 6| Step: 6
Training loss: 2.9478709798087555
Validation loss: 2.980981284607734

Epoch: 6| Step: 7
Training loss: 2.405532928235081
Validation loss: 2.9655391944230214

Epoch: 6| Step: 8
Training loss: 2.861485437228487
Validation loss: 2.957627668251915

Epoch: 6| Step: 9
Training loss: 3.5545458419576086
Validation loss: 2.9571989040124502

Epoch: 6| Step: 10
Training loss: 3.1020472073335505
Validation loss: 2.9454333875505343

Epoch: 6| Step: 11
Training loss: 3.842314413300814
Validation loss: 2.9426023199376625

Epoch: 6| Step: 12
Training loss: 3.2340851437336875
Validation loss: 2.941785937918324

Epoch: 6| Step: 13
Training loss: 3.5359107123964595
Validation loss: 2.939808406501127

Epoch: 80| Step: 0
Training loss: 3.3858656991370424
Validation loss: 2.9407717729399114

Epoch: 6| Step: 1
Training loss: 3.3268189352450896
Validation loss: 2.939631634492992

Epoch: 6| Step: 2
Training loss: 2.420803300558539
Validation loss: 2.9388587591406314

Epoch: 6| Step: 3
Training loss: 2.977627941492856
Validation loss: 2.9396420891598036

Epoch: 6| Step: 4
Training loss: 3.4929928800312107
Validation loss: 2.9408886803068293

Epoch: 6| Step: 5
Training loss: 3.431189553539608
Validation loss: 2.9456070202471234

Epoch: 6| Step: 6
Training loss: 3.5929784858838794
Validation loss: 2.975120688961874

Epoch: 6| Step: 7
Training loss: 3.1911682264263392
Validation loss: 2.9593470435611926

Epoch: 6| Step: 8
Training loss: 2.832926178643308
Validation loss: 2.9515052212383113

Epoch: 6| Step: 9
Training loss: 2.902342107061278
Validation loss: 2.9350673977231425

Epoch: 6| Step: 10
Training loss: 3.142224260491707
Validation loss: 2.94014445713905

Epoch: 6| Step: 11
Training loss: 3.423278242173698
Validation loss: 2.943960635583043

Epoch: 6| Step: 12
Training loss: 3.219762254076894
Validation loss: 2.9421529405685103

Epoch: 6| Step: 13
Training loss: 3.9229958440995403
Validation loss: 2.941644809005738

Epoch: 81| Step: 0
Training loss: 2.5350025759350934
Validation loss: 2.9452971406380954

Epoch: 6| Step: 1
Training loss: 3.8891964170174798
Validation loss: 2.9446006905516837

Epoch: 6| Step: 2
Training loss: 2.590591345776672
Validation loss: 2.9365837755854782

Epoch: 6| Step: 3
Training loss: 3.580007799022853
Validation loss: 2.9359919041819316

Epoch: 6| Step: 4
Training loss: 2.7115245700111985
Validation loss: 2.936197023760161

Epoch: 6| Step: 5
Training loss: 3.1581211397927658
Validation loss: 2.932049860304663

Epoch: 6| Step: 6
Training loss: 3.476493371854861
Validation loss: 2.9342537814117327

Epoch: 6| Step: 7
Training loss: 3.1416653101047114
Validation loss: 2.9387827079709594

Epoch: 6| Step: 8
Training loss: 3.3917282348843227
Validation loss: 2.9529389179923253

Epoch: 6| Step: 9
Training loss: 3.5401625786641526
Validation loss: 2.946387471157111

Epoch: 6| Step: 10
Training loss: 2.930231557555818
Validation loss: 2.936798027537291

Epoch: 6| Step: 11
Training loss: 3.579050535746423
Validation loss: 2.9291866976476775

Epoch: 6| Step: 12
Training loss: 3.038658134801095
Validation loss: 2.930159862653395

Epoch: 6| Step: 13
Training loss: 3.2445905121999465
Validation loss: 2.9309212835612413

Epoch: 82| Step: 0
Training loss: 2.856980952716446
Validation loss: 2.9303520331678072

Epoch: 6| Step: 1
Training loss: 3.600183185579112
Validation loss: 2.9313512808284345

Epoch: 6| Step: 2
Training loss: 3.491347107265774
Validation loss: 2.930534346062679

Epoch: 6| Step: 3
Training loss: 2.9979431730843347
Validation loss: 2.9277036101109117

Epoch: 6| Step: 4
Training loss: 2.9162752887988117
Validation loss: 2.927334667198846

Epoch: 6| Step: 5
Training loss: 4.131020516212803
Validation loss: 2.929863111476215

Epoch: 6| Step: 6
Training loss: 3.047641442562881
Validation loss: 2.9244577003459447

Epoch: 6| Step: 7
Training loss: 2.9194957817767113
Validation loss: 2.926395178739103

Epoch: 6| Step: 8
Training loss: 3.479067879071913
Validation loss: 2.9245544119436238

Epoch: 6| Step: 9
Training loss: 3.062751603982163
Validation loss: 2.927367741814469

Epoch: 6| Step: 10
Training loss: 3.0727321418489697
Validation loss: 2.9271490598891363

Epoch: 6| Step: 11
Training loss: 2.964491510387765
Validation loss: 2.9330246852700244

Epoch: 6| Step: 12
Training loss: 3.15147870188311
Validation loss: 2.9338565801145604

Epoch: 6| Step: 13
Training loss: 2.9662961757070314
Validation loss: 2.9340570468312

Epoch: 83| Step: 0
Training loss: 3.1650102867694514
Validation loss: 2.9311380485098932

Epoch: 6| Step: 1
Training loss: 3.264321829216554
Validation loss: 2.934239793533566

Epoch: 6| Step: 2
Training loss: 3.619302415602479
Validation loss: 2.93355941288111

Epoch: 6| Step: 3
Training loss: 2.541130843251566
Validation loss: 2.9335494652486527

Epoch: 6| Step: 4
Training loss: 2.7709903720342908
Validation loss: 2.9349133796290046

Epoch: 6| Step: 5
Training loss: 3.93887329373473
Validation loss: 2.930755542185285

Epoch: 6| Step: 6
Training loss: 2.854053819936177
Validation loss: 2.923564426643487

Epoch: 6| Step: 7
Training loss: 3.345277811553864
Validation loss: 2.923355807376326

Epoch: 6| Step: 8
Training loss: 3.4645940955188532
Validation loss: 2.9218948869838366

Epoch: 6| Step: 9
Training loss: 3.03843733528103
Validation loss: 2.925326442846551

Epoch: 6| Step: 10
Training loss: 2.6778497650192534
Validation loss: 2.9235666162337735

Epoch: 6| Step: 11
Training loss: 3.1221430116457602
Validation loss: 2.9263347435865406

Epoch: 6| Step: 12
Training loss: 3.815616522052416
Validation loss: 2.926769525438404

Epoch: 6| Step: 13
Training loss: 2.9730736017184896
Validation loss: 2.9272280888517423

Epoch: 84| Step: 0
Training loss: 3.1348203850357277
Validation loss: 2.932202006540983

Epoch: 6| Step: 1
Training loss: 3.1244231645351728
Validation loss: 2.929512840615792

Epoch: 6| Step: 2
Training loss: 2.74091442150194
Validation loss: 2.929548341789125

Epoch: 6| Step: 3
Training loss: 3.8252777098525956
Validation loss: 2.934497317070245

Epoch: 6| Step: 4
Training loss: 3.0820047935829784
Validation loss: 2.9265993608829812

Epoch: 6| Step: 5
Training loss: 3.294450202652386
Validation loss: 2.926106966501651

Epoch: 6| Step: 6
Training loss: 3.0127723918928164
Validation loss: 2.9260024514731144

Epoch: 6| Step: 7
Training loss: 3.496568769012431
Validation loss: 2.9240644647427496

Epoch: 6| Step: 8
Training loss: 3.1174053221201143
Validation loss: 2.9218484990193265

Epoch: 6| Step: 9
Training loss: 3.1113020709635744
Validation loss: 2.922327080024701

Epoch: 6| Step: 10
Training loss: 3.906859083373608
Validation loss: 2.9181218632121024

Epoch: 6| Step: 11
Training loss: 2.833583558944832
Validation loss: 2.917702100520824

Epoch: 6| Step: 12
Training loss: 2.7379272928720124
Validation loss: 2.9196968841653925

Epoch: 6| Step: 13
Training loss: 3.491855136151859
Validation loss: 2.917503532791842

Epoch: 85| Step: 0
Training loss: 2.8137992401085143
Validation loss: 2.9159893995767243

Epoch: 6| Step: 1
Training loss: 3.2596170015549637
Validation loss: 2.9151865553943477

Epoch: 6| Step: 2
Training loss: 3.4032080830222027
Validation loss: 2.9152453872477

Epoch: 6| Step: 3
Training loss: 3.1437409539215806
Validation loss: 2.9163441217450106

Epoch: 6| Step: 4
Training loss: 3.101813241350341
Validation loss: 2.9142263220663795

Epoch: 6| Step: 5
Training loss: 2.861060974356684
Validation loss: 2.917026056980235

Epoch: 6| Step: 6
Training loss: 3.8178715621102954
Validation loss: 2.9124893868517177

Epoch: 6| Step: 7
Training loss: 2.5752402147263274
Validation loss: 2.914361361460251

Epoch: 6| Step: 8
Training loss: 2.84016611822294
Validation loss: 2.916168366039959

Epoch: 6| Step: 9
Training loss: 3.0125030011047356
Validation loss: 2.914034611855178

Epoch: 6| Step: 10
Training loss: 4.227506013997931
Validation loss: 2.914766399886392

Epoch: 6| Step: 11
Training loss: 2.715610050208553
Validation loss: 2.914573243963933

Epoch: 6| Step: 12
Training loss: 3.869137174247578
Validation loss: 2.915194164029134

Epoch: 6| Step: 13
Training loss: 2.259359707391462
Validation loss: 2.9160797536502963

Epoch: 86| Step: 0
Training loss: 3.225683503576658
Validation loss: 2.9157887052988074

Epoch: 6| Step: 1
Training loss: 2.9971539985057953
Validation loss: 2.913513579685573

Epoch: 6| Step: 2
Training loss: 3.1404579839375266
Validation loss: 2.915751826761404

Epoch: 6| Step: 3
Training loss: 3.2688671608928934
Validation loss: 2.915412406959838

Epoch: 6| Step: 4
Training loss: 3.3493255050085797
Validation loss: 2.9167030909383644

Epoch: 6| Step: 5
Training loss: 3.579577421896074
Validation loss: 2.913964728446362

Epoch: 6| Step: 6
Training loss: 3.043172454871378
Validation loss: 2.9098234988593927

Epoch: 6| Step: 7
Training loss: 2.52895430082314
Validation loss: 2.908749968897343

Epoch: 6| Step: 8
Training loss: 3.5482727523178523
Validation loss: 2.9072902801054537

Epoch: 6| Step: 9
Training loss: 3.7095532214599967
Validation loss: 2.9070682703477844

Epoch: 6| Step: 10
Training loss: 2.515130983737516
Validation loss: 2.906375102088335

Epoch: 6| Step: 11
Training loss: 3.8017445173797837
Validation loss: 2.907565854705209

Epoch: 6| Step: 12
Training loss: 2.7879614272767315
Validation loss: 2.9064903711194425

Epoch: 6| Step: 13
Training loss: 2.807929670110631
Validation loss: 2.9076087546094493

Epoch: 87| Step: 0
Training loss: 2.6658818361576846
Validation loss: 2.905594479133286

Epoch: 6| Step: 1
Training loss: 2.766733066114413
Validation loss: 2.9051778039232024

Epoch: 6| Step: 2
Training loss: 3.1674152459876708
Validation loss: 2.905153197904902

Epoch: 6| Step: 3
Training loss: 3.2275482223773198
Validation loss: 2.9059995450043044

Epoch: 6| Step: 4
Training loss: 3.4207728452983925
Validation loss: 2.9041789377710994

Epoch: 6| Step: 5
Training loss: 2.9033145641445786
Validation loss: 2.904279471513929

Epoch: 6| Step: 6
Training loss: 2.428325504385486
Validation loss: 2.904113912504172

Epoch: 6| Step: 7
Training loss: 3.471980884218111
Validation loss: 2.9045239969972996

Epoch: 6| Step: 8
Training loss: 3.5731247525284293
Validation loss: 2.9041948694544675

Epoch: 6| Step: 9
Training loss: 4.086231578506484
Validation loss: 2.903823543529075

Epoch: 6| Step: 10
Training loss: 2.6828423882198704
Validation loss: 2.90408956583347

Epoch: 6| Step: 11
Training loss: 3.4085983440710073
Validation loss: 2.90370658252894

Epoch: 6| Step: 12
Training loss: 2.7697064299928082
Validation loss: 2.9016374249607684

Epoch: 6| Step: 13
Training loss: 4.082362052983618
Validation loss: 2.9021208848184443

Epoch: 88| Step: 0
Training loss: 3.50590439451422
Validation loss: 2.9018703261116023

Epoch: 6| Step: 1
Training loss: 3.635611425974155
Validation loss: 2.9010853574754614

Epoch: 6| Step: 2
Training loss: 3.0158498413387442
Validation loss: 2.900322995640879

Epoch: 6| Step: 3
Training loss: 3.2719542573002505
Validation loss: 2.8995099560292945

Epoch: 6| Step: 4
Training loss: 3.3940481318408615
Validation loss: 2.8988290516795607

Epoch: 6| Step: 5
Training loss: 2.5515704723077097
Validation loss: 2.901931447441354

Epoch: 6| Step: 6
Training loss: 3.2124052753658345
Validation loss: 2.903705124443058

Epoch: 6| Step: 7
Training loss: 2.659054700342598
Validation loss: 2.9009113285065826

Epoch: 6| Step: 8
Training loss: 3.2205233827383783
Validation loss: 2.901505189768623

Epoch: 6| Step: 9
Training loss: 3.8184191921065906
Validation loss: 2.8988059659644563

Epoch: 6| Step: 10
Training loss: 3.242375012226326
Validation loss: 2.8997420193043326

Epoch: 6| Step: 11
Training loss: 2.897701036195076
Validation loss: 2.8978678604002504

Epoch: 6| Step: 12
Training loss: 2.8712536825672097
Validation loss: 2.8992377897979074

Epoch: 6| Step: 13
Training loss: 3.0590409966446725
Validation loss: 2.8994023893649903

Epoch: 89| Step: 0
Training loss: 2.9850031805740356
Validation loss: 2.9143260359491636

Epoch: 6| Step: 1
Training loss: 3.436356371596209
Validation loss: 2.9251000342289877

Epoch: 6| Step: 2
Training loss: 3.2565899574462764
Validation loss: 2.940027553313995

Epoch: 6| Step: 3
Training loss: 3.6959336385838193
Validation loss: 2.921227820902477

Epoch: 6| Step: 4
Training loss: 3.3903046206104
Validation loss: 2.9047025701763416

Epoch: 6| Step: 5
Training loss: 3.325934177043258
Validation loss: 2.9013777606077684

Epoch: 6| Step: 6
Training loss: 3.2010247020393963
Validation loss: 2.897349812104453

Epoch: 6| Step: 7
Training loss: 3.1242174313106745
Validation loss: 2.8948241575199902

Epoch: 6| Step: 8
Training loss: 3.2559362630112254
Validation loss: 2.896830584407948

Epoch: 6| Step: 9
Training loss: 1.9404194893494595
Validation loss: 2.897435351068007

Epoch: 6| Step: 10
Training loss: 3.3357592497111797
Validation loss: 2.8973323819313435

Epoch: 6| Step: 11
Training loss: 3.463275197422032
Validation loss: 2.9010847070844914

Epoch: 6| Step: 12
Training loss: 2.8417651617109327
Validation loss: 2.89851332461575

Epoch: 6| Step: 13
Training loss: 2.9912716731407363
Validation loss: 2.897275373676141

Epoch: 90| Step: 0
Training loss: 3.878047114227213
Validation loss: 2.898434637787103

Epoch: 6| Step: 1
Training loss: 3.515687255308161
Validation loss: 2.902438842768463

Epoch: 6| Step: 2
Training loss: 3.4480844017018732
Validation loss: 2.895609792947671

Epoch: 6| Step: 3
Training loss: 2.712156258174684
Validation loss: 2.895277730623882

Epoch: 6| Step: 4
Training loss: 3.1600168242187734
Validation loss: 2.893335169765176

Epoch: 6| Step: 5
Training loss: 3.348416218799032
Validation loss: 2.891031316410595

Epoch: 6| Step: 6
Training loss: 3.4069624689406997
Validation loss: 2.8902786681529062

Epoch: 6| Step: 7
Training loss: 2.4196637303040736
Validation loss: 2.892867953135285

Epoch: 6| Step: 8
Training loss: 2.314093375917623
Validation loss: 2.89772545069749

Epoch: 6| Step: 9
Training loss: 3.055321200852843
Validation loss: 2.908611381373119

Epoch: 6| Step: 10
Training loss: 3.306462381677026
Validation loss: 2.915649340945772

Epoch: 6| Step: 11
Training loss: 3.555167029597541
Validation loss: 2.9099902060291445

Epoch: 6| Step: 12
Training loss: 3.005021026080766
Validation loss: 2.8923314922702685

Epoch: 6| Step: 13
Training loss: 3.0305001816050114
Validation loss: 2.886745820364042

Epoch: 91| Step: 0
Training loss: 2.402678576450841
Validation loss: 2.8887077538482915

Epoch: 6| Step: 1
Training loss: 3.7754440501183075
Validation loss: 2.887992764138336

Epoch: 6| Step: 2
Training loss: 3.795988379674718
Validation loss: 2.887257924786715

Epoch: 6| Step: 3
Training loss: 2.610197200413951
Validation loss: 2.8851299822417396

Epoch: 6| Step: 4
Training loss: 3.2687383531176946
Validation loss: 2.8865848198086073

Epoch: 6| Step: 5
Training loss: 3.137334209788414
Validation loss: 2.8868914997135042

Epoch: 6| Step: 6
Training loss: 3.384629252878867
Validation loss: 2.884537732930509

Epoch: 6| Step: 7
Training loss: 3.4991135155775472
Validation loss: 2.88891951410906

Epoch: 6| Step: 8
Training loss: 2.509150353206264
Validation loss: 2.8892809953042047

Epoch: 6| Step: 9
Training loss: 3.46314508371359
Validation loss: 2.901749097360254

Epoch: 6| Step: 10
Training loss: 3.005875079911458
Validation loss: 2.910274772160297

Epoch: 6| Step: 11
Training loss: 3.191194524944024
Validation loss: 2.921104408064385

Epoch: 6| Step: 12
Training loss: 2.7702995493629716
Validation loss: 2.9327970501392704

Epoch: 6| Step: 13
Training loss: 3.4672163588640967
Validation loss: 2.9263567360782816

Epoch: 92| Step: 0
Training loss: 2.9320023406931446
Validation loss: 2.9197954822775087

Epoch: 6| Step: 1
Training loss: 2.3079508807742
Validation loss: 2.9199911917824584

Epoch: 6| Step: 2
Training loss: 3.4904552831688402
Validation loss: 2.916446096163582

Epoch: 6| Step: 3
Training loss: 4.487773391768923
Validation loss: 2.8907365745821845

Epoch: 6| Step: 4
Training loss: 3.220267817572714
Validation loss: 2.8818347614671915

Epoch: 6| Step: 5
Training loss: 3.0481466134020576
Validation loss: 2.882573429944697

Epoch: 6| Step: 6
Training loss: 2.727505059171997
Validation loss: 2.880278928362897

Epoch: 6| Step: 7
Training loss: 3.0783925206460325
Validation loss: 2.8820528139417396

Epoch: 6| Step: 8
Training loss: 3.7810021941898238
Validation loss: 2.8807606233857803

Epoch: 6| Step: 9
Training loss: 2.1597932093144316
Validation loss: 2.884065553311414

Epoch: 6| Step: 10
Training loss: 3.454121579626406
Validation loss: 2.8823204559919047

Epoch: 6| Step: 11
Training loss: 3.176082732845432
Validation loss: 2.883183667036821

Epoch: 6| Step: 12
Training loss: 2.560996102761696
Validation loss: 2.883523905673727

Epoch: 6| Step: 13
Training loss: 3.50734131500993
Validation loss: 2.884031211414476

Epoch: 93| Step: 0
Training loss: 3.691444485582401
Validation loss: 2.87962081077294

Epoch: 6| Step: 1
Training loss: 2.6307939437738503
Validation loss: 2.88235866948267

Epoch: 6| Step: 2
Training loss: 3.0661131117348943
Validation loss: 2.879482299201796

Epoch: 6| Step: 3
Training loss: 2.662912607235163
Validation loss: 2.8783596662730035

Epoch: 6| Step: 4
Training loss: 3.2628164671366013
Validation loss: 2.8806356414853322

Epoch: 6| Step: 5
Training loss: 2.904397845998264
Validation loss: 2.878370078072883

Epoch: 6| Step: 6
Training loss: 3.038565077684406
Validation loss: 2.8787893101036617

Epoch: 6| Step: 7
Training loss: 2.9707854671465395
Validation loss: 2.8792658808980036

Epoch: 6| Step: 8
Training loss: 3.2219530482787144
Validation loss: 2.878856499608658

Epoch: 6| Step: 9
Training loss: 3.619635591870006
Validation loss: 2.887669407826018

Epoch: 6| Step: 10
Training loss: 3.0942696799559863
Validation loss: 2.8865723674175894

Epoch: 6| Step: 11
Training loss: 3.713005822655643
Validation loss: 2.8911481007616073

Epoch: 6| Step: 12
Training loss: 3.4839723636656665
Validation loss: 2.882719585162902

Epoch: 6| Step: 13
Training loss: 2.49068240454941
Validation loss: 2.8783369659248517

Epoch: 94| Step: 0
Training loss: 3.2999428310644197
Validation loss: 2.8756729272946884

Epoch: 6| Step: 1
Training loss: 2.7681109791045517
Validation loss: 2.87584024485763

Epoch: 6| Step: 2
Training loss: 3.692775637825282
Validation loss: 2.8742112089291973

Epoch: 6| Step: 3
Training loss: 3.2430415855468055
Validation loss: 2.8735285591974464

Epoch: 6| Step: 4
Training loss: 3.192899730394691
Validation loss: 2.8717085762011294

Epoch: 6| Step: 5
Training loss: 2.5708573062547706
Validation loss: 2.8724929236384296

Epoch: 6| Step: 6
Training loss: 3.7390430594997777
Validation loss: 2.8696839752874044

Epoch: 6| Step: 7
Training loss: 2.6643683741766995
Validation loss: 2.8796958880619234

Epoch: 6| Step: 8
Training loss: 2.6743429286074143
Validation loss: 2.8853387575939955

Epoch: 6| Step: 9
Training loss: 3.068424333434776
Validation loss: 2.900746478723672

Epoch: 6| Step: 10
Training loss: 3.224336978860471
Validation loss: 2.8830360716966896

Epoch: 6| Step: 11
Training loss: 2.5553992910109025
Validation loss: 2.871183515056082

Epoch: 6| Step: 12
Training loss: 3.631540777280798
Validation loss: 2.8709452491557563

Epoch: 6| Step: 13
Training loss: 3.9762256532107765
Validation loss: 2.8684531095914716

Epoch: 95| Step: 0
Training loss: 3.4820154523073876
Validation loss: 2.8757477626526797

Epoch: 6| Step: 1
Training loss: 2.4446463850685163
Validation loss: 2.874955967462952

Epoch: 6| Step: 2
Training loss: 3.668641310061485
Validation loss: 2.877260499179723

Epoch: 6| Step: 3
Training loss: 3.1638641672021666
Validation loss: 2.8779113727303898

Epoch: 6| Step: 4
Training loss: 2.573240149133443
Validation loss: 2.8723498029758696

Epoch: 6| Step: 5
Training loss: 3.998687886563285
Validation loss: 2.8696466605855697

Epoch: 6| Step: 6
Training loss: 2.7106183218703315
Validation loss: 2.872354321820446

Epoch: 6| Step: 7
Training loss: 3.7396902141687107
Validation loss: 2.870235009481866

Epoch: 6| Step: 8
Training loss: 2.82788927982173
Validation loss: 2.8682508660269623

Epoch: 6| Step: 9
Training loss: 3.67646612907588
Validation loss: 2.8695377198561376

Epoch: 6| Step: 10
Training loss: 2.605535915258257
Validation loss: 2.8748488330735547

Epoch: 6| Step: 11
Training loss: 2.6295714762450633
Validation loss: 2.8761750682692813

Epoch: 6| Step: 12
Training loss: 2.7442029192495627
Validation loss: 2.8915352755830135

Epoch: 6| Step: 13
Training loss: 3.8888748093002
Validation loss: 2.8961330069014375

Epoch: 96| Step: 0
Training loss: 3.0527521817498897
Validation loss: 2.8953469069220628

Epoch: 6| Step: 1
Training loss: 3.05139404081908
Validation loss: 2.886525094735637

Epoch: 6| Step: 2
Training loss: 2.9302873734817414
Validation loss: 2.881087386290438

Epoch: 6| Step: 3
Training loss: 3.3488891183079192
Validation loss: 2.876758658171488

Epoch: 6| Step: 4
Training loss: 3.3311035009524423
Validation loss: 2.8690782823903276

Epoch: 6| Step: 5
Training loss: 2.826381504216858
Validation loss: 2.869489402672793

Epoch: 6| Step: 6
Training loss: 2.9573727691447202
Validation loss: 2.8645045336552664

Epoch: 6| Step: 7
Training loss: 3.2501445151256982
Validation loss: 2.86188468175116

Epoch: 6| Step: 8
Training loss: 2.820084327492045
Validation loss: 2.863112923612867

Epoch: 6| Step: 9
Training loss: 3.5778100820495395
Validation loss: 2.8613829976529632

Epoch: 6| Step: 10
Training loss: 3.7442448004058457
Validation loss: 2.864826385538398

Epoch: 6| Step: 11
Training loss: 3.54874401171301
Validation loss: 2.8617229570741047

Epoch: 6| Step: 12
Training loss: 2.376692319555886
Validation loss: 2.8645483545459185

Epoch: 6| Step: 13
Training loss: 3.2636850243788067
Validation loss: 2.8635859717399503

Epoch: 97| Step: 0
Training loss: 3.284800035031296
Validation loss: 2.86461886535862

Epoch: 6| Step: 1
Training loss: 3.040685695814749
Validation loss: 2.8668462704425615

Epoch: 6| Step: 2
Training loss: 3.4805060148117293
Validation loss: 2.8658613672358255

Epoch: 6| Step: 3
Training loss: 2.842143684540206
Validation loss: 2.8659241868321175

Epoch: 6| Step: 4
Training loss: 2.8723596805200673
Validation loss: 2.8663291445444092

Epoch: 6| Step: 5
Training loss: 2.9595853994595824
Validation loss: 2.8637596961407503

Epoch: 6| Step: 6
Training loss: 3.185074425610756
Validation loss: 2.865046239835287

Epoch: 6| Step: 7
Training loss: 3.3015453650503352
Validation loss: 2.8653944055686877

Epoch: 6| Step: 8
Training loss: 3.2492771812077503
Validation loss: 2.8621591647638693

Epoch: 6| Step: 9
Training loss: 2.942098872895516
Validation loss: 2.8612914010829584

Epoch: 6| Step: 10
Training loss: 3.316190283475274
Validation loss: 2.861424102399868

Epoch: 6| Step: 11
Training loss: 3.7999628015002522
Validation loss: 2.8571457309459407

Epoch: 6| Step: 12
Training loss: 3.01950408804892
Validation loss: 2.855942962846176

Epoch: 6| Step: 13
Training loss: 2.638415795019744
Validation loss: 2.857207123521454

Epoch: 98| Step: 0
Training loss: 3.4078897151743357
Validation loss: 2.8597809209643317

Epoch: 6| Step: 1
Training loss: 3.0629608430367767
Validation loss: 2.8591202630779797

Epoch: 6| Step: 2
Training loss: 3.020741761672197
Validation loss: 2.860431465439447

Epoch: 6| Step: 3
Training loss: 2.7284810221723172
Validation loss: 2.859425286587661

Epoch: 6| Step: 4
Training loss: 3.372354388872188
Validation loss: 2.8635261232949962

Epoch: 6| Step: 5
Training loss: 4.167515680916341
Validation loss: 2.8761052169226566

Epoch: 6| Step: 6
Training loss: 3.0293171806318964
Validation loss: 2.8684880920039557

Epoch: 6| Step: 7
Training loss: 2.8315513467311173
Validation loss: 2.8602128321366616

Epoch: 6| Step: 8
Training loss: 3.137124459334065
Validation loss: 2.8558557026349916

Epoch: 6| Step: 9
Training loss: 3.4820477706726103
Validation loss: 2.8546279143506146

Epoch: 6| Step: 10
Training loss: 3.0500812582229173
Validation loss: 2.8543305199924953

Epoch: 6| Step: 11
Training loss: 2.626927440191581
Validation loss: 2.8562355686840193

Epoch: 6| Step: 12
Training loss: 2.947264492472032
Validation loss: 2.8581375904471082

Epoch: 6| Step: 13
Training loss: 2.9593783578984545
Validation loss: 2.8617047087925527

Epoch: 99| Step: 0
Training loss: 3.3195805719005893
Validation loss: 2.860227580898509

Epoch: 6| Step: 1
Training loss: 3.4216495248024827
Validation loss: 2.8640600078079097

Epoch: 6| Step: 2
Training loss: 3.3080982256032327
Validation loss: 2.8621336783561535

Epoch: 6| Step: 3
Training loss: 2.8692459907686536
Validation loss: 2.861344655447062

Epoch: 6| Step: 4
Training loss: 2.46039800634153
Validation loss: 2.860432835794109

Epoch: 6| Step: 5
Training loss: 3.1794222034499486
Validation loss: 2.8580486454202783

Epoch: 6| Step: 6
Training loss: 3.027007289770578
Validation loss: 2.8551425030626416

Epoch: 6| Step: 7
Training loss: 3.073676132921745
Validation loss: 2.8544996112463425

Epoch: 6| Step: 8
Training loss: 3.1128761094901716
Validation loss: 2.8548529407442453

Epoch: 6| Step: 9
Training loss: 3.77527316286168
Validation loss: 2.85269073044815

Epoch: 6| Step: 10
Training loss: 2.3160286864248407
Validation loss: 2.8542918162928084

Epoch: 6| Step: 11
Training loss: 3.6144500326738904
Validation loss: 2.8525263868916855

Epoch: 6| Step: 12
Training loss: 3.012727600617092
Validation loss: 2.847162145292112

Epoch: 6| Step: 13
Training loss: 3.7022142537756206
Validation loss: 2.847238619604014

Epoch: 100| Step: 0
Training loss: 3.936233316763505
Validation loss: 2.8493057614738957

Epoch: 6| Step: 1
Training loss: 3.489471130085503
Validation loss: 2.850103385559864

Epoch: 6| Step: 2
Training loss: 2.549181122287327
Validation loss: 2.8486349948894367

Epoch: 6| Step: 3
Training loss: 3.779763173752848
Validation loss: 2.849703917265206

Epoch: 6| Step: 4
Training loss: 3.364303734719236
Validation loss: 2.8500749273404984

Epoch: 6| Step: 5
Training loss: 3.73593566715797
Validation loss: 2.8525971355502597

Epoch: 6| Step: 6
Training loss: 3.0858358245710438
Validation loss: 2.850504319597297

Epoch: 6| Step: 7
Training loss: 2.7551311825849516
Validation loss: 2.8485954569332343

Epoch: 6| Step: 8
Training loss: 2.3931008277881753
Validation loss: 2.8486371979761294

Epoch: 6| Step: 9
Training loss: 2.3524527147914345
Validation loss: 2.8483725732966296

Epoch: 6| Step: 10
Training loss: 2.942043118978412
Validation loss: 2.8472268045906937

Epoch: 6| Step: 11
Training loss: 2.966146190577422
Validation loss: 2.8447128382363287

Epoch: 6| Step: 12
Training loss: 3.257213656413689
Validation loss: 2.847165879329796

Epoch: 6| Step: 13
Training loss: 2.8847163666876074
Validation loss: 2.869817222039386

Epoch: 101| Step: 0
Training loss: 3.002512833109674
Validation loss: 2.8984520586782128

Epoch: 6| Step: 1
Training loss: 3.1434362175272637
Validation loss: 2.9348111244380277

Epoch: 6| Step: 2
Training loss: 3.3413051330379018
Validation loss: 2.937399274032502

Epoch: 6| Step: 3
Training loss: 3.021119799130488
Validation loss: 2.9200155375608516

Epoch: 6| Step: 4
Training loss: 3.055412030943291
Validation loss: 2.8744416026762063

Epoch: 6| Step: 5
Training loss: 2.8990412080802614
Validation loss: 2.845620275149156

Epoch: 6| Step: 6
Training loss: 3.359225247616062
Validation loss: 2.8475623176706932

Epoch: 6| Step: 7
Training loss: 3.310472263631938
Validation loss: 2.852082768929346

Epoch: 6| Step: 8
Training loss: 3.1101588502406865
Validation loss: 2.856076970050272

Epoch: 6| Step: 9
Training loss: 2.7615466030483904
Validation loss: 2.865376806956065

Epoch: 6| Step: 10
Training loss: 3.12569587589022
Validation loss: 2.878409593583485

Epoch: 6| Step: 11
Training loss: 2.9343589059146638
Validation loss: 2.885839029255776

Epoch: 6| Step: 12
Training loss: 3.7681350889591285
Validation loss: 2.8770207138169286

Epoch: 6| Step: 13
Training loss: 3.4564818209668506
Validation loss: 2.8635091882409505

Epoch: 102| Step: 0
Training loss: 2.793321109766227
Validation loss: 2.857798715179388

Epoch: 6| Step: 1
Training loss: 3.1729019081204966
Validation loss: 2.8492467890605737

Epoch: 6| Step: 2
Training loss: 3.4136920789109175
Validation loss: 2.845535819223594

Epoch: 6| Step: 3
Training loss: 3.0441663390739953
Validation loss: 2.844397583701209

Epoch: 6| Step: 4
Training loss: 2.9155511811980848
Validation loss: 2.8420791233781806

Epoch: 6| Step: 5
Training loss: 3.5693200399355267
Validation loss: 2.839495686278259

Epoch: 6| Step: 6
Training loss: 3.2311376319693528
Validation loss: 2.8407681533890963

Epoch: 6| Step: 7
Training loss: 3.1369572568978374
Validation loss: 2.8405725793297414

Epoch: 6| Step: 8
Training loss: 2.601859594112093
Validation loss: 2.8417661702917125

Epoch: 6| Step: 9
Training loss: 2.876675324970298
Validation loss: 2.8417764897304796

Epoch: 6| Step: 10
Training loss: 2.936195895694057
Validation loss: 2.842056957708521

Epoch: 6| Step: 11
Training loss: 3.1628005537069988
Validation loss: 2.8635291708062476

Epoch: 6| Step: 12
Training loss: 3.857405063254504
Validation loss: 2.898863823173906

Epoch: 6| Step: 13
Training loss: 3.2247766166030396
Validation loss: 2.8870572009926048

Epoch: 103| Step: 0
Training loss: 2.599001428607403
Validation loss: 2.8476097402135427

Epoch: 6| Step: 1
Training loss: 3.259437942262882
Validation loss: 2.841483309798417

Epoch: 6| Step: 2
Training loss: 2.9678344921121864
Validation loss: 2.840709047957945

Epoch: 6| Step: 3
Training loss: 3.0972609201550214
Validation loss: 2.836543844470094

Epoch: 6| Step: 4
Training loss: 2.7394050762554203
Validation loss: 2.838322427770219

Epoch: 6| Step: 5
Training loss: 3.228796972626476
Validation loss: 2.8393457224302314

Epoch: 6| Step: 6
Training loss: 2.947783468267888
Validation loss: 2.8379573491931502

Epoch: 6| Step: 7
Training loss: 3.2055369158606353
Validation loss: 2.8383973275265935

Epoch: 6| Step: 8
Training loss: 3.2549433160349484
Validation loss: 2.8396633930638995

Epoch: 6| Step: 9
Training loss: 3.2972530491741283
Validation loss: 2.8390468094126837

Epoch: 6| Step: 10
Training loss: 2.949319314821026
Validation loss: 2.83846456816818

Epoch: 6| Step: 11
Training loss: 3.9127046281727194
Validation loss: 2.838915194165512

Epoch: 6| Step: 12
Training loss: 3.4485606411379037
Validation loss: 2.835268627931189

Epoch: 6| Step: 13
Training loss: 2.760371072260664
Validation loss: 2.835593793694687

Epoch: 104| Step: 0
Training loss: 3.3253808685378283
Validation loss: 2.8342150873013985

Epoch: 6| Step: 1
Training loss: 2.806685052465654
Validation loss: 2.834314560650841

Epoch: 6| Step: 2
Training loss: 3.3893632782584455
Validation loss: 2.83151448107475

Epoch: 6| Step: 3
Training loss: 3.0983156365895885
Validation loss: 2.8342051573224336

Epoch: 6| Step: 4
Training loss: 3.446228320828762
Validation loss: 2.830030699465971

Epoch: 6| Step: 5
Training loss: 3.7025648248678418
Validation loss: 2.8316054392732086

Epoch: 6| Step: 6
Training loss: 2.750240835567949
Validation loss: 2.831214545667061

Epoch: 6| Step: 7
Training loss: 3.051214795438904
Validation loss: 2.8355055031135645

Epoch: 6| Step: 8
Training loss: 3.423593028865277
Validation loss: 2.8388409989126373

Epoch: 6| Step: 9
Training loss: 2.957518523570181
Validation loss: 2.8466123293047323

Epoch: 6| Step: 10
Training loss: 2.8807008033689083
Validation loss: 2.865099663314106

Epoch: 6| Step: 11
Training loss: 3.2793055994895854
Validation loss: 2.86879959022476

Epoch: 6| Step: 12
Training loss: 2.8017205401733936
Validation loss: 2.8514048030557624

Epoch: 6| Step: 13
Training loss: 2.630734311128182
Validation loss: 2.834474131860851

Epoch: 105| Step: 0
Training loss: 3.1368294170234865
Validation loss: 2.8269430113199183

Epoch: 6| Step: 1
Training loss: 3.0073468529068883
Validation loss: 2.827088041668352

Epoch: 6| Step: 2
Training loss: 2.909117237968942
Validation loss: 2.8260751720979402

Epoch: 6| Step: 3
Training loss: 2.8623471681532897
Validation loss: 2.82821838228362

Epoch: 6| Step: 4
Training loss: 3.625886742886657
Validation loss: 2.828559102030649

Epoch: 6| Step: 5
Training loss: 2.690486401965748
Validation loss: 2.827329084093463

Epoch: 6| Step: 6
Training loss: 3.422492402697338
Validation loss: 2.82852966571668

Epoch: 6| Step: 7
Training loss: 2.9742999751886536
Validation loss: 2.8260458604976626

Epoch: 6| Step: 8
Training loss: 3.0037871933696896
Validation loss: 2.8260626263493216

Epoch: 6| Step: 9
Training loss: 2.8840481557436655
Validation loss: 2.825786562240575

Epoch: 6| Step: 10
Training loss: 3.5611875023651804
Validation loss: 2.8237009444209566

Epoch: 6| Step: 11
Training loss: 2.718707117202888
Validation loss: 2.824242361889642

Epoch: 6| Step: 12
Training loss: 3.52305922412495
Validation loss: 2.8268546790864377

Epoch: 6| Step: 13
Training loss: 3.49914785638235
Validation loss: 2.8302206087933004

Epoch: 106| Step: 0
Training loss: 3.5818193179534954
Validation loss: 2.835143978958697

Epoch: 6| Step: 1
Training loss: 3.617124091430934
Validation loss: 2.8331946918750015

Epoch: 6| Step: 2
Training loss: 2.854421859433417
Validation loss: 2.82700515319651

Epoch: 6| Step: 3
Training loss: 2.621687388385704
Validation loss: 2.823698381415546

Epoch: 6| Step: 4
Training loss: 3.0610640915869003
Validation loss: 2.826314604701502

Epoch: 6| Step: 5
Training loss: 3.399541004838609
Validation loss: 2.8262728777589716

Epoch: 6| Step: 6
Training loss: 3.237652725682472
Validation loss: 2.827392853199797

Epoch: 6| Step: 7
Training loss: 3.2915441433923367
Validation loss: 2.8293293965237765

Epoch: 6| Step: 8
Training loss: 3.3688119744596454
Validation loss: 2.8288323127463433

Epoch: 6| Step: 9
Training loss: 2.0475954142080033
Validation loss: 2.8317064618838876

Epoch: 6| Step: 10
Training loss: 3.311085812971971
Validation loss: 2.8320037290532234

Epoch: 6| Step: 11
Training loss: 3.0826976911354187
Validation loss: 2.8272301166771796

Epoch: 6| Step: 12
Training loss: 2.7741054536485534
Validation loss: 2.824033784880603

Epoch: 6| Step: 13
Training loss: 3.4931385358219527
Validation loss: 2.822179883348592

Epoch: 107| Step: 0
Training loss: 3.3727419328265804
Validation loss: 2.8255738076989028

Epoch: 6| Step: 1
Training loss: 3.359251649942892
Validation loss: 2.8253634725096304

Epoch: 6| Step: 2
Training loss: 3.123284135863236
Validation loss: 2.82606568885969

Epoch: 6| Step: 3
Training loss: 3.2532388247640456
Validation loss: 2.818406201932259

Epoch: 6| Step: 4
Training loss: 3.036131870175151
Validation loss: 2.822953358842248

Epoch: 6| Step: 5
Training loss: 3.003255349465276
Validation loss: 2.8229887897541355

Epoch: 6| Step: 6
Training loss: 2.0688550893592867
Validation loss: 2.8228241873121376

Epoch: 6| Step: 7
Training loss: 3.472991686862933
Validation loss: 2.8201492540022057

Epoch: 6| Step: 8
Training loss: 3.414455504678984
Validation loss: 2.824102656548188

Epoch: 6| Step: 9
Training loss: 2.635817626687633
Validation loss: 2.823867696379682

Epoch: 6| Step: 10
Training loss: 3.290724237146566
Validation loss: 2.8246182846558767

Epoch: 6| Step: 11
Training loss: 3.181687084816556
Validation loss: 2.8228639082278444

Epoch: 6| Step: 12
Training loss: 3.245162003856574
Validation loss: 2.8156262213147194

Epoch: 6| Step: 13
Training loss: 2.891860780237844
Validation loss: 2.8178034158239273

Epoch: 108| Step: 0
Training loss: 3.2818316716109273
Validation loss: 2.817115283803704

Epoch: 6| Step: 1
Training loss: 2.99225267782513
Validation loss: 2.8179456305228308

Epoch: 6| Step: 2
Training loss: 2.4844412165040572
Validation loss: 2.815941414903254

Epoch: 6| Step: 3
Training loss: 2.9694890758687937
Validation loss: 2.8170650618984503

Epoch: 6| Step: 4
Training loss: 3.488890318117706
Validation loss: 2.8191950141953694

Epoch: 6| Step: 5
Training loss: 3.23378700403276
Validation loss: 2.8186716217108216

Epoch: 6| Step: 6
Training loss: 2.918013361700892
Validation loss: 2.8159794421667974

Epoch: 6| Step: 7
Training loss: 3.3763943370372553
Validation loss: 2.815356604350777

Epoch: 6| Step: 8
Training loss: 3.2450553252172303
Validation loss: 2.8144420176572207

Epoch: 6| Step: 9
Training loss: 2.723040297799491
Validation loss: 2.8191644625305505

Epoch: 6| Step: 10
Training loss: 2.938110450460296
Validation loss: 2.814827331395084

Epoch: 6| Step: 11
Training loss: 3.499804082564195
Validation loss: 2.8137497999723364

Epoch: 6| Step: 12
Training loss: 3.1159806365169276
Validation loss: 2.8142786415615224

Epoch: 6| Step: 13
Training loss: 3.4745425410326756
Validation loss: 2.817851558447451

Epoch: 109| Step: 0
Training loss: 3.4874388221105566
Validation loss: 2.8116748323978524

Epoch: 6| Step: 1
Training loss: 2.6870342117136197
Validation loss: 2.8125123856612455

Epoch: 6| Step: 2
Training loss: 3.072870407187338
Validation loss: 2.8166575813280423

Epoch: 6| Step: 3
Training loss: 2.481590197708476
Validation loss: 2.8138122669259347

Epoch: 6| Step: 4
Training loss: 3.1901371836089023
Validation loss: 2.809518230216875

Epoch: 6| Step: 5
Training loss: 2.3381597352882864
Validation loss: 2.8102281316106685

Epoch: 6| Step: 6
Training loss: 3.2411690088900724
Validation loss: 2.8125847743302974

Epoch: 6| Step: 7
Training loss: 2.6821827295397145
Validation loss: 2.8107529185081814

Epoch: 6| Step: 8
Training loss: 3.515199084443367
Validation loss: 2.8091101577789286

Epoch: 6| Step: 9
Training loss: 3.9534443963732238
Validation loss: 2.8119332967450203

Epoch: 6| Step: 10
Training loss: 2.850624076376416
Validation loss: 2.8055188905168036

Epoch: 6| Step: 11
Training loss: 3.134366304151618
Validation loss: 2.8063651387347224

Epoch: 6| Step: 12
Training loss: 3.473454764422344
Validation loss: 2.8122421565753695

Epoch: 6| Step: 13
Training loss: 3.106199857433724
Validation loss: 2.8117895799191674

Epoch: 110| Step: 0
Training loss: 2.588215449838501
Validation loss: 2.812771263394708

Epoch: 6| Step: 1
Training loss: 2.8071509463416597
Validation loss: 2.8189484089706367

Epoch: 6| Step: 2
Training loss: 3.413119746792489
Validation loss: 2.839456578128517

Epoch: 6| Step: 3
Training loss: 3.205589276920031
Validation loss: 2.8060749255775534

Epoch: 6| Step: 4
Training loss: 3.727761513576158
Validation loss: 2.8063111607784723

Epoch: 6| Step: 5
Training loss: 2.7062633135250067
Validation loss: 2.8083278131843046

Epoch: 6| Step: 6
Training loss: 3.1453769849675375
Validation loss: 2.8074224435002195

Epoch: 6| Step: 7
Training loss: 3.0645996992312585
Validation loss: 2.8106834871379713

Epoch: 6| Step: 8
Training loss: 3.2982709921223248
Validation loss: 2.8095871930916934

Epoch: 6| Step: 9
Training loss: 3.222653142754184
Validation loss: 2.8079997292277663

Epoch: 6| Step: 10
Training loss: 3.58505577267474
Validation loss: 2.808554387721344

Epoch: 6| Step: 11
Training loss: 2.613132717775354
Validation loss: 2.8120203126407586

Epoch: 6| Step: 12
Training loss: 3.2415306069292606
Validation loss: 2.812076020728027

Epoch: 6| Step: 13
Training loss: 2.609253200954847
Validation loss: 2.8161121967168445

Epoch: 111| Step: 0
Training loss: 3.462041192350157
Validation loss: 2.823227771286321

Epoch: 6| Step: 1
Training loss: 2.109959274188227
Validation loss: 2.822576133501751

Epoch: 6| Step: 2
Training loss: 3.2306821814886226
Validation loss: 2.8102434884452463

Epoch: 6| Step: 3
Training loss: 3.267897112063686
Validation loss: 2.8111225232379295

Epoch: 6| Step: 4
Training loss: 3.065108609041005
Validation loss: 2.8070230185190073

Epoch: 6| Step: 5
Training loss: 3.8820902039367224
Validation loss: 2.80922658608273

Epoch: 6| Step: 6
Training loss: 2.7382824689614798
Validation loss: 2.8077843112222074

Epoch: 6| Step: 7
Training loss: 2.576833135434566
Validation loss: 2.8066531333405123

Epoch: 6| Step: 8
Training loss: 3.226370226139679
Validation loss: 2.807466903338179

Epoch: 6| Step: 9
Training loss: 3.16695243817562
Validation loss: 2.8045247604554833

Epoch: 6| Step: 10
Training loss: 3.1827815418114245
Validation loss: 2.799203790092462

Epoch: 6| Step: 11
Training loss: 3.126298253275368
Validation loss: 2.8020299584750106

Epoch: 6| Step: 12
Training loss: 3.2495606932471164
Validation loss: 2.799758913791728

Epoch: 6| Step: 13
Training loss: 2.9601091418893617
Validation loss: 2.79925703139912

Epoch: 112| Step: 0
Training loss: 2.524754797483223
Validation loss: 2.803475877728632

Epoch: 6| Step: 1
Training loss: 3.2983276638029184
Validation loss: 2.820890944810144

Epoch: 6| Step: 2
Training loss: 3.9867785814666963
Validation loss: 2.825019673954043

Epoch: 6| Step: 3
Training loss: 3.1075407972903157
Validation loss: 2.8261084802006646

Epoch: 6| Step: 4
Training loss: 2.6060206616534805
Validation loss: 2.8360205350904426

Epoch: 6| Step: 5
Training loss: 2.3820141064460776
Validation loss: 2.8510349758373805

Epoch: 6| Step: 6
Training loss: 2.6578846109285834
Validation loss: 2.8631782273138286

Epoch: 6| Step: 7
Training loss: 3.4934672287282504
Validation loss: 2.885881617420807

Epoch: 6| Step: 8
Training loss: 3.75558335772374
Validation loss: 2.8766460744532147

Epoch: 6| Step: 9
Training loss: 3.4994975138041022
Validation loss: 2.8264622704256865

Epoch: 6| Step: 10
Training loss: 2.727322710186095
Validation loss: 2.7937839641526674

Epoch: 6| Step: 11
Training loss: 2.7617657130023945
Validation loss: 2.798297520554642

Epoch: 6| Step: 12
Training loss: 3.158390641174828
Validation loss: 2.802614896209307

Epoch: 6| Step: 13
Training loss: 3.3413496582147983
Validation loss: 2.8045119373085607

Epoch: 113| Step: 0
Training loss: 2.6395608236130372
Validation loss: 2.8046495353530254

Epoch: 6| Step: 1
Training loss: 3.26457467596338
Validation loss: 2.8108805288261562

Epoch: 6| Step: 2
Training loss: 2.9613402402242777
Validation loss: 2.813179468186136

Epoch: 6| Step: 3
Training loss: 2.39698414460796
Validation loss: 2.8115449293282464

Epoch: 6| Step: 4
Training loss: 2.9198461006054246
Validation loss: 2.8141610904223087

Epoch: 6| Step: 5
Training loss: 3.6051661404698985
Validation loss: 2.8126087910565913

Epoch: 6| Step: 6
Training loss: 2.5245635646917646
Validation loss: 2.8108270945232805

Epoch: 6| Step: 7
Training loss: 2.874502387727445
Validation loss: 2.805463027551904

Epoch: 6| Step: 8
Training loss: 3.7875635072526728
Validation loss: 2.8055752439758055

Epoch: 6| Step: 9
Training loss: 3.4655613720541902
Validation loss: 2.803212581275131

Epoch: 6| Step: 10
Training loss: 3.247994464352781
Validation loss: 2.8040151899423496

Epoch: 6| Step: 11
Training loss: 3.069084407198789
Validation loss: 2.799624220840661

Epoch: 6| Step: 12
Training loss: 3.1755524162251456
Validation loss: 2.794880305861701

Epoch: 6| Step: 13
Training loss: 3.671972135517054
Validation loss: 2.7983185047309695

Epoch: 114| Step: 0
Training loss: 2.908458895737287
Validation loss: 2.7932388318499086

Epoch: 6| Step: 1
Training loss: 2.771742611791013
Validation loss: 2.8020521031749843

Epoch: 6| Step: 2
Training loss: 3.1938580698141843
Validation loss: 2.812611465341786

Epoch: 6| Step: 3
Training loss: 3.098960726867948
Validation loss: 2.8102957889942357

Epoch: 6| Step: 4
Training loss: 2.8150162355215644
Validation loss: 2.8068787196490033

Epoch: 6| Step: 5
Training loss: 2.8531498083767923
Validation loss: 2.8163806554058497

Epoch: 6| Step: 6
Training loss: 2.6040822333317553
Validation loss: 2.8400845637478347

Epoch: 6| Step: 7
Training loss: 3.2580105289127514
Validation loss: 2.831053132682921

Epoch: 6| Step: 8
Training loss: 3.362805978686991
Validation loss: 2.8043647146422024

Epoch: 6| Step: 9
Training loss: 2.906995616141873
Validation loss: 2.787070958427612

Epoch: 6| Step: 10
Training loss: 3.22555991938114
Validation loss: 2.7924758817023556

Epoch: 6| Step: 11
Training loss: 3.0496964913364772
Validation loss: 2.797732448807325

Epoch: 6| Step: 12
Training loss: 3.865819330658126
Validation loss: 2.8009423325602194

Epoch: 6| Step: 13
Training loss: 3.5198844368344586
Validation loss: 2.8085965796302967

Epoch: 115| Step: 0
Training loss: 2.761565510384599
Validation loss: 2.821079515606676

Epoch: 6| Step: 1
Training loss: 3.1799718181392986
Validation loss: 2.818752422385838

Epoch: 6| Step: 2
Training loss: 2.6635334462822335
Validation loss: 2.815422412050986

Epoch: 6| Step: 3
Training loss: 2.741092561096271
Validation loss: 2.8051868900982404

Epoch: 6| Step: 4
Training loss: 3.701892502817578
Validation loss: 2.802130234031483

Epoch: 6| Step: 5
Training loss: 3.3218651585688828
Validation loss: 2.7977028924909155

Epoch: 6| Step: 6
Training loss: 3.3909554737962213
Validation loss: 2.7964089333496114

Epoch: 6| Step: 7
Training loss: 2.9758181304529057
Validation loss: 2.793751568199757

Epoch: 6| Step: 8
Training loss: 3.4825145732632223
Validation loss: 2.7939179788710584

Epoch: 6| Step: 9
Training loss: 3.4849546489200254
Validation loss: 2.791803900869317

Epoch: 6| Step: 10
Training loss: 2.5505872012952495
Validation loss: 2.7897833178823004

Epoch: 6| Step: 11
Training loss: 2.4732267134513064
Validation loss: 2.7916882685078237

Epoch: 6| Step: 12
Training loss: 3.6275420647988033
Validation loss: 2.787558319836973

Epoch: 6| Step: 13
Training loss: 2.9119200820855515
Validation loss: 2.800385889001024

Epoch: 116| Step: 0
Training loss: 3.2590174653532524
Validation loss: 2.826111436527543

Epoch: 6| Step: 1
Training loss: 2.7496407014038047
Validation loss: 2.841838484059414

Epoch: 6| Step: 2
Training loss: 3.0334455266751807
Validation loss: 2.8866937202111034

Epoch: 6| Step: 3
Training loss: 3.3366098195459752
Validation loss: 2.8688065980496975

Epoch: 6| Step: 4
Training loss: 3.0679266980900173
Validation loss: 2.8335598095662453

Epoch: 6| Step: 5
Training loss: 3.0976423958351917
Validation loss: 2.8157293331624875

Epoch: 6| Step: 6
Training loss: 3.2091925490240416
Validation loss: 2.802553681696686

Epoch: 6| Step: 7
Training loss: 2.8124743990262777
Validation loss: 2.8109238212945904

Epoch: 6| Step: 8
Training loss: 3.2701921421727675
Validation loss: 2.8112826156644712

Epoch: 6| Step: 9
Training loss: 3.139218143385039
Validation loss: 2.786849776657557

Epoch: 6| Step: 10
Training loss: 2.911766968520538
Validation loss: 2.7853528545219453

Epoch: 6| Step: 11
Training loss: 2.8042873426509964
Validation loss: 2.7841302112527613

Epoch: 6| Step: 12
Training loss: 3.7845202719717124
Validation loss: 2.7827870277941957

Epoch: 6| Step: 13
Training loss: 2.9070586033318224
Validation loss: 2.787736013287397

Epoch: 117| Step: 0
Training loss: 2.020897762674153
Validation loss: 2.78511354098722

Epoch: 6| Step: 1
Training loss: 3.5856611689724334
Validation loss: 2.788094054820302

Epoch: 6| Step: 2
Training loss: 2.8725736579714
Validation loss: 2.7855670492934084

Epoch: 6| Step: 3
Training loss: 3.583299784540254
Validation loss: 2.7844058382428045

Epoch: 6| Step: 4
Training loss: 3.238639636851821
Validation loss: 2.785035729905448

Epoch: 6| Step: 5
Training loss: 2.702084291370215
Validation loss: 2.782784538577441

Epoch: 6| Step: 6
Training loss: 2.9599063255333973
Validation loss: 2.78034199899837

Epoch: 6| Step: 7
Training loss: 3.0195656758427263
Validation loss: 2.7797601776157332

Epoch: 6| Step: 8
Training loss: 2.5041233391168585
Validation loss: 2.7824894382205705

Epoch: 6| Step: 9
Training loss: 2.952896351515401
Validation loss: 2.780872958653289

Epoch: 6| Step: 10
Training loss: 3.5882271166039685
Validation loss: 2.7806012829367672

Epoch: 6| Step: 11
Training loss: 3.413378055498081
Validation loss: 2.780361404593993

Epoch: 6| Step: 12
Training loss: 3.4505981590195773
Validation loss: 2.778420930738101

Epoch: 6| Step: 13
Training loss: 3.0540916076291045
Validation loss: 2.7767780259062063

Epoch: 118| Step: 0
Training loss: 3.1191780790350703
Validation loss: 2.7760613565882357

Epoch: 6| Step: 1
Training loss: 3.3215125933214185
Validation loss: 2.775718725743936

Epoch: 6| Step: 2
Training loss: 2.9082906798228967
Validation loss: 2.774103567493754

Epoch: 6| Step: 3
Training loss: 2.7955822221198083
Validation loss: 2.773240093281089

Epoch: 6| Step: 4
Training loss: 2.1550996448465045
Validation loss: 2.781549464113883

Epoch: 6| Step: 5
Training loss: 3.4364203404807343
Validation loss: 2.7840434139126597

Epoch: 6| Step: 6
Training loss: 3.354646415441102
Validation loss: 2.787910542255475

Epoch: 6| Step: 7
Training loss: 3.5419064309735067
Validation loss: 2.7884391588362

Epoch: 6| Step: 8
Training loss: 3.3180794420993043
Validation loss: 2.7840400804931416

Epoch: 6| Step: 9
Training loss: 2.3402043289244943
Validation loss: 2.775380652668979

Epoch: 6| Step: 10
Training loss: 3.105597113109664
Validation loss: 2.7731999675845325

Epoch: 6| Step: 11
Training loss: 3.0342738220129584
Validation loss: 2.7710674525303625

Epoch: 6| Step: 12
Training loss: 3.413169342462684
Validation loss: 2.7702396641040057

Epoch: 6| Step: 13
Training loss: 3.08911417414773
Validation loss: 2.7677367402570643

Epoch: 119| Step: 0
Training loss: 2.5635111604808096
Validation loss: 2.7698603335810934

Epoch: 6| Step: 1
Training loss: 3.256041560027298
Validation loss: 2.768659212586962

Epoch: 6| Step: 2
Training loss: 3.1967173428408606
Validation loss: 2.7656632204023626

Epoch: 6| Step: 3
Training loss: 2.820383678605352
Validation loss: 2.768379228118423

Epoch: 6| Step: 4
Training loss: 3.7926115738028923
Validation loss: 2.765408493029641

Epoch: 6| Step: 5
Training loss: 3.065364665605397
Validation loss: 2.762226550792492

Epoch: 6| Step: 6
Training loss: 2.395222151931735
Validation loss: 2.7653691084379592

Epoch: 6| Step: 7
Training loss: 3.1904157878198136
Validation loss: 2.767606723806776

Epoch: 6| Step: 8
Training loss: 2.9982466342245218
Validation loss: 2.7654430064642788

Epoch: 6| Step: 9
Training loss: 3.0877500981029797
Validation loss: 2.7666967563300053

Epoch: 6| Step: 10
Training loss: 3.11238435584023
Validation loss: 2.7642569073705605

Epoch: 6| Step: 11
Training loss: 3.039457712242313
Validation loss: 2.76685244138776

Epoch: 6| Step: 12
Training loss: 3.2019088297152676
Validation loss: 2.7739536090003623

Epoch: 6| Step: 13
Training loss: 3.353505387287809
Validation loss: 2.7728803778452393

Epoch: 120| Step: 0
Training loss: 2.580042825092072
Validation loss: 2.7723565335548375

Epoch: 6| Step: 1
Training loss: 3.023774988229673
Validation loss: 2.7772882406184545

Epoch: 6| Step: 2
Training loss: 2.446070057094164
Validation loss: 2.7922707150434314

Epoch: 6| Step: 3
Training loss: 3.037445972103416
Validation loss: 2.817810935319951

Epoch: 6| Step: 4
Training loss: 2.9491408179893774
Validation loss: 2.8279436817376222

Epoch: 6| Step: 5
Training loss: 2.514183721470815
Validation loss: 2.818558566000701

Epoch: 6| Step: 6
Training loss: 2.6166917018138207
Validation loss: 2.7902502973721766

Epoch: 6| Step: 7
Training loss: 3.1154688636278127
Validation loss: 2.77487347414264

Epoch: 6| Step: 8
Training loss: 3.4378406702639803
Validation loss: 2.7725966532376556

Epoch: 6| Step: 9
Training loss: 3.042481369926945
Validation loss: 2.761004504260502

Epoch: 6| Step: 10
Training loss: 2.882621779503762
Validation loss: 2.758046163519368

Epoch: 6| Step: 11
Training loss: 3.6549072408321
Validation loss: 2.761418513971039

Epoch: 6| Step: 12
Training loss: 3.7515738681301625
Validation loss: 2.7667077115831082

Epoch: 6| Step: 13
Training loss: 4.012062719172426
Validation loss: 2.7642270014660504

Epoch: 121| Step: 0
Training loss: 3.7516460620704652
Validation loss: 2.768813422525342

Epoch: 6| Step: 1
Training loss: 2.855800708517241
Validation loss: 2.7703844148261236

Epoch: 6| Step: 2
Training loss: 2.7753346146925675
Validation loss: 2.769146913916298

Epoch: 6| Step: 3
Training loss: 3.870318753819193
Validation loss: 2.7737785909534747

Epoch: 6| Step: 4
Training loss: 2.546622983481284
Validation loss: 2.7720654225029557

Epoch: 6| Step: 5
Training loss: 3.667262780254297
Validation loss: 2.7764679088357895

Epoch: 6| Step: 6
Training loss: 3.020050596356495
Validation loss: 2.772971658090577

Epoch: 6| Step: 7
Training loss: 2.060819577074653
Validation loss: 2.7750514902121286

Epoch: 6| Step: 8
Training loss: 3.0688979600715065
Validation loss: 2.7697782565572675

Epoch: 6| Step: 9
Training loss: 3.5606802592610594
Validation loss: 2.7711851266915066

Epoch: 6| Step: 10
Training loss: 3.4198983113747756
Validation loss: 2.766528764790056

Epoch: 6| Step: 11
Training loss: 2.1884410468866284
Validation loss: 2.7692062543853724

Epoch: 6| Step: 12
Training loss: 3.184196106262874
Validation loss: 2.7622451267832164

Epoch: 6| Step: 13
Training loss: 2.34907547235047
Validation loss: 2.7625094408259923

Epoch: 122| Step: 0
Training loss: 2.6052838993412966
Validation loss: 2.7630944743765675

Epoch: 6| Step: 1
Training loss: 2.8911729447931855
Validation loss: 2.760955217190173

Epoch: 6| Step: 2
Training loss: 2.988335662545869
Validation loss: 2.7596689328690034

Epoch: 6| Step: 3
Training loss: 2.999451269192378
Validation loss: 2.7595838395977106

Epoch: 6| Step: 4
Training loss: 2.5511723871307956
Validation loss: 2.7615738495490953

Epoch: 6| Step: 5
Training loss: 2.5681712962861085
Validation loss: 2.7607053197545848

Epoch: 6| Step: 6
Training loss: 2.8617447169003443
Validation loss: 2.7648471743993666

Epoch: 6| Step: 7
Training loss: 3.6804445949758584
Validation loss: 2.7996785502344315

Epoch: 6| Step: 8
Training loss: 3.470124668223419
Validation loss: 2.8350405233744964

Epoch: 6| Step: 9
Training loss: 3.068177390817858
Validation loss: 2.818307974542103

Epoch: 6| Step: 10
Training loss: 2.84321706619851
Validation loss: 2.7763978481480756

Epoch: 6| Step: 11
Training loss: 3.0489826444267645
Validation loss: 2.7539998598522826

Epoch: 6| Step: 12
Training loss: 3.9071493105412904
Validation loss: 2.754091071451526

Epoch: 6| Step: 13
Training loss: 3.5563032900499802
Validation loss: 2.7586651945351925

Epoch: 123| Step: 0
Training loss: 3.2309513861618546
Validation loss: 2.760719066981137

Epoch: 6| Step: 1
Training loss: 3.0983544196659105
Validation loss: 2.76104406810209

Epoch: 6| Step: 2
Training loss: 2.5836751670686087
Validation loss: 2.7626594572419605

Epoch: 6| Step: 3
Training loss: 2.560632350725792
Validation loss: 2.7646670037089094

Epoch: 6| Step: 4
Training loss: 3.020186379094067
Validation loss: 2.769269274352407

Epoch: 6| Step: 5
Training loss: 2.21833303052679
Validation loss: 2.770862231002498

Epoch: 6| Step: 6
Training loss: 3.2122556482147098
Validation loss: 2.7708609745615487

Epoch: 6| Step: 7
Training loss: 3.4913738762239572
Validation loss: 2.7732160637844907

Epoch: 6| Step: 8
Training loss: 4.16001159703032
Validation loss: 2.7709921946210607

Epoch: 6| Step: 9
Training loss: 2.8265035628399744
Validation loss: 2.7710996159528047

Epoch: 6| Step: 10
Training loss: 3.00413831749466
Validation loss: 2.763646335614972

Epoch: 6| Step: 11
Training loss: 3.301185429673539
Validation loss: 2.7617192345606725

Epoch: 6| Step: 12
Training loss: 2.891350072703048
Validation loss: 2.759496513579361

Epoch: 6| Step: 13
Training loss: 3.369155344170746
Validation loss: 2.757976503052717

Epoch: 124| Step: 0
Training loss: 2.7169658901753744
Validation loss: 2.7563670973060965

Epoch: 6| Step: 1
Training loss: 2.9644781598441354
Validation loss: 2.757371533197066

Epoch: 6| Step: 2
Training loss: 3.218036609590777
Validation loss: 2.7587915138947383

Epoch: 6| Step: 3
Training loss: 2.2965671047486875
Validation loss: 2.756823072007908

Epoch: 6| Step: 4
Training loss: 3.6170024124150117
Validation loss: 2.758177514565862

Epoch: 6| Step: 5
Training loss: 3.1347050836248873
Validation loss: 2.758767137381356

Epoch: 6| Step: 6
Training loss: 3.0466735773265547
Validation loss: 2.7571430492424587

Epoch: 6| Step: 7
Training loss: 3.1854651444719195
Validation loss: 2.7569422821859977

Epoch: 6| Step: 8
Training loss: 3.4357797653262345
Validation loss: 2.756133219814188

Epoch: 6| Step: 9
Training loss: 3.201318445393766
Validation loss: 2.755076981546105

Epoch: 6| Step: 10
Training loss: 3.2806603764788487
Validation loss: 2.7525038577156655

Epoch: 6| Step: 11
Training loss: 2.856152829577031
Validation loss: 2.756533370980657

Epoch: 6| Step: 12
Training loss: 2.956026297043217
Validation loss: 2.755409997413905

Epoch: 6| Step: 13
Training loss: 3.0273426474292346
Validation loss: 2.7533256077476156

Epoch: 125| Step: 0
Training loss: 2.298657614348629
Validation loss: 2.7546665901149563

Epoch: 6| Step: 1
Training loss: 3.3878060853628393
Validation loss: 2.751416111162311

Epoch: 6| Step: 2
Training loss: 2.6415965081975674
Validation loss: 2.75255162430914

Epoch: 6| Step: 3
Training loss: 3.015031350954947
Validation loss: 2.7534716088967253

Epoch: 6| Step: 4
Training loss: 3.131883136142629
Validation loss: 2.754243995320993

Epoch: 6| Step: 5
Training loss: 2.8185228074365547
Validation loss: 2.752347081606679

Epoch: 6| Step: 6
Training loss: 3.9837298899473055
Validation loss: 2.751532384976631

Epoch: 6| Step: 7
Training loss: 3.210659042870013
Validation loss: 2.7522930027170966

Epoch: 6| Step: 8
Training loss: 3.161491196957528
Validation loss: 2.753620915760902

Epoch: 6| Step: 9
Training loss: 2.7441112584616385
Validation loss: 2.74772411150915

Epoch: 6| Step: 10
Training loss: 2.633473751895509
Validation loss: 2.7516949772710846

Epoch: 6| Step: 11
Training loss: 3.070574489607446
Validation loss: 2.75097548708485

Epoch: 6| Step: 12
Training loss: 3.117423218345214
Validation loss: 2.746568623492513

Epoch: 6| Step: 13
Training loss: 3.821347461140142
Validation loss: 2.748851823558227

Epoch: 126| Step: 0
Training loss: 3.3499905828087377
Validation loss: 2.746862493614382

Epoch: 6| Step: 1
Training loss: 3.5801010339215202
Validation loss: 2.7465370520697237

Epoch: 6| Step: 2
Training loss: 3.5937637992262244
Validation loss: 2.7473916878042286

Epoch: 6| Step: 3
Training loss: 3.7358100719409872
Validation loss: 2.7478871623763585

Epoch: 6| Step: 4
Training loss: 3.370642498132919
Validation loss: 2.7453815500150283

Epoch: 6| Step: 5
Training loss: 3.2531329972959457
Validation loss: 2.7558466398358945

Epoch: 6| Step: 6
Training loss: 3.254365922897981
Validation loss: 2.77772934047621

Epoch: 6| Step: 7
Training loss: 2.736338319289763
Validation loss: 2.7742081080689234

Epoch: 6| Step: 8
Training loss: 2.6752336596107646
Validation loss: 2.7993115226914345

Epoch: 6| Step: 9
Training loss: 2.5048654894016
Validation loss: 2.7944616539625544

Epoch: 6| Step: 10
Training loss: 2.509299814658458
Validation loss: 2.7826713901778843

Epoch: 6| Step: 11
Training loss: 2.7255184940206845
Validation loss: 2.7671871140810054

Epoch: 6| Step: 12
Training loss: 2.748675634359195
Validation loss: 2.7511092677392868

Epoch: 6| Step: 13
Training loss: 2.211155964871942
Validation loss: 2.7428472876432757

Epoch: 127| Step: 0
Training loss: 2.9861464111449636
Validation loss: 2.7440118000304534

Epoch: 6| Step: 1
Training loss: 3.2749608394232532
Validation loss: 2.746559791669967

Epoch: 6| Step: 2
Training loss: 3.636114641898118
Validation loss: 2.7485266707275824

Epoch: 6| Step: 3
Training loss: 2.226298641163947
Validation loss: 2.7470736273208844

Epoch: 6| Step: 4
Training loss: 2.665968495605634
Validation loss: 2.7565292249330637

Epoch: 6| Step: 5
Training loss: 3.4411618235771653
Validation loss: 2.7735205206201172

Epoch: 6| Step: 6
Training loss: 3.320549164359668
Validation loss: 2.7789216987792797

Epoch: 6| Step: 7
Training loss: 3.368695056587542
Validation loss: 2.746011868183265

Epoch: 6| Step: 8
Training loss: 2.965339709629549
Validation loss: 2.7408969505456517

Epoch: 6| Step: 9
Training loss: 1.9165598245226056
Validation loss: 2.7379765244383334

Epoch: 6| Step: 10
Training loss: 3.2639959187014624
Validation loss: 2.740139152532929

Epoch: 6| Step: 11
Training loss: 3.2165668083331806
Validation loss: 2.7424027515890987

Epoch: 6| Step: 12
Training loss: 2.9110478001990874
Validation loss: 2.7440485277027618

Epoch: 6| Step: 13
Training loss: 3.4473516610191433
Validation loss: 2.741201608645185

Epoch: 128| Step: 0
Training loss: 3.118179507624996
Validation loss: 2.7414365215212513

Epoch: 6| Step: 1
Training loss: 3.587948171022248
Validation loss: 2.7485875448515373

Epoch: 6| Step: 2
Training loss: 3.1592903223962376
Validation loss: 2.7523841740118438

Epoch: 6| Step: 3
Training loss: 3.6388456392185105
Validation loss: 2.7586929545866496

Epoch: 6| Step: 4
Training loss: 3.6319114305897435
Validation loss: 2.7706963749457185

Epoch: 6| Step: 5
Training loss: 2.6474124871650178
Validation loss: 2.763000778313037

Epoch: 6| Step: 6
Training loss: 2.2675627741593876
Validation loss: 2.7654500277586895

Epoch: 6| Step: 7
Training loss: 3.0906896385785165
Validation loss: 2.7606426856176256

Epoch: 6| Step: 8
Training loss: 2.860028301712534
Validation loss: 2.7684652960766414

Epoch: 6| Step: 9
Training loss: 2.6057591769706385
Validation loss: 2.7668122944000406

Epoch: 6| Step: 10
Training loss: 2.4406924737842157
Validation loss: 2.7702271782827066

Epoch: 6| Step: 11
Training loss: 3.207023221004718
Validation loss: 2.77333608901492

Epoch: 6| Step: 12
Training loss: 3.1500276473512336
Validation loss: 2.7461129691126307

Epoch: 6| Step: 13
Training loss: 3.1321116588658704
Validation loss: 2.7343236306048633

Epoch: 129| Step: 0
Training loss: 2.953310360212796
Validation loss: 2.73503140447785

Epoch: 6| Step: 1
Training loss: 3.442521190702753
Validation loss: 2.7403876623746455

Epoch: 6| Step: 2
Training loss: 3.1569059086995033
Validation loss: 2.741074732132352

Epoch: 6| Step: 3
Training loss: 2.93611550677149
Validation loss: 2.7364760560579926

Epoch: 6| Step: 4
Training loss: 2.9324612520459628
Validation loss: 2.7380955701774425

Epoch: 6| Step: 5
Training loss: 3.174591104204452
Validation loss: 2.733846999608516

Epoch: 6| Step: 6
Training loss: 2.4889775474213067
Validation loss: 2.734840749519658

Epoch: 6| Step: 7
Training loss: 2.8277830475677104
Validation loss: 2.7372652937749113

Epoch: 6| Step: 8
Training loss: 3.458877949555589
Validation loss: 2.7343859563042545

Epoch: 6| Step: 9
Training loss: 3.2213823239641144
Validation loss: 2.7328960547885264

Epoch: 6| Step: 10
Training loss: 3.6393537798706235
Validation loss: 2.738127066658392

Epoch: 6| Step: 11
Training loss: 3.1112922623286257
Validation loss: 2.727707942140565

Epoch: 6| Step: 12
Training loss: 2.264190851315684
Validation loss: 2.729054858646168

Epoch: 6| Step: 13
Training loss: 2.99232598126227
Validation loss: 2.7264846446041924

Epoch: 130| Step: 0
Training loss: 2.132637100552982
Validation loss: 2.733276782312458

Epoch: 6| Step: 1
Training loss: 2.5323773922853614
Validation loss: 2.7417737299639886

Epoch: 6| Step: 2
Training loss: 2.6618777627028214
Validation loss: 2.7698813064352716

Epoch: 6| Step: 3
Training loss: 3.4865075671607455
Validation loss: 2.780140095684495

Epoch: 6| Step: 4
Training loss: 3.413218378599911
Validation loss: 2.7903462040342366

Epoch: 6| Step: 5
Training loss: 2.9086157901163503
Validation loss: 2.810033154365554

Epoch: 6| Step: 6
Training loss: 3.4220636742540917
Validation loss: 2.7804103559580122

Epoch: 6| Step: 7
Training loss: 3.40207437178083
Validation loss: 2.7384700346405877

Epoch: 6| Step: 8
Training loss: 2.4112327805255767
Validation loss: 2.725731500166848

Epoch: 6| Step: 9
Training loss: 3.157738665020033
Validation loss: 2.7307916697596775

Epoch: 6| Step: 10
Training loss: 3.3758211902885598
Validation loss: 2.729529385736353

Epoch: 6| Step: 11
Training loss: 3.2218897052359003
Validation loss: 2.7327430648499194

Epoch: 6| Step: 12
Training loss: 2.9263939820675633
Validation loss: 2.73458220416086

Epoch: 6| Step: 13
Training loss: 3.764317582332386
Validation loss: 2.7373299205585573

Epoch: 131| Step: 0
Training loss: 3.1000627019140015
Validation loss: 2.741686792303218

Epoch: 6| Step: 1
Training loss: 3.2295664550067222
Validation loss: 2.745508591198264

Epoch: 6| Step: 2
Training loss: 2.937716212330499
Validation loss: 2.73717117998105

Epoch: 6| Step: 3
Training loss: 2.791394623743674
Validation loss: 2.735109719569735

Epoch: 6| Step: 4
Training loss: 2.9295019472489767
Validation loss: 2.7325682856481337

Epoch: 6| Step: 5
Training loss: 3.3894741372915305
Validation loss: 2.732352968631141

Epoch: 6| Step: 6
Training loss: 3.7484317043270767
Validation loss: 2.7313563894695334

Epoch: 6| Step: 7
Training loss: 3.3652930362523605
Validation loss: 2.7315788258263223

Epoch: 6| Step: 8
Training loss: 2.4436643853763824
Validation loss: 2.7309786178090594

Epoch: 6| Step: 9
Training loss: 3.178173857756903
Validation loss: 2.733661373086392

Epoch: 6| Step: 10
Training loss: 2.782749757482436
Validation loss: 2.7358144704441143

Epoch: 6| Step: 11
Training loss: 2.931137011206879
Validation loss: 2.7380729700119417

Epoch: 6| Step: 12
Training loss: 2.556095959935089
Validation loss: 2.742705261770383

Epoch: 6| Step: 13
Training loss: 3.415665658218455
Validation loss: 2.7474368316821516

Epoch: 132| Step: 0
Training loss: 2.9192287273019026
Validation loss: 2.746488195174988

Epoch: 6| Step: 1
Training loss: 2.9758580292811367
Validation loss: 2.749443506892127

Epoch: 6| Step: 2
Training loss: 3.397219946226195
Validation loss: 2.7604466652396202

Epoch: 6| Step: 3
Training loss: 3.2746827299467536
Validation loss: 2.769159750851196

Epoch: 6| Step: 4
Training loss: 3.511010697963739
Validation loss: 2.794775584555456

Epoch: 6| Step: 5
Training loss: 3.4886380106092094
Validation loss: 2.790038252069996

Epoch: 6| Step: 6
Training loss: 2.8441408328933964
Validation loss: 2.7724691985835035

Epoch: 6| Step: 7
Training loss: 2.8573265868104487
Validation loss: 2.7608436376542054

Epoch: 6| Step: 8
Training loss: 2.6497369239787534
Validation loss: 2.7466612635114416

Epoch: 6| Step: 9
Training loss: 2.899602033998184
Validation loss: 2.721104193973093

Epoch: 6| Step: 10
Training loss: 3.140965988854328
Validation loss: 2.721702156283368

Epoch: 6| Step: 11
Training loss: 2.9476053637437785
Validation loss: 2.7192044989131126

Epoch: 6| Step: 12
Training loss: 2.694713315843402
Validation loss: 2.721860653238173

Epoch: 6| Step: 13
Training loss: 3.2531118900207137
Validation loss: 2.7253215831474553

Epoch: 133| Step: 0
Training loss: 3.6414901294880893
Validation loss: 2.7271684214924115

Epoch: 6| Step: 1
Training loss: 2.7815689589808255
Validation loss: 2.7291952559241746

Epoch: 6| Step: 2
Training loss: 2.3716394842774458
Validation loss: 2.7331901212141445

Epoch: 6| Step: 3
Training loss: 2.2570247133767083
Validation loss: 2.7383666808468337

Epoch: 6| Step: 4
Training loss: 3.5434288727113397
Validation loss: 2.7362439065903037

Epoch: 6| Step: 5
Training loss: 2.702851121732157
Validation loss: 2.740269089492943

Epoch: 6| Step: 6
Training loss: 3.233627749013398
Validation loss: 2.729159228263011

Epoch: 6| Step: 7
Training loss: 3.100104693213879
Validation loss: 2.7278162268713992

Epoch: 6| Step: 8
Training loss: 3.3557178551396754
Validation loss: 2.7248345674722816

Epoch: 6| Step: 9
Training loss: 3.491498704267882
Validation loss: 2.7204805985179563

Epoch: 6| Step: 10
Training loss: 2.789865159225251
Validation loss: 2.7214618680193836

Epoch: 6| Step: 11
Training loss: 2.996688127310021
Validation loss: 2.7195591234702845

Epoch: 6| Step: 12
Training loss: 3.1477611941796817
Validation loss: 2.7196476413579114

Epoch: 6| Step: 13
Training loss: 2.9157080210225064
Validation loss: 2.7193754987939434

Epoch: 134| Step: 0
Training loss: 2.493052652322489
Validation loss: 2.732886639390038

Epoch: 6| Step: 1
Training loss: 2.6964077258499755
Validation loss: 2.7446163548264795

Epoch: 6| Step: 2
Training loss: 2.8666727295153476
Validation loss: 2.7583747835994585

Epoch: 6| Step: 3
Training loss: 3.0990472006143666
Validation loss: 2.7615688449394264

Epoch: 6| Step: 4
Training loss: 2.7461154551618208
Validation loss: 2.7300702615418606

Epoch: 6| Step: 5
Training loss: 3.495887520104538
Validation loss: 2.71833141378015

Epoch: 6| Step: 6
Training loss: 3.014576467749197
Validation loss: 2.7143465618647533

Epoch: 6| Step: 7
Training loss: 3.0952403784663125
Validation loss: 2.712246540397724

Epoch: 6| Step: 8
Training loss: 2.9588285398836778
Validation loss: 2.7138072746289685

Epoch: 6| Step: 9
Training loss: 3.19170550994211
Validation loss: 2.7131511901788308

Epoch: 6| Step: 10
Training loss: 3.393168536932956
Validation loss: 2.7145916730642625

Epoch: 6| Step: 11
Training loss: 2.957587206240846
Validation loss: 2.7156680069501817

Epoch: 6| Step: 12
Training loss: 3.5504819032492327
Validation loss: 2.720759363884911

Epoch: 6| Step: 13
Training loss: 2.85190494519124
Validation loss: 2.722885281567821

Epoch: 135| Step: 0
Training loss: 3.399078940004315
Validation loss: 2.719452593331215

Epoch: 6| Step: 1
Training loss: 2.8672590116890913
Validation loss: 2.7265796867101835

Epoch: 6| Step: 2
Training loss: 2.6629554932012574
Validation loss: 2.719620460282685

Epoch: 6| Step: 3
Training loss: 3.01891878339374
Validation loss: 2.719352418746186

Epoch: 6| Step: 4
Training loss: 3.2003283689820834
Validation loss: 2.7356644541344206

Epoch: 6| Step: 5
Training loss: 3.009915496045522
Validation loss: 2.7387555947503133

Epoch: 6| Step: 6
Training loss: 2.7599203467277786
Validation loss: 2.7597702492305056

Epoch: 6| Step: 7
Training loss: 3.017624582470049
Validation loss: 2.753991938991481

Epoch: 6| Step: 8
Training loss: 3.049020803889148
Validation loss: 2.742040251045937

Epoch: 6| Step: 9
Training loss: 2.811094059806579
Validation loss: 2.721841627384749

Epoch: 6| Step: 10
Training loss: 3.4558680069760515
Validation loss: 2.711530279643952

Epoch: 6| Step: 11
Training loss: 2.535112800872374
Validation loss: 2.7090039207910923

Epoch: 6| Step: 12
Training loss: 3.944915086729232
Validation loss: 2.708662950763331

Epoch: 6| Step: 13
Training loss: 2.452508739646404
Validation loss: 2.708047792765791

Epoch: 136| Step: 0
Training loss: 3.0860858350425056
Validation loss: 2.7120894883814146

Epoch: 6| Step: 1
Training loss: 2.6115281592641573
Validation loss: 2.7113085954345673

Epoch: 6| Step: 2
Training loss: 3.06523352873698
Validation loss: 2.713442127325559

Epoch: 6| Step: 3
Training loss: 2.6667162076004005
Validation loss: 2.715336945941499

Epoch: 6| Step: 4
Training loss: 3.0398048729764686
Validation loss: 2.714354784477842

Epoch: 6| Step: 5
Training loss: 2.7142005652502066
Validation loss: 2.718910990450972

Epoch: 6| Step: 6
Training loss: 3.557542530483813
Validation loss: 2.7156177620487028

Epoch: 6| Step: 7
Training loss: 3.271354941469386
Validation loss: 2.7128302407388034

Epoch: 6| Step: 8
Training loss: 3.05479473891645
Validation loss: 2.709843503385866

Epoch: 6| Step: 9
Training loss: 3.0409460041404315
Validation loss: 2.70803972708438

Epoch: 6| Step: 10
Training loss: 3.3613397574791457
Validation loss: 2.7052498548179673

Epoch: 6| Step: 11
Training loss: 2.828221103447422
Validation loss: 2.709432685182043

Epoch: 6| Step: 12
Training loss: 3.391446484316308
Validation loss: 2.718670364022608

Epoch: 6| Step: 13
Training loss: 2.6222715275739374
Validation loss: 2.7207111324102393

Epoch: 137| Step: 0
Training loss: 2.888982027541283
Validation loss: 2.7229273905547897

Epoch: 6| Step: 1
Training loss: 2.7351967584943906
Validation loss: 2.7152445882855005

Epoch: 6| Step: 2
Training loss: 3.5413791913812953
Validation loss: 2.711025114512222

Epoch: 6| Step: 3
Training loss: 3.3434205650544624
Validation loss: 2.7136573435395026

Epoch: 6| Step: 4
Training loss: 3.1254301156637543
Validation loss: 2.7101299372358927

Epoch: 6| Step: 5
Training loss: 3.0359875339659226
Validation loss: 2.706450322839839

Epoch: 6| Step: 6
Training loss: 3.8105359881395606
Validation loss: 2.709729328185691

Epoch: 6| Step: 7
Training loss: 2.993195286847739
Validation loss: 2.7081982123758577

Epoch: 6| Step: 8
Training loss: 3.046987678204953
Validation loss: 2.70912454626039

Epoch: 6| Step: 9
Training loss: 2.6349487693482474
Validation loss: 2.7075798175976984

Epoch: 6| Step: 10
Training loss: 2.414313343434958
Validation loss: 2.7111602329513507

Epoch: 6| Step: 11
Training loss: 3.301330881799867
Validation loss: 2.709767267914941

Epoch: 6| Step: 12
Training loss: 2.6960536656457696
Validation loss: 2.706463824673647

Epoch: 6| Step: 13
Training loss: 2.259064535123452
Validation loss: 2.710883719457618

Epoch: 138| Step: 0
Training loss: 3.1304170578072417
Validation loss: 2.709481888556082

Epoch: 6| Step: 1
Training loss: 3.0652747526750694
Validation loss: 2.7021947594116433

Epoch: 6| Step: 2
Training loss: 3.441837140926788
Validation loss: 2.705499502724678

Epoch: 6| Step: 3
Training loss: 3.44390023625544
Validation loss: 2.7016813942644204

Epoch: 6| Step: 4
Training loss: 3.041471257312424
Validation loss: 2.7045725367330347

Epoch: 6| Step: 5
Training loss: 2.6961914398526066
Validation loss: 2.7060983932102096

Epoch: 6| Step: 6
Training loss: 2.631348335802589
Validation loss: 2.7053583893397866

Epoch: 6| Step: 7
Training loss: 3.5270098320110392
Validation loss: 2.711738818128863

Epoch: 6| Step: 8
Training loss: 2.7727847768446026
Validation loss: 2.7210482128275704

Epoch: 6| Step: 9
Training loss: 2.9778971245637185
Validation loss: 2.7376198150206097

Epoch: 6| Step: 10
Training loss: 3.2961277408660066
Validation loss: 2.7376329196529587

Epoch: 6| Step: 11
Training loss: 2.034469166347418
Validation loss: 2.713694757888832

Epoch: 6| Step: 12
Training loss: 3.191459440537464
Validation loss: 2.7028840399973824

Epoch: 6| Step: 13
Training loss: 2.8824677713516347
Validation loss: 2.697039793119045

Epoch: 139| Step: 0
Training loss: 2.9999046310524866
Validation loss: 2.7013505285739194

Epoch: 6| Step: 1
Training loss: 3.2763744644106967
Validation loss: 2.7089435360114416

Epoch: 6| Step: 2
Training loss: 3.2169897210428586
Validation loss: 2.708433914841083

Epoch: 6| Step: 3
Training loss: 3.0849580007009605
Validation loss: 2.7075868080968353

Epoch: 6| Step: 4
Training loss: 2.954683407317201
Validation loss: 2.7090281157754283

Epoch: 6| Step: 5
Training loss: 3.3705140429822316
Validation loss: 2.707341125676886

Epoch: 6| Step: 6
Training loss: 2.6837648562058787
Validation loss: 2.7083653854354024

Epoch: 6| Step: 7
Training loss: 3.2053753647018777
Validation loss: 2.7071651747661476

Epoch: 6| Step: 8
Training loss: 2.8799593072241647
Validation loss: 2.706136667100446

Epoch: 6| Step: 9
Training loss: 2.8386083379259244
Validation loss: 2.70507996166927

Epoch: 6| Step: 10
Training loss: 3.297447263398616
Validation loss: 2.7040632114528993

Epoch: 6| Step: 11
Training loss: 2.9930829732592534
Validation loss: 2.7010189342282893

Epoch: 6| Step: 12
Training loss: 2.9595014567280566
Validation loss: 2.709952540733383

Epoch: 6| Step: 13
Training loss: 2.4927870648059507
Validation loss: 2.717481065028259

Epoch: 140| Step: 0
Training loss: 3.222047616532177
Validation loss: 2.7294690502324266

Epoch: 6| Step: 1
Training loss: 3.3081913402715473
Validation loss: 2.7459838856413215

Epoch: 6| Step: 2
Training loss: 2.6211050291998372
Validation loss: 2.763090683321676

Epoch: 6| Step: 3
Training loss: 2.9751896132622004
Validation loss: 2.768487857416321

Epoch: 6| Step: 4
Training loss: 2.808809105013978
Validation loss: 2.7776277170017245

Epoch: 6| Step: 5
Training loss: 2.7125005695676427
Validation loss: 2.7779290103420466

Epoch: 6| Step: 6
Training loss: 3.3913058814658754
Validation loss: 2.7893972715559157

Epoch: 6| Step: 7
Training loss: 2.9170623147642516
Validation loss: 2.7456191118398414

Epoch: 6| Step: 8
Training loss: 2.3334196165571237
Validation loss: 2.7122503769995316

Epoch: 6| Step: 9
Training loss: 2.8173283140309593
Validation loss: 2.6986121246072132

Epoch: 6| Step: 10
Training loss: 3.5591211189910967
Validation loss: 2.6987713839180336

Epoch: 6| Step: 11
Training loss: 3.3870783244273617
Validation loss: 2.70330293842565

Epoch: 6| Step: 12
Training loss: 3.1005624076370957
Validation loss: 2.7022341758157666

Epoch: 6| Step: 13
Training loss: 3.0961160570910535
Validation loss: 2.7070993444107425

Epoch: 141| Step: 0
Training loss: 2.905177092677714
Validation loss: 2.7065110208871705

Epoch: 6| Step: 1
Training loss: 2.9329077354093203
Validation loss: 2.7090760432939156

Epoch: 6| Step: 2
Training loss: 2.983477552398218
Validation loss: 2.706864384746229

Epoch: 6| Step: 3
Training loss: 2.6726328349488595
Validation loss: 2.7084315428111765

Epoch: 6| Step: 4
Training loss: 3.5961224230166637
Validation loss: 2.7074793722729105

Epoch: 6| Step: 5
Training loss: 3.3578763235921922
Validation loss: 2.7083757720600814

Epoch: 6| Step: 6
Training loss: 3.31172905353618
Validation loss: 2.7082124495367985

Epoch: 6| Step: 7
Training loss: 3.132274705193717
Validation loss: 2.712343851729606

Epoch: 6| Step: 8
Training loss: 3.158550066460696
Validation loss: 2.707350323587255

Epoch: 6| Step: 9
Training loss: 2.632525148190093
Validation loss: 2.7034490636355257

Epoch: 6| Step: 10
Training loss: 2.53677800623016
Validation loss: 2.7025831994154808

Epoch: 6| Step: 11
Training loss: 2.866274321860903
Validation loss: 2.7020577718596677

Epoch: 6| Step: 12
Training loss: 2.8592314136911994
Validation loss: 2.7020201209467176

Epoch: 6| Step: 13
Training loss: 3.748587533063886
Validation loss: 2.699170009193807

Epoch: 142| Step: 0
Training loss: 2.195124390711889
Validation loss: 2.6958915679307522

Epoch: 6| Step: 1
Training loss: 2.2053563066682838
Validation loss: 2.699041887282613

Epoch: 6| Step: 2
Training loss: 2.726114230756536
Validation loss: 2.6978320638530247

Epoch: 6| Step: 3
Training loss: 3.8066210836786776
Validation loss: 2.6951928714826323

Epoch: 6| Step: 4
Training loss: 2.4379553736294257
Validation loss: 2.691936119818433

Epoch: 6| Step: 5
Training loss: 2.528059561770186
Validation loss: 2.6882587715330115

Epoch: 6| Step: 6
Training loss: 3.0130946162143277
Validation loss: 2.695085346814813

Epoch: 6| Step: 7
Training loss: 3.9751897514685592
Validation loss: 2.6908220200305304

Epoch: 6| Step: 8
Training loss: 2.1127236242267284
Validation loss: 2.696467511922145

Epoch: 6| Step: 9
Training loss: 3.7934269574304267
Validation loss: 2.7097412753503916

Epoch: 6| Step: 10
Training loss: 3.1684845341044174
Validation loss: 2.707395621904833

Epoch: 6| Step: 11
Training loss: 3.8644684451455147
Validation loss: 2.7161380572372846

Epoch: 6| Step: 12
Training loss: 2.936861983467477
Validation loss: 2.705976011842598

Epoch: 6| Step: 13
Training loss: 2.332284373694656
Validation loss: 2.695133070452101

Epoch: 143| Step: 0
Training loss: 2.594531022106001
Validation loss: 2.6894954142749254

Epoch: 6| Step: 1
Training loss: 2.9299124262614957
Validation loss: 2.693375055526439

Epoch: 6| Step: 2
Training loss: 3.456692471041569
Validation loss: 2.691666428151246

Epoch: 6| Step: 3
Training loss: 2.397216585530117
Validation loss: 2.6839014100795766

Epoch: 6| Step: 4
Training loss: 3.211844137607276
Validation loss: 2.685010949320629

Epoch: 6| Step: 5
Training loss: 2.5756405968715685
Validation loss: 2.6848779112820624

Epoch: 6| Step: 6
Training loss: 3.3081075948447967
Validation loss: 2.68560675584664

Epoch: 6| Step: 7
Training loss: 2.7927604544268645
Validation loss: 2.6851110522004933

Epoch: 6| Step: 8
Training loss: 2.9434322760754617
Validation loss: 2.684616969227582

Epoch: 6| Step: 9
Training loss: 3.6773453890146657
Validation loss: 2.6835451400076855

Epoch: 6| Step: 10
Training loss: 2.509815022616987
Validation loss: 2.6826135636762576

Epoch: 6| Step: 11
Training loss: 3.8077285175039326
Validation loss: 2.6986041689473566

Epoch: 6| Step: 12
Training loss: 3.2419574701907163
Validation loss: 2.7084550898013258

Epoch: 6| Step: 13
Training loss: 1.8817799376235729
Validation loss: 2.71210909592228

Epoch: 144| Step: 0
Training loss: 3.0494733637171696
Validation loss: 2.699960365407089

Epoch: 6| Step: 1
Training loss: 2.830835213498208
Validation loss: 2.6890965865838323

Epoch: 6| Step: 2
Training loss: 2.4853850416765213
Validation loss: 2.6824039087288334

Epoch: 6| Step: 3
Training loss: 2.6379412494390286
Validation loss: 2.6876558591077084

Epoch: 6| Step: 4
Training loss: 2.9787498306997926
Validation loss: 2.6844157506871396

Epoch: 6| Step: 5
Training loss: 3.1167811843586124
Validation loss: 2.6835768392028583

Epoch: 6| Step: 6
Training loss: 3.5185065773060447
Validation loss: 2.6850597466467785

Epoch: 6| Step: 7
Training loss: 2.9179692402421775
Validation loss: 2.6813237324365713

Epoch: 6| Step: 8
Training loss: 3.080538350653371
Validation loss: 2.6821068624902904

Epoch: 6| Step: 9
Training loss: 2.9862735161987097
Validation loss: 2.6818200061184583

Epoch: 6| Step: 10
Training loss: 2.81953956389265
Validation loss: 2.6842022824549994

Epoch: 6| Step: 11
Training loss: 3.732117293629476
Validation loss: 2.6906659689259773

Epoch: 6| Step: 12
Training loss: 3.3559268731935528
Validation loss: 2.6893816192007787

Epoch: 6| Step: 13
Training loss: 1.8423932789675406
Validation loss: 2.6928175269376657

Epoch: 145| Step: 0
Training loss: 3.226898693091569
Validation loss: 2.692625937594904

Epoch: 6| Step: 1
Training loss: 2.7238674890214103
Validation loss: 2.677555073468446

Epoch: 6| Step: 2
Training loss: 2.584286626667873
Validation loss: 2.6772795791553112

Epoch: 6| Step: 3
Training loss: 3.445288141212076
Validation loss: 2.675379486736591

Epoch: 6| Step: 4
Training loss: 2.946793484900387
Validation loss: 2.6762184235639443

Epoch: 6| Step: 5
Training loss: 3.250160653471835
Validation loss: 2.677196021661158

Epoch: 6| Step: 6
Training loss: 3.4060972686963598
Validation loss: 2.676975887940749

Epoch: 6| Step: 7
Training loss: 3.2429260148164407
Validation loss: 2.674857132839644

Epoch: 6| Step: 8
Training loss: 2.6976359649699795
Validation loss: 2.676260342427751

Epoch: 6| Step: 9
Training loss: 2.9694510184360867
Validation loss: 2.6748662569969404

Epoch: 6| Step: 10
Training loss: 3.229290637846281
Validation loss: 2.6814546694704595

Epoch: 6| Step: 11
Training loss: 2.9747776878062866
Validation loss: 2.683129205992215

Epoch: 6| Step: 12
Training loss: 2.8027964727985744
Validation loss: 2.691934083713003

Epoch: 6| Step: 13
Training loss: 1.9751933787836315
Validation loss: 2.6916970792796038

Epoch: 146| Step: 0
Training loss: 2.9408952286835635
Validation loss: 2.682770744443752

Epoch: 6| Step: 1
Training loss: 2.791826518781946
Validation loss: 2.6840120094600004

Epoch: 6| Step: 2
Training loss: 2.3803418968561965
Validation loss: 2.6816059067849163

Epoch: 6| Step: 3
Training loss: 2.9098527788498303
Validation loss: 2.681423994957275

Epoch: 6| Step: 4
Training loss: 3.0364527148832203
Validation loss: 2.6797616599701204

Epoch: 6| Step: 5
Training loss: 2.184503082755182
Validation loss: 2.6751541618460055

Epoch: 6| Step: 6
Training loss: 3.7281486926161316
Validation loss: 2.678223491421826

Epoch: 6| Step: 7
Training loss: 3.2389915064729493
Validation loss: 2.6743795154646155

Epoch: 6| Step: 8
Training loss: 3.3754930489284463
Validation loss: 2.674312452438255

Epoch: 6| Step: 9
Training loss: 3.333898559967639
Validation loss: 2.675983846857095

Epoch: 6| Step: 10
Training loss: 2.1170113690863404
Validation loss: 2.67123163164426

Epoch: 6| Step: 11
Training loss: 3.076097779365567
Validation loss: 2.6756522994066065

Epoch: 6| Step: 12
Training loss: 3.103972221958099
Validation loss: 2.6751301961945666

Epoch: 6| Step: 13
Training loss: 3.775337325428864
Validation loss: 2.678498714454255

Epoch: 147| Step: 0
Training loss: 3.227290701724513
Validation loss: 2.677145716417267

Epoch: 6| Step: 1
Training loss: 3.0502579126592284
Validation loss: 2.6729465368399548

Epoch: 6| Step: 2
Training loss: 3.8145682556309928
Validation loss: 2.6677500064993267

Epoch: 6| Step: 3
Training loss: 2.971564474639734
Validation loss: 2.6675832519724163

Epoch: 6| Step: 4
Training loss: 2.881585250183855
Validation loss: 2.6692392325262757

Epoch: 6| Step: 5
Training loss: 2.868283096248878
Validation loss: 2.6674859156196726

Epoch: 6| Step: 6
Training loss: 2.83394904085054
Validation loss: 2.666129065423789

Epoch: 6| Step: 7
Training loss: 2.8927502217120034
Validation loss: 2.670246321347978

Epoch: 6| Step: 8
Training loss: 2.419902170268847
Validation loss: 2.671349775648581

Epoch: 6| Step: 9
Training loss: 2.569721003131575
Validation loss: 2.6795822357747943

Epoch: 6| Step: 10
Training loss: 2.9211166948191196
Validation loss: 2.6889950961742404

Epoch: 6| Step: 11
Training loss: 3.457603071087308
Validation loss: 2.693286901112545

Epoch: 6| Step: 12
Training loss: 2.6914800404037638
Validation loss: 2.6925652940561275

Epoch: 6| Step: 13
Training loss: 3.4666582278613545
Validation loss: 2.7007443411917005

Epoch: 148| Step: 0
Training loss: 3.7594645273103047
Validation loss: 2.707019470811415

Epoch: 6| Step: 1
Training loss: 3.172868244271705
Validation loss: 2.7043269615597545

Epoch: 6| Step: 2
Training loss: 2.3972358799979125
Validation loss: 2.701180904101276

Epoch: 6| Step: 3
Training loss: 2.95336412541488
Validation loss: 2.6955735707775017

Epoch: 6| Step: 4
Training loss: 2.8220579711128857
Validation loss: 2.6708080246075157

Epoch: 6| Step: 5
Training loss: 2.4227498105019243
Validation loss: 2.6715697089092125

Epoch: 6| Step: 6
Training loss: 3.3055127423360653
Validation loss: 2.665917245734839

Epoch: 6| Step: 7
Training loss: 3.3261113768903607
Validation loss: 2.6661700429110238

Epoch: 6| Step: 8
Training loss: 3.4217863724609936
Validation loss: 2.665517421567846

Epoch: 6| Step: 9
Training loss: 2.8365634195953087
Validation loss: 2.6748106758283576

Epoch: 6| Step: 10
Training loss: 2.7673355243882183
Validation loss: 2.687616427304226

Epoch: 6| Step: 11
Training loss: 2.5145088705201095
Validation loss: 2.691219995695659

Epoch: 6| Step: 12
Training loss: 2.603023084681026
Validation loss: 2.6870272746024204

Epoch: 6| Step: 13
Training loss: 3.789689159680772
Validation loss: 2.6889441984189966

Epoch: 149| Step: 0
Training loss: 2.5991204975019278
Validation loss: 2.6975316681902264

Epoch: 6| Step: 1
Training loss: 2.7237912498176153
Validation loss: 2.701913268378305

Epoch: 6| Step: 2
Training loss: 2.7036909271714453
Validation loss: 2.720300629457423

Epoch: 6| Step: 3
Training loss: 3.1218082149720368
Validation loss: 2.7261833991961413

Epoch: 6| Step: 4
Training loss: 3.4250743662981757
Validation loss: 2.7252937606744707

Epoch: 6| Step: 5
Training loss: 3.282498367436999
Validation loss: 2.7301647431272142

Epoch: 6| Step: 6
Training loss: 2.6182131451420787
Validation loss: 2.7070535486837657

Epoch: 6| Step: 7
Training loss: 3.6500871674044824
Validation loss: 2.7081430739094268

Epoch: 6| Step: 8
Training loss: 2.522979316805059
Validation loss: 2.707382119036493

Epoch: 6| Step: 9
Training loss: 2.748079583055394
Validation loss: 2.701844750069166

Epoch: 6| Step: 10
Training loss: 3.4582076145592398
Validation loss: 2.697680407671641

Epoch: 6| Step: 11
Training loss: 3.0073029321808136
Validation loss: 2.692613366078935

Epoch: 6| Step: 12
Training loss: 2.965576563802379
Validation loss: 2.69563091502262

Epoch: 6| Step: 13
Training loss: 3.1725249728519302
Validation loss: 2.6931130976620694

Epoch: 150| Step: 0
Training loss: 3.1726585886030074
Validation loss: 2.697338263808427

Epoch: 6| Step: 1
Training loss: 3.1824230077499673
Validation loss: 2.690894405965717

Epoch: 6| Step: 2
Training loss: 3.0397479306670525
Validation loss: 2.699991333513468

Epoch: 6| Step: 3
Training loss: 3.435205422024119
Validation loss: 2.7018333372984324

Epoch: 6| Step: 4
Training loss: 3.0533978405708506
Validation loss: 2.7057336874346545

Epoch: 6| Step: 5
Training loss: 2.8008047446059545
Validation loss: 2.694187987760642

Epoch: 6| Step: 6
Training loss: 3.628491528878975
Validation loss: 2.6935637039310065

Epoch: 6| Step: 7
Training loss: 3.0568635414421976
Validation loss: 2.698174445343504

Epoch: 6| Step: 8
Training loss: 2.539511960669327
Validation loss: 2.6995669360393015

Epoch: 6| Step: 9
Training loss: 3.311261359339664
Validation loss: 2.693536864014057

Epoch: 6| Step: 10
Training loss: 2.751261855103785
Validation loss: 2.688471365558668

Epoch: 6| Step: 11
Training loss: 2.6958764412296334
Validation loss: 2.684723245905704

Epoch: 6| Step: 12
Training loss: 2.7256557410557187
Validation loss: 2.6857553701599324

Epoch: 6| Step: 13
Training loss: 2.340934079062952
Validation loss: 2.6773667788560287

Epoch: 151| Step: 0
Training loss: 3.1503695861530137
Validation loss: 2.6807087464081416

Epoch: 6| Step: 1
Training loss: 3.3599764972954693
Validation loss: 2.6731483530614764

Epoch: 6| Step: 2
Training loss: 3.1963411275071305
Validation loss: 2.669685514919917

Epoch: 6| Step: 3
Training loss: 2.5689311388289338
Validation loss: 2.673595180569667

Epoch: 6| Step: 4
Training loss: 3.561452611245647
Validation loss: 2.6775554617167447

Epoch: 6| Step: 5
Training loss: 2.870933808523346
Validation loss: 2.6692441826227014

Epoch: 6| Step: 6
Training loss: 3.102882546348725
Validation loss: 2.66213406456176

Epoch: 6| Step: 7
Training loss: 2.915288345182871
Validation loss: 2.663047422242774

Epoch: 6| Step: 8
Training loss: 2.900435342668744
Validation loss: 2.6601285747643484

Epoch: 6| Step: 9
Training loss: 2.8030506341057846
Validation loss: 2.660395389743898

Epoch: 6| Step: 10
Training loss: 2.735510715592624
Validation loss: 2.6673061596835725

Epoch: 6| Step: 11
Training loss: 2.7444674585727102
Validation loss: 2.6603233264816852

Epoch: 6| Step: 12
Training loss: 2.765450682238089
Validation loss: 2.658348429189504

Epoch: 6| Step: 13
Training loss: 3.310228972798703
Validation loss: 2.6598305511782776

Epoch: 152| Step: 0
Training loss: 3.196147483163263
Validation loss: 2.65791400131731

Epoch: 6| Step: 1
Training loss: 3.3565649300404776
Validation loss: 2.656118679480077

Epoch: 6| Step: 2
Training loss: 2.7476363861693573
Validation loss: 2.65790407627407

Epoch: 6| Step: 3
Training loss: 3.186253621880144
Validation loss: 2.6570248269370857

Epoch: 6| Step: 4
Training loss: 3.175807976229023
Validation loss: 2.65924135654155

Epoch: 6| Step: 5
Training loss: 3.053736389854354
Validation loss: 2.6622057090262796

Epoch: 6| Step: 6
Training loss: 2.6605515599437077
Validation loss: 2.6722312008093154

Epoch: 6| Step: 7
Training loss: 1.9208647390957774
Validation loss: 2.6924311753349848

Epoch: 6| Step: 8
Training loss: 3.453793560226934
Validation loss: 2.7081119841306593

Epoch: 6| Step: 9
Training loss: 3.1846600016598123
Validation loss: 2.7327023595245388

Epoch: 6| Step: 10
Training loss: 3.241214321188728
Validation loss: 2.726714712244611

Epoch: 6| Step: 11
Training loss: 3.141254418913059
Validation loss: 2.660334113642331

Epoch: 6| Step: 12
Training loss: 2.717947128837095
Validation loss: 2.6617375381848616

Epoch: 6| Step: 13
Training loss: 2.4397529558284448
Validation loss: 2.6662821691199574

Epoch: 153| Step: 0
Training loss: 2.774548976777331
Validation loss: 2.680191812948616

Epoch: 6| Step: 1
Training loss: 3.5079234218264284
Validation loss: 2.7095548706852703

Epoch: 6| Step: 2
Training loss: 3.300143244553229
Validation loss: 2.70487826367086

Epoch: 6| Step: 3
Training loss: 2.9925199080006593
Validation loss: 2.729134083578176

Epoch: 6| Step: 4
Training loss: 2.790190054733624
Validation loss: 2.723582258015512

Epoch: 6| Step: 5
Training loss: 3.0278159283986614
Validation loss: 2.7351040554107104

Epoch: 6| Step: 6
Training loss: 2.911800212042975
Validation loss: 2.726420335735941

Epoch: 6| Step: 7
Training loss: 3.160957979747824
Validation loss: 2.7191715321518624

Epoch: 6| Step: 8
Training loss: 3.0436189909201263
Validation loss: 2.6967399100108

Epoch: 6| Step: 9
Training loss: 2.423143411546234
Validation loss: 2.682179685302658

Epoch: 6| Step: 10
Training loss: 2.774176872450838
Validation loss: 2.682096306272978

Epoch: 6| Step: 11
Training loss: 3.081776114033725
Validation loss: 2.6713814065102004

Epoch: 6| Step: 12
Training loss: 3.5425201434826
Validation loss: 2.67100425798988

Epoch: 6| Step: 13
Training loss: 3.484062694016134
Validation loss: 2.663470701382941

Epoch: 154| Step: 0
Training loss: 3.360549792313188
Validation loss: 2.6660763628107773

Epoch: 6| Step: 1
Training loss: 2.7839713338110523
Validation loss: 2.6547540726689065

Epoch: 6| Step: 2
Training loss: 2.8633771726770143
Validation loss: 2.6678076384208858

Epoch: 6| Step: 3
Training loss: 2.554965782757572
Validation loss: 2.662630705817324

Epoch: 6| Step: 4
Training loss: 2.648338203481714
Validation loss: 2.6809688276598194

Epoch: 6| Step: 5
Training loss: 3.5073516475003803
Validation loss: 2.6955327406955987

Epoch: 6| Step: 6
Training loss: 3.374988979745463
Validation loss: 2.722567334634889

Epoch: 6| Step: 7
Training loss: 3.207547145149155
Validation loss: 2.72961254245996

Epoch: 6| Step: 8
Training loss: 2.613549188811109
Validation loss: 2.716054402075496

Epoch: 6| Step: 9
Training loss: 2.8060940161770263
Validation loss: 2.693830812201977

Epoch: 6| Step: 10
Training loss: 2.8730118552951542
Validation loss: 2.6835784546270736

Epoch: 6| Step: 11
Training loss: 2.9195452699230207
Validation loss: 2.6808831407934988

Epoch: 6| Step: 12
Training loss: 3.141757590060014
Validation loss: 2.6711189213958546

Epoch: 6| Step: 13
Training loss: 3.2348272772170903
Validation loss: 2.6753950100887036

Epoch: 155| Step: 0
Training loss: 2.5765200156277026
Validation loss: 2.6727252867297833

Epoch: 6| Step: 1
Training loss: 2.1746232462831685
Validation loss: 2.673158947491055

Epoch: 6| Step: 2
Training loss: 2.8765133730761345
Validation loss: 2.6945487018686127

Epoch: 6| Step: 3
Training loss: 3.014425879327274
Validation loss: 2.753379585351177

Epoch: 6| Step: 4
Training loss: 3.476947068793175
Validation loss: 2.752188741908074

Epoch: 6| Step: 5
Training loss: 3.3988527943091054
Validation loss: 2.754587290764318

Epoch: 6| Step: 6
Training loss: 2.6509885851349164
Validation loss: 2.7521701828072884

Epoch: 6| Step: 7
Training loss: 3.21047769860229
Validation loss: 2.7706730016162426

Epoch: 6| Step: 8
Training loss: 3.3548084537500107
Validation loss: 2.7870534806205596

Epoch: 6| Step: 9
Training loss: 3.336011398890572
Validation loss: 2.7830822900383945

Epoch: 6| Step: 10
Training loss: 2.9525242754578613
Validation loss: 2.7499645777161468

Epoch: 6| Step: 11
Training loss: 3.1703877086188412
Validation loss: 2.685647704378554

Epoch: 6| Step: 12
Training loss: 2.566973247630901
Validation loss: 2.681503898634521

Epoch: 6| Step: 13
Training loss: 3.6633473168043453
Validation loss: 2.68646522560564

Epoch: 156| Step: 0
Training loss: 2.97889309851952
Validation loss: 2.69794111628367

Epoch: 6| Step: 1
Training loss: 2.6972628848250473
Validation loss: 2.7386774269757153

Epoch: 6| Step: 2
Training loss: 2.945401541985451
Validation loss: 2.7094136373454516

Epoch: 6| Step: 3
Training loss: 3.360432303183956
Validation loss: 2.6769193258538317

Epoch: 6| Step: 4
Training loss: 3.5441370407888577
Validation loss: 2.669466726746848

Epoch: 6| Step: 5
Training loss: 2.4087527252007646
Validation loss: 2.6691368958219504

Epoch: 6| Step: 6
Training loss: 2.866543149135295
Validation loss: 2.6614432925165796

Epoch: 6| Step: 7
Training loss: 2.2965220485088116
Validation loss: 2.6560552980508074

Epoch: 6| Step: 8
Training loss: 3.3614783511153377
Validation loss: 2.6627240238229515

Epoch: 6| Step: 9
Training loss: 3.2231360615822857
Validation loss: 2.6678614503457103

Epoch: 6| Step: 10
Training loss: 2.760518677943849
Validation loss: 2.6628674148245817

Epoch: 6| Step: 11
Training loss: 2.82953772904176
Validation loss: 2.668629958649537

Epoch: 6| Step: 12
Training loss: 3.2298741375756546
Validation loss: 2.6759213373699398

Epoch: 6| Step: 13
Training loss: 3.4788773620077693
Validation loss: 2.67733172418328

Epoch: 157| Step: 0
Training loss: 3.4840056219307423
Validation loss: 2.686527196325722

Epoch: 6| Step: 1
Training loss: 2.2665167796374086
Validation loss: 2.676420432726473

Epoch: 6| Step: 2
Training loss: 3.7041558870917495
Validation loss: 2.661103387334851

Epoch: 6| Step: 3
Training loss: 2.4754295284662886
Validation loss: 2.661836372418837

Epoch: 6| Step: 4
Training loss: 2.818384837923134
Validation loss: 2.654688896252177

Epoch: 6| Step: 5
Training loss: 2.918981741419134
Validation loss: 2.6522618813835876

Epoch: 6| Step: 6
Training loss: 3.1149677222280268
Validation loss: 2.652741418643843

Epoch: 6| Step: 7
Training loss: 3.38228555499998
Validation loss: 2.6524618779968248

Epoch: 6| Step: 8
Training loss: 3.140573833295497
Validation loss: 2.6556001837117935

Epoch: 6| Step: 9
Training loss: 3.109020730544282
Validation loss: 2.656527245739145

Epoch: 6| Step: 10
Training loss: 2.821919076095856
Validation loss: 2.6496156131627973

Epoch: 6| Step: 11
Training loss: 3.0361907649161166
Validation loss: 2.6541111325521443

Epoch: 6| Step: 12
Training loss: 2.6630939054072678
Validation loss: 2.656500021974356

Epoch: 6| Step: 13
Training loss: 2.3680988231993165
Validation loss: 2.661454017342994

Epoch: 158| Step: 0
Training loss: 3.212265742329053
Validation loss: 2.666325282605109

Epoch: 6| Step: 1
Training loss: 3.426717597592825
Validation loss: 2.6640719921595037

Epoch: 6| Step: 2
Training loss: 3.027435734489643
Validation loss: 2.6701599404315717

Epoch: 6| Step: 3
Training loss: 3.384729278422132
Validation loss: 2.6679243283666585

Epoch: 6| Step: 4
Training loss: 3.6496825615788793
Validation loss: 2.6654307214855173

Epoch: 6| Step: 5
Training loss: 2.517584185892627
Validation loss: 2.671455279811619

Epoch: 6| Step: 6
Training loss: 2.3130318313631504
Validation loss: 2.6764983076657565

Epoch: 6| Step: 7
Training loss: 2.5153124123411086
Validation loss: 2.6650066233448384

Epoch: 6| Step: 8
Training loss: 2.9880070978205486
Validation loss: 2.662158158764711

Epoch: 6| Step: 9
Training loss: 3.2499634667323902
Validation loss: 2.6519702901752584

Epoch: 6| Step: 10
Training loss: 3.1908199000447337
Validation loss: 2.6548311694407722

Epoch: 6| Step: 11
Training loss: 2.5858858685366717
Validation loss: 2.648741490948361

Epoch: 6| Step: 12
Training loss: 2.595055768510748
Validation loss: 2.6514202279331474

Epoch: 6| Step: 13
Training loss: 2.569026636973761
Validation loss: 2.642476302220218

Epoch: 159| Step: 0
Training loss: 2.6649759018830146
Validation loss: 2.6458965946690087

Epoch: 6| Step: 1
Training loss: 3.1569247893593197
Validation loss: 2.645593476479365

Epoch: 6| Step: 2
Training loss: 2.593945139702624
Validation loss: 2.643313885494017

Epoch: 6| Step: 3
Training loss: 3.093180131927697
Validation loss: 2.6476401352227295

Epoch: 6| Step: 4
Training loss: 2.993104161819053
Validation loss: 2.6492050026306533

Epoch: 6| Step: 5
Training loss: 2.917147969088913
Validation loss: 2.65088817821695

Epoch: 6| Step: 6
Training loss: 3.0203635190235527
Validation loss: 2.649964256262262

Epoch: 6| Step: 7
Training loss: 3.146633947358579
Validation loss: 2.6558580798292803

Epoch: 6| Step: 8
Training loss: 3.5497453141527098
Validation loss: 2.657213505127287

Epoch: 6| Step: 9
Training loss: 2.42933951581356
Validation loss: 2.6533762008397788

Epoch: 6| Step: 10
Training loss: 2.8947328813881676
Validation loss: 2.646518389596734

Epoch: 6| Step: 11
Training loss: 3.037244238113011
Validation loss: 2.6427021394506562

Epoch: 6| Step: 12
Training loss: 2.908594313956264
Validation loss: 2.6435139704135815

Epoch: 6| Step: 13
Training loss: 3.3467372491949416
Validation loss: 2.6423274813579476

Epoch: 160| Step: 0
Training loss: 3.06342924383682
Validation loss: 2.6475271972283703

Epoch: 6| Step: 1
Training loss: 2.6957435152714684
Validation loss: 2.6451932688262474

Epoch: 6| Step: 2
Training loss: 2.954134813862448
Validation loss: 2.6504533187646886

Epoch: 6| Step: 3
Training loss: 2.9004455355702805
Validation loss: 2.6445935029745544

Epoch: 6| Step: 4
Training loss: 2.625457905385584
Validation loss: 2.645380970915202

Epoch: 6| Step: 5
Training loss: 2.7308178243312127
Validation loss: 2.643629915385385

Epoch: 6| Step: 6
Training loss: 3.198844766707459
Validation loss: 2.6470746368084925

Epoch: 6| Step: 7
Training loss: 2.9755854567504536
Validation loss: 2.63867993606059

Epoch: 6| Step: 8
Training loss: 3.4071581268653857
Validation loss: 2.6440725503253972

Epoch: 6| Step: 9
Training loss: 2.7992628762133944
Validation loss: 2.638023056173326

Epoch: 6| Step: 10
Training loss: 3.6019592728586645
Validation loss: 2.644095694105679

Epoch: 6| Step: 11
Training loss: 2.717798439209695
Validation loss: 2.6405850309320384

Epoch: 6| Step: 12
Training loss: 2.981085277301203
Validation loss: 2.6439322851807354

Epoch: 6| Step: 13
Training loss: 3.0254423212174566
Validation loss: 2.644755418989636

Epoch: 161| Step: 0
Training loss: 2.8719939397147587
Validation loss: 2.65150800782834

Epoch: 6| Step: 1
Training loss: 2.7829951265479513
Validation loss: 2.6533308633935153

Epoch: 6| Step: 2
Training loss: 2.9385701928731227
Validation loss: 2.6560312942331525

Epoch: 6| Step: 3
Training loss: 2.494147985532649
Validation loss: 2.6606378370390624

Epoch: 6| Step: 4
Training loss: 3.5179408604962674
Validation loss: 2.6758625523259263

Epoch: 6| Step: 5
Training loss: 2.8952798840517353
Validation loss: 2.680787254165793

Epoch: 6| Step: 6
Training loss: 1.8122279522060232
Validation loss: 2.686995607526117

Epoch: 6| Step: 7
Training loss: 2.791088148687077
Validation loss: 2.7084571513482203

Epoch: 6| Step: 8
Training loss: 3.202506252166577
Validation loss: 2.743661076075539

Epoch: 6| Step: 9
Training loss: 3.334218495779798
Validation loss: 2.75308852281046

Epoch: 6| Step: 10
Training loss: 3.2718878016180435
Validation loss: 2.763159630347993

Epoch: 6| Step: 11
Training loss: 3.389231030506686
Validation loss: 2.7612874433603363

Epoch: 6| Step: 12
Training loss: 2.8640337237604943
Validation loss: 2.757082874498202

Epoch: 6| Step: 13
Training loss: 3.5142964883521755
Validation loss: 2.723687028409812

Epoch: 162| Step: 0
Training loss: 3.3391378091647774
Validation loss: 2.696607901252061

Epoch: 6| Step: 1
Training loss: 2.7225216540831965
Validation loss: 2.6882132909337906

Epoch: 6| Step: 2
Training loss: 3.2111284705033443
Validation loss: 2.6807063058543554

Epoch: 6| Step: 3
Training loss: 2.655913746812078
Validation loss: 2.676085096903749

Epoch: 6| Step: 4
Training loss: 3.07324544580976
Validation loss: 2.669772574236954

Epoch: 6| Step: 5
Training loss: 3.0953432854744305
Validation loss: 2.66133601393992

Epoch: 6| Step: 6
Training loss: 3.1685346481309384
Validation loss: 2.6662113976495476

Epoch: 6| Step: 7
Training loss: 2.866059874106843
Validation loss: 2.6724209062562685

Epoch: 6| Step: 8
Training loss: 2.4155091330707577
Validation loss: 2.7042352194981136

Epoch: 6| Step: 9
Training loss: 2.878510529483463
Validation loss: 2.7297899423291323

Epoch: 6| Step: 10
Training loss: 3.1965727990469626
Validation loss: 2.7194165921446114

Epoch: 6| Step: 11
Training loss: 3.254534858717363
Validation loss: 2.7300918245940133

Epoch: 6| Step: 12
Training loss: 3.0910427694431624
Validation loss: 2.7109342365056706

Epoch: 6| Step: 13
Training loss: 3.3548995613265915
Validation loss: 2.699351897061127

Epoch: 163| Step: 0
Training loss: 2.962379124746755
Validation loss: 2.652113291605181

Epoch: 6| Step: 1
Training loss: 3.494585890569843
Validation loss: 2.6392514507775533

Epoch: 6| Step: 2
Training loss: 3.1883995432409136
Validation loss: 2.634777148275302

Epoch: 6| Step: 3
Training loss: 2.633798567401509
Validation loss: 2.6352935743462496

Epoch: 6| Step: 4
Training loss: 2.7255399256573987
Validation loss: 2.6475650987477946

Epoch: 6| Step: 5
Training loss: 3.0505716444780084
Validation loss: 2.672656700215125

Epoch: 6| Step: 6
Training loss: 3.9083788144543243
Validation loss: 2.6743117890754013

Epoch: 6| Step: 7
Training loss: 2.6710292079789597
Validation loss: 2.6821073499640087

Epoch: 6| Step: 8
Training loss: 2.504516336800147
Validation loss: 2.6777005003530006

Epoch: 6| Step: 9
Training loss: 3.0812673262598405
Validation loss: 2.65768140990537

Epoch: 6| Step: 10
Training loss: 2.2010143802490223
Validation loss: 2.6484746644518555

Epoch: 6| Step: 11
Training loss: 2.935538428339478
Validation loss: 2.6451091270995954

Epoch: 6| Step: 12
Training loss: 2.787222460970067
Validation loss: 2.6533055508406567

Epoch: 6| Step: 13
Training loss: 3.4086225453781696
Validation loss: 2.6639083766239056

Epoch: 164| Step: 0
Training loss: 2.9152283164591006
Validation loss: 2.6509110129869984

Epoch: 6| Step: 1
Training loss: 2.1542516100114817
Validation loss: 2.656272795432792

Epoch: 6| Step: 2
Training loss: 3.5081413131924486
Validation loss: 2.6620056643982286

Epoch: 6| Step: 3
Training loss: 3.1265480784665525
Validation loss: 2.649746814790579

Epoch: 6| Step: 4
Training loss: 3.4184126385870046
Validation loss: 2.6396384340661316

Epoch: 6| Step: 5
Training loss: 3.3557228285280503
Validation loss: 2.6360716619669526

Epoch: 6| Step: 6
Training loss: 2.6256968163736825
Validation loss: 2.626753302102622

Epoch: 6| Step: 7
Training loss: 2.952491813473895
Validation loss: 2.6305558962596742

Epoch: 6| Step: 8
Training loss: 3.0464931150903607
Validation loss: 2.6314817098237744

Epoch: 6| Step: 9
Training loss: 2.8604667538793085
Validation loss: 2.629097501940577

Epoch: 6| Step: 10
Training loss: 2.946792675822272
Validation loss: 2.6347150652190527

Epoch: 6| Step: 11
Training loss: 3.08642265272593
Validation loss: 2.632156670627686

Epoch: 6| Step: 12
Training loss: 2.709720481308452
Validation loss: 2.6329815842127573

Epoch: 6| Step: 13
Training loss: 2.705279423354056
Validation loss: 2.6327367565815054

Epoch: 165| Step: 0
Training loss: 3.0310675182669504
Validation loss: 2.6309515446519063

Epoch: 6| Step: 1
Training loss: 2.7483067935227394
Validation loss: 2.635873541837221

Epoch: 6| Step: 2
Training loss: 3.050352488926757
Validation loss: 2.627822460222575

Epoch: 6| Step: 3
Training loss: 3.4314624824813045
Validation loss: 2.633402970004529

Epoch: 6| Step: 4
Training loss: 3.0778055557790798
Validation loss: 2.6323157481747783

Epoch: 6| Step: 5
Training loss: 2.423219664355159
Validation loss: 2.632741257273365

Epoch: 6| Step: 6
Training loss: 3.1521896078814238
Validation loss: 2.6367681551991002

Epoch: 6| Step: 7
Training loss: 2.9495262541468192
Validation loss: 2.6390305970216046

Epoch: 6| Step: 8
Training loss: 2.598818411465623
Validation loss: 2.630732091224862

Epoch: 6| Step: 9
Training loss: 2.8447508675047355
Validation loss: 2.629450839891534

Epoch: 6| Step: 10
Training loss: 3.3347723397898603
Validation loss: 2.6303346925003708

Epoch: 6| Step: 11
Training loss: 3.1163985322334087
Validation loss: 2.6357531978148625

Epoch: 6| Step: 12
Training loss: 2.942487176107175
Validation loss: 2.6354244880085176

Epoch: 6| Step: 13
Training loss: 2.5952824121760227
Validation loss: 2.633793384241344

Epoch: 166| Step: 0
Training loss: 3.1625920399175276
Validation loss: 2.6461232599559383

Epoch: 6| Step: 1
Training loss: 2.7761109267726645
Validation loss: 2.6561914137110465

Epoch: 6| Step: 2
Training loss: 3.385323172036309
Validation loss: 2.6558215071351605

Epoch: 6| Step: 3
Training loss: 2.839385823475426
Validation loss: 2.65355372575723

Epoch: 6| Step: 4
Training loss: 3.1522124498290753
Validation loss: 2.64811053411374

Epoch: 6| Step: 5
Training loss: 2.210224157849582
Validation loss: 2.644175824122918

Epoch: 6| Step: 6
Training loss: 3.0886762224106246
Validation loss: 2.6457058536152

Epoch: 6| Step: 7
Training loss: 2.600288881245731
Validation loss: 2.63423457141141

Epoch: 6| Step: 8
Training loss: 3.443497298535245
Validation loss: 2.631352614787763

Epoch: 6| Step: 9
Training loss: 2.7034990349569092
Validation loss: 2.625318526452012

Epoch: 6| Step: 10
Training loss: 2.8710932517537833
Validation loss: 2.6273272150583358

Epoch: 6| Step: 11
Training loss: 3.2664440533307837
Validation loss: 2.6234826948721723

Epoch: 6| Step: 12
Training loss: 3.1066885993521667
Validation loss: 2.626238313557859

Epoch: 6| Step: 13
Training loss: 2.5717557895699437
Validation loss: 2.6268272583531607

Epoch: 167| Step: 0
Training loss: 3.18941963584684
Validation loss: 2.6211035278523296

Epoch: 6| Step: 1
Training loss: 2.8791233845248576
Validation loss: 2.6251462699347563

Epoch: 6| Step: 2
Training loss: 2.5898506544202364
Validation loss: 2.619827797379876

Epoch: 6| Step: 3
Training loss: 2.852361196204948
Validation loss: 2.620276803224731

Epoch: 6| Step: 4
Training loss: 3.2266734845375775
Validation loss: 2.6213742680325547

Epoch: 6| Step: 5
Training loss: 2.824016642956416
Validation loss: 2.619350393168663

Epoch: 6| Step: 6
Training loss: 3.554726267173563
Validation loss: 2.621244040472197

Epoch: 6| Step: 7
Training loss: 2.8696371730382246
Validation loss: 2.6204834163833426

Epoch: 6| Step: 8
Training loss: 2.7892593613505343
Validation loss: 2.6183978428085775

Epoch: 6| Step: 9
Training loss: 2.6688666110503436
Validation loss: 2.621641459901395

Epoch: 6| Step: 10
Training loss: 2.921946152417418
Validation loss: 2.6242588909268156

Epoch: 6| Step: 11
Training loss: 2.5598644566415922
Validation loss: 2.6260660109650273

Epoch: 6| Step: 12
Training loss: 3.505358953012563
Validation loss: 2.640682434634084

Epoch: 6| Step: 13
Training loss: 2.870568716609115
Validation loss: 2.639791715534031

Epoch: 168| Step: 0
Training loss: 2.6286145710218305
Validation loss: 2.65437017200134

Epoch: 6| Step: 1
Training loss: 3.3912958984418586
Validation loss: 2.680191314604845

Epoch: 6| Step: 2
Training loss: 2.7083194634498113
Validation loss: 2.655217807299581

Epoch: 6| Step: 3
Training loss: 3.39573235546921
Validation loss: 2.654668934133492

Epoch: 6| Step: 4
Training loss: 3.000138120650607
Validation loss: 2.651917100752924

Epoch: 6| Step: 5
Training loss: 3.218484960217765
Validation loss: 2.6456436529777902

Epoch: 6| Step: 6
Training loss: 2.9877303669108644
Validation loss: 2.6345910387319837

Epoch: 6| Step: 7
Training loss: 2.723252700427513
Validation loss: 2.6269845682740156

Epoch: 6| Step: 8
Training loss: 3.216340431575854
Validation loss: 2.620715259320946

Epoch: 6| Step: 9
Training loss: 2.90880497020259
Validation loss: 2.612694027331091

Epoch: 6| Step: 10
Training loss: 2.9970564706730705
Validation loss: 2.6191702201273404

Epoch: 6| Step: 11
Training loss: 2.890195742515325
Validation loss: 2.6187308259438695

Epoch: 6| Step: 12
Training loss: 2.5246366598244663
Validation loss: 2.6220343518513824

Epoch: 6| Step: 13
Training loss: 2.710405984711373
Validation loss: 2.6195742537432207

Epoch: 169| Step: 0
Training loss: 3.057333188313834
Validation loss: 2.622540022978874

Epoch: 6| Step: 1
Training loss: 3.2234856295448
Validation loss: 2.6208978752182572

Epoch: 6| Step: 2
Training loss: 2.9155542886383645
Validation loss: 2.620820575491793

Epoch: 6| Step: 3
Training loss: 2.7893735567910136
Validation loss: 2.622845280543035

Epoch: 6| Step: 4
Training loss: 2.424064384952475
Validation loss: 2.630730266965771

Epoch: 6| Step: 5
Training loss: 2.7755095142991033
Validation loss: 2.6327730024151443

Epoch: 6| Step: 6
Training loss: 3.282164237404769
Validation loss: 2.6291171384897285

Epoch: 6| Step: 7
Training loss: 2.980935876319796
Validation loss: 2.630031940820384

Epoch: 6| Step: 8
Training loss: 2.9429838248510576
Validation loss: 2.634835014924609

Epoch: 6| Step: 9
Training loss: 2.8804717032590976
Validation loss: 2.6376845591056735

Epoch: 6| Step: 10
Training loss: 3.179350064155304
Validation loss: 2.6367134529890044

Epoch: 6| Step: 11
Training loss: 2.692486417518296
Validation loss: 2.638400160007336

Epoch: 6| Step: 12
Training loss: 2.99080361019262
Validation loss: 2.644744940512129

Epoch: 6| Step: 13
Training loss: 3.4841961322941417
Validation loss: 2.6718302902129873

Epoch: 170| Step: 0
Training loss: 2.506223466309386
Validation loss: 2.6911676796647255

Epoch: 6| Step: 1
Training loss: 3.27175284579382
Validation loss: 2.7437135227041702

Epoch: 6| Step: 2
Training loss: 3.1860155126908802
Validation loss: 2.7546134055349345

Epoch: 6| Step: 3
Training loss: 3.4141307972377057
Validation loss: 2.8079588010601424

Epoch: 6| Step: 4
Training loss: 3.1630061894180472
Validation loss: 2.8116976314688733

Epoch: 6| Step: 5
Training loss: 2.6209293774430837
Validation loss: 2.7542783172968073

Epoch: 6| Step: 6
Training loss: 3.043316450319399
Validation loss: 2.697701761119192

Epoch: 6| Step: 7
Training loss: 3.537011232072998
Validation loss: 2.6704862283977397

Epoch: 6| Step: 8
Training loss: 3.0559171655323407
Validation loss: 2.6553379333969023

Epoch: 6| Step: 9
Training loss: 2.9267033955985537
Validation loss: 2.651909848468024

Epoch: 6| Step: 10
Training loss: 2.1158384409849464
Validation loss: 2.652770800299383

Epoch: 6| Step: 11
Training loss: 3.609902611684244
Validation loss: 2.651373949111967

Epoch: 6| Step: 12
Training loss: 2.531715726981865
Validation loss: 2.642380591671739

Epoch: 6| Step: 13
Training loss: 2.479765352254118
Validation loss: 2.646604136135928

Epoch: 171| Step: 0
Training loss: 3.073691025920977
Validation loss: 2.6395650484930777

Epoch: 6| Step: 1
Training loss: 3.144250399919284
Validation loss: 2.648418719140731

Epoch: 6| Step: 2
Training loss: 3.284355365320636
Validation loss: 2.647018307436035

Epoch: 6| Step: 3
Training loss: 2.840315201151895
Validation loss: 2.6482565314612554

Epoch: 6| Step: 4
Training loss: 3.0225346126420356
Validation loss: 2.65194211914685

Epoch: 6| Step: 5
Training loss: 2.372973330264683
Validation loss: 2.658426141123399

Epoch: 6| Step: 6
Training loss: 2.8761305866544475
Validation loss: 2.669306661193812

Epoch: 6| Step: 7
Training loss: 2.9300393668905405
Validation loss: 2.6813649892250235

Epoch: 6| Step: 8
Training loss: 3.650067702410153
Validation loss: 2.7011937683948877

Epoch: 6| Step: 9
Training loss: 3.3268973365218755
Validation loss: 2.719336906868051

Epoch: 6| Step: 10
Training loss: 2.910449695513521
Validation loss: 2.717681216414903

Epoch: 6| Step: 11
Training loss: 2.7656636208461567
Validation loss: 2.728254215648039

Epoch: 6| Step: 12
Training loss: 3.0670697120129446
Validation loss: 2.727853343643942

Epoch: 6| Step: 13
Training loss: 1.759158759100107
Validation loss: 2.6989679084798874

Epoch: 172| Step: 0
Training loss: 3.753334851397337
Validation loss: 2.711527821449506

Epoch: 6| Step: 1
Training loss: 2.6582163993285386
Validation loss: 2.7101714346890127

Epoch: 6| Step: 2
Training loss: 2.4928865319361004
Validation loss: 2.720646595669264

Epoch: 6| Step: 3
Training loss: 2.5704966192188006
Validation loss: 2.710599969950075

Epoch: 6| Step: 4
Training loss: 3.081565831461793
Validation loss: 2.6976060294526842

Epoch: 6| Step: 5
Training loss: 2.922748129225659
Validation loss: 2.6762077923912297

Epoch: 6| Step: 6
Training loss: 3.5365962515199056
Validation loss: 2.665306834461889

Epoch: 6| Step: 7
Training loss: 2.684539939067445
Validation loss: 2.6700457293591855

Epoch: 6| Step: 8
Training loss: 2.93308055467663
Validation loss: 2.664348626023288

Epoch: 6| Step: 9
Training loss: 2.7010012536213694
Validation loss: 2.6613089578522375

Epoch: 6| Step: 10
Training loss: 2.788690451375654
Validation loss: 2.654631520328659

Epoch: 6| Step: 11
Training loss: 3.3282453488363477
Validation loss: 2.664468783055509

Epoch: 6| Step: 12
Training loss: 3.372261773271503
Validation loss: 2.645770533324055

Epoch: 6| Step: 13
Training loss: 2.4674000006513155
Validation loss: 2.6437630344235274

Epoch: 173| Step: 0
Training loss: 2.5735829426303045
Validation loss: 2.652105384472508

Epoch: 6| Step: 1
Training loss: 3.626397356828374
Validation loss: 2.652396704213579

Epoch: 6| Step: 2
Training loss: 2.732751069815254
Validation loss: 2.6570415970089405

Epoch: 6| Step: 3
Training loss: 2.7710870803481726
Validation loss: 2.6505828414596504

Epoch: 6| Step: 4
Training loss: 3.2355698299733526
Validation loss: 2.649580745265353

Epoch: 6| Step: 5
Training loss: 2.6060369463956192
Validation loss: 2.6462895435514833

Epoch: 6| Step: 6
Training loss: 2.788299627182058
Validation loss: 2.6541366914548576

Epoch: 6| Step: 7
Training loss: 3.13142467019213
Validation loss: 2.646848147912832

Epoch: 6| Step: 8
Training loss: 2.980019631801175
Validation loss: 2.642223453224356

Epoch: 6| Step: 9
Training loss: 2.9303563689586767
Validation loss: 2.642852234203338

Epoch: 6| Step: 10
Training loss: 3.0134590553399674
Validation loss: 2.6415761841365097

Epoch: 6| Step: 11
Training loss: 3.0570527502717932
Validation loss: 2.64532126103793

Epoch: 6| Step: 12
Training loss: 3.099422302562066
Validation loss: 2.6501955061228206

Epoch: 6| Step: 13
Training loss: 2.9497845845856245
Validation loss: 2.659141924532275

Epoch: 174| Step: 0
Training loss: 2.8419483891632304
Validation loss: 2.6705850767602333

Epoch: 6| Step: 1
Training loss: 3.1990296024957385
Validation loss: 2.6872693301713446

Epoch: 6| Step: 2
Training loss: 2.8183836536062286
Validation loss: 2.667632103812777

Epoch: 6| Step: 3
Training loss: 2.3937811866899983
Validation loss: 2.6623735061862965

Epoch: 6| Step: 4
Training loss: 2.782754555408977
Validation loss: 2.6486687079690294

Epoch: 6| Step: 5
Training loss: 3.2539937349902743
Validation loss: 2.65947059621577

Epoch: 6| Step: 6
Training loss: 3.32045524739105
Validation loss: 2.6380157958176973

Epoch: 6| Step: 7
Training loss: 2.8243932393095634
Validation loss: 2.6237403769500007

Epoch: 6| Step: 8
Training loss: 3.415472861040174
Validation loss: 2.617585045624788

Epoch: 6| Step: 9
Training loss: 3.3342987252031877
Validation loss: 2.611130928559839

Epoch: 6| Step: 10
Training loss: 2.6356682839479313
Validation loss: 2.6104947731244845

Epoch: 6| Step: 11
Training loss: 3.10068666790116
Validation loss: 2.6058003738089073

Epoch: 6| Step: 12
Training loss: 2.8647095993419667
Validation loss: 2.608482132921542

Epoch: 6| Step: 13
Training loss: 2.063632076413273
Validation loss: 2.6065457466013613

Epoch: 175| Step: 0
Training loss: 3.212365494224069
Validation loss: 2.6032974384001233

Epoch: 6| Step: 1
Training loss: 2.880917306091262
Validation loss: 2.6055563630173224

Epoch: 6| Step: 2
Training loss: 3.1017755776343314
Validation loss: 2.603211768195925

Epoch: 6| Step: 3
Training loss: 2.714559899729374
Validation loss: 2.6049264940476347

Epoch: 6| Step: 4
Training loss: 3.148579255881358
Validation loss: 2.607324702644552

Epoch: 6| Step: 5
Training loss: 1.9043902095516576
Validation loss: 2.6094510324822275

Epoch: 6| Step: 6
Training loss: 3.169612133713845
Validation loss: 2.6118649058891212

Epoch: 6| Step: 7
Training loss: 3.355804106859231
Validation loss: 2.6107325646222566

Epoch: 6| Step: 8
Training loss: 2.9971815220997233
Validation loss: 2.611213736247189

Epoch: 6| Step: 9
Training loss: 2.311391410070851
Validation loss: 2.6089748905757886

Epoch: 6| Step: 10
Training loss: 3.512136398447365
Validation loss: 2.6061934169819043

Epoch: 6| Step: 11
Training loss: 2.0139936602586443
Validation loss: 2.605475173191773

Epoch: 6| Step: 12
Training loss: 3.340122144373025
Validation loss: 2.6054671628945685

Epoch: 6| Step: 13
Training loss: 3.2720330988042297
Validation loss: 2.6063269854560307

Epoch: 176| Step: 0
Training loss: 3.1076327095941143
Validation loss: 2.603049389454182

Epoch: 6| Step: 1
Training loss: 2.653434877305604
Validation loss: 2.6029445390890835

Epoch: 6| Step: 2
Training loss: 2.8343148121021353
Validation loss: 2.6009810381542966

Epoch: 6| Step: 3
Training loss: 3.1561227905019136
Validation loss: 2.6007825860043563

Epoch: 6| Step: 4
Training loss: 2.9377244904142374
Validation loss: 2.5999446845658385

Epoch: 6| Step: 5
Training loss: 2.4578291381350383
Validation loss: 2.602914264065317

Epoch: 6| Step: 6
Training loss: 3.434011180097435
Validation loss: 2.602785183265749

Epoch: 6| Step: 7
Training loss: 3.15052184974493
Validation loss: 2.60178587112029

Epoch: 6| Step: 8
Training loss: 2.8142233760753994
Validation loss: 2.6046172397454974

Epoch: 6| Step: 9
Training loss: 2.8678277155844656
Validation loss: 2.6027110624541394

Epoch: 6| Step: 10
Training loss: 3.058110107535301
Validation loss: 2.5997179059766182

Epoch: 6| Step: 11
Training loss: 2.6739701650605663
Validation loss: 2.5987686014648337

Epoch: 6| Step: 12
Training loss: 3.2381967273536585
Validation loss: 2.599699972288775

Epoch: 6| Step: 13
Training loss: 2.776335413828474
Validation loss: 2.60088800650767

Epoch: 177| Step: 0
Training loss: 2.811883986086285
Validation loss: 2.61262148828649

Epoch: 6| Step: 1
Training loss: 3.3621879688116887
Validation loss: 2.623973859751888

Epoch: 6| Step: 2
Training loss: 2.3886491177115037
Validation loss: 2.643474299114108

Epoch: 6| Step: 3
Training loss: 2.680808853102466
Validation loss: 2.6410672940601128

Epoch: 6| Step: 4
Training loss: 3.203848110546769
Validation loss: 2.648113715294419

Epoch: 6| Step: 5
Training loss: 3.3135538404173737
Validation loss: 2.641413615135014

Epoch: 6| Step: 6
Training loss: 3.171925812112248
Validation loss: 2.620554422014938

Epoch: 6| Step: 7
Training loss: 3.141335478172585
Validation loss: 2.605345088663985

Epoch: 6| Step: 8
Training loss: 2.955695431330516
Validation loss: 2.5958970216746695

Epoch: 6| Step: 9
Training loss: 2.739814535811377
Validation loss: 2.6033179382078675

Epoch: 6| Step: 10
Training loss: 2.9716798479604787
Validation loss: 2.602225223211185

Epoch: 6| Step: 11
Training loss: 2.2477036519864715
Validation loss: 2.6102222160005457

Epoch: 6| Step: 12
Training loss: 2.9926700053608197
Validation loss: 2.6086243415583685

Epoch: 6| Step: 13
Training loss: 3.5609439329229
Validation loss: 2.615062625732501

Epoch: 178| Step: 0
Training loss: 3.0072464843851225
Validation loss: 2.6111738682615133

Epoch: 6| Step: 1
Training loss: 3.4351723853420517
Validation loss: 2.612033818435198

Epoch: 6| Step: 2
Training loss: 3.2466833357281883
Validation loss: 2.6021741080210288

Epoch: 6| Step: 3
Training loss: 2.639887780203058
Validation loss: 2.606057062643432

Epoch: 6| Step: 4
Training loss: 2.4268646032526724
Validation loss: 2.6047127237739898

Epoch: 6| Step: 5
Training loss: 2.5963905405897463
Validation loss: 2.5988296290160458

Epoch: 6| Step: 6
Training loss: 2.3443970867795603
Validation loss: 2.6031176167438925

Epoch: 6| Step: 7
Training loss: 2.608730579225335
Validation loss: 2.6136617215711566

Epoch: 6| Step: 8
Training loss: 3.0913505111501163
Validation loss: 2.6320025889936276

Epoch: 6| Step: 9
Training loss: 2.987298143023642
Validation loss: 2.6460504291802263

Epoch: 6| Step: 10
Training loss: 3.27104882828302
Validation loss: 2.680776041508292

Epoch: 6| Step: 11
Training loss: 3.2326963924688856
Validation loss: 2.663555395916048

Epoch: 6| Step: 12
Training loss: 3.4319660377689365
Validation loss: 2.675599105045122

Epoch: 6| Step: 13
Training loss: 2.9975564860031887
Validation loss: 2.6645294955118786

Epoch: 179| Step: 0
Training loss: 2.8583969361223422
Validation loss: 2.6204041125355086

Epoch: 6| Step: 1
Training loss: 3.252837776161372
Validation loss: 2.5987329655143205

Epoch: 6| Step: 2
Training loss: 3.2285077971301805
Validation loss: 2.5894279105919304

Epoch: 6| Step: 3
Training loss: 2.8880055699175857
Validation loss: 2.591182115143835

Epoch: 6| Step: 4
Training loss: 3.3007543799756913
Validation loss: 2.5902773955089184

Epoch: 6| Step: 5
Training loss: 3.0790822046350743
Validation loss: 2.5933408655421606

Epoch: 6| Step: 6
Training loss: 2.6867139687014467
Validation loss: 2.593857898486691

Epoch: 6| Step: 7
Training loss: 2.2971555577417093
Validation loss: 2.606708724816094

Epoch: 6| Step: 8
Training loss: 2.9572276525140815
Validation loss: 2.6198044636770863

Epoch: 6| Step: 9
Training loss: 3.014542934003785
Validation loss: 2.618155527997324

Epoch: 6| Step: 10
Training loss: 2.711457128496424
Validation loss: 2.6070837688009245

Epoch: 6| Step: 11
Training loss: 2.6580666108291906
Validation loss: 2.6044795173669564

Epoch: 6| Step: 12
Training loss: 3.1195660458063634
Validation loss: 2.608639473005145

Epoch: 6| Step: 13
Training loss: 3.1582111271253757
Validation loss: 2.602386172755441

Epoch: 180| Step: 0
Training loss: 3.060439058606675
Validation loss: 2.6127081863691353

Epoch: 6| Step: 1
Training loss: 2.4317060224325866
Validation loss: 2.615466073553666

Epoch: 6| Step: 2
Training loss: 3.067436754589767
Validation loss: 2.6427437130042

Epoch: 6| Step: 3
Training loss: 3.586103580925604
Validation loss: 2.6749423514483253

Epoch: 6| Step: 4
Training loss: 2.9478360402075094
Validation loss: 2.7289840861360593

Epoch: 6| Step: 5
Training loss: 3.3247488744452567
Validation loss: 2.720405109706847

Epoch: 6| Step: 6
Training loss: 3.2155295251253913
Validation loss: 2.6894720444449565

Epoch: 6| Step: 7
Training loss: 2.714595558293165
Validation loss: 2.6551809554396177

Epoch: 6| Step: 8
Training loss: 2.470117986695085
Validation loss: 2.6310198522584187

Epoch: 6| Step: 9
Training loss: 3.1520185149176694
Validation loss: 2.631254252877863

Epoch: 6| Step: 10
Training loss: 3.1427128622452107
Validation loss: 2.6165703325139225

Epoch: 6| Step: 11
Training loss: 2.9613674526021008
Validation loss: 2.608264521008555

Epoch: 6| Step: 12
Training loss: 2.7714128007847396
Validation loss: 2.6032674382944223

Epoch: 6| Step: 13
Training loss: 2.632057874165023
Validation loss: 2.608656904476345

Epoch: 181| Step: 0
Training loss: 3.1334689016300943
Validation loss: 2.6140784996282584

Epoch: 6| Step: 1
Training loss: 2.9133650121414116
Validation loss: 2.620910662588794

Epoch: 6| Step: 2
Training loss: 3.1698901350555913
Validation loss: 2.615425037786367

Epoch: 6| Step: 3
Training loss: 2.573843990942239
Validation loss: 2.6230377660616746

Epoch: 6| Step: 4
Training loss: 2.457281976227669
Validation loss: 2.6146956140516635

Epoch: 6| Step: 5
Training loss: 3.239209675884045
Validation loss: 2.6147935566509974

Epoch: 6| Step: 6
Training loss: 2.78454137919404
Validation loss: 2.613937951954304

Epoch: 6| Step: 7
Training loss: 2.2555935525538526
Validation loss: 2.6105403320659457

Epoch: 6| Step: 8
Training loss: 3.3405214213344063
Validation loss: 2.6054845403180575

Epoch: 6| Step: 9
Training loss: 2.778155029958443
Validation loss: 2.6083074307432463

Epoch: 6| Step: 10
Training loss: 3.9217424712262936
Validation loss: 2.6165855894688352

Epoch: 6| Step: 11
Training loss: 3.1268082536904434
Validation loss: 2.612708544514286

Epoch: 6| Step: 12
Training loss: 2.845844712986309
Validation loss: 2.615444550562692

Epoch: 6| Step: 13
Training loss: 2.65410329801966
Validation loss: 2.619784938360244

Epoch: 182| Step: 0
Training loss: 2.632946701478157
Validation loss: 2.61776341808632

Epoch: 6| Step: 1
Training loss: 2.968908365944624
Validation loss: 2.6044806355539563

Epoch: 6| Step: 2
Training loss: 3.0844310318670183
Validation loss: 2.605762833887839

Epoch: 6| Step: 3
Training loss: 3.0227370128357327
Validation loss: 2.598190235215488

Epoch: 6| Step: 4
Training loss: 2.8533819377479097
Validation loss: 2.602653385317125

Epoch: 6| Step: 5
Training loss: 2.077302124478653
Validation loss: 2.5943273185233187

Epoch: 6| Step: 6
Training loss: 3.1174698704148427
Validation loss: 2.60382715058824

Epoch: 6| Step: 7
Training loss: 2.9137024848824487
Validation loss: 2.601348980529245

Epoch: 6| Step: 8
Training loss: 2.6857666813455663
Validation loss: 2.596169090991677

Epoch: 6| Step: 9
Training loss: 3.216977714824239
Validation loss: 2.5973801584483764

Epoch: 6| Step: 10
Training loss: 3.4135409377959407
Validation loss: 2.5987345212186295

Epoch: 6| Step: 11
Training loss: 3.0117065587768006
Validation loss: 2.59606664383353

Epoch: 6| Step: 12
Training loss: 2.7695884967692885
Validation loss: 2.589213645894319

Epoch: 6| Step: 13
Training loss: 3.3475932913238147
Validation loss: 2.5910024500109134

Epoch: 183| Step: 0
Training loss: 3.098797620351244
Validation loss: 2.596430859211802

Epoch: 6| Step: 1
Training loss: 2.8655279278303643
Validation loss: 2.59921817383592

Epoch: 6| Step: 2
Training loss: 2.612018000477898
Validation loss: 2.601801822721643

Epoch: 6| Step: 3
Training loss: 3.049043636781708
Validation loss: 2.6002805246923115

Epoch: 6| Step: 4
Training loss: 3.2757014273287206
Validation loss: 2.5980754505722383

Epoch: 6| Step: 5
Training loss: 3.286213055065988
Validation loss: 2.599145277436804

Epoch: 6| Step: 6
Training loss: 2.9502161625690735
Validation loss: 2.604266972404599

Epoch: 6| Step: 7
Training loss: 3.265375885291188
Validation loss: 2.603629585913542

Epoch: 6| Step: 8
Training loss: 2.235916779513421
Validation loss: 2.5967116572883513

Epoch: 6| Step: 9
Training loss: 3.0116994340131225
Validation loss: 2.5942172397982577

Epoch: 6| Step: 10
Training loss: 3.3794047963582177
Validation loss: 2.5980524642217935

Epoch: 6| Step: 11
Training loss: 2.468966317658946
Validation loss: 2.5999473231984602

Epoch: 6| Step: 12
Training loss: 2.2347954841249966
Validation loss: 2.600431151489274

Epoch: 6| Step: 13
Training loss: 3.1745383820658057
Validation loss: 2.605837521634101

Epoch: 184| Step: 0
Training loss: 2.8918083449366443
Validation loss: 2.630132970437923

Epoch: 6| Step: 1
Training loss: 2.9062257170944537
Validation loss: 2.627622254636424

Epoch: 6| Step: 2
Training loss: 3.343438677689077
Validation loss: 2.6370687744479544

Epoch: 6| Step: 3
Training loss: 2.4860996042431642
Validation loss: 2.632545120461349

Epoch: 6| Step: 4
Training loss: 2.815026060156522
Validation loss: 2.6183731119202602

Epoch: 6| Step: 5
Training loss: 2.702728771651042
Validation loss: 2.5871019974865193

Epoch: 6| Step: 6
Training loss: 2.856419938455676
Validation loss: 2.5848730300676013

Epoch: 6| Step: 7
Training loss: 3.5252760596429744
Validation loss: 2.5836258738153286

Epoch: 6| Step: 8
Training loss: 2.819463628527222
Validation loss: 2.591377854817924

Epoch: 6| Step: 9
Training loss: 3.0976151491303083
Validation loss: 2.5940107661004617

Epoch: 6| Step: 10
Training loss: 2.6255421759770825
Validation loss: 2.5990975864798354

Epoch: 6| Step: 11
Training loss: 2.8689928737377697
Validation loss: 2.599020039831617

Epoch: 6| Step: 12
Training loss: 3.1573902751979444
Validation loss: 2.5950488137260077

Epoch: 6| Step: 13
Training loss: 3.2151387520804438
Validation loss: 2.5993851057631256

Epoch: 185| Step: 0
Training loss: 3.139110902419733
Validation loss: 2.596656399519289

Epoch: 6| Step: 1
Training loss: 2.799361588722122
Validation loss: 2.5955553726256255

Epoch: 6| Step: 2
Training loss: 3.3043798569495113
Validation loss: 2.595933375009899

Epoch: 6| Step: 3
Training loss: 3.548911564485864
Validation loss: 2.5939939453124925

Epoch: 6| Step: 4
Training loss: 1.9500437120282204
Validation loss: 2.593459844390258

Epoch: 6| Step: 5
Training loss: 2.735269106051456
Validation loss: 2.5925329520585634

Epoch: 6| Step: 6
Training loss: 3.232180233131847
Validation loss: 2.589075305148155

Epoch: 6| Step: 7
Training loss: 3.431419821394873
Validation loss: 2.581934855685102

Epoch: 6| Step: 8
Training loss: 2.6110489096120415
Validation loss: 2.5836451534456346

Epoch: 6| Step: 9
Training loss: 2.8987260453787673
Validation loss: 2.5839081348689916

Epoch: 6| Step: 10
Training loss: 2.761144769959342
Validation loss: 2.5918226418751873

Epoch: 6| Step: 11
Training loss: 3.1389161580419436
Validation loss: 2.5962572360579386

Epoch: 6| Step: 12
Training loss: 2.6973051362455003
Validation loss: 2.602506325020675

Epoch: 6| Step: 13
Training loss: 2.2846635336200007
Validation loss: 2.60345636406253

Epoch: 186| Step: 0
Training loss: 2.5824522751481718
Validation loss: 2.5969776975588013

Epoch: 6| Step: 1
Training loss: 3.2215688269517244
Validation loss: 2.5995588000841967

Epoch: 6| Step: 2
Training loss: 3.0333993115079063
Validation loss: 2.6023318639749857

Epoch: 6| Step: 3
Training loss: 3.314586054530886
Validation loss: 2.599331348726095

Epoch: 6| Step: 4
Training loss: 2.855674475318287
Validation loss: 2.591899198151805

Epoch: 6| Step: 5
Training loss: 2.815267091753924
Validation loss: 2.5894863382114957

Epoch: 6| Step: 6
Training loss: 3.265270159119477
Validation loss: 2.5837477250105563

Epoch: 6| Step: 7
Training loss: 2.6939281502072405
Validation loss: 2.579353486804739

Epoch: 6| Step: 8
Training loss: 2.871544129216049
Validation loss: 2.5782147155445365

Epoch: 6| Step: 9
Training loss: 2.3163954427380165
Validation loss: 2.5784382768695338

Epoch: 6| Step: 10
Training loss: 2.641412561110658
Validation loss: 2.579640583082667

Epoch: 6| Step: 11
Training loss: 3.224029951065314
Validation loss: 2.5804215132736417

Epoch: 6| Step: 12
Training loss: 3.2300687124779714
Validation loss: 2.578601093899836

Epoch: 6| Step: 13
Training loss: 2.656038343187266
Validation loss: 2.5764706630930485

Epoch: 187| Step: 0
Training loss: 2.5958421840690327
Validation loss: 2.5767389931623397

Epoch: 6| Step: 1
Training loss: 2.588986354115617
Validation loss: 2.579006100439819

Epoch: 6| Step: 2
Training loss: 2.3912167284296455
Validation loss: 2.575979649404333

Epoch: 6| Step: 3
Training loss: 2.5849195245726406
Validation loss: 2.577314838334958

Epoch: 6| Step: 4
Training loss: 2.938568894725433
Validation loss: 2.578346095295341

Epoch: 6| Step: 5
Training loss: 2.9087989048274867
Validation loss: 2.580463262653875

Epoch: 6| Step: 6
Training loss: 2.6795495000510585
Validation loss: 2.5840239119501334

Epoch: 6| Step: 7
Training loss: 3.5507974991463325
Validation loss: 2.5802380029133496

Epoch: 6| Step: 8
Training loss: 3.1861811882840554
Validation loss: 2.5805667008052584

Epoch: 6| Step: 9
Training loss: 3.0451101033266164
Validation loss: 2.591748516659305

Epoch: 6| Step: 10
Training loss: 2.582544780686385
Validation loss: 2.5918650256020928

Epoch: 6| Step: 11
Training loss: 3.6095290378216838
Validation loss: 2.597372918718679

Epoch: 6| Step: 12
Training loss: 2.937154871368434
Validation loss: 2.6085401691337884

Epoch: 6| Step: 13
Training loss: 3.2732539523794326
Validation loss: 2.6076836894270174

Epoch: 188| Step: 0
Training loss: 2.5095207124544308
Validation loss: 2.595662348650188

Epoch: 6| Step: 1
Training loss: 2.7813723247930606
Validation loss: 2.5836338158894177

Epoch: 6| Step: 2
Training loss: 2.836798250917088
Validation loss: 2.5813085326375704

Epoch: 6| Step: 3
Training loss: 2.3211522493338093
Validation loss: 2.575808286461061

Epoch: 6| Step: 4
Training loss: 2.893112514466436
Validation loss: 2.57550593466547

Epoch: 6| Step: 5
Training loss: 2.8733763048833914
Validation loss: 2.576135005953144

Epoch: 6| Step: 6
Training loss: 2.486258122971251
Validation loss: 2.577587983852801

Epoch: 6| Step: 7
Training loss: 2.918121701563648
Validation loss: 2.577923329489975

Epoch: 6| Step: 8
Training loss: 3.446743830020612
Validation loss: 2.575695133017169

Epoch: 6| Step: 9
Training loss: 3.601754470971757
Validation loss: 2.5807317100452685

Epoch: 6| Step: 10
Training loss: 2.45908889366584
Validation loss: 2.580161236758802

Epoch: 6| Step: 11
Training loss: 3.4393183667169747
Validation loss: 2.575420852041549

Epoch: 6| Step: 12
Training loss: 3.0455084450453875
Validation loss: 2.577205591717781

Epoch: 6| Step: 13
Training loss: 3.2488590585296158
Validation loss: 2.5724935111820812

Epoch: 189| Step: 0
Training loss: 2.9870310842341685
Validation loss: 2.573468695158977

Epoch: 6| Step: 1
Training loss: 3.50901369458209
Validation loss: 2.5727030400652993

Epoch: 6| Step: 2
Training loss: 2.2697215960679467
Validation loss: 2.5836525199529583

Epoch: 6| Step: 3
Training loss: 2.9475772154500106
Validation loss: 2.5820895451492594

Epoch: 6| Step: 4
Training loss: 2.58572174739589
Validation loss: 2.5859687133368547

Epoch: 6| Step: 5
Training loss: 3.088692278135469
Validation loss: 2.5948001116108044

Epoch: 6| Step: 6
Training loss: 2.6961848961791857
Validation loss: 2.5945276546793328

Epoch: 6| Step: 7
Training loss: 3.2621723522072483
Validation loss: 2.5869323791510257

Epoch: 6| Step: 8
Training loss: 2.668444299274864
Validation loss: 2.578957711010556

Epoch: 6| Step: 9
Training loss: 3.2999022267046865
Validation loss: 2.574485526344736

Epoch: 6| Step: 10
Training loss: 3.271561916058669
Validation loss: 2.571684772389784

Epoch: 6| Step: 11
Training loss: 2.98619383665326
Validation loss: 2.5750377995932094

Epoch: 6| Step: 12
Training loss: 2.2899900256277026
Validation loss: 2.573996399820629

Epoch: 6| Step: 13
Training loss: 2.7733386384778753
Validation loss: 2.571978565697051

Epoch: 190| Step: 0
Training loss: 2.7162878353540125
Validation loss: 2.5719840767670408

Epoch: 6| Step: 1
Training loss: 3.2179631132450175
Validation loss: 2.5766914740105853

Epoch: 6| Step: 2
Training loss: 3.1231673398143287
Validation loss: 2.5779023622182358

Epoch: 6| Step: 3
Training loss: 2.6821121501416565
Validation loss: 2.584011294241352

Epoch: 6| Step: 4
Training loss: 3.463467536458027
Validation loss: 2.5747725152407503

Epoch: 6| Step: 5
Training loss: 2.584111885967165
Validation loss: 2.587591794282921

Epoch: 6| Step: 6
Training loss: 2.970948700093771
Validation loss: 2.5842276077904045

Epoch: 6| Step: 7
Training loss: 2.696531423738237
Validation loss: 2.59003649568978

Epoch: 6| Step: 8
Training loss: 2.6236705138082517
Validation loss: 2.5974277437468687

Epoch: 6| Step: 9
Training loss: 3.0521795021156217
Validation loss: 2.6095052255192046

Epoch: 6| Step: 10
Training loss: 3.151361286357583
Validation loss: 2.592921316758683

Epoch: 6| Step: 11
Training loss: 2.603459946422636
Validation loss: 2.600526101119573

Epoch: 6| Step: 12
Training loss: 2.811786391538199
Validation loss: 2.590837417100241

Epoch: 6| Step: 13
Training loss: 3.201609480938082
Validation loss: 2.595917691518054

Epoch: 191| Step: 0
Training loss: 2.8545134025148173
Validation loss: 2.589936253844121

Epoch: 6| Step: 1
Training loss: 3.0043468772249664
Validation loss: 2.5861632922637003

Epoch: 6| Step: 2
Training loss: 2.4322070829291014
Validation loss: 2.5883005268863597

Epoch: 6| Step: 3
Training loss: 2.73927417553045
Validation loss: 2.590206643164187

Epoch: 6| Step: 4
Training loss: 2.8897225285681425
Validation loss: 2.5949897358320078

Epoch: 6| Step: 5
Training loss: 3.3816427626751215
Validation loss: 2.597448885031383

Epoch: 6| Step: 6
Training loss: 2.593945139702624
Validation loss: 2.5840905740589886

Epoch: 6| Step: 7
Training loss: 3.3320985096340223
Validation loss: 2.5701028440558664

Epoch: 6| Step: 8
Training loss: 3.1607721244932594
Validation loss: 2.5737709575766137

Epoch: 6| Step: 9
Training loss: 2.4541608239338033
Validation loss: 2.572708329362312

Epoch: 6| Step: 10
Training loss: 2.930732398299424
Validation loss: 2.5698617125396024

Epoch: 6| Step: 11
Training loss: 2.890316178604806
Validation loss: 2.5759089457319595

Epoch: 6| Step: 12
Training loss: 3.024188754170217
Validation loss: 2.575703420037368

Epoch: 6| Step: 13
Training loss: 3.3686582535120833
Validation loss: 2.5738238151629664

Epoch: 192| Step: 0
Training loss: 2.9737113854561774
Validation loss: 2.5717824490412937

Epoch: 6| Step: 1
Training loss: 3.4718913382653094
Validation loss: 2.5682497085108897

Epoch: 6| Step: 2
Training loss: 3.1911567207567013
Validation loss: 2.5700179895456325

Epoch: 6| Step: 3
Training loss: 2.4164008509578383
Validation loss: 2.5730049849164276

Epoch: 6| Step: 4
Training loss: 2.465613775384879
Validation loss: 2.5718259335708784

Epoch: 6| Step: 5
Training loss: 2.489341713474241
Validation loss: 2.5782025486832416

Epoch: 6| Step: 6
Training loss: 2.759847176785154
Validation loss: 2.5875299532948275

Epoch: 6| Step: 7
Training loss: 2.638045908038968
Validation loss: 2.604366871347031

Epoch: 6| Step: 8
Training loss: 4.043262179871073
Validation loss: 2.6098821465379367

Epoch: 6| Step: 9
Training loss: 2.736496979365885
Validation loss: 2.6072797482665324

Epoch: 6| Step: 10
Training loss: 2.7932430106000212
Validation loss: 2.5917637703714798

Epoch: 6| Step: 11
Training loss: 2.1765779580952334
Validation loss: 2.594645016999036

Epoch: 6| Step: 12
Training loss: 3.1803330274655797
Validation loss: 2.5891825805909234

Epoch: 6| Step: 13
Training loss: 3.2678308657111574
Validation loss: 2.5840334391822637

Epoch: 193| Step: 0
Training loss: 2.5995415063219935
Validation loss: 2.579075825586226

Epoch: 6| Step: 1
Training loss: 2.759493393912394
Validation loss: 2.572967274386373

Epoch: 6| Step: 2
Training loss: 2.507462616753052
Validation loss: 2.5705562400805286

Epoch: 6| Step: 3
Training loss: 2.2415228200751116
Validation loss: 2.5708171729163283

Epoch: 6| Step: 4
Training loss: 2.6797588550198186
Validation loss: 2.5684363012523135

Epoch: 6| Step: 5
Training loss: 2.869916651243204
Validation loss: 2.5708028659267335

Epoch: 6| Step: 6
Training loss: 2.5259658854545086
Validation loss: 2.570905253833538

Epoch: 6| Step: 7
Training loss: 3.6960343992523317
Validation loss: 2.56953115038888

Epoch: 6| Step: 8
Training loss: 2.268417321396672
Validation loss: 2.5623045455860427

Epoch: 6| Step: 9
Training loss: 3.251086566928297
Validation loss: 2.566574591868388

Epoch: 6| Step: 10
Training loss: 3.298624595926841
Validation loss: 2.5718972409061607

Epoch: 6| Step: 11
Training loss: 3.3843912929096938
Validation loss: 2.563937846522026

Epoch: 6| Step: 12
Training loss: 3.397738680845033
Validation loss: 2.5636383787493426

Epoch: 6| Step: 13
Training loss: 2.9228055563535977
Validation loss: 2.572131343254267

Epoch: 194| Step: 0
Training loss: 2.795969299633565
Validation loss: 2.570532468096945

Epoch: 6| Step: 1
Training loss: 2.5604401660044633
Validation loss: 2.5729177022527256

Epoch: 6| Step: 2
Training loss: 2.678794244853868
Validation loss: 2.574469115215707

Epoch: 6| Step: 3
Training loss: 3.4130490542535017
Validation loss: 2.579645274796898

Epoch: 6| Step: 4
Training loss: 2.7273452640770737
Validation loss: 2.5804461131317935

Epoch: 6| Step: 5
Training loss: 3.028970392122138
Validation loss: 2.587362291173877

Epoch: 6| Step: 6
Training loss: 3.0782263104956935
Validation loss: 2.606768868718221

Epoch: 6| Step: 7
Training loss: 3.512046247069183
Validation loss: 2.612049922885069

Epoch: 6| Step: 8
Training loss: 2.9258032519095125
Validation loss: 2.5985652256298484

Epoch: 6| Step: 9
Training loss: 2.7674265882615994
Validation loss: 2.5870452531587684

Epoch: 6| Step: 10
Training loss: 2.78608591793693
Validation loss: 2.5812280172627466

Epoch: 6| Step: 11
Training loss: 2.964774752933572
Validation loss: 2.5706700744767583

Epoch: 6| Step: 12
Training loss: 3.095145787270449
Validation loss: 2.568540547125634

Epoch: 6| Step: 13
Training loss: 1.5044694910933678
Validation loss: 2.5696837182915346

Epoch: 195| Step: 0
Training loss: 2.876418385788573
Validation loss: 2.564310905128583

Epoch: 6| Step: 1
Training loss: 3.1143746364592526
Validation loss: 2.5656848047710548

Epoch: 6| Step: 2
Training loss: 3.1055716251631607
Validation loss: 2.5596900077473217

Epoch: 6| Step: 3
Training loss: 3.2110969893670402
Validation loss: 2.56124437784869

Epoch: 6| Step: 4
Training loss: 2.5021358902678927
Validation loss: 2.5611718210024

Epoch: 6| Step: 5
Training loss: 3.2106942411846036
Validation loss: 2.5643694081653035

Epoch: 6| Step: 6
Training loss: 3.518517419097312
Validation loss: 2.5624845580829523

Epoch: 6| Step: 7
Training loss: 2.4597239575151666
Validation loss: 2.5633765741508485

Epoch: 6| Step: 8
Training loss: 2.4015347739153614
Validation loss: 2.56454475832119

Epoch: 6| Step: 9
Training loss: 2.695487992475226
Validation loss: 2.5658415749738923

Epoch: 6| Step: 10
Training loss: 2.8156450277244924
Validation loss: 2.5725480711924935

Epoch: 6| Step: 11
Training loss: 2.997766935220347
Validation loss: 2.567770329548393

Epoch: 6| Step: 12
Training loss: 2.7598216057220357
Validation loss: 2.5713936712734062

Epoch: 6| Step: 13
Training loss: 3.0061864643956837
Validation loss: 2.5790388161458506

Epoch: 196| Step: 0
Training loss: 2.610339049463789
Validation loss: 2.584129330608406

Epoch: 6| Step: 1
Training loss: 3.092242403395934
Validation loss: 2.5935475843340368

Epoch: 6| Step: 2
Training loss: 3.470675097488127
Validation loss: 2.584660279268652

Epoch: 6| Step: 3
Training loss: 3.158385659004977
Validation loss: 2.591877682227786

Epoch: 6| Step: 4
Training loss: 2.635612199086001
Validation loss: 2.581993585911636

Epoch: 6| Step: 5
Training loss: 2.632112766632914
Validation loss: 2.578100245740076

Epoch: 6| Step: 6
Training loss: 2.548173818974393
Validation loss: 2.58283355898652

Epoch: 6| Step: 7
Training loss: 2.8875863264646555
Validation loss: 2.5731051660220388

Epoch: 6| Step: 8
Training loss: 2.717589382747632
Validation loss: 2.578168211494338

Epoch: 6| Step: 9
Training loss: 3.2620315858585234
Validation loss: 2.5791775282366816

Epoch: 6| Step: 10
Training loss: 2.7709420166116483
Validation loss: 2.586344250086861

Epoch: 6| Step: 11
Training loss: 3.1245197690087143
Validation loss: 2.577735571661018

Epoch: 6| Step: 12
Training loss: 3.223010160491106
Validation loss: 2.573467250696112

Epoch: 6| Step: 13
Training loss: 2.006952836467558
Validation loss: 2.5769999465969438

Epoch: 197| Step: 0
Training loss: 2.4043826499283782
Validation loss: 2.5847848439196346

Epoch: 6| Step: 1
Training loss: 3.0110120525543302
Validation loss: 2.5791305932555533

Epoch: 6| Step: 2
Training loss: 2.441194326739631
Validation loss: 2.5806025488729567

Epoch: 6| Step: 3
Training loss: 3.162872618183119
Validation loss: 2.592083525714656

Epoch: 6| Step: 4
Training loss: 2.5402939847087698
Validation loss: 2.5861181405428657

Epoch: 6| Step: 5
Training loss: 2.65761351650666
Validation loss: 2.5769221717075905

Epoch: 6| Step: 6
Training loss: 2.2570808043409123
Validation loss: 2.5700235247701424

Epoch: 6| Step: 7
Training loss: 3.4764168355193292
Validation loss: 2.5644652831179218

Epoch: 6| Step: 8
Training loss: 2.9854734306680086
Validation loss: 2.565071587391844

Epoch: 6| Step: 9
Training loss: 3.385297677320963
Validation loss: 2.569455661728872

Epoch: 6| Step: 10
Training loss: 3.0220658692730535
Validation loss: 2.562615082620433

Epoch: 6| Step: 11
Training loss: 2.6171479634956807
Validation loss: 2.5622601900856186

Epoch: 6| Step: 12
Training loss: 3.0326339865675145
Validation loss: 2.56467769998951

Epoch: 6| Step: 13
Training loss: 3.7214730174593145
Validation loss: 2.564204864660014

Epoch: 198| Step: 0
Training loss: 3.0151907652671244
Validation loss: 2.566228317775648

Epoch: 6| Step: 1
Training loss: 3.2353073471737224
Validation loss: 2.565552847593617

Epoch: 6| Step: 2
Training loss: 2.951428768910763
Validation loss: 2.5669028202158466

Epoch: 6| Step: 3
Training loss: 3.3488493921923266
Validation loss: 2.5674657381113004

Epoch: 6| Step: 4
Training loss: 2.6709873442698138
Validation loss: 2.5680644309193736

Epoch: 6| Step: 5
Training loss: 2.89067481745501
Validation loss: 2.572500878729558

Epoch: 6| Step: 6
Training loss: 2.650879131098604
Validation loss: 2.5663856331582187

Epoch: 6| Step: 7
Training loss: 3.560308485059836
Validation loss: 2.5705962548255963

Epoch: 6| Step: 8
Training loss: 2.9274403817013126
Validation loss: 2.5734279689648063

Epoch: 6| Step: 9
Training loss: 2.969659284577861
Validation loss: 2.579444252882112

Epoch: 6| Step: 10
Training loss: 2.175583671214537
Validation loss: 2.580788514715101

Epoch: 6| Step: 11
Training loss: 2.8133247014074496
Validation loss: 2.5866847678450706

Epoch: 6| Step: 12
Training loss: 2.5252550506193847
Validation loss: 2.5880697246049396

Epoch: 6| Step: 13
Training loss: 2.5378068371998355
Validation loss: 2.5998393756955402

Epoch: 199| Step: 0
Training loss: 2.386960480930594
Validation loss: 2.5878096675147617

Epoch: 6| Step: 1
Training loss: 3.2345477808998013
Validation loss: 2.5816258600659343

Epoch: 6| Step: 2
Training loss: 2.740261346924903
Validation loss: 2.5795078043301496

Epoch: 6| Step: 3
Training loss: 1.9244282827158752
Validation loss: 2.5751637953583097

Epoch: 6| Step: 4
Training loss: 3.4322891968567237
Validation loss: 2.563206611010152

Epoch: 6| Step: 5
Training loss: 3.350560463097199
Validation loss: 2.5595708959262464

Epoch: 6| Step: 6
Training loss: 3.015352701335641
Validation loss: 2.5597257445694828

Epoch: 6| Step: 7
Training loss: 2.8124711776951976
Validation loss: 2.557749962024485

Epoch: 6| Step: 8
Training loss: 2.28189725707752
Validation loss: 2.557970172561328

Epoch: 6| Step: 9
Training loss: 3.3052089270779454
Validation loss: 2.5566581868925247

Epoch: 6| Step: 10
Training loss: 3.238868724512314
Validation loss: 2.56305050982968

Epoch: 6| Step: 11
Training loss: 2.960362199841102
Validation loss: 2.559184045118916

Epoch: 6| Step: 12
Training loss: 2.408290443786484
Validation loss: 2.553856140800921

Epoch: 6| Step: 13
Training loss: 3.3447237112214125
Validation loss: 2.559942531454978

Epoch: 200| Step: 0
Training loss: 2.814623222002536
Validation loss: 2.5588671436359256

Epoch: 6| Step: 1
Training loss: 2.644501769043808
Validation loss: 2.550388259613562

Epoch: 6| Step: 2
Training loss: 2.6701390388090775
Validation loss: 2.5529142599569594

Epoch: 6| Step: 3
Training loss: 3.2697998811574664
Validation loss: 2.556383429828163

Epoch: 6| Step: 4
Training loss: 3.01306249028684
Validation loss: 2.5614165299806846

Epoch: 6| Step: 5
Training loss: 2.9171800070831395
Validation loss: 2.5706540134653424

Epoch: 6| Step: 6
Training loss: 3.147068682168091
Validation loss: 2.565570455399538

Epoch: 6| Step: 7
Training loss: 2.89514334895292
Validation loss: 2.5744534946473374

Epoch: 6| Step: 8
Training loss: 2.04411957458586
Validation loss: 2.589003027220887

Epoch: 6| Step: 9
Training loss: 3.030886284155258
Validation loss: 2.5971163863268165

Epoch: 6| Step: 10
Training loss: 3.146425574598003
Validation loss: 2.6054077593914124

Epoch: 6| Step: 11
Training loss: 2.977408221389347
Validation loss: 2.577128568114634

Epoch: 6| Step: 12
Training loss: 2.9221684109657162
Validation loss: 2.5670329363435247

Epoch: 6| Step: 13
Training loss: 3.1575471837376075
Validation loss: 2.551823702060341

Epoch: 201| Step: 0
Training loss: 2.592723781304159
Validation loss: 2.5572770778285903

Epoch: 6| Step: 1
Training loss: 2.736131812166326
Validation loss: 2.555645306072186

Epoch: 6| Step: 2
Training loss: 2.83666713775858
Validation loss: 2.5620616289767204

Epoch: 6| Step: 3
Training loss: 3.592487279223045
Validation loss: 2.5588086740990437

Epoch: 6| Step: 4
Training loss: 2.917157776675536
Validation loss: 2.553224867735959

Epoch: 6| Step: 5
Training loss: 2.80756080106422
Validation loss: 2.556277668254598

Epoch: 6| Step: 6
Training loss: 3.0510930525981657
Validation loss: 2.559918272345938

Epoch: 6| Step: 7
Training loss: 3.138106365805715
Validation loss: 2.563062652596072

Epoch: 6| Step: 8
Training loss: 3.0453772360358946
Validation loss: 2.5710537537267033

Epoch: 6| Step: 9
Training loss: 2.385406383064681
Validation loss: 2.5613482678505566

Epoch: 6| Step: 10
Training loss: 2.593926297366491
Validation loss: 2.5573384083316806

Epoch: 6| Step: 11
Training loss: 2.977852449224203
Validation loss: 2.559023782511754

Epoch: 6| Step: 12
Training loss: 2.737145900033476
Validation loss: 2.557072130910136

Epoch: 6| Step: 13
Training loss: 3.4320412034537973
Validation loss: 2.5575426522909406

Epoch: 202| Step: 0
Training loss: 3.171838919899474
Validation loss: 2.563530770646206

Epoch: 6| Step: 1
Training loss: 2.9191869110558315
Validation loss: 2.568765404492393

Epoch: 6| Step: 2
Training loss: 2.1900341069600806
Validation loss: 2.5648097951501216

Epoch: 6| Step: 3
Training loss: 3.3321614748695016
Validation loss: 2.5908559895047167

Epoch: 6| Step: 4
Training loss: 2.726310128060943
Validation loss: 2.601002398937361

Epoch: 6| Step: 5
Training loss: 3.1635509689708443
Validation loss: 2.6228657790687055

Epoch: 6| Step: 6
Training loss: 2.6631452038349286
Validation loss: 2.6017653286953513

Epoch: 6| Step: 7
Training loss: 2.9848919964904743
Validation loss: 2.6027750194383463

Epoch: 6| Step: 8
Training loss: 2.98303879788137
Validation loss: 2.5890236748681885

Epoch: 6| Step: 9
Training loss: 2.602443877979121
Validation loss: 2.5868918203240363

Epoch: 6| Step: 10
Training loss: 3.2453785830341575
Validation loss: 2.58868912745002

Epoch: 6| Step: 11
Training loss: 2.764062472397894
Validation loss: 2.5905101659085927

Epoch: 6| Step: 12
Training loss: 2.7526158116340027
Validation loss: 2.588192850375187

Epoch: 6| Step: 13
Training loss: 2.847534846895586
Validation loss: 2.587890297101635

Epoch: 203| Step: 0
Training loss: 2.151970195719867
Validation loss: 2.5876272567249945

Epoch: 6| Step: 1
Training loss: 3.0100919731003963
Validation loss: 2.602964278384341

Epoch: 6| Step: 2
Training loss: 2.828872497576366
Validation loss: 2.628517464294512

Epoch: 6| Step: 3
Training loss: 2.5396217082511536
Validation loss: 2.6336234137642105

Epoch: 6| Step: 4
Training loss: 2.602321571294525
Validation loss: 2.662356269943593

Epoch: 6| Step: 5
Training loss: 3.4080913361412364
Validation loss: 2.6507436595016527

Epoch: 6| Step: 6
Training loss: 2.845295915550068
Validation loss: 2.626399413831208

Epoch: 6| Step: 7
Training loss: 2.7961670389773357
Validation loss: 2.579695320874054

Epoch: 6| Step: 8
Training loss: 3.1013240386231016
Validation loss: 2.5892640684200905

Epoch: 6| Step: 9
Training loss: 3.0239820359619864
Validation loss: 2.5686448077312254

Epoch: 6| Step: 10
Training loss: 3.402943117099569
Validation loss: 2.576460525806197

Epoch: 6| Step: 11
Training loss: 2.5910741952676846
Validation loss: 2.569812295980377

Epoch: 6| Step: 12
Training loss: 3.3022431696927206
Validation loss: 2.566683998323736

Epoch: 6| Step: 13
Training loss: 3.0511569721022553
Validation loss: 2.5641104427024133

Epoch: 204| Step: 0
Training loss: 2.8675896053398784
Validation loss: 2.5614969494878768

Epoch: 6| Step: 1
Training loss: 3.267792634826089
Validation loss: 2.560826605312752

Epoch: 6| Step: 2
Training loss: 2.802178155554409
Validation loss: 2.560425938202881

Epoch: 6| Step: 3
Training loss: 3.2222636775569184
Validation loss: 2.5576693104365122

Epoch: 6| Step: 4
Training loss: 2.6547916672573963
Validation loss: 2.5530250762215894

Epoch: 6| Step: 5
Training loss: 2.604267169284609
Validation loss: 2.5522087218718625

Epoch: 6| Step: 6
Training loss: 3.1111495738452373
Validation loss: 2.55492902210323

Epoch: 6| Step: 7
Training loss: 3.1373659751200242
Validation loss: 2.5601666980191893

Epoch: 6| Step: 8
Training loss: 2.93804845356831
Validation loss: 2.5624107917566437

Epoch: 6| Step: 9
Training loss: 2.7210387319368836
Validation loss: 2.565448767114178

Epoch: 6| Step: 10
Training loss: 3.269053288643625
Validation loss: 2.585281370619183

Epoch: 6| Step: 11
Training loss: 2.589911872807863
Validation loss: 2.6184088545826962

Epoch: 6| Step: 12
Training loss: 2.8183795930873474
Validation loss: 2.62172602233269

Epoch: 6| Step: 13
Training loss: 2.6273965340812655
Validation loss: 2.626269852267625

Epoch: 205| Step: 0
Training loss: 2.6257306853093105
Validation loss: 2.637193231705473

Epoch: 6| Step: 1
Training loss: 3.4709096148390732
Validation loss: 2.6645042614428096

Epoch: 6| Step: 2
Training loss: 2.6770626814425387
Validation loss: 2.6514318422308523

Epoch: 6| Step: 3
Training loss: 2.621622728616986
Validation loss: 2.620406349993312

Epoch: 6| Step: 4
Training loss: 3.1861686169963788
Validation loss: 2.5749207811508237

Epoch: 6| Step: 5
Training loss: 2.9993282201751224
Validation loss: 2.5647515430544336

Epoch: 6| Step: 6
Training loss: 3.030219148573071
Validation loss: 2.554306457949287

Epoch: 6| Step: 7
Training loss: 3.27669492352999
Validation loss: 2.55308143999389

Epoch: 6| Step: 8
Training loss: 2.683026693921514
Validation loss: 2.5558832877293094

Epoch: 6| Step: 9
Training loss: 2.393834571240831
Validation loss: 2.5651531225846083

Epoch: 6| Step: 10
Training loss: 3.1123877263788913
Validation loss: 2.5622728188547357

Epoch: 6| Step: 11
Training loss: 2.2535122902287252
Validation loss: 2.5614096850331616

Epoch: 6| Step: 12
Training loss: 2.8398239365926767
Validation loss: 2.5709095027897004

Epoch: 6| Step: 13
Training loss: 3.6258641232482485
Validation loss: 2.5717046290072143

Epoch: 206| Step: 0
Training loss: 3.1799484258344184
Validation loss: 2.572443233310797

Epoch: 6| Step: 1
Training loss: 2.568948586762815
Validation loss: 2.5718643536138814

Epoch: 6| Step: 2
Training loss: 2.6575248800352917
Validation loss: 2.5844560704715875

Epoch: 6| Step: 3
Training loss: 3.015086862252275
Validation loss: 2.5658915635702644

Epoch: 6| Step: 4
Training loss: 2.9596250337798153
Validation loss: 2.563605715512509

Epoch: 6| Step: 5
Training loss: 2.836615363201363
Validation loss: 2.5599729761913586

Epoch: 6| Step: 6
Training loss: 3.0967180291204883
Validation loss: 2.557723478033392

Epoch: 6| Step: 7
Training loss: 2.879485239013949
Validation loss: 2.558347266914391

Epoch: 6| Step: 8
Training loss: 3.2130558052618774
Validation loss: 2.554304298084341

Epoch: 6| Step: 9
Training loss: 1.6177964100766162
Validation loss: 2.5534694909400137

Epoch: 6| Step: 10
Training loss: 2.9373892905292975
Validation loss: 2.5510025947238497

Epoch: 6| Step: 11
Training loss: 2.981466423832069
Validation loss: 2.5572040705678876

Epoch: 6| Step: 12
Training loss: 3.1039669988195335
Validation loss: 2.552881283771185

Epoch: 6| Step: 13
Training loss: 3.4177963126145308
Validation loss: 2.5586395707951652

Epoch: 207| Step: 0
Training loss: 2.826241893731378
Validation loss: 2.5591680993494634

Epoch: 6| Step: 1
Training loss: 2.7049594894450038
Validation loss: 2.5611211056613223

Epoch: 6| Step: 2
Training loss: 3.61874389120848
Validation loss: 2.5733646339794602

Epoch: 6| Step: 3
Training loss: 2.667046539747333
Validation loss: 2.5721385598429647

Epoch: 6| Step: 4
Training loss: 2.8395643346033848
Validation loss: 2.571380715422127

Epoch: 6| Step: 5
Training loss: 2.980497387589729
Validation loss: 2.575296530299469

Epoch: 6| Step: 6
Training loss: 3.0596967050676693
Validation loss: 2.5814057488075335

Epoch: 6| Step: 7
Training loss: 2.792114212449073
Validation loss: 2.5787891495790527

Epoch: 6| Step: 8
Training loss: 2.9007901003307284
Validation loss: 2.5749340208612552

Epoch: 6| Step: 9
Training loss: 2.7781456756680623
Validation loss: 2.574740850540147

Epoch: 6| Step: 10
Training loss: 3.2018087520443768
Validation loss: 2.56654458003973

Epoch: 6| Step: 11
Training loss: 2.946702057667622
Validation loss: 2.5529677632586174

Epoch: 6| Step: 12
Training loss: 2.821940789453838
Validation loss: 2.546019274932259

Epoch: 6| Step: 13
Training loss: 1.4800043912770877
Validation loss: 2.5434055771341506

Epoch: 208| Step: 0
Training loss: 2.8309462159066103
Validation loss: 2.544975486893742

Epoch: 6| Step: 1
Training loss: 3.0776063123820228
Validation loss: 2.541969139771793

Epoch: 6| Step: 2
Training loss: 3.185204071741353
Validation loss: 2.541161905805049

Epoch: 6| Step: 3
Training loss: 2.223858821408444
Validation loss: 2.538031393215344

Epoch: 6| Step: 4
Training loss: 3.2304350956152055
Validation loss: 2.5396167538280316

Epoch: 6| Step: 5
Training loss: 2.9558146504995726
Validation loss: 2.5402327129851217

Epoch: 6| Step: 6
Training loss: 2.834155655252238
Validation loss: 2.541681153128211

Epoch: 6| Step: 7
Training loss: 2.556921026300012
Validation loss: 2.540404195006748

Epoch: 6| Step: 8
Training loss: 3.1998737489113798
Validation loss: 2.548085302412978

Epoch: 6| Step: 9
Training loss: 2.661480320630012
Validation loss: 2.542371653787168

Epoch: 6| Step: 10
Training loss: 3.3844208803175464
Validation loss: 2.5444773728735903

Epoch: 6| Step: 11
Training loss: 2.589577225309387
Validation loss: 2.5587294425386817

Epoch: 6| Step: 12
Training loss: 2.665791775315011
Validation loss: 2.565248064812897

Epoch: 6| Step: 13
Training loss: 2.988276143786487
Validation loss: 2.570132833286145

Epoch: 209| Step: 0
Training loss: 2.8670537849865774
Validation loss: 2.5929604939956077

Epoch: 6| Step: 1
Training loss: 3.4980223381677127
Validation loss: 2.604583647456337

Epoch: 6| Step: 2
Training loss: 2.7697471459177163
Validation loss: 2.6144284065710117

Epoch: 6| Step: 3
Training loss: 2.8969080917953836
Validation loss: 2.597326584464273

Epoch: 6| Step: 4
Training loss: 3.094129750998756
Validation loss: 2.5672100858124414

Epoch: 6| Step: 5
Training loss: 2.153662414363947
Validation loss: 2.566325188666106

Epoch: 6| Step: 6
Training loss: 2.8233627773882866
Validation loss: 2.5566799350345084

Epoch: 6| Step: 7
Training loss: 2.842546648567053
Validation loss: 2.550366943333461

Epoch: 6| Step: 8
Training loss: 3.374318654550321
Validation loss: 2.5430275212274247

Epoch: 6| Step: 9
Training loss: 2.345109875673098
Validation loss: 2.543456364500579

Epoch: 6| Step: 10
Training loss: 2.7229430213203467
Validation loss: 2.5390653816250968

Epoch: 6| Step: 11
Training loss: 3.016350377258695
Validation loss: 2.5408163142664884

Epoch: 6| Step: 12
Training loss: 2.9845964439480825
Validation loss: 2.5410353974221787

Epoch: 6| Step: 13
Training loss: 3.025890213048203
Validation loss: 2.535746963307586

Epoch: 210| Step: 0
Training loss: 2.47198448276279
Validation loss: 2.5391883656089904

Epoch: 6| Step: 1
Training loss: 3.20523537686485
Validation loss: 2.5418546635014763

Epoch: 6| Step: 2
Training loss: 3.171638066504806
Validation loss: 2.5477666420815592

Epoch: 6| Step: 3
Training loss: 2.2826334272746833
Validation loss: 2.558972151008803

Epoch: 6| Step: 4
Training loss: 2.648192717906515
Validation loss: 2.5704915766991294

Epoch: 6| Step: 5
Training loss: 3.282337698719103
Validation loss: 2.5823527098113797

Epoch: 6| Step: 6
Training loss: 2.5933447831529537
Validation loss: 2.5949316830643974

Epoch: 6| Step: 7
Training loss: 3.062466991013115
Validation loss: 2.6119050268653377

Epoch: 6| Step: 8
Training loss: 3.3506037267725803
Validation loss: 2.6335043687159247

Epoch: 6| Step: 9
Training loss: 2.9735576050115906
Validation loss: 2.6439579415118266

Epoch: 6| Step: 10
Training loss: 2.6670150727917785
Validation loss: 2.6353837542602814

Epoch: 6| Step: 11
Training loss: 3.341967241146082
Validation loss: 2.6328141952581734

Epoch: 6| Step: 12
Training loss: 2.8935985220692566
Validation loss: 2.5961635937370575

Epoch: 6| Step: 13
Training loss: 2.204597251769807
Validation loss: 2.5586914725179324

Epoch: 211| Step: 0
Training loss: 2.975758201087227
Validation loss: 2.534405988122411

Epoch: 6| Step: 1
Training loss: 3.0125764449301284
Validation loss: 2.5523732914465174

Epoch: 6| Step: 2
Training loss: 2.8270959826200257
Validation loss: 2.5619516323674434

Epoch: 6| Step: 3
Training loss: 3.1377667378269507
Validation loss: 2.585051685198248

Epoch: 6| Step: 4
Training loss: 2.7651943582720864
Validation loss: 2.598966912462928

Epoch: 6| Step: 5
Training loss: 3.1949174632125823
Validation loss: 2.6064071804016478

Epoch: 6| Step: 6
Training loss: 3.046170979861407
Validation loss: 2.6092546118516338

Epoch: 6| Step: 7
Training loss: 3.120373467321103
Validation loss: 2.5996421331824022

Epoch: 6| Step: 8
Training loss: 2.6854869489052593
Validation loss: 2.5952457385584373

Epoch: 6| Step: 9
Training loss: 3.0102941010723807
Validation loss: 2.588671625397096

Epoch: 6| Step: 10
Training loss: 2.93567097313374
Validation loss: 2.5727599243496995

Epoch: 6| Step: 11
Training loss: 2.949548887254738
Validation loss: 2.5681636977036404

Epoch: 6| Step: 12
Training loss: 2.9289489629016607
Validation loss: 2.562929832210527

Epoch: 6| Step: 13
Training loss: 2.919600473532094
Validation loss: 2.55813094613172

Epoch: 212| Step: 0
Training loss: 3.0157952927650395
Validation loss: 2.5492090707707513

Epoch: 6| Step: 1
Training loss: 3.544239560712665
Validation loss: 2.5545011143000798

Epoch: 6| Step: 2
Training loss: 3.2218268049540786
Validation loss: 2.5507203206504374

Epoch: 6| Step: 3
Training loss: 2.51742432496661
Validation loss: 2.5593998882506908

Epoch: 6| Step: 4
Training loss: 3.2457458823832486
Validation loss: 2.581475338133883

Epoch: 6| Step: 5
Training loss: 2.6371496682019315
Validation loss: 2.6056260103321405

Epoch: 6| Step: 6
Training loss: 1.9435522855924574
Validation loss: 2.6645351759587284

Epoch: 6| Step: 7
Training loss: 3.124956512148581
Validation loss: 2.7380724559866194

Epoch: 6| Step: 8
Training loss: 2.953182966682659
Validation loss: 2.7024288007658197

Epoch: 6| Step: 9
Training loss: 2.846198065765176
Validation loss: 2.681775169611307

Epoch: 6| Step: 10
Training loss: 2.7568324781903555
Validation loss: 2.6562126731300797

Epoch: 6| Step: 11
Training loss: 2.971846080362543
Validation loss: 2.609266736100375

Epoch: 6| Step: 12
Training loss: 3.0709980983001572
Validation loss: 2.579073047312177

Epoch: 6| Step: 13
Training loss: 3.032872660382674
Validation loss: 2.5357264075686166

Epoch: 213| Step: 0
Training loss: 2.524192201173107
Validation loss: 2.5322442623272003

Epoch: 6| Step: 1
Training loss: 3.3690998638838634
Validation loss: 2.537045831598271

Epoch: 6| Step: 2
Training loss: 2.4850388125913545
Validation loss: 2.562082151034598

Epoch: 6| Step: 3
Training loss: 2.3443161344243992
Validation loss: 2.586433876785651

Epoch: 6| Step: 4
Training loss: 2.672124126041061
Validation loss: 2.6034281392645773

Epoch: 6| Step: 5
Training loss: 3.1564886928230744
Validation loss: 2.6598362869605685

Epoch: 6| Step: 6
Training loss: 3.2400457086988768
Validation loss: 2.69686779716664

Epoch: 6| Step: 7
Training loss: 2.6070158567308512
Validation loss: 2.6626887229407963

Epoch: 6| Step: 8
Training loss: 2.5930765035916323
Validation loss: 2.676382602668992

Epoch: 6| Step: 9
Training loss: 3.1345403382344665
Validation loss: 2.6521201982439537

Epoch: 6| Step: 10
Training loss: 3.6752934552797107
Validation loss: 2.6660030982073186

Epoch: 6| Step: 11
Training loss: 2.8438433956697122
Validation loss: 2.6407647763032958

Epoch: 6| Step: 12
Training loss: 3.4451630229053793
Validation loss: 2.6170895872379925

Epoch: 6| Step: 13
Training loss: 2.6905113027831815
Validation loss: 2.595570122956467

Epoch: 214| Step: 0
Training loss: 3.2140459667590986
Validation loss: 2.5655936228551983

Epoch: 6| Step: 1
Training loss: 3.490221805902102
Validation loss: 2.583223171511791

Epoch: 6| Step: 2
Training loss: 2.2101118615265167
Validation loss: 2.63099323567407

Epoch: 6| Step: 3
Training loss: 3.106737100951529
Validation loss: 2.7507116920098555

Epoch: 6| Step: 4
Training loss: 3.1937740138395907
Validation loss: 2.76219714821957

Epoch: 6| Step: 5
Training loss: 3.205187621910828
Validation loss: 2.728964277620904

Epoch: 6| Step: 6
Training loss: 2.515667079786839
Validation loss: 2.6317960940640286

Epoch: 6| Step: 7
Training loss: 3.2457939220642578
Validation loss: 2.6125305746677565

Epoch: 6| Step: 8
Training loss: 2.867237724675058
Validation loss: 2.5449590713240258

Epoch: 6| Step: 9
Training loss: 2.9177435567178542
Validation loss: 2.5357716861854587

Epoch: 6| Step: 10
Training loss: 2.69811856804338
Validation loss: 2.543429968541807

Epoch: 6| Step: 11
Training loss: 2.675728322640322
Validation loss: 2.557366211529836

Epoch: 6| Step: 12
Training loss: 2.9220363959957663
Validation loss: 2.5784997244503094

Epoch: 6| Step: 13
Training loss: 2.7437576189565345
Validation loss: 2.6069506580237656

Epoch: 215| Step: 0
Training loss: 3.006064642824705
Validation loss: 2.639400793775246

Epoch: 6| Step: 1
Training loss: 2.9991347336683294
Validation loss: 2.7034434573678303

Epoch: 6| Step: 2
Training loss: 2.7778573936073014
Validation loss: 2.733592363852418

Epoch: 6| Step: 3
Training loss: 3.243938368544633
Validation loss: 2.7041561045793463

Epoch: 6| Step: 4
Training loss: 3.4910403422043745
Validation loss: 2.7294694437761264

Epoch: 6| Step: 5
Training loss: 3.49632560770975
Validation loss: 2.702212880004835

Epoch: 6| Step: 6
Training loss: 2.8769319097147164
Validation loss: 2.684670991391822

Epoch: 6| Step: 7
Training loss: 2.635916761713582
Validation loss: 2.6545386991359474

Epoch: 6| Step: 8
Training loss: 2.819913798969423
Validation loss: 2.6366766478026777

Epoch: 6| Step: 9
Training loss: 2.356132350584937
Validation loss: 2.620189959316828

Epoch: 6| Step: 10
Training loss: 3.5674952236857314
Validation loss: 2.6118540049224404

Epoch: 6| Step: 11
Training loss: 2.5699735377392847
Validation loss: 2.606625161286501

Epoch: 6| Step: 12
Training loss: 3.174048670221914
Validation loss: 2.5965312985754494

Epoch: 6| Step: 13
Training loss: 3.1911662839135966
Validation loss: 2.6065249367900774

Epoch: 216| Step: 0
Training loss: 2.650066943492688
Validation loss: 2.6054175823360652

Epoch: 6| Step: 1
Training loss: 2.782112416489643
Validation loss: 2.617249958662568

Epoch: 6| Step: 2
Training loss: 2.633102265211608
Validation loss: 2.6137389407281906

Epoch: 6| Step: 3
Training loss: 3.078560580499064
Validation loss: 2.6198194963007033

Epoch: 6| Step: 4
Training loss: 3.3247336718371083
Validation loss: 2.609701489758206

Epoch: 6| Step: 5
Training loss: 2.578436352973769
Validation loss: 2.5886733545136864

Epoch: 6| Step: 6
Training loss: 2.9683336467910535
Validation loss: 2.5812849758759806

Epoch: 6| Step: 7
Training loss: 2.9144363777099747
Validation loss: 2.569746449651974

Epoch: 6| Step: 8
Training loss: 2.899922034432328
Validation loss: 2.5747606825933462

Epoch: 6| Step: 9
Training loss: 3.0869929959162423
Validation loss: 2.5764164627716966

Epoch: 6| Step: 10
Training loss: 2.5034161116234332
Validation loss: 2.576420035962317

Epoch: 6| Step: 11
Training loss: 3.111593250729182
Validation loss: 2.580002382524883

Epoch: 6| Step: 12
Training loss: 3.0576953177398054
Validation loss: 2.5736053795174203

Epoch: 6| Step: 13
Training loss: 3.510889144177389
Validation loss: 2.5774012708555087

Epoch: 217| Step: 0
Training loss: 2.1312647083479708
Validation loss: 2.5660974685127065

Epoch: 6| Step: 1
Training loss: 2.783957203218215
Validation loss: 2.555373053530921

Epoch: 6| Step: 2
Training loss: 3.3762716087714697
Validation loss: 2.5485669255039007

Epoch: 6| Step: 3
Training loss: 2.9364852775933445
Validation loss: 2.5420938887907285

Epoch: 6| Step: 4
Training loss: 3.027413211148686
Validation loss: 2.5392530729779565

Epoch: 6| Step: 5
Training loss: 2.8979824151031472
Validation loss: 2.5452964345334514

Epoch: 6| Step: 6
Training loss: 3.130144081577643
Validation loss: 2.5390292641457783

Epoch: 6| Step: 7
Training loss: 3.0590380349614517
Validation loss: 2.5451627091702322

Epoch: 6| Step: 8
Training loss: 2.6275912619438646
Validation loss: 2.5362518510177097

Epoch: 6| Step: 9
Training loss: 2.6351584105676458
Validation loss: 2.539781823380842

Epoch: 6| Step: 10
Training loss: 2.7877399290004017
Validation loss: 2.542561116645332

Epoch: 6| Step: 11
Training loss: 3.1031056752136186
Validation loss: 2.5350013785590995

Epoch: 6| Step: 12
Training loss: 2.9587239468728455
Validation loss: 2.537957944453824

Epoch: 6| Step: 13
Training loss: 2.800518795043665
Validation loss: 2.5372279776823206

Epoch: 218| Step: 0
Training loss: 2.6690755533877986
Validation loss: 2.5392393130446673

Epoch: 6| Step: 1
Training loss: 2.6116063976170336
Validation loss: 2.542628396974558

Epoch: 6| Step: 2
Training loss: 2.971364365921547
Validation loss: 2.547648304607901

Epoch: 6| Step: 3
Training loss: 3.260681206611947
Validation loss: 2.5519923508887867

Epoch: 6| Step: 4
Training loss: 2.733721758605455
Validation loss: 2.551461468276254

Epoch: 6| Step: 5
Training loss: 2.884942650448101
Validation loss: 2.5566740640872108

Epoch: 6| Step: 6
Training loss: 3.246299103669192
Validation loss: 2.5431275475439556

Epoch: 6| Step: 7
Training loss: 2.646910911055231
Validation loss: 2.540548071039471

Epoch: 6| Step: 8
Training loss: 2.7196756299932443
Validation loss: 2.5301044682029534

Epoch: 6| Step: 9
Training loss: 3.12747216667396
Validation loss: 2.530207037406222

Epoch: 6| Step: 10
Training loss: 2.8178118241931096
Validation loss: 2.5294790419233455

Epoch: 6| Step: 11
Training loss: 2.8779001949625576
Validation loss: 2.533175676968957

Epoch: 6| Step: 12
Training loss: 2.9345662502571717
Validation loss: 2.5274041078562828

Epoch: 6| Step: 13
Training loss: 2.7189827304192042
Validation loss: 2.5287186678547124

Epoch: 219| Step: 0
Training loss: 3.074135610772233
Validation loss: 2.5335582952511078

Epoch: 6| Step: 1
Training loss: 3.105314891530571
Validation loss: 2.5256274688146947

Epoch: 6| Step: 2
Training loss: 3.2278887445310613
Validation loss: 2.5339637787189586

Epoch: 6| Step: 3
Training loss: 2.7438074961831487
Validation loss: 2.5361897841720906

Epoch: 6| Step: 4
Training loss: 2.937191723819394
Validation loss: 2.5370842427820794

Epoch: 6| Step: 5
Training loss: 2.528134724865895
Validation loss: 2.539465170862349

Epoch: 6| Step: 6
Training loss: 3.033115717309487
Validation loss: 2.545392149638724

Epoch: 6| Step: 7
Training loss: 3.3038245262489565
Validation loss: 2.5337107415580316

Epoch: 6| Step: 8
Training loss: 2.936527497035355
Validation loss: 2.5393363144916568

Epoch: 6| Step: 9
Training loss: 2.8661933027566526
Validation loss: 2.5444736963891628

Epoch: 6| Step: 10
Training loss: 2.9818535983441588
Validation loss: 2.544513921817107

Epoch: 6| Step: 11
Training loss: 2.3245958038431365
Validation loss: 2.5519056896658134

Epoch: 6| Step: 12
Training loss: 2.5178174244724922
Validation loss: 2.5639712254350036

Epoch: 6| Step: 13
Training loss: 2.269745965934939
Validation loss: 2.5855764348812

Epoch: 220| Step: 0
Training loss: 2.8800508664195608
Validation loss: 2.6024832807759215

Epoch: 6| Step: 1
Training loss: 2.8819737648653345
Validation loss: 2.5982184162709445

Epoch: 6| Step: 2
Training loss: 2.9929618928970654
Validation loss: 2.562604708449383

Epoch: 6| Step: 3
Training loss: 2.705531289603023
Validation loss: 2.548721832647773

Epoch: 6| Step: 4
Training loss: 2.0709173506560545
Validation loss: 2.5318724579550933

Epoch: 6| Step: 5
Training loss: 3.1613694774996803
Validation loss: 2.5260195921548747

Epoch: 6| Step: 6
Training loss: 3.3708559661847293
Validation loss: 2.5220276632122296

Epoch: 6| Step: 7
Training loss: 3.049126209102878
Validation loss: 2.5210649110587875

Epoch: 6| Step: 8
Training loss: 2.2941330093628918
Validation loss: 2.526863989498354

Epoch: 6| Step: 9
Training loss: 3.1554429939354116
Validation loss: 2.522277077569285

Epoch: 6| Step: 10
Training loss: 2.9479424752946732
Validation loss: 2.5235767316566786

Epoch: 6| Step: 11
Training loss: 2.6629243360335453
Validation loss: 2.5211110071869403

Epoch: 6| Step: 12
Training loss: 3.130810942486431
Validation loss: 2.525941947556183

Epoch: 6| Step: 13
Training loss: 2.8380626775959144
Validation loss: 2.5322617949860713

Epoch: 221| Step: 0
Training loss: 2.9868270626878926
Validation loss: 2.5283095623685132

Epoch: 6| Step: 1
Training loss: 2.499112162295131
Validation loss: 2.525284659788726

Epoch: 6| Step: 2
Training loss: 2.3633704302646708
Validation loss: 2.532451816801751

Epoch: 6| Step: 3
Training loss: 2.723197543876697
Validation loss: 2.524663949878042

Epoch: 6| Step: 4
Training loss: 3.345793482890324
Validation loss: 2.529448430834916

Epoch: 6| Step: 5
Training loss: 2.9795787677419625
Validation loss: 2.5265823589039678

Epoch: 6| Step: 6
Training loss: 2.700610363811797
Validation loss: 2.53097686043364

Epoch: 6| Step: 7
Training loss: 2.641725750893179
Validation loss: 2.5239474726930444

Epoch: 6| Step: 8
Training loss: 2.7874392105111316
Validation loss: 2.5207930151219378

Epoch: 6| Step: 9
Training loss: 2.87473461750711
Validation loss: 2.522616652009409

Epoch: 6| Step: 10
Training loss: 2.9717451546559626
Validation loss: 2.5245114264282686

Epoch: 6| Step: 11
Training loss: 3.139247611223937
Validation loss: 2.523572678308816

Epoch: 6| Step: 12
Training loss: 3.2616216770734567
Validation loss: 2.523982083340315

Epoch: 6| Step: 13
Training loss: 3.073071354135374
Validation loss: 2.526642936862758

Epoch: 222| Step: 0
Training loss: 2.570935854936201
Validation loss: 2.530175150354436

Epoch: 6| Step: 1
Training loss: 2.766341553012054
Validation loss: 2.5282510634928994

Epoch: 6| Step: 2
Training loss: 3.375509859355755
Validation loss: 2.551436604534733

Epoch: 6| Step: 3
Training loss: 3.0844117074500104
Validation loss: 2.557182240666335

Epoch: 6| Step: 4
Training loss: 2.8838899247938774
Validation loss: 2.5545517101779147

Epoch: 6| Step: 5
Training loss: 3.294325579564036
Validation loss: 2.5309303048382716

Epoch: 6| Step: 6
Training loss: 3.0497523097787758
Validation loss: 2.5150976589433998

Epoch: 6| Step: 7
Training loss: 2.916832147172729
Validation loss: 2.525221274666999

Epoch: 6| Step: 8
Training loss: 2.8190701355749863
Validation loss: 2.527012442833901

Epoch: 6| Step: 9
Training loss: 2.837360287894421
Validation loss: 2.539549569361921

Epoch: 6| Step: 10
Training loss: 2.2679448319979763
Validation loss: 2.5361037464570515

Epoch: 6| Step: 11
Training loss: 2.9320312890312747
Validation loss: 2.539815551049348

Epoch: 6| Step: 12
Training loss: 3.200290821688521
Validation loss: 2.5424364888648965

Epoch: 6| Step: 13
Training loss: 2.079237790569873
Validation loss: 2.538883459248541

Epoch: 223| Step: 0
Training loss: 3.201813517718684
Validation loss: 2.539849604295566

Epoch: 6| Step: 1
Training loss: 3.0200610171084468
Validation loss: 2.5361408598351467

Epoch: 6| Step: 2
Training loss: 2.8603954057859564
Validation loss: 2.5352920088096007

Epoch: 6| Step: 3
Training loss: 3.1671225738269184
Validation loss: 2.5355260238571042

Epoch: 6| Step: 4
Training loss: 3.5375815823586687
Validation loss: 2.531721094821729

Epoch: 6| Step: 5
Training loss: 2.9887728417647286
Validation loss: 2.5297853665269114

Epoch: 6| Step: 6
Training loss: 2.516835176329505
Validation loss: 2.5261268042343064

Epoch: 6| Step: 7
Training loss: 1.7906915835372306
Validation loss: 2.525150791418466

Epoch: 6| Step: 8
Training loss: 3.124391114997855
Validation loss: 2.5220535645108346

Epoch: 6| Step: 9
Training loss: 2.6529011877978492
Validation loss: 2.522220200240021

Epoch: 6| Step: 10
Training loss: 2.730954019322159
Validation loss: 2.524264020295463

Epoch: 6| Step: 11
Training loss: 2.8714149347346147
Validation loss: 2.5286324555188147

Epoch: 6| Step: 12
Training loss: 2.814544273875345
Validation loss: 2.5350403506324852

Epoch: 6| Step: 13
Training loss: 2.924180207748855
Validation loss: 2.55261236805384

Epoch: 224| Step: 0
Training loss: 3.1037794208706924
Validation loss: 2.5795243866434285

Epoch: 6| Step: 1
Training loss: 2.7879467182842106
Validation loss: 2.6193447556693847

Epoch: 6| Step: 2
Training loss: 2.6591764597850407
Validation loss: 2.622127202255673

Epoch: 6| Step: 3
Training loss: 3.2884593419639536
Validation loss: 2.611647541484381

Epoch: 6| Step: 4
Training loss: 2.6121486153727824
Validation loss: 2.5914691148093416

Epoch: 6| Step: 5
Training loss: 3.2900189166699176
Validation loss: 2.6141748972588923

Epoch: 6| Step: 6
Training loss: 2.858462328729491
Validation loss: 2.604294567946047

Epoch: 6| Step: 7
Training loss: 2.6929808330569145
Validation loss: 2.597448839630116

Epoch: 6| Step: 8
Training loss: 3.23149504036798
Validation loss: 2.5778164964579733

Epoch: 6| Step: 9
Training loss: 2.850018310488055
Validation loss: 2.559793540202583

Epoch: 6| Step: 10
Training loss: 2.237314278337693
Validation loss: 2.5508947709147565

Epoch: 6| Step: 11
Training loss: 2.5971520414973885
Validation loss: 2.5509144788224423

Epoch: 6| Step: 12
Training loss: 3.1674464085598406
Validation loss: 2.554652642026704

Epoch: 6| Step: 13
Training loss: 3.1324534222305442
Validation loss: 2.5470807241354043

Epoch: 225| Step: 0
Training loss: 3.5951755515835524
Validation loss: 2.5394412774328563

Epoch: 6| Step: 1
Training loss: 2.2885206186550464
Validation loss: 2.5414482949499284

Epoch: 6| Step: 2
Training loss: 2.8082523058815014
Validation loss: 2.543783827294194

Epoch: 6| Step: 3
Training loss: 2.586615159596843
Validation loss: 2.541596337214003

Epoch: 6| Step: 4
Training loss: 2.549019033948336
Validation loss: 2.537546363171409

Epoch: 6| Step: 5
Training loss: 2.9311659680910456
Validation loss: 2.5426524187504853

Epoch: 6| Step: 6
Training loss: 2.815917926415922
Validation loss: 2.546011707908633

Epoch: 6| Step: 7
Training loss: 2.789524328639566
Validation loss: 2.5602751807266375

Epoch: 6| Step: 8
Training loss: 3.0118883137152404
Validation loss: 2.55678287145703

Epoch: 6| Step: 9
Training loss: 3.2524888705650343
Validation loss: 2.567348827882497

Epoch: 6| Step: 10
Training loss: 2.580088104991107
Validation loss: 2.58276395513704

Epoch: 6| Step: 11
Training loss: 3.5362788488641317
Validation loss: 2.5770829338016186

Epoch: 6| Step: 12
Training loss: 2.5728428221284583
Validation loss: 2.5874605352281144

Epoch: 6| Step: 13
Training loss: 3.2731487720406376
Validation loss: 2.5886959953369497

Epoch: 226| Step: 0
Training loss: 3.2696447136263487
Validation loss: 2.5747317389757884

Epoch: 6| Step: 1
Training loss: 2.8919369581323884
Validation loss: 2.5728827634479727

Epoch: 6| Step: 2
Training loss: 3.3758000026147594
Validation loss: 2.564208769797562

Epoch: 6| Step: 3
Training loss: 2.8824011036168002
Validation loss: 2.5493298297178932

Epoch: 6| Step: 4
Training loss: 2.746840309036841
Validation loss: 2.5445915840603117

Epoch: 6| Step: 5
Training loss: 2.853360547206314
Validation loss: 2.5367865517586403

Epoch: 6| Step: 6
Training loss: 2.9302056833402816
Validation loss: 2.5358705853961596

Epoch: 6| Step: 7
Training loss: 2.66540726088792
Validation loss: 2.530265749423918

Epoch: 6| Step: 8
Training loss: 2.8832838712062343
Validation loss: 2.5234124774734203

Epoch: 6| Step: 9
Training loss: 2.255179695023912
Validation loss: 2.5216812599977176

Epoch: 6| Step: 10
Training loss: 2.71179941860215
Validation loss: 2.5277325431829807

Epoch: 6| Step: 11
Training loss: 2.9447471015255893
Validation loss: 2.529017791066805

Epoch: 6| Step: 12
Training loss: 2.8248077664757125
Validation loss: 2.528051621554693

Epoch: 6| Step: 13
Training loss: 3.2648223912767493
Validation loss: 2.5365825214260425

Epoch: 227| Step: 0
Training loss: 2.6373973736073664
Validation loss: 2.537832551190678

Epoch: 6| Step: 1
Training loss: 3.0751264654686135
Validation loss: 2.5550356361760467

Epoch: 6| Step: 2
Training loss: 2.8349335209555275
Validation loss: 2.5653690750822067

Epoch: 6| Step: 3
Training loss: 3.0820900412247525
Validation loss: 2.5711067858285954

Epoch: 6| Step: 4
Training loss: 2.9560232321480533
Validation loss: 2.574594742006659

Epoch: 6| Step: 5
Training loss: 3.3389103170656913
Validation loss: 2.557126038464128

Epoch: 6| Step: 6
Training loss: 2.604546379380907
Validation loss: 2.554837490431653

Epoch: 6| Step: 7
Training loss: 2.706989238462558
Validation loss: 2.550208132142109

Epoch: 6| Step: 8
Training loss: 3.057612197077531
Validation loss: 2.544327877030471

Epoch: 6| Step: 9
Training loss: 2.904660518330086
Validation loss: 2.531327868658622

Epoch: 6| Step: 10
Training loss: 2.135492562286636
Validation loss: 2.5218436415713428

Epoch: 6| Step: 11
Training loss: 2.962936008736962
Validation loss: 2.521166184967337

Epoch: 6| Step: 12
Training loss: 2.9909742001996213
Validation loss: 2.524200332278916

Epoch: 6| Step: 13
Training loss: 2.9946941503598024
Validation loss: 2.517547403829737

Epoch: 228| Step: 0
Training loss: 3.2049062846701255
Validation loss: 2.5247923183327527

Epoch: 6| Step: 1
Training loss: 2.5599269509324105
Validation loss: 2.524701723902663

Epoch: 6| Step: 2
Training loss: 3.389512824552398
Validation loss: 2.5201523044877185

Epoch: 6| Step: 3
Training loss: 2.3421668236896953
Validation loss: 2.518985647434726

Epoch: 6| Step: 4
Training loss: 2.9296393225205373
Validation loss: 2.5255561594616647

Epoch: 6| Step: 5
Training loss: 2.5037605612232596
Validation loss: 2.5300798434570124

Epoch: 6| Step: 6
Training loss: 3.226243564461841
Validation loss: 2.5373980320773635

Epoch: 6| Step: 7
Training loss: 2.833481579062535
Validation loss: 2.543827913890077

Epoch: 6| Step: 8
Training loss: 2.2981260875775065
Validation loss: 2.5542758382806694

Epoch: 6| Step: 9
Training loss: 2.8234413944928956
Validation loss: 2.557114497109829

Epoch: 6| Step: 10
Training loss: 2.4917308424868336
Validation loss: 2.549370330482147

Epoch: 6| Step: 11
Training loss: 3.412298169996924
Validation loss: 2.543181305124067

Epoch: 6| Step: 12
Training loss: 2.9720387763655127
Validation loss: 2.539509407639246

Epoch: 6| Step: 13
Training loss: 3.110963348633823
Validation loss: 2.5335577822311643

Epoch: 229| Step: 0
Training loss: 2.771924446980925
Validation loss: 2.5276149945216404

Epoch: 6| Step: 1
Training loss: 3.2523293583973265
Validation loss: 2.513298480859923

Epoch: 6| Step: 2
Training loss: 2.9051912081325297
Validation loss: 2.5105516743515053

Epoch: 6| Step: 3
Training loss: 3.2052041353866234
Validation loss: 2.5107315612140018

Epoch: 6| Step: 4
Training loss: 3.1643091929775458
Validation loss: 2.507620571202085

Epoch: 6| Step: 5
Training loss: 3.069462704688101
Validation loss: 2.50873764178841

Epoch: 6| Step: 6
Training loss: 2.5171727696845534
Validation loss: 2.509144554957706

Epoch: 6| Step: 7
Training loss: 3.0926104672190977
Validation loss: 2.5050396176278587

Epoch: 6| Step: 8
Training loss: 2.2738938545408733
Validation loss: 2.5074175835275625

Epoch: 6| Step: 9
Training loss: 2.519225582536341
Validation loss: 2.509285622798018

Epoch: 6| Step: 10
Training loss: 2.957691033353433
Validation loss: 2.514230126277124

Epoch: 6| Step: 11
Training loss: 2.778952517592148
Validation loss: 2.5095755576819503

Epoch: 6| Step: 12
Training loss: 3.1414666258031705
Validation loss: 2.504568763358468

Epoch: 6| Step: 13
Training loss: 2.0395240699748647
Validation loss: 2.5080623640878086

Epoch: 230| Step: 0
Training loss: 2.916564031339166
Validation loss: 2.5092614338226027

Epoch: 6| Step: 1
Training loss: 2.324324097369607
Validation loss: 2.506656820397467

Epoch: 6| Step: 2
Training loss: 2.90357930516321
Validation loss: 2.50906546448778

Epoch: 6| Step: 3
Training loss: 2.7314364965389997
Validation loss: 2.508126335145834

Epoch: 6| Step: 4
Training loss: 2.5371439566542353
Validation loss: 2.501222704222255

Epoch: 6| Step: 5
Training loss: 3.246693322805317
Validation loss: 2.503332300376698

Epoch: 6| Step: 6
Training loss: 2.879070385999033
Validation loss: 2.505996580775324

Epoch: 6| Step: 7
Training loss: 3.4961155725575903
Validation loss: 2.5078402787852156

Epoch: 6| Step: 8
Training loss: 3.0551724646502896
Validation loss: 2.5095855197545323

Epoch: 6| Step: 9
Training loss: 2.6292783295324917
Validation loss: 2.5132988796917437

Epoch: 6| Step: 10
Training loss: 3.026235306147529
Validation loss: 2.5280034645768024

Epoch: 6| Step: 11
Training loss: 2.9636514349499437
Validation loss: 2.5113105470927812

Epoch: 6| Step: 12
Training loss: 2.3589365975016614
Validation loss: 2.508390880078989

Epoch: 6| Step: 13
Training loss: 3.046097406784802
Validation loss: 2.5087954951241502

Epoch: 231| Step: 0
Training loss: 2.6396811338961874
Validation loss: 2.5078039109426022

Epoch: 6| Step: 1
Training loss: 2.387569094951286
Validation loss: 2.5067439792561377

Epoch: 6| Step: 2
Training loss: 2.6969411158938708
Validation loss: 2.507393822311617

Epoch: 6| Step: 3
Training loss: 2.381996089967326
Validation loss: 2.508370948449232

Epoch: 6| Step: 4
Training loss: 3.161610800236622
Validation loss: 2.5039053899604102

Epoch: 6| Step: 5
Training loss: 2.7674413201676544
Validation loss: 2.511068675500309

Epoch: 6| Step: 6
Training loss: 3.2667481165742047
Validation loss: 2.5071773435829714

Epoch: 6| Step: 7
Training loss: 3.0667952952844293
Validation loss: 2.514830261786978

Epoch: 6| Step: 8
Training loss: 3.250026115899428
Validation loss: 2.5189636410197

Epoch: 6| Step: 9
Training loss: 3.1035017969916923
Validation loss: 2.5303153294039813

Epoch: 6| Step: 10
Training loss: 2.8164964891598405
Validation loss: 2.5308850864836847

Epoch: 6| Step: 11
Training loss: 2.745332311169047
Validation loss: 2.5260693041895697

Epoch: 6| Step: 12
Training loss: 2.9184259467586062
Validation loss: 2.540863668427457

Epoch: 6| Step: 13
Training loss: 2.732506773190772
Validation loss: 2.5518688507728102

Epoch: 232| Step: 0
Training loss: 3.078588460509083
Validation loss: 2.5460754383602464

Epoch: 6| Step: 1
Training loss: 2.8115052901355106
Validation loss: 2.5457676283714896

Epoch: 6| Step: 2
Training loss: 2.808875057897974
Validation loss: 2.542473783562063

Epoch: 6| Step: 3
Training loss: 2.816054746832562
Validation loss: 2.5417286323835637

Epoch: 6| Step: 4
Training loss: 2.5055540378995453
Validation loss: 2.5261086495114125

Epoch: 6| Step: 5
Training loss: 2.688863896112789
Validation loss: 2.5229894830290593

Epoch: 6| Step: 6
Training loss: 2.795683026051652
Validation loss: 2.5232528587986063

Epoch: 6| Step: 7
Training loss: 3.19997358907291
Validation loss: 2.534611796814444

Epoch: 6| Step: 8
Training loss: 2.8326403574497983
Validation loss: 2.53179555989474

Epoch: 6| Step: 9
Training loss: 2.961671602341277
Validation loss: 2.534609277283838

Epoch: 6| Step: 10
Training loss: 2.9772648821164185
Validation loss: 2.539375560256537

Epoch: 6| Step: 11
Training loss: 2.9252510354327357
Validation loss: 2.533864718579012

Epoch: 6| Step: 12
Training loss: 3.004126254236263
Validation loss: 2.540772689500127

Epoch: 6| Step: 13
Training loss: 2.6892666000587235
Validation loss: 2.5353801550110897

Epoch: 233| Step: 0
Training loss: 2.0913151489981607
Validation loss: 2.540239174979736

Epoch: 6| Step: 1
Training loss: 3.3351889849280725
Validation loss: 2.543185981943517

Epoch: 6| Step: 2
Training loss: 2.763401926828234
Validation loss: 2.537519532936787

Epoch: 6| Step: 3
Training loss: 3.1740381541083202
Validation loss: 2.534270564230129

Epoch: 6| Step: 4
Training loss: 3.0602548894501127
Validation loss: 2.5334362714926364

Epoch: 6| Step: 5
Training loss: 3.126755030860309
Validation loss: 2.5424933767595954

Epoch: 6| Step: 6
Training loss: 3.5549392778707407
Validation loss: 2.538514352195943

Epoch: 6| Step: 7
Training loss: 2.4977343783599784
Validation loss: 2.5374582214973542

Epoch: 6| Step: 8
Training loss: 2.6774288701601106
Validation loss: 2.5463899469746942

Epoch: 6| Step: 9
Training loss: 3.1095738946378777
Validation loss: 2.5660380507663967

Epoch: 6| Step: 10
Training loss: 2.4801696116375256
Validation loss: 2.5805237122703946

Epoch: 6| Step: 11
Training loss: 2.6984909997704802
Validation loss: 2.5920003333611845

Epoch: 6| Step: 12
Training loss: 2.5195773334872276
Validation loss: 2.5808817285246852

Epoch: 6| Step: 13
Training loss: 2.3546203806220696
Validation loss: 2.582019776282551

Epoch: 234| Step: 0
Training loss: 2.465150937920134
Validation loss: 2.56159839430772

Epoch: 6| Step: 1
Training loss: 2.8871774270346156
Validation loss: 2.5564496424090195

Epoch: 6| Step: 2
Training loss: 2.5688325743385674
Validation loss: 2.5412920738508484

Epoch: 6| Step: 3
Training loss: 2.9264466123757407
Validation loss: 2.534676708000662

Epoch: 6| Step: 4
Training loss: 3.1737222037613737
Validation loss: 2.5351970166303097

Epoch: 6| Step: 5
Training loss: 3.1168671636978202
Validation loss: 2.537686509837549

Epoch: 6| Step: 6
Training loss: 3.1265297769323936
Validation loss: 2.5354746317413976

Epoch: 6| Step: 7
Training loss: 2.8077915197234997
Validation loss: 2.535674877970167

Epoch: 6| Step: 8
Training loss: 3.1568385415850333
Validation loss: 2.537881872229486

Epoch: 6| Step: 9
Training loss: 2.4441264143121124
Validation loss: 2.5295165950596927

Epoch: 6| Step: 10
Training loss: 3.1089007912184448
Validation loss: 2.5219374767202485

Epoch: 6| Step: 11
Training loss: 2.687628898190907
Validation loss: 2.5231137342454826

Epoch: 6| Step: 12
Training loss: 3.0187867346003467
Validation loss: 2.530065638459074

Epoch: 6| Step: 13
Training loss: 1.935171142816507
Validation loss: 2.5160370483339207

Epoch: 235| Step: 0
Training loss: 3.189901905524701
Validation loss: 2.527935153068334

Epoch: 6| Step: 1
Training loss: 2.8069683353498553
Validation loss: 2.5326135655065216

Epoch: 6| Step: 2
Training loss: 2.789253292450035
Validation loss: 2.537906888463743

Epoch: 6| Step: 3
Training loss: 2.9199489834653
Validation loss: 2.545762201027776

Epoch: 6| Step: 4
Training loss: 2.8017004571617137
Validation loss: 2.55454645855385

Epoch: 6| Step: 5
Training loss: 3.2122618828184906
Validation loss: 2.5579525284740243

Epoch: 6| Step: 6
Training loss: 2.7897013298607183
Validation loss: 2.5545073665821887

Epoch: 6| Step: 7
Training loss: 2.677870954929928
Validation loss: 2.558003446944298

Epoch: 6| Step: 8
Training loss: 2.636528042148407
Validation loss: 2.5741907374326347

Epoch: 6| Step: 9
Training loss: 2.9484084475106314
Validation loss: 2.5712439467025714

Epoch: 6| Step: 10
Training loss: 2.340232956856731
Validation loss: 2.5519387759030217

Epoch: 6| Step: 11
Training loss: 3.2546240849390173
Validation loss: 2.5372760272770405

Epoch: 6| Step: 12
Training loss: 1.8488241299203811
Validation loss: 2.5222691496423493

Epoch: 6| Step: 13
Training loss: 3.888661329484069
Validation loss: 2.517672470426373

Epoch: 236| Step: 0
Training loss: 3.0188094802588297
Validation loss: 2.517533280865598

Epoch: 6| Step: 1
Training loss: 2.6854908552395855
Validation loss: 2.5151892230911193

Epoch: 6| Step: 2
Training loss: 2.316859594951957
Validation loss: 2.5160830735512607

Epoch: 6| Step: 3
Training loss: 3.3334110886723805
Validation loss: 2.5178619479099154

Epoch: 6| Step: 4
Training loss: 2.8708343181045533
Validation loss: 2.5204575920575967

Epoch: 6| Step: 5
Training loss: 2.684877224748852
Validation loss: 2.518401812374741

Epoch: 6| Step: 6
Training loss: 2.7856244607214076
Validation loss: 2.534638325064174

Epoch: 6| Step: 7
Training loss: 2.4097142239259846
Validation loss: 2.528183648988387

Epoch: 6| Step: 8
Training loss: 3.316645205889971
Validation loss: 2.5390554130461607

Epoch: 6| Step: 9
Training loss: 2.8452818381319136
Validation loss: 2.5539789756747067

Epoch: 6| Step: 10
Training loss: 3.042077772672453
Validation loss: 2.5524831439006017

Epoch: 6| Step: 11
Training loss: 2.7383636157481392
Validation loss: 2.5486849990343172

Epoch: 6| Step: 12
Training loss: 3.238778328103631
Validation loss: 2.536479927539258

Epoch: 6| Step: 13
Training loss: 2.5606718287470134
Validation loss: 2.539073889164903

Epoch: 237| Step: 0
Training loss: 2.9308640215751853
Validation loss: 2.5223576808108263

Epoch: 6| Step: 1
Training loss: 3.224411069339576
Validation loss: 2.5128703805188937

Epoch: 6| Step: 2
Training loss: 3.5858429540998147
Validation loss: 2.5130111157722856

Epoch: 6| Step: 3
Training loss: 2.892736045549893
Validation loss: 2.509327965203654

Epoch: 6| Step: 4
Training loss: 2.9718592373563313
Validation loss: 2.5087854686025666

Epoch: 6| Step: 5
Training loss: 2.6114050911607682
Validation loss: 2.5060423505098552

Epoch: 6| Step: 6
Training loss: 2.8747726018786612
Validation loss: 2.5116133976140227

Epoch: 6| Step: 7
Training loss: 2.0946556523909856
Validation loss: 2.5120891143034707

Epoch: 6| Step: 8
Training loss: 2.7254099336311683
Validation loss: 2.5045807080626803

Epoch: 6| Step: 9
Training loss: 2.920567347396096
Validation loss: 2.5107210431172406

Epoch: 6| Step: 10
Training loss: 2.677030708795198
Validation loss: 2.5050050758207396

Epoch: 6| Step: 11
Training loss: 2.6033962076420183
Validation loss: 2.5052859925540494

Epoch: 6| Step: 12
Training loss: 3.2764414112307927
Validation loss: 2.524368513139115

Epoch: 6| Step: 13
Training loss: 2.481946898249679
Validation loss: 2.5240195567661767

Epoch: 238| Step: 0
Training loss: 2.2677174343848785
Validation loss: 2.5302681061033865

Epoch: 6| Step: 1
Training loss: 3.0361108248439916
Validation loss: 2.5498204686220167

Epoch: 6| Step: 2
Training loss: 2.2855497624586527
Validation loss: 2.534225737283152

Epoch: 6| Step: 3
Training loss: 2.9196370575973485
Validation loss: 2.5405553980284874

Epoch: 6| Step: 4
Training loss: 2.5219530398408203
Validation loss: 2.537903934813389

Epoch: 6| Step: 5
Training loss: 3.028436357771332
Validation loss: 2.5330815972487306

Epoch: 6| Step: 6
Training loss: 3.2125893309526172
Validation loss: 2.534593600710157

Epoch: 6| Step: 7
Training loss: 2.7435704409297133
Validation loss: 2.533320383501336

Epoch: 6| Step: 8
Training loss: 2.9482271460054363
Validation loss: 2.5404585389962357

Epoch: 6| Step: 9
Training loss: 3.077487317949283
Validation loss: 2.5328618281432163

Epoch: 6| Step: 10
Training loss: 2.9619985807983378
Validation loss: 2.5198346462095262

Epoch: 6| Step: 11
Training loss: 3.192284676766709
Validation loss: 2.5254533125437537

Epoch: 6| Step: 12
Training loss: 2.7892274781060045
Validation loss: 2.524569152865103

Epoch: 6| Step: 13
Training loss: 2.96353687538515
Validation loss: 2.5203444090569507

Epoch: 239| Step: 0
Training loss: 3.0820795207721816
Validation loss: 2.5148258518197206

Epoch: 6| Step: 1
Training loss: 2.590818011889998
Validation loss: 2.517496489912322

Epoch: 6| Step: 2
Training loss: 3.3200999472407404
Validation loss: 2.5047942204682387

Epoch: 6| Step: 3
Training loss: 2.887834016050828
Validation loss: 2.4972671297180917

Epoch: 6| Step: 4
Training loss: 3.462214042891685
Validation loss: 2.512417585647397

Epoch: 6| Step: 5
Training loss: 3.103333397635498
Validation loss: 2.5072071519280925

Epoch: 6| Step: 6
Training loss: 3.171320523811192
Validation loss: 2.5118393517323327

Epoch: 6| Step: 7
Training loss: 2.645424808792688
Validation loss: 2.5150786642043794

Epoch: 6| Step: 8
Training loss: 2.1275652940639382
Validation loss: 2.5102598403175733

Epoch: 6| Step: 9
Training loss: 2.9051521442642625
Validation loss: 2.5256612109139525

Epoch: 6| Step: 10
Training loss: 2.6762885510778487
Validation loss: 2.52918529174886

Epoch: 6| Step: 11
Training loss: 2.2206965759234456
Validation loss: 2.551321784370135

Epoch: 6| Step: 12
Training loss: 2.8790231833655744
Validation loss: 2.5750430532317523

Epoch: 6| Step: 13
Training loss: 2.5585255388092687
Validation loss: 2.5798909115350384

Epoch: 240| Step: 0
Training loss: 2.6027669781768763
Validation loss: 2.5622529932002047

Epoch: 6| Step: 1
Training loss: 2.7369714235340834
Validation loss: 2.5525587237254515

Epoch: 6| Step: 2
Training loss: 2.8570447087459865
Validation loss: 2.530601976565606

Epoch: 6| Step: 3
Training loss: 3.0542013654693694
Validation loss: 2.516679853836559

Epoch: 6| Step: 4
Training loss: 3.1547229963235623
Validation loss: 2.5064101189228563

Epoch: 6| Step: 5
Training loss: 2.4470015959553257
Validation loss: 2.501377001308646

Epoch: 6| Step: 6
Training loss: 2.664158525721959
Validation loss: 2.5052568039856817

Epoch: 6| Step: 7
Training loss: 2.754378647564887
Validation loss: 2.5101571878049422

Epoch: 6| Step: 8
Training loss: 2.9400523034458197
Validation loss: 2.514697104075802

Epoch: 6| Step: 9
Training loss: 3.2796410385119437
Validation loss: 2.5055710298442517

Epoch: 6| Step: 10
Training loss: 3.1328108257184586
Validation loss: 2.5092342286091545

Epoch: 6| Step: 11
Training loss: 2.8251675480132015
Validation loss: 2.510111996614322

Epoch: 6| Step: 12
Training loss: 2.8257860659852776
Validation loss: 2.510309954314498

Epoch: 6| Step: 13
Training loss: 2.8752887414979496
Validation loss: 2.5076388689753673

Epoch: 241| Step: 0
Training loss: 2.7023181924000133
Validation loss: 2.5053833150003078

Epoch: 6| Step: 1
Training loss: 3.1668321332030995
Validation loss: 2.530900680682807

Epoch: 6| Step: 2
Training loss: 2.5585580604917824
Validation loss: 2.5522240270759013

Epoch: 6| Step: 3
Training loss: 2.719867432813831
Validation loss: 2.580558120441506

Epoch: 6| Step: 4
Training loss: 2.274238890883365
Validation loss: 2.610432424868378

Epoch: 6| Step: 5
Training loss: 2.628029936569152
Validation loss: 2.6356186927741865

Epoch: 6| Step: 6
Training loss: 2.922858251276593
Validation loss: 2.5997533262737496

Epoch: 6| Step: 7
Training loss: 3.04340090149839
Validation loss: 2.5498666019038962

Epoch: 6| Step: 8
Training loss: 3.1453424201220663
Validation loss: 2.553582112287089

Epoch: 6| Step: 9
Training loss: 2.9615928709689356
Validation loss: 2.5321204054863142

Epoch: 6| Step: 10
Training loss: 2.902793551639934
Validation loss: 2.526670470065899

Epoch: 6| Step: 11
Training loss: 2.8770661600545537
Validation loss: 2.5171532497979867

Epoch: 6| Step: 12
Training loss: 3.1415589115946134
Validation loss: 2.512728471224215

Epoch: 6| Step: 13
Training loss: 2.9753309690873637
Validation loss: 2.510276675815429

Epoch: 242| Step: 0
Training loss: 2.4757486925665773
Validation loss: 2.5177941615592996

Epoch: 6| Step: 1
Training loss: 2.5625640116814337
Validation loss: 2.52135795301181

Epoch: 6| Step: 2
Training loss: 2.73818599518924
Validation loss: 2.5221221044411446

Epoch: 6| Step: 3
Training loss: 2.8486748274776956
Validation loss: 2.5312374068594745

Epoch: 6| Step: 4
Training loss: 2.616509466450466
Validation loss: 2.525504573602638

Epoch: 6| Step: 5
Training loss: 3.098826241549755
Validation loss: 2.524059048811756

Epoch: 6| Step: 6
Training loss: 3.2107294391133245
Validation loss: 2.5244488556378757

Epoch: 6| Step: 7
Training loss: 2.8111282394182213
Validation loss: 2.526648495071141

Epoch: 6| Step: 8
Training loss: 2.5413470041174846
Validation loss: 2.5206221750803763

Epoch: 6| Step: 9
Training loss: 3.501929704850576
Validation loss: 2.529396696310806

Epoch: 6| Step: 10
Training loss: 2.6577414420719134
Validation loss: 2.513428700676337

Epoch: 6| Step: 11
Training loss: 3.1367594905122003
Validation loss: 2.5185806519980423

Epoch: 6| Step: 12
Training loss: 3.0014320770158123
Validation loss: 2.514610859086062

Epoch: 6| Step: 13
Training loss: 2.7207344968018106
Validation loss: 2.5172833435319832

Epoch: 243| Step: 0
Training loss: 2.551396387770206
Validation loss: 2.5257932455602194

Epoch: 6| Step: 1
Training loss: 2.5486275663430757
Validation loss: 2.535332747977856

Epoch: 6| Step: 2
Training loss: 2.974647045836236
Validation loss: 2.5446176697565464

Epoch: 6| Step: 3
Training loss: 2.982039891171247
Validation loss: 2.545985504587039

Epoch: 6| Step: 4
Training loss: 2.9566429215789074
Validation loss: 2.5394458960256725

Epoch: 6| Step: 5
Training loss: 2.947648718061209
Validation loss: 2.5282331856371334

Epoch: 6| Step: 6
Training loss: 2.708553970348482
Validation loss: 2.529704192766469

Epoch: 6| Step: 7
Training loss: 3.1582183743157666
Validation loss: 2.5175199714599468

Epoch: 6| Step: 8
Training loss: 2.853380266617622
Validation loss: 2.510308419383305

Epoch: 6| Step: 9
Training loss: 2.5805198874561857
Validation loss: 2.51647848118244

Epoch: 6| Step: 10
Training loss: 2.957859825243342
Validation loss: 2.520284484313307

Epoch: 6| Step: 11
Training loss: 2.919452499376923
Validation loss: 2.5162218705888364

Epoch: 6| Step: 12
Training loss: 2.9381618971496968
Validation loss: 2.5222410327436475

Epoch: 6| Step: 13
Training loss: 2.727401473156522
Validation loss: 2.5236822784414485

Epoch: 244| Step: 0
Training loss: 3.339960250161108
Validation loss: 2.523965398172779

Epoch: 6| Step: 1
Training loss: 2.4448621048685975
Validation loss: 2.540764442926554

Epoch: 6| Step: 2
Training loss: 2.766477636597474
Validation loss: 2.545549459574606

Epoch: 6| Step: 3
Training loss: 3.048214349053137
Validation loss: 2.556475113729349

Epoch: 6| Step: 4
Training loss: 2.981480338037384
Validation loss: 2.556534693566063

Epoch: 6| Step: 5
Training loss: 2.65130567953517
Validation loss: 2.55570597506515

Epoch: 6| Step: 6
Training loss: 2.7949397035212726
Validation loss: 2.5533267606900547

Epoch: 6| Step: 7
Training loss: 3.1706654915685806
Validation loss: 2.56850460556914

Epoch: 6| Step: 8
Training loss: 2.586042788111001
Validation loss: 2.5670711814509573

Epoch: 6| Step: 9
Training loss: 3.0570368403347814
Validation loss: 2.5780883567694426

Epoch: 6| Step: 10
Training loss: 2.045234313822624
Validation loss: 2.5667216393627688

Epoch: 6| Step: 11
Training loss: 2.4431088789522426
Validation loss: 2.5639525927700357

Epoch: 6| Step: 12
Training loss: 3.402240037706029
Validation loss: 2.5538478541604

Epoch: 6| Step: 13
Training loss: 2.815228643261995
Validation loss: 2.5514601937208674

Epoch: 245| Step: 0
Training loss: 3.020960382004152
Validation loss: 2.5353321867810226

Epoch: 6| Step: 1
Training loss: 3.287285041308414
Validation loss: 2.5281229091939705

Epoch: 6| Step: 2
Training loss: 2.4767377051343527
Validation loss: 2.527337923499832

Epoch: 6| Step: 3
Training loss: 2.5155908807371774
Validation loss: 2.5222900630532115

Epoch: 6| Step: 4
Training loss: 3.221818072817883
Validation loss: 2.5217343991815855

Epoch: 6| Step: 5
Training loss: 2.395436748907718
Validation loss: 2.519095599282287

Epoch: 6| Step: 6
Training loss: 2.9775382617762944
Validation loss: 2.520782873600722

Epoch: 6| Step: 7
Training loss: 2.740540534254394
Validation loss: 2.5153123929760497

Epoch: 6| Step: 8
Training loss: 2.8726007152726196
Validation loss: 2.5218780310181397

Epoch: 6| Step: 9
Training loss: 2.518734165643563
Validation loss: 2.5235256610296135

Epoch: 6| Step: 10
Training loss: 3.0123363212977834
Validation loss: 2.5362240023437326

Epoch: 6| Step: 11
Training loss: 3.2265823031134118
Validation loss: 2.5496676934840976

Epoch: 6| Step: 12
Training loss: 2.71654078732165
Validation loss: 2.554885491811574

Epoch: 6| Step: 13
Training loss: 2.568706532502705
Validation loss: 2.567400813161023

Epoch: 246| Step: 0
Training loss: 1.8220938942015308
Validation loss: 2.59156324627821

Epoch: 6| Step: 1
Training loss: 3.1375550405834205
Validation loss: 2.6097761070260916

Epoch: 6| Step: 2
Training loss: 2.4957026740906816
Validation loss: 2.5863769998456454

Epoch: 6| Step: 3
Training loss: 2.497125594415196
Validation loss: 2.5707059997189194

Epoch: 6| Step: 4
Training loss: 3.0573319405930888
Validation loss: 2.597588703351497

Epoch: 6| Step: 5
Training loss: 3.065908753681505
Validation loss: 2.6079342348423955

Epoch: 6| Step: 6
Training loss: 2.485112974335119
Validation loss: 2.613794622007758

Epoch: 6| Step: 7
Training loss: 2.7507109156606084
Validation loss: 2.6328042379133825

Epoch: 6| Step: 8
Training loss: 2.8349251109194196
Validation loss: 2.6668851359792924

Epoch: 6| Step: 9
Training loss: 3.6364651600797213
Validation loss: 2.6825914488799705

Epoch: 6| Step: 10
Training loss: 2.8873595893045985
Validation loss: 2.6175157537359506

Epoch: 6| Step: 11
Training loss: 3.4929445542751925
Validation loss: 2.61096980916143

Epoch: 6| Step: 12
Training loss: 2.7010525382622834
Validation loss: 2.5672367180930116

Epoch: 6| Step: 13
Training loss: 3.0145147780237913
Validation loss: 2.545899961043541

Epoch: 247| Step: 0
Training loss: 3.2963983995798265
Validation loss: 2.5271151608670808

Epoch: 6| Step: 1
Training loss: 3.1173848254625884
Validation loss: 2.5271402476685862

Epoch: 6| Step: 2
Training loss: 2.7254620711508237
Validation loss: 2.528345264147603

Epoch: 6| Step: 3
Training loss: 2.883093512673466
Validation loss: 2.52779994233532

Epoch: 6| Step: 4
Training loss: 2.42106280090108
Validation loss: 2.5371334268006054

Epoch: 6| Step: 5
Training loss: 3.0518673417844666
Validation loss: 2.5363322021943646

Epoch: 6| Step: 6
Training loss: 2.589744140182363
Validation loss: 2.5501635290508395

Epoch: 6| Step: 7
Training loss: 2.637195866120945
Validation loss: 2.5329783524742497

Epoch: 6| Step: 8
Training loss: 2.3610742778024356
Validation loss: 2.539849875815302

Epoch: 6| Step: 9
Training loss: 3.230572072675062
Validation loss: 2.534961216582104

Epoch: 6| Step: 10
Training loss: 2.6648094047540756
Validation loss: 2.5212464607208194

Epoch: 6| Step: 11
Training loss: 3.020756126381811
Validation loss: 2.5189684915460457

Epoch: 6| Step: 12
Training loss: 3.2547506676970683
Validation loss: 2.5401704426549907

Epoch: 6| Step: 13
Training loss: 3.0247315784249347
Validation loss: 2.567194241823644

Epoch: 248| Step: 0
Training loss: 3.014200931769493
Validation loss: 2.572904702761131

Epoch: 6| Step: 1
Training loss: 2.24362296167173
Validation loss: 2.5727519546867055

Epoch: 6| Step: 2
Training loss: 2.9934474593101497
Validation loss: 2.5655340125734134

Epoch: 6| Step: 3
Training loss: 2.8131632552631816
Validation loss: 2.570435211706404

Epoch: 6| Step: 4
Training loss: 3.072288129933864
Validation loss: 2.5729125419212644

Epoch: 6| Step: 5
Training loss: 3.0434206429945037
Validation loss: 2.5591689448243424

Epoch: 6| Step: 6
Training loss: 3.3160303844168824
Validation loss: 2.557213034056963

Epoch: 6| Step: 7
Training loss: 2.7483795767140635
Validation loss: 2.5439451230444896

Epoch: 6| Step: 8
Training loss: 2.9328332720403516
Validation loss: 2.5386598854387787

Epoch: 6| Step: 9
Training loss: 3.2607905911819937
Validation loss: 2.527642981151884

Epoch: 6| Step: 10
Training loss: 2.539719998252789
Validation loss: 2.523389456123439

Epoch: 6| Step: 11
Training loss: 2.477830435911307
Validation loss: 2.5184212849195453

Epoch: 6| Step: 12
Training loss: 2.748841301692786
Validation loss: 2.516851531887596

Epoch: 6| Step: 13
Training loss: 2.3569293957616178
Validation loss: 2.5200030095755817

Epoch: 249| Step: 0
Training loss: 2.721342144563881
Validation loss: 2.5134144811302694

Epoch: 6| Step: 1
Training loss: 2.609828429885988
Validation loss: 2.522544084743813

Epoch: 6| Step: 2
Training loss: 2.9886134542674334
Validation loss: 2.522751945436834

Epoch: 6| Step: 3
Training loss: 2.704234342115194
Validation loss: 2.5259681405946046

Epoch: 6| Step: 4
Training loss: 2.5520741572831422
Validation loss: 2.531397339343207

Epoch: 6| Step: 5
Training loss: 2.6620473987420685
Validation loss: 2.5293406176240043

Epoch: 6| Step: 6
Training loss: 3.3194817434970414
Validation loss: 2.548492509874381

Epoch: 6| Step: 7
Training loss: 2.761338527463961
Validation loss: 2.573597288952279

Epoch: 6| Step: 8
Training loss: 2.4810359756831977
Validation loss: 2.5808020650428025

Epoch: 6| Step: 9
Training loss: 3.2315449150277638
Validation loss: 2.5877260455075337

Epoch: 6| Step: 10
Training loss: 2.850326813815679
Validation loss: 2.5874748491909023

Epoch: 6| Step: 11
Training loss: 2.575254842499029
Validation loss: 2.5877330130380987

Epoch: 6| Step: 12
Training loss: 2.6521788870315515
Validation loss: 2.611123858519418

Epoch: 6| Step: 13
Training loss: 4.059389302593404
Validation loss: 2.650655968420393

Epoch: 250| Step: 0
Training loss: 2.0982020856044614
Validation loss: 2.5805666163627765

Epoch: 6| Step: 1
Training loss: 3.023695508411502
Validation loss: 2.533125755239285

Epoch: 6| Step: 2
Training loss: 2.3809623164015057
Validation loss: 2.512674184552966

Epoch: 6| Step: 3
Training loss: 3.0398902060106727
Validation loss: 2.506263871945115

Epoch: 6| Step: 4
Training loss: 3.1585992813533683
Validation loss: 2.5085427781784935

Epoch: 6| Step: 5
Training loss: 3.244096676450131
Validation loss: 2.512432321791891

Epoch: 6| Step: 6
Training loss: 2.9056464768385464
Validation loss: 2.5175400343182814

Epoch: 6| Step: 7
Training loss: 3.016171262608969
Validation loss: 2.5189397637961344

Epoch: 6| Step: 8
Training loss: 3.0083882362942185
Validation loss: 2.5251224010150164

Epoch: 6| Step: 9
Training loss: 2.0846960824164467
Validation loss: 2.527300016432427

Epoch: 6| Step: 10
Training loss: 3.1673175410564363
Validation loss: 2.5263273946321565

Epoch: 6| Step: 11
Training loss: 3.0286457633589485
Validation loss: 2.529984184393071

Epoch: 6| Step: 12
Training loss: 2.8023461049657308
Validation loss: 2.5277599610699153

Epoch: 6| Step: 13
Training loss: 2.750619818455679
Validation loss: 2.5217117315476827

Epoch: 251| Step: 0
Training loss: 2.703188151244799
Validation loss: 2.51663884735161

Epoch: 6| Step: 1
Training loss: 3.034864806883023
Validation loss: 2.526101697727086

Epoch: 6| Step: 2
Training loss: 2.9078960064392154
Validation loss: 2.519947008732101

Epoch: 6| Step: 3
Training loss: 2.2287944114483547
Validation loss: 2.518634748253369

Epoch: 6| Step: 4
Training loss: 3.329303371660768
Validation loss: 2.520812582081263

Epoch: 6| Step: 5
Training loss: 2.6709557452147177
Validation loss: 2.5308178322970662

Epoch: 6| Step: 6
Training loss: 2.3230720319808174
Validation loss: 2.5390600626313002

Epoch: 6| Step: 7
Training loss: 3.2235592958237027
Validation loss: 2.5539091575987785

Epoch: 6| Step: 8
Training loss: 2.6172426132548283
Validation loss: 2.546851745817388

Epoch: 6| Step: 9
Training loss: 2.5551350519428504
Validation loss: 2.541536349689921

Epoch: 6| Step: 10
Training loss: 3.037087237409271
Validation loss: 2.5626694267841517

Epoch: 6| Step: 11
Training loss: 3.221939728583392
Validation loss: 2.562576509899707

Epoch: 6| Step: 12
Training loss: 3.0628991937292462
Validation loss: 2.5452825743188376

Epoch: 6| Step: 13
Training loss: 3.2315651302771453
Validation loss: 2.522384772939079

Epoch: 252| Step: 0
Training loss: 2.7142740873216833
Validation loss: 2.514960294238955

Epoch: 6| Step: 1
Training loss: 3.1092013976741404
Validation loss: 2.5178851165249845

Epoch: 6| Step: 2
Training loss: 2.845399985730721
Validation loss: 2.5078776008682544

Epoch: 6| Step: 3
Training loss: 3.215968291083631
Validation loss: 2.5004526097758695

Epoch: 6| Step: 4
Training loss: 2.444333596558008
Validation loss: 2.503638561212815

Epoch: 6| Step: 5
Training loss: 3.1014837836358664
Validation loss: 2.5058429006354497

Epoch: 6| Step: 6
Training loss: 3.083616364006893
Validation loss: 2.5002303868446614

Epoch: 6| Step: 7
Training loss: 1.8192603217897985
Validation loss: 2.5017532476670326

Epoch: 6| Step: 8
Training loss: 3.11651451093018
Validation loss: 2.502547359885693

Epoch: 6| Step: 9
Training loss: 3.021887093394558
Validation loss: 2.5019015945320766

Epoch: 6| Step: 10
Training loss: 2.4080605569112987
Validation loss: 2.5064708479128717

Epoch: 6| Step: 11
Training loss: 2.8158341036935974
Validation loss: 2.5103517780198916

Epoch: 6| Step: 12
Training loss: 2.589485615497536
Validation loss: 2.5133444338254427

Epoch: 6| Step: 13
Training loss: 3.3021176854862806
Validation loss: 2.5284244653404726

Epoch: 253| Step: 0
Training loss: 3.393158840447041
Validation loss: 2.530829903822801

Epoch: 6| Step: 1
Training loss: 2.440720606847182
Validation loss: 2.5417716375979285

Epoch: 6| Step: 2
Training loss: 2.70682603022395
Validation loss: 2.5471233803193916

Epoch: 6| Step: 3
Training loss: 2.4970405227740073
Validation loss: 2.5470254877392304

Epoch: 6| Step: 4
Training loss: 3.2403456270458006
Validation loss: 2.5384446814046875

Epoch: 6| Step: 5
Training loss: 3.173310805195361
Validation loss: 2.538363256855455

Epoch: 6| Step: 6
Training loss: 2.9522561707620723
Validation loss: 2.54168942396068

Epoch: 6| Step: 7
Training loss: 2.1111771408708218
Validation loss: 2.527919743401619

Epoch: 6| Step: 8
Training loss: 3.379850645884929
Validation loss: 2.5259656225915132

Epoch: 6| Step: 9
Training loss: 3.369077501673162
Validation loss: 2.519964620845147

Epoch: 6| Step: 10
Training loss: 2.6134516684670266
Validation loss: 2.5292515027703257

Epoch: 6| Step: 11
Training loss: 2.562964978714438
Validation loss: 2.5222542450722494

Epoch: 6| Step: 12
Training loss: 2.2530552994823796
Validation loss: 2.5306728955458486

Epoch: 6| Step: 13
Training loss: 2.087936757704793
Validation loss: 2.5381342587166777

Epoch: 254| Step: 0
Training loss: 2.6371267045516364
Validation loss: 2.5384387016273093

Epoch: 6| Step: 1
Training loss: 2.2762865390180655
Validation loss: 2.568698507348297

Epoch: 6| Step: 2
Training loss: 2.2424248227517816
Validation loss: 2.5776616360937656

Epoch: 6| Step: 3
Training loss: 2.8970511274899047
Validation loss: 2.6131293429259173

Epoch: 6| Step: 4
Training loss: 3.4941089643618706
Validation loss: 2.671399308106754

Epoch: 6| Step: 5
Training loss: 2.6744668447080033
Validation loss: 2.6804985713907534

Epoch: 6| Step: 6
Training loss: 2.8178937266922683
Validation loss: 2.593286594704964

Epoch: 6| Step: 7
Training loss: 3.364433419083414
Validation loss: 2.5403670329058907

Epoch: 6| Step: 8
Training loss: 2.741112479305901
Validation loss: 2.5380134125360163

Epoch: 6| Step: 9
Training loss: 2.7441986620864514
Validation loss: 2.5159232588813616

Epoch: 6| Step: 10
Training loss: 3.3682146032649793
Validation loss: 2.521105794709011

Epoch: 6| Step: 11
Training loss: 2.7508566129112153
Validation loss: 2.522475224959303

Epoch: 6| Step: 12
Training loss: 2.7871937194337386
Validation loss: 2.517345028209313

Epoch: 6| Step: 13
Training loss: 2.6313723465480856
Validation loss: 2.5066270801683004

Epoch: 255| Step: 0
Training loss: 2.4491341559541167
Validation loss: 2.5022775970636375

Epoch: 6| Step: 1
Training loss: 2.822469715804026
Validation loss: 2.5084777865523

Epoch: 6| Step: 2
Training loss: 2.7909168735810206
Validation loss: 2.5017438508055316

Epoch: 6| Step: 3
Training loss: 3.437988662665527
Validation loss: 2.499785473550952

Epoch: 6| Step: 4
Training loss: 2.589224670893259
Validation loss: 2.5029143717538567

Epoch: 6| Step: 5
Training loss: 2.6138769363236345
Validation loss: 2.5069515792615924

Epoch: 6| Step: 6
Training loss: 2.8358620037191837
Validation loss: 2.50600038736454

Epoch: 6| Step: 7
Training loss: 3.1438615358258564
Validation loss: 2.526488902253591

Epoch: 6| Step: 8
Training loss: 2.846279486502196
Validation loss: 2.528343368041935

Epoch: 6| Step: 9
Training loss: 3.1946552225501264
Validation loss: 2.5207857984961057

Epoch: 6| Step: 10
Training loss: 2.871845006941789
Validation loss: 2.553285815635558

Epoch: 6| Step: 11
Training loss: 2.8579074449655044
Validation loss: 2.5778506772247582

Epoch: 6| Step: 12
Training loss: 2.737733097690619
Validation loss: 2.629233616933255

Epoch: 6| Step: 13
Training loss: 2.1414112958044917
Validation loss: 2.607566807776023

Epoch: 256| Step: 0
Training loss: 3.123520004762865
Validation loss: 2.607052719765962

Epoch: 6| Step: 1
Training loss: 2.4122843196300288
Validation loss: 2.5599281596831194

Epoch: 6| Step: 2
Training loss: 2.578810352205373
Validation loss: 2.5473918670910507

Epoch: 6| Step: 3
Training loss: 3.289317648951394
Validation loss: 2.5534560294969193

Epoch: 6| Step: 4
Training loss: 2.418643099371768
Validation loss: 2.545623794062757

Epoch: 6| Step: 5
Training loss: 2.9460668432625052
Validation loss: 2.5354376228681104

Epoch: 6| Step: 6
Training loss: 2.534640455160944
Validation loss: 2.5276902940649975

Epoch: 6| Step: 7
Training loss: 3.0742665230166715
Validation loss: 2.5227621054636677

Epoch: 6| Step: 8
Training loss: 3.060230426215589
Validation loss: 2.526131203606681

Epoch: 6| Step: 9
Training loss: 3.015770626999078
Validation loss: 2.50848214636027

Epoch: 6| Step: 10
Training loss: 2.5471866159597845
Validation loss: 2.510115075907909

Epoch: 6| Step: 11
Training loss: 2.9253683983061185
Validation loss: 2.507294030925454

Epoch: 6| Step: 12
Training loss: 2.6175218055494507
Validation loss: 2.5110810635082688

Epoch: 6| Step: 13
Training loss: 2.794574835962341
Validation loss: 2.520268308701203

Epoch: 257| Step: 0
Training loss: 2.8075253042030153
Validation loss: 2.520222551663612

Epoch: 6| Step: 1
Training loss: 3.325083027426868
Validation loss: 2.5279088414747166

Epoch: 6| Step: 2
Training loss: 2.6263804665958363
Validation loss: 2.536173977873293

Epoch: 6| Step: 3
Training loss: 3.084369347904364
Validation loss: 2.545250175105482

Epoch: 6| Step: 4
Training loss: 2.8413394310735285
Validation loss: 2.5556582644532617

Epoch: 6| Step: 5
Training loss: 2.384638152593582
Validation loss: 2.5531557951718087

Epoch: 6| Step: 6
Training loss: 2.7121125678497338
Validation loss: 2.5407432648603607

Epoch: 6| Step: 7
Training loss: 2.616162272958646
Validation loss: 2.548353790451333

Epoch: 6| Step: 8
Training loss: 2.771847379217831
Validation loss: 2.5551788709499816

Epoch: 6| Step: 9
Training loss: 2.692652177255849
Validation loss: 2.565125698617417

Epoch: 6| Step: 10
Training loss: 3.1809454451736356
Validation loss: 2.56425341551477

Epoch: 6| Step: 11
Training loss: 2.7880619081440425
Validation loss: 2.5792041964756454

Epoch: 6| Step: 12
Training loss: 2.50440248044471
Validation loss: 2.5706806394859956

Epoch: 6| Step: 13
Training loss: 3.3023774570597597
Validation loss: 2.5655666082926207

Epoch: 258| Step: 0
Training loss: 3.23771634943888
Validation loss: 2.5599033476320607

Epoch: 6| Step: 1
Training loss: 3.2030106686912547
Validation loss: 2.5624190176896358

Epoch: 6| Step: 2
Training loss: 2.5144635475112174
Validation loss: 2.58068369569388

Epoch: 6| Step: 3
Training loss: 2.6772013439089033
Validation loss: 2.557273163108347

Epoch: 6| Step: 4
Training loss: 2.732325543334077
Validation loss: 2.5480908631476673

Epoch: 6| Step: 5
Training loss: 2.9131748187182422
Validation loss: 2.534890543994537

Epoch: 6| Step: 6
Training loss: 3.248029111261933
Validation loss: 2.537667435660907

Epoch: 6| Step: 7
Training loss: 2.692110941059028
Validation loss: 2.531347400771849

Epoch: 6| Step: 8
Training loss: 2.382539026795339
Validation loss: 2.5282561902598166

Epoch: 6| Step: 9
Training loss: 2.8534574718150316
Validation loss: 2.525686899350301

Epoch: 6| Step: 10
Training loss: 3.0245737705551625
Validation loss: 2.532056123324481

Epoch: 6| Step: 11
Training loss: 2.5654612852545906
Validation loss: 2.5210963845625716

Epoch: 6| Step: 12
Training loss: 2.5735484800513873
Validation loss: 2.5294518828736843

Epoch: 6| Step: 13
Training loss: 2.508665516128837
Validation loss: 2.525793667793677

Epoch: 259| Step: 0
Training loss: 3.177241553864226
Validation loss: 2.5238510946483133

Epoch: 6| Step: 1
Training loss: 2.5179651405339376
Validation loss: 2.545076961695013

Epoch: 6| Step: 2
Training loss: 2.8448273012007648
Validation loss: 2.541393293233575

Epoch: 6| Step: 3
Training loss: 2.793030382023222
Validation loss: 2.5364262866753973

Epoch: 6| Step: 4
Training loss: 2.6932356199473566
Validation loss: 2.5423665575012895

Epoch: 6| Step: 5
Training loss: 2.9736531775267343
Validation loss: 2.525641042039917

Epoch: 6| Step: 6
Training loss: 2.851516347015202
Validation loss: 2.529904781735067

Epoch: 6| Step: 7
Training loss: 2.4047166967571454
Validation loss: 2.5152757275182496

Epoch: 6| Step: 8
Training loss: 2.8017612163407346
Validation loss: 2.5328080104485884

Epoch: 6| Step: 9
Training loss: 3.317110847237965
Validation loss: 2.5156369192128554

Epoch: 6| Step: 10
Training loss: 1.7512608481921375
Validation loss: 2.51352509179838

Epoch: 6| Step: 11
Training loss: 3.1044683800498745
Validation loss: 2.5184803785751755

Epoch: 6| Step: 12
Training loss: 2.9382230802101446
Validation loss: 2.5223046624952246

Epoch: 6| Step: 13
Training loss: 2.8646280366126025
Validation loss: 2.51258831498514

Epoch: 260| Step: 0
Training loss: 3.0480089473943472
Validation loss: 2.534809397690513

Epoch: 6| Step: 1
Training loss: 3.4190600936263356
Validation loss: 2.562489518314977

Epoch: 6| Step: 2
Training loss: 3.0584599842037474
Validation loss: 2.6060041190686922

Epoch: 6| Step: 3
Training loss: 2.7102438619202998
Validation loss: 2.6649359257431855

Epoch: 6| Step: 4
Training loss: 2.8931688816898533
Validation loss: 2.685068388344261

Epoch: 6| Step: 5
Training loss: 2.908513162148676
Validation loss: 2.720851522096342

Epoch: 6| Step: 6
Training loss: 2.8323706693154476
Validation loss: 2.7177002600744418

Epoch: 6| Step: 7
Training loss: 2.3218417795507897
Validation loss: 2.6482380726490438

Epoch: 6| Step: 8
Training loss: 2.3630236776927713
Validation loss: 2.5624557289203023

Epoch: 6| Step: 9
Training loss: 2.960785793957441
Validation loss: 2.5253663197457237

Epoch: 6| Step: 10
Training loss: 2.8146388927729618
Validation loss: 2.51193488072476

Epoch: 6| Step: 11
Training loss: 2.1809664566559923
Validation loss: 2.518186531419021

Epoch: 6| Step: 12
Training loss: 2.4004744537589677
Validation loss: 2.5016720031008894

Epoch: 6| Step: 13
Training loss: 3.5729743500586117
Validation loss: 2.4963301323107894

Epoch: 261| Step: 0
Training loss: 2.3837010462294574
Validation loss: 2.493513912798822

Epoch: 6| Step: 1
Training loss: 2.888912869215333
Validation loss: 2.488079237800091

Epoch: 6| Step: 2
Training loss: 2.347843511796259
Validation loss: 2.495453406229611

Epoch: 6| Step: 3
Training loss: 2.5187436314353224
Validation loss: 2.492254156979703

Epoch: 6| Step: 4
Training loss: 2.3886238648525056
Validation loss: 2.4931578887717385

Epoch: 6| Step: 5
Training loss: 3.1080176683215814
Validation loss: 2.512823453753277

Epoch: 6| Step: 6
Training loss: 2.649209239226053
Validation loss: 2.536500418551128

Epoch: 6| Step: 7
Training loss: 2.924675726236619
Validation loss: 2.5471071909620213

Epoch: 6| Step: 8
Training loss: 3.0794563318951007
Validation loss: 2.5454881814126806

Epoch: 6| Step: 9
Training loss: 2.847310949250825
Validation loss: 2.5623837196265113

Epoch: 6| Step: 10
Training loss: 3.38978221632616
Validation loss: 2.5974810545904896

Epoch: 6| Step: 11
Training loss: 3.2927832500298657
Validation loss: 2.665020900777418

Epoch: 6| Step: 12
Training loss: 2.556668880997171
Validation loss: 2.6401130125073635

Epoch: 6| Step: 13
Training loss: 3.174954277370166
Validation loss: 2.5954140628945344

Epoch: 262| Step: 0
Training loss: 2.586073212073302
Validation loss: 2.545524699729021

Epoch: 6| Step: 1
Training loss: 2.281835611505476
Validation loss: 2.5209693777062916

Epoch: 6| Step: 2
Training loss: 2.8347701935917264
Validation loss: 2.503389370281811

Epoch: 6| Step: 3
Training loss: 2.917791113495726
Validation loss: 2.4935931644512634

Epoch: 6| Step: 4
Training loss: 3.12005468076082
Validation loss: 2.5004124301221244

Epoch: 6| Step: 5
Training loss: 3.061285907103304
Validation loss: 2.5009434663030508

Epoch: 6| Step: 6
Training loss: 2.356927170318961
Validation loss: 2.5043967541198793

Epoch: 6| Step: 7
Training loss: 2.8666051954139955
Validation loss: 2.5054777819696255

Epoch: 6| Step: 8
Training loss: 2.6307221669282885
Validation loss: 2.518148736525826

Epoch: 6| Step: 9
Training loss: 3.152557933011873
Validation loss: 2.530312252403556

Epoch: 6| Step: 10
Training loss: 3.270120109662061
Validation loss: 2.5355343774546775

Epoch: 6| Step: 11
Training loss: 3.0692295173743958
Validation loss: 2.550952890212485

Epoch: 6| Step: 12
Training loss: 2.4616658419653104
Validation loss: 2.5617824543257477

Epoch: 6| Step: 13
Training loss: 2.6576655486856606
Validation loss: 2.556076632983916

Epoch: 263| Step: 0
Training loss: 2.8723344470623977
Validation loss: 2.5436182106525256

Epoch: 6| Step: 1
Training loss: 2.3292661596713957
Validation loss: 2.5277465685940506

Epoch: 6| Step: 2
Training loss: 3.0511569721022553
Validation loss: 2.5193890402284853

Epoch: 6| Step: 3
Training loss: 2.409828794420967
Validation loss: 2.5157390740079695

Epoch: 6| Step: 4
Training loss: 2.956438577133604
Validation loss: 2.51941020751453

Epoch: 6| Step: 5
Training loss: 2.5536720987725334
Validation loss: 2.5111392895939777

Epoch: 6| Step: 6
Training loss: 3.093941422522569
Validation loss: 2.5052069081832467

Epoch: 6| Step: 7
Training loss: 3.0915363753867355
Validation loss: 2.5117609222759953

Epoch: 6| Step: 8
Training loss: 2.934569337562234
Validation loss: 2.5243162692891246

Epoch: 6| Step: 9
Training loss: 2.861779707858988
Validation loss: 2.5361131969504234

Epoch: 6| Step: 10
Training loss: 2.9603080785076634
Validation loss: 2.5390025101635514

Epoch: 6| Step: 11
Training loss: 2.9507373664144017
Validation loss: 2.557003064018075

Epoch: 6| Step: 12
Training loss: 2.2361669224104923
Validation loss: 2.568467055537444

Epoch: 6| Step: 13
Training loss: 3.1165527615327613
Validation loss: 2.6236312425775337

Epoch: 264| Step: 0
Training loss: 3.2089461860079274
Validation loss: 2.6346860494876303

Epoch: 6| Step: 1
Training loss: 2.8412076883316475
Validation loss: 2.613068736166854

Epoch: 6| Step: 2
Training loss: 2.6199064337060802
Validation loss: 2.570598112783947

Epoch: 6| Step: 3
Training loss: 3.2277386532934855
Validation loss: 2.5757999291134075

Epoch: 6| Step: 4
Training loss: 1.8380764452796887
Validation loss: 2.564016389213159

Epoch: 6| Step: 5
Training loss: 3.340552111009806
Validation loss: 2.575057272946662

Epoch: 6| Step: 6
Training loss: 2.7840457537497776
Validation loss: 2.559084391946647

Epoch: 6| Step: 7
Training loss: 3.10193391589097
Validation loss: 2.5727506742371737

Epoch: 6| Step: 8
Training loss: 2.830488366088786
Validation loss: 2.5414389167497062

Epoch: 6| Step: 9
Training loss: 2.2967350716039805
Validation loss: 2.551324653153659

Epoch: 6| Step: 10
Training loss: 2.66375676970962
Validation loss: 2.552106693873285

Epoch: 6| Step: 11
Training loss: 2.7632467097873095
Validation loss: 2.547325375293014

Epoch: 6| Step: 12
Training loss: 2.786987558655332
Validation loss: 2.553955412764261

Epoch: 6| Step: 13
Training loss: 3.2005958062069433
Validation loss: 2.535584247718046

Epoch: 265| Step: 0
Training loss: 2.702746943678772
Validation loss: 2.5411058537115947

Epoch: 6| Step: 1
Training loss: 3.052848086493821
Validation loss: 2.541559396299376

Epoch: 6| Step: 2
Training loss: 3.0079101546647227
Validation loss: 2.558330614476591

Epoch: 6| Step: 3
Training loss: 3.379084623181994
Validation loss: 2.55855756050047

Epoch: 6| Step: 4
Training loss: 3.017337451213342
Validation loss: 2.565048289290322

Epoch: 6| Step: 5
Training loss: 2.5073985295858803
Validation loss: 2.5611004632910253

Epoch: 6| Step: 6
Training loss: 2.3601544842023663
Validation loss: 2.5451749523863

Epoch: 6| Step: 7
Training loss: 2.828652685685422
Validation loss: 2.5472669050156584

Epoch: 6| Step: 8
Training loss: 2.9246222488488858
Validation loss: 2.556210112338864

Epoch: 6| Step: 9
Training loss: 2.9925903367865314
Validation loss: 2.5602249502938483

Epoch: 6| Step: 10
Training loss: 2.9862390259149487
Validation loss: 2.5769011395831263

Epoch: 6| Step: 11
Training loss: 2.249452948294175
Validation loss: 2.592138563494778

Epoch: 6| Step: 12
Training loss: 2.6371629580971696
Validation loss: 2.6280337849099804

Epoch: 6| Step: 13
Training loss: 3.036368698620509
Validation loss: 2.6474932992036933

Epoch: 266| Step: 0
Training loss: 2.3778864737154004
Validation loss: 2.616119514598133

Epoch: 6| Step: 1
Training loss: 2.073932750115575
Validation loss: 2.580075776059802

Epoch: 6| Step: 2
Training loss: 2.0468547325004463
Validation loss: 2.5724420453894066

Epoch: 6| Step: 3
Training loss: 2.8559361191452064
Validation loss: 2.554081642542263

Epoch: 6| Step: 4
Training loss: 2.712414429892627
Validation loss: 2.556666880556243

Epoch: 6| Step: 5
Training loss: 3.856654640866991
Validation loss: 2.555987867545413

Epoch: 6| Step: 6
Training loss: 3.3299943572217083
Validation loss: 2.5651006110273777

Epoch: 6| Step: 7
Training loss: 3.310017069055162
Validation loss: 2.548966028083953

Epoch: 6| Step: 8
Training loss: 2.296708081466735
Validation loss: 2.5465036988854575

Epoch: 6| Step: 9
Training loss: 2.36309561512658
Validation loss: 2.543284736479423

Epoch: 6| Step: 10
Training loss: 2.7251357578443023
Validation loss: 2.542617699271191

Epoch: 6| Step: 11
Training loss: 3.1568965438503396
Validation loss: 2.5316300313859434

Epoch: 6| Step: 12
Training loss: 3.203259572249341
Validation loss: 2.5289306456570526

Epoch: 6| Step: 13
Training loss: 2.5044879683930774
Validation loss: 2.5300997631496602

Epoch: 267| Step: 0
Training loss: 2.926452315293472
Validation loss: 2.5306298111296233

Epoch: 6| Step: 1
Training loss: 2.5766699181553046
Validation loss: 2.542183786280046

Epoch: 6| Step: 2
Training loss: 2.8897637811235297
Validation loss: 2.535749355332883

Epoch: 6| Step: 3
Training loss: 2.955929993292152
Validation loss: 2.5284857940661825

Epoch: 6| Step: 4
Training loss: 3.1593956709882627
Validation loss: 2.5281748249301543

Epoch: 6| Step: 5
Training loss: 2.9756133400957623
Validation loss: 2.507695336873493

Epoch: 6| Step: 6
Training loss: 3.047287820090462
Validation loss: 2.5051700272819915

Epoch: 6| Step: 7
Training loss: 2.50600161189631
Validation loss: 2.5026830913647258

Epoch: 6| Step: 8
Training loss: 2.217252629017774
Validation loss: 2.5013396396260106

Epoch: 6| Step: 9
Training loss: 2.8872621512606953
Validation loss: 2.4979887696477467

Epoch: 6| Step: 10
Training loss: 2.351516266935466
Validation loss: 2.5103737486153124

Epoch: 6| Step: 11
Training loss: 3.199352741346601
Validation loss: 2.5217643201056834

Epoch: 6| Step: 12
Training loss: 2.4292400966252803
Validation loss: 2.527408669327675

Epoch: 6| Step: 13
Training loss: 3.12304229449711
Validation loss: 2.5263290202927835

Epoch: 268| Step: 0
Training loss: 2.8674296347009003
Validation loss: 2.5216841848677034

Epoch: 6| Step: 1
Training loss: 3.0050215021211493
Validation loss: 2.5182624055672367

Epoch: 6| Step: 2
Training loss: 2.6175395671837904
Validation loss: 2.5016240115951907

Epoch: 6| Step: 3
Training loss: 3.0064472221031906
Validation loss: 2.492921445274108

Epoch: 6| Step: 4
Training loss: 2.0546623199428464
Validation loss: 2.4951288024286518

Epoch: 6| Step: 5
Training loss: 2.792205919782425
Validation loss: 2.489426997747483

Epoch: 6| Step: 6
Training loss: 2.7821927990777766
Validation loss: 2.485722735603426

Epoch: 6| Step: 7
Training loss: 2.6079894630359686
Validation loss: 2.4983115062433154

Epoch: 6| Step: 8
Training loss: 3.226440575168744
Validation loss: 2.506590849160276

Epoch: 6| Step: 9
Training loss: 2.666019828150304
Validation loss: 2.5311738163158206

Epoch: 6| Step: 10
Training loss: 3.216976825472929
Validation loss: 2.5478008929331053

Epoch: 6| Step: 11
Training loss: 3.3548094486979068
Validation loss: 2.5578413739389028

Epoch: 6| Step: 12
Training loss: 2.120263486898676
Validation loss: 2.6354834595821486

Epoch: 6| Step: 13
Training loss: 1.9081188483940297
Validation loss: 2.680188745406889

Epoch: 269| Step: 0
Training loss: 2.910728531450721
Validation loss: 2.8424440504637833

Epoch: 6| Step: 1
Training loss: 3.0806022783441014
Validation loss: 3.011185548542348

Epoch: 6| Step: 2
Training loss: 3.0048160043454746
Validation loss: 3.005583835721717

Epoch: 6| Step: 3
Training loss: 2.6580901111400324
Validation loss: 2.888761725702038

Epoch: 6| Step: 4
Training loss: 2.769104401443938
Validation loss: 2.745924870512321

Epoch: 6| Step: 5
Training loss: 3.5998152261575296
Validation loss: 2.6689282416492532

Epoch: 6| Step: 6
Training loss: 2.720062640534702
Validation loss: 2.58482502222509

Epoch: 6| Step: 7
Training loss: 2.041925517690031
Validation loss: 2.5492743494143073

Epoch: 6| Step: 8
Training loss: 3.348330346412016
Validation loss: 2.5091398315463787

Epoch: 6| Step: 9
Training loss: 2.881085134162642
Validation loss: 2.481926281176988

Epoch: 6| Step: 10
Training loss: 2.558711251625622
Validation loss: 2.489729288808203

Epoch: 6| Step: 11
Training loss: 1.9401868218004572
Validation loss: 2.4783357199891385

Epoch: 6| Step: 12
Training loss: 2.9472212942946694
Validation loss: 2.4946936405425686

Epoch: 6| Step: 13
Training loss: 3.4293888457310597
Validation loss: 2.4862940145949453

Epoch: 270| Step: 0
Training loss: 2.3641654386126136
Validation loss: 2.4852992638580713

Epoch: 6| Step: 1
Training loss: 3.171179183030923
Validation loss: 2.4793516920546854

Epoch: 6| Step: 2
Training loss: 2.3010691023906804
Validation loss: 2.486864791239013

Epoch: 6| Step: 3
Training loss: 3.047053718216063
Validation loss: 2.488146829112635

Epoch: 6| Step: 4
Training loss: 3.287554542466169
Validation loss: 2.5033679098234134

Epoch: 6| Step: 5
Training loss: 2.500635352462471
Validation loss: 2.5393825110368367

Epoch: 6| Step: 6
Training loss: 2.6964969409802904
Validation loss: 2.5599742319876495

Epoch: 6| Step: 7
Training loss: 2.2920551202014643
Validation loss: 2.606588503662276

Epoch: 6| Step: 8
Training loss: 3.24521063992357
Validation loss: 2.6210647634465873

Epoch: 6| Step: 9
Training loss: 2.3013540179994276
Validation loss: 2.638823550361176

Epoch: 6| Step: 10
Training loss: 2.9444952926403785
Validation loss: 2.663043697663004

Epoch: 6| Step: 11
Training loss: 3.079792945639803
Validation loss: 2.6282187600580613

Epoch: 6| Step: 12
Training loss: 3.369280737575697
Validation loss: 2.615548634214047

Epoch: 6| Step: 13
Training loss: 2.938077991517707
Validation loss: 2.577873501609533

Epoch: 271| Step: 0
Training loss: 2.9862173096059887
Validation loss: 2.5299232405750156

Epoch: 6| Step: 1
Training loss: 2.2726815661255935
Validation loss: 2.5146795876016546

Epoch: 6| Step: 2
Training loss: 2.5430386910144684
Validation loss: 2.518436773063869

Epoch: 6| Step: 3
Training loss: 2.409428070710908
Validation loss: 2.518350288652897

Epoch: 6| Step: 4
Training loss: 3.2726767300064905
Validation loss: 2.5158265072041055

Epoch: 6| Step: 5
Training loss: 2.8757212190339403
Validation loss: 2.523631478643675

Epoch: 6| Step: 6
Training loss: 2.319437497776413
Validation loss: 2.5251991774168387

Epoch: 6| Step: 7
Training loss: 3.2017613927704467
Validation loss: 2.5418408490683744

Epoch: 6| Step: 8
Training loss: 2.8224519767088396
Validation loss: 2.5381335597624917

Epoch: 6| Step: 9
Training loss: 2.51526236437826
Validation loss: 2.5627431066382105

Epoch: 6| Step: 10
Training loss: 3.2073036291913835
Validation loss: 2.603835643443863

Epoch: 6| Step: 11
Training loss: 2.511905075922081
Validation loss: 2.6299459483488

Epoch: 6| Step: 12
Training loss: 3.1638685378917115
Validation loss: 2.6485355760871307

Epoch: 6| Step: 13
Training loss: 3.185308563280887
Validation loss: 2.616214169227791

Epoch: 272| Step: 0
Training loss: 2.3877282637680275
Validation loss: 2.5512515509210716

Epoch: 6| Step: 1
Training loss: 3.271090956988075
Validation loss: 2.5172354072715204

Epoch: 6| Step: 2
Training loss: 2.5896852194480386
Validation loss: 2.5148308739420164

Epoch: 6| Step: 3
Training loss: 2.6339519084053595
Validation loss: 2.518213190961957

Epoch: 6| Step: 4
Training loss: 2.9250787316836195
Validation loss: 2.514777093947866

Epoch: 6| Step: 5
Training loss: 3.1624248269536483
Validation loss: 2.5299736581793155

Epoch: 6| Step: 6
Training loss: 3.0269850782991323
Validation loss: 2.541184158829309

Epoch: 6| Step: 7
Training loss: 2.6816093292966263
Validation loss: 2.5567180291832776

Epoch: 6| Step: 8
Training loss: 2.8405508973850067
Validation loss: 2.561298601958994

Epoch: 6| Step: 9
Training loss: 2.819229382944862
Validation loss: 2.556937203651747

Epoch: 6| Step: 10
Training loss: 2.787808432856692
Validation loss: 2.551502637027361

Epoch: 6| Step: 11
Training loss: 2.9504632812345886
Validation loss: 2.5496190780481434

Epoch: 6| Step: 12
Training loss: 2.832355517534824
Validation loss: 2.555440284464953

Epoch: 6| Step: 13
Training loss: 3.019157593815524
Validation loss: 2.5664482373608717

Epoch: 273| Step: 0
Training loss: 2.7806514996127407
Validation loss: 2.556163304241728

Epoch: 6| Step: 1
Training loss: 2.430745081702662
Validation loss: 2.5594136870393656

Epoch: 6| Step: 2
Training loss: 3.035282559509815
Validation loss: 2.595411636960101

Epoch: 6| Step: 3
Training loss: 3.478798273802258
Validation loss: 2.618525313962852

Epoch: 6| Step: 4
Training loss: 2.857325418634292
Validation loss: 2.629483386201495

Epoch: 6| Step: 5
Training loss: 2.6005621009046527
Validation loss: 2.616344377687714

Epoch: 6| Step: 6
Training loss: 1.8859501570408825
Validation loss: 2.622025200286222

Epoch: 6| Step: 7
Training loss: 2.8629761412302943
Validation loss: 2.600127440027842

Epoch: 6| Step: 8
Training loss: 2.298925405824515
Validation loss: 2.591279970010425

Epoch: 6| Step: 9
Training loss: 3.1407112375442474
Validation loss: 2.587183221868378

Epoch: 6| Step: 10
Training loss: 2.8217383502643
Validation loss: 2.557816612305545

Epoch: 6| Step: 11
Training loss: 3.0277208056519247
Validation loss: 2.5632904308305813

Epoch: 6| Step: 12
Training loss: 2.9787807259073484
Validation loss: 2.554157567517824

Epoch: 6| Step: 13
Training loss: 3.1576619530927887
Validation loss: 2.556997233916618

Epoch: 274| Step: 0
Training loss: 3.1343483525338627
Validation loss: 2.554309990809946

Epoch: 6| Step: 1
Training loss: 2.899196473973806
Validation loss: 2.542469532459053

Epoch: 6| Step: 2
Training loss: 2.873234745939398
Validation loss: 2.5571293017545638

Epoch: 6| Step: 3
Training loss: 2.14056474364183
Validation loss: 2.5599991069420094

Epoch: 6| Step: 4
Training loss: 3.1570857990388346
Validation loss: 2.5533221270440793

Epoch: 6| Step: 5
Training loss: 2.4749362552024796
Validation loss: 2.5597250234682005

Epoch: 6| Step: 6
Training loss: 3.1220371696805898
Validation loss: 2.542522280017236

Epoch: 6| Step: 7
Training loss: 3.1775173870484354
Validation loss: 2.5510418459209356

Epoch: 6| Step: 8
Training loss: 2.5984331618391514
Validation loss: 2.5460915980298977

Epoch: 6| Step: 9
Training loss: 2.6967210710253497
Validation loss: 2.5421498177493036

Epoch: 6| Step: 10
Training loss: 2.4314147108911492
Validation loss: 2.547681681600743

Epoch: 6| Step: 11
Training loss: 2.7018409281057525
Validation loss: 2.5377103824107263

Epoch: 6| Step: 12
Training loss: 2.993818590497363
Validation loss: 2.535767614924161

Epoch: 6| Step: 13
Training loss: 2.394602041769372
Validation loss: 2.5472033583615974

Epoch: 275| Step: 0
Training loss: 3.113078609749673
Validation loss: 2.542178347755573

Epoch: 6| Step: 1
Training loss: 2.926125438700093
Validation loss: 2.539231046347005

Epoch: 6| Step: 2
Training loss: 3.50991941527976
Validation loss: 2.5383514887959198

Epoch: 6| Step: 3
Training loss: 2.855728408968292
Validation loss: 2.5585180448460063

Epoch: 6| Step: 4
Training loss: 2.9466365195871127
Validation loss: 2.559034580935862

Epoch: 6| Step: 5
Training loss: 2.445969076034435
Validation loss: 2.579839790071489

Epoch: 6| Step: 6
Training loss: 2.106493302507345
Validation loss: 2.5773201350771924

Epoch: 6| Step: 7
Training loss: 2.9418954632389602
Validation loss: 2.551919532995636

Epoch: 6| Step: 8
Training loss: 2.5480302870071734
Validation loss: 2.547794285097331

Epoch: 6| Step: 9
Training loss: 2.985722901494182
Validation loss: 2.5136112649124254

Epoch: 6| Step: 10
Training loss: 2.700795840487961
Validation loss: 2.498193070413064

Epoch: 6| Step: 11
Training loss: 2.5324184405344594
Validation loss: 2.505312778118149

Epoch: 6| Step: 12
Training loss: 2.3469334662376538
Validation loss: 2.497116307442861

Epoch: 6| Step: 13
Training loss: 2.88226296580953
Validation loss: 2.4985671808371697

Epoch: 276| Step: 0
Training loss: 2.9903766142280266
Validation loss: 2.491550196011622

Epoch: 6| Step: 1
Training loss: 3.085657343641806
Validation loss: 2.495093017342899

Epoch: 6| Step: 2
Training loss: 2.9094037407952036
Validation loss: 2.5093671531300683

Epoch: 6| Step: 3
Training loss: 2.8034796278886738
Validation loss: 2.5078977204197717

Epoch: 6| Step: 4
Training loss: 2.768122262167422
Validation loss: 2.5155580053502096

Epoch: 6| Step: 5
Training loss: 2.6968370631656025
Validation loss: 2.5224938184551293

Epoch: 6| Step: 6
Training loss: 3.24571649996492
Validation loss: 2.547069916299089

Epoch: 6| Step: 7
Training loss: 2.257615447107643
Validation loss: 2.555976315033781

Epoch: 6| Step: 8
Training loss: 2.470997234224063
Validation loss: 2.5773722783123714

Epoch: 6| Step: 9
Training loss: 2.9591229598322286
Validation loss: 2.594044173126955

Epoch: 6| Step: 10
Training loss: 2.763836298388447
Validation loss: 2.604077645697873

Epoch: 6| Step: 11
Training loss: 2.846766622010893
Validation loss: 2.6214141202440726

Epoch: 6| Step: 12
Training loss: 2.9346799909308547
Validation loss: 2.590431613018356

Epoch: 6| Step: 13
Training loss: 2.551071360799346
Validation loss: 2.586314105867003

Epoch: 277| Step: 0
Training loss: 2.2428954598448687
Validation loss: 2.560588339703613

Epoch: 6| Step: 1
Training loss: 2.2183302361370947
Validation loss: 2.5571664829205547

Epoch: 6| Step: 2
Training loss: 3.094030502395841
Validation loss: 2.5721187618925208

Epoch: 6| Step: 3
Training loss: 3.0538817608920743
Validation loss: 2.5748018636357095

Epoch: 6| Step: 4
Training loss: 2.913576469081689
Validation loss: 2.5790274662921755

Epoch: 6| Step: 5
Training loss: 2.3463393086348607
Validation loss: 2.5818926703737257

Epoch: 6| Step: 6
Training loss: 3.1723712100798447
Validation loss: 2.583700988150045

Epoch: 6| Step: 7
Training loss: 2.5030930458724794
Validation loss: 2.569642253697666

Epoch: 6| Step: 8
Training loss: 2.457788008211967
Validation loss: 2.5532867976016362

Epoch: 6| Step: 9
Training loss: 3.2979676664212105
Validation loss: 2.5424310498726386

Epoch: 6| Step: 10
Training loss: 2.3219105775553834
Validation loss: 2.5281757487097005

Epoch: 6| Step: 11
Training loss: 3.093866673591078
Validation loss: 2.5272593171813984

Epoch: 6| Step: 12
Training loss: 2.8523901169497243
Validation loss: 2.527303139704135

Epoch: 6| Step: 13
Training loss: 3.0561137662452764
Validation loss: 2.515417900775805

Epoch: 278| Step: 0
Training loss: 3.1686186212093754
Validation loss: 2.5247740453668968

Epoch: 6| Step: 1
Training loss: 2.125696068248387
Validation loss: 2.5228488837175513

Epoch: 6| Step: 2
Training loss: 2.676225655955917
Validation loss: 2.5177365628546524

Epoch: 6| Step: 3
Training loss: 2.6212265504034633
Validation loss: 2.5219447378275786

Epoch: 6| Step: 4
Training loss: 2.359708648736404
Validation loss: 2.5302309222885198

Epoch: 6| Step: 5
Training loss: 2.4737538678185755
Validation loss: 2.5300862249901495

Epoch: 6| Step: 6
Training loss: 2.3602644904683503
Validation loss: 2.5386854211377847

Epoch: 6| Step: 7
Training loss: 2.702863471108174
Validation loss: 2.557987705281631

Epoch: 6| Step: 8
Training loss: 3.069954965366737
Validation loss: 2.5797572383707656

Epoch: 6| Step: 9
Training loss: 2.677379626391887
Validation loss: 2.583873605616064

Epoch: 6| Step: 10
Training loss: 3.5627660819286207
Validation loss: 2.5665076456108675

Epoch: 6| Step: 11
Training loss: 3.277357281007899
Validation loss: 2.5528566783866875

Epoch: 6| Step: 12
Training loss: 3.009299487853074
Validation loss: 2.5425081667180724

Epoch: 6| Step: 13
Training loss: 2.7528494897306595
Validation loss: 2.5355925930353047

Epoch: 279| Step: 0
Training loss: 2.0823536921988213
Validation loss: 2.5242787362856407

Epoch: 6| Step: 1
Training loss: 3.198081758858008
Validation loss: 2.5339041178874058

Epoch: 6| Step: 2
Training loss: 2.385908972788846
Validation loss: 2.5302436640593444

Epoch: 6| Step: 3
Training loss: 3.26903476386433
Validation loss: 2.5370672830424237

Epoch: 6| Step: 4
Training loss: 2.9325939359197286
Validation loss: 2.5501118146657586

Epoch: 6| Step: 5
Training loss: 3.104880607140108
Validation loss: 2.5485090113256006

Epoch: 6| Step: 6
Training loss: 2.4946200657536886
Validation loss: 2.5433552262151213

Epoch: 6| Step: 7
Training loss: 2.772400224161311
Validation loss: 2.541411341795951

Epoch: 6| Step: 8
Training loss: 2.542124430806663
Validation loss: 2.5127795195001044

Epoch: 6| Step: 9
Training loss: 3.033608531694849
Validation loss: 2.519951325298228

Epoch: 6| Step: 10
Training loss: 2.8416384728189965
Validation loss: 2.5230385048905135

Epoch: 6| Step: 11
Training loss: 2.590944726446415
Validation loss: 2.537122298715682

Epoch: 6| Step: 12
Training loss: 2.5118214540262884
Validation loss: 2.562206364537083

Epoch: 6| Step: 13
Training loss: 2.928405644047434
Validation loss: 2.58963952921789

Epoch: 280| Step: 0
Training loss: 2.5303437294245392
Validation loss: 2.591909588598669

Epoch: 6| Step: 1
Training loss: 2.311634829777981
Validation loss: 2.574043636573724

Epoch: 6| Step: 2
Training loss: 2.908991679211489
Validation loss: 2.550925788942006

Epoch: 6| Step: 3
Training loss: 2.6774241506338625
Validation loss: 2.5296133379571404

Epoch: 6| Step: 4
Training loss: 3.1441493969431304
Validation loss: 2.5191556021719665

Epoch: 6| Step: 5
Training loss: 2.919518484363816
Validation loss: 2.5065580653996773

Epoch: 6| Step: 6
Training loss: 2.8039009032539925
Validation loss: 2.5209256474524655

Epoch: 6| Step: 7
Training loss: 3.4579314185998173
Validation loss: 2.5066758104317715

Epoch: 6| Step: 8
Training loss: 1.9893946799534157
Validation loss: 2.513727321118899

Epoch: 6| Step: 9
Training loss: 2.7679676543644636
Validation loss: 2.520418219548109

Epoch: 6| Step: 10
Training loss: 2.5857826947208125
Validation loss: 2.530131352244557

Epoch: 6| Step: 11
Training loss: 3.031848179893791
Validation loss: 2.5516016157484587

Epoch: 6| Step: 12
Training loss: 2.6522765115971083
Validation loss: 2.5460741293913003

Epoch: 6| Step: 13
Training loss: 2.786453779460478
Validation loss: 2.5739420886340576

Epoch: 281| Step: 0
Training loss: 2.5456583124196595
Validation loss: 2.5852196449277978

Epoch: 6| Step: 1
Training loss: 2.6161963564589943
Validation loss: 2.605399432047912

Epoch: 6| Step: 2
Training loss: 2.227029530583358
Validation loss: 2.60854823977214

Epoch: 6| Step: 3
Training loss: 2.6457066142657486
Validation loss: 2.5984072977242985

Epoch: 6| Step: 4
Training loss: 3.342857740912192
Validation loss: 2.589393706418385

Epoch: 6| Step: 5
Training loss: 2.460674356591008
Validation loss: 2.59367846120836

Epoch: 6| Step: 6
Training loss: 2.949913418032665
Validation loss: 2.5870641793036966

Epoch: 6| Step: 7
Training loss: 3.235772609515873
Validation loss: 2.5845726175206716

Epoch: 6| Step: 8
Training loss: 2.6655820389177993
Validation loss: 2.5296756127767623

Epoch: 6| Step: 9
Training loss: 3.2026127103198485
Validation loss: 2.5024745056860627

Epoch: 6| Step: 10
Training loss: 2.7484074229318254
Validation loss: 2.4796183019546394

Epoch: 6| Step: 11
Training loss: 2.8484635745815274
Validation loss: 2.482227744393363

Epoch: 6| Step: 12
Training loss: 2.632483940111751
Validation loss: 2.4821406655743026

Epoch: 6| Step: 13
Training loss: 2.9285311845679254
Validation loss: 2.4847247944908735

Epoch: 282| Step: 0
Training loss: 2.1781930483199856
Validation loss: 2.492728996257207

Epoch: 6| Step: 1
Training loss: 3.0923000752763627
Validation loss: 2.4907483432398574

Epoch: 6| Step: 2
Training loss: 2.6217034848734624
Validation loss: 2.496618745851793

Epoch: 6| Step: 3
Training loss: 2.772235706689827
Validation loss: 2.4969391676948027

Epoch: 6| Step: 4
Training loss: 2.995658275881843
Validation loss: 2.502853534959829

Epoch: 6| Step: 5
Training loss: 3.3344474520047043
Validation loss: 2.495024895982464

Epoch: 6| Step: 6
Training loss: 2.6517374640731575
Validation loss: 2.504781644771878

Epoch: 6| Step: 7
Training loss: 2.630677758555835
Validation loss: 2.4937136419804284

Epoch: 6| Step: 8
Training loss: 3.444074412606428
Validation loss: 2.4939091739397257

Epoch: 6| Step: 9
Training loss: 2.7715535387115176
Validation loss: 2.490196234619897

Epoch: 6| Step: 10
Training loss: 2.9993472978727946
Validation loss: 2.4925404654646948

Epoch: 6| Step: 11
Training loss: 2.4650400026182244
Validation loss: 2.4977924629446293

Epoch: 6| Step: 12
Training loss: 2.630932960528993
Validation loss: 2.519545378044819

Epoch: 6| Step: 13
Training loss: 2.4319951423295345
Validation loss: 2.5189603781551364

Epoch: 283| Step: 0
Training loss: 2.7599114489517027
Validation loss: 2.538633034657494

Epoch: 6| Step: 1
Training loss: 2.86993027552534
Validation loss: 2.6659102007839346

Epoch: 6| Step: 2
Training loss: 2.9380982783988476
Validation loss: 2.739520274612171

Epoch: 6| Step: 3
Training loss: 3.107343613977564
Validation loss: 2.757814427973283

Epoch: 6| Step: 4
Training loss: 2.0832992042289127
Validation loss: 2.727683914728945

Epoch: 6| Step: 5
Training loss: 2.8882502518327446
Validation loss: 2.711664755557396

Epoch: 6| Step: 6
Training loss: 2.9903710332199247
Validation loss: 2.6664267051952977

Epoch: 6| Step: 7
Training loss: 3.1395629301633776
Validation loss: 2.6132048511967105

Epoch: 6| Step: 8
Training loss: 3.3227772618691476
Validation loss: 2.529922305273618

Epoch: 6| Step: 9
Training loss: 2.2551091783910646
Validation loss: 2.489117520144863

Epoch: 6| Step: 10
Training loss: 2.6274123233645255
Validation loss: 2.4674364507511966

Epoch: 6| Step: 11
Training loss: 2.8445602771731155
Validation loss: 2.4829457952957874

Epoch: 6| Step: 12
Training loss: 2.9376723867926495
Validation loss: 2.5044806198238865

Epoch: 6| Step: 13
Training loss: 3.1142974688306886
Validation loss: 2.4974964219151174

Epoch: 284| Step: 0
Training loss: 3.0221471275399625
Validation loss: 2.51188155923564

Epoch: 6| Step: 1
Training loss: 3.162021911429359
Validation loss: 2.5235826054439574

Epoch: 6| Step: 2
Training loss: 2.066878324355459
Validation loss: 2.5305744689159813

Epoch: 6| Step: 3
Training loss: 2.7182006280885553
Validation loss: 2.5386849727732366

Epoch: 6| Step: 4
Training loss: 2.978146429475137
Validation loss: 2.5324226953496853

Epoch: 6| Step: 5
Training loss: 2.7175693798596177
Validation loss: 2.526673826466225

Epoch: 6| Step: 6
Training loss: 3.052518498944989
Validation loss: 2.530521088857382

Epoch: 6| Step: 7
Training loss: 2.7671944857767112
Validation loss: 2.5304807767503186

Epoch: 6| Step: 8
Training loss: 3.5011306026519735
Validation loss: 2.5267664189455634

Epoch: 6| Step: 9
Training loss: 2.5912353091230624
Validation loss: 2.5166846374585066

Epoch: 6| Step: 10
Training loss: 2.9545686614185533
Validation loss: 2.4963422576427234

Epoch: 6| Step: 11
Training loss: 3.3141960264623527
Validation loss: 2.4923722239227146

Epoch: 6| Step: 12
Training loss: 2.971523555348373
Validation loss: 2.4872070627285154

Epoch: 6| Step: 13
Training loss: 2.0124252115889347
Validation loss: 2.482889479029356

Epoch: 285| Step: 0
Training loss: 2.497046442555544
Validation loss: 2.4777864202405717

Epoch: 6| Step: 1
Training loss: 3.2383233632477246
Validation loss: 2.473826086960152

Epoch: 6| Step: 2
Training loss: 2.8074518463543394
Validation loss: 2.469411503558465

Epoch: 6| Step: 3
Training loss: 2.9339266205955226
Validation loss: 2.4803773697323295

Epoch: 6| Step: 4
Training loss: 3.0466054943907896
Validation loss: 2.480176249763423

Epoch: 6| Step: 5
Training loss: 2.407156142003689
Validation loss: 2.509609462482172

Epoch: 6| Step: 6
Training loss: 2.7515493709981
Validation loss: 2.53141182853502

Epoch: 6| Step: 7
Training loss: 2.9195406967961626
Validation loss: 2.5474580305922196

Epoch: 6| Step: 8
Training loss: 2.7601394130215935
Validation loss: 2.56564514808537

Epoch: 6| Step: 9
Training loss: 2.60191017554113
Validation loss: 2.5848081000043104

Epoch: 6| Step: 10
Training loss: 2.6851285185504272
Validation loss: 2.578839986679338

Epoch: 6| Step: 11
Training loss: 3.1698424493284287
Validation loss: 2.542845725037809

Epoch: 6| Step: 12
Training loss: 2.449223811921603
Validation loss: 2.5290158174111497

Epoch: 6| Step: 13
Training loss: 2.6012277931977605
Validation loss: 2.515484553667241

Epoch: 286| Step: 0
Training loss: 3.0735082714192297
Validation loss: 2.510594422236494

Epoch: 6| Step: 1
Training loss: 3.084966965657691
Validation loss: 2.5036076254744186

Epoch: 6| Step: 2
Training loss: 1.6137967890805005
Validation loss: 2.4932427258117684

Epoch: 6| Step: 3
Training loss: 2.8165081709410216
Validation loss: 2.500006731085791

Epoch: 6| Step: 4
Training loss: 2.885060496100924
Validation loss: 2.4863646038443563

Epoch: 6| Step: 5
Training loss: 3.04632610365295
Validation loss: 2.5069426457007364

Epoch: 6| Step: 6
Training loss: 2.77490118383477
Validation loss: 2.495200191774189

Epoch: 6| Step: 7
Training loss: 2.6198771306703623
Validation loss: 2.5059397226772737

Epoch: 6| Step: 8
Training loss: 3.342808385873035
Validation loss: 2.4998425270035125

Epoch: 6| Step: 9
Training loss: 2.617540933458363
Validation loss: 2.5250234280537716

Epoch: 6| Step: 10
Training loss: 2.214151910175869
Validation loss: 2.509500723396023

Epoch: 6| Step: 11
Training loss: 2.533237665862962
Validation loss: 2.506051037672919

Epoch: 6| Step: 12
Training loss: 2.363817894907136
Validation loss: 2.4997768548621604

Epoch: 6| Step: 13
Training loss: 3.5307076636908516
Validation loss: 2.514290774466923

Epoch: 287| Step: 0
Training loss: 2.876385893779992
Validation loss: 2.5412388412424045

Epoch: 6| Step: 1
Training loss: 2.8277489849524153
Validation loss: 2.5425714667279276

Epoch: 6| Step: 2
Training loss: 2.480752090731548
Validation loss: 2.5374614322870794

Epoch: 6| Step: 3
Training loss: 2.9250216752251785
Validation loss: 2.555869127342134

Epoch: 6| Step: 4
Training loss: 2.9454454144101905
Validation loss: 2.538942732971937

Epoch: 6| Step: 5
Training loss: 1.979712528109692
Validation loss: 2.5467304163784044

Epoch: 6| Step: 6
Training loss: 2.739070414016528
Validation loss: 2.5515834805201267

Epoch: 6| Step: 7
Training loss: 2.6640692120688447
Validation loss: 2.5387431565002636

Epoch: 6| Step: 8
Training loss: 2.7886917337976107
Validation loss: 2.5209093640898557

Epoch: 6| Step: 9
Training loss: 3.106515000397209
Validation loss: 2.501492191363844

Epoch: 6| Step: 10
Training loss: 3.0564153521220736
Validation loss: 2.4923578965872126

Epoch: 6| Step: 11
Training loss: 2.4823209320362354
Validation loss: 2.492724599640728

Epoch: 6| Step: 12
Training loss: 2.7924280883764334
Validation loss: 2.4842269171238387

Epoch: 6| Step: 13
Training loss: 2.7101216696421426
Validation loss: 2.486274441487488

Epoch: 288| Step: 0
Training loss: 2.3295362662664925
Validation loss: 2.482939435606121

Epoch: 6| Step: 1
Training loss: 2.7705475700465105
Validation loss: 2.4750934753466165

Epoch: 6| Step: 2
Training loss: 2.5907255256760893
Validation loss: 2.4832847412760906

Epoch: 6| Step: 3
Training loss: 2.7274516494899
Validation loss: 2.4823135539910837

Epoch: 6| Step: 4
Training loss: 2.913517714397311
Validation loss: 2.498023141644327

Epoch: 6| Step: 5
Training loss: 2.5014289586808474
Validation loss: 2.5139720986788507

Epoch: 6| Step: 6
Training loss: 2.9337249198267386
Validation loss: 2.522794581098179

Epoch: 6| Step: 7
Training loss: 2.654095752273747
Validation loss: 2.5460600347738143

Epoch: 6| Step: 8
Training loss: 2.6748291103644957
Validation loss: 2.5416811783442044

Epoch: 6| Step: 9
Training loss: 2.4373001603589555
Validation loss: 2.547422926764124

Epoch: 6| Step: 10
Training loss: 2.8547921899099418
Validation loss: 2.56388192339542

Epoch: 6| Step: 11
Training loss: 3.03440205397955
Validation loss: 2.563436105591532

Epoch: 6| Step: 12
Training loss: 2.7034653465910203
Validation loss: 2.5848845912900322

Epoch: 6| Step: 13
Training loss: 3.4562540506128783
Validation loss: 2.612397727685663

Epoch: 289| Step: 0
Training loss: 3.193850903494088
Validation loss: 2.5632332573829033

Epoch: 6| Step: 1
Training loss: 2.266022535503275
Validation loss: 2.5188318071388465

Epoch: 6| Step: 2
Training loss: 2.001178751719043
Validation loss: 2.5036834796361402

Epoch: 6| Step: 3
Training loss: 2.814343928826991
Validation loss: 2.4999210509273104

Epoch: 6| Step: 4
Training loss: 2.726342659643231
Validation loss: 2.4889827066734047

Epoch: 6| Step: 5
Training loss: 2.682366902799263
Validation loss: 2.4949192923298495

Epoch: 6| Step: 6
Training loss: 3.3294746635218866
Validation loss: 2.4954495095844176

Epoch: 6| Step: 7
Training loss: 2.6309654933764612
Validation loss: 2.499360309304274

Epoch: 6| Step: 8
Training loss: 3.0214884782009954
Validation loss: 2.504888001423208

Epoch: 6| Step: 9
Training loss: 2.7268092527470085
Validation loss: 2.5177000355431787

Epoch: 6| Step: 10
Training loss: 2.242363686899918
Validation loss: 2.541019868446362

Epoch: 6| Step: 11
Training loss: 3.150613870296484
Validation loss: 2.558467911180205

Epoch: 6| Step: 12
Training loss: 2.8510934104214702
Validation loss: 2.5860253524120607

Epoch: 6| Step: 13
Training loss: 2.3970564553460076
Validation loss: 2.577698204832102

Epoch: 290| Step: 0
Training loss: 2.7452314821901824
Validation loss: 2.565413040563117

Epoch: 6| Step: 1
Training loss: 2.229797155280886
Validation loss: 2.556818727120542

Epoch: 6| Step: 2
Training loss: 3.0093958266697234
Validation loss: 2.5614031358254956

Epoch: 6| Step: 3
Training loss: 2.5635426888792585
Validation loss: 2.547665833898012

Epoch: 6| Step: 4
Training loss: 3.0955333771481266
Validation loss: 2.5494626456853946

Epoch: 6| Step: 5
Training loss: 3.23364323248448
Validation loss: 2.533896260737681

Epoch: 6| Step: 6
Training loss: 2.131854949740577
Validation loss: 2.514448858700734

Epoch: 6| Step: 7
Training loss: 2.5841718563883496
Validation loss: 2.498130022067131

Epoch: 6| Step: 8
Training loss: 2.34779030009345
Validation loss: 2.5181685128817217

Epoch: 6| Step: 9
Training loss: 2.8863217877116956
Validation loss: 2.5436744260873105

Epoch: 6| Step: 10
Training loss: 3.4939853213634597
Validation loss: 2.5587606486305865

Epoch: 6| Step: 11
Training loss: 2.5919946452780147
Validation loss: 2.536101920846936

Epoch: 6| Step: 12
Training loss: 2.662160602840742
Validation loss: 2.5461477991305106

Epoch: 6| Step: 13
Training loss: 1.8316800364433607
Validation loss: 2.5490813294911003

Epoch: 291| Step: 0
Training loss: 2.610579161420782
Validation loss: 2.5385553527148286

Epoch: 6| Step: 1
Training loss: 2.9068537259353753
Validation loss: 2.5232951994871757

Epoch: 6| Step: 2
Training loss: 2.800808830604263
Validation loss: 2.5239112993617074

Epoch: 6| Step: 3
Training loss: 2.8439139853345505
Validation loss: 2.5252630158713294

Epoch: 6| Step: 4
Training loss: 2.9292161079094075
Validation loss: 2.5419573591584146

Epoch: 6| Step: 5
Training loss: 2.8910629353120383
Validation loss: 2.5195720150699015

Epoch: 6| Step: 6
Training loss: 3.047871275168549
Validation loss: 2.4990287668213265

Epoch: 6| Step: 7
Training loss: 2.2049780012836906
Validation loss: 2.4910368944098513

Epoch: 6| Step: 8
Training loss: 2.909833442142478
Validation loss: 2.4923781496492183

Epoch: 6| Step: 9
Training loss: 2.9191058903744396
Validation loss: 2.4853714322089395

Epoch: 6| Step: 10
Training loss: 2.7311019054216654
Validation loss: 2.479972957109031

Epoch: 6| Step: 11
Training loss: 2.8311023530503565
Validation loss: 2.486474252652568

Epoch: 6| Step: 12
Training loss: 2.0626246096797503
Validation loss: 2.5024904602989433

Epoch: 6| Step: 13
Training loss: 1.8525713011370193
Validation loss: 2.536526253929554

Epoch: 292| Step: 0
Training loss: 3.123864234523854
Validation loss: 2.5488491111705174

Epoch: 6| Step: 1
Training loss: 2.149161255045607
Validation loss: 2.556119019695184

Epoch: 6| Step: 2
Training loss: 2.532753015439768
Validation loss: 2.6073261195011286

Epoch: 6| Step: 3
Training loss: 2.6285569751087423
Validation loss: 2.6761441539099016

Epoch: 6| Step: 4
Training loss: 3.4133413151061593
Validation loss: 2.760102307805943

Epoch: 6| Step: 5
Training loss: 1.9226769735683478
Validation loss: 2.835239649181944

Epoch: 6| Step: 6
Training loss: 2.6648551231640365
Validation loss: 2.9636132108586732

Epoch: 6| Step: 7
Training loss: 2.821842528839687
Validation loss: 2.91335140794949

Epoch: 6| Step: 8
Training loss: 3.104568830889794
Validation loss: 2.814630543237033

Epoch: 6| Step: 9
Training loss: 2.846661094225299
Validation loss: 2.665092308917474

Epoch: 6| Step: 10
Training loss: 3.2411687146522965
Validation loss: 2.566451153165935

Epoch: 6| Step: 11
Training loss: 2.8944208739287673
Validation loss: 2.52255943070192

Epoch: 6| Step: 12
Training loss: 2.603532566436112
Validation loss: 2.4931213252622344

Epoch: 6| Step: 13
Training loss: 2.7948408348335727
Validation loss: 2.4851834387848553

Epoch: 293| Step: 0
Training loss: 3.218525999107914
Validation loss: 2.4859490335936245

Epoch: 6| Step: 1
Training loss: 2.8534106810356685
Validation loss: 2.479403265188958

Epoch: 6| Step: 2
Training loss: 2.679064708883678
Validation loss: 2.4877241224442765

Epoch: 6| Step: 3
Training loss: 3.128953950020693
Validation loss: 2.4869704812625204

Epoch: 6| Step: 4
Training loss: 2.2678573659890304
Validation loss: 2.4896963396518883

Epoch: 6| Step: 5
Training loss: 2.322628214307967
Validation loss: 2.4940178342149113

Epoch: 6| Step: 6
Training loss: 2.5779786964287976
Validation loss: 2.492989559326275

Epoch: 6| Step: 7
Training loss: 2.8353613906693167
Validation loss: 2.502239100320514

Epoch: 6| Step: 8
Training loss: 2.887069577590677
Validation loss: 2.500509186645259

Epoch: 6| Step: 9
Training loss: 2.956798226813821
Validation loss: 2.5008068469588305

Epoch: 6| Step: 10
Training loss: 2.5823811858062613
Validation loss: 2.5100480424582536

Epoch: 6| Step: 11
Training loss: 2.7574145324410404
Validation loss: 2.496635895132305

Epoch: 6| Step: 12
Training loss: 3.038408459104119
Validation loss: 2.5183779003031543

Epoch: 6| Step: 13
Training loss: 3.374321339507887
Validation loss: 2.5292501648225056

Epoch: 294| Step: 0
Training loss: 3.1935752865655
Validation loss: 2.5485258466390217

Epoch: 6| Step: 1
Training loss: 2.998655017717644
Validation loss: 2.5501422953368746

Epoch: 6| Step: 2
Training loss: 3.102177402836897
Validation loss: 2.5637832327844943

Epoch: 6| Step: 3
Training loss: 2.4990198121188043
Validation loss: 2.59386896601148

Epoch: 6| Step: 4
Training loss: 2.864411467974063
Validation loss: 2.609261249737421

Epoch: 6| Step: 5
Training loss: 2.7626378365906215
Validation loss: 2.625539220341998

Epoch: 6| Step: 6
Training loss: 2.841393133368646
Validation loss: 2.5838191895057303

Epoch: 6| Step: 7
Training loss: 2.365795872109424
Validation loss: 2.5676788772350796

Epoch: 6| Step: 8
Training loss: 2.6361253310814785
Validation loss: 2.5540662947694037

Epoch: 6| Step: 9
Training loss: 2.841606925567573
Validation loss: 2.544591535700979

Epoch: 6| Step: 10
Training loss: 2.0259591080058876
Validation loss: 2.541706614093821

Epoch: 6| Step: 11
Training loss: 2.9869994761744607
Validation loss: 2.546509693953134

Epoch: 6| Step: 12
Training loss: 1.826408689107122
Validation loss: 2.5143660096334233

Epoch: 6| Step: 13
Training loss: 2.8610306412657014
Validation loss: 2.5018365226074053

Epoch: 295| Step: 0
Training loss: 2.803763489743901
Validation loss: 2.4876658862474357

Epoch: 6| Step: 1
Training loss: 2.9875963011985984
Validation loss: 2.4838145697044927

Epoch: 6| Step: 2
Training loss: 2.369713974122791
Validation loss: 2.47335906995511

Epoch: 6| Step: 3
Training loss: 2.20690874418023
Validation loss: 2.472155783439815

Epoch: 6| Step: 4
Training loss: 2.509011050537879
Validation loss: 2.4823848724544257

Epoch: 6| Step: 5
Training loss: 2.730984400355101
Validation loss: 2.4766650212474457

Epoch: 6| Step: 6
Training loss: 3.294983814066609
Validation loss: 2.4729333141179954

Epoch: 6| Step: 7
Training loss: 2.1563664280515007
Validation loss: 2.4831428488086407

Epoch: 6| Step: 8
Training loss: 2.5851068459127866
Validation loss: 2.4929296881441676

Epoch: 6| Step: 9
Training loss: 3.312296591217477
Validation loss: 2.5031085254188032

Epoch: 6| Step: 10
Training loss: 3.1727809269992124
Validation loss: 2.5175745752163934

Epoch: 6| Step: 11
Training loss: 2.5498753760308706
Validation loss: 2.519744455496981

Epoch: 6| Step: 12
Training loss: 2.6185959399662755
Validation loss: 2.547765938726306

Epoch: 6| Step: 13
Training loss: 2.4901237912027416
Validation loss: 2.586147128220631

Epoch: 296| Step: 0
Training loss: 3.266087549478638
Validation loss: 2.6406581405964817

Epoch: 6| Step: 1
Training loss: 2.6284433215181937
Validation loss: 2.6722135254407835

Epoch: 6| Step: 2
Training loss: 3.050957863905875
Validation loss: 2.6469702247844706

Epoch: 6| Step: 3
Training loss: 2.4889913411095193
Validation loss: 2.618813437372078

Epoch: 6| Step: 4
Training loss: 2.195927869678735
Validation loss: 2.5682722129522264

Epoch: 6| Step: 5
Training loss: 2.5641140390408337
Validation loss: 2.5124241709675137

Epoch: 6| Step: 6
Training loss: 3.234068335401538
Validation loss: 2.5003964560979175

Epoch: 6| Step: 7
Training loss: 2.1786105869356405
Validation loss: 2.470772718987761

Epoch: 6| Step: 8
Training loss: 2.968925711802528
Validation loss: 2.470373394346939

Epoch: 6| Step: 9
Training loss: 3.066569213424451
Validation loss: 2.467746300572489

Epoch: 6| Step: 10
Training loss: 2.692845904871427
Validation loss: 2.4663729560424885

Epoch: 6| Step: 11
Training loss: 2.7759282492728596
Validation loss: 2.4607902820082326

Epoch: 6| Step: 12
Training loss: 2.6607794346792835
Validation loss: 2.468306279730843

Epoch: 6| Step: 13
Training loss: 2.358998754956223
Validation loss: 2.486988881487374

Epoch: 297| Step: 0
Training loss: 2.933288802184586
Validation loss: 2.525853177645549

Epoch: 6| Step: 1
Training loss: 2.798532857713249
Validation loss: 2.5597289965334378

Epoch: 6| Step: 2
Training loss: 2.8838318880688205
Validation loss: 2.5741394888228273

Epoch: 6| Step: 3
Training loss: 2.3557587250575587
Validation loss: 2.565737827444061

Epoch: 6| Step: 4
Training loss: 2.2934091590204115
Validation loss: 2.5640039280093165

Epoch: 6| Step: 5
Training loss: 2.157224794165187
Validation loss: 2.5581771660493473

Epoch: 6| Step: 6
Training loss: 2.0087757694321957
Validation loss: 2.554232529711728

Epoch: 6| Step: 7
Training loss: 2.6744742438330777
Validation loss: 2.541742291091171

Epoch: 6| Step: 8
Training loss: 3.16426534120262
Validation loss: 2.5178000977106794

Epoch: 6| Step: 9
Training loss: 3.067421675772588
Validation loss: 2.492105687435725

Epoch: 6| Step: 10
Training loss: 3.285550596175889
Validation loss: 2.4820066537395284

Epoch: 6| Step: 11
Training loss: 2.6621868432934486
Validation loss: 2.4707907594399074

Epoch: 6| Step: 12
Training loss: 2.3322462433285778
Validation loss: 2.4780413044317466

Epoch: 6| Step: 13
Training loss: 2.9769616848059592
Validation loss: 2.478359092604298

Epoch: 298| Step: 0
Training loss: 2.6875903092225664
Validation loss: 2.4958420991439776

Epoch: 6| Step: 1
Training loss: 2.939396023116465
Validation loss: 2.4903944016443615

Epoch: 6| Step: 2
Training loss: 2.6907639311433638
Validation loss: 2.5054550910670836

Epoch: 6| Step: 3
Training loss: 2.475895451866702
Validation loss: 2.5049648658227786

Epoch: 6| Step: 4
Training loss: 2.6559439987747644
Validation loss: 2.5270583229385193

Epoch: 6| Step: 5
Training loss: 2.1687550261601407
Validation loss: 2.5373025923357937

Epoch: 6| Step: 6
Training loss: 2.8204076861858796
Validation loss: 2.545969714798216

Epoch: 6| Step: 7
Training loss: 2.4317576920238753
Validation loss: 2.540936544870973

Epoch: 6| Step: 8
Training loss: 2.8326706578828174
Validation loss: 2.5504894145238324

Epoch: 6| Step: 9
Training loss: 3.154921752636472
Validation loss: 2.565582686163467

Epoch: 6| Step: 10
Training loss: 2.7406418837893916
Validation loss: 2.5656197927853124

Epoch: 6| Step: 11
Training loss: 2.654747122667023
Validation loss: 2.5532278307727134

Epoch: 6| Step: 12
Training loss: 2.4742315737094165
Validation loss: 2.570403224285097

Epoch: 6| Step: 13
Training loss: 2.734717560154902
Validation loss: 2.571294838261947

Epoch: 299| Step: 0
Training loss: 2.581066880646568
Validation loss: 2.554372777560186

Epoch: 6| Step: 1
Training loss: 2.582309448213794
Validation loss: 2.5616094641022134

Epoch: 6| Step: 2
Training loss: 2.5584980488125426
Validation loss: 2.540540132519189

Epoch: 6| Step: 3
Training loss: 2.6530296101849884
Validation loss: 2.534147342593465

Epoch: 6| Step: 4
Training loss: 2.532114140449374
Validation loss: 2.5178619591099127

Epoch: 6| Step: 5
Training loss: 2.282246202311729
Validation loss: 2.5342597361566104

Epoch: 6| Step: 6
Training loss: 3.21601173440491
Validation loss: 2.537269025258369

Epoch: 6| Step: 7
Training loss: 2.6354380570298757
Validation loss: 2.524632876257382

Epoch: 6| Step: 8
Training loss: 2.992364066469658
Validation loss: 2.539818462101433

Epoch: 6| Step: 9
Training loss: 2.9111334676911373
Validation loss: 2.52402934502508

Epoch: 6| Step: 10
Training loss: 2.582340931752656
Validation loss: 2.5133721402495297

Epoch: 6| Step: 11
Training loss: 2.0250574645377784
Validation loss: 2.504903351157177

Epoch: 6| Step: 12
Training loss: 3.1282493482753817
Validation loss: 2.5058745857870317

Epoch: 6| Step: 13
Training loss: 2.57515087241234
Validation loss: 2.5027521827701977

Epoch: 300| Step: 0
Training loss: 2.9707705397922703
Validation loss: 2.507328732910208

Epoch: 6| Step: 1
Training loss: 2.7151231800328075
Validation loss: 2.5353641778357394

Epoch: 6| Step: 2
Training loss: 2.329385198760678
Validation loss: 2.5303685162391627

Epoch: 6| Step: 3
Training loss: 2.9331415185924494
Validation loss: 2.525591181496555

Epoch: 6| Step: 4
Training loss: 2.755291962150635
Validation loss: 2.5322918694193124

Epoch: 6| Step: 5
Training loss: 2.550156053742104
Validation loss: 2.5430085254200603

Epoch: 6| Step: 6
Training loss: 2.790005991802823
Validation loss: 2.55018366985229

Epoch: 6| Step: 7
Training loss: 2.765660344991746
Validation loss: 2.5490006057779153

Epoch: 6| Step: 8
Training loss: 2.576055540013288
Validation loss: 2.5630001137336347

Epoch: 6| Step: 9
Training loss: 2.9625170679043373
Validation loss: 2.5705050855631453

Epoch: 6| Step: 10
Training loss: 2.3894684431088002
Validation loss: 2.558789301512309

Epoch: 6| Step: 11
Training loss: 2.4172555490986958
Validation loss: 2.5414685174275085

Epoch: 6| Step: 12
Training loss: 2.7042811572775123
Validation loss: 2.5063001956474675

Epoch: 6| Step: 13
Training loss: 3.051978742002995
Validation loss: 2.5127311514502857

Epoch: 301| Step: 0
Training loss: 2.455132313132592
Validation loss: 2.5047532241000874

Epoch: 6| Step: 1
Training loss: 2.335537573219581
Validation loss: 2.504326958237396

Epoch: 6| Step: 2
Training loss: 2.3539983863662983
Validation loss: 2.499472740931991

Epoch: 6| Step: 3
Training loss: 2.4117434328309515
Validation loss: 2.5244064672732733

Epoch: 6| Step: 4
Training loss: 2.808865551271479
Validation loss: 2.5505067745201058

Epoch: 6| Step: 5
Training loss: 2.5488214836180236
Validation loss: 2.5635809430553893

Epoch: 6| Step: 6
Training loss: 3.5966737215281093
Validation loss: 2.582467850808817

Epoch: 6| Step: 7
Training loss: 2.3262315257229
Validation loss: 2.698563825045218

Epoch: 6| Step: 8
Training loss: 2.719651697522122
Validation loss: 2.761138030185938

Epoch: 6| Step: 9
Training loss: 3.0797926359844525
Validation loss: 2.8138099327083643

Epoch: 6| Step: 10
Training loss: 3.4243965786836936
Validation loss: 2.776459794458975

Epoch: 6| Step: 11
Training loss: 2.7756009971785085
Validation loss: 2.6198539216819676

Epoch: 6| Step: 12
Training loss: 2.646647340606287
Validation loss: 2.527364630548791

Epoch: 6| Step: 13
Training loss: 3.1580544025646717
Validation loss: 2.4648659702205182

Epoch: 302| Step: 0
Training loss: 2.7410881251434156
Validation loss: 2.4799688697082405

Epoch: 6| Step: 1
Training loss: 3.428039015575752
Validation loss: 2.496936110140744

Epoch: 6| Step: 2
Training loss: 3.1099426671474726
Validation loss: 2.5255008674684554

Epoch: 6| Step: 3
Training loss: 3.0701696153934486
Validation loss: 2.5485348336089144

Epoch: 6| Step: 4
Training loss: 2.7988800874559665
Validation loss: 2.5479491214947223

Epoch: 6| Step: 5
Training loss: 2.5442083709660652
Validation loss: 2.5560253050273323

Epoch: 6| Step: 6
Training loss: 3.0948099189527363
Validation loss: 2.5570240432499696

Epoch: 6| Step: 7
Training loss: 3.1130049330405445
Validation loss: 2.5580657261335045

Epoch: 6| Step: 8
Training loss: 3.043513081629806
Validation loss: 2.5564198105573257

Epoch: 6| Step: 9
Training loss: 2.972596577710867
Validation loss: 2.5465795588573727

Epoch: 6| Step: 10
Training loss: 2.528618846137743
Validation loss: 2.5449396467008207

Epoch: 6| Step: 11
Training loss: 1.983561251337661
Validation loss: 2.5463148878041753

Epoch: 6| Step: 12
Training loss: 3.03234638954056
Validation loss: 2.540882738789403

Epoch: 6| Step: 13
Training loss: 3.3569466263951564
Validation loss: 2.54669391132482

Epoch: 303| Step: 0
Training loss: 2.7405602824835418
Validation loss: 2.538657113426101

Epoch: 6| Step: 1
Training loss: 2.72950799763422
Validation loss: 2.543469898018085

Epoch: 6| Step: 2
Training loss: 3.0546578408286797
Validation loss: 2.536840357811308

Epoch: 6| Step: 3
Training loss: 2.899399261077073
Validation loss: 2.546941273557591

Epoch: 6| Step: 4
Training loss: 3.3843652275979927
Validation loss: 2.549850409855459

Epoch: 6| Step: 5
Training loss: 2.558910181410891
Validation loss: 2.5665680004035107

Epoch: 6| Step: 6
Training loss: 2.384005288675062
Validation loss: 2.590312626707346

Epoch: 6| Step: 7
Training loss: 2.793375735207649
Validation loss: 2.5615741939150376

Epoch: 6| Step: 8
Training loss: 2.791901668697044
Validation loss: 2.5766622441457128

Epoch: 6| Step: 9
Training loss: 2.7456286105612624
Validation loss: 2.5709749134917512

Epoch: 6| Step: 10
Training loss: 2.895627533623163
Validation loss: 2.55789513749474

Epoch: 6| Step: 11
Training loss: 2.842599321574382
Validation loss: 2.555509817939617

Epoch: 6| Step: 12
Training loss: 2.7684123330630706
Validation loss: 2.578349554450729

Epoch: 6| Step: 13
Training loss: 2.929611652664019
Validation loss: 2.570266186113359

Epoch: 304| Step: 0
Training loss: 2.4699070790221858
Validation loss: 2.5766477925097875

Epoch: 6| Step: 1
Training loss: 2.996103617466639
Validation loss: 2.61626011263749

Epoch: 6| Step: 2
Training loss: 2.8134776641409247
Validation loss: 2.627740333972433

Epoch: 6| Step: 3
Training loss: 2.4824310950851594
Validation loss: 2.6295458248116

Epoch: 6| Step: 4
Training loss: 2.6706635701407073
Validation loss: 2.644728539333555

Epoch: 6| Step: 5
Training loss: 2.6759942854006296
Validation loss: 2.658147471241342

Epoch: 6| Step: 6
Training loss: 3.1398979598066634
Validation loss: 2.6562530845706216

Epoch: 6| Step: 7
Training loss: 2.674956034361425
Validation loss: 2.6061301267286785

Epoch: 6| Step: 8
Training loss: 2.911565534134189
Validation loss: 2.5404173411274376

Epoch: 6| Step: 9
Training loss: 2.5570942685350984
Validation loss: 2.5101723715273963

Epoch: 6| Step: 10
Training loss: 2.8449039004542533
Validation loss: 2.499735025494373

Epoch: 6| Step: 11
Training loss: 2.6750000641724765
Validation loss: 2.4925148041435756

Epoch: 6| Step: 12
Training loss: 2.578951616416899
Validation loss: 2.4890981345467336

Epoch: 6| Step: 13
Training loss: 2.9793870395347524
Validation loss: 2.480906827051734

Epoch: 305| Step: 0
Training loss: 2.4777784761884964
Validation loss: 2.479867391673047

Epoch: 6| Step: 1
Training loss: 2.7901863804299203
Validation loss: 2.4811905775442664

Epoch: 6| Step: 2
Training loss: 3.286260648284295
Validation loss: 2.4884093998194383

Epoch: 6| Step: 3
Training loss: 3.313183552012869
Validation loss: 2.4945934510718537

Epoch: 6| Step: 4
Training loss: 2.637471951882437
Validation loss: 2.4897931450272535

Epoch: 6| Step: 5
Training loss: 2.6588351964818693
Validation loss: 2.5260439251220537

Epoch: 6| Step: 6
Training loss: 2.543370743955929
Validation loss: 2.547701610583461

Epoch: 6| Step: 7
Training loss: 2.9201748231261138
Validation loss: 2.591056859717079

Epoch: 6| Step: 8
Training loss: 2.6435346655480236
Validation loss: 2.6400791630011553

Epoch: 6| Step: 9
Training loss: 2.5641332864143482
Validation loss: 2.6795480218824803

Epoch: 6| Step: 10
Training loss: 2.5950992246264377
Validation loss: 2.6501634792301534

Epoch: 6| Step: 11
Training loss: 2.65950324604362
Validation loss: 2.59147123627977

Epoch: 6| Step: 12
Training loss: 2.136487763523134
Validation loss: 2.523144334806913

Epoch: 6| Step: 13
Training loss: 2.7540478825503167
Validation loss: 2.491824448412196

Epoch: 306| Step: 0
Training loss: 2.983054942633723
Validation loss: 2.4933905508446985

Epoch: 6| Step: 1
Training loss: 2.460921417668185
Validation loss: 2.4874741663657765

Epoch: 6| Step: 2
Training loss: 2.9249577706703866
Validation loss: 2.4924944066529737

Epoch: 6| Step: 3
Training loss: 1.9853956346175066
Validation loss: 2.4961646295569966

Epoch: 6| Step: 4
Training loss: 3.2445008630796974
Validation loss: 2.515886579908478

Epoch: 6| Step: 5
Training loss: 2.379130836747024
Validation loss: 2.5151666024739714

Epoch: 6| Step: 6
Training loss: 2.9789353572084707
Validation loss: 2.523877855861859

Epoch: 6| Step: 7
Training loss: 2.821753981520459
Validation loss: 2.5310778511845364

Epoch: 6| Step: 8
Training loss: 2.5154739239743322
Validation loss: 2.541232793387457

Epoch: 6| Step: 9
Training loss: 2.9240748645993553
Validation loss: 2.528333538688477

Epoch: 6| Step: 10
Training loss: 2.4165457881644135
Validation loss: 2.55814055376211

Epoch: 6| Step: 11
Training loss: 2.835236433823668
Validation loss: 2.565001992293217

Epoch: 6| Step: 12
Training loss: 2.4683016599296814
Validation loss: 2.5780227407172918

Epoch: 6| Step: 13
Training loss: 2.8196689368094274
Validation loss: 2.5903387428631204

Epoch: 307| Step: 0
Training loss: 2.5235544655917583
Validation loss: 2.5515480114588818

Epoch: 6| Step: 1
Training loss: 2.621850258456992
Validation loss: 2.5333211657529286

Epoch: 6| Step: 2
Training loss: 2.3591177086402904
Validation loss: 2.5391457588674227

Epoch: 6| Step: 3
Training loss: 2.5610393920514305
Validation loss: 2.5309880631447834

Epoch: 6| Step: 4
Training loss: 2.5260278970139898
Validation loss: 2.530132150680773

Epoch: 6| Step: 5
Training loss: 2.778985205068392
Validation loss: 2.5283614458813872

Epoch: 6| Step: 6
Training loss: 2.845144412057825
Validation loss: 2.548495056923203

Epoch: 6| Step: 7
Training loss: 3.2691386179644932
Validation loss: 2.591726155728127

Epoch: 6| Step: 8
Training loss: 2.628217813891821
Validation loss: 2.616746622712027

Epoch: 6| Step: 9
Training loss: 3.3481194299249566
Validation loss: 2.66438552331435

Epoch: 6| Step: 10
Training loss: 2.8060455859526474
Validation loss: 2.6852335739474786

Epoch: 6| Step: 11
Training loss: 2.2286611203600013
Validation loss: 2.646142800193481

Epoch: 6| Step: 12
Training loss: 3.000483156080346
Validation loss: 2.62698909150733

Epoch: 6| Step: 13
Training loss: 2.998888604609048
Validation loss: 2.5993727283102794

Epoch: 308| Step: 0
Training loss: 2.0989954135039564
Validation loss: 2.5635310254071113

Epoch: 6| Step: 1
Training loss: 2.62098986992594
Validation loss: 2.5545872328711066

Epoch: 6| Step: 2
Training loss: 3.3121357843511627
Validation loss: 2.5329537733795098

Epoch: 6| Step: 3
Training loss: 2.5666001245204195
Validation loss: 2.51119474467059

Epoch: 6| Step: 4
Training loss: 2.7892420093886576
Validation loss: 2.5124588791329963

Epoch: 6| Step: 5
Training loss: 2.1758890724518185
Validation loss: 2.515353186670169

Epoch: 6| Step: 6
Training loss: 2.4234513597811485
Validation loss: 2.5113122763913527

Epoch: 6| Step: 7
Training loss: 3.166078429213983
Validation loss: 2.506048599909875

Epoch: 6| Step: 8
Training loss: 3.070083726120215
Validation loss: 2.4885985237745256

Epoch: 6| Step: 9
Training loss: 2.373123833307156
Validation loss: 2.4933685935670336

Epoch: 6| Step: 10
Training loss: 2.836686300829107
Validation loss: 2.4980583367363822

Epoch: 6| Step: 11
Training loss: 2.49521445963768
Validation loss: 2.5014285415585373

Epoch: 6| Step: 12
Training loss: 2.429247064933955
Validation loss: 2.5123206048291684

Epoch: 6| Step: 13
Training loss: 3.3330703313705077
Validation loss: 2.52224346908639

Epoch: 309| Step: 0
Training loss: 2.1595327846885146
Validation loss: 2.508744117463454

Epoch: 6| Step: 1
Training loss: 2.8575496996998813
Validation loss: 2.5185303422317675

Epoch: 6| Step: 2
Training loss: 2.146239665055983
Validation loss: 2.5076274586967244

Epoch: 6| Step: 3
Training loss: 2.2636000430120427
Validation loss: 2.5021754633675295

Epoch: 6| Step: 4
Training loss: 3.083958708431035
Validation loss: 2.508245490626482

Epoch: 6| Step: 5
Training loss: 2.8716794616744794
Validation loss: 2.5031478076409

Epoch: 6| Step: 6
Training loss: 2.5772928455479494
Validation loss: 2.5127867713625145

Epoch: 6| Step: 7
Training loss: 3.0943633733418086
Validation loss: 2.5259684861728258

Epoch: 6| Step: 8
Training loss: 2.8169997776344218
Validation loss: 2.536456433522251

Epoch: 6| Step: 9
Training loss: 2.3201318535661133
Validation loss: 2.5458000275450092

Epoch: 6| Step: 10
Training loss: 2.923432287051489
Validation loss: 2.533315290258344

Epoch: 6| Step: 11
Training loss: 3.1302676245500405
Validation loss: 2.5194270958326346

Epoch: 6| Step: 12
Training loss: 1.9970866083725418
Validation loss: 2.5323009023602028

Epoch: 6| Step: 13
Training loss: 2.985371528136949
Validation loss: 2.5352850852397166

Epoch: 310| Step: 0
Training loss: 2.813039855007496
Validation loss: 2.539385202503082

Epoch: 6| Step: 1
Training loss: 3.0289985711543634
Validation loss: 2.5375884279872345

Epoch: 6| Step: 2
Training loss: 2.608001438836713
Validation loss: 2.5345878454948934

Epoch: 6| Step: 3
Training loss: 2.9925619742621548
Validation loss: 2.5396619206888973

Epoch: 6| Step: 4
Training loss: 2.9284202988603503
Validation loss: 2.5435084802932937

Epoch: 6| Step: 5
Training loss: 2.497720823864197
Validation loss: 2.5521563236797595

Epoch: 6| Step: 6
Training loss: 2.7162262175318035
Validation loss: 2.5517074706644682

Epoch: 6| Step: 7
Training loss: 2.1400758359074703
Validation loss: 2.5772759544428654

Epoch: 6| Step: 8
Training loss: 2.757853045719341
Validation loss: 2.548856297624371

Epoch: 6| Step: 9
Training loss: 3.150630518464422
Validation loss: 2.5655995473350703

Epoch: 6| Step: 10
Training loss: 2.4364065016090324
Validation loss: 2.532655435911121

Epoch: 6| Step: 11
Training loss: 1.9459607985881227
Validation loss: 2.5096607836102294

Epoch: 6| Step: 12
Training loss: 2.683004833829878
Validation loss: 2.494829075372886

Epoch: 6| Step: 13
Training loss: 1.64960853961451
Validation loss: 2.49024489623937

Epoch: 311| Step: 0
Training loss: 2.593195844534375
Validation loss: 2.4914502094046767

Epoch: 6| Step: 1
Training loss: 2.4797678520389974
Validation loss: 2.5004494109294417

Epoch: 6| Step: 2
Training loss: 2.735553857908007
Validation loss: 2.4966388031358573

Epoch: 6| Step: 3
Training loss: 2.9426767713266386
Validation loss: 2.4836373028813106

Epoch: 6| Step: 4
Training loss: 3.0930620449686876
Validation loss: 2.4884555620562985

Epoch: 6| Step: 5
Training loss: 1.849802460305121
Validation loss: 2.4997839126721058

Epoch: 6| Step: 6
Training loss: 3.13256286996404
Validation loss: 2.520336246184709

Epoch: 6| Step: 7
Training loss: 2.709490475069246
Validation loss: 2.5482229730568875

Epoch: 6| Step: 8
Training loss: 2.3779738028505397
Validation loss: 2.548040209406781

Epoch: 6| Step: 9
Training loss: 2.6143471863224907
Validation loss: 2.5451799725411286

Epoch: 6| Step: 10
Training loss: 2.72744483115733
Validation loss: 2.566844532722971

Epoch: 6| Step: 11
Training loss: 2.7250053965663845
Validation loss: 2.589039048604133

Epoch: 6| Step: 12
Training loss: 2.6945856413490468
Validation loss: 2.6334795820758017

Epoch: 6| Step: 13
Training loss: 2.769826596199906
Validation loss: 2.652340384447418

Epoch: 312| Step: 0
Training loss: 2.7207110117998576
Validation loss: 2.6448566751964417

Epoch: 6| Step: 1
Training loss: 2.672698847596535
Validation loss: 2.5871815561644342

Epoch: 6| Step: 2
Training loss: 2.5545437740294483
Validation loss: 2.55297345494777

Epoch: 6| Step: 3
Training loss: 2.406659178189421
Validation loss: 2.523809090367647

Epoch: 6| Step: 4
Training loss: 2.4684709801717237
Validation loss: 2.5104398821230167

Epoch: 6| Step: 5
Training loss: 2.9914747539655555
Validation loss: 2.5016376371731766

Epoch: 6| Step: 6
Training loss: 2.7308828670171703
Validation loss: 2.4885085330127605

Epoch: 6| Step: 7
Training loss: 2.846741496702476
Validation loss: 2.4826226333700587

Epoch: 6| Step: 8
Training loss: 2.288603544606887
Validation loss: 2.510126819063177

Epoch: 6| Step: 9
Training loss: 2.4770191625994267
Validation loss: 2.5055587783025257

Epoch: 6| Step: 10
Training loss: 2.7843766371939456
Validation loss: 2.512298146143428

Epoch: 6| Step: 11
Training loss: 2.8023476363730193
Validation loss: 2.5149089752414864

Epoch: 6| Step: 12
Training loss: 3.2800677394850175
Validation loss: 2.515676520432811

Epoch: 6| Step: 13
Training loss: 2.430636107305846
Validation loss: 2.549685729725912

Epoch: 313| Step: 0
Training loss: 2.9261200610630063
Validation loss: 2.5812650320623525

Epoch: 6| Step: 1
Training loss: 2.29724927694351
Validation loss: 2.6214867758677998

Epoch: 6| Step: 2
Training loss: 2.907214589169583
Validation loss: 2.6384614528843495

Epoch: 6| Step: 3
Training loss: 2.6146969916170386
Validation loss: 2.6531442648445487

Epoch: 6| Step: 4
Training loss: 2.4512942340600476
Validation loss: 2.642924334430172

Epoch: 6| Step: 5
Training loss: 2.599943739942597
Validation loss: 2.6279246342174396

Epoch: 6| Step: 6
Training loss: 3.292439012013305
Validation loss: 2.6358003792166143

Epoch: 6| Step: 7
Training loss: 2.606792702648233
Validation loss: 2.6083032146967544

Epoch: 6| Step: 8
Training loss: 1.8909965339237524
Validation loss: 2.5768341711047955

Epoch: 6| Step: 9
Training loss: 2.957250226679887
Validation loss: 2.5801609476220393

Epoch: 6| Step: 10
Training loss: 2.4923028709948243
Validation loss: 2.5873123874529185

Epoch: 6| Step: 11
Training loss: 2.9415365851353017
Validation loss: 2.590718420730073

Epoch: 6| Step: 12
Training loss: 2.890252166623169
Validation loss: 2.5800227613813136

Epoch: 6| Step: 13
Training loss: 2.496487438693649
Validation loss: 2.579992723155016

Epoch: 314| Step: 0
Training loss: 2.7677352526849597
Validation loss: 2.5640467535828213

Epoch: 6| Step: 1
Training loss: 2.677379626391887
Validation loss: 2.521476898038662

Epoch: 6| Step: 2
Training loss: 2.739658156462229
Validation loss: 2.5125291041777857

Epoch: 6| Step: 3
Training loss: 2.3880998826471878
Validation loss: 2.513412336104609

Epoch: 6| Step: 4
Training loss: 2.9809147612303013
Validation loss: 2.500351753920014

Epoch: 6| Step: 5
Training loss: 2.5589998112298704
Validation loss: 2.499172390571869

Epoch: 6| Step: 6
Training loss: 2.40679974902169
Validation loss: 2.494918701491683

Epoch: 6| Step: 7
Training loss: 2.706079180746695
Validation loss: 2.496686236385077

Epoch: 6| Step: 8
Training loss: 2.5393511329334837
Validation loss: 2.502688370382324

Epoch: 6| Step: 9
Training loss: 2.347751913803307
Validation loss: 2.501778330043694

Epoch: 6| Step: 10
Training loss: 2.8654365702238245
Validation loss: 2.5137343499586655

Epoch: 6| Step: 11
Training loss: 2.89457671712772
Validation loss: 2.526334784174717

Epoch: 6| Step: 12
Training loss: 2.516143555831958
Validation loss: 2.5387834363725355

Epoch: 6| Step: 13
Training loss: 2.5935922597695504
Validation loss: 2.5532453940497626

Epoch: 315| Step: 0
Training loss: 2.427292013952193
Validation loss: 2.5611008246490496

Epoch: 6| Step: 1
Training loss: 2.1592605140909704
Validation loss: 2.596746649647321

Epoch: 6| Step: 2
Training loss: 2.8983996612464398
Validation loss: 2.6317552194080025

Epoch: 6| Step: 3
Training loss: 3.2079113439167375
Validation loss: 2.6212733644138217

Epoch: 6| Step: 4
Training loss: 2.8787969312266948
Validation loss: 2.591412248466348

Epoch: 6| Step: 5
Training loss: 2.9113991355450795
Validation loss: 2.5746681542743723

Epoch: 6| Step: 6
Training loss: 1.7364375591656336
Validation loss: 2.56709642255022

Epoch: 6| Step: 7
Training loss: 3.1388104259245377
Validation loss: 2.5533068946894613

Epoch: 6| Step: 8
Training loss: 2.599408240100033
Validation loss: 2.541380504218257

Epoch: 6| Step: 9
Training loss: 2.3737646202693785
Validation loss: 2.5306258683573213

Epoch: 6| Step: 10
Training loss: 2.8094442085338263
Validation loss: 2.5207953470965276

Epoch: 6| Step: 11
Training loss: 1.843303497043095
Validation loss: 2.503678824766123

Epoch: 6| Step: 12
Training loss: 2.607869336312838
Validation loss: 2.488695541821629

Epoch: 6| Step: 13
Training loss: 3.006533660512457
Validation loss: 2.4950059231039186

Epoch: 316| Step: 0
Training loss: 2.3066100296976
Validation loss: 2.4743543103106025

Epoch: 6| Step: 1
Training loss: 3.047768173372615
Validation loss: 2.4786381670475834

Epoch: 6| Step: 2
Training loss: 2.7508451723593024
Validation loss: 2.4694791698048646

Epoch: 6| Step: 3
Training loss: 2.265742226560479
Validation loss: 2.475348013355147

Epoch: 6| Step: 4
Training loss: 3.264803404329409
Validation loss: 2.5105427627916432

Epoch: 6| Step: 5
Training loss: 2.70828671537528
Validation loss: 2.5116757732232013

Epoch: 6| Step: 6
Training loss: 2.11897208251133
Validation loss: 2.528695634997165

Epoch: 6| Step: 7
Training loss: 2.8651193753016653
Validation loss: 2.557416352758455

Epoch: 6| Step: 8
Training loss: 2.766703939378297
Validation loss: 2.609344011633275

Epoch: 6| Step: 9
Training loss: 2.490276405129377
Validation loss: 2.6235999100837266

Epoch: 6| Step: 10
Training loss: 2.432264623280607
Validation loss: 2.639831276110645

Epoch: 6| Step: 11
Training loss: 2.842044528513018
Validation loss: 2.6388311621226395

Epoch: 6| Step: 12
Training loss: 2.1601468684456653
Validation loss: 2.5921757933699126

Epoch: 6| Step: 13
Training loss: 2.3706966362972968
Validation loss: 2.5761307437223606

Epoch: 317| Step: 0
Training loss: 3.1776842560007377
Validation loss: 2.584160864395467

Epoch: 6| Step: 1
Training loss: 2.555890841073929
Validation loss: 2.5696293748154604

Epoch: 6| Step: 2
Training loss: 3.1706104482613475
Validation loss: 2.558926377244439

Epoch: 6| Step: 3
Training loss: 2.4786677993941457
Validation loss: 2.593902180162517

Epoch: 6| Step: 4
Training loss: 2.060440653734301
Validation loss: 2.6169349427333803

Epoch: 6| Step: 5
Training loss: 2.20437326983348
Validation loss: 2.6482124011528114

Epoch: 6| Step: 6
Training loss: 2.1281070433991998
Validation loss: 2.647518821289268

Epoch: 6| Step: 7
Training loss: 2.251787958763096
Validation loss: 2.650791510263238

Epoch: 6| Step: 8
Training loss: 2.5583270450808837
Validation loss: 2.6157051385731074

Epoch: 6| Step: 9
Training loss: 2.472494352081606
Validation loss: 2.6028366784620065

Epoch: 6| Step: 10
Training loss: 3.086127707498467
Validation loss: 2.554550180755166

Epoch: 6| Step: 11
Training loss: 3.0036019318685545
Validation loss: 2.5166690101794624

Epoch: 6| Step: 12
Training loss: 2.1852529701428316
Validation loss: 2.4710081589939668

Epoch: 6| Step: 13
Training loss: 2.969538052015937
Validation loss: 2.454443078005145

Epoch: 318| Step: 0
Training loss: 2.711680549565724
Validation loss: 2.465895922417512

Epoch: 6| Step: 1
Training loss: 2.3328103660170036
Validation loss: 2.4604239354232846

Epoch: 6| Step: 2
Training loss: 2.8012625095917096
Validation loss: 2.461567260772744

Epoch: 6| Step: 3
Training loss: 2.4017041355080773
Validation loss: 2.4735180864737427

Epoch: 6| Step: 4
Training loss: 3.43526302724336
Validation loss: 2.4966155728985293

Epoch: 6| Step: 5
Training loss: 2.58594432265197
Validation loss: 2.5217258626256105

Epoch: 6| Step: 6
Training loss: 2.2795579461666775
Validation loss: 2.53519758392438

Epoch: 6| Step: 7
Training loss: 3.06981952000048
Validation loss: 2.5865785761846105

Epoch: 6| Step: 8
Training loss: 2.829809709223834
Validation loss: 2.6031972788062787

Epoch: 6| Step: 9
Training loss: 2.3831253596800046
Validation loss: 2.606524414526394

Epoch: 6| Step: 10
Training loss: 2.0492302542686036
Validation loss: 2.574201523024205

Epoch: 6| Step: 11
Training loss: 2.721502905375051
Validation loss: 2.5764697725497183

Epoch: 6| Step: 12
Training loss: 2.2211894204933142
Validation loss: 2.545608152085816

Epoch: 6| Step: 13
Training loss: 2.228844259839422
Validation loss: 2.550657428412757

Epoch: 319| Step: 0
Training loss: 2.2718897004419296
Validation loss: 2.554175004960719

Epoch: 6| Step: 1
Training loss: 2.710117007048687
Validation loss: 2.5577220096437707

Epoch: 6| Step: 2
Training loss: 2.359369139000895
Validation loss: 2.5814009937539457

Epoch: 6| Step: 3
Training loss: 2.6788775496170567
Validation loss: 2.569571756765421

Epoch: 6| Step: 4
Training loss: 2.7180353738196565
Validation loss: 2.596435449495705

Epoch: 6| Step: 5
Training loss: 2.375707420599392
Validation loss: 2.581001491294163

Epoch: 6| Step: 6
Training loss: 2.0217463079470455
Validation loss: 2.580990128219198

Epoch: 6| Step: 7
Training loss: 2.65533251905353
Validation loss: 2.568101906977105

Epoch: 6| Step: 8
Training loss: 2.930432685176555
Validation loss: 2.565538177494028

Epoch: 6| Step: 9
Training loss: 2.6315189432531074
Validation loss: 2.593060501281131

Epoch: 6| Step: 10
Training loss: 2.060128206504121
Validation loss: 2.570743889016457

Epoch: 6| Step: 11
Training loss: 2.815113718097209
Validation loss: 2.571281859978059

Epoch: 6| Step: 12
Training loss: 2.816728761278199
Validation loss: 2.5491238214573055

Epoch: 6| Step: 13
Training loss: 2.893070485558833
Validation loss: 2.5264036894516484

Epoch: 320| Step: 0
Training loss: 1.9510224889439671
Validation loss: 2.4818966588125186

Epoch: 6| Step: 1
Training loss: 3.018870134510275
Validation loss: 2.4838878886447273

Epoch: 6| Step: 2
Training loss: 2.5681363897379725
Validation loss: 2.4701106022986776

Epoch: 6| Step: 3
Training loss: 2.8764697754609947
Validation loss: 2.4756695432882005

Epoch: 6| Step: 4
Training loss: 2.264681178847785
Validation loss: 2.473217567373088

Epoch: 6| Step: 5
Training loss: 2.708024012190096
Validation loss: 2.4810416794618533

Epoch: 6| Step: 6
Training loss: 2.5682457496253646
Validation loss: 2.489713467624873

Epoch: 6| Step: 7
Training loss: 2.2776617806317696
Validation loss: 2.532312868616143

Epoch: 6| Step: 8
Training loss: 3.126879927703555
Validation loss: 2.5724362552613522

Epoch: 6| Step: 9
Training loss: 2.612374232427089
Validation loss: 2.6076658498469008

Epoch: 6| Step: 10
Training loss: 3.0747580146167124
Validation loss: 2.6224335128264262

Epoch: 6| Step: 11
Training loss: 2.773839615160243
Validation loss: 2.6132579245521828

Epoch: 6| Step: 12
Training loss: 2.08860659478562
Validation loss: 2.570812856994488

Epoch: 6| Step: 13
Training loss: 2.666952316561636
Validation loss: 2.5581758011401754

Epoch: 321| Step: 0
Training loss: 2.4111094761426375
Validation loss: 2.5368765448549597

Epoch: 6| Step: 1
Training loss: 2.5663677892023906
Validation loss: 2.5377345982301898

Epoch: 6| Step: 2
Training loss: 2.969622674471515
Validation loss: 2.5684968971825968

Epoch: 6| Step: 3
Training loss: 2.4184141965877815
Validation loss: 2.563293280218237

Epoch: 6| Step: 4
Training loss: 2.9048568503848906
Validation loss: 2.56970612637267

Epoch: 6| Step: 5
Training loss: 2.282242545976604
Validation loss: 2.5690739571212395

Epoch: 6| Step: 6
Training loss: 2.8719137461044117
Validation loss: 2.5852218424297564

Epoch: 6| Step: 7
Training loss: 3.1685809991375797
Validation loss: 2.5412978199359606

Epoch: 6| Step: 8
Training loss: 2.4138543986773344
Validation loss: 2.531817993462263

Epoch: 6| Step: 9
Training loss: 2.3897586823581176
Validation loss: 2.5065452489948323

Epoch: 6| Step: 10
Training loss: 2.7221862299695783
Validation loss: 2.5155692991473266

Epoch: 6| Step: 11
Training loss: 2.141753296145257
Validation loss: 2.5027228212430233

Epoch: 6| Step: 12
Training loss: 2.0554943748625423
Validation loss: 2.50088119563656

Epoch: 6| Step: 13
Training loss: 2.394768508681906
Validation loss: 2.494027675462509

Epoch: 322| Step: 0
Training loss: 2.506432269310721
Validation loss: 2.478169883428431

Epoch: 6| Step: 1
Training loss: 2.3109878544869997
Validation loss: 2.4780718149902428

Epoch: 6| Step: 2
Training loss: 2.418965517836737
Validation loss: 2.488567682822

Epoch: 6| Step: 3
Training loss: 2.508294650399481
Validation loss: 2.5134274767030806

Epoch: 6| Step: 4
Training loss: 2.495075621137382
Validation loss: 2.521299172864186

Epoch: 6| Step: 5
Training loss: 1.8692265952179312
Validation loss: 2.5345150737669964

Epoch: 6| Step: 6
Training loss: 3.0676817361210826
Validation loss: 2.5699740295243925

Epoch: 6| Step: 7
Training loss: 2.2548888393501634
Validation loss: 2.565850487306975

Epoch: 6| Step: 8
Training loss: 2.6603775268479595
Validation loss: 2.5946753479998965

Epoch: 6| Step: 9
Training loss: 2.8789029373708894
Validation loss: 2.5815422989273964

Epoch: 6| Step: 10
Training loss: 3.074964730905621
Validation loss: 2.5870711377164324

Epoch: 6| Step: 11
Training loss: 2.385654143349557
Validation loss: 2.552807330329074

Epoch: 6| Step: 12
Training loss: 2.4914395636038567
Validation loss: 2.5525445443928927

Epoch: 6| Step: 13
Training loss: 2.6115489743640095
Validation loss: 2.547502809863712

Epoch: 323| Step: 0
Training loss: 2.6641904738667765
Validation loss: 2.5387287722635623

Epoch: 6| Step: 1
Training loss: 2.767717507351588
Validation loss: 2.5387528546682616

Epoch: 6| Step: 2
Training loss: 1.7774322823073954
Validation loss: 2.546079798228882

Epoch: 6| Step: 3
Training loss: 2.3718568180477977
Validation loss: 2.522492077512142

Epoch: 6| Step: 4
Training loss: 2.459518459454753
Validation loss: 2.5344429028158117

Epoch: 6| Step: 5
Training loss: 2.640083844414016
Validation loss: 2.5350605145037735

Epoch: 6| Step: 6
Training loss: 1.8982163288652467
Validation loss: 2.5543699011600527

Epoch: 6| Step: 7
Training loss: 2.5860211223438876
Validation loss: 2.571323383875043

Epoch: 6| Step: 8
Training loss: 2.726414192778848
Validation loss: 2.597845936135775

Epoch: 6| Step: 9
Training loss: 1.936971592373325
Validation loss: 2.6070477646696033

Epoch: 6| Step: 10
Training loss: 2.6895671257951
Validation loss: 2.631058232731373

Epoch: 6| Step: 11
Training loss: 2.4629095985837357
Validation loss: 2.627414995883059

Epoch: 6| Step: 12
Training loss: 3.2484426435069307
Validation loss: 2.5897057874111113

Epoch: 6| Step: 13
Training loss: 3.334205481555884
Validation loss: 2.5358106868592216

Epoch: 324| Step: 0
Training loss: 2.4341728782726917
Validation loss: 2.4680882807111484

Epoch: 6| Step: 1
Training loss: 2.486777433565247
Validation loss: 2.4534334817375347

Epoch: 6| Step: 2
Training loss: 2.357395781947041
Validation loss: 2.4400037417676463

Epoch: 6| Step: 3
Training loss: 3.0809687921366744
Validation loss: 2.433928496998137

Epoch: 6| Step: 4
Training loss: 2.3772948371300653
Validation loss: 2.4417861589071186

Epoch: 6| Step: 5
Training loss: 2.23267764197441
Validation loss: 2.442124071220568

Epoch: 6| Step: 6
Training loss: 2.86056693826818
Validation loss: 2.4424336658099985

Epoch: 6| Step: 7
Training loss: 2.3450945240157384
Validation loss: 2.447838104460545

Epoch: 6| Step: 8
Training loss: 3.004998176053679
Validation loss: 2.4745446669740483

Epoch: 6| Step: 9
Training loss: 2.8435616902474043
Validation loss: 2.4857800705700974

Epoch: 6| Step: 10
Training loss: 2.6886184494206207
Validation loss: 2.5230624195315015

Epoch: 6| Step: 11
Training loss: 2.0305847252268157
Validation loss: 2.578453783317559

Epoch: 6| Step: 12
Training loss: 2.23161818087239
Validation loss: 2.658887754335046

Epoch: 6| Step: 13
Training loss: 2.804741309029657
Validation loss: 2.6925378900483494

Epoch: 325| Step: 0
Training loss: 2.5254412274996003
Validation loss: 2.7571500358844228

Epoch: 6| Step: 1
Training loss: 3.0745537658943287
Validation loss: 2.78478162290245

Epoch: 6| Step: 2
Training loss: 2.7999502995031
Validation loss: 2.7815441525868803

Epoch: 6| Step: 3
Training loss: 2.865599813735419
Validation loss: 2.768627995850863

Epoch: 6| Step: 4
Training loss: 2.201409070724358
Validation loss: 2.6888429272685035

Epoch: 6| Step: 5
Training loss: 2.8569258743726893
Validation loss: 2.643829570096376

Epoch: 6| Step: 6
Training loss: 2.7704356967063792
Validation loss: 2.589918524633791

Epoch: 6| Step: 7
Training loss: 2.6657759450411724
Validation loss: 2.6001629208050705

Epoch: 6| Step: 8
Training loss: 2.4962326273841327
Validation loss: 2.5504987895998963

Epoch: 6| Step: 9
Training loss: 2.434252017713488
Validation loss: 2.53109809777217

Epoch: 6| Step: 10
Training loss: 2.4759657468752887
Validation loss: 2.4972321303335145

Epoch: 6| Step: 11
Training loss: 2.573491967834425
Validation loss: 2.4740918053641283

Epoch: 6| Step: 12
Training loss: 2.62975860880351
Validation loss: 2.451283414909685

Epoch: 6| Step: 13
Training loss: 1.7198389245172905
Validation loss: 2.4197712134221874

Epoch: 326| Step: 0
Training loss: 2.426425129673716
Validation loss: 2.4084764356819477

Epoch: 6| Step: 1
Training loss: 2.176129681341314
Validation loss: 2.4112037781785665

Epoch: 6| Step: 2
Training loss: 2.8118595665692365
Validation loss: 2.4110539392119534

Epoch: 6| Step: 3
Training loss: 2.054428954592437
Validation loss: 2.415792630349039

Epoch: 6| Step: 4
Training loss: 2.950915605083479
Validation loss: 2.4173177256553413

Epoch: 6| Step: 5
Training loss: 2.629920979027034
Validation loss: 2.421623904482709

Epoch: 6| Step: 6
Training loss: 2.390420443690508
Validation loss: 2.4282355413406824

Epoch: 6| Step: 7
Training loss: 2.6771585970935114
Validation loss: 2.4397247800835307

Epoch: 6| Step: 8
Training loss: 2.725837151961964
Validation loss: 2.4685613503788617

Epoch: 6| Step: 9
Training loss: 2.602327434817327
Validation loss: 2.518961465098636

Epoch: 6| Step: 10
Training loss: 2.1970700867854807
Validation loss: 2.595419225899723

Epoch: 6| Step: 11
Training loss: 2.9480817409347573
Validation loss: 2.693458817345916

Epoch: 6| Step: 12
Training loss: 2.976273169685676
Validation loss: 2.6916786345463413

Epoch: 6| Step: 13
Training loss: 2.87952100797191
Validation loss: 2.6525482645474567

Epoch: 327| Step: 0
Training loss: 1.8276366535240771
Validation loss: 2.577935609048025

Epoch: 6| Step: 1
Training loss: 2.9256674893396055
Validation loss: 2.5462464735299184

Epoch: 6| Step: 2
Training loss: 2.8852178365092866
Validation loss: 2.5363707631638253

Epoch: 6| Step: 3
Training loss: 2.441571869382381
Validation loss: 2.492900833609118

Epoch: 6| Step: 4
Training loss: 1.8002258900788142
Validation loss: 2.4791342868553463

Epoch: 6| Step: 5
Training loss: 2.9488091797042593
Validation loss: 2.4711826759040534

Epoch: 6| Step: 6
Training loss: 2.7090864650464104
Validation loss: 2.480963490053894

Epoch: 6| Step: 7
Training loss: 2.092593884475494
Validation loss: 2.491552402045078

Epoch: 6| Step: 8
Training loss: 2.898904850135506
Validation loss: 2.524507290294539

Epoch: 6| Step: 9
Training loss: 2.5590779785403655
Validation loss: 2.5218471060530976

Epoch: 6| Step: 10
Training loss: 2.014398600942779
Validation loss: 2.553756544743949

Epoch: 6| Step: 11
Training loss: 2.1403522178427923
Validation loss: 2.566907151700454

Epoch: 6| Step: 12
Training loss: 2.9740362385412755
Validation loss: 2.583375935065953

Epoch: 6| Step: 13
Training loss: 2.6936708620134175
Validation loss: 2.5705452257687647

Epoch: 328| Step: 0
Training loss: 1.9301538560250753
Validation loss: 2.551234228148278

Epoch: 6| Step: 1
Training loss: 2.6364069549445657
Validation loss: 2.547955078952165

Epoch: 6| Step: 2
Training loss: 3.1112586981719605
Validation loss: 2.5280721971063844

Epoch: 6| Step: 3
Training loss: 2.381676074579592
Validation loss: 2.535568538751572

Epoch: 6| Step: 4
Training loss: 2.6318964510668317
Validation loss: 2.5227555326484206

Epoch: 6| Step: 5
Training loss: 2.858604952823344
Validation loss: 2.5291003517476525

Epoch: 6| Step: 6
Training loss: 2.2671619332342248
Validation loss: 2.5357592246881206

Epoch: 6| Step: 7
Training loss: 2.2929738449222037
Validation loss: 2.5400101814505214

Epoch: 6| Step: 8
Training loss: 2.8459770788153036
Validation loss: 2.5302500808944886

Epoch: 6| Step: 9
Training loss: 2.4706288202141877
Validation loss: 2.547732981434763

Epoch: 6| Step: 10
Training loss: 2.0919878932099283
Validation loss: 2.5312810653102957

Epoch: 6| Step: 11
Training loss: 2.3906668865049863
Validation loss: 2.5264903745899523

Epoch: 6| Step: 12
Training loss: 2.3898545563307905
Validation loss: 2.5007078440255794

Epoch: 6| Step: 13
Training loss: 1.8745836431442697
Validation loss: 2.497304988618016

Epoch: 329| Step: 0
Training loss: 2.5976085228228283
Validation loss: 2.4923697203221766

Epoch: 6| Step: 1
Training loss: 2.14474647428661
Validation loss: 2.5121023983950774

Epoch: 6| Step: 2
Training loss: 2.3591633884951086
Validation loss: 2.528651284065724

Epoch: 6| Step: 3
Training loss: 2.6355028301723906
Validation loss: 2.53254830484319

Epoch: 6| Step: 4
Training loss: 3.232864985678338
Validation loss: 2.5398755600379768

Epoch: 6| Step: 5
Training loss: 1.6359678744727117
Validation loss: 2.5257920306236508

Epoch: 6| Step: 6
Training loss: 2.768291588716751
Validation loss: 2.5372598599605722

Epoch: 6| Step: 7
Training loss: 2.1186814333643373
Validation loss: 2.52172064938536

Epoch: 6| Step: 8
Training loss: 2.7229335649156208
Validation loss: 2.521426661312019

Epoch: 6| Step: 9
Training loss: 3.066995862900189
Validation loss: 2.523376082105934

Epoch: 6| Step: 10
Training loss: 2.239152615551245
Validation loss: 2.5360583656050575

Epoch: 6| Step: 11
Training loss: 1.8603292629076886
Validation loss: 2.5367859989681114

Epoch: 6| Step: 12
Training loss: 2.2509405501457667
Validation loss: 2.540933142738784

Epoch: 6| Step: 13
Training loss: 2.4287666955551717
Validation loss: 2.5451129631335863

Epoch: 330| Step: 0
Training loss: 2.133324194928306
Validation loss: 2.5334687995258527

Epoch: 6| Step: 1
Training loss: 2.86189717437691
Validation loss: 2.5605326678156306

Epoch: 6| Step: 2
Training loss: 2.151105299432556
Validation loss: 2.547443386109245

Epoch: 6| Step: 3
Training loss: 2.105991277453843
Validation loss: 2.5409263989971014

Epoch: 6| Step: 4
Training loss: 2.442915061114302
Validation loss: 2.568069605984105

Epoch: 6| Step: 5
Training loss: 1.9731024209229862
Validation loss: 2.566077679400977

Epoch: 6| Step: 6
Training loss: 2.134285889492586
Validation loss: 2.589484948224468

Epoch: 6| Step: 7
Training loss: 2.516135691108601
Validation loss: 2.6053970419783195

Epoch: 6| Step: 8
Training loss: 2.509080797861104
Validation loss: 2.617991203041701

Epoch: 6| Step: 9
Training loss: 2.424745298557854
Validation loss: 2.574858522336699

Epoch: 6| Step: 10
Training loss: 3.2239781853101097
Validation loss: 2.5355797606073467

Epoch: 6| Step: 11
Training loss: 2.275338862407474
Validation loss: 2.4938495175825515

Epoch: 6| Step: 12
Training loss: 3.040395253235743
Validation loss: 2.477115828985403

Epoch: 6| Step: 13
Training loss: 2.487415109077237
Validation loss: 2.4508792684409424

Epoch: 331| Step: 0
Training loss: 2.0348016060137613
Validation loss: 2.4421693122459502

Epoch: 6| Step: 1
Training loss: 2.9428237397286217
Validation loss: 2.447258276404132

Epoch: 6| Step: 2
Training loss: 2.096292119657931
Validation loss: 2.435416075175708

Epoch: 6| Step: 3
Training loss: 2.4593279706828066
Validation loss: 2.44461467920951

Epoch: 6| Step: 4
Training loss: 2.364757133740103
Validation loss: 2.4435151362992045

Epoch: 6| Step: 5
Training loss: 3.0278442756591035
Validation loss: 2.4475632146404656

Epoch: 6| Step: 6
Training loss: 2.525096053005568
Validation loss: 2.485345234238212

Epoch: 6| Step: 7
Training loss: 2.516338934200817
Validation loss: 2.5160179536994263

Epoch: 6| Step: 8
Training loss: 2.3596399423754906
Validation loss: 2.537804581467839

Epoch: 6| Step: 9
Training loss: 2.7094687404937687
Validation loss: 2.5596653316020683

Epoch: 6| Step: 10
Training loss: 2.4478276879121768
Validation loss: 2.571387287571234

Epoch: 6| Step: 11
Training loss: 2.2113066995186212
Validation loss: 2.573260421145051

Epoch: 6| Step: 12
Training loss: 2.1819802534711643
Validation loss: 2.60054259820765

Epoch: 6| Step: 13
Training loss: 2.7430257792942454
Validation loss: 2.5876059777328893

Epoch: 332| Step: 0
Training loss: 2.245966156362313
Validation loss: 2.5757518098902747

Epoch: 6| Step: 1
Training loss: 2.2678960532936516
Validation loss: 2.511125351106821

Epoch: 6| Step: 2
Training loss: 2.5280870055183433
Validation loss: 2.498264673375865

Epoch: 6| Step: 3
Training loss: 2.8010245288018645
Validation loss: 2.4862981941925795

Epoch: 6| Step: 4
Training loss: 2.454219306765531
Validation loss: 2.475156620581025

Epoch: 6| Step: 5
Training loss: 2.0288282776760216
Validation loss: 2.4524484494006

Epoch: 6| Step: 6
Training loss: 2.068882055764137
Validation loss: 2.4572479451422033

Epoch: 6| Step: 7
Training loss: 2.2250806729554027
Validation loss: 2.4578969135981543

Epoch: 6| Step: 8
Training loss: 2.8471305791067723
Validation loss: 2.464128369029629

Epoch: 6| Step: 9
Training loss: 2.356931621202173
Validation loss: 2.4760721267940915

Epoch: 6| Step: 10
Training loss: 2.6956877074099936
Validation loss: 2.499860080782287

Epoch: 6| Step: 11
Training loss: 2.6351231246933606
Validation loss: 2.5129914697054487

Epoch: 6| Step: 12
Training loss: 2.5597972107080533
Validation loss: 2.547015528171175

Epoch: 6| Step: 13
Training loss: 2.277292764658953
Validation loss: 2.5724993141364982

Epoch: 333| Step: 0
Training loss: 2.8449538480907055
Validation loss: 2.59058434338099

Epoch: 6| Step: 1
Training loss: 2.9954927281785064
Validation loss: 2.634640582108456

Epoch: 6| Step: 2
Training loss: 1.6246955292905587
Validation loss: 2.6476031488408993

Epoch: 6| Step: 3
Training loss: 2.2573076891598185
Validation loss: 2.6269805632298615

Epoch: 6| Step: 4
Training loss: 2.40013792913187
Validation loss: 2.6181670842321174

Epoch: 6| Step: 5
Training loss: 2.405989992040049
Validation loss: 2.5418214792852436

Epoch: 6| Step: 6
Training loss: 2.199878654601363
Validation loss: 2.4987315969758974

Epoch: 6| Step: 7
Training loss: 2.884267217703255
Validation loss: 2.4755702972484377

Epoch: 6| Step: 8
Training loss: 2.3436673976329363
Validation loss: 2.455035114263184

Epoch: 6| Step: 9
Training loss: 2.7795187029908397
Validation loss: 2.4516707964966153

Epoch: 6| Step: 10
Training loss: 2.432146404320587
Validation loss: 2.4398592502943703

Epoch: 6| Step: 11
Training loss: 2.4918365709773105
Validation loss: 2.4369042875220255

Epoch: 6| Step: 12
Training loss: 2.2710824415662194
Validation loss: 2.438258637533986

Epoch: 6| Step: 13
Training loss: 2.2132605759408808
Validation loss: 2.436655035354629

Epoch: 334| Step: 0
Training loss: 2.5236073723177896
Validation loss: 2.4608178519341317

Epoch: 6| Step: 1
Training loss: 1.7644206302700218
Validation loss: 2.479878326471064

Epoch: 6| Step: 2
Training loss: 2.3092829003248845
Validation loss: 2.51805069337162

Epoch: 6| Step: 3
Training loss: 2.664472173699043
Validation loss: 2.5474670414561387

Epoch: 6| Step: 4
Training loss: 2.756417156522482
Validation loss: 2.5952744603097306

Epoch: 6| Step: 5
Training loss: 2.4024285030146406
Validation loss: 2.616911597931094

Epoch: 6| Step: 6
Training loss: 2.4984893049126096
Validation loss: 2.604283381317963

Epoch: 6| Step: 7
Training loss: 3.2206424223926255
Validation loss: 2.5775716332552023

Epoch: 6| Step: 8
Training loss: 1.9754362855763234
Validation loss: 2.541013221789716

Epoch: 6| Step: 9
Training loss: 2.2735736190054627
Validation loss: 2.5158837231936086

Epoch: 6| Step: 10
Training loss: 2.45552596663671
Validation loss: 2.514414843788443

Epoch: 6| Step: 11
Training loss: 2.340896293288666
Validation loss: 2.5182521459442135

Epoch: 6| Step: 12
Training loss: 2.6829317878415115
Validation loss: 2.508194252971242

Epoch: 6| Step: 13
Training loss: 2.2427823543662004
Validation loss: 2.485540894370771

Epoch: 335| Step: 0
Training loss: 2.793916042778569
Validation loss: 2.4892930990806352

Epoch: 6| Step: 1
Training loss: 2.7247168297583078
Validation loss: 2.4950978289941825

Epoch: 6| Step: 2
Training loss: 2.8526251498157498
Validation loss: 2.5114330895511316

Epoch: 6| Step: 3
Training loss: 2.110275189501892
Validation loss: 2.5206369570830547

Epoch: 6| Step: 4
Training loss: 2.489996637702112
Validation loss: 2.5064990527317974

Epoch: 6| Step: 5
Training loss: 2.7353649854075335
Validation loss: 2.5213237699960023

Epoch: 6| Step: 6
Training loss: 2.227913750990879
Validation loss: 2.5189714144772606

Epoch: 6| Step: 7
Training loss: 2.123493333634057
Validation loss: 2.5273264875340886

Epoch: 6| Step: 8
Training loss: 1.947561717885663
Validation loss: 2.5158641601885137

Epoch: 6| Step: 9
Training loss: 1.923298440426091
Validation loss: 2.4956962323733487

Epoch: 6| Step: 10
Training loss: 2.831266060419404
Validation loss: 2.5404012149946493

Epoch: 6| Step: 11
Training loss: 2.1262381817165745
Validation loss: 2.5251483284387355

Epoch: 6| Step: 12
Training loss: 2.305705631177059
Validation loss: 2.5209780368208032

Epoch: 6| Step: 13
Training loss: 2.7543067153973446
Validation loss: 2.514501455909555

Epoch: 336| Step: 0
Training loss: 2.25639282788924
Validation loss: 2.515386336856109

Epoch: 6| Step: 1
Training loss: 2.3183973224108434
Validation loss: 2.4966039725881504

Epoch: 6| Step: 2
Training loss: 2.4648374626937937
Validation loss: 2.5017823674661277

Epoch: 6| Step: 3
Training loss: 2.144493894824932
Validation loss: 2.4963460912769593

Epoch: 6| Step: 4
Training loss: 2.1571673224946575
Validation loss: 2.5067696222404416

Epoch: 6| Step: 5
Training loss: 2.86848175190904
Validation loss: 2.50526097394817

Epoch: 6| Step: 6
Training loss: 2.6573655422642974
Validation loss: 2.5111309273276965

Epoch: 6| Step: 7
Training loss: 2.282831871582389
Validation loss: 2.499240178344655

Epoch: 6| Step: 8
Training loss: 2.0337424611876256
Validation loss: 2.470720968814727

Epoch: 6| Step: 9
Training loss: 2.4457198221184746
Validation loss: 2.447497491984525

Epoch: 6| Step: 10
Training loss: 2.5646942792291334
Validation loss: 2.455763224366437

Epoch: 6| Step: 11
Training loss: 2.319182252309527
Validation loss: 2.4649719077033794

Epoch: 6| Step: 12
Training loss: 2.7486145691166937
Validation loss: 2.4966442956799364

Epoch: 6| Step: 13
Training loss: 2.457199406289959
Validation loss: 2.518985310058081

Epoch: 337| Step: 0
Training loss: 1.7837766161766044
Validation loss: 2.528674998619523

Epoch: 6| Step: 1
Training loss: 2.1616001925202233
Validation loss: 2.5441065803778042

Epoch: 6| Step: 2
Training loss: 2.2872513516057573
Validation loss: 2.543826500970142

Epoch: 6| Step: 3
Training loss: 2.775275682381881
Validation loss: 2.538598468238664

Epoch: 6| Step: 4
Training loss: 2.512786970308923
Validation loss: 2.539895877299487

Epoch: 6| Step: 5
Training loss: 2.0540872719711847
Validation loss: 2.514293075765693

Epoch: 6| Step: 6
Training loss: 2.2029023835818453
Validation loss: 2.499425082601561

Epoch: 6| Step: 7
Training loss: 1.6294629360126198
Validation loss: 2.487869895030635

Epoch: 6| Step: 8
Training loss: 2.8462855175752475
Validation loss: 2.482899643681786

Epoch: 6| Step: 9
Training loss: 2.2805751690761347
Validation loss: 2.493149916578034

Epoch: 6| Step: 10
Training loss: 3.018010120271231
Validation loss: 2.4905515322350733

Epoch: 6| Step: 11
Training loss: 2.682726590842264
Validation loss: 2.469192616297544

Epoch: 6| Step: 12
Training loss: 2.48122758446857
Validation loss: 2.4689668710971584

Epoch: 6| Step: 13
Training loss: 2.357811416008904
Validation loss: 2.462692393937702

Epoch: 338| Step: 0
Training loss: 2.7781596641823776
Validation loss: 2.4940366285587703

Epoch: 6| Step: 1
Training loss: 2.5179458243107256
Validation loss: 2.5354863059763764

Epoch: 6| Step: 2
Training loss: 2.3082152183785305
Validation loss: 2.5548996019606136

Epoch: 6| Step: 3
Training loss: 2.2642413945994315
Validation loss: 2.5416462257110646

Epoch: 6| Step: 4
Training loss: 2.400069784103557
Validation loss: 2.559406525220906

Epoch: 6| Step: 5
Training loss: 2.47879678440621
Validation loss: 2.532131635536359

Epoch: 6| Step: 6
Training loss: 1.921818305939378
Validation loss: 2.5397887740586906

Epoch: 6| Step: 7
Training loss: 2.3688395058019545
Validation loss: 2.5485696163239893

Epoch: 6| Step: 8
Training loss: 2.1364826302066686
Validation loss: 2.5596874127470546

Epoch: 6| Step: 9
Training loss: 1.8314825021052148
Validation loss: 2.585458930613943

Epoch: 6| Step: 10
Training loss: 2.8425890889964798
Validation loss: 2.567475152047869

Epoch: 6| Step: 11
Training loss: 2.3961586330548283
Validation loss: 2.552114393502723

Epoch: 6| Step: 12
Training loss: 2.673480705835121
Validation loss: 2.5129416448447572

Epoch: 6| Step: 13
Training loss: 2.223629274227257
Validation loss: 2.4723228270353994

Epoch: 339| Step: 0
Training loss: 2.183193217821724
Validation loss: 2.4794827993272297

Epoch: 6| Step: 1
Training loss: 2.4950466676066716
Validation loss: 2.475970420713334

Epoch: 6| Step: 2
Training loss: 2.083483448978064
Validation loss: 2.4848303815745063

Epoch: 6| Step: 3
Training loss: 2.3752235508160737
Validation loss: 2.5097416204306318

Epoch: 6| Step: 4
Training loss: 2.5126490079050576
Validation loss: 2.5363650781854603

Epoch: 6| Step: 5
Training loss: 2.8798061501643497
Validation loss: 2.54487801235588

Epoch: 6| Step: 6
Training loss: 1.771086222224987
Validation loss: 2.5114017317703228

Epoch: 6| Step: 7
Training loss: 2.41090319665324
Validation loss: 2.4917071714067736

Epoch: 6| Step: 8
Training loss: 2.5247765168348937
Validation loss: 2.480438085987742

Epoch: 6| Step: 9
Training loss: 1.7860109382542204
Validation loss: 2.4571845368752943

Epoch: 6| Step: 10
Training loss: 2.6241162947028474
Validation loss: 2.4714381021530425

Epoch: 6| Step: 11
Training loss: 2.182648974705609
Validation loss: 2.4623798259209573

Epoch: 6| Step: 12
Training loss: 2.3553743106262237
Validation loss: 2.4620158806754135

Epoch: 6| Step: 13
Training loss: 2.75436116242141
Validation loss: 2.484412762300804

Epoch: 340| Step: 0
Training loss: 2.277414520368
Validation loss: 2.4694853871581537

Epoch: 6| Step: 1
Training loss: 2.266726522029375
Validation loss: 2.491171814883018

Epoch: 6| Step: 2
Training loss: 2.394173376027722
Validation loss: 2.4823474221772113

Epoch: 6| Step: 3
Training loss: 2.0788132524529996
Validation loss: 2.498864623638079

Epoch: 6| Step: 4
Training loss: 2.5445740960566003
Validation loss: 2.4959643030597682

Epoch: 6| Step: 5
Training loss: 2.348135646930973
Validation loss: 2.491682212973972

Epoch: 6| Step: 6
Training loss: 2.413974896171649
Validation loss: 2.4826446800088857

Epoch: 6| Step: 7
Training loss: 2.0356165974823943
Validation loss: 2.4885738195200457

Epoch: 6| Step: 8
Training loss: 2.9789817770470695
Validation loss: 2.4700560017083077

Epoch: 6| Step: 9
Training loss: 2.389616310892033
Validation loss: 2.4468760110918

Epoch: 6| Step: 10
Training loss: 2.3179117749254154
Validation loss: 2.436625751669602

Epoch: 6| Step: 11
Training loss: 1.808689123156056
Validation loss: 2.437604502795507

Epoch: 6| Step: 12
Training loss: 2.475332056754958
Validation loss: 2.450322702554789

Epoch: 6| Step: 13
Training loss: 2.3987955329394164
Validation loss: 2.4670233191234163

Epoch: 341| Step: 0
Training loss: 2.002327042062316
Validation loss: 2.4876265780276827

Epoch: 6| Step: 1
Training loss: 2.0096525673906607
Validation loss: 2.490953748317538

Epoch: 6| Step: 2
Training loss: 2.563173624213262
Validation loss: 2.5147911447201

Epoch: 6| Step: 3
Training loss: 2.457202996344946
Validation loss: 2.512028110877094

Epoch: 6| Step: 4
Training loss: 1.926429685793076
Validation loss: 2.508034790152274

Epoch: 6| Step: 5
Training loss: 2.5883007487522023
Validation loss: 2.5024709529177867

Epoch: 6| Step: 6
Training loss: 2.2008765901789573
Validation loss: 2.508432480279328

Epoch: 6| Step: 7
Training loss: 1.7577407483185796
Validation loss: 2.5175537779255017

Epoch: 6| Step: 8
Training loss: 3.0887963295599357
Validation loss: 2.510888893449319

Epoch: 6| Step: 9
Training loss: 2.7596305063570035
Validation loss: 2.5114134219526845

Epoch: 6| Step: 10
Training loss: 2.080313541182306
Validation loss: 2.5188247772567682

Epoch: 6| Step: 11
Training loss: 2.276676767344523
Validation loss: 2.5092077995877227

Epoch: 6| Step: 12
Training loss: 2.212069703409388
Validation loss: 2.5091644314001726

Epoch: 6| Step: 13
Training loss: 2.3475833316592776
Validation loss: 2.5186491592037084

Epoch: 342| Step: 0
Training loss: 1.0889351177836504
Validation loss: 2.515283915986462

Epoch: 6| Step: 1
Training loss: 2.464966204181377
Validation loss: 2.5049362404958297

Epoch: 6| Step: 2
Training loss: 2.220139941195147
Validation loss: 2.4993932849175895

Epoch: 6| Step: 3
Training loss: 2.5837213060827793
Validation loss: 2.526993355044735

Epoch: 6| Step: 4
Training loss: 1.484548056703778
Validation loss: 2.5182104595603505

Epoch: 6| Step: 5
Training loss: 2.608285459458934
Validation loss: 2.5297109395690476

Epoch: 6| Step: 6
Training loss: 2.091717088960413
Validation loss: 2.4970396367562433

Epoch: 6| Step: 7
Training loss: 1.889514691649286
Validation loss: 2.4782521219073264

Epoch: 6| Step: 8
Training loss: 2.837894153527142
Validation loss: 2.485170260443393

Epoch: 6| Step: 9
Training loss: 2.256371272412793
Validation loss: 2.468982435847113

Epoch: 6| Step: 10
Training loss: 2.936100727962379
Validation loss: 2.4675216007077845

Epoch: 6| Step: 11
Training loss: 2.546697505078498
Validation loss: 2.487534215746117

Epoch: 6| Step: 12
Training loss: 1.702033997112114
Validation loss: 2.4995865818409797

Epoch: 6| Step: 13
Training loss: 3.162448499659795
Validation loss: 2.5408111603757586

Epoch: 343| Step: 0
Training loss: 2.4356915538799426
Validation loss: 2.488441992561544

Epoch: 6| Step: 1
Training loss: 2.228255207382241
Validation loss: 2.46919416796253

Epoch: 6| Step: 2
Training loss: 2.4329494156037685
Validation loss: 2.451949435207947

Epoch: 6| Step: 3
Training loss: 2.4736064031481066
Validation loss: 2.4899355882481897

Epoch: 6| Step: 4
Training loss: 2.151115052924122
Validation loss: 2.4752357142786097

Epoch: 6| Step: 5
Training loss: 2.3513096264706808
Validation loss: 2.4819841170034187

Epoch: 6| Step: 6
Training loss: 2.037284221807857
Validation loss: 2.472981189612705

Epoch: 6| Step: 7
Training loss: 2.641340802026954
Validation loss: 2.477808530603071

Epoch: 6| Step: 8
Training loss: 2.56394471171693
Validation loss: 2.502818454928751

Epoch: 6| Step: 9
Training loss: 1.9744143064232527
Validation loss: 2.5349677486479285

Epoch: 6| Step: 10
Training loss: 1.9233850888782045
Validation loss: 2.547241804578661

Epoch: 6| Step: 11
Training loss: 1.825749932976661
Validation loss: 2.570392549421932

Epoch: 6| Step: 12
Training loss: 2.9351160643209933
Validation loss: 2.60325816265343

Epoch: 6| Step: 13
Training loss: 2.159586771008494
Validation loss: 2.5565560627083475

Epoch: 344| Step: 0
Training loss: 2.36631612823346
Validation loss: 2.522960927063612

Epoch: 6| Step: 1
Training loss: 2.235789884736803
Validation loss: 2.5032156536688013

Epoch: 6| Step: 2
Training loss: 2.4809351685312784
Validation loss: 2.4967968077850524

Epoch: 6| Step: 3
Training loss: 2.3006333722970305
Validation loss: 2.5047630610379255

Epoch: 6| Step: 4
Training loss: 2.251092645461245
Validation loss: 2.512248707551202

Epoch: 6| Step: 5
Training loss: 1.9708662617723716
Validation loss: 2.5271941515703418

Epoch: 6| Step: 6
Training loss: 2.465163704347725
Validation loss: 2.5093118098901885

Epoch: 6| Step: 7
Training loss: 2.2129773546345306
Validation loss: 2.507352115925511

Epoch: 6| Step: 8
Training loss: 2.320181692013334
Validation loss: 2.4638770534505516

Epoch: 6| Step: 9
Training loss: 2.4536671616441
Validation loss: 2.441309055419969

Epoch: 6| Step: 10
Training loss: 2.5016373994230534
Validation loss: 2.4281218699834723

Epoch: 6| Step: 11
Training loss: 1.9531511839065183
Validation loss: 2.4144427540988147

Epoch: 6| Step: 12
Training loss: 2.1248577294688222
Validation loss: 2.42168136230114

Epoch: 6| Step: 13
Training loss: 2.31206993021689
Validation loss: 2.43462049870852

Epoch: 345| Step: 0
Training loss: 2.1679513741561562
Validation loss: 2.4457755812891815

Epoch: 6| Step: 1
Training loss: 2.0377124979805834
Validation loss: 2.44570011873843

Epoch: 6| Step: 2
Training loss: 2.0605660821824006
Validation loss: 2.466971037213589

Epoch: 6| Step: 3
Training loss: 2.2821717163860633
Validation loss: 2.501455955672694

Epoch: 6| Step: 4
Training loss: 2.03622332401494
Validation loss: 2.511542680995917

Epoch: 6| Step: 5
Training loss: 2.331328370768707
Validation loss: 2.520363876764797

Epoch: 6| Step: 6
Training loss: 2.6222602533915915
Validation loss: 2.4933315483517013

Epoch: 6| Step: 7
Training loss: 2.1849633904713817
Validation loss: 2.506015699595134

Epoch: 6| Step: 8
Training loss: 2.1957436134882227
Validation loss: 2.497002610069992

Epoch: 6| Step: 9
Training loss: 2.4630154994735562
Validation loss: 2.4991874563899237

Epoch: 6| Step: 10
Training loss: 2.418295892083407
Validation loss: 2.4945915580869107

Epoch: 6| Step: 11
Training loss: 2.0347431371291655
Validation loss: 2.4817660839921714

Epoch: 6| Step: 12
Training loss: 2.6271455261790613
Validation loss: 2.4407504022894866

Epoch: 6| Step: 13
Training loss: 2.243359515286268
Validation loss: 2.441836002582631

Epoch: 346| Step: 0
Training loss: 2.42558978272654
Validation loss: 2.4329329354110114

Epoch: 6| Step: 1
Training loss: 2.3462958178672624
Validation loss: 2.4413868572818505

Epoch: 6| Step: 2
Training loss: 2.006501835023491
Validation loss: 2.453646842944546

Epoch: 6| Step: 3
Training loss: 2.2701271312252644
Validation loss: 2.476162718617366

Epoch: 6| Step: 4
Training loss: 2.4079407535881208
Validation loss: 2.524979440066662

Epoch: 6| Step: 5
Training loss: 2.7906014606982437
Validation loss: 2.5506173506310463

Epoch: 6| Step: 6
Training loss: 2.430781470804682
Validation loss: 2.559650627759419

Epoch: 6| Step: 7
Training loss: 2.2830008489780127
Validation loss: 2.5867844062757857

Epoch: 6| Step: 8
Training loss: 1.7466399770012804
Validation loss: 2.6175640728504406

Epoch: 6| Step: 9
Training loss: 2.0293557357696126
Validation loss: 2.586085381558004

Epoch: 6| Step: 10
Training loss: 2.2450570807390102
Validation loss: 2.5772817207668455

Epoch: 6| Step: 11
Training loss: 1.9420866052348609
Validation loss: 2.5732162485175265

Epoch: 6| Step: 12
Training loss: 2.5491577403010046
Validation loss: 2.562502072921463

Epoch: 6| Step: 13
Training loss: 1.8905203293759343
Validation loss: 2.52102072993906

Epoch: 347| Step: 0
Training loss: 1.9617933252304074
Validation loss: 2.4882668012311338

Epoch: 6| Step: 1
Training loss: 2.1364629895776246
Validation loss: 2.4988810393649183

Epoch: 6| Step: 2
Training loss: 2.636229066942001
Validation loss: 2.483659403993729

Epoch: 6| Step: 3
Training loss: 2.4723069846758614
Validation loss: 2.498009785759882

Epoch: 6| Step: 4
Training loss: 1.5449454092362427
Validation loss: 2.4548860771550127

Epoch: 6| Step: 5
Training loss: 2.995079137301098
Validation loss: 2.447089425467174

Epoch: 6| Step: 6
Training loss: 1.900530881498841
Validation loss: 2.453234923312493

Epoch: 6| Step: 7
Training loss: 2.1425312770844003
Validation loss: 2.4617709455514043

Epoch: 6| Step: 8
Training loss: 2.248946473050762
Validation loss: 2.4530821640322165

Epoch: 6| Step: 9
Training loss: 1.7646166867733666
Validation loss: 2.492615114704556

Epoch: 6| Step: 10
Training loss: 1.6270774619777637
Validation loss: 2.493396012501773

Epoch: 6| Step: 11
Training loss: 2.990827365832798
Validation loss: 2.4706315170573236

Epoch: 6| Step: 12
Training loss: 2.0152585191753656
Validation loss: 2.532882876764401

Epoch: 6| Step: 13
Training loss: 2.919217129887433
Validation loss: 2.5489288590542167

Epoch: 348| Step: 0
Training loss: 2.4035556124654898
Validation loss: 2.5323846011867825

Epoch: 6| Step: 1
Training loss: 1.6246608967188791
Validation loss: 2.5017437493561254

Epoch: 6| Step: 2
Training loss: 1.820093166251343
Validation loss: 2.445110516221618

Epoch: 6| Step: 3
Training loss: 1.8768473108099344
Validation loss: 2.453732672031244

Epoch: 6| Step: 4
Training loss: 2.3606602281886437
Validation loss: 2.452848811970554

Epoch: 6| Step: 5
Training loss: 2.529423183984198
Validation loss: 2.453979698611126

Epoch: 6| Step: 6
Training loss: 2.437129750619815
Validation loss: 2.473021659450602

Epoch: 6| Step: 7
Training loss: 2.5175793561199957
Validation loss: 2.470247475218667

Epoch: 6| Step: 8
Training loss: 2.1471270639516566
Validation loss: 2.485070619604521

Epoch: 6| Step: 9
Training loss: 2.940899120044301
Validation loss: 2.4757703748303577

Epoch: 6| Step: 10
Training loss: 2.274282816092951
Validation loss: 2.474917889672047

Epoch: 6| Step: 11
Training loss: 2.239124079494386
Validation loss: 2.4685245845591157

Epoch: 6| Step: 12
Training loss: 1.9424101845340724
Validation loss: 2.5068820242682466

Epoch: 6| Step: 13
Training loss: 1.9492677976748094
Validation loss: 2.526781168047368

Epoch: 349| Step: 0
Training loss: 1.6238007154759855
Validation loss: 2.5777930440328074

Epoch: 6| Step: 1
Training loss: 2.6283767416334123
Validation loss: 2.6126929999883384

Epoch: 6| Step: 2
Training loss: 2.1079181302511616
Validation loss: 2.6230597291046465

Epoch: 6| Step: 3
Training loss: 2.4618062741365687
Validation loss: 2.6623988134103946

Epoch: 6| Step: 4
Training loss: 2.6149707117136356
Validation loss: 2.6506854118786682

Epoch: 6| Step: 5
Training loss: 1.9713134425469938
Validation loss: 2.5605029446091128

Epoch: 6| Step: 6
Training loss: 2.1550800632553138
Validation loss: 2.48949874162363

Epoch: 6| Step: 7
Training loss: 2.04121373141434
Validation loss: 2.4599921694018234

Epoch: 6| Step: 8
Training loss: 2.161501694822651
Validation loss: 2.436163064190163

Epoch: 6| Step: 9
Training loss: 2.567973176762613
Validation loss: 2.4194930171816242

Epoch: 6| Step: 10
Training loss: 2.2492474251045835
Validation loss: 2.402406934615391

Epoch: 6| Step: 11
Training loss: 2.7490626384860395
Validation loss: 2.419769770442964

Epoch: 6| Step: 12
Training loss: 2.1383066361927003
Validation loss: 2.4129143435760194

Epoch: 6| Step: 13
Training loss: 1.8885682954364424
Validation loss: 2.445102278328782

Epoch: 350| Step: 0
Training loss: 1.9667653570898163
Validation loss: 2.4706158034168415

Epoch: 6| Step: 1
Training loss: 2.1038686585352573
Validation loss: 2.54391395137445

Epoch: 6| Step: 2
Training loss: 2.263513462425191
Validation loss: 2.575172048249583

Epoch: 6| Step: 3
Training loss: 2.0257291446550507
Validation loss: 2.6211529036399863

Epoch: 6| Step: 4
Training loss: 1.6630791279266417
Validation loss: 2.6726587279855627

Epoch: 6| Step: 5
Training loss: 2.091932960165469
Validation loss: 2.6659943331676903

Epoch: 6| Step: 6
Training loss: 2.2619137589316347
Validation loss: 2.6264075916230905

Epoch: 6| Step: 7
Training loss: 2.738394262835962
Validation loss: 2.5312188988601383

Epoch: 6| Step: 8
Training loss: 2.7165917786025644
Validation loss: 2.461777531233847

Epoch: 6| Step: 9
Training loss: 2.351998830470618
Validation loss: 2.427523746289213

Epoch: 6| Step: 10
Training loss: 2.611576636279442
Validation loss: 2.400900373589564

Epoch: 6| Step: 11
Training loss: 1.8985068854065705
Validation loss: 2.403351911912159

Epoch: 6| Step: 12
Training loss: 2.4687985765530924
Validation loss: 2.4016791704268567

Epoch: 6| Step: 13
Training loss: 1.9624049558524852
Validation loss: 2.3963317145852754

Testing loss: 2.481967231101777
