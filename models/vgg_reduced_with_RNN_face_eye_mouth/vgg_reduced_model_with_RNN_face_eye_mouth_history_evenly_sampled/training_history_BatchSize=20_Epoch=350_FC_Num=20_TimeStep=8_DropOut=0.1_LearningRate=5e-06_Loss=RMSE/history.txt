Epoch: 1| Step: 0
Training loss: 4.953327162795675
Validation loss: 5.766587541729573

Epoch: 5| Step: 1
Training loss: 6.477124676388924
Validation loss: 5.760995898905344

Epoch: 5| Step: 2
Training loss: 6.11043919809399
Validation loss: 5.756144428940724

Epoch: 5| Step: 3
Training loss: 4.926826626284789
Validation loss: 5.750855967552239

Epoch: 5| Step: 4
Training loss: 5.265979969952916
Validation loss: 5.745668439195916

Epoch: 5| Step: 5
Training loss: 6.363874113917793
Validation loss: 5.7409941067627495

Epoch: 5| Step: 6
Training loss: 5.529480387055377
Validation loss: 5.736209225198079

Epoch: 5| Step: 7
Training loss: 5.639873422866168
Validation loss: 5.7311454110782

Epoch: 5| Step: 8
Training loss: 4.820708767076453
Validation loss: 5.726030819702864

Epoch: 5| Step: 9
Training loss: 6.243490873196773
Validation loss: 5.720588767272203

Epoch: 5| Step: 10
Training loss: 6.955921630786432
Validation loss: 5.714442591227744

Epoch: 2| Step: 0
Training loss: 4.756794136191051
Validation loss: 5.709057288284002

Epoch: 5| Step: 1
Training loss: 6.1877700284355015
Validation loss: 5.702715225321146

Epoch: 5| Step: 2
Training loss: 5.872722752529373
Validation loss: 5.6962457661905965

Epoch: 5| Step: 3
Training loss: 5.781998869361094
Validation loss: 5.6906005510701485

Epoch: 5| Step: 4
Training loss: 5.97386517461783
Validation loss: 5.683825709081394

Epoch: 5| Step: 5
Training loss: 6.134447557716905
Validation loss: 5.675950045973794

Epoch: 5| Step: 6
Training loss: 5.0627633485467864
Validation loss: 5.668410188009823

Epoch: 5| Step: 7
Training loss: 5.435806536871858
Validation loss: 5.660145386975502

Epoch: 5| Step: 8
Training loss: 5.983283598258359
Validation loss: 5.651615863963065

Epoch: 5| Step: 9
Training loss: 5.656531564016663
Validation loss: 5.643245623308496

Epoch: 5| Step: 10
Training loss: 5.816669568313414
Validation loss: 5.633629672639386

Epoch: 3| Step: 0
Training loss: 5.073349993591089
Validation loss: 5.623399367755349

Epoch: 5| Step: 1
Training loss: 5.1024010335696905
Validation loss: 5.61407574097236

Epoch: 5| Step: 2
Training loss: 5.690956490679628
Validation loss: 5.603539633020464

Epoch: 5| Step: 3
Training loss: 6.476528632394109
Validation loss: 5.592714315671935

Epoch: 5| Step: 4
Training loss: 5.735364781745578
Validation loss: 5.582071558767332

Epoch: 5| Step: 5
Training loss: 6.21326269614434
Validation loss: 5.569049312228018

Epoch: 5| Step: 6
Training loss: 6.5075050455396966
Validation loss: 5.557525353373156

Epoch: 5| Step: 7
Training loss: 5.802954269962615
Validation loss: 5.543667061754083

Epoch: 5| Step: 8
Training loss: 3.7905733537418396
Validation loss: 5.530152426268241

Epoch: 5| Step: 9
Training loss: 5.4350352346336255
Validation loss: 5.516571691548284

Epoch: 5| Step: 10
Training loss: 5.279810421459075
Validation loss: 5.50181673199251

Epoch: 4| Step: 0
Training loss: 5.649647605506582
Validation loss: 5.487159615032434

Epoch: 5| Step: 1
Training loss: 5.523849450360151
Validation loss: 5.472170780375193

Epoch: 5| Step: 2
Training loss: 6.168790640499043
Validation loss: 5.456982286732601

Epoch: 5| Step: 3
Training loss: 4.718379732472227
Validation loss: 5.440197426563115

Epoch: 5| Step: 4
Training loss: 5.544362877445602
Validation loss: 5.422976312566207

Epoch: 5| Step: 5
Training loss: 5.619510939418322
Validation loss: 5.406512865111671

Epoch: 5| Step: 6
Training loss: 5.203324964191973
Validation loss: 5.388196020165307

Epoch: 5| Step: 7
Training loss: 5.46038475022442
Validation loss: 5.369715675026443

Epoch: 5| Step: 8
Training loss: 5.113669547541675
Validation loss: 5.351145488269191

Epoch: 5| Step: 9
Training loss: 5.052183400634568
Validation loss: 5.332302768156777

Epoch: 5| Step: 10
Training loss: 5.787336455108594
Validation loss: 5.312327732137862

Epoch: 5| Step: 0
Training loss: 5.668164934040154
Validation loss: 5.291440945204347

Epoch: 5| Step: 1
Training loss: 6.058449562073733
Validation loss: 5.270580667826541

Epoch: 5| Step: 2
Training loss: 5.340476120714599
Validation loss: 5.248023302169328

Epoch: 5| Step: 3
Training loss: 4.2022888032491394
Validation loss: 5.225452709138342

Epoch: 5| Step: 4
Training loss: 5.6484979438977225
Validation loss: 5.2060943883982125

Epoch: 5| Step: 5
Training loss: 5.035479361359913
Validation loss: 5.181256152753663

Epoch: 5| Step: 6
Training loss: 4.271918380729122
Validation loss: 5.158281348648363

Epoch: 5| Step: 7
Training loss: 4.495694537962083
Validation loss: 5.136929130449209

Epoch: 5| Step: 8
Training loss: 5.910756808651951
Validation loss: 5.113075678566969

Epoch: 5| Step: 9
Training loss: 5.048504545663301
Validation loss: 5.091566281948428

Epoch: 5| Step: 10
Training loss: 5.5641891829293275
Validation loss: 5.0659368190659295

Epoch: 6| Step: 0
Training loss: 4.012886271200062
Validation loss: 5.042711678292997

Epoch: 5| Step: 1
Training loss: 4.793913781502795
Validation loss: 5.019558866282917

Epoch: 5| Step: 2
Training loss: 5.728641148364792
Validation loss: 4.995991931851987

Epoch: 5| Step: 3
Training loss: 5.309404615798986
Validation loss: 4.971193100580229

Epoch: 5| Step: 4
Training loss: 4.644811315410101
Validation loss: 4.947734540902358

Epoch: 5| Step: 5
Training loss: 5.48533861003567
Validation loss: 4.925156095579721

Epoch: 5| Step: 6
Training loss: 5.040031399099241
Validation loss: 4.899516042701351

Epoch: 5| Step: 7
Training loss: 5.10799545655911
Validation loss: 4.878017632726144

Epoch: 5| Step: 8
Training loss: 4.648874060382457
Validation loss: 4.855442713670148

Epoch: 5| Step: 9
Training loss: 4.812705890165063
Validation loss: 4.832020004420795

Epoch: 5| Step: 10
Training loss: 5.136595657092157
Validation loss: 4.809085639955083

Epoch: 7| Step: 0
Training loss: 4.208157954322802
Validation loss: 4.787525540828891

Epoch: 5| Step: 1
Training loss: 4.203784536355376
Validation loss: 4.76488393491592

Epoch: 5| Step: 2
Training loss: 4.570451887564617
Validation loss: 4.742023739883929

Epoch: 5| Step: 3
Training loss: 4.965822905143129
Validation loss: 4.7205654216880175

Epoch: 5| Step: 4
Training loss: 5.290036448477525
Validation loss: 4.698726285884051

Epoch: 5| Step: 5
Training loss: 4.282469861068717
Validation loss: 4.673528927449584

Epoch: 5| Step: 6
Training loss: 5.49256429017353
Validation loss: 4.650188891733091

Epoch: 5| Step: 7
Training loss: 4.773136610172103
Validation loss: 4.624332458514981

Epoch: 5| Step: 8
Training loss: 4.96031365264262
Validation loss: 4.596013881726394

Epoch: 5| Step: 9
Training loss: 4.152126475236204
Validation loss: 4.566644599603149

Epoch: 5| Step: 10
Training loss: 5.189152649668115
Validation loss: 4.53770408631306

Epoch: 8| Step: 0
Training loss: 4.280987362567415
Validation loss: 4.509527527686503

Epoch: 5| Step: 1
Training loss: 4.85620602620957
Validation loss: 4.485873919370054

Epoch: 5| Step: 2
Training loss: 4.039932717999991
Validation loss: 4.463010289697668

Epoch: 5| Step: 3
Training loss: 5.5043369880023
Validation loss: 4.440407157300672

Epoch: 5| Step: 4
Training loss: 5.097304525701243
Validation loss: 4.421231469299483

Epoch: 5| Step: 5
Training loss: 4.484351606673521
Validation loss: 4.399173149975275

Epoch: 5| Step: 6
Training loss: 4.116188579602684
Validation loss: 4.378449692855116

Epoch: 5| Step: 7
Training loss: 4.410886232765297
Validation loss: 4.360055181835787

Epoch: 5| Step: 8
Training loss: 3.8977681351700326
Validation loss: 4.338165302726419

Epoch: 5| Step: 9
Training loss: 3.676349267640808
Validation loss: 4.319238447286873

Epoch: 5| Step: 10
Training loss: 4.943400659769327
Validation loss: 4.298586831772597

Epoch: 9| Step: 0
Training loss: 3.5844832652602334
Validation loss: 4.2760948459727315

Epoch: 5| Step: 1
Training loss: 4.00927564894808
Validation loss: 4.253532657000022

Epoch: 5| Step: 2
Training loss: 4.966919375824164
Validation loss: 4.237655637177467

Epoch: 5| Step: 3
Training loss: 4.441341403028138
Validation loss: 4.215446629390251

Epoch: 5| Step: 4
Training loss: 3.8351193427623578
Validation loss: 4.198117905724653

Epoch: 5| Step: 5
Training loss: 4.58459494595558
Validation loss: 4.186451957857466

Epoch: 5| Step: 6
Training loss: 3.955490188796705
Validation loss: 4.169605458318908

Epoch: 5| Step: 7
Training loss: 4.958245840289098
Validation loss: 4.155192117575054

Epoch: 5| Step: 8
Training loss: 4.345480814187278
Validation loss: 4.139593034255799

Epoch: 5| Step: 9
Training loss: 4.445874974712119
Validation loss: 4.121622198519553

Epoch: 5| Step: 10
Training loss: 4.024508257853287
Validation loss: 4.106744030147304

Epoch: 10| Step: 0
Training loss: 3.6218827096957416
Validation loss: 4.092791620083571

Epoch: 5| Step: 1
Training loss: 4.371619744310199
Validation loss: 4.075544329777365

Epoch: 5| Step: 2
Training loss: 3.830258144912042
Validation loss: 4.0667808701933605

Epoch: 5| Step: 3
Training loss: 4.6525917787841395
Validation loss: 4.054349278012744

Epoch: 5| Step: 4
Training loss: 4.546353969019691
Validation loss: 4.040768463392509

Epoch: 5| Step: 5
Training loss: 4.398302851999311
Validation loss: 4.031370720308198

Epoch: 5| Step: 6
Training loss: 4.539488780609798
Validation loss: 4.019487421700954

Epoch: 5| Step: 7
Training loss: 4.066877618123149
Validation loss: 4.00872591344223

Epoch: 5| Step: 8
Training loss: 3.856584289009494
Validation loss: 4.001431234731225

Epoch: 5| Step: 9
Training loss: 4.4182791495457305
Validation loss: 3.9902431640990788

Epoch: 5| Step: 10
Training loss: 3.2851497182883196
Validation loss: 3.984202885635125

Epoch: 11| Step: 0
Training loss: 4.4312876884030645
Validation loss: 3.974794897163067

Epoch: 5| Step: 1
Training loss: 3.8559701085336844
Validation loss: 3.9639200410476483

Epoch: 5| Step: 2
Training loss: 4.582608576027848
Validation loss: 3.9605345887078873

Epoch: 5| Step: 3
Training loss: 3.273612443350656
Validation loss: 3.948108726975095

Epoch: 5| Step: 4
Training loss: 3.378274812296575
Validation loss: 3.9386924426416847

Epoch: 5| Step: 5
Training loss: 4.481467763379425
Validation loss: 3.93300194777356

Epoch: 5| Step: 6
Training loss: 4.61560485876773
Validation loss: 3.9206268124514816

Epoch: 5| Step: 7
Training loss: 4.388211384455298
Validation loss: 3.9125619150778768

Epoch: 5| Step: 8
Training loss: 4.387012230693671
Validation loss: 3.907254638114997

Epoch: 5| Step: 9
Training loss: 3.608189772172029
Validation loss: 3.8965816510641247

Epoch: 5| Step: 10
Training loss: 3.5992140653797926
Validation loss: 3.886882662561964

Epoch: 12| Step: 0
Training loss: 4.323409724172161
Validation loss: 3.8810292422447414

Epoch: 5| Step: 1
Training loss: 3.7337651093888917
Validation loss: 3.870949935273947

Epoch: 5| Step: 2
Training loss: 3.719325686220644
Validation loss: 3.8670198992783114

Epoch: 5| Step: 3
Training loss: 4.237269239415854
Validation loss: 3.861496894252827

Epoch: 5| Step: 4
Training loss: 4.261983246117416
Validation loss: 3.8565669245319083

Epoch: 5| Step: 5
Training loss: 4.521675465049484
Validation loss: 3.8491075969060518

Epoch: 5| Step: 6
Training loss: 4.210392564606738
Validation loss: 3.8426451843943994

Epoch: 5| Step: 7
Training loss: 3.753826223864089
Validation loss: 3.837452911721899

Epoch: 5| Step: 8
Training loss: 4.834884898759528
Validation loss: 3.8313086344774883

Epoch: 5| Step: 9
Training loss: 3.0228277177998457
Validation loss: 3.8250949462585258

Epoch: 5| Step: 10
Training loss: 3.0591148819190837
Validation loss: 3.819706980363602

Epoch: 13| Step: 0
Training loss: 4.788936644451492
Validation loss: 3.812627972103018

Epoch: 5| Step: 1
Training loss: 3.1175656196889276
Validation loss: 3.8056083495196624

Epoch: 5| Step: 2
Training loss: 4.246562914297044
Validation loss: 3.8022476428246823

Epoch: 5| Step: 3
Training loss: 3.8271937892024575
Validation loss: 3.7907869160607555

Epoch: 5| Step: 4
Training loss: 4.014326189823241
Validation loss: 3.786522507675586

Epoch: 5| Step: 5
Training loss: 2.6506967276429902
Validation loss: 3.777518402435052

Epoch: 5| Step: 6
Training loss: 3.960071356159384
Validation loss: 3.7714700922100755

Epoch: 5| Step: 7
Training loss: 4.697070714511241
Validation loss: 3.7652093141079144

Epoch: 5| Step: 8
Training loss: 4.169726786639591
Validation loss: 3.761707548721271

Epoch: 5| Step: 9
Training loss: 3.382154863318682
Validation loss: 3.7573269926594497

Epoch: 5| Step: 10
Training loss: 4.155624227812028
Validation loss: 3.7497756972962044

Epoch: 14| Step: 0
Training loss: 3.8508231979750756
Validation loss: 3.7417332567092836

Epoch: 5| Step: 1
Training loss: 4.933292576045854
Validation loss: 3.7425478568356576

Epoch: 5| Step: 2
Training loss: 3.227992888384883
Validation loss: 3.731768468299854

Epoch: 5| Step: 3
Training loss: 3.8428550856954993
Validation loss: 3.72507286314346

Epoch: 5| Step: 4
Training loss: 3.731447612698846
Validation loss: 3.7209289638993663

Epoch: 5| Step: 5
Training loss: 3.718701402362669
Validation loss: 3.717477929893684

Epoch: 5| Step: 6
Training loss: 4.569405751062897
Validation loss: 3.7082634730647075

Epoch: 5| Step: 7
Training loss: 3.3574261357411883
Validation loss: 3.704216158689073

Epoch: 5| Step: 8
Training loss: 3.7319761096888837
Validation loss: 3.699904387551551

Epoch: 5| Step: 9
Training loss: 3.8270081428419274
Validation loss: 3.695154638282583

Epoch: 5| Step: 10
Training loss: 3.809236223855231
Validation loss: 3.690289706913358

Epoch: 15| Step: 0
Training loss: 3.6596437011891365
Validation loss: 3.684169524329576

Epoch: 5| Step: 1
Training loss: 3.7581450697837027
Validation loss: 3.6779215922541812

Epoch: 5| Step: 2
Training loss: 4.167459844751619
Validation loss: 3.673209785187639

Epoch: 5| Step: 3
Training loss: 4.167986825977088
Validation loss: 3.668740786856202

Epoch: 5| Step: 4
Training loss: 3.9275597941838707
Validation loss: 3.6655602370589992

Epoch: 5| Step: 5
Training loss: 3.6886669833938495
Validation loss: 3.659303862075358

Epoch: 5| Step: 6
Training loss: 3.706747994891457
Validation loss: 3.655615544775761

Epoch: 5| Step: 7
Training loss: 4.737197487867959
Validation loss: 3.6511375665441963

Epoch: 5| Step: 8
Training loss: 3.7363915525278224
Validation loss: 3.6466373148965556

Epoch: 5| Step: 9
Training loss: 3.196831153427242
Validation loss: 3.640587206679602

Epoch: 5| Step: 10
Training loss: 3.308443284469712
Validation loss: 3.638342085124727

Epoch: 16| Step: 0
Training loss: 4.4014975166872805
Validation loss: 3.6334394009534936

Epoch: 5| Step: 1
Training loss: 3.156441408906379
Validation loss: 3.6296692741913654

Epoch: 5| Step: 2
Training loss: 3.892626389330111
Validation loss: 3.6273159242997064

Epoch: 5| Step: 3
Training loss: 3.5426984892097746
Validation loss: 3.6242232446990794

Epoch: 5| Step: 4
Training loss: 4.055034879823713
Validation loss: 3.618642937977934

Epoch: 5| Step: 5
Training loss: 3.601633199465377
Validation loss: 3.6142750984204093

Epoch: 5| Step: 6
Training loss: 3.839954642385586
Validation loss: 3.608126630368569

Epoch: 5| Step: 7
Training loss: 3.095063826437458
Validation loss: 3.609698770405253

Epoch: 5| Step: 8
Training loss: 3.9450962725013694
Validation loss: 3.6040283770292243

Epoch: 5| Step: 9
Training loss: 3.951323328589816
Validation loss: 3.601789070213249

Epoch: 5| Step: 10
Training loss: 4.285817626433815
Validation loss: 3.596481425184717

Epoch: 17| Step: 0
Training loss: 4.050293881150063
Validation loss: 3.593663101608059

Epoch: 5| Step: 1
Training loss: 3.514532029539312
Validation loss: 3.5913784882127544

Epoch: 5| Step: 2
Training loss: 3.797669253065131
Validation loss: 3.58613696575616

Epoch: 5| Step: 3
Training loss: 3.738130859411227
Validation loss: 3.5845357652197647

Epoch: 5| Step: 4
Training loss: 3.8454712526117114
Validation loss: 3.583462329115656

Epoch: 5| Step: 5
Training loss: 3.5685392354267695
Validation loss: 3.5772543599918283

Epoch: 5| Step: 6
Training loss: 3.0656278557720356
Validation loss: 3.574447635804073

Epoch: 5| Step: 7
Training loss: 3.7141540079555146
Validation loss: 3.5723768678123844

Epoch: 5| Step: 8
Training loss: 3.434610990793725
Validation loss: 3.566653106448234

Epoch: 5| Step: 9
Training loss: 4.61281030949854
Validation loss: 3.5645456735573213

Epoch: 5| Step: 10
Training loss: 4.053492963642447
Validation loss: 3.5655247027916084

Epoch: 18| Step: 0
Training loss: 3.4671261397334887
Validation loss: 3.5612270424746924

Epoch: 5| Step: 1
Training loss: 4.212479063259358
Validation loss: 3.5559133704576196

Epoch: 5| Step: 2
Training loss: 3.525827481156712
Validation loss: 3.5539219055811277

Epoch: 5| Step: 3
Training loss: 3.5563503526094515
Validation loss: 3.551548428066791

Epoch: 5| Step: 4
Training loss: 3.3832333767662317
Validation loss: 3.548677603024939

Epoch: 5| Step: 5
Training loss: 3.2425778073612963
Validation loss: 3.5429531653823125

Epoch: 5| Step: 6
Training loss: 4.318229518061111
Validation loss: 3.542811544679072

Epoch: 5| Step: 7
Training loss: 3.578189366190647
Validation loss: 3.539568456274858

Epoch: 5| Step: 8
Training loss: 3.8417499580097823
Validation loss: 3.5371908050058947

Epoch: 5| Step: 9
Training loss: 4.228928557710075
Validation loss: 3.535886842884828

Epoch: 5| Step: 10
Training loss: 3.741971131124209
Validation loss: 3.5300466592712176

Epoch: 19| Step: 0
Training loss: 4.018689363060716
Validation loss: 3.5287840045543044

Epoch: 5| Step: 1
Training loss: 4.054893062136328
Validation loss: 3.5297625609945573

Epoch: 5| Step: 2
Training loss: 3.3584735459306243
Validation loss: 3.526620565632971

Epoch: 5| Step: 3
Training loss: 3.55651044109801
Validation loss: 3.521818318975338

Epoch: 5| Step: 4
Training loss: 4.267332301272356
Validation loss: 3.5222536530256927

Epoch: 5| Step: 5
Training loss: 3.1775522021575857
Validation loss: 3.5177553754931568

Epoch: 5| Step: 6
Training loss: 3.7268794342838607
Validation loss: 3.5139451824465415

Epoch: 5| Step: 7
Training loss: 3.8511299060593536
Validation loss: 3.513094900626837

Epoch: 5| Step: 8
Training loss: 3.5397703292395466
Validation loss: 3.509162694686564

Epoch: 5| Step: 9
Training loss: 3.7152945227953706
Validation loss: 3.5057053364095245

Epoch: 5| Step: 10
Training loss: 3.568028493656261
Validation loss: 3.5039681179618825

Epoch: 20| Step: 0
Training loss: 3.9630245451204376
Validation loss: 3.4976842458945785

Epoch: 5| Step: 1
Training loss: 3.4349716598474402
Validation loss: 3.4979011157755053

Epoch: 5| Step: 2
Training loss: 3.897363671542192
Validation loss: 3.493946267650719

Epoch: 5| Step: 3
Training loss: 3.042527760588257
Validation loss: 3.493884238369426

Epoch: 5| Step: 4
Training loss: 3.2331061339109057
Validation loss: 3.490427663985655

Epoch: 5| Step: 5
Training loss: 3.6103110152493865
Validation loss: 3.4886875791188636

Epoch: 5| Step: 6
Training loss: 4.3563265515994
Validation loss: 3.4894439086585907

Epoch: 5| Step: 7
Training loss: 3.9796562226545014
Validation loss: 3.4826365903393532

Epoch: 5| Step: 8
Training loss: 3.5079824155847414
Validation loss: 3.476973618297018

Epoch: 5| Step: 9
Training loss: 3.6112103440433625
Validation loss: 3.47714419446621

Epoch: 5| Step: 10
Training loss: 3.9149171425344567
Validation loss: 3.47383872820656

Epoch: 21| Step: 0
Training loss: 3.882734271053931
Validation loss: 3.470536139910674

Epoch: 5| Step: 1
Training loss: 3.591069424235652
Validation loss: 3.466092721596226

Epoch: 5| Step: 2
Training loss: 3.3630514210363582
Validation loss: 3.46615193176485

Epoch: 5| Step: 3
Training loss: 4.682692643911072
Validation loss: 3.462298462024049

Epoch: 5| Step: 4
Training loss: 2.963721262624773
Validation loss: 3.4610948228024556

Epoch: 5| Step: 5
Training loss: 3.7007930833539966
Validation loss: 3.454513887435446

Epoch: 5| Step: 6
Training loss: 3.494410547584992
Validation loss: 3.4524741479315457

Epoch: 5| Step: 7
Training loss: 3.6703873887750866
Validation loss: 3.4487554525429127

Epoch: 5| Step: 8
Training loss: 2.962882095354812
Validation loss: 3.445727750065276

Epoch: 5| Step: 9
Training loss: 3.9711169296029425
Validation loss: 3.4458518806945673

Epoch: 5| Step: 10
Training loss: 3.8496958327588353
Validation loss: 3.440491594112583

Epoch: 22| Step: 0
Training loss: 3.569970312769788
Validation loss: 3.435468883193813

Epoch: 5| Step: 1
Training loss: 3.6916714366138605
Validation loss: 3.4341936530130694

Epoch: 5| Step: 2
Training loss: 3.600408869942651
Validation loss: 3.431135085290971

Epoch: 5| Step: 3
Training loss: 4.041261056164556
Validation loss: 3.4291275086372126

Epoch: 5| Step: 4
Training loss: 3.040782608385539
Validation loss: 3.4228178718042477

Epoch: 5| Step: 5
Training loss: 3.6805589943795765
Validation loss: 3.423483150360887

Epoch: 5| Step: 6
Training loss: 3.117041103969508
Validation loss: 3.4170361946058265

Epoch: 5| Step: 7
Training loss: 3.764748878969765
Validation loss: 3.41329785220951

Epoch: 5| Step: 8
Training loss: 3.413866958430466
Validation loss: 3.4104434397071755

Epoch: 5| Step: 9
Training loss: 4.392507129331219
Validation loss: 3.410280271146204

Epoch: 5| Step: 10
Training loss: 3.59860074612579
Validation loss: 3.406323681527701

Epoch: 23| Step: 0
Training loss: 3.64538250270166
Validation loss: 3.4034492370683354

Epoch: 5| Step: 1
Training loss: 3.9191414474810387
Validation loss: 3.3999041304321675

Epoch: 5| Step: 2
Training loss: 3.7558030051347084
Validation loss: 3.398932412234644

Epoch: 5| Step: 3
Training loss: 4.112144784167035
Validation loss: 3.3958127486521477

Epoch: 5| Step: 4
Training loss: 3.021861688373521
Validation loss: 3.3912368826424246

Epoch: 5| Step: 5
Training loss: 4.179949885893847
Validation loss: 3.389619074970727

Epoch: 5| Step: 6
Training loss: 3.9093788738521225
Validation loss: 3.38630996365805

Epoch: 5| Step: 7
Training loss: 2.424618846394824
Validation loss: 3.384960966400932

Epoch: 5| Step: 8
Training loss: 3.0648433517078506
Validation loss: 3.3793561252903106

Epoch: 5| Step: 9
Training loss: 3.9601951369940456
Validation loss: 3.3770677634883195

Epoch: 5| Step: 10
Training loss: 3.3658630173587776
Validation loss: 3.372602816917984

Epoch: 24| Step: 0
Training loss: 3.4569084878450225
Validation loss: 3.3744214837082454

Epoch: 5| Step: 1
Training loss: 3.1134298138369005
Validation loss: 3.369719319840372

Epoch: 5| Step: 2
Training loss: 3.404987486201523
Validation loss: 3.365773946226505

Epoch: 5| Step: 3
Training loss: 3.737555007784937
Validation loss: 3.361681154187048

Epoch: 5| Step: 4
Training loss: 2.432768312811222
Validation loss: 3.3581051806815614

Epoch: 5| Step: 5
Training loss: 3.960071837804371
Validation loss: 3.3550394815952447

Epoch: 5| Step: 6
Training loss: 3.0615067720339866
Validation loss: 3.3519050485623887

Epoch: 5| Step: 7
Training loss: 4.272979098043244
Validation loss: 3.348808309072083

Epoch: 5| Step: 8
Training loss: 3.231609839467168
Validation loss: 3.3462286935410095

Epoch: 5| Step: 9
Training loss: 4.060290161061966
Validation loss: 3.3447235916516123

Epoch: 5| Step: 10
Training loss: 4.3611381000782465
Validation loss: 3.3418333494468384

Epoch: 25| Step: 0
Training loss: 3.7545382695063183
Validation loss: 3.340086259129023

Epoch: 5| Step: 1
Training loss: 3.973041046921421
Validation loss: 3.3366352975021965

Epoch: 5| Step: 2
Training loss: 2.900022993325468
Validation loss: 3.332596370281903

Epoch: 5| Step: 3
Training loss: 4.095931076378885
Validation loss: 3.331518331786087

Epoch: 5| Step: 4
Training loss: 3.5202680656923695
Validation loss: 3.3268545937144305

Epoch: 5| Step: 5
Training loss: 4.105359105933593
Validation loss: 3.326535127239571

Epoch: 5| Step: 6
Training loss: 3.9094169291222967
Validation loss: 3.323675619756277

Epoch: 5| Step: 7
Training loss: 3.4460395858890895
Validation loss: 3.319320488439123

Epoch: 5| Step: 8
Training loss: 3.7153062021152543
Validation loss: 3.3198967353767204

Epoch: 5| Step: 9
Training loss: 2.12042315650447
Validation loss: 3.317034749666525

Epoch: 5| Step: 10
Training loss: 3.1247608856272815
Validation loss: 3.3173662453842088

Epoch: 26| Step: 0
Training loss: 3.7707552963246953
Validation loss: 3.316606576117241

Epoch: 5| Step: 1
Training loss: 3.7013125591666167
Validation loss: 3.3150903839904116

Epoch: 5| Step: 2
Training loss: 3.463456522341997
Validation loss: 3.309074511337871

Epoch: 5| Step: 3
Training loss: 3.33853798487674
Validation loss: 3.3095217546690328

Epoch: 5| Step: 4
Training loss: 3.142651563584111
Validation loss: 3.306630713541599

Epoch: 5| Step: 5
Training loss: 4.380373025973894
Validation loss: 3.3011461841006913

Epoch: 5| Step: 6
Training loss: 3.508511819776892
Validation loss: 3.3042153378707257

Epoch: 5| Step: 7
Training loss: 3.4071924148296002
Validation loss: 3.299555991821731

Epoch: 5| Step: 8
Training loss: 3.4407319567666748
Validation loss: 3.297678730653184

Epoch: 5| Step: 9
Training loss: 3.5143338015165044
Validation loss: 3.2958965084870897

Epoch: 5| Step: 10
Training loss: 3.13856309608481
Validation loss: 3.2952186176631684

Epoch: 27| Step: 0
Training loss: 3.408273498333272
Validation loss: 3.2902860855102953

Epoch: 5| Step: 1
Training loss: 3.4447789200711423
Validation loss: 3.2917006212951856

Epoch: 5| Step: 2
Training loss: 3.4267795200046276
Validation loss: 3.288789415070026

Epoch: 5| Step: 3
Training loss: 4.115821568364837
Validation loss: 3.2879211348810613

Epoch: 5| Step: 4
Training loss: 2.835904207901177
Validation loss: 3.2837752024955065

Epoch: 5| Step: 5
Training loss: 3.6114176465208976
Validation loss: 3.2838167276227836

Epoch: 5| Step: 6
Training loss: 4.107431626682432
Validation loss: 3.2825549115575483

Epoch: 5| Step: 7
Training loss: 3.837164470902676
Validation loss: 3.280054708148893

Epoch: 5| Step: 8
Training loss: 3.7761082014163354
Validation loss: 3.2781757976084474

Epoch: 5| Step: 9
Training loss: 3.26328014531755
Validation loss: 3.279333544280006

Epoch: 5| Step: 10
Training loss: 2.55585511382277
Validation loss: 3.27590865006285

Epoch: 28| Step: 0
Training loss: 2.697130557579463
Validation loss: 3.2759594402809165

Epoch: 5| Step: 1
Training loss: 4.159469848743638
Validation loss: 3.2751993922862654

Epoch: 5| Step: 2
Training loss: 3.88671224775681
Validation loss: 3.2729979976347416

Epoch: 5| Step: 3
Training loss: 3.529603827617434
Validation loss: 3.271038743145107

Epoch: 5| Step: 4
Training loss: 3.3740707813700817
Validation loss: 3.2709751389718718

Epoch: 5| Step: 5
Training loss: 3.558966507216288
Validation loss: 3.2692734778220465

Epoch: 5| Step: 6
Training loss: 3.546987926685229
Validation loss: 3.2662674545251766

Epoch: 5| Step: 7
Training loss: 3.4785674410970877
Validation loss: 3.265931083071794

Epoch: 5| Step: 8
Training loss: 3.137204257355291
Validation loss: 3.263942656681066

Epoch: 5| Step: 9
Training loss: 3.8392026721173202
Validation loss: 3.261287778977508

Epoch: 5| Step: 10
Training loss: 3.2062618619762606
Validation loss: 3.26086834093237

Epoch: 29| Step: 0
Training loss: 3.736316128525566
Validation loss: 3.2600036666696495

Epoch: 5| Step: 1
Training loss: 2.6324873816902334
Validation loss: 3.257887530466771

Epoch: 5| Step: 2
Training loss: 3.4334257082564363
Validation loss: 3.255130597505117

Epoch: 5| Step: 3
Training loss: 2.996831174018865
Validation loss: 3.256186839973973

Epoch: 5| Step: 4
Training loss: 3.9319325398879847
Validation loss: 3.255981065877132

Epoch: 5| Step: 5
Training loss: 4.037476691305711
Validation loss: 3.2530581534824785

Epoch: 5| Step: 6
Training loss: 3.8947748932532944
Validation loss: 3.2518726346183207

Epoch: 5| Step: 7
Training loss: 3.278419363589651
Validation loss: 3.251652798218279

Epoch: 5| Step: 8
Training loss: 3.0699941067219685
Validation loss: 3.2503259872377117

Epoch: 5| Step: 9
Training loss: 3.7190331102842613
Validation loss: 3.2482707177151684

Epoch: 5| Step: 10
Training loss: 3.54088176930883
Validation loss: 3.247063514689404

Epoch: 30| Step: 0
Training loss: 2.9803778758262927
Validation loss: 3.2467436635864533

Epoch: 5| Step: 1
Training loss: 3.5928951407679173
Validation loss: 3.2474301387508584

Epoch: 5| Step: 2
Training loss: 3.7399635794595105
Validation loss: 3.2417120835898485

Epoch: 5| Step: 3
Training loss: 3.6860137789257075
Validation loss: 3.2406713212901086

Epoch: 5| Step: 4
Training loss: 3.1390923703235987
Validation loss: 3.2398576612715977

Epoch: 5| Step: 5
Training loss: 3.098167579270554
Validation loss: 3.238824620523872

Epoch: 5| Step: 6
Training loss: 3.417661258489964
Validation loss: 3.236736166355627

Epoch: 5| Step: 7
Training loss: 4.180032248851727
Validation loss: 3.2352568902506116

Epoch: 5| Step: 8
Training loss: 3.387591714778745
Validation loss: 3.2342899535839003

Epoch: 5| Step: 9
Training loss: 3.196388119550444
Validation loss: 3.2333807106297865

Epoch: 5| Step: 10
Training loss: 3.862321477918624
Validation loss: 3.232446659346173

Epoch: 31| Step: 0
Training loss: 3.3342046234734015
Validation loss: 3.233007427153923

Epoch: 5| Step: 1
Training loss: 3.0131542777423546
Validation loss: 3.2303009745522258

Epoch: 5| Step: 2
Training loss: 3.562623808198485
Validation loss: 3.2268274229229887

Epoch: 5| Step: 3
Training loss: 3.3630684354399683
Validation loss: 3.2268870105420464

Epoch: 5| Step: 4
Training loss: 2.9236528016594034
Validation loss: 3.2278548249792447

Epoch: 5| Step: 5
Training loss: 3.44438979061068
Validation loss: 3.2237807298880656

Epoch: 5| Step: 6
Training loss: 3.7168068818014266
Validation loss: 3.2248880537196563

Epoch: 5| Step: 7
Training loss: 3.732069508893674
Validation loss: 3.2224340831238227

Epoch: 5| Step: 8
Training loss: 4.170929648055493
Validation loss: 3.2229091010364264

Epoch: 5| Step: 9
Training loss: 3.8388521576992094
Validation loss: 3.219007795352196

Epoch: 5| Step: 10
Training loss: 2.8571199790856063
Validation loss: 3.2182078595382944

Epoch: 32| Step: 0
Training loss: 2.9634150705410907
Validation loss: 3.21798004393861

Epoch: 5| Step: 1
Training loss: 3.2781750030631382
Validation loss: 3.218670774066831

Epoch: 5| Step: 2
Training loss: 3.382798686010334
Validation loss: 3.2151882019147773

Epoch: 5| Step: 3
Training loss: 3.069522668715337
Validation loss: 3.215723416591171

Epoch: 5| Step: 4
Training loss: 3.4062877967907275
Validation loss: 3.2136665309741907

Epoch: 5| Step: 5
Training loss: 4.107069173590247
Validation loss: 3.213319457073152

Epoch: 5| Step: 6
Training loss: 3.7465328718937814
Validation loss: 3.2113961227415952

Epoch: 5| Step: 7
Training loss: 4.476360749230448
Validation loss: 3.2078332472635362

Epoch: 5| Step: 8
Training loss: 3.006278461789482
Validation loss: 3.2069294327932503

Epoch: 5| Step: 9
Training loss: 3.5456235585242557
Validation loss: 3.2059312838371716

Epoch: 5| Step: 10
Training loss: 2.653815286833211
Validation loss: 3.204853014936739

Epoch: 33| Step: 0
Training loss: 3.6392737242547817
Validation loss: 3.2019401273655133

Epoch: 5| Step: 1
Training loss: 3.3231746051293722
Validation loss: 3.2028051169094502

Epoch: 5| Step: 2
Training loss: 3.485340754352463
Validation loss: 3.2011874874239084

Epoch: 5| Step: 3
Training loss: 3.534342264281838
Validation loss: 3.201250306339205

Epoch: 5| Step: 4
Training loss: 3.199942892280264
Validation loss: 3.201056687474592

Epoch: 5| Step: 5
Training loss: 3.140190891610635
Validation loss: 3.1964676764112

Epoch: 5| Step: 6
Training loss: 3.811123583865601
Validation loss: 3.195014641871842

Epoch: 5| Step: 7
Training loss: 3.017717337251995
Validation loss: 3.1954557208863124

Epoch: 5| Step: 8
Training loss: 3.1765590714615812
Validation loss: 3.1956264605266247

Epoch: 5| Step: 9
Training loss: 3.6198227842168933
Validation loss: 3.1947190654594584

Epoch: 5| Step: 10
Training loss: 4.053331798963089
Validation loss: 3.1943026568414363

Epoch: 34| Step: 0
Training loss: 3.910228442765125
Validation loss: 3.190943657532459

Epoch: 5| Step: 1
Training loss: 3.2585590339664305
Validation loss: 3.1891370209415157

Epoch: 5| Step: 2
Training loss: 3.702215541753686
Validation loss: 3.185733119672986

Epoch: 5| Step: 3
Training loss: 3.376703468215096
Validation loss: 3.1856365318369426

Epoch: 5| Step: 4
Training loss: 3.2876972617954476
Validation loss: 3.187776629552412

Epoch: 5| Step: 5
Training loss: 3.793850922852544
Validation loss: 3.1869190128129756

Epoch: 5| Step: 6
Training loss: 2.6773390196376363
Validation loss: 3.1851314557164114

Epoch: 5| Step: 7
Training loss: 3.6451749079932063
Validation loss: 3.181614658453181

Epoch: 5| Step: 8
Training loss: 3.484169992480135
Validation loss: 3.182398286551937

Epoch: 5| Step: 9
Training loss: 3.0982771608357513
Validation loss: 3.17889948268515

Epoch: 5| Step: 10
Training loss: 3.5327534133714313
Validation loss: 3.177397048015716

Epoch: 35| Step: 0
Training loss: 3.078039487628829
Validation loss: 3.17768231411967

Epoch: 5| Step: 1
Training loss: 3.9825899800530244
Validation loss: 3.176657678475866

Epoch: 5| Step: 2
Training loss: 3.9925473642615166
Validation loss: 3.1756003794917635

Epoch: 5| Step: 3
Training loss: 3.477024964851586
Validation loss: 3.172722623650323

Epoch: 5| Step: 4
Training loss: 3.918132318370299
Validation loss: 3.1724776079437853

Epoch: 5| Step: 5
Training loss: 2.489008870477989
Validation loss: 3.1737513706212215

Epoch: 5| Step: 6
Training loss: 2.990265948865801
Validation loss: 3.170737765385539

Epoch: 5| Step: 7
Training loss: 3.2541584407166773
Validation loss: 3.1701992054797348

Epoch: 5| Step: 8
Training loss: 4.009182166132558
Validation loss: 3.1694067203440035

Epoch: 5| Step: 9
Training loss: 2.667686793786413
Validation loss: 3.1690816435624747

Epoch: 5| Step: 10
Training loss: 3.5548954158802872
Validation loss: 3.166925835541795

Epoch: 36| Step: 0
Training loss: 3.906675758047451
Validation loss: 3.165821574439665

Epoch: 5| Step: 1
Training loss: 3.478592663468225
Validation loss: 3.1684005542357183

Epoch: 5| Step: 2
Training loss: 3.06404215073041
Validation loss: 3.167305422631136

Epoch: 5| Step: 3
Training loss: 4.3092747666263085
Validation loss: 3.16423354613877

Epoch: 5| Step: 4
Training loss: 3.099167675138841
Validation loss: 3.1614421260148204

Epoch: 5| Step: 5
Training loss: 2.4095741199587937
Validation loss: 3.161414326323675

Epoch: 5| Step: 6
Training loss: 3.4066636420558134
Validation loss: 3.1650911199392295

Epoch: 5| Step: 7
Training loss: 3.3015921595442204
Validation loss: 3.162632396876859

Epoch: 5| Step: 8
Training loss: 3.4528811269405475
Validation loss: 3.157830623024621

Epoch: 5| Step: 9
Training loss: 3.575820780613301
Validation loss: 3.1595412275103256

Epoch: 5| Step: 10
Training loss: 3.402223779816551
Validation loss: 3.1585300600093738

Epoch: 37| Step: 0
Training loss: 3.303141202859828
Validation loss: 3.156039043805787

Epoch: 5| Step: 1
Training loss: 3.5650055757668913
Validation loss: 3.1571125097599553

Epoch: 5| Step: 2
Training loss: 3.606675364565512
Validation loss: 3.1558848173538325

Epoch: 5| Step: 3
Training loss: 3.2900426858376455
Validation loss: 3.1556272457864996

Epoch: 5| Step: 4
Training loss: 2.925755825365166
Validation loss: 3.156096037288733

Epoch: 5| Step: 5
Training loss: 3.7737680610257396
Validation loss: 3.155837748597514

Epoch: 5| Step: 6
Training loss: 3.724817535232614
Validation loss: 3.1544616483473393

Epoch: 5| Step: 7
Training loss: 3.8507861734251594
Validation loss: 3.153733761958315

Epoch: 5| Step: 8
Training loss: 2.8237097401512
Validation loss: 3.1516377349594697

Epoch: 5| Step: 9
Training loss: 3.265390780139719
Validation loss: 3.1498709665080793

Epoch: 5| Step: 10
Training loss: 3.3476353113861657
Validation loss: 3.1485663927852765

Epoch: 38| Step: 0
Training loss: 3.471908643338063
Validation loss: 3.145415400501438

Epoch: 5| Step: 1
Training loss: 3.3590656936549412
Validation loss: 3.148490738999382

Epoch: 5| Step: 2
Training loss: 3.575192778398105
Validation loss: 3.1444421919522774

Epoch: 5| Step: 3
Training loss: 3.3377691953300106
Validation loss: 3.1439881031160204

Epoch: 5| Step: 4
Training loss: 3.844726066405226
Validation loss: 3.1434696884832136

Epoch: 5| Step: 5
Training loss: 3.6322832275736014
Validation loss: 3.144836330270223

Epoch: 5| Step: 6
Training loss: 2.643187684483736
Validation loss: 3.1404867364753954

Epoch: 5| Step: 7
Training loss: 3.480966722889878
Validation loss: 3.137198617217729

Epoch: 5| Step: 8
Training loss: 3.6200418436150605
Validation loss: 3.137628912122997

Epoch: 5| Step: 9
Training loss: 2.9810891161999145
Validation loss: 3.135430001794085

Epoch: 5| Step: 10
Training loss: 3.4580333227225517
Validation loss: 3.137863105517253

Epoch: 39| Step: 0
Training loss: 2.29099408307887
Validation loss: 3.1347844983473445

Epoch: 5| Step: 1
Training loss: 3.836122092721517
Validation loss: 3.135746400356329

Epoch: 5| Step: 2
Training loss: 3.838556269803817
Validation loss: 3.1342624601285243

Epoch: 5| Step: 3
Training loss: 3.720558432020863
Validation loss: 3.134930118127933

Epoch: 5| Step: 4
Training loss: 3.303403780892039
Validation loss: 3.1316239817769773

Epoch: 5| Step: 5
Training loss: 3.8310906580885247
Validation loss: 3.1363160142189654

Epoch: 5| Step: 6
Training loss: 3.194745971896854
Validation loss: 3.130333999263344

Epoch: 5| Step: 7
Training loss: 3.434011180097435
Validation loss: 3.132371374433298

Epoch: 5| Step: 8
Training loss: 3.062358930803072
Validation loss: 3.1410476987021783

Epoch: 5| Step: 9
Training loss: 3.462153856072852
Validation loss: 3.1442532674771617

Epoch: 5| Step: 10
Training loss: 3.1574023569795258
Validation loss: 3.1241380663657456

Epoch: 40| Step: 0
Training loss: 3.7614003142737613
Validation loss: 3.126772265206178

Epoch: 5| Step: 1
Training loss: 2.8634850818477897
Validation loss: 3.1267824762243244

Epoch: 5| Step: 2
Training loss: 2.897020677444673
Validation loss: 3.1304480399961268

Epoch: 5| Step: 3
Training loss: 3.6458038038238647
Validation loss: 3.1283162566890073

Epoch: 5| Step: 4
Training loss: 4.1168025088323725
Validation loss: 3.1295257430718646

Epoch: 5| Step: 5
Training loss: 3.7779473628208633
Validation loss: 3.130515310058125

Epoch: 5| Step: 6
Training loss: 3.291879783845623
Validation loss: 3.13123461151943

Epoch: 5| Step: 7
Training loss: 3.4499781842855035
Validation loss: 3.131164143318826

Epoch: 5| Step: 8
Training loss: 2.9297273760307068
Validation loss: 3.128861684096338

Epoch: 5| Step: 9
Training loss: 3.2570656485238283
Validation loss: 3.1276364876512717

Epoch: 5| Step: 10
Training loss: 3.1598835793307822
Validation loss: 3.125872428280977

Epoch: 41| Step: 0
Training loss: 2.8141084098565816
Validation loss: 3.1247011341212305

Epoch: 5| Step: 1
Training loss: 3.409376476927384
Validation loss: 3.1241739177955874

Epoch: 5| Step: 2
Training loss: 3.9423878924601903
Validation loss: 3.1228176692281586

Epoch: 5| Step: 3
Training loss: 3.591952064899481
Validation loss: 3.122012711003472

Epoch: 5| Step: 4
Training loss: 3.779635754751856
Validation loss: 3.119659355831522

Epoch: 5| Step: 5
Training loss: 3.396217340081364
Validation loss: 3.1189721050446084

Epoch: 5| Step: 6
Training loss: 3.2317303888872786
Validation loss: 3.116433441956019

Epoch: 5| Step: 7
Training loss: 3.163109906757361
Validation loss: 3.1147424520937363

Epoch: 5| Step: 8
Training loss: 3.1693041676147704
Validation loss: 3.1155940631498065

Epoch: 5| Step: 9
Training loss: 3.3244525544798056
Validation loss: 3.113743218944418

Epoch: 5| Step: 10
Training loss: 3.3888559252971904
Validation loss: 3.1135335638761283

Epoch: 42| Step: 0
Training loss: 3.449696629772447
Validation loss: 3.11176012383598

Epoch: 5| Step: 1
Training loss: 3.5262316939491685
Validation loss: 3.1125814817368282

Epoch: 5| Step: 2
Training loss: 4.028302675150782
Validation loss: 3.111365483569689

Epoch: 5| Step: 3
Training loss: 3.6554019303073537
Validation loss: 3.1060873067621464

Epoch: 5| Step: 4
Training loss: 3.263025590792164
Validation loss: 3.1051650213696913

Epoch: 5| Step: 5
Training loss: 2.9227048949899546
Validation loss: 3.1066450202140583

Epoch: 5| Step: 6
Training loss: 3.258639370204065
Validation loss: 3.106367038428298

Epoch: 5| Step: 7
Training loss: 3.0947076105348224
Validation loss: 3.1055761653943614

Epoch: 5| Step: 8
Training loss: 3.1601726970079578
Validation loss: 3.102889679860056

Epoch: 5| Step: 9
Training loss: 3.6778628609974295
Validation loss: 3.104175104852541

Epoch: 5| Step: 10
Training loss: 2.965992982502389
Validation loss: 3.101150347687859

Epoch: 43| Step: 0
Training loss: 3.010025122147972
Validation loss: 3.1006478280086913

Epoch: 5| Step: 1
Training loss: 3.4264494397618988
Validation loss: 3.100488678254028

Epoch: 5| Step: 2
Training loss: 3.017641016233781
Validation loss: 3.101805092075093

Epoch: 5| Step: 3
Training loss: 3.8513918949125707
Validation loss: 3.0980185226916475

Epoch: 5| Step: 4
Training loss: 2.7981416189089168
Validation loss: 3.0982786585030637

Epoch: 5| Step: 5
Training loss: 2.8815172381808
Validation loss: 3.096323313061244

Epoch: 5| Step: 6
Training loss: 4.175325602552345
Validation loss: 3.0975545669338165

Epoch: 5| Step: 7
Training loss: 2.8719783328522097
Validation loss: 3.0963542108242446

Epoch: 5| Step: 8
Training loss: 3.482105148726079
Validation loss: 3.095974673056799

Epoch: 5| Step: 9
Training loss: 4.031203868513301
Validation loss: 3.095385945392811

Epoch: 5| Step: 10
Training loss: 3.243166561981497
Validation loss: 3.096224876650727

Epoch: 44| Step: 0
Training loss: 3.6746588360472776
Validation loss: 3.0941148735224946

Epoch: 5| Step: 1
Training loss: 2.7213063991801794
Validation loss: 3.093203830663752

Epoch: 5| Step: 2
Training loss: 4.06605374350167
Validation loss: 3.0934819552539703

Epoch: 5| Step: 3
Training loss: 2.7419895198463142
Validation loss: 3.0915346074361976

Epoch: 5| Step: 4
Training loss: 3.305634779920155
Validation loss: 3.0930641071115357

Epoch: 5| Step: 5
Training loss: 3.500206804977715
Validation loss: 3.0911424341038045

Epoch: 5| Step: 6
Training loss: 2.9560395244490527
Validation loss: 3.09099945076444

Epoch: 5| Step: 7
Training loss: 3.7721978909795992
Validation loss: 3.091335139305094

Epoch: 5| Step: 8
Training loss: 3.5321392188796654
Validation loss: 3.088759884902405

Epoch: 5| Step: 9
Training loss: 2.6501528605872453
Validation loss: 3.0878731686626777

Epoch: 5| Step: 10
Training loss: 3.89876492335089
Validation loss: 3.0883427252047055

Epoch: 45| Step: 0
Training loss: 3.2956613051268406
Validation loss: 3.0877299193567675

Epoch: 5| Step: 1
Training loss: 3.46555641870086
Validation loss: 3.0869266186007387

Epoch: 5| Step: 2
Training loss: 3.06236111072972
Validation loss: 3.08752065340039

Epoch: 5| Step: 3
Training loss: 4.084284198104813
Validation loss: 3.0855026617890413

Epoch: 5| Step: 4
Training loss: 3.9364897627870006
Validation loss: 3.0867708816357866

Epoch: 5| Step: 5
Training loss: 3.96315424960222
Validation loss: 3.0858579696764425

Epoch: 5| Step: 6
Training loss: 2.9518468603714796
Validation loss: 3.0854968905852993

Epoch: 5| Step: 7
Training loss: 3.681360985940019
Validation loss: 3.0837524720065033

Epoch: 5| Step: 8
Training loss: 2.294832320393615
Validation loss: 3.0831278577572108

Epoch: 5| Step: 9
Training loss: 2.4641090906318794
Validation loss: 3.082231059068006

Epoch: 5| Step: 10
Training loss: 3.3226171057552687
Validation loss: 3.082395966236065

Epoch: 46| Step: 0
Training loss: 2.8408527077368273
Validation loss: 3.0824141597043977

Epoch: 5| Step: 1
Training loss: 3.3881779291479703
Validation loss: 3.0825764548292964

Epoch: 5| Step: 2
Training loss: 3.7620621283844726
Validation loss: 3.081144346291871

Epoch: 5| Step: 3
Training loss: 3.3958394961310945
Validation loss: 3.0819912866319363

Epoch: 5| Step: 4
Training loss: 2.978107682104685
Validation loss: 3.079673368079497

Epoch: 5| Step: 5
Training loss: 3.8515856511965847
Validation loss: 3.0807240533544022

Epoch: 5| Step: 6
Training loss: 3.210355311423634
Validation loss: 3.0818122694373664

Epoch: 5| Step: 7
Training loss: 3.065901599347625
Validation loss: 3.081255313697564

Epoch: 5| Step: 8
Training loss: 3.654025713566514
Validation loss: 3.0788643399166356

Epoch: 5| Step: 9
Training loss: 3.3514557934827285
Validation loss: 3.0788919665482894

Epoch: 5| Step: 10
Training loss: 3.3634949017051277
Validation loss: 3.079828332715005

Epoch: 47| Step: 0
Training loss: 2.8816807290464563
Validation loss: 3.078696943655635

Epoch: 5| Step: 1
Training loss: 3.1442294716411703
Validation loss: 3.0770461500565642

Epoch: 5| Step: 2
Training loss: 3.140945342318554
Validation loss: 3.0775625729997262

Epoch: 5| Step: 3
Training loss: 3.8043418272930736
Validation loss: 3.076999015074152

Epoch: 5| Step: 4
Training loss: 4.004536440497387
Validation loss: 3.077479600745548

Epoch: 5| Step: 5
Training loss: 3.090369178668048
Validation loss: 3.078210556634391

Epoch: 5| Step: 6
Training loss: 3.490012633074
Validation loss: 3.076764254211944

Epoch: 5| Step: 7
Training loss: 2.728599071933292
Validation loss: 3.0766858666239445

Epoch: 5| Step: 8
Training loss: 3.5869482274016127
Validation loss: 3.076177935381895

Epoch: 5| Step: 9
Training loss: 3.191225156466961
Validation loss: 3.076151743645725

Epoch: 5| Step: 10
Training loss: 3.7271124156132136
Validation loss: 3.0749422088776273

Epoch: 48| Step: 0
Training loss: 3.43103167841626
Validation loss: 3.0767738721271174

Epoch: 5| Step: 1
Training loss: 3.254484896825387
Validation loss: 3.0761359708259484

Epoch: 5| Step: 2
Training loss: 3.1066849156554537
Validation loss: 3.0747532437817306

Epoch: 5| Step: 3
Training loss: 3.6513781571612434
Validation loss: 3.0747784994407734

Epoch: 5| Step: 4
Training loss: 3.3464646772648954
Validation loss: 3.0732264781608416

Epoch: 5| Step: 5
Training loss: 2.992074351748566
Validation loss: 3.0732180161725715

Epoch: 5| Step: 6
Training loss: 2.7998156725292436
Validation loss: 3.0724616819121824

Epoch: 5| Step: 7
Training loss: 2.9687027776877524
Validation loss: 3.073796776150639

Epoch: 5| Step: 8
Training loss: 4.076387115483906
Validation loss: 3.073253866013607

Epoch: 5| Step: 9
Training loss: 3.560449244195963
Validation loss: 3.0724093666921255

Epoch: 5| Step: 10
Training loss: 3.5949667819508537
Validation loss: 3.0718519504443353

Epoch: 49| Step: 0
Training loss: 3.2549315963097096
Validation loss: 3.0717559313011633

Epoch: 5| Step: 1
Training loss: 2.934414155838995
Validation loss: 3.070003008488097

Epoch: 5| Step: 2
Training loss: 3.43932918084812
Validation loss: 3.0712973712081184

Epoch: 5| Step: 3
Training loss: 4.2895480855587005
Validation loss: 3.07100839208696

Epoch: 5| Step: 4
Training loss: 3.1111500336467786
Validation loss: 3.070391691547044

Epoch: 5| Step: 5
Training loss: 3.0136098503014592
Validation loss: 3.071462194336867

Epoch: 5| Step: 6
Training loss: 2.194893141906555
Validation loss: 3.0713012609512313

Epoch: 5| Step: 7
Training loss: 3.4991255076429173
Validation loss: 3.0701687519868224

Epoch: 5| Step: 8
Training loss: 4.062958207332589
Validation loss: 3.0694095265168944

Epoch: 5| Step: 9
Training loss: 3.5984861263777854
Validation loss: 3.0694641462572365

Epoch: 5| Step: 10
Training loss: 2.9790061071563128
Validation loss: 3.0688210723929266

Epoch: 50| Step: 0
Training loss: 2.5697178486114325
Validation loss: 3.0696576177351855

Epoch: 5| Step: 1
Training loss: 2.587797757767678
Validation loss: 3.0694129918540876

Epoch: 5| Step: 2
Training loss: 3.680366858357624
Validation loss: 3.068889791891326

Epoch: 5| Step: 3
Training loss: 2.9739106948876244
Validation loss: 3.0682013695720487

Epoch: 5| Step: 4
Training loss: 2.7847229779740026
Validation loss: 3.0669720602877035

Epoch: 5| Step: 5
Training loss: 3.724639844444721
Validation loss: 3.0676763375385367

Epoch: 5| Step: 6
Training loss: 3.347888275260315
Validation loss: 3.0692252123809025

Epoch: 5| Step: 7
Training loss: 3.1518596669825834
Validation loss: 3.0671733552197877

Epoch: 5| Step: 8
Training loss: 3.8030059670444873
Validation loss: 3.066330124198993

Epoch: 5| Step: 9
Training loss: 3.8610012319345985
Validation loss: 3.067624891745861

Epoch: 5| Step: 10
Training loss: 4.097453531463765
Validation loss: 3.065947263545121

Epoch: 51| Step: 0
Training loss: 3.1974794832455715
Validation loss: 3.064801337350291

Epoch: 5| Step: 1
Training loss: 3.4334104313264686
Validation loss: 3.0646650719622017

Epoch: 5| Step: 2
Training loss: 3.5949167762429206
Validation loss: 3.0643041543882195

Epoch: 5| Step: 3
Training loss: 3.6300125981472187
Validation loss: 3.0652931272158512

Epoch: 5| Step: 4
Training loss: 3.121668298425229
Validation loss: 3.0644810279493946

Epoch: 5| Step: 5
Training loss: 3.1243483817700204
Validation loss: 3.0638385381429454

Epoch: 5| Step: 6
Training loss: 3.0193938585536153
Validation loss: 3.063836124979715

Epoch: 5| Step: 7
Training loss: 3.081486759026741
Validation loss: 3.064125366372572

Epoch: 5| Step: 8
Training loss: 3.309305918317426
Validation loss: 3.0623759867622313

Epoch: 5| Step: 9
Training loss: 3.3051314540465455
Validation loss: 3.0622321776225028

Epoch: 5| Step: 10
Training loss: 4.024708252752663
Validation loss: 3.060554437635642

Epoch: 52| Step: 0
Training loss: 3.420248960390136
Validation loss: 3.0627818025038946

Epoch: 5| Step: 1
Training loss: 2.762778244850373
Validation loss: 3.0611482608369416

Epoch: 5| Step: 2
Training loss: 3.284362769716614
Validation loss: 3.061579912842364

Epoch: 5| Step: 3
Training loss: 3.592874569621749
Validation loss: 3.0611640003353693

Epoch: 5| Step: 4
Training loss: 3.450190751704104
Validation loss: 3.058493339866295

Epoch: 5| Step: 5
Training loss: 2.7387776707096245
Validation loss: 3.0598985431199215

Epoch: 5| Step: 6
Training loss: 3.1064450055013997
Validation loss: 3.0583867587240032

Epoch: 5| Step: 7
Training loss: 3.53267431651123
Validation loss: 3.058824886806979

Epoch: 5| Step: 8
Training loss: 3.44230995047003
Validation loss: 3.0607444280133214

Epoch: 5| Step: 9
Training loss: 3.93969532151655
Validation loss: 3.058807164019983

Epoch: 5| Step: 10
Training loss: 3.385578390317865
Validation loss: 3.057082645332698

Epoch: 53| Step: 0
Training loss: 3.1964395862337804
Validation loss: 3.0558208503914384

Epoch: 5| Step: 1
Training loss: 3.6515262443626284
Validation loss: 3.057079863726558

Epoch: 5| Step: 2
Training loss: 3.895038843316249
Validation loss: 3.0570745923369813

Epoch: 5| Step: 3
Training loss: 3.2847820345536425
Validation loss: 3.0564933923029374

Epoch: 5| Step: 4
Training loss: 3.029125294846663
Validation loss: 3.0561452231989157

Epoch: 5| Step: 5
Training loss: 3.9052281378264806
Validation loss: 3.0565468723544744

Epoch: 5| Step: 6
Training loss: 3.2387351901659147
Validation loss: 3.054538066544823

Epoch: 5| Step: 7
Training loss: 2.611293064929187
Validation loss: 3.053980820045925

Epoch: 5| Step: 8
Training loss: 2.831903620507719
Validation loss: 3.0547201549684555

Epoch: 5| Step: 9
Training loss: 3.3019339991996812
Validation loss: 3.0549248267822504

Epoch: 5| Step: 10
Training loss: 3.6408253888821833
Validation loss: 3.0537654678056216

Epoch: 54| Step: 0
Training loss: 3.2959723660690217
Validation loss: 3.053941194755273

Epoch: 5| Step: 1
Training loss: 3.425905684295823
Validation loss: 3.0549058326577394

Epoch: 5| Step: 2
Training loss: 3.332402449007821
Validation loss: 3.0528785660438573

Epoch: 5| Step: 3
Training loss: 3.6636518886812905
Validation loss: 3.0534975266344335

Epoch: 5| Step: 4
Training loss: 3.6135512462469563
Validation loss: 3.0534958424462237

Epoch: 5| Step: 5
Training loss: 2.572243101677444
Validation loss: 3.0508425660481637

Epoch: 5| Step: 6
Training loss: 2.8646869617560276
Validation loss: 3.0519166927727985

Epoch: 5| Step: 7
Training loss: 4.197854293221033
Validation loss: 3.052152934770498

Epoch: 5| Step: 8
Training loss: 3.6759283541068055
Validation loss: 3.052315219591787

Epoch: 5| Step: 9
Training loss: 2.9648530781514983
Validation loss: 3.0515989239551637

Epoch: 5| Step: 10
Training loss: 2.7413988854175355
Validation loss: 3.0519521493902397

Epoch: 55| Step: 0
Training loss: 2.8061992853080704
Validation loss: 3.052766378200041

Epoch: 5| Step: 1
Training loss: 2.845900508447105
Validation loss: 3.0550933854418174

Epoch: 5| Step: 2
Training loss: 4.401357545370235
Validation loss: 3.058773434622529

Epoch: 5| Step: 3
Training loss: 3.780341299281097
Validation loss: 3.05318258911369

Epoch: 5| Step: 4
Training loss: 2.8454923217862893
Validation loss: 3.0496674342730565

Epoch: 5| Step: 5
Training loss: 2.646949372490865
Validation loss: 3.049948435387341

Epoch: 5| Step: 6
Training loss: 3.414960450687642
Validation loss: 3.0480827182404804

Epoch: 5| Step: 7
Training loss: 2.842850092093877
Validation loss: 3.049123330274952

Epoch: 5| Step: 8
Training loss: 3.1191672250548614
Validation loss: 3.049419176167636

Epoch: 5| Step: 9
Training loss: 3.75933692766985
Validation loss: 3.0511309739293586

Epoch: 5| Step: 10
Training loss: 3.8898481336432167
Validation loss: 3.0499202683556006

Epoch: 56| Step: 0
Training loss: 3.9872471648511185
Validation loss: 3.0500066481097043

Epoch: 5| Step: 1
Training loss: 3.155113242122646
Validation loss: 3.0478270384030908

Epoch: 5| Step: 2
Training loss: 3.3248551473400245
Validation loss: 3.0484153957630116

Epoch: 5| Step: 3
Training loss: 3.0495140188795284
Validation loss: 3.0479489789850382

Epoch: 5| Step: 4
Training loss: 3.6626236618048402
Validation loss: 3.04486351875767

Epoch: 5| Step: 5
Training loss: 3.471888316735825
Validation loss: 3.0463488490249366

Epoch: 5| Step: 6
Training loss: 3.2107723592722057
Validation loss: 3.045752739294897

Epoch: 5| Step: 7
Training loss: 2.7766434313689974
Validation loss: 3.0483905667208577

Epoch: 5| Step: 8
Training loss: 3.3872976545309132
Validation loss: 3.0493509695752286

Epoch: 5| Step: 9
Training loss: 3.6684408808230438
Validation loss: 3.0528414994582826

Epoch: 5| Step: 10
Training loss: 2.7340527153821084
Validation loss: 3.054394027703168

Epoch: 57| Step: 0
Training loss: 2.702128496775447
Validation loss: 3.067209284069629

Epoch: 5| Step: 1
Training loss: 3.1000596256059354
Validation loss: 3.0731245623731964

Epoch: 5| Step: 2
Training loss: 3.3544294992777832
Validation loss: 3.059234351312656

Epoch: 5| Step: 3
Training loss: 2.859820555279376
Validation loss: 3.0474519791746046

Epoch: 5| Step: 4
Training loss: 3.28337304596355
Validation loss: 3.0446039150228694

Epoch: 5| Step: 5
Training loss: 3.601610957086572
Validation loss: 3.0450047257917796

Epoch: 5| Step: 6
Training loss: 3.876085929067698
Validation loss: 3.0469690721165494

Epoch: 5| Step: 7
Training loss: 3.7931463826598684
Validation loss: 3.0473047963537296

Epoch: 5| Step: 8
Training loss: 3.865349103353525
Validation loss: 3.0434075418187865

Epoch: 5| Step: 9
Training loss: 3.3097119384070837
Validation loss: 3.0427599231879743

Epoch: 5| Step: 10
Training loss: 2.5721190808377283
Validation loss: 3.044165313336742

Epoch: 58| Step: 0
Training loss: 3.6156270098866092
Validation loss: 3.042751924964929

Epoch: 5| Step: 1
Training loss: 3.4669517461006056
Validation loss: 3.047982219215159

Epoch: 5| Step: 2
Training loss: 3.5723074049719847
Validation loss: 3.045823903363303

Epoch: 5| Step: 3
Training loss: 3.012478308381934
Validation loss: 3.048787585140424

Epoch: 5| Step: 4
Training loss: 2.744291710003422
Validation loss: 3.056811573173475

Epoch: 5| Step: 5
Training loss: 3.967809610767609
Validation loss: 3.0671620313513843

Epoch: 5| Step: 6
Training loss: 3.440498015704897
Validation loss: 3.043489046506981

Epoch: 5| Step: 7
Training loss: 3.0307212447076948
Validation loss: 3.038613122706229

Epoch: 5| Step: 8
Training loss: 3.3646481313853114
Validation loss: 3.040469332759182

Epoch: 5| Step: 9
Training loss: 3.2452049094278785
Validation loss: 3.041085296531826

Epoch: 5| Step: 10
Training loss: 3.0074732205157106
Validation loss: 3.0412964409418723

Epoch: 59| Step: 0
Training loss: 2.896264755349734
Validation loss: 3.0428403162523145

Epoch: 5| Step: 1
Training loss: 3.376423853296469
Validation loss: 3.044456750296324

Epoch: 5| Step: 2
Training loss: 3.0173565730763268
Validation loss: 3.042510523425882

Epoch: 5| Step: 3
Training loss: 3.188791499568789
Validation loss: 3.043514174973208

Epoch: 5| Step: 4
Training loss: 2.7211764677641503
Validation loss: 3.0417819738059615

Epoch: 5| Step: 5
Training loss: 3.7025775746236507
Validation loss: 3.042289994230326

Epoch: 5| Step: 6
Training loss: 3.79035760827986
Validation loss: 3.0389069573456275

Epoch: 5| Step: 7
Training loss: 3.4881195338441677
Validation loss: 3.038397593342132

Epoch: 5| Step: 8
Training loss: 3.7158879398001687
Validation loss: 3.0388167179854633

Epoch: 5| Step: 9
Training loss: 3.3348614210078744
Validation loss: 3.0396722091864237

Epoch: 5| Step: 10
Training loss: 3.250693760698212
Validation loss: 3.037308050670747

Epoch: 60| Step: 0
Training loss: 3.338968298319134
Validation loss: 3.040066936546136

Epoch: 5| Step: 1
Training loss: 3.102359390699682
Validation loss: 3.0389183730027725

Epoch: 5| Step: 2
Training loss: 3.4952504765989287
Validation loss: 3.03434381562847

Epoch: 5| Step: 3
Training loss: 2.9396648140655723
Validation loss: 3.0329376696813193

Epoch: 5| Step: 4
Training loss: 3.659026306374715
Validation loss: 3.0330978223246894

Epoch: 5| Step: 5
Training loss: 3.2857526131284103
Validation loss: 3.035483754981118

Epoch: 5| Step: 6
Training loss: 3.298945929059597
Validation loss: 3.0373297865751465

Epoch: 5| Step: 7
Training loss: 3.432046344115169
Validation loss: 3.037202572099086

Epoch: 5| Step: 8
Training loss: 2.5055290117382616
Validation loss: 3.0360925658491804

Epoch: 5| Step: 9
Training loss: 4.554688128149078
Validation loss: 3.039362101933247

Epoch: 5| Step: 10
Training loss: 2.310036042497857
Validation loss: 3.0368701562180864

Epoch: 61| Step: 0
Training loss: 3.1301657133750087
Validation loss: 3.036780301225227

Epoch: 5| Step: 1
Training loss: 3.4049240471299256
Validation loss: 3.034593759855214

Epoch: 5| Step: 2
Training loss: 3.372152610854971
Validation loss: 3.034607896792762

Epoch: 5| Step: 3
Training loss: 3.521650652099053
Validation loss: 3.0349990348532594

Epoch: 5| Step: 4
Training loss: 3.5299088623558097
Validation loss: 3.0363182303328666

Epoch: 5| Step: 5
Training loss: 2.988944504877075
Validation loss: 3.0324795065447745

Epoch: 5| Step: 6
Training loss: 2.893695911536384
Validation loss: 3.029146992986162

Epoch: 5| Step: 7
Training loss: 2.519523679736689
Validation loss: 3.028334006347704

Epoch: 5| Step: 8
Training loss: 3.6135648379000367
Validation loss: 3.0256546250522067

Epoch: 5| Step: 9
Training loss: 3.769342384152993
Validation loss: 3.0272888309870725

Epoch: 5| Step: 10
Training loss: 3.61620302583188
Validation loss: 3.0230682580864103

Epoch: 62| Step: 0
Training loss: 2.467014233700034
Validation loss: 3.024200611940291

Epoch: 5| Step: 1
Training loss: 3.5590292102014818
Validation loss: 3.0234166868230674

Epoch: 5| Step: 2
Training loss: 3.442679231475468
Validation loss: 3.018874129169546

Epoch: 5| Step: 3
Training loss: 3.112154690994442
Validation loss: 3.0231565261333295

Epoch: 5| Step: 4
Training loss: 3.930597340272211
Validation loss: 3.0203184312034423

Epoch: 5| Step: 5
Training loss: 3.2971946235950735
Validation loss: 3.0253205327105883

Epoch: 5| Step: 6
Training loss: 2.8004858481007537
Validation loss: 3.0268124015439204

Epoch: 5| Step: 7
Training loss: 3.413777424587969
Validation loss: 3.0255801887307747

Epoch: 5| Step: 8
Training loss: 3.5648060077890555
Validation loss: 3.0229700652513576

Epoch: 5| Step: 9
Training loss: 3.2600360847301486
Validation loss: 3.0210029517655808

Epoch: 5| Step: 10
Training loss: 3.4321736077634717
Validation loss: 3.0158111431504375

Epoch: 63| Step: 0
Training loss: 3.294724183180939
Validation loss: 3.0173056049624853

Epoch: 5| Step: 1
Training loss: 3.535580570615451
Validation loss: 3.0170736827153

Epoch: 5| Step: 2
Training loss: 3.6185915633916084
Validation loss: 3.023993214633862

Epoch: 5| Step: 3
Training loss: 3.4594636624905144
Validation loss: 3.029590041811698

Epoch: 5| Step: 4
Training loss: 2.897939798649917
Validation loss: 3.0297353521093005

Epoch: 5| Step: 5
Training loss: 2.7983237835022687
Validation loss: 3.035602188350118

Epoch: 5| Step: 6
Training loss: 3.3579427815436484
Validation loss: 3.023057362628079

Epoch: 5| Step: 7
Training loss: 3.095811869639715
Validation loss: 3.021305417070858

Epoch: 5| Step: 8
Training loss: 3.174341004233355
Validation loss: 3.0188782461087738

Epoch: 5| Step: 9
Training loss: 3.3782382547341907
Validation loss: 3.017221359719145

Epoch: 5| Step: 10
Training loss: 3.699761001497351
Validation loss: 3.0193426004845754

Epoch: 64| Step: 0
Training loss: 3.8394069791887473
Validation loss: 3.0137618490361926

Epoch: 5| Step: 1
Training loss: 3.3760755732425656
Validation loss: 3.0119717616455577

Epoch: 5| Step: 2
Training loss: 3.5640013358801874
Validation loss: 3.0170428703384076

Epoch: 5| Step: 3
Training loss: 2.644602381596217
Validation loss: 3.0116125582091406

Epoch: 5| Step: 4
Training loss: 3.1599021403937866
Validation loss: 3.013755652933607

Epoch: 5| Step: 5
Training loss: 2.714963622156844
Validation loss: 3.0118963198460316

Epoch: 5| Step: 6
Training loss: 3.396489148303863
Validation loss: 3.010272394785252

Epoch: 5| Step: 7
Training loss: 3.2471048224199976
Validation loss: 3.0137855819307235

Epoch: 5| Step: 8
Training loss: 3.108438475384228
Validation loss: 3.0153921756749256

Epoch: 5| Step: 9
Training loss: 2.961925331745789
Validation loss: 3.0158039039737057

Epoch: 5| Step: 10
Training loss: 4.186590067371287
Validation loss: 3.016825030891753

Epoch: 65| Step: 0
Training loss: 3.739897662511905
Validation loss: 3.018944308288575

Epoch: 5| Step: 1
Training loss: 3.1541629349465174
Validation loss: 3.015300429135552

Epoch: 5| Step: 2
Training loss: 2.792081934849747
Validation loss: 3.017410036502857

Epoch: 5| Step: 3
Training loss: 3.179575025364073
Validation loss: 3.0195685013457814

Epoch: 5| Step: 4
Training loss: 3.1731086924992127
Validation loss: 3.02480547286365

Epoch: 5| Step: 5
Training loss: 2.5697312089055053
Validation loss: 3.0228596941492447

Epoch: 5| Step: 6
Training loss: 3.31672729807375
Validation loss: 3.0206808157082428

Epoch: 5| Step: 7
Training loss: 3.6316757556602557
Validation loss: 3.0222082000154185

Epoch: 5| Step: 8
Training loss: 3.936802635805627
Validation loss: 3.015996725703129

Epoch: 5| Step: 9
Training loss: 3.028001755606824
Validation loss: 3.0132652799927717

Epoch: 5| Step: 10
Training loss: 3.545391427881002
Validation loss: 3.0121091154450554

Epoch: 66| Step: 0
Training loss: 3.425965255267171
Validation loss: 3.010973579973084

Epoch: 5| Step: 1
Training loss: 3.0791701657933928
Validation loss: 3.0113842710619187

Epoch: 5| Step: 2
Training loss: 3.4764305518324203
Validation loss: 3.010790313776388

Epoch: 5| Step: 3
Training loss: 3.7025117648064634
Validation loss: 3.012118213812994

Epoch: 5| Step: 4
Training loss: 3.2347376523364857
Validation loss: 3.010633256809672

Epoch: 5| Step: 5
Training loss: 2.692460029609978
Validation loss: 3.011774102742112

Epoch: 5| Step: 6
Training loss: 3.199312201731483
Validation loss: 3.0080116013236324

Epoch: 5| Step: 7
Training loss: 2.636545585314922
Validation loss: 3.010706082069758

Epoch: 5| Step: 8
Training loss: 3.7702800422090252
Validation loss: 3.010204505420244

Epoch: 5| Step: 9
Training loss: 3.518145797649044
Validation loss: 3.0097067097589374

Epoch: 5| Step: 10
Training loss: 3.2958670426745496
Validation loss: 3.0108948912599764

Epoch: 67| Step: 0
Training loss: 3.3461081487366773
Validation loss: 3.011360049312005

Epoch: 5| Step: 1
Training loss: 3.3966790922746877
Validation loss: 3.008081780748958

Epoch: 5| Step: 2
Training loss: 3.4612108385289098
Validation loss: 3.009769538048021

Epoch: 5| Step: 3
Training loss: 2.7577679768283216
Validation loss: 3.009445364720486

Epoch: 5| Step: 4
Training loss: 2.697563138404948
Validation loss: 3.0098654529814395

Epoch: 5| Step: 5
Training loss: 3.301056727363671
Validation loss: 3.010282513845204

Epoch: 5| Step: 6
Training loss: 3.3582462277407914
Validation loss: 3.0075213002224856

Epoch: 5| Step: 7
Training loss: 3.3673094264921177
Validation loss: 3.007217920796631

Epoch: 5| Step: 8
Training loss: 3.263769763549201
Validation loss: 3.0079454805712946

Epoch: 5| Step: 9
Training loss: 3.6070377329139545
Validation loss: 3.005956845788497

Epoch: 5| Step: 10
Training loss: 3.5455323757618804
Validation loss: 3.007843180216163

Epoch: 68| Step: 0
Training loss: 3.5128337715101474
Validation loss: 3.0110272146316306

Epoch: 5| Step: 1
Training loss: 3.5865129661479904
Validation loss: 3.007089649838497

Epoch: 5| Step: 2
Training loss: 3.4837614468652345
Validation loss: 3.007949349111279

Epoch: 5| Step: 3
Training loss: 3.230739153208476
Validation loss: 3.0116999634764268

Epoch: 5| Step: 4
Training loss: 3.415087792537302
Validation loss: 3.005643412631293

Epoch: 5| Step: 5
Training loss: 3.5750327262180797
Validation loss: 3.005276462950441

Epoch: 5| Step: 6
Training loss: 2.2283047468491204
Validation loss: 3.003615852781784

Epoch: 5| Step: 7
Training loss: 3.2552206217215973
Validation loss: 3.0057896392212062

Epoch: 5| Step: 8
Training loss: 3.2732036934979187
Validation loss: 3.0049432376804077

Epoch: 5| Step: 9
Training loss: 3.4199246635839575
Validation loss: 3.007653714055811

Epoch: 5| Step: 10
Training loss: 2.890114899037523
Validation loss: 3.00371092210302

Epoch: 69| Step: 0
Training loss: 3.0299972619777686
Validation loss: 3.0037571050066334

Epoch: 5| Step: 1
Training loss: 3.275699243808667
Validation loss: 3.003269087603802

Epoch: 5| Step: 2
Training loss: 2.7316457151858944
Validation loss: 3.0031602153570276

Epoch: 5| Step: 3
Training loss: 3.214748524846528
Validation loss: 3.0066184746668303

Epoch: 5| Step: 4
Training loss: 3.457663750842699
Validation loss: 3.0128485384263746

Epoch: 5| Step: 5
Training loss: 3.755626018572914
Validation loss: 3.0116823821805214

Epoch: 5| Step: 6
Training loss: 3.75675990853501
Validation loss: 3.0078018595274627

Epoch: 5| Step: 7
Training loss: 3.5959048237919227
Validation loss: 3.0010690442148635

Epoch: 5| Step: 8
Training loss: 2.488184760841375
Validation loss: 3.0025103535813944

Epoch: 5| Step: 9
Training loss: 3.148980105761536
Validation loss: 3.0029395709211535

Epoch: 5| Step: 10
Training loss: 3.525479894126007
Validation loss: 3.003568210728043

Epoch: 70| Step: 0
Training loss: 4.055249596003762
Validation loss: 3.0006420929288904

Epoch: 5| Step: 1
Training loss: 2.6681562276850417
Validation loss: 3.0014493835333234

Epoch: 5| Step: 2
Training loss: 3.660578065258353
Validation loss: 2.999082083060281

Epoch: 5| Step: 3
Training loss: 2.6171496032704047
Validation loss: 2.9998872250378392

Epoch: 5| Step: 4
Training loss: 3.0426684954964003
Validation loss: 3.000744959583734

Epoch: 5| Step: 5
Training loss: 3.4961592172641303
Validation loss: 2.9986289456539237

Epoch: 5| Step: 6
Training loss: 3.5834927338624563
Validation loss: 2.997701531787871

Epoch: 5| Step: 7
Training loss: 3.472808525600131
Validation loss: 2.9964465576265558

Epoch: 5| Step: 8
Training loss: 3.1963157664348127
Validation loss: 2.9974744037417707

Epoch: 5| Step: 9
Training loss: 3.319211817791933
Validation loss: 3.002504636314169

Epoch: 5| Step: 10
Training loss: 2.5340622714850873
Validation loss: 3.0110928122137186

Epoch: 71| Step: 0
Training loss: 3.4666957786755974
Validation loss: 3.0049552515896254

Epoch: 5| Step: 1
Training loss: 3.238064490634461
Validation loss: 2.9967405693236167

Epoch: 5| Step: 2
Training loss: 3.8785909196082384
Validation loss: 2.990936273864438

Epoch: 5| Step: 3
Training loss: 2.992398804855363
Validation loss: 2.989700638082276

Epoch: 5| Step: 4
Training loss: 3.016945821445684
Validation loss: 2.9891111133798423

Epoch: 5| Step: 5
Training loss: 3.071583569693384
Validation loss: 2.987462450868351

Epoch: 5| Step: 6
Training loss: 2.5287916702555697
Validation loss: 2.984120091828319

Epoch: 5| Step: 7
Training loss: 2.912988541522605
Validation loss: 2.9862466750041907

Epoch: 5| Step: 8
Training loss: 3.7172585710271098
Validation loss: 2.986242301890922

Epoch: 5| Step: 9
Training loss: 3.7880145639302722
Validation loss: 2.9858820732391123

Epoch: 5| Step: 10
Training loss: 3.0400953719588255
Validation loss: 2.9841747469087525

Epoch: 72| Step: 0
Training loss: 3.572988229522407
Validation loss: 2.980008324306391

Epoch: 5| Step: 1
Training loss: 3.2489607689984825
Validation loss: 2.9791269303303647

Epoch: 5| Step: 2
Training loss: 3.4133137944774887
Validation loss: 2.979915681067146

Epoch: 5| Step: 3
Training loss: 3.1169442677072627
Validation loss: 2.976533476593532

Epoch: 5| Step: 4
Training loss: 3.7661814931367297
Validation loss: 2.9779064187132316

Epoch: 5| Step: 5
Training loss: 2.4530438452253356
Validation loss: 2.9776109390597765

Epoch: 5| Step: 6
Training loss: 3.5854553031428185
Validation loss: 2.9821258661703016

Epoch: 5| Step: 7
Training loss: 3.1613320708264947
Validation loss: 2.982419014304738

Epoch: 5| Step: 8
Training loss: 3.741474633220206
Validation loss: 2.9807498051954853

Epoch: 5| Step: 9
Training loss: 2.7916098536693412
Validation loss: 2.9769293584024434

Epoch: 5| Step: 10
Training loss: 2.6715244710216632
Validation loss: 2.9789486842684147

Epoch: 73| Step: 0
Training loss: 4.082366257933751
Validation loss: 2.979872276570791

Epoch: 5| Step: 1
Training loss: 3.2893351897146954
Validation loss: 2.9714500398333894

Epoch: 5| Step: 2
Training loss: 2.509236059463481
Validation loss: 2.9751865336412133

Epoch: 5| Step: 3
Training loss: 3.7510537256528833
Validation loss: 2.975170616758034

Epoch: 5| Step: 4
Training loss: 2.6786663456402833
Validation loss: 2.974394424061628

Epoch: 5| Step: 5
Training loss: 3.156399260664691
Validation loss: 2.97764113148446

Epoch: 5| Step: 6
Training loss: 3.277273475157244
Validation loss: 2.9744713720770983

Epoch: 5| Step: 7
Training loss: 3.172702474663645
Validation loss: 2.971579116759076

Epoch: 5| Step: 8
Training loss: 3.373826847338967
Validation loss: 2.9707120550452815

Epoch: 5| Step: 9
Training loss: 2.6496606213600695
Validation loss: 2.9680904897215736

Epoch: 5| Step: 10
Training loss: 3.6875969825534494
Validation loss: 2.971907034916823

Epoch: 74| Step: 0
Training loss: 2.997753096610003
Validation loss: 2.9760258459214177

Epoch: 5| Step: 1
Training loss: 3.0050684710681894
Validation loss: 2.979813454261882

Epoch: 5| Step: 2
Training loss: 3.084728612601653
Validation loss: 2.983503751710397

Epoch: 5| Step: 3
Training loss: 3.567547217673452
Validation loss: 2.9760097457342667

Epoch: 5| Step: 4
Training loss: 3.529678670290389
Validation loss: 2.9700991023557517

Epoch: 5| Step: 5
Training loss: 3.517168986044259
Validation loss: 2.969098622567332

Epoch: 5| Step: 6
Training loss: 2.4352760929189685
Validation loss: 2.967122670014335

Epoch: 5| Step: 7
Training loss: 3.614355836831008
Validation loss: 2.970934325820323

Epoch: 5| Step: 8
Training loss: 3.6704618291248448
Validation loss: 2.974463151443879

Epoch: 5| Step: 9
Training loss: 3.114232242320159
Validation loss: 2.9700641497595055

Epoch: 5| Step: 10
Training loss: 3.1197503819013366
Validation loss: 2.9683542001775263

Epoch: 75| Step: 0
Training loss: 3.6883337080573644
Validation loss: 2.9646939802092223

Epoch: 5| Step: 1
Training loss: 3.8029238394554694
Validation loss: 2.9664547262315626

Epoch: 5| Step: 2
Training loss: 3.513220206169977
Validation loss: 2.967711476323054

Epoch: 5| Step: 3
Training loss: 3.5724103177708497
Validation loss: 2.96727477953928

Epoch: 5| Step: 4
Training loss: 3.3617109826539218
Validation loss: 2.964821636595166

Epoch: 5| Step: 5
Training loss: 2.5249208041320172
Validation loss: 2.964164829413814

Epoch: 5| Step: 6
Training loss: 2.820409038719547
Validation loss: 2.9654566806676486

Epoch: 5| Step: 7
Training loss: 2.543321060644348
Validation loss: 2.9640600830661943

Epoch: 5| Step: 8
Training loss: 3.243638341374733
Validation loss: 2.9707656451087296

Epoch: 5| Step: 9
Training loss: 2.8774228046048362
Validation loss: 2.972175301701639

Epoch: 5| Step: 10
Training loss: 3.5891517744308197
Validation loss: 2.972331113267448

Epoch: 76| Step: 0
Training loss: 3.203929967450619
Validation loss: 2.9660285829226947

Epoch: 5| Step: 1
Training loss: 3.0844865309195026
Validation loss: 2.966166432418168

Epoch: 5| Step: 2
Training loss: 3.3388154884122634
Validation loss: 2.962772123203825

Epoch: 5| Step: 3
Training loss: 2.200662088468948
Validation loss: 2.9625584265809137

Epoch: 5| Step: 4
Training loss: 3.8711932772901845
Validation loss: 2.9616400265981926

Epoch: 5| Step: 5
Training loss: 3.212994512948065
Validation loss: 2.9622325848002373

Epoch: 5| Step: 6
Training loss: 3.3536595184257068
Validation loss: 2.9621356225479984

Epoch: 5| Step: 7
Training loss: 3.183000418013133
Validation loss: 2.96100732068033

Epoch: 5| Step: 8
Training loss: 3.497319148461617
Validation loss: 2.960901592471013

Epoch: 5| Step: 9
Training loss: 3.114224127189255
Validation loss: 2.9598919166890862

Epoch: 5| Step: 10
Training loss: 3.4699820315200864
Validation loss: 2.965492865870452

Epoch: 77| Step: 0
Training loss: 3.4829887061471267
Validation loss: 2.971787452876883

Epoch: 5| Step: 1
Training loss: 3.0896039211404376
Validation loss: 2.974071992660786

Epoch: 5| Step: 2
Training loss: 3.5953380227374585
Validation loss: 2.971448834560998

Epoch: 5| Step: 3
Training loss: 3.016911997926831
Validation loss: 2.960706667563642

Epoch: 5| Step: 4
Training loss: 2.954687603285297
Validation loss: 2.961533332408772

Epoch: 5| Step: 5
Training loss: 3.696048203637014
Validation loss: 2.9599983339989566

Epoch: 5| Step: 6
Training loss: 3.356135736150696
Validation loss: 2.960598757757716

Epoch: 5| Step: 7
Training loss: 3.229224633137529
Validation loss: 2.96065053583624

Epoch: 5| Step: 8
Training loss: 3.330049343488159
Validation loss: 2.9614502975774233

Epoch: 5| Step: 9
Training loss: 3.0622992936364257
Validation loss: 2.9615389002411123

Epoch: 5| Step: 10
Training loss: 2.7730897497378835
Validation loss: 2.9591604656839805

Epoch: 78| Step: 0
Training loss: 3.027282950498339
Validation loss: 2.9593940859771464

Epoch: 5| Step: 1
Training loss: 3.076043834140805
Validation loss: 2.9596870481778117

Epoch: 5| Step: 2
Training loss: 3.3693612642880355
Validation loss: 2.9588577958748834

Epoch: 5| Step: 3
Training loss: 2.744766630942857
Validation loss: 2.96041866610507

Epoch: 5| Step: 4
Training loss: 2.845511760574085
Validation loss: 2.960955372214557

Epoch: 5| Step: 5
Training loss: 3.088972004870714
Validation loss: 2.9630176850796586

Epoch: 5| Step: 6
Training loss: 2.950533421021849
Validation loss: 2.9609485677638405

Epoch: 5| Step: 7
Training loss: 4.475274078670895
Validation loss: 2.962862367536019

Epoch: 5| Step: 8
Training loss: 3.4304244307676446
Validation loss: 2.9625049095862535

Epoch: 5| Step: 9
Training loss: 3.6582376668901126
Validation loss: 2.9596816882115857

Epoch: 5| Step: 10
Training loss: 2.4525276963345064
Validation loss: 2.95885803327646

Epoch: 79| Step: 0
Training loss: 3.5882001399651333
Validation loss: 2.9628264418022816

Epoch: 5| Step: 1
Training loss: 2.774077693497525
Validation loss: 2.962770529349447

Epoch: 5| Step: 2
Training loss: 3.2929806239591675
Validation loss: 2.97000380908209

Epoch: 5| Step: 3
Training loss: 3.4025304241628045
Validation loss: 2.9809693391990337

Epoch: 5| Step: 4
Training loss: 3.55218860697685
Validation loss: 2.9772251114995703

Epoch: 5| Step: 5
Training loss: 2.905532584293054
Validation loss: 2.9604164596067633

Epoch: 5| Step: 6
Training loss: 3.6957163680762357
Validation loss: 2.9555151102908233

Epoch: 5| Step: 7
Training loss: 3.0459842260081276
Validation loss: 2.956733488244413

Epoch: 5| Step: 8
Training loss: 2.8664187198429016
Validation loss: 2.9553994216779333

Epoch: 5| Step: 9
Training loss: 3.322275097814978
Validation loss: 2.9578842025511416

Epoch: 5| Step: 10
Training loss: 3.064022697723221
Validation loss: 2.9586525464204567

Epoch: 80| Step: 0
Training loss: 3.0724298296272607
Validation loss: 2.958764486915938

Epoch: 5| Step: 1
Training loss: 3.3580291181145925
Validation loss: 2.9566125242620376

Epoch: 5| Step: 2
Training loss: 3.5373551248060604
Validation loss: 2.9562157402489353

Epoch: 5| Step: 3
Training loss: 3.201658927541418
Validation loss: 2.954820829983019

Epoch: 5| Step: 4
Training loss: 3.1108934538255544
Validation loss: 2.955583118717088

Epoch: 5| Step: 5
Training loss: 3.40605022999522
Validation loss: 2.9599801199588267

Epoch: 5| Step: 6
Training loss: 3.0352608798929936
Validation loss: 2.9666086294459415

Epoch: 5| Step: 7
Training loss: 2.821642448500117
Validation loss: 2.9798837893369527

Epoch: 5| Step: 8
Training loss: 3.4748625638939536
Validation loss: 2.990271000241874

Epoch: 5| Step: 9
Training loss: 3.470366230307824
Validation loss: 2.9987884283123583

Epoch: 5| Step: 10
Training loss: 3.262823920411261
Validation loss: 2.957222825573316

Epoch: 81| Step: 0
Training loss: 3.2453937165883873
Validation loss: 2.952982503067469

Epoch: 5| Step: 1
Training loss: 3.6589283058918016
Validation loss: 2.9536215230248613

Epoch: 5| Step: 2
Training loss: 2.572558780958763
Validation loss: 2.9593110734191894

Epoch: 5| Step: 3
Training loss: 3.0128311101890444
Validation loss: 2.965404277604466

Epoch: 5| Step: 4
Training loss: 3.972691178519938
Validation loss: 2.9681347928983755

Epoch: 5| Step: 5
Training loss: 2.941904702070074
Validation loss: 2.9606115404359716

Epoch: 5| Step: 6
Training loss: 3.160556536810485
Validation loss: 2.9642515632893525

Epoch: 5| Step: 7
Training loss: 2.9655841209560716
Validation loss: 2.9557979640603884

Epoch: 5| Step: 8
Training loss: 3.1766513885205367
Validation loss: 2.956888613587238

Epoch: 5| Step: 9
Training loss: 3.509709921911199
Validation loss: 2.954933179378127

Epoch: 5| Step: 10
Training loss: 3.335221582283505
Validation loss: 2.956832761390076

Epoch: 82| Step: 0
Training loss: 3.851886356503521
Validation loss: 2.9562935837461835

Epoch: 5| Step: 1
Training loss: 3.36803169023551
Validation loss: 2.9537655704853356

Epoch: 5| Step: 2
Training loss: 3.483259082227927
Validation loss: 2.9561873496044377

Epoch: 5| Step: 3
Training loss: 3.340555394074666
Validation loss: 2.955287783988404

Epoch: 5| Step: 4
Training loss: 3.3090292543770663
Validation loss: 2.957988501115201

Epoch: 5| Step: 5
Training loss: 3.4118112784334946
Validation loss: 2.9538279422345877

Epoch: 5| Step: 6
Training loss: 3.1362016947657345
Validation loss: 2.9510256820096434

Epoch: 5| Step: 7
Training loss: 3.461410317942696
Validation loss: 2.950619448681937

Epoch: 5| Step: 8
Training loss: 2.948395671052489
Validation loss: 2.950625362926258

Epoch: 5| Step: 9
Training loss: 2.1957097355937
Validation loss: 2.949983468347457

Epoch: 5| Step: 10
Training loss: 2.828157034845328
Validation loss: 2.948978511264453

Epoch: 83| Step: 0
Training loss: 2.821733703117393
Validation loss: 2.9483638166162076

Epoch: 5| Step: 1
Training loss: 3.2301649621936335
Validation loss: 2.9492970606775555

Epoch: 5| Step: 2
Training loss: 3.034377068028791
Validation loss: 2.9480423479643796

Epoch: 5| Step: 3
Training loss: 2.8211093104569045
Validation loss: 2.949134133188601

Epoch: 5| Step: 4
Training loss: 3.1243340354839146
Validation loss: 2.9490439068892145

Epoch: 5| Step: 5
Training loss: 3.610806532184494
Validation loss: 2.9485310461763543

Epoch: 5| Step: 6
Training loss: 3.9998042535569738
Validation loss: 2.95087921071978

Epoch: 5| Step: 7
Training loss: 3.0185478948382807
Validation loss: 2.948601720553527

Epoch: 5| Step: 8
Training loss: 3.670332954125637
Validation loss: 2.950655973968746

Epoch: 5| Step: 9
Training loss: 2.8704283481699275
Validation loss: 2.9496091327169034

Epoch: 5| Step: 10
Training loss: 3.1686162134101603
Validation loss: 2.951995030957398

Epoch: 84| Step: 0
Training loss: 3.671580201347474
Validation loss: 2.951132547601567

Epoch: 5| Step: 1
Training loss: 2.8087108094248907
Validation loss: 2.952039737217255

Epoch: 5| Step: 2
Training loss: 3.214448146651647
Validation loss: 2.9506900191707794

Epoch: 5| Step: 3
Training loss: 3.161386370690878
Validation loss: 2.949234557467662

Epoch: 5| Step: 4
Training loss: 3.317503694763656
Validation loss: 2.9579924098564363

Epoch: 5| Step: 5
Training loss: 3.2747537884363047
Validation loss: 2.9438747024536713

Epoch: 5| Step: 6
Training loss: 2.886362593260831
Validation loss: 2.942923123187922

Epoch: 5| Step: 7
Training loss: 3.527070940014328
Validation loss: 2.9436562356985654

Epoch: 5| Step: 8
Training loss: 3.1407918553604808
Validation loss: 2.9435719345124114

Epoch: 5| Step: 9
Training loss: 3.461810619708079
Validation loss: 2.9441876270093785

Epoch: 5| Step: 10
Training loss: 2.988601806999926
Validation loss: 2.945019582487652

Epoch: 85| Step: 0
Training loss: 3.24629322820825
Validation loss: 2.944231660323112

Epoch: 5| Step: 1
Training loss: 3.6277125502819465
Validation loss: 2.9450599264214525

Epoch: 5| Step: 2
Training loss: 2.9211712157921617
Validation loss: 2.9455733210019273

Epoch: 5| Step: 3
Training loss: 2.345038504863925
Validation loss: 2.944409619776359

Epoch: 5| Step: 4
Training loss: 3.9601917655828776
Validation loss: 2.944869250200846

Epoch: 5| Step: 5
Training loss: 2.564373355040277
Validation loss: 2.943964028270445

Epoch: 5| Step: 6
Training loss: 3.880564724046572
Validation loss: 2.945212479052301

Epoch: 5| Step: 7
Training loss: 3.0347714763245657
Validation loss: 2.9517137704227

Epoch: 5| Step: 8
Training loss: 3.206374887633064
Validation loss: 2.9594146338808724

Epoch: 5| Step: 9
Training loss: 3.132606100004149
Validation loss: 2.9477297978294517

Epoch: 5| Step: 10
Training loss: 3.330202555638992
Validation loss: 2.940939858725483

Epoch: 86| Step: 0
Training loss: 3.4650918727656475
Validation loss: 2.9394779933468507

Epoch: 5| Step: 1
Training loss: 2.5109933425590225
Validation loss: 2.940163641583237

Epoch: 5| Step: 2
Training loss: 3.3872741455010376
Validation loss: 2.940165352325249

Epoch: 5| Step: 3
Training loss: 3.3814976627940236
Validation loss: 2.940723922638517

Epoch: 5| Step: 4
Training loss: 3.380879120573477
Validation loss: 2.9426458246313065

Epoch: 5| Step: 5
Training loss: 3.443104977441314
Validation loss: 2.942054689153303

Epoch: 5| Step: 6
Training loss: 3.458975414434681
Validation loss: 2.9409638951020853

Epoch: 5| Step: 7
Training loss: 3.0887242349548085
Validation loss: 2.9382434620654023

Epoch: 5| Step: 8
Training loss: 2.9375350625400785
Validation loss: 2.9407024926622998

Epoch: 5| Step: 9
Training loss: 3.1827294048086148
Validation loss: 2.9395859938729303

Epoch: 5| Step: 10
Training loss: 3.1315936906915467
Validation loss: 2.9404016152439083

Epoch: 87| Step: 0
Training loss: 3.0710789934617493
Validation loss: 2.9415746795133058

Epoch: 5| Step: 1
Training loss: 3.096740202371107
Validation loss: 2.939294844911236

Epoch: 5| Step: 2
Training loss: 3.36490548464489
Validation loss: 2.9426191535146424

Epoch: 5| Step: 3
Training loss: 3.8052513127789287
Validation loss: 2.9379069479079796

Epoch: 5| Step: 4
Training loss: 3.1998417099903773
Validation loss: 2.9419737666856287

Epoch: 5| Step: 5
Training loss: 2.8556120245562138
Validation loss: 2.939431562785125

Epoch: 5| Step: 6
Training loss: 3.0323783111686278
Validation loss: 2.942393652080174

Epoch: 5| Step: 7
Training loss: 2.81366646207548
Validation loss: 2.9525904894702912

Epoch: 5| Step: 8
Training loss: 3.3978415481868005
Validation loss: 2.953008681237165

Epoch: 5| Step: 9
Training loss: 3.6493623202613708
Validation loss: 2.9419583498081985

Epoch: 5| Step: 10
Training loss: 3.0829731670725193
Validation loss: 2.936737479979776

Epoch: 88| Step: 0
Training loss: 3.672123547522142
Validation loss: 2.9373425982842885

Epoch: 5| Step: 1
Training loss: 3.5814113933419285
Validation loss: 2.933412356992554

Epoch: 5| Step: 2
Training loss: 3.202817427592042
Validation loss: 2.933948402393366

Epoch: 5| Step: 3
Training loss: 2.757630166572305
Validation loss: 2.9349729393515864

Epoch: 5| Step: 4
Training loss: 3.4730088491549505
Validation loss: 2.934633221509161

Epoch: 5| Step: 5
Training loss: 2.4400949603503843
Validation loss: 2.936673329283747

Epoch: 5| Step: 6
Training loss: 3.2635554276334635
Validation loss: 2.934128330215813

Epoch: 5| Step: 7
Training loss: 3.1380170175785067
Validation loss: 2.935677235363928

Epoch: 5| Step: 8
Training loss: 3.7388404101144364
Validation loss: 2.936915188230207

Epoch: 5| Step: 9
Training loss: 2.4474011358569117
Validation loss: 2.9364153627482126

Epoch: 5| Step: 10
Training loss: 3.4825968631546895
Validation loss: 2.9354325251352256

Epoch: 89| Step: 0
Training loss: 3.201609183064664
Validation loss: 2.935864307545367

Epoch: 5| Step: 1
Training loss: 2.6170997718797233
Validation loss: 2.933933763833712

Epoch: 5| Step: 2
Training loss: 3.181916376555578
Validation loss: 2.9336488928661084

Epoch: 5| Step: 3
Training loss: 3.346579237121397
Validation loss: 2.9324149857705257

Epoch: 5| Step: 4
Training loss: 3.405743342524349
Validation loss: 2.933704814176934

Epoch: 5| Step: 5
Training loss: 2.6861623051930588
Validation loss: 2.932228351873283

Epoch: 5| Step: 6
Training loss: 3.6850263412962687
Validation loss: 2.9321648736727113

Epoch: 5| Step: 7
Training loss: 3.482479246889648
Validation loss: 2.9319614533454024

Epoch: 5| Step: 8
Training loss: 3.5372471479759877
Validation loss: 2.9326728653600496

Epoch: 5| Step: 9
Training loss: 3.24674722311774
Validation loss: 2.9293389882173204

Epoch: 5| Step: 10
Training loss: 2.8570240132274356
Validation loss: 2.930953365179107

Epoch: 90| Step: 0
Training loss: 3.0168563621550644
Validation loss: 2.931743852973835

Epoch: 5| Step: 1
Training loss: 3.033236766857061
Validation loss: 2.932737776654637

Epoch: 5| Step: 2
Training loss: 2.5026810575033203
Validation loss: 2.936603245189715

Epoch: 5| Step: 3
Training loss: 3.536713011854744
Validation loss: 2.93675526377191

Epoch: 5| Step: 4
Training loss: 2.3281392346657426
Validation loss: 2.932464680767378

Epoch: 5| Step: 5
Training loss: 2.9297364904758054
Validation loss: 2.9308094316190236

Epoch: 5| Step: 6
Training loss: 2.790758402712566
Validation loss: 2.92806257090604

Epoch: 5| Step: 7
Training loss: 4.247846394335389
Validation loss: 2.930852739611807

Epoch: 5| Step: 8
Training loss: 3.553191354311502
Validation loss: 2.9311281372657563

Epoch: 5| Step: 9
Training loss: 3.6600319628544518
Validation loss: 2.927760558263125

Epoch: 5| Step: 10
Training loss: 3.378135778531674
Validation loss: 2.929340953826271

Epoch: 91| Step: 0
Training loss: 2.9114209185785414
Validation loss: 2.927895148553884

Epoch: 5| Step: 1
Training loss: 3.227114872606951
Validation loss: 2.9301714919996775

Epoch: 5| Step: 2
Training loss: 3.60486006635798
Validation loss: 2.9281337638315224

Epoch: 5| Step: 3
Training loss: 3.4694897661862183
Validation loss: 2.9291299155076422

Epoch: 5| Step: 4
Training loss: 3.168730581852331
Validation loss: 2.927997886928054

Epoch: 5| Step: 5
Training loss: 3.351258448611818
Validation loss: 2.9295963720006295

Epoch: 5| Step: 6
Training loss: 2.850271941478718
Validation loss: 2.9265522065341423

Epoch: 5| Step: 7
Training loss: 3.8041327540100167
Validation loss: 2.9296706201210627

Epoch: 5| Step: 8
Training loss: 3.096116211102446
Validation loss: 2.934481500979745

Epoch: 5| Step: 9
Training loss: 2.251329453086653
Validation loss: 2.93186533321838

Epoch: 5| Step: 10
Training loss: 3.4034150251347524
Validation loss: 2.928522027853764

Epoch: 92| Step: 0
Training loss: 3.0813748781228107
Validation loss: 2.9302721418359075

Epoch: 5| Step: 1
Training loss: 3.3032523571858547
Validation loss: 2.9315276496535025

Epoch: 5| Step: 2
Training loss: 2.7955110090295165
Validation loss: 2.925964846527471

Epoch: 5| Step: 3
Training loss: 3.236658294724527
Validation loss: 2.9267289705470465

Epoch: 5| Step: 4
Training loss: 3.524031155598986
Validation loss: 2.9246027152634033

Epoch: 5| Step: 5
Training loss: 3.9185575155048236
Validation loss: 2.9236325688709295

Epoch: 5| Step: 6
Training loss: 3.065585547765938
Validation loss: 2.926245764468893

Epoch: 5| Step: 7
Training loss: 2.99321328849203
Validation loss: 2.926569538013714

Epoch: 5| Step: 8
Training loss: 3.2560970629253236
Validation loss: 2.926885003812611

Epoch: 5| Step: 9
Training loss: 3.191828911013273
Validation loss: 2.9233218735493547

Epoch: 5| Step: 10
Training loss: 2.8309607014840683
Validation loss: 2.9239630058971917

Epoch: 93| Step: 0
Training loss: 3.0718884488157725
Validation loss: 2.9231561248873543

Epoch: 5| Step: 1
Training loss: 3.717290640029861
Validation loss: 2.923937545286238

Epoch: 5| Step: 2
Training loss: 2.7774183475224867
Validation loss: 2.9277523605854965

Epoch: 5| Step: 3
Training loss: 3.3635049672436717
Validation loss: 2.9237013583775178

Epoch: 5| Step: 4
Training loss: 1.8216250684944024
Validation loss: 2.9275175077754234

Epoch: 5| Step: 5
Training loss: 3.637307943930441
Validation loss: 2.9253946150142904

Epoch: 5| Step: 6
Training loss: 2.920852237337315
Validation loss: 2.92936217986847

Epoch: 5| Step: 7
Training loss: 2.717562975395057
Validation loss: 2.9320374182639806

Epoch: 5| Step: 8
Training loss: 4.007105476820914
Validation loss: 2.9295817957031205

Epoch: 5| Step: 9
Training loss: 3.512160022070447
Validation loss: 2.926092463063212

Epoch: 5| Step: 10
Training loss: 3.252070134437718
Validation loss: 2.930344337910588

Epoch: 94| Step: 0
Training loss: 3.404917325039838
Validation loss: 2.9234138276515598

Epoch: 5| Step: 1
Training loss: 3.215649046219464
Validation loss: 2.9254256399186507

Epoch: 5| Step: 2
Training loss: 2.4290230876002834
Validation loss: 2.9319110048367896

Epoch: 5| Step: 3
Training loss: 3.3505210414328803
Validation loss: 2.9321261796587437

Epoch: 5| Step: 4
Training loss: 2.768028637192166
Validation loss: 2.935016944078729

Epoch: 5| Step: 5
Training loss: 3.4403590017220558
Validation loss: 2.9267795075017706

Epoch: 5| Step: 6
Training loss: 3.137592274802121
Validation loss: 2.9327711207595564

Epoch: 5| Step: 7
Training loss: 4.056842797080583
Validation loss: 2.9334106746482265

Epoch: 5| Step: 8
Training loss: 3.023151551753667
Validation loss: 2.921259073474186

Epoch: 5| Step: 9
Training loss: 2.6106898484270733
Validation loss: 2.9208989167181936

Epoch: 5| Step: 10
Training loss: 3.6307948918847006
Validation loss: 2.9218268595321497

Epoch: 95| Step: 0
Training loss: 3.263267871042945
Validation loss: 2.920084162941989

Epoch: 5| Step: 1
Training loss: 3.0875264772831996
Validation loss: 2.9211365922311736

Epoch: 5| Step: 2
Training loss: 3.635908616381166
Validation loss: 2.9199119959229343

Epoch: 5| Step: 3
Training loss: 3.0570263896448235
Validation loss: 2.919203436167367

Epoch: 5| Step: 4
Training loss: 2.6554552572277372
Validation loss: 2.9217481451270575

Epoch: 5| Step: 5
Training loss: 3.7540817934209074
Validation loss: 2.920743860076775

Epoch: 5| Step: 6
Training loss: 3.327492523987452
Validation loss: 2.920450895887191

Epoch: 5| Step: 7
Training loss: 3.2088542036516663
Validation loss: 2.919411983343153

Epoch: 5| Step: 8
Training loss: 2.47786844279633
Validation loss: 2.919254772576834

Epoch: 5| Step: 9
Training loss: 3.530659043817656
Validation loss: 2.9177162204014375

Epoch: 5| Step: 10
Training loss: 3.1002726527259235
Validation loss: 2.918109386384935

Epoch: 96| Step: 0
Training loss: 3.6008184827095024
Validation loss: 2.916074742551351

Epoch: 5| Step: 1
Training loss: 3.194903284558183
Validation loss: 2.9200891487238803

Epoch: 5| Step: 2
Training loss: 3.20811557443625
Validation loss: 2.9173790256614915

Epoch: 5| Step: 3
Training loss: 2.699489552318848
Validation loss: 2.917822290415105

Epoch: 5| Step: 4
Training loss: 3.7943973699069575
Validation loss: 2.9234876110603247

Epoch: 5| Step: 5
Training loss: 3.7182818206223693
Validation loss: 2.9343229693168036

Epoch: 5| Step: 6
Training loss: 2.51110177300929
Validation loss: 2.926101594087386

Epoch: 5| Step: 7
Training loss: 3.4694111511842918
Validation loss: 2.9168456138410734

Epoch: 5| Step: 8
Training loss: 2.565014140813267
Validation loss: 2.916736644719905

Epoch: 5| Step: 9
Training loss: 3.511168779497807
Validation loss: 2.916603664883845

Epoch: 5| Step: 10
Training loss: 2.6160232003842645
Validation loss: 2.918644260729943

Epoch: 97| Step: 0
Training loss: 2.2922407876069957
Validation loss: 2.9151474073704926

Epoch: 5| Step: 1
Training loss: 3.162384417084048
Validation loss: 2.9148955304337907

Epoch: 5| Step: 2
Training loss: 3.549360706631724
Validation loss: 2.9177651254460484

Epoch: 5| Step: 3
Training loss: 2.9335336082175694
Validation loss: 2.9163471369182776

Epoch: 5| Step: 4
Training loss: 3.5565180833330787
Validation loss: 2.9189838202725706

Epoch: 5| Step: 5
Training loss: 3.08391850735154
Validation loss: 2.9190644816288014

Epoch: 5| Step: 6
Training loss: 3.59030092003597
Validation loss: 2.917374667068748

Epoch: 5| Step: 7
Training loss: 3.5650051745020055
Validation loss: 2.919054694500317

Epoch: 5| Step: 8
Training loss: 3.1060948538460424
Validation loss: 2.9200212381135313

Epoch: 5| Step: 9
Training loss: 2.897404653775887
Validation loss: 2.916515620813475

Epoch: 5| Step: 10
Training loss: 3.305021228577828
Validation loss: 2.915024519824453

Epoch: 98| Step: 0
Training loss: 2.2986855150712735
Validation loss: 2.9146438621784596

Epoch: 5| Step: 1
Training loss: 3.2671522739724335
Validation loss: 2.918386849216371

Epoch: 5| Step: 2
Training loss: 3.1714411095821804
Validation loss: 2.93106083490338

Epoch: 5| Step: 3
Training loss: 3.279320576475917
Validation loss: 2.9369816930464565

Epoch: 5| Step: 4
Training loss: 3.347954361772021
Validation loss: 2.949236467223072

Epoch: 5| Step: 5
Training loss: 3.1105528474410513
Validation loss: 2.967862760974246

Epoch: 5| Step: 6
Training loss: 3.1872159045902655
Validation loss: 2.9288180798599055

Epoch: 5| Step: 7
Training loss: 3.6779716362494783
Validation loss: 2.91167645420014

Epoch: 5| Step: 8
Training loss: 2.737177954416608
Validation loss: 2.913450748767359

Epoch: 5| Step: 9
Training loss: 3.715532978994153
Validation loss: 2.9174311806395004

Epoch: 5| Step: 10
Training loss: 3.337772623993063
Validation loss: 2.9204227913524994

Epoch: 99| Step: 0
Training loss: 2.8798511874641157
Validation loss: 2.927383204005595

Epoch: 5| Step: 1
Training loss: 3.369613587726465
Validation loss: 2.930475866639173

Epoch: 5| Step: 2
Training loss: 3.7965106553825323
Validation loss: 2.9270691441957775

Epoch: 5| Step: 3
Training loss: 2.9048340332105114
Validation loss: 2.916887464530675

Epoch: 5| Step: 4
Training loss: 3.476279120736503
Validation loss: 2.9178076834144018

Epoch: 5| Step: 5
Training loss: 3.7545857682814807
Validation loss: 2.9115730932380552

Epoch: 5| Step: 6
Training loss: 3.3673851857935637
Validation loss: 2.912690983548437

Epoch: 5| Step: 7
Training loss: 3.0559029661022326
Validation loss: 2.9196124206541185

Epoch: 5| Step: 8
Training loss: 3.18900891660375
Validation loss: 2.9195653589311545

Epoch: 5| Step: 9
Training loss: 2.4070266857308233
Validation loss: 2.922140097040831

Epoch: 5| Step: 10
Training loss: 2.87667433041126
Validation loss: 2.9349910412986184

Epoch: 100| Step: 0
Training loss: 2.403075663403666
Validation loss: 2.9372868317647636

Epoch: 5| Step: 1
Training loss: 3.189392724665377
Validation loss: 2.9330119956341525

Epoch: 5| Step: 2
Training loss: 2.6942581547138245
Validation loss: 2.9265212373729805

Epoch: 5| Step: 3
Training loss: 3.0474253622026253
Validation loss: 2.9273814341248072

Epoch: 5| Step: 4
Training loss: 3.2259550469536644
Validation loss: 2.9162133446150875

Epoch: 5| Step: 5
Training loss: 2.9939197277145784
Validation loss: 2.9132707133703595

Epoch: 5| Step: 6
Training loss: 3.2013062314505953
Validation loss: 2.9105170349558023

Epoch: 5| Step: 7
Training loss: 3.7673868829848662
Validation loss: 2.9108063064211582

Epoch: 5| Step: 8
Training loss: 3.326995084703333
Validation loss: 2.9091564345341934

Epoch: 5| Step: 9
Training loss: 3.829521204848751
Validation loss: 2.9122939883582077

Epoch: 5| Step: 10
Training loss: 3.3096227565740057
Validation loss: 2.9089680766338226

Epoch: 101| Step: 0
Training loss: 2.387758019370854
Validation loss: 2.909123938055502

Epoch: 5| Step: 1
Training loss: 3.720023442061201
Validation loss: 2.9083960534635622

Epoch: 5| Step: 2
Training loss: 3.4900608628002185
Validation loss: 2.91067386331414

Epoch: 5| Step: 3
Training loss: 3.4193324567476715
Validation loss: 2.9087282892521245

Epoch: 5| Step: 4
Training loss: 3.133702786625947
Validation loss: 2.9088762449039045

Epoch: 5| Step: 5
Training loss: 2.447678661274274
Validation loss: 2.9095297487632887

Epoch: 5| Step: 6
Training loss: 3.186604392694831
Validation loss: 2.9101164458380553

Epoch: 5| Step: 7
Training loss: 2.4471412133866766
Validation loss: 2.909377790614291

Epoch: 5| Step: 8
Training loss: 3.5560293494559203
Validation loss: 2.911475973328804

Epoch: 5| Step: 9
Training loss: 3.6950612537226237
Validation loss: 2.9128031395838345

Epoch: 5| Step: 10
Training loss: 3.4008419957728706
Validation loss: 2.912518990366861

Epoch: 102| Step: 0
Training loss: 3.263103478986714
Validation loss: 2.9075526805501775

Epoch: 5| Step: 1
Training loss: 3.385579657910319
Validation loss: 2.9075804915565744

Epoch: 5| Step: 2
Training loss: 3.1288833903074114
Validation loss: 2.90655032628495

Epoch: 5| Step: 3
Training loss: 2.53519565451729
Validation loss: 2.9050473448214333

Epoch: 5| Step: 4
Training loss: 3.306670908104832
Validation loss: 2.9057521210563793

Epoch: 5| Step: 5
Training loss: 3.364006363063242
Validation loss: 2.90633220205715

Epoch: 5| Step: 6
Training loss: 3.134782509446351
Validation loss: 2.906089551582804

Epoch: 5| Step: 7
Training loss: 3.5338963407934227
Validation loss: 2.9068812314287378

Epoch: 5| Step: 8
Training loss: 2.52226565524818
Validation loss: 2.907135442963027

Epoch: 5| Step: 9
Training loss: 3.283206901116954
Validation loss: 2.906108071624616

Epoch: 5| Step: 10
Training loss: 3.625384343259696
Validation loss: 2.905310133146202

Epoch: 103| Step: 0
Training loss: 3.5086532978448495
Validation loss: 2.90538959202384

Epoch: 5| Step: 1
Training loss: 3.357518024410401
Validation loss: 2.90512980240402

Epoch: 5| Step: 2
Training loss: 3.4363816262655473
Validation loss: 2.9052984625232416

Epoch: 5| Step: 3
Training loss: 3.0241165384311324
Validation loss: 2.9063245261176087

Epoch: 5| Step: 4
Training loss: 3.086438256690991
Validation loss: 2.90649208404053

Epoch: 5| Step: 5
Training loss: 3.5916484493020784
Validation loss: 2.903787569817015

Epoch: 5| Step: 6
Training loss: 2.9380856194014484
Validation loss: 2.9028054460584403

Epoch: 5| Step: 7
Training loss: 2.8202049678686505
Validation loss: 2.9046447798424477

Epoch: 5| Step: 8
Training loss: 2.881270991515774
Validation loss: 2.905198908244824

Epoch: 5| Step: 9
Training loss: 3.3213677378765993
Validation loss: 2.9053556063027846

Epoch: 5| Step: 10
Training loss: 3.101320656060341
Validation loss: 2.9073363413028286

Epoch: 104| Step: 0
Training loss: 3.2432459562737055
Validation loss: 2.9142998687744606

Epoch: 5| Step: 1
Training loss: 2.6612829659473096
Validation loss: 2.901330056730549

Epoch: 5| Step: 2
Training loss: 3.107730603181866
Validation loss: 2.9030101976353198

Epoch: 5| Step: 3
Training loss: 2.9013704744806357
Validation loss: 2.9045866017720527

Epoch: 5| Step: 4
Training loss: 3.8188046715252004
Validation loss: 2.9030466446006815

Epoch: 5| Step: 5
Training loss: 3.555216789663999
Validation loss: 2.901261740599063

Epoch: 5| Step: 6
Training loss: 3.0939708592350073
Validation loss: 2.9031231524208603

Epoch: 5| Step: 7
Training loss: 3.3658358168744336
Validation loss: 2.9014610098941773

Epoch: 5| Step: 8
Training loss: 3.1044645401214654
Validation loss: 2.9028328203458114

Epoch: 5| Step: 9
Training loss: 2.8777747654582018
Validation loss: 2.9013123420881746

Epoch: 5| Step: 10
Training loss: 3.2692758695158375
Validation loss: 2.9025299066004773

Epoch: 105| Step: 0
Training loss: 2.8695378038355934
Validation loss: 2.903612502043029

Epoch: 5| Step: 1
Training loss: 3.293026526544967
Validation loss: 2.902422087948737

Epoch: 5| Step: 2
Training loss: 2.978018657310766
Validation loss: 2.9024323436517077

Epoch: 5| Step: 3
Training loss: 2.821510631064667
Validation loss: 2.904562234350022

Epoch: 5| Step: 4
Training loss: 3.242186617563886
Validation loss: 2.901944802155969

Epoch: 5| Step: 5
Training loss: 3.0811243306312885
Validation loss: 2.9009469684887734

Epoch: 5| Step: 6
Training loss: 2.7954256362153265
Validation loss: 2.9025162993194225

Epoch: 5| Step: 7
Training loss: 3.9915650362099147
Validation loss: 2.9029446816692404

Epoch: 5| Step: 8
Training loss: 3.714224233223283
Validation loss: 2.900114718209548

Epoch: 5| Step: 9
Training loss: 3.4511396820000337
Validation loss: 2.9031806215919724

Epoch: 5| Step: 10
Training loss: 2.480118181581393
Validation loss: 2.8978448510715937

Epoch: 106| Step: 0
Training loss: 2.8147354566762677
Validation loss: 2.8998901965209716

Epoch: 5| Step: 1
Training loss: 2.921681933220776
Validation loss: 2.9042025669120144

Epoch: 5| Step: 2
Training loss: 2.817323913487461
Validation loss: 2.9055596055454784

Epoch: 5| Step: 3
Training loss: 3.0519256203863496
Validation loss: 2.9180782968724888

Epoch: 5| Step: 4
Training loss: 3.705134237022387
Validation loss: 2.919529543183682

Epoch: 5| Step: 5
Training loss: 3.463941523289621
Validation loss: 2.9140241383362677

Epoch: 5| Step: 6
Training loss: 2.9246812695684383
Validation loss: 2.8986025200148897

Epoch: 5| Step: 7
Training loss: 2.640312672941365
Validation loss: 2.897983096267756

Epoch: 5| Step: 8
Training loss: 3.6928292251547763
Validation loss: 2.8968178441904344

Epoch: 5| Step: 9
Training loss: 3.926307513894518
Validation loss: 2.8982229588722066

Epoch: 5| Step: 10
Training loss: 2.813129100377049
Validation loss: 2.898049079128297

Epoch: 107| Step: 0
Training loss: 3.274169257410477
Validation loss: 2.899973783774118

Epoch: 5| Step: 1
Training loss: 2.986293954697411
Validation loss: 2.9017060935965215

Epoch: 5| Step: 2
Training loss: 2.780012562675358
Validation loss: 2.8989409887902684

Epoch: 5| Step: 3
Training loss: 3.1638430672366735
Validation loss: 2.9046722709495145

Epoch: 5| Step: 4
Training loss: 2.8252029919907296
Validation loss: 2.9009676325671343

Epoch: 5| Step: 5
Training loss: 3.0399656547312834
Validation loss: 2.9005344417500125

Epoch: 5| Step: 6
Training loss: 3.546770136287127
Validation loss: 2.9022322524150868

Epoch: 5| Step: 7
Training loss: 3.18900607562391
Validation loss: 2.8991691431671636

Epoch: 5| Step: 8
Training loss: 3.2660522181488165
Validation loss: 2.898441250237589

Epoch: 5| Step: 9
Training loss: 3.4549151307211354
Validation loss: 2.8960048128710247

Epoch: 5| Step: 10
Training loss: 3.611292078097206
Validation loss: 2.8953053708820997

Epoch: 108| Step: 0
Training loss: 3.414263337467285
Validation loss: 2.8959166466930557

Epoch: 5| Step: 1
Training loss: 3.70578152299444
Validation loss: 2.8964013986763897

Epoch: 5| Step: 2
Training loss: 3.688105129439884
Validation loss: 2.895930392985565

Epoch: 5| Step: 3
Training loss: 3.198772469158793
Validation loss: 2.896559978143955

Epoch: 5| Step: 4
Training loss: 3.104407555025628
Validation loss: 2.9013363639229772

Epoch: 5| Step: 5
Training loss: 3.5265014589069508
Validation loss: 2.899041038293431

Epoch: 5| Step: 6
Training loss: 1.9908099030235926
Validation loss: 2.8997357997057986

Epoch: 5| Step: 7
Training loss: 2.1278770268696197
Validation loss: 2.9003448919145685

Epoch: 5| Step: 8
Training loss: 3.578299439022002
Validation loss: 2.896691116861754

Epoch: 5| Step: 9
Training loss: 3.109947573597095
Validation loss: 2.9000482793515494

Epoch: 5| Step: 10
Training loss: 3.079523224032174
Validation loss: 2.907506707426322

Epoch: 109| Step: 0
Training loss: 3.3393502924935206
Validation loss: 2.903741911421467

Epoch: 5| Step: 1
Training loss: 3.0206285779992195
Validation loss: 2.898298996965956

Epoch: 5| Step: 2
Training loss: 3.1253278941746188
Validation loss: 2.895334418724046

Epoch: 5| Step: 3
Training loss: 3.5897987205163466
Validation loss: 2.8934880120714466

Epoch: 5| Step: 4
Training loss: 2.6069147081078663
Validation loss: 2.8930099107535905

Epoch: 5| Step: 5
Training loss: 3.344410340891093
Validation loss: 2.8915149847410033

Epoch: 5| Step: 6
Training loss: 3.0462166881970485
Validation loss: 2.8925504427278876

Epoch: 5| Step: 7
Training loss: 3.0168653714263622
Validation loss: 2.890485020169106

Epoch: 5| Step: 8
Training loss: 3.7387070049643802
Validation loss: 2.8924914452976713

Epoch: 5| Step: 9
Training loss: 2.8421539187216935
Validation loss: 2.8919418603556744

Epoch: 5| Step: 10
Training loss: 3.2063351803892033
Validation loss: 2.8880907864672496

Epoch: 110| Step: 0
Training loss: 3.2189522096393253
Validation loss: 2.89095226010638

Epoch: 5| Step: 1
Training loss: 3.5909582821688897
Validation loss: 2.8901896318776448

Epoch: 5| Step: 2
Training loss: 3.2263397804960694
Validation loss: 2.8895209326099454

Epoch: 5| Step: 3
Training loss: 2.989290513286915
Validation loss: 2.8896467305636215

Epoch: 5| Step: 4
Training loss: 3.6549525118768242
Validation loss: 2.8907266294644622

Epoch: 5| Step: 5
Training loss: 2.6889770352371394
Validation loss: 2.889727590687605

Epoch: 5| Step: 6
Training loss: 2.895949619803399
Validation loss: 2.889808398869656

Epoch: 5| Step: 7
Training loss: 3.0607735574855317
Validation loss: 2.892761833067848

Epoch: 5| Step: 8
Training loss: 3.786548149936122
Validation loss: 2.8980022979668107

Epoch: 5| Step: 9
Training loss: 3.076617031282531
Validation loss: 2.8970500682478453

Epoch: 5| Step: 10
Training loss: 2.4870164372445864
Validation loss: 2.898740393005432

Epoch: 111| Step: 0
Training loss: 1.9108598969392263
Validation loss: 2.898206734299832

Epoch: 5| Step: 1
Training loss: 3.0762000866761903
Validation loss: 2.8946026830931726

Epoch: 5| Step: 2
Training loss: 2.8822498961412335
Validation loss: 2.8912827798461946

Epoch: 5| Step: 3
Training loss: 3.2140228224527387
Validation loss: 2.8941740368287556

Epoch: 5| Step: 4
Training loss: 3.0521446629808042
Validation loss: 2.894238520107771

Epoch: 5| Step: 5
Training loss: 3.342810097620695
Validation loss: 2.8923823598982383

Epoch: 5| Step: 6
Training loss: 2.8355261974681736
Validation loss: 2.8943375124940887

Epoch: 5| Step: 7
Training loss: 3.6898717203560216
Validation loss: 2.8925228913631273

Epoch: 5| Step: 8
Training loss: 3.584978228812835
Validation loss: 2.8884484084698605

Epoch: 5| Step: 9
Training loss: 3.9385570742065203
Validation loss: 2.8918694448963245

Epoch: 5| Step: 10
Training loss: 2.99149882307098
Validation loss: 2.888284972275657

Epoch: 112| Step: 0
Training loss: 2.875872769773942
Validation loss: 2.8876625230154596

Epoch: 5| Step: 1
Training loss: 2.366512693402139
Validation loss: 2.8900739859118847

Epoch: 5| Step: 2
Training loss: 3.3994035422039883
Validation loss: 2.8885279850523915

Epoch: 5| Step: 3
Training loss: 3.297145886614608
Validation loss: 2.8887502358235126

Epoch: 5| Step: 4
Training loss: 2.9709243039991398
Validation loss: 2.888102443185606

Epoch: 5| Step: 5
Training loss: 3.7538861801134926
Validation loss: 2.891930343220453

Epoch: 5| Step: 6
Training loss: 2.7399856987461626
Validation loss: 2.8884590617055954

Epoch: 5| Step: 7
Training loss: 3.387859429579008
Validation loss: 2.901066603888196

Epoch: 5| Step: 8
Training loss: 2.9924983966157037
Validation loss: 2.8922569805267293

Epoch: 5| Step: 9
Training loss: 3.7510890650842104
Validation loss: 2.8894087130763153

Epoch: 5| Step: 10
Training loss: 3.204202610272294
Validation loss: 2.887507760926611

Epoch: 113| Step: 0
Training loss: 3.268345334038951
Validation loss: 2.8838721296914596

Epoch: 5| Step: 1
Training loss: 3.1083065478386964
Validation loss: 2.8842755976372123

Epoch: 5| Step: 2
Training loss: 2.779644620670801
Validation loss: 2.884935661380911

Epoch: 5| Step: 3
Training loss: 3.1736601518050533
Validation loss: 2.8854210018630195

Epoch: 5| Step: 4
Training loss: 3.288322456085369
Validation loss: 2.8858937743117856

Epoch: 5| Step: 5
Training loss: 3.1389662884047054
Validation loss: 2.8847288972971574

Epoch: 5| Step: 6
Training loss: 2.420262938472846
Validation loss: 2.8844774979775836

Epoch: 5| Step: 7
Training loss: 3.4915026648220495
Validation loss: 2.884471105927761

Epoch: 5| Step: 8
Training loss: 3.3677224710067235
Validation loss: 2.8847559596732855

Epoch: 5| Step: 9
Training loss: 3.7615041384376924
Validation loss: 2.8840019057212682

Epoch: 5| Step: 10
Training loss: 2.9453656017262153
Validation loss: 2.8840900699080483

Epoch: 114| Step: 0
Training loss: 3.114051560814799
Validation loss: 2.8806279531402024

Epoch: 5| Step: 1
Training loss: 3.6144546500540526
Validation loss: 2.882682197303383

Epoch: 5| Step: 2
Training loss: 3.1226297163152155
Validation loss: 2.8815888853457947

Epoch: 5| Step: 3
Training loss: 3.2967935705750313
Validation loss: 2.8844459810885468

Epoch: 5| Step: 4
Training loss: 2.7955228637895657
Validation loss: 2.8824132351638765

Epoch: 5| Step: 5
Training loss: 2.921143302486982
Validation loss: 2.8848673977870525

Epoch: 5| Step: 6
Training loss: 3.497594551733438
Validation loss: 2.884062383498745

Epoch: 5| Step: 7
Training loss: 3.0633104769988972
Validation loss: 2.885211630917034

Epoch: 5| Step: 8
Training loss: 2.7692665221074493
Validation loss: 2.887961582103574

Epoch: 5| Step: 9
Training loss: 3.467835726832501
Validation loss: 2.895719089646287

Epoch: 5| Step: 10
Training loss: 3.114216165153476
Validation loss: 2.900476391594791

Epoch: 115| Step: 0
Training loss: 3.1700208534493446
Validation loss: 2.891639719832169

Epoch: 5| Step: 1
Training loss: 3.0779448325782286
Validation loss: 2.885168384214722

Epoch: 5| Step: 2
Training loss: 3.4185922980330514
Validation loss: 2.881663004817349

Epoch: 5| Step: 3
Training loss: 3.5537171097775473
Validation loss: 2.883805158388708

Epoch: 5| Step: 4
Training loss: 2.856965430745207
Validation loss: 2.882762057560075

Epoch: 5| Step: 5
Training loss: 3.7368425333208046
Validation loss: 2.881832130069804

Epoch: 5| Step: 6
Training loss: 2.8515143403467436
Validation loss: 2.880737870763283

Epoch: 5| Step: 7
Training loss: 3.053955146435191
Validation loss: 2.8844085213946618

Epoch: 5| Step: 8
Training loss: 2.8793269229201353
Validation loss: 2.879333311253814

Epoch: 5| Step: 9
Training loss: 2.975169899841413
Validation loss: 2.8795637260810025

Epoch: 5| Step: 10
Training loss: 3.228955579852054
Validation loss: 2.880252210213912

Epoch: 116| Step: 0
Training loss: 3.2166604972608894
Validation loss: 2.8813384363391257

Epoch: 5| Step: 1
Training loss: 3.153065500747162
Validation loss: 2.880453894159414

Epoch: 5| Step: 2
Training loss: 3.549143733601142
Validation loss: 2.885056487661255

Epoch: 5| Step: 3
Training loss: 3.158240719714783
Validation loss: 2.882227316268411

Epoch: 5| Step: 4
Training loss: 2.8613677871611194
Validation loss: 2.879451041031661

Epoch: 5| Step: 5
Training loss: 2.932212128359448
Validation loss: 2.876298599101046

Epoch: 5| Step: 6
Training loss: 3.1190518036332064
Validation loss: 2.8775461139353222

Epoch: 5| Step: 7
Training loss: 2.9584802582123855
Validation loss: 2.8754638558056573

Epoch: 5| Step: 8
Training loss: 3.4389953135297366
Validation loss: 2.878409134901359

Epoch: 5| Step: 9
Training loss: 3.3403237159691304
Validation loss: 2.879973467943333

Epoch: 5| Step: 10
Training loss: 3.1826941968667115
Validation loss: 2.8782048279433696

Epoch: 117| Step: 0
Training loss: 3.213358242708691
Validation loss: 2.876521984146389

Epoch: 5| Step: 1
Training loss: 3.602771084584065
Validation loss: 2.878345820034937

Epoch: 5| Step: 2
Training loss: 2.489241817358624
Validation loss: 2.8767282660279463

Epoch: 5| Step: 3
Training loss: 2.7678776419447426
Validation loss: 2.876956861361956

Epoch: 5| Step: 4
Training loss: 3.413310721094016
Validation loss: 2.877176770641476

Epoch: 5| Step: 5
Training loss: 3.44595157984691
Validation loss: 2.877248499159534

Epoch: 5| Step: 6
Training loss: 3.358151093137898
Validation loss: 2.8777426005621902

Epoch: 5| Step: 7
Training loss: 3.539170421445355
Validation loss: 2.879584925537556

Epoch: 5| Step: 8
Training loss: 3.209958115063788
Validation loss: 2.8755142461796597

Epoch: 5| Step: 9
Training loss: 2.8052795125375893
Validation loss: 2.8757025122101663

Epoch: 5| Step: 10
Training loss: 2.7647608899551313
Validation loss: 2.8756163526287963

Epoch: 118| Step: 0
Training loss: 3.1101064157218574
Validation loss: 2.8813740955432388

Epoch: 5| Step: 1
Training loss: 3.152587427413837
Validation loss: 2.879427083238365

Epoch: 5| Step: 2
Training loss: 3.29591796869213
Validation loss: 2.881235166872791

Epoch: 5| Step: 3
Training loss: 3.401505552068371
Validation loss: 2.8783018351198524

Epoch: 5| Step: 4
Training loss: 3.2950780228912513
Validation loss: 2.8829447326915525

Epoch: 5| Step: 5
Training loss: 3.2853382618090996
Validation loss: 2.890939793716583

Epoch: 5| Step: 6
Training loss: 3.2835445555569422
Validation loss: 2.8970005152856833

Epoch: 5| Step: 7
Training loss: 3.2941980567502567
Validation loss: 2.894836412352095

Epoch: 5| Step: 8
Training loss: 2.5953232004219506
Validation loss: 2.8744204250425818

Epoch: 5| Step: 9
Training loss: 3.166029933024039
Validation loss: 2.873056433379658

Epoch: 5| Step: 10
Training loss: 2.856904343458727
Validation loss: 2.8734225849671713

Epoch: 119| Step: 0
Training loss: 3.353370872221717
Validation loss: 2.8744804328378604

Epoch: 5| Step: 1
Training loss: 3.0638865232146295
Validation loss: 2.877954009618929

Epoch: 5| Step: 2
Training loss: 3.4132465985076617
Validation loss: 2.87732774933196

Epoch: 5| Step: 3
Training loss: 2.945468240763874
Validation loss: 2.878916785381922

Epoch: 5| Step: 4
Training loss: 3.3095404881641577
Validation loss: 2.878517679320593

Epoch: 5| Step: 5
Training loss: 3.4680729110691573
Validation loss: 2.8720833204859866

Epoch: 5| Step: 6
Training loss: 2.912618734534479
Validation loss: 2.873542557117694

Epoch: 5| Step: 7
Training loss: 3.095700352423837
Validation loss: 2.873343468876061

Epoch: 5| Step: 8
Training loss: 2.9427411012878766
Validation loss: 2.8701696242830677

Epoch: 5| Step: 9
Training loss: 3.3945502136894774
Validation loss: 2.8729597603966925

Epoch: 5| Step: 10
Training loss: 2.88886665270472
Validation loss: 2.8699918358930963

Epoch: 120| Step: 0
Training loss: 2.5402581319529567
Validation loss: 2.87094376326914

Epoch: 5| Step: 1
Training loss: 3.6699893086456985
Validation loss: 2.868482802932228

Epoch: 5| Step: 2
Training loss: 3.500133239389816
Validation loss: 2.874952150921298

Epoch: 5| Step: 3
Training loss: 2.9863659673554754
Validation loss: 2.8755645447349854

Epoch: 5| Step: 4
Training loss: 2.953906727820809
Validation loss: 2.883985482029191

Epoch: 5| Step: 5
Training loss: 2.850563522308239
Validation loss: 2.8869851425289106

Epoch: 5| Step: 6
Training loss: 3.350436788523126
Validation loss: 2.882428349719348

Epoch: 5| Step: 7
Training loss: 2.987733878074868
Validation loss: 2.8937457310512573

Epoch: 5| Step: 8
Training loss: 3.1786287311758725
Validation loss: 2.8940305320618007

Epoch: 5| Step: 9
Training loss: 3.255631922309709
Validation loss: 2.88932997926501

Epoch: 5| Step: 10
Training loss: 3.4887357375134638
Validation loss: 2.8791885129631853

Epoch: 121| Step: 0
Training loss: 2.907262154163643
Validation loss: 2.868330700857575

Epoch: 5| Step: 1
Training loss: 2.7903391590226962
Validation loss: 2.869435618674681

Epoch: 5| Step: 2
Training loss: 3.763531114591786
Validation loss: 2.8679457889486644

Epoch: 5| Step: 3
Training loss: 3.243877806745756
Validation loss: 2.8713625885485228

Epoch: 5| Step: 4
Training loss: 3.5066289795517194
Validation loss: 2.871359335071652

Epoch: 5| Step: 5
Training loss: 2.904554631404189
Validation loss: 2.875374224375673

Epoch: 5| Step: 6
Training loss: 3.1215853536687503
Validation loss: 2.874201079974768

Epoch: 5| Step: 7
Training loss: 3.1764406315008027
Validation loss: 2.873172689355974

Epoch: 5| Step: 8
Training loss: 2.563064140931191
Validation loss: 2.874815755275491

Epoch: 5| Step: 9
Training loss: 3.5899071091134083
Validation loss: 2.8749224735702037

Epoch: 5| Step: 10
Training loss: 3.152616014032409
Validation loss: 2.8757942840437427

Epoch: 122| Step: 0
Training loss: 2.8954959553930917
Validation loss: 2.875636557739672

Epoch: 5| Step: 1
Training loss: 3.6273991768073763
Validation loss: 2.87117557103503

Epoch: 5| Step: 2
Training loss: 3.5242909414972856
Validation loss: 2.8721849071434353

Epoch: 5| Step: 3
Training loss: 3.280203225422663
Validation loss: 2.8716836432289163

Epoch: 5| Step: 4
Training loss: 3.401650078854697
Validation loss: 2.8704746516691335

Epoch: 5| Step: 5
Training loss: 3.1654985347992057
Validation loss: 2.871013175855571

Epoch: 5| Step: 6
Training loss: 3.1906265184060723
Validation loss: 2.8699856831314734

Epoch: 5| Step: 7
Training loss: 2.9801249174523887
Validation loss: 2.866685752156459

Epoch: 5| Step: 8
Training loss: 3.132121250061282
Validation loss: 2.8690397767462237

Epoch: 5| Step: 9
Training loss: 2.885662541202068
Validation loss: 2.8683180038699283

Epoch: 5| Step: 10
Training loss: 2.5795824959524114
Validation loss: 2.8684194906102376

Epoch: 123| Step: 0
Training loss: 2.994046502770856
Validation loss: 2.865418019927669

Epoch: 5| Step: 1
Training loss: 3.618749030183916
Validation loss: 2.8663526698129727

Epoch: 5| Step: 2
Training loss: 3.3557043559055026
Validation loss: 2.8641324398589485

Epoch: 5| Step: 3
Training loss: 2.5575889419796285
Validation loss: 2.8668600622300113

Epoch: 5| Step: 4
Training loss: 3.287460118040972
Validation loss: 2.867954658155032

Epoch: 5| Step: 5
Training loss: 2.8051199831945133
Validation loss: 2.867161425239225

Epoch: 5| Step: 6
Training loss: 3.2940975982993557
Validation loss: 2.8645846536732127

Epoch: 5| Step: 7
Training loss: 3.2815978819492
Validation loss: 2.8675243958434624

Epoch: 5| Step: 8
Training loss: 3.128879427943713
Validation loss: 2.8682892759011875

Epoch: 5| Step: 9
Training loss: 3.0801126481796204
Validation loss: 2.8689184483753323

Epoch: 5| Step: 10
Training loss: 3.273526647988052
Validation loss: 2.8742937314625157

Epoch: 124| Step: 0
Training loss: 3.3105474511430177
Validation loss: 2.872115747809462

Epoch: 5| Step: 1
Training loss: 2.7310508358615926
Validation loss: 2.8687694980259795

Epoch: 5| Step: 2
Training loss: 3.9642875995410574
Validation loss: 2.867963318163972

Epoch: 5| Step: 3
Training loss: 2.9982881430301616
Validation loss: 2.864173364621396

Epoch: 5| Step: 4
Training loss: 2.833100552439743
Validation loss: 2.860871683872243

Epoch: 5| Step: 5
Training loss: 3.1408905372528335
Validation loss: 2.8600921896976104

Epoch: 5| Step: 6
Training loss: 2.9184435926603136
Validation loss: 2.8611275909753116

Epoch: 5| Step: 7
Training loss: 3.2285222712896653
Validation loss: 2.8609689758923853

Epoch: 5| Step: 8
Training loss: 3.0797344202254022
Validation loss: 2.859181342472575

Epoch: 5| Step: 9
Training loss: 3.3640853151078405
Validation loss: 2.860445099049929

Epoch: 5| Step: 10
Training loss: 3.0041668881765875
Validation loss: 2.857389255800362

Epoch: 125| Step: 0
Training loss: 2.6804764812272377
Validation loss: 2.8598221365886727

Epoch: 5| Step: 1
Training loss: 3.280881297877032
Validation loss: 2.8624986639152707

Epoch: 5| Step: 2
Training loss: 3.252262355089233
Validation loss: 2.861235565275434

Epoch: 5| Step: 3
Training loss: 3.497283289905334
Validation loss: 2.8544229767063656

Epoch: 5| Step: 4
Training loss: 3.1590693506137697
Validation loss: 2.8559144052768595

Epoch: 5| Step: 5
Training loss: 2.698693672924588
Validation loss: 2.8514090844708493

Epoch: 5| Step: 6
Training loss: 3.2460216234183816
Validation loss: 2.8545180115641595

Epoch: 5| Step: 7
Training loss: 2.6626701408074487
Validation loss: 2.852913159910486

Epoch: 5| Step: 8
Training loss: 3.039491441752601
Validation loss: 2.851603012707443

Epoch: 5| Step: 9
Training loss: 3.600657450723911
Validation loss: 2.8497170318442198

Epoch: 5| Step: 10
Training loss: 3.4681347825501363
Validation loss: 2.8495787346803323

Epoch: 126| Step: 0
Training loss: 3.588879012523036
Validation loss: 2.849375150546961

Epoch: 5| Step: 1
Training loss: 3.336800885646559
Validation loss: 2.8475286654169896

Epoch: 5| Step: 2
Training loss: 2.6089716616722174
Validation loss: 2.8433005198479777

Epoch: 5| Step: 3
Training loss: 3.0208271596560476
Validation loss: 2.843600439019467

Epoch: 5| Step: 4
Training loss: 2.738588585251538
Validation loss: 2.8434374237550104

Epoch: 5| Step: 5
Training loss: 3.1713994613990537
Validation loss: 2.8453533390535424

Epoch: 5| Step: 6
Training loss: 3.046475584797871
Validation loss: 2.8382824535088504

Epoch: 5| Step: 7
Training loss: 3.330223031121447
Validation loss: 2.8415368451735805

Epoch: 5| Step: 8
Training loss: 3.1889893287439475
Validation loss: 2.846844139844526

Epoch: 5| Step: 9
Training loss: 2.7440278488280767
Validation loss: 2.855901342047232

Epoch: 5| Step: 10
Training loss: 3.706314837707193
Validation loss: 2.8480266779853225

Epoch: 127| Step: 0
Training loss: 2.830445070349299
Validation loss: 2.8517874374597185

Epoch: 5| Step: 1
Training loss: 2.373627316165569
Validation loss: 2.8419266464507853

Epoch: 5| Step: 2
Training loss: 3.4124314800831104
Validation loss: 2.837268438047889

Epoch: 5| Step: 3
Training loss: 2.6763583041374046
Validation loss: 2.8380655862415485

Epoch: 5| Step: 4
Training loss: 3.510263381162011
Validation loss: 2.8375655290963198

Epoch: 5| Step: 5
Training loss: 3.582426725331672
Validation loss: 2.8360574669174614

Epoch: 5| Step: 6
Training loss: 2.9616463248077194
Validation loss: 2.836992335706846

Epoch: 5| Step: 7
Training loss: 3.5615233036142695
Validation loss: 2.8364671848500302

Epoch: 5| Step: 8
Training loss: 3.26198627037279
Validation loss: 2.837574982033006

Epoch: 5| Step: 9
Training loss: 2.520365826680538
Validation loss: 2.838559638774899

Epoch: 5| Step: 10
Training loss: 3.6737071559363743
Validation loss: 2.8370002380920063

Epoch: 128| Step: 0
Training loss: 3.096996723019348
Validation loss: 2.8344573759673115

Epoch: 5| Step: 1
Training loss: 3.310153634000766
Validation loss: 2.8324574266332947

Epoch: 5| Step: 2
Training loss: 3.20192982775813
Validation loss: 2.832290425504531

Epoch: 5| Step: 3
Training loss: 3.020763071931191
Validation loss: 2.834974598649702

Epoch: 5| Step: 4
Training loss: 2.782568886753316
Validation loss: 2.839150492837778

Epoch: 5| Step: 5
Training loss: 2.52590868622801
Validation loss: 2.841155976666051

Epoch: 5| Step: 6
Training loss: 2.942111352552012
Validation loss: 2.8458464191700257

Epoch: 5| Step: 7
Training loss: 3.6773596525608188
Validation loss: 2.8438832737360764

Epoch: 5| Step: 8
Training loss: 3.3626151139645892
Validation loss: 2.8454058231562933

Epoch: 5| Step: 9
Training loss: 3.6145028023813803
Validation loss: 2.83708084025974

Epoch: 5| Step: 10
Training loss: 2.7884801261950156
Validation loss: 2.8352062412869072

Epoch: 129| Step: 0
Training loss: 3.0052736342468416
Validation loss: 2.835407086908982

Epoch: 5| Step: 1
Training loss: 3.0367506005432685
Validation loss: 2.8356351909090747

Epoch: 5| Step: 2
Training loss: 2.589744324307557
Validation loss: 2.836993732745321

Epoch: 5| Step: 3
Training loss: 3.074313829980199
Validation loss: 2.836752552686649

Epoch: 5| Step: 4
Training loss: 3.357244623375193
Validation loss: 2.8390925023188682

Epoch: 5| Step: 5
Training loss: 3.621766193588834
Validation loss: 2.835695394755287

Epoch: 5| Step: 6
Training loss: 3.060746761530626
Validation loss: 2.834449333537369

Epoch: 5| Step: 7
Training loss: 3.534695320218548
Validation loss: 2.8395219229980557

Epoch: 5| Step: 8
Training loss: 2.9979333116724516
Validation loss: 2.8307879745286093

Epoch: 5| Step: 9
Training loss: 2.9397756000438675
Validation loss: 2.8281039790884575

Epoch: 5| Step: 10
Training loss: 3.185843542190574
Validation loss: 2.8283969646631477

Epoch: 130| Step: 0
Training loss: 2.9135965992442125
Validation loss: 2.8286388897771744

Epoch: 5| Step: 1
Training loss: 3.1858173491761907
Validation loss: 2.8307938239733246

Epoch: 5| Step: 2
Training loss: 3.2323122680151783
Validation loss: 2.8311757052493056

Epoch: 5| Step: 3
Training loss: 3.427290024172165
Validation loss: 2.8299125579305264

Epoch: 5| Step: 4
Training loss: 2.4882332454344596
Validation loss: 2.827828338642405

Epoch: 5| Step: 5
Training loss: 2.6409344012235825
Validation loss: 2.8282485506161295

Epoch: 5| Step: 6
Training loss: 3.327945184998982
Validation loss: 2.8300017368339296

Epoch: 5| Step: 7
Training loss: 3.3024523957003074
Validation loss: 2.8272820014425135

Epoch: 5| Step: 8
Training loss: 3.0795012364992784
Validation loss: 2.825710838299072

Epoch: 5| Step: 9
Training loss: 3.3820324850840175
Validation loss: 2.8274956184554108

Epoch: 5| Step: 10
Training loss: 3.4241453677719043
Validation loss: 2.8262599392157703

Epoch: 131| Step: 0
Training loss: 3.1993101151197454
Validation loss: 2.828309152803748

Epoch: 5| Step: 1
Training loss: 3.2287860440949756
Validation loss: 2.8283960881804937

Epoch: 5| Step: 2
Training loss: 3.065189348504836
Validation loss: 2.8306921592839935

Epoch: 5| Step: 3
Training loss: 3.0503829715616626
Validation loss: 2.829164403630302

Epoch: 5| Step: 4
Training loss: 3.1417556169972216
Validation loss: 2.8288195145982216

Epoch: 5| Step: 5
Training loss: 3.1368212083398728
Validation loss: 2.829678504182885

Epoch: 5| Step: 6
Training loss: 3.333666848346085
Validation loss: 2.8343444623949483

Epoch: 5| Step: 7
Training loss: 3.026504735045839
Validation loss: 2.832306553377004

Epoch: 5| Step: 8
Training loss: 3.0034857208791426
Validation loss: 2.831608644268717

Epoch: 5| Step: 9
Training loss: 3.488080026390996
Validation loss: 2.828662236380545

Epoch: 5| Step: 10
Training loss: 2.706349648982257
Validation loss: 2.824840760995103

Epoch: 132| Step: 0
Training loss: 3.739340063203181
Validation loss: 2.82460057902162

Epoch: 5| Step: 1
Training loss: 3.386801255573019
Validation loss: 2.8234355443435852

Epoch: 5| Step: 2
Training loss: 3.023227575934553
Validation loss: 2.8249656585862413

Epoch: 5| Step: 3
Training loss: 3.289645544280848
Validation loss: 2.8260913862389234

Epoch: 5| Step: 4
Training loss: 2.9420748858746335
Validation loss: 2.8264552229187094

Epoch: 5| Step: 5
Training loss: 3.079646165513295
Validation loss: 2.8260284232532733

Epoch: 5| Step: 6
Training loss: 3.058087810116368
Validation loss: 2.824432546047614

Epoch: 5| Step: 7
Training loss: 3.046087544726704
Validation loss: 2.823580825668776

Epoch: 5| Step: 8
Training loss: 2.878854075648746
Validation loss: 2.8232109668062577

Epoch: 5| Step: 9
Training loss: 2.739412387015736
Validation loss: 2.8253868080691897

Epoch: 5| Step: 10
Training loss: 3.158243135424126
Validation loss: 2.8246700431393097

Epoch: 133| Step: 0
Training loss: 2.878876767466913
Validation loss: 2.822247782884755

Epoch: 5| Step: 1
Training loss: 2.2904196612032193
Validation loss: 2.829022398576601

Epoch: 5| Step: 2
Training loss: 3.1403011325839607
Validation loss: 2.842845639975996

Epoch: 5| Step: 3
Training loss: 3.0313811912855635
Validation loss: 2.863944555453822

Epoch: 5| Step: 4
Training loss: 3.1662306903742765
Validation loss: 2.8640826601953666

Epoch: 5| Step: 5
Training loss: 2.7830815660131623
Validation loss: 2.88711963398634

Epoch: 5| Step: 6
Training loss: 3.3139130079768955
Validation loss: 2.8548559032247107

Epoch: 5| Step: 7
Training loss: 3.449616457863086
Validation loss: 2.822880824661859

Epoch: 5| Step: 8
Training loss: 3.6587179608859675
Validation loss: 2.8230984869949562

Epoch: 5| Step: 9
Training loss: 3.3084215211685097
Validation loss: 2.824273801741978

Epoch: 5| Step: 10
Training loss: 3.218283462045821
Validation loss: 2.82108914646498

Epoch: 134| Step: 0
Training loss: 3.1272196706743105
Validation loss: 2.822956083264942

Epoch: 5| Step: 1
Training loss: 3.203697041860068
Validation loss: 2.824647413214155

Epoch: 5| Step: 2
Training loss: 2.8079829075665312
Validation loss: 2.8266959021146314

Epoch: 5| Step: 3
Training loss: 3.454373785480792
Validation loss: 2.8309333947141395

Epoch: 5| Step: 4
Training loss: 2.416851716246314
Validation loss: 2.8312127772416575

Epoch: 5| Step: 5
Training loss: 3.3769209304784034
Validation loss: 2.833483421167554

Epoch: 5| Step: 6
Training loss: 3.3361344647831954
Validation loss: 2.8302252891069726

Epoch: 5| Step: 7
Training loss: 3.212247929164692
Validation loss: 2.8325441704330756

Epoch: 5| Step: 8
Training loss: 3.0049978586909685
Validation loss: 2.8314814484305066

Epoch: 5| Step: 9
Training loss: 2.9895214823174134
Validation loss: 2.826959626754152

Epoch: 5| Step: 10
Training loss: 3.5539932411400064
Validation loss: 2.824514223436728

Epoch: 135| Step: 0
Training loss: 2.828254907480192
Validation loss: 2.8214198271845046

Epoch: 5| Step: 1
Training loss: 2.9991533356250426
Validation loss: 2.8192497939372236

Epoch: 5| Step: 2
Training loss: 2.6260753427172348
Validation loss: 2.8194624428449324

Epoch: 5| Step: 3
Training loss: 3.010325622941833
Validation loss: 2.820555604804817

Epoch: 5| Step: 4
Training loss: 2.5758868125548045
Validation loss: 2.825567768709492

Epoch: 5| Step: 5
Training loss: 3.6420672920123125
Validation loss: 2.829071735830837

Epoch: 5| Step: 6
Training loss: 2.7476174697547178
Validation loss: 2.8425405139615125

Epoch: 5| Step: 7
Training loss: 3.7956902810256605
Validation loss: 2.838783144757619

Epoch: 5| Step: 8
Training loss: 3.0010129490045148
Validation loss: 2.8324517163885723

Epoch: 5| Step: 9
Training loss: 3.8848344845659954
Validation loss: 2.8255590232210275

Epoch: 5| Step: 10
Training loss: 3.117507038613261
Validation loss: 2.820988939583301

Epoch: 136| Step: 0
Training loss: 3.234998854765181
Validation loss: 2.8178820088053493

Epoch: 5| Step: 1
Training loss: 3.0094921624024082
Validation loss: 2.819811873841996

Epoch: 5| Step: 2
Training loss: 3.31496007006318
Validation loss: 2.8196985529074077

Epoch: 5| Step: 3
Training loss: 3.41963477811389
Validation loss: 2.816224778049408

Epoch: 5| Step: 4
Training loss: 2.678379373477145
Validation loss: 2.818153756627181

Epoch: 5| Step: 5
Training loss: 3.0243325498076716
Validation loss: 2.8167157315663114

Epoch: 5| Step: 6
Training loss: 3.0462724138702426
Validation loss: 2.818251519100112

Epoch: 5| Step: 7
Training loss: 2.9764586903649812
Validation loss: 2.8178888193781644

Epoch: 5| Step: 8
Training loss: 3.0276982844316396
Validation loss: 2.8185820015577256

Epoch: 5| Step: 9
Training loss: 3.3967641635138195
Validation loss: 2.8186583854226774

Epoch: 5| Step: 10
Training loss: 3.2584865979558084
Validation loss: 2.824923020545579

Epoch: 137| Step: 0
Training loss: 3.0190208171418655
Validation loss: 2.8223463345910282

Epoch: 5| Step: 1
Training loss: 3.6247603238552903
Validation loss: 2.8180554967849676

Epoch: 5| Step: 2
Training loss: 2.747019019056539
Validation loss: 2.8181630135969966

Epoch: 5| Step: 3
Training loss: 3.4113711435760887
Validation loss: 2.813776733219254

Epoch: 5| Step: 4
Training loss: 3.3332741891064384
Validation loss: 2.8168071621740567

Epoch: 5| Step: 5
Training loss: 2.7782068641710165
Validation loss: 2.816984532257238

Epoch: 5| Step: 6
Training loss: 2.7132705191793542
Validation loss: 2.815417134379335

Epoch: 5| Step: 7
Training loss: 3.2883265163417352
Validation loss: 2.8182415728990784

Epoch: 5| Step: 8
Training loss: 3.3471746287429185
Validation loss: 2.818916030293026

Epoch: 5| Step: 9
Training loss: 2.867392051946408
Validation loss: 2.817302445725087

Epoch: 5| Step: 10
Training loss: 3.1577231113743824
Validation loss: 2.8195665236651046

Epoch: 138| Step: 0
Training loss: 3.2326899022658244
Validation loss: 2.8200484564586095

Epoch: 5| Step: 1
Training loss: 2.9189619751113574
Validation loss: 2.8167905614838813

Epoch: 5| Step: 2
Training loss: 3.210164889084719
Validation loss: 2.815552642476339

Epoch: 5| Step: 3
Training loss: 2.683849872210844
Validation loss: 2.816125839151102

Epoch: 5| Step: 4
Training loss: 3.1663543312904414
Validation loss: 2.8129466213797962

Epoch: 5| Step: 5
Training loss: 2.94631706125866
Validation loss: 2.815526395462415

Epoch: 5| Step: 6
Training loss: 3.136446626291478
Validation loss: 2.8171040504533043

Epoch: 5| Step: 7
Training loss: 2.6848041409000203
Validation loss: 2.822207024101401

Epoch: 5| Step: 8
Training loss: 3.4111329522885026
Validation loss: 2.8217743215572106

Epoch: 5| Step: 9
Training loss: 3.6162453530549072
Validation loss: 2.8224979046591168

Epoch: 5| Step: 10
Training loss: 3.3045749509868063
Validation loss: 2.829772864363532

Epoch: 139| Step: 0
Training loss: 2.7829792775935975
Validation loss: 2.823351182081299

Epoch: 5| Step: 1
Training loss: 3.4068555381161634
Validation loss: 2.8307111889180683

Epoch: 5| Step: 2
Training loss: 2.942210539627827
Validation loss: 2.8312728397026112

Epoch: 5| Step: 3
Training loss: 3.283894517707622
Validation loss: 2.8251894070000794

Epoch: 5| Step: 4
Training loss: 3.1447298923088853
Validation loss: 2.818547103735779

Epoch: 5| Step: 5
Training loss: 3.4005295902014216
Validation loss: 2.814184285664782

Epoch: 5| Step: 6
Training loss: 2.839226111157461
Validation loss: 2.819098149265173

Epoch: 5| Step: 7
Training loss: 3.5341093926502545
Validation loss: 2.81599505167724

Epoch: 5| Step: 8
Training loss: 3.017148438511471
Validation loss: 2.8140174559434348

Epoch: 5| Step: 9
Training loss: 2.74311330442093
Validation loss: 2.815780767945635

Epoch: 5| Step: 10
Training loss: 3.1736104192160295
Validation loss: 2.8150848415025203

Epoch: 140| Step: 0
Training loss: 3.8065892661844494
Validation loss: 2.818494841693006

Epoch: 5| Step: 1
Training loss: 2.7123986080222924
Validation loss: 2.814142286849434

Epoch: 5| Step: 2
Training loss: 2.733275448566129
Validation loss: 2.8181490553557107

Epoch: 5| Step: 3
Training loss: 3.34024962697335
Validation loss: 2.8194779757889696

Epoch: 5| Step: 4
Training loss: 2.7012434568595105
Validation loss: 2.8186904741961465

Epoch: 5| Step: 5
Training loss: 3.3704093512430044
Validation loss: 2.8287705558456406

Epoch: 5| Step: 6
Training loss: 3.291304813889119
Validation loss: 2.8194022078918284

Epoch: 5| Step: 7
Training loss: 2.977111765728188
Validation loss: 2.815689317666245

Epoch: 5| Step: 8
Training loss: 2.6314552498907777
Validation loss: 2.813130108288856

Epoch: 5| Step: 9
Training loss: 3.0636466857349345
Validation loss: 2.8124690565733683

Epoch: 5| Step: 10
Training loss: 3.5209013953016366
Validation loss: 2.8138375988019146

Epoch: 141| Step: 0
Training loss: 3.8587974703099044
Validation loss: 2.813159425059262

Epoch: 5| Step: 1
Training loss: 2.87103362766557
Validation loss: 2.8113954505796404

Epoch: 5| Step: 2
Training loss: 3.427474644050326
Validation loss: 2.812604847985234

Epoch: 5| Step: 3
Training loss: 2.5749986593002236
Validation loss: 2.8134875561099166

Epoch: 5| Step: 4
Training loss: 2.8974798630680363
Validation loss: 2.8115689740851977

Epoch: 5| Step: 5
Training loss: 2.717083475009271
Validation loss: 2.8126714929870524

Epoch: 5| Step: 6
Training loss: 3.4694780839996677
Validation loss: 2.811995013624484

Epoch: 5| Step: 7
Training loss: 2.71219124509041
Validation loss: 2.81179745922546

Epoch: 5| Step: 8
Training loss: 3.1704250084479044
Validation loss: 2.8121383872051187

Epoch: 5| Step: 9
Training loss: 3.0980345986824918
Validation loss: 2.8085559057027094

Epoch: 5| Step: 10
Training loss: 3.2980687298943505
Validation loss: 2.810231627364161

Epoch: 142| Step: 0
Training loss: 4.177002003069017
Validation loss: 2.808452746824587

Epoch: 5| Step: 1
Training loss: 2.663569340408571
Validation loss: 2.8077633366151447

Epoch: 5| Step: 2
Training loss: 3.346266468051748
Validation loss: 2.809703232096447

Epoch: 5| Step: 3
Training loss: 2.6261332654178795
Validation loss: 2.8087023263471855

Epoch: 5| Step: 4
Training loss: 2.20989663792893
Validation loss: 2.807902128408463

Epoch: 5| Step: 5
Training loss: 2.606961899093033
Validation loss: 2.8109616391844563

Epoch: 5| Step: 6
Training loss: 3.3949739893954822
Validation loss: 2.8134221141115225

Epoch: 5| Step: 7
Training loss: 3.001283212245219
Validation loss: 2.813297316405175

Epoch: 5| Step: 8
Training loss: 3.41520032973709
Validation loss: 2.8131083260131184

Epoch: 5| Step: 9
Training loss: 3.081346868574698
Validation loss: 2.8106070917685972

Epoch: 5| Step: 10
Training loss: 3.337546896158557
Validation loss: 2.808335708593303

Epoch: 143| Step: 0
Training loss: 3.117424136097578
Validation loss: 2.806055287595765

Epoch: 5| Step: 1
Training loss: 2.9840205915829756
Validation loss: 2.8071561674074887

Epoch: 5| Step: 2
Training loss: 2.899167855673606
Validation loss: 2.809914384621568

Epoch: 5| Step: 3
Training loss: 3.305376562691671
Validation loss: 2.8092818586119215

Epoch: 5| Step: 4
Training loss: 3.524706153255456
Validation loss: 2.8090050022978152

Epoch: 5| Step: 5
Training loss: 2.6249050849830127
Validation loss: 2.8078133697237244

Epoch: 5| Step: 6
Training loss: 2.8443503951213627
Validation loss: 2.8063868253615594

Epoch: 5| Step: 7
Training loss: 4.043550871437423
Validation loss: 2.8066669313620016

Epoch: 5| Step: 8
Training loss: 2.3556383872113544
Validation loss: 2.8076421945108283

Epoch: 5| Step: 9
Training loss: 3.0710384685128007
Validation loss: 2.8114178497827464

Epoch: 5| Step: 10
Training loss: 3.1859417266593164
Validation loss: 2.807899115476299

Epoch: 144| Step: 0
Training loss: 3.39211314368932
Validation loss: 2.8106554880875905

Epoch: 5| Step: 1
Training loss: 3.330218735576122
Validation loss: 2.809132252140566

Epoch: 5| Step: 2
Training loss: 3.5191236931063976
Validation loss: 2.809503157764541

Epoch: 5| Step: 3
Training loss: 3.027196001938968
Validation loss: 2.814939389446308

Epoch: 5| Step: 4
Training loss: 2.7815121302143884
Validation loss: 2.8109720872148136

Epoch: 5| Step: 5
Training loss: 3.1778592188905868
Validation loss: 2.813179140119373

Epoch: 5| Step: 6
Training loss: 3.002337975239616
Validation loss: 2.806601349508031

Epoch: 5| Step: 7
Training loss: 2.948909273394141
Validation loss: 2.807731795887204

Epoch: 5| Step: 8
Training loss: 3.281928582641252
Validation loss: 2.8070139051881084

Epoch: 5| Step: 9
Training loss: 2.807478172509527
Validation loss: 2.8064932728446292

Epoch: 5| Step: 10
Training loss: 2.828906546663544
Validation loss: 2.810443132429253

Epoch: 145| Step: 0
Training loss: 2.9201204468432915
Validation loss: 2.8095027827315504

Epoch: 5| Step: 1
Training loss: 3.2444062144351062
Validation loss: 2.8107578975661918

Epoch: 5| Step: 2
Training loss: 3.144341845761267
Validation loss: 2.816263968489587

Epoch: 5| Step: 3
Training loss: 3.13596753997936
Validation loss: 2.810666931457322

Epoch: 5| Step: 4
Training loss: 3.0930327537718965
Validation loss: 2.8056126825665255

Epoch: 5| Step: 5
Training loss: 2.749681454328985
Validation loss: 2.8061854173831478

Epoch: 5| Step: 6
Training loss: 2.895570720227258
Validation loss: 2.815046357736462

Epoch: 5| Step: 7
Training loss: 2.76400355852508
Validation loss: 2.8199740293585913

Epoch: 5| Step: 8
Training loss: 3.148530035812518
Validation loss: 2.808645003290681

Epoch: 5| Step: 9
Training loss: 4.021036383421786
Validation loss: 2.8046236844743206

Epoch: 5| Step: 10
Training loss: 2.9467451016385455
Validation loss: 2.806584041737353

Epoch: 146| Step: 0
Training loss: 2.9502672365343066
Validation loss: 2.801791847976259

Epoch: 5| Step: 1
Training loss: 3.492668920867808
Validation loss: 2.8045523828577945

Epoch: 5| Step: 2
Training loss: 3.2649894716522443
Validation loss: 2.8084040615138095

Epoch: 5| Step: 3
Training loss: 3.047083764382444
Validation loss: 2.8048685923560392

Epoch: 5| Step: 4
Training loss: 2.9288245799475563
Validation loss: 2.7999754546447617

Epoch: 5| Step: 5
Training loss: 3.3783659927553527
Validation loss: 2.8035385123334726

Epoch: 5| Step: 6
Training loss: 3.0628159029213604
Validation loss: 2.8033380400921377

Epoch: 5| Step: 7
Training loss: 3.5991364291005032
Validation loss: 2.805858882858617

Epoch: 5| Step: 8
Training loss: 3.124239562018468
Validation loss: 2.800611502297943

Epoch: 5| Step: 9
Training loss: 2.57931657477711
Validation loss: 2.80393433579239

Epoch: 5| Step: 10
Training loss: 2.514003633956286
Validation loss: 2.8044144756363933

Epoch: 147| Step: 0
Training loss: 3.0524157103352048
Validation loss: 2.801629556061642

Epoch: 5| Step: 1
Training loss: 2.965662585584072
Validation loss: 2.8001069290205853

Epoch: 5| Step: 2
Training loss: 3.1374381678594263
Validation loss: 2.799765164112553

Epoch: 5| Step: 3
Training loss: 2.8601388380056756
Validation loss: 2.8037534555727666

Epoch: 5| Step: 4
Training loss: 3.366763484305503
Validation loss: 2.798687489036308

Epoch: 5| Step: 5
Training loss: 3.4544433562691923
Validation loss: 2.799585563925279

Epoch: 5| Step: 6
Training loss: 3.3208454018584534
Validation loss: 2.7998328857096086

Epoch: 5| Step: 7
Training loss: 3.2218871892482053
Validation loss: 2.799403070253602

Epoch: 5| Step: 8
Training loss: 2.423164073834693
Validation loss: 2.803127461313425

Epoch: 5| Step: 9
Training loss: 2.892589829219653
Validation loss: 2.797491056517461

Epoch: 5| Step: 10
Training loss: 3.3877098102979635
Validation loss: 2.7995496307838064

Epoch: 148| Step: 0
Training loss: 2.982067234460807
Validation loss: 2.7987574497484964

Epoch: 5| Step: 1
Training loss: 2.8505593403499683
Validation loss: 2.799790892285948

Epoch: 5| Step: 2
Training loss: 3.1105448760079284
Validation loss: 2.7972511400178646

Epoch: 5| Step: 3
Training loss: 3.4354302851166234
Validation loss: 2.7987640796938473

Epoch: 5| Step: 4
Training loss: 3.101864432525005
Validation loss: 2.7975316558061194

Epoch: 5| Step: 5
Training loss: 3.185766010243295
Validation loss: 2.798869713361064

Epoch: 5| Step: 6
Training loss: 2.989341238677807
Validation loss: 2.799767738954988

Epoch: 5| Step: 7
Training loss: 3.158079768917065
Validation loss: 2.7984559767391906

Epoch: 5| Step: 8
Training loss: 2.658698625090636
Validation loss: 2.798055861833936

Epoch: 5| Step: 9
Training loss: 3.2790360020379667
Validation loss: 2.8069467491144

Epoch: 5| Step: 10
Training loss: 3.386673272519415
Validation loss: 2.805085535706803

Epoch: 149| Step: 0
Training loss: 2.577638152422527
Validation loss: 2.8007378337049538

Epoch: 5| Step: 1
Training loss: 3.5250933154585327
Validation loss: 2.7989614832889265

Epoch: 5| Step: 2
Training loss: 2.7314320449043166
Validation loss: 2.7953115816312635

Epoch: 5| Step: 3
Training loss: 3.6818738787598684
Validation loss: 2.7949214218787204

Epoch: 5| Step: 4
Training loss: 3.5225922443990436
Validation loss: 2.7964629044241756

Epoch: 5| Step: 5
Training loss: 3.256357137780937
Validation loss: 2.79673483048136

Epoch: 5| Step: 6
Training loss: 2.953604200125009
Validation loss: 2.7956280238656013

Epoch: 5| Step: 7
Training loss: 3.309040782503074
Validation loss: 2.796448685688329

Epoch: 5| Step: 8
Training loss: 2.617598225263493
Validation loss: 2.79602484798949

Epoch: 5| Step: 9
Training loss: 2.7572107279885514
Validation loss: 2.7955677127889524

Epoch: 5| Step: 10
Training loss: 2.9388875727739694
Validation loss: 2.7950683283873503

Epoch: 150| Step: 0
Training loss: 2.8889264039106144
Validation loss: 2.7947352387686295

Epoch: 5| Step: 1
Training loss: 3.811313381950449
Validation loss: 2.7948545774299642

Epoch: 5| Step: 2
Training loss: 3.0200403334595807
Validation loss: 2.7958126923112583

Epoch: 5| Step: 3
Training loss: 3.421116575037325
Validation loss: 2.794374085791403

Epoch: 5| Step: 4
Training loss: 3.4207863665449136
Validation loss: 2.795114527440991

Epoch: 5| Step: 5
Training loss: 2.8134415639907076
Validation loss: 2.793558245451095

Epoch: 5| Step: 6
Training loss: 2.7173961030668927
Validation loss: 2.797385213162017

Epoch: 5| Step: 7
Training loss: 3.548417751537819
Validation loss: 2.796891388919871

Epoch: 5| Step: 8
Training loss: 2.9148219860024054
Validation loss: 2.7999918849303023

Epoch: 5| Step: 9
Training loss: 2.8843503742262016
Validation loss: 2.800434596530217

Epoch: 5| Step: 10
Training loss: 2.322554304886219
Validation loss: 2.7940782083552085

Epoch: 151| Step: 0
Training loss: 3.0693387338915037
Validation loss: 2.79858227170598

Epoch: 5| Step: 1
Training loss: 3.1446144993347387
Validation loss: 2.794577246792281

Epoch: 5| Step: 2
Training loss: 3.110210057367854
Validation loss: 2.793566768551023

Epoch: 5| Step: 3
Training loss: 3.3349036014928526
Validation loss: 2.791264292101657

Epoch: 5| Step: 4
Training loss: 3.156556067404005
Validation loss: 2.7920066006360273

Epoch: 5| Step: 5
Training loss: 3.322366810490634
Validation loss: 2.7959611721682083

Epoch: 5| Step: 6
Training loss: 3.0994015331328764
Validation loss: 2.79465270343384

Epoch: 5| Step: 7
Training loss: 2.5917058956043415
Validation loss: 2.7923905106564084

Epoch: 5| Step: 8
Training loss: 3.0559655367221175
Validation loss: 2.7968686460595946

Epoch: 5| Step: 9
Training loss: 3.3937339768286137
Validation loss: 2.7924504698819224

Epoch: 5| Step: 10
Training loss: 2.6560055788567563
Validation loss: 2.7934068883013836

Epoch: 152| Step: 0
Training loss: 2.8386256400936647
Validation loss: 2.7981272639440937

Epoch: 5| Step: 1
Training loss: 2.8565578236388776
Validation loss: 2.8011985318417243

Epoch: 5| Step: 2
Training loss: 2.879141602542792
Validation loss: 2.8139384484569554

Epoch: 5| Step: 3
Training loss: 3.1327593791767385
Validation loss: 2.821888193255389

Epoch: 5| Step: 4
Training loss: 3.5054951173059785
Validation loss: 2.807122607940208

Epoch: 5| Step: 5
Training loss: 3.369931972281152
Validation loss: 2.7944216504255963

Epoch: 5| Step: 6
Training loss: 3.3317986929303522
Validation loss: 2.791767967662377

Epoch: 5| Step: 7
Training loss: 3.0371329254512967
Validation loss: 2.7908953138411596

Epoch: 5| Step: 8
Training loss: 3.5422297908915357
Validation loss: 2.792420704340662

Epoch: 5| Step: 9
Training loss: 2.8637040516943992
Validation loss: 2.79189259829044

Epoch: 5| Step: 10
Training loss: 2.489204079911194
Validation loss: 2.789654513664656

Epoch: 153| Step: 0
Training loss: 3.165424270516976
Validation loss: 2.791233389714325

Epoch: 5| Step: 1
Training loss: 2.9358783872296295
Validation loss: 2.789192722206123

Epoch: 5| Step: 2
Training loss: 3.548312261497053
Validation loss: 2.7904375137860864

Epoch: 5| Step: 3
Training loss: 3.174982662604146
Validation loss: 2.7890877560976337

Epoch: 5| Step: 4
Training loss: 2.8972278960251554
Validation loss: 2.7913476293019706

Epoch: 5| Step: 5
Training loss: 2.598763733167449
Validation loss: 2.789869227245808

Epoch: 5| Step: 6
Training loss: 2.9495973861868987
Validation loss: 2.792672187566456

Epoch: 5| Step: 7
Training loss: 3.529155954271893
Validation loss: 2.7884022500034873

Epoch: 5| Step: 8
Training loss: 3.0325250205370287
Validation loss: 2.792605808873331

Epoch: 5| Step: 9
Training loss: 3.243919847337808
Validation loss: 2.7991243860016457

Epoch: 5| Step: 10
Training loss: 2.8824618159839464
Validation loss: 2.8059995358087915

Epoch: 154| Step: 0
Training loss: 2.3679405500192128
Validation loss: 2.812165705093349

Epoch: 5| Step: 1
Training loss: 3.503002377626057
Validation loss: 2.8090808516809522

Epoch: 5| Step: 2
Training loss: 3.7748923330552975
Validation loss: 2.792810824239345

Epoch: 5| Step: 3
Training loss: 2.4330724950887554
Validation loss: 2.7892875512799775

Epoch: 5| Step: 4
Training loss: 3.0052677635694147
Validation loss: 2.786840419355078

Epoch: 5| Step: 5
Training loss: 3.619182917867092
Validation loss: 2.7876258542467967

Epoch: 5| Step: 6
Training loss: 3.1677494372973314
Validation loss: 2.791426252635878

Epoch: 5| Step: 7
Training loss: 2.6627032708313734
Validation loss: 2.7906997639598243

Epoch: 5| Step: 8
Training loss: 2.983059418391183
Validation loss: 2.7893016227008713

Epoch: 5| Step: 9
Training loss: 3.6214055623570127
Validation loss: 2.793535639724013

Epoch: 5| Step: 10
Training loss: 2.5202439830380126
Validation loss: 2.7896744150550608

Epoch: 155| Step: 0
Training loss: 3.197856906659707
Validation loss: 2.7925155385527245

Epoch: 5| Step: 1
Training loss: 3.0303554198042373
Validation loss: 2.789525127271566

Epoch: 5| Step: 2
Training loss: 3.1375279885065743
Validation loss: 2.792298172216364

Epoch: 5| Step: 3
Training loss: 2.804521561073018
Validation loss: 2.7963189902453145

Epoch: 5| Step: 4
Training loss: 3.7605053300346802
Validation loss: 2.79556200514126

Epoch: 5| Step: 5
Training loss: 2.868295730826077
Validation loss: 2.792549672902996

Epoch: 5| Step: 6
Training loss: 3.5650877003629655
Validation loss: 2.79325232718028

Epoch: 5| Step: 7
Training loss: 3.480141706760416
Validation loss: 2.784358518219831

Epoch: 5| Step: 8
Training loss: 2.4825942657183213
Validation loss: 2.7903265839820133

Epoch: 5| Step: 9
Training loss: 2.838973508877187
Validation loss: 2.7839911975554066

Epoch: 5| Step: 10
Training loss: 2.638439018540949
Validation loss: 2.7856556627683986

Epoch: 156| Step: 0
Training loss: 3.2682933947975874
Validation loss: 2.7847184126709426

Epoch: 5| Step: 1
Training loss: 3.133547575369567
Validation loss: 2.7871191416380867

Epoch: 5| Step: 2
Training loss: 3.3147447285819194
Validation loss: 2.78379737196489

Epoch: 5| Step: 3
Training loss: 3.098442141500085
Validation loss: 2.7857052858561797

Epoch: 5| Step: 4
Training loss: 3.07992532045068
Validation loss: 2.784792024623434

Epoch: 5| Step: 5
Training loss: 2.6543668466851007
Validation loss: 2.7876958479437315

Epoch: 5| Step: 6
Training loss: 3.1068204421212564
Validation loss: 2.7865095027855764

Epoch: 5| Step: 7
Training loss: 2.5498481667886694
Validation loss: 2.7922749035054397

Epoch: 5| Step: 8
Training loss: 3.3453373929005825
Validation loss: 2.7935179463224054

Epoch: 5| Step: 9
Training loss: 3.152434507290184
Validation loss: 2.794826330826616

Epoch: 5| Step: 10
Training loss: 3.2756714401927183
Validation loss: 2.797145870490929

Epoch: 157| Step: 0
Training loss: 3.384335357912885
Validation loss: 2.7969314478754734

Epoch: 5| Step: 1
Training loss: 3.135587077193767
Validation loss: 2.7921941363272333

Epoch: 5| Step: 2
Training loss: 2.1620161937562377
Validation loss: 2.79511006624347

Epoch: 5| Step: 3
Training loss: 3.183507026474084
Validation loss: 2.789857007544792

Epoch: 5| Step: 4
Training loss: 3.2187791841535716
Validation loss: 2.784098417520943

Epoch: 5| Step: 5
Training loss: 3.6259757734647673
Validation loss: 2.7850841011275547

Epoch: 5| Step: 6
Training loss: 3.262767508928851
Validation loss: 2.7852250456728873

Epoch: 5| Step: 7
Training loss: 2.9574050163178516
Validation loss: 2.7859440314044654

Epoch: 5| Step: 8
Training loss: 2.8627058130094993
Validation loss: 2.78143960846362

Epoch: 5| Step: 9
Training loss: 2.8094005884823443
Validation loss: 2.7829894447012853

Epoch: 5| Step: 10
Training loss: 3.2550463013058692
Validation loss: 2.784225838878639

Epoch: 158| Step: 0
Training loss: 3.012937939733662
Validation loss: 2.784438242112995

Epoch: 5| Step: 1
Training loss: 2.5100581017262824
Validation loss: 2.78436122055919

Epoch: 5| Step: 2
Training loss: 2.531521252827166
Validation loss: 2.785420228876991

Epoch: 5| Step: 3
Training loss: 2.9349974665720207
Validation loss: 2.7836593123384783

Epoch: 5| Step: 4
Training loss: 3.1812290513223878
Validation loss: 2.7845985503041932

Epoch: 5| Step: 5
Training loss: 3.3933496734385606
Validation loss: 2.7841269000365076

Epoch: 5| Step: 6
Training loss: 2.980853174698292
Validation loss: 2.7828397596052143

Epoch: 5| Step: 7
Training loss: 3.511822352085165
Validation loss: 2.785342481587071

Epoch: 5| Step: 8
Training loss: 3.6198919415021016
Validation loss: 2.7833031319722408

Epoch: 5| Step: 9
Training loss: 3.2795431874998626
Validation loss: 2.7822086985843755

Epoch: 5| Step: 10
Training loss: 2.896037215778793
Validation loss: 2.7864034704619502

Epoch: 159| Step: 0
Training loss: 2.7353920053463265
Validation loss: 2.782099103020242

Epoch: 5| Step: 1
Training loss: 3.694578456758569
Validation loss: 2.7840338298603684

Epoch: 5| Step: 2
Training loss: 3.268234013810939
Validation loss: 2.7917437009386896

Epoch: 5| Step: 3
Training loss: 2.7051049186398686
Validation loss: 2.792508498095994

Epoch: 5| Step: 4
Training loss: 3.145055274659583
Validation loss: 2.7918210569277395

Epoch: 5| Step: 5
Training loss: 3.2524787546764364
Validation loss: 2.8008539208107215

Epoch: 5| Step: 6
Training loss: 2.614565683333157
Validation loss: 2.8112860316824597

Epoch: 5| Step: 7
Training loss: 3.3617719748448214
Validation loss: 2.8237759750783846

Epoch: 5| Step: 8
Training loss: 3.068249501981332
Validation loss: 2.8005568541343604

Epoch: 5| Step: 9
Training loss: 2.689225995481404
Validation loss: 2.782000092229077

Epoch: 5| Step: 10
Training loss: 3.3954762152056586
Validation loss: 2.7794835637423754

Epoch: 160| Step: 0
Training loss: 2.6749776037116435
Validation loss: 2.779635986171006

Epoch: 5| Step: 1
Training loss: 3.1742468173349154
Validation loss: 2.779839154504659

Epoch: 5| Step: 2
Training loss: 2.623080778151385
Validation loss: 2.7844320991758207

Epoch: 5| Step: 3
Training loss: 2.848937114146061
Validation loss: 2.781940217861076

Epoch: 5| Step: 4
Training loss: 2.9844232525344916
Validation loss: 2.783406906108542

Epoch: 5| Step: 5
Training loss: 3.7763464793684873
Validation loss: 2.783455858253369

Epoch: 5| Step: 6
Training loss: 3.350035134885642
Validation loss: 2.77919473693086

Epoch: 5| Step: 7
Training loss: 3.058255738426905
Validation loss: 2.7804736327787083

Epoch: 5| Step: 8
Training loss: 4.022479311722115
Validation loss: 2.7790049420920084

Epoch: 5| Step: 9
Training loss: 2.368687824651158
Validation loss: 2.7793369643286088

Epoch: 5| Step: 10
Training loss: 2.754010224239566
Validation loss: 2.780233547938065

Epoch: 161| Step: 0
Training loss: 3.5603871019332707
Validation loss: 2.781782933630913

Epoch: 5| Step: 1
Training loss: 2.1689514682206656
Validation loss: 2.7919956050828456

Epoch: 5| Step: 2
Training loss: 2.8161565958340318
Validation loss: 2.7954947780051405

Epoch: 5| Step: 3
Training loss: 2.98073367720005
Validation loss: 2.805194503730411

Epoch: 5| Step: 4
Training loss: 2.7835645153256685
Validation loss: 2.83737956735578

Epoch: 5| Step: 5
Training loss: 3.1481294315587913
Validation loss: 2.8381493566664835

Epoch: 5| Step: 6
Training loss: 3.1268277735844645
Validation loss: 2.8313475338876324

Epoch: 5| Step: 7
Training loss: 3.5971252513434306
Validation loss: 2.8010318508006784

Epoch: 5| Step: 8
Training loss: 3.0919631267485794
Validation loss: 2.7813036642581115

Epoch: 5| Step: 9
Training loss: 3.3718844974868416
Validation loss: 2.774973010820931

Epoch: 5| Step: 10
Training loss: 3.119487630881654
Validation loss: 2.7791993417479604

Epoch: 162| Step: 0
Training loss: 2.975393150702125
Validation loss: 2.784266435474648

Epoch: 5| Step: 1
Training loss: 2.8588142887521117
Validation loss: 2.784310242119533

Epoch: 5| Step: 2
Training loss: 2.1080771515497214
Validation loss: 2.789832398900397

Epoch: 5| Step: 3
Training loss: 3.6985264808126574
Validation loss: 2.7904849305426525

Epoch: 5| Step: 4
Training loss: 3.4547261802271216
Validation loss: 2.791505779270242

Epoch: 5| Step: 5
Training loss: 3.3032604409909347
Validation loss: 2.7999394807266818

Epoch: 5| Step: 6
Training loss: 3.2854532114406116
Validation loss: 2.7920766084682658

Epoch: 5| Step: 7
Training loss: 3.54916240858181
Validation loss: 2.790296769139836

Epoch: 5| Step: 8
Training loss: 2.786732531214829
Validation loss: 2.781141328088495

Epoch: 5| Step: 9
Training loss: 3.1877887071496227
Validation loss: 2.778386069181638

Epoch: 5| Step: 10
Training loss: 2.5306836660287835
Validation loss: 2.7748992649615962

Epoch: 163| Step: 0
Training loss: 3.469251716689765
Validation loss: 2.7786275130692832

Epoch: 5| Step: 1
Training loss: 2.6533718897383958
Validation loss: 2.77442259127983

Epoch: 5| Step: 2
Training loss: 2.3005399982280825
Validation loss: 2.777654745768133

Epoch: 5| Step: 3
Training loss: 3.3601114574747117
Validation loss: 2.7770115633059587

Epoch: 5| Step: 4
Training loss: 2.8907592742251222
Validation loss: 2.782662906948769

Epoch: 5| Step: 5
Training loss: 3.2113399207034607
Validation loss: 2.7858635886509764

Epoch: 5| Step: 6
Training loss: 3.0462054177122417
Validation loss: 2.795517200068904

Epoch: 5| Step: 7
Training loss: 3.7134184243972994
Validation loss: 2.7972374495211554

Epoch: 5| Step: 8
Training loss: 3.4876374849954814
Validation loss: 2.7965316740477517

Epoch: 5| Step: 9
Training loss: 3.0671569294117758
Validation loss: 2.7839972991063924

Epoch: 5| Step: 10
Training loss: 2.3956823771368407
Validation loss: 2.7765675804045586

Epoch: 164| Step: 0
Training loss: 2.816839473171083
Validation loss: 2.7745167979016796

Epoch: 5| Step: 1
Training loss: 3.1427447249383667
Validation loss: 2.772796712125701

Epoch: 5| Step: 2
Training loss: 2.9540353814900753
Validation loss: 2.778745280397379

Epoch: 5| Step: 3
Training loss: 2.911861457735902
Validation loss: 2.7744026608756975

Epoch: 5| Step: 4
Training loss: 3.140045871764014
Validation loss: 2.7732246507897753

Epoch: 5| Step: 5
Training loss: 2.894125638437207
Validation loss: 2.7731274475539323

Epoch: 5| Step: 6
Training loss: 3.484364325673812
Validation loss: 2.774223993270984

Epoch: 5| Step: 7
Training loss: 3.2718140575486334
Validation loss: 2.7733590988038257

Epoch: 5| Step: 8
Training loss: 3.279254124665507
Validation loss: 2.7737841687439047

Epoch: 5| Step: 9
Training loss: 2.835898491036808
Validation loss: 2.773908551942967

Epoch: 5| Step: 10
Training loss: 3.217757136718954
Validation loss: 2.7728616133046526

Epoch: 165| Step: 0
Training loss: 3.2901392100834452
Validation loss: 2.7744839182561214

Epoch: 5| Step: 1
Training loss: 3.2781681665245817
Validation loss: 2.7767425897705795

Epoch: 5| Step: 2
Training loss: 3.0274584151671524
Validation loss: 2.778253040947911

Epoch: 5| Step: 3
Training loss: 3.1353393409969397
Validation loss: 2.781784135373373

Epoch: 5| Step: 4
Training loss: 3.102382753233165
Validation loss: 2.7910486258672824

Epoch: 5| Step: 5
Training loss: 3.04450669801213
Validation loss: 2.786982513214218

Epoch: 5| Step: 6
Training loss: 3.2592550692707962
Validation loss: 2.780087843821963

Epoch: 5| Step: 7
Training loss: 2.7484255531836443
Validation loss: 2.783370416863449

Epoch: 5| Step: 8
Training loss: 2.989805064911737
Validation loss: 2.782553574347287

Epoch: 5| Step: 9
Training loss: 3.052602226926227
Validation loss: 2.782328690626268

Epoch: 5| Step: 10
Training loss: 3.003055764629767
Validation loss: 2.7713131325348734

Epoch: 166| Step: 0
Training loss: 3.679865158554596
Validation loss: 2.7749873876354325

Epoch: 5| Step: 1
Training loss: 1.8871395676411848
Validation loss: 2.775366588259046

Epoch: 5| Step: 2
Training loss: 3.149925315819291
Validation loss: 2.773882650249903

Epoch: 5| Step: 3
Training loss: 3.067073287819586
Validation loss: 2.7708813847173275

Epoch: 5| Step: 4
Training loss: 3.454820725776291
Validation loss: 2.7714499451249255

Epoch: 5| Step: 5
Training loss: 3.224654032757847
Validation loss: 2.7703094326382853

Epoch: 5| Step: 6
Training loss: 3.205347397376174
Validation loss: 2.7718972837245572

Epoch: 5| Step: 7
Training loss: 3.239787268071532
Validation loss: 2.7713763811800436

Epoch: 5| Step: 8
Training loss: 3.1351524233230292
Validation loss: 2.773024326937579

Epoch: 5| Step: 9
Training loss: 2.943228310525437
Validation loss: 2.774396010599576

Epoch: 5| Step: 10
Training loss: 2.5070633289142834
Validation loss: 2.7693590239966235

Epoch: 167| Step: 0
Training loss: 2.9153953142862137
Validation loss: 2.7702922738432005

Epoch: 5| Step: 1
Training loss: 2.9433480346704233
Validation loss: 2.772926831925772

Epoch: 5| Step: 2
Training loss: 3.3095986957970718
Validation loss: 2.773803135920168

Epoch: 5| Step: 3
Training loss: 2.412234110830983
Validation loss: 2.776653504419172

Epoch: 5| Step: 4
Training loss: 3.0929843456070722
Validation loss: 2.7785215416418727

Epoch: 5| Step: 5
Training loss: 3.1493678836246253
Validation loss: 2.7742374110671313

Epoch: 5| Step: 6
Training loss: 3.459062399864626
Validation loss: 2.7807716657911214

Epoch: 5| Step: 7
Training loss: 2.8510159739538876
Validation loss: 2.780486204435792

Epoch: 5| Step: 8
Training loss: 3.059577325787924
Validation loss: 2.772079486090321

Epoch: 5| Step: 9
Training loss: 3.160176469245422
Validation loss: 2.7701242023516888

Epoch: 5| Step: 10
Training loss: 3.448473805632684
Validation loss: 2.769447324810026

Epoch: 168| Step: 0
Training loss: 2.687067041342283
Validation loss: 2.768455058960914

Epoch: 5| Step: 1
Training loss: 2.822362434812358
Validation loss: 2.7684343197726275

Epoch: 5| Step: 2
Training loss: 3.422987247667287
Validation loss: 2.7696483951821564

Epoch: 5| Step: 3
Training loss: 2.6606602576412866
Validation loss: 2.7665954068309224

Epoch: 5| Step: 4
Training loss: 3.1412665627555603
Validation loss: 2.7697074065007747

Epoch: 5| Step: 5
Training loss: 3.0134603212262445
Validation loss: 2.766375119750765

Epoch: 5| Step: 6
Training loss: 3.3028363032209187
Validation loss: 2.7654038188966727

Epoch: 5| Step: 7
Training loss: 3.164107861605778
Validation loss: 2.767064084371661

Epoch: 5| Step: 8
Training loss: 3.184886833587848
Validation loss: 2.767071259054552

Epoch: 5| Step: 9
Training loss: 3.160503127931925
Validation loss: 2.7663065901994

Epoch: 5| Step: 10
Training loss: 3.255717164007672
Validation loss: 2.767017821858738

Epoch: 169| Step: 0
Training loss: 2.7029156024950955
Validation loss: 2.7707868675933005

Epoch: 5| Step: 1
Training loss: 3.3031943264329318
Validation loss: 2.771822039097116

Epoch: 5| Step: 2
Training loss: 2.833657433167842
Validation loss: 2.7764505932735966

Epoch: 5| Step: 3
Training loss: 2.823768674831772
Validation loss: 2.7906969529285566

Epoch: 5| Step: 4
Training loss: 2.643414981618506
Validation loss: 2.7862543653409437

Epoch: 5| Step: 5
Training loss: 3.7356606030247463
Validation loss: 2.7850333669668927

Epoch: 5| Step: 6
Training loss: 3.754322231398804
Validation loss: 2.7676311419555284

Epoch: 5| Step: 7
Training loss: 2.9422985410476072
Validation loss: 2.770014627507706

Epoch: 5| Step: 8
Training loss: 2.68127269957566
Validation loss: 2.769815342293306

Epoch: 5| Step: 9
Training loss: 3.3323060042055057
Validation loss: 2.7663742171304486

Epoch: 5| Step: 10
Training loss: 2.8104571234692206
Validation loss: 2.765190274347459

Epoch: 170| Step: 0
Training loss: 3.1430361777252496
Validation loss: 2.7672684897689717

Epoch: 5| Step: 1
Training loss: 2.5079830503849236
Validation loss: 2.7654226247711513

Epoch: 5| Step: 2
Training loss: 3.27930676275311
Validation loss: 2.7644338246988953

Epoch: 5| Step: 3
Training loss: 3.6073198288558017
Validation loss: 2.7639348968976565

Epoch: 5| Step: 4
Training loss: 2.4788473762472316
Validation loss: 2.7648730188735664

Epoch: 5| Step: 5
Training loss: 3.4477504140795405
Validation loss: 2.7635826744330045

Epoch: 5| Step: 6
Training loss: 2.996248920107867
Validation loss: 2.7664069392455226

Epoch: 5| Step: 7
Training loss: 3.167989069900538
Validation loss: 2.762680784490654

Epoch: 5| Step: 8
Training loss: 3.3023653281025567
Validation loss: 2.7649865683210617

Epoch: 5| Step: 9
Training loss: 3.303232003231879
Validation loss: 2.765658518891253

Epoch: 5| Step: 10
Training loss: 2.197147783298345
Validation loss: 2.765928157845893

Epoch: 171| Step: 0
Training loss: 2.7894955253503646
Validation loss: 2.766112939723267

Epoch: 5| Step: 1
Training loss: 3.445189181865102
Validation loss: 2.770378275890773

Epoch: 5| Step: 2
Training loss: 3.1810491772051956
Validation loss: 2.7686996587235413

Epoch: 5| Step: 3
Training loss: 3.475709137497539
Validation loss: 2.7684629782599055

Epoch: 5| Step: 4
Training loss: 2.827680099647264
Validation loss: 2.779244799148382

Epoch: 5| Step: 5
Training loss: 2.97183886003632
Validation loss: 2.7686677942803963

Epoch: 5| Step: 6
Training loss: 2.671640396972632
Validation loss: 2.776716544633458

Epoch: 5| Step: 7
Training loss: 2.8431855364627503
Validation loss: 2.7744000283033823

Epoch: 5| Step: 8
Training loss: 2.698391601313513
Validation loss: 2.7789111551556793

Epoch: 5| Step: 9
Training loss: 3.246785261219273
Validation loss: 2.7674822685814253

Epoch: 5| Step: 10
Training loss: 3.54749000359727
Validation loss: 2.766613794106474

Epoch: 172| Step: 0
Training loss: 3.057060861188208
Validation loss: 2.760710364002919

Epoch: 5| Step: 1
Training loss: 3.2869973846415856
Validation loss: 2.7644436222983444

Epoch: 5| Step: 2
Training loss: 2.802507748895119
Validation loss: 2.76098126801559

Epoch: 5| Step: 3
Training loss: 3.0706904909063013
Validation loss: 2.7617039866394495

Epoch: 5| Step: 4
Training loss: 2.6715674864726573
Validation loss: 2.7614217131603205

Epoch: 5| Step: 5
Training loss: 2.9699860258447983
Validation loss: 2.7596472669573013

Epoch: 5| Step: 6
Training loss: 2.51342867109699
Validation loss: 2.758460093072312

Epoch: 5| Step: 7
Training loss: 3.1419116369068782
Validation loss: 2.7625368031106863

Epoch: 5| Step: 8
Training loss: 3.3799659081720446
Validation loss: 2.7598165282660965

Epoch: 5| Step: 9
Training loss: 3.0391913143992793
Validation loss: 2.7607477479846896

Epoch: 5| Step: 10
Training loss: 3.783138465624203
Validation loss: 2.7630816593653913

Epoch: 173| Step: 0
Training loss: 3.195967851880539
Validation loss: 2.757801400648327

Epoch: 5| Step: 1
Training loss: 2.743211690802261
Validation loss: 2.7609674877389683

Epoch: 5| Step: 2
Training loss: 3.1075747084901524
Validation loss: 2.7612525483904746

Epoch: 5| Step: 3
Training loss: 2.9181030732763107
Validation loss: 2.758781093128893

Epoch: 5| Step: 4
Training loss: 3.180492252421377
Validation loss: 2.758490429526221

Epoch: 5| Step: 5
Training loss: 2.7994450530110213
Validation loss: 2.764524202411234

Epoch: 5| Step: 6
Training loss: 3.221423473964328
Validation loss: 2.7675876965646253

Epoch: 5| Step: 7
Training loss: 3.107505965039151
Validation loss: 2.7677310530219144

Epoch: 5| Step: 8
Training loss: 3.039572861679338
Validation loss: 2.774464876268829

Epoch: 5| Step: 9
Training loss: 3.4275038595476963
Validation loss: 2.7755185606581003

Epoch: 5| Step: 10
Training loss: 3.009439558404268
Validation loss: 2.783915659136125

Epoch: 174| Step: 0
Training loss: 2.9378244748382256
Validation loss: 2.772296137888199

Epoch: 5| Step: 1
Training loss: 3.45510434690092
Validation loss: 2.769870557173184

Epoch: 5| Step: 2
Training loss: 3.096039974526289
Validation loss: 2.7583953000850725

Epoch: 5| Step: 3
Training loss: 3.184664493537956
Validation loss: 2.7626076533252943

Epoch: 5| Step: 4
Training loss: 2.8690252832712724
Validation loss: 2.7657716069273297

Epoch: 5| Step: 5
Training loss: 3.4093212315753996
Validation loss: 2.7641441552458685

Epoch: 5| Step: 6
Training loss: 3.0283193677441287
Validation loss: 2.7567590886572857

Epoch: 5| Step: 7
Training loss: 3.2964970521200576
Validation loss: 2.7537286833104515

Epoch: 5| Step: 8
Training loss: 2.573353461333438
Validation loss: 2.753951328978893

Epoch: 5| Step: 9
Training loss: 2.803740700218638
Validation loss: 2.7564646860341884

Epoch: 5| Step: 10
Training loss: 2.99471723823387
Validation loss: 2.7562897033711447

Epoch: 175| Step: 0
Training loss: 3.543045463698838
Validation loss: 2.760717958216551

Epoch: 5| Step: 1
Training loss: 3.266533392179189
Validation loss: 2.758923898055888

Epoch: 5| Step: 2
Training loss: 3.343402309701392
Validation loss: 2.76070954589184

Epoch: 5| Step: 3
Training loss: 2.4157934803705854
Validation loss: 2.75639289480151

Epoch: 5| Step: 4
Training loss: 2.809316741033776
Validation loss: 2.7548908192042685

Epoch: 5| Step: 5
Training loss: 3.0704771196723875
Validation loss: 2.75569343743203

Epoch: 5| Step: 6
Training loss: 3.162671195360944
Validation loss: 2.7574882522380513

Epoch: 5| Step: 7
Training loss: 2.5051778578672494
Validation loss: 2.7601467849639145

Epoch: 5| Step: 8
Training loss: 2.839773562900712
Validation loss: 2.759941050503476

Epoch: 5| Step: 9
Training loss: 3.3794589786808222
Validation loss: 2.7663921267676326

Epoch: 5| Step: 10
Training loss: 3.275035531819491
Validation loss: 2.775375581508764

Epoch: 176| Step: 0
Training loss: 3.03876421329967
Validation loss: 2.7887393558206197

Epoch: 5| Step: 1
Training loss: 2.6508813795835993
Validation loss: 2.804651135885789

Epoch: 5| Step: 2
Training loss: 3.5244817095717713
Validation loss: 2.8306690123674216

Epoch: 5| Step: 3
Training loss: 2.858910361305421
Validation loss: 2.821979654321307

Epoch: 5| Step: 4
Training loss: 3.0621241124749004
Validation loss: 2.807093960566715

Epoch: 5| Step: 5
Training loss: 3.379540814917012
Validation loss: 2.777091253481499

Epoch: 5| Step: 6
Training loss: 3.001930728151243
Validation loss: 2.7646642320457433

Epoch: 5| Step: 7
Training loss: 2.7124952957886017
Validation loss: 2.759427239048241

Epoch: 5| Step: 8
Training loss: 3.3134810236578427
Validation loss: 2.754712147097831

Epoch: 5| Step: 9
Training loss: 2.886746830990787
Validation loss: 2.752895229509699

Epoch: 5| Step: 10
Training loss: 3.391113949165251
Validation loss: 2.7546362348161955

Epoch: 177| Step: 0
Training loss: 3.367667816670388
Validation loss: 2.7541219921924798

Epoch: 5| Step: 1
Training loss: 3.1553944854044014
Validation loss: 2.752225441500086

Epoch: 5| Step: 2
Training loss: 2.626318918129118
Validation loss: 2.7517501243934177

Epoch: 5| Step: 3
Training loss: 2.4966537014667467
Validation loss: 2.7538918552911205

Epoch: 5| Step: 4
Training loss: 3.149642827205149
Validation loss: 2.7555279392365772

Epoch: 5| Step: 5
Training loss: 3.3923358029102944
Validation loss: 2.7529423421030885

Epoch: 5| Step: 6
Training loss: 2.9306033724659817
Validation loss: 2.7535730755452628

Epoch: 5| Step: 7
Training loss: 2.5082714575890814
Validation loss: 2.7564306861105967

Epoch: 5| Step: 8
Training loss: 3.2822108723777017
Validation loss: 2.7625748509448793

Epoch: 5| Step: 9
Training loss: 2.789683211468485
Validation loss: 2.777020046258688

Epoch: 5| Step: 10
Training loss: 3.9250373401202046
Validation loss: 2.785004120488586

Epoch: 178| Step: 0
Training loss: 2.705040490064236
Validation loss: 2.7808946633915035

Epoch: 5| Step: 1
Training loss: 3.6040566635249958
Validation loss: 2.7611160615115273

Epoch: 5| Step: 2
Training loss: 2.7770819131476014
Validation loss: 2.755600660083737

Epoch: 5| Step: 3
Training loss: 3.123718304055412
Validation loss: 2.7550963910914676

Epoch: 5| Step: 4
Training loss: 3.275557457457355
Validation loss: 2.746815258074888

Epoch: 5| Step: 5
Training loss: 3.4177100906592335
Validation loss: 2.7451317580309875

Epoch: 5| Step: 6
Training loss: 3.0788268242875625
Validation loss: 2.749942557069628

Epoch: 5| Step: 7
Training loss: 2.2936356726486524
Validation loss: 2.7504141077192275

Epoch: 5| Step: 8
Training loss: 3.0176795720204703
Validation loss: 2.752321892613833

Epoch: 5| Step: 9
Training loss: 3.163335570671917
Validation loss: 2.7497509967614824

Epoch: 5| Step: 10
Training loss: 3.1574786221587705
Validation loss: 2.7481456174187637

Epoch: 179| Step: 0
Training loss: 3.1090507913381082
Validation loss: 2.7501394212270203

Epoch: 5| Step: 1
Training loss: 3.137655344001195
Validation loss: 2.750408982137247

Epoch: 5| Step: 2
Training loss: 3.1733896932752748
Validation loss: 2.7511334204367945

Epoch: 5| Step: 3
Training loss: 3.3366749861769436
Validation loss: 2.7546570052958956

Epoch: 5| Step: 4
Training loss: 2.79178894306581
Validation loss: 2.759493430144401

Epoch: 5| Step: 5
Training loss: 3.241707419275759
Validation loss: 2.7604361987143653

Epoch: 5| Step: 6
Training loss: 3.2467300397365553
Validation loss: 2.7608331085622275

Epoch: 5| Step: 7
Training loss: 2.6202308382742743
Validation loss: 2.756119204150853

Epoch: 5| Step: 8
Training loss: 3.0195768878443885
Validation loss: 2.752325841012779

Epoch: 5| Step: 9
Training loss: 2.6966795177491436
Validation loss: 2.747856141622144

Epoch: 5| Step: 10
Training loss: 3.3273856187932807
Validation loss: 2.7487693570555467

Epoch: 180| Step: 0
Training loss: 3.332626522149281
Validation loss: 2.7551348357128047

Epoch: 5| Step: 1
Training loss: 3.1250874316382413
Validation loss: 2.7480708838943833

Epoch: 5| Step: 2
Training loss: 3.1542279404232163
Validation loss: 2.7528854755534646

Epoch: 5| Step: 3
Training loss: 3.422057543201092
Validation loss: 2.753091355480291

Epoch: 5| Step: 4
Training loss: 2.9019967406955876
Validation loss: 2.7522794229823107

Epoch: 5| Step: 5
Training loss: 3.019282835381087
Validation loss: 2.7498178897196013

Epoch: 5| Step: 6
Training loss: 3.0436992037879906
Validation loss: 2.749669203341533

Epoch: 5| Step: 7
Training loss: 3.1548765612363003
Validation loss: 2.747325675444543

Epoch: 5| Step: 8
Training loss: 3.302327785809828
Validation loss: 2.7484269084937494

Epoch: 5| Step: 9
Training loss: 2.6285504444688583
Validation loss: 2.7463227826236913

Epoch: 5| Step: 10
Training loss: 2.3714605358812504
Validation loss: 2.744838336788238

Epoch: 181| Step: 0
Training loss: 3.1889713855606803
Validation loss: 2.7469061277383844

Epoch: 5| Step: 1
Training loss: 3.247697748355418
Validation loss: 2.7462102192890683

Epoch: 5| Step: 2
Training loss: 3.5218393968815156
Validation loss: 2.74838950336852

Epoch: 5| Step: 3
Training loss: 2.9605867283775216
Validation loss: 2.751497117520663

Epoch: 5| Step: 4
Training loss: 3.1054119368820445
Validation loss: 2.751700887707692

Epoch: 5| Step: 5
Training loss: 3.1757970154993824
Validation loss: 2.7522470545261144

Epoch: 5| Step: 6
Training loss: 2.622010208662864
Validation loss: 2.745973422806675

Epoch: 5| Step: 7
Training loss: 3.185176526122764
Validation loss: 2.746054375931798

Epoch: 5| Step: 8
Training loss: 2.844118031591606
Validation loss: 2.747975257543025

Epoch: 5| Step: 9
Training loss: 3.0187970017590766
Validation loss: 2.7468826173071514

Epoch: 5| Step: 10
Training loss: 2.6372907004091064
Validation loss: 2.7465860537044917

Epoch: 182| Step: 0
Training loss: 3.4020704472786965
Validation loss: 2.7495006973112983

Epoch: 5| Step: 1
Training loss: 2.3811677853466473
Validation loss: 2.753864743174405

Epoch: 5| Step: 2
Training loss: 2.7328209520823235
Validation loss: 2.7540310543617816

Epoch: 5| Step: 3
Training loss: 3.609943559791872
Validation loss: 2.7501215194746145

Epoch: 5| Step: 4
Training loss: 2.7837788946658835
Validation loss: 2.747918686567516

Epoch: 5| Step: 5
Training loss: 3.1971976168698673
Validation loss: 2.752570908232084

Epoch: 5| Step: 6
Training loss: 3.1210662496832886
Validation loss: 2.747805898452845

Epoch: 5| Step: 7
Training loss: 2.945641132507243
Validation loss: 2.7470063838289893

Epoch: 5| Step: 8
Training loss: 3.1176023278959657
Validation loss: 2.7517340526239056

Epoch: 5| Step: 9
Training loss: 2.6867381058306576
Validation loss: 2.7492738624590527

Epoch: 5| Step: 10
Training loss: 3.5020178019247075
Validation loss: 2.7492022751004233

Epoch: 183| Step: 0
Training loss: 2.8892228308464163
Validation loss: 2.7489186796433

Epoch: 5| Step: 1
Training loss: 3.49963867502245
Validation loss: 2.7488747081500855

Epoch: 5| Step: 2
Training loss: 2.9437290458176393
Validation loss: 2.747818584116442

Epoch: 5| Step: 3
Training loss: 2.753428143061203
Validation loss: 2.759447358440563

Epoch: 5| Step: 4
Training loss: 2.625937430706248
Validation loss: 2.7556507685754488

Epoch: 5| Step: 5
Training loss: 3.4743878710488283
Validation loss: 2.759513564847453

Epoch: 5| Step: 6
Training loss: 2.3262951719724505
Validation loss: 2.747011283381249

Epoch: 5| Step: 7
Training loss: 2.797793019266437
Validation loss: 2.7447377558588197

Epoch: 5| Step: 8
Training loss: 3.0897003796442983
Validation loss: 2.7442142482972782

Epoch: 5| Step: 9
Training loss: 3.6114097243519123
Validation loss: 2.7478022421122206

Epoch: 5| Step: 10
Training loss: 3.4264632169340374
Validation loss: 2.743558895240975

Epoch: 184| Step: 0
Training loss: 2.890658981535902
Validation loss: 2.7436066045231433

Epoch: 5| Step: 1
Training loss: 3.447161604308783
Validation loss: 2.7459023842680015

Epoch: 5| Step: 2
Training loss: 2.628181618387926
Validation loss: 2.7436960387372697

Epoch: 5| Step: 3
Training loss: 2.4859243875729566
Validation loss: 2.7415566953054165

Epoch: 5| Step: 4
Training loss: 2.6331583129890666
Validation loss: 2.7463464079972906

Epoch: 5| Step: 5
Training loss: 3.2812261671381493
Validation loss: 2.74417559276249

Epoch: 5| Step: 6
Training loss: 3.391570491192615
Validation loss: 2.739242576188387

Epoch: 5| Step: 7
Training loss: 3.3377506233439327
Validation loss: 2.743936723147601

Epoch: 5| Step: 8
Training loss: 2.724619875651808
Validation loss: 2.744964962758152

Epoch: 5| Step: 9
Training loss: 3.56230363806594
Validation loss: 2.7545514705009135

Epoch: 5| Step: 10
Training loss: 3.0979822667933736
Validation loss: 2.7522900583821817

Epoch: 185| Step: 0
Training loss: 3.7083227321744685
Validation loss: 2.7536858238802115

Epoch: 5| Step: 1
Training loss: 3.1709859569843712
Validation loss: 2.7482044346717323

Epoch: 5| Step: 2
Training loss: 3.5175411173702202
Validation loss: 2.747222831180728

Epoch: 5| Step: 3
Training loss: 3.0339877949156726
Validation loss: 2.7412094392740283

Epoch: 5| Step: 4
Training loss: 2.566983928723732
Validation loss: 2.740876160907246

Epoch: 5| Step: 5
Training loss: 2.625162210448061
Validation loss: 2.739692460916264

Epoch: 5| Step: 6
Training loss: 3.1087869826181236
Validation loss: 2.737203048623061

Epoch: 5| Step: 7
Training loss: 2.563799830807532
Validation loss: 2.7380627082131053

Epoch: 5| Step: 8
Training loss: 3.1282397452087043
Validation loss: 2.7404098168650317

Epoch: 5| Step: 9
Training loss: 2.8315181714646425
Validation loss: 2.7394394905628823

Epoch: 5| Step: 10
Training loss: 3.2092129050738865
Validation loss: 2.7388200033724592

Epoch: 186| Step: 0
Training loss: 2.203006064809658
Validation loss: 2.7419723362288946

Epoch: 5| Step: 1
Training loss: 2.6609496783315527
Validation loss: 2.7455176985918985

Epoch: 5| Step: 2
Training loss: 3.6185115755430255
Validation loss: 2.7412593142341013

Epoch: 5| Step: 3
Training loss: 3.252098872953861
Validation loss: 2.7419095546647334

Epoch: 5| Step: 4
Training loss: 2.8891198440893278
Validation loss: 2.737847373844953

Epoch: 5| Step: 5
Training loss: 2.9666408073355517
Validation loss: 2.742607061931121

Epoch: 5| Step: 6
Training loss: 3.0854488710263492
Validation loss: 2.7405073021658244

Epoch: 5| Step: 7
Training loss: 3.1524692968919905
Validation loss: 2.742788465802612

Epoch: 5| Step: 8
Training loss: 3.545767455753516
Validation loss: 2.738762580560109

Epoch: 5| Step: 9
Training loss: 2.887230607053774
Validation loss: 2.7508286843117356

Epoch: 5| Step: 10
Training loss: 3.0754316135593354
Validation loss: 2.740363523486718

Epoch: 187| Step: 0
Training loss: 2.726889167170037
Validation loss: 2.74822018473163

Epoch: 5| Step: 1
Training loss: 3.7581568696970296
Validation loss: 2.7407739043073165

Epoch: 5| Step: 2
Training loss: 2.967984391924595
Validation loss: 2.737514389464017

Epoch: 5| Step: 3
Training loss: 3.2484492490261463
Validation loss: 2.740604227418804

Epoch: 5| Step: 4
Training loss: 2.813049008509038
Validation loss: 2.736725622640755

Epoch: 5| Step: 5
Training loss: 2.74442558573817
Validation loss: 2.7395475876446462

Epoch: 5| Step: 6
Training loss: 2.7765291416995845
Validation loss: 2.736870125418657

Epoch: 5| Step: 7
Training loss: 3.539497938168191
Validation loss: 2.737955921427211

Epoch: 5| Step: 8
Training loss: 2.808492390762732
Validation loss: 2.7387146530348705

Epoch: 5| Step: 9
Training loss: 2.635183019923366
Validation loss: 2.7366816360327824

Epoch: 5| Step: 10
Training loss: 3.4000181534226424
Validation loss: 2.7357446459021104

Epoch: 188| Step: 0
Training loss: 3.5401598847916027
Validation loss: 2.7360813274656914

Epoch: 5| Step: 1
Training loss: 2.9347862532342712
Validation loss: 2.7332912452582767

Epoch: 5| Step: 2
Training loss: 2.447404642867909
Validation loss: 2.7389358478403727

Epoch: 5| Step: 3
Training loss: 3.491423179737358
Validation loss: 2.734228828613342

Epoch: 5| Step: 4
Training loss: 3.0624878552254406
Validation loss: 2.7346535255161304

Epoch: 5| Step: 5
Training loss: 2.6382116541834333
Validation loss: 2.7323435935827964

Epoch: 5| Step: 6
Training loss: 3.6673517165211873
Validation loss: 2.739967957080162

Epoch: 5| Step: 7
Training loss: 3.232538853859521
Validation loss: 2.7335856743140403

Epoch: 5| Step: 8
Training loss: 2.53862000350915
Validation loss: 2.7433312251898374

Epoch: 5| Step: 9
Training loss: 2.9723565931834317
Validation loss: 2.7400308242990983

Epoch: 5| Step: 10
Training loss: 2.6990608136002967
Validation loss: 2.747576814044422

Epoch: 189| Step: 0
Training loss: 3.0090445237014483
Validation loss: 2.73946312382858

Epoch: 5| Step: 1
Training loss: 3.2472190696658223
Validation loss: 2.7452904253784607

Epoch: 5| Step: 2
Training loss: 3.3242326639782984
Validation loss: 2.7510276116194006

Epoch: 5| Step: 3
Training loss: 2.7232402684135817
Validation loss: 2.7367932910913972

Epoch: 5| Step: 4
Training loss: 3.4018658062517866
Validation loss: 2.7392709635774817

Epoch: 5| Step: 5
Training loss: 3.1152828966146786
Validation loss: 2.737911579109007

Epoch: 5| Step: 6
Training loss: 2.4511226573121476
Validation loss: 2.7335924904592535

Epoch: 5| Step: 7
Training loss: 2.9184883604877943
Validation loss: 2.7352682362800382

Epoch: 5| Step: 8
Training loss: 2.9341994878017936
Validation loss: 2.730031452689671

Epoch: 5| Step: 9
Training loss: 3.02510470374629
Validation loss: 2.7327113111832486

Epoch: 5| Step: 10
Training loss: 3.2978057270745027
Validation loss: 2.735466060916141

Epoch: 190| Step: 0
Training loss: 3.189652408090266
Validation loss: 2.732083006532526

Epoch: 5| Step: 1
Training loss: 3.149626173816512
Validation loss: 2.734306435377288

Epoch: 5| Step: 2
Training loss: 3.4359424183364924
Validation loss: 2.7334559598688166

Epoch: 5| Step: 3
Training loss: 2.9288301154269325
Validation loss: 2.7380952387321673

Epoch: 5| Step: 4
Training loss: 2.1728138163856263
Validation loss: 2.736693748439145

Epoch: 5| Step: 5
Training loss: 2.8904397441163994
Validation loss: 2.7468020320529334

Epoch: 5| Step: 6
Training loss: 3.0098571961451133
Validation loss: 2.749473239792751

Epoch: 5| Step: 7
Training loss: 3.508033660509694
Validation loss: 2.758014880571301

Epoch: 5| Step: 8
Training loss: 3.6802520642821235
Validation loss: 2.755432685187989

Epoch: 5| Step: 9
Training loss: 2.5399382504143615
Validation loss: 2.7460295427930794

Epoch: 5| Step: 10
Training loss: 2.7125862670400056
Validation loss: 2.7352253209649247

Epoch: 191| Step: 0
Training loss: 2.981932434411618
Validation loss: 2.731668813370336

Epoch: 5| Step: 1
Training loss: 3.3732724890166
Validation loss: 2.7293990417562415

Epoch: 5| Step: 2
Training loss: 3.19992128513798
Validation loss: 2.728627130350188

Epoch: 5| Step: 3
Training loss: 2.901304405455035
Validation loss: 2.7314845217354975

Epoch: 5| Step: 4
Training loss: 2.9248583245812214
Validation loss: 2.730385208101764

Epoch: 5| Step: 5
Training loss: 2.849214271518879
Validation loss: 2.730772600985236

Epoch: 5| Step: 6
Training loss: 2.699208150530925
Validation loss: 2.7318937167111423

Epoch: 5| Step: 7
Training loss: 3.402519212790459
Validation loss: 2.728734326367131

Epoch: 5| Step: 8
Training loss: 2.9294044459616737
Validation loss: 2.730452048772751

Epoch: 5| Step: 9
Training loss: 3.0141069613628733
Validation loss: 2.7289595880376973

Epoch: 5| Step: 10
Training loss: 3.236706321963151
Validation loss: 2.7328994280767347

Epoch: 192| Step: 0
Training loss: 3.2676487542800032
Validation loss: 2.7317767308832717

Epoch: 5| Step: 1
Training loss: 3.516081377712937
Validation loss: 2.731860753867937

Epoch: 5| Step: 2
Training loss: 2.4745117746328527
Validation loss: 2.7293812237601

Epoch: 5| Step: 3
Training loss: 3.2998731819985068
Validation loss: 2.731000060104187

Epoch: 5| Step: 4
Training loss: 3.1870751191243367
Validation loss: 2.731956271447738

Epoch: 5| Step: 5
Training loss: 3.1940930564858645
Validation loss: 2.7347676725627874

Epoch: 5| Step: 6
Training loss: 3.147824817043729
Validation loss: 2.732694393818253

Epoch: 5| Step: 7
Training loss: 2.413409592317584
Validation loss: 2.7360633196780504

Epoch: 5| Step: 8
Training loss: 2.8788525849391013
Validation loss: 2.7367673978352616

Epoch: 5| Step: 9
Training loss: 3.276368933960041
Validation loss: 2.7372024941609396

Epoch: 5| Step: 10
Training loss: 2.524401312377134
Validation loss: 2.7374483486952954

Epoch: 193| Step: 0
Training loss: 2.7552326876760382
Validation loss: 2.738923219315604

Epoch: 5| Step: 1
Training loss: 2.89579747312741
Validation loss: 2.741403419058951

Epoch: 5| Step: 2
Training loss: 3.6734811719393994
Validation loss: 2.7453948230334566

Epoch: 5| Step: 3
Training loss: 3.11042039636353
Validation loss: 2.7432974148030667

Epoch: 5| Step: 4
Training loss: 2.803482179201709
Validation loss: 2.74103515128702

Epoch: 5| Step: 5
Training loss: 2.8905453232790133
Validation loss: 2.739245586021772

Epoch: 5| Step: 6
Training loss: 2.6604502063171505
Validation loss: 2.734983769636151

Epoch: 5| Step: 7
Training loss: 3.28902161633958
Validation loss: 2.729785786654635

Epoch: 5| Step: 8
Training loss: 2.893858549582663
Validation loss: 2.730226259523704

Epoch: 5| Step: 9
Training loss: 3.1057409778971508
Validation loss: 2.731237542775947

Epoch: 5| Step: 10
Training loss: 3.34773459059079
Validation loss: 2.727089272004904

Epoch: 194| Step: 0
Training loss: 2.8781742319541506
Validation loss: 2.732122462781266

Epoch: 5| Step: 1
Training loss: 3.3137708421394905
Validation loss: 2.7293908494374057

Epoch: 5| Step: 2
Training loss: 2.858451819304235
Validation loss: 2.73406888264944

Epoch: 5| Step: 3
Training loss: 2.98704433397789
Validation loss: 2.727436343465592

Epoch: 5| Step: 4
Training loss: 2.600471611532507
Validation loss: 2.7299593842168663

Epoch: 5| Step: 5
Training loss: 3.599800257969577
Validation loss: 2.733263850010492

Epoch: 5| Step: 6
Training loss: 2.726978696520986
Validation loss: 2.7317289426256064

Epoch: 5| Step: 7
Training loss: 2.6651127778143344
Validation loss: 2.7354051946908933

Epoch: 5| Step: 8
Training loss: 3.518832087533292
Validation loss: 2.7341438263708993

Epoch: 5| Step: 9
Training loss: 3.2162677860175934
Validation loss: 2.7375787533081684

Epoch: 5| Step: 10
Training loss: 2.9017242961713663
Validation loss: 2.7388124102186056

Epoch: 195| Step: 0
Training loss: 2.909104288948241
Validation loss: 2.743102268956421

Epoch: 5| Step: 1
Training loss: 2.820680631244917
Validation loss: 2.7469987246447403

Epoch: 5| Step: 2
Training loss: 2.9649074381746487
Validation loss: 2.7387046285959316

Epoch: 5| Step: 3
Training loss: 3.0825284646259945
Validation loss: 2.7297086129861

Epoch: 5| Step: 4
Training loss: 3.225581798267856
Validation loss: 2.724059144444759

Epoch: 5| Step: 5
Training loss: 2.9079443801745035
Validation loss: 2.7263509438695754

Epoch: 5| Step: 6
Training loss: 3.4251027669594674
Validation loss: 2.724249262833715

Epoch: 5| Step: 7
Training loss: 3.0368465395714725
Validation loss: 2.724615185177485

Epoch: 5| Step: 8
Training loss: 2.9265318291029963
Validation loss: 2.726453724482617

Epoch: 5| Step: 9
Training loss: 3.269180333710774
Validation loss: 2.7255564839151716

Epoch: 5| Step: 10
Training loss: 2.8838737209254894
Validation loss: 2.7248933920845495

Epoch: 196| Step: 0
Training loss: 2.987279946111584
Validation loss: 2.7268696151376037

Epoch: 5| Step: 1
Training loss: 2.4683211714680846
Validation loss: 2.7211177248460916

Epoch: 5| Step: 2
Training loss: 2.9559898407158856
Validation loss: 2.7223074720186657

Epoch: 5| Step: 3
Training loss: 3.114640727625358
Validation loss: 2.724900376740808

Epoch: 5| Step: 4
Training loss: 3.4299244027662485
Validation loss: 2.725418401295744

Epoch: 5| Step: 5
Training loss: 2.6348949312981556
Validation loss: 2.7244710223103725

Epoch: 5| Step: 6
Training loss: 2.8108371481335657
Validation loss: 2.7231519237921638

Epoch: 5| Step: 7
Training loss: 3.332957167063211
Validation loss: 2.723030637434478

Epoch: 5| Step: 8
Training loss: 3.2760954560845645
Validation loss: 2.725666696667486

Epoch: 5| Step: 9
Training loss: 3.194544319766077
Validation loss: 2.723919727121897

Epoch: 5| Step: 10
Training loss: 3.1606348380263265
Validation loss: 2.7324871074884736

Epoch: 197| Step: 0
Training loss: 2.7549932404312316
Validation loss: 2.736176790466215

Epoch: 5| Step: 1
Training loss: 3.2209083209534706
Validation loss: 2.753442617472916

Epoch: 5| Step: 2
Training loss: 2.9085439837079266
Validation loss: 2.7352728719335624

Epoch: 5| Step: 3
Training loss: 2.551950744506342
Validation loss: 2.74089660260321

Epoch: 5| Step: 4
Training loss: 3.5301457932058646
Validation loss: 2.731012721511721

Epoch: 5| Step: 5
Training loss: 3.3105236851602986
Validation loss: 2.7317835712494647

Epoch: 5| Step: 6
Training loss: 2.848207103892735
Validation loss: 2.725829591299129

Epoch: 5| Step: 7
Training loss: 2.9766196898725923
Validation loss: 2.727390438036741

Epoch: 5| Step: 8
Training loss: 3.1407479788772115
Validation loss: 2.7210663972398623

Epoch: 5| Step: 9
Training loss: 3.206005159960501
Validation loss: 2.7266518868218954

Epoch: 5| Step: 10
Training loss: 2.9041321944421554
Validation loss: 2.7265736437778227

Epoch: 198| Step: 0
Training loss: 2.9361153443673986
Validation loss: 2.721950061665832

Epoch: 5| Step: 1
Training loss: 3.4425470927112483
Validation loss: 2.721951864346425

Epoch: 5| Step: 2
Training loss: 3.4312865541939495
Validation loss: 2.7291157847751593

Epoch: 5| Step: 3
Training loss: 3.0603449498640187
Validation loss: 2.72559136466028

Epoch: 5| Step: 4
Training loss: 3.312044796166188
Validation loss: 2.7231252691233903

Epoch: 5| Step: 5
Training loss: 3.0284483241949722
Validation loss: 2.7237262909732336

Epoch: 5| Step: 6
Training loss: 2.963811521305915
Validation loss: 2.7288285526387757

Epoch: 5| Step: 7
Training loss: 2.874919558519254
Validation loss: 2.7278763498873895

Epoch: 5| Step: 8
Training loss: 3.0460252408279924
Validation loss: 2.7291286446757197

Epoch: 5| Step: 9
Training loss: 2.5349771821388933
Validation loss: 2.7342158248675874

Epoch: 5| Step: 10
Training loss: 2.5434477043017463
Validation loss: 2.7371173388722285

Epoch: 199| Step: 0
Training loss: 3.2687950991843553
Validation loss: 2.7626091455143946

Epoch: 5| Step: 1
Training loss: 2.7184675223392736
Validation loss: 2.7571925244027544

Epoch: 5| Step: 2
Training loss: 3.0163914788553123
Validation loss: 2.777132152844037

Epoch: 5| Step: 3
Training loss: 3.6743699707993493
Validation loss: 2.7593080386732916

Epoch: 5| Step: 4
Training loss: 2.979923463388993
Validation loss: 2.7260570801059725

Epoch: 5| Step: 5
Training loss: 3.6142186284099242
Validation loss: 2.724298786748893

Epoch: 5| Step: 6
Training loss: 2.9483423004387808
Validation loss: 2.7196418045430213

Epoch: 5| Step: 7
Training loss: 2.93423003954833
Validation loss: 2.7168426536944215

Epoch: 5| Step: 8
Training loss: 3.215288096759918
Validation loss: 2.720521735485534

Epoch: 5| Step: 9
Training loss: 2.135209298338498
Validation loss: 2.7202247351162767

Epoch: 5| Step: 10
Training loss: 2.680773011931037
Validation loss: 2.717473673568589

Epoch: 200| Step: 0
Training loss: 2.7336136112107594
Validation loss: 2.7184731909844446

Epoch: 5| Step: 1
Training loss: 3.242461190678939
Validation loss: 2.723613992926481

Epoch: 5| Step: 2
Training loss: 3.309305918317426
Validation loss: 2.7183378296375302

Epoch: 5| Step: 3
Training loss: 3.067069556542996
Validation loss: 2.7190353306063195

Epoch: 5| Step: 4
Training loss: 3.136995562242914
Validation loss: 2.7178223823405303

Epoch: 5| Step: 5
Training loss: 2.788298686607097
Validation loss: 2.7215271239446284

Epoch: 5| Step: 6
Training loss: 3.4927868766080294
Validation loss: 2.7255692900652035

Epoch: 5| Step: 7
Training loss: 2.388039880397191
Validation loss: 2.732554365837533

Epoch: 5| Step: 8
Training loss: 3.332622945110188
Validation loss: 2.7311322716681024

Epoch: 5| Step: 9
Training loss: 2.986525155472905
Validation loss: 2.720579006185218

Epoch: 5| Step: 10
Training loss: 2.7665945821203417
Validation loss: 2.7164965399338277

Epoch: 201| Step: 0
Training loss: 2.984829213993079
Validation loss: 2.7145874346263903

Epoch: 5| Step: 1
Training loss: 2.854347353225639
Validation loss: 2.7178514471672215

Epoch: 5| Step: 2
Training loss: 3.0710870673340547
Validation loss: 2.7217790954375554

Epoch: 5| Step: 3
Training loss: 3.2488685986079076
Validation loss: 2.7226310951623445

Epoch: 5| Step: 4
Training loss: 3.10675966314635
Validation loss: 2.722316235614108

Epoch: 5| Step: 5
Training loss: 2.4972452244909142
Validation loss: 2.720062844113233

Epoch: 5| Step: 6
Training loss: 2.601878928796174
Validation loss: 2.7229004022761982

Epoch: 5| Step: 7
Training loss: 3.1427925183724104
Validation loss: 2.724252213948647

Epoch: 5| Step: 8
Training loss: 3.566637547692006
Validation loss: 2.7173656276615112

Epoch: 5| Step: 9
Training loss: 3.2818347228264284
Validation loss: 2.7208647197394327

Epoch: 5| Step: 10
Training loss: 2.9900957968685025
Validation loss: 2.7229778818787347

Epoch: 202| Step: 0
Training loss: 3.7853346271823964
Validation loss: 2.718640766676901

Epoch: 5| Step: 1
Training loss: 2.5730147143587025
Validation loss: 2.725226629804915

Epoch: 5| Step: 2
Training loss: 3.1212676075051835
Validation loss: 2.7446583919450873

Epoch: 5| Step: 3
Training loss: 3.0820262991088243
Validation loss: 2.7557702499420995

Epoch: 5| Step: 4
Training loss: 2.4097399483455355
Validation loss: 2.7674384975542377

Epoch: 5| Step: 5
Training loss: 3.406784995525445
Validation loss: 2.7534213499494244

Epoch: 5| Step: 6
Training loss: 2.7719118892102994
Validation loss: 2.7475293351240166

Epoch: 5| Step: 7
Training loss: 3.1027154965374466
Validation loss: 2.7568598847309587

Epoch: 5| Step: 8
Training loss: 3.131007561654116
Validation loss: 2.7504927043725913

Epoch: 5| Step: 9
Training loss: 2.7121507200034323
Validation loss: 2.7589472845052554

Epoch: 5| Step: 10
Training loss: 3.1546463622178473
Validation loss: 2.7624193647015307

Epoch: 203| Step: 0
Training loss: 2.945671727461218
Validation loss: 2.7572471924461257

Epoch: 5| Step: 1
Training loss: 3.077599495116892
Validation loss: 2.7586757430531046

Epoch: 5| Step: 2
Training loss: 3.3473517013417617
Validation loss: 2.7529016998446436

Epoch: 5| Step: 3
Training loss: 3.0416923068982094
Validation loss: 2.7393573948707766

Epoch: 5| Step: 4
Training loss: 3.667222732225168
Validation loss: 2.7385028411650927

Epoch: 5| Step: 5
Training loss: 2.7027010723057545
Validation loss: 2.7234409096287324

Epoch: 5| Step: 6
Training loss: 3.0493676577583453
Validation loss: 2.719600287573342

Epoch: 5| Step: 7
Training loss: 2.4420422999587044
Validation loss: 2.709851989418534

Epoch: 5| Step: 8
Training loss: 2.55718517405453
Validation loss: 2.7098921562792473

Epoch: 5| Step: 9
Training loss: 3.4048450617332326
Validation loss: 2.7123007920329436

Epoch: 5| Step: 10
Training loss: 2.940747353159939
Validation loss: 2.7129477695241224

Epoch: 204| Step: 0
Training loss: 3.379692206729992
Validation loss: 2.710720664365849

Epoch: 5| Step: 1
Training loss: 3.3215585322817995
Validation loss: 2.7132760777413565

Epoch: 5| Step: 2
Training loss: 3.126829298571053
Validation loss: 2.710791812500054

Epoch: 5| Step: 3
Training loss: 2.801589657619434
Validation loss: 2.7117548991015656

Epoch: 5| Step: 4
Training loss: 3.613567609007498
Validation loss: 2.709913990575259

Epoch: 5| Step: 5
Training loss: 2.74580948336426
Validation loss: 2.714405549542306

Epoch: 5| Step: 6
Training loss: 2.2119170805718924
Validation loss: 2.712923820225953

Epoch: 5| Step: 7
Training loss: 2.824438062834548
Validation loss: 2.716730370244281

Epoch: 5| Step: 8
Training loss: 3.199545148471028
Validation loss: 2.71069571843133

Epoch: 5| Step: 9
Training loss: 2.7550835872646298
Validation loss: 2.715276943704928

Epoch: 5| Step: 10
Training loss: 3.1724511736636365
Validation loss: 2.7132593783997754

Epoch: 205| Step: 0
Training loss: 2.6187922326372033
Validation loss: 2.721476261873576

Epoch: 5| Step: 1
Training loss: 3.0906751360553666
Validation loss: 2.7263116438780592

Epoch: 5| Step: 2
Training loss: 3.0368156070243866
Validation loss: 2.718566346133002

Epoch: 5| Step: 3
Training loss: 2.9022476365205234
Validation loss: 2.7264708911923665

Epoch: 5| Step: 4
Training loss: 3.196393937564887
Validation loss: 2.724113511855212

Epoch: 5| Step: 5
Training loss: 2.8043732958576557
Validation loss: 2.723874784072303

Epoch: 5| Step: 6
Training loss: 2.858623802025007
Validation loss: 2.721418405276975

Epoch: 5| Step: 7
Training loss: 3.0677577448148643
Validation loss: 2.717539737504953

Epoch: 5| Step: 8
Training loss: 3.0576167196482396
Validation loss: 2.7232670885817805

Epoch: 5| Step: 9
Training loss: 3.683455625434282
Validation loss: 2.716079324277618

Epoch: 5| Step: 10
Training loss: 2.8606316145123882
Validation loss: 2.7132302653265192

Epoch: 206| Step: 0
Training loss: 2.953197660006418
Validation loss: 2.7095640719615086

Epoch: 5| Step: 1
Training loss: 3.246663948961357
Validation loss: 2.712395042890382

Epoch: 5| Step: 2
Training loss: 2.974751559871268
Validation loss: 2.7132306376039312

Epoch: 5| Step: 3
Training loss: 3.2205615825098395
Validation loss: 2.71130826449685

Epoch: 5| Step: 4
Training loss: 3.0608949152976677
Validation loss: 2.708783393615145

Epoch: 5| Step: 5
Training loss: 3.5372181648699916
Validation loss: 2.7157727277270474

Epoch: 5| Step: 6
Training loss: 3.2111495567522352
Validation loss: 2.711760811505766

Epoch: 5| Step: 7
Training loss: 2.803745037045553
Validation loss: 2.7128005721157336

Epoch: 5| Step: 8
Training loss: 2.507149011420404
Validation loss: 2.7101259954697987

Epoch: 5| Step: 9
Training loss: 2.699048623494001
Validation loss: 2.7124192151868454

Epoch: 5| Step: 10
Training loss: 2.9716897964932394
Validation loss: 2.7123065973860885

Epoch: 207| Step: 0
Training loss: 2.9920251070182937
Validation loss: 2.713893767786345

Epoch: 5| Step: 1
Training loss: 3.0235166711816035
Validation loss: 2.7143164507943442

Epoch: 5| Step: 2
Training loss: 3.1867510345761354
Validation loss: 2.7151497971217897

Epoch: 5| Step: 3
Training loss: 3.127726776658842
Validation loss: 2.7211806808654257

Epoch: 5| Step: 4
Training loss: 3.0350776966588286
Validation loss: 2.731487357100032

Epoch: 5| Step: 5
Training loss: 3.4172132256494065
Validation loss: 2.735462772328311

Epoch: 5| Step: 6
Training loss: 2.3870639582592488
Validation loss: 2.7204183877323413

Epoch: 5| Step: 7
Training loss: 2.912592376422813
Validation loss: 2.7136525802677287

Epoch: 5| Step: 8
Training loss: 3.072773730730682
Validation loss: 2.709729953549356

Epoch: 5| Step: 9
Training loss: 2.8211342414901672
Validation loss: 2.7119607006617996

Epoch: 5| Step: 10
Training loss: 3.261328394025471
Validation loss: 2.712404931110577

Epoch: 208| Step: 0
Training loss: 3.3678102559081036
Validation loss: 2.7091648961301633

Epoch: 5| Step: 1
Training loss: 3.1200112768116144
Validation loss: 2.7079701283438786

Epoch: 5| Step: 2
Training loss: 2.6433633002963317
Validation loss: 2.7086874488184

Epoch: 5| Step: 3
Training loss: 2.771818392239009
Validation loss: 2.7051164246981165

Epoch: 5| Step: 4
Training loss: 3.5766115944335533
Validation loss: 2.7085216037130264

Epoch: 5| Step: 5
Training loss: 3.584583301029089
Validation loss: 2.7051900420317856

Epoch: 5| Step: 6
Training loss: 3.280956146161089
Validation loss: 2.706712433360734

Epoch: 5| Step: 7
Training loss: 2.7037211736446594
Validation loss: 2.7022827038706163

Epoch: 5| Step: 8
Training loss: 2.4301920179944076
Validation loss: 2.7046984924326956

Epoch: 5| Step: 9
Training loss: 2.482754160613954
Validation loss: 2.708974640851957

Epoch: 5| Step: 10
Training loss: 3.060558092672486
Validation loss: 2.708550918837545

Epoch: 209| Step: 0
Training loss: 3.221882305266482
Validation loss: 2.7160690284645304

Epoch: 5| Step: 1
Training loss: 2.1436921581772794
Validation loss: 2.7296677112029344

Epoch: 5| Step: 2
Training loss: 2.8286466170166893
Validation loss: 2.7380856371009163

Epoch: 5| Step: 3
Training loss: 3.31211793243602
Validation loss: 2.7664865920224786

Epoch: 5| Step: 4
Training loss: 3.3423962571129997
Validation loss: 2.740496647232127

Epoch: 5| Step: 5
Training loss: 2.798230913418693
Validation loss: 2.742093719691571

Epoch: 5| Step: 6
Training loss: 2.5268189063628954
Validation loss: 2.724263592085383

Epoch: 5| Step: 7
Training loss: 3.391504832787763
Validation loss: 2.7076369170342454

Epoch: 5| Step: 8
Training loss: 3.1721561100608966
Validation loss: 2.7099852138098197

Epoch: 5| Step: 9
Training loss: 3.325163477270513
Validation loss: 2.710833930604384

Epoch: 5| Step: 10
Training loss: 2.9761666262443054
Validation loss: 2.7005042519415694

Epoch: 210| Step: 0
Training loss: 3.5269876598188783
Validation loss: 2.7028672110040812

Epoch: 5| Step: 1
Training loss: 2.899483957087403
Validation loss: 2.702779569171622

Epoch: 5| Step: 2
Training loss: 2.7409743535464384
Validation loss: 2.702639239574114

Epoch: 5| Step: 3
Training loss: 2.1515064861067748
Validation loss: 2.70563644440908

Epoch: 5| Step: 4
Training loss: 3.491698501793819
Validation loss: 2.7026787158947325

Epoch: 5| Step: 5
Training loss: 2.895981069039279
Validation loss: 2.7011513699493324

Epoch: 5| Step: 6
Training loss: 3.3496068125901277
Validation loss: 2.707358116716899

Epoch: 5| Step: 7
Training loss: 2.863369512303513
Validation loss: 2.718347148306249

Epoch: 5| Step: 8
Training loss: 3.074495450936955
Validation loss: 2.7248682983549832

Epoch: 5| Step: 9
Training loss: 3.084268239192088
Validation loss: 2.7284077748781854

Epoch: 5| Step: 10
Training loss: 3.1257565917606347
Validation loss: 2.7305328424055344

Epoch: 211| Step: 0
Training loss: 3.432215842691178
Validation loss: 2.718343856927059

Epoch: 5| Step: 1
Training loss: 3.448461913976078
Validation loss: 2.7177848040858352

Epoch: 5| Step: 2
Training loss: 2.720226106361871
Validation loss: 2.7012061898849278

Epoch: 5| Step: 3
Training loss: 2.9031838270454324
Validation loss: 2.7051979712158456

Epoch: 5| Step: 4
Training loss: 2.95934242625371
Validation loss: 2.7022441524474727

Epoch: 5| Step: 5
Training loss: 3.0107849494206183
Validation loss: 2.706702693883515

Epoch: 5| Step: 6
Training loss: 2.7225476630516297
Validation loss: 2.703014854507335

Epoch: 5| Step: 7
Training loss: 2.6970409214082176
Validation loss: 2.7023953476058686

Epoch: 5| Step: 8
Training loss: 3.2178946534452284
Validation loss: 2.7005517649513977

Epoch: 5| Step: 9
Training loss: 3.061299458513463
Validation loss: 2.7061293517050387

Epoch: 5| Step: 10
Training loss: 2.9958191985821276
Validation loss: 2.700721129452294

Epoch: 212| Step: 0
Training loss: 3.7708109368489904
Validation loss: 2.7063951099255896

Epoch: 5| Step: 1
Training loss: 2.5937623173065028
Validation loss: 2.6999430035523235

Epoch: 5| Step: 2
Training loss: 2.838968134116394
Validation loss: 2.7032218022854897

Epoch: 5| Step: 3
Training loss: 3.382216755693685
Validation loss: 2.701859460023385

Epoch: 5| Step: 4
Training loss: 2.725800765785772
Validation loss: 2.7121759399063197

Epoch: 5| Step: 5
Training loss: 3.3957343213833586
Validation loss: 2.7079257617396526

Epoch: 5| Step: 6
Training loss: 3.339830043831525
Validation loss: 2.705170123727929

Epoch: 5| Step: 7
Training loss: 2.8971500467795392
Validation loss: 2.7145670176913463

Epoch: 5| Step: 8
Training loss: 2.444456102844334
Validation loss: 2.722080660618754

Epoch: 5| Step: 9
Training loss: 2.8998416265453897
Validation loss: 2.725146537747599

Epoch: 5| Step: 10
Training loss: 2.562962746125059
Validation loss: 2.7335367566257185

Epoch: 213| Step: 0
Training loss: 2.78220873820633
Validation loss: 2.7429638480495258

Epoch: 5| Step: 1
Training loss: 2.579706527667514
Validation loss: 2.7512620218969452

Epoch: 5| Step: 2
Training loss: 3.2597278846489637
Validation loss: 2.754327307327528

Epoch: 5| Step: 3
Training loss: 3.3371148276504967
Validation loss: 2.7470022122033213

Epoch: 5| Step: 4
Training loss: 2.98644580197552
Validation loss: 2.7420071156692027

Epoch: 5| Step: 5
Training loss: 3.204482818866966
Validation loss: 2.7268833646581387

Epoch: 5| Step: 6
Training loss: 2.636279893310421
Validation loss: 2.720620850274413

Epoch: 5| Step: 7
Training loss: 2.9879825218332936
Validation loss: 2.7142531372147447

Epoch: 5| Step: 8
Training loss: 3.0414519735015872
Validation loss: 2.7175066797945853

Epoch: 5| Step: 9
Training loss: 3.0000569020279055
Validation loss: 2.705777647514271

Epoch: 5| Step: 10
Training loss: 3.3297605122545564
Validation loss: 2.700896689087346

Epoch: 214| Step: 0
Training loss: 2.9652527136317883
Validation loss: 2.6986332626373333

Epoch: 5| Step: 1
Training loss: 2.9700189388197917
Validation loss: 2.6983252433831866

Epoch: 5| Step: 2
Training loss: 2.9899007560054094
Validation loss: 2.6993968775382147

Epoch: 5| Step: 3
Training loss: 2.7932710070549476
Validation loss: 2.6979660784770743

Epoch: 5| Step: 4
Training loss: 3.223405896474301
Validation loss: 2.699480073585328

Epoch: 5| Step: 5
Training loss: 3.1660778267813976
Validation loss: 2.6977764426887036

Epoch: 5| Step: 6
Training loss: 3.2196830212024046
Validation loss: 2.6986713697620766

Epoch: 5| Step: 7
Training loss: 2.8102874530094746
Validation loss: 2.6984410231114975

Epoch: 5| Step: 8
Training loss: 2.726037792008216
Validation loss: 2.701002061343266

Epoch: 5| Step: 9
Training loss: 2.6707101703242326
Validation loss: 2.696850037061471

Epoch: 5| Step: 10
Training loss: 3.6959563454531112
Validation loss: 2.698258291902821

Epoch: 215| Step: 0
Training loss: 2.9795237151621845
Validation loss: 2.698266400124475

Epoch: 5| Step: 1
Training loss: 2.797867327207986
Validation loss: 2.6987323947591344

Epoch: 5| Step: 2
Training loss: 2.963651274054784
Validation loss: 2.704521065748527

Epoch: 5| Step: 3
Training loss: 3.2884243960048325
Validation loss: 2.701247328070242

Epoch: 5| Step: 4
Training loss: 3.25631174332845
Validation loss: 2.697391438137522

Epoch: 5| Step: 5
Training loss: 3.2329388807179016
Validation loss: 2.697643978128913

Epoch: 5| Step: 6
Training loss: 3.4061503264516553
Validation loss: 2.7106665929560427

Epoch: 5| Step: 7
Training loss: 2.0702129987881834
Validation loss: 2.704045899643155

Epoch: 5| Step: 8
Training loss: 3.268816834563357
Validation loss: 2.7129339522109945

Epoch: 5| Step: 9
Training loss: 2.9950550969680863
Validation loss: 2.709037210959285

Epoch: 5| Step: 10
Training loss: 2.6000053625785107
Validation loss: 2.697600197214983

Epoch: 216| Step: 0
Training loss: 2.7125062828166993
Validation loss: 2.6998576083781374

Epoch: 5| Step: 1
Training loss: 2.9071945788360756
Validation loss: 2.7000121065853544

Epoch: 5| Step: 2
Training loss: 3.2245270079104085
Validation loss: 2.7104863704632733

Epoch: 5| Step: 3
Training loss: 3.1967507555432606
Validation loss: 2.6984370414696017

Epoch: 5| Step: 4
Training loss: 3.059299431433516
Validation loss: 2.6964690473674744

Epoch: 5| Step: 5
Training loss: 2.7871534294597713
Validation loss: 2.697892543393314

Epoch: 5| Step: 6
Training loss: 3.4478995024070422
Validation loss: 2.6992396971258397

Epoch: 5| Step: 7
Training loss: 2.2420910538722016
Validation loss: 2.7044024891763723

Epoch: 5| Step: 8
Training loss: 2.905732795880359
Validation loss: 2.700127779801809

Epoch: 5| Step: 9
Training loss: 3.1250840747967628
Validation loss: 2.6983078567560956

Epoch: 5| Step: 10
Training loss: 3.4060628297110087
Validation loss: 2.7082995170457296

Epoch: 217| Step: 0
Training loss: 2.696905665925013
Validation loss: 2.7049320802127763

Epoch: 5| Step: 1
Training loss: 3.459374619564046
Validation loss: 2.710377069887283

Epoch: 5| Step: 2
Training loss: 2.929755207550944
Validation loss: 2.7148906909977137

Epoch: 5| Step: 3
Training loss: 3.0140767446668804
Validation loss: 2.7153550071557166

Epoch: 5| Step: 4
Training loss: 3.094089836182472
Validation loss: 2.710602371293233

Epoch: 5| Step: 5
Training loss: 2.953097550198979
Validation loss: 2.7069039585577266

Epoch: 5| Step: 6
Training loss: 2.9963531580781337
Validation loss: 2.7033760427952624

Epoch: 5| Step: 7
Training loss: 2.8807312603928352
Validation loss: 2.700779481637041

Epoch: 5| Step: 8
Training loss: 2.96709275418317
Validation loss: 2.708118550103557

Epoch: 5| Step: 9
Training loss: 2.9339532746154893
Validation loss: 2.704336477813375

Epoch: 5| Step: 10
Training loss: 3.224677544375213
Validation loss: 2.6978635771258452

Epoch: 218| Step: 0
Training loss: 2.584844721367522
Validation loss: 2.6932397473015306

Epoch: 5| Step: 1
Training loss: 3.3731164267945064
Validation loss: 2.6937248862832033

Epoch: 5| Step: 2
Training loss: 3.0777232881015406
Validation loss: 2.6957794959556804

Epoch: 5| Step: 3
Training loss: 2.8655154474547944
Validation loss: 2.692173860252184

Epoch: 5| Step: 4
Training loss: 2.7398248911682543
Validation loss: 2.6919978860303355

Epoch: 5| Step: 5
Training loss: 2.9453575070127243
Validation loss: 2.6951899798633363

Epoch: 5| Step: 6
Training loss: 2.9901319968390205
Validation loss: 2.693777701775496

Epoch: 5| Step: 7
Training loss: 3.525960826463598
Validation loss: 2.6959375390017133

Epoch: 5| Step: 8
Training loss: 2.769386621311799
Validation loss: 2.6931898445382907

Epoch: 5| Step: 9
Training loss: 3.258959378509331
Validation loss: 2.6952060130922897

Epoch: 5| Step: 10
Training loss: 2.8664576461646627
Validation loss: 2.705597065252878

Epoch: 219| Step: 0
Training loss: 2.9135051122633318
Validation loss: 2.695278819644907

Epoch: 5| Step: 1
Training loss: 3.393803666675769
Validation loss: 2.7024439145066075

Epoch: 5| Step: 2
Training loss: 2.4457484822499094
Validation loss: 2.702215801108982

Epoch: 5| Step: 3
Training loss: 3.230076831813216
Validation loss: 2.6974153333595705

Epoch: 5| Step: 4
Training loss: 2.80700672711204
Validation loss: 2.691435440071638

Epoch: 5| Step: 5
Training loss: 3.0391668385145723
Validation loss: 2.7003534284333393

Epoch: 5| Step: 6
Training loss: 2.17671641006218
Validation loss: 2.7016581867802034

Epoch: 5| Step: 7
Training loss: 3.047555700705299
Validation loss: 2.7072416028281343

Epoch: 5| Step: 8
Training loss: 3.1275172966616775
Validation loss: 2.6978472375545666

Epoch: 5| Step: 9
Training loss: 3.283112206411425
Validation loss: 2.696372074910586

Epoch: 5| Step: 10
Training loss: 3.493489477172046
Validation loss: 2.691477275288483

Epoch: 220| Step: 0
Training loss: 3.3340750504841283
Validation loss: 2.697931012563557

Epoch: 5| Step: 1
Training loss: 2.983913365955001
Validation loss: 2.69050451756434

Epoch: 5| Step: 2
Training loss: 2.942422030314479
Validation loss: 2.691620923220653

Epoch: 5| Step: 3
Training loss: 2.884674050150268
Validation loss: 2.6887451515446372

Epoch: 5| Step: 4
Training loss: 3.6558792056656437
Validation loss: 2.693456359790932

Epoch: 5| Step: 5
Training loss: 2.2135841515147785
Validation loss: 2.6913153972692827

Epoch: 5| Step: 6
Training loss: 2.9640423843915804
Validation loss: 2.6899727818044163

Epoch: 5| Step: 7
Training loss: 2.89717901418507
Validation loss: 2.6890763078754203

Epoch: 5| Step: 8
Training loss: 3.1011329180424063
Validation loss: 2.6939561814692015

Epoch: 5| Step: 9
Training loss: 3.056820956142207
Validation loss: 2.696689744991008

Epoch: 5| Step: 10
Training loss: 2.9400651161612164
Validation loss: 2.6929723881057077

Epoch: 221| Step: 0
Training loss: 2.564949911420436
Validation loss: 2.702168598183818

Epoch: 5| Step: 1
Training loss: 3.264650190229114
Validation loss: 2.7028810219215282

Epoch: 5| Step: 2
Training loss: 2.8528728661996565
Validation loss: 2.6924715544755284

Epoch: 5| Step: 3
Training loss: 2.7026364099903843
Validation loss: 2.693794045094045

Epoch: 5| Step: 4
Training loss: 2.770581475382191
Validation loss: 2.6918310679104587

Epoch: 5| Step: 5
Training loss: 2.7995199132511885
Validation loss: 2.690454557397787

Epoch: 5| Step: 6
Training loss: 3.38664300079287
Validation loss: 2.6884594354412172

Epoch: 5| Step: 7
Training loss: 3.0486288647049045
Validation loss: 2.6897961422368772

Epoch: 5| Step: 8
Training loss: 3.1993703282257506
Validation loss: 2.6881740437366872

Epoch: 5| Step: 9
Training loss: 2.9398386959019307
Validation loss: 2.6883353909320715

Epoch: 5| Step: 10
Training loss: 3.5761872087584288
Validation loss: 2.6902383826569465

Epoch: 222| Step: 0
Training loss: 3.3421016444895284
Validation loss: 2.691446274941796

Epoch: 5| Step: 1
Training loss: 3.2214138526084835
Validation loss: 2.6928000504828415

Epoch: 5| Step: 2
Training loss: 2.711091050957985
Validation loss: 2.696097499248501

Epoch: 5| Step: 3
Training loss: 2.9350127383317983
Validation loss: 2.7014349389512464

Epoch: 5| Step: 4
Training loss: 3.0640533556064944
Validation loss: 2.707713499362944

Epoch: 5| Step: 5
Training loss: 3.349871584580327
Validation loss: 2.707404536980505

Epoch: 5| Step: 6
Training loss: 2.936067434768205
Validation loss: 2.7063523070172577

Epoch: 5| Step: 7
Training loss: 2.5307483882505126
Validation loss: 2.718252888796553

Epoch: 5| Step: 8
Training loss: 2.5345831694993026
Validation loss: 2.7246361064183966

Epoch: 5| Step: 9
Training loss: 3.3846322114232743
Validation loss: 2.7257793258542495

Epoch: 5| Step: 10
Training loss: 2.9917869997042104
Validation loss: 2.7052524172729595

Epoch: 223| Step: 0
Training loss: 2.9292808962634274
Validation loss: 2.696950388721987

Epoch: 5| Step: 1
Training loss: 3.0869562326584146
Validation loss: 2.693781465705839

Epoch: 5| Step: 2
Training loss: 3.4630506277368447
Validation loss: 2.684369686397977

Epoch: 5| Step: 3
Training loss: 2.3401560375974837
Validation loss: 2.6854895521741478

Epoch: 5| Step: 4
Training loss: 2.980832698894117
Validation loss: 2.6864906985640156

Epoch: 5| Step: 5
Training loss: 3.2511219142277445
Validation loss: 2.688422126663367

Epoch: 5| Step: 6
Training loss: 2.782509079444515
Validation loss: 2.6885637971436744

Epoch: 5| Step: 7
Training loss: 3.421472813211856
Validation loss: 2.6884525020075745

Epoch: 5| Step: 8
Training loss: 3.1144358792480005
Validation loss: 2.6906726108194783

Epoch: 5| Step: 9
Training loss: 2.3032677366831895
Validation loss: 2.6870419359192375

Epoch: 5| Step: 10
Training loss: 3.3322559204919
Validation loss: 2.6816799181045434

Epoch: 224| Step: 0
Training loss: 3.274055368019369
Validation loss: 2.6834930861019513

Epoch: 5| Step: 1
Training loss: 2.7944636685734183
Validation loss: 2.687576508440573

Epoch: 5| Step: 2
Training loss: 2.960746175175839
Validation loss: 2.6876116417267943

Epoch: 5| Step: 3
Training loss: 2.477893171013546
Validation loss: 2.692605925397142

Epoch: 5| Step: 4
Training loss: 3.370368746950025
Validation loss: 2.6993577625532774

Epoch: 5| Step: 5
Training loss: 3.3618570783782427
Validation loss: 2.711149300040624

Epoch: 5| Step: 6
Training loss: 3.1770207800205097
Validation loss: 2.714253513129905

Epoch: 5| Step: 7
Training loss: 2.602844930284864
Validation loss: 2.7433606524095215

Epoch: 5| Step: 8
Training loss: 2.583475560200601
Validation loss: 2.7611807479451755

Epoch: 5| Step: 9
Training loss: 3.2407380690387027
Validation loss: 2.7818182226189108

Epoch: 5| Step: 10
Training loss: 3.3086727272524934
Validation loss: 2.7178362502624034

Epoch: 225| Step: 0
Training loss: 3.1591067840796034
Validation loss: 2.6850896229706662

Epoch: 5| Step: 1
Training loss: 2.77262544160711
Validation loss: 2.6849802466899293

Epoch: 5| Step: 2
Training loss: 3.1588948565087662
Validation loss: 2.6851056367878474

Epoch: 5| Step: 3
Training loss: 3.1312873152833633
Validation loss: 2.6807250919407224

Epoch: 5| Step: 4
Training loss: 3.1805595682961934
Validation loss: 2.685724899402428

Epoch: 5| Step: 5
Training loss: 3.146586212271923
Validation loss: 2.6854604712166488

Epoch: 5| Step: 6
Training loss: 3.129337352528515
Validation loss: 2.6896983392105596

Epoch: 5| Step: 7
Training loss: 2.9256405968465273
Validation loss: 2.6898378704711914

Epoch: 5| Step: 8
Training loss: 2.9130784078431016
Validation loss: 2.69287216428521

Epoch: 5| Step: 9
Training loss: 2.519194919109339
Validation loss: 2.6886171221260593

Epoch: 5| Step: 10
Training loss: 3.074635032766783
Validation loss: 2.6889659225141216

Epoch: 226| Step: 0
Training loss: 3.6155047529397986
Validation loss: 2.6902435961965407

Epoch: 5| Step: 1
Training loss: 2.779018750083898
Validation loss: 2.6850228899864597

Epoch: 5| Step: 2
Training loss: 2.423946257854744
Validation loss: 2.691940415824417

Epoch: 5| Step: 3
Training loss: 3.1546049457723866
Validation loss: 2.68883216962444

Epoch: 5| Step: 4
Training loss: 2.2427215471836677
Validation loss: 2.685183923382577

Epoch: 5| Step: 5
Training loss: 3.1028364433435134
Validation loss: 2.6858165989001046

Epoch: 5| Step: 6
Training loss: 3.405009332495628
Validation loss: 2.685565789507561

Epoch: 5| Step: 7
Training loss: 2.5903144972456746
Validation loss: 2.6860377518293332

Epoch: 5| Step: 8
Training loss: 2.972609570972614
Validation loss: 2.684648455232594

Epoch: 5| Step: 9
Training loss: 3.5353330789252193
Validation loss: 2.6870889513900273

Epoch: 5| Step: 10
Training loss: 2.8933448985816463
Validation loss: 2.69815613990439

Epoch: 227| Step: 0
Training loss: 2.941083629489208
Validation loss: 2.7063441093485348

Epoch: 5| Step: 1
Training loss: 2.9134475018138213
Validation loss: 2.7148427886972994

Epoch: 5| Step: 2
Training loss: 2.864829775295289
Validation loss: 2.712601404518945

Epoch: 5| Step: 3
Training loss: 3.0013110157246867
Validation loss: 2.706081951783504

Epoch: 5| Step: 4
Training loss: 3.5911573262776497
Validation loss: 2.701178655251891

Epoch: 5| Step: 5
Training loss: 3.2584567450707507
Validation loss: 2.704666039848828

Epoch: 5| Step: 6
Training loss: 3.171945655674717
Validation loss: 2.717098615739041

Epoch: 5| Step: 7
Training loss: 3.2207682679888636
Validation loss: 2.7209485266239852

Epoch: 5| Step: 8
Training loss: 3.0629879309764863
Validation loss: 2.712642120392933

Epoch: 5| Step: 9
Training loss: 2.858564918708374
Validation loss: 2.6939926684931077

Epoch: 5| Step: 10
Training loss: 1.836789456997829
Validation loss: 2.6916700959806836

Epoch: 228| Step: 0
Training loss: 2.8179194476470997
Validation loss: 2.6878574788924987

Epoch: 5| Step: 1
Training loss: 3.077397139416121
Validation loss: 2.6776356325875925

Epoch: 5| Step: 2
Training loss: 2.7790010768013893
Validation loss: 2.684382012879638

Epoch: 5| Step: 3
Training loss: 3.132207721735129
Validation loss: 2.6831193723108133

Epoch: 5| Step: 4
Training loss: 3.267906450648554
Validation loss: 2.683109653250214

Epoch: 5| Step: 5
Training loss: 3.258816717508892
Validation loss: 2.6834119060550976

Epoch: 5| Step: 6
Training loss: 2.706425498575492
Validation loss: 2.687789598044751

Epoch: 5| Step: 7
Training loss: 2.979933704432449
Validation loss: 2.6856807055943746

Epoch: 5| Step: 8
Training loss: 3.2950641305149952
Validation loss: 2.682742502658912

Epoch: 5| Step: 9
Training loss: 2.392007266081424
Validation loss: 2.682033579845156

Epoch: 5| Step: 10
Training loss: 3.3061253370929347
Validation loss: 2.6831747660800143

Epoch: 229| Step: 0
Training loss: 2.568990071534022
Validation loss: 2.6875925269943743

Epoch: 5| Step: 1
Training loss: 3.2547933003649536
Validation loss: 2.6906698915610887

Epoch: 5| Step: 2
Training loss: 2.64832316914219
Validation loss: 2.684497790418548

Epoch: 5| Step: 3
Training loss: 3.55433227105548
Validation loss: 2.6810911437923943

Epoch: 5| Step: 4
Training loss: 3.409321930889247
Validation loss: 2.691394145243069

Epoch: 5| Step: 5
Training loss: 3.290661203560192
Validation loss: 2.6883584397409166

Epoch: 5| Step: 6
Training loss: 2.9335843224507303
Validation loss: 2.6890600398000215

Epoch: 5| Step: 7
Training loss: 2.788074564200752
Validation loss: 2.690322908220625

Epoch: 5| Step: 8
Training loss: 3.3324616881999276
Validation loss: 2.6992678147419946

Epoch: 5| Step: 9
Training loss: 2.38448857628135
Validation loss: 2.692800530308577

Epoch: 5| Step: 10
Training loss: 2.596748457303208
Validation loss: 2.692704524425119

Epoch: 230| Step: 0
Training loss: 3.0158626482521647
Validation loss: 2.7020178912971553

Epoch: 5| Step: 1
Training loss: 2.6536685741724217
Validation loss: 2.7015568418384306

Epoch: 5| Step: 2
Training loss: 3.271215299102316
Validation loss: 2.692228131672096

Epoch: 5| Step: 3
Training loss: 2.8295065524437764
Validation loss: 2.685101015728928

Epoch: 5| Step: 4
Training loss: 2.5603449994313814
Validation loss: 2.6878909594313525

Epoch: 5| Step: 5
Training loss: 3.0386203159793785
Validation loss: 2.690089219304765

Epoch: 5| Step: 6
Training loss: 3.6801336386505907
Validation loss: 2.6856465273926107

Epoch: 5| Step: 7
Training loss: 2.6999957543798905
Validation loss: 2.690318286594082

Epoch: 5| Step: 8
Training loss: 2.897314136721827
Validation loss: 2.690399298269135

Epoch: 5| Step: 9
Training loss: 3.0895310736823838
Validation loss: 2.6917600681480676

Epoch: 5| Step: 10
Training loss: 3.1972908294001208
Validation loss: 2.6911301493186444

Epoch: 231| Step: 0
Training loss: 3.0795774179851785
Validation loss: 2.6975042291022064

Epoch: 5| Step: 1
Training loss: 2.3397778229508686
Validation loss: 2.6926546650594885

Epoch: 5| Step: 2
Training loss: 2.9757838394662532
Validation loss: 2.689914028405517

Epoch: 5| Step: 3
Training loss: 3.3911720221356836
Validation loss: 2.7004822931490247

Epoch: 5| Step: 4
Training loss: 3.29359627352289
Validation loss: 2.6924333386546033

Epoch: 5| Step: 5
Training loss: 3.3867899921320284
Validation loss: 2.6927551502208833

Epoch: 5| Step: 6
Training loss: 2.7159951821398245
Validation loss: 2.690918859049075

Epoch: 5| Step: 7
Training loss: 3.076231088219785
Validation loss: 2.6943885136121697

Epoch: 5| Step: 8
Training loss: 2.3589596414319565
Validation loss: 2.6878200129664065

Epoch: 5| Step: 9
Training loss: 3.345569293924677
Validation loss: 2.6831194105296214

Epoch: 5| Step: 10
Training loss: 2.848861962361606
Validation loss: 2.684347525902293

Epoch: 232| Step: 0
Training loss: 2.7304406335171656
Validation loss: 2.6853574782004768

Epoch: 5| Step: 1
Training loss: 2.6435225801522675
Validation loss: 2.6820530649198076

Epoch: 5| Step: 2
Training loss: 3.5370872661167128
Validation loss: 2.686608220214325

Epoch: 5| Step: 3
Training loss: 3.542648149513988
Validation loss: 2.678291466356097

Epoch: 5| Step: 4
Training loss: 2.8938653053726684
Validation loss: 2.6887880707474747

Epoch: 5| Step: 5
Training loss: 3.132539732514378
Validation loss: 2.6872896673529043

Epoch: 5| Step: 6
Training loss: 2.970945971593137
Validation loss: 2.673593222548448

Epoch: 5| Step: 7
Training loss: 2.966411593183478
Validation loss: 2.6779913304301233

Epoch: 5| Step: 8
Training loss: 2.403526548413186
Validation loss: 2.6750680683067602

Epoch: 5| Step: 9
Training loss: 3.0888590057293634
Validation loss: 2.6753348556392833

Epoch: 5| Step: 10
Training loss: 2.960912216199355
Validation loss: 2.6732830834189194

Epoch: 233| Step: 0
Training loss: 2.8184146994634864
Validation loss: 2.674455109015252

Epoch: 5| Step: 1
Training loss: 3.2172234628157836
Validation loss: 2.6760750332867342

Epoch: 5| Step: 2
Training loss: 3.3889164289456786
Validation loss: 2.6812835535218453

Epoch: 5| Step: 3
Training loss: 2.8625160849839766
Validation loss: 2.6850421280385097

Epoch: 5| Step: 4
Training loss: 3.29050832398467
Validation loss: 2.6776325094589155

Epoch: 5| Step: 5
Training loss: 2.7289105554825754
Validation loss: 2.695213925040914

Epoch: 5| Step: 6
Training loss: 2.7727175355674905
Validation loss: 2.6961155048795984

Epoch: 5| Step: 7
Training loss: 2.454312274112869
Validation loss: 2.6872184078380204

Epoch: 5| Step: 8
Training loss: 3.0002738509754687
Validation loss: 2.6967959356552664

Epoch: 5| Step: 9
Training loss: 3.1968108676954783
Validation loss: 2.6921350221819313

Epoch: 5| Step: 10
Training loss: 3.1895476103579696
Validation loss: 2.6853642659231656

Epoch: 234| Step: 0
Training loss: 2.808269285684763
Validation loss: 2.6890049722445286

Epoch: 5| Step: 1
Training loss: 3.254123126400927
Validation loss: 2.6870685354099995

Epoch: 5| Step: 2
Training loss: 2.601791784131865
Validation loss: 2.6844101696099743

Epoch: 5| Step: 3
Training loss: 3.0561540210217677
Validation loss: 2.6949690205350887

Epoch: 5| Step: 4
Training loss: 3.1829613180299874
Validation loss: 2.688914660957116

Epoch: 5| Step: 5
Training loss: 3.0684597647286806
Validation loss: 2.678366759020869

Epoch: 5| Step: 6
Training loss: 2.768729498724889
Validation loss: 2.683930094336234

Epoch: 5| Step: 7
Training loss: 3.3164610302178454
Validation loss: 2.6789620805176613

Epoch: 5| Step: 8
Training loss: 3.1983997754591633
Validation loss: 2.676454609492781

Epoch: 5| Step: 9
Training loss: 2.7931649946079578
Validation loss: 2.6872327556745397

Epoch: 5| Step: 10
Training loss: 2.806745194071264
Validation loss: 2.67694250743272

Epoch: 235| Step: 0
Training loss: 3.330685915254793
Validation loss: 2.670652432090728

Epoch: 5| Step: 1
Training loss: 2.745367830573252
Validation loss: 2.674953131408405

Epoch: 5| Step: 2
Training loss: 2.8640132452376132
Validation loss: 2.672491413525775

Epoch: 5| Step: 3
Training loss: 2.8314462623192
Validation loss: 2.673312989225205

Epoch: 5| Step: 4
Training loss: 2.785846212777428
Validation loss: 2.675931815436819

Epoch: 5| Step: 5
Training loss: 3.6292720483019645
Validation loss: 2.67583558755183

Epoch: 5| Step: 6
Training loss: 2.7200154834194428
Validation loss: 2.6863037594023416

Epoch: 5| Step: 7
Training loss: 2.994494154153221
Validation loss: 2.682355080291121

Epoch: 5| Step: 8
Training loss: 2.7331412011361396
Validation loss: 2.6782975818523105

Epoch: 5| Step: 9
Training loss: 3.2904151436599838
Validation loss: 2.675002965157826

Epoch: 5| Step: 10
Training loss: 2.901055071723873
Validation loss: 2.6725991124271546

Epoch: 236| Step: 0
Training loss: 3.0269816126647755
Validation loss: 2.6769237465157802

Epoch: 5| Step: 1
Training loss: 2.9030491419675815
Validation loss: 2.6702685916687128

Epoch: 5| Step: 2
Training loss: 3.0065185934456444
Validation loss: 2.6690579877500786

Epoch: 5| Step: 3
Training loss: 2.716067075578088
Validation loss: 2.673049822951182

Epoch: 5| Step: 4
Training loss: 2.9659474847714136
Validation loss: 2.672275375288296

Epoch: 5| Step: 5
Training loss: 3.0321804860126416
Validation loss: 2.6735013598245936

Epoch: 5| Step: 6
Training loss: 3.3820911369564244
Validation loss: 2.6696740664594074

Epoch: 5| Step: 7
Training loss: 3.0162474627272697
Validation loss: 2.6763859648089823

Epoch: 5| Step: 8
Training loss: 2.997139838870572
Validation loss: 2.6777972030925064

Epoch: 5| Step: 9
Training loss: 2.6642617964940247
Validation loss: 2.681480195285355

Epoch: 5| Step: 10
Training loss: 3.2428663163628535
Validation loss: 2.684709732135285

Epoch: 237| Step: 0
Training loss: 2.3433992250528966
Validation loss: 2.679708045879033

Epoch: 5| Step: 1
Training loss: 2.891303070544447
Validation loss: 2.681337769051845

Epoch: 5| Step: 2
Training loss: 3.09170125306175
Validation loss: 2.683378234922751

Epoch: 5| Step: 3
Training loss: 3.164056923943775
Validation loss: 2.681722471441892

Epoch: 5| Step: 4
Training loss: 3.1207638830004334
Validation loss: 2.683957761983784

Epoch: 5| Step: 5
Training loss: 2.9284898268067194
Validation loss: 2.678583026651879

Epoch: 5| Step: 6
Training loss: 3.3020288761754766
Validation loss: 2.6887873098896224

Epoch: 5| Step: 7
Training loss: 3.0588483253828973
Validation loss: 2.689031170016042

Epoch: 5| Step: 8
Training loss: 2.796395287318263
Validation loss: 2.6802844927573535

Epoch: 5| Step: 9
Training loss: 3.0566991245899624
Validation loss: 2.6866698665452766

Epoch: 5| Step: 10
Training loss: 3.0696251951673434
Validation loss: 2.696160226520707

Epoch: 238| Step: 0
Training loss: 3.3326841834896874
Validation loss: 2.6976247453670843

Epoch: 5| Step: 1
Training loss: 2.651731979537617
Validation loss: 2.6878917377108613

Epoch: 5| Step: 2
Training loss: 3.183628498660054
Validation loss: 2.6821662724581765

Epoch: 5| Step: 3
Training loss: 2.6866491878341674
Validation loss: 2.6762474468910815

Epoch: 5| Step: 4
Training loss: 2.8971215728543305
Validation loss: 2.674806393523209

Epoch: 5| Step: 5
Training loss: 3.2453192235576718
Validation loss: 2.666941862813971

Epoch: 5| Step: 6
Training loss: 2.6913214726930454
Validation loss: 2.665826273465357

Epoch: 5| Step: 7
Training loss: 2.5475114834482655
Validation loss: 2.6644817933276728

Epoch: 5| Step: 8
Training loss: 3.4077846324818406
Validation loss: 2.664195604625572

Epoch: 5| Step: 9
Training loss: 2.969484419078323
Validation loss: 2.66942261431155

Epoch: 5| Step: 10
Training loss: 3.1922779550307476
Validation loss: 2.6636384198166265

Epoch: 239| Step: 0
Training loss: 3.1336365945303215
Validation loss: 2.664594478369478

Epoch: 5| Step: 1
Training loss: 2.6036897960191117
Validation loss: 2.6705980169179324

Epoch: 5| Step: 2
Training loss: 3.0536943855483623
Validation loss: 2.6740590214721873

Epoch: 5| Step: 3
Training loss: 3.3038346292522403
Validation loss: 2.669651500691302

Epoch: 5| Step: 4
Training loss: 2.7172617730490978
Validation loss: 2.679645799302626

Epoch: 5| Step: 5
Training loss: 2.111518731278286
Validation loss: 2.683398081395047

Epoch: 5| Step: 6
Training loss: 3.0753480419659223
Validation loss: 2.681903216896032

Epoch: 5| Step: 7
Training loss: 3.508373054285577
Validation loss: 2.69005784844394

Epoch: 5| Step: 8
Training loss: 2.938105743935849
Validation loss: 2.7051734643043983

Epoch: 5| Step: 9
Training loss: 3.0250985563002057
Validation loss: 2.732072665934089

Epoch: 5| Step: 10
Training loss: 3.2215503251536455
Validation loss: 2.736974939793216

Epoch: 240| Step: 0
Training loss: 3.0215860064921047
Validation loss: 2.7633947787994035

Epoch: 5| Step: 1
Training loss: 2.615081668694431
Validation loss: 2.7548443932100115

Epoch: 5| Step: 2
Training loss: 2.6003123535919057
Validation loss: 2.73440398357635

Epoch: 5| Step: 3
Training loss: 2.888786102161766
Validation loss: 2.69831458339888

Epoch: 5| Step: 4
Training loss: 3.084359762816973
Validation loss: 2.6919348360627096

Epoch: 5| Step: 5
Training loss: 3.059517010986397
Validation loss: 2.6845217889487145

Epoch: 5| Step: 6
Training loss: 2.2663121726949322
Validation loss: 2.6727138042896974

Epoch: 5| Step: 7
Training loss: 3.0067208030490282
Validation loss: 2.6714365475344843

Epoch: 5| Step: 8
Training loss: 3.284647753684357
Validation loss: 2.6759968490455117

Epoch: 5| Step: 9
Training loss: 3.6580532224526063
Validation loss: 2.6735511506354146

Epoch: 5| Step: 10
Training loss: 3.4685567166202045
Validation loss: 2.6738435250464434

Epoch: 241| Step: 0
Training loss: 2.888655202738821
Validation loss: 2.679550882544557

Epoch: 5| Step: 1
Training loss: 2.557213051099693
Validation loss: 2.679692914881898

Epoch: 5| Step: 2
Training loss: 3.0011743790053655
Validation loss: 2.6748119428833115

Epoch: 5| Step: 3
Training loss: 3.0903532859540244
Validation loss: 2.6765362107978503

Epoch: 5| Step: 4
Training loss: 2.8321435524608574
Validation loss: 2.6759545701465295

Epoch: 5| Step: 5
Training loss: 3.201654310571623
Validation loss: 2.672223301399943

Epoch: 5| Step: 6
Training loss: 3.4672820963253117
Validation loss: 2.6726261347945957

Epoch: 5| Step: 7
Training loss: 2.9069990607891003
Validation loss: 2.671705061022578

Epoch: 5| Step: 8
Training loss: 2.6262758878133714
Validation loss: 2.669630749695983

Epoch: 5| Step: 9
Training loss: 3.1952842953656644
Validation loss: 2.67222956029751

Epoch: 5| Step: 10
Training loss: 3.140583854140063
Validation loss: 2.6755708948751624

Epoch: 242| Step: 0
Training loss: 3.416124083693095
Validation loss: 2.6724321424577093

Epoch: 5| Step: 1
Training loss: 3.2669479391750755
Validation loss: 2.678273307394692

Epoch: 5| Step: 2
Training loss: 2.7423542548010977
Validation loss: 2.673563381245442

Epoch: 5| Step: 3
Training loss: 2.6276172124704535
Validation loss: 2.68189092490493

Epoch: 5| Step: 4
Training loss: 2.8286407169096055
Validation loss: 2.677122462861985

Epoch: 5| Step: 5
Training loss: 3.047116157573679
Validation loss: 2.6868204477252204

Epoch: 5| Step: 6
Training loss: 2.966255183739841
Validation loss: 2.6933512729464404

Epoch: 5| Step: 7
Training loss: 2.8877410523833533
Validation loss: 2.698018310193085

Epoch: 5| Step: 8
Training loss: 3.3592282285343216
Validation loss: 2.713481668506498

Epoch: 5| Step: 9
Training loss: 2.504618193868699
Validation loss: 2.713649071577064

Epoch: 5| Step: 10
Training loss: 3.189004281319549
Validation loss: 2.6996581800825497

Epoch: 243| Step: 0
Training loss: 2.9482562585060874
Validation loss: 2.688844311657754

Epoch: 5| Step: 1
Training loss: 3.320684147399013
Validation loss: 2.676557518382758

Epoch: 5| Step: 2
Training loss: 3.2600049296148743
Validation loss: 2.662758180459041

Epoch: 5| Step: 3
Training loss: 2.9607572878144186
Validation loss: 2.663107768565688

Epoch: 5| Step: 4
Training loss: 3.2318589011259617
Validation loss: 2.656749346881858

Epoch: 5| Step: 5
Training loss: 3.086589039457397
Validation loss: 2.6649618185293726

Epoch: 5| Step: 6
Training loss: 3.1484977773192377
Validation loss: 2.6587507083509525

Epoch: 5| Step: 7
Training loss: 2.316030951166295
Validation loss: 2.663695900087426

Epoch: 5| Step: 8
Training loss: 3.0979891931235732
Validation loss: 2.6636932168105205

Epoch: 5| Step: 9
Training loss: 2.644474000747805
Validation loss: 2.6621225451059822

Epoch: 5| Step: 10
Training loss: 2.6540913505787245
Validation loss: 2.657731818303204

Epoch: 244| Step: 0
Training loss: 3.1589327448888427
Validation loss: 2.661615160025708

Epoch: 5| Step: 1
Training loss: 3.285374982267456
Validation loss: 2.6598984689477647

Epoch: 5| Step: 2
Training loss: 2.9166394005363827
Validation loss: 2.6634251536411364

Epoch: 5| Step: 3
Training loss: 2.7729337852708165
Validation loss: 2.659118987871076

Epoch: 5| Step: 4
Training loss: 2.6294111699363296
Validation loss: 2.663737512669534

Epoch: 5| Step: 5
Training loss: 2.9290697590916963
Validation loss: 2.6642484887783255

Epoch: 5| Step: 6
Training loss: 3.4192466918991786
Validation loss: 2.669596138416964

Epoch: 5| Step: 7
Training loss: 2.5565777706058075
Validation loss: 2.6647369096001943

Epoch: 5| Step: 8
Training loss: 2.95141325896929
Validation loss: 2.6659482852244705

Epoch: 5| Step: 9
Training loss: 2.7920297604808306
Validation loss: 2.6612008636916427

Epoch: 5| Step: 10
Training loss: 3.3721383289820777
Validation loss: 2.6609230277778186

Epoch: 245| Step: 0
Training loss: 2.681284436980648
Validation loss: 2.6533117355202074

Epoch: 5| Step: 1
Training loss: 2.835791718069916
Validation loss: 2.6573434488874854

Epoch: 5| Step: 2
Training loss: 2.9069505072895643
Validation loss: 2.6538178574131837

Epoch: 5| Step: 3
Training loss: 3.3636969155524796
Validation loss: 2.658179247629862

Epoch: 5| Step: 4
Training loss: 3.4454888192730144
Validation loss: 2.652262983292015

Epoch: 5| Step: 5
Training loss: 2.7160401267344594
Validation loss: 2.6562952026922027

Epoch: 5| Step: 6
Training loss: 2.6107093916849555
Validation loss: 2.6573137521514374

Epoch: 5| Step: 7
Training loss: 3.20056079480536
Validation loss: 2.657692176921575

Epoch: 5| Step: 8
Training loss: 3.029991281830486
Validation loss: 2.6622338624484807

Epoch: 5| Step: 9
Training loss: 2.8203916247989973
Validation loss: 2.654752151932398

Epoch: 5| Step: 10
Training loss: 3.1513488787913304
Validation loss: 2.6588426612837366

Epoch: 246| Step: 0
Training loss: 2.560305702612975
Validation loss: 2.670605919214854

Epoch: 5| Step: 1
Training loss: 2.6527308770028752
Validation loss: 2.670029698670246

Epoch: 5| Step: 2
Training loss: 3.242510455488938
Validation loss: 2.681635271410949

Epoch: 5| Step: 3
Training loss: 2.4861770907644223
Validation loss: 2.677484231334081

Epoch: 5| Step: 4
Training loss: 2.664013993613116
Validation loss: 2.692402353124743

Epoch: 5| Step: 5
Training loss: 3.5082713891100896
Validation loss: 2.679458411771019

Epoch: 5| Step: 6
Training loss: 2.9763571200265297
Validation loss: 2.6758832387078146

Epoch: 5| Step: 7
Training loss: 3.1741472195361484
Validation loss: 2.6747443798389106

Epoch: 5| Step: 8
Training loss: 3.172120183479034
Validation loss: 2.664731056411949

Epoch: 5| Step: 9
Training loss: 3.280837260127574
Validation loss: 2.683695604203789

Epoch: 5| Step: 10
Training loss: 2.931169872368149
Validation loss: 2.682801667299544

Epoch: 247| Step: 0
Training loss: 3.1134975075847304
Validation loss: 2.679266329298652

Epoch: 5| Step: 1
Training loss: 2.8968481760110243
Validation loss: 2.6688662287423472

Epoch: 5| Step: 2
Training loss: 3.0699298028034168
Validation loss: 2.6651792345126974

Epoch: 5| Step: 3
Training loss: 2.073837216447686
Validation loss: 2.6631667244483737

Epoch: 5| Step: 4
Training loss: 2.9777712632894033
Validation loss: 2.6588090116579086

Epoch: 5| Step: 5
Training loss: 3.5232718485866186
Validation loss: 2.6620370095171597

Epoch: 5| Step: 6
Training loss: 3.074490177721385
Validation loss: 2.6604331175744504

Epoch: 5| Step: 7
Training loss: 2.961653891990072
Validation loss: 2.664020496018387

Epoch: 5| Step: 8
Training loss: 3.112375469857172
Validation loss: 2.661973579280123

Epoch: 5| Step: 9
Training loss: 2.923415486809993
Validation loss: 2.6542723404797632

Epoch: 5| Step: 10
Training loss: 2.9348041257207704
Validation loss: 2.6630850480039796

Epoch: 248| Step: 0
Training loss: 2.9705210974187612
Validation loss: 2.6619540444966603

Epoch: 5| Step: 1
Training loss: 3.3815991910617167
Validation loss: 2.6603660759140504

Epoch: 5| Step: 2
Training loss: 3.260193903486429
Validation loss: 2.657194024110287

Epoch: 5| Step: 3
Training loss: 2.5401117123044665
Validation loss: 2.6683816631251935

Epoch: 5| Step: 4
Training loss: 2.714173861400269
Validation loss: 2.666818319002625

Epoch: 5| Step: 5
Training loss: 2.9246688785769246
Validation loss: 2.6768308066908406

Epoch: 5| Step: 6
Training loss: 3.545387393030922
Validation loss: 2.6925735850893413

Epoch: 5| Step: 7
Training loss: 3.029621276603873
Validation loss: 2.680834984656939

Epoch: 5| Step: 8
Training loss: 2.4102688211276555
Validation loss: 2.6829329574185645

Epoch: 5| Step: 9
Training loss: 2.7587410117496836
Validation loss: 2.6888577808126586

Epoch: 5| Step: 10
Training loss: 3.181095945454109
Validation loss: 2.6747942960699675

Epoch: 249| Step: 0
Training loss: 3.1678334311901746
Validation loss: 2.662984564808924

Epoch: 5| Step: 1
Training loss: 2.8651807867134242
Validation loss: 2.662196863112561

Epoch: 5| Step: 2
Training loss: 3.024395142921934
Validation loss: 2.6535299012304225

Epoch: 5| Step: 3
Training loss: 3.0770422875712895
Validation loss: 2.6516058862314518

Epoch: 5| Step: 4
Training loss: 3.650416227672388
Validation loss: 2.653647247033591

Epoch: 5| Step: 5
Training loss: 2.8267863778040474
Validation loss: 2.6514908044083723

Epoch: 5| Step: 6
Training loss: 2.8696079276101685
Validation loss: 2.6500049409918947

Epoch: 5| Step: 7
Training loss: 2.8859307190423515
Validation loss: 2.655633444411902

Epoch: 5| Step: 8
Training loss: 2.6966123238625754
Validation loss: 2.652012364663092

Epoch: 5| Step: 9
Training loss: 3.0290421772964504
Validation loss: 2.6516761609576363

Epoch: 5| Step: 10
Training loss: 2.571470886593773
Validation loss: 2.648050353316286

Epoch: 250| Step: 0
Training loss: 3.7400798556528385
Validation loss: 2.650286190779816

Epoch: 5| Step: 1
Training loss: 2.8052965953231994
Validation loss: 2.65240452252315

Epoch: 5| Step: 2
Training loss: 2.852817207104388
Validation loss: 2.651924516391902

Epoch: 5| Step: 3
Training loss: 3.0054675188252937
Validation loss: 2.654595672422011

Epoch: 5| Step: 4
Training loss: 3.096309797366389
Validation loss: 2.651870330803884

Epoch: 5| Step: 5
Training loss: 2.803563309745383
Validation loss: 2.6535446461837973

Epoch: 5| Step: 6
Training loss: 3.4254445309594748
Validation loss: 2.6609253795346945

Epoch: 5| Step: 7
Training loss: 2.765004751191015
Validation loss: 2.6670997143673003

Epoch: 5| Step: 8
Training loss: 2.861982980204371
Validation loss: 2.663999776222402

Epoch: 5| Step: 9
Training loss: 2.582440919449564
Validation loss: 2.674354699302097

Epoch: 5| Step: 10
Training loss: 2.5643389546415256
Validation loss: 2.664152824264305

Epoch: 251| Step: 0
Training loss: 2.8004833791927797
Validation loss: 2.6989994388858416

Epoch: 5| Step: 1
Training loss: 3.153070491323401
Validation loss: 2.708393877802524

Epoch: 5| Step: 2
Training loss: 3.0165968203669427
Validation loss: 2.708861520218666

Epoch: 5| Step: 3
Training loss: 3.139081129490669
Validation loss: 2.7080280204434826

Epoch: 5| Step: 4
Training loss: 2.862849225059679
Validation loss: 2.7239525757139

Epoch: 5| Step: 5
Training loss: 3.076102274758261
Validation loss: 2.7077248561054286

Epoch: 5| Step: 6
Training loss: 2.816404049008762
Validation loss: 2.732682774033585

Epoch: 5| Step: 7
Training loss: 2.826915672088938
Validation loss: 2.7056117955500607

Epoch: 5| Step: 8
Training loss: 3.207570930820567
Validation loss: 2.7066850125179895

Epoch: 5| Step: 9
Training loss: 2.8246139735238636
Validation loss: 2.676778166333803

Epoch: 5| Step: 10
Training loss: 3.0271854482301004
Validation loss: 2.652494348790968

Epoch: 252| Step: 0
Training loss: 2.5521968167563376
Validation loss: 2.653071696378895

Epoch: 5| Step: 1
Training loss: 3.256755849605621
Validation loss: 2.651893257655844

Epoch: 5| Step: 2
Training loss: 2.7333809925979584
Validation loss: 2.649253741938551

Epoch: 5| Step: 3
Training loss: 2.781623300938496
Validation loss: 2.6570049788543915

Epoch: 5| Step: 4
Training loss: 2.6052430840123986
Validation loss: 2.64693378885346

Epoch: 5| Step: 5
Training loss: 2.8029128386670448
Validation loss: 2.6509592959054973

Epoch: 5| Step: 6
Training loss: 3.367785194968022
Validation loss: 2.661906447363835

Epoch: 5| Step: 7
Training loss: 3.1331000065334558
Validation loss: 2.649957086668783

Epoch: 5| Step: 8
Training loss: 3.2523048737598885
Validation loss: 2.64906720217125

Epoch: 5| Step: 9
Training loss: 2.9381395009098257
Validation loss: 2.6594913450323507

Epoch: 5| Step: 10
Training loss: 3.226459640082614
Validation loss: 2.663440576299031

Epoch: 253| Step: 0
Training loss: 3.230639968633706
Validation loss: 2.66243852625944

Epoch: 5| Step: 1
Training loss: 3.2045884673664764
Validation loss: 2.6576984140926974

Epoch: 5| Step: 2
Training loss: 2.8294066164926943
Validation loss: 2.6593320354314267

Epoch: 5| Step: 3
Training loss: 3.0224806580031127
Validation loss: 2.6534241171682846

Epoch: 5| Step: 4
Training loss: 2.715642270997924
Validation loss: 2.6562146121134336

Epoch: 5| Step: 5
Training loss: 2.789845247249581
Validation loss: 2.6557634789972075

Epoch: 5| Step: 6
Training loss: 2.401817202045109
Validation loss: 2.6528741896733603

Epoch: 5| Step: 7
Training loss: 3.2821348904465997
Validation loss: 2.648481990996977

Epoch: 5| Step: 8
Training loss: 3.350187860032593
Validation loss: 2.65414871210005

Epoch: 5| Step: 9
Training loss: 2.7043646467137195
Validation loss: 2.657349920343198

Epoch: 5| Step: 10
Training loss: 3.0010968428446017
Validation loss: 2.6570525113443955

Epoch: 254| Step: 0
Training loss: 2.452835260276645
Validation loss: 2.6584120886471996

Epoch: 5| Step: 1
Training loss: 3.111554479417217
Validation loss: 2.6619063086796744

Epoch: 5| Step: 2
Training loss: 3.0349989841717147
Validation loss: 2.6622053325025736

Epoch: 5| Step: 3
Training loss: 3.0011244891645017
Validation loss: 2.6649240740050044

Epoch: 5| Step: 4
Training loss: 3.3154921063711895
Validation loss: 2.664830808990839

Epoch: 5| Step: 5
Training loss: 2.7034309522765336
Validation loss: 2.6697741183134007

Epoch: 5| Step: 6
Training loss: 2.8480200934076314
Validation loss: 2.6679254401416688

Epoch: 5| Step: 7
Training loss: 2.592187617729051
Validation loss: 2.6678519947315316

Epoch: 5| Step: 8
Training loss: 3.088879382929213
Validation loss: 2.668518710216603

Epoch: 5| Step: 9
Training loss: 3.4857500724384822
Validation loss: 2.6625511523862833

Epoch: 5| Step: 10
Training loss: 2.871050734424788
Validation loss: 2.6714314460370736

Epoch: 255| Step: 0
Training loss: 2.6970219153283637
Validation loss: 2.691772742698693

Epoch: 5| Step: 1
Training loss: 3.1547042536373326
Validation loss: 2.6820224603373473

Epoch: 5| Step: 2
Training loss: 3.368014842483182
Validation loss: 2.67275368423918

Epoch: 5| Step: 3
Training loss: 3.2767969341390395
Validation loss: 2.6587017849242818

Epoch: 5| Step: 4
Training loss: 3.0449416066350734
Validation loss: 2.6505184764973007

Epoch: 5| Step: 5
Training loss: 2.997722556002492
Validation loss: 2.645787460966897

Epoch: 5| Step: 6
Training loss: 2.687155590610982
Validation loss: 2.646752475350645

Epoch: 5| Step: 7
Training loss: 2.999266534788814
Validation loss: 2.654601537334903

Epoch: 5| Step: 8
Training loss: 3.0384001414587742
Validation loss: 2.650606771301598

Epoch: 5| Step: 9
Training loss: 2.5116433804180778
Validation loss: 2.6576363272538086

Epoch: 5| Step: 10
Training loss: 2.824370700658171
Validation loss: 2.6570751956900884

Epoch: 256| Step: 0
Training loss: 3.2076376784189926
Validation loss: 2.6571438216276073

Epoch: 5| Step: 1
Training loss: 2.7743692041978067
Validation loss: 2.6525060569682664

Epoch: 5| Step: 2
Training loss: 3.1583131901913126
Validation loss: 2.648567680740741

Epoch: 5| Step: 3
Training loss: 3.0851907719960163
Validation loss: 2.642140962471484

Epoch: 5| Step: 4
Training loss: 2.5151154375222027
Validation loss: 2.6450613615685183

Epoch: 5| Step: 5
Training loss: 2.7925912455214403
Validation loss: 2.6474229250654466

Epoch: 5| Step: 6
Training loss: 3.015643974600279
Validation loss: 2.642266023957823

Epoch: 5| Step: 7
Training loss: 3.003694167171875
Validation loss: 2.6449344598029594

Epoch: 5| Step: 8
Training loss: 3.1485989436934547
Validation loss: 2.641352903228813

Epoch: 5| Step: 9
Training loss: 3.060115898281156
Validation loss: 2.6435152805930167

Epoch: 5| Step: 10
Training loss: 2.841583600512857
Validation loss: 2.6536439836068477

Epoch: 257| Step: 0
Training loss: 2.9424909033104
Validation loss: 2.6612664489818822

Epoch: 5| Step: 1
Training loss: 3.0910187041384103
Validation loss: 2.6780254043433684

Epoch: 5| Step: 2
Training loss: 3.1549420054284973
Validation loss: 2.685583357905295

Epoch: 5| Step: 3
Training loss: 2.5820305112990622
Validation loss: 2.6823875046137515

Epoch: 5| Step: 4
Training loss: 3.3198277736711552
Validation loss: 2.685848998615296

Epoch: 5| Step: 5
Training loss: 3.260634117472008
Validation loss: 2.6897264364757674

Epoch: 5| Step: 6
Training loss: 3.196662449785885
Validation loss: 2.667493446553405

Epoch: 5| Step: 7
Training loss: 3.2781057642689624
Validation loss: 2.667796745984149

Epoch: 5| Step: 8
Training loss: 2.3843158919581193
Validation loss: 2.6588821698111675

Epoch: 5| Step: 9
Training loss: 3.0691366103647217
Validation loss: 2.6569829442310384

Epoch: 5| Step: 10
Training loss: 2.089308055064236
Validation loss: 2.6454552058969845

Epoch: 258| Step: 0
Training loss: 3.1851603579313403
Validation loss: 2.6489714345848805

Epoch: 5| Step: 1
Training loss: 2.5126865830104874
Validation loss: 2.646219986063506

Epoch: 5| Step: 2
Training loss: 2.770720620599589
Validation loss: 2.6439769557371675

Epoch: 5| Step: 3
Training loss: 3.212625398674653
Validation loss: 2.6417298597398315

Epoch: 5| Step: 4
Training loss: 2.9304523741128023
Validation loss: 2.6385060538018053

Epoch: 5| Step: 5
Training loss: 2.962989438344856
Validation loss: 2.6444087328587336

Epoch: 5| Step: 6
Training loss: 2.8397681896541624
Validation loss: 2.6393493514710635

Epoch: 5| Step: 7
Training loss: 3.1651146917067186
Validation loss: 2.636952842368795

Epoch: 5| Step: 8
Training loss: 3.0850516677560864
Validation loss: 2.6434334731400297

Epoch: 5| Step: 9
Training loss: 3.1199082664306625
Validation loss: 2.637915083654325

Epoch: 5| Step: 10
Training loss: 2.7700235335524366
Validation loss: 2.64310072817112

Epoch: 259| Step: 0
Training loss: 2.855719392267995
Validation loss: 2.6442521977547746

Epoch: 5| Step: 1
Training loss: 3.283475865660653
Validation loss: 2.6417896042100852

Epoch: 5| Step: 2
Training loss: 3.2943153026529592
Validation loss: 2.6532646374841127

Epoch: 5| Step: 3
Training loss: 2.2494311143341923
Validation loss: 2.650772330216515

Epoch: 5| Step: 4
Training loss: 3.3358959043531584
Validation loss: 2.6552497017814165

Epoch: 5| Step: 5
Training loss: 2.3552012125543396
Validation loss: 2.6590532021038933

Epoch: 5| Step: 6
Training loss: 3.1025891658686504
Validation loss: 2.6621112644269296

Epoch: 5| Step: 7
Training loss: 2.9179677695153976
Validation loss: 2.666261827466398

Epoch: 5| Step: 8
Training loss: 3.0189142028504823
Validation loss: 2.672223531647814

Epoch: 5| Step: 9
Training loss: 2.8690229564451686
Validation loss: 2.6701407574144365

Epoch: 5| Step: 10
Training loss: 3.1775963207565474
Validation loss: 2.6650721404698046

Epoch: 260| Step: 0
Training loss: 2.905916256353653
Validation loss: 2.660233576649984

Epoch: 5| Step: 1
Training loss: 3.0113387406172336
Validation loss: 2.6693561422470435

Epoch: 5| Step: 2
Training loss: 3.623448796355424
Validation loss: 2.668360281607056

Epoch: 5| Step: 3
Training loss: 2.8081427836836728
Validation loss: 2.6667743982836787

Epoch: 5| Step: 4
Training loss: 3.0944043633060403
Validation loss: 2.6559274186839694

Epoch: 5| Step: 5
Training loss: 3.353300768679578
Validation loss: 2.6469092345109515

Epoch: 5| Step: 6
Training loss: 2.8371352511663317
Validation loss: 2.642658468859739

Epoch: 5| Step: 7
Training loss: 2.847133761223184
Validation loss: 2.6384438583277334

Epoch: 5| Step: 8
Training loss: 2.7624868919096093
Validation loss: 2.637405103212569

Epoch: 5| Step: 9
Training loss: 2.6650770833961097
Validation loss: 2.637216530151322

Epoch: 5| Step: 10
Training loss: 2.558635495842645
Validation loss: 2.642902133912022

Epoch: 261| Step: 0
Training loss: 3.293510709173855
Validation loss: 2.6407798454221294

Epoch: 5| Step: 1
Training loss: 2.877679156999168
Validation loss: 2.637423561052672

Epoch: 5| Step: 2
Training loss: 2.5960956675648386
Validation loss: 2.6414891078077547

Epoch: 5| Step: 3
Training loss: 3.3241306746006978
Validation loss: 2.64442444674104

Epoch: 5| Step: 4
Training loss: 3.043718160035836
Validation loss: 2.641924607277328

Epoch: 5| Step: 5
Training loss: 3.219051013685701
Validation loss: 2.6470183694201164

Epoch: 5| Step: 6
Training loss: 2.7464665340299317
Validation loss: 2.6459612309597293

Epoch: 5| Step: 7
Training loss: 3.019256302923238
Validation loss: 2.651226660417774

Epoch: 5| Step: 8
Training loss: 3.0107537491162213
Validation loss: 2.664804301152081

Epoch: 5| Step: 9
Training loss: 2.6471586937857445
Validation loss: 2.650997288577841

Epoch: 5| Step: 10
Training loss: 2.7210175277106172
Validation loss: 2.6474994519496415

Epoch: 262| Step: 0
Training loss: 2.887877111869
Validation loss: 2.643370217189325

Epoch: 5| Step: 1
Training loss: 3.32249755767434
Validation loss: 2.6454415186669284

Epoch: 5| Step: 2
Training loss: 2.6821171280945877
Validation loss: 2.6394597789785896

Epoch: 5| Step: 3
Training loss: 2.9455673148020693
Validation loss: 2.642796831444117

Epoch: 5| Step: 4
Training loss: 2.7291764023779463
Validation loss: 2.644349771763787

Epoch: 5| Step: 5
Training loss: 2.949907922115943
Validation loss: 2.6454888054013166

Epoch: 5| Step: 6
Training loss: 2.816348261771916
Validation loss: 2.6414069959327273

Epoch: 5| Step: 7
Training loss: 3.227531527742718
Validation loss: 2.6539075054358796

Epoch: 5| Step: 8
Training loss: 3.329561738280063
Validation loss: 2.651125817696202

Epoch: 5| Step: 9
Training loss: 3.0525745782013183
Validation loss: 2.670790696896033

Epoch: 5| Step: 10
Training loss: 2.474713715458866
Validation loss: 2.659955548141618

Epoch: 263| Step: 0
Training loss: 3.1833848007062664
Validation loss: 2.669324412474697

Epoch: 5| Step: 1
Training loss: 2.784385970551085
Validation loss: 2.6717131922560746

Epoch: 5| Step: 2
Training loss: 3.124171795770019
Validation loss: 2.6652866652328946

Epoch: 5| Step: 3
Training loss: 3.356119254920342
Validation loss: 2.668121091875883

Epoch: 5| Step: 4
Training loss: 2.4993145956804144
Validation loss: 2.6620946707442927

Epoch: 5| Step: 5
Training loss: 2.3509847241696
Validation loss: 2.6591340865041913

Epoch: 5| Step: 6
Training loss: 3.5808391022423027
Validation loss: 2.662165429354666

Epoch: 5| Step: 7
Training loss: 3.3371636953468458
Validation loss: 2.6776098479970614

Epoch: 5| Step: 8
Training loss: 2.373416272207212
Validation loss: 2.6757458253268096

Epoch: 5| Step: 9
Training loss: 2.659866294798909
Validation loss: 2.674170420971798

Epoch: 5| Step: 10
Training loss: 3.0152622459320457
Validation loss: 2.678241986701805

Epoch: 264| Step: 0
Training loss: 3.204470319377447
Validation loss: 2.7155683800262516

Epoch: 5| Step: 1
Training loss: 2.9155096393099407
Validation loss: 2.7127326765732995

Epoch: 5| Step: 2
Training loss: 2.377034570682498
Validation loss: 2.71928440301969

Epoch: 5| Step: 3
Training loss: 2.610125770607829
Validation loss: 2.741836202345334

Epoch: 5| Step: 4
Training loss: 3.1653483474212534
Validation loss: 2.739168932508877

Epoch: 5| Step: 5
Training loss: 2.572367487275779
Validation loss: 2.7171606204260907

Epoch: 5| Step: 6
Training loss: 3.689589086463847
Validation loss: 2.704009374774058

Epoch: 5| Step: 7
Training loss: 3.2379733354532054
Validation loss: 2.6902013701424092

Epoch: 5| Step: 8
Training loss: 2.96390081194889
Validation loss: 2.6710796264973373

Epoch: 5| Step: 9
Training loss: 3.2451038159425836
Validation loss: 2.666393120512535

Epoch: 5| Step: 10
Training loss: 2.1609774747889925
Validation loss: 2.656175014684878

Epoch: 265| Step: 0
Training loss: 2.6428688041694857
Validation loss: 2.6615637666101293

Epoch: 5| Step: 1
Training loss: 3.2164440598488135
Validation loss: 2.650578531618139

Epoch: 5| Step: 2
Training loss: 2.851413001753233
Validation loss: 2.644039315812858

Epoch: 5| Step: 3
Training loss: 2.82481975149176
Validation loss: 2.6473068237415665

Epoch: 5| Step: 4
Training loss: 2.8976625295875946
Validation loss: 2.6423825844641082

Epoch: 5| Step: 5
Training loss: 3.1469956497050795
Validation loss: 2.6431749059560454

Epoch: 5| Step: 6
Training loss: 3.162477600259574
Validation loss: 2.650588394142344

Epoch: 5| Step: 7
Training loss: 2.8478829669051495
Validation loss: 2.654431188834866

Epoch: 5| Step: 8
Training loss: 2.7360120831774872
Validation loss: 2.6634743416265723

Epoch: 5| Step: 9
Training loss: 2.989348576241707
Validation loss: 2.6744445964057815

Epoch: 5| Step: 10
Training loss: 3.2137309821867013
Validation loss: 2.6702592041028796

Epoch: 266| Step: 0
Training loss: 3.233382068017685
Validation loss: 2.660065072034948

Epoch: 5| Step: 1
Training loss: 2.897043556157203
Validation loss: 2.6490872103726013

Epoch: 5| Step: 2
Training loss: 3.1021117677702668
Validation loss: 2.6356473237565234

Epoch: 5| Step: 3
Training loss: 2.820055329070867
Validation loss: 2.6338179985644894

Epoch: 5| Step: 4
Training loss: 2.8285407503674502
Validation loss: 2.6370924006346774

Epoch: 5| Step: 5
Training loss: 2.850489417098788
Validation loss: 2.636321030385414

Epoch: 5| Step: 6
Training loss: 2.6351756009506198
Validation loss: 2.6388555973315495

Epoch: 5| Step: 7
Training loss: 2.722269783339798
Validation loss: 2.6411627231500905

Epoch: 5| Step: 8
Training loss: 3.0308038442199905
Validation loss: 2.638686139475409

Epoch: 5| Step: 9
Training loss: 3.3237863835484243
Validation loss: 2.6412500732761037

Epoch: 5| Step: 10
Training loss: 2.9970327644071855
Validation loss: 2.6495131406616004

Epoch: 267| Step: 0
Training loss: 3.1204578195809956
Validation loss: 2.6427195291027648

Epoch: 5| Step: 1
Training loss: 3.111853297200615
Validation loss: 2.6408249309161245

Epoch: 5| Step: 2
Training loss: 2.529999035318666
Validation loss: 2.6339560060195364

Epoch: 5| Step: 3
Training loss: 2.653310518102782
Validation loss: 2.6316495118236056

Epoch: 5| Step: 4
Training loss: 2.724614012792872
Validation loss: 2.635227744426334

Epoch: 5| Step: 5
Training loss: 3.381685346686853
Validation loss: 2.6352569429211967

Epoch: 5| Step: 6
Training loss: 2.8248444809768416
Validation loss: 2.6301903427485063

Epoch: 5| Step: 7
Training loss: 3.4002407157058236
Validation loss: 2.628707832665012

Epoch: 5| Step: 8
Training loss: 3.2042584158498255
Validation loss: 2.6338583915252007

Epoch: 5| Step: 9
Training loss: 2.5924523106219564
Validation loss: 2.634794733262564

Epoch: 5| Step: 10
Training loss: 2.824973020171567
Validation loss: 2.6390273592344076

Epoch: 268| Step: 0
Training loss: 2.9464735580907275
Validation loss: 2.6458665664661822

Epoch: 5| Step: 1
Training loss: 3.4526025713490447
Validation loss: 2.656637353902002

Epoch: 5| Step: 2
Training loss: 3.048458529057161
Validation loss: 2.6574786496425973

Epoch: 5| Step: 3
Training loss: 2.9735704337155995
Validation loss: 2.6610199086131625

Epoch: 5| Step: 4
Training loss: 2.8410685546509717
Validation loss: 2.663108231600287

Epoch: 5| Step: 5
Training loss: 2.8488331731795737
Validation loss: 2.6587474145476606

Epoch: 5| Step: 6
Training loss: 2.7233739533618686
Validation loss: 2.6555981940804623

Epoch: 5| Step: 7
Training loss: 2.769272118243415
Validation loss: 2.6519925361004497

Epoch: 5| Step: 8
Training loss: 3.229966702363426
Validation loss: 2.654279700280135

Epoch: 5| Step: 9
Training loss: 2.8689135934895598
Validation loss: 2.652020115471818

Epoch: 5| Step: 10
Training loss: 2.674122629045751
Validation loss: 2.666254150749847

Epoch: 269| Step: 0
Training loss: 3.4060010906582856
Validation loss: 2.65460530949169

Epoch: 5| Step: 1
Training loss: 2.74868647676753
Validation loss: 2.650993167017653

Epoch: 5| Step: 2
Training loss: 2.900540722389322
Validation loss: 2.652583059127537

Epoch: 5| Step: 3
Training loss: 2.4701767673638106
Validation loss: 2.6403109553107957

Epoch: 5| Step: 4
Training loss: 2.859883581072845
Validation loss: 2.6501486849928164

Epoch: 5| Step: 5
Training loss: 2.4493659308349103
Validation loss: 2.63496690484202

Epoch: 5| Step: 6
Training loss: 2.7689673276043423
Validation loss: 2.6395523281843563

Epoch: 5| Step: 7
Training loss: 3.7554322633186983
Validation loss: 2.6415313371091536

Epoch: 5| Step: 8
Training loss: 2.474605521159193
Validation loss: 2.6350285675059406

Epoch: 5| Step: 9
Training loss: 3.1973321403244546
Validation loss: 2.641541414897444

Epoch: 5| Step: 10
Training loss: 3.238872699540778
Validation loss: 2.646323324276124

Epoch: 270| Step: 0
Training loss: 2.989780822681787
Validation loss: 2.6453389203311217

Epoch: 5| Step: 1
Training loss: 2.7835397617137616
Validation loss: 2.6432303056401776

Epoch: 5| Step: 2
Training loss: 2.813074773760871
Validation loss: 2.6536063350809385

Epoch: 5| Step: 3
Training loss: 2.9550171295547365
Validation loss: 2.644164289451552

Epoch: 5| Step: 4
Training loss: 2.639467606470189
Validation loss: 2.636708006234956

Epoch: 5| Step: 5
Training loss: 2.7452226236533113
Validation loss: 2.6395924702282487

Epoch: 5| Step: 6
Training loss: 2.523240970481652
Validation loss: 2.639247714957361

Epoch: 5| Step: 7
Training loss: 2.983555546446298
Validation loss: 2.6421089815484615

Epoch: 5| Step: 8
Training loss: 3.205617688386923
Validation loss: 2.637520169782321

Epoch: 5| Step: 9
Training loss: 3.7245109237037517
Validation loss: 2.6463398444144226

Epoch: 5| Step: 10
Training loss: 2.9326269433529037
Validation loss: 2.644122360104575

Epoch: 271| Step: 0
Training loss: 3.3016503628811726
Validation loss: 2.6514592949718874

Epoch: 5| Step: 1
Training loss: 2.9153411759798
Validation loss: 2.634299648581696

Epoch: 5| Step: 2
Training loss: 2.9410335309692823
Validation loss: 2.6351020307724675

Epoch: 5| Step: 3
Training loss: 3.1750699193269343
Validation loss: 2.639699990517979

Epoch: 5| Step: 4
Training loss: 2.7248129054244936
Validation loss: 2.6450389221421142

Epoch: 5| Step: 5
Training loss: 2.8259226617293836
Validation loss: 2.64567104659351

Epoch: 5| Step: 6
Training loss: 3.1833172449900395
Validation loss: 2.641368755641718

Epoch: 5| Step: 7
Training loss: 2.3776320880254582
Validation loss: 2.6406478128444744

Epoch: 5| Step: 8
Training loss: 2.8038151056330243
Validation loss: 2.6398687977053754

Epoch: 5| Step: 9
Training loss: 3.264544294489446
Validation loss: 2.6450628435021666

Epoch: 5| Step: 10
Training loss: 2.791272823583802
Validation loss: 2.6486285466808197

Epoch: 272| Step: 0
Training loss: 2.830973671066111
Validation loss: 2.6514746518685115

Epoch: 5| Step: 1
Training loss: 2.825656045001897
Validation loss: 2.6420183723295114

Epoch: 5| Step: 2
Training loss: 2.8049300150036904
Validation loss: 2.643124308199235

Epoch: 5| Step: 3
Training loss: 2.7632420505529094
Validation loss: 2.634321249136623

Epoch: 5| Step: 4
Training loss: 2.79724348826839
Validation loss: 2.629708324671117

Epoch: 5| Step: 5
Training loss: 3.0174194689278524
Validation loss: 2.643665217660498

Epoch: 5| Step: 6
Training loss: 2.7425800270777034
Validation loss: 2.635864712593975

Epoch: 5| Step: 7
Training loss: 3.3122863700644083
Validation loss: 2.6283902641325954

Epoch: 5| Step: 8
Training loss: 2.667164626914546
Validation loss: 2.62565668645529

Epoch: 5| Step: 9
Training loss: 3.8600142100176376
Validation loss: 2.627603592329797

Epoch: 5| Step: 10
Training loss: 2.5179448774332287
Validation loss: 2.629010000599581

Epoch: 273| Step: 0
Training loss: 2.9915807522167426
Validation loss: 2.628373724811314

Epoch: 5| Step: 1
Training loss: 2.87048300131313
Validation loss: 2.6366018302027943

Epoch: 5| Step: 2
Training loss: 2.748356848439359
Validation loss: 2.637817785747635

Epoch: 5| Step: 3
Training loss: 2.5348957321723984
Validation loss: 2.6405957501849593

Epoch: 5| Step: 4
Training loss: 2.515989478582025
Validation loss: 2.6444199649640256

Epoch: 5| Step: 5
Training loss: 2.7772876932359303
Validation loss: 2.6368729148043935

Epoch: 5| Step: 6
Training loss: 3.240038055855757
Validation loss: 2.6440619547307365

Epoch: 5| Step: 7
Training loss: 3.499469853168457
Validation loss: 2.6397956545261105

Epoch: 5| Step: 8
Training loss: 2.88884387429534
Validation loss: 2.6470004947004435

Epoch: 5| Step: 9
Training loss: 3.0058527122855008
Validation loss: 2.637077910748528

Epoch: 5| Step: 10
Training loss: 3.184220365863347
Validation loss: 2.647551308165256

Epoch: 274| Step: 0
Training loss: 3.096348605566696
Validation loss: 2.657748429579448

Epoch: 5| Step: 1
Training loss: 2.868745053355621
Validation loss: 2.6840093168839045

Epoch: 5| Step: 2
Training loss: 2.7080356336472065
Validation loss: 2.648798436006826

Epoch: 5| Step: 3
Training loss: 3.1829589210805302
Validation loss: 2.644976311336488

Epoch: 5| Step: 4
Training loss: 3.3120744539820817
Validation loss: 2.6343191500095497

Epoch: 5| Step: 5
Training loss: 2.712746228411711
Validation loss: 2.624097427701398

Epoch: 5| Step: 6
Training loss: 3.0277472639344745
Validation loss: 2.624680284288069

Epoch: 5| Step: 7
Training loss: 3.2528213579136227
Validation loss: 2.623449790729527

Epoch: 5| Step: 8
Training loss: 2.729730989385962
Validation loss: 2.6321449196579754

Epoch: 5| Step: 9
Training loss: 2.7074218292082217
Validation loss: 2.6305812932309203

Epoch: 5| Step: 10
Training loss: 2.7623790938902313
Validation loss: 2.6396910895799475

Epoch: 275| Step: 0
Training loss: 2.9399890499819334
Validation loss: 2.6470187829701235

Epoch: 5| Step: 1
Training loss: 3.126063814289193
Validation loss: 2.6517986352595253

Epoch: 5| Step: 2
Training loss: 3.0314433242656644
Validation loss: 2.65473740692596

Epoch: 5| Step: 3
Training loss: 3.3869516189223754
Validation loss: 2.6576729521433613

Epoch: 5| Step: 4
Training loss: 3.0160193309012655
Validation loss: 2.6611185671923763

Epoch: 5| Step: 5
Training loss: 2.4138651646817726
Validation loss: 2.653417581066443

Epoch: 5| Step: 6
Training loss: 3.1871267361968156
Validation loss: 2.6444854022259476

Epoch: 5| Step: 7
Training loss: 2.615212312908716
Validation loss: 2.6409639006462595

Epoch: 5| Step: 8
Training loss: 2.8762870892947987
Validation loss: 2.6473422319264004

Epoch: 5| Step: 9
Training loss: 2.8499746421890504
Validation loss: 2.636830135470583

Epoch: 5| Step: 10
Training loss: 2.9732447278572542
Validation loss: 2.6268831911547545

Epoch: 276| Step: 0
Training loss: 3.410790033861705
Validation loss: 2.626575166327027

Epoch: 5| Step: 1
Training loss: 2.6162282523806457
Validation loss: 2.6348413913384943

Epoch: 5| Step: 2
Training loss: 3.2912906158294013
Validation loss: 2.6307397078826993

Epoch: 5| Step: 3
Training loss: 2.6032045240035835
Validation loss: 2.640762657542859

Epoch: 5| Step: 4
Training loss: 2.8808252778702514
Validation loss: 2.6306745026919667

Epoch: 5| Step: 5
Training loss: 3.1186694301067286
Validation loss: 2.6318216724250014

Epoch: 5| Step: 6
Training loss: 3.0297833856889467
Validation loss: 2.6324081307546194

Epoch: 5| Step: 7
Training loss: 2.9016687524719744
Validation loss: 2.634692915210686

Epoch: 5| Step: 8
Training loss: 2.9032193040262233
Validation loss: 2.626367810301368

Epoch: 5| Step: 9
Training loss: 2.7057003916782043
Validation loss: 2.6305977143960795

Epoch: 5| Step: 10
Training loss: 2.8721979833383986
Validation loss: 2.6263549391992624

Epoch: 277| Step: 0
Training loss: 2.6102566628664734
Validation loss: 2.6301456471156084

Epoch: 5| Step: 1
Training loss: 2.974913613483664
Validation loss: 2.6275074502758864

Epoch: 5| Step: 2
Training loss: 2.9663341128660528
Validation loss: 2.6298408933115507

Epoch: 5| Step: 3
Training loss: 3.2634267024345873
Validation loss: 2.6319162673892875

Epoch: 5| Step: 4
Training loss: 2.759298815598968
Validation loss: 2.62961800520676

Epoch: 5| Step: 5
Training loss: 2.738523638523137
Validation loss: 2.634297855988488

Epoch: 5| Step: 6
Training loss: 3.1863015109568
Validation loss: 2.6289197483218114

Epoch: 5| Step: 7
Training loss: 2.523524988506107
Validation loss: 2.637489779398651

Epoch: 5| Step: 8
Training loss: 3.1808944773291867
Validation loss: 2.6423520370428997

Epoch: 5| Step: 9
Training loss: 3.1215150856681295
Validation loss: 2.6529711682704584

Epoch: 5| Step: 10
Training loss: 2.958619994839612
Validation loss: 2.6715209290725026

Epoch: 278| Step: 0
Training loss: 2.7826419733094547
Validation loss: 2.6737412706056287

Epoch: 5| Step: 1
Training loss: 3.145179293181055
Validation loss: 2.6855145365538293

Epoch: 5| Step: 2
Training loss: 2.881373100381746
Validation loss: 2.705096829968192

Epoch: 5| Step: 3
Training loss: 2.627480651755194
Validation loss: 2.6969680502582323

Epoch: 5| Step: 4
Training loss: 3.2282567044447505
Validation loss: 2.693472624156514

Epoch: 5| Step: 5
Training loss: 3.521354110094121
Validation loss: 2.691073768508965

Epoch: 5| Step: 6
Training loss: 2.8950573730054407
Validation loss: 2.676934473485968

Epoch: 5| Step: 7
Training loss: 2.8917376052407446
Validation loss: 2.6573396950886448

Epoch: 5| Step: 8
Training loss: 2.1421931850321743
Validation loss: 2.6341309078569335

Epoch: 5| Step: 9
Training loss: 3.339157515848783
Validation loss: 2.6289990225026827

Epoch: 5| Step: 10
Training loss: 2.6295952312127984
Validation loss: 2.630019079852149

Epoch: 279| Step: 0
Training loss: 3.005620618512789
Validation loss: 2.630659636372185

Epoch: 5| Step: 1
Training loss: 3.1633250189438447
Validation loss: 2.629664905754147

Epoch: 5| Step: 2
Training loss: 3.270271609397445
Validation loss: 2.6359817438633257

Epoch: 5| Step: 3
Training loss: 2.6103679115591176
Validation loss: 2.6306807542198993

Epoch: 5| Step: 4
Training loss: 2.758019112690185
Validation loss: 2.6390508707443163

Epoch: 5| Step: 5
Training loss: 3.146803817777353
Validation loss: 2.6298633727324705

Epoch: 5| Step: 6
Training loss: 3.6445549313020145
Validation loss: 2.6368244808970394

Epoch: 5| Step: 7
Training loss: 2.7997527422042947
Validation loss: 2.6393710146292264

Epoch: 5| Step: 8
Training loss: 2.7762687738119594
Validation loss: 2.6353740702477064

Epoch: 5| Step: 9
Training loss: 2.5545050412970345
Validation loss: 2.635299322675825

Epoch: 5| Step: 10
Training loss: 2.7504449831132884
Validation loss: 2.6377235438391855

Epoch: 280| Step: 0
Training loss: 3.0022603103037544
Validation loss: 2.636116574647045

Epoch: 5| Step: 1
Training loss: 2.9983371258623848
Validation loss: 2.6347703508819844

Epoch: 5| Step: 2
Training loss: 3.2482039550674493
Validation loss: 2.641122560321738

Epoch: 5| Step: 3
Training loss: 3.0690216379307125
Validation loss: 2.6416521447816645

Epoch: 5| Step: 4
Training loss: 2.429685243071952
Validation loss: 2.6528161270232213

Epoch: 5| Step: 5
Training loss: 2.792941177338768
Validation loss: 2.676107616085569

Epoch: 5| Step: 6
Training loss: 3.0591471477132814
Validation loss: 2.675058700458747

Epoch: 5| Step: 7
Training loss: 2.8452342425356583
Validation loss: 2.6796342613700252

Epoch: 5| Step: 8
Training loss: 3.242474131955246
Validation loss: 2.6866738932980643

Epoch: 5| Step: 9
Training loss: 2.8812263074053837
Validation loss: 2.6786827811570255

Epoch: 5| Step: 10
Training loss: 2.7762811401214647
Validation loss: 2.6694519823475336

Epoch: 281| Step: 0
Training loss: 2.8172199063333463
Validation loss: 2.664739010741557

Epoch: 5| Step: 1
Training loss: 2.8409240430958618
Validation loss: 2.6531446223626016

Epoch: 5| Step: 2
Training loss: 2.8285704204012574
Validation loss: 2.6309326623556486

Epoch: 5| Step: 3
Training loss: 2.5884822068526705
Validation loss: 2.6248964962181236

Epoch: 5| Step: 4
Training loss: 2.5933572862527363
Validation loss: 2.6224174022454556

Epoch: 5| Step: 5
Training loss: 2.989709689740906
Validation loss: 2.6229125149518313

Epoch: 5| Step: 6
Training loss: 3.0799983951019465
Validation loss: 2.6223274705385524

Epoch: 5| Step: 7
Training loss: 3.1306696005530745
Validation loss: 2.6187344167777615

Epoch: 5| Step: 8
Training loss: 2.7281845208630426
Validation loss: 2.6190344347033974

Epoch: 5| Step: 9
Training loss: 3.1979978138985956
Validation loss: 2.6130046097498956

Epoch: 5| Step: 10
Training loss: 3.613313186091974
Validation loss: 2.6123090860021003

Epoch: 282| Step: 0
Training loss: 3.427913267678682
Validation loss: 2.6186592764752135

Epoch: 5| Step: 1
Training loss: 2.7933619082437646
Validation loss: 2.617162105294454

Epoch: 5| Step: 2
Training loss: 2.848878700124395
Validation loss: 2.6130277147493355

Epoch: 5| Step: 3
Training loss: 2.3704949868854652
Validation loss: 2.6197256740762938

Epoch: 5| Step: 4
Training loss: 2.966590497471382
Validation loss: 2.615255601720467

Epoch: 5| Step: 5
Training loss: 2.8462913811062402
Validation loss: 2.620597082579409

Epoch: 5| Step: 6
Training loss: 3.2286808920098
Validation loss: 2.6237433267947323

Epoch: 5| Step: 7
Training loss: 3.31912217289394
Validation loss: 2.626924288981369

Epoch: 5| Step: 8
Training loss: 2.836611833083504
Validation loss: 2.628397241886627

Epoch: 5| Step: 9
Training loss: 2.868755525072549
Validation loss: 2.627462609969915

Epoch: 5| Step: 10
Training loss: 2.7082017622068997
Validation loss: 2.643541855469182

Epoch: 283| Step: 0
Training loss: 2.663492986487594
Validation loss: 2.642210795197343

Epoch: 5| Step: 1
Training loss: 2.9826680839352173
Validation loss: 2.652929595542777

Epoch: 5| Step: 2
Training loss: 3.1243793634184653
Validation loss: 2.660956989797159

Epoch: 5| Step: 3
Training loss: 3.0325204605456384
Validation loss: 2.655998911080197

Epoch: 5| Step: 4
Training loss: 2.9900747464638604
Validation loss: 2.6703815874146986

Epoch: 5| Step: 5
Training loss: 2.698543657380509
Validation loss: 2.6456776987322406

Epoch: 5| Step: 6
Training loss: 2.989606336622538
Validation loss: 2.651166006909462

Epoch: 5| Step: 7
Training loss: 3.2671187055615944
Validation loss: 2.6384693892463513

Epoch: 5| Step: 8
Training loss: 2.8920698524259465
Validation loss: 2.6437278246070166

Epoch: 5| Step: 9
Training loss: 3.370650986186305
Validation loss: 2.638631766558302

Epoch: 5| Step: 10
Training loss: 2.046326192417207
Validation loss: 2.6302855056427616

Epoch: 284| Step: 0
Training loss: 3.625650939375148
Validation loss: 2.613862736538854

Epoch: 5| Step: 1
Training loss: 2.88992103046379
Validation loss: 2.6237330135602734

Epoch: 5| Step: 2
Training loss: 3.32912705787392
Validation loss: 2.6261916641939616

Epoch: 5| Step: 3
Training loss: 2.6305622932789103
Validation loss: 2.6238530246610132

Epoch: 5| Step: 4
Training loss: 2.776036723539855
Validation loss: 2.6272602741466553

Epoch: 5| Step: 5
Training loss: 2.846837306689098
Validation loss: 2.6291031195024632

Epoch: 5| Step: 6
Training loss: 3.047365745735364
Validation loss: 2.62886131945597

Epoch: 5| Step: 7
Training loss: 2.6097657602073476
Validation loss: 2.6305010219817997

Epoch: 5| Step: 8
Training loss: 2.654925027137158
Validation loss: 2.6426245510668025

Epoch: 5| Step: 9
Training loss: 3.3559223263723688
Validation loss: 2.648428059251754

Epoch: 5| Step: 10
Training loss: 2.1940266926479626
Validation loss: 2.6392578616891167

Epoch: 285| Step: 0
Training loss: 3.12780300316163
Validation loss: 2.635043932598757

Epoch: 5| Step: 1
Training loss: 2.9814427535405
Validation loss: 2.624269580153706

Epoch: 5| Step: 2
Training loss: 2.8199230992538724
Validation loss: 2.6260007736813096

Epoch: 5| Step: 3
Training loss: 3.5891250704541218
Validation loss: 2.6176411533850965

Epoch: 5| Step: 4
Training loss: 2.8607504616333372
Validation loss: 2.6198665487749384

Epoch: 5| Step: 5
Training loss: 2.5853560332740675
Validation loss: 2.6143090689667967

Epoch: 5| Step: 6
Training loss: 2.3527944385829906
Validation loss: 2.630386817908719

Epoch: 5| Step: 7
Training loss: 2.9284727299237785
Validation loss: 2.6393432671444694

Epoch: 5| Step: 8
Training loss: 2.682912059751741
Validation loss: 2.6456476917855114

Epoch: 5| Step: 9
Training loss: 3.2074173614726647
Validation loss: 2.646709029474271

Epoch: 5| Step: 10
Training loss: 3.018925733170238
Validation loss: 2.674931631823677

Epoch: 286| Step: 0
Training loss: 3.3651247012199628
Validation loss: 2.6873762880179415

Epoch: 5| Step: 1
Training loss: 2.8674730371805626
Validation loss: 2.687951895364424

Epoch: 5| Step: 2
Training loss: 2.8448226079628176
Validation loss: 2.694190894728512

Epoch: 5| Step: 3
Training loss: 2.803664251913427
Validation loss: 2.686887001054858

Epoch: 5| Step: 4
Training loss: 3.3002764614938003
Validation loss: 2.664725044470007

Epoch: 5| Step: 5
Training loss: 2.612800679403101
Validation loss: 2.655632738734107

Epoch: 5| Step: 6
Training loss: 3.180755360938294
Validation loss: 2.6469159716749364

Epoch: 5| Step: 7
Training loss: 2.9140494093204627
Validation loss: 2.646006768313653

Epoch: 5| Step: 8
Training loss: 2.4787889935556744
Validation loss: 2.6343293711953

Epoch: 5| Step: 9
Training loss: 3.335335384588115
Validation loss: 2.647543357390213

Epoch: 5| Step: 10
Training loss: 2.261117700488554
Validation loss: 2.6390220960002977

Epoch: 287| Step: 0
Training loss: 2.922280676111654
Validation loss: 2.644033010545447

Epoch: 5| Step: 1
Training loss: 2.665303855593047
Validation loss: 2.6260008410427527

Epoch: 5| Step: 2
Training loss: 2.643009170371985
Validation loss: 2.628095160550943

Epoch: 5| Step: 3
Training loss: 2.3445610169068987
Validation loss: 2.6269438090526895

Epoch: 5| Step: 4
Training loss: 3.307331010879822
Validation loss: 2.638333683692391

Epoch: 5| Step: 5
Training loss: 1.8992503117677453
Validation loss: 2.6309901097960053

Epoch: 5| Step: 6
Training loss: 3.0596508864170975
Validation loss: 2.641967804822346

Epoch: 5| Step: 7
Training loss: 3.4974314938012734
Validation loss: 2.6477911622661794

Epoch: 5| Step: 8
Training loss: 3.53114696791235
Validation loss: 2.661284705684697

Epoch: 5| Step: 9
Training loss: 2.838739697375934
Validation loss: 2.6671358402071355

Epoch: 5| Step: 10
Training loss: 3.134605294283819
Validation loss: 2.664772338239363

Epoch: 288| Step: 0
Training loss: 3.125471308453075
Validation loss: 2.646689735572532

Epoch: 5| Step: 1
Training loss: 2.70604790336009
Validation loss: 2.6377925954864785

Epoch: 5| Step: 2
Training loss: 2.7170755776798368
Validation loss: 2.6258452637190453

Epoch: 5| Step: 3
Training loss: 3.0344411825079254
Validation loss: 2.62015163636609

Epoch: 5| Step: 4
Training loss: 2.5645433978006458
Validation loss: 2.6174473013544803

Epoch: 5| Step: 5
Training loss: 2.732212890311555
Validation loss: 2.616229447857706

Epoch: 5| Step: 6
Training loss: 2.8865297743455884
Validation loss: 2.6195289302132414

Epoch: 5| Step: 7
Training loss: 3.456993456272931
Validation loss: 2.6210979772604297

Epoch: 5| Step: 8
Training loss: 3.153531405039563
Validation loss: 2.6229305997636114

Epoch: 5| Step: 9
Training loss: 2.8778132067855644
Validation loss: 2.6266583147765163

Epoch: 5| Step: 10
Training loss: 3.015939962907631
Validation loss: 2.621538955942446

Epoch: 289| Step: 0
Training loss: 2.7544824308595732
Validation loss: 2.6201423118909757

Epoch: 5| Step: 1
Training loss: 3.135577344526571
Validation loss: 2.618470612476886

Epoch: 5| Step: 2
Training loss: 3.009411354677216
Validation loss: 2.6274353641122565

Epoch: 5| Step: 3
Training loss: 3.1913079348190245
Validation loss: 2.6302507586952784

Epoch: 5| Step: 4
Training loss: 2.7760580228188907
Validation loss: 2.6235484765131285

Epoch: 5| Step: 5
Training loss: 2.8673428277706474
Validation loss: 2.62273334513257

Epoch: 5| Step: 6
Training loss: 3.2770483818219343
Validation loss: 2.629277025909235

Epoch: 5| Step: 7
Training loss: 2.579871401132354
Validation loss: 2.635182225103917

Epoch: 5| Step: 8
Training loss: 3.248283813422704
Validation loss: 2.649224842380106

Epoch: 5| Step: 9
Training loss: 2.6170481174988356
Validation loss: 2.6527298825609846

Epoch: 5| Step: 10
Training loss: 2.7039197514154756
Validation loss: 2.661977502784223

Epoch: 290| Step: 0
Training loss: 2.8136000283402613
Validation loss: 2.661379480158065

Epoch: 5| Step: 1
Training loss: 3.040107919885539
Validation loss: 2.6667712143687368

Epoch: 5| Step: 2
Training loss: 2.966388927988831
Validation loss: 2.6605125782365846

Epoch: 5| Step: 3
Training loss: 2.562017069644331
Validation loss: 2.6459649921810793

Epoch: 5| Step: 4
Training loss: 2.4427257176629915
Validation loss: 2.63508974812152

Epoch: 5| Step: 5
Training loss: 3.2536812987312356
Validation loss: 2.628417751733501

Epoch: 5| Step: 6
Training loss: 3.200916701382123
Validation loss: 2.6149506718796163

Epoch: 5| Step: 7
Training loss: 2.988088005649163
Validation loss: 2.615851457826899

Epoch: 5| Step: 8
Training loss: 2.9736640815782067
Validation loss: 2.613957957380039

Epoch: 5| Step: 9
Training loss: 3.4364222831180333
Validation loss: 2.611647376572526

Epoch: 5| Step: 10
Training loss: 2.3268654507572486
Validation loss: 2.6105118912102445

Epoch: 291| Step: 0
Training loss: 3.3809877191662974
Validation loss: 2.611269361415681

Epoch: 5| Step: 1
Training loss: 2.883315458591453
Validation loss: 2.6111959453289013

Epoch: 5| Step: 2
Training loss: 2.8069726671900113
Validation loss: 2.609310985200213

Epoch: 5| Step: 3
Training loss: 2.4881518942656995
Validation loss: 2.605970916517069

Epoch: 5| Step: 4
Training loss: 3.440168142866899
Validation loss: 2.61584169464421

Epoch: 5| Step: 5
Training loss: 2.906680167572211
Validation loss: 2.622370243034208

Epoch: 5| Step: 6
Training loss: 2.807791434810293
Validation loss: 2.6154945801189178

Epoch: 5| Step: 7
Training loss: 2.618563071341561
Validation loss: 2.6175322098564133

Epoch: 5| Step: 8
Training loss: 2.826366235973943
Validation loss: 2.6261520191974554

Epoch: 5| Step: 9
Training loss: 2.8755031642959423
Validation loss: 2.626520566120043

Epoch: 5| Step: 10
Training loss: 3.183178833679097
Validation loss: 2.629200329407521

Epoch: 292| Step: 0
Training loss: 2.958156759517554
Validation loss: 2.6487327626713957

Epoch: 5| Step: 1
Training loss: 3.547751028629971
Validation loss: 2.6473229833118648

Epoch: 5| Step: 2
Training loss: 3.2586683434431607
Validation loss: 2.668907858687595

Epoch: 5| Step: 3
Training loss: 2.4994733255652886
Validation loss: 2.6634610954279494

Epoch: 5| Step: 4
Training loss: 2.7449545959719908
Validation loss: 2.6672746621507493

Epoch: 5| Step: 5
Training loss: 2.640408840022367
Validation loss: 2.651775197138164

Epoch: 5| Step: 6
Training loss: 2.8495360816696644
Validation loss: 2.6636091070284365

Epoch: 5| Step: 7
Training loss: 3.2524089688486244
Validation loss: 2.6732573546638836

Epoch: 5| Step: 8
Training loss: 2.3528377078952136
Validation loss: 2.655486792620356

Epoch: 5| Step: 9
Training loss: 3.2700870091706102
Validation loss: 2.6530667557258427

Epoch: 5| Step: 10
Training loss: 2.541311447669088
Validation loss: 2.640531921396707

Epoch: 293| Step: 0
Training loss: 2.855454054767248
Validation loss: 2.6308817151433868

Epoch: 5| Step: 1
Training loss: 2.6173039196937817
Validation loss: 2.6253838197479524

Epoch: 5| Step: 2
Training loss: 3.366670856536172
Validation loss: 2.624748466968632

Epoch: 5| Step: 3
Training loss: 3.2068159470207216
Validation loss: 2.6211824877837517

Epoch: 5| Step: 4
Training loss: 3.201786412851505
Validation loss: 2.6184125643270586

Epoch: 5| Step: 5
Training loss: 2.703399732442985
Validation loss: 2.619007405591746

Epoch: 5| Step: 6
Training loss: 2.71962986882086
Validation loss: 2.629026890865041

Epoch: 5| Step: 7
Training loss: 3.4490471837197156
Validation loss: 2.6237278271263365

Epoch: 5| Step: 8
Training loss: 2.4336839784700413
Validation loss: 2.629998986047376

Epoch: 5| Step: 9
Training loss: 2.434669611956572
Validation loss: 2.6394284289573227

Epoch: 5| Step: 10
Training loss: 3.0051289266390313
Validation loss: 2.647644910744918

Epoch: 294| Step: 0
Training loss: 3.201243224637668
Validation loss: 2.6262993572960243

Epoch: 5| Step: 1
Training loss: 3.2541382192881625
Validation loss: 2.619688359636693

Epoch: 5| Step: 2
Training loss: 2.382959580181504
Validation loss: 2.619452404362352

Epoch: 5| Step: 3
Training loss: 3.317590365066685
Validation loss: 2.612880571164093

Epoch: 5| Step: 4
Training loss: 2.8132328350262488
Validation loss: 2.6103022839091143

Epoch: 5| Step: 5
Training loss: 3.030019451368487
Validation loss: 2.605693672322147

Epoch: 5| Step: 6
Training loss: 3.084445099966448
Validation loss: 2.617684399092897

Epoch: 5| Step: 7
Training loss: 2.258702086387505
Validation loss: 2.6125055507642747

Epoch: 5| Step: 8
Training loss: 3.3778965141385684
Validation loss: 2.6142640336602705

Epoch: 5| Step: 9
Training loss: 2.7820958769270168
Validation loss: 2.6230070534596663

Epoch: 5| Step: 10
Training loss: 2.3982441479410608
Validation loss: 2.6122593124262425

Epoch: 295| Step: 0
Training loss: 3.0496706925515435
Validation loss: 2.6301663348584094

Epoch: 5| Step: 1
Training loss: 2.898066165303015
Validation loss: 2.651012589161231

Epoch: 5| Step: 2
Training loss: 2.3765745464874874
Validation loss: 2.6659098142054183

Epoch: 5| Step: 3
Training loss: 3.1030684881836557
Validation loss: 2.6558340095549458

Epoch: 5| Step: 4
Training loss: 2.954670012456099
Validation loss: 2.6678600070214045

Epoch: 5| Step: 5
Training loss: 2.827099861953158
Validation loss: 2.6930733726031804

Epoch: 5| Step: 6
Training loss: 3.4325250865578
Validation loss: 2.6801968059463515

Epoch: 5| Step: 7
Training loss: 2.623329539346759
Validation loss: 2.6717038730966127

Epoch: 5| Step: 8
Training loss: 3.1783262896113835
Validation loss: 2.661826636324294

Epoch: 5| Step: 9
Training loss: 2.8474723850749895
Validation loss: 2.6367767558521504

Epoch: 5| Step: 10
Training loss: 2.754946594689905
Validation loss: 2.635216807797464

Epoch: 296| Step: 0
Training loss: 3.034169943861085
Validation loss: 2.617578025336852

Epoch: 5| Step: 1
Training loss: 3.1284769170859716
Validation loss: 2.6110448811062548

Epoch: 5| Step: 2
Training loss: 2.725303993417407
Validation loss: 2.6053966641326167

Epoch: 5| Step: 3
Training loss: 3.122598717307207
Validation loss: 2.600400897482576

Epoch: 5| Step: 4
Training loss: 2.7793384798197023
Validation loss: 2.6023589992970098

Epoch: 5| Step: 5
Training loss: 2.786143851433836
Validation loss: 2.5999955398925185

Epoch: 5| Step: 6
Training loss: 2.9193231383421003
Validation loss: 2.6118474776695786

Epoch: 5| Step: 7
Training loss: 2.731831964779141
Validation loss: 2.6072533514654443

Epoch: 5| Step: 8
Training loss: 3.2106072100502363
Validation loss: 2.61149187772835

Epoch: 5| Step: 9
Training loss: 2.7337708595990575
Validation loss: 2.613442028746771

Epoch: 5| Step: 10
Training loss: 3.016655306153658
Validation loss: 2.6207161837403254

Epoch: 297| Step: 0
Training loss: 3.117776838918617
Validation loss: 2.6476422479953685

Epoch: 5| Step: 1
Training loss: 2.220533809061749
Validation loss: 2.652160364655992

Epoch: 5| Step: 2
Training loss: 3.527126098541793
Validation loss: 2.6824884106961475

Epoch: 5| Step: 3
Training loss: 3.072426725651414
Validation loss: 2.6500613558587762

Epoch: 5| Step: 4
Training loss: 3.072946287540412
Validation loss: 2.6228634381475224

Epoch: 5| Step: 5
Training loss: 2.8854478818304385
Validation loss: 2.6211855236410266

Epoch: 5| Step: 6
Training loss: 3.0981374128784456
Validation loss: 2.619068703022538

Epoch: 5| Step: 7
Training loss: 3.083616673278267
Validation loss: 2.6047706353189914

Epoch: 5| Step: 8
Training loss: 2.9114708715361077
Validation loss: 2.6046594231492466

Epoch: 5| Step: 9
Training loss: 2.4720053154971557
Validation loss: 2.6046729693710686

Epoch: 5| Step: 10
Training loss: 2.5101667625380455
Validation loss: 2.6011324463649466

Epoch: 298| Step: 0
Training loss: 3.1449432292720703
Validation loss: 2.616397508857886

Epoch: 5| Step: 1
Training loss: 3.1246151496422763
Validation loss: 2.6315789721466825

Epoch: 5| Step: 2
Training loss: 3.4345797532390865
Validation loss: 2.6353934664477

Epoch: 5| Step: 3
Training loss: 3.0501319106296387
Validation loss: 2.6506653838245646

Epoch: 5| Step: 4
Training loss: 3.150468573460278
Validation loss: 2.666474726393688

Epoch: 5| Step: 5
Training loss: 2.7527755255700104
Validation loss: 2.702367937980334

Epoch: 5| Step: 6
Training loss: 2.6478644457173948
Validation loss: 2.7379882144527365

Epoch: 5| Step: 7
Training loss: 2.274825154387085
Validation loss: 2.6954130886640786

Epoch: 5| Step: 8
Training loss: 2.720158091747224
Validation loss: 2.6849385097979797

Epoch: 5| Step: 9
Training loss: 3.0027818497653596
Validation loss: 2.6708566475698325

Epoch: 5| Step: 10
Training loss: 2.783362882613371
Validation loss: 2.651151663566075

Epoch: 299| Step: 0
Training loss: 2.8843632690587895
Validation loss: 2.6421858622191126

Epoch: 5| Step: 1
Training loss: 3.106424129525387
Validation loss: 2.626953903767198

Epoch: 5| Step: 2
Training loss: 2.7329979617142293
Validation loss: 2.6110558335611582

Epoch: 5| Step: 3
Training loss: 2.977719219859276
Validation loss: 2.6036606531234026

Epoch: 5| Step: 4
Training loss: 2.7119101942266255
Validation loss: 2.6048387328851135

Epoch: 5| Step: 5
Training loss: 3.0039016465646617
Validation loss: 2.596103275242308

Epoch: 5| Step: 6
Training loss: 2.334677774385832
Validation loss: 2.5954616802885426

Epoch: 5| Step: 7
Training loss: 3.223544207686802
Validation loss: 2.599527834740486

Epoch: 5| Step: 8
Training loss: 3.0975169358548653
Validation loss: 2.596379191545986

Epoch: 5| Step: 9
Training loss: 2.895289271632571
Validation loss: 2.5934165328068404

Epoch: 5| Step: 10
Training loss: 3.1658311210022783
Validation loss: 2.6016231274699355

Epoch: 300| Step: 0
Training loss: 3.2204292139246617
Validation loss: 2.6035149022417152

Epoch: 5| Step: 1
Training loss: 2.9822271317190334
Validation loss: 2.6023902688459772

Epoch: 5| Step: 2
Training loss: 2.73091185198359
Validation loss: 2.611116121805562

Epoch: 5| Step: 3
Training loss: 2.752831648440522
Validation loss: 2.630010089613951

Epoch: 5| Step: 4
Training loss: 3.3056828147547876
Validation loss: 2.646357047413701

Epoch: 5| Step: 5
Training loss: 2.768907743141121
Validation loss: 2.6420533439109377

Epoch: 5| Step: 6
Training loss: 3.170455389436005
Validation loss: 2.6556024774334

Epoch: 5| Step: 7
Training loss: 2.8193969085728368
Validation loss: 2.6338822684289775

Epoch: 5| Step: 8
Training loss: 2.906045229681246
Validation loss: 2.661270533438723

Epoch: 5| Step: 9
Training loss: 2.797138734455708
Validation loss: 2.6677903517619295

Epoch: 5| Step: 10
Training loss: 2.590346343695733
Validation loss: 2.68188298799016

Epoch: 301| Step: 0
Training loss: 2.2112617389718854
Validation loss: 2.6654110514158096

Epoch: 5| Step: 1
Training loss: 2.868785942700183
Validation loss: 2.674012552512345

Epoch: 5| Step: 2
Training loss: 2.4158488457365825
Validation loss: 2.67637287830186

Epoch: 5| Step: 3
Training loss: 2.9880249711388647
Validation loss: 2.6423636577269574

Epoch: 5| Step: 4
Training loss: 3.24567800859445
Validation loss: 2.6460525044679937

Epoch: 5| Step: 5
Training loss: 2.939040084664157
Validation loss: 2.6219261217934746

Epoch: 5| Step: 6
Training loss: 3.2866522504581916
Validation loss: 2.6095049072138

Epoch: 5| Step: 7
Training loss: 3.055219755119948
Validation loss: 2.613582810547944

Epoch: 5| Step: 8
Training loss: 3.018615978733133
Validation loss: 2.6074522196025725

Epoch: 5| Step: 9
Training loss: 2.6126941882519823
Validation loss: 2.604850628690107

Epoch: 5| Step: 10
Training loss: 3.4255408590917624
Validation loss: 2.6120450744339037

Epoch: 302| Step: 0
Training loss: 3.115999918182333
Validation loss: 2.607819899730985

Epoch: 5| Step: 1
Training loss: 2.5540186388475252
Validation loss: 2.616148332520308

Epoch: 5| Step: 2
Training loss: 3.221215498254323
Validation loss: 2.61300813192649

Epoch: 5| Step: 3
Training loss: 2.6938902709975574
Validation loss: 2.621498855278791

Epoch: 5| Step: 4
Training loss: 2.2466522318586666
Validation loss: 2.6207934738292984

Epoch: 5| Step: 5
Training loss: 3.0297322357006973
Validation loss: 2.637876346659718

Epoch: 5| Step: 6
Training loss: 2.8457430049324675
Validation loss: 2.65953975364914

Epoch: 5| Step: 7
Training loss: 3.108758146354331
Validation loss: 2.651095301878129

Epoch: 5| Step: 8
Training loss: 3.128265353321002
Validation loss: 2.696149899332436

Epoch: 5| Step: 9
Training loss: 3.0224964343129623
Validation loss: 2.689402826920638

Epoch: 5| Step: 10
Training loss: 2.916511876676389
Validation loss: 2.688803770305177

Epoch: 303| Step: 0
Training loss: 3.0381841885832603
Validation loss: 2.6807936384264153

Epoch: 5| Step: 1
Training loss: 2.535441848349815
Validation loss: 2.677061081239147

Epoch: 5| Step: 2
Training loss: 2.5846500937608043
Validation loss: 2.6939312753800344

Epoch: 5| Step: 3
Training loss: 2.5540560720706593
Validation loss: 2.702982015608055

Epoch: 5| Step: 4
Training loss: 3.009437973932228
Validation loss: 2.709062104977141

Epoch: 5| Step: 5
Training loss: 3.031741544844938
Validation loss: 2.6973682726286947

Epoch: 5| Step: 6
Training loss: 3.3572062744365607
Validation loss: 2.6617276938561045

Epoch: 5| Step: 7
Training loss: 2.8942024157427233
Validation loss: 2.6340341621664156

Epoch: 5| Step: 8
Training loss: 3.0829861591534495
Validation loss: 2.608856088662095

Epoch: 5| Step: 9
Training loss: 3.1827455853491604
Validation loss: 2.6042846590609128

Epoch: 5| Step: 10
Training loss: 2.3829022500067345
Validation loss: 2.6078080027246986

Epoch: 304| Step: 0
Training loss: 2.966897969033446
Validation loss: 2.5996674791212007

Epoch: 5| Step: 1
Training loss: 3.1641054503739956
Validation loss: 2.6034800589493505

Epoch: 5| Step: 2
Training loss: 2.4457903020432075
Validation loss: 2.6039729568464383

Epoch: 5| Step: 3
Training loss: 3.3234892603937563
Validation loss: 2.601428143900531

Epoch: 5| Step: 4
Training loss: 3.1236235066570255
Validation loss: 2.605266708527783

Epoch: 5| Step: 5
Training loss: 2.530569479557742
Validation loss: 2.6036577681578774

Epoch: 5| Step: 6
Training loss: 2.390660703305184
Validation loss: 2.601495265661595

Epoch: 5| Step: 7
Training loss: 2.9434204500236922
Validation loss: 2.613962917030732

Epoch: 5| Step: 8
Training loss: 2.722463154889378
Validation loss: 2.6181178607020374

Epoch: 5| Step: 9
Training loss: 3.277007639294294
Validation loss: 2.6258734740630723

Epoch: 5| Step: 10
Training loss: 3.0990288905384684
Validation loss: 2.6334178996912447

Epoch: 305| Step: 0
Training loss: 2.900646920231273
Validation loss: 2.641437349012243

Epoch: 5| Step: 1
Training loss: 2.8625074228248804
Validation loss: 2.6477431662672646

Epoch: 5| Step: 2
Training loss: 3.3877093880328806
Validation loss: 2.658423176724432

Epoch: 5| Step: 3
Training loss: 2.857610439459174
Validation loss: 2.6527467445339807

Epoch: 5| Step: 4
Training loss: 2.7852534936565077
Validation loss: 2.6399507282456423

Epoch: 5| Step: 5
Training loss: 2.559138442438376
Validation loss: 2.624048574315868

Epoch: 5| Step: 6
Training loss: 2.5577599950585235
Validation loss: 2.6321271377551514

Epoch: 5| Step: 7
Training loss: 3.0883331657309436
Validation loss: 2.6185170674971947

Epoch: 5| Step: 8
Training loss: 2.7957156884749406
Validation loss: 2.612943408475545

Epoch: 5| Step: 9
Training loss: 2.7299921277390324
Validation loss: 2.6132238537400965

Epoch: 5| Step: 10
Training loss: 3.4487007071777027
Validation loss: 2.6094147986975944

Epoch: 306| Step: 0
Training loss: 3.1497357817752136
Validation loss: 2.635794273081006

Epoch: 5| Step: 1
Training loss: 3.1541927166916675
Validation loss: 2.638440799575745

Epoch: 5| Step: 2
Training loss: 3.0541114361510635
Validation loss: 2.663465973486377

Epoch: 5| Step: 3
Training loss: 2.7505671176484614
Validation loss: 2.694077906048729

Epoch: 5| Step: 4
Training loss: 2.8426353869241066
Validation loss: 2.712755662681564

Epoch: 5| Step: 5
Training loss: 2.9186697121794967
Validation loss: 2.7315565143055442

Epoch: 5| Step: 6
Training loss: 2.3811546687069556
Validation loss: 2.709520298207162

Epoch: 5| Step: 7
Training loss: 3.3343267549923206
Validation loss: 2.6929129594992736

Epoch: 5| Step: 8
Training loss: 3.166965085742039
Validation loss: 2.647573535543278

Epoch: 5| Step: 9
Training loss: 2.5950014703118014
Validation loss: 2.6295827600277333

Epoch: 5| Step: 10
Training loss: 2.4962711181664234
Validation loss: 2.607097650525376

Epoch: 307| Step: 0
Training loss: 3.5178894887962726
Validation loss: 2.5945940528471825

Epoch: 5| Step: 1
Training loss: 2.722967537772251
Validation loss: 2.5990737421527426

Epoch: 5| Step: 2
Training loss: 2.7108565876343778
Validation loss: 2.5950409105389056

Epoch: 5| Step: 3
Training loss: 2.8252059456354517
Validation loss: 2.601001102826186

Epoch: 5| Step: 4
Training loss: 2.589655758578157
Validation loss: 2.5944138670793824

Epoch: 5| Step: 5
Training loss: 2.7047850522365895
Validation loss: 2.6020780323118773

Epoch: 5| Step: 6
Training loss: 3.070970925742836
Validation loss: 2.606221766267415

Epoch: 5| Step: 7
Training loss: 2.9757798334840913
Validation loss: 2.598130702828653

Epoch: 5| Step: 8
Training loss: 3.080639426998039
Validation loss: 2.601858620624735

Epoch: 5| Step: 9
Training loss: 2.7888778497174327
Validation loss: 2.6083568856048336

Epoch: 5| Step: 10
Training loss: 2.958952628491002
Validation loss: 2.6485420332500955

Epoch: 308| Step: 0
Training loss: 3.3657515223106595
Validation loss: 2.6762089591592293

Epoch: 5| Step: 1
Training loss: 2.870290963180888
Validation loss: 2.688484873770982

Epoch: 5| Step: 2
Training loss: 2.1055149505019215
Validation loss: 2.6965889805350742

Epoch: 5| Step: 3
Training loss: 2.7799140207456126
Validation loss: 2.672494706697395

Epoch: 5| Step: 4
Training loss: 2.7307532166396853
Validation loss: 2.667665001154577

Epoch: 5| Step: 5
Training loss: 3.698770787991877
Validation loss: 2.646929572829387

Epoch: 5| Step: 6
Training loss: 2.4140805734494863
Validation loss: 2.6103572547772917

Epoch: 5| Step: 7
Training loss: 3.189590217554664
Validation loss: 2.6041156558711545

Epoch: 5| Step: 8
Training loss: 2.5101756907522637
Validation loss: 2.6061758839453715

Epoch: 5| Step: 9
Training loss: 3.2094252243495123
Validation loss: 2.594620826442771

Epoch: 5| Step: 10
Training loss: 2.787266770257914
Validation loss: 2.6015381983593526

Epoch: 309| Step: 0
Training loss: 2.812375638119651
Validation loss: 2.5943318650969696

Epoch: 5| Step: 1
Training loss: 3.0784648572097093
Validation loss: 2.602531100299066

Epoch: 5| Step: 2
Training loss: 2.8524267271829706
Validation loss: 2.608730618533965

Epoch: 5| Step: 3
Training loss: 3.442769121719298
Validation loss: 2.603009937611579

Epoch: 5| Step: 4
Training loss: 3.0771380551137923
Validation loss: 2.606883225341425

Epoch: 5| Step: 5
Training loss: 2.5199085041874674
Validation loss: 2.6097358315109505

Epoch: 5| Step: 6
Training loss: 3.238469724611697
Validation loss: 2.6141955392820204

Epoch: 5| Step: 7
Training loss: 2.71351162728482
Validation loss: 2.6216929553311408

Epoch: 5| Step: 8
Training loss: 2.418176990225217
Validation loss: 2.653951358959699

Epoch: 5| Step: 9
Training loss: 2.484708943505365
Validation loss: 2.675963771515052

Epoch: 5| Step: 10
Training loss: 3.265887674235018
Validation loss: 2.6742797423184403

Epoch: 310| Step: 0
Training loss: 2.922709136867791
Validation loss: 2.6698877370354896

Epoch: 5| Step: 1
Training loss: 3.3943725127406132
Validation loss: 2.6922296885799883

Epoch: 5| Step: 2
Training loss: 2.688291034054322
Validation loss: 2.6815143156897125

Epoch: 5| Step: 3
Training loss: 2.6706994577103407
Validation loss: 2.6487047522381313

Epoch: 5| Step: 4
Training loss: 3.1404639055679806
Validation loss: 2.650675564222918

Epoch: 5| Step: 5
Training loss: 2.5256345650261216
Validation loss: 2.6374636975878927

Epoch: 5| Step: 6
Training loss: 2.526666046266639
Validation loss: 2.6296982819625065

Epoch: 5| Step: 7
Training loss: 2.8410020903190594
Validation loss: 2.6276714201257536

Epoch: 5| Step: 8
Training loss: 3.016557618448134
Validation loss: 2.6318389542497846

Epoch: 5| Step: 9
Training loss: 2.9973005229380467
Validation loss: 2.630161550019078

Epoch: 5| Step: 10
Training loss: 3.046379322911863
Validation loss: 2.6254117919087734

Epoch: 311| Step: 0
Training loss: 2.7965699780754547
Validation loss: 2.6276809647174386

Epoch: 5| Step: 1
Training loss: 2.870067843921279
Validation loss: 2.602959032840291

Epoch: 5| Step: 2
Training loss: 2.7343999371072707
Validation loss: 2.602278213128163

Epoch: 5| Step: 3
Training loss: 2.2420354386182257
Validation loss: 2.6043716395937815

Epoch: 5| Step: 4
Training loss: 2.9764071046010048
Validation loss: 2.6107500665664722

Epoch: 5| Step: 5
Training loss: 2.5902198760032866
Validation loss: 2.6161960664052035

Epoch: 5| Step: 6
Training loss: 3.1195071965834815
Validation loss: 2.6497428093210025

Epoch: 5| Step: 7
Training loss: 3.0545043890430255
Validation loss: 2.673390647820122

Epoch: 5| Step: 8
Training loss: 3.1732742906201383
Validation loss: 2.6858509954268137

Epoch: 5| Step: 9
Training loss: 3.487912285611779
Validation loss: 2.67221533289265

Epoch: 5| Step: 10
Training loss: 2.6663198444215856
Validation loss: 2.6561285137116117

Epoch: 312| Step: 0
Training loss: 3.0360880517466855
Validation loss: 2.6552918242328074

Epoch: 5| Step: 1
Training loss: 2.675867677949532
Validation loss: 2.6841741120828098

Epoch: 5| Step: 2
Training loss: 3.676221636701977
Validation loss: 2.7028554250503127

Epoch: 5| Step: 3
Training loss: 2.536394143255138
Validation loss: 2.6920400581929687

Epoch: 5| Step: 4
Training loss: 2.585974378985517
Validation loss: 2.6793893316766613

Epoch: 5| Step: 5
Training loss: 2.9494379833664257
Validation loss: 2.676867070318297

Epoch: 5| Step: 6
Training loss: 3.0200521752606173
Validation loss: 2.664596157255904

Epoch: 5| Step: 7
Training loss: 3.134241401358119
Validation loss: 2.6349803137411127

Epoch: 5| Step: 8
Training loss: 2.6205226315774994
Validation loss: 2.6286479683685537

Epoch: 5| Step: 9
Training loss: 3.3023757243543153
Validation loss: 2.615864841227113

Epoch: 5| Step: 10
Training loss: 2.059256459646408
Validation loss: 2.6083389611884433

Epoch: 313| Step: 0
Training loss: 3.3934369359067325
Validation loss: 2.6099865590768876

Epoch: 5| Step: 1
Training loss: 3.1199655797478014
Validation loss: 2.619933538673399

Epoch: 5| Step: 2
Training loss: 2.8981147031126047
Validation loss: 2.6236024154853412

Epoch: 5| Step: 3
Training loss: 2.782428791680737
Validation loss: 2.6343861227246297

Epoch: 5| Step: 4
Training loss: 2.775806629377318
Validation loss: 2.665943773279469

Epoch: 5| Step: 5
Training loss: 2.692129273319072
Validation loss: 2.71523410425003

Epoch: 5| Step: 6
Training loss: 2.2996791408473465
Validation loss: 2.73986134560555

Epoch: 5| Step: 7
Training loss: 3.1006034694386226
Validation loss: 2.7650183657811516

Epoch: 5| Step: 8
Training loss: 3.4745198967891366
Validation loss: 2.752803639300169

Epoch: 5| Step: 9
Training loss: 2.9011456364207477
Validation loss: 2.663232888945306

Epoch: 5| Step: 10
Training loss: 2.5043687794938694
Validation loss: 2.6249603037999374

Epoch: 314| Step: 0
Training loss: 2.716336461537457
Validation loss: 2.6091109293190957

Epoch: 5| Step: 1
Training loss: 3.0774949101794102
Validation loss: 2.598367669829395

Epoch: 5| Step: 2
Training loss: 2.736786569097503
Validation loss: 2.592306572370184

Epoch: 5| Step: 3
Training loss: 2.850909767170704
Validation loss: 2.5893955102968755

Epoch: 5| Step: 4
Training loss: 2.300024766374014
Validation loss: 2.5930520957279253

Epoch: 5| Step: 5
Training loss: 2.814206940514597
Validation loss: 2.584763654595827

Epoch: 5| Step: 6
Training loss: 2.863458437986174
Validation loss: 2.590205558404895

Epoch: 5| Step: 7
Training loss: 3.237292462033854
Validation loss: 2.5867093477823344

Epoch: 5| Step: 8
Training loss: 3.256665803277309
Validation loss: 2.5887764883864635

Epoch: 5| Step: 9
Training loss: 3.447018432399691
Validation loss: 2.586640053385837

Epoch: 5| Step: 10
Training loss: 2.6673974784162424
Validation loss: 2.5893352044330062

Epoch: 315| Step: 0
Training loss: 3.33297948548613
Validation loss: 2.5937960527079884

Epoch: 5| Step: 1
Training loss: 2.7885345044695407
Validation loss: 2.59491766067918

Epoch: 5| Step: 2
Training loss: 2.7791005947908394
Validation loss: 2.602222204641004

Epoch: 5| Step: 3
Training loss: 2.8411172270390956
Validation loss: 2.602882040510739

Epoch: 5| Step: 4
Training loss: 3.0498231367517543
Validation loss: 2.5965025917142768

Epoch: 5| Step: 5
Training loss: 2.9585297389493244
Validation loss: 2.6103337244567917

Epoch: 5| Step: 6
Training loss: 2.6044204181384587
Validation loss: 2.630470614827628

Epoch: 5| Step: 7
Training loss: 2.855422827146542
Validation loss: 2.6602493232988396

Epoch: 5| Step: 8
Training loss: 3.263307323904168
Validation loss: 2.682004223403578

Epoch: 5| Step: 9
Training loss: 3.0130194441721536
Validation loss: 2.6669576861672657

Epoch: 5| Step: 10
Training loss: 2.3752646047859645
Validation loss: 2.6286889917918224

Epoch: 316| Step: 0
Training loss: 2.939344760253364
Validation loss: 2.628903347881013

Epoch: 5| Step: 1
Training loss: 2.408845566742813
Validation loss: 2.623068961112046

Epoch: 5| Step: 2
Training loss: 3.461906900116004
Validation loss: 2.6174413002998755

Epoch: 5| Step: 3
Training loss: 2.868418915037264
Validation loss: 2.610684024307606

Epoch: 5| Step: 4
Training loss: 3.147335645340152
Validation loss: 2.6130326732223765

Epoch: 5| Step: 5
Training loss: 2.7276967484852084
Validation loss: 2.6006162189275135

Epoch: 5| Step: 6
Training loss: 2.474789920714961
Validation loss: 2.6076454766336585

Epoch: 5| Step: 7
Training loss: 2.7281357562889776
Validation loss: 2.607599733407143

Epoch: 5| Step: 8
Training loss: 2.780047982028215
Validation loss: 2.6172678308673887

Epoch: 5| Step: 9
Training loss: 3.3202645332013185
Validation loss: 2.6237183873603374

Epoch: 5| Step: 10
Training loss: 2.9311516523638406
Validation loss: 2.6168293555605744

Epoch: 317| Step: 0
Training loss: 3.3430460251205365
Validation loss: 2.6333453201367965

Epoch: 5| Step: 1
Training loss: 2.7912381445858863
Validation loss: 2.613395152929847

Epoch: 5| Step: 2
Training loss: 2.8776761743618313
Validation loss: 2.610774460193406

Epoch: 5| Step: 3
Training loss: 3.0969383687485066
Validation loss: 2.593661298246974

Epoch: 5| Step: 4
Training loss: 2.57656720810478
Validation loss: 2.600905312015936

Epoch: 5| Step: 5
Training loss: 3.1346090972894944
Validation loss: 2.6009584047189946

Epoch: 5| Step: 6
Training loss: 3.104943419354069
Validation loss: 2.603965526729536

Epoch: 5| Step: 7
Training loss: 2.395871656912975
Validation loss: 2.6155894092856244

Epoch: 5| Step: 8
Training loss: 2.946168810470649
Validation loss: 2.6247239228922963

Epoch: 5| Step: 9
Training loss: 3.129218344297672
Validation loss: 2.6336449965034

Epoch: 5| Step: 10
Training loss: 2.1925877940435186
Validation loss: 2.620370485868065

Epoch: 318| Step: 0
Training loss: 3.38751865958955
Validation loss: 2.6318192279359884

Epoch: 5| Step: 1
Training loss: 1.6430847620399267
Validation loss: 2.643153707527485

Epoch: 5| Step: 2
Training loss: 2.5049877955278363
Validation loss: 2.6563008872362888

Epoch: 5| Step: 3
Training loss: 2.7700293863713945
Validation loss: 2.642848271636036

Epoch: 5| Step: 4
Training loss: 2.7995862552949107
Validation loss: 2.6484747496331016

Epoch: 5| Step: 5
Training loss: 3.3828494310014965
Validation loss: 2.6525830528454852

Epoch: 5| Step: 6
Training loss: 3.42772241139294
Validation loss: 2.6720127640374427

Epoch: 5| Step: 7
Training loss: 2.508348449289731
Validation loss: 2.6672982005148436

Epoch: 5| Step: 8
Training loss: 2.784735049891767
Validation loss: 2.6428470358182374

Epoch: 5| Step: 9
Training loss: 2.793846664633877
Validation loss: 2.6345813021788635

Epoch: 5| Step: 10
Training loss: 3.425603359566778
Validation loss: 2.6503195558934145

Epoch: 319| Step: 0
Training loss: 2.822770165352218
Validation loss: 2.6117434320381117

Epoch: 5| Step: 1
Training loss: 2.9206623682186232
Validation loss: 2.6028045337281034

Epoch: 5| Step: 2
Training loss: 2.5535967536912807
Validation loss: 2.5845170486352558

Epoch: 5| Step: 3
Training loss: 2.4071331632806237
Validation loss: 2.590988468201068

Epoch: 5| Step: 4
Training loss: 2.987019430796535
Validation loss: 2.5806839867588662

Epoch: 5| Step: 5
Training loss: 2.4862052845182268
Validation loss: 2.5982215776293383

Epoch: 5| Step: 6
Training loss: 3.4464122029218633
Validation loss: 2.599200491170373

Epoch: 5| Step: 7
Training loss: 3.137706406327649
Validation loss: 2.6175763025819547

Epoch: 5| Step: 8
Training loss: 3.226319680302061
Validation loss: 2.6087930153235432

Epoch: 5| Step: 9
Training loss: 2.962145234446416
Validation loss: 2.614154843478831

Epoch: 5| Step: 10
Training loss: 2.727641506982322
Validation loss: 2.613180394906409

Epoch: 320| Step: 0
Training loss: 3.340619912781513
Validation loss: 2.6167391436307854

Epoch: 5| Step: 1
Training loss: 3.0210216244299604
Validation loss: 2.635403333269721

Epoch: 5| Step: 2
Training loss: 2.7282865915584256
Validation loss: 2.651291720822705

Epoch: 5| Step: 3
Training loss: 2.9116823022688623
Validation loss: 2.6465041537749627

Epoch: 5| Step: 4
Training loss: 2.8728596556947155
Validation loss: 2.6510295916399427

Epoch: 5| Step: 5
Training loss: 2.433986577005604
Validation loss: 2.6722469726959917

Epoch: 5| Step: 6
Training loss: 2.6091729731216007
Validation loss: 2.6695620058902083

Epoch: 5| Step: 7
Training loss: 2.584535247373456
Validation loss: 2.665646016110519

Epoch: 5| Step: 8
Training loss: 3.1037001461921454
Validation loss: 2.67390475042777

Epoch: 5| Step: 9
Training loss: 3.330923703586771
Validation loss: 2.697593598037549

Epoch: 5| Step: 10
Training loss: 2.7150798887017062
Validation loss: 2.672165882717752

Epoch: 321| Step: 0
Training loss: 2.8658425817389386
Validation loss: 2.6565936614833143

Epoch: 5| Step: 1
Training loss: 3.1580784100104946
Validation loss: 2.6443167801996683

Epoch: 5| Step: 2
Training loss: 3.2503927433688715
Validation loss: 2.6293329972743034

Epoch: 5| Step: 3
Training loss: 2.886447506602887
Validation loss: 2.615378689580574

Epoch: 5| Step: 4
Training loss: 2.4092493561318995
Validation loss: 2.6156537487249483

Epoch: 5| Step: 5
Training loss: 2.3014646593521855
Validation loss: 2.618375256141291

Epoch: 5| Step: 6
Training loss: 3.539002811694854
Validation loss: 2.6188635523444033

Epoch: 5| Step: 7
Training loss: 2.7081050972258907
Validation loss: 2.6273477195976214

Epoch: 5| Step: 8
Training loss: 2.896879450888234
Validation loss: 2.6336564322074674

Epoch: 5| Step: 9
Training loss: 2.7227031862435647
Validation loss: 2.627764904508081

Epoch: 5| Step: 10
Training loss: 2.7710218628344743
Validation loss: 2.6203206942057142

Epoch: 322| Step: 0
Training loss: 2.933015850254519
Validation loss: 2.612622718776484

Epoch: 5| Step: 1
Training loss: 3.0684945740225227
Validation loss: 2.648687065055235

Epoch: 5| Step: 2
Training loss: 2.9641229811366205
Validation loss: 2.646653493381588

Epoch: 5| Step: 3
Training loss: 2.999572882447069
Validation loss: 2.6487987824972477

Epoch: 5| Step: 4
Training loss: 2.9211237140433783
Validation loss: 2.6929383148242567

Epoch: 5| Step: 5
Training loss: 2.9012863266037683
Validation loss: 2.68856455615771

Epoch: 5| Step: 6
Training loss: 3.0653783545399307
Validation loss: 2.733185799999293

Epoch: 5| Step: 7
Training loss: 3.0542950390269774
Validation loss: 2.7557331184570995

Epoch: 5| Step: 8
Training loss: 2.4781179266849125
Validation loss: 2.7818191082476833

Epoch: 5| Step: 9
Training loss: 2.805207865691733
Validation loss: 2.758223446684943

Epoch: 5| Step: 10
Training loss: 2.340979604509195
Validation loss: 2.701674628558939

Epoch: 323| Step: 0
Training loss: 3.081777661313673
Validation loss: 2.641469933975819

Epoch: 5| Step: 1
Training loss: 2.903407686101183
Validation loss: 2.625078343688729

Epoch: 5| Step: 2
Training loss: 2.849644514969251
Validation loss: 2.6054589183927086

Epoch: 5| Step: 3
Training loss: 2.4543933869468
Validation loss: 2.591381592376813

Epoch: 5| Step: 4
Training loss: 2.9753808106396655
Validation loss: 2.5929486543756948

Epoch: 5| Step: 5
Training loss: 2.943545674159696
Validation loss: 2.5933134529750386

Epoch: 5| Step: 6
Training loss: 3.112079919862648
Validation loss: 2.5893832850847867

Epoch: 5| Step: 7
Training loss: 2.604485596518657
Validation loss: 2.590757469985108

Epoch: 5| Step: 8
Training loss: 3.143637962695916
Validation loss: 2.5896370008577434

Epoch: 5| Step: 9
Training loss: 2.962404878916111
Validation loss: 2.5891670591860754

Epoch: 5| Step: 10
Training loss: 2.8776683863497676
Validation loss: 2.5950308299888274

Epoch: 324| Step: 0
Training loss: 2.8570884358808946
Validation loss: 2.59302352336616

Epoch: 5| Step: 1
Training loss: 3.606496348305285
Validation loss: 2.598072465663784

Epoch: 5| Step: 2
Training loss: 2.6386380818177484
Validation loss: 2.6008520684037952

Epoch: 5| Step: 3
Training loss: 2.8654720153240842
Validation loss: 2.6056820627353368

Epoch: 5| Step: 4
Training loss: 2.6099183207918277
Validation loss: 2.608284619093441

Epoch: 5| Step: 5
Training loss: 2.896849328249333
Validation loss: 2.61438589049591

Epoch: 5| Step: 6
Training loss: 2.6682439748688327
Validation loss: 2.6196146236334195

Epoch: 5| Step: 7
Training loss: 2.7849305049368613
Validation loss: 2.6329657017499164

Epoch: 5| Step: 8
Training loss: 2.961137669221332
Validation loss: 2.6640544936104584

Epoch: 5| Step: 9
Training loss: 2.5435786533991496
Validation loss: 2.669215824611851

Epoch: 5| Step: 10
Training loss: 3.524112205442365
Validation loss: 2.703503386553583

Epoch: 325| Step: 0
Training loss: 3.0682925502947622
Validation loss: 2.7243235159037207

Epoch: 5| Step: 1
Training loss: 3.153142173274204
Validation loss: 2.7563662751156626

Epoch: 5| Step: 2
Training loss: 3.182515903861679
Validation loss: 2.7666420211119283

Epoch: 5| Step: 3
Training loss: 2.309871210413583
Validation loss: 2.7676913791372035

Epoch: 5| Step: 4
Training loss: 2.404936493889669
Validation loss: 2.7490015333465756

Epoch: 5| Step: 5
Training loss: 3.4278794651896165
Validation loss: 2.7500798231530283

Epoch: 5| Step: 6
Training loss: 3.720197379915779
Validation loss: 2.7268417783746735

Epoch: 5| Step: 7
Training loss: 3.0618559490980863
Validation loss: 2.704171824886832

Epoch: 5| Step: 8
Training loss: 2.0081077981942856
Validation loss: 2.6790583348567534

Epoch: 5| Step: 9
Training loss: 3.3727149292005607
Validation loss: 2.632992847539329

Epoch: 5| Step: 10
Training loss: 2.0414384467837468
Validation loss: 2.622946701328099

Epoch: 326| Step: 0
Training loss: 2.8529049574367162
Validation loss: 2.612803217727266

Epoch: 5| Step: 1
Training loss: 3.0776833154418157
Validation loss: 2.606440313954993

Epoch: 5| Step: 2
Training loss: 2.9579688013274352
Validation loss: 2.603636788553046

Epoch: 5| Step: 3
Training loss: 2.6715960440658795
Validation loss: 2.5923279452948234

Epoch: 5| Step: 4
Training loss: 2.7485197591697665
Validation loss: 2.589600521513682

Epoch: 5| Step: 5
Training loss: 3.3053647332628
Validation loss: 2.58611133817568

Epoch: 5| Step: 6
Training loss: 2.972604437838957
Validation loss: 2.5908477098869453

Epoch: 5| Step: 7
Training loss: 2.843176815410277
Validation loss: 2.5812623783049062

Epoch: 5| Step: 8
Training loss: 2.9561156615366597
Validation loss: 2.5815879616621142

Epoch: 5| Step: 9
Training loss: 2.866646614300287
Validation loss: 2.583091492965187

Epoch: 5| Step: 10
Training loss: 2.8703570815659507
Validation loss: 2.577515612563374

Epoch: 327| Step: 0
Training loss: 2.8841830668129624
Validation loss: 2.580693822351946

Epoch: 5| Step: 1
Training loss: 3.151315892584937
Validation loss: 2.580265116234546

Epoch: 5| Step: 2
Training loss: 2.7105925502686268
Validation loss: 2.585751711633247

Epoch: 5| Step: 3
Training loss: 2.8054039340285284
Validation loss: 2.5924396647128023

Epoch: 5| Step: 4
Training loss: 2.6365639422147
Validation loss: 2.598796287944794

Epoch: 5| Step: 5
Training loss: 2.7868943108049806
Validation loss: 2.6013958664598307

Epoch: 5| Step: 6
Training loss: 2.7705794961481107
Validation loss: 2.6210795589918865

Epoch: 5| Step: 7
Training loss: 2.8568844814639753
Validation loss: 2.625696460976499

Epoch: 5| Step: 8
Training loss: 2.5045588888082757
Validation loss: 2.6349469460626227

Epoch: 5| Step: 9
Training loss: 3.6451504458343162
Validation loss: 2.6482182893990953

Epoch: 5| Step: 10
Training loss: 2.9732209921114388
Validation loss: 2.6330075497689815

Epoch: 328| Step: 0
Training loss: 2.6104044453993698
Validation loss: 2.658666230070495

Epoch: 5| Step: 1
Training loss: 3.6013404628801253
Validation loss: 2.672280016607352

Epoch: 5| Step: 2
Training loss: 2.660733198206572
Validation loss: 2.6609140427178666

Epoch: 5| Step: 3
Training loss: 2.4783103382896856
Validation loss: 2.647747325806475

Epoch: 5| Step: 4
Training loss: 2.586044724191993
Validation loss: 2.648897559454767

Epoch: 5| Step: 5
Training loss: 2.887944643869104
Validation loss: 2.6482772147037092

Epoch: 5| Step: 6
Training loss: 3.255182828676127
Validation loss: 2.6452309120709168

Epoch: 5| Step: 7
Training loss: 3.0255888941044073
Validation loss: 2.6297678163191094

Epoch: 5| Step: 8
Training loss: 2.408796770941357
Validation loss: 2.633236576539024

Epoch: 5| Step: 9
Training loss: 3.161233876203428
Validation loss: 2.6456419068310844

Epoch: 5| Step: 10
Training loss: 2.8524584891051212
Validation loss: 2.6547370438282982

Epoch: 329| Step: 0
Training loss: 3.3141574671554235
Validation loss: 2.633792447864655

Epoch: 5| Step: 1
Training loss: 3.001481008540435
Validation loss: 2.6292107596547623

Epoch: 5| Step: 2
Training loss: 3.103027305332907
Validation loss: 2.6297997065366014

Epoch: 5| Step: 3
Training loss: 2.608587180349572
Validation loss: 2.6401076368552836

Epoch: 5| Step: 4
Training loss: 2.5673207783015215
Validation loss: 2.634103775742315

Epoch: 5| Step: 5
Training loss: 3.265003784084026
Validation loss: 2.6384504975951817

Epoch: 5| Step: 6
Training loss: 3.1778872780803695
Validation loss: 2.6292251866164023

Epoch: 5| Step: 7
Training loss: 2.7125749287606093
Validation loss: 2.6422565174978736

Epoch: 5| Step: 8
Training loss: 2.6468243482623093
Validation loss: 2.638823195760394

Epoch: 5| Step: 9
Training loss: 2.4873832866949153
Validation loss: 2.641853981937548

Epoch: 5| Step: 10
Training loss: 2.5721273305411225
Validation loss: 2.636022808760411

Epoch: 330| Step: 0
Training loss: 3.429991272006038
Validation loss: 2.6445343540557746

Epoch: 5| Step: 1
Training loss: 3.125473139231111
Validation loss: 2.6465077456729813

Epoch: 5| Step: 2
Training loss: 2.5382799086915027
Validation loss: 2.6400965932351217

Epoch: 5| Step: 3
Training loss: 2.826028120264099
Validation loss: 2.6447664712666215

Epoch: 5| Step: 4
Training loss: 2.6291938159667354
Validation loss: 2.6468024739360465

Epoch: 5| Step: 5
Training loss: 2.782605301748673
Validation loss: 2.6491171493273704

Epoch: 5| Step: 6
Training loss: 2.4635163857666287
Validation loss: 2.642454124132637

Epoch: 5| Step: 7
Training loss: 2.9002304906340997
Validation loss: 2.6613197911092414

Epoch: 5| Step: 8
Training loss: 2.538355238785112
Validation loss: 2.667387665548364

Epoch: 5| Step: 9
Training loss: 3.240550756385697
Validation loss: 2.661138696723296

Epoch: 5| Step: 10
Training loss: 2.9581063053613135
Validation loss: 2.679627533756545

Epoch: 331| Step: 0
Training loss: 2.4915156400535294
Validation loss: 2.658850056642858

Epoch: 5| Step: 1
Training loss: 3.0610070774179743
Validation loss: 2.653911387735529

Epoch: 5| Step: 2
Training loss: 3.005196521191492
Validation loss: 2.62774151738289

Epoch: 5| Step: 3
Training loss: 3.148945429038661
Validation loss: 2.625669738680667

Epoch: 5| Step: 4
Training loss: 3.1604053601888555
Validation loss: 2.6145099351287073

Epoch: 5| Step: 5
Training loss: 2.783886720462847
Validation loss: 2.607064705769788

Epoch: 5| Step: 6
Training loss: 3.010697366020162
Validation loss: 2.61220612652915

Epoch: 5| Step: 7
Training loss: 2.845860965831047
Validation loss: 2.6119633678448038

Epoch: 5| Step: 8
Training loss: 2.565793038184281
Validation loss: 2.6257057159330857

Epoch: 5| Step: 9
Training loss: 2.8571727172108656
Validation loss: 2.62430448444534

Epoch: 5| Step: 10
Training loss: 2.508501570204026
Validation loss: 2.61975748054548

Epoch: 332| Step: 0
Training loss: 2.9643087796546594
Validation loss: 2.627513332722419

Epoch: 5| Step: 1
Training loss: 3.0370123452145124
Validation loss: 2.642874560273209

Epoch: 5| Step: 2
Training loss: 2.608698317450392
Validation loss: 2.6386525709089557

Epoch: 5| Step: 3
Training loss: 2.778951917031245
Validation loss: 2.6365534904948045

Epoch: 5| Step: 4
Training loss: 3.1064606623913433
Validation loss: 2.640358871832564

Epoch: 5| Step: 5
Training loss: 2.7173147688329156
Validation loss: 2.637012362583483

Epoch: 5| Step: 6
Training loss: 3.191281039561059
Validation loss: 2.6370507136831827

Epoch: 5| Step: 7
Training loss: 3.0436739808288777
Validation loss: 2.607148753750462

Epoch: 5| Step: 8
Training loss: 2.838651677137618
Validation loss: 2.6214354783351665

Epoch: 5| Step: 9
Training loss: 2.38516109602255
Validation loss: 2.6229937641663805

Epoch: 5| Step: 10
Training loss: 2.8054947820277376
Validation loss: 2.6335101579427374

Epoch: 333| Step: 0
Training loss: 3.277111822749372
Validation loss: 2.6407398126831714

Epoch: 5| Step: 1
Training loss: 2.35575437316521
Validation loss: 2.6320793694196363

Epoch: 5| Step: 2
Training loss: 3.041297541825699
Validation loss: 2.6333998684040645

Epoch: 5| Step: 3
Training loss: 2.6512228573457843
Validation loss: 2.626527455627754

Epoch: 5| Step: 4
Training loss: 2.8027832026996755
Validation loss: 2.625419053919669

Epoch: 5| Step: 5
Training loss: 3.001290202858581
Validation loss: 2.6309872840302195

Epoch: 5| Step: 6
Training loss: 3.189987857281286
Validation loss: 2.6446798431310112

Epoch: 5| Step: 7
Training loss: 2.5586647547995836
Validation loss: 2.6554891752577943

Epoch: 5| Step: 8
Training loss: 2.682150373471914
Validation loss: 2.6350553700148587

Epoch: 5| Step: 9
Training loss: 2.538469262878296
Validation loss: 2.6551257133813086

Epoch: 5| Step: 10
Training loss: 3.3360963019780736
Validation loss: 2.6462451096652293

Epoch: 334| Step: 0
Training loss: 2.528596688345295
Validation loss: 2.6447104824101038

Epoch: 5| Step: 1
Training loss: 2.802522891901393
Validation loss: 2.6340785840273444

Epoch: 5| Step: 2
Training loss: 2.7539690159347763
Validation loss: 2.6351319622585825

Epoch: 5| Step: 3
Training loss: 2.7267819728891673
Validation loss: 2.6236032206529027

Epoch: 5| Step: 4
Training loss: 2.966266757999735
Validation loss: 2.6351906110693757

Epoch: 5| Step: 5
Training loss: 2.99774927905108
Validation loss: 2.6345966231729077

Epoch: 5| Step: 6
Training loss: 2.9411528580783624
Validation loss: 2.634872715667201

Epoch: 5| Step: 7
Training loss: 3.224653589140777
Validation loss: 2.641727911095357

Epoch: 5| Step: 8
Training loss: 2.505672884964299
Validation loss: 2.6314915455248507

Epoch: 5| Step: 9
Training loss: 3.224696323971598
Validation loss: 2.632768066514271

Epoch: 5| Step: 10
Training loss: 2.8065248384530217
Validation loss: 2.6122811717770076

Epoch: 335| Step: 0
Training loss: 3.2636607710388605
Validation loss: 2.604564132055726

Epoch: 5| Step: 1
Training loss: 2.32441856743482
Validation loss: 2.611597615907927

Epoch: 5| Step: 2
Training loss: 3.4161739149110875
Validation loss: 2.6234303765836415

Epoch: 5| Step: 3
Training loss: 2.558331145576594
Validation loss: 2.629390747787866

Epoch: 5| Step: 4
Training loss: 3.0812151738610916
Validation loss: 2.631827653839927

Epoch: 5| Step: 5
Training loss: 2.645574411854342
Validation loss: 2.6532155810122724

Epoch: 5| Step: 6
Training loss: 2.3683033947413614
Validation loss: 2.6766861342057764

Epoch: 5| Step: 7
Training loss: 2.5382615924331153
Validation loss: 2.6949484692400474

Epoch: 5| Step: 8
Training loss: 2.9481838001940384
Validation loss: 2.693721186990063

Epoch: 5| Step: 9
Training loss: 3.2915137211158556
Validation loss: 2.6532329210825005

Epoch: 5| Step: 10
Training loss: 2.916618637416117
Validation loss: 2.5995224787114224

Epoch: 336| Step: 0
Training loss: 3.0617067516390635
Validation loss: 2.600706093090274

Epoch: 5| Step: 1
Training loss: 3.1344483021829563
Validation loss: 2.5864283023417807

Epoch: 5| Step: 2
Training loss: 2.981808182705948
Validation loss: 2.602015934608415

Epoch: 5| Step: 3
Training loss: 3.000555146033348
Validation loss: 2.5810828500454766

Epoch: 5| Step: 4
Training loss: 3.2685796339520823
Validation loss: 2.5870112067574595

Epoch: 5| Step: 5
Training loss: 2.2722346214053544
Validation loss: 2.5871450709345667

Epoch: 5| Step: 6
Training loss: 3.0799270234813525
Validation loss: 2.598712319049789

Epoch: 5| Step: 7
Training loss: 2.4503560566542824
Validation loss: 2.594186166225201

Epoch: 5| Step: 8
Training loss: 2.6957070766719062
Validation loss: 2.590143546236552

Epoch: 5| Step: 9
Training loss: 3.14684139714867
Validation loss: 2.602389382246841

Epoch: 5| Step: 10
Training loss: 2.4292941741020524
Validation loss: 2.6165562218089553

Epoch: 337| Step: 0
Training loss: 2.6178447752091496
Validation loss: 2.6314502472188996

Epoch: 5| Step: 1
Training loss: 2.7305088285852834
Validation loss: 2.65115341575376

Epoch: 5| Step: 2
Training loss: 2.902272445603745
Validation loss: 2.6995041146124636

Epoch: 5| Step: 3
Training loss: 2.534367090252858
Validation loss: 2.7224383674025256

Epoch: 5| Step: 4
Training loss: 3.245655236767237
Validation loss: 2.751466632217918

Epoch: 5| Step: 5
Training loss: 3.072703122407791
Validation loss: 2.739377289198855

Epoch: 5| Step: 6
Training loss: 3.292092420511306
Validation loss: 2.7078546575902886

Epoch: 5| Step: 7
Training loss: 2.992075467315592
Validation loss: 2.6375128895745408

Epoch: 5| Step: 8
Training loss: 2.6074109023645526
Validation loss: 2.622692977305645

Epoch: 5| Step: 9
Training loss: 2.8180045620276926
Validation loss: 2.597694607763819

Epoch: 5| Step: 10
Training loss: 2.7147516248701478
Validation loss: 2.5923238827517325

Epoch: 338| Step: 0
Training loss: 2.809562420560475
Validation loss: 2.5817895564276148

Epoch: 5| Step: 1
Training loss: 3.149741534573772
Validation loss: 2.5821294367640237

Epoch: 5| Step: 2
Training loss: 3.007639060035978
Validation loss: 2.5831461179326025

Epoch: 5| Step: 3
Training loss: 3.1073040223566015
Validation loss: 2.5878357514724013

Epoch: 5| Step: 4
Training loss: 2.6202281995211636
Validation loss: 2.592969029364053

Epoch: 5| Step: 5
Training loss: 2.671397116237648
Validation loss: 2.5859142025203354

Epoch: 5| Step: 6
Training loss: 2.6405128590625178
Validation loss: 2.592136835700691

Epoch: 5| Step: 7
Training loss: 2.6983412380310856
Validation loss: 2.6062583818347855

Epoch: 5| Step: 8
Training loss: 3.3008003189168122
Validation loss: 2.62467844019481

Epoch: 5| Step: 9
Training loss: 3.295040252856456
Validation loss: 2.638207591359386

Epoch: 5| Step: 10
Training loss: 2.1298458720575777
Validation loss: 2.665030353930989

Epoch: 339| Step: 0
Training loss: 2.7731323074268617
Validation loss: 2.680693279647844

Epoch: 5| Step: 1
Training loss: 2.8194309029674174
Validation loss: 2.68927633881252

Epoch: 5| Step: 2
Training loss: 2.710147709639226
Validation loss: 2.672552951901438

Epoch: 5| Step: 3
Training loss: 2.4409294456277744
Validation loss: 2.647886370329865

Epoch: 5| Step: 4
Training loss: 3.249053083536222
Validation loss: 2.6422173279732637

Epoch: 5| Step: 5
Training loss: 3.1488298876820986
Validation loss: 2.626539609950025

Epoch: 5| Step: 6
Training loss: 2.833523145563288
Validation loss: 2.6122507782599462

Epoch: 5| Step: 7
Training loss: 2.4719793710002183
Validation loss: 2.6110542979620024

Epoch: 5| Step: 8
Training loss: 2.782829778961393
Validation loss: 2.601456408136007

Epoch: 5| Step: 9
Training loss: 2.9152422196794996
Validation loss: 2.585343938693063

Epoch: 5| Step: 10
Training loss: 3.284343750548218
Validation loss: 2.5871980110131134

Epoch: 340| Step: 0
Training loss: 2.5540851034445207
Validation loss: 2.5960129958347204

Epoch: 5| Step: 1
Training loss: 3.03351830627642
Validation loss: 2.6027006378067807

Epoch: 5| Step: 2
Training loss: 3.3243528668505395
Validation loss: 2.593642377739477

Epoch: 5| Step: 3
Training loss: 2.356475463117825
Validation loss: 2.61261762411239

Epoch: 5| Step: 4
Training loss: 2.9692164004522885
Validation loss: 2.617605392404846

Epoch: 5| Step: 5
Training loss: 2.429942028782709
Validation loss: 2.643233178450549

Epoch: 5| Step: 6
Training loss: 2.7004329969982326
Validation loss: 2.64566429753836

Epoch: 5| Step: 7
Training loss: 2.6980278159164675
Validation loss: 2.6337728870547035

Epoch: 5| Step: 8
Training loss: 2.760444055577321
Validation loss: 2.645416467867759

Epoch: 5| Step: 9
Training loss: 3.4472659016465896
Validation loss: 2.651270146364437

Epoch: 5| Step: 10
Training loss: 2.9840167564555693
Validation loss: 2.626810210479231

Epoch: 341| Step: 0
Training loss: 3.2829594110355425
Validation loss: 2.6206085761996896

Epoch: 5| Step: 1
Training loss: 3.0082164146408172
Validation loss: 2.6094306845050546

Epoch: 5| Step: 2
Training loss: 3.0002852940008804
Validation loss: 2.605354833125802

Epoch: 5| Step: 3
Training loss: 2.769205910925678
Validation loss: 2.608461221603134

Epoch: 5| Step: 4
Training loss: 2.5990713294978787
Validation loss: 2.6221932672071464

Epoch: 5| Step: 5
Training loss: 2.846900452417352
Validation loss: 2.629207785717305

Epoch: 5| Step: 6
Training loss: 2.914839653721827
Validation loss: 2.6627072933909286

Epoch: 5| Step: 7
Training loss: 2.4721053294670208
Validation loss: 2.679583046126222

Epoch: 5| Step: 8
Training loss: 2.82998208461523
Validation loss: 2.6758993579177837

Epoch: 5| Step: 9
Training loss: 3.07351432203931
Validation loss: 2.682478788742104

Epoch: 5| Step: 10
Training loss: 2.6627714994739304
Validation loss: 2.6675612220781657

Epoch: 342| Step: 0
Training loss: 2.8492127653016732
Validation loss: 2.6209600067971106

Epoch: 5| Step: 1
Training loss: 3.0734216997043973
Validation loss: 2.6131752385427305

Epoch: 5| Step: 2
Training loss: 2.806158503546724
Validation loss: 2.6102995673525946

Epoch: 5| Step: 3
Training loss: 2.5783955749942447
Validation loss: 2.605162842899659

Epoch: 5| Step: 4
Training loss: 3.0937447596033585
Validation loss: 2.597209154293969

Epoch: 5| Step: 5
Training loss: 2.7939476165175314
Validation loss: 2.5989531283669978

Epoch: 5| Step: 6
Training loss: 3.0820377480325987
Validation loss: 2.5921340348322714

Epoch: 5| Step: 7
Training loss: 3.233212026961966
Validation loss: 2.5853222918597236

Epoch: 5| Step: 8
Training loss: 2.470038934624718
Validation loss: 2.5880869464391774

Epoch: 5| Step: 9
Training loss: 2.6628048073100468
Validation loss: 2.577505298365294

Epoch: 5| Step: 10
Training loss: 2.763711903420366
Validation loss: 2.583877117893778

Epoch: 343| Step: 0
Training loss: 3.354511661833937
Validation loss: 2.600395826195183

Epoch: 5| Step: 1
Training loss: 2.274612699804639
Validation loss: 2.5991352788902304

Epoch: 5| Step: 2
Training loss: 3.089020167182746
Validation loss: 2.6160956999834166

Epoch: 5| Step: 3
Training loss: 2.1703395767665032
Validation loss: 2.6298738871085803

Epoch: 5| Step: 4
Training loss: 2.8720322923890307
Validation loss: 2.6301874313246856

Epoch: 5| Step: 5
Training loss: 2.9388264035475093
Validation loss: 2.6470951433389103

Epoch: 5| Step: 6
Training loss: 2.704470966382855
Validation loss: 2.65953279976635

Epoch: 5| Step: 7
Training loss: 2.6399042172829343
Validation loss: 2.664406877074207

Epoch: 5| Step: 8
Training loss: 3.018861605079802
Validation loss: 2.6835736675806356

Epoch: 5| Step: 9
Training loss: 3.0326188919397703
Validation loss: 2.6747500299659652

Epoch: 5| Step: 10
Training loss: 3.1159803304577847
Validation loss: 2.658595153650659

Epoch: 344| Step: 0
Training loss: 2.8695831684636675
Validation loss: 2.655244007262866

Epoch: 5| Step: 1
Training loss: 2.7439159369201302
Validation loss: 2.6273262997953566

Epoch: 5| Step: 2
Training loss: 2.9503524117183897
Validation loss: 2.6014963762622627

Epoch: 5| Step: 3
Training loss: 2.6362219222315852
Validation loss: 2.5909530675953207

Epoch: 5| Step: 4
Training loss: 2.8243382852037358
Validation loss: 2.5771585123956586

Epoch: 5| Step: 5
Training loss: 3.0332417973830577
Validation loss: 2.574070517353242

Epoch: 5| Step: 6
Training loss: 2.9107773495661875
Validation loss: 2.5749567585958366

Epoch: 5| Step: 7
Training loss: 2.895336373771648
Validation loss: 2.5815816726817804

Epoch: 5| Step: 8
Training loss: 2.910036635020784
Validation loss: 2.5933322720844845

Epoch: 5| Step: 9
Training loss: 3.0381275298000743
Validation loss: 2.617104618803121

Epoch: 5| Step: 10
Training loss: 2.6266656767977223
Validation loss: 2.636177615258958

Epoch: 345| Step: 0
Training loss: 3.4279970073887194
Validation loss: 2.62093157043613

Epoch: 5| Step: 1
Training loss: 2.380387269576449
Validation loss: 2.6315497698620884

Epoch: 5| Step: 2
Training loss: 3.053144841046713
Validation loss: 2.6327035376931494

Epoch: 5| Step: 3
Training loss: 2.4142217984771888
Validation loss: 2.622281634408999

Epoch: 5| Step: 4
Training loss: 2.816455433240153
Validation loss: 2.6416666027842997

Epoch: 5| Step: 5
Training loss: 2.762928914738258
Validation loss: 2.654753091538717

Epoch: 5| Step: 6
Training loss: 2.721319278085769
Validation loss: 2.661553480487515

Epoch: 5| Step: 7
Training loss: 3.0780351499814755
Validation loss: 2.6526149094220837

Epoch: 5| Step: 8
Training loss: 3.2867420555686677
Validation loss: 2.6454164698059346

Epoch: 5| Step: 9
Training loss: 2.1904758375376856
Validation loss: 2.621128720056233

Epoch: 5| Step: 10
Training loss: 2.996290138303617
Validation loss: 2.6254472961841473

Epoch: 346| Step: 0
Training loss: 2.709746789117539
Validation loss: 2.646831275482034

Epoch: 5| Step: 1
Training loss: 3.022979307325323
Validation loss: 2.641227241367862

Epoch: 5| Step: 2
Training loss: 2.8730956695168173
Validation loss: 2.64539884979419

Epoch: 5| Step: 3
Training loss: 2.435746466955837
Validation loss: 2.6605241971672884

Epoch: 5| Step: 4
Training loss: 3.1690718568243006
Validation loss: 2.647711117456912

Epoch: 5| Step: 5
Training loss: 2.7919842458734117
Validation loss: 2.6223259229651203

Epoch: 5| Step: 6
Training loss: 2.9529462487754055
Validation loss: 2.6463478143052868

Epoch: 5| Step: 7
Training loss: 2.5139132534225683
Validation loss: 2.625143682997995

Epoch: 5| Step: 8
Training loss: 2.935775737762352
Validation loss: 2.657204702411263

Epoch: 5| Step: 9
Training loss: 2.8813732658712983
Validation loss: 2.6463375165081375

Epoch: 5| Step: 10
Training loss: 3.012340595254196
Validation loss: 2.634654450973171

Epoch: 347| Step: 0
Training loss: 3.4359629575888695
Validation loss: 2.6132718745232872

Epoch: 5| Step: 1
Training loss: 3.1003147949850076
Validation loss: 2.6122014098768567

Epoch: 5| Step: 2
Training loss: 2.5574750245367306
Validation loss: 2.608855375244684

Epoch: 5| Step: 3
Training loss: 2.7109266825083616
Validation loss: 2.5951059560163086

Epoch: 5| Step: 4
Training loss: 2.8180043082112936
Validation loss: 2.5971338956323464

Epoch: 5| Step: 5
Training loss: 2.2698150824963754
Validation loss: 2.6005409947873557

Epoch: 5| Step: 6
Training loss: 2.7826054731122305
Validation loss: 2.6031934754881636

Epoch: 5| Step: 7
Training loss: 2.7463185203453095
Validation loss: 2.611276628395434

Epoch: 5| Step: 8
Training loss: 3.302989334019929
Validation loss: 2.6203397155875012

Epoch: 5| Step: 9
Training loss: 2.4702026342756427
Validation loss: 2.626985089397733

Epoch: 5| Step: 10
Training loss: 2.970838755584377
Validation loss: 2.6130249416696394

Epoch: 348| Step: 0
Training loss: 2.58790951128132
Validation loss: 2.588841660561255

Epoch: 5| Step: 1
Training loss: 3.2206895040266854
Validation loss: 2.5832770563427006

Epoch: 5| Step: 2
Training loss: 2.676798249933978
Validation loss: 2.5692693326020923

Epoch: 5| Step: 3
Training loss: 3.043937479938591
Validation loss: 2.5884127410324433

Epoch: 5| Step: 4
Training loss: 2.81476434049842
Validation loss: 2.5872188296256877

Epoch: 5| Step: 5
Training loss: 3.0458102982498443
Validation loss: 2.5913135082062757

Epoch: 5| Step: 6
Training loss: 3.1462476512246957
Validation loss: 2.5741886032146533

Epoch: 5| Step: 7
Training loss: 2.0968851558251753
Validation loss: 2.5861178129154188

Epoch: 5| Step: 8
Training loss: 3.1547598767681064
Validation loss: 2.5934978974899034

Epoch: 5| Step: 9
Training loss: 2.707187224239162
Validation loss: 2.5959321701861042

Epoch: 5| Step: 10
Training loss: 2.6764448025329908
Validation loss: 2.6054468216864755

Epoch: 349| Step: 0
Training loss: 3.0447311292684174
Validation loss: 2.622234634069123

Epoch: 5| Step: 1
Training loss: 2.989469005423406
Validation loss: 2.635989045805866

Epoch: 5| Step: 2
Training loss: 2.574274320103917
Validation loss: 2.655023524033745

Epoch: 5| Step: 3
Training loss: 2.6955832525072396
Validation loss: 2.6639852306003116

Epoch: 5| Step: 4
Training loss: 2.9453523263844152
Validation loss: 2.6541162702387977

Epoch: 5| Step: 5
Training loss: 3.0209853210799724
Validation loss: 2.6473112280017026

Epoch: 5| Step: 6
Training loss: 2.945891710392687
Validation loss: 2.6507546877779062

Epoch: 5| Step: 7
Training loss: 2.347907079921355
Validation loss: 2.626471341020589

Epoch: 5| Step: 8
Training loss: 2.901317389287802
Validation loss: 2.623702570961654

Epoch: 5| Step: 9
Training loss: 2.7362758459941667
Validation loss: 2.630143245905776

Epoch: 5| Step: 10
Training loss: 3.030367693355642
Validation loss: 2.6253500293395633

Epoch: 350| Step: 0
Training loss: 2.6033425413091793
Validation loss: 2.632094987434848

Epoch: 5| Step: 1
Training loss: 2.102666855404268
Validation loss: 2.6460580773148594

Epoch: 5| Step: 2
Training loss: 3.0125075913962798
Validation loss: 2.6548409360180196

Epoch: 5| Step: 3
Training loss: 3.0846851753331994
Validation loss: 2.665063066951271

Epoch: 5| Step: 4
Training loss: 2.6877980621414923
Validation loss: 2.6592852474307165

Epoch: 5| Step: 5
Training loss: 2.1148004905805458
Validation loss: 2.65186088584222

Epoch: 5| Step: 6
Training loss: 2.965472530388911
Validation loss: 2.6491830153852187

Epoch: 5| Step: 7
Training loss: 2.9455504789260303
Validation loss: 2.6200377248173985

Epoch: 5| Step: 8
Training loss: 3.2037617864551957
Validation loss: 2.618548304654764

Epoch: 5| Step: 9
Training loss: 2.810099615863149
Validation loss: 2.6187947543855934

Epoch: 5| Step: 10
Training loss: 3.408150938667439
Validation loss: 2.61262433489763

Testing loss: 2.7844058264269784
