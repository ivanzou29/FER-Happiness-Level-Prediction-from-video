Epoch: 1| Step: 0
Training loss: 4.999163557660933
Validation loss: 5.7541164877205055

Epoch: 5| Step: 1
Training loss: 5.002165897465965
Validation loss: 5.744931750278457

Epoch: 5| Step: 2
Training loss: 5.448733247301077
Validation loss: 5.736182690457473

Epoch: 5| Step: 3
Training loss: 5.318758879137528
Validation loss: 5.727442576356226

Epoch: 5| Step: 4
Training loss: 4.5512460364848595
Validation loss: 5.719015024652905

Epoch: 5| Step: 5
Training loss: 5.4061432756242365
Validation loss: 5.709781849474303

Epoch: 5| Step: 6
Training loss: 6.159562047772661
Validation loss: 5.700194642378265

Epoch: 5| Step: 7
Training loss: 7.354018025251411
Validation loss: 5.690025718056011

Epoch: 5| Step: 8
Training loss: 5.484702945479042
Validation loss: 5.678986399652748

Epoch: 5| Step: 9
Training loss: 6.950151334802729
Validation loss: 5.667427329826034

Epoch: 5| Step: 10
Training loss: 5.874749360926893
Validation loss: 5.654887482473668

Epoch: 2| Step: 0
Training loss: 4.7650838575959895
Validation loss: 5.64153416930415

Epoch: 5| Step: 1
Training loss: 5.496411106298225
Validation loss: 5.627034264977645

Epoch: 5| Step: 2
Training loss: 5.678934207374607
Validation loss: 5.611734093049942

Epoch: 5| Step: 3
Training loss: 5.096838640730024
Validation loss: 5.595439154236034

Epoch: 5| Step: 4
Training loss: 5.639035156724889
Validation loss: 5.578752547144707

Epoch: 5| Step: 5
Training loss: 4.618623616679414
Validation loss: 5.559094232445683

Epoch: 5| Step: 6
Training loss: 6.13932774942369
Validation loss: 5.539188960193687

Epoch: 5| Step: 7
Training loss: 6.598197702489869
Validation loss: 5.517993824441752

Epoch: 5| Step: 8
Training loss: 5.518196695138308
Validation loss: 5.4954924696744865

Epoch: 5| Step: 9
Training loss: 5.977063525771939
Validation loss: 5.472274103261075

Epoch: 5| Step: 10
Training loss: 5.690027367068482
Validation loss: 5.447017933025473

Epoch: 3| Step: 0
Training loss: 6.178105476128578
Validation loss: 5.421933994088698

Epoch: 5| Step: 1
Training loss: 4.547454482443718
Validation loss: 5.394956462936515

Epoch: 5| Step: 2
Training loss: 4.633409021065822
Validation loss: 5.369036663902456

Epoch: 5| Step: 3
Training loss: 5.466929977557477
Validation loss: 5.341968062006573

Epoch: 5| Step: 4
Training loss: 6.304989113855002
Validation loss: 5.315493137764905

Epoch: 5| Step: 5
Training loss: 4.9427057178464935
Validation loss: 5.288932135729655

Epoch: 5| Step: 6
Training loss: 4.858594040503388
Validation loss: 5.262321252953447

Epoch: 5| Step: 7
Training loss: 6.125909854495914
Validation loss: 5.236350788934085

Epoch: 5| Step: 8
Training loss: 4.334346995026012
Validation loss: 5.208768000359133

Epoch: 5| Step: 9
Training loss: 5.657490125403929
Validation loss: 5.182277924751378

Epoch: 5| Step: 10
Training loss: 5.2315762909156645
Validation loss: 5.15595951697727

Epoch: 4| Step: 0
Training loss: 5.810595784983227
Validation loss: 5.129367894909246

Epoch: 5| Step: 1
Training loss: 5.12816243178371
Validation loss: 5.103239045556944

Epoch: 5| Step: 2
Training loss: 4.501454012462902
Validation loss: 5.077857807409232

Epoch: 5| Step: 3
Training loss: 5.588293899016248
Validation loss: 5.053063179025706

Epoch: 5| Step: 4
Training loss: 5.645395222049096
Validation loss: 5.026925157999055

Epoch: 5| Step: 5
Training loss: 4.320269455100324
Validation loss: 4.999557610906602

Epoch: 5| Step: 6
Training loss: 5.020468206570339
Validation loss: 4.973461061796161

Epoch: 5| Step: 7
Training loss: 4.659421314441701
Validation loss: 4.945366425550607

Epoch: 5| Step: 8
Training loss: 5.013776492018174
Validation loss: 4.916024899124725

Epoch: 5| Step: 9
Training loss: 4.659520581514856
Validation loss: 4.885900472649853

Epoch: 5| Step: 10
Training loss: 5.220132062271854
Validation loss: 4.8593097797532065

Epoch: 5| Step: 0
Training loss: 4.621290214018971
Validation loss: 4.831924900875463

Epoch: 5| Step: 1
Training loss: 5.64115653875396
Validation loss: 4.809494880837234

Epoch: 5| Step: 2
Training loss: 5.811549939681841
Validation loss: 4.788399932207895

Epoch: 5| Step: 3
Training loss: 5.337014040835036
Validation loss: 4.76709046622911

Epoch: 5| Step: 4
Training loss: 5.0925995633369805
Validation loss: 4.747031148136809

Epoch: 5| Step: 5
Training loss: 3.79976578542795
Validation loss: 4.72618151418878

Epoch: 5| Step: 6
Training loss: 3.1860234449617133
Validation loss: 4.70621603314927

Epoch: 5| Step: 7
Training loss: 4.678302540847085
Validation loss: 4.689138048332661

Epoch: 5| Step: 8
Training loss: 4.776593103332614
Validation loss: 4.673371373910972

Epoch: 5| Step: 9
Training loss: 4.233934217645639
Validation loss: 4.6567204495068415

Epoch: 5| Step: 10
Training loss: 5.266048244592892
Validation loss: 4.639396705183505

Epoch: 6| Step: 0
Training loss: 5.289646313675357
Validation loss: 4.619292351669071

Epoch: 5| Step: 1
Training loss: 4.545494892634874
Validation loss: 4.598037188028398

Epoch: 5| Step: 2
Training loss: 5.31207489107952
Validation loss: 4.576155595119912

Epoch: 5| Step: 3
Training loss: 4.288725848439857
Validation loss: 4.558001754170203

Epoch: 5| Step: 4
Training loss: 4.866559865293486
Validation loss: 4.542024101438549

Epoch: 5| Step: 5
Training loss: 4.6431312857377485
Validation loss: 4.52677897748675

Epoch: 5| Step: 6
Training loss: 4.778870033874031
Validation loss: 4.509886699443235

Epoch: 5| Step: 7
Training loss: 3.8846724601149436
Validation loss: 4.497334804223319

Epoch: 5| Step: 8
Training loss: 3.6413545982562177
Validation loss: 4.484201927656931

Epoch: 5| Step: 9
Training loss: 4.872364994877801
Validation loss: 4.473753568598719

Epoch: 5| Step: 10
Training loss: 4.59707894667026
Validation loss: 4.45876052982569

Epoch: 7| Step: 0
Training loss: 5.214007204086659
Validation loss: 4.443372903537541

Epoch: 5| Step: 1
Training loss: 4.882294113107563
Validation loss: 4.4223394378661105

Epoch: 5| Step: 2
Training loss: 3.0280850591869752
Validation loss: 4.410599641607627

Epoch: 5| Step: 3
Training loss: 4.151680865626568
Validation loss: 4.4049468721864535

Epoch: 5| Step: 4
Training loss: 4.186536535763566
Validation loss: 4.39606127692033

Epoch: 5| Step: 5
Training loss: 4.7685207886812195
Validation loss: 4.383518952519082

Epoch: 5| Step: 6
Training loss: 4.851376933850521
Validation loss: 4.373177399829193

Epoch: 5| Step: 7
Training loss: 4.60162343112779
Validation loss: 4.360317982562015

Epoch: 5| Step: 8
Training loss: 3.701684212766854
Validation loss: 4.3457609726992805

Epoch: 5| Step: 9
Training loss: 5.570888238073746
Validation loss: 4.335166197241719

Epoch: 5| Step: 10
Training loss: 3.821956600587571
Validation loss: 4.323733683282598

Epoch: 8| Step: 0
Training loss: 4.779656437613596
Validation loss: 4.31415863741144

Epoch: 5| Step: 1
Training loss: 4.858380869157934
Validation loss: 4.303566431101386

Epoch: 5| Step: 2
Training loss: 4.942021870619123
Validation loss: 4.292065152812401

Epoch: 5| Step: 3
Training loss: 4.269001166130187
Validation loss: 4.282335010199787

Epoch: 5| Step: 4
Training loss: 3.762281144072497
Validation loss: 4.27530528999809

Epoch: 5| Step: 5
Training loss: 4.3146569206904175
Validation loss: 4.271514237232045

Epoch: 5| Step: 6
Training loss: 4.0273496699914055
Validation loss: 4.259034299465446

Epoch: 5| Step: 7
Training loss: 3.831092400599807
Validation loss: 4.2516392725913335

Epoch: 5| Step: 8
Training loss: 4.791963031836361
Validation loss: 4.2536110493774615

Epoch: 5| Step: 9
Training loss: 4.698367529279244
Validation loss: 4.246395948732409

Epoch: 5| Step: 10
Training loss: 3.8016434227749745
Validation loss: 4.239227304563501

Epoch: 9| Step: 0
Training loss: 5.007461130845522
Validation loss: 4.227658965909447

Epoch: 5| Step: 1
Training loss: 4.572862536458291
Validation loss: 4.218709868768515

Epoch: 5| Step: 2
Training loss: 4.685013582093898
Validation loss: 4.213544763163148

Epoch: 5| Step: 3
Training loss: 4.366708145721125
Validation loss: 4.2056622958723775

Epoch: 5| Step: 4
Training loss: 2.770624157651381
Validation loss: 4.1993527584151344

Epoch: 5| Step: 5
Training loss: 3.570812365642104
Validation loss: 4.191367921882485

Epoch: 5| Step: 6
Training loss: 5.073230814622719
Validation loss: 4.187023991048055

Epoch: 5| Step: 7
Training loss: 3.9206303905107633
Validation loss: 4.179000175728344

Epoch: 5| Step: 8
Training loss: 4.625844929815229
Validation loss: 4.177175023357322

Epoch: 5| Step: 9
Training loss: 4.230647512165529
Validation loss: 4.16875974361258

Epoch: 5| Step: 10
Training loss: 4.286793037161583
Validation loss: 4.15947407558965

Epoch: 10| Step: 0
Training loss: 4.337700892476655
Validation loss: 4.155535912695339

Epoch: 5| Step: 1
Training loss: 5.009041621965329
Validation loss: 4.1475994651850305

Epoch: 5| Step: 2
Training loss: 3.8726176660342126
Validation loss: 4.14030442857238

Epoch: 5| Step: 3
Training loss: 4.06462299921314
Validation loss: 4.131568983228651

Epoch: 5| Step: 4
Training loss: 4.093140068917664
Validation loss: 4.123360781412171

Epoch: 5| Step: 5
Training loss: 4.614591691789599
Validation loss: 4.112815347288034

Epoch: 5| Step: 6
Training loss: 3.887599274082236
Validation loss: 4.101759340374748

Epoch: 5| Step: 7
Training loss: 3.0696306320805484
Validation loss: 4.0888753394943755

Epoch: 5| Step: 8
Training loss: 4.547088932628267
Validation loss: 4.07102895916917

Epoch: 5| Step: 9
Training loss: 4.748294724994454
Validation loss: 4.050294255857487

Epoch: 5| Step: 10
Training loss: 4.155493645935011
Validation loss: 4.013986218575788

Epoch: 11| Step: 0
Training loss: 4.88727023079734
Validation loss: 3.971083457861313

Epoch: 5| Step: 1
Training loss: 3.9044334154932785
Validation loss: 3.9550695766658914

Epoch: 5| Step: 2
Training loss: 4.607481693722005
Validation loss: 3.951845640955195

Epoch: 5| Step: 3
Training loss: 4.370021930700656
Validation loss: 3.957265495904317

Epoch: 5| Step: 4
Training loss: 3.730094723150708
Validation loss: 3.951188100918639

Epoch: 5| Step: 5
Training loss: 3.834085736171273
Validation loss: 3.943499194248416

Epoch: 5| Step: 6
Training loss: 4.426754042402707
Validation loss: 3.9341814282976166

Epoch: 5| Step: 7
Training loss: 3.441869836557123
Validation loss: 3.927357541533797

Epoch: 5| Step: 8
Training loss: 3.3947534696933617
Validation loss: 3.9218052310945253

Epoch: 5| Step: 9
Training loss: 3.640833116075738
Validation loss: 3.9141190782495365

Epoch: 5| Step: 10
Training loss: 4.584228405107061
Validation loss: 3.903150610121887

Epoch: 12| Step: 0
Training loss: 4.44674171575061
Validation loss: 3.891735053132954

Epoch: 5| Step: 1
Training loss: 4.192851731906574
Validation loss: 3.8825196295427546

Epoch: 5| Step: 2
Training loss: 3.741208388393154
Validation loss: 3.8739106681172304

Epoch: 5| Step: 3
Training loss: 2.486165103527332
Validation loss: 3.863521148135512

Epoch: 5| Step: 4
Training loss: 4.971224378673741
Validation loss: 3.859966024076807

Epoch: 5| Step: 5
Training loss: 4.405072426866271
Validation loss: 3.853638687930898

Epoch: 5| Step: 6
Training loss: 3.8565839180824155
Validation loss: 3.8517567335732346

Epoch: 5| Step: 7
Training loss: 4.125340303197725
Validation loss: 3.8482253443382834

Epoch: 5| Step: 8
Training loss: 3.8927991070302244
Validation loss: 3.8373496766860633

Epoch: 5| Step: 9
Training loss: 4.172832022062544
Validation loss: 3.832648727540452

Epoch: 5| Step: 10
Training loss: 3.378063365786895
Validation loss: 3.8272397593002885

Epoch: 13| Step: 0
Training loss: 4.295601284939039
Validation loss: 3.8249395574954543

Epoch: 5| Step: 1
Training loss: 3.665382391534596
Validation loss: 3.816968683718005

Epoch: 5| Step: 2
Training loss: 2.147532546448463
Validation loss: 3.8098654598568826

Epoch: 5| Step: 3
Training loss: 5.089787726631912
Validation loss: 3.801916191865101

Epoch: 5| Step: 4
Training loss: 4.069237858226792
Validation loss: 3.8024725165986633

Epoch: 5| Step: 5
Training loss: 4.444339692682714
Validation loss: 3.8022971993966057

Epoch: 5| Step: 6
Training loss: 3.1366511013389364
Validation loss: 3.793899660654991

Epoch: 5| Step: 7
Training loss: 3.998537750001067
Validation loss: 3.787739249216369

Epoch: 5| Step: 8
Training loss: 4.4406857942074645
Validation loss: 3.7795580369549295

Epoch: 5| Step: 9
Training loss: 4.074990657491448
Validation loss: 3.7747664692502867

Epoch: 5| Step: 10
Training loss: 3.48467455204982
Validation loss: 3.773139933897685

Epoch: 14| Step: 0
Training loss: 4.399038053611169
Validation loss: 3.7647550947608193

Epoch: 5| Step: 1
Training loss: 3.8499217533235486
Validation loss: 3.7600265781001707

Epoch: 5| Step: 2
Training loss: 4.051595754961382
Validation loss: 3.7599804735211237

Epoch: 5| Step: 3
Training loss: 3.2953463079202368
Validation loss: 3.7518823226897675

Epoch: 5| Step: 4
Training loss: 3.6994854388836576
Validation loss: 3.7452473867248535

Epoch: 5| Step: 5
Training loss: 3.8073335254766887
Validation loss: 3.7451141522979983

Epoch: 5| Step: 6
Training loss: 4.2802238626849025
Validation loss: 3.741382700814861

Epoch: 5| Step: 7
Training loss: 4.606832339614962
Validation loss: 3.7361836652360045

Epoch: 5| Step: 8
Training loss: 3.0355299789514176
Validation loss: 3.7304757293668525

Epoch: 5| Step: 9
Training loss: 4.694956634288709
Validation loss: 3.7293414754771375

Epoch: 5| Step: 10
Training loss: 2.864299265330365
Validation loss: 3.7252753895452098

Epoch: 15| Step: 0
Training loss: 4.027406738262277
Validation loss: 3.7209998687731685

Epoch: 5| Step: 1
Training loss: 4.640413940973273
Validation loss: 3.7099335635096766

Epoch: 5| Step: 2
Training loss: 3.746892786182634
Validation loss: 3.7106390962079385

Epoch: 5| Step: 3
Training loss: 4.066523276338995
Validation loss: 3.712228233676944

Epoch: 5| Step: 4
Training loss: 4.004973419139345
Validation loss: 3.7043323527729504

Epoch: 5| Step: 5
Training loss: 4.753000215375892
Validation loss: 3.6960180991638385

Epoch: 5| Step: 6
Training loss: 3.6202620751792205
Validation loss: 3.6975805194226825

Epoch: 5| Step: 7
Training loss: 3.5864355867484234
Validation loss: 3.6994221852246536

Epoch: 5| Step: 8
Training loss: 3.656425667479677
Validation loss: 3.688859780980003

Epoch: 5| Step: 9
Training loss: 3.392508691089267
Validation loss: 3.6807444409374908

Epoch: 5| Step: 10
Training loss: 2.714357796407416
Validation loss: 3.6795709596450896

Epoch: 16| Step: 0
Training loss: 3.5383477910363803
Validation loss: 3.679815660031048

Epoch: 5| Step: 1
Training loss: 3.611479702910048
Validation loss: 3.6779063020593075

Epoch: 5| Step: 2
Training loss: 3.500657428576949
Validation loss: 3.6682543314416454

Epoch: 5| Step: 3
Training loss: 4.013438063445271
Validation loss: 3.6613224624972993

Epoch: 5| Step: 4
Training loss: 3.566364802007918
Validation loss: 3.656042709623674

Epoch: 5| Step: 5
Training loss: 4.138834094567396
Validation loss: 3.656318975919327

Epoch: 5| Step: 6
Training loss: 2.8599142597924607
Validation loss: 3.6594935115822387

Epoch: 5| Step: 7
Training loss: 4.75923403595671
Validation loss: 3.667983339363173

Epoch: 5| Step: 8
Training loss: 3.8869977227928847
Validation loss: 3.6444272420604578

Epoch: 5| Step: 9
Training loss: 3.8963922245917293
Validation loss: 3.640172305008514

Epoch: 5| Step: 10
Training loss: 4.321542740611916
Validation loss: 3.6415845696189897

Epoch: 17| Step: 0
Training loss: 3.2012065818073565
Validation loss: 3.636923552453765

Epoch: 5| Step: 1
Training loss: 3.8195243287643112
Validation loss: 3.629535782177001

Epoch: 5| Step: 2
Training loss: 3.705357647106248
Validation loss: 3.6254248958817046

Epoch: 5| Step: 3
Training loss: 4.015071608117413
Validation loss: 3.623001288776843

Epoch: 5| Step: 4
Training loss: 4.630335436672327
Validation loss: 3.620443196451215

Epoch: 5| Step: 5
Training loss: 3.8212190578257386
Validation loss: 3.616234987163371

Epoch: 5| Step: 6
Training loss: 3.8123288976077543
Validation loss: 3.610465870886991

Epoch: 5| Step: 7
Training loss: 3.9672682992430333
Validation loss: 3.6035748892812176

Epoch: 5| Step: 8
Training loss: 4.007826301298118
Validation loss: 3.6011442283636788

Epoch: 5| Step: 9
Training loss: 3.2075202373957397
Validation loss: 3.5995529840122393

Epoch: 5| Step: 10
Training loss: 3.485635982589834
Validation loss: 3.595255709215457

Epoch: 18| Step: 0
Training loss: 3.8948772433601455
Validation loss: 3.588280776349472

Epoch: 5| Step: 1
Training loss: 3.5067244373634567
Validation loss: 3.586483587734289

Epoch: 5| Step: 2
Training loss: 3.2515786078446824
Validation loss: 3.5918135638351893

Epoch: 5| Step: 3
Training loss: 3.37654445772236
Validation loss: 3.5858156263628476

Epoch: 5| Step: 4
Training loss: 4.386401986211883
Validation loss: 3.5772656300176835

Epoch: 5| Step: 5
Training loss: 3.8621018386602155
Validation loss: 3.5787906646392456

Epoch: 5| Step: 6
Training loss: 3.598258863711832
Validation loss: 3.5743378947789215

Epoch: 5| Step: 7
Training loss: 4.1212608267376085
Validation loss: 3.5709849787195114

Epoch: 5| Step: 8
Training loss: 3.7316427410722306
Validation loss: 3.5656003631962645

Epoch: 5| Step: 9
Training loss: 4.158069871852096
Validation loss: 3.56297415956655

Epoch: 5| Step: 10
Training loss: 3.464235409355944
Validation loss: 3.557766342629276

Epoch: 19| Step: 0
Training loss: 4.0293851575550335
Validation loss: 3.5591412931411246

Epoch: 5| Step: 1
Training loss: 3.5049406330125454
Validation loss: 3.5552388651253266

Epoch: 5| Step: 2
Training loss: 3.882504364620391
Validation loss: 3.550883328291898

Epoch: 5| Step: 3
Training loss: 4.3760084897225715
Validation loss: 3.547030255919126

Epoch: 5| Step: 4
Training loss: 2.9405563362691183
Validation loss: 3.539964541704977

Epoch: 5| Step: 5
Training loss: 4.194491798071823
Validation loss: 3.5354755633364143

Epoch: 5| Step: 6
Training loss: 4.25215655196363
Validation loss: 3.5330234553262065

Epoch: 5| Step: 7
Training loss: 3.2424228077261144
Validation loss: 3.530170719680765

Epoch: 5| Step: 8
Training loss: 3.3293812847704727
Validation loss: 3.524768077976803

Epoch: 5| Step: 9
Training loss: 3.5240036875329874
Validation loss: 3.5217364927599517

Epoch: 5| Step: 10
Training loss: 3.657239470312669
Validation loss: 3.518111949796451

Epoch: 20| Step: 0
Training loss: 4.110412234680807
Validation loss: 3.5188205706161795

Epoch: 5| Step: 1
Training loss: 3.7901301502034146
Validation loss: 3.515665485691317

Epoch: 5| Step: 2
Training loss: 3.4347106714016298
Validation loss: 3.5103435701666736

Epoch: 5| Step: 3
Training loss: 3.7219519414243463
Validation loss: 3.505953226059555

Epoch: 5| Step: 4
Training loss: 3.3021703923218073
Validation loss: 3.501288406854907

Epoch: 5| Step: 5
Training loss: 3.8906981679631607
Validation loss: 3.5023820845629494

Epoch: 5| Step: 6
Training loss: 3.227731857658918
Validation loss: 3.49866798942795

Epoch: 5| Step: 7
Training loss: 3.3744095179796627
Validation loss: 3.495060342871632

Epoch: 5| Step: 8
Training loss: 3.6929866253682704
Validation loss: 3.490566283581264

Epoch: 5| Step: 9
Training loss: 4.116668842227583
Validation loss: 3.4884120150166713

Epoch: 5| Step: 10
Training loss: 4.12626073817971
Validation loss: 3.489090457515836

Epoch: 21| Step: 0
Training loss: 4.292859896111971
Validation loss: 3.481448455336469

Epoch: 5| Step: 1
Training loss: 3.6156693438528293
Validation loss: 3.4757284917473688

Epoch: 5| Step: 2
Training loss: 4.02873257833579
Validation loss: 3.4814098883836415

Epoch: 5| Step: 3
Training loss: 3.8294652966985043
Validation loss: 3.470654945372211

Epoch: 5| Step: 4
Training loss: 3.2847850830285705
Validation loss: 3.466485476156369

Epoch: 5| Step: 5
Training loss: 3.6877118065990833
Validation loss: 3.476621677862406

Epoch: 5| Step: 6
Training loss: 3.142382229803694
Validation loss: 3.467719912047682

Epoch: 5| Step: 7
Training loss: 3.681941223015214
Validation loss: 3.4598645377352506

Epoch: 5| Step: 8
Training loss: 3.692452676995412
Validation loss: 3.4580131962772533

Epoch: 5| Step: 9
Training loss: 3.783649912513237
Validation loss: 3.4520410126168426

Epoch: 5| Step: 10
Training loss: 3.2780528159689903
Validation loss: 3.4465977651588937

Epoch: 22| Step: 0
Training loss: 4.28529378553783
Validation loss: 3.4435466845027562

Epoch: 5| Step: 1
Training loss: 3.5121146754353285
Validation loss: 3.437763655200943

Epoch: 5| Step: 2
Training loss: 3.9833098539886778
Validation loss: 3.4359145803206173

Epoch: 5| Step: 3
Training loss: 3.29550836812136
Validation loss: 3.4320104131063762

Epoch: 5| Step: 4
Training loss: 3.2066113363186113
Validation loss: 3.4314810164520115

Epoch: 5| Step: 5
Training loss: 2.8348648943320405
Validation loss: 3.4275195667014136

Epoch: 5| Step: 6
Training loss: 3.922448591256462
Validation loss: 3.4224959307522607

Epoch: 5| Step: 7
Training loss: 3.632968562886067
Validation loss: 3.4186248605218807

Epoch: 5| Step: 8
Training loss: 3.4507824991684686
Validation loss: 3.41519734512751

Epoch: 5| Step: 9
Training loss: 4.23096511760804
Validation loss: 3.410845478653035

Epoch: 5| Step: 10
Training loss: 3.476435215366543
Validation loss: 3.402809204755596

Epoch: 23| Step: 0
Training loss: 3.431236803484556
Validation loss: 3.403760099535629

Epoch: 5| Step: 1
Training loss: 3.3565372280202608
Validation loss: 3.400603701748864

Epoch: 5| Step: 2
Training loss: 3.0834159496339497
Validation loss: 3.396856076337949

Epoch: 5| Step: 3
Training loss: 4.384666445147804
Validation loss: 3.391214574178992

Epoch: 5| Step: 4
Training loss: 3.4306744869344183
Validation loss: 3.3868248238993157

Epoch: 5| Step: 5
Training loss: 3.28422803613497
Validation loss: 3.388802919037603

Epoch: 5| Step: 6
Training loss: 3.9070403253228307
Validation loss: 3.3856975707076487

Epoch: 5| Step: 7
Training loss: 3.75305051705859
Validation loss: 3.3771879866216286

Epoch: 5| Step: 8
Training loss: 2.945592406554124
Validation loss: 3.3720586980312

Epoch: 5| Step: 9
Training loss: 3.8900780963658295
Validation loss: 3.3727407531422045

Epoch: 5| Step: 10
Training loss: 4.124314222262299
Validation loss: 3.369269783834096

Epoch: 24| Step: 0
Training loss: 2.7182015929194354
Validation loss: 3.367153129005355

Epoch: 5| Step: 1
Training loss: 2.9473863176290074
Validation loss: 3.3754427629677424

Epoch: 5| Step: 2
Training loss: 3.48245994046428
Validation loss: 3.372704749767101

Epoch: 5| Step: 3
Training loss: 3.8115303182185523
Validation loss: 3.361326785721689

Epoch: 5| Step: 4
Training loss: 4.333814056336791
Validation loss: 3.3544042726428795

Epoch: 5| Step: 5
Training loss: 3.7552311332670074
Validation loss: 3.3528224784325147

Epoch: 5| Step: 6
Training loss: 3.7359654060575544
Validation loss: 3.355301428804473

Epoch: 5| Step: 7
Training loss: 3.454264871254266
Validation loss: 3.3508065667700344

Epoch: 5| Step: 8
Training loss: 3.6043642610985605
Validation loss: 3.341639589826979

Epoch: 5| Step: 9
Training loss: 3.569004478667686
Validation loss: 3.3370015316136854

Epoch: 5| Step: 10
Training loss: 3.8347139912852035
Validation loss: 3.3319531972704457

Epoch: 25| Step: 0
Training loss: 2.9473829201829265
Validation loss: 3.33570543353126

Epoch: 5| Step: 1
Training loss: 3.0938862471971564
Validation loss: 3.334456547312935

Epoch: 5| Step: 2
Training loss: 3.145780516595802
Validation loss: 3.3291241716730933

Epoch: 5| Step: 3
Training loss: 3.893742671855564
Validation loss: 3.323100655299006

Epoch: 5| Step: 4
Training loss: 3.5872814842957057
Validation loss: 3.317730945452083

Epoch: 5| Step: 5
Training loss: 3.918435339941909
Validation loss: 3.3162163945177086

Epoch: 5| Step: 6
Training loss: 4.120498975889053
Validation loss: 3.3113497723923007

Epoch: 5| Step: 7
Training loss: 3.830471643037927
Validation loss: 3.307799287144641

Epoch: 5| Step: 8
Training loss: 3.86124192770191
Validation loss: 3.3091769864407086

Epoch: 5| Step: 9
Training loss: 3.0566908567158495
Validation loss: 3.3202913426226415

Epoch: 5| Step: 10
Training loss: 3.4094654270561264
Validation loss: 3.3150367937155956

Epoch: 26| Step: 0
Training loss: 3.158726391117222
Validation loss: 3.3004327910374047

Epoch: 5| Step: 1
Training loss: 3.8264684713079844
Validation loss: 3.3111916355617077

Epoch: 5| Step: 2
Training loss: 3.701262830759037
Validation loss: 3.310727842476747

Epoch: 5| Step: 3
Training loss: 4.294036704629238
Validation loss: 3.3024445831698657

Epoch: 5| Step: 4
Training loss: 2.8294064479636574
Validation loss: 3.298447618446486

Epoch: 5| Step: 5
Training loss: 3.524725904697707
Validation loss: 3.2934087134036933

Epoch: 5| Step: 6
Training loss: 3.2226029825143145
Validation loss: 3.2939362345273135

Epoch: 5| Step: 7
Training loss: 3.2989502653250744
Validation loss: 3.293451884048507

Epoch: 5| Step: 8
Training loss: 2.9972481822422696
Validation loss: 3.290903876633478

Epoch: 5| Step: 9
Training loss: 4.105301495165847
Validation loss: 3.2803384580234964

Epoch: 5| Step: 10
Training loss: 3.7373060909734104
Validation loss: 3.2758462924151934

Epoch: 27| Step: 0
Training loss: 3.6484358009481457
Validation loss: 3.278204623206646

Epoch: 5| Step: 1
Training loss: 2.9771984151954642
Validation loss: 3.274921902700191

Epoch: 5| Step: 2
Training loss: 3.393951893345824
Validation loss: 3.2674113817793065

Epoch: 5| Step: 3
Training loss: 3.6545137374688625
Validation loss: 3.2658847478463837

Epoch: 5| Step: 4
Training loss: 3.9126424745206214
Validation loss: 3.262224142145308

Epoch: 5| Step: 5
Training loss: 4.232035648765482
Validation loss: 3.257697983688962

Epoch: 5| Step: 6
Training loss: 3.772031660390043
Validation loss: 3.2547350278598097

Epoch: 5| Step: 7
Training loss: 3.927874956692873
Validation loss: 3.25033891139735

Epoch: 5| Step: 8
Training loss: 2.7270437433464467
Validation loss: 3.2446194418042875

Epoch: 5| Step: 9
Training loss: 2.7250029467645516
Validation loss: 3.240842978633624

Epoch: 5| Step: 10
Training loss: 3.208621784140678
Validation loss: 3.23927885334717

Epoch: 28| Step: 0
Training loss: 3.8267244229183737
Validation loss: 3.2352913708708346

Epoch: 5| Step: 1
Training loss: 3.6690509731175664
Validation loss: 3.234851567630065

Epoch: 5| Step: 2
Training loss: 3.3119068694358553
Validation loss: 3.232667121423057

Epoch: 5| Step: 3
Training loss: 3.51296204484068
Validation loss: 3.2317296662165726

Epoch: 5| Step: 4
Training loss: 3.2808318825401126
Validation loss: 3.2322325258406828

Epoch: 5| Step: 5
Training loss: 3.3368187484101095
Validation loss: 3.2319943155089255

Epoch: 5| Step: 6
Training loss: 3.4280570984116796
Validation loss: 3.2492767930256417

Epoch: 5| Step: 7
Training loss: 3.4284145625877667
Validation loss: 3.2176889434261997

Epoch: 5| Step: 8
Training loss: 3.444668871906988
Validation loss: 3.2224587756299012

Epoch: 5| Step: 9
Training loss: 3.815962423015613
Validation loss: 3.2211936406464328

Epoch: 5| Step: 10
Training loss: 3.1428160355096573
Validation loss: 3.2165285021398855

Epoch: 29| Step: 0
Training loss: 3.2708781212981948
Validation loss: 3.2103312972314173

Epoch: 5| Step: 1
Training loss: 3.7057539866892517
Validation loss: 3.2113196308251424

Epoch: 5| Step: 2
Training loss: 3.53490589583129
Validation loss: 3.2089418815091273

Epoch: 5| Step: 3
Training loss: 3.8416023767571206
Validation loss: 3.209221228953158

Epoch: 5| Step: 4
Training loss: 2.5405837915510854
Validation loss: 3.2117855025203754

Epoch: 5| Step: 5
Training loss: 3.2583320624177476
Validation loss: 3.2153372373306834

Epoch: 5| Step: 6
Training loss: 3.7062562990697945
Validation loss: 3.219424036888396

Epoch: 5| Step: 7
Training loss: 3.0139837196381225
Validation loss: 3.2095065971405257

Epoch: 5| Step: 8
Training loss: 3.5254871978635527
Validation loss: 3.2109601395990532

Epoch: 5| Step: 9
Training loss: 3.6940053680496576
Validation loss: 3.2043208409373745

Epoch: 5| Step: 10
Training loss: 3.9336739979866815
Validation loss: 3.1957784221204832

Epoch: 30| Step: 0
Training loss: 3.197869879331665
Validation loss: 3.195158835722047

Epoch: 5| Step: 1
Training loss: 3.650130146789423
Validation loss: 3.196503207437228

Epoch: 5| Step: 2
Training loss: 3.8477329614418303
Validation loss: 3.197708705660263

Epoch: 5| Step: 3
Training loss: 4.6372512215979755
Validation loss: 3.1918298876904765

Epoch: 5| Step: 4
Training loss: 2.966743996144539
Validation loss: 3.1849903615903994

Epoch: 5| Step: 5
Training loss: 3.0785181404435544
Validation loss: 3.1832156614814173

Epoch: 5| Step: 6
Training loss: 3.3788893153477364
Validation loss: 3.183336715543969

Epoch: 5| Step: 7
Training loss: 2.923634045516725
Validation loss: 3.1859483507188826

Epoch: 5| Step: 8
Training loss: 3.4059187701804317
Validation loss: 3.18638697089472

Epoch: 5| Step: 9
Training loss: 2.6428179240906893
Validation loss: 3.187581736260422

Epoch: 5| Step: 10
Training loss: 3.843098158731
Validation loss: 3.187818848669526

Epoch: 31| Step: 0
Training loss: 4.21580888871657
Validation loss: 3.1806203620588

Epoch: 5| Step: 1
Training loss: 3.3135121076876977
Validation loss: 3.1772346147212094

Epoch: 5| Step: 2
Training loss: 3.460834441362022
Validation loss: 3.1729551535422695

Epoch: 5| Step: 3
Training loss: 3.1589673119786177
Validation loss: 3.1816830165881296

Epoch: 5| Step: 4
Training loss: 3.1141033164190346
Validation loss: 3.2121097157642207

Epoch: 5| Step: 5
Training loss: 3.833442824638253
Validation loss: 3.2470241644817732

Epoch: 5| Step: 6
Training loss: 2.669912052206236
Validation loss: 3.173799254482524

Epoch: 5| Step: 7
Training loss: 4.002197139034666
Validation loss: 3.187027315676794

Epoch: 5| Step: 8
Training loss: 3.6598141244685065
Validation loss: 3.203617959015098

Epoch: 5| Step: 9
Training loss: 3.287271696220583
Validation loss: 3.2406833504789057

Epoch: 5| Step: 10
Training loss: 3.0082340093755295
Validation loss: 3.2243374368327338

Epoch: 32| Step: 0
Training loss: 3.412120834357546
Validation loss: 3.21741213912488

Epoch: 5| Step: 1
Training loss: 3.8860407405647592
Validation loss: 3.211218449349106

Epoch: 5| Step: 2
Training loss: 2.5165664143415225
Validation loss: 3.1980345191468826

Epoch: 5| Step: 3
Training loss: 3.526757817908221
Validation loss: 3.1973869561351393

Epoch: 5| Step: 4
Training loss: 3.059989367198547
Validation loss: 3.1954060483219417

Epoch: 5| Step: 5
Training loss: 4.364009895376426
Validation loss: 3.195707967678833

Epoch: 5| Step: 6
Training loss: 3.160635139761364
Validation loss: 3.191712480274765

Epoch: 5| Step: 7
Training loss: 3.2765757373547877
Validation loss: 3.189551973181026

Epoch: 5| Step: 8
Training loss: 3.4910225856097385
Validation loss: 3.1887973796805253

Epoch: 5| Step: 9
Training loss: 3.6517563291400688
Validation loss: 3.1898505905388364

Epoch: 5| Step: 10
Training loss: 3.357684326565741
Validation loss: 3.1763782178030957

Epoch: 33| Step: 0
Training loss: 3.039346480646612
Validation loss: 3.171121230196581

Epoch: 5| Step: 1
Training loss: 3.063580692115762
Validation loss: 3.1745210476726253

Epoch: 5| Step: 2
Training loss: 4.318812518626494
Validation loss: 3.1761354406488875

Epoch: 5| Step: 3
Training loss: 3.7054701192050232
Validation loss: 3.176445664445596

Epoch: 5| Step: 4
Training loss: 3.3689252082401326
Validation loss: 3.169823094033652

Epoch: 5| Step: 5
Training loss: 3.8409257142526494
Validation loss: 3.1683835835460057

Epoch: 5| Step: 6
Training loss: 3.3743657116551034
Validation loss: 3.161449349580453

Epoch: 5| Step: 7
Training loss: 3.0734572285347204
Validation loss: 3.1581777596383978

Epoch: 5| Step: 8
Training loss: 2.6173491015290455
Validation loss: 3.1542325943023037

Epoch: 5| Step: 9
Training loss: 3.6058911440853514
Validation loss: 3.154611282936608

Epoch: 5| Step: 10
Training loss: 3.4501165342690414
Validation loss: 3.151933799455256

Epoch: 34| Step: 0
Training loss: 2.500253473783509
Validation loss: 3.1510800508367955

Epoch: 5| Step: 1
Training loss: 3.156190777213565
Validation loss: 3.1470465067158515

Epoch: 5| Step: 2
Training loss: 3.02350279271795
Validation loss: 3.1463729247854912

Epoch: 5| Step: 3
Training loss: 4.107916859737265
Validation loss: 3.145321860998737

Epoch: 5| Step: 4
Training loss: 3.118973681545241
Validation loss: 3.1426463802585967

Epoch: 5| Step: 5
Training loss: 2.849801300885521
Validation loss: 3.1436300172573595

Epoch: 5| Step: 6
Training loss: 3.910257953613028
Validation loss: 3.1408323618364427

Epoch: 5| Step: 7
Training loss: 2.7627390658816626
Validation loss: 3.13922704648425

Epoch: 5| Step: 8
Training loss: 3.981282069677425
Validation loss: 3.1397165580336686

Epoch: 5| Step: 9
Training loss: 3.6676844282525973
Validation loss: 3.1392200102450287

Epoch: 5| Step: 10
Training loss: 4.093619075166663
Validation loss: 3.137886191459667

Epoch: 35| Step: 0
Training loss: 3.6270876167764334
Validation loss: 3.136342890382767

Epoch: 5| Step: 1
Training loss: 3.2380985075001814
Validation loss: 3.136946145710481

Epoch: 5| Step: 2
Training loss: 3.500268380910715
Validation loss: 3.134381201593409

Epoch: 5| Step: 3
Training loss: 3.43943454752578
Validation loss: 3.1331471043106003

Epoch: 5| Step: 4
Training loss: 4.010693561193235
Validation loss: 3.130483742182649

Epoch: 5| Step: 5
Training loss: 2.9808496554294592
Validation loss: 3.129550254439078

Epoch: 5| Step: 6
Training loss: 3.164913712902712
Validation loss: 3.1301320223508324

Epoch: 5| Step: 7
Training loss: 2.968440953280903
Validation loss: 3.1276328409219025

Epoch: 5| Step: 8
Training loss: 3.70947339538832
Validation loss: 3.1265585116050176

Epoch: 5| Step: 9
Training loss: 3.274237268750943
Validation loss: 3.1260075542548753

Epoch: 5| Step: 10
Training loss: 3.3948635908765437
Validation loss: 3.124894187530462

Epoch: 36| Step: 0
Training loss: 3.2750541682532024
Validation loss: 3.1226835471947045

Epoch: 5| Step: 1
Training loss: 2.8587162113569784
Validation loss: 3.1211158207180993

Epoch: 5| Step: 2
Training loss: 3.060331394227213
Validation loss: 3.1216028555423936

Epoch: 5| Step: 3
Training loss: 3.4890638885290284
Validation loss: 3.1209031730832946

Epoch: 5| Step: 4
Training loss: 3.2802974226478723
Validation loss: 3.121047088029051

Epoch: 5| Step: 5
Training loss: 2.5357264742951684
Validation loss: 3.1186191905008327

Epoch: 5| Step: 6
Training loss: 3.1208957423110117
Validation loss: 3.118899997782811

Epoch: 5| Step: 7
Training loss: 3.380221530945361
Validation loss: 3.1212532158475548

Epoch: 5| Step: 8
Training loss: 4.506126048675595
Validation loss: 3.1156600016924587

Epoch: 5| Step: 9
Training loss: 3.8337932117316686
Validation loss: 3.1173100630004815

Epoch: 5| Step: 10
Training loss: 3.6437364633612996
Validation loss: 3.1162892094675483

Epoch: 37| Step: 0
Training loss: 2.7203790453857217
Validation loss: 3.1154204436560127

Epoch: 5| Step: 1
Training loss: 2.4443166246615187
Validation loss: 3.1142827914208713

Epoch: 5| Step: 2
Training loss: 3.4951302847093246
Validation loss: 3.116158477300187

Epoch: 5| Step: 3
Training loss: 3.693252860499719
Validation loss: 3.113804891572449

Epoch: 5| Step: 4
Training loss: 3.530541002783974
Validation loss: 3.1122923499272357

Epoch: 5| Step: 5
Training loss: 3.8373527324637706
Validation loss: 3.11124588924812

Epoch: 5| Step: 6
Training loss: 3.6570522373756886
Validation loss: 3.111448433810774

Epoch: 5| Step: 7
Training loss: 3.0416027915901647
Validation loss: 3.1114247751647643

Epoch: 5| Step: 8
Training loss: 3.9324285150761584
Validation loss: 3.108950499329471

Epoch: 5| Step: 9
Training loss: 3.5191035037221723
Validation loss: 3.108720377107308

Epoch: 5| Step: 10
Training loss: 3.0207725431091546
Validation loss: 3.106355741895599

Epoch: 38| Step: 0
Training loss: 3.04595620411517
Validation loss: 3.106457161632478

Epoch: 5| Step: 1
Training loss: 3.8983608077767586
Validation loss: 3.106332206220138

Epoch: 5| Step: 2
Training loss: 3.61655613309886
Validation loss: 3.103444452228013

Epoch: 5| Step: 3
Training loss: 3.1976663365171207
Validation loss: 3.1046101419276217

Epoch: 5| Step: 4
Training loss: 2.891476562436674
Validation loss: 3.1030198747146063

Epoch: 5| Step: 5
Training loss: 3.724619872904057
Validation loss: 3.1043539687905763

Epoch: 5| Step: 6
Training loss: 3.2113515025453676
Validation loss: 3.101620658167443

Epoch: 5| Step: 7
Training loss: 4.014316211966642
Validation loss: 3.101106108735171

Epoch: 5| Step: 8
Training loss: 3.416376442717057
Validation loss: 3.0997356038072077

Epoch: 5| Step: 9
Training loss: 2.419507844865304
Validation loss: 3.0998636105239528

Epoch: 5| Step: 10
Training loss: 3.457397855296606
Validation loss: 3.097873595030905

Epoch: 39| Step: 0
Training loss: 3.3185509171194223
Validation loss: 3.0975657515558312

Epoch: 5| Step: 1
Training loss: 3.1414638936167103
Validation loss: 3.0948925939170775

Epoch: 5| Step: 2
Training loss: 3.335917488413338
Validation loss: 3.096640922359191

Epoch: 5| Step: 3
Training loss: 3.3978137616811526
Validation loss: 3.097338373182973

Epoch: 5| Step: 4
Training loss: 3.629638203858032
Validation loss: 3.098978567466676

Epoch: 5| Step: 5
Training loss: 2.9009357389678754
Validation loss: 3.0973430910209143

Epoch: 5| Step: 6
Training loss: 2.525488996839372
Validation loss: 3.093585854695369

Epoch: 5| Step: 7
Training loss: 3.5992355276734798
Validation loss: 3.0942567128820695

Epoch: 5| Step: 8
Training loss: 3.859433069448635
Validation loss: 3.087144741454152

Epoch: 5| Step: 9
Training loss: 3.729738173921636
Validation loss: 3.0858355196759644

Epoch: 5| Step: 10
Training loss: 3.482647112431721
Validation loss: 3.0819179348188586

Epoch: 40| Step: 0
Training loss: 3.9180567418692807
Validation loss: 3.079325595329697

Epoch: 5| Step: 1
Training loss: 3.084025348296928
Validation loss: 3.076569831396229

Epoch: 5| Step: 2
Training loss: 3.8544934245944305
Validation loss: 3.0752577056665378

Epoch: 5| Step: 3
Training loss: 3.342754322725074
Validation loss: 3.071733270572627

Epoch: 5| Step: 4
Training loss: 3.38467095402803
Validation loss: 3.0744348759542945

Epoch: 5| Step: 5
Training loss: 3.2156002596097126
Validation loss: 3.073946754550323

Epoch: 5| Step: 6
Training loss: 3.2280030810070817
Validation loss: 3.0676078223493377

Epoch: 5| Step: 7
Training loss: 3.2995584423694964
Validation loss: 3.069000447249174

Epoch: 5| Step: 8
Training loss: 3.156946237651873
Validation loss: 3.0642735391720612

Epoch: 5| Step: 9
Training loss: 3.4108641284105743
Validation loss: 3.0670910932351

Epoch: 5| Step: 10
Training loss: 2.7922278642004983
Validation loss: 3.070626411963896

Epoch: 41| Step: 0
Training loss: 2.990909472800423
Validation loss: 3.06404268453592

Epoch: 5| Step: 1
Training loss: 3.6481313965038633
Validation loss: 3.0619133895379305

Epoch: 5| Step: 2
Training loss: 3.621632425843004
Validation loss: 3.0612788977296823

Epoch: 5| Step: 3
Training loss: 3.3920976807006955
Validation loss: 3.06085070091908

Epoch: 5| Step: 4
Training loss: 3.759828403493737
Validation loss: 3.0602130433107546

Epoch: 5| Step: 5
Training loss: 3.003646065465183
Validation loss: 3.060116363237547

Epoch: 5| Step: 6
Training loss: 2.581594456187544
Validation loss: 3.059256883393446

Epoch: 5| Step: 7
Training loss: 2.685984783189153
Validation loss: 3.055693426654331

Epoch: 5| Step: 8
Training loss: 3.9931068630884328
Validation loss: 3.0600185105607545

Epoch: 5| Step: 9
Training loss: 3.398124733048359
Validation loss: 3.0635259155957955

Epoch: 5| Step: 10
Training loss: 3.4679037900556757
Validation loss: 3.0640721993177973

Epoch: 42| Step: 0
Training loss: 3.1495347300042478
Validation loss: 3.085202252385962

Epoch: 5| Step: 1
Training loss: 3.182980193943887
Validation loss: 3.0944784928192712

Epoch: 5| Step: 2
Training loss: 3.8830023552206887
Validation loss: 3.05334627090669

Epoch: 5| Step: 3
Training loss: 2.681494990184627
Validation loss: 3.0550035629411463

Epoch: 5| Step: 4
Training loss: 3.9340114580073857
Validation loss: 3.0731721038075763

Epoch: 5| Step: 5
Training loss: 2.8115149574377147
Validation loss: 3.0598761640591583

Epoch: 5| Step: 6
Training loss: 3.716695779136145
Validation loss: 3.062958712081906

Epoch: 5| Step: 7
Training loss: 3.529941687818224
Validation loss: 3.07553189413988

Epoch: 5| Step: 8
Training loss: 3.352420154732975
Validation loss: 3.0669307939638313

Epoch: 5| Step: 9
Training loss: 3.3696870310996294
Validation loss: 3.0634375529412

Epoch: 5| Step: 10
Training loss: 2.913785455947053
Validation loss: 3.0623225917665704

Epoch: 43| Step: 0
Training loss: 3.4574119228969296
Validation loss: 3.0623104211736614

Epoch: 5| Step: 1
Training loss: 3.631469478310318
Validation loss: 3.0618347456641803

Epoch: 5| Step: 2
Training loss: 3.2224233462240863
Validation loss: 3.0595303858891127

Epoch: 5| Step: 3
Training loss: 3.4381661896629865
Validation loss: 3.056416942436485

Epoch: 5| Step: 4
Training loss: 3.7797192714533834
Validation loss: 3.060954420695424

Epoch: 5| Step: 5
Training loss: 2.8982716638878614
Validation loss: 3.0519488280273572

Epoch: 5| Step: 6
Training loss: 3.560387905503934
Validation loss: 3.0465925188273784

Epoch: 5| Step: 7
Training loss: 2.9822851723029418
Validation loss: 3.044964089564349

Epoch: 5| Step: 8
Training loss: 3.757889395896584
Validation loss: 3.0471047515952567

Epoch: 5| Step: 9
Training loss: 3.1912662470725612
Validation loss: 3.0408817131923973

Epoch: 5| Step: 10
Training loss: 2.512671780763305
Validation loss: 3.0409932435478506

Epoch: 44| Step: 0
Training loss: 3.705197812461269
Validation loss: 3.041121484701403

Epoch: 5| Step: 1
Training loss: 3.629631109698708
Validation loss: 3.0480566231957638

Epoch: 5| Step: 2
Training loss: 3.6956642418978993
Validation loss: 3.0439956661242724

Epoch: 5| Step: 3
Training loss: 3.5443031969164775
Validation loss: 3.0414297039953957

Epoch: 5| Step: 4
Training loss: 2.9351563539725825
Validation loss: 3.0348990047301583

Epoch: 5| Step: 5
Training loss: 3.0367326999635367
Validation loss: 3.0335518525227507

Epoch: 5| Step: 6
Training loss: 3.092475397355968
Validation loss: 3.034039394500777

Epoch: 5| Step: 7
Training loss: 2.996739045719879
Validation loss: 3.035189474917528

Epoch: 5| Step: 8
Training loss: 3.0820781283566503
Validation loss: 3.0395165028990565

Epoch: 5| Step: 9
Training loss: 3.546427290972052
Validation loss: 3.037240439804686

Epoch: 5| Step: 10
Training loss: 3.235768041221335
Validation loss: 3.0396780395620357

Epoch: 45| Step: 0
Training loss: 2.9341778738740816
Validation loss: 3.0332804489889633

Epoch: 5| Step: 1
Training loss: 3.3415022095303764
Validation loss: 3.030482513963521

Epoch: 5| Step: 2
Training loss: 3.150063069030077
Validation loss: 3.0286007903746874

Epoch: 5| Step: 3
Training loss: 3.4299872404256
Validation loss: 3.0330349405460755

Epoch: 5| Step: 4
Training loss: 3.569171213923041
Validation loss: 3.0319307317938153

Epoch: 5| Step: 5
Training loss: 3.945742744176647
Validation loss: 3.027703383430766

Epoch: 5| Step: 6
Training loss: 3.3003179281425066
Validation loss: 3.0290772042824368

Epoch: 5| Step: 7
Training loss: 3.1928531350451705
Validation loss: 3.022786435717197

Epoch: 5| Step: 8
Training loss: 3.2036686133600827
Validation loss: 3.026436915021888

Epoch: 5| Step: 9
Training loss: 2.8197500243891698
Validation loss: 3.0295745182235883

Epoch: 5| Step: 10
Training loss: 3.5046505685017735
Validation loss: 3.031265827083086

Epoch: 46| Step: 0
Training loss: 3.793489681657741
Validation loss: 3.0274215234140343

Epoch: 5| Step: 1
Training loss: 3.160935050145028
Validation loss: 3.029866599670793

Epoch: 5| Step: 2
Training loss: 3.49254167710752
Validation loss: 3.0268083512969626

Epoch: 5| Step: 3
Training loss: 3.223653964874938
Validation loss: 3.0281015784123797

Epoch: 5| Step: 4
Training loss: 2.6910755413825695
Validation loss: 3.0258371621051974

Epoch: 5| Step: 5
Training loss: 2.787715811137238
Validation loss: 3.0267590211916855

Epoch: 5| Step: 6
Training loss: 3.780529237260537
Validation loss: 3.0288611334737396

Epoch: 5| Step: 7
Training loss: 2.6488095362598467
Validation loss: 3.0212200665472526

Epoch: 5| Step: 8
Training loss: 3.5507554660780025
Validation loss: 3.0220315703163574

Epoch: 5| Step: 9
Training loss: 3.3639483881199146
Validation loss: 3.02289396674822

Epoch: 5| Step: 10
Training loss: 3.7313130486814883
Validation loss: 3.02419556298411

Epoch: 47| Step: 0
Training loss: 2.940026029095289
Validation loss: 3.023820543372343

Epoch: 5| Step: 1
Training loss: 3.4826994147238532
Validation loss: 3.025536136139655

Epoch: 5| Step: 2
Training loss: 2.8795008051891497
Validation loss: 3.023172831458172

Epoch: 5| Step: 3
Training loss: 3.5530218560673648
Validation loss: 3.0234653939772853

Epoch: 5| Step: 4
Training loss: 2.655418624921103
Validation loss: 3.0195354696235115

Epoch: 5| Step: 5
Training loss: 3.274562888058362
Validation loss: 3.0173288222906764

Epoch: 5| Step: 6
Training loss: 3.7132196416063947
Validation loss: 3.015169357808

Epoch: 5| Step: 7
Training loss: 3.4328619445101367
Validation loss: 3.0172570252307107

Epoch: 5| Step: 8
Training loss: 3.4390692163563874
Validation loss: 3.018713021489784

Epoch: 5| Step: 9
Training loss: 3.8384558962690374
Validation loss: 3.0283750011722073

Epoch: 5| Step: 10
Training loss: 2.8769917430474123
Validation loss: 3.016552000892456

Epoch: 48| Step: 0
Training loss: 3.6687358017602842
Validation loss: 3.0152786806678633

Epoch: 5| Step: 1
Training loss: 2.7615317533602424
Validation loss: 3.013576407883606

Epoch: 5| Step: 2
Training loss: 3.636310034053384
Validation loss: 3.020315703165022

Epoch: 5| Step: 3
Training loss: 3.447925364011799
Validation loss: 3.030127502393671

Epoch: 5| Step: 4
Training loss: 3.115748788102
Validation loss: 3.0169062323233446

Epoch: 5| Step: 5
Training loss: 3.85370840836513
Validation loss: 3.012381564333574

Epoch: 5| Step: 6
Training loss: 3.0562989650306562
Validation loss: 3.010418640083841

Epoch: 5| Step: 7
Training loss: 3.054657528625345
Validation loss: 3.011633183969821

Epoch: 5| Step: 8
Training loss: 3.7167832759702613
Validation loss: 3.0133883605322747

Epoch: 5| Step: 9
Training loss: 3.1769930133592665
Validation loss: 3.014296067825536

Epoch: 5| Step: 10
Training loss: 2.366575054849175
Validation loss: 3.0151299774810636

Epoch: 49| Step: 0
Training loss: 3.7731962580995213
Validation loss: 3.01750124143017

Epoch: 5| Step: 1
Training loss: 3.2357979560651784
Validation loss: 3.015041613896258

Epoch: 5| Step: 2
Training loss: 3.1738697413136947
Validation loss: 3.009375971012144

Epoch: 5| Step: 3
Training loss: 3.3675553901948327
Validation loss: 3.010481505460917

Epoch: 5| Step: 4
Training loss: 3.6217760679805537
Validation loss: 3.0061415630509383

Epoch: 5| Step: 5
Training loss: 3.1182963375776516
Validation loss: 3.0052921180194443

Epoch: 5| Step: 6
Training loss: 2.5301518825129814
Validation loss: 3.0030456860982633

Epoch: 5| Step: 7
Training loss: 3.571311493725699
Validation loss: 3.002696097368066

Epoch: 5| Step: 8
Training loss: 3.445442733552248
Validation loss: 3.003864332362924

Epoch: 5| Step: 9
Training loss: 3.1650252019713476
Validation loss: 3.003816887132393

Epoch: 5| Step: 10
Training loss: 2.982708370735147
Validation loss: 3.004615477113193

Epoch: 50| Step: 0
Training loss: 2.969146059621227
Validation loss: 3.009376887639687

Epoch: 5| Step: 1
Training loss: 3.350514067877192
Validation loss: 3.0231464196370563

Epoch: 5| Step: 2
Training loss: 2.833343412343966
Validation loss: 3.023442823252669

Epoch: 5| Step: 3
Training loss: 2.334505184276492
Validation loss: 3.019753458220632

Epoch: 5| Step: 4
Training loss: 3.3098603293462814
Validation loss: 3.0121512332530997

Epoch: 5| Step: 5
Training loss: 3.73858762500086
Validation loss: 3.0057463848946355

Epoch: 5| Step: 6
Training loss: 3.364578687981547
Validation loss: 3.00022439220013

Epoch: 5| Step: 7
Training loss: 3.821482348604824
Validation loss: 3.0082728306014057

Epoch: 5| Step: 8
Training loss: 3.2822271436142003
Validation loss: 3.0215286241142887

Epoch: 5| Step: 9
Training loss: 3.52013748485659
Validation loss: 3.0102797945960273

Epoch: 5| Step: 10
Training loss: 3.414038756263974
Validation loss: 3.0052558037987533

Epoch: 51| Step: 0
Training loss: 3.6324095143588755
Validation loss: 3.00349880926494

Epoch: 5| Step: 1
Training loss: 3.0840160713717113
Validation loss: 3.0005136395395806

Epoch: 5| Step: 2
Training loss: 3.239365712468447
Validation loss: 3.0005099724499913

Epoch: 5| Step: 3
Training loss: 3.5766830537342997
Validation loss: 2.997290388275535

Epoch: 5| Step: 4
Training loss: 2.876258077266116
Validation loss: 3.0005258540256095

Epoch: 5| Step: 5
Training loss: 3.3209087240419555
Validation loss: 2.9993304595885726

Epoch: 5| Step: 6
Training loss: 3.480297765160287
Validation loss: 3.009050690314059

Epoch: 5| Step: 7
Training loss: 4.2460843167731
Validation loss: 3.012920602206992

Epoch: 5| Step: 8
Training loss: 2.767159591180813
Validation loss: 3.0030557603613803

Epoch: 5| Step: 9
Training loss: 2.93875695789573
Validation loss: 3.0139754179452836

Epoch: 5| Step: 10
Training loss: 2.6001297038077804
Validation loss: 3.029531284463369

Epoch: 52| Step: 0
Training loss: 3.2309468110505013
Validation loss: 3.041121897767383

Epoch: 5| Step: 1
Training loss: 2.9293201267058744
Validation loss: 3.0507870801530905

Epoch: 5| Step: 2
Training loss: 3.9091502904918283
Validation loss: 3.0525340662615066

Epoch: 5| Step: 3
Training loss: 3.1436299234744793
Validation loss: 3.0355609262882024

Epoch: 5| Step: 4
Training loss: 3.8618805817642285
Validation loss: 3.02746943704795

Epoch: 5| Step: 5
Training loss: 3.0967813148532017
Validation loss: 3.013396658737928

Epoch: 5| Step: 6
Training loss: 2.4446033753641503
Validation loss: 3.0009881702819534

Epoch: 5| Step: 7
Training loss: 3.3140620741063787
Validation loss: 2.999533745209054

Epoch: 5| Step: 8
Training loss: 3.0789556786325925
Validation loss: 3.0001132971039666

Epoch: 5| Step: 9
Training loss: 3.5532917342575003
Validation loss: 3.006767133267473

Epoch: 5| Step: 10
Training loss: 3.6114547484477013
Validation loss: 3.0173996737155173

Epoch: 53| Step: 0
Training loss: 3.2261009347997955
Validation loss: 3.011154480095988

Epoch: 5| Step: 1
Training loss: 2.946268508328619
Validation loss: 3.0025619843829916

Epoch: 5| Step: 2
Training loss: 3.6818680508337067
Validation loss: 2.99843229586324

Epoch: 5| Step: 3
Training loss: 2.9142491994167674
Validation loss: 2.9901839442570615

Epoch: 5| Step: 4
Training loss: 3.6884439844172885
Validation loss: 2.990556359983963

Epoch: 5| Step: 5
Training loss: 3.701132580390023
Validation loss: 2.9899624665619724

Epoch: 5| Step: 6
Training loss: 2.681505926406972
Validation loss: 2.988824786215629

Epoch: 5| Step: 7
Training loss: 4.030274738952116
Validation loss: 2.9856246645189515

Epoch: 5| Step: 8
Training loss: 3.4433251702161733
Validation loss: 2.9861890290620923

Epoch: 5| Step: 9
Training loss: 2.5448443971142285
Validation loss: 2.9848367464508487

Epoch: 5| Step: 10
Training loss: 2.815182826201557
Validation loss: 2.9831732609089796

Epoch: 54| Step: 0
Training loss: 3.5453459683045243
Validation loss: 2.986171508760778

Epoch: 5| Step: 1
Training loss: 3.37101029417627
Validation loss: 2.985680907169156

Epoch: 5| Step: 2
Training loss: 3.333810311205644
Validation loss: 2.9864412574685204

Epoch: 5| Step: 3
Training loss: 3.716101721234697
Validation loss: 2.9868779054454424

Epoch: 5| Step: 4
Training loss: 2.9000252952787906
Validation loss: 2.98761091880653

Epoch: 5| Step: 5
Training loss: 2.59805225996355
Validation loss: 2.988346045049843

Epoch: 5| Step: 6
Training loss: 2.8784621580710033
Validation loss: 2.985392374695641

Epoch: 5| Step: 7
Training loss: 2.8480149031474196
Validation loss: 2.9896717422194192

Epoch: 5| Step: 8
Training loss: 3.1524366249290936
Validation loss: 2.9948041299112083

Epoch: 5| Step: 9
Training loss: 3.7951029343146225
Validation loss: 2.986387200138984

Epoch: 5| Step: 10
Training loss: 3.69143273076646
Validation loss: 2.9812218079975636

Epoch: 55| Step: 0
Training loss: 3.1421239511673487
Validation loss: 2.9796539660775707

Epoch: 5| Step: 1
Training loss: 2.8279798270211502
Validation loss: 2.981447303946801

Epoch: 5| Step: 2
Training loss: 3.3139694121657954
Validation loss: 2.9790191051638

Epoch: 5| Step: 3
Training loss: 3.7940272574001126
Validation loss: 2.9806247817048037

Epoch: 5| Step: 4
Training loss: 2.8666209978709376
Validation loss: 2.9777681983913458

Epoch: 5| Step: 5
Training loss: 2.486678105584528
Validation loss: 2.9790421011024755

Epoch: 5| Step: 6
Training loss: 3.4559292691021772
Validation loss: 2.9816927541972515

Epoch: 5| Step: 7
Training loss: 2.8952232285317456
Validation loss: 2.9813542771968686

Epoch: 5| Step: 8
Training loss: 4.168947943201617
Validation loss: 2.9855800009124844

Epoch: 5| Step: 9
Training loss: 3.4007903975493647
Validation loss: 2.979458643497705

Epoch: 5| Step: 10
Training loss: 3.261194902029911
Validation loss: 2.9816563520295123

Epoch: 56| Step: 0
Training loss: 2.7884480630361836
Validation loss: 2.9790857138987903

Epoch: 5| Step: 1
Training loss: 3.2504128413982074
Validation loss: 2.9761512159345114

Epoch: 5| Step: 2
Training loss: 3.7420455491572753
Validation loss: 2.989092740533738

Epoch: 5| Step: 3
Training loss: 2.780801201088781
Validation loss: 2.9925561985816533

Epoch: 5| Step: 4
Training loss: 3.4808648052136832
Validation loss: 2.9893083840772054

Epoch: 5| Step: 5
Training loss: 2.400347418275961
Validation loss: 2.991578208782595

Epoch: 5| Step: 6
Training loss: 3.5336058193677915
Validation loss: 2.987811838238481

Epoch: 5| Step: 7
Training loss: 4.0077004221810535
Validation loss: 2.986960753528141

Epoch: 5| Step: 8
Training loss: 3.09669924332559
Validation loss: 2.9821758365810176

Epoch: 5| Step: 9
Training loss: 3.0909536034647904
Validation loss: 2.975940547533737

Epoch: 5| Step: 10
Training loss: 3.4412506449373517
Validation loss: 2.97373273100929

Epoch: 57| Step: 0
Training loss: 3.298574145372071
Validation loss: 2.9737803743174127

Epoch: 5| Step: 1
Training loss: 2.9252867338050104
Validation loss: 2.970863224867454

Epoch: 5| Step: 2
Training loss: 3.7750502273552833
Validation loss: 2.9748295388143418

Epoch: 5| Step: 3
Training loss: 2.8317461804262907
Validation loss: 2.974001739089221

Epoch: 5| Step: 4
Training loss: 3.5286988351742843
Validation loss: 2.9715869821665994

Epoch: 5| Step: 5
Training loss: 3.1197812563680567
Validation loss: 2.97287527270354

Epoch: 5| Step: 6
Training loss: 3.1471920153013793
Validation loss: 2.969887229485791

Epoch: 5| Step: 7
Training loss: 3.453325360729583
Validation loss: 2.969769416051509

Epoch: 5| Step: 8
Training loss: 2.3874399746843786
Validation loss: 2.967708038220758

Epoch: 5| Step: 9
Training loss: 3.7192795320366496
Validation loss: 2.968237649934028

Epoch: 5| Step: 10
Training loss: 3.3823977738162885
Validation loss: 2.9682753385861473

Epoch: 58| Step: 0
Training loss: 3.6177561500406887
Validation loss: 2.966469461844252

Epoch: 5| Step: 1
Training loss: 2.992552732482663
Validation loss: 2.964678390932488

Epoch: 5| Step: 2
Training loss: 3.3537503728535802
Validation loss: 2.967131320527132

Epoch: 5| Step: 3
Training loss: 2.948917681756209
Validation loss: 2.9670420890858797

Epoch: 5| Step: 4
Training loss: 3.7808504760523953
Validation loss: 2.965455897429526

Epoch: 5| Step: 5
Training loss: 3.2402299601574804
Validation loss: 2.9637996796924524

Epoch: 5| Step: 6
Training loss: 2.9739328217400365
Validation loss: 2.9626559011091835

Epoch: 5| Step: 7
Training loss: 3.2452870455658736
Validation loss: 2.9618189680922655

Epoch: 5| Step: 8
Training loss: 3.1158998358595187
Validation loss: 2.960213481573574

Epoch: 5| Step: 9
Training loss: 3.2591552894398257
Validation loss: 2.9614251246332954

Epoch: 5| Step: 10
Training loss: 3.119328807870194
Validation loss: 2.9596429710890355

Epoch: 59| Step: 0
Training loss: 3.704362622210279
Validation loss: 2.9581481876235247

Epoch: 5| Step: 1
Training loss: 3.634019483002841
Validation loss: 2.9575665398904327

Epoch: 5| Step: 2
Training loss: 3.4631393007686424
Validation loss: 2.960136997804624

Epoch: 5| Step: 3
Training loss: 3.1915426610324262
Validation loss: 2.9581239624206037

Epoch: 5| Step: 4
Training loss: 2.9729454511404247
Validation loss: 2.9575163287773347

Epoch: 5| Step: 5
Training loss: 3.0499120981025576
Validation loss: 2.960189975630227

Epoch: 5| Step: 6
Training loss: 2.656535234283327
Validation loss: 2.9562705712833126

Epoch: 5| Step: 7
Training loss: 3.402983052469628
Validation loss: 2.9570950995001173

Epoch: 5| Step: 8
Training loss: 3.2481010464608424
Validation loss: 2.956226327917502

Epoch: 5| Step: 9
Training loss: 2.7042010155736196
Validation loss: 2.957082036334707

Epoch: 5| Step: 10
Training loss: 3.516549086450663
Validation loss: 2.9539314093961466

Epoch: 60| Step: 0
Training loss: 3.8379034221717307
Validation loss: 2.95627808111679

Epoch: 5| Step: 1
Training loss: 3.250937253348259
Validation loss: 2.9549611335378945

Epoch: 5| Step: 2
Training loss: 3.3000733107313196
Validation loss: 2.9522633643021727

Epoch: 5| Step: 3
Training loss: 2.7492346999195427
Validation loss: 2.9560415937192244

Epoch: 5| Step: 4
Training loss: 2.8971368796812786
Validation loss: 2.954864996354642

Epoch: 5| Step: 5
Training loss: 3.478350301816014
Validation loss: 2.953277111720638

Epoch: 5| Step: 6
Training loss: 2.6335337751694956
Validation loss: 2.9502723251128695

Epoch: 5| Step: 7
Training loss: 2.7528613549906624
Validation loss: 2.951318642739208

Epoch: 5| Step: 8
Training loss: 3.2953279309478978
Validation loss: 2.9527376112583963

Epoch: 5| Step: 9
Training loss: 4.054535791282165
Validation loss: 2.9536199598191595

Epoch: 5| Step: 10
Training loss: 3.0365415968474343
Validation loss: 2.952875990058729

Epoch: 61| Step: 0
Training loss: 3.0008785233029833
Validation loss: 2.9533351379172723

Epoch: 5| Step: 1
Training loss: 3.004338306562415
Validation loss: 2.950120990893714

Epoch: 5| Step: 2
Training loss: 2.6326954076973457
Validation loss: 2.953067205805121

Epoch: 5| Step: 3
Training loss: 2.83008503304238
Validation loss: 2.950752450716872

Epoch: 5| Step: 4
Training loss: 3.559004691858031
Validation loss: 2.9514315119799672

Epoch: 5| Step: 5
Training loss: 3.4332304361966943
Validation loss: 2.949787365685712

Epoch: 5| Step: 6
Training loss: 2.949139524494649
Validation loss: 2.94814611991579

Epoch: 5| Step: 7
Training loss: 3.4586317247710507
Validation loss: 2.9452624403363092

Epoch: 5| Step: 8
Training loss: 3.650490030289451
Validation loss: 2.9467349958100266

Epoch: 5| Step: 9
Training loss: 3.231175853830377
Validation loss: 2.9468081387455642

Epoch: 5| Step: 10
Training loss: 3.6830252960189838
Validation loss: 2.942964155290353

Epoch: 62| Step: 0
Training loss: 2.626890500821857
Validation loss: 2.942853349093949

Epoch: 5| Step: 1
Training loss: 2.6357197543274684
Validation loss: 2.9439767734544087

Epoch: 5| Step: 2
Training loss: 3.676239147306453
Validation loss: 2.944846269469342

Epoch: 5| Step: 3
Training loss: 3.4654384992825324
Validation loss: 2.947111077011388

Epoch: 5| Step: 4
Training loss: 3.411413076940193
Validation loss: 2.945369339213303

Epoch: 5| Step: 5
Training loss: 3.167030731822954
Validation loss: 2.9405161188620323

Epoch: 5| Step: 6
Training loss: 3.9442841955476005
Validation loss: 2.942225746065351

Epoch: 5| Step: 7
Training loss: 3.3053670414473677
Validation loss: 2.941985335390471

Epoch: 5| Step: 8
Training loss: 2.909297370899334
Validation loss: 2.939112444792661

Epoch: 5| Step: 9
Training loss: 3.2023534822560396
Validation loss: 2.942804260752171

Epoch: 5| Step: 10
Training loss: 2.943961807697767
Validation loss: 2.9402171780938295

Epoch: 63| Step: 0
Training loss: 2.715615581324917
Validation loss: 2.947160437216078

Epoch: 5| Step: 1
Training loss: 2.5072041662014817
Validation loss: 2.951290858211245

Epoch: 5| Step: 2
Training loss: 3.3251322153521587
Validation loss: 2.948955470405869

Epoch: 5| Step: 3
Training loss: 2.7479269710537486
Validation loss: 2.9577554502013985

Epoch: 5| Step: 4
Training loss: 3.0294678158370294
Validation loss: 2.9432428270783366

Epoch: 5| Step: 5
Training loss: 3.142821042361318
Validation loss: 2.9485017824922686

Epoch: 5| Step: 6
Training loss: 3.512562278113997
Validation loss: 2.9455747744638985

Epoch: 5| Step: 7
Training loss: 3.294580031448343
Validation loss: 2.9466882576423106

Epoch: 5| Step: 8
Training loss: 3.9223829449607472
Validation loss: 2.9420946171480176

Epoch: 5| Step: 9
Training loss: 3.4281178838609057
Validation loss: 2.9385840397461354

Epoch: 5| Step: 10
Training loss: 3.635261218983998
Validation loss: 2.9378478420939995

Epoch: 64| Step: 0
Training loss: 3.1285958011073505
Validation loss: 2.9362072357072777

Epoch: 5| Step: 1
Training loss: 3.202197726871722
Validation loss: 2.9403332042357606

Epoch: 5| Step: 2
Training loss: 3.5620685784636743
Validation loss: 2.9416873962411905

Epoch: 5| Step: 3
Training loss: 3.0112736592010605
Validation loss: 2.9415399919484253

Epoch: 5| Step: 4
Training loss: 2.995874747536967
Validation loss: 2.9378802267891895

Epoch: 5| Step: 5
Training loss: 3.2272286454827785
Validation loss: 2.9365427276635665

Epoch: 5| Step: 6
Training loss: 3.3230777490171945
Validation loss: 2.937218180629936

Epoch: 5| Step: 7
Training loss: 2.834842018421693
Validation loss: 2.9359471281965464

Epoch: 5| Step: 8
Training loss: 3.6808160237849634
Validation loss: 2.9346582704717767

Epoch: 5| Step: 9
Training loss: 2.9670485590042603
Validation loss: 2.9447323016127886

Epoch: 5| Step: 10
Training loss: 3.4971999821062205
Validation loss: 2.9404171780377815

Epoch: 65| Step: 0
Training loss: 3.44114242391108
Validation loss: 2.9361816219533163

Epoch: 5| Step: 1
Training loss: 2.9687021352021343
Validation loss: 2.929063994751743

Epoch: 5| Step: 2
Training loss: 2.7084661206680507
Validation loss: 2.9352261084040956

Epoch: 5| Step: 3
Training loss: 3.046701905640106
Validation loss: 2.935685143691875

Epoch: 5| Step: 4
Training loss: 2.5911967568050107
Validation loss: 2.934317255048784

Epoch: 5| Step: 5
Training loss: 2.7663486202154846
Validation loss: 2.931466651300515

Epoch: 5| Step: 6
Training loss: 3.864530386480643
Validation loss: 2.935324708911922

Epoch: 5| Step: 7
Training loss: 3.04731254370366
Validation loss: 2.9310666198063164

Epoch: 5| Step: 8
Training loss: 3.520735895437538
Validation loss: 2.934222106329692

Epoch: 5| Step: 9
Training loss: 3.7710871040280933
Validation loss: 2.9259099575092913

Epoch: 5| Step: 10
Training loss: 3.4201325461150778
Validation loss: 2.9328979717494486

Epoch: 66| Step: 0
Training loss: 3.1361291694703106
Validation loss: 2.9300687869674764

Epoch: 5| Step: 1
Training loss: 2.8679572379250873
Validation loss: 2.9310801618923263

Epoch: 5| Step: 2
Training loss: 3.3128821674351863
Validation loss: 2.934717847601551

Epoch: 5| Step: 3
Training loss: 3.132045585388277
Validation loss: 2.9377247661754278

Epoch: 5| Step: 4
Training loss: 2.839492461293768
Validation loss: 2.9430614303516323

Epoch: 5| Step: 5
Training loss: 2.871326255466632
Validation loss: 2.948341540478784

Epoch: 5| Step: 6
Training loss: 3.2826986838741212
Validation loss: 2.9403402508244803

Epoch: 5| Step: 7
Training loss: 3.685761251921311
Validation loss: 2.9336226214627015

Epoch: 5| Step: 8
Training loss: 3.6380762174737282
Validation loss: 2.930713250090304

Epoch: 5| Step: 9
Training loss: 3.4225286268844064
Validation loss: 2.924717027487723

Epoch: 5| Step: 10
Training loss: 2.9959676982121266
Validation loss: 2.9245699442338107

Epoch: 67| Step: 0
Training loss: 3.0443655781922185
Validation loss: 2.9282353132357963

Epoch: 5| Step: 1
Training loss: 3.585499589231928
Validation loss: 2.9273046372575227

Epoch: 5| Step: 2
Training loss: 3.398114068436628
Validation loss: 2.925224982199261

Epoch: 5| Step: 3
Training loss: 2.7446328587105726
Validation loss: 2.928203275818458

Epoch: 5| Step: 4
Training loss: 3.453356981036939
Validation loss: 2.9254551107755167

Epoch: 5| Step: 5
Training loss: 3.1842868541912788
Validation loss: 2.923969656183829

Epoch: 5| Step: 6
Training loss: 2.803225250322676
Validation loss: 2.926808370854632

Epoch: 5| Step: 7
Training loss: 3.4455295070546668
Validation loss: 2.9292922682973614

Epoch: 5| Step: 8
Training loss: 2.8630744057918904
Validation loss: 2.931746117778339

Epoch: 5| Step: 9
Training loss: 3.5318891908883363
Validation loss: 2.926703862478919

Epoch: 5| Step: 10
Training loss: 3.137135555180418
Validation loss: 2.921917044500666

Epoch: 68| Step: 0
Training loss: 3.0353973960570215
Validation loss: 2.9201867591193187

Epoch: 5| Step: 1
Training loss: 3.095846525414873
Validation loss: 2.9211548448632136

Epoch: 5| Step: 2
Training loss: 3.4220172730572314
Validation loss: 2.918583519267075

Epoch: 5| Step: 3
Training loss: 3.1178514734290617
Validation loss: 2.9220658554136736

Epoch: 5| Step: 4
Training loss: 3.130661680342144
Validation loss: 2.9179593817900153

Epoch: 5| Step: 5
Training loss: 3.56024821541233
Validation loss: 2.918829688641583

Epoch: 5| Step: 6
Training loss: 3.251643718858148
Validation loss: 2.919827733552751

Epoch: 5| Step: 7
Training loss: 3.0220956905218768
Validation loss: 2.9174476998788172

Epoch: 5| Step: 8
Training loss: 3.180737371305548
Validation loss: 2.920808346593655

Epoch: 5| Step: 9
Training loss: 3.4098628771107853
Validation loss: 2.9206013878384636

Epoch: 5| Step: 10
Training loss: 2.954566240571004
Validation loss: 2.9227278094776743

Epoch: 69| Step: 0
Training loss: 3.1052872514768373
Validation loss: 2.926299729068071

Epoch: 5| Step: 1
Training loss: 3.915408209593721
Validation loss: 2.940056030247931

Epoch: 5| Step: 2
Training loss: 2.955432777276617
Validation loss: 2.9190919282717194

Epoch: 5| Step: 3
Training loss: 2.3408146087487873
Validation loss: 2.9171946233783728

Epoch: 5| Step: 4
Training loss: 3.3741852518632705
Validation loss: 2.91743591875952

Epoch: 5| Step: 5
Training loss: 3.269049642041826
Validation loss: 2.9177953677889312

Epoch: 5| Step: 6
Training loss: 3.034342967374048
Validation loss: 2.919132402202024

Epoch: 5| Step: 7
Training loss: 3.637871613806628
Validation loss: 2.918880519577977

Epoch: 5| Step: 8
Training loss: 3.1248222300510773
Validation loss: 2.9165523389450603

Epoch: 5| Step: 9
Training loss: 3.033387050222896
Validation loss: 2.9144649182118076

Epoch: 5| Step: 10
Training loss: 3.175101757671685
Validation loss: 2.9144976260608173

Epoch: 70| Step: 0
Training loss: 3.180205431846364
Validation loss: 2.91305166490717

Epoch: 5| Step: 1
Training loss: 3.5554860989091397
Validation loss: 2.9156357649978664

Epoch: 5| Step: 2
Training loss: 2.4857966356150807
Validation loss: 2.9140311271379455

Epoch: 5| Step: 3
Training loss: 3.681185472113914
Validation loss: 2.915679100538915

Epoch: 5| Step: 4
Training loss: 3.201288804158318
Validation loss: 2.9209486373727147

Epoch: 5| Step: 5
Training loss: 3.6145436983747947
Validation loss: 2.9162978353674087

Epoch: 5| Step: 6
Training loss: 3.2005114802241197
Validation loss: 2.913604748761673

Epoch: 5| Step: 7
Training loss: 2.8861478207403137
Validation loss: 2.9167180181339494

Epoch: 5| Step: 8
Training loss: 3.175307948279387
Validation loss: 2.9160555508418873

Epoch: 5| Step: 9
Training loss: 2.7767814142056326
Validation loss: 2.928064080339397

Epoch: 5| Step: 10
Training loss: 3.2628646939065966
Validation loss: 2.934740925115486

Epoch: 71| Step: 0
Training loss: 2.6530048069053036
Validation loss: 2.9224459138790766

Epoch: 5| Step: 1
Training loss: 2.704406963500678
Validation loss: 2.9402136145456312

Epoch: 5| Step: 2
Training loss: 3.577427558725298
Validation loss: 2.935032253296048

Epoch: 5| Step: 3
Training loss: 3.462663964751429
Validation loss: 2.9131784144616573

Epoch: 5| Step: 4
Training loss: 2.94504956759074
Validation loss: 2.9112733863685856

Epoch: 5| Step: 5
Training loss: 3.026463298126985
Validation loss: 2.9113188949467728

Epoch: 5| Step: 6
Training loss: 2.9302668697957626
Validation loss: 2.915123659400311

Epoch: 5| Step: 7
Training loss: 3.817505973806248
Validation loss: 2.9135375933125367

Epoch: 5| Step: 8
Training loss: 3.3991906044140445
Validation loss: 2.9219207505645315

Epoch: 5| Step: 9
Training loss: 3.167005738292009
Validation loss: 2.9198518269510103

Epoch: 5| Step: 10
Training loss: 3.4442438730341953
Validation loss: 2.9157128542639668

Epoch: 72| Step: 0
Training loss: 3.4219477397555567
Validation loss: 2.9108365523667925

Epoch: 5| Step: 1
Training loss: 3.1097790632854823
Validation loss: 2.9114677738260664

Epoch: 5| Step: 2
Training loss: 3.6913579382585926
Validation loss: 2.90811258085822

Epoch: 5| Step: 3
Training loss: 3.841047996525022
Validation loss: 2.9047345406810936

Epoch: 5| Step: 4
Training loss: 2.5939436690861917
Validation loss: 2.9063742447113694

Epoch: 5| Step: 5
Training loss: 3.3124946738146304
Validation loss: 2.9065721086127247

Epoch: 5| Step: 6
Training loss: 3.0211628876620704
Validation loss: 2.9022218785211966

Epoch: 5| Step: 7
Training loss: 3.0104258888041775
Validation loss: 2.9075812886216337

Epoch: 5| Step: 8
Training loss: 2.2944420625408988
Validation loss: 2.910973410858001

Epoch: 5| Step: 9
Training loss: 3.4143760414966864
Validation loss: 2.9298581012015807

Epoch: 5| Step: 10
Training loss: 3.1658672695712435
Validation loss: 2.9513194088817434

Epoch: 73| Step: 0
Training loss: 3.0020836905365167
Validation loss: 2.93575597537187

Epoch: 5| Step: 1
Training loss: 2.7105988832446544
Validation loss: 2.931327263581506

Epoch: 5| Step: 2
Training loss: 2.9918376827681907
Validation loss: 2.930968265282172

Epoch: 5| Step: 3
Training loss: 3.0049166127344207
Validation loss: 2.94906988704718

Epoch: 5| Step: 4
Training loss: 3.394670876461674
Validation loss: 2.9404582808548585

Epoch: 5| Step: 5
Training loss: 3.635056194516459
Validation loss: 2.896791975960401

Epoch: 5| Step: 6
Training loss: 3.306121587152482
Validation loss: 2.900432814767051

Epoch: 5| Step: 7
Training loss: 2.7726846022243254
Validation loss: 2.9038894704878055

Epoch: 5| Step: 8
Training loss: 3.5541318354329086
Validation loss: 2.914194921057884

Epoch: 5| Step: 9
Training loss: 3.7022953955186653
Validation loss: 2.9140546614348413

Epoch: 5| Step: 10
Training loss: 3.0111354159054224
Validation loss: 2.912939589727727

Epoch: 74| Step: 0
Training loss: 3.385152311518667
Validation loss: 2.9125711566757313

Epoch: 5| Step: 1
Training loss: 3.2715485068340895
Validation loss: 2.9087774555784245

Epoch: 5| Step: 2
Training loss: 3.0294023368771534
Validation loss: 2.90332627982835

Epoch: 5| Step: 3
Training loss: 3.200963477286544
Validation loss: 2.90107998467612

Epoch: 5| Step: 4
Training loss: 2.802862141850409
Validation loss: 2.899429753340506

Epoch: 5| Step: 5
Training loss: 2.9382662483933877
Validation loss: 2.898846526799813

Epoch: 5| Step: 6
Training loss: 3.1891819125541123
Validation loss: 2.90078816486671

Epoch: 5| Step: 7
Training loss: 3.493826735307241
Validation loss: 2.900594804618484

Epoch: 5| Step: 8
Training loss: 3.168732538118723
Validation loss: 2.90762751449444

Epoch: 5| Step: 9
Training loss: 3.487776802043678
Validation loss: 2.9039987733741683

Epoch: 5| Step: 10
Training loss: 3.0744160415568405
Validation loss: 2.9104876629950955

Epoch: 75| Step: 0
Training loss: 3.0745067728104174
Validation loss: 2.918697044835681

Epoch: 5| Step: 1
Training loss: 2.7495211271010893
Validation loss: 2.943634942030002

Epoch: 5| Step: 2
Training loss: 2.818079606073649
Validation loss: 2.938460680583213

Epoch: 5| Step: 3
Training loss: 3.1129710809949453
Validation loss: 2.949578436932016

Epoch: 5| Step: 4
Training loss: 3.02134423155922
Validation loss: 2.904310281509658

Epoch: 5| Step: 5
Training loss: 2.973639547406166
Validation loss: 2.895518279508475

Epoch: 5| Step: 6
Training loss: 3.8125996811139475
Validation loss: 2.8947201319382616

Epoch: 5| Step: 7
Training loss: 3.8931260247320276
Validation loss: 2.901535681105941

Epoch: 5| Step: 8
Training loss: 3.2329164616428656
Validation loss: 2.8986435091068325

Epoch: 5| Step: 9
Training loss: 3.040090352773638
Validation loss: 2.9015015115250797

Epoch: 5| Step: 10
Training loss: 3.2590761364040604
Validation loss: 2.902884937286778

Epoch: 76| Step: 0
Training loss: 3.04000910356062
Validation loss: 2.8994775344596264

Epoch: 5| Step: 1
Training loss: 3.9452687478236146
Validation loss: 2.901769855559154

Epoch: 5| Step: 2
Training loss: 2.619028747581431
Validation loss: 2.8983735382432023

Epoch: 5| Step: 3
Training loss: 3.2579572540251625
Validation loss: 2.894404481013807

Epoch: 5| Step: 4
Training loss: 3.562241126576368
Validation loss: 2.8961757552777043

Epoch: 5| Step: 5
Training loss: 2.8869189449780275
Validation loss: 2.890895410697825

Epoch: 5| Step: 6
Training loss: 3.295474943857231
Validation loss: 2.894173750717431

Epoch: 5| Step: 7
Training loss: 3.520490610871637
Validation loss: 2.891031079646616

Epoch: 5| Step: 8
Training loss: 2.843377560550702
Validation loss: 2.8901884104581703

Epoch: 5| Step: 9
Training loss: 2.7588768653063087
Validation loss: 2.8892334341993497

Epoch: 5| Step: 10
Training loss: 3.02320155127456
Validation loss: 2.8963510884537293

Epoch: 77| Step: 0
Training loss: 3.6948514170834708
Validation loss: 2.9065375660481325

Epoch: 5| Step: 1
Training loss: 3.2403747638551765
Validation loss: 2.8998033711495426

Epoch: 5| Step: 2
Training loss: 2.7602308870574075
Validation loss: 2.8912932461898886

Epoch: 5| Step: 3
Training loss: 3.0973412833449103
Validation loss: 2.8886855199840564

Epoch: 5| Step: 4
Training loss: 2.8818303117532347
Validation loss: 2.8914561869531616

Epoch: 5| Step: 5
Training loss: 2.8637135427844305
Validation loss: 2.8886691468829357

Epoch: 5| Step: 6
Training loss: 3.1213520883678125
Validation loss: 2.891278694911704

Epoch: 5| Step: 7
Training loss: 3.144287858156236
Validation loss: 2.8897960623899137

Epoch: 5| Step: 8
Training loss: 3.379794212487235
Validation loss: 2.8883483062519457

Epoch: 5| Step: 9
Training loss: 3.6744231776949343
Validation loss: 2.8892618776123067

Epoch: 5| Step: 10
Training loss: 3.0150243922017097
Validation loss: 2.8873544857423505

Epoch: 78| Step: 0
Training loss: 2.542423875507435
Validation loss: 2.8858858334737088

Epoch: 5| Step: 1
Training loss: 2.75917948703059
Validation loss: 2.8849530846984663

Epoch: 5| Step: 2
Training loss: 3.9947727141579357
Validation loss: 2.8889617737846263

Epoch: 5| Step: 3
Training loss: 2.9985297096947154
Validation loss: 2.8861038916623922

Epoch: 5| Step: 4
Training loss: 2.936062887375795
Validation loss: 2.8866883064161244

Epoch: 5| Step: 5
Training loss: 3.6487915390070444
Validation loss: 2.883774319561437

Epoch: 5| Step: 6
Training loss: 2.9723267541806644
Validation loss: 2.8851066865017554

Epoch: 5| Step: 7
Training loss: 3.0602349449169455
Validation loss: 2.8845583003716624

Epoch: 5| Step: 8
Training loss: 2.7250088962794683
Validation loss: 2.8857825988135386

Epoch: 5| Step: 9
Training loss: 3.599612686726976
Validation loss: 2.8846594432645567

Epoch: 5| Step: 10
Training loss: 3.4355682493827704
Validation loss: 2.88550420509634

Epoch: 79| Step: 0
Training loss: 3.4418986527873785
Validation loss: 2.8865676905410718

Epoch: 5| Step: 1
Training loss: 3.2893596886407668
Validation loss: 2.889583684996049

Epoch: 5| Step: 2
Training loss: 3.5794218286961628
Validation loss: 2.8842346896763242

Epoch: 5| Step: 3
Training loss: 2.821518489584403
Validation loss: 2.883647954266888

Epoch: 5| Step: 4
Training loss: 3.2222241661095143
Validation loss: 2.8839642171380317

Epoch: 5| Step: 5
Training loss: 2.8794665263728043
Validation loss: 2.8835571191786

Epoch: 5| Step: 6
Training loss: 3.229298611478153
Validation loss: 2.883267498551025

Epoch: 5| Step: 7
Training loss: 3.3733451459574786
Validation loss: 2.881418883682683

Epoch: 5| Step: 8
Training loss: 2.7607283698142004
Validation loss: 2.8803660503434716

Epoch: 5| Step: 9
Training loss: 2.9126554062930454
Validation loss: 2.880417273462815

Epoch: 5| Step: 10
Training loss: 3.2683006896846805
Validation loss: 2.8813420700329746

Epoch: 80| Step: 0
Training loss: 2.6057918411170484
Validation loss: 2.8834166975368585

Epoch: 5| Step: 1
Training loss: 3.204818947568542
Validation loss: 2.8807312621726893

Epoch: 5| Step: 2
Training loss: 3.2145194982856142
Validation loss: 2.8790723992841123

Epoch: 5| Step: 3
Training loss: 2.9015270947919
Validation loss: 2.8771811954754787

Epoch: 5| Step: 4
Training loss: 3.146463461580871
Validation loss: 2.8725505477750395

Epoch: 5| Step: 5
Training loss: 3.3495055958322015
Validation loss: 2.8758556667379502

Epoch: 5| Step: 6
Training loss: 3.3941550446918636
Validation loss: 2.8723210501769074

Epoch: 5| Step: 7
Training loss: 3.2814758223073492
Validation loss: 2.8739265838489114

Epoch: 5| Step: 8
Training loss: 3.068245150493655
Validation loss: 2.8726879192968666

Epoch: 5| Step: 9
Training loss: 3.4048663487580937
Validation loss: 2.87297277149416

Epoch: 5| Step: 10
Training loss: 3.1731519712451823
Validation loss: 2.86983521684918

Epoch: 81| Step: 0
Training loss: 2.7155268187163473
Validation loss: 2.8778803852287926

Epoch: 5| Step: 1
Training loss: 2.7538316216062833
Validation loss: 2.8865639781650265

Epoch: 5| Step: 2
Training loss: 3.3012654508021853
Validation loss: 2.8871767140186213

Epoch: 5| Step: 3
Training loss: 2.9195367769674405
Validation loss: 2.889319721862641

Epoch: 5| Step: 4
Training loss: 3.2059763057259136
Validation loss: 2.8917722616490606

Epoch: 5| Step: 5
Training loss: 3.5872308397503847
Validation loss: 2.875623837736726

Epoch: 5| Step: 6
Training loss: 3.2391733153359774
Validation loss: 2.8705141401178347

Epoch: 5| Step: 7
Training loss: 2.933025279631014
Validation loss: 2.8705061469101674

Epoch: 5| Step: 8
Training loss: 3.2763609293438742
Validation loss: 2.870257132607664

Epoch: 5| Step: 9
Training loss: 2.932401737475814
Validation loss: 2.869358217979742

Epoch: 5| Step: 10
Training loss: 3.883447975027302
Validation loss: 2.8674813285118397

Epoch: 82| Step: 0
Training loss: 2.8243970379409635
Validation loss: 2.868657335362993

Epoch: 5| Step: 1
Training loss: 2.7434061065174253
Validation loss: 2.8686963421221185

Epoch: 5| Step: 2
Training loss: 3.5826986475280087
Validation loss: 2.866911897760882

Epoch: 5| Step: 3
Training loss: 3.69671165640731
Validation loss: 2.869499412460442

Epoch: 5| Step: 4
Training loss: 3.1162179763317557
Validation loss: 2.869355549230301

Epoch: 5| Step: 5
Training loss: 2.8213098511370647
Validation loss: 2.8679785785950282

Epoch: 5| Step: 6
Training loss: 2.642437555446871
Validation loss: 2.86758773507994

Epoch: 5| Step: 7
Training loss: 3.7060784903303463
Validation loss: 2.866342541709006

Epoch: 5| Step: 8
Training loss: 3.2507694507284812
Validation loss: 2.8667809769684918

Epoch: 5| Step: 9
Training loss: 3.088007519974718
Validation loss: 2.864886925384112

Epoch: 5| Step: 10
Training loss: 3.1340071001100234
Validation loss: 2.8635716350850315

Epoch: 83| Step: 0
Training loss: 3.1828008682420466
Validation loss: 2.8661427994928457

Epoch: 5| Step: 1
Training loss: 3.2354727093980067
Validation loss: 2.867473682678639

Epoch: 5| Step: 2
Training loss: 3.0895319997201716
Validation loss: 2.866732610638962

Epoch: 5| Step: 3
Training loss: 2.9098437659937475
Validation loss: 2.8718406810078174

Epoch: 5| Step: 4
Training loss: 2.795390838156503
Validation loss: 2.870855992796895

Epoch: 5| Step: 5
Training loss: 2.8934612484385926
Validation loss: 2.871716666939355

Epoch: 5| Step: 6
Training loss: 3.493634975771382
Validation loss: 2.875799678677441

Epoch: 5| Step: 7
Training loss: 3.556172423363004
Validation loss: 2.8744155955035264

Epoch: 5| Step: 8
Training loss: 2.9344768794922227
Validation loss: 2.8691187193278966

Epoch: 5| Step: 9
Training loss: 3.4443099105020325
Validation loss: 2.8622148661149622

Epoch: 5| Step: 10
Training loss: 3.120288043052861
Validation loss: 2.865172247139656

Epoch: 84| Step: 0
Training loss: 2.708450451788343
Validation loss: 2.8635014234726484

Epoch: 5| Step: 1
Training loss: 2.997286682174256
Validation loss: 2.8612530728813677

Epoch: 5| Step: 2
Training loss: 3.9313133926010946
Validation loss: 2.863951875030819

Epoch: 5| Step: 3
Training loss: 3.1441163352040387
Validation loss: 2.863147109009711

Epoch: 5| Step: 4
Training loss: 3.4090670914251437
Validation loss: 2.861254511833365

Epoch: 5| Step: 5
Training loss: 3.187877258714014
Validation loss: 2.8613125719572183

Epoch: 5| Step: 6
Training loss: 3.710980931078088
Validation loss: 2.861120701434055

Epoch: 5| Step: 7
Training loss: 2.540622736518105
Validation loss: 2.861982190146789

Epoch: 5| Step: 8
Training loss: 2.5979813221765893
Validation loss: 2.8579691405157814

Epoch: 5| Step: 9
Training loss: 2.817279738419974
Validation loss: 2.8578053759037547

Epoch: 5| Step: 10
Training loss: 3.371542678592299
Validation loss: 2.858197335560472

Epoch: 85| Step: 0
Training loss: 3.584334669742662
Validation loss: 2.857156306189718

Epoch: 5| Step: 1
Training loss: 2.545701394249546
Validation loss: 2.8566420945983255

Epoch: 5| Step: 2
Training loss: 3.301208685111229
Validation loss: 2.854841701429989

Epoch: 5| Step: 3
Training loss: 2.991161837970352
Validation loss: 2.85784041778625

Epoch: 5| Step: 4
Training loss: 2.917517201978479
Validation loss: 2.856235671005771

Epoch: 5| Step: 5
Training loss: 3.366418454176213
Validation loss: 2.854700278590955

Epoch: 5| Step: 6
Training loss: 2.9784858476995133
Validation loss: 2.855514453055166

Epoch: 5| Step: 7
Training loss: 3.1586373242418557
Validation loss: 2.8543447485807536

Epoch: 5| Step: 8
Training loss: 3.483641679857114
Validation loss: 2.85328433805544

Epoch: 5| Step: 9
Training loss: 3.4199125332271754
Validation loss: 2.857218647829106

Epoch: 5| Step: 10
Training loss: 2.7352005938346062
Validation loss: 2.8497917814532343

Epoch: 86| Step: 0
Training loss: 3.44057147047653
Validation loss: 2.8537888144692776

Epoch: 5| Step: 1
Training loss: 3.336263671938459
Validation loss: 2.858572235020627

Epoch: 5| Step: 2
Training loss: 2.7456320839870183
Validation loss: 2.8620385434575706

Epoch: 5| Step: 3
Training loss: 3.080387271710065
Validation loss: 2.8839990185148014

Epoch: 5| Step: 4
Training loss: 3.1801881888024695
Validation loss: 2.892576313438523

Epoch: 5| Step: 5
Training loss: 3.350610557828154
Validation loss: 2.8882061780952695

Epoch: 5| Step: 6
Training loss: 2.273191668141387
Validation loss: 2.8556221530127788

Epoch: 5| Step: 7
Training loss: 3.441651490357369
Validation loss: 2.853004959870396

Epoch: 5| Step: 8
Training loss: 3.5796083265895935
Validation loss: 2.8520884929031953

Epoch: 5| Step: 9
Training loss: 2.906070498593909
Validation loss: 2.859100785900932

Epoch: 5| Step: 10
Training loss: 3.2300036094338296
Validation loss: 2.861394135118568

Epoch: 87| Step: 0
Training loss: 3.170978137472354
Validation loss: 2.862961108442783

Epoch: 5| Step: 1
Training loss: 2.848251803774996
Validation loss: 2.8576640207881763

Epoch: 5| Step: 2
Training loss: 3.3280102347344966
Validation loss: 2.858066682035338

Epoch: 5| Step: 3
Training loss: 3.190660592682994
Validation loss: 2.8559631689032696

Epoch: 5| Step: 4
Training loss: 3.561387674784224
Validation loss: 2.8518165069561414

Epoch: 5| Step: 5
Training loss: 3.2552459633241666
Validation loss: 2.8551250100654233

Epoch: 5| Step: 6
Training loss: 3.5341050750707206
Validation loss: 2.8549474126334062

Epoch: 5| Step: 7
Training loss: 2.550743675247273
Validation loss: 2.8542472145948996

Epoch: 5| Step: 8
Training loss: 3.103633775136567
Validation loss: 2.8594399237562165

Epoch: 5| Step: 9
Training loss: 3.2077212224535665
Validation loss: 2.854486263577261

Epoch: 5| Step: 10
Training loss: 2.784102530800196
Validation loss: 2.8572004676832305

Epoch: 88| Step: 0
Training loss: 3.0289061618398554
Validation loss: 2.859067167238754

Epoch: 5| Step: 1
Training loss: 3.19562915081767
Validation loss: 2.856150641263367

Epoch: 5| Step: 2
Training loss: 3.327316400863843
Validation loss: 2.8563045452789866

Epoch: 5| Step: 3
Training loss: 2.8830263632244786
Validation loss: 2.8609663665229728

Epoch: 5| Step: 4
Training loss: 3.633210191185608
Validation loss: 2.8644864266002203

Epoch: 5| Step: 5
Training loss: 3.609636305560832
Validation loss: 2.866102325935774

Epoch: 5| Step: 6
Training loss: 2.885098509800815
Validation loss: 2.8624039602998996

Epoch: 5| Step: 7
Training loss: 2.2500686635030753
Validation loss: 2.861042549811051

Epoch: 5| Step: 8
Training loss: 3.1086047574768987
Validation loss: 2.876620817993896

Epoch: 5| Step: 9
Training loss: 3.26286630145332
Validation loss: 2.878289219526486

Epoch: 5| Step: 10
Training loss: 3.2454739379400577
Validation loss: 2.8725612903134614

Epoch: 89| Step: 0
Training loss: 3.3590752046461763
Validation loss: 2.852276815842992

Epoch: 5| Step: 1
Training loss: 3.222285430843635
Validation loss: 2.8503504342830164

Epoch: 5| Step: 2
Training loss: 2.857834030746019
Validation loss: 2.8487512827798813

Epoch: 5| Step: 3
Training loss: 3.0698838262290917
Validation loss: 2.846465384672285

Epoch: 5| Step: 4
Training loss: 2.772960439136372
Validation loss: 2.8425767189456685

Epoch: 5| Step: 5
Training loss: 3.298689356539543
Validation loss: 2.8431973881065664

Epoch: 5| Step: 6
Training loss: 3.217735501009299
Validation loss: 2.8432369425200563

Epoch: 5| Step: 7
Training loss: 3.2978171498426634
Validation loss: 2.8424170948264456

Epoch: 5| Step: 8
Training loss: 2.5711853029589484
Validation loss: 2.8405068010478596

Epoch: 5| Step: 9
Training loss: 3.629925374296478
Validation loss: 2.843116988196967

Epoch: 5| Step: 10
Training loss: 3.1227886768364943
Validation loss: 2.84302439104213

Epoch: 90| Step: 0
Training loss: 3.6046588686569505
Validation loss: 2.8405853479899954

Epoch: 5| Step: 1
Training loss: 3.9404704681517377
Validation loss: 2.840866558036229

Epoch: 5| Step: 2
Training loss: 3.1718405735797224
Validation loss: 2.842744390061447

Epoch: 5| Step: 3
Training loss: 2.9752896207994137
Validation loss: 2.84294805676191

Epoch: 5| Step: 4
Training loss: 3.051860935757659
Validation loss: 2.846424311588568

Epoch: 5| Step: 5
Training loss: 2.834460501763884
Validation loss: 2.8475540916809843

Epoch: 5| Step: 6
Training loss: 3.1873044720685937
Validation loss: 2.845067002898954

Epoch: 5| Step: 7
Training loss: 3.1887277968593337
Validation loss: 2.8389904476148784

Epoch: 5| Step: 8
Training loss: 2.650070362236574
Validation loss: 2.839392253819545

Epoch: 5| Step: 9
Training loss: 2.9976212289458055
Validation loss: 2.837940163547651

Epoch: 5| Step: 10
Training loss: 2.6372779535773336
Validation loss: 2.839498942858825

Epoch: 91| Step: 0
Training loss: 3.345967778362537
Validation loss: 2.837500837567247

Epoch: 5| Step: 1
Training loss: 3.5337108038559246
Validation loss: 2.835045640630897

Epoch: 5| Step: 2
Training loss: 2.8574462388956174
Validation loss: 2.8386073246106074

Epoch: 5| Step: 3
Training loss: 2.9418162026009127
Validation loss: 2.835080236803608

Epoch: 5| Step: 4
Training loss: 2.8305636687740128
Validation loss: 2.8359907115840466

Epoch: 5| Step: 5
Training loss: 3.337447171025298
Validation loss: 2.8346127644029453

Epoch: 5| Step: 6
Training loss: 3.2013564274802397
Validation loss: 2.833979602292182

Epoch: 5| Step: 7
Training loss: 2.884998020323499
Validation loss: 2.832815609475775

Epoch: 5| Step: 8
Training loss: 2.909840324714061
Validation loss: 2.833982106246035

Epoch: 5| Step: 9
Training loss: 3.306873365166418
Validation loss: 2.8326563168042913

Epoch: 5| Step: 10
Training loss: 3.265304768754231
Validation loss: 2.8368917019446624

Epoch: 92| Step: 0
Training loss: 3.4458962289835213
Validation loss: 2.840595085995249

Epoch: 5| Step: 1
Training loss: 3.5547261330318225
Validation loss: 2.8385411910054503

Epoch: 5| Step: 2
Training loss: 2.9898267551613933
Validation loss: 2.83262881731614

Epoch: 5| Step: 3
Training loss: 2.7861066269471366
Validation loss: 2.8332813877673892

Epoch: 5| Step: 4
Training loss: 3.5359136792171553
Validation loss: 2.834333207784161

Epoch: 5| Step: 5
Training loss: 2.590730863278705
Validation loss: 2.831874885245219

Epoch: 5| Step: 6
Training loss: 3.0761703249004033
Validation loss: 2.8323983016462146

Epoch: 5| Step: 7
Training loss: 3.0570510344982558
Validation loss: 2.8317885056996874

Epoch: 5| Step: 8
Training loss: 3.6266383710860652
Validation loss: 2.8343326813679357

Epoch: 5| Step: 9
Training loss: 3.0469892431506835
Validation loss: 2.83451744203123

Epoch: 5| Step: 10
Training loss: 2.472589428617988
Validation loss: 2.832811288194386

Epoch: 93| Step: 0
Training loss: 3.228287575127812
Validation loss: 2.830398286802131

Epoch: 5| Step: 1
Training loss: 2.8780392048957553
Validation loss: 2.8341078094847933

Epoch: 5| Step: 2
Training loss: 3.361433383284397
Validation loss: 2.8338536644904604

Epoch: 5| Step: 3
Training loss: 3.1788976939665825
Validation loss: 2.8484991282844203

Epoch: 5| Step: 4
Training loss: 2.695659228151141
Validation loss: 2.858805091673185

Epoch: 5| Step: 5
Training loss: 2.4051725278898424
Validation loss: 2.8349255639768396

Epoch: 5| Step: 6
Training loss: 4.093631655314695
Validation loss: 2.8288736965331394

Epoch: 5| Step: 7
Training loss: 3.433040153306376
Validation loss: 2.828860377481403

Epoch: 5| Step: 8
Training loss: 2.956047105984249
Validation loss: 2.8312585866188913

Epoch: 5| Step: 9
Training loss: 3.024606562478513
Validation loss: 2.8296551569045185

Epoch: 5| Step: 10
Training loss: 2.9117193133509987
Validation loss: 2.829314438671385

Epoch: 94| Step: 0
Training loss: 3.1283049845101165
Validation loss: 2.832167925621839

Epoch: 5| Step: 1
Training loss: 3.1368967578207085
Validation loss: 2.8325110629096413

Epoch: 5| Step: 2
Training loss: 2.8226756500920467
Validation loss: 2.8304164656515107

Epoch: 5| Step: 3
Training loss: 3.577265607084944
Validation loss: 2.8299600615394174

Epoch: 5| Step: 4
Training loss: 3.3637965712482822
Validation loss: 2.83060384894985

Epoch: 5| Step: 5
Training loss: 2.9847643533341257
Validation loss: 2.8309815422567377

Epoch: 5| Step: 6
Training loss: 3.0385525233864117
Validation loss: 2.827664142125707

Epoch: 5| Step: 7
Training loss: 3.6209824759989795
Validation loss: 2.828285054575225

Epoch: 5| Step: 8
Training loss: 3.2230341279403425
Validation loss: 2.8269580769396425

Epoch: 5| Step: 9
Training loss: 2.8701485875175017
Validation loss: 2.8268564647483805

Epoch: 5| Step: 10
Training loss: 2.4385568332865857
Validation loss: 2.82666116976692

Epoch: 95| Step: 0
Training loss: 3.2020517923906766
Validation loss: 2.8268900311740808

Epoch: 5| Step: 1
Training loss: 3.146502560468863
Validation loss: 2.831106151735077

Epoch: 5| Step: 2
Training loss: 3.757683194606463
Validation loss: 2.839177981529994

Epoch: 5| Step: 3
Training loss: 2.68524483386712
Validation loss: 2.8414289379438036

Epoch: 5| Step: 4
Training loss: 2.8935561706353776
Validation loss: 2.840661399208569

Epoch: 5| Step: 5
Training loss: 3.365798840863518
Validation loss: 2.8487055459144917

Epoch: 5| Step: 6
Training loss: 3.313907827952233
Validation loss: 2.8349516087787614

Epoch: 5| Step: 7
Training loss: 2.664440497376982
Validation loss: 2.8344587172745386

Epoch: 5| Step: 8
Training loss: 3.2129735872172622
Validation loss: 2.8301007758155357

Epoch: 5| Step: 9
Training loss: 3.1725977182331646
Validation loss: 2.821675748963881

Epoch: 5| Step: 10
Training loss: 2.7565702498832683
Validation loss: 2.823408391792379

Epoch: 96| Step: 0
Training loss: 3.2355997466497644
Validation loss: 2.8216001318493973

Epoch: 5| Step: 1
Training loss: 2.5982122987749894
Validation loss: 2.8220956634168646

Epoch: 5| Step: 2
Training loss: 3.3664892760524823
Validation loss: 2.8211342796566976

Epoch: 5| Step: 3
Training loss: 2.9098463879183964
Validation loss: 2.822577336041317

Epoch: 5| Step: 4
Training loss: 3.562629965034431
Validation loss: 2.822393780249192

Epoch: 5| Step: 5
Training loss: 3.1237404382993637
Validation loss: 2.8198536027502152

Epoch: 5| Step: 6
Training loss: 3.196116152852461
Validation loss: 2.818899587533691

Epoch: 5| Step: 7
Training loss: 2.8348709496891744
Validation loss: 2.8218011500485978

Epoch: 5| Step: 8
Training loss: 3.4549071257235684
Validation loss: 2.820528959884193

Epoch: 5| Step: 9
Training loss: 2.9418808755518127
Validation loss: 2.8185046860374876

Epoch: 5| Step: 10
Training loss: 3.0013386600717697
Validation loss: 2.8183192804128008

Epoch: 97| Step: 0
Training loss: 3.2479044687475573
Validation loss: 2.81822790886839

Epoch: 5| Step: 1
Training loss: 3.0965172307886952
Validation loss: 2.816723183884456

Epoch: 5| Step: 2
Training loss: 2.703564999441899
Validation loss: 2.8192566912297146

Epoch: 5| Step: 3
Training loss: 3.6408796098602454
Validation loss: 2.822247650262969

Epoch: 5| Step: 4
Training loss: 2.8670005633457083
Validation loss: 2.8217228006899155

Epoch: 5| Step: 5
Training loss: 2.8721172973566715
Validation loss: 2.8269250200734706

Epoch: 5| Step: 6
Training loss: 3.4655755441093348
Validation loss: 2.851715225847492

Epoch: 5| Step: 7
Training loss: 3.1671537392787767
Validation loss: 2.826891993654527

Epoch: 5| Step: 8
Training loss: 3.23838373443077
Validation loss: 2.8167272213070094

Epoch: 5| Step: 9
Training loss: 3.3856743034729107
Validation loss: 2.8162674330832353

Epoch: 5| Step: 10
Training loss: 2.361046104533572
Validation loss: 2.8163486431755116

Epoch: 98| Step: 0
Training loss: 2.9080653929776035
Validation loss: 2.821649138243402

Epoch: 5| Step: 1
Training loss: 2.902354593372241
Validation loss: 2.8250316834803373

Epoch: 5| Step: 2
Training loss: 3.0233102224602937
Validation loss: 2.826315147124115

Epoch: 5| Step: 3
Training loss: 3.4723309427830316
Validation loss: 2.833168347698696

Epoch: 5| Step: 4
Training loss: 3.1571735503881486
Validation loss: 2.8273689865363654

Epoch: 5| Step: 5
Training loss: 3.4983494817813283
Validation loss: 2.826672470342599

Epoch: 5| Step: 6
Training loss: 2.8670055529165097
Validation loss: 2.82352200147004

Epoch: 5| Step: 7
Training loss: 3.460880459903124
Validation loss: 2.8193860116577363

Epoch: 5| Step: 8
Training loss: 3.076893826492366
Validation loss: 2.8205944833052894

Epoch: 5| Step: 9
Training loss: 2.8921549279487606
Validation loss: 2.8188898255094066

Epoch: 5| Step: 10
Training loss: 3.1074873979087383
Validation loss: 2.8178038033991677

Epoch: 99| Step: 0
Training loss: 2.3584691007465044
Validation loss: 2.816477649295652

Epoch: 5| Step: 1
Training loss: 3.362103157308065
Validation loss: 2.8161637091680896

Epoch: 5| Step: 2
Training loss: 2.8752393208285416
Validation loss: 2.8144074483455537

Epoch: 5| Step: 3
Training loss: 3.295961226253771
Validation loss: 2.814832327836566

Epoch: 5| Step: 4
Training loss: 2.9915550898268193
Validation loss: 2.811610636587919

Epoch: 5| Step: 5
Training loss: 3.3368479002348543
Validation loss: 2.8203823478747836

Epoch: 5| Step: 6
Training loss: 3.236989020007546
Validation loss: 2.826559422645487

Epoch: 5| Step: 7
Training loss: 3.1424744887063776
Validation loss: 2.8327560421803124

Epoch: 5| Step: 8
Training loss: 3.066353689338547
Validation loss: 2.8207885896653084

Epoch: 5| Step: 9
Training loss: 3.0342562211239987
Validation loss: 2.8158752852066544

Epoch: 5| Step: 10
Training loss: 3.5261761157474223
Validation loss: 2.816520533515025

Epoch: 100| Step: 0
Training loss: 2.3994768605691403
Validation loss: 2.8136856934160464

Epoch: 5| Step: 1
Training loss: 3.0794746035027085
Validation loss: 2.8116803322746557

Epoch: 5| Step: 2
Training loss: 2.8594925653021144
Validation loss: 2.812560467542868

Epoch: 5| Step: 3
Training loss: 2.7314746406407253
Validation loss: 2.814157135861265

Epoch: 5| Step: 4
Training loss: 3.2646795483018827
Validation loss: 2.8130185960584027

Epoch: 5| Step: 5
Training loss: 3.3355651218814497
Validation loss: 2.811114563610784

Epoch: 5| Step: 6
Training loss: 3.645458107667444
Validation loss: 2.8133998711942683

Epoch: 5| Step: 7
Training loss: 2.8356573633806885
Validation loss: 2.811766883710193

Epoch: 5| Step: 8
Training loss: 3.09910059156258
Validation loss: 2.8108981439469627

Epoch: 5| Step: 9
Training loss: 3.252820038586546
Validation loss: 2.810237168379968

Epoch: 5| Step: 10
Training loss: 3.6650458279147524
Validation loss: 2.8125154838910578

Epoch: 101| Step: 0
Training loss: 3.272658080034252
Validation loss: 2.8156261557583875

Epoch: 5| Step: 1
Training loss: 3.7497704753569767
Validation loss: 2.812000891221643

Epoch: 5| Step: 2
Training loss: 2.671040811876014
Validation loss: 2.8061048349784303

Epoch: 5| Step: 3
Training loss: 2.6940811661725297
Validation loss: 2.8065618177017684

Epoch: 5| Step: 4
Training loss: 3.016157824629091
Validation loss: 2.8065036489037594

Epoch: 5| Step: 5
Training loss: 3.01239188225817
Validation loss: 2.8095076700188613

Epoch: 5| Step: 6
Training loss: 2.885492004806502
Validation loss: 2.8054929087520892

Epoch: 5| Step: 7
Training loss: 3.7691049285314775
Validation loss: 2.8044802850554906

Epoch: 5| Step: 8
Training loss: 2.578422575451917
Validation loss: 2.8039991096297507

Epoch: 5| Step: 9
Training loss: 3.5091364004085626
Validation loss: 2.807237852946285

Epoch: 5| Step: 10
Training loss: 2.7281963186129157
Validation loss: 2.8045382947170436

Epoch: 102| Step: 0
Training loss: 3.666624040066869
Validation loss: 2.8044405313817964

Epoch: 5| Step: 1
Training loss: 3.350487169740718
Validation loss: 2.8048283250284096

Epoch: 5| Step: 2
Training loss: 3.037732772385244
Validation loss: 2.806998711975446

Epoch: 5| Step: 3
Training loss: 2.8098493165039153
Validation loss: 2.807050462905459

Epoch: 5| Step: 4
Training loss: 2.99012306649054
Validation loss: 2.8172129940443504

Epoch: 5| Step: 5
Training loss: 3.166175871175952
Validation loss: 2.8104557898628593

Epoch: 5| Step: 6
Training loss: 3.259896103777216
Validation loss: 2.8097885533931968

Epoch: 5| Step: 7
Training loss: 2.7690666034936284
Validation loss: 2.805186505349265

Epoch: 5| Step: 8
Training loss: 2.9595019400903317
Validation loss: 2.818696687084735

Epoch: 5| Step: 9
Training loss: 3.3970091174758226
Validation loss: 2.810030287864505

Epoch: 5| Step: 10
Training loss: 2.5744512102812616
Validation loss: 2.8023493434246025

Epoch: 103| Step: 0
Training loss: 2.9429112367248202
Validation loss: 2.801598465119941

Epoch: 5| Step: 1
Training loss: 3.1366378754751456
Validation loss: 2.802115120467105

Epoch: 5| Step: 2
Training loss: 3.258079023916766
Validation loss: 2.8029404824422666

Epoch: 5| Step: 3
Training loss: 3.1897655738147206
Validation loss: 2.8013889745343974

Epoch: 5| Step: 4
Training loss: 2.815250408221697
Validation loss: 2.8015827525196726

Epoch: 5| Step: 5
Training loss: 2.859080148305324
Validation loss: 2.803460861492554

Epoch: 5| Step: 6
Training loss: 3.658137950734166
Validation loss: 2.803492656935339

Epoch: 5| Step: 7
Training loss: 3.6938376840682476
Validation loss: 2.8033585997094916

Epoch: 5| Step: 8
Training loss: 2.3080175103394356
Validation loss: 2.8054990156260957

Epoch: 5| Step: 9
Training loss: 3.192545021116073
Validation loss: 2.8028045859312067

Epoch: 5| Step: 10
Training loss: 2.9624987187765064
Validation loss: 2.8054167549259015

Epoch: 104| Step: 0
Training loss: 2.4838383892825004
Validation loss: 2.827045059304721

Epoch: 5| Step: 1
Training loss: 2.7751422639413508
Validation loss: 2.839856166259246

Epoch: 5| Step: 2
Training loss: 3.210988881983201
Validation loss: 2.8491616812127614

Epoch: 5| Step: 3
Training loss: 3.6311727124917006
Validation loss: 2.8321067895599112

Epoch: 5| Step: 4
Training loss: 3.3319808759380938
Validation loss: 2.8007530714073376

Epoch: 5| Step: 5
Training loss: 3.3037761757340864
Validation loss: 2.800792240352323

Epoch: 5| Step: 6
Training loss: 2.919154568392198
Validation loss: 2.801946335128113

Epoch: 5| Step: 7
Training loss: 3.125034789845409
Validation loss: 2.8019129063176367

Epoch: 5| Step: 8
Training loss: 2.9353374881141723
Validation loss: 2.8000676690038957

Epoch: 5| Step: 9
Training loss: 3.5248648380852874
Validation loss: 2.802366292213138

Epoch: 5| Step: 10
Training loss: 2.827253344340315
Validation loss: 2.8052001579652974

Epoch: 105| Step: 0
Training loss: 3.053343338124016
Validation loss: 2.8054652828168933

Epoch: 5| Step: 1
Training loss: 2.707911404731108
Validation loss: 2.806304729541977

Epoch: 5| Step: 2
Training loss: 2.760062275335995
Validation loss: 2.804595946685395

Epoch: 5| Step: 3
Training loss: 2.8315116037262027
Validation loss: 2.797266621251266

Epoch: 5| Step: 4
Training loss: 3.5903743646461304
Validation loss: 2.806281841894129

Epoch: 5| Step: 5
Training loss: 3.1458884396473805
Validation loss: 2.8084630453566355

Epoch: 5| Step: 6
Training loss: 3.3386896649118
Validation loss: 2.8022866794958365

Epoch: 5| Step: 7
Training loss: 3.041862551160287
Validation loss: 2.7946487231021786

Epoch: 5| Step: 8
Training loss: 3.2633200363911765
Validation loss: 2.7899888631758873

Epoch: 5| Step: 9
Training loss: 2.937058111190642
Validation loss: 2.7887054276371566

Epoch: 5| Step: 10
Training loss: 3.3839168728116844
Validation loss: 2.792344909201445

Epoch: 106| Step: 0
Training loss: 3.718481230439763
Validation loss: 2.798018424748221

Epoch: 5| Step: 1
Training loss: 3.164814122724506
Validation loss: 2.8016497631128807

Epoch: 5| Step: 2
Training loss: 3.1340293138370985
Validation loss: 2.790529673097581

Epoch: 5| Step: 3
Training loss: 2.325028786429762
Validation loss: 2.7890249771255555

Epoch: 5| Step: 4
Training loss: 3.3737889695575802
Validation loss: 2.7881600342961805

Epoch: 5| Step: 5
Training loss: 2.918558941945052
Validation loss: 2.7897787277783213

Epoch: 5| Step: 6
Training loss: 3.3023084369230626
Validation loss: 2.7911081271130254

Epoch: 5| Step: 7
Training loss: 2.787993838096826
Validation loss: 2.7960471154341437

Epoch: 5| Step: 8
Training loss: 2.9326758847251826
Validation loss: 2.8027446250275037

Epoch: 5| Step: 9
Training loss: 2.979662304888236
Validation loss: 2.8092593575089775

Epoch: 5| Step: 10
Training loss: 3.4335869451635497
Validation loss: 2.802126289023479

Epoch: 107| Step: 0
Training loss: 3.4243333599345926
Validation loss: 2.79840239588954

Epoch: 5| Step: 1
Training loss: 2.5856031679998006
Validation loss: 2.7927675649311157

Epoch: 5| Step: 2
Training loss: 2.7292476865278688
Validation loss: 2.7905354893381698

Epoch: 5| Step: 3
Training loss: 2.8728427256879354
Validation loss: 2.7886943105906257

Epoch: 5| Step: 4
Training loss: 2.9267612338881404
Validation loss: 2.78671068519548

Epoch: 5| Step: 5
Training loss: 3.6952354632809743
Validation loss: 2.789795318280625

Epoch: 5| Step: 6
Training loss: 3.399528521216573
Validation loss: 2.7896568037653875

Epoch: 5| Step: 7
Training loss: 2.620139390280508
Validation loss: 2.7974949145886447

Epoch: 5| Step: 8
Training loss: 2.988965084644128
Validation loss: 2.8020042810535815

Epoch: 5| Step: 9
Training loss: 3.3080774690351036
Validation loss: 2.813123715880052

Epoch: 5| Step: 10
Training loss: 3.4184995402589258
Validation loss: 2.8232687205504408

Epoch: 108| Step: 0
Training loss: 3.5092745921988135
Validation loss: 2.83149863298654

Epoch: 5| Step: 1
Training loss: 2.5078389294143735
Validation loss: 2.8370764116187286

Epoch: 5| Step: 2
Training loss: 2.9286277380125396
Validation loss: 2.832675944134835

Epoch: 5| Step: 3
Training loss: 3.0539865299270046
Validation loss: 2.845500721312159

Epoch: 5| Step: 4
Training loss: 3.523232599969978
Validation loss: 2.81755392822066

Epoch: 5| Step: 5
Training loss: 3.668342741891066
Validation loss: 2.7842556551979167

Epoch: 5| Step: 6
Training loss: 2.743298080174565
Validation loss: 2.7854154300198384

Epoch: 5| Step: 7
Training loss: 3.1421286556096524
Validation loss: 2.7901196320339756

Epoch: 5| Step: 8
Training loss: 2.850453785691463
Validation loss: 2.7976891034072153

Epoch: 5| Step: 9
Training loss: 2.5212112858021736
Validation loss: 2.8066500706564783

Epoch: 5| Step: 10
Training loss: 3.5369396453358566
Validation loss: 2.8249620798796404

Epoch: 109| Step: 0
Training loss: 3.041002140003017
Validation loss: 2.797340513357913

Epoch: 5| Step: 1
Training loss: 2.7208045124515667
Validation loss: 2.7990636016412664

Epoch: 5| Step: 2
Training loss: 3.574404452143042
Validation loss: 2.7957833953745626

Epoch: 5| Step: 3
Training loss: 3.4440489374421053
Validation loss: 2.790717769190989

Epoch: 5| Step: 4
Training loss: 3.2546876699490626
Validation loss: 2.790267954529992

Epoch: 5| Step: 5
Training loss: 2.9595831438318987
Validation loss: 2.7922987497083414

Epoch: 5| Step: 6
Training loss: 2.9202948392657526
Validation loss: 2.791992116797678

Epoch: 5| Step: 7
Training loss: 3.156481139529286
Validation loss: 2.794727387495022

Epoch: 5| Step: 8
Training loss: 2.6385610968025848
Validation loss: 2.7970194226758145

Epoch: 5| Step: 9
Training loss: 2.915577021916509
Validation loss: 2.7991440781038226

Epoch: 5| Step: 10
Training loss: 3.5083862379227577
Validation loss: 2.8031632982910666

Epoch: 110| Step: 0
Training loss: 2.9805239451085983
Validation loss: 2.803091411695949

Epoch: 5| Step: 1
Training loss: 2.883540364000954
Validation loss: 2.804316329515472

Epoch: 5| Step: 2
Training loss: 2.5585102562712763
Validation loss: 2.79925076345875

Epoch: 5| Step: 3
Training loss: 3.4360015377445356
Validation loss: 2.790662874920348

Epoch: 5| Step: 4
Training loss: 3.026151478931202
Validation loss: 2.7906100465708086

Epoch: 5| Step: 5
Training loss: 2.7000137681963228
Validation loss: 2.7858511516886395

Epoch: 5| Step: 6
Training loss: 2.8962366020014576
Validation loss: 2.7824764121743093

Epoch: 5| Step: 7
Training loss: 3.4409791852459524
Validation loss: 2.7837521675663157

Epoch: 5| Step: 8
Training loss: 3.6967004342997756
Validation loss: 2.782960602794408

Epoch: 5| Step: 9
Training loss: 3.0515839012946415
Validation loss: 2.782607653850774

Epoch: 5| Step: 10
Training loss: 3.312501871360394
Validation loss: 2.7799359021935013

Epoch: 111| Step: 0
Training loss: 3.2788603300669754
Validation loss: 2.7839196410003546

Epoch: 5| Step: 1
Training loss: 3.0231914568006863
Validation loss: 2.7830878473402993

Epoch: 5| Step: 2
Training loss: 3.12143320617631
Validation loss: 2.7819263022664886

Epoch: 5| Step: 3
Training loss: 2.6186718731062513
Validation loss: 2.7903754689393683

Epoch: 5| Step: 4
Training loss: 3.126171197763656
Validation loss: 2.794193005987739

Epoch: 5| Step: 5
Training loss: 3.244026416327639
Validation loss: 2.8041852655107706

Epoch: 5| Step: 6
Training loss: 3.3639879359279585
Validation loss: 2.7977415809174686

Epoch: 5| Step: 7
Training loss: 3.120688706948559
Validation loss: 2.803603156325651

Epoch: 5| Step: 8
Training loss: 2.536819171239519
Validation loss: 2.7832889196949124

Epoch: 5| Step: 9
Training loss: 3.6305755619223294
Validation loss: 2.7754927053948952

Epoch: 5| Step: 10
Training loss: 2.696212043477355
Validation loss: 2.7785315792808394

Epoch: 112| Step: 0
Training loss: 3.4210429813079015
Validation loss: 2.776216565438449

Epoch: 5| Step: 1
Training loss: 2.6586476892497393
Validation loss: 2.777323794405374

Epoch: 5| Step: 2
Training loss: 2.991093129158603
Validation loss: 2.7734483149316342

Epoch: 5| Step: 3
Training loss: 2.8297696047434986
Validation loss: 2.7754141257887963

Epoch: 5| Step: 4
Training loss: 2.5095394284923995
Validation loss: 2.77492544725721

Epoch: 5| Step: 5
Training loss: 3.649013302311234
Validation loss: 2.7748437528736565

Epoch: 5| Step: 6
Training loss: 3.227725357473335
Validation loss: 2.775813491464243

Epoch: 5| Step: 7
Training loss: 3.173029046042026
Validation loss: 2.773479107676512

Epoch: 5| Step: 8
Training loss: 2.55498388595128
Validation loss: 2.774802569404177

Epoch: 5| Step: 9
Training loss: 3.3579088427114088
Validation loss: 2.7751156144030142

Epoch: 5| Step: 10
Training loss: 3.4314890238016487
Validation loss: 2.774444378820555

Epoch: 113| Step: 0
Training loss: 3.092874113997235
Validation loss: 2.7782499201963557

Epoch: 5| Step: 1
Training loss: 3.4660712543874115
Validation loss: 2.7812063709877557

Epoch: 5| Step: 2
Training loss: 2.880653130858894
Validation loss: 2.7823331059766967

Epoch: 5| Step: 3
Training loss: 3.2968867152579917
Validation loss: 2.7849598074200816

Epoch: 5| Step: 4
Training loss: 3.0803524420092234
Validation loss: 2.786916321883996

Epoch: 5| Step: 5
Training loss: 3.3468878452827435
Validation loss: 2.793307526661326

Epoch: 5| Step: 6
Training loss: 2.8428702198721862
Validation loss: 2.7987832897756415

Epoch: 5| Step: 7
Training loss: 3.3885663370633177
Validation loss: 2.7977531998947107

Epoch: 5| Step: 8
Training loss: 2.922098243059231
Validation loss: 2.777872215087649

Epoch: 5| Step: 9
Training loss: 2.84150724737588
Validation loss: 2.7676477559181802

Epoch: 5| Step: 10
Training loss: 2.6630486044034725
Validation loss: 2.769160692372205

Epoch: 114| Step: 0
Training loss: 3.112450999904519
Validation loss: 2.768767720716247

Epoch: 5| Step: 1
Training loss: 2.9254839635346555
Validation loss: 2.7687921943654055

Epoch: 5| Step: 2
Training loss: 2.723868451845012
Validation loss: 2.7687987423631832

Epoch: 5| Step: 3
Training loss: 3.0929380950603407
Validation loss: 2.769943162472608

Epoch: 5| Step: 4
Training loss: 3.3444146182088086
Validation loss: 2.7709540199669567

Epoch: 5| Step: 5
Training loss: 3.303915163516588
Validation loss: 2.77276143776201

Epoch: 5| Step: 6
Training loss: 3.4682887689995563
Validation loss: 2.766067086711906

Epoch: 5| Step: 7
Training loss: 3.090401426739503
Validation loss: 2.7687772353915694

Epoch: 5| Step: 8
Training loss: 2.7826333195501265
Validation loss: 2.770726082411813

Epoch: 5| Step: 9
Training loss: 2.901066906109817
Validation loss: 2.76771797048419

Epoch: 5| Step: 10
Training loss: 3.1121882454880527
Validation loss: 2.771914636054073

Epoch: 115| Step: 0
Training loss: 3.5977636066534933
Validation loss: 2.762594347936849

Epoch: 5| Step: 1
Training loss: 2.7427605793621734
Validation loss: 2.7631911287466178

Epoch: 5| Step: 2
Training loss: 3.5002330974887044
Validation loss: 2.764589564860914

Epoch: 5| Step: 3
Training loss: 3.147360946577235
Validation loss: 2.7644017673414236

Epoch: 5| Step: 4
Training loss: 2.679987587544179
Validation loss: 2.7630873728710554

Epoch: 5| Step: 5
Training loss: 2.960112041466449
Validation loss: 2.761630138947024

Epoch: 5| Step: 6
Training loss: 2.905371420354024
Validation loss: 2.76524579110119

Epoch: 5| Step: 7
Training loss: 2.9412575895679245
Validation loss: 2.770209770962383

Epoch: 5| Step: 8
Training loss: 2.910316165908246
Validation loss: 2.7747839139487236

Epoch: 5| Step: 9
Training loss: 3.215991866201107
Validation loss: 2.773226208446944

Epoch: 5| Step: 10
Training loss: 3.1213077858497624
Validation loss: 2.7708707374073134

Epoch: 116| Step: 0
Training loss: 3.42269344209492
Validation loss: 2.767825226202547

Epoch: 5| Step: 1
Training loss: 2.9418703399549977
Validation loss: 2.760013796259275

Epoch: 5| Step: 2
Training loss: 3.288451801788426
Validation loss: 2.7594089878379444

Epoch: 5| Step: 3
Training loss: 3.0206172120404142
Validation loss: 2.7633762968148807

Epoch: 5| Step: 4
Training loss: 3.274513814233266
Validation loss: 2.7589376885397825

Epoch: 5| Step: 5
Training loss: 2.8872634724765023
Validation loss: 2.7625153355489935

Epoch: 5| Step: 6
Training loss: 2.411500626942211
Validation loss: 2.76129305381015

Epoch: 5| Step: 7
Training loss: 2.9794697818520057
Validation loss: 2.7607950357956637

Epoch: 5| Step: 8
Training loss: 2.9868597900871827
Validation loss: 2.758336911113805

Epoch: 5| Step: 9
Training loss: 3.2745483261691954
Validation loss: 2.7576228325258065

Epoch: 5| Step: 10
Training loss: 3.2508235768205425
Validation loss: 2.7574263464470183

Epoch: 117| Step: 0
Training loss: 2.979278366733598
Validation loss: 2.7652987813879597

Epoch: 5| Step: 1
Training loss: 2.7236826205836975
Validation loss: 2.768335362924498

Epoch: 5| Step: 2
Training loss: 3.473125001318017
Validation loss: 2.7866100838462913

Epoch: 5| Step: 3
Training loss: 2.423560558861838
Validation loss: 2.812552232154751

Epoch: 5| Step: 4
Training loss: 3.0229879828746413
Validation loss: 2.8388427327851997

Epoch: 5| Step: 5
Training loss: 2.881848678121193
Validation loss: 2.8214970428337383

Epoch: 5| Step: 6
Training loss: 2.90721491720669
Validation loss: 2.7654785948060026

Epoch: 5| Step: 7
Training loss: 3.342870578808734
Validation loss: 2.764421821780799

Epoch: 5| Step: 8
Training loss: 3.1044379676867186
Validation loss: 2.758551073552892

Epoch: 5| Step: 9
Training loss: 3.1227259181737645
Validation loss: 2.7595771851957864

Epoch: 5| Step: 10
Training loss: 3.7875925889988826
Validation loss: 2.75996435402466

Epoch: 118| Step: 0
Training loss: 2.75031876883948
Validation loss: 2.760198546831707

Epoch: 5| Step: 1
Training loss: 2.7188793458534253
Validation loss: 2.7626887556038615

Epoch: 5| Step: 2
Training loss: 3.409575352782764
Validation loss: 2.760851046716024

Epoch: 5| Step: 3
Training loss: 3.4161746128221444
Validation loss: 2.762870815506933

Epoch: 5| Step: 4
Training loss: 3.146882309663649
Validation loss: 2.762786955233392

Epoch: 5| Step: 5
Training loss: 2.6619954522120537
Validation loss: 2.762721209582173

Epoch: 5| Step: 6
Training loss: 3.0944200811182268
Validation loss: 2.7622019604992163

Epoch: 5| Step: 7
Training loss: 3.034856008165035
Validation loss: 2.761399387457974

Epoch: 5| Step: 8
Training loss: 3.0776252147199914
Validation loss: 2.758923207647127

Epoch: 5| Step: 9
Training loss: 3.3964211982875088
Validation loss: 2.7572233043664833

Epoch: 5| Step: 10
Training loss: 3.1361673328851505
Validation loss: 2.7582013181655296

Epoch: 119| Step: 0
Training loss: 2.705163881340361
Validation loss: 2.758876391397214

Epoch: 5| Step: 1
Training loss: 2.999519945518691
Validation loss: 2.759679243916005

Epoch: 5| Step: 2
Training loss: 2.978247938790877
Validation loss: 2.7567223359655646

Epoch: 5| Step: 3
Training loss: 2.830031284658096
Validation loss: 2.7549723701259565

Epoch: 5| Step: 4
Training loss: 3.3338831130272286
Validation loss: 2.7616260367552705

Epoch: 5| Step: 5
Training loss: 3.078606272605523
Validation loss: 2.759341956689023

Epoch: 5| Step: 6
Training loss: 3.365497634163709
Validation loss: 2.763492647205845

Epoch: 5| Step: 7
Training loss: 3.342893258972136
Validation loss: 2.765380792048142

Epoch: 5| Step: 8
Training loss: 2.9450196138256652
Validation loss: 2.768249532635299

Epoch: 5| Step: 9
Training loss: 3.291457801340891
Validation loss: 2.7704950891503235

Epoch: 5| Step: 10
Training loss: 2.7726409197974946
Validation loss: 2.7673714997054324

Epoch: 120| Step: 0
Training loss: 3.69750214881654
Validation loss: 2.7679759788719216

Epoch: 5| Step: 1
Training loss: 3.190947220660201
Validation loss: 2.7663558792321554

Epoch: 5| Step: 2
Training loss: 3.2123132436177624
Validation loss: 2.756475814949452

Epoch: 5| Step: 3
Training loss: 2.964566947872071
Validation loss: 2.754482120931156

Epoch: 5| Step: 4
Training loss: 2.7936408241325967
Validation loss: 2.7538751983695606

Epoch: 5| Step: 5
Training loss: 2.6505800655975413
Validation loss: 2.7539270501888358

Epoch: 5| Step: 6
Training loss: 2.7264550305366893
Validation loss: 2.753204976473963

Epoch: 5| Step: 7
Training loss: 3.31671090855316
Validation loss: 2.7520000981519015

Epoch: 5| Step: 8
Training loss: 2.823328239214136
Validation loss: 2.748935301316849

Epoch: 5| Step: 9
Training loss: 3.100742029781566
Validation loss: 2.752487896525701

Epoch: 5| Step: 10
Training loss: 3.1915985385671983
Validation loss: 2.749759021205434

Epoch: 121| Step: 0
Training loss: 3.2982536434540046
Validation loss: 2.7532183011661067

Epoch: 5| Step: 1
Training loss: 3.299567980375113
Validation loss: 2.7477896953876244

Epoch: 5| Step: 2
Training loss: 2.8457966241288783
Validation loss: 2.7498894582552387

Epoch: 5| Step: 3
Training loss: 2.948037907743583
Validation loss: 2.752817181991659

Epoch: 5| Step: 4
Training loss: 3.8262910147671074
Validation loss: 2.7487735716991364

Epoch: 5| Step: 5
Training loss: 3.4839211754274517
Validation loss: 2.7548089476013224

Epoch: 5| Step: 6
Training loss: 2.0342445015253414
Validation loss: 2.766498398794191

Epoch: 5| Step: 7
Training loss: 2.580967763475525
Validation loss: 2.753531042316439

Epoch: 5| Step: 8
Training loss: 3.2418903996028474
Validation loss: 2.758448821603412

Epoch: 5| Step: 9
Training loss: 3.1117887856361865
Validation loss: 2.7503142340480533

Epoch: 5| Step: 10
Training loss: 2.5243266992559454
Validation loss: 2.751289000324595

Epoch: 122| Step: 0
Training loss: 3.401159279597242
Validation loss: 2.7476142843497993

Epoch: 5| Step: 1
Training loss: 2.7476891431881434
Validation loss: 2.7433684553824356

Epoch: 5| Step: 2
Training loss: 2.7818138322552537
Validation loss: 2.7437747040316034

Epoch: 5| Step: 3
Training loss: 3.4843013738542727
Validation loss: 2.7417092813301265

Epoch: 5| Step: 4
Training loss: 2.8102986515755517
Validation loss: 2.7414868608491703

Epoch: 5| Step: 5
Training loss: 2.9671925525110026
Validation loss: 2.7437628859044207

Epoch: 5| Step: 6
Training loss: 2.5340864513496415
Validation loss: 2.7423462002763714

Epoch: 5| Step: 7
Training loss: 2.535158318987503
Validation loss: 2.744274046621298

Epoch: 5| Step: 8
Training loss: 3.748840915840558
Validation loss: 2.7417036018186427

Epoch: 5| Step: 9
Training loss: 3.388475712531956
Validation loss: 2.7411769709635947

Epoch: 5| Step: 10
Training loss: 3.0271422879034575
Validation loss: 2.7423850872582727

Epoch: 123| Step: 0
Training loss: 2.9758564269288676
Validation loss: 2.738809106928017

Epoch: 5| Step: 1
Training loss: 3.33133166930553
Validation loss: 2.7378185493875122

Epoch: 5| Step: 2
Training loss: 3.24571679379042
Validation loss: 2.737791904543107

Epoch: 5| Step: 3
Training loss: 2.8377795581651064
Validation loss: 2.7383559586035755

Epoch: 5| Step: 4
Training loss: 3.074788255301722
Validation loss: 2.7402536960187556

Epoch: 5| Step: 5
Training loss: 2.8358016388771965
Validation loss: 2.742578093068744

Epoch: 5| Step: 6
Training loss: 2.90300692840706
Validation loss: 2.7443700653687277

Epoch: 5| Step: 7
Training loss: 3.096776233564751
Validation loss: 2.746725772355026

Epoch: 5| Step: 8
Training loss: 2.955319189915402
Validation loss: 2.7496177653806972

Epoch: 5| Step: 9
Training loss: 3.4866309282891614
Validation loss: 2.7505187219388727

Epoch: 5| Step: 10
Training loss: 2.741383404771092
Validation loss: 2.752113497784261

Epoch: 124| Step: 0
Training loss: 2.9271737262348423
Validation loss: 2.7369770772719195

Epoch: 5| Step: 1
Training loss: 3.0434717196044763
Validation loss: 2.737534738266765

Epoch: 5| Step: 2
Training loss: 2.8533535283999116
Validation loss: 2.7382927617681916

Epoch: 5| Step: 3
Training loss: 2.5420364569474034
Validation loss: 2.7359762342971963

Epoch: 5| Step: 4
Training loss: 3.261527671470843
Validation loss: 2.7349042960875045

Epoch: 5| Step: 5
Training loss: 3.7219908881221953
Validation loss: 2.7373470682289356

Epoch: 5| Step: 6
Training loss: 3.3680840734648734
Validation loss: 2.736299476603267

Epoch: 5| Step: 7
Training loss: 2.866966800355103
Validation loss: 2.7344168757969167

Epoch: 5| Step: 8
Training loss: 3.3836804128931384
Validation loss: 2.738734677464916

Epoch: 5| Step: 9
Training loss: 2.586490353035169
Validation loss: 2.7380684224293743

Epoch: 5| Step: 10
Training loss: 2.80635144702403
Validation loss: 2.737110997006425

Epoch: 125| Step: 0
Training loss: 3.205652644558277
Validation loss: 2.7371688216156147

Epoch: 5| Step: 1
Training loss: 2.758719924465524
Validation loss: 2.7355392110581045

Epoch: 5| Step: 2
Training loss: 3.423871855557151
Validation loss: 2.734605125669946

Epoch: 5| Step: 3
Training loss: 3.1440141146005716
Validation loss: 2.7378047911103205

Epoch: 5| Step: 4
Training loss: 2.552716442649333
Validation loss: 2.74528220577501

Epoch: 5| Step: 5
Training loss: 3.4148089467973812
Validation loss: 2.7434059037366425

Epoch: 5| Step: 6
Training loss: 2.6121677826275187
Validation loss: 2.742236045545826

Epoch: 5| Step: 7
Training loss: 3.8239989173680136
Validation loss: 2.744294372392497

Epoch: 5| Step: 8
Training loss: 2.7714872998685234
Validation loss: 2.7359732227412352

Epoch: 5| Step: 9
Training loss: 3.086528325561291
Validation loss: 2.730705960618596

Epoch: 5| Step: 10
Training loss: 2.3459364801183344
Validation loss: 2.7321681995633

Epoch: 126| Step: 0
Training loss: 3.465745604250807
Validation loss: 2.7326894789161704

Epoch: 5| Step: 1
Training loss: 3.167126638903248
Validation loss: 2.7307013669697886

Epoch: 5| Step: 2
Training loss: 3.05874185215746
Validation loss: 2.727857671426368

Epoch: 5| Step: 3
Training loss: 2.9929988547901902
Validation loss: 2.7325966190032522

Epoch: 5| Step: 4
Training loss: 3.5551384608349657
Validation loss: 2.7298362243762693

Epoch: 5| Step: 5
Training loss: 2.991316945099606
Validation loss: 2.7331138991216495

Epoch: 5| Step: 6
Training loss: 2.85757790046297
Validation loss: 2.733232359392956

Epoch: 5| Step: 7
Training loss: 2.7440555654354943
Validation loss: 2.734229865609944

Epoch: 5| Step: 8
Training loss: 2.9235061743462127
Validation loss: 2.7415013253681524

Epoch: 5| Step: 9
Training loss: 2.8720067239964227
Validation loss: 2.753987176596702

Epoch: 5| Step: 10
Training loss: 2.8357133592876558
Validation loss: 2.7626109235197576

Epoch: 127| Step: 0
Training loss: 3.0127867945997036
Validation loss: 2.7464896139805615

Epoch: 5| Step: 1
Training loss: 2.9673516443539345
Validation loss: 2.7460010964367876

Epoch: 5| Step: 2
Training loss: 3.252123505765568
Validation loss: 2.7328651631171192

Epoch: 5| Step: 3
Training loss: 3.059367699463407
Validation loss: 2.7372637896430314

Epoch: 5| Step: 4
Training loss: 3.087477365016979
Validation loss: 2.732195170422094

Epoch: 5| Step: 5
Training loss: 2.7327483652221827
Validation loss: 2.7328339333846037

Epoch: 5| Step: 6
Training loss: 3.317815294842146
Validation loss: 2.7303686950895845

Epoch: 5| Step: 7
Training loss: 3.1451498809178395
Validation loss: 2.729225729802871

Epoch: 5| Step: 8
Training loss: 3.4606201853071896
Validation loss: 2.7300799749371283

Epoch: 5| Step: 9
Training loss: 2.833380268680546
Validation loss: 2.7271784450940504

Epoch: 5| Step: 10
Training loss: 2.540527672211323
Validation loss: 2.7274752775968047

Epoch: 128| Step: 0
Training loss: 3.2088681720629646
Validation loss: 2.726883527301625

Epoch: 5| Step: 1
Training loss: 3.465638973665401
Validation loss: 2.7295881908826343

Epoch: 5| Step: 2
Training loss: 2.8340116324714333
Validation loss: 2.7321357917688545

Epoch: 5| Step: 3
Training loss: 3.1596640072631055
Validation loss: 2.7327194227191307

Epoch: 5| Step: 4
Training loss: 2.4277288754463053
Validation loss: 2.7407983566689027

Epoch: 5| Step: 5
Training loss: 2.7175797322498663
Validation loss: 2.735362617049846

Epoch: 5| Step: 6
Training loss: 3.4298875615678073
Validation loss: 2.7408750487923035

Epoch: 5| Step: 7
Training loss: 2.7081363508531124
Validation loss: 2.739527969677447

Epoch: 5| Step: 8
Training loss: 3.0283344838027015
Validation loss: 2.7395976304176735

Epoch: 5| Step: 9
Training loss: 2.8673431603692654
Validation loss: 2.7262987631670588

Epoch: 5| Step: 10
Training loss: 3.535495602669326
Validation loss: 2.7330718110692436

Epoch: 129| Step: 0
Training loss: 3.08497113899073
Validation loss: 2.730920598293558

Epoch: 5| Step: 1
Training loss: 3.3125287900429305
Validation loss: 2.7356411750850156

Epoch: 5| Step: 2
Training loss: 2.6191076721803785
Validation loss: 2.7379645178942105

Epoch: 5| Step: 3
Training loss: 2.617159350798947
Validation loss: 2.7360319671613973

Epoch: 5| Step: 4
Training loss: 2.8545636831407277
Validation loss: 2.733091740832437

Epoch: 5| Step: 5
Training loss: 3.249158016590215
Validation loss: 2.728938558088904

Epoch: 5| Step: 6
Training loss: 2.9644143015930244
Validation loss: 2.728056102978833

Epoch: 5| Step: 7
Training loss: 3.1341730906603162
Validation loss: 2.721785104745668

Epoch: 5| Step: 8
Training loss: 3.016259635596885
Validation loss: 2.720700725033786

Epoch: 5| Step: 9
Training loss: 3.3109779459853352
Validation loss: 2.718533937447076

Epoch: 5| Step: 10
Training loss: 3.2460305842417765
Validation loss: 2.7178907996907427

Epoch: 130| Step: 0
Training loss: 3.0636918220614824
Validation loss: 2.7199694037360356

Epoch: 5| Step: 1
Training loss: 3.4351654448222404
Validation loss: 2.71964511885999

Epoch: 5| Step: 2
Training loss: 2.8010953463717247
Validation loss: 2.718399296801314

Epoch: 5| Step: 3
Training loss: 2.8808896648301707
Validation loss: 2.7221351249924783

Epoch: 5| Step: 4
Training loss: 3.1903160969410034
Validation loss: 2.7217899960112693

Epoch: 5| Step: 5
Training loss: 3.3939216865401707
Validation loss: 2.735915466565822

Epoch: 5| Step: 6
Training loss: 2.8438703909740997
Validation loss: 2.750436520726555

Epoch: 5| Step: 7
Training loss: 3.0136600081283698
Validation loss: 2.741652167761572

Epoch: 5| Step: 8
Training loss: 2.804896269867532
Validation loss: 2.7429028360320333

Epoch: 5| Step: 9
Training loss: 2.53963034515637
Validation loss: 2.7378684458548093

Epoch: 5| Step: 10
Training loss: 3.4355522880056135
Validation loss: 2.7275280514347218

Epoch: 131| Step: 0
Training loss: 3.1001880588709794
Validation loss: 2.7302923923528764

Epoch: 5| Step: 1
Training loss: 2.966546455548068
Validation loss: 2.725833360817442

Epoch: 5| Step: 2
Training loss: 2.944609297529996
Validation loss: 2.7278477433611172

Epoch: 5| Step: 3
Training loss: 2.7315959650199515
Validation loss: 2.7238826409830845

Epoch: 5| Step: 4
Training loss: 2.534218919042427
Validation loss: 2.717116575609152

Epoch: 5| Step: 5
Training loss: 3.0853173514039867
Validation loss: 2.715406806202812

Epoch: 5| Step: 6
Training loss: 3.3573781310777404
Validation loss: 2.718275591032285

Epoch: 5| Step: 7
Training loss: 3.1575533753487477
Validation loss: 2.7194990673311965

Epoch: 5| Step: 8
Training loss: 2.8322262190430623
Validation loss: 2.7240316234116855

Epoch: 5| Step: 9
Training loss: 3.3658182497781355
Validation loss: 2.718903373755121

Epoch: 5| Step: 10
Training loss: 3.2733828738077064
Validation loss: 2.715603660003937

Epoch: 132| Step: 0
Training loss: 3.06831026675374
Validation loss: 2.7174385381528587

Epoch: 5| Step: 1
Training loss: 3.0387526013368293
Validation loss: 2.7135104963965464

Epoch: 5| Step: 2
Training loss: 2.683540177122874
Validation loss: 2.7117714772461396

Epoch: 5| Step: 3
Training loss: 2.8754245610431166
Validation loss: 2.714421704439494

Epoch: 5| Step: 4
Training loss: 3.0423436043005427
Validation loss: 2.71169445078845

Epoch: 5| Step: 5
Training loss: 2.695663738861261
Validation loss: 2.712739453446005

Epoch: 5| Step: 6
Training loss: 3.4585401787237746
Validation loss: 2.713266413791812

Epoch: 5| Step: 7
Training loss: 3.341460112342065
Validation loss: 2.712415317389072

Epoch: 5| Step: 8
Training loss: 3.2580119924962694
Validation loss: 2.711551958931555

Epoch: 5| Step: 9
Training loss: 3.1144294488117685
Validation loss: 2.7139633223026634

Epoch: 5| Step: 10
Training loss: 2.724656277598091
Validation loss: 2.712056707372058

Epoch: 133| Step: 0
Training loss: 2.88778266348904
Validation loss: 2.712544075018183

Epoch: 5| Step: 1
Training loss: 3.0280682096874125
Validation loss: 2.7122803087347203

Epoch: 5| Step: 2
Training loss: 3.3653980288395444
Validation loss: 2.7221902201952624

Epoch: 5| Step: 3
Training loss: 3.012455831496746
Validation loss: 2.734213401132811

Epoch: 5| Step: 4
Training loss: 3.0459087698205645
Validation loss: 2.7187678131775965

Epoch: 5| Step: 5
Training loss: 2.757248774935763
Validation loss: 2.712403111688328

Epoch: 5| Step: 6
Training loss: 3.3011201402399535
Validation loss: 2.715029309986157

Epoch: 5| Step: 7
Training loss: 3.4972556117568594
Validation loss: 2.7122441480719477

Epoch: 5| Step: 8
Training loss: 2.4743044212934224
Validation loss: 2.7113151177359622

Epoch: 5| Step: 9
Training loss: 2.517278092575655
Validation loss: 2.712364278783037

Epoch: 5| Step: 10
Training loss: 3.338278598904868
Validation loss: 2.714292199055144

Epoch: 134| Step: 0
Training loss: 3.398044887971456
Validation loss: 2.7121167430422037

Epoch: 5| Step: 1
Training loss: 2.993923709424882
Validation loss: 2.7102081309659467

Epoch: 5| Step: 2
Training loss: 2.7312745745707767
Validation loss: 2.71259721022563

Epoch: 5| Step: 3
Training loss: 3.024657799147024
Validation loss: 2.716942227287277

Epoch: 5| Step: 4
Training loss: 2.9120769537304887
Validation loss: 2.712093305354876

Epoch: 5| Step: 5
Training loss: 2.9011890275786367
Validation loss: 2.7097219259881653

Epoch: 5| Step: 6
Training loss: 3.3419173022208093
Validation loss: 2.7065796081372127

Epoch: 5| Step: 7
Training loss: 3.045832685547919
Validation loss: 2.708156502932522

Epoch: 5| Step: 8
Training loss: 3.048975606768835
Validation loss: 2.7063957161673824

Epoch: 5| Step: 9
Training loss: 3.0254409027354714
Validation loss: 2.705177953464067

Epoch: 5| Step: 10
Training loss: 2.8249401052421566
Validation loss: 2.7082508090361666

Epoch: 135| Step: 0
Training loss: 2.579576673154552
Validation loss: 2.7107186225094932

Epoch: 5| Step: 1
Training loss: 3.719992678440231
Validation loss: 2.7091653792083363

Epoch: 5| Step: 2
Training loss: 3.2489472664932717
Validation loss: 2.7081094830739354

Epoch: 5| Step: 3
Training loss: 2.5911273795897265
Validation loss: 2.71110511217418

Epoch: 5| Step: 4
Training loss: 3.006746653178709
Validation loss: 2.706800814460013

Epoch: 5| Step: 5
Training loss: 3.177137097179998
Validation loss: 2.7027084320766193

Epoch: 5| Step: 6
Training loss: 3.1779279409585115
Validation loss: 2.705181611502959

Epoch: 5| Step: 7
Training loss: 3.1454248900025354
Validation loss: 2.703279962981526

Epoch: 5| Step: 8
Training loss: 3.0916799690666448
Validation loss: 2.7053553399100894

Epoch: 5| Step: 9
Training loss: 2.795338128507095
Validation loss: 2.710236769494815

Epoch: 5| Step: 10
Training loss: 2.611929916165993
Validation loss: 2.7273629515587614

Epoch: 136| Step: 0
Training loss: 2.4384819400408766
Validation loss: 2.7360556242384027

Epoch: 5| Step: 1
Training loss: 2.9079288022797978
Validation loss: 2.732977537858483

Epoch: 5| Step: 2
Training loss: 3.3886897457651974
Validation loss: 2.736084333280818

Epoch: 5| Step: 3
Training loss: 3.3180679453767548
Validation loss: 2.7223095108331474

Epoch: 5| Step: 4
Training loss: 2.885359138071352
Validation loss: 2.7155874800405666

Epoch: 5| Step: 5
Training loss: 3.0786868129724736
Validation loss: 2.7132003298979943

Epoch: 5| Step: 6
Training loss: 3.528840449785729
Validation loss: 2.7115622331326135

Epoch: 5| Step: 7
Training loss: 3.1574373938846785
Validation loss: 2.7124250183962366

Epoch: 5| Step: 8
Training loss: 2.509516152180376
Validation loss: 2.7061619231568894

Epoch: 5| Step: 9
Training loss: 2.623493761523772
Validation loss: 2.7068324080020227

Epoch: 5| Step: 10
Training loss: 3.316484322319777
Validation loss: 2.701024612917026

Epoch: 137| Step: 0
Training loss: 2.820476664575951
Validation loss: 2.701568325524701

Epoch: 5| Step: 1
Training loss: 3.5354083398118847
Validation loss: 2.699972346303617

Epoch: 5| Step: 2
Training loss: 3.4334940369658256
Validation loss: 2.7045390835482386

Epoch: 5| Step: 3
Training loss: 2.8732538310806834
Validation loss: 2.699552851285644

Epoch: 5| Step: 4
Training loss: 2.7705484305931574
Validation loss: 2.7017955110387826

Epoch: 5| Step: 5
Training loss: 3.0938033282375073
Validation loss: 2.700410258208158

Epoch: 5| Step: 6
Training loss: 2.638760602632488
Validation loss: 2.701271737734083

Epoch: 5| Step: 7
Training loss: 3.542192771581253
Validation loss: 2.6982159242906953

Epoch: 5| Step: 8
Training loss: 3.387433356160921
Validation loss: 2.7017579850441105

Epoch: 5| Step: 9
Training loss: 2.442436989446854
Validation loss: 2.7022753756703093

Epoch: 5| Step: 10
Training loss: 2.4103773315526027
Validation loss: 2.7037787869348784

Epoch: 138| Step: 0
Training loss: 3.419989915799449
Validation loss: 2.7162942333870834

Epoch: 5| Step: 1
Training loss: 2.590762704610664
Validation loss: 2.726671837183692

Epoch: 5| Step: 2
Training loss: 2.5810184772100544
Validation loss: 2.7491843914908887

Epoch: 5| Step: 3
Training loss: 2.6122882592941377
Validation loss: 2.765501275993385

Epoch: 5| Step: 4
Training loss: 2.8200708005688346
Validation loss: 2.7498615505982196

Epoch: 5| Step: 5
Training loss: 3.16508968304552
Validation loss: 2.7434328313983136

Epoch: 5| Step: 6
Training loss: 3.5790413428596946
Validation loss: 2.7421614463925694

Epoch: 5| Step: 7
Training loss: 3.1086882019649593
Validation loss: 2.7201436598164808

Epoch: 5| Step: 8
Training loss: 3.4335595868074327
Validation loss: 2.699686186984174

Epoch: 5| Step: 9
Training loss: 2.8863396298851267
Validation loss: 2.6986199353713496

Epoch: 5| Step: 10
Training loss: 2.8418270778034187
Validation loss: 2.6968723728724804

Epoch: 139| Step: 0
Training loss: 3.249401184082191
Validation loss: 2.7000618376842067

Epoch: 5| Step: 1
Training loss: 3.343689819935228
Validation loss: 2.7016349031828764

Epoch: 5| Step: 2
Training loss: 3.1729062663605214
Validation loss: 2.701702446602294

Epoch: 5| Step: 3
Training loss: 2.962636817315939
Validation loss: 2.7049787970541703

Epoch: 5| Step: 4
Training loss: 3.170911520463078
Validation loss: 2.7022999795415448

Epoch: 5| Step: 5
Training loss: 3.1159426849539402
Validation loss: 2.699694563453659

Epoch: 5| Step: 6
Training loss: 3.131018679177809
Validation loss: 2.6980302427021368

Epoch: 5| Step: 7
Training loss: 2.17969690683174
Validation loss: 2.6975453667216396

Epoch: 5| Step: 8
Training loss: 3.098783155774019
Validation loss: 2.6978189863496436

Epoch: 5| Step: 9
Training loss: 2.7319569386429956
Validation loss: 2.695373036074974

Epoch: 5| Step: 10
Training loss: 3.0545977410985423
Validation loss: 2.6975151564920523

Epoch: 140| Step: 0
Training loss: 3.109524977244345
Validation loss: 2.6973702941774924

Epoch: 5| Step: 1
Training loss: 2.7357465519437594
Validation loss: 2.7098077766130695

Epoch: 5| Step: 2
Training loss: 3.0037979880320305
Validation loss: 2.7108624641701247

Epoch: 5| Step: 3
Training loss: 3.048134724310326
Validation loss: 2.711832961840573

Epoch: 5| Step: 4
Training loss: 2.8572176106074303
Validation loss: 2.7013593867292034

Epoch: 5| Step: 5
Training loss: 3.09132382598966
Validation loss: 2.705853434503933

Epoch: 5| Step: 6
Training loss: 2.7106746139366082
Validation loss: 2.695839381546783

Epoch: 5| Step: 7
Training loss: 3.1655859023124666
Validation loss: 2.6954222345447714

Epoch: 5| Step: 8
Training loss: 2.940099175006604
Validation loss: 2.6981006869489175

Epoch: 5| Step: 9
Training loss: 3.321106005825275
Validation loss: 2.695538162740875

Epoch: 5| Step: 10
Training loss: 3.2671054240516444
Validation loss: 2.69642212034056

Epoch: 141| Step: 0
Training loss: 2.7842359480296452
Validation loss: 2.6968119897562137

Epoch: 5| Step: 1
Training loss: 3.4100934664090947
Validation loss: 2.6951519738050522

Epoch: 5| Step: 2
Training loss: 2.848545934943203
Validation loss: 2.6945465592756794

Epoch: 5| Step: 3
Training loss: 3.2629165734239223
Validation loss: 2.6925137830123576

Epoch: 5| Step: 4
Training loss: 2.6797266476276755
Validation loss: 2.6957440088382194

Epoch: 5| Step: 5
Training loss: 2.8402690332884877
Validation loss: 2.6919610253201887

Epoch: 5| Step: 6
Training loss: 2.737098950137133
Validation loss: 2.697972063857906

Epoch: 5| Step: 7
Training loss: 3.078328237262577
Validation loss: 2.722123298147902

Epoch: 5| Step: 8
Training loss: 3.3425693031721555
Validation loss: 2.7303415108879405

Epoch: 5| Step: 9
Training loss: 3.1904902176592693
Validation loss: 2.737218369341111

Epoch: 5| Step: 10
Training loss: 2.94005343875197
Validation loss: 2.7603718570377724

Epoch: 142| Step: 0
Training loss: 2.625995810407331
Validation loss: 2.772774473389188

Epoch: 5| Step: 1
Training loss: 2.7010490075092672
Validation loss: 2.76790084622901

Epoch: 5| Step: 2
Training loss: 2.7348141562802524
Validation loss: 2.7780261157059707

Epoch: 5| Step: 3
Training loss: 3.5781551176577726
Validation loss: 2.743295242999469

Epoch: 5| Step: 4
Training loss: 3.241074851438478
Validation loss: 2.723290128862842

Epoch: 5| Step: 5
Training loss: 2.8916911040784163
Validation loss: 2.7016256198635804

Epoch: 5| Step: 6
Training loss: 2.872935009612645
Validation loss: 2.695183791407143

Epoch: 5| Step: 7
Training loss: 3.1821585386476094
Validation loss: 2.6903093253805306

Epoch: 5| Step: 8
Training loss: 3.24397511665782
Validation loss: 2.692162984506278

Epoch: 5| Step: 9
Training loss: 2.8202606788164584
Validation loss: 2.6938235871061327

Epoch: 5| Step: 10
Training loss: 3.4130206930012146
Validation loss: 2.701404686809099

Epoch: 143| Step: 0
Training loss: 3.0689585566303195
Validation loss: 2.698712263502294

Epoch: 5| Step: 1
Training loss: 2.4680706006776223
Validation loss: 2.7021428740735227

Epoch: 5| Step: 2
Training loss: 3.0772242123624034
Validation loss: 2.7088597930555696

Epoch: 5| Step: 3
Training loss: 2.9481931810580044
Validation loss: 2.705747076304504

Epoch: 5| Step: 4
Training loss: 3.1047480676634085
Validation loss: 2.701838812170356

Epoch: 5| Step: 5
Training loss: 3.363841507488128
Validation loss: 2.693984174374822

Epoch: 5| Step: 6
Training loss: 3.1048563419347976
Validation loss: 2.692710324423518

Epoch: 5| Step: 7
Training loss: 1.9224842625483554
Validation loss: 2.6926047124164847

Epoch: 5| Step: 8
Training loss: 3.381054004904688
Validation loss: 2.6905059639865305

Epoch: 5| Step: 9
Training loss: 3.1687910750697035
Validation loss: 2.6925617159932553

Epoch: 5| Step: 10
Training loss: 3.4883214386507713
Validation loss: 2.6881013766403843

Epoch: 144| Step: 0
Training loss: 3.0620409563092448
Validation loss: 2.6912312962972655

Epoch: 5| Step: 1
Training loss: 2.655954681136241
Validation loss: 2.6938232454553095

Epoch: 5| Step: 2
Training loss: 2.9227362194811546
Validation loss: 2.750488488635003

Epoch: 5| Step: 3
Training loss: 2.989054740580624
Validation loss: 2.8735010110198793

Epoch: 5| Step: 4
Training loss: 3.36301328010217
Validation loss: 2.9165360897620185

Epoch: 5| Step: 5
Training loss: 3.3422554455057285
Validation loss: 2.880538894461105

Epoch: 5| Step: 6
Training loss: 3.4247168319480545
Validation loss: 2.759004992471427

Epoch: 5| Step: 7
Training loss: 3.1402024321693722
Validation loss: 2.68663358446712

Epoch: 5| Step: 8
Training loss: 3.3409748861219035
Validation loss: 2.684066817458053

Epoch: 5| Step: 9
Training loss: 2.4577769495775064
Validation loss: 2.693737355537965

Epoch: 5| Step: 10
Training loss: 2.5013004735213022
Validation loss: 2.696838275193248

Epoch: 145| Step: 0
Training loss: 3.119101641751148
Validation loss: 2.6984142763596184

Epoch: 5| Step: 1
Training loss: 3.4230100935113765
Validation loss: 2.6985298717653747

Epoch: 5| Step: 2
Training loss: 2.748103614985929
Validation loss: 2.6976231098442494

Epoch: 5| Step: 3
Training loss: 2.938555426409308
Validation loss: 2.698576428690375

Epoch: 5| Step: 4
Training loss: 3.408770547321587
Validation loss: 2.6944085791727876

Epoch: 5| Step: 5
Training loss: 3.320334616194726
Validation loss: 2.7000600108941

Epoch: 5| Step: 6
Training loss: 3.017387547076598
Validation loss: 2.6944932241464095

Epoch: 5| Step: 7
Training loss: 2.8870036767897203
Validation loss: 2.6892629661294194

Epoch: 5| Step: 8
Training loss: 2.6899341826204286
Validation loss: 2.6903142205090718

Epoch: 5| Step: 9
Training loss: 3.185869585317082
Validation loss: 2.688869953239978

Epoch: 5| Step: 10
Training loss: 2.3459540621202217
Validation loss: 2.689596611292584

Epoch: 146| Step: 0
Training loss: 2.5714489126157787
Validation loss: 2.699779458611653

Epoch: 5| Step: 1
Training loss: 2.8860936294563073
Validation loss: 2.700751231678649

Epoch: 5| Step: 2
Training loss: 3.6368354426263454
Validation loss: 2.725032742188729

Epoch: 5| Step: 3
Training loss: 3.358178781845148
Validation loss: 2.727301341438399

Epoch: 5| Step: 4
Training loss: 2.6773629741351423
Validation loss: 2.747830916126305

Epoch: 5| Step: 5
Training loss: 3.0546909342012345
Validation loss: 2.7523989678023217

Epoch: 5| Step: 6
Training loss: 2.8862292709696593
Validation loss: 2.7573177750637394

Epoch: 5| Step: 7
Training loss: 3.2492830512730095
Validation loss: 2.738942235088658

Epoch: 5| Step: 8
Training loss: 2.9534238633803764
Validation loss: 2.713046697994108

Epoch: 5| Step: 9
Training loss: 2.8202367545230134
Validation loss: 2.6966400115972573

Epoch: 5| Step: 10
Training loss: 2.918781295053134
Validation loss: 2.688874781388884

Epoch: 147| Step: 0
Training loss: 2.8530151011765614
Validation loss: 2.681676531054342

Epoch: 5| Step: 1
Training loss: 3.1039333554516677
Validation loss: 2.6872876735183797

Epoch: 5| Step: 2
Training loss: 2.7390490012045707
Validation loss: 2.6882020815945036

Epoch: 5| Step: 3
Training loss: 3.2901135575196356
Validation loss: 2.692940166437156

Epoch: 5| Step: 4
Training loss: 2.8284962447331843
Validation loss: 2.697294240320078

Epoch: 5| Step: 5
Training loss: 3.2553852653738518
Validation loss: 2.697936467797935

Epoch: 5| Step: 6
Training loss: 3.058330266329053
Validation loss: 2.6976832044412133

Epoch: 5| Step: 7
Training loss: 2.9292690130796744
Validation loss: 2.6975077302815076

Epoch: 5| Step: 8
Training loss: 3.1481207979381356
Validation loss: 2.689004307739345

Epoch: 5| Step: 9
Training loss: 3.3439509251201365
Validation loss: 2.6827928677957287

Epoch: 5| Step: 10
Training loss: 2.664582143091846
Validation loss: 2.6827370079277792

Epoch: 148| Step: 0
Training loss: 3.122734927402396
Validation loss: 2.6776384895482193

Epoch: 5| Step: 1
Training loss: 2.8637222012952663
Validation loss: 2.6770916304985035

Epoch: 5| Step: 2
Training loss: 3.0581509597272123
Validation loss: 2.6781428705342116

Epoch: 5| Step: 3
Training loss: 3.209048121371177
Validation loss: 2.6788752184051257

Epoch: 5| Step: 4
Training loss: 2.5712824791325235
Validation loss: 2.680436304915303

Epoch: 5| Step: 5
Training loss: 3.2343298867438026
Validation loss: 2.68706063286999

Epoch: 5| Step: 6
Training loss: 2.9228703236638944
Validation loss: 2.701556471748155

Epoch: 5| Step: 7
Training loss: 2.776635789306462
Validation loss: 2.7152572164715254

Epoch: 5| Step: 8
Training loss: 2.4498552046047646
Validation loss: 2.7037777022287295

Epoch: 5| Step: 9
Training loss: 3.1833181437451197
Validation loss: 2.699591910264054

Epoch: 5| Step: 10
Training loss: 3.5946805329758127
Validation loss: 2.681529499507699

Epoch: 149| Step: 0
Training loss: 3.1102247754280596
Validation loss: 2.6766020294818755

Epoch: 5| Step: 1
Training loss: 2.891801089662858
Validation loss: 2.6748256820526106

Epoch: 5| Step: 2
Training loss: 3.37976303263088
Validation loss: 2.676406530285598

Epoch: 5| Step: 3
Training loss: 2.79267303395162
Validation loss: 2.6782477768602444

Epoch: 5| Step: 4
Training loss: 2.353331347330496
Validation loss: 2.679795590834856

Epoch: 5| Step: 5
Training loss: 3.030121426053487
Validation loss: 2.676791756540391

Epoch: 5| Step: 6
Training loss: 3.086033918588661
Validation loss: 2.6742237602277714

Epoch: 5| Step: 7
Training loss: 3.159547499598903
Validation loss: 2.674519481671206

Epoch: 5| Step: 8
Training loss: 2.8916492194126664
Validation loss: 2.6834405496871585

Epoch: 5| Step: 9
Training loss: 2.8967912219462626
Validation loss: 2.674252473034614

Epoch: 5| Step: 10
Training loss: 3.377319669053058
Validation loss: 2.6747545069283927

Epoch: 150| Step: 0
Training loss: 2.921644069093168
Validation loss: 2.684451150242021

Epoch: 5| Step: 1
Training loss: 2.2311055198074197
Validation loss: 2.686196079811931

Epoch: 5| Step: 2
Training loss: 2.942686817911989
Validation loss: 2.6933606219069244

Epoch: 5| Step: 3
Training loss: 3.267228896226794
Validation loss: 2.6898574791438046

Epoch: 5| Step: 4
Training loss: 3.2258379771630232
Validation loss: 2.6899504196770705

Epoch: 5| Step: 5
Training loss: 3.51129670625058
Validation loss: 2.691412977699015

Epoch: 5| Step: 6
Training loss: 3.070039460366594
Validation loss: 2.6798134438764603

Epoch: 5| Step: 7
Training loss: 3.0529652298947476
Validation loss: 2.6744564395039574

Epoch: 5| Step: 8
Training loss: 3.0454107434087336
Validation loss: 2.6701511899973065

Epoch: 5| Step: 9
Training loss: 2.1244834945371522
Validation loss: 2.6667573577574446

Epoch: 5| Step: 10
Training loss: 3.40559562907065
Validation loss: 2.667772518200945

Epoch: 151| Step: 0
Training loss: 2.9453282039638538
Validation loss: 2.6687433868892647

Epoch: 5| Step: 1
Training loss: 2.9558403005447063
Validation loss: 2.667236529367849

Epoch: 5| Step: 2
Training loss: 2.877943605221691
Validation loss: 2.668675998746199

Epoch: 5| Step: 3
Training loss: 2.5177561576403575
Validation loss: 2.6686792313025367

Epoch: 5| Step: 4
Training loss: 3.135114247553802
Validation loss: 2.6701923496242963

Epoch: 5| Step: 5
Training loss: 2.92526472801059
Validation loss: 2.667497890524744

Epoch: 5| Step: 6
Training loss: 3.3060147120615158
Validation loss: 2.6729538567314193

Epoch: 5| Step: 7
Training loss: 2.799324880680636
Validation loss: 2.66792383061417

Epoch: 5| Step: 8
Training loss: 3.1579176019376187
Validation loss: 2.6800215078959235

Epoch: 5| Step: 9
Training loss: 3.043067000128809
Validation loss: 2.682383070974422

Epoch: 5| Step: 10
Training loss: 3.3079167453663194
Validation loss: 2.681250242896872

Epoch: 152| Step: 0
Training loss: 2.913008184670953
Validation loss: 2.68279979626667

Epoch: 5| Step: 1
Training loss: 3.338076046725956
Validation loss: 2.6890209822889415

Epoch: 5| Step: 2
Training loss: 3.101284216400289
Validation loss: 2.686885785492422

Epoch: 5| Step: 3
Training loss: 2.9769035404302033
Validation loss: 2.6806574694469867

Epoch: 5| Step: 4
Training loss: 2.680594332540262
Validation loss: 2.670084770635619

Epoch: 5| Step: 5
Training loss: 2.913952209185489
Validation loss: 2.6722352800191005

Epoch: 5| Step: 6
Training loss: 3.202904819271256
Validation loss: 2.666854199678233

Epoch: 5| Step: 7
Training loss: 2.699015762933224
Validation loss: 2.6656916720861883

Epoch: 5| Step: 8
Training loss: 3.0644540586160147
Validation loss: 2.6675792348434597

Epoch: 5| Step: 9
Training loss: 2.988829159839033
Validation loss: 2.663803063414697

Epoch: 5| Step: 10
Training loss: 3.0487187993391336
Validation loss: 2.666368885744217

Epoch: 153| Step: 0
Training loss: 3.0165426014491197
Validation loss: 2.66955727149576

Epoch: 5| Step: 1
Training loss: 2.813479952163005
Validation loss: 2.662586225455383

Epoch: 5| Step: 2
Training loss: 3.3014546627228807
Validation loss: 2.665618906633395

Epoch: 5| Step: 3
Training loss: 3.2002693658944126
Validation loss: 2.6647855028805965

Epoch: 5| Step: 4
Training loss: 2.7955211580717916
Validation loss: 2.662673689716095

Epoch: 5| Step: 5
Training loss: 2.9003350557597556
Validation loss: 2.6661831093046406

Epoch: 5| Step: 6
Training loss: 3.2037480934545206
Validation loss: 2.6725014973521932

Epoch: 5| Step: 7
Training loss: 3.3333342711129457
Validation loss: 2.6694932747193776

Epoch: 5| Step: 8
Training loss: 2.611650034793299
Validation loss: 2.6682404285649852

Epoch: 5| Step: 9
Training loss: 3.086682502535685
Validation loss: 2.6701464355250586

Epoch: 5| Step: 10
Training loss: 2.4832806366144617
Validation loss: 2.66821601841393

Epoch: 154| Step: 0
Training loss: 3.149320947024638
Validation loss: 2.675063000568604

Epoch: 5| Step: 1
Training loss: 3.3343885341037125
Validation loss: 2.683366396807359

Epoch: 5| Step: 2
Training loss: 3.2127756022818765
Validation loss: 2.6694853979392734

Epoch: 5| Step: 3
Training loss: 2.4311174802776145
Validation loss: 2.666722565944382

Epoch: 5| Step: 4
Training loss: 3.2956788121269702
Validation loss: 2.6620353819838147

Epoch: 5| Step: 5
Training loss: 2.8807021275940357
Validation loss: 2.662073804024709

Epoch: 5| Step: 6
Training loss: 2.7020494382953446
Validation loss: 2.663946495457098

Epoch: 5| Step: 7
Training loss: 3.284318633462411
Validation loss: 2.665802914439873

Epoch: 5| Step: 8
Training loss: 2.8144017889250272
Validation loss: 2.6724287033965464

Epoch: 5| Step: 9
Training loss: 2.4838235111041937
Validation loss: 2.676383901547506

Epoch: 5| Step: 10
Training loss: 3.2113727358137107
Validation loss: 2.690226848224543

Epoch: 155| Step: 0
Training loss: 2.868891321495253
Validation loss: 2.6919646975098876

Epoch: 5| Step: 1
Training loss: 2.4660071092612945
Validation loss: 2.663835372868293

Epoch: 5| Step: 2
Training loss: 2.943597187846339
Validation loss: 2.6627830093828972

Epoch: 5| Step: 3
Training loss: 3.6415713148633175
Validation loss: 2.6593486627404115

Epoch: 5| Step: 4
Training loss: 2.825711732852482
Validation loss: 2.6693348943475

Epoch: 5| Step: 5
Training loss: 3.362167971643216
Validation loss: 2.6646542816721337

Epoch: 5| Step: 6
Training loss: 2.9629942662740096
Validation loss: 2.6690054649584436

Epoch: 5| Step: 7
Training loss: 3.1858769192625664
Validation loss: 2.6674832880530532

Epoch: 5| Step: 8
Training loss: 2.403329836048786
Validation loss: 2.6643952779617006

Epoch: 5| Step: 9
Training loss: 3.312074166043398
Validation loss: 2.6766354439273563

Epoch: 5| Step: 10
Training loss: 2.613098046876139
Validation loss: 2.672357139222774

Epoch: 156| Step: 0
Training loss: 2.6459338752286534
Validation loss: 2.674805201223957

Epoch: 5| Step: 1
Training loss: 3.2878733317811077
Validation loss: 2.680268446787549

Epoch: 5| Step: 2
Training loss: 2.8764515405210322
Validation loss: 2.686514417823631

Epoch: 5| Step: 3
Training loss: 3.048273636066709
Validation loss: 2.6847365628998063

Epoch: 5| Step: 4
Training loss: 3.1082639002949786
Validation loss: 2.671155576406072

Epoch: 5| Step: 5
Training loss: 2.750353963786651
Validation loss: 2.661742427107127

Epoch: 5| Step: 6
Training loss: 2.398491576141203
Validation loss: 2.6596961206000946

Epoch: 5| Step: 7
Training loss: 2.8960803541764304
Validation loss: 2.6567145600661277

Epoch: 5| Step: 8
Training loss: 3.0313039558563784
Validation loss: 2.6552478026444235

Epoch: 5| Step: 9
Training loss: 3.6915501480716117
Validation loss: 2.6574885690395567

Epoch: 5| Step: 10
Training loss: 2.9646819501511046
Validation loss: 2.651933151993846

Epoch: 157| Step: 0
Training loss: 2.712446688642342
Validation loss: 2.6518872021092155

Epoch: 5| Step: 1
Training loss: 2.892948021377939
Validation loss: 2.6558711245603708

Epoch: 5| Step: 2
Training loss: 3.002558412007515
Validation loss: 2.6528630532776702

Epoch: 5| Step: 3
Training loss: 2.583510720920485
Validation loss: 2.651095635497204

Epoch: 5| Step: 4
Training loss: 2.5634253157079976
Validation loss: 2.659798580543568

Epoch: 5| Step: 5
Training loss: 3.1044014110175153
Validation loss: 2.663929084620197

Epoch: 5| Step: 6
Training loss: 3.364515620791324
Validation loss: 2.6758145923002727

Epoch: 5| Step: 7
Training loss: 3.595096501738378
Validation loss: 2.7067463133599965

Epoch: 5| Step: 8
Training loss: 2.7494579994835475
Validation loss: 2.737247704933257

Epoch: 5| Step: 9
Training loss: 3.3181136446133572
Validation loss: 2.7667187501868025

Epoch: 5| Step: 10
Training loss: 2.969327689733168
Validation loss: 2.738954907985384

Epoch: 158| Step: 0
Training loss: 2.7788319738380123
Validation loss: 2.6905159450407288

Epoch: 5| Step: 1
Training loss: 2.919957475221941
Validation loss: 2.659141804985649

Epoch: 5| Step: 2
Training loss: 2.4197307323370922
Validation loss: 2.6553134297362853

Epoch: 5| Step: 3
Training loss: 3.375170950622035
Validation loss: 2.65107217955638

Epoch: 5| Step: 4
Training loss: 2.625502583665363
Validation loss: 2.647084949170651

Epoch: 5| Step: 5
Training loss: 3.2201828221138182
Validation loss: 2.6521934510067

Epoch: 5| Step: 6
Training loss: 2.9946124656247095
Validation loss: 2.658349772561375

Epoch: 5| Step: 7
Training loss: 2.898430096804477
Validation loss: 2.6521899886021205

Epoch: 5| Step: 8
Training loss: 3.1429283084491098
Validation loss: 2.6564249327335827

Epoch: 5| Step: 9
Training loss: 3.1947171652288886
Validation loss: 2.6547835701401064

Epoch: 5| Step: 10
Training loss: 3.254243427955431
Validation loss: 2.654890310083583

Epoch: 159| Step: 0
Training loss: 2.485519337565268
Validation loss: 2.6551159420583015

Epoch: 5| Step: 1
Training loss: 2.8371562598313464
Validation loss: 2.653048484989179

Epoch: 5| Step: 2
Training loss: 2.8840238512404723
Validation loss: 2.6502600636864027

Epoch: 5| Step: 3
Training loss: 2.603207729531637
Validation loss: 2.651959974092777

Epoch: 5| Step: 4
Training loss: 2.5516359728614284
Validation loss: 2.6551277062633254

Epoch: 5| Step: 5
Training loss: 3.019771591037331
Validation loss: 2.6640160308490928

Epoch: 5| Step: 6
Training loss: 3.320769298770503
Validation loss: 2.6598120791957807

Epoch: 5| Step: 7
Training loss: 3.2537915048139325
Validation loss: 2.659876337816877

Epoch: 5| Step: 8
Training loss: 3.3591400774054283
Validation loss: 2.660802214431448

Epoch: 5| Step: 9
Training loss: 3.043516841786053
Validation loss: 2.6645625956825167

Epoch: 5| Step: 10
Training loss: 3.341067940846394
Validation loss: 2.6588394428015953

Epoch: 160| Step: 0
Training loss: 3.495877290130322
Validation loss: 2.666163584210067

Epoch: 5| Step: 1
Training loss: 2.998576303264031
Validation loss: 2.6722148685579983

Epoch: 5| Step: 2
Training loss: 2.602584317441902
Validation loss: 2.6680487131296933

Epoch: 5| Step: 3
Training loss: 3.133662158539868
Validation loss: 2.6896753628848455

Epoch: 5| Step: 4
Training loss: 3.174560011767071
Validation loss: 2.6750184475685574

Epoch: 5| Step: 5
Training loss: 3.0106371806513827
Validation loss: 2.6646626306871393

Epoch: 5| Step: 6
Training loss: 2.3298282409360533
Validation loss: 2.6513105528838103

Epoch: 5| Step: 7
Training loss: 2.6681460409614832
Validation loss: 2.648646407509663

Epoch: 5| Step: 8
Training loss: 3.230957879857169
Validation loss: 2.649770718804022

Epoch: 5| Step: 9
Training loss: 3.368984795988701
Validation loss: 2.6479274548898433

Epoch: 5| Step: 10
Training loss: 2.5903630030988873
Validation loss: 2.6456381373983615

Epoch: 161| Step: 0
Training loss: 3.281565769078772
Validation loss: 2.6481492094991426

Epoch: 5| Step: 1
Training loss: 3.410393530771633
Validation loss: 2.6476847015868965

Epoch: 5| Step: 2
Training loss: 2.3944168436869524
Validation loss: 2.6465043000470647

Epoch: 5| Step: 3
Training loss: 3.1549580262017316
Validation loss: 2.649069925424565

Epoch: 5| Step: 4
Training loss: 3.0692703769246985
Validation loss: 2.6474592022352943

Epoch: 5| Step: 5
Training loss: 2.755752355929446
Validation loss: 2.6465510427720935

Epoch: 5| Step: 6
Training loss: 3.4466948558114554
Validation loss: 2.6468355894880644

Epoch: 5| Step: 7
Training loss: 2.8192936544283396
Validation loss: 2.6534059542048363

Epoch: 5| Step: 8
Training loss: 2.429494770415763
Validation loss: 2.6599067066315856

Epoch: 5| Step: 9
Training loss: 2.9246796391778176
Validation loss: 2.6650375464626377

Epoch: 5| Step: 10
Training loss: 2.926372473433873
Validation loss: 2.6769092443039217

Epoch: 162| Step: 0
Training loss: 2.3824004270354657
Validation loss: 2.6861032670669878

Epoch: 5| Step: 1
Training loss: 3.435269412340722
Validation loss: 2.690440172905626

Epoch: 5| Step: 2
Training loss: 3.545640907191396
Validation loss: 2.6576617847309194

Epoch: 5| Step: 3
Training loss: 3.5460918082773794
Validation loss: 2.647566143544654

Epoch: 5| Step: 4
Training loss: 2.3785282830703274
Validation loss: 2.6462295015358333

Epoch: 5| Step: 5
Training loss: 2.907973240053657
Validation loss: 2.6488672318558195

Epoch: 5| Step: 6
Training loss: 2.709273033467289
Validation loss: 2.6486208798349384

Epoch: 5| Step: 7
Training loss: 2.913084955371943
Validation loss: 2.6491155670818696

Epoch: 5| Step: 8
Training loss: 3.195233407009346
Validation loss: 2.650756571758422

Epoch: 5| Step: 9
Training loss: 2.686589552559095
Validation loss: 2.647588850102998

Epoch: 5| Step: 10
Training loss: 3.0174526546528098
Validation loss: 2.6514490779405184

Epoch: 163| Step: 0
Training loss: 2.810075689905097
Validation loss: 2.654802910476622

Epoch: 5| Step: 1
Training loss: 3.241011882116376
Validation loss: 2.6496362393540367

Epoch: 5| Step: 2
Training loss: 2.667061379148685
Validation loss: 2.6484663340999353

Epoch: 5| Step: 3
Training loss: 3.169481398463332
Validation loss: 2.64742273817326

Epoch: 5| Step: 4
Training loss: 3.0315845737453864
Validation loss: 2.6497684113267996

Epoch: 5| Step: 5
Training loss: 2.7937172906996164
Validation loss: 2.6481503518423635

Epoch: 5| Step: 6
Training loss: 3.1996801693349224
Validation loss: 2.6473913265414564

Epoch: 5| Step: 7
Training loss: 2.86845814668477
Validation loss: 2.6519805414494435

Epoch: 5| Step: 8
Training loss: 3.064497938247861
Validation loss: 2.6647018277987593

Epoch: 5| Step: 9
Training loss: 3.133633094679451
Validation loss: 2.6915709104363095

Epoch: 5| Step: 10
Training loss: 2.8981487613614587
Validation loss: 2.723933465650764

Epoch: 164| Step: 0
Training loss: 3.214730132124265
Validation loss: 2.725795186679623

Epoch: 5| Step: 1
Training loss: 2.8070087655980065
Validation loss: 2.7245600232762768

Epoch: 5| Step: 2
Training loss: 2.911972810241024
Validation loss: 2.701527537174312

Epoch: 5| Step: 3
Training loss: 2.8966165668060406
Validation loss: 2.695178257359121

Epoch: 5| Step: 4
Training loss: 2.9031077800194858
Validation loss: 2.671145241801825

Epoch: 5| Step: 5
Training loss: 3.2530770040850303
Validation loss: 2.6658480782433442

Epoch: 5| Step: 6
Training loss: 3.307878545318896
Validation loss: 2.6440947749514474

Epoch: 5| Step: 7
Training loss: 2.435007434810121
Validation loss: 2.6473366153003064

Epoch: 5| Step: 8
Training loss: 3.2970197745260372
Validation loss: 2.645406044339617

Epoch: 5| Step: 9
Training loss: 2.8006561123652802
Validation loss: 2.64324350579979

Epoch: 5| Step: 10
Training loss: 2.8607976324037487
Validation loss: 2.6453789600304183

Epoch: 165| Step: 0
Training loss: 2.698141454417176
Validation loss: 2.6445184275548526

Epoch: 5| Step: 1
Training loss: 3.1645727429056834
Validation loss: 2.6510142727808965

Epoch: 5| Step: 2
Training loss: 2.5757234427456535
Validation loss: 2.6424544986198253

Epoch: 5| Step: 3
Training loss: 3.2738549596762945
Validation loss: 2.645666371191021

Epoch: 5| Step: 4
Training loss: 2.7318111934292624
Validation loss: 2.645815546855937

Epoch: 5| Step: 5
Training loss: 2.8403276243760938
Validation loss: 2.643915242878524

Epoch: 5| Step: 6
Training loss: 3.388820748260783
Validation loss: 2.644773646207188

Epoch: 5| Step: 7
Training loss: 2.6193428843301363
Validation loss: 2.643631176050508

Epoch: 5| Step: 8
Training loss: 2.858688188626042
Validation loss: 2.644801864995642

Epoch: 5| Step: 9
Training loss: 3.4213335836930256
Validation loss: 2.653360944804093

Epoch: 5| Step: 10
Training loss: 3.1872841257034845
Validation loss: 2.673906235551068

Epoch: 166| Step: 0
Training loss: 2.6564333684122796
Validation loss: 2.6845372575254816

Epoch: 5| Step: 1
Training loss: 3.2456195360971845
Validation loss: 2.7272908332508954

Epoch: 5| Step: 2
Training loss: 2.902831825917255
Validation loss: 2.759787597921772

Epoch: 5| Step: 3
Training loss: 2.8932265663078063
Validation loss: 2.811145043170005

Epoch: 5| Step: 4
Training loss: 3.0287304661680174
Validation loss: 2.8087683109457457

Epoch: 5| Step: 5
Training loss: 3.1063779255796162
Validation loss: 2.7666564222223493

Epoch: 5| Step: 6
Training loss: 3.0532507285836648
Validation loss: 2.7197805499346566

Epoch: 5| Step: 7
Training loss: 2.8723437436252244
Validation loss: 2.700391937545712

Epoch: 5| Step: 8
Training loss: 2.859550095497057
Validation loss: 2.679596151397806

Epoch: 5| Step: 9
Training loss: 2.964061850073647
Validation loss: 2.6651291882172843

Epoch: 5| Step: 10
Training loss: 3.5656702759231065
Validation loss: 2.6441507196417837

Epoch: 167| Step: 0
Training loss: 2.147225998972074
Validation loss: 2.6410870541916713

Epoch: 5| Step: 1
Training loss: 3.5848454825967377
Validation loss: 2.642018529523638

Epoch: 5| Step: 2
Training loss: 3.3437681108501205
Validation loss: 2.646887149742469

Epoch: 5| Step: 3
Training loss: 2.883135025466765
Validation loss: 2.6467323013029582

Epoch: 5| Step: 4
Training loss: 2.727228209103303
Validation loss: 2.648353374225734

Epoch: 5| Step: 5
Training loss: 3.3973844453249527
Validation loss: 2.6442887113547537

Epoch: 5| Step: 6
Training loss: 2.990144116555012
Validation loss: 2.6394501079781922

Epoch: 5| Step: 7
Training loss: 3.410251332079385
Validation loss: 2.641954357640183

Epoch: 5| Step: 8
Training loss: 2.441077907608273
Validation loss: 2.6408493520455587

Epoch: 5| Step: 9
Training loss: 2.6334868792744244
Validation loss: 2.6385357591511003

Epoch: 5| Step: 10
Training loss: 3.021612676301908
Validation loss: 2.6392094783490947

Epoch: 168| Step: 0
Training loss: 2.8181169158420274
Validation loss: 2.6403885592497693

Epoch: 5| Step: 1
Training loss: 2.3913593037136867
Validation loss: 2.6484199581665777

Epoch: 5| Step: 2
Training loss: 3.4887722306344524
Validation loss: 2.6614239879127752

Epoch: 5| Step: 3
Training loss: 2.955815295786456
Validation loss: 2.680703685508084

Epoch: 5| Step: 4
Training loss: 3.028156078009865
Validation loss: 2.6763679078645497

Epoch: 5| Step: 5
Training loss: 3.205054023275467
Validation loss: 2.7047270651327486

Epoch: 5| Step: 6
Training loss: 2.664950136215615
Validation loss: 2.727014156972574

Epoch: 5| Step: 7
Training loss: 2.875011609924758
Validation loss: 2.724921446322125

Epoch: 5| Step: 8
Training loss: 3.321409228337418
Validation loss: 2.702933674626287

Epoch: 5| Step: 9
Training loss: 2.8470307593337107
Validation loss: 2.6860548933750414

Epoch: 5| Step: 10
Training loss: 3.1370580354331636
Validation loss: 2.6519018198890287

Epoch: 169| Step: 0
Training loss: 3.3421301795356344
Validation loss: 2.645579541893514

Epoch: 5| Step: 1
Training loss: 2.832340702382063
Validation loss: 2.639882855662748

Epoch: 5| Step: 2
Training loss: 2.7126666004683715
Validation loss: 2.634763360815943

Epoch: 5| Step: 3
Training loss: 3.096369703471498
Validation loss: 2.6310141774022786

Epoch: 5| Step: 4
Training loss: 2.247529050577749
Validation loss: 2.6343173000125364

Epoch: 5| Step: 5
Training loss: 3.270099986936263
Validation loss: 2.6322165067452166

Epoch: 5| Step: 6
Training loss: 2.6825063576316333
Validation loss: 2.635994027220698

Epoch: 5| Step: 7
Training loss: 2.9504015439130837
Validation loss: 2.6337838569336687

Epoch: 5| Step: 8
Training loss: 3.640186725480206
Validation loss: 2.634255605128167

Epoch: 5| Step: 9
Training loss: 2.7526068902460854
Validation loss: 2.6324467836324206

Epoch: 5| Step: 10
Training loss: 3.1069780628619617
Validation loss: 2.631159897671556

Epoch: 170| Step: 0
Training loss: 3.015710068525691
Validation loss: 2.6287081535214063

Epoch: 5| Step: 1
Training loss: 2.9887063116807693
Validation loss: 2.6267045830242393

Epoch: 5| Step: 2
Training loss: 2.60975598506349
Validation loss: 2.6283043515782913

Epoch: 5| Step: 3
Training loss: 2.8758643136520035
Validation loss: 2.6282562981972606

Epoch: 5| Step: 4
Training loss: 3.3742844564828434
Validation loss: 2.634434657902431

Epoch: 5| Step: 5
Training loss: 3.061066428210515
Validation loss: 2.6346191330497333

Epoch: 5| Step: 6
Training loss: 2.5374670092312552
Validation loss: 2.644008267340188

Epoch: 5| Step: 7
Training loss: 3.0882054746881793
Validation loss: 2.65669986551514

Epoch: 5| Step: 8
Training loss: 3.1775239899432766
Validation loss: 2.657160070918749

Epoch: 5| Step: 9
Training loss: 2.9640383625405082
Validation loss: 2.6655385921792685

Epoch: 5| Step: 10
Training loss: 2.8899543602847446
Validation loss: 2.6484246509717164

Epoch: 171| Step: 0
Training loss: 2.9579931430698485
Validation loss: 2.631415798182162

Epoch: 5| Step: 1
Training loss: 2.594445744236637
Validation loss: 2.6310642139331413

Epoch: 5| Step: 2
Training loss: 3.300196705359755
Validation loss: 2.6253576987184717

Epoch: 5| Step: 3
Training loss: 3.051463110770642
Validation loss: 2.6241217480538235

Epoch: 5| Step: 4
Training loss: 3.071964974312982
Validation loss: 2.624945194162521

Epoch: 5| Step: 5
Training loss: 3.035851515545264
Validation loss: 2.625754099131726

Epoch: 5| Step: 6
Training loss: 2.821481309297838
Validation loss: 2.6223229402420505

Epoch: 5| Step: 7
Training loss: 2.794680965552016
Validation loss: 2.624540717538749

Epoch: 5| Step: 8
Training loss: 2.9655870151800454
Validation loss: 2.6233583073829876

Epoch: 5| Step: 9
Training loss: 3.1373632393624944
Validation loss: 2.6245043804793946

Epoch: 5| Step: 10
Training loss: 2.788430022003397
Validation loss: 2.6360773609462718

Epoch: 172| Step: 0
Training loss: 3.564701805323478
Validation loss: 2.631055239933041

Epoch: 5| Step: 1
Training loss: 2.254605348482254
Validation loss: 2.6397397175684367

Epoch: 5| Step: 2
Training loss: 3.392404959239198
Validation loss: 2.6427985959614277

Epoch: 5| Step: 3
Training loss: 2.984054628122717
Validation loss: 2.6599350048617887

Epoch: 5| Step: 4
Training loss: 3.173880708699014
Validation loss: 2.6582463675884886

Epoch: 5| Step: 5
Training loss: 2.9785146644465663
Validation loss: 2.665783396177462

Epoch: 5| Step: 6
Training loss: 2.634624186141805
Validation loss: 2.65045173538235

Epoch: 5| Step: 7
Training loss: 2.739717158734325
Validation loss: 2.645140730595117

Epoch: 5| Step: 8
Training loss: 2.781714068497068
Validation loss: 2.631007110123561

Epoch: 5| Step: 9
Training loss: 3.036109725457011
Validation loss: 2.627240415875184

Epoch: 5| Step: 10
Training loss: 2.901212530851527
Validation loss: 2.624998670813033

Epoch: 173| Step: 0
Training loss: 3.1647963438153726
Validation loss: 2.6216559842554927

Epoch: 5| Step: 1
Training loss: 3.062366716248261
Validation loss: 2.6218875455509116

Epoch: 5| Step: 2
Training loss: 3.709815568478307
Validation loss: 2.6228034834629073

Epoch: 5| Step: 3
Training loss: 2.72761178798945
Validation loss: 2.6218286001359514

Epoch: 5| Step: 4
Training loss: 3.1966548422500916
Validation loss: 2.630723960008995

Epoch: 5| Step: 5
Training loss: 2.7927465390460626
Validation loss: 2.62262894545176

Epoch: 5| Step: 6
Training loss: 2.922843894859221
Validation loss: 2.62131578051445

Epoch: 5| Step: 7
Training loss: 2.651907479048864
Validation loss: 2.620725208795356

Epoch: 5| Step: 8
Training loss: 2.983194007674787
Validation loss: 2.6215462717096942

Epoch: 5| Step: 9
Training loss: 2.590933499989374
Validation loss: 2.6292732759168156

Epoch: 5| Step: 10
Training loss: 2.6697328245237575
Validation loss: 2.632621853902905

Epoch: 174| Step: 0
Training loss: 2.7200202166984067
Validation loss: 2.626210218416829

Epoch: 5| Step: 1
Training loss: 2.4982566476987498
Validation loss: 2.6224408026362744

Epoch: 5| Step: 2
Training loss: 3.067401777838536
Validation loss: 2.62081215332755

Epoch: 5| Step: 3
Training loss: 2.898923272813994
Validation loss: 2.6196878527191534

Epoch: 5| Step: 4
Training loss: 3.391745667783296
Validation loss: 2.6179490718985217

Epoch: 5| Step: 5
Training loss: 3.398110420009142
Validation loss: 2.617191460278447

Epoch: 5| Step: 6
Training loss: 3.2398061072648927
Validation loss: 2.61690858258643

Epoch: 5| Step: 7
Training loss: 2.468046257055433
Validation loss: 2.6222679875328283

Epoch: 5| Step: 8
Training loss: 2.494477848923404
Validation loss: 2.6181388926872144

Epoch: 5| Step: 9
Training loss: 2.933039098490077
Validation loss: 2.6199364624704464

Epoch: 5| Step: 10
Training loss: 3.257885536454609
Validation loss: 2.620022086788021

Epoch: 175| Step: 0
Training loss: 3.020863780602666
Validation loss: 2.628428774198273

Epoch: 5| Step: 1
Training loss: 2.960915437077679
Validation loss: 2.6150150750716894

Epoch: 5| Step: 2
Training loss: 3.202837079761796
Validation loss: 2.6296211785365813

Epoch: 5| Step: 3
Training loss: 2.7422357538656397
Validation loss: 2.6338692890211597

Epoch: 5| Step: 4
Training loss: 3.2014091548062162
Validation loss: 2.633674383865433

Epoch: 5| Step: 5
Training loss: 2.994916105034712
Validation loss: 2.6449715242113623

Epoch: 5| Step: 6
Training loss: 2.874987063171471
Validation loss: 2.6771035720125935

Epoch: 5| Step: 7
Training loss: 2.5514813290525296
Validation loss: 2.6540416689705353

Epoch: 5| Step: 8
Training loss: 2.856683683964161
Validation loss: 2.639738534680983

Epoch: 5| Step: 9
Training loss: 2.7873493992104414
Validation loss: 2.622065648789554

Epoch: 5| Step: 10
Training loss: 3.349344867016236
Validation loss: 2.6102519888522737

Epoch: 176| Step: 0
Training loss: 3.2590145390886507
Validation loss: 2.6173802546789044

Epoch: 5| Step: 1
Training loss: 2.3449116180617544
Validation loss: 2.6158974762085907

Epoch: 5| Step: 2
Training loss: 3.628110143350154
Validation loss: 2.6142427871209

Epoch: 5| Step: 3
Training loss: 3.190679721942128
Validation loss: 2.617786073688203

Epoch: 5| Step: 4
Training loss: 2.8995530277303287
Validation loss: 2.6171112710635254

Epoch: 5| Step: 5
Training loss: 2.3616124337734834
Validation loss: 2.6142285589232035

Epoch: 5| Step: 6
Training loss: 3.311925298391995
Validation loss: 2.6129915756929867

Epoch: 5| Step: 7
Training loss: 2.572525880199629
Validation loss: 2.6195128242778756

Epoch: 5| Step: 8
Training loss: 2.8315809852191216
Validation loss: 2.635093310825852

Epoch: 5| Step: 9
Training loss: 3.2316757954597564
Validation loss: 2.624255979760788

Epoch: 5| Step: 10
Training loss: 2.5787275130474434
Validation loss: 2.6367910772481222

Epoch: 177| Step: 0
Training loss: 2.8819492774116
Validation loss: 2.6305046610708676

Epoch: 5| Step: 1
Training loss: 3.2133027435630073
Validation loss: 2.6349606235928555

Epoch: 5| Step: 2
Training loss: 3.2016172256372357
Validation loss: 2.622432460949281

Epoch: 5| Step: 3
Training loss: 2.8624744397483957
Validation loss: 2.6231573760216693

Epoch: 5| Step: 4
Training loss: 3.0595103092683855
Validation loss: 2.6244575908904775

Epoch: 5| Step: 5
Training loss: 3.3632925921701897
Validation loss: 2.6264213663326568

Epoch: 5| Step: 6
Training loss: 3.0784667159426933
Validation loss: 2.6273133416669356

Epoch: 5| Step: 7
Training loss: 2.2603100753005387
Validation loss: 2.6137279593021563

Epoch: 5| Step: 8
Training loss: 2.571874636607185
Validation loss: 2.610822870685048

Epoch: 5| Step: 9
Training loss: 2.4442711706111817
Validation loss: 2.614495648571364

Epoch: 5| Step: 10
Training loss: 3.359221131105545
Validation loss: 2.620116627829384

Epoch: 178| Step: 0
Training loss: 3.0164618245192063
Validation loss: 2.6350524124026604

Epoch: 5| Step: 1
Training loss: 3.1145392237232845
Validation loss: 2.619829865061779

Epoch: 5| Step: 2
Training loss: 2.9904005327162007
Validation loss: 2.620190219575964

Epoch: 5| Step: 3
Training loss: 2.949383338226088
Validation loss: 2.617699909081985

Epoch: 5| Step: 4
Training loss: 2.857189906959058
Validation loss: 2.614606202133434

Epoch: 5| Step: 5
Training loss: 2.9472504167309737
Validation loss: 2.6154281361979566

Epoch: 5| Step: 6
Training loss: 2.8414699930126672
Validation loss: 2.612201045283009

Epoch: 5| Step: 7
Training loss: 2.4332212404883315
Validation loss: 2.6215161469682853

Epoch: 5| Step: 8
Training loss: 2.8331741026471784
Validation loss: 2.619385138883786

Epoch: 5| Step: 9
Training loss: 2.8194952544179
Validation loss: 2.6115731995387215

Epoch: 5| Step: 10
Training loss: 3.6136384694620567
Validation loss: 2.612407846224322

Epoch: 179| Step: 0
Training loss: 2.886343099183819
Validation loss: 2.6162924056113264

Epoch: 5| Step: 1
Training loss: 3.1057643149932748
Validation loss: 2.6159571756104225

Epoch: 5| Step: 2
Training loss: 2.6861821869269265
Validation loss: 2.6235754363663006

Epoch: 5| Step: 3
Training loss: 3.473468766991947
Validation loss: 2.622998601664585

Epoch: 5| Step: 4
Training loss: 2.340094296601332
Validation loss: 2.6239630511020002

Epoch: 5| Step: 5
Training loss: 3.113440840973096
Validation loss: 2.621615538232482

Epoch: 5| Step: 6
Training loss: 3.2798208848382395
Validation loss: 2.6197417175415003

Epoch: 5| Step: 7
Training loss: 2.7016941759927717
Validation loss: 2.615669418751505

Epoch: 5| Step: 8
Training loss: 2.7600069905621
Validation loss: 2.6172733396271686

Epoch: 5| Step: 9
Training loss: 2.9182275864116134
Validation loss: 2.6180268647462466

Epoch: 5| Step: 10
Training loss: 2.991231182850602
Validation loss: 2.6225515823768006

Epoch: 180| Step: 0
Training loss: 2.7618161282779154
Validation loss: 2.6208216495358796

Epoch: 5| Step: 1
Training loss: 3.1513593193076552
Validation loss: 2.61970382057453

Epoch: 5| Step: 2
Training loss: 2.644522324607584
Validation loss: 2.617682902639004

Epoch: 5| Step: 3
Training loss: 2.9625775870291533
Validation loss: 2.620277282633546

Epoch: 5| Step: 4
Training loss: 3.2441291602183027
Validation loss: 2.624461959256505

Epoch: 5| Step: 5
Training loss: 3.0667313907537888
Validation loss: 2.6182224030511985

Epoch: 5| Step: 6
Training loss: 3.0498481525080776
Validation loss: 2.6114736361488635

Epoch: 5| Step: 7
Training loss: 2.8955178580664698
Validation loss: 2.6124553648541795

Epoch: 5| Step: 8
Training loss: 3.1568841580394227
Validation loss: 2.6264560185049928

Epoch: 5| Step: 9
Training loss: 2.109441685505513
Validation loss: 2.613659127190717

Epoch: 5| Step: 10
Training loss: 3.19366860481949
Validation loss: 2.632917193046243

Epoch: 181| Step: 0
Training loss: 3.062071011139079
Validation loss: 2.6188626732800184

Epoch: 5| Step: 1
Training loss: 3.1417276904371225
Validation loss: 2.6117471689185408

Epoch: 5| Step: 2
Training loss: 2.7214322944389653
Validation loss: 2.610645230882271

Epoch: 5| Step: 3
Training loss: 2.855701525759237
Validation loss: 2.603673460165555

Epoch: 5| Step: 4
Training loss: 3.1084294247198785
Validation loss: 2.609779097212722

Epoch: 5| Step: 5
Training loss: 2.5975399593624386
Validation loss: 2.6074358591440046

Epoch: 5| Step: 6
Training loss: 2.650717145221679
Validation loss: 2.60482353605545

Epoch: 5| Step: 7
Training loss: 3.421796684588256
Validation loss: 2.6072503426497238

Epoch: 5| Step: 8
Training loss: 2.995514377244306
Validation loss: 2.607395257430286

Epoch: 5| Step: 9
Training loss: 3.2763281829831796
Validation loss: 2.6094836774328125

Epoch: 5| Step: 10
Training loss: 2.347117738323169
Validation loss: 2.61375726703262

Epoch: 182| Step: 0
Training loss: 3.0579384288090576
Validation loss: 2.6178034858745405

Epoch: 5| Step: 1
Training loss: 2.916620108823207
Validation loss: 2.61860846543435

Epoch: 5| Step: 2
Training loss: 2.71820527681601
Validation loss: 2.6220171799299368

Epoch: 5| Step: 3
Training loss: 3.089542340456612
Validation loss: 2.6230897237252004

Epoch: 5| Step: 4
Training loss: 2.860956807178162
Validation loss: 2.641232230374569

Epoch: 5| Step: 5
Training loss: 2.54810832299096
Validation loss: 2.6660194194709153

Epoch: 5| Step: 6
Training loss: 2.9139729913050285
Validation loss: 2.676622350019879

Epoch: 5| Step: 7
Training loss: 3.2013178495927415
Validation loss: 2.6616879819592776

Epoch: 5| Step: 8
Training loss: 2.6919396568098923
Validation loss: 2.6512177488629236

Epoch: 5| Step: 9
Training loss: 3.0548512446621947
Validation loss: 2.635189846410522

Epoch: 5| Step: 10
Training loss: 3.3571551418369547
Validation loss: 2.6315333448958955

Epoch: 183| Step: 0
Training loss: 2.46458276494445
Validation loss: 2.6165594746653427

Epoch: 5| Step: 1
Training loss: 2.968816495451848
Validation loss: 2.6142672825043194

Epoch: 5| Step: 2
Training loss: 2.8376123616158218
Validation loss: 2.609909648328557

Epoch: 5| Step: 3
Training loss: 2.740670243589009
Validation loss: 2.615178302849146

Epoch: 5| Step: 4
Training loss: 2.896631547066007
Validation loss: 2.615508573050155

Epoch: 5| Step: 5
Training loss: 3.4018959425183986
Validation loss: 2.6114305987886497

Epoch: 5| Step: 6
Training loss: 3.19235607566618
Validation loss: 2.6020486871247037

Epoch: 5| Step: 7
Training loss: 2.7801393155654335
Validation loss: 2.6057069593323883

Epoch: 5| Step: 8
Training loss: 3.2158837750912297
Validation loss: 2.6091442638606157

Epoch: 5| Step: 9
Training loss: 2.552758751587179
Validation loss: 2.6073694517359267

Epoch: 5| Step: 10
Training loss: 3.18243664267164
Validation loss: 2.601608932737536

Epoch: 184| Step: 0
Training loss: 2.2799070402903983
Validation loss: 2.6013492407023704

Epoch: 5| Step: 1
Training loss: 2.8150319887989594
Validation loss: 2.6084935669004867

Epoch: 5| Step: 2
Training loss: 3.0289039578354107
Validation loss: 2.6132177208486427

Epoch: 5| Step: 3
Training loss: 2.7157037264844455
Validation loss: 2.6100946919522166

Epoch: 5| Step: 4
Training loss: 3.2573935699056533
Validation loss: 2.605904741333335

Epoch: 5| Step: 5
Training loss: 3.337486461369061
Validation loss: 2.6046092090929043

Epoch: 5| Step: 6
Training loss: 2.749364085799067
Validation loss: 2.611995735533449

Epoch: 5| Step: 7
Training loss: 3.488255414194288
Validation loss: 2.611916762890153

Epoch: 5| Step: 8
Training loss: 2.541465678371841
Validation loss: 2.6019946668781984

Epoch: 5| Step: 9
Training loss: 2.809129942325102
Validation loss: 2.607431763114091

Epoch: 5| Step: 10
Training loss: 3.123640451330699
Validation loss: 2.604341773924198

Epoch: 185| Step: 0
Training loss: 2.955152995994679
Validation loss: 2.6026144840109255

Epoch: 5| Step: 1
Training loss: 2.697097054862125
Validation loss: 2.6040766651639182

Epoch: 5| Step: 2
Training loss: 3.377917970988281
Validation loss: 2.59957307109888

Epoch: 5| Step: 3
Training loss: 3.0718178201439303
Validation loss: 2.6027701812889052

Epoch: 5| Step: 4
Training loss: 2.6254528200047322
Validation loss: 2.598465671428155

Epoch: 5| Step: 5
Training loss: 2.7432121253632555
Validation loss: 2.597169630516848

Epoch: 5| Step: 6
Training loss: 2.9139101535767495
Validation loss: 2.605903177120427

Epoch: 5| Step: 7
Training loss: 2.590711445395732
Validation loss: 2.606902132354843

Epoch: 5| Step: 8
Training loss: 2.8451725681844016
Validation loss: 2.60844175781807

Epoch: 5| Step: 9
Training loss: 3.239426947413977
Validation loss: 2.6071145431184815

Epoch: 5| Step: 10
Training loss: 3.1515914227241724
Validation loss: 2.6164286517819804

Epoch: 186| Step: 0
Training loss: 2.810940288820097
Validation loss: 2.6144766386021883

Epoch: 5| Step: 1
Training loss: 3.4026161899390233
Validation loss: 2.621800164395487

Epoch: 5| Step: 2
Training loss: 3.40090649245138
Validation loss: 2.6145896501362285

Epoch: 5| Step: 3
Training loss: 2.486874360810433
Validation loss: 2.6128086544619906

Epoch: 5| Step: 4
Training loss: 3.140392086065629
Validation loss: 2.6092175283965897

Epoch: 5| Step: 5
Training loss: 2.773741713481832
Validation loss: 2.6066391349521654

Epoch: 5| Step: 6
Training loss: 2.533331403815221
Validation loss: 2.6057400944106393

Epoch: 5| Step: 7
Training loss: 2.6781954601371005
Validation loss: 2.6004797318576247

Epoch: 5| Step: 8
Training loss: 3.089503909783792
Validation loss: 2.60012028189538

Epoch: 5| Step: 9
Training loss: 2.8978828660395584
Validation loss: 2.5925766976708013

Epoch: 5| Step: 10
Training loss: 2.9365870903684854
Validation loss: 2.5981815660334187

Epoch: 187| Step: 0
Training loss: 3.5288636913355504
Validation loss: 2.602038997278114

Epoch: 5| Step: 1
Training loss: 2.70216096655254
Validation loss: 2.5993411265812614

Epoch: 5| Step: 2
Training loss: 2.7796990002484843
Validation loss: 2.6056890422677097

Epoch: 5| Step: 3
Training loss: 3.299528961086911
Validation loss: 2.608234151454826

Epoch: 5| Step: 4
Training loss: 2.916268257904781
Validation loss: 2.6127176629714146

Epoch: 5| Step: 5
Training loss: 3.177020930109911
Validation loss: 2.6171294493490245

Epoch: 5| Step: 6
Training loss: 2.8982063468620898
Validation loss: 2.6169153715154274

Epoch: 5| Step: 7
Training loss: 2.5404189961190036
Validation loss: 2.615919088574481

Epoch: 5| Step: 8
Training loss: 2.9828468124949903
Validation loss: 2.6205937770170133

Epoch: 5| Step: 9
Training loss: 2.424037435563583
Validation loss: 2.6112831590387207

Epoch: 5| Step: 10
Training loss: 2.8797046480791146
Validation loss: 2.6091273539492246

Epoch: 188| Step: 0
Training loss: 2.826379310993667
Validation loss: 2.6028274938707097

Epoch: 5| Step: 1
Training loss: 3.1610489422570223
Validation loss: 2.603183159624545

Epoch: 5| Step: 2
Training loss: 3.109813716743213
Validation loss: 2.59955139186712

Epoch: 5| Step: 3
Training loss: 2.307930013445046
Validation loss: 2.5905078155417227

Epoch: 5| Step: 4
Training loss: 2.9840223493480558
Validation loss: 2.5894048702477472

Epoch: 5| Step: 5
Training loss: 3.2271204874663417
Validation loss: 2.588097422520178

Epoch: 5| Step: 6
Training loss: 2.612627754555653
Validation loss: 2.5912115804256683

Epoch: 5| Step: 7
Training loss: 2.9056945598150823
Validation loss: 2.5888787536614

Epoch: 5| Step: 8
Training loss: 2.641763836570728
Validation loss: 2.589854981675809

Epoch: 5| Step: 9
Training loss: 3.640808624744866
Validation loss: 2.600106001066453

Epoch: 5| Step: 10
Training loss: 2.6291104785781325
Validation loss: 2.603442405809215

Epoch: 189| Step: 0
Training loss: 2.6656455429376757
Validation loss: 2.615501930435855

Epoch: 5| Step: 1
Training loss: 3.1406672081080096
Validation loss: 2.643980920491352

Epoch: 5| Step: 2
Training loss: 3.31582086471766
Validation loss: 2.619064623227885

Epoch: 5| Step: 3
Training loss: 2.969132248212101
Validation loss: 2.604595065083956

Epoch: 5| Step: 4
Training loss: 2.7760596546117546
Validation loss: 2.6018734179873886

Epoch: 5| Step: 5
Training loss: 3.2146237785941345
Validation loss: 2.5924887478602705

Epoch: 5| Step: 6
Training loss: 2.193340569786649
Validation loss: 2.5867015994929785

Epoch: 5| Step: 7
Training loss: 2.627388548660499
Validation loss: 2.5907844841017433

Epoch: 5| Step: 8
Training loss: 2.9685852005039988
Validation loss: 2.590470580497861

Epoch: 5| Step: 9
Training loss: 3.1346439326067825
Validation loss: 2.590629852677106

Epoch: 5| Step: 10
Training loss: 3.271635665811456
Validation loss: 2.5910653790945366

Epoch: 190| Step: 0
Training loss: 3.170001599525024
Validation loss: 2.5918604578862707

Epoch: 5| Step: 1
Training loss: 2.6601295413834487
Validation loss: 2.5944035380454347

Epoch: 5| Step: 2
Training loss: 3.0962923951186094
Validation loss: 2.6103569228263344

Epoch: 5| Step: 3
Training loss: 2.954609815523414
Validation loss: 2.624340202982897

Epoch: 5| Step: 4
Training loss: 2.8329446937448997
Validation loss: 2.6156364525840146

Epoch: 5| Step: 5
Training loss: 2.752337589305747
Validation loss: 2.603797665612336

Epoch: 5| Step: 6
Training loss: 3.0117950627693895
Validation loss: 2.605501404012307

Epoch: 5| Step: 7
Training loss: 3.0672100981600336
Validation loss: 2.601194814507095

Epoch: 5| Step: 8
Training loss: 2.7284451955499542
Validation loss: 2.596505169667558

Epoch: 5| Step: 9
Training loss: 3.18957063326476
Validation loss: 2.591659919511838

Epoch: 5| Step: 10
Training loss: 2.702902724107238
Validation loss: 2.595519048566149

Epoch: 191| Step: 0
Training loss: 2.3372030752973614
Validation loss: 2.591546041609948

Epoch: 5| Step: 1
Training loss: 3.049477898358288
Validation loss: 2.5934387872319458

Epoch: 5| Step: 2
Training loss: 2.6779539322939763
Validation loss: 2.592777909675018

Epoch: 5| Step: 3
Training loss: 2.2724550621701014
Validation loss: 2.594099615013504

Epoch: 5| Step: 4
Training loss: 3.4565799052116937
Validation loss: 2.595158636886566

Epoch: 5| Step: 5
Training loss: 3.097543875542861
Validation loss: 2.5957392509320147

Epoch: 5| Step: 6
Training loss: 3.3680241866251337
Validation loss: 2.5905118997357555

Epoch: 5| Step: 7
Training loss: 3.0505991550469145
Validation loss: 2.59691236233227

Epoch: 5| Step: 8
Training loss: 3.3503788634186407
Validation loss: 2.59817568526062

Epoch: 5| Step: 9
Training loss: 2.5300534092689944
Validation loss: 2.6001217174673266

Epoch: 5| Step: 10
Training loss: 2.7044115477795136
Validation loss: 2.5992538544217254

Epoch: 192| Step: 0
Training loss: 3.206128308104238
Validation loss: 2.610711610938233

Epoch: 5| Step: 1
Training loss: 2.6706928515770207
Validation loss: 2.614682013863731

Epoch: 5| Step: 2
Training loss: 2.232498768360785
Validation loss: 2.6229624831893115

Epoch: 5| Step: 3
Training loss: 3.0303071118818594
Validation loss: 2.619056146474912

Epoch: 5| Step: 4
Training loss: 2.9062043873478753
Validation loss: 2.6110056315684895

Epoch: 5| Step: 5
Training loss: 2.983630022466243
Validation loss: 2.5962055994977944

Epoch: 5| Step: 6
Training loss: 3.11296847697619
Validation loss: 2.5892760798385517

Epoch: 5| Step: 7
Training loss: 3.154600259935923
Validation loss: 2.59357949685001

Epoch: 5| Step: 8
Training loss: 2.980179478917755
Validation loss: 2.592251066421815

Epoch: 5| Step: 9
Training loss: 2.813131812442717
Validation loss: 2.5885549063665945

Epoch: 5| Step: 10
Training loss: 3.030104273144396
Validation loss: 2.590337252384735

Epoch: 193| Step: 0
Training loss: 3.0228182530612124
Validation loss: 2.589965132469393

Epoch: 5| Step: 1
Training loss: 2.5191388911428945
Validation loss: 2.59341314811674

Epoch: 5| Step: 2
Training loss: 3.1186201966819147
Validation loss: 2.600842319885719

Epoch: 5| Step: 3
Training loss: 3.1423099989038996
Validation loss: 2.6056602129591284

Epoch: 5| Step: 4
Training loss: 2.589948326979861
Validation loss: 2.6004692031320675

Epoch: 5| Step: 5
Training loss: 2.784885302361365
Validation loss: 2.6157779792308635

Epoch: 5| Step: 6
Training loss: 2.528120484601528
Validation loss: 2.6100781575087404

Epoch: 5| Step: 7
Training loss: 3.1680817871999745
Validation loss: 2.6119502294599863

Epoch: 5| Step: 8
Training loss: 3.075208647557623
Validation loss: 2.60064364422369

Epoch: 5| Step: 9
Training loss: 3.197082626148472
Validation loss: 2.594547744555617

Epoch: 5| Step: 10
Training loss: 2.9082785469148775
Validation loss: 2.59570953581434

Epoch: 194| Step: 0
Training loss: 2.82953503270091
Validation loss: 2.5947983934928955

Epoch: 5| Step: 1
Training loss: 2.740579421600672
Validation loss: 2.599058919973189

Epoch: 5| Step: 2
Training loss: 2.8843473984874173
Validation loss: 2.590411001335087

Epoch: 5| Step: 3
Training loss: 3.331546081783043
Validation loss: 2.5887697583638123

Epoch: 5| Step: 4
Training loss: 2.5524160570470253
Validation loss: 2.5932175482291058

Epoch: 5| Step: 5
Training loss: 2.8819646648223616
Validation loss: 2.5859969006836505

Epoch: 5| Step: 6
Training loss: 3.274786550540221
Validation loss: 2.5840877307383336

Epoch: 5| Step: 7
Training loss: 2.6072741062996925
Validation loss: 2.592901733356173

Epoch: 5| Step: 8
Training loss: 3.0486628055655114
Validation loss: 2.5901786807750193

Epoch: 5| Step: 9
Training loss: 3.206384107971402
Validation loss: 2.599203667115373

Epoch: 5| Step: 10
Training loss: 2.6273380040137972
Validation loss: 2.5932301903449044

Epoch: 195| Step: 0
Training loss: 3.4753156504905327
Validation loss: 2.589628994037673

Epoch: 5| Step: 1
Training loss: 2.2252592857243383
Validation loss: 2.593334274887588

Epoch: 5| Step: 2
Training loss: 3.1912164900171263
Validation loss: 2.5867758257240467

Epoch: 5| Step: 3
Training loss: 3.2210759027557043
Validation loss: 2.590471475134825

Epoch: 5| Step: 4
Training loss: 2.964081959115092
Validation loss: 2.5872745535189243

Epoch: 5| Step: 5
Training loss: 2.7756753838511687
Validation loss: 2.5872341784145867

Epoch: 5| Step: 6
Training loss: 3.1694675573616413
Validation loss: 2.5857877401387794

Epoch: 5| Step: 7
Training loss: 2.6268061827223064
Validation loss: 2.5833673689945758

Epoch: 5| Step: 8
Training loss: 2.9727778366026443
Validation loss: 2.578702001057097

Epoch: 5| Step: 9
Training loss: 2.750502973856217
Validation loss: 2.58313900404878

Epoch: 5| Step: 10
Training loss: 2.4660407543790313
Validation loss: 2.5815422155098915

Epoch: 196| Step: 0
Training loss: 3.0191620160526007
Validation loss: 2.5791003686993523

Epoch: 5| Step: 1
Training loss: 2.9697255991037568
Validation loss: 2.5786662220090086

Epoch: 5| Step: 2
Training loss: 2.8512897517783404
Validation loss: 2.584489441300536

Epoch: 5| Step: 3
Training loss: 3.362335036531634
Validation loss: 2.587486454271985

Epoch: 5| Step: 4
Training loss: 2.7248504422644446
Validation loss: 2.5995033947479476

Epoch: 5| Step: 5
Training loss: 3.2508634740675233
Validation loss: 2.6046685412416415

Epoch: 5| Step: 6
Training loss: 3.2939663028811634
Validation loss: 2.5899027087018394

Epoch: 5| Step: 7
Training loss: 2.651377528611279
Validation loss: 2.5929020052527627

Epoch: 5| Step: 8
Training loss: 2.6896921133376552
Validation loss: 2.607212803940257

Epoch: 5| Step: 9
Training loss: 2.6887256577585616
Validation loss: 2.5988512881276806

Epoch: 5| Step: 10
Training loss: 2.3728282435294417
Validation loss: 2.5952258447364867

Epoch: 197| Step: 0
Training loss: 2.9614015884857854
Validation loss: 2.585769251791597

Epoch: 5| Step: 1
Training loss: 2.791695001562758
Validation loss: 2.5867499273095866

Epoch: 5| Step: 2
Training loss: 3.16272667837647
Validation loss: 2.5822419677286166

Epoch: 5| Step: 3
Training loss: 2.9932872056132678
Validation loss: 2.5797012547068228

Epoch: 5| Step: 4
Training loss: 2.8473893238023686
Validation loss: 2.576686696825561

Epoch: 5| Step: 5
Training loss: 2.889725828794245
Validation loss: 2.580824848425872

Epoch: 5| Step: 6
Training loss: 3.2975870963416547
Validation loss: 2.578834256645247

Epoch: 5| Step: 7
Training loss: 2.593851202403712
Validation loss: 2.5789754380349796

Epoch: 5| Step: 8
Training loss: 2.9735891955955513
Validation loss: 2.5780126403607153

Epoch: 5| Step: 9
Training loss: 2.866595048527296
Validation loss: 2.5818394388072683

Epoch: 5| Step: 10
Training loss: 2.734859053137354
Validation loss: 2.5796785319589137

Epoch: 198| Step: 0
Training loss: 3.0438527303353107
Validation loss: 2.5791152002167292

Epoch: 5| Step: 1
Training loss: 3.296533503631347
Validation loss: 2.5870433594466107

Epoch: 5| Step: 2
Training loss: 3.1172095276477347
Validation loss: 2.5943772958099127

Epoch: 5| Step: 3
Training loss: 2.9394490695050925
Validation loss: 2.6133012143460825

Epoch: 5| Step: 4
Training loss: 2.079347523357817
Validation loss: 2.6072610563777134

Epoch: 5| Step: 5
Training loss: 2.886049680899502
Validation loss: 2.6277584548256865

Epoch: 5| Step: 6
Training loss: 3.0711525891280633
Validation loss: 2.647700238201555

Epoch: 5| Step: 7
Training loss: 2.5925700249774586
Validation loss: 2.642824460216044

Epoch: 5| Step: 8
Training loss: 3.123681820373067
Validation loss: 2.6253814771660475

Epoch: 5| Step: 9
Training loss: 2.8719881286588262
Validation loss: 2.5936878264598864

Epoch: 5| Step: 10
Training loss: 3.0058081351728343
Validation loss: 2.5787938020832533

Epoch: 199| Step: 0
Training loss: 3.1731226679921294
Validation loss: 2.5784921572990225

Epoch: 5| Step: 1
Training loss: 2.912810437599011
Validation loss: 2.5852179045763197

Epoch: 5| Step: 2
Training loss: 2.8868170322727114
Validation loss: 2.587891426419091

Epoch: 5| Step: 3
Training loss: 3.05132809474574
Validation loss: 2.592000039610716

Epoch: 5| Step: 4
Training loss: 2.8596618174968205
Validation loss: 2.590621910279909

Epoch: 5| Step: 5
Training loss: 2.953725925239284
Validation loss: 2.591920415192279

Epoch: 5| Step: 6
Training loss: 3.1835470184453603
Validation loss: 2.588166668983024

Epoch: 5| Step: 7
Training loss: 2.7516275271476585
Validation loss: 2.5878775734242425

Epoch: 5| Step: 8
Training loss: 3.021762906572519
Validation loss: 2.586846990024766

Epoch: 5| Step: 9
Training loss: 2.991487027639539
Validation loss: 2.584971610714887

Epoch: 5| Step: 10
Training loss: 2.7452287898927845
Validation loss: 2.583840770549334

Epoch: 200| Step: 0
Training loss: 2.570892175859388
Validation loss: 2.5817996032826795

Epoch: 5| Step: 1
Training loss: 2.892943571034179
Validation loss: 2.582469515582285

Epoch: 5| Step: 2
Training loss: 2.640972408036435
Validation loss: 2.5778745408397055

Epoch: 5| Step: 3
Training loss: 2.791442881102795
Validation loss: 2.572258708261014

Epoch: 5| Step: 4
Training loss: 2.718176945768671
Validation loss: 2.5740816012357595

Epoch: 5| Step: 5
Training loss: 2.8922345603275548
Validation loss: 2.571564787069344

Epoch: 5| Step: 6
Training loss: 3.2213553837512015
Validation loss: 2.5847017290808276

Epoch: 5| Step: 7
Training loss: 3.088144329344849
Validation loss: 2.6024102093658725

Epoch: 5| Step: 8
Training loss: 3.3545945331002893
Validation loss: 2.6052144820027796

Epoch: 5| Step: 9
Training loss: 3.0622697081880355
Validation loss: 2.5991491231731425

Epoch: 5| Step: 10
Training loss: 2.889549261404282
Validation loss: 2.598800314721735

Testing loss: 2.806577611735121
