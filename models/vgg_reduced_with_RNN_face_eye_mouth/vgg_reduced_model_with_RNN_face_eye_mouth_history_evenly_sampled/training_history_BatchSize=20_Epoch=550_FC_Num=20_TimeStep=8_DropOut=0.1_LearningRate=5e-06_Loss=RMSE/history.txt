Epoch: 1| Step: 0
Training loss: 5.600943090862473
Validation loss: 5.807537672660425

Epoch: 5| Step: 1
Training loss: 4.684887984818618
Validation loss: 5.801931263652601

Epoch: 5| Step: 2
Training loss: 6.21939681633462
Validation loss: 5.796746759831784

Epoch: 5| Step: 3
Training loss: 6.1455015276117955
Validation loss: 5.791988263246507

Epoch: 5| Step: 4
Training loss: 6.452213989682328
Validation loss: 5.787198107302065

Epoch: 5| Step: 5
Training loss: 6.293137873076577
Validation loss: 5.783000071206036

Epoch: 5| Step: 6
Training loss: 4.782673144000513
Validation loss: 5.778530818124361

Epoch: 5| Step: 7
Training loss: 6.303343524464008
Validation loss: 5.774675949146916

Epoch: 5| Step: 8
Training loss: 6.084532040458591
Validation loss: 5.770179381263036

Epoch: 5| Step: 9
Training loss: 5.751192715547549
Validation loss: 5.765802484237158

Epoch: 5| Step: 10
Training loss: 5.267109013744722
Validation loss: 5.7610829330416955

Epoch: 2| Step: 0
Training loss: 6.4244810139674415
Validation loss: 5.756770983485437

Epoch: 5| Step: 1
Training loss: 5.787509478237885
Validation loss: 5.751635878290917

Epoch: 5| Step: 2
Training loss: 6.587618467362329
Validation loss: 5.746783019600706

Epoch: 5| Step: 3
Training loss: 5.586522041093636
Validation loss: 5.74148187398745

Epoch: 5| Step: 4
Training loss: 5.6493402078956
Validation loss: 5.735299771406848

Epoch: 5| Step: 5
Training loss: 5.5222130353012435
Validation loss: 5.729313620493958

Epoch: 5| Step: 6
Training loss: 6.18469421272247
Validation loss: 5.722832042168572

Epoch: 5| Step: 7
Training loss: 5.3504888863768505
Validation loss: 5.716240387634708

Epoch: 5| Step: 8
Training loss: 5.568788895219631
Validation loss: 5.709293748460289

Epoch: 5| Step: 9
Training loss: 6.012548041201327
Validation loss: 5.701923427522955

Epoch: 5| Step: 10
Training loss: 4.159836218617586
Validation loss: 5.694109534656155

Epoch: 3| Step: 0
Training loss: 6.223798533241018
Validation loss: 5.685209496180961

Epoch: 5| Step: 1
Training loss: 5.747122998510625
Validation loss: 5.677174094781274

Epoch: 5| Step: 2
Training loss: 4.857373576735152
Validation loss: 5.668414489981569

Epoch: 5| Step: 3
Training loss: 5.979987146880457
Validation loss: 5.6586270107773196

Epoch: 5| Step: 4
Training loss: 5.311428904546934
Validation loss: 5.648390929400124

Epoch: 5| Step: 5
Training loss: 5.339695513327406
Validation loss: 5.637570331654

Epoch: 5| Step: 6
Training loss: 4.89127450353391
Validation loss: 5.626094103728018

Epoch: 5| Step: 7
Training loss: 5.755832864928771
Validation loss: 5.614698358591447

Epoch: 5| Step: 8
Training loss: 5.981533880084084
Validation loss: 5.602694089407206

Epoch: 5| Step: 9
Training loss: 6.046620129480136
Validation loss: 5.59013078668254

Epoch: 5| Step: 10
Training loss: 6.099226618034025
Validation loss: 5.57603923393525

Epoch: 4| Step: 0
Training loss: 5.491301159810339
Validation loss: 5.5628923381702595

Epoch: 5| Step: 1
Training loss: 5.589893738038629
Validation loss: 5.547291280564747

Epoch: 5| Step: 2
Training loss: 5.629352157476971
Validation loss: 5.532446379924343

Epoch: 5| Step: 3
Training loss: 6.166361758280516
Validation loss: 5.5175946565642295

Epoch: 5| Step: 4
Training loss: 4.774205022813066
Validation loss: 5.499773417976717

Epoch: 5| Step: 5
Training loss: 6.157143774844902
Validation loss: 5.483100005515821

Epoch: 5| Step: 6
Training loss: 5.678728319110329
Validation loss: 5.465574139647249

Epoch: 5| Step: 7
Training loss: 5.22377749656493
Validation loss: 5.447159864246635

Epoch: 5| Step: 8
Training loss: 5.8738324242893425
Validation loss: 5.428426139676688

Epoch: 5| Step: 9
Training loss: 5.01753573995576
Validation loss: 5.409691603740662

Epoch: 5| Step: 10
Training loss: 4.85132228483915
Validation loss: 5.391648075464582

Epoch: 5| Step: 0
Training loss: 5.923878675497306
Validation loss: 5.372475500801888

Epoch: 5| Step: 1
Training loss: 4.852410431260757
Validation loss: 5.352489303337013

Epoch: 5| Step: 2
Training loss: 5.450484808960572
Validation loss: 5.332241840088605

Epoch: 5| Step: 3
Training loss: 5.8575374722879765
Validation loss: 5.312919099262781

Epoch: 5| Step: 4
Training loss: 4.874669186053748
Validation loss: 5.291523489720036

Epoch: 5| Step: 5
Training loss: 5.19592832199592
Validation loss: 5.271824163306337

Epoch: 5| Step: 6
Training loss: 5.204983399407759
Validation loss: 5.2515706214559215

Epoch: 5| Step: 7
Training loss: 5.395073423548877
Validation loss: 5.232217870285054

Epoch: 5| Step: 8
Training loss: 5.082822721924282
Validation loss: 5.211353958194876

Epoch: 5| Step: 9
Training loss: 5.955610422258073
Validation loss: 5.191581291829748

Epoch: 5| Step: 10
Training loss: 4.374675411717507
Validation loss: 5.169499049954682

Epoch: 6| Step: 0
Training loss: 4.90564660899496
Validation loss: 5.150445863733957

Epoch: 5| Step: 1
Training loss: 5.224772558783361
Validation loss: 5.13003171178763

Epoch: 5| Step: 2
Training loss: 6.279185093289655
Validation loss: 5.111155095712932

Epoch: 5| Step: 3
Training loss: 3.4786679182604754
Validation loss: 5.09164386981345

Epoch: 5| Step: 4
Training loss: 5.1990320185053065
Validation loss: 5.073280946858535

Epoch: 5| Step: 5
Training loss: 5.090884848016757
Validation loss: 5.055272860313933

Epoch: 5| Step: 6
Training loss: 4.466685852085493
Validation loss: 5.035103668974716

Epoch: 5| Step: 7
Training loss: 5.615292458938721
Validation loss: 5.017270769621942

Epoch: 5| Step: 8
Training loss: 4.843129567434471
Validation loss: 4.9976096130591765

Epoch: 5| Step: 9
Training loss: 5.611761154105939
Validation loss: 4.980250450656764

Epoch: 5| Step: 10
Training loss: 5.024122983399126
Validation loss: 4.962970410456714

Epoch: 7| Step: 0
Training loss: 3.5519104558466195
Validation loss: 4.9450719346179515

Epoch: 5| Step: 1
Training loss: 5.212063280285007
Validation loss: 4.927266494366793

Epoch: 5| Step: 2
Training loss: 4.754550360470381
Validation loss: 4.910293159896585

Epoch: 5| Step: 3
Training loss: 5.356482434209335
Validation loss: 4.894422114703731

Epoch: 5| Step: 4
Training loss: 4.654516934448344
Validation loss: 4.877033801202081

Epoch: 5| Step: 5
Training loss: 4.360192881876109
Validation loss: 4.860748294273867

Epoch: 5| Step: 6
Training loss: 4.961690049650795
Validation loss: 4.846206032844131

Epoch: 5| Step: 7
Training loss: 4.603379724606261
Validation loss: 4.829138639604217

Epoch: 5| Step: 8
Training loss: 5.966056175895875
Validation loss: 4.815353159331386

Epoch: 5| Step: 9
Training loss: 4.938058749103207
Validation loss: 4.800094959813472

Epoch: 5| Step: 10
Training loss: 5.608060464933017
Validation loss: 4.78552253049578

Epoch: 8| Step: 0
Training loss: 5.041049488638196
Validation loss: 4.770948952528021

Epoch: 5| Step: 1
Training loss: 4.323345092624112
Validation loss: 4.7568002866039505

Epoch: 5| Step: 2
Training loss: 5.220644304405827
Validation loss: 4.740594927627321

Epoch: 5| Step: 3
Training loss: 4.050909792590435
Validation loss: 4.7265155830248045

Epoch: 5| Step: 4
Training loss: 5.453651905563433
Validation loss: 4.712749329442136

Epoch: 5| Step: 5
Training loss: 5.354906538175318
Validation loss: 4.698128131268767

Epoch: 5| Step: 6
Training loss: 5.135594651837168
Validation loss: 4.6833637389103

Epoch: 5| Step: 7
Training loss: 4.684518908834349
Validation loss: 4.66767459450057

Epoch: 5| Step: 8
Training loss: 4.216329600818035
Validation loss: 4.656577982489704

Epoch: 5| Step: 9
Training loss: 4.220525071441006
Validation loss: 4.642361913027548

Epoch: 5| Step: 10
Training loss: 4.693332756179716
Validation loss: 4.627672803886141

Epoch: 9| Step: 0
Training loss: 3.80700061831959
Validation loss: 4.613148791589854

Epoch: 5| Step: 1
Training loss: 5.2907704873537575
Validation loss: 4.599267020285473

Epoch: 5| Step: 2
Training loss: 4.970400937830679
Validation loss: 4.584193864660395

Epoch: 5| Step: 3
Training loss: 4.625987385694273
Validation loss: 4.570680192716754

Epoch: 5| Step: 4
Training loss: 3.9246995944579353
Validation loss: 4.5555691018959035

Epoch: 5| Step: 5
Training loss: 4.868681505380084
Validation loss: 4.5412996333280065

Epoch: 5| Step: 6
Training loss: 4.542495558573305
Validation loss: 4.528533059904407

Epoch: 5| Step: 7
Training loss: 4.2651773853688795
Validation loss: 4.5148395068470535

Epoch: 5| Step: 8
Training loss: 4.67622076405245
Validation loss: 4.501572057478485

Epoch: 5| Step: 9
Training loss: 5.054364861829243
Validation loss: 4.487707295369982

Epoch: 5| Step: 10
Training loss: 4.829839408210841
Validation loss: 4.475985012836484

Epoch: 10| Step: 0
Training loss: 5.028464736983246
Validation loss: 4.462968501624156

Epoch: 5| Step: 1
Training loss: 4.146388925611841
Validation loss: 4.451962937501894

Epoch: 5| Step: 2
Training loss: 4.45874119019019
Validation loss: 4.441542778572241

Epoch: 5| Step: 3
Training loss: 5.252262536209284
Validation loss: 4.428773451368416

Epoch: 5| Step: 4
Training loss: 4.046472242189673
Validation loss: 4.416904433001867

Epoch: 5| Step: 5
Training loss: 4.861628068350724
Validation loss: 4.407931513516454

Epoch: 5| Step: 6
Training loss: 4.603775606190349
Validation loss: 4.3958456325704

Epoch: 5| Step: 7
Training loss: 5.200087751968598
Validation loss: 4.383486260052715

Epoch: 5| Step: 8
Training loss: 4.20463903449516
Validation loss: 4.373361461755538

Epoch: 5| Step: 9
Training loss: 3.8731326864627036
Validation loss: 4.365451818064774

Epoch: 5| Step: 10
Training loss: 3.5341925050282215
Validation loss: 4.352607045397877

Epoch: 11| Step: 0
Training loss: 4.280280678717067
Validation loss: 4.345684922223868

Epoch: 5| Step: 1
Training loss: 4.797513142737217
Validation loss: 4.337277074763191

Epoch: 5| Step: 2
Training loss: 3.8061412877184675
Validation loss: 4.325941396886922

Epoch: 5| Step: 3
Training loss: 4.63486253948137
Validation loss: 4.315464633756648

Epoch: 5| Step: 4
Training loss: 5.004589644614864
Validation loss: 4.307650476001508

Epoch: 5| Step: 5
Training loss: 4.902831228875606
Validation loss: 4.30165877965313

Epoch: 5| Step: 6
Training loss: 3.5240049053335527
Validation loss: 4.288522618629728

Epoch: 5| Step: 7
Training loss: 3.726153017334869
Validation loss: 4.282134985363454

Epoch: 5| Step: 8
Training loss: 3.479417224625765
Validation loss: 4.271646316108104

Epoch: 5| Step: 9
Training loss: 4.792884981376264
Validation loss: 4.264588925662112

Epoch: 5| Step: 10
Training loss: 5.3370168998840954
Validation loss: 4.259615310114447

Epoch: 12| Step: 0
Training loss: 5.445907056796384
Validation loss: 4.252167551323294

Epoch: 5| Step: 1
Training loss: 4.173734443409351
Validation loss: 4.244543009267503

Epoch: 5| Step: 2
Training loss: 4.619952566390508
Validation loss: 4.23340509760959

Epoch: 5| Step: 3
Training loss: 4.728991579464123
Validation loss: 4.2230716642253485

Epoch: 5| Step: 4
Training loss: 3.261764069202377
Validation loss: 4.214408750107887

Epoch: 5| Step: 5
Training loss: 3.945521706048257
Validation loss: 4.209891228390546

Epoch: 5| Step: 6
Training loss: 4.388345907453832
Validation loss: 4.203827910470849

Epoch: 5| Step: 7
Training loss: 4.024899707753065
Validation loss: 4.197728171463142

Epoch: 5| Step: 8
Training loss: 4.660151338534713
Validation loss: 4.191180024384218

Epoch: 5| Step: 9
Training loss: 4.416615083981037
Validation loss: 4.185991206732134

Epoch: 5| Step: 10
Training loss: 3.5874537501527266
Validation loss: 4.179586591739747

Epoch: 13| Step: 0
Training loss: 3.938751143028895
Validation loss: 4.17651819413763

Epoch: 5| Step: 1
Training loss: 4.301589432537485
Validation loss: 4.170341868435037

Epoch: 5| Step: 2
Training loss: 3.5733701605346204
Validation loss: 4.163265488223

Epoch: 5| Step: 3
Training loss: 4.569859252364976
Validation loss: 4.153799591268588

Epoch: 5| Step: 4
Training loss: 3.842266385702419
Validation loss: 4.151019513252787

Epoch: 5| Step: 5
Training loss: 4.814137564138585
Validation loss: 4.143706392582061

Epoch: 5| Step: 6
Training loss: 4.819022972202583
Validation loss: 4.138209140660133

Epoch: 5| Step: 7
Training loss: 3.96747971277753
Validation loss: 4.130803830291586

Epoch: 5| Step: 8
Training loss: 4.4751408901092855
Validation loss: 4.1272112729418

Epoch: 5| Step: 9
Training loss: 3.563287748277757
Validation loss: 4.121308112409826

Epoch: 5| Step: 10
Training loss: 5.064260106172829
Validation loss: 4.11764097529119

Epoch: 14| Step: 0
Training loss: 4.31020282985015
Validation loss: 4.110021294488571

Epoch: 5| Step: 1
Training loss: 5.257185968080121
Validation loss: 4.107496840775654

Epoch: 5| Step: 2
Training loss: 4.192268048343302
Validation loss: 4.104838281604814

Epoch: 5| Step: 3
Training loss: 2.933655353412357
Validation loss: 4.09889390363202

Epoch: 5| Step: 4
Training loss: 4.622243111106752
Validation loss: 4.092826425337068

Epoch: 5| Step: 5
Training loss: 5.041385464142897
Validation loss: 4.088112480168897

Epoch: 5| Step: 6
Training loss: 3.903982496175455
Validation loss: 4.081803492108277

Epoch: 5| Step: 7
Training loss: 4.345335087996959
Validation loss: 4.074061960522601

Epoch: 5| Step: 8
Training loss: 4.11353349772602
Validation loss: 4.068931137500526

Epoch: 5| Step: 9
Training loss: 3.5522444493660283
Validation loss: 4.0652497255066375

Epoch: 5| Step: 10
Training loss: 3.66614595241504
Validation loss: 4.058437116163913

Epoch: 15| Step: 0
Training loss: 4.998661052716646
Validation loss: 4.0519245657641365

Epoch: 5| Step: 1
Training loss: 4.396390665649467
Validation loss: 4.045945266982063

Epoch: 5| Step: 2
Training loss: 3.683431417502746
Validation loss: 4.044007031687841

Epoch: 5| Step: 3
Training loss: 3.46551926832521
Validation loss: 4.037909146499387

Epoch: 5| Step: 4
Training loss: 3.455466464803252
Validation loss: 4.0328066797206485

Epoch: 5| Step: 5
Training loss: 4.1558020787771826
Validation loss: 4.027237433111599

Epoch: 5| Step: 6
Training loss: 4.820130083536833
Validation loss: 4.02104859581111

Epoch: 5| Step: 7
Training loss: 4.189987582459178
Validation loss: 4.011281445258291

Epoch: 5| Step: 8
Training loss: 4.375150405478267
Validation loss: 4.000956892593803

Epoch: 5| Step: 9
Training loss: 3.783483176828043
Validation loss: 3.9974309108112056

Epoch: 5| Step: 10
Training loss: 4.259797863530001
Validation loss: 3.986975926786215

Epoch: 16| Step: 0
Training loss: 3.891833994587984
Validation loss: 3.974127287516068

Epoch: 5| Step: 1
Training loss: 4.29492720412357
Validation loss: 3.963255197359959

Epoch: 5| Step: 2
Training loss: 4.259035715204637
Validation loss: 3.9538902350421963

Epoch: 5| Step: 3
Training loss: 4.965994016596876
Validation loss: 3.9416753075288224

Epoch: 5| Step: 4
Training loss: 3.5210840861998514
Validation loss: 3.9361866109731785

Epoch: 5| Step: 5
Training loss: 4.075788157250472
Validation loss: 3.9244865753123275

Epoch: 5| Step: 6
Training loss: 4.381112760171094
Validation loss: 3.9221313684310037

Epoch: 5| Step: 7
Training loss: 3.7015297588351213
Validation loss: 3.9172828222823406

Epoch: 5| Step: 8
Training loss: 3.747875374691473
Validation loss: 3.9138137849380557

Epoch: 5| Step: 9
Training loss: 3.5949909223884924
Validation loss: 3.9061558419641442

Epoch: 5| Step: 10
Training loss: 4.387000057070027
Validation loss: 3.90648371696651

Epoch: 17| Step: 0
Training loss: 3.4475325786332034
Validation loss: 3.9032618779375303

Epoch: 5| Step: 1
Training loss: 3.8154078166365095
Validation loss: 3.899223587543629

Epoch: 5| Step: 2
Training loss: 4.08691954618061
Validation loss: 3.8945642342932913

Epoch: 5| Step: 3
Training loss: 3.3911957853646983
Validation loss: 3.890916552728464

Epoch: 5| Step: 4
Training loss: 4.837651899451691
Validation loss: 3.888905279844776

Epoch: 5| Step: 5
Training loss: 2.809484857738699
Validation loss: 3.88005654279762

Epoch: 5| Step: 6
Training loss: 4.293417021210213
Validation loss: 3.877159842542906

Epoch: 5| Step: 7
Training loss: 3.7543297249921936
Validation loss: 3.876967995192698

Epoch: 5| Step: 8
Training loss: 4.602284295509604
Validation loss: 3.871649224571938

Epoch: 5| Step: 9
Training loss: 5.259946211623263
Validation loss: 3.863951035807351

Epoch: 5| Step: 10
Training loss: 3.4931175137117285
Validation loss: 3.857270585262215

Epoch: 18| Step: 0
Training loss: 3.7090184439670812
Validation loss: 3.857988053611303

Epoch: 5| Step: 1
Training loss: 3.6158647858311936
Validation loss: 3.8620131587254463

Epoch: 5| Step: 2
Training loss: 4.056186876555254
Validation loss: 3.8585911190906965

Epoch: 5| Step: 3
Training loss: 3.6374942268247117
Validation loss: 3.848249870628826

Epoch: 5| Step: 4
Training loss: 4.152838891868599
Validation loss: 3.8361740171382093

Epoch: 5| Step: 5
Training loss: 4.264818052321714
Validation loss: 3.838043543000035

Epoch: 5| Step: 6
Training loss: 4.022628199097429
Validation loss: 3.830670154362627

Epoch: 5| Step: 7
Training loss: 4.533399400977613
Validation loss: 3.833363186923748

Epoch: 5| Step: 8
Training loss: 4.409729577940299
Validation loss: 3.8272491638509734

Epoch: 5| Step: 9
Training loss: 4.157660911689624
Validation loss: 3.824056305229187

Epoch: 5| Step: 10
Training loss: 3.1656122627265653
Validation loss: 3.8228188582361855

Epoch: 19| Step: 0
Training loss: 3.076419260885941
Validation loss: 3.816715837989333

Epoch: 5| Step: 1
Training loss: 4.363060053424105
Validation loss: 3.8138113121903836

Epoch: 5| Step: 2
Training loss: 4.254144106713885
Validation loss: 3.808919223270251

Epoch: 5| Step: 3
Training loss: 3.7121979510290815
Validation loss: 3.805237966535573

Epoch: 5| Step: 4
Training loss: 3.357593152535623
Validation loss: 3.8058146513371005

Epoch: 5| Step: 5
Training loss: 3.6211577474623824
Validation loss: 3.7989429639044943

Epoch: 5| Step: 6
Training loss: 4.356760204763572
Validation loss: 3.7966276279236446

Epoch: 5| Step: 7
Training loss: 3.4362216306356945
Validation loss: 3.7925767524173137

Epoch: 5| Step: 8
Training loss: 3.938804410403066
Validation loss: 3.7900088543460684

Epoch: 5| Step: 9
Training loss: 4.4530601095189875
Validation loss: 3.7882543295886975

Epoch: 5| Step: 10
Training loss: 4.8523434119530755
Validation loss: 3.7912210993520308

Epoch: 20| Step: 0
Training loss: 3.380140416541104
Validation loss: 3.7769738614625803

Epoch: 5| Step: 1
Training loss: 4.120284419566217
Validation loss: 3.7762311447293104

Epoch: 5| Step: 2
Training loss: 3.8628958884994224
Validation loss: 3.7703333833549566

Epoch: 5| Step: 3
Training loss: 4.742304340161216
Validation loss: 3.7642794563098825

Epoch: 5| Step: 4
Training loss: 3.887341688066573
Validation loss: 3.76048773869206

Epoch: 5| Step: 5
Training loss: 3.8911134957040505
Validation loss: 3.7576297025402194

Epoch: 5| Step: 6
Training loss: 3.9890035634630974
Validation loss: 3.7554418490583243

Epoch: 5| Step: 7
Training loss: 3.886424911356679
Validation loss: 3.7508156111648314

Epoch: 5| Step: 8
Training loss: 4.072781741874141
Validation loss: 3.7507419194074516

Epoch: 5| Step: 9
Training loss: 3.672390256401476
Validation loss: 3.7477705887974797

Epoch: 5| Step: 10
Training loss: 3.6006881744876242
Validation loss: 3.739588850112526

Epoch: 21| Step: 0
Training loss: 3.656374546114247
Validation loss: 3.7392630395219184

Epoch: 5| Step: 1
Training loss: 4.790019451571731
Validation loss: 3.73936931020398

Epoch: 5| Step: 2
Training loss: 3.4243251441964837
Validation loss: 3.732702201095821

Epoch: 5| Step: 3
Training loss: 3.556486039465581
Validation loss: 3.727710400809187

Epoch: 5| Step: 4
Training loss: 4.128339629329541
Validation loss: 3.7275413740501566

Epoch: 5| Step: 5
Training loss: 4.361768933444293
Validation loss: 3.719900631395044

Epoch: 5| Step: 6
Training loss: 3.7783143809319557
Validation loss: 3.7148801488389123

Epoch: 5| Step: 7
Training loss: 3.6514119800759524
Validation loss: 3.7103463645614383

Epoch: 5| Step: 8
Training loss: 3.6618809824613243
Validation loss: 3.714724732195653

Epoch: 5| Step: 9
Training loss: 3.6479886614138084
Validation loss: 3.712120130742238

Epoch: 5| Step: 10
Training loss: 4.131784120044081
Validation loss: 3.704825741857256

Epoch: 22| Step: 0
Training loss: 3.735838280177509
Validation loss: 3.6999613623803653

Epoch: 5| Step: 1
Training loss: 4.185754668488753
Validation loss: 3.6941739368633435

Epoch: 5| Step: 2
Training loss: 3.8649539547012006
Validation loss: 3.6980863558520034

Epoch: 5| Step: 3
Training loss: 3.5334104157682793
Validation loss: 3.7024672248428123

Epoch: 5| Step: 4
Training loss: 3.2564754532507245
Validation loss: 3.6918430771123516

Epoch: 5| Step: 5
Training loss: 4.89720437622473
Validation loss: 3.689792994253511

Epoch: 5| Step: 6
Training loss: 3.664780796464205
Validation loss: 3.682275234266449

Epoch: 5| Step: 7
Training loss: 4.113675843935034
Validation loss: 3.6815016834463608

Epoch: 5| Step: 8
Training loss: 4.026250059879259
Validation loss: 3.681211382918605

Epoch: 5| Step: 9
Training loss: 3.3502903371226767
Validation loss: 3.680452145649497

Epoch: 5| Step: 10
Training loss: 3.692636048865347
Validation loss: 3.6680285943961928

Epoch: 23| Step: 0
Training loss: 4.30860725186291
Validation loss: 3.664812099100734

Epoch: 5| Step: 1
Training loss: 4.300718052371163
Validation loss: 3.6530101800500523

Epoch: 5| Step: 2
Training loss: 4.13835409977824
Validation loss: 3.648745325907397

Epoch: 5| Step: 3
Training loss: 3.6506927512160945
Validation loss: 3.6504664183898177

Epoch: 5| Step: 4
Training loss: 4.06917668931112
Validation loss: 3.643210881922149

Epoch: 5| Step: 5
Training loss: 3.7632570537971626
Validation loss: 3.6439756905919016

Epoch: 5| Step: 6
Training loss: 4.440012475760863
Validation loss: 3.650802979225645

Epoch: 5| Step: 7
Training loss: 2.521641142069474
Validation loss: 3.6281919008628827

Epoch: 5| Step: 8
Training loss: 4.050693433760635
Validation loss: 3.6333832259721257

Epoch: 5| Step: 9
Training loss: 3.6885677020362366
Validation loss: 3.6278979804196836

Epoch: 5| Step: 10
Training loss: 2.548229676361609
Validation loss: 3.624666069188946

Epoch: 24| Step: 0
Training loss: 3.9499636588054567
Validation loss: 3.6253894827222104

Epoch: 5| Step: 1
Training loss: 3.542871846111393
Validation loss: 3.6146517265402553

Epoch: 5| Step: 2
Training loss: 4.520041658665254
Validation loss: 3.615011505406835

Epoch: 5| Step: 3
Training loss: 3.675386478577013
Validation loss: 3.6129726447740445

Epoch: 5| Step: 4
Training loss: 4.084303811933416
Validation loss: 3.6075396133563014

Epoch: 5| Step: 5
Training loss: 3.8827454467141536
Validation loss: 3.606039899227015

Epoch: 5| Step: 6
Training loss: 3.9226339753260593
Validation loss: 3.5986919591507784

Epoch: 5| Step: 7
Training loss: 3.4180544074088166
Validation loss: 3.598092819450404

Epoch: 5| Step: 8
Training loss: 3.2100133749424735
Validation loss: 3.5904190927329758

Epoch: 5| Step: 9
Training loss: 3.291459250051712
Validation loss: 3.5891221469044576

Epoch: 5| Step: 10
Training loss: 4.165685512735644
Validation loss: 3.5905353037543843

Epoch: 25| Step: 0
Training loss: 3.802861521612834
Validation loss: 3.5858530875583874

Epoch: 5| Step: 1
Training loss: 3.484234862652775
Validation loss: 3.581694917838595

Epoch: 5| Step: 2
Training loss: 3.7992473459236384
Validation loss: 3.574728759370772

Epoch: 5| Step: 3
Training loss: 3.6316589492872247
Validation loss: 3.5739574415527073

Epoch: 5| Step: 4
Training loss: 2.4282149486009033
Validation loss: 3.569976475606735

Epoch: 5| Step: 5
Training loss: 3.9172401549456417
Validation loss: 3.5637543943004153

Epoch: 5| Step: 6
Training loss: 3.6827821454369944
Validation loss: 3.5690198841630765

Epoch: 5| Step: 7
Training loss: 4.3346374212252545
Validation loss: 3.561167907078485

Epoch: 5| Step: 8
Training loss: 3.7570439621457843
Validation loss: 3.5573131262934403

Epoch: 5| Step: 9
Training loss: 4.19850307309755
Validation loss: 3.5547416573804647

Epoch: 5| Step: 10
Training loss: 4.121479497275216
Validation loss: 3.5470012327738174

Epoch: 26| Step: 0
Training loss: 3.8067470983858827
Validation loss: 3.548567814946767

Epoch: 5| Step: 1
Training loss: 3.77018493360654
Validation loss: 3.5467406657586653

Epoch: 5| Step: 2
Training loss: 3.5787712746219995
Validation loss: 3.537550136585254

Epoch: 5| Step: 3
Training loss: 3.846260305545205
Validation loss: 3.534973397242813

Epoch: 5| Step: 4
Training loss: 3.827088133854452
Validation loss: 3.5421936212565646

Epoch: 5| Step: 5
Training loss: 4.440737335910316
Validation loss: 3.5346603093725126

Epoch: 5| Step: 6
Training loss: 4.096435830607167
Validation loss: 3.5276579625109656

Epoch: 5| Step: 7
Training loss: 3.157187445386735
Validation loss: 3.5265812946757085

Epoch: 5| Step: 8
Training loss: 3.4901917491801107
Validation loss: 3.5254350445990417

Epoch: 5| Step: 9
Training loss: 3.442619534192262
Validation loss: 3.5232803181973704

Epoch: 5| Step: 10
Training loss: 3.4917916365832866
Validation loss: 3.5192278959951397

Epoch: 27| Step: 0
Training loss: 3.327216225782501
Validation loss: 3.5185317538176255

Epoch: 5| Step: 1
Training loss: 4.10884166200972
Validation loss: 3.5193677530113505

Epoch: 5| Step: 2
Training loss: 3.6421301354039746
Validation loss: 3.5111065594366866

Epoch: 5| Step: 3
Training loss: 4.26452913285577
Validation loss: 3.5083654226308174

Epoch: 5| Step: 4
Training loss: 3.362130104338762
Validation loss: 3.507214163533412

Epoch: 5| Step: 5
Training loss: 4.15134731620891
Validation loss: 3.508913991385961

Epoch: 5| Step: 6
Training loss: 2.451907396338309
Validation loss: 3.50482082463274

Epoch: 5| Step: 7
Training loss: 4.190732249367486
Validation loss: 3.497643446521451

Epoch: 5| Step: 8
Training loss: 3.0114247219374413
Validation loss: 3.4957647613715395

Epoch: 5| Step: 9
Training loss: 4.336101576991287
Validation loss: 3.4978670661576374

Epoch: 5| Step: 10
Training loss: 3.563455955339155
Validation loss: 3.4997586783849406

Epoch: 28| Step: 0
Training loss: 3.2238595646451027
Validation loss: 3.4955453783247625

Epoch: 5| Step: 1
Training loss: 4.77874450858896
Validation loss: 3.4951443104634103

Epoch: 5| Step: 2
Training loss: 3.001881009726671
Validation loss: 3.4896310101727828

Epoch: 5| Step: 3
Training loss: 4.1708512210875215
Validation loss: 3.4851916876460236

Epoch: 5| Step: 4
Training loss: 3.878693819711774
Validation loss: 3.4855437998186427

Epoch: 5| Step: 5
Training loss: 3.8665277708253276
Validation loss: 3.481000616720048

Epoch: 5| Step: 6
Training loss: 3.609245661280102
Validation loss: 3.483051967272254

Epoch: 5| Step: 7
Training loss: 2.8529270199527987
Validation loss: 3.478996569404285

Epoch: 5| Step: 8
Training loss: 3.2397261871209255
Validation loss: 3.4755951960178373

Epoch: 5| Step: 9
Training loss: 3.4198456063472285
Validation loss: 3.471966525654356

Epoch: 5| Step: 10
Training loss: 4.268183684868007
Validation loss: 3.4780855056797515

Epoch: 29| Step: 0
Training loss: 3.9179407577047143
Validation loss: 3.469757075787871

Epoch: 5| Step: 1
Training loss: 3.3132562313920726
Validation loss: 3.468961288549022

Epoch: 5| Step: 2
Training loss: 2.9211530966595256
Validation loss: 3.468059006466152

Epoch: 5| Step: 3
Training loss: 3.849962254128647
Validation loss: 3.4675209168620675

Epoch: 5| Step: 4
Training loss: 3.4483933287376916
Validation loss: 3.462372840378738

Epoch: 5| Step: 5
Training loss: 3.580497654684359
Validation loss: 3.4628337355280143

Epoch: 5| Step: 6
Training loss: 3.6392709727211336
Validation loss: 3.459046950079147

Epoch: 5| Step: 7
Training loss: 3.426630486867569
Validation loss: 3.460934378537532

Epoch: 5| Step: 8
Training loss: 4.464265507243609
Validation loss: 3.458057462737182

Epoch: 5| Step: 9
Training loss: 3.461774393339118
Validation loss: 3.453448616973569

Epoch: 5| Step: 10
Training loss: 4.266602344822828
Validation loss: 3.452077639668755

Epoch: 30| Step: 0
Training loss: 4.241764616569139
Validation loss: 3.44803147322652

Epoch: 5| Step: 1
Training loss: 3.228796086530705
Validation loss: 3.447267841146787

Epoch: 5| Step: 2
Training loss: 3.93419569120479
Validation loss: 3.4445753873713536

Epoch: 5| Step: 3
Training loss: 3.499437695701438
Validation loss: 3.4480245444640443

Epoch: 5| Step: 4
Training loss: 3.4079745065693725
Validation loss: 3.4450238861075557

Epoch: 5| Step: 5
Training loss: 3.4370796640202115
Validation loss: 3.4392525241144316

Epoch: 5| Step: 6
Training loss: 3.2351972483856244
Validation loss: 3.4327130387756815

Epoch: 5| Step: 7
Training loss: 3.996708827259016
Validation loss: 3.4387643974037005

Epoch: 5| Step: 8
Training loss: 3.135841332421266
Validation loss: 3.4357239088442206

Epoch: 5| Step: 9
Training loss: 4.538340525897534
Validation loss: 3.4371263780151136

Epoch: 5| Step: 10
Training loss: 3.2467093314383906
Validation loss: 3.430110478032647

Epoch: 31| Step: 0
Training loss: 3.231601871538004
Validation loss: 3.4310606947614284

Epoch: 5| Step: 1
Training loss: 3.1606641061908314
Validation loss: 3.4247873345490443

Epoch: 5| Step: 2
Training loss: 3.3586552758270414
Validation loss: 3.4351419253113145

Epoch: 5| Step: 3
Training loss: 3.6789748358191217
Validation loss: 3.429790407733096

Epoch: 5| Step: 4
Training loss: 3.0373946371760456
Validation loss: 3.42914443591911

Epoch: 5| Step: 5
Training loss: 2.9317818035210315
Validation loss: 3.423650860920553

Epoch: 5| Step: 6
Training loss: 4.7708431504771855
Validation loss: 3.4314825405244775

Epoch: 5| Step: 7
Training loss: 4.2024696718445735
Validation loss: 3.416544003889666

Epoch: 5| Step: 8
Training loss: 3.313940778526608
Validation loss: 3.4172270805704055

Epoch: 5| Step: 9
Training loss: 3.912903756950486
Validation loss: 3.422334175807226

Epoch: 5| Step: 10
Training loss: 4.131654862087837
Validation loss: 3.418839749272901

Epoch: 32| Step: 0
Training loss: 3.5290144874402936
Validation loss: 3.41887145007697

Epoch: 5| Step: 1
Training loss: 3.4261651166597633
Validation loss: 3.4198609603648267

Epoch: 5| Step: 2
Training loss: 3.5587570873172507
Validation loss: 3.423448955166842

Epoch: 5| Step: 3
Training loss: 3.67491705664631
Validation loss: 3.4201965995669514

Epoch: 5| Step: 4
Training loss: 3.8900839800950804
Validation loss: 3.4176951125344

Epoch: 5| Step: 5
Training loss: 4.236631348285382
Validation loss: 3.4047835957561094

Epoch: 5| Step: 6
Training loss: 2.757033110974949
Validation loss: 3.4054363099596334

Epoch: 5| Step: 7
Training loss: 3.882816798248061
Validation loss: 3.4053817294166557

Epoch: 5| Step: 8
Training loss: 3.713729675298983
Validation loss: 3.4047063856159188

Epoch: 5| Step: 9
Training loss: 2.798774543031022
Validation loss: 3.4000773907852877

Epoch: 5| Step: 10
Training loss: 4.261213655549004
Validation loss: 3.401284727734726

Epoch: 33| Step: 0
Training loss: 3.9287940767287446
Validation loss: 3.397543717946466

Epoch: 5| Step: 1
Training loss: 4.163637636993928
Validation loss: 3.401144460742684

Epoch: 5| Step: 2
Training loss: 3.050142541274871
Validation loss: 3.409112760474414

Epoch: 5| Step: 3
Training loss: 3.3170181267110506
Validation loss: 3.406985897798839

Epoch: 5| Step: 4
Training loss: 3.251309204501154
Validation loss: 3.4081618817813917

Epoch: 5| Step: 5
Training loss: 3.610340071957303
Validation loss: 3.401510839870623

Epoch: 5| Step: 6
Training loss: 3.5208183754748066
Validation loss: 3.3921166383452146

Epoch: 5| Step: 7
Training loss: 3.0687679064941067
Validation loss: 3.394687339686643

Epoch: 5| Step: 8
Training loss: 4.2196529976158095
Validation loss: 3.389964424629303

Epoch: 5| Step: 9
Training loss: 3.9813474634238744
Validation loss: 3.391195470881365

Epoch: 5| Step: 10
Training loss: 3.4803502397665196
Validation loss: 3.38737737906477

Epoch: 34| Step: 0
Training loss: 3.74609107692651
Validation loss: 3.386116875995255

Epoch: 5| Step: 1
Training loss: 2.9997094331534195
Validation loss: 3.3871269602194682

Epoch: 5| Step: 2
Training loss: 3.0961594880002994
Validation loss: 3.385541964626793

Epoch: 5| Step: 3
Training loss: 4.662635469897522
Validation loss: 3.388827523462036

Epoch: 5| Step: 4
Training loss: 3.679303256502256
Validation loss: 3.3839938451674683

Epoch: 5| Step: 5
Training loss: 3.24422440486717
Validation loss: 3.388583361803152

Epoch: 5| Step: 6
Training loss: 4.435632447022423
Validation loss: 3.385455567899202

Epoch: 5| Step: 7
Training loss: 3.568841209515401
Validation loss: 3.38255488118042

Epoch: 5| Step: 8
Training loss: 3.3987537456125634
Validation loss: 3.385893220261444

Epoch: 5| Step: 9
Training loss: 3.1540430492397404
Validation loss: 3.384496338398824

Epoch: 5| Step: 10
Training loss: 3.3218818097479885
Validation loss: 3.381035940615395

Epoch: 35| Step: 0
Training loss: 3.2689685405665605
Validation loss: 3.3813745890397295

Epoch: 5| Step: 1
Training loss: 3.3854847280067437
Validation loss: 3.382711579579098

Epoch: 5| Step: 2
Training loss: 3.217678002662914
Validation loss: 3.380927119124892

Epoch: 5| Step: 3
Training loss: 3.867197980770204
Validation loss: 3.384478237944779

Epoch: 5| Step: 4
Training loss: 3.34508580415666
Validation loss: 3.3773048746390493

Epoch: 5| Step: 5
Training loss: 3.565718685861814
Validation loss: 3.37844128557951

Epoch: 5| Step: 6
Training loss: 4.309656504951854
Validation loss: 3.3780829865474686

Epoch: 5| Step: 7
Training loss: 3.500575427028034
Validation loss: 3.3753459863978024

Epoch: 5| Step: 8
Training loss: 3.559897961600764
Validation loss: 3.3753479292477753

Epoch: 5| Step: 9
Training loss: 3.5842505914837024
Validation loss: 3.377888068578281

Epoch: 5| Step: 10
Training loss: 4.049843189359119
Validation loss: 3.3712931306334637

Epoch: 36| Step: 0
Training loss: 4.253574887375296
Validation loss: 3.3747735260846565

Epoch: 5| Step: 1
Training loss: 3.837333844591981
Validation loss: 3.371101376058817

Epoch: 5| Step: 2
Training loss: 3.9541255604436625
Validation loss: 3.3719876137519122

Epoch: 5| Step: 3
Training loss: 3.570831461445612
Validation loss: 3.370699974614379

Epoch: 5| Step: 4
Training loss: 2.7953270405902386
Validation loss: 3.368644600656038

Epoch: 5| Step: 5
Training loss: 3.4579785789324893
Validation loss: 3.3735737447451792

Epoch: 5| Step: 6
Training loss: 3.509177301397238
Validation loss: 3.371033008601278

Epoch: 5| Step: 7
Training loss: 3.8058750562982007
Validation loss: 3.369421967346778

Epoch: 5| Step: 8
Training loss: 3.447875715091295
Validation loss: 3.368651905017008

Epoch: 5| Step: 9
Training loss: 3.2877689092041718
Validation loss: 3.367776606822148

Epoch: 5| Step: 10
Training loss: 3.501518873617883
Validation loss: 3.36451816575097

Epoch: 37| Step: 0
Training loss: 3.4154406107755504
Validation loss: 3.3677575639274013

Epoch: 5| Step: 1
Training loss: 3.862407898036274
Validation loss: 3.363048140112787

Epoch: 5| Step: 2
Training loss: 3.797965940880189
Validation loss: 3.3646307333337675

Epoch: 5| Step: 3
Training loss: 3.192956629562801
Validation loss: 3.3614694753511682

Epoch: 5| Step: 4
Training loss: 3.926214970405397
Validation loss: 3.3616209305949996

Epoch: 5| Step: 5
Training loss: 3.4045638364380593
Validation loss: 3.361602706968975

Epoch: 5| Step: 6
Training loss: 4.059879807821296
Validation loss: 3.361921410949257

Epoch: 5| Step: 7
Training loss: 3.6413384913106857
Validation loss: 3.358896522950165

Epoch: 5| Step: 8
Training loss: 3.7885081092090167
Validation loss: 3.3607807420521034

Epoch: 5| Step: 9
Training loss: 3.240729093581165
Validation loss: 3.359582465810915

Epoch: 5| Step: 10
Training loss: 3.004284977446049
Validation loss: 3.359062039448933

Epoch: 38| Step: 0
Training loss: 3.4474789129308014
Validation loss: 3.364677896976886

Epoch: 5| Step: 1
Training loss: 3.836592173600259
Validation loss: 3.358555957626873

Epoch: 5| Step: 2
Training loss: 2.8003148923645935
Validation loss: 3.3524016057932786

Epoch: 5| Step: 3
Training loss: 4.299814779151512
Validation loss: 3.3544351761615965

Epoch: 5| Step: 4
Training loss: 3.983130765629715
Validation loss: 3.351710209870038

Epoch: 5| Step: 5
Training loss: 3.6974301873374666
Validation loss: 3.3522700855446903

Epoch: 5| Step: 6
Training loss: 3.7868439461844616
Validation loss: 3.3489928905523656

Epoch: 5| Step: 7
Training loss: 3.6459678116474556
Validation loss: 3.348960261892248

Epoch: 5| Step: 8
Training loss: 3.2674678001772737
Validation loss: 3.3488752776829136

Epoch: 5| Step: 9
Training loss: 2.9117265189936936
Validation loss: 3.3487134789833277

Epoch: 5| Step: 10
Training loss: 3.4982349849965635
Validation loss: 3.350402766005115

Epoch: 39| Step: 0
Training loss: 3.348365664011934
Validation loss: 3.3477413049756803

Epoch: 5| Step: 1
Training loss: 3.152215777781144
Validation loss: 3.3479337527585837

Epoch: 5| Step: 2
Training loss: 4.1271516216905395
Validation loss: 3.346760928071734

Epoch: 5| Step: 3
Training loss: 3.5852127173825874
Validation loss: 3.342662945473691

Epoch: 5| Step: 4
Training loss: 4.007235420426616
Validation loss: 3.339528180685511

Epoch: 5| Step: 5
Training loss: 3.7589008238369876
Validation loss: 3.3444702542690825

Epoch: 5| Step: 6
Training loss: 3.3749929357384114
Validation loss: 3.342316023404375

Epoch: 5| Step: 7
Training loss: 3.916502901806457
Validation loss: 3.3397451988177544

Epoch: 5| Step: 8
Training loss: 3.1737154427112255
Validation loss: 3.340236712998188

Epoch: 5| Step: 9
Training loss: 3.918268620129583
Validation loss: 3.3351689765368806

Epoch: 5| Step: 10
Training loss: 2.5896309007084963
Validation loss: 3.3351007933720327

Epoch: 40| Step: 0
Training loss: 3.521449574971907
Validation loss: 3.332706949898059

Epoch: 5| Step: 1
Training loss: 3.8797757652219182
Validation loss: 3.331847854039462

Epoch: 5| Step: 2
Training loss: 2.946618557043876
Validation loss: 3.330602633833358

Epoch: 5| Step: 3
Training loss: 3.369707549675033
Validation loss: 3.330495800759331

Epoch: 5| Step: 4
Training loss: 3.772857431880238
Validation loss: 3.3263456263708058

Epoch: 5| Step: 5
Training loss: 3.3922656612097977
Validation loss: 3.3281037336062216

Epoch: 5| Step: 6
Training loss: 3.6093472566405347
Validation loss: 3.3239278217646953

Epoch: 5| Step: 7
Training loss: 3.760490113841714
Validation loss: 3.326280969520735

Epoch: 5| Step: 8
Training loss: 3.874325601281608
Validation loss: 3.3261422372914695

Epoch: 5| Step: 9
Training loss: 3.5138301082179466
Validation loss: 3.328056171819952

Epoch: 5| Step: 10
Training loss: 3.470548421302387
Validation loss: 3.3215755801671496

Epoch: 41| Step: 0
Training loss: 3.2295069525478923
Validation loss: 3.322687551138705

Epoch: 5| Step: 1
Training loss: 4.259066167929625
Validation loss: 3.318720045603996

Epoch: 5| Step: 2
Training loss: 3.772010802042149
Validation loss: 3.319576586941245

Epoch: 5| Step: 3
Training loss: 3.9112064502275086
Validation loss: 3.317534867834395

Epoch: 5| Step: 4
Training loss: 3.1558101838616563
Validation loss: 3.320380869480608

Epoch: 5| Step: 5
Training loss: 3.2470265504569804
Validation loss: 3.320060713677777

Epoch: 5| Step: 6
Training loss: 3.4303696633929786
Validation loss: 3.3173361387400533

Epoch: 5| Step: 7
Training loss: 3.064870423009571
Validation loss: 3.31815018006209

Epoch: 5| Step: 8
Training loss: 4.069161689896398
Validation loss: 3.315660813308591

Epoch: 5| Step: 9
Training loss: 3.681151663692486
Validation loss: 3.3177014463813

Epoch: 5| Step: 10
Training loss: 2.9444714870850484
Validation loss: 3.313952988892438

Epoch: 42| Step: 0
Training loss: 2.402752402679382
Validation loss: 3.316060940489624

Epoch: 5| Step: 1
Training loss: 3.3791651984861097
Validation loss: 3.3175628893467004

Epoch: 5| Step: 2
Training loss: 3.374834409819417
Validation loss: 3.313394134448742

Epoch: 5| Step: 3
Training loss: 3.972567306918236
Validation loss: 3.3147361747099517

Epoch: 5| Step: 4
Training loss: 3.2741528004926894
Validation loss: 3.31826810782443

Epoch: 5| Step: 5
Training loss: 3.7245433143394404
Validation loss: 3.314277278940028

Epoch: 5| Step: 6
Training loss: 3.5053645302753185
Validation loss: 3.3104893407293967

Epoch: 5| Step: 7
Training loss: 3.655096540519829
Validation loss: 3.312694372819422

Epoch: 5| Step: 8
Training loss: 4.303488119480154
Validation loss: 3.3130473564827807

Epoch: 5| Step: 9
Training loss: 3.9677092621871384
Validation loss: 3.3131499238163937

Epoch: 5| Step: 10
Training loss: 3.080948053077448
Validation loss: 3.310011422873954

Epoch: 43| Step: 0
Training loss: 3.2502878501770867
Validation loss: 3.310889619017457

Epoch: 5| Step: 1
Training loss: 3.437307317708807
Validation loss: 3.3088379962864125

Epoch: 5| Step: 2
Training loss: 3.07662834534866
Validation loss: 3.312131487020688

Epoch: 5| Step: 3
Training loss: 3.9214793457825854
Validation loss: 3.3093467558976384

Epoch: 5| Step: 4
Training loss: 3.913813356552558
Validation loss: 3.3165365673966893

Epoch: 5| Step: 5
Training loss: 3.2359662403283695
Validation loss: 3.3088795152464274

Epoch: 5| Step: 6
Training loss: 4.157710227582948
Validation loss: 3.311888116814989

Epoch: 5| Step: 7
Training loss: 3.2338647117367043
Validation loss: 3.3059467620060876

Epoch: 5| Step: 8
Training loss: 3.338779070066023
Validation loss: 3.307509408917162

Epoch: 5| Step: 9
Training loss: 3.7797219207445325
Validation loss: 3.315838888438032

Epoch: 5| Step: 10
Training loss: 3.520810791184232
Validation loss: 3.321874468915874

Epoch: 44| Step: 0
Training loss: 3.8810953990963952
Validation loss: 3.3254674337597656

Epoch: 5| Step: 1
Training loss: 3.149632532393474
Validation loss: 3.310449573537577

Epoch: 5| Step: 2
Training loss: 3.9796490335271666
Validation loss: 3.306683771750435

Epoch: 5| Step: 3
Training loss: 3.6885426227288605
Validation loss: 3.3071055525209823

Epoch: 5| Step: 4
Training loss: 3.556814106748597
Validation loss: 3.310412846231353

Epoch: 5| Step: 5
Training loss: 3.085455052774295
Validation loss: 3.311776919471744

Epoch: 5| Step: 6
Training loss: 3.4360007050838792
Validation loss: 3.3147977945779363

Epoch: 5| Step: 7
Training loss: 3.189575716221786
Validation loss: 3.3201607587331896

Epoch: 5| Step: 8
Training loss: 3.894196246248624
Validation loss: 3.3147338436600027

Epoch: 5| Step: 9
Training loss: 2.9878561278486377
Validation loss: 3.3073968753192444

Epoch: 5| Step: 10
Training loss: 4.111785529781426
Validation loss: 3.3078318265804803

Epoch: 45| Step: 0
Training loss: 3.117087608782858
Validation loss: 3.3013550913596665

Epoch: 5| Step: 1
Training loss: 4.056557402402236
Validation loss: 3.3039108710125418

Epoch: 5| Step: 2
Training loss: 3.6514364002867907
Validation loss: 3.3040003466869274

Epoch: 5| Step: 3
Training loss: 3.5730777774590874
Validation loss: 3.303569949079239

Epoch: 5| Step: 4
Training loss: 2.74664683083282
Validation loss: 3.3030030331750906

Epoch: 5| Step: 5
Training loss: 4.275927945977847
Validation loss: 3.303957299905219

Epoch: 5| Step: 6
Training loss: 3.7109083315054314
Validation loss: 3.3018807590734536

Epoch: 5| Step: 7
Training loss: 3.132888602761747
Validation loss: 3.300704219836983

Epoch: 5| Step: 8
Training loss: 3.6173060090855875
Validation loss: 3.299371535094669

Epoch: 5| Step: 9
Training loss: 3.7247405966741103
Validation loss: 3.2996719658456124

Epoch: 5| Step: 10
Training loss: 2.996625273704715
Validation loss: 3.2973215274804533

Epoch: 46| Step: 0
Training loss: 3.84052656278797
Validation loss: 3.2976125492767943

Epoch: 5| Step: 1
Training loss: 3.967731615503808
Validation loss: 3.29763129600754

Epoch: 5| Step: 2
Training loss: 3.7134441061522123
Validation loss: 3.297605135760435

Epoch: 5| Step: 3
Training loss: 3.8692422975740905
Validation loss: 3.2945987347400587

Epoch: 5| Step: 4
Training loss: 2.8040194340031044
Validation loss: 3.2972956330124994

Epoch: 5| Step: 5
Training loss: 3.2718516584873596
Validation loss: 3.2967463082687716

Epoch: 5| Step: 6
Training loss: 3.2064581671465997
Validation loss: 3.295342741759374

Epoch: 5| Step: 7
Training loss: 3.8848083401686306
Validation loss: 3.295503487450016

Epoch: 5| Step: 8
Training loss: 3.1946932838564455
Validation loss: 3.2952547659006486

Epoch: 5| Step: 9
Training loss: 3.2735707840836072
Validation loss: 3.2956032581690757

Epoch: 5| Step: 10
Training loss: 3.7052521209803384
Validation loss: 3.2927223673635795

Epoch: 47| Step: 0
Training loss: 3.8705004748457594
Validation loss: 3.2944139132964994

Epoch: 5| Step: 1
Training loss: 3.562825505962578
Validation loss: 3.2912933622879077

Epoch: 5| Step: 2
Training loss: 3.442100913767858
Validation loss: 3.2919616408690398

Epoch: 5| Step: 3
Training loss: 2.414203331058477
Validation loss: 3.2909802870887215

Epoch: 5| Step: 4
Training loss: 3.3998421407966024
Validation loss: 3.2912934721150435

Epoch: 5| Step: 5
Training loss: 4.471756570608716
Validation loss: 3.294283534764033

Epoch: 5| Step: 6
Training loss: 3.6038944531141603
Validation loss: 3.291058278640385

Epoch: 5| Step: 7
Training loss: 3.308433772051037
Validation loss: 3.290876947772778

Epoch: 5| Step: 8
Training loss: 3.23378833112497
Validation loss: 3.2908047487022625

Epoch: 5| Step: 9
Training loss: 3.9407228873647027
Validation loss: 3.2871272629054267

Epoch: 5| Step: 10
Training loss: 3.2062565080305236
Validation loss: 3.2904679989916903

Epoch: 48| Step: 0
Training loss: 3.533597048029013
Validation loss: 3.291145297955221

Epoch: 5| Step: 1
Training loss: 3.577067656233657
Validation loss: 3.2866886871335876

Epoch: 5| Step: 2
Training loss: 3.926627512954123
Validation loss: 3.2890372131745873

Epoch: 5| Step: 3
Training loss: 4.059831652604003
Validation loss: 3.285103747780991

Epoch: 5| Step: 4
Training loss: 3.101836300542595
Validation loss: 3.285934958591717

Epoch: 5| Step: 5
Training loss: 2.8421388190967383
Validation loss: 3.2866848674364144

Epoch: 5| Step: 6
Training loss: 2.5767389444114213
Validation loss: 3.2878753824600997

Epoch: 5| Step: 7
Training loss: 3.8935598311666553
Validation loss: 3.2862808561588217

Epoch: 5| Step: 8
Training loss: 4.080354161692202
Validation loss: 3.2857599332320464

Epoch: 5| Step: 9
Training loss: 3.363090412250566
Validation loss: 3.286713130126372

Epoch: 5| Step: 10
Training loss: 3.556760749275651
Validation loss: 3.2864267916427123

Epoch: 49| Step: 0
Training loss: 3.971350831410826
Validation loss: 3.286414075708509

Epoch: 5| Step: 1
Training loss: 4.202604467215696
Validation loss: 3.2868235047022516

Epoch: 5| Step: 2
Training loss: 4.054955857644605
Validation loss: 3.2857983607778216

Epoch: 5| Step: 3
Training loss: 3.6168666227648094
Validation loss: 3.2843498217697307

Epoch: 5| Step: 4
Training loss: 4.1125529369901
Validation loss: 3.285548281872523

Epoch: 5| Step: 5
Training loss: 2.3798240056401325
Validation loss: 3.283641779855067

Epoch: 5| Step: 6
Training loss: 3.516268387308061
Validation loss: 3.2850467480784316

Epoch: 5| Step: 7
Training loss: 2.950368735334361
Validation loss: 3.287903859475475

Epoch: 5| Step: 8
Training loss: 3.0576019043054643
Validation loss: 3.286444266708633

Epoch: 5| Step: 9
Training loss: 2.6851912939311533
Validation loss: 3.2849913909310327

Epoch: 5| Step: 10
Training loss: 3.75809634716861
Validation loss: 3.2803262178796646

Epoch: 50| Step: 0
Training loss: 4.366069507291986
Validation loss: 3.283235007128083

Epoch: 5| Step: 1
Training loss: 3.8588360244064317
Validation loss: 3.279867157625799

Epoch: 5| Step: 2
Training loss: 3.6812892270548345
Validation loss: 3.280769177750673

Epoch: 5| Step: 3
Training loss: 3.239031255031253
Validation loss: 3.282828271461734

Epoch: 5| Step: 4
Training loss: 3.124421485758044
Validation loss: 3.2807858390285225

Epoch: 5| Step: 5
Training loss: 4.03909413898996
Validation loss: 3.2806728451185587

Epoch: 5| Step: 6
Training loss: 3.5720906243442134
Validation loss: 3.2792585635839697

Epoch: 5| Step: 7
Training loss: 3.395539549930768
Validation loss: 3.2805491060713363

Epoch: 5| Step: 8
Training loss: 2.6234075166262323
Validation loss: 3.279531602587223

Epoch: 5| Step: 9
Training loss: 3.7297054448553038
Validation loss: 3.2787242710181994

Epoch: 5| Step: 10
Training loss: 2.603695381752768
Validation loss: 3.2768681940032764

Epoch: 51| Step: 0
Training loss: 2.9700608421284613
Validation loss: 3.2805262051030466

Epoch: 5| Step: 1
Training loss: 3.4230424117621108
Validation loss: 3.277780044846411

Epoch: 5| Step: 2
Training loss: 3.797274847130299
Validation loss: 3.279804808018293

Epoch: 5| Step: 3
Training loss: 3.559606749213375
Validation loss: 3.2768487229492336

Epoch: 5| Step: 4
Training loss: 3.5636450282612566
Validation loss: 3.2786248772736686

Epoch: 5| Step: 5
Training loss: 3.5486177036716033
Validation loss: 3.2788723176670604

Epoch: 5| Step: 6
Training loss: 3.476116023165272
Validation loss: 3.276043861957463

Epoch: 5| Step: 7
Training loss: 3.9445476130453834
Validation loss: 3.2767207891131074

Epoch: 5| Step: 8
Training loss: 3.3563917531459193
Validation loss: 3.2755009709906364

Epoch: 5| Step: 9
Training loss: 3.3342333691163555
Validation loss: 3.2753989372387893

Epoch: 5| Step: 10
Training loss: 3.723079693339118
Validation loss: 3.275602038908306

Epoch: 52| Step: 0
Training loss: 3.3961228479332717
Validation loss: 3.27691527204291

Epoch: 5| Step: 1
Training loss: 3.3403718229727732
Validation loss: 3.27537933221844

Epoch: 5| Step: 2
Training loss: 3.431558641682189
Validation loss: 3.274091629330509

Epoch: 5| Step: 3
Training loss: 4.055138594096875
Validation loss: 3.274976005362971

Epoch: 5| Step: 4
Training loss: 3.527930936383893
Validation loss: 3.276011349539895

Epoch: 5| Step: 5
Training loss: 3.0636997597604996
Validation loss: 3.272611473439366

Epoch: 5| Step: 6
Training loss: 4.104740677145309
Validation loss: 3.273908544363212

Epoch: 5| Step: 7
Training loss: 3.63015932390287
Validation loss: 3.2716584958013883

Epoch: 5| Step: 8
Training loss: 2.7258151103939983
Validation loss: 3.274985945301259

Epoch: 5| Step: 9
Training loss: 3.858624960724275
Validation loss: 3.2721802118801624

Epoch: 5| Step: 10
Training loss: 3.334422855337673
Validation loss: 3.271064219265852

Epoch: 53| Step: 0
Training loss: 3.19258728959516
Validation loss: 3.2720582224452617

Epoch: 5| Step: 1
Training loss: 4.024033348627859
Validation loss: 3.270523513302938

Epoch: 5| Step: 2
Training loss: 3.6792897780929406
Validation loss: 3.272440927877103

Epoch: 5| Step: 3
Training loss: 4.386682443986558
Validation loss: 3.2702773649539343

Epoch: 5| Step: 4
Training loss: 2.3155717810153646
Validation loss: 3.2706016603219945

Epoch: 5| Step: 5
Training loss: 3.599932452733746
Validation loss: 3.275078894554063

Epoch: 5| Step: 6
Training loss: 4.035265201896127
Validation loss: 3.2713394703529803

Epoch: 5| Step: 7
Training loss: 3.5957032576130477
Validation loss: 3.268309752578719

Epoch: 5| Step: 8
Training loss: 3.3077192535735898
Validation loss: 3.2696825747314895

Epoch: 5| Step: 9
Training loss: 3.1639350017714603
Validation loss: 3.27105664839731

Epoch: 5| Step: 10
Training loss: 2.7993618442288444
Validation loss: 3.2699743464535094

Epoch: 54| Step: 0
Training loss: 3.3763916537281684
Validation loss: 3.272529893066741

Epoch: 5| Step: 1
Training loss: 3.385021167052224
Validation loss: 3.2682215432117077

Epoch: 5| Step: 2
Training loss: 3.47901332920873
Validation loss: 3.268492978606034

Epoch: 5| Step: 3
Training loss: 3.175822840719741
Validation loss: 3.2689747611153117

Epoch: 5| Step: 4
Training loss: 3.6585485292255235
Validation loss: 3.2689141926061303

Epoch: 5| Step: 5
Training loss: 3.5053626258451316
Validation loss: 3.2702521006352474

Epoch: 5| Step: 6
Training loss: 3.841780863710598
Validation loss: 3.26816380665083

Epoch: 5| Step: 7
Training loss: 3.8798293506809385
Validation loss: 3.2674689755011688

Epoch: 5| Step: 8
Training loss: 2.921650434217897
Validation loss: 3.26850079228581

Epoch: 5| Step: 9
Training loss: 2.870124829863932
Validation loss: 3.266715548523986

Epoch: 5| Step: 10
Training loss: 4.453177254353503
Validation loss: 3.2680182793843384

Epoch: 55| Step: 0
Training loss: 3.4073150089731263
Validation loss: 3.268751892297603

Epoch: 5| Step: 1
Training loss: 2.9294057481705313
Validation loss: 3.265666914494897

Epoch: 5| Step: 2
Training loss: 3.3771708535759877
Validation loss: 3.2692698079409586

Epoch: 5| Step: 3
Training loss: 4.028691152438146
Validation loss: 3.2670150948551564

Epoch: 5| Step: 4
Training loss: 3.247197777103435
Validation loss: 3.264488943064517

Epoch: 5| Step: 5
Training loss: 3.903991168191957
Validation loss: 3.2665213875508847

Epoch: 5| Step: 6
Training loss: 3.6009142244648267
Validation loss: 3.266808747216787

Epoch: 5| Step: 7
Training loss: 2.5910849610403726
Validation loss: 3.2648818453063115

Epoch: 5| Step: 8
Training loss: 3.72519542002274
Validation loss: 3.2639711618508738

Epoch: 5| Step: 9
Training loss: 3.8081051870131484
Validation loss: 3.266194581954365

Epoch: 5| Step: 10
Training loss: 3.7858776432584453
Validation loss: 3.2633278263198124

Epoch: 56| Step: 0
Training loss: 2.8525893779262406
Validation loss: 3.2656166770135413

Epoch: 5| Step: 1
Training loss: 3.56064838676948
Validation loss: 3.2650278971075943

Epoch: 5| Step: 2
Training loss: 3.51464789481449
Validation loss: 3.26655579949727

Epoch: 5| Step: 3
Training loss: 3.737284400870927
Validation loss: 3.26721497174672

Epoch: 5| Step: 4
Training loss: 3.6928688663656017
Validation loss: 3.2669489185059657

Epoch: 5| Step: 5
Training loss: 3.4023518786678157
Validation loss: 3.2648783966315507

Epoch: 5| Step: 6
Training loss: 3.2248963864263973
Validation loss: 3.261980479753394

Epoch: 5| Step: 7
Training loss: 3.418816022217986
Validation loss: 3.2613023591996284

Epoch: 5| Step: 8
Training loss: 3.3582953558983952
Validation loss: 3.2626231710483236

Epoch: 5| Step: 9
Training loss: 3.601244467638686
Validation loss: 3.2633839563067055

Epoch: 5| Step: 10
Training loss: 4.235114114027849
Validation loss: 3.2639943745455238

Epoch: 57| Step: 0
Training loss: 3.4802151468791256
Validation loss: 3.2628447071476168

Epoch: 5| Step: 1
Training loss: 3.2856968855545206
Validation loss: 3.2627241570051444

Epoch: 5| Step: 2
Training loss: 3.5655336012229917
Validation loss: 3.263346737009101

Epoch: 5| Step: 3
Training loss: 3.4465025492196206
Validation loss: 3.2631588649114587

Epoch: 5| Step: 4
Training loss: 3.6541974427780533
Validation loss: 3.264236513777866

Epoch: 5| Step: 5
Training loss: 3.7079597170636442
Validation loss: 3.262580904713606

Epoch: 5| Step: 6
Training loss: 4.018378237886489
Validation loss: 3.26308711710482

Epoch: 5| Step: 7
Training loss: 2.949591566357145
Validation loss: 3.2610245935027056

Epoch: 5| Step: 8
Training loss: 3.398802007660975
Validation loss: 3.2616085382402566

Epoch: 5| Step: 9
Training loss: 3.302224831101608
Validation loss: 3.262964361877178

Epoch: 5| Step: 10
Training loss: 3.753963029414181
Validation loss: 3.2615271699871777

Epoch: 58| Step: 0
Training loss: 3.2123745489302373
Validation loss: 3.2592217121305573

Epoch: 5| Step: 1
Training loss: 4.175216422496278
Validation loss: 3.258241480552951

Epoch: 5| Step: 2
Training loss: 3.677162681062072
Validation loss: 3.26011897642731

Epoch: 5| Step: 3
Training loss: 3.825866531253517
Validation loss: 3.2572598347958923

Epoch: 5| Step: 4
Training loss: 2.95193408991729
Validation loss: 3.2592387926839668

Epoch: 5| Step: 5
Training loss: 2.6915003257664813
Validation loss: 3.257156667647432

Epoch: 5| Step: 6
Training loss: 3.6369419049921716
Validation loss: 3.2575225461033956

Epoch: 5| Step: 7
Training loss: 3.094435644755549
Validation loss: 3.2566354448469705

Epoch: 5| Step: 8
Training loss: 4.006072679901151
Validation loss: 3.2579404854434175

Epoch: 5| Step: 9
Training loss: 3.456063379695554
Validation loss: 3.256012684666887

Epoch: 5| Step: 10
Training loss: 3.5610872110830094
Validation loss: 3.2592145432269013

Epoch: 59| Step: 0
Training loss: 3.6599457149961596
Validation loss: 3.2582362088730417

Epoch: 5| Step: 1
Training loss: 3.289437533129759
Validation loss: 3.2550273471192144

Epoch: 5| Step: 2
Training loss: 4.059923969177015
Validation loss: 3.25566529418217

Epoch: 5| Step: 3
Training loss: 3.1363978239565893
Validation loss: 3.2602767298376554

Epoch: 5| Step: 4
Training loss: 3.4448158788546284
Validation loss: 3.2577933399943992

Epoch: 5| Step: 5
Training loss: 3.567447907161715
Validation loss: 3.2561635464263774

Epoch: 5| Step: 6
Training loss: 3.793286924050353
Validation loss: 3.256074360815912

Epoch: 5| Step: 7
Training loss: 2.959812886793539
Validation loss: 3.2550903241168196

Epoch: 5| Step: 8
Training loss: 3.403765971314066
Validation loss: 3.2543197743504266

Epoch: 5| Step: 9
Training loss: 3.261486004046291
Validation loss: 3.257110780600197

Epoch: 5| Step: 10
Training loss: 3.866532580473339
Validation loss: 3.2541152262021638

Epoch: 60| Step: 0
Training loss: 3.306350325737045
Validation loss: 3.254271772297336

Epoch: 5| Step: 1
Training loss: 3.323573622541057
Validation loss: 3.2532609887411703

Epoch: 5| Step: 2
Training loss: 4.50780636474615
Validation loss: 3.252349392435251

Epoch: 5| Step: 3
Training loss: 3.130187802027916
Validation loss: 3.2517104778959878

Epoch: 5| Step: 4
Training loss: 3.477448699814113
Validation loss: 3.2537282789112005

Epoch: 5| Step: 5
Training loss: 3.7128698196911825
Validation loss: 3.253203952010089

Epoch: 5| Step: 6
Training loss: 2.887209962752719
Validation loss: 3.2532461943859388

Epoch: 5| Step: 7
Training loss: 3.3922620064922637
Validation loss: 3.2534676078044305

Epoch: 5| Step: 8
Training loss: 3.6357655325935974
Validation loss: 3.2529382935632714

Epoch: 5| Step: 9
Training loss: 3.467783887885549
Validation loss: 3.252343203147756

Epoch: 5| Step: 10
Training loss: 3.438169102138861
Validation loss: 3.250272018496162

Epoch: 61| Step: 0
Training loss: 3.879547772942922
Validation loss: 3.2515516954792925

Epoch: 5| Step: 1
Training loss: 3.207528711132491
Validation loss: 3.248189605705774

Epoch: 5| Step: 2
Training loss: 3.4328977814726076
Validation loss: 3.2491875540931954

Epoch: 5| Step: 3
Training loss: 3.3781966153298675
Validation loss: 3.250124992825692

Epoch: 5| Step: 4
Training loss: 2.996540299899352
Validation loss: 3.2494838342574806

Epoch: 5| Step: 5
Training loss: 3.450054754292631
Validation loss: 3.2508713364297637

Epoch: 5| Step: 6
Training loss: 3.551741299238145
Validation loss: 3.2517502412726498

Epoch: 5| Step: 7
Training loss: 3.75354408636864
Validation loss: 3.2495005265606327

Epoch: 5| Step: 8
Training loss: 3.9496893748542954
Validation loss: 3.2544679181463807

Epoch: 5| Step: 9
Training loss: 3.6694685172261083
Validation loss: 3.2480269122960417

Epoch: 5| Step: 10
Training loss: 3.0023122459742027
Validation loss: 3.247691875424791

Epoch: 62| Step: 0
Training loss: 3.812500750432175
Validation loss: 3.2465484408493013

Epoch: 5| Step: 1
Training loss: 3.3571953378071178
Validation loss: 3.2469691452388623

Epoch: 5| Step: 2
Training loss: 3.136207624432701
Validation loss: 3.2466449110942066

Epoch: 5| Step: 3
Training loss: 3.7926847467454765
Validation loss: 3.248826510002046

Epoch: 5| Step: 4
Training loss: 3.8234126767941636
Validation loss: 3.2482891154605564

Epoch: 5| Step: 5
Training loss: 3.302690628637319
Validation loss: 3.2468199052401645

Epoch: 5| Step: 6
Training loss: 3.108592639432998
Validation loss: 3.2480252926691

Epoch: 5| Step: 7
Training loss: 3.5249002807797156
Validation loss: 3.2453377652162745

Epoch: 5| Step: 8
Training loss: 3.4967148213181436
Validation loss: 3.2488265636606704

Epoch: 5| Step: 9
Training loss: 3.1739586812089997
Validation loss: 3.2459369374401197

Epoch: 5| Step: 10
Training loss: 3.8673892190129884
Validation loss: 3.2488393343880966

Epoch: 63| Step: 0
Training loss: 4.04279371979217
Validation loss: 3.246697141385513

Epoch: 5| Step: 1
Training loss: 3.070606324402868
Validation loss: 3.247386904171003

Epoch: 5| Step: 2
Training loss: 3.8047679602792313
Validation loss: 3.245165271247329

Epoch: 5| Step: 3
Training loss: 3.68535047047224
Validation loss: 3.249295727106251

Epoch: 5| Step: 4
Training loss: 3.8130222650733776
Validation loss: 3.2470760760216453

Epoch: 5| Step: 5
Training loss: 3.7403742273543616
Validation loss: 3.246585592142962

Epoch: 5| Step: 6
Training loss: 4.220616358721764
Validation loss: 3.2450363821951806

Epoch: 5| Step: 7
Training loss: 2.407802229753557
Validation loss: 3.24592325965681

Epoch: 5| Step: 8
Training loss: 3.4702120612259315
Validation loss: 3.2470147153079405

Epoch: 5| Step: 9
Training loss: 2.849123060263353
Validation loss: 3.246795843334517

Epoch: 5| Step: 10
Training loss: 2.7518671806132518
Validation loss: 3.2448275860771036

Epoch: 64| Step: 0
Training loss: 3.9981678104419407
Validation loss: 3.2441153894667933

Epoch: 5| Step: 1
Training loss: 2.986031756467899
Validation loss: 3.247365513238079

Epoch: 5| Step: 2
Training loss: 3.178456210991882
Validation loss: 3.2463488740827318

Epoch: 5| Step: 3
Training loss: 3.246744432660314
Validation loss: 3.2516891012140396

Epoch: 5| Step: 4
Training loss: 3.7810893379317156
Validation loss: 3.242398322602592

Epoch: 5| Step: 5
Training loss: 3.4790108621092743
Validation loss: 3.2406385054106996

Epoch: 5| Step: 6
Training loss: 3.3370683883870242
Validation loss: 3.2416236961480376

Epoch: 5| Step: 7
Training loss: 3.438969662083537
Validation loss: 3.2419286275407595

Epoch: 5| Step: 8
Training loss: 4.1817605840161685
Validation loss: 3.2430014339675552

Epoch: 5| Step: 9
Training loss: 2.948490118498252
Validation loss: 3.2427490183017182

Epoch: 5| Step: 10
Training loss: 3.643994258067928
Validation loss: 3.2411384728778105

Epoch: 65| Step: 0
Training loss: 4.014228785876726
Validation loss: 3.2404896423586558

Epoch: 5| Step: 1
Training loss: 3.6638247284675307
Validation loss: 3.2442714548246268

Epoch: 5| Step: 2
Training loss: 3.5220772767218897
Validation loss: 3.243467777292993

Epoch: 5| Step: 3
Training loss: 3.3536022177321256
Validation loss: 3.247128155686789

Epoch: 5| Step: 4
Training loss: 3.6882507077313837
Validation loss: 3.245974994514509

Epoch: 5| Step: 5
Training loss: 2.6135956214473444
Validation loss: 3.2451579701728304

Epoch: 5| Step: 6
Training loss: 3.543375986535723
Validation loss: 3.242811224204019

Epoch: 5| Step: 7
Training loss: 3.252680040283398
Validation loss: 3.2412632411184252

Epoch: 5| Step: 8
Training loss: 3.375284536164802
Validation loss: 3.24020032200877

Epoch: 5| Step: 9
Training loss: 3.519475430502137
Validation loss: 3.2382816141668327

Epoch: 5| Step: 10
Training loss: 3.7305597583794103
Validation loss: 3.2405255799195207

Epoch: 66| Step: 0
Training loss: 3.7150735072055343
Validation loss: 3.2375205886888696

Epoch: 5| Step: 1
Training loss: 3.47847532305752
Validation loss: 3.236962097221697

Epoch: 5| Step: 2
Training loss: 3.8790274579029522
Validation loss: 3.241768540396179

Epoch: 5| Step: 3
Training loss: 3.651858439305935
Validation loss: 3.2380735383987465

Epoch: 5| Step: 4
Training loss: 3.183750265755734
Validation loss: 3.2385237142969645

Epoch: 5| Step: 5
Training loss: 3.6361029704907586
Validation loss: 3.2426377198457907

Epoch: 5| Step: 6
Training loss: 3.5124683365124363
Validation loss: 3.2442321442413014

Epoch: 5| Step: 7
Training loss: 3.4740938830298567
Validation loss: 3.2492855318457865

Epoch: 5| Step: 8
Training loss: 3.210994228038275
Validation loss: 3.240673218307064

Epoch: 5| Step: 9
Training loss: 3.525880224832273
Validation loss: 3.238150524127773

Epoch: 5| Step: 10
Training loss: 2.922080456043152
Validation loss: 3.2384816764834707

Epoch: 67| Step: 0
Training loss: 3.268146034591779
Validation loss: 3.236830687623528

Epoch: 5| Step: 1
Training loss: 3.4314595643131383
Validation loss: 3.2376823206398626

Epoch: 5| Step: 2
Training loss: 3.093946046108508
Validation loss: 3.234535930209195

Epoch: 5| Step: 3
Training loss: 3.330601160583679
Validation loss: 3.237261509335545

Epoch: 5| Step: 4
Training loss: 3.306673359582137
Validation loss: 3.232542963563357

Epoch: 5| Step: 5
Training loss: 3.8291110267512467
Validation loss: 3.2319452647999425

Epoch: 5| Step: 6
Training loss: 3.402263723630106
Validation loss: 3.234706350249166

Epoch: 5| Step: 7
Training loss: 3.8239683667394817
Validation loss: 3.23562288557277

Epoch: 5| Step: 8
Training loss: 3.2322504557077334
Validation loss: 3.2344067333064292

Epoch: 5| Step: 9
Training loss: 3.859302226627585
Validation loss: 3.236073714515278

Epoch: 5| Step: 10
Training loss: 3.6855208694680686
Validation loss: 3.2366956165667746

Epoch: 68| Step: 0
Training loss: 3.7583253633424505
Validation loss: 3.2360257483953356

Epoch: 5| Step: 1
Training loss: 3.850457642343434
Validation loss: 3.239178323621679

Epoch: 5| Step: 2
Training loss: 2.954060078479384
Validation loss: 3.238026015977507

Epoch: 5| Step: 3
Training loss: 3.2150568839301643
Validation loss: 3.2393102647841254

Epoch: 5| Step: 4
Training loss: 2.8443277631444546
Validation loss: 3.244717767661683

Epoch: 5| Step: 5
Training loss: 3.4121137072006698
Validation loss: 3.23865864895164

Epoch: 5| Step: 6
Training loss: 3.850669772855751
Validation loss: 3.2389353811845303

Epoch: 5| Step: 7
Training loss: 3.4768304957274676
Validation loss: 3.234599461513958

Epoch: 5| Step: 8
Training loss: 3.729878036305001
Validation loss: 3.2308035034765226

Epoch: 5| Step: 9
Training loss: 3.8977113708770257
Validation loss: 3.2308461966360573

Epoch: 5| Step: 10
Training loss: 3.0397582838935584
Validation loss: 3.2297175201870783

Epoch: 69| Step: 0
Training loss: 3.1418091928007477
Validation loss: 3.230160527239421

Epoch: 5| Step: 1
Training loss: 3.480560130280126
Validation loss: 3.2301921940123575

Epoch: 5| Step: 2
Training loss: 3.1549846265512
Validation loss: 3.2315673515510555

Epoch: 5| Step: 3
Training loss: 3.361865021264776
Validation loss: 3.2305754317968907

Epoch: 5| Step: 4
Training loss: 2.8307349875541483
Validation loss: 3.230323078459958

Epoch: 5| Step: 5
Training loss: 4.284041559667802
Validation loss: 3.2268499383267013

Epoch: 5| Step: 6
Training loss: 3.414288476234865
Validation loss: 3.2285106176429785

Epoch: 5| Step: 7
Training loss: 4.207896194163941
Validation loss: 3.228892024835537

Epoch: 5| Step: 8
Training loss: 2.9650370619003033
Validation loss: 3.229800986800602

Epoch: 5| Step: 9
Training loss: 3.510330621738296
Validation loss: 3.228916883913726

Epoch: 5| Step: 10
Training loss: 3.647625132264798
Validation loss: 3.2298903438675852

Epoch: 70| Step: 0
Training loss: 3.333907141570275
Validation loss: 3.2316242172299012

Epoch: 5| Step: 1
Training loss: 4.138953911756276
Validation loss: 3.2326835896902297

Epoch: 5| Step: 2
Training loss: 3.3672432950169955
Validation loss: 3.2288551098231584

Epoch: 5| Step: 3
Training loss: 3.8174040474914626
Validation loss: 3.227949174266482

Epoch: 5| Step: 4
Training loss: 3.9351144254884143
Validation loss: 3.232152313729584

Epoch: 5| Step: 5
Training loss: 2.9205890620490162
Validation loss: 3.2331742264238517

Epoch: 5| Step: 6
Training loss: 3.5712110861906985
Validation loss: 3.2354030828939124

Epoch: 5| Step: 7
Training loss: 3.380547379632106
Validation loss: 3.2376286083159984

Epoch: 5| Step: 8
Training loss: 3.158312284320619
Validation loss: 3.23842973800498

Epoch: 5| Step: 9
Training loss: 3.220098860982301
Validation loss: 3.2375512728501423

Epoch: 5| Step: 10
Training loss: 3.1763946954225317
Validation loss: 3.2371346909353766

Epoch: 71| Step: 0
Training loss: 3.806132392757605
Validation loss: 3.232793304623163

Epoch: 5| Step: 1
Training loss: 3.0251734281905036
Validation loss: 3.233649497204247

Epoch: 5| Step: 2
Training loss: 3.6771740924703917
Validation loss: 3.2330935468478836

Epoch: 5| Step: 3
Training loss: 3.3709394258292247
Validation loss: 3.2296794120402774

Epoch: 5| Step: 4
Training loss: 3.528372883767981
Validation loss: 3.228445065493598

Epoch: 5| Step: 5
Training loss: 3.62647966900876
Validation loss: 3.2291137807420687

Epoch: 5| Step: 6
Training loss: 3.331450327849159
Validation loss: 3.2291544082731782

Epoch: 5| Step: 7
Training loss: 3.9765093786742263
Validation loss: 3.2281492225478265

Epoch: 5| Step: 8
Training loss: 3.3014471522273676
Validation loss: 3.2264389717212394

Epoch: 5| Step: 9
Training loss: 3.3792124703184414
Validation loss: 3.22598545808339

Epoch: 5| Step: 10
Training loss: 3.0301914529777187
Validation loss: 3.2290998872063548

Epoch: 72| Step: 0
Training loss: 3.4522078318794405
Validation loss: 3.224231723023706

Epoch: 5| Step: 1
Training loss: 3.6051876995940444
Validation loss: 3.22567724404958

Epoch: 5| Step: 2
Training loss: 4.297366138479408
Validation loss: 3.2270074988546877

Epoch: 5| Step: 3
Training loss: 3.4021394057285104
Validation loss: 3.2257466751630837

Epoch: 5| Step: 4
Training loss: 3.5148329457161265
Validation loss: 3.2252035336388207

Epoch: 5| Step: 5
Training loss: 2.499065987633555
Validation loss: 3.223137052634379

Epoch: 5| Step: 6
Training loss: 4.34090324811801
Validation loss: 3.2263364209372543

Epoch: 5| Step: 7
Training loss: 3.5749877769421317
Validation loss: 3.2219253115822957

Epoch: 5| Step: 8
Training loss: 3.0082221210525404
Validation loss: 3.226000650825855

Epoch: 5| Step: 9
Training loss: 3.0019669442488524
Validation loss: 3.2248112061015055

Epoch: 5| Step: 10
Training loss: 3.0025164857994633
Validation loss: 3.2262956228369144

Epoch: 73| Step: 0
Training loss: 3.2436418695379774
Validation loss: 3.2273956671571353

Epoch: 5| Step: 1
Training loss: 3.765621327758518
Validation loss: 3.2270585773024

Epoch: 5| Step: 2
Training loss: 3.4717116900335805
Validation loss: 3.228593891537754

Epoch: 5| Step: 3
Training loss: 3.8678574723471395
Validation loss: 3.2241319883975024

Epoch: 5| Step: 4
Training loss: 3.5777936890316098
Validation loss: 3.2255021376786694

Epoch: 5| Step: 5
Training loss: 3.361841618063142
Validation loss: 3.220596834985194

Epoch: 5| Step: 6
Training loss: 3.630308539358932
Validation loss: 3.220213338706396

Epoch: 5| Step: 7
Training loss: 3.4402535247529644
Validation loss: 3.2206315075826746

Epoch: 5| Step: 8
Training loss: 2.672557542857638
Validation loss: 3.2233898373237246

Epoch: 5| Step: 9
Training loss: 3.5272304647679196
Validation loss: 3.2237584045804715

Epoch: 5| Step: 10
Training loss: 3.5041641259533853
Validation loss: 3.221313109955165

Epoch: 74| Step: 0
Training loss: 3.2243630068475166
Validation loss: 3.2201605307750305

Epoch: 5| Step: 1
Training loss: 2.8795345868118183
Validation loss: 3.223287928409557

Epoch: 5| Step: 2
Training loss: 3.8507945937554107
Validation loss: 3.2238410553181507

Epoch: 5| Step: 3
Training loss: 3.6538101271733554
Validation loss: 3.2236576246559303

Epoch: 5| Step: 4
Training loss: 4.085884050125424
Validation loss: 3.223302087986672

Epoch: 5| Step: 5
Training loss: 3.853628598706681
Validation loss: 3.2234508047261308

Epoch: 5| Step: 6
Training loss: 3.0260137577487916
Validation loss: 3.224423049470057

Epoch: 5| Step: 7
Training loss: 3.3724731593552066
Validation loss: 3.2214302590322386

Epoch: 5| Step: 8
Training loss: 3.2725182018546093
Validation loss: 3.2204276839054793

Epoch: 5| Step: 9
Training loss: 3.353585581863509
Validation loss: 3.2184109945847013

Epoch: 5| Step: 10
Training loss: 3.3700236614539913
Validation loss: 3.219027565301123

Epoch: 75| Step: 0
Training loss: 2.9032687411329574
Validation loss: 3.2204453674439137

Epoch: 5| Step: 1
Training loss: 3.9390414414832153
Validation loss: 3.219560528484817

Epoch: 5| Step: 2
Training loss: 3.6077258813768336
Validation loss: 3.220780779844894

Epoch: 5| Step: 3
Training loss: 3.743408513614923
Validation loss: 3.221553239293365

Epoch: 5| Step: 4
Training loss: 2.819188705104107
Validation loss: 3.2245221533684973

Epoch: 5| Step: 5
Training loss: 3.553029371600255
Validation loss: 3.223378836377649

Epoch: 5| Step: 6
Training loss: 3.802573742875649
Validation loss: 3.220395757127089

Epoch: 5| Step: 7
Training loss: 3.8949164197227617
Validation loss: 3.2209317516664897

Epoch: 5| Step: 8
Training loss: 3.5367680200069316
Validation loss: 3.218936532853258

Epoch: 5| Step: 9
Training loss: 2.8869793971680595
Validation loss: 3.219482888003039

Epoch: 5| Step: 10
Training loss: 3.1167377348224243
Validation loss: 3.219659055879574

Epoch: 76| Step: 0
Training loss: 2.8573963427494804
Validation loss: 3.220152989898636

Epoch: 5| Step: 1
Training loss: 4.219207060744417
Validation loss: 3.2201465221818837

Epoch: 5| Step: 2
Training loss: 2.944268727207606
Validation loss: 3.219158227561877

Epoch: 5| Step: 3
Training loss: 3.6196421786756696
Validation loss: 3.2232245249050973

Epoch: 5| Step: 4
Training loss: 3.1131473833162837
Validation loss: 3.2228103659512675

Epoch: 5| Step: 5
Training loss: 3.7360788711864843
Validation loss: 3.224900424784445

Epoch: 5| Step: 6
Training loss: 3.222180066618541
Validation loss: 3.2213461855730317

Epoch: 5| Step: 7
Training loss: 4.258299857429165
Validation loss: 3.217953669556692

Epoch: 5| Step: 8
Training loss: 3.8534356876053795
Validation loss: 3.21843321360681

Epoch: 5| Step: 9
Training loss: 2.3723278070796128
Validation loss: 3.216419914171328

Epoch: 5| Step: 10
Training loss: 3.3762495765276195
Validation loss: 3.2171971874163625

Epoch: 77| Step: 0
Training loss: 3.5240131593040687
Validation loss: 3.216111363736096

Epoch: 5| Step: 1
Training loss: 2.9205371425352107
Validation loss: 3.21524621003359

Epoch: 5| Step: 2
Training loss: 3.719908333541128
Validation loss: 3.2151459993270706

Epoch: 5| Step: 3
Training loss: 3.270973024402248
Validation loss: 3.2160555852741095

Epoch: 5| Step: 4
Training loss: 4.329982537989833
Validation loss: 3.2149604434581613

Epoch: 5| Step: 5
Training loss: 2.9092778665981918
Validation loss: 3.21676350315559

Epoch: 5| Step: 6
Training loss: 3.8648888123620564
Validation loss: 3.217301957839181

Epoch: 5| Step: 7
Training loss: 3.3278140786946615
Validation loss: 3.215734827985185

Epoch: 5| Step: 8
Training loss: 2.8440167647778383
Validation loss: 3.2151811859962223

Epoch: 5| Step: 9
Training loss: 3.4005152872844397
Validation loss: 3.214513858225727

Epoch: 5| Step: 10
Training loss: 3.673795417019473
Validation loss: 3.2136536555739754

Epoch: 78| Step: 0
Training loss: 3.7108627151181572
Validation loss: 3.2167050932265258

Epoch: 5| Step: 1
Training loss: 3.758702670358505
Validation loss: 3.2161485414002464

Epoch: 5| Step: 2
Training loss: 3.0957464076725785
Validation loss: 3.2154149268877195

Epoch: 5| Step: 3
Training loss: 2.822011926989423
Validation loss: 3.212979743829402

Epoch: 5| Step: 4
Training loss: 2.82397088404875
Validation loss: 3.2135183921491395

Epoch: 5| Step: 5
Training loss: 3.275074406135326
Validation loss: 3.2135844849139303

Epoch: 5| Step: 6
Training loss: 3.8327889816116247
Validation loss: 3.2125539906081295

Epoch: 5| Step: 7
Training loss: 3.3626083072959743
Validation loss: 3.21368338857634

Epoch: 5| Step: 8
Training loss: 3.7697970123688798
Validation loss: 3.2126563397620784

Epoch: 5| Step: 9
Training loss: 3.345708255797292
Validation loss: 3.2106248039504846

Epoch: 5| Step: 10
Training loss: 4.078803112024428
Validation loss: 3.2109011642116307

Epoch: 79| Step: 0
Training loss: 3.2229746528312893
Validation loss: 3.2093143207255057

Epoch: 5| Step: 1
Training loss: 3.5728342178366645
Validation loss: 3.2130826698495394

Epoch: 5| Step: 2
Training loss: 3.4124891902766348
Validation loss: 3.219351956224837

Epoch: 5| Step: 3
Training loss: 4.401873423814254
Validation loss: 3.208792206308526

Epoch: 5| Step: 4
Training loss: 3.017604988250169
Validation loss: 3.2130133289143554

Epoch: 5| Step: 5
Training loss: 3.0440283364118703
Validation loss: 3.214540844610455

Epoch: 5| Step: 6
Training loss: 3.1577584467305204
Validation loss: 3.2131108698450928

Epoch: 5| Step: 7
Training loss: 3.2393714532937636
Validation loss: 3.2136524174906413

Epoch: 5| Step: 8
Training loss: 3.5152087155883005
Validation loss: 3.2101824119382925

Epoch: 5| Step: 9
Training loss: 3.6072246536843857
Validation loss: 3.210180421835045

Epoch: 5| Step: 10
Training loss: 3.6360516945381844
Validation loss: 3.210219409106592

Epoch: 80| Step: 0
Training loss: 3.693080623280687
Validation loss: 3.210297053219233

Epoch: 5| Step: 1
Training loss: 3.7877089137508464
Validation loss: 3.213368425904821

Epoch: 5| Step: 2
Training loss: 3.399039379622371
Validation loss: 3.210091549530023

Epoch: 5| Step: 3
Training loss: 3.1403691581407838
Validation loss: 3.2064163357719213

Epoch: 5| Step: 4
Training loss: 2.910595342293743
Validation loss: 3.208268180242088

Epoch: 5| Step: 5
Training loss: 3.634820329929883
Validation loss: 3.207667066774979

Epoch: 5| Step: 6
Training loss: 4.053382619466122
Validation loss: 3.2074311954678794

Epoch: 5| Step: 7
Training loss: 3.0092012444362375
Validation loss: 3.2050734553650178

Epoch: 5| Step: 8
Training loss: 3.4152112202370453
Validation loss: 3.2064412011999477

Epoch: 5| Step: 9
Training loss: 3.615498026709479
Validation loss: 3.2046461045705557

Epoch: 5| Step: 10
Training loss: 3.1030886184080932
Validation loss: 3.2062142294556053

Epoch: 81| Step: 0
Training loss: 3.9391192785072677
Validation loss: 3.2076190235345963

Epoch: 5| Step: 1
Training loss: 2.7065896999365253
Validation loss: 3.2067130676900613

Epoch: 5| Step: 2
Training loss: 3.1744084505503216
Validation loss: 3.2072285184342175

Epoch: 5| Step: 3
Training loss: 3.598099837567195
Validation loss: 3.204556229183311

Epoch: 5| Step: 4
Training loss: 2.6160844442638016
Validation loss: 3.2063843222488075

Epoch: 5| Step: 5
Training loss: 3.8521757740230034
Validation loss: 3.204285285388715

Epoch: 5| Step: 6
Training loss: 3.409094086847847
Validation loss: 3.206428480678704

Epoch: 5| Step: 7
Training loss: 3.235612715369357
Validation loss: 3.20846429234467

Epoch: 5| Step: 8
Training loss: 3.960062204893501
Validation loss: 3.208998980359816

Epoch: 5| Step: 9
Training loss: 4.146522094152511
Validation loss: 3.209496976803831

Epoch: 5| Step: 10
Training loss: 2.824544674123492
Validation loss: 3.207009908048491

Epoch: 82| Step: 0
Training loss: 3.2019338486442455
Validation loss: 3.206103939207731

Epoch: 5| Step: 1
Training loss: 2.6650042617219842
Validation loss: 3.2121066717430375

Epoch: 5| Step: 2
Training loss: 3.928937411910063
Validation loss: 3.204057645642559

Epoch: 5| Step: 3
Training loss: 3.3884522116754288
Validation loss: 3.20492526090885

Epoch: 5| Step: 4
Training loss: 4.173021937524946
Validation loss: 3.2034672988167516

Epoch: 5| Step: 5
Training loss: 3.825784271220346
Validation loss: 3.2038312083959437

Epoch: 5| Step: 6
Training loss: 3.0207125584805175
Validation loss: 3.204491911846947

Epoch: 5| Step: 7
Training loss: 2.992802728495798
Validation loss: 3.2029063064347723

Epoch: 5| Step: 8
Training loss: 3.278513030295798
Validation loss: 3.2045036944417866

Epoch: 5| Step: 9
Training loss: 3.951655661381124
Validation loss: 3.2045270290997974

Epoch: 5| Step: 10
Training loss: 3.1285756825905264
Validation loss: 3.204695202734145

Epoch: 83| Step: 0
Training loss: 3.507001685419213
Validation loss: 3.2021741830972914

Epoch: 5| Step: 1
Training loss: 2.7710929309208154
Validation loss: 3.2006048125096735

Epoch: 5| Step: 2
Training loss: 3.3395536240945622
Validation loss: 3.2020188577380333

Epoch: 5| Step: 3
Training loss: 3.425750488699905
Validation loss: 3.202597649976096

Epoch: 5| Step: 4
Training loss: 3.148752655839879
Validation loss: 3.1984124028721452

Epoch: 5| Step: 5
Training loss: 3.5461266354122047
Validation loss: 3.201822698347481

Epoch: 5| Step: 6
Training loss: 3.6299838302714553
Validation loss: 3.206031216029185

Epoch: 5| Step: 7
Training loss: 3.088145410207389
Validation loss: 3.2009482305824326

Epoch: 5| Step: 8
Training loss: 3.3536349204811495
Validation loss: 3.2035859143267635

Epoch: 5| Step: 9
Training loss: 3.7755565814048726
Validation loss: 3.2007905109924137

Epoch: 5| Step: 10
Training loss: 4.250470303711623
Validation loss: 3.2015786124566143

Epoch: 84| Step: 0
Training loss: 3.2085947367868886
Validation loss: 3.2024374075033393

Epoch: 5| Step: 1
Training loss: 3.3441107724656054
Validation loss: 3.200180153460658

Epoch: 5| Step: 2
Training loss: 3.507020720773902
Validation loss: 3.20215316504061

Epoch: 5| Step: 3
Training loss: 3.208864457065895
Validation loss: 3.2019012522591397

Epoch: 5| Step: 4
Training loss: 3.9028993197725153
Validation loss: 3.2049045568613304

Epoch: 5| Step: 5
Training loss: 3.55177459419152
Validation loss: 3.2077040825651086

Epoch: 5| Step: 6
Training loss: 3.260331677841402
Validation loss: 3.2089130185291057

Epoch: 5| Step: 7
Training loss: 3.8244324605920137
Validation loss: 3.2061503851602526

Epoch: 5| Step: 8
Training loss: 3.347388168871454
Validation loss: 3.203195393746986

Epoch: 5| Step: 9
Training loss: 3.458321919862841
Validation loss: 3.1984886872887413

Epoch: 5| Step: 10
Training loss: 3.1580941128952
Validation loss: 3.197406181456064

Epoch: 85| Step: 0
Training loss: 3.1109285547040684
Validation loss: 3.196857961895686

Epoch: 5| Step: 1
Training loss: 3.3467731535131957
Validation loss: 3.1993083987122963

Epoch: 5| Step: 2
Training loss: 3.7126314493149444
Validation loss: 3.1982384970326736

Epoch: 5| Step: 3
Training loss: 3.133646181058341
Validation loss: 3.1974106169420025

Epoch: 5| Step: 4
Training loss: 3.567390966105861
Validation loss: 3.197493379479519

Epoch: 5| Step: 5
Training loss: 3.872742764551467
Validation loss: 3.207379999476292

Epoch: 5| Step: 6
Training loss: 3.7038511698999907
Validation loss: 3.1970173421398598

Epoch: 5| Step: 7
Training loss: 2.681993120979744
Validation loss: 3.1957626019742045

Epoch: 5| Step: 8
Training loss: 3.20870233040424
Validation loss: 3.197716887919893

Epoch: 5| Step: 9
Training loss: 3.735636605750046
Validation loss: 3.193629346463335

Epoch: 5| Step: 10
Training loss: 3.6307075554932298
Validation loss: 3.1978746653059917

Epoch: 86| Step: 0
Training loss: 3.2696419427106562
Validation loss: 3.1984514261846044

Epoch: 5| Step: 1
Training loss: 3.1473292821227687
Validation loss: 3.201308114957066

Epoch: 5| Step: 2
Training loss: 3.2843488320162053
Validation loss: 3.1991548638631913

Epoch: 5| Step: 3
Training loss: 3.38979909656001
Validation loss: 3.2025276929743445

Epoch: 5| Step: 4
Training loss: 3.109014595652688
Validation loss: 3.2015022447165027

Epoch: 5| Step: 5
Training loss: 3.151604737134468
Validation loss: 3.202865436400764

Epoch: 5| Step: 6
Training loss: 3.806297760461783
Validation loss: 3.2024623838778132

Epoch: 5| Step: 7
Training loss: 3.694598332564618
Validation loss: 3.1998122649856926

Epoch: 5| Step: 8
Training loss: 3.900645393375727
Validation loss: 3.198579813578345

Epoch: 5| Step: 9
Training loss: 2.658935804667402
Validation loss: 3.1966965992665264

Epoch: 5| Step: 10
Training loss: 4.274640180826582
Validation loss: 3.1969087891082157

Epoch: 87| Step: 0
Training loss: 3.4505692772493597
Validation loss: 3.1973971629363955

Epoch: 5| Step: 1
Training loss: 3.2729328649659495
Validation loss: 3.1975187296080976

Epoch: 5| Step: 2
Training loss: 3.711867430769639
Validation loss: 3.195521585544815

Epoch: 5| Step: 3
Training loss: 3.3213704656390757
Validation loss: 3.1974100252235185

Epoch: 5| Step: 4
Training loss: 3.241060874708603
Validation loss: 3.2014552508657896

Epoch: 5| Step: 5
Training loss: 4.112768824177095
Validation loss: 3.193428917913748

Epoch: 5| Step: 6
Training loss: 2.7836903356454044
Validation loss: 3.194533357516798

Epoch: 5| Step: 7
Training loss: 3.255352015058181
Validation loss: 3.1935164348594443

Epoch: 5| Step: 8
Training loss: 3.550955957997396
Validation loss: 3.193981165386801

Epoch: 5| Step: 9
Training loss: 3.4474357584610362
Validation loss: 3.194556774633225

Epoch: 5| Step: 10
Training loss: 3.5123209028639204
Validation loss: 3.1961369082150695

Epoch: 88| Step: 0
Training loss: 3.2104371509397716
Validation loss: 3.1920984288498078

Epoch: 5| Step: 1
Training loss: 3.683723973291344
Validation loss: 3.192605418022488

Epoch: 5| Step: 2
Training loss: 2.7940497593855347
Validation loss: 3.1903736850313393

Epoch: 5| Step: 3
Training loss: 3.7583362745680935
Validation loss: 3.1920739351777563

Epoch: 5| Step: 4
Training loss: 3.297702920380553
Validation loss: 3.190955384907683

Epoch: 5| Step: 5
Training loss: 4.014346620595088
Validation loss: 3.1893998029389965

Epoch: 5| Step: 6
Training loss: 3.5794925658266976
Validation loss: 3.189703158835413

Epoch: 5| Step: 7
Training loss: 3.418126391453965
Validation loss: 3.188042445134785

Epoch: 5| Step: 8
Training loss: 3.976005350289688
Validation loss: 3.188365454448737

Epoch: 5| Step: 9
Training loss: 3.12869075266407
Validation loss: 3.1906846649343263

Epoch: 5| Step: 10
Training loss: 2.4960465643158405
Validation loss: 3.189277140648858

Epoch: 89| Step: 0
Training loss: 3.3762070651892326
Validation loss: 3.188624581554531

Epoch: 5| Step: 1
Training loss: 3.085162642533419
Validation loss: 3.1900691022655643

Epoch: 5| Step: 2
Training loss: 3.8868587296165757
Validation loss: 3.1959950429927817

Epoch: 5| Step: 3
Training loss: 3.753312364613404
Validation loss: 3.1946693621817563

Epoch: 5| Step: 4
Training loss: 3.654532004477855
Validation loss: 3.1993302423723757

Epoch: 5| Step: 5
Training loss: 3.7054698618356965
Validation loss: 3.1906206513072366

Epoch: 5| Step: 6
Training loss: 3.2068977281697695
Validation loss: 3.191442690465652

Epoch: 5| Step: 7
Training loss: 3.2213974222266817
Validation loss: 3.188470831347045

Epoch: 5| Step: 8
Training loss: 3.185658091013434
Validation loss: 3.187429825044282

Epoch: 5| Step: 9
Training loss: 3.7740213957292776
Validation loss: 3.185628250949854

Epoch: 5| Step: 10
Training loss: 2.5947227951786256
Validation loss: 3.188694777651442

Epoch: 90| Step: 0
Training loss: 3.398657920967823
Validation loss: 3.1902238410097934

Epoch: 5| Step: 1
Training loss: 3.816578169106253
Validation loss: 3.1877160004167244

Epoch: 5| Step: 2
Training loss: 4.157132392087338
Validation loss: 3.186426112515629

Epoch: 5| Step: 3
Training loss: 3.87420916947482
Validation loss: 3.187029215665962

Epoch: 5| Step: 4
Training loss: 3.1740742092098744
Validation loss: 3.1884358669099124

Epoch: 5| Step: 5
Training loss: 3.099357993803698
Validation loss: 3.188405708709551

Epoch: 5| Step: 6
Training loss: 2.765613706748879
Validation loss: 3.187029104659005

Epoch: 5| Step: 7
Training loss: 3.8180384196151333
Validation loss: 3.1895200958212766

Epoch: 5| Step: 8
Training loss: 2.728335702980922
Validation loss: 3.1888660750472777

Epoch: 5| Step: 9
Training loss: 3.1935476638392886
Validation loss: 3.189485626761428

Epoch: 5| Step: 10
Training loss: 3.366843504715017
Validation loss: 3.1878609192568477

Epoch: 91| Step: 0
Training loss: 3.2253151022574675
Validation loss: 3.1906381722225428

Epoch: 5| Step: 1
Training loss: 3.0658628723374988
Validation loss: 3.188423974282637

Epoch: 5| Step: 2
Training loss: 2.996975486749311
Validation loss: 3.1932957280905296

Epoch: 5| Step: 3
Training loss: 3.1552994306999596
Validation loss: 3.195841432389936

Epoch: 5| Step: 4
Training loss: 3.9096223236083607
Validation loss: 3.196180972407302

Epoch: 5| Step: 5
Training loss: 4.016340971176741
Validation loss: 3.190238284752543

Epoch: 5| Step: 6
Training loss: 3.9690560050198194
Validation loss: 3.190695576128618

Epoch: 5| Step: 7
Training loss: 2.555833751859611
Validation loss: 3.1855926605948253

Epoch: 5| Step: 8
Training loss: 3.995165406623578
Validation loss: 3.184965393086512

Epoch: 5| Step: 9
Training loss: 3.377260087172904
Validation loss: 3.180775894142081

Epoch: 5| Step: 10
Training loss: 3.0079168128218647
Validation loss: 3.181876870069415

Epoch: 92| Step: 0
Training loss: 3.424877365032964
Validation loss: 3.1817107189533615

Epoch: 5| Step: 1
Training loss: 3.2341618122109286
Validation loss: 3.1810875995576935

Epoch: 5| Step: 2
Training loss: 3.8661154754253952
Validation loss: 3.1803851884374232

Epoch: 5| Step: 3
Training loss: 3.0613533520337537
Validation loss: 3.179898723871004

Epoch: 5| Step: 4
Training loss: 3.765158723319907
Validation loss: 3.1808063954896366

Epoch: 5| Step: 5
Training loss: 2.9870286896959
Validation loss: 3.1807981624758264

Epoch: 5| Step: 6
Training loss: 3.7539625213247976
Validation loss: 3.1811382242233064

Epoch: 5| Step: 7
Training loss: 3.119423277199878
Validation loss: 3.1802759121185074

Epoch: 5| Step: 8
Training loss: 3.6231509787519953
Validation loss: 3.1795971900354116

Epoch: 5| Step: 9
Training loss: 3.3969898867721877
Validation loss: 3.1797276706218565

Epoch: 5| Step: 10
Training loss: 3.2982177892503017
Validation loss: 3.1772114346461553

Epoch: 93| Step: 0
Training loss: 2.870900756162323
Validation loss: 3.1835714102250074

Epoch: 5| Step: 1
Training loss: 3.242561190107943
Validation loss: 3.1843290116964775

Epoch: 5| Step: 2
Training loss: 3.795177943866447
Validation loss: 3.188396217678024

Epoch: 5| Step: 3
Training loss: 3.481310125136502
Validation loss: 3.1877523777148262

Epoch: 5| Step: 4
Training loss: 3.9132363062261777
Validation loss: 3.1872631928452893

Epoch: 5| Step: 5
Training loss: 3.5742714466316827
Validation loss: 3.1812866717482375

Epoch: 5| Step: 6
Training loss: 3.086285767037043
Validation loss: 3.178063252647851

Epoch: 5| Step: 7
Training loss: 3.7304667048423714
Validation loss: 3.1800983541753003

Epoch: 5| Step: 8
Training loss: 3.2315375371680237
Validation loss: 3.1755401500031026

Epoch: 5| Step: 9
Training loss: 3.112880858134226
Validation loss: 3.1791970072538325

Epoch: 5| Step: 10
Training loss: 3.5097334260052646
Validation loss: 3.1776600110424345

Epoch: 94| Step: 0
Training loss: 3.1176491302330933
Validation loss: 3.1779971213504967

Epoch: 5| Step: 1
Training loss: 4.096521036670242
Validation loss: 3.175870149279308

Epoch: 5| Step: 2
Training loss: 3.463469876953171
Validation loss: 3.1774763203489687

Epoch: 5| Step: 3
Training loss: 2.497480076127106
Validation loss: 3.173286316773156

Epoch: 5| Step: 4
Training loss: 2.924163085668601
Validation loss: 3.1743443025251588

Epoch: 5| Step: 5
Training loss: 3.315378485889614
Validation loss: 3.1757443295258123

Epoch: 5| Step: 6
Training loss: 3.4485448781672248
Validation loss: 3.174330073973484

Epoch: 5| Step: 7
Training loss: 3.371831607627782
Validation loss: 3.175623605232585

Epoch: 5| Step: 8
Training loss: 3.9051488926595783
Validation loss: 3.1759926093538753

Epoch: 5| Step: 9
Training loss: 3.2957647542333146
Validation loss: 3.1766156935548304

Epoch: 5| Step: 10
Training loss: 3.9626319165338355
Validation loss: 3.1765130902865377

Epoch: 95| Step: 0
Training loss: 3.5673198553420162
Validation loss: 3.182127277654483

Epoch: 5| Step: 1
Training loss: 3.6883792152314765
Validation loss: 3.179686393817218

Epoch: 5| Step: 2
Training loss: 3.3633762394941122
Validation loss: 3.1748362814134183

Epoch: 5| Step: 3
Training loss: 3.8007103657556955
Validation loss: 3.1719174081418466

Epoch: 5| Step: 4
Training loss: 3.2420305696678193
Validation loss: 3.172838566720143

Epoch: 5| Step: 5
Training loss: 3.59591092364488
Validation loss: 3.1730452162605127

Epoch: 5| Step: 6
Training loss: 3.4942261891686086
Validation loss: 3.1757985815508594

Epoch: 5| Step: 7
Training loss: 3.699260771854116
Validation loss: 3.1784398521403756

Epoch: 5| Step: 8
Training loss: 2.597708198200022
Validation loss: 3.1710621865146593

Epoch: 5| Step: 9
Training loss: 3.2498661894027943
Validation loss: 3.1790377238758825

Epoch: 5| Step: 10
Training loss: 3.1296609832661146
Validation loss: 3.1699496081693255

Epoch: 96| Step: 0
Training loss: 3.5898426873638254
Validation loss: 3.169787559954003

Epoch: 5| Step: 1
Training loss: 3.1423162205383464
Validation loss: 3.169547877293028

Epoch: 5| Step: 2
Training loss: 3.2566395942033872
Validation loss: 3.1722762648485534

Epoch: 5| Step: 3
Training loss: 3.7873864940593664
Validation loss: 3.1700164556588915

Epoch: 5| Step: 4
Training loss: 3.6308948336588904
Validation loss: 3.1705750135660886

Epoch: 5| Step: 5
Training loss: 3.6910670210366243
Validation loss: 3.1696166808876653

Epoch: 5| Step: 6
Training loss: 2.7480965876200414
Validation loss: 3.1718287828045453

Epoch: 5| Step: 7
Training loss: 3.1225999389488153
Validation loss: 3.170471713477051

Epoch: 5| Step: 8
Training loss: 3.7188128297771375
Validation loss: 3.168280618204065

Epoch: 5| Step: 9
Training loss: 4.057964434035911
Validation loss: 3.1696932854698043

Epoch: 5| Step: 10
Training loss: 2.3980802089712654
Validation loss: 3.1680286338538513

Epoch: 97| Step: 0
Training loss: 3.38759452997609
Validation loss: 3.168544993182925

Epoch: 5| Step: 1
Training loss: 3.105341763569172
Validation loss: 3.174635199351347

Epoch: 5| Step: 2
Training loss: 2.8856921196481466
Validation loss: 3.1705568254779304

Epoch: 5| Step: 3
Training loss: 3.281675184040889
Validation loss: 3.171825179609913

Epoch: 5| Step: 4
Training loss: 4.014914839472052
Validation loss: 3.1689144882664055

Epoch: 5| Step: 5
Training loss: 3.0660902504375382
Validation loss: 3.169127899203141

Epoch: 5| Step: 6
Training loss: 3.7228728448515542
Validation loss: 3.1670906050818193

Epoch: 5| Step: 7
Training loss: 4.050337676111381
Validation loss: 3.170613325129822

Epoch: 5| Step: 8
Training loss: 3.653095677945838
Validation loss: 3.1678437591096085

Epoch: 5| Step: 9
Training loss: 3.3617593509705435
Validation loss: 3.1640426402175774

Epoch: 5| Step: 10
Training loss: 2.664768516979378
Validation loss: 3.173812772172596

Epoch: 98| Step: 0
Training loss: 3.131295386192951
Validation loss: 3.1674421658319525

Epoch: 5| Step: 1
Training loss: 3.4574330241900935
Validation loss: 3.169374050691789

Epoch: 5| Step: 2
Training loss: 3.0006067933903036
Validation loss: 3.1672947125335247

Epoch: 5| Step: 3
Training loss: 3.328413973159167
Validation loss: 3.168515996853794

Epoch: 5| Step: 4
Training loss: 4.033081821344706
Validation loss: 3.1666431042928536

Epoch: 5| Step: 5
Training loss: 3.7762314461558795
Validation loss: 3.1681728882698676

Epoch: 5| Step: 6
Training loss: 3.419587925630181
Validation loss: 3.167589604982323

Epoch: 5| Step: 7
Training loss: 4.087238987046322
Validation loss: 3.1707046121959777

Epoch: 5| Step: 8
Training loss: 3.3399394060680283
Validation loss: 3.1674773474410984

Epoch: 5| Step: 9
Training loss: 2.9417636851736986
Validation loss: 3.1664409951030175

Epoch: 5| Step: 10
Training loss: 2.6833331607636897
Validation loss: 3.1664050522547242

Epoch: 99| Step: 0
Training loss: 3.2973632450970864
Validation loss: 3.1656252849330797

Epoch: 5| Step: 1
Training loss: 4.046464464728023
Validation loss: 3.1639684235991417

Epoch: 5| Step: 2
Training loss: 3.0274247090989226
Validation loss: 3.1647382854390806

Epoch: 5| Step: 3
Training loss: 3.6809686265026595
Validation loss: 3.164110911292806

Epoch: 5| Step: 4
Training loss: 2.2150777595596947
Validation loss: 3.1663720544921374

Epoch: 5| Step: 5
Training loss: 3.4721524159514034
Validation loss: 3.165937267380721

Epoch: 5| Step: 6
Training loss: 3.5897431966585773
Validation loss: 3.1662304523277007

Epoch: 5| Step: 7
Training loss: 3.4135174698137454
Validation loss: 3.1650732875075267

Epoch: 5| Step: 8
Training loss: 3.726765177271495
Validation loss: 3.164054896726478

Epoch: 5| Step: 9
Training loss: 3.593323657412645
Validation loss: 3.167421835947849

Epoch: 5| Step: 10
Training loss: 3.119056848632291
Validation loss: 3.1611459812949856

Epoch: 100| Step: 0
Training loss: 3.494450938655585
Validation loss: 3.1631192580738823

Epoch: 5| Step: 1
Training loss: 3.495083898538733
Validation loss: 3.162518855238969

Epoch: 5| Step: 2
Training loss: 3.5026864232422277
Validation loss: 3.162408865084429

Epoch: 5| Step: 3
Training loss: 3.187856317687747
Validation loss: 3.162471534211463

Epoch: 5| Step: 4
Training loss: 3.6702685149290764
Validation loss: 3.162341954062375

Epoch: 5| Step: 5
Training loss: 3.793976104886303
Validation loss: 3.1626135681245824

Epoch: 5| Step: 6
Training loss: 3.696527067758452
Validation loss: 3.1624745473761977

Epoch: 5| Step: 7
Training loss: 2.5960210027153683
Validation loss: 3.161139235518079

Epoch: 5| Step: 8
Training loss: 2.6942963827118738
Validation loss: 3.1614188220373367

Epoch: 5| Step: 9
Training loss: 3.4672533535301278
Validation loss: 3.1622560940037143

Epoch: 5| Step: 10
Training loss: 3.7215044094942646
Validation loss: 3.1592214578260798

Epoch: 101| Step: 0
Training loss: 2.7576691587548985
Validation loss: 3.1636830902398163

Epoch: 5| Step: 1
Training loss: 3.400038208466305
Validation loss: 3.1673886804257636

Epoch: 5| Step: 2
Training loss: 3.8903243473426294
Validation loss: 3.1675277104955004

Epoch: 5| Step: 3
Training loss: 3.995255756236296
Validation loss: 3.1696899200607924

Epoch: 5| Step: 4
Training loss: 3.1393496832490357
Validation loss: 3.173894086305365

Epoch: 5| Step: 5
Training loss: 3.3753444354589055
Validation loss: 3.181442040716083

Epoch: 5| Step: 6
Training loss: 3.1010837137337908
Validation loss: 3.1718884709305186

Epoch: 5| Step: 7
Training loss: 3.308220456085049
Validation loss: 3.16305383556045

Epoch: 5| Step: 8
Training loss: 3.3688780751414047
Validation loss: 3.160860578072764

Epoch: 5| Step: 9
Training loss: 3.340528130264272
Validation loss: 3.160852175502758

Epoch: 5| Step: 10
Training loss: 3.7407720831665543
Validation loss: 3.158456525532924

Epoch: 102| Step: 0
Training loss: 3.645364320650741
Validation loss: 3.163012615521227

Epoch: 5| Step: 1
Training loss: 3.0178235198056056
Validation loss: 3.161841468417319

Epoch: 5| Step: 2
Training loss: 3.172475673380863
Validation loss: 3.1642844890593658

Epoch: 5| Step: 3
Training loss: 2.566524137114791
Validation loss: 3.1735149988992095

Epoch: 5| Step: 4
Training loss: 3.4869110047580136
Validation loss: 3.163297777169173

Epoch: 5| Step: 5
Training loss: 3.6758053785904408
Validation loss: 3.166906299710047

Epoch: 5| Step: 6
Training loss: 3.0906631019951334
Validation loss: 3.1604206443041973

Epoch: 5| Step: 7
Training loss: 4.1435566438467575
Validation loss: 3.1605729054890563

Epoch: 5| Step: 8
Training loss: 3.6288473824611738
Validation loss: 3.1596289009293343

Epoch: 5| Step: 9
Training loss: 3.354367804962908
Validation loss: 3.1622313853962445

Epoch: 5| Step: 10
Training loss: 3.537847112333514
Validation loss: 3.1586153371444454

Epoch: 103| Step: 0
Training loss: 3.970332993924011
Validation loss: 3.162024807462471

Epoch: 5| Step: 1
Training loss: 3.1114251360523366
Validation loss: 3.1562944740289987

Epoch: 5| Step: 2
Training loss: 3.468969664620551
Validation loss: 3.1561668447584643

Epoch: 5| Step: 3
Training loss: 2.8063093931034326
Validation loss: 3.1547427205564205

Epoch: 5| Step: 4
Training loss: 3.365859475641493
Validation loss: 3.1616244835597254

Epoch: 5| Step: 5
Training loss: 3.6970168330764053
Validation loss: 3.154637840701035

Epoch: 5| Step: 6
Training loss: 3.4065811976133222
Validation loss: 3.1565649833258353

Epoch: 5| Step: 7
Training loss: 3.0127951829577007
Validation loss: 3.157831770148705

Epoch: 5| Step: 8
Training loss: 3.1620018547868205
Validation loss: 3.1571896183017416

Epoch: 5| Step: 9
Training loss: 3.8484011166301233
Validation loss: 3.15497947161341

Epoch: 5| Step: 10
Training loss: 3.459354494993783
Validation loss: 3.1541710529829805

Epoch: 104| Step: 0
Training loss: 3.3162137212684883
Validation loss: 3.1541944316408657

Epoch: 5| Step: 1
Training loss: 3.79119988946345
Validation loss: 3.1520061327119464

Epoch: 5| Step: 2
Training loss: 2.8112120328368855
Validation loss: 3.155605525308578

Epoch: 5| Step: 3
Training loss: 3.249598404941139
Validation loss: 3.15375373380505

Epoch: 5| Step: 4
Training loss: 3.0028637886570113
Validation loss: 3.1548160555572853

Epoch: 5| Step: 5
Training loss: 3.6224722105741316
Validation loss: 3.1537082834242725

Epoch: 5| Step: 6
Training loss: 3.4313903613122396
Validation loss: 3.1474516602093674

Epoch: 5| Step: 7
Training loss: 3.714205361115426
Validation loss: 3.1504366920488853

Epoch: 5| Step: 8
Training loss: 3.2677643261725975
Validation loss: 3.151958561946324

Epoch: 5| Step: 9
Training loss: 3.902643476704246
Validation loss: 3.151853950585082

Epoch: 5| Step: 10
Training loss: 3.1291305709226664
Validation loss: 3.15106274116294

Epoch: 105| Step: 0
Training loss: 2.6904063810526355
Validation loss: 3.1497535545354896

Epoch: 5| Step: 1
Training loss: 3.4166566957157687
Validation loss: 3.14960345799663

Epoch: 5| Step: 2
Training loss: 3.0289666139079423
Validation loss: 3.152813410268875

Epoch: 5| Step: 3
Training loss: 3.8198578920944035
Validation loss: 3.1485164193456066

Epoch: 5| Step: 4
Training loss: 3.66472042334064
Validation loss: 3.150205574515528

Epoch: 5| Step: 5
Training loss: 2.860475755615124
Validation loss: 3.1521432386903454

Epoch: 5| Step: 6
Training loss: 3.972901823392497
Validation loss: 3.1530130105944156

Epoch: 5| Step: 7
Training loss: 2.655194061428508
Validation loss: 3.1499477184206603

Epoch: 5| Step: 8
Training loss: 3.5169456883484114
Validation loss: 3.148031259983753

Epoch: 5| Step: 9
Training loss: 3.7532802222533044
Validation loss: 3.150895827615288

Epoch: 5| Step: 10
Training loss: 3.7521635807711307
Validation loss: 3.1475629712315145

Epoch: 106| Step: 0
Training loss: 3.164515484067248
Validation loss: 3.1474280424986634

Epoch: 5| Step: 1
Training loss: 3.682038999501181
Validation loss: 3.1471578907181876

Epoch: 5| Step: 2
Training loss: 2.9216822596335357
Validation loss: 3.1486912883112965

Epoch: 5| Step: 3
Training loss: 3.40574572268869
Validation loss: 3.149682231734772

Epoch: 5| Step: 4
Training loss: 3.4521884942866965
Validation loss: 3.1473877300552444

Epoch: 5| Step: 5
Training loss: 3.5438324234138467
Validation loss: 3.147838788328683

Epoch: 5| Step: 6
Training loss: 3.713686533167006
Validation loss: 3.147150943894346

Epoch: 5| Step: 7
Training loss: 3.1059112425512816
Validation loss: 3.147312210846986

Epoch: 5| Step: 8
Training loss: 3.8699343395330836
Validation loss: 3.1499073568361866

Epoch: 5| Step: 9
Training loss: 3.269313353794318
Validation loss: 3.1506752630311627

Epoch: 5| Step: 10
Training loss: 3.055452919209181
Validation loss: 3.1483534381319003

Epoch: 107| Step: 0
Training loss: 2.7200991911192482
Validation loss: 3.1462808584196407

Epoch: 5| Step: 1
Training loss: 3.659557313881222
Validation loss: 3.147729421358601

Epoch: 5| Step: 2
Training loss: 3.837997473862509
Validation loss: 3.148804700018624

Epoch: 5| Step: 3
Training loss: 3.786796852032014
Validation loss: 3.144418884279362

Epoch: 5| Step: 4
Training loss: 3.489720234628989
Validation loss: 3.1445673874312474

Epoch: 5| Step: 5
Training loss: 3.2768662005882416
Validation loss: 3.144177411252069

Epoch: 5| Step: 6
Training loss: 3.3808060613755693
Validation loss: 3.144912049141537

Epoch: 5| Step: 7
Training loss: 3.5161357593387357
Validation loss: 3.143030747073761

Epoch: 5| Step: 8
Training loss: 3.0100313003788273
Validation loss: 3.145365970357723

Epoch: 5| Step: 9
Training loss: 3.535961282863359
Validation loss: 3.143164526949003

Epoch: 5| Step: 10
Training loss: 2.92714896530113
Validation loss: 3.1456039234774904

Epoch: 108| Step: 0
Training loss: 3.517732929252568
Validation loss: 3.1428811427201393

Epoch: 5| Step: 1
Training loss: 3.036560283713863
Validation loss: 3.143686014923332

Epoch: 5| Step: 2
Training loss: 3.4246278602411877
Validation loss: 3.142381728885804

Epoch: 5| Step: 3
Training loss: 3.516194208477535
Validation loss: 3.1429494166841936

Epoch: 5| Step: 4
Training loss: 4.022698373401757
Validation loss: 3.143628783400633

Epoch: 5| Step: 5
Training loss: 3.419505513900325
Validation loss: 3.141663611164589

Epoch: 5| Step: 6
Training loss: 3.862627149544585
Validation loss: 3.145151230738402

Epoch: 5| Step: 7
Training loss: 2.989265947851148
Validation loss: 3.141759695311751

Epoch: 5| Step: 8
Training loss: 3.053401900886118
Validation loss: 3.1450763115605165

Epoch: 5| Step: 9
Training loss: 3.224192933815049
Validation loss: 3.145166344450578

Epoch: 5| Step: 10
Training loss: 3.0275258261778424
Validation loss: 3.143972261282618

Epoch: 109| Step: 0
Training loss: 3.3485792705875563
Validation loss: 3.148676716675522

Epoch: 5| Step: 1
Training loss: 3.2551749184482888
Validation loss: 3.1450580020958587

Epoch: 5| Step: 2
Training loss: 3.055760968172166
Validation loss: 3.145484152483245

Epoch: 5| Step: 3
Training loss: 4.034548570606023
Validation loss: 3.1429103975787522

Epoch: 5| Step: 4
Training loss: 3.585774336948718
Validation loss: 3.1404879609544416

Epoch: 5| Step: 5
Training loss: 3.594688226712523
Validation loss: 3.141949730085489

Epoch: 5| Step: 6
Training loss: 3.3777578883115322
Validation loss: 3.138068186758763

Epoch: 5| Step: 7
Training loss: 3.5565514676410883
Validation loss: 3.1394195977965604

Epoch: 5| Step: 8
Training loss: 2.957480473328957
Validation loss: 3.142931892568575

Epoch: 5| Step: 9
Training loss: 3.3029633481575997
Validation loss: 3.1384810650626123

Epoch: 5| Step: 10
Training loss: 3.0454063592874556
Validation loss: 3.1410672721197317

Epoch: 110| Step: 0
Training loss: 2.918601910838927
Validation loss: 3.1403022640694873

Epoch: 5| Step: 1
Training loss: 3.691194138664549
Validation loss: 3.1421078878017297

Epoch: 5| Step: 2
Training loss: 3.1324598156664574
Validation loss: 3.1474666537309552

Epoch: 5| Step: 3
Training loss: 3.8822379656203587
Validation loss: 3.1475546569647594

Epoch: 5| Step: 4
Training loss: 3.508566862354529
Validation loss: 3.150746617054483

Epoch: 5| Step: 5
Training loss: 3.118436099597904
Validation loss: 3.1463690545193788

Epoch: 5| Step: 6
Training loss: 3.5510085970001875
Validation loss: 3.14475372919493

Epoch: 5| Step: 7
Training loss: 3.645399507415415
Validation loss: 3.1444913634986595

Epoch: 5| Step: 8
Training loss: 3.257079556574264
Validation loss: 3.139690818775518

Epoch: 5| Step: 9
Training loss: 2.5607984522554155
Validation loss: 3.140687017349364

Epoch: 5| Step: 10
Training loss: 3.8415851234062193
Validation loss: 3.1398352900107374

Epoch: 111| Step: 0
Training loss: 3.646581140755445
Validation loss: 3.138760373115751

Epoch: 5| Step: 1
Training loss: 3.8774209612249835
Validation loss: 3.1385321858358584

Epoch: 5| Step: 2
Training loss: 3.4022251813618074
Validation loss: 3.137338865847515

Epoch: 5| Step: 3
Training loss: 3.7526056773676624
Validation loss: 3.1376489350061085

Epoch: 5| Step: 4
Training loss: 3.7556371915723807
Validation loss: 3.1353220433581996

Epoch: 5| Step: 5
Training loss: 3.7131076610849325
Validation loss: 3.1364846550658605

Epoch: 5| Step: 6
Training loss: 3.1682082155082494
Validation loss: 3.1352314751087227

Epoch: 5| Step: 7
Training loss: 2.9970475609575504
Validation loss: 3.136684769745828

Epoch: 5| Step: 8
Training loss: 3.1646214121037923
Validation loss: 3.1352916301902383

Epoch: 5| Step: 9
Training loss: 2.944021736448319
Validation loss: 3.1358644422405364

Epoch: 5| Step: 10
Training loss: 2.4600695820403584
Validation loss: 3.1337843659899214

Epoch: 112| Step: 0
Training loss: 3.743473731850497
Validation loss: 3.135016307072379

Epoch: 5| Step: 1
Training loss: 3.021005998258877
Validation loss: 3.1368069468860593

Epoch: 5| Step: 2
Training loss: 3.1443506414068585
Validation loss: 3.1339553607222372

Epoch: 5| Step: 3
Training loss: 3.620812463791686
Validation loss: 3.1387494961906475

Epoch: 5| Step: 4
Training loss: 3.7115686140967994
Validation loss: 3.136569162529145

Epoch: 5| Step: 5
Training loss: 3.449386575316208
Validation loss: 3.1357788775033493

Epoch: 5| Step: 6
Training loss: 2.80310592049492
Validation loss: 3.1359352143895096

Epoch: 5| Step: 7
Training loss: 3.9906542795611215
Validation loss: 3.139602263598827

Epoch: 5| Step: 8
Training loss: 3.1400244598893834
Validation loss: 3.1407689172940523

Epoch: 5| Step: 9
Training loss: 3.4670293165914376
Validation loss: 3.141744664762618

Epoch: 5| Step: 10
Training loss: 2.828951720067463
Validation loss: 3.1380067164878342

Epoch: 113| Step: 0
Training loss: 3.2350205224165958
Validation loss: 3.1382404683348715

Epoch: 5| Step: 1
Training loss: 2.9925798203762657
Validation loss: 3.1375719459703113

Epoch: 5| Step: 2
Training loss: 4.25257571090768
Validation loss: 3.1373102331809073

Epoch: 5| Step: 3
Training loss: 3.346873740544158
Validation loss: 3.135000049462645

Epoch: 5| Step: 4
Training loss: 3.5659894751940624
Validation loss: 3.136701362708889

Epoch: 5| Step: 5
Training loss: 3.4387519637296027
Validation loss: 3.133871078907091

Epoch: 5| Step: 6
Training loss: 3.0058766662615883
Validation loss: 3.133997250468841

Epoch: 5| Step: 7
Training loss: 3.240599020225689
Validation loss: 3.13322969226839

Epoch: 5| Step: 8
Training loss: 3.0531150107088534
Validation loss: 3.134024178419563

Epoch: 5| Step: 9
Training loss: 3.6135656296452425
Validation loss: 3.135408206811498

Epoch: 5| Step: 10
Training loss: 3.2598051202483056
Validation loss: 3.1342236895024995

Epoch: 114| Step: 0
Training loss: 4.009018982254043
Validation loss: 3.1341565791963077

Epoch: 5| Step: 1
Training loss: 2.9824506537167497
Validation loss: 3.1320892220001197

Epoch: 5| Step: 2
Training loss: 3.198299438895971
Validation loss: 3.1302518082816033

Epoch: 5| Step: 3
Training loss: 3.6156474515832744
Validation loss: 3.1310529452696167

Epoch: 5| Step: 4
Training loss: 2.901111284627154
Validation loss: 3.1273735630574717

Epoch: 5| Step: 5
Training loss: 3.2797746520437157
Validation loss: 3.1289952455350134

Epoch: 5| Step: 6
Training loss: 4.100411389808811
Validation loss: 3.129466116948326

Epoch: 5| Step: 7
Training loss: 2.378493199561459
Validation loss: 3.131591401779719

Epoch: 5| Step: 8
Training loss: 3.3661513006484753
Validation loss: 3.128517328982358

Epoch: 5| Step: 9
Training loss: 3.563151785136426
Validation loss: 3.126382642480408

Epoch: 5| Step: 10
Training loss: 3.458535904677422
Validation loss: 3.1278985828335824

Epoch: 115| Step: 0
Training loss: 2.74825023123734
Validation loss: 3.1281485137853937

Epoch: 5| Step: 1
Training loss: 3.604536107409882
Validation loss: 3.1304748928347066

Epoch: 5| Step: 2
Training loss: 3.736933386474628
Validation loss: 3.1287042186096903

Epoch: 5| Step: 3
Training loss: 3.752054923015481
Validation loss: 3.130951467421675

Epoch: 5| Step: 4
Training loss: 3.209849523659727
Validation loss: 3.1332410490060147

Epoch: 5| Step: 5
Training loss: 3.7923081802008345
Validation loss: 3.1329160451277906

Epoch: 5| Step: 6
Training loss: 3.3716747715906497
Validation loss: 3.13256738744276

Epoch: 5| Step: 7
Training loss: 3.3252235624258866
Validation loss: 3.1276232695690522

Epoch: 5| Step: 8
Training loss: 3.530181453028809
Validation loss: 3.13317356581569

Epoch: 5| Step: 9
Training loss: 3.3460232146758058
Validation loss: 3.130703775476644

Epoch: 5| Step: 10
Training loss: 2.327985618566551
Validation loss: 3.1286434403084473

Epoch: 116| Step: 0
Training loss: 3.702704297082512
Validation loss: 3.1291289749607474

Epoch: 5| Step: 1
Training loss: 2.5146129776019257
Validation loss: 3.1289642719020536

Epoch: 5| Step: 2
Training loss: 4.2695620745971
Validation loss: 3.1273495256594006

Epoch: 5| Step: 3
Training loss: 2.6868112258104158
Validation loss: 3.12557467683277

Epoch: 5| Step: 4
Training loss: 3.5199552866956867
Validation loss: 3.1286524374134994

Epoch: 5| Step: 5
Training loss: 2.7117464908729425
Validation loss: 3.127121249291762

Epoch: 5| Step: 6
Training loss: 3.328570412215236
Validation loss: 3.1266774275726807

Epoch: 5| Step: 7
Training loss: 3.4810000098715292
Validation loss: 3.125266213511749

Epoch: 5| Step: 8
Training loss: 3.253512758273665
Validation loss: 3.1262179530014724

Epoch: 5| Step: 9
Training loss: 3.6860255510228046
Validation loss: 3.1246392318688394

Epoch: 5| Step: 10
Training loss: 3.6110950681541962
Validation loss: 3.1256391860114374

Epoch: 117| Step: 0
Training loss: 2.8875788954488164
Validation loss: 3.1247878841480197

Epoch: 5| Step: 1
Training loss: 2.9741459045227017
Validation loss: 3.125005543201411

Epoch: 5| Step: 2
Training loss: 3.777051249622243
Validation loss: 3.12646629183547

Epoch: 5| Step: 3
Training loss: 3.138595152832909
Validation loss: 3.1265036995210256

Epoch: 5| Step: 4
Training loss: 3.687942090446621
Validation loss: 3.1295308957012553

Epoch: 5| Step: 5
Training loss: 3.4163955642948314
Validation loss: 3.137290570951262

Epoch: 5| Step: 6
Training loss: 3.4044757386764877
Validation loss: 3.135221620319453

Epoch: 5| Step: 7
Training loss: 2.8514849090471155
Validation loss: 3.1331087911899367

Epoch: 5| Step: 8
Training loss: 3.8522959662688114
Validation loss: 3.1274811941990874

Epoch: 5| Step: 9
Training loss: 3.0415822544316686
Validation loss: 3.126061908409145

Epoch: 5| Step: 10
Training loss: 3.961804176632709
Validation loss: 3.1276236613745994

Epoch: 118| Step: 0
Training loss: 3.258224351496167
Validation loss: 3.123310710479089

Epoch: 5| Step: 1
Training loss: 3.199003815563105
Validation loss: 3.1243073612600356

Epoch: 5| Step: 2
Training loss: 3.4853313142974462
Validation loss: 3.12150877165439

Epoch: 5| Step: 3
Training loss: 3.036918923640717
Validation loss: 3.1240979785805134

Epoch: 5| Step: 4
Training loss: 3.6867768176582993
Validation loss: 3.121427032439939

Epoch: 5| Step: 5
Training loss: 2.7915457134709345
Validation loss: 3.121160255738083

Epoch: 5| Step: 6
Training loss: 3.73846454230801
Validation loss: 3.124082918858743

Epoch: 5| Step: 7
Training loss: 3.587144436644639
Validation loss: 3.120672444524774

Epoch: 5| Step: 8
Training loss: 3.1739233759745393
Validation loss: 3.120581796964506

Epoch: 5| Step: 9
Training loss: 3.6206438922965374
Validation loss: 3.121815002213712

Epoch: 5| Step: 10
Training loss: 3.4303903750156484
Validation loss: 3.1205416100940377

Epoch: 119| Step: 0
Training loss: 3.2523762745528715
Validation loss: 3.119680780930069

Epoch: 5| Step: 1
Training loss: 3.1708073063975677
Validation loss: 3.1184873122059433

Epoch: 5| Step: 2
Training loss: 2.7931117307971323
Validation loss: 3.1215352825420264

Epoch: 5| Step: 3
Training loss: 2.7222549821435127
Validation loss: 3.1199905836364494

Epoch: 5| Step: 4
Training loss: 3.5910086085727033
Validation loss: 3.119541740332557

Epoch: 5| Step: 5
Training loss: 4.005757479810847
Validation loss: 3.120601511895129

Epoch: 5| Step: 6
Training loss: 3.811507549247887
Validation loss: 3.118756903585805

Epoch: 5| Step: 7
Training loss: 3.683894447521003
Validation loss: 3.121343760955095

Epoch: 5| Step: 8
Training loss: 3.386528106568311
Validation loss: 3.120268612061563

Epoch: 5| Step: 9
Training loss: 3.3761663893876093
Validation loss: 3.1184799332227167

Epoch: 5| Step: 10
Training loss: 3.012273161012729
Validation loss: 3.1168773166901684

Epoch: 120| Step: 0
Training loss: 3.2663723761155405
Validation loss: 3.1202732377165545

Epoch: 5| Step: 1
Training loss: 2.066856292003199
Validation loss: 3.120496304459923

Epoch: 5| Step: 2
Training loss: 3.5200434744924523
Validation loss: 3.1199921990631787

Epoch: 5| Step: 3
Training loss: 3.993577927776315
Validation loss: 3.1162125828571403

Epoch: 5| Step: 4
Training loss: 3.0204094600359093
Validation loss: 3.1193064023380064

Epoch: 5| Step: 5
Training loss: 3.418544315378412
Validation loss: 3.116935748393566

Epoch: 5| Step: 6
Training loss: 3.658229715766946
Validation loss: 3.117719684357588

Epoch: 5| Step: 7
Training loss: 3.328546774917321
Validation loss: 3.1150331209798363

Epoch: 5| Step: 8
Training loss: 3.293097044412888
Validation loss: 3.1166957504664103

Epoch: 5| Step: 9
Training loss: 3.6206477115813676
Validation loss: 3.117431004429273

Epoch: 5| Step: 10
Training loss: 3.5524397565873134
Validation loss: 3.1155251987690216

Epoch: 121| Step: 0
Training loss: 3.8425462279954714
Validation loss: 3.11672162122733

Epoch: 5| Step: 1
Training loss: 3.530292077232949
Validation loss: 3.115617211245797

Epoch: 5| Step: 2
Training loss: 3.518627190352439
Validation loss: 3.1163111340520913

Epoch: 5| Step: 3
Training loss: 3.545647900428563
Validation loss: 3.1165118218540266

Epoch: 5| Step: 4
Training loss: 3.6191987281577847
Validation loss: 3.1163417768783153

Epoch: 5| Step: 5
Training loss: 2.7267094001437027
Validation loss: 3.1183737729100263

Epoch: 5| Step: 6
Training loss: 2.4399165376865795
Validation loss: 3.1148374983803047

Epoch: 5| Step: 7
Training loss: 3.280878681789618
Validation loss: 3.119292313940989

Epoch: 5| Step: 8
Training loss: 3.622505513589163
Validation loss: 3.1209765434114534

Epoch: 5| Step: 9
Training loss: 3.1402785076860558
Validation loss: 3.123522259372496

Epoch: 5| Step: 10
Training loss: 3.552472642314033
Validation loss: 3.1265744023133073

Epoch: 122| Step: 0
Training loss: 3.073982665946897
Validation loss: 3.117539826652109

Epoch: 5| Step: 1
Training loss: 3.0246040400354928
Validation loss: 3.120569161861386

Epoch: 5| Step: 2
Training loss: 3.2953733667402094
Validation loss: 3.114508293999199

Epoch: 5| Step: 3
Training loss: 2.596156187681354
Validation loss: 3.1156690724938976

Epoch: 5| Step: 4
Training loss: 3.7724159390113305
Validation loss: 3.114588047547654

Epoch: 5| Step: 5
Training loss: 3.372683259751124
Validation loss: 3.112308895014633

Epoch: 5| Step: 6
Training loss: 4.002477593820868
Validation loss: 3.112554481939824

Epoch: 5| Step: 7
Training loss: 3.479780101186324
Validation loss: 3.113738509488791

Epoch: 5| Step: 8
Training loss: 3.276978973712348
Validation loss: 3.110823437127755

Epoch: 5| Step: 9
Training loss: 3.2672449501857312
Validation loss: 3.1117354410278573

Epoch: 5| Step: 10
Training loss: 3.6735002532622443
Validation loss: 3.1137444490003614

Epoch: 123| Step: 0
Training loss: 3.4672814087014143
Validation loss: 3.112695530459603

Epoch: 5| Step: 1
Training loss: 3.6505067499670747
Validation loss: 3.1157153311957178

Epoch: 5| Step: 2
Training loss: 4.100667685129726
Validation loss: 3.1114533807306626

Epoch: 5| Step: 3
Training loss: 3.556160087320366
Validation loss: 3.1108806903708732

Epoch: 5| Step: 4
Training loss: 3.4478809704426183
Validation loss: 3.1114370617975573

Epoch: 5| Step: 5
Training loss: 2.477523280399083
Validation loss: 3.111984579286087

Epoch: 5| Step: 6
Training loss: 3.0080521921540284
Validation loss: 3.1141276116525636

Epoch: 5| Step: 7
Training loss: 3.3421270406924886
Validation loss: 3.1101416886911126

Epoch: 5| Step: 8
Training loss: 3.7836032827140262
Validation loss: 3.1079649139264993

Epoch: 5| Step: 9
Training loss: 2.9695049731329672
Validation loss: 3.111548495353636

Epoch: 5| Step: 10
Training loss: 2.782823781714042
Validation loss: 3.1101644421487764

Epoch: 124| Step: 0
Training loss: 3.3931814655377406
Validation loss: 3.1101147179953377

Epoch: 5| Step: 1
Training loss: 3.382615997738907
Validation loss: 3.111204227127333

Epoch: 5| Step: 2
Training loss: 3.828808781804345
Validation loss: 3.107955431304101

Epoch: 5| Step: 3
Training loss: 3.353441400878503
Validation loss: 3.1113519705967048

Epoch: 5| Step: 4
Training loss: 2.7259258412316596
Validation loss: 3.1094607636497638

Epoch: 5| Step: 5
Training loss: 3.0952445379476603
Validation loss: 3.112999405528834

Epoch: 5| Step: 6
Training loss: 3.473925055135227
Validation loss: 3.111517553202833

Epoch: 5| Step: 7
Training loss: 2.9893193853916675
Validation loss: 3.1106290794198004

Epoch: 5| Step: 8
Training loss: 4.012954239372151
Validation loss: 3.1091669319838235

Epoch: 5| Step: 9
Training loss: 3.6900415229011805
Validation loss: 3.1101881441770622

Epoch: 5| Step: 10
Training loss: 2.6607732519416776
Validation loss: 3.107037847435599

Epoch: 125| Step: 0
Training loss: 3.432774989704954
Validation loss: 3.107581154760646

Epoch: 5| Step: 1
Training loss: 2.9420794239746653
Validation loss: 3.108212661930093

Epoch: 5| Step: 2
Training loss: 3.5877142599634406
Validation loss: 3.108707609678589

Epoch: 5| Step: 3
Training loss: 3.8888247817674397
Validation loss: 3.108228474049455

Epoch: 5| Step: 4
Training loss: 3.634078004334711
Validation loss: 3.1057058893780143

Epoch: 5| Step: 5
Training loss: 2.8450527351198245
Validation loss: 3.107709044551048

Epoch: 5| Step: 6
Training loss: 3.343473619108547
Validation loss: 3.1060820690223205

Epoch: 5| Step: 7
Training loss: 2.8497502669290697
Validation loss: 3.106956901672438

Epoch: 5| Step: 8
Training loss: 3.275548722984518
Validation loss: 3.1150206378448058

Epoch: 5| Step: 9
Training loss: 3.7254533376632106
Validation loss: 3.1080247801486784

Epoch: 5| Step: 10
Training loss: 3.2540995344660866
Validation loss: 3.106682778383181

Epoch: 126| Step: 0
Training loss: 3.340851284888218
Validation loss: 3.107894189495836

Epoch: 5| Step: 1
Training loss: 3.357325438778266
Validation loss: 3.110271016192291

Epoch: 5| Step: 2
Training loss: 3.145728675836099
Validation loss: 3.1058592150664803

Epoch: 5| Step: 3
Training loss: 3.4024523642160336
Validation loss: 3.105992497847329

Epoch: 5| Step: 4
Training loss: 3.930188732905498
Validation loss: 3.1068281310026475

Epoch: 5| Step: 5
Training loss: 3.137670237265584
Validation loss: 3.1092480230435364

Epoch: 5| Step: 6
Training loss: 3.4438247755624607
Validation loss: 3.103572206849978

Epoch: 5| Step: 7
Training loss: 3.8558384062040645
Validation loss: 3.104495738370082

Epoch: 5| Step: 8
Training loss: 2.9519600967460184
Validation loss: 3.105358646190305

Epoch: 5| Step: 9
Training loss: 2.9810025798245143
Validation loss: 3.1050322562488413

Epoch: 5| Step: 10
Training loss: 3.2175818240084357
Validation loss: 3.1049758909060734

Epoch: 127| Step: 0
Training loss: 4.087872894729824
Validation loss: 3.104410332625304

Epoch: 5| Step: 1
Training loss: 2.558576138268346
Validation loss: 3.105589493823829

Epoch: 5| Step: 2
Training loss: 3.885996689171198
Validation loss: 3.1043265935302213

Epoch: 5| Step: 3
Training loss: 3.3830770693036456
Validation loss: 3.1035342191960043

Epoch: 5| Step: 4
Training loss: 3.708056807476874
Validation loss: 3.1030452910898467

Epoch: 5| Step: 5
Training loss: 3.155307440189348
Validation loss: 3.103963873521793

Epoch: 5| Step: 6
Training loss: 2.960776291940262
Validation loss: 3.10363164897938

Epoch: 5| Step: 7
Training loss: 3.144732924918646
Validation loss: 3.1039390419943818

Epoch: 5| Step: 8
Training loss: 3.292041869850923
Validation loss: 3.102978346698662

Epoch: 5| Step: 9
Training loss: 2.5973516988411762
Validation loss: 3.102337474943033

Epoch: 5| Step: 10
Training loss: 3.8176157663875117
Validation loss: 3.1040966876419303

Epoch: 128| Step: 0
Training loss: 3.5351879476738457
Validation loss: 3.1035514222387715

Epoch: 5| Step: 1
Training loss: 3.9083968709784602
Validation loss: 3.1016055975863535

Epoch: 5| Step: 2
Training loss: 3.8831815179665568
Validation loss: 3.1001750479162773

Epoch: 5| Step: 3
Training loss: 3.440686500269917
Validation loss: 3.1032054613477604

Epoch: 5| Step: 4
Training loss: 3.5347200071822953
Validation loss: 3.106318937097766

Epoch: 5| Step: 5
Training loss: 2.761667901289976
Validation loss: 3.111590172638513

Epoch: 5| Step: 6
Training loss: 3.740137354934556
Validation loss: 3.1045285267473623

Epoch: 5| Step: 7
Training loss: 3.1271338234895234
Validation loss: 3.106483026882218

Epoch: 5| Step: 8
Training loss: 2.8164688082240454
Validation loss: 3.112675913704778

Epoch: 5| Step: 9
Training loss: 3.2917452130825016
Validation loss: 3.1089063820909257

Epoch: 5| Step: 10
Training loss: 2.3914741553828796
Validation loss: 3.1009791106496896

Epoch: 129| Step: 0
Training loss: 4.20595049989226
Validation loss: 3.1010408726127645

Epoch: 5| Step: 1
Training loss: 3.22122808079632
Validation loss: 3.0987638546744307

Epoch: 5| Step: 2
Training loss: 3.094668165422126
Validation loss: 3.099023374497291

Epoch: 5| Step: 3
Training loss: 2.8126844557568575
Validation loss: 3.100026702302748

Epoch: 5| Step: 4
Training loss: 3.9015522288720805
Validation loss: 3.10121537814983

Epoch: 5| Step: 5
Training loss: 3.0003493423512304
Validation loss: 3.1016142375302134

Epoch: 5| Step: 6
Training loss: 3.313278682521553
Validation loss: 3.0994270900156917

Epoch: 5| Step: 7
Training loss: 3.4650276075091786
Validation loss: 3.0979385949731824

Epoch: 5| Step: 8
Training loss: 3.4801877440310047
Validation loss: 3.095913730842113

Epoch: 5| Step: 9
Training loss: 3.101597245259571
Validation loss: 3.096661406474733

Epoch: 5| Step: 10
Training loss: 2.964535100298338
Validation loss: 3.0982753024033727

Epoch: 130| Step: 0
Training loss: 3.511007166851642
Validation loss: 3.1003722538630565

Epoch: 5| Step: 1
Training loss: 3.546287992191211
Validation loss: 3.094840833481631

Epoch: 5| Step: 2
Training loss: 2.451707564098622
Validation loss: 3.096185888879672

Epoch: 5| Step: 3
Training loss: 3.981032581471029
Validation loss: 3.0960430457199686

Epoch: 5| Step: 4
Training loss: 3.6642740997835745
Validation loss: 3.0955612517072093

Epoch: 5| Step: 5
Training loss: 3.7096777775511494
Validation loss: 3.0958432759866303

Epoch: 5| Step: 6
Training loss: 3.225819647669719
Validation loss: 3.095720043623314

Epoch: 5| Step: 7
Training loss: 3.311186764071163
Validation loss: 3.096748737507024

Epoch: 5| Step: 8
Training loss: 3.2308244613146506
Validation loss: 3.096640138358705

Epoch: 5| Step: 9
Training loss: 3.2963152224901835
Validation loss: 3.098354868954977

Epoch: 5| Step: 10
Training loss: 2.476516001171573
Validation loss: 3.096069758931808

Epoch: 131| Step: 0
Training loss: 4.074254095229594
Validation loss: 3.0961651697766963

Epoch: 5| Step: 1
Training loss: 4.042847503465756
Validation loss: 3.097758747376799

Epoch: 5| Step: 2
Training loss: 3.007539811096776
Validation loss: 3.0952834075420093

Epoch: 5| Step: 3
Training loss: 3.2080353107173822
Validation loss: 3.093944161873782

Epoch: 5| Step: 4
Training loss: 3.3131192186381067
Validation loss: 3.094943301505386

Epoch: 5| Step: 5
Training loss: 3.128983666918349
Validation loss: 3.0945223195114986

Epoch: 5| Step: 6
Training loss: 2.9786294483886553
Validation loss: 3.09393898146527

Epoch: 5| Step: 7
Training loss: 2.9116210528074165
Validation loss: 3.091130758484904

Epoch: 5| Step: 8
Training loss: 3.269795506233974
Validation loss: 3.094198487556535

Epoch: 5| Step: 9
Training loss: 3.180375158384823
Validation loss: 3.093640198410679

Epoch: 5| Step: 10
Training loss: 3.5304012122450597
Validation loss: 3.0916070842869625

Epoch: 132| Step: 0
Training loss: 3.764794222412345
Validation loss: 3.0905745289411906

Epoch: 5| Step: 1
Training loss: 3.2977147772935687
Validation loss: 3.090964278669233

Epoch: 5| Step: 2
Training loss: 3.1416290348406366
Validation loss: 3.0916530661790587

Epoch: 5| Step: 3
Training loss: 2.885810760870954
Validation loss: 3.0916988251613438

Epoch: 5| Step: 4
Training loss: 3.6012803502973756
Validation loss: 3.0937483087217883

Epoch: 5| Step: 5
Training loss: 3.9387285041767295
Validation loss: 3.090199089699955

Epoch: 5| Step: 6
Training loss: 3.0057816424118955
Validation loss: 3.0895010221119064

Epoch: 5| Step: 7
Training loss: 3.316807231767852
Validation loss: 3.0912478062695588

Epoch: 5| Step: 8
Training loss: 3.3406216256505554
Validation loss: 3.0893867594158646

Epoch: 5| Step: 9
Training loss: 3.322003533073811
Validation loss: 3.0921821719257623

Epoch: 5| Step: 10
Training loss: 2.997082881459878
Validation loss: 3.091727009584519

Epoch: 133| Step: 0
Training loss: 3.212906950471441
Validation loss: 3.0903627446090995

Epoch: 5| Step: 1
Training loss: 3.391969616331018
Validation loss: 3.0922918047616785

Epoch: 5| Step: 2
Training loss: 3.7276334683159082
Validation loss: 3.091404336884171

Epoch: 5| Step: 3
Training loss: 3.5907861844397364
Validation loss: 3.094096653570792

Epoch: 5| Step: 4
Training loss: 2.526263564808105
Validation loss: 3.0930964945091235

Epoch: 5| Step: 5
Training loss: 4.37086923958449
Validation loss: 3.0967315554514196

Epoch: 5| Step: 6
Training loss: 3.409959505573472
Validation loss: 3.095428596441249

Epoch: 5| Step: 7
Training loss: 2.298334605120039
Validation loss: 3.0919678461552356

Epoch: 5| Step: 8
Training loss: 3.266606963513846
Validation loss: 3.088341808771546

Epoch: 5| Step: 9
Training loss: 3.1287683273187095
Validation loss: 3.090425360805982

Epoch: 5| Step: 10
Training loss: 3.4185200448256845
Validation loss: 3.092334815175837

Epoch: 134| Step: 0
Training loss: 3.138551397569125
Validation loss: 3.088870983741259

Epoch: 5| Step: 1
Training loss: 4.050657882945432
Validation loss: 3.0910347211555878

Epoch: 5| Step: 2
Training loss: 2.737690773504522
Validation loss: 3.087720382893871

Epoch: 5| Step: 3
Training loss: 3.336830180528599
Validation loss: 3.0874594006661673

Epoch: 5| Step: 4
Training loss: 3.5372905547882465
Validation loss: 3.088335730754161

Epoch: 5| Step: 5
Training loss: 3.0925899604165186
Validation loss: 3.0871478123624345

Epoch: 5| Step: 6
Training loss: 2.84100678986836
Validation loss: 3.0907200203310223

Epoch: 5| Step: 7
Training loss: 2.740029553720403
Validation loss: 3.0864453086007715

Epoch: 5| Step: 8
Training loss: 3.9161605237375885
Validation loss: 3.0860263573348754

Epoch: 5| Step: 9
Training loss: 4.076281368318577
Validation loss: 3.089037489231299

Epoch: 5| Step: 10
Training loss: 2.822252530922263
Validation loss: 3.0895525882233854

Epoch: 135| Step: 0
Training loss: 3.4839838603857958
Validation loss: 3.0874042631154817

Epoch: 5| Step: 1
Training loss: 2.8992862743921832
Validation loss: 3.088837380951266

Epoch: 5| Step: 2
Training loss: 3.1902711079830883
Validation loss: 3.088223653024391

Epoch: 5| Step: 3
Training loss: 4.025667568787772
Validation loss: 3.0878183116505067

Epoch: 5| Step: 4
Training loss: 3.1825828772793887
Validation loss: 3.0861625816719482

Epoch: 5| Step: 5
Training loss: 2.863209638962105
Validation loss: 3.0868113910613078

Epoch: 5| Step: 6
Training loss: 3.0316010891234058
Validation loss: 3.087194832253755

Epoch: 5| Step: 7
Training loss: 3.8411860404631186
Validation loss: 3.085885900063699

Epoch: 5| Step: 8
Training loss: 3.49029435083297
Validation loss: 3.087330845601552

Epoch: 5| Step: 9
Training loss: 3.3630624804084963
Validation loss: 3.0870396129047006

Epoch: 5| Step: 10
Training loss: 3.1415236975993235
Validation loss: 3.0850421122113185

Epoch: 136| Step: 0
Training loss: 3.853776214342173
Validation loss: 3.08476276959243

Epoch: 5| Step: 1
Training loss: 3.6078752316472626
Validation loss: 3.086055916066289

Epoch: 5| Step: 2
Training loss: 3.581803342667891
Validation loss: 3.083598165160965

Epoch: 5| Step: 3
Training loss: 2.921994783118759
Validation loss: 3.085418374221882

Epoch: 5| Step: 4
Training loss: 3.680502896362044
Validation loss: 3.0852980250600472

Epoch: 5| Step: 5
Training loss: 3.3889876248788564
Validation loss: 3.0849246893593882

Epoch: 5| Step: 6
Training loss: 3.425531532642479
Validation loss: 3.084741485925556

Epoch: 5| Step: 7
Training loss: 3.8348188148082336
Validation loss: 3.0858827747307256

Epoch: 5| Step: 8
Training loss: 2.6722030884376498
Validation loss: 3.0836623528183433

Epoch: 5| Step: 9
Training loss: 1.8784811764368736
Validation loss: 3.0816075423812777

Epoch: 5| Step: 10
Training loss: 3.3645296515718437
Validation loss: 3.083269036001492

Epoch: 137| Step: 0
Training loss: 4.104914692260645
Validation loss: 3.0851887394905657

Epoch: 5| Step: 1
Training loss: 3.1520843210027594
Validation loss: 3.0835264412079915

Epoch: 5| Step: 2
Training loss: 3.019700217115122
Validation loss: 3.083675761831776

Epoch: 5| Step: 3
Training loss: 2.527448837713298
Validation loss: 3.082859369270967

Epoch: 5| Step: 4
Training loss: 3.826507600364778
Validation loss: 3.0835067436412316

Epoch: 5| Step: 5
Training loss: 3.229345419253417
Validation loss: 3.0836665952572577

Epoch: 5| Step: 6
Training loss: 3.5145422052141364
Validation loss: 3.0836357682313844

Epoch: 5| Step: 7
Training loss: 3.458603185826509
Validation loss: 3.0835498366855996

Epoch: 5| Step: 8
Training loss: 3.879348406988624
Validation loss: 3.0810041141176803

Epoch: 5| Step: 9
Training loss: 2.5798102217376155
Validation loss: 3.0806559523462345

Epoch: 5| Step: 10
Training loss: 2.97781770127453
Validation loss: 3.0794259206001366

Epoch: 138| Step: 0
Training loss: 3.287701032750623
Validation loss: 3.0801491435489363

Epoch: 5| Step: 1
Training loss: 2.905027563125192
Validation loss: 3.0801957259536965

Epoch: 5| Step: 2
Training loss: 3.2015135642650105
Validation loss: 3.0804255265018634

Epoch: 5| Step: 3
Training loss: 3.209535612936552
Validation loss: 3.079186281076283

Epoch: 5| Step: 4
Training loss: 3.4363683051444114
Validation loss: 3.0792909267891377

Epoch: 5| Step: 5
Training loss: 3.2493201791901165
Validation loss: 3.0806355032758437

Epoch: 5| Step: 6
Training loss: 3.409966357560201
Validation loss: 3.079944819512888

Epoch: 5| Step: 7
Training loss: 3.8422295269057987
Validation loss: 3.080521415227027

Epoch: 5| Step: 8
Training loss: 3.296361367952161
Validation loss: 3.0827828281406786

Epoch: 5| Step: 9
Training loss: 3.2538234521559852
Validation loss: 3.0840415894989905

Epoch: 5| Step: 10
Training loss: 3.551262784060086
Validation loss: 3.080324080271593

Epoch: 139| Step: 0
Training loss: 4.104401221890812
Validation loss: 3.077901364540464

Epoch: 5| Step: 1
Training loss: 3.0069819901500763
Validation loss: 3.0796758271037215

Epoch: 5| Step: 2
Training loss: 3.4209562836334593
Validation loss: 3.079580175108261

Epoch: 5| Step: 3
Training loss: 3.886633606557991
Validation loss: 3.0762052286204904

Epoch: 5| Step: 4
Training loss: 3.584324027034097
Validation loss: 3.078969751766316

Epoch: 5| Step: 5
Training loss: 3.287594429081384
Validation loss: 3.0826231369436417

Epoch: 5| Step: 6
Training loss: 2.381882983404277
Validation loss: 3.077584794296313

Epoch: 5| Step: 7
Training loss: 3.211955482259916
Validation loss: 3.0773426088281246

Epoch: 5| Step: 8
Training loss: 3.425564523102859
Validation loss: 3.0807729337648753

Epoch: 5| Step: 9
Training loss: 2.9874272740661776
Validation loss: 3.080380866736566

Epoch: 5| Step: 10
Training loss: 3.0008400694533064
Validation loss: 3.0812785001138625

Epoch: 140| Step: 0
Training loss: 3.1291205133995605
Validation loss: 3.0812821209996377

Epoch: 5| Step: 1
Training loss: 2.9093180223697863
Validation loss: 3.080085168166236

Epoch: 5| Step: 2
Training loss: 2.917852233439686
Validation loss: 3.079716494784253

Epoch: 5| Step: 3
Training loss: 3.2796949789062833
Validation loss: 3.0800798362694772

Epoch: 5| Step: 4
Training loss: 4.225904713211315
Validation loss: 3.078396877776653

Epoch: 5| Step: 5
Training loss: 3.207594121680372
Validation loss: 3.079806701964099

Epoch: 5| Step: 6
Training loss: 3.3845382411541696
Validation loss: 3.085501877451015

Epoch: 5| Step: 7
Training loss: 3.793835589026296
Validation loss: 3.0811085682902686

Epoch: 5| Step: 8
Training loss: 3.2426176590112714
Validation loss: 3.0764260582668532

Epoch: 5| Step: 9
Training loss: 3.021804092348506
Validation loss: 3.075222174295556

Epoch: 5| Step: 10
Training loss: 3.3099666480836
Validation loss: 3.074350758592553

Epoch: 141| Step: 0
Training loss: 2.8528942603978056
Validation loss: 3.0724634942133258

Epoch: 5| Step: 1
Training loss: 3.3882950191204837
Validation loss: 3.073278082104331

Epoch: 5| Step: 2
Training loss: 3.5620044564375077
Validation loss: 3.0757249039232404

Epoch: 5| Step: 3
Training loss: 3.1144047986832146
Validation loss: 3.072880770621539

Epoch: 5| Step: 4
Training loss: 3.403346652964782
Validation loss: 3.072744247802443

Epoch: 5| Step: 5
Training loss: 3.105890823567751
Validation loss: 3.074172365566496

Epoch: 5| Step: 6
Training loss: 3.194395945821244
Validation loss: 3.0750853369185163

Epoch: 5| Step: 7
Training loss: 3.4008401730228797
Validation loss: 3.073423284555559

Epoch: 5| Step: 8
Training loss: 3.820513573720159
Validation loss: 3.071982793102113

Epoch: 5| Step: 9
Training loss: 3.0041845066283335
Validation loss: 3.073631910564403

Epoch: 5| Step: 10
Training loss: 3.71744982646441
Validation loss: 3.071847629096575

Epoch: 142| Step: 0
Training loss: 3.1287779287630255
Validation loss: 3.0733364034775335

Epoch: 5| Step: 1
Training loss: 2.9686916947913513
Validation loss: 3.0728503309584037

Epoch: 5| Step: 2
Training loss: 3.6959176404785046
Validation loss: 3.0753576301322765

Epoch: 5| Step: 3
Training loss: 2.883654298355952
Validation loss: 3.073567375808327

Epoch: 5| Step: 4
Training loss: 2.705401217449177
Validation loss: 3.0731865604622035

Epoch: 5| Step: 5
Training loss: 4.553760048087901
Validation loss: 3.077208964897833

Epoch: 5| Step: 6
Training loss: 3.4014201788507785
Validation loss: 3.077350859538573

Epoch: 5| Step: 7
Training loss: 3.1906746407438566
Validation loss: 3.0723673640131137

Epoch: 5| Step: 8
Training loss: 2.578665566848841
Validation loss: 3.0736892635531365

Epoch: 5| Step: 9
Training loss: 3.760339977436966
Validation loss: 3.072235849308944

Epoch: 5| Step: 10
Training loss: 3.233658126039089
Validation loss: 3.0729467664064485

Epoch: 143| Step: 0
Training loss: 2.9125293451885548
Validation loss: 3.0764162509338764

Epoch: 5| Step: 1
Training loss: 3.247025228775365
Validation loss: 3.0795823711483705

Epoch: 5| Step: 2
Training loss: 3.810210619333803
Validation loss: 3.0718921425262766

Epoch: 5| Step: 3
Training loss: 3.200198441551339
Validation loss: 3.0721837880940375

Epoch: 5| Step: 4
Training loss: 3.3219910451549017
Validation loss: 3.069197494559921

Epoch: 5| Step: 5
Training loss: 3.6159932284502747
Validation loss: 3.070110185062181

Epoch: 5| Step: 6
Training loss: 3.005457206130758
Validation loss: 3.0676636533392503

Epoch: 5| Step: 7
Training loss: 3.6030503383553576
Validation loss: 3.0722940394334786

Epoch: 5| Step: 8
Training loss: 3.7174076254064707
Validation loss: 3.0779790248709875

Epoch: 5| Step: 9
Training loss: 2.9493303088379035
Validation loss: 3.0770780778606825

Epoch: 5| Step: 10
Training loss: 3.0449336200362804
Validation loss: 3.072834372665572

Epoch: 144| Step: 0
Training loss: 3.2558035751348453
Validation loss: 3.071525768408999

Epoch: 5| Step: 1
Training loss: 3.1958965336710548
Validation loss: 3.066964090935165

Epoch: 5| Step: 2
Training loss: 3.8562475961835347
Validation loss: 3.066728184039745

Epoch: 5| Step: 3
Training loss: 2.7040491894643797
Validation loss: 3.067528128530222

Epoch: 5| Step: 4
Training loss: 3.702176773417674
Validation loss: 3.066481494417994

Epoch: 5| Step: 5
Training loss: 3.3471454243975463
Validation loss: 3.0711141169889453

Epoch: 5| Step: 6
Training loss: 3.3640602264184
Validation loss: 3.067844396138946

Epoch: 5| Step: 7
Training loss: 3.3165488779695282
Validation loss: 3.0698630106130156

Epoch: 5| Step: 8
Training loss: 3.3431656941925096
Validation loss: 3.0669317351845846

Epoch: 5| Step: 9
Training loss: 3.27314294477624
Validation loss: 3.0709602236127904

Epoch: 5| Step: 10
Training loss: 3.045118559234586
Validation loss: 3.065884067981566

Epoch: 145| Step: 0
Training loss: 3.800034452583333
Validation loss: 3.0706796216582926

Epoch: 5| Step: 1
Training loss: 3.362256610669568
Validation loss: 3.067717595504873

Epoch: 5| Step: 2
Training loss: 3.181973621980774
Validation loss: 3.0680159500507935

Epoch: 5| Step: 3
Training loss: 2.125366515920454
Validation loss: 3.06968294621872

Epoch: 5| Step: 4
Training loss: 3.265253219248919
Validation loss: 3.0704453595169827

Epoch: 5| Step: 5
Training loss: 3.035933033090271
Validation loss: 3.0750903673463736

Epoch: 5| Step: 6
Training loss: 3.3448290643509067
Validation loss: 3.069223282899903

Epoch: 5| Step: 7
Training loss: 2.981989841108716
Validation loss: 3.067474815695243

Epoch: 5| Step: 8
Training loss: 3.8294118781265127
Validation loss: 3.0642205487087457

Epoch: 5| Step: 9
Training loss: 3.921998770535134
Validation loss: 3.062648608026073

Epoch: 5| Step: 10
Training loss: 3.315566029505113
Validation loss: 3.062814692589036

Epoch: 146| Step: 0
Training loss: 3.3133473302237246
Validation loss: 3.062719590445038

Epoch: 5| Step: 1
Training loss: 3.497926779197145
Validation loss: 3.0619929925500777

Epoch: 5| Step: 2
Training loss: 3.346227850799729
Validation loss: 3.0631570418853995

Epoch: 5| Step: 3
Training loss: 3.285122865559413
Validation loss: 3.062537842031856

Epoch: 5| Step: 4
Training loss: 3.4944288327896507
Validation loss: 3.0622321022762695

Epoch: 5| Step: 5
Training loss: 3.673792042369989
Validation loss: 3.062585460750364

Epoch: 5| Step: 6
Training loss: 3.0920817183124654
Validation loss: 3.0621692452910296

Epoch: 5| Step: 7
Training loss: 2.886834375855852
Validation loss: 3.063625972507308

Epoch: 5| Step: 8
Training loss: 3.0493223094043143
Validation loss: 3.0627790788066567

Epoch: 5| Step: 9
Training loss: 3.500339082913759
Validation loss: 3.0651033798967986

Epoch: 5| Step: 10
Training loss: 3.3490632526738215
Validation loss: 3.0621268283826257

Epoch: 147| Step: 0
Training loss: 3.4780186721712933
Validation loss: 3.0633006803996

Epoch: 5| Step: 1
Training loss: 3.16876444013868
Validation loss: 3.0607605289114774

Epoch: 5| Step: 2
Training loss: 3.2359823020290777
Validation loss: 3.0617200349186584

Epoch: 5| Step: 3
Training loss: 2.634792409750808
Validation loss: 3.0611470716196614

Epoch: 5| Step: 4
Training loss: 3.414370594919105
Validation loss: 3.0599892147200407

Epoch: 5| Step: 5
Training loss: 2.528665141154053
Validation loss: 3.059571986641159

Epoch: 5| Step: 6
Training loss: 3.623843699227811
Validation loss: 3.0608912736450065

Epoch: 5| Step: 7
Training loss: 3.819648045209142
Validation loss: 3.0614408394727812

Epoch: 5| Step: 8
Training loss: 3.3979046984909473
Validation loss: 3.0627326600710005

Epoch: 5| Step: 9
Training loss: 2.968654751504521
Validation loss: 3.061558176607563

Epoch: 5| Step: 10
Training loss: 4.061718205273814
Validation loss: 3.0607569549432183

Epoch: 148| Step: 0
Training loss: 3.23637512578084
Validation loss: 3.066463764049205

Epoch: 5| Step: 1
Training loss: 3.5228850276224852
Validation loss: 3.0636805221432803

Epoch: 5| Step: 2
Training loss: 3.0292436704507315
Validation loss: 3.0702529922751687

Epoch: 5| Step: 3
Training loss: 2.6878999811649127
Validation loss: 3.066699519077298

Epoch: 5| Step: 4
Training loss: 3.7105404290033754
Validation loss: 3.0716411470476355

Epoch: 5| Step: 5
Training loss: 3.394861483999669
Validation loss: 3.0624766362504263

Epoch: 5| Step: 6
Training loss: 2.7258689020025413
Validation loss: 3.0611497079965018

Epoch: 5| Step: 7
Training loss: 3.5368659000444818
Validation loss: 3.0600381917659254

Epoch: 5| Step: 8
Training loss: 3.186127310987634
Validation loss: 3.056502231061111

Epoch: 5| Step: 9
Training loss: 3.350690394757623
Validation loss: 3.057872568539297

Epoch: 5| Step: 10
Training loss: 4.011834043575142
Validation loss: 3.0581450681659454

Epoch: 149| Step: 0
Training loss: 3.973789889797501
Validation loss: 3.0579808761489207

Epoch: 5| Step: 1
Training loss: 2.9362728721146816
Validation loss: 3.0627341935344106

Epoch: 5| Step: 2
Training loss: 3.0020098311678165
Validation loss: 3.0628464774647544

Epoch: 5| Step: 3
Training loss: 3.258923238313197
Validation loss: 3.056965410640841

Epoch: 5| Step: 4
Training loss: 3.3092317112492733
Validation loss: 3.057745942949747

Epoch: 5| Step: 5
Training loss: 3.3382274620674033
Validation loss: 3.054683579030429

Epoch: 5| Step: 6
Training loss: 3.489544237211999
Validation loss: 3.0540855453908273

Epoch: 5| Step: 7
Training loss: 3.2644118104305733
Validation loss: 3.0530793022541016

Epoch: 5| Step: 8
Training loss: 2.8355378008512164
Validation loss: 3.05396914506032

Epoch: 5| Step: 9
Training loss: 3.475730127707601
Validation loss: 3.054671853018624

Epoch: 5| Step: 10
Training loss: 3.506215706995845
Validation loss: 3.0528201813490994

Epoch: 150| Step: 0
Training loss: 2.7162628197400376
Validation loss: 3.053738428182681

Epoch: 5| Step: 1
Training loss: 3.749247793413828
Validation loss: 3.0541397609487224

Epoch: 5| Step: 2
Training loss: 3.2136900304409215
Validation loss: 3.054765444171499

Epoch: 5| Step: 3
Training loss: 3.405054144967973
Validation loss: 3.054472154778729

Epoch: 5| Step: 4
Training loss: 3.5969513276036156
Validation loss: 3.05412081566359

Epoch: 5| Step: 5
Training loss: 3.7035205484950398
Validation loss: 3.051970930898531

Epoch: 5| Step: 6
Training loss: 3.383382630263109
Validation loss: 3.054035691376776

Epoch: 5| Step: 7
Training loss: 3.026818408299191
Validation loss: 3.0535308315593186

Epoch: 5| Step: 8
Training loss: 3.109947113617772
Validation loss: 3.055201774791989

Epoch: 5| Step: 9
Training loss: 3.4319727068796166
Validation loss: 3.0569308382238756

Epoch: 5| Step: 10
Training loss: 2.9051355665815812
Validation loss: 3.0590701875919852

Epoch: 151| Step: 0
Training loss: 3.062099508451383
Validation loss: 3.060524883484821

Epoch: 5| Step: 1
Training loss: 3.712803807013643
Validation loss: 3.0661422002359995

Epoch: 5| Step: 2
Training loss: 2.9844615983631777
Validation loss: 3.0615653209945446

Epoch: 5| Step: 3
Training loss: 3.7927628214727966
Validation loss: 3.0590703728000808

Epoch: 5| Step: 4
Training loss: 3.0707316415858013
Validation loss: 3.0561292917603553

Epoch: 5| Step: 5
Training loss: 3.0236612872908286
Validation loss: 3.053594727739592

Epoch: 5| Step: 6
Training loss: 3.6675808084916692
Validation loss: 3.052697802562666

Epoch: 5| Step: 7
Training loss: 3.026928209888266
Validation loss: 3.0551467800753698

Epoch: 5| Step: 8
Training loss: 3.42567045234881
Validation loss: 3.0515975562761226

Epoch: 5| Step: 9
Training loss: 3.2852678676880185
Validation loss: 3.051498787730465

Epoch: 5| Step: 10
Training loss: 3.274748400858946
Validation loss: 3.052116420462488

Epoch: 152| Step: 0
Training loss: 3.5693649269941092
Validation loss: 3.0527036739844133

Epoch: 5| Step: 1
Training loss: 3.337413595274102
Validation loss: 3.0498541744155503

Epoch: 5| Step: 2
Training loss: 3.545351348166469
Validation loss: 3.0519129513658276

Epoch: 5| Step: 3
Training loss: 2.9462568555063497
Validation loss: 3.0517003085980154

Epoch: 5| Step: 4
Training loss: 3.9307033674277077
Validation loss: 3.053096494021952

Epoch: 5| Step: 5
Training loss: 2.9630541319419663
Validation loss: 3.0534626840670342

Epoch: 5| Step: 6
Training loss: 4.187217589007683
Validation loss: 3.0522829672477703

Epoch: 5| Step: 7
Training loss: 3.005897606004843
Validation loss: 3.0511413381037586

Epoch: 5| Step: 8
Training loss: 3.080482780469094
Validation loss: 3.0481146769224434

Epoch: 5| Step: 9
Training loss: 2.475878792620077
Validation loss: 3.047602081420986

Epoch: 5| Step: 10
Training loss: 2.962219121953142
Validation loss: 3.051166806011792

Epoch: 153| Step: 0
Training loss: 3.7609574764721208
Validation loss: 3.0520379550518077

Epoch: 5| Step: 1
Training loss: 3.7444877801859513
Validation loss: 3.0603478809631057

Epoch: 5| Step: 2
Training loss: 2.7114980156645214
Validation loss: 3.0560445681962563

Epoch: 5| Step: 3
Training loss: 3.8642513958595957
Validation loss: 3.0522225889357095

Epoch: 5| Step: 4
Training loss: 2.6567963879678738
Validation loss: 3.0522777278894995

Epoch: 5| Step: 5
Training loss: 3.7706311138298894
Validation loss: 3.0468908233273773

Epoch: 5| Step: 6
Training loss: 3.374213374266744
Validation loss: 3.0477546274077674

Epoch: 5| Step: 7
Training loss: 3.17805877886623
Validation loss: 3.0455454695640642

Epoch: 5| Step: 8
Training loss: 2.9950366287666346
Validation loss: 3.0482643066847426

Epoch: 5| Step: 9
Training loss: 2.9820400510742537
Validation loss: 3.0479615887830263

Epoch: 5| Step: 10
Training loss: 3.0608216961408266
Validation loss: 3.045565129818038

Epoch: 154| Step: 0
Training loss: 3.182770754915397
Validation loss: 3.046913094988406

Epoch: 5| Step: 1
Training loss: 3.2662123740503928
Validation loss: 3.045548385444651

Epoch: 5| Step: 2
Training loss: 3.0474843516272707
Validation loss: 3.0449370281931665

Epoch: 5| Step: 3
Training loss: 3.8790714655146936
Validation loss: 3.045945154022293

Epoch: 5| Step: 4
Training loss: 3.050756398196233
Validation loss: 3.046975695405684

Epoch: 5| Step: 5
Training loss: 3.2529074062018357
Validation loss: 3.0446785699618006

Epoch: 5| Step: 6
Training loss: 3.2765910178759405
Validation loss: 3.05100804969936

Epoch: 5| Step: 7
Training loss: 3.1922050606295467
Validation loss: 3.048636313529282

Epoch: 5| Step: 8
Training loss: 3.390109115239865
Validation loss: 3.051677840854049

Epoch: 5| Step: 9
Training loss: 2.7296126391971254
Validation loss: 3.056756556259579

Epoch: 5| Step: 10
Training loss: 4.040877799425835
Validation loss: 3.0735030365472498

Epoch: 155| Step: 0
Training loss: 3.429625908161717
Validation loss: 3.058042745327527

Epoch: 5| Step: 1
Training loss: 2.8363974962680985
Validation loss: 3.0677772677325574

Epoch: 5| Step: 2
Training loss: 3.581343223862993
Validation loss: 3.0612772513201216

Epoch: 5| Step: 3
Training loss: 2.831829195378294
Validation loss: 3.062868402090411

Epoch: 5| Step: 4
Training loss: 2.9430248169081095
Validation loss: 3.0507838701249494

Epoch: 5| Step: 5
Training loss: 3.6920326952741944
Validation loss: 3.0466320444764596

Epoch: 5| Step: 6
Training loss: 3.204767317872944
Validation loss: 3.0433274383545337

Epoch: 5| Step: 7
Training loss: 3.4529653659014934
Validation loss: 3.0450611404301355

Epoch: 5| Step: 8
Training loss: 3.839076480677001
Validation loss: 3.0420479939305363

Epoch: 5| Step: 9
Training loss: 3.279591168301496
Validation loss: 3.042533330183812

Epoch: 5| Step: 10
Training loss: 3.06251136621974
Validation loss: 3.0431218635372526

Epoch: 156| Step: 0
Training loss: 3.301883599210362
Validation loss: 3.040607061051691

Epoch: 5| Step: 1
Training loss: 2.9709260695127124
Validation loss: 3.0402013109252395

Epoch: 5| Step: 2
Training loss: 3.6044634805227083
Validation loss: 3.042688541695046

Epoch: 5| Step: 3
Training loss: 2.5128391549383555
Validation loss: 3.0389014207533416

Epoch: 5| Step: 4
Training loss: 2.8295854201459165
Validation loss: 3.041140634044045

Epoch: 5| Step: 5
Training loss: 3.737663576763099
Validation loss: 3.0405063014400073

Epoch: 5| Step: 6
Training loss: 3.323583522040407
Validation loss: 3.037960163105562

Epoch: 5| Step: 7
Training loss: 3.594590196663008
Validation loss: 3.036671527878334

Epoch: 5| Step: 8
Training loss: 3.3718685174831973
Validation loss: 3.039014858563411

Epoch: 5| Step: 9
Training loss: 3.267937092692709
Validation loss: 3.0373559146954854

Epoch: 5| Step: 10
Training loss: 3.689997199246137
Validation loss: 3.0406842928749422

Epoch: 157| Step: 0
Training loss: 3.088276654989625
Validation loss: 3.0380866901999597

Epoch: 5| Step: 1
Training loss: 3.1840384143543985
Validation loss: 3.0377098443475092

Epoch: 5| Step: 2
Training loss: 3.334773483705013
Validation loss: 3.041538649385268

Epoch: 5| Step: 3
Training loss: 3.398112805519865
Validation loss: 3.0444285164561045

Epoch: 5| Step: 4
Training loss: 3.388211705516845
Validation loss: 3.0391294258632238

Epoch: 5| Step: 5
Training loss: 3.363050003165505
Validation loss: 3.0394261196913455

Epoch: 5| Step: 6
Training loss: 3.2077071003941344
Validation loss: 3.036680037676368

Epoch: 5| Step: 7
Training loss: 2.892858024206818
Validation loss: 3.0399117480401294

Epoch: 5| Step: 8
Training loss: 3.8984606174555685
Validation loss: 3.0378411583576153

Epoch: 5| Step: 9
Training loss: 3.483288514306756
Validation loss: 3.037428642801047

Epoch: 5| Step: 10
Training loss: 2.9143907295668097
Validation loss: 3.041392368069089

Epoch: 158| Step: 0
Training loss: 2.9182315079988674
Validation loss: 3.0386970229188326

Epoch: 5| Step: 1
Training loss: 3.2347161302026435
Validation loss: 3.0393221375960566

Epoch: 5| Step: 2
Training loss: 2.995301859423344
Validation loss: 3.0371604361988416

Epoch: 5| Step: 3
Training loss: 3.6464495910064323
Validation loss: 3.0390405335404713

Epoch: 5| Step: 4
Training loss: 3.0016689426626004
Validation loss: 3.0417863117397963

Epoch: 5| Step: 5
Training loss: 4.195725063731513
Validation loss: 3.0368119103267177

Epoch: 5| Step: 6
Training loss: 3.498575329333638
Validation loss: 3.0364873710198914

Epoch: 5| Step: 7
Training loss: 3.562168306669962
Validation loss: 3.037765152205013

Epoch: 5| Step: 8
Training loss: 3.7768233689347768
Validation loss: 3.0375439299244222

Epoch: 5| Step: 9
Training loss: 2.131737071115632
Validation loss: 3.0370414997207216

Epoch: 5| Step: 10
Training loss: 2.805205740905614
Validation loss: 3.038552007039174

Epoch: 159| Step: 0
Training loss: 2.861533595704958
Validation loss: 3.0382177600971874

Epoch: 5| Step: 1
Training loss: 2.7395531153493025
Validation loss: 3.041219104963135

Epoch: 5| Step: 2
Training loss: 3.929325762076624
Validation loss: 3.044572155258864

Epoch: 5| Step: 3
Training loss: 3.651857002993477
Validation loss: 3.0451951816217826

Epoch: 5| Step: 4
Training loss: 2.7526140793279312
Validation loss: 3.046310847967174

Epoch: 5| Step: 5
Training loss: 2.7713427732611384
Validation loss: 3.0437067842798338

Epoch: 5| Step: 6
Training loss: 3.7892111208368853
Validation loss: 3.0372503609760297

Epoch: 5| Step: 7
Training loss: 3.771322791156012
Validation loss: 3.0342076778974016

Epoch: 5| Step: 8
Training loss: 2.9443922957914617
Validation loss: 3.034605277907664

Epoch: 5| Step: 9
Training loss: 3.262607768533316
Validation loss: 3.0336877365899384

Epoch: 5| Step: 10
Training loss: 3.5035288595799616
Validation loss: 3.0325363959695335

Epoch: 160| Step: 0
Training loss: 3.3047525746677238
Validation loss: 3.0360473552813443

Epoch: 5| Step: 1
Training loss: 3.034656301830449
Validation loss: 3.0336300287531355

Epoch: 5| Step: 2
Training loss: 2.546337983788787
Validation loss: 3.033341922723057

Epoch: 5| Step: 3
Training loss: 3.13078048140228
Validation loss: 3.0378105709707888

Epoch: 5| Step: 4
Training loss: 3.699778271810229
Validation loss: 3.033004129722946

Epoch: 5| Step: 5
Training loss: 4.2621729929492735
Validation loss: 3.030054549972266

Epoch: 5| Step: 6
Training loss: 3.315504618768491
Validation loss: 3.035114845040655

Epoch: 5| Step: 7
Training loss: 3.9805239747533774
Validation loss: 3.034908398004763

Epoch: 5| Step: 8
Training loss: 3.081096937854131
Validation loss: 3.0354750813629843

Epoch: 5| Step: 9
Training loss: 3.0284961894167086
Validation loss: 3.0342628180897337

Epoch: 5| Step: 10
Training loss: 2.248620139969068
Validation loss: 3.0320405181952714

Epoch: 161| Step: 0
Training loss: 3.741281801975033
Validation loss: 3.032821537137556

Epoch: 5| Step: 1
Training loss: 2.9496507340912417
Validation loss: 3.0344712994890637

Epoch: 5| Step: 2
Training loss: 3.242011449239424
Validation loss: 3.0329079440483344

Epoch: 5| Step: 3
Training loss: 3.9620779829597246
Validation loss: 3.032063027455044

Epoch: 5| Step: 4
Training loss: 2.500092218605542
Validation loss: 3.0321017718732346

Epoch: 5| Step: 5
Training loss: 2.9593933427155608
Validation loss: 3.032043852065452

Epoch: 5| Step: 6
Training loss: 3.4392799624123467
Validation loss: 3.0326360399247685

Epoch: 5| Step: 7
Training loss: 2.989504893976325
Validation loss: 3.031567594862044

Epoch: 5| Step: 8
Training loss: 3.4096212240481334
Validation loss: 3.030441307395336

Epoch: 5| Step: 9
Training loss: 3.3836492688475786
Validation loss: 3.0330134181388537

Epoch: 5| Step: 10
Training loss: 3.4431071932878035
Validation loss: 3.032974770737267

Epoch: 162| Step: 0
Training loss: 2.711409997576404
Validation loss: 3.037934911062385

Epoch: 5| Step: 1
Training loss: 3.012827153466498
Validation loss: 3.037721760737365

Epoch: 5| Step: 2
Training loss: 3.8469589608494603
Validation loss: 3.0393089538043347

Epoch: 5| Step: 3
Training loss: 2.7337801040924523
Validation loss: 3.031533277405409

Epoch: 5| Step: 4
Training loss: 2.720550817647744
Validation loss: 3.027853755167629

Epoch: 5| Step: 5
Training loss: 3.279235221278676
Validation loss: 3.029096817389579

Epoch: 5| Step: 6
Training loss: 3.8438710759640227
Validation loss: 3.0316520722804006

Epoch: 5| Step: 7
Training loss: 3.701772579674286
Validation loss: 3.02910957675884

Epoch: 5| Step: 8
Training loss: 3.3142537207069296
Validation loss: 3.03116687643349

Epoch: 5| Step: 9
Training loss: 3.5480624324462124
Validation loss: 3.026972230362995

Epoch: 5| Step: 10
Training loss: 3.20012304546302
Validation loss: 3.03131963042857

Epoch: 163| Step: 0
Training loss: 3.8708353119931673
Validation loss: 3.0267977132322987

Epoch: 5| Step: 1
Training loss: 3.15363679480839
Validation loss: 3.0248461053059517

Epoch: 5| Step: 2
Training loss: 2.921244017660588
Validation loss: 3.026198202945194

Epoch: 5| Step: 3
Training loss: 3.863648184079943
Validation loss: 3.030172879121948

Epoch: 5| Step: 4
Training loss: 3.0574932042792615
Validation loss: 3.026949550277237

Epoch: 5| Step: 5
Training loss: 3.5447938165575015
Validation loss: 3.027990605279955

Epoch: 5| Step: 6
Training loss: 2.754064850264585
Validation loss: 3.0266394904753695

Epoch: 5| Step: 7
Training loss: 3.0794061618387256
Validation loss: 3.0257478318265894

Epoch: 5| Step: 8
Training loss: 2.9157255198332432
Validation loss: 3.025710360008343

Epoch: 5| Step: 9
Training loss: 3.1736258949994616
Validation loss: 3.0256487964619994

Epoch: 5| Step: 10
Training loss: 3.716956980589988
Validation loss: 3.026123835907848

Epoch: 164| Step: 0
Training loss: 3.4314135680965916
Validation loss: 3.025147493150353

Epoch: 5| Step: 1
Training loss: 3.5422555022575555
Validation loss: 3.024319229467729

Epoch: 5| Step: 2
Training loss: 4.22758654812064
Validation loss: 3.023875644067556

Epoch: 5| Step: 3
Training loss: 3.640078786060212
Validation loss: 3.0245114727194236

Epoch: 5| Step: 4
Training loss: 2.502616847889686
Validation loss: 3.0278628748061363

Epoch: 5| Step: 5
Training loss: 2.867185670607812
Validation loss: 3.0230126372421275

Epoch: 5| Step: 6
Training loss: 3.762076957974109
Validation loss: 3.0240676323713678

Epoch: 5| Step: 7
Training loss: 3.018916887997373
Validation loss: 3.0254765865915587

Epoch: 5| Step: 8
Training loss: 2.703321681281714
Validation loss: 3.0231947351340187

Epoch: 5| Step: 9
Training loss: 2.871363288527697
Validation loss: 3.0234283292804647

Epoch: 5| Step: 10
Training loss: 3.1951031231542952
Validation loss: 3.0269276187208467

Epoch: 165| Step: 0
Training loss: 3.3652795754273632
Validation loss: 3.028729719607257

Epoch: 5| Step: 1
Training loss: 3.3583853749927703
Validation loss: 3.030834312002234

Epoch: 5| Step: 2
Training loss: 3.2613577820003674
Validation loss: 3.028632390885792

Epoch: 5| Step: 3
Training loss: 2.898590495140786
Validation loss: 3.0259594500093563

Epoch: 5| Step: 4
Training loss: 3.198142293287275
Validation loss: 3.028670662005147

Epoch: 5| Step: 5
Training loss: 2.9354131875018656
Validation loss: 3.024217203246001

Epoch: 5| Step: 6
Training loss: 3.190419673758007
Validation loss: 3.03225533099216

Epoch: 5| Step: 7
Training loss: 3.81623332355153
Validation loss: 3.030137447699996

Epoch: 5| Step: 8
Training loss: 3.4016722269369457
Validation loss: 3.028486576477665

Epoch: 5| Step: 9
Training loss: 2.8924103043611247
Validation loss: 3.024524007318648

Epoch: 5| Step: 10
Training loss: 3.7654792472521765
Validation loss: 3.02302280015622

Epoch: 166| Step: 0
Training loss: 3.039833579025567
Validation loss: 3.024761766656228

Epoch: 5| Step: 1
Training loss: 3.4830571577719827
Validation loss: 3.0226478267204326

Epoch: 5| Step: 2
Training loss: 3.8578893605173756
Validation loss: 3.023225810436843

Epoch: 5| Step: 3
Training loss: 2.09468911588761
Validation loss: 3.0188256460131746

Epoch: 5| Step: 4
Training loss: 3.6577666959701567
Validation loss: 3.022467449945322

Epoch: 5| Step: 5
Training loss: 3.614876126057196
Validation loss: 3.0260606329942705

Epoch: 5| Step: 6
Training loss: 3.3652097199655455
Validation loss: 3.020389980643103

Epoch: 5| Step: 7
Training loss: 2.932489708039288
Validation loss: 3.0193432576665846

Epoch: 5| Step: 8
Training loss: 3.5749679030464736
Validation loss: 3.023881154760094

Epoch: 5| Step: 9
Training loss: 3.431495693839405
Validation loss: 3.0217493653513405

Epoch: 5| Step: 10
Training loss: 2.618922873824842
Validation loss: 3.023834670481908

Epoch: 167| Step: 0
Training loss: 3.58554852937884
Validation loss: 3.0226663789654786

Epoch: 5| Step: 1
Training loss: 3.102965837374791
Validation loss: 3.020298520031285

Epoch: 5| Step: 2
Training loss: 3.0644403655526276
Validation loss: 3.019210643250754

Epoch: 5| Step: 3
Training loss: 2.7749588353308527
Validation loss: 3.0209810423815133

Epoch: 5| Step: 4
Training loss: 3.361611265130393
Validation loss: 3.018849909768178

Epoch: 5| Step: 5
Training loss: 3.217427991462905
Validation loss: 3.0194818672313164

Epoch: 5| Step: 6
Training loss: 3.18334300920171
Validation loss: 3.0206825826934254

Epoch: 5| Step: 7
Training loss: 2.899982215563733
Validation loss: 3.0218715633219193

Epoch: 5| Step: 8
Training loss: 3.70944871451608
Validation loss: 3.021336090943816

Epoch: 5| Step: 9
Training loss: 3.8970670871456483
Validation loss: 3.024704636076712

Epoch: 5| Step: 10
Training loss: 3.128965379630115
Validation loss: 3.0363606109510624

Epoch: 168| Step: 0
Training loss: 2.9704260662427955
Validation loss: 3.0311671825987068

Epoch: 5| Step: 1
Training loss: 3.4501954507058423
Validation loss: 3.0416488998125693

Epoch: 5| Step: 2
Training loss: 3.3719799516835303
Validation loss: 3.026711130191916

Epoch: 5| Step: 3
Training loss: 2.6318918310681227
Validation loss: 3.0177811761883833

Epoch: 5| Step: 4
Training loss: 3.391751713041856
Validation loss: 3.017984801537941

Epoch: 5| Step: 5
Training loss: 3.1539615606409943
Validation loss: 3.0225322360525815

Epoch: 5| Step: 6
Training loss: 2.977570130413516
Validation loss: 3.017855626481746

Epoch: 5| Step: 7
Training loss: 3.678092076130722
Validation loss: 3.020551450404393

Epoch: 5| Step: 8
Training loss: 3.138698309530094
Validation loss: 3.020379272440587

Epoch: 5| Step: 9
Training loss: 3.359851608178476
Validation loss: 3.016797542050257

Epoch: 5| Step: 10
Training loss: 3.935166651530451
Validation loss: 3.014910204793736

Epoch: 169| Step: 0
Training loss: 3.082366654357416
Validation loss: 3.014469478558316

Epoch: 5| Step: 1
Training loss: 2.7628377889151703
Validation loss: 3.016946720477867

Epoch: 5| Step: 2
Training loss: 3.4726684707409405
Validation loss: 3.0173488635119177

Epoch: 5| Step: 3
Training loss: 3.6664011310027123
Validation loss: 3.0160780429341263

Epoch: 5| Step: 4
Training loss: 3.7248866633640314
Validation loss: 3.016920000073352

Epoch: 5| Step: 5
Training loss: 2.949521080840624
Validation loss: 3.0163220715655052

Epoch: 5| Step: 6
Training loss: 3.834422012202566
Validation loss: 3.014852591612759

Epoch: 5| Step: 7
Training loss: 3.335039433327676
Validation loss: 3.0152785769414105

Epoch: 5| Step: 8
Training loss: 3.381097301483228
Validation loss: 3.012753548970625

Epoch: 5| Step: 9
Training loss: 2.6946320932684875
Validation loss: 3.012046638108085

Epoch: 5| Step: 10
Training loss: 2.945085025978316
Validation loss: 3.0116131404653212

Epoch: 170| Step: 0
Training loss: 3.4965353574968443
Validation loss: 3.011036459306389

Epoch: 5| Step: 1
Training loss: 3.4776658953896153
Validation loss: 3.013203471536587

Epoch: 5| Step: 2
Training loss: 3.6170275922655675
Validation loss: 3.0149106546133666

Epoch: 5| Step: 3
Training loss: 3.108202382483495
Validation loss: 3.0140069183253444

Epoch: 5| Step: 4
Training loss: 3.500590547059399
Validation loss: 3.023606255606549

Epoch: 5| Step: 5
Training loss: 3.00737444177143
Validation loss: 3.014375433177184

Epoch: 5| Step: 6
Training loss: 2.860654284190032
Validation loss: 3.009835016538652

Epoch: 5| Step: 7
Training loss: 3.4971849837646487
Validation loss: 3.0103268535263035

Epoch: 5| Step: 8
Training loss: 3.3022420145088844
Validation loss: 3.012552408919777

Epoch: 5| Step: 9
Training loss: 2.963302432808466
Validation loss: 3.0089765333610843

Epoch: 5| Step: 10
Training loss: 3.105322876389181
Validation loss: 3.0089151872081095

Epoch: 171| Step: 0
Training loss: 3.350005813138103
Validation loss: 3.009218853859

Epoch: 5| Step: 1
Training loss: 2.907051878202141
Validation loss: 3.011759179358936

Epoch: 5| Step: 2
Training loss: 3.2742189189352886
Validation loss: 3.0111059356453453

Epoch: 5| Step: 3
Training loss: 3.2000466045323774
Validation loss: 3.0122649150314422

Epoch: 5| Step: 4
Training loss: 3.2743000359936483
Validation loss: 3.0109790444616396

Epoch: 5| Step: 5
Training loss: 2.583220469152514
Validation loss: 3.011066130110292

Epoch: 5| Step: 6
Training loss: 3.863149303192581
Validation loss: 3.011101590121965

Epoch: 5| Step: 7
Training loss: 3.6789302492199396
Validation loss: 3.0111114611940355

Epoch: 5| Step: 8
Training loss: 3.4217835853942367
Validation loss: 3.011750006702056

Epoch: 5| Step: 9
Training loss: 2.8379069233982257
Validation loss: 3.0120284443168472

Epoch: 5| Step: 10
Training loss: 3.4571751106631226
Validation loss: 3.0146893318466885

Epoch: 172| Step: 0
Training loss: 2.696634338886144
Validation loss: 3.0088455316260196

Epoch: 5| Step: 1
Training loss: 2.895382816389291
Validation loss: 3.0091171088211444

Epoch: 5| Step: 2
Training loss: 3.4552634681685923
Validation loss: 3.008708861312891

Epoch: 5| Step: 3
Training loss: 4.229875602245725
Validation loss: 3.006896777007558

Epoch: 5| Step: 4
Training loss: 3.0860070329389453
Validation loss: 3.0077085466643667

Epoch: 5| Step: 5
Training loss: 3.5121066650407324
Validation loss: 3.00718835353958

Epoch: 5| Step: 6
Training loss: 3.2226439689633417
Validation loss: 3.0066592812679933

Epoch: 5| Step: 7
Training loss: 3.2145620711672698
Validation loss: 3.0043022555826804

Epoch: 5| Step: 8
Training loss: 3.0341020518310344
Validation loss: 3.00506513286426

Epoch: 5| Step: 9
Training loss: 2.576787058134364
Validation loss: 3.0076143725562043

Epoch: 5| Step: 10
Training loss: 3.86336925317645
Validation loss: 3.005327877330638

Epoch: 173| Step: 0
Training loss: 4.079672333518582
Validation loss: 3.0111004918205877

Epoch: 5| Step: 1
Training loss: 3.382328976792615
Validation loss: 3.005155532642352

Epoch: 5| Step: 2
Training loss: 3.08129069396223
Validation loss: 3.0105545983726727

Epoch: 5| Step: 3
Training loss: 3.1340740451111326
Validation loss: 3.0079862043970493

Epoch: 5| Step: 4
Training loss: 3.4990712704744062
Validation loss: 3.01179495722056

Epoch: 5| Step: 5
Training loss: 3.077488867385524
Validation loss: 3.0097505996660288

Epoch: 5| Step: 6
Training loss: 2.815987861444581
Validation loss: 3.01049981589837

Epoch: 5| Step: 7
Training loss: 3.110275214918548
Validation loss: 3.0085399066133425

Epoch: 5| Step: 8
Training loss: 3.1066381016292564
Validation loss: 3.006154020742641

Epoch: 5| Step: 9
Training loss: 3.4259219689866622
Validation loss: 3.004513595811352

Epoch: 5| Step: 10
Training loss: 3.08997091038909
Validation loss: 3.007580920582715

Epoch: 174| Step: 0
Training loss: 3.57877180758383
Validation loss: 3.0065969140830435

Epoch: 5| Step: 1
Training loss: 3.352140078984
Validation loss: 3.0038151836237064

Epoch: 5| Step: 2
Training loss: 3.477990292307998
Validation loss: 3.00992257563162

Epoch: 5| Step: 3
Training loss: 3.6819475688526953
Validation loss: 3.0090394459065006

Epoch: 5| Step: 4
Training loss: 3.3215125933214185
Validation loss: 3.00533921922176

Epoch: 5| Step: 5
Training loss: 3.6497651325066025
Validation loss: 3.0049094974660226

Epoch: 5| Step: 6
Training loss: 2.5045997266328635
Validation loss: 3.003825445627346

Epoch: 5| Step: 7
Training loss: 3.0624070445375327
Validation loss: 3.003083519258956

Epoch: 5| Step: 8
Training loss: 2.910095787700348
Validation loss: 3.0048583182261055

Epoch: 5| Step: 9
Training loss: 3.014630405679794
Validation loss: 3.0037243389536523

Epoch: 5| Step: 10
Training loss: 3.22766065036673
Validation loss: 3.0041131907719296

Epoch: 175| Step: 0
Training loss: 3.559544458282307
Validation loss: 3.005120957076607

Epoch: 5| Step: 1
Training loss: 2.9931006569548533
Validation loss: 3.0056655920365483

Epoch: 5| Step: 2
Training loss: 2.7177012382893313
Validation loss: 3.0032285012701347

Epoch: 5| Step: 3
Training loss: 3.3766851103700395
Validation loss: 3.0059095342244584

Epoch: 5| Step: 4
Training loss: 3.592956189927628
Validation loss: 3.0055983069940853

Epoch: 5| Step: 5
Training loss: 3.382952046324259
Validation loss: 3.003040543524348

Epoch: 5| Step: 6
Training loss: 2.997546305167534
Validation loss: 3.0034804339540337

Epoch: 5| Step: 7
Training loss: 3.543498175283473
Validation loss: 3.0035956243335953

Epoch: 5| Step: 8
Training loss: 3.209596971303513
Validation loss: 3.0059072826550963

Epoch: 5| Step: 9
Training loss: 3.1522597971801845
Validation loss: 3.0093796000377715

Epoch: 5| Step: 10
Training loss: 3.397320162495584
Validation loss: 3.003914431022849

Epoch: 176| Step: 0
Training loss: 2.786080783447776
Validation loss: 3.001637212875453

Epoch: 5| Step: 1
Training loss: 3.2512473133725774
Validation loss: 3.0014822666666245

Epoch: 5| Step: 2
Training loss: 3.0144212919568547
Validation loss: 3.0025131976957877

Epoch: 5| Step: 3
Training loss: 3.0711713759248753
Validation loss: 3.0021816886697597

Epoch: 5| Step: 4
Training loss: 3.7996734227841227
Validation loss: 2.9990431291873207

Epoch: 5| Step: 5
Training loss: 3.3368633334507316
Validation loss: 3.000934882435989

Epoch: 5| Step: 6
Training loss: 2.635589041117459
Validation loss: 3.0030967784234757

Epoch: 5| Step: 7
Training loss: 3.5921227793195687
Validation loss: 3.00189568160685

Epoch: 5| Step: 8
Training loss: 3.174847792934455
Validation loss: 3.0025768160140194

Epoch: 5| Step: 9
Training loss: 3.309990129945912
Validation loss: 3.002753134425473

Epoch: 5| Step: 10
Training loss: 3.8528536785350003
Validation loss: 3.0005526170415084

Epoch: 177| Step: 0
Training loss: 2.957341972766132
Validation loss: 2.9990284159974943

Epoch: 5| Step: 1
Training loss: 3.351894833465002
Validation loss: 2.9989228451192327

Epoch: 5| Step: 2
Training loss: 3.0780187288325496
Validation loss: 2.998876933988804

Epoch: 5| Step: 3
Training loss: 3.4769846456307723
Validation loss: 2.9990377822863996

Epoch: 5| Step: 4
Training loss: 2.5982212914890677
Validation loss: 2.9990219791679533

Epoch: 5| Step: 5
Training loss: 3.1400574128557386
Validation loss: 2.9989839494474264

Epoch: 5| Step: 6
Training loss: 3.630759826247607
Validation loss: 3.001536556914416

Epoch: 5| Step: 7
Training loss: 3.5279152577228707
Validation loss: 2.99784249143534

Epoch: 5| Step: 8
Training loss: 3.0784549439481723
Validation loss: 2.999899517277042

Epoch: 5| Step: 9
Training loss: 3.4329773715279353
Validation loss: 3.0005378343580493

Epoch: 5| Step: 10
Training loss: 3.5560033353998013
Validation loss: 2.996923186569746

Epoch: 178| Step: 0
Training loss: 2.89294769172308
Validation loss: 2.999200936688011

Epoch: 5| Step: 1
Training loss: 3.5880711011188966
Validation loss: 2.9977899481183456

Epoch: 5| Step: 2
Training loss: 3.0238543082669365
Validation loss: 2.9998478833808617

Epoch: 5| Step: 3
Training loss: 3.0351532650101958
Validation loss: 2.9970702457801868

Epoch: 5| Step: 4
Training loss: 3.0570577416075184
Validation loss: 3.0007003903185403

Epoch: 5| Step: 5
Training loss: 3.186955873009733
Validation loss: 2.9992117085375645

Epoch: 5| Step: 6
Training loss: 3.3608630765782226
Validation loss: 3.0029171515495836

Epoch: 5| Step: 7
Training loss: 3.357017079927768
Validation loss: 2.998164261322276

Epoch: 5| Step: 8
Training loss: 2.9484601996861515
Validation loss: 2.9963239250964873

Epoch: 5| Step: 9
Training loss: 3.4715369773322813
Validation loss: 2.996961273235053

Epoch: 5| Step: 10
Training loss: 3.930559247437905
Validation loss: 2.993120397886177

Epoch: 179| Step: 0
Training loss: 2.7035184364431
Validation loss: 2.9964701093971993

Epoch: 5| Step: 1
Training loss: 3.1315547101965344
Validation loss: 2.9946875347136896

Epoch: 5| Step: 2
Training loss: 3.6344305557373824
Validation loss: 2.9938969453795563

Epoch: 5| Step: 3
Training loss: 2.9683185464646704
Validation loss: 2.994178599792324

Epoch: 5| Step: 4
Training loss: 3.4793677509849745
Validation loss: 2.993917465415741

Epoch: 5| Step: 5
Training loss: 3.1534434011281465
Validation loss: 2.9916958729121577

Epoch: 5| Step: 6
Training loss: 3.2210387453521974
Validation loss: 2.9940317350579826

Epoch: 5| Step: 7
Training loss: 3.337910910467177
Validation loss: 2.9927280096019

Epoch: 5| Step: 8
Training loss: 3.947336051875126
Validation loss: 2.990458654702477

Epoch: 5| Step: 9
Training loss: 3.198755624340579
Validation loss: 2.993166972880608

Epoch: 5| Step: 10
Training loss: 2.878590042367798
Validation loss: 2.9938205976903354

Epoch: 180| Step: 0
Training loss: 4.040053815955355
Validation loss: 2.9933652917795865

Epoch: 5| Step: 1
Training loss: 3.5107515592277556
Validation loss: 2.994736313631579

Epoch: 5| Step: 2
Training loss: 3.062286525214812
Validation loss: 2.99745335041787

Epoch: 5| Step: 3
Training loss: 3.5110955793973444
Validation loss: 2.9934717198053225

Epoch: 5| Step: 4
Training loss: 3.3044033785128666
Validation loss: 2.993556802980112

Epoch: 5| Step: 5
Training loss: 2.565929258196501
Validation loss: 2.9911971354095073

Epoch: 5| Step: 6
Training loss: 3.1706725599021888
Validation loss: 2.992125153323758

Epoch: 5| Step: 7
Training loss: 2.929092224680055
Validation loss: 2.996014552391851

Epoch: 5| Step: 8
Training loss: 3.1950577538752167
Validation loss: 2.9923959562680835

Epoch: 5| Step: 9
Training loss: 3.3714275526363875
Validation loss: 2.9968641839597896

Epoch: 5| Step: 10
Training loss: 2.9440782627193527
Validation loss: 2.9966699566196215

Epoch: 181| Step: 0
Training loss: 3.011209209794525
Validation loss: 2.9944766190910257

Epoch: 5| Step: 1
Training loss: 3.9330339080722276
Validation loss: 2.99604197521562

Epoch: 5| Step: 2
Training loss: 3.490168113485106
Validation loss: 2.9943061558473536

Epoch: 5| Step: 3
Training loss: 2.790890305777541
Validation loss: 2.994567628731336

Epoch: 5| Step: 4
Training loss: 2.89701458739722
Validation loss: 2.9912415017387537

Epoch: 5| Step: 5
Training loss: 2.6546600070942006
Validation loss: 2.9894547579343245

Epoch: 5| Step: 6
Training loss: 3.4815736466090583
Validation loss: 2.991167103815216

Epoch: 5| Step: 7
Training loss: 3.2389806123384703
Validation loss: 2.991067670002959

Epoch: 5| Step: 8
Training loss: 3.6996312138055143
Validation loss: 2.9918564174955735

Epoch: 5| Step: 9
Training loss: 3.2591551431328454
Validation loss: 2.989629671305725

Epoch: 5| Step: 10
Training loss: 3.1770712096603124
Validation loss: 2.994938821409656

Epoch: 182| Step: 0
Training loss: 2.8705248625913993
Validation loss: 2.992715619376396

Epoch: 5| Step: 1
Training loss: 3.612052815884448
Validation loss: 2.9918338696575524

Epoch: 5| Step: 2
Training loss: 3.2781798031774354
Validation loss: 2.9881429793734964

Epoch: 5| Step: 3
Training loss: 2.910963276837528
Validation loss: 2.990655325611546

Epoch: 5| Step: 4
Training loss: 2.9754444335302863
Validation loss: 2.993643055239479

Epoch: 5| Step: 5
Training loss: 4.163472031745964
Validation loss: 2.9875182358688956

Epoch: 5| Step: 6
Training loss: 2.9486143187532745
Validation loss: 2.9903741606432592

Epoch: 5| Step: 7
Training loss: 3.220772709508306
Validation loss: 2.992336116460623

Epoch: 5| Step: 8
Training loss: 3.024718178476154
Validation loss: 2.9898793809729036

Epoch: 5| Step: 9
Training loss: 3.7752705104486206
Validation loss: 2.9892452620951273

Epoch: 5| Step: 10
Training loss: 2.699533888531876
Validation loss: 2.990520391465833

Epoch: 183| Step: 0
Training loss: 4.0488215297823755
Validation loss: 2.9861275427225427

Epoch: 5| Step: 1
Training loss: 2.807726560369648
Validation loss: 2.9895146888608988

Epoch: 5| Step: 2
Training loss: 3.7040410578699356
Validation loss: 2.987971496720964

Epoch: 5| Step: 3
Training loss: 2.957697320903144
Validation loss: 2.99161882891561

Epoch: 5| Step: 4
Training loss: 2.700794781161866
Validation loss: 2.988147543598789

Epoch: 5| Step: 5
Training loss: 3.8222194662995963
Validation loss: 2.985367753139012

Epoch: 5| Step: 6
Training loss: 3.084717019084504
Validation loss: 2.9847745571542887

Epoch: 5| Step: 7
Training loss: 2.510914912712706
Validation loss: 2.989886709499197

Epoch: 5| Step: 8
Training loss: 3.4441367152034914
Validation loss: 2.9874163747685136

Epoch: 5| Step: 9
Training loss: 3.2546051850075948
Validation loss: 2.986916111616905

Epoch: 5| Step: 10
Training loss: 3.0722901476095372
Validation loss: 2.9882720172870014

Epoch: 184| Step: 0
Training loss: 3.8321081497922393
Validation loss: 2.9848789398873463

Epoch: 5| Step: 1
Training loss: 3.577809815497003
Validation loss: 2.986202081654094

Epoch: 5| Step: 2
Training loss: 3.5015352151906476
Validation loss: 2.988010823582287

Epoch: 5| Step: 3
Training loss: 2.9337065531533053
Validation loss: 2.9855539537744944

Epoch: 5| Step: 4
Training loss: 2.6590255597375605
Validation loss: 2.982443254484197

Epoch: 5| Step: 5
Training loss: 2.9399906718826228
Validation loss: 2.987179069840091

Epoch: 5| Step: 6
Training loss: 2.342845894956006
Validation loss: 2.980943631897955

Epoch: 5| Step: 7
Training loss: 3.49317675751642
Validation loss: 2.9822699543598743

Epoch: 5| Step: 8
Training loss: 3.3119778491491143
Validation loss: 2.9833664953501833

Epoch: 5| Step: 9
Training loss: 3.4799463156143813
Validation loss: 2.9808439585397264

Epoch: 5| Step: 10
Training loss: 3.434953335774056
Validation loss: 2.9883124498731433

Epoch: 185| Step: 0
Training loss: 3.8813471341225747
Validation loss: 2.9858075357634353

Epoch: 5| Step: 1
Training loss: 3.649487493407612
Validation loss: 2.9878904501718364

Epoch: 5| Step: 2
Training loss: 3.2649566112398505
Validation loss: 2.990865308977838

Epoch: 5| Step: 3
Training loss: 2.965031915656939
Validation loss: 2.982236869700891

Epoch: 5| Step: 4
Training loss: 3.1789141940104106
Validation loss: 2.979436235016122

Epoch: 5| Step: 5
Training loss: 2.63464816703299
Validation loss: 2.98114092536952

Epoch: 5| Step: 6
Training loss: 2.9956480885950416
Validation loss: 2.985454027309248

Epoch: 5| Step: 7
Training loss: 3.2367459512645325
Validation loss: 2.9825392969521496

Epoch: 5| Step: 8
Training loss: 3.041849853712661
Validation loss: 2.9832336961399752

Epoch: 5| Step: 9
Training loss: 3.464032788938609
Validation loss: 2.993355848646698

Epoch: 5| Step: 10
Training loss: 3.2966592003943815
Validation loss: 2.984197199702328

Epoch: 186| Step: 0
Training loss: 3.088240370225341
Validation loss: 2.9822377602845096

Epoch: 5| Step: 1
Training loss: 3.287023786857377
Validation loss: 2.9801201637290236

Epoch: 5| Step: 2
Training loss: 3.032912280304924
Validation loss: 2.9829832402211856

Epoch: 5| Step: 3
Training loss: 2.9860686444557594
Validation loss: 2.9825043354244105

Epoch: 5| Step: 4
Training loss: 3.3511458984961866
Validation loss: 2.9815771681706593

Epoch: 5| Step: 5
Training loss: 3.2985849872469286
Validation loss: 2.982031742984091

Epoch: 5| Step: 6
Training loss: 2.7879608286564577
Validation loss: 2.9803875157697273

Epoch: 5| Step: 7
Training loss: 3.9523864779978135
Validation loss: 2.9809161303787945

Epoch: 5| Step: 8
Training loss: 3.429347271217076
Validation loss: 2.981433893470211

Epoch: 5| Step: 9
Training loss: 3.118179354703341
Validation loss: 2.978027870160919

Epoch: 5| Step: 10
Training loss: 3.279568050366521
Validation loss: 2.9818042346835165

Epoch: 187| Step: 0
Training loss: 2.8494803573967555
Validation loss: 2.9789903328827556

Epoch: 5| Step: 1
Training loss: 3.3291426701132454
Validation loss: 2.980781807207924

Epoch: 5| Step: 2
Training loss: 3.795936876734881
Validation loss: 2.978049017771011

Epoch: 5| Step: 3
Training loss: 3.096374323431465
Validation loss: 2.9811870305251063

Epoch: 5| Step: 4
Training loss: 3.3276120359158856
Validation loss: 2.9785664452370013

Epoch: 5| Step: 5
Training loss: 2.9069695351089866
Validation loss: 2.9800927698847746

Epoch: 5| Step: 6
Training loss: 3.648878965277839
Validation loss: 2.979536297912005

Epoch: 5| Step: 7
Training loss: 2.5077978591253896
Validation loss: 2.9803157035923458

Epoch: 5| Step: 8
Training loss: 3.629422088522534
Validation loss: 2.9861188734074027

Epoch: 5| Step: 9
Training loss: 3.1403415229360436
Validation loss: 2.9810842332987724

Epoch: 5| Step: 10
Training loss: 3.3070841726659537
Validation loss: 2.9805806357946927

Epoch: 188| Step: 0
Training loss: 4.114912008686625
Validation loss: 2.9789448081879053

Epoch: 5| Step: 1
Training loss: 3.051604683658207
Validation loss: 2.977938834372265

Epoch: 5| Step: 2
Training loss: 3.1910742373388947
Validation loss: 2.978528772328808

Epoch: 5| Step: 3
Training loss: 3.498151290928343
Validation loss: 2.9788562679790296

Epoch: 5| Step: 4
Training loss: 3.037843121273344
Validation loss: 2.9777467267979567

Epoch: 5| Step: 5
Training loss: 2.6176871207172554
Validation loss: 2.976249663958354

Epoch: 5| Step: 6
Training loss: 3.332254346420129
Validation loss: 2.9775775245360645

Epoch: 5| Step: 7
Training loss: 3.0847312404594827
Validation loss: 2.9755416306751803

Epoch: 5| Step: 8
Training loss: 3.0376111171162323
Validation loss: 2.975745788448559

Epoch: 5| Step: 9
Training loss: 3.2707872974695382
Validation loss: 2.9753527527900694

Epoch: 5| Step: 10
Training loss: 3.2654477304046505
Validation loss: 2.972306637093454

Epoch: 189| Step: 0
Training loss: 2.9943220129641666
Validation loss: 2.978311617498407

Epoch: 5| Step: 1
Training loss: 3.5448343061239878
Validation loss: 2.977091658585528

Epoch: 5| Step: 2
Training loss: 2.7327794242589047
Validation loss: 2.9750743200391656

Epoch: 5| Step: 3
Training loss: 3.8566396803861016
Validation loss: 2.979913618911908

Epoch: 5| Step: 4
Training loss: 3.259438088557168
Validation loss: 2.9781431273772845

Epoch: 5| Step: 5
Training loss: 3.0350065255762675
Validation loss: 2.9780206510490217

Epoch: 5| Step: 6
Training loss: 3.1072550692285597
Validation loss: 2.9736772874276167

Epoch: 5| Step: 7
Training loss: 3.460878393215299
Validation loss: 2.9754886625364803

Epoch: 5| Step: 8
Training loss: 3.0727619369258834
Validation loss: 2.9783825561342256

Epoch: 5| Step: 9
Training loss: 3.191786184305848
Validation loss: 2.976356429235759

Epoch: 5| Step: 10
Training loss: 3.326162413282931
Validation loss: 2.975949413621515

Epoch: 190| Step: 0
Training loss: 3.314914902735503
Validation loss: 2.975182083092101

Epoch: 5| Step: 1
Training loss: 3.0367716414406765
Validation loss: 2.972536145274795

Epoch: 5| Step: 2
Training loss: 3.2205879371267914
Validation loss: 2.9692824313176893

Epoch: 5| Step: 3
Training loss: 3.43005702780424
Validation loss: 2.970698345844136

Epoch: 5| Step: 4
Training loss: 3.0100324092907154
Validation loss: 2.973438742022872

Epoch: 5| Step: 5
Training loss: 3.3483618189687236
Validation loss: 2.972845396651584

Epoch: 5| Step: 6
Training loss: 4.0153932022106344
Validation loss: 2.9716678806906778

Epoch: 5| Step: 7
Training loss: 3.4356405604320486
Validation loss: 2.970005463793008

Epoch: 5| Step: 8
Training loss: 3.2186891124114423
Validation loss: 2.9726005379623337

Epoch: 5| Step: 9
Training loss: 3.084886898397301
Validation loss: 2.9736882707046246

Epoch: 5| Step: 10
Training loss: 2.0798685890647803
Validation loss: 2.9696638046964554

Epoch: 191| Step: 0
Training loss: 3.1334495752835605
Validation loss: 2.9694910701539143

Epoch: 5| Step: 1
Training loss: 3.668512631069492
Validation loss: 2.969792998103518

Epoch: 5| Step: 2
Training loss: 2.91738399585527
Validation loss: 2.9689494827511393

Epoch: 5| Step: 3
Training loss: 3.0431536519160387
Validation loss: 2.9697177175439022

Epoch: 5| Step: 4
Training loss: 3.812239466035538
Validation loss: 2.971270928578516

Epoch: 5| Step: 5
Training loss: 2.954916435906179
Validation loss: 2.9698366500439035

Epoch: 5| Step: 6
Training loss: 3.354285212410216
Validation loss: 2.9737609472504625

Epoch: 5| Step: 7
Training loss: 3.49594889932119
Validation loss: 2.9713033579575288

Epoch: 5| Step: 8
Training loss: 3.0303790227435865
Validation loss: 2.9717534828775047

Epoch: 5| Step: 9
Training loss: 3.074501499614266
Validation loss: 2.9767269233049003

Epoch: 5| Step: 10
Training loss: 2.9878752787960585
Validation loss: 2.9810770491073844

Epoch: 192| Step: 0
Training loss: 3.0784905695830416
Validation loss: 2.977268180021907

Epoch: 5| Step: 1
Training loss: 3.4826045306661797
Validation loss: 2.982495426934015

Epoch: 5| Step: 2
Training loss: 2.85052454621928
Validation loss: 2.9700486784389835

Epoch: 5| Step: 3
Training loss: 3.0496647509822763
Validation loss: 2.9701733202326444

Epoch: 5| Step: 4
Training loss: 3.3122839227413876
Validation loss: 2.97313125362153

Epoch: 5| Step: 5
Training loss: 2.933682660052061
Validation loss: 2.971360179698791

Epoch: 5| Step: 6
Training loss: 3.745508174057773
Validation loss: 2.9678994774411382

Epoch: 5| Step: 7
Training loss: 3.641068460199609
Validation loss: 2.967651796175837

Epoch: 5| Step: 8
Training loss: 3.1864683688353757
Validation loss: 2.96690915972743

Epoch: 5| Step: 9
Training loss: 3.5029875402509383
Validation loss: 2.967655287038791

Epoch: 5| Step: 10
Training loss: 2.6349621608268414
Validation loss: 2.970935159388566

Epoch: 193| Step: 0
Training loss: 3.5515378978865635
Validation loss: 2.9679117432277917

Epoch: 5| Step: 1
Training loss: 3.1439401011694246
Validation loss: 2.969001901816901

Epoch: 5| Step: 2
Training loss: 3.9201415589132678
Validation loss: 2.966939783354231

Epoch: 5| Step: 3
Training loss: 3.22804074911422
Validation loss: 2.970373914832368

Epoch: 5| Step: 4
Training loss: 3.608004223011193
Validation loss: 2.967440618540876

Epoch: 5| Step: 5
Training loss: 2.5707667914568075
Validation loss: 2.9705472228646013

Epoch: 5| Step: 6
Training loss: 3.7365838704619083
Validation loss: 2.9695092517564925

Epoch: 5| Step: 7
Training loss: 3.3204532369070234
Validation loss: 2.9696921839087516

Epoch: 5| Step: 8
Training loss: 2.3918477839388532
Validation loss: 2.9695659817849283

Epoch: 5| Step: 9
Training loss: 3.1030715615088105
Validation loss: 2.9716167017794373

Epoch: 5| Step: 10
Training loss: 2.599130220914958
Validation loss: 2.969886011494198

Epoch: 194| Step: 0
Training loss: 3.899953543557505
Validation loss: 2.9727571999669067

Epoch: 5| Step: 1
Training loss: 2.945261178214582
Validation loss: 2.971865757172084

Epoch: 5| Step: 2
Training loss: 3.4353735155148812
Validation loss: 2.968422715044027

Epoch: 5| Step: 3
Training loss: 2.9984858188443293
Validation loss: 2.9674920077003377

Epoch: 5| Step: 4
Training loss: 2.8077703762556525
Validation loss: 2.968140328481716

Epoch: 5| Step: 5
Training loss: 3.508720025674162
Validation loss: 2.9632689590250894

Epoch: 5| Step: 6
Training loss: 3.169711121835274
Validation loss: 2.962267427292186

Epoch: 5| Step: 7
Training loss: 3.3304993662275906
Validation loss: 2.9705159744846243

Epoch: 5| Step: 8
Training loss: 2.698289813499109
Validation loss: 2.965190459428447

Epoch: 5| Step: 9
Training loss: 3.3228204567752178
Validation loss: 2.9656576876567398

Epoch: 5| Step: 10
Training loss: 3.347765783879359
Validation loss: 2.966128735119972

Epoch: 195| Step: 0
Training loss: 3.36061846763142
Validation loss: 2.9658054794424715

Epoch: 5| Step: 1
Training loss: 3.3054886516421824
Validation loss: 2.9634598649103165

Epoch: 5| Step: 2
Training loss: 3.5202328472717865
Validation loss: 2.9702156365221506

Epoch: 5| Step: 3
Training loss: 3.51945713994012
Validation loss: 2.964080215471997

Epoch: 5| Step: 4
Training loss: 2.999927360926828
Validation loss: 2.9665472419549905

Epoch: 5| Step: 5
Training loss: 2.8338183006667608
Validation loss: 2.9633886356629398

Epoch: 5| Step: 6
Training loss: 3.515207494740403
Validation loss: 2.96714680360333

Epoch: 5| Step: 7
Training loss: 2.982815799541457
Validation loss: 2.969598737979182

Epoch: 5| Step: 8
Training loss: 2.9576597566254836
Validation loss: 2.973327785093415

Epoch: 5| Step: 9
Training loss: 3.277631235528683
Validation loss: 2.9692473965825874

Epoch: 5| Step: 10
Training loss: 3.245304971244502
Validation loss: 2.9667345443192463

Epoch: 196| Step: 0
Training loss: 2.9721161079676417
Validation loss: 2.9718640560519147

Epoch: 5| Step: 1
Training loss: 3.250286529821631
Validation loss: 2.974037245365509

Epoch: 5| Step: 2
Training loss: 3.6799190634658894
Validation loss: 2.9702499771198743

Epoch: 5| Step: 3
Training loss: 2.9566674355122777
Validation loss: 2.972623557681941

Epoch: 5| Step: 4
Training loss: 3.6365935307137907
Validation loss: 2.9736529809637697

Epoch: 5| Step: 5
Training loss: 3.4005971776815844
Validation loss: 2.9689860597117828

Epoch: 5| Step: 6
Training loss: 3.183124456160293
Validation loss: 2.9619589340971944

Epoch: 5| Step: 7
Training loss: 3.1526819588939743
Validation loss: 2.964719268076202

Epoch: 5| Step: 8
Training loss: 3.27640109776602
Validation loss: 2.9604662534997774

Epoch: 5| Step: 9
Training loss: 3.147579104495259
Validation loss: 2.9592748654718495

Epoch: 5| Step: 10
Training loss: 2.7230290030490925
Validation loss: 2.9594399417373873

Epoch: 197| Step: 0
Training loss: 3.343316165909155
Validation loss: 2.9646041479093364

Epoch: 5| Step: 1
Training loss: 3.270600539425255
Validation loss: 2.9588858559161784

Epoch: 5| Step: 2
Training loss: 3.503141355859175
Validation loss: 2.9650789180270922

Epoch: 5| Step: 3
Training loss: 2.7964096960952496
Validation loss: 2.9616488645162375

Epoch: 5| Step: 4
Training loss: 2.8273551272405535
Validation loss: 2.9636948002021963

Epoch: 5| Step: 5
Training loss: 2.976292555375413
Validation loss: 2.960442997229501

Epoch: 5| Step: 6
Training loss: 3.1901498887295303
Validation loss: 2.9668940063546043

Epoch: 5| Step: 7
Training loss: 3.3816365583372656
Validation loss: 2.9603466778163914

Epoch: 5| Step: 8
Training loss: 2.8137894111899886
Validation loss: 2.9620303310124143

Epoch: 5| Step: 9
Training loss: 3.3645061251793895
Validation loss: 2.9642862229190325

Epoch: 5| Step: 10
Training loss: 4.024293560324342
Validation loss: 2.965756350028213

Epoch: 198| Step: 0
Training loss: 3.7925621624091153
Validation loss: 2.9628789267990867

Epoch: 5| Step: 1
Training loss: 2.991462799039886
Validation loss: 2.958518860571702

Epoch: 5| Step: 2
Training loss: 3.148686780124542
Validation loss: 2.9575309485634262

Epoch: 5| Step: 3
Training loss: 3.608378615473296
Validation loss: 2.9574930701141975

Epoch: 5| Step: 4
Training loss: 3.477829605815938
Validation loss: 2.960944109666961

Epoch: 5| Step: 5
Training loss: 3.5062823452197076
Validation loss: 2.9589056882248053

Epoch: 5| Step: 6
Training loss: 3.4238505474255088
Validation loss: 2.959962440626996

Epoch: 5| Step: 7
Training loss: 2.7583018617092723
Validation loss: 2.957479909887681

Epoch: 5| Step: 8
Training loss: 2.7580446140202346
Validation loss: 2.9574307947325544

Epoch: 5| Step: 9
Training loss: 2.6257579254231267
Validation loss: 2.9646502957842347

Epoch: 5| Step: 10
Training loss: 3.2870483030107245
Validation loss: 2.9567466569954752

Epoch: 199| Step: 0
Training loss: 2.8847056223130956
Validation loss: 2.9648744459756102

Epoch: 5| Step: 1
Training loss: 3.4607309662997436
Validation loss: 2.9755207392261362

Epoch: 5| Step: 2
Training loss: 3.3618156615944166
Validation loss: 2.980445618842696

Epoch: 5| Step: 3
Training loss: 3.4328041600927794
Validation loss: 2.991122407262535

Epoch: 5| Step: 4
Training loss: 3.4141583112807328
Validation loss: 2.98505576861202

Epoch: 5| Step: 5
Training loss: 3.7935130615653088
Validation loss: 2.958247083983545

Epoch: 5| Step: 6
Training loss: 2.593708543561063
Validation loss: 2.954671324353456

Epoch: 5| Step: 7
Training loss: 2.9762113268893873
Validation loss: 2.957142312981509

Epoch: 5| Step: 8
Training loss: 3.727556587879616
Validation loss: 2.957728683909859

Epoch: 5| Step: 9
Training loss: 2.9938853255170264
Validation loss: 2.955238559531641

Epoch: 5| Step: 10
Training loss: 2.5687086672833703
Validation loss: 2.957210068125131

Epoch: 200| Step: 0
Training loss: 2.826023227075153
Validation loss: 2.9589909647708437

Epoch: 5| Step: 1
Training loss: 3.8575621760481886
Validation loss: 2.9568676839845196

Epoch: 5| Step: 2
Training loss: 2.1529406154396407
Validation loss: 2.960766385531034

Epoch: 5| Step: 3
Training loss: 3.1588112287546166
Validation loss: 2.960388282444154

Epoch: 5| Step: 4
Training loss: 3.233163800333976
Validation loss: 2.9566512524545585

Epoch: 5| Step: 5
Training loss: 3.41650833755474
Validation loss: 2.95884487045664

Epoch: 5| Step: 6
Training loss: 3.546152721922346
Validation loss: 2.9511554967554545

Epoch: 5| Step: 7
Training loss: 3.706454168810558
Validation loss: 2.9584136673521284

Epoch: 5| Step: 8
Training loss: 3.2482427101027027
Validation loss: 2.956034664346942

Epoch: 5| Step: 9
Training loss: 2.989490060093355
Validation loss: 2.955556085544197

Epoch: 5| Step: 10
Training loss: 3.024056304770767
Validation loss: 2.959026474424597

Epoch: 201| Step: 0
Training loss: 2.681417279482808
Validation loss: 2.9551602432091677

Epoch: 5| Step: 1
Training loss: 3.490366074564766
Validation loss: 2.9566232284331444

Epoch: 5| Step: 2
Training loss: 3.1519881075039278
Validation loss: 2.9511620709975572

Epoch: 5| Step: 3
Training loss: 3.224769223258298
Validation loss: 2.95234087002465

Epoch: 5| Step: 4
Training loss: 3.5178221216042243
Validation loss: 2.949612502393569

Epoch: 5| Step: 5
Training loss: 2.942881261195
Validation loss: 2.9543165980230977

Epoch: 5| Step: 6
Training loss: 3.5353007081586334
Validation loss: 2.9544410496800673

Epoch: 5| Step: 7
Training loss: 3.0555765170524696
Validation loss: 2.9572758105261525

Epoch: 5| Step: 8
Training loss: 3.2343913644570166
Validation loss: 2.9534556293890826

Epoch: 5| Step: 9
Training loss: 3.2659173131918764
Validation loss: 2.955237143787215

Epoch: 5| Step: 10
Training loss: 3.3167964494574864
Validation loss: 2.954889637824834

Epoch: 202| Step: 0
Training loss: 3.127005582008467
Validation loss: 2.9550047599260396

Epoch: 5| Step: 1
Training loss: 3.436716163740076
Validation loss: 2.9506958628987645

Epoch: 5| Step: 2
Training loss: 3.4777111427604894
Validation loss: 2.948920037692894

Epoch: 5| Step: 3
Training loss: 3.539359040289168
Validation loss: 2.9538877558730046

Epoch: 5| Step: 4
Training loss: 2.9582800703671457
Validation loss: 2.951448904959821

Epoch: 5| Step: 5
Training loss: 2.5831108202523154
Validation loss: 2.953199837174723

Epoch: 5| Step: 6
Training loss: 3.065374465644291
Validation loss: 2.9494370689717577

Epoch: 5| Step: 7
Training loss: 3.3107614813368405
Validation loss: 2.95074064357733

Epoch: 5| Step: 8
Training loss: 3.487850764966758
Validation loss: 2.9472347447555376

Epoch: 5| Step: 9
Training loss: 3.3509818332126176
Validation loss: 2.9479248042124575

Epoch: 5| Step: 10
Training loss: 3.0022768281679326
Validation loss: 2.950014528385106

Epoch: 203| Step: 0
Training loss: 3.6335464228400323
Validation loss: 2.9502180360614383

Epoch: 5| Step: 1
Training loss: 3.3456578026155257
Validation loss: 2.9508985217161032

Epoch: 5| Step: 2
Training loss: 3.2014679879442856
Validation loss: 2.951709526800817

Epoch: 5| Step: 3
Training loss: 2.6130135574427076
Validation loss: 2.948005361573197

Epoch: 5| Step: 4
Training loss: 3.4241509380584327
Validation loss: 2.955563664849919

Epoch: 5| Step: 5
Training loss: 3.3072201378163544
Validation loss: 2.949619624158204

Epoch: 5| Step: 6
Training loss: 2.76041158039896
Validation loss: 2.9526551738795748

Epoch: 5| Step: 7
Training loss: 2.7747539136216113
Validation loss: 2.9593272298036153

Epoch: 5| Step: 8
Training loss: 3.5803122685810185
Validation loss: 2.952218869839385

Epoch: 5| Step: 9
Training loss: 3.055886113945716
Validation loss: 2.9511196986730366

Epoch: 5| Step: 10
Training loss: 3.6223475519066635
Validation loss: 2.951871749367107

Epoch: 204| Step: 0
Training loss: 3.749227189859158
Validation loss: 2.9469051912261595

Epoch: 5| Step: 1
Training loss: 3.2157835392104874
Validation loss: 2.9476253832757293

Epoch: 5| Step: 2
Training loss: 2.2565686452623703
Validation loss: 2.944129883769551

Epoch: 5| Step: 3
Training loss: 3.2417434572148087
Validation loss: 2.9467681014911444

Epoch: 5| Step: 4
Training loss: 3.987427264180977
Validation loss: 2.9468181260074546

Epoch: 5| Step: 5
Training loss: 3.042773337204729
Validation loss: 2.945658980907814

Epoch: 5| Step: 6
Training loss: 3.4674490473715927
Validation loss: 2.9465234875511936

Epoch: 5| Step: 7
Training loss: 2.836248543656145
Validation loss: 2.9481231055958994

Epoch: 5| Step: 8
Training loss: 3.2540835621895012
Validation loss: 2.9481152680250333

Epoch: 5| Step: 9
Training loss: 3.02469863020911
Validation loss: 2.9480768294514124

Epoch: 5| Step: 10
Training loss: 2.9817208675990097
Validation loss: 2.9463090596516346

Epoch: 205| Step: 0
Training loss: 3.2472770728344615
Validation loss: 2.94611694494926

Epoch: 5| Step: 1
Training loss: 2.901289284968957
Validation loss: 2.94677276112092

Epoch: 5| Step: 2
Training loss: 3.565684183818089
Validation loss: 2.9502861831030236

Epoch: 5| Step: 3
Training loss: 2.6370466014344927
Validation loss: 2.9478297281455768

Epoch: 5| Step: 4
Training loss: 3.5784678732162893
Validation loss: 2.946253213989939

Epoch: 5| Step: 5
Training loss: 2.8754023394807904
Validation loss: 2.9510744277105516

Epoch: 5| Step: 6
Training loss: 2.4496050808308816
Validation loss: 2.9484692318779833

Epoch: 5| Step: 7
Training loss: 3.597530068701976
Validation loss: 2.9448048204748014

Epoch: 5| Step: 8
Training loss: 3.459033175209823
Validation loss: 2.948096797084661

Epoch: 5| Step: 9
Training loss: 3.0075889603418413
Validation loss: 2.941534367959331

Epoch: 5| Step: 10
Training loss: 3.8823341366623567
Validation loss: 2.9439517741716323

Epoch: 206| Step: 0
Training loss: 2.649663230801948
Validation loss: 2.9417337537248684

Epoch: 5| Step: 1
Training loss: 3.4993653403201814
Validation loss: 2.9432101146490828

Epoch: 5| Step: 2
Training loss: 2.8665517990992146
Validation loss: 2.9485515376250113

Epoch: 5| Step: 3
Training loss: 3.8854072850227444
Validation loss: 2.942379147892124

Epoch: 5| Step: 4
Training loss: 3.2121992393447623
Validation loss: 2.9429638747934526

Epoch: 5| Step: 5
Training loss: 3.500906690594595
Validation loss: 2.9429962310670437

Epoch: 5| Step: 6
Training loss: 3.617475131568239
Validation loss: 2.9498832251265883

Epoch: 5| Step: 7
Training loss: 2.7832332783454308
Validation loss: 2.9467085913854705

Epoch: 5| Step: 8
Training loss: 3.2310030401954055
Validation loss: 2.9479744308124634

Epoch: 5| Step: 9
Training loss: 3.040967172813671
Validation loss: 2.9479611785240287

Epoch: 5| Step: 10
Training loss: 2.8264019179818423
Validation loss: 2.9523783126805268

Epoch: 207| Step: 0
Training loss: 2.9651095908176957
Validation loss: 2.9431059456644553

Epoch: 5| Step: 1
Training loss: 3.1659969491660767
Validation loss: 2.944714686137269

Epoch: 5| Step: 2
Training loss: 2.7383295727001826
Validation loss: 2.940927400249169

Epoch: 5| Step: 3
Training loss: 3.235480373039486
Validation loss: 2.941828692170982

Epoch: 5| Step: 4
Training loss: 2.8469143543391646
Validation loss: 2.9413295909574897

Epoch: 5| Step: 5
Training loss: 3.8162695587886497
Validation loss: 2.9442700254543688

Epoch: 5| Step: 6
Training loss: 3.4968065952295557
Validation loss: 2.9424425538517482

Epoch: 5| Step: 7
Training loss: 3.4832241740911045
Validation loss: 2.945916075345898

Epoch: 5| Step: 8
Training loss: 3.7515908999243917
Validation loss: 2.9441924892529925

Epoch: 5| Step: 9
Training loss: 3.034562022046907
Validation loss: 2.9429040638809862

Epoch: 5| Step: 10
Training loss: 2.4633397563322346
Validation loss: 2.941525478321909

Epoch: 208| Step: 0
Training loss: 2.958889940221624
Validation loss: 2.9412396116072252

Epoch: 5| Step: 1
Training loss: 3.767047027918138
Validation loss: 2.9418016685507906

Epoch: 5| Step: 2
Training loss: 3.2793454410303355
Validation loss: 2.939380289203621

Epoch: 5| Step: 3
Training loss: 3.3509288980333936
Validation loss: 2.9383725162373953

Epoch: 5| Step: 4
Training loss: 3.097042143128814
Validation loss: 2.9407343010652967

Epoch: 5| Step: 5
Training loss: 4.089981790889134
Validation loss: 2.9428986907700962

Epoch: 5| Step: 6
Training loss: 3.3134598690818806
Validation loss: 2.9392786412128937

Epoch: 5| Step: 7
Training loss: 2.8999728431745533
Validation loss: 2.936229501749948

Epoch: 5| Step: 8
Training loss: 2.552425304519242
Validation loss: 2.9376554646542363

Epoch: 5| Step: 9
Training loss: 2.7714515990563258
Validation loss: 2.9409054618005985

Epoch: 5| Step: 10
Training loss: 2.9170116402201223
Validation loss: 2.9422905093433793

Epoch: 209| Step: 0
Training loss: 3.1410704339554907
Validation loss: 2.9400408282837747

Epoch: 5| Step: 1
Training loss: 2.979272284780764
Validation loss: 2.9478247675407125

Epoch: 5| Step: 2
Training loss: 3.1435850248031314
Validation loss: 2.9450802835938674

Epoch: 5| Step: 3
Training loss: 3.5970447861463275
Validation loss: 2.9410251976949624

Epoch: 5| Step: 4
Training loss: 3.6416454276739296
Validation loss: 2.9487525945862774

Epoch: 5| Step: 5
Training loss: 3.4279647358490446
Validation loss: 2.9419847811811826

Epoch: 5| Step: 6
Training loss: 2.8615290965044546
Validation loss: 2.942460604618348

Epoch: 5| Step: 7
Training loss: 2.8663488507599575
Validation loss: 2.938361144446883

Epoch: 5| Step: 8
Training loss: 2.8858362069603536
Validation loss: 2.9347215741894463

Epoch: 5| Step: 9
Training loss: 2.8712349162787096
Validation loss: 2.9394703847748866

Epoch: 5| Step: 10
Training loss: 3.837155523588669
Validation loss: 2.9399855567884856

Epoch: 210| Step: 0
Training loss: 2.779802095518057
Validation loss: 2.9361803489432177

Epoch: 5| Step: 1
Training loss: 3.1249935913020224
Validation loss: 2.9368632832425714

Epoch: 5| Step: 2
Training loss: 3.470712879620155
Validation loss: 2.9394086363509637

Epoch: 5| Step: 3
Training loss: 3.201004144953696
Validation loss: 2.9355912143292286

Epoch: 5| Step: 4
Training loss: 3.125947884806756
Validation loss: 2.9393005979091402

Epoch: 5| Step: 5
Training loss: 3.994998427523231
Validation loss: 2.9425876033293017

Epoch: 5| Step: 6
Training loss: 2.655880891174427
Validation loss: 2.9399256242434335

Epoch: 5| Step: 7
Training loss: 3.2753767947028374
Validation loss: 2.9382840874974328

Epoch: 5| Step: 8
Training loss: 3.393875884080107
Validation loss: 2.9440616203498444

Epoch: 5| Step: 9
Training loss: 3.2036629573980613
Validation loss: 2.9406859558531293

Epoch: 5| Step: 10
Training loss: 2.8570138323124903
Validation loss: 2.935823534236084

Epoch: 211| Step: 0
Training loss: 3.008455123619922
Validation loss: 2.9380649668299017

Epoch: 5| Step: 1
Training loss: 3.3047560375853076
Validation loss: 2.9351881657066

Epoch: 5| Step: 2
Training loss: 2.828056882596454
Validation loss: 2.932569748328472

Epoch: 5| Step: 3
Training loss: 2.850568540650066
Validation loss: 2.9381201392106546

Epoch: 5| Step: 4
Training loss: 2.8477677688426053
Validation loss: 2.9344472895688147

Epoch: 5| Step: 5
Training loss: 3.4505387369327187
Validation loss: 2.931863411273365

Epoch: 5| Step: 6
Training loss: 3.124156838156794
Validation loss: 2.9353786323656945

Epoch: 5| Step: 7
Training loss: 3.0042259333915458
Validation loss: 2.9317589108303834

Epoch: 5| Step: 8
Training loss: 3.5294922361362815
Validation loss: 2.9356998075757486

Epoch: 5| Step: 9
Training loss: 3.018768095669107
Validation loss: 2.9319331426194375

Epoch: 5| Step: 10
Training loss: 4.256448677792284
Validation loss: 2.935161893232373

Epoch: 212| Step: 0
Training loss: 3.9754632356018678
Validation loss: 2.9334744885700452

Epoch: 5| Step: 1
Training loss: 3.518419841773207
Validation loss: 2.9311885260647528

Epoch: 5| Step: 2
Training loss: 3.510733087392587
Validation loss: 2.930345323002624

Epoch: 5| Step: 3
Training loss: 2.652565498801745
Validation loss: 2.931758246257626

Epoch: 5| Step: 4
Training loss: 2.6309878764668837
Validation loss: 2.9357842867822774

Epoch: 5| Step: 5
Training loss: 3.5124141696204045
Validation loss: 2.9361584736889372

Epoch: 5| Step: 6
Training loss: 3.647916507484931
Validation loss: 2.9314555789196066

Epoch: 5| Step: 7
Training loss: 2.6593745983585184
Validation loss: 2.9313048920849787

Epoch: 5| Step: 8
Training loss: 2.529379730634929
Validation loss: 2.928714557060859

Epoch: 5| Step: 9
Training loss: 2.9835918257697873
Validation loss: 2.9313322144983016

Epoch: 5| Step: 10
Training loss: 3.326733938720625
Validation loss: 2.931098747938348

Epoch: 213| Step: 0
Training loss: 2.6082307968054317
Validation loss: 2.9317416826074147

Epoch: 5| Step: 1
Training loss: 3.1570678255699582
Validation loss: 2.9315861658122824

Epoch: 5| Step: 2
Training loss: 3.1249917602430433
Validation loss: 2.9323050311543954

Epoch: 5| Step: 3
Training loss: 2.982023740923379
Validation loss: 2.931624725288406

Epoch: 5| Step: 4
Training loss: 3.060857682796359
Validation loss: 2.9321668513763575

Epoch: 5| Step: 5
Training loss: 3.4457030475038253
Validation loss: 2.933302300800365

Epoch: 5| Step: 6
Training loss: 3.4258852239335043
Validation loss: 2.937216553707054

Epoch: 5| Step: 7
Training loss: 3.6467509976759165
Validation loss: 2.932516418830132

Epoch: 5| Step: 8
Training loss: 3.0630573621877755
Validation loss: 2.9352603334459

Epoch: 5| Step: 9
Training loss: 3.611186047942083
Validation loss: 2.928805351865723

Epoch: 5| Step: 10
Training loss: 3.0091112379745755
Validation loss: 2.9315395306777523

Epoch: 214| Step: 0
Training loss: 3.2205133145061104
Validation loss: 2.928722134927475

Epoch: 5| Step: 1
Training loss: 3.2854283931106036
Validation loss: 2.93126481012219

Epoch: 5| Step: 2
Training loss: 3.2712459101522007
Validation loss: 2.928273750932741

Epoch: 5| Step: 3
Training loss: 2.9836164379231156
Validation loss: 2.9282892398569427

Epoch: 5| Step: 4
Training loss: 3.5647989183725604
Validation loss: 2.9286697696042743

Epoch: 5| Step: 5
Training loss: 3.584902944488027
Validation loss: 2.9301677736235883

Epoch: 5| Step: 6
Training loss: 2.712009536771407
Validation loss: 2.9262568364128323

Epoch: 5| Step: 7
Training loss: 2.931144494474019
Validation loss: 2.9278438016562762

Epoch: 5| Step: 8
Training loss: 3.4836397635515164
Validation loss: 2.925676851269089

Epoch: 5| Step: 9
Training loss: 3.0785695640854187
Validation loss: 2.9274624044187028

Epoch: 5| Step: 10
Training loss: 3.000849921312984
Validation loss: 2.927141699531824

Epoch: 215| Step: 0
Training loss: 3.0049877030665293
Validation loss: 2.925281543922892

Epoch: 5| Step: 1
Training loss: 2.4247170784679217
Validation loss: 2.922839344435576

Epoch: 5| Step: 2
Training loss: 2.6707201687250968
Validation loss: 2.923842287194729

Epoch: 5| Step: 3
Training loss: 3.1280816714461444
Validation loss: 2.9242018552451676

Epoch: 5| Step: 4
Training loss: 3.231001711959173
Validation loss: 2.9291975169194684

Epoch: 5| Step: 5
Training loss: 3.1075124098022835
Validation loss: 2.9306017226256635

Epoch: 5| Step: 6
Training loss: 3.680621051005653
Validation loss: 2.936639778939984

Epoch: 5| Step: 7
Training loss: 3.2384848904512666
Validation loss: 2.9299937815930774

Epoch: 5| Step: 8
Training loss: 3.5626108252704203
Validation loss: 2.9345322512482177

Epoch: 5| Step: 9
Training loss: 2.7643593516069678
Validation loss: 2.9364606388287298

Epoch: 5| Step: 10
Training loss: 4.232194515048666
Validation loss: 2.9325134395145964

Epoch: 216| Step: 0
Training loss: 2.9817749201095536
Validation loss: 2.927024021510449

Epoch: 5| Step: 1
Training loss: 3.4822819329180037
Validation loss: 2.923503722515502

Epoch: 5| Step: 2
Training loss: 2.940875123237727
Validation loss: 2.9257112002857757

Epoch: 5| Step: 3
Training loss: 3.1186338047559388
Validation loss: 2.9236233143885513

Epoch: 5| Step: 4
Training loss: 3.1509107998661876
Validation loss: 2.922201046627213

Epoch: 5| Step: 5
Training loss: 3.214800884197437
Validation loss: 2.9240941930493003

Epoch: 5| Step: 6
Training loss: 3.1180791894082645
Validation loss: 2.9248014540274974

Epoch: 5| Step: 7
Training loss: 2.919414769667214
Validation loss: 2.9244955271682014

Epoch: 5| Step: 8
Training loss: 3.421837793435352
Validation loss: 2.9280513910938004

Epoch: 5| Step: 9
Training loss: 3.66123062373511
Validation loss: 2.9239627454967345

Epoch: 5| Step: 10
Training loss: 3.186641951615432
Validation loss: 2.926144119297454

Epoch: 217| Step: 0
Training loss: 2.917563128078507
Validation loss: 2.9242622310295383

Epoch: 5| Step: 1
Training loss: 3.1361060583319635
Validation loss: 2.9216622878437395

Epoch: 5| Step: 2
Training loss: 3.2318425238457995
Validation loss: 2.922513226912214

Epoch: 5| Step: 3
Training loss: 2.872308217312212
Validation loss: 2.924256616768883

Epoch: 5| Step: 4
Training loss: 3.148528824231889
Validation loss: 2.923292054076543

Epoch: 5| Step: 5
Training loss: 3.607046722253339
Validation loss: 2.92284216169947

Epoch: 5| Step: 6
Training loss: 3.2422829487550278
Validation loss: 2.923102820538149

Epoch: 5| Step: 7
Training loss: 2.951367374915205
Validation loss: 2.9251963345923437

Epoch: 5| Step: 8
Training loss: 4.168749606519964
Validation loss: 2.9241831981848456

Epoch: 5| Step: 9
Training loss: 3.030818003910355
Validation loss: 2.921230248315704

Epoch: 5| Step: 10
Training loss: 2.5368046037897436
Validation loss: 2.921313002944259

Epoch: 218| Step: 0
Training loss: 2.1803044365559763
Validation loss: 2.9259041115920703

Epoch: 5| Step: 1
Training loss: 3.386105104530966
Validation loss: 2.9285094062480588

Epoch: 5| Step: 2
Training loss: 3.6876254302853093
Validation loss: 2.927344116626724

Epoch: 5| Step: 3
Training loss: 3.336344566791532
Validation loss: 2.922582909422151

Epoch: 5| Step: 4
Training loss: 3.0012795580544815
Validation loss: 2.9203527992112224

Epoch: 5| Step: 5
Training loss: 2.985991035432639
Validation loss: 2.9254180727922754

Epoch: 5| Step: 6
Training loss: 3.1303079920352883
Validation loss: 2.925450183212834

Epoch: 5| Step: 7
Training loss: 3.355715155297185
Validation loss: 2.926872059824366

Epoch: 5| Step: 8
Training loss: 2.8901624154780294
Validation loss: 2.932325829205809

Epoch: 5| Step: 9
Training loss: 4.348460326167407
Validation loss: 2.9301392907062347

Epoch: 5| Step: 10
Training loss: 2.348257790679988
Validation loss: 2.9362519841524968

Epoch: 219| Step: 0
Training loss: 3.520651381867981
Validation loss: 2.9299873785956416

Epoch: 5| Step: 1
Training loss: 3.331117529319646
Validation loss: 2.924012459644355

Epoch: 5| Step: 2
Training loss: 2.877435067618273
Validation loss: 2.9229549429981883

Epoch: 5| Step: 3
Training loss: 2.6044065034415147
Validation loss: 2.9202347220764207

Epoch: 5| Step: 4
Training loss: 3.252984657155256
Validation loss: 2.9207207097106456

Epoch: 5| Step: 5
Training loss: 4.287370970094036
Validation loss: 2.9195538295889856

Epoch: 5| Step: 6
Training loss: 3.265601345140852
Validation loss: 2.929623424198486

Epoch: 5| Step: 7
Training loss: 2.4495062895034367
Validation loss: 2.925930470698362

Epoch: 5| Step: 8
Training loss: 3.5603991554741823
Validation loss: 2.9243963178322487

Epoch: 5| Step: 9
Training loss: 2.154758545698053
Validation loss: 2.9282902238893773

Epoch: 5| Step: 10
Training loss: 3.378783895228687
Validation loss: 2.9260913784126976

Epoch: 220| Step: 0
Training loss: 3.237422668240419
Validation loss: 2.929711758202101

Epoch: 5| Step: 1
Training loss: 3.0900082550432373
Validation loss: 2.936819950403627

Epoch: 5| Step: 2
Training loss: 2.87402741940346
Validation loss: 2.9338556958161486

Epoch: 5| Step: 3
Training loss: 3.3516104456888898
Validation loss: 2.928892811615785

Epoch: 5| Step: 4
Training loss: 3.389244677587929
Validation loss: 2.923933924195768

Epoch: 5| Step: 5
Training loss: 3.31841081800546
Validation loss: 2.928654884943465

Epoch: 5| Step: 6
Training loss: 3.649040744092998
Validation loss: 2.9212546092176614

Epoch: 5| Step: 7
Training loss: 3.1861126442325105
Validation loss: 2.9149589731083103

Epoch: 5| Step: 8
Training loss: 2.9131672892910747
Validation loss: 2.9170492164544823

Epoch: 5| Step: 9
Training loss: 3.0971568451858618
Validation loss: 2.9170904833133084

Epoch: 5| Step: 10
Training loss: 2.9698291624109037
Validation loss: 2.9147030867125503

Epoch: 221| Step: 0
Training loss: 3.6725073736543945
Validation loss: 2.913689163821651

Epoch: 5| Step: 1
Training loss: 3.3199966819011237
Validation loss: 2.9167095942934624

Epoch: 5| Step: 2
Training loss: 2.5345798771805543
Validation loss: 2.9166623705877726

Epoch: 5| Step: 3
Training loss: 2.8709459331633993
Validation loss: 2.9164499410338043

Epoch: 5| Step: 4
Training loss: 2.8911963645620875
Validation loss: 2.9176788407900247

Epoch: 5| Step: 5
Training loss: 2.5919056045274416
Validation loss: 2.916668961929848

Epoch: 5| Step: 6
Training loss: 3.7718213018278535
Validation loss: 2.9154855689424477

Epoch: 5| Step: 7
Training loss: 3.0570780188250994
Validation loss: 2.914914673493383

Epoch: 5| Step: 8
Training loss: 4.126322216475549
Validation loss: 2.9158224955613985

Epoch: 5| Step: 9
Training loss: 3.056702088539388
Validation loss: 2.9174189293298465

Epoch: 5| Step: 10
Training loss: 2.8084233727062147
Validation loss: 2.9142978565141435

Epoch: 222| Step: 0
Training loss: 2.780073795848551
Validation loss: 2.916988669403621

Epoch: 5| Step: 1
Training loss: 3.2503361161361277
Validation loss: 2.91518942754199

Epoch: 5| Step: 2
Training loss: 3.6014258633924037
Validation loss: 2.9152907450046333

Epoch: 5| Step: 3
Training loss: 2.986175153967178
Validation loss: 2.921712294716102

Epoch: 5| Step: 4
Training loss: 3.3078596613589286
Validation loss: 2.9286145399892973

Epoch: 5| Step: 5
Training loss: 2.7927015483526674
Validation loss: 2.921630682455299

Epoch: 5| Step: 6
Training loss: 3.2847518399825204
Validation loss: 2.9222121005589576

Epoch: 5| Step: 7
Training loss: 2.9120322510851184
Validation loss: 2.9386561219083416

Epoch: 5| Step: 8
Training loss: 3.7206202059740057
Validation loss: 2.9163968912223477

Epoch: 5| Step: 9
Training loss: 3.059168346310699
Validation loss: 2.917841893993396

Epoch: 5| Step: 10
Training loss: 3.3206076098172854
Validation loss: 2.9122105953881

Epoch: 223| Step: 0
Training loss: 2.5239187437178194
Validation loss: 2.913080321060712

Epoch: 5| Step: 1
Training loss: 3.5151893176215565
Validation loss: 2.910975332504554

Epoch: 5| Step: 2
Training loss: 2.8897332542891956
Validation loss: 2.912116024185563

Epoch: 5| Step: 3
Training loss: 2.8136718004325445
Validation loss: 2.9125451343723263

Epoch: 5| Step: 4
Training loss: 3.0061866230143024
Validation loss: 2.9118786539115322

Epoch: 5| Step: 5
Training loss: 3.651930907064862
Validation loss: 2.911128324788999

Epoch: 5| Step: 6
Training loss: 3.3184447297181756
Validation loss: 2.913293354470378

Epoch: 5| Step: 7
Training loss: 3.0618427116216225
Validation loss: 2.9107209727958123

Epoch: 5| Step: 8
Training loss: 3.4552048163424374
Validation loss: 2.9122889883508707

Epoch: 5| Step: 9
Training loss: 3.550585717251011
Validation loss: 2.9099638558241105

Epoch: 5| Step: 10
Training loss: 3.157752255521477
Validation loss: 2.9103976321162617

Epoch: 224| Step: 0
Training loss: 3.1475533505282143
Validation loss: 2.9126225448488605

Epoch: 5| Step: 1
Training loss: 2.444782918798732
Validation loss: 2.90978784865924

Epoch: 5| Step: 2
Training loss: 2.8467213962960765
Validation loss: 2.9140825388308826

Epoch: 5| Step: 3
Training loss: 4.016650117283413
Validation loss: 2.9166654249853723

Epoch: 5| Step: 4
Training loss: 3.1418463766032234
Validation loss: 2.9223924114779303

Epoch: 5| Step: 5
Training loss: 3.407463907343142
Validation loss: 2.921149888106259

Epoch: 5| Step: 6
Training loss: 3.513379002611476
Validation loss: 2.9163416216981064

Epoch: 5| Step: 7
Training loss: 3.128389122908705
Validation loss: 2.9119630996409605

Epoch: 5| Step: 8
Training loss: 3.27963929379435
Validation loss: 2.909569139782567

Epoch: 5| Step: 9
Training loss: 2.6519170089152624
Validation loss: 2.9089820256376004

Epoch: 5| Step: 10
Training loss: 3.328739449817012
Validation loss: 2.9102829864758033

Epoch: 225| Step: 0
Training loss: 3.3382441744719626
Validation loss: 2.908673315582359

Epoch: 5| Step: 1
Training loss: 3.524086767628795
Validation loss: 2.9098618709696162

Epoch: 5| Step: 2
Training loss: 2.8431595409389065
Validation loss: 2.909827159535081

Epoch: 5| Step: 3
Training loss: 3.1893511613945047
Validation loss: 2.9085817451376172

Epoch: 5| Step: 4
Training loss: 3.3076427043136647
Validation loss: 2.909425609260307

Epoch: 5| Step: 5
Training loss: 2.76791218294187
Validation loss: 2.9088872710337577

Epoch: 5| Step: 6
Training loss: 3.1666070196323175
Validation loss: 2.9078277775631025

Epoch: 5| Step: 7
Training loss: 3.215348603851083
Validation loss: 2.911060985396756

Epoch: 5| Step: 8
Training loss: 2.7490128566070795
Validation loss: 2.9074606947787283

Epoch: 5| Step: 9
Training loss: 3.1498249489721615
Validation loss: 2.905859317690242

Epoch: 5| Step: 10
Training loss: 3.77601614406335
Validation loss: 2.9038000984696453

Epoch: 226| Step: 0
Training loss: 3.650093307347601
Validation loss: 2.9096485475521496

Epoch: 5| Step: 1
Training loss: 3.0407648883565805
Validation loss: 2.9121925983273167

Epoch: 5| Step: 2
Training loss: 3.237766717359365
Validation loss: 2.9082691007709744

Epoch: 5| Step: 3
Training loss: 3.797963932068981
Validation loss: 2.91578316616241

Epoch: 5| Step: 4
Training loss: 3.2901419637365996
Validation loss: 2.9103059873167614

Epoch: 5| Step: 5
Training loss: 2.4191386854354002
Validation loss: 2.9141040466825396

Epoch: 5| Step: 6
Training loss: 3.344403639749007
Validation loss: 2.908707179690295

Epoch: 5| Step: 7
Training loss: 3.0880305278435243
Validation loss: 2.910111674658165

Epoch: 5| Step: 8
Training loss: 2.9621660004024806
Validation loss: 2.90431479917523

Epoch: 5| Step: 9
Training loss: 3.1213995983004974
Validation loss: 2.9050276690232817

Epoch: 5| Step: 10
Training loss: 2.8425479905666178
Validation loss: 2.9057355238576648

Epoch: 227| Step: 0
Training loss: 2.9485835926147184
Validation loss: 2.9123600651136328

Epoch: 5| Step: 1
Training loss: 3.591524712279053
Validation loss: 2.9083873525390316

Epoch: 5| Step: 2
Training loss: 3.23404548182734
Validation loss: 2.908359927400117

Epoch: 5| Step: 3
Training loss: 3.6002004037813915
Validation loss: 2.911017449006828

Epoch: 5| Step: 4
Training loss: 3.4270199631665257
Validation loss: 2.9155814130924567

Epoch: 5| Step: 5
Training loss: 3.065712314493853
Validation loss: 2.9058702308734508

Epoch: 5| Step: 6
Training loss: 2.5207568595783063
Validation loss: 2.911503746859474

Epoch: 5| Step: 7
Training loss: 3.0672554929701037
Validation loss: 2.9058889887486936

Epoch: 5| Step: 8
Training loss: 2.96166967030811
Validation loss: 2.9022954154139637

Epoch: 5| Step: 9
Training loss: 3.0220777031371693
Validation loss: 2.905481632776982

Epoch: 5| Step: 10
Training loss: 3.490300498639162
Validation loss: 2.9024876006956273

Epoch: 228| Step: 0
Training loss: 3.2143492011203705
Validation loss: 2.902418039890643

Epoch: 5| Step: 1
Training loss: 2.497079287540089
Validation loss: 2.9073990883253993

Epoch: 5| Step: 2
Training loss: 2.8162391390804813
Validation loss: 2.9092724542944683

Epoch: 5| Step: 3
Training loss: 2.918436403602127
Validation loss: 2.9087174317416284

Epoch: 5| Step: 4
Training loss: 3.30253931661762
Validation loss: 2.9114776551397634

Epoch: 5| Step: 5
Training loss: 3.3922698781866747
Validation loss: 2.9182471929774554

Epoch: 5| Step: 6
Training loss: 3.5063476222518624
Validation loss: 2.9076502815335434

Epoch: 5| Step: 7
Training loss: 3.2741580434135296
Validation loss: 2.9099281844375584

Epoch: 5| Step: 8
Training loss: 2.840792281090217
Validation loss: 2.9070021923632092

Epoch: 5| Step: 9
Training loss: 3.152758338259584
Validation loss: 2.9034242409796014

Epoch: 5| Step: 10
Training loss: 4.0275265553201
Validation loss: 2.901738758845396

Epoch: 229| Step: 0
Training loss: 2.4219975594304306
Validation loss: 2.902710519857895

Epoch: 5| Step: 1
Training loss: 3.261979546085786
Validation loss: 2.902057983037073

Epoch: 5| Step: 2
Training loss: 3.1701822508879856
Validation loss: 2.8984888796017976

Epoch: 5| Step: 3
Training loss: 3.7773339035710602
Validation loss: 2.9073749031944027

Epoch: 5| Step: 4
Training loss: 3.7244484461087883
Validation loss: 2.9023598812239455

Epoch: 5| Step: 5
Training loss: 2.640839065813572
Validation loss: 2.9032272001032977

Epoch: 5| Step: 6
Training loss: 2.7843713282979436
Validation loss: 2.9049100597557955

Epoch: 5| Step: 7
Training loss: 3.8743445549655005
Validation loss: 2.901673450951031

Epoch: 5| Step: 8
Training loss: 3.0759463272967955
Validation loss: 2.9022752457326253

Epoch: 5| Step: 9
Training loss: 2.5124076029171305
Validation loss: 2.901454430832888

Epoch: 5| Step: 10
Training loss: 3.4027044759800242
Validation loss: 2.904748799497474

Epoch: 230| Step: 0
Training loss: 3.462409746116135
Validation loss: 2.905953976059919

Epoch: 5| Step: 1
Training loss: 2.7454028284609238
Validation loss: 2.9053585005223694

Epoch: 5| Step: 2
Training loss: 3.0844195918267707
Validation loss: 2.9069023057450534

Epoch: 5| Step: 3
Training loss: 3.3557803772002783
Validation loss: 2.9033008563460267

Epoch: 5| Step: 4
Training loss: 2.776985241892979
Validation loss: 2.914186181145628

Epoch: 5| Step: 5
Training loss: 3.267996916808001
Validation loss: 2.913022608923589

Epoch: 5| Step: 6
Training loss: 3.374937551415159
Validation loss: 2.9119110580201615

Epoch: 5| Step: 7
Training loss: 3.258516011560357
Validation loss: 2.913244948114235

Epoch: 5| Step: 8
Training loss: 2.777994887026647
Validation loss: 2.902756985800899

Epoch: 5| Step: 9
Training loss: 3.2083826597971465
Validation loss: 2.8989328988645515

Epoch: 5| Step: 10
Training loss: 3.6561099294583825
Validation loss: 2.899632757538543

Epoch: 231| Step: 0
Training loss: 3.2601327660795993
Validation loss: 2.8981013564017464

Epoch: 5| Step: 1
Training loss: 3.4003492568653226
Validation loss: 2.9002524813035104

Epoch: 5| Step: 2
Training loss: 3.784155619883142
Validation loss: 2.9024020878546253

Epoch: 5| Step: 3
Training loss: 3.1256020538213978
Validation loss: 2.9097827756242234

Epoch: 5| Step: 4
Training loss: 3.1461700528717316
Validation loss: 2.9048760454786486

Epoch: 5| Step: 5
Training loss: 2.879118415954505
Validation loss: 2.9032381275956958

Epoch: 5| Step: 6
Training loss: 2.9076252626445434
Validation loss: 2.91319510917795

Epoch: 5| Step: 7
Training loss: 2.8333487977746534
Validation loss: 2.9070449484626764

Epoch: 5| Step: 8
Training loss: 3.5689816321244767
Validation loss: 2.8997391212471446

Epoch: 5| Step: 9
Training loss: 2.9431876453303145
Validation loss: 2.8993861236456855

Epoch: 5| Step: 10
Training loss: 3.101695483068888
Validation loss: 2.897129414759474

Epoch: 232| Step: 0
Training loss: 2.518318676993208
Validation loss: 2.899496785501096

Epoch: 5| Step: 1
Training loss: 3.5260654976441885
Validation loss: 2.8968734897492285

Epoch: 5| Step: 2
Training loss: 3.514395129929539
Validation loss: 2.8962763641225475

Epoch: 5| Step: 3
Training loss: 3.28689757654706
Validation loss: 2.8997660187843697

Epoch: 5| Step: 4
Training loss: 2.976329243649224
Validation loss: 2.902796520833318

Epoch: 5| Step: 5
Training loss: 2.976849880012407
Validation loss: 2.9022813715572076

Epoch: 5| Step: 6
Training loss: 3.3816860517156475
Validation loss: 2.908817204912316

Epoch: 5| Step: 7
Training loss: 3.136455444077844
Validation loss: 2.910152012729086

Epoch: 5| Step: 8
Training loss: 3.151789468773057
Validation loss: 2.906335948282291

Epoch: 5| Step: 9
Training loss: 3.1645852493035895
Validation loss: 2.9012597427119395

Epoch: 5| Step: 10
Training loss: 3.2678920050137985
Validation loss: 2.896938447449605

Epoch: 233| Step: 0
Training loss: 3.1194735679576646
Validation loss: 2.896405771128076

Epoch: 5| Step: 1
Training loss: 2.7445922045585807
Validation loss: 2.892854225966156

Epoch: 5| Step: 2
Training loss: 3.513103886615347
Validation loss: 2.893412555481677

Epoch: 5| Step: 3
Training loss: 3.0156308505144835
Validation loss: 2.894278370796424

Epoch: 5| Step: 4
Training loss: 2.8522490210620486
Validation loss: 2.895666975647784

Epoch: 5| Step: 5
Training loss: 3.3041993269843526
Validation loss: 2.8949807423506457

Epoch: 5| Step: 6
Training loss: 3.2178980616515283
Validation loss: 2.898927077694481

Epoch: 5| Step: 7
Training loss: 3.1930896890135987
Validation loss: 2.8947887388329687

Epoch: 5| Step: 8
Training loss: 2.6432576796523755
Validation loss: 2.8967597301758

Epoch: 5| Step: 9
Training loss: 3.8797377879232444
Validation loss: 2.892967306121787

Epoch: 5| Step: 10
Training loss: 3.372401190597619
Validation loss: 2.8927184271670767

Epoch: 234| Step: 0
Training loss: 2.6972262899636803
Validation loss: 2.8943803042176808

Epoch: 5| Step: 1
Training loss: 3.3481731216080064
Validation loss: 2.892906107056531

Epoch: 5| Step: 2
Training loss: 3.340988016700206
Validation loss: 2.8932462248919526

Epoch: 5| Step: 3
Training loss: 3.244721160334921
Validation loss: 2.901227259401467

Epoch: 5| Step: 4
Training loss: 3.365163243317448
Validation loss: 2.8953022665018238

Epoch: 5| Step: 5
Training loss: 3.623628291033332
Validation loss: 2.8963589864376074

Epoch: 5| Step: 6
Training loss: 2.9385774949431944
Validation loss: 2.894819953599382

Epoch: 5| Step: 7
Training loss: 3.3423062353813924
Validation loss: 2.8936200262460856

Epoch: 5| Step: 8
Training loss: 2.600086973642961
Validation loss: 2.892457458700576

Epoch: 5| Step: 9
Training loss: 3.0744555914068292
Validation loss: 2.8909788563104484

Epoch: 5| Step: 10
Training loss: 3.2616870261836746
Validation loss: 2.8895701897548594

Epoch: 235| Step: 0
Training loss: 3.6019811159408825
Validation loss: 2.8923559840058486

Epoch: 5| Step: 1
Training loss: 2.6975736559551025
Validation loss: 2.886828472122505

Epoch: 5| Step: 2
Training loss: 2.6540498485238944
Validation loss: 2.8887966130488216

Epoch: 5| Step: 3
Training loss: 2.9850290590338258
Validation loss: 2.891874650416335

Epoch: 5| Step: 4
Training loss: 3.506910042336978
Validation loss: 2.892963442448454

Epoch: 5| Step: 5
Training loss: 3.602306363621803
Validation loss: 2.889411933808044

Epoch: 5| Step: 6
Training loss: 2.9988637997849525
Validation loss: 2.8887895631976943

Epoch: 5| Step: 7
Training loss: 3.1505106496916975
Validation loss: 2.8894388990883213

Epoch: 5| Step: 8
Training loss: 2.8741218220821723
Validation loss: 2.8886267258397917

Epoch: 5| Step: 9
Training loss: 3.6845942541214605
Validation loss: 2.8926415315957295

Epoch: 5| Step: 10
Training loss: 2.9008208395683326
Validation loss: 2.8898938399219194

Epoch: 236| Step: 0
Training loss: 3.411829866556959
Validation loss: 2.8931864406194396

Epoch: 5| Step: 1
Training loss: 3.5605546424935843
Validation loss: 2.892255817595077

Epoch: 5| Step: 2
Training loss: 3.1983860595025293
Validation loss: 2.8911079896761303

Epoch: 5| Step: 3
Training loss: 2.8444920504414166
Validation loss: 2.89388998965147

Epoch: 5| Step: 4
Training loss: 3.23776907373412
Validation loss: 2.8982822995914863

Epoch: 5| Step: 5
Training loss: 3.1062198138545223
Validation loss: 2.895792238361885

Epoch: 5| Step: 6
Training loss: 2.760109784803844
Validation loss: 2.894254675690915

Epoch: 5| Step: 7
Training loss: 3.636668662802909
Validation loss: 2.894103936051439

Epoch: 5| Step: 8
Training loss: 2.955599600799158
Validation loss: 2.8938085760907164

Epoch: 5| Step: 9
Training loss: 3.0756903765031773
Validation loss: 2.8945311224614705

Epoch: 5| Step: 10
Training loss: 2.9598844160246505
Validation loss: 2.8893616704643157

Epoch: 237| Step: 0
Training loss: 3.1538440863582857
Validation loss: 2.8890192406981168

Epoch: 5| Step: 1
Training loss: 3.632270362353206
Validation loss: 2.8909198445433604

Epoch: 5| Step: 2
Training loss: 3.093198939095067
Validation loss: 2.8943046335086584

Epoch: 5| Step: 3
Training loss: 2.660450475164769
Validation loss: 2.8952580008291657

Epoch: 5| Step: 4
Training loss: 3.133355224478794
Validation loss: 2.8920871255053644

Epoch: 5| Step: 5
Training loss: 3.477135908865678
Validation loss: 2.8883619856048917

Epoch: 5| Step: 6
Training loss: 3.27082418128675
Validation loss: 2.8888862042957553

Epoch: 5| Step: 7
Training loss: 3.0297139788803897
Validation loss: 2.8913967797316777

Epoch: 5| Step: 8
Training loss: 2.9192555155197666
Validation loss: 2.883118737328541

Epoch: 5| Step: 9
Training loss: 3.6431737008915954
Validation loss: 2.882893221007636

Epoch: 5| Step: 10
Training loss: 2.5937270197941897
Validation loss: 2.8819803421414565

Epoch: 238| Step: 0
Training loss: 3.8172875034069667
Validation loss: 2.8840734413831197

Epoch: 5| Step: 1
Training loss: 3.307768988019052
Validation loss: 2.8892580001108654

Epoch: 5| Step: 2
Training loss: 2.9823705522659236
Validation loss: 2.8856913325281703

Epoch: 5| Step: 3
Training loss: 2.7890076191094715
Validation loss: 2.887516186501934

Epoch: 5| Step: 4
Training loss: 3.0629307969383666
Validation loss: 2.890989634123691

Epoch: 5| Step: 5
Training loss: 3.2002896297037333
Validation loss: 2.8859505872216893

Epoch: 5| Step: 6
Training loss: 2.7764505701898017
Validation loss: 2.8876292475313883

Epoch: 5| Step: 7
Training loss: 3.263054232820927
Validation loss: 2.891912755388508

Epoch: 5| Step: 8
Training loss: 3.072726089688669
Validation loss: 2.8868805645153586

Epoch: 5| Step: 9
Training loss: 3.328989409182642
Validation loss: 2.8869560373188463

Epoch: 5| Step: 10
Training loss: 3.137463396930335
Validation loss: 2.8947988276324845

Epoch: 239| Step: 0
Training loss: 2.923286790495394
Validation loss: 2.8851809750599355

Epoch: 5| Step: 1
Training loss: 2.1481104376407245
Validation loss: 2.8870151425396324

Epoch: 5| Step: 2
Training loss: 2.548168485792987
Validation loss: 2.884204578970075

Epoch: 5| Step: 3
Training loss: 3.179295471168599
Validation loss: 2.8874977283338334

Epoch: 5| Step: 4
Training loss: 3.559990249791884
Validation loss: 2.887487885704956

Epoch: 5| Step: 5
Training loss: 3.3641627061575035
Validation loss: 2.888279380392656

Epoch: 5| Step: 6
Training loss: 2.831666194144111
Validation loss: 2.892150495885708

Epoch: 5| Step: 7
Training loss: 2.7852277278422246
Validation loss: 2.8825155152390853

Epoch: 5| Step: 8
Training loss: 3.1463467682122777
Validation loss: 2.8822755729044864

Epoch: 5| Step: 9
Training loss: 4.146962968803076
Validation loss: 2.8868826895737545

Epoch: 5| Step: 10
Training loss: 3.791300004829944
Validation loss: 2.8880709614164797

Epoch: 240| Step: 0
Training loss: 3.5525605598028718
Validation loss: 2.884431781000376

Epoch: 5| Step: 1
Training loss: 3.107429087191112
Validation loss: 2.8842413764574704

Epoch: 5| Step: 2
Training loss: 2.957278282902929
Validation loss: 2.8824622589015005

Epoch: 5| Step: 3
Training loss: 3.2029612429557983
Validation loss: 2.8822406226357336

Epoch: 5| Step: 4
Training loss: 2.2395961554108488
Validation loss: 2.8804827678077034

Epoch: 5| Step: 5
Training loss: 3.0072103318694787
Validation loss: 2.881265740145506

Epoch: 5| Step: 6
Training loss: 3.1431164324923
Validation loss: 2.8830147624554234

Epoch: 5| Step: 7
Training loss: 4.061673828627938
Validation loss: 2.8868625960317678

Epoch: 5| Step: 8
Training loss: 3.5525555935294224
Validation loss: 2.884768117753246

Epoch: 5| Step: 9
Training loss: 2.9559840334717875
Validation loss: 2.8878456897848555

Epoch: 5| Step: 10
Training loss: 2.6209615796303067
Validation loss: 2.8868801799977297

Epoch: 241| Step: 0
Training loss: 3.0836176010922016
Validation loss: 2.884179195816496

Epoch: 5| Step: 1
Training loss: 3.5749815080071077
Validation loss: 2.8838591624348187

Epoch: 5| Step: 2
Training loss: 2.6593009929467644
Validation loss: 2.879656518399565

Epoch: 5| Step: 3
Training loss: 3.3779524145936084
Validation loss: 2.884996031611659

Epoch: 5| Step: 4
Training loss: 3.054439290687108
Validation loss: 2.885342307173057

Epoch: 5| Step: 5
Training loss: 3.21024881295844
Validation loss: 2.881776605067585

Epoch: 5| Step: 6
Training loss: 2.944887327878839
Validation loss: 2.8878237200445724

Epoch: 5| Step: 7
Training loss: 3.246993067690231
Validation loss: 2.8859547516514894

Epoch: 5| Step: 8
Training loss: 3.13593804131823
Validation loss: 2.889479554149351

Epoch: 5| Step: 9
Training loss: 3.2852754151711285
Validation loss: 2.8833999851093

Epoch: 5| Step: 10
Training loss: 3.1533628043262016
Validation loss: 2.8840938094684985

Epoch: 242| Step: 0
Training loss: 3.258040093172314
Validation loss: 2.8804873531036783

Epoch: 5| Step: 1
Training loss: 3.1483900951669277
Validation loss: 2.8751802000094915

Epoch: 5| Step: 2
Training loss: 3.0837787272116852
Validation loss: 2.8808071968660705

Epoch: 5| Step: 3
Training loss: 3.1446528630404216
Validation loss: 2.8805272124750427

Epoch: 5| Step: 4
Training loss: 2.5516123330552123
Validation loss: 2.8804699908846825

Epoch: 5| Step: 5
Training loss: 2.929998844133481
Validation loss: 2.8771281299868465

Epoch: 5| Step: 6
Training loss: 3.1040356670277123
Validation loss: 2.8818982879017065

Epoch: 5| Step: 7
Training loss: 3.1778844271579554
Validation loss: 2.88362987318087

Epoch: 5| Step: 8
Training loss: 3.611733462835731
Validation loss: 2.8798656389183557

Epoch: 5| Step: 9
Training loss: 3.544967878058943
Validation loss: 2.8796624038969543

Epoch: 5| Step: 10
Training loss: 3.1378317790507197
Validation loss: 2.8766970037765827

Epoch: 243| Step: 0
Training loss: 3.536517375440074
Validation loss: 2.876653809979318

Epoch: 5| Step: 1
Training loss: 2.8914452291199444
Validation loss: 2.883494091608603

Epoch: 5| Step: 2
Training loss: 3.2141594604643497
Validation loss: 2.8798083828174823

Epoch: 5| Step: 3
Training loss: 2.907337436477482
Validation loss: 2.8770293501008553

Epoch: 5| Step: 4
Training loss: 3.217363521879582
Validation loss: 2.8777760830121943

Epoch: 5| Step: 5
Training loss: 3.0847541181860065
Validation loss: 2.877693688848682

Epoch: 5| Step: 6
Training loss: 3.373903025619103
Validation loss: 2.877934908435105

Epoch: 5| Step: 7
Training loss: 3.1167022403855986
Validation loss: 2.877060943780388

Epoch: 5| Step: 8
Training loss: 2.6769990029516633
Validation loss: 2.876660290694389

Epoch: 5| Step: 9
Training loss: 3.210017385703092
Validation loss: 2.877971331787943

Epoch: 5| Step: 10
Training loss: 3.5175224100685516
Validation loss: 2.887479656261283

Epoch: 244| Step: 0
Training loss: 3.838351917450992
Validation loss: 2.8798625214554283

Epoch: 5| Step: 1
Training loss: 3.225045131397131
Validation loss: 2.876464075049368

Epoch: 5| Step: 2
Training loss: 2.9000516031869954
Validation loss: 2.8769533317342013

Epoch: 5| Step: 3
Training loss: 3.3579568397879114
Validation loss: 2.8814635265495716

Epoch: 5| Step: 4
Training loss: 3.0977920175362215
Validation loss: 2.8754691623494875

Epoch: 5| Step: 5
Training loss: 2.9156157825647275
Validation loss: 2.876479060441238

Epoch: 5| Step: 6
Training loss: 2.44934256938812
Validation loss: 2.879367070802159

Epoch: 5| Step: 7
Training loss: 3.310246978949684
Validation loss: 2.8745455211010613

Epoch: 5| Step: 8
Training loss: 3.672677719355324
Validation loss: 2.8772838860666403

Epoch: 5| Step: 9
Training loss: 3.3952522170661603
Validation loss: 2.8712080434328673

Epoch: 5| Step: 10
Training loss: 2.0473594965718953
Validation loss: 2.8740428759872

Epoch: 245| Step: 0
Training loss: 3.75389062598368
Validation loss: 2.880424233442445

Epoch: 5| Step: 1
Training loss: 3.0761848958057763
Validation loss: 2.8759411693124832

Epoch: 5| Step: 2
Training loss: 2.9268506773305223
Validation loss: 2.8739934401382086

Epoch: 5| Step: 3
Training loss: 3.383183765080706
Validation loss: 2.873685149127142

Epoch: 5| Step: 4
Training loss: 2.543191973239583
Validation loss: 2.878401984794609

Epoch: 5| Step: 5
Training loss: 3.0271093659267168
Validation loss: 2.8715721737963893

Epoch: 5| Step: 6
Training loss: 3.49025705390995
Validation loss: 2.8754698114018913

Epoch: 5| Step: 7
Training loss: 3.214065401913265
Validation loss: 2.8738952081607514

Epoch: 5| Step: 8
Training loss: 3.3651812389250284
Validation loss: 2.8762815846079492

Epoch: 5| Step: 9
Training loss: 2.9470203416405134
Validation loss: 2.872184455500416

Epoch: 5| Step: 10
Training loss: 2.7683800374806538
Validation loss: 2.87616025332244

Epoch: 246| Step: 0
Training loss: 3.204724317289882
Validation loss: 2.878964296973131

Epoch: 5| Step: 1
Training loss: 3.3719431844610606
Validation loss: 2.876261406310998

Epoch: 5| Step: 2
Training loss: 2.0804531278750686
Validation loss: 2.880687836965705

Epoch: 5| Step: 3
Training loss: 3.616674926560868
Validation loss: 2.876936437401929

Epoch: 5| Step: 4
Training loss: 3.0812897654476354
Validation loss: 2.8789030299820775

Epoch: 5| Step: 5
Training loss: 3.522954328272889
Validation loss: 2.886245777822324

Epoch: 5| Step: 6
Training loss: 2.911545881252799
Validation loss: 2.888349499159427

Epoch: 5| Step: 7
Training loss: 3.4727192756074157
Validation loss: 2.8907058753284924

Epoch: 5| Step: 8
Training loss: 3.279003136970995
Validation loss: 2.8812088891343337

Epoch: 5| Step: 9
Training loss: 3.145508267279151
Validation loss: 2.8825225928860303

Epoch: 5| Step: 10
Training loss: 2.66433329618255
Validation loss: 2.881510431198211

Epoch: 247| Step: 0
Training loss: 3.420707329223321
Validation loss: 2.872770972834453

Epoch: 5| Step: 1
Training loss: 3.0882334220303544
Validation loss: 2.871710242914708

Epoch: 5| Step: 2
Training loss: 3.6738919825989287
Validation loss: 2.870110220390324

Epoch: 5| Step: 3
Training loss: 3.083391206215391
Validation loss: 2.8724081475583314

Epoch: 5| Step: 4
Training loss: 2.714565520814864
Validation loss: 2.8674909984232304

Epoch: 5| Step: 5
Training loss: 2.9811738906198144
Validation loss: 2.8687858381451674

Epoch: 5| Step: 6
Training loss: 2.9828500096883603
Validation loss: 2.8715534827965565

Epoch: 5| Step: 7
Training loss: 3.1139399311541682
Validation loss: 2.869749759257687

Epoch: 5| Step: 8
Training loss: 3.055825414204347
Validation loss: 2.866370884926499

Epoch: 5| Step: 9
Training loss: 3.31974345997016
Validation loss: 2.872167443859163

Epoch: 5| Step: 10
Training loss: 3.204296363087397
Validation loss: 2.869541457832941

Epoch: 248| Step: 0
Training loss: 3.2295714750151365
Validation loss: 2.8702137159573793

Epoch: 5| Step: 1
Training loss: 2.802474655186492
Validation loss: 2.8694269452405248

Epoch: 5| Step: 2
Training loss: 3.662373037383496
Validation loss: 2.8659670360450376

Epoch: 5| Step: 3
Training loss: 3.600017224376587
Validation loss: 2.87224021413238

Epoch: 5| Step: 4
Training loss: 2.483589864021614
Validation loss: 2.870398337351851

Epoch: 5| Step: 5
Training loss: 3.293803008664558
Validation loss: 2.8782052893301793

Epoch: 5| Step: 6
Training loss: 3.1547022886718437
Validation loss: 2.873188444984722

Epoch: 5| Step: 7
Training loss: 3.4933435630163228
Validation loss: 2.8733076676270564

Epoch: 5| Step: 8
Training loss: 2.5986695113201566
Validation loss: 2.8661257573586383

Epoch: 5| Step: 9
Training loss: 2.7522774715710585
Validation loss: 2.873346333777548

Epoch: 5| Step: 10
Training loss: 3.4121737984491287
Validation loss: 2.8672375717813665

Epoch: 249| Step: 0
Training loss: 3.3254438175771823
Validation loss: 2.869242540110843

Epoch: 5| Step: 1
Training loss: 3.452646351777769
Validation loss: 2.8733654288841577

Epoch: 5| Step: 2
Training loss: 3.4296537149976762
Validation loss: 2.8662776464019784

Epoch: 5| Step: 3
Training loss: 3.2713505686255453
Validation loss: 2.869510994609573

Epoch: 5| Step: 4
Training loss: 2.9868642601431534
Validation loss: 2.8743352964270716

Epoch: 5| Step: 5
Training loss: 2.850635116482251
Validation loss: 2.8652075344550654

Epoch: 5| Step: 6
Training loss: 2.7598757711731063
Validation loss: 2.8674777326840317

Epoch: 5| Step: 7
Training loss: 3.7105530228459966
Validation loss: 2.870612427066641

Epoch: 5| Step: 8
Training loss: 2.580499653597969
Validation loss: 2.8711755504985863

Epoch: 5| Step: 9
Training loss: 2.8736997234763426
Validation loss: 2.8727674514496147

Epoch: 5| Step: 10
Training loss: 3.2874831804780795
Validation loss: 2.8696414522654394

Epoch: 250| Step: 0
Training loss: 3.6041438519117737
Validation loss: 2.864296845161743

Epoch: 5| Step: 1
Training loss: 2.840451853629645
Validation loss: 2.865311044269671

Epoch: 5| Step: 2
Training loss: 2.418540775998713
Validation loss: 2.8651683781961386

Epoch: 5| Step: 3
Training loss: 3.314107253057092
Validation loss: 2.863300866169486

Epoch: 5| Step: 4
Training loss: 3.4245674305650367
Validation loss: 2.864311734894569

Epoch: 5| Step: 5
Training loss: 3.4627427329354212
Validation loss: 2.861595209492474

Epoch: 5| Step: 6
Training loss: 3.2156029288050703
Validation loss: 2.8659864674537157

Epoch: 5| Step: 7
Training loss: 3.336301118209684
Validation loss: 2.8656106762659963

Epoch: 5| Step: 8
Training loss: 2.976490250158658
Validation loss: 2.8645358170999367

Epoch: 5| Step: 9
Training loss: 3.0071335856149455
Validation loss: 2.8612797551985927

Epoch: 5| Step: 10
Training loss: 2.85207113667888
Validation loss: 2.866831758724247

Epoch: 251| Step: 0
Training loss: 2.8777721143132484
Validation loss: 2.86976842895221

Epoch: 5| Step: 1
Training loss: 2.5714737608132947
Validation loss: 2.87361658615743

Epoch: 5| Step: 2
Training loss: 4.09552895135139
Validation loss: 2.8648156068365194

Epoch: 5| Step: 3
Training loss: 2.2738846276908657
Validation loss: 2.869548790828738

Epoch: 5| Step: 4
Training loss: 3.4927999825554923
Validation loss: 2.871249493243671

Epoch: 5| Step: 5
Training loss: 2.927419043642382
Validation loss: 2.872536567332358

Epoch: 5| Step: 6
Training loss: 3.4173019717927264
Validation loss: 2.8710091576256898

Epoch: 5| Step: 7
Training loss: 3.2068751270425757
Validation loss: 2.8734305816604397

Epoch: 5| Step: 8
Training loss: 3.2454231019290334
Validation loss: 2.8683900129030246

Epoch: 5| Step: 9
Training loss: 3.2417897911192033
Validation loss: 2.8622389079693136

Epoch: 5| Step: 10
Training loss: 2.870333159512017
Validation loss: 2.8611664530892775

Epoch: 252| Step: 0
Training loss: 3.1831096257666713
Validation loss: 2.8610196457544212

Epoch: 5| Step: 1
Training loss: 3.5853579516186875
Validation loss: 2.863819776927777

Epoch: 5| Step: 2
Training loss: 3.2136470008704463
Validation loss: 2.8598536586058407

Epoch: 5| Step: 3
Training loss: 2.9881944431836156
Validation loss: 2.8594259545232985

Epoch: 5| Step: 4
Training loss: 3.403011637499357
Validation loss: 2.856734455859039

Epoch: 5| Step: 5
Training loss: 3.494191663528165
Validation loss: 2.865451981891033

Epoch: 5| Step: 6
Training loss: 3.198079224140164
Validation loss: 2.8597958530349215

Epoch: 5| Step: 7
Training loss: 2.403973183429963
Validation loss: 2.8591502541921523

Epoch: 5| Step: 8
Training loss: 3.031230965780687
Validation loss: 2.8603432863523452

Epoch: 5| Step: 9
Training loss: 3.010580161823731
Validation loss: 2.8649872012808957

Epoch: 5| Step: 10
Training loss: 2.9982397955538955
Validation loss: 2.8621138723567694

Epoch: 253| Step: 0
Training loss: 3.881538043797744
Validation loss: 2.858173022914962

Epoch: 5| Step: 1
Training loss: 3.223944463171059
Validation loss: 2.8600805828514853

Epoch: 5| Step: 2
Training loss: 2.289829268941704
Validation loss: 2.863380843489218

Epoch: 5| Step: 3
Training loss: 3.2673218621493207
Validation loss: 2.859024117773198

Epoch: 5| Step: 4
Training loss: 3.3433535331909474
Validation loss: 2.861979622906021

Epoch: 5| Step: 5
Training loss: 2.8449382604996347
Validation loss: 2.860292890423921

Epoch: 5| Step: 6
Training loss: 3.569044827176251
Validation loss: 2.8617828602492312

Epoch: 5| Step: 7
Training loss: 3.3798881735727493
Validation loss: 2.862115430901848

Epoch: 5| Step: 8
Training loss: 2.7081823062357886
Validation loss: 2.8582051048718236

Epoch: 5| Step: 9
Training loss: 2.680200199649081
Validation loss: 2.8661509265149165

Epoch: 5| Step: 10
Training loss: 3.098775154063995
Validation loss: 2.861537240213441

Epoch: 254| Step: 0
Training loss: 2.9555624938666694
Validation loss: 2.8665742180529437

Epoch: 5| Step: 1
Training loss: 3.7820153841041666
Validation loss: 2.8665822794608955

Epoch: 5| Step: 2
Training loss: 2.5462503427796466
Validation loss: 2.8642775070101663

Epoch: 5| Step: 3
Training loss: 2.769833998818695
Validation loss: 2.85734604916506

Epoch: 5| Step: 4
Training loss: 3.0155298089533993
Validation loss: 2.862173300692121

Epoch: 5| Step: 5
Training loss: 3.1064319580328323
Validation loss: 2.85553316734109

Epoch: 5| Step: 6
Training loss: 1.9190282439737105
Validation loss: 2.8538957854560345

Epoch: 5| Step: 7
Training loss: 3.820637382937807
Validation loss: 2.8566130876697087

Epoch: 5| Step: 8
Training loss: 3.3990197395454085
Validation loss: 2.857943553950907

Epoch: 5| Step: 9
Training loss: 3.2058120993643193
Validation loss: 2.8610307344554133

Epoch: 5| Step: 10
Training loss: 3.676949359012865
Validation loss: 2.8546068501647524

Epoch: 255| Step: 0
Training loss: 3.8466524160463846
Validation loss: 2.85549582303902

Epoch: 5| Step: 1
Training loss: 3.4168538918409253
Validation loss: 2.855754214671842

Epoch: 5| Step: 2
Training loss: 2.7038072375598188
Validation loss: 2.852854954006717

Epoch: 5| Step: 3
Training loss: 2.907482911155646
Validation loss: 2.8551220146415397

Epoch: 5| Step: 4
Training loss: 2.6084993457877457
Validation loss: 2.85376588812829

Epoch: 5| Step: 5
Training loss: 3.768506226001894
Validation loss: 2.8538671476641646

Epoch: 5| Step: 6
Training loss: 3.2685514780011133
Validation loss: 2.851871074500956

Epoch: 5| Step: 7
Training loss: 2.6250414163864426
Validation loss: 2.851107933908469

Epoch: 5| Step: 8
Training loss: 2.788994625344882
Validation loss: 2.8570821117647176

Epoch: 5| Step: 9
Training loss: 3.125104826122697
Validation loss: 2.8576309028619926

Epoch: 5| Step: 10
Training loss: 3.2795043661556966
Validation loss: 2.8538438666703083

Epoch: 256| Step: 0
Training loss: 3.6522225915733064
Validation loss: 2.8566783703445937

Epoch: 5| Step: 1
Training loss: 2.625393338479432
Validation loss: 2.852648025112597

Epoch: 5| Step: 2
Training loss: 2.9455443273319353
Validation loss: 2.8537183271290663

Epoch: 5| Step: 3
Training loss: 3.2920430286140085
Validation loss: 2.856030836161146

Epoch: 5| Step: 4
Training loss: 3.577224284916271
Validation loss: 2.8580698752972804

Epoch: 5| Step: 5
Training loss: 2.786194424594785
Validation loss: 2.8572047852764677

Epoch: 5| Step: 6
Training loss: 2.7892609854202597
Validation loss: 2.855668197446343

Epoch: 5| Step: 7
Training loss: 3.269020614946444
Validation loss: 2.8564728447704124

Epoch: 5| Step: 8
Training loss: 3.5027795381379416
Validation loss: 2.8531768989270274

Epoch: 5| Step: 9
Training loss: 3.183836832888047
Validation loss: 2.8534820932678486

Epoch: 5| Step: 10
Training loss: 2.690932366407568
Validation loss: 2.8524626817602714

Epoch: 257| Step: 0
Training loss: 3.860010504041225
Validation loss: 2.8535085742320323

Epoch: 5| Step: 1
Training loss: 3.3696830688775727
Validation loss: 2.8528006209548646

Epoch: 5| Step: 2
Training loss: 3.0189137290007833
Validation loss: 2.8511841854972197

Epoch: 5| Step: 3
Training loss: 3.193526312054769
Validation loss: 2.8517314515273124

Epoch: 5| Step: 4
Training loss: 2.89161178654052
Validation loss: 2.848660340182939

Epoch: 5| Step: 5
Training loss: 2.3026550641690684
Validation loss: 2.8528329960729932

Epoch: 5| Step: 6
Training loss: 3.867111544392965
Validation loss: 2.854045772544543

Epoch: 5| Step: 7
Training loss: 2.444837042559862
Validation loss: 2.8493395978779175

Epoch: 5| Step: 8
Training loss: 3.3041134599504276
Validation loss: 2.8497745731680193

Epoch: 5| Step: 9
Training loss: 3.029244929740801
Validation loss: 2.8545100813363016

Epoch: 5| Step: 10
Training loss: 2.878641393271682
Validation loss: 2.854793980547398

Epoch: 258| Step: 0
Training loss: 2.65005182899318
Validation loss: 2.86292951855739

Epoch: 5| Step: 1
Training loss: 2.648967678600112
Validation loss: 2.8624384524032753

Epoch: 5| Step: 2
Training loss: 3.2996075772551188
Validation loss: 2.869912628798209

Epoch: 5| Step: 3
Training loss: 2.811625026657599
Validation loss: 2.8775486984701475

Epoch: 5| Step: 4
Training loss: 3.245950523549391
Validation loss: 2.891058795088541

Epoch: 5| Step: 5
Training loss: 3.3817888433408765
Validation loss: 2.865732558872964

Epoch: 5| Step: 6
Training loss: 3.4342797194116423
Validation loss: 2.8518089530687374

Epoch: 5| Step: 7
Training loss: 3.0299373025985576
Validation loss: 2.848811357927342

Epoch: 5| Step: 8
Training loss: 3.5332611568444556
Validation loss: 2.850524415812439

Epoch: 5| Step: 9
Training loss: 3.4606061307486717
Validation loss: 2.852690861654635

Epoch: 5| Step: 10
Training loss: 2.9356956621891332
Validation loss: 2.8513846968619316

Epoch: 259| Step: 0
Training loss: 2.9679574008773866
Validation loss: 2.8529353463695974

Epoch: 5| Step: 1
Training loss: 3.4231863078557403
Validation loss: 2.85053050535586

Epoch: 5| Step: 2
Training loss: 2.901415012701171
Validation loss: 2.8512128124730625

Epoch: 5| Step: 3
Training loss: 3.6221961654968844
Validation loss: 2.8506522943918178

Epoch: 5| Step: 4
Training loss: 2.336372666667034
Validation loss: 2.849481910256216

Epoch: 5| Step: 5
Training loss: 3.1694613890251127
Validation loss: 2.85030119282548

Epoch: 5| Step: 6
Training loss: 3.415987288377682
Validation loss: 2.85186228202505

Epoch: 5| Step: 7
Training loss: 2.9118440994617676
Validation loss: 2.853014209792598

Epoch: 5| Step: 8
Training loss: 3.142326084079907
Validation loss: 2.8555122355231126

Epoch: 5| Step: 9
Training loss: 3.0112484813415574
Validation loss: 2.865667189030776

Epoch: 5| Step: 10
Training loss: 3.556004005867554
Validation loss: 2.8697057435360946

Epoch: 260| Step: 0
Training loss: 2.777386500033592
Validation loss: 2.874166065413505

Epoch: 5| Step: 1
Training loss: 2.739533882033238
Validation loss: 2.8812927816639218

Epoch: 5| Step: 2
Training loss: 3.263803658601328
Validation loss: 2.8750233071886324

Epoch: 5| Step: 3
Training loss: 3.564187035230746
Validation loss: 2.8721971023706834

Epoch: 5| Step: 4
Training loss: 3.127358881437054
Validation loss: 2.860072528215778

Epoch: 5| Step: 5
Training loss: 3.101966351177177
Validation loss: 2.8660812664724302

Epoch: 5| Step: 6
Training loss: 3.297008782876939
Validation loss: 2.850947986242102

Epoch: 5| Step: 7
Training loss: 3.091644186947541
Validation loss: 2.8546613931092146

Epoch: 5| Step: 8
Training loss: 3.714975573329791
Validation loss: 2.8552245693072367

Epoch: 5| Step: 9
Training loss: 2.983021853789876
Validation loss: 2.8503548072229394

Epoch: 5| Step: 10
Training loss: 2.6231123176869824
Validation loss: 2.8460371107339966

Epoch: 261| Step: 0
Training loss: 3.02482931743217
Validation loss: 2.847916091967017

Epoch: 5| Step: 1
Training loss: 3.1291462666895904
Validation loss: 2.8480329114915284

Epoch: 5| Step: 2
Training loss: 3.0146406869940052
Validation loss: 2.8422640434348696

Epoch: 5| Step: 3
Training loss: 2.8880871328592743
Validation loss: 2.844373360400114

Epoch: 5| Step: 4
Training loss: 3.065342265398846
Validation loss: 2.8459113813090586

Epoch: 5| Step: 5
Training loss: 3.4056415539397125
Validation loss: 2.8455253521504047

Epoch: 5| Step: 6
Training loss: 3.333409658193967
Validation loss: 2.841530106617773

Epoch: 5| Step: 7
Training loss: 2.9068130439974817
Validation loss: 2.842639912421301

Epoch: 5| Step: 8
Training loss: 3.24876644492895
Validation loss: 2.8464923569117557

Epoch: 5| Step: 9
Training loss: 2.8028944654300454
Validation loss: 2.847170298580029

Epoch: 5| Step: 10
Training loss: 3.6954331489207175
Validation loss: 2.846768430304106

Epoch: 262| Step: 0
Training loss: 2.8474772414050693
Validation loss: 2.852870970116728

Epoch: 5| Step: 1
Training loss: 3.193009047584128
Validation loss: 2.846788533980562

Epoch: 5| Step: 2
Training loss: 3.8300560887863657
Validation loss: 2.850159556382872

Epoch: 5| Step: 3
Training loss: 3.01832483429101
Validation loss: 2.851600319250136

Epoch: 5| Step: 4
Training loss: 3.6478891879618445
Validation loss: 2.8542501579440214

Epoch: 5| Step: 5
Training loss: 2.705607867099642
Validation loss: 2.8446531559795507

Epoch: 5| Step: 6
Training loss: 2.891700668208347
Validation loss: 2.8473570263438965

Epoch: 5| Step: 7
Training loss: 3.2734453660966047
Validation loss: 2.8455897107973174

Epoch: 5| Step: 8
Training loss: 2.5377250083043745
Validation loss: 2.845835266799665

Epoch: 5| Step: 9
Training loss: 2.7825921924052435
Validation loss: 2.85228769136264

Epoch: 5| Step: 10
Training loss: 3.5769504801644696
Validation loss: 2.8621011603298134

Epoch: 263| Step: 0
Training loss: 2.7936577220585876
Validation loss: 2.8582695143584176

Epoch: 5| Step: 1
Training loss: 3.7905972548158915
Validation loss: 2.858072592258073

Epoch: 5| Step: 2
Training loss: 3.2534682035110354
Validation loss: 2.860028805471853

Epoch: 5| Step: 3
Training loss: 2.9963229214830447
Validation loss: 2.8610411501787207

Epoch: 5| Step: 4
Training loss: 3.096220321051016
Validation loss: 2.8613876807515375

Epoch: 5| Step: 5
Training loss: 2.9251136170842256
Validation loss: 2.8516966168595324

Epoch: 5| Step: 6
Training loss: 2.903633662769944
Validation loss: 2.8570354790513686

Epoch: 5| Step: 7
Training loss: 2.98177044242401
Validation loss: 2.8444987215958424

Epoch: 5| Step: 8
Training loss: 2.7953249082934932
Validation loss: 2.8433467620116835

Epoch: 5| Step: 9
Training loss: 2.7281875795438344
Validation loss: 2.843803164564256

Epoch: 5| Step: 10
Training loss: 4.0662547439655405
Validation loss: 2.838420490449212

Epoch: 264| Step: 0
Training loss: 3.6244186724488383
Validation loss: 2.841265152052847

Epoch: 5| Step: 1
Training loss: 3.5441238555965553
Validation loss: 2.8412882072329313

Epoch: 5| Step: 2
Training loss: 2.9597012397415776
Validation loss: 2.841567408009066

Epoch: 5| Step: 3
Training loss: 2.664240945785442
Validation loss: 2.838702464490734

Epoch: 5| Step: 4
Training loss: 2.7513780608957163
Validation loss: 2.8411800812227823

Epoch: 5| Step: 5
Training loss: 3.037025533911088
Validation loss: 2.838922912397734

Epoch: 5| Step: 6
Training loss: 2.7141825577486696
Validation loss: 2.8371728434646633

Epoch: 5| Step: 7
Training loss: 3.720588806478691
Validation loss: 2.839744028877079

Epoch: 5| Step: 8
Training loss: 3.2066126746577734
Validation loss: 2.837307525759323

Epoch: 5| Step: 9
Training loss: 3.1884820958508646
Validation loss: 2.8455649192505774

Epoch: 5| Step: 10
Training loss: 2.773672948165044
Validation loss: 2.8380243590729406

Epoch: 265| Step: 0
Training loss: 3.2650017394547555
Validation loss: 2.8468178841566916

Epoch: 5| Step: 1
Training loss: 3.6144933038908884
Validation loss: 2.8398859816701236

Epoch: 5| Step: 2
Training loss: 2.9873252785638007
Validation loss: 2.8557543466352873

Epoch: 5| Step: 3
Training loss: 2.890144926878972
Validation loss: 2.8547570746897644

Epoch: 5| Step: 4
Training loss: 3.413771558013977
Validation loss: 2.8560914924307355

Epoch: 5| Step: 5
Training loss: 3.323489547343465
Validation loss: 2.8505203282294747

Epoch: 5| Step: 6
Training loss: 2.653680703205766
Validation loss: 2.8448345789484444

Epoch: 5| Step: 7
Training loss: 2.9859937501855995
Validation loss: 2.838639352695644

Epoch: 5| Step: 8
Training loss: 2.971763767603659
Validation loss: 2.8412045031873325

Epoch: 5| Step: 9
Training loss: 3.0673050844776113
Validation loss: 2.8386270309095427

Epoch: 5| Step: 10
Training loss: 3.219712196898874
Validation loss: 2.8381484109332415

Epoch: 266| Step: 0
Training loss: 3.069730203559271
Validation loss: 2.836926053302313

Epoch: 5| Step: 1
Training loss: 3.665570499831288
Validation loss: 2.836314604177501

Epoch: 5| Step: 2
Training loss: 3.3296144403169254
Validation loss: 2.840384262903219

Epoch: 5| Step: 3
Training loss: 3.2354115469933604
Validation loss: 2.8352696116970657

Epoch: 5| Step: 4
Training loss: 2.3415629036970618
Validation loss: 2.838949190531915

Epoch: 5| Step: 5
Training loss: 2.2861259294134957
Validation loss: 2.8351187153828894

Epoch: 5| Step: 6
Training loss: 2.6348483310893323
Validation loss: 2.8384154447587697

Epoch: 5| Step: 7
Training loss: 3.3257667173785435
Validation loss: 2.835911636914854

Epoch: 5| Step: 8
Training loss: 3.571477186689556
Validation loss: 2.838176571428175

Epoch: 5| Step: 9
Training loss: 3.562926551312332
Validation loss: 2.8410538751693615

Epoch: 5| Step: 10
Training loss: 3.0136835836008777
Validation loss: 2.844835337721957

Epoch: 267| Step: 0
Training loss: 3.0347691194551256
Validation loss: 2.8594472396227437

Epoch: 5| Step: 1
Training loss: 2.764757009386787
Validation loss: 2.8529611485821937

Epoch: 5| Step: 2
Training loss: 3.8496504984168287
Validation loss: 2.857028727698411

Epoch: 5| Step: 3
Training loss: 2.76263662837549
Validation loss: 2.846002174840754

Epoch: 5| Step: 4
Training loss: 3.4820433885389726
Validation loss: 2.8360465119839913

Epoch: 5| Step: 5
Training loss: 3.2996286761285107
Validation loss: 2.8431072444022893

Epoch: 5| Step: 6
Training loss: 3.2190652341083914
Validation loss: 2.8354626429241945

Epoch: 5| Step: 7
Training loss: 2.7914253718919375
Validation loss: 2.8352884071657702

Epoch: 5| Step: 8
Training loss: 3.5047814542410753
Validation loss: 2.833616600558685

Epoch: 5| Step: 9
Training loss: 3.1387014998893594
Validation loss: 2.830316345800408

Epoch: 5| Step: 10
Training loss: 2.108097622125603
Validation loss: 2.831329479178118

Epoch: 268| Step: 0
Training loss: 3.300238173010577
Validation loss: 2.8300835637486514

Epoch: 5| Step: 1
Training loss: 3.6119510325917794
Validation loss: 2.8339737549000024

Epoch: 5| Step: 2
Training loss: 2.920113098619303
Validation loss: 2.832194879236864

Epoch: 5| Step: 3
Training loss: 3.0466734208158033
Validation loss: 2.8341412131411996

Epoch: 5| Step: 4
Training loss: 3.314985674198548
Validation loss: 2.834306634496626

Epoch: 5| Step: 5
Training loss: 2.8289116034237183
Validation loss: 2.833582219032809

Epoch: 5| Step: 6
Training loss: 3.557004605165621
Validation loss: 2.831465064153934

Epoch: 5| Step: 7
Training loss: 3.074833848387654
Validation loss: 2.8302429966916645

Epoch: 5| Step: 8
Training loss: 2.4948604205273326
Validation loss: 2.83034614576712

Epoch: 5| Step: 9
Training loss: 2.9170068996532237
Validation loss: 2.8312054762499193

Epoch: 5| Step: 10
Training loss: 3.1916384291499496
Validation loss: 2.834433890777842

Epoch: 269| Step: 0
Training loss: 3.5122470479547276
Validation loss: 2.8371693528948554

Epoch: 5| Step: 1
Training loss: 3.0156017559519506
Validation loss: 2.8353713129822893

Epoch: 5| Step: 2
Training loss: 2.6691197695280917
Validation loss: 2.839756881609142

Epoch: 5| Step: 3
Training loss: 3.2545407192995914
Validation loss: 2.8443737840122267

Epoch: 5| Step: 4
Training loss: 2.766940736026366
Validation loss: 2.8429473696250502

Epoch: 5| Step: 5
Training loss: 3.241581503984229
Validation loss: 2.83998493683671

Epoch: 5| Step: 6
Training loss: 3.2030324038635944
Validation loss: 2.837534631334654

Epoch: 5| Step: 7
Training loss: 3.6203056720641267
Validation loss: 2.8392697768265323

Epoch: 5| Step: 8
Training loss: 3.36935602798739
Validation loss: 2.8357223916860512

Epoch: 5| Step: 9
Training loss: 3.0407316434218803
Validation loss: 2.8306505620798728

Epoch: 5| Step: 10
Training loss: 2.3697702148360857
Validation loss: 2.8304294427089327

Epoch: 270| Step: 0
Training loss: 3.6918880410623585
Validation loss: 2.8281535703133414

Epoch: 5| Step: 1
Training loss: 3.1217377992405178
Validation loss: 2.8316844413551117

Epoch: 5| Step: 2
Training loss: 2.294544412940783
Validation loss: 2.8299606096045498

Epoch: 5| Step: 3
Training loss: 3.623699481107991
Validation loss: 2.8280328021615113

Epoch: 5| Step: 4
Training loss: 3.139830835244185
Validation loss: 2.831099815761561

Epoch: 5| Step: 5
Training loss: 3.518084805696594
Validation loss: 2.8282191582053438

Epoch: 5| Step: 6
Training loss: 2.8128587282075714
Validation loss: 2.8328833237729203

Epoch: 5| Step: 7
Training loss: 3.015731256223874
Validation loss: 2.8276386177009765

Epoch: 5| Step: 8
Training loss: 2.8972050187683243
Validation loss: 2.831300157686153

Epoch: 5| Step: 9
Training loss: 2.6379028374259175
Validation loss: 2.829872049961069

Epoch: 5| Step: 10
Training loss: 3.360212212854641
Validation loss: 2.829786571396122

Epoch: 271| Step: 0
Training loss: 3.665271811612739
Validation loss: 2.83330840860463

Epoch: 5| Step: 1
Training loss: 2.23932329191088
Validation loss: 2.8305327099779283

Epoch: 5| Step: 2
Training loss: 3.5459658091833686
Validation loss: 2.833633805640681

Epoch: 5| Step: 3
Training loss: 3.040451085604746
Validation loss: 2.831728962970092

Epoch: 5| Step: 4
Training loss: 2.835432359669291
Validation loss: 2.8311400317930144

Epoch: 5| Step: 5
Training loss: 2.6597645565035855
Validation loss: 2.8300938243307807

Epoch: 5| Step: 6
Training loss: 2.9666962597117514
Validation loss: 2.82838979598784

Epoch: 5| Step: 7
Training loss: 2.920336966210547
Validation loss: 2.827846235297923

Epoch: 5| Step: 8
Training loss: 3.463490115286389
Validation loss: 2.8269077442338264

Epoch: 5| Step: 9
Training loss: 3.3077198302091264
Validation loss: 2.8335055652390193

Epoch: 5| Step: 10
Training loss: 3.442994321793509
Validation loss: 2.828987303311742

Epoch: 272| Step: 0
Training loss: 3.480241042372309
Validation loss: 2.825741889842316

Epoch: 5| Step: 1
Training loss: 3.4726916762991924
Validation loss: 2.829749929169631

Epoch: 5| Step: 2
Training loss: 2.6171265552314074
Validation loss: 2.824959268003149

Epoch: 5| Step: 3
Training loss: 3.2163878726874344
Validation loss: 2.8282221105130416

Epoch: 5| Step: 4
Training loss: 3.06547479757347
Validation loss: 2.832045721880606

Epoch: 5| Step: 5
Training loss: 2.8676202016179793
Validation loss: 2.826965738039013

Epoch: 5| Step: 6
Training loss: 3.0799092190232353
Validation loss: 2.8314593654890974

Epoch: 5| Step: 7
Training loss: 3.1070870267615804
Validation loss: 2.8328058999318766

Epoch: 5| Step: 8
Training loss: 2.8169586444130656
Validation loss: 2.830652655992501

Epoch: 5| Step: 9
Training loss: 3.2577144324455847
Validation loss: 2.830808555753983

Epoch: 5| Step: 10
Training loss: 3.2417434572148087
Validation loss: 2.8319933880349653

Epoch: 273| Step: 0
Training loss: 3.51633537744828
Validation loss: 2.8324979030593873

Epoch: 5| Step: 1
Training loss: 2.837625636877761
Validation loss: 2.8304335529660483

Epoch: 5| Step: 2
Training loss: 3.3711534408642074
Validation loss: 2.8413636802395925

Epoch: 5| Step: 3
Training loss: 2.823349435063025
Validation loss: 2.839974746292851

Epoch: 5| Step: 4
Training loss: 3.7117800749873693
Validation loss: 2.837549601418539

Epoch: 5| Step: 5
Training loss: 3.6983755050897615
Validation loss: 2.829319576251361

Epoch: 5| Step: 6
Training loss: 2.962540889409518
Validation loss: 2.821949885012743

Epoch: 5| Step: 7
Training loss: 2.990846816619159
Validation loss: 2.827395553396962

Epoch: 5| Step: 8
Training loss: 2.508078492696132
Validation loss: 2.8225920371369204

Epoch: 5| Step: 9
Training loss: 3.053216214022969
Validation loss: 2.8235759727278413

Epoch: 5| Step: 10
Training loss: 2.551833772459406
Validation loss: 2.826187718488582

Epoch: 274| Step: 0
Training loss: 3.0084693884969873
Validation loss: 2.8229297743132262

Epoch: 5| Step: 1
Training loss: 2.455935283814729
Validation loss: 2.8233396248634084

Epoch: 5| Step: 2
Training loss: 2.7191128543443437
Validation loss: 2.823732577327011

Epoch: 5| Step: 3
Training loss: 3.452712642852893
Validation loss: 2.8323940430861625

Epoch: 5| Step: 4
Training loss: 3.112499411709282
Validation loss: 2.82047309062638

Epoch: 5| Step: 5
Training loss: 2.7434966611235283
Validation loss: 2.8255879388473955

Epoch: 5| Step: 6
Training loss: 3.4250433202078323
Validation loss: 2.831884886764662

Epoch: 5| Step: 7
Training loss: 4.126102184663057
Validation loss: 2.832469516855093

Epoch: 5| Step: 8
Training loss: 3.350455147868119
Validation loss: 2.832759042249531

Epoch: 5| Step: 9
Training loss: 2.7471504186185127
Validation loss: 2.8257787500652602

Epoch: 5| Step: 10
Training loss: 2.7731708237217383
Validation loss: 2.8253311791454188

Epoch: 275| Step: 0
Training loss: 3.3078641300920166
Validation loss: 2.8493813037273776

Epoch: 5| Step: 1
Training loss: 3.2461837958047015
Validation loss: 2.8497981307435816

Epoch: 5| Step: 2
Training loss: 3.1455704198112002
Validation loss: 2.8518356572250867

Epoch: 5| Step: 3
Training loss: 3.284394710056968
Validation loss: 2.8871407797379063

Epoch: 5| Step: 4
Training loss: 3.666876844682322
Validation loss: 2.8626246105167916

Epoch: 5| Step: 5
Training loss: 2.7309197093010043
Validation loss: 2.8444908481538835

Epoch: 5| Step: 6
Training loss: 2.9173171453369706
Validation loss: 2.8310816019093585

Epoch: 5| Step: 7
Training loss: 3.257326231601181
Validation loss: 2.830883846299643

Epoch: 5| Step: 8
Training loss: 2.8309590171184045
Validation loss: 2.8260638346624583

Epoch: 5| Step: 9
Training loss: 2.97961253495475
Validation loss: 2.8223688458086325

Epoch: 5| Step: 10
Training loss: 2.804476079171259
Validation loss: 2.8283005345336143

Epoch: 276| Step: 0
Training loss: 3.765980304085091
Validation loss: 2.828855951377252

Epoch: 5| Step: 1
Training loss: 2.599248366650098
Validation loss: 2.8287203065954656

Epoch: 5| Step: 2
Training loss: 2.8209510989002404
Validation loss: 2.8225203819697597

Epoch: 5| Step: 3
Training loss: 3.1058969646295447
Validation loss: 2.821193903325354

Epoch: 5| Step: 4
Training loss: 2.922282797359232
Validation loss: 2.8271607462920576

Epoch: 5| Step: 5
Training loss: 3.324866190347488
Validation loss: 2.8196500435875365

Epoch: 5| Step: 6
Training loss: 2.991958649252675
Validation loss: 2.820855828354855

Epoch: 5| Step: 7
Training loss: 3.150642323475655
Validation loss: 2.820727758645979

Epoch: 5| Step: 8
Training loss: 3.23729953218858
Validation loss: 2.821762039237922

Epoch: 5| Step: 9
Training loss: 3.436133928222336
Validation loss: 2.818630568368828

Epoch: 5| Step: 10
Training loss: 2.713090201301676
Validation loss: 2.829567931326613

Epoch: 277| Step: 0
Training loss: 3.101579718938349
Validation loss: 2.825730092908956

Epoch: 5| Step: 1
Training loss: 2.650386127195428
Validation loss: 2.8279876657509884

Epoch: 5| Step: 2
Training loss: 3.294662818154105
Validation loss: 2.8281589021737332

Epoch: 5| Step: 3
Training loss: 3.2097488022198952
Validation loss: 2.824748688297755

Epoch: 5| Step: 4
Training loss: 3.0403816086525897
Validation loss: 2.8207098740840255

Epoch: 5| Step: 5
Training loss: 3.052501315679743
Validation loss: 2.826239182454062

Epoch: 5| Step: 6
Training loss: 2.6533009932414537
Validation loss: 2.821560972822852

Epoch: 5| Step: 7
Training loss: 3.364164548779844
Validation loss: 2.8249595974243573

Epoch: 5| Step: 8
Training loss: 2.857787311624405
Validation loss: 2.8224488267134604

Epoch: 5| Step: 9
Training loss: 3.227484989146127
Validation loss: 2.8180851898799393

Epoch: 5| Step: 10
Training loss: 3.8671978574671906
Validation loss: 2.816745938908031

Epoch: 278| Step: 0
Training loss: 3.580542534790618
Validation loss: 2.8209197337974663

Epoch: 5| Step: 1
Training loss: 2.4582535897807456
Validation loss: 2.821968598406144

Epoch: 5| Step: 2
Training loss: 3.156856063215018
Validation loss: 2.8267475100979738

Epoch: 5| Step: 3
Training loss: 3.2517668982901324
Validation loss: 2.825696928229281

Epoch: 5| Step: 4
Training loss: 2.643770409904318
Validation loss: 2.8261095959672327

Epoch: 5| Step: 5
Training loss: 3.1097514629101433
Validation loss: 2.8270674913938714

Epoch: 5| Step: 6
Training loss: 2.1989999665680555
Validation loss: 2.835722002943644

Epoch: 5| Step: 7
Training loss: 3.800209370918579
Validation loss: 2.844226386622672

Epoch: 5| Step: 8
Training loss: 3.837982813380704
Validation loss: 2.829611266761292

Epoch: 5| Step: 9
Training loss: 2.656968412298388
Validation loss: 2.829332890423143

Epoch: 5| Step: 10
Training loss: 3.1438465202181844
Validation loss: 2.8209137575484884

Epoch: 279| Step: 0
Training loss: 2.62049215266176
Validation loss: 2.8169545117643

Epoch: 5| Step: 1
Training loss: 2.9002831024893
Validation loss: 2.8180303756728655

Epoch: 5| Step: 2
Training loss: 3.2852997992288295
Validation loss: 2.8146253706474784

Epoch: 5| Step: 3
Training loss: 2.7469315315826277
Validation loss: 2.820540447725115

Epoch: 5| Step: 4
Training loss: 3.25663227319533
Validation loss: 2.817557240187943

Epoch: 5| Step: 5
Training loss: 2.944189368501567
Validation loss: 2.8207416477778238

Epoch: 5| Step: 6
Training loss: 2.6387899670268924
Validation loss: 2.818947829662677

Epoch: 5| Step: 7
Training loss: 3.2724600632272782
Validation loss: 2.815301658705448

Epoch: 5| Step: 8
Training loss: 3.7444653676168813
Validation loss: 2.8140441921266026

Epoch: 5| Step: 9
Training loss: 3.8442561118779452
Validation loss: 2.813189237267777

Epoch: 5| Step: 10
Training loss: 2.7128314786962755
Validation loss: 2.8203616123935813

Epoch: 280| Step: 0
Training loss: 3.5888060687822927
Validation loss: 2.817173945116935

Epoch: 5| Step: 1
Training loss: 2.7957190143921977
Validation loss: 2.8268713802868315

Epoch: 5| Step: 2
Training loss: 2.4737212914125735
Validation loss: 2.8192876911002407

Epoch: 5| Step: 3
Training loss: 3.1877725522070253
Validation loss: 2.8350952582780833

Epoch: 5| Step: 4
Training loss: 2.9205851436273447
Validation loss: 2.834092595530181

Epoch: 5| Step: 5
Training loss: 3.20930621436526
Validation loss: 2.839258784626437

Epoch: 5| Step: 6
Training loss: 2.8469666115585377
Validation loss: 2.8472873035685904

Epoch: 5| Step: 7
Training loss: 3.160072052049685
Validation loss: 2.8431155039971943

Epoch: 5| Step: 8
Training loss: 2.9199241612658273
Validation loss: 2.8398681356117637

Epoch: 5| Step: 9
Training loss: 3.5638609846342004
Validation loss: 2.825486102268071

Epoch: 5| Step: 10
Training loss: 3.4329119494708604
Validation loss: 2.823169478217901

Epoch: 281| Step: 0
Training loss: 2.9146963457979647
Validation loss: 2.815053212507971

Epoch: 5| Step: 1
Training loss: 3.5870209430543674
Validation loss: 2.8249336075157

Epoch: 5| Step: 2
Training loss: 3.671834223094726
Validation loss: 2.8191218185930254

Epoch: 5| Step: 3
Training loss: 2.6893498463909373
Validation loss: 2.815688838751515

Epoch: 5| Step: 4
Training loss: 2.9383108764875043
Validation loss: 2.812105232708645

Epoch: 5| Step: 5
Training loss: 2.877861257722681
Validation loss: 2.813008035330688

Epoch: 5| Step: 6
Training loss: 2.494288500626808
Validation loss: 2.8127921751385303

Epoch: 5| Step: 7
Training loss: 3.5201632221265817
Validation loss: 2.817074863917445

Epoch: 5| Step: 8
Training loss: 3.0389807525858736
Validation loss: 2.8170333550318776

Epoch: 5| Step: 9
Training loss: 3.1534902763694608
Validation loss: 2.8103267298954555

Epoch: 5| Step: 10
Training loss: 3.1023026743436475
Validation loss: 2.818142385504325

Epoch: 282| Step: 0
Training loss: 3.9468849598811016
Validation loss: 2.814099780892166

Epoch: 5| Step: 1
Training loss: 3.029541320579428
Validation loss: 2.813648520784507

Epoch: 5| Step: 2
Training loss: 2.3221775355848444
Validation loss: 2.8226659601622504

Epoch: 5| Step: 3
Training loss: 3.5907779511626257
Validation loss: 2.814331767115081

Epoch: 5| Step: 4
Training loss: 3.603313293565986
Validation loss: 2.8177554543411873

Epoch: 5| Step: 5
Training loss: 2.5017169778412662
Validation loss: 2.824585832107635

Epoch: 5| Step: 6
Training loss: 2.892128713083495
Validation loss: 2.81775446809984

Epoch: 5| Step: 7
Training loss: 3.057494763847852
Validation loss: 2.8199312376594405

Epoch: 5| Step: 8
Training loss: 3.4071102630893284
Validation loss: 2.8249980468772287

Epoch: 5| Step: 9
Training loss: 2.7707026362368277
Validation loss: 2.82611780726992

Epoch: 5| Step: 10
Training loss: 2.646941986497402
Validation loss: 2.8131433532735692

Epoch: 283| Step: 0
Training loss: 3.76562879886673
Validation loss: 2.813188247603028

Epoch: 5| Step: 1
Training loss: 2.7976504481600863
Validation loss: 2.8138082526536143

Epoch: 5| Step: 2
Training loss: 3.17078234263528
Validation loss: 2.8061966633802196

Epoch: 5| Step: 3
Training loss: 2.6692531281170937
Validation loss: 2.810731427920667

Epoch: 5| Step: 4
Training loss: 3.4580167755726117
Validation loss: 2.8081280051175503

Epoch: 5| Step: 5
Training loss: 3.1563546947073724
Validation loss: 2.806655351112609

Epoch: 5| Step: 6
Training loss: 3.0318094897343824
Validation loss: 2.809287418839667

Epoch: 5| Step: 7
Training loss: 2.948802064676126
Validation loss: 2.8100261286046004

Epoch: 5| Step: 8
Training loss: 2.5923618140771647
Validation loss: 2.80989850867995

Epoch: 5| Step: 9
Training loss: 3.3079215023224697
Validation loss: 2.808332393053692

Epoch: 5| Step: 10
Training loss: 3.121624153147785
Validation loss: 2.8093025727542456

Epoch: 284| Step: 0
Training loss: 3.355892345615957
Validation loss: 2.812689291942975

Epoch: 5| Step: 1
Training loss: 3.604960462588822
Validation loss: 2.8135386309561192

Epoch: 5| Step: 2
Training loss: 3.7021744550325564
Validation loss: 2.833198215392272

Epoch: 5| Step: 3
Training loss: 2.973543333013344
Validation loss: 2.820854843197476

Epoch: 5| Step: 4
Training loss: 2.740027204364577
Validation loss: 2.825302431479861

Epoch: 5| Step: 5
Training loss: 3.2585957635303058
Validation loss: 2.8218951286147025

Epoch: 5| Step: 6
Training loss: 2.392934543764916
Validation loss: 2.8195470723938434

Epoch: 5| Step: 7
Training loss: 3.1267609784421633
Validation loss: 2.8245734177022124

Epoch: 5| Step: 8
Training loss: 2.68780116678152
Validation loss: 2.826551062066142

Epoch: 5| Step: 9
Training loss: 3.1615203063689163
Validation loss: 2.8171464765007426

Epoch: 5| Step: 10
Training loss: 2.889635566252172
Validation loss: 2.814487070713488

Epoch: 285| Step: 0
Training loss: 3.091209833028409
Validation loss: 2.804848076711097

Epoch: 5| Step: 1
Training loss: 2.6066483739746014
Validation loss: 2.810946921951515

Epoch: 5| Step: 2
Training loss: 3.7517234656498233
Validation loss: 2.8053144949880733

Epoch: 5| Step: 3
Training loss: 2.3220727068798634
Validation loss: 2.8094844252160778

Epoch: 5| Step: 4
Training loss: 2.9906950333545774
Validation loss: 2.8056573748468256

Epoch: 5| Step: 5
Training loss: 3.2561701378574806
Validation loss: 2.8059622686622334

Epoch: 5| Step: 6
Training loss: 2.991111302872542
Validation loss: 2.8058766345768698

Epoch: 5| Step: 7
Training loss: 3.208473763963634
Validation loss: 2.810205295986614

Epoch: 5| Step: 8
Training loss: 3.2138737157142754
Validation loss: 2.8082016232968683

Epoch: 5| Step: 9
Training loss: 3.5641430194728208
Validation loss: 2.808117526420688

Epoch: 5| Step: 10
Training loss: 2.911343776425878
Validation loss: 2.8084273554234467

Epoch: 286| Step: 0
Training loss: 2.4117215852563207
Validation loss: 2.809037781784994

Epoch: 5| Step: 1
Training loss: 3.080567451074181
Validation loss: 2.810179539092086

Epoch: 5| Step: 2
Training loss: 3.1223006224678285
Validation loss: 2.8099146565034716

Epoch: 5| Step: 3
Training loss: 2.675035804437614
Validation loss: 2.8148019064198473

Epoch: 5| Step: 4
Training loss: 3.2056463971003084
Validation loss: 2.8145123555270093

Epoch: 5| Step: 5
Training loss: 4.216059073799789
Validation loss: 2.8175717181706452

Epoch: 5| Step: 6
Training loss: 3.1902515278730283
Validation loss: 2.810053323794402

Epoch: 5| Step: 7
Training loss: 2.4243696592999346
Validation loss: 2.8101048962233093

Epoch: 5| Step: 8
Training loss: 3.197225506343825
Validation loss: 2.8068923165406097

Epoch: 5| Step: 9
Training loss: 3.1740537780359452
Validation loss: 2.8043158751696176

Epoch: 5| Step: 10
Training loss: 3.0304142694574367
Validation loss: 2.8058824582927993

Epoch: 287| Step: 0
Training loss: 3.0973626823868523
Validation loss: 2.806297973987201

Epoch: 5| Step: 1
Training loss: 3.3580120781777274
Validation loss: 2.802995209435046

Epoch: 5| Step: 2
Training loss: 3.074305144166044
Validation loss: 2.8055392815514453

Epoch: 5| Step: 3
Training loss: 2.7206040122661803
Validation loss: 2.804162571750205

Epoch: 5| Step: 4
Training loss: 3.3859061175882568
Validation loss: 2.798206154871893

Epoch: 5| Step: 5
Training loss: 2.748291698793582
Validation loss: 2.8031830580476176

Epoch: 5| Step: 6
Training loss: 2.6513535191866837
Validation loss: 2.8086026112972338

Epoch: 5| Step: 7
Training loss: 3.2651203258360173
Validation loss: 2.8058674933102785

Epoch: 5| Step: 8
Training loss: 3.4915594777942847
Validation loss: 2.8104596866917086

Epoch: 5| Step: 9
Training loss: 3.362870354092262
Validation loss: 2.803699052440395

Epoch: 5| Step: 10
Training loss: 2.7769644648607086
Validation loss: 2.8057582572101523

Epoch: 288| Step: 0
Training loss: 3.5237547061343397
Validation loss: 2.813233219586055

Epoch: 5| Step: 1
Training loss: 3.1033340122483026
Validation loss: 2.8127067444354115

Epoch: 5| Step: 2
Training loss: 2.65153533795752
Validation loss: 2.819047761707783

Epoch: 5| Step: 3
Training loss: 3.422049182656571
Validation loss: 2.811852650220351

Epoch: 5| Step: 4
Training loss: 2.9729383938767753
Validation loss: 2.816345968797898

Epoch: 5| Step: 5
Training loss: 3.1268953297770214
Validation loss: 2.8041857939295474

Epoch: 5| Step: 6
Training loss: 3.1308136839694676
Validation loss: 2.811278481055192

Epoch: 5| Step: 7
Training loss: 3.253871226036372
Validation loss: 2.8157950675097343

Epoch: 5| Step: 8
Training loss: 2.94938382324658
Validation loss: 2.8121119761358906

Epoch: 5| Step: 9
Training loss: 2.637224343887003
Validation loss: 2.81864582576217

Epoch: 5| Step: 10
Training loss: 3.196643057992237
Validation loss: 2.8165869211202814

Epoch: 289| Step: 0
Training loss: 2.7391211599715533
Validation loss: 2.805309179109325

Epoch: 5| Step: 1
Training loss: 2.8750431223413444
Validation loss: 2.8146752280399863

Epoch: 5| Step: 2
Training loss: 2.989712241624556
Validation loss: 2.8042819023239702

Epoch: 5| Step: 3
Training loss: 2.785916817118174
Validation loss: 2.7974344678073684

Epoch: 5| Step: 4
Training loss: 3.704581058924687
Validation loss: 2.7989842686787516

Epoch: 5| Step: 5
Training loss: 3.5624670729872245
Validation loss: 2.7970833026245767

Epoch: 5| Step: 6
Training loss: 3.0602653291148663
Validation loss: 2.8036920236081633

Epoch: 5| Step: 7
Training loss: 3.1641464410643967
Validation loss: 2.7995656954458283

Epoch: 5| Step: 8
Training loss: 2.987874480842367
Validation loss: 2.7989881869740723

Epoch: 5| Step: 9
Training loss: 3.080143610343413
Validation loss: 2.796051796104372

Epoch: 5| Step: 10
Training loss: 3.0720275282222445
Validation loss: 2.7990020470525274

Epoch: 290| Step: 0
Training loss: 3.53201974226898
Validation loss: 2.797704772815245

Epoch: 5| Step: 1
Training loss: 2.907024977527834
Validation loss: 2.800238286447068

Epoch: 5| Step: 2
Training loss: 2.576831192432522
Validation loss: 2.7995362628781493

Epoch: 5| Step: 3
Training loss: 2.8794372151772056
Validation loss: 2.798942965042734

Epoch: 5| Step: 4
Training loss: 2.804851134050752
Validation loss: 2.8005318479346855

Epoch: 5| Step: 5
Training loss: 3.2389542601589567
Validation loss: 2.798227547427232

Epoch: 5| Step: 6
Training loss: 3.3688691579944927
Validation loss: 2.803802715382704

Epoch: 5| Step: 7
Training loss: 2.926656798285992
Validation loss: 2.8022842634054745

Epoch: 5| Step: 8
Training loss: 2.954543484507084
Validation loss: 2.8025241542722696

Epoch: 5| Step: 9
Training loss: 3.572013332995642
Validation loss: 2.8063483264593234

Epoch: 5| Step: 10
Training loss: 3.19063264582481
Validation loss: 2.8024232195224585

Epoch: 291| Step: 0
Training loss: 2.759718800746173
Validation loss: 2.8112986999115424

Epoch: 5| Step: 1
Training loss: 3.06312928254537
Validation loss: 2.8174725144733297

Epoch: 5| Step: 2
Training loss: 3.4418784260356112
Validation loss: 2.8237390260675146

Epoch: 5| Step: 3
Training loss: 3.5438012067267333
Validation loss: 2.8309472826764708

Epoch: 5| Step: 4
Training loss: 2.5178248104813874
Validation loss: 2.827537418020441

Epoch: 5| Step: 5
Training loss: 3.600660761486914
Validation loss: 2.839642025575417

Epoch: 5| Step: 6
Training loss: 2.9565176070469814
Validation loss: 2.813877852910414

Epoch: 5| Step: 7
Training loss: 2.7697610907691956
Validation loss: 2.7973256328156566

Epoch: 5| Step: 8
Training loss: 3.3934828848069265
Validation loss: 2.7976810872340168

Epoch: 5| Step: 9
Training loss: 2.9078007324243016
Validation loss: 2.798367479106694

Epoch: 5| Step: 10
Training loss: 2.9367040002061255
Validation loss: 2.7956525191375263

Epoch: 292| Step: 0
Training loss: 3.0464333238566215
Validation loss: 2.8020583328270536

Epoch: 5| Step: 1
Training loss: 3.809990729373256
Validation loss: 2.799346111748128

Epoch: 5| Step: 2
Training loss: 2.7823888611511878
Validation loss: 2.798451847913522

Epoch: 5| Step: 3
Training loss: 3.1696774240984453
Validation loss: 2.798821255221827

Epoch: 5| Step: 4
Training loss: 2.821560401320007
Validation loss: 2.799703964208924

Epoch: 5| Step: 5
Training loss: 3.3621771902108346
Validation loss: 2.7943830252081123

Epoch: 5| Step: 6
Training loss: 2.898748417138724
Validation loss: 2.795666573193727

Epoch: 5| Step: 7
Training loss: 3.419205551899467
Validation loss: 2.795488145808502

Epoch: 5| Step: 8
Training loss: 2.8436037801522374
Validation loss: 2.800429437083912

Epoch: 5| Step: 9
Training loss: 2.875298194348005
Validation loss: 2.7940588218717726

Epoch: 5| Step: 10
Training loss: 2.8662904588627915
Validation loss: 2.7952831277887475

Epoch: 293| Step: 0
Training loss: 2.573873169644205
Validation loss: 2.799164260052237

Epoch: 5| Step: 1
Training loss: 2.9585809917391437
Validation loss: 2.79767483775521

Epoch: 5| Step: 2
Training loss: 3.329758220979515
Validation loss: 2.8037934091724104

Epoch: 5| Step: 3
Training loss: 2.9444925396268147
Validation loss: 2.8123499402995007

Epoch: 5| Step: 4
Training loss: 2.816292219459295
Validation loss: 2.811573655357536

Epoch: 5| Step: 5
Training loss: 3.6397392275954963
Validation loss: 2.819437573407695

Epoch: 5| Step: 6
Training loss: 3.2502789010907183
Validation loss: 2.805349421258087

Epoch: 5| Step: 7
Training loss: 3.2913332098248125
Validation loss: 2.8116240473838707

Epoch: 5| Step: 8
Training loss: 3.3752131924581383
Validation loss: 2.8090876114946925

Epoch: 5| Step: 9
Training loss: 2.8517151674136616
Validation loss: 2.79747743042727

Epoch: 5| Step: 10
Training loss: 2.807891036237093
Validation loss: 2.796665262843836

Epoch: 294| Step: 0
Training loss: 2.9493173746961467
Validation loss: 2.795526876807493

Epoch: 5| Step: 1
Training loss: 2.7567022320237857
Validation loss: 2.791345977975143

Epoch: 5| Step: 2
Training loss: 2.80043170189526
Validation loss: 2.7988253377040353

Epoch: 5| Step: 3
Training loss: 3.3324927382737046
Validation loss: 2.791310324506945

Epoch: 5| Step: 4
Training loss: 3.4154139447423395
Validation loss: 2.7925477477962315

Epoch: 5| Step: 5
Training loss: 3.290785675618211
Validation loss: 2.8002420409429796

Epoch: 5| Step: 6
Training loss: 3.257669642401365
Validation loss: 2.808896984349302

Epoch: 5| Step: 7
Training loss: 3.569641183724492
Validation loss: 2.8034022963973855

Epoch: 5| Step: 8
Training loss: 2.6058120615739235
Validation loss: 2.8074526134050166

Epoch: 5| Step: 9
Training loss: 2.9641104332844224
Validation loss: 2.816740815255278

Epoch: 5| Step: 10
Training loss: 2.9274374497635014
Validation loss: 2.8216524699349765

Epoch: 295| Step: 0
Training loss: 2.6433692531702713
Validation loss: 2.827014366673317

Epoch: 5| Step: 1
Training loss: 3.0638617777112467
Validation loss: 2.8355746069671124

Epoch: 5| Step: 2
Training loss: 3.6139079112409846
Validation loss: 2.8289727804433524

Epoch: 5| Step: 3
Training loss: 3.1871445401525516
Validation loss: 2.8093638929841735

Epoch: 5| Step: 4
Training loss: 3.4316585499051633
Validation loss: 2.7912504363092374

Epoch: 5| Step: 5
Training loss: 2.9802042792536123
Validation loss: 2.788921746631545

Epoch: 5| Step: 6
Training loss: 2.790794625418694
Validation loss: 2.7917238482767335

Epoch: 5| Step: 7
Training loss: 3.271824988098627
Validation loss: 2.7957846011856833

Epoch: 5| Step: 8
Training loss: 3.269300081200112
Validation loss: 2.793815961486102

Epoch: 5| Step: 9
Training loss: 3.151201648696813
Validation loss: 2.7892989692646224

Epoch: 5| Step: 10
Training loss: 2.449306261363978
Validation loss: 2.792179919725265

Epoch: 296| Step: 0
Training loss: 2.8153466124092343
Validation loss: 2.7948324362411974

Epoch: 5| Step: 1
Training loss: 2.772155121386393
Validation loss: 2.8059826372885426

Epoch: 5| Step: 2
Training loss: 3.0031384899459637
Validation loss: 2.81257161877596

Epoch: 5| Step: 3
Training loss: 3.5172179279680447
Validation loss: 2.8109089442579407

Epoch: 5| Step: 4
Training loss: 3.5829346161438687
Validation loss: 2.8130779789081575

Epoch: 5| Step: 5
Training loss: 2.9527266299280783
Validation loss: 2.8015257330948127

Epoch: 5| Step: 6
Training loss: 2.9397305075726448
Validation loss: 2.792968849132217

Epoch: 5| Step: 7
Training loss: 2.6369813237315474
Validation loss: 2.7914272096065598

Epoch: 5| Step: 8
Training loss: 2.6350453131469385
Validation loss: 2.7911293343436534

Epoch: 5| Step: 9
Training loss: 3.9602004349200826
Validation loss: 2.7878021428542934

Epoch: 5| Step: 10
Training loss: 2.9630201760260757
Validation loss: 2.789315894413053

Epoch: 297| Step: 0
Training loss: 3.3771304717746204
Validation loss: 2.7892266508959858

Epoch: 5| Step: 1
Training loss: 3.4388757900248086
Validation loss: 2.7844083623783025

Epoch: 5| Step: 2
Training loss: 2.8443674947178192
Validation loss: 2.789825385672674

Epoch: 5| Step: 3
Training loss: 3.1581140433671937
Validation loss: 2.786084130068393

Epoch: 5| Step: 4
Training loss: 2.934315680248555
Validation loss: 2.799986360263271

Epoch: 5| Step: 5
Training loss: 3.2982365838411716
Validation loss: 2.806631209454682

Epoch: 5| Step: 6
Training loss: 2.786877542970656
Validation loss: 2.8190681521897125

Epoch: 5| Step: 7
Training loss: 2.724902940473965
Validation loss: 2.8149267576377763

Epoch: 5| Step: 8
Training loss: 3.7342838292185405
Validation loss: 2.8134576331616747

Epoch: 5| Step: 9
Training loss: 3.0927900886629436
Validation loss: 2.80147123362512

Epoch: 5| Step: 10
Training loss: 2.255702844779004
Validation loss: 2.7936130507091685

Epoch: 298| Step: 0
Training loss: 2.684607523927033
Validation loss: 2.783843201841361

Epoch: 5| Step: 1
Training loss: 2.6899869191018317
Validation loss: 2.785833256721106

Epoch: 5| Step: 2
Training loss: 2.817222868347729
Validation loss: 2.786555562217246

Epoch: 5| Step: 3
Training loss: 2.67485103727184
Validation loss: 2.7897665205461237

Epoch: 5| Step: 4
Training loss: 3.5276903423644383
Validation loss: 2.792619725873385

Epoch: 5| Step: 5
Training loss: 3.4224324926234764
Validation loss: 2.7905984658338485

Epoch: 5| Step: 6
Training loss: 3.7587719364623484
Validation loss: 2.790555953111518

Epoch: 5| Step: 7
Training loss: 2.3883282967208426
Validation loss: 2.7915119415392957

Epoch: 5| Step: 8
Training loss: 2.955229962690764
Validation loss: 2.7853227038735877

Epoch: 5| Step: 9
Training loss: 3.5693288570808708
Validation loss: 2.787326806591159

Epoch: 5| Step: 10
Training loss: 3.23942959697684
Validation loss: 2.785072893225009

Epoch: 299| Step: 0
Training loss: 3.3900223297463983
Validation loss: 2.7881912916393103

Epoch: 5| Step: 1
Training loss: 3.2532177181754354
Validation loss: 2.790327913427512

Epoch: 5| Step: 2
Training loss: 3.3044814458145204
Validation loss: 2.789879392217259

Epoch: 5| Step: 3
Training loss: 3.0546715777438296
Validation loss: 2.791761308246452

Epoch: 5| Step: 4
Training loss: 2.630594468178621
Validation loss: 2.7890098251755466

Epoch: 5| Step: 5
Training loss: 3.530631492258978
Validation loss: 2.79352182548182

Epoch: 5| Step: 6
Training loss: 2.8715077627197636
Validation loss: 2.8138198918409514

Epoch: 5| Step: 7
Training loss: 2.868664270254463
Validation loss: 2.8197399816461455

Epoch: 5| Step: 8
Training loss: 2.8656081337468824
Validation loss: 2.8377526675320794

Epoch: 5| Step: 9
Training loss: 3.0380594123018367
Validation loss: 2.8105499617142704

Epoch: 5| Step: 10
Training loss: 3.163834476496128
Validation loss: 2.801015396869647

Epoch: 300| Step: 0
Training loss: 2.5136001683391123
Validation loss: 2.793482066366186

Epoch: 5| Step: 1
Training loss: 2.9486139953219044
Validation loss: 2.780493135188625

Epoch: 5| Step: 2
Training loss: 2.529079212853262
Validation loss: 2.7817854329597407

Epoch: 5| Step: 3
Training loss: 2.6895399114253995
Validation loss: 2.7830887952032164

Epoch: 5| Step: 4
Training loss: 3.313161244160865
Validation loss: 2.7836518543893014

Epoch: 5| Step: 5
Training loss: 3.0474467988099723
Validation loss: 2.7824856242985705

Epoch: 5| Step: 6
Training loss: 2.7507494858801347
Validation loss: 2.785441981015348

Epoch: 5| Step: 7
Training loss: 3.3027785539069163
Validation loss: 2.786379880186945

Epoch: 5| Step: 8
Training loss: 3.5826226498145677
Validation loss: 2.788917342631326

Epoch: 5| Step: 9
Training loss: 3.315346987876897
Validation loss: 2.782813234449982

Epoch: 5| Step: 10
Training loss: 3.817776515017049
Validation loss: 2.785358677890901

Epoch: 301| Step: 0
Training loss: 2.9479939121509564
Validation loss: 2.7842529776167333

Epoch: 5| Step: 1
Training loss: 2.7921458919522455
Validation loss: 2.7859115212795507

Epoch: 5| Step: 2
Training loss: 3.7216588032000626
Validation loss: 2.7842946529368136

Epoch: 5| Step: 3
Training loss: 3.1262488349384636
Validation loss: 2.7824912680167806

Epoch: 5| Step: 4
Training loss: 3.3605126162455203
Validation loss: 2.781126819006036

Epoch: 5| Step: 5
Training loss: 3.01009815119404
Validation loss: 2.781541463178918

Epoch: 5| Step: 6
Training loss: 3.0795828373280254
Validation loss: 2.782603422276705

Epoch: 5| Step: 7
Training loss: 2.996639276647375
Validation loss: 2.7893739841603784

Epoch: 5| Step: 8
Training loss: 3.3815474402283843
Validation loss: 2.787565270712809

Epoch: 5| Step: 9
Training loss: 3.030896824977661
Validation loss: 2.8007745561797055

Epoch: 5| Step: 10
Training loss: 2.0826242257351413
Validation loss: 2.8161215687285335

Epoch: 302| Step: 0
Training loss: 2.4693362348792136
Validation loss: 2.849415827510625

Epoch: 5| Step: 1
Training loss: 3.3713237378999277
Validation loss: 2.871314445821401

Epoch: 5| Step: 2
Training loss: 2.6997242080271753
Validation loss: 2.8357600370674994

Epoch: 5| Step: 3
Training loss: 3.2304082308985094
Validation loss: 2.8237102249687296

Epoch: 5| Step: 4
Training loss: 3.282612835469314
Validation loss: 2.8045189777975414

Epoch: 5| Step: 5
Training loss: 3.092645775605668
Validation loss: 2.789464823938737

Epoch: 5| Step: 6
Training loss: 3.1119101459505103
Validation loss: 2.7871900798113662

Epoch: 5| Step: 7
Training loss: 2.9439025256253477
Validation loss: 2.778910297198722

Epoch: 5| Step: 8
Training loss: 2.995055893008692
Validation loss: 2.780286182490895

Epoch: 5| Step: 9
Training loss: 3.1642237492669203
Validation loss: 2.779455010585296

Epoch: 5| Step: 10
Training loss: 3.582094347948214
Validation loss: 2.7794517758889596

Epoch: 303| Step: 0
Training loss: 3.3544756981945527
Validation loss: 2.780442475846051

Epoch: 5| Step: 1
Training loss: 2.7308459369305327
Validation loss: 2.781756756897156

Epoch: 5| Step: 2
Training loss: 2.598851529808276
Validation loss: 2.782121100434799

Epoch: 5| Step: 3
Training loss: 3.8790465115391544
Validation loss: 2.783243425182198

Epoch: 5| Step: 4
Training loss: 3.1556766102484644
Validation loss: 2.7808944937662754

Epoch: 5| Step: 5
Training loss: 3.338579261952947
Validation loss: 2.7797010218696125

Epoch: 5| Step: 6
Training loss: 2.744219339673985
Validation loss: 2.7800907310525518

Epoch: 5| Step: 7
Training loss: 2.2468177756289727
Validation loss: 2.7851000458008066

Epoch: 5| Step: 8
Training loss: 3.1796467096585097
Validation loss: 2.780026664443708

Epoch: 5| Step: 9
Training loss: 2.9222645219449697
Validation loss: 2.7800345028270446

Epoch: 5| Step: 10
Training loss: 3.5739834066986687
Validation loss: 2.776029897559171

Epoch: 304| Step: 0
Training loss: 3.34041450486778
Validation loss: 2.776434315457108

Epoch: 5| Step: 1
Training loss: 3.3967645846532677
Validation loss: 2.7798071918035765

Epoch: 5| Step: 2
Training loss: 2.7592198398466317
Validation loss: 2.7794276340700623

Epoch: 5| Step: 3
Training loss: 3.6059603040883084
Validation loss: 2.781304080884852

Epoch: 5| Step: 4
Training loss: 3.004824573645488
Validation loss: 2.7849495388826564

Epoch: 5| Step: 5
Training loss: 2.8339313736106018
Validation loss: 2.795955185666037

Epoch: 5| Step: 6
Training loss: 2.274556621900829
Validation loss: 2.7988343682397785

Epoch: 5| Step: 7
Training loss: 2.7745868719005538
Validation loss: 2.801206922329538

Epoch: 5| Step: 8
Training loss: 3.2850032593872065
Validation loss: 2.8141390792703915

Epoch: 5| Step: 9
Training loss: 2.9747485142688164
Validation loss: 2.8087388552430146

Epoch: 5| Step: 10
Training loss: 3.471455249425965
Validation loss: 2.8069786338482077

Epoch: 305| Step: 0
Training loss: 3.6866191523170597
Validation loss: 2.7942993528369082

Epoch: 5| Step: 1
Training loss: 2.8059858541913782
Validation loss: 2.786845950764676

Epoch: 5| Step: 2
Training loss: 2.677231444381884
Validation loss: 2.7838473449664582

Epoch: 5| Step: 3
Training loss: 3.193269482201888
Validation loss: 2.7866287383281194

Epoch: 5| Step: 4
Training loss: 2.853497243374231
Validation loss: 2.7814500770624906

Epoch: 5| Step: 5
Training loss: 3.3660671556452164
Validation loss: 2.7799885022670816

Epoch: 5| Step: 6
Training loss: 3.079357384611381
Validation loss: 2.7808109041450813

Epoch: 5| Step: 7
Training loss: 2.6245947933799716
Validation loss: 2.7783862426508437

Epoch: 5| Step: 8
Training loss: 2.7357585785299112
Validation loss: 2.7748611191135333

Epoch: 5| Step: 9
Training loss: 2.8425786886336533
Validation loss: 2.7771256198794103

Epoch: 5| Step: 10
Training loss: 3.862433576784305
Validation loss: 2.784140179868353

Epoch: 306| Step: 0
Training loss: 3.3351020570892835
Validation loss: 2.7764897671204394

Epoch: 5| Step: 1
Training loss: 3.0979182359853503
Validation loss: 2.779469985879759

Epoch: 5| Step: 2
Training loss: 3.3260729557186046
Validation loss: 2.7768799703638747

Epoch: 5| Step: 3
Training loss: 2.917329731003922
Validation loss: 2.7724213340749313

Epoch: 5| Step: 4
Training loss: 3.032043667743027
Validation loss: 2.7819332266669465

Epoch: 5| Step: 5
Training loss: 3.5659704871804387
Validation loss: 2.776765358984538

Epoch: 5| Step: 6
Training loss: 3.121528986637238
Validation loss: 2.775310350228658

Epoch: 5| Step: 7
Training loss: 2.823215163849394
Validation loss: 2.774739579021701

Epoch: 5| Step: 8
Training loss: 2.62552328797624
Validation loss: 2.7736454350909696

Epoch: 5| Step: 9
Training loss: 2.7889957366560627
Validation loss: 2.771620243076817

Epoch: 5| Step: 10
Training loss: 3.157454006074526
Validation loss: 2.7829400596796603

Epoch: 307| Step: 0
Training loss: 2.6480665819262272
Validation loss: 2.777074199363287

Epoch: 5| Step: 1
Training loss: 3.4181552683483525
Validation loss: 2.7803460422261517

Epoch: 5| Step: 2
Training loss: 3.308582940922795
Validation loss: 2.7817398309143075

Epoch: 5| Step: 3
Training loss: 2.7193044338307026
Validation loss: 2.7909550213556726

Epoch: 5| Step: 4
Training loss: 3.033622835478163
Validation loss: 2.7937655639141497

Epoch: 5| Step: 5
Training loss: 3.1343065157375287
Validation loss: 2.8047787688061465

Epoch: 5| Step: 6
Training loss: 3.1638144313441403
Validation loss: 2.79703893253828

Epoch: 5| Step: 7
Training loss: 2.765592585659268
Validation loss: 2.810919553001301

Epoch: 5| Step: 8
Training loss: 3.2634629388723804
Validation loss: 2.7952831442971044

Epoch: 5| Step: 9
Training loss: 2.6164321037010665
Validation loss: 2.797964700830443

Epoch: 5| Step: 10
Training loss: 3.709901299616078
Validation loss: 2.7940498584793976

Epoch: 308| Step: 0
Training loss: 2.9482955599259717
Validation loss: 2.7844855851793424

Epoch: 5| Step: 1
Training loss: 3.071087222600622
Validation loss: 2.7719753563290115

Epoch: 5| Step: 2
Training loss: 3.313883654396746
Validation loss: 2.771878412642323

Epoch: 5| Step: 3
Training loss: 3.1797249906611973
Validation loss: 2.7728494203532

Epoch: 5| Step: 4
Training loss: 3.3938410400768713
Validation loss: 2.7685911025540566

Epoch: 5| Step: 5
Training loss: 2.7681176972696626
Validation loss: 2.7676227923271415

Epoch: 5| Step: 6
Training loss: 2.589046764153297
Validation loss: 2.7698991193534304

Epoch: 5| Step: 7
Training loss: 2.5783496180856225
Validation loss: 2.769085706673863

Epoch: 5| Step: 8
Training loss: 3.2280343972681407
Validation loss: 2.771062224528105

Epoch: 5| Step: 9
Training loss: 3.070904934245497
Validation loss: 2.7708351072949835

Epoch: 5| Step: 10
Training loss: 3.621578048368529
Validation loss: 2.771850457234089

Epoch: 309| Step: 0
Training loss: 3.3859763910289553
Validation loss: 2.7692426923471136

Epoch: 5| Step: 1
Training loss: 3.0461672229813996
Validation loss: 2.7680851231854553

Epoch: 5| Step: 2
Training loss: 3.152925005223247
Validation loss: 2.7724154363720235

Epoch: 5| Step: 3
Training loss: 2.8869797275044182
Validation loss: 2.7745574256800083

Epoch: 5| Step: 4
Training loss: 3.685597074214303
Validation loss: 2.777161174825119

Epoch: 5| Step: 5
Training loss: 2.790185696838
Validation loss: 2.7720273097947703

Epoch: 5| Step: 6
Training loss: 3.0779702394569886
Validation loss: 2.7776487936474825

Epoch: 5| Step: 7
Training loss: 3.2469424023208755
Validation loss: 2.777948215000271

Epoch: 5| Step: 8
Training loss: 2.9299820815440056
Validation loss: 2.7798804441116243

Epoch: 5| Step: 9
Training loss: 2.345981400346969
Validation loss: 2.794393545775043

Epoch: 5| Step: 10
Training loss: 3.095809559240911
Validation loss: 2.7990684320527786

Epoch: 310| Step: 0
Training loss: 3.4018380526166245
Validation loss: 2.7819011719113673

Epoch: 5| Step: 1
Training loss: 2.7680207129458703
Validation loss: 2.7951941380744914

Epoch: 5| Step: 2
Training loss: 3.145810680855209
Validation loss: 2.784415615744904

Epoch: 5| Step: 3
Training loss: 3.0469468328371323
Validation loss: 2.774841064362689

Epoch: 5| Step: 4
Training loss: 3.0379798353177665
Validation loss: 2.7708057599881966

Epoch: 5| Step: 5
Training loss: 3.3560430992187027
Validation loss: 2.772673474569584

Epoch: 5| Step: 6
Training loss: 3.165497329713198
Validation loss: 2.7699456345381632

Epoch: 5| Step: 7
Training loss: 2.5062163315031225
Validation loss: 2.7699526055475316

Epoch: 5| Step: 8
Training loss: 3.117359280932112
Validation loss: 2.7685670456707503

Epoch: 5| Step: 9
Training loss: 2.767993839246035
Validation loss: 2.7660400772512483

Epoch: 5| Step: 10
Training loss: 3.4461866727316135
Validation loss: 2.7677723305980853

Epoch: 311| Step: 0
Training loss: 2.7825429247126903
Validation loss: 2.768426830994688

Epoch: 5| Step: 1
Training loss: 2.8590344502420564
Validation loss: 2.7695842749241066

Epoch: 5| Step: 2
Training loss: 3.098479537948011
Validation loss: 2.7699990661549627

Epoch: 5| Step: 3
Training loss: 3.871225795553167
Validation loss: 2.768093382509884

Epoch: 5| Step: 4
Training loss: 2.75044611000036
Validation loss: 2.7713268345416133

Epoch: 5| Step: 5
Training loss: 3.278730460547552
Validation loss: 2.7733998378268763

Epoch: 5| Step: 6
Training loss: 2.7728870114164903
Validation loss: 2.771901928410549

Epoch: 5| Step: 7
Training loss: 3.6972256440158686
Validation loss: 2.780428236037925

Epoch: 5| Step: 8
Training loss: 2.967223568054794
Validation loss: 2.7804542759115143

Epoch: 5| Step: 9
Training loss: 2.804605381860597
Validation loss: 2.784832967386161

Epoch: 5| Step: 10
Training loss: 2.5697169208106536
Validation loss: 2.7871349164615666

Epoch: 312| Step: 0
Training loss: 2.281691312561603
Validation loss: 2.7980278930981317

Epoch: 5| Step: 1
Training loss: 3.2520394895157145
Validation loss: 2.792273017688382

Epoch: 5| Step: 2
Training loss: 2.643689966985639
Validation loss: 2.7866573992144934

Epoch: 5| Step: 3
Training loss: 3.2795239949826547
Validation loss: 2.786712827763339

Epoch: 5| Step: 4
Training loss: 2.8930195555937486
Validation loss: 2.7889883361793

Epoch: 5| Step: 5
Training loss: 3.521002154093124
Validation loss: 2.797445881865264

Epoch: 5| Step: 6
Training loss: 3.522146999412948
Validation loss: 2.7760855110589517

Epoch: 5| Step: 7
Training loss: 3.119826650449897
Validation loss: 2.7784282458702245

Epoch: 5| Step: 8
Training loss: 3.1251055890364654
Validation loss: 2.7688095513403415

Epoch: 5| Step: 9
Training loss: 2.8144482116868113
Validation loss: 2.76666500873815

Epoch: 5| Step: 10
Training loss: 3.1533083662962778
Validation loss: 2.768713911630535

Epoch: 313| Step: 0
Training loss: 2.5630889773959438
Validation loss: 2.7657185135406426

Epoch: 5| Step: 1
Training loss: 3.416781462314829
Validation loss: 2.7682036566703743

Epoch: 5| Step: 2
Training loss: 3.4298889518088953
Validation loss: 2.76217756489287

Epoch: 5| Step: 3
Training loss: 2.8269264674303614
Validation loss: 2.7627264208905666

Epoch: 5| Step: 4
Training loss: 3.0563676121086414
Validation loss: 2.763963704992823

Epoch: 5| Step: 5
Training loss: 2.858317528802387
Validation loss: 2.762832700300034

Epoch: 5| Step: 6
Training loss: 3.171645433358503
Validation loss: 2.765262063393579

Epoch: 5| Step: 7
Training loss: 3.0470099003589968
Validation loss: 2.7652486901201816

Epoch: 5| Step: 8
Training loss: 2.4634440902085633
Validation loss: 2.7679761326175965

Epoch: 5| Step: 9
Training loss: 3.35620720123906
Validation loss: 2.762065695957631

Epoch: 5| Step: 10
Training loss: 3.48650072883304
Validation loss: 2.7695941144699887

Epoch: 314| Step: 0
Training loss: 2.771801361172391
Validation loss: 2.772558509921415

Epoch: 5| Step: 1
Training loss: 3.2477616157902487
Validation loss: 2.772338723480036

Epoch: 5| Step: 2
Training loss: 2.562088072627605
Validation loss: 2.7748929115140832

Epoch: 5| Step: 3
Training loss: 3.314506211133873
Validation loss: 2.7792495994359814

Epoch: 5| Step: 4
Training loss: 2.9980495788363215
Validation loss: 2.777879173588503

Epoch: 5| Step: 5
Training loss: 3.184129765794334
Validation loss: 2.7742899496161395

Epoch: 5| Step: 6
Training loss: 3.292939499332572
Validation loss: 2.771613263312312

Epoch: 5| Step: 7
Training loss: 3.1317736646541197
Validation loss: 2.773772136969208

Epoch: 5| Step: 8
Training loss: 3.2509109980903634
Validation loss: 2.765410721629727

Epoch: 5| Step: 9
Training loss: 2.869727399952236
Validation loss: 2.7619956653503306

Epoch: 5| Step: 10
Training loss: 3.035309108974558
Validation loss: 2.764124340861464

Epoch: 315| Step: 0
Training loss: 3.1118221908412615
Validation loss: 2.7609604745443552

Epoch: 5| Step: 1
Training loss: 2.638360581858743
Validation loss: 2.7641996707514123

Epoch: 5| Step: 2
Training loss: 3.460111153421341
Validation loss: 2.7664435364015176

Epoch: 5| Step: 3
Training loss: 2.447340054609393
Validation loss: 2.7627000914337443

Epoch: 5| Step: 4
Training loss: 2.7501525836575755
Validation loss: 2.7611760796538944

Epoch: 5| Step: 5
Training loss: 2.907774166651882
Validation loss: 2.7623587267129235

Epoch: 5| Step: 6
Training loss: 2.899356500986385
Validation loss: 2.7705193014032217

Epoch: 5| Step: 7
Training loss: 3.310179419365529
Validation loss: 2.758670879551069

Epoch: 5| Step: 8
Training loss: 3.264029373139626
Validation loss: 2.766736603851323

Epoch: 5| Step: 9
Training loss: 3.449760765958444
Validation loss: 2.76208837082874

Epoch: 5| Step: 10
Training loss: 3.3502467847423953
Validation loss: 2.7649708321749347

Epoch: 316| Step: 0
Training loss: 3.2315558342292667
Validation loss: 2.772726359887666

Epoch: 5| Step: 1
Training loss: 2.440746590568664
Validation loss: 2.770175237328417

Epoch: 5| Step: 2
Training loss: 3.1409239365756703
Validation loss: 2.774010977063903

Epoch: 5| Step: 3
Training loss: 2.814193554780753
Validation loss: 2.771970942977059

Epoch: 5| Step: 4
Training loss: 2.149448226386828
Validation loss: 2.7778661139262057

Epoch: 5| Step: 5
Training loss: 2.9624361055461366
Validation loss: 2.7832084453354167

Epoch: 5| Step: 6
Training loss: 3.3233743350434053
Validation loss: 2.8019283078114223

Epoch: 5| Step: 7
Training loss: 3.378751435895213
Validation loss: 2.800296897573231

Epoch: 5| Step: 8
Training loss: 3.0766630622233735
Validation loss: 2.77144407773057

Epoch: 5| Step: 9
Training loss: 3.172970136432793
Validation loss: 2.775899373249611

Epoch: 5| Step: 10
Training loss: 3.844187021610252
Validation loss: 2.757603271564354

Epoch: 317| Step: 0
Training loss: 3.043446024729917
Validation loss: 2.7656552263455914

Epoch: 5| Step: 1
Training loss: 3.4382297088150775
Validation loss: 2.7607994020121267

Epoch: 5| Step: 2
Training loss: 2.8170657926601184
Validation loss: 2.75751870536832

Epoch: 5| Step: 3
Training loss: 3.483938420746794
Validation loss: 2.757990041955269

Epoch: 5| Step: 4
Training loss: 2.872985465756866
Validation loss: 2.7578350908540012

Epoch: 5| Step: 5
Training loss: 2.58959720410422
Validation loss: 2.7586991204546485

Epoch: 5| Step: 6
Training loss: 2.9533533078702923
Validation loss: 2.7577778278569514

Epoch: 5| Step: 7
Training loss: 3.405779604847747
Validation loss: 2.757367464648609

Epoch: 5| Step: 8
Training loss: 3.162013164939233
Validation loss: 2.7577482941873837

Epoch: 5| Step: 9
Training loss: 3.0120559681711607
Validation loss: 2.7562140168446514

Epoch: 5| Step: 10
Training loss: 2.828608181812359
Validation loss: 2.758136674322893

Epoch: 318| Step: 0
Training loss: 3.849267364746218
Validation loss: 2.758673898389637

Epoch: 5| Step: 1
Training loss: 2.7919963717887937
Validation loss: 2.7626105495448203

Epoch: 5| Step: 2
Training loss: 2.795015622745315
Validation loss: 2.769524172404705

Epoch: 5| Step: 3
Training loss: 2.8776461821145554
Validation loss: 2.771301457283803

Epoch: 5| Step: 4
Training loss: 3.0497929612226535
Validation loss: 2.7672143615566585

Epoch: 5| Step: 5
Training loss: 3.1735435569542356
Validation loss: 2.7630110662560114

Epoch: 5| Step: 6
Training loss: 3.021083496960233
Validation loss: 2.77333693020854

Epoch: 5| Step: 7
Training loss: 2.3902204582655817
Validation loss: 2.769747693864885

Epoch: 5| Step: 8
Training loss: 3.349361951047688
Validation loss: 2.772764912332646

Epoch: 5| Step: 9
Training loss: 3.4551177337946566
Validation loss: 2.7636766522450777

Epoch: 5| Step: 10
Training loss: 2.5953804314970856
Validation loss: 2.769703783700768

Epoch: 319| Step: 0
Training loss: 2.9405443364916377
Validation loss: 2.763494173241272

Epoch: 5| Step: 1
Training loss: 2.8378791992629595
Validation loss: 2.768193018509235

Epoch: 5| Step: 2
Training loss: 3.1333156571667478
Validation loss: 2.7580048226400433

Epoch: 5| Step: 3
Training loss: 3.224084969756832
Validation loss: 2.7597648707053377

Epoch: 5| Step: 4
Training loss: 3.140534812429414
Validation loss: 2.7657327512219587

Epoch: 5| Step: 5
Training loss: 2.983633538455565
Validation loss: 2.760952769573613

Epoch: 5| Step: 6
Training loss: 2.6227452721826316
Validation loss: 2.7575477060004134

Epoch: 5| Step: 7
Training loss: 3.4023807492965266
Validation loss: 2.75644225879901

Epoch: 5| Step: 8
Training loss: 3.265127627812322
Validation loss: 2.761250854926414

Epoch: 5| Step: 9
Training loss: 3.2947861259639795
Validation loss: 2.759791553289211

Epoch: 5| Step: 10
Training loss: 2.6529356081237307
Validation loss: 2.7588525657448835

Epoch: 320| Step: 0
Training loss: 3.042252540774777
Validation loss: 2.7664794352835687

Epoch: 5| Step: 1
Training loss: 2.9817282239154435
Validation loss: 2.7628352733737387

Epoch: 5| Step: 2
Training loss: 2.865557547704129
Validation loss: 2.7633018926350394

Epoch: 5| Step: 3
Training loss: 3.1450281354800986
Validation loss: 2.7591383940247756

Epoch: 5| Step: 4
Training loss: 2.9380737718288312
Validation loss: 2.7574176572491504

Epoch: 5| Step: 5
Training loss: 3.527915392884039
Validation loss: 2.7596527181715094

Epoch: 5| Step: 6
Training loss: 2.7663444833181066
Validation loss: 2.764643551586022

Epoch: 5| Step: 7
Training loss: 3.1194105897377735
Validation loss: 2.765405898247162

Epoch: 5| Step: 8
Training loss: 3.0525275591731713
Validation loss: 2.7637423222945627

Epoch: 5| Step: 9
Training loss: 3.2179525924614087
Validation loss: 2.7594802690687947

Epoch: 5| Step: 10
Training loss: 2.9515297430996448
Validation loss: 2.764549977573276

Epoch: 321| Step: 0
Training loss: 3.26436769657388
Validation loss: 2.760773442330121

Epoch: 5| Step: 1
Training loss: 2.7480047964251333
Validation loss: 2.7649654980720824

Epoch: 5| Step: 2
Training loss: 2.6724172120077734
Validation loss: 2.7694640778377773

Epoch: 5| Step: 3
Training loss: 2.741580646019582
Validation loss: 2.762453022716431

Epoch: 5| Step: 4
Training loss: 3.1084470658209287
Validation loss: 2.763388515793598

Epoch: 5| Step: 5
Training loss: 3.239509230049315
Validation loss: 2.7669955672511923

Epoch: 5| Step: 6
Training loss: 3.1869611097583705
Validation loss: 2.772486563977637

Epoch: 5| Step: 7
Training loss: 3.052518498944989
Validation loss: 2.766813326596963

Epoch: 5| Step: 8
Training loss: 3.174822860942679
Validation loss: 2.759757477306224

Epoch: 5| Step: 9
Training loss: 3.1841493835486
Validation loss: 2.75651455933244

Epoch: 5| Step: 10
Training loss: 3.2358072399260003
Validation loss: 2.763194168160727

Epoch: 322| Step: 0
Training loss: 2.4799513870519947
Validation loss: 2.7560539942888687

Epoch: 5| Step: 1
Training loss: 3.1111321013363176
Validation loss: 2.758889277049425

Epoch: 5| Step: 2
Training loss: 2.265494823004525
Validation loss: 2.7616430897278472

Epoch: 5| Step: 3
Training loss: 3.511331199502909
Validation loss: 2.7597132214671474

Epoch: 5| Step: 4
Training loss: 2.8214306926201957
Validation loss: 2.770104313207859

Epoch: 5| Step: 5
Training loss: 3.167359845102337
Validation loss: 2.7629658168352638

Epoch: 5| Step: 6
Training loss: 2.9580429543554656
Validation loss: 2.776288826560277

Epoch: 5| Step: 7
Training loss: 3.4034986670894822
Validation loss: 2.7841517975974623

Epoch: 5| Step: 8
Training loss: 2.779542034217671
Validation loss: 2.772720095769729

Epoch: 5| Step: 9
Training loss: 3.3518012257455214
Validation loss: 2.771627616856111

Epoch: 5| Step: 10
Training loss: 3.605464517874006
Validation loss: 2.77029226736537

Epoch: 323| Step: 0
Training loss: 2.9913408560689803
Validation loss: 2.7616492768581677

Epoch: 5| Step: 1
Training loss: 3.120799484035407
Validation loss: 2.76818987808143

Epoch: 5| Step: 2
Training loss: 2.593686206446764
Validation loss: 2.769459986324163

Epoch: 5| Step: 3
Training loss: 3.0476548981828584
Validation loss: 2.756334984262833

Epoch: 5| Step: 4
Training loss: 3.312014274253124
Validation loss: 2.754565848733172

Epoch: 5| Step: 5
Training loss: 3.439691018710724
Validation loss: 2.7522224235059607

Epoch: 5| Step: 6
Training loss: 2.8315080672453483
Validation loss: 2.7543380004387608

Epoch: 5| Step: 7
Training loss: 3.0820753435237007
Validation loss: 2.7555024760199855

Epoch: 5| Step: 8
Training loss: 2.768771778994082
Validation loss: 2.7513715525022415

Epoch: 5| Step: 9
Training loss: 3.0569407550335606
Validation loss: 2.7503565429420638

Epoch: 5| Step: 10
Training loss: 3.3649331177729165
Validation loss: 2.7434495162115273

Epoch: 324| Step: 0
Training loss: 2.3942648909066784
Validation loss: 2.7475057348514915

Epoch: 5| Step: 1
Training loss: 3.6204008984794003
Validation loss: 2.747245210500893

Epoch: 5| Step: 2
Training loss: 2.5312793871268653
Validation loss: 2.7560801519027436

Epoch: 5| Step: 3
Training loss: 2.8707632276799515
Validation loss: 2.7625193501154244

Epoch: 5| Step: 4
Training loss: 3.1515192515895643
Validation loss: 2.7579399236782365

Epoch: 5| Step: 5
Training loss: 3.1675379374339006
Validation loss: 2.760227506304851

Epoch: 5| Step: 6
Training loss: 3.170167660777033
Validation loss: 2.7581778835650503

Epoch: 5| Step: 7
Training loss: 3.0792466651803676
Validation loss: 2.753249700999712

Epoch: 5| Step: 8
Training loss: 2.613689213998682
Validation loss: 2.7564466514413866

Epoch: 5| Step: 9
Training loss: 4.008677606740801
Validation loss: 2.7589813128845853

Epoch: 5| Step: 10
Training loss: 2.5712845190510087
Validation loss: 2.756605347344699

Epoch: 325| Step: 0
Training loss: 3.4163613686970935
Validation loss: 2.75892184634267

Epoch: 5| Step: 1
Training loss: 3.138851443117053
Validation loss: 2.7558039277681776

Epoch: 5| Step: 2
Training loss: 2.9615999552680887
Validation loss: 2.7650573668901943

Epoch: 5| Step: 3
Training loss: 2.6972929382046225
Validation loss: 2.768907358443306

Epoch: 5| Step: 4
Training loss: 1.7648671642167073
Validation loss: 2.7631871439174995

Epoch: 5| Step: 5
Training loss: 3.7843845710664863
Validation loss: 2.772543998457985

Epoch: 5| Step: 6
Training loss: 3.0516273409609806
Validation loss: 2.778387760505931

Epoch: 5| Step: 7
Training loss: 2.8324886820769892
Validation loss: 2.747748669959894

Epoch: 5| Step: 8
Training loss: 2.8595387563038397
Validation loss: 2.756272111296676

Epoch: 5| Step: 9
Training loss: 3.5533064957750944
Validation loss: 2.7444466007013237

Epoch: 5| Step: 10
Training loss: 3.1133347031660423
Validation loss: 2.745253472455226

Epoch: 326| Step: 0
Training loss: 3.3505376925173507
Validation loss: 2.7468035085621056

Epoch: 5| Step: 1
Training loss: 3.4140738131337875
Validation loss: 2.7453430042977534

Epoch: 5| Step: 2
Training loss: 2.9564495446763988
Validation loss: 2.7466538908423663

Epoch: 5| Step: 3
Training loss: 3.0623924080769536
Validation loss: 2.74711914224412

Epoch: 5| Step: 4
Training loss: 2.913033065802044
Validation loss: 2.748148163198001

Epoch: 5| Step: 5
Training loss: 2.2195523382874893
Validation loss: 2.745316614577979

Epoch: 5| Step: 6
Training loss: 2.7494175033943447
Validation loss: 2.751340544943947

Epoch: 5| Step: 7
Training loss: 3.2822761021161004
Validation loss: 2.7522915626852917

Epoch: 5| Step: 8
Training loss: 3.156238215962686
Validation loss: 2.7564831120560305

Epoch: 5| Step: 9
Training loss: 3.274827903127885
Validation loss: 2.7596283938564268

Epoch: 5| Step: 10
Training loss: 3.131785388487445
Validation loss: 2.755733564997948

Epoch: 327| Step: 0
Training loss: 2.535271828578051
Validation loss: 2.7561952848688738

Epoch: 5| Step: 1
Training loss: 2.584092602874501
Validation loss: 2.750236148707099

Epoch: 5| Step: 2
Training loss: 2.8837131654315757
Validation loss: 2.7481908207412573

Epoch: 5| Step: 3
Training loss: 3.4174500164403523
Validation loss: 2.7469037338665916

Epoch: 5| Step: 4
Training loss: 3.067287051294923
Validation loss: 2.742862666561727

Epoch: 5| Step: 5
Training loss: 3.0757182825303118
Validation loss: 2.7439122492355876

Epoch: 5| Step: 6
Training loss: 3.6709340289908012
Validation loss: 2.7430784072294494

Epoch: 5| Step: 7
Training loss: 3.098748840602644
Validation loss: 2.7392876784197395

Epoch: 5| Step: 8
Training loss: 3.017151757398499
Validation loss: 2.7417995535003623

Epoch: 5| Step: 9
Training loss: 3.0832947049857187
Validation loss: 2.7447905601855247

Epoch: 5| Step: 10
Training loss: 2.993749146272223
Validation loss: 2.7414074692178274

Epoch: 328| Step: 0
Training loss: 3.5424105741834087
Validation loss: 2.7436171539390406

Epoch: 5| Step: 1
Training loss: 3.0028121801196135
Validation loss: 2.7425674845052477

Epoch: 5| Step: 2
Training loss: 2.5236006645621383
Validation loss: 2.751274945074813

Epoch: 5| Step: 3
Training loss: 3.0159970385084107
Validation loss: 2.7438016939447625

Epoch: 5| Step: 4
Training loss: 3.0952363730345467
Validation loss: 2.7421230610910525

Epoch: 5| Step: 5
Training loss: 3.218485552840841
Validation loss: 2.74446353716674

Epoch: 5| Step: 6
Training loss: 2.8596923318512992
Validation loss: 2.755851404598851

Epoch: 5| Step: 7
Training loss: 2.914177368190956
Validation loss: 2.7564945171177695

Epoch: 5| Step: 8
Training loss: 3.1298293372479358
Validation loss: 2.7674076144367032

Epoch: 5| Step: 9
Training loss: 2.7527096143799574
Validation loss: 2.7573162516534238

Epoch: 5| Step: 10
Training loss: 3.4275926174836213
Validation loss: 2.7532000767701112

Epoch: 329| Step: 0
Training loss: 2.4640867397782737
Validation loss: 2.76535336890632

Epoch: 5| Step: 1
Training loss: 2.610669391776128
Validation loss: 2.769974228337133

Epoch: 5| Step: 2
Training loss: 3.0034069742650535
Validation loss: 2.7692439856267317

Epoch: 5| Step: 3
Training loss: 2.7679022772137087
Validation loss: 2.773562384934619

Epoch: 5| Step: 4
Training loss: 3.2198131990448084
Validation loss: 2.772757021962923

Epoch: 5| Step: 5
Training loss: 3.505717648162455
Validation loss: 2.774025800612283

Epoch: 5| Step: 6
Training loss: 3.47889052035624
Validation loss: 2.759977374855746

Epoch: 5| Step: 7
Training loss: 3.531714214768772
Validation loss: 2.759505477724883

Epoch: 5| Step: 8
Training loss: 2.909790835384646
Validation loss: 2.7525977192266127

Epoch: 5| Step: 9
Training loss: 2.683915253638721
Validation loss: 2.752667670412331

Epoch: 5| Step: 10
Training loss: 3.1942138275345915
Validation loss: 2.7506690698323992

Epoch: 330| Step: 0
Training loss: 2.751995576378128
Validation loss: 2.7557501213791284

Epoch: 5| Step: 1
Training loss: 2.9796791080542713
Validation loss: 2.757811832552812

Epoch: 5| Step: 2
Training loss: 3.4792445434869608
Validation loss: 2.750770397544474

Epoch: 5| Step: 3
Training loss: 3.3105581097707595
Validation loss: 2.7544609033163394

Epoch: 5| Step: 4
Training loss: 2.7999362495521924
Validation loss: 2.7528050427440607

Epoch: 5| Step: 5
Training loss: 3.7176273478569875
Validation loss: 2.7493089318448445

Epoch: 5| Step: 6
Training loss: 3.2381191236085183
Validation loss: 2.750632102489954

Epoch: 5| Step: 7
Training loss: 2.9314956985017857
Validation loss: 2.739093743476779

Epoch: 5| Step: 8
Training loss: 2.6176089730300163
Validation loss: 2.7402778218410386

Epoch: 5| Step: 9
Training loss: 2.75950972335106
Validation loss: 2.7487778394971687

Epoch: 5| Step: 10
Training loss: 2.9200347164128293
Validation loss: 2.7445369575113534

Epoch: 331| Step: 0
Training loss: 2.5184412764669926
Validation loss: 2.750543909735912

Epoch: 5| Step: 1
Training loss: 3.2101828623467217
Validation loss: 2.754397658088123

Epoch: 5| Step: 2
Training loss: 3.3737236717867423
Validation loss: 2.7570036855609

Epoch: 5| Step: 3
Training loss: 3.310845591703801
Validation loss: 2.763161845917197

Epoch: 5| Step: 4
Training loss: 3.4109670193033095
Validation loss: 2.7781051483509933

Epoch: 5| Step: 5
Training loss: 3.3684994294748027
Validation loss: 2.777957468441966

Epoch: 5| Step: 6
Training loss: 2.4730548266215355
Validation loss: 2.790964642265193

Epoch: 5| Step: 7
Training loss: 2.7440868440292596
Validation loss: 2.7973088468604526

Epoch: 5| Step: 8
Training loss: 2.376723517406292
Validation loss: 2.813653592210739

Epoch: 5| Step: 9
Training loss: 2.9744343195781573
Validation loss: 2.80992484566941

Epoch: 5| Step: 10
Training loss: 3.5782817156592204
Validation loss: 2.7999125059362977

Epoch: 332| Step: 0
Training loss: 3.3995585379382205
Validation loss: 2.7824152797873447

Epoch: 5| Step: 1
Training loss: 3.3704898509908503
Validation loss: 2.761410838129754

Epoch: 5| Step: 2
Training loss: 3.374129712960848
Validation loss: 2.742317533417689

Epoch: 5| Step: 3
Training loss: 2.624391576101851
Validation loss: 2.741284709620314

Epoch: 5| Step: 4
Training loss: 3.1523283210008106
Validation loss: 2.740525618451959

Epoch: 5| Step: 5
Training loss: 2.920952636052661
Validation loss: 2.7353214099220846

Epoch: 5| Step: 6
Training loss: 2.79191524670458
Validation loss: 2.741161645248773

Epoch: 5| Step: 7
Training loss: 3.121724510193285
Validation loss: 2.7375530884886583

Epoch: 5| Step: 8
Training loss: 3.2305970172256893
Validation loss: 2.738118006307696

Epoch: 5| Step: 9
Training loss: 2.8838770278448
Validation loss: 2.7389590314962473

Epoch: 5| Step: 10
Training loss: 2.5843573868323158
Validation loss: 2.7351233105041652

Epoch: 333| Step: 0
Training loss: 3.311426816592133
Validation loss: 2.7387631684044726

Epoch: 5| Step: 1
Training loss: 2.8495332369133592
Validation loss: 2.7422413995545045

Epoch: 5| Step: 2
Training loss: 3.810688151092331
Validation loss: 2.7555637905331016

Epoch: 5| Step: 3
Training loss: 2.757725873672677
Validation loss: 2.745303369196262

Epoch: 5| Step: 4
Training loss: 3.2013741522997115
Validation loss: 2.754098796549659

Epoch: 5| Step: 5
Training loss: 3.1755950610396186
Validation loss: 2.742066702215281

Epoch: 5| Step: 6
Training loss: 2.449523809438351
Validation loss: 2.746182957585448

Epoch: 5| Step: 7
Training loss: 2.590709696858843
Validation loss: 2.738758649113669

Epoch: 5| Step: 8
Training loss: 2.9458828077968326
Validation loss: 2.7359554269452495

Epoch: 5| Step: 9
Training loss: 3.42866768588321
Validation loss: 2.737428921716857

Epoch: 5| Step: 10
Training loss: 2.7680673967656766
Validation loss: 2.734922109971537

Epoch: 334| Step: 0
Training loss: 2.992763374230536
Validation loss: 2.738249270323633

Epoch: 5| Step: 1
Training loss: 2.715977449888121
Validation loss: 2.7466743754077516

Epoch: 5| Step: 2
Training loss: 3.244569937211034
Validation loss: 2.7524335819621806

Epoch: 5| Step: 3
Training loss: 3.6968589595340275
Validation loss: 2.7474931130592632

Epoch: 5| Step: 4
Training loss: 3.0057578463197747
Validation loss: 2.7380189144307234

Epoch: 5| Step: 5
Training loss: 2.801336895719669
Validation loss: 2.741900210422096

Epoch: 5| Step: 6
Training loss: 3.083743471928101
Validation loss: 2.742721601429289

Epoch: 5| Step: 7
Training loss: 2.9573292349032227
Validation loss: 2.742064085344744

Epoch: 5| Step: 8
Training loss: 3.17571788691786
Validation loss: 2.755075664866974

Epoch: 5| Step: 9
Training loss: 2.659001888364858
Validation loss: 2.749136935671493

Epoch: 5| Step: 10
Training loss: 3.060833068592847
Validation loss: 2.7575382557734396

Epoch: 335| Step: 0
Training loss: 3.0291591394078177
Validation loss: 2.74819398402247

Epoch: 5| Step: 1
Training loss: 3.2391937773950246
Validation loss: 2.7471782269031007

Epoch: 5| Step: 2
Training loss: 2.502949024353465
Validation loss: 2.7413406796410618

Epoch: 5| Step: 3
Training loss: 2.671255296372557
Validation loss: 2.7496692769967956

Epoch: 5| Step: 4
Training loss: 3.4205380967885786
Validation loss: 2.7451593841132174

Epoch: 5| Step: 5
Training loss: 3.151823357759065
Validation loss: 2.7427484227108607

Epoch: 5| Step: 6
Training loss: 3.149690364575571
Validation loss: 2.7431201398820155

Epoch: 5| Step: 7
Training loss: 3.221181303097787
Validation loss: 2.7411946234397764

Epoch: 5| Step: 8
Training loss: 3.32194382030149
Validation loss: 2.7440947374268845

Epoch: 5| Step: 9
Training loss: 2.6992046173653175
Validation loss: 2.7447389514044747

Epoch: 5| Step: 10
Training loss: 2.9624631468979516
Validation loss: 2.7522169836563397

Epoch: 336| Step: 0
Training loss: 3.051412949264402
Validation loss: 2.7499999170312655

Epoch: 5| Step: 1
Training loss: 3.0369281874209273
Validation loss: 2.7472037990034766

Epoch: 5| Step: 2
Training loss: 3.227180477196381
Validation loss: 2.7478422628699684

Epoch: 5| Step: 3
Training loss: 2.777770877405709
Validation loss: 2.744824070114696

Epoch: 5| Step: 4
Training loss: 2.844789755080391
Validation loss: 2.738249349903477

Epoch: 5| Step: 5
Training loss: 3.027754193446459
Validation loss: 2.7406426994721387

Epoch: 5| Step: 6
Training loss: 2.6548620749242957
Validation loss: 2.7407880798193123

Epoch: 5| Step: 7
Training loss: 3.215879178543748
Validation loss: 2.7403453754457967

Epoch: 5| Step: 8
Training loss: 3.67874839769718
Validation loss: 2.7436472863608015

Epoch: 5| Step: 9
Training loss: 2.7551856133161814
Validation loss: 2.7424986432879486

Epoch: 5| Step: 10
Training loss: 3.0990171966518747
Validation loss: 2.7347947921446782

Epoch: 337| Step: 0
Training loss: 3.0099484476636427
Validation loss: 2.738449527086614

Epoch: 5| Step: 1
Training loss: 3.2397357540928637
Validation loss: 2.7485285856270982

Epoch: 5| Step: 2
Training loss: 2.72532735135765
Validation loss: 2.7505079231035574

Epoch: 5| Step: 3
Training loss: 3.101089249257485
Validation loss: 2.753691113732806

Epoch: 5| Step: 4
Training loss: 3.184679616147804
Validation loss: 2.742661930030346

Epoch: 5| Step: 5
Training loss: 2.550535508567298
Validation loss: 2.763783716025706

Epoch: 5| Step: 6
Training loss: 3.151969197272816
Validation loss: 2.76938544010939

Epoch: 5| Step: 7
Training loss: 2.965997001703024
Validation loss: 2.7754132538190537

Epoch: 5| Step: 8
Training loss: 3.717289357275063
Validation loss: 2.7622623828988986

Epoch: 5| Step: 9
Training loss: 2.4855059083029234
Validation loss: 2.778994119264727

Epoch: 5| Step: 10
Training loss: 3.212101115239669
Validation loss: 2.772321371955486

Epoch: 338| Step: 0
Training loss: 2.813139016354452
Validation loss: 2.736688777956214

Epoch: 5| Step: 1
Training loss: 3.366388991836854
Validation loss: 2.732386955726471

Epoch: 5| Step: 2
Training loss: 3.301353702902414
Validation loss: 2.729255023557112

Epoch: 5| Step: 3
Training loss: 3.235856606040125
Validation loss: 2.733288172592143

Epoch: 5| Step: 4
Training loss: 3.233547823631183
Validation loss: 2.7322547692207597

Epoch: 5| Step: 5
Training loss: 3.0035693868944744
Validation loss: 2.73080408992664

Epoch: 5| Step: 6
Training loss: 3.2222931258486716
Validation loss: 2.7381778497576503

Epoch: 5| Step: 7
Training loss: 2.794475101187342
Validation loss: 2.736447414831078

Epoch: 5| Step: 8
Training loss: 2.8156122577814995
Validation loss: 2.7355725822202515

Epoch: 5| Step: 9
Training loss: 3.2601999001559783
Validation loss: 2.7397117530060306

Epoch: 5| Step: 10
Training loss: 2.393904885642173
Validation loss: 2.7404787573275406

Epoch: 339| Step: 0
Training loss: 2.7285484798039827
Validation loss: 2.7396971255776705

Epoch: 5| Step: 1
Training loss: 2.477879892857548
Validation loss: 2.737521366266941

Epoch: 5| Step: 2
Training loss: 3.344652000765638
Validation loss: 2.7319946259958154

Epoch: 5| Step: 3
Training loss: 3.153728270877306
Validation loss: 2.7347353930666123

Epoch: 5| Step: 4
Training loss: 3.1340780009073614
Validation loss: 2.737527516140089

Epoch: 5| Step: 5
Training loss: 2.713801912701186
Validation loss: 2.7448908057534207

Epoch: 5| Step: 6
Training loss: 3.3312984613325423
Validation loss: 2.7500760691573087

Epoch: 5| Step: 7
Training loss: 3.344869836119345
Validation loss: 2.74920878862938

Epoch: 5| Step: 8
Training loss: 3.034679085672015
Validation loss: 2.761201218513519

Epoch: 5| Step: 9
Training loss: 2.760636998626149
Validation loss: 2.7611339356193274

Epoch: 5| Step: 10
Training loss: 3.457767179789424
Validation loss: 2.7644425289380448

Epoch: 340| Step: 0
Training loss: 2.9689978245142274
Validation loss: 2.7624876797977236

Epoch: 5| Step: 1
Training loss: 2.9216945000857044
Validation loss: 2.755317346364939

Epoch: 5| Step: 2
Training loss: 2.9875892785430906
Validation loss: 2.7554292873835626

Epoch: 5| Step: 3
Training loss: 3.8091089144773838
Validation loss: 2.7537304158463223

Epoch: 5| Step: 4
Training loss: 2.833928849710191
Validation loss: 2.7628318215757925

Epoch: 5| Step: 5
Training loss: 3.258690146367362
Validation loss: 2.752892709539211

Epoch: 5| Step: 6
Training loss: 3.0306301466350787
Validation loss: 2.73673636344926

Epoch: 5| Step: 7
Training loss: 2.868678399150289
Validation loss: 2.737595650790591

Epoch: 5| Step: 8
Training loss: 3.319965227703323
Validation loss: 2.7250529245439856

Epoch: 5| Step: 9
Training loss: 2.832414103970687
Validation loss: 2.7285512984887124

Epoch: 5| Step: 10
Training loss: 2.3382930042852115
Validation loss: 2.7240486284558485

Epoch: 341| Step: 0
Training loss: 3.2874899976454897
Validation loss: 2.725258847899426

Epoch: 5| Step: 1
Training loss: 2.9313676822683745
Validation loss: 2.726031682984975

Epoch: 5| Step: 2
Training loss: 2.6526836014608355
Validation loss: 2.728202870077313

Epoch: 5| Step: 3
Training loss: 2.6831009813571436
Validation loss: 2.732734538264897

Epoch: 5| Step: 4
Training loss: 2.959132306017526
Validation loss: 2.7348951350715494

Epoch: 5| Step: 5
Training loss: 3.3913113650862816
Validation loss: 2.7373086051132467

Epoch: 5| Step: 6
Training loss: 3.248787727210285
Validation loss: 2.735894329850926

Epoch: 5| Step: 7
Training loss: 3.641574195601445
Validation loss: 2.734687500893955

Epoch: 5| Step: 8
Training loss: 2.7018983736953066
Validation loss: 2.7313135459729168

Epoch: 5| Step: 9
Training loss: 2.766368098024171
Validation loss: 2.7254324337439466

Epoch: 5| Step: 10
Training loss: 3.0870056621473636
Validation loss: 2.7224476852188557

Epoch: 342| Step: 0
Training loss: 3.205394108624018
Validation loss: 2.7191971130809613

Epoch: 5| Step: 1
Training loss: 2.693269259222579
Validation loss: 2.7247460139210458

Epoch: 5| Step: 2
Training loss: 2.57540870682143
Validation loss: 2.725240151498368

Epoch: 5| Step: 3
Training loss: 2.5330026469316596
Validation loss: 2.7247806905248635

Epoch: 5| Step: 4
Training loss: 3.423386052910297
Validation loss: 2.7204312689571712

Epoch: 5| Step: 5
Training loss: 2.7282197391800143
Validation loss: 2.724792455028853

Epoch: 5| Step: 6
Training loss: 3.656923541768988
Validation loss: 2.7239991649306994

Epoch: 5| Step: 7
Training loss: 2.878419252610507
Validation loss: 2.735886222574486

Epoch: 5| Step: 8
Training loss: 3.4435813516351823
Validation loss: 2.724324198142529

Epoch: 5| Step: 9
Training loss: 2.848671144914786
Validation loss: 2.7218044097936787

Epoch: 5| Step: 10
Training loss: 3.2401912564472077
Validation loss: 2.7263959603480368

Epoch: 343| Step: 0
Training loss: 3.4056873381774735
Validation loss: 2.7319252800015175

Epoch: 5| Step: 1
Training loss: 2.42666182452896
Validation loss: 2.7294062976016797

Epoch: 5| Step: 2
Training loss: 2.560819959008691
Validation loss: 2.7389366565432063

Epoch: 5| Step: 3
Training loss: 3.1602363717728577
Validation loss: 2.731318107618028

Epoch: 5| Step: 4
Training loss: 3.4191931400735434
Validation loss: 2.734011305662943

Epoch: 5| Step: 5
Training loss: 3.8668434683619504
Validation loss: 2.736164029278049

Epoch: 5| Step: 6
Training loss: 2.675296934528339
Validation loss: 2.72956077161812

Epoch: 5| Step: 7
Training loss: 3.164160456141868
Validation loss: 2.7296343974587334

Epoch: 5| Step: 8
Training loss: 2.5102430312598756
Validation loss: 2.728616955167386

Epoch: 5| Step: 9
Training loss: 2.865973691203294
Validation loss: 2.726845457179626

Epoch: 5| Step: 10
Training loss: 3.057360949968707
Validation loss: 2.725860330402685

Epoch: 344| Step: 0
Training loss: 3.31947542297578
Validation loss: 2.7272547945319876

Epoch: 5| Step: 1
Training loss: 2.585260769439361
Validation loss: 2.728101822419474

Epoch: 5| Step: 2
Training loss: 3.1273010937128047
Validation loss: 2.7215929792778604

Epoch: 5| Step: 3
Training loss: 3.1413127089289152
Validation loss: 2.726019024774403

Epoch: 5| Step: 4
Training loss: 3.3290283696394445
Validation loss: 2.724909457519832

Epoch: 5| Step: 5
Training loss: 3.603871563129057
Validation loss: 2.724062587024755

Epoch: 5| Step: 6
Training loss: 2.8753975303141
Validation loss: 2.7320255153118342

Epoch: 5| Step: 7
Training loss: 2.461067123632333
Validation loss: 2.72022246101467

Epoch: 5| Step: 8
Training loss: 2.8503706440088696
Validation loss: 2.724211889923698

Epoch: 5| Step: 9
Training loss: 2.7190683112758087
Validation loss: 2.7268531485265655

Epoch: 5| Step: 10
Training loss: 3.1709061068297304
Validation loss: 2.729198524823331

Epoch: 345| Step: 0
Training loss: 3.2109676461765355
Validation loss: 2.7238190255192425

Epoch: 5| Step: 1
Training loss: 3.1326506993850924
Validation loss: 2.7264391744901895

Epoch: 5| Step: 2
Training loss: 3.347843124889096
Validation loss: 2.729371861046873

Epoch: 5| Step: 3
Training loss: 3.213850718536883
Validation loss: 2.730466596159588

Epoch: 5| Step: 4
Training loss: 2.950413826833916
Validation loss: 2.7201666030916303

Epoch: 5| Step: 5
Training loss: 2.7431047867060436
Validation loss: 2.7211839735238894

Epoch: 5| Step: 6
Training loss: 2.6305963714702196
Validation loss: 2.7257417387906973

Epoch: 5| Step: 7
Training loss: 2.7722406088151983
Validation loss: 2.7314209659995754

Epoch: 5| Step: 8
Training loss: 3.340732532051617
Validation loss: 2.7235977278307026

Epoch: 5| Step: 9
Training loss: 2.7246364140963424
Validation loss: 2.7194958687870616

Epoch: 5| Step: 10
Training loss: 3.2435751277995974
Validation loss: 2.7264503375777807

Epoch: 346| Step: 0
Training loss: 2.5157356948665694
Validation loss: 2.724208671504387

Epoch: 5| Step: 1
Training loss: 3.6650872007563406
Validation loss: 2.720341053867432

Epoch: 5| Step: 2
Training loss: 2.6070970654432064
Validation loss: 2.720725158984275

Epoch: 5| Step: 3
Training loss: 2.78422010613857
Validation loss: 2.7224374869402124

Epoch: 5| Step: 4
Training loss: 2.7529336713455566
Validation loss: 2.72581972638484

Epoch: 5| Step: 5
Training loss: 3.1174037925234597
Validation loss: 2.727094542943153

Epoch: 5| Step: 6
Training loss: 3.1420072483923707
Validation loss: 2.7208290142526375

Epoch: 5| Step: 7
Training loss: 3.194751046619741
Validation loss: 2.7277663382539217

Epoch: 5| Step: 8
Training loss: 3.1959693438762944
Validation loss: 2.733268695410172

Epoch: 5| Step: 9
Training loss: 3.140051946028104
Validation loss: 2.7318737547475767

Epoch: 5| Step: 10
Training loss: 3.0490822646421294
Validation loss: 2.728069718716586

Epoch: 347| Step: 0
Training loss: 2.7158452444019203
Validation loss: 2.7223312540118765

Epoch: 5| Step: 1
Training loss: 2.9922482158188015
Validation loss: 2.722549859880457

Epoch: 5| Step: 2
Training loss: 3.1344957657403745
Validation loss: 2.7154949402017023

Epoch: 5| Step: 3
Training loss: 3.4303575699715805
Validation loss: 2.716339531671953

Epoch: 5| Step: 4
Training loss: 2.9335633541721737
Validation loss: 2.7216035038131805

Epoch: 5| Step: 5
Training loss: 3.209285710326803
Validation loss: 2.7179567336988626

Epoch: 5| Step: 6
Training loss: 2.988668818055308
Validation loss: 2.718325142201267

Epoch: 5| Step: 7
Training loss: 2.678363261535333
Validation loss: 2.7267138190602265

Epoch: 5| Step: 8
Training loss: 2.7529281286023433
Validation loss: 2.7311050068306

Epoch: 5| Step: 9
Training loss: 3.380350745697912
Validation loss: 2.728911293410553

Epoch: 5| Step: 10
Training loss: 3.010815357528001
Validation loss: 2.7315713514449276

Epoch: 348| Step: 0
Training loss: 2.6211619702257463
Validation loss: 2.7323478551429874

Epoch: 5| Step: 1
Training loss: 2.7473164382719935
Validation loss: 2.7301351661610846

Epoch: 5| Step: 2
Training loss: 3.058025282920572
Validation loss: 2.73722330139899

Epoch: 5| Step: 3
Training loss: 2.964340147086598
Validation loss: 2.7496082795077355

Epoch: 5| Step: 4
Training loss: 2.7567301671449496
Validation loss: 2.7411880562643

Epoch: 5| Step: 5
Training loss: 3.030784649867435
Validation loss: 2.7304002300018158

Epoch: 5| Step: 6
Training loss: 3.1403229981022123
Validation loss: 2.7314852519289627

Epoch: 5| Step: 7
Training loss: 3.2055970120040262
Validation loss: 2.723807882707154

Epoch: 5| Step: 8
Training loss: 3.1165798426755384
Validation loss: 2.7260668472983527

Epoch: 5| Step: 9
Training loss: 3.3988988102852655
Validation loss: 2.7191607002769413

Epoch: 5| Step: 10
Training loss: 3.213823121706792
Validation loss: 2.7220551642382387

Epoch: 349| Step: 0
Training loss: 3.3754977106519712
Validation loss: 2.72035324656958

Epoch: 5| Step: 1
Training loss: 3.19742296282654
Validation loss: 2.7235274611242097

Epoch: 5| Step: 2
Training loss: 2.7333824754189617
Validation loss: 2.7192129095356856

Epoch: 5| Step: 3
Training loss: 3.1123598427219785
Validation loss: 2.718169296835131

Epoch: 5| Step: 4
Training loss: 2.7932477905024338
Validation loss: 2.711776482056137

Epoch: 5| Step: 5
Training loss: 3.18238539903685
Validation loss: 2.7159968858872854

Epoch: 5| Step: 6
Training loss: 2.480321203934829
Validation loss: 2.717571003378137

Epoch: 5| Step: 7
Training loss: 3.087713189428924
Validation loss: 2.7227740994145115

Epoch: 5| Step: 8
Training loss: 2.7969870944443125
Validation loss: 2.7178929682132864

Epoch: 5| Step: 9
Training loss: 3.3056268461715956
Validation loss: 2.7164711638459114

Epoch: 5| Step: 10
Training loss: 3.1642288729406984
Validation loss: 2.720100158104141

Epoch: 350| Step: 0
Training loss: 3.4134840835372313
Validation loss: 2.7131622784887974

Epoch: 5| Step: 1
Training loss: 2.8514399253942426
Validation loss: 2.72186243525684

Epoch: 5| Step: 2
Training loss: 2.816472109634346
Validation loss: 2.7213706941844102

Epoch: 5| Step: 3
Training loss: 3.4773095174872934
Validation loss: 2.7324173039387967

Epoch: 5| Step: 4
Training loss: 2.6651054421583895
Validation loss: 2.7304517145218266

Epoch: 5| Step: 5
Training loss: 2.6201369334247095
Validation loss: 2.739232717463466

Epoch: 5| Step: 6
Training loss: 2.5329737504275927
Validation loss: 2.7317200168403506

Epoch: 5| Step: 7
Training loss: 2.9299379775737915
Validation loss: 2.731602829301598

Epoch: 5| Step: 8
Training loss: 3.3787477665596373
Validation loss: 2.7422377068134756

Epoch: 5| Step: 9
Training loss: 3.2313759578157275
Validation loss: 2.7316343152420415

Epoch: 5| Step: 10
Training loss: 3.248865663202186
Validation loss: 2.7240471603174212

Epoch: 351| Step: 0
Training loss: 2.8880610461770564
Validation loss: 2.7176106307022727

Epoch: 5| Step: 1
Training loss: 3.0154153227178253
Validation loss: 2.716247242083224

Epoch: 5| Step: 2
Training loss: 3.3924805797900937
Validation loss: 2.7155936172794

Epoch: 5| Step: 3
Training loss: 3.262847449264653
Validation loss: 2.7130198429357297

Epoch: 5| Step: 4
Training loss: 2.691169008559179
Validation loss: 2.7226457267093305

Epoch: 5| Step: 5
Training loss: 2.9918000690041215
Validation loss: 2.7105792572130247

Epoch: 5| Step: 6
Training loss: 2.8187365580236152
Validation loss: 2.7155477769341383

Epoch: 5| Step: 7
Training loss: 2.842358594613124
Validation loss: 2.7116696508967633

Epoch: 5| Step: 8
Training loss: 2.6349584510321544
Validation loss: 2.7136928325796377

Epoch: 5| Step: 9
Training loss: 3.419783558382261
Validation loss: 2.7157031657448183

Epoch: 5| Step: 10
Training loss: 3.263821044288897
Validation loss: 2.7141080867478102

Epoch: 352| Step: 0
Training loss: 3.1786719347645587
Validation loss: 2.7178478797554497

Epoch: 5| Step: 1
Training loss: 2.590667547559891
Validation loss: 2.718379296100653

Epoch: 5| Step: 2
Training loss: 2.456741582779786
Validation loss: 2.715851245128784

Epoch: 5| Step: 3
Training loss: 2.875352589091759
Validation loss: 2.7192992411255656

Epoch: 5| Step: 4
Training loss: 3.1442103630916693
Validation loss: 2.7138226546875686

Epoch: 5| Step: 5
Training loss: 3.401140773355414
Validation loss: 2.721488267683911

Epoch: 5| Step: 6
Training loss: 3.2254880728039117
Validation loss: 2.7145615675459407

Epoch: 5| Step: 7
Training loss: 3.375036168787677
Validation loss: 2.7173760789442003

Epoch: 5| Step: 8
Training loss: 2.9454991612871098
Validation loss: 2.7166566315458107

Epoch: 5| Step: 9
Training loss: 2.528079743799535
Validation loss: 2.730220575843509

Epoch: 5| Step: 10
Training loss: 3.3701617564877475
Validation loss: 2.720841759737734

Epoch: 353| Step: 0
Training loss: 3.0093593830721472
Validation loss: 2.7228989401092485

Epoch: 5| Step: 1
Training loss: 2.7815570447504188
Validation loss: 2.742893889594755

Epoch: 5| Step: 2
Training loss: 3.3065269887812896
Validation loss: 2.7353626123637387

Epoch: 5| Step: 3
Training loss: 3.0474363152325186
Validation loss: 2.7270886111392683

Epoch: 5| Step: 4
Training loss: 3.1419923756857187
Validation loss: 2.7267854092110704

Epoch: 5| Step: 5
Training loss: 2.852813529888681
Validation loss: 2.7176421759296616

Epoch: 5| Step: 6
Training loss: 3.0140364025324935
Validation loss: 2.7217575993368164

Epoch: 5| Step: 7
Training loss: 3.428399263328159
Validation loss: 2.717646285555308

Epoch: 5| Step: 8
Training loss: 3.289331855527218
Validation loss: 2.7134741962386957

Epoch: 5| Step: 9
Training loss: 2.754840838340063
Validation loss: 2.709030156066962

Epoch: 5| Step: 10
Training loss: 2.4260544676802636
Validation loss: 2.7128698380878453

Epoch: 354| Step: 0
Training loss: 2.716645928364176
Validation loss: 2.7060005768557494

Epoch: 5| Step: 1
Training loss: 3.2929615097599823
Validation loss: 2.7055395806995906

Epoch: 5| Step: 2
Training loss: 2.790324889787938
Validation loss: 2.7183187381026657

Epoch: 5| Step: 3
Training loss: 3.6550074365125327
Validation loss: 2.712748856553289

Epoch: 5| Step: 4
Training loss: 2.5992075482727044
Validation loss: 2.7171033965576674

Epoch: 5| Step: 5
Training loss: 3.318605518249253
Validation loss: 2.7175167795988817

Epoch: 5| Step: 6
Training loss: 2.9145707001774737
Validation loss: 2.7250054257306786

Epoch: 5| Step: 7
Training loss: 2.4508269413053276
Validation loss: 2.7314359362134644

Epoch: 5| Step: 8
Training loss: 2.90844692748007
Validation loss: 2.729606368179788

Epoch: 5| Step: 9
Training loss: 3.02803262071663
Validation loss: 2.7287868456828743

Epoch: 5| Step: 10
Training loss: 3.3778366601005643
Validation loss: 2.7344914434106644

Epoch: 355| Step: 0
Training loss: 2.8809020786029893
Validation loss: 2.725545236275229

Epoch: 5| Step: 1
Training loss: 2.8592205735493734
Validation loss: 2.7112215881541317

Epoch: 5| Step: 2
Training loss: 2.4227500073184243
Validation loss: 2.710697892709843

Epoch: 5| Step: 3
Training loss: 2.9534566380211
Validation loss: 2.7155702983413894

Epoch: 5| Step: 4
Training loss: 3.2359080344147517
Validation loss: 2.7110073100351904

Epoch: 5| Step: 5
Training loss: 3.1323989252709454
Validation loss: 2.707211179778566

Epoch: 5| Step: 6
Training loss: 3.48184468037201
Validation loss: 2.7078164808833423

Epoch: 5| Step: 7
Training loss: 3.4721676597546796
Validation loss: 2.709759608488184

Epoch: 5| Step: 8
Training loss: 2.576721734284682
Validation loss: 2.7083689407267078

Epoch: 5| Step: 9
Training loss: 3.192039100158919
Validation loss: 2.7110855493809187

Epoch: 5| Step: 10
Training loss: 2.8085579266339336
Validation loss: 2.7081440470567193

Epoch: 356| Step: 0
Training loss: 3.2948972727112036
Validation loss: 2.709731430390964

Epoch: 5| Step: 1
Training loss: 3.322396806731826
Validation loss: 2.706066081519919

Epoch: 5| Step: 2
Training loss: 2.7296769245119714
Validation loss: 2.711216457032008

Epoch: 5| Step: 3
Training loss: 3.223625268612424
Validation loss: 2.718525557729801

Epoch: 5| Step: 4
Training loss: 3.1696100275500148
Validation loss: 2.7118450434307007

Epoch: 5| Step: 5
Training loss: 3.1183824280530974
Validation loss: 2.725875902028381

Epoch: 5| Step: 6
Training loss: 2.553919872248773
Validation loss: 2.718300302834369

Epoch: 5| Step: 7
Training loss: 2.896095995803098
Validation loss: 2.7290110095536604

Epoch: 5| Step: 8
Training loss: 3.417222156183217
Validation loss: 2.7257685268215446

Epoch: 5| Step: 9
Training loss: 2.728559140054312
Validation loss: 2.7355919820844568

Epoch: 5| Step: 10
Training loss: 2.4961260344278564
Validation loss: 2.7189323817677558

Epoch: 357| Step: 0
Training loss: 3.1280908176867706
Validation loss: 2.719497445906405

Epoch: 5| Step: 1
Training loss: 3.0499094402439173
Validation loss: 2.725359426221592

Epoch: 5| Step: 2
Training loss: 2.550783773657586
Validation loss: 2.7288302211292246

Epoch: 5| Step: 3
Training loss: 3.1937193688045364
Validation loss: 2.7232715563875742

Epoch: 5| Step: 4
Training loss: 2.613774046456613
Validation loss: 2.7220240892597785

Epoch: 5| Step: 5
Training loss: 3.3635989580722354
Validation loss: 2.726995105027987

Epoch: 5| Step: 6
Training loss: 3.188829032729034
Validation loss: 2.720411075873801

Epoch: 5| Step: 7
Training loss: 3.3133605702877844
Validation loss: 2.714431580554658

Epoch: 5| Step: 8
Training loss: 2.635011292493101
Validation loss: 2.7149108750939157

Epoch: 5| Step: 9
Training loss: 2.913333914238052
Validation loss: 2.708830330795898

Epoch: 5| Step: 10
Training loss: 3.0996366041750596
Validation loss: 2.712176411577994

Epoch: 358| Step: 0
Training loss: 3.1848694661697716
Validation loss: 2.705582806749115

Epoch: 5| Step: 1
Training loss: 3.3087172592151513
Validation loss: 2.710297536923277

Epoch: 5| Step: 2
Training loss: 3.1316590123863803
Validation loss: 2.714014669946852

Epoch: 5| Step: 3
Training loss: 2.87714388979513
Validation loss: 2.7052411515503456

Epoch: 5| Step: 4
Training loss: 2.7815421304620136
Validation loss: 2.7039924352208393

Epoch: 5| Step: 5
Training loss: 3.063339274099385
Validation loss: 2.7054424510406268

Epoch: 5| Step: 6
Training loss: 3.010981488067367
Validation loss: 2.7038151361913574

Epoch: 5| Step: 7
Training loss: 3.328976804231347
Validation loss: 2.709989943795772

Epoch: 5| Step: 8
Training loss: 2.980781988679831
Validation loss: 2.705722551626821

Epoch: 5| Step: 9
Training loss: 3.1365192962738866
Validation loss: 2.7045689868779834

Epoch: 5| Step: 10
Training loss: 2.1128119830833496
Validation loss: 2.7086251886464034

Epoch: 359| Step: 0
Training loss: 3.157648815233296
Validation loss: 2.712225559505892

Epoch: 5| Step: 1
Training loss: 2.476025159045505
Validation loss: 2.724118589981331

Epoch: 5| Step: 2
Training loss: 3.057906774004233
Validation loss: 2.731964595893362

Epoch: 5| Step: 3
Training loss: 2.6363167915547154
Validation loss: 2.7449263962476405

Epoch: 5| Step: 4
Training loss: 3.5216178847576742
Validation loss: 2.7538866747414454

Epoch: 5| Step: 5
Training loss: 2.451912744422649
Validation loss: 2.7502855756711253

Epoch: 5| Step: 6
Training loss: 3.349643113213836
Validation loss: 2.721972900240957

Epoch: 5| Step: 7
Training loss: 2.5735331014398364
Validation loss: 2.7339542338242446

Epoch: 5| Step: 8
Training loss: 3.0758057197758224
Validation loss: 2.7136633698882213

Epoch: 5| Step: 9
Training loss: 3.1504402700676093
Validation loss: 2.709012829627685

Epoch: 5| Step: 10
Training loss: 3.7051037358679286
Validation loss: 2.701728261254969

Epoch: 360| Step: 0
Training loss: 2.677099106639502
Validation loss: 2.701088866785218

Epoch: 5| Step: 1
Training loss: 2.975179355888823
Validation loss: 2.6960787385005185

Epoch: 5| Step: 2
Training loss: 2.490915386354
Validation loss: 2.7005818301446154

Epoch: 5| Step: 3
Training loss: 2.841079631888456
Validation loss: 2.703679486162029

Epoch: 5| Step: 4
Training loss: 3.1517958229856893
Validation loss: 2.7025751971070138

Epoch: 5| Step: 5
Training loss: 3.5157842303350275
Validation loss: 2.7030706087788583

Epoch: 5| Step: 6
Training loss: 3.063159949370461
Validation loss: 2.7042481735426835

Epoch: 5| Step: 7
Training loss: 3.2323637527818323
Validation loss: 2.7036592637323413

Epoch: 5| Step: 8
Training loss: 2.528294474387576
Validation loss: 2.7022815768213606

Epoch: 5| Step: 9
Training loss: 3.4079188187292297
Validation loss: 2.7012094755720835

Epoch: 5| Step: 10
Training loss: 3.237809131842574
Validation loss: 2.705241503131059

Epoch: 361| Step: 0
Training loss: 2.9029505879516564
Validation loss: 2.706349759812707

Epoch: 5| Step: 1
Training loss: 3.2438401755438964
Validation loss: 2.712572067011849

Epoch: 5| Step: 2
Training loss: 2.860662451897513
Validation loss: 2.7225024200365118

Epoch: 5| Step: 3
Training loss: 3.006556340270656
Validation loss: 2.7192549811138065

Epoch: 5| Step: 4
Training loss: 3.148270595471357
Validation loss: 2.729018977556739

Epoch: 5| Step: 5
Training loss: 2.778028186531514
Validation loss: 2.7370605828185632

Epoch: 5| Step: 6
Training loss: 3.0589967269755247
Validation loss: 2.7412423196280837

Epoch: 5| Step: 7
Training loss: 2.3673532761543328
Validation loss: 2.7570601919348703

Epoch: 5| Step: 8
Training loss: 3.571839387971463
Validation loss: 2.76380086792208

Epoch: 5| Step: 9
Training loss: 2.7780603699520103
Validation loss: 2.7451213059568635

Epoch: 5| Step: 10
Training loss: 3.3524823115918347
Validation loss: 2.7572768551428477

Epoch: 362| Step: 0
Training loss: 3.0842700944276684
Validation loss: 2.744755402246612

Epoch: 5| Step: 1
Training loss: 2.625259204964247
Validation loss: 2.7276812953382437

Epoch: 5| Step: 2
Training loss: 2.983958270151882
Validation loss: 2.7203515332993833

Epoch: 5| Step: 3
Training loss: 3.0405258930987586
Validation loss: 2.7229795106459025

Epoch: 5| Step: 4
Training loss: 2.8476642875400975
Validation loss: 2.721390981886872

Epoch: 5| Step: 5
Training loss: 2.806219421084178
Validation loss: 2.7158941862340416

Epoch: 5| Step: 6
Training loss: 2.9698919408901
Validation loss: 2.716807079354261

Epoch: 5| Step: 7
Training loss: 3.115253661284344
Validation loss: 2.7108407982824447

Epoch: 5| Step: 8
Training loss: 3.2225198242903543
Validation loss: 2.7245337653485007

Epoch: 5| Step: 9
Training loss: 3.386348576538412
Validation loss: 2.725153392874674

Epoch: 5| Step: 10
Training loss: 2.9518368449623607
Validation loss: 2.7152752253434014

Epoch: 363| Step: 0
Training loss: 3.029013368976921
Validation loss: 2.7259373506305544

Epoch: 5| Step: 1
Training loss: 3.271477961747445
Validation loss: 2.72262034955501

Epoch: 5| Step: 2
Training loss: 2.8025492643574332
Validation loss: 2.7291266814077493

Epoch: 5| Step: 3
Training loss: 3.162702404676943
Validation loss: 2.734815443343125

Epoch: 5| Step: 4
Training loss: 3.219337039487465
Validation loss: 2.7495057583860514

Epoch: 5| Step: 5
Training loss: 2.9266934570731533
Validation loss: 2.739006622474354

Epoch: 5| Step: 6
Training loss: 2.6249217975411736
Validation loss: 2.7530272453585782

Epoch: 5| Step: 7
Training loss: 3.1030684881836557
Validation loss: 2.7594098983109547

Epoch: 5| Step: 8
Training loss: 3.1273286916773833
Validation loss: 2.7511165343511617

Epoch: 5| Step: 9
Training loss: 2.893481024153051
Validation loss: 2.7556561886220763

Epoch: 5| Step: 10
Training loss: 2.9038778488909096
Validation loss: 2.738843041988175

Epoch: 364| Step: 0
Training loss: 3.4391750069447693
Validation loss: 2.7320823459364822

Epoch: 5| Step: 1
Training loss: 3.264862847711627
Validation loss: 2.72563875450329

Epoch: 5| Step: 2
Training loss: 2.72955726177459
Validation loss: 2.7265915901288724

Epoch: 5| Step: 3
Training loss: 3.0417379257703687
Validation loss: 2.7051613178538187

Epoch: 5| Step: 4
Training loss: 3.14544732628704
Validation loss: 2.7035303750205855

Epoch: 5| Step: 5
Training loss: 2.6764366962109274
Validation loss: 2.697535496259151

Epoch: 5| Step: 6
Training loss: 2.7102518671256473
Validation loss: 2.6953717187644943

Epoch: 5| Step: 7
Training loss: 2.5261073677459014
Validation loss: 2.6974515369453407

Epoch: 5| Step: 8
Training loss: 2.952942534768914
Validation loss: 2.6959589024500445

Epoch: 5| Step: 9
Training loss: 3.171324583506494
Validation loss: 2.6972441806567318

Epoch: 5| Step: 10
Training loss: 3.403085761286282
Validation loss: 2.693469473704792

Epoch: 365| Step: 0
Training loss: 2.7825508932855776
Validation loss: 2.697711636675158

Epoch: 5| Step: 1
Training loss: 3.122064966907763
Validation loss: 2.6980613127773116

Epoch: 5| Step: 2
Training loss: 3.0078167803845357
Validation loss: 2.696847806939909

Epoch: 5| Step: 3
Training loss: 2.6566449040088314
Validation loss: 2.6970011353845607

Epoch: 5| Step: 4
Training loss: 3.42252793026904
Validation loss: 2.6978272099229668

Epoch: 5| Step: 5
Training loss: 2.851975502518872
Validation loss: 2.6949814659594082

Epoch: 5| Step: 6
Training loss: 3.136404057318923
Validation loss: 2.6966755135423766

Epoch: 5| Step: 7
Training loss: 3.092129061138507
Validation loss: 2.6955240022492117

Epoch: 5| Step: 8
Training loss: 2.97280959587232
Validation loss: 2.69682936511377

Epoch: 5| Step: 9
Training loss: 2.8489071540954525
Validation loss: 2.696500989185748

Epoch: 5| Step: 10
Training loss: 3.3087238885175623
Validation loss: 2.699283126633935

Epoch: 366| Step: 0
Training loss: 2.9631395832596836
Validation loss: 2.7073813548819725

Epoch: 5| Step: 1
Training loss: 2.7528546862011884
Validation loss: 2.7023446567035836

Epoch: 5| Step: 2
Training loss: 2.6464326635284587
Validation loss: 2.7107912157528555

Epoch: 5| Step: 3
Training loss: 2.999835009806301
Validation loss: 2.718631537655621

Epoch: 5| Step: 4
Training loss: 3.345692720859115
Validation loss: 2.7210615715660045

Epoch: 5| Step: 5
Training loss: 3.4448632187396346
Validation loss: 2.7144930785617603

Epoch: 5| Step: 6
Training loss: 3.407392957521597
Validation loss: 2.7131617965947172

Epoch: 5| Step: 7
Training loss: 3.4293717432328172
Validation loss: 2.704607010370103

Epoch: 5| Step: 8
Training loss: 2.587896797604667
Validation loss: 2.706708382431988

Epoch: 5| Step: 9
Training loss: 2.715836816742372
Validation loss: 2.7079657697245345

Epoch: 5| Step: 10
Training loss: 2.5822643919244648
Validation loss: 2.7094006431828825

Epoch: 367| Step: 0
Training loss: 2.8985918111929867
Validation loss: 2.699907607241389

Epoch: 5| Step: 1
Training loss: 3.0523279154991445
Validation loss: 2.698379899368488

Epoch: 5| Step: 2
Training loss: 1.6159999744301974
Validation loss: 2.7001461278916015

Epoch: 5| Step: 3
Training loss: 3.3232268345130955
Validation loss: 2.7026131253348775

Epoch: 5| Step: 4
Training loss: 2.817093975526813
Validation loss: 2.6975398888380018

Epoch: 5| Step: 5
Training loss: 3.2034140851827853
Validation loss: 2.695581241030888

Epoch: 5| Step: 6
Training loss: 3.1729137805534022
Validation loss: 2.698174758889339

Epoch: 5| Step: 7
Training loss: 3.3079971802502275
Validation loss: 2.7022922211566978

Epoch: 5| Step: 8
Training loss: 3.26586562734881
Validation loss: 2.7011613980347535

Epoch: 5| Step: 9
Training loss: 3.0360198884898075
Validation loss: 2.699234930256219

Epoch: 5| Step: 10
Training loss: 3.003612727196705
Validation loss: 2.6995486775539472

Epoch: 368| Step: 0
Training loss: 2.9456953614409196
Validation loss: 2.696466400506373

Epoch: 5| Step: 1
Training loss: 3.102483578991218
Validation loss: 2.7117522860681635

Epoch: 5| Step: 2
Training loss: 2.735370650900685
Validation loss: 2.7239344406860417

Epoch: 5| Step: 3
Training loss: 2.7315113003738105
Validation loss: 2.7374065576700812

Epoch: 5| Step: 4
Training loss: 2.923992348583976
Validation loss: 2.7259486963411432

Epoch: 5| Step: 5
Training loss: 2.597249164090236
Validation loss: 2.749986123677405

Epoch: 5| Step: 6
Training loss: 2.749929253795251
Validation loss: 2.7426040193316132

Epoch: 5| Step: 7
Training loss: 3.334074192368077
Validation loss: 2.7437149354696104

Epoch: 5| Step: 8
Training loss: 3.4325155012498927
Validation loss: 2.7332183275956883

Epoch: 5| Step: 9
Training loss: 3.091740427568259
Validation loss: 2.725276532930558

Epoch: 5| Step: 10
Training loss: 3.3724086844691596
Validation loss: 2.703474035661669

Epoch: 369| Step: 0
Training loss: 2.9229479772876026
Validation loss: 2.701579488419981

Epoch: 5| Step: 1
Training loss: 2.626694177961133
Validation loss: 2.6955032725780588

Epoch: 5| Step: 2
Training loss: 2.672318984950004
Validation loss: 2.694503031541485

Epoch: 5| Step: 3
Training loss: 3.1477816445262228
Validation loss: 2.6986628143727764

Epoch: 5| Step: 4
Training loss: 3.083310015478543
Validation loss: 2.6957398082874726

Epoch: 5| Step: 5
Training loss: 2.9649868856464887
Validation loss: 2.694984354948641

Epoch: 5| Step: 6
Training loss: 3.4890100416245065
Validation loss: 2.7046885295934278

Epoch: 5| Step: 7
Training loss: 2.916376499092744
Validation loss: 2.6983972969321117

Epoch: 5| Step: 8
Training loss: 3.4021996731477704
Validation loss: 2.7041046834996765

Epoch: 5| Step: 9
Training loss: 3.028167258204961
Validation loss: 2.7085999905782483

Epoch: 5| Step: 10
Training loss: 2.59566748646998
Validation loss: 2.7100288873483054

Epoch: 370| Step: 0
Training loss: 2.5946743708290656
Validation loss: 2.7135666415486472

Epoch: 5| Step: 1
Training loss: 2.4511255753844416
Validation loss: 2.707176217517716

Epoch: 5| Step: 2
Training loss: 3.26578123458133
Validation loss: 2.7183419971545915

Epoch: 5| Step: 3
Training loss: 2.5907379493893252
Validation loss: 2.7313307910163394

Epoch: 5| Step: 4
Training loss: 2.272598793559756
Validation loss: 2.7309451154113296

Epoch: 5| Step: 5
Training loss: 3.27969410656195
Validation loss: 2.727511959126971

Epoch: 5| Step: 6
Training loss: 3.4885882576790586
Validation loss: 2.7452923014467374

Epoch: 5| Step: 7
Training loss: 2.887967594482706
Validation loss: 2.7596278048828022

Epoch: 5| Step: 8
Training loss: 3.4226782565790614
Validation loss: 2.7642421547835996

Epoch: 5| Step: 9
Training loss: 3.724751478263899
Validation loss: 2.7670439619922296

Epoch: 5| Step: 10
Training loss: 2.719497402542706
Validation loss: 2.752085917289365

Epoch: 371| Step: 0
Training loss: 3.3120508429269035
Validation loss: 2.748277284938242

Epoch: 5| Step: 1
Training loss: 2.6362899318544923
Validation loss: 2.72664571241907

Epoch: 5| Step: 2
Training loss: 2.8220964955270254
Validation loss: 2.7140879675240424

Epoch: 5| Step: 3
Training loss: 3.55632219559743
Validation loss: 2.7092193845338746

Epoch: 5| Step: 4
Training loss: 2.6953900754517877
Validation loss: 2.695224294813859

Epoch: 5| Step: 5
Training loss: 2.785320603495729
Validation loss: 2.6894980022254162

Epoch: 5| Step: 6
Training loss: 2.915323020612666
Validation loss: 2.6910432627061542

Epoch: 5| Step: 7
Training loss: 2.7823828629534666
Validation loss: 2.6932810376289713

Epoch: 5| Step: 8
Training loss: 3.153512201646383
Validation loss: 2.6943412696591067

Epoch: 5| Step: 9
Training loss: 3.357358105260809
Validation loss: 2.687496503907334

Epoch: 5| Step: 10
Training loss: 2.9632631695067806
Validation loss: 2.6928591312397887

Epoch: 372| Step: 0
Training loss: 3.21990383170442
Validation loss: 2.690371230900527

Epoch: 5| Step: 1
Training loss: 2.9864924244065305
Validation loss: 2.6935214014355173

Epoch: 5| Step: 2
Training loss: 2.6412752693870316
Validation loss: 2.6996507379257975

Epoch: 5| Step: 3
Training loss: 2.978356489089013
Validation loss: 2.6942633661840603

Epoch: 5| Step: 4
Training loss: 3.2409733348715832
Validation loss: 2.6993603344004145

Epoch: 5| Step: 5
Training loss: 3.034018441965863
Validation loss: 2.714141092341979

Epoch: 5| Step: 6
Training loss: 2.966261935396934
Validation loss: 2.701229626180706

Epoch: 5| Step: 7
Training loss: 3.041334543428873
Validation loss: 2.7089711450294134

Epoch: 5| Step: 8
Training loss: 3.0032667811306037
Validation loss: 2.7038424235315244

Epoch: 5| Step: 9
Training loss: 2.583471038183524
Validation loss: 2.712222674703279

Epoch: 5| Step: 10
Training loss: 3.3372391388062197
Validation loss: 2.707449022911422

Epoch: 373| Step: 0
Training loss: 3.051555774562161
Validation loss: 2.705345803076073

Epoch: 5| Step: 1
Training loss: 2.762018988663509
Validation loss: 2.711383562187434

Epoch: 5| Step: 2
Training loss: 3.2583322087616864
Validation loss: 2.7131930259888186

Epoch: 5| Step: 3
Training loss: 3.2763785394736273
Validation loss: 2.7098971702362666

Epoch: 5| Step: 4
Training loss: 2.8212884709511754
Validation loss: 2.7072663552167504

Epoch: 5| Step: 5
Training loss: 3.0479247803405136
Validation loss: 2.7003408976398133

Epoch: 5| Step: 6
Training loss: 2.4917622266155406
Validation loss: 2.702134043154086

Epoch: 5| Step: 7
Training loss: 3.578239472402985
Validation loss: 2.695306031235846

Epoch: 5| Step: 8
Training loss: 2.5582090598209524
Validation loss: 2.6938684019921397

Epoch: 5| Step: 9
Training loss: 3.09913305650214
Validation loss: 2.692713662368345

Epoch: 5| Step: 10
Training loss: 3.0306842708632984
Validation loss: 2.684805530236435

Epoch: 374| Step: 0
Training loss: 2.3355092960696147
Validation loss: 2.6874116681314137

Epoch: 5| Step: 1
Training loss: 3.625752338079622
Validation loss: 2.6843450370849813

Epoch: 5| Step: 2
Training loss: 2.7113966319425176
Validation loss: 2.684399868843996

Epoch: 5| Step: 3
Training loss: 2.6368639644618828
Validation loss: 2.685074398656627

Epoch: 5| Step: 4
Training loss: 2.791766995197639
Validation loss: 2.6905819029179967

Epoch: 5| Step: 5
Training loss: 3.4391787504577453
Validation loss: 2.687926828726339

Epoch: 5| Step: 6
Training loss: 2.950395887287608
Validation loss: 2.6877017068301248

Epoch: 5| Step: 7
Training loss: 3.0028137680878366
Validation loss: 2.6873367252341525

Epoch: 5| Step: 8
Training loss: 3.2037296375784026
Validation loss: 2.6919899112995265

Epoch: 5| Step: 9
Training loss: 3.1438994537078333
Validation loss: 2.690891568795362

Epoch: 5| Step: 10
Training loss: 3.0100208449037975
Validation loss: 2.685113879247784

Epoch: 375| Step: 0
Training loss: 2.9599694755629913
Validation loss: 2.6905599536636364

Epoch: 5| Step: 1
Training loss: 3.140847269420183
Validation loss: 2.696204404494326

Epoch: 5| Step: 2
Training loss: 2.6465425717194386
Validation loss: 2.689943464354248

Epoch: 5| Step: 3
Training loss: 3.0126445054974385
Validation loss: 2.7040069903300172

Epoch: 5| Step: 4
Training loss: 3.4538480942305525
Validation loss: 2.713164195670476

Epoch: 5| Step: 5
Training loss: 3.0415784918837847
Validation loss: 2.7143232747150785

Epoch: 5| Step: 6
Training loss: 3.0324750174981636
Validation loss: 2.7191643960733907

Epoch: 5| Step: 7
Training loss: 3.3686613676340396
Validation loss: 2.7066746696043893

Epoch: 5| Step: 8
Training loss: 2.697964897362889
Validation loss: 2.6992893009431604

Epoch: 5| Step: 9
Training loss: 2.468214822053866
Validation loss: 2.6994639318361866

Epoch: 5| Step: 10
Training loss: 3.084259272204383
Validation loss: 2.694812163118172

Epoch: 376| Step: 0
Training loss: 3.571055529049182
Validation loss: 2.699076255842283

Epoch: 5| Step: 1
Training loss: 2.8384314466069815
Validation loss: 2.6935618746373584

Epoch: 5| Step: 2
Training loss: 3.066182005634174
Validation loss: 2.6925826035108127

Epoch: 5| Step: 3
Training loss: 2.9193943529543116
Validation loss: 2.69225324777173

Epoch: 5| Step: 4
Training loss: 3.054575418040463
Validation loss: 2.685438492512991

Epoch: 5| Step: 5
Training loss: 3.0744802516440113
Validation loss: 2.6809087456819802

Epoch: 5| Step: 6
Training loss: 2.783164918871537
Validation loss: 2.679447269138318

Epoch: 5| Step: 7
Training loss: 2.653194779735383
Validation loss: 2.6840134670222366

Epoch: 5| Step: 8
Training loss: 2.9331950032244563
Validation loss: 2.6791477794118945

Epoch: 5| Step: 9
Training loss: 3.038933523231162
Validation loss: 2.6813208841831444

Epoch: 5| Step: 10
Training loss: 3.003947839337421
Validation loss: 2.685087500040706

Epoch: 377| Step: 0
Training loss: 3.0908477733772197
Validation loss: 2.6812464900593427

Epoch: 5| Step: 1
Training loss: 3.247020823166094
Validation loss: 2.7042735477239424

Epoch: 5| Step: 2
Training loss: 2.9449093489627822
Validation loss: 2.724754732979496

Epoch: 5| Step: 3
Training loss: 3.034192102736508
Validation loss: 2.751261305338548

Epoch: 5| Step: 4
Training loss: 3.0163184440931894
Validation loss: 2.762438585308353

Epoch: 5| Step: 5
Training loss: 2.6181245407428277
Validation loss: 2.7476780169380906

Epoch: 5| Step: 6
Training loss: 3.1403642992213068
Validation loss: 2.7504464269081383

Epoch: 5| Step: 7
Training loss: 2.347089803849176
Validation loss: 2.735635862512224

Epoch: 5| Step: 8
Training loss: 3.3104826344246465
Validation loss: 2.725898788592264

Epoch: 5| Step: 9
Training loss: 3.1516148742045904
Validation loss: 2.692140665330718

Epoch: 5| Step: 10
Training loss: 3.141359765183925
Validation loss: 2.6815232336357933

Epoch: 378| Step: 0
Training loss: 3.385861474183975
Validation loss: 2.681922509826706

Epoch: 5| Step: 1
Training loss: 3.5162156350646288
Validation loss: 2.6749763894459924

Epoch: 5| Step: 2
Training loss: 2.3395005421810087
Validation loss: 2.679062709884823

Epoch: 5| Step: 3
Training loss: 3.2773777956552554
Validation loss: 2.6773250434485516

Epoch: 5| Step: 4
Training loss: 2.660040361342005
Validation loss: 2.6761904977261

Epoch: 5| Step: 5
Training loss: 2.92538192733468
Validation loss: 2.677069027661651

Epoch: 5| Step: 6
Training loss: 3.4120318137023995
Validation loss: 2.679769893993832

Epoch: 5| Step: 7
Training loss: 2.510392522629834
Validation loss: 2.678370820271604

Epoch: 5| Step: 8
Training loss: 2.605521640498118
Validation loss: 2.6801369783172215

Epoch: 5| Step: 9
Training loss: 2.7144573128745217
Validation loss: 2.6788903444510153

Epoch: 5| Step: 10
Training loss: 3.461373949624719
Validation loss: 2.681634669131512

Epoch: 379| Step: 0
Training loss: 2.958225588560227
Validation loss: 2.6784891623947282

Epoch: 5| Step: 1
Training loss: 3.2758395684052792
Validation loss: 2.684185303859902

Epoch: 5| Step: 2
Training loss: 2.6181784504570156
Validation loss: 2.6828383891612213

Epoch: 5| Step: 3
Training loss: 2.928609827833274
Validation loss: 2.693961202247001

Epoch: 5| Step: 4
Training loss: 2.447361973892727
Validation loss: 2.6997996132465847

Epoch: 5| Step: 5
Training loss: 2.7938383869296186
Validation loss: 2.7171325587086725

Epoch: 5| Step: 6
Training loss: 2.783668837817982
Validation loss: 2.716070107318062

Epoch: 5| Step: 7
Training loss: 3.62266860179922
Validation loss: 2.7217652494890503

Epoch: 5| Step: 8
Training loss: 2.9478206731221337
Validation loss: 2.704301775106943

Epoch: 5| Step: 9
Training loss: 3.2112532040471256
Validation loss: 2.6941639059566014

Epoch: 5| Step: 10
Training loss: 3.293474948118889
Validation loss: 2.6911996920256835

Epoch: 380| Step: 0
Training loss: 2.9619881167588775
Validation loss: 2.6908082158159927

Epoch: 5| Step: 1
Training loss: 3.2993264869263825
Validation loss: 2.6815366573449797

Epoch: 5| Step: 2
Training loss: 3.136583603243229
Validation loss: 2.682869349459708

Epoch: 5| Step: 3
Training loss: 2.673864059262507
Validation loss: 2.6902113828211363

Epoch: 5| Step: 4
Training loss: 2.6894517066081955
Validation loss: 2.685028958642904

Epoch: 5| Step: 5
Training loss: 2.7424145031297362
Validation loss: 2.6768500270013194

Epoch: 5| Step: 6
Training loss: 2.242265121764538
Validation loss: 2.6822453874864087

Epoch: 5| Step: 7
Training loss: 3.5448061921551375
Validation loss: 2.6846064801767886

Epoch: 5| Step: 8
Training loss: 2.917455421244467
Validation loss: 2.6826361685347893

Epoch: 5| Step: 9
Training loss: 3.3829301985424483
Validation loss: 2.692619738485269

Epoch: 5| Step: 10
Training loss: 3.1073219767588514
Validation loss: 2.6931128149404455

Epoch: 381| Step: 0
Training loss: 2.7647715830486077
Validation loss: 2.7014645872022816

Epoch: 5| Step: 1
Training loss: 2.7375893147151347
Validation loss: 2.703144700069081

Epoch: 5| Step: 2
Training loss: 3.4852016135613173
Validation loss: 2.6981073608990926

Epoch: 5| Step: 3
Training loss: 2.6998654155390645
Validation loss: 2.698482700317551

Epoch: 5| Step: 4
Training loss: 3.302903291160193
Validation loss: 2.6928682029696036

Epoch: 5| Step: 5
Training loss: 2.9878885247962126
Validation loss: 2.685840242025651

Epoch: 5| Step: 6
Training loss: 2.9712762624617475
Validation loss: 2.6794546200663287

Epoch: 5| Step: 7
Training loss: 2.895808011682982
Validation loss: 2.677520340576562

Epoch: 5| Step: 8
Training loss: 3.099167367419329
Validation loss: 2.6758834398991467

Epoch: 5| Step: 9
Training loss: 3.069958848459991
Validation loss: 2.6748002796293795

Epoch: 5| Step: 10
Training loss: 2.8409126295587868
Validation loss: 2.6785170192827605

Epoch: 382| Step: 0
Training loss: 2.7642759491926476
Validation loss: 2.678059112143826

Epoch: 5| Step: 1
Training loss: 2.9133416069082045
Validation loss: 2.678751892870417

Epoch: 5| Step: 2
Training loss: 3.3559351142912472
Validation loss: 2.6860838295067375

Epoch: 5| Step: 3
Training loss: 2.8486128928318792
Validation loss: 2.680478366315188

Epoch: 5| Step: 4
Training loss: 3.0306590969238982
Validation loss: 2.6850111822911082

Epoch: 5| Step: 5
Training loss: 3.2653395240520435
Validation loss: 2.6841069021780375

Epoch: 5| Step: 6
Training loss: 2.450414824886978
Validation loss: 2.6838373417348618

Epoch: 5| Step: 7
Training loss: 3.3315279044915354
Validation loss: 2.686487225491829

Epoch: 5| Step: 8
Training loss: 3.317812420436416
Validation loss: 2.687205013942572

Epoch: 5| Step: 9
Training loss: 2.855074624390726
Validation loss: 2.6889173886644118

Epoch: 5| Step: 10
Training loss: 2.588430810367276
Validation loss: 2.683020743996389

Epoch: 383| Step: 0
Training loss: 2.7837248517302102
Validation loss: 2.6901796998602148

Epoch: 5| Step: 1
Training loss: 3.1397568750713973
Validation loss: 2.690907886771224

Epoch: 5| Step: 2
Training loss: 3.276494676636578
Validation loss: 2.6837867464057883

Epoch: 5| Step: 3
Training loss: 2.897032857501172
Validation loss: 2.684178430062757

Epoch: 5| Step: 4
Training loss: 3.0162963119979542
Validation loss: 2.689741383312069

Epoch: 5| Step: 5
Training loss: 2.8543949639190416
Validation loss: 2.686640717255314

Epoch: 5| Step: 6
Training loss: 2.981042409263108
Validation loss: 2.675038300957746

Epoch: 5| Step: 7
Training loss: 3.025062144248032
Validation loss: 2.6798795819400105

Epoch: 5| Step: 8
Training loss: 2.9075809835502984
Validation loss: 2.6838115173836794

Epoch: 5| Step: 9
Training loss: 3.168299872877038
Validation loss: 2.6807402027671308

Epoch: 5| Step: 10
Training loss: 2.7809622969391494
Validation loss: 2.686424381624453

Epoch: 384| Step: 0
Training loss: 2.803579042335842
Validation loss: 2.685112589366056

Epoch: 5| Step: 1
Training loss: 2.768811044816564
Validation loss: 2.6753156215685645

Epoch: 5| Step: 2
Training loss: 3.246363145503804
Validation loss: 2.6850179517933404

Epoch: 5| Step: 3
Training loss: 3.332944434049849
Validation loss: 2.6850092115893665

Epoch: 5| Step: 4
Training loss: 2.5040684973272276
Validation loss: 2.6851892126124914

Epoch: 5| Step: 5
Training loss: 2.3121934636030486
Validation loss: 2.6855383493953746

Epoch: 5| Step: 6
Training loss: 3.27477271769188
Validation loss: 2.6959086820070826

Epoch: 5| Step: 7
Training loss: 2.674605998319442
Validation loss: 2.6916519320327326

Epoch: 5| Step: 8
Training loss: 2.585807958395011
Validation loss: 2.702317279767772

Epoch: 5| Step: 9
Training loss: 3.56553092651906
Validation loss: 2.711582532767036

Epoch: 5| Step: 10
Training loss: 3.57023677286519
Validation loss: 2.7132341411665135

Epoch: 385| Step: 0
Training loss: 3.2535501310415054
Validation loss: 2.699698526148056

Epoch: 5| Step: 1
Training loss: 3.2045737363057976
Validation loss: 2.692878121003812

Epoch: 5| Step: 2
Training loss: 2.4845402500686973
Validation loss: 2.685569947741184

Epoch: 5| Step: 3
Training loss: 3.2834726707467836
Validation loss: 2.6768717448571095

Epoch: 5| Step: 4
Training loss: 2.7885260399964933
Validation loss: 2.675507659015073

Epoch: 5| Step: 5
Training loss: 2.7908085505320237
Validation loss: 2.676831046119544

Epoch: 5| Step: 6
Training loss: 3.510554883520547
Validation loss: 2.6698612323541395

Epoch: 5| Step: 7
Training loss: 2.7902414944774336
Validation loss: 2.671447834898761

Epoch: 5| Step: 8
Training loss: 3.0843127645380237
Validation loss: 2.6786623767153706

Epoch: 5| Step: 9
Training loss: 2.7829402116774338
Validation loss: 2.677060587100743

Epoch: 5| Step: 10
Training loss: 2.812335200249866
Validation loss: 2.676101443854092

Epoch: 386| Step: 0
Training loss: 2.269398250392442
Validation loss: 2.6756837184404474

Epoch: 5| Step: 1
Training loss: 3.05708566174144
Validation loss: 2.676672258046997

Epoch: 5| Step: 2
Training loss: 2.8930782321092687
Validation loss: 2.677769911228905

Epoch: 5| Step: 3
Training loss: 3.4992040001468268
Validation loss: 2.682927986712568

Epoch: 5| Step: 4
Training loss: 3.3307334456467252
Validation loss: 2.6856123487558814

Epoch: 5| Step: 5
Training loss: 2.947579642037647
Validation loss: 2.681516538486724

Epoch: 5| Step: 6
Training loss: 3.031546037513446
Validation loss: 2.6856861904846743

Epoch: 5| Step: 7
Training loss: 2.950498674561449
Validation loss: 2.693477826676879

Epoch: 5| Step: 8
Training loss: 2.9258997324036224
Validation loss: 2.6787381183306267

Epoch: 5| Step: 9
Training loss: 3.2250705622560822
Validation loss: 2.688018806940407

Epoch: 5| Step: 10
Training loss: 2.4631031982262344
Validation loss: 2.6931968533503414

Epoch: 387| Step: 0
Training loss: 3.655510460814738
Validation loss: 2.6968358330758115

Epoch: 5| Step: 1
Training loss: 3.062732609848387
Validation loss: 2.699034425379644

Epoch: 5| Step: 2
Training loss: 2.5122642102791968
Validation loss: 2.7030903357998497

Epoch: 5| Step: 3
Training loss: 2.887927637181662
Validation loss: 2.706758330518759

Epoch: 5| Step: 4
Training loss: 2.5271756383061597
Validation loss: 2.696649165675545

Epoch: 5| Step: 5
Training loss: 3.135899875112947
Validation loss: 2.6994569953274086

Epoch: 5| Step: 6
Training loss: 2.922429486053025
Validation loss: 2.7050370014779106

Epoch: 5| Step: 7
Training loss: 2.892672581646913
Validation loss: 2.710911837348164

Epoch: 5| Step: 8
Training loss: 2.663956357569812
Validation loss: 2.711254879932103

Epoch: 5| Step: 9
Training loss: 3.3183481666416066
Validation loss: 2.702961654227869

Epoch: 5| Step: 10
Training loss: 3.1640510464684675
Validation loss: 2.700982262121182

Epoch: 388| Step: 0
Training loss: 2.4403104962890154
Validation loss: 2.6956626870286255

Epoch: 5| Step: 1
Training loss: 3.0138381645125802
Validation loss: 2.691689718926141

Epoch: 5| Step: 2
Training loss: 3.078790428153284
Validation loss: 2.687788675710309

Epoch: 5| Step: 3
Training loss: 3.28411275322997
Validation loss: 2.69250061112387

Epoch: 5| Step: 4
Training loss: 2.9186161247444247
Validation loss: 2.68946583711251

Epoch: 5| Step: 5
Training loss: 2.803900137974627
Validation loss: 2.6879757075957165

Epoch: 5| Step: 6
Training loss: 3.01362124268873
Validation loss: 2.69640412626456

Epoch: 5| Step: 7
Training loss: 2.789669280737832
Validation loss: 2.6963766975701224

Epoch: 5| Step: 8
Training loss: 3.014812617006507
Validation loss: 2.708470029828333

Epoch: 5| Step: 9
Training loss: 3.266110032853165
Validation loss: 2.700204979557084

Epoch: 5| Step: 10
Training loss: 3.144720491200043
Validation loss: 2.7004663073850956

Epoch: 389| Step: 0
Training loss: 2.6827832015431166
Validation loss: 2.690949335299755

Epoch: 5| Step: 1
Training loss: 2.833573630371689
Validation loss: 2.6866657968470498

Epoch: 5| Step: 2
Training loss: 2.813694255315641
Validation loss: 2.6756648557584555

Epoch: 5| Step: 3
Training loss: 2.915323020612666
Validation loss: 2.6748532972339762

Epoch: 5| Step: 4
Training loss: 3.2982666549638
Validation loss: 2.6654966835925595

Epoch: 5| Step: 5
Training loss: 3.0116650765827697
Validation loss: 2.677220937886338

Epoch: 5| Step: 6
Training loss: 3.0149003971785246
Validation loss: 2.67705734646988

Epoch: 5| Step: 7
Training loss: 3.188447250535251
Validation loss: 2.6806599865529805

Epoch: 5| Step: 8
Training loss: 2.905222229065506
Validation loss: 2.675348684114743

Epoch: 5| Step: 9
Training loss: 3.4264775507007985
Validation loss: 2.672732039390584

Epoch: 5| Step: 10
Training loss: 2.5616013416539336
Validation loss: 2.691295948772079

Epoch: 390| Step: 0
Training loss: 3.4627262082900954
Validation loss: 2.6862087653456204

Epoch: 5| Step: 1
Training loss: 3.2215719352433765
Validation loss: 2.6814032977804136

Epoch: 5| Step: 2
Training loss: 3.114458079461521
Validation loss: 2.6872944372859546

Epoch: 5| Step: 3
Training loss: 3.136545748945724
Validation loss: 2.6880232694332085

Epoch: 5| Step: 4
Training loss: 3.133670831995725
Validation loss: 2.6824939422528318

Epoch: 5| Step: 5
Training loss: 2.8294512763337143
Validation loss: 2.6827708696266126

Epoch: 5| Step: 6
Training loss: 2.5879206587290238
Validation loss: 2.6802940986767383

Epoch: 5| Step: 7
Training loss: 2.461912416172347
Validation loss: 2.6925179600319202

Epoch: 5| Step: 8
Training loss: 2.922589383027015
Validation loss: 2.7068817779740812

Epoch: 5| Step: 9
Training loss: 2.9452106650477874
Validation loss: 2.6935949054741752

Epoch: 5| Step: 10
Training loss: 2.9252154996340556
Validation loss: 2.688036365028109

Epoch: 391| Step: 0
Training loss: 2.98760172778473
Validation loss: 2.685018184763212

Epoch: 5| Step: 1
Training loss: 3.152048165645602
Validation loss: 2.6894992070751815

Epoch: 5| Step: 2
Training loss: 3.762146668936998
Validation loss: 2.6766571175509344

Epoch: 5| Step: 3
Training loss: 2.838509898343348
Validation loss: 2.676065299180048

Epoch: 5| Step: 4
Training loss: 2.54397680222833
Validation loss: 2.671686176967318

Epoch: 5| Step: 5
Training loss: 2.7024343854224155
Validation loss: 2.6684570461411634

Epoch: 5| Step: 6
Training loss: 2.751176755728313
Validation loss: 2.6647364709001407

Epoch: 5| Step: 7
Training loss: 3.0257579957209786
Validation loss: 2.6679151583672063

Epoch: 5| Step: 8
Training loss: 3.001060139578137
Validation loss: 2.667781645447341

Epoch: 5| Step: 9
Training loss: 2.753084966604465
Validation loss: 2.673040736231482

Epoch: 5| Step: 10
Training loss: 3.122795395450708
Validation loss: 2.673751634487216

Epoch: 392| Step: 0
Training loss: 2.9098049284582097
Validation loss: 2.676764162315129

Epoch: 5| Step: 1
Training loss: 3.5990823741833453
Validation loss: 2.692468807517257

Epoch: 5| Step: 2
Training loss: 2.240718559748516
Validation loss: 2.681842172204643

Epoch: 5| Step: 3
Training loss: 2.325020582866826
Validation loss: 2.689338015496584

Epoch: 5| Step: 4
Training loss: 3.6229754088723065
Validation loss: 2.7008000094446856

Epoch: 5| Step: 5
Training loss: 2.711803902465299
Validation loss: 2.7179068772775956

Epoch: 5| Step: 6
Training loss: 2.7798852036465247
Validation loss: 2.7076345774448023

Epoch: 5| Step: 7
Training loss: 3.773614788431931
Validation loss: 2.687974453422097

Epoch: 5| Step: 8
Training loss: 2.7996287508486057
Validation loss: 2.6829893067311765

Epoch: 5| Step: 9
Training loss: 2.517747066916919
Validation loss: 2.66898885650682

Epoch: 5| Step: 10
Training loss: 3.0771248833793856
Validation loss: 2.6680920349193427

Epoch: 393| Step: 0
Training loss: 2.911926304712595
Validation loss: 2.66557339848413

Epoch: 5| Step: 1
Training loss: 3.286536762412074
Validation loss: 2.6628037617530205

Epoch: 5| Step: 2
Training loss: 2.5822739941504036
Validation loss: 2.667203577721512

Epoch: 5| Step: 3
Training loss: 3.480674112514249
Validation loss: 2.664339318630502

Epoch: 5| Step: 4
Training loss: 2.9516720704500035
Validation loss: 2.6703016984640073

Epoch: 5| Step: 5
Training loss: 2.527618251792472
Validation loss: 2.671159311269233

Epoch: 5| Step: 6
Training loss: 2.984099210608602
Validation loss: 2.6850808911155526

Epoch: 5| Step: 7
Training loss: 2.703008042820669
Validation loss: 2.677448836373825

Epoch: 5| Step: 8
Training loss: 2.72633304012975
Validation loss: 2.6783313666302897

Epoch: 5| Step: 9
Training loss: 3.4869090902491435
Validation loss: 2.675868492300042

Epoch: 5| Step: 10
Training loss: 2.8999348600240684
Validation loss: 2.6797056072839167

Epoch: 394| Step: 0
Training loss: 3.258156444954693
Validation loss: 2.6838099450848443

Epoch: 5| Step: 1
Training loss: 3.114385966465961
Validation loss: 2.6812217049454223

Epoch: 5| Step: 2
Training loss: 3.1408036973512705
Validation loss: 2.679341861520662

Epoch: 5| Step: 3
Training loss: 2.452603229990486
Validation loss: 2.6839480421384443

Epoch: 5| Step: 4
Training loss: 3.2584855735966367
Validation loss: 2.6805958665576823

Epoch: 5| Step: 5
Training loss: 3.110227688369219
Validation loss: 2.6846343623975604

Epoch: 5| Step: 6
Training loss: 3.0420812211087913
Validation loss: 2.6900742057851446

Epoch: 5| Step: 7
Training loss: 2.6157196027813754
Validation loss: 2.6879716341521136

Epoch: 5| Step: 8
Training loss: 2.8526438713734956
Validation loss: 2.6744752378582963

Epoch: 5| Step: 9
Training loss: 2.9285214150707235
Validation loss: 2.6770635787434833

Epoch: 5| Step: 10
Training loss: 2.7964943568177683
Validation loss: 2.6844924224728297

Epoch: 395| Step: 0
Training loss: 2.25564365428928
Validation loss: 2.681633533404205

Epoch: 5| Step: 1
Training loss: 2.957576242916827
Validation loss: 2.6856796460336976

Epoch: 5| Step: 2
Training loss: 3.2718181382915694
Validation loss: 2.6820217501325403

Epoch: 5| Step: 3
Training loss: 3.1176212936335896
Validation loss: 2.679269677294662

Epoch: 5| Step: 4
Training loss: 2.8841392544738156
Validation loss: 2.6775727633633744

Epoch: 5| Step: 5
Training loss: 2.622008844717138
Validation loss: 2.6829223471191805

Epoch: 5| Step: 6
Training loss: 2.6365771446350315
Validation loss: 2.6934976258584307

Epoch: 5| Step: 7
Training loss: 3.5888748936992094
Validation loss: 2.7035950842276955

Epoch: 5| Step: 8
Training loss: 3.166381739463409
Validation loss: 2.7006389247063898

Epoch: 5| Step: 9
Training loss: 3.057106250727126
Validation loss: 2.6970414518085253

Epoch: 5| Step: 10
Training loss: 2.9397279123014526
Validation loss: 2.6830899646874706

Epoch: 396| Step: 0
Training loss: 2.80101823003707
Validation loss: 2.6782593781980575

Epoch: 5| Step: 1
Training loss: 2.948829069350922
Validation loss: 2.673320527717968

Epoch: 5| Step: 2
Training loss: 2.625222151302431
Validation loss: 2.666084226584857

Epoch: 5| Step: 3
Training loss: 3.5302851886474547
Validation loss: 2.66399935857217

Epoch: 5| Step: 4
Training loss: 3.0546394207773195
Validation loss: 2.665287309681029

Epoch: 5| Step: 5
Training loss: 2.693294931018365
Validation loss: 2.6626635523028104

Epoch: 5| Step: 6
Training loss: 2.8461720977562806
Validation loss: 2.662494281934242

Epoch: 5| Step: 7
Training loss: 2.9567353315956364
Validation loss: 2.6687095931249902

Epoch: 5| Step: 8
Training loss: 3.3400203546600515
Validation loss: 2.6687084855191743

Epoch: 5| Step: 9
Training loss: 2.860080986210122
Validation loss: 2.6726479243829426

Epoch: 5| Step: 10
Training loss: 2.925649235068222
Validation loss: 2.669319430833529

Epoch: 397| Step: 0
Training loss: 2.862296191293685
Validation loss: 2.6773783145911634

Epoch: 5| Step: 1
Training loss: 2.6595461869866694
Validation loss: 2.684170510418045

Epoch: 5| Step: 2
Training loss: 3.3480769886749506
Validation loss: 2.6864341344989113

Epoch: 5| Step: 3
Training loss: 2.806501986398407
Validation loss: 2.6972574130209486

Epoch: 5| Step: 4
Training loss: 2.5309508347033427
Validation loss: 2.686638423791637

Epoch: 5| Step: 5
Training loss: 3.3424795714205597
Validation loss: 2.6938154255414704

Epoch: 5| Step: 6
Training loss: 3.226805153651796
Validation loss: 2.700844989534572

Epoch: 5| Step: 7
Training loss: 2.731096667562018
Validation loss: 2.7084195160385884

Epoch: 5| Step: 8
Training loss: 2.232758691031229
Validation loss: 2.720973679115262

Epoch: 5| Step: 9
Training loss: 3.523486490183947
Validation loss: 2.6915038823805064

Epoch: 5| Step: 10
Training loss: 3.2388693134057274
Validation loss: 2.6710585890637026

Epoch: 398| Step: 0
Training loss: 2.8946363504662256
Validation loss: 2.6644629908565167

Epoch: 5| Step: 1
Training loss: 3.1006606782330324
Validation loss: 2.6623911197778067

Epoch: 5| Step: 2
Training loss: 3.1805408279396317
Validation loss: 2.6596035233959014

Epoch: 5| Step: 3
Training loss: 2.5715979981994197
Validation loss: 2.66255048416745

Epoch: 5| Step: 4
Training loss: 2.9046429528590516
Validation loss: 2.6633771101851558

Epoch: 5| Step: 5
Training loss: 2.736437036387603
Validation loss: 2.6638894103524122

Epoch: 5| Step: 6
Training loss: 2.854713517494842
Validation loss: 2.667128167928628

Epoch: 5| Step: 7
Training loss: 3.324026243416099
Validation loss: 2.656075657063935

Epoch: 5| Step: 8
Training loss: 3.144382032562077
Validation loss: 2.658430795049527

Epoch: 5| Step: 9
Training loss: 3.0898287805322435
Validation loss: 2.661908256035767

Epoch: 5| Step: 10
Training loss: 3.005695182375936
Validation loss: 2.6559673972119793

Epoch: 399| Step: 0
Training loss: 2.50353115563256
Validation loss: 2.667255852455276

Epoch: 5| Step: 1
Training loss: 2.835033430275779
Validation loss: 2.660116403814433

Epoch: 5| Step: 2
Training loss: 3.4708012195092186
Validation loss: 2.666587542570046

Epoch: 5| Step: 3
Training loss: 3.0522169967043142
Validation loss: 2.673972024055678

Epoch: 5| Step: 4
Training loss: 3.3788053464431527
Validation loss: 2.695019478227256

Epoch: 5| Step: 5
Training loss: 3.312780116491242
Validation loss: 2.69657391288693

Epoch: 5| Step: 6
Training loss: 2.6773259291711127
Validation loss: 2.7068087304015873

Epoch: 5| Step: 7
Training loss: 2.4485169885290228
Validation loss: 2.7122113245064643

Epoch: 5| Step: 8
Training loss: 3.237996750356965
Validation loss: 2.708251024861835

Epoch: 5| Step: 9
Training loss: 2.343181592044697
Validation loss: 2.70665451406946

Epoch: 5| Step: 10
Training loss: 3.237667158959078
Validation loss: 2.696931164322006

Epoch: 400| Step: 0
Training loss: 3.1091556950967476
Validation loss: 2.675279544855734

Epoch: 5| Step: 1
Training loss: 3.113035874407277
Validation loss: 2.6606803164479

Epoch: 5| Step: 2
Training loss: 2.937890858720573
Validation loss: 2.6604944549930813

Epoch: 5| Step: 3
Training loss: 2.775480393763972
Validation loss: 2.65597061917444

Epoch: 5| Step: 4
Training loss: 3.1437361002135096
Validation loss: 2.6566207974384795

Epoch: 5| Step: 5
Training loss: 3.076380976276158
Validation loss: 2.662966825177999

Epoch: 5| Step: 6
Training loss: 3.386965275188039
Validation loss: 2.669770248518133

Epoch: 5| Step: 7
Training loss: 2.4229775165013794
Validation loss: 2.6683098539798595

Epoch: 5| Step: 8
Training loss: 3.159250928968755
Validation loss: 2.6731469423218273

Epoch: 5| Step: 9
Training loss: 2.809497077843972
Validation loss: 2.673353803853575

Epoch: 5| Step: 10
Training loss: 2.696591015977839
Validation loss: 2.672122408711328

Epoch: 401| Step: 0
Training loss: 3.4579221795119315
Validation loss: 2.6731684322846654

Epoch: 5| Step: 1
Training loss: 2.818342963558853
Validation loss: 2.670949510207254

Epoch: 5| Step: 2
Training loss: 2.252649019415873
Validation loss: 2.6712037285316117

Epoch: 5| Step: 3
Training loss: 2.754507532153423
Validation loss: 2.673017316050898

Epoch: 5| Step: 4
Training loss: 3.2862345301400753
Validation loss: 2.675278883649222

Epoch: 5| Step: 5
Training loss: 2.5924699681160237
Validation loss: 2.672052579614496

Epoch: 5| Step: 6
Training loss: 2.894180667871522
Validation loss: 2.66831612397849

Epoch: 5| Step: 7
Training loss: 3.309977020460499
Validation loss: 2.6707784583881518

Epoch: 5| Step: 8
Training loss: 2.957114940350946
Validation loss: 2.662538758536485

Epoch: 5| Step: 9
Training loss: 3.137492729269775
Validation loss: 2.662223640544998

Epoch: 5| Step: 10
Training loss: 2.9803919551050138
Validation loss: 2.665449240130526

Epoch: 402| Step: 0
Training loss: 2.5038181711972864
Validation loss: 2.6761961840756547

Epoch: 5| Step: 1
Training loss: 2.8434412862029514
Validation loss: 2.6808694240615796

Epoch: 5| Step: 2
Training loss: 3.125944833972843
Validation loss: 2.6786300278917725

Epoch: 5| Step: 3
Training loss: 2.965460953029129
Validation loss: 2.685025275057919

Epoch: 5| Step: 4
Training loss: 2.7289093323348075
Validation loss: 2.6935050478965796

Epoch: 5| Step: 5
Training loss: 3.0802499630053934
Validation loss: 2.6914063614458095

Epoch: 5| Step: 6
Training loss: 3.259968069657362
Validation loss: 2.6971111852330676

Epoch: 5| Step: 7
Training loss: 2.982160775397568
Validation loss: 2.6835327332561087

Epoch: 5| Step: 8
Training loss: 3.299345708775918
Validation loss: 2.6926464323533965

Epoch: 5| Step: 9
Training loss: 2.774190279385643
Validation loss: 2.689156062349947

Epoch: 5| Step: 10
Training loss: 2.912958094380889
Validation loss: 2.687585336637664

Epoch: 403| Step: 0
Training loss: 2.9637127353701826
Validation loss: 2.699398363831884

Epoch: 5| Step: 1
Training loss: 2.9191127510838015
Validation loss: 2.684787668376159

Epoch: 5| Step: 2
Training loss: 2.7063154675183387
Validation loss: 2.6879922120845303

Epoch: 5| Step: 3
Training loss: 2.9960649431775996
Validation loss: 2.682688418725102

Epoch: 5| Step: 4
Training loss: 2.391891742265935
Validation loss: 2.6980160620332976

Epoch: 5| Step: 5
Training loss: 2.9098308202061642
Validation loss: 2.692443841013438

Epoch: 5| Step: 6
Training loss: 3.2580389223156514
Validation loss: 2.701793242300343

Epoch: 5| Step: 7
Training loss: 3.0040773657983824
Validation loss: 2.691232634686204

Epoch: 5| Step: 8
Training loss: 3.307237871989093
Validation loss: 2.682687567742061

Epoch: 5| Step: 9
Training loss: 2.9808376578908478
Validation loss: 2.686672347483727

Epoch: 5| Step: 10
Training loss: 3.0120765483394742
Validation loss: 2.685677230997439

Epoch: 404| Step: 0
Training loss: 2.652633089399346
Validation loss: 2.6824236099728624

Epoch: 5| Step: 1
Training loss: 3.240071610495314
Validation loss: 2.6808317897089036

Epoch: 5| Step: 2
Training loss: 2.61482975217767
Validation loss: 2.6722423773687902

Epoch: 5| Step: 3
Training loss: 2.7952585504058374
Validation loss: 2.6825326169576416

Epoch: 5| Step: 4
Training loss: 2.374935450429606
Validation loss: 2.674811265267764

Epoch: 5| Step: 5
Training loss: 3.3866608822640507
Validation loss: 2.6745503992813844

Epoch: 5| Step: 6
Training loss: 3.3756549341025455
Validation loss: 2.683184607201978

Epoch: 5| Step: 7
Training loss: 2.9752668629694026
Validation loss: 2.679489148013349

Epoch: 5| Step: 8
Training loss: 2.9062257170944537
Validation loss: 2.674987928301737

Epoch: 5| Step: 9
Training loss: 3.1318740009769876
Validation loss: 2.6858735424947673

Epoch: 5| Step: 10
Training loss: 2.9569939997756967
Validation loss: 2.679866650247871

Epoch: 405| Step: 0
Training loss: 2.763438076738338
Validation loss: 2.6887809350746474

Epoch: 5| Step: 1
Training loss: 2.304520526591792
Validation loss: 2.6820830660184605

Epoch: 5| Step: 2
Training loss: 2.3795878619288593
Validation loss: 2.6816868164695973

Epoch: 5| Step: 3
Training loss: 2.80655474123229
Validation loss: 2.6873261361379472

Epoch: 5| Step: 4
Training loss: 2.909487817791551
Validation loss: 2.6812926510301014

Epoch: 5| Step: 5
Training loss: 2.732718963505431
Validation loss: 2.6859387066759965

Epoch: 5| Step: 6
Training loss: 3.542430361518902
Validation loss: 2.68413608376037

Epoch: 5| Step: 7
Training loss: 3.118416527175754
Validation loss: 2.6851194960978555

Epoch: 5| Step: 8
Training loss: 3.346165435258273
Validation loss: 2.682767969396249

Epoch: 5| Step: 9
Training loss: 3.2913956510462357
Validation loss: 2.683586915765698

Epoch: 5| Step: 10
Training loss: 3.165561349272173
Validation loss: 2.676356000425539

Epoch: 406| Step: 0
Training loss: 3.8575420274008763
Validation loss: 2.68397557301233

Epoch: 5| Step: 1
Training loss: 2.9615741940990303
Validation loss: 2.6869709641744732

Epoch: 5| Step: 2
Training loss: 2.4170414096945008
Validation loss: 2.684738821224752

Epoch: 5| Step: 3
Training loss: 3.452689441121378
Validation loss: 2.6742603491946464

Epoch: 5| Step: 4
Training loss: 2.399433637390899
Validation loss: 2.6782181185582963

Epoch: 5| Step: 5
Training loss: 3.1742289410370494
Validation loss: 2.682041174118459

Epoch: 5| Step: 6
Training loss: 3.009379981681527
Validation loss: 2.684129842120412

Epoch: 5| Step: 7
Training loss: 3.0883972408670197
Validation loss: 2.682818017281038

Epoch: 5| Step: 8
Training loss: 2.4890964196833987
Validation loss: 2.6881955709248135

Epoch: 5| Step: 9
Training loss: 2.4226339812179436
Validation loss: 2.6888421406833847

Epoch: 5| Step: 10
Training loss: 2.93247035799387
Validation loss: 2.6979596840156175

Epoch: 407| Step: 0
Training loss: 2.4667379171373804
Validation loss: 2.696516427072714

Epoch: 5| Step: 1
Training loss: 2.8718933237713684
Validation loss: 2.702023257633582

Epoch: 5| Step: 2
Training loss: 3.014344887485174
Validation loss: 2.6911086789474896

Epoch: 5| Step: 3
Training loss: 2.1178745407827173
Validation loss: 2.6905988325730483

Epoch: 5| Step: 4
Training loss: 3.263198023696679
Validation loss: 2.688710526974356

Epoch: 5| Step: 5
Training loss: 3.42043660907196
Validation loss: 2.678493170818245

Epoch: 5| Step: 6
Training loss: 2.981362944888675
Validation loss: 2.6588055617252113

Epoch: 5| Step: 7
Training loss: 3.5785428931733163
Validation loss: 2.660128550671146

Epoch: 5| Step: 8
Training loss: 3.1270423318884513
Validation loss: 2.658850639014463

Epoch: 5| Step: 9
Training loss: 2.7699648325371267
Validation loss: 2.6510849035790574

Epoch: 5| Step: 10
Training loss: 2.6217514099891375
Validation loss: 2.6535992101073433

Epoch: 408| Step: 0
Training loss: 2.600457950755963
Validation loss: 2.6503282131687844

Epoch: 5| Step: 1
Training loss: 3.044080812622164
Validation loss: 2.6513703464019454

Epoch: 5| Step: 2
Training loss: 3.1004747457916815
Validation loss: 2.6520138011454417

Epoch: 5| Step: 3
Training loss: 2.760670162053472
Validation loss: 2.6608710853108066

Epoch: 5| Step: 4
Training loss: 2.7040920402053357
Validation loss: 2.66812206809035

Epoch: 5| Step: 5
Training loss: 3.058538092914343
Validation loss: 2.666476270456952

Epoch: 5| Step: 6
Training loss: 2.8862609913295785
Validation loss: 2.685577438463974

Epoch: 5| Step: 7
Training loss: 3.258946063746857
Validation loss: 2.69796973014059

Epoch: 5| Step: 8
Training loss: 3.2517680714051487
Validation loss: 2.7017889401369817

Epoch: 5| Step: 9
Training loss: 2.6547346392707216
Validation loss: 2.6812921050848644

Epoch: 5| Step: 10
Training loss: 3.2265276225793538
Validation loss: 2.6801684681695086

Epoch: 409| Step: 0
Training loss: 2.4266257666540096
Validation loss: 2.67827510118509

Epoch: 5| Step: 1
Training loss: 2.9807480747428166
Validation loss: 2.6756571475738613

Epoch: 5| Step: 2
Training loss: 2.8523780806060195
Validation loss: 2.684210049192858

Epoch: 5| Step: 3
Training loss: 2.993218226977292
Validation loss: 2.670841368521293

Epoch: 5| Step: 4
Training loss: 3.01477323372038
Validation loss: 2.668732708647791

Epoch: 5| Step: 5
Training loss: 2.8885290846955867
Validation loss: 2.6619063279413635

Epoch: 5| Step: 6
Training loss: 3.062298670787826
Validation loss: 2.6578783250026596

Epoch: 5| Step: 7
Training loss: 2.7416208230527137
Validation loss: 2.6602562579623714

Epoch: 5| Step: 8
Training loss: 3.2536669364934037
Validation loss: 2.6611840350559413

Epoch: 5| Step: 9
Training loss: 3.135727741275895
Validation loss: 2.658172933467568

Epoch: 5| Step: 10
Training loss: 3.0685020331055433
Validation loss: 2.6736337289402616

Epoch: 410| Step: 0
Training loss: 3.79638995302314
Validation loss: 2.6691576131984136

Epoch: 5| Step: 1
Training loss: 2.87798138155558
Validation loss: 2.672862027663351

Epoch: 5| Step: 2
Training loss: 3.3606572032972553
Validation loss: 2.6768090396590507

Epoch: 5| Step: 3
Training loss: 2.2860954767215045
Validation loss: 2.6770305977085678

Epoch: 5| Step: 4
Training loss: 2.7177477337481513
Validation loss: 2.681759529282012

Epoch: 5| Step: 5
Training loss: 2.920144450912793
Validation loss: 2.6783057658174134

Epoch: 5| Step: 6
Training loss: 2.74217871857457
Validation loss: 2.6840599653255817

Epoch: 5| Step: 7
Training loss: 2.6056283332874757
Validation loss: 2.6714361540784846

Epoch: 5| Step: 8
Training loss: 3.0453038003639685
Validation loss: 2.6649530077377013

Epoch: 5| Step: 9
Training loss: 3.1229691582243033
Validation loss: 2.662936127356551

Epoch: 5| Step: 10
Training loss: 2.7073809685435455
Validation loss: 2.6614642537613067

Epoch: 411| Step: 0
Training loss: 3.1865936187394857
Validation loss: 2.6619202955187347

Epoch: 5| Step: 1
Training loss: 3.1879584786787585
Validation loss: 2.6618293628966496

Epoch: 5| Step: 2
Training loss: 3.0064174042405534
Validation loss: 2.6516112521084865

Epoch: 5| Step: 3
Training loss: 2.7737142075596948
Validation loss: 2.6613013188671597

Epoch: 5| Step: 4
Training loss: 2.819078846630237
Validation loss: 2.6660514818614165

Epoch: 5| Step: 5
Training loss: 2.9302471796130733
Validation loss: 2.6689698581402754

Epoch: 5| Step: 6
Training loss: 2.991330813485123
Validation loss: 2.6633593308162298

Epoch: 5| Step: 7
Training loss: 2.697384422166641
Validation loss: 2.6789689858811667

Epoch: 5| Step: 8
Training loss: 2.7622536838550777
Validation loss: 2.682062393044512

Epoch: 5| Step: 9
Training loss: 3.1325414069408133
Validation loss: 2.6677422360454544

Epoch: 5| Step: 10
Training loss: 2.9582355823396007
Validation loss: 2.6729410248487047

Epoch: 412| Step: 0
Training loss: 3.3369702208015886
Validation loss: 2.664091222724482

Epoch: 5| Step: 1
Training loss: 3.0210377240368436
Validation loss: 2.671560366218739

Epoch: 5| Step: 2
Training loss: 2.8698560057880114
Validation loss: 2.6740650306445053

Epoch: 5| Step: 3
Training loss: 3.5303859497544505
Validation loss: 2.6718982934671027

Epoch: 5| Step: 4
Training loss: 2.372021463769871
Validation loss: 2.6649966314052436

Epoch: 5| Step: 5
Training loss: 3.090559730573442
Validation loss: 2.675087518825345

Epoch: 5| Step: 6
Training loss: 2.920568816813793
Validation loss: 2.6670023747857714

Epoch: 5| Step: 7
Training loss: 2.938138851740907
Validation loss: 2.668862283666435

Epoch: 5| Step: 8
Training loss: 2.746154610839849
Validation loss: 2.6649832802223234

Epoch: 5| Step: 9
Training loss: 2.629099687145299
Validation loss: 2.6653034035203125

Epoch: 5| Step: 10
Training loss: 2.8543147770304715
Validation loss: 2.666722578441868

Epoch: 413| Step: 0
Training loss: 3.127189327089644
Validation loss: 2.6774002785509032

Epoch: 5| Step: 1
Training loss: 3.1954638158510082
Validation loss: 2.672000435182353

Epoch: 5| Step: 2
Training loss: 2.5157090640978987
Validation loss: 2.6746971655879905

Epoch: 5| Step: 3
Training loss: 2.9028651717646716
Validation loss: 2.665203238663387

Epoch: 5| Step: 4
Training loss: 3.206719293882884
Validation loss: 2.676475747710388

Epoch: 5| Step: 5
Training loss: 3.542672242666194
Validation loss: 2.6810714566620413

Epoch: 5| Step: 6
Training loss: 2.9885981373034993
Validation loss: 2.683285327576987

Epoch: 5| Step: 7
Training loss: 2.362507136904316
Validation loss: 2.6735889114447646

Epoch: 5| Step: 8
Training loss: 2.9402029709591497
Validation loss: 2.6762536935037007

Epoch: 5| Step: 9
Training loss: 2.194355060135859
Validation loss: 2.6705903517059753

Epoch: 5| Step: 10
Training loss: 3.2127273657229063
Validation loss: 2.6771621727605455

Epoch: 414| Step: 0
Training loss: 2.4825193564590977
Validation loss: 2.6702513449433294

Epoch: 5| Step: 1
Training loss: 2.6577883585304973
Validation loss: 2.683460793601325

Epoch: 5| Step: 2
Training loss: 3.3595862033899073
Validation loss: 2.706600347219969

Epoch: 5| Step: 3
Training loss: 2.911422556394019
Validation loss: 2.697292350826788

Epoch: 5| Step: 4
Training loss: 3.1714642639311856
Validation loss: 2.6884399872623876

Epoch: 5| Step: 5
Training loss: 2.5061090215668025
Validation loss: 2.692082078280988

Epoch: 5| Step: 6
Training loss: 2.530186088111389
Validation loss: 2.6908162888463227

Epoch: 5| Step: 7
Training loss: 3.1059226034313636
Validation loss: 2.6766729706289625

Epoch: 5| Step: 8
Training loss: 3.0411835552440785
Validation loss: 2.6699874765089278

Epoch: 5| Step: 9
Training loss: 3.3987089903680334
Validation loss: 2.6687169467321707

Epoch: 5| Step: 10
Training loss: 3.1019171600889344
Validation loss: 2.653703774783079

Epoch: 415| Step: 0
Training loss: 2.8312027344116215
Validation loss: 2.6529751070209424

Epoch: 5| Step: 1
Training loss: 2.1437913629306093
Validation loss: 2.651828697314871

Epoch: 5| Step: 2
Training loss: 3.626896592266067
Validation loss: 2.65238630425068

Epoch: 5| Step: 3
Training loss: 2.5338359856941572
Validation loss: 2.645688724869709

Epoch: 5| Step: 4
Training loss: 2.636259816107601
Validation loss: 2.658829837470137

Epoch: 5| Step: 5
Training loss: 3.1914970917303744
Validation loss: 2.6491541107004775

Epoch: 5| Step: 6
Training loss: 3.2897401958719246
Validation loss: 2.659191981317514

Epoch: 5| Step: 7
Training loss: 2.8146378762932023
Validation loss: 2.650672397722812

Epoch: 5| Step: 8
Training loss: 3.0113059625615413
Validation loss: 2.673093841961992

Epoch: 5| Step: 9
Training loss: 3.2517387434027785
Validation loss: 2.6787256797445362

Epoch: 5| Step: 10
Training loss: 2.787886171148975
Validation loss: 2.6837184903464504

Epoch: 416| Step: 0
Training loss: 3.676671827306322
Validation loss: 2.6768004373804244

Epoch: 5| Step: 1
Training loss: 2.8454224415989247
Validation loss: 2.6688188154022643

Epoch: 5| Step: 2
Training loss: 2.7255131579543197
Validation loss: 2.6707221259729588

Epoch: 5| Step: 3
Training loss: 2.71871448362106
Validation loss: 2.66798573282275

Epoch: 5| Step: 4
Training loss: 2.672421583518617
Validation loss: 2.6782174063874415

Epoch: 5| Step: 5
Training loss: 2.9748539864747525
Validation loss: 2.669278384522393

Epoch: 5| Step: 6
Training loss: 2.650441989386907
Validation loss: 2.675092035473129

Epoch: 5| Step: 7
Training loss: 2.4024168918299043
Validation loss: 2.671010588849721

Epoch: 5| Step: 8
Training loss: 3.0712687238495886
Validation loss: 2.6742964933394564

Epoch: 5| Step: 9
Training loss: 3.047212239699896
Validation loss: 2.6820679245239805

Epoch: 5| Step: 10
Training loss: 3.4168598926769125
Validation loss: 2.6770390967800926

Epoch: 417| Step: 0
Training loss: 2.937683911349294
Validation loss: 2.670363508109439

Epoch: 5| Step: 1
Training loss: 2.9942892078776553
Validation loss: 2.6913302238320176

Epoch: 5| Step: 2
Training loss: 2.703222901440169
Validation loss: 2.704061974221543

Epoch: 5| Step: 3
Training loss: 2.6808995655887458
Validation loss: 2.6793434871527553

Epoch: 5| Step: 4
Training loss: 3.103979903028259
Validation loss: 2.679503679316236

Epoch: 5| Step: 5
Training loss: 3.3758344678296965
Validation loss: 2.666531088930621

Epoch: 5| Step: 6
Training loss: 3.0173704798096566
Validation loss: 2.669787728809321

Epoch: 5| Step: 7
Training loss: 3.1910179023300267
Validation loss: 2.6597696076070605

Epoch: 5| Step: 8
Training loss: 2.7558714003270146
Validation loss: 2.660283346920867

Epoch: 5| Step: 9
Training loss: 3.014969986850026
Validation loss: 2.6591462417044203

Epoch: 5| Step: 10
Training loss: 2.4276838964859744
Validation loss: 2.658155813689208

Epoch: 418| Step: 0
Training loss: 3.5498705074709433
Validation loss: 2.6494319209362396

Epoch: 5| Step: 1
Training loss: 2.621241922070486
Validation loss: 2.651890041373461

Epoch: 5| Step: 2
Training loss: 2.819784690943191
Validation loss: 2.653810125379321

Epoch: 5| Step: 3
Training loss: 2.5185540248460256
Validation loss: 2.6562330135644405

Epoch: 5| Step: 4
Training loss: 2.765705516957791
Validation loss: 2.6609144261683966

Epoch: 5| Step: 5
Training loss: 2.6789459003085123
Validation loss: 2.668018233765927

Epoch: 5| Step: 6
Training loss: 3.5819354028888837
Validation loss: 2.6663940531323207

Epoch: 5| Step: 7
Training loss: 3.1231418425796913
Validation loss: 2.6719308053462547

Epoch: 5| Step: 8
Training loss: 3.0971382160131884
Validation loss: 2.6766840003008934

Epoch: 5| Step: 9
Training loss: 2.49115466297671
Validation loss: 2.669804789363292

Epoch: 5| Step: 10
Training loss: 3.002702131876127
Validation loss: 2.682957713346577

Epoch: 419| Step: 0
Training loss: 2.9602634598785444
Validation loss: 2.668337756609663

Epoch: 5| Step: 1
Training loss: 3.2475653111892075
Validation loss: 2.6730966011581656

Epoch: 5| Step: 2
Training loss: 3.3079229438229825
Validation loss: 2.6713008795111355

Epoch: 5| Step: 3
Training loss: 2.8535914897298786
Validation loss: 2.6655285637627717

Epoch: 5| Step: 4
Training loss: 2.614276052303759
Validation loss: 2.665241746814013

Epoch: 5| Step: 5
Training loss: 3.2865374878521645
Validation loss: 2.6532480029671817

Epoch: 5| Step: 6
Training loss: 2.761823207061413
Validation loss: 2.6578093457067475

Epoch: 5| Step: 7
Training loss: 2.2693054822287775
Validation loss: 2.6742793943362915

Epoch: 5| Step: 8
Training loss: 2.8985714123167305
Validation loss: 2.695387270596106

Epoch: 5| Step: 9
Training loss: 3.081205888474974
Validation loss: 2.68058165104093

Epoch: 5| Step: 10
Training loss: 2.9621651955231747
Validation loss: 2.680908753332045

Epoch: 420| Step: 0
Training loss: 3.395464137939927
Validation loss: 2.6643103955531764

Epoch: 5| Step: 1
Training loss: 2.788944615883415
Validation loss: 2.6570318336965104

Epoch: 5| Step: 2
Training loss: 2.747277212369368
Validation loss: 2.650358121661173

Epoch: 5| Step: 3
Training loss: 2.7228199103710007
Validation loss: 2.659206156928638

Epoch: 5| Step: 4
Training loss: 3.0726961390788956
Validation loss: 2.6564949641715137

Epoch: 5| Step: 5
Training loss: 2.8678975486386022
Validation loss: 2.6660610890605327

Epoch: 5| Step: 6
Training loss: 2.5092774862722522
Validation loss: 2.6662500417166948

Epoch: 5| Step: 7
Training loss: 3.4598854136373487
Validation loss: 2.6628913156228107

Epoch: 5| Step: 8
Training loss: 2.995462960457556
Validation loss: 2.674369968823045

Epoch: 5| Step: 9
Training loss: 2.574429446962273
Validation loss: 2.675298641195908

Epoch: 5| Step: 10
Training loss: 3.164600166508747
Validation loss: 2.672697515273691

Epoch: 421| Step: 0
Training loss: 3.2436287859133426
Validation loss: 2.668329434466127

Epoch: 5| Step: 1
Training loss: 2.702512903315029
Validation loss: 2.6627800305789413

Epoch: 5| Step: 2
Training loss: 3.044885230195627
Validation loss: 2.6644634339313193

Epoch: 5| Step: 3
Training loss: 3.106436256028531
Validation loss: 2.661775041844787

Epoch: 5| Step: 4
Training loss: 2.813011970546081
Validation loss: 2.671118454951082

Epoch: 5| Step: 5
Training loss: 2.9599422503327957
Validation loss: 2.665153402515352

Epoch: 5| Step: 6
Training loss: 2.9506636762033587
Validation loss: 2.672388259321493

Epoch: 5| Step: 7
Training loss: 2.783501731514328
Validation loss: 2.6664646284286433

Epoch: 5| Step: 8
Training loss: 2.8904959984939556
Validation loss: 2.661308877898283

Epoch: 5| Step: 9
Training loss: 2.4539411608505914
Validation loss: 2.6506192223941416

Epoch: 5| Step: 10
Training loss: 3.356236042583292
Validation loss: 2.64736630290778

Epoch: 422| Step: 0
Training loss: 2.8334314291933076
Validation loss: 2.647437265370122

Epoch: 5| Step: 1
Training loss: 2.789868663034592
Validation loss: 2.655364892955155

Epoch: 5| Step: 2
Training loss: 2.928957265764192
Validation loss: 2.6445414443181656

Epoch: 5| Step: 3
Training loss: 3.19591384116521
Validation loss: 2.645605127015915

Epoch: 5| Step: 4
Training loss: 2.9845330161557815
Validation loss: 2.652777811530142

Epoch: 5| Step: 5
Training loss: 2.638999574135778
Validation loss: 2.6791826261249403

Epoch: 5| Step: 6
Training loss: 2.914074445193765
Validation loss: 2.6659219442817

Epoch: 5| Step: 7
Training loss: 3.2748027130574204
Validation loss: 2.667646384491818

Epoch: 5| Step: 8
Training loss: 2.6879114235293815
Validation loss: 2.6560871882671617

Epoch: 5| Step: 9
Training loss: 2.955337260923982
Validation loss: 2.6459433481296433

Epoch: 5| Step: 10
Training loss: 3.1261898064566798
Validation loss: 2.640225708843594

Epoch: 423| Step: 0
Training loss: 2.3048675983988063
Validation loss: 2.6443817556403624

Epoch: 5| Step: 1
Training loss: 3.4767002035579546
Validation loss: 2.64346632055977

Epoch: 5| Step: 2
Training loss: 2.5347881314375873
Validation loss: 2.637410455212154

Epoch: 5| Step: 3
Training loss: 2.7279475063687832
Validation loss: 2.631566111919769

Epoch: 5| Step: 4
Training loss: 3.2623264135023127
Validation loss: 2.636535163665173

Epoch: 5| Step: 5
Training loss: 3.4823569710545956
Validation loss: 2.6351279676516413

Epoch: 5| Step: 6
Training loss: 2.6744890420218166
Validation loss: 2.641108998179843

Epoch: 5| Step: 7
Training loss: 2.876028954849603
Validation loss: 2.6410419396835043

Epoch: 5| Step: 8
Training loss: 2.8881077708902856
Validation loss: 2.641819361915696

Epoch: 5| Step: 9
Training loss: 3.1473883686464275
Validation loss: 2.643549272297493

Epoch: 5| Step: 10
Training loss: 2.7368571323491886
Validation loss: 2.6448074521094482

Epoch: 424| Step: 0
Training loss: 2.867050791295502
Validation loss: 2.6384970749922294

Epoch: 5| Step: 1
Training loss: 2.4026558525986634
Validation loss: 2.64260244601226

Epoch: 5| Step: 2
Training loss: 2.552421754988414
Validation loss: 2.6536520223722393

Epoch: 5| Step: 3
Training loss: 3.0193384264414997
Validation loss: 2.671206526149951

Epoch: 5| Step: 4
Training loss: 3.4589171012656164
Validation loss: 2.659595251999692

Epoch: 5| Step: 5
Training loss: 2.5464016527156756
Validation loss: 2.686963424860877

Epoch: 5| Step: 6
Training loss: 3.2113201720818227
Validation loss: 2.6916745143227248

Epoch: 5| Step: 7
Training loss: 3.091779293123572
Validation loss: 2.68727956842271

Epoch: 5| Step: 8
Training loss: 2.8487419497220094
Validation loss: 2.692569817566274

Epoch: 5| Step: 9
Training loss: 2.8211187758242917
Validation loss: 2.6905667396955013

Epoch: 5| Step: 10
Training loss: 3.5748193121644656
Validation loss: 2.646434594177968

Epoch: 425| Step: 0
Training loss: 3.0214671730582565
Validation loss: 2.6405159425990647

Epoch: 5| Step: 1
Training loss: 3.06349041552295
Validation loss: 2.6397760274880233

Epoch: 5| Step: 2
Training loss: 2.640175685238727
Validation loss: 2.6564334176307813

Epoch: 5| Step: 3
Training loss: 3.080038647347275
Validation loss: 2.6600222522289965

Epoch: 5| Step: 4
Training loss: 2.7369904135277268
Validation loss: 2.6729428807231375

Epoch: 5| Step: 5
Training loss: 3.0655843034039783
Validation loss: 2.684838307863685

Epoch: 5| Step: 6
Training loss: 3.100179445548998
Validation loss: 2.692726334334565

Epoch: 5| Step: 7
Training loss: 2.964801451289588
Validation loss: 2.662727323297826

Epoch: 5| Step: 8
Training loss: 2.5136888528649153
Validation loss: 2.6635550263205543

Epoch: 5| Step: 9
Training loss: 3.3551838124344497
Validation loss: 2.653526029966143

Epoch: 5| Step: 10
Training loss: 3.1275782820969535
Validation loss: 2.6616421648417865

Epoch: 426| Step: 0
Training loss: 3.027112201326364
Validation loss: 2.659743783311987

Epoch: 5| Step: 1
Training loss: 3.73874756267421
Validation loss: 2.6579197229094587

Epoch: 5| Step: 2
Training loss: 3.081596933761846
Validation loss: 2.658066551031697

Epoch: 5| Step: 3
Training loss: 2.5423618887539736
Validation loss: 2.657537383123546

Epoch: 5| Step: 4
Training loss: 2.780927918033229
Validation loss: 2.653681231645863

Epoch: 5| Step: 5
Training loss: 3.0398047161120676
Validation loss: 2.658985360122363

Epoch: 5| Step: 6
Training loss: 2.6958196632789417
Validation loss: 2.6607934505656123

Epoch: 5| Step: 7
Training loss: 2.8633160556483617
Validation loss: 2.664725176273008

Epoch: 5| Step: 8
Training loss: 2.7619668506508614
Validation loss: 2.6700039913738656

Epoch: 5| Step: 9
Training loss: 2.82799036538022
Validation loss: 2.7107503548073644

Epoch: 5| Step: 10
Training loss: 2.909759043781992
Validation loss: 2.7064999043803266

Epoch: 427| Step: 0
Training loss: 2.736609543154999
Validation loss: 2.721953437217232

Epoch: 5| Step: 1
Training loss: 2.5096825968148586
Validation loss: 2.74298252645234

Epoch: 5| Step: 2
Training loss: 3.1274864985649504
Validation loss: 2.7338091375813947

Epoch: 5| Step: 3
Training loss: 3.0265283680154633
Validation loss: 2.744170011776794

Epoch: 5| Step: 4
Training loss: 2.4757962651036673
Validation loss: 2.696668204803963

Epoch: 5| Step: 5
Training loss: 3.331860662031263
Validation loss: 2.659668355753811

Epoch: 5| Step: 6
Training loss: 3.107188927570419
Validation loss: 2.652336430255973

Epoch: 5| Step: 7
Training loss: 3.3096018654902646
Validation loss: 2.629350926287156

Epoch: 5| Step: 8
Training loss: 3.0876087926315163
Validation loss: 2.6285060267143745

Epoch: 5| Step: 9
Training loss: 3.0183290997676835
Validation loss: 2.6232536315735526

Epoch: 5| Step: 10
Training loss: 2.8822919173953423
Validation loss: 2.625996882334724

Epoch: 428| Step: 0
Training loss: 2.4620368560709758
Validation loss: 2.6324198250386526

Epoch: 5| Step: 1
Training loss: 3.128179534833069
Validation loss: 2.6434749459704423

Epoch: 5| Step: 2
Training loss: 3.173422750554258
Validation loss: 2.6607981957362186

Epoch: 5| Step: 3
Training loss: 3.1735597843292496
Validation loss: 2.64384165893716

Epoch: 5| Step: 4
Training loss: 2.9175010214364976
Validation loss: 2.656741430388293

Epoch: 5| Step: 5
Training loss: 2.935833072480071
Validation loss: 2.647066103511496

Epoch: 5| Step: 6
Training loss: 2.621714943329955
Validation loss: 2.6624643557108203

Epoch: 5| Step: 7
Training loss: 2.3505227461190827
Validation loss: 2.6625849376585236

Epoch: 5| Step: 8
Training loss: 2.8749300077460105
Validation loss: 2.6735379908009134

Epoch: 5| Step: 9
Training loss: 3.0184644860248984
Validation loss: 2.6878747995891143

Epoch: 5| Step: 10
Training loss: 3.7980215594185487
Validation loss: 2.684049521855017

Epoch: 429| Step: 0
Training loss: 3.029465927040703
Validation loss: 2.6926467398783163

Epoch: 5| Step: 1
Training loss: 2.9207366521037774
Validation loss: 2.687720029103385

Epoch: 5| Step: 2
Training loss: 2.9351680508646187
Validation loss: 2.6798244290534874

Epoch: 5| Step: 3
Training loss: 2.974698341527002
Validation loss: 2.667260942716054

Epoch: 5| Step: 4
Training loss: 2.4839742085320338
Validation loss: 2.6688997525268268

Epoch: 5| Step: 5
Training loss: 2.875561534941541
Validation loss: 2.665318266092656

Epoch: 5| Step: 6
Training loss: 2.8410774500117615
Validation loss: 2.656387223252709

Epoch: 5| Step: 7
Training loss: 3.158831456609334
Validation loss: 2.653424319096378

Epoch: 5| Step: 8
Training loss: 3.5244531626658335
Validation loss: 2.656072975740735

Epoch: 5| Step: 9
Training loss: 2.63965503100476
Validation loss: 2.650214407882809

Epoch: 5| Step: 10
Training loss: 3.0219019260410076
Validation loss: 2.6498878324858053

Epoch: 430| Step: 0
Training loss: 3.4422293294684523
Validation loss: 2.662969786444409

Epoch: 5| Step: 1
Training loss: 3.0176454406933404
Validation loss: 2.654714447660944

Epoch: 5| Step: 2
Training loss: 3.17083512722638
Validation loss: 2.658499385993893

Epoch: 5| Step: 3
Training loss: 2.6021169810464975
Validation loss: 2.6599838188663667

Epoch: 5| Step: 4
Training loss: 2.5040808749194197
Validation loss: 2.66610071466487

Epoch: 5| Step: 5
Training loss: 3.0556876259977526
Validation loss: 2.6771122068336632

Epoch: 5| Step: 6
Training loss: 3.1404481145286236
Validation loss: 2.6845370006397324

Epoch: 5| Step: 7
Training loss: 3.1286044886087114
Validation loss: 2.6845946216940058

Epoch: 5| Step: 8
Training loss: 2.661149835094638
Validation loss: 2.6941509819282787

Epoch: 5| Step: 9
Training loss: 2.9738491236492632
Validation loss: 2.7017078306454145

Epoch: 5| Step: 10
Training loss: 2.558235620958337
Validation loss: 2.669065037839473

Epoch: 431| Step: 0
Training loss: 3.0778024572246743
Validation loss: 2.651861512284936

Epoch: 5| Step: 1
Training loss: 3.2151074585227524
Validation loss: 2.6456671502638436

Epoch: 5| Step: 2
Training loss: 2.9449291030303257
Validation loss: 2.6362737678640427

Epoch: 5| Step: 3
Training loss: 2.7054519780581234
Validation loss: 2.635143991767752

Epoch: 5| Step: 4
Training loss: 3.020109488921427
Validation loss: 2.632332304605661

Epoch: 5| Step: 5
Training loss: 2.654202289032842
Validation loss: 2.633627551313226

Epoch: 5| Step: 6
Training loss: 2.6233486249091067
Validation loss: 2.6372523586318364

Epoch: 5| Step: 7
Training loss: 2.9110450155537904
Validation loss: 2.636064655901091

Epoch: 5| Step: 8
Training loss: 3.0915703079000103
Validation loss: 2.6395310938636483

Epoch: 5| Step: 9
Training loss: 2.8627316310400843
Validation loss: 2.646579546769138

Epoch: 5| Step: 10
Training loss: 3.3312244578915693
Validation loss: 2.642283291319586

Epoch: 432| Step: 0
Training loss: 2.558139906373108
Validation loss: 2.645393099183061

Epoch: 5| Step: 1
Training loss: 3.1236682342904216
Validation loss: 2.65220742623865

Epoch: 5| Step: 2
Training loss: 3.114445984192397
Validation loss: 2.655322755249853

Epoch: 5| Step: 3
Training loss: 2.8134108869731786
Validation loss: 2.653616465552831

Epoch: 5| Step: 4
Training loss: 3.1309064360643486
Validation loss: 2.679684570601734

Epoch: 5| Step: 5
Training loss: 2.5572439112869083
Validation loss: 2.687304082064716

Epoch: 5| Step: 6
Training loss: 2.9724048803973955
Validation loss: 2.713822290993313

Epoch: 5| Step: 7
Training loss: 3.25204330181839
Validation loss: 2.7015535195646794

Epoch: 5| Step: 8
Training loss: 2.8629411648944973
Validation loss: 2.704376927560928

Epoch: 5| Step: 9
Training loss: 2.661418060973488
Validation loss: 2.677827089120858

Epoch: 5| Step: 10
Training loss: 3.181506936839861
Validation loss: 2.653456693091656

Epoch: 433| Step: 0
Training loss: 2.729841386707666
Validation loss: 2.6430693641089946

Epoch: 5| Step: 1
Training loss: 3.2104750251458056
Validation loss: 2.6368244983974574

Epoch: 5| Step: 2
Training loss: 3.534004420002978
Validation loss: 2.643104417808093

Epoch: 5| Step: 3
Training loss: 2.9167656109693656
Validation loss: 2.6361989184080796

Epoch: 5| Step: 4
Training loss: 3.02660982156999
Validation loss: 2.633461942552713

Epoch: 5| Step: 5
Training loss: 2.80656943765192
Validation loss: 2.6389164104080773

Epoch: 5| Step: 6
Training loss: 2.9447641039218375
Validation loss: 2.639621073647955

Epoch: 5| Step: 7
Training loss: 2.852923008598929
Validation loss: 2.6523983173640224

Epoch: 5| Step: 8
Training loss: 2.560472197793092
Validation loss: 2.6527268644420605

Epoch: 5| Step: 9
Training loss: 2.919547883135152
Validation loss: 2.6561626219688983

Epoch: 5| Step: 10
Training loss: 2.7707074550249016
Validation loss: 2.656429793795496

Epoch: 434| Step: 0
Training loss: 2.8345525212827942
Validation loss: 2.6688696589460528

Epoch: 5| Step: 1
Training loss: 2.8605020938646253
Validation loss: 2.684267050745142

Epoch: 5| Step: 2
Training loss: 3.130561762114131
Validation loss: 2.700429081899559

Epoch: 5| Step: 3
Training loss: 3.108184433166902
Validation loss: 2.741405323971641

Epoch: 5| Step: 4
Training loss: 3.415331571911247
Validation loss: 2.748438943021196

Epoch: 5| Step: 5
Training loss: 3.115605079334667
Validation loss: 2.731003486425038

Epoch: 5| Step: 6
Training loss: 2.4381727610674515
Validation loss: 2.70268715992219

Epoch: 5| Step: 7
Training loss: 3.334880009083954
Validation loss: 2.6874039373569145

Epoch: 5| Step: 8
Training loss: 2.4769043310461205
Validation loss: 2.665477769979847

Epoch: 5| Step: 9
Training loss: 2.85913651936254
Validation loss: 2.654856892330123

Epoch: 5| Step: 10
Training loss: 2.9055706583785015
Validation loss: 2.645440669753981

Epoch: 435| Step: 0
Training loss: 2.706072572878236
Validation loss: 2.645585695214118

Epoch: 5| Step: 1
Training loss: 3.3574494276974445
Validation loss: 2.6422758311578622

Epoch: 5| Step: 2
Training loss: 3.2412899383544107
Validation loss: 2.642225248202581

Epoch: 5| Step: 3
Training loss: 2.9910563031365216
Validation loss: 2.638316522631683

Epoch: 5| Step: 4
Training loss: 2.9054080194668908
Validation loss: 2.6340953571192

Epoch: 5| Step: 5
Training loss: 3.2883057799798556
Validation loss: 2.633376763020601

Epoch: 5| Step: 6
Training loss: 3.218058687802267
Validation loss: 2.63214787469334

Epoch: 5| Step: 7
Training loss: 2.6956349055645314
Validation loss: 2.6313870851110153

Epoch: 5| Step: 8
Training loss: 2.691072617712363
Validation loss: 2.628448543513363

Epoch: 5| Step: 9
Training loss: 2.633869807809366
Validation loss: 2.6331719676814225

Epoch: 5| Step: 10
Training loss: 2.5463847993311317
Validation loss: 2.6347206776147276

Epoch: 436| Step: 0
Training loss: 2.7229056333061976
Validation loss: 2.640440639587349

Epoch: 5| Step: 1
Training loss: 2.927850009703586
Validation loss: 2.6591362933018887

Epoch: 5| Step: 2
Training loss: 3.1510910324559362
Validation loss: 2.675521889992633

Epoch: 5| Step: 3
Training loss: 3.009730611767059
Validation loss: 2.6729776289765224

Epoch: 5| Step: 4
Training loss: 2.750517796405969
Validation loss: 2.692552786049236

Epoch: 5| Step: 5
Training loss: 3.012749917201664
Validation loss: 2.688892243312401

Epoch: 5| Step: 6
Training loss: 2.9882914624008503
Validation loss: 2.681279337966041

Epoch: 5| Step: 7
Training loss: 2.9084510262038403
Validation loss: 2.690614070886573

Epoch: 5| Step: 8
Training loss: 2.9885317628859696
Validation loss: 2.6852153406825745

Epoch: 5| Step: 9
Training loss: 2.8982930520146586
Validation loss: 2.679641276936456

Epoch: 5| Step: 10
Training loss: 2.7947840200104657
Validation loss: 2.6691281285870474

Epoch: 437| Step: 0
Training loss: 2.8224060234866233
Validation loss: 2.6567526064941225

Epoch: 5| Step: 1
Training loss: 3.0240249260273737
Validation loss: 2.6520739384038756

Epoch: 5| Step: 2
Training loss: 2.727801284723282
Validation loss: 2.6425319619971517

Epoch: 5| Step: 3
Training loss: 3.1526005863656943
Validation loss: 2.6415613815960475

Epoch: 5| Step: 4
Training loss: 3.0409105658835394
Validation loss: 2.648977398082866

Epoch: 5| Step: 5
Training loss: 3.0047487186219994
Validation loss: 2.64378869627583

Epoch: 5| Step: 6
Training loss: 3.6765602899715786
Validation loss: 2.642138246630835

Epoch: 5| Step: 7
Training loss: 2.751713998881538
Validation loss: 2.6475976131363352

Epoch: 5| Step: 8
Training loss: 2.4235292753037654
Validation loss: 2.6460810244926583

Epoch: 5| Step: 9
Training loss: 2.5962672140903464
Validation loss: 2.6528186618488

Epoch: 5| Step: 10
Training loss: 2.671655835538038
Validation loss: 2.6496706179176917

Epoch: 438| Step: 0
Training loss: 2.9278216714803915
Validation loss: 2.6685537572108475

Epoch: 5| Step: 1
Training loss: 3.0219738791224904
Validation loss: 2.652770929797128

Epoch: 5| Step: 2
Training loss: 3.1691290333396105
Validation loss: 2.6559540305626403

Epoch: 5| Step: 3
Training loss: 2.5246967209077322
Validation loss: 2.6620897612825236

Epoch: 5| Step: 4
Training loss: 3.3497530091744294
Validation loss: 2.6464731976697204

Epoch: 5| Step: 5
Training loss: 2.816369425497167
Validation loss: 2.642454238613182

Epoch: 5| Step: 6
Training loss: 2.6213840829794566
Validation loss: 2.644793079128684

Epoch: 5| Step: 7
Training loss: 3.5175645691368445
Validation loss: 2.6416591331172916

Epoch: 5| Step: 8
Training loss: 2.752410092665478
Validation loss: 2.635650734942007

Epoch: 5| Step: 9
Training loss: 2.4582776424328387
Validation loss: 2.6417783910043235

Epoch: 5| Step: 10
Training loss: 2.7602625006085244
Validation loss: 2.644713816959683

Epoch: 439| Step: 0
Training loss: 2.9741038984403794
Validation loss: 2.6478483610982204

Epoch: 5| Step: 1
Training loss: 3.3512806451542443
Validation loss: 2.65461129703114

Epoch: 5| Step: 2
Training loss: 2.7611901021447047
Validation loss: 2.661560912622045

Epoch: 5| Step: 3
Training loss: 2.8736489480044685
Validation loss: 2.6594268496090026

Epoch: 5| Step: 4
Training loss: 2.734956951883522
Validation loss: 2.669544358944409

Epoch: 5| Step: 5
Training loss: 2.896421981005741
Validation loss: 2.654049922900917

Epoch: 5| Step: 6
Training loss: 2.905681103226061
Validation loss: 2.6614379690989507

Epoch: 5| Step: 7
Training loss: 2.573573307977296
Validation loss: 2.655217520542951

Epoch: 5| Step: 8
Training loss: 3.4086207267888047
Validation loss: 2.6473459756915885

Epoch: 5| Step: 9
Training loss: 2.2786393577846975
Validation loss: 2.6569244590141583

Epoch: 5| Step: 10
Training loss: 3.1920815247185055
Validation loss: 2.6593452935207895

Epoch: 440| Step: 0
Training loss: 3.0730102179990806
Validation loss: 2.653874291690726

Epoch: 5| Step: 1
Training loss: 3.174711866145404
Validation loss: 2.6595859395392636

Epoch: 5| Step: 2
Training loss: 3.1157746519154035
Validation loss: 2.659293528467432

Epoch: 5| Step: 3
Training loss: 3.110711198792405
Validation loss: 2.657062083542469

Epoch: 5| Step: 4
Training loss: 2.692191885459193
Validation loss: 2.6872128092083374

Epoch: 5| Step: 5
Training loss: 3.0235598832627377
Validation loss: 2.6931874314770887

Epoch: 5| Step: 6
Training loss: 2.7303532260801457
Validation loss: 2.7079496492095836

Epoch: 5| Step: 7
Training loss: 3.0879928504386713
Validation loss: 2.714065136274954

Epoch: 5| Step: 8
Training loss: 3.1808827845908816
Validation loss: 2.711665693406024

Epoch: 5| Step: 9
Training loss: 2.447551640559015
Validation loss: 2.6941714841166613

Epoch: 5| Step: 10
Training loss: 2.3323368147080368
Validation loss: 2.6722613073798835

Epoch: 441| Step: 0
Training loss: 3.088785831949087
Validation loss: 2.670011333734794

Epoch: 5| Step: 1
Training loss: 3.5172754101335286
Validation loss: 2.6558100896485057

Epoch: 5| Step: 2
Training loss: 3.2480459941557736
Validation loss: 2.6504403160434733

Epoch: 5| Step: 3
Training loss: 2.532684296570291
Validation loss: 2.647665909578168

Epoch: 5| Step: 4
Training loss: 3.051988272548157
Validation loss: 2.64073889721489

Epoch: 5| Step: 5
Training loss: 2.647488584412773
Validation loss: 2.640174871531065

Epoch: 5| Step: 6
Training loss: 2.796875937690791
Validation loss: 2.6315054943096747

Epoch: 5| Step: 7
Training loss: 2.564396877209445
Validation loss: 2.6247302940795376

Epoch: 5| Step: 8
Training loss: 2.9631719285957687
Validation loss: 2.6318115890758316

Epoch: 5| Step: 9
Training loss: 2.997971325646223
Validation loss: 2.6278302160406657

Epoch: 5| Step: 10
Training loss: 2.5901885802791833
Validation loss: 2.6295583692917397

Epoch: 442| Step: 0
Training loss: 3.1526987473884445
Validation loss: 2.636780030432101

Epoch: 5| Step: 1
Training loss: 2.8394578674167645
Validation loss: 2.6359203553952297

Epoch: 5| Step: 2
Training loss: 3.0882717141106255
Validation loss: 2.6588352379423354

Epoch: 5| Step: 3
Training loss: 2.9082350975723172
Validation loss: 2.6433350215374167

Epoch: 5| Step: 4
Training loss: 2.035054795560812
Validation loss: 2.649366140413176

Epoch: 5| Step: 5
Training loss: 2.7149259486207247
Validation loss: 2.667530349359048

Epoch: 5| Step: 6
Training loss: 3.3226427943972787
Validation loss: 2.662497908106934

Epoch: 5| Step: 7
Training loss: 3.249930454390374
Validation loss: 2.6562697465948

Epoch: 5| Step: 8
Training loss: 3.2025166747993934
Validation loss: 2.668982312416154

Epoch: 5| Step: 9
Training loss: 2.9683606344170905
Validation loss: 2.6538681102541815

Epoch: 5| Step: 10
Training loss: 2.1707747712049272
Validation loss: 2.6495672148069027

Epoch: 443| Step: 0
Training loss: 2.8376390801177007
Validation loss: 2.6573621676361197

Epoch: 5| Step: 1
Training loss: 2.530047660951669
Validation loss: 2.6536513625393914

Epoch: 5| Step: 2
Training loss: 3.0195438833823687
Validation loss: 2.650791034438828

Epoch: 5| Step: 3
Training loss: 3.2649665424215795
Validation loss: 2.6442027045499654

Epoch: 5| Step: 4
Training loss: 2.5097660999817157
Validation loss: 2.6419903198204824

Epoch: 5| Step: 5
Training loss: 2.978535476368273
Validation loss: 2.6365004222663058

Epoch: 5| Step: 6
Training loss: 2.9738048685342764
Validation loss: 2.640081761521329

Epoch: 5| Step: 7
Training loss: 2.4000972012863477
Validation loss: 2.632353654456516

Epoch: 5| Step: 8
Training loss: 3.500605667025457
Validation loss: 2.6296731650305696

Epoch: 5| Step: 9
Training loss: 3.072498426693047
Validation loss: 2.6347822623632666

Epoch: 5| Step: 10
Training loss: 2.7665410652911664
Validation loss: 2.6266328398571726

Epoch: 444| Step: 0
Training loss: 2.7872617234826818
Validation loss: 2.6367153956165192

Epoch: 5| Step: 1
Training loss: 2.8792123204838127
Validation loss: 2.645131424428379

Epoch: 5| Step: 2
Training loss: 3.025483772119574
Validation loss: 2.6537816372190695

Epoch: 5| Step: 3
Training loss: 2.7461676336689087
Validation loss: 2.669841297257404

Epoch: 5| Step: 4
Training loss: 2.798528768391901
Validation loss: 2.6649286309660924

Epoch: 5| Step: 5
Training loss: 2.9348385705695526
Validation loss: 2.661159845331337

Epoch: 5| Step: 6
Training loss: 2.4514764968831555
Validation loss: 2.6719780723169904

Epoch: 5| Step: 7
Training loss: 2.799469495653111
Validation loss: 2.677153814846848

Epoch: 5| Step: 8
Training loss: 3.038567431609506
Validation loss: 2.6575013949844033

Epoch: 5| Step: 9
Training loss: 3.3751455204992125
Validation loss: 2.6664748686859814

Epoch: 5| Step: 10
Training loss: 3.1066727901229214
Validation loss: 2.6697471218133084

Epoch: 445| Step: 0
Training loss: 3.231395141175193
Validation loss: 2.6588483384530424

Epoch: 5| Step: 1
Training loss: 2.5073954868309807
Validation loss: 2.649905340416046

Epoch: 5| Step: 2
Training loss: 2.7294855489633045
Validation loss: 2.650646765761398

Epoch: 5| Step: 3
Training loss: 2.796689245779244
Validation loss: 2.638297376271517

Epoch: 5| Step: 4
Training loss: 2.8389587282605224
Validation loss: 2.6466858785188276

Epoch: 5| Step: 5
Training loss: 3.011501833851025
Validation loss: 2.6476663414240535

Epoch: 5| Step: 6
Training loss: 2.737896205152414
Validation loss: 2.6493745772791755

Epoch: 5| Step: 7
Training loss: 2.405964425715821
Validation loss: 2.6515346621283102

Epoch: 5| Step: 8
Training loss: 3.3279648146786736
Validation loss: 2.645174603525009

Epoch: 5| Step: 9
Training loss: 3.168812744000972
Validation loss: 2.646692582349649

Epoch: 5| Step: 10
Training loss: 3.139637350534468
Validation loss: 2.656718392910428

Epoch: 446| Step: 0
Training loss: 2.6439879181855637
Validation loss: 2.6502978893660005

Epoch: 5| Step: 1
Training loss: 3.128016732368693
Validation loss: 2.6473697967987837

Epoch: 5| Step: 2
Training loss: 3.0557010461867815
Validation loss: 2.635748136188194

Epoch: 5| Step: 3
Training loss: 2.8992135790298468
Validation loss: 2.64879711972995

Epoch: 5| Step: 4
Training loss: 2.819087303939679
Validation loss: 2.6433295370253456

Epoch: 5| Step: 5
Training loss: 2.8330345744276304
Validation loss: 2.6547604142762586

Epoch: 5| Step: 6
Training loss: 2.85604147118557
Validation loss: 2.6573850644717303

Epoch: 5| Step: 7
Training loss: 2.9578208121189498
Validation loss: 2.6436984830582797

Epoch: 5| Step: 8
Training loss: 2.6709858268096114
Validation loss: 2.6455860992978204

Epoch: 5| Step: 9
Training loss: 3.3944398013879375
Validation loss: 2.6516879491244

Epoch: 5| Step: 10
Training loss: 2.5154723127005663
Validation loss: 2.6592571514837156

Epoch: 447| Step: 0
Training loss: 2.9729812183781283
Validation loss: 2.6569786766117596

Epoch: 5| Step: 1
Training loss: 3.2041630249267308
Validation loss: 2.662583471254313

Epoch: 5| Step: 2
Training loss: 2.630176526371469
Validation loss: 2.661002615432159

Epoch: 5| Step: 3
Training loss: 2.6544644806009314
Validation loss: 2.6629993488675607

Epoch: 5| Step: 4
Training loss: 2.665573720673555
Validation loss: 2.659987732776251

Epoch: 5| Step: 5
Training loss: 2.7927604544268645
Validation loss: 2.6791560937867445

Epoch: 5| Step: 6
Training loss: 2.795862110366952
Validation loss: 2.6708670063272417

Epoch: 5| Step: 7
Training loss: 3.2681609168151806
Validation loss: 2.6693030721226743

Epoch: 5| Step: 8
Training loss: 3.113884957052337
Validation loss: 2.6627561278190446

Epoch: 5| Step: 9
Training loss: 2.8130691800091467
Validation loss: 2.637424419350272

Epoch: 5| Step: 10
Training loss: 3.012860706308892
Validation loss: 2.6443724613446684

Epoch: 448| Step: 0
Training loss: 2.6889892710013825
Validation loss: 2.639325169492422

Epoch: 5| Step: 1
Training loss: 2.440405556634649
Validation loss: 2.636501506453017

Epoch: 5| Step: 2
Training loss: 2.6881968459759125
Validation loss: 2.643410919033195

Epoch: 5| Step: 3
Training loss: 2.8651681384002075
Validation loss: 2.633643461420857

Epoch: 5| Step: 4
Training loss: 2.769534865620436
Validation loss: 2.6297332409320413

Epoch: 5| Step: 5
Training loss: 3.1728876310853855
Validation loss: 2.6307974596741563

Epoch: 5| Step: 6
Training loss: 2.8455224853656804
Validation loss: 2.651946660714068

Epoch: 5| Step: 7
Training loss: 2.4679774753649375
Validation loss: 2.664244975645759

Epoch: 5| Step: 8
Training loss: 3.5246520391480223
Validation loss: 2.679259419917268

Epoch: 5| Step: 9
Training loss: 3.249104009511549
Validation loss: 2.718032551775162

Epoch: 5| Step: 10
Training loss: 3.16086580776915
Validation loss: 2.700216141917305

Epoch: 449| Step: 0
Training loss: 2.9642910850594433
Validation loss: 2.698553013052464

Epoch: 5| Step: 1
Training loss: 2.5119693328540493
Validation loss: 2.6866956223916545

Epoch: 5| Step: 2
Training loss: 1.8619174404627847
Validation loss: 2.664197924625977

Epoch: 5| Step: 3
Training loss: 2.5336126909656627
Validation loss: 2.6678243118830287

Epoch: 5| Step: 4
Training loss: 3.102308053988324
Validation loss: 2.6592967261553837

Epoch: 5| Step: 5
Training loss: 3.8169589623435622
Validation loss: 2.657063202757007

Epoch: 5| Step: 6
Training loss: 3.1094755990321845
Validation loss: 2.6513239835542373

Epoch: 5| Step: 7
Training loss: 3.018553107812592
Validation loss: 2.644831126452393

Epoch: 5| Step: 8
Training loss: 3.00512384905257
Validation loss: 2.647054425508091

Epoch: 5| Step: 9
Training loss: 2.680834110612868
Validation loss: 2.6403791363272697

Epoch: 5| Step: 10
Training loss: 2.883564011124081
Validation loss: 2.629939079981214

Epoch: 450| Step: 0
Training loss: 3.2343275278634223
Validation loss: 2.6338626206856044

Epoch: 5| Step: 1
Training loss: 2.6826015453903262
Validation loss: 2.619723253529706

Epoch: 5| Step: 2
Training loss: 2.760930187515739
Validation loss: 2.6291265159676893

Epoch: 5| Step: 3
Training loss: 2.387908189641252
Validation loss: 2.6253282104492244

Epoch: 5| Step: 4
Training loss: 2.4327277392332385
Validation loss: 2.621869294164524

Epoch: 5| Step: 5
Training loss: 2.9678712849430076
Validation loss: 2.6292829931248347

Epoch: 5| Step: 6
Training loss: 2.7542012807389766
Validation loss: 2.6240033417472723

Epoch: 5| Step: 7
Training loss: 2.844498923478683
Validation loss: 2.624072404682062

Epoch: 5| Step: 8
Training loss: 3.0996102980268003
Validation loss: 2.6337864460909834

Epoch: 5| Step: 9
Training loss: 3.43364832707798
Validation loss: 2.6472878934740693

Epoch: 5| Step: 10
Training loss: 3.2964072234609825
Validation loss: 2.649818992508258

Epoch: 451| Step: 0
Training loss: 3.120193752728415
Validation loss: 2.6489494957260975

Epoch: 5| Step: 1
Training loss: 2.474780864840257
Validation loss: 2.6651620433487366

Epoch: 5| Step: 2
Training loss: 2.9891357795758013
Validation loss: 2.6702117214083088

Epoch: 5| Step: 3
Training loss: 2.974221097135106
Validation loss: 2.670559601361499

Epoch: 5| Step: 4
Training loss: 2.8077021046940884
Validation loss: 2.6620138859308122

Epoch: 5| Step: 5
Training loss: 2.85487520282517
Validation loss: 2.6710714415070362

Epoch: 5| Step: 6
Training loss: 3.463429675287434
Validation loss: 2.665143309163089

Epoch: 5| Step: 7
Training loss: 2.7096379487983473
Validation loss: 2.677918136199739

Epoch: 5| Step: 8
Training loss: 3.084371976068284
Validation loss: 2.6582631309184666

Epoch: 5| Step: 9
Training loss: 2.257506458699903
Validation loss: 2.6568456726233345

Epoch: 5| Step: 10
Training loss: 2.9880099703253453
Validation loss: 2.6555390035559343

Epoch: 452| Step: 0
Training loss: 2.912253137694712
Validation loss: 2.637201149525593

Epoch: 5| Step: 1
Training loss: 2.40324392433712
Validation loss: 2.634558949618019

Epoch: 5| Step: 2
Training loss: 3.0766771658418275
Validation loss: 2.6400115083270848

Epoch: 5| Step: 3
Training loss: 3.452578125883907
Validation loss: 2.6381325392528345

Epoch: 5| Step: 4
Training loss: 2.6354746956649913
Validation loss: 2.622551277385307

Epoch: 5| Step: 5
Training loss: 2.9016802556922796
Validation loss: 2.6314676917429267

Epoch: 5| Step: 6
Training loss: 2.753320769711603
Validation loss: 2.6479309461040836

Epoch: 5| Step: 7
Training loss: 2.8967163240004976
Validation loss: 2.648567577171723

Epoch: 5| Step: 8
Training loss: 2.7182345723872396
Validation loss: 2.6483222611354345

Epoch: 5| Step: 9
Training loss: 2.835757583501752
Validation loss: 2.6591189772660417

Epoch: 5| Step: 10
Training loss: 3.2567537997981977
Validation loss: 2.659137209185061

Epoch: 453| Step: 0
Training loss: 3.2844417489017386
Validation loss: 2.6696733174391425

Epoch: 5| Step: 1
Training loss: 2.2481599277204256
Validation loss: 2.6558018093336826

Epoch: 5| Step: 2
Training loss: 2.871148556555978
Validation loss: 2.6686099115637463

Epoch: 5| Step: 3
Training loss: 3.0169248003313727
Validation loss: 2.6747583445926395

Epoch: 5| Step: 4
Training loss: 2.9147153230510714
Validation loss: 2.6525921666372803

Epoch: 5| Step: 5
Training loss: 2.561442831663985
Validation loss: 2.653016429727071

Epoch: 5| Step: 6
Training loss: 3.521073929430638
Validation loss: 2.6297559152700885

Epoch: 5| Step: 7
Training loss: 3.321888699866652
Validation loss: 2.6369755042099454

Epoch: 5| Step: 8
Training loss: 2.2725863092229153
Validation loss: 2.6314524967175186

Epoch: 5| Step: 9
Training loss: 2.70935381712767
Validation loss: 2.627458090478908

Epoch: 5| Step: 10
Training loss: 2.8811692100336113
Validation loss: 2.6306034944269148

Epoch: 454| Step: 0
Training loss: 2.670852019135032
Validation loss: 2.635516767454294

Epoch: 5| Step: 1
Training loss: 2.464197427735876
Validation loss: 2.6363547268535417

Epoch: 5| Step: 2
Training loss: 2.8909210878235587
Validation loss: 2.6415297415852166

Epoch: 5| Step: 3
Training loss: 2.9053643630729615
Validation loss: 2.6357500892535946

Epoch: 5| Step: 4
Training loss: 2.9918161664779848
Validation loss: 2.6436380398766826

Epoch: 5| Step: 5
Training loss: 2.776977686626503
Validation loss: 2.638427798868578

Epoch: 5| Step: 6
Training loss: 2.8327662704575527
Validation loss: 2.635598996695487

Epoch: 5| Step: 7
Training loss: 2.5870620725518605
Validation loss: 2.641921822318029

Epoch: 5| Step: 8
Training loss: 3.016855413809152
Validation loss: 2.64463563617531

Epoch: 5| Step: 9
Training loss: 3.322876135759296
Validation loss: 2.6563087143220763

Epoch: 5| Step: 10
Training loss: 3.3574457350810114
Validation loss: 2.6561918229374073

Epoch: 455| Step: 0
Training loss: 2.985728012074268
Validation loss: 2.6674507210048284

Epoch: 5| Step: 1
Training loss: 3.2589071433600205
Validation loss: 2.6776829845931833

Epoch: 5| Step: 2
Training loss: 2.811515127039211
Validation loss: 2.675143559026697

Epoch: 5| Step: 3
Training loss: 2.1854792389277415
Validation loss: 2.656305016002788

Epoch: 5| Step: 4
Training loss: 3.123248715823566
Validation loss: 2.661802122088589

Epoch: 5| Step: 5
Training loss: 2.4889520672128866
Validation loss: 2.667139362027414

Epoch: 5| Step: 6
Training loss: 2.529543265930889
Validation loss: 2.662499021184975

Epoch: 5| Step: 7
Training loss: 3.0077335495928956
Validation loss: 2.6646910790041023

Epoch: 5| Step: 8
Training loss: 3.1831219095319585
Validation loss: 2.6701133517678874

Epoch: 5| Step: 9
Training loss: 3.1085736186105963
Validation loss: 2.6692100984200153

Epoch: 5| Step: 10
Training loss: 2.935853050036512
Validation loss: 2.666142857030132

Epoch: 456| Step: 0
Training loss: 2.9859164586066904
Validation loss: 2.659117511842767

Epoch: 5| Step: 1
Training loss: 3.012743902819257
Validation loss: 2.6394196931940117

Epoch: 5| Step: 2
Training loss: 2.515407102637323
Validation loss: 2.6420316338529735

Epoch: 5| Step: 3
Training loss: 2.896858381534385
Validation loss: 2.6359818673779722

Epoch: 5| Step: 4
Training loss: 3.5078845452129612
Validation loss: 2.6278705381212797

Epoch: 5| Step: 5
Training loss: 2.5405124690998577
Validation loss: 2.629956171909

Epoch: 5| Step: 6
Training loss: 3.293592943649016
Validation loss: 2.629022500830151

Epoch: 5| Step: 7
Training loss: 2.664377769989571
Validation loss: 2.629343190067413

Epoch: 5| Step: 8
Training loss: 2.525330958063498
Validation loss: 2.6281842442784256

Epoch: 5| Step: 9
Training loss: 2.746531119319803
Validation loss: 2.6330346483920017

Epoch: 5| Step: 10
Training loss: 2.980305718478919
Validation loss: 2.6338747620855885

Epoch: 457| Step: 0
Training loss: 3.164590975107824
Validation loss: 2.645490246394973

Epoch: 5| Step: 1
Training loss: 2.942687790160364
Validation loss: 2.647704403617707

Epoch: 5| Step: 2
Training loss: 3.4878113911844593
Validation loss: 2.6474389338332354

Epoch: 5| Step: 3
Training loss: 2.4107542609881576
Validation loss: 2.6418027921601097

Epoch: 5| Step: 4
Training loss: 3.0366527741578855
Validation loss: 2.6326750480288825

Epoch: 5| Step: 5
Training loss: 2.9038211969128085
Validation loss: 2.6542879689239007

Epoch: 5| Step: 6
Training loss: 2.6579126876256685
Validation loss: 2.645726135294055

Epoch: 5| Step: 7
Training loss: 2.660731047653403
Validation loss: 2.6403758992227946

Epoch: 5| Step: 8
Training loss: 3.138139186964577
Validation loss: 2.636446525956436

Epoch: 5| Step: 9
Training loss: 2.7775405835500986
Validation loss: 2.6427227778876308

Epoch: 5| Step: 10
Training loss: 2.312478452015053
Validation loss: 2.649749952404185

Epoch: 458| Step: 0
Training loss: 2.4739058532502503
Validation loss: 2.6484549545994036

Epoch: 5| Step: 1
Training loss: 3.378554556299569
Validation loss: 2.661905867586949

Epoch: 5| Step: 2
Training loss: 2.8000140768787207
Validation loss: 2.667681438141351

Epoch: 5| Step: 3
Training loss: 3.0709903347368845
Validation loss: 2.6728299203623287

Epoch: 5| Step: 4
Training loss: 3.420356587787605
Validation loss: 2.663481955129029

Epoch: 5| Step: 5
Training loss: 2.6530732849616494
Validation loss: 2.666008889945065

Epoch: 5| Step: 6
Training loss: 3.0371806538058514
Validation loss: 2.6539042896625986

Epoch: 5| Step: 7
Training loss: 2.9622474530573117
Validation loss: 2.6393306535836425

Epoch: 5| Step: 8
Training loss: 2.7375391500103436
Validation loss: 2.6260607588501323

Epoch: 5| Step: 9
Training loss: 2.3305179663642654
Validation loss: 2.6219768040102207

Epoch: 5| Step: 10
Training loss: 2.715714173778848
Validation loss: 2.63460954645212

Epoch: 459| Step: 0
Training loss: 2.699529649244186
Validation loss: 2.623818641001611

Epoch: 5| Step: 1
Training loss: 3.27234932012721
Validation loss: 2.621464449543105

Epoch: 5| Step: 2
Training loss: 3.063835786935893
Validation loss: 2.6140983696227957

Epoch: 5| Step: 3
Training loss: 2.9899170231867624
Validation loss: 2.619247741801666

Epoch: 5| Step: 4
Training loss: 2.747297693220256
Validation loss: 2.6232308805089657

Epoch: 5| Step: 5
Training loss: 2.900467894067542
Validation loss: 2.6213254763650777

Epoch: 5| Step: 6
Training loss: 2.7246240759012
Validation loss: 2.627206055080685

Epoch: 5| Step: 7
Training loss: 2.6450320154282405
Validation loss: 2.6248183072793343

Epoch: 5| Step: 8
Training loss: 3.5039962025539078
Validation loss: 2.621038368541929

Epoch: 5| Step: 9
Training loss: 2.424211322700514
Validation loss: 2.6335738872700247

Epoch: 5| Step: 10
Training loss: 2.647038273014754
Validation loss: 2.6387809474078114

Epoch: 460| Step: 0
Training loss: 2.985474388982513
Validation loss: 2.6380279890444274

Epoch: 5| Step: 1
Training loss: 2.4331636247721917
Validation loss: 2.6457486560989345

Epoch: 5| Step: 2
Training loss: 2.977264401637977
Validation loss: 2.6548140252158103

Epoch: 5| Step: 3
Training loss: 2.9593675623380333
Validation loss: 2.652640397693832

Epoch: 5| Step: 4
Training loss: 3.0157826436794903
Validation loss: 2.684624912383534

Epoch: 5| Step: 5
Training loss: 2.9257059533243224
Validation loss: 2.672473572964177

Epoch: 5| Step: 6
Training loss: 2.9523030100845835
Validation loss: 2.678624865442771

Epoch: 5| Step: 7
Training loss: 2.6498999594752726
Validation loss: 2.6791720851784135

Epoch: 5| Step: 8
Training loss: 3.152395784499292
Validation loss: 2.6596373837040983

Epoch: 5| Step: 9
Training loss: 2.7764915306969224
Validation loss: 2.632988966526468

Epoch: 5| Step: 10
Training loss: 2.917114786509667
Validation loss: 2.6315985989471034

Epoch: 461| Step: 0
Training loss: 3.216525447954116
Validation loss: 2.629749709311791

Epoch: 5| Step: 1
Training loss: 2.9974401997128304
Validation loss: 2.626022032476459

Epoch: 5| Step: 2
Training loss: 2.700522873723514
Validation loss: 2.6168442602839073

Epoch: 5| Step: 3
Training loss: 3.2704881295596873
Validation loss: 2.622710802644776

Epoch: 5| Step: 4
Training loss: 2.8757709630457313
Validation loss: 2.6200355888062505

Epoch: 5| Step: 5
Training loss: 2.817491383171275
Validation loss: 2.6149323299195255

Epoch: 5| Step: 6
Training loss: 2.579538408727346
Validation loss: 2.6281637472410297

Epoch: 5| Step: 7
Training loss: 2.8572588318039
Validation loss: 2.6371011450796114

Epoch: 5| Step: 8
Training loss: 3.0402693129758034
Validation loss: 2.6474234073053293

Epoch: 5| Step: 9
Training loss: 2.4415001935050618
Validation loss: 2.670077067465025

Epoch: 5| Step: 10
Training loss: 2.8361846563916404
Validation loss: 2.660252565131012

Epoch: 462| Step: 0
Training loss: 2.9363540686836123
Validation loss: 2.6746362986136782

Epoch: 5| Step: 1
Training loss: 3.2346083699681283
Validation loss: 2.660649121074567

Epoch: 5| Step: 2
Training loss: 3.098284702121151
Validation loss: 2.6343978092013534

Epoch: 5| Step: 3
Training loss: 3.2178530137637544
Validation loss: 2.647498882574318

Epoch: 5| Step: 4
Training loss: 2.9655056542519675
Validation loss: 2.654460864701323

Epoch: 5| Step: 5
Training loss: 2.636099735642349
Validation loss: 2.6369367825788985

Epoch: 5| Step: 6
Training loss: 2.8609551404724782
Validation loss: 2.65938092123569

Epoch: 5| Step: 7
Training loss: 2.539254237051363
Validation loss: 2.6381482759423345

Epoch: 5| Step: 8
Training loss: 1.9037422820227228
Validation loss: 2.644790447434037

Epoch: 5| Step: 9
Training loss: 2.7588824825167246
Validation loss: 2.6396569403889814

Epoch: 5| Step: 10
Training loss: 3.329191941287494
Validation loss: 2.6537323816374103

Epoch: 463| Step: 0
Training loss: 2.476340587794133
Validation loss: 2.637990718234331

Epoch: 5| Step: 1
Training loss: 3.4461394893955024
Validation loss: 2.637667065307692

Epoch: 5| Step: 2
Training loss: 2.8133635996445485
Validation loss: 2.6338641682938135

Epoch: 5| Step: 3
Training loss: 2.9434862217089
Validation loss: 2.642866843754486

Epoch: 5| Step: 4
Training loss: 3.073554193776332
Validation loss: 2.6351233212137375

Epoch: 5| Step: 5
Training loss: 2.7728767795306823
Validation loss: 2.6552290902311473

Epoch: 5| Step: 6
Training loss: 2.7062659564880343
Validation loss: 2.6473074774086065

Epoch: 5| Step: 7
Training loss: 2.849270335704012
Validation loss: 2.6534119396198457

Epoch: 5| Step: 8
Training loss: 3.1810479780102847
Validation loss: 2.642895133827944

Epoch: 5| Step: 9
Training loss: 2.561714796393049
Validation loss: 2.647513781188287

Epoch: 5| Step: 10
Training loss: 2.6821175725542217
Validation loss: 2.634679557392909

Epoch: 464| Step: 0
Training loss: 2.750575872293281
Validation loss: 2.6230638153909895

Epoch: 5| Step: 1
Training loss: 3.2725193675308106
Validation loss: 2.6339239734078275

Epoch: 5| Step: 2
Training loss: 2.3454284761282533
Validation loss: 2.619516409146457

Epoch: 5| Step: 3
Training loss: 2.9685408669142554
Validation loss: 2.625277547036432

Epoch: 5| Step: 4
Training loss: 2.9036482783878905
Validation loss: 2.6281980467429285

Epoch: 5| Step: 5
Training loss: 3.0807261054485178
Validation loss: 2.636887247344777

Epoch: 5| Step: 6
Training loss: 2.6945951087576
Validation loss: 2.644641913832929

Epoch: 5| Step: 7
Training loss: 3.242461337739187
Validation loss: 2.6213596560551817

Epoch: 5| Step: 8
Training loss: 2.675323402606256
Validation loss: 2.6416194815158045

Epoch: 5| Step: 9
Training loss: 3.037769660439661
Validation loss: 2.635310828052595

Epoch: 5| Step: 10
Training loss: 2.5222581877177115
Validation loss: 2.6304834443505416

Epoch: 465| Step: 0
Training loss: 3.4323674117873093
Validation loss: 2.6451506696070646

Epoch: 5| Step: 1
Training loss: 2.552511239022405
Validation loss: 2.641836952429172

Epoch: 5| Step: 2
Training loss: 3.0122137986353104
Validation loss: 2.6607525849024425

Epoch: 5| Step: 3
Training loss: 2.695472159701674
Validation loss: 2.6461187616796233

Epoch: 5| Step: 4
Training loss: 2.8755374903588846
Validation loss: 2.653371578627716

Epoch: 5| Step: 5
Training loss: 2.9871573534993816
Validation loss: 2.655933914825489

Epoch: 5| Step: 6
Training loss: 2.754946594689905
Validation loss: 2.649307082566548

Epoch: 5| Step: 7
Training loss: 3.1192610878037637
Validation loss: 2.6396771655973743

Epoch: 5| Step: 8
Training loss: 2.885667498504682
Validation loss: 2.632535302330262

Epoch: 5| Step: 9
Training loss: 2.6323818680937983
Validation loss: 2.6445155609877724

Epoch: 5| Step: 10
Training loss: 2.534919998140505
Validation loss: 2.6207947298282237

Epoch: 466| Step: 0
Training loss: 2.8863305436068836
Validation loss: 2.636245707711442

Epoch: 5| Step: 1
Training loss: 3.2699155228461625
Validation loss: 2.6342711537960612

Epoch: 5| Step: 2
Training loss: 2.635150267715517
Validation loss: 2.6227429497257346

Epoch: 5| Step: 3
Training loss: 2.9628557015801884
Validation loss: 2.618425597834333

Epoch: 5| Step: 4
Training loss: 2.776890627868348
Validation loss: 2.6202388797528124

Epoch: 5| Step: 5
Training loss: 2.582453290696021
Validation loss: 2.6239153769310586

Epoch: 5| Step: 6
Training loss: 3.139558373756819
Validation loss: 2.618736797611477

Epoch: 5| Step: 7
Training loss: 2.990886993252786
Validation loss: 2.626628194983939

Epoch: 5| Step: 8
Training loss: 2.6164899665148815
Validation loss: 2.641258127438704

Epoch: 5| Step: 9
Training loss: 2.9685018335317146
Validation loss: 2.6367118895520067

Epoch: 5| Step: 10
Training loss: 2.8375942130559735
Validation loss: 2.6429052932316393

Epoch: 467| Step: 0
Training loss: 2.3521122590801626
Validation loss: 2.650505139435147

Epoch: 5| Step: 1
Training loss: 2.971641658122175
Validation loss: 2.652059638637337

Epoch: 5| Step: 2
Training loss: 2.832316290881765
Validation loss: 2.6407502148269857

Epoch: 5| Step: 3
Training loss: 2.5846744460739153
Validation loss: 2.631907315775668

Epoch: 5| Step: 4
Training loss: 2.9469006048811397
Validation loss: 2.636170479161475

Epoch: 5| Step: 5
Training loss: 2.9929375169160437
Validation loss: 2.6339753231186074

Epoch: 5| Step: 6
Training loss: 3.066109845845708
Validation loss: 2.6277142519779533

Epoch: 5| Step: 7
Training loss: 2.616367040678091
Validation loss: 2.6298908995257455

Epoch: 5| Step: 8
Training loss: 2.792626419962428
Validation loss: 2.6273695724557222

Epoch: 5| Step: 9
Training loss: 2.8848461225122097
Validation loss: 2.6179075922717847

Epoch: 5| Step: 10
Training loss: 3.5558397374893733
Validation loss: 2.634764395121149

Epoch: 468| Step: 0
Training loss: 3.2141880928837296
Validation loss: 2.6348777128140233

Epoch: 5| Step: 1
Training loss: 2.8229314843571314
Validation loss: 2.6258646072902474

Epoch: 5| Step: 2
Training loss: 2.7530045135494303
Validation loss: 2.6321957654779484

Epoch: 5| Step: 3
Training loss: 2.9400879842866403
Validation loss: 2.635801616393052

Epoch: 5| Step: 4
Training loss: 2.700342499237772
Validation loss: 2.6484241669781716

Epoch: 5| Step: 5
Training loss: 2.5828028000812733
Validation loss: 2.6442433751588355

Epoch: 5| Step: 6
Training loss: 2.554316595841156
Validation loss: 2.6565232881294145

Epoch: 5| Step: 7
Training loss: 2.9036423664614017
Validation loss: 2.644638090628766

Epoch: 5| Step: 8
Training loss: 3.3808762997843265
Validation loss: 2.6551717781192163

Epoch: 5| Step: 9
Training loss: 3.069859595054733
Validation loss: 2.6472110999661793

Epoch: 5| Step: 10
Training loss: 2.5522730438928893
Validation loss: 2.6502442480122985

Epoch: 469| Step: 0
Training loss: 2.8144765901877897
Validation loss: 2.630328856324009

Epoch: 5| Step: 1
Training loss: 2.975690098070264
Validation loss: 2.6278100801334365

Epoch: 5| Step: 2
Training loss: 2.8961913255750105
Validation loss: 2.626906180916305

Epoch: 5| Step: 3
Training loss: 2.6433591513156585
Validation loss: 2.620170122798181

Epoch: 5| Step: 4
Training loss: 2.6549837572423494
Validation loss: 2.614256299375079

Epoch: 5| Step: 5
Training loss: 2.869774257009399
Validation loss: 2.614757896929745

Epoch: 5| Step: 6
Training loss: 3.2276287395351773
Validation loss: 2.6172391153877292

Epoch: 5| Step: 7
Training loss: 2.828554911104226
Validation loss: 2.623738798942928

Epoch: 5| Step: 8
Training loss: 3.403343290363608
Validation loss: 2.6171854223941935

Epoch: 5| Step: 9
Training loss: 2.35375094048577
Validation loss: 2.6150080086701055

Epoch: 5| Step: 10
Training loss: 2.8050985646057645
Validation loss: 2.616118844318962

Epoch: 470| Step: 0
Training loss: 2.6921686828274476
Validation loss: 2.6341948644971573

Epoch: 5| Step: 1
Training loss: 3.29322851928016
Validation loss: 2.6449213097610618

Epoch: 5| Step: 2
Training loss: 2.35464893453768
Validation loss: 2.627094480150908

Epoch: 5| Step: 3
Training loss: 3.1066376411599212
Validation loss: 2.6329948318582956

Epoch: 5| Step: 4
Training loss: 2.755615569643845
Validation loss: 2.626929534490239

Epoch: 5| Step: 5
Training loss: 2.7560317041707867
Validation loss: 2.644985686380792

Epoch: 5| Step: 6
Training loss: 2.8860133319634036
Validation loss: 2.6379128629909854

Epoch: 5| Step: 7
Training loss: 2.897150375956229
Validation loss: 2.637610176373457

Epoch: 5| Step: 8
Training loss: 2.5412768289075824
Validation loss: 2.650060051817864

Epoch: 5| Step: 9
Training loss: 3.2384159810161934
Validation loss: 2.6518111170090473

Epoch: 5| Step: 10
Training loss: 3.015781220654046
Validation loss: 2.6439356691933074

Epoch: 471| Step: 0
Training loss: 2.528988145522167
Validation loss: 2.6333869722878838

Epoch: 5| Step: 1
Training loss: 3.203646882504113
Validation loss: 2.6218955320813997

Epoch: 5| Step: 2
Training loss: 2.4905897418007026
Validation loss: 2.6236033330245694

Epoch: 5| Step: 3
Training loss: 3.386649759155281
Validation loss: 2.6222471626872084

Epoch: 5| Step: 4
Training loss: 2.71157011626518
Validation loss: 2.6115033603750484

Epoch: 5| Step: 5
Training loss: 2.8970825647683847
Validation loss: 2.6180784988373595

Epoch: 5| Step: 6
Training loss: 3.0515679628447328
Validation loss: 2.634100456958843

Epoch: 5| Step: 7
Training loss: 3.0291082937151175
Validation loss: 2.6290528984047246

Epoch: 5| Step: 8
Training loss: 2.6710448285978643
Validation loss: 2.617858804542623

Epoch: 5| Step: 9
Training loss: 2.8063134710869617
Validation loss: 2.6310089566017707

Epoch: 5| Step: 10
Training loss: 2.6146326149073986
Validation loss: 2.6325356344061133

Epoch: 472| Step: 0
Training loss: 3.2007784552232583
Validation loss: 2.629100687599867

Epoch: 5| Step: 1
Training loss: 3.0148760404140167
Validation loss: 2.6170250127287935

Epoch: 5| Step: 2
Training loss: 3.097755228508139
Validation loss: 2.6240317418888286

Epoch: 5| Step: 3
Training loss: 3.0635855171691064
Validation loss: 2.632742353719416

Epoch: 5| Step: 4
Training loss: 2.8698134701287676
Validation loss: 2.6323934797145334

Epoch: 5| Step: 5
Training loss: 3.1193213174611207
Validation loss: 2.6399986124625463

Epoch: 5| Step: 6
Training loss: 2.2600024733065687
Validation loss: 2.6269307651095004

Epoch: 5| Step: 7
Training loss: 2.877044282648651
Validation loss: 2.6234980586944485

Epoch: 5| Step: 8
Training loss: 2.458501282035861
Validation loss: 2.6226306893253573

Epoch: 5| Step: 9
Training loss: 2.8440018427074274
Validation loss: 2.6261200417311996

Epoch: 5| Step: 10
Training loss: 2.5813687350325627
Validation loss: 2.6165348576923337

Epoch: 473| Step: 0
Training loss: 3.2731371175014683
Validation loss: 2.6279410836895973

Epoch: 5| Step: 1
Training loss: 3.2751638007514874
Validation loss: 2.6253712445797337

Epoch: 5| Step: 2
Training loss: 2.591041161549211
Validation loss: 2.64022974380185

Epoch: 5| Step: 3
Training loss: 2.00439375808831
Validation loss: 2.644419023140354

Epoch: 5| Step: 4
Training loss: 2.999287997631574
Validation loss: 2.6534943021968114

Epoch: 5| Step: 5
Training loss: 3.240123266300644
Validation loss: 2.677759782140103

Epoch: 5| Step: 6
Training loss: 3.041150471681112
Validation loss: 2.6773708248669843

Epoch: 5| Step: 7
Training loss: 2.447714116800205
Validation loss: 2.6499424852494213

Epoch: 5| Step: 8
Training loss: 2.7747053660098873
Validation loss: 2.6320924005096393

Epoch: 5| Step: 9
Training loss: 2.909147561399487
Validation loss: 2.6062999160372438

Epoch: 5| Step: 10
Training loss: 2.7896069761892988
Validation loss: 2.606980573459283

Epoch: 474| Step: 0
Training loss: 3.3662279359340177
Validation loss: 2.608410418302905

Epoch: 5| Step: 1
Training loss: 3.0399477730832367
Validation loss: 2.6114689603860644

Epoch: 5| Step: 2
Training loss: 2.8167800549438873
Validation loss: 2.6160695097325823

Epoch: 5| Step: 3
Training loss: 2.493853642884134
Validation loss: 2.6121238763532917

Epoch: 5| Step: 4
Training loss: 2.402728290329995
Validation loss: 2.6245318130521387

Epoch: 5| Step: 5
Training loss: 3.3126321442355264
Validation loss: 2.629738688484215

Epoch: 5| Step: 6
Training loss: 2.7734295052426585
Validation loss: 2.6514097477552134

Epoch: 5| Step: 7
Training loss: 2.6399678874230186
Validation loss: 2.6567574553770803

Epoch: 5| Step: 8
Training loss: 2.665222631319851
Validation loss: 2.663571442470963

Epoch: 5| Step: 9
Training loss: 3.069232158502456
Validation loss: 2.6911088199372633

Epoch: 5| Step: 10
Training loss: 2.896801921494718
Validation loss: 2.6915083848147137

Epoch: 475| Step: 0
Training loss: 3.146696077656557
Validation loss: 2.684588441281828

Epoch: 5| Step: 1
Training loss: 2.0912435531744857
Validation loss: 2.640064472963078

Epoch: 5| Step: 2
Training loss: 2.720213748162699
Validation loss: 2.629053156811368

Epoch: 5| Step: 3
Training loss: 2.8396489681309256
Validation loss: 2.6170095320464952

Epoch: 5| Step: 4
Training loss: 3.2813855824387974
Validation loss: 2.606992020907499

Epoch: 5| Step: 5
Training loss: 3.094907601846111
Validation loss: 2.5933010801541982

Epoch: 5| Step: 6
Training loss: 2.456330167515292
Validation loss: 2.599569525788124

Epoch: 5| Step: 7
Training loss: 3.2369924081095234
Validation loss: 2.5967288410597242

Epoch: 5| Step: 8
Training loss: 2.800127152553092
Validation loss: 2.5986529732385804

Epoch: 5| Step: 9
Training loss: 2.9005736013937056
Validation loss: 2.599439054989223

Epoch: 5| Step: 10
Training loss: 2.83051262489068
Validation loss: 2.6036418623895274

Epoch: 476| Step: 0
Training loss: 2.9270896685295282
Validation loss: 2.6043714683150445

Epoch: 5| Step: 1
Training loss: 2.842177910183021
Validation loss: 2.6047371355565767

Epoch: 5| Step: 2
Training loss: 2.9539879239506366
Validation loss: 2.6195017633174684

Epoch: 5| Step: 3
Training loss: 2.8600538104670497
Validation loss: 2.6129731591514256

Epoch: 5| Step: 4
Training loss: 3.0592143280575614
Validation loss: 2.6343691568537673

Epoch: 5| Step: 5
Training loss: 2.463374599305576
Validation loss: 2.636959142205185

Epoch: 5| Step: 6
Training loss: 2.624026708455349
Validation loss: 2.636294153224439

Epoch: 5| Step: 7
Training loss: 3.1476134932874142
Validation loss: 2.64591546512943

Epoch: 5| Step: 8
Training loss: 2.5734534276435794
Validation loss: 2.6313461212886313

Epoch: 5| Step: 9
Training loss: 3.113447120297088
Validation loss: 2.638266461369574

Epoch: 5| Step: 10
Training loss: 3.0084143890986237
Validation loss: 2.616464884457613

Epoch: 477| Step: 0
Training loss: 2.2545182109680164
Validation loss: 2.6116117612576115

Epoch: 5| Step: 1
Training loss: 2.9657537498704447
Validation loss: 2.5994338062763473

Epoch: 5| Step: 2
Training loss: 2.862427629780355
Validation loss: 2.5986929085205213

Epoch: 5| Step: 3
Training loss: 3.423837038279898
Validation loss: 2.5995721746633205

Epoch: 5| Step: 4
Training loss: 2.427243588986713
Validation loss: 2.59509670356134

Epoch: 5| Step: 5
Training loss: 2.8759455577170003
Validation loss: 2.5963660582292323

Epoch: 5| Step: 6
Training loss: 3.359680303850292
Validation loss: 2.601141558587591

Epoch: 5| Step: 7
Training loss: 2.4732455113423333
Validation loss: 2.6046749575485357

Epoch: 5| Step: 8
Training loss: 2.9463322743454463
Validation loss: 2.6181297568812694

Epoch: 5| Step: 9
Training loss: 2.7392082005868246
Validation loss: 2.6131264409443404

Epoch: 5| Step: 10
Training loss: 3.083092568422399
Validation loss: 2.6294724003313514

Epoch: 478| Step: 0
Training loss: 3.0129866844007087
Validation loss: 2.6361587217714857

Epoch: 5| Step: 1
Training loss: 2.935971613224431
Validation loss: 2.6502050237659005

Epoch: 5| Step: 2
Training loss: 2.6492214786714605
Validation loss: 2.6636075093297653

Epoch: 5| Step: 3
Training loss: 3.1318427889599985
Validation loss: 2.658044672774555

Epoch: 5| Step: 4
Training loss: 2.92871761289461
Validation loss: 2.6507844502581457

Epoch: 5| Step: 5
Training loss: 2.6135851308452795
Validation loss: 2.643998089388826

Epoch: 5| Step: 6
Training loss: 2.98674101186364
Validation loss: 2.6218237844352896

Epoch: 5| Step: 7
Training loss: 2.9889185007827312
Validation loss: 2.6158578761049225

Epoch: 5| Step: 8
Training loss: 2.3709093301813375
Validation loss: 2.603628134552192

Epoch: 5| Step: 9
Training loss: 2.6555321116013357
Validation loss: 2.5953132790157243

Epoch: 5| Step: 10
Training loss: 3.304700053306166
Validation loss: 2.5981589111711174

Epoch: 479| Step: 0
Training loss: 3.1350865660280034
Validation loss: 2.6000989611923435

Epoch: 5| Step: 1
Training loss: 3.3144420472984444
Validation loss: 2.5844234511163457

Epoch: 5| Step: 2
Training loss: 2.659620144188047
Validation loss: 2.591828496508733

Epoch: 5| Step: 3
Training loss: 2.718569519366466
Validation loss: 2.596886993451981

Epoch: 5| Step: 4
Training loss: 3.014706486574657
Validation loss: 2.6076654320221406

Epoch: 5| Step: 5
Training loss: 2.5358322488375262
Validation loss: 2.6102141407164643

Epoch: 5| Step: 6
Training loss: 2.912395256025414
Validation loss: 2.6313539953240723

Epoch: 5| Step: 7
Training loss: 3.2210837486864956
Validation loss: 2.6158720131177082

Epoch: 5| Step: 8
Training loss: 2.900481210443576
Validation loss: 2.6466451892625553

Epoch: 5| Step: 9
Training loss: 2.1491695752024955
Validation loss: 2.64688720107558

Epoch: 5| Step: 10
Training loss: 2.8118434563550787
Validation loss: 2.648013283595579

Epoch: 480| Step: 0
Training loss: 2.4956365653175347
Validation loss: 2.64571591162644

Epoch: 5| Step: 1
Training loss: 2.4232479018833244
Validation loss: 2.6999628597699417

Epoch: 5| Step: 2
Training loss: 3.1559413343520157
Validation loss: 2.711820560665713

Epoch: 5| Step: 3
Training loss: 2.6267261279422716
Validation loss: 2.71408139237825

Epoch: 5| Step: 4
Training loss: 3.198630701593002
Validation loss: 2.6688880096445073

Epoch: 5| Step: 5
Training loss: 2.890766367161857
Validation loss: 2.6408970432930037

Epoch: 5| Step: 6
Training loss: 2.943537574441413
Validation loss: 2.6191241055741097

Epoch: 5| Step: 7
Training loss: 3.150262876168407
Validation loss: 2.600831099680604

Epoch: 5| Step: 8
Training loss: 3.0529528910016435
Validation loss: 2.5922661757559338

Epoch: 5| Step: 9
Training loss: 2.6412016109253083
Validation loss: 2.599715953453095

Epoch: 5| Step: 10
Training loss: 2.8957449444424763
Validation loss: 2.5921797968056772

Epoch: 481| Step: 0
Training loss: 2.617209089958757
Validation loss: 2.586958692944202

Epoch: 5| Step: 1
Training loss: 2.4712864846762024
Validation loss: 2.58946691198611

Epoch: 5| Step: 2
Training loss: 3.2329418305846223
Validation loss: 2.5889357281351373

Epoch: 5| Step: 3
Training loss: 3.653233514614784
Validation loss: 2.597050381363018

Epoch: 5| Step: 4
Training loss: 2.6420206749314317
Validation loss: 2.5979821648880934

Epoch: 5| Step: 5
Training loss: 2.9150335008322155
Validation loss: 2.6043679777700524

Epoch: 5| Step: 6
Training loss: 3.2525299202248714
Validation loss: 2.6037950988174887

Epoch: 5| Step: 7
Training loss: 2.50990821047426
Validation loss: 2.6066044661972345

Epoch: 5| Step: 8
Training loss: 2.783287673469078
Validation loss: 2.6195610311991393

Epoch: 5| Step: 9
Training loss: 2.6476309569392535
Validation loss: 2.627995510007642

Epoch: 5| Step: 10
Training loss: 2.7538741306028074
Validation loss: 2.649713226708924

Epoch: 482| Step: 0
Training loss: 3.1423376167969304
Validation loss: 2.640814640220521

Epoch: 5| Step: 1
Training loss: 3.636660008924097
Validation loss: 2.657003406130401

Epoch: 5| Step: 2
Training loss: 3.120677705423213
Validation loss: 2.6402726001057997

Epoch: 5| Step: 3
Training loss: 3.0101114578142045
Validation loss: 2.6641042608223064

Epoch: 5| Step: 4
Training loss: 2.8778897565201476
Validation loss: 2.653371992153705

Epoch: 5| Step: 5
Training loss: 3.042914060754943
Validation loss: 2.6434508007624484

Epoch: 5| Step: 6
Training loss: 1.9995603078078308
Validation loss: 2.628008968134002

Epoch: 5| Step: 7
Training loss: 2.76411008562063
Validation loss: 2.6116064977436606

Epoch: 5| Step: 8
Training loss: 2.6501620369081014
Validation loss: 2.6031147508732504

Epoch: 5| Step: 9
Training loss: 2.310730953413335
Validation loss: 2.591252893783894

Epoch: 5| Step: 10
Training loss: 2.7045606207659136
Validation loss: 2.5971207049312945

Epoch: 483| Step: 0
Training loss: 2.6399074685613355
Validation loss: 2.5953966239709634

Epoch: 5| Step: 1
Training loss: 2.8841099907671297
Validation loss: 2.5925716773309517

Epoch: 5| Step: 2
Training loss: 3.295903645829218
Validation loss: 2.598947828365613

Epoch: 5| Step: 3
Training loss: 2.895111396504277
Validation loss: 2.5966436694317085

Epoch: 5| Step: 4
Training loss: 2.902667390792025
Validation loss: 2.60229175598301

Epoch: 5| Step: 5
Training loss: 2.6222199750700264
Validation loss: 2.6166093467180445

Epoch: 5| Step: 6
Training loss: 2.5649259295560345
Validation loss: 2.6198536398614674

Epoch: 5| Step: 7
Training loss: 2.7331332629724634
Validation loss: 2.626752839491319

Epoch: 5| Step: 8
Training loss: 2.9748772283273484
Validation loss: 2.6248530958627647

Epoch: 5| Step: 9
Training loss: 3.219776619454681
Validation loss: 2.647872066344062

Epoch: 5| Step: 10
Training loss: 2.6929731306455973
Validation loss: 2.6571483292191016

Epoch: 484| Step: 0
Training loss: 2.9761105492168243
Validation loss: 2.6769075683515053

Epoch: 5| Step: 1
Training loss: 2.933127862785433
Validation loss: 2.6719846330568875

Epoch: 5| Step: 2
Training loss: 2.927140494407302
Validation loss: 2.6689361181525864

Epoch: 5| Step: 3
Training loss: 2.6384444403452614
Validation loss: 2.6630351086794075

Epoch: 5| Step: 4
Training loss: 2.8151530997616554
Validation loss: 2.6487398407274316

Epoch: 5| Step: 5
Training loss: 2.67222102194495
Validation loss: 2.619097209529386

Epoch: 5| Step: 6
Training loss: 2.9700574706197487
Validation loss: 2.61924540743461

Epoch: 5| Step: 7
Training loss: 3.005338845595162
Validation loss: 2.6170311038814735

Epoch: 5| Step: 8
Training loss: 2.21604883958175
Validation loss: 2.609642525489357

Epoch: 5| Step: 9
Training loss: 3.370859078276359
Validation loss: 2.628611843156491

Epoch: 5| Step: 10
Training loss: 2.870110043532705
Validation loss: 2.6198704042143217

Epoch: 485| Step: 0
Training loss: 2.3842426948287456
Validation loss: 2.6159928180038046

Epoch: 5| Step: 1
Training loss: 3.128898934916543
Validation loss: 2.6108733904028183

Epoch: 5| Step: 2
Training loss: 3.0387351833093694
Validation loss: 2.6121267608013596

Epoch: 5| Step: 3
Training loss: 3.0730232522012155
Validation loss: 2.604847530491143

Epoch: 5| Step: 4
Training loss: 2.393290610591791
Validation loss: 2.608055250130446

Epoch: 5| Step: 5
Training loss: 3.5534019073778365
Validation loss: 2.5997614093981785

Epoch: 5| Step: 6
Training loss: 2.432833875930948
Validation loss: 2.6007772236878326

Epoch: 5| Step: 7
Training loss: 2.682675044738069
Validation loss: 2.600158183292518

Epoch: 5| Step: 8
Training loss: 2.9985659668691658
Validation loss: 2.612358728109948

Epoch: 5| Step: 9
Training loss: 2.983368389271757
Validation loss: 2.630516635723967

Epoch: 5| Step: 10
Training loss: 2.454498101108397
Validation loss: 2.6438218379412657

Epoch: 486| Step: 0
Training loss: 2.665485259459522
Validation loss: 2.6474325979285482

Epoch: 5| Step: 1
Training loss: 2.6567999775303877
Validation loss: 2.6765472774303687

Epoch: 5| Step: 2
Training loss: 2.7423950290672714
Validation loss: 2.681376894498067

Epoch: 5| Step: 3
Training loss: 3.4011323613940223
Validation loss: 2.6819288789582556

Epoch: 5| Step: 4
Training loss: 2.848594814357043
Validation loss: 2.70139757876871

Epoch: 5| Step: 5
Training loss: 2.9332987183638126
Validation loss: 2.6752159322077484

Epoch: 5| Step: 6
Training loss: 2.5800906923899074
Validation loss: 2.654004988174084

Epoch: 5| Step: 7
Training loss: 3.031240246943878
Validation loss: 2.633506529821083

Epoch: 5| Step: 8
Training loss: 2.7224659572746335
Validation loss: 2.6212554657283627

Epoch: 5| Step: 9
Training loss: 3.0605844228811137
Validation loss: 2.6138098848661846

Epoch: 5| Step: 10
Training loss: 2.7833018074610623
Validation loss: 2.6122856812144604

Epoch: 487| Step: 0
Training loss: 2.9122729495370074
Validation loss: 2.595757425311357

Epoch: 5| Step: 1
Training loss: 2.676219063463784
Validation loss: 2.594112438622309

Epoch: 5| Step: 2
Training loss: 2.670973240782939
Validation loss: 2.5921971555050343

Epoch: 5| Step: 3
Training loss: 2.788783724660869
Validation loss: 2.5885372508873328

Epoch: 5| Step: 4
Training loss: 3.1439534479825006
Validation loss: 2.5860193944279466

Epoch: 5| Step: 5
Training loss: 3.267243490738178
Validation loss: 2.584194334272995

Epoch: 5| Step: 6
Training loss: 2.2302286583373547
Validation loss: 2.5865050946012724

Epoch: 5| Step: 7
Training loss: 2.993248972847422
Validation loss: 2.581390823193257

Epoch: 5| Step: 8
Training loss: 2.9858166473061547
Validation loss: 2.5837604253679354

Epoch: 5| Step: 9
Training loss: 2.7441304596953624
Validation loss: 2.5956590103458343

Epoch: 5| Step: 10
Training loss: 3.0606736946244073
Validation loss: 2.599837218159159

Epoch: 488| Step: 0
Training loss: 3.450978159797511
Validation loss: 2.619995751830321

Epoch: 5| Step: 1
Training loss: 2.80066462530679
Validation loss: 2.6280192148375194

Epoch: 5| Step: 2
Training loss: 2.648231340784631
Validation loss: 2.6425804489420566

Epoch: 5| Step: 3
Training loss: 2.5778707667912872
Validation loss: 2.660874892898705

Epoch: 5| Step: 4
Training loss: 3.0760146909246355
Validation loss: 2.6631046476526294

Epoch: 5| Step: 5
Training loss: 2.872733176173739
Validation loss: 2.6694345613213524

Epoch: 5| Step: 6
Training loss: 2.8772255949131686
Validation loss: 2.6347015742086266

Epoch: 5| Step: 7
Training loss: 2.8912248968410896
Validation loss: 2.6158030649344597

Epoch: 5| Step: 8
Training loss: 2.7517036016223915
Validation loss: 2.6060393486668363

Epoch: 5| Step: 9
Training loss: 2.708093564106145
Validation loss: 2.6128709156006558

Epoch: 5| Step: 10
Training loss: 2.589256070347862
Validation loss: 2.5982287597398077

Epoch: 489| Step: 0
Training loss: 2.8981485968298175
Validation loss: 2.597817084919938

Epoch: 5| Step: 1
Training loss: 2.7918965449034547
Validation loss: 2.6075077588575075

Epoch: 5| Step: 2
Training loss: 2.5893510030398272
Validation loss: 2.58750732208416

Epoch: 5| Step: 3
Training loss: 2.9307494820003153
Validation loss: 2.5878798687232085

Epoch: 5| Step: 4
Training loss: 2.9015566758532354
Validation loss: 2.591563137463395

Epoch: 5| Step: 5
Training loss: 2.7850176548012997
Validation loss: 2.6050568602650483

Epoch: 5| Step: 6
Training loss: 2.6196100211196023
Validation loss: 2.6083540815136046

Epoch: 5| Step: 7
Training loss: 2.4552053389748814
Validation loss: 2.616730752417124

Epoch: 5| Step: 8
Training loss: 2.825798215596318
Validation loss: 2.62777619409706

Epoch: 5| Step: 9
Training loss: 3.3693963614444558
Validation loss: 2.624849767336365

Epoch: 5| Step: 10
Training loss: 3.1510407923337285
Validation loss: 2.624163946173385

Epoch: 490| Step: 0
Training loss: 2.868444016704062
Validation loss: 2.622004172097693

Epoch: 5| Step: 1
Training loss: 2.6365700008678545
Validation loss: 2.6270888329218436

Epoch: 5| Step: 2
Training loss: 3.432036062784726
Validation loss: 2.627207638811618

Epoch: 5| Step: 3
Training loss: 2.274093061490522
Validation loss: 2.6215332703420913

Epoch: 5| Step: 4
Training loss: 3.1047792448974367
Validation loss: 2.6086047620415918

Epoch: 5| Step: 5
Training loss: 2.5861698288289037
Validation loss: 2.5949742353307346

Epoch: 5| Step: 6
Training loss: 3.0722808352492206
Validation loss: 2.5968646106240914

Epoch: 5| Step: 7
Training loss: 2.8690482190276043
Validation loss: 2.5977110187173396

Epoch: 5| Step: 8
Training loss: 2.733418935117634
Validation loss: 2.6053116371242613

Epoch: 5| Step: 9
Training loss: 2.624495684907418
Validation loss: 2.596268926299079

Epoch: 5| Step: 10
Training loss: 3.0171577629943176
Validation loss: 2.6074832914096286

Epoch: 491| Step: 0
Training loss: 2.9156211795761413
Validation loss: 2.6078042169447477

Epoch: 5| Step: 1
Training loss: 3.0018117520183814
Validation loss: 2.6115429185260477

Epoch: 5| Step: 2
Training loss: 2.5776560963854176
Validation loss: 2.6109593148822237

Epoch: 5| Step: 3
Training loss: 2.3288253652404056
Validation loss: 2.6177578231977594

Epoch: 5| Step: 4
Training loss: 3.0060573460634887
Validation loss: 2.6103064127553304

Epoch: 5| Step: 5
Training loss: 3.029351337860672
Validation loss: 2.5989703027435334

Epoch: 5| Step: 6
Training loss: 3.1669491257094013
Validation loss: 2.6047483871627546

Epoch: 5| Step: 7
Training loss: 3.0106021775546137
Validation loss: 2.600643450026679

Epoch: 5| Step: 8
Training loss: 2.6702817215325942
Validation loss: 2.593959647170449

Epoch: 5| Step: 9
Training loss: 2.6139886694022656
Validation loss: 2.609165903671031

Epoch: 5| Step: 10
Training loss: 2.820329407194821
Validation loss: 2.615439646652142

Epoch: 492| Step: 0
Training loss: 2.672081119550911
Validation loss: 2.630236297397036

Epoch: 5| Step: 1
Training loss: 2.9529502857336842
Validation loss: 2.6391303263045978

Epoch: 5| Step: 2
Training loss: 2.6413359277543345
Validation loss: 2.6494153204128654

Epoch: 5| Step: 3
Training loss: 2.7374434339000486
Validation loss: 2.650607003910807

Epoch: 5| Step: 4
Training loss: 2.9348479940898278
Validation loss: 2.6517490982504275

Epoch: 5| Step: 5
Training loss: 3.3117653373938465
Validation loss: 2.6485485145958605

Epoch: 5| Step: 6
Training loss: 2.872024157016073
Validation loss: 2.626235532463699

Epoch: 5| Step: 7
Training loss: 2.9657460323674747
Validation loss: 2.6216090059471293

Epoch: 5| Step: 8
Training loss: 2.914772744848862
Validation loss: 2.6255722799121983

Epoch: 5| Step: 9
Training loss: 2.728452885206111
Validation loss: 2.6062641543662095

Epoch: 5| Step: 10
Training loss: 2.4797913114358443
Validation loss: 2.5991524343091044

Epoch: 493| Step: 0
Training loss: 3.1178874135908314
Validation loss: 2.6008101327597726

Epoch: 5| Step: 1
Training loss: 3.223751293594793
Validation loss: 2.5961699525596273

Epoch: 5| Step: 2
Training loss: 2.931653474478419
Validation loss: 2.592619618855895

Epoch: 5| Step: 3
Training loss: 2.6600334598473236
Validation loss: 2.5892611763247766

Epoch: 5| Step: 4
Training loss: 2.7410561164864955
Validation loss: 2.5897714212558287

Epoch: 5| Step: 5
Training loss: 2.6743512195761037
Validation loss: 2.60483615530591

Epoch: 5| Step: 6
Training loss: 2.0691248528194657
Validation loss: 2.6086073899489337

Epoch: 5| Step: 7
Training loss: 2.9770179059736597
Validation loss: 2.6198248881398682

Epoch: 5| Step: 8
Training loss: 2.8541518904774525
Validation loss: 2.6448065118777286

Epoch: 5| Step: 9
Training loss: 2.9100916912931454
Validation loss: 2.637849324987757

Epoch: 5| Step: 10
Training loss: 3.0252627991576673
Validation loss: 2.6479569499867863

Epoch: 494| Step: 0
Training loss: 3.422945456094495
Validation loss: 2.6451087093742207

Epoch: 5| Step: 1
Training loss: 2.502359802404218
Validation loss: 2.638698638559013

Epoch: 5| Step: 2
Training loss: 3.3068872079315685
Validation loss: 2.6470957089271834

Epoch: 5| Step: 3
Training loss: 2.5413633280195183
Validation loss: 2.6166416373413384

Epoch: 5| Step: 4
Training loss: 2.6318142863499494
Validation loss: 2.6144491907358343

Epoch: 5| Step: 5
Training loss: 2.807448279565938
Validation loss: 2.6123128917505074

Epoch: 5| Step: 6
Training loss: 2.5356688370651694
Validation loss: 2.6086567359358277

Epoch: 5| Step: 7
Training loss: 2.7419560435282535
Validation loss: 2.6038114595067854

Epoch: 5| Step: 8
Training loss: 2.5983472779760084
Validation loss: 2.588232537976293

Epoch: 5| Step: 9
Training loss: 2.563960984735122
Validation loss: 2.5983009418570053

Epoch: 5| Step: 10
Training loss: 3.4602135445732034
Validation loss: 2.6144726212613567

Epoch: 495| Step: 0
Training loss: 3.1203208988174085
Validation loss: 2.6190613744617144

Epoch: 5| Step: 1
Training loss: 2.1192859793179846
Validation loss: 2.6218966340407848

Epoch: 5| Step: 2
Training loss: 3.08580074731604
Validation loss: 2.6349888170998983

Epoch: 5| Step: 3
Training loss: 3.0889942337234237
Validation loss: 2.6310725457922604

Epoch: 5| Step: 4
Training loss: 2.409842645407073
Validation loss: 2.6349780137432433

Epoch: 5| Step: 5
Training loss: 3.081764199952106
Validation loss: 2.65150331757974

Epoch: 5| Step: 6
Training loss: 2.4761878852428953
Validation loss: 2.6364856033826243

Epoch: 5| Step: 7
Training loss: 3.049739801533184
Validation loss: 2.6206258414810986

Epoch: 5| Step: 8
Training loss: 2.929811358058917
Validation loss: 2.6193703983633183

Epoch: 5| Step: 9
Training loss: 2.5664105233863777
Validation loss: 2.599768595143542

Epoch: 5| Step: 10
Training loss: 3.214647660237086
Validation loss: 2.5941725978551147

Epoch: 496| Step: 0
Training loss: 2.598262125360434
Validation loss: 2.583008236298355

Epoch: 5| Step: 1
Training loss: 2.9394729157348713
Validation loss: 2.5782640167970334

Epoch: 5| Step: 2
Training loss: 2.9306373785647915
Validation loss: 2.5791524928409535

Epoch: 5| Step: 3
Training loss: 2.708961316198275
Validation loss: 2.5796594929942023

Epoch: 5| Step: 4
Training loss: 2.9571052652869483
Validation loss: 2.5804143173659506

Epoch: 5| Step: 5
Training loss: 2.51284200134152
Validation loss: 2.578578801890835

Epoch: 5| Step: 6
Training loss: 2.986166211785469
Validation loss: 2.576489478858388

Epoch: 5| Step: 7
Training loss: 3.083656569025377
Validation loss: 2.583465829468945

Epoch: 5| Step: 8
Training loss: 2.5968207141329755
Validation loss: 2.584596095715023

Epoch: 5| Step: 9
Training loss: 2.660284142913839
Validation loss: 2.6023967262339096

Epoch: 5| Step: 10
Training loss: 3.3221825214198333
Validation loss: 2.6066732077420385

Epoch: 497| Step: 0
Training loss: 2.355701036529177
Validation loss: 2.622504942704654

Epoch: 5| Step: 1
Training loss: 2.80799386060212
Validation loss: 2.6290911042825735

Epoch: 5| Step: 2
Training loss: 2.802874305767543
Validation loss: 2.633694906153711

Epoch: 5| Step: 3
Training loss: 2.713420862790269
Validation loss: 2.6286398901974684

Epoch: 5| Step: 4
Training loss: 2.804023515316996
Validation loss: 2.6100790719445808

Epoch: 5| Step: 5
Training loss: 2.706261287251604
Validation loss: 2.6165381811196853

Epoch: 5| Step: 6
Training loss: 2.7525518888178593
Validation loss: 2.6129912980379246

Epoch: 5| Step: 7
Training loss: 2.936827237621037
Validation loss: 2.6234993588375946

Epoch: 5| Step: 8
Training loss: 3.2916866897424693
Validation loss: 2.6140455536068434

Epoch: 5| Step: 9
Training loss: 2.956089852574123
Validation loss: 2.6213831304344066

Epoch: 5| Step: 10
Training loss: 3.0872660806978307
Validation loss: 2.6256577907416823

Epoch: 498| Step: 0
Training loss: 2.44844269207256
Validation loss: 2.6191804402349397

Epoch: 5| Step: 1
Training loss: 3.0780833285071876
Validation loss: 2.6018862200324846

Epoch: 5| Step: 2
Training loss: 3.0436255709615363
Validation loss: 2.602299921855971

Epoch: 5| Step: 3
Training loss: 2.7806110291013217
Validation loss: 2.60794215892096

Epoch: 5| Step: 4
Training loss: 2.801035679283188
Validation loss: 2.5905283789528877

Epoch: 5| Step: 5
Training loss: 2.6012609725200124
Validation loss: 2.587023554166704

Epoch: 5| Step: 6
Training loss: 3.1078838817747383
Validation loss: 2.597439972550068

Epoch: 5| Step: 7
Training loss: 3.0629076005260676
Validation loss: 2.587319147028474

Epoch: 5| Step: 8
Training loss: 2.3882963520105407
Validation loss: 2.5925351047962333

Epoch: 5| Step: 9
Training loss: 2.650001086828621
Validation loss: 2.5927833735688486

Epoch: 5| Step: 10
Training loss: 3.1631700552260558
Validation loss: 2.603936226442177

Epoch: 499| Step: 0
Training loss: 3.5111416182285833
Validation loss: 2.621593747912408

Epoch: 5| Step: 1
Training loss: 2.884631567689544
Validation loss: 2.628133805652482

Epoch: 5| Step: 2
Training loss: 2.855337325175355
Validation loss: 2.6356530820140285

Epoch: 5| Step: 3
Training loss: 2.162348981225664
Validation loss: 2.6188527764434784

Epoch: 5| Step: 4
Training loss: 3.160044438254881
Validation loss: 2.633384021563512

Epoch: 5| Step: 5
Training loss: 2.866721965197293
Validation loss: 2.621931895518813

Epoch: 5| Step: 6
Training loss: 2.5308870596945736
Validation loss: 2.5984537799371017

Epoch: 5| Step: 7
Training loss: 2.5748287514342865
Validation loss: 2.5904482580180166

Epoch: 5| Step: 8
Training loss: 2.3346435637508316
Validation loss: 2.583010732439479

Epoch: 5| Step: 9
Training loss: 3.1492665905395456
Validation loss: 2.5962929287003247

Epoch: 5| Step: 10
Training loss: 3.031067360950372
Validation loss: 2.5928287424271157

Epoch: 500| Step: 0
Training loss: 3.177795897241729
Validation loss: 2.6001587876832577

Epoch: 5| Step: 1
Training loss: 3.1861772971765037
Validation loss: 2.604687770430086

Epoch: 5| Step: 2
Training loss: 2.603997451370797
Validation loss: 2.6105145947792416

Epoch: 5| Step: 3
Training loss: 2.477362277979093
Validation loss: 2.6085873493859677

Epoch: 5| Step: 4
Training loss: 2.036564257534522
Validation loss: 2.621320159984204

Epoch: 5| Step: 5
Training loss: 3.055703542959633
Validation loss: 2.642834872585381

Epoch: 5| Step: 6
Training loss: 1.9788560790920706
Validation loss: 2.6400442400401647

Epoch: 5| Step: 7
Training loss: 3.0855558135196204
Validation loss: 2.6288540025913205

Epoch: 5| Step: 8
Training loss: 3.4061840645944215
Validation loss: 2.638409307244163

Epoch: 5| Step: 9
Training loss: 2.8165847785226905
Validation loss: 2.625454260277767

Epoch: 5| Step: 10
Training loss: 3.0423950124538726
Validation loss: 2.6144799313070095

Epoch: 501| Step: 0
Training loss: 2.9495464622871967
Validation loss: 2.6058756094354463

Epoch: 5| Step: 1
Training loss: 3.0790360549941767
Validation loss: 2.598365400567772

Epoch: 5| Step: 2
Training loss: 3.150968759917585
Validation loss: 2.599551196602327

Epoch: 5| Step: 3
Training loss: 3.0176506552266362
Validation loss: 2.5972998915669696

Epoch: 5| Step: 4
Training loss: 2.843748826246753
Validation loss: 2.600746965821069

Epoch: 5| Step: 5
Training loss: 2.6285951608865954
Validation loss: 2.5973791240615105

Epoch: 5| Step: 6
Training loss: 2.204370025118651
Validation loss: 2.6128133925852293

Epoch: 5| Step: 7
Training loss: 3.064195124874665
Validation loss: 2.606560968797369

Epoch: 5| Step: 8
Training loss: 2.627466677700316
Validation loss: 2.6134046545079106

Epoch: 5| Step: 9
Training loss: 2.6494632861200946
Validation loss: 2.6127641280466554

Epoch: 5| Step: 10
Training loss: 2.7908928685991876
Validation loss: 2.6441376587795427

Epoch: 502| Step: 0
Training loss: 2.899810876927708
Validation loss: 2.6165933198082576

Epoch: 5| Step: 1
Training loss: 2.5962159717223394
Validation loss: 2.6230233148420443

Epoch: 5| Step: 2
Training loss: 2.9602557280621724
Validation loss: 2.6055532656575293

Epoch: 5| Step: 3
Training loss: 3.612262710117006
Validation loss: 2.616536189219306

Epoch: 5| Step: 4
Training loss: 2.428352013461339
Validation loss: 2.602123747483641

Epoch: 5| Step: 5
Training loss: 3.004640169609021
Validation loss: 2.5988882936041144

Epoch: 5| Step: 6
Training loss: 3.1668044277810203
Validation loss: 2.601572815391988

Epoch: 5| Step: 7
Training loss: 2.8691469404074468
Validation loss: 2.599827600928823

Epoch: 5| Step: 8
Training loss: 2.5147695093730196
Validation loss: 2.623916980723183

Epoch: 5| Step: 9
Training loss: 2.6161891570400293
Validation loss: 2.606668323227513

Epoch: 5| Step: 10
Training loss: 2.124561825623631
Validation loss: 2.617071436593746

Epoch: 503| Step: 0
Training loss: 3.0619637156005455
Validation loss: 2.627735724227523

Epoch: 5| Step: 1
Training loss: 2.602503975637076
Validation loss: 2.6100566509854746

Epoch: 5| Step: 2
Training loss: 2.7063298273096335
Validation loss: 2.597281895779058

Epoch: 5| Step: 3
Training loss: 2.505613509713458
Validation loss: 2.6094176841753605

Epoch: 5| Step: 4
Training loss: 3.0458757375817322
Validation loss: 2.6162048601163073

Epoch: 5| Step: 5
Training loss: 3.0087665580544294
Validation loss: 2.618005633076549

Epoch: 5| Step: 6
Training loss: 2.8962843472844146
Validation loss: 2.6119583798597845

Epoch: 5| Step: 7
Training loss: 2.5756381901359546
Validation loss: 2.619748485428431

Epoch: 5| Step: 8
Training loss: 3.2638486566611613
Validation loss: 2.6208269688843484

Epoch: 5| Step: 9
Training loss: 2.7224149884419186
Validation loss: 2.6326032095095444

Epoch: 5| Step: 10
Training loss: 2.6066302637288454
Validation loss: 2.6211381075306326

Epoch: 504| Step: 0
Training loss: 2.9062278500605014
Validation loss: 2.612103850010679

Epoch: 5| Step: 1
Training loss: 2.8481022991709706
Validation loss: 2.6182321142738356

Epoch: 5| Step: 2
Training loss: 2.7953956996760465
Validation loss: 2.616744277296396

Epoch: 5| Step: 3
Training loss: 2.4794209347223206
Validation loss: 2.6129032955944456

Epoch: 5| Step: 4
Training loss: 2.7733581531618356
Validation loss: 2.600362627947073

Epoch: 5| Step: 5
Training loss: 3.0539848124308193
Validation loss: 2.5892616743475823

Epoch: 5| Step: 6
Training loss: 3.1658966399796094
Validation loss: 2.607685081510799

Epoch: 5| Step: 7
Training loss: 2.646137240119753
Validation loss: 2.594947239144241

Epoch: 5| Step: 8
Training loss: 2.8685126711342948
Validation loss: 2.5899002647367846

Epoch: 5| Step: 9
Training loss: 2.6833985547813226
Validation loss: 2.61432175324027

Epoch: 5| Step: 10
Training loss: 2.7638741678669096
Validation loss: 2.6087473266134404

Epoch: 505| Step: 0
Training loss: 3.1014724064961205
Validation loss: 2.6266820599780725

Epoch: 5| Step: 1
Training loss: 2.7797894017977636
Validation loss: 2.6254607146441704

Epoch: 5| Step: 2
Training loss: 2.545993675847376
Validation loss: 2.621216433632021

Epoch: 5| Step: 3
Training loss: 2.349004628020592
Validation loss: 2.6242338801931013

Epoch: 5| Step: 4
Training loss: 2.521761405494714
Validation loss: 2.6354695586020505

Epoch: 5| Step: 5
Training loss: 2.2431451433817973
Validation loss: 2.641447945429503

Epoch: 5| Step: 6
Training loss: 3.5044565438487902
Validation loss: 2.657143331503756

Epoch: 5| Step: 7
Training loss: 3.110961202763953
Validation loss: 2.627648819510524

Epoch: 5| Step: 8
Training loss: 2.7846592784774753
Validation loss: 2.619709560053832

Epoch: 5| Step: 9
Training loss: 3.321107154447631
Validation loss: 2.606847993379686

Epoch: 5| Step: 10
Training loss: 2.4524858942122
Validation loss: 2.5876191376777427

Epoch: 506| Step: 0
Training loss: 2.5019517908978686
Validation loss: 2.581107051273606

Epoch: 5| Step: 1
Training loss: 2.489485947580971
Validation loss: 2.580636482134447

Epoch: 5| Step: 2
Training loss: 3.295089889249588
Validation loss: 2.585783167636218

Epoch: 5| Step: 3
Training loss: 2.889485232432806
Validation loss: 2.5869936160568403

Epoch: 5| Step: 4
Training loss: 2.5475117642146925
Validation loss: 2.596845325480935

Epoch: 5| Step: 5
Training loss: 3.3223531757460174
Validation loss: 2.6017772306697786

Epoch: 5| Step: 6
Training loss: 2.576915850448549
Validation loss: 2.623203545743009

Epoch: 5| Step: 7
Training loss: 2.0950529684503905
Validation loss: 2.63749472104312

Epoch: 5| Step: 8
Training loss: 3.29771289754191
Validation loss: 2.638882255078109

Epoch: 5| Step: 9
Training loss: 2.9135216423240324
Validation loss: 2.5998931212422276

Epoch: 5| Step: 10
Training loss: 2.9716025050053223
Validation loss: 2.5981816992386886

Epoch: 507| Step: 0
Training loss: 2.688700829078035
Validation loss: 2.5845868611824034

Epoch: 5| Step: 1
Training loss: 3.23060410203335
Validation loss: 2.577761405496027

Epoch: 5| Step: 2
Training loss: 2.878430848743978
Validation loss: 2.5817814865444775

Epoch: 5| Step: 3
Training loss: 2.673958128059913
Validation loss: 2.5749387241380006

Epoch: 5| Step: 4
Training loss: 2.798779313486393
Validation loss: 2.5721660719983857

Epoch: 5| Step: 5
Training loss: 2.279939667087505
Validation loss: 2.572687169119563

Epoch: 5| Step: 6
Training loss: 2.625305339674964
Validation loss: 2.572912335667214

Epoch: 5| Step: 7
Training loss: 3.475908745150577
Validation loss: 2.582013463531876

Epoch: 5| Step: 8
Training loss: 3.0338950660579194
Validation loss: 2.5781085657992437

Epoch: 5| Step: 9
Training loss: 2.8609249729317665
Validation loss: 2.582964456667624

Epoch: 5| Step: 10
Training loss: 2.2769993935551964
Validation loss: 2.588235328209269

Epoch: 508| Step: 0
Training loss: 2.8067588701604933
Validation loss: 2.599616775162552

Epoch: 5| Step: 1
Training loss: 2.4506372362651985
Validation loss: 2.6079658258307754

Epoch: 5| Step: 2
Training loss: 2.69074195669649
Validation loss: 2.619531032384289

Epoch: 5| Step: 3
Training loss: 2.8293147666794156
Validation loss: 2.6379324091374787

Epoch: 5| Step: 4
Training loss: 3.054169828058526
Validation loss: 2.6185577914504496

Epoch: 5| Step: 5
Training loss: 2.809950032859002
Validation loss: 2.6423748616576535

Epoch: 5| Step: 6
Training loss: 2.6871361597087353
Validation loss: 2.6424693761961446

Epoch: 5| Step: 7
Training loss: 2.815205523101037
Validation loss: 2.6427873307737597

Epoch: 5| Step: 8
Training loss: 3.0629477660146254
Validation loss: 2.626445656381096

Epoch: 5| Step: 9
Training loss: 2.980709361192137
Validation loss: 2.6220997279047507

Epoch: 5| Step: 10
Training loss: 2.697178645185181
Validation loss: 2.63825930079889

Epoch: 509| Step: 0
Training loss: 2.794486619071983
Validation loss: 2.6161043979971983

Epoch: 5| Step: 1
Training loss: 2.2136465130078924
Validation loss: 2.615842314032108

Epoch: 5| Step: 2
Training loss: 2.608433079462726
Validation loss: 2.5956733966291883

Epoch: 5| Step: 3
Training loss: 3.3496318671803147
Validation loss: 2.5904887641313943

Epoch: 5| Step: 4
Training loss: 2.5429595618953633
Validation loss: 2.5818086630935526

Epoch: 5| Step: 5
Training loss: 2.934225489308368
Validation loss: 2.5874523294583565

Epoch: 5| Step: 6
Training loss: 3.0474111232049093
Validation loss: 2.5894949622525107

Epoch: 5| Step: 7
Training loss: 2.736733079198142
Validation loss: 2.587964606130225

Epoch: 5| Step: 8
Training loss: 2.8993569943756428
Validation loss: 2.5812643934525576

Epoch: 5| Step: 9
Training loss: 3.0818138674426807
Validation loss: 2.5952942263323817

Epoch: 5| Step: 10
Training loss: 2.729739636172784
Validation loss: 2.6058174892833366

Epoch: 510| Step: 0
Training loss: 2.789097804425759
Validation loss: 2.6403339786526447

Epoch: 5| Step: 1
Training loss: 2.4976799690234803
Validation loss: 2.613996153410867

Epoch: 5| Step: 2
Training loss: 3.12981638726315
Validation loss: 2.635022788425493

Epoch: 5| Step: 3
Training loss: 2.9020654229138376
Validation loss: 2.6231538635634783

Epoch: 5| Step: 4
Training loss: 2.5180785730114974
Validation loss: 2.624041903494039

Epoch: 5| Step: 5
Training loss: 2.7178376519542833
Validation loss: 2.6056992862275203

Epoch: 5| Step: 6
Training loss: 3.147281709089936
Validation loss: 2.5944114906048226

Epoch: 5| Step: 7
Training loss: 2.418000401303595
Validation loss: 2.6032695260230545

Epoch: 5| Step: 8
Training loss: 3.067959492909624
Validation loss: 2.5875117468868227

Epoch: 5| Step: 9
Training loss: 3.0768033206082666
Validation loss: 2.586458895225481

Epoch: 5| Step: 10
Training loss: 2.591032788032774
Validation loss: 2.58713245308874

Epoch: 511| Step: 0
Training loss: 3.147082924816082
Validation loss: 2.596583685927752

Epoch: 5| Step: 1
Training loss: 2.9001791931563456
Validation loss: 2.597073605596164

Epoch: 5| Step: 2
Training loss: 2.611034938927671
Validation loss: 2.5913088485006046

Epoch: 5| Step: 3
Training loss: 3.170445312605882
Validation loss: 2.605317018152058

Epoch: 5| Step: 4
Training loss: 2.70322325423174
Validation loss: 2.605421814367619

Epoch: 5| Step: 5
Training loss: 2.5968049224689342
Validation loss: 2.6149006672113626

Epoch: 5| Step: 6
Training loss: 3.035457404672089
Validation loss: 2.613371116313991

Epoch: 5| Step: 7
Training loss: 3.0905186896173307
Validation loss: 2.599201017864626

Epoch: 5| Step: 8
Training loss: 2.1929138763813945
Validation loss: 2.6005734602821176

Epoch: 5| Step: 9
Training loss: 2.804349661113883
Validation loss: 2.597858837961081

Epoch: 5| Step: 10
Training loss: 2.5751642045191634
Validation loss: 2.593232616342874

Epoch: 512| Step: 0
Training loss: 2.7747945554823112
Validation loss: 2.594992553376533

Epoch: 5| Step: 1
Training loss: 2.6805229997606985
Validation loss: 2.5974086374837335

Epoch: 5| Step: 2
Training loss: 2.755569107482086
Validation loss: 2.5867103804893956

Epoch: 5| Step: 3
Training loss: 2.5382904287391272
Validation loss: 2.603639089651857

Epoch: 5| Step: 4
Training loss: 2.804869239465628
Validation loss: 2.6027785515181505

Epoch: 5| Step: 5
Training loss: 2.6089900298156548
Validation loss: 2.589772845735931

Epoch: 5| Step: 6
Training loss: 2.606440007078246
Validation loss: 2.6001358917258135

Epoch: 5| Step: 7
Training loss: 2.956564378857759
Validation loss: 2.6002705038913327

Epoch: 5| Step: 8
Training loss: 3.243327700958641
Validation loss: 2.591218762178685

Epoch: 5| Step: 9
Training loss: 3.2024446090446315
Validation loss: 2.58623310993551

Epoch: 5| Step: 10
Training loss: 2.7007340457709508
Validation loss: 2.589354207896794

Epoch: 513| Step: 0
Training loss: 2.6204633110926614
Validation loss: 2.601947947411569

Epoch: 5| Step: 1
Training loss: 3.02232399477732
Validation loss: 2.591699734050082

Epoch: 5| Step: 2
Training loss: 2.6299986702223053
Validation loss: 2.6072656226779145

Epoch: 5| Step: 3
Training loss: 3.0920430107727723
Validation loss: 2.619235344673813

Epoch: 5| Step: 4
Training loss: 2.825997242412585
Validation loss: 2.6203892006669305

Epoch: 5| Step: 5
Training loss: 2.9074691348352317
Validation loss: 2.62740589330697

Epoch: 5| Step: 6
Training loss: 3.0700444305882826
Validation loss: 2.615863622062559

Epoch: 5| Step: 7
Training loss: 2.7145783438725752
Validation loss: 2.6292978058014955

Epoch: 5| Step: 8
Training loss: 2.859417357417655
Validation loss: 2.623491076216044

Epoch: 5| Step: 9
Training loss: 2.3921675349224016
Validation loss: 2.638835506694452

Epoch: 5| Step: 10
Training loss: 2.777279452023611
Validation loss: 2.632092873870391

Epoch: 514| Step: 0
Training loss: 2.5378447913830637
Validation loss: 2.6187096273928536

Epoch: 5| Step: 1
Training loss: 2.629109843789192
Validation loss: 2.589587510235209

Epoch: 5| Step: 2
Training loss: 3.341305846587081
Validation loss: 2.5865768853129727

Epoch: 5| Step: 3
Training loss: 2.587429019857413
Validation loss: 2.580853963103391

Epoch: 5| Step: 4
Training loss: 2.7999303740972703
Validation loss: 2.575821366347428

Epoch: 5| Step: 5
Training loss: 2.195040757272271
Validation loss: 2.572510534340449

Epoch: 5| Step: 6
Training loss: 2.5532192478970606
Validation loss: 2.580996171315294

Epoch: 5| Step: 7
Training loss: 2.953741584472033
Validation loss: 2.5837511174011887

Epoch: 5| Step: 8
Training loss: 2.8239876004884303
Validation loss: 2.5840011101438445

Epoch: 5| Step: 9
Training loss: 3.004006888857891
Validation loss: 2.5995214530665938

Epoch: 5| Step: 10
Training loss: 3.382745261988748
Validation loss: 2.5953955117479035

Epoch: 515| Step: 0
Training loss: 2.7944618768908773
Validation loss: 2.598355751250565

Epoch: 5| Step: 1
Training loss: 2.9831121678838626
Validation loss: 2.5897851779986034

Epoch: 5| Step: 2
Training loss: 2.9858530588551586
Validation loss: 2.58793386561372

Epoch: 5| Step: 3
Training loss: 2.9575362586848444
Validation loss: 2.5793165658318076

Epoch: 5| Step: 4
Training loss: 2.3216425618903234
Validation loss: 2.586490326273694

Epoch: 5| Step: 5
Training loss: 2.543552782816226
Validation loss: 2.590649729344632

Epoch: 5| Step: 6
Training loss: 3.0062778273343382
Validation loss: 2.582854414763062

Epoch: 5| Step: 7
Training loss: 2.6807156472723404
Validation loss: 2.5789776269407754

Epoch: 5| Step: 8
Training loss: 2.873717478086505
Validation loss: 2.5979000396897733

Epoch: 5| Step: 9
Training loss: 2.858252466538879
Validation loss: 2.593807628518697

Epoch: 5| Step: 10
Training loss: 2.942407769351511
Validation loss: 2.6043875369677467

Epoch: 516| Step: 0
Training loss: 2.90638027104287
Validation loss: 2.6178711376807033

Epoch: 5| Step: 1
Training loss: 3.0979870382669485
Validation loss: 2.639662528680542

Epoch: 5| Step: 2
Training loss: 3.232258422038055
Validation loss: 2.65335585686287

Epoch: 5| Step: 3
Training loss: 2.786725686815685
Validation loss: 2.652202666664534

Epoch: 5| Step: 4
Training loss: 2.9525378415543715
Validation loss: 2.653780916558354

Epoch: 5| Step: 5
Training loss: 2.966740781594061
Validation loss: 2.673477863609678

Epoch: 5| Step: 6
Training loss: 2.3339263525737657
Validation loss: 2.6284290619268025

Epoch: 5| Step: 7
Training loss: 2.4983856711102246
Validation loss: 2.613338541505618

Epoch: 5| Step: 8
Training loss: 1.9276022822334693
Validation loss: 2.591165937886884

Epoch: 5| Step: 9
Training loss: 2.952025516637501
Validation loss: 2.5914999429822414

Epoch: 5| Step: 10
Training loss: 3.1881772985994186
Validation loss: 2.580776853687768

Epoch: 517| Step: 0
Training loss: 2.9138258768918788
Validation loss: 2.565951211504267

Epoch: 5| Step: 1
Training loss: 2.990993171758073
Validation loss: 2.57257573891099

Epoch: 5| Step: 2
Training loss: 3.169544134003346
Validation loss: 2.5736490882511345

Epoch: 5| Step: 3
Training loss: 2.717087072673959
Validation loss: 2.5685810324260063

Epoch: 5| Step: 4
Training loss: 2.7574537870627798
Validation loss: 2.565968943461361

Epoch: 5| Step: 5
Training loss: 2.4504147275897443
Validation loss: 2.568063946754798

Epoch: 5| Step: 6
Training loss: 2.5469731036991337
Validation loss: 2.574121781279209

Epoch: 5| Step: 7
Training loss: 3.2465573196744333
Validation loss: 2.597894556952877

Epoch: 5| Step: 8
Training loss: 2.3796131104872966
Validation loss: 2.6021255903199454

Epoch: 5| Step: 9
Training loss: 3.0084229481488687
Validation loss: 2.6096697095551766

Epoch: 5| Step: 10
Training loss: 2.5396980311899537
Validation loss: 2.627404571191516

Epoch: 518| Step: 0
Training loss: 2.6130153822973488
Validation loss: 2.643643469443424

Epoch: 5| Step: 1
Training loss: 2.9688001126527057
Validation loss: 2.632862602646414

Epoch: 5| Step: 2
Training loss: 2.968785817783519
Validation loss: 2.6257785759748526

Epoch: 5| Step: 3
Training loss: 2.0156996365708424
Validation loss: 2.610345860389219

Epoch: 5| Step: 4
Training loss: 2.7763819578397118
Validation loss: 2.602050630508504

Epoch: 5| Step: 5
Training loss: 2.6443650885125516
Validation loss: 2.5837846997445024

Epoch: 5| Step: 6
Training loss: 2.709507193854821
Validation loss: 2.5910350844943646

Epoch: 5| Step: 7
Training loss: 2.8468724808749832
Validation loss: 2.590403845053311

Epoch: 5| Step: 8
Training loss: 3.467099458626167
Validation loss: 2.5891686830169167

Epoch: 5| Step: 9
Training loss: 2.587605840020246
Validation loss: 2.601218516196955

Epoch: 5| Step: 10
Training loss: 3.172850660780112
Validation loss: 2.5945776251427817

Epoch: 519| Step: 0
Training loss: 2.8009898854202095
Validation loss: 2.6133820335147138

Epoch: 5| Step: 1
Training loss: 2.7647658053338815
Validation loss: 2.6075621456539535

Epoch: 5| Step: 2
Training loss: 2.4199059141801125
Validation loss: 2.599751573957136

Epoch: 5| Step: 3
Training loss: 2.8441517305098385
Validation loss: 2.6032125865638576

Epoch: 5| Step: 4
Training loss: 3.0293385879723997
Validation loss: 2.6097716895200596

Epoch: 5| Step: 5
Training loss: 3.1565108994021283
Validation loss: 2.6038885621911225

Epoch: 5| Step: 6
Training loss: 2.773963384066224
Validation loss: 2.6186823296247788

Epoch: 5| Step: 7
Training loss: 2.6418038169163838
Validation loss: 2.630673869254948

Epoch: 5| Step: 8
Training loss: 3.2736074908781436
Validation loss: 2.640134663573282

Epoch: 5| Step: 9
Training loss: 2.3047071553054868
Validation loss: 2.6251544306341876

Epoch: 5| Step: 10
Training loss: 2.6899560750331797
Validation loss: 2.6205403131971763

Epoch: 520| Step: 0
Training loss: 2.7287469982876873
Validation loss: 2.6024771334095202

Epoch: 5| Step: 1
Training loss: 2.8230537766007635
Validation loss: 2.5837854002401914

Epoch: 5| Step: 2
Training loss: 2.9042108416561234
Validation loss: 2.575459914248726

Epoch: 5| Step: 3
Training loss: 2.5182240015007835
Validation loss: 2.583744800942872

Epoch: 5| Step: 4
Training loss: 2.4326489422355353
Validation loss: 2.5819398043663804

Epoch: 5| Step: 5
Training loss: 2.8016107626319915
Validation loss: 2.5718717837684566

Epoch: 5| Step: 6
Training loss: 3.223147748978189
Validation loss: 2.5708980003774795

Epoch: 5| Step: 7
Training loss: 2.9126956792102296
Validation loss: 2.575726696408607

Epoch: 5| Step: 8
Training loss: 2.939921902508072
Validation loss: 2.579168860751152

Epoch: 5| Step: 9
Training loss: 3.079285223867578
Validation loss: 2.58464342639232

Epoch: 5| Step: 10
Training loss: 2.256654647088922
Validation loss: 2.5937251339256795

Epoch: 521| Step: 0
Training loss: 2.725250103173544
Validation loss: 2.5939680685606663

Epoch: 5| Step: 1
Training loss: 2.8486376668517948
Validation loss: 2.5944595710541383

Epoch: 5| Step: 2
Training loss: 3.0349501217006742
Validation loss: 2.5987019439643335

Epoch: 5| Step: 3
Training loss: 2.1050285487832765
Validation loss: 2.6063455030585505

Epoch: 5| Step: 4
Training loss: 3.129672105573253
Validation loss: 2.605956998293984

Epoch: 5| Step: 5
Training loss: 3.2134526187341117
Validation loss: 2.616009976551171

Epoch: 5| Step: 6
Training loss: 2.447461825921553
Validation loss: 2.6080901296123957

Epoch: 5| Step: 7
Training loss: 3.1427447249383667
Validation loss: 2.6228362256407047

Epoch: 5| Step: 8
Training loss: 2.914215329332713
Validation loss: 2.609343626499234

Epoch: 5| Step: 9
Training loss: 2.6385900116256567
Validation loss: 2.6084563940004273

Epoch: 5| Step: 10
Training loss: 2.116356605688225
Validation loss: 2.5953635119183414

Epoch: 522| Step: 0
Training loss: 2.6537217618182862
Validation loss: 2.5864038495806545

Epoch: 5| Step: 1
Training loss: 2.6160870871965693
Validation loss: 2.5947488600299624

Epoch: 5| Step: 2
Training loss: 2.4582583421379196
Validation loss: 2.58518168615827

Epoch: 5| Step: 3
Training loss: 2.790765920671369
Validation loss: 2.5682095833364187

Epoch: 5| Step: 4
Training loss: 2.497344514056322
Validation loss: 2.5818590505124432

Epoch: 5| Step: 5
Training loss: 3.2275579731859008
Validation loss: 2.577330432111885

Epoch: 5| Step: 6
Training loss: 2.5952972025825223
Validation loss: 2.582706415703188

Epoch: 5| Step: 7
Training loss: 3.2943397645435617
Validation loss: 2.583182596128402

Epoch: 5| Step: 8
Training loss: 3.0487441369657615
Validation loss: 2.583241279131608

Epoch: 5| Step: 9
Training loss: 2.8722464602456306
Validation loss: 2.5906554045475643

Epoch: 5| Step: 10
Training loss: 2.6094029590684937
Validation loss: 2.59609107964265

Epoch: 523| Step: 0
Training loss: 2.501588984009118
Validation loss: 2.6119829251298285

Epoch: 5| Step: 1
Training loss: 2.996355863442823
Validation loss: 2.6010601358460517

Epoch: 5| Step: 2
Training loss: 3.08596515884559
Validation loss: 2.600210263905907

Epoch: 5| Step: 3
Training loss: 3.0090074419694672
Validation loss: 2.591570582364671

Epoch: 5| Step: 4
Training loss: 2.72852846987738
Validation loss: 2.5921577867334458

Epoch: 5| Step: 5
Training loss: 2.76169414590238
Validation loss: 2.5898487489010784

Epoch: 5| Step: 6
Training loss: 2.2991866332133464
Validation loss: 2.5907902178859756

Epoch: 5| Step: 7
Training loss: 3.0482900610248
Validation loss: 2.607691443206248

Epoch: 5| Step: 8
Training loss: 2.7860804411481626
Validation loss: 2.5919252261179557

Epoch: 5| Step: 9
Training loss: 2.5884831279273297
Validation loss: 2.603715139970953

Epoch: 5| Step: 10
Training loss: 2.853473514191328
Validation loss: 2.6145558241602336

Epoch: 524| Step: 0
Training loss: 2.173149777639518
Validation loss: 2.632352854887173

Epoch: 5| Step: 1
Training loss: 2.8337743827265545
Validation loss: 2.653261814184161

Epoch: 5| Step: 2
Training loss: 2.394297453028571
Validation loss: 2.6588884321519766

Epoch: 5| Step: 3
Training loss: 3.161591193451759
Validation loss: 2.6441846944516683

Epoch: 5| Step: 4
Training loss: 3.1769840079035037
Validation loss: 2.6250190968558633

Epoch: 5| Step: 5
Training loss: 2.506087901516903
Validation loss: 2.6067215055728727

Epoch: 5| Step: 6
Training loss: 3.040100704834007
Validation loss: 2.5835176730271594

Epoch: 5| Step: 7
Training loss: 2.948021409473291
Validation loss: 2.580067822039571

Epoch: 5| Step: 8
Training loss: 2.6688107771731344
Validation loss: 2.5684066894744686

Epoch: 5| Step: 9
Training loss: 2.414648978586498
Validation loss: 2.5585189055657267

Epoch: 5| Step: 10
Training loss: 3.4710071540040035
Validation loss: 2.5719106267599794

Epoch: 525| Step: 0
Training loss: 2.812908227751824
Validation loss: 2.574549413289696

Epoch: 5| Step: 1
Training loss: 2.5839329813187923
Validation loss: 2.565719894551383

Epoch: 5| Step: 2
Training loss: 2.5711043509186844
Validation loss: 2.571257772161391

Epoch: 5| Step: 3
Training loss: 2.9015270947919
Validation loss: 2.578994798156396

Epoch: 5| Step: 4
Training loss: 2.805348947888905
Validation loss: 2.589916911171631

Epoch: 5| Step: 5
Training loss: 2.28683999134091
Validation loss: 2.6005705551332

Epoch: 5| Step: 6
Training loss: 2.9075344077753336
Validation loss: 2.6271903806792456

Epoch: 5| Step: 7
Training loss: 2.892813683911679
Validation loss: 2.6524738782032715

Epoch: 5| Step: 8
Training loss: 3.194006468745437
Validation loss: 2.6574626386496925

Epoch: 5| Step: 9
Training loss: 3.1915631296546976
Validation loss: 2.6354453809066305

Epoch: 5| Step: 10
Training loss: 2.744826913181448
Validation loss: 2.608749359838488

Epoch: 526| Step: 0
Training loss: 2.6611409654404925
Validation loss: 2.597657478696767

Epoch: 5| Step: 1
Training loss: 2.893908146600703
Validation loss: 2.5733259324837623

Epoch: 5| Step: 2
Training loss: 2.929491204361376
Validation loss: 2.567322927215824

Epoch: 5| Step: 3
Training loss: 3.049122143093953
Validation loss: 2.563886011007438

Epoch: 5| Step: 4
Training loss: 2.374947296360899
Validation loss: 2.569271270346872

Epoch: 5| Step: 5
Training loss: 3.3258558964344287
Validation loss: 2.559472519367452

Epoch: 5| Step: 6
Training loss: 2.6845331893690974
Validation loss: 2.5625450906655605

Epoch: 5| Step: 7
Training loss: 2.722846616988551
Validation loss: 2.5661032319828783

Epoch: 5| Step: 8
Training loss: 2.8198596030653293
Validation loss: 2.5680081913490005

Epoch: 5| Step: 9
Training loss: 2.4053805873730427
Validation loss: 2.569887101802841

Epoch: 5| Step: 10
Training loss: 2.8589153649957852
Validation loss: 2.581059006160977

Epoch: 527| Step: 0
Training loss: 2.8450641320480474
Validation loss: 2.5895977495812694

Epoch: 5| Step: 1
Training loss: 2.8789223161971136
Validation loss: 2.5904932679603827

Epoch: 5| Step: 2
Training loss: 2.8838712407335185
Validation loss: 2.618102681220267

Epoch: 5| Step: 3
Training loss: 2.8088482355476874
Validation loss: 2.604437083981048

Epoch: 5| Step: 4
Training loss: 2.8099296692704496
Validation loss: 2.6162341111929197

Epoch: 5| Step: 5
Training loss: 2.7900247062765056
Validation loss: 2.6248118435197023

Epoch: 5| Step: 6
Training loss: 2.536331163125779
Validation loss: 2.607529588236375

Epoch: 5| Step: 7
Training loss: 2.6085725566943347
Validation loss: 2.598839051168567

Epoch: 5| Step: 8
Training loss: 2.9087293980044673
Validation loss: 2.583341716259214

Epoch: 5| Step: 9
Training loss: 2.6937828256682526
Validation loss: 2.5832228380588713

Epoch: 5| Step: 10
Training loss: 2.95568542896237
Validation loss: 2.5695751578944686

Epoch: 528| Step: 0
Training loss: 2.695501967695279
Validation loss: 2.571160948517182

Epoch: 5| Step: 1
Training loss: 2.422431930987146
Validation loss: 2.5784110041458996

Epoch: 5| Step: 2
Training loss: 2.680154209255166
Validation loss: 2.5691394654474213

Epoch: 5| Step: 3
Training loss: 2.540567931863337
Validation loss: 2.5688405831065326

Epoch: 5| Step: 4
Training loss: 2.723858823593679
Validation loss: 2.5693311710844853

Epoch: 5| Step: 5
Training loss: 2.8005796649909707
Validation loss: 2.57230031904227

Epoch: 5| Step: 6
Training loss: 3.194994026859055
Validation loss: 2.585548340120169

Epoch: 5| Step: 7
Training loss: 2.7273114331706636
Validation loss: 2.592247909649696

Epoch: 5| Step: 8
Training loss: 3.0611008542583837
Validation loss: 2.5797782501915845

Epoch: 5| Step: 9
Training loss: 3.008855148525693
Validation loss: 2.5860796834388653

Epoch: 5| Step: 10
Training loss: 2.771824327283091
Validation loss: 2.5938689185708603

Epoch: 529| Step: 0
Training loss: 2.814824309481768
Validation loss: 2.590833785622764

Epoch: 5| Step: 1
Training loss: 2.4604516897096396
Validation loss: 2.5897724972877785

Epoch: 5| Step: 2
Training loss: 2.922827254378121
Validation loss: 2.615503253667141

Epoch: 5| Step: 3
Training loss: 2.668741630880558
Validation loss: 2.606720166573822

Epoch: 5| Step: 4
Training loss: 2.861193802841218
Validation loss: 2.5985433993769482

Epoch: 5| Step: 5
Training loss: 2.524995116427392
Validation loss: 2.609088035279519

Epoch: 5| Step: 6
Training loss: 3.1598093339884676
Validation loss: 2.597316843935222

Epoch: 5| Step: 7
Training loss: 2.914487587858331
Validation loss: 2.5936666594606548

Epoch: 5| Step: 8
Training loss: 2.8469590745187863
Validation loss: 2.5945006360601965

Epoch: 5| Step: 9
Training loss: 2.8329482284323566
Validation loss: 2.5852449517867053

Epoch: 5| Step: 10
Training loss: 2.54579841935295
Validation loss: 2.5732983206510895

Epoch: 530| Step: 0
Training loss: 2.913520987669947
Validation loss: 2.570427400397302

Epoch: 5| Step: 1
Training loss: 3.119350820396842
Validation loss: 2.5674681275450113

Epoch: 5| Step: 2
Training loss: 2.93290741024588
Validation loss: 2.5659776245624544

Epoch: 5| Step: 3
Training loss: 2.8055223162940837
Validation loss: 2.5735631433394275

Epoch: 5| Step: 4
Training loss: 2.869327089860687
Validation loss: 2.5726093884109384

Epoch: 5| Step: 5
Training loss: 2.5840055965091344
Validation loss: 2.5754865781800267

Epoch: 5| Step: 6
Training loss: 2.7634505004646033
Validation loss: 2.5718092497852725

Epoch: 5| Step: 7
Training loss: 2.9401569119574473
Validation loss: 2.5695544058489883

Epoch: 5| Step: 8
Training loss: 3.0108372131654892
Validation loss: 2.5814951149743277

Epoch: 5| Step: 9
Training loss: 2.458034777427084
Validation loss: 2.5899021820963606

Epoch: 5| Step: 10
Training loss: 2.1070979508424803
Validation loss: 2.586623511734066

Epoch: 531| Step: 0
Training loss: 2.8543946298116794
Validation loss: 2.5953878624851043

Epoch: 5| Step: 1
Training loss: 3.1284779840139456
Validation loss: 2.6044763202944363

Epoch: 5| Step: 2
Training loss: 3.0121750145835557
Validation loss: 2.627664349710275

Epoch: 5| Step: 3
Training loss: 2.8998457374321345
Validation loss: 2.6033524143903684

Epoch: 5| Step: 4
Training loss: 2.585027159911568
Validation loss: 2.6324814733522492

Epoch: 5| Step: 5
Training loss: 2.5908949431804253
Validation loss: 2.641014293234576

Epoch: 5| Step: 6
Training loss: 2.8034935750382526
Validation loss: 2.6034511008004926

Epoch: 5| Step: 7
Training loss: 2.604661899525511
Validation loss: 2.5971400847655515

Epoch: 5| Step: 8
Training loss: 3.345641839868504
Validation loss: 2.580526630053422

Epoch: 5| Step: 9
Training loss: 2.0718962747393532
Validation loss: 2.593364626161079

Epoch: 5| Step: 10
Training loss: 2.4684206585974215
Validation loss: 2.584736480352942

Epoch: 532| Step: 0
Training loss: 2.3935562812367195
Validation loss: 2.568939909713735

Epoch: 5| Step: 1
Training loss: 2.902129338637607
Validation loss: 2.567228339332416

Epoch: 5| Step: 2
Training loss: 2.953080111369321
Validation loss: 2.556813796996625

Epoch: 5| Step: 3
Training loss: 2.9888261285816027
Validation loss: 2.554279117256438

Epoch: 5| Step: 4
Training loss: 2.6779305172681687
Validation loss: 2.5592698884102427

Epoch: 5| Step: 5
Training loss: 2.6189668442709197
Validation loss: 2.560000196990139

Epoch: 5| Step: 6
Training loss: 2.4826378657080284
Validation loss: 2.5629604105064

Epoch: 5| Step: 7
Training loss: 3.09811955916108
Validation loss: 2.5546131402310897

Epoch: 5| Step: 8
Training loss: 2.668260147914641
Validation loss: 2.574223771276252

Epoch: 5| Step: 9
Training loss: 3.0934457340317794
Validation loss: 2.597380819745107

Epoch: 5| Step: 10
Training loss: 2.6921208599785125
Validation loss: 2.5945894622697407

Epoch: 533| Step: 0
Training loss: 2.8402101052162427
Validation loss: 2.607607146286761

Epoch: 5| Step: 1
Training loss: 2.9180364026419467
Validation loss: 2.6029175162416207

Epoch: 5| Step: 2
Training loss: 2.5209272908337055
Validation loss: 2.615516374694323

Epoch: 5| Step: 3
Training loss: 3.107820515265085
Validation loss: 2.633152396420523

Epoch: 5| Step: 4
Training loss: 2.794635494123237
Validation loss: 2.6102253451418576

Epoch: 5| Step: 5
Training loss: 2.1994832559075275
Validation loss: 2.6045692267242684

Epoch: 5| Step: 6
Training loss: 2.8677585459307395
Validation loss: 2.6179299724324983

Epoch: 5| Step: 7
Training loss: 2.522705538856806
Validation loss: 2.583295794745845

Epoch: 5| Step: 8
Training loss: 3.192855225876708
Validation loss: 2.5789059815584645

Epoch: 5| Step: 9
Training loss: 2.5023248353184315
Validation loss: 2.5763365010117303

Epoch: 5| Step: 10
Training loss: 3.082074569958546
Validation loss: 2.5589823335313313

Epoch: 534| Step: 0
Training loss: 2.9945221799040826
Validation loss: 2.5616054279011555

Epoch: 5| Step: 1
Training loss: 2.884445265619794
Validation loss: 2.56519863432978

Epoch: 5| Step: 2
Training loss: 2.750770634265319
Validation loss: 2.5635882322147494

Epoch: 5| Step: 3
Training loss: 2.764014685838828
Validation loss: 2.5839332085203814

Epoch: 5| Step: 4
Training loss: 2.9022850965115583
Validation loss: 2.5731261703913897

Epoch: 5| Step: 5
Training loss: 2.5789571632830253
Validation loss: 2.5835000188470247

Epoch: 5| Step: 6
Training loss: 2.659179777158693
Validation loss: 2.5953058379361647

Epoch: 5| Step: 7
Training loss: 2.963348132061846
Validation loss: 2.6052211321505587

Epoch: 5| Step: 8
Training loss: 2.9475552142976063
Validation loss: 2.6138236921273537

Epoch: 5| Step: 9
Training loss: 3.0591502651632907
Validation loss: 2.6232865626082145

Epoch: 5| Step: 10
Training loss: 2.022322417433108
Validation loss: 2.6119584544538847

Epoch: 535| Step: 0
Training loss: 2.4803424472642246
Validation loss: 2.608087160097393

Epoch: 5| Step: 1
Training loss: 3.3566578366852595
Validation loss: 2.581549086521276

Epoch: 5| Step: 2
Training loss: 2.844456343907394
Validation loss: 2.5729157632686097

Epoch: 5| Step: 3
Training loss: 2.8304720249730915
Validation loss: 2.5687530741114184

Epoch: 5| Step: 4
Training loss: 2.625988274686832
Validation loss: 2.555206425751557

Epoch: 5| Step: 5
Training loss: 2.7130479320730907
Validation loss: 2.550938698939001

Epoch: 5| Step: 6
Training loss: 2.4827327458588084
Validation loss: 2.5547254863803825

Epoch: 5| Step: 7
Training loss: 2.274938133991509
Validation loss: 2.577642765232365

Epoch: 5| Step: 8
Training loss: 3.1648838813777957
Validation loss: 2.577508001743478

Epoch: 5| Step: 9
Training loss: 2.8250359794553566
Validation loss: 2.6039734402414103

Epoch: 5| Step: 10
Training loss: 2.877927036497761
Validation loss: 2.5976846411355763

Epoch: 536| Step: 0
Training loss: 2.3152022167564277
Validation loss: 2.6106348757241684

Epoch: 5| Step: 1
Training loss: 2.7442747687408517
Validation loss: 2.6075785004044256

Epoch: 5| Step: 2
Training loss: 3.015142688822531
Validation loss: 2.603582499951546

Epoch: 5| Step: 3
Training loss: 3.1818251114311558
Validation loss: 2.5920727878260985

Epoch: 5| Step: 4
Training loss: 2.4789677922171265
Validation loss: 2.588818094115125

Epoch: 5| Step: 5
Training loss: 2.9787383049444376
Validation loss: 2.5905804483149395

Epoch: 5| Step: 6
Training loss: 3.2427029487196717
Validation loss: 2.5821375244236178

Epoch: 5| Step: 7
Training loss: 2.277440796971398
Validation loss: 2.5861347508530694

Epoch: 5| Step: 8
Training loss: 2.4990381297804722
Validation loss: 2.5728948787427464

Epoch: 5| Step: 9
Training loss: 2.8902402879551623
Validation loss: 2.5730627054277897

Epoch: 5| Step: 10
Training loss: 2.793890954201854
Validation loss: 2.566485918816644

Epoch: 537| Step: 0
Training loss: 2.937651934651237
Validation loss: 2.562989895160174

Epoch: 5| Step: 1
Training loss: 2.557680575651109
Validation loss: 2.56893143621521

Epoch: 5| Step: 2
Training loss: 2.737221070454047
Validation loss: 2.5733090143437654

Epoch: 5| Step: 3
Training loss: 2.6804350319111694
Validation loss: 2.5792520853009338

Epoch: 5| Step: 4
Training loss: 3.6798305605151933
Validation loss: 2.5985876031818007

Epoch: 5| Step: 5
Training loss: 2.971439628921098
Validation loss: 2.587642299929598

Epoch: 5| Step: 6
Training loss: 2.469070606901559
Validation loss: 2.607167952846422

Epoch: 5| Step: 7
Training loss: 2.0535154299475606
Validation loss: 2.5951837312477637

Epoch: 5| Step: 8
Training loss: 2.7622502313303583
Validation loss: 2.605354655023777

Epoch: 5| Step: 9
Training loss: 2.6218495309749814
Validation loss: 2.5987401787657625

Epoch: 5| Step: 10
Training loss: 2.7418682205954625
Validation loss: 2.6141809391544517

Epoch: 538| Step: 0
Training loss: 2.7877393303325646
Validation loss: 2.637319151877504

Epoch: 5| Step: 1
Training loss: 2.7528843058958996
Validation loss: 2.617055566309394

Epoch: 5| Step: 2
Training loss: 2.9419805566390287
Validation loss: 2.6069206350545735

Epoch: 5| Step: 3
Training loss: 3.121964468070157
Validation loss: 2.6108658287090205

Epoch: 5| Step: 4
Training loss: 2.289781268805422
Validation loss: 2.583699762738532

Epoch: 5| Step: 5
Training loss: 2.472452983968466
Validation loss: 2.5666757231340678

Epoch: 5| Step: 6
Training loss: 2.8587107069136524
Validation loss: 2.56404716451769

Epoch: 5| Step: 7
Training loss: 3.0296614112143887
Validation loss: 2.5701155470038777

Epoch: 5| Step: 8
Training loss: 2.4804821104155446
Validation loss: 2.560758382518909

Epoch: 5| Step: 9
Training loss: 2.6658265658125058
Validation loss: 2.5657383245373646

Epoch: 5| Step: 10
Training loss: 3.138497006494961
Validation loss: 2.5690810061719507

Epoch: 539| Step: 0
Training loss: 3.031672497436665
Validation loss: 2.5722757150337183

Epoch: 5| Step: 1
Training loss: 3.2259256320902465
Validation loss: 2.589157042899664

Epoch: 5| Step: 2
Training loss: 2.7337412944527757
Validation loss: 2.5929229036336623

Epoch: 5| Step: 3
Training loss: 2.428527456975409
Validation loss: 2.6121393074754593

Epoch: 5| Step: 4
Training loss: 2.404107762699932
Validation loss: 2.640780882224824

Epoch: 5| Step: 5
Training loss: 2.5753501987278637
Validation loss: 2.6484076424175047

Epoch: 5| Step: 6
Training loss: 2.9272423064117494
Validation loss: 2.6591840316048088

Epoch: 5| Step: 7
Training loss: 2.7912310549840065
Validation loss: 2.6349172240912684

Epoch: 5| Step: 8
Training loss: 3.000442631174806
Validation loss: 2.6268122873042308

Epoch: 5| Step: 9
Training loss: 2.7438724916266017
Validation loss: 2.596068847953938

Epoch: 5| Step: 10
Training loss: 2.6198381807863362
Validation loss: 2.589593691664861

Epoch: 540| Step: 0
Training loss: 2.5915672585740257
Validation loss: 2.579371655383031

Epoch: 5| Step: 1
Training loss: 2.6454274224127596
Validation loss: 2.5747122870570176

Epoch: 5| Step: 2
Training loss: 2.4169116937354045
Validation loss: 2.568040825543923

Epoch: 5| Step: 3
Training loss: 3.2629234419179043
Validation loss: 2.577121339137835

Epoch: 5| Step: 4
Training loss: 2.8921140392501523
Validation loss: 2.579353967856273

Epoch: 5| Step: 5
Training loss: 2.583243173646154
Validation loss: 2.575156150708406

Epoch: 5| Step: 6
Training loss: 2.547449620490896
Validation loss: 2.592455634266761

Epoch: 5| Step: 7
Training loss: 3.1207820655540166
Validation loss: 2.590580931240113

Epoch: 5| Step: 8
Training loss: 2.732688078275344
Validation loss: 2.592577490719461

Epoch: 5| Step: 9
Training loss: 2.795681746836708
Validation loss: 2.5987062086355475

Epoch: 5| Step: 10
Training loss: 2.8973383297386337
Validation loss: 2.584580284905439

Epoch: 541| Step: 0
Training loss: 2.5656114622030737
Validation loss: 2.6052949754000947

Epoch: 5| Step: 1
Training loss: 2.533323592451676
Validation loss: 2.595641194789825

Epoch: 5| Step: 2
Training loss: 2.519968299514957
Validation loss: 2.5784630984760786

Epoch: 5| Step: 3
Training loss: 2.829283756160908
Validation loss: 2.5737939496195916

Epoch: 5| Step: 4
Training loss: 2.5689645496623488
Validation loss: 2.580740236189672

Epoch: 5| Step: 5
Training loss: 3.0177990286254737
Validation loss: 2.5941874064477686

Epoch: 5| Step: 6
Training loss: 2.871506600312743
Validation loss: 2.5898436737790576

Epoch: 5| Step: 7
Training loss: 2.875336668785467
Validation loss: 2.5996093996540948

Epoch: 5| Step: 8
Training loss: 2.7924909276311176
Validation loss: 2.5859708893836095

Epoch: 5| Step: 9
Training loss: 2.911108078926714
Validation loss: 2.5782086619515527

Epoch: 5| Step: 10
Training loss: 2.942503381304228
Validation loss: 2.590877521334531

Epoch: 542| Step: 0
Training loss: 2.434439278024546
Validation loss: 2.593392115292475

Epoch: 5| Step: 1
Training loss: 2.7029836981560873
Validation loss: 2.585124571429894

Epoch: 5| Step: 2
Training loss: 2.656292634509637
Validation loss: 2.5838303903190547

Epoch: 5| Step: 3
Training loss: 3.3649915008664317
Validation loss: 2.5744904773956754

Epoch: 5| Step: 4
Training loss: 2.910546357294696
Validation loss: 2.559877122266455

Epoch: 5| Step: 5
Training loss: 2.6098414934924277
Validation loss: 2.567765087487317

Epoch: 5| Step: 6
Training loss: 2.588227609250701
Validation loss: 2.571646653714358

Epoch: 5| Step: 7
Training loss: 2.8211727785182603
Validation loss: 2.56492487808298

Epoch: 5| Step: 8
Training loss: 3.139138244656865
Validation loss: 2.5679532503607025

Epoch: 5| Step: 9
Training loss: 2.8128054135117497
Validation loss: 2.5736892332108936

Epoch: 5| Step: 10
Training loss: 2.1205532446115147
Validation loss: 2.5816173259230215

Epoch: 543| Step: 0
Training loss: 2.800892422011273
Validation loss: 2.582307580811813

Epoch: 5| Step: 1
Training loss: 2.8632106381982108
Validation loss: 2.5864615248188456

Epoch: 5| Step: 2
Training loss: 2.792004313380891
Validation loss: 2.6104018988501476

Epoch: 5| Step: 3
Training loss: 2.773184149547416
Validation loss: 2.5879031504883026

Epoch: 5| Step: 4
Training loss: 2.5364370064488306
Validation loss: 2.5787140383100846

Epoch: 5| Step: 5
Training loss: 2.6032407004482345
Validation loss: 2.5797196315144832

Epoch: 5| Step: 6
Training loss: 2.5334977895494797
Validation loss: 2.592789274482152

Epoch: 5| Step: 7
Training loss: 2.939208163069518
Validation loss: 2.5846770343367806

Epoch: 5| Step: 8
Training loss: 2.3376134263532315
Validation loss: 2.5879958673315384

Epoch: 5| Step: 9
Training loss: 2.8247627800111252
Validation loss: 2.584266490751133

Epoch: 5| Step: 10
Training loss: 3.404125846204049
Validation loss: 2.5970204216276818

Epoch: 544| Step: 0
Training loss: 2.685185611354555
Validation loss: 2.581033362267298

Epoch: 5| Step: 1
Training loss: 2.9849079714698963
Validation loss: 2.586437619506516

Epoch: 5| Step: 2
Training loss: 2.151445537149967
Validation loss: 2.57922932778325

Epoch: 5| Step: 3
Training loss: 3.0425602022858467
Validation loss: 2.5880882143483617

Epoch: 5| Step: 4
Training loss: 2.820733374473196
Validation loss: 2.5945372727813587

Epoch: 5| Step: 5
Training loss: 2.8560434746732466
Validation loss: 2.598865992131478

Epoch: 5| Step: 6
Training loss: 2.9917887529062948
Validation loss: 2.591425479106264

Epoch: 5| Step: 7
Training loss: 2.4638265454436348
Validation loss: 2.592193284620091

Epoch: 5| Step: 8
Training loss: 2.8546189741022685
Validation loss: 2.5767191793202366

Epoch: 5| Step: 9
Training loss: 2.800715872667926
Validation loss: 2.5875353410829938

Epoch: 5| Step: 10
Training loss: 2.5853454280837265
Validation loss: 2.572029159647125

Epoch: 545| Step: 0
Training loss: 2.388651113973556
Validation loss: 2.5646336704226083

Epoch: 5| Step: 1
Training loss: 3.147185651793594
Validation loss: 2.568611097311614

Epoch: 5| Step: 2
Training loss: 2.79791385388227
Validation loss: 2.567655315241609

Epoch: 5| Step: 3
Training loss: 3.031899136911353
Validation loss: 2.554036584137966

Epoch: 5| Step: 4
Training loss: 2.6067314233890846
Validation loss: 2.5582004154916707

Epoch: 5| Step: 5
Training loss: 2.607837886698163
Validation loss: 2.5690959194806404

Epoch: 5| Step: 6
Training loss: 2.3858457176676753
Validation loss: 2.577852845206901

Epoch: 5| Step: 7
Training loss: 2.884402614473717
Validation loss: 2.577324271004687

Epoch: 5| Step: 8
Training loss: 3.025872090633461
Validation loss: 2.5801524434097804

Epoch: 5| Step: 9
Training loss: 2.533659835739306
Validation loss: 2.5897302594808798

Epoch: 5| Step: 10
Training loss: 2.909637773654472
Validation loss: 2.601777572583464

Epoch: 546| Step: 0
Training loss: 3.0625426620314524
Validation loss: 2.587047341096207

Epoch: 5| Step: 1
Training loss: 2.850841357872077
Validation loss: 2.6030551498971253

Epoch: 5| Step: 2
Training loss: 2.893501129324195
Validation loss: 2.624763389232912

Epoch: 5| Step: 3
Training loss: 2.825725739017932
Validation loss: 2.6253643124900585

Epoch: 5| Step: 4
Training loss: 2.570029292403543
Validation loss: 2.6033103250253045

Epoch: 5| Step: 5
Training loss: 2.6152793190977968
Validation loss: 2.5823706994415203

Epoch: 5| Step: 6
Training loss: 2.737621538085755
Validation loss: 2.557813627523043

Epoch: 5| Step: 7
Training loss: 2.5936710391607303
Validation loss: 2.5622317626206494

Epoch: 5| Step: 8
Training loss: 2.76176873449175
Validation loss: 2.5514172091309084

Epoch: 5| Step: 9
Training loss: 2.6365666550461917
Validation loss: 2.554400468516651

Epoch: 5| Step: 10
Training loss: 2.8176919275018917
Validation loss: 2.5532598129761532

Epoch: 547| Step: 0
Training loss: 2.54606999505881
Validation loss: 2.550499459031478

Epoch: 5| Step: 1
Training loss: 2.8654610323821514
Validation loss: 2.555974262396346

Epoch: 5| Step: 2
Training loss: 3.081064128105584
Validation loss: 2.5640925739147353

Epoch: 5| Step: 3
Training loss: 2.619169754219076
Validation loss: 2.565185692162442

Epoch: 5| Step: 4
Training loss: 2.5364479101281496
Validation loss: 2.584862319749432

Epoch: 5| Step: 5
Training loss: 2.4814235982053665
Validation loss: 2.593703262495118

Epoch: 5| Step: 6
Training loss: 2.952416067456614
Validation loss: 2.5905866145105496

Epoch: 5| Step: 7
Training loss: 2.7414566326756935
Validation loss: 2.6006464270554166

Epoch: 5| Step: 8
Training loss: 2.9348980357250127
Validation loss: 2.6025270201911144

Epoch: 5| Step: 9
Training loss: 2.4970869258466704
Validation loss: 2.620635027280535

Epoch: 5| Step: 10
Training loss: 3.1175240165317644
Validation loss: 2.611746676164979

Epoch: 548| Step: 0
Training loss: 3.2367256210515714
Validation loss: 2.6145865566140807

Epoch: 5| Step: 1
Training loss: 3.4483407826724988
Validation loss: 2.579079559104706

Epoch: 5| Step: 2
Training loss: 2.549356573870133
Validation loss: 2.5644343398847047

Epoch: 5| Step: 3
Training loss: 2.2986065831544757
Validation loss: 2.540749522745547

Epoch: 5| Step: 4
Training loss: 2.68354115441545
Validation loss: 2.549194509760751

Epoch: 5| Step: 5
Training loss: 2.7251504559059154
Validation loss: 2.544804496256461

Epoch: 5| Step: 6
Training loss: 2.5875144368381693
Validation loss: 2.5416019827527894

Epoch: 5| Step: 7
Training loss: 2.774613080243109
Validation loss: 2.5385794413091087

Epoch: 5| Step: 8
Training loss: 2.8598395632046403
Validation loss: 2.5458695443764263

Epoch: 5| Step: 9
Training loss: 2.580179586444173
Validation loss: 2.5470379424287564

Epoch: 5| Step: 10
Training loss: 2.779561934226977
Validation loss: 2.5535559786176267

Epoch: 549| Step: 0
Training loss: 2.443248718829704
Validation loss: 2.5518214687651404

Epoch: 5| Step: 1
Training loss: 2.1993980537890887
Validation loss: 2.5508158749471255

Epoch: 5| Step: 2
Training loss: 3.0428958830231827
Validation loss: 2.56176778064796

Epoch: 5| Step: 3
Training loss: 2.7730374759655034
Validation loss: 2.5695459563263046

Epoch: 5| Step: 4
Training loss: 3.371948558157052
Validation loss: 2.5608197667972012

Epoch: 5| Step: 5
Training loss: 2.424848048375143
Validation loss: 2.567084328824035

Epoch: 5| Step: 6
Training loss: 2.2074008868422457
Validation loss: 2.5596069944779836

Epoch: 5| Step: 7
Training loss: 3.33189915957589
Validation loss: 2.5682787900613167

Epoch: 5| Step: 8
Training loss: 2.4494689132234653
Validation loss: 2.570962512439727

Epoch: 5| Step: 9
Training loss: 2.9190042846480964
Validation loss: 2.5657027743796554

Epoch: 5| Step: 10
Training loss: 2.9604208301691197
Validation loss: 2.592746361049465

Epoch: 550| Step: 0
Training loss: 2.8632910755608187
Validation loss: 2.5889937985050233

Epoch: 5| Step: 1
Training loss: 2.7724076199082437
Validation loss: 2.6029604747257777

Epoch: 5| Step: 2
Training loss: 2.628387989579752
Validation loss: 2.626320279836462

Epoch: 5| Step: 3
Training loss: 2.2169218456652002
Validation loss: 2.6783198565366293

Epoch: 5| Step: 4
Training loss: 2.754468408657909
Validation loss: 2.696863862633274

Epoch: 5| Step: 5
Training loss: 2.9007315798122577
Validation loss: 2.681657471527814

Epoch: 5| Step: 6
Training loss: 2.9339366971437335
Validation loss: 2.65079696676388

Epoch: 5| Step: 7
Training loss: 3.2129925836310704
Validation loss: 2.611748630491806

Epoch: 5| Step: 8
Training loss: 2.482062937360435
Validation loss: 2.5740730928737348

Epoch: 5| Step: 9
Training loss: 3.2741736264898
Validation loss: 2.5458091792159836

Epoch: 5| Step: 10
Training loss: 2.262257460771682
Validation loss: 2.5447032513687415

Testing loss: 2.733038313381419
