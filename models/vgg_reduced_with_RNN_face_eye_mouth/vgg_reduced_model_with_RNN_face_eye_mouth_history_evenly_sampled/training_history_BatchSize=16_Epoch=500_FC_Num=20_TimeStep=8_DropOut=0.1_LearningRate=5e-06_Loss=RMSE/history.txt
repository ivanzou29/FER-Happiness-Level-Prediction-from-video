Epoch: 1| Step: 0
Training loss: 4.721514365804063
Validation loss: 5.736924188616615

Epoch: 6| Step: 1
Training loss: 4.559207093753306
Validation loss: 5.7328954661567835

Epoch: 6| Step: 2
Training loss: 5.701722189417244
Validation loss: 5.728732513653583

Epoch: 6| Step: 3
Training loss: 6.182560345779022
Validation loss: 5.724378695916642

Epoch: 6| Step: 4
Training loss: 6.863889837665905
Validation loss: 5.720281304371578

Epoch: 6| Step: 5
Training loss: 6.34309571749079
Validation loss: 5.715494270161573

Epoch: 6| Step: 6
Training loss: 6.027296598871793
Validation loss: 5.711175767631972

Epoch: 6| Step: 7
Training loss: 7.356506695802081
Validation loss: 5.706613155566839

Epoch: 6| Step: 8
Training loss: 5.928438680872992
Validation loss: 5.701813581396119

Epoch: 6| Step: 9
Training loss: 4.109150811523678
Validation loss: 5.697210385509544

Epoch: 6| Step: 10
Training loss: 5.5014207912180195
Validation loss: 5.692294876573782

Epoch: 6| Step: 11
Training loss: 4.2880566916774825
Validation loss: 5.687490974174801

Epoch: 6| Step: 12
Training loss: 5.988931619322262
Validation loss: 5.682432426624469

Epoch: 6| Step: 13
Training loss: 5.937127995130845
Validation loss: 5.677472359667621

Epoch: 2| Step: 0
Training loss: 5.540035533584501
Validation loss: 5.672013683833277

Epoch: 6| Step: 1
Training loss: 6.1318750527548795
Validation loss: 5.666073908678596

Epoch: 6| Step: 2
Training loss: 6.269444241023968
Validation loss: 5.660219943935451

Epoch: 6| Step: 3
Training loss: 4.28120388925043
Validation loss: 5.654075932190912

Epoch: 6| Step: 4
Training loss: 5.496633366255849
Validation loss: 5.647530560539361

Epoch: 6| Step: 5
Training loss: 5.683103769687058
Validation loss: 5.641135361203393

Epoch: 6| Step: 6
Training loss: 4.893062094014727
Validation loss: 5.634523784055378

Epoch: 6| Step: 7
Training loss: 5.391304658806833
Validation loss: 5.627441687558669

Epoch: 6| Step: 8
Training loss: 6.120653751336535
Validation loss: 5.619474599953742

Epoch: 6| Step: 9
Training loss: 6.097540512794956
Validation loss: 5.61216053300024

Epoch: 6| Step: 10
Training loss: 5.557635291027666
Validation loss: 5.603802775703451

Epoch: 6| Step: 11
Training loss: 6.053570965599302
Validation loss: 5.595496622633424

Epoch: 6| Step: 12
Training loss: 6.126721510006933
Validation loss: 5.586632175392438

Epoch: 6| Step: 13
Training loss: 5.098148623251937
Validation loss: 5.577220442300149

Epoch: 3| Step: 0
Training loss: 6.90527613060777
Validation loss: 5.567178445336518

Epoch: 6| Step: 1
Training loss: 4.800105395749424
Validation loss: 5.557197007271873

Epoch: 6| Step: 2
Training loss: 4.886162132318245
Validation loss: 5.5471912922994635

Epoch: 6| Step: 3
Training loss: 5.2800065783257395
Validation loss: 5.5371900573536665

Epoch: 6| Step: 4
Training loss: 5.770552682306725
Validation loss: 5.525334149729009

Epoch: 6| Step: 5
Training loss: 5.372752762249785
Validation loss: 5.514106021453954

Epoch: 6| Step: 6
Training loss: 5.3149925218961975
Validation loss: 5.502742150873719

Epoch: 6| Step: 7
Training loss: 5.909093101874525
Validation loss: 5.490575526043056

Epoch: 6| Step: 8
Training loss: 5.3832440694646
Validation loss: 5.478173666774726

Epoch: 6| Step: 9
Training loss: 5.068941139540194
Validation loss: 5.465889917235141

Epoch: 6| Step: 10
Training loss: 4.741335545639821
Validation loss: 5.453055331056057

Epoch: 6| Step: 11
Training loss: 7.085145546462033
Validation loss: 5.440057017741145

Epoch: 6| Step: 12
Training loss: 5.2537151089185175
Validation loss: 5.426138684429329

Epoch: 6| Step: 13
Training loss: 4.8944242789961665
Validation loss: 5.4116280450047265

Epoch: 4| Step: 0
Training loss: 5.164930400545632
Validation loss: 5.3979522134116555

Epoch: 6| Step: 1
Training loss: 4.183860221803642
Validation loss: 5.383318678318045

Epoch: 6| Step: 2
Training loss: 5.691997719888237
Validation loss: 5.368783246473327

Epoch: 6| Step: 3
Training loss: 5.314239037802432
Validation loss: 5.353773189830789

Epoch: 6| Step: 4
Training loss: 4.551869588877782
Validation loss: 5.338844602460055

Epoch: 6| Step: 5
Training loss: 5.4006507410796365
Validation loss: 5.322671401740749

Epoch: 6| Step: 6
Training loss: 5.610987524469811
Validation loss: 5.308194205255405

Epoch: 6| Step: 7
Training loss: 5.2300862064878935
Validation loss: 5.290644807266473

Epoch: 6| Step: 8
Training loss: 5.6918418995070805
Validation loss: 5.273864519763503

Epoch: 6| Step: 9
Training loss: 4.054015234340354
Validation loss: 5.256350637942537

Epoch: 6| Step: 10
Training loss: 6.172783507104874
Validation loss: 5.23879257488448

Epoch: 6| Step: 11
Training loss: 5.63049421075744
Validation loss: 5.220313843149243

Epoch: 6| Step: 12
Training loss: 6.1296232252716045
Validation loss: 5.201561783105917

Epoch: 6| Step: 13
Training loss: 5.593417877055431
Validation loss: 5.182534723821814

Epoch: 5| Step: 0
Training loss: 4.5231912443763775
Validation loss: 5.162333138160386

Epoch: 6| Step: 1
Training loss: 4.116773320308124
Validation loss: 5.140977633147322

Epoch: 6| Step: 2
Training loss: 4.910846864966606
Validation loss: 5.120333996852494

Epoch: 6| Step: 3
Training loss: 4.61380051057338
Validation loss: 5.09908975226978

Epoch: 6| Step: 4
Training loss: 5.5749234113008335
Validation loss: 5.075331709285065

Epoch: 6| Step: 5
Training loss: 5.734367349811825
Validation loss: 5.053085636044926

Epoch: 6| Step: 6
Training loss: 5.342712837088919
Validation loss: 5.028918940593452

Epoch: 6| Step: 7
Training loss: 5.027075890057214
Validation loss: 5.004498773334559

Epoch: 6| Step: 8
Training loss: 4.44906377480589
Validation loss: 4.980937531471052

Epoch: 6| Step: 9
Training loss: 4.926705064292701
Validation loss: 4.9562447087773895

Epoch: 6| Step: 10
Training loss: 5.741466326418068
Validation loss: 4.9313190756219605

Epoch: 6| Step: 11
Training loss: 5.32013216987432
Validation loss: 4.907292218949381

Epoch: 6| Step: 12
Training loss: 4.863785192891221
Validation loss: 4.882317315700565

Epoch: 6| Step: 13
Training loss: 5.903768028023369
Validation loss: 4.860583606622151

Epoch: 6| Step: 0
Training loss: 4.310570326595698
Validation loss: 4.8352383892781265

Epoch: 6| Step: 1
Training loss: 4.466859217426776
Validation loss: 4.810261161263025

Epoch: 6| Step: 2
Training loss: 5.460464915509105
Validation loss: 4.78850681219499

Epoch: 6| Step: 3
Training loss: 4.043394971117224
Validation loss: 4.766696395683789

Epoch: 6| Step: 4
Training loss: 4.72652396194258
Validation loss: 4.746044995086071

Epoch: 6| Step: 5
Training loss: 5.245512724944874
Validation loss: 4.721934067300694

Epoch: 6| Step: 6
Training loss: 5.935778237716898
Validation loss: 4.7007214304303115

Epoch: 6| Step: 7
Training loss: 4.689099255182297
Validation loss: 4.6795231885507995

Epoch: 6| Step: 8
Training loss: 4.543684111777269
Validation loss: 4.658911234740343

Epoch: 6| Step: 9
Training loss: 4.039872993890117
Validation loss: 4.639826981957669

Epoch: 6| Step: 10
Training loss: 4.580710244225532
Validation loss: 4.622968097107086

Epoch: 6| Step: 11
Training loss: 4.380276359305052
Validation loss: 4.607935673747089

Epoch: 6| Step: 12
Training loss: 5.435216139046304
Validation loss: 4.593897716900465

Epoch: 6| Step: 13
Training loss: 4.57412075911799
Validation loss: 4.579938318396332

Epoch: 7| Step: 0
Training loss: 4.605157092601096
Validation loss: 4.565898591987542

Epoch: 6| Step: 1
Training loss: 4.635860990452877
Validation loss: 4.553522363999699

Epoch: 6| Step: 2
Training loss: 4.998530362629881
Validation loss: 4.540543673174691

Epoch: 6| Step: 3
Training loss: 4.588632237048941
Validation loss: 4.527719894449538

Epoch: 6| Step: 4
Training loss: 4.737638953594317
Validation loss: 4.515097853207378

Epoch: 6| Step: 5
Training loss: 5.652571520009133
Validation loss: 4.501454052328874

Epoch: 6| Step: 6
Training loss: 3.457058284675365
Validation loss: 4.488201292473425

Epoch: 6| Step: 7
Training loss: 5.517242453838112
Validation loss: 4.475720745264933

Epoch: 6| Step: 8
Training loss: 4.436731191309704
Validation loss: 4.461971036728124

Epoch: 6| Step: 9
Training loss: 4.652810894040101
Validation loss: 4.449378363805457

Epoch: 6| Step: 10
Training loss: 4.038632751859784
Validation loss: 4.433586034080966

Epoch: 6| Step: 11
Training loss: 4.107381474926137
Validation loss: 4.422721862575812

Epoch: 6| Step: 12
Training loss: 4.0785865960925936
Validation loss: 4.410071839228388

Epoch: 6| Step: 13
Training loss: 4.024830993516025
Validation loss: 4.398396378392699

Epoch: 8| Step: 0
Training loss: 4.638017634783896
Validation loss: 4.386953325749403

Epoch: 6| Step: 1
Training loss: 4.46499796389953
Validation loss: 4.3748209669101845

Epoch: 6| Step: 2
Training loss: 5.375931769937146
Validation loss: 4.362261101383287

Epoch: 6| Step: 3
Training loss: 3.527654387017408
Validation loss: 4.351606587988791

Epoch: 6| Step: 4
Training loss: 4.956227579342711
Validation loss: 4.339479711828056

Epoch: 6| Step: 5
Training loss: 4.234610350427332
Validation loss: 4.329891826423998

Epoch: 6| Step: 6
Training loss: 3.929455244052876
Validation loss: 4.320763352641502

Epoch: 6| Step: 7
Training loss: 4.775815380841253
Validation loss: 4.309213897147797

Epoch: 6| Step: 8
Training loss: 5.005963202749324
Validation loss: 4.298368387101343

Epoch: 6| Step: 9
Training loss: 4.369149792541791
Validation loss: 4.287297026752766

Epoch: 6| Step: 10
Training loss: 3.6908004990339744
Validation loss: 4.274663280061079

Epoch: 6| Step: 11
Training loss: 5.227442645903534
Validation loss: 4.267546127866563

Epoch: 6| Step: 12
Training loss: 3.636833607040984
Validation loss: 4.255607985149068

Epoch: 6| Step: 13
Training loss: 3.066756735045713
Validation loss: 4.243798875494795

Epoch: 9| Step: 0
Training loss: 4.739690132474895
Validation loss: 4.234996784966055

Epoch: 6| Step: 1
Training loss: 4.285454905698962
Validation loss: 4.224871958888056

Epoch: 6| Step: 2
Training loss: 4.269853333717105
Validation loss: 4.2176830575707385

Epoch: 6| Step: 3
Training loss: 4.4714972314477315
Validation loss: 4.20989538147184

Epoch: 6| Step: 4
Training loss: 4.713637456043538
Validation loss: 4.204620433202428

Epoch: 6| Step: 5
Training loss: 4.017406261516049
Validation loss: 4.1933233218855515

Epoch: 6| Step: 6
Training loss: 4.69457859898478
Validation loss: 4.187385330993309

Epoch: 6| Step: 7
Training loss: 4.715050061507251
Validation loss: 4.176509362450864

Epoch: 6| Step: 8
Training loss: 4.926440250078921
Validation loss: 4.172106758044435

Epoch: 6| Step: 9
Training loss: 3.6554087135584687
Validation loss: 4.161491252941404

Epoch: 6| Step: 10
Training loss: 4.135675891403405
Validation loss: 4.154996110555889

Epoch: 6| Step: 11
Training loss: 3.9066059408144356
Validation loss: 4.150401968181052

Epoch: 6| Step: 12
Training loss: 3.558479315616834
Validation loss: 4.1417969803236305

Epoch: 6| Step: 13
Training loss: 3.8797307823615177
Validation loss: 4.134587561116237

Epoch: 10| Step: 0
Training loss: 3.5939901520472612
Validation loss: 4.126458388459608

Epoch: 6| Step: 1
Training loss: 2.630503199198521
Validation loss: 4.11893375557031

Epoch: 6| Step: 2
Training loss: 5.103559725220866
Validation loss: 4.115625776786543

Epoch: 6| Step: 3
Training loss: 4.222382966266603
Validation loss: 4.109368037808979

Epoch: 6| Step: 4
Training loss: 3.729501137394341
Validation loss: 4.1026218410046456

Epoch: 6| Step: 5
Training loss: 3.2609850760746877
Validation loss: 4.095305567387149

Epoch: 6| Step: 6
Training loss: 4.992134965551535
Validation loss: 4.089607806532649

Epoch: 6| Step: 7
Training loss: 4.383886848186787
Validation loss: 4.087359614221079

Epoch: 6| Step: 8
Training loss: 4.280774166645598
Validation loss: 4.080627733320077

Epoch: 6| Step: 9
Training loss: 4.176196199930911
Validation loss: 4.0767819551201026

Epoch: 6| Step: 10
Training loss: 4.54353487746482
Validation loss: 4.0697122370222765

Epoch: 6| Step: 11
Training loss: 4.147416903426179
Validation loss: 4.064128436398459

Epoch: 6| Step: 12
Training loss: 4.384017805801207
Validation loss: 4.055336326140578

Epoch: 6| Step: 13
Training loss: 5.539354841214342
Validation loss: 4.051890911203992

Epoch: 11| Step: 0
Training loss: 4.3780180194426395
Validation loss: 4.047445605668899

Epoch: 6| Step: 1
Training loss: 3.8305983669097676
Validation loss: 4.037911410527529

Epoch: 6| Step: 2
Training loss: 4.395388154301909
Validation loss: 4.032134810912248

Epoch: 6| Step: 3
Training loss: 4.240480195330159
Validation loss: 4.024374817926105

Epoch: 6| Step: 4
Training loss: 4.888460210347366
Validation loss: 4.018213510903157

Epoch: 6| Step: 5
Training loss: 3.11304720928644
Validation loss: 4.010955387407014

Epoch: 6| Step: 6
Training loss: 4.006059110619603
Validation loss: 4.003077278269986

Epoch: 6| Step: 7
Training loss: 3.4992516943847147
Validation loss: 3.996700985031194

Epoch: 6| Step: 8
Training loss: 4.4219532882176305
Validation loss: 3.9922745328748963

Epoch: 6| Step: 9
Training loss: 4.651951591561277
Validation loss: 3.988766539733514

Epoch: 6| Step: 10
Training loss: 4.516441192254231
Validation loss: 3.979460222810555

Epoch: 6| Step: 11
Training loss: 4.353996650747081
Validation loss: 3.9731715458372037

Epoch: 6| Step: 12
Training loss: 3.752429175372471
Validation loss: 3.967296822317939

Epoch: 6| Step: 13
Training loss: 3.3557593471826332
Validation loss: 3.9617560354932175

Epoch: 12| Step: 0
Training loss: 4.773169177516379
Validation loss: 3.958788931792042

Epoch: 6| Step: 1
Training loss: 4.097662301145436
Validation loss: 3.9506085384096723

Epoch: 6| Step: 2
Training loss: 3.4919922366585796
Validation loss: 3.9448419664575183

Epoch: 6| Step: 3
Training loss: 2.6808276183881983
Validation loss: 3.940326459467003

Epoch: 6| Step: 4
Training loss: 3.6553393150872946
Validation loss: 3.93662382300946

Epoch: 6| Step: 5
Training loss: 4.323190899465654
Validation loss: 3.926814769288517

Epoch: 6| Step: 6
Training loss: 4.5972326662086465
Validation loss: 3.924163754513723

Epoch: 6| Step: 7
Training loss: 4.087843033048333
Validation loss: 3.9201245635991304

Epoch: 6| Step: 8
Training loss: 3.963018890004712
Validation loss: 3.9157720096868127

Epoch: 6| Step: 9
Training loss: 5.039262161439298
Validation loss: 3.9094080632322363

Epoch: 6| Step: 10
Training loss: 4.546362359685642
Validation loss: 3.90547216928115

Epoch: 6| Step: 11
Training loss: 3.202229742220325
Validation loss: 3.9049889938961773

Epoch: 6| Step: 12
Training loss: 3.869260659972338
Validation loss: 3.901247271662185

Epoch: 6| Step: 13
Training loss: 4.29111208002084
Validation loss: 3.902900801638098

Epoch: 13| Step: 0
Training loss: 4.159511806379112
Validation loss: 3.896421328349724

Epoch: 6| Step: 1
Training loss: 3.370679986874099
Validation loss: 3.890991196339507

Epoch: 6| Step: 2
Training loss: 4.633365797482566
Validation loss: 3.8905709794131558

Epoch: 6| Step: 3
Training loss: 4.076645856935711
Validation loss: 3.882444235376638

Epoch: 6| Step: 4
Training loss: 4.175807970637731
Validation loss: 3.8787808611721615

Epoch: 6| Step: 5
Training loss: 4.119486968310505
Validation loss: 3.873209753784748

Epoch: 6| Step: 6
Training loss: 3.585955850392182
Validation loss: 3.867744279267344

Epoch: 6| Step: 7
Training loss: 3.677700016227913
Validation loss: 3.8623456239738023

Epoch: 6| Step: 8
Training loss: 4.62927584560872
Validation loss: 3.8596452632747766

Epoch: 6| Step: 9
Training loss: 3.740309592504118
Validation loss: 3.860155512657658

Epoch: 6| Step: 10
Training loss: 3.9983732968922836
Validation loss: 3.854659669181397

Epoch: 6| Step: 11
Training loss: 4.496165655308486
Validation loss: 3.8509365635564636

Epoch: 6| Step: 12
Training loss: 3.079141981329624
Validation loss: 3.847053159000632

Epoch: 6| Step: 13
Training loss: 4.664201130555939
Validation loss: 3.8420381399831567

Epoch: 14| Step: 0
Training loss: 4.907661380766962
Validation loss: 3.8388803393621833

Epoch: 6| Step: 1
Training loss: 3.374558596533115
Validation loss: 3.836911606373582

Epoch: 6| Step: 2
Training loss: 3.0642390082144195
Validation loss: 3.8341785375663164

Epoch: 6| Step: 3
Training loss: 4.879697443853941
Validation loss: 3.8332427354319214

Epoch: 6| Step: 4
Training loss: 4.55376549315245
Validation loss: 3.8279615717666076

Epoch: 6| Step: 5
Training loss: 2.482636233123094
Validation loss: 3.821348808253834

Epoch: 6| Step: 6
Training loss: 2.9776508414161373
Validation loss: 3.8167075829400128

Epoch: 6| Step: 7
Training loss: 4.127905313795737
Validation loss: 3.8124594576149406

Epoch: 6| Step: 8
Training loss: 4.928678527205455
Validation loss: 3.80918502656277

Epoch: 6| Step: 9
Training loss: 3.9166183198149844
Validation loss: 3.8049707111275284

Epoch: 6| Step: 10
Training loss: 3.787396314353699
Validation loss: 3.80705456549324

Epoch: 6| Step: 11
Training loss: 3.6411647150991273
Validation loss: 3.8046789318085183

Epoch: 6| Step: 12
Training loss: 4.078957425220054
Validation loss: 3.7971595189308496

Epoch: 6| Step: 13
Training loss: 4.290431514636623
Validation loss: 3.792108024396005

Epoch: 15| Step: 0
Training loss: 3.580771055034345
Validation loss: 3.7873558714726823

Epoch: 6| Step: 1
Training loss: 3.2946332930641313
Validation loss: 3.7860964635328522

Epoch: 6| Step: 2
Training loss: 4.441093816311284
Validation loss: 3.7860078166877966

Epoch: 6| Step: 3
Training loss: 4.413669913058794
Validation loss: 3.7827588641083936

Epoch: 6| Step: 4
Training loss: 4.021269041709414
Validation loss: 3.7814782145891463

Epoch: 6| Step: 5
Training loss: 3.9197729792349243
Validation loss: 3.777641731465053

Epoch: 6| Step: 6
Training loss: 4.156295890841575
Validation loss: 3.7729561830659555

Epoch: 6| Step: 7
Training loss: 4.02120334853129
Validation loss: 3.76654613613114

Epoch: 6| Step: 8
Training loss: 3.726932019480907
Validation loss: 3.765956750525006

Epoch: 6| Step: 9
Training loss: 4.300824711690026
Validation loss: 3.7639499431761547

Epoch: 6| Step: 10
Training loss: 4.077582429184832
Validation loss: 3.7620356991059896

Epoch: 6| Step: 11
Training loss: 3.977597324947707
Validation loss: 3.7545828800256973

Epoch: 6| Step: 12
Training loss: 2.7735024887852275
Validation loss: 3.7516057381048222

Epoch: 6| Step: 13
Training loss: 4.44351090057571
Validation loss: 3.7581965121684044

Epoch: 16| Step: 0
Training loss: 3.78368028458691
Validation loss: 3.748592405129393

Epoch: 6| Step: 1
Training loss: 3.912384587252298
Validation loss: 3.7483777929833764

Epoch: 6| Step: 2
Training loss: 4.772455242380733
Validation loss: 3.747193523011981

Epoch: 6| Step: 3
Training loss: 4.147809399543499
Validation loss: 3.7441252738295625

Epoch: 6| Step: 4
Training loss: 3.5953576514083445
Validation loss: 3.7396062641787267

Epoch: 6| Step: 5
Training loss: 2.818633533448456
Validation loss: 3.737814355148994

Epoch: 6| Step: 6
Training loss: 3.8438032193104967
Validation loss: 3.732748870615664

Epoch: 6| Step: 7
Training loss: 4.070831675742263
Validation loss: 3.7295296875512323

Epoch: 6| Step: 8
Training loss: 3.5312216428445207
Validation loss: 3.7288942322881833

Epoch: 6| Step: 9
Training loss: 4.985058011221549
Validation loss: 3.7260367331162447

Epoch: 6| Step: 10
Training loss: 3.716084270150025
Validation loss: 3.723421607509604

Epoch: 6| Step: 11
Training loss: 3.5465316270154563
Validation loss: 3.72089088385421

Epoch: 6| Step: 12
Training loss: 4.416617675125663
Validation loss: 3.7172647351936763

Epoch: 6| Step: 13
Training loss: 2.2951887519358705
Validation loss: 3.712114962186481

Epoch: 17| Step: 0
Training loss: 3.3767917256922453
Validation loss: 3.7110367092996506

Epoch: 6| Step: 1
Training loss: 4.16578029105588
Validation loss: 3.708917578456911

Epoch: 6| Step: 2
Training loss: 4.409021250094976
Validation loss: 3.7038570905926598

Epoch: 6| Step: 3
Training loss: 3.770146484767079
Validation loss: 3.704242233675114

Epoch: 6| Step: 4
Training loss: 2.754796440233656
Validation loss: 3.704181334081019

Epoch: 6| Step: 5
Training loss: 3.963096978016754
Validation loss: 3.6989173423755775

Epoch: 6| Step: 6
Training loss: 3.6416103355770564
Validation loss: 3.6971178194007983

Epoch: 6| Step: 7
Training loss: 4.031615011560557
Validation loss: 3.7016418402817743

Epoch: 6| Step: 8
Training loss: 3.719845906829561
Validation loss: 3.695025857166134

Epoch: 6| Step: 9
Training loss: 3.200084154691394
Validation loss: 3.6902980627436865

Epoch: 6| Step: 10
Training loss: 4.0562635236376545
Validation loss: 3.690041747998794

Epoch: 6| Step: 11
Training loss: 4.286924068816913
Validation loss: 3.6858823108544536

Epoch: 6| Step: 12
Training loss: 5.11515532465646
Validation loss: 3.679047962413846

Epoch: 6| Step: 13
Training loss: 2.6612724841499786
Validation loss: 3.681125870860273

Epoch: 18| Step: 0
Training loss: 3.6730931635423465
Validation loss: 3.6756176936515566

Epoch: 6| Step: 1
Training loss: 3.0724144649161635
Validation loss: 3.674593671790188

Epoch: 6| Step: 2
Training loss: 4.358713845052992
Validation loss: 3.6743366690025763

Epoch: 6| Step: 3
Training loss: 3.4888979717981417
Validation loss: 3.671560987155292

Epoch: 6| Step: 4
Training loss: 4.687229809921381
Validation loss: 3.668116716749134

Epoch: 6| Step: 5
Training loss: 3.5827033058292863
Validation loss: 3.66498127757088

Epoch: 6| Step: 6
Training loss: 4.439706388164689
Validation loss: 3.665015660447944

Epoch: 6| Step: 7
Training loss: 3.38343153436772
Validation loss: 3.660968967259598

Epoch: 6| Step: 8
Training loss: 3.6073358233256485
Validation loss: 3.662419039326901

Epoch: 6| Step: 9
Training loss: 3.4945333568243426
Validation loss: 3.6607696320069114

Epoch: 6| Step: 10
Training loss: 3.8670908289684878
Validation loss: 3.6587453523016626

Epoch: 6| Step: 11
Training loss: 3.5454289517668194
Validation loss: 3.655547212001741

Epoch: 6| Step: 12
Training loss: 4.2776661372513765
Validation loss: 3.652620072874259

Epoch: 6| Step: 13
Training loss: 4.338561107993406
Validation loss: 3.650312428146672

Epoch: 19| Step: 0
Training loss: 3.853236579362296
Validation loss: 3.6472193760897973

Epoch: 6| Step: 1
Training loss: 4.136404283078046
Validation loss: 3.6417314627044775

Epoch: 6| Step: 2
Training loss: 3.357510781345398
Validation loss: 3.6424429946093935

Epoch: 6| Step: 3
Training loss: 3.3037361958186824
Validation loss: 3.6419088737071297

Epoch: 6| Step: 4
Training loss: 4.366631924634177
Validation loss: 3.6441035025883823

Epoch: 6| Step: 5
Training loss: 3.857932867657567
Validation loss: 3.6366443112034577

Epoch: 6| Step: 6
Training loss: 3.3183917065909476
Validation loss: 3.6342809014628528

Epoch: 6| Step: 7
Training loss: 3.4509397470746217
Validation loss: 3.630459926442001

Epoch: 6| Step: 8
Training loss: 3.462046288465682
Validation loss: 3.6279133400508514

Epoch: 6| Step: 9
Training loss: 3.226887314821159
Validation loss: 3.6271410338146883

Epoch: 6| Step: 10
Training loss: 4.137145224858836
Validation loss: 3.627831758578497

Epoch: 6| Step: 11
Training loss: 4.605890748133333
Validation loss: 3.6271568080034386

Epoch: 6| Step: 12
Training loss: 4.007131894268818
Validation loss: 3.6252094501074823

Epoch: 6| Step: 13
Training loss: 4.364706955693822
Validation loss: 3.6230108244002075

Epoch: 20| Step: 0
Training loss: 4.301823100916302
Validation loss: 3.6176631060846924

Epoch: 6| Step: 1
Training loss: 3.925115454852677
Validation loss: 3.6160933602470933

Epoch: 6| Step: 2
Training loss: 3.5397576666177173
Validation loss: 3.611109259715104

Epoch: 6| Step: 3
Training loss: 1.9478418536447724
Validation loss: 3.6094136116396323

Epoch: 6| Step: 4
Training loss: 3.362776768294885
Validation loss: 3.607451800654146

Epoch: 6| Step: 5
Training loss: 3.97294047041298
Validation loss: 3.603284227151712

Epoch: 6| Step: 6
Training loss: 5.010713162707059
Validation loss: 3.606482252327294

Epoch: 6| Step: 7
Training loss: 3.6162350679808593
Validation loss: 3.6036991373568745

Epoch: 6| Step: 8
Training loss: 3.822950953746461
Validation loss: 3.5998064238621326

Epoch: 6| Step: 9
Training loss: 3.363294860599638
Validation loss: 3.608243618181184

Epoch: 6| Step: 10
Training loss: 3.6987038790814055
Validation loss: 3.59862795397682

Epoch: 6| Step: 11
Training loss: 4.063797963474495
Validation loss: 3.5956172819795125

Epoch: 6| Step: 12
Training loss: 3.9242308330710602
Validation loss: 3.5973365681475133

Epoch: 6| Step: 13
Training loss: 4.045416727561425
Validation loss: 3.596763726107968

Epoch: 21| Step: 0
Training loss: 4.088961763930395
Validation loss: 3.592756315712418

Epoch: 6| Step: 1
Training loss: 3.675305391455108
Validation loss: 3.594677394999123

Epoch: 6| Step: 2
Training loss: 4.31317575661158
Validation loss: 3.595673458054983

Epoch: 6| Step: 3
Training loss: 4.2959635929717415
Validation loss: 3.5933721613918417

Epoch: 6| Step: 4
Training loss: 3.974497560620084
Validation loss: 3.5864979481617096

Epoch: 6| Step: 5
Training loss: 3.6376447144132067
Validation loss: 3.5785812973265854

Epoch: 6| Step: 6
Training loss: 3.3558194528966325
Validation loss: 3.58229282112209

Epoch: 6| Step: 7
Training loss: 2.7734213385312567
Validation loss: 3.5845275633586677

Epoch: 6| Step: 8
Training loss: 3.9258959093952366
Validation loss: 3.598096300723043

Epoch: 6| Step: 9
Training loss: 3.260420452924161
Validation loss: 3.5855590626342284

Epoch: 6| Step: 10
Training loss: 4.477937230967226
Validation loss: 3.5741657757252967

Epoch: 6| Step: 11
Training loss: 3.4000473243561373
Validation loss: 3.5723235203220183

Epoch: 6| Step: 12
Training loss: 4.047673327084706
Validation loss: 3.570853328377232

Epoch: 6| Step: 13
Training loss: 2.9415506882178626
Validation loss: 3.5709979635077835

Epoch: 22| Step: 0
Training loss: 3.9758351678203723
Validation loss: 3.575486515741084

Epoch: 6| Step: 1
Training loss: 3.2388911023867593
Validation loss: 3.5719445578345077

Epoch: 6| Step: 2
Training loss: 3.334575723543024
Validation loss: 3.565936485069091

Epoch: 6| Step: 3
Training loss: 4.301156425223137
Validation loss: 3.5608031703031364

Epoch: 6| Step: 4
Training loss: 3.4770992936182687
Validation loss: 3.5564676696516817

Epoch: 6| Step: 5
Training loss: 3.7733371634402118
Validation loss: 3.5580458977961613

Epoch: 6| Step: 6
Training loss: 4.222506284917984
Validation loss: 3.5630960273519885

Epoch: 6| Step: 7
Training loss: 3.761825227270313
Validation loss: 3.559058020011629

Epoch: 6| Step: 8
Training loss: 3.16180595652837
Validation loss: 3.5571293570509575

Epoch: 6| Step: 9
Training loss: 3.1966609581136267
Validation loss: 3.5502620713520607

Epoch: 6| Step: 10
Training loss: 3.9673365681764925
Validation loss: 3.5483442101166194

Epoch: 6| Step: 11
Training loss: 3.6761905065325196
Validation loss: 3.5502307407830886

Epoch: 6| Step: 12
Training loss: 4.670253714749536
Validation loss: 3.549812202622257

Epoch: 6| Step: 13
Training loss: 3.375866107717231
Validation loss: 3.5454866287639883

Epoch: 23| Step: 0
Training loss: 3.4060892889624554
Validation loss: 3.542820798288308

Epoch: 6| Step: 1
Training loss: 3.89674918821315
Validation loss: 3.5435148195640758

Epoch: 6| Step: 2
Training loss: 3.780634932502593
Validation loss: 3.5391529512390387

Epoch: 6| Step: 3
Training loss: 2.978586064740846
Validation loss: 3.5384173510698673

Epoch: 6| Step: 4
Training loss: 3.6596668938144687
Validation loss: 3.537195052140396

Epoch: 6| Step: 5
Training loss: 2.9881655602095023
Validation loss: 3.5352169793319366

Epoch: 6| Step: 6
Training loss: 3.1191027118860517
Validation loss: 3.537716918031988

Epoch: 6| Step: 7
Training loss: 4.640543002550511
Validation loss: 3.5339783250663417

Epoch: 6| Step: 8
Training loss: 4.080200135053407
Validation loss: 3.5312807265286223

Epoch: 6| Step: 9
Training loss: 3.3989243432715854
Validation loss: 3.5302698937029535

Epoch: 6| Step: 10
Training loss: 3.7049831444566665
Validation loss: 3.5302584126475174

Epoch: 6| Step: 11
Training loss: 4.681071438204112
Validation loss: 3.531652060504865

Epoch: 6| Step: 12
Training loss: 4.258747299189001
Validation loss: 3.5307762981863826

Epoch: 6| Step: 13
Training loss: 2.8239584732946805
Validation loss: 3.5274264098450216

Epoch: 24| Step: 0
Training loss: 2.605171884441668
Validation loss: 3.5272437698007013

Epoch: 6| Step: 1
Training loss: 4.386534825424073
Validation loss: 3.523398273601548

Epoch: 6| Step: 2
Training loss: 3.397914942762981
Validation loss: 3.5220107408154937

Epoch: 6| Step: 3
Training loss: 4.156484726322397
Validation loss: 3.5191608895253013

Epoch: 6| Step: 4
Training loss: 4.479651751606795
Validation loss: 3.5152089402125988

Epoch: 6| Step: 5
Training loss: 3.4886250257096023
Validation loss: 3.515470896343431

Epoch: 6| Step: 6
Training loss: 3.4134872964567027
Validation loss: 3.5159302267021264

Epoch: 6| Step: 7
Training loss: 4.413831748669902
Validation loss: 3.5140833587597187

Epoch: 6| Step: 8
Training loss: 3.546170068000699
Validation loss: 3.515492960320049

Epoch: 6| Step: 9
Training loss: 3.851511987815325
Validation loss: 3.511736374206641

Epoch: 6| Step: 10
Training loss: 4.260794451067553
Validation loss: 3.5076826716382525

Epoch: 6| Step: 11
Training loss: 3.0816286546898013
Validation loss: 3.5111870708879236

Epoch: 6| Step: 12
Training loss: 2.7673565460214222
Validation loss: 3.50885284188592

Epoch: 6| Step: 13
Training loss: 3.5708394736404476
Validation loss: 3.5080501230076853

Epoch: 25| Step: 0
Training loss: 3.6325544368185585
Validation loss: 3.5066543502709075

Epoch: 6| Step: 1
Training loss: 3.3187185972060673
Validation loss: 3.50562754086826

Epoch: 6| Step: 2
Training loss: 4.311855986785882
Validation loss: 3.5038313660628044

Epoch: 6| Step: 3
Training loss: 2.3670533397161804
Validation loss: 3.503549810438981

Epoch: 6| Step: 4
Training loss: 2.863350527811289
Validation loss: 3.5013963621077995

Epoch: 6| Step: 5
Training loss: 4.010139964412675
Validation loss: 3.5053839840728025

Epoch: 6| Step: 6
Training loss: 3.270383589291317
Validation loss: 3.500290403023237

Epoch: 6| Step: 7
Training loss: 4.74964321201914
Validation loss: 3.4976407902652227

Epoch: 6| Step: 8
Training loss: 3.912983941809297
Validation loss: 3.5024208319430823

Epoch: 6| Step: 9
Training loss: 4.286679132027149
Validation loss: 3.5014475438098027

Epoch: 6| Step: 10
Training loss: 4.011113463800597
Validation loss: 3.4967612606347958

Epoch: 6| Step: 11
Training loss: 3.5705259163341565
Validation loss: 3.494691322482444

Epoch: 6| Step: 12
Training loss: 3.4537150021359615
Validation loss: 3.494777530440886

Epoch: 6| Step: 13
Training loss: 3.4126880244621143
Validation loss: 3.4930097825852706

Epoch: 26| Step: 0
Training loss: 3.8797398772988543
Validation loss: 3.4946035160844273

Epoch: 6| Step: 1
Training loss: 3.3024151431782567
Validation loss: 3.5011489303764822

Epoch: 6| Step: 2
Training loss: 2.738248947323064
Validation loss: 3.5039541275280524

Epoch: 6| Step: 3
Training loss: 3.4121342501418686
Validation loss: 3.510511555081053

Epoch: 6| Step: 4
Training loss: 5.002709989472659
Validation loss: 3.4915350378151313

Epoch: 6| Step: 5
Training loss: 3.897832850349057
Validation loss: 3.486269150138595

Epoch: 6| Step: 6
Training loss: 3.7009233456712756
Validation loss: 3.500907472668536

Epoch: 6| Step: 7
Training loss: 3.303553321229069
Validation loss: 3.5186824302427326

Epoch: 6| Step: 8
Training loss: 3.77764329639749
Validation loss: 3.5105165136483008

Epoch: 6| Step: 9
Training loss: 3.6342022606298334
Validation loss: 3.4897775585259216

Epoch: 6| Step: 10
Training loss: 3.837658280578302
Validation loss: 3.488195635547373

Epoch: 6| Step: 11
Training loss: 4.097001742592819
Validation loss: 3.4855074567746973

Epoch: 6| Step: 12
Training loss: 3.524080408146712
Validation loss: 3.489280029006465

Epoch: 6| Step: 13
Training loss: 2.9515158492562166
Validation loss: 3.4955763966993603

Epoch: 27| Step: 0
Training loss: 2.59389780381772
Validation loss: 3.493511792986431

Epoch: 6| Step: 1
Training loss: 3.960354312497504
Validation loss: 3.4863523867624555

Epoch: 6| Step: 2
Training loss: 3.7771182855895526
Validation loss: 3.483636892034781

Epoch: 6| Step: 3
Training loss: 3.861195493975952
Validation loss: 3.4834555077581917

Epoch: 6| Step: 4
Training loss: 3.802974871616365
Validation loss: 3.4840196453768

Epoch: 6| Step: 5
Training loss: 3.407099626603335
Validation loss: 3.4777685790932065

Epoch: 6| Step: 6
Training loss: 4.4907729600331
Validation loss: 3.478597144281742

Epoch: 6| Step: 7
Training loss: 4.202989767515482
Validation loss: 3.478121310080284

Epoch: 6| Step: 8
Training loss: 3.7300961293369155
Validation loss: 3.47703155491019

Epoch: 6| Step: 9
Training loss: 3.375692508434236
Validation loss: 3.4751717278385628

Epoch: 6| Step: 10
Training loss: 3.8857567905056714
Validation loss: 3.480049164818065

Epoch: 6| Step: 11
Training loss: 2.6449361967240743
Validation loss: 3.4681488982593054

Epoch: 6| Step: 12
Training loss: 3.6017139593288388
Validation loss: 3.467896704357201

Epoch: 6| Step: 13
Training loss: 4.059436993202657
Validation loss: 3.470259255605357

Epoch: 28| Step: 0
Training loss: 3.835530370173077
Validation loss: 3.468420648464201

Epoch: 6| Step: 1
Training loss: 3.580550924777744
Validation loss: 3.4688492154461694

Epoch: 6| Step: 2
Training loss: 3.9297288774924595
Validation loss: 3.468978727959444

Epoch: 6| Step: 3
Training loss: 3.123276502267953
Validation loss: 3.468472180765336

Epoch: 6| Step: 4
Training loss: 3.8055338769992915
Validation loss: 3.466607649204562

Epoch: 6| Step: 5
Training loss: 3.402017746382888
Validation loss: 3.464188781186329

Epoch: 6| Step: 6
Training loss: 3.302570214864309
Validation loss: 3.4612442399556547

Epoch: 6| Step: 7
Training loss: 4.274164057866133
Validation loss: 3.4608054124176255

Epoch: 6| Step: 8
Training loss: 3.977567354659384
Validation loss: 3.462458732018172

Epoch: 6| Step: 9
Training loss: 3.3530517683893613
Validation loss: 3.458736853267389

Epoch: 6| Step: 10
Training loss: 3.341189536058848
Validation loss: 3.459721798139706

Epoch: 6| Step: 11
Training loss: 4.127561294220696
Validation loss: 3.458083859244777

Epoch: 6| Step: 12
Training loss: 3.5190082462059156
Validation loss: 3.4554750724172774

Epoch: 6| Step: 13
Training loss: 3.8073490554234692
Validation loss: 3.4553950271598266

Epoch: 29| Step: 0
Training loss: 4.310802844475774
Validation loss: 3.4521907770788216

Epoch: 6| Step: 1
Training loss: 3.2006966666995607
Validation loss: 3.453659051213064

Epoch: 6| Step: 2
Training loss: 4.028311197906355
Validation loss: 3.4525996725337205

Epoch: 6| Step: 3
Training loss: 4.760323198710016
Validation loss: 3.4496353981617154

Epoch: 6| Step: 4
Training loss: 3.254289290836349
Validation loss: 3.448989035690179

Epoch: 6| Step: 5
Training loss: 3.910685470086704
Validation loss: 3.4502938176812754

Epoch: 6| Step: 6
Training loss: 4.40146978278612
Validation loss: 3.446816299327325

Epoch: 6| Step: 7
Training loss: 3.9109350566422028
Validation loss: 3.4502482166973825

Epoch: 6| Step: 8
Training loss: 3.3717283710208297
Validation loss: 3.44477558749492

Epoch: 6| Step: 9
Training loss: 3.317388993269559
Validation loss: 3.455106980951841

Epoch: 6| Step: 10
Training loss: 3.8350993248760896
Validation loss: 3.451144988836704

Epoch: 6| Step: 11
Training loss: 2.6550416778626555
Validation loss: 3.4458595332516735

Epoch: 6| Step: 12
Training loss: 1.9884214820198662
Validation loss: 3.4468286920108246

Epoch: 6| Step: 13
Training loss: 3.385745990091966
Validation loss: 3.4500655124787745

Epoch: 30| Step: 0
Training loss: 3.4797324141304595
Validation loss: 3.443025329619809

Epoch: 6| Step: 1
Training loss: 4.297144877888399
Validation loss: 3.4418488215910905

Epoch: 6| Step: 2
Training loss: 3.6054470603017696
Validation loss: 3.442865054480726

Epoch: 6| Step: 3
Training loss: 3.509741170094269
Validation loss: 3.448527180794065

Epoch: 6| Step: 4
Training loss: 3.523565251980008
Validation loss: 3.4470046035123407

Epoch: 6| Step: 5
Training loss: 3.6920253335449362
Validation loss: 3.448171212813472

Epoch: 6| Step: 6
Training loss: 3.7925573846829637
Validation loss: 3.446005839197263

Epoch: 6| Step: 7
Training loss: 3.7071349247060845
Validation loss: 3.4452836885117946

Epoch: 6| Step: 8
Training loss: 3.9405938966326777
Validation loss: 3.4395919557214407

Epoch: 6| Step: 9
Training loss: 4.19295340191026
Validation loss: 3.4379886447691983

Epoch: 6| Step: 10
Training loss: 3.4386999636760325
Validation loss: 3.441610080363359

Epoch: 6| Step: 11
Training loss: 3.516129792318632
Validation loss: 3.443759235004702

Epoch: 6| Step: 12
Training loss: 3.000264632951036
Validation loss: 3.4383266912923696

Epoch: 6| Step: 13
Training loss: 3.155451305291127
Validation loss: 3.4339019111847433

Epoch: 31| Step: 0
Training loss: 3.752891188937001
Validation loss: 3.4354326312807824

Epoch: 6| Step: 1
Training loss: 4.3256906211581505
Validation loss: 3.435430116467357

Epoch: 6| Step: 2
Training loss: 3.290889277990105
Validation loss: 3.433096674743266

Epoch: 6| Step: 3
Training loss: 3.5918887418580656
Validation loss: 3.4320337546352535

Epoch: 6| Step: 4
Training loss: 3.5942601380877512
Validation loss: 3.4315442290306315

Epoch: 6| Step: 5
Training loss: 4.064049762616405
Validation loss: 3.4295798350272677

Epoch: 6| Step: 6
Training loss: 2.8604625863994304
Validation loss: 3.4293513484033764

Epoch: 6| Step: 7
Training loss: 3.2765990219300094
Validation loss: 3.4289307133204976

Epoch: 6| Step: 8
Training loss: 4.267601812720301
Validation loss: 3.429761748395865

Epoch: 6| Step: 9
Training loss: 4.4482682362368475
Validation loss: 3.424977291502858

Epoch: 6| Step: 10
Training loss: 3.6010159224624547
Validation loss: 3.4259308034851106

Epoch: 6| Step: 11
Training loss: 3.358797103500435
Validation loss: 3.4253548970823497

Epoch: 6| Step: 12
Training loss: 3.4185660750378095
Validation loss: 3.423206630075898

Epoch: 6| Step: 13
Training loss: 1.96431195625512
Validation loss: 3.4237817282479237

Epoch: 32| Step: 0
Training loss: 3.7380601903274955
Validation loss: 3.422261905715315

Epoch: 6| Step: 1
Training loss: 3.9071006153938543
Validation loss: 3.4240045473192953

Epoch: 6| Step: 2
Training loss: 3.7721504875657184
Validation loss: 3.42156858931742

Epoch: 6| Step: 3
Training loss: 4.180251038966356
Validation loss: 3.4266810032181656

Epoch: 6| Step: 4
Training loss: 3.2142159832853534
Validation loss: 3.4217660118371542

Epoch: 6| Step: 5
Training loss: 4.089588641906392
Validation loss: 3.4198298969314433

Epoch: 6| Step: 6
Training loss: 3.708936935049097
Validation loss: 3.420061487310671

Epoch: 6| Step: 7
Training loss: 2.53224765284796
Validation loss: 3.419323609699595

Epoch: 6| Step: 8
Training loss: 3.374976122736356
Validation loss: 3.414468349679142

Epoch: 6| Step: 9
Training loss: 3.165041322363047
Validation loss: 3.420149149127236

Epoch: 6| Step: 10
Training loss: 3.564877168698141
Validation loss: 3.4169389604723035

Epoch: 6| Step: 11
Training loss: 3.7874877174102743
Validation loss: 3.4187893690148443

Epoch: 6| Step: 12
Training loss: 4.32804633664695
Validation loss: 3.4177590976528034

Epoch: 6| Step: 13
Training loss: 2.876735826665086
Validation loss: 3.414684994033926

Epoch: 33| Step: 0
Training loss: 3.407191575128476
Validation loss: 3.4149919532836384

Epoch: 6| Step: 1
Training loss: 3.6488574029392904
Validation loss: 3.4132081464597865

Epoch: 6| Step: 2
Training loss: 4.125907566915723
Validation loss: 3.412849785890968

Epoch: 6| Step: 3
Training loss: 2.8819443137131833
Validation loss: 3.4160069344670574

Epoch: 6| Step: 4
Training loss: 4.1175699074513625
Validation loss: 3.4098461247711698

Epoch: 6| Step: 5
Training loss: 3.926069835475083
Validation loss: 3.411643107593234

Epoch: 6| Step: 6
Training loss: 2.9679005260815
Validation loss: 3.4116950210917607

Epoch: 6| Step: 7
Training loss: 3.732000002731209
Validation loss: 3.409204167423402

Epoch: 6| Step: 8
Training loss: 3.252191978137006
Validation loss: 3.413228175828435

Epoch: 6| Step: 9
Training loss: 4.292018962338271
Validation loss: 3.410806671828315

Epoch: 6| Step: 10
Training loss: 3.3084107115286074
Validation loss: 3.4103540580399367

Epoch: 6| Step: 11
Training loss: 3.612250301614786
Validation loss: 3.4096326992868677

Epoch: 6| Step: 12
Training loss: 3.5416595159720248
Validation loss: 3.410687062464883

Epoch: 6| Step: 13
Training loss: 3.8315379596170422
Validation loss: 3.409460869674153

Epoch: 34| Step: 0
Training loss: 4.171925748023505
Validation loss: 3.410339680560849

Epoch: 6| Step: 1
Training loss: 4.12899078600191
Validation loss: 3.415709810007425

Epoch: 6| Step: 2
Training loss: 3.453951223270875
Validation loss: 3.410204860367718

Epoch: 6| Step: 3
Training loss: 2.890106649575903
Validation loss: 3.406931403784132

Epoch: 6| Step: 4
Training loss: 2.735104883055397
Validation loss: 3.4064422128707084

Epoch: 6| Step: 5
Training loss: 3.652608117312174
Validation loss: 3.40810284060219

Epoch: 6| Step: 6
Training loss: 3.1386626076695014
Validation loss: 3.409317855316206

Epoch: 6| Step: 7
Training loss: 3.741423399450412
Validation loss: 3.4078821142670197

Epoch: 6| Step: 8
Training loss: 3.9689436737623334
Validation loss: 3.4100459009461996

Epoch: 6| Step: 9
Training loss: 3.5488180476346325
Validation loss: 3.406951672468929

Epoch: 6| Step: 10
Training loss: 3.316968674703583
Validation loss: 3.4037385781307825

Epoch: 6| Step: 11
Training loss: 4.33135160957259
Validation loss: 3.404507767507426

Epoch: 6| Step: 12
Training loss: 3.319054075632124
Validation loss: 3.4020652628296135

Epoch: 6| Step: 13
Training loss: 4.287457942478329
Validation loss: 3.4061301147160346

Epoch: 35| Step: 0
Training loss: 4.078960230860483
Validation loss: 3.414271762128654

Epoch: 6| Step: 1
Training loss: 4.078306464473221
Validation loss: 3.422889554948924

Epoch: 6| Step: 2
Training loss: 2.9353464226928687
Validation loss: 3.401203300108833

Epoch: 6| Step: 3
Training loss: 3.4535344083957153
Validation loss: 3.4002413007776253

Epoch: 6| Step: 4
Training loss: 4.445527887741072
Validation loss: 3.4027842207621544

Epoch: 6| Step: 5
Training loss: 3.4637054328157557
Validation loss: 3.4072449890379017

Epoch: 6| Step: 6
Training loss: 3.616015646098898
Validation loss: 3.414479108868762

Epoch: 6| Step: 7
Training loss: 3.9506074027943074
Validation loss: 3.412651903156033

Epoch: 6| Step: 8
Training loss: 3.4337409533647776
Validation loss: 3.405907414904599

Epoch: 6| Step: 9
Training loss: 3.285682663261878
Validation loss: 3.401676412658079

Epoch: 6| Step: 10
Training loss: 3.590218973733762
Validation loss: 3.3975836873539556

Epoch: 6| Step: 11
Training loss: 2.5805025177610545
Validation loss: 3.397782866393369

Epoch: 6| Step: 12
Training loss: 3.8711149367167446
Validation loss: 3.399275861676319

Epoch: 6| Step: 13
Training loss: 3.7220504604077815
Validation loss: 3.397027050035285

Epoch: 36| Step: 0
Training loss: 3.4500442502045017
Validation loss: 3.3956802145412293

Epoch: 6| Step: 1
Training loss: 4.22422875582549
Validation loss: 3.3969957476127153

Epoch: 6| Step: 2
Training loss: 3.2572427887274227
Validation loss: 3.3981066946256693

Epoch: 6| Step: 3
Training loss: 3.0524275827526552
Validation loss: 3.3964012290693

Epoch: 6| Step: 4
Training loss: 3.8489446506420504
Validation loss: 3.394343999969137

Epoch: 6| Step: 5
Training loss: 3.8679463576391195
Validation loss: 3.396435926039076

Epoch: 6| Step: 6
Training loss: 4.0574600648354355
Validation loss: 3.3951787407664114

Epoch: 6| Step: 7
Training loss: 4.449785017328304
Validation loss: 3.393843822896726

Epoch: 6| Step: 8
Training loss: 2.7407864635059767
Validation loss: 3.3929637896800653

Epoch: 6| Step: 9
Training loss: 3.4099958628967784
Validation loss: 3.3920634759566743

Epoch: 6| Step: 10
Training loss: 3.635289945097133
Validation loss: 3.392988137260693

Epoch: 6| Step: 11
Training loss: 3.4463892354915755
Validation loss: 3.3914904373856385

Epoch: 6| Step: 12
Training loss: 3.7263238538546477
Validation loss: 3.391564510617349

Epoch: 6| Step: 13
Training loss: 2.6858294418106348
Validation loss: 3.391444444860711

Epoch: 37| Step: 0
Training loss: 4.2464142426626355
Validation loss: 3.392251767820935

Epoch: 6| Step: 1
Training loss: 3.1052160004260183
Validation loss: 3.388905558339752

Epoch: 6| Step: 2
Training loss: 3.23205719241915
Validation loss: 3.390837648574699

Epoch: 6| Step: 3
Training loss: 3.9678735441084982
Validation loss: 3.390517219715739

Epoch: 6| Step: 4
Training loss: 2.1295487580477777
Validation loss: 3.3881853291070514

Epoch: 6| Step: 5
Training loss: 3.5803727332068944
Validation loss: 3.3864078637590582

Epoch: 6| Step: 6
Training loss: 3.605309777355927
Validation loss: 3.387148591713139

Epoch: 6| Step: 7
Training loss: 4.628574536505838
Validation loss: 3.3868957140987948

Epoch: 6| Step: 8
Training loss: 3.1398420733931203
Validation loss: 3.3847495240322263

Epoch: 6| Step: 9
Training loss: 4.2601659027891285
Validation loss: 3.385276771601982

Epoch: 6| Step: 10
Training loss: 2.8961468716676833
Validation loss: 3.383164002647539

Epoch: 6| Step: 11
Training loss: 2.912880174439816
Validation loss: 3.3827352249022047

Epoch: 6| Step: 12
Training loss: 4.583088238260596
Validation loss: 3.3832406299288507

Epoch: 6| Step: 13
Training loss: 3.144966578707787
Validation loss: 3.3815730314487844

Epoch: 38| Step: 0
Training loss: 3.5328877120044906
Validation loss: 3.380895482620685

Epoch: 6| Step: 1
Training loss: 3.064072808419044
Validation loss: 3.3798740624343044

Epoch: 6| Step: 2
Training loss: 3.774581072469373
Validation loss: 3.380018120098383

Epoch: 6| Step: 3
Training loss: 3.5585420271865456
Validation loss: 3.3804509721601708

Epoch: 6| Step: 4
Training loss: 3.3051460254629883
Validation loss: 3.3810448984646695

Epoch: 6| Step: 5
Training loss: 3.7277361862912137
Validation loss: 3.3787906571712054

Epoch: 6| Step: 6
Training loss: 3.1964667364400916
Validation loss: 3.3798717535539686

Epoch: 6| Step: 7
Training loss: 4.404535054535366
Validation loss: 3.3770799839751944

Epoch: 6| Step: 8
Training loss: 4.111352017077253
Validation loss: 3.3790462307703875

Epoch: 6| Step: 9
Training loss: 3.5705638438095075
Validation loss: 3.380584675116186

Epoch: 6| Step: 10
Training loss: 3.440700636196053
Validation loss: 3.3884888345670126

Epoch: 6| Step: 11
Training loss: 3.2675543383492403
Validation loss: 3.393201698493811

Epoch: 6| Step: 12
Training loss: 3.6276225107591342
Validation loss: 3.376686024468573

Epoch: 6| Step: 13
Training loss: 3.7769859799384173
Validation loss: 3.375628743613395

Epoch: 39| Step: 0
Training loss: 3.7809673865767386
Validation loss: 3.3755858173829543

Epoch: 6| Step: 1
Training loss: 3.029715395361764
Validation loss: 3.3744597843906443

Epoch: 6| Step: 2
Training loss: 3.906279785042695
Validation loss: 3.3770595238581573

Epoch: 6| Step: 3
Training loss: 2.9674713593589614
Validation loss: 3.3734334958564585

Epoch: 6| Step: 4
Training loss: 3.673585274278388
Validation loss: 3.3745892850967465

Epoch: 6| Step: 5
Training loss: 3.604102044086634
Validation loss: 3.372426043915287

Epoch: 6| Step: 6
Training loss: 4.012626270434569
Validation loss: 3.373520293183957

Epoch: 6| Step: 7
Training loss: 2.9525523765886055
Validation loss: 3.3718408104194744

Epoch: 6| Step: 8
Training loss: 3.1450583069555944
Validation loss: 3.37007645797378

Epoch: 6| Step: 9
Training loss: 4.509119330313822
Validation loss: 3.368083583279755

Epoch: 6| Step: 10
Training loss: 3.4025721861997
Validation loss: 3.368744698246208

Epoch: 6| Step: 11
Training loss: 3.691333911328244
Validation loss: 3.3733393337029884

Epoch: 6| Step: 12
Training loss: 3.425586377367909
Validation loss: 3.3690854146011513

Epoch: 6| Step: 13
Training loss: 4.164663418179043
Validation loss: 3.3718327131197836

Epoch: 40| Step: 0
Training loss: 3.865516255236114
Validation loss: 3.3670450740096385

Epoch: 6| Step: 1
Training loss: 3.6308189254403667
Validation loss: 3.368010041002959

Epoch: 6| Step: 2
Training loss: 3.6954559878986646
Validation loss: 3.3646738770449676

Epoch: 6| Step: 3
Training loss: 3.156511050466757
Validation loss: 3.367653511210418

Epoch: 6| Step: 4
Training loss: 3.0397444795837147
Validation loss: 3.366032288819715

Epoch: 6| Step: 5
Training loss: 3.386490511655786
Validation loss: 3.3627156692996816

Epoch: 6| Step: 6
Training loss: 3.6371338440435905
Validation loss: 3.3629629767672204

Epoch: 6| Step: 7
Training loss: 3.125686875195988
Validation loss: 3.363643379444222

Epoch: 6| Step: 8
Training loss: 3.655350272828232
Validation loss: 3.3620382258194965

Epoch: 6| Step: 9
Training loss: 4.029952675894134
Validation loss: 3.3614961529081833

Epoch: 6| Step: 10
Training loss: 3.3517935435369663
Validation loss: 3.3619445817811666

Epoch: 6| Step: 11
Training loss: 4.191208521008845
Validation loss: 3.36075311978821

Epoch: 6| Step: 12
Training loss: 3.6813738091313946
Validation loss: 3.357329447655435

Epoch: 6| Step: 13
Training loss: 3.716667297317611
Validation loss: 3.3591980925957623

Epoch: 41| Step: 0
Training loss: 3.873298763792774
Validation loss: 3.359516922437096

Epoch: 6| Step: 1
Training loss: 3.6089590914662573
Validation loss: 3.3575766937300218

Epoch: 6| Step: 2
Training loss: 3.575771974031078
Validation loss: 3.3561857476646235

Epoch: 6| Step: 3
Training loss: 2.843559845655652
Validation loss: 3.3580812161164246

Epoch: 6| Step: 4
Training loss: 3.6645363051950084
Validation loss: 3.3533474479640333

Epoch: 6| Step: 5
Training loss: 3.937385557418907
Validation loss: 3.3551782193384696

Epoch: 6| Step: 6
Training loss: 3.5578162205424935
Validation loss: 3.3557457365778607

Epoch: 6| Step: 7
Training loss: 3.8273030546960025
Validation loss: 3.354777932701146

Epoch: 6| Step: 8
Training loss: 3.2767490579433924
Validation loss: 3.355316777140947

Epoch: 6| Step: 9
Training loss: 3.0209502800414345
Validation loss: 3.3543213554048683

Epoch: 6| Step: 10
Training loss: 3.7025998543945704
Validation loss: 3.3517455591644

Epoch: 6| Step: 11
Training loss: 4.2371924904842375
Validation loss: 3.3496223737658846

Epoch: 6| Step: 12
Training loss: 3.6273233268930225
Validation loss: 3.3494799540128746

Epoch: 6| Step: 13
Training loss: 2.9043325025660245
Validation loss: 3.3478441096548837

Epoch: 42| Step: 0
Training loss: 3.0014196851394797
Validation loss: 3.3468308744586355

Epoch: 6| Step: 1
Training loss: 4.058132229834831
Validation loss: 3.3464261772126522

Epoch: 6| Step: 2
Training loss: 2.928325366937711
Validation loss: 3.347223450670366

Epoch: 6| Step: 3
Training loss: 2.995764921960895
Validation loss: 3.353594674191598

Epoch: 6| Step: 4
Training loss: 4.757783435551107
Validation loss: 3.3544817525364574

Epoch: 6| Step: 5
Training loss: 3.9317041762437044
Validation loss: 3.346029831359916

Epoch: 6| Step: 6
Training loss: 2.9969266407706967
Validation loss: 3.3462088216451114

Epoch: 6| Step: 7
Training loss: 3.6267092391161344
Validation loss: 3.3471636578039274

Epoch: 6| Step: 8
Training loss: 4.387309604437045
Validation loss: 3.34551113128452

Epoch: 6| Step: 9
Training loss: 3.379568892755244
Validation loss: 3.3449504768542186

Epoch: 6| Step: 10
Training loss: 2.689109320401972
Validation loss: 3.34753410241051

Epoch: 6| Step: 11
Training loss: 3.460609299918812
Validation loss: 3.3423017743467542

Epoch: 6| Step: 12
Training loss: 3.52165417253908
Validation loss: 3.3449530014443805

Epoch: 6| Step: 13
Training loss: 3.856289019765931
Validation loss: 3.340608097644786

Epoch: 43| Step: 0
Training loss: 2.3055402826725095
Validation loss: 3.336711052551049

Epoch: 6| Step: 1
Training loss: 3.688733815823726
Validation loss: 3.3381449340316296

Epoch: 6| Step: 2
Training loss: 3.8597099375078403
Validation loss: 3.3363776138908916

Epoch: 6| Step: 3
Training loss: 3.3874308223628633
Validation loss: 3.3365411740794255

Epoch: 6| Step: 4
Training loss: 3.5255510372957515
Validation loss: 3.3362761279494975

Epoch: 6| Step: 5
Training loss: 3.121039207468901
Validation loss: 3.338177895725928

Epoch: 6| Step: 6
Training loss: 3.685380876337521
Validation loss: 3.340974012896715

Epoch: 6| Step: 7
Training loss: 3.4820941935621668
Validation loss: 3.3402845856349153

Epoch: 6| Step: 8
Training loss: 3.859069441463904
Validation loss: 3.339847589497907

Epoch: 6| Step: 9
Training loss: 4.310518334678398
Validation loss: 3.338716757914818

Epoch: 6| Step: 10
Training loss: 3.4757873356757947
Validation loss: 3.338389348159083

Epoch: 6| Step: 11
Training loss: 4.110650274434805
Validation loss: 3.3374633250584034

Epoch: 6| Step: 12
Training loss: 3.4252826323458616
Validation loss: 3.3356815655039402

Epoch: 6| Step: 13
Training loss: 3.2491169243294196
Validation loss: 3.3312167667094195

Epoch: 44| Step: 0
Training loss: 4.447805339244899
Validation loss: 3.3351413058793877

Epoch: 6| Step: 1
Training loss: 2.659637714323862
Validation loss: 3.3306255699530403

Epoch: 6| Step: 2
Training loss: 3.5149036260771576
Validation loss: 3.3307210782042747

Epoch: 6| Step: 3
Training loss: 3.0324714008941966
Validation loss: 3.3292293746948016

Epoch: 6| Step: 4
Training loss: 3.3076403977171327
Validation loss: 3.325898476331631

Epoch: 6| Step: 5
Training loss: 4.053799511762685
Validation loss: 3.326470748434523

Epoch: 6| Step: 6
Training loss: 4.664241410343161
Validation loss: 3.326944763843249

Epoch: 6| Step: 7
Training loss: 3.5358586577737956
Validation loss: 3.3228634505257624

Epoch: 6| Step: 8
Training loss: 3.093959300349906
Validation loss: 3.320660551240121

Epoch: 6| Step: 9
Training loss: 2.972254240946953
Validation loss: 3.3208967384200543

Epoch: 6| Step: 10
Training loss: 3.6985177138171106
Validation loss: 3.3217824540062435

Epoch: 6| Step: 11
Training loss: 2.874633268103329
Validation loss: 3.3202289166869354

Epoch: 6| Step: 12
Training loss: 4.147533483479311
Validation loss: 3.3205083302144063

Epoch: 6| Step: 13
Training loss: 2.838932694032664
Validation loss: 3.3206958697577122

Epoch: 45| Step: 0
Training loss: 3.4956837333766257
Validation loss: 3.3162671069923495

Epoch: 6| Step: 1
Training loss: 3.682745503142726
Validation loss: 3.3205697966455054

Epoch: 6| Step: 2
Training loss: 3.5694162257984376
Validation loss: 3.318077794856287

Epoch: 6| Step: 3
Training loss: 3.4303443644627385
Validation loss: 3.315506545651829

Epoch: 6| Step: 4
Training loss: 2.745560704205036
Validation loss: 3.3181455582975135

Epoch: 6| Step: 5
Training loss: 4.183627715271204
Validation loss: 3.313722604258247

Epoch: 6| Step: 6
Training loss: 3.681034691930822
Validation loss: 3.3146831185553127

Epoch: 6| Step: 7
Training loss: 3.693430899376849
Validation loss: 3.312173560680238

Epoch: 6| Step: 8
Training loss: 3.351900808337064
Validation loss: 3.3132032273672514

Epoch: 6| Step: 9
Training loss: 2.6046218982803837
Validation loss: 3.3126620908717093

Epoch: 6| Step: 10
Training loss: 3.531584327197557
Validation loss: 3.3110792286600947

Epoch: 6| Step: 11
Training loss: 4.386882232038311
Validation loss: 3.3130941680407022

Epoch: 6| Step: 12
Training loss: 3.4385069325998328
Validation loss: 3.3119400411734503

Epoch: 6| Step: 13
Training loss: 3.5353224235806096
Validation loss: 3.3127400099827597

Epoch: 46| Step: 0
Training loss: 3.9015891383204684
Validation loss: 3.3118950741689264

Epoch: 6| Step: 1
Training loss: 3.9508957438731636
Validation loss: 3.3098678377912485

Epoch: 6| Step: 2
Training loss: 4.405015055428279
Validation loss: 3.3110389296607092

Epoch: 6| Step: 3
Training loss: 2.7854298247257425
Validation loss: 3.3072627219956283

Epoch: 6| Step: 4
Training loss: 3.249320619439553
Validation loss: 3.3086589787383014

Epoch: 6| Step: 5
Training loss: 3.23010591362835
Validation loss: 3.30923253242439

Epoch: 6| Step: 6
Training loss: 3.5551239751774952
Validation loss: 3.304963034960389

Epoch: 6| Step: 7
Training loss: 3.390028378078096
Validation loss: 3.307068736913853

Epoch: 6| Step: 8
Training loss: 3.4931100057845597
Validation loss: 3.30439580489497

Epoch: 6| Step: 9
Training loss: 3.2857051576760066
Validation loss: 3.30347465772182

Epoch: 6| Step: 10
Training loss: 3.4609694640877224
Validation loss: 3.3032639908430204

Epoch: 6| Step: 11
Training loss: 3.053927978375871
Validation loss: 3.301690834708039

Epoch: 6| Step: 12
Training loss: 3.3548255099588276
Validation loss: 3.301116737189299

Epoch: 6| Step: 13
Training loss: 4.585310261086995
Validation loss: 3.3010278908534043

Epoch: 47| Step: 0
Training loss: 3.6973498415940105
Validation loss: 3.300056496686889

Epoch: 6| Step: 1
Training loss: 4.337997029874637
Validation loss: 3.2998662630030857

Epoch: 6| Step: 2
Training loss: 1.977488425277613
Validation loss: 3.2997495779342554

Epoch: 6| Step: 3
Training loss: 2.76988805455154
Validation loss: 3.302037531287052

Epoch: 6| Step: 4
Training loss: 3.9201736711450015
Validation loss: 3.299053078219515

Epoch: 6| Step: 5
Training loss: 3.7507117549637483
Validation loss: 3.30113613810337

Epoch: 6| Step: 6
Training loss: 3.580111023230937
Validation loss: 3.297633340618406

Epoch: 6| Step: 7
Training loss: 3.718169607823713
Validation loss: 3.2993673190423607

Epoch: 6| Step: 8
Training loss: 3.354684509361295
Validation loss: 3.297773831113171

Epoch: 6| Step: 9
Training loss: 3.752045137308764
Validation loss: 3.299267008664472

Epoch: 6| Step: 10
Training loss: 3.3872979360751923
Validation loss: 3.2960039745647935

Epoch: 6| Step: 11
Training loss: 3.1076219687306095
Validation loss: 3.2987044942116084

Epoch: 6| Step: 12
Training loss: 3.835672342183226
Validation loss: 3.29860308960114

Epoch: 6| Step: 13
Training loss: 3.8982839917249694
Validation loss: 3.296774436491206

Epoch: 48| Step: 0
Training loss: 3.8443595588980513
Validation loss: 3.2952141333371214

Epoch: 6| Step: 1
Training loss: 3.5971978938304088
Validation loss: 3.293683587716799

Epoch: 6| Step: 2
Training loss: 2.468993935424229
Validation loss: 3.2963470641257278

Epoch: 6| Step: 3
Training loss: 3.399738492445647
Validation loss: 3.3078998719893367

Epoch: 6| Step: 4
Training loss: 4.289536969288022
Validation loss: 3.29188084453988

Epoch: 6| Step: 5
Training loss: 2.8760480214488227
Validation loss: 3.291482106885461

Epoch: 6| Step: 6
Training loss: 3.776895585244689
Validation loss: 3.2992598848146417

Epoch: 6| Step: 7
Training loss: 2.657458849325452
Validation loss: 3.3039474952351835

Epoch: 6| Step: 8
Training loss: 3.6945952350434363
Validation loss: 3.314519508445324

Epoch: 6| Step: 9
Training loss: 3.4468341676259637
Validation loss: 3.30775845991085

Epoch: 6| Step: 10
Training loss: 4.114540016171642
Validation loss: 3.304642051078408

Epoch: 6| Step: 11
Training loss: 3.2979506053290777
Validation loss: 3.307420147541643

Epoch: 6| Step: 12
Training loss: 3.781960664912747
Validation loss: 3.3116080394452236

Epoch: 6| Step: 13
Training loss: 4.07945890279277
Validation loss: 3.3039994109270245

Epoch: 49| Step: 0
Training loss: 3.6674390904023917
Validation loss: 3.3004772912563674

Epoch: 6| Step: 1
Training loss: 3.621036730731968
Validation loss: 3.2983801405129016

Epoch: 6| Step: 2
Training loss: 4.237009727900819
Validation loss: 3.2980041747475

Epoch: 6| Step: 3
Training loss: 3.5853912003872677
Validation loss: 3.2964782406121786

Epoch: 6| Step: 4
Training loss: 3.891521794783175
Validation loss: 3.2968942003731545

Epoch: 6| Step: 5
Training loss: 1.9250062694695174
Validation loss: 3.294567436469242

Epoch: 6| Step: 6
Training loss: 3.871703191336681
Validation loss: 3.293283140122916

Epoch: 6| Step: 7
Training loss: 3.6498129496264244
Validation loss: 3.291943739516003

Epoch: 6| Step: 8
Training loss: 3.6386634879801356
Validation loss: 3.2910542622608308

Epoch: 6| Step: 9
Training loss: 4.273278158449602
Validation loss: 3.2913151889960672

Epoch: 6| Step: 10
Training loss: 3.474910866671408
Validation loss: 3.29133475673264

Epoch: 6| Step: 11
Training loss: 3.3815628104495743
Validation loss: 3.292129392695277

Epoch: 6| Step: 12
Training loss: 2.299856106776561
Validation loss: 3.2884694711241513

Epoch: 6| Step: 13
Training loss: 2.878185994747617
Validation loss: 3.286432492384187

Epoch: 50| Step: 0
Training loss: 3.4749558754733587
Validation loss: 3.285512499694829

Epoch: 6| Step: 1
Training loss: 2.920608327545768
Validation loss: 3.2850775985878755

Epoch: 6| Step: 2
Training loss: 3.3191080938277957
Validation loss: 3.2831610142865095

Epoch: 6| Step: 3
Training loss: 3.323177474897043
Validation loss: 3.2849938086407984

Epoch: 6| Step: 4
Training loss: 3.7982320989687715
Validation loss: 3.2833827215585867

Epoch: 6| Step: 5
Training loss: 2.7788008289433117
Validation loss: 3.282502411467352

Epoch: 6| Step: 6
Training loss: 3.821905821881032
Validation loss: 3.280891027703551

Epoch: 6| Step: 7
Training loss: 3.4265734323169768
Validation loss: 3.282832332266003

Epoch: 6| Step: 8
Training loss: 3.3833320342062976
Validation loss: 3.2792557976647174

Epoch: 6| Step: 9
Training loss: 4.166502046512022
Validation loss: 3.2817309189754367

Epoch: 6| Step: 10
Training loss: 3.332229590466284
Validation loss: 3.28282809341097

Epoch: 6| Step: 11
Training loss: 3.525413077750523
Validation loss: 3.2798569823583392

Epoch: 6| Step: 12
Training loss: 4.081441531864366
Validation loss: 3.2801519147446876

Epoch: 6| Step: 13
Training loss: 3.821332861563775
Validation loss: 3.279726952198337

Epoch: 51| Step: 0
Training loss: 3.2788705099910644
Validation loss: 3.2787313034360674

Epoch: 6| Step: 1
Training loss: 3.6802650209033145
Validation loss: 3.281210222213129

Epoch: 6| Step: 2
Training loss: 3.385496277484416
Validation loss: 3.28788129745325

Epoch: 6| Step: 3
Training loss: 3.1305803447089064
Validation loss: 3.2799811203405995

Epoch: 6| Step: 4
Training loss: 3.251894032167677
Validation loss: 3.276696780914118

Epoch: 6| Step: 5
Training loss: 3.4620359584939715
Validation loss: 3.276480540372109

Epoch: 6| Step: 6
Training loss: 3.1563188904146364
Validation loss: 3.277033053365885

Epoch: 6| Step: 7
Training loss: 3.603529651480154
Validation loss: 3.2748812245242536

Epoch: 6| Step: 8
Training loss: 3.414024509943095
Validation loss: 3.2741398982989924

Epoch: 6| Step: 9
Training loss: 3.724339491893684
Validation loss: 3.274315388205475

Epoch: 6| Step: 10
Training loss: 3.965044349143377
Validation loss: 3.2745342597925102

Epoch: 6| Step: 11
Training loss: 4.007774427207075
Validation loss: 3.271934691971192

Epoch: 6| Step: 12
Training loss: 3.264225564100189
Validation loss: 3.2720045761158434

Epoch: 6| Step: 13
Training loss: 3.967828238069139
Validation loss: 3.2720623420583794

Epoch: 52| Step: 0
Training loss: 2.8511241837252457
Validation loss: 3.272931748000732

Epoch: 6| Step: 1
Training loss: 3.4933992540774197
Validation loss: 3.2698446085340707

Epoch: 6| Step: 2
Training loss: 2.8980330933128635
Validation loss: 3.272477315185795

Epoch: 6| Step: 3
Training loss: 3.798915487427331
Validation loss: 3.2721075132994892

Epoch: 6| Step: 4
Training loss: 3.525480570398637
Validation loss: 3.2712938621857117

Epoch: 6| Step: 5
Training loss: 2.4911733255870527
Validation loss: 3.2724031409898644

Epoch: 6| Step: 6
Training loss: 3.386172416645955
Validation loss: 3.268500508351979

Epoch: 6| Step: 7
Training loss: 4.39050814109945
Validation loss: 3.2707576806969327

Epoch: 6| Step: 8
Training loss: 3.6467821176398236
Validation loss: 3.2689064677505333

Epoch: 6| Step: 9
Training loss: 3.9526432030231713
Validation loss: 3.267679634104066

Epoch: 6| Step: 10
Training loss: 3.8525811448113534
Validation loss: 3.26769140068382

Epoch: 6| Step: 11
Training loss: 4.045917176708051
Validation loss: 3.270630172513734

Epoch: 6| Step: 12
Training loss: 3.0501115872341584
Validation loss: 3.267576067859327

Epoch: 6| Step: 13
Training loss: 3.1575048992393824
Validation loss: 3.27008812867544

Epoch: 53| Step: 0
Training loss: 2.652714968787156
Validation loss: 3.267677203583779

Epoch: 6| Step: 1
Training loss: 2.983099699906136
Validation loss: 3.268855701270711

Epoch: 6| Step: 2
Training loss: 4.007176874928034
Validation loss: 3.2669837802972093

Epoch: 6| Step: 3
Training loss: 3.540823054350737
Validation loss: 3.267300562498272

Epoch: 6| Step: 4
Training loss: 3.6506474273468186
Validation loss: 3.2659671331619604

Epoch: 6| Step: 5
Training loss: 3.6560131550558466
Validation loss: 3.26696863375545

Epoch: 6| Step: 6
Training loss: 3.1971916511754035
Validation loss: 3.265288593769374

Epoch: 6| Step: 7
Training loss: 3.0784476638764016
Validation loss: 3.2664601425405597

Epoch: 6| Step: 8
Training loss: 3.977075929603193
Validation loss: 3.2647064309747083

Epoch: 6| Step: 9
Training loss: 3.8365720391114126
Validation loss: 3.2647358120992966

Epoch: 6| Step: 10
Training loss: 3.6492121852194215
Validation loss: 3.2654556895450915

Epoch: 6| Step: 11
Training loss: 3.5688405414593363
Validation loss: 3.2639991201129734

Epoch: 6| Step: 12
Training loss: 3.4943535080482317
Validation loss: 3.265878986118608

Epoch: 6| Step: 13
Training loss: 3.5800903786274203
Validation loss: 3.2642350718341753

Epoch: 54| Step: 0
Training loss: 3.4385563007741706
Validation loss: 3.264466382558432

Epoch: 6| Step: 1
Training loss: 3.3048371265347347
Validation loss: 3.266674733235677

Epoch: 6| Step: 2
Training loss: 3.154618247463779
Validation loss: 3.267767657261227

Epoch: 6| Step: 3
Training loss: 3.4159279621756427
Validation loss: 3.2610033714290414

Epoch: 6| Step: 4
Training loss: 2.477984191819477
Validation loss: 3.2612088136950894

Epoch: 6| Step: 5
Training loss: 3.752696911285428
Validation loss: 3.258540163152155

Epoch: 6| Step: 6
Training loss: 3.810090851589143
Validation loss: 3.260758170401976

Epoch: 6| Step: 7
Training loss: 3.5234021779254308
Validation loss: 3.259056381276117

Epoch: 6| Step: 8
Training loss: 3.999043946452294
Validation loss: 3.258246232925738

Epoch: 6| Step: 9
Training loss: 3.0062004228021233
Validation loss: 3.2573033727793783

Epoch: 6| Step: 10
Training loss: 3.4949192226609194
Validation loss: 3.258671008829756

Epoch: 6| Step: 11
Training loss: 3.708564208198117
Validation loss: 3.2571920458833823

Epoch: 6| Step: 12
Training loss: 3.925260868029038
Validation loss: 3.2568245567667424

Epoch: 6| Step: 13
Training loss: 3.8877059832888596
Validation loss: 3.2567771316313423

Epoch: 55| Step: 0
Training loss: 3.1016698093251485
Validation loss: 3.2571238116428347

Epoch: 6| Step: 1
Training loss: 3.153969271155176
Validation loss: 3.257005203305027

Epoch: 6| Step: 2
Training loss: 3.4848551740067
Validation loss: 3.2575650999979775

Epoch: 6| Step: 3
Training loss: 3.7746494155681822
Validation loss: 3.255920866657163

Epoch: 6| Step: 4
Training loss: 4.090034021361978
Validation loss: 3.254135904703361

Epoch: 6| Step: 5
Training loss: 3.5737098873591835
Validation loss: 3.256518551423433

Epoch: 6| Step: 6
Training loss: 3.512507433900399
Validation loss: 3.2545021495428372

Epoch: 6| Step: 7
Training loss: 3.576168941577852
Validation loss: 3.2530717287643705

Epoch: 6| Step: 8
Training loss: 3.1149841016728024
Validation loss: 3.2534476878170566

Epoch: 6| Step: 9
Training loss: 2.9033720471866444
Validation loss: 3.254330795957976

Epoch: 6| Step: 10
Training loss: 3.5102713957629574
Validation loss: 3.2538230881528185

Epoch: 6| Step: 11
Training loss: 3.3338040178497526
Validation loss: 3.25160919245967

Epoch: 6| Step: 12
Training loss: 3.7963605618572376
Validation loss: 3.2515003237329942

Epoch: 6| Step: 13
Training loss: 4.091037696204069
Validation loss: 3.2530356776212868

Epoch: 56| Step: 0
Training loss: 3.234142645262009
Validation loss: 3.252878908110782

Epoch: 6| Step: 1
Training loss: 4.226217033666091
Validation loss: 3.2584526216313057

Epoch: 6| Step: 2
Training loss: 4.112104662412992
Validation loss: 3.254669788070526

Epoch: 6| Step: 3
Training loss: 3.44963041896749
Validation loss: 3.2489396030548794

Epoch: 6| Step: 4
Training loss: 3.42029259729498
Validation loss: 3.2465205297205846

Epoch: 6| Step: 5
Training loss: 3.018263537145669
Validation loss: 3.2478405899138045

Epoch: 6| Step: 6
Training loss: 3.3822061819057376
Validation loss: 3.2477439467939155

Epoch: 6| Step: 7
Training loss: 4.056811061432265
Validation loss: 3.2492142808992908

Epoch: 6| Step: 8
Training loss: 3.549844313955235
Validation loss: 3.248181355642555

Epoch: 6| Step: 9
Training loss: 3.512125401189314
Validation loss: 3.249193719409474

Epoch: 6| Step: 10
Training loss: 3.081800715692875
Validation loss: 3.245996062111193

Epoch: 6| Step: 11
Training loss: 3.093683723741641
Validation loss: 3.2453374839955904

Epoch: 6| Step: 12
Training loss: 3.8655338951976446
Validation loss: 3.243241137655218

Epoch: 6| Step: 13
Training loss: 1.4635601472423152
Validation loss: 3.2411991491374863

Epoch: 57| Step: 0
Training loss: 2.9664840884943304
Validation loss: 3.243129480608269

Epoch: 6| Step: 1
Training loss: 3.280592207596663
Validation loss: 3.2457762312986658

Epoch: 6| Step: 2
Training loss: 3.945191878183934
Validation loss: 3.257426475132269

Epoch: 6| Step: 3
Training loss: 3.5364274410795575
Validation loss: 3.24500988484728

Epoch: 6| Step: 4
Training loss: 4.056804244112455
Validation loss: 3.2399954482104434

Epoch: 6| Step: 5
Training loss: 3.0459585523283867
Validation loss: 3.23411546573126

Epoch: 6| Step: 6
Training loss: 4.235079886123248
Validation loss: 3.236194508002402

Epoch: 6| Step: 7
Training loss: 4.241622746707989
Validation loss: 3.233445729821469

Epoch: 6| Step: 8
Training loss: 3.3348983110884047
Validation loss: 3.2320303554629306

Epoch: 6| Step: 9
Training loss: 3.6829221078765086
Validation loss: 3.232670816996429

Epoch: 6| Step: 10
Training loss: 2.997255341357961
Validation loss: 3.2297730468312174

Epoch: 6| Step: 11
Training loss: 2.468177535888237
Validation loss: 3.2278092949577504

Epoch: 6| Step: 12
Training loss: 3.3779449330206703
Validation loss: 3.2274419798645297

Epoch: 6| Step: 13
Training loss: 2.746268775538913
Validation loss: 3.2248758177502634

Epoch: 58| Step: 0
Training loss: 3.8508847396667485
Validation loss: 3.224291189256745

Epoch: 6| Step: 1
Training loss: 3.008161093588245
Validation loss: 3.2206899091862016

Epoch: 6| Step: 2
Training loss: 3.4314804083170247
Validation loss: 3.2218696027417137

Epoch: 6| Step: 3
Training loss: 3.602518281698332
Validation loss: 3.2182232554872843

Epoch: 6| Step: 4
Training loss: 2.5977986920532534
Validation loss: 3.219779017659162

Epoch: 6| Step: 5
Training loss: 3.502408152866067
Validation loss: 3.2229931989507956

Epoch: 6| Step: 6
Training loss: 4.189244376719503
Validation loss: 3.225691544937067

Epoch: 6| Step: 7
Training loss: 3.2835553018377888
Validation loss: 3.2268927330501675

Epoch: 6| Step: 8
Training loss: 3.770059341044589
Validation loss: 3.2225171799171823

Epoch: 6| Step: 9
Training loss: 2.9017878907583268
Validation loss: 3.2145473363661083

Epoch: 6| Step: 10
Training loss: 3.6875986635618876
Validation loss: 3.2159021293284105

Epoch: 6| Step: 11
Training loss: 3.1448977428605396
Validation loss: 3.217615710034669

Epoch: 6| Step: 12
Training loss: 3.4613119572928186
Validation loss: 3.215840393816648

Epoch: 6| Step: 13
Training loss: 4.012649799533507
Validation loss: 3.2152141947270216

Epoch: 59| Step: 0
Training loss: 3.2182443462326016
Validation loss: 3.2174136012563364

Epoch: 6| Step: 1
Training loss: 3.268360069459933
Validation loss: 3.214124242669415

Epoch: 6| Step: 2
Training loss: 4.102346465255719
Validation loss: 3.2114175089864916

Epoch: 6| Step: 3
Training loss: 3.8577515434680825
Validation loss: 3.211046086546064

Epoch: 6| Step: 4
Training loss: 3.2583004519729526
Validation loss: 3.210726577429615

Epoch: 6| Step: 5
Training loss: 2.5186398844159132
Validation loss: 3.210844502395849

Epoch: 6| Step: 6
Training loss: 2.5314774587653472
Validation loss: 3.215597505903458

Epoch: 6| Step: 7
Training loss: 3.507413641803874
Validation loss: 3.2167826588948243

Epoch: 6| Step: 8
Training loss: 4.071175569785653
Validation loss: 3.217254898347118

Epoch: 6| Step: 9
Training loss: 2.9208621957380494
Validation loss: 3.2148976500208732

Epoch: 6| Step: 10
Training loss: 3.8537419403021587
Validation loss: 3.210449469089206

Epoch: 6| Step: 11
Training loss: 3.948451238320727
Validation loss: 3.2079383011338485

Epoch: 6| Step: 12
Training loss: 3.6835776983014528
Validation loss: 3.2075431936414964

Epoch: 6| Step: 13
Training loss: 3.0017180291807866
Validation loss: 3.2064963074182518

Epoch: 60| Step: 0
Training loss: 3.569743772656098
Validation loss: 3.2047010200667154

Epoch: 6| Step: 1
Training loss: 3.307406558146298
Validation loss: 3.203731758121084

Epoch: 6| Step: 2
Training loss: 2.7260930660087555
Validation loss: 3.201172765939294

Epoch: 6| Step: 3
Training loss: 3.245897197625598
Validation loss: 3.2031029525146124

Epoch: 6| Step: 4
Training loss: 4.1269910226608255
Validation loss: 3.1991476436974993

Epoch: 6| Step: 5
Training loss: 2.7027580585481332
Validation loss: 3.1997506564937606

Epoch: 6| Step: 6
Training loss: 4.281704843681802
Validation loss: 3.198322815613407

Epoch: 6| Step: 7
Training loss: 3.261903677626275
Validation loss: 3.197708811486212

Epoch: 6| Step: 8
Training loss: 2.9479877656555966
Validation loss: 3.1989511832259256

Epoch: 6| Step: 9
Training loss: 2.8994244234510904
Validation loss: 3.200885198301479

Epoch: 6| Step: 10
Training loss: 3.642127516950971
Validation loss: 3.199232962416489

Epoch: 6| Step: 11
Training loss: 3.867926756203822
Validation loss: 3.199817429418113

Epoch: 6| Step: 12
Training loss: 3.9591297486182544
Validation loss: 3.200653284630105

Epoch: 6| Step: 13
Training loss: 3.222045840628107
Validation loss: 3.1979472012010874

Epoch: 61| Step: 0
Training loss: 4.237630008289799
Validation loss: 3.196036351414878

Epoch: 6| Step: 1
Training loss: 3.3978054818198697
Validation loss: 3.197764935624446

Epoch: 6| Step: 2
Training loss: 3.950872571152647
Validation loss: 3.1983803380908915

Epoch: 6| Step: 3
Training loss: 2.797467387455037
Validation loss: 3.1991175159578926

Epoch: 6| Step: 4
Training loss: 3.109281758966309
Validation loss: 3.1998460379473834

Epoch: 6| Step: 5
Training loss: 2.8973380005832983
Validation loss: 3.200137780188211

Epoch: 6| Step: 6
Training loss: 2.765447750984953
Validation loss: 3.1994253430903576

Epoch: 6| Step: 7
Training loss: 3.5668752472634946
Validation loss: 3.1979290180796824

Epoch: 6| Step: 8
Training loss: 3.036192649528964
Validation loss: 3.198494357209618

Epoch: 6| Step: 9
Training loss: 3.7443232484315665
Validation loss: 3.195407896796354

Epoch: 6| Step: 10
Training loss: 3.3505576167831808
Validation loss: 3.195819402842078

Epoch: 6| Step: 11
Training loss: 4.329857655006926
Validation loss: 3.193833151371156

Epoch: 6| Step: 12
Training loss: 2.732827669759167
Validation loss: 3.192054382188904

Epoch: 6| Step: 13
Training loss: 4.070567879014673
Validation loss: 3.1880981942432283

Epoch: 62| Step: 0
Training loss: 3.3562979867015845
Validation loss: 3.186683180963126

Epoch: 6| Step: 1
Training loss: 3.426249177439277
Validation loss: 3.1844207798702393

Epoch: 6| Step: 2
Training loss: 3.2656419379420187
Validation loss: 3.1826036725683022

Epoch: 6| Step: 3
Training loss: 3.659170695920698
Validation loss: 3.1833211750283037

Epoch: 6| Step: 4
Training loss: 3.102490341577243
Validation loss: 3.1831552249394686

Epoch: 6| Step: 5
Training loss: 3.529963301124758
Validation loss: 3.182348746910002

Epoch: 6| Step: 6
Training loss: 3.7586709546834576
Validation loss: 3.1826491501092677

Epoch: 6| Step: 7
Training loss: 3.7788698886701626
Validation loss: 3.181905800235345

Epoch: 6| Step: 8
Training loss: 3.1675692493362826
Validation loss: 3.1788852938772787

Epoch: 6| Step: 9
Training loss: 3.8070806539622883
Validation loss: 3.18078318905551

Epoch: 6| Step: 10
Training loss: 3.8118967298146957
Validation loss: 3.1786186367043703

Epoch: 6| Step: 11
Training loss: 3.051281837881747
Validation loss: 3.1770737998707745

Epoch: 6| Step: 12
Training loss: 2.8899657451355094
Validation loss: 3.1780917811259117

Epoch: 6| Step: 13
Training loss: 3.2521292240701736
Validation loss: 3.1785244410614037

Epoch: 63| Step: 0
Training loss: 2.9579118956778907
Validation loss: 3.177525071061115

Epoch: 6| Step: 1
Training loss: 3.762847255764555
Validation loss: 3.1775301619916627

Epoch: 6| Step: 2
Training loss: 3.055740526168582
Validation loss: 3.1780928781838016

Epoch: 6| Step: 3
Training loss: 3.8726699961221516
Validation loss: 3.175618109215827

Epoch: 6| Step: 4
Training loss: 3.6030897762432934
Validation loss: 3.1770264979375313

Epoch: 6| Step: 5
Training loss: 3.5553037004545507
Validation loss: 3.174541825513774

Epoch: 6| Step: 6
Training loss: 3.2613510564175394
Validation loss: 3.173002060483402

Epoch: 6| Step: 7
Training loss: 3.6393797222292212
Validation loss: 3.1720769326815765

Epoch: 6| Step: 8
Training loss: 2.9251719758429306
Validation loss: 3.173518886144484

Epoch: 6| Step: 9
Training loss: 2.7723467334042624
Validation loss: 3.173057078461928

Epoch: 6| Step: 10
Training loss: 3.2429289555985603
Validation loss: 3.171691354159073

Epoch: 6| Step: 11
Training loss: 3.90613940273121
Validation loss: 3.173549809447266

Epoch: 6| Step: 12
Training loss: 3.1978337942976567
Validation loss: 3.170966050823098

Epoch: 6| Step: 13
Training loss: 4.344488945549068
Validation loss: 3.1698931306548146

Epoch: 64| Step: 0
Training loss: 3.241479709075117
Validation loss: 3.168153110087865

Epoch: 6| Step: 1
Training loss: 3.5067351796041066
Validation loss: 3.1711938598389326

Epoch: 6| Step: 2
Training loss: 3.5121619228148226
Validation loss: 3.17029863781465

Epoch: 6| Step: 3
Training loss: 3.4696873953337484
Validation loss: 3.1719219641343344

Epoch: 6| Step: 4
Training loss: 2.6492903244982844
Validation loss: 3.1719944380463008

Epoch: 6| Step: 5
Training loss: 3.6473452385013347
Validation loss: 3.1748235327750542

Epoch: 6| Step: 6
Training loss: 3.824022983609644
Validation loss: 3.167913871860226

Epoch: 6| Step: 7
Training loss: 3.8027943124931016
Validation loss: 3.1707251579323654

Epoch: 6| Step: 8
Training loss: 3.54297655603123
Validation loss: 3.1658364153682186

Epoch: 6| Step: 9
Training loss: 2.9872777113954436
Validation loss: 3.167711982949261

Epoch: 6| Step: 10
Training loss: 3.57526533302608
Validation loss: 3.1668806543462478

Epoch: 6| Step: 11
Training loss: 2.7824299056143325
Validation loss: 3.168316107689395

Epoch: 6| Step: 12
Training loss: 3.5588842413679362
Validation loss: 3.165915204657983

Epoch: 6| Step: 13
Training loss: 3.823759244251082
Validation loss: 3.1656699034006293

Epoch: 65| Step: 0
Training loss: 2.6135016606414814
Validation loss: 3.1658233292472517

Epoch: 6| Step: 1
Training loss: 3.30240980072785
Validation loss: 3.167382807514172

Epoch: 6| Step: 2
Training loss: 3.742690528397642
Validation loss: 3.1659317561681233

Epoch: 6| Step: 3
Training loss: 3.6909548851858838
Validation loss: 3.1667477193108455

Epoch: 6| Step: 4
Training loss: 4.010949407425352
Validation loss: 3.1649102152381987

Epoch: 6| Step: 5
Training loss: 2.7998933329019273
Validation loss: 3.1644306867497427

Epoch: 6| Step: 6
Training loss: 4.129923338836687
Validation loss: 3.164614221701792

Epoch: 6| Step: 7
Training loss: 3.2998990476945784
Validation loss: 3.162327616381086

Epoch: 6| Step: 8
Training loss: 2.957318915581651
Validation loss: 3.1633841122197777

Epoch: 6| Step: 9
Training loss: 3.6819394099167817
Validation loss: 3.166881112532284

Epoch: 6| Step: 10
Training loss: 4.199786934670717
Validation loss: 3.163190127154352

Epoch: 6| Step: 11
Training loss: 3.167290140981436
Validation loss: 3.1634999737190683

Epoch: 6| Step: 12
Training loss: 2.9971444526916438
Validation loss: 3.1657020249714223

Epoch: 6| Step: 13
Training loss: 2.2137964318961716
Validation loss: 3.1696606203888247

Epoch: 66| Step: 0
Training loss: 3.042183418447522
Validation loss: 3.1666460009571433

Epoch: 6| Step: 1
Training loss: 3.4081119033279217
Validation loss: 3.1652496877626755

Epoch: 6| Step: 2
Training loss: 2.9862061320324624
Validation loss: 3.1638061614057196

Epoch: 6| Step: 3
Training loss: 3.097360219195309
Validation loss: 3.165452767124591

Epoch: 6| Step: 4
Training loss: 4.1284627540906875
Validation loss: 3.16548231226219

Epoch: 6| Step: 5
Training loss: 3.2822243833208327
Validation loss: 3.1639642037563536

Epoch: 6| Step: 6
Training loss: 3.5735843283007958
Validation loss: 3.163679566904712

Epoch: 6| Step: 7
Training loss: 3.861130535220192
Validation loss: 3.16374444004796

Epoch: 6| Step: 8
Training loss: 2.70724059337208
Validation loss: 3.1631416636768903

Epoch: 6| Step: 9
Training loss: 3.804771218759363
Validation loss: 3.164513977241719

Epoch: 6| Step: 10
Training loss: 3.697974893174219
Validation loss: 3.162244372883129

Epoch: 6| Step: 11
Training loss: 3.2273356178788855
Validation loss: 3.1618674205953528

Epoch: 6| Step: 12
Training loss: 3.5083824323418535
Validation loss: 3.1640271313350348

Epoch: 6| Step: 13
Training loss: 3.1601634927296485
Validation loss: 3.1639175906484382

Epoch: 67| Step: 0
Training loss: 3.0067490320138317
Validation loss: 3.1625858541178493

Epoch: 6| Step: 1
Training loss: 3.871475955329294
Validation loss: 3.1620850998047274

Epoch: 6| Step: 2
Training loss: 2.8226035156729776
Validation loss: 3.1592025535638344

Epoch: 6| Step: 3
Training loss: 3.8879502995458006
Validation loss: 3.156739678496887

Epoch: 6| Step: 4
Training loss: 4.049933614304491
Validation loss: 3.1582572952101455

Epoch: 6| Step: 5
Training loss: 3.0391227500454385
Validation loss: 3.1575662684103487

Epoch: 6| Step: 6
Training loss: 3.1644502378647643
Validation loss: 3.1570986249878783

Epoch: 6| Step: 7
Training loss: 3.4985961823554863
Validation loss: 3.156007013153087

Epoch: 6| Step: 8
Training loss: 2.8184333944877635
Validation loss: 3.157050657539152

Epoch: 6| Step: 9
Training loss: 4.1822750460182405
Validation loss: 3.153993389352772

Epoch: 6| Step: 10
Training loss: 3.429022722402042
Validation loss: 3.1549799445289235

Epoch: 6| Step: 11
Training loss: 2.3584792097645986
Validation loss: 3.1530290525520273

Epoch: 6| Step: 12
Training loss: 3.7397404516396433
Validation loss: 3.153178612031417

Epoch: 6| Step: 13
Training loss: 3.400153768091596
Validation loss: 3.152590449212361

Epoch: 68| Step: 0
Training loss: 3.3290266508053765
Validation loss: 3.151061336110509

Epoch: 6| Step: 1
Training loss: 2.4050253191465747
Validation loss: 3.1526693597393836

Epoch: 6| Step: 2
Training loss: 3.80486922251147
Validation loss: 3.1525547680599284

Epoch: 6| Step: 3
Training loss: 2.742785092525796
Validation loss: 3.154798360886532

Epoch: 6| Step: 4
Training loss: 3.313779763656825
Validation loss: 3.153997528248432

Epoch: 6| Step: 5
Training loss: 3.6055831477737765
Validation loss: 3.153493475339459

Epoch: 6| Step: 6
Training loss: 3.607904836630349
Validation loss: 3.1545512248322205

Epoch: 6| Step: 7
Training loss: 3.761473714071115
Validation loss: 3.153412893637888

Epoch: 6| Step: 8
Training loss: 3.2399950818624963
Validation loss: 3.1521103583938865

Epoch: 6| Step: 9
Training loss: 3.593136809736569
Validation loss: 3.1514577174817346

Epoch: 6| Step: 10
Training loss: 3.3778660225913564
Validation loss: 3.150782492804933

Epoch: 6| Step: 11
Training loss: 3.820942270992436
Validation loss: 3.151944717098469

Epoch: 6| Step: 12
Training loss: 3.818621114750399
Validation loss: 3.1522861242704097

Epoch: 6| Step: 13
Training loss: 2.63770453215947
Validation loss: 3.1531535932575663

Epoch: 69| Step: 0
Training loss: 3.272406295005974
Validation loss: 3.1534274653384973

Epoch: 6| Step: 1
Training loss: 3.204043670661475
Validation loss: 3.153870473380565

Epoch: 6| Step: 2
Training loss: 3.6994773186262777
Validation loss: 3.152745630448741

Epoch: 6| Step: 3
Training loss: 3.0975723543868385
Validation loss: 3.1523504202618478

Epoch: 6| Step: 4
Training loss: 3.6393954447807966
Validation loss: 3.1540751697381575

Epoch: 6| Step: 5
Training loss: 3.476994108347033
Validation loss: 3.1521213071445247

Epoch: 6| Step: 6
Training loss: 3.8356396468182643
Validation loss: 3.1515440913622865

Epoch: 6| Step: 7
Training loss: 3.431069758116059
Validation loss: 3.1534233468318615

Epoch: 6| Step: 8
Training loss: 3.552058931119596
Validation loss: 3.150360799174397

Epoch: 6| Step: 9
Training loss: 3.278486559541422
Validation loss: 3.148205414868527

Epoch: 6| Step: 10
Training loss: 3.509991145543942
Validation loss: 3.147077200556646

Epoch: 6| Step: 11
Training loss: 3.448544463351234
Validation loss: 3.14951161141855

Epoch: 6| Step: 12
Training loss: 3.178614779891598
Validation loss: 3.146240189050263

Epoch: 6| Step: 13
Training loss: 2.705326837336658
Validation loss: 3.148538998074905

Epoch: 70| Step: 0
Training loss: 3.7636860647760533
Validation loss: 3.150333422509152

Epoch: 6| Step: 1
Training loss: 2.1688921087576376
Validation loss: 3.1479353346874817

Epoch: 6| Step: 2
Training loss: 3.0775136582592872
Validation loss: 3.146340732174471

Epoch: 6| Step: 3
Training loss: 3.0146210733796135
Validation loss: 3.1479625856194473

Epoch: 6| Step: 4
Training loss: 3.132143172683364
Validation loss: 3.1452525210552285

Epoch: 6| Step: 5
Training loss: 3.691156675590968
Validation loss: 3.1460698204628095

Epoch: 6| Step: 6
Training loss: 3.692880487486813
Validation loss: 3.1448244692263816

Epoch: 6| Step: 7
Training loss: 3.8138180314869405
Validation loss: 3.14594602936453

Epoch: 6| Step: 8
Training loss: 3.840828630529068
Validation loss: 3.1443063400630322

Epoch: 6| Step: 9
Training loss: 3.756877187964006
Validation loss: 3.1446479667169434

Epoch: 6| Step: 10
Training loss: 2.30802339844107
Validation loss: 3.143366444513718

Epoch: 6| Step: 11
Training loss: 3.283052512486459
Validation loss: 3.144898502603138

Epoch: 6| Step: 12
Training loss: 3.876432707711376
Validation loss: 3.1441911239687985

Epoch: 6| Step: 13
Training loss: 3.8450807578308055
Validation loss: 3.1447582617697796

Epoch: 71| Step: 0
Training loss: 3.7914226299744045
Validation loss: 3.1527553019854024

Epoch: 6| Step: 1
Training loss: 3.003027659733102
Validation loss: 3.149658117966266

Epoch: 6| Step: 2
Training loss: 2.8929335165286267
Validation loss: 3.1612225697506133

Epoch: 6| Step: 3
Training loss: 2.9766496460340064
Validation loss: 3.1437034174054754

Epoch: 6| Step: 4
Training loss: 4.159158248469927
Validation loss: 3.152757341347173

Epoch: 6| Step: 5
Training loss: 3.426354389681039
Validation loss: 3.146455579496469

Epoch: 6| Step: 6
Training loss: 3.883543256616718
Validation loss: 3.1480397586660565

Epoch: 6| Step: 7
Training loss: 2.8742895492456624
Validation loss: 3.1447257314331

Epoch: 6| Step: 8
Training loss: 3.868967960362053
Validation loss: 3.145948108996119

Epoch: 6| Step: 9
Training loss: 3.0855369597653706
Validation loss: 3.1441947767694467

Epoch: 6| Step: 10
Training loss: 3.9155038094850942
Validation loss: 3.1439258850551064

Epoch: 6| Step: 11
Training loss: 3.0504678523707094
Validation loss: 3.1436798155716046

Epoch: 6| Step: 12
Training loss: 3.0964103588826375
Validation loss: 3.1459789447514668

Epoch: 6| Step: 13
Training loss: 3.2298108022449767
Validation loss: 3.1466442397598318

Epoch: 72| Step: 0
Training loss: 4.215779028383972
Validation loss: 3.14596715972653

Epoch: 6| Step: 1
Training loss: 3.462492100675641
Validation loss: 3.1464610115697758

Epoch: 6| Step: 2
Training loss: 3.6000849078020076
Validation loss: 3.14406809222911

Epoch: 6| Step: 3
Training loss: 4.024270099304136
Validation loss: 3.147638829756486

Epoch: 6| Step: 4
Training loss: 3.396915629967742
Validation loss: 3.1448792823632603

Epoch: 6| Step: 5
Training loss: 2.8048955898606156
Validation loss: 3.140506125636858

Epoch: 6| Step: 6
Training loss: 3.3067228213536044
Validation loss: 3.137592273167976

Epoch: 6| Step: 7
Training loss: 3.1499628579508245
Validation loss: 3.138658399135842

Epoch: 6| Step: 8
Training loss: 3.2642568250106954
Validation loss: 3.137704561444315

Epoch: 6| Step: 9
Training loss: 3.655295353343998
Validation loss: 3.139604303338797

Epoch: 6| Step: 10
Training loss: 3.5593913385218867
Validation loss: 3.1362567289031547

Epoch: 6| Step: 11
Training loss: 3.0317284904441077
Validation loss: 3.1373162686157583

Epoch: 6| Step: 12
Training loss: 2.849977151879529
Validation loss: 3.138780251564818

Epoch: 6| Step: 13
Training loss: 2.5551153635455703
Validation loss: 3.1437423956801958

Epoch: 73| Step: 0
Training loss: 2.981213877716992
Validation loss: 3.1459531467186657

Epoch: 6| Step: 1
Training loss: 4.095613244870968
Validation loss: 3.1392883956808477

Epoch: 6| Step: 2
Training loss: 3.0274921208601215
Validation loss: 3.1358671793056296

Epoch: 6| Step: 3
Training loss: 4.318528536516012
Validation loss: 3.135890231708298

Epoch: 6| Step: 4
Training loss: 3.5907329333942957
Validation loss: 3.1357617662378567

Epoch: 6| Step: 5
Training loss: 3.041748742515998
Validation loss: 3.1374078495625706

Epoch: 6| Step: 6
Training loss: 3.827441594371519
Validation loss: 3.137779153347058

Epoch: 6| Step: 7
Training loss: 2.6238756042337297
Validation loss: 3.1406391004510015

Epoch: 6| Step: 8
Training loss: 3.6022550037102277
Validation loss: 3.1430185284814347

Epoch: 6| Step: 9
Training loss: 2.953529935655054
Validation loss: 3.1428627527637274

Epoch: 6| Step: 10
Training loss: 3.368105734399997
Validation loss: 3.144918118897846

Epoch: 6| Step: 11
Training loss: 3.652193345833646
Validation loss: 3.1431869516371145

Epoch: 6| Step: 12
Training loss: 3.586571199028153
Validation loss: 3.1405680996209466

Epoch: 6| Step: 13
Training loss: 1.3159934735266765
Validation loss: 3.1383348585182835

Epoch: 74| Step: 0
Training loss: 3.326016900153242
Validation loss: 3.14110938124281

Epoch: 6| Step: 1
Training loss: 3.0236668068526176
Validation loss: 3.138704721283136

Epoch: 6| Step: 2
Training loss: 3.5466588160301264
Validation loss: 3.138976686801983

Epoch: 6| Step: 3
Training loss: 3.446950510119614
Validation loss: 3.135770409359837

Epoch: 6| Step: 4
Training loss: 3.596436930741558
Validation loss: 3.1373804660969764

Epoch: 6| Step: 5
Training loss: 4.070303362288807
Validation loss: 3.1337369693750388

Epoch: 6| Step: 6
Training loss: 3.8549121582472843
Validation loss: 3.1342099102737793

Epoch: 6| Step: 7
Training loss: 3.595899652169354
Validation loss: 3.1335496828646336

Epoch: 6| Step: 8
Training loss: 2.283712756057328
Validation loss: 3.1318580127358615

Epoch: 6| Step: 9
Training loss: 3.09860803670563
Validation loss: 3.13124067749577

Epoch: 6| Step: 10
Training loss: 3.1562910927089827
Validation loss: 3.1338107951181216

Epoch: 6| Step: 11
Training loss: 3.870465609710246
Validation loss: 3.1332869500981895

Epoch: 6| Step: 12
Training loss: 2.921424708628657
Validation loss: 3.1353580424539005

Epoch: 6| Step: 13
Training loss: 3.3235186726100245
Validation loss: 3.1383507484132904

Epoch: 75| Step: 0
Training loss: 2.9573888927752385
Validation loss: 3.136635300912306

Epoch: 6| Step: 1
Training loss: 3.960290257769151
Validation loss: 3.14513159715

Epoch: 6| Step: 2
Training loss: 3.1567083347018263
Validation loss: 3.133406657964838

Epoch: 6| Step: 3
Training loss: 3.989662641064023
Validation loss: 3.1313796620136523

Epoch: 6| Step: 4
Training loss: 2.9451020264236893
Validation loss: 3.1277640393562067

Epoch: 6| Step: 5
Training loss: 3.479268664541943
Validation loss: 3.126292657424321

Epoch: 6| Step: 6
Training loss: 3.497575737744612
Validation loss: 3.1252655950091643

Epoch: 6| Step: 7
Training loss: 3.367238763476506
Validation loss: 3.124662260447456

Epoch: 6| Step: 8
Training loss: 3.5401974641285157
Validation loss: 3.1193117460827318

Epoch: 6| Step: 9
Training loss: 3.957906492542609
Validation loss: 3.1211839087624704

Epoch: 6| Step: 10
Training loss: 2.6197536357042983
Validation loss: 3.11866572768025

Epoch: 6| Step: 11
Training loss: 2.2736620185863075
Validation loss: 3.117243861650274

Epoch: 6| Step: 12
Training loss: 3.4658082051951107
Validation loss: 3.1208442735003112

Epoch: 6| Step: 13
Training loss: 3.9884842569691585
Validation loss: 3.131725631023681

Epoch: 76| Step: 0
Training loss: 3.6913547088415677
Validation loss: 3.13963752037486

Epoch: 6| Step: 1
Training loss: 2.3830910441702993
Validation loss: 3.1238853878686625

Epoch: 6| Step: 2
Training loss: 3.526438177551504
Validation loss: 3.1195244380990506

Epoch: 6| Step: 3
Training loss: 3.6205056051319673
Validation loss: 3.1152927980188627

Epoch: 6| Step: 4
Training loss: 2.937210718073895
Validation loss: 3.113687059045409

Epoch: 6| Step: 5
Training loss: 3.505370923711951
Validation loss: 3.1174456818191763

Epoch: 6| Step: 6
Training loss: 3.337713479061758
Validation loss: 3.1181097844385715

Epoch: 6| Step: 7
Training loss: 3.6131498075754376
Validation loss: 3.11905648369617

Epoch: 6| Step: 8
Training loss: 3.9428599373390925
Validation loss: 3.1180532986678844

Epoch: 6| Step: 9
Training loss: 3.041894059412485
Validation loss: 3.1202247805591425

Epoch: 6| Step: 10
Training loss: 3.3929335650104773
Validation loss: 3.118741083195073

Epoch: 6| Step: 11
Training loss: 3.2551334626806443
Validation loss: 3.124168318960123

Epoch: 6| Step: 12
Training loss: 3.2619465091700266
Validation loss: 3.1214045343772643

Epoch: 6| Step: 13
Training loss: 3.73047194555655
Validation loss: 3.1181706644658034

Epoch: 77| Step: 0
Training loss: 3.57280512302918
Validation loss: 3.1159090812103325

Epoch: 6| Step: 1
Training loss: 3.765796958194464
Validation loss: 3.1140532962237506

Epoch: 6| Step: 2
Training loss: 2.8963549759320673
Validation loss: 3.112167427806821

Epoch: 6| Step: 3
Training loss: 3.3376420465880314
Validation loss: 3.114009607750033

Epoch: 6| Step: 4
Training loss: 3.202610476968359
Validation loss: 3.110613163296936

Epoch: 6| Step: 5
Training loss: 2.337986484433048
Validation loss: 3.1102242858162894

Epoch: 6| Step: 6
Training loss: 2.569488114910917
Validation loss: 3.11106720070339

Epoch: 6| Step: 7
Training loss: 3.8873415654024996
Validation loss: 3.1076927422529903

Epoch: 6| Step: 8
Training loss: 2.443445437445642
Validation loss: 3.108603825575104

Epoch: 6| Step: 9
Training loss: 4.098527988332223
Validation loss: 3.107901440185057

Epoch: 6| Step: 10
Training loss: 4.100534422864974
Validation loss: 3.1068981090156256

Epoch: 6| Step: 11
Training loss: 3.0521637230051746
Validation loss: 3.1091400996022323

Epoch: 6| Step: 12
Training loss: 3.986525011597296
Validation loss: 3.108084755744929

Epoch: 6| Step: 13
Training loss: 3.240442160117413
Validation loss: 3.1084074305224885

Epoch: 78| Step: 0
Training loss: 2.896449967924012
Validation loss: 3.108667410325641

Epoch: 6| Step: 1
Training loss: 2.386734533179708
Validation loss: 3.106675640378256

Epoch: 6| Step: 2
Training loss: 2.7917032856223876
Validation loss: 3.1067867883945888

Epoch: 6| Step: 3
Training loss: 3.8250306371322047
Validation loss: 3.105245475561907

Epoch: 6| Step: 4
Training loss: 3.8444204598586995
Validation loss: 3.1067135269054598

Epoch: 6| Step: 5
Training loss: 3.0935223428213137
Validation loss: 3.1086166115732246

Epoch: 6| Step: 6
Training loss: 2.9105153931074863
Validation loss: 3.1102841695446974

Epoch: 6| Step: 7
Training loss: 4.055681816005267
Validation loss: 3.1075462627388433

Epoch: 6| Step: 8
Training loss: 3.8546835612882693
Validation loss: 3.108020753249739

Epoch: 6| Step: 9
Training loss: 3.18101754828814
Validation loss: 3.103084748682893

Epoch: 6| Step: 10
Training loss: 2.781064488085389
Validation loss: 3.102650023235895

Epoch: 6| Step: 11
Training loss: 3.870745753901335
Validation loss: 3.103205282904406

Epoch: 6| Step: 12
Training loss: 3.983027690403311
Validation loss: 3.1011506816641727

Epoch: 6| Step: 13
Training loss: 3.0258419914265313
Validation loss: 3.1020983004352356

Epoch: 79| Step: 0
Training loss: 3.5631796205325816
Validation loss: 3.1031406956494973

Epoch: 6| Step: 1
Training loss: 3.2959194154424982
Validation loss: 3.102768634327528

Epoch: 6| Step: 2
Training loss: 3.1957634418774536
Validation loss: 3.1022621275541664

Epoch: 6| Step: 3
Training loss: 3.233192411937066
Validation loss: 3.1017443702088925

Epoch: 6| Step: 4
Training loss: 3.5899644899870076
Validation loss: 3.102139014648163

Epoch: 6| Step: 5
Training loss: 3.6679300096962417
Validation loss: 3.100772767765642

Epoch: 6| Step: 6
Training loss: 3.073828162230747
Validation loss: 3.101616114625711

Epoch: 6| Step: 7
Training loss: 3.0765212475213293
Validation loss: 3.1007608109261278

Epoch: 6| Step: 8
Training loss: 3.4092160531396165
Validation loss: 3.1035755506135545

Epoch: 6| Step: 9
Training loss: 3.33332811990966
Validation loss: 3.102944925598711

Epoch: 6| Step: 10
Training loss: 2.853148638490521
Validation loss: 3.102031389325768

Epoch: 6| Step: 11
Training loss: 3.515646294423356
Validation loss: 3.101165624587377

Epoch: 6| Step: 12
Training loss: 3.372064231957666
Validation loss: 3.099793132967948

Epoch: 6| Step: 13
Training loss: 4.197122932660567
Validation loss: 3.0986727250557995

Epoch: 80| Step: 0
Training loss: 4.073156845673037
Validation loss: 3.099148821471915

Epoch: 6| Step: 1
Training loss: 3.3703282836487887
Validation loss: 3.1001157412852347

Epoch: 6| Step: 2
Training loss: 3.3829396424396414
Validation loss: 3.099163798863405

Epoch: 6| Step: 3
Training loss: 3.2796862554525092
Validation loss: 3.0970617719923985

Epoch: 6| Step: 4
Training loss: 3.7117888106581116
Validation loss: 3.096431881924681

Epoch: 6| Step: 5
Training loss: 3.1583809787776542
Validation loss: 3.095853948407879

Epoch: 6| Step: 6
Training loss: 3.3772696881156303
Validation loss: 3.1056206626108054

Epoch: 6| Step: 7
Training loss: 3.6893993593885495
Validation loss: 3.0994356905401013

Epoch: 6| Step: 8
Training loss: 2.8119945495791403
Validation loss: 3.096138600634173

Epoch: 6| Step: 9
Training loss: 3.0646955444068547
Validation loss: 3.095182168332028

Epoch: 6| Step: 10
Training loss: 3.351184032207812
Validation loss: 3.094379305110823

Epoch: 6| Step: 11
Training loss: 3.310202899718488
Validation loss: 3.095374070443907

Epoch: 6| Step: 12
Training loss: 3.3640691563123593
Validation loss: 3.0959181676507184

Epoch: 6| Step: 13
Training loss: 2.6022849239776806
Validation loss: 3.096262257651692

Epoch: 81| Step: 0
Training loss: 3.8188626087024273
Validation loss: 3.095459243082098

Epoch: 6| Step: 1
Training loss: 3.779759262936516
Validation loss: 3.0964025215968274

Epoch: 6| Step: 2
Training loss: 4.588647824581031
Validation loss: 3.09637376042596

Epoch: 6| Step: 3
Training loss: 3.3225159278872467
Validation loss: 3.0943134549247198

Epoch: 6| Step: 4
Training loss: 2.5724632285764417
Validation loss: 3.0934505332209943

Epoch: 6| Step: 5
Training loss: 2.883028182565138
Validation loss: 3.092551814649849

Epoch: 6| Step: 6
Training loss: 2.4103206535170782
Validation loss: 3.093101934922108

Epoch: 6| Step: 7
Training loss: 2.5984495858870784
Validation loss: 3.0930862816909594

Epoch: 6| Step: 8
Training loss: 3.8386064555869783
Validation loss: 3.09321093262424

Epoch: 6| Step: 9
Training loss: 3.4130336861164903
Validation loss: 3.0926179029531156

Epoch: 6| Step: 10
Training loss: 2.700200875192055
Validation loss: 3.0946202633222923

Epoch: 6| Step: 11
Training loss: 3.3021262052783413
Validation loss: 3.091729020378648

Epoch: 6| Step: 12
Training loss: 3.6297027075223554
Validation loss: 3.09309914675309

Epoch: 6| Step: 13
Training loss: 3.516700546197873
Validation loss: 3.0917193942599708

Epoch: 82| Step: 0
Training loss: 3.481316699719392
Validation loss: 3.093195535215106

Epoch: 6| Step: 1
Training loss: 3.7609461924916423
Validation loss: 3.0923830196218196

Epoch: 6| Step: 2
Training loss: 3.1412252734995096
Validation loss: 3.0908005784726065

Epoch: 6| Step: 3
Training loss: 3.4398206333593992
Validation loss: 3.091574434174369

Epoch: 6| Step: 4
Training loss: 3.8088973486766937
Validation loss: 3.0894708076084605

Epoch: 6| Step: 5
Training loss: 3.092299921074908
Validation loss: 3.0918950859007475

Epoch: 6| Step: 6
Training loss: 3.560502680317465
Validation loss: 3.0900587076079966

Epoch: 6| Step: 7
Training loss: 2.774423343437486
Validation loss: 3.0914491060848728

Epoch: 6| Step: 8
Training loss: 3.1060362099466903
Validation loss: 3.090548379580115

Epoch: 6| Step: 9
Training loss: 2.869083287112145
Validation loss: 3.0896307439596615

Epoch: 6| Step: 10
Training loss: 3.386201002766985
Validation loss: 3.08879468287824

Epoch: 6| Step: 11
Training loss: 3.4288452782710652
Validation loss: 3.0900924705100024

Epoch: 6| Step: 12
Training loss: 3.9439131568493657
Validation loss: 3.0890311403698547

Epoch: 6| Step: 13
Training loss: 2.709984867574524
Validation loss: 3.0882021259045525

Epoch: 83| Step: 0
Training loss: 2.5223382498352658
Validation loss: 3.0898890346460397

Epoch: 6| Step: 1
Training loss: 3.306238987116509
Validation loss: 3.0896678910970277

Epoch: 6| Step: 2
Training loss: 2.6149995226886964
Validation loss: 3.088614108612167

Epoch: 6| Step: 3
Training loss: 3.595459108708174
Validation loss: 3.0893539928965392

Epoch: 6| Step: 4
Training loss: 3.6480889164060124
Validation loss: 3.0909759756518613

Epoch: 6| Step: 5
Training loss: 3.590615937675547
Validation loss: 3.088203092187558

Epoch: 6| Step: 6
Training loss: 3.6849928269128847
Validation loss: 3.090077739523127

Epoch: 6| Step: 7
Training loss: 2.7560577429326747
Validation loss: 3.0891686778557697

Epoch: 6| Step: 8
Training loss: 2.346074693458236
Validation loss: 3.087316171604686

Epoch: 6| Step: 9
Training loss: 3.6572809314633608
Validation loss: 3.087452131862394

Epoch: 6| Step: 10
Training loss: 3.9780557223368667
Validation loss: 3.0878492347396764

Epoch: 6| Step: 11
Training loss: 3.796153938050262
Validation loss: 3.0860757036935467

Epoch: 6| Step: 12
Training loss: 3.419308470697788
Validation loss: 3.0851350828566897

Epoch: 6| Step: 13
Training loss: 3.651088103009499
Validation loss: 3.0865165411229394

Epoch: 84| Step: 0
Training loss: 2.9367950892287604
Validation loss: 3.083974311562448

Epoch: 6| Step: 1
Training loss: 3.6274883017164035
Validation loss: 3.0856795049828536

Epoch: 6| Step: 2
Training loss: 3.615229626718924
Validation loss: 3.084108356416556

Epoch: 6| Step: 3
Training loss: 2.6967424662923216
Validation loss: 3.08360445454129

Epoch: 6| Step: 4
Training loss: 3.051046635884286
Validation loss: 3.0835309041543084

Epoch: 6| Step: 5
Training loss: 4.014870658111813
Validation loss: 3.0823998128640357

Epoch: 6| Step: 6
Training loss: 3.848499867858924
Validation loss: 3.084996771375388

Epoch: 6| Step: 7
Training loss: 3.018605552992657
Validation loss: 3.08095974897876

Epoch: 6| Step: 8
Training loss: 3.2317683086441757
Validation loss: 3.0842154941781756

Epoch: 6| Step: 9
Training loss: 3.894589285002019
Validation loss: 3.086025122876609

Epoch: 6| Step: 10
Training loss: 3.223409002994491
Validation loss: 3.0828845443861477

Epoch: 6| Step: 11
Training loss: 3.4372781855369325
Validation loss: 3.082703056758857

Epoch: 6| Step: 12
Training loss: 2.9841746317922193
Validation loss: 3.082320724395971

Epoch: 6| Step: 13
Training loss: 2.759344091706717
Validation loss: 3.0814054091221377

Epoch: 85| Step: 0
Training loss: 3.386515434172517
Validation loss: 3.0816167633316747

Epoch: 6| Step: 1
Training loss: 3.9996565432914903
Validation loss: 3.0818013321044138

Epoch: 6| Step: 2
Training loss: 3.590446214067728
Validation loss: 3.0820886188696495

Epoch: 6| Step: 3
Training loss: 3.669663043027961
Validation loss: 3.0817091643164707

Epoch: 6| Step: 4
Training loss: 2.408601181904738
Validation loss: 3.079759203012322

Epoch: 6| Step: 5
Training loss: 3.983494201242242
Validation loss: 3.0813190942264366

Epoch: 6| Step: 6
Training loss: 3.2880450416969698
Validation loss: 3.080278218894176

Epoch: 6| Step: 7
Training loss: 3.4464259002923674
Validation loss: 3.079023963787142

Epoch: 6| Step: 8
Training loss: 2.9244331136572232
Validation loss: 3.079576091868034

Epoch: 6| Step: 9
Training loss: 3.8024637667743577
Validation loss: 3.0795406561082013

Epoch: 6| Step: 10
Training loss: 2.807138206425388
Validation loss: 3.0804239219506773

Epoch: 6| Step: 11
Training loss: 3.5173955231355936
Validation loss: 3.079327743264473

Epoch: 6| Step: 12
Training loss: 2.310055652294814
Validation loss: 3.079761503809106

Epoch: 6| Step: 13
Training loss: 3.1167798074459845
Validation loss: 3.0784887941404055

Epoch: 86| Step: 0
Training loss: 2.2452318743815236
Validation loss: 3.0777680180817413

Epoch: 6| Step: 1
Training loss: 4.139921999578936
Validation loss: 3.0803894072531026

Epoch: 6| Step: 2
Training loss: 3.15087402570374
Validation loss: 3.083864698932695

Epoch: 6| Step: 3
Training loss: 3.259978308576254
Validation loss: 3.082619176659168

Epoch: 6| Step: 4
Training loss: 3.405636233407331
Validation loss: 3.0830255242256928

Epoch: 6| Step: 5
Training loss: 4.237088955998555
Validation loss: 3.086051561442116

Epoch: 6| Step: 6
Training loss: 4.246135525467218
Validation loss: 3.079893241536193

Epoch: 6| Step: 7
Training loss: 3.5687412669380616
Validation loss: 3.07707712474696

Epoch: 6| Step: 8
Training loss: 3.0134024063847127
Validation loss: 3.0772905232086

Epoch: 6| Step: 9
Training loss: 3.2746199700394474
Validation loss: 3.0826593880302218

Epoch: 6| Step: 10
Training loss: 3.140453125155481
Validation loss: 3.0832363516386625

Epoch: 6| Step: 11
Training loss: 2.970056025686272
Validation loss: 3.0841104303648406

Epoch: 6| Step: 12
Training loss: 2.2905362433376726
Validation loss: 3.0920552351314505

Epoch: 6| Step: 13
Training loss: 3.0848086839704045
Validation loss: 3.089902044110163

Epoch: 87| Step: 0
Training loss: 3.6129111930434106
Validation loss: 3.0865225296964023

Epoch: 6| Step: 1
Training loss: 3.52884612506202
Validation loss: 3.0848945954088043

Epoch: 6| Step: 2
Training loss: 2.9746553814461767
Validation loss: 3.0832257428032013

Epoch: 6| Step: 3
Training loss: 2.5938416430358133
Validation loss: 3.0762285431048326

Epoch: 6| Step: 4
Training loss: 3.9061263408161135
Validation loss: 3.0756876825746122

Epoch: 6| Step: 5
Training loss: 3.3275754949544845
Validation loss: 3.076577659207984

Epoch: 6| Step: 6
Training loss: 3.580643879192625
Validation loss: 3.0762203552207366

Epoch: 6| Step: 7
Training loss: 3.9034408844665998
Validation loss: 3.076288166911334

Epoch: 6| Step: 8
Training loss: 3.6812792532362466
Validation loss: 3.0740818896400683

Epoch: 6| Step: 9
Training loss: 2.965769827937132
Validation loss: 3.0753070480912714

Epoch: 6| Step: 10
Training loss: 2.787287299418909
Validation loss: 3.0792527578080944

Epoch: 6| Step: 11
Training loss: 3.6034260394944884
Validation loss: 3.0784916854798587

Epoch: 6| Step: 12
Training loss: 2.779680302027903
Validation loss: 3.0780666044492873

Epoch: 6| Step: 13
Training loss: 3.160280279453414
Validation loss: 3.0767517757908367

Epoch: 88| Step: 0
Training loss: 3.7007677003508945
Validation loss: 3.0730108620354564

Epoch: 6| Step: 1
Training loss: 3.4216326623395403
Validation loss: 3.0752254438457403

Epoch: 6| Step: 2
Training loss: 2.478929802187299
Validation loss: 3.0748709700183747

Epoch: 6| Step: 3
Training loss: 3.3561929935892074
Validation loss: 3.073559657937305

Epoch: 6| Step: 4
Training loss: 3.393867313612485
Validation loss: 3.071132921550935

Epoch: 6| Step: 5
Training loss: 2.3987372891326366
Validation loss: 3.0704848185738096

Epoch: 6| Step: 6
Training loss: 3.3387676446206354
Validation loss: 3.072054956805963

Epoch: 6| Step: 7
Training loss: 3.755458546563721
Validation loss: 3.0727242208085275

Epoch: 6| Step: 8
Training loss: 3.9799146631571367
Validation loss: 3.0705375790324267

Epoch: 6| Step: 9
Training loss: 3.4079851403248234
Validation loss: 3.0687825860615665

Epoch: 6| Step: 10
Training loss: 3.0587692892435245
Validation loss: 3.068920188972935

Epoch: 6| Step: 11
Training loss: 3.4717737713605183
Validation loss: 3.069745364571504

Epoch: 6| Step: 12
Training loss: 3.4559601757086242
Validation loss: 3.0675596907360427

Epoch: 6| Step: 13
Training loss: 3.061492598528889
Validation loss: 3.0682147918439693

Epoch: 89| Step: 0
Training loss: 3.3396250156808516
Validation loss: 3.0699980014565913

Epoch: 6| Step: 1
Training loss: 3.965333203702034
Validation loss: 3.070151562295268

Epoch: 6| Step: 2
Training loss: 2.0886460909974005
Validation loss: 3.066068794509254

Epoch: 6| Step: 3
Training loss: 3.389306159117877
Validation loss: 3.0659381919675592

Epoch: 6| Step: 4
Training loss: 3.535283308749119
Validation loss: 3.06699908939546

Epoch: 6| Step: 5
Training loss: 3.2448246169930273
Validation loss: 3.0644579436602464

Epoch: 6| Step: 6
Training loss: 2.863037931712623
Validation loss: 3.0662353150286172

Epoch: 6| Step: 7
Training loss: 3.1518599695576888
Validation loss: 3.0645399567649743

Epoch: 6| Step: 8
Training loss: 3.4100018758013535
Validation loss: 3.065612850010634

Epoch: 6| Step: 9
Training loss: 2.9481975480017373
Validation loss: 3.066982665161785

Epoch: 6| Step: 10
Training loss: 3.6877327538434144
Validation loss: 3.069774430345916

Epoch: 6| Step: 11
Training loss: 3.550483111967883
Validation loss: 3.070366014886087

Epoch: 6| Step: 12
Training loss: 2.906594204772283
Validation loss: 3.0640789780723767

Epoch: 6| Step: 13
Training loss: 4.635110063449731
Validation loss: 3.0682392540843195

Epoch: 90| Step: 0
Training loss: 3.3759678053473348
Validation loss: 3.0623717650570286

Epoch: 6| Step: 1
Training loss: 3.4481972448660696
Validation loss: 3.064409390292358

Epoch: 6| Step: 2
Training loss: 3.204201419742718
Validation loss: 3.065037161699113

Epoch: 6| Step: 3
Training loss: 3.181985310710614
Validation loss: 3.0615039550906618

Epoch: 6| Step: 4
Training loss: 3.3266136785452227
Validation loss: 3.0625220158388133

Epoch: 6| Step: 5
Training loss: 3.5716934705313843
Validation loss: 3.063662106132775

Epoch: 6| Step: 6
Training loss: 3.268632881590072
Validation loss: 3.061952425212769

Epoch: 6| Step: 7
Training loss: 3.5375175556515575
Validation loss: 3.0591243617389186

Epoch: 6| Step: 8
Training loss: 3.375448974133299
Validation loss: 3.061985202805663

Epoch: 6| Step: 9
Training loss: 2.961692049615039
Validation loss: 3.0611671509052525

Epoch: 6| Step: 10
Training loss: 4.185079757677863
Validation loss: 3.0598386544056346

Epoch: 6| Step: 11
Training loss: 2.7211780448515723
Validation loss: 3.0592112844174557

Epoch: 6| Step: 12
Training loss: 2.650992991981755
Validation loss: 3.059151880872691

Epoch: 6| Step: 13
Training loss: 3.7077188447038525
Validation loss: 3.0594150826206583

Epoch: 91| Step: 0
Training loss: 2.6824412085071256
Validation loss: 3.0612312009027134

Epoch: 6| Step: 1
Training loss: 3.6946867398868872
Validation loss: 3.0600091457746346

Epoch: 6| Step: 2
Training loss: 2.5315555341017526
Validation loss: 3.0616008835823147

Epoch: 6| Step: 3
Training loss: 3.389213443980751
Validation loss: 3.0599742868699544

Epoch: 6| Step: 4
Training loss: 3.424890313167206
Validation loss: 3.060731845751166

Epoch: 6| Step: 5
Training loss: 3.173657146836902
Validation loss: 3.0577699900919706

Epoch: 6| Step: 6
Training loss: 3.913005389152577
Validation loss: 3.0578402507303557

Epoch: 6| Step: 7
Training loss: 3.663498304318514
Validation loss: 3.057461198569897

Epoch: 6| Step: 8
Training loss: 3.588301268093384
Validation loss: 3.0566711908609063

Epoch: 6| Step: 9
Training loss: 2.8113530681436982
Validation loss: 3.057138191389325

Epoch: 6| Step: 10
Training loss: 3.719163374805696
Validation loss: 3.060123980134711

Epoch: 6| Step: 11
Training loss: 3.3562826428521984
Validation loss: 3.0573485902441053

Epoch: 6| Step: 12
Training loss: 2.8079086975023815
Validation loss: 3.0565279436668322

Epoch: 6| Step: 13
Training loss: 3.5983370489890802
Validation loss: 3.0555422787892157

Epoch: 92| Step: 0
Training loss: 3.070009017583172
Validation loss: 3.057074044735857

Epoch: 6| Step: 1
Training loss: 2.732960885732157
Validation loss: 3.0553419368186776

Epoch: 6| Step: 2
Training loss: 3.5706818971753043
Validation loss: 3.057188560000959

Epoch: 6| Step: 3
Training loss: 3.674036047495438
Validation loss: 3.0560640652763063

Epoch: 6| Step: 4
Training loss: 3.7630074295104414
Validation loss: 3.0549181670196006

Epoch: 6| Step: 5
Training loss: 3.875347244947335
Validation loss: 3.054833846253974

Epoch: 6| Step: 6
Training loss: 3.0324849238260727
Validation loss: 3.056312635853475

Epoch: 6| Step: 7
Training loss: 2.9916940785235138
Validation loss: 3.0560676019504185

Epoch: 6| Step: 8
Training loss: 2.957349550962339
Validation loss: 3.0573302258147557

Epoch: 6| Step: 9
Training loss: 3.402703915440958
Validation loss: 3.059032926176865

Epoch: 6| Step: 10
Training loss: 3.7517579090937176
Validation loss: 3.056818338675903

Epoch: 6| Step: 11
Training loss: 2.2558396111485424
Validation loss: 3.0590629016139395

Epoch: 6| Step: 12
Training loss: 3.2979579792017617
Validation loss: 3.058288978960722

Epoch: 6| Step: 13
Training loss: 4.103106340771191
Validation loss: 3.059014032985991

Epoch: 93| Step: 0
Training loss: 3.113427975977071
Validation loss: 3.0550288148773825

Epoch: 6| Step: 1
Training loss: 3.798414381389179
Validation loss: 3.056998224094364

Epoch: 6| Step: 2
Training loss: 2.7288785787250256
Validation loss: 3.0535880617178446

Epoch: 6| Step: 3
Training loss: 3.0603564798986436
Validation loss: 3.052842379521987

Epoch: 6| Step: 4
Training loss: 3.4817820938525528
Validation loss: 3.052184360311421

Epoch: 6| Step: 5
Training loss: 3.5388118832000286
Validation loss: 3.052013482233817

Epoch: 6| Step: 6
Training loss: 3.444425922945603
Validation loss: 3.05231250251293

Epoch: 6| Step: 7
Training loss: 2.921858354000879
Validation loss: 3.052374210263055

Epoch: 6| Step: 8
Training loss: 2.930732723704181
Validation loss: 3.0543224069436294

Epoch: 6| Step: 9
Training loss: 3.856173156269414
Validation loss: 3.0527406246738127

Epoch: 6| Step: 10
Training loss: 3.059222900849181
Validation loss: 3.051987076401693

Epoch: 6| Step: 11
Training loss: 4.035984068870293
Validation loss: 3.050557946246644

Epoch: 6| Step: 12
Training loss: 3.125561320436708
Validation loss: 3.05237800149763

Epoch: 6| Step: 13
Training loss: 3.0558536576787243
Validation loss: 3.0518769650798223

Epoch: 94| Step: 0
Training loss: 2.896567345406388
Validation loss: 3.0486129595791516

Epoch: 6| Step: 1
Training loss: 3.80505218951291
Validation loss: 3.051070327469286

Epoch: 6| Step: 2
Training loss: 3.878423224700974
Validation loss: 3.0511141760779696

Epoch: 6| Step: 3
Training loss: 2.712022196090925
Validation loss: 3.0503844070198385

Epoch: 6| Step: 4
Training loss: 3.1233783328934366
Validation loss: 3.049176425883973

Epoch: 6| Step: 5
Training loss: 4.269079800512008
Validation loss: 3.0500134118960496

Epoch: 6| Step: 6
Training loss: 2.571888912714875
Validation loss: 3.0481317638048906

Epoch: 6| Step: 7
Training loss: 3.725676425219916
Validation loss: 3.0487739966158593

Epoch: 6| Step: 8
Training loss: 3.9129089970446325
Validation loss: 3.0494551115923696

Epoch: 6| Step: 9
Training loss: 2.9281959093560213
Validation loss: 3.0479081128551275

Epoch: 6| Step: 10
Training loss: 3.948157525410933
Validation loss: 3.0479921289727274

Epoch: 6| Step: 11
Training loss: 2.844772658022092
Validation loss: 3.0482400609230984

Epoch: 6| Step: 12
Training loss: 2.5300122284122515
Validation loss: 3.0522018426968445

Epoch: 6| Step: 13
Training loss: 1.977952671830945
Validation loss: 3.0470057423414385

Epoch: 95| Step: 0
Training loss: 3.2622730629285734
Validation loss: 3.047176271935701

Epoch: 6| Step: 1
Training loss: 2.8162154346009243
Validation loss: 3.0487313773629023

Epoch: 6| Step: 2
Training loss: 3.026350958683092
Validation loss: 3.0473875352494058

Epoch: 6| Step: 3
Training loss: 4.310001257522293
Validation loss: 3.045146183050657

Epoch: 6| Step: 4
Training loss: 3.4963302447071145
Validation loss: 3.046368099313448

Epoch: 6| Step: 5
Training loss: 3.635148411046915
Validation loss: 3.0461325271676105

Epoch: 6| Step: 6
Training loss: 3.83247222074132
Validation loss: 3.046725535085776

Epoch: 6| Step: 7
Training loss: 3.5196526408033595
Validation loss: 3.0470116201039765

Epoch: 6| Step: 8
Training loss: 3.795313007579281
Validation loss: 3.047361324045918

Epoch: 6| Step: 9
Training loss: 2.4266031688025906
Validation loss: 3.04621915234767

Epoch: 6| Step: 10
Training loss: 2.5593482382915758
Validation loss: 3.0468498235250796

Epoch: 6| Step: 11
Training loss: 2.6767601283166744
Validation loss: 3.044389592921531

Epoch: 6| Step: 12
Training loss: 3.3073088077291204
Validation loss: 3.0442456768663915

Epoch: 6| Step: 13
Training loss: 3.2090189973120857
Validation loss: 3.04560957957161

Epoch: 96| Step: 0
Training loss: 4.045541668850931
Validation loss: 3.0452357120594185

Epoch: 6| Step: 1
Training loss: 3.3955854703784896
Validation loss: 3.0428221557729414

Epoch: 6| Step: 2
Training loss: 2.839473317161489
Validation loss: 3.0452262226783

Epoch: 6| Step: 3
Training loss: 3.1577998218159182
Validation loss: 3.0513517690224314

Epoch: 6| Step: 4
Training loss: 3.1881835802892495
Validation loss: 3.055019090741617

Epoch: 6| Step: 5
Training loss: 3.2951445897147615
Validation loss: 3.0556032878718558

Epoch: 6| Step: 6
Training loss: 2.96903877861521
Validation loss: 3.058371802934672

Epoch: 6| Step: 7
Training loss: 3.369146427757684
Validation loss: 3.052909300569625

Epoch: 6| Step: 8
Training loss: 3.1105136032653244
Validation loss: 3.0522087469264054

Epoch: 6| Step: 9
Training loss: 3.921070517900393
Validation loss: 3.057681051108801

Epoch: 6| Step: 10
Training loss: 3.535978139524938
Validation loss: 3.0405813200472367

Epoch: 6| Step: 11
Training loss: 3.4630112473704244
Validation loss: 3.0435107129985304

Epoch: 6| Step: 12
Training loss: 3.2732988205260196
Validation loss: 3.0417330239194156

Epoch: 6| Step: 13
Training loss: 2.0451685657373755
Validation loss: 3.0451247268802493

Epoch: 97| Step: 0
Training loss: 3.519794754850341
Validation loss: 3.045866425263767

Epoch: 6| Step: 1
Training loss: 3.8753821892075053
Validation loss: 3.048884957844176

Epoch: 6| Step: 2
Training loss: 2.4651485200286736
Validation loss: 3.0485286141026253

Epoch: 6| Step: 3
Training loss: 3.369299418812225
Validation loss: 3.0499342569211567

Epoch: 6| Step: 4
Training loss: 3.5347780141234977
Validation loss: 3.0522260359894284

Epoch: 6| Step: 5
Training loss: 3.744978530883367
Validation loss: 3.0465577588550996

Epoch: 6| Step: 6
Training loss: 2.5809407896442838
Validation loss: 3.046501844855649

Epoch: 6| Step: 7
Training loss: 3.372233634592849
Validation loss: 3.0455088844532363

Epoch: 6| Step: 8
Training loss: 3.0095862769001105
Validation loss: 3.045289426854336

Epoch: 6| Step: 9
Training loss: 3.7133413780668585
Validation loss: 3.0431817737482114

Epoch: 6| Step: 10
Training loss: 3.1373029001037676
Validation loss: 3.04278762823647

Epoch: 6| Step: 11
Training loss: 3.237453746097027
Validation loss: 3.043348135580679

Epoch: 6| Step: 12
Training loss: 3.178904293994391
Validation loss: 3.0427602020680156

Epoch: 6| Step: 13
Training loss: 3.5298195701501434
Validation loss: 3.0451831227359047

Epoch: 98| Step: 0
Training loss: 3.212119819914536
Validation loss: 3.0457904426207034

Epoch: 6| Step: 1
Training loss: 2.371621187926309
Validation loss: 3.044299875659807

Epoch: 6| Step: 2
Training loss: 4.007247319813605
Validation loss: 3.04347217952256

Epoch: 6| Step: 3
Training loss: 3.3134483563307278
Validation loss: 3.0403702069214473

Epoch: 6| Step: 4
Training loss: 2.946698659432612
Validation loss: 3.0426429303350737

Epoch: 6| Step: 5
Training loss: 3.193510783394543
Validation loss: 3.0407540748558777

Epoch: 6| Step: 6
Training loss: 2.8264993452836955
Validation loss: 3.041113424002622

Epoch: 6| Step: 7
Training loss: 3.5680576274135407
Validation loss: 3.0405968203231226

Epoch: 6| Step: 8
Training loss: 3.560209508367343
Validation loss: 3.038057194685545

Epoch: 6| Step: 9
Training loss: 3.14834935370173
Validation loss: 3.0368878652058537

Epoch: 6| Step: 10
Training loss: 3.444227674971353
Validation loss: 3.038071852187877

Epoch: 6| Step: 11
Training loss: 3.7903826429311835
Validation loss: 3.038135087065775

Epoch: 6| Step: 12
Training loss: 3.6191565672291213
Validation loss: 3.038324734864512

Epoch: 6| Step: 13
Training loss: 2.876485192183692
Validation loss: 3.038275010376271

Epoch: 99| Step: 0
Training loss: 3.9770711337435802
Validation loss: 3.0385238710442883

Epoch: 6| Step: 1
Training loss: 3.4821989509060804
Validation loss: 3.037066183504208

Epoch: 6| Step: 2
Training loss: 3.2031860345747525
Validation loss: 3.037772745816912

Epoch: 6| Step: 3
Training loss: 3.303594025052237
Validation loss: 3.035545571739436

Epoch: 6| Step: 4
Training loss: 3.653098549596154
Validation loss: 3.03582047996867

Epoch: 6| Step: 5
Training loss: 3.5211903919595464
Validation loss: 3.035780619324567

Epoch: 6| Step: 6
Training loss: 3.125138394152326
Validation loss: 3.034002673180412

Epoch: 6| Step: 7
Training loss: 2.996994102108192
Validation loss: 3.035577533199671

Epoch: 6| Step: 8
Training loss: 3.446751162257572
Validation loss: 3.0359850015571475

Epoch: 6| Step: 9
Training loss: 2.9877206313890907
Validation loss: 3.0345683201291234

Epoch: 6| Step: 10
Training loss: 3.470058572368268
Validation loss: 3.0354826967503596

Epoch: 6| Step: 11
Training loss: 2.9307205210010725
Validation loss: 3.039897049652689

Epoch: 6| Step: 12
Training loss: 2.8640595298206435
Validation loss: 3.045021420114248

Epoch: 6| Step: 13
Training loss: 3.175734103182477
Validation loss: 3.051907353526985

Epoch: 100| Step: 0
Training loss: 3.1241435593993323
Validation loss: 3.0519798365136164

Epoch: 6| Step: 1
Training loss: 3.8220280888761407
Validation loss: 3.0371892330803782

Epoch: 6| Step: 2
Training loss: 3.7275164200992292
Validation loss: 3.034175703697201

Epoch: 6| Step: 3
Training loss: 2.690979855981206
Validation loss: 3.032618999299899

Epoch: 6| Step: 4
Training loss: 2.7853814631890716
Validation loss: 3.032326964848149

Epoch: 6| Step: 5
Training loss: 3.649204606437347
Validation loss: 3.03174560879579

Epoch: 6| Step: 6
Training loss: 2.798362975456763
Validation loss: 3.0336948350648028

Epoch: 6| Step: 7
Training loss: 3.5002811863890395
Validation loss: 3.034771339474132

Epoch: 6| Step: 8
Training loss: 3.222370370842676
Validation loss: 3.0335588118751677

Epoch: 6| Step: 9
Training loss: 2.9686854305272568
Validation loss: 3.0350939244253445

Epoch: 6| Step: 10
Training loss: 3.5445364750467743
Validation loss: 3.036223559714679

Epoch: 6| Step: 11
Training loss: 3.5263770585831797
Validation loss: 3.038463393128912

Epoch: 6| Step: 12
Training loss: 3.4033353041725043
Validation loss: 3.035151335830164

Epoch: 6| Step: 13
Training loss: 3.3859775176453843
Validation loss: 3.036150728437765

Epoch: 101| Step: 0
Training loss: 2.776425839025007
Validation loss: 3.0351068258263614

Epoch: 6| Step: 1
Training loss: 2.9537462660821987
Validation loss: 3.0333140832271472

Epoch: 6| Step: 2
Training loss: 4.049343931959457
Validation loss: 3.0330051575443244

Epoch: 6| Step: 3
Training loss: 3.378520118833004
Validation loss: 3.0311533628451417

Epoch: 6| Step: 4
Training loss: 3.1133501722491714
Validation loss: 3.032687437649838

Epoch: 6| Step: 5
Training loss: 3.095166431198233
Validation loss: 3.03116374711873

Epoch: 6| Step: 6
Training loss: 3.2865714382693185
Validation loss: 3.0330946223129738

Epoch: 6| Step: 7
Training loss: 3.685605871944333
Validation loss: 3.029709208193327

Epoch: 6| Step: 8
Training loss: 2.9485444567535604
Validation loss: 3.0290671437772776

Epoch: 6| Step: 9
Training loss: 3.109931014298595
Validation loss: 3.0306947709395975

Epoch: 6| Step: 10
Training loss: 3.4570367672978572
Validation loss: 3.029490020952856

Epoch: 6| Step: 11
Training loss: 3.408561552159268
Validation loss: 3.030178478194584

Epoch: 6| Step: 12
Training loss: 3.198419156601955
Validation loss: 3.033305628218547

Epoch: 6| Step: 13
Training loss: 3.830337943563447
Validation loss: 3.031137212091241

Epoch: 102| Step: 0
Training loss: 3.951172116364921
Validation loss: 3.0307581225172244

Epoch: 6| Step: 1
Training loss: 2.758466864481763
Validation loss: 3.0366534866899406

Epoch: 6| Step: 2
Training loss: 3.489831321596825
Validation loss: 3.039154026892799

Epoch: 6| Step: 3
Training loss: 3.40014577440901
Validation loss: 3.0376635860319925

Epoch: 6| Step: 4
Training loss: 3.930491431574016
Validation loss: 3.0402633580928526

Epoch: 6| Step: 5
Training loss: 3.0286656010322397
Validation loss: 3.028767319970432

Epoch: 6| Step: 6
Training loss: 2.9161608302761883
Validation loss: 3.02687482310877

Epoch: 6| Step: 7
Training loss: 3.021760066153483
Validation loss: 3.0251066834009306

Epoch: 6| Step: 8
Training loss: 2.9404739584325053
Validation loss: 3.0267358423202357

Epoch: 6| Step: 9
Training loss: 3.129592877317877
Validation loss: 3.0260402233322323

Epoch: 6| Step: 10
Training loss: 3.2573878608425426
Validation loss: 3.02730453397006

Epoch: 6| Step: 11
Training loss: 3.7635231325207177
Validation loss: 3.0278632549668707

Epoch: 6| Step: 12
Training loss: 3.1456625852076994
Validation loss: 3.0284179847832404

Epoch: 6| Step: 13
Training loss: 3.300678535985078
Validation loss: 3.0274687630004604

Epoch: 103| Step: 0
Training loss: 3.5120067372268324
Validation loss: 3.026626248050726

Epoch: 6| Step: 1
Training loss: 3.420062974495019
Validation loss: 3.025545111091569

Epoch: 6| Step: 2
Training loss: 3.5699820668173476
Validation loss: 3.0252527946081798

Epoch: 6| Step: 3
Training loss: 4.15820587717147
Validation loss: 3.0250493322133187

Epoch: 6| Step: 4
Training loss: 3.4496271014824527
Validation loss: 3.02465980791188

Epoch: 6| Step: 5
Training loss: 2.881908905749805
Validation loss: 3.0263438836439085

Epoch: 6| Step: 6
Training loss: 3.1067404776169623
Validation loss: 3.025612527449135

Epoch: 6| Step: 7
Training loss: 2.9829379311631468
Validation loss: 3.022809637239766

Epoch: 6| Step: 8
Training loss: 3.7829501530758685
Validation loss: 3.023991266465444

Epoch: 6| Step: 9
Training loss: 2.7463647917559992
Validation loss: 3.023255654163002

Epoch: 6| Step: 10
Training loss: 2.479363719471223
Validation loss: 3.0213433541998067

Epoch: 6| Step: 11
Training loss: 3.222135078596439
Validation loss: 3.022026726422632

Epoch: 6| Step: 12
Training loss: 3.280600637940299
Validation loss: 3.0254917812516795

Epoch: 6| Step: 13
Training loss: 3.2064641156005145
Validation loss: 3.026901017761383

Epoch: 104| Step: 0
Training loss: 2.9540126213367137
Validation loss: 3.025369266835613

Epoch: 6| Step: 1
Training loss: 2.969622674471515
Validation loss: 3.028716395752129

Epoch: 6| Step: 2
Training loss: 2.8249858484504506
Validation loss: 3.027955894227345

Epoch: 6| Step: 3
Training loss: 2.964629516098868
Validation loss: 3.0246964502609908

Epoch: 6| Step: 4
Training loss: 2.85068981455774
Validation loss: 3.022414842760667

Epoch: 6| Step: 5
Training loss: 3.711672675943385
Validation loss: 3.021247639036795

Epoch: 6| Step: 6
Training loss: 3.9423725316081577
Validation loss: 3.0209054691469888

Epoch: 6| Step: 7
Training loss: 3.241479414865544
Validation loss: 3.022204876501991

Epoch: 6| Step: 8
Training loss: 2.5363710193893256
Validation loss: 3.0212122989579915

Epoch: 6| Step: 9
Training loss: 4.432827060636555
Validation loss: 3.020028888887747

Epoch: 6| Step: 10
Training loss: 1.9248163309040278
Validation loss: 3.0213958833122585

Epoch: 6| Step: 11
Training loss: 3.8118044109222686
Validation loss: 3.0200276639543695

Epoch: 6| Step: 12
Training loss: 3.622864324284089
Validation loss: 3.021530238729748

Epoch: 6| Step: 13
Training loss: 3.79130402951302
Validation loss: 3.0186520770293175

Epoch: 105| Step: 0
Training loss: 2.891986258340903
Validation loss: 3.020080189636178

Epoch: 6| Step: 1
Training loss: 3.8752943357846825
Validation loss: 3.02080729257281

Epoch: 6| Step: 2
Training loss: 3.399253589378819
Validation loss: 3.019711291084301

Epoch: 6| Step: 3
Training loss: 3.1157422073341494
Validation loss: 3.0193146760605325

Epoch: 6| Step: 4
Training loss: 2.3887212815247674
Validation loss: 3.0174519647740703

Epoch: 6| Step: 5
Training loss: 3.4240910570033605
Validation loss: 3.0193331095377522

Epoch: 6| Step: 6
Training loss: 2.5453688023418732
Validation loss: 3.019824043919901

Epoch: 6| Step: 7
Training loss: 3.235591346428653
Validation loss: 3.026007546067703

Epoch: 6| Step: 8
Training loss: 3.7470948728264024
Validation loss: 3.045628656924722

Epoch: 6| Step: 9
Training loss: 3.0376134717805803
Validation loss: 3.0153924902432903

Epoch: 6| Step: 10
Training loss: 3.2340733484220223
Validation loss: 3.019546839654133

Epoch: 6| Step: 11
Training loss: 3.6418170860062764
Validation loss: 3.0177895209309855

Epoch: 6| Step: 12
Training loss: 3.1047863096458754
Validation loss: 3.016791253606896

Epoch: 6| Step: 13
Training loss: 4.638234148754972
Validation loss: 3.0210305279338923

Epoch: 106| Step: 0
Training loss: 4.490620480762774
Validation loss: 3.02345126005476

Epoch: 6| Step: 1
Training loss: 3.309341364213214
Validation loss: 3.028159322184009

Epoch: 6| Step: 2
Training loss: 3.3915859565848128
Validation loss: 3.025807718328794

Epoch: 6| Step: 3
Training loss: 3.266130764139279
Validation loss: 3.026131763712175

Epoch: 6| Step: 4
Training loss: 2.9330150373758155
Validation loss: 3.024007841964483

Epoch: 6| Step: 5
Training loss: 3.2525266949132097
Validation loss: 3.024972408015954

Epoch: 6| Step: 6
Training loss: 2.6294535142380475
Validation loss: 3.022665707239474

Epoch: 6| Step: 7
Training loss: 3.261142264034486
Validation loss: 3.0191355606530035

Epoch: 6| Step: 8
Training loss: 3.5252642917980443
Validation loss: 3.0216357366653783

Epoch: 6| Step: 9
Training loss: 3.490752537650552
Validation loss: 3.018358652169907

Epoch: 6| Step: 10
Training loss: 3.228091415718028
Validation loss: 3.016702527372582

Epoch: 6| Step: 11
Training loss: 2.881693470353861
Validation loss: 3.0171294835690454

Epoch: 6| Step: 12
Training loss: 2.974774962817648
Validation loss: 3.018323888105204

Epoch: 6| Step: 13
Training loss: 3.1470350450201474
Validation loss: 3.0188043475542736

Epoch: 107| Step: 0
Training loss: 2.9003722116418875
Validation loss: 3.018136009137603

Epoch: 6| Step: 1
Training loss: 2.745954485600099
Validation loss: 3.0153195231066023

Epoch: 6| Step: 2
Training loss: 3.6920506474997894
Validation loss: 3.0138603231652374

Epoch: 6| Step: 3
Training loss: 2.879548827965367
Validation loss: 3.014119781635549

Epoch: 6| Step: 4
Training loss: 3.4808175439882127
Validation loss: 3.0148777359722825

Epoch: 6| Step: 5
Training loss: 3.488693913467158
Validation loss: 3.0139764386464556

Epoch: 6| Step: 6
Training loss: 3.7949854540640358
Validation loss: 3.0151634434796044

Epoch: 6| Step: 7
Training loss: 3.269197253232358
Validation loss: 3.0121431154544114

Epoch: 6| Step: 8
Training loss: 3.285468886078759
Validation loss: 3.01472668298894

Epoch: 6| Step: 9
Training loss: 3.744526237804386
Validation loss: 3.013568287118386

Epoch: 6| Step: 10
Training loss: 3.2898319458868617
Validation loss: 3.0149289653615536

Epoch: 6| Step: 11
Training loss: 2.907430265579304
Validation loss: 3.0120496170585676

Epoch: 6| Step: 12
Training loss: 3.4082062029892977
Validation loss: 3.0136596882751254

Epoch: 6| Step: 13
Training loss: 2.8206894218514518
Validation loss: 3.0110406823202274

Epoch: 108| Step: 0
Training loss: 3.3214307629743574
Validation loss: 3.0114510901401146

Epoch: 6| Step: 1
Training loss: 3.1418913001204323
Validation loss: 3.0089876996202602

Epoch: 6| Step: 2
Training loss: 3.3604235055234644
Validation loss: 3.0115648213319086

Epoch: 6| Step: 3
Training loss: 3.103456932362728
Validation loss: 3.0114607846998767

Epoch: 6| Step: 4
Training loss: 3.526504704074056
Validation loss: 3.0121479156651283

Epoch: 6| Step: 5
Training loss: 3.774052982405184
Validation loss: 3.014399790584809

Epoch: 6| Step: 6
Training loss: 2.677055645711687
Validation loss: 3.0111659107197144

Epoch: 6| Step: 7
Training loss: 3.746541781080629
Validation loss: 3.01034263306625

Epoch: 6| Step: 8
Training loss: 3.397594408712329
Validation loss: 3.010456898346599

Epoch: 6| Step: 9
Training loss: 3.1924821401169687
Validation loss: 3.008854339095258

Epoch: 6| Step: 10
Training loss: 3.079635327040946
Validation loss: 3.0119432411666414

Epoch: 6| Step: 11
Training loss: 3.1705493881741633
Validation loss: 3.0106762936142983

Epoch: 6| Step: 12
Training loss: 3.145693811686822
Validation loss: 3.0115025353082228

Epoch: 6| Step: 13
Training loss: 3.361955653944858
Validation loss: 3.01220931853687

Epoch: 109| Step: 0
Training loss: 2.7548893898361753
Validation loss: 3.010904411360035

Epoch: 6| Step: 1
Training loss: 4.290401729100704
Validation loss: 3.009807576289355

Epoch: 6| Step: 2
Training loss: 2.7919178939813754
Validation loss: 3.008644839248584

Epoch: 6| Step: 3
Training loss: 3.405558384667183
Validation loss: 3.009507944615138

Epoch: 6| Step: 4
Training loss: 2.9734795090819404
Validation loss: 3.0080861289302985

Epoch: 6| Step: 5
Training loss: 4.213757534965267
Validation loss: 3.008239518042024

Epoch: 6| Step: 6
Training loss: 3.4402155467081563
Validation loss: 3.008313253435287

Epoch: 6| Step: 7
Training loss: 2.969558445124256
Validation loss: 3.0092218407203895

Epoch: 6| Step: 8
Training loss: 3.1242885542691017
Validation loss: 3.0101017572053403

Epoch: 6| Step: 9
Training loss: 3.420349059556493
Validation loss: 3.0146197901222993

Epoch: 6| Step: 10
Training loss: 3.037201220727397
Validation loss: 3.014197618138573

Epoch: 6| Step: 11
Training loss: 2.8041663575609177
Validation loss: 3.013605277001265

Epoch: 6| Step: 12
Training loss: 2.856222781128855
Validation loss: 3.013802712030724

Epoch: 6| Step: 13
Training loss: 3.710932617184288
Validation loss: 3.007557699605576

Epoch: 110| Step: 0
Training loss: 3.924590246108951
Validation loss: 3.0102037712978635

Epoch: 6| Step: 1
Training loss: 3.726765177271495
Validation loss: 3.0060061658983055

Epoch: 6| Step: 2
Training loss: 3.086098195974216
Validation loss: 3.0051048250888335

Epoch: 6| Step: 3
Training loss: 3.2206431626752163
Validation loss: 3.008560642911282

Epoch: 6| Step: 4
Training loss: 2.7927124759501534
Validation loss: 3.006928510975049

Epoch: 6| Step: 5
Training loss: 3.4059442505409523
Validation loss: 3.0046801583940237

Epoch: 6| Step: 6
Training loss: 3.837284139221972
Validation loss: 3.0044037191106647

Epoch: 6| Step: 7
Training loss: 3.5015552335133493
Validation loss: 3.004508307281899

Epoch: 6| Step: 8
Training loss: 2.6621155546344726
Validation loss: 3.0064917326091316

Epoch: 6| Step: 9
Training loss: 3.4878426988461695
Validation loss: 3.0049555655442854

Epoch: 6| Step: 10
Training loss: 2.5227803889375915
Validation loss: 3.004593711030315

Epoch: 6| Step: 11
Training loss: 2.5154521243006074
Validation loss: 3.0061460402530367

Epoch: 6| Step: 12
Training loss: 3.233030325334684
Validation loss: 3.005284341677794

Epoch: 6| Step: 13
Training loss: 3.882607897888366
Validation loss: 3.0042261143006423

Epoch: 111| Step: 0
Training loss: 4.022840614857719
Validation loss: 3.0083850781721826

Epoch: 6| Step: 1
Training loss: 3.0790101923090902
Validation loss: 3.003203450591565

Epoch: 6| Step: 2
Training loss: 2.323064232032223
Validation loss: 3.0044897930891565

Epoch: 6| Step: 3
Training loss: 3.1577450072613193
Validation loss: 3.0041790434344997

Epoch: 6| Step: 4
Training loss: 2.6163371512400193
Validation loss: 3.002824038636224

Epoch: 6| Step: 5
Training loss: 2.9868537235719503
Validation loss: 3.0042726263504935

Epoch: 6| Step: 6
Training loss: 3.5892632381383462
Validation loss: 3.0056992235445934

Epoch: 6| Step: 7
Training loss: 3.737949846938498
Validation loss: 3.006119865155906

Epoch: 6| Step: 8
Training loss: 3.599371982473177
Validation loss: 3.0083360902129774

Epoch: 6| Step: 9
Training loss: 3.575413905371875
Validation loss: 3.0032984638251046

Epoch: 6| Step: 10
Training loss: 2.992701872196696
Validation loss: 3.0029899488008955

Epoch: 6| Step: 11
Training loss: 3.0077324398334477
Validation loss: 3.0040906581252216

Epoch: 6| Step: 12
Training loss: 3.4489746007340774
Validation loss: 3.001281401379865

Epoch: 6| Step: 13
Training loss: 3.473205728902093
Validation loss: 3.002304511439988

Epoch: 112| Step: 0
Training loss: 2.601439327039096
Validation loss: 3.003274854632662

Epoch: 6| Step: 1
Training loss: 3.641942649410707
Validation loss: 3.003756253235459

Epoch: 6| Step: 2
Training loss: 3.743605566024841
Validation loss: 3.0040537371256057

Epoch: 6| Step: 3
Training loss: 3.1220272420394766
Validation loss: 3.003749882013553

Epoch: 6| Step: 4
Training loss: 3.2109404700792226
Validation loss: 3.003370554452776

Epoch: 6| Step: 5
Training loss: 3.317025601950359
Validation loss: 3.0063757484437

Epoch: 6| Step: 6
Training loss: 4.332846809853901
Validation loss: 3.0025719398811326

Epoch: 6| Step: 7
Training loss: 2.8556313944574048
Validation loss: 2.99952263178818

Epoch: 6| Step: 8
Training loss: 3.1552488042117206
Validation loss: 3.001124043258137

Epoch: 6| Step: 9
Training loss: 3.2796448187302123
Validation loss: 2.999822346407483

Epoch: 6| Step: 10
Training loss: 3.0671878668949573
Validation loss: 2.9978240421160653

Epoch: 6| Step: 11
Training loss: 2.906762026730345
Validation loss: 2.999098279071801

Epoch: 6| Step: 12
Training loss: 3.046556035487968
Validation loss: 2.9995246924278907

Epoch: 6| Step: 13
Training loss: 3.2622433908620527
Validation loss: 2.9978676245377813

Epoch: 113| Step: 0
Training loss: 2.584127478410559
Validation loss: 2.9993500381450295

Epoch: 6| Step: 1
Training loss: 2.832366797201443
Validation loss: 2.9985204632243097

Epoch: 6| Step: 2
Training loss: 3.1087814608010818
Validation loss: 2.999547108096575

Epoch: 6| Step: 3
Training loss: 3.5040091304921375
Validation loss: 3.0004162379997763

Epoch: 6| Step: 4
Training loss: 3.218342134874248
Validation loss: 2.998085682770002

Epoch: 6| Step: 5
Training loss: 3.7261906404319642
Validation loss: 2.9978863746014373

Epoch: 6| Step: 6
Training loss: 3.064497471446573
Validation loss: 2.997706993103486

Epoch: 6| Step: 7
Training loss: 2.7959765477649943
Validation loss: 2.998259829274849

Epoch: 6| Step: 8
Training loss: 3.116351252080351
Validation loss: 2.998104028723843

Epoch: 6| Step: 9
Training loss: 3.093284186542811
Validation loss: 2.9996873836273035

Epoch: 6| Step: 10
Training loss: 3.468663394980935
Validation loss: 2.996159183395038

Epoch: 6| Step: 11
Training loss: 3.888938691562071
Validation loss: 2.997140781479755

Epoch: 6| Step: 12
Training loss: 3.4718969692905133
Validation loss: 3.002244647964606

Epoch: 6| Step: 13
Training loss: 4.077321174297412
Validation loss: 3.0009267530902064

Epoch: 114| Step: 0
Training loss: 3.186174902646417
Validation loss: 2.9984802674643793

Epoch: 6| Step: 1
Training loss: 3.126711719923088
Validation loss: 2.99619545385402

Epoch: 6| Step: 2
Training loss: 3.75398957698881
Validation loss: 2.9951361002907486

Epoch: 6| Step: 3
Training loss: 3.451750192508069
Validation loss: 2.9959106260999873

Epoch: 6| Step: 4
Training loss: 3.173646328927999
Validation loss: 2.9942253723752317

Epoch: 6| Step: 5
Training loss: 3.0062026434517173
Validation loss: 2.9958910610066978

Epoch: 6| Step: 6
Training loss: 3.6381576100958624
Validation loss: 2.9960356757237054

Epoch: 6| Step: 7
Training loss: 2.581943158423058
Validation loss: 2.9970944701070907

Epoch: 6| Step: 8
Training loss: 2.7050968100663337
Validation loss: 2.9939177556956653

Epoch: 6| Step: 9
Training loss: 3.3650359960390723
Validation loss: 2.9951657420153848

Epoch: 6| Step: 10
Training loss: 3.554398677955672
Validation loss: 2.9947994362978667

Epoch: 6| Step: 11
Training loss: 3.434795355996226
Validation loss: 2.9955627772661257

Epoch: 6| Step: 12
Training loss: 3.288784568080083
Validation loss: 2.9960327664184314

Epoch: 6| Step: 13
Training loss: 3.5385192049870944
Validation loss: 2.996065543857351

Epoch: 115| Step: 0
Training loss: 3.7351979901028747
Validation loss: 2.9934859396116194

Epoch: 6| Step: 1
Training loss: 2.893119766451473
Validation loss: 2.9931455380923553

Epoch: 6| Step: 2
Training loss: 3.063458818086959
Validation loss: 2.9929950602898363

Epoch: 6| Step: 3
Training loss: 3.3897087863307562
Validation loss: 2.9915093227140694

Epoch: 6| Step: 4
Training loss: 3.9925059212083567
Validation loss: 2.9940755499225853

Epoch: 6| Step: 5
Training loss: 3.7480221936882767
Validation loss: 2.9926331310676924

Epoch: 6| Step: 6
Training loss: 3.0539926192238784
Validation loss: 2.995124718050741

Epoch: 6| Step: 7
Training loss: 3.2773741583157987
Validation loss: 2.997965942628664

Epoch: 6| Step: 8
Training loss: 3.3688224487440874
Validation loss: 2.9939328270933903

Epoch: 6| Step: 9
Training loss: 2.5146962222401585
Validation loss: 2.992990915456525

Epoch: 6| Step: 10
Training loss: 3.134253420235559
Validation loss: 2.991235433825448

Epoch: 6| Step: 11
Training loss: 3.0910182413422516
Validation loss: 2.9911676763381543

Epoch: 6| Step: 12
Training loss: 3.3732303642369224
Validation loss: 2.992720502145613

Epoch: 6| Step: 13
Training loss: 2.5578812633632158
Validation loss: 2.9922976247996624

Epoch: 116| Step: 0
Training loss: 3.2937574064399504
Validation loss: 2.99218583785008

Epoch: 6| Step: 1
Training loss: 3.4614246447509243
Validation loss: 2.9926207618657172

Epoch: 6| Step: 2
Training loss: 3.05092723072234
Validation loss: 2.9915273533569993

Epoch: 6| Step: 3
Training loss: 3.047065924506888
Validation loss: 2.9907279224395427

Epoch: 6| Step: 4
Training loss: 4.266878607572263
Validation loss: 2.99284980696836

Epoch: 6| Step: 5
Training loss: 2.8739949003637593
Validation loss: 2.9927890468182743

Epoch: 6| Step: 6
Training loss: 3.1057967102768345
Validation loss: 2.992105009983781

Epoch: 6| Step: 7
Training loss: 3.651871627239372
Validation loss: 2.9899306785648916

Epoch: 6| Step: 8
Training loss: 3.7890783565228783
Validation loss: 2.9899531618727746

Epoch: 6| Step: 9
Training loss: 3.029267911692617
Validation loss: 2.9878929366845095

Epoch: 6| Step: 10
Training loss: 2.733013053675833
Validation loss: 2.988067644626753

Epoch: 6| Step: 11
Training loss: 3.037568418886077
Validation loss: 2.9901328404880743

Epoch: 6| Step: 12
Training loss: 3.46681805671346
Validation loss: 2.9871394200632806

Epoch: 6| Step: 13
Training loss: 2.022586599412748
Validation loss: 2.9882632066338917

Epoch: 117| Step: 0
Training loss: 3.585494003629212
Validation loss: 2.9888132083913015

Epoch: 6| Step: 1
Training loss: 3.0273837572961293
Validation loss: 2.9883649848231895

Epoch: 6| Step: 2
Training loss: 3.017642596398654
Validation loss: 2.99461146914245

Epoch: 6| Step: 3
Training loss: 3.780824999924449
Validation loss: 2.9931502548552644

Epoch: 6| Step: 4
Training loss: 2.972579734509259
Validation loss: 2.9953821183179365

Epoch: 6| Step: 5
Training loss: 2.9802751590757035
Validation loss: 2.991974065543102

Epoch: 6| Step: 6
Training loss: 3.989250282084386
Validation loss: 2.989189109665735

Epoch: 6| Step: 7
Training loss: 3.1881117888107533
Validation loss: 2.9866706734685713

Epoch: 6| Step: 8
Training loss: 3.373271782229334
Validation loss: 2.988235127329486

Epoch: 6| Step: 9
Training loss: 2.933231580298785
Validation loss: 2.984908852667886

Epoch: 6| Step: 10
Training loss: 2.778989580528161
Validation loss: 2.9858241034329405

Epoch: 6| Step: 11
Training loss: 3.4401764593775237
Validation loss: 2.9874498912048133

Epoch: 6| Step: 12
Training loss: 3.3019702462808804
Validation loss: 2.986123265588827

Epoch: 6| Step: 13
Training loss: 3.073708866397977
Validation loss: 2.986234059576595

Epoch: 118| Step: 0
Training loss: 3.6074522767905455
Validation loss: 2.9863931645890553

Epoch: 6| Step: 1
Training loss: 3.1538566352999293
Validation loss: 2.9868312126415395

Epoch: 6| Step: 2
Training loss: 2.579914466120212
Validation loss: 2.9870620765955183

Epoch: 6| Step: 3
Training loss: 3.8056278515806774
Validation loss: 2.9886466716338784

Epoch: 6| Step: 4
Training loss: 3.616190630850357
Validation loss: 2.9858638805759123

Epoch: 6| Step: 5
Training loss: 3.825673840576671
Validation loss: 2.9863539627910334

Epoch: 6| Step: 6
Training loss: 3.095446035016712
Validation loss: 2.985983495583986

Epoch: 6| Step: 7
Training loss: 3.124891660719672
Validation loss: 2.98701439966955

Epoch: 6| Step: 8
Training loss: 3.224203877915028
Validation loss: 2.9851361277892208

Epoch: 6| Step: 9
Training loss: 3.1381818843473055
Validation loss: 2.986500673733494

Epoch: 6| Step: 10
Training loss: 3.2273131598798392
Validation loss: 2.9843991143385695

Epoch: 6| Step: 11
Training loss: 2.9848364028956063
Validation loss: 2.9860206932451603

Epoch: 6| Step: 12
Training loss: 3.407561163573751
Validation loss: 2.9844438205285932

Epoch: 6| Step: 13
Training loss: 2.1093193894579274
Validation loss: 2.984479194844777

Epoch: 119| Step: 0
Training loss: 3.4198808825534397
Validation loss: 2.982155656984916

Epoch: 6| Step: 1
Training loss: 3.102560118308705
Validation loss: 2.982267771765389

Epoch: 6| Step: 2
Training loss: 3.6560222848258945
Validation loss: 2.981356223990159

Epoch: 6| Step: 3
Training loss: 3.3810410299262745
Validation loss: 2.9880854849806457

Epoch: 6| Step: 4
Training loss: 3.204416154359453
Validation loss: 2.993340451462998

Epoch: 6| Step: 5
Training loss: 3.2030791488715273
Validation loss: 2.986703694420942

Epoch: 6| Step: 6
Training loss: 2.9322238369962523
Validation loss: 2.995851297196464

Epoch: 6| Step: 7
Training loss: 2.9461327177195327
Validation loss: 2.995379881087807

Epoch: 6| Step: 8
Training loss: 2.871958409074649
Validation loss: 2.98991926793423

Epoch: 6| Step: 9
Training loss: 3.2356049046694646
Validation loss: 2.984248680014563

Epoch: 6| Step: 10
Training loss: 3.6333571815291346
Validation loss: 2.9826568157044684

Epoch: 6| Step: 11
Training loss: 3.0585948413052813
Validation loss: 2.98056909991664

Epoch: 6| Step: 12
Training loss: 3.1581931600608097
Validation loss: 2.9794537932024827

Epoch: 6| Step: 13
Training loss: 4.058926228185786
Validation loss: 2.978151482469716

Epoch: 120| Step: 0
Training loss: 3.301890964299777
Validation loss: 2.980659435003472

Epoch: 6| Step: 1
Training loss: 3.456278608041639
Validation loss: 2.980703849811325

Epoch: 6| Step: 2
Training loss: 2.707603933465225
Validation loss: 2.9790427645931685

Epoch: 6| Step: 3
Training loss: 2.7622220930929946
Validation loss: 2.9830900231794826

Epoch: 6| Step: 4
Training loss: 3.578858279589761
Validation loss: 2.9803324007123586

Epoch: 6| Step: 5
Training loss: 3.484461625053042
Validation loss: 2.9812927427396843

Epoch: 6| Step: 6
Training loss: 2.744723720300688
Validation loss: 2.9800964483342187

Epoch: 6| Step: 7
Training loss: 3.3792308144334853
Validation loss: 2.979506616854618

Epoch: 6| Step: 8
Training loss: 3.384869168343763
Validation loss: 2.9793364303435794

Epoch: 6| Step: 9
Training loss: 3.177838211848362
Validation loss: 2.9790004463273263

Epoch: 6| Step: 10
Training loss: 3.1090172029830945
Validation loss: 2.979456837436951

Epoch: 6| Step: 11
Training loss: 3.256677663179988
Validation loss: 2.9784406234359864

Epoch: 6| Step: 12
Training loss: 4.286377001794601
Validation loss: 2.9792153824680394

Epoch: 6| Step: 13
Training loss: 2.1030532484582576
Validation loss: 2.9797046868854777

Epoch: 121| Step: 0
Training loss: 2.8612601314446966
Validation loss: 2.9765560455937

Epoch: 6| Step: 1
Training loss: 2.927281075492082
Validation loss: 2.9776758074526053

Epoch: 6| Step: 2
Training loss: 3.5040517243090608
Validation loss: 2.9744410009561104

Epoch: 6| Step: 3
Training loss: 3.4621257593506867
Validation loss: 2.977985147501623

Epoch: 6| Step: 4
Training loss: 2.7381967049905214
Validation loss: 2.979186736857553

Epoch: 6| Step: 5
Training loss: 3.812139024999331
Validation loss: 2.9768738847939176

Epoch: 6| Step: 6
Training loss: 3.257729947807491
Validation loss: 2.977538043083976

Epoch: 6| Step: 7
Training loss: 3.06330238263002
Validation loss: 2.9780725566422914

Epoch: 6| Step: 8
Training loss: 3.2780848177909974
Validation loss: 2.975927738522927

Epoch: 6| Step: 9
Training loss: 3.178602178678976
Validation loss: 2.9768865906977213

Epoch: 6| Step: 10
Training loss: 3.525480570398637
Validation loss: 2.9757689647534953

Epoch: 6| Step: 11
Training loss: 3.5437502099092613
Validation loss: 2.975535568654841

Epoch: 6| Step: 12
Training loss: 3.363001369833348
Validation loss: 2.976637848602938

Epoch: 6| Step: 13
Training loss: 2.606961350365556
Validation loss: 2.9771725306685495

Epoch: 122| Step: 0
Training loss: 2.8081967812080593
Validation loss: 2.9766209550618625

Epoch: 6| Step: 1
Training loss: 2.6699022293763326
Validation loss: 2.9763780831245534

Epoch: 6| Step: 2
Training loss: 3.2660377643128196
Validation loss: 2.9762727700149245

Epoch: 6| Step: 3
Training loss: 3.6864256506070503
Validation loss: 2.975460934833

Epoch: 6| Step: 4
Training loss: 4.335276510358324
Validation loss: 2.974439669335928

Epoch: 6| Step: 5
Training loss: 2.881876475644649
Validation loss: 2.975468384169312

Epoch: 6| Step: 6
Training loss: 2.9966332299301626
Validation loss: 2.9766500689079125

Epoch: 6| Step: 7
Training loss: 3.8811065794757558
Validation loss: 2.9752174141508063

Epoch: 6| Step: 8
Training loss: 2.2823090903590484
Validation loss: 2.971983410732946

Epoch: 6| Step: 9
Training loss: 3.448659642008184
Validation loss: 2.9741514746025857

Epoch: 6| Step: 10
Training loss: 3.3610724840142696
Validation loss: 2.974717609931765

Epoch: 6| Step: 11
Training loss: 2.994036787786866
Validation loss: 2.9749639566660773

Epoch: 6| Step: 12
Training loss: 3.643941915440677
Validation loss: 2.970367110380639

Epoch: 6| Step: 13
Training loss: 2.2644999900812817
Validation loss: 2.973605184741419

Epoch: 123| Step: 0
Training loss: 2.79001855358668
Validation loss: 2.9725716397343778

Epoch: 6| Step: 1
Training loss: 3.506870882544839
Validation loss: 2.9759383732190208

Epoch: 6| Step: 2
Training loss: 3.224068109289852
Validation loss: 2.974576847215106

Epoch: 6| Step: 3
Training loss: 3.3094432330279178
Validation loss: 2.9717320713471858

Epoch: 6| Step: 4
Training loss: 2.9377352031938604
Validation loss: 2.973794115000497

Epoch: 6| Step: 5
Training loss: 2.8564371327340146
Validation loss: 2.97083936309053

Epoch: 6| Step: 6
Training loss: 2.9368743230149583
Validation loss: 2.9713413623303384

Epoch: 6| Step: 7
Training loss: 2.726979658246104
Validation loss: 2.9749954314940896

Epoch: 6| Step: 8
Training loss: 3.193276799152153
Validation loss: 2.9860256127183487

Epoch: 6| Step: 9
Training loss: 3.8090622207875593
Validation loss: 2.9811238690158968

Epoch: 6| Step: 10
Training loss: 3.866066263435158
Validation loss: 2.974342259487267

Epoch: 6| Step: 11
Training loss: 3.537755324783938
Validation loss: 2.9736525895620387

Epoch: 6| Step: 12
Training loss: 3.5297957945375895
Validation loss: 2.968905136467655

Epoch: 6| Step: 13
Training loss: 2.820728049480484
Validation loss: 2.9709852161997867

Epoch: 124| Step: 0
Training loss: 2.74660742175764
Validation loss: 2.9696322465972256

Epoch: 6| Step: 1
Training loss: 3.1242729867213335
Validation loss: 2.970396140528037

Epoch: 6| Step: 2
Training loss: 3.9271223368170793
Validation loss: 2.969007301946131

Epoch: 6| Step: 3
Training loss: 3.9243991221782997
Validation loss: 2.970935345776464

Epoch: 6| Step: 4
Training loss: 3.184281463297489
Validation loss: 2.9685139500156277

Epoch: 6| Step: 5
Training loss: 2.513847813232631
Validation loss: 2.9713668904215376

Epoch: 6| Step: 6
Training loss: 3.165297881657659
Validation loss: 2.970111454004619

Epoch: 6| Step: 7
Training loss: 3.1237404382993637
Validation loss: 2.969576698831667

Epoch: 6| Step: 8
Training loss: 3.8690644612487204
Validation loss: 2.969526806480246

Epoch: 6| Step: 9
Training loss: 3.3991252334836495
Validation loss: 2.9700120990277887

Epoch: 6| Step: 10
Training loss: 3.6186486211882922
Validation loss: 2.971872344259051

Epoch: 6| Step: 11
Training loss: 3.041616117153178
Validation loss: 2.9794728931840133

Epoch: 6| Step: 12
Training loss: 3.073350485659362
Validation loss: 2.9863764077848294

Epoch: 6| Step: 13
Training loss: 1.3051054507799895
Validation loss: 2.976788053503332

Epoch: 125| Step: 0
Training loss: 3.328886706087387
Validation loss: 2.9716360764362255

Epoch: 6| Step: 1
Training loss: 3.2782081673457144
Validation loss: 2.969674220971055

Epoch: 6| Step: 2
Training loss: 2.9711729100826303
Validation loss: 2.9707591315081827

Epoch: 6| Step: 3
Training loss: 3.454516652548425
Validation loss: 2.969167962954528

Epoch: 6| Step: 4
Training loss: 2.9289330083154357
Validation loss: 2.9703099313113475

Epoch: 6| Step: 5
Training loss: 2.8235736284229835
Validation loss: 2.9683323918881097

Epoch: 6| Step: 6
Training loss: 3.14704807566967
Validation loss: 2.9673798193266077

Epoch: 6| Step: 7
Training loss: 3.4082762964476996
Validation loss: 2.967694909470875

Epoch: 6| Step: 8
Training loss: 3.8050623401643002
Validation loss: 2.963911053862585

Epoch: 6| Step: 9
Training loss: 2.8748470763295
Validation loss: 2.964270180047697

Epoch: 6| Step: 10
Training loss: 3.5773749085848223
Validation loss: 2.96662542186114

Epoch: 6| Step: 11
Training loss: 2.8357622917424785
Validation loss: 2.9683525004995652

Epoch: 6| Step: 12
Training loss: 3.5590397945707744
Validation loss: 2.9671187733008706

Epoch: 6| Step: 13
Training loss: 3.3970458941387243
Validation loss: 2.966719470418906

Epoch: 126| Step: 0
Training loss: 3.794765310154934
Validation loss: 2.9665241595287934

Epoch: 6| Step: 1
Training loss: 2.907730381793602
Validation loss: 2.9679484642713767

Epoch: 6| Step: 2
Training loss: 2.9790829377757317
Validation loss: 2.9683330966375228

Epoch: 6| Step: 3
Training loss: 2.7978674976367763
Validation loss: 2.966690654895008

Epoch: 6| Step: 4
Training loss: 3.4347102549148576
Validation loss: 2.9681429127292898

Epoch: 6| Step: 5
Training loss: 3.752008408909141
Validation loss: 2.9678604494438403

Epoch: 6| Step: 6
Training loss: 2.957669268655064
Validation loss: 2.9680570362519556

Epoch: 6| Step: 7
Training loss: 3.0706960812196593
Validation loss: 2.9662271864970124

Epoch: 6| Step: 8
Training loss: 3.1783897507182317
Validation loss: 2.965680695569877

Epoch: 6| Step: 9
Training loss: 3.537597218178458
Validation loss: 2.9647991347783282

Epoch: 6| Step: 10
Training loss: 3.0060740016881633
Validation loss: 2.9651823738770333

Epoch: 6| Step: 11
Training loss: 3.224265696593034
Validation loss: 2.9646431945614897

Epoch: 6| Step: 12
Training loss: 3.380579257513867
Validation loss: 2.9664972951955346

Epoch: 6| Step: 13
Training loss: 3.3469395621490126
Validation loss: 2.9676377678930277

Epoch: 127| Step: 0
Training loss: 3.998399652776745
Validation loss: 2.9679315843260645

Epoch: 6| Step: 1
Training loss: 3.308329998434261
Validation loss: 2.979979411886335

Epoch: 6| Step: 2
Training loss: 2.944261439252373
Validation loss: 2.971692037755388

Epoch: 6| Step: 3
Training loss: 3.229128355393745
Validation loss: 2.9864041217026163

Epoch: 6| Step: 4
Training loss: 2.6357980886879506
Validation loss: 2.969718741370932

Epoch: 6| Step: 5
Training loss: 2.8104500823488676
Validation loss: 2.9611843784473595

Epoch: 6| Step: 6
Training loss: 4.027096997017662
Validation loss: 2.9651876426295694

Epoch: 6| Step: 7
Training loss: 3.771526097403219
Validation loss: 2.9611738673773895

Epoch: 6| Step: 8
Training loss: 3.6235947351527136
Validation loss: 2.9624681799128894

Epoch: 6| Step: 9
Training loss: 2.8395609760780336
Validation loss: 2.958838931919367

Epoch: 6| Step: 10
Training loss: 2.488289106946485
Validation loss: 2.9604013544017023

Epoch: 6| Step: 11
Training loss: 3.030000252046984
Validation loss: 2.9600498566936553

Epoch: 6| Step: 12
Training loss: 3.170326193022733
Validation loss: 2.9593604484389457

Epoch: 6| Step: 13
Training loss: 3.0336196917953053
Validation loss: 2.9596039026446705

Epoch: 128| Step: 0
Training loss: 3.3362056436802314
Validation loss: 2.958856343739277

Epoch: 6| Step: 1
Training loss: 3.817086134824435
Validation loss: 2.9591233947406534

Epoch: 6| Step: 2
Training loss: 3.071152433864801
Validation loss: 2.957768392514873

Epoch: 6| Step: 3
Training loss: 3.139375200736761
Validation loss: 2.9597577558604695

Epoch: 6| Step: 4
Training loss: 3.572906419982156
Validation loss: 2.9566842722493165

Epoch: 6| Step: 5
Training loss: 3.0817004510964536
Validation loss: 2.9590231596537935

Epoch: 6| Step: 6
Training loss: 2.8083205640674223
Validation loss: 2.9576730495353076

Epoch: 6| Step: 7
Training loss: 4.008426373856567
Validation loss: 2.956535143527848

Epoch: 6| Step: 8
Training loss: 2.9364385107335953
Validation loss: 2.9584546969134897

Epoch: 6| Step: 9
Training loss: 3.0805075472488666
Validation loss: 2.9593621913977803

Epoch: 6| Step: 10
Training loss: 3.2965457986930593
Validation loss: 2.966037269471033

Epoch: 6| Step: 11
Training loss: 2.819030724056595
Validation loss: 2.9647246007759116

Epoch: 6| Step: 12
Training loss: 3.202216191576961
Validation loss: 2.9636081953590367

Epoch: 6| Step: 13
Training loss: 2.8282878681305847
Validation loss: 2.963118781732648

Epoch: 129| Step: 0
Training loss: 3.763838094733771
Validation loss: 2.9552464285252187

Epoch: 6| Step: 1
Training loss: 2.883857351619061
Validation loss: 2.9543648225776256

Epoch: 6| Step: 2
Training loss: 3.5334179730144415
Validation loss: 2.954393385193387

Epoch: 6| Step: 3
Training loss: 3.11257861547499
Validation loss: 2.9565510228672105

Epoch: 6| Step: 4
Training loss: 3.476061838510841
Validation loss: 2.9577949582300276

Epoch: 6| Step: 5
Training loss: 3.1463588924000954
Validation loss: 2.9568641205618413

Epoch: 6| Step: 6
Training loss: 3.286323621178419
Validation loss: 2.9556086788291043

Epoch: 6| Step: 7
Training loss: 3.568773067152629
Validation loss: 2.9547576185022786

Epoch: 6| Step: 8
Training loss: 3.213338803277432
Validation loss: 2.954337031987742

Epoch: 6| Step: 9
Training loss: 3.7104090906687346
Validation loss: 2.9565476628328224

Epoch: 6| Step: 10
Training loss: 2.7733627094339126
Validation loss: 2.9564571659153756

Epoch: 6| Step: 11
Training loss: 2.543387429831542
Validation loss: 2.9574190185897504

Epoch: 6| Step: 12
Training loss: 2.918991216130777
Validation loss: 2.953289938241935

Epoch: 6| Step: 13
Training loss: 3.177801449190316
Validation loss: 2.956619753158511

Epoch: 130| Step: 0
Training loss: 3.767824409151552
Validation loss: 2.9520757013005263

Epoch: 6| Step: 1
Training loss: 2.5521685112472974
Validation loss: 2.956147143656253

Epoch: 6| Step: 2
Training loss: 3.690869876706214
Validation loss: 2.9590448164935674

Epoch: 6| Step: 3
Training loss: 3.1498161686131985
Validation loss: 2.9658152402250377

Epoch: 6| Step: 4
Training loss: 3.0902323134908114
Validation loss: 2.9640358075810997

Epoch: 6| Step: 5
Training loss: 3.175308548960796
Validation loss: 2.964638865678198

Epoch: 6| Step: 6
Training loss: 2.79032958924457
Validation loss: 2.9589076532536516

Epoch: 6| Step: 7
Training loss: 3.4256403860363625
Validation loss: 2.954455623943417

Epoch: 6| Step: 8
Training loss: 3.329416230499438
Validation loss: 2.9553203132844117

Epoch: 6| Step: 9
Training loss: 2.3111692156375194
Validation loss: 2.9507541275179943

Epoch: 6| Step: 10
Training loss: 2.789462961036126
Validation loss: 2.9492528752481872

Epoch: 6| Step: 11
Training loss: 4.118301038338846
Validation loss: 2.9516350548469577

Epoch: 6| Step: 12
Training loss: 3.6940154365915103
Validation loss: 2.9490359187661315

Epoch: 6| Step: 13
Training loss: 2.7870752430077608
Validation loss: 2.9532942368849584

Epoch: 131| Step: 0
Training loss: 2.8211596793682063
Validation loss: 2.954421400863045

Epoch: 6| Step: 1
Training loss: 2.8716264918154124
Validation loss: 2.9541070471434465

Epoch: 6| Step: 2
Training loss: 2.9029266059683065
Validation loss: 2.9569383749869402

Epoch: 6| Step: 3
Training loss: 3.530165379138057
Validation loss: 2.956786740342813

Epoch: 6| Step: 4
Training loss: 3.425795725810351
Validation loss: 2.959239509537915

Epoch: 6| Step: 5
Training loss: 3.433860100146471
Validation loss: 2.959344590238489

Epoch: 6| Step: 6
Training loss: 3.9410121936236795
Validation loss: 2.9576341050238075

Epoch: 6| Step: 7
Training loss: 2.740435178962052
Validation loss: 2.957015292611367

Epoch: 6| Step: 8
Training loss: 3.4778863679333796
Validation loss: 2.95125029976643

Epoch: 6| Step: 9
Training loss: 3.5042184203714952
Validation loss: 2.952806893932972

Epoch: 6| Step: 10
Training loss: 3.0166744323405705
Validation loss: 2.950558347162787

Epoch: 6| Step: 11
Training loss: 2.7215612500019555
Validation loss: 2.9499035298943013

Epoch: 6| Step: 12
Training loss: 3.329776551135701
Validation loss: 2.952748273042243

Epoch: 6| Step: 13
Training loss: 3.5972676186333925
Validation loss: 2.9521507839112293

Epoch: 132| Step: 0
Training loss: 2.732729432995733
Validation loss: 2.958396525894568

Epoch: 6| Step: 1
Training loss: 3.4404154118618813
Validation loss: 2.9554847690329584

Epoch: 6| Step: 2
Training loss: 3.2122522340217974
Validation loss: 2.962830375310647

Epoch: 6| Step: 3
Training loss: 3.4158503479885525
Validation loss: 2.9563963888280225

Epoch: 6| Step: 4
Training loss: 3.3785621776586656
Validation loss: 2.9567916755077746

Epoch: 6| Step: 5
Training loss: 3.2838641697698225
Validation loss: 2.9469892074193753

Epoch: 6| Step: 6
Training loss: 3.521752337237999
Validation loss: 2.9497123359010664

Epoch: 6| Step: 7
Training loss: 3.231429818497533
Validation loss: 2.9481804523627226

Epoch: 6| Step: 8
Training loss: 3.002868711271165
Validation loss: 2.9505377219431015

Epoch: 6| Step: 9
Training loss: 3.220557584880565
Validation loss: 2.94707998898319

Epoch: 6| Step: 10
Training loss: 3.3908002254369456
Validation loss: 2.9476632624186543

Epoch: 6| Step: 11
Training loss: 2.7623097004656487
Validation loss: 2.9482395858086607

Epoch: 6| Step: 12
Training loss: 3.452384489586933
Validation loss: 2.943670180573014

Epoch: 6| Step: 13
Training loss: 3.0861321882811374
Validation loss: 2.944321785067696

Epoch: 133| Step: 0
Training loss: 3.123364745490674
Validation loss: 2.9465849737718868

Epoch: 6| Step: 1
Training loss: 2.7992114319041588
Validation loss: 2.9470089649436946

Epoch: 6| Step: 2
Training loss: 3.642626821892989
Validation loss: 2.946498408948407

Epoch: 6| Step: 3
Training loss: 3.650532090582489
Validation loss: 2.9483619758566353

Epoch: 6| Step: 4
Training loss: 3.35970939923596
Validation loss: 2.9518309930712734

Epoch: 6| Step: 5
Training loss: 2.6147201522551846
Validation loss: 2.951715373721562

Epoch: 6| Step: 6
Training loss: 3.25633912650939
Validation loss: 2.946026071054707

Epoch: 6| Step: 7
Training loss: 2.999829605349746
Validation loss: 2.9448968150026342

Epoch: 6| Step: 8
Training loss: 3.7130948190661623
Validation loss: 2.9435498137167886

Epoch: 6| Step: 9
Training loss: 2.906687713803492
Validation loss: 2.9444802119801134

Epoch: 6| Step: 10
Training loss: 2.505497514579239
Validation loss: 2.947354722794966

Epoch: 6| Step: 11
Training loss: 3.301913637118964
Validation loss: 2.955759007853186

Epoch: 6| Step: 12
Training loss: 3.4291758231639093
Validation loss: 2.978766678602439

Epoch: 6| Step: 13
Training loss: 4.022042101017034
Validation loss: 2.9591091484242735

Epoch: 134| Step: 0
Training loss: 2.356747408306121
Validation loss: 2.9457305248591603

Epoch: 6| Step: 1
Training loss: 3.216128865350398
Validation loss: 2.9440347391367707

Epoch: 6| Step: 2
Training loss: 3.177760184475704
Validation loss: 2.943743134912901

Epoch: 6| Step: 3
Training loss: 2.565224664378415
Validation loss: 2.946383459140656

Epoch: 6| Step: 4
Training loss: 2.974257650639516
Validation loss: 2.947547804005319

Epoch: 6| Step: 5
Training loss: 3.4783006759107264
Validation loss: 2.951222425121959

Epoch: 6| Step: 6
Training loss: 4.028018336219306
Validation loss: 2.9510249922389935

Epoch: 6| Step: 7
Training loss: 3.122675527093676
Validation loss: 2.9539119055965606

Epoch: 6| Step: 8
Training loss: 3.5941135388475076
Validation loss: 2.955193288338724

Epoch: 6| Step: 9
Training loss: 3.304797736599622
Validation loss: 2.951138327907198

Epoch: 6| Step: 10
Training loss: 3.092525972150878
Validation loss: 2.950446907745554

Epoch: 6| Step: 11
Training loss: 3.402994542559458
Validation loss: 2.945174369054707

Epoch: 6| Step: 12
Training loss: 3.4072905184865236
Validation loss: 2.942548006122163

Epoch: 6| Step: 13
Training loss: 3.3975615677016426
Validation loss: 2.9448847362817143

Epoch: 135| Step: 0
Training loss: 2.8660325886802895
Validation loss: 2.9412743279912617

Epoch: 6| Step: 1
Training loss: 3.539438122485035
Validation loss: 2.9423524691304177

Epoch: 6| Step: 2
Training loss: 2.9682687469715487
Validation loss: 2.942711540450558

Epoch: 6| Step: 3
Training loss: 2.326120114971736
Validation loss: 2.9450914936452386

Epoch: 6| Step: 4
Training loss: 3.420558728538491
Validation loss: 2.946281334037006

Epoch: 6| Step: 5
Training loss: 3.171652499508217
Validation loss: 2.944220250211457

Epoch: 6| Step: 6
Training loss: 4.059658054177187
Validation loss: 2.9471554894025855

Epoch: 6| Step: 7
Training loss: 2.475986449819288
Validation loss: 2.9518840687256764

Epoch: 6| Step: 8
Training loss: 3.2083941036925894
Validation loss: 2.9489266177880045

Epoch: 6| Step: 9
Training loss: 3.7569368416800737
Validation loss: 2.9520728511457612

Epoch: 6| Step: 10
Training loss: 3.8717594748343083
Validation loss: 2.944444643569984

Epoch: 6| Step: 11
Training loss: 2.795681405712624
Validation loss: 2.939868944877491

Epoch: 6| Step: 12
Training loss: 3.127284016397274
Validation loss: 2.939197972015516

Epoch: 6| Step: 13
Training loss: 3.1787497897491206
Validation loss: 2.9366388518304336

Epoch: 136| Step: 0
Training loss: 3.5186068626006004
Validation loss: 2.9408442011703495

Epoch: 6| Step: 1
Training loss: 3.7447932654082483
Validation loss: 2.9389988023852585

Epoch: 6| Step: 2
Training loss: 2.965887999052696
Validation loss: 2.9410102552730324

Epoch: 6| Step: 3
Training loss: 3.26150544891066
Validation loss: 2.9374281552198838

Epoch: 6| Step: 4
Training loss: 3.6686951199379654
Validation loss: 2.937204116096229

Epoch: 6| Step: 5
Training loss: 2.9145602294646027
Validation loss: 2.937121892126334

Epoch: 6| Step: 6
Training loss: 2.8668724947232964
Validation loss: 2.9365183425569334

Epoch: 6| Step: 7
Training loss: 3.6022048344298043
Validation loss: 2.938514144301015

Epoch: 6| Step: 8
Training loss: 2.8412773365295005
Validation loss: 2.9365126548230367

Epoch: 6| Step: 9
Training loss: 3.07463999555963
Validation loss: 2.9341244857942623

Epoch: 6| Step: 10
Training loss: 3.0462495602062285
Validation loss: 2.936022459979256

Epoch: 6| Step: 11
Training loss: 2.7573352433178973
Validation loss: 2.9353081016301323

Epoch: 6| Step: 12
Training loss: 3.5247829938605575
Validation loss: 2.935471821832026

Epoch: 6| Step: 13
Training loss: 3.151207701457041
Validation loss: 2.9359647831787026

Epoch: 137| Step: 0
Training loss: 2.6061651165721726
Validation loss: 2.936562077064926

Epoch: 6| Step: 1
Training loss: 2.8027428816290767
Validation loss: 2.939295235654931

Epoch: 6| Step: 2
Training loss: 2.837919357164857
Validation loss: 2.9381612165745628

Epoch: 6| Step: 3
Training loss: 3.2418434787833568
Validation loss: 2.9458113319436463

Epoch: 6| Step: 4
Training loss: 3.6404205395829052
Validation loss: 2.9547362243685438

Epoch: 6| Step: 5
Training loss: 3.502205290175213
Validation loss: 2.9355818857644596

Epoch: 6| Step: 6
Training loss: 3.5844735541925212
Validation loss: 2.9328600041772783

Epoch: 6| Step: 7
Training loss: 3.3006497870455194
Validation loss: 2.934790591209472

Epoch: 6| Step: 8
Training loss: 2.9549238589525504
Validation loss: 2.935402780654852

Epoch: 6| Step: 9
Training loss: 3.860781517567603
Validation loss: 2.936351776002696

Epoch: 6| Step: 10
Training loss: 3.329897699474391
Validation loss: 2.9385358266624135

Epoch: 6| Step: 11
Training loss: 2.501769393380663
Validation loss: 2.939683302231402

Epoch: 6| Step: 12
Training loss: 3.1448287538807818
Validation loss: 2.939617394004884

Epoch: 6| Step: 13
Training loss: 3.782163399332193
Validation loss: 2.9410574445460993

Epoch: 138| Step: 0
Training loss: 3.7984897021492614
Validation loss: 2.940544845637507

Epoch: 6| Step: 1
Training loss: 3.752433750043019
Validation loss: 2.939030972902895

Epoch: 6| Step: 2
Training loss: 3.011972379580604
Validation loss: 2.9397378765257387

Epoch: 6| Step: 3
Training loss: 2.4376747851183325
Validation loss: 2.9388860933245162

Epoch: 6| Step: 4
Training loss: 3.504982807373022
Validation loss: 2.9380787436617792

Epoch: 6| Step: 5
Training loss: 2.767985225825489
Validation loss: 2.936626417010775

Epoch: 6| Step: 6
Training loss: 2.930654137406136
Validation loss: 2.9347223306879586

Epoch: 6| Step: 7
Training loss: 3.3249006098756935
Validation loss: 2.93403548952229

Epoch: 6| Step: 8
Training loss: 3.658575378150274
Validation loss: 2.9322819843036574

Epoch: 6| Step: 9
Training loss: 1.7746878094210239
Validation loss: 2.9320565700663193

Epoch: 6| Step: 10
Training loss: 2.6595788180538884
Validation loss: 2.931830012249698

Epoch: 6| Step: 11
Training loss: 3.630892995070275
Validation loss: 2.9318832602353635

Epoch: 6| Step: 12
Training loss: 3.1937714757029303
Validation loss: 2.9328499789988998

Epoch: 6| Step: 13
Training loss: 4.505879270247581
Validation loss: 2.929817267056336

Epoch: 139| Step: 0
Training loss: 3.017087591602271
Validation loss: 2.9310843706581053

Epoch: 6| Step: 1
Training loss: 3.3423093740562524
Validation loss: 2.931969974140129

Epoch: 6| Step: 2
Training loss: 3.5214234408725624
Validation loss: 2.943544746612442

Epoch: 6| Step: 3
Training loss: 2.8601113293727307
Validation loss: 2.9379365239292325

Epoch: 6| Step: 4
Training loss: 2.357386679651317
Validation loss: 2.938339263616133

Epoch: 6| Step: 5
Training loss: 3.1068463802611794
Validation loss: 2.9379661799310517

Epoch: 6| Step: 6
Training loss: 3.621190930886491
Validation loss: 2.939520257018281

Epoch: 6| Step: 7
Training loss: 3.532546489002013
Validation loss: 2.9358611430126444

Epoch: 6| Step: 8
Training loss: 3.784495828528215
Validation loss: 2.9352376888557807

Epoch: 6| Step: 9
Training loss: 3.10611696015949
Validation loss: 2.9324379266677387

Epoch: 6| Step: 10
Training loss: 3.0706482526542045
Validation loss: 2.932579177828068

Epoch: 6| Step: 11
Training loss: 3.3572267272583445
Validation loss: 2.9299499262926383

Epoch: 6| Step: 12
Training loss: 2.7832263396784027
Validation loss: 2.930309586521191

Epoch: 6| Step: 13
Training loss: 3.4329559810137567
Validation loss: 2.9311192982829097

Epoch: 140| Step: 0
Training loss: 3.395073850612213
Validation loss: 2.9300369170269445

Epoch: 6| Step: 1
Training loss: 2.9277096188079423
Validation loss: 2.930393214173601

Epoch: 6| Step: 2
Training loss: 2.6294755475128992
Validation loss: 2.9308105923735965

Epoch: 6| Step: 3
Training loss: 3.5665923589173323
Validation loss: 2.9299400337788803

Epoch: 6| Step: 4
Training loss: 3.8447199892390467
Validation loss: 2.931492053515775

Epoch: 6| Step: 5
Training loss: 2.94017994154849
Validation loss: 2.930046273744951

Epoch: 6| Step: 6
Training loss: 3.1619318817445263
Validation loss: 2.929455614983087

Epoch: 6| Step: 7
Training loss: 2.5857323510427848
Validation loss: 2.9376808238267396

Epoch: 6| Step: 8
Training loss: 3.007450072015984
Validation loss: 2.9479553128520464

Epoch: 6| Step: 9
Training loss: 3.8730529077187636
Validation loss: 2.9441994325647487

Epoch: 6| Step: 10
Training loss: 3.101704860850439
Validation loss: 2.9475469638231164

Epoch: 6| Step: 11
Training loss: 2.4077521255320593
Validation loss: 2.940011960554206

Epoch: 6| Step: 12
Training loss: 3.81745076405689
Validation loss: 2.9394355642306356

Epoch: 6| Step: 13
Training loss: 3.4862591904949563
Validation loss: 2.938562855888384

Epoch: 141| Step: 0
Training loss: 3.6428485677922726
Validation loss: 2.935862175153659

Epoch: 6| Step: 1
Training loss: 2.5969117897631864
Validation loss: 2.927441324859895

Epoch: 6| Step: 2
Training loss: 3.481256432244815
Validation loss: 2.929459094479093

Epoch: 6| Step: 3
Training loss: 3.6416648067466704
Validation loss: 2.9277986226114217

Epoch: 6| Step: 4
Training loss: 3.2925351763607997
Validation loss: 2.9279450375916607

Epoch: 6| Step: 5
Training loss: 2.769793112014292
Validation loss: 2.9288992205072684

Epoch: 6| Step: 6
Training loss: 3.0693665423128165
Validation loss: 2.925546667464012

Epoch: 6| Step: 7
Training loss: 2.31178437578466
Validation loss: 2.927654972660807

Epoch: 6| Step: 8
Training loss: 3.5195495401768784
Validation loss: 2.9255836862935705

Epoch: 6| Step: 9
Training loss: 3.975197908285093
Validation loss: 2.9275282999393895

Epoch: 6| Step: 10
Training loss: 3.3560543237683853
Validation loss: 2.9264110069956804

Epoch: 6| Step: 11
Training loss: 2.835709659892479
Validation loss: 2.9228911888486775

Epoch: 6| Step: 12
Training loss: 3.449232297980896
Validation loss: 2.92736565665433

Epoch: 6| Step: 13
Training loss: 2.0499372798350013
Validation loss: 2.9238747481031604

Epoch: 142| Step: 0
Training loss: 4.10058489093372
Validation loss: 2.9232875788931074

Epoch: 6| Step: 1
Training loss: 2.6625922388566976
Validation loss: 2.923095831500164

Epoch: 6| Step: 2
Training loss: 2.5420019418512427
Validation loss: 2.924164522594602

Epoch: 6| Step: 3
Training loss: 3.4842377366198254
Validation loss: 2.9255840385595056

Epoch: 6| Step: 4
Training loss: 3.2246209091821276
Validation loss: 2.9232070340666865

Epoch: 6| Step: 5
Training loss: 2.8936678979814863
Validation loss: 2.924452272304518

Epoch: 6| Step: 6
Training loss: 2.8854832463667983
Validation loss: 2.923156948400747

Epoch: 6| Step: 7
Training loss: 2.92063902146451
Validation loss: 2.923845441061965

Epoch: 6| Step: 8
Training loss: 3.1283987255168464
Validation loss: 2.924586638789756

Epoch: 6| Step: 9
Training loss: 3.3706357076748206
Validation loss: 2.921015920840952

Epoch: 6| Step: 10
Training loss: 3.1312017319056067
Validation loss: 2.92665492985809

Epoch: 6| Step: 11
Training loss: 4.145132008694878
Validation loss: 2.923409780598895

Epoch: 6| Step: 12
Training loss: 3.2114089656817053
Validation loss: 2.924064613788334

Epoch: 6| Step: 13
Training loss: 2.5102398969745
Validation loss: 2.9225551692489113

Epoch: 143| Step: 0
Training loss: 3.1258557483096885
Validation loss: 2.9275928068967443

Epoch: 6| Step: 1
Training loss: 2.4287528543264094
Validation loss: 2.9256049483585165

Epoch: 6| Step: 2
Training loss: 2.6126098682718597
Validation loss: 2.92582485234885

Epoch: 6| Step: 3
Training loss: 3.554400421958553
Validation loss: 2.9233255752013587

Epoch: 6| Step: 4
Training loss: 3.508054185455353
Validation loss: 2.9189410967704745

Epoch: 6| Step: 5
Training loss: 3.3480504982260757
Validation loss: 2.9167178203708612

Epoch: 6| Step: 6
Training loss: 2.6642712821701053
Validation loss: 2.918548807033406

Epoch: 6| Step: 7
Training loss: 3.4224733151829905
Validation loss: 2.9181703933631367

Epoch: 6| Step: 8
Training loss: 3.193418804397306
Validation loss: 2.9196302191937193

Epoch: 6| Step: 9
Training loss: 2.7714448029459953
Validation loss: 2.9180776616899498

Epoch: 6| Step: 10
Training loss: 3.7341336607260045
Validation loss: 2.9175932512568945

Epoch: 6| Step: 11
Training loss: 2.9865127017435875
Validation loss: 2.919046201873901

Epoch: 6| Step: 12
Training loss: 3.6694832012302943
Validation loss: 2.9207716841602784

Epoch: 6| Step: 13
Training loss: 3.8319024580564522
Validation loss: 2.919720056698095

Epoch: 144| Step: 0
Training loss: 3.6469953737765635
Validation loss: 2.9195086381679194

Epoch: 6| Step: 1
Training loss: 3.4533868060396746
Validation loss: 2.9183786480477667

Epoch: 6| Step: 2
Training loss: 4.013475844893544
Validation loss: 2.9180336299370957

Epoch: 6| Step: 3
Training loss: 3.130079946989907
Validation loss: 2.916652576277724

Epoch: 6| Step: 4
Training loss: 2.8623861498451246
Validation loss: 2.918865874836301

Epoch: 6| Step: 5
Training loss: 2.9626242631692663
Validation loss: 2.917100728751431

Epoch: 6| Step: 6
Training loss: 2.6192126281990795
Validation loss: 2.91795186910172

Epoch: 6| Step: 7
Training loss: 2.381176195978354
Validation loss: 2.9159376636770125

Epoch: 6| Step: 8
Training loss: 2.366263936480849
Validation loss: 2.91791752714567

Epoch: 6| Step: 9
Training loss: 3.385935410101527
Validation loss: 2.916621058996686

Epoch: 6| Step: 10
Training loss: 3.291302061208858
Validation loss: 2.9168754262677417

Epoch: 6| Step: 11
Training loss: 3.848315744955964
Validation loss: 2.9152081201765494

Epoch: 6| Step: 12
Training loss: 2.8774824620167307
Validation loss: 2.9164403631309437

Epoch: 6| Step: 13
Training loss: 3.78388532121211
Validation loss: 2.914941881293765

Epoch: 145| Step: 0
Training loss: 2.2252290714943888
Validation loss: 2.9132203028734085

Epoch: 6| Step: 1
Training loss: 3.4917564040664915
Validation loss: 2.915089201458628

Epoch: 6| Step: 2
Training loss: 2.847710837846991
Validation loss: 2.917348691126948

Epoch: 6| Step: 3
Training loss: 3.5944250385036374
Validation loss: 2.918063985464736

Epoch: 6| Step: 4
Training loss: 3.2816365332226605
Validation loss: 2.9137807391658144

Epoch: 6| Step: 5
Training loss: 3.013987042010018
Validation loss: 2.91555748752221

Epoch: 6| Step: 6
Training loss: 3.112607875930831
Validation loss: 2.9183667222284755

Epoch: 6| Step: 7
Training loss: 3.0549230460356456
Validation loss: 2.916665068126422

Epoch: 6| Step: 8
Training loss: 3.735433133300525
Validation loss: 2.9159056700594244

Epoch: 6| Step: 9
Training loss: 3.140088087656489
Validation loss: 2.9304142278815837

Epoch: 6| Step: 10
Training loss: 3.7352611815046046
Validation loss: 2.9229762382179576

Epoch: 6| Step: 11
Training loss: 2.363073923143636
Validation loss: 2.9345698931719686

Epoch: 6| Step: 12
Training loss: 3.2858615984383452
Validation loss: 2.9383109672262426

Epoch: 6| Step: 13
Training loss: 3.908069644537776
Validation loss: 2.9336938865656426

Epoch: 146| Step: 0
Training loss: 3.19877008405718
Validation loss: 2.932659031662735

Epoch: 6| Step: 1
Training loss: 3.566416545071737
Validation loss: 2.9313858344642254

Epoch: 6| Step: 2
Training loss: 3.1999621150635202
Validation loss: 2.919264313144041

Epoch: 6| Step: 3
Training loss: 2.857435892609158
Validation loss: 2.9126885903863093

Epoch: 6| Step: 4
Training loss: 3.0826916585401953
Validation loss: 2.914209212759286

Epoch: 6| Step: 5
Training loss: 2.8258965074037374
Validation loss: 2.915034102379338

Epoch: 6| Step: 6
Training loss: 2.8791507115085304
Validation loss: 2.9158147980066182

Epoch: 6| Step: 7
Training loss: 3.537926767439877
Validation loss: 2.91858283236975

Epoch: 6| Step: 8
Training loss: 2.4506974570457403
Validation loss: 2.918936116932129

Epoch: 6| Step: 9
Training loss: 3.493108777213123
Validation loss: 2.9228451421020902

Epoch: 6| Step: 10
Training loss: 3.8920996142633135
Validation loss: 2.9201293805731416

Epoch: 6| Step: 11
Training loss: 3.2389856177561596
Validation loss: 2.9189549735238645

Epoch: 6| Step: 12
Training loss: 3.162782461948866
Validation loss: 2.9179660615736904

Epoch: 6| Step: 13
Training loss: 3.4991665256467206
Validation loss: 2.914987788164509

Epoch: 147| Step: 0
Training loss: 3.2730807380822995
Validation loss: 2.913202058608109

Epoch: 6| Step: 1
Training loss: 2.885141811753069
Validation loss: 2.9121084682516862

Epoch: 6| Step: 2
Training loss: 3.0559773953485565
Validation loss: 2.912953188802274

Epoch: 6| Step: 3
Training loss: 3.421917362038012
Validation loss: 2.9108762762249176

Epoch: 6| Step: 4
Training loss: 2.8880858120202686
Validation loss: 2.9101736289127107

Epoch: 6| Step: 5
Training loss: 3.623458139772838
Validation loss: 2.909814255082139

Epoch: 6| Step: 6
Training loss: 2.899502211631567
Validation loss: 2.909023955087161

Epoch: 6| Step: 7
Training loss: 3.1885650949615454
Validation loss: 2.9090333124155667

Epoch: 6| Step: 8
Training loss: 3.49682186792012
Validation loss: 2.9113471137825027

Epoch: 6| Step: 9
Training loss: 3.100003328629214
Validation loss: 2.911520135073047

Epoch: 6| Step: 10
Training loss: 3.5859559833656953
Validation loss: 2.913848078170912

Epoch: 6| Step: 11
Training loss: 3.107358652523097
Validation loss: 2.9160167520812923

Epoch: 6| Step: 12
Training loss: 3.4318120888616317
Validation loss: 2.910527009340581

Epoch: 6| Step: 13
Training loss: 2.4491075797761304
Validation loss: 2.910257923271372

Epoch: 148| Step: 0
Training loss: 2.797113163360578
Validation loss: 2.9101139281078394

Epoch: 6| Step: 1
Training loss: 3.7440852249177974
Validation loss: 2.908334147727658

Epoch: 6| Step: 2
Training loss: 3.396543338871452
Validation loss: 2.907871956802662

Epoch: 6| Step: 3
Training loss: 2.8558142331719
Validation loss: 2.9071495665460128

Epoch: 6| Step: 4
Training loss: 2.6941444409113724
Validation loss: 2.908030329509772

Epoch: 6| Step: 5
Training loss: 3.3226313134645022
Validation loss: 2.9094080796076205

Epoch: 6| Step: 6
Training loss: 3.0190119722475792
Validation loss: 2.906051461359214

Epoch: 6| Step: 7
Training loss: 3.115347182763557
Validation loss: 2.909624457773736

Epoch: 6| Step: 8
Training loss: 3.38340052896554
Validation loss: 2.9089344658519836

Epoch: 6| Step: 9
Training loss: 3.7873677347083894
Validation loss: 2.9090887807148897

Epoch: 6| Step: 10
Training loss: 2.957958161827442
Validation loss: 2.90792351970595

Epoch: 6| Step: 11
Training loss: 2.9336820098969265
Validation loss: 2.911891728818191

Epoch: 6| Step: 12
Training loss: 3.442974378469985
Validation loss: 2.90855871215171

Epoch: 6| Step: 13
Training loss: 3.1559846974281087
Validation loss: 2.908376064480837

Epoch: 149| Step: 0
Training loss: 3.0521132605499113
Validation loss: 2.907336212562464

Epoch: 6| Step: 1
Training loss: 3.3501151278626353
Validation loss: 2.90643276628323

Epoch: 6| Step: 2
Training loss: 3.7889609411727787
Validation loss: 2.905574478817912

Epoch: 6| Step: 3
Training loss: 3.227667150682626
Validation loss: 2.906126643595276

Epoch: 6| Step: 4
Training loss: 2.8963757196831894
Validation loss: 2.9079383994012553

Epoch: 6| Step: 5
Training loss: 3.8433181396034066
Validation loss: 2.9051489674560007

Epoch: 6| Step: 6
Training loss: 2.5302738144056067
Validation loss: 2.9057670065773085

Epoch: 6| Step: 7
Training loss: 2.6827487198141666
Validation loss: 2.904990848907165

Epoch: 6| Step: 8
Training loss: 3.851878186146738
Validation loss: 2.9064437002466477

Epoch: 6| Step: 9
Training loss: 3.136148783394907
Validation loss: 2.906484262104296

Epoch: 6| Step: 10
Training loss: 2.8665669364732684
Validation loss: 2.9053650319182887

Epoch: 6| Step: 11
Training loss: 3.062800022921463
Validation loss: 2.908803320337206

Epoch: 6| Step: 12
Training loss: 2.6186906284348277
Validation loss: 2.9076180900413333

Epoch: 6| Step: 13
Training loss: 3.704166829152456
Validation loss: 2.905688158855548

Epoch: 150| Step: 0
Training loss: 2.7765833246913116
Validation loss: 2.9082167056729156

Epoch: 6| Step: 1
Training loss: 3.1607410469800357
Validation loss: 2.9015873769297524

Epoch: 6| Step: 2
Training loss: 3.256793185157927
Validation loss: 2.903099465042357

Epoch: 6| Step: 3
Training loss: 3.6986057696079278
Validation loss: 2.9017453531647166

Epoch: 6| Step: 4
Training loss: 3.1051134206109765
Validation loss: 2.907429770033056

Epoch: 6| Step: 5
Training loss: 2.841298146744091
Validation loss: 2.9046756530402567

Epoch: 6| Step: 6
Training loss: 3.4309552397870005
Validation loss: 2.9000722780651222

Epoch: 6| Step: 7
Training loss: 2.965030950735314
Validation loss: 2.900961130154379

Epoch: 6| Step: 8
Training loss: 3.1710543768920227
Validation loss: 2.904015795410924

Epoch: 6| Step: 9
Training loss: 2.671954058988883
Validation loss: 2.902318624418813

Epoch: 6| Step: 10
Training loss: 3.2049738316650442
Validation loss: 2.9049421012253456

Epoch: 6| Step: 11
Training loss: 3.333963207497244
Validation loss: 2.903822590050911

Epoch: 6| Step: 12
Training loss: 3.4149758101537917
Validation loss: 2.903856667872408

Epoch: 6| Step: 13
Training loss: 3.7252626211281417
Validation loss: 2.901860549017687

Epoch: 151| Step: 0
Training loss: 3.3518047823175934
Validation loss: 2.89939904356456

Epoch: 6| Step: 1
Training loss: 2.6771023127455766
Validation loss: 2.9001632235020067

Epoch: 6| Step: 2
Training loss: 3.23555258723124
Validation loss: 2.900030079516948

Epoch: 6| Step: 3
Training loss: 3.034658815917915
Validation loss: 2.8995458042135036

Epoch: 6| Step: 4
Training loss: 2.324938135452038
Validation loss: 2.903547424358682

Epoch: 6| Step: 5
Training loss: 3.6996533824328037
Validation loss: 2.901663720019628

Epoch: 6| Step: 6
Training loss: 3.377176783729933
Validation loss: 2.9026577462139596

Epoch: 6| Step: 7
Training loss: 3.25154429205618
Validation loss: 2.8995289124310264

Epoch: 6| Step: 8
Training loss: 2.9033285244165734
Validation loss: 2.899171155758969

Epoch: 6| Step: 9
Training loss: 3.272624859507936
Validation loss: 2.9000419233896504

Epoch: 6| Step: 10
Training loss: 3.8015048209634816
Validation loss: 2.8988470636097845

Epoch: 6| Step: 11
Training loss: 2.8136112984593944
Validation loss: 2.900417505004861

Epoch: 6| Step: 12
Training loss: 3.222340775278351
Validation loss: 2.8988313050562464

Epoch: 6| Step: 13
Training loss: 3.6247349346196946
Validation loss: 2.899952346161287

Epoch: 152| Step: 0
Training loss: 2.490702697997007
Validation loss: 2.899554408772745

Epoch: 6| Step: 1
Training loss: 2.785842275997882
Validation loss: 2.8993248248666035

Epoch: 6| Step: 2
Training loss: 3.4472421099587494
Validation loss: 2.9012730952166907

Epoch: 6| Step: 3
Training loss: 2.982199150317725
Validation loss: 2.9055604993380406

Epoch: 6| Step: 4
Training loss: 3.44929063663764
Validation loss: 2.9049917764095285

Epoch: 6| Step: 5
Training loss: 3.280040118274506
Validation loss: 2.8979230965518608

Epoch: 6| Step: 6
Training loss: 3.860740759733446
Validation loss: 2.899020198653163

Epoch: 6| Step: 7
Training loss: 3.591966269285877
Validation loss: 2.896358505814526

Epoch: 6| Step: 8
Training loss: 2.936147175397668
Validation loss: 2.895364868794781

Epoch: 6| Step: 9
Training loss: 2.8921547630761366
Validation loss: 2.8987593385206494

Epoch: 6| Step: 10
Training loss: 3.4487553217128886
Validation loss: 2.899750675442648

Epoch: 6| Step: 11
Training loss: 3.1146108738799008
Validation loss: 2.897048338240141

Epoch: 6| Step: 12
Training loss: 2.9236368181714827
Validation loss: 2.8963351614217427

Epoch: 6| Step: 13
Training loss: 3.219143149059349
Validation loss: 2.896290828331674

Epoch: 153| Step: 0
Training loss: 2.5546279573646955
Validation loss: 2.8970899191981605

Epoch: 6| Step: 1
Training loss: 2.2691062752594093
Validation loss: 2.894871973919791

Epoch: 6| Step: 2
Training loss: 3.616858448856203
Validation loss: 2.894795380866099

Epoch: 6| Step: 3
Training loss: 3.3037486084073815
Validation loss: 2.9005714289161517

Epoch: 6| Step: 4
Training loss: 3.6733385131947114
Validation loss: 2.8959447969550607

Epoch: 6| Step: 5
Training loss: 3.42930152476476
Validation loss: 2.8954258069336216

Epoch: 6| Step: 6
Training loss: 3.070489543440419
Validation loss: 2.895733422956212

Epoch: 6| Step: 7
Training loss: 3.3303120908462205
Validation loss: 2.893622301398491

Epoch: 6| Step: 8
Training loss: 3.1444557323036038
Validation loss: 2.8980471701411954

Epoch: 6| Step: 9
Training loss: 2.9191112809331528
Validation loss: 2.893455514164929

Epoch: 6| Step: 10
Training loss: 3.375204574601391
Validation loss: 2.89464967152815

Epoch: 6| Step: 11
Training loss: 3.386951900495419
Validation loss: 2.8917120018564035

Epoch: 6| Step: 12
Training loss: 3.137138291136501
Validation loss: 2.893570384863507

Epoch: 6| Step: 13
Training loss: 3.0992632205696853
Validation loss: 2.892783368278541

Epoch: 154| Step: 0
Training loss: 3.630309984196923
Validation loss: 2.895246323334147

Epoch: 6| Step: 1
Training loss: 3.489880237000049
Validation loss: 2.8940860726513162

Epoch: 6| Step: 2
Training loss: 3.0437584220879375
Validation loss: 2.893916763493179

Epoch: 6| Step: 3
Training loss: 2.691819822207778
Validation loss: 2.895702427858982

Epoch: 6| Step: 4
Training loss: 3.7398466621421056
Validation loss: 2.896042013687003

Epoch: 6| Step: 5
Training loss: 3.4920995645737944
Validation loss: 2.90782729442748

Epoch: 6| Step: 6
Training loss: 3.112021388747744
Validation loss: 2.9071570515938934

Epoch: 6| Step: 7
Training loss: 3.1748330740714183
Validation loss: 2.8949563985695805

Epoch: 6| Step: 8
Training loss: 2.9983366487607355
Validation loss: 2.893344161390141

Epoch: 6| Step: 9
Training loss: 2.7378847104440145
Validation loss: 2.8933174690832204

Epoch: 6| Step: 10
Training loss: 3.2789909215523982
Validation loss: 2.894492541798285

Epoch: 6| Step: 11
Training loss: 2.694920077297741
Validation loss: 2.893647944581339

Epoch: 6| Step: 12
Training loss: 3.138577225402761
Validation loss: 2.8931307835146804

Epoch: 6| Step: 13
Training loss: 3.3300241415620744
Validation loss: 2.894180069962198

Epoch: 155| Step: 0
Training loss: 2.781334693562122
Validation loss: 2.8909742916452448

Epoch: 6| Step: 1
Training loss: 3.630310115545803
Validation loss: 2.891836548488101

Epoch: 6| Step: 2
Training loss: 2.840029619895244
Validation loss: 2.8941563085027555

Epoch: 6| Step: 3
Training loss: 3.8706377147660986
Validation loss: 2.89361982247456

Epoch: 6| Step: 4
Training loss: 2.749165495052899
Validation loss: 2.892996935273608

Epoch: 6| Step: 5
Training loss: 3.113371461257703
Validation loss: 2.892382658595555

Epoch: 6| Step: 6
Training loss: 3.793132428802944
Validation loss: 2.893071497520729

Epoch: 6| Step: 7
Training loss: 2.844003687012505
Validation loss: 2.8942726018253855

Epoch: 6| Step: 8
Training loss: 2.714657827913151
Validation loss: 2.8933381167671346

Epoch: 6| Step: 9
Training loss: 3.4425227143557064
Validation loss: 2.8904378354253497

Epoch: 6| Step: 10
Training loss: 3.6734047158488945
Validation loss: 2.8911786046767247

Epoch: 6| Step: 11
Training loss: 3.1853632029073284
Validation loss: 2.8912858016477223

Epoch: 6| Step: 12
Training loss: 2.8666359685392644
Validation loss: 2.891212676356288

Epoch: 6| Step: 13
Training loss: 2.3757365239156667
Validation loss: 2.8910834634262086

Epoch: 156| Step: 0
Training loss: 2.990484883724162
Validation loss: 2.8924304967442747

Epoch: 6| Step: 1
Training loss: 2.6486483239627647
Validation loss: 2.8943327223892825

Epoch: 6| Step: 2
Training loss: 3.6592572226656683
Validation loss: 2.8941242583474796

Epoch: 6| Step: 3
Training loss: 3.643208254394428
Validation loss: 2.8916950917960573

Epoch: 6| Step: 4
Training loss: 2.8252001227328996
Validation loss: 2.900788350459206

Epoch: 6| Step: 5
Training loss: 2.9476746009318116
Validation loss: 2.898067350672

Epoch: 6| Step: 6
Training loss: 2.955680750423715
Validation loss: 2.8952386870698956

Epoch: 6| Step: 7
Training loss: 3.042686047723256
Validation loss: 2.891918742709839

Epoch: 6| Step: 8
Training loss: 3.9696317879599894
Validation loss: 2.8934814769019206

Epoch: 6| Step: 9
Training loss: 2.8825486638774342
Validation loss: 2.8884404036507814

Epoch: 6| Step: 10
Training loss: 2.884445265619794
Validation loss: 2.8915561673944365

Epoch: 6| Step: 11
Training loss: 3.4701470663253264
Validation loss: 2.8919641197134784

Epoch: 6| Step: 12
Training loss: 3.209195074964251
Validation loss: 2.8910252164066153

Epoch: 6| Step: 13
Training loss: 3.1729838119752722
Validation loss: 2.8904794165776253

Epoch: 157| Step: 0
Training loss: 3.7167066842791527
Validation loss: 2.889760674338681

Epoch: 6| Step: 1
Training loss: 2.908580542899944
Validation loss: 2.8886247174388022

Epoch: 6| Step: 2
Training loss: 3.316761370765251
Validation loss: 2.887363342388199

Epoch: 6| Step: 3
Training loss: 3.533758707052649
Validation loss: 2.885413323603301

Epoch: 6| Step: 4
Training loss: 3.2687196806746948
Validation loss: 2.8838962719064485

Epoch: 6| Step: 5
Training loss: 2.942358665734391
Validation loss: 2.8869756462493346

Epoch: 6| Step: 6
Training loss: 3.3951957587770223
Validation loss: 2.8853070164330754

Epoch: 6| Step: 7
Training loss: 3.227432983317268
Validation loss: 2.88452131939935

Epoch: 6| Step: 8
Training loss: 3.1435742550940384
Validation loss: 2.884365203100945

Epoch: 6| Step: 9
Training loss: 3.6977619980537537
Validation loss: 2.885723050805712

Epoch: 6| Step: 10
Training loss: 3.1740973443509914
Validation loss: 2.8862758352581968

Epoch: 6| Step: 11
Training loss: 2.46719137315887
Validation loss: 2.8906030340892745

Epoch: 6| Step: 12
Training loss: 2.627906461830662
Validation loss: 2.890603618104848

Epoch: 6| Step: 13
Training loss: 2.522494774804502
Validation loss: 2.890146695613064

Epoch: 158| Step: 0
Training loss: 2.853134432690373
Validation loss: 2.8887642212191618

Epoch: 6| Step: 1
Training loss: 3.3748112378492046
Validation loss: 2.8880521029037043

Epoch: 6| Step: 2
Training loss: 3.3482971646178434
Validation loss: 2.882707296606642

Epoch: 6| Step: 3
Training loss: 2.4536480194213777
Validation loss: 2.886447777493092

Epoch: 6| Step: 4
Training loss: 3.178104090739047
Validation loss: 2.8839191542869416

Epoch: 6| Step: 5
Training loss: 2.5027850850128335
Validation loss: 2.885340708752388

Epoch: 6| Step: 6
Training loss: 3.326499721208862
Validation loss: 2.8856034064993787

Epoch: 6| Step: 7
Training loss: 3.5726170687651004
Validation loss: 2.8847456224656605

Epoch: 6| Step: 8
Training loss: 3.1256447699092633
Validation loss: 2.8856196699516317

Epoch: 6| Step: 9
Training loss: 3.47164342676211
Validation loss: 2.886681881961862

Epoch: 6| Step: 10
Training loss: 3.218113215890343
Validation loss: 2.881318490089852

Epoch: 6| Step: 11
Training loss: 3.303477541498882
Validation loss: 2.88299861413564

Epoch: 6| Step: 12
Training loss: 2.8766517869808363
Validation loss: 2.8839777377227986

Epoch: 6| Step: 13
Training loss: 3.9684915533544243
Validation loss: 2.88125619298392

Epoch: 159| Step: 0
Training loss: 3.240131360440523
Validation loss: 2.881243296702563

Epoch: 6| Step: 1
Training loss: 2.914326428281261
Validation loss: 2.884662443565443

Epoch: 6| Step: 2
Training loss: 3.1931350862556926
Validation loss: 2.87811385669604

Epoch: 6| Step: 3
Training loss: 3.1458670675393163
Validation loss: 2.88228182217494

Epoch: 6| Step: 4
Training loss: 3.5922656103455095
Validation loss: 2.880492760753139

Epoch: 6| Step: 5
Training loss: 3.436024852160992
Validation loss: 2.883283163451366

Epoch: 6| Step: 6
Training loss: 1.865562146532206
Validation loss: 2.882361755784294

Epoch: 6| Step: 7
Training loss: 3.0453523401323066
Validation loss: 2.883091174082096

Epoch: 6| Step: 8
Training loss: 2.588286931624367
Validation loss: 2.8796231076691763

Epoch: 6| Step: 9
Training loss: 3.5681070740717713
Validation loss: 2.8806046904092146

Epoch: 6| Step: 10
Training loss: 3.9589215025687206
Validation loss: 2.8836403264058963

Epoch: 6| Step: 11
Training loss: 3.0967161813424373
Validation loss: 2.8815164748315727

Epoch: 6| Step: 12
Training loss: 3.557944882442535
Validation loss: 2.882099095241874

Epoch: 6| Step: 13
Training loss: 2.508855394887488
Validation loss: 2.88166941110277

Epoch: 160| Step: 0
Training loss: 2.791051673522886
Validation loss: 2.880170741382301

Epoch: 6| Step: 1
Training loss: 2.6608674251269195
Validation loss: 2.880857064851224

Epoch: 6| Step: 2
Training loss: 2.760150555913317
Validation loss: 2.8828206582849774

Epoch: 6| Step: 3
Training loss: 2.7826330625073585
Validation loss: 2.883292081505664

Epoch: 6| Step: 4
Training loss: 3.0470166295708574
Validation loss: 2.8872364629049847

Epoch: 6| Step: 5
Training loss: 2.993876565635061
Validation loss: 2.886997942121697

Epoch: 6| Step: 6
Training loss: 2.7857949486257194
Validation loss: 2.879900614449007

Epoch: 6| Step: 7
Training loss: 2.599185625329017
Validation loss: 2.879967142450906

Epoch: 6| Step: 8
Training loss: 3.549660550933775
Validation loss: 2.8816326804128853

Epoch: 6| Step: 9
Training loss: 3.7498886091854553
Validation loss: 2.87952148161204

Epoch: 6| Step: 10
Training loss: 3.136620544948522
Validation loss: 2.8772344016557847

Epoch: 6| Step: 11
Training loss: 3.881992798520955
Validation loss: 2.879924467713121

Epoch: 6| Step: 12
Training loss: 3.9594423982322855
Validation loss: 2.8788938694744464

Epoch: 6| Step: 13
Training loss: 3.4411833016513325
Validation loss: 2.88352982506347

Epoch: 161| Step: 0
Training loss: 2.851398787306063
Validation loss: 2.8845206208356853

Epoch: 6| Step: 1
Training loss: 3.399064771267959
Validation loss: 2.881298476081358

Epoch: 6| Step: 2
Training loss: 3.6882300220011266
Validation loss: 2.8786366874794904

Epoch: 6| Step: 3
Training loss: 3.340736243141657
Validation loss: 2.878217230137597

Epoch: 6| Step: 4
Training loss: 3.483043878261936
Validation loss: 2.8777632985260424

Epoch: 6| Step: 5
Training loss: 2.1696503586950584
Validation loss: 2.8782466802358835

Epoch: 6| Step: 6
Training loss: 2.909042657376148
Validation loss: 2.8778785501624635

Epoch: 6| Step: 7
Training loss: 3.083453373677248
Validation loss: 2.8784701452169372

Epoch: 6| Step: 8
Training loss: 3.1642370105231765
Validation loss: 2.8782001232188232

Epoch: 6| Step: 9
Training loss: 3.5486951014729025
Validation loss: 2.877835550482038

Epoch: 6| Step: 10
Training loss: 3.0178894079939105
Validation loss: 2.8775004766013796

Epoch: 6| Step: 11
Training loss: 2.873586887875996
Validation loss: 2.8765917309047784

Epoch: 6| Step: 12
Training loss: 3.415599485757505
Validation loss: 2.87776930637749

Epoch: 6| Step: 13
Training loss: 3.395439842845017
Validation loss: 2.8749888751156694

Epoch: 162| Step: 0
Training loss: 2.6547267360830054
Validation loss: 2.8751413650320123

Epoch: 6| Step: 1
Training loss: 3.3248016527717015
Validation loss: 2.87570055629524

Epoch: 6| Step: 2
Training loss: 3.1400136779681627
Validation loss: 2.87645985766439

Epoch: 6| Step: 3
Training loss: 3.3386910931279687
Validation loss: 2.8761413363222235

Epoch: 6| Step: 4
Training loss: 3.4178233786049956
Validation loss: 2.8800130282156355

Epoch: 6| Step: 5
Training loss: 2.653027004054185
Validation loss: 2.879486582494639

Epoch: 6| Step: 6
Training loss: 2.8457683066166592
Validation loss: 2.8805036347614297

Epoch: 6| Step: 7
Training loss: 2.7405025163376924
Validation loss: 2.8888643569459482

Epoch: 6| Step: 8
Training loss: 3.777713603677644
Validation loss: 2.8814447119836353

Epoch: 6| Step: 9
Training loss: 3.0790098825750185
Validation loss: 2.8778019983481253

Epoch: 6| Step: 10
Training loss: 3.1715580824203764
Validation loss: 2.8746208326101694

Epoch: 6| Step: 11
Training loss: 3.415089049176632
Validation loss: 2.8726296330504892

Epoch: 6| Step: 12
Training loss: 3.814014821768388
Validation loss: 2.8754957377160184

Epoch: 6| Step: 13
Training loss: 2.3515505362678435
Validation loss: 2.872847082238324

Epoch: 163| Step: 0
Training loss: 2.9501385801707545
Validation loss: 2.8738539704603525

Epoch: 6| Step: 1
Training loss: 3.0203958830397055
Validation loss: 2.876391028390251

Epoch: 6| Step: 2
Training loss: 3.4993072914186016
Validation loss: 2.8729235822579846

Epoch: 6| Step: 3
Training loss: 3.5298894100858917
Validation loss: 2.879000535443611

Epoch: 6| Step: 4
Training loss: 3.020585008258211
Validation loss: 2.8747220486842755

Epoch: 6| Step: 5
Training loss: 3.3016988889484895
Validation loss: 2.874043257762339

Epoch: 6| Step: 6
Training loss: 2.287902329714383
Validation loss: 2.8737049048149728

Epoch: 6| Step: 7
Training loss: 3.311914644164232
Validation loss: 2.8741006523500356

Epoch: 6| Step: 8
Training loss: 3.115332948087797
Validation loss: 2.8798680210779297

Epoch: 6| Step: 9
Training loss: 3.606594848011775
Validation loss: 2.878380042726838

Epoch: 6| Step: 10
Training loss: 3.070266684464545
Validation loss: 2.8804964595937625

Epoch: 6| Step: 11
Training loss: 3.3831359849572116
Validation loss: 2.8784933735424936

Epoch: 6| Step: 12
Training loss: 3.036587921221466
Validation loss: 2.8853417945057127

Epoch: 6| Step: 13
Training loss: 2.859941270131874
Validation loss: 2.8901046856683443

Epoch: 164| Step: 0
Training loss: 3.2999002036986083
Validation loss: 2.9015944928748123

Epoch: 6| Step: 1
Training loss: 3.0159447060735007
Validation loss: 2.8919869816951342

Epoch: 6| Step: 2
Training loss: 2.5546565156043437
Validation loss: 2.8821007603941555

Epoch: 6| Step: 3
Training loss: 2.886788456427503
Validation loss: 2.8746688994530007

Epoch: 6| Step: 4
Training loss: 4.004978895953292
Validation loss: 2.868839943516212

Epoch: 6| Step: 5
Training loss: 3.2531842991300763
Validation loss: 2.8693145027113798

Epoch: 6| Step: 6
Training loss: 3.734916105132474
Validation loss: 2.870625380037769

Epoch: 6| Step: 7
Training loss: 3.2158682061135213
Validation loss: 2.869384145014934

Epoch: 6| Step: 8
Training loss: 3.1125674320867507
Validation loss: 2.8706792417657883

Epoch: 6| Step: 9
Training loss: 3.154006009228581
Validation loss: 2.868796015709145

Epoch: 6| Step: 10
Training loss: 2.558307474442637
Validation loss: 2.870706867031853

Epoch: 6| Step: 11
Training loss: 2.8619898112373607
Validation loss: 2.8693542867778263

Epoch: 6| Step: 12
Training loss: 3.2332499293421195
Validation loss: 2.8717826159166666

Epoch: 6| Step: 13
Training loss: 3.270973024402248
Validation loss: 2.870391533474754

Epoch: 165| Step: 0
Training loss: 3.347470504254738
Validation loss: 2.868959216402658

Epoch: 6| Step: 1
Training loss: 3.151219504306047
Validation loss: 2.8702042392163634

Epoch: 6| Step: 2
Training loss: 3.913469037351776
Validation loss: 2.8688632712612296

Epoch: 6| Step: 3
Training loss: 2.699129094844481
Validation loss: 2.87043277536869

Epoch: 6| Step: 4
Training loss: 2.673083829422237
Validation loss: 2.8663595226302396

Epoch: 6| Step: 5
Training loss: 2.909583855988147
Validation loss: 2.8662694580244246

Epoch: 6| Step: 6
Training loss: 3.6726540895547783
Validation loss: 2.866593897990062

Epoch: 6| Step: 7
Training loss: 3.888243164464622
Validation loss: 2.869596030489037

Epoch: 6| Step: 8
Training loss: 2.549495355374792
Validation loss: 2.8702875584375978

Epoch: 6| Step: 9
Training loss: 3.3276313809682976
Validation loss: 2.8755223271015677

Epoch: 6| Step: 10
Training loss: 2.8594016819110295
Validation loss: 2.871503991591127

Epoch: 6| Step: 11
Training loss: 3.274049833651348
Validation loss: 2.8737019234053522

Epoch: 6| Step: 12
Training loss: 2.510188893053388
Validation loss: 2.8791543408401257

Epoch: 6| Step: 13
Training loss: 3.202321617048118
Validation loss: 2.868828279125761

Epoch: 166| Step: 0
Training loss: 3.493596076645514
Validation loss: 2.8672003736662686

Epoch: 6| Step: 1
Training loss: 3.2811061282632656
Validation loss: 2.8667377705876436

Epoch: 6| Step: 2
Training loss: 3.29900851527211
Validation loss: 2.8652311807753845

Epoch: 6| Step: 3
Training loss: 2.1270282266211846
Validation loss: 2.864381361000426

Epoch: 6| Step: 4
Training loss: 2.7627772955867735
Validation loss: 2.864774955239555

Epoch: 6| Step: 5
Training loss: 3.5539755307344314
Validation loss: 2.8656525872482597

Epoch: 6| Step: 6
Training loss: 3.6676754575233
Validation loss: 2.863389531656229

Epoch: 6| Step: 7
Training loss: 3.3531584241184205
Validation loss: 2.868250501356822

Epoch: 6| Step: 8
Training loss: 3.281352159635481
Validation loss: 2.8648087172157912

Epoch: 6| Step: 9
Training loss: 3.2031839504864994
Validation loss: 2.8654408083063685

Epoch: 6| Step: 10
Training loss: 2.899165881987317
Validation loss: 2.866564545048937

Epoch: 6| Step: 11
Training loss: 3.2141524877640153
Validation loss: 2.867716308140207

Epoch: 6| Step: 12
Training loss: 3.030604972246092
Validation loss: 2.864173963424327

Epoch: 6| Step: 13
Training loss: 2.5260132673312303
Validation loss: 2.8628887139171675

Epoch: 167| Step: 0
Training loss: 2.9779177806769077
Validation loss: 2.862854076797267

Epoch: 6| Step: 1
Training loss: 3.657475714351938
Validation loss: 2.864079358169246

Epoch: 6| Step: 2
Training loss: 3.2659211092949985
Validation loss: 2.8650850085311514

Epoch: 6| Step: 3
Training loss: 3.875496494111006
Validation loss: 2.8627779148516974

Epoch: 6| Step: 4
Training loss: 2.552698510172694
Validation loss: 2.8615749177803274

Epoch: 6| Step: 5
Training loss: 3.2997343129795893
Validation loss: 2.8613383505935053

Epoch: 6| Step: 6
Training loss: 2.76895906162824
Validation loss: 2.863642511928084

Epoch: 6| Step: 7
Training loss: 1.968996547217415
Validation loss: 2.8677038650016295

Epoch: 6| Step: 8
Training loss: 3.2683713033501105
Validation loss: 2.8664825897134816

Epoch: 6| Step: 9
Training loss: 2.7498476679832717
Validation loss: 2.871785285981432

Epoch: 6| Step: 10
Training loss: 3.683547148101291
Validation loss: 2.876928646496251

Epoch: 6| Step: 11
Training loss: 2.735599091241348
Validation loss: 2.8702025921716605

Epoch: 6| Step: 12
Training loss: 3.637429861329803
Validation loss: 2.8650771147099294

Epoch: 6| Step: 13
Training loss: 3.3166089754182955
Validation loss: 2.8625017268498993

Epoch: 168| Step: 0
Training loss: 2.8280159101996376
Validation loss: 2.8622351407507285

Epoch: 6| Step: 1
Training loss: 3.718743588738565
Validation loss: 2.8598484225901397

Epoch: 6| Step: 2
Training loss: 2.918784562422924
Validation loss: 2.860098551079045

Epoch: 6| Step: 3
Training loss: 4.344131343211805
Validation loss: 2.8600079554089968

Epoch: 6| Step: 4
Training loss: 3.1982360746601888
Validation loss: 2.8590339794847197

Epoch: 6| Step: 5
Training loss: 2.9494363666608314
Validation loss: 2.860265816182873

Epoch: 6| Step: 6
Training loss: 3.139770543407047
Validation loss: 2.8603497914745324

Epoch: 6| Step: 7
Training loss: 2.9445139158998272
Validation loss: 2.8602605163883448

Epoch: 6| Step: 8
Training loss: 3.243853699307317
Validation loss: 2.8600316379959105

Epoch: 6| Step: 9
Training loss: 2.8625314102781654
Validation loss: 2.8639557304003462

Epoch: 6| Step: 10
Training loss: 2.92982502932404
Validation loss: 2.859658780207924

Epoch: 6| Step: 11
Training loss: 3.2810304114116207
Validation loss: 2.859711577296467

Epoch: 6| Step: 12
Training loss: 2.6737446629139696
Validation loss: 2.861020081238762

Epoch: 6| Step: 13
Training loss: 2.5432136288825187
Validation loss: 2.859466976231065

Epoch: 169| Step: 0
Training loss: 2.6089646250854974
Validation loss: 2.863785623730871

Epoch: 6| Step: 1
Training loss: 3.180179792155942
Validation loss: 2.860662729710282

Epoch: 6| Step: 2
Training loss: 3.343435254836512
Validation loss: 2.860214164951022

Epoch: 6| Step: 3
Training loss: 3.1257985429921855
Validation loss: 2.8577132582783396

Epoch: 6| Step: 4
Training loss: 2.945853348106006
Validation loss: 2.858642917453

Epoch: 6| Step: 5
Training loss: 3.272957195287628
Validation loss: 2.860423420754238

Epoch: 6| Step: 6
Training loss: 2.9740923546802445
Validation loss: 2.863910970377324

Epoch: 6| Step: 7
Training loss: 3.152881751304276
Validation loss: 2.859982722779739

Epoch: 6| Step: 8
Training loss: 2.6429032649430586
Validation loss: 2.864137764711861

Epoch: 6| Step: 9
Training loss: 2.7801031255462223
Validation loss: 2.865788251599792

Epoch: 6| Step: 10
Training loss: 2.7268307616732685
Validation loss: 2.8637792705396192

Epoch: 6| Step: 11
Training loss: 3.941779944073799
Validation loss: 2.862848929549372

Epoch: 6| Step: 12
Training loss: 3.792784194306351
Validation loss: 2.8620610640485027

Epoch: 6| Step: 13
Training loss: 3.585288793192373
Validation loss: 2.8585015140697263

Epoch: 170| Step: 0
Training loss: 3.137280861546131
Validation loss: 2.8617559129786656

Epoch: 6| Step: 1
Training loss: 2.556223463000007
Validation loss: 2.8589869060496493

Epoch: 6| Step: 2
Training loss: 3.165064222217571
Validation loss: 2.860365128375311

Epoch: 6| Step: 3
Training loss: 3.486221029736392
Validation loss: 2.856195471738498

Epoch: 6| Step: 4
Training loss: 3.0735025310763477
Validation loss: 2.857256983493429

Epoch: 6| Step: 5
Training loss: 3.4348574104309884
Validation loss: 2.8602304159146335

Epoch: 6| Step: 6
Training loss: 3.266704472173831
Validation loss: 2.8599860716656367

Epoch: 6| Step: 7
Training loss: 3.629413680127828
Validation loss: 2.8552552864140286

Epoch: 6| Step: 8
Training loss: 3.7913574819299396
Validation loss: 2.8585105031605353

Epoch: 6| Step: 9
Training loss: 3.637619152935975
Validation loss: 2.856195055265132

Epoch: 6| Step: 10
Training loss: 2.394309004011273
Validation loss: 2.849859309182523

Epoch: 6| Step: 11
Training loss: 2.6019785322143787
Validation loss: 2.8541985487469015

Epoch: 6| Step: 12
Training loss: 2.719382902996176
Validation loss: 2.853771492841096

Epoch: 6| Step: 13
Training loss: 2.7133862431996585
Validation loss: 2.85668764516644

Epoch: 171| Step: 0
Training loss: 2.3628042196757604
Validation loss: 2.8522305252127533

Epoch: 6| Step: 1
Training loss: 2.719790029555702
Validation loss: 2.8581886244349373

Epoch: 6| Step: 2
Training loss: 2.720873299539322
Validation loss: 2.8547909982463784

Epoch: 6| Step: 3
Training loss: 3.133565531574827
Validation loss: 2.8588120199746654

Epoch: 6| Step: 4
Training loss: 2.4533193717780417
Validation loss: 2.8634661357240785

Epoch: 6| Step: 5
Training loss: 3.8274515610612903
Validation loss: 2.8658064595660298

Epoch: 6| Step: 6
Training loss: 2.9951616053215204
Validation loss: 2.862505201754223

Epoch: 6| Step: 7
Training loss: 3.536656115267801
Validation loss: 2.861327325801982

Epoch: 6| Step: 8
Training loss: 3.73906027590171
Validation loss: 2.857407776574884

Epoch: 6| Step: 9
Training loss: 2.929167597098133
Validation loss: 2.8565730660246706

Epoch: 6| Step: 10
Training loss: 3.339774647494187
Validation loss: 2.863641697261693

Epoch: 6| Step: 11
Training loss: 3.728671390882619
Validation loss: 2.8606060347343245

Epoch: 6| Step: 12
Training loss: 3.3435859996471056
Validation loss: 2.8537022250408004

Epoch: 6| Step: 13
Training loss: 2.6381269749297607
Validation loss: 2.8531521319743702

Epoch: 172| Step: 0
Training loss: 3.606535484081227
Validation loss: 2.849192719220406

Epoch: 6| Step: 1
Training loss: 3.3517906982700705
Validation loss: 2.852785133751758

Epoch: 6| Step: 2
Training loss: 2.6202281995211636
Validation loss: 2.852116513063567

Epoch: 6| Step: 3
Training loss: 3.659998480165927
Validation loss: 2.852642796540844

Epoch: 6| Step: 4
Training loss: 2.624317898003032
Validation loss: 2.855051382425792

Epoch: 6| Step: 5
Training loss: 2.614269485989066
Validation loss: 2.8549535295591415

Epoch: 6| Step: 6
Training loss: 3.369196670729491
Validation loss: 2.855850925185325

Epoch: 6| Step: 7
Training loss: 2.88949447381527
Validation loss: 2.8557516310597624

Epoch: 6| Step: 8
Training loss: 2.9141539694822445
Validation loss: 2.8561353454605403

Epoch: 6| Step: 9
Training loss: 2.9869367379742338
Validation loss: 2.8508948254265216

Epoch: 6| Step: 10
Training loss: 3.965332482193131
Validation loss: 2.854088169530747

Epoch: 6| Step: 11
Training loss: 3.1659918283536594
Validation loss: 2.8530946632620453

Epoch: 6| Step: 12
Training loss: 3.0839635016017013
Validation loss: 2.850802551047325

Epoch: 6| Step: 13
Training loss: 2.9119795240059605
Validation loss: 2.8498651059891937

Epoch: 173| Step: 0
Training loss: 2.6636696802754836
Validation loss: 2.851874631576085

Epoch: 6| Step: 1
Training loss: 4.018519445661082
Validation loss: 2.849526464186728

Epoch: 6| Step: 2
Training loss: 2.6647747799177224
Validation loss: 2.8497647932130517

Epoch: 6| Step: 3
Training loss: 3.6015824919371244
Validation loss: 2.848474362959647

Epoch: 6| Step: 4
Training loss: 3.215652901664664
Validation loss: 2.8487316150188384

Epoch: 6| Step: 5
Training loss: 2.438630062186595
Validation loss: 2.8508771867657834

Epoch: 6| Step: 6
Training loss: 3.0746747348852685
Validation loss: 2.8544208140104237

Epoch: 6| Step: 7
Training loss: 3.465924461091891
Validation loss: 2.8603668733996597

Epoch: 6| Step: 8
Training loss: 3.258695706821329
Validation loss: 2.8535213074678767

Epoch: 6| Step: 9
Training loss: 2.1798294732128927
Validation loss: 2.850047922442117

Epoch: 6| Step: 10
Training loss: 3.206833344276161
Validation loss: 2.8571675256317555

Epoch: 6| Step: 11
Training loss: 3.691165460069933
Validation loss: 2.8534729248224684

Epoch: 6| Step: 12
Training loss: 2.984390658192725
Validation loss: 2.8515498281420117

Epoch: 6| Step: 13
Training loss: 3.229710850956496
Validation loss: 2.849736717093669

Epoch: 174| Step: 0
Training loss: 3.632651836165003
Validation loss: 2.852876308800084

Epoch: 6| Step: 1
Training loss: 3.807257628212597
Validation loss: 2.852149975460098

Epoch: 6| Step: 2
Training loss: 3.158606527653168
Validation loss: 2.8516222507152107

Epoch: 6| Step: 3
Training loss: 3.2822838017546916
Validation loss: 2.857941072784662

Epoch: 6| Step: 4
Training loss: 2.281795175285097
Validation loss: 2.86136272325086

Epoch: 6| Step: 5
Training loss: 3.7156963473079916
Validation loss: 2.861331978529014

Epoch: 6| Step: 6
Training loss: 3.0132087158777923
Validation loss: 2.853122011317975

Epoch: 6| Step: 7
Training loss: 2.9417878368230235
Validation loss: 2.851698358198483

Epoch: 6| Step: 8
Training loss: 2.7031271168253994
Validation loss: 2.8533035193537826

Epoch: 6| Step: 9
Training loss: 2.8905372400106994
Validation loss: 2.851442468858707

Epoch: 6| Step: 10
Training loss: 3.4934328320822927
Validation loss: 2.848216415300949

Epoch: 6| Step: 11
Training loss: 3.1488816773858415
Validation loss: 2.846059604812066

Epoch: 6| Step: 12
Training loss: 2.6100926126294226
Validation loss: 2.851775700623875

Epoch: 6| Step: 13
Training loss: 3.085761033819196
Validation loss: 2.8516122159333896

Epoch: 175| Step: 0
Training loss: 3.0750979338146727
Validation loss: 2.8582925427005086

Epoch: 6| Step: 1
Training loss: 2.7893266312364884
Validation loss: 2.8615965049319922

Epoch: 6| Step: 2
Training loss: 3.5258100349980666
Validation loss: 2.8582515211788353

Epoch: 6| Step: 3
Training loss: 2.728496051737239
Validation loss: 2.8612675125437037

Epoch: 6| Step: 4
Training loss: 3.9349601667974006
Validation loss: 2.856519921044235

Epoch: 6| Step: 5
Training loss: 2.872088077182819
Validation loss: 2.847836248372626

Epoch: 6| Step: 6
Training loss: 2.1774937244416828
Validation loss: 2.8502757020232012

Epoch: 6| Step: 7
Training loss: 3.524196230106709
Validation loss: 2.8549888641569536

Epoch: 6| Step: 8
Training loss: 3.62598879252415
Validation loss: 2.8667412528770506

Epoch: 6| Step: 9
Training loss: 3.2823609424198374
Validation loss: 2.871314983314437

Epoch: 6| Step: 10
Training loss: 3.315263279374998
Validation loss: 2.8608334781921534

Epoch: 6| Step: 11
Training loss: 2.812496354842473
Validation loss: 2.8744351767145835

Epoch: 6| Step: 12
Training loss: 2.3724984496807986
Validation loss: 2.8583957719711424

Epoch: 6| Step: 13
Training loss: 3.8086596047992387
Validation loss: 2.8520935364265374

Epoch: 176| Step: 0
Training loss: 3.167067619505235
Validation loss: 2.8458379585066256

Epoch: 6| Step: 1
Training loss: 1.7807620534642885
Validation loss: 2.8481292649097383

Epoch: 6| Step: 2
Training loss: 3.870148975550753
Validation loss: 2.843648027703301

Epoch: 6| Step: 3
Training loss: 3.6897096640644143
Validation loss: 2.842504493404698

Epoch: 6| Step: 4
Training loss: 3.159533162219004
Validation loss: 2.8450665631705663

Epoch: 6| Step: 5
Training loss: 2.263545482882147
Validation loss: 2.842143624105568

Epoch: 6| Step: 6
Training loss: 3.328462538817953
Validation loss: 2.843406783645952

Epoch: 6| Step: 7
Training loss: 3.547358811776692
Validation loss: 2.8373199820305945

Epoch: 6| Step: 8
Training loss: 2.9812927307009573
Validation loss: 2.8399455664174367

Epoch: 6| Step: 9
Training loss: 3.111670791903845
Validation loss: 2.8418042940218347

Epoch: 6| Step: 10
Training loss: 2.9827240376770567
Validation loss: 2.840194013197331

Epoch: 6| Step: 11
Training loss: 3.5858345764947597
Validation loss: 2.845253409175474

Epoch: 6| Step: 12
Training loss: 3.2387253257786224
Validation loss: 2.849367518209523

Epoch: 6| Step: 13
Training loss: 2.3049937933716196
Validation loss: 2.8560308612946064

Epoch: 177| Step: 0
Training loss: 2.6830207401743675
Validation loss: 2.8599176858492408

Epoch: 6| Step: 1
Training loss: 3.447122319082229
Validation loss: 2.8629626342904326

Epoch: 6| Step: 2
Training loss: 3.1021300596497277
Validation loss: 2.866527485765715

Epoch: 6| Step: 3
Training loss: 3.2629824811422465
Validation loss: 2.8690344279297753

Epoch: 6| Step: 4
Training loss: 3.7348784422594785
Validation loss: 2.844331651422833

Epoch: 6| Step: 5
Training loss: 3.4003523419639192
Validation loss: 2.844307429362878

Epoch: 6| Step: 6
Training loss: 3.1257315733036273
Validation loss: 2.8389754413323773

Epoch: 6| Step: 7
Training loss: 2.9897626408803277
Validation loss: 2.8404173039293066

Epoch: 6| Step: 8
Training loss: 2.6660274295755144
Validation loss: 2.8419777315933814

Epoch: 6| Step: 9
Training loss: 3.5521178630742796
Validation loss: 2.839827662224335

Epoch: 6| Step: 10
Training loss: 3.1399550601148762
Validation loss: 2.8425896707013933

Epoch: 6| Step: 11
Training loss: 3.6246002239905635
Validation loss: 2.838967759363708

Epoch: 6| Step: 12
Training loss: 1.986751425021006
Validation loss: 2.843178705334589

Epoch: 6| Step: 13
Training loss: 2.826428405043919
Validation loss: 2.8435680750860595

Epoch: 178| Step: 0
Training loss: 3.4202235865984285
Validation loss: 2.8394666396173402

Epoch: 6| Step: 1
Training loss: 2.8223058361105986
Validation loss: 2.8394133378785615

Epoch: 6| Step: 2
Training loss: 3.318833827452523
Validation loss: 2.837088344807025

Epoch: 6| Step: 3
Training loss: 3.283968571306909
Validation loss: 2.8364330059887743

Epoch: 6| Step: 4
Training loss: 3.321002771768674
Validation loss: 2.8472014123206333

Epoch: 6| Step: 5
Training loss: 3.7662184631465547
Validation loss: 2.842925309016925

Epoch: 6| Step: 6
Training loss: 3.038133807833644
Validation loss: 2.8421698688536887

Epoch: 6| Step: 7
Training loss: 2.963185928706381
Validation loss: 2.8356830036728797

Epoch: 6| Step: 8
Training loss: 2.64810331593671
Validation loss: 2.832944155306459

Epoch: 6| Step: 9
Training loss: 2.993227944618048
Validation loss: 2.8346113408676303

Epoch: 6| Step: 10
Training loss: 2.4267652791635634
Validation loss: 2.833175179436555

Epoch: 6| Step: 11
Training loss: 3.6850126250217685
Validation loss: 2.840655135989155

Epoch: 6| Step: 12
Training loss: 3.405946210560789
Validation loss: 2.8383712068606797

Epoch: 6| Step: 13
Training loss: 2.076188526104736
Validation loss: 2.841941591144305

Epoch: 179| Step: 0
Training loss: 3.5329738224116793
Validation loss: 2.8465418065544914

Epoch: 6| Step: 1
Training loss: 3.044021287299775
Validation loss: 2.8437529442974876

Epoch: 6| Step: 2
Training loss: 3.397000274173073
Validation loss: 2.852092331051337

Epoch: 6| Step: 3
Training loss: 2.727085883069188
Validation loss: 2.844745469414466

Epoch: 6| Step: 4
Training loss: 3.049681168448107
Validation loss: 2.8391189667012378

Epoch: 6| Step: 5
Training loss: 2.493173816630449
Validation loss: 2.8369475180583565

Epoch: 6| Step: 6
Training loss: 3.051089145494586
Validation loss: 2.8361571282924185

Epoch: 6| Step: 7
Training loss: 2.9243660981674027
Validation loss: 2.8364067117738556

Epoch: 6| Step: 8
Training loss: 3.3043680239524966
Validation loss: 2.8359413563908813

Epoch: 6| Step: 9
Training loss: 3.5521277968382274
Validation loss: 2.8365879554172433

Epoch: 6| Step: 10
Training loss: 2.8743351706681395
Validation loss: 2.838864359144202

Epoch: 6| Step: 11
Training loss: 3.4900268424676937
Validation loss: 2.8392229671311364

Epoch: 6| Step: 12
Training loss: 2.9802705191389145
Validation loss: 2.837768089521061

Epoch: 6| Step: 13
Training loss: 3.4209688284490003
Validation loss: 2.8395644790559986

Epoch: 180| Step: 0
Training loss: 2.959042226899395
Validation loss: 2.8377596969195618

Epoch: 6| Step: 1
Training loss: 2.9734220984456448
Validation loss: 2.838291792960083

Epoch: 6| Step: 2
Training loss: 3.4093868265899654
Validation loss: 2.8364744316267485

Epoch: 6| Step: 3
Training loss: 3.2250775113512593
Validation loss: 2.8390288226294396

Epoch: 6| Step: 4
Training loss: 2.7080819428976373
Validation loss: 2.8441539424775075

Epoch: 6| Step: 5
Training loss: 3.013082747069193
Validation loss: 2.8402754589252233

Epoch: 6| Step: 6
Training loss: 2.596332597148734
Validation loss: 2.848666024236552

Epoch: 6| Step: 7
Training loss: 3.1183568916946456
Validation loss: 2.853280909873891

Epoch: 6| Step: 8
Training loss: 3.423584114950102
Validation loss: 2.8645993629223354

Epoch: 6| Step: 9
Training loss: 3.4334504289627557
Validation loss: 2.8610841164286316

Epoch: 6| Step: 10
Training loss: 3.456163683291155
Validation loss: 2.8600686953987444

Epoch: 6| Step: 11
Training loss: 3.489088898356877
Validation loss: 2.8441726972622026

Epoch: 6| Step: 12
Training loss: 3.135141776740904
Validation loss: 2.8362607822236674

Epoch: 6| Step: 13
Training loss: 2.8848261223133442
Validation loss: 2.8373697171196524

Epoch: 181| Step: 0
Training loss: 3.2707208180766214
Validation loss: 2.836909948077067

Epoch: 6| Step: 1
Training loss: 3.4663930222519195
Validation loss: 2.8357639099724135

Epoch: 6| Step: 2
Training loss: 3.4277580238678502
Validation loss: 2.83616535796068

Epoch: 6| Step: 3
Training loss: 2.8059584094423102
Validation loss: 2.8365612975096814

Epoch: 6| Step: 4
Training loss: 2.596215053391107
Validation loss: 2.836230031140614

Epoch: 6| Step: 5
Training loss: 3.6052716863636114
Validation loss: 2.8358584428312454

Epoch: 6| Step: 6
Training loss: 3.3069326290977132
Validation loss: 2.8327214474874163

Epoch: 6| Step: 7
Training loss: 2.685682436209248
Validation loss: 2.835625986457192

Epoch: 6| Step: 8
Training loss: 3.065749332500386
Validation loss: 2.831494588559054

Epoch: 6| Step: 9
Training loss: 3.4443771926576643
Validation loss: 2.835255185206466

Epoch: 6| Step: 10
Training loss: 3.3299735939422312
Validation loss: 2.8341751844585903

Epoch: 6| Step: 11
Training loss: 2.9501211238499585
Validation loss: 2.833611234636209

Epoch: 6| Step: 12
Training loss: 2.490610131730293
Validation loss: 2.8303861678062647

Epoch: 6| Step: 13
Training loss: 3.3777539355568695
Validation loss: 2.833116281171217

Epoch: 182| Step: 0
Training loss: 3.5102374354639485
Validation loss: 2.8295627026895436

Epoch: 6| Step: 1
Training loss: 3.680369320042376
Validation loss: 2.833500597201108

Epoch: 6| Step: 2
Training loss: 4.043141413885468
Validation loss: 2.833307710986549

Epoch: 6| Step: 3
Training loss: 2.5515255273031254
Validation loss: 2.8328876698307353

Epoch: 6| Step: 4
Training loss: 3.8510677491882546
Validation loss: 2.828419593592846

Epoch: 6| Step: 5
Training loss: 2.6236377996304867
Validation loss: 2.832168309420958

Epoch: 6| Step: 6
Training loss: 2.8972856644092597
Validation loss: 2.8299992655935

Epoch: 6| Step: 7
Training loss: 2.4291934771445964
Validation loss: 2.829319898822209

Epoch: 6| Step: 8
Training loss: 2.9578783643576285
Validation loss: 2.830486812772069

Epoch: 6| Step: 9
Training loss: 3.1711910619134365
Validation loss: 2.8305057541205962

Epoch: 6| Step: 10
Training loss: 3.0657763958021493
Validation loss: 2.828046481367636

Epoch: 6| Step: 11
Training loss: 3.0477503375032176
Validation loss: 2.8301183428679066

Epoch: 6| Step: 12
Training loss: 2.8096301377722086
Validation loss: 2.8295883574379195

Epoch: 6| Step: 13
Training loss: 2.43111169416772
Validation loss: 2.834019225655039

Epoch: 183| Step: 0
Training loss: 3.204983651153715
Validation loss: 2.8335146915318217

Epoch: 6| Step: 1
Training loss: 3.391333861897705
Validation loss: 2.8340902083638277

Epoch: 6| Step: 2
Training loss: 2.792849750251171
Validation loss: 2.8416174575961404

Epoch: 6| Step: 3
Training loss: 3.2752351399812456
Validation loss: 2.8448486973293403

Epoch: 6| Step: 4
Training loss: 3.460634653175453
Validation loss: 2.8459512213903464

Epoch: 6| Step: 5
Training loss: 2.9169764944547736
Validation loss: 2.8324649398098356

Epoch: 6| Step: 6
Training loss: 2.7588225938227726
Validation loss: 2.8358249463999576

Epoch: 6| Step: 7
Training loss: 3.310074259913233
Validation loss: 2.8277142818585688

Epoch: 6| Step: 8
Training loss: 3.094249338253974
Validation loss: 2.8267186117749104

Epoch: 6| Step: 9
Training loss: 2.841086009672264
Validation loss: 2.826424075811272

Epoch: 6| Step: 10
Training loss: 3.062315331944237
Validation loss: 2.8255818817422558

Epoch: 6| Step: 11
Training loss: 3.3469314413716615
Validation loss: 2.82610271993536

Epoch: 6| Step: 12
Training loss: 3.277960299853705
Validation loss: 2.822905355899363

Epoch: 6| Step: 13
Training loss: 3.0203883051548215
Validation loss: 2.823773196974076

Epoch: 184| Step: 0
Training loss: 2.759031377632598
Validation loss: 2.825028986468601

Epoch: 6| Step: 1
Training loss: 3.4385820939766147
Validation loss: 2.825409912061329

Epoch: 6| Step: 2
Training loss: 2.783063404524722
Validation loss: 2.82475208621588

Epoch: 6| Step: 3
Training loss: 3.1827222134308566
Validation loss: 2.8256668551356343

Epoch: 6| Step: 4
Training loss: 3.3948324089652697
Validation loss: 2.823243469664092

Epoch: 6| Step: 5
Training loss: 3.327267818475732
Validation loss: 2.8269336008213526

Epoch: 6| Step: 6
Training loss: 2.8677542227719868
Validation loss: 2.8234776564315336

Epoch: 6| Step: 7
Training loss: 3.019494612892223
Validation loss: 2.823064157176036

Epoch: 6| Step: 8
Training loss: 3.2685621276898438
Validation loss: 2.8246682633559037

Epoch: 6| Step: 9
Training loss: 3.7858674411691293
Validation loss: 2.8282347491107602

Epoch: 6| Step: 10
Training loss: 2.5811825279303044
Validation loss: 2.8255495219189304

Epoch: 6| Step: 11
Training loss: 3.558497137606961
Validation loss: 2.8284783712241928

Epoch: 6| Step: 12
Training loss: 2.711325318137594
Validation loss: 2.831869912535991

Epoch: 6| Step: 13
Training loss: 2.696792682615824
Validation loss: 2.8326356277293057

Epoch: 185| Step: 0
Training loss: 2.894730904678023
Validation loss: 2.832567931947421

Epoch: 6| Step: 1
Training loss: 3.6039526697622195
Validation loss: 2.8359971613777852

Epoch: 6| Step: 2
Training loss: 3.546246981372429
Validation loss: 2.8372267827491044

Epoch: 6| Step: 3
Training loss: 3.523887994560208
Validation loss: 2.8311204273187385

Epoch: 6| Step: 4
Training loss: 2.687878072005548
Validation loss: 2.8326223698082416

Epoch: 6| Step: 5
Training loss: 3.2356703371198954
Validation loss: 2.8352173513748835

Epoch: 6| Step: 6
Training loss: 2.824103599722888
Validation loss: 2.824889553262153

Epoch: 6| Step: 7
Training loss: 2.6872121967308034
Validation loss: 2.8282052255738033

Epoch: 6| Step: 8
Training loss: 3.2947324326374883
Validation loss: 2.8223213197969668

Epoch: 6| Step: 9
Training loss: 3.744720302674643
Validation loss: 2.8221927552088077

Epoch: 6| Step: 10
Training loss: 2.5968913163867207
Validation loss: 2.8212509668659616

Epoch: 6| Step: 11
Training loss: 2.708287683738004
Validation loss: 2.824059596974314

Epoch: 6| Step: 12
Training loss: 3.103281769725329
Validation loss: 2.822431854099999

Epoch: 6| Step: 13
Training loss: 3.0156835046340773
Validation loss: 2.8289810468699055

Epoch: 186| Step: 0
Training loss: 3.041631323900822
Validation loss: 2.8281690500849423

Epoch: 6| Step: 1
Training loss: 2.5865568128179706
Validation loss: 2.830313687338286

Epoch: 6| Step: 2
Training loss: 3.2948217280645946
Validation loss: 2.831016441649755

Epoch: 6| Step: 3
Training loss: 3.576472937986175
Validation loss: 2.8302209856100156

Epoch: 6| Step: 4
Training loss: 2.638654526682423
Validation loss: 2.8299623760947483

Epoch: 6| Step: 5
Training loss: 2.4179168843513517
Validation loss: 2.8286209827293036

Epoch: 6| Step: 6
Training loss: 3.203690939428455
Validation loss: 2.82953441841322

Epoch: 6| Step: 7
Training loss: 2.771115472717578
Validation loss: 2.825558872608581

Epoch: 6| Step: 8
Training loss: 2.751855397705848
Validation loss: 2.825254706188503

Epoch: 6| Step: 9
Training loss: 3.374659203171311
Validation loss: 2.825591973583533

Epoch: 6| Step: 10
Training loss: 3.518767719664601
Validation loss: 2.823476042055609

Epoch: 6| Step: 11
Training loss: 3.3077637983727306
Validation loss: 2.822915648021377

Epoch: 6| Step: 12
Training loss: 3.715742032683995
Validation loss: 2.8232552197809864

Epoch: 6| Step: 13
Training loss: 3.5953610996772984
Validation loss: 2.8340247925294038

Epoch: 187| Step: 0
Training loss: 3.577872454797042
Validation loss: 2.825996743472794

Epoch: 6| Step: 1
Training loss: 2.732609118684928
Validation loss: 2.8315732333938053

Epoch: 6| Step: 2
Training loss: 3.04952730987274
Validation loss: 2.8400140296497645

Epoch: 6| Step: 3
Training loss: 2.917419627046037
Validation loss: 2.8364099375553304

Epoch: 6| Step: 4
Training loss: 3.4189517280716726
Validation loss: 2.8318806699806305

Epoch: 6| Step: 5
Training loss: 3.065622722846536
Validation loss: 2.837407286434252

Epoch: 6| Step: 6
Training loss: 2.8843356608211654
Validation loss: 2.8396658613108294

Epoch: 6| Step: 7
Training loss: 3.1155597767942633
Validation loss: 2.840980157181442

Epoch: 6| Step: 8
Training loss: 3.3979107327919107
Validation loss: 2.834613156915098

Epoch: 6| Step: 9
Training loss: 3.4362069212099398
Validation loss: 2.831654022632212

Epoch: 6| Step: 10
Training loss: 3.2351415343181373
Validation loss: 2.8243271495669453

Epoch: 6| Step: 11
Training loss: 3.1778881783711266
Validation loss: 2.8198377527655185

Epoch: 6| Step: 12
Training loss: 2.7202328551419725
Validation loss: 2.8169103154322968

Epoch: 6| Step: 13
Training loss: 2.825026189632042
Validation loss: 2.8181272245422746

Epoch: 188| Step: 0
Training loss: 2.532099263455656
Validation loss: 2.8154300899710987

Epoch: 6| Step: 1
Training loss: 2.9355756259507726
Validation loss: 2.8149011477698083

Epoch: 6| Step: 2
Training loss: 3.1406634124380552
Validation loss: 2.815806652051778

Epoch: 6| Step: 3
Training loss: 3.1372402797970627
Validation loss: 2.8159375475099764

Epoch: 6| Step: 4
Training loss: 3.7564394022434398
Validation loss: 2.816955491915194

Epoch: 6| Step: 5
Training loss: 3.1606547524770034
Validation loss: 2.815445794494142

Epoch: 6| Step: 6
Training loss: 2.985929074517564
Validation loss: 2.812660767803913

Epoch: 6| Step: 7
Training loss: 2.8879779964993086
Validation loss: 2.8147942249646896

Epoch: 6| Step: 8
Training loss: 3.1625973170087245
Validation loss: 2.8157592811343997

Epoch: 6| Step: 9
Training loss: 3.364201259276121
Validation loss: 2.813966166127398

Epoch: 6| Step: 10
Training loss: 3.1716979029031553
Validation loss: 2.8122081928799956

Epoch: 6| Step: 11
Training loss: 3.3482162737159276
Validation loss: 2.8152692171419567

Epoch: 6| Step: 12
Training loss: 2.9326414144749364
Validation loss: 2.816982460037172

Epoch: 6| Step: 13
Training loss: 2.956623245774824
Validation loss: 2.8153894182456214

Epoch: 189| Step: 0
Training loss: 2.323277489617245
Validation loss: 2.8205884727377706

Epoch: 6| Step: 1
Training loss: 2.3494749213075825
Validation loss: 2.821266071059483

Epoch: 6| Step: 2
Training loss: 3.3538753469888603
Validation loss: 2.82401788664133

Epoch: 6| Step: 3
Training loss: 3.0793657464766557
Validation loss: 2.82659646902008

Epoch: 6| Step: 4
Training loss: 2.9374837672008263
Validation loss: 2.820724259540992

Epoch: 6| Step: 5
Training loss: 3.8527981089634866
Validation loss: 2.8215951283121004

Epoch: 6| Step: 6
Training loss: 3.3702663144345735
Validation loss: 2.816426513056472

Epoch: 6| Step: 7
Training loss: 3.293216067039784
Validation loss: 2.82043583838596

Epoch: 6| Step: 8
Training loss: 2.2684930997478294
Validation loss: 2.8126510415486767

Epoch: 6| Step: 9
Training loss: 2.898672747254976
Validation loss: 2.808686288386241

Epoch: 6| Step: 10
Training loss: 3.9950003372593286
Validation loss: 2.814576995226258

Epoch: 6| Step: 11
Training loss: 3.1485295814698366
Validation loss: 2.812316479272735

Epoch: 6| Step: 12
Training loss: 3.3615400567812257
Validation loss: 2.8142434480628613

Epoch: 6| Step: 13
Training loss: 2.5789468091232726
Validation loss: 2.8149226775606166

Epoch: 190| Step: 0
Training loss: 3.1734059214370784
Validation loss: 2.812413674400427

Epoch: 6| Step: 1
Training loss: 2.988540857544758
Validation loss: 2.8140076947476858

Epoch: 6| Step: 2
Training loss: 3.1099227346162803
Validation loss: 2.8145143967746056

Epoch: 6| Step: 3
Training loss: 3.6742557680316126
Validation loss: 2.811542963430037

Epoch: 6| Step: 4
Training loss: 2.6542695684761695
Validation loss: 2.8131113133170427

Epoch: 6| Step: 5
Training loss: 3.067032243527432
Validation loss: 2.815396950563116

Epoch: 6| Step: 6
Training loss: 3.3067591601428243
Validation loss: 2.8147678725142278

Epoch: 6| Step: 7
Training loss: 3.448198489439203
Validation loss: 2.8147339602433883

Epoch: 6| Step: 8
Training loss: 2.78522370458725
Validation loss: 2.814844838027375

Epoch: 6| Step: 9
Training loss: 3.926776755969601
Validation loss: 2.810710862035235

Epoch: 6| Step: 10
Training loss: 2.935236119353089
Validation loss: 2.8082769046534386

Epoch: 6| Step: 11
Training loss: 2.6040597105314585
Validation loss: 2.8076906738936507

Epoch: 6| Step: 12
Training loss: 3.1186480243653545
Validation loss: 2.811477061276932

Epoch: 6| Step: 13
Training loss: 2.232613676280482
Validation loss: 2.8158959016842293

Epoch: 191| Step: 0
Training loss: 3.2721061092976385
Validation loss: 2.808330020505185

Epoch: 6| Step: 1
Training loss: 3.0114790329979924
Validation loss: 2.8073957889930172

Epoch: 6| Step: 2
Training loss: 3.3136266555767606
Validation loss: 2.8107645438971476

Epoch: 6| Step: 3
Training loss: 3.518177784116985
Validation loss: 2.8109073190153504

Epoch: 6| Step: 4
Training loss: 2.9220863306659415
Validation loss: 2.8064732486502373

Epoch: 6| Step: 5
Training loss: 3.538709340779905
Validation loss: 2.809143079318198

Epoch: 6| Step: 6
Training loss: 3.4265464354424213
Validation loss: 2.8065569371594123

Epoch: 6| Step: 7
Training loss: 2.755270156214818
Validation loss: 2.8089685708673167

Epoch: 6| Step: 8
Training loss: 2.8333812784364447
Validation loss: 2.808568787973359

Epoch: 6| Step: 9
Training loss: 3.2070789775015096
Validation loss: 2.8104559102705733

Epoch: 6| Step: 10
Training loss: 3.0168084703138875
Validation loss: 2.8099486141639547

Epoch: 6| Step: 11
Training loss: 3.2521003391978756
Validation loss: 2.812294708015217

Epoch: 6| Step: 12
Training loss: 2.3581037317485163
Validation loss: 2.810081769486076

Epoch: 6| Step: 13
Training loss: 2.8632402820440563
Validation loss: 2.811944326474501

Epoch: 192| Step: 0
Training loss: 3.345870014399734
Validation loss: 2.810556295670527

Epoch: 6| Step: 1
Training loss: 3.1442240120674487
Validation loss: 2.812145152432022

Epoch: 6| Step: 2
Training loss: 3.4619274230613133
Validation loss: 2.817147587626708

Epoch: 6| Step: 3
Training loss: 2.395299890812223
Validation loss: 2.8151390555647327

Epoch: 6| Step: 4
Training loss: 3.2246405763462462
Validation loss: 2.8246828047252635

Epoch: 6| Step: 5
Training loss: 3.7027158873348327
Validation loss: 2.833168796512709

Epoch: 6| Step: 6
Training loss: 3.051722968551082
Validation loss: 2.8182311418125976

Epoch: 6| Step: 7
Training loss: 3.387015676186761
Validation loss: 2.806362767263594

Epoch: 6| Step: 8
Training loss: 3.015210375175733
Validation loss: 2.804009346805539

Epoch: 6| Step: 9
Training loss: 2.6011367770277665
Validation loss: 2.8047048688328977

Epoch: 6| Step: 10
Training loss: 2.811476881642807
Validation loss: 2.80499381259267

Epoch: 6| Step: 11
Training loss: 3.435966843379562
Validation loss: 2.804617735658071

Epoch: 6| Step: 12
Training loss: 2.8713692669143027
Validation loss: 2.8056174176372806

Epoch: 6| Step: 13
Training loss: 2.976267402018076
Validation loss: 2.806544608339997

Epoch: 193| Step: 0
Training loss: 3.081397471274448
Validation loss: 2.8065944110668655

Epoch: 6| Step: 1
Training loss: 3.200711713561163
Validation loss: 2.8094985323541573

Epoch: 6| Step: 2
Training loss: 3.600668972166025
Validation loss: 2.8054005958337327

Epoch: 6| Step: 3
Training loss: 2.099747906040365
Validation loss: 2.8046090016248715

Epoch: 6| Step: 4
Training loss: 2.59150221528789
Validation loss: 2.810358243324803

Epoch: 6| Step: 5
Training loss: 3.035375560167105
Validation loss: 2.803390077159044

Epoch: 6| Step: 6
Training loss: 3.255921471363452
Validation loss: 2.8011648515776746

Epoch: 6| Step: 7
Training loss: 2.779124272684196
Validation loss: 2.8033811810957117

Epoch: 6| Step: 8
Training loss: 3.178014066517394
Validation loss: 2.8049538980267563

Epoch: 6| Step: 9
Training loss: 3.751262960745245
Validation loss: 2.8072673052209933

Epoch: 6| Step: 10
Training loss: 3.240320610384265
Validation loss: 2.8068701771469056

Epoch: 6| Step: 11
Training loss: 2.80639978701483
Validation loss: 2.8128177969167565

Epoch: 6| Step: 12
Training loss: 2.961387096885116
Validation loss: 2.8194399838914324

Epoch: 6| Step: 13
Training loss: 4.013972673491333
Validation loss: 2.824087245264989

Epoch: 194| Step: 0
Training loss: 2.706753715170825
Validation loss: 2.8371417182373357

Epoch: 6| Step: 1
Training loss: 2.5445383973060793
Validation loss: 2.8319116375776385

Epoch: 6| Step: 2
Training loss: 2.8858155526841576
Validation loss: 2.833588928538648

Epoch: 6| Step: 3
Training loss: 3.1436282549542462
Validation loss: 2.8279656035736065

Epoch: 6| Step: 4
Training loss: 3.530855950169127
Validation loss: 2.823384981768852

Epoch: 6| Step: 5
Training loss: 3.6494121025800865
Validation loss: 2.810297482095583

Epoch: 6| Step: 6
Training loss: 3.4677210475924984
Validation loss: 2.8058102969031493

Epoch: 6| Step: 7
Training loss: 3.4726602320439066
Validation loss: 2.8112448586317638

Epoch: 6| Step: 8
Training loss: 3.4655055088257556
Validation loss: 2.804030325722044

Epoch: 6| Step: 9
Training loss: 2.5824579991399235
Validation loss: 2.803959285133583

Epoch: 6| Step: 10
Training loss: 2.5470272088935837
Validation loss: 2.8006582525029033

Epoch: 6| Step: 11
Training loss: 2.976824571181159
Validation loss: 2.7990945302354864

Epoch: 6| Step: 12
Training loss: 3.255607462510057
Validation loss: 2.8010257332719846

Epoch: 6| Step: 13
Training loss: 2.9416408166659136
Validation loss: 2.8002009801618706

Epoch: 195| Step: 0
Training loss: 3.488652772331112
Validation loss: 2.801684107353719

Epoch: 6| Step: 1
Training loss: 3.278179948635335
Validation loss: 2.797294056880435

Epoch: 6| Step: 2
Training loss: 2.7570372618439167
Validation loss: 2.79823806865655

Epoch: 6| Step: 3
Training loss: 3.420201837484282
Validation loss: 2.796219718332333

Epoch: 6| Step: 4
Training loss: 3.435162529799738
Validation loss: 2.7988775209564634

Epoch: 6| Step: 5
Training loss: 2.1341177610816287
Validation loss: 2.797945445729291

Epoch: 6| Step: 6
Training loss: 3.4726156054286235
Validation loss: 2.7983125535044566

Epoch: 6| Step: 7
Training loss: 3.2688886040500793
Validation loss: 2.7980223260714285

Epoch: 6| Step: 8
Training loss: 2.8662982777897947
Validation loss: 2.8009880741153976

Epoch: 6| Step: 9
Training loss: 3.389584429990235
Validation loss: 2.7984746795927467

Epoch: 6| Step: 10
Training loss: 2.8514885879761818
Validation loss: 2.797796282237971

Epoch: 6| Step: 11
Training loss: 3.270317830729799
Validation loss: 2.7993617224281517

Epoch: 6| Step: 12
Training loss: 2.7575804529013532
Validation loss: 2.798450550726299

Epoch: 6| Step: 13
Training loss: 2.4973935845570123
Validation loss: 2.798788636368981

Epoch: 196| Step: 0
Training loss: 3.0140522230417073
Validation loss: 2.8104823423754484

Epoch: 6| Step: 1
Training loss: 2.9736738631197706
Validation loss: 2.8137384638965277

Epoch: 6| Step: 2
Training loss: 3.2750895480660622
Validation loss: 2.8354301173899903

Epoch: 6| Step: 3
Training loss: 3.2115783794352364
Validation loss: 2.843475925382511

Epoch: 6| Step: 4
Training loss: 3.2013997711930817
Validation loss: 2.826518437611882

Epoch: 6| Step: 5
Training loss: 3.8984648984508152
Validation loss: 2.8141854107139013

Epoch: 6| Step: 6
Training loss: 2.752740708028936
Validation loss: 2.8065577875783148

Epoch: 6| Step: 7
Training loss: 2.7579995759184954
Validation loss: 2.7980584657359504

Epoch: 6| Step: 8
Training loss: 3.9198577677944857
Validation loss: 2.797011340423828

Epoch: 6| Step: 9
Training loss: 2.65361987779157
Validation loss: 2.7938342347629974

Epoch: 6| Step: 10
Training loss: 2.95996754241881
Validation loss: 2.7981909885046776

Epoch: 6| Step: 11
Training loss: 2.430353790870294
Validation loss: 2.797517140090833

Epoch: 6| Step: 12
Training loss: 3.294978314850784
Validation loss: 2.797172506273568

Epoch: 6| Step: 13
Training loss: 2.757010281083921
Validation loss: 2.799742100304515

Epoch: 197| Step: 0
Training loss: 3.513418089865528
Validation loss: 2.7993260794714216

Epoch: 6| Step: 1
Training loss: 3.0398475397929987
Validation loss: 2.8011350926073466

Epoch: 6| Step: 2
Training loss: 3.053151400558355
Validation loss: 2.7994555174660243

Epoch: 6| Step: 3
Training loss: 3.1702849814178093
Validation loss: 2.800632524059151

Epoch: 6| Step: 4
Training loss: 2.637248210730268
Validation loss: 2.804540866091382

Epoch: 6| Step: 5
Training loss: 2.9722064325818387
Validation loss: 2.800895644760356

Epoch: 6| Step: 6
Training loss: 2.8199422070147677
Validation loss: 2.79726169149769

Epoch: 6| Step: 7
Training loss: 3.4281221958312367
Validation loss: 2.7965520600255642

Epoch: 6| Step: 8
Training loss: 2.883188445432841
Validation loss: 2.7942356496217338

Epoch: 6| Step: 9
Training loss: 3.5317533691286487
Validation loss: 2.7925396379136784

Epoch: 6| Step: 10
Training loss: 2.8416317606671737
Validation loss: 2.794717665791634

Epoch: 6| Step: 11
Training loss: 3.1184599533213104
Validation loss: 2.7954489887494187

Epoch: 6| Step: 12
Training loss: 3.2968117947418123
Validation loss: 2.7933753038617417

Epoch: 6| Step: 13
Training loss: 3.2332662994934305
Validation loss: 2.7922954775582607

Epoch: 198| Step: 0
Training loss: 3.129054681540935
Validation loss: 2.7934727523875864

Epoch: 6| Step: 1
Training loss: 3.1884291547490147
Validation loss: 2.794052095430663

Epoch: 6| Step: 2
Training loss: 3.877772293220535
Validation loss: 2.792697768113677

Epoch: 6| Step: 3
Training loss: 2.797983131177877
Validation loss: 2.795024667424421

Epoch: 6| Step: 4
Training loss: 3.0967365068403625
Validation loss: 2.7945141342851576

Epoch: 6| Step: 5
Training loss: 2.363759596153078
Validation loss: 2.792713614239099

Epoch: 6| Step: 6
Training loss: 2.9751521095690623
Validation loss: 2.795981467864756

Epoch: 6| Step: 7
Training loss: 3.044581719093492
Validation loss: 2.7981053007420273

Epoch: 6| Step: 8
Training loss: 3.2872701006086293
Validation loss: 2.7975571406013273

Epoch: 6| Step: 9
Training loss: 3.4852259670211816
Validation loss: 2.796767411872696

Epoch: 6| Step: 10
Training loss: 3.2905548407020917
Validation loss: 2.7972845713830132

Epoch: 6| Step: 11
Training loss: 3.223739460472696
Validation loss: 2.7938821324975054

Epoch: 6| Step: 12
Training loss: 2.243037152551114
Validation loss: 2.79385062867379

Epoch: 6| Step: 13
Training loss: 3.20797317927462
Validation loss: 2.7889140655947156

Epoch: 199| Step: 0
Training loss: 2.9184377107049326
Validation loss: 2.793337326805641

Epoch: 6| Step: 1
Training loss: 2.4675933446108327
Validation loss: 2.7887319849999166

Epoch: 6| Step: 2
Training loss: 3.277747182829002
Validation loss: 2.7907407808096703

Epoch: 6| Step: 3
Training loss: 2.80388134604911
Validation loss: 2.793101466529653

Epoch: 6| Step: 4
Training loss: 3.027181037714001
Validation loss: 2.7924211541954453

Epoch: 6| Step: 5
Training loss: 2.8723382652972
Validation loss: 2.7939904336445434

Epoch: 6| Step: 6
Training loss: 4.0642787853797735
Validation loss: 2.793993357891646

Epoch: 6| Step: 7
Training loss: 2.651680819962967
Validation loss: 2.7931494383245967

Epoch: 6| Step: 8
Training loss: 3.606442007047294
Validation loss: 2.793367751626538

Epoch: 6| Step: 9
Training loss: 3.0610198511765447
Validation loss: 2.7960921999108423

Epoch: 6| Step: 10
Training loss: 2.700443591659681
Validation loss: 2.7968989325570894

Epoch: 6| Step: 11
Training loss: 3.9950664613086775
Validation loss: 2.791720829822265

Epoch: 6| Step: 12
Training loss: 3.079342364166731
Validation loss: 2.7908699748943313

Epoch: 6| Step: 13
Training loss: 1.77711985089555
Validation loss: 2.789351986960556

Epoch: 200| Step: 0
Training loss: 2.759173092740048
Validation loss: 2.78663090947832

Epoch: 6| Step: 1
Training loss: 3.680748658942582
Validation loss: 2.7888271864109044

Epoch: 6| Step: 2
Training loss: 3.2740491054443335
Validation loss: 2.7920902462249266

Epoch: 6| Step: 3
Training loss: 2.923908851747543
Validation loss: 2.791021938990376

Epoch: 6| Step: 4
Training loss: 3.0714635656904297
Validation loss: 2.785347545645817

Epoch: 6| Step: 5
Training loss: 2.912816167214611
Validation loss: 2.792379638720199

Epoch: 6| Step: 6
Training loss: 2.6967690775238826
Validation loss: 2.7874444317099303

Epoch: 6| Step: 7
Training loss: 3.491802834440532
Validation loss: 2.7882099300253436

Epoch: 6| Step: 8
Training loss: 3.2468845400335065
Validation loss: 2.789416981779118

Epoch: 6| Step: 9
Training loss: 3.2872727116096048
Validation loss: 2.7934317343539057

Epoch: 6| Step: 10
Training loss: 3.031189436160034
Validation loss: 2.794450405691873

Epoch: 6| Step: 11
Training loss: 2.31770573876625
Validation loss: 2.790978927518587

Epoch: 6| Step: 12
Training loss: 2.943400199824707
Validation loss: 2.797683278213677

Epoch: 6| Step: 13
Training loss: 3.8857090544264703
Validation loss: 2.7875962873365148

Epoch: 201| Step: 0
Training loss: 3.054360296574237
Validation loss: 2.7894427962075268

Epoch: 6| Step: 1
Training loss: 2.661351499758597
Validation loss: 2.7879020795662246

Epoch: 6| Step: 2
Training loss: 3.2451896280565635
Validation loss: 2.7939755866433367

Epoch: 6| Step: 3
Training loss: 3.4879323821206873
Validation loss: 2.7889089013816615

Epoch: 6| Step: 4
Training loss: 3.1722823759908985
Validation loss: 2.7884957756407602

Epoch: 6| Step: 5
Training loss: 3.025549808695514
Validation loss: 2.787863917603751

Epoch: 6| Step: 6
Training loss: 2.82215613974486
Validation loss: 2.788295589970967

Epoch: 6| Step: 7
Training loss: 3.1807955374174073
Validation loss: 2.788167059988097

Epoch: 6| Step: 8
Training loss: 2.6820184562326848
Validation loss: 2.788707691857773

Epoch: 6| Step: 9
Training loss: 3.3216598828660056
Validation loss: 2.786891317476143

Epoch: 6| Step: 10
Training loss: 3.190264232538284
Validation loss: 2.7847472257850967

Epoch: 6| Step: 11
Training loss: 3.1903664658853077
Validation loss: 2.7965216826825694

Epoch: 6| Step: 12
Training loss: 3.4859437703923044
Validation loss: 2.791667084807902

Epoch: 6| Step: 13
Training loss: 2.3269994690439155
Validation loss: 2.7875228055387757

Epoch: 202| Step: 0
Training loss: 2.5694578657286606
Validation loss: 2.791372319184981

Epoch: 6| Step: 1
Training loss: 3.544967609036942
Validation loss: 2.7931903769823534

Epoch: 6| Step: 2
Training loss: 3.286667774295685
Validation loss: 2.792657350080749

Epoch: 6| Step: 3
Training loss: 3.6444210841301183
Validation loss: 2.7995014733324624

Epoch: 6| Step: 4
Training loss: 3.605003583168228
Validation loss: 2.790246952992099

Epoch: 6| Step: 5
Training loss: 1.7696657782273546
Validation loss: 2.783791435740752

Epoch: 6| Step: 6
Training loss: 3.0136541537878196
Validation loss: 2.783389822529304

Epoch: 6| Step: 7
Training loss: 3.3706597571523482
Validation loss: 2.7812879033701536

Epoch: 6| Step: 8
Training loss: 3.2554820848433996
Validation loss: 2.7812934762400947

Epoch: 6| Step: 9
Training loss: 1.9018283278912247
Validation loss: 2.780212417119001

Epoch: 6| Step: 10
Training loss: 3.0323234309205
Validation loss: 2.7847820638647707

Epoch: 6| Step: 11
Training loss: 3.1526005863656943
Validation loss: 2.7827629397841744

Epoch: 6| Step: 12
Training loss: 3.292398170281037
Validation loss: 2.784903990489696

Epoch: 6| Step: 13
Training loss: 3.265004806398181
Validation loss: 2.78444025476902

Epoch: 203| Step: 0
Training loss: 3.3710846972647857
Validation loss: 2.7825114721669384

Epoch: 6| Step: 1
Training loss: 3.52292103164616
Validation loss: 2.77943203189238

Epoch: 6| Step: 2
Training loss: 3.4300649517793818
Validation loss: 2.783383963725369

Epoch: 6| Step: 3
Training loss: 2.6619224566680604
Validation loss: 2.781372322027907

Epoch: 6| Step: 4
Training loss: 3.539606385196182
Validation loss: 2.783749961017375

Epoch: 6| Step: 5
Training loss: 3.8193155871916935
Validation loss: 2.7813182848698057

Epoch: 6| Step: 6
Training loss: 2.7388760387367674
Validation loss: 2.787115158825972

Epoch: 6| Step: 7
Training loss: 3.014017734224814
Validation loss: 2.7850274425823325

Epoch: 6| Step: 8
Training loss: 3.038133650882963
Validation loss: 2.785740988974253

Epoch: 6| Step: 9
Training loss: 2.8719036179736563
Validation loss: 2.7872727395501564

Epoch: 6| Step: 10
Training loss: 2.0416121053865948
Validation loss: 2.793125216645374

Epoch: 6| Step: 11
Training loss: 3.3873945043824336
Validation loss: 2.787921335066593

Epoch: 6| Step: 12
Training loss: 2.633158765712622
Validation loss: 2.7824013439949424

Epoch: 6| Step: 13
Training loss: 2.452832830244948
Validation loss: 2.7826384797477655

Epoch: 204| Step: 0
Training loss: 3.330980392338794
Validation loss: 2.792031437112814

Epoch: 6| Step: 1
Training loss: 3.9019898644593827
Validation loss: 2.7901120893629803

Epoch: 6| Step: 2
Training loss: 2.5959088636485568
Validation loss: 2.7873737869666835

Epoch: 6| Step: 3
Training loss: 3.414580491355534
Validation loss: 2.789204443891779

Epoch: 6| Step: 4
Training loss: 2.9792471565808563
Validation loss: 2.7860683796607435

Epoch: 6| Step: 5
Training loss: 2.5042631040803216
Validation loss: 2.7838721492550325

Epoch: 6| Step: 6
Training loss: 2.6277601172472282
Validation loss: 2.779413429646754

Epoch: 6| Step: 7
Training loss: 2.7301108107941494
Validation loss: 2.779142424861186

Epoch: 6| Step: 8
Training loss: 2.7859948649252995
Validation loss: 2.7789353208345036

Epoch: 6| Step: 9
Training loss: 2.9396539461092996
Validation loss: 2.778871801412259

Epoch: 6| Step: 10
Training loss: 3.9512047004938986
Validation loss: 2.7776462629078726

Epoch: 6| Step: 11
Training loss: 3.324027964835847
Validation loss: 2.7797294083369355

Epoch: 6| Step: 12
Training loss: 2.8574327219654854
Validation loss: 2.777154280989715

Epoch: 6| Step: 13
Training loss: 2.9199463706121347
Validation loss: 2.782979422219744

Epoch: 205| Step: 0
Training loss: 3.047076722338781
Validation loss: 2.7803651721000886

Epoch: 6| Step: 1
Training loss: 3.022206137028443
Validation loss: 2.7847716648683596

Epoch: 6| Step: 2
Training loss: 2.893008017936643
Validation loss: 2.782784936557471

Epoch: 6| Step: 3
Training loss: 2.796121335912747
Validation loss: 2.7863314136898896

Epoch: 6| Step: 4
Training loss: 3.03288665319211
Validation loss: 2.787533665148462

Epoch: 6| Step: 5
Training loss: 3.1853958365385315
Validation loss: 2.7815420899089016

Epoch: 6| Step: 6
Training loss: 2.8516626627849546
Validation loss: 2.791149584347609

Epoch: 6| Step: 7
Training loss: 3.4414641670956447
Validation loss: 2.77786507476169

Epoch: 6| Step: 8
Training loss: 3.317631615311156
Validation loss: 2.780786396141724

Epoch: 6| Step: 9
Training loss: 3.0567217441312713
Validation loss: 2.775014507710674

Epoch: 6| Step: 10
Training loss: 3.239313308567044
Validation loss: 2.7776589267353162

Epoch: 6| Step: 11
Training loss: 3.1649436948085814
Validation loss: 2.7757477629649743

Epoch: 6| Step: 12
Training loss: 3.0256375925566004
Validation loss: 2.7763903457620898

Epoch: 6| Step: 13
Training loss: 3.220679732423386
Validation loss: 2.777067299773094

Epoch: 206| Step: 0
Training loss: 3.0356209299815404
Validation loss: 2.7762017258846368

Epoch: 6| Step: 1
Training loss: 2.8539054546882445
Validation loss: 2.776071404046147

Epoch: 6| Step: 2
Training loss: 3.6963789773987816
Validation loss: 2.774790433024672

Epoch: 6| Step: 3
Training loss: 2.949897900123797
Validation loss: 2.779785771847911

Epoch: 6| Step: 4
Training loss: 3.5532816695512537
Validation loss: 2.7821138908455696

Epoch: 6| Step: 5
Training loss: 2.131672425231234
Validation loss: 2.792073801577746

Epoch: 6| Step: 6
Training loss: 2.497051312042739
Validation loss: 2.791254877958789

Epoch: 6| Step: 7
Training loss: 3.148813381427926
Validation loss: 2.788934428201345

Epoch: 6| Step: 8
Training loss: 3.0642053954998754
Validation loss: 2.7965031116109564

Epoch: 6| Step: 9
Training loss: 3.133955673206163
Validation loss: 2.797813367648241

Epoch: 6| Step: 10
Training loss: 3.276558419344666
Validation loss: 2.792295705250085

Epoch: 6| Step: 11
Training loss: 3.0703746216679835
Validation loss: 2.7876409162368527

Epoch: 6| Step: 12
Training loss: 3.289946158759906
Validation loss: 2.775486466917569

Epoch: 6| Step: 13
Training loss: 3.449377451579748
Validation loss: 2.7782190492968937

Epoch: 207| Step: 0
Training loss: 3.928126121648296
Validation loss: 2.775200036061713

Epoch: 6| Step: 1
Training loss: 2.1582027935873613
Validation loss: 2.777067141914996

Epoch: 6| Step: 2
Training loss: 2.8372592840725983
Validation loss: 2.7743668608199363

Epoch: 6| Step: 3
Training loss: 3.8398911870003465
Validation loss: 2.777525284034958

Epoch: 6| Step: 4
Training loss: 2.6692737610343444
Validation loss: 2.7746479078968527

Epoch: 6| Step: 5
Training loss: 2.789217648077752
Validation loss: 2.777283653863414

Epoch: 6| Step: 6
Training loss: 3.292396287493929
Validation loss: 2.7776233144767035

Epoch: 6| Step: 7
Training loss: 3.123432987242316
Validation loss: 2.783169857935261

Epoch: 6| Step: 8
Training loss: 3.0296711693530667
Validation loss: 2.7808105575091635

Epoch: 6| Step: 9
Training loss: 3.4063817269988603
Validation loss: 2.7767972376015386

Epoch: 6| Step: 10
Training loss: 2.9487231513948164
Validation loss: 2.7762357154560666

Epoch: 6| Step: 11
Training loss: 2.922136590844822
Validation loss: 2.7871074194607046

Epoch: 6| Step: 12
Training loss: 3.1832164330180306
Validation loss: 2.783931500917907

Epoch: 6| Step: 13
Training loss: 2.4144659106513617
Validation loss: 2.78823801655327

Epoch: 208| Step: 0
Training loss: 3.16041893922292
Validation loss: 2.797090886988431

Epoch: 6| Step: 1
Training loss: 3.3216929000938933
Validation loss: 2.7846281333932716

Epoch: 6| Step: 2
Training loss: 3.6458644901942496
Validation loss: 2.7757864835589756

Epoch: 6| Step: 3
Training loss: 2.7753112480951954
Validation loss: 2.7778232974421164

Epoch: 6| Step: 4
Training loss: 2.8105453480603044
Validation loss: 2.7707167011898397

Epoch: 6| Step: 5
Training loss: 2.9860339921164987
Validation loss: 2.7727473092142647

Epoch: 6| Step: 6
Training loss: 3.3714862475645795
Validation loss: 2.7741602661700484

Epoch: 6| Step: 7
Training loss: 3.2644651260511424
Validation loss: 2.7706896167696127

Epoch: 6| Step: 8
Training loss: 3.1095277374939334
Validation loss: 2.774327307703319

Epoch: 6| Step: 9
Training loss: 3.37515286699882
Validation loss: 2.776730400935331

Epoch: 6| Step: 10
Training loss: 2.1100288790493753
Validation loss: 2.77520642298544

Epoch: 6| Step: 11
Training loss: 2.9699438003720147
Validation loss: 2.773216670209679

Epoch: 6| Step: 12
Training loss: 3.3001444004717193
Validation loss: 2.7730496616186957

Epoch: 6| Step: 13
Training loss: 2.4944377056088385
Validation loss: 2.7715277306333403

Epoch: 209| Step: 0
Training loss: 3.351946330822126
Validation loss: 2.7692968586759235

Epoch: 6| Step: 1
Training loss: 2.5513719047193817
Validation loss: 2.774287676400772

Epoch: 6| Step: 2
Training loss: 3.182265677504649
Validation loss: 2.7833754946417595

Epoch: 6| Step: 3
Training loss: 3.4061139280805706
Validation loss: 2.78369464937358

Epoch: 6| Step: 4
Training loss: 3.2958719616992163
Validation loss: 2.7766909599647325

Epoch: 6| Step: 5
Training loss: 3.2534512021907784
Validation loss: 2.77764651210553

Epoch: 6| Step: 6
Training loss: 2.9944307767720866
Validation loss: 2.7744095144227248

Epoch: 6| Step: 7
Training loss: 3.3982660359941805
Validation loss: 2.768350047395998

Epoch: 6| Step: 8
Training loss: 3.2670393075998247
Validation loss: 2.7743361269032984

Epoch: 6| Step: 9
Training loss: 3.3326502735914754
Validation loss: 2.7731046854487

Epoch: 6| Step: 10
Training loss: 2.129237046045929
Validation loss: 2.7706960316707416

Epoch: 6| Step: 11
Training loss: 3.0417738246766937
Validation loss: 2.7707533339459123

Epoch: 6| Step: 12
Training loss: 3.02923170716896
Validation loss: 2.771251271922916

Epoch: 6| Step: 13
Training loss: 2.285991183606866
Validation loss: 2.7704012047540814

Epoch: 210| Step: 0
Training loss: 3.0282217413819
Validation loss: 2.7709195548209498

Epoch: 6| Step: 1
Training loss: 2.723787748540014
Validation loss: 2.7681780850069555

Epoch: 6| Step: 2
Training loss: 3.517672743469945
Validation loss: 2.7684968702330557

Epoch: 6| Step: 3
Training loss: 3.148588039689657
Validation loss: 2.7668701811506486

Epoch: 6| Step: 4
Training loss: 3.586860089268578
Validation loss: 2.770275474000941

Epoch: 6| Step: 5
Training loss: 2.6201007172830733
Validation loss: 2.7683609590645224

Epoch: 6| Step: 6
Training loss: 2.5229786553132025
Validation loss: 2.765182132439318

Epoch: 6| Step: 7
Training loss: 3.3034371249319863
Validation loss: 2.7676586277464232

Epoch: 6| Step: 8
Training loss: 3.389419833700457
Validation loss: 2.7700408911412415

Epoch: 6| Step: 9
Training loss: 2.9437050720803537
Validation loss: 2.769787567837469

Epoch: 6| Step: 10
Training loss: 3.4002869933680695
Validation loss: 2.771922632406008

Epoch: 6| Step: 11
Training loss: 2.6526782986383584
Validation loss: 2.767786216857287

Epoch: 6| Step: 12
Training loss: 2.9927262500970615
Validation loss: 2.7693447068321766

Epoch: 6| Step: 13
Training loss: 3.2410237993015665
Validation loss: 2.769805320271044

Epoch: 211| Step: 0
Training loss: 3.2959677365399833
Validation loss: 2.7677140847992576

Epoch: 6| Step: 1
Training loss: 3.1161997671474033
Validation loss: 2.7705702624796427

Epoch: 6| Step: 2
Training loss: 3.3136401823273705
Validation loss: 2.7676921497970857

Epoch: 6| Step: 3
Training loss: 3.5931836552725187
Validation loss: 2.7723047841515744

Epoch: 6| Step: 4
Training loss: 3.1300031665627546
Validation loss: 2.7709333651707797

Epoch: 6| Step: 5
Training loss: 3.164499210313568
Validation loss: 2.7695970579962066

Epoch: 6| Step: 6
Training loss: 3.0401960676108706
Validation loss: 2.7675083515269363

Epoch: 6| Step: 7
Training loss: 2.354966851910275
Validation loss: 2.7767876146905524

Epoch: 6| Step: 8
Training loss: 2.865865376581645
Validation loss: 2.775359026738734

Epoch: 6| Step: 9
Training loss: 2.720708996286513
Validation loss: 2.7688831149662216

Epoch: 6| Step: 10
Training loss: 2.8052239290227208
Validation loss: 2.7674656425091064

Epoch: 6| Step: 11
Training loss: 3.3581719661845453
Validation loss: 2.769792611280247

Epoch: 6| Step: 12
Training loss: 3.1675072273828295
Validation loss: 2.7675082579670707

Epoch: 6| Step: 13
Training loss: 3.0158267571352195
Validation loss: 2.76750326686789

Epoch: 212| Step: 0
Training loss: 2.928060583425897
Validation loss: 2.7668358578587964

Epoch: 6| Step: 1
Training loss: 3.083691206774802
Validation loss: 2.7661555880692505

Epoch: 6| Step: 2
Training loss: 3.1271742314278006
Validation loss: 2.7624225311783324

Epoch: 6| Step: 3
Training loss: 3.874363262406729
Validation loss: 2.765272208496419

Epoch: 6| Step: 4
Training loss: 2.850747355131297
Validation loss: 2.7670448847768627

Epoch: 6| Step: 5
Training loss: 3.307681772048085
Validation loss: 2.767404022901744

Epoch: 6| Step: 6
Training loss: 2.629570388226134
Validation loss: 2.7655259213069963

Epoch: 6| Step: 7
Training loss: 2.8086767701677218
Validation loss: 2.761074614788284

Epoch: 6| Step: 8
Training loss: 3.2830371167969017
Validation loss: 2.7626635783143354

Epoch: 6| Step: 9
Training loss: 3.040140230558446
Validation loss: 2.766122915808351

Epoch: 6| Step: 10
Training loss: 2.836980454526473
Validation loss: 2.7647368980338585

Epoch: 6| Step: 11
Training loss: 3.489701788111169
Validation loss: 2.761242691189537

Epoch: 6| Step: 12
Training loss: 2.5372497660709805
Validation loss: 2.7633459091652446

Epoch: 6| Step: 13
Training loss: 3.1100427878524357
Validation loss: 2.7684076177000168

Epoch: 213| Step: 0
Training loss: 2.6692939471973087
Validation loss: 2.7608990059586267

Epoch: 6| Step: 1
Training loss: 2.9566355028484828
Validation loss: 2.770036110989674

Epoch: 6| Step: 2
Training loss: 3.8515225112417624
Validation loss: 2.7705969131744306

Epoch: 6| Step: 3
Training loss: 2.8247563653724472
Validation loss: 2.7661914350816397

Epoch: 6| Step: 4
Training loss: 3.1199703176015703
Validation loss: 2.764989708678415

Epoch: 6| Step: 5
Training loss: 3.5464842997060515
Validation loss: 2.7643829554495167

Epoch: 6| Step: 6
Training loss: 3.151728044057147
Validation loss: 2.7656259983423155

Epoch: 6| Step: 7
Training loss: 3.179751533782059
Validation loss: 2.7645178974519427

Epoch: 6| Step: 8
Training loss: 3.01040466376599
Validation loss: 2.7614420891053677

Epoch: 6| Step: 9
Training loss: 3.123904226830298
Validation loss: 2.7661878744048423

Epoch: 6| Step: 10
Training loss: 2.7221638960872
Validation loss: 2.7632770400793514

Epoch: 6| Step: 11
Training loss: 2.6247280524938845
Validation loss: 2.76268144519381

Epoch: 6| Step: 12
Training loss: 3.0262012713171416
Validation loss: 2.7698146731106443

Epoch: 6| Step: 13
Training loss: 3.090694112747455
Validation loss: 2.7645235542038455

Epoch: 214| Step: 0
Training loss: 2.670914683737153
Validation loss: 2.7625588597824047

Epoch: 6| Step: 1
Training loss: 2.5810463739579506
Validation loss: 2.7636205956240367

Epoch: 6| Step: 2
Training loss: 2.896404694832889
Validation loss: 2.765567799110991

Epoch: 6| Step: 3
Training loss: 3.255347327761699
Validation loss: 2.76731160851967

Epoch: 6| Step: 4
Training loss: 2.9892901942565757
Validation loss: 2.7728274224245903

Epoch: 6| Step: 5
Training loss: 4.201934532414477
Validation loss: 2.7695542617791333

Epoch: 6| Step: 6
Training loss: 3.265808246344554
Validation loss: 2.769939144782924

Epoch: 6| Step: 7
Training loss: 3.1083465869065336
Validation loss: 2.7696073380981354

Epoch: 6| Step: 8
Training loss: 2.781229597724062
Validation loss: 2.767819146427186

Epoch: 6| Step: 9
Training loss: 3.286968225904082
Validation loss: 2.7660801075466828

Epoch: 6| Step: 10
Training loss: 3.292619173040933
Validation loss: 2.7635836920661245

Epoch: 6| Step: 11
Training loss: 2.8505491363460385
Validation loss: 2.7624717113312456

Epoch: 6| Step: 12
Training loss: 2.5983124097854775
Validation loss: 2.7615019293454752

Epoch: 6| Step: 13
Training loss: 3.0985629473292957
Validation loss: 2.7605021520199253

Epoch: 215| Step: 0
Training loss: 3.2448272621484247
Validation loss: 2.7656599742100174

Epoch: 6| Step: 1
Training loss: 4.008188925274526
Validation loss: 2.7723161305974653

Epoch: 6| Step: 2
Training loss: 3.2136217763716104
Validation loss: 2.7922254559327584

Epoch: 6| Step: 3
Training loss: 3.0786253236902654
Validation loss: 2.803225876777378

Epoch: 6| Step: 4
Training loss: 3.6498307175768816
Validation loss: 2.8222802059993266

Epoch: 6| Step: 5
Training loss: 2.8093284526698667
Validation loss: 2.786030418944468

Epoch: 6| Step: 6
Training loss: 2.934080853004111
Validation loss: 2.768676640767343

Epoch: 6| Step: 7
Training loss: 2.652582126967536
Validation loss: 2.7646614705799797

Epoch: 6| Step: 8
Training loss: 3.426552558463548
Validation loss: 2.759302641594456

Epoch: 6| Step: 9
Training loss: 2.839331075575033
Validation loss: 2.7567517522933764

Epoch: 6| Step: 10
Training loss: 2.4465467366787452
Validation loss: 2.755987210833312

Epoch: 6| Step: 11
Training loss: 2.515346630166776
Validation loss: 2.7592032494669354

Epoch: 6| Step: 12
Training loss: 3.2984707843758234
Validation loss: 2.7600954939676066

Epoch: 6| Step: 13
Training loss: 2.491869771668226
Validation loss: 2.761796263774143

Epoch: 216| Step: 0
Training loss: 2.7298515178837808
Validation loss: 2.761460027016747

Epoch: 6| Step: 1
Training loss: 2.5013843518214287
Validation loss: 2.759324946169192

Epoch: 6| Step: 2
Training loss: 3.1956258680766596
Validation loss: 2.7583306115294435

Epoch: 6| Step: 3
Training loss: 3.4751404329094937
Validation loss: 2.7587845063196865

Epoch: 6| Step: 4
Training loss: 3.7106049398683485
Validation loss: 2.759259900333753

Epoch: 6| Step: 5
Training loss: 2.689030943114062
Validation loss: 2.763513319580098

Epoch: 6| Step: 6
Training loss: 3.536200505082538
Validation loss: 2.76168148962885

Epoch: 6| Step: 7
Training loss: 3.3661273606175315
Validation loss: 2.7625629559490203

Epoch: 6| Step: 8
Training loss: 3.1091383647491124
Validation loss: 2.757910430785987

Epoch: 6| Step: 9
Training loss: 3.013209665371428
Validation loss: 2.7597873814818215

Epoch: 6| Step: 10
Training loss: 3.1785337712244703
Validation loss: 2.7563781754612076

Epoch: 6| Step: 11
Training loss: 2.061630990725291
Validation loss: 2.7617622245936757

Epoch: 6| Step: 12
Training loss: 3.15820040729243
Validation loss: 2.7619116773293473

Epoch: 6| Step: 13
Training loss: 2.8558763455781677
Validation loss: 2.7619663308622586

Epoch: 217| Step: 0
Training loss: 2.7346449364527743
Validation loss: 2.758837177460692

Epoch: 6| Step: 1
Training loss: 3.0978814484561807
Validation loss: 2.753826885000505

Epoch: 6| Step: 2
Training loss: 3.336538077616347
Validation loss: 2.7587689160043243

Epoch: 6| Step: 3
Training loss: 3.637981191577075
Validation loss: 2.755057101020021

Epoch: 6| Step: 4
Training loss: 2.206329396145751
Validation loss: 2.764365615195392

Epoch: 6| Step: 5
Training loss: 2.8577070530646163
Validation loss: 2.758173903576237

Epoch: 6| Step: 6
Training loss: 2.5738740033165435
Validation loss: 2.760172154251845

Epoch: 6| Step: 7
Training loss: 2.6305704503329768
Validation loss: 2.7529784133160344

Epoch: 6| Step: 8
Training loss: 3.6163484658985285
Validation loss: 2.7595275288972716

Epoch: 6| Step: 9
Training loss: 3.3305580665876566
Validation loss: 2.757170059386915

Epoch: 6| Step: 10
Training loss: 3.0039654590739024
Validation loss: 2.7555333409175864

Epoch: 6| Step: 11
Training loss: 3.097314033991176
Validation loss: 2.755086378801716

Epoch: 6| Step: 12
Training loss: 3.3516148560887316
Validation loss: 2.7535202599501343

Epoch: 6| Step: 13
Training loss: 3.2461555924934142
Validation loss: 2.7498166758716382

Epoch: 218| Step: 0
Training loss: 2.7595168080510066
Validation loss: 2.75550582349417

Epoch: 6| Step: 1
Training loss: 2.956466479772857
Validation loss: 2.7566108538641787

Epoch: 6| Step: 2
Training loss: 2.9831355052405772
Validation loss: 2.755039779302648

Epoch: 6| Step: 3
Training loss: 2.69566869178917
Validation loss: 2.755567361216683

Epoch: 6| Step: 4
Training loss: 3.378528587095033
Validation loss: 2.757122582947292

Epoch: 6| Step: 5
Training loss: 3.3958385132046063
Validation loss: 2.7576886485968273

Epoch: 6| Step: 6
Training loss: 3.0063990058373498
Validation loss: 2.760745785844327

Epoch: 6| Step: 7
Training loss: 2.8314028128169495
Validation loss: 2.769982965143846

Epoch: 6| Step: 8
Training loss: 3.1265732429010993
Validation loss: 2.7860299827806165

Epoch: 6| Step: 9
Training loss: 3.0798067252713857
Validation loss: 2.788177785604551

Epoch: 6| Step: 10
Training loss: 3.455994945310499
Validation loss: 2.764961868131787

Epoch: 6| Step: 11
Training loss: 2.6561886051038974
Validation loss: 2.761226475984945

Epoch: 6| Step: 12
Training loss: 3.4666609788505647
Validation loss: 2.754755479137646

Epoch: 6| Step: 13
Training loss: 3.0113596423794937
Validation loss: 2.7538204242868787

Epoch: 219| Step: 0
Training loss: 3.3845613465296873
Validation loss: 2.749149555511793

Epoch: 6| Step: 1
Training loss: 3.020677040704736
Validation loss: 2.7473122610516816

Epoch: 6| Step: 2
Training loss: 2.787581448583882
Validation loss: 2.750451130188108

Epoch: 6| Step: 3
Training loss: 3.0523650958269486
Validation loss: 2.750084043245898

Epoch: 6| Step: 4
Training loss: 2.9532544950320077
Validation loss: 2.7483938473179457

Epoch: 6| Step: 5
Training loss: 2.860460085908589
Validation loss: 2.7486251851200034

Epoch: 6| Step: 6
Training loss: 3.0310105691320888
Validation loss: 2.750288754253594

Epoch: 6| Step: 7
Training loss: 3.5052426446574003
Validation loss: 2.749200734604275

Epoch: 6| Step: 8
Training loss: 3.413025024045136
Validation loss: 2.747385361256908

Epoch: 6| Step: 9
Training loss: 2.675780091668317
Validation loss: 2.752307920880643

Epoch: 6| Step: 10
Training loss: 3.1610388354408174
Validation loss: 2.75590045085217

Epoch: 6| Step: 11
Training loss: 2.6330850612926353
Validation loss: 2.75953615385289

Epoch: 6| Step: 12
Training loss: 3.114216930734724
Validation loss: 2.757038887227284

Epoch: 6| Step: 13
Training loss: 3.382065758867241
Validation loss: 2.7531422704076958

Epoch: 220| Step: 0
Training loss: 2.709161974002181
Validation loss: 2.748130188770724

Epoch: 6| Step: 1
Training loss: 3.204614209360459
Validation loss: 2.7499828897430527

Epoch: 6| Step: 2
Training loss: 2.2804626778407084
Validation loss: 2.7479018730886073

Epoch: 6| Step: 3
Training loss: 3.2701381908462896
Validation loss: 2.7492439763389105

Epoch: 6| Step: 4
Training loss: 3.0847729767248886
Validation loss: 2.7460781903274567

Epoch: 6| Step: 5
Training loss: 3.0039281559059843
Validation loss: 2.7456638478882396

Epoch: 6| Step: 6
Training loss: 2.5425011458342754
Validation loss: 2.7446514183394264

Epoch: 6| Step: 7
Training loss: 3.3158926234697135
Validation loss: 2.74840756471334

Epoch: 6| Step: 8
Training loss: 3.5472399822106824
Validation loss: 2.7454970606632787

Epoch: 6| Step: 9
Training loss: 3.2354489814698573
Validation loss: 2.7470908294225715

Epoch: 6| Step: 10
Training loss: 3.3753721243959776
Validation loss: 2.7475215542318323

Epoch: 6| Step: 11
Training loss: 2.9364427327723526
Validation loss: 2.7512436009755703

Epoch: 6| Step: 12
Training loss: 2.7810400551411627
Validation loss: 2.7508890405969613

Epoch: 6| Step: 13
Training loss: 3.707954058736
Validation loss: 2.756567877424204

Epoch: 221| Step: 0
Training loss: 3.5462437542714786
Validation loss: 2.7554610481318433

Epoch: 6| Step: 1
Training loss: 3.1013244998813736
Validation loss: 2.7483339362154786

Epoch: 6| Step: 2
Training loss: 2.5453421069367503
Validation loss: 2.7455069230390747

Epoch: 6| Step: 3
Training loss: 2.7193269665490716
Validation loss: 2.7457570431582687

Epoch: 6| Step: 4
Training loss: 2.6521321410317498
Validation loss: 2.7462491906487534

Epoch: 6| Step: 5
Training loss: 2.8576621673571108
Validation loss: 2.7488945690384643

Epoch: 6| Step: 6
Training loss: 3.2145183115770033
Validation loss: 2.7475505465509014

Epoch: 6| Step: 7
Training loss: 3.5873097970763825
Validation loss: 2.7507594077102118

Epoch: 6| Step: 8
Training loss: 2.8728004002344822
Validation loss: 2.7533286980898803

Epoch: 6| Step: 9
Training loss: 3.2191640346857686
Validation loss: 2.7535815776367265

Epoch: 6| Step: 10
Training loss: 3.003001142442545
Validation loss: 2.7544721799354126

Epoch: 6| Step: 11
Training loss: 3.151733944512866
Validation loss: 2.764352158756796

Epoch: 6| Step: 12
Training loss: 3.329336599533481
Validation loss: 2.7639948631061872

Epoch: 6| Step: 13
Training loss: 2.8130091736091667
Validation loss: 2.7602401079460788

Epoch: 222| Step: 0
Training loss: 2.9187229718870364
Validation loss: 2.7626477185085263

Epoch: 6| Step: 1
Training loss: 2.196150541707754
Validation loss: 2.7621082898486655

Epoch: 6| Step: 2
Training loss: 2.653232251483096
Validation loss: 2.7607502496419847

Epoch: 6| Step: 3
Training loss: 3.157800576830688
Validation loss: 2.7569717947338375

Epoch: 6| Step: 4
Training loss: 2.5326448529796797
Validation loss: 2.75228660360493

Epoch: 6| Step: 5
Training loss: 3.3877379611847704
Validation loss: 2.744585062651754

Epoch: 6| Step: 6
Training loss: 2.83644070114911
Validation loss: 2.7526870680750406

Epoch: 6| Step: 7
Training loss: 2.8712282733153334
Validation loss: 2.74987339425649

Epoch: 6| Step: 8
Training loss: 3.1033068155152086
Validation loss: 2.742764546198751

Epoch: 6| Step: 9
Training loss: 3.3611411486527896
Validation loss: 2.740552053370439

Epoch: 6| Step: 10
Training loss: 2.8612964615355567
Validation loss: 2.744863736420551

Epoch: 6| Step: 11
Training loss: 3.7670674074287303
Validation loss: 2.7453496250333624

Epoch: 6| Step: 12
Training loss: 3.6880155299970623
Validation loss: 2.7604963737274804

Epoch: 6| Step: 13
Training loss: 3.2418167086071645
Validation loss: 2.7574858898658308

Epoch: 223| Step: 0
Training loss: 3.178711087509597
Validation loss: 2.7736675642493935

Epoch: 6| Step: 1
Training loss: 2.691830362198283
Validation loss: 2.780990933257869

Epoch: 6| Step: 2
Training loss: 2.581067711995373
Validation loss: 2.772034799018902

Epoch: 6| Step: 3
Training loss: 3.041633832223026
Validation loss: 2.78587400749744

Epoch: 6| Step: 4
Training loss: 3.7093102672041645
Validation loss: 2.7958203012119207

Epoch: 6| Step: 5
Training loss: 3.057298875807798
Validation loss: 2.789655982196561

Epoch: 6| Step: 6
Training loss: 2.900018389413341
Validation loss: 2.777637858473062

Epoch: 6| Step: 7
Training loss: 3.053577270119799
Validation loss: 2.7674858164767278

Epoch: 6| Step: 8
Training loss: 2.9915971696550794
Validation loss: 2.7498988135731186

Epoch: 6| Step: 9
Training loss: 3.463973046689087
Validation loss: 2.7390646738119635

Epoch: 6| Step: 10
Training loss: 2.75351940711632
Validation loss: 2.743819653748172

Epoch: 6| Step: 11
Training loss: 2.927293455426382
Validation loss: 2.7438619039510375

Epoch: 6| Step: 12
Training loss: 2.8761771736059947
Validation loss: 2.7482512200332487

Epoch: 6| Step: 13
Training loss: 3.9038521693256687
Validation loss: 2.7509124394379807

Epoch: 224| Step: 0
Training loss: 2.802092475356229
Validation loss: 2.746287953286478

Epoch: 6| Step: 1
Training loss: 2.8195956262187396
Validation loss: 2.74769193943862

Epoch: 6| Step: 2
Training loss: 2.9172882144421464
Validation loss: 2.7484669761208314

Epoch: 6| Step: 3
Training loss: 3.189917750718293
Validation loss: 2.748749675265265

Epoch: 6| Step: 4
Training loss: 3.0148477293820104
Validation loss: 2.7469439431696645

Epoch: 6| Step: 5
Training loss: 3.44374640545943
Validation loss: 2.7464419323774547

Epoch: 6| Step: 6
Training loss: 3.1306689913067913
Validation loss: 2.7438725766492458

Epoch: 6| Step: 7
Training loss: 2.5938014749222025
Validation loss: 2.7422134187371716

Epoch: 6| Step: 8
Training loss: 2.905126210817914
Validation loss: 2.7422381480729183

Epoch: 6| Step: 9
Training loss: 2.804404921893838
Validation loss: 2.7403165866192563

Epoch: 6| Step: 10
Training loss: 3.2535340095080287
Validation loss: 2.7388270770053524

Epoch: 6| Step: 11
Training loss: 3.4581058534622677
Validation loss: 2.7418165680278603

Epoch: 6| Step: 12
Training loss: 3.548253535109077
Validation loss: 2.739679187408005

Epoch: 6| Step: 13
Training loss: 2.7679501689273227
Validation loss: 2.7434448355032357

Epoch: 225| Step: 0
Training loss: 3.2053393641630405
Validation loss: 2.742199292663136

Epoch: 6| Step: 1
Training loss: 2.8761504815303436
Validation loss: 2.7378339883900806

Epoch: 6| Step: 2
Training loss: 3.1518820574619206
Validation loss: 2.7404661513481123

Epoch: 6| Step: 3
Training loss: 2.7784951957810753
Validation loss: 2.738804142156204

Epoch: 6| Step: 4
Training loss: 2.9343917309951335
Validation loss: 2.7404691200799633

Epoch: 6| Step: 5
Training loss: 3.6085042852794125
Validation loss: 2.7370943681542697

Epoch: 6| Step: 6
Training loss: 3.5898412262385717
Validation loss: 2.739975164353441

Epoch: 6| Step: 7
Training loss: 3.0884264216330006
Validation loss: 2.740995088192938

Epoch: 6| Step: 8
Training loss: 3.2430606999017257
Validation loss: 2.7437756874327848

Epoch: 6| Step: 9
Training loss: 2.6191610154873692
Validation loss: 2.7382203152777973

Epoch: 6| Step: 10
Training loss: 2.372626071872412
Validation loss: 2.7369571270935444

Epoch: 6| Step: 11
Training loss: 3.204968029225779
Validation loss: 2.7413613918782227

Epoch: 6| Step: 12
Training loss: 2.9919937110875585
Validation loss: 2.737586730086587

Epoch: 6| Step: 13
Training loss: 2.7974915916991496
Validation loss: 2.7414077310611873

Epoch: 226| Step: 0
Training loss: 3.372441063458554
Validation loss: 2.740677960681394

Epoch: 6| Step: 1
Training loss: 2.948226175583797
Validation loss: 2.743760160397969

Epoch: 6| Step: 2
Training loss: 3.204448593958218
Validation loss: 2.7438197303634584

Epoch: 6| Step: 3
Training loss: 3.343479181178364
Validation loss: 2.7464067190353543

Epoch: 6| Step: 4
Training loss: 3.5751705048989093
Validation loss: 2.739546487155643

Epoch: 6| Step: 5
Training loss: 2.6161637310853996
Validation loss: 2.7400305174141657

Epoch: 6| Step: 6
Training loss: 3.2812436058345438
Validation loss: 2.7400591015397917

Epoch: 6| Step: 7
Training loss: 2.7822834623656902
Validation loss: 2.738188252499384

Epoch: 6| Step: 8
Training loss: 3.174725383987237
Validation loss: 2.7359198462503866

Epoch: 6| Step: 9
Training loss: 2.619666721607885
Validation loss: 2.7392533052559567

Epoch: 6| Step: 10
Training loss: 2.795646696119509
Validation loss: 2.737090158942483

Epoch: 6| Step: 11
Training loss: 3.2875538172505037
Validation loss: 2.7401666306074905

Epoch: 6| Step: 12
Training loss: 2.9280278502218526
Validation loss: 2.73702173539568

Epoch: 6| Step: 13
Training loss: 2.3539245503471022
Validation loss: 2.739304177909239

Epoch: 227| Step: 0
Training loss: 3.200331944891829
Validation loss: 2.7362655493482215

Epoch: 6| Step: 1
Training loss: 3.782370283142737
Validation loss: 2.735946433427658

Epoch: 6| Step: 2
Training loss: 2.154637604620525
Validation loss: 2.7344338968851387

Epoch: 6| Step: 3
Training loss: 3.0087329595548393
Validation loss: 2.738044339871674

Epoch: 6| Step: 4
Training loss: 2.9037487792966186
Validation loss: 2.742516846253534

Epoch: 6| Step: 5
Training loss: 3.5438181606512655
Validation loss: 2.745745079973433

Epoch: 6| Step: 6
Training loss: 2.480346099945065
Validation loss: 2.738690541524714

Epoch: 6| Step: 7
Training loss: 3.149825403127994
Validation loss: 2.7397930081090265

Epoch: 6| Step: 8
Training loss: 2.962692344634366
Validation loss: 2.745114950829795

Epoch: 6| Step: 9
Training loss: 3.1224818956203033
Validation loss: 2.7427865805442324

Epoch: 6| Step: 10
Training loss: 3.1646250283610846
Validation loss: 2.750290949430838

Epoch: 6| Step: 11
Training loss: 3.187114019024684
Validation loss: 2.7408547406897097

Epoch: 6| Step: 12
Training loss: 3.0187876823395383
Validation loss: 2.748766412676892

Epoch: 6| Step: 13
Training loss: 2.5564732274564146
Validation loss: 2.747386264517063

Epoch: 228| Step: 0
Training loss: 3.4039536881484698
Validation loss: 2.7404658693020485

Epoch: 6| Step: 1
Training loss: 3.1092421920247695
Validation loss: 2.7387422942359074

Epoch: 6| Step: 2
Training loss: 3.76259101428086
Validation loss: 2.7424854852533076

Epoch: 6| Step: 3
Training loss: 2.905908379934447
Validation loss: 2.7446216495493285

Epoch: 6| Step: 4
Training loss: 2.7800849446004947
Validation loss: 2.7397304498374386

Epoch: 6| Step: 5
Training loss: 3.570282983970924
Validation loss: 2.74561744328094

Epoch: 6| Step: 6
Training loss: 2.202419952773872
Validation loss: 2.742023854035033

Epoch: 6| Step: 7
Training loss: 2.8670506249792393
Validation loss: 2.737465335950316

Epoch: 6| Step: 8
Training loss: 3.2483388616972517
Validation loss: 2.742297362202373

Epoch: 6| Step: 9
Training loss: 2.4284952556460877
Validation loss: 2.7473603460580915

Epoch: 6| Step: 10
Training loss: 2.8031913996118187
Validation loss: 2.741401335529958

Epoch: 6| Step: 11
Training loss: 3.2511387810609165
Validation loss: 2.7452056405086984

Epoch: 6| Step: 12
Training loss: 2.7582277844413534
Validation loss: 2.745102179828264

Epoch: 6| Step: 13
Training loss: 3.4833922775124257
Validation loss: 2.747791685439303

Epoch: 229| Step: 0
Training loss: 3.288904616673412
Validation loss: 2.7459597735415615

Epoch: 6| Step: 1
Training loss: 3.1486050014570255
Validation loss: 2.7393999684443284

Epoch: 6| Step: 2
Training loss: 3.4962325936989895
Validation loss: 2.734553882472618

Epoch: 6| Step: 3
Training loss: 3.249113402111455
Validation loss: 2.7349241679719736

Epoch: 6| Step: 4
Training loss: 2.511775323162454
Validation loss: 2.73218545422529

Epoch: 6| Step: 5
Training loss: 3.0835492513851266
Validation loss: 2.733125646515832

Epoch: 6| Step: 6
Training loss: 2.488890377206963
Validation loss: 2.732832361147488

Epoch: 6| Step: 7
Training loss: 3.002222985949052
Validation loss: 2.7298875702161025

Epoch: 6| Step: 8
Training loss: 3.045759573972688
Validation loss: 2.732677900388863

Epoch: 6| Step: 9
Training loss: 3.1564979078170197
Validation loss: 2.734519497617615

Epoch: 6| Step: 10
Training loss: 3.0208041134879022
Validation loss: 2.744521722484292

Epoch: 6| Step: 11
Training loss: 2.7487569080108116
Validation loss: 2.741296537028485

Epoch: 6| Step: 12
Training loss: 3.275625585546152
Validation loss: 2.7358742405906162

Epoch: 6| Step: 13
Training loss: 3.0751960877956313
Validation loss: 2.734579341068067

Epoch: 230| Step: 0
Training loss: 3.5124388774291546
Validation loss: 2.731466751131526

Epoch: 6| Step: 1
Training loss: 3.2088943255206144
Validation loss: 2.7325933307148267

Epoch: 6| Step: 2
Training loss: 2.374250394077435
Validation loss: 2.733805838091721

Epoch: 6| Step: 3
Training loss: 3.2508464591250177
Validation loss: 2.7332852199780864

Epoch: 6| Step: 4
Training loss: 3.2672877117096477
Validation loss: 2.7333218891925677

Epoch: 6| Step: 5
Training loss: 2.3562898991695023
Validation loss: 2.7370527871520993

Epoch: 6| Step: 6
Training loss: 3.4553947066486272
Validation loss: 2.733616099249114

Epoch: 6| Step: 7
Training loss: 2.8215369950444202
Validation loss: 2.7340465220612993

Epoch: 6| Step: 8
Training loss: 3.0694066232812767
Validation loss: 2.7342829263071997

Epoch: 6| Step: 9
Training loss: 2.9623532093878358
Validation loss: 2.732139334894636

Epoch: 6| Step: 10
Training loss: 3.481460104719627
Validation loss: 2.7333014377435783

Epoch: 6| Step: 11
Training loss: 2.744950861117545
Validation loss: 2.732339270090897

Epoch: 6| Step: 12
Training loss: 3.3168161451179556
Validation loss: 2.7285019034359235

Epoch: 6| Step: 13
Training loss: 2.2129145433256143
Validation loss: 2.7367297499789247

Epoch: 231| Step: 0
Training loss: 2.637367632107057
Validation loss: 2.729798840616526

Epoch: 6| Step: 1
Training loss: 3.385002009110862
Validation loss: 2.7355087222297074

Epoch: 6| Step: 2
Training loss: 3.13483285802122
Validation loss: 2.7391327486999613

Epoch: 6| Step: 3
Training loss: 2.462826926899816
Validation loss: 2.7518611140245963

Epoch: 6| Step: 4
Training loss: 2.541336684355206
Validation loss: 2.747106297503731

Epoch: 6| Step: 5
Training loss: 3.1764325251823204
Validation loss: 2.7772083899373636

Epoch: 6| Step: 6
Training loss: 3.119558555966925
Validation loss: 2.76467919565561

Epoch: 6| Step: 7
Training loss: 3.1888885465556043
Validation loss: 2.745131325641648

Epoch: 6| Step: 8
Training loss: 2.723960706273365
Validation loss: 2.744675670830859

Epoch: 6| Step: 9
Training loss: 3.1800860780785882
Validation loss: 2.7328538601921477

Epoch: 6| Step: 10
Training loss: 2.741009494513149
Validation loss: 2.7292107437082644

Epoch: 6| Step: 11
Training loss: 3.2440133342539426
Validation loss: 2.7244959954923518

Epoch: 6| Step: 12
Training loss: 3.6320378615888815
Validation loss: 2.730033247216851

Epoch: 6| Step: 13
Training loss: 3.631235613113241
Validation loss: 2.727226236007094

Epoch: 232| Step: 0
Training loss: 3.122183025999494
Validation loss: 2.7261096500592616

Epoch: 6| Step: 1
Training loss: 2.7683126030899246
Validation loss: 2.7255572025284893

Epoch: 6| Step: 2
Training loss: 2.623622623748408
Validation loss: 2.736911868433417

Epoch: 6| Step: 3
Training loss: 2.613685200351811
Validation loss: 2.765057175895969

Epoch: 6| Step: 4
Training loss: 3.5269037016573277
Validation loss: 2.8028800963918545

Epoch: 6| Step: 5
Training loss: 3.244506447851341
Validation loss: 2.754605338461158

Epoch: 6| Step: 6
Training loss: 3.257080581375631
Validation loss: 2.746883219279736

Epoch: 6| Step: 7
Training loss: 3.866147419715353
Validation loss: 2.7343692058730373

Epoch: 6| Step: 8
Training loss: 3.075305402522914
Validation loss: 2.7336257512784705

Epoch: 6| Step: 9
Training loss: 2.988934613775826
Validation loss: 2.729994847270531

Epoch: 6| Step: 10
Training loss: 2.4976829281582233
Validation loss: 2.7258835378012174

Epoch: 6| Step: 11
Training loss: 3.0543476510818857
Validation loss: 2.7287275046631114

Epoch: 6| Step: 12
Training loss: 2.944159244024481
Validation loss: 2.72843633512993

Epoch: 6| Step: 13
Training loss: 2.9034807691428277
Validation loss: 2.728914108432507

Epoch: 233| Step: 0
Training loss: 3.6764453770390175
Validation loss: 2.731432634326319

Epoch: 6| Step: 1
Training loss: 2.9117507560246225
Validation loss: 2.733097981340731

Epoch: 6| Step: 2
Training loss: 3.5571406692174246
Validation loss: 2.732520040259156

Epoch: 6| Step: 3
Training loss: 2.4967431789162546
Validation loss: 2.731927229059107

Epoch: 6| Step: 4
Training loss: 3.0047718879327165
Validation loss: 2.7318934060968996

Epoch: 6| Step: 5
Training loss: 2.771808414455099
Validation loss: 2.728897520757528

Epoch: 6| Step: 6
Training loss: 3.318703510655657
Validation loss: 2.7317691538133877

Epoch: 6| Step: 7
Training loss: 3.273209666332939
Validation loss: 2.733631019929164

Epoch: 6| Step: 8
Training loss: 3.8665317172036233
Validation loss: 2.736872069081376

Epoch: 6| Step: 9
Training loss: 2.3342211487510895
Validation loss: 2.7417690454597876

Epoch: 6| Step: 10
Training loss: 2.665701353672278
Validation loss: 2.742219802090767

Epoch: 6| Step: 11
Training loss: 2.407819954119809
Validation loss: 2.7437032077191104

Epoch: 6| Step: 12
Training loss: 2.9680165238036142
Validation loss: 2.7366903142542016

Epoch: 6| Step: 13
Training loss: 3.195013279417138
Validation loss: 2.7347455023625917

Epoch: 234| Step: 0
Training loss: 2.776140813625569
Validation loss: 2.7306739945584746

Epoch: 6| Step: 1
Training loss: 2.330003428640831
Validation loss: 2.7291619373522598

Epoch: 6| Step: 2
Training loss: 2.5005198891803526
Validation loss: 2.725660987489994

Epoch: 6| Step: 3
Training loss: 3.3200390512398816
Validation loss: 2.724097338205119

Epoch: 6| Step: 4
Training loss: 3.780236226526687
Validation loss: 2.7268442190033024

Epoch: 6| Step: 5
Training loss: 2.3530011513022653
Validation loss: 2.725090050731133

Epoch: 6| Step: 6
Training loss: 2.786386097955099
Validation loss: 2.727342999672586

Epoch: 6| Step: 7
Training loss: 3.331490833959747
Validation loss: 2.723977595059052

Epoch: 6| Step: 8
Training loss: 3.7863987949033326
Validation loss: 2.7232808911220823

Epoch: 6| Step: 9
Training loss: 3.420171165421586
Validation loss: 2.7210105019958966

Epoch: 6| Step: 10
Training loss: 2.411188383763714
Validation loss: 2.72105217834186

Epoch: 6| Step: 11
Training loss: 2.9738523305160633
Validation loss: 2.722266365331934

Epoch: 6| Step: 12
Training loss: 2.7995695634781383
Validation loss: 2.7205978571184635

Epoch: 6| Step: 13
Training loss: 3.8325355501261766
Validation loss: 2.7239309697094476

Epoch: 235| Step: 0
Training loss: 2.8161686176676257
Validation loss: 2.7239207901603937

Epoch: 6| Step: 1
Training loss: 3.412717785715151
Validation loss: 2.7167203156426845

Epoch: 6| Step: 2
Training loss: 3.1136267648610962
Validation loss: 2.7215608232875836

Epoch: 6| Step: 3
Training loss: 3.168183381774445
Validation loss: 2.7199325620481556

Epoch: 6| Step: 4
Training loss: 3.5086921659404706
Validation loss: 2.7185823103359548

Epoch: 6| Step: 5
Training loss: 2.4841916958344483
Validation loss: 2.719849542006964

Epoch: 6| Step: 6
Training loss: 2.6329990400116268
Validation loss: 2.7177833636920696

Epoch: 6| Step: 7
Training loss: 2.322529359925524
Validation loss: 2.718684833949298

Epoch: 6| Step: 8
Training loss: 3.029528414094213
Validation loss: 2.7190338031899786

Epoch: 6| Step: 9
Training loss: 3.8736670878062456
Validation loss: 2.721130135467202

Epoch: 6| Step: 10
Training loss: 3.288823714841999
Validation loss: 2.718597270149012

Epoch: 6| Step: 11
Training loss: 2.9042710981013964
Validation loss: 2.7211800006648117

Epoch: 6| Step: 12
Training loss: 2.358229403233266
Validation loss: 2.717127329773475

Epoch: 6| Step: 13
Training loss: 3.4740628632352006
Validation loss: 2.71816166862942

Epoch: 236| Step: 0
Training loss: 3.106127552712261
Validation loss: 2.7178875766159796

Epoch: 6| Step: 1
Training loss: 3.1487988437379095
Validation loss: 2.7188934780531655

Epoch: 6| Step: 2
Training loss: 2.560688401885855
Validation loss: 2.7213728043536753

Epoch: 6| Step: 3
Training loss: 2.5462482828051134
Validation loss: 2.720199244901351

Epoch: 6| Step: 4
Training loss: 3.636650306065789
Validation loss: 2.718974233283401

Epoch: 6| Step: 5
Training loss: 3.000277983184124
Validation loss: 2.72065905838068

Epoch: 6| Step: 6
Training loss: 3.5956137426933816
Validation loss: 2.72300411715089

Epoch: 6| Step: 7
Training loss: 2.8579421492127985
Validation loss: 2.724040275114086

Epoch: 6| Step: 8
Training loss: 2.5706970483730984
Validation loss: 2.7233483260032183

Epoch: 6| Step: 9
Training loss: 3.252569210128326
Validation loss: 2.7242387946311135

Epoch: 6| Step: 10
Training loss: 3.30723239314913
Validation loss: 2.7258192636575043

Epoch: 6| Step: 11
Training loss: 3.1500172024211737
Validation loss: 2.726210769676714

Epoch: 6| Step: 12
Training loss: 2.904075875817449
Validation loss: 2.7238909722202163

Epoch: 6| Step: 13
Training loss: 2.376139317342298
Validation loss: 2.7185690855814264

Epoch: 237| Step: 0
Training loss: 2.9968375385636015
Validation loss: 2.7221942057063213

Epoch: 6| Step: 1
Training loss: 3.4236045890644533
Validation loss: 2.723848216477786

Epoch: 6| Step: 2
Training loss: 3.356255506798686
Validation loss: 2.7173777035216333

Epoch: 6| Step: 3
Training loss: 2.608558389950146
Validation loss: 2.719938895898212

Epoch: 6| Step: 4
Training loss: 2.9109947276773673
Validation loss: 2.7171480746796335

Epoch: 6| Step: 5
Training loss: 3.2441441526169865
Validation loss: 2.722717153593306

Epoch: 6| Step: 6
Training loss: 3.005211277546534
Validation loss: 2.721925131996592

Epoch: 6| Step: 7
Training loss: 3.2022304867595075
Validation loss: 2.7149177985584556

Epoch: 6| Step: 8
Training loss: 2.8848864530700222
Validation loss: 2.7210579772719297

Epoch: 6| Step: 9
Training loss: 2.653888774878301
Validation loss: 2.720040005523009

Epoch: 6| Step: 10
Training loss: 2.854881549789777
Validation loss: 2.722243606912266

Epoch: 6| Step: 11
Training loss: 2.5339206688136597
Validation loss: 2.7224968840786707

Epoch: 6| Step: 12
Training loss: 3.5397239892115606
Validation loss: 2.7277384420337154

Epoch: 6| Step: 13
Training loss: 3.1876132421386254
Validation loss: 2.7205015411889746

Epoch: 238| Step: 0
Training loss: 3.2435105898787002
Validation loss: 2.721866609621583

Epoch: 6| Step: 1
Training loss: 2.635882933209563
Validation loss: 2.7274212460243805

Epoch: 6| Step: 2
Training loss: 3.2847453074666713
Validation loss: 2.7285541528738144

Epoch: 6| Step: 3
Training loss: 2.9358129323668662
Validation loss: 2.7221278770772606

Epoch: 6| Step: 4
Training loss: 2.648771641900732
Validation loss: 2.7211398553379476

Epoch: 6| Step: 5
Training loss: 2.5859859035606334
Validation loss: 2.713387259817478

Epoch: 6| Step: 6
Training loss: 3.0770887770418445
Validation loss: 2.7135175141317056

Epoch: 6| Step: 7
Training loss: 3.5669948931914943
Validation loss: 2.7136071785559492

Epoch: 6| Step: 8
Training loss: 2.9505187144304137
Validation loss: 2.7122074349169307

Epoch: 6| Step: 9
Training loss: 3.3763584652552634
Validation loss: 2.7145479652725477

Epoch: 6| Step: 10
Training loss: 3.2758078357755833
Validation loss: 2.714121632663239

Epoch: 6| Step: 11
Training loss: 3.2850572568876593
Validation loss: 2.7123469916004073

Epoch: 6| Step: 12
Training loss: 2.746622612547424
Validation loss: 2.7140762869710553

Epoch: 6| Step: 13
Training loss: 2.501790263989749
Validation loss: 2.712949777573962

Epoch: 239| Step: 0
Training loss: 2.805830528666499
Validation loss: 2.7165601810701503

Epoch: 6| Step: 1
Training loss: 3.6176246065877886
Validation loss: 2.710463245935531

Epoch: 6| Step: 2
Training loss: 3.2044680873206164
Validation loss: 2.7123208139270134

Epoch: 6| Step: 3
Training loss: 3.509452317592876
Validation loss: 2.7129961342906337

Epoch: 6| Step: 4
Training loss: 2.9400910657934887
Validation loss: 2.712716374585926

Epoch: 6| Step: 5
Training loss: 2.9529506086901085
Validation loss: 2.719115284939526

Epoch: 6| Step: 6
Training loss: 2.9160736752740775
Validation loss: 2.718117828667152

Epoch: 6| Step: 7
Training loss: 3.3070749447119288
Validation loss: 2.7118206967972283

Epoch: 6| Step: 8
Training loss: 2.4641706269995356
Validation loss: 2.713831487247387

Epoch: 6| Step: 9
Training loss: 2.460110189249561
Validation loss: 2.711637544570183

Epoch: 6| Step: 10
Training loss: 2.683819046447108
Validation loss: 2.7155270424603373

Epoch: 6| Step: 11
Training loss: 3.1625529891689967
Validation loss: 2.7087045814248367

Epoch: 6| Step: 12
Training loss: 2.8507545476213294
Validation loss: 2.7122313858147877

Epoch: 6| Step: 13
Training loss: 3.668142816315394
Validation loss: 2.711652757306057

Epoch: 240| Step: 0
Training loss: 3.130842621699562
Validation loss: 2.7145011911778227

Epoch: 6| Step: 1
Training loss: 3.038467466651311
Validation loss: 2.710507756385137

Epoch: 6| Step: 2
Training loss: 2.6284264499358105
Validation loss: 2.7082744068206708

Epoch: 6| Step: 3
Training loss: 3.0353317308204533
Validation loss: 2.711209737814558

Epoch: 6| Step: 4
Training loss: 2.209049672477931
Validation loss: 2.7121738188006232

Epoch: 6| Step: 5
Training loss: 3.084366255943944
Validation loss: 2.710369258953849

Epoch: 6| Step: 6
Training loss: 2.7728288869245663
Validation loss: 2.7122714739590634

Epoch: 6| Step: 7
Training loss: 3.457349721603695
Validation loss: 2.7131814719769447

Epoch: 6| Step: 8
Training loss: 3.191846389956007
Validation loss: 2.7113606509618196

Epoch: 6| Step: 9
Training loss: 3.5419277020167246
Validation loss: 2.710990220350695

Epoch: 6| Step: 10
Training loss: 2.896994012817896
Validation loss: 2.7107685137274142

Epoch: 6| Step: 11
Training loss: 2.7301288005641196
Validation loss: 2.7137163584795645

Epoch: 6| Step: 12
Training loss: 3.148145638466959
Validation loss: 2.7092159363404673

Epoch: 6| Step: 13
Training loss: 3.542181059937077
Validation loss: 2.7133811336500524

Epoch: 241| Step: 0
Training loss: 3.1781812094609863
Validation loss: 2.713878646017721

Epoch: 6| Step: 1
Training loss: 2.046132542729276
Validation loss: 2.709842910214027

Epoch: 6| Step: 2
Training loss: 3.724898952675307
Validation loss: 2.7096364416299563

Epoch: 6| Step: 3
Training loss: 3.150469935649234
Validation loss: 2.7091849705342828

Epoch: 6| Step: 4
Training loss: 3.1192724000616128
Validation loss: 2.709665400309454

Epoch: 6| Step: 5
Training loss: 3.331501854971745
Validation loss: 2.7084145930541745

Epoch: 6| Step: 6
Training loss: 1.7796066466763185
Validation loss: 2.708854464868777

Epoch: 6| Step: 7
Training loss: 2.819425490951932
Validation loss: 2.7114433830082003

Epoch: 6| Step: 8
Training loss: 3.395693177371329
Validation loss: 2.7096319040356893

Epoch: 6| Step: 9
Training loss: 3.5248306125497675
Validation loss: 2.707947456630369

Epoch: 6| Step: 10
Training loss: 3.0928317161780994
Validation loss: 2.7090233093497353

Epoch: 6| Step: 11
Training loss: 3.1315276062851147
Validation loss: 2.714308861818749

Epoch: 6| Step: 12
Training loss: 2.4230914598711273
Validation loss: 2.7100904133692953

Epoch: 6| Step: 13
Training loss: 3.169421670668241
Validation loss: 2.707681586614238

Epoch: 242| Step: 0
Training loss: 2.570808525110013
Validation loss: 2.7101851601423

Epoch: 6| Step: 1
Training loss: 1.9680733501868517
Validation loss: 2.7092643024350282

Epoch: 6| Step: 2
Training loss: 3.577959748162723
Validation loss: 2.7114493027100823

Epoch: 6| Step: 3
Training loss: 2.99126960081636
Validation loss: 2.7102659847201394

Epoch: 6| Step: 4
Training loss: 3.3042118821451774
Validation loss: 2.7111664454575215

Epoch: 6| Step: 5
Training loss: 3.128789054209271
Validation loss: 2.7062622961256477

Epoch: 6| Step: 6
Training loss: 2.635136786716126
Validation loss: 2.7076805129395964

Epoch: 6| Step: 7
Training loss: 3.1617727777923372
Validation loss: 2.70455544809564

Epoch: 6| Step: 8
Training loss: 2.8468696334570542
Validation loss: 2.7077877249203643

Epoch: 6| Step: 9
Training loss: 3.4922036121517293
Validation loss: 2.708701508315306

Epoch: 6| Step: 10
Training loss: 3.172221047452615
Validation loss: 2.7048436716991424

Epoch: 6| Step: 11
Training loss: 3.1404358156833516
Validation loss: 2.7036607211329273

Epoch: 6| Step: 12
Training loss: 3.3979452544007085
Validation loss: 2.701907205385006

Epoch: 6| Step: 13
Training loss: 2.3520531633557846
Validation loss: 2.7056081049292917

Epoch: 243| Step: 0
Training loss: 3.2243603449039413
Validation loss: 2.704650553692683

Epoch: 6| Step: 1
Training loss: 2.583123742081811
Validation loss: 2.7071494737349013

Epoch: 6| Step: 2
Training loss: 3.2872410893471424
Validation loss: 2.705189296211556

Epoch: 6| Step: 3
Training loss: 2.9615526189475214
Validation loss: 2.705720087208462

Epoch: 6| Step: 4
Training loss: 3.1522877817018853
Validation loss: 2.7049020756940054

Epoch: 6| Step: 5
Training loss: 3.1397260451625195
Validation loss: 2.7025455610399143

Epoch: 6| Step: 6
Training loss: 3.6869159817911648
Validation loss: 2.7054452407337273

Epoch: 6| Step: 7
Training loss: 2.637836496302526
Validation loss: 2.7053963031864328

Epoch: 6| Step: 8
Training loss: 3.034646873983903
Validation loss: 2.7061942213876384

Epoch: 6| Step: 9
Training loss: 2.8065947526914106
Validation loss: 2.7094302004835185

Epoch: 6| Step: 10
Training loss: 2.7054807067307256
Validation loss: 2.7084548209860966

Epoch: 6| Step: 11
Training loss: 3.199871811683408
Validation loss: 2.7097982081457452

Epoch: 6| Step: 12
Training loss: 2.743511260818611
Validation loss: 2.711689547930626

Epoch: 6| Step: 13
Training loss: 3.1565429249417014
Validation loss: 2.7030963496673746

Epoch: 244| Step: 0
Training loss: 2.6747205427847276
Validation loss: 2.7071263102861054

Epoch: 6| Step: 1
Training loss: 3.068325496610393
Validation loss: 2.7118257109699484

Epoch: 6| Step: 2
Training loss: 3.310341617668996
Validation loss: 2.7085787978210174

Epoch: 6| Step: 3
Training loss: 2.052117542685258
Validation loss: 2.705608806100249

Epoch: 6| Step: 4
Training loss: 2.8653831521317543
Validation loss: 2.7057486927045202

Epoch: 6| Step: 5
Training loss: 3.3465732527483607
Validation loss: 2.701036294861928

Epoch: 6| Step: 6
Training loss: 2.618736696778514
Validation loss: 2.70399027546047

Epoch: 6| Step: 7
Training loss: 3.452211975635221
Validation loss: 2.7040647937809124

Epoch: 6| Step: 8
Training loss: 3.093979027487772
Validation loss: 2.7044978778921416

Epoch: 6| Step: 9
Training loss: 2.513943886433375
Validation loss: 2.704077526320737

Epoch: 6| Step: 10
Training loss: 2.9562630909152046
Validation loss: 2.703374643088193

Epoch: 6| Step: 11
Training loss: 3.232324807360535
Validation loss: 2.700621243510154

Epoch: 6| Step: 12
Training loss: 3.582843983674497
Validation loss: 2.7061624811368703

Epoch: 6| Step: 13
Training loss: 3.444892009930501
Validation loss: 2.7025860945074913

Epoch: 245| Step: 0
Training loss: 3.1910719959119165
Validation loss: 2.7062875372739628

Epoch: 6| Step: 1
Training loss: 2.8623320084630928
Validation loss: 2.7056671978428577

Epoch: 6| Step: 2
Training loss: 2.8745493328315526
Validation loss: 2.705788626763597

Epoch: 6| Step: 3
Training loss: 3.0632634670964323
Validation loss: 2.701265656217938

Epoch: 6| Step: 4
Training loss: 3.1784983667882827
Validation loss: 2.7025000258540195

Epoch: 6| Step: 5
Training loss: 2.752931419607472
Validation loss: 2.704728143771144

Epoch: 6| Step: 6
Training loss: 2.966530703168568
Validation loss: 2.7026660384213606

Epoch: 6| Step: 7
Training loss: 3.4293945465448537
Validation loss: 2.7073411270972687

Epoch: 6| Step: 8
Training loss: 3.612683781895558
Validation loss: 2.70837273643991

Epoch: 6| Step: 9
Training loss: 2.975196985727472
Validation loss: 2.7106850541326875

Epoch: 6| Step: 10
Training loss: 2.973146736493783
Validation loss: 2.7088106682904454

Epoch: 6| Step: 11
Training loss: 2.737579212174897
Validation loss: 2.7066822657773897

Epoch: 6| Step: 12
Training loss: 2.75713714024412
Validation loss: 2.7051726549849744

Epoch: 6| Step: 13
Training loss: 2.907493407355958
Validation loss: 2.702416061406607

Epoch: 246| Step: 0
Training loss: 2.8330160599134517
Validation loss: 2.6999082358295294

Epoch: 6| Step: 1
Training loss: 3.474305523971858
Validation loss: 2.7037465338081024

Epoch: 6| Step: 2
Training loss: 2.462021652467341
Validation loss: 2.705511373811473

Epoch: 6| Step: 3
Training loss: 2.5909309234185995
Validation loss: 2.7054835882988706

Epoch: 6| Step: 4
Training loss: 2.823079534995974
Validation loss: 2.704089721250363

Epoch: 6| Step: 5
Training loss: 3.4540566961056256
Validation loss: 2.704885958245206

Epoch: 6| Step: 6
Training loss: 3.2263297304147187
Validation loss: 2.702528751756847

Epoch: 6| Step: 7
Training loss: 1.7964812801074803
Validation loss: 2.7017431834445453

Epoch: 6| Step: 8
Training loss: 2.483911243075437
Validation loss: 2.7068038830976855

Epoch: 6| Step: 9
Training loss: 3.5569377106839455
Validation loss: 2.713299237821371

Epoch: 6| Step: 10
Training loss: 3.4839926197661444
Validation loss: 2.7043258453162253

Epoch: 6| Step: 11
Training loss: 3.026537821151642
Validation loss: 2.701082380533931

Epoch: 6| Step: 12
Training loss: 3.7897482969097913
Validation loss: 2.705768920362579

Epoch: 6| Step: 13
Training loss: 2.50054887468384
Validation loss: 2.7018804037553834

Epoch: 247| Step: 0
Training loss: 2.7322904651991635
Validation loss: 2.697809707954638

Epoch: 6| Step: 1
Training loss: 2.7148719401919945
Validation loss: 2.703072996894155

Epoch: 6| Step: 2
Training loss: 3.330064092254158
Validation loss: 2.7007393766888996

Epoch: 6| Step: 3
Training loss: 3.784069428837259
Validation loss: 2.7041706104579406

Epoch: 6| Step: 4
Training loss: 3.4427768779323453
Validation loss: 2.697761321804902

Epoch: 6| Step: 5
Training loss: 2.7040396669852833
Validation loss: 2.698712332848614

Epoch: 6| Step: 6
Training loss: 2.6022064969856067
Validation loss: 2.696984613784409

Epoch: 6| Step: 7
Training loss: 2.8958050477181034
Validation loss: 2.696110697304186

Epoch: 6| Step: 8
Training loss: 2.935881797988927
Validation loss: 2.6981528143934526

Epoch: 6| Step: 9
Training loss: 2.69885269089811
Validation loss: 2.696428753759926

Epoch: 6| Step: 10
Training loss: 2.687732597753878
Validation loss: 2.7051274018926508

Epoch: 6| Step: 11
Training loss: 3.190987268817577
Validation loss: 2.6958954525322607

Epoch: 6| Step: 12
Training loss: 3.297366426551976
Validation loss: 2.696957052210766

Epoch: 6| Step: 13
Training loss: 3.1066201432746183
Validation loss: 2.695427653959017

Epoch: 248| Step: 0
Training loss: 2.870947760159516
Validation loss: 2.7002673028566315

Epoch: 6| Step: 1
Training loss: 2.6006630382217537
Validation loss: 2.7011448686626287

Epoch: 6| Step: 2
Training loss: 2.4620050930215327
Validation loss: 2.697838588327085

Epoch: 6| Step: 3
Training loss: 3.7230489549720085
Validation loss: 2.7013832335664176

Epoch: 6| Step: 4
Training loss: 3.4242556577586876
Validation loss: 2.6962312796605055

Epoch: 6| Step: 5
Training loss: 3.5899893281825843
Validation loss: 2.6943429614090233

Epoch: 6| Step: 6
Training loss: 2.3331363685672244
Validation loss: 2.693308505464501

Epoch: 6| Step: 7
Training loss: 2.6645548524942555
Validation loss: 2.6953994220962953

Epoch: 6| Step: 8
Training loss: 3.0200614907781356
Validation loss: 2.696265475818477

Epoch: 6| Step: 9
Training loss: 3.1381261193220844
Validation loss: 2.69608159303329

Epoch: 6| Step: 10
Training loss: 3.4631918976743385
Validation loss: 2.6966227405457377

Epoch: 6| Step: 11
Training loss: 2.9095728756722448
Validation loss: 2.695803335093635

Epoch: 6| Step: 12
Training loss: 2.800053330322286
Validation loss: 2.6940781287193065

Epoch: 6| Step: 13
Training loss: 2.886426195901639
Validation loss: 2.7021224883438664

Epoch: 249| Step: 0
Training loss: 2.9675529877608686
Validation loss: 2.6996707767193917

Epoch: 6| Step: 1
Training loss: 3.1817263503260893
Validation loss: 2.6972474217460545

Epoch: 6| Step: 2
Training loss: 2.7651922889607476
Validation loss: 2.6942562573821904

Epoch: 6| Step: 3
Training loss: 2.9303521381507127
Validation loss: 2.695495734303371

Epoch: 6| Step: 4
Training loss: 3.1953717438445035
Validation loss: 2.6961299009303343

Epoch: 6| Step: 5
Training loss: 3.526997258772838
Validation loss: 2.6939127736191137

Epoch: 6| Step: 6
Training loss: 2.983933660818063
Validation loss: 2.6970456379750334

Epoch: 6| Step: 7
Training loss: 3.015038467845054
Validation loss: 2.697852249190498

Epoch: 6| Step: 8
Training loss: 2.9127958679542894
Validation loss: 2.694578886369339

Epoch: 6| Step: 9
Training loss: 3.4426016663586467
Validation loss: 2.6932437547127006

Epoch: 6| Step: 10
Training loss: 3.0320941496853546
Validation loss: 2.696923556843842

Epoch: 6| Step: 11
Training loss: 2.4282636487497307
Validation loss: 2.6942779481610546

Epoch: 6| Step: 12
Training loss: 3.1706537611078174
Validation loss: 2.6970155932463094

Epoch: 6| Step: 13
Training loss: 2.171735361124777
Validation loss: 2.696228613549497

Epoch: 250| Step: 0
Training loss: 3.354357569851625
Validation loss: 2.6969651415309395

Epoch: 6| Step: 1
Training loss: 3.77770451555708
Validation loss: 2.694142377928059

Epoch: 6| Step: 2
Training loss: 3.105043547688894
Validation loss: 2.698325138873741

Epoch: 6| Step: 3
Training loss: 2.455823058473727
Validation loss: 2.696217121858253

Epoch: 6| Step: 4
Training loss: 2.9377515969173484
Validation loss: 2.698003175461635

Epoch: 6| Step: 5
Training loss: 2.9919651835348726
Validation loss: 2.7008071304483234

Epoch: 6| Step: 6
Training loss: 3.053224959830912
Validation loss: 2.697646486987823

Epoch: 6| Step: 7
Training loss: 2.860778297482381
Validation loss: 2.701171455504573

Epoch: 6| Step: 8
Training loss: 2.8111625034256744
Validation loss: 2.7009924607318907

Epoch: 6| Step: 9
Training loss: 2.8229014172206646
Validation loss: 2.7075099902032664

Epoch: 6| Step: 10
Training loss: 3.0314708511282498
Validation loss: 2.695831784301177

Epoch: 6| Step: 11
Training loss: 2.560341181520501
Validation loss: 2.7036601417759893

Epoch: 6| Step: 12
Training loss: 2.961527662419495
Validation loss: 2.702097073090262

Epoch: 6| Step: 13
Training loss: 3.566674580669239
Validation loss: 2.699337326348496

Epoch: 251| Step: 0
Training loss: 3.129137580692381
Validation loss: 2.6912571370883347

Epoch: 6| Step: 1
Training loss: 2.6820157893752246
Validation loss: 2.6914515642476213

Epoch: 6| Step: 2
Training loss: 3.2761606620359265
Validation loss: 2.693493993830258

Epoch: 6| Step: 3
Training loss: 3.0327311564350565
Validation loss: 2.6904806047959804

Epoch: 6| Step: 4
Training loss: 3.1653195745023956
Validation loss: 2.6937405190002273

Epoch: 6| Step: 5
Training loss: 3.0479620143796207
Validation loss: 2.694717334857864

Epoch: 6| Step: 6
Training loss: 3.279351548085038
Validation loss: 2.6934133550711876

Epoch: 6| Step: 7
Training loss: 3.032122928734265
Validation loss: 2.693226954957902

Epoch: 6| Step: 8
Training loss: 3.168965325196823
Validation loss: 2.693863825466323

Epoch: 6| Step: 9
Training loss: 2.759962070867894
Validation loss: 2.691110793793322

Epoch: 6| Step: 10
Training loss: 2.576362701127547
Validation loss: 2.6922554683679913

Epoch: 6| Step: 11
Training loss: 3.0145100326080083
Validation loss: 2.697297642925381

Epoch: 6| Step: 12
Training loss: 3.243564396070329
Validation loss: 2.690484551522712

Epoch: 6| Step: 13
Training loss: 2.4849244475824355
Validation loss: 2.6946603445870227

Epoch: 252| Step: 0
Training loss: 2.718814191389291
Validation loss: 2.7003301734597116

Epoch: 6| Step: 1
Training loss: 3.461907313330868
Validation loss: 2.69612453997934

Epoch: 6| Step: 2
Training loss: 2.6137558943665136
Validation loss: 2.6984643342670975

Epoch: 6| Step: 3
Training loss: 2.629512178557113
Validation loss: 2.6900836175963767

Epoch: 6| Step: 4
Training loss: 3.2475661921638106
Validation loss: 2.6926374598461593

Epoch: 6| Step: 5
Training loss: 3.74168134543436
Validation loss: 2.6914373612997085

Epoch: 6| Step: 6
Training loss: 2.8828379725542983
Validation loss: 2.69187692928142

Epoch: 6| Step: 7
Training loss: 3.4906611509850243
Validation loss: 2.6875149372789395

Epoch: 6| Step: 8
Training loss: 2.6071577874220857
Validation loss: 2.691566599553485

Epoch: 6| Step: 9
Training loss: 2.8269102744027665
Validation loss: 2.693096798759574

Epoch: 6| Step: 10
Training loss: 3.0534421914142396
Validation loss: 2.691826594587369

Epoch: 6| Step: 11
Training loss: 2.9742744843391504
Validation loss: 2.6929700919425996

Epoch: 6| Step: 12
Training loss: 2.8863222833291133
Validation loss: 2.690549855574425

Epoch: 6| Step: 13
Training loss: 2.7819817255545694
Validation loss: 2.69069942499918

Epoch: 253| Step: 0
Training loss: 3.2585703016455856
Validation loss: 2.6848096323554276

Epoch: 6| Step: 1
Training loss: 2.7359900364387637
Validation loss: 2.6883096736828103

Epoch: 6| Step: 2
Training loss: 3.3721108963040725
Validation loss: 2.688324705639416

Epoch: 6| Step: 3
Training loss: 2.409550372716293
Validation loss: 2.6882896798963927

Epoch: 6| Step: 4
Training loss: 3.5786995905324805
Validation loss: 2.6904763255162005

Epoch: 6| Step: 5
Training loss: 2.7176681646203096
Validation loss: 2.6862686218942584

Epoch: 6| Step: 6
Training loss: 3.5067120633492648
Validation loss: 2.6883017175735566

Epoch: 6| Step: 7
Training loss: 2.6192626014428915
Validation loss: 2.6893402442195216

Epoch: 6| Step: 8
Training loss: 2.7807709356327717
Validation loss: 2.687208218485477

Epoch: 6| Step: 9
Training loss: 3.165434965886109
Validation loss: 2.68611606947632

Epoch: 6| Step: 10
Training loss: 2.5618798971024646
Validation loss: 2.6855314456500192

Epoch: 6| Step: 11
Training loss: 2.8071623272846327
Validation loss: 2.6868891020492316

Epoch: 6| Step: 12
Training loss: 3.302073353332135
Validation loss: 2.6869283622904176

Epoch: 6| Step: 13
Training loss: 3.2417819953022624
Validation loss: 2.685901579550793

Epoch: 254| Step: 0
Training loss: 2.3624877606433126
Validation loss: 2.6877688010907357

Epoch: 6| Step: 1
Training loss: 2.560722851325631
Validation loss: 2.683945946483215

Epoch: 6| Step: 2
Training loss: 2.5971315700148447
Validation loss: 2.69014030886284

Epoch: 6| Step: 3
Training loss: 3.443729097334051
Validation loss: 2.6897693619422527

Epoch: 6| Step: 4
Training loss: 2.888175627696643
Validation loss: 2.6909584901591415

Epoch: 6| Step: 5
Training loss: 2.924941142215481
Validation loss: 2.687561530486531

Epoch: 6| Step: 6
Training loss: 2.6621491393536036
Validation loss: 2.6849473848616867

Epoch: 6| Step: 7
Training loss: 3.1570738670835183
Validation loss: 2.6839243575094276

Epoch: 6| Step: 8
Training loss: 3.16003976048432
Validation loss: 2.681897460439058

Epoch: 6| Step: 9
Training loss: 3.3027069433551812
Validation loss: 2.684806040137042

Epoch: 6| Step: 10
Training loss: 2.98211536443746
Validation loss: 2.681429863335059

Epoch: 6| Step: 11
Training loss: 2.9242780462842415
Validation loss: 2.6836349580387435

Epoch: 6| Step: 12
Training loss: 3.752554849710454
Validation loss: 2.686592741614122

Epoch: 6| Step: 13
Training loss: 3.3398564567101117
Validation loss: 2.686416699540876

Epoch: 255| Step: 0
Training loss: 3.4527587696417323
Validation loss: 2.686442210653769

Epoch: 6| Step: 1
Training loss: 2.665529714046276
Validation loss: 2.683790082076012

Epoch: 6| Step: 2
Training loss: 2.8310140953561973
Validation loss: 2.6864795440650937

Epoch: 6| Step: 3
Training loss: 3.075216555529597
Validation loss: 2.6899011849825243

Epoch: 6| Step: 4
Training loss: 3.2355091115333656
Validation loss: 2.683934427036464

Epoch: 6| Step: 5
Training loss: 2.350370491528672
Validation loss: 2.6850795114693446

Epoch: 6| Step: 6
Training loss: 3.144142117324003
Validation loss: 2.686901073010578

Epoch: 6| Step: 7
Training loss: 3.2019505278216256
Validation loss: 2.6920220910126016

Epoch: 6| Step: 8
Training loss: 3.398620179626757
Validation loss: 2.6897111025862133

Epoch: 6| Step: 9
Training loss: 3.1847419025759294
Validation loss: 2.690303419196453

Epoch: 6| Step: 10
Training loss: 2.8973090347673196
Validation loss: 2.6847781024064012

Epoch: 6| Step: 11
Training loss: 2.4719530404330996
Validation loss: 2.683129313004484

Epoch: 6| Step: 12
Training loss: 2.871969699232237
Validation loss: 2.6907426341112295

Epoch: 6| Step: 13
Training loss: 3.2509159851389025
Validation loss: 2.6834162214400794

Epoch: 256| Step: 0
Training loss: 2.3868673874543114
Validation loss: 2.6829180500506564

Epoch: 6| Step: 1
Training loss: 3.6791767648721763
Validation loss: 2.683929198375746

Epoch: 6| Step: 2
Training loss: 3.751040505060625
Validation loss: 2.6800916018999117

Epoch: 6| Step: 3
Training loss: 2.8550365449667545
Validation loss: 2.6790139908838366

Epoch: 6| Step: 4
Training loss: 2.9765379897182296
Validation loss: 2.6803830878534516

Epoch: 6| Step: 5
Training loss: 3.134060960518804
Validation loss: 2.6834580078032273

Epoch: 6| Step: 6
Training loss: 3.028402347677558
Validation loss: 2.683303017910939

Epoch: 6| Step: 7
Training loss: 3.173733622391141
Validation loss: 2.6819406737125804

Epoch: 6| Step: 8
Training loss: 2.452713172506254
Validation loss: 2.6792622426136576

Epoch: 6| Step: 9
Training loss: 2.3040303990756072
Validation loss: 2.6820890591247255

Epoch: 6| Step: 10
Training loss: 2.6262590023069863
Validation loss: 2.682955393324117

Epoch: 6| Step: 11
Training loss: 2.847392673094113
Validation loss: 2.6847955308176963

Epoch: 6| Step: 12
Training loss: 3.6761453673185605
Validation loss: 2.683060916961949

Epoch: 6| Step: 13
Training loss: 2.64651644641545
Validation loss: 2.6806480953103304

Epoch: 257| Step: 0
Training loss: 2.939181232234237
Validation loss: 2.6847931780078746

Epoch: 6| Step: 1
Training loss: 2.9788335511675577
Validation loss: 2.6770106393884436

Epoch: 6| Step: 2
Training loss: 2.720619172980152
Validation loss: 2.681045051067889

Epoch: 6| Step: 3
Training loss: 3.4809931607243594
Validation loss: 2.6831309301313393

Epoch: 6| Step: 4
Training loss: 3.489554622399185
Validation loss: 2.6788231924235113

Epoch: 6| Step: 5
Training loss: 3.3261559620967707
Validation loss: 2.685519933958829

Epoch: 6| Step: 6
Training loss: 3.0554051641579525
Validation loss: 2.6779990807183025

Epoch: 6| Step: 7
Training loss: 2.7315277970931806
Validation loss: 2.680085330753187

Epoch: 6| Step: 8
Training loss: 3.194914627486736
Validation loss: 2.6788692315067335

Epoch: 6| Step: 9
Training loss: 2.8339436565605127
Validation loss: 2.678640659500165

Epoch: 6| Step: 10
Training loss: 2.846677509915548
Validation loss: 2.6766089993595075

Epoch: 6| Step: 11
Training loss: 2.3946065221906845
Validation loss: 2.6786228421888167

Epoch: 6| Step: 12
Training loss: 3.113151365703449
Validation loss: 2.678749534752323

Epoch: 6| Step: 13
Training loss: 2.7302863369806243
Validation loss: 2.676945897599703

Epoch: 258| Step: 0
Training loss: 2.708149908652469
Validation loss: 2.6836031788074046

Epoch: 6| Step: 1
Training loss: 3.133749348503809
Validation loss: 2.689028036288262

Epoch: 6| Step: 2
Training loss: 2.754048575112129
Validation loss: 2.686101081469913

Epoch: 6| Step: 3
Training loss: 3.2191644790593266
Validation loss: 2.6923849872846626

Epoch: 6| Step: 4
Training loss: 3.3623944574405242
Validation loss: 2.6868069616779073

Epoch: 6| Step: 5
Training loss: 2.454346273830662
Validation loss: 2.688536843424677

Epoch: 6| Step: 6
Training loss: 2.916205633147259
Validation loss: 2.6807055121000984

Epoch: 6| Step: 7
Training loss: 3.289643804869311
Validation loss: 2.675834564331743

Epoch: 6| Step: 8
Training loss: 3.5536773923258744
Validation loss: 2.6780760003466595

Epoch: 6| Step: 9
Training loss: 2.7562974436995242
Validation loss: 2.677862452754502

Epoch: 6| Step: 10
Training loss: 3.260871018672011
Validation loss: 2.677915149340979

Epoch: 6| Step: 11
Training loss: 2.2486388009670106
Validation loss: 2.675373855187143

Epoch: 6| Step: 12
Training loss: 2.8314812908898372
Validation loss: 2.6796597557338115

Epoch: 6| Step: 13
Training loss: 3.6152957064033875
Validation loss: 2.6791744381402074

Epoch: 259| Step: 0
Training loss: 2.5962076148961537
Validation loss: 2.6769567451475256

Epoch: 6| Step: 1
Training loss: 3.0707463935819073
Validation loss: 2.675882215505949

Epoch: 6| Step: 2
Training loss: 2.4796248795234845
Validation loss: 2.6782049605968528

Epoch: 6| Step: 3
Training loss: 2.9162747982718713
Validation loss: 2.6761893175388294

Epoch: 6| Step: 4
Training loss: 2.6171459593251787
Validation loss: 2.674835113973047

Epoch: 6| Step: 5
Training loss: 3.1974377268318728
Validation loss: 2.6806389066736407

Epoch: 6| Step: 6
Training loss: 3.1425007395109947
Validation loss: 2.6798614404362295

Epoch: 6| Step: 7
Training loss: 3.090777886507794
Validation loss: 2.679793227895241

Epoch: 6| Step: 8
Training loss: 3.1646929830942674
Validation loss: 2.6791341198207195

Epoch: 6| Step: 9
Training loss: 3.42676880542017
Validation loss: 2.6794499021946363

Epoch: 6| Step: 10
Training loss: 4.011230914533223
Validation loss: 2.6814967655670543

Epoch: 6| Step: 11
Training loss: 3.074556557540078
Validation loss: 2.678036139345516

Epoch: 6| Step: 12
Training loss: 2.0492307196502786
Validation loss: 2.675340447982642

Epoch: 6| Step: 13
Training loss: 2.6487836133364198
Validation loss: 2.6777479670553097

Epoch: 260| Step: 0
Training loss: 3.301370024227099
Validation loss: 2.6751837098915425

Epoch: 6| Step: 1
Training loss: 2.346272243095567
Validation loss: 2.676761429885216

Epoch: 6| Step: 2
Training loss: 3.185603755814979
Validation loss: 2.670904881871759

Epoch: 6| Step: 3
Training loss: 2.9082175536915407
Validation loss: 2.67742405871361

Epoch: 6| Step: 4
Training loss: 2.8645785984809353
Validation loss: 2.6748482750933027

Epoch: 6| Step: 5
Training loss: 3.1964518187728603
Validation loss: 2.677851231679717

Epoch: 6| Step: 6
Training loss: 3.39009997262645
Validation loss: 2.6751221529717615

Epoch: 6| Step: 7
Training loss: 2.783728962798637
Validation loss: 2.676209494646179

Epoch: 6| Step: 8
Training loss: 3.683534332475786
Validation loss: 2.6737150773913885

Epoch: 6| Step: 9
Training loss: 2.6090798582266514
Validation loss: 2.6770752369250026

Epoch: 6| Step: 10
Training loss: 3.1908124280198082
Validation loss: 2.6773388932432685

Epoch: 6| Step: 11
Training loss: 3.3411855400423787
Validation loss: 2.6780537494805623

Epoch: 6| Step: 12
Training loss: 1.5630089503133902
Validation loss: 2.673588788708615

Epoch: 6| Step: 13
Training loss: 3.1533643164802845
Validation loss: 2.6765257494644192

Epoch: 261| Step: 0
Training loss: 3.2008670943417266
Validation loss: 2.673925979271322

Epoch: 6| Step: 1
Training loss: 2.3909895874460414
Validation loss: 2.6715488509431284

Epoch: 6| Step: 2
Training loss: 3.0840428197636527
Validation loss: 2.6794774898100964

Epoch: 6| Step: 3
Training loss: 3.5495194983016
Validation loss: 2.6751820007548885

Epoch: 6| Step: 4
Training loss: 3.101964813967477
Validation loss: 2.676590731287961

Epoch: 6| Step: 5
Training loss: 2.9933531559866235
Validation loss: 2.6759832749203007

Epoch: 6| Step: 6
Training loss: 3.1015488170254697
Validation loss: 2.6747559062771322

Epoch: 6| Step: 7
Training loss: 2.8767833983369804
Validation loss: 2.669568704131702

Epoch: 6| Step: 8
Training loss: 3.027475425563778
Validation loss: 2.675211258608825

Epoch: 6| Step: 9
Training loss: 2.9647031808532747
Validation loss: 2.6734857219145542

Epoch: 6| Step: 10
Training loss: 2.613374215198767
Validation loss: 2.6714938648177204

Epoch: 6| Step: 11
Training loss: 3.4818995967195465
Validation loss: 2.6700474211404606

Epoch: 6| Step: 12
Training loss: 2.675059244801094
Validation loss: 2.6712253828848853

Epoch: 6| Step: 13
Training loss: 2.664401483084245
Validation loss: 2.669484820768786

Epoch: 262| Step: 0
Training loss: 3.074615801868839
Validation loss: 2.67423617230061

Epoch: 6| Step: 1
Training loss: 3.613082236918006
Validation loss: 2.6745614070337456

Epoch: 6| Step: 2
Training loss: 3.201883214894974
Validation loss: 2.671818310737642

Epoch: 6| Step: 3
Training loss: 3.0961251437501227
Validation loss: 2.675172222191468

Epoch: 6| Step: 4
Training loss: 2.1113891028139378
Validation loss: 2.6706997120874227

Epoch: 6| Step: 5
Training loss: 2.282104018793621
Validation loss: 2.672884766784571

Epoch: 6| Step: 6
Training loss: 2.3203850423345567
Validation loss: 2.6704673894834072

Epoch: 6| Step: 7
Training loss: 2.99846228290631
Validation loss: 2.674590868172453

Epoch: 6| Step: 8
Training loss: 2.9862479678786187
Validation loss: 2.6738852318616964

Epoch: 6| Step: 9
Training loss: 2.9330186140404253
Validation loss: 2.671950688393793

Epoch: 6| Step: 10
Training loss: 2.8601166644010125
Validation loss: 2.677738478377634

Epoch: 6| Step: 11
Training loss: 3.261329856120034
Validation loss: 2.687821656361962

Epoch: 6| Step: 12
Training loss: 3.6323428270817373
Validation loss: 2.6808041070125976

Epoch: 6| Step: 13
Training loss: 3.4623517662295367
Validation loss: 2.671720723748244

Epoch: 263| Step: 0
Training loss: 2.7292795716050176
Validation loss: 2.6714505583689028

Epoch: 6| Step: 1
Training loss: 3.4471604976888113
Validation loss: 2.6735987475781924

Epoch: 6| Step: 2
Training loss: 3.219050865555967
Validation loss: 2.672410602446309

Epoch: 6| Step: 3
Training loss: 3.1138237034280336
Validation loss: 2.6706681125088685

Epoch: 6| Step: 4
Training loss: 2.801712115537717
Validation loss: 2.672214609528302

Epoch: 6| Step: 5
Training loss: 3.2121745972643745
Validation loss: 2.672195569817522

Epoch: 6| Step: 6
Training loss: 2.9333027823620075
Validation loss: 2.674533515655376

Epoch: 6| Step: 7
Training loss: 3.144068713555975
Validation loss: 2.6729093414685314

Epoch: 6| Step: 8
Training loss: 3.218035424179164
Validation loss: 2.673367662714447

Epoch: 6| Step: 9
Training loss: 3.051351847997992
Validation loss: 2.671989653863772

Epoch: 6| Step: 10
Training loss: 3.0084899932000058
Validation loss: 2.672536604349821

Epoch: 6| Step: 11
Training loss: 2.8737873339457582
Validation loss: 2.670873667701163

Epoch: 6| Step: 12
Training loss: 2.2097842170697892
Validation loss: 2.67675994443056

Epoch: 6| Step: 13
Training loss: 2.926221582665006
Validation loss: 2.677476060177623

Epoch: 264| Step: 0
Training loss: 2.134274383452105
Validation loss: 2.6743423917881137

Epoch: 6| Step: 1
Training loss: 3.2808160404069002
Validation loss: 2.6727553637554666

Epoch: 6| Step: 2
Training loss: 3.5761481408790514
Validation loss: 2.682789756882088

Epoch: 6| Step: 3
Training loss: 3.026505365260757
Validation loss: 2.6778419147341856

Epoch: 6| Step: 4
Training loss: 3.140904959731264
Validation loss: 2.682199909103473

Epoch: 6| Step: 5
Training loss: 2.6167406298476092
Validation loss: 2.677401725828624

Epoch: 6| Step: 6
Training loss: 3.923492219787172
Validation loss: 2.676111447019535

Epoch: 6| Step: 7
Training loss: 2.8472811395602142
Validation loss: 2.6736935160739908

Epoch: 6| Step: 8
Training loss: 2.4447622441809163
Validation loss: 2.671682020154303

Epoch: 6| Step: 9
Training loss: 2.2444907663095495
Validation loss: 2.6714135945580435

Epoch: 6| Step: 10
Training loss: 2.9742153254880797
Validation loss: 2.6732883060507273

Epoch: 6| Step: 11
Training loss: 3.1653049619774927
Validation loss: 2.6744214276840816

Epoch: 6| Step: 12
Training loss: 3.1502033894589245
Validation loss: 2.675717145311941

Epoch: 6| Step: 13
Training loss: 3.0388032856595943
Validation loss: 2.6731142956227645

Epoch: 265| Step: 0
Training loss: 3.0205376491312497
Validation loss: 2.673825323413095

Epoch: 6| Step: 1
Training loss: 3.3106955165745457
Validation loss: 2.6687205289065656

Epoch: 6| Step: 2
Training loss: 4.008059488460359
Validation loss: 2.6688456061225785

Epoch: 6| Step: 3
Training loss: 2.909288028519305
Validation loss: 2.6701394612596596

Epoch: 6| Step: 4
Training loss: 2.6324578564232946
Validation loss: 2.669025005763006

Epoch: 6| Step: 5
Training loss: 3.4900384558714985
Validation loss: 2.672509096649054

Epoch: 6| Step: 6
Training loss: 2.4155485153427088
Validation loss: 2.6762310711367405

Epoch: 6| Step: 7
Training loss: 3.025120466371475
Validation loss: 2.6732950342738016

Epoch: 6| Step: 8
Training loss: 2.8120310922317304
Validation loss: 2.6752856059078147

Epoch: 6| Step: 9
Training loss: 2.894596979421973
Validation loss: 2.67450386888512

Epoch: 6| Step: 10
Training loss: 2.7459629076503655
Validation loss: 2.682228310483216

Epoch: 6| Step: 11
Training loss: 2.573215688608815
Validation loss: 2.6873094491639993

Epoch: 6| Step: 12
Training loss: 3.0824704552291884
Validation loss: 2.690305605191232

Epoch: 6| Step: 13
Training loss: 2.565902126274237
Validation loss: 2.687558586777431

Epoch: 266| Step: 0
Training loss: 3.128862664041771
Validation loss: 2.6831811828778083

Epoch: 6| Step: 1
Training loss: 2.634875929370772
Validation loss: 2.686167366306997

Epoch: 6| Step: 2
Training loss: 3.1717073743903623
Validation loss: 2.679042375321526

Epoch: 6| Step: 3
Training loss: 2.840604278858177
Validation loss: 2.677669170087746

Epoch: 6| Step: 4
Training loss: 3.1290872928662368
Validation loss: 2.682209075188224

Epoch: 6| Step: 5
Training loss: 3.3168775315721626
Validation loss: 2.670029390460681

Epoch: 6| Step: 6
Training loss: 3.174257182537148
Validation loss: 2.6639025293140906

Epoch: 6| Step: 7
Training loss: 2.8642761250693147
Validation loss: 2.6715643428157194

Epoch: 6| Step: 8
Training loss: 2.9298574169475513
Validation loss: 2.666115362209995

Epoch: 6| Step: 9
Training loss: 3.315230198112869
Validation loss: 2.668474195902668

Epoch: 6| Step: 10
Training loss: 2.5459344917673845
Validation loss: 2.67060880097475

Epoch: 6| Step: 11
Training loss: 3.248649756839716
Validation loss: 2.6718770264447134

Epoch: 6| Step: 12
Training loss: 2.7367562524750766
Validation loss: 2.671143790654342

Epoch: 6| Step: 13
Training loss: 2.858947221619073
Validation loss: 2.667183244056386

Epoch: 267| Step: 0
Training loss: 2.984392735293752
Validation loss: 2.6705339346851122

Epoch: 6| Step: 1
Training loss: 3.0234539021680416
Validation loss: 2.663415409878828

Epoch: 6| Step: 2
Training loss: 3.0883161817370492
Validation loss: 2.668168370608417

Epoch: 6| Step: 3
Training loss: 2.6753421172507896
Validation loss: 2.666130170254953

Epoch: 6| Step: 4
Training loss: 2.6414342238471757
Validation loss: 2.6658879291541124

Epoch: 6| Step: 5
Training loss: 2.215897136380332
Validation loss: 2.6730923506330164

Epoch: 6| Step: 6
Training loss: 2.7940364477446753
Validation loss: 2.679947185797957

Epoch: 6| Step: 7
Training loss: 3.5390301633456462
Validation loss: 2.6713474100366263

Epoch: 6| Step: 8
Training loss: 2.987278828753723
Validation loss: 2.6856438288186757

Epoch: 6| Step: 9
Training loss: 3.6868945125743138
Validation loss: 2.684587954258632

Epoch: 6| Step: 10
Training loss: 2.7335263924532582
Validation loss: 2.687386199609854

Epoch: 6| Step: 11
Training loss: 3.074494520370159
Validation loss: 2.6907109040503907

Epoch: 6| Step: 12
Training loss: 2.510932953693331
Validation loss: 2.703763785903283

Epoch: 6| Step: 13
Training loss: 4.034081462697632
Validation loss: 2.7222518555841515

Epoch: 268| Step: 0
Training loss: 3.0300839727870765
Validation loss: 2.7216024186754675

Epoch: 6| Step: 1
Training loss: 3.27933642583356
Validation loss: 2.7092844830280236

Epoch: 6| Step: 2
Training loss: 3.518837507931641
Validation loss: 2.7016310069065783

Epoch: 6| Step: 3
Training loss: 3.0307129059651605
Validation loss: 2.707449137484405

Epoch: 6| Step: 4
Training loss: 2.7900423951841753
Validation loss: 2.685184365425115

Epoch: 6| Step: 5
Training loss: 2.985084329560866
Validation loss: 2.6948435718623975

Epoch: 6| Step: 6
Training loss: 2.8542197192382504
Validation loss: 2.6726967853254724

Epoch: 6| Step: 7
Training loss: 3.6966986284402084
Validation loss: 2.6726665205952

Epoch: 6| Step: 8
Training loss: 2.2713149606991543
Validation loss: 2.6714234761274325

Epoch: 6| Step: 9
Training loss: 2.73619516010145
Validation loss: 2.665170434058832

Epoch: 6| Step: 10
Training loss: 2.532866162173477
Validation loss: 2.663979139026083

Epoch: 6| Step: 11
Training loss: 3.119569561439082
Validation loss: 2.662445708460839

Epoch: 6| Step: 12
Training loss: 3.1568512296716325
Validation loss: 2.6595312709507564

Epoch: 6| Step: 13
Training loss: 2.316433113547066
Validation loss: 2.66004652650791

Epoch: 269| Step: 0
Training loss: 2.9803589966890747
Validation loss: 2.659944715111179

Epoch: 6| Step: 1
Training loss: 3.3976424065415554
Validation loss: 2.6582319235735996

Epoch: 6| Step: 2
Training loss: 3.3306005879096463
Validation loss: 2.660417131107568

Epoch: 6| Step: 3
Training loss: 3.3953113427754875
Validation loss: 2.6624971435876645

Epoch: 6| Step: 4
Training loss: 2.595495624730349
Validation loss: 2.6621305707879293

Epoch: 6| Step: 5
Training loss: 2.740661022336668
Validation loss: 2.657467578847647

Epoch: 6| Step: 6
Training loss: 2.991727549607267
Validation loss: 2.6599768420499035

Epoch: 6| Step: 7
Training loss: 3.3945872979316363
Validation loss: 2.6611148919349494

Epoch: 6| Step: 8
Training loss: 3.2685573134512906
Validation loss: 2.663149294074049

Epoch: 6| Step: 9
Training loss: 2.851483738477781
Validation loss: 2.6601085243258327

Epoch: 6| Step: 10
Training loss: 2.741911958506674
Validation loss: 2.658956791464222

Epoch: 6| Step: 11
Training loss: 2.5311737049048717
Validation loss: 2.663493867184786

Epoch: 6| Step: 12
Training loss: 2.7516502284069806
Validation loss: 2.657594397270604

Epoch: 6| Step: 13
Training loss: 2.5249946443104365
Validation loss: 2.659812910991959

Epoch: 270| Step: 0
Training loss: 3.718033921996569
Validation loss: 2.6629230835393582

Epoch: 6| Step: 1
Training loss: 3.248530422421115
Validation loss: 2.6653114773354263

Epoch: 6| Step: 2
Training loss: 2.9157345145081774
Validation loss: 2.669493312172922

Epoch: 6| Step: 3
Training loss: 2.7797323651094477
Validation loss: 2.658315663435372

Epoch: 6| Step: 4
Training loss: 3.1538149060961174
Validation loss: 2.6591885019955352

Epoch: 6| Step: 5
Training loss: 3.036980315284379
Validation loss: 2.662473933486943

Epoch: 6| Step: 6
Training loss: 2.901433748132086
Validation loss: 2.6575082422800707

Epoch: 6| Step: 7
Training loss: 2.7237420564547037
Validation loss: 2.6573698507456163

Epoch: 6| Step: 8
Training loss: 2.825156155211702
Validation loss: 2.6593205597512317

Epoch: 6| Step: 9
Training loss: 2.8927746177353106
Validation loss: 2.6687637355645304

Epoch: 6| Step: 10
Training loss: 2.572065966945224
Validation loss: 2.6745797474358786

Epoch: 6| Step: 11
Training loss: 2.816124255153719
Validation loss: 2.678482708513983

Epoch: 6| Step: 12
Training loss: 3.5050679708248937
Validation loss: 2.6806847672970653

Epoch: 6| Step: 13
Training loss: 2.2841222787649933
Validation loss: 2.67926469883552

Epoch: 271| Step: 0
Training loss: 3.2336740517443627
Validation loss: 2.6832550638037374

Epoch: 6| Step: 1
Training loss: 3.1262601219114052
Validation loss: 2.689085533462586

Epoch: 6| Step: 2
Training loss: 2.4583807364166206
Validation loss: 2.67634691583102

Epoch: 6| Step: 3
Training loss: 2.5197859761012333
Validation loss: 2.673782392226217

Epoch: 6| Step: 4
Training loss: 2.6956185429736963
Validation loss: 2.6741230441562243

Epoch: 6| Step: 5
Training loss: 3.314564763146407
Validation loss: 2.667542593158542

Epoch: 6| Step: 6
Training loss: 3.380788995196462
Validation loss: 2.6586426586750216

Epoch: 6| Step: 7
Training loss: 2.98667459617425
Validation loss: 2.654475113866914

Epoch: 6| Step: 8
Training loss: 3.1171168269126635
Validation loss: 2.65775545275839

Epoch: 6| Step: 9
Training loss: 2.663561642457134
Validation loss: 2.656155268350984

Epoch: 6| Step: 10
Training loss: 2.9097229910287825
Validation loss: 2.6582561245113334

Epoch: 6| Step: 11
Training loss: 3.0426821298242537
Validation loss: 2.6568231040390495

Epoch: 6| Step: 12
Training loss: 3.3629642208667754
Validation loss: 2.6583040502818287

Epoch: 6| Step: 13
Training loss: 2.934284316866631
Validation loss: 2.6570536546840495

Epoch: 272| Step: 0
Training loss: 2.9437311516095592
Validation loss: 2.6545054710757254

Epoch: 6| Step: 1
Training loss: 2.9534606742817497
Validation loss: 2.657090254800841

Epoch: 6| Step: 2
Training loss: 3.1245962263561013
Validation loss: 2.6577734847166785

Epoch: 6| Step: 3
Training loss: 3.3747915980669534
Validation loss: 2.657434057480405

Epoch: 6| Step: 4
Training loss: 3.0241151193272797
Validation loss: 2.658855969058588

Epoch: 6| Step: 5
Training loss: 2.9973237498233125
Validation loss: 2.6547544579748563

Epoch: 6| Step: 6
Training loss: 2.5740951948369197
Validation loss: 2.658536020208376

Epoch: 6| Step: 7
Training loss: 3.399252747716605
Validation loss: 2.6561281093013953

Epoch: 6| Step: 8
Training loss: 3.040870109315509
Validation loss: 2.657035824318516

Epoch: 6| Step: 9
Training loss: 2.6186839821444368
Validation loss: 2.65869864823255

Epoch: 6| Step: 10
Training loss: 2.6049601045507913
Validation loss: 2.658138056299366

Epoch: 6| Step: 11
Training loss: 2.539784959566188
Validation loss: 2.6584615574313286

Epoch: 6| Step: 12
Training loss: 3.280526508314318
Validation loss: 2.656971649449817

Epoch: 6| Step: 13
Training loss: 3.4837087498889363
Validation loss: 2.6635095974463425

Epoch: 273| Step: 0
Training loss: 2.6119532838998847
Validation loss: 2.661238711115506

Epoch: 6| Step: 1
Training loss: 3.67930727409548
Validation loss: 2.660706980031418

Epoch: 6| Step: 2
Training loss: 2.816859363608152
Validation loss: 2.6591581259426773

Epoch: 6| Step: 3
Training loss: 2.9768264933784248
Validation loss: 2.6620234865146206

Epoch: 6| Step: 4
Training loss: 2.550391642096596
Validation loss: 2.6701740424535707

Epoch: 6| Step: 5
Training loss: 3.3672197875844683
Validation loss: 2.673417344778528

Epoch: 6| Step: 6
Training loss: 3.0809622918495494
Validation loss: 2.659337884114639

Epoch: 6| Step: 7
Training loss: 2.9398354519319674
Validation loss: 2.6670295951608742

Epoch: 6| Step: 8
Training loss: 2.667973218162895
Validation loss: 2.6662992184521457

Epoch: 6| Step: 9
Training loss: 2.4181994696316425
Validation loss: 2.664869959376137

Epoch: 6| Step: 10
Training loss: 3.2263162809921653
Validation loss: 2.6694574948205623

Epoch: 6| Step: 11
Training loss: 3.2997643704532442
Validation loss: 2.6716594665482316

Epoch: 6| Step: 12
Training loss: 2.9567637152443624
Validation loss: 2.662094637038721

Epoch: 6| Step: 13
Training loss: 2.9999213208371613
Validation loss: 2.6673643201965267

Epoch: 274| Step: 0
Training loss: 2.6047910526700733
Validation loss: 2.6683800557943784

Epoch: 6| Step: 1
Training loss: 3.177188425462606
Validation loss: 2.6745932807584847

Epoch: 6| Step: 2
Training loss: 3.7886446692947837
Validation loss: 2.6738071878128946

Epoch: 6| Step: 3
Training loss: 2.867484344998423
Validation loss: 2.659503630661515

Epoch: 6| Step: 4
Training loss: 2.7601490874727954
Validation loss: 2.6593895625089794

Epoch: 6| Step: 5
Training loss: 3.1095038152494334
Validation loss: 2.659931356883007

Epoch: 6| Step: 6
Training loss: 2.28134196892952
Validation loss: 2.660075228988385

Epoch: 6| Step: 7
Training loss: 3.027991834611856
Validation loss: 2.6640587008171934

Epoch: 6| Step: 8
Training loss: 3.0035079473724053
Validation loss: 2.6626256105560118

Epoch: 6| Step: 9
Training loss: 3.4353678246228747
Validation loss: 2.6617314034222823

Epoch: 6| Step: 10
Training loss: 2.9524716254929224
Validation loss: 2.6589105126912385

Epoch: 6| Step: 11
Training loss: 3.4180496642208227
Validation loss: 2.6579924338976193

Epoch: 6| Step: 12
Training loss: 2.33280985500546
Validation loss: 2.6561367312366655

Epoch: 6| Step: 13
Training loss: 2.524226298626422
Validation loss: 2.65484355292158

Epoch: 275| Step: 0
Training loss: 2.381126933284345
Validation loss: 2.6551854528460725

Epoch: 6| Step: 1
Training loss: 3.4719119395326175
Validation loss: 2.655513988156445

Epoch: 6| Step: 2
Training loss: 3.738631117501627
Validation loss: 2.6590675867031908

Epoch: 6| Step: 3
Training loss: 3.2904739794442097
Validation loss: 2.6582600101040255

Epoch: 6| Step: 4
Training loss: 2.4753615298313782
Validation loss: 2.656509889535657

Epoch: 6| Step: 5
Training loss: 2.7504735018825586
Validation loss: 2.6533155549222034

Epoch: 6| Step: 6
Training loss: 2.7602032464974564
Validation loss: 2.651161538463001

Epoch: 6| Step: 7
Training loss: 3.265962720136108
Validation loss: 2.6589196173290057

Epoch: 6| Step: 8
Training loss: 2.680908903464558
Validation loss: 2.6609268641945603

Epoch: 6| Step: 9
Training loss: 3.3597282756197018
Validation loss: 2.654809923100284

Epoch: 6| Step: 10
Training loss: 2.7554151797515334
Validation loss: 2.657289924675198

Epoch: 6| Step: 11
Training loss: 2.6426996511863803
Validation loss: 2.6559868119379773

Epoch: 6| Step: 12
Training loss: 3.0434004314612073
Validation loss: 2.6613708992894716

Epoch: 6| Step: 13
Training loss: 2.806212114447946
Validation loss: 2.6582637963574127

Epoch: 276| Step: 0
Training loss: 2.8650694463545
Validation loss: 2.6505234131954354

Epoch: 6| Step: 1
Training loss: 2.563254826719665
Validation loss: 2.66324736744403

Epoch: 6| Step: 2
Training loss: 3.2391705183538355
Validation loss: 2.6550262073823716

Epoch: 6| Step: 3
Training loss: 2.9566246972730412
Validation loss: 2.659642534813183

Epoch: 6| Step: 4
Training loss: 2.9719991471506284
Validation loss: 2.658554949455952

Epoch: 6| Step: 5
Training loss: 2.774052769286242
Validation loss: 2.6637955335965375

Epoch: 6| Step: 6
Training loss: 3.078177669481178
Validation loss: 2.6573595175177345

Epoch: 6| Step: 7
Training loss: 3.387577779517435
Validation loss: 2.659818128266111

Epoch: 6| Step: 8
Training loss: 3.14742745604477
Validation loss: 2.663683386446572

Epoch: 6| Step: 9
Training loss: 2.543338309300239
Validation loss: 2.6541831655078543

Epoch: 6| Step: 10
Training loss: 3.1281810591606747
Validation loss: 2.6579514132851516

Epoch: 6| Step: 11
Training loss: 2.7547860546084224
Validation loss: 2.65458530328612

Epoch: 6| Step: 12
Training loss: 3.288431066216578
Validation loss: 2.6591551189760794

Epoch: 6| Step: 13
Training loss: 3.0086830365629997
Validation loss: 2.6552607837545317

Epoch: 277| Step: 0
Training loss: 2.3934364491973534
Validation loss: 2.652466123887931

Epoch: 6| Step: 1
Training loss: 2.9968502676125244
Validation loss: 2.651779532104124

Epoch: 6| Step: 2
Training loss: 3.42643371423509
Validation loss: 2.6534029416857656

Epoch: 6| Step: 3
Training loss: 2.6937022831135717
Validation loss: 2.6518037725927153

Epoch: 6| Step: 4
Training loss: 3.5209413470491597
Validation loss: 2.6540538841988224

Epoch: 6| Step: 5
Training loss: 2.6260809716250657
Validation loss: 2.652307882771278

Epoch: 6| Step: 6
Training loss: 2.9029436890452383
Validation loss: 2.6572696096968778

Epoch: 6| Step: 7
Training loss: 2.6563887615984565
Validation loss: 2.6477486077488064

Epoch: 6| Step: 8
Training loss: 2.6691263795548164
Validation loss: 2.6542028656630783

Epoch: 6| Step: 9
Training loss: 3.0998382772284594
Validation loss: 2.647006466512825

Epoch: 6| Step: 10
Training loss: 2.5300699945047973
Validation loss: 2.6505432459780094

Epoch: 6| Step: 11
Training loss: 3.4265169334599945
Validation loss: 2.6509708580674074

Epoch: 6| Step: 12
Training loss: 3.6252180888901844
Validation loss: 2.648319480967825

Epoch: 6| Step: 13
Training loss: 2.915547910204739
Validation loss: 2.652634999106381

Epoch: 278| Step: 0
Training loss: 3.0289932187326563
Validation loss: 2.6561716337183334

Epoch: 6| Step: 1
Training loss: 2.5719763289707562
Validation loss: 2.6524517382826454

Epoch: 6| Step: 2
Training loss: 2.9902771112638438
Validation loss: 2.6508450138522646

Epoch: 6| Step: 3
Training loss: 2.215277304760581
Validation loss: 2.650536132114764

Epoch: 6| Step: 4
Training loss: 3.454688637335153
Validation loss: 2.6531481617887245

Epoch: 6| Step: 5
Training loss: 2.6525893174934323
Validation loss: 2.6568237823827205

Epoch: 6| Step: 6
Training loss: 2.8991908819143646
Validation loss: 2.6577580581109466

Epoch: 6| Step: 7
Training loss: 2.8423904690403132
Validation loss: 2.6626073274226374

Epoch: 6| Step: 8
Training loss: 3.386603999146297
Validation loss: 2.6546059352867677

Epoch: 6| Step: 9
Training loss: 2.9814528294308285
Validation loss: 2.6476936327792417

Epoch: 6| Step: 10
Training loss: 3.593982191463073
Validation loss: 2.656982704943501

Epoch: 6| Step: 11
Training loss: 2.8300545364355116
Validation loss: 2.652370478057892

Epoch: 6| Step: 12
Training loss: 3.1608997502997958
Validation loss: 2.649709734940435

Epoch: 6| Step: 13
Training loss: 2.7982143839247415
Validation loss: 2.653736582989579

Epoch: 279| Step: 0
Training loss: 2.796611240672811
Validation loss: 2.65331334424952

Epoch: 6| Step: 1
Training loss: 3.3465780972416437
Validation loss: 2.651570768956951

Epoch: 6| Step: 2
Training loss: 2.8816807290464563
Validation loss: 2.648478032980865

Epoch: 6| Step: 3
Training loss: 3.3447687611389108
Validation loss: 2.6489452035508605

Epoch: 6| Step: 4
Training loss: 2.843492098002273
Validation loss: 2.6479025960721234

Epoch: 6| Step: 5
Training loss: 3.4557269895767604
Validation loss: 2.648086583166327

Epoch: 6| Step: 6
Training loss: 2.916022002410558
Validation loss: 2.6529432625003078

Epoch: 6| Step: 7
Training loss: 2.908391676119919
Validation loss: 2.649560832710271

Epoch: 6| Step: 8
Training loss: 2.7450454469125343
Validation loss: 2.645199267978644

Epoch: 6| Step: 9
Training loss: 2.636920384362098
Validation loss: 2.650121159182015

Epoch: 6| Step: 10
Training loss: 2.643681038752948
Validation loss: 2.64514358582363

Epoch: 6| Step: 11
Training loss: 3.129790030069784
Validation loss: 2.646734996931924

Epoch: 6| Step: 12
Training loss: 3.560266028547693
Validation loss: 2.647855565447343

Epoch: 6| Step: 13
Training loss: 1.4673702170903926
Validation loss: 2.6474946994049247

Epoch: 280| Step: 0
Training loss: 3.058016394911154
Validation loss: 2.6472678610208686

Epoch: 6| Step: 1
Training loss: 3.345785644368743
Validation loss: 2.6591332072553193

Epoch: 6| Step: 2
Training loss: 3.2692176732279985
Validation loss: 2.6488354831254997

Epoch: 6| Step: 3
Training loss: 2.8689830677042063
Validation loss: 2.648707810751816

Epoch: 6| Step: 4
Training loss: 2.2924373602343304
Validation loss: 2.644840173903674

Epoch: 6| Step: 5
Training loss: 3.2973872505445447
Validation loss: 2.648550195910115

Epoch: 6| Step: 6
Training loss: 3.239341571450643
Validation loss: 2.64348395927147

Epoch: 6| Step: 7
Training loss: 2.684569424392814
Validation loss: 2.645560274639757

Epoch: 6| Step: 8
Training loss: 2.772087692822285
Validation loss: 2.645181379997284

Epoch: 6| Step: 9
Training loss: 3.3857272587643186
Validation loss: 2.644956303053776

Epoch: 6| Step: 10
Training loss: 2.6113865574053308
Validation loss: 2.6410598925875033

Epoch: 6| Step: 11
Training loss: 2.371387746265812
Validation loss: 2.647780266879928

Epoch: 6| Step: 12
Training loss: 3.331646699169703
Validation loss: 2.64965628583008

Epoch: 6| Step: 13
Training loss: 2.8636371136398764
Validation loss: 2.6443708491150226

Epoch: 281| Step: 0
Training loss: 3.4772805833189464
Validation loss: 2.648428609067606

Epoch: 6| Step: 1
Training loss: 3.183396634043372
Validation loss: 2.653036506707878

Epoch: 6| Step: 2
Training loss: 2.228210053820176
Validation loss: 2.6506827753953583

Epoch: 6| Step: 3
Training loss: 2.8462211854704993
Validation loss: 2.6591950798287383

Epoch: 6| Step: 4
Training loss: 3.143369320218128
Validation loss: 2.6532811028090935

Epoch: 6| Step: 5
Training loss: 2.8384877237683095
Validation loss: 2.6563844669672583

Epoch: 6| Step: 6
Training loss: 2.7948197640053905
Validation loss: 2.659695663718665

Epoch: 6| Step: 7
Training loss: 3.0587616505340574
Validation loss: 2.6679702105615974

Epoch: 6| Step: 8
Training loss: 3.089729856762328
Validation loss: 2.681825387060739

Epoch: 6| Step: 9
Training loss: 2.2616994590134234
Validation loss: 2.6823487303307196

Epoch: 6| Step: 10
Training loss: 3.175100105689952
Validation loss: 2.6930455834666827

Epoch: 6| Step: 11
Training loss: 3.0667449181013073
Validation loss: 2.685381244701479

Epoch: 6| Step: 12
Training loss: 3.2966241967140193
Validation loss: 2.6712363707489035

Epoch: 6| Step: 13
Training loss: 3.068239089482678
Validation loss: 2.656295084947697

Epoch: 282| Step: 0
Training loss: 2.4581897715229033
Validation loss: 2.651324880863703

Epoch: 6| Step: 1
Training loss: 3.590510757793528
Validation loss: 2.6463124955034676

Epoch: 6| Step: 2
Training loss: 2.8560842119511873
Validation loss: 2.6443524087443886

Epoch: 6| Step: 3
Training loss: 3.0960425927832653
Validation loss: 2.6425068748841753

Epoch: 6| Step: 4
Training loss: 3.231595674246183
Validation loss: 2.643235801996793

Epoch: 6| Step: 5
Training loss: 2.3823184642499418
Validation loss: 2.6443973358973327

Epoch: 6| Step: 6
Training loss: 3.1058400058154367
Validation loss: 2.63748648431586

Epoch: 6| Step: 7
Training loss: 2.519046139405472
Validation loss: 2.6477108502204882

Epoch: 6| Step: 8
Training loss: 3.4174133198258225
Validation loss: 2.645940145930536

Epoch: 6| Step: 9
Training loss: 2.344979129202229
Validation loss: 2.646550362764065

Epoch: 6| Step: 10
Training loss: 2.971374957418407
Validation loss: 2.655988937375647

Epoch: 6| Step: 11
Training loss: 3.3794287834311163
Validation loss: 2.6655398713358474

Epoch: 6| Step: 12
Training loss: 2.914008500567875
Validation loss: 2.6672922068539315

Epoch: 6| Step: 13
Training loss: 3.1920325272893817
Validation loss: 2.6621557647621366

Epoch: 283| Step: 0
Training loss: 3.049652711451162
Validation loss: 2.6612968857411747

Epoch: 6| Step: 1
Training loss: 2.917765128960575
Validation loss: 2.651994308032931

Epoch: 6| Step: 2
Training loss: 2.755995024567253
Validation loss: 2.660494181331929

Epoch: 6| Step: 3
Training loss: 3.273498680253154
Validation loss: 2.6509958322037153

Epoch: 6| Step: 4
Training loss: 3.0285793219512325
Validation loss: 2.648918507709992

Epoch: 6| Step: 5
Training loss: 2.8528080140562344
Validation loss: 2.6419972830030574

Epoch: 6| Step: 6
Training loss: 3.310242945580377
Validation loss: 2.6384337920276435

Epoch: 6| Step: 7
Training loss: 2.9747244699294537
Validation loss: 2.638803713045836

Epoch: 6| Step: 8
Training loss: 2.9876689208728453
Validation loss: 2.6448286935027463

Epoch: 6| Step: 9
Training loss: 2.4173408642122203
Validation loss: 2.641498413219254

Epoch: 6| Step: 10
Training loss: 3.027604575457639
Validation loss: 2.6437078757251227

Epoch: 6| Step: 11
Training loss: 2.9302204918815375
Validation loss: 2.6460090383786827

Epoch: 6| Step: 12
Training loss: 3.2803363799688396
Validation loss: 2.649544405223458

Epoch: 6| Step: 13
Training loss: 2.679054919612247
Validation loss: 2.6423737342812554

Epoch: 284| Step: 0
Training loss: 2.9962659485431886
Validation loss: 2.6425417197031233

Epoch: 6| Step: 1
Training loss: 3.22457994786126
Validation loss: 2.6444961967949743

Epoch: 6| Step: 2
Training loss: 2.655694342444311
Validation loss: 2.643552198098649

Epoch: 6| Step: 3
Training loss: 2.447098637247277
Validation loss: 2.645374222089095

Epoch: 6| Step: 4
Training loss: 2.7303098269424724
Validation loss: 2.64242078679883

Epoch: 6| Step: 5
Training loss: 2.703601243948393
Validation loss: 2.6387863617089184

Epoch: 6| Step: 6
Training loss: 3.155088758716372
Validation loss: 2.643826538908091

Epoch: 6| Step: 7
Training loss: 2.8766527815476683
Validation loss: 2.6393599222752466

Epoch: 6| Step: 8
Training loss: 3.144745965107292
Validation loss: 2.6417341665495626

Epoch: 6| Step: 9
Training loss: 3.2893246072819133
Validation loss: 2.639068783765018

Epoch: 6| Step: 10
Training loss: 3.3759231717646827
Validation loss: 2.6488097491860345

Epoch: 6| Step: 11
Training loss: 2.851577215287374
Validation loss: 2.640823227694948

Epoch: 6| Step: 12
Training loss: 2.8403897396820414
Validation loss: 2.6426062100739323

Epoch: 6| Step: 13
Training loss: 3.3977249275401236
Validation loss: 2.6404056126635767

Epoch: 285| Step: 0
Training loss: 2.66818231981712
Validation loss: 2.640113385384559

Epoch: 6| Step: 1
Training loss: 2.7061672841176887
Validation loss: 2.6394283172593975

Epoch: 6| Step: 2
Training loss: 2.910059247544412
Validation loss: 2.64375534571017

Epoch: 6| Step: 3
Training loss: 3.132993621537199
Validation loss: 2.6453662424812747

Epoch: 6| Step: 4
Training loss: 2.6986132769385907
Validation loss: 2.644270205454292

Epoch: 6| Step: 5
Training loss: 3.1337951488917213
Validation loss: 2.6390948021138865

Epoch: 6| Step: 6
Training loss: 3.0662578959932922
Validation loss: 2.642494977849514

Epoch: 6| Step: 7
Training loss: 3.2037486888035933
Validation loss: 2.6375089617531593

Epoch: 6| Step: 8
Training loss: 2.5698308522412248
Validation loss: 2.6385900261995805

Epoch: 6| Step: 9
Training loss: 3.7064739809336165
Validation loss: 2.6410377812318857

Epoch: 6| Step: 10
Training loss: 2.8355097172193418
Validation loss: 2.6413263393291966

Epoch: 6| Step: 11
Training loss: 2.8303392709698154
Validation loss: 2.6401524430080316

Epoch: 6| Step: 12
Training loss: 2.789824395071215
Validation loss: 2.638287841907577

Epoch: 6| Step: 13
Training loss: 3.4031867856248446
Validation loss: 2.6442202423664076

Epoch: 286| Step: 0
Training loss: 2.947914653727964
Validation loss: 2.643379399598668

Epoch: 6| Step: 1
Training loss: 3.2110613499723315
Validation loss: 2.642564794429187

Epoch: 6| Step: 2
Training loss: 2.7765289699610043
Validation loss: 2.642398287110895

Epoch: 6| Step: 3
Training loss: 2.5317014126865884
Validation loss: 2.6352808353650636

Epoch: 6| Step: 4
Training loss: 3.0717173849283554
Validation loss: 2.637004511276873

Epoch: 6| Step: 5
Training loss: 2.91046673443344
Validation loss: 2.63967476965881

Epoch: 6| Step: 6
Training loss: 2.4967860543804865
Validation loss: 2.642058615661302

Epoch: 6| Step: 7
Training loss: 3.1426597570387322
Validation loss: 2.6460025827853175

Epoch: 6| Step: 8
Training loss: 2.8377437671696772
Validation loss: 2.6442692126781004

Epoch: 6| Step: 9
Training loss: 3.0819696727253225
Validation loss: 2.6373778278698023

Epoch: 6| Step: 10
Training loss: 3.3300600828873415
Validation loss: 2.6473798126586634

Epoch: 6| Step: 11
Training loss: 3.0002703544867764
Validation loss: 2.6490275908094483

Epoch: 6| Step: 12
Training loss: 3.1203753010901303
Validation loss: 2.6369449306085038

Epoch: 6| Step: 13
Training loss: 3.094679567576676
Validation loss: 2.6325618419728647

Epoch: 287| Step: 0
Training loss: 2.7215586218925103
Validation loss: 2.6361572824844104

Epoch: 6| Step: 1
Training loss: 3.1275563274772478
Validation loss: 2.632426968381963

Epoch: 6| Step: 2
Training loss: 2.657830161025335
Validation loss: 2.633204591643301

Epoch: 6| Step: 3
Training loss: 3.1702239150619724
Validation loss: 2.6332564742914006

Epoch: 6| Step: 4
Training loss: 2.984908929965943
Validation loss: 2.6363272169849963

Epoch: 6| Step: 5
Training loss: 3.1748257146143106
Validation loss: 2.63354810933372

Epoch: 6| Step: 6
Training loss: 3.0320622250656273
Validation loss: 2.632438908970219

Epoch: 6| Step: 7
Training loss: 2.48441703328976
Validation loss: 2.6306309053022634

Epoch: 6| Step: 8
Training loss: 2.7911960337948796
Validation loss: 2.630116731568893

Epoch: 6| Step: 9
Training loss: 3.716086836491146
Validation loss: 2.6317123870825583

Epoch: 6| Step: 10
Training loss: 3.1773641660215888
Validation loss: 2.6323996375632377

Epoch: 6| Step: 11
Training loss: 2.7729398039080135
Validation loss: 2.629984476575576

Epoch: 6| Step: 12
Training loss: 2.7858916565037743
Validation loss: 2.6396007227220233

Epoch: 6| Step: 13
Training loss: 2.7834064824282025
Validation loss: 2.645722905700735

Epoch: 288| Step: 0
Training loss: 2.7580426257894177
Validation loss: 2.64309316604812

Epoch: 6| Step: 1
Training loss: 2.91202193499258
Validation loss: 2.659240030008933

Epoch: 6| Step: 2
Training loss: 3.1740042018465955
Validation loss: 2.659924307643783

Epoch: 6| Step: 3
Training loss: 2.781802347606217
Validation loss: 2.6538983990590808

Epoch: 6| Step: 4
Training loss: 3.1498376653107156
Validation loss: 2.65245809022709

Epoch: 6| Step: 5
Training loss: 3.0625446861276666
Validation loss: 2.644046617803736

Epoch: 6| Step: 6
Training loss: 3.4533888772108554
Validation loss: 2.6404230989977737

Epoch: 6| Step: 7
Training loss: 2.3142633674188544
Validation loss: 2.638925612200778

Epoch: 6| Step: 8
Training loss: 2.8245685619285568
Validation loss: 2.6380878649677344

Epoch: 6| Step: 9
Training loss: 3.006942028566427
Validation loss: 2.637816529107336

Epoch: 6| Step: 10
Training loss: 2.714049122831751
Validation loss: 2.6356296783151056

Epoch: 6| Step: 11
Training loss: 2.8567529548542274
Validation loss: 2.633569791008197

Epoch: 6| Step: 12
Training loss: 2.812119352225234
Validation loss: 2.6318773281352366

Epoch: 6| Step: 13
Training loss: 3.939694232210229
Validation loss: 2.6312471375286504

Epoch: 289| Step: 0
Training loss: 3.0342823081193697
Validation loss: 2.6317239013217937

Epoch: 6| Step: 1
Training loss: 2.9888773404654225
Validation loss: 2.6379846657595882

Epoch: 6| Step: 2
Training loss: 2.7544778433570087
Validation loss: 2.6319092112994387

Epoch: 6| Step: 3
Training loss: 2.698513264522921
Validation loss: 2.6333968685318414

Epoch: 6| Step: 4
Training loss: 3.294782652567713
Validation loss: 2.6345049128737905

Epoch: 6| Step: 5
Training loss: 2.572983302027
Validation loss: 2.637212775894867

Epoch: 6| Step: 6
Training loss: 2.9726933039637897
Validation loss: 2.630819173762529

Epoch: 6| Step: 7
Training loss: 3.073660619304144
Validation loss: 2.6322029347520832

Epoch: 6| Step: 8
Training loss: 3.150811069762652
Validation loss: 2.6321661327255494

Epoch: 6| Step: 9
Training loss: 3.0494092525521697
Validation loss: 2.635579798494405

Epoch: 6| Step: 10
Training loss: 2.371486273111166
Validation loss: 2.633431923940362

Epoch: 6| Step: 11
Training loss: 3.424192436407851
Validation loss: 2.63672217632817

Epoch: 6| Step: 12
Training loss: 2.90870677514248
Validation loss: 2.63487842502343

Epoch: 6| Step: 13
Training loss: 3.228429665087501
Validation loss: 2.635237177013391

Epoch: 290| Step: 0
Training loss: 3.0507760920951115
Validation loss: 2.6321910145204135

Epoch: 6| Step: 1
Training loss: 3.1530751794332788
Validation loss: 2.631521746041284

Epoch: 6| Step: 2
Training loss: 2.6861361214351027
Validation loss: 2.6316308615156285

Epoch: 6| Step: 3
Training loss: 2.280814769457012
Validation loss: 2.631029120644118

Epoch: 6| Step: 4
Training loss: 3.2634354693515957
Validation loss: 2.6365515195499594

Epoch: 6| Step: 5
Training loss: 3.1374085310410904
Validation loss: 2.6324252733613545

Epoch: 6| Step: 6
Training loss: 2.972867659922501
Validation loss: 2.641362914728226

Epoch: 6| Step: 7
Training loss: 2.7370874520805715
Validation loss: 2.6321583234536146

Epoch: 6| Step: 8
Training loss: 2.9165254467881288
Validation loss: 2.6354135162037666

Epoch: 6| Step: 9
Training loss: 3.0110774563468334
Validation loss: 2.641744325080619

Epoch: 6| Step: 10
Training loss: 2.896785789852691
Validation loss: 2.644434434009153

Epoch: 6| Step: 11
Training loss: 2.923262159756303
Validation loss: 2.637249727189062

Epoch: 6| Step: 12
Training loss: 3.180458818840427
Validation loss: 2.6446411557842673

Epoch: 6| Step: 13
Training loss: 3.457730911057668
Validation loss: 2.6362710245852212

Epoch: 291| Step: 0
Training loss: 3.0675670200478673
Validation loss: 2.6362784044947105

Epoch: 6| Step: 1
Training loss: 3.151391397199384
Validation loss: 2.6358581553201588

Epoch: 6| Step: 2
Training loss: 3.1996490226434253
Validation loss: 2.6334655629479107

Epoch: 6| Step: 3
Training loss: 2.338338479190239
Validation loss: 2.63133290723634

Epoch: 6| Step: 4
Training loss: 2.59254979320298
Validation loss: 2.6390924435316028

Epoch: 6| Step: 5
Training loss: 2.961904081132209
Validation loss: 2.6358594936200257

Epoch: 6| Step: 6
Training loss: 2.573987565491467
Validation loss: 2.6317669170803115

Epoch: 6| Step: 7
Training loss: 3.094646901832499
Validation loss: 2.6360094022466622

Epoch: 6| Step: 8
Training loss: 2.9125376948590054
Validation loss: 2.6406615598715226

Epoch: 6| Step: 9
Training loss: 3.2464139667945657
Validation loss: 2.6278268561645444

Epoch: 6| Step: 10
Training loss: 3.294392740559743
Validation loss: 2.6266571416141318

Epoch: 6| Step: 11
Training loss: 2.910433967191211
Validation loss: 2.631426071563415

Epoch: 6| Step: 12
Training loss: 2.7497676404409184
Validation loss: 2.628723507770692

Epoch: 6| Step: 13
Training loss: 3.4760330311354815
Validation loss: 2.632257025570396

Epoch: 292| Step: 0
Training loss: 2.849417101496083
Validation loss: 2.629038671373348

Epoch: 6| Step: 1
Training loss: 3.1470929249346655
Validation loss: 2.6289068507070246

Epoch: 6| Step: 2
Training loss: 2.1936541501051248
Validation loss: 2.6294895625646686

Epoch: 6| Step: 3
Training loss: 3.474070000557619
Validation loss: 2.629325480868459

Epoch: 6| Step: 4
Training loss: 3.1822379566078314
Validation loss: 2.627554811938801

Epoch: 6| Step: 5
Training loss: 3.1883857842647836
Validation loss: 2.629774637366257

Epoch: 6| Step: 6
Training loss: 3.159082935390551
Validation loss: 2.633419531282028

Epoch: 6| Step: 7
Training loss: 2.8205170702513223
Validation loss: 2.6291352030493305

Epoch: 6| Step: 8
Training loss: 2.54395524680162
Validation loss: 2.6280438988495787

Epoch: 6| Step: 9
Training loss: 3.434344143507596
Validation loss: 2.6245064474073407

Epoch: 6| Step: 10
Training loss: 3.212053462361478
Validation loss: 2.6329020677289243

Epoch: 6| Step: 11
Training loss: 2.124326935931731
Validation loss: 2.6286127726010955

Epoch: 6| Step: 12
Training loss: 3.0051251184499894
Validation loss: 2.64006677629809

Epoch: 6| Step: 13
Training loss: 2.681652271887262
Validation loss: 2.6280897944585178

Epoch: 293| Step: 0
Training loss: 2.7469046251524345
Validation loss: 2.6405473447573815

Epoch: 6| Step: 1
Training loss: 3.3070925354770475
Validation loss: 2.6324020771308185

Epoch: 6| Step: 2
Training loss: 2.7808540148066494
Validation loss: 2.638485223033399

Epoch: 6| Step: 3
Training loss: 2.77300575011985
Validation loss: 2.6500985981450627

Epoch: 6| Step: 4
Training loss: 2.483603399641377
Validation loss: 2.6564913211192343

Epoch: 6| Step: 5
Training loss: 3.147329888144026
Validation loss: 2.651898907166763

Epoch: 6| Step: 6
Training loss: 3.011602377220307
Validation loss: 2.672066491276538

Epoch: 6| Step: 7
Training loss: 3.3755167812720788
Validation loss: 2.656415392017215

Epoch: 6| Step: 8
Training loss: 2.9363519576012496
Validation loss: 2.6424980842972303

Epoch: 6| Step: 9
Training loss: 3.227284496154036
Validation loss: 2.6311185483653934

Epoch: 6| Step: 10
Training loss: 2.2066256800338087
Validation loss: 2.6268374042645415

Epoch: 6| Step: 11
Training loss: 2.831856810360433
Validation loss: 2.623575009349401

Epoch: 6| Step: 12
Training loss: 3.1435786539937594
Validation loss: 2.627420033558467

Epoch: 6| Step: 13
Training loss: 3.6294323362272443
Validation loss: 2.6257493765490176

Epoch: 294| Step: 0
Training loss: 3.0704122046668885
Validation loss: 2.6284774993565936

Epoch: 6| Step: 1
Training loss: 2.930497121203222
Validation loss: 2.625671047024038

Epoch: 6| Step: 2
Training loss: 3.2630003096089055
Validation loss: 2.625270522906057

Epoch: 6| Step: 3
Training loss: 2.9837163228250727
Validation loss: 2.625521605097984

Epoch: 6| Step: 4
Training loss: 3.4244497706477537
Validation loss: 2.6268275228344184

Epoch: 6| Step: 5
Training loss: 2.9624441535933093
Validation loss: 2.6247576305264966

Epoch: 6| Step: 6
Training loss: 2.7784966545256458
Validation loss: 2.629053509804553

Epoch: 6| Step: 7
Training loss: 3.410068716212621
Validation loss: 2.6229673994244442

Epoch: 6| Step: 8
Training loss: 2.6070605767063517
Validation loss: 2.6281788432519124

Epoch: 6| Step: 9
Training loss: 2.4110024819853773
Validation loss: 2.628441059690768

Epoch: 6| Step: 10
Training loss: 2.3295832425793344
Validation loss: 2.6270131986969054

Epoch: 6| Step: 11
Training loss: 3.495917527856209
Validation loss: 2.641011535465765

Epoch: 6| Step: 12
Training loss: 2.526658214296615
Validation loss: 2.6395910561229248

Epoch: 6| Step: 13
Training loss: 3.1314280202365903
Validation loss: 2.6333670764950736

Epoch: 295| Step: 0
Training loss: 2.8560573320911984
Validation loss: 2.624713673091499

Epoch: 6| Step: 1
Training loss: 3.0882133493792456
Validation loss: 2.6234880928632967

Epoch: 6| Step: 2
Training loss: 2.7601859710069276
Validation loss: 2.626474386381877

Epoch: 6| Step: 3
Training loss: 2.7456056858410682
Validation loss: 2.6249927837079263

Epoch: 6| Step: 4
Training loss: 3.330182080030644
Validation loss: 2.6256573045042297

Epoch: 6| Step: 5
Training loss: 3.1661407803667028
Validation loss: 2.6270159282222596

Epoch: 6| Step: 6
Training loss: 2.2758942533776416
Validation loss: 2.626879869104398

Epoch: 6| Step: 7
Training loss: 3.164314919281302
Validation loss: 2.6260792808062914

Epoch: 6| Step: 8
Training loss: 3.0672265771756124
Validation loss: 2.6252716136835486

Epoch: 6| Step: 9
Training loss: 2.6841562450656267
Validation loss: 2.6244630669760727

Epoch: 6| Step: 10
Training loss: 3.3614801952091287
Validation loss: 2.6277634957450426

Epoch: 6| Step: 11
Training loss: 2.846579014354061
Validation loss: 2.621230556415083

Epoch: 6| Step: 12
Training loss: 3.0479376089263566
Validation loss: 2.6202749472269216

Epoch: 6| Step: 13
Training loss: 2.947934711162935
Validation loss: 2.632876908332496

Epoch: 296| Step: 0
Training loss: 3.1424573421086652
Validation loss: 2.6317581544244777

Epoch: 6| Step: 1
Training loss: 3.525443104699416
Validation loss: 2.6260908246252868

Epoch: 6| Step: 2
Training loss: 3.0284806018124333
Validation loss: 2.626349696447268

Epoch: 6| Step: 3
Training loss: 2.9297677397865924
Validation loss: 2.621999642220338

Epoch: 6| Step: 4
Training loss: 3.056281022926569
Validation loss: 2.6218885458241212

Epoch: 6| Step: 5
Training loss: 2.9246488246241613
Validation loss: 2.6195439301649763

Epoch: 6| Step: 6
Training loss: 3.1065110095025648
Validation loss: 2.621542825546781

Epoch: 6| Step: 7
Training loss: 3.051612652797672
Validation loss: 2.623345809479787

Epoch: 6| Step: 8
Training loss: 3.184558782992392
Validation loss: 2.622018332680448

Epoch: 6| Step: 9
Training loss: 2.481426672807305
Validation loss: 2.6215565563863246

Epoch: 6| Step: 10
Training loss: 2.546997254602685
Validation loss: 2.6232539208469867

Epoch: 6| Step: 11
Training loss: 2.907579343570895
Validation loss: 2.6232464779095634

Epoch: 6| Step: 12
Training loss: 2.4501826626940297
Validation loss: 2.6201556420643075

Epoch: 6| Step: 13
Training loss: 3.1609848313080793
Validation loss: 2.6247827407770847

Epoch: 297| Step: 0
Training loss: 3.0672850303281876
Validation loss: 2.6376589603302345

Epoch: 6| Step: 1
Training loss: 2.2539735251820683
Validation loss: 2.640629510547397

Epoch: 6| Step: 2
Training loss: 2.799091760606582
Validation loss: 2.652677691717231

Epoch: 6| Step: 3
Training loss: 3.0144296757664795
Validation loss: 2.668194005273883

Epoch: 6| Step: 4
Training loss: 3.283757005908406
Validation loss: 2.65952196501393

Epoch: 6| Step: 5
Training loss: 2.826457338079663
Validation loss: 2.6469824590866797

Epoch: 6| Step: 6
Training loss: 3.665341802586105
Validation loss: 2.6651547982479893

Epoch: 6| Step: 7
Training loss: 2.911395859886853
Validation loss: 2.6560906147052794

Epoch: 6| Step: 8
Training loss: 2.755904621101596
Validation loss: 2.646852771831176

Epoch: 6| Step: 9
Training loss: 3.2165647329146467
Validation loss: 2.648119755267549

Epoch: 6| Step: 10
Training loss: 2.7858432174021925
Validation loss: 2.654295865691283

Epoch: 6| Step: 11
Training loss: 3.111240919750507
Validation loss: 2.6542136757665316

Epoch: 6| Step: 12
Training loss: 2.516898265396703
Validation loss: 2.642016994454668

Epoch: 6| Step: 13
Training loss: 3.2861357146161034
Validation loss: 2.634795795772282

Epoch: 298| Step: 0
Training loss: 3.253825210716164
Validation loss: 2.6314638211456294

Epoch: 6| Step: 1
Training loss: 3.1174276541458035
Validation loss: 2.622760678934268

Epoch: 6| Step: 2
Training loss: 2.962432403437095
Validation loss: 2.627075791650433

Epoch: 6| Step: 3
Training loss: 3.379051320043294
Validation loss: 2.6229147805693054

Epoch: 6| Step: 4
Training loss: 2.475890829659221
Validation loss: 2.6238651850210304

Epoch: 6| Step: 5
Training loss: 2.8531496412502118
Validation loss: 2.6221172336585803

Epoch: 6| Step: 6
Training loss: 2.900752949801353
Validation loss: 2.630734211729566

Epoch: 6| Step: 7
Training loss: 2.9347691930319884
Validation loss: 2.624774896352397

Epoch: 6| Step: 8
Training loss: 2.3816496466136843
Validation loss: 2.6361439301418543

Epoch: 6| Step: 9
Training loss: 3.2624563513865055
Validation loss: 2.647571301678435

Epoch: 6| Step: 10
Training loss: 2.1720770872216417
Validation loss: 2.6479398580707545

Epoch: 6| Step: 11
Training loss: 3.5869140625
Validation loss: 2.6432696692718154

Epoch: 6| Step: 12
Training loss: 2.909641051291943
Validation loss: 2.6409344711163154

Epoch: 6| Step: 13
Training loss: 2.8890668638948416
Validation loss: 2.622468001650047

Epoch: 299| Step: 0
Training loss: 2.9340147079587986
Validation loss: 2.6148349680256873

Epoch: 6| Step: 1
Training loss: 3.200668360530588
Validation loss: 2.620327889121738

Epoch: 6| Step: 2
Training loss: 2.0005628270716804
Validation loss: 2.6257933381249456

Epoch: 6| Step: 3
Training loss: 2.6988489805854874
Validation loss: 2.617975405900955

Epoch: 6| Step: 4
Training loss: 2.7175146343605707
Validation loss: 2.6190623856026867

Epoch: 6| Step: 5
Training loss: 3.1091526277856176
Validation loss: 2.6193576514311165

Epoch: 6| Step: 6
Training loss: 3.3702104279788556
Validation loss: 2.6157788838335922

Epoch: 6| Step: 7
Training loss: 3.2677552790254403
Validation loss: 2.617869991917584

Epoch: 6| Step: 8
Training loss: 3.177988859278343
Validation loss: 2.6228648016488414

Epoch: 6| Step: 9
Training loss: 3.2162640795675657
Validation loss: 2.62056735193328

Epoch: 6| Step: 10
Training loss: 2.784700631945579
Validation loss: 2.6224249814649605

Epoch: 6| Step: 11
Training loss: 2.8837126693657344
Validation loss: 2.6162044985301507

Epoch: 6| Step: 12
Training loss: 2.6696060987366863
Validation loss: 2.6162374771378407

Epoch: 6| Step: 13
Training loss: 3.346392719130834
Validation loss: 2.6183737659568154

Epoch: 300| Step: 0
Training loss: 2.993867964998741
Validation loss: 2.6219179534903896

Epoch: 6| Step: 1
Training loss: 3.413716942519907
Validation loss: 2.6174942897142732

Epoch: 6| Step: 2
Training loss: 3.065851207479549
Validation loss: 2.6243957316244977

Epoch: 6| Step: 3
Training loss: 2.5570581851406557
Validation loss: 2.6210212487816364

Epoch: 6| Step: 4
Training loss: 2.9821024125932256
Validation loss: 2.6180206202129876

Epoch: 6| Step: 5
Training loss: 3.149138190436911
Validation loss: 2.632309288216769

Epoch: 6| Step: 6
Training loss: 3.2197370774870007
Validation loss: 2.6235472902341392

Epoch: 6| Step: 7
Training loss: 2.2442222162060714
Validation loss: 2.621378858647009

Epoch: 6| Step: 8
Training loss: 2.221449163864498
Validation loss: 2.6214860697994706

Epoch: 6| Step: 9
Training loss: 2.7049295212453845
Validation loss: 2.6225650958104647

Epoch: 6| Step: 10
Training loss: 3.316529468273759
Validation loss: 2.617933581991565

Epoch: 6| Step: 11
Training loss: 2.398185393661851
Validation loss: 2.6252749914777573

Epoch: 6| Step: 12
Training loss: 3.402063999872506
Validation loss: 2.617313694073417

Epoch: 6| Step: 13
Training loss: 3.680040864924884
Validation loss: 2.6223213662701346

Epoch: 301| Step: 0
Training loss: 3.0827374440959057
Validation loss: 2.616692051575944

Epoch: 6| Step: 1
Training loss: 2.541477029531879
Validation loss: 2.6257952907840867

Epoch: 6| Step: 2
Training loss: 2.457351445377448
Validation loss: 2.618419685180832

Epoch: 6| Step: 3
Training loss: 3.3708503078289502
Validation loss: 2.6266859141976586

Epoch: 6| Step: 4
Training loss: 3.4141943445651917
Validation loss: 2.621466969698869

Epoch: 6| Step: 5
Training loss: 3.003791320745165
Validation loss: 2.618697026048546

Epoch: 6| Step: 6
Training loss: 3.027250817626016
Validation loss: 2.6160835975839962

Epoch: 6| Step: 7
Training loss: 2.7685604573077
Validation loss: 2.6124880345761317

Epoch: 6| Step: 8
Training loss: 3.1389216268476963
Validation loss: 2.6150679538544823

Epoch: 6| Step: 9
Training loss: 2.3437811277229814
Validation loss: 2.6160728484504716

Epoch: 6| Step: 10
Training loss: 2.9636424248075444
Validation loss: 2.6176152547823617

Epoch: 6| Step: 11
Training loss: 3.076985879403866
Validation loss: 2.6190593198768704

Epoch: 6| Step: 12
Training loss: 3.029999150442879
Validation loss: 2.6406028956821626

Epoch: 6| Step: 13
Training loss: 3.0045528832014425
Validation loss: 2.627325786545401

Epoch: 302| Step: 0
Training loss: 3.1933793840160596
Validation loss: 2.644967728622699

Epoch: 6| Step: 1
Training loss: 2.4822580206913667
Validation loss: 2.641966857757925

Epoch: 6| Step: 2
Training loss: 2.982664247068749
Validation loss: 2.660320211938689

Epoch: 6| Step: 3
Training loss: 2.8402856538057653
Validation loss: 2.6427002700998963

Epoch: 6| Step: 4
Training loss: 2.9335352336873606
Validation loss: 2.6365047181712127

Epoch: 6| Step: 5
Training loss: 3.104040890050731
Validation loss: 2.6302882610121943

Epoch: 6| Step: 6
Training loss: 2.9622001270838383
Validation loss: 2.620469911780986

Epoch: 6| Step: 7
Training loss: 3.4102351123827983
Validation loss: 2.6177446668872193

Epoch: 6| Step: 8
Training loss: 2.6708632667359833
Validation loss: 2.6095154996894663

Epoch: 6| Step: 9
Training loss: 2.8671389375570655
Validation loss: 2.621277399694256

Epoch: 6| Step: 10
Training loss: 2.9862760710186973
Validation loss: 2.614335486703931

Epoch: 6| Step: 11
Training loss: 2.418626834385075
Validation loss: 2.6119069624247886

Epoch: 6| Step: 12
Training loss: 3.4598640516617767
Validation loss: 2.6126194693592675

Epoch: 6| Step: 13
Training loss: 3.0701300103309097
Validation loss: 2.617553527636052

Epoch: 303| Step: 0
Training loss: 2.731629306459373
Validation loss: 2.61886517734015

Epoch: 6| Step: 1
Training loss: 2.881126841397425
Validation loss: 2.6215978218153904

Epoch: 6| Step: 2
Training loss: 2.968393726052225
Validation loss: 2.62051617776638

Epoch: 6| Step: 3
Training loss: 3.400020677840241
Validation loss: 2.6238799100609542

Epoch: 6| Step: 4
Training loss: 3.1778694222609913
Validation loss: 2.631955732051042

Epoch: 6| Step: 5
Training loss: 2.821466690550975
Validation loss: 2.6334228119835865

Epoch: 6| Step: 6
Training loss: 2.2940264834045134
Validation loss: 2.6535297340908532

Epoch: 6| Step: 7
Training loss: 3.3023872757067725
Validation loss: 2.6426216048363416

Epoch: 6| Step: 8
Training loss: 3.106102683183382
Validation loss: 2.6421732108039517

Epoch: 6| Step: 9
Training loss: 2.8130190900093153
Validation loss: 2.6353461065496777

Epoch: 6| Step: 10
Training loss: 2.66082871685669
Validation loss: 2.6421068216578485

Epoch: 6| Step: 11
Training loss: 3.664313138998856
Validation loss: 2.638574991697131

Epoch: 6| Step: 12
Training loss: 2.748649438924168
Validation loss: 2.6223789358779466

Epoch: 6| Step: 13
Training loss: 2.3638142638848567
Validation loss: 2.621041514602381

Epoch: 304| Step: 0
Training loss: 3.7066926791515615
Validation loss: 2.6208053891655907

Epoch: 6| Step: 1
Training loss: 2.7156472752824103
Validation loss: 2.6133273489563167

Epoch: 6| Step: 2
Training loss: 2.9169527912576476
Validation loss: 2.6158989335029217

Epoch: 6| Step: 3
Training loss: 2.8887332809142694
Validation loss: 2.6085536038041286

Epoch: 6| Step: 4
Training loss: 3.0435995640482036
Validation loss: 2.6168219119841676

Epoch: 6| Step: 5
Training loss: 3.2095864230963183
Validation loss: 2.616163480224941

Epoch: 6| Step: 6
Training loss: 3.4740071367136682
Validation loss: 2.6115475264221852

Epoch: 6| Step: 7
Training loss: 2.273822974595825
Validation loss: 2.6112728309543356

Epoch: 6| Step: 8
Training loss: 2.5950649559108783
Validation loss: 2.610881255483766

Epoch: 6| Step: 9
Training loss: 2.752946402291621
Validation loss: 2.6071482345616785

Epoch: 6| Step: 10
Training loss: 2.584434602688985
Validation loss: 2.61520871723877

Epoch: 6| Step: 11
Training loss: 3.05449158803706
Validation loss: 2.6141230723040745

Epoch: 6| Step: 12
Training loss: 2.8597593622408715
Validation loss: 2.6147629580102256

Epoch: 6| Step: 13
Training loss: 3.0190315573358046
Validation loss: 2.6148329748278516

Epoch: 305| Step: 0
Training loss: 2.5388312131738093
Validation loss: 2.6154456052502275

Epoch: 6| Step: 1
Training loss: 3.1336165083765155
Validation loss: 2.6200846403024296

Epoch: 6| Step: 2
Training loss: 2.383686243173794
Validation loss: 2.6164646953541157

Epoch: 6| Step: 3
Training loss: 2.9990978473958454
Validation loss: 2.6149832408210116

Epoch: 6| Step: 4
Training loss: 3.3383885833033102
Validation loss: 2.618069921949723

Epoch: 6| Step: 5
Training loss: 3.1370273310036474
Validation loss: 2.6158034373567514

Epoch: 6| Step: 6
Training loss: 2.615219241519414
Validation loss: 2.619192421147345

Epoch: 6| Step: 7
Training loss: 3.0504741050072566
Validation loss: 2.617617203748298

Epoch: 6| Step: 8
Training loss: 2.700726806868728
Validation loss: 2.618311348788973

Epoch: 6| Step: 9
Training loss: 2.7468669557073886
Validation loss: 2.6294502081096778

Epoch: 6| Step: 10
Training loss: 3.195944576656571
Validation loss: 2.633240708367671

Epoch: 6| Step: 11
Training loss: 3.5620550580489723
Validation loss: 2.630024125211441

Epoch: 6| Step: 12
Training loss: 2.7813660672432543
Validation loss: 2.6258607840832133

Epoch: 6| Step: 13
Training loss: 2.8859786348246
Validation loss: 2.6263811664678136

Epoch: 306| Step: 0
Training loss: 3.384881987775496
Validation loss: 2.6116780853362154

Epoch: 6| Step: 1
Training loss: 3.42680860227928
Validation loss: 2.610356192141238

Epoch: 6| Step: 2
Training loss: 2.2496939556942204
Validation loss: 2.6126248402419234

Epoch: 6| Step: 3
Training loss: 2.9858680705048655
Validation loss: 2.6157673278287286

Epoch: 6| Step: 4
Training loss: 3.1819890570892975
Validation loss: 2.615375161774484

Epoch: 6| Step: 5
Training loss: 2.7241205248615867
Validation loss: 2.6148734571328753

Epoch: 6| Step: 6
Training loss: 3.005522254842414
Validation loss: 2.6177198779229505

Epoch: 6| Step: 7
Training loss: 2.785418183795418
Validation loss: 2.6151448030864497

Epoch: 6| Step: 8
Training loss: 3.2016196086178215
Validation loss: 2.613277777241804

Epoch: 6| Step: 9
Training loss: 2.670226185108421
Validation loss: 2.607079165798692

Epoch: 6| Step: 10
Training loss: 2.224420742112304
Validation loss: 2.6141187023521235

Epoch: 6| Step: 11
Training loss: 2.7350888437629166
Validation loss: 2.6134035195390664

Epoch: 6| Step: 12
Training loss: 3.3510277950690286
Validation loss: 2.615083356820581

Epoch: 6| Step: 13
Training loss: 3.244831082924636
Validation loss: 2.615086102719151

Epoch: 307| Step: 0
Training loss: 3.4341155991201164
Validation loss: 2.62496603471587

Epoch: 6| Step: 1
Training loss: 2.9006839077307887
Validation loss: 2.617952309314708

Epoch: 6| Step: 2
Training loss: 3.003804020326442
Validation loss: 2.6130259713346358

Epoch: 6| Step: 3
Training loss: 3.0410414972105113
Validation loss: 2.621189197180115

Epoch: 6| Step: 4
Training loss: 2.7202899999854786
Validation loss: 2.6229047700048413

Epoch: 6| Step: 5
Training loss: 2.8669955737662236
Validation loss: 2.626000294341136

Epoch: 6| Step: 6
Training loss: 2.892272974335038
Validation loss: 2.6168689311666102

Epoch: 6| Step: 7
Training loss: 2.286592472344497
Validation loss: 2.6231074505899374

Epoch: 6| Step: 8
Training loss: 2.6033434571261855
Validation loss: 2.610798536426673

Epoch: 6| Step: 9
Training loss: 2.8156238585542828
Validation loss: 2.6191279973437176

Epoch: 6| Step: 10
Training loss: 2.815919450442323
Validation loss: 2.6340421955692626

Epoch: 6| Step: 11
Training loss: 3.3159090170348358
Validation loss: 2.6245810823424858

Epoch: 6| Step: 12
Training loss: 3.2050964243364715
Validation loss: 2.614643257205161

Epoch: 6| Step: 13
Training loss: 3.370587042324778
Validation loss: 2.6248352811652693

Epoch: 308| Step: 0
Training loss: 3.0225298798175095
Validation loss: 2.6194331886267364

Epoch: 6| Step: 1
Training loss: 2.7206473909627005
Validation loss: 2.630430143529681

Epoch: 6| Step: 2
Training loss: 3.337129688078321
Validation loss: 2.642723543277094

Epoch: 6| Step: 3
Training loss: 2.9802570792812415
Validation loss: 2.63664986469157

Epoch: 6| Step: 4
Training loss: 2.7986906327991443
Validation loss: 2.6200599605606762

Epoch: 6| Step: 5
Training loss: 3.0557573791279986
Validation loss: 2.612425762349729

Epoch: 6| Step: 6
Training loss: 3.196678261469026
Validation loss: 2.6204071806013416

Epoch: 6| Step: 7
Training loss: 2.3601073082272457
Validation loss: 2.6093879052429396

Epoch: 6| Step: 8
Training loss: 2.7664167057627265
Validation loss: 2.611872519656349

Epoch: 6| Step: 9
Training loss: 2.7451672137250647
Validation loss: 2.6148023746874873

Epoch: 6| Step: 10
Training loss: 2.932888550704662
Validation loss: 2.6151925111753593

Epoch: 6| Step: 11
Training loss: 3.050134099294921
Validation loss: 2.6118636200760412

Epoch: 6| Step: 12
Training loss: 3.063714856895993
Validation loss: 2.6150378329117188

Epoch: 6| Step: 13
Training loss: 3.324673721251937
Validation loss: 2.6118509621449406

Epoch: 309| Step: 0
Training loss: 2.795658891431061
Validation loss: 2.614336070166159

Epoch: 6| Step: 1
Training loss: 2.891906454238013
Validation loss: 2.6114648088357186

Epoch: 6| Step: 2
Training loss: 3.2211635392368376
Validation loss: 2.615879895510448

Epoch: 6| Step: 3
Training loss: 3.0921543514716716
Validation loss: 2.6072653099986987

Epoch: 6| Step: 4
Training loss: 2.787125970353974
Validation loss: 2.610690020273261

Epoch: 6| Step: 5
Training loss: 3.071321821417106
Validation loss: 2.606684685552942

Epoch: 6| Step: 6
Training loss: 2.872842393726021
Validation loss: 2.6077243849594063

Epoch: 6| Step: 7
Training loss: 2.2035567489597883
Validation loss: 2.607552164634101

Epoch: 6| Step: 8
Training loss: 3.4165809124365234
Validation loss: 2.621386367521411

Epoch: 6| Step: 9
Training loss: 2.1442132655018487
Validation loss: 2.609484211384627

Epoch: 6| Step: 10
Training loss: 3.400264415556991
Validation loss: 2.615343110374604

Epoch: 6| Step: 11
Training loss: 2.9547161679866676
Validation loss: 2.6125454852715486

Epoch: 6| Step: 12
Training loss: 2.9799492259468434
Validation loss: 2.6200478001520464

Epoch: 6| Step: 13
Training loss: 3.279426285880865
Validation loss: 2.6229153689648954

Epoch: 310| Step: 0
Training loss: 2.5277835987941617
Validation loss: 2.6167886870023436

Epoch: 6| Step: 1
Training loss: 3.0188857717368855
Validation loss: 2.6211002874817817

Epoch: 6| Step: 2
Training loss: 3.0590556491405274
Validation loss: 2.618676452794348

Epoch: 6| Step: 3
Training loss: 2.6031997614974727
Validation loss: 2.616793724561366

Epoch: 6| Step: 4
Training loss: 2.873552372572151
Validation loss: 2.610428877610775

Epoch: 6| Step: 5
Training loss: 2.428199140479713
Validation loss: 2.61315071820681

Epoch: 6| Step: 6
Training loss: 2.665355737643836
Validation loss: 2.6062616868897

Epoch: 6| Step: 7
Training loss: 3.021178513021689
Validation loss: 2.618169825917346

Epoch: 6| Step: 8
Training loss: 2.967865179613999
Validation loss: 2.602397585247542

Epoch: 6| Step: 9
Training loss: 3.4510690774163892
Validation loss: 2.608915036312637

Epoch: 6| Step: 10
Training loss: 3.4737013112184165
Validation loss: 2.6054740495279334

Epoch: 6| Step: 11
Training loss: 2.7629829329834386
Validation loss: 2.6083720097574936

Epoch: 6| Step: 12
Training loss: 3.352422430519299
Validation loss: 2.603753021531339

Epoch: 6| Step: 13
Training loss: 2.781740381107137
Validation loss: 2.605835446784764

Epoch: 311| Step: 0
Training loss: 3.0468779735061613
Validation loss: 2.604190013821859

Epoch: 6| Step: 1
Training loss: 2.3742918665410944
Validation loss: 2.608137708232494

Epoch: 6| Step: 2
Training loss: 2.7475700913740018
Validation loss: 2.606715974022217

Epoch: 6| Step: 3
Training loss: 2.948040495699173
Validation loss: 2.6024140414115258

Epoch: 6| Step: 4
Training loss: 3.3007176861483236
Validation loss: 2.603074447140375

Epoch: 6| Step: 5
Training loss: 2.651196598304726
Validation loss: 2.612341577474334

Epoch: 6| Step: 6
Training loss: 2.7386517893019686
Validation loss: 2.6271805191172217

Epoch: 6| Step: 7
Training loss: 3.101703630979064
Validation loss: 2.6329168249920443

Epoch: 6| Step: 8
Training loss: 2.933157775422669
Validation loss: 2.634480180410427

Epoch: 6| Step: 9
Training loss: 2.6906941084897453
Validation loss: 2.647703166193509

Epoch: 6| Step: 10
Training loss: 3.2155504342230024
Validation loss: 2.6555209631825036

Epoch: 6| Step: 11
Training loss: 2.454008490015343
Validation loss: 2.648019737191472

Epoch: 6| Step: 12
Training loss: 3.5579679338748185
Validation loss: 2.6425850536494284

Epoch: 6| Step: 13
Training loss: 3.4866894617545108
Validation loss: 2.6308517138637892

Epoch: 312| Step: 0
Training loss: 2.718346401380433
Validation loss: 2.603549336429163

Epoch: 6| Step: 1
Training loss: 2.2873170206230773
Validation loss: 2.604576013366363

Epoch: 6| Step: 2
Training loss: 2.7957456215878156
Validation loss: 2.6097630696151777

Epoch: 6| Step: 3
Training loss: 2.9165381993657093
Validation loss: 2.611204275786113

Epoch: 6| Step: 4
Training loss: 3.4353664365990038
Validation loss: 2.613251531281047

Epoch: 6| Step: 5
Training loss: 3.054872004797949
Validation loss: 2.6115591609801716

Epoch: 6| Step: 6
Training loss: 3.25509684053857
Validation loss: 2.609924054286947

Epoch: 6| Step: 7
Training loss: 2.893492724720464
Validation loss: 2.605037955604635

Epoch: 6| Step: 8
Training loss: 3.0901869475961727
Validation loss: 2.6081873501183837

Epoch: 6| Step: 9
Training loss: 3.0646955444068547
Validation loss: 2.6056661142270845

Epoch: 6| Step: 10
Training loss: 3.2237054400047187
Validation loss: 2.6039009841423595

Epoch: 6| Step: 11
Training loss: 3.5030948035293945
Validation loss: 2.605989980663119

Epoch: 6| Step: 12
Training loss: 2.1277318112305554
Validation loss: 2.60365664666359

Epoch: 6| Step: 13
Training loss: 2.4091022975384178
Validation loss: 2.6113050373601254

Epoch: 313| Step: 0
Training loss: 3.1828753263389973
Validation loss: 2.615468866099264

Epoch: 6| Step: 1
Training loss: 2.8712349162787096
Validation loss: 2.6074465957065187

Epoch: 6| Step: 2
Training loss: 2.6063731395437992
Validation loss: 2.6178358068159975

Epoch: 6| Step: 3
Training loss: 2.904574331589655
Validation loss: 2.617291254770397

Epoch: 6| Step: 4
Training loss: 2.719655028794456
Validation loss: 2.6129379131532002

Epoch: 6| Step: 5
Training loss: 2.59261968411818
Validation loss: 2.6096472644492246

Epoch: 6| Step: 6
Training loss: 2.9136872650816064
Validation loss: 2.6076335925953966

Epoch: 6| Step: 7
Training loss: 3.221736078384548
Validation loss: 2.604066863741962

Epoch: 6| Step: 8
Training loss: 2.472279403920561
Validation loss: 2.6063385547926483

Epoch: 6| Step: 9
Training loss: 3.165701886492641
Validation loss: 2.6039792291599717

Epoch: 6| Step: 10
Training loss: 3.3572040018931153
Validation loss: 2.6092786215430195

Epoch: 6| Step: 11
Training loss: 2.2726778944026678
Validation loss: 2.6022927992537666

Epoch: 6| Step: 12
Training loss: 3.3956072367346244
Validation loss: 2.611365032205976

Epoch: 6| Step: 13
Training loss: 3.6948897460676284
Validation loss: 2.6115209283242966

Epoch: 314| Step: 0
Training loss: 2.5526640458404457
Validation loss: 2.6093524609882355

Epoch: 6| Step: 1
Training loss: 3.1616767083067048
Validation loss: 2.6053452067431104

Epoch: 6| Step: 2
Training loss: 3.2464894628502123
Validation loss: 2.600373915241245

Epoch: 6| Step: 3
Training loss: 2.4377646669336435
Validation loss: 2.606309282166644

Epoch: 6| Step: 4
Training loss: 3.468561940636949
Validation loss: 2.607296559052821

Epoch: 6| Step: 5
Training loss: 2.9617851070777927
Validation loss: 2.608108204164393

Epoch: 6| Step: 6
Training loss: 3.062716418034782
Validation loss: 2.6107255774610287

Epoch: 6| Step: 7
Training loss: 2.787655943199198
Validation loss: 2.61153987734941

Epoch: 6| Step: 8
Training loss: 2.9842650707829748
Validation loss: 2.6145474494720617

Epoch: 6| Step: 9
Training loss: 2.8623576632763923
Validation loss: 2.610345789677467

Epoch: 6| Step: 10
Training loss: 3.202506252166577
Validation loss: 2.609877634420999

Epoch: 6| Step: 11
Training loss: 3.0440635817274924
Validation loss: 2.6134143748042953

Epoch: 6| Step: 12
Training loss: 2.7795341427952196
Validation loss: 2.6031411325213605

Epoch: 6| Step: 13
Training loss: 2.4421388549255467
Validation loss: 2.602967992412236

Epoch: 315| Step: 0
Training loss: 3.071975063739341
Validation loss: 2.6047909227554022

Epoch: 6| Step: 1
Training loss: 3.0004297584432074
Validation loss: 2.606941929468699

Epoch: 6| Step: 2
Training loss: 2.5828778470375413
Validation loss: 2.6065167369431106

Epoch: 6| Step: 3
Training loss: 2.7108334568077206
Validation loss: 2.6105386567145734

Epoch: 6| Step: 4
Training loss: 2.9747372936012995
Validation loss: 2.6104363855741757

Epoch: 6| Step: 5
Training loss: 2.8497850705132337
Validation loss: 2.619338970368882

Epoch: 6| Step: 6
Training loss: 2.5222424018526874
Validation loss: 2.6455082388838433

Epoch: 6| Step: 7
Training loss: 3.0853740708945865
Validation loss: 2.6343171082978847

Epoch: 6| Step: 8
Training loss: 3.225887939285271
Validation loss: 2.63884940014409

Epoch: 6| Step: 9
Training loss: 3.1625594725312856
Validation loss: 2.6304427169290827

Epoch: 6| Step: 10
Training loss: 2.6986904924695434
Validation loss: 2.6151649414232394

Epoch: 6| Step: 11
Training loss: 3.3563869228173293
Validation loss: 2.6119141903328997

Epoch: 6| Step: 12
Training loss: 2.836605781442667
Validation loss: 2.597242460957452

Epoch: 6| Step: 13
Training loss: 3.1374782911058756
Validation loss: 2.605676978113571

Epoch: 316| Step: 0
Training loss: 3.354467879961057
Validation loss: 2.6018355169433764

Epoch: 6| Step: 1
Training loss: 2.912654587732044
Validation loss: 2.600726835115403

Epoch: 6| Step: 2
Training loss: 3.2241346632518666
Validation loss: 2.5956357546899196

Epoch: 6| Step: 3
Training loss: 2.1660127631152193
Validation loss: 2.604941438335496

Epoch: 6| Step: 4
Training loss: 2.857791983570936
Validation loss: 2.5974184270183334

Epoch: 6| Step: 5
Training loss: 3.1614213634426283
Validation loss: 2.5941435476669583

Epoch: 6| Step: 6
Training loss: 3.1306916856507967
Validation loss: 2.5979945854766484

Epoch: 6| Step: 7
Training loss: 2.892366781505223
Validation loss: 2.594230406722222

Epoch: 6| Step: 8
Training loss: 2.3215079262553164
Validation loss: 2.5957054459714324

Epoch: 6| Step: 9
Training loss: 2.3545610440729954
Validation loss: 2.6005907343666013

Epoch: 6| Step: 10
Training loss: 2.819635537180385
Validation loss: 2.5982514870073405

Epoch: 6| Step: 11
Training loss: 3.574010090391562
Validation loss: 2.5975186046493985

Epoch: 6| Step: 12
Training loss: 3.06005481496346
Validation loss: 2.603412693928468

Epoch: 6| Step: 13
Training loss: 3.07936435283402
Validation loss: 2.6040209316370557

Epoch: 317| Step: 0
Training loss: 2.7113328804795493
Validation loss: 2.606239414574756

Epoch: 6| Step: 1
Training loss: 3.226532942888228
Validation loss: 2.6081709136711386

Epoch: 6| Step: 2
Training loss: 2.2389901255312767
Validation loss: 2.616583288978118

Epoch: 6| Step: 3
Training loss: 3.5735780569037776
Validation loss: 2.613451188787069

Epoch: 6| Step: 4
Training loss: 2.5466331882007194
Validation loss: 2.6142157869193614

Epoch: 6| Step: 5
Training loss: 2.219439976825231
Validation loss: 2.609154568928933

Epoch: 6| Step: 6
Training loss: 3.7269196089295162
Validation loss: 2.6214264845751662

Epoch: 6| Step: 7
Training loss: 2.5179660874038143
Validation loss: 2.606594922127701

Epoch: 6| Step: 8
Training loss: 2.900872783208169
Validation loss: 2.5902942735866175

Epoch: 6| Step: 9
Training loss: 3.160560157718736
Validation loss: 2.5927665319641044

Epoch: 6| Step: 10
Training loss: 2.522747406031744
Validation loss: 2.5994311148522

Epoch: 6| Step: 11
Training loss: 3.1444202474584966
Validation loss: 2.5999944606963377

Epoch: 6| Step: 12
Training loss: 3.0572492779593565
Validation loss: 2.5940806749728607

Epoch: 6| Step: 13
Training loss: 3.3520117683113018
Validation loss: 2.5938172226047627

Epoch: 318| Step: 0
Training loss: 2.9446237097656907
Validation loss: 2.5957506175881466

Epoch: 6| Step: 1
Training loss: 2.5006455541641714
Validation loss: 2.600606276311341

Epoch: 6| Step: 2
Training loss: 2.852238154383124
Validation loss: 2.5965258948971632

Epoch: 6| Step: 3
Training loss: 2.9314834989746648
Validation loss: 2.5973485235927227

Epoch: 6| Step: 4
Training loss: 2.7818182889719605
Validation loss: 2.5908570665704675

Epoch: 6| Step: 5
Training loss: 2.676243829769058
Validation loss: 2.5986212384527665

Epoch: 6| Step: 6
Training loss: 3.612334652188844
Validation loss: 2.5940551874784146

Epoch: 6| Step: 7
Training loss: 2.952074459460123
Validation loss: 2.59468712045879

Epoch: 6| Step: 8
Training loss: 2.5740912120755777
Validation loss: 2.593381986815146

Epoch: 6| Step: 9
Training loss: 3.268605017865784
Validation loss: 2.5967160170437023

Epoch: 6| Step: 10
Training loss: 3.206034906322238
Validation loss: 2.596565723681568

Epoch: 6| Step: 11
Training loss: 2.8716967306336394
Validation loss: 2.5958812787083847

Epoch: 6| Step: 12
Training loss: 2.905976477436552
Validation loss: 2.6012959273346588

Epoch: 6| Step: 13
Training loss: 2.8625282452784795
Validation loss: 2.596812359252917

Epoch: 319| Step: 0
Training loss: 2.460403335970157
Validation loss: 2.604487149771139

Epoch: 6| Step: 1
Training loss: 2.9578287115121302
Validation loss: 2.6057621589769533

Epoch: 6| Step: 2
Training loss: 2.858203418622713
Validation loss: 2.6176202887919136

Epoch: 6| Step: 3
Training loss: 2.872113810874274
Validation loss: 2.642425213270443

Epoch: 6| Step: 4
Training loss: 2.766452902460033
Validation loss: 2.6615922952458786

Epoch: 6| Step: 5
Training loss: 2.848365810410768
Validation loss: 2.6584437490451016

Epoch: 6| Step: 6
Training loss: 2.7180239705536806
Validation loss: 2.6705357634331675

Epoch: 6| Step: 7
Training loss: 3.1341635057439654
Validation loss: 2.6897582200869237

Epoch: 6| Step: 8
Training loss: 3.3362728191580104
Validation loss: 2.692254306649764

Epoch: 6| Step: 9
Training loss: 3.2736035580269878
Validation loss: 2.6578448541499857

Epoch: 6| Step: 10
Training loss: 2.7351423658178207
Validation loss: 2.6167362152815206

Epoch: 6| Step: 11
Training loss: 2.889212598352112
Validation loss: 2.596941847495083

Epoch: 6| Step: 12
Training loss: 3.277930478851272
Validation loss: 2.5982791405174384

Epoch: 6| Step: 13
Training loss: 3.0957869172413806
Validation loss: 2.6087322675304523

Epoch: 320| Step: 0
Training loss: 3.2453746159742876
Validation loss: 2.6022841969369805

Epoch: 6| Step: 1
Training loss: 2.8201041950428776
Validation loss: 2.606411749673181

Epoch: 6| Step: 2
Training loss: 2.844568658722621
Validation loss: 2.6075745845152905

Epoch: 6| Step: 3
Training loss: 3.2790732293265625
Validation loss: 2.6085101123709338

Epoch: 6| Step: 4
Training loss: 2.5823910645721497
Validation loss: 2.6054497617403016

Epoch: 6| Step: 5
Training loss: 2.93065804236511
Validation loss: 2.6027856294528244

Epoch: 6| Step: 6
Training loss: 3.0133490794397764
Validation loss: 2.6044710216893114

Epoch: 6| Step: 7
Training loss: 2.806486185240679
Validation loss: 2.6026543368369914

Epoch: 6| Step: 8
Training loss: 2.6024436031390827
Validation loss: 2.6016184753901883

Epoch: 6| Step: 9
Training loss: 3.181422854300989
Validation loss: 2.5934178356741064

Epoch: 6| Step: 10
Training loss: 2.924638226951313
Validation loss: 2.6009114315559625

Epoch: 6| Step: 11
Training loss: 2.8883177751084324
Validation loss: 2.6190305555198217

Epoch: 6| Step: 12
Training loss: 3.3428671553744764
Validation loss: 2.650118905215173

Epoch: 6| Step: 13
Training loss: 2.939888976978629
Validation loss: 2.6527123981048644

Epoch: 321| Step: 0
Training loss: 2.7154463943025666
Validation loss: 2.654756163363426

Epoch: 6| Step: 1
Training loss: 3.078319717677279
Validation loss: 2.635972532766573

Epoch: 6| Step: 2
Training loss: 2.526249880255121
Validation loss: 2.6168257836654045

Epoch: 6| Step: 3
Training loss: 2.727090079520449
Validation loss: 2.6073183833171916

Epoch: 6| Step: 4
Training loss: 2.832686312979554
Validation loss: 2.5994460177524434

Epoch: 6| Step: 5
Training loss: 3.0028739514644616
Validation loss: 2.5971004553029577

Epoch: 6| Step: 6
Training loss: 2.5313315672742287
Validation loss: 2.6010605971132463

Epoch: 6| Step: 7
Training loss: 2.556131683819923
Validation loss: 2.6011733212665096

Epoch: 6| Step: 8
Training loss: 2.586983460546352
Validation loss: 2.5995942077566534

Epoch: 6| Step: 9
Training loss: 3.3250694038203426
Validation loss: 2.5981645660248023

Epoch: 6| Step: 10
Training loss: 3.514412225712335
Validation loss: 2.6044460561863225

Epoch: 6| Step: 11
Training loss: 2.8778501563705454
Validation loss: 2.604993610302993

Epoch: 6| Step: 12
Training loss: 3.7074199508904764
Validation loss: 2.6005312244010708

Epoch: 6| Step: 13
Training loss: 2.954105597879475
Validation loss: 2.601447169398214

Epoch: 322| Step: 0
Training loss: 3.1753702683699045
Validation loss: 2.5943294865709525

Epoch: 6| Step: 1
Training loss: 2.7307228330346773
Validation loss: 2.5941325455496145

Epoch: 6| Step: 2
Training loss: 3.334702274238661
Validation loss: 2.5921389195369193

Epoch: 6| Step: 3
Training loss: 2.627384918915764
Validation loss: 2.5913706369017517

Epoch: 6| Step: 4
Training loss: 2.896470875621779
Validation loss: 2.596476886092203

Epoch: 6| Step: 5
Training loss: 3.4892902004426736
Validation loss: 2.594310174677196

Epoch: 6| Step: 6
Training loss: 2.5713309731202703
Validation loss: 2.595331456378029

Epoch: 6| Step: 7
Training loss: 2.829921931345847
Validation loss: 2.594470471984872

Epoch: 6| Step: 8
Training loss: 3.1527448774760023
Validation loss: 2.5912366180337942

Epoch: 6| Step: 9
Training loss: 2.727649723352627
Validation loss: 2.593471752848335

Epoch: 6| Step: 10
Training loss: 2.6570644252088984
Validation loss: 2.5924096022476055

Epoch: 6| Step: 11
Training loss: 3.1915768749332045
Validation loss: 2.5926164407784045

Epoch: 6| Step: 12
Training loss: 2.807647418315507
Validation loss: 2.5967453741187607

Epoch: 6| Step: 13
Training loss: 2.730802807544669
Validation loss: 2.597964550779309

Epoch: 323| Step: 0
Training loss: 2.34482376933029
Validation loss: 2.6022178156888836

Epoch: 6| Step: 1
Training loss: 2.7698800495493665
Validation loss: 2.6067842981026135

Epoch: 6| Step: 2
Training loss: 2.7946574194636247
Validation loss: 2.613974883117778

Epoch: 6| Step: 3
Training loss: 3.563333246595657
Validation loss: 2.6056504529134377

Epoch: 6| Step: 4
Training loss: 2.246722483333057
Validation loss: 2.603685002892788

Epoch: 6| Step: 5
Training loss: 2.447760675749292
Validation loss: 2.6167558828705

Epoch: 6| Step: 6
Training loss: 2.866615342264778
Validation loss: 2.625067873583663

Epoch: 6| Step: 7
Training loss: 3.3684595099562715
Validation loss: 2.623185634817872

Epoch: 6| Step: 8
Training loss: 3.18976497585579
Validation loss: 2.6101539878050772

Epoch: 6| Step: 9
Training loss: 3.230308445709008
Validation loss: 2.628056203700074

Epoch: 6| Step: 10
Training loss: 3.372431307376569
Validation loss: 2.6135804137389584

Epoch: 6| Step: 11
Training loss: 2.5027267844137273
Validation loss: 2.6133187505895084

Epoch: 6| Step: 12
Training loss: 3.108840973201311
Validation loss: 2.611113943150658

Epoch: 6| Step: 13
Training loss: 2.974638710202937
Validation loss: 2.6082754418914784

Epoch: 324| Step: 0
Training loss: 2.578385033642933
Validation loss: 2.613968141473638

Epoch: 6| Step: 1
Training loss: 3.4390956989715438
Validation loss: 2.6234367294137915

Epoch: 6| Step: 2
Training loss: 2.790866129710862
Validation loss: 2.623550940922955

Epoch: 6| Step: 3
Training loss: 2.5524051281730284
Validation loss: 2.6507776997151438

Epoch: 6| Step: 4
Training loss: 3.5819764044669813
Validation loss: 2.6244411024899064

Epoch: 6| Step: 5
Training loss: 2.7433888121596284
Validation loss: 2.619614265453812

Epoch: 6| Step: 6
Training loss: 3.1935428858299764
Validation loss: 2.608882256992356

Epoch: 6| Step: 7
Training loss: 3.100360627886572
Validation loss: 2.603861699777381

Epoch: 6| Step: 8
Training loss: 2.759382627655927
Validation loss: 2.5962972545990484

Epoch: 6| Step: 9
Training loss: 2.3956882488162683
Validation loss: 2.6025572908541896

Epoch: 6| Step: 10
Training loss: 2.750296576720084
Validation loss: 2.5936318113736383

Epoch: 6| Step: 11
Training loss: 2.9534262851643027
Validation loss: 2.588533388394748

Epoch: 6| Step: 12
Training loss: 3.287782252273818
Validation loss: 2.590096789184454

Epoch: 6| Step: 13
Training loss: 2.5416336891244544
Validation loss: 2.5892361027824133

Epoch: 325| Step: 0
Training loss: 3.0533000790424554
Validation loss: 2.587851062425041

Epoch: 6| Step: 1
Training loss: 3.011870107051107
Validation loss: 2.588952766958765

Epoch: 6| Step: 2
Training loss: 3.1330459774088246
Validation loss: 2.594406982708222

Epoch: 6| Step: 3
Training loss: 2.8791720760605632
Validation loss: 2.592931844494289

Epoch: 6| Step: 4
Training loss: 2.658567786167022
Validation loss: 2.596495678324055

Epoch: 6| Step: 5
Training loss: 2.805272118463799
Validation loss: 2.5975557692575726

Epoch: 6| Step: 6
Training loss: 3.0933635740062577
Validation loss: 2.60329868019064

Epoch: 6| Step: 7
Training loss: 2.5099257837395057
Validation loss: 2.6064153919045516

Epoch: 6| Step: 8
Training loss: 3.0425545602763315
Validation loss: 2.617076018102906

Epoch: 6| Step: 9
Training loss: 2.882142524091202
Validation loss: 2.609159504303359

Epoch: 6| Step: 10
Training loss: 3.1112518013825956
Validation loss: 2.611252987565782

Epoch: 6| Step: 11
Training loss: 3.1122407981460127
Validation loss: 2.611397648812043

Epoch: 6| Step: 12
Training loss: 2.7863720651742647
Validation loss: 2.5977669122911746

Epoch: 6| Step: 13
Training loss: 3.0639758543751365
Validation loss: 2.592755387553165

Epoch: 326| Step: 0
Training loss: 2.6732721969894455
Validation loss: 2.5916342657658364

Epoch: 6| Step: 1
Training loss: 3.39662139423162
Validation loss: 2.5848086901316796

Epoch: 6| Step: 2
Training loss: 3.0007062716404134
Validation loss: 2.5861389400920665

Epoch: 6| Step: 3
Training loss: 3.0994998405346967
Validation loss: 2.586799568352317

Epoch: 6| Step: 4
Training loss: 3.275395574776373
Validation loss: 2.5870992506231865

Epoch: 6| Step: 5
Training loss: 3.4129705363180185
Validation loss: 2.594817115877995

Epoch: 6| Step: 6
Training loss: 2.433809567796664
Validation loss: 2.58886052901173

Epoch: 6| Step: 7
Training loss: 3.2538417704445686
Validation loss: 2.5904113368317008

Epoch: 6| Step: 8
Training loss: 2.732896328704187
Validation loss: 2.5923330818117107

Epoch: 6| Step: 9
Training loss: 2.67949833772255
Validation loss: 2.5874445259275

Epoch: 6| Step: 10
Training loss: 2.849513992899059
Validation loss: 2.593295268387759

Epoch: 6| Step: 11
Training loss: 2.5486988487929247
Validation loss: 2.5941091724425136

Epoch: 6| Step: 12
Training loss: 2.7426074105913103
Validation loss: 2.5947997549458233

Epoch: 6| Step: 13
Training loss: 2.5595718028658383
Validation loss: 2.590916641412628

Epoch: 327| Step: 0
Training loss: 2.7307387233530283
Validation loss: 2.5951463904182788

Epoch: 6| Step: 1
Training loss: 3.1116260450586135
Validation loss: 2.5870131837342507

Epoch: 6| Step: 2
Training loss: 2.347769888414129
Validation loss: 2.5942410457535185

Epoch: 6| Step: 3
Training loss: 3.270575025203274
Validation loss: 2.5892567238184188

Epoch: 6| Step: 4
Training loss: 3.288587522302805
Validation loss: 2.5833493634803975

Epoch: 6| Step: 5
Training loss: 2.742192890564057
Validation loss: 2.586597878407071

Epoch: 6| Step: 6
Training loss: 2.6055688567139494
Validation loss: 2.587232651466845

Epoch: 6| Step: 7
Training loss: 3.1702058656675423
Validation loss: 2.588618965023964

Epoch: 6| Step: 8
Training loss: 3.125879392868472
Validation loss: 2.581781813232743

Epoch: 6| Step: 9
Training loss: 2.5817568080557827
Validation loss: 2.5832400872440604

Epoch: 6| Step: 10
Training loss: 2.591128207710677
Validation loss: 2.5901118754534043

Epoch: 6| Step: 11
Training loss: 2.9034656599906805
Validation loss: 2.584083565952467

Epoch: 6| Step: 12
Training loss: 3.006295274802007
Validation loss: 2.6014565766502797

Epoch: 6| Step: 13
Training loss: 3.653205843276506
Validation loss: 2.600667837903432

Epoch: 328| Step: 0
Training loss: 3.056332976730192
Validation loss: 2.5965317369511958

Epoch: 6| Step: 1
Training loss: 3.3146890568650886
Validation loss: 2.5963821705019816

Epoch: 6| Step: 2
Training loss: 3.002795506402573
Validation loss: 2.5988634934628774

Epoch: 6| Step: 3
Training loss: 2.381148360678932
Validation loss: 2.5958148077926233

Epoch: 6| Step: 4
Training loss: 2.8564825384860626
Validation loss: 2.590132765663424

Epoch: 6| Step: 5
Training loss: 3.4603450087159957
Validation loss: 2.583994179180298

Epoch: 6| Step: 6
Training loss: 3.0060043647008543
Validation loss: 2.5808941618772816

Epoch: 6| Step: 7
Training loss: 3.009152438449596
Validation loss: 2.583209267679417

Epoch: 6| Step: 8
Training loss: 2.3310566308053797
Validation loss: 2.5886119622446064

Epoch: 6| Step: 9
Training loss: 2.2631525689789616
Validation loss: 2.580848730233669

Epoch: 6| Step: 10
Training loss: 3.284879729509333
Validation loss: 2.582762492050427

Epoch: 6| Step: 11
Training loss: 2.7578684339173267
Validation loss: 2.5809685571113783

Epoch: 6| Step: 12
Training loss: 2.747202924611974
Validation loss: 2.59195007187487

Epoch: 6| Step: 13
Training loss: 3.4525057552436076
Validation loss: 2.5832934268987824

Epoch: 329| Step: 0
Training loss: 2.933414133721905
Validation loss: 2.5833366114833436

Epoch: 6| Step: 1
Training loss: 2.979780245109204
Validation loss: 2.589126059100136

Epoch: 6| Step: 2
Training loss: 2.906371903682853
Validation loss: 2.586673388110326

Epoch: 6| Step: 3
Training loss: 2.8099093903835275
Validation loss: 2.5960351480124904

Epoch: 6| Step: 4
Training loss: 2.8457686417367944
Validation loss: 2.5989446037735897

Epoch: 6| Step: 5
Training loss: 2.7752337589268063
Validation loss: 2.604724644760146

Epoch: 6| Step: 6
Training loss: 2.7615536825227713
Validation loss: 2.5931167066624456

Epoch: 6| Step: 7
Training loss: 3.3661899726464934
Validation loss: 2.589918118793711

Epoch: 6| Step: 8
Training loss: 2.9516232825059254
Validation loss: 2.584669083069952

Epoch: 6| Step: 9
Training loss: 3.1169381484111147
Validation loss: 2.5813745220079127

Epoch: 6| Step: 10
Training loss: 3.061917775142069
Validation loss: 2.5812584532814062

Epoch: 6| Step: 11
Training loss: 2.297087990363807
Validation loss: 2.57863037088302

Epoch: 6| Step: 12
Training loss: 2.901798900532368
Validation loss: 2.5793154198389705

Epoch: 6| Step: 13
Training loss: 3.39802945197568
Validation loss: 2.5755916953050004

Epoch: 330| Step: 0
Training loss: 3.088880463534543
Validation loss: 2.5822394172333

Epoch: 6| Step: 1
Training loss: 2.8020134294339183
Validation loss: 2.5824394621362576

Epoch: 6| Step: 2
Training loss: 3.38309849329638
Validation loss: 2.585659173592003

Epoch: 6| Step: 3
Training loss: 3.261134953134591
Validation loss: 2.5867697218007204

Epoch: 6| Step: 4
Training loss: 2.501459553951439
Validation loss: 2.591157058210831

Epoch: 6| Step: 5
Training loss: 2.137028589745559
Validation loss: 2.597600869220585

Epoch: 6| Step: 6
Training loss: 3.0379762252670917
Validation loss: 2.605366614400099

Epoch: 6| Step: 7
Training loss: 3.1214691050985066
Validation loss: 2.5978335651652413

Epoch: 6| Step: 8
Training loss: 2.6723079219125556
Validation loss: 2.597471982329565

Epoch: 6| Step: 9
Training loss: 3.0837914066449543
Validation loss: 2.610173513467336

Epoch: 6| Step: 10
Training loss: 3.4349071087000227
Validation loss: 2.5877960726459843

Epoch: 6| Step: 11
Training loss: 2.8229568215830394
Validation loss: 2.5843738542067585

Epoch: 6| Step: 12
Training loss: 2.438895193027622
Validation loss: 2.579734119605133

Epoch: 6| Step: 13
Training loss: 2.9576525016671034
Validation loss: 2.5748037225419838

Epoch: 331| Step: 0
Training loss: 3.0308390859934393
Validation loss: 2.5813042868945333

Epoch: 6| Step: 1
Training loss: 2.630014806495441
Validation loss: 2.5781574723282876

Epoch: 6| Step: 2
Training loss: 3.0417067294334705
Validation loss: 2.5782870339007786

Epoch: 6| Step: 3
Training loss: 3.194748360002746
Validation loss: 2.582908905788746

Epoch: 6| Step: 4
Training loss: 3.0978805249142627
Validation loss: 2.579571733853352

Epoch: 6| Step: 5
Training loss: 3.3205046474732725
Validation loss: 2.5800906735110467

Epoch: 6| Step: 6
Training loss: 3.1165425104173186
Validation loss: 2.5898032238992266

Epoch: 6| Step: 7
Training loss: 2.1943972162671987
Validation loss: 2.5795364866459307

Epoch: 6| Step: 8
Training loss: 2.8527561981398604
Validation loss: 2.579196607038989

Epoch: 6| Step: 9
Training loss: 2.35865570623821
Validation loss: 2.5830300762107874

Epoch: 6| Step: 10
Training loss: 3.472988528991964
Validation loss: 2.583738224507091

Epoch: 6| Step: 11
Training loss: 2.6129820784995474
Validation loss: 2.583406196926888

Epoch: 6| Step: 12
Training loss: 3.114259496755973
Validation loss: 2.5827703404978815

Epoch: 6| Step: 13
Training loss: 2.537108717192226
Validation loss: 2.578474612876237

Epoch: 332| Step: 0
Training loss: 2.696238040959449
Validation loss: 2.580749587796966

Epoch: 6| Step: 1
Training loss: 3.063543647904692
Validation loss: 2.5790934036915507

Epoch: 6| Step: 2
Training loss: 3.351774622466733
Validation loss: 2.5790345110005424

Epoch: 6| Step: 3
Training loss: 3.7980837055803187
Validation loss: 2.5841225726096333

Epoch: 6| Step: 4
Training loss: 2.5128624004698445
Validation loss: 2.582616016408374

Epoch: 6| Step: 5
Training loss: 2.3180304714171593
Validation loss: 2.57754504211536

Epoch: 6| Step: 6
Training loss: 3.3437996263475642
Validation loss: 2.590891884693665

Epoch: 6| Step: 7
Training loss: 2.576251094545801
Validation loss: 2.581029544167914

Epoch: 6| Step: 8
Training loss: 3.0276641085535947
Validation loss: 2.581475173777272

Epoch: 6| Step: 9
Training loss: 2.4972682332896885
Validation loss: 2.583686268289914

Epoch: 6| Step: 10
Training loss: 2.469765273304025
Validation loss: 2.5865681435087975

Epoch: 6| Step: 11
Training loss: 2.6221123207179624
Validation loss: 2.602103197873896

Epoch: 6| Step: 12
Training loss: 3.1487711310803923
Validation loss: 2.603958715852461

Epoch: 6| Step: 13
Training loss: 3.2021858141021595
Validation loss: 2.5998024389778402

Epoch: 333| Step: 0
Training loss: 2.749931854790888
Validation loss: 2.605195995722981

Epoch: 6| Step: 1
Training loss: 2.569896536796543
Validation loss: 2.5986986944044705

Epoch: 6| Step: 2
Training loss: 2.7167364973520938
Validation loss: 2.5886768632501598

Epoch: 6| Step: 3
Training loss: 2.7190568246575046
Validation loss: 2.5850876684205386

Epoch: 6| Step: 4
Training loss: 2.890425391651227
Validation loss: 2.5831045697158963

Epoch: 6| Step: 5
Training loss: 2.9847066804806563
Validation loss: 2.5809634615477743

Epoch: 6| Step: 6
Training loss: 3.4107109046982047
Validation loss: 2.5770224880328403

Epoch: 6| Step: 7
Training loss: 3.1663361092419504
Validation loss: 2.577598415081045

Epoch: 6| Step: 8
Training loss: 2.4688035983291186
Validation loss: 2.5806604103886333

Epoch: 6| Step: 9
Training loss: 3.3223884824432384
Validation loss: 2.5822120486417406

Epoch: 6| Step: 10
Training loss: 3.153087277749145
Validation loss: 2.5856045937848027

Epoch: 6| Step: 11
Training loss: 2.753040366977395
Validation loss: 2.5804488223704434

Epoch: 6| Step: 12
Training loss: 3.126767231016016
Validation loss: 2.583369067921092

Epoch: 6| Step: 13
Training loss: 2.5824685238658405
Validation loss: 2.583648370341637

Epoch: 334| Step: 0
Training loss: 2.9831964052910602
Validation loss: 2.586043666435686

Epoch: 6| Step: 1
Training loss: 3.192925118600228
Validation loss: 2.583131839033964

Epoch: 6| Step: 2
Training loss: 2.839378602187038
Validation loss: 2.584360730807509

Epoch: 6| Step: 3
Training loss: 3.3046701850166955
Validation loss: 2.5777180887228717

Epoch: 6| Step: 4
Training loss: 2.4928165227927614
Validation loss: 2.5814278813414466

Epoch: 6| Step: 5
Training loss: 2.484379990290782
Validation loss: 2.591207184696238

Epoch: 6| Step: 6
Training loss: 3.0114625656078835
Validation loss: 2.5794903463237353

Epoch: 6| Step: 7
Training loss: 2.693975232968404
Validation loss: 2.583877768756017

Epoch: 6| Step: 8
Training loss: 3.1303728835809306
Validation loss: 2.5868034264964397

Epoch: 6| Step: 9
Training loss: 2.9051449223151193
Validation loss: 2.594285711223511

Epoch: 6| Step: 10
Training loss: 3.169191324474281
Validation loss: 2.5967487248480197

Epoch: 6| Step: 11
Training loss: 2.8722909520294686
Validation loss: 2.611605775261246

Epoch: 6| Step: 12
Training loss: 2.979828572046825
Validation loss: 2.60717849778525

Epoch: 6| Step: 13
Training loss: 2.461095895665163
Validation loss: 2.608071506441233

Epoch: 335| Step: 0
Training loss: 3.0553305649045317
Validation loss: 2.609854785907627

Epoch: 6| Step: 1
Training loss: 3.1936266492698793
Validation loss: 2.5888357892703238

Epoch: 6| Step: 2
Training loss: 3.2164144097540412
Validation loss: 2.5875357235184318

Epoch: 6| Step: 3
Training loss: 2.764983021854749
Validation loss: 2.59500291167925

Epoch: 6| Step: 4
Training loss: 3.506133699443246
Validation loss: 2.5824812841202296

Epoch: 6| Step: 5
Training loss: 2.730756359751943
Validation loss: 2.5802789236601336

Epoch: 6| Step: 6
Training loss: 2.8164507773764265
Validation loss: 2.5806139504111707

Epoch: 6| Step: 7
Training loss: 3.1266106078999694
Validation loss: 2.575182328985588

Epoch: 6| Step: 8
Training loss: 2.274934780317824
Validation loss: 2.5772608865407265

Epoch: 6| Step: 9
Training loss: 2.5656173166956835
Validation loss: 2.5756664198685018

Epoch: 6| Step: 10
Training loss: 3.17150155109895
Validation loss: 2.5735004731368893

Epoch: 6| Step: 11
Training loss: 2.4401537802967628
Validation loss: 2.582799084848426

Epoch: 6| Step: 12
Training loss: 2.6545786367708244
Validation loss: 2.5780045954486086

Epoch: 6| Step: 13
Training loss: 3.3165508908203667
Validation loss: 2.581518942913868

Epoch: 336| Step: 0
Training loss: 2.499273194521658
Validation loss: 2.578911505658938

Epoch: 6| Step: 1
Training loss: 2.6887621022993518
Validation loss: 2.582569619406697

Epoch: 6| Step: 2
Training loss: 3.5405375457225277
Validation loss: 2.583398531019252

Epoch: 6| Step: 3
Training loss: 2.9944562552774934
Validation loss: 2.5876201472348526

Epoch: 6| Step: 4
Training loss: 3.2301764765380976
Validation loss: 2.5870938272441255

Epoch: 6| Step: 5
Training loss: 2.9965619413968283
Validation loss: 2.587370149448334

Epoch: 6| Step: 6
Training loss: 2.849775365710386
Validation loss: 2.5890962512498485

Epoch: 6| Step: 7
Training loss: 2.954816061578736
Validation loss: 2.588012921753507

Epoch: 6| Step: 8
Training loss: 2.7702398214257355
Validation loss: 2.5990384684421906

Epoch: 6| Step: 9
Training loss: 3.008055521077246
Validation loss: 2.5990426674602127

Epoch: 6| Step: 10
Training loss: 2.231650552138289
Validation loss: 2.5968971102333906

Epoch: 6| Step: 11
Training loss: 2.622945072019252
Validation loss: 2.6112554174366718

Epoch: 6| Step: 12
Training loss: 3.142371759461029
Validation loss: 2.6090348633431564

Epoch: 6| Step: 13
Training loss: 3.2594522790717306
Validation loss: 2.6009342235986965

Epoch: 337| Step: 0
Training loss: 2.918521690833097
Validation loss: 2.58728654296155

Epoch: 6| Step: 1
Training loss: 2.298817961094247
Validation loss: 2.5814792404830995

Epoch: 6| Step: 2
Training loss: 2.6355587364371997
Validation loss: 2.579352437237444

Epoch: 6| Step: 3
Training loss: 3.151952858741778
Validation loss: 2.5789388009235874

Epoch: 6| Step: 4
Training loss: 2.2748272505347282
Validation loss: 2.5790126203536996

Epoch: 6| Step: 5
Training loss: 3.1154902912123914
Validation loss: 2.572532642752581

Epoch: 6| Step: 6
Training loss: 3.6122912231095374
Validation loss: 2.5775265045902325

Epoch: 6| Step: 7
Training loss: 2.7644168779692793
Validation loss: 2.5752349107196197

Epoch: 6| Step: 8
Training loss: 3.4451523654944736
Validation loss: 2.5744464413867005

Epoch: 6| Step: 9
Training loss: 2.7603367823911777
Validation loss: 2.5809188019291587

Epoch: 6| Step: 10
Training loss: 1.7817596241913323
Validation loss: 2.5790106571247713

Epoch: 6| Step: 11
Training loss: 3.402246765085847
Validation loss: 2.5872541505306157

Epoch: 6| Step: 12
Training loss: 2.587197909941858
Validation loss: 2.593386554816699

Epoch: 6| Step: 13
Training loss: 3.8505133695292293
Validation loss: 2.5846063677299456

Epoch: 338| Step: 0
Training loss: 3.518657681760005
Validation loss: 2.5866501022141923

Epoch: 6| Step: 1
Training loss: 2.7219599924055364
Validation loss: 2.577597075374746

Epoch: 6| Step: 2
Training loss: 2.683415880374926
Validation loss: 2.5780146759482165

Epoch: 6| Step: 3
Training loss: 2.4832240863639643
Validation loss: 2.5900531610451076

Epoch: 6| Step: 4
Training loss: 2.755208717927864
Validation loss: 2.57454659627508

Epoch: 6| Step: 5
Training loss: 3.008165056448189
Validation loss: 2.584951739973954

Epoch: 6| Step: 6
Training loss: 3.248795506216256
Validation loss: 2.594235200517407

Epoch: 6| Step: 7
Training loss: 2.4087372842560955
Validation loss: 2.5935507464435132

Epoch: 6| Step: 8
Training loss: 3.2385312709762153
Validation loss: 2.599634261710298

Epoch: 6| Step: 9
Training loss: 2.556796728487273
Validation loss: 2.593149305640637

Epoch: 6| Step: 10
Training loss: 2.9957512332735767
Validation loss: 2.601590977103061

Epoch: 6| Step: 11
Training loss: 3.0911510609960446
Validation loss: 2.595215223572023

Epoch: 6| Step: 12
Training loss: 2.7732574834293646
Validation loss: 2.5899429382722974

Epoch: 6| Step: 13
Training loss: 3.3762968891818335
Validation loss: 2.5846993883099096

Epoch: 339| Step: 0
Training loss: 2.3694980537260055
Validation loss: 2.583503563386603

Epoch: 6| Step: 1
Training loss: 2.860241367852204
Validation loss: 2.578515551665507

Epoch: 6| Step: 2
Training loss: 2.938777726860789
Validation loss: 2.583324213703213

Epoch: 6| Step: 3
Training loss: 3.4716446629298647
Validation loss: 2.5762236513908388

Epoch: 6| Step: 4
Training loss: 3.017752573840975
Validation loss: 2.5808869533809595

Epoch: 6| Step: 5
Training loss: 2.615860696653332
Validation loss: 2.5811312269476163

Epoch: 6| Step: 6
Training loss: 2.827582544391785
Validation loss: 2.597001653923173

Epoch: 6| Step: 7
Training loss: 3.141772312104809
Validation loss: 2.592644129672376

Epoch: 6| Step: 8
Training loss: 2.5009715099946526
Validation loss: 2.5921146719663284

Epoch: 6| Step: 9
Training loss: 3.534930986003215
Validation loss: 2.5964963694664367

Epoch: 6| Step: 10
Training loss: 3.0071307313776208
Validation loss: 2.6081465703967224

Epoch: 6| Step: 11
Training loss: 2.9962899791610944
Validation loss: 2.6143143868571683

Epoch: 6| Step: 12
Training loss: 2.9653821614634075
Validation loss: 2.6132161320727674

Epoch: 6| Step: 13
Training loss: 1.628366650826504
Validation loss: 2.6051872278312223

Epoch: 340| Step: 0
Training loss: 2.824131121403776
Validation loss: 2.6095028401925737

Epoch: 6| Step: 1
Training loss: 3.1628822668586305
Validation loss: 2.597560269715776

Epoch: 6| Step: 2
Training loss: 3.1891258431572833
Validation loss: 2.5910072379051026

Epoch: 6| Step: 3
Training loss: 2.7543716362088038
Validation loss: 2.586219519665814

Epoch: 6| Step: 4
Training loss: 3.109462104229077
Validation loss: 2.581968858812216

Epoch: 6| Step: 5
Training loss: 2.604787482966873
Validation loss: 2.5841779267658227

Epoch: 6| Step: 6
Training loss: 2.115316429906602
Validation loss: 2.5736083360239213

Epoch: 6| Step: 7
Training loss: 3.1153857538161414
Validation loss: 2.5747364077728747

Epoch: 6| Step: 8
Training loss: 3.2781163829184736
Validation loss: 2.576465149679617

Epoch: 6| Step: 9
Training loss: 2.8271373056775664
Validation loss: 2.5762806589490594

Epoch: 6| Step: 10
Training loss: 2.70898824745127
Validation loss: 2.5788032502197997

Epoch: 6| Step: 11
Training loss: 3.149593169567946
Validation loss: 2.5804499877296476

Epoch: 6| Step: 12
Training loss: 3.066802603016957
Validation loss: 2.5782555411294705

Epoch: 6| Step: 13
Training loss: 2.624403022821817
Validation loss: 2.581264544414763

Epoch: 341| Step: 0
Training loss: 3.108622397582954
Validation loss: 2.580136567612907

Epoch: 6| Step: 1
Training loss: 2.417494423829268
Validation loss: 2.5805629903006415

Epoch: 6| Step: 2
Training loss: 3.370414727384497
Validation loss: 2.5779066861601736

Epoch: 6| Step: 3
Training loss: 3.1272532160031354
Validation loss: 2.583750723491186

Epoch: 6| Step: 4
Training loss: 2.6611705308393456
Validation loss: 2.5835094080955003

Epoch: 6| Step: 5
Training loss: 3.65130868208344
Validation loss: 2.5828025747654073

Epoch: 6| Step: 6
Training loss: 3.011092658961941
Validation loss: 2.5810585750898056

Epoch: 6| Step: 7
Training loss: 3.082490101200493
Validation loss: 2.5881742831281302

Epoch: 6| Step: 8
Training loss: 2.2368131553028383
Validation loss: 2.587958422790652

Epoch: 6| Step: 9
Training loss: 2.711298937709832
Validation loss: 2.5820814454250858

Epoch: 6| Step: 10
Training loss: 2.597395942667078
Validation loss: 2.5761545237552763

Epoch: 6| Step: 11
Training loss: 3.1075945026393765
Validation loss: 2.574724936396827

Epoch: 6| Step: 12
Training loss: 2.4861742138327916
Validation loss: 2.57574951871325

Epoch: 6| Step: 13
Training loss: 2.858034080061924
Validation loss: 2.5764116238815955

Epoch: 342| Step: 0
Training loss: 2.827647975081744
Validation loss: 2.574377271008327

Epoch: 6| Step: 1
Training loss: 3.147897981747695
Validation loss: 2.5797119556455685

Epoch: 6| Step: 2
Training loss: 3.167979286260993
Validation loss: 2.5848334456054944

Epoch: 6| Step: 3
Training loss: 3.071081322465554
Validation loss: 2.593799660270658

Epoch: 6| Step: 4
Training loss: 3.0727864555745654
Validation loss: 2.589812986253394

Epoch: 6| Step: 5
Training loss: 2.6496763679530595
Validation loss: 2.5939723232251772

Epoch: 6| Step: 6
Training loss: 2.8967308099080937
Validation loss: 2.588088921603684

Epoch: 6| Step: 7
Training loss: 3.0155498910355814
Validation loss: 2.6025848877779927

Epoch: 6| Step: 8
Training loss: 2.0944739840802544
Validation loss: 2.5915271927122148

Epoch: 6| Step: 9
Training loss: 3.064024876466168
Validation loss: 2.596819619302652

Epoch: 6| Step: 10
Training loss: 2.916560434495813
Validation loss: 2.593846350574263

Epoch: 6| Step: 11
Training loss: 2.7301126447081647
Validation loss: 2.5893369172652516

Epoch: 6| Step: 12
Training loss: 2.9917972001383
Validation loss: 2.5707391082583713

Epoch: 6| Step: 13
Training loss: 3.0276603287092887
Validation loss: 2.5925885113019733

Epoch: 343| Step: 0
Training loss: 2.9339672516267394
Validation loss: 2.5867927965174964

Epoch: 6| Step: 1
Training loss: 3.1693067253460545
Validation loss: 2.584511985857811

Epoch: 6| Step: 2
Training loss: 2.386558315048155
Validation loss: 2.572659793575776

Epoch: 6| Step: 3
Training loss: 2.933186712357531
Validation loss: 2.5758021495808157

Epoch: 6| Step: 4
Training loss: 2.5839337194758474
Validation loss: 2.5741123926463483

Epoch: 6| Step: 5
Training loss: 2.6681403220820887
Validation loss: 2.5788555493638237

Epoch: 6| Step: 6
Training loss: 3.109568834253543
Validation loss: 2.5827533968740117

Epoch: 6| Step: 7
Training loss: 3.1206095562214076
Validation loss: 2.5839300440667543

Epoch: 6| Step: 8
Training loss: 3.6700770095104684
Validation loss: 2.5860224517379824

Epoch: 6| Step: 9
Training loss: 3.138498221948256
Validation loss: 2.586358523640462

Epoch: 6| Step: 10
Training loss: 2.248980397099558
Validation loss: 2.58676164366865

Epoch: 6| Step: 11
Training loss: 3.0223544445597055
Validation loss: 2.580104239427136

Epoch: 6| Step: 12
Training loss: 2.5763771374466726
Validation loss: 2.5788932493415677

Epoch: 6| Step: 13
Training loss: 2.900797333121823
Validation loss: 2.58083004906048

Epoch: 344| Step: 0
Training loss: 2.9578221018172366
Validation loss: 2.5766637475091745

Epoch: 6| Step: 1
Training loss: 2.144318672581125
Validation loss: 2.583580430671291

Epoch: 6| Step: 2
Training loss: 3.0136060528294655
Validation loss: 2.5779232539110435

Epoch: 6| Step: 3
Training loss: 2.9857893383530025
Validation loss: 2.589810463012064

Epoch: 6| Step: 4
Training loss: 2.762764523644813
Validation loss: 2.5856745792301217

Epoch: 6| Step: 5
Training loss: 2.795395443806808
Validation loss: 2.5982091137246197

Epoch: 6| Step: 6
Training loss: 2.9129793746747117
Validation loss: 2.589043290574717

Epoch: 6| Step: 7
Training loss: 2.524142896007782
Validation loss: 2.5867158819765903

Epoch: 6| Step: 8
Training loss: 3.5755715400154635
Validation loss: 2.604801055096075

Epoch: 6| Step: 9
Training loss: 3.1914409135969395
Validation loss: 2.612153173129051

Epoch: 6| Step: 10
Training loss: 2.953231890323288
Validation loss: 2.5946280234606554

Epoch: 6| Step: 11
Training loss: 3.311425952607065
Validation loss: 2.597755540641332

Epoch: 6| Step: 12
Training loss: 2.5641198969524153
Validation loss: 2.59935284043094

Epoch: 6| Step: 13
Training loss: 2.609015982593901
Validation loss: 2.603909451159252

Epoch: 345| Step: 0
Training loss: 3.1680291072490863
Validation loss: 2.606856863862065

Epoch: 6| Step: 1
Training loss: 3.0721684638760567
Validation loss: 2.6155657486282466

Epoch: 6| Step: 2
Training loss: 2.933742636243488
Validation loss: 2.6058110994013086

Epoch: 6| Step: 3
Training loss: 3.286977220169109
Validation loss: 2.5895227053135077

Epoch: 6| Step: 4
Training loss: 2.1268184959042142
Validation loss: 2.5800149492900823

Epoch: 6| Step: 5
Training loss: 3.108709676287001
Validation loss: 2.570841958413137

Epoch: 6| Step: 6
Training loss: 2.772343121450994
Validation loss: 2.5728153137222813

Epoch: 6| Step: 7
Training loss: 3.1044233757905486
Validation loss: 2.5693721966913223

Epoch: 6| Step: 8
Training loss: 2.3043585073710133
Validation loss: 2.570018012488559

Epoch: 6| Step: 9
Training loss: 3.212996590672764
Validation loss: 2.5630610002230054

Epoch: 6| Step: 10
Training loss: 2.349799322122646
Validation loss: 2.563651117728906

Epoch: 6| Step: 11
Training loss: 3.5324545637206684
Validation loss: 2.5626991728805795

Epoch: 6| Step: 12
Training loss: 2.643612858527183
Validation loss: 2.5643175443841373

Epoch: 6| Step: 13
Training loss: 2.92507188496737
Validation loss: 2.566965765346599

Epoch: 346| Step: 0
Training loss: 3.3197053960134477
Validation loss: 2.5645767408423703

Epoch: 6| Step: 1
Training loss: 3.2471165703941884
Validation loss: 2.5770989557414574

Epoch: 6| Step: 2
Training loss: 3.124962920922601
Validation loss: 2.573651467959648

Epoch: 6| Step: 3
Training loss: 2.151144202300105
Validation loss: 2.568931471143126

Epoch: 6| Step: 4
Training loss: 2.653809087870814
Validation loss: 2.5792195631403754

Epoch: 6| Step: 5
Training loss: 2.8026724459621515
Validation loss: 2.57465338177582

Epoch: 6| Step: 6
Training loss: 2.7884652489351636
Validation loss: 2.5760836208727342

Epoch: 6| Step: 7
Training loss: 2.8348066949622392
Validation loss: 2.580038055602859

Epoch: 6| Step: 8
Training loss: 3.496508900804945
Validation loss: 2.5788395154729904

Epoch: 6| Step: 9
Training loss: 3.449258287836104
Validation loss: 2.5680783388821915

Epoch: 6| Step: 10
Training loss: 3.083850318937645
Validation loss: 2.560624563576193

Epoch: 6| Step: 11
Training loss: 2.477883934042993
Validation loss: 2.5723202745571663

Epoch: 6| Step: 12
Training loss: 2.33824793635432
Validation loss: 2.5632951554716343

Epoch: 6| Step: 13
Training loss: 2.3041371868471217
Validation loss: 2.564534481924785

Epoch: 347| Step: 0
Training loss: 2.1855623655477623
Validation loss: 2.5678537937396895

Epoch: 6| Step: 1
Training loss: 2.7331273311427964
Validation loss: 2.569461607235969

Epoch: 6| Step: 2
Training loss: 3.1577990668009677
Validation loss: 2.584967541569306

Epoch: 6| Step: 3
Training loss: 2.575128374325558
Validation loss: 2.5703580660096983

Epoch: 6| Step: 4
Training loss: 2.901737113797163
Validation loss: 2.5785158012175287

Epoch: 6| Step: 5
Training loss: 3.0655519498157333
Validation loss: 2.5701836471009725

Epoch: 6| Step: 6
Training loss: 2.8230383214508237
Validation loss: 2.58066860695925

Epoch: 6| Step: 7
Training loss: 3.0993664555586653
Validation loss: 2.577883133119053

Epoch: 6| Step: 8
Training loss: 2.2516635467070962
Validation loss: 2.610135935277124

Epoch: 6| Step: 9
Training loss: 2.683240753456447
Validation loss: 2.602579253364154

Epoch: 6| Step: 10
Training loss: 3.631338956862731
Validation loss: 2.6111956979183337

Epoch: 6| Step: 11
Training loss: 3.484632268739392
Validation loss: 2.59659366073108

Epoch: 6| Step: 12
Training loss: 3.141466018650829
Validation loss: 2.5830636991914786

Epoch: 6| Step: 13
Training loss: 2.3898906701910674
Validation loss: 2.5871143033389927

Epoch: 348| Step: 0
Training loss: 2.3584946764784207
Validation loss: 2.5749351488917913

Epoch: 6| Step: 1
Training loss: 2.2958878452408786
Validation loss: 2.566843944458085

Epoch: 6| Step: 2
Training loss: 3.254418817016005
Validation loss: 2.570231994251831

Epoch: 6| Step: 3
Training loss: 3.074316776947283
Validation loss: 2.577152947731658

Epoch: 6| Step: 4
Training loss: 3.0253578415751217
Validation loss: 2.5864181684002436

Epoch: 6| Step: 5
Training loss: 3.030167848577329
Validation loss: 2.5857302372570845

Epoch: 6| Step: 6
Training loss: 2.8871858500221905
Validation loss: 2.5918753934365015

Epoch: 6| Step: 7
Training loss: 3.3355180892122163
Validation loss: 2.611348280498821

Epoch: 6| Step: 8
Training loss: 3.030281462737117
Validation loss: 2.599358945380084

Epoch: 6| Step: 9
Training loss: 2.4804547166802835
Validation loss: 2.6062742903240386

Epoch: 6| Step: 10
Training loss: 2.7495635293161724
Validation loss: 2.6151180063003894

Epoch: 6| Step: 11
Training loss: 2.8209441684903127
Validation loss: 2.625093360760273

Epoch: 6| Step: 12
Training loss: 2.7785659011074175
Validation loss: 2.6370666673002945

Epoch: 6| Step: 13
Training loss: 3.7804935423764707
Validation loss: 2.663371428230935

Epoch: 349| Step: 0
Training loss: 3.1314968476295593
Validation loss: 2.6620503725876374

Epoch: 6| Step: 1
Training loss: 2.7547019296009623
Validation loss: 2.6502812217186116

Epoch: 6| Step: 2
Training loss: 2.994519950592594
Validation loss: 2.6146127656414917

Epoch: 6| Step: 3
Training loss: 2.5711672211091696
Validation loss: 2.6022108199498977

Epoch: 6| Step: 4
Training loss: 3.2386461151316945
Validation loss: 2.578030370900368

Epoch: 6| Step: 5
Training loss: 2.5439155093623715
Validation loss: 2.5707548925047297

Epoch: 6| Step: 6
Training loss: 2.8393465260096704
Validation loss: 2.5624899174941844

Epoch: 6| Step: 7
Training loss: 2.999232511893733
Validation loss: 2.564488463556659

Epoch: 6| Step: 8
Training loss: 3.414657156896649
Validation loss: 2.570313856469435

Epoch: 6| Step: 9
Training loss: 3.190990855195209
Validation loss: 2.569475922691498

Epoch: 6| Step: 10
Training loss: 2.9770443343608437
Validation loss: 2.57324708913731

Epoch: 6| Step: 11
Training loss: 2.829279374212407
Validation loss: 2.570811649372731

Epoch: 6| Step: 12
Training loss: 2.754947200483816
Validation loss: 2.5675273883841863

Epoch: 6| Step: 13
Training loss: 2.0920090910529856
Validation loss: 2.5721161614908996

Epoch: 350| Step: 0
Training loss: 2.9647170128956213
Validation loss: 2.5783545646994708

Epoch: 6| Step: 1
Training loss: 3.009940843476095
Validation loss: 2.6176327640835892

Epoch: 6| Step: 2
Training loss: 3.5222635618391847
Validation loss: 2.63266019787486

Epoch: 6| Step: 3
Training loss: 3.5016255010054964
Validation loss: 2.61198997223368

Epoch: 6| Step: 4
Training loss: 2.5058433906836264
Validation loss: 2.5871539594260766

Epoch: 6| Step: 5
Training loss: 3.2288990196961147
Validation loss: 2.572421267638723

Epoch: 6| Step: 6
Training loss: 2.4930877494563357
Validation loss: 2.5713292303475987

Epoch: 6| Step: 7
Training loss: 2.0850853483080742
Validation loss: 2.5710934974940827

Epoch: 6| Step: 8
Training loss: 3.239522035924472
Validation loss: 2.5685170609074928

Epoch: 6| Step: 9
Training loss: 2.7208517435180255
Validation loss: 2.568291668728803

Epoch: 6| Step: 10
Training loss: 2.4158868408418233
Validation loss: 2.571991976046442

Epoch: 6| Step: 11
Training loss: 3.1931179130327716
Validation loss: 2.5734804919074206

Epoch: 6| Step: 12
Training loss: 2.9304113689063565
Validation loss: 2.5787771315651473

Epoch: 6| Step: 13
Training loss: 2.6041377154966234
Validation loss: 2.57216923148949

Epoch: 351| Step: 0
Training loss: 2.2761168536607594
Validation loss: 2.57876677469427

Epoch: 6| Step: 1
Training loss: 2.903883103511128
Validation loss: 2.5760057387016415

Epoch: 6| Step: 2
Training loss: 3.5369082329957067
Validation loss: 2.5744394159892905

Epoch: 6| Step: 3
Training loss: 3.1526002838616707
Validation loss: 2.5682087418360116

Epoch: 6| Step: 4
Training loss: 3.4209369087724006
Validation loss: 2.56938123347176

Epoch: 6| Step: 5
Training loss: 3.1046121435518557
Validation loss: 2.574067811360838

Epoch: 6| Step: 6
Training loss: 2.813670359924493
Validation loss: 2.5554634213688665

Epoch: 6| Step: 7
Training loss: 2.580234473759157
Validation loss: 2.5598314898703927

Epoch: 6| Step: 8
Training loss: 2.8791447492796687
Validation loss: 2.564238573019565

Epoch: 6| Step: 9
Training loss: 2.9146173271140046
Validation loss: 2.574105436052655

Epoch: 6| Step: 10
Training loss: 3.1119346626110826
Validation loss: 2.567816149329175

Epoch: 6| Step: 11
Training loss: 2.8822689215880843
Validation loss: 2.5693284910320204

Epoch: 6| Step: 12
Training loss: 2.4915584140936904
Validation loss: 2.565338003842546

Epoch: 6| Step: 13
Training loss: 1.939389445785533
Validation loss: 2.5645543819091623

Epoch: 352| Step: 0
Training loss: 3.377778781366478
Validation loss: 2.5723587500033123

Epoch: 6| Step: 1
Training loss: 2.7875391970217858
Validation loss: 2.5632620597979856

Epoch: 6| Step: 2
Training loss: 3.146554691563767
Validation loss: 2.5548150914190595

Epoch: 6| Step: 3
Training loss: 3.1649424895113123
Validation loss: 2.5615942950388932

Epoch: 6| Step: 4
Training loss: 2.6801852550815206
Validation loss: 2.559001822870649

Epoch: 6| Step: 5
Training loss: 2.690590168620047
Validation loss: 2.5589695953535863

Epoch: 6| Step: 6
Training loss: 3.048842513779307
Validation loss: 2.5575303910966283

Epoch: 6| Step: 7
Training loss: 3.1143942342826803
Validation loss: 2.5584058111271775

Epoch: 6| Step: 8
Training loss: 2.566775035634625
Validation loss: 2.5582759657011316

Epoch: 6| Step: 9
Training loss: 2.7801319403864686
Validation loss: 2.566261366204277

Epoch: 6| Step: 10
Training loss: 3.5286916732156666
Validation loss: 2.5602579931057337

Epoch: 6| Step: 11
Training loss: 2.739343456214638
Validation loss: 2.5604738788702064

Epoch: 6| Step: 12
Training loss: 2.2647545556476225
Validation loss: 2.562523772466816

Epoch: 6| Step: 13
Training loss: 2.1836752014800833
Validation loss: 2.571098254659922

Epoch: 353| Step: 0
Training loss: 3.4468150765682375
Validation loss: 2.575330459810415

Epoch: 6| Step: 1
Training loss: 2.449984830692586
Validation loss: 2.574590567341069

Epoch: 6| Step: 2
Training loss: 2.8963903719257997
Validation loss: 2.57650083989226

Epoch: 6| Step: 3
Training loss: 3.2437363934828727
Validation loss: 2.576271093095628

Epoch: 6| Step: 4
Training loss: 3.047556013636173
Validation loss: 2.5900792426999

Epoch: 6| Step: 5
Training loss: 2.5264430615297577
Validation loss: 2.5980372454585576

Epoch: 6| Step: 6
Training loss: 2.938115156977204
Validation loss: 2.598635361703612

Epoch: 6| Step: 7
Training loss: 2.8879088141292804
Validation loss: 2.607143090850548

Epoch: 6| Step: 8
Training loss: 2.988900154199685
Validation loss: 2.598580338206009

Epoch: 6| Step: 9
Training loss: 2.4882920772490595
Validation loss: 2.5869925071578974

Epoch: 6| Step: 10
Training loss: 2.8928497825676938
Validation loss: 2.6002501841438814

Epoch: 6| Step: 11
Training loss: 2.6443191060069338
Validation loss: 2.5738231308809496

Epoch: 6| Step: 12
Training loss: 2.8252683934010547
Validation loss: 2.568835328758778

Epoch: 6| Step: 13
Training loss: 3.4005758639324406
Validation loss: 2.5680825465951194

Epoch: 354| Step: 0
Training loss: 2.9445634693904212
Validation loss: 2.561875321956118

Epoch: 6| Step: 1
Training loss: 3.043182169686118
Validation loss: 2.5604072857456304

Epoch: 6| Step: 2
Training loss: 2.5092947789121123
Validation loss: 2.564012813734725

Epoch: 6| Step: 3
Training loss: 3.146745781011701
Validation loss: 2.5576137504220475

Epoch: 6| Step: 4
Training loss: 2.6452549179488574
Validation loss: 2.5608866995720545

Epoch: 6| Step: 5
Training loss: 2.6750123638687326
Validation loss: 2.562752083765379

Epoch: 6| Step: 6
Training loss: 2.9727128734033084
Validation loss: 2.5612204874067652

Epoch: 6| Step: 7
Training loss: 2.875815566111305
Validation loss: 2.5664940178150926

Epoch: 6| Step: 8
Training loss: 3.0050135681049146
Validation loss: 2.561780232714514

Epoch: 6| Step: 9
Training loss: 2.849955233841385
Validation loss: 2.5699259528455265

Epoch: 6| Step: 10
Training loss: 3.158703747234452
Validation loss: 2.569080098098836

Epoch: 6| Step: 11
Training loss: 2.5565240540532055
Validation loss: 2.5614230666432816

Epoch: 6| Step: 12
Training loss: 2.6028486858503905
Validation loss: 2.5789615093138836

Epoch: 6| Step: 13
Training loss: 3.8932591601931326
Validation loss: 2.588047698399383

Epoch: 355| Step: 0
Training loss: 3.08796829811189
Validation loss: 2.6137803903896435

Epoch: 6| Step: 1
Training loss: 2.5829858443654667
Validation loss: 2.6099339024710253

Epoch: 6| Step: 2
Training loss: 3.18834480609282
Validation loss: 2.6061381113795394

Epoch: 6| Step: 3
Training loss: 3.0827768871881793
Validation loss: 2.6124227673418643

Epoch: 6| Step: 4
Training loss: 3.1886860753810655
Validation loss: 2.58326691897071

Epoch: 6| Step: 5
Training loss: 2.912569292414805
Validation loss: 2.5777265472614244

Epoch: 6| Step: 6
Training loss: 2.506197590648591
Validation loss: 2.5616752173552553

Epoch: 6| Step: 7
Training loss: 2.853858838338897
Validation loss: 2.564402206631793

Epoch: 6| Step: 8
Training loss: 2.7994582537675754
Validation loss: 2.5604913403802025

Epoch: 6| Step: 9
Training loss: 3.3911517740458414
Validation loss: 2.558437287206508

Epoch: 6| Step: 10
Training loss: 2.6335192900400757
Validation loss: 2.5590936974680445

Epoch: 6| Step: 11
Training loss: 2.544351275189819
Validation loss: 2.556825369788232

Epoch: 6| Step: 12
Training loss: 3.325387177834684
Validation loss: 2.5653340124820905

Epoch: 6| Step: 13
Training loss: 1.8693750567294323
Validation loss: 2.5558004803241228

Epoch: 356| Step: 0
Training loss: 2.570874741116198
Validation loss: 2.552682845263905

Epoch: 6| Step: 1
Training loss: 2.666893581828967
Validation loss: 2.548472066999329

Epoch: 6| Step: 2
Training loss: 2.920496651204597
Validation loss: 2.5601051819219145

Epoch: 6| Step: 3
Training loss: 2.9719599987433982
Validation loss: 2.557545308607992

Epoch: 6| Step: 4
Training loss: 3.3007236091953103
Validation loss: 2.5550768903158816

Epoch: 6| Step: 5
Training loss: 2.6445101535693794
Validation loss: 2.5567714077659125

Epoch: 6| Step: 6
Training loss: 2.4850531078474
Validation loss: 2.570019557644325

Epoch: 6| Step: 7
Training loss: 2.816205275477178
Validation loss: 2.582271591611696

Epoch: 6| Step: 8
Training loss: 2.9533168185470537
Validation loss: 2.5987316278248995

Epoch: 6| Step: 9
Training loss: 2.9462212493749607
Validation loss: 2.5944578349245204

Epoch: 6| Step: 10
Training loss: 2.8400509429445995
Validation loss: 2.5965441279467494

Epoch: 6| Step: 11
Training loss: 2.794684889880794
Validation loss: 2.6024721055711293

Epoch: 6| Step: 12
Training loss: 3.192347412286517
Validation loss: 2.575553523966183

Epoch: 6| Step: 13
Training loss: 3.6852135762779343
Validation loss: 2.5957428656703554

Epoch: 357| Step: 0
Training loss: 3.156804404336957
Validation loss: 2.576579840378302

Epoch: 6| Step: 1
Training loss: 2.8172531653445776
Validation loss: 2.5763098090587926

Epoch: 6| Step: 2
Training loss: 2.608152548605406
Validation loss: 2.56598276387236

Epoch: 6| Step: 3
Training loss: 2.778655309878453
Validation loss: 2.5651481675032

Epoch: 6| Step: 4
Training loss: 2.7295084343769593
Validation loss: 2.560320567907517

Epoch: 6| Step: 5
Training loss: 2.8846180128427905
Validation loss: 2.5637481384963356

Epoch: 6| Step: 6
Training loss: 3.665157845755317
Validation loss: 2.559262466245461

Epoch: 6| Step: 7
Training loss: 2.96162925832548
Validation loss: 2.5573605236025156

Epoch: 6| Step: 8
Training loss: 2.6346910606109555
Validation loss: 2.563937731535354

Epoch: 6| Step: 9
Training loss: 2.2462428831264747
Validation loss: 2.5574783836131814

Epoch: 6| Step: 10
Training loss: 3.2381581465970815
Validation loss: 2.556358908294836

Epoch: 6| Step: 11
Training loss: 3.238942040919163
Validation loss: 2.5621500344033996

Epoch: 6| Step: 12
Training loss: 2.6707934594314655
Validation loss: 2.5572948358466547

Epoch: 6| Step: 13
Training loss: 2.558461426086861
Validation loss: 2.552825975049206

Epoch: 358| Step: 0
Training loss: 2.4546958607531866
Validation loss: 2.560285291479731

Epoch: 6| Step: 1
Training loss: 2.1920935221163784
Validation loss: 2.5604139891914777

Epoch: 6| Step: 2
Training loss: 3.600251528112144
Validation loss: 2.564388970529623

Epoch: 6| Step: 3
Training loss: 2.5645420032913298
Validation loss: 2.590874367836301

Epoch: 6| Step: 4
Training loss: 3.041674121864972
Validation loss: 2.6013294369198334

Epoch: 6| Step: 5
Training loss: 2.782325450978216
Validation loss: 2.5988097098526883

Epoch: 6| Step: 6
Training loss: 3.108581441704868
Validation loss: 2.6226210882311145

Epoch: 6| Step: 7
Training loss: 2.75311146623487
Validation loss: 2.601820821839031

Epoch: 6| Step: 8
Training loss: 2.914666898091625
Validation loss: 2.604119279655909

Epoch: 6| Step: 9
Training loss: 2.3175577064745023
Validation loss: 2.600703305393647

Epoch: 6| Step: 10
Training loss: 3.582551708287504
Validation loss: 2.619911762740935

Epoch: 6| Step: 11
Training loss: 2.8171180111423078
Validation loss: 2.613145567670905

Epoch: 6| Step: 12
Training loss: 3.335733376183178
Validation loss: 2.5982201656748005

Epoch: 6| Step: 13
Training loss: 2.6312196707166824
Validation loss: 2.5775441917274637

Epoch: 359| Step: 0
Training loss: 2.6319919292245046
Validation loss: 2.5513301847218903

Epoch: 6| Step: 1
Training loss: 3.3958747408786008
Validation loss: 2.549121527466377

Epoch: 6| Step: 2
Training loss: 2.728868181829692
Validation loss: 2.5548263320913565

Epoch: 6| Step: 3
Training loss: 3.2247109631086723
Validation loss: 2.555855047621723

Epoch: 6| Step: 4
Training loss: 3.0478684590808482
Validation loss: 2.549984234224885

Epoch: 6| Step: 5
Training loss: 2.474668048985002
Validation loss: 2.5526056235313863

Epoch: 6| Step: 6
Training loss: 2.913572541228883
Validation loss: 2.552546703738181

Epoch: 6| Step: 7
Training loss: 2.892273798664371
Validation loss: 2.5523917193720496

Epoch: 6| Step: 8
Training loss: 2.509764675036299
Validation loss: 2.5527502896548544

Epoch: 6| Step: 9
Training loss: 2.729086683037964
Validation loss: 2.5523413277650855

Epoch: 6| Step: 10
Training loss: 3.1109458750789765
Validation loss: 2.550836938733401

Epoch: 6| Step: 11
Training loss: 2.6163709590852045
Validation loss: 2.5497919487172416

Epoch: 6| Step: 12
Training loss: 3.1743665408693773
Validation loss: 2.5611913517363187

Epoch: 6| Step: 13
Training loss: 3.182676967306399
Validation loss: 2.5645085178460167

Epoch: 360| Step: 0
Training loss: 2.7872612102507905
Validation loss: 2.566563352706401

Epoch: 6| Step: 1
Training loss: 2.4593092603028355
Validation loss: 2.567161855511564

Epoch: 6| Step: 2
Training loss: 3.4279755857971463
Validation loss: 2.569074858211331

Epoch: 6| Step: 3
Training loss: 2.876806603745125
Validation loss: 2.583836266038544

Epoch: 6| Step: 4
Training loss: 3.266323179234727
Validation loss: 2.5723227222688556

Epoch: 6| Step: 5
Training loss: 2.7203722093263987
Validation loss: 2.5668817729117483

Epoch: 6| Step: 6
Training loss: 2.928377311201173
Validation loss: 2.5652977801588066

Epoch: 6| Step: 7
Training loss: 2.7021008795112404
Validation loss: 2.562989973179977

Epoch: 6| Step: 8
Training loss: 3.0807406548065246
Validation loss: 2.559296184607726

Epoch: 6| Step: 9
Training loss: 2.9571621864587483
Validation loss: 2.566788075658254

Epoch: 6| Step: 10
Training loss: 2.6953326680631315
Validation loss: 2.561041784477832

Epoch: 6| Step: 11
Training loss: 2.720622503067858
Validation loss: 2.5514596963577336

Epoch: 6| Step: 12
Training loss: 3.019499982151335
Validation loss: 2.5611701794210133

Epoch: 6| Step: 13
Training loss: 2.8216467578123243
Validation loss: 2.561719211706086

Epoch: 361| Step: 0
Training loss: 3.031175750137668
Validation loss: 2.5517097924708985

Epoch: 6| Step: 1
Training loss: 3.2051046069327964
Validation loss: 2.55791136080224

Epoch: 6| Step: 2
Training loss: 2.5689878441807745
Validation loss: 2.552333959277711

Epoch: 6| Step: 3
Training loss: 2.8426345482002398
Validation loss: 2.5485136064436924

Epoch: 6| Step: 4
Training loss: 2.724207432129621
Validation loss: 2.5634120325579355

Epoch: 6| Step: 5
Training loss: 2.8931830557311313
Validation loss: 2.558999335368399

Epoch: 6| Step: 6
Training loss: 2.9216249736357787
Validation loss: 2.563217834885785

Epoch: 6| Step: 7
Training loss: 2.7268102145318878
Validation loss: 2.5673578627979725

Epoch: 6| Step: 8
Training loss: 3.115105031356772
Validation loss: 2.5643294442144637

Epoch: 6| Step: 9
Training loss: 3.707847963493884
Validation loss: 2.566050297284687

Epoch: 6| Step: 10
Training loss: 3.233143300112146
Validation loss: 2.585802649296301

Epoch: 6| Step: 11
Training loss: 2.8678814206794905
Validation loss: 2.5788667796885334

Epoch: 6| Step: 12
Training loss: 2.208740220882095
Validation loss: 2.5879308699986185

Epoch: 6| Step: 13
Training loss: 1.5383500517284199
Validation loss: 2.5851690384001556

Epoch: 362| Step: 0
Training loss: 2.8670268416543645
Validation loss: 2.6131209430637137

Epoch: 6| Step: 1
Training loss: 2.6708455919132215
Validation loss: 2.6143699146749726

Epoch: 6| Step: 2
Training loss: 2.651770730685003
Validation loss: 2.628812240584568

Epoch: 6| Step: 3
Training loss: 3.0533881582588083
Validation loss: 2.6191600895402987

Epoch: 6| Step: 4
Training loss: 3.311524733439366
Validation loss: 2.5794893663820386

Epoch: 6| Step: 5
Training loss: 2.410457548972383
Validation loss: 2.5767973453605335

Epoch: 6| Step: 6
Training loss: 3.0008311709716033
Validation loss: 2.5731870922550923

Epoch: 6| Step: 7
Training loss: 2.8048025973619706
Validation loss: 2.5668951539595515

Epoch: 6| Step: 8
Training loss: 3.1457007845475897
Validation loss: 2.5536631379132

Epoch: 6| Step: 9
Training loss: 2.9898805016461
Validation loss: 2.555035919125767

Epoch: 6| Step: 10
Training loss: 3.273369617714261
Validation loss: 2.551680103128728

Epoch: 6| Step: 11
Training loss: 3.3041441991618616
Validation loss: 2.5551866014542686

Epoch: 6| Step: 12
Training loss: 2.3956071387505133
Validation loss: 2.550746494428235

Epoch: 6| Step: 13
Training loss: 2.6595409874939238
Validation loss: 2.556772158778126

Epoch: 363| Step: 0
Training loss: 2.8789524607786317
Validation loss: 2.554042642828205

Epoch: 6| Step: 1
Training loss: 2.5022923450269494
Validation loss: 2.5733579513183695

Epoch: 6| Step: 2
Training loss: 3.3823817025056933
Validation loss: 2.595265467262891

Epoch: 6| Step: 3
Training loss: 3.4572218675378408
Validation loss: 2.6300758493335454

Epoch: 6| Step: 4
Training loss: 2.8211959342863424
Validation loss: 2.6723798711283404

Epoch: 6| Step: 5
Training loss: 2.9165332945347773
Validation loss: 2.691181680177847

Epoch: 6| Step: 6
Training loss: 3.6207630784242935
Validation loss: 2.737098423752738

Epoch: 6| Step: 7
Training loss: 2.4027806822870104
Validation loss: 2.711112081290617

Epoch: 6| Step: 8
Training loss: 2.888646453890003
Validation loss: 2.7133595011011833

Epoch: 6| Step: 9
Training loss: 2.8200494109890917
Validation loss: 2.703012768892481

Epoch: 6| Step: 10
Training loss: 3.2608291966247704
Validation loss: 2.67109303742688

Epoch: 6| Step: 11
Training loss: 2.2373539200306602
Validation loss: 2.622176086549626

Epoch: 6| Step: 12
Training loss: 2.69658005251926
Validation loss: 2.59577872439215

Epoch: 6| Step: 13
Training loss: 2.660300274729771
Validation loss: 2.5708015835091964

Epoch: 364| Step: 0
Training loss: 2.982944485205658
Validation loss: 2.5588260097146773

Epoch: 6| Step: 1
Training loss: 2.8991668688306294
Validation loss: 2.5531177292060794

Epoch: 6| Step: 2
Training loss: 2.904196228869325
Validation loss: 2.5627837485447627

Epoch: 6| Step: 3
Training loss: 2.817326960018307
Validation loss: 2.5738049022183622

Epoch: 6| Step: 4
Training loss: 3.424811788246488
Validation loss: 2.580628545240392

Epoch: 6| Step: 5
Training loss: 2.822136033194707
Validation loss: 2.57766889140294

Epoch: 6| Step: 6
Training loss: 3.1490744426864627
Validation loss: 2.580547417050922

Epoch: 6| Step: 7
Training loss: 3.3850414518131333
Validation loss: 2.5649675183679372

Epoch: 6| Step: 8
Training loss: 3.0914850131922025
Validation loss: 2.5609625459264

Epoch: 6| Step: 9
Training loss: 2.730635871193258
Validation loss: 2.5533821740265585

Epoch: 6| Step: 10
Training loss: 2.929799802535076
Validation loss: 2.544640114202673

Epoch: 6| Step: 11
Training loss: 2.8689248956294926
Validation loss: 2.5425863590767923

Epoch: 6| Step: 12
Training loss: 2.684339394738493
Validation loss: 2.556486785325557

Epoch: 6| Step: 13
Training loss: 1.2480891881703837
Validation loss: 2.5659510166798523

Epoch: 365| Step: 0
Training loss: 2.1699934019700398
Validation loss: 2.5819446080732043

Epoch: 6| Step: 1
Training loss: 2.996398989808922
Validation loss: 2.5810096271853737

Epoch: 6| Step: 2
Training loss: 2.5269631713912792
Validation loss: 2.5965253775336237

Epoch: 6| Step: 3
Training loss: 3.5928930173002156
Validation loss: 2.58619740633036

Epoch: 6| Step: 4
Training loss: 3.178051576919658
Validation loss: 2.601287765208685

Epoch: 6| Step: 5
Training loss: 3.158270613987851
Validation loss: 2.5661120245218134

Epoch: 6| Step: 6
Training loss: 2.0964119913091244
Validation loss: 2.5562806809053855

Epoch: 6| Step: 7
Training loss: 3.0711322495738536
Validation loss: 2.5483517583331206

Epoch: 6| Step: 8
Training loss: 2.9537215664690066
Validation loss: 2.5411371102708467

Epoch: 6| Step: 9
Training loss: 3.38156337449306
Validation loss: 2.542303844316047

Epoch: 6| Step: 10
Training loss: 3.2583701116204953
Validation loss: 2.542491241142175

Epoch: 6| Step: 11
Training loss: 2.7328415412733817
Validation loss: 2.5384708888424794

Epoch: 6| Step: 12
Training loss: 2.442767882011003
Validation loss: 2.545452513610384

Epoch: 6| Step: 13
Training loss: 2.6009110101819597
Validation loss: 2.538136330326869

Epoch: 366| Step: 0
Training loss: 2.8754401492007693
Validation loss: 2.5455666991735586

Epoch: 6| Step: 1
Training loss: 3.495830777470075
Validation loss: 2.54525392298845

Epoch: 6| Step: 2
Training loss: 3.155176263350055
Validation loss: 2.545590383037895

Epoch: 6| Step: 3
Training loss: 2.90291625751704
Validation loss: 2.5544291557539696

Epoch: 6| Step: 4
Training loss: 2.672297126485088
Validation loss: 2.560728840134744

Epoch: 6| Step: 5
Training loss: 2.788860324402622
Validation loss: 2.54807760066975

Epoch: 6| Step: 6
Training loss: 3.3012276071166706
Validation loss: 2.57694539827176

Epoch: 6| Step: 7
Training loss: 2.5038660674062223
Validation loss: 2.55346194699862

Epoch: 6| Step: 8
Training loss: 2.9337177682153546
Validation loss: 2.558400646576224

Epoch: 6| Step: 9
Training loss: 3.3046880771645477
Validation loss: 2.558502812363659

Epoch: 6| Step: 10
Training loss: 2.6178229172676817
Validation loss: 2.552987464201296

Epoch: 6| Step: 11
Training loss: 2.5263041461500593
Validation loss: 2.556653701672451

Epoch: 6| Step: 12
Training loss: 2.787914820027988
Validation loss: 2.5634691310136137

Epoch: 6| Step: 13
Training loss: 1.930660975236214
Validation loss: 2.558373598147521

Epoch: 367| Step: 0
Training loss: 2.9385510451365393
Validation loss: 2.548008590804303

Epoch: 6| Step: 1
Training loss: 2.1398717292775356
Validation loss: 2.5530216590695205

Epoch: 6| Step: 2
Training loss: 3.2178494573247027
Validation loss: 2.556729260486597

Epoch: 6| Step: 3
Training loss: 2.5389712273258387
Validation loss: 2.563067354651857

Epoch: 6| Step: 4
Training loss: 3.0025114037950686
Validation loss: 2.5657385763313227

Epoch: 6| Step: 5
Training loss: 3.046710670147852
Validation loss: 2.561031888426763

Epoch: 6| Step: 6
Training loss: 3.3529126842221193
Validation loss: 2.580626555921797

Epoch: 6| Step: 7
Training loss: 2.3572147407965436
Validation loss: 2.572875133941596

Epoch: 6| Step: 8
Training loss: 2.941643086051626
Validation loss: 2.570385684493047

Epoch: 6| Step: 9
Training loss: 2.9363027527131496
Validation loss: 2.559062694292559

Epoch: 6| Step: 10
Training loss: 3.0529457063067365
Validation loss: 2.5625841680670494

Epoch: 6| Step: 11
Training loss: 2.330144121845376
Validation loss: 2.5561987754546753

Epoch: 6| Step: 12
Training loss: 3.466271967304118
Validation loss: 2.5569986084782794

Epoch: 6| Step: 13
Training loss: 2.7163680593127997
Validation loss: 2.5483202874559363

Epoch: 368| Step: 0
Training loss: 2.307540214246016
Validation loss: 2.5477738225326623

Epoch: 6| Step: 1
Training loss: 3.484171634777888
Validation loss: 2.5481933366530884

Epoch: 6| Step: 2
Training loss: 2.8521955231659986
Validation loss: 2.5431032449706112

Epoch: 6| Step: 3
Training loss: 2.782227076660623
Validation loss: 2.5491738945108433

Epoch: 6| Step: 4
Training loss: 3.262932210187084
Validation loss: 2.550252090088186

Epoch: 6| Step: 5
Training loss: 2.8953508665833576
Validation loss: 2.5444329343093224

Epoch: 6| Step: 6
Training loss: 2.9145391243196483
Validation loss: 2.549938996848239

Epoch: 6| Step: 7
Training loss: 2.59161472902253
Validation loss: 2.554944909040062

Epoch: 6| Step: 8
Training loss: 2.537693534949687
Validation loss: 2.5627976551552747

Epoch: 6| Step: 9
Training loss: 3.3761920942914596
Validation loss: 2.5709126937401923

Epoch: 6| Step: 10
Training loss: 3.067189266070238
Validation loss: 2.5819088104126817

Epoch: 6| Step: 11
Training loss: 2.830810789015325
Validation loss: 2.5888402939944757

Epoch: 6| Step: 12
Training loss: 2.3670705634212883
Validation loss: 2.5988813313195536

Epoch: 6| Step: 13
Training loss: 2.949904850863904
Validation loss: 2.589668949684486

Epoch: 369| Step: 0
Training loss: 2.7686843760960684
Validation loss: 2.579765033354908

Epoch: 6| Step: 1
Training loss: 2.617270306088589
Validation loss: 2.575719641657909

Epoch: 6| Step: 2
Training loss: 2.7080076364158794
Validation loss: 2.581571694492378

Epoch: 6| Step: 3
Training loss: 3.2929743973761627
Validation loss: 2.5977460854461665

Epoch: 6| Step: 4
Training loss: 3.09019404570527
Validation loss: 2.582190147205611

Epoch: 6| Step: 5
Training loss: 2.345704649607904
Validation loss: 2.553709164632575

Epoch: 6| Step: 6
Training loss: 3.1491191116730395
Validation loss: 2.55367920338849

Epoch: 6| Step: 7
Training loss: 3.4177354831115196
Validation loss: 2.547996038233065

Epoch: 6| Step: 8
Training loss: 2.8856942677916395
Validation loss: 2.5358718996319816

Epoch: 6| Step: 9
Training loss: 2.881718952799666
Validation loss: 2.5431591431630483

Epoch: 6| Step: 10
Training loss: 2.0320346197197887
Validation loss: 2.547154199700026

Epoch: 6| Step: 11
Training loss: 3.1363269756019037
Validation loss: 2.545759250449198

Epoch: 6| Step: 12
Training loss: 3.023288456991368
Validation loss: 2.5462034764364114

Epoch: 6| Step: 13
Training loss: 2.7832397886839497
Validation loss: 2.5446878032080154

Epoch: 370| Step: 0
Training loss: 2.9329691906522695
Validation loss: 2.54969052482303

Epoch: 6| Step: 1
Training loss: 2.7329453572890428
Validation loss: 2.557637974255623

Epoch: 6| Step: 2
Training loss: 2.5371806051755184
Validation loss: 2.5661520646098706

Epoch: 6| Step: 3
Training loss: 3.1191277835130147
Validation loss: 2.5864864240511753

Epoch: 6| Step: 4
Training loss: 3.2984421607580465
Validation loss: 2.5788406447775114

Epoch: 6| Step: 5
Training loss: 2.7747778863767794
Validation loss: 2.5806797350213366

Epoch: 6| Step: 6
Training loss: 2.253094558404358
Validation loss: 2.5763386981300442

Epoch: 6| Step: 7
Training loss: 3.0103490661282066
Validation loss: 2.596589172419883

Epoch: 6| Step: 8
Training loss: 3.3627142345150673
Validation loss: 2.567418340393328

Epoch: 6| Step: 9
Training loss: 2.8819919648650782
Validation loss: 2.562131175368651

Epoch: 6| Step: 10
Training loss: 2.6085099482435274
Validation loss: 2.5453365613479364

Epoch: 6| Step: 11
Training loss: 3.1332123232531575
Validation loss: 2.543354153728595

Epoch: 6| Step: 12
Training loss: 2.742189673615814
Validation loss: 2.5474404233888714

Epoch: 6| Step: 13
Training loss: 2.7641471750628104
Validation loss: 2.5498802461760928

Epoch: 371| Step: 0
Training loss: 3.168266912650726
Validation loss: 2.5467823111601597

Epoch: 6| Step: 1
Training loss: 3.0480009688328282
Validation loss: 2.545550196776811

Epoch: 6| Step: 2
Training loss: 2.598732265101804
Validation loss: 2.554762261001642

Epoch: 6| Step: 3
Training loss: 2.7722509290508044
Validation loss: 2.5412781080659452

Epoch: 6| Step: 4
Training loss: 2.9592616993082372
Validation loss: 2.5430547651390536

Epoch: 6| Step: 5
Training loss: 3.2929699084369255
Validation loss: 2.5454545752360587

Epoch: 6| Step: 6
Training loss: 2.768521015695811
Validation loss: 2.5447945340405402

Epoch: 6| Step: 7
Training loss: 2.6026532976511985
Validation loss: 2.5459549318582546

Epoch: 6| Step: 8
Training loss: 2.9571531565442744
Validation loss: 2.5574451224471733

Epoch: 6| Step: 9
Training loss: 2.9014094249176514
Validation loss: 2.544841708399556

Epoch: 6| Step: 10
Training loss: 2.6274187660907815
Validation loss: 2.5675323458633255

Epoch: 6| Step: 11
Training loss: 3.2201832663467873
Validation loss: 2.56787953330935

Epoch: 6| Step: 12
Training loss: 2.159854695413062
Validation loss: 2.5874894781435245

Epoch: 6| Step: 13
Training loss: 3.246688916745665
Validation loss: 2.5914531362082593

Epoch: 372| Step: 0
Training loss: 2.8440964037173027
Validation loss: 2.616495121245177

Epoch: 6| Step: 1
Training loss: 2.547105556420003
Validation loss: 2.6323151872021198

Epoch: 6| Step: 2
Training loss: 3.1597657215817763
Validation loss: 2.620132431629194

Epoch: 6| Step: 3
Training loss: 2.72196340844353
Validation loss: 2.6203433169353105

Epoch: 6| Step: 4
Training loss: 3.074878200196704
Validation loss: 2.602982455993834

Epoch: 6| Step: 5
Training loss: 2.903588501687832
Validation loss: 2.585360485557

Epoch: 6| Step: 6
Training loss: 2.782414738941695
Validation loss: 2.567480147571043

Epoch: 6| Step: 7
Training loss: 3.1038686792772405
Validation loss: 2.56041792364043

Epoch: 6| Step: 8
Training loss: 2.454838051358671
Validation loss: 2.5654617109522326

Epoch: 6| Step: 9
Training loss: 3.3284742861570074
Validation loss: 2.5493335695919646

Epoch: 6| Step: 10
Training loss: 3.0612826360642775
Validation loss: 2.5437335317340195

Epoch: 6| Step: 11
Training loss: 2.6821066388258488
Validation loss: 2.54236134524266

Epoch: 6| Step: 12
Training loss: 3.0318665811378165
Validation loss: 2.5411293582118923

Epoch: 6| Step: 13
Training loss: 2.4803888743598446
Validation loss: 2.5377102369393345

Epoch: 373| Step: 0
Training loss: 2.54461682146181
Validation loss: 2.5430934827465985

Epoch: 6| Step: 1
Training loss: 3.165196646416434
Validation loss: 2.5496890528126284

Epoch: 6| Step: 2
Training loss: 3.0423807499130358
Validation loss: 2.5371572444567687

Epoch: 6| Step: 3
Training loss: 3.082219377971872
Validation loss: 2.5498106768173012

Epoch: 6| Step: 4
Training loss: 3.0520532669478606
Validation loss: 2.5534005645506612

Epoch: 6| Step: 5
Training loss: 3.054570422648485
Validation loss: 2.538433982228799

Epoch: 6| Step: 6
Training loss: 3.232657008536301
Validation loss: 2.543395627582086

Epoch: 6| Step: 7
Training loss: 2.824362427999428
Validation loss: 2.545596113378053

Epoch: 6| Step: 8
Training loss: 2.6959080134979443
Validation loss: 2.5572518089808476

Epoch: 6| Step: 9
Training loss: 3.0807750157835248
Validation loss: 2.5699441322104395

Epoch: 6| Step: 10
Training loss: 2.3820851701168095
Validation loss: 2.559222956466456

Epoch: 6| Step: 11
Training loss: 2.543571529641698
Validation loss: 2.580975624333526

Epoch: 6| Step: 12
Training loss: 2.3658395082886523
Validation loss: 2.5784111085444072

Epoch: 6| Step: 13
Training loss: 3.213627266426449
Validation loss: 2.5806721961171726

Epoch: 374| Step: 0
Training loss: 2.5770021710044353
Validation loss: 2.591000722448656

Epoch: 6| Step: 1
Training loss: 2.8140999375839013
Validation loss: 2.6068414516254497

Epoch: 6| Step: 2
Training loss: 3.236342122169112
Validation loss: 2.606192738739669

Epoch: 6| Step: 3
Training loss: 3.171130764846948
Validation loss: 2.6027180110466985

Epoch: 6| Step: 4
Training loss: 3.1926904940249385
Validation loss: 2.589739138109594

Epoch: 6| Step: 5
Training loss: 2.2741838521320874
Validation loss: 2.582546766045686

Epoch: 6| Step: 6
Training loss: 2.9663871597748743
Validation loss: 2.5788544856764655

Epoch: 6| Step: 7
Training loss: 2.8658327649260062
Validation loss: 2.5626410838900644

Epoch: 6| Step: 8
Training loss: 2.7620422950727073
Validation loss: 2.5680205063389434

Epoch: 6| Step: 9
Training loss: 3.189870812840593
Validation loss: 2.5517688888163046

Epoch: 6| Step: 10
Training loss: 2.3426287194125752
Validation loss: 2.5499046450212477

Epoch: 6| Step: 11
Training loss: 2.7550779623088086
Validation loss: 2.537636590976343

Epoch: 6| Step: 12
Training loss: 2.754929545863803
Validation loss: 2.548483812468102

Epoch: 6| Step: 13
Training loss: 3.4239189279530717
Validation loss: 2.550556126883578

Epoch: 375| Step: 0
Training loss: 3.1941569507615983
Validation loss: 2.542227495741591

Epoch: 6| Step: 1
Training loss: 2.94975548716873
Validation loss: 2.5406764128947934

Epoch: 6| Step: 2
Training loss: 3.012225354603148
Validation loss: 2.550488712924602

Epoch: 6| Step: 3
Training loss: 2.5648766637823033
Validation loss: 2.5481564682361526

Epoch: 6| Step: 4
Training loss: 3.0813628077410304
Validation loss: 2.547677110138798

Epoch: 6| Step: 5
Training loss: 3.499748902169249
Validation loss: 2.5512162882677765

Epoch: 6| Step: 6
Training loss: 2.414426411973293
Validation loss: 2.550637554185417

Epoch: 6| Step: 7
Training loss: 2.748257258210357
Validation loss: 2.542635019243776

Epoch: 6| Step: 8
Training loss: 3.1921739903788255
Validation loss: 2.563610718575775

Epoch: 6| Step: 9
Training loss: 2.7924861464331814
Validation loss: 2.573182401717374

Epoch: 6| Step: 10
Training loss: 2.6639307610389156
Validation loss: 2.5696051338285053

Epoch: 6| Step: 11
Training loss: 2.6476298763417003
Validation loss: 2.564756664829888

Epoch: 6| Step: 12
Training loss: 2.67546598707325
Validation loss: 2.5628176686580266

Epoch: 6| Step: 13
Training loss: 2.7339435345972696
Validation loss: 2.5555138547395138

Epoch: 376| Step: 0
Training loss: 2.8899833998153857
Validation loss: 2.565387256759412

Epoch: 6| Step: 1
Training loss: 2.5755061864998923
Validation loss: 2.550670642801161

Epoch: 6| Step: 2
Training loss: 3.0555326653596078
Validation loss: 2.55435236869855

Epoch: 6| Step: 3
Training loss: 3.019345217324749
Validation loss: 2.5662080411622274

Epoch: 6| Step: 4
Training loss: 3.0013731357110642
Validation loss: 2.552473641526704

Epoch: 6| Step: 5
Training loss: 3.0749375934005725
Validation loss: 2.545409508644688

Epoch: 6| Step: 6
Training loss: 2.3087174693874064
Validation loss: 2.574297214040295

Epoch: 6| Step: 7
Training loss: 2.419876356828263
Validation loss: 2.575928818553485

Epoch: 6| Step: 8
Training loss: 2.8044909565100196
Validation loss: 2.5677124890694416

Epoch: 6| Step: 9
Training loss: 3.0301648586734924
Validation loss: 2.5512808483367544

Epoch: 6| Step: 10
Training loss: 3.000695783673718
Validation loss: 2.561573424294564

Epoch: 6| Step: 11
Training loss: 2.8762671953638064
Validation loss: 2.5553884200409085

Epoch: 6| Step: 12
Training loss: 3.0505077127091242
Validation loss: 2.5594529514781597

Epoch: 6| Step: 13
Training loss: 3.1883923646520795
Validation loss: 2.552137761459592

Epoch: 377| Step: 0
Training loss: 2.5353341767540987
Validation loss: 2.546099062113354

Epoch: 6| Step: 1
Training loss: 3.001977745456536
Validation loss: 2.5523335896474677

Epoch: 6| Step: 2
Training loss: 2.9329083857360927
Validation loss: 2.545758490145973

Epoch: 6| Step: 3
Training loss: 3.133431161881882
Validation loss: 2.5498690591048687

Epoch: 6| Step: 4
Training loss: 2.9047240486328567
Validation loss: 2.559849861101176

Epoch: 6| Step: 5
Training loss: 2.5476637478986857
Validation loss: 2.5555801941782343

Epoch: 6| Step: 6
Training loss: 3.268434183243235
Validation loss: 2.565564990507495

Epoch: 6| Step: 7
Training loss: 3.18696649611942
Validation loss: 2.559380548185609

Epoch: 6| Step: 8
Training loss: 2.1401910272348683
Validation loss: 2.5670027571001417

Epoch: 6| Step: 9
Training loss: 2.9317855443340854
Validation loss: 2.56445496941479

Epoch: 6| Step: 10
Training loss: 2.7722991756426287
Validation loss: 2.57242083512009

Epoch: 6| Step: 11
Training loss: 2.9857666605529527
Validation loss: 2.593901363798849

Epoch: 6| Step: 12
Training loss: 2.8961694279948222
Validation loss: 2.5663455038123164

Epoch: 6| Step: 13
Training loss: 2.852924345717512
Validation loss: 2.570334237336512

Epoch: 378| Step: 0
Training loss: 3.779456351609409
Validation loss: 2.569580582331804

Epoch: 6| Step: 1
Training loss: 1.9886920257308738
Validation loss: 2.573029732400501

Epoch: 6| Step: 2
Training loss: 2.7443963959984243
Validation loss: 2.576064809109218

Epoch: 6| Step: 3
Training loss: 2.7069974294424095
Validation loss: 2.5513510226999405

Epoch: 6| Step: 4
Training loss: 2.884567098947022
Validation loss: 2.5633736858517198

Epoch: 6| Step: 5
Training loss: 2.8375199371847413
Validation loss: 2.562286621181738

Epoch: 6| Step: 6
Training loss: 2.8765934384581815
Validation loss: 2.5473165727577043

Epoch: 6| Step: 7
Training loss: 2.367061397605516
Validation loss: 2.561068984907547

Epoch: 6| Step: 8
Training loss: 2.4196376187152695
Validation loss: 2.5609888873084152

Epoch: 6| Step: 9
Training loss: 3.3934972173640885
Validation loss: 2.5546115636790017

Epoch: 6| Step: 10
Training loss: 3.3168126947917247
Validation loss: 2.5430621151486243

Epoch: 6| Step: 11
Training loss: 2.392825640896029
Validation loss: 2.5364026496473584

Epoch: 6| Step: 12
Training loss: 3.1858698846621265
Validation loss: 2.5378642723300744

Epoch: 6| Step: 13
Training loss: 3.1132207503237836
Validation loss: 2.539694347786908

Epoch: 379| Step: 0
Training loss: 3.2753073511701016
Validation loss: 2.5494920994074253

Epoch: 6| Step: 1
Training loss: 2.7059056968243
Validation loss: 2.570780242032934

Epoch: 6| Step: 2
Training loss: 2.898504127908807
Validation loss: 2.5660217054997365

Epoch: 6| Step: 3
Training loss: 2.8032488094957704
Validation loss: 2.5871313130353197

Epoch: 6| Step: 4
Training loss: 3.324482675333675
Validation loss: 2.5983375388066703

Epoch: 6| Step: 5
Training loss: 2.6505889705915795
Validation loss: 2.6161485637836335

Epoch: 6| Step: 6
Training loss: 2.5913491225249428
Validation loss: 2.6698510108465667

Epoch: 6| Step: 7
Training loss: 2.2933840010095183
Validation loss: 2.705574527155494

Epoch: 6| Step: 8
Training loss: 2.760375304482026
Validation loss: 2.7320811204553297

Epoch: 6| Step: 9
Training loss: 2.8103804336900495
Validation loss: 2.7586550771759586

Epoch: 6| Step: 10
Training loss: 3.0985421721398754
Validation loss: 2.7469456529199467

Epoch: 6| Step: 11
Training loss: 3.10282906679911
Validation loss: 2.6885990596034017

Epoch: 6| Step: 12
Training loss: 3.0087836741269505
Validation loss: 2.6439835665663445

Epoch: 6| Step: 13
Training loss: 3.015003041381314
Validation loss: 2.607416469311354

Epoch: 380| Step: 0
Training loss: 3.106451912962573
Validation loss: 2.5671743573095704

Epoch: 6| Step: 1
Training loss: 2.994012102029992
Validation loss: 2.5501061748974214

Epoch: 6| Step: 2
Training loss: 2.9772307679543917
Validation loss: 2.5495449726656467

Epoch: 6| Step: 3
Training loss: 3.060540331338729
Validation loss: 2.552455456248728

Epoch: 6| Step: 4
Training loss: 2.768529885801607
Validation loss: 2.534663725289546

Epoch: 6| Step: 5
Training loss: 3.227499615634508
Validation loss: 2.5334711218566284

Epoch: 6| Step: 6
Training loss: 3.2025856122165823
Validation loss: 2.538749845453084

Epoch: 6| Step: 7
Training loss: 2.5716261825621847
Validation loss: 2.544174744861387

Epoch: 6| Step: 8
Training loss: 1.874360674898434
Validation loss: 2.5389032159637726

Epoch: 6| Step: 9
Training loss: 2.8336602938621174
Validation loss: 2.541357408574391

Epoch: 6| Step: 10
Training loss: 2.468027902578347
Validation loss: 2.536392551335649

Epoch: 6| Step: 11
Training loss: 3.036576457967592
Validation loss: 2.5309404543187264

Epoch: 6| Step: 12
Training loss: 3.1300749197576563
Validation loss: 2.5323532274850735

Epoch: 6| Step: 13
Training loss: 3.138895953760289
Validation loss: 2.5294894799937904

Epoch: 381| Step: 0
Training loss: 2.7413121752769745
Validation loss: 2.5402011253724086

Epoch: 6| Step: 1
Training loss: 3.005051492513273
Validation loss: 2.547189534691195

Epoch: 6| Step: 2
Training loss: 2.588870226593133
Validation loss: 2.5606222248236308

Epoch: 6| Step: 3
Training loss: 2.5496903287561197
Validation loss: 2.5602361832355305

Epoch: 6| Step: 4
Training loss: 3.1416572658354323
Validation loss: 2.5829777722647567

Epoch: 6| Step: 5
Training loss: 3.20745081137614
Validation loss: 2.5774576774660085

Epoch: 6| Step: 6
Training loss: 2.8452442980096535
Validation loss: 2.5865555709189056

Epoch: 6| Step: 7
Training loss: 2.9548238076289524
Validation loss: 2.5963564024689005

Epoch: 6| Step: 8
Training loss: 2.2616322028116502
Validation loss: 2.622932180211702

Epoch: 6| Step: 9
Training loss: 2.893893811337311
Validation loss: 2.599895491720163

Epoch: 6| Step: 10
Training loss: 2.9002854042361745
Validation loss: 2.58067037720051

Epoch: 6| Step: 11
Training loss: 2.8449974258491655
Validation loss: 2.5922767180196336

Epoch: 6| Step: 12
Training loss: 3.3120852516646417
Validation loss: 2.604040303435699

Epoch: 6| Step: 13
Training loss: 3.016623850425514
Validation loss: 2.5856697487425797

Epoch: 382| Step: 0
Training loss: 2.773384716982322
Validation loss: 2.5789114320971236

Epoch: 6| Step: 1
Training loss: 3.2272493310292756
Validation loss: 2.5619216074102797

Epoch: 6| Step: 2
Training loss: 3.076234498370507
Validation loss: 2.5511837614243604

Epoch: 6| Step: 3
Training loss: 3.1905712216559254
Validation loss: 2.5475526088590366

Epoch: 6| Step: 4
Training loss: 2.930223583765323
Validation loss: 2.547953485200348

Epoch: 6| Step: 5
Training loss: 2.710383729688142
Validation loss: 2.541123030641817

Epoch: 6| Step: 6
Training loss: 2.208356449318106
Validation loss: 2.5332229300644347

Epoch: 6| Step: 7
Training loss: 2.638561458239829
Validation loss: 2.5298687032111418

Epoch: 6| Step: 8
Training loss: 3.0629855958187058
Validation loss: 2.533271084972202

Epoch: 6| Step: 9
Training loss: 3.1513567470097428
Validation loss: 2.529468034217385

Epoch: 6| Step: 10
Training loss: 2.7652318642717093
Validation loss: 2.529434096614142

Epoch: 6| Step: 11
Training loss: 3.0680581861048846
Validation loss: 2.5377995527844566

Epoch: 6| Step: 12
Training loss: 2.850714235989542
Validation loss: 2.5421016737091655

Epoch: 6| Step: 13
Training loss: 2.302108822044244
Validation loss: 2.543879260198309

Epoch: 383| Step: 0
Training loss: 3.3130740262139975
Validation loss: 2.5395272919193506

Epoch: 6| Step: 1
Training loss: 2.752379948131386
Validation loss: 2.556056913726555

Epoch: 6| Step: 2
Training loss: 2.696912384658141
Validation loss: 2.5606308769960315

Epoch: 6| Step: 3
Training loss: 2.9879662441200665
Validation loss: 2.561316394151447

Epoch: 6| Step: 4
Training loss: 2.941332974477396
Validation loss: 2.572533836611395

Epoch: 6| Step: 5
Training loss: 1.9747625304762777
Validation loss: 2.5830049967700544

Epoch: 6| Step: 6
Training loss: 2.694880796496242
Validation loss: 2.5724977345941316

Epoch: 6| Step: 7
Training loss: 2.8068857742948796
Validation loss: 2.577022994389677

Epoch: 6| Step: 8
Training loss: 3.0429408570408074
Validation loss: 2.5846661005326945

Epoch: 6| Step: 9
Training loss: 3.4995660512843942
Validation loss: 2.5715891506463433

Epoch: 6| Step: 10
Training loss: 2.9314408815614623
Validation loss: 2.5603964080031782

Epoch: 6| Step: 11
Training loss: 2.8144033984861516
Validation loss: 2.551135771790865

Epoch: 6| Step: 12
Training loss: 2.9366210271757875
Validation loss: 2.55946271140233

Epoch: 6| Step: 13
Training loss: 2.4958139659743646
Validation loss: 2.5669898400078974

Epoch: 384| Step: 0
Training loss: 3.163784288019359
Validation loss: 2.54401173493385

Epoch: 6| Step: 1
Training loss: 2.2037873050433796
Validation loss: 2.537824088482915

Epoch: 6| Step: 2
Training loss: 3.042545313627002
Validation loss: 2.5444952091379593

Epoch: 6| Step: 3
Training loss: 2.6722463606257265
Validation loss: 2.5392022459636747

Epoch: 6| Step: 4
Training loss: 2.2804390497942846
Validation loss: 2.51950846995073

Epoch: 6| Step: 5
Training loss: 2.3449360199030944
Validation loss: 2.532533095334199

Epoch: 6| Step: 6
Training loss: 3.5860648870177134
Validation loss: 2.5330914142502854

Epoch: 6| Step: 7
Training loss: 2.8342821738994477
Validation loss: 2.5379020246361756

Epoch: 6| Step: 8
Training loss: 3.1488463938497455
Validation loss: 2.5327141427941107

Epoch: 6| Step: 9
Training loss: 3.1379077600813585
Validation loss: 2.544452585467424

Epoch: 6| Step: 10
Training loss: 2.985786783116537
Validation loss: 2.55522758126452

Epoch: 6| Step: 11
Training loss: 3.0641924794050204
Validation loss: 2.559780696897266

Epoch: 6| Step: 12
Training loss: 2.8346970212261553
Validation loss: 2.5799005265697104

Epoch: 6| Step: 13
Training loss: 2.488509378799936
Validation loss: 2.5778324283119765

Epoch: 385| Step: 0
Training loss: 2.751395738304206
Validation loss: 2.570611953185052

Epoch: 6| Step: 1
Training loss: 2.8589944221412815
Validation loss: 2.590692328687683

Epoch: 6| Step: 2
Training loss: 3.211249491809227
Validation loss: 2.5906400324869994

Epoch: 6| Step: 3
Training loss: 3.0795620889352002
Validation loss: 2.5703633930458905

Epoch: 6| Step: 4
Training loss: 3.3821829194558917
Validation loss: 2.5478410175334667

Epoch: 6| Step: 5
Training loss: 3.215336146601865
Validation loss: 2.5456527574490235

Epoch: 6| Step: 6
Training loss: 2.90994782181461
Validation loss: 2.537162047570274

Epoch: 6| Step: 7
Training loss: 3.3778478122304936
Validation loss: 2.5361725414835155

Epoch: 6| Step: 8
Training loss: 2.410479902549636
Validation loss: 2.5309948845181616

Epoch: 6| Step: 9
Training loss: 2.8906080090822432
Validation loss: 2.5296380528800997

Epoch: 6| Step: 10
Training loss: 1.8632066499823174
Validation loss: 2.535176269355128

Epoch: 6| Step: 11
Training loss: 2.2201339274037344
Validation loss: 2.527580293144585

Epoch: 6| Step: 12
Training loss: 2.6549693891409354
Validation loss: 2.535625676781423

Epoch: 6| Step: 13
Training loss: 3.3121331929500957
Validation loss: 2.5385130352885743

Epoch: 386| Step: 0
Training loss: 2.761098487188936
Validation loss: 2.5371278006215743

Epoch: 6| Step: 1
Training loss: 3.4299979449563502
Validation loss: 2.5440653599610945

Epoch: 6| Step: 2
Training loss: 2.211784389307406
Validation loss: 2.54464933754524

Epoch: 6| Step: 3
Training loss: 2.495956966371519
Validation loss: 2.5546483248873986

Epoch: 6| Step: 4
Training loss: 3.2649317831533664
Validation loss: 2.568996862354921

Epoch: 6| Step: 5
Training loss: 2.465731550073196
Validation loss: 2.5886490566554516

Epoch: 6| Step: 6
Training loss: 3.164892469269851
Validation loss: 2.595199270011353

Epoch: 6| Step: 7
Training loss: 2.942795221626993
Validation loss: 2.6260021404348888

Epoch: 6| Step: 8
Training loss: 2.3285760634574264
Validation loss: 2.6083651071868714

Epoch: 6| Step: 9
Training loss: 2.6805791233412455
Validation loss: 2.630759926611047

Epoch: 6| Step: 10
Training loss: 3.2971011983643845
Validation loss: 2.6066646587291813

Epoch: 6| Step: 11
Training loss: 3.065984806329216
Validation loss: 2.559164099367962

Epoch: 6| Step: 12
Training loss: 2.784562356555803
Validation loss: 2.522386891023877

Epoch: 6| Step: 13
Training loss: 3.112273279228482
Validation loss: 2.532591536298145

Epoch: 387| Step: 0
Training loss: 2.4484741441897286
Validation loss: 2.536514507668144

Epoch: 6| Step: 1
Training loss: 2.751610024522149
Validation loss: 2.5313115944831956

Epoch: 6| Step: 2
Training loss: 2.6834244098568396
Validation loss: 2.5341892250866787

Epoch: 6| Step: 3
Training loss: 3.277658004152889
Validation loss: 2.535393209889256

Epoch: 6| Step: 4
Training loss: 3.283144158917988
Validation loss: 2.5452330753823604

Epoch: 6| Step: 5
Training loss: 3.0462298370432874
Validation loss: 2.551961379980757

Epoch: 6| Step: 6
Training loss: 2.800765246314982
Validation loss: 2.576483933644735

Epoch: 6| Step: 7
Training loss: 2.8895363897146806
Validation loss: 2.5895737276927133

Epoch: 6| Step: 8
Training loss: 3.006328266100475
Validation loss: 2.5913715252921903

Epoch: 6| Step: 9
Training loss: 2.4089744304156664
Validation loss: 2.579288862082633

Epoch: 6| Step: 10
Training loss: 3.1656179866731913
Validation loss: 2.5630825950146034

Epoch: 6| Step: 11
Training loss: 2.8346897879931823
Validation loss: 2.553994991985768

Epoch: 6| Step: 12
Training loss: 2.942777073600246
Validation loss: 2.542560987584124

Epoch: 6| Step: 13
Training loss: 2.654153692272659
Validation loss: 2.544953752560022

Epoch: 388| Step: 0
Training loss: 3.1574003936931643
Validation loss: 2.5285514870632726

Epoch: 6| Step: 1
Training loss: 2.943039236903098
Validation loss: 2.535884324181593

Epoch: 6| Step: 2
Training loss: 2.905081893633262
Validation loss: 2.535604823819563

Epoch: 6| Step: 3
Training loss: 2.9092513143141945
Validation loss: 2.5320355224350584

Epoch: 6| Step: 4
Training loss: 2.1566833945111545
Validation loss: 2.5425336123438464

Epoch: 6| Step: 5
Training loss: 2.793550700134363
Validation loss: 2.5493592457559213

Epoch: 6| Step: 6
Training loss: 3.0787284762969467
Validation loss: 2.5525759270328856

Epoch: 6| Step: 7
Training loss: 3.50301013659536
Validation loss: 2.5539834786412

Epoch: 6| Step: 8
Training loss: 3.536498768518644
Validation loss: 2.566449127385996

Epoch: 6| Step: 9
Training loss: 3.0621409303012763
Validation loss: 2.554817967317965

Epoch: 6| Step: 10
Training loss: 2.2884835301965705
Validation loss: 2.5557377577378984

Epoch: 6| Step: 11
Training loss: 2.5537249417039534
Validation loss: 2.571023285648276

Epoch: 6| Step: 12
Training loss: 2.3719882943055923
Validation loss: 2.5678737403812266

Epoch: 6| Step: 13
Training loss: 2.5821752003119776
Validation loss: 2.56554454077619

Epoch: 389| Step: 0
Training loss: 3.086987126181759
Validation loss: 2.5741409777249085

Epoch: 6| Step: 1
Training loss: 3.3267138717706617
Validation loss: 2.5818505518934702

Epoch: 6| Step: 2
Training loss: 3.4471062728749953
Validation loss: 2.562836233550414

Epoch: 6| Step: 3
Training loss: 2.7874827465669534
Validation loss: 2.5531256386595977

Epoch: 6| Step: 4
Training loss: 2.756124093084252
Validation loss: 2.54014809294543

Epoch: 6| Step: 5
Training loss: 3.4160658765600593
Validation loss: 2.543923163241309

Epoch: 6| Step: 6
Training loss: 2.9729266851978577
Validation loss: 2.5406480627873993

Epoch: 6| Step: 7
Training loss: 2.148317423846177
Validation loss: 2.53454634990491

Epoch: 6| Step: 8
Training loss: 1.9178190153451673
Validation loss: 2.5297186789883144

Epoch: 6| Step: 9
Training loss: 3.1233204715210166
Validation loss: 2.535753134445174

Epoch: 6| Step: 10
Training loss: 2.496317249016891
Validation loss: 2.5499473595298032

Epoch: 6| Step: 11
Training loss: 2.6091000532014803
Validation loss: 2.557494751905576

Epoch: 6| Step: 12
Training loss: 2.8384442140608384
Validation loss: 2.5850629233149554

Epoch: 6| Step: 13
Training loss: 2.697827125349715
Validation loss: 2.6328284982861176

Epoch: 390| Step: 0
Training loss: 2.710040996846698
Validation loss: 2.635401153291815

Epoch: 6| Step: 1
Training loss: 3.0140783267003637
Validation loss: 2.6451688853784345

Epoch: 6| Step: 2
Training loss: 3.187711820857091
Validation loss: 2.630247306392847

Epoch: 6| Step: 3
Training loss: 2.223891841659769
Validation loss: 2.619851945023653

Epoch: 6| Step: 4
Training loss: 2.9473021892405518
Validation loss: 2.5895093738707713

Epoch: 6| Step: 5
Training loss: 2.8509326814098337
Validation loss: 2.562789134339286

Epoch: 6| Step: 6
Training loss: 2.9001805084876224
Validation loss: 2.573265663468437

Epoch: 6| Step: 7
Training loss: 2.0106416355686383
Validation loss: 2.5679961488369862

Epoch: 6| Step: 8
Training loss: 2.9563327705135305
Validation loss: 2.544669210687271

Epoch: 6| Step: 9
Training loss: 3.029894024094112
Validation loss: 2.554953514213891

Epoch: 6| Step: 10
Training loss: 2.6308336377035437
Validation loss: 2.548841434365903

Epoch: 6| Step: 11
Training loss: 3.2317396844330535
Validation loss: 2.554440855766873

Epoch: 6| Step: 12
Training loss: 3.09029187450456
Validation loss: 2.5620394136975544

Epoch: 6| Step: 13
Training loss: 3.350465110261279
Validation loss: 2.5425174593013686

Epoch: 391| Step: 0
Training loss: 3.2626393372461946
Validation loss: 2.549796123264585

Epoch: 6| Step: 1
Training loss: 3.023576600179549
Validation loss: 2.5562522110131036

Epoch: 6| Step: 2
Training loss: 2.596300824126579
Validation loss: 2.5535664919526364

Epoch: 6| Step: 3
Training loss: 2.745603341256623
Validation loss: 2.5635094633945377

Epoch: 6| Step: 4
Training loss: 2.636909896138661
Validation loss: 2.563629657726832

Epoch: 6| Step: 5
Training loss: 2.8353657632182956
Validation loss: 2.54996952884781

Epoch: 6| Step: 6
Training loss: 2.6097583603354586
Validation loss: 2.559816103963312

Epoch: 6| Step: 7
Training loss: 2.7791192111224965
Validation loss: 2.5593539548566557

Epoch: 6| Step: 8
Training loss: 2.854194659539012
Validation loss: 2.55641053742157

Epoch: 6| Step: 9
Training loss: 3.063774155233996
Validation loss: 2.5292576988785385

Epoch: 6| Step: 10
Training loss: 2.8952737903426202
Validation loss: 2.528848983707926

Epoch: 6| Step: 11
Training loss: 2.750226705049731
Validation loss: 2.527236226389733

Epoch: 6| Step: 12
Training loss: 2.7483422744849206
Validation loss: 2.5335772384650865

Epoch: 6| Step: 13
Training loss: 3.56731343926353
Validation loss: 2.5311615712103857

Epoch: 392| Step: 0
Training loss: 2.398988741175257
Validation loss: 2.54761903988363

Epoch: 6| Step: 1
Training loss: 2.898459215931115
Validation loss: 2.568429429098474

Epoch: 6| Step: 2
Training loss: 2.789166274931688
Validation loss: 2.5864256201815405

Epoch: 6| Step: 3
Training loss: 3.1627776374625522
Validation loss: 2.5685069900439905

Epoch: 6| Step: 4
Training loss: 2.359441895199738
Validation loss: 2.5648953397099046

Epoch: 6| Step: 5
Training loss: 2.559433660894586
Validation loss: 2.563268744776448

Epoch: 6| Step: 6
Training loss: 3.063877963471918
Validation loss: 2.5658873372775504

Epoch: 6| Step: 7
Training loss: 3.353605203648527
Validation loss: 2.5290299066634567

Epoch: 6| Step: 8
Training loss: 3.7880626499751453
Validation loss: 2.5468790323676096

Epoch: 6| Step: 9
Training loss: 2.421834047032783
Validation loss: 2.5335177754625056

Epoch: 6| Step: 10
Training loss: 3.264871172619788
Validation loss: 2.54143516929313

Epoch: 6| Step: 11
Training loss: 2.848027627639495
Validation loss: 2.54218249950987

Epoch: 6| Step: 12
Training loss: 1.9928355041965955
Validation loss: 2.5424880447709186

Epoch: 6| Step: 13
Training loss: 2.5267482333072846
Validation loss: 2.5429154748630154

Epoch: 393| Step: 0
Training loss: 2.918364348654325
Validation loss: 2.559856807362983

Epoch: 6| Step: 1
Training loss: 2.3001446968671075
Validation loss: 2.5871989028181335

Epoch: 6| Step: 2
Training loss: 2.2578235876741704
Validation loss: 2.632875841153587

Epoch: 6| Step: 3
Training loss: 3.0394384156564778
Validation loss: 2.603684872922929

Epoch: 6| Step: 4
Training loss: 2.630234540047092
Validation loss: 2.589658901680885

Epoch: 6| Step: 5
Training loss: 3.2358502695362636
Validation loss: 2.588050131236477

Epoch: 6| Step: 6
Training loss: 3.136794605976848
Validation loss: 2.5583261472197534

Epoch: 6| Step: 7
Training loss: 2.872962229484735
Validation loss: 2.553420847487518

Epoch: 6| Step: 8
Training loss: 3.1744255747768544
Validation loss: 2.536172858884282

Epoch: 6| Step: 9
Training loss: 2.3861887541595057
Validation loss: 2.547715599519262

Epoch: 6| Step: 10
Training loss: 2.659485226777497
Validation loss: 2.532129728091774

Epoch: 6| Step: 11
Training loss: 3.1905248912084825
Validation loss: 2.5455267965452903

Epoch: 6| Step: 12
Training loss: 2.78498520934528
Validation loss: 2.5366443310547244

Epoch: 6| Step: 13
Training loss: 3.5634994443376753
Validation loss: 2.537988572100296

Epoch: 394| Step: 0
Training loss: 3.015752443773199
Validation loss: 2.556514192659336

Epoch: 6| Step: 1
Training loss: 2.3225085209258003
Validation loss: 2.5671925556603754

Epoch: 6| Step: 2
Training loss: 3.249260157958528
Validation loss: 2.571108973456582

Epoch: 6| Step: 3
Training loss: 2.5816208690753775
Validation loss: 2.6087512938084503

Epoch: 6| Step: 4
Training loss: 3.1873471092506747
Validation loss: 2.6262120341016133

Epoch: 6| Step: 5
Training loss: 3.299617404144443
Validation loss: 2.6316279867554337

Epoch: 6| Step: 6
Training loss: 2.6275422637473067
Validation loss: 2.6330721636346097

Epoch: 6| Step: 7
Training loss: 3.0601911599780673
Validation loss: 2.6654343956010735

Epoch: 6| Step: 8
Training loss: 2.8792239134231865
Validation loss: 2.647940512549688

Epoch: 6| Step: 9
Training loss: 3.176481913357328
Validation loss: 2.6144869912914572

Epoch: 6| Step: 10
Training loss: 2.457897621810013
Validation loss: 2.566879563703835

Epoch: 6| Step: 11
Training loss: 2.669356737692886
Validation loss: 2.53513077785469

Epoch: 6| Step: 12
Training loss: 2.694533525766245
Validation loss: 2.514674010074585

Epoch: 6| Step: 13
Training loss: 2.5412353608272205
Validation loss: 2.528847155901772

Epoch: 395| Step: 0
Training loss: 3.054906656740347
Validation loss: 2.5168900444933615

Epoch: 6| Step: 1
Training loss: 3.3677836375023142
Validation loss: 2.5259883951537248

Epoch: 6| Step: 2
Training loss: 1.856421553265571
Validation loss: 2.5315006891056018

Epoch: 6| Step: 3
Training loss: 3.2853849968666866
Validation loss: 2.5273571212802075

Epoch: 6| Step: 4
Training loss: 2.599439424824849
Validation loss: 2.533709565831434

Epoch: 6| Step: 5
Training loss: 3.0797900039127155
Validation loss: 2.532125729945569

Epoch: 6| Step: 6
Training loss: 2.7458860663375386
Validation loss: 2.5248954592108532

Epoch: 6| Step: 7
Training loss: 2.9765070712317776
Validation loss: 2.5271127956678088

Epoch: 6| Step: 8
Training loss: 3.416496892913428
Validation loss: 2.526993975412831

Epoch: 6| Step: 9
Training loss: 2.6853127561302954
Validation loss: 2.524753499799354

Epoch: 6| Step: 10
Training loss: 2.8179581978528696
Validation loss: 2.5242513790999963

Epoch: 6| Step: 11
Training loss: 2.4274473995084573
Validation loss: 2.5150474487123384

Epoch: 6| Step: 12
Training loss: 2.878594183603683
Validation loss: 2.5193302945323293

Epoch: 6| Step: 13
Training loss: 3.0322753116049097
Validation loss: 2.516781532368019

Epoch: 396| Step: 0
Training loss: 2.813156729423684
Validation loss: 2.5189162160990106

Epoch: 6| Step: 1
Training loss: 2.608105744821685
Validation loss: 2.5242174891715456

Epoch: 6| Step: 2
Training loss: 2.867792465873243
Validation loss: 2.547166317600008

Epoch: 6| Step: 3
Training loss: 2.6063225532514034
Validation loss: 2.5537694605080126

Epoch: 6| Step: 4
Training loss: 2.912268856192208
Validation loss: 2.5663268034746274

Epoch: 6| Step: 5
Training loss: 3.170102230072224
Validation loss: 2.5969765435648444

Epoch: 6| Step: 6
Training loss: 3.1945626794430915
Validation loss: 2.669238124179796

Epoch: 6| Step: 7
Training loss: 2.8148204132306973
Validation loss: 2.700962084039818

Epoch: 6| Step: 8
Training loss: 3.2363764518117786
Validation loss: 2.7462033723821753

Epoch: 6| Step: 9
Training loss: 2.8622848629793682
Validation loss: 2.770718389793634

Epoch: 6| Step: 10
Training loss: 2.6761030685806912
Validation loss: 2.7350202951609806

Epoch: 6| Step: 11
Training loss: 3.4478257888542
Validation loss: 2.6856016688569473

Epoch: 6| Step: 12
Training loss: 2.3915890015365324
Validation loss: 2.6466590446217144

Epoch: 6| Step: 13
Training loss: 2.3623143764011725
Validation loss: 2.592710845026739

Epoch: 397| Step: 0
Training loss: 3.007651426287757
Validation loss: 2.574423032946957

Epoch: 6| Step: 1
Training loss: 2.594388216849314
Validation loss: 2.5455872247992115

Epoch: 6| Step: 2
Training loss: 3.370570348816111
Validation loss: 2.5539654707427437

Epoch: 6| Step: 3
Training loss: 2.9945072116379614
Validation loss: 2.5493203427419533

Epoch: 6| Step: 4
Training loss: 3.156282934640204
Validation loss: 2.5527789030448593

Epoch: 6| Step: 5
Training loss: 2.364257509971325
Validation loss: 2.5510024409658607

Epoch: 6| Step: 6
Training loss: 3.235112055587415
Validation loss: 2.556059563563893

Epoch: 6| Step: 7
Training loss: 2.678837677574998
Validation loss: 2.570123975701908

Epoch: 6| Step: 8
Training loss: 2.7348707349171995
Validation loss: 2.568643735823343

Epoch: 6| Step: 9
Training loss: 3.033814279624241
Validation loss: 2.5687894493135532

Epoch: 6| Step: 10
Training loss: 2.459431893103854
Validation loss: 2.579413604630712

Epoch: 6| Step: 11
Training loss: 2.9157533214661053
Validation loss: 2.576828751988043

Epoch: 6| Step: 12
Training loss: 3.0585126805188385
Validation loss: 2.569555685895874

Epoch: 6| Step: 13
Training loss: 2.6351575058075407
Validation loss: 2.559987120387662

Epoch: 398| Step: 0
Training loss: 2.7085669979142
Validation loss: 2.5582525125157587

Epoch: 6| Step: 1
Training loss: 3.054980954174853
Validation loss: 2.544884673095458

Epoch: 6| Step: 2
Training loss: 2.466987076990293
Validation loss: 2.548727507666591

Epoch: 6| Step: 3
Training loss: 3.1568183009603703
Validation loss: 2.5441742460740135

Epoch: 6| Step: 4
Training loss: 2.803137390721726
Validation loss: 2.5440094040863053

Epoch: 6| Step: 5
Training loss: 2.8665857333209996
Validation loss: 2.5414061275782363

Epoch: 6| Step: 6
Training loss: 2.319173925262544
Validation loss: 2.53778969338434

Epoch: 6| Step: 7
Training loss: 3.1303274901058673
Validation loss: 2.549706158848274

Epoch: 6| Step: 8
Training loss: 3.006602650853962
Validation loss: 2.5510461882572937

Epoch: 6| Step: 9
Training loss: 2.6693542368194554
Validation loss: 2.5408275119358827

Epoch: 6| Step: 10
Training loss: 2.804035589169144
Validation loss: 2.5696007215901053

Epoch: 6| Step: 11
Training loss: 3.175853019926269
Validation loss: 2.578066029500367

Epoch: 6| Step: 12
Training loss: 2.786331848886478
Validation loss: 2.5612029778174303

Epoch: 6| Step: 13
Training loss: 3.263439122226732
Validation loss: 2.572514812534824

Epoch: 399| Step: 0
Training loss: 1.9179818022802442
Validation loss: 2.569822797677279

Epoch: 6| Step: 1
Training loss: 2.253637869738326
Validation loss: 2.5668260118024984

Epoch: 6| Step: 2
Training loss: 2.6416289999730345
Validation loss: 2.5661026415499717

Epoch: 6| Step: 3
Training loss: 2.8033380263747016
Validation loss: 2.5746471087156118

Epoch: 6| Step: 4
Training loss: 2.5604849545275714
Validation loss: 2.57229159549457

Epoch: 6| Step: 5
Training loss: 3.0181804364505207
Validation loss: 2.5627438403949934

Epoch: 6| Step: 6
Training loss: 2.5190805904494598
Validation loss: 2.567173623321195

Epoch: 6| Step: 7
Training loss: 3.037458217003807
Validation loss: 2.567362050722146

Epoch: 6| Step: 8
Training loss: 3.2469876340507846
Validation loss: 2.5734728063947077

Epoch: 6| Step: 9
Training loss: 3.082808286622422
Validation loss: 2.5695400608995826

Epoch: 6| Step: 10
Training loss: 3.1917639243610325
Validation loss: 2.58639362435265

Epoch: 6| Step: 11
Training loss: 3.3009736676533814
Validation loss: 2.600894364129316

Epoch: 6| Step: 12
Training loss: 3.0726044232197145
Validation loss: 2.5812303621748387

Epoch: 6| Step: 13
Training loss: 2.7562739157125695
Validation loss: 2.5937888494281176

Epoch: 400| Step: 0
Training loss: 2.521421968026123
Validation loss: 2.6014297186880206

Epoch: 6| Step: 1
Training loss: 2.3936053877293033
Validation loss: 2.5947990376637455

Epoch: 6| Step: 2
Training loss: 2.7419529132542406
Validation loss: 2.5882257758337013

Epoch: 6| Step: 3
Training loss: 2.978726298901853
Validation loss: 2.5867395448783697

Epoch: 6| Step: 4
Training loss: 2.0913415977907346
Validation loss: 2.5521735970006665

Epoch: 6| Step: 5
Training loss: 3.2989729583547747
Validation loss: 2.542943205898181

Epoch: 6| Step: 6
Training loss: 2.84739501759599
Validation loss: 2.5413970528569307

Epoch: 6| Step: 7
Training loss: 2.9615510088552854
Validation loss: 2.5244026569570472

Epoch: 6| Step: 8
Training loss: 2.587290983004676
Validation loss: 2.5220691675743776

Epoch: 6| Step: 9
Training loss: 3.1478310277782318
Validation loss: 2.52144222046835

Epoch: 6| Step: 10
Training loss: 3.3096692927899487
Validation loss: 2.5303849525039546

Epoch: 6| Step: 11
Training loss: 3.3000156575611768
Validation loss: 2.5240841939188425

Epoch: 6| Step: 12
Training loss: 2.7004898545276443
Validation loss: 2.5260589575336954

Epoch: 6| Step: 13
Training loss: 2.5610471188799497
Validation loss: 2.538733084665169

Epoch: 401| Step: 0
Training loss: 2.7831529258082566
Validation loss: 2.541530651552971

Epoch: 6| Step: 1
Training loss: 3.2520169088620836
Validation loss: 2.552143794522419

Epoch: 6| Step: 2
Training loss: 3.17415262764166
Validation loss: 2.5578514091200413

Epoch: 6| Step: 3
Training loss: 2.3770138083166406
Validation loss: 2.587324671001542

Epoch: 6| Step: 4
Training loss: 2.797873206995248
Validation loss: 2.5861397053758832

Epoch: 6| Step: 5
Training loss: 2.8389599039942106
Validation loss: 2.589681979362724

Epoch: 6| Step: 6
Training loss: 2.93034465286012
Validation loss: 2.5906711020842272

Epoch: 6| Step: 7
Training loss: 2.8811541493788404
Validation loss: 2.5703431241179446

Epoch: 6| Step: 8
Training loss: 2.9147365905154867
Validation loss: 2.582928624507427

Epoch: 6| Step: 9
Training loss: 2.9297171222460774
Validation loss: 2.5525203435311568

Epoch: 6| Step: 10
Training loss: 2.8476830417121017
Validation loss: 2.538514788471853

Epoch: 6| Step: 11
Training loss: 2.649621569405633
Validation loss: 2.5184958714457135

Epoch: 6| Step: 12
Training loss: 2.920657470313649
Validation loss: 2.5187434080226905

Epoch: 6| Step: 13
Training loss: 2.2913459090967208
Validation loss: 2.5207534485168717

Epoch: 402| Step: 0
Training loss: 3.3032237750021203
Validation loss: 2.5254999934656004

Epoch: 6| Step: 1
Training loss: 2.2172739196237243
Validation loss: 2.5254683931359705

Epoch: 6| Step: 2
Training loss: 3.1824170143593205
Validation loss: 2.5343100361318247

Epoch: 6| Step: 3
Training loss: 3.327628371745309
Validation loss: 2.5333776795025327

Epoch: 6| Step: 4
Training loss: 3.0852425480835977
Validation loss: 2.55589949421747

Epoch: 6| Step: 5
Training loss: 2.7509257752345135
Validation loss: 2.561705063062772

Epoch: 6| Step: 6
Training loss: 2.961778023221506
Validation loss: 2.5492333664237377

Epoch: 6| Step: 7
Training loss: 2.64100129645943
Validation loss: 2.554312110523996

Epoch: 6| Step: 8
Training loss: 2.389575603265296
Validation loss: 2.5677038767340257

Epoch: 6| Step: 9
Training loss: 2.9087169390587637
Validation loss: 2.5835187561291626

Epoch: 6| Step: 10
Training loss: 2.726505399177112
Validation loss: 2.5711766504083746

Epoch: 6| Step: 11
Training loss: 2.8743288666601496
Validation loss: 2.565784001755235

Epoch: 6| Step: 12
Training loss: 2.5727749887190146
Validation loss: 2.5736658437827846

Epoch: 6| Step: 13
Training loss: 2.682209307446273
Validation loss: 2.566606092623842

Epoch: 403| Step: 0
Training loss: 2.6766559145827467
Validation loss: 2.5520756982350523

Epoch: 6| Step: 1
Training loss: 2.516918347470667
Validation loss: 2.544861252641076

Epoch: 6| Step: 2
Training loss: 3.6824945648422585
Validation loss: 2.558142435799176

Epoch: 6| Step: 3
Training loss: 2.457062495143643
Validation loss: 2.538885065762202

Epoch: 6| Step: 4
Training loss: 1.86480906166189
Validation loss: 2.541919501680286

Epoch: 6| Step: 5
Training loss: 2.9145522127996357
Validation loss: 2.523653784662906

Epoch: 6| Step: 6
Training loss: 2.4273596894152494
Validation loss: 2.5241785521096034

Epoch: 6| Step: 7
Training loss: 3.5210670228108376
Validation loss: 2.521799816686134

Epoch: 6| Step: 8
Training loss: 2.933775955820034
Validation loss: 2.5207045479928083

Epoch: 6| Step: 9
Training loss: 2.7984156281315675
Validation loss: 2.5277550016531993

Epoch: 6| Step: 10
Training loss: 2.8353765263870545
Validation loss: 2.5406823833693255

Epoch: 6| Step: 11
Training loss: 2.906466240170187
Validation loss: 2.551835682254267

Epoch: 6| Step: 12
Training loss: 3.0884122172734183
Validation loss: 2.5775477026838653

Epoch: 6| Step: 13
Training loss: 2.618956830362612
Validation loss: 2.598950240148711

Epoch: 404| Step: 0
Training loss: 2.551416385202288
Validation loss: 2.588940075239169

Epoch: 6| Step: 1
Training loss: 3.070294484481179
Validation loss: 2.633713581754567

Epoch: 6| Step: 2
Training loss: 2.2937848330147395
Validation loss: 2.6407115679620623

Epoch: 6| Step: 3
Training loss: 3.7604423092349104
Validation loss: 2.639838254699551

Epoch: 6| Step: 4
Training loss: 2.598166600624531
Validation loss: 2.5889948421833386

Epoch: 6| Step: 5
Training loss: 2.5128168580020174
Validation loss: 2.5559419610982665

Epoch: 6| Step: 6
Training loss: 2.8948640001467605
Validation loss: 2.5240313835214585

Epoch: 6| Step: 7
Training loss: 2.7756669660598385
Validation loss: 2.5186213662919723

Epoch: 6| Step: 8
Training loss: 2.325389714547634
Validation loss: 2.5125745559509123

Epoch: 6| Step: 9
Training loss: 3.2688369651881493
Validation loss: 2.5013116482329

Epoch: 6| Step: 10
Training loss: 2.759435332903424
Validation loss: 2.5055312422987823

Epoch: 6| Step: 11
Training loss: 2.9719015960626436
Validation loss: 2.5072771355234527

Epoch: 6| Step: 12
Training loss: 2.893837952564574
Validation loss: 2.5047246669773986

Epoch: 6| Step: 13
Training loss: 3.3654562621821627
Validation loss: 2.5165636139179024

Epoch: 405| Step: 0
Training loss: 3.4023221668912154
Validation loss: 2.5063011223752354

Epoch: 6| Step: 1
Training loss: 2.5602289696459106
Validation loss: 2.5335674203103813

Epoch: 6| Step: 2
Training loss: 2.519209115186756
Validation loss: 2.5522636803563747

Epoch: 6| Step: 3
Training loss: 3.2557578800448477
Validation loss: 2.587387664268214

Epoch: 6| Step: 4
Training loss: 2.6866052601929966
Validation loss: 2.596564361179948

Epoch: 6| Step: 5
Training loss: 3.02924146669185
Validation loss: 2.6694224097521544

Epoch: 6| Step: 6
Training loss: 3.068019641738743
Validation loss: 2.6574558529771526

Epoch: 6| Step: 7
Training loss: 2.8664935776847997
Validation loss: 2.628605288270786

Epoch: 6| Step: 8
Training loss: 3.225348662225515
Validation loss: 2.639932189993757

Epoch: 6| Step: 9
Training loss: 2.7628618650639782
Validation loss: 2.587648467182289

Epoch: 6| Step: 10
Training loss: 2.6701535931532203
Validation loss: 2.575667242011777

Epoch: 6| Step: 11
Training loss: 2.337390664547409
Validation loss: 2.5505854182156216

Epoch: 6| Step: 12
Training loss: 2.6578509723226884
Validation loss: 2.5580587709993905

Epoch: 6| Step: 13
Training loss: 2.6324545959440653
Validation loss: 2.5397806070607323

Epoch: 406| Step: 0
Training loss: 2.6732613162696004
Validation loss: 2.523540547931555

Epoch: 6| Step: 1
Training loss: 2.9102714362166453
Validation loss: 2.5116277340209767

Epoch: 6| Step: 2
Training loss: 2.986335789313252
Validation loss: 2.515349266835126

Epoch: 6| Step: 3
Training loss: 2.549711835698081
Validation loss: 2.5097145368719036

Epoch: 6| Step: 4
Training loss: 3.161438105527383
Validation loss: 2.519171547815797

Epoch: 6| Step: 5
Training loss: 3.209737363154451
Validation loss: 2.506948331441411

Epoch: 6| Step: 6
Training loss: 2.884871081243581
Validation loss: 2.517009529641955

Epoch: 6| Step: 7
Training loss: 2.843356430150711
Validation loss: 2.5026556399864046

Epoch: 6| Step: 8
Training loss: 2.9091913249284693
Validation loss: 2.5309807692333317

Epoch: 6| Step: 9
Training loss: 3.059855974086578
Validation loss: 2.5270072090505167

Epoch: 6| Step: 10
Training loss: 3.016001939686928
Validation loss: 2.534510936763092

Epoch: 6| Step: 11
Training loss: 2.5273812953040995
Validation loss: 2.5453757145982725

Epoch: 6| Step: 12
Training loss: 2.502832810472756
Validation loss: 2.5473903444397887

Epoch: 6| Step: 13
Training loss: 2.358211002839045
Validation loss: 2.5617584368048343

Epoch: 407| Step: 0
Training loss: 2.785736323189114
Validation loss: 2.5484275663110862

Epoch: 6| Step: 1
Training loss: 2.408607813979374
Validation loss: 2.5748738790931593

Epoch: 6| Step: 2
Training loss: 2.5700236334994284
Validation loss: 2.5434342261030984

Epoch: 6| Step: 3
Training loss: 2.6852694281399176
Validation loss: 2.543345435726886

Epoch: 6| Step: 4
Training loss: 2.7419469135523946
Validation loss: 2.57290329534663

Epoch: 6| Step: 5
Training loss: 2.600210760817551
Validation loss: 2.5389305626956107

Epoch: 6| Step: 6
Training loss: 2.4669668783895427
Validation loss: 2.561484973445679

Epoch: 6| Step: 7
Training loss: 2.73052140213787
Validation loss: 2.5653757815518463

Epoch: 6| Step: 8
Training loss: 3.2695268747170547
Validation loss: 2.558702004829149

Epoch: 6| Step: 9
Training loss: 2.999206120036412
Validation loss: 2.5617257986344626

Epoch: 6| Step: 10
Training loss: 3.2764178344632375
Validation loss: 2.554412602221625

Epoch: 6| Step: 11
Training loss: 2.9848443905447737
Validation loss: 2.5202545641301968

Epoch: 6| Step: 12
Training loss: 2.828930144800355
Validation loss: 2.5085068650813636

Epoch: 6| Step: 13
Training loss: 3.513714080268686
Validation loss: 2.528395259986564

Epoch: 408| Step: 0
Training loss: 3.066026797780318
Validation loss: 2.515129440536332

Epoch: 6| Step: 1
Training loss: 3.069515522804661
Validation loss: 2.5209690146634953

Epoch: 6| Step: 2
Training loss: 2.685551669029812
Validation loss: 2.50205198183297

Epoch: 6| Step: 3
Training loss: 3.332146592284857
Validation loss: 2.5167941835799965

Epoch: 6| Step: 4
Training loss: 2.764041080682978
Validation loss: 2.5146877199014446

Epoch: 6| Step: 5
Training loss: 2.7418918721967063
Validation loss: 2.5031590529660317

Epoch: 6| Step: 6
Training loss: 3.3199207029869093
Validation loss: 2.5237232629211905

Epoch: 6| Step: 7
Training loss: 2.2205843797270557
Validation loss: 2.5444019157194364

Epoch: 6| Step: 8
Training loss: 2.6226775476740345
Validation loss: 2.551088387221658

Epoch: 6| Step: 9
Training loss: 3.067721839102185
Validation loss: 2.622387941524179

Epoch: 6| Step: 10
Training loss: 2.0979690176509846
Validation loss: 2.6424958694256064

Epoch: 6| Step: 11
Training loss: 3.1126991790404706
Validation loss: 2.6993745630909247

Epoch: 6| Step: 12
Training loss: 2.735370650900685
Validation loss: 2.7929745065469276

Epoch: 6| Step: 13
Training loss: 2.355908000218422
Validation loss: 2.788999712186645

Epoch: 409| Step: 0
Training loss: 2.845766463455209
Validation loss: 2.7642821851475614

Epoch: 6| Step: 1
Training loss: 2.716038195536701
Validation loss: 2.7187196180366686

Epoch: 6| Step: 2
Training loss: 2.737280996262978
Validation loss: 2.6951563807318113

Epoch: 6| Step: 3
Training loss: 3.555507020486599
Validation loss: 2.624080441226914

Epoch: 6| Step: 4
Training loss: 2.527829248884769
Validation loss: 2.5704631455194966

Epoch: 6| Step: 5
Training loss: 2.526532899474389
Validation loss: 2.5344629389322018

Epoch: 6| Step: 6
Training loss: 3.006686388727819
Validation loss: 2.5248896595520693

Epoch: 6| Step: 7
Training loss: 3.08766948528203
Validation loss: 2.521699898996409

Epoch: 6| Step: 8
Training loss: 2.7712371264250315
Validation loss: 2.5129829452764

Epoch: 6| Step: 9
Training loss: 2.86165773752101
Validation loss: 2.517054364265167

Epoch: 6| Step: 10
Training loss: 2.7788701537423197
Validation loss: 2.5187551562432238

Epoch: 6| Step: 11
Training loss: 2.741565079435072
Validation loss: 2.526155564929098

Epoch: 6| Step: 12
Training loss: 3.203874304983544
Validation loss: 2.521128666079084

Epoch: 6| Step: 13
Training loss: 2.9837375779007203
Validation loss: 2.5182118104999427

Epoch: 410| Step: 0
Training loss: 3.2172202021088676
Validation loss: 2.5271340970910305

Epoch: 6| Step: 1
Training loss: 2.824499683468572
Validation loss: 2.546831454854682

Epoch: 6| Step: 2
Training loss: 3.0749140223446916
Validation loss: 2.5537986286526184

Epoch: 6| Step: 3
Training loss: 2.430499857915275
Validation loss: 2.558279405897773

Epoch: 6| Step: 4
Training loss: 3.28493503546963
Validation loss: 2.555719883575305

Epoch: 6| Step: 5
Training loss: 2.666145830153798
Validation loss: 2.589871419043839

Epoch: 6| Step: 6
Training loss: 3.1793998569411466
Validation loss: 2.585934662675616

Epoch: 6| Step: 7
Training loss: 2.3924247599124286
Validation loss: 2.6128614925369624

Epoch: 6| Step: 8
Training loss: 2.6472678513367685
Validation loss: 2.629544694859763

Epoch: 6| Step: 9
Training loss: 3.2089845235944123
Validation loss: 2.6084657749913918

Epoch: 6| Step: 10
Training loss: 3.613365708472374
Validation loss: 2.592072902553705

Epoch: 6| Step: 11
Training loss: 1.6584311464431303
Validation loss: 2.560529085470158

Epoch: 6| Step: 12
Training loss: 2.503606864658202
Validation loss: 2.5689428478885814

Epoch: 6| Step: 13
Training loss: 2.6028325643600785
Validation loss: 2.5648989069615284

Epoch: 411| Step: 0
Training loss: 3.0394650857021124
Validation loss: 2.550398355784402

Epoch: 6| Step: 1
Training loss: 3.1898074306613164
Validation loss: 2.5626310109428796

Epoch: 6| Step: 2
Training loss: 2.54071836030225
Validation loss: 2.5623206679378163

Epoch: 6| Step: 3
Training loss: 2.6217607766551327
Validation loss: 2.5589900705783744

Epoch: 6| Step: 4
Training loss: 2.5674400163606284
Validation loss: 2.553053936564455

Epoch: 6| Step: 5
Training loss: 3.089985879168297
Validation loss: 2.5638070063519076

Epoch: 6| Step: 6
Training loss: 1.899063195621877
Validation loss: 2.564708834205792

Epoch: 6| Step: 7
Training loss: 3.163084128492073
Validation loss: 2.585942516366031

Epoch: 6| Step: 8
Training loss: 2.7829701965304285
Validation loss: 2.6003165781579214

Epoch: 6| Step: 9
Training loss: 2.647432299676815
Validation loss: 2.581889188163224

Epoch: 6| Step: 10
Training loss: 2.896992696039844
Validation loss: 2.5660998202578624

Epoch: 6| Step: 11
Training loss: 3.3098492362731435
Validation loss: 2.5732670104110715

Epoch: 6| Step: 12
Training loss: 3.299921878699188
Validation loss: 2.5815951473470866

Epoch: 6| Step: 13
Training loss: 2.564823213995279
Validation loss: 2.5434762640985342

Epoch: 412| Step: 0
Training loss: 2.691474991184913
Validation loss: 2.55070741859379

Epoch: 6| Step: 1
Training loss: 2.4553286622612625
Validation loss: 2.5485731400366163

Epoch: 6| Step: 2
Training loss: 2.663753547540788
Validation loss: 2.5302171107575666

Epoch: 6| Step: 3
Training loss: 3.2414132170327634
Validation loss: 2.526175933676164

Epoch: 6| Step: 4
Training loss: 2.3516271842095176
Validation loss: 2.5346477506782445

Epoch: 6| Step: 5
Training loss: 3.2229034883853998
Validation loss: 2.5367486747175914

Epoch: 6| Step: 6
Training loss: 3.2153569086570823
Validation loss: 2.5278114603355686

Epoch: 6| Step: 7
Training loss: 2.838291504828536
Validation loss: 2.522445027895031

Epoch: 6| Step: 8
Training loss: 2.4736625949709765
Validation loss: 2.522557755862819

Epoch: 6| Step: 9
Training loss: 2.69342806633761
Validation loss: 2.5328073333045618

Epoch: 6| Step: 10
Training loss: 3.3635812375286966
Validation loss: 2.53193525333517

Epoch: 6| Step: 11
Training loss: 2.8487605294153946
Validation loss: 2.5471440272622345

Epoch: 6| Step: 12
Training loss: 2.9279833911049473
Validation loss: 2.5494746208852184

Epoch: 6| Step: 13
Training loss: 2.653546202601496
Validation loss: 2.542336272001653

Epoch: 413| Step: 0
Training loss: 2.9149157218462265
Validation loss: 2.563518204826902

Epoch: 6| Step: 1
Training loss: 3.1945262585174383
Validation loss: 2.570296911521559

Epoch: 6| Step: 2
Training loss: 2.47254651927482
Validation loss: 2.5879407305519146

Epoch: 6| Step: 3
Training loss: 3.4420618478470573
Validation loss: 2.599840958347917

Epoch: 6| Step: 4
Training loss: 2.3557796747524082
Validation loss: 2.592388028258382

Epoch: 6| Step: 5
Training loss: 2.925693240707355
Validation loss: 2.5592482178725846

Epoch: 6| Step: 6
Training loss: 2.361689966589818
Validation loss: 2.533463361519447

Epoch: 6| Step: 7
Training loss: 2.5408520774195793
Validation loss: 2.5294529126060046

Epoch: 6| Step: 8
Training loss: 3.4324032539130864
Validation loss: 2.518908510660928

Epoch: 6| Step: 9
Training loss: 2.795101861070062
Validation loss: 2.5221846902636464

Epoch: 6| Step: 10
Training loss: 2.5240908506217408
Validation loss: 2.5203757267771967

Epoch: 6| Step: 11
Training loss: 3.212780500107363
Validation loss: 2.5303501609499808

Epoch: 6| Step: 12
Training loss: 2.85100343005169
Validation loss: 2.543530054624774

Epoch: 6| Step: 13
Training loss: 2.3208405892368855
Validation loss: 2.5347885056491255

Epoch: 414| Step: 0
Training loss: 2.1287299686907333
Validation loss: 2.5547625168878114

Epoch: 6| Step: 1
Training loss: 2.9320371437165984
Validation loss: 2.5442909798058713

Epoch: 6| Step: 2
Training loss: 2.9796587842128694
Validation loss: 2.542239441492185

Epoch: 6| Step: 3
Training loss: 2.520943841534922
Validation loss: 2.528038700144315

Epoch: 6| Step: 4
Training loss: 2.73301183236412
Validation loss: 2.516720797516127

Epoch: 6| Step: 5
Training loss: 2.8429037658526912
Validation loss: 2.522702901747233

Epoch: 6| Step: 6
Training loss: 3.1023604666096936
Validation loss: 2.523892690914734

Epoch: 6| Step: 7
Training loss: 2.8181266450655076
Validation loss: 2.5081223365553247

Epoch: 6| Step: 8
Training loss: 3.0404708462537418
Validation loss: 2.5038785934360654

Epoch: 6| Step: 9
Training loss: 2.990119558132054
Validation loss: 2.524160970414536

Epoch: 6| Step: 10
Training loss: 3.0901156569875456
Validation loss: 2.5358554787119534

Epoch: 6| Step: 11
Training loss: 2.713582707910503
Validation loss: 2.537322231022304

Epoch: 6| Step: 12
Training loss: 2.6321634913281065
Validation loss: 2.570211357228476

Epoch: 6| Step: 13
Training loss: 3.2097553388104165
Validation loss: 2.616937657789922

Epoch: 415| Step: 0
Training loss: 2.572266922633974
Validation loss: 2.626462137565929

Epoch: 6| Step: 1
Training loss: 3.623030555050845
Validation loss: 2.641394605750843

Epoch: 6| Step: 2
Training loss: 2.943696972800662
Validation loss: 2.645963981631922

Epoch: 6| Step: 3
Training loss: 2.7193783439557806
Validation loss: 2.65029533761992

Epoch: 6| Step: 4
Training loss: 2.9922171409473446
Validation loss: 2.654257042267736

Epoch: 6| Step: 5
Training loss: 2.4695138835929926
Validation loss: 2.64383552192046

Epoch: 6| Step: 6
Training loss: 2.2689550722195837
Validation loss: 2.5964720233714833

Epoch: 6| Step: 7
Training loss: 3.240610497496479
Validation loss: 2.583428368886137

Epoch: 6| Step: 8
Training loss: 2.6570533883872627
Validation loss: 2.547042213082882

Epoch: 6| Step: 9
Training loss: 3.2051023753176886
Validation loss: 2.528239800995922

Epoch: 6| Step: 10
Training loss: 2.34343931046205
Validation loss: 2.529732483613209

Epoch: 6| Step: 11
Training loss: 2.7749779090345714
Validation loss: 2.504170552791367

Epoch: 6| Step: 12
Training loss: 2.9661014990079138
Validation loss: 2.5110843917412975

Epoch: 6| Step: 13
Training loss: 2.4841547454510406
Validation loss: 2.499407983229579

Epoch: 416| Step: 0
Training loss: 2.8821415314187653
Validation loss: 2.504449625391542

Epoch: 6| Step: 1
Training loss: 2.798188481840926
Validation loss: 2.5019442115038237

Epoch: 6| Step: 2
Training loss: 2.4912957297040825
Validation loss: 2.494390576985313

Epoch: 6| Step: 3
Training loss: 1.946778078559869
Validation loss: 2.5049560602690173

Epoch: 6| Step: 4
Training loss: 3.4178187746114372
Validation loss: 2.5050462983300856

Epoch: 6| Step: 5
Training loss: 2.399486001923181
Validation loss: 2.502754894166529

Epoch: 6| Step: 6
Training loss: 2.7229308505711614
Validation loss: 2.5168419306368204

Epoch: 6| Step: 7
Training loss: 2.8422013981307908
Validation loss: 2.513194859964536

Epoch: 6| Step: 8
Training loss: 2.8367859803272353
Validation loss: 2.506467662884002

Epoch: 6| Step: 9
Training loss: 3.06444378882421
Validation loss: 2.5193540144002746

Epoch: 6| Step: 10
Training loss: 3.263161492062385
Validation loss: 2.525212194574376

Epoch: 6| Step: 11
Training loss: 3.285523021059451
Validation loss: 2.539371398865239

Epoch: 6| Step: 12
Training loss: 2.703393558986876
Validation loss: 2.5687137342615123

Epoch: 6| Step: 13
Training loss: 2.7502279187167225
Validation loss: 2.570857697154355

Epoch: 417| Step: 0
Training loss: 2.447056547520947
Validation loss: 2.628813611727679

Epoch: 6| Step: 1
Training loss: 3.037626500890314
Validation loss: 2.6850263005043242

Epoch: 6| Step: 2
Training loss: 2.9132384907046562
Validation loss: 2.7548791441486395

Epoch: 6| Step: 3
Training loss: 2.8756810915707396
Validation loss: 2.8105888226461295

Epoch: 6| Step: 4
Training loss: 2.6379717978878046
Validation loss: 2.791819529847223

Epoch: 6| Step: 5
Training loss: 2.6452033627073224
Validation loss: 2.7646134180376816

Epoch: 6| Step: 6
Training loss: 3.1259516983449602
Validation loss: 2.725535892365105

Epoch: 6| Step: 7
Training loss: 3.0965929936520493
Validation loss: 2.645650663716142

Epoch: 6| Step: 8
Training loss: 2.2774411110325534
Validation loss: 2.580456018181913

Epoch: 6| Step: 9
Training loss: 2.7136623089721814
Validation loss: 2.5367473220278516

Epoch: 6| Step: 10
Training loss: 3.1543593078670416
Validation loss: 2.5124193863763904

Epoch: 6| Step: 11
Training loss: 2.556964477823427
Validation loss: 2.499549566729654

Epoch: 6| Step: 12
Training loss: 3.229896577767804
Validation loss: 2.500574447919246

Epoch: 6| Step: 13
Training loss: 3.4705780985675623
Validation loss: 2.503876487339141

Epoch: 418| Step: 0
Training loss: 2.6468138092065883
Validation loss: 2.505099075046672

Epoch: 6| Step: 1
Training loss: 2.9550293932903546
Validation loss: 2.505777476808818

Epoch: 6| Step: 2
Training loss: 2.544245948526643
Validation loss: 2.5082617100443434

Epoch: 6| Step: 3
Training loss: 2.8718800408751837
Validation loss: 2.5149397072347366

Epoch: 6| Step: 4
Training loss: 3.242402071918886
Validation loss: 2.5198552227264157

Epoch: 6| Step: 5
Training loss: 3.0019286631851427
Validation loss: 2.515466494373232

Epoch: 6| Step: 6
Training loss: 3.335830007782218
Validation loss: 2.5161455059616564

Epoch: 6| Step: 7
Training loss: 3.0974145629036007
Validation loss: 2.51330960630592

Epoch: 6| Step: 8
Training loss: 2.8507415007655483
Validation loss: 2.5082488491962556

Epoch: 6| Step: 9
Training loss: 2.6200893427634293
Validation loss: 2.509438618080716

Epoch: 6| Step: 10
Training loss: 2.7055196573885976
Validation loss: 2.5146305353196667

Epoch: 6| Step: 11
Training loss: 2.5007411811762355
Validation loss: 2.5335216307594703

Epoch: 6| Step: 12
Training loss: 2.503029323087592
Validation loss: 2.5225494355139793

Epoch: 6| Step: 13
Training loss: 3.5506657580571357
Validation loss: 2.5389948081308242

Epoch: 419| Step: 0
Training loss: 2.7063229557625696
Validation loss: 2.544443876266983

Epoch: 6| Step: 1
Training loss: 3.147182621547269
Validation loss: 2.578076573150437

Epoch: 6| Step: 2
Training loss: 3.3819494401884858
Validation loss: 2.5802590247289907

Epoch: 6| Step: 3
Training loss: 3.235704231787935
Validation loss: 2.610308208074626

Epoch: 6| Step: 4
Training loss: 2.473280600356657
Validation loss: 2.5741091190161245

Epoch: 6| Step: 5
Training loss: 2.4718143421933916
Validation loss: 2.563847631393607

Epoch: 6| Step: 6
Training loss: 3.2206998678159695
Validation loss: 2.557508114906224

Epoch: 6| Step: 7
Training loss: 2.6711033827905606
Validation loss: 2.566508574571809

Epoch: 6| Step: 8
Training loss: 2.42189252293308
Validation loss: 2.546634556276304

Epoch: 6| Step: 9
Training loss: 3.0719969499195376
Validation loss: 2.546554622786075

Epoch: 6| Step: 10
Training loss: 1.9537656420022358
Validation loss: 2.5445674083091587

Epoch: 6| Step: 11
Training loss: 3.0347920595732143
Validation loss: 2.5494051198986605

Epoch: 6| Step: 12
Training loss: 2.726787743651086
Validation loss: 2.5473249249267997

Epoch: 6| Step: 13
Training loss: 2.6508716661147442
Validation loss: 2.5396333472715233

Epoch: 420| Step: 0
Training loss: 2.6525610945673987
Validation loss: 2.5471060898605553

Epoch: 6| Step: 1
Training loss: 2.514483649030201
Validation loss: 2.514943020167668

Epoch: 6| Step: 2
Training loss: 2.2754840880751086
Validation loss: 2.5393863877164953

Epoch: 6| Step: 3
Training loss: 2.4462983213085763
Validation loss: 2.5368213894460028

Epoch: 6| Step: 4
Training loss: 3.178783091298983
Validation loss: 2.535833793593375

Epoch: 6| Step: 5
Training loss: 2.356962271374245
Validation loss: 2.5205880512477647

Epoch: 6| Step: 6
Training loss: 2.8697833957079846
Validation loss: 2.547710492791781

Epoch: 6| Step: 7
Training loss: 2.7845948069388062
Validation loss: 2.5322563948833814

Epoch: 6| Step: 8
Training loss: 3.3295412587308943
Validation loss: 2.518796279927041

Epoch: 6| Step: 9
Training loss: 3.2247084493221836
Validation loss: 2.5184601359070196

Epoch: 6| Step: 10
Training loss: 2.981864152583563
Validation loss: 2.533065120793599

Epoch: 6| Step: 11
Training loss: 3.0931809027154924
Validation loss: 2.5295602173347933

Epoch: 6| Step: 12
Training loss: 2.7467988195694253
Validation loss: 2.5405442617233773

Epoch: 6| Step: 13
Training loss: 2.8152262719721737
Validation loss: 2.5292604254451496

Epoch: 421| Step: 0
Training loss: 2.4919787471961015
Validation loss: 2.5431404225314274

Epoch: 6| Step: 1
Training loss: 2.921321388061189
Validation loss: 2.555055338231361

Epoch: 6| Step: 2
Training loss: 2.3692829186838558
Validation loss: 2.5619414076106777

Epoch: 6| Step: 3
Training loss: 2.6750175332894104
Validation loss: 2.558844453286142

Epoch: 6| Step: 4
Training loss: 3.2188726605496503
Validation loss: 2.556910526757954

Epoch: 6| Step: 5
Training loss: 2.8850171929281827
Validation loss: 2.5712842987079854

Epoch: 6| Step: 6
Training loss: 3.028048368100428
Validation loss: 2.559739985276666

Epoch: 6| Step: 7
Training loss: 3.232952745068084
Validation loss: 2.550567947185706

Epoch: 6| Step: 8
Training loss: 2.7908862052580115
Validation loss: 2.569751017768038

Epoch: 6| Step: 9
Training loss: 2.6772720527677514
Validation loss: 2.5651621422473547

Epoch: 6| Step: 10
Training loss: 2.7113228559751965
Validation loss: 2.5475160924416165

Epoch: 6| Step: 11
Training loss: 2.7827374199190578
Validation loss: 2.5869766346890315

Epoch: 6| Step: 12
Training loss: 2.7097216251315497
Validation loss: 2.6027718281518584

Epoch: 6| Step: 13
Training loss: 3.1374913614465707
Validation loss: 2.6103900155756565

Epoch: 422| Step: 0
Training loss: 2.789010183661119
Validation loss: 2.592971868878058

Epoch: 6| Step: 1
Training loss: 2.8307899017041747
Validation loss: 2.602840751189974

Epoch: 6| Step: 2
Training loss: 2.668055431024629
Validation loss: 2.538968040659194

Epoch: 6| Step: 3
Training loss: 2.3367334751186823
Validation loss: 2.5338775283284054

Epoch: 6| Step: 4
Training loss: 2.8253050175295473
Validation loss: 2.5250747663705977

Epoch: 6| Step: 5
Training loss: 2.521389345584126
Validation loss: 2.512534768093521

Epoch: 6| Step: 6
Training loss: 2.4984393016624993
Validation loss: 2.5232120546422996

Epoch: 6| Step: 7
Training loss: 2.79900343053784
Validation loss: 2.5135234048197828

Epoch: 6| Step: 8
Training loss: 2.780009475252758
Validation loss: 2.5285920205339214

Epoch: 6| Step: 9
Training loss: 3.2346816355250674
Validation loss: 2.515995770524525

Epoch: 6| Step: 10
Training loss: 2.643469638252544
Validation loss: 2.5343593296245164

Epoch: 6| Step: 11
Training loss: 3.441725336148971
Validation loss: 2.5344543228551166

Epoch: 6| Step: 12
Training loss: 3.1480829309012086
Validation loss: 2.5473553171712084

Epoch: 6| Step: 13
Training loss: 2.8352397974717203
Validation loss: 2.5514812757999525

Epoch: 423| Step: 0
Training loss: 2.7507557264041487
Validation loss: 2.568636219480923

Epoch: 6| Step: 1
Training loss: 2.65441112819774
Validation loss: 2.5548697158863356

Epoch: 6| Step: 2
Training loss: 2.907865669957366
Validation loss: 2.5700964890671085

Epoch: 6| Step: 3
Training loss: 3.3225829495996355
Validation loss: 2.550095175805321

Epoch: 6| Step: 4
Training loss: 2.3928443729409636
Validation loss: 2.548132660327901

Epoch: 6| Step: 5
Training loss: 3.3356101525390645
Validation loss: 2.5374619010741633

Epoch: 6| Step: 6
Training loss: 2.705437877984505
Validation loss: 2.53998087817904

Epoch: 6| Step: 7
Training loss: 3.3121392395494316
Validation loss: 2.545266004610705

Epoch: 6| Step: 8
Training loss: 2.5688381430546383
Validation loss: 2.545348580132384

Epoch: 6| Step: 9
Training loss: 3.234280939623386
Validation loss: 2.5382576807055526

Epoch: 6| Step: 10
Training loss: 2.2099264144729465
Validation loss: 2.536043712914541

Epoch: 6| Step: 11
Training loss: 2.4442610262442317
Validation loss: 2.550415180636614

Epoch: 6| Step: 12
Training loss: 2.733920686309455
Validation loss: 2.5521959087027217

Epoch: 6| Step: 13
Training loss: 2.4591966072344538
Validation loss: 2.5536501091732116

Epoch: 424| Step: 0
Training loss: 3.0243741735846283
Validation loss: 2.572171157082796

Epoch: 6| Step: 1
Training loss: 2.5933821084045583
Validation loss: 2.6026810196370107

Epoch: 6| Step: 2
Training loss: 3.037147526639392
Validation loss: 2.61680019735002

Epoch: 6| Step: 3
Training loss: 3.2054589676992458
Validation loss: 2.6280024556424935

Epoch: 6| Step: 4
Training loss: 2.3705802751139387
Validation loss: 2.6040496392975654

Epoch: 6| Step: 5
Training loss: 3.0552966981151246
Validation loss: 2.560500583718485

Epoch: 6| Step: 6
Training loss: 2.5561041680781336
Validation loss: 2.5606035722944314

Epoch: 6| Step: 7
Training loss: 3.2935974317391006
Validation loss: 2.535341261975841

Epoch: 6| Step: 8
Training loss: 3.222138038354038
Validation loss: 2.5139922250322395

Epoch: 6| Step: 9
Training loss: 2.756791571524649
Validation loss: 2.5039688242545077

Epoch: 6| Step: 10
Training loss: 2.6213457012033503
Validation loss: 2.5062946056101203

Epoch: 6| Step: 11
Training loss: 2.8471150034330255
Validation loss: 2.525230396350607

Epoch: 6| Step: 12
Training loss: 1.9834885907778985
Validation loss: 2.525452583686787

Epoch: 6| Step: 13
Training loss: 2.813435293025374
Validation loss: 2.5142427199716537

Epoch: 425| Step: 0
Training loss: 2.963421506853643
Validation loss: 2.5073054130698798

Epoch: 6| Step: 1
Training loss: 2.7124335039136125
Validation loss: 2.5310307970821304

Epoch: 6| Step: 2
Training loss: 3.0877467006702477
Validation loss: 2.5683541915356516

Epoch: 6| Step: 3
Training loss: 2.8210137253690744
Validation loss: 2.5646408896160646

Epoch: 6| Step: 4
Training loss: 2.826927395153091
Validation loss: 2.5850400721618643

Epoch: 6| Step: 5
Training loss: 2.33772316749634
Validation loss: 2.6163291114872975

Epoch: 6| Step: 6
Training loss: 2.284094408913376
Validation loss: 2.6354725060186714

Epoch: 6| Step: 7
Training loss: 2.878277941687865
Validation loss: 2.6065418596504575

Epoch: 6| Step: 8
Training loss: 2.3175132640800595
Validation loss: 2.5760750444850755

Epoch: 6| Step: 9
Training loss: 3.1284897201976425
Validation loss: 2.5678574048026253

Epoch: 6| Step: 10
Training loss: 3.252066908670053
Validation loss: 2.5482440074709674

Epoch: 6| Step: 11
Training loss: 2.612576833078835
Validation loss: 2.5349487197497216

Epoch: 6| Step: 12
Training loss: 3.5803234559456127
Validation loss: 2.528116265135861

Epoch: 6| Step: 13
Training loss: 2.1266312789165083
Validation loss: 2.5223571218090175

Epoch: 426| Step: 0
Training loss: 3.023148081724685
Validation loss: 2.5106764170413154

Epoch: 6| Step: 1
Training loss: 2.8982022336499895
Validation loss: 2.503159055014356

Epoch: 6| Step: 2
Training loss: 2.761559466957878
Validation loss: 2.505890320281252

Epoch: 6| Step: 3
Training loss: 3.254962653489338
Validation loss: 2.500155213367679

Epoch: 6| Step: 4
Training loss: 2.947854965876257
Validation loss: 2.49474204899071

Epoch: 6| Step: 5
Training loss: 2.3057234165512592
Validation loss: 2.5032815499976477

Epoch: 6| Step: 6
Training loss: 2.605572425346647
Validation loss: 2.5161915567042836

Epoch: 6| Step: 7
Training loss: 2.8489145186063713
Validation loss: 2.5224948520441806

Epoch: 6| Step: 8
Training loss: 3.2159135783525987
Validation loss: 2.536470633051168

Epoch: 6| Step: 9
Training loss: 3.19162169608231
Validation loss: 2.547639310485594

Epoch: 6| Step: 10
Training loss: 2.865093079497944
Validation loss: 2.57158622671028

Epoch: 6| Step: 11
Training loss: 2.0253261162280003
Validation loss: 2.5872827142728525

Epoch: 6| Step: 12
Training loss: 2.7853693084761364
Validation loss: 2.6136718666038568

Epoch: 6| Step: 13
Training loss: 2.753173384311644
Validation loss: 2.6337885252019317

Epoch: 427| Step: 0
Training loss: 2.2508685237087813
Validation loss: 2.6363359629955374

Epoch: 6| Step: 1
Training loss: 2.8494490643092347
Validation loss: 2.592107085220145

Epoch: 6| Step: 2
Training loss: 2.4383666625214504
Validation loss: 2.568220455936099

Epoch: 6| Step: 3
Training loss: 2.564661928321078
Validation loss: 2.5502173976732294

Epoch: 6| Step: 4
Training loss: 3.3113859210517353
Validation loss: 2.5243524500196726

Epoch: 6| Step: 5
Training loss: 2.724649364765894
Validation loss: 2.5195666325393105

Epoch: 6| Step: 6
Training loss: 2.84777982467212
Validation loss: 2.517322285406619

Epoch: 6| Step: 7
Training loss: 3.0846615241789497
Validation loss: 2.520819690829808

Epoch: 6| Step: 8
Training loss: 2.944339662362901
Validation loss: 2.5317658273905903

Epoch: 6| Step: 9
Training loss: 2.7953510927848746
Validation loss: 2.5082371708390214

Epoch: 6| Step: 10
Training loss: 3.0560365317592764
Validation loss: 2.5223312093982955

Epoch: 6| Step: 11
Training loss: 2.690128460479279
Validation loss: 2.538282033712317

Epoch: 6| Step: 12
Training loss: 3.2114646460344995
Validation loss: 2.5202506305568924

Epoch: 6| Step: 13
Training loss: 2.0442499698295094
Validation loss: 2.5402689405130983

Epoch: 428| Step: 0
Training loss: 2.44446858721669
Validation loss: 2.548248991398429

Epoch: 6| Step: 1
Training loss: 2.8844353468048927
Validation loss: 2.5598497569471643

Epoch: 6| Step: 2
Training loss: 2.366091433540767
Validation loss: 2.59206015786801

Epoch: 6| Step: 3
Training loss: 2.647184812751336
Validation loss: 2.5961543104897453

Epoch: 6| Step: 4
Training loss: 2.5663610074077687
Validation loss: 2.6244464667627603

Epoch: 6| Step: 5
Training loss: 2.9101736183416276
Validation loss: 2.627945789651778

Epoch: 6| Step: 6
Training loss: 3.232144826212511
Validation loss: 2.623943133681164

Epoch: 6| Step: 7
Training loss: 2.775587940651545
Validation loss: 2.632952693481911

Epoch: 6| Step: 8
Training loss: 2.9026136722040565
Validation loss: 2.6430302865430204

Epoch: 6| Step: 9
Training loss: 2.760548129040282
Validation loss: 2.588356014049831

Epoch: 6| Step: 10
Training loss: 2.922800825184003
Validation loss: 2.5579092170103555

Epoch: 6| Step: 11
Training loss: 2.7532286331122164
Validation loss: 2.527437915497347

Epoch: 6| Step: 12
Training loss: 2.9624460851213774
Validation loss: 2.503416835631583

Epoch: 6| Step: 13
Training loss: 3.490908668077328
Validation loss: 2.514017675794765

Epoch: 429| Step: 0
Training loss: 3.5115059691602055
Validation loss: 2.5053063140395206

Epoch: 6| Step: 1
Training loss: 2.5959568976011296
Validation loss: 2.5028716811646397

Epoch: 6| Step: 2
Training loss: 2.299361148511512
Validation loss: 2.5050775893232142

Epoch: 6| Step: 3
Training loss: 2.981581893776261
Validation loss: 2.5118281442478243

Epoch: 6| Step: 4
Training loss: 3.1547308561265837
Validation loss: 2.506015122626089

Epoch: 6| Step: 5
Training loss: 2.4791508094430066
Validation loss: 2.506182064714707

Epoch: 6| Step: 6
Training loss: 2.6963034756892474
Validation loss: 2.5128292669780072

Epoch: 6| Step: 7
Training loss: 3.0600409463873017
Validation loss: 2.5110783008673185

Epoch: 6| Step: 8
Training loss: 3.2046017103834266
Validation loss: 2.5115192129745805

Epoch: 6| Step: 9
Training loss: 2.942674988864365
Validation loss: 2.514499135939947

Epoch: 6| Step: 10
Training loss: 2.8797134240940063
Validation loss: 2.5402605560616687

Epoch: 6| Step: 11
Training loss: 2.9674581829103803
Validation loss: 2.538308433715627

Epoch: 6| Step: 12
Training loss: 1.9537497780007147
Validation loss: 2.545197076650003

Epoch: 6| Step: 13
Training loss: 1.9204815410709148
Validation loss: 2.5961261188781797

Epoch: 430| Step: 0
Training loss: 2.63120725692138
Validation loss: 2.623567238020547

Epoch: 6| Step: 1
Training loss: 2.8865553792890646
Validation loss: 2.6367208608286927

Epoch: 6| Step: 2
Training loss: 3.3408505712419516
Validation loss: 2.6779780373317426

Epoch: 6| Step: 3
Training loss: 2.68914700097726
Validation loss: 2.675177584881204

Epoch: 6| Step: 4
Training loss: 2.537837933367219
Validation loss: 2.673015480368865

Epoch: 6| Step: 5
Training loss: 3.012135280200414
Validation loss: 2.637361752198886

Epoch: 6| Step: 6
Training loss: 3.580735632688291
Validation loss: 2.604256533805151

Epoch: 6| Step: 7
Training loss: 3.283076622572214
Validation loss: 2.576340075308322

Epoch: 6| Step: 8
Training loss: 2.9030609682246586
Validation loss: 2.5605528101555803

Epoch: 6| Step: 9
Training loss: 2.4744858564156464
Validation loss: 2.5541293620287853

Epoch: 6| Step: 10
Training loss: 2.286709458124058
Validation loss: 2.5559162808512474

Epoch: 6| Step: 11
Training loss: 3.1173629520152395
Validation loss: 2.538881330692106

Epoch: 6| Step: 12
Training loss: 2.242110300894984
Validation loss: 2.5373003987991445

Epoch: 6| Step: 13
Training loss: 2.6103296418131223
Validation loss: 2.531139874237068

Epoch: 431| Step: 0
Training loss: 2.9141631326353092
Validation loss: 2.5308436608551443

Epoch: 6| Step: 1
Training loss: 3.0997798226213535
Validation loss: 2.52898667514682

Epoch: 6| Step: 2
Training loss: 2.356694296477496
Validation loss: 2.540843596013149

Epoch: 6| Step: 3
Training loss: 2.4263170421521765
Validation loss: 2.5304403637021355

Epoch: 6| Step: 4
Training loss: 3.145490076061839
Validation loss: 2.5255554275891385

Epoch: 6| Step: 5
Training loss: 2.4968843118544095
Validation loss: 2.535329576961323

Epoch: 6| Step: 6
Training loss: 2.6045543432954044
Validation loss: 2.531471725834161

Epoch: 6| Step: 7
Training loss: 2.9171458441074654
Validation loss: 2.5296288345977915

Epoch: 6| Step: 8
Training loss: 2.4972261298911307
Validation loss: 2.5253722964692833

Epoch: 6| Step: 9
Training loss: 2.7291929132107042
Validation loss: 2.5194275557647607

Epoch: 6| Step: 10
Training loss: 2.7912556549711978
Validation loss: 2.53401763712129

Epoch: 6| Step: 11
Training loss: 3.115571867739423
Validation loss: 2.52630298016861

Epoch: 6| Step: 12
Training loss: 2.695787294005498
Validation loss: 2.5337296998211403

Epoch: 6| Step: 13
Training loss: 3.8770260590195798
Validation loss: 2.5458314590872826

Epoch: 432| Step: 0
Training loss: 2.598729879751845
Validation loss: 2.5495572883513877

Epoch: 6| Step: 1
Training loss: 3.4721198681474377
Validation loss: 2.5690686832930463

Epoch: 6| Step: 2
Training loss: 3.062856536663866
Validation loss: 2.5836406247795756

Epoch: 6| Step: 3
Training loss: 2.6634963879984173
Validation loss: 2.5835445117938662

Epoch: 6| Step: 4
Training loss: 2.617475715823321
Validation loss: 2.5971326064745153

Epoch: 6| Step: 5
Training loss: 2.459731808751492
Validation loss: 2.581280402349347

Epoch: 6| Step: 6
Training loss: 2.850299712366646
Validation loss: 2.5753132143889963

Epoch: 6| Step: 7
Training loss: 2.580483577268747
Validation loss: 2.594052922844605

Epoch: 6| Step: 8
Training loss: 2.650530772766159
Validation loss: 2.596768126216

Epoch: 6| Step: 9
Training loss: 2.7142421138101094
Validation loss: 2.6020980303968737

Epoch: 6| Step: 10
Training loss: 2.9541872727751963
Validation loss: 2.606620568293042

Epoch: 6| Step: 11
Training loss: 2.5793550273620216
Validation loss: 2.6133402312482583

Epoch: 6| Step: 12
Training loss: 2.8608449690734297
Validation loss: 2.6129944307309607

Epoch: 6| Step: 13
Training loss: 3.302397816280634
Validation loss: 2.564627825180119

Epoch: 433| Step: 0
Training loss: 2.2160914437193853
Validation loss: 2.5402553021411927

Epoch: 6| Step: 1
Training loss: 2.9950886896977313
Validation loss: 2.5163010468620395

Epoch: 6| Step: 2
Training loss: 3.4970004989017154
Validation loss: 2.506151079049444

Epoch: 6| Step: 3
Training loss: 2.270166094917009
Validation loss: 2.5006569409405426

Epoch: 6| Step: 4
Training loss: 3.5759942652850496
Validation loss: 2.5030635531491576

Epoch: 6| Step: 5
Training loss: 2.8865377036426842
Validation loss: 2.5004821537999553

Epoch: 6| Step: 6
Training loss: 2.5193263717269847
Validation loss: 2.492191284477186

Epoch: 6| Step: 7
Training loss: 3.0603792282179363
Validation loss: 2.501211882724299

Epoch: 6| Step: 8
Training loss: 2.4707803224105795
Validation loss: 2.5033731121274156

Epoch: 6| Step: 9
Training loss: 2.826663319237844
Validation loss: 2.5325844995642774

Epoch: 6| Step: 10
Training loss: 2.3740669224537077
Validation loss: 2.549114734988367

Epoch: 6| Step: 11
Training loss: 2.9856749893804437
Validation loss: 2.5609681097325545

Epoch: 6| Step: 12
Training loss: 2.6722768737886327
Validation loss: 2.581649539831145

Epoch: 6| Step: 13
Training loss: 2.6519010958173137
Validation loss: 2.5805096061287993

Epoch: 434| Step: 0
Training loss: 3.3878198789346063
Validation loss: 2.59110103887329

Epoch: 6| Step: 1
Training loss: 3.241285966290385
Validation loss: 2.5896367098090796

Epoch: 6| Step: 2
Training loss: 2.5799558669758698
Validation loss: 2.587520792642119

Epoch: 6| Step: 3
Training loss: 2.9056271121386037
Validation loss: 2.5626069633595656

Epoch: 6| Step: 4
Training loss: 3.165412972552586
Validation loss: 2.549675845905331

Epoch: 6| Step: 5
Training loss: 2.7435700933263267
Validation loss: 2.543254969953519

Epoch: 6| Step: 6
Training loss: 2.6640521186335486
Validation loss: 2.545823862302452

Epoch: 6| Step: 7
Training loss: 2.175701694643525
Validation loss: 2.5283166135351838

Epoch: 6| Step: 8
Training loss: 2.781457786084751
Validation loss: 2.5274529680189177

Epoch: 6| Step: 9
Training loss: 2.3193244243135296
Validation loss: 2.5581111384852786

Epoch: 6| Step: 10
Training loss: 3.13118954902819
Validation loss: 2.5876966272235924

Epoch: 6| Step: 11
Training loss: 2.0473061609795122
Validation loss: 2.596562192036401

Epoch: 6| Step: 12
Training loss: 2.6922338622313835
Validation loss: 2.583870000069512

Epoch: 6| Step: 13
Training loss: 3.1467510846770224
Validation loss: 2.603337448179049

Epoch: 435| Step: 0
Training loss: 3.131322339834605
Validation loss: 2.594112504835291

Epoch: 6| Step: 1
Training loss: 2.978107842218823
Validation loss: 2.584153616400573

Epoch: 6| Step: 2
Training loss: 3.252051952796345
Validation loss: 2.5498045115503953

Epoch: 6| Step: 3
Training loss: 2.3633998872597943
Validation loss: 2.5432243664163585

Epoch: 6| Step: 4
Training loss: 2.5955321841933205
Validation loss: 2.5275568563742614

Epoch: 6| Step: 5
Training loss: 2.390366284701284
Validation loss: 2.524498869743058

Epoch: 6| Step: 6
Training loss: 2.6603763618094733
Validation loss: 2.5138694809873576

Epoch: 6| Step: 7
Training loss: 2.6641432226933577
Validation loss: 2.5257713421028036

Epoch: 6| Step: 8
Training loss: 2.7391953187501428
Validation loss: 2.5421118199347186

Epoch: 6| Step: 9
Training loss: 2.8707575802342937
Validation loss: 2.559191577201499

Epoch: 6| Step: 10
Training loss: 2.1176277631927722
Validation loss: 2.557657771032542

Epoch: 6| Step: 11
Training loss: 3.604657810388203
Validation loss: 2.5995822045663326

Epoch: 6| Step: 12
Training loss: 2.259185057025477
Validation loss: 2.6339232040013303

Epoch: 6| Step: 13
Training loss: 3.4949229064646543
Validation loss: 2.6490859242393183

Epoch: 436| Step: 0
Training loss: 2.997765503642929
Validation loss: 2.5809757902118733

Epoch: 6| Step: 1
Training loss: 2.589967106201555
Validation loss: 2.520879338440536

Epoch: 6| Step: 2
Training loss: 2.681694058013045
Validation loss: 2.5328643959710084

Epoch: 6| Step: 3
Training loss: 2.3327075482398634
Validation loss: 2.506533009374422

Epoch: 6| Step: 4
Training loss: 3.1218939031232944
Validation loss: 2.508112978888253

Epoch: 6| Step: 5
Training loss: 2.1595215235682175
Validation loss: 2.493623145974173

Epoch: 6| Step: 6
Training loss: 2.9606279598879217
Validation loss: 2.5088084931642345

Epoch: 6| Step: 7
Training loss: 2.9251773552229747
Validation loss: 2.4955485326184506

Epoch: 6| Step: 8
Training loss: 2.696014931962859
Validation loss: 2.5259314755423925

Epoch: 6| Step: 9
Training loss: 2.8960447897424406
Validation loss: 2.5256788633680087

Epoch: 6| Step: 10
Training loss: 3.2611485513952867
Validation loss: 2.5396355660483643

Epoch: 6| Step: 11
Training loss: 2.368572874668619
Validation loss: 2.5615252309805294

Epoch: 6| Step: 12
Training loss: 3.0509806823018883
Validation loss: 2.5660904372413955

Epoch: 6| Step: 13
Training loss: 3.1596739675635566
Validation loss: 2.5562660072367636

Epoch: 437| Step: 0
Training loss: 2.7827017777620298
Validation loss: 2.5819538957439385

Epoch: 6| Step: 1
Training loss: 3.244902060372345
Validation loss: 2.605291553989303

Epoch: 6| Step: 2
Training loss: 2.77728520370562
Validation loss: 2.586368903636359

Epoch: 6| Step: 3
Training loss: 3.0582427972044393
Validation loss: 2.609708056760659

Epoch: 6| Step: 4
Training loss: 2.356184564385085
Validation loss: 2.6262900761231966

Epoch: 6| Step: 5
Training loss: 2.8747699479650795
Validation loss: 2.6398527051561955

Epoch: 6| Step: 6
Training loss: 2.660133664207533
Validation loss: 2.6588037528710635

Epoch: 6| Step: 7
Training loss: 2.2499947018031152
Validation loss: 2.6586671277947

Epoch: 6| Step: 8
Training loss: 2.4555916988748865
Validation loss: 2.644591761950805

Epoch: 6| Step: 9
Training loss: 3.312275141155664
Validation loss: 2.619677451101883

Epoch: 6| Step: 10
Training loss: 2.8568629502380527
Validation loss: 2.603707295581451

Epoch: 6| Step: 11
Training loss: 2.6842358305518825
Validation loss: 2.5604376328407903

Epoch: 6| Step: 12
Training loss: 2.79802965592653
Validation loss: 2.5495362858884305

Epoch: 6| Step: 13
Training loss: 2.979244595733297
Validation loss: 2.5323940169671544

Epoch: 438| Step: 0
Training loss: 2.2985647823688455
Validation loss: 2.5142559100936763

Epoch: 6| Step: 1
Training loss: 2.0302654521247483
Validation loss: 2.5011629968078872

Epoch: 6| Step: 2
Training loss: 2.746014828585646
Validation loss: 2.500790764227177

Epoch: 6| Step: 3
Training loss: 2.923267705768639
Validation loss: 2.4982259577888515

Epoch: 6| Step: 4
Training loss: 2.5226582838743155
Validation loss: 2.505265828492075

Epoch: 6| Step: 5
Training loss: 2.7477716607701312
Validation loss: 2.5142408213877867

Epoch: 6| Step: 6
Training loss: 2.8752862539006645
Validation loss: 2.5068833731315183

Epoch: 6| Step: 7
Training loss: 2.817355563397256
Validation loss: 2.505120395824858

Epoch: 6| Step: 8
Training loss: 2.817875281915641
Validation loss: 2.5087099322096065

Epoch: 6| Step: 9
Training loss: 2.716830222544258
Validation loss: 2.5152453166145

Epoch: 6| Step: 10
Training loss: 3.468533758348085
Validation loss: 2.5218843631631813

Epoch: 6| Step: 11
Training loss: 3.0941986375207167
Validation loss: 2.5299765582629865

Epoch: 6| Step: 12
Training loss: 3.252248426438317
Validation loss: 2.5341328032853947

Epoch: 6| Step: 13
Training loss: 2.936649280486526
Validation loss: 2.5231818684283644

Epoch: 439| Step: 0
Training loss: 2.389610424292821
Validation loss: 2.5345863879769683

Epoch: 6| Step: 1
Training loss: 3.5256908848933866
Validation loss: 2.545633167923559

Epoch: 6| Step: 2
Training loss: 2.8938898567693956
Validation loss: 2.5597935612341436

Epoch: 6| Step: 3
Training loss: 2.9207459578639186
Validation loss: 2.557507847767183

Epoch: 6| Step: 4
Training loss: 2.3358335950318034
Validation loss: 2.5581624125651987

Epoch: 6| Step: 5
Training loss: 2.4171265350919278
Validation loss: 2.5625063558200036

Epoch: 6| Step: 6
Training loss: 2.2016410429178395
Validation loss: 2.5697505917833277

Epoch: 6| Step: 7
Training loss: 2.8530102542729017
Validation loss: 2.580444070520942

Epoch: 6| Step: 8
Training loss: 2.918144905053491
Validation loss: 2.5732257460252046

Epoch: 6| Step: 9
Training loss: 2.770166924057085
Validation loss: 2.5900553970075904

Epoch: 6| Step: 10
Training loss: 2.5789698285826264
Validation loss: 2.5783191616496324

Epoch: 6| Step: 11
Training loss: 2.986595086988366
Validation loss: 2.580123254244177

Epoch: 6| Step: 12
Training loss: 2.9202914103016404
Validation loss: 2.5782327728268206

Epoch: 6| Step: 13
Training loss: 2.844759918970673
Validation loss: 2.5935524396877967

Epoch: 440| Step: 0
Training loss: 2.7755693865338893
Validation loss: 2.5897278410911753

Epoch: 6| Step: 1
Training loss: 2.874727650886682
Validation loss: 2.573003510302406

Epoch: 6| Step: 2
Training loss: 3.482114871405183
Validation loss: 2.5295768037772897

Epoch: 6| Step: 3
Training loss: 2.3867373301880095
Validation loss: 2.5162978131469735

Epoch: 6| Step: 4
Training loss: 2.244225934484634
Validation loss: 2.5276197914257996

Epoch: 6| Step: 5
Training loss: 2.477763080505817
Validation loss: 2.5310291668447835

Epoch: 6| Step: 6
Training loss: 2.6337519477942046
Validation loss: 2.540560703800759

Epoch: 6| Step: 7
Training loss: 3.403088563666212
Validation loss: 2.542976682955014

Epoch: 6| Step: 8
Training loss: 2.638023404079037
Validation loss: 2.5276314015291295

Epoch: 6| Step: 9
Training loss: 2.388701219604605
Validation loss: 2.5473678105036437

Epoch: 6| Step: 10
Training loss: 2.5691572103244877
Validation loss: 2.5511208047412652

Epoch: 6| Step: 11
Training loss: 2.89525797957808
Validation loss: 2.5695846698577616

Epoch: 6| Step: 12
Training loss: 2.7591365413083064
Validation loss: 2.535106954811561

Epoch: 6| Step: 13
Training loss: 3.1861928615781996
Validation loss: 2.554886911660136

Epoch: 441| Step: 0
Training loss: 2.785140242136018
Validation loss: 2.574135545966936

Epoch: 6| Step: 1
Training loss: 2.3918379156319394
Validation loss: 2.5684152904699644

Epoch: 6| Step: 2
Training loss: 2.7957650651475547
Validation loss: 2.55592976544542

Epoch: 6| Step: 3
Training loss: 2.7348785808607263
Validation loss: 2.5179035311201066

Epoch: 6| Step: 4
Training loss: 2.7549306709164925
Validation loss: 2.5520071038787533

Epoch: 6| Step: 5
Training loss: 2.840304456697958
Validation loss: 2.5528958950516776

Epoch: 6| Step: 6
Training loss: 3.0103473237354996
Validation loss: 2.541762403812996

Epoch: 6| Step: 7
Training loss: 2.258945062233576
Validation loss: 2.546515576253511

Epoch: 6| Step: 8
Training loss: 3.0176753056256906
Validation loss: 2.5612845630952434

Epoch: 6| Step: 9
Training loss: 2.8135014764277853
Validation loss: 2.5482804933369385

Epoch: 6| Step: 10
Training loss: 3.182058738928803
Validation loss: 2.55332259492724

Epoch: 6| Step: 11
Training loss: 2.8838513991209593
Validation loss: 2.5543832373522077

Epoch: 6| Step: 12
Training loss: 2.5593659378655196
Validation loss: 2.5456589025590475

Epoch: 6| Step: 13
Training loss: 2.4394361191485907
Validation loss: 2.5781949001169844

Epoch: 442| Step: 0
Training loss: 2.779263075986948
Validation loss: 2.5910985436001615

Epoch: 6| Step: 1
Training loss: 2.80715332445296
Validation loss: 2.616095158071506

Epoch: 6| Step: 2
Training loss: 3.190232545514199
Validation loss: 2.5960218179187162

Epoch: 6| Step: 3
Training loss: 2.8239285015208266
Validation loss: 2.593256578635295

Epoch: 6| Step: 4
Training loss: 2.893467675560617
Validation loss: 2.571796613019081

Epoch: 6| Step: 5
Training loss: 2.270686526904759
Validation loss: 2.5591053190540425

Epoch: 6| Step: 6
Training loss: 3.3464168003420207
Validation loss: 2.5448732676260377

Epoch: 6| Step: 7
Training loss: 2.6398106509998636
Validation loss: 2.534741645843828

Epoch: 6| Step: 8
Training loss: 2.5522241877916083
Validation loss: 2.536053225295189

Epoch: 6| Step: 9
Training loss: 2.350488766102743
Validation loss: 2.5546475852930666

Epoch: 6| Step: 10
Training loss: 2.3310778025011256
Validation loss: 2.551768257894545

Epoch: 6| Step: 11
Training loss: 2.8236841563754647
Validation loss: 2.5879394734671917

Epoch: 6| Step: 12
Training loss: 2.8099026872883033
Validation loss: 2.6094131884483156

Epoch: 6| Step: 13
Training loss: 3.2123683145451203
Validation loss: 2.591971251903323

Epoch: 443| Step: 0
Training loss: 2.0602721695588406
Validation loss: 2.596009965103474

Epoch: 6| Step: 1
Training loss: 2.0213911984111737
Validation loss: 2.5502422446517494

Epoch: 6| Step: 2
Training loss: 2.6278231743441407
Validation loss: 2.556950624710127

Epoch: 6| Step: 3
Training loss: 2.810716529799594
Validation loss: 2.54752313271318

Epoch: 6| Step: 4
Training loss: 2.973370299629816
Validation loss: 2.5419499151864815

Epoch: 6| Step: 5
Training loss: 3.0598748302415255
Validation loss: 2.5385358083987453

Epoch: 6| Step: 6
Training loss: 3.2666152839771603
Validation loss: 2.508352033592896

Epoch: 6| Step: 7
Training loss: 2.8114338019479663
Validation loss: 2.5294897110720544

Epoch: 6| Step: 8
Training loss: 3.2720465060428956
Validation loss: 2.5270996432325914

Epoch: 6| Step: 9
Training loss: 2.6664532536304453
Validation loss: 2.5591227137678807

Epoch: 6| Step: 10
Training loss: 3.0517798436704764
Validation loss: 2.5315749439511626

Epoch: 6| Step: 11
Training loss: 2.849418440259849
Validation loss: 2.563938657427887

Epoch: 6| Step: 12
Training loss: 2.3274337459193735
Validation loss: 2.587592549229618

Epoch: 6| Step: 13
Training loss: 2.4110248305103377
Validation loss: 2.5807595830720764

Epoch: 444| Step: 0
Training loss: 2.691888464262277
Validation loss: 2.6249665328010194

Epoch: 6| Step: 1
Training loss: 2.7764253237900642
Validation loss: 2.6215694794062054

Epoch: 6| Step: 2
Training loss: 2.7767231995077526
Validation loss: 2.623229839701678

Epoch: 6| Step: 3
Training loss: 3.1843159049618137
Validation loss: 2.609131007128206

Epoch: 6| Step: 4
Training loss: 2.9539367528922975
Validation loss: 2.5935806859629644

Epoch: 6| Step: 5
Training loss: 2.791650933368435
Validation loss: 2.591564291889429

Epoch: 6| Step: 6
Training loss: 2.690665753595344
Validation loss: 2.570080691799693

Epoch: 6| Step: 7
Training loss: 2.340643184168506
Validation loss: 2.5599840339872895

Epoch: 6| Step: 8
Training loss: 2.8389279910499137
Validation loss: 2.5455439063806464

Epoch: 6| Step: 9
Training loss: 2.5982807527335523
Validation loss: 2.540943280514267

Epoch: 6| Step: 10
Training loss: 2.9075183356798378
Validation loss: 2.538782417493224

Epoch: 6| Step: 11
Training loss: 2.4677267730612225
Validation loss: 2.5544672914967914

Epoch: 6| Step: 12
Training loss: 2.8208504372495637
Validation loss: 2.547689890690113

Epoch: 6| Step: 13
Training loss: 2.5975495051199835
Validation loss: 2.5475422377545978

Epoch: 445| Step: 0
Training loss: 2.6648545863575115
Validation loss: 2.547469744507829

Epoch: 6| Step: 1
Training loss: 3.028221583917483
Validation loss: 2.548181537529941

Epoch: 6| Step: 2
Training loss: 2.713934920523728
Validation loss: 2.5477838163667412

Epoch: 6| Step: 3
Training loss: 2.531108522582226
Validation loss: 2.534120203226134

Epoch: 6| Step: 4
Training loss: 3.1593460157142137
Validation loss: 2.5322047845470843

Epoch: 6| Step: 5
Training loss: 3.272048983461418
Validation loss: 2.5320104724915837

Epoch: 6| Step: 6
Training loss: 2.492409436140716
Validation loss: 2.524659932800671

Epoch: 6| Step: 7
Training loss: 2.9054986125973588
Validation loss: 2.535500982110119

Epoch: 6| Step: 8
Training loss: 2.6460102853149827
Validation loss: 2.5285902493182717

Epoch: 6| Step: 9
Training loss: 2.6917231889425617
Validation loss: 2.532805794800271

Epoch: 6| Step: 10
Training loss: 2.5213773366368737
Validation loss: 2.5586019912107307

Epoch: 6| Step: 11
Training loss: 2.5009137391135785
Validation loss: 2.6357486721141528

Epoch: 6| Step: 12
Training loss: 2.7362962349252524
Validation loss: 2.662517271361852

Epoch: 6| Step: 13
Training loss: 2.4157610106084535
Validation loss: 2.7268306328721783

Epoch: 446| Step: 0
Training loss: 3.387345094411736
Validation loss: 2.7584847901420453

Epoch: 6| Step: 1
Training loss: 2.471076352121216
Validation loss: 2.75961134515582

Epoch: 6| Step: 2
Training loss: 2.6578655939556928
Validation loss: 2.7158256978177464

Epoch: 6| Step: 3
Training loss: 2.6817932752266764
Validation loss: 2.7083039385491703

Epoch: 6| Step: 4
Training loss: 2.3616627092492064
Validation loss: 2.7263347985379753

Epoch: 6| Step: 5
Training loss: 2.6942292178824006
Validation loss: 2.699032759366413

Epoch: 6| Step: 6
Training loss: 3.4201602907151254
Validation loss: 2.6300425237300242

Epoch: 6| Step: 7
Training loss: 2.5457799698834567
Validation loss: 2.5817584117228387

Epoch: 6| Step: 8
Training loss: 3.0878662262832726
Validation loss: 2.549035913162559

Epoch: 6| Step: 9
Training loss: 2.5011872333541816
Validation loss: 2.54162600313443

Epoch: 6| Step: 10
Training loss: 3.047206449820417
Validation loss: 2.492970446527618

Epoch: 6| Step: 11
Training loss: 2.7238475322373925
Validation loss: 2.4993215624796155

Epoch: 6| Step: 12
Training loss: 2.172243594720041
Validation loss: 2.5061621206328075

Epoch: 6| Step: 13
Training loss: 2.9150539480880404
Validation loss: 2.4994243410260415

Epoch: 447| Step: 0
Training loss: 3.0126258285646044
Validation loss: 2.5125782597250454

Epoch: 6| Step: 1
Training loss: 3.143127203770091
Validation loss: 2.493124686725434

Epoch: 6| Step: 2
Training loss: 2.7359775751600313
Validation loss: 2.4859113853811676

Epoch: 6| Step: 3
Training loss: 2.9269596675574148
Validation loss: 2.524254676765108

Epoch: 6| Step: 4
Training loss: 2.5493203809554106
Validation loss: 2.5234528547479105

Epoch: 6| Step: 5
Training loss: 2.4416627794913985
Validation loss: 2.558817863402615

Epoch: 6| Step: 6
Training loss: 2.6087441052898934
Validation loss: 2.584884978084776

Epoch: 6| Step: 7
Training loss: 3.3295299448000635
Validation loss: 2.6549553540958306

Epoch: 6| Step: 8
Training loss: 2.673367445990494
Validation loss: 2.695613361703653

Epoch: 6| Step: 9
Training loss: 2.3258156812000945
Validation loss: 2.7119828680653284

Epoch: 6| Step: 10
Training loss: 2.863414308545023
Validation loss: 2.70678959117223

Epoch: 6| Step: 11
Training loss: 2.878369554366483
Validation loss: 2.6973194427834626

Epoch: 6| Step: 12
Training loss: 2.5895798952955
Validation loss: 2.7117557329271795

Epoch: 6| Step: 13
Training loss: 2.5179420367986016
Validation loss: 2.654872300065055

Epoch: 448| Step: 0
Training loss: 2.8637265305408675
Validation loss: 2.6156669028109856

Epoch: 6| Step: 1
Training loss: 2.6338276250305417
Validation loss: 2.5837849299357414

Epoch: 6| Step: 2
Training loss: 2.78116676120282
Validation loss: 2.5353013986245703

Epoch: 6| Step: 3
Training loss: 3.0014227036781715
Validation loss: 2.521374699154895

Epoch: 6| Step: 4
Training loss: 2.712038195979665
Validation loss: 2.4943153292601457

Epoch: 6| Step: 5
Training loss: 2.805651145876115
Validation loss: 2.4917874610038013

Epoch: 6| Step: 6
Training loss: 2.27978217573496
Validation loss: 2.5122528026399786

Epoch: 6| Step: 7
Training loss: 2.6939723124451276
Validation loss: 2.524871344645782

Epoch: 6| Step: 8
Training loss: 2.91317612818185
Validation loss: 2.51671684721453

Epoch: 6| Step: 9
Training loss: 3.077655272297022
Validation loss: 2.5387796011834647

Epoch: 6| Step: 10
Training loss: 2.6454683387489712
Validation loss: 2.537040586177739

Epoch: 6| Step: 11
Training loss: 2.9313819969405737
Validation loss: 2.540371950545178

Epoch: 6| Step: 12
Training loss: 3.174706909588977
Validation loss: 2.5385204479331143

Epoch: 6| Step: 13
Training loss: 2.2816243321810634
Validation loss: 2.526790255691431

Epoch: 449| Step: 0
Training loss: 1.9403793105721583
Validation loss: 2.5744596287676598

Epoch: 6| Step: 1
Training loss: 2.7011239467514465
Validation loss: 2.620783435598187

Epoch: 6| Step: 2
Training loss: 2.951955089237801
Validation loss: 2.631584430490793

Epoch: 6| Step: 3
Training loss: 2.9741550431719586
Validation loss: 2.620711603703762

Epoch: 6| Step: 4
Training loss: 2.913123094434919
Validation loss: 2.6271757317673132

Epoch: 6| Step: 5
Training loss: 3.0226276900183753
Validation loss: 2.6076604240185155

Epoch: 6| Step: 6
Training loss: 2.8646862959419686
Validation loss: 2.5550197267257455

Epoch: 6| Step: 7
Training loss: 3.024698314913445
Validation loss: 2.5440681170117148

Epoch: 6| Step: 8
Training loss: 2.472279596794044
Validation loss: 2.5144345857888033

Epoch: 6| Step: 9
Training loss: 3.0099639728202363
Validation loss: 2.493507406309788

Epoch: 6| Step: 10
Training loss: 3.0366874769763035
Validation loss: 2.4820419287589117

Epoch: 6| Step: 11
Training loss: 3.0253654070123934
Validation loss: 2.5063444608359755

Epoch: 6| Step: 12
Training loss: 2.61818027171176
Validation loss: 2.5220528234899757

Epoch: 6| Step: 13
Training loss: 2.445226308260321
Validation loss: 2.5202487649810608

Epoch: 450| Step: 0
Training loss: 2.29345302894118
Validation loss: 2.534449006322405

Epoch: 6| Step: 1
Training loss: 2.8184892250438414
Validation loss: 2.5462023155400595

Epoch: 6| Step: 2
Training loss: 3.1782692785531292
Validation loss: 2.572202483652148

Epoch: 6| Step: 3
Training loss: 2.729532367772236
Validation loss: 2.5868128840290887

Epoch: 6| Step: 4
Training loss: 2.9923678908988482
Validation loss: 2.577681534190362

Epoch: 6| Step: 5
Training loss: 3.030971710959091
Validation loss: 2.5690716480140687

Epoch: 6| Step: 6
Training loss: 2.9125570136125996
Validation loss: 2.565221635248272

Epoch: 6| Step: 7
Training loss: 2.712789381210167
Validation loss: 2.551293416901327

Epoch: 6| Step: 8
Training loss: 3.268951765729724
Validation loss: 2.5353989824880268

Epoch: 6| Step: 9
Training loss: 2.4742562419145426
Validation loss: 2.5475437240876047

Epoch: 6| Step: 10
Training loss: 2.6424613752041486
Validation loss: 2.533661079281759

Epoch: 6| Step: 11
Training loss: 2.63006049518124
Validation loss: 2.516783408662894

Epoch: 6| Step: 12
Training loss: 3.0588710849180862
Validation loss: 2.5070132389839883

Epoch: 6| Step: 13
Training loss: 3.0239889741020423
Validation loss: 2.4975040373898425

Epoch: 451| Step: 0
Training loss: 3.359493093854525
Validation loss: 2.510649857693804

Epoch: 6| Step: 1
Training loss: 2.785024760220107
Validation loss: 2.5274701758624967

Epoch: 6| Step: 2
Training loss: 2.775917341491276
Validation loss: 2.535561150842656

Epoch: 6| Step: 3
Training loss: 2.3738902661512262
Validation loss: 2.5535627311714224

Epoch: 6| Step: 4
Training loss: 2.6859316130657382
Validation loss: 2.569442025622961

Epoch: 6| Step: 5
Training loss: 3.0606631005571825
Validation loss: 2.5710589905782806

Epoch: 6| Step: 6
Training loss: 2.7766071099179084
Validation loss: 2.585091211774919

Epoch: 6| Step: 7
Training loss: 2.816596967824203
Validation loss: 2.597336749378296

Epoch: 6| Step: 8
Training loss: 3.1270894503973072
Validation loss: 2.5745732348139105

Epoch: 6| Step: 9
Training loss: 2.748801230195628
Validation loss: 2.55092340813284

Epoch: 6| Step: 10
Training loss: 2.8610084745727598
Validation loss: 2.537885208751783

Epoch: 6| Step: 11
Training loss: 1.8528341441403056
Validation loss: 2.5344191582753

Epoch: 6| Step: 12
Training loss: 2.860856303089386
Validation loss: 2.540464957024161

Epoch: 6| Step: 13
Training loss: 2.481701834254193
Validation loss: 2.5058348818376843

Epoch: 452| Step: 0
Training loss: 2.843868546582577
Validation loss: 2.5166982202060146

Epoch: 6| Step: 1
Training loss: 2.328458621295733
Validation loss: 2.5174081075541475

Epoch: 6| Step: 2
Training loss: 2.355724921775455
Validation loss: 2.5056009023183985

Epoch: 6| Step: 3
Training loss: 2.748781541172395
Validation loss: 2.5016244553294573

Epoch: 6| Step: 4
Training loss: 2.5262920661908295
Validation loss: 2.502601613204596

Epoch: 6| Step: 5
Training loss: 2.5255967105526267
Validation loss: 2.5022385982965316

Epoch: 6| Step: 6
Training loss: 3.275372136063276
Validation loss: 2.5179539236622914

Epoch: 6| Step: 7
Training loss: 3.107955531937511
Validation loss: 2.5101863071358697

Epoch: 6| Step: 8
Training loss: 2.7895926177421364
Validation loss: 2.5040215765855516

Epoch: 6| Step: 9
Training loss: 2.7273558416128587
Validation loss: 2.524337721256815

Epoch: 6| Step: 10
Training loss: 2.495531284436555
Validation loss: 2.5489081516384586

Epoch: 6| Step: 11
Training loss: 2.758405238095021
Validation loss: 2.5543750317082012

Epoch: 6| Step: 12
Training loss: 3.678542556331939
Validation loss: 2.5685092287933737

Epoch: 6| Step: 13
Training loss: 2.532964996698437
Validation loss: 2.581814231624399

Epoch: 453| Step: 0
Training loss: 2.8070105492720123
Validation loss: 2.5986603583672316

Epoch: 6| Step: 1
Training loss: 2.260139190472312
Validation loss: 2.6986888765917545

Epoch: 6| Step: 2
Training loss: 2.309030765796025
Validation loss: 2.6883651574254435

Epoch: 6| Step: 3
Training loss: 2.28560859572063
Validation loss: 2.737458018117122

Epoch: 6| Step: 4
Training loss: 3.236953371067437
Validation loss: 2.7534867329546526

Epoch: 6| Step: 5
Training loss: 3.3100746920822024
Validation loss: 2.71026251231896

Epoch: 6| Step: 6
Training loss: 3.2356535370223907
Validation loss: 2.5782601309594746

Epoch: 6| Step: 7
Training loss: 2.9854676807745246
Validation loss: 2.528786634800944

Epoch: 6| Step: 8
Training loss: 2.962803074266794
Validation loss: 2.51063572247813

Epoch: 6| Step: 9
Training loss: 2.550032454639422
Validation loss: 2.473713885645615

Epoch: 6| Step: 10
Training loss: 3.2754801565636877
Validation loss: 2.479998263903608

Epoch: 6| Step: 11
Training loss: 2.6941503700764833
Validation loss: 2.4836745561711386

Epoch: 6| Step: 12
Training loss: 2.5384815666546814
Validation loss: 2.4840471233602113

Epoch: 6| Step: 13
Training loss: 2.200601850895466
Validation loss: 2.4962823420937097

Epoch: 454| Step: 0
Training loss: 3.2923138782955936
Validation loss: 2.4978673252201657

Epoch: 6| Step: 1
Training loss: 2.9308721563179256
Validation loss: 2.4970711297207253

Epoch: 6| Step: 2
Training loss: 2.2682055279755122
Validation loss: 2.498932668025983

Epoch: 6| Step: 3
Training loss: 3.282583347258933
Validation loss: 2.4972655303083444

Epoch: 6| Step: 4
Training loss: 2.7021862891785533
Validation loss: 2.496202827661192

Epoch: 6| Step: 5
Training loss: 2.795466574553486
Validation loss: 2.496926587345131

Epoch: 6| Step: 6
Training loss: 2.841860300516436
Validation loss: 2.4924365472852106

Epoch: 6| Step: 7
Training loss: 3.0095808899543988
Validation loss: 2.4901203247951447

Epoch: 6| Step: 8
Training loss: 2.545148954997526
Validation loss: 2.4898948620401997

Epoch: 6| Step: 9
Training loss: 3.11488199662608
Validation loss: 2.4898187443048263

Epoch: 6| Step: 10
Training loss: 2.868481086975804
Validation loss: 2.4903048757200237

Epoch: 6| Step: 11
Training loss: 2.9308760609864213
Validation loss: 2.5027245810595824

Epoch: 6| Step: 12
Training loss: 2.0695785661057133
Validation loss: 2.5197329230048506

Epoch: 6| Step: 13
Training loss: 3.1910601910371836
Validation loss: 2.5237337385107974

Epoch: 455| Step: 0
Training loss: 2.574375176778196
Validation loss: 2.555626046935599

Epoch: 6| Step: 1
Training loss: 2.598941249956901
Validation loss: 2.5689475598887253

Epoch: 6| Step: 2
Training loss: 2.505226108754966
Validation loss: 2.5944094560246658

Epoch: 6| Step: 3
Training loss: 2.880251028194001
Validation loss: 2.6236711567530584

Epoch: 6| Step: 4
Training loss: 2.953119025653266
Validation loss: 2.6648032987092205

Epoch: 6| Step: 5
Training loss: 3.067107957380862
Validation loss: 2.7163818478325457

Epoch: 6| Step: 6
Training loss: 2.9567948401823063
Validation loss: 2.742530208852803

Epoch: 6| Step: 7
Training loss: 3.0185599004625807
Validation loss: 2.7443678832042373

Epoch: 6| Step: 8
Training loss: 3.2129577073164075
Validation loss: 2.70743142217116

Epoch: 6| Step: 9
Training loss: 2.9695603720248873
Validation loss: 2.653562278768141

Epoch: 6| Step: 10
Training loss: 2.3122201698697804
Validation loss: 2.585362885225245

Epoch: 6| Step: 11
Training loss: 2.595399263276352
Validation loss: 2.5321905631218065

Epoch: 6| Step: 12
Training loss: 2.8066655996083507
Validation loss: 2.5058434377446153

Epoch: 6| Step: 13
Training loss: 2.5002093227492486
Validation loss: 2.4999888696730403

Epoch: 456| Step: 0
Training loss: 3.028781790509426
Validation loss: 2.483757609456304

Epoch: 6| Step: 1
Training loss: 2.4514008312516795
Validation loss: 2.498538617652443

Epoch: 6| Step: 2
Training loss: 3.069363124531598
Validation loss: 2.4956568266982724

Epoch: 6| Step: 3
Training loss: 3.4362602078871434
Validation loss: 2.497508107383999

Epoch: 6| Step: 4
Training loss: 2.8536466324307224
Validation loss: 2.4962017575101267

Epoch: 6| Step: 5
Training loss: 2.012166212371865
Validation loss: 2.4917578776779465

Epoch: 6| Step: 6
Training loss: 2.8917778396855938
Validation loss: 2.4992573691316875

Epoch: 6| Step: 7
Training loss: 2.335711924400486
Validation loss: 2.5019291971246957

Epoch: 6| Step: 8
Training loss: 2.867170536500397
Validation loss: 2.5021698385010422

Epoch: 6| Step: 9
Training loss: 2.4443187705399967
Validation loss: 2.503692495478333

Epoch: 6| Step: 10
Training loss: 3.037300913373403
Validation loss: 2.5056795977414454

Epoch: 6| Step: 11
Training loss: 2.9521918866199743
Validation loss: 2.507160372750118

Epoch: 6| Step: 12
Training loss: 3.039366248477273
Validation loss: 2.497635412221159

Epoch: 6| Step: 13
Training loss: 3.253909473944231
Validation loss: 2.5349620094518053

Epoch: 457| Step: 0
Training loss: 2.905892955218327
Validation loss: 2.5455156457330794

Epoch: 6| Step: 1
Training loss: 2.2999673384959607
Validation loss: 2.5637247483704675

Epoch: 6| Step: 2
Training loss: 2.8404374164548805
Validation loss: 2.5858255958267535

Epoch: 6| Step: 3
Training loss: 2.932493122739931
Validation loss: 2.6092403918242537

Epoch: 6| Step: 4
Training loss: 2.961399012206405
Validation loss: 2.613472870429398

Epoch: 6| Step: 5
Training loss: 3.1396511712663058
Validation loss: 2.6102612936581675

Epoch: 6| Step: 6
Training loss: 2.380763238932741
Validation loss: 2.600286041834651

Epoch: 6| Step: 7
Training loss: 2.939859781619439
Validation loss: 2.6106250920505687

Epoch: 6| Step: 8
Training loss: 2.9489539021187308
Validation loss: 2.5885188871596094

Epoch: 6| Step: 9
Training loss: 2.7618225164491874
Validation loss: 2.5636515707270138

Epoch: 6| Step: 10
Training loss: 3.0142294070719022
Validation loss: 2.5245574581029575

Epoch: 6| Step: 11
Training loss: 2.071374469670686
Validation loss: 2.5181760750023465

Epoch: 6| Step: 12
Training loss: 2.5541051731724402
Validation loss: 2.5284219812153865

Epoch: 6| Step: 13
Training loss: 3.2835685168106123
Validation loss: 2.5231037016268103

Epoch: 458| Step: 0
Training loss: 2.9279423513209224
Validation loss: 2.52862894609292

Epoch: 6| Step: 1
Training loss: 3.039131222612284
Validation loss: 2.5043132009039057

Epoch: 6| Step: 2
Training loss: 3.01796777672373
Validation loss: 2.4943636926337818

Epoch: 6| Step: 3
Training loss: 2.963894054913232
Validation loss: 2.5043764098989207

Epoch: 6| Step: 4
Training loss: 2.4677000106557387
Validation loss: 2.5091287908059194

Epoch: 6| Step: 5
Training loss: 2.6118607245404517
Validation loss: 2.521167013697623

Epoch: 6| Step: 6
Training loss: 2.638901548745646
Validation loss: 2.508246320559541

Epoch: 6| Step: 7
Training loss: 2.875353584107975
Validation loss: 2.5298477870888103

Epoch: 6| Step: 8
Training loss: 3.3048277480213395
Validation loss: 2.5315664810847354

Epoch: 6| Step: 9
Training loss: 2.1955535864896265
Validation loss: 2.544213770891536

Epoch: 6| Step: 10
Training loss: 2.774986844418246
Validation loss: 2.5833930681158512

Epoch: 6| Step: 11
Training loss: 2.9644406814907174
Validation loss: 2.567602393571091

Epoch: 6| Step: 12
Training loss: 2.4879539190606286
Validation loss: 2.5705727076053093

Epoch: 6| Step: 13
Training loss: 1.6476965228712275
Validation loss: 2.5727920957090538

Epoch: 459| Step: 0
Training loss: 2.3371387059677518
Validation loss: 2.5760225913615034

Epoch: 6| Step: 1
Training loss: 2.6775388416710646
Validation loss: 2.5726213525272317

Epoch: 6| Step: 2
Training loss: 2.619371647214826
Validation loss: 2.565516935129082

Epoch: 6| Step: 3
Training loss: 3.1755199817574784
Validation loss: 2.574432706243858

Epoch: 6| Step: 4
Training loss: 3.2414755901386707
Validation loss: 2.5892440652723026

Epoch: 6| Step: 5
Training loss: 3.152135300864488
Validation loss: 2.5582493198034983

Epoch: 6| Step: 6
Training loss: 2.433698183516129
Validation loss: 2.5539867128222222

Epoch: 6| Step: 7
Training loss: 2.559264489700306
Validation loss: 2.5486301373982765

Epoch: 6| Step: 8
Training loss: 3.12291739686258
Validation loss: 2.57870348434238

Epoch: 6| Step: 9
Training loss: 2.5217263292548187
Validation loss: 2.5485922915256993

Epoch: 6| Step: 10
Training loss: 2.4849764497742464
Validation loss: 2.5390407493801885

Epoch: 6| Step: 11
Training loss: 2.7234791807748437
Validation loss: 2.534412664245332

Epoch: 6| Step: 12
Training loss: 2.7495607545490865
Validation loss: 2.509616043167959

Epoch: 6| Step: 13
Training loss: 2.593960673037778
Validation loss: 2.5357601163858106

Epoch: 460| Step: 0
Training loss: 2.0729504171975326
Validation loss: 2.5281093401672123

Epoch: 6| Step: 1
Training loss: 2.476127899256038
Validation loss: 2.533019089382139

Epoch: 6| Step: 2
Training loss: 3.073422630596021
Validation loss: 2.5380656209010377

Epoch: 6| Step: 3
Training loss: 2.5151700384398716
Validation loss: 2.5501458269293407

Epoch: 6| Step: 4
Training loss: 3.039452535121553
Validation loss: 2.5473329650839522

Epoch: 6| Step: 5
Training loss: 2.563344304623913
Validation loss: 2.5531793504003453

Epoch: 6| Step: 6
Training loss: 2.5693641466761963
Validation loss: 2.546105633066326

Epoch: 6| Step: 7
Training loss: 2.703967453760735
Validation loss: 2.5557216249549675

Epoch: 6| Step: 8
Training loss: 2.287379665023739
Validation loss: 2.569625463948377

Epoch: 6| Step: 9
Training loss: 2.614816804672379
Validation loss: 2.5982903756893436

Epoch: 6| Step: 10
Training loss: 2.745848382919199
Validation loss: 2.6327235534040696

Epoch: 6| Step: 11
Training loss: 3.388611507702569
Validation loss: 2.6349428597188598

Epoch: 6| Step: 12
Training loss: 3.0370231787909
Validation loss: 2.5981009617788375

Epoch: 6| Step: 13
Training loss: 3.273400791299244
Validation loss: 2.589388295765429

Epoch: 461| Step: 0
Training loss: 1.6840314185593654
Validation loss: 2.562750638263964

Epoch: 6| Step: 1
Training loss: 2.9671670006018283
Validation loss: 2.5850643682404653

Epoch: 6| Step: 2
Training loss: 2.626754991511562
Validation loss: 2.5681254389185986

Epoch: 6| Step: 3
Training loss: 3.1461582310796503
Validation loss: 2.5813894377851994

Epoch: 6| Step: 4
Training loss: 2.693535348788075
Validation loss: 2.5774737905718967

Epoch: 6| Step: 5
Training loss: 3.069243344431397
Validation loss: 2.618454054556662

Epoch: 6| Step: 6
Training loss: 3.16006118763462
Validation loss: 2.612827284096859

Epoch: 6| Step: 7
Training loss: 2.377078301449219
Validation loss: 2.5426717086015977

Epoch: 6| Step: 8
Training loss: 2.3178858542590106
Validation loss: 2.5568573586288306

Epoch: 6| Step: 9
Training loss: 3.0708414257948795
Validation loss: 2.5340418679957692

Epoch: 6| Step: 10
Training loss: 2.616402306130855
Validation loss: 2.5070985336093923

Epoch: 6| Step: 11
Training loss: 3.03406134731606
Validation loss: 2.5080840992005577

Epoch: 6| Step: 12
Training loss: 2.949253188178485
Validation loss: 2.502277991504913

Epoch: 6| Step: 13
Training loss: 1.9277361064930167
Validation loss: 2.500468329175838

Epoch: 462| Step: 0
Training loss: 2.8355342693918386
Validation loss: 2.493260454584914

Epoch: 6| Step: 1
Training loss: 2.6243548735836852
Validation loss: 2.496508954190304

Epoch: 6| Step: 2
Training loss: 2.400300833603337
Validation loss: 2.502506439396407

Epoch: 6| Step: 3
Training loss: 2.6557781922435626
Validation loss: 2.5064325117201443

Epoch: 6| Step: 4
Training loss: 2.922285081777979
Validation loss: 2.5210197262528227

Epoch: 6| Step: 5
Training loss: 2.6032929035455057
Validation loss: 2.5397575483475636

Epoch: 6| Step: 6
Training loss: 2.7528458521954526
Validation loss: 2.5451388188650084

Epoch: 6| Step: 7
Training loss: 2.966805071941853
Validation loss: 2.5373014132216722

Epoch: 6| Step: 8
Training loss: 2.8806059541608553
Validation loss: 2.569142440065348

Epoch: 6| Step: 9
Training loss: 2.439657576875744
Validation loss: 2.575631159031106

Epoch: 6| Step: 10
Training loss: 2.774185122879924
Validation loss: 2.593839407372109

Epoch: 6| Step: 11
Training loss: 3.2916330907211795
Validation loss: 2.574026583715825

Epoch: 6| Step: 12
Training loss: 2.7920229290673793
Validation loss: 2.5585627497843038

Epoch: 6| Step: 13
Training loss: 2.5507862038440123
Validation loss: 2.5508265046005447

Epoch: 463| Step: 0
Training loss: 3.256930371335191
Validation loss: 2.548924828923634

Epoch: 6| Step: 1
Training loss: 2.972168089075589
Validation loss: 2.5506392437545498

Epoch: 6| Step: 2
Training loss: 2.7636737729123344
Validation loss: 2.5187280118420112

Epoch: 6| Step: 3
Training loss: 3.0243602990559606
Validation loss: 2.521276695018262

Epoch: 6| Step: 4
Training loss: 2.793537983540696
Validation loss: 2.5296833918276262

Epoch: 6| Step: 5
Training loss: 2.498369352688836
Validation loss: 2.544161630247725

Epoch: 6| Step: 6
Training loss: 2.8473628642590882
Validation loss: 2.552185507246946

Epoch: 6| Step: 7
Training loss: 2.8920100012852963
Validation loss: 2.603375674969531

Epoch: 6| Step: 8
Training loss: 2.315657547736161
Validation loss: 2.5902423845410962

Epoch: 6| Step: 9
Training loss: 2.609707108794983
Validation loss: 2.6093568644668017

Epoch: 6| Step: 10
Training loss: 2.3637501149048923
Validation loss: 2.678115014540683

Epoch: 6| Step: 11
Training loss: 2.4902496935803353
Validation loss: 2.6967204996840266

Epoch: 6| Step: 12
Training loss: 2.350479129889301
Validation loss: 2.6416324276961745

Epoch: 6| Step: 13
Training loss: 3.2408513636605325
Validation loss: 2.5919847200325754

Epoch: 464| Step: 0
Training loss: 3.069590864721588
Validation loss: 2.5448187514557348

Epoch: 6| Step: 1
Training loss: 2.5202769987061977
Validation loss: 2.5397418793257827

Epoch: 6| Step: 2
Training loss: 3.128004537086416
Validation loss: 2.5139326832323294

Epoch: 6| Step: 3
Training loss: 2.9710846404528537
Validation loss: 2.509898054592741

Epoch: 6| Step: 4
Training loss: 2.463564871960333
Validation loss: 2.5020058542534933

Epoch: 6| Step: 5
Training loss: 2.42845755598627
Validation loss: 2.49640316171804

Epoch: 6| Step: 6
Training loss: 2.6961933852659667
Validation loss: 2.516806250047078

Epoch: 6| Step: 7
Training loss: 2.5454899116635405
Validation loss: 2.5395509543768213

Epoch: 6| Step: 8
Training loss: 2.704163809266856
Validation loss: 2.5420032660277596

Epoch: 6| Step: 9
Training loss: 2.779259644592082
Validation loss: 2.574918042200876

Epoch: 6| Step: 10
Training loss: 2.6913428222977815
Validation loss: 2.6116095525855743

Epoch: 6| Step: 11
Training loss: 3.0386513870790224
Validation loss: 2.6852054000736034

Epoch: 6| Step: 12
Training loss: 2.4195249907844047
Validation loss: 2.6668103612618625

Epoch: 6| Step: 13
Training loss: 3.025724113115967
Validation loss: 2.670942688731523

Epoch: 465| Step: 0
Training loss: 2.271408591478186
Validation loss: 2.697005862477012

Epoch: 6| Step: 1
Training loss: 2.404724628441946
Validation loss: 2.6621326662823757

Epoch: 6| Step: 2
Training loss: 2.7046533574726603
Validation loss: 2.6988111723420323

Epoch: 6| Step: 3
Training loss: 3.561562665802263
Validation loss: 2.6951430828820997

Epoch: 6| Step: 4
Training loss: 2.4719653859353885
Validation loss: 2.6514139924304816

Epoch: 6| Step: 5
Training loss: 2.6919242460069777
Validation loss: 2.6432615708048495

Epoch: 6| Step: 6
Training loss: 2.61022624675815
Validation loss: 2.6109118917610807

Epoch: 6| Step: 7
Training loss: 2.418098212059486
Validation loss: 2.5951242405326886

Epoch: 6| Step: 8
Training loss: 2.4479509932904615
Validation loss: 2.582976212032865

Epoch: 6| Step: 9
Training loss: 2.077844930720728
Validation loss: 2.602202769063505

Epoch: 6| Step: 10
Training loss: 3.0494794620260763
Validation loss: 2.585225081163444

Epoch: 6| Step: 11
Training loss: 3.525080329574924
Validation loss: 2.593158814175442

Epoch: 6| Step: 12
Training loss: 2.6377587647981633
Validation loss: 2.55760116881296

Epoch: 6| Step: 13
Training loss: 3.0758088203417313
Validation loss: 2.5448365304247416

Epoch: 466| Step: 0
Training loss: 2.7949728864470442
Validation loss: 2.5118992503525335

Epoch: 6| Step: 1
Training loss: 2.7877884206682304
Validation loss: 2.515450434537737

Epoch: 6| Step: 2
Training loss: 2.928622853429057
Validation loss: 2.507191470688628

Epoch: 6| Step: 3
Training loss: 3.199732030138972
Validation loss: 2.490016713322488

Epoch: 6| Step: 4
Training loss: 2.850556663893455
Validation loss: 2.5031094983922504

Epoch: 6| Step: 5
Training loss: 2.2939830401790573
Validation loss: 2.5067178635184217

Epoch: 6| Step: 6
Training loss: 2.5700324465414117
Validation loss: 2.5254129276630017

Epoch: 6| Step: 7
Training loss: 1.9606322396667308
Validation loss: 2.522168501427199

Epoch: 6| Step: 8
Training loss: 2.8187904371926256
Validation loss: 2.5763382513430026

Epoch: 6| Step: 9
Training loss: 3.2805298514511656
Validation loss: 2.592598112865957

Epoch: 6| Step: 10
Training loss: 2.5408556431130447
Validation loss: 2.594044901488832

Epoch: 6| Step: 11
Training loss: 2.5155563819009226
Validation loss: 2.620995082318219

Epoch: 6| Step: 12
Training loss: 2.7337272530766246
Validation loss: 2.6184676459224825

Epoch: 6| Step: 13
Training loss: 3.424180181914043
Validation loss: 2.6262599599166516

Epoch: 467| Step: 0
Training loss: 2.6995347717159737
Validation loss: 2.60427964554049

Epoch: 6| Step: 1
Training loss: 2.8230758190452705
Validation loss: 2.642590236057778

Epoch: 6| Step: 2
Training loss: 2.1756361633908603
Validation loss: 2.635168181956986

Epoch: 6| Step: 3
Training loss: 2.9367629404845594
Validation loss: 2.6408368611997473

Epoch: 6| Step: 4
Training loss: 2.403311780955499
Validation loss: 2.6138684476509577

Epoch: 6| Step: 5
Training loss: 3.0366610965894023
Validation loss: 2.6280659429669293

Epoch: 6| Step: 6
Training loss: 3.195063275828485
Validation loss: 2.6250534794404476

Epoch: 6| Step: 7
Training loss: 3.090358840698314
Validation loss: 2.587290890854785

Epoch: 6| Step: 8
Training loss: 3.2379232652795187
Validation loss: 2.5503602255421347

Epoch: 6| Step: 9
Training loss: 2.3172340393537394
Validation loss: 2.504666887474263

Epoch: 6| Step: 10
Training loss: 2.1542674362647465
Validation loss: 2.4910800075352304

Epoch: 6| Step: 11
Training loss: 2.6764999426876113
Validation loss: 2.475336024424417

Epoch: 6| Step: 12
Training loss: 2.4488405364563746
Validation loss: 2.4916314959028716

Epoch: 6| Step: 13
Training loss: 3.149020536218272
Validation loss: 2.4997982989745258

Epoch: 468| Step: 0
Training loss: 2.3338961149630144
Validation loss: 2.4950973450552993

Epoch: 6| Step: 1
Training loss: 2.7934793499070176
Validation loss: 2.5094607161970135

Epoch: 6| Step: 2
Training loss: 2.846944837833703
Validation loss: 2.5061035405596206

Epoch: 6| Step: 3
Training loss: 3.2964643611361435
Validation loss: 2.517609201685596

Epoch: 6| Step: 4
Training loss: 2.6766079036426924
Validation loss: 2.532435016355309

Epoch: 6| Step: 5
Training loss: 2.2659945482557124
Validation loss: 2.547087260347927

Epoch: 6| Step: 6
Training loss: 2.6952320916164982
Validation loss: 2.5837442304168943

Epoch: 6| Step: 7
Training loss: 2.644955216517208
Validation loss: 2.5391946202588587

Epoch: 6| Step: 8
Training loss: 3.2533900846419694
Validation loss: 2.5675419422776184

Epoch: 6| Step: 9
Training loss: 2.8862816424182087
Validation loss: 2.5340727048401566

Epoch: 6| Step: 10
Training loss: 2.192825157212718
Validation loss: 2.533329529656867

Epoch: 6| Step: 11
Training loss: 3.00454590017929
Validation loss: 2.545523563701041

Epoch: 6| Step: 12
Training loss: 3.0167088907845057
Validation loss: 2.525893048015352

Epoch: 6| Step: 13
Training loss: 1.6219539703959327
Validation loss: 2.5102549617297

Epoch: 469| Step: 0
Training loss: 2.468054564826503
Validation loss: 2.501001766446039

Epoch: 6| Step: 1
Training loss: 2.7444978637575805
Validation loss: 2.5283244941083134

Epoch: 6| Step: 2
Training loss: 2.623511664482229
Validation loss: 2.5389295630602655

Epoch: 6| Step: 3
Training loss: 2.7596092530782856
Validation loss: 2.5568782668658168

Epoch: 6| Step: 4
Training loss: 2.882318221726884
Validation loss: 2.5768864465411983

Epoch: 6| Step: 5
Training loss: 2.3876707485316215
Validation loss: 2.5550330615328236

Epoch: 6| Step: 6
Training loss: 3.0848556746939404
Validation loss: 2.584953062975726

Epoch: 6| Step: 7
Training loss: 2.7922968556443823
Validation loss: 2.5783603594342366

Epoch: 6| Step: 8
Training loss: 2.4245708597110056
Validation loss: 2.600169912194403

Epoch: 6| Step: 9
Training loss: 3.3478851418157296
Validation loss: 2.64988757320852

Epoch: 6| Step: 10
Training loss: 2.7866035970215774
Validation loss: 2.6758672698161243

Epoch: 6| Step: 11
Training loss: 3.0075647029115946
Validation loss: 2.600873789035213

Epoch: 6| Step: 12
Training loss: 2.0118949738880034
Validation loss: 2.566863973353428

Epoch: 6| Step: 13
Training loss: 2.572680093079613
Validation loss: 2.5236935323261775

Epoch: 470| Step: 0
Training loss: 2.9444931873949436
Validation loss: 2.485873992356835

Epoch: 6| Step: 1
Training loss: 3.2463430224029013
Validation loss: 2.484265429840307

Epoch: 6| Step: 2
Training loss: 2.415758345897351
Validation loss: 2.4798741691342516

Epoch: 6| Step: 3
Training loss: 3.004665402843457
Validation loss: 2.4830584967847793

Epoch: 6| Step: 4
Training loss: 3.0643863707177212
Validation loss: 2.4840048526296887

Epoch: 6| Step: 5
Training loss: 3.119034834030944
Validation loss: 2.4826564374477944

Epoch: 6| Step: 6
Training loss: 2.635324247848144
Validation loss: 2.4789562303205845

Epoch: 6| Step: 7
Training loss: 2.6473224284244377
Validation loss: 2.4963336537671164

Epoch: 6| Step: 8
Training loss: 2.6142412141679836
Validation loss: 2.5109767620047565

Epoch: 6| Step: 9
Training loss: 2.481359415020079
Validation loss: 2.51613540072775

Epoch: 6| Step: 10
Training loss: 2.640288924099438
Validation loss: 2.570076895333887

Epoch: 6| Step: 11
Training loss: 2.5782946906454085
Validation loss: 2.580198237054657

Epoch: 6| Step: 12
Training loss: 2.654724041809088
Validation loss: 2.600041172373663

Epoch: 6| Step: 13
Training loss: 3.1726477672892788
Validation loss: 2.638276957804056

Epoch: 471| Step: 0
Training loss: 2.4217893523792204
Validation loss: 2.61685365627035

Epoch: 6| Step: 1
Training loss: 3.538240518333395
Validation loss: 2.589065524169602

Epoch: 6| Step: 2
Training loss: 3.3475474247553727
Validation loss: 2.551787991204772

Epoch: 6| Step: 3
Training loss: 2.2807699247035798
Validation loss: 2.52038505722415

Epoch: 6| Step: 4
Training loss: 3.0996487572324853
Validation loss: 2.5315396279802314

Epoch: 6| Step: 5
Training loss: 2.4797925613155147
Validation loss: 2.5123400071597164

Epoch: 6| Step: 6
Training loss: 2.2822165335947813
Validation loss: 2.5146725450923837

Epoch: 6| Step: 7
Training loss: 2.4758869778130617
Validation loss: 2.51226211121216

Epoch: 6| Step: 8
Training loss: 2.635510429151812
Validation loss: 2.514705387198976

Epoch: 6| Step: 9
Training loss: 2.855508493546091
Validation loss: 2.5080701662217644

Epoch: 6| Step: 10
Training loss: 3.0159201996362124
Validation loss: 2.5041567178170627

Epoch: 6| Step: 11
Training loss: 2.8502692647523316
Validation loss: 2.533270506620837

Epoch: 6| Step: 12
Training loss: 1.9987721250262578
Validation loss: 2.548856310699776

Epoch: 6| Step: 13
Training loss: 2.469217570004721
Validation loss: 2.5430708351296842

Epoch: 472| Step: 0
Training loss: 2.7949735688681185
Validation loss: 2.5610249653725523

Epoch: 6| Step: 1
Training loss: 2.355726338689235
Validation loss: 2.60923390028181

Epoch: 6| Step: 2
Training loss: 2.4181765958478
Validation loss: 2.627322728510319

Epoch: 6| Step: 3
Training loss: 2.898194500795438
Validation loss: 2.6281305973610403

Epoch: 6| Step: 4
Training loss: 2.491179067900569
Validation loss: 2.5858219216195835

Epoch: 6| Step: 5
Training loss: 3.1973291576041136
Validation loss: 2.562977582005101

Epoch: 6| Step: 6
Training loss: 3.1804940515278752
Validation loss: 2.5210929007453964

Epoch: 6| Step: 7
Training loss: 2.7703609111620247
Validation loss: 2.513184387879774

Epoch: 6| Step: 8
Training loss: 3.2081308837693983
Validation loss: 2.513575060121357

Epoch: 6| Step: 9
Training loss: 2.8537677755316038
Validation loss: 2.5067433175708107

Epoch: 6| Step: 10
Training loss: 2.73144583621956
Validation loss: 2.518314111272921

Epoch: 6| Step: 11
Training loss: 2.535073677211209
Validation loss: 2.4959872918262307

Epoch: 6| Step: 12
Training loss: 2.330397143592223
Validation loss: 2.5080929356802675

Epoch: 6| Step: 13
Training loss: 2.284324142370025
Validation loss: 2.4976028752970616

Epoch: 473| Step: 0
Training loss: 2.377839449006485
Validation loss: 2.5111508380717167

Epoch: 6| Step: 1
Training loss: 3.2985526060749653
Validation loss: 2.5235425837751104

Epoch: 6| Step: 2
Training loss: 2.3905846087465568
Validation loss: 2.537168999362504

Epoch: 6| Step: 3
Training loss: 2.6090915548827054
Validation loss: 2.560129272030804

Epoch: 6| Step: 4
Training loss: 2.362022077064798
Validation loss: 2.5675082093898487

Epoch: 6| Step: 5
Training loss: 2.7776757751386305
Validation loss: 2.606106056552077

Epoch: 6| Step: 6
Training loss: 3.1591110104107822
Validation loss: 2.6355863360340206

Epoch: 6| Step: 7
Training loss: 3.105645017599693
Validation loss: 2.631587706660841

Epoch: 6| Step: 8
Training loss: 2.800909957162987
Validation loss: 2.5918023468967992

Epoch: 6| Step: 9
Training loss: 2.4649185193505594
Validation loss: 2.589096690884468

Epoch: 6| Step: 10
Training loss: 3.0609340167257013
Validation loss: 2.611802423475275

Epoch: 6| Step: 11
Training loss: 2.369001945845842
Validation loss: 2.5833738947716403

Epoch: 6| Step: 12
Training loss: 2.6445903010797696
Validation loss: 2.6044707765928816

Epoch: 6| Step: 13
Training loss: 2.252512376859238
Validation loss: 2.5745334282592007

Epoch: 474| Step: 0
Training loss: 3.790639898989488
Validation loss: 2.540682812209697

Epoch: 6| Step: 1
Training loss: 2.550733580443257
Validation loss: 2.5346939224309324

Epoch: 6| Step: 2
Training loss: 2.2156349128103243
Validation loss: 2.496508125489757

Epoch: 6| Step: 3
Training loss: 2.5270684636227063
Validation loss: 2.4931427978286402

Epoch: 6| Step: 4
Training loss: 2.247306270884921
Validation loss: 2.4933012481756225

Epoch: 6| Step: 5
Training loss: 2.7946944447452116
Validation loss: 2.476470988016482

Epoch: 6| Step: 6
Training loss: 2.70093813951673
Validation loss: 2.473945185697082

Epoch: 6| Step: 7
Training loss: 2.7603328092301482
Validation loss: 2.514899935389055

Epoch: 6| Step: 8
Training loss: 2.713375523338385
Validation loss: 2.493445133976231

Epoch: 6| Step: 9
Training loss: 2.5164609669205418
Validation loss: 2.4821229100520608

Epoch: 6| Step: 10
Training loss: 2.750424092277031
Validation loss: 2.528941430656084

Epoch: 6| Step: 11
Training loss: 2.348601749079918
Validation loss: 2.527099908006548

Epoch: 6| Step: 12
Training loss: 3.3482270972597155
Validation loss: 2.5186892107896677

Epoch: 6| Step: 13
Training loss: 2.949004351168036
Validation loss: 2.564895528117687

Epoch: 475| Step: 0
Training loss: 2.34113033121229
Validation loss: 2.5254139651330183

Epoch: 6| Step: 1
Training loss: 2.6799816270454673
Validation loss: 2.535883210119499

Epoch: 6| Step: 2
Training loss: 3.2132800390907637
Validation loss: 2.5360452069975192

Epoch: 6| Step: 3
Training loss: 2.391238763347094
Validation loss: 2.5244954901409327

Epoch: 6| Step: 4
Training loss: 2.161752066512326
Validation loss: 2.5179222571366733

Epoch: 6| Step: 5
Training loss: 2.669653431834544
Validation loss: 2.50860523984599

Epoch: 6| Step: 6
Training loss: 2.8207369244627527
Validation loss: 2.5220259565084744

Epoch: 6| Step: 7
Training loss: 2.881678577911076
Validation loss: 2.5106831613686764

Epoch: 6| Step: 8
Training loss: 2.884185381408597
Validation loss: 2.531534658752491

Epoch: 6| Step: 9
Training loss: 2.2751185962659606
Validation loss: 2.5144896444840947

Epoch: 6| Step: 10
Training loss: 2.4343863921578355
Validation loss: 2.5348157430438283

Epoch: 6| Step: 11
Training loss: 2.6058197471362883
Validation loss: 2.5641363238288535

Epoch: 6| Step: 12
Training loss: 3.285887574430147
Validation loss: 2.581206680550518

Epoch: 6| Step: 13
Training loss: 3.300070998844132
Validation loss: 2.5889090531943633

Epoch: 476| Step: 0
Training loss: 2.2330110027898034
Validation loss: 2.615501661868831

Epoch: 6| Step: 1
Training loss: 3.144834212404645
Validation loss: 2.6034338456948705

Epoch: 6| Step: 2
Training loss: 2.4786869407708387
Validation loss: 2.5664844943971548

Epoch: 6| Step: 3
Training loss: 2.692643499915865
Validation loss: 2.5805753715433055

Epoch: 6| Step: 4
Training loss: 2.9238410088122118
Validation loss: 2.5439339239817294

Epoch: 6| Step: 5
Training loss: 3.0190054965049744
Validation loss: 2.5386945903773994

Epoch: 6| Step: 6
Training loss: 1.923569715156215
Validation loss: 2.514925276047976

Epoch: 6| Step: 7
Training loss: 2.7561868085126577
Validation loss: 2.5097960420347563

Epoch: 6| Step: 8
Training loss: 2.9565988927540165
Validation loss: 2.485219866348658

Epoch: 6| Step: 9
Training loss: 2.469928798035381
Validation loss: 2.5067897696041777

Epoch: 6| Step: 10
Training loss: 2.423158170341683
Validation loss: 2.503242509520261

Epoch: 6| Step: 11
Training loss: 2.7451201404622148
Validation loss: 2.5285472064702215

Epoch: 6| Step: 12
Training loss: 3.174607626631809
Validation loss: 2.524887341512453

Epoch: 6| Step: 13
Training loss: 3.015568707983348
Validation loss: 2.565474490842217

Epoch: 477| Step: 0
Training loss: 3.138034340392784
Validation loss: 2.579902654075124

Epoch: 6| Step: 1
Training loss: 2.692252016539823
Validation loss: 2.592689766953311

Epoch: 6| Step: 2
Training loss: 2.405973542420742
Validation loss: 2.619738770041032

Epoch: 6| Step: 3
Training loss: 3.0339063822737455
Validation loss: 2.604467740938806

Epoch: 6| Step: 4
Training loss: 2.056750520123033
Validation loss: 2.616566895473785

Epoch: 6| Step: 5
Training loss: 2.844766120884411
Validation loss: 2.5990966819894137

Epoch: 6| Step: 6
Training loss: 2.8581280099805793
Validation loss: 2.607194650417033

Epoch: 6| Step: 7
Training loss: 2.277511878375201
Validation loss: 2.555736866991861

Epoch: 6| Step: 8
Training loss: 2.987883258321256
Validation loss: 2.5713506819225964

Epoch: 6| Step: 9
Training loss: 1.832924826221496
Validation loss: 2.5513525118381577

Epoch: 6| Step: 10
Training loss: 2.661551447145902
Validation loss: 2.5740198808619965

Epoch: 6| Step: 11
Training loss: 2.7081467393028538
Validation loss: 2.5435762747839963

Epoch: 6| Step: 12
Training loss: 3.131275132738926
Validation loss: 2.581975594646897

Epoch: 6| Step: 13
Training loss: 2.740793596603832
Validation loss: 2.596610561433814

Epoch: 478| Step: 0
Training loss: 2.319317639730454
Validation loss: 2.5783992916007583

Epoch: 6| Step: 1
Training loss: 2.649293744244348
Validation loss: 2.563016104679076

Epoch: 6| Step: 2
Training loss: 2.613867267767409
Validation loss: 2.554676425299326

Epoch: 6| Step: 3
Training loss: 2.5489188576403277
Validation loss: 2.5427904137852124

Epoch: 6| Step: 4
Training loss: 2.6554163802780395
Validation loss: 2.5194330042242368

Epoch: 6| Step: 5
Training loss: 2.911043213723061
Validation loss: 2.5436991434727063

Epoch: 6| Step: 6
Training loss: 2.5711917011214886
Validation loss: 2.574821587687951

Epoch: 6| Step: 7
Training loss: 3.027025562915669
Validation loss: 2.559088311910426

Epoch: 6| Step: 8
Training loss: 2.834808377041718
Validation loss: 2.576229715618856

Epoch: 6| Step: 9
Training loss: 3.0622611439259444
Validation loss: 2.543470120770694

Epoch: 6| Step: 10
Training loss: 2.9069737999479774
Validation loss: 2.54875114707199

Epoch: 6| Step: 11
Training loss: 2.769611825564485
Validation loss: 2.543399359046656

Epoch: 6| Step: 12
Training loss: 2.2994857793751065
Validation loss: 2.564482257601535

Epoch: 6| Step: 13
Training loss: 2.561272210713228
Validation loss: 2.5651761049225597

Epoch: 479| Step: 0
Training loss: 2.890179409015362
Validation loss: 2.52863702541971

Epoch: 6| Step: 1
Training loss: 2.455859270151948
Validation loss: 2.5440497980875505

Epoch: 6| Step: 2
Training loss: 3.1095038152494334
Validation loss: 2.5482113581790284

Epoch: 6| Step: 3
Training loss: 2.8019593978379786
Validation loss: 2.5491192978379686

Epoch: 6| Step: 4
Training loss: 2.3375082699226515
Validation loss: 2.543303396576998

Epoch: 6| Step: 5
Training loss: 2.620214459763748
Validation loss: 2.5503988010845253

Epoch: 6| Step: 6
Training loss: 2.7279760855356474
Validation loss: 2.530904318133686

Epoch: 6| Step: 7
Training loss: 2.214595074292051
Validation loss: 2.520749844217961

Epoch: 6| Step: 8
Training loss: 2.579159430851644
Validation loss: 2.5091997087859457

Epoch: 6| Step: 9
Training loss: 3.292657694939594
Validation loss: 2.507981361722891

Epoch: 6| Step: 10
Training loss: 2.4276593443001375
Validation loss: 2.522126171301308

Epoch: 6| Step: 11
Training loss: 2.4876821326665666
Validation loss: 2.5503123742116345

Epoch: 6| Step: 12
Training loss: 2.977456586827158
Validation loss: 2.5790566410210425

Epoch: 6| Step: 13
Training loss: 2.5502973158797673
Validation loss: 2.5987251840193086

Epoch: 480| Step: 0
Training loss: 2.455435958191843
Validation loss: 2.619083667435661

Epoch: 6| Step: 1
Training loss: 2.584127386147857
Validation loss: 2.6540795914393005

Epoch: 6| Step: 2
Training loss: 2.802143611519595
Validation loss: 2.593317386444146

Epoch: 6| Step: 3
Training loss: 2.7541985106442777
Validation loss: 2.6092467094442715

Epoch: 6| Step: 4
Training loss: 2.714232363570925
Validation loss: 2.56886096069277

Epoch: 6| Step: 5
Training loss: 2.75687459498999
Validation loss: 2.549929920824439

Epoch: 6| Step: 6
Training loss: 3.0565708920260555
Validation loss: 2.5384926665629854

Epoch: 6| Step: 7
Training loss: 2.185058539193435
Validation loss: 2.5160242180597354

Epoch: 6| Step: 8
Training loss: 2.9102152363988423
Validation loss: 2.5251972870706467

Epoch: 6| Step: 9
Training loss: 2.236715837877132
Validation loss: 2.5284099316531954

Epoch: 6| Step: 10
Training loss: 3.2621479414481698
Validation loss: 2.563305749877461

Epoch: 6| Step: 11
Training loss: 2.52549333946182
Validation loss: 2.620069550492305

Epoch: 6| Step: 12
Training loss: 2.284170710956603
Validation loss: 2.59668171141588

Epoch: 6| Step: 13
Training loss: 3.8451241618771514
Validation loss: 2.5926835251725944

Epoch: 481| Step: 0
Training loss: 2.840246536675843
Validation loss: 2.5936816241466945

Epoch: 6| Step: 1
Training loss: 2.9513592966628184
Validation loss: 2.582446524340352

Epoch: 6| Step: 2
Training loss: 3.379640708878084
Validation loss: 2.5682007171225485

Epoch: 6| Step: 3
Training loss: 2.826970829103745
Validation loss: 2.528395597628502

Epoch: 6| Step: 4
Training loss: 2.6135394278180075
Validation loss: 2.516224598036023

Epoch: 6| Step: 5
Training loss: 2.5814009689259487
Validation loss: 2.5333651930738363

Epoch: 6| Step: 6
Training loss: 2.3844968752129643
Validation loss: 2.4956980885675626

Epoch: 6| Step: 7
Training loss: 2.553152480613705
Validation loss: 2.511176745385537

Epoch: 6| Step: 8
Training loss: 2.1437856910336937
Validation loss: 2.5269254189978017

Epoch: 6| Step: 9
Training loss: 2.6921177603200994
Validation loss: 2.5187773507392874

Epoch: 6| Step: 10
Training loss: 3.0534275119810608
Validation loss: 2.520703506550425

Epoch: 6| Step: 11
Training loss: 2.356377725149672
Validation loss: 2.548223132012839

Epoch: 6| Step: 12
Training loss: 2.8651972627219022
Validation loss: 2.5643852796043594

Epoch: 6| Step: 13
Training loss: 2.0084778392082945
Validation loss: 2.5482508324511226

Epoch: 482| Step: 0
Training loss: 2.961183562912255
Validation loss: 2.596545040237631

Epoch: 6| Step: 1
Training loss: 2.719086111054115
Validation loss: 2.5846530108530916

Epoch: 6| Step: 2
Training loss: 2.2504635439320357
Validation loss: 2.6366531005367664

Epoch: 6| Step: 3
Training loss: 3.1259526135934372
Validation loss: 2.6221606421442747

Epoch: 6| Step: 4
Training loss: 2.2666763497127076
Validation loss: 2.569690631985067

Epoch: 6| Step: 5
Training loss: 2.6390797986581047
Validation loss: 2.543675677835904

Epoch: 6| Step: 6
Training loss: 3.1249218740234133
Validation loss: 2.525643998865798

Epoch: 6| Step: 7
Training loss: 1.9861863047215884
Validation loss: 2.5266381629628096

Epoch: 6| Step: 8
Training loss: 2.1965224437613347
Validation loss: 2.5094312625552635

Epoch: 6| Step: 9
Training loss: 2.9718422295240736
Validation loss: 2.4871165794203365

Epoch: 6| Step: 10
Training loss: 2.935038407706433
Validation loss: 2.5179049097148094

Epoch: 6| Step: 11
Training loss: 2.876937710784827
Validation loss: 2.526113443694304

Epoch: 6| Step: 12
Training loss: 2.8580447578636097
Validation loss: 2.5165774647277073

Epoch: 6| Step: 13
Training loss: 3.0510047508360296
Validation loss: 2.5119805989014266

Epoch: 483| Step: 0
Training loss: 2.6902473069422013
Validation loss: 2.5447006985097294

Epoch: 6| Step: 1
Training loss: 2.4436085769825007
Validation loss: 2.5232597828715937

Epoch: 6| Step: 2
Training loss: 2.390347932205584
Validation loss: 2.5408162204310614

Epoch: 6| Step: 3
Training loss: 3.229024691178095
Validation loss: 2.5494428440979773

Epoch: 6| Step: 4
Training loss: 2.841198625549044
Validation loss: 2.536999554105163

Epoch: 6| Step: 5
Training loss: 2.704530736301785
Validation loss: 2.537894878883814

Epoch: 6| Step: 6
Training loss: 3.3401338507049383
Validation loss: 2.5584539680087883

Epoch: 6| Step: 7
Training loss: 2.8312997438890313
Validation loss: 2.539480638679211

Epoch: 6| Step: 8
Training loss: 3.1838735258584174
Validation loss: 2.5554596724081096

Epoch: 6| Step: 9
Training loss: 2.2924493204586525
Validation loss: 2.5393842282855092

Epoch: 6| Step: 10
Training loss: 2.2480786915374487
Validation loss: 2.5305704845216543

Epoch: 6| Step: 11
Training loss: 2.288883553759006
Validation loss: 2.542246567973933

Epoch: 6| Step: 12
Training loss: 2.734414934139195
Validation loss: 2.5569119795714905

Epoch: 6| Step: 13
Training loss: 2.2686810107290056
Validation loss: 2.5667227490289233

Epoch: 484| Step: 0
Training loss: 2.148040956834853
Validation loss: 2.568766060181573

Epoch: 6| Step: 1
Training loss: 2.954456816190643
Validation loss: 2.566824266969895

Epoch: 6| Step: 2
Training loss: 3.152092641214536
Validation loss: 2.5662313407225703

Epoch: 6| Step: 3
Training loss: 2.679905206939673
Validation loss: 2.5253170258297755

Epoch: 6| Step: 4
Training loss: 1.473133202175115
Validation loss: 2.5346554800804304

Epoch: 6| Step: 5
Training loss: 2.456096623026681
Validation loss: 2.5268432032250945

Epoch: 6| Step: 6
Training loss: 2.658436761436481
Validation loss: 2.5040798275870655

Epoch: 6| Step: 7
Training loss: 2.8753880777906122
Validation loss: 2.5127184828422657

Epoch: 6| Step: 8
Training loss: 3.15478783911287
Validation loss: 2.5163015043091095

Epoch: 6| Step: 9
Training loss: 2.643653712762496
Validation loss: 2.5091083822687743

Epoch: 6| Step: 10
Training loss: 2.6116786998219204
Validation loss: 2.5358419096119165

Epoch: 6| Step: 11
Training loss: 2.6160063398383544
Validation loss: 2.5350288806462733

Epoch: 6| Step: 12
Training loss: 3.1639041060373034
Validation loss: 2.5779376079015504

Epoch: 6| Step: 13
Training loss: 2.5277706770279003
Validation loss: 2.577402212799344

Epoch: 485| Step: 0
Training loss: 2.8601083284149493
Validation loss: 2.616576452158591

Epoch: 6| Step: 1
Training loss: 2.1054390814960935
Validation loss: 2.6445145867226363

Epoch: 6| Step: 2
Training loss: 3.3879328996573363
Validation loss: 2.586958185559164

Epoch: 6| Step: 3
Training loss: 2.3450865939811827
Validation loss: 2.5791766088086914

Epoch: 6| Step: 4
Training loss: 2.9065164423394965
Validation loss: 2.5509500069412305

Epoch: 6| Step: 5
Training loss: 2.728027562239901
Validation loss: 2.5482809933326314

Epoch: 6| Step: 6
Training loss: 2.425297441626261
Validation loss: 2.551463386890356

Epoch: 6| Step: 7
Training loss: 2.5257123489964264
Validation loss: 2.5310723346082957

Epoch: 6| Step: 8
Training loss: 2.5546523158832413
Validation loss: 2.546440286212229

Epoch: 6| Step: 9
Training loss: 2.677903006577026
Validation loss: 2.5420064640170974

Epoch: 6| Step: 10
Training loss: 2.7626070269397043
Validation loss: 2.531643629136633

Epoch: 6| Step: 11
Training loss: 2.528654109628309
Validation loss: 2.551170555220659

Epoch: 6| Step: 12
Training loss: 2.83026952208212
Validation loss: 2.5628203635217015

Epoch: 6| Step: 13
Training loss: 2.7078669415441947
Validation loss: 2.5634487745709724

Epoch: 486| Step: 0
Training loss: 3.0704382950732847
Validation loss: 2.5747041974808855

Epoch: 6| Step: 1
Training loss: 2.7805353167958895
Validation loss: 2.5954355890122667

Epoch: 6| Step: 2
Training loss: 2.9675856063565695
Validation loss: 2.6114764408171784

Epoch: 6| Step: 3
Training loss: 2.877571945815556
Validation loss: 2.6119032218468896

Epoch: 6| Step: 4
Training loss: 2.3869163319019977
Validation loss: 2.5719249056582343

Epoch: 6| Step: 5
Training loss: 2.685834501642803
Validation loss: 2.5726179454603004

Epoch: 6| Step: 6
Training loss: 3.1602597591013173
Validation loss: 2.543534869389869

Epoch: 6| Step: 7
Training loss: 2.64090686625502
Validation loss: 2.5563439968973554

Epoch: 6| Step: 8
Training loss: 2.3724480018504885
Validation loss: 2.5434136044822013

Epoch: 6| Step: 9
Training loss: 2.1911420747908945
Validation loss: 2.5253488219496396

Epoch: 6| Step: 10
Training loss: 2.5852807815913397
Validation loss: 2.525436549795419

Epoch: 6| Step: 11
Training loss: 2.4818670701817886
Validation loss: 2.5302913607179214

Epoch: 6| Step: 12
Training loss: 2.8556542708094215
Validation loss: 2.549205856675552

Epoch: 6| Step: 13
Training loss: 2.5968908573405556
Validation loss: 2.5884518379462382

Epoch: 487| Step: 0
Training loss: 2.329374451715248
Validation loss: 2.58807720927216

Epoch: 6| Step: 1
Training loss: 3.210429427517419
Validation loss: 2.5847161942045935

Epoch: 6| Step: 2
Training loss: 2.8707099087061807
Validation loss: 2.579695645838955

Epoch: 6| Step: 3
Training loss: 2.920761467398267
Validation loss: 2.561228724169266

Epoch: 6| Step: 4
Training loss: 3.208329601203102
Validation loss: 2.5333588572426917

Epoch: 6| Step: 5
Training loss: 2.925403117253672
Validation loss: 2.5035031498297378

Epoch: 6| Step: 6
Training loss: 2.542517087235698
Validation loss: 2.5121890172774224

Epoch: 6| Step: 7
Training loss: 2.4841671262900835
Validation loss: 2.4788415484854656

Epoch: 6| Step: 8
Training loss: 2.28812938849188
Validation loss: 2.493997989191214

Epoch: 6| Step: 9
Training loss: 2.1735271509412772
Validation loss: 2.518325003836066

Epoch: 6| Step: 10
Training loss: 2.567989795622947
Validation loss: 2.551795850529244

Epoch: 6| Step: 11
Training loss: 2.1159222753199876
Validation loss: 2.600646767146231

Epoch: 6| Step: 12
Training loss: 3.047742045352954
Validation loss: 2.6191642396599217

Epoch: 6| Step: 13
Training loss: 2.856836077705182
Validation loss: 2.657097465931165

Epoch: 488| Step: 0
Training loss: 2.0037418171601913
Validation loss: 2.7087439598868963

Epoch: 6| Step: 1
Training loss: 3.357513621764909
Validation loss: 2.738432619894297

Epoch: 6| Step: 2
Training loss: 2.6548228300647865
Validation loss: 2.7925814851689674

Epoch: 6| Step: 3
Training loss: 2.8156947323105754
Validation loss: 2.7792282222267404

Epoch: 6| Step: 4
Training loss: 2.759474472378481
Validation loss: 2.773865607827962

Epoch: 6| Step: 5
Training loss: 3.191148801245704
Validation loss: 2.7224428742351034

Epoch: 6| Step: 6
Training loss: 2.9944890585339743
Validation loss: 2.630323801802755

Epoch: 6| Step: 7
Training loss: 2.394644655214998
Validation loss: 2.5210273520210182

Epoch: 6| Step: 8
Training loss: 2.462025332329062
Validation loss: 2.499302657093462

Epoch: 6| Step: 9
Training loss: 2.7698853862200528
Validation loss: 2.4570690506678337

Epoch: 6| Step: 10
Training loss: 2.9339560375183424
Validation loss: 2.461582948337515

Epoch: 6| Step: 11
Training loss: 2.590968651520435
Validation loss: 2.459721144488115

Epoch: 6| Step: 12
Training loss: 2.5895662691306507
Validation loss: 2.4603399183716625

Epoch: 6| Step: 13
Training loss: 2.413287189509677
Validation loss: 2.4555357481261346

Epoch: 489| Step: 0
Training loss: 2.478544002096959
Validation loss: 2.4530649245099765

Epoch: 6| Step: 1
Training loss: 2.6886820300674033
Validation loss: 2.460791699891717

Epoch: 6| Step: 2
Training loss: 2.778026126779908
Validation loss: 2.4549388357322917

Epoch: 6| Step: 3
Training loss: 2.979186335856635
Validation loss: 2.448882585052104

Epoch: 6| Step: 4
Training loss: 2.838381552190514
Validation loss: 2.4692404324644546

Epoch: 6| Step: 5
Training loss: 2.3652831623013366
Validation loss: 2.476092756373626

Epoch: 6| Step: 6
Training loss: 2.467283175294203
Validation loss: 2.4881212909401498

Epoch: 6| Step: 7
Training loss: 2.6640644688752806
Validation loss: 2.495510518659048

Epoch: 6| Step: 8
Training loss: 2.5186025874540574
Validation loss: 2.5394643834367017

Epoch: 6| Step: 9
Training loss: 2.50325525066374
Validation loss: 2.558921942084823

Epoch: 6| Step: 10
Training loss: 2.309336379867788
Validation loss: 2.6125612014170283

Epoch: 6| Step: 11
Training loss: 3.2858447647250615
Validation loss: 2.704985302394686

Epoch: 6| Step: 12
Training loss: 3.308224203646391
Validation loss: 2.7297743535866603

Epoch: 6| Step: 13
Training loss: 3.6696260098523745
Validation loss: 2.763326919381772

Epoch: 490| Step: 0
Training loss: 2.757178387670625
Validation loss: 2.6701134708232943

Epoch: 6| Step: 1
Training loss: 2.658658181395361
Validation loss: 2.657225002449313

Epoch: 6| Step: 2
Training loss: 2.7625697442135806
Validation loss: 2.5491473998634318

Epoch: 6| Step: 3
Training loss: 2.459698949706499
Validation loss: 2.5051313672460767

Epoch: 6| Step: 4
Training loss: 2.244805060846031
Validation loss: 2.4785919367766116

Epoch: 6| Step: 5
Training loss: 2.3759514759901488
Validation loss: 2.466747862543188

Epoch: 6| Step: 6
Training loss: 2.7025399870477025
Validation loss: 2.4552843058511016

Epoch: 6| Step: 7
Training loss: 2.9002262158789414
Validation loss: 2.4570987125528725

Epoch: 6| Step: 8
Training loss: 2.867258013863839
Validation loss: 2.4547042826367083

Epoch: 6| Step: 9
Training loss: 2.95747402408701
Validation loss: 2.462938581210585

Epoch: 6| Step: 10
Training loss: 2.832758190646495
Validation loss: 2.4605818056985433

Epoch: 6| Step: 11
Training loss: 2.8233973995837998
Validation loss: 2.4709874008523562

Epoch: 6| Step: 12
Training loss: 2.322071782805595
Validation loss: 2.4647414266484797

Epoch: 6| Step: 13
Training loss: 3.558018994945923
Validation loss: 2.476887674444995

Epoch: 491| Step: 0
Training loss: 2.477298278295037
Validation loss: 2.4674441164040326

Epoch: 6| Step: 1
Training loss: 2.6977076406524882
Validation loss: 2.4765246252438327

Epoch: 6| Step: 2
Training loss: 2.6907612729536865
Validation loss: 2.5198702951091794

Epoch: 6| Step: 3
Training loss: 3.498378377996692
Validation loss: 2.5438350439840494

Epoch: 6| Step: 4
Training loss: 2.680357201528036
Validation loss: 2.5435108226869363

Epoch: 6| Step: 5
Training loss: 2.676343783535377
Validation loss: 2.563899238707241

Epoch: 6| Step: 6
Training loss: 2.5004024181734463
Validation loss: 2.5353781286728

Epoch: 6| Step: 7
Training loss: 2.5123892878342455
Validation loss: 2.5264730362781633

Epoch: 6| Step: 8
Training loss: 2.820820347931207
Validation loss: 2.525326140061318

Epoch: 6| Step: 9
Training loss: 3.129710195366725
Validation loss: 2.5304265720571806

Epoch: 6| Step: 10
Training loss: 2.5947023964166793
Validation loss: 2.554159783714718

Epoch: 6| Step: 11
Training loss: 2.665080125044366
Validation loss: 2.5124178966106063

Epoch: 6| Step: 12
Training loss: 2.5957257203093866
Validation loss: 2.5316198563159085

Epoch: 6| Step: 13
Training loss: 1.5811473496481718
Validation loss: 2.5545795025601428

Epoch: 492| Step: 0
Training loss: 2.8754005153150617
Validation loss: 2.566207195009483

Epoch: 6| Step: 1
Training loss: 3.0890806777411544
Validation loss: 2.5316982269955455

Epoch: 6| Step: 2
Training loss: 2.4389606892012914
Validation loss: 2.5375857144099054

Epoch: 6| Step: 3
Training loss: 1.9866838614895248
Validation loss: 2.546693216733188

Epoch: 6| Step: 4
Training loss: 2.7344230429652194
Validation loss: 2.5295741839657606

Epoch: 6| Step: 5
Training loss: 2.80247780293395
Validation loss: 2.514026436353029

Epoch: 6| Step: 6
Training loss: 2.7111962274659653
Validation loss: 2.53843052523605

Epoch: 6| Step: 7
Training loss: 2.781034825605913
Validation loss: 2.521983480661064

Epoch: 6| Step: 8
Training loss: 2.8296678244350635
Validation loss: 2.535734899013743

Epoch: 6| Step: 9
Training loss: 2.817613911530368
Validation loss: 2.519723660345689

Epoch: 6| Step: 10
Training loss: 2.5121650358643706
Validation loss: 2.543498255981845

Epoch: 6| Step: 11
Training loss: 2.731174623335285
Validation loss: 2.542150548878201

Epoch: 6| Step: 12
Training loss: 2.717189033775489
Validation loss: 2.579616749718384

Epoch: 6| Step: 13
Training loss: 2.146950279815022
Validation loss: 2.554967090181302

Epoch: 493| Step: 0
Training loss: 2.5039676652776697
Validation loss: 2.5831829097378205

Epoch: 6| Step: 1
Training loss: 2.7213703550499115
Validation loss: 2.612489634098465

Epoch: 6| Step: 2
Training loss: 2.3716101296236687
Validation loss: 2.6235496530199325

Epoch: 6| Step: 3
Training loss: 2.8844770055982756
Validation loss: 2.6288571368605047

Epoch: 6| Step: 4
Training loss: 3.1168318237227055
Validation loss: 2.5741026803001765

Epoch: 6| Step: 5
Training loss: 2.666039949522732
Validation loss: 2.5513449797239236

Epoch: 6| Step: 6
Training loss: 2.4620933119431294
Validation loss: 2.5180938331759184

Epoch: 6| Step: 7
Training loss: 2.8173715574677702
Validation loss: 2.5119736416970513

Epoch: 6| Step: 8
Training loss: 2.588934415090434
Validation loss: 2.4829339044852308

Epoch: 6| Step: 9
Training loss: 2.8447434922148997
Validation loss: 2.4930116263745363

Epoch: 6| Step: 10
Training loss: 2.594471842502926
Validation loss: 2.5102022729892757

Epoch: 6| Step: 11
Training loss: 2.9113267426389613
Validation loss: 2.5084238545083193

Epoch: 6| Step: 12
Training loss: 2.7344578321717257
Validation loss: 2.518695098010704

Epoch: 6| Step: 13
Training loss: 2.20879138538597
Validation loss: 2.524097009630575

Epoch: 494| Step: 0
Training loss: 2.772674799534888
Validation loss: 2.5736162651822694

Epoch: 6| Step: 1
Training loss: 2.6261736652913448
Validation loss: 2.588546675345053

Epoch: 6| Step: 2
Training loss: 2.875865640104148
Validation loss: 2.580060179996537

Epoch: 6| Step: 3
Training loss: 2.912117562132187
Validation loss: 2.586917260466

Epoch: 6| Step: 4
Training loss: 2.7156131230523686
Validation loss: 2.561561334517373

Epoch: 6| Step: 5
Training loss: 1.7827894017079766
Validation loss: 2.5973388122632115

Epoch: 6| Step: 6
Training loss: 2.361823422064859
Validation loss: 2.6125075800831308

Epoch: 6| Step: 7
Training loss: 2.3313579258213
Validation loss: 2.577213378503842

Epoch: 6| Step: 8
Training loss: 2.842524505482762
Validation loss: 2.5504249701204684

Epoch: 6| Step: 9
Training loss: 2.3365891992386114
Validation loss: 2.558262418316103

Epoch: 6| Step: 10
Training loss: 3.2835142043846113
Validation loss: 2.569338237389607

Epoch: 6| Step: 11
Training loss: 2.478725126894813
Validation loss: 2.5404610577713926

Epoch: 6| Step: 12
Training loss: 2.6141487358174698
Validation loss: 2.521098366451747

Epoch: 6| Step: 13
Training loss: 3.3176849380378926
Validation loss: 2.53283115166097

Epoch: 495| Step: 0
Training loss: 2.755338169396703
Validation loss: 2.534399943181395

Epoch: 6| Step: 1
Training loss: 2.6936851121915826
Validation loss: 2.5240951865086485

Epoch: 6| Step: 2
Training loss: 2.553629711602583
Validation loss: 2.5242769752462

Epoch: 6| Step: 3
Training loss: 2.837547496784642
Validation loss: 2.5494954157076872

Epoch: 6| Step: 4
Training loss: 2.525574337442427
Validation loss: 2.550343348056255

Epoch: 6| Step: 5
Training loss: 3.138810122091482
Validation loss: 2.5630793913152363

Epoch: 6| Step: 6
Training loss: 2.437451484392978
Validation loss: 2.5692942108589922

Epoch: 6| Step: 7
Training loss: 2.3999924977503184
Validation loss: 2.567329516742472

Epoch: 6| Step: 8
Training loss: 2.670143860502428
Validation loss: 2.582099229439222

Epoch: 6| Step: 9
Training loss: 2.9224139853710134
Validation loss: 2.53505477450639

Epoch: 6| Step: 10
Training loss: 2.228987166643743
Validation loss: 2.5261263566852685

Epoch: 6| Step: 11
Training loss: 2.4391185570774816
Validation loss: 2.513210485384515

Epoch: 6| Step: 12
Training loss: 3.0229499680104266
Validation loss: 2.5091984214479877

Epoch: 6| Step: 13
Training loss: 2.7613901592997396
Validation loss: 2.5514294735783993

Epoch: 496| Step: 0
Training loss: 2.1621119112380676
Validation loss: 2.5332845696800774

Epoch: 6| Step: 1
Training loss: 2.5849712675700283
Validation loss: 2.5486337897809195

Epoch: 6| Step: 2
Training loss: 2.8370463407736692
Validation loss: 2.5642189245270375

Epoch: 6| Step: 3
Training loss: 2.3557693517376497
Validation loss: 2.5468154559034493

Epoch: 6| Step: 4
Training loss: 2.623395702035903
Validation loss: 2.545129099703311

Epoch: 6| Step: 5
Training loss: 2.400623629926406
Validation loss: 2.5870323162330853

Epoch: 6| Step: 6
Training loss: 3.203130359179968
Validation loss: 2.582723389413613

Epoch: 6| Step: 7
Training loss: 2.5180318939879665
Validation loss: 2.6027469665171843

Epoch: 6| Step: 8
Training loss: 3.0634977311390075
Validation loss: 2.5958365271189874

Epoch: 6| Step: 9
Training loss: 2.672585733035939
Validation loss: 2.5683885750868565

Epoch: 6| Step: 10
Training loss: 2.654265436543488
Validation loss: 2.563113659588374

Epoch: 6| Step: 11
Training loss: 2.761299155381882
Validation loss: 2.555272747086539

Epoch: 6| Step: 12
Training loss: 2.595832815726419
Validation loss: 2.5343394413885756

Epoch: 6| Step: 13
Training loss: 2.4794124727179594
Validation loss: 2.498582537595143

Epoch: 497| Step: 0
Training loss: 2.9690509844340744
Validation loss: 2.49821264044463

Epoch: 6| Step: 1
Training loss: 2.748893254993699
Validation loss: 2.50529315763864

Epoch: 6| Step: 2
Training loss: 2.152773500937312
Validation loss: 2.5059864959969045

Epoch: 6| Step: 3
Training loss: 3.033036325047898
Validation loss: 2.5159909906875373

Epoch: 6| Step: 4
Training loss: 2.9041374486021723
Validation loss: 2.5167540957248247

Epoch: 6| Step: 5
Training loss: 2.475618681982656
Validation loss: 2.5267465348650697

Epoch: 6| Step: 6
Training loss: 2.521019500499632
Validation loss: 2.5593001553336063

Epoch: 6| Step: 7
Training loss: 2.4785839218697974
Validation loss: 2.553113956718476

Epoch: 6| Step: 8
Training loss: 3.004305293411525
Validation loss: 2.566266910530488

Epoch: 6| Step: 9
Training loss: 1.805749819974588
Validation loss: 2.525261759056544

Epoch: 6| Step: 10
Training loss: 3.2419662951647683
Validation loss: 2.5302900243331305

Epoch: 6| Step: 11
Training loss: 2.9134507751653405
Validation loss: 2.527591033192325

Epoch: 6| Step: 12
Training loss: 2.149758338653863
Validation loss: 2.5457846092009886

Epoch: 6| Step: 13
Training loss: 2.707576988442978
Validation loss: 2.508623866652489

Epoch: 498| Step: 0
Training loss: 1.9665679949991757
Validation loss: 2.5321499607004005

Epoch: 6| Step: 1
Training loss: 3.0805354096381006
Validation loss: 2.5848901422849506

Epoch: 6| Step: 2
Training loss: 2.892049572426122
Validation loss: 2.633200189101743

Epoch: 6| Step: 3
Training loss: 2.365667780661924
Validation loss: 2.6642140654604693

Epoch: 6| Step: 4
Training loss: 2.825878536710653
Validation loss: 2.6796124013480607

Epoch: 6| Step: 5
Training loss: 2.8039329597686886
Validation loss: 2.668519432661415

Epoch: 6| Step: 6
Training loss: 2.9253519351869697
Validation loss: 2.618087194180547

Epoch: 6| Step: 7
Training loss: 2.67376178355427
Validation loss: 2.5619921727561197

Epoch: 6| Step: 8
Training loss: 2.5972661464011924
Validation loss: 2.5205217713167443

Epoch: 6| Step: 9
Training loss: 2.6763851180481972
Validation loss: 2.4916019940671297

Epoch: 6| Step: 10
Training loss: 2.5931379216502703
Validation loss: 2.474403996289468

Epoch: 6| Step: 11
Training loss: 2.928664209311699
Validation loss: 2.477932082201643

Epoch: 6| Step: 12
Training loss: 2.9980950665406088
Validation loss: 2.4678951718592725

Epoch: 6| Step: 13
Training loss: 1.8844369552321534
Validation loss: 2.4753992628937596

Epoch: 499| Step: 0
Training loss: 2.5921362947139825
Validation loss: 2.4802572258200577

Epoch: 6| Step: 1
Training loss: 2.8709675248613653
Validation loss: 2.4847879229804626

Epoch: 6| Step: 2
Training loss: 2.9807068016008174
Validation loss: 2.475565772813731

Epoch: 6| Step: 3
Training loss: 2.7997415866134405
Validation loss: 2.5104186042250887

Epoch: 6| Step: 4
Training loss: 2.855105688807806
Validation loss: 2.4797723998214867

Epoch: 6| Step: 5
Training loss: 2.7863955101465483
Validation loss: 2.5106279456759664

Epoch: 6| Step: 6
Training loss: 2.5508986441688086
Validation loss: 2.5404220094118535

Epoch: 6| Step: 7
Training loss: 2.6761415559195174
Validation loss: 2.5275375972253635

Epoch: 6| Step: 8
Training loss: 2.1528444901934507
Validation loss: 2.5811899779422456

Epoch: 6| Step: 9
Training loss: 2.9314696727825527
Validation loss: 2.600582704095408

Epoch: 6| Step: 10
Training loss: 2.3025863121000287
Validation loss: 2.6069300461568017

Epoch: 6| Step: 11
Training loss: 2.9445811205957706
Validation loss: 2.6137864518326075

Epoch: 6| Step: 12
Training loss: 1.9653530787886941
Validation loss: 2.6056410332540274

Epoch: 6| Step: 13
Training loss: 2.6996562067782155
Validation loss: 2.5877682863071203

Epoch: 500| Step: 0
Training loss: 3.1169695096768866
Validation loss: 2.5350817895956563

Epoch: 6| Step: 1
Training loss: 2.47724563370652
Validation loss: 2.525984091948859

Epoch: 6| Step: 2
Training loss: 2.7045826592447226
Validation loss: 2.518669884851682

Epoch: 6| Step: 3
Training loss: 2.7721977794268713
Validation loss: 2.508245640873005

Epoch: 6| Step: 4
Training loss: 2.4983516981363065
Validation loss: 2.517070529466947

Epoch: 6| Step: 5
Training loss: 2.805667886489084
Validation loss: 2.517399416811124

Epoch: 6| Step: 6
Training loss: 2.4026994147289966
Validation loss: 2.522279622631828

Epoch: 6| Step: 7
Training loss: 2.02881640858528
Validation loss: 2.544986379174243

Epoch: 6| Step: 8
Training loss: 2.579645714054603
Validation loss: 2.5304211579067113

Epoch: 6| Step: 9
Training loss: 3.009238799153299
Validation loss: 2.5263989247396563

Epoch: 6| Step: 10
Training loss: 2.8146913256893966
Validation loss: 2.5479152278144643

Epoch: 6| Step: 11
Training loss: 2.3428479302454464
Validation loss: 2.527394201817342

Epoch: 6| Step: 12
Training loss: 3.0602296471284736
Validation loss: 2.5164203755810965

Epoch: 6| Step: 13
Training loss: 2.169294841827364
Validation loss: 2.5336520425895457

Testing loss: 2.7114708904923766
