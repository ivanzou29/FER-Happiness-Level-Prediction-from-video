Epoch: 1| Step: 0
Training loss: 5.525577068328857
Validation loss: 5.143413066864014

Epoch: 6| Step: 1
Training loss: 4.216721534729004
Validation loss: 5.135180493836762

Epoch: 6| Step: 2
Training loss: 5.244653701782227
Validation loss: 5.128034842911587

Epoch: 6| Step: 3
Training loss: 3.643117904663086
Validation loss: 5.120629197807722

Epoch: 6| Step: 4
Training loss: 5.005298614501953
Validation loss: 5.114088668618151

Epoch: 6| Step: 5
Training loss: 4.659567832946777
Validation loss: 5.106399305405155

Epoch: 6| Step: 6
Training loss: 4.652211666107178
Validation loss: 5.099553687598116

Epoch: 6| Step: 7
Training loss: 5.024340629577637
Validation loss: 5.0925889425380255

Epoch: 6| Step: 8
Training loss: 5.24564266204834
Validation loss: 5.085686868236911

Epoch: 6| Step: 9
Training loss: 4.982681751251221
Validation loss: 5.078170555894093

Epoch: 6| Step: 10
Training loss: 6.227976322174072
Validation loss: 5.070857494108139

Epoch: 6| Step: 11
Training loss: 4.524409770965576
Validation loss: 5.063439394838067

Epoch: 6| Step: 12
Training loss: 4.822154521942139
Validation loss: 5.055936272426318

Epoch: 6| Step: 13
Training loss: 4.5695343017578125
Validation loss: 5.047489207278016

Epoch: 2| Step: 0
Training loss: 3.732994556427002
Validation loss: 5.038286373179446

Epoch: 6| Step: 1
Training loss: 5.089820861816406
Validation loss: 5.02998879648024

Epoch: 6| Step: 2
Training loss: 4.1195783615112305
Validation loss: 5.020841213964647

Epoch: 6| Step: 3
Training loss: 5.131384372711182
Validation loss: 5.010009345187936

Epoch: 6| Step: 4
Training loss: 3.390331745147705
Validation loss: 5.000216771197575

Epoch: 6| Step: 5
Training loss: 4.106438159942627
Validation loss: 4.990113381416567

Epoch: 6| Step: 6
Training loss: 4.950037956237793
Validation loss: 4.977881185470089

Epoch: 6| Step: 7
Training loss: 5.322605609893799
Validation loss: 4.965657193173644

Epoch: 6| Step: 8
Training loss: 5.472754955291748
Validation loss: 4.954752865658011

Epoch: 6| Step: 9
Training loss: 5.900241374969482
Validation loss: 4.941078785927065

Epoch: 6| Step: 10
Training loss: 5.140090465545654
Validation loss: 4.927220988017257

Epoch: 6| Step: 11
Training loss: 5.186871528625488
Validation loss: 4.912558619694043

Epoch: 6| Step: 12
Training loss: 3.5203187465667725
Validation loss: 4.897881964201568

Epoch: 6| Step: 13
Training loss: 6.257285118103027
Validation loss: 4.882583031090357

Epoch: 3| Step: 0
Training loss: 5.296199798583984
Validation loss: 4.865959080316687

Epoch: 6| Step: 1
Training loss: 4.79421854019165
Validation loss: 4.847866119876985

Epoch: 6| Step: 2
Training loss: 5.3851704597473145
Validation loss: 4.829508899360575

Epoch: 6| Step: 3
Training loss: 4.599380016326904
Validation loss: 4.809215386708577

Epoch: 6| Step: 4
Training loss: 4.81141471862793
Validation loss: 4.78972101724276

Epoch: 6| Step: 5
Training loss: 4.070478916168213
Validation loss: 4.768027926004061

Epoch: 6| Step: 6
Training loss: 5.260706424713135
Validation loss: 4.746749062691966

Epoch: 6| Step: 7
Training loss: 4.529877185821533
Validation loss: 4.724295775095622

Epoch: 6| Step: 8
Training loss: 3.2768478393554688
Validation loss: 4.69980590574203

Epoch: 6| Step: 9
Training loss: 5.260466575622559
Validation loss: 4.67464151177355

Epoch: 6| Step: 10
Training loss: 3.4312992095947266
Validation loss: 4.647995436063376

Epoch: 6| Step: 11
Training loss: 5.60420036315918
Validation loss: 4.623393099795106

Epoch: 6| Step: 12
Training loss: 3.500200033187866
Validation loss: 4.594974753677204

Epoch: 6| Step: 13
Training loss: 2.680081367492676
Validation loss: 4.569762199155746

Epoch: 4| Step: 0
Training loss: 3.5686264038085938
Validation loss: 4.540034976056827

Epoch: 6| Step: 1
Training loss: 3.782186508178711
Validation loss: 4.509613970274566

Epoch: 6| Step: 2
Training loss: 4.299386024475098
Validation loss: 4.477971041074363

Epoch: 6| Step: 3
Training loss: 4.788839340209961
Validation loss: 4.445954897070444

Epoch: 6| Step: 4
Training loss: 3.854987382888794
Validation loss: 4.413948520537345

Epoch: 6| Step: 5
Training loss: 4.488426685333252
Validation loss: 4.383225497379098

Epoch: 6| Step: 6
Training loss: 4.550073623657227
Validation loss: 4.35156903728362

Epoch: 6| Step: 7
Training loss: 4.321566581726074
Validation loss: 4.32054078707131

Epoch: 6| Step: 8
Training loss: 4.501101493835449
Validation loss: 4.288884906358616

Epoch: 6| Step: 9
Training loss: 5.051048755645752
Validation loss: 4.255282432802262

Epoch: 6| Step: 10
Training loss: 3.9826819896698
Validation loss: 4.226061426183229

Epoch: 6| Step: 11
Training loss: 3.6685733795166016
Validation loss: 4.194695857263381

Epoch: 6| Step: 12
Training loss: 3.139080762863159
Validation loss: 4.167083530015843

Epoch: 6| Step: 13
Training loss: 4.017764568328857
Validation loss: 4.138921809452836

Epoch: 5| Step: 0
Training loss: 4.360978126525879
Validation loss: 4.114078521728516

Epoch: 6| Step: 1
Training loss: 2.4367058277130127
Validation loss: 4.088779552008516

Epoch: 6| Step: 2
Training loss: 4.611309051513672
Validation loss: 4.061557795411797

Epoch: 6| Step: 3
Training loss: 3.6652255058288574
Validation loss: 4.037921977299516

Epoch: 6| Step: 4
Training loss: 3.485546827316284
Validation loss: 4.0112195425136115

Epoch: 6| Step: 5
Training loss: 6.033984661102295
Validation loss: 3.989013974384595

Epoch: 6| Step: 6
Training loss: 3.793461799621582
Validation loss: 3.9643576811718684

Epoch: 6| Step: 7
Training loss: 3.3427906036376953
Validation loss: 3.943236299740371

Epoch: 6| Step: 8
Training loss: 3.7856991291046143
Validation loss: 3.9241747240866385

Epoch: 6| Step: 9
Training loss: 3.2345643043518066
Validation loss: 3.901855925078033

Epoch: 6| Step: 10
Training loss: 3.7443981170654297
Validation loss: 3.880950548315561

Epoch: 6| Step: 11
Training loss: 4.254042148590088
Validation loss: 3.863088351424022

Epoch: 6| Step: 12
Training loss: 2.8472518920898438
Validation loss: 3.8414875717573267

Epoch: 6| Step: 13
Training loss: 3.779170036315918
Validation loss: 3.8224397782356507

Epoch: 6| Step: 0
Training loss: 3.6898274421691895
Validation loss: 3.8051058938426356

Epoch: 6| Step: 1
Training loss: 4.697031021118164
Validation loss: 3.7847599393577984

Epoch: 6| Step: 2
Training loss: 4.777505874633789
Validation loss: 3.7663087742303007

Epoch: 6| Step: 3
Training loss: 3.3235883712768555
Validation loss: 3.750058199769707

Epoch: 6| Step: 4
Training loss: 3.1015102863311768
Validation loss: 3.7304906281091834

Epoch: 6| Step: 5
Training loss: 2.843179941177368
Validation loss: 3.7134614811148694

Epoch: 6| Step: 6
Training loss: 3.6947109699249268
Validation loss: 3.700663205116026

Epoch: 6| Step: 7
Training loss: 3.9427270889282227
Validation loss: 3.685546867309078

Epoch: 6| Step: 8
Training loss: 2.1717898845672607
Validation loss: 3.6670487824306695

Epoch: 6| Step: 9
Training loss: 2.5545425415039062
Validation loss: 3.651570189383722

Epoch: 6| Step: 10
Training loss: 3.0910696983337402
Validation loss: 3.6314381553280737

Epoch: 6| Step: 11
Training loss: 3.733523368835449
Validation loss: 3.6152995991450485

Epoch: 6| Step: 12
Training loss: 3.7887399196624756
Validation loss: 3.5947289723221973

Epoch: 6| Step: 13
Training loss: 5.963755130767822
Validation loss: 3.5797990752804663

Epoch: 7| Step: 0
Training loss: 4.85865592956543
Validation loss: 3.566297951564994

Epoch: 6| Step: 1
Training loss: 2.542548179626465
Validation loss: 3.5533642461222987

Epoch: 6| Step: 2
Training loss: 4.284414291381836
Validation loss: 3.541885922032018

Epoch: 6| Step: 3
Training loss: 3.6396634578704834
Validation loss: 3.5287478457215014

Epoch: 6| Step: 4
Training loss: 3.8143744468688965
Validation loss: 3.518528525547315

Epoch: 6| Step: 5
Training loss: 2.6243810653686523
Validation loss: 3.508571614501297

Epoch: 6| Step: 6
Training loss: 3.5798110961914062
Validation loss: 3.4980657587769213

Epoch: 6| Step: 7
Training loss: 4.466056823730469
Validation loss: 3.489851669598651

Epoch: 6| Step: 8
Training loss: 2.8790340423583984
Validation loss: 3.476494791687176

Epoch: 6| Step: 9
Training loss: 4.054134368896484
Validation loss: 3.468642670621154

Epoch: 6| Step: 10
Training loss: 2.6275272369384766
Validation loss: 3.4570274788846254

Epoch: 6| Step: 11
Training loss: 3.5511248111724854
Validation loss: 3.4465485413869223

Epoch: 6| Step: 12
Training loss: 2.2102293968200684
Validation loss: 3.4359403066737677

Epoch: 6| Step: 13
Training loss: 2.6101956367492676
Validation loss: 3.4289862391769246

Epoch: 8| Step: 0
Training loss: 3.2545504570007324
Validation loss: 3.4204032677476124

Epoch: 6| Step: 1
Training loss: 4.300591468811035
Validation loss: 3.4142365788900726

Epoch: 6| Step: 2
Training loss: 2.4071526527404785
Validation loss: 3.404201343495359

Epoch: 6| Step: 3
Training loss: 3.098686695098877
Validation loss: 3.396588146045644

Epoch: 6| Step: 4
Training loss: 3.0617971420288086
Validation loss: 3.387108820740895

Epoch: 6| Step: 5
Training loss: 3.525240898132324
Validation loss: 3.3808426549357753

Epoch: 6| Step: 6
Training loss: 3.7023091316223145
Validation loss: 3.371161422421855

Epoch: 6| Step: 7
Training loss: 2.9894485473632812
Validation loss: 3.364836526173417

Epoch: 6| Step: 8
Training loss: 3.576159715652466
Validation loss: 3.3575640109277542

Epoch: 6| Step: 9
Training loss: 3.2990803718566895
Validation loss: 3.3491150127944125

Epoch: 6| Step: 10
Training loss: 3.2378668785095215
Validation loss: 3.339752117792765

Epoch: 6| Step: 11
Training loss: 4.138714790344238
Validation loss: 3.3341977468100925

Epoch: 6| Step: 12
Training loss: 3.3553483486175537
Validation loss: 3.3235947137237876

Epoch: 6| Step: 13
Training loss: 2.042436361312866
Validation loss: 3.316205350301599

Epoch: 9| Step: 0
Training loss: 4.153456687927246
Validation loss: 3.306352707647508

Epoch: 6| Step: 1
Training loss: 2.341831922531128
Validation loss: 3.2967347586026756

Epoch: 6| Step: 2
Training loss: 2.717587471008301
Validation loss: 3.2904031097248034

Epoch: 6| Step: 3
Training loss: 3.602294921875
Validation loss: 3.280637361670053

Epoch: 6| Step: 4
Training loss: 3.2112112045288086
Validation loss: 3.2707941916681107

Epoch: 6| Step: 5
Training loss: 3.958566665649414
Validation loss: 3.2620642518484466

Epoch: 6| Step: 6
Training loss: 3.439760208129883
Validation loss: 3.2529200071929605

Epoch: 6| Step: 7
Training loss: 3.715550661087036
Validation loss: 3.242649362933251

Epoch: 6| Step: 8
Training loss: 2.0026917457580566
Validation loss: 3.228093777933428

Epoch: 6| Step: 9
Training loss: 3.381924629211426
Validation loss: 3.2220524664848083

Epoch: 6| Step: 10
Training loss: 3.155393362045288
Validation loss: 3.2090358862312893

Epoch: 6| Step: 11
Training loss: 3.472438335418701
Validation loss: 3.1987654137355026

Epoch: 6| Step: 12
Training loss: 3.106302261352539
Validation loss: 3.1899931610271497

Epoch: 6| Step: 13
Training loss: 2.626781940460205
Validation loss: 3.181483922466155

Epoch: 10| Step: 0
Training loss: 2.5998809337615967
Validation loss: 3.1697456503427155

Epoch: 6| Step: 1
Training loss: 3.3544387817382812
Validation loss: 3.164448227933658

Epoch: 6| Step: 2
Training loss: 2.718754768371582
Validation loss: 3.1540611995163785

Epoch: 6| Step: 3
Training loss: 3.680891990661621
Validation loss: 3.1495403576922674

Epoch: 6| Step: 4
Training loss: 2.7776472568511963
Validation loss: 3.141366525362897

Epoch: 6| Step: 5
Training loss: 3.3563241958618164
Validation loss: 3.1313558983546432

Epoch: 6| Step: 6
Training loss: 3.346768856048584
Validation loss: 3.122642860617689

Epoch: 6| Step: 7
Training loss: 3.7762300968170166
Validation loss: 3.117336344975297

Epoch: 6| Step: 8
Training loss: 1.8080140352249146
Validation loss: 3.1077157861442974

Epoch: 6| Step: 9
Training loss: 3.9358510971069336
Validation loss: 3.1023439668839976

Epoch: 6| Step: 10
Training loss: 2.6880316734313965
Validation loss: 3.0968095666618756

Epoch: 6| Step: 11
Training loss: 3.7531535625457764
Validation loss: 3.091235222355012

Epoch: 6| Step: 12
Training loss: 3.051844596862793
Validation loss: 3.085455212541806

Epoch: 6| Step: 13
Training loss: 3.1149961948394775
Validation loss: 3.0794778331633537

Epoch: 11| Step: 0
Training loss: 2.5805468559265137
Validation loss: 3.0762813065641668

Epoch: 6| Step: 1
Training loss: 2.8043975830078125
Validation loss: 3.0707445477926605

Epoch: 6| Step: 2
Training loss: 2.985792636871338
Validation loss: 3.061939675320861

Epoch: 6| Step: 3
Training loss: 2.7101473808288574
Validation loss: 3.0567405146937214

Epoch: 6| Step: 4
Training loss: 3.26688551902771
Validation loss: 3.052034947179979

Epoch: 6| Step: 5
Training loss: 2.3849079608917236
Validation loss: 3.045681545811315

Epoch: 6| Step: 6
Training loss: 2.60752534866333
Validation loss: 3.042057521881596

Epoch: 6| Step: 7
Training loss: 3.1341381072998047
Validation loss: 3.0391014417012534

Epoch: 6| Step: 8
Training loss: 3.459056854248047
Validation loss: 3.0327551903263217

Epoch: 6| Step: 9
Training loss: 3.4565978050231934
Validation loss: 3.030469781608992

Epoch: 6| Step: 10
Training loss: 3.3657009601593018
Validation loss: 3.0230526667769237

Epoch: 6| Step: 11
Training loss: 3.232691764831543
Validation loss: 3.0156511798981698

Epoch: 6| Step: 12
Training loss: 3.2639946937561035
Validation loss: 3.0117858814936813

Epoch: 6| Step: 13
Training loss: 4.655065536499023
Validation loss: 3.009003787912348

Epoch: 12| Step: 0
Training loss: 2.573934316635132
Validation loss: 3.000468207943824

Epoch: 6| Step: 1
Training loss: 4.267831802368164
Validation loss: 2.9981586804953952

Epoch: 6| Step: 2
Training loss: 3.5103819370269775
Validation loss: 2.991463326638745

Epoch: 6| Step: 3
Training loss: 3.5046136379241943
Validation loss: 2.9861309900078723

Epoch: 6| Step: 4
Training loss: 2.522433280944824
Validation loss: 2.980781547484859

Epoch: 6| Step: 5
Training loss: 2.628549337387085
Validation loss: 2.973582121633714

Epoch: 6| Step: 6
Training loss: 2.70322847366333
Validation loss: 2.9726662046165875

Epoch: 6| Step: 7
Training loss: 3.21504282951355
Validation loss: 2.9670768655756468

Epoch: 6| Step: 8
Training loss: 3.052903175354004
Validation loss: 2.9632461865743003

Epoch: 6| Step: 9
Training loss: 3.8161091804504395
Validation loss: 2.9568458910911315

Epoch: 6| Step: 10
Training loss: 2.720426082611084
Validation loss: 2.9490625012305474

Epoch: 6| Step: 11
Training loss: 2.36491060256958
Validation loss: 2.9486036249386367

Epoch: 6| Step: 12
Training loss: 2.6705658435821533
Validation loss: 2.9435125371461273

Epoch: 6| Step: 13
Training loss: 3.0678815841674805
Validation loss: 2.9410307689379622

Epoch: 13| Step: 0
Training loss: 4.184488296508789
Validation loss: 2.935444865175473

Epoch: 6| Step: 1
Training loss: 3.0867152214050293
Validation loss: 2.9302910758603002

Epoch: 6| Step: 2
Training loss: 3.029592514038086
Validation loss: 2.929787282020815

Epoch: 6| Step: 3
Training loss: 2.788722276687622
Validation loss: 2.9244898801208823

Epoch: 6| Step: 4
Training loss: 2.3600170612335205
Validation loss: 2.921914105774254

Epoch: 6| Step: 5
Training loss: 2.8938846588134766
Validation loss: 2.919596267002885

Epoch: 6| Step: 6
Training loss: 4.360572338104248
Validation loss: 2.913969316790181

Epoch: 6| Step: 7
Training loss: 2.9193310737609863
Validation loss: 2.904801648150208

Epoch: 6| Step: 8
Training loss: 2.8251688480377197
Validation loss: 2.9013844715651644

Epoch: 6| Step: 9
Training loss: 2.336472272872925
Validation loss: 2.8961134264546056

Epoch: 6| Step: 10
Training loss: 2.7383110523223877
Validation loss: 2.8914889776578514

Epoch: 6| Step: 11
Training loss: 2.9840829372406006
Validation loss: 2.884501482850762

Epoch: 6| Step: 12
Training loss: 2.45676326751709
Validation loss: 2.8828911371128534

Epoch: 6| Step: 13
Training loss: 3.15822434425354
Validation loss: 2.8751154689378637

Epoch: 14| Step: 0
Training loss: 2.147592544555664
Validation loss: 2.8728958150391937

Epoch: 6| Step: 1
Training loss: 2.779832601547241
Validation loss: 2.8692066977100987

Epoch: 6| Step: 2
Training loss: 2.3492112159729004
Validation loss: 2.8646102259235997

Epoch: 6| Step: 3
Training loss: 3.188444137573242
Validation loss: 2.8586104685260403

Epoch: 6| Step: 4
Training loss: 3.610628128051758
Validation loss: 2.851487572475146

Epoch: 6| Step: 5
Training loss: 3.196833610534668
Validation loss: 2.8434796640949864

Epoch: 6| Step: 6
Training loss: 2.268054962158203
Validation loss: 2.838709303127822

Epoch: 6| Step: 7
Training loss: 3.1819019317626953
Validation loss: 2.831593026397049

Epoch: 6| Step: 8
Training loss: 2.93552565574646
Validation loss: 2.828097874118436

Epoch: 6| Step: 9
Training loss: 3.4606263637542725
Validation loss: 2.821923504593552

Epoch: 6| Step: 10
Training loss: 3.1570491790771484
Validation loss: 2.8235106237473024

Epoch: 6| Step: 11
Training loss: 2.725886344909668
Validation loss: 2.8175302884911977

Epoch: 6| Step: 12
Training loss: 3.6907477378845215
Validation loss: 2.8130735171738492

Epoch: 6| Step: 13
Training loss: 2.49003529548645
Validation loss: 2.809349021603984

Epoch: 15| Step: 0
Training loss: 2.552156925201416
Validation loss: 2.804452890990883

Epoch: 6| Step: 1
Training loss: 3.0930638313293457
Validation loss: 2.7919060953201784

Epoch: 6| Step: 2
Training loss: 2.6916441917419434
Validation loss: 2.788081330637778

Epoch: 6| Step: 3
Training loss: 3.5636072158813477
Validation loss: 2.7814992217607397

Epoch: 6| Step: 4
Training loss: 3.097909450531006
Validation loss: 2.7777610568590063

Epoch: 6| Step: 5
Training loss: 2.408721923828125
Validation loss: 2.77082323515287

Epoch: 6| Step: 6
Training loss: 2.904258966445923
Validation loss: 2.7636316360965854

Epoch: 6| Step: 7
Training loss: 2.1710729598999023
Validation loss: 2.7592366741549585

Epoch: 6| Step: 8
Training loss: 2.6097803115844727
Validation loss: 2.7558615156399306

Epoch: 6| Step: 9
Training loss: 3.1687076091766357
Validation loss: 2.753094957720849

Epoch: 6| Step: 10
Training loss: 2.7290585041046143
Validation loss: 2.7442199209684968

Epoch: 6| Step: 11
Training loss: 2.569472074508667
Validation loss: 2.7429173787434897

Epoch: 6| Step: 12
Training loss: 3.5116896629333496
Validation loss: 2.741384574162063

Epoch: 6| Step: 13
Training loss: 4.190986633300781
Validation loss: 2.735126446652156

Epoch: 16| Step: 0
Training loss: 3.56037974357605
Validation loss: 2.7317315301587506

Epoch: 6| Step: 1
Training loss: 2.6461234092712402
Validation loss: 2.7338625923279793

Epoch: 6| Step: 2
Training loss: 3.420818328857422
Validation loss: 2.73127459197916

Epoch: 6| Step: 3
Training loss: 3.733081340789795
Validation loss: 2.7398841099072526

Epoch: 6| Step: 4
Training loss: 2.503056049346924
Validation loss: 2.7224447393930085

Epoch: 6| Step: 5
Training loss: 2.5152101516723633
Validation loss: 2.712723321812127

Epoch: 6| Step: 6
Training loss: 2.8203227519989014
Validation loss: 2.7093326327621297

Epoch: 6| Step: 7
Training loss: 2.4659249782562256
Validation loss: 2.706174868409352

Epoch: 6| Step: 8
Training loss: 3.2422385215759277
Validation loss: 2.7085397679318666

Epoch: 6| Step: 9
Training loss: 2.5013279914855957
Validation loss: 2.717355410257975

Epoch: 6| Step: 10
Training loss: 2.1878936290740967
Validation loss: 2.703450649015365

Epoch: 6| Step: 11
Training loss: 2.536457061767578
Validation loss: 2.6943824624502533

Epoch: 6| Step: 12
Training loss: 2.955641746520996
Validation loss: 2.6914420102232244

Epoch: 6| Step: 13
Training loss: 3.3303825855255127
Validation loss: 2.700649469129501

Epoch: 17| Step: 0
Training loss: 3.9542160034179688
Validation loss: 2.6942814909001833

Epoch: 6| Step: 1
Training loss: 2.7982969284057617
Validation loss: 2.681621915550642

Epoch: 6| Step: 2
Training loss: 2.569775104522705
Validation loss: 2.6858195591998357

Epoch: 6| Step: 3
Training loss: 2.9858922958374023
Validation loss: 2.6864174489052064

Epoch: 6| Step: 4
Training loss: 3.074199914932251
Validation loss: 2.6837457995260916

Epoch: 6| Step: 5
Training loss: 3.1081185340881348
Validation loss: 2.6857721549208446

Epoch: 6| Step: 6
Training loss: 2.1144800186157227
Validation loss: 2.6793495147458968

Epoch: 6| Step: 7
Training loss: 2.150890350341797
Validation loss: 2.668993739671605

Epoch: 6| Step: 8
Training loss: 3.0645296573638916
Validation loss: 2.6680536167595976

Epoch: 6| Step: 9
Training loss: 3.0450267791748047
Validation loss: 2.6674906822942916

Epoch: 6| Step: 10
Training loss: 3.2583680152893066
Validation loss: 2.6630677100150817

Epoch: 6| Step: 11
Training loss: 2.1066479682922363
Validation loss: 2.6619719330982496

Epoch: 6| Step: 12
Training loss: 2.5237653255462646
Validation loss: 2.655088593882899

Epoch: 6| Step: 13
Training loss: 3.4829869270324707
Validation loss: 2.6554858325630106

Epoch: 18| Step: 0
Training loss: 2.9383792877197266
Validation loss: 2.6555167423781527

Epoch: 6| Step: 1
Training loss: 3.071195602416992
Validation loss: 2.650120976150677

Epoch: 6| Step: 2
Training loss: 2.1092472076416016
Validation loss: 2.649232349088115

Epoch: 6| Step: 3
Training loss: 2.820038318634033
Validation loss: 2.6473837078258557

Epoch: 6| Step: 4
Training loss: 2.777524709701538
Validation loss: 2.643960219557567

Epoch: 6| Step: 5
Training loss: 3.7311413288116455
Validation loss: 2.6432921783898466

Epoch: 6| Step: 6
Training loss: 2.7236948013305664
Validation loss: 2.6397954033267115

Epoch: 6| Step: 7
Training loss: 2.602142810821533
Validation loss: 2.6381953095877044

Epoch: 6| Step: 8
Training loss: 2.940267324447632
Validation loss: 2.634149835955712

Epoch: 6| Step: 9
Training loss: 2.877509593963623
Validation loss: 2.6320954958597818

Epoch: 6| Step: 10
Training loss: 2.747270345687866
Validation loss: 2.6299567222595215

Epoch: 6| Step: 11
Training loss: 2.9174554347991943
Validation loss: 2.626353850928686

Epoch: 6| Step: 12
Training loss: 2.413512706756592
Validation loss: 2.6256918650801464

Epoch: 6| Step: 13
Training loss: 3.032555341720581
Validation loss: 2.619552681522985

Epoch: 19| Step: 0
Training loss: 3.0371623039245605
Validation loss: 2.6218649341214086

Epoch: 6| Step: 1
Training loss: 3.26101016998291
Validation loss: 2.6181735812976794

Epoch: 6| Step: 2
Training loss: 1.872473955154419
Validation loss: 2.617960663251979

Epoch: 6| Step: 3
Training loss: 2.8789491653442383
Validation loss: 2.6188230053071053

Epoch: 6| Step: 4
Training loss: 2.74780535697937
Validation loss: 2.6177807443885395

Epoch: 6| Step: 5
Training loss: 2.6835057735443115
Validation loss: 2.6215503164516982

Epoch: 6| Step: 6
Training loss: 3.0743823051452637
Validation loss: 2.6155372588865218

Epoch: 6| Step: 7
Training loss: 2.4582958221435547
Validation loss: 2.612144629160563

Epoch: 6| Step: 8
Training loss: 2.5139517784118652
Validation loss: 2.6102598251834994

Epoch: 6| Step: 9
Training loss: 3.1709580421447754
Validation loss: 2.6092699035521476

Epoch: 6| Step: 10
Training loss: 2.8070507049560547
Validation loss: 2.608374621278496

Epoch: 6| Step: 11
Training loss: 3.414435625076294
Validation loss: 2.6049639101951354

Epoch: 6| Step: 12
Training loss: 2.7402563095092773
Validation loss: 2.603711856308804

Epoch: 6| Step: 13
Training loss: 2.5590267181396484
Validation loss: 2.5998608399462957

Epoch: 20| Step: 0
Training loss: 2.7379283905029297
Validation loss: 2.6129195356881745

Epoch: 6| Step: 1
Training loss: 2.6273720264434814
Validation loss: 2.6301969661507556

Epoch: 6| Step: 2
Training loss: 2.815610885620117
Validation loss: 2.611074391231742

Epoch: 6| Step: 3
Training loss: 3.4788036346435547
Validation loss: 2.5945003917140346

Epoch: 6| Step: 4
Training loss: 2.4043049812316895
Validation loss: 2.5971350798042874

Epoch: 6| Step: 5
Training loss: 2.374532461166382
Validation loss: 2.6014943251045803

Epoch: 6| Step: 6
Training loss: 3.077120065689087
Validation loss: 2.6022054251804145

Epoch: 6| Step: 7
Training loss: 2.553328037261963
Validation loss: 2.6008922284649265

Epoch: 6| Step: 8
Training loss: 2.8871657848358154
Validation loss: 2.6026529137806227

Epoch: 6| Step: 9
Training loss: 3.34320068359375
Validation loss: 2.597863592127318

Epoch: 6| Step: 10
Training loss: 2.5246024131774902
Validation loss: 2.5973536224775415

Epoch: 6| Step: 11
Training loss: 2.7844955921173096
Validation loss: 2.5937677480841197

Epoch: 6| Step: 12
Training loss: 3.2871339321136475
Validation loss: 2.5953034534249255

Epoch: 6| Step: 13
Training loss: 1.9961340427398682
Validation loss: 2.5923118232398905

Epoch: 21| Step: 0
Training loss: 2.748035430908203
Validation loss: 2.591415436037125

Epoch: 6| Step: 1
Training loss: 2.9018430709838867
Validation loss: 2.5902904515625327

Epoch: 6| Step: 2
Training loss: 2.925041675567627
Validation loss: 2.5898098945617676

Epoch: 6| Step: 3
Training loss: 3.3592147827148438
Validation loss: 2.591554821178477

Epoch: 6| Step: 4
Training loss: 3.4163451194763184
Validation loss: 2.587071398253082

Epoch: 6| Step: 5
Training loss: 2.862473964691162
Validation loss: 2.5859697018900225

Epoch: 6| Step: 6
Training loss: 2.5962939262390137
Validation loss: 2.583727188007806

Epoch: 6| Step: 7
Training loss: 2.651914119720459
Validation loss: 2.5828037108144453

Epoch: 6| Step: 8
Training loss: 2.917628765106201
Validation loss: 2.586623643034248

Epoch: 6| Step: 9
Training loss: 2.396771192550659
Validation loss: 2.579931805210729

Epoch: 6| Step: 10
Training loss: 2.6636691093444824
Validation loss: 2.5793396862604285

Epoch: 6| Step: 11
Training loss: 2.636017322540283
Validation loss: 2.5744247436523438

Epoch: 6| Step: 12
Training loss: 2.4975500106811523
Validation loss: 2.5744238797054497

Epoch: 6| Step: 13
Training loss: 2.306256055831909
Validation loss: 2.5733971416309314

Epoch: 22| Step: 0
Training loss: 3.02009916305542
Validation loss: 2.57130463405322

Epoch: 6| Step: 1
Training loss: 2.8557987213134766
Validation loss: 2.5691959499030985

Epoch: 6| Step: 2
Training loss: 3.13139271736145
Validation loss: 2.5656273903385287

Epoch: 6| Step: 3
Training loss: 2.970855712890625
Validation loss: 2.5671019913047872

Epoch: 6| Step: 4
Training loss: 2.515171527862549
Validation loss: 2.5643626669401764

Epoch: 6| Step: 5
Training loss: 3.5782127380371094
Validation loss: 2.562501415129631

Epoch: 6| Step: 6
Training loss: 2.437584161758423
Validation loss: 2.561938078172745

Epoch: 6| Step: 7
Training loss: 2.7336010932922363
Validation loss: 2.561427088193996

Epoch: 6| Step: 8
Training loss: 2.162931203842163
Validation loss: 2.5589901888242332

Epoch: 6| Step: 9
Training loss: 2.39274263381958
Validation loss: 2.5575596363313737

Epoch: 6| Step: 10
Training loss: 2.5183911323547363
Validation loss: 2.55951702210211

Epoch: 6| Step: 11
Training loss: 2.8961668014526367
Validation loss: 2.5587702874214417

Epoch: 6| Step: 12
Training loss: 2.381269693374634
Validation loss: 2.5553376931016163

Epoch: 6| Step: 13
Training loss: 3.795048952102661
Validation loss: 2.5553245954616095

Epoch: 23| Step: 0
Training loss: 2.309523344039917
Validation loss: 2.5516088598517963

Epoch: 6| Step: 1
Training loss: 2.6195552349090576
Validation loss: 2.5462622975790374

Epoch: 6| Step: 2
Training loss: 2.7603800296783447
Validation loss: 2.5486701534640406

Epoch: 6| Step: 3
Training loss: 3.0797858238220215
Validation loss: 2.5492813920462005

Epoch: 6| Step: 4
Training loss: 2.881202220916748
Validation loss: 2.5476980850260746

Epoch: 6| Step: 5
Training loss: 2.5907135009765625
Validation loss: 2.5448584684761624

Epoch: 6| Step: 6
Training loss: 2.693887948989868
Validation loss: 2.543367862701416

Epoch: 6| Step: 7
Training loss: 2.6658871173858643
Validation loss: 2.5408772524966987

Epoch: 6| Step: 8
Training loss: 2.975609540939331
Validation loss: 2.5412412945942213

Epoch: 6| Step: 9
Training loss: 2.6449637413024902
Validation loss: 2.543229700416647

Epoch: 6| Step: 10
Training loss: 3.1969714164733887
Validation loss: 2.538247287914317

Epoch: 6| Step: 11
Training loss: 2.9996161460876465
Validation loss: 2.5363147233122136

Epoch: 6| Step: 12
Training loss: 2.455124855041504
Validation loss: 2.5351878673799577

Epoch: 6| Step: 13
Training loss: 2.9985451698303223
Validation loss: 2.5362088885358585

Epoch: 24| Step: 0
Training loss: 3.27534818649292
Validation loss: 2.5384678994455645

Epoch: 6| Step: 1
Training loss: 2.9942269325256348
Validation loss: 2.5350262670106787

Epoch: 6| Step: 2
Training loss: 2.4903564453125
Validation loss: 2.5402259801023748

Epoch: 6| Step: 3
Training loss: 2.881525993347168
Validation loss: 2.5365198760904293

Epoch: 6| Step: 4
Training loss: 3.70894718170166
Validation loss: 2.5390305596013225

Epoch: 6| Step: 5
Training loss: 1.8124409914016724
Validation loss: 2.5382857732875372

Epoch: 6| Step: 6
Training loss: 2.974142074584961
Validation loss: 2.5360289004541214

Epoch: 6| Step: 7
Training loss: 2.037628173828125
Validation loss: 2.53441963144528

Epoch: 6| Step: 8
Training loss: 2.1454977989196777
Validation loss: 2.5341852736729447

Epoch: 6| Step: 9
Training loss: 2.9167885780334473
Validation loss: 2.529577145012476

Epoch: 6| Step: 10
Training loss: 3.4410572052001953
Validation loss: 2.5268828407410653

Epoch: 6| Step: 11
Training loss: 2.453029155731201
Validation loss: 2.5279783048937396

Epoch: 6| Step: 12
Training loss: 2.8951587677001953
Validation loss: 2.5234283811302594

Epoch: 6| Step: 13
Training loss: 2.4860966205596924
Validation loss: 2.51980314459852

Epoch: 25| Step: 0
Training loss: 2.716766834259033
Validation loss: 2.528593765792026

Epoch: 6| Step: 1
Training loss: 2.00753116607666
Validation loss: 2.54347946054192

Epoch: 6| Step: 2
Training loss: 3.158228874206543
Validation loss: 2.555688109449161

Epoch: 6| Step: 3
Training loss: 3.7185287475585938
Validation loss: 2.5587829979517127

Epoch: 6| Step: 4
Training loss: 3.4506397247314453
Validation loss: 2.532042041901619

Epoch: 6| Step: 5
Training loss: 2.337597608566284
Validation loss: 2.513124640269946

Epoch: 6| Step: 6
Training loss: 1.8961533308029175
Validation loss: 2.5079864507080405

Epoch: 6| Step: 7
Training loss: 3.0037031173706055
Validation loss: 2.507580118794595

Epoch: 6| Step: 8
Training loss: 2.261791706085205
Validation loss: 2.5075731662011917

Epoch: 6| Step: 9
Training loss: 2.6094393730163574
Validation loss: 2.5048326189799974

Epoch: 6| Step: 10
Training loss: 2.70670747756958
Validation loss: 2.5064562828310075

Epoch: 6| Step: 11
Training loss: 2.7727012634277344
Validation loss: 2.5038080189817693

Epoch: 6| Step: 12
Training loss: 2.535823345184326
Validation loss: 2.4997992284836306

Epoch: 6| Step: 13
Training loss: 3.9334499835968018
Validation loss: 2.5009081491860012

Epoch: 26| Step: 0
Training loss: 3.129883289337158
Validation loss: 2.4940298039426088

Epoch: 6| Step: 1
Training loss: 3.2744717597961426
Validation loss: 2.4913064202954693

Epoch: 6| Step: 2
Training loss: 1.9440422058105469
Validation loss: 2.4873417423617457

Epoch: 6| Step: 3
Training loss: 3.048600435256958
Validation loss: 2.4831815765750025

Epoch: 6| Step: 4
Training loss: 2.6414923667907715
Validation loss: 2.4874692091377835

Epoch: 6| Step: 5
Training loss: 2.5179362297058105
Validation loss: 2.4799904464393534

Epoch: 6| Step: 6
Training loss: 2.9140706062316895
Validation loss: 2.481883151556856

Epoch: 6| Step: 7
Training loss: 2.281156063079834
Validation loss: 2.4777108341135006

Epoch: 6| Step: 8
Training loss: 2.204293966293335
Validation loss: 2.479075285696214

Epoch: 6| Step: 9
Training loss: 3.346754312515259
Validation loss: 2.476842708485101

Epoch: 6| Step: 10
Training loss: 2.3307788372039795
Validation loss: 2.4762531967573267

Epoch: 6| Step: 11
Training loss: 3.1393320560455322
Validation loss: 2.500226613013975

Epoch: 6| Step: 12
Training loss: 2.7850914001464844
Validation loss: 2.489870927667105

Epoch: 6| Step: 13
Training loss: 2.561825752258301
Validation loss: 2.4949767281932216

Epoch: 27| Step: 0
Training loss: 2.3941779136657715
Validation loss: 2.4990367325403358

Epoch: 6| Step: 1
Training loss: 1.963317632675171
Validation loss: 2.4727939867204234

Epoch: 6| Step: 2
Training loss: 2.676337480545044
Validation loss: 2.4773186432418

Epoch: 6| Step: 3
Training loss: 3.4650282859802246
Validation loss: 2.4946598775925173

Epoch: 6| Step: 4
Training loss: 2.7828407287597656
Validation loss: 2.487418108088996

Epoch: 6| Step: 5
Training loss: 2.941883087158203
Validation loss: 2.4754401650480045

Epoch: 6| Step: 6
Training loss: 3.2891674041748047
Validation loss: 2.472316216397029

Epoch: 6| Step: 7
Training loss: 2.5894813537597656
Validation loss: 2.475852317707513

Epoch: 6| Step: 8
Training loss: 2.5214614868164062
Validation loss: 2.472897183510565

Epoch: 6| Step: 9
Training loss: 2.5831055641174316
Validation loss: 2.475027076659664

Epoch: 6| Step: 10
Training loss: 3.484872579574585
Validation loss: 2.4678018554564445

Epoch: 6| Step: 11
Training loss: 2.3489737510681152
Validation loss: 2.4654187220399097

Epoch: 6| Step: 12
Training loss: 2.3048806190490723
Validation loss: 2.4659474203663487

Epoch: 6| Step: 13
Training loss: 2.6691980361938477
Validation loss: 2.4599570817844842

Epoch: 28| Step: 0
Training loss: 3.878643274307251
Validation loss: 2.473449804449594

Epoch: 6| Step: 1
Training loss: 2.096709728240967
Validation loss: 2.485999212470106

Epoch: 6| Step: 2
Training loss: 2.730024576187134
Validation loss: 2.4930145432872157

Epoch: 6| Step: 3
Training loss: 2.7764902114868164
Validation loss: 2.4879314002170356

Epoch: 6| Step: 4
Training loss: 2.579226493835449
Validation loss: 2.4651683402317826

Epoch: 6| Step: 5
Training loss: 2.537114143371582
Validation loss: 2.4594652883468138

Epoch: 6| Step: 6
Training loss: 2.9670886993408203
Validation loss: 2.4587993468007734

Epoch: 6| Step: 7
Training loss: 2.831925630569458
Validation loss: 2.4529641366774038

Epoch: 6| Step: 8
Training loss: 2.1683807373046875
Validation loss: 2.451418138319446

Epoch: 6| Step: 9
Training loss: 3.2091121673583984
Validation loss: 2.4545043694075717

Epoch: 6| Step: 10
Training loss: 2.86771297454834
Validation loss: 2.474800617464127

Epoch: 6| Step: 11
Training loss: 2.2669317722320557
Validation loss: 2.4902578502572994

Epoch: 6| Step: 12
Training loss: 2.469902515411377
Validation loss: 2.49760712346723

Epoch: 6| Step: 13
Training loss: 2.634396553039551
Validation loss: 2.498985303345547

Epoch: 29| Step: 0
Training loss: 2.373556613922119
Validation loss: 2.47610060117578

Epoch: 6| Step: 1
Training loss: 2.6471643447875977
Validation loss: 2.4517371526328464

Epoch: 6| Step: 2
Training loss: 2.742805004119873
Validation loss: 2.4479671883326706

Epoch: 6| Step: 3
Training loss: 3.1441752910614014
Validation loss: 2.4477387602611254

Epoch: 6| Step: 4
Training loss: 2.707341194152832
Validation loss: 2.446093979702201

Epoch: 6| Step: 5
Training loss: 3.0215234756469727
Validation loss: 2.4457808515076995

Epoch: 6| Step: 6
Training loss: 2.1183922290802
Validation loss: 2.448529548542474

Epoch: 6| Step: 7
Training loss: 3.121739149093628
Validation loss: 2.4413031813918904

Epoch: 6| Step: 8
Training loss: 2.565765857696533
Validation loss: 2.4459097436679307

Epoch: 6| Step: 9
Training loss: 2.2871899604797363
Validation loss: 2.4478749203425583

Epoch: 6| Step: 10
Training loss: 2.7954907417297363
Validation loss: 2.4520536750875492

Epoch: 6| Step: 11
Training loss: 2.737604856491089
Validation loss: 2.4516811114485546

Epoch: 6| Step: 12
Training loss: 2.828375816345215
Validation loss: 2.45070311843708

Epoch: 6| Step: 13
Training loss: 2.9190335273742676
Validation loss: 2.4588053149561726

Epoch: 30| Step: 0
Training loss: 3.4933650493621826
Validation loss: 2.449032924508536

Epoch: 6| Step: 1
Training loss: 2.662970542907715
Validation loss: 2.445317232480613

Epoch: 6| Step: 2
Training loss: 2.9933509826660156
Validation loss: 2.4460925338088826

Epoch: 6| Step: 3
Training loss: 2.693495273590088
Validation loss: 2.4416787162903817

Epoch: 6| Step: 4
Training loss: 3.0719547271728516
Validation loss: 2.439901649311025

Epoch: 6| Step: 5
Training loss: 2.5220630168914795
Validation loss: 2.43589194615682

Epoch: 6| Step: 6
Training loss: 2.590916395187378
Validation loss: 2.4409325763743412

Epoch: 6| Step: 7
Training loss: 2.2195329666137695
Validation loss: 2.4463369205433834

Epoch: 6| Step: 8
Training loss: 1.8390824794769287
Validation loss: 2.458082304205946

Epoch: 6| Step: 9
Training loss: 3.0592427253723145
Validation loss: 2.4662717926886772

Epoch: 6| Step: 10
Training loss: 2.8264293670654297
Validation loss: 2.4798225741232596

Epoch: 6| Step: 11
Training loss: 2.1965203285217285
Validation loss: 2.4942083538219495

Epoch: 6| Step: 12
Training loss: 2.7474255561828613
Validation loss: 2.52361269920103

Epoch: 6| Step: 13
Training loss: 3.0012848377227783
Validation loss: 2.5320557753245034

Epoch: 31| Step: 0
Training loss: 3.5567736625671387
Validation loss: 2.493753687027962

Epoch: 6| Step: 1
Training loss: 2.0844759941101074
Validation loss: 2.465830797790199

Epoch: 6| Step: 2
Training loss: 2.2828445434570312
Validation loss: 2.435678574346727

Epoch: 6| Step: 3
Training loss: 3.2254233360290527
Validation loss: 2.434906359641783

Epoch: 6| Step: 4
Training loss: 2.8643994331359863
Validation loss: 2.422758435690275

Epoch: 6| Step: 5
Training loss: 1.8546686172485352
Validation loss: 2.430512712847802

Epoch: 6| Step: 6
Training loss: 1.9423437118530273
Validation loss: 2.428622217588527

Epoch: 6| Step: 7
Training loss: 2.4528560638427734
Validation loss: 2.4293243961949504

Epoch: 6| Step: 8
Training loss: 3.4480485916137695
Validation loss: 2.4386787901642504

Epoch: 6| Step: 9
Training loss: 3.126164674758911
Validation loss: 2.4346783507254814

Epoch: 6| Step: 10
Training loss: 3.2683768272399902
Validation loss: 2.4396378224895847

Epoch: 6| Step: 11
Training loss: 2.9197802543640137
Validation loss: 2.427037690275459

Epoch: 6| Step: 12
Training loss: 2.446410655975342
Validation loss: 2.441871722539266

Epoch: 6| Step: 13
Training loss: 1.9633309841156006
Validation loss: 2.439716536511657

Epoch: 32| Step: 0
Training loss: 2.8049206733703613
Validation loss: 2.4380317939225065

Epoch: 6| Step: 1
Training loss: 2.920747756958008
Validation loss: 2.4492628087279615

Epoch: 6| Step: 2
Training loss: 2.9968748092651367
Validation loss: 2.4642585272430093

Epoch: 6| Step: 3
Training loss: 2.337127208709717
Validation loss: 2.453115619638915

Epoch: 6| Step: 4
Training loss: 3.121306896209717
Validation loss: 2.4739485222806215

Epoch: 6| Step: 5
Training loss: 2.231415271759033
Validation loss: 2.478481364506547

Epoch: 6| Step: 6
Training loss: 2.260159492492676
Validation loss: 2.476351148338728

Epoch: 6| Step: 7
Training loss: 2.601545810699463
Validation loss: 2.4801471412822766

Epoch: 6| Step: 8
Training loss: 2.1950769424438477
Validation loss: 2.4790005863353772

Epoch: 6| Step: 9
Training loss: 3.539888858795166
Validation loss: 2.463871576452768

Epoch: 6| Step: 10
Training loss: 2.762685775756836
Validation loss: 2.4559746147483907

Epoch: 6| Step: 11
Training loss: 2.6648380756378174
Validation loss: 2.4338863101056827

Epoch: 6| Step: 12
Training loss: 2.8839597702026367
Validation loss: 2.4230200552171275

Epoch: 6| Step: 13
Training loss: 1.9373193979263306
Validation loss: 2.4155758991036365

Epoch: 33| Step: 0
Training loss: 2.7866897583007812
Validation loss: 2.4201556405713482

Epoch: 6| Step: 1
Training loss: 2.1650209426879883
Validation loss: 2.4197628831350677

Epoch: 6| Step: 2
Training loss: 2.9176928997039795
Validation loss: 2.4236344316954255

Epoch: 6| Step: 3
Training loss: 2.7302916049957275
Validation loss: 2.419458655900853

Epoch: 6| Step: 4
Training loss: 2.571161985397339
Validation loss: 2.4168500054267144

Epoch: 6| Step: 5
Training loss: 2.57487154006958
Validation loss: 2.4197143944360877

Epoch: 6| Step: 6
Training loss: 2.9341330528259277
Validation loss: 2.4274046626142276

Epoch: 6| Step: 7
Training loss: 3.3893985748291016
Validation loss: 2.426955064137777

Epoch: 6| Step: 8
Training loss: 2.8336503505706787
Validation loss: 2.426146945645732

Epoch: 6| Step: 9
Training loss: 2.8156399726867676
Validation loss: 2.436746771617602

Epoch: 6| Step: 10
Training loss: 2.4038615226745605
Validation loss: 2.4490048910981868

Epoch: 6| Step: 11
Training loss: 1.8753080368041992
Validation loss: 2.4781776294913342

Epoch: 6| Step: 12
Training loss: 2.3870620727539062
Validation loss: 2.469012442455497

Epoch: 6| Step: 13
Training loss: 3.6097934246063232
Validation loss: 2.464910699475196

Epoch: 34| Step: 0
Training loss: 3.0773324966430664
Validation loss: 2.43914197849971

Epoch: 6| Step: 1
Training loss: 3.092977285385132
Validation loss: 2.426089116322097

Epoch: 6| Step: 2
Training loss: 2.0830752849578857
Validation loss: 2.412577470143636

Epoch: 6| Step: 3
Training loss: 2.383605718612671
Validation loss: 2.40434572773595

Epoch: 6| Step: 4
Training loss: 3.091402530670166
Validation loss: 2.401409697789018

Epoch: 6| Step: 5
Training loss: 2.7824935913085938
Validation loss: 2.4041574590949604

Epoch: 6| Step: 6
Training loss: 2.557602882385254
Validation loss: 2.4064383481138494

Epoch: 6| Step: 7
Training loss: 2.5970277786254883
Validation loss: 2.401314094502439

Epoch: 6| Step: 8
Training loss: 2.8976683616638184
Validation loss: 2.4029109119087138

Epoch: 6| Step: 9
Training loss: 2.693547248840332
Validation loss: 2.402638655836864

Epoch: 6| Step: 10
Training loss: 1.9738998413085938
Validation loss: 2.400663419436383

Epoch: 6| Step: 11
Training loss: 2.8464064598083496
Validation loss: 2.406432626067951

Epoch: 6| Step: 12
Training loss: 2.557711124420166
Validation loss: 2.4095228461809057

Epoch: 6| Step: 13
Training loss: 3.3913156986236572
Validation loss: 2.410717777026597

Epoch: 35| Step: 0
Training loss: 2.7424731254577637
Validation loss: 2.4047071267199773

Epoch: 6| Step: 1
Training loss: 1.7974478006362915
Validation loss: 2.401921715787662

Epoch: 6| Step: 2
Training loss: 2.1193108558654785
Validation loss: 2.4183252652486167

Epoch: 6| Step: 3
Training loss: 3.034499406814575
Validation loss: 2.421278799733808

Epoch: 6| Step: 4
Training loss: 2.440340757369995
Validation loss: 2.4416045219667497

Epoch: 6| Step: 5
Training loss: 3.3797028064727783
Validation loss: 2.4783209523847027

Epoch: 6| Step: 6
Training loss: 3.203951120376587
Validation loss: 2.4832245226829284

Epoch: 6| Step: 7
Training loss: 2.9097561836242676
Validation loss: 2.4526325733430925

Epoch: 6| Step: 8
Training loss: 2.403048515319824
Validation loss: 2.4384364799786638

Epoch: 6| Step: 9
Training loss: 2.691392183303833
Validation loss: 2.419851231318648

Epoch: 6| Step: 10
Training loss: 2.8313753604888916
Validation loss: 2.4182874130946335

Epoch: 6| Step: 11
Training loss: 3.32711124420166
Validation loss: 2.404979699401445

Epoch: 6| Step: 12
Training loss: 2.1886816024780273
Validation loss: 2.4034035641659974

Epoch: 6| Step: 13
Training loss: 2.2276313304901123
Validation loss: 2.3936573279801237

Epoch: 36| Step: 0
Training loss: 2.5517654418945312
Validation loss: 2.394476121471774

Epoch: 6| Step: 1
Training loss: 2.8620588779449463
Validation loss: 2.3954123040681243

Epoch: 6| Step: 2
Training loss: 3.1647791862487793
Validation loss: 2.392820158312398

Epoch: 6| Step: 3
Training loss: 2.322580337524414
Validation loss: 2.3905250257061375

Epoch: 6| Step: 4
Training loss: 1.9686973094940186
Validation loss: 2.395355419446063

Epoch: 6| Step: 5
Training loss: 2.285763740539551
Validation loss: 2.397503988717192

Epoch: 6| Step: 6
Training loss: 2.8947601318359375
Validation loss: 2.403374966754708

Epoch: 6| Step: 7
Training loss: 2.94527530670166
Validation loss: 2.41230430141572

Epoch: 6| Step: 8
Training loss: 2.361332416534424
Validation loss: 2.4288502764958206

Epoch: 6| Step: 9
Training loss: 2.2953171730041504
Validation loss: 2.4425163807407504

Epoch: 6| Step: 10
Training loss: 2.9553208351135254
Validation loss: 2.455199780002717

Epoch: 6| Step: 11
Training loss: 2.791682243347168
Validation loss: 2.465971996707301

Epoch: 6| Step: 12
Training loss: 2.514047384262085
Validation loss: 2.4567019939422607

Epoch: 6| Step: 13
Training loss: 4.10517692565918
Validation loss: 2.4527974128723145

Epoch: 37| Step: 0
Training loss: 2.831592321395874
Validation loss: 2.4134756083129556

Epoch: 6| Step: 1
Training loss: 2.804293155670166
Validation loss: 2.3933997692600375

Epoch: 6| Step: 2
Training loss: 3.2882020473480225
Validation loss: 2.3862045272704093

Epoch: 6| Step: 3
Training loss: 2.7725448608398438
Validation loss: 2.3808547373740905

Epoch: 6| Step: 4
Training loss: 2.4187936782836914
Validation loss: 2.380826298908521

Epoch: 6| Step: 5
Training loss: 2.473020553588867
Validation loss: 2.377019291282982

Epoch: 6| Step: 6
Training loss: 2.4695281982421875
Validation loss: 2.378503786620273

Epoch: 6| Step: 7
Training loss: 2.477954626083374
Validation loss: 2.385144741304459

Epoch: 6| Step: 8
Training loss: 2.2496540546417236
Validation loss: 2.3840249020566224

Epoch: 6| Step: 9
Training loss: 2.901049852371216
Validation loss: 2.3910438809343564

Epoch: 6| Step: 10
Training loss: 3.2134218215942383
Validation loss: 2.3982755548210553

Epoch: 6| Step: 11
Training loss: 2.583026885986328
Validation loss: 2.393338249575707

Epoch: 6| Step: 12
Training loss: 2.0234131813049316
Validation loss: 2.3916825120167067

Epoch: 6| Step: 13
Training loss: 2.9793879985809326
Validation loss: 2.387773113866006

Epoch: 38| Step: 0
Training loss: 2.7392396926879883
Validation loss: 2.381786295162734

Epoch: 6| Step: 1
Training loss: 2.753443479537964
Validation loss: 2.3851805733096216

Epoch: 6| Step: 2
Training loss: 2.1464805603027344
Validation loss: 2.3820724718032347

Epoch: 6| Step: 3
Training loss: 2.646723985671997
Validation loss: 2.383952799663749

Epoch: 6| Step: 4
Training loss: 2.615013599395752
Validation loss: 2.392790609790433

Epoch: 6| Step: 5
Training loss: 2.207620620727539
Validation loss: 2.4133698453185377

Epoch: 6| Step: 6
Training loss: 3.318533420562744
Validation loss: 2.429605181499194

Epoch: 6| Step: 7
Training loss: 2.217257499694824
Validation loss: 2.4299911811787593

Epoch: 6| Step: 8
Training loss: 2.63128924369812
Validation loss: 2.4229067910102104

Epoch: 6| Step: 9
Training loss: 2.268709182739258
Validation loss: 2.4231606683423443

Epoch: 6| Step: 10
Training loss: 2.750370740890503
Validation loss: 2.416815552660214

Epoch: 6| Step: 11
Training loss: 2.5488414764404297
Validation loss: 2.4146753459848385

Epoch: 6| Step: 12
Training loss: 3.0895116329193115
Validation loss: 2.40450813693385

Epoch: 6| Step: 13
Training loss: 3.6774728298187256
Validation loss: 2.388815577312182

Epoch: 39| Step: 0
Training loss: 3.409115791320801
Validation loss: 2.3779012131434616

Epoch: 6| Step: 1
Training loss: 2.853140354156494
Validation loss: 2.3788695771207093

Epoch: 6| Step: 2
Training loss: 3.1734817028045654
Validation loss: 2.3743902714021745

Epoch: 6| Step: 3
Training loss: 2.3526418209075928
Validation loss: 2.37213219365766

Epoch: 6| Step: 4
Training loss: 2.7429659366607666
Validation loss: 2.371941299848659

Epoch: 6| Step: 5
Training loss: 2.3897783756256104
Validation loss: 2.3735764257369505

Epoch: 6| Step: 6
Training loss: 2.265845775604248
Validation loss: 2.373499137099071

Epoch: 6| Step: 7
Training loss: 2.6374025344848633
Validation loss: 2.377938555132958

Epoch: 6| Step: 8
Training loss: 1.9382234811782837
Validation loss: 2.388648212596934

Epoch: 6| Step: 9
Training loss: 2.9450860023498535
Validation loss: 2.3851420161544636

Epoch: 6| Step: 10
Training loss: 2.023202419281006
Validation loss: 2.398083233064221

Epoch: 6| Step: 11
Training loss: 3.0230813026428223
Validation loss: 2.4071990315632155

Epoch: 6| Step: 12
Training loss: 2.638866901397705
Validation loss: 2.423648839355797

Epoch: 6| Step: 13
Training loss: 2.616548776626587
Validation loss: 2.4239442348480225

Epoch: 40| Step: 0
Training loss: 2.332519054412842
Validation loss: 2.416015055871779

Epoch: 6| Step: 1
Training loss: 2.7423038482666016
Validation loss: 2.4199548190639866

Epoch: 6| Step: 2
Training loss: 3.5413031578063965
Validation loss: 2.428263189972088

Epoch: 6| Step: 3
Training loss: 3.5331532955169678
Validation loss: 2.408216714859009

Epoch: 6| Step: 4
Training loss: 2.777947425842285
Validation loss: 2.4004580192668463

Epoch: 6| Step: 5
Training loss: 2.8841030597686768
Validation loss: 2.4012235902970835

Epoch: 6| Step: 6
Training loss: 2.519429922103882
Validation loss: 2.3874953023848997

Epoch: 6| Step: 7
Training loss: 2.2889397144317627
Validation loss: 2.3840038827670518

Epoch: 6| Step: 8
Training loss: 1.4318761825561523
Validation loss: 2.3812734234717583

Epoch: 6| Step: 9
Training loss: 2.4246137142181396
Validation loss: 2.380698965441796

Epoch: 6| Step: 10
Training loss: 2.444251537322998
Validation loss: 2.376113127636653

Epoch: 6| Step: 11
Training loss: 3.4839038848876953
Validation loss: 2.375403663163544

Epoch: 6| Step: 12
Training loss: 2.623035430908203
Validation loss: 2.374588471586986

Epoch: 6| Step: 13
Training loss: 1.4591931104660034
Validation loss: 2.369814747123308

Epoch: 41| Step: 0
Training loss: 1.9798851013183594
Validation loss: 2.364488458120695

Epoch: 6| Step: 1
Training loss: 2.8645191192626953
Validation loss: 2.382050206584315

Epoch: 6| Step: 2
Training loss: 2.707254409790039
Validation loss: 2.3833040216917634

Epoch: 6| Step: 3
Training loss: 2.4423437118530273
Validation loss: 2.3748706104934856

Epoch: 6| Step: 4
Training loss: 2.7281177043914795
Validation loss: 2.3846410961561304

Epoch: 6| Step: 5
Training loss: 3.2571635246276855
Validation loss: 2.3953655586447766

Epoch: 6| Step: 6
Training loss: 3.210144281387329
Validation loss: 2.39770180948319

Epoch: 6| Step: 7
Training loss: 3.2913966178894043
Validation loss: 2.3820057325465704

Epoch: 6| Step: 8
Training loss: 2.2709968090057373
Validation loss: 2.3833341239601054

Epoch: 6| Step: 9
Training loss: 2.5598816871643066
Validation loss: 2.369087291020219

Epoch: 6| Step: 10
Training loss: 2.265347957611084
Validation loss: 2.3617608957393195

Epoch: 6| Step: 11
Training loss: 2.380204200744629
Validation loss: 2.3638517907870713

Epoch: 6| Step: 12
Training loss: 2.527555465698242
Validation loss: 2.365676538918608

Epoch: 6| Step: 13
Training loss: 2.4471397399902344
Validation loss: 2.3739673578610985

Epoch: 42| Step: 0
Training loss: 2.8503239154815674
Validation loss: 2.379332196327948

Epoch: 6| Step: 1
Training loss: 1.9654550552368164
Validation loss: 2.382584471856394

Epoch: 6| Step: 2
Training loss: 3.2365293502807617
Validation loss: 2.3808979180551346

Epoch: 6| Step: 3
Training loss: 2.309113025665283
Validation loss: 2.381007709810811

Epoch: 6| Step: 4
Training loss: 2.84726619720459
Validation loss: 2.383506787720547

Epoch: 6| Step: 5
Training loss: 2.5009078979492188
Validation loss: 2.3941634342234623

Epoch: 6| Step: 6
Training loss: 2.5612101554870605
Validation loss: 2.391654981079922

Epoch: 6| Step: 7
Training loss: 2.760122299194336
Validation loss: 2.4003823726407942

Epoch: 6| Step: 8
Training loss: 2.5255231857299805
Validation loss: 2.389287423062068

Epoch: 6| Step: 9
Training loss: 3.099561929702759
Validation loss: 2.394179021158526

Epoch: 6| Step: 10
Training loss: 2.2116870880126953
Validation loss: 2.384440327203402

Epoch: 6| Step: 11
Training loss: 3.243349075317383
Validation loss: 2.3885099016210085

Epoch: 6| Step: 12
Training loss: 2.4089722633361816
Validation loss: 2.391349087479294

Epoch: 6| Step: 13
Training loss: 2.3806495666503906
Validation loss: 2.381130961961644

Epoch: 43| Step: 0
Training loss: 3.0281882286071777
Validation loss: 2.3929332943372827

Epoch: 6| Step: 1
Training loss: 2.6792802810668945
Validation loss: 2.3961972985216367

Epoch: 6| Step: 2
Training loss: 2.356801986694336
Validation loss: 2.3971223728631132

Epoch: 6| Step: 3
Training loss: 2.38216495513916
Validation loss: 2.4021107253207954

Epoch: 6| Step: 4
Training loss: 2.7557384967803955
Validation loss: 2.4125378721503803

Epoch: 6| Step: 5
Training loss: 2.6230273246765137
Validation loss: 2.433581941871233

Epoch: 6| Step: 6
Training loss: 3.178248405456543
Validation loss: 2.4305889939749115

Epoch: 6| Step: 7
Training loss: 2.770054340362549
Validation loss: 2.43346062526908

Epoch: 6| Step: 8
Training loss: 2.4762563705444336
Validation loss: 2.4292712570518575

Epoch: 6| Step: 9
Training loss: 1.774263620376587
Validation loss: 2.419739141259142

Epoch: 6| Step: 10
Training loss: 2.6407337188720703
Validation loss: 2.398613009401547

Epoch: 6| Step: 11
Training loss: 2.572577953338623
Validation loss: 2.3765424259247316

Epoch: 6| Step: 12
Training loss: 2.9073314666748047
Validation loss: 2.3677110543815036

Epoch: 6| Step: 13
Training loss: 2.8058416843414307
Validation loss: 2.3462140713968584

Epoch: 44| Step: 0
Training loss: 2.491457462310791
Validation loss: 2.349930158225439

Epoch: 6| Step: 1
Training loss: 3.0004630088806152
Validation loss: 2.3540643748416694

Epoch: 6| Step: 2
Training loss: 2.876408100128174
Validation loss: 2.354070181487709

Epoch: 6| Step: 3
Training loss: 2.310189723968506
Validation loss: 2.3512131988361316

Epoch: 6| Step: 4
Training loss: 2.7285521030426025
Validation loss: 2.354129381077264

Epoch: 6| Step: 5
Training loss: 2.366236686706543
Validation loss: 2.34879481920632

Epoch: 6| Step: 6
Training loss: 2.7399375438690186
Validation loss: 2.3561884510901665

Epoch: 6| Step: 7
Training loss: 2.6849684715270996
Validation loss: 2.3538592707726265

Epoch: 6| Step: 8
Training loss: 2.9185054302215576
Validation loss: 2.3566357551082486

Epoch: 6| Step: 9
Training loss: 2.154134511947632
Validation loss: 2.358590852829718

Epoch: 6| Step: 10
Training loss: 2.1418724060058594
Validation loss: 2.361055022926741

Epoch: 6| Step: 11
Training loss: 2.989187717437744
Validation loss: 2.370218471814227

Epoch: 6| Step: 12
Training loss: 2.7242512702941895
Validation loss: 2.383185625076294

Epoch: 6| Step: 13
Training loss: 2.883422613143921
Validation loss: 2.394299678905036

Epoch: 45| Step: 0
Training loss: 2.672520875930786
Validation loss: 2.39055210544217

Epoch: 6| Step: 1
Training loss: 2.680476665496826
Validation loss: 2.385946278930992

Epoch: 6| Step: 2
Training loss: 2.4727277755737305
Validation loss: 2.376896963324598

Epoch: 6| Step: 3
Training loss: 2.313947916030884
Validation loss: 2.3664212303776897

Epoch: 6| Step: 4
Training loss: 1.8363268375396729
Validation loss: 2.363736931995679

Epoch: 6| Step: 5
Training loss: 3.129682779312134
Validation loss: 2.3614903649976178

Epoch: 6| Step: 6
Training loss: 2.853828191757202
Validation loss: 2.3663912537277385

Epoch: 6| Step: 7
Training loss: 2.891451835632324
Validation loss: 2.3704857723687285

Epoch: 6| Step: 8
Training loss: 2.8306894302368164
Validation loss: 2.3740700855050036

Epoch: 6| Step: 9
Training loss: 1.9641460180282593
Validation loss: 2.3625892669923845

Epoch: 6| Step: 10
Training loss: 2.822072744369507
Validation loss: 2.3623389787571405

Epoch: 6| Step: 11
Training loss: 2.407545566558838
Validation loss: 2.359509350151144

Epoch: 6| Step: 12
Training loss: 2.8882994651794434
Validation loss: 2.354852581536898

Epoch: 6| Step: 13
Training loss: 3.2732348442077637
Validation loss: 2.3580716989373647

Epoch: 46| Step: 0
Training loss: 2.3282387256622314
Validation loss: 2.361141968798894

Epoch: 6| Step: 1
Training loss: 2.45937180519104
Validation loss: 2.3589828193828626

Epoch: 6| Step: 2
Training loss: 2.6870017051696777
Validation loss: 2.373535725378221

Epoch: 6| Step: 3
Training loss: 2.895655393600464
Validation loss: 2.383718744401009

Epoch: 6| Step: 4
Training loss: 3.0346765518188477
Validation loss: 2.3979450887249363

Epoch: 6| Step: 5
Training loss: 2.5033152103424072
Validation loss: 2.3899803238530315

Epoch: 6| Step: 6
Training loss: 3.0279269218444824
Validation loss: 2.381476858610748

Epoch: 6| Step: 7
Training loss: 1.97866690158844
Validation loss: 2.3708173792849303

Epoch: 6| Step: 8
Training loss: 2.2912354469299316
Validation loss: 2.3477443238740325

Epoch: 6| Step: 9
Training loss: 2.9740591049194336
Validation loss: 2.336090090454266

Epoch: 6| Step: 10
Training loss: 1.818096399307251
Validation loss: 2.333361771798903

Epoch: 6| Step: 11
Training loss: 2.7167582511901855
Validation loss: 2.3341889663409163

Epoch: 6| Step: 12
Training loss: 3.257958173751831
Validation loss: 2.336415278014316

Epoch: 6| Step: 13
Training loss: 2.995026111602783
Validation loss: 2.3392729502852245

Epoch: 47| Step: 0
Training loss: 2.4732625484466553
Validation loss: 2.3413635799961705

Epoch: 6| Step: 1
Training loss: 2.8450684547424316
Validation loss: 2.344452997689606

Epoch: 6| Step: 2
Training loss: 3.5281357765197754
Validation loss: 2.337596560037264

Epoch: 6| Step: 3
Training loss: 2.2469136714935303
Validation loss: 2.3340976443341983

Epoch: 6| Step: 4
Training loss: 2.5734353065490723
Validation loss: 2.3316083620953303

Epoch: 6| Step: 5
Training loss: 2.668351650238037
Validation loss: 2.334285769411313

Epoch: 6| Step: 6
Training loss: 2.669165849685669
Validation loss: 2.344885767147105

Epoch: 6| Step: 7
Training loss: 2.8808858394622803
Validation loss: 2.351827831678493

Epoch: 6| Step: 8
Training loss: 3.0734894275665283
Validation loss: 2.359129592936526

Epoch: 6| Step: 9
Training loss: 2.3936681747436523
Validation loss: 2.377041594956511

Epoch: 6| Step: 10
Training loss: 1.8721153736114502
Validation loss: 2.3908590091172086

Epoch: 6| Step: 11
Training loss: 2.805245876312256
Validation loss: 2.3959468154497046

Epoch: 6| Step: 12
Training loss: 2.1057870388031006
Validation loss: 2.4033570315248225

Epoch: 6| Step: 13
Training loss: 2.8448503017425537
Validation loss: 2.4008968799344954

Epoch: 48| Step: 0
Training loss: 2.3387298583984375
Validation loss: 2.3971258235234085

Epoch: 6| Step: 1
Training loss: 3.033174514770508
Validation loss: 2.3876376408402638

Epoch: 6| Step: 2
Training loss: 2.6106643676757812
Validation loss: 2.3893655730832006

Epoch: 6| Step: 3
Training loss: 2.2214126586914062
Validation loss: 2.377696180856356

Epoch: 6| Step: 4
Training loss: 2.4715733528137207
Validation loss: 2.3690180317048104

Epoch: 6| Step: 5
Training loss: 2.4525015354156494
Validation loss: 2.366048248865271

Epoch: 6| Step: 6
Training loss: 2.6041975021362305
Validation loss: 2.368834712172067

Epoch: 6| Step: 7
Training loss: 2.6110496520996094
Validation loss: 2.3648461475167224

Epoch: 6| Step: 8
Training loss: 2.7227768898010254
Validation loss: 2.3596856235176005

Epoch: 6| Step: 9
Training loss: 2.8204028606414795
Validation loss: 2.353087802087107

Epoch: 6| Step: 10
Training loss: 2.502631187438965
Validation loss: 2.3557372170109905

Epoch: 6| Step: 11
Training loss: 2.9001262187957764
Validation loss: 2.3537044243146013

Epoch: 6| Step: 12
Training loss: 2.5315704345703125
Validation loss: 2.3515471771199215

Epoch: 6| Step: 13
Training loss: 3.0718634128570557
Validation loss: 2.339769540294524

Epoch: 49| Step: 0
Training loss: 2.8951778411865234
Validation loss: 2.352271615817983

Epoch: 6| Step: 1
Training loss: 2.338287115097046
Validation loss: 2.3456808187628306

Epoch: 6| Step: 2
Training loss: 1.8829302787780762
Validation loss: 2.33780405341938

Epoch: 6| Step: 3
Training loss: 3.1376495361328125
Validation loss: 2.349882000236101

Epoch: 6| Step: 4
Training loss: 2.9105048179626465
Validation loss: 2.3538337548573813

Epoch: 6| Step: 5
Training loss: 2.3952431678771973
Validation loss: 2.3475811994203957

Epoch: 6| Step: 6
Training loss: 3.3461198806762695
Validation loss: 2.3580127390482093

Epoch: 6| Step: 7
Training loss: 1.9831576347351074
Validation loss: 2.3453428053086802

Epoch: 6| Step: 8
Training loss: 3.047434091567993
Validation loss: 2.3507425810701106

Epoch: 6| Step: 9
Training loss: 2.0107297897338867
Validation loss: 2.3470444704896662

Epoch: 6| Step: 10
Training loss: 2.9595844745635986
Validation loss: 2.34363583595522

Epoch: 6| Step: 11
Training loss: 2.7321600914001465
Validation loss: 2.339377116131526

Epoch: 6| Step: 12
Training loss: 2.635180950164795
Validation loss: 2.3351830205609723

Epoch: 6| Step: 13
Training loss: 2.1760571002960205
Validation loss: 2.3311247979440997

Epoch: 50| Step: 0
Training loss: 2.601576805114746
Validation loss: 2.330862752852901

Epoch: 6| Step: 1
Training loss: 2.2452445030212402
Validation loss: 2.33235885507317

Epoch: 6| Step: 2
Training loss: 2.3195457458496094
Validation loss: 2.33125792267502

Epoch: 6| Step: 3
Training loss: 2.6617507934570312
Validation loss: 2.3319813666805143

Epoch: 6| Step: 4
Training loss: 2.791661024093628
Validation loss: 2.343299050484934

Epoch: 6| Step: 5
Training loss: 2.9390053749084473
Validation loss: 2.3511072076776975

Epoch: 6| Step: 6
Training loss: 2.464137077331543
Validation loss: 2.358611686255342

Epoch: 6| Step: 7
Training loss: 2.8475685119628906
Validation loss: 2.3632500120388564

Epoch: 6| Step: 8
Training loss: 2.9711012840270996
Validation loss: 2.3638433153911302

Epoch: 6| Step: 9
Training loss: 2.7110352516174316
Validation loss: 2.3628030489849787

Epoch: 6| Step: 10
Training loss: 3.0468008518218994
Validation loss: 2.3771967759696384

Epoch: 6| Step: 11
Training loss: 2.0025696754455566
Validation loss: 2.3696483591551423

Epoch: 6| Step: 12
Training loss: 2.7839555740356445
Validation loss: 2.389018010067683

Epoch: 6| Step: 13
Training loss: 1.808722972869873
Validation loss: 2.4042611634859474

Testing loss: 2.5255872779422335
