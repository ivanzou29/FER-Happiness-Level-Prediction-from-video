Epoch: 1| Step: 0
Training loss: 5.726098180997071
Validation loss: 5.82667565314636

Epoch: 6| Step: 1
Training loss: 6.117333109597621
Validation loss: 5.822147259629775

Epoch: 6| Step: 2
Training loss: 6.239430760559838
Validation loss: 5.817526723866935

Epoch: 6| Step: 3
Training loss: 5.712557749383288
Validation loss: 5.813298751281886

Epoch: 6| Step: 4
Training loss: 5.577840161998435
Validation loss: 5.809009525011889

Epoch: 6| Step: 5
Training loss: 5.519504641545028
Validation loss: 5.804336501244958

Epoch: 6| Step: 6
Training loss: 6.178371901877561
Validation loss: 5.800136175880219

Epoch: 6| Step: 7
Training loss: 6.523288382464843
Validation loss: 5.795475312204301

Epoch: 6| Step: 8
Training loss: 6.82714948516388
Validation loss: 5.791316892600308

Epoch: 6| Step: 9
Training loss: 5.709168792992966
Validation loss: 5.786548669361583

Epoch: 6| Step: 10
Training loss: 5.204493986922467
Validation loss: 5.7819784063076325

Epoch: 6| Step: 11
Training loss: 5.650692733562906
Validation loss: 5.777109184080236

Epoch: 6| Step: 12
Training loss: 5.4193985530010185
Validation loss: 5.7720539594913545

Epoch: 6| Step: 13
Training loss: 4.167409957709372
Validation loss: 5.767200917004014

Epoch: 2| Step: 0
Training loss: 6.817577184975297
Validation loss: 5.761883312758367

Epoch: 6| Step: 1
Training loss: 4.582392139320451
Validation loss: 5.756650867082903

Epoch: 6| Step: 2
Training loss: 6.295384232942487
Validation loss: 5.751505525798456

Epoch: 6| Step: 3
Training loss: 5.210185258320993
Validation loss: 5.745181611073241

Epoch: 6| Step: 4
Training loss: 3.8893315260129575
Validation loss: 5.739463225875777

Epoch: 6| Step: 5
Training loss: 6.299550285637026
Validation loss: 5.7331367544588945

Epoch: 6| Step: 6
Training loss: 7.147069114247331
Validation loss: 5.726895897376465

Epoch: 6| Step: 7
Training loss: 6.020114244156444
Validation loss: 5.720130625096024

Epoch: 6| Step: 8
Training loss: 4.6445388473050775
Validation loss: 5.71308165864775

Epoch: 6| Step: 9
Training loss: 4.868301876340423
Validation loss: 5.705756781785742

Epoch: 6| Step: 10
Training loss: 6.060352692365303
Validation loss: 5.698346659681021

Epoch: 6| Step: 11
Training loss: 6.025308637509459
Validation loss: 5.690299930547893

Epoch: 6| Step: 12
Training loss: 6.764039591686346
Validation loss: 5.682579644631265

Epoch: 6| Step: 13
Training loss: 4.074936595961758
Validation loss: 5.673440186910517

Epoch: 3| Step: 0
Training loss: 6.679086116020278
Validation loss: 5.664737694609077

Epoch: 6| Step: 1
Training loss: 5.1463153731739
Validation loss: 5.654727959214482

Epoch: 6| Step: 2
Training loss: 5.352980644386341
Validation loss: 5.645382913789214

Epoch: 6| Step: 3
Training loss: 6.0925798906638144
Validation loss: 5.635591066592416

Epoch: 6| Step: 4
Training loss: 5.064557446259727
Validation loss: 5.625333696354966

Epoch: 6| Step: 5
Training loss: 6.522585729852194
Validation loss: 5.614138827063016

Epoch: 6| Step: 6
Training loss: 4.46253845027312
Validation loss: 5.602881951022644

Epoch: 6| Step: 7
Training loss: 5.737386385721507
Validation loss: 5.592311840848401

Epoch: 6| Step: 8
Training loss: 4.776076565957837
Validation loss: 5.579620733440075

Epoch: 6| Step: 9
Training loss: 5.722351941034433
Validation loss: 5.567373666537913

Epoch: 6| Step: 10
Training loss: 7.268151809862062
Validation loss: 5.554985952539266

Epoch: 6| Step: 11
Training loss: 5.302062788388281
Validation loss: 5.541468053357018

Epoch: 6| Step: 12
Training loss: 5.582010919148157
Validation loss: 5.52797033374058

Epoch: 6| Step: 13
Training loss: 3.153370365089364
Validation loss: 5.51354945693279

Epoch: 4| Step: 0
Training loss: 5.903078549769273
Validation loss: 5.50033375351066

Epoch: 6| Step: 1
Training loss: 6.217201845315977
Validation loss: 5.485538975823951

Epoch: 6| Step: 2
Training loss: 5.935563906174151
Validation loss: 5.469246516738731

Epoch: 6| Step: 3
Training loss: 5.372419935706457
Validation loss: 5.454000509751866

Epoch: 6| Step: 4
Training loss: 5.399690562671848
Validation loss: 5.438719069067556

Epoch: 6| Step: 5
Training loss: 5.904567902830878
Validation loss: 5.421267977244211

Epoch: 6| Step: 6
Training loss: 5.15880766348088
Validation loss: 5.403090367940784

Epoch: 6| Step: 7
Training loss: 4.957566445078982
Validation loss: 5.386292462196307

Epoch: 6| Step: 8
Training loss: 4.703279917247162
Validation loss: 5.368540082083278

Epoch: 6| Step: 9
Training loss: 4.785004980070737
Validation loss: 5.348022330476038

Epoch: 6| Step: 10
Training loss: 4.230547198891744
Validation loss: 5.330409557307626

Epoch: 6| Step: 11
Training loss: 6.360616576819003
Validation loss: 5.3106398528288645

Epoch: 6| Step: 12
Training loss: 5.160781626089937
Validation loss: 5.287862285908622

Epoch: 6| Step: 13
Training loss: 5.846595764832174
Validation loss: 5.264935731437424

Epoch: 5| Step: 0
Training loss: 4.1092687092658196
Validation loss: 5.242201287004329

Epoch: 6| Step: 1
Training loss: 4.725455868644199
Validation loss: 5.219545121682108

Epoch: 6| Step: 2
Training loss: 5.894311535521617
Validation loss: 5.197253790519988

Epoch: 6| Step: 3
Training loss: 4.961093593754919
Validation loss: 5.1709860484556005

Epoch: 6| Step: 4
Training loss: 4.884488189030087
Validation loss: 5.145440861062918

Epoch: 6| Step: 5
Training loss: 4.684472492366487
Validation loss: 5.1218730782533255

Epoch: 6| Step: 6
Training loss: 5.049021922658713
Validation loss: 5.095842736948003

Epoch: 6| Step: 7
Training loss: 5.355741197596721
Validation loss: 5.071192809470329

Epoch: 6| Step: 8
Training loss: 5.848474235123743
Validation loss: 5.044596288778859

Epoch: 6| Step: 9
Training loss: 5.531073443509858
Validation loss: 5.0178593912489795

Epoch: 6| Step: 10
Training loss: 5.4344293101373475
Validation loss: 4.991850852961265

Epoch: 6| Step: 11
Training loss: 4.702257044598537
Validation loss: 4.964871833641613

Epoch: 6| Step: 12
Training loss: 5.378566357214528
Validation loss: 4.939121684602168

Epoch: 6| Step: 13
Training loss: 5.09174443178785
Validation loss: 4.915598602971918

Epoch: 6| Step: 0
Training loss: 5.207316408698232
Validation loss: 4.893125068356974

Epoch: 6| Step: 1
Training loss: 4.91900609281612
Validation loss: 4.871051974492871

Epoch: 6| Step: 2
Training loss: 5.902827810436958
Validation loss: 4.849606220145432

Epoch: 6| Step: 3
Training loss: 5.293024604756031
Validation loss: 4.827790127605027

Epoch: 6| Step: 4
Training loss: 4.306385072491558
Validation loss: 4.807818659457533

Epoch: 6| Step: 5
Training loss: 5.212103534504522
Validation loss: 4.783709102856129

Epoch: 6| Step: 6
Training loss: 4.46034442546748
Validation loss: 4.760378056578715

Epoch: 6| Step: 7
Training loss: 3.386008499450291
Validation loss: 4.739437001036165

Epoch: 6| Step: 8
Training loss: 4.726236631651473
Validation loss: 4.7182522218970036

Epoch: 6| Step: 9
Training loss: 4.34703236342362
Validation loss: 4.700374439032218

Epoch: 6| Step: 10
Training loss: 5.646457182516242
Validation loss: 4.682065179856019

Epoch: 6| Step: 11
Training loss: 3.8673641896583337
Validation loss: 4.666639645816141

Epoch: 6| Step: 12
Training loss: 4.991385095431772
Validation loss: 4.653599083219276

Epoch: 6| Step: 13
Training loss: 5.006346298987003
Validation loss: 4.637590263683869

Epoch: 7| Step: 0
Training loss: 4.533074373440886
Validation loss: 4.624878820524081

Epoch: 6| Step: 1
Training loss: 4.892896813161214
Validation loss: 4.612145995225762

Epoch: 6| Step: 2
Training loss: 5.058775485393782
Validation loss: 4.599794807333897

Epoch: 6| Step: 3
Training loss: 5.698671206134374
Validation loss: 4.586743986241662

Epoch: 6| Step: 4
Training loss: 5.200151940106684
Validation loss: 4.577386320716543

Epoch: 6| Step: 5
Training loss: 4.427445316849369
Validation loss: 4.563592143706447

Epoch: 6| Step: 6
Training loss: 4.2191073796110565
Validation loss: 4.552008332581511

Epoch: 6| Step: 7
Training loss: 5.120317320229174
Validation loss: 4.541482661842608

Epoch: 6| Step: 8
Training loss: 4.955323703019712
Validation loss: 4.529720687924325

Epoch: 6| Step: 9
Training loss: 4.902704014401851
Validation loss: 4.516070959051809

Epoch: 6| Step: 10
Training loss: 3.769682791238225
Validation loss: 4.50563224388111

Epoch: 6| Step: 11
Training loss: 4.219980696141354
Validation loss: 4.4922444498055585

Epoch: 6| Step: 12
Training loss: 3.7188384742790754
Validation loss: 4.483465945723114

Epoch: 6| Step: 13
Training loss: 3.3211663079619487
Validation loss: 4.469371456135583

Epoch: 8| Step: 0
Training loss: 4.043170898101499
Validation loss: 4.459646663868656

Epoch: 6| Step: 1
Training loss: 4.1503019291993235
Validation loss: 4.449364651864403

Epoch: 6| Step: 2
Training loss: 5.587546889003832
Validation loss: 4.438004273979235

Epoch: 6| Step: 3
Training loss: 4.707630723950325
Validation loss: 4.428574411608491

Epoch: 6| Step: 4
Training loss: 4.174820335314242
Validation loss: 4.4178023283897945

Epoch: 6| Step: 5
Training loss: 3.335458904303113
Validation loss: 4.406044866737738

Epoch: 6| Step: 6
Training loss: 4.842732377983077
Validation loss: 4.393820007594554

Epoch: 6| Step: 7
Training loss: 4.219901372832728
Validation loss: 4.383574757235568

Epoch: 6| Step: 8
Training loss: 3.877977888220339
Validation loss: 4.372510036813298

Epoch: 6| Step: 9
Training loss: 5.624204452206094
Validation loss: 4.362856787630678

Epoch: 6| Step: 10
Training loss: 3.2974338148298887
Validation loss: 4.351481083682167

Epoch: 6| Step: 11
Training loss: 4.471155759497044
Validation loss: 4.3379320672337345

Epoch: 6| Step: 12
Training loss: 5.031971376249718
Validation loss: 4.32579634234287

Epoch: 6| Step: 13
Training loss: 5.223992552665788
Validation loss: 4.316928907125547

Epoch: 9| Step: 0
Training loss: 3.952770714847715
Validation loss: 4.306122043923857

Epoch: 6| Step: 1
Training loss: 3.790786193791601
Validation loss: 4.290021815117475

Epoch: 6| Step: 2
Training loss: 5.1220573723323195
Validation loss: 4.282027501291009

Epoch: 6| Step: 3
Training loss: 4.091767041955683
Validation loss: 4.271851265784321

Epoch: 6| Step: 4
Training loss: 4.858421305693668
Validation loss: 4.26069737950327

Epoch: 6| Step: 5
Training loss: 4.420223075795488
Validation loss: 4.253915210274765

Epoch: 6| Step: 6
Training loss: 3.871349830510396
Validation loss: 4.243703870250604

Epoch: 6| Step: 7
Training loss: 4.72378998456084
Validation loss: 4.234844803937557

Epoch: 6| Step: 8
Training loss: 4.584228821174582
Validation loss: 4.229091616747174

Epoch: 6| Step: 9
Training loss: 3.8826609530127407
Validation loss: 4.220866917242304

Epoch: 6| Step: 10
Training loss: 4.429595784847493
Validation loss: 4.214825304444092

Epoch: 6| Step: 11
Training loss: 4.844458743510788
Validation loss: 4.205788436934765

Epoch: 6| Step: 12
Training loss: 4.8800632885440445
Validation loss: 4.200261929348456

Epoch: 6| Step: 13
Training loss: 2.034668027339062
Validation loss: 4.187252800810547

Epoch: 10| Step: 0
Training loss: 3.966454029528059
Validation loss: 4.181147351237262

Epoch: 6| Step: 1
Training loss: 4.540053241434355
Validation loss: 4.171880531775928

Epoch: 6| Step: 2
Training loss: 3.7710427213811744
Validation loss: 4.1664329405829585

Epoch: 6| Step: 3
Training loss: 5.153056132340473
Validation loss: 4.160110887342444

Epoch: 6| Step: 4
Training loss: 4.343968008594491
Validation loss: 4.152711375787759

Epoch: 6| Step: 5
Training loss: 3.5908245618855736
Validation loss: 4.1455467983806935

Epoch: 6| Step: 6
Training loss: 4.175423816481533
Validation loss: 4.138930659663637

Epoch: 6| Step: 7
Training loss: 3.7731048879676625
Validation loss: 4.133081471718285

Epoch: 6| Step: 8
Training loss: 4.973407793450689
Validation loss: 4.127284737609989

Epoch: 6| Step: 9
Training loss: 4.4293705794919385
Validation loss: 4.121436826516303

Epoch: 6| Step: 10
Training loss: 4.045675799638579
Validation loss: 4.116566713044751

Epoch: 6| Step: 11
Training loss: 3.980219210813079
Validation loss: 4.109362857332307

Epoch: 6| Step: 12
Training loss: 4.760164327910428
Validation loss: 4.106034648264868

Epoch: 6| Step: 13
Training loss: 3.7988666601114276
Validation loss: 4.099086291598281

Epoch: 11| Step: 0
Training loss: 4.123668340109766
Validation loss: 4.0948013024109775

Epoch: 6| Step: 1
Training loss: 3.595286165395459
Validation loss: 4.085585204080334

Epoch: 6| Step: 2
Training loss: 5.874784749734486
Validation loss: 4.080489442584326

Epoch: 6| Step: 3
Training loss: 4.2747530681836245
Validation loss: 4.076475185715276

Epoch: 6| Step: 4
Training loss: 5.001067429089299
Validation loss: 4.067865625670405

Epoch: 6| Step: 5
Training loss: 3.9443638633651807
Validation loss: 4.064218533418335

Epoch: 6| Step: 6
Training loss: 3.707826101066763
Validation loss: 4.057331593287405

Epoch: 6| Step: 7
Training loss: 4.0122253038729125
Validation loss: 4.050584187995205

Epoch: 6| Step: 8
Training loss: 3.3713342043806565
Validation loss: 4.043692881499385

Epoch: 6| Step: 9
Training loss: 3.541051983317891
Validation loss: 4.040539354153385

Epoch: 6| Step: 10
Training loss: 5.163728596428953
Validation loss: 4.033509295686435

Epoch: 6| Step: 11
Training loss: 3.9659269610213763
Validation loss: 4.0264479817583965

Epoch: 6| Step: 12
Training loss: 4.2012013851532135
Validation loss: 4.021502964053489

Epoch: 6| Step: 13
Training loss: 2.1102381317849783
Validation loss: 4.014717340065785

Epoch: 12| Step: 0
Training loss: 4.376911508684908
Validation loss: 4.010967150483018

Epoch: 6| Step: 1
Training loss: 3.890541903056498
Validation loss: 4.010095730445095

Epoch: 6| Step: 2
Training loss: 4.66462231316351
Validation loss: 4.004269994684908

Epoch: 6| Step: 3
Training loss: 4.464029873737747
Validation loss: 3.9976703194290386

Epoch: 6| Step: 4
Training loss: 4.072125578377245
Validation loss: 3.994149192409542

Epoch: 6| Step: 5
Training loss: 3.4203588183714193
Validation loss: 3.9854816158713566

Epoch: 6| Step: 6
Training loss: 3.684483733121734
Validation loss: 3.981708051147033

Epoch: 6| Step: 7
Training loss: 4.823357558507044
Validation loss: 3.97783029273399

Epoch: 6| Step: 8
Training loss: 4.3970053799188324
Validation loss: 3.9698413811031448

Epoch: 6| Step: 9
Training loss: 4.145345278947153
Validation loss: 3.9663978423178787

Epoch: 6| Step: 10
Training loss: 4.171718637343625
Validation loss: 3.9600664736742335

Epoch: 6| Step: 11
Training loss: 3.905354511614683
Validation loss: 3.956011321119805

Epoch: 6| Step: 12
Training loss: 3.212554598689421
Validation loss: 3.9494357864877307

Epoch: 6| Step: 13
Training loss: 4.491827643534826
Validation loss: 3.950499629463881

Epoch: 13| Step: 0
Training loss: 3.905041561125337
Validation loss: 3.9439333127611556

Epoch: 6| Step: 1
Training loss: 3.800544127607724
Validation loss: 3.938463214672961

Epoch: 6| Step: 2
Training loss: 4.366035432302189
Validation loss: 3.932328640506529

Epoch: 6| Step: 3
Training loss: 3.926485672186608
Validation loss: 3.9320760266719685

Epoch: 6| Step: 4
Training loss: 4.906441265678688
Validation loss: 3.9240917880687998

Epoch: 6| Step: 5
Training loss: 3.7562995133016712
Validation loss: 3.9213688093167303

Epoch: 6| Step: 6
Training loss: 3.5719553967603392
Validation loss: 3.9208943444588233

Epoch: 6| Step: 7
Training loss: 3.231318997323443
Validation loss: 3.912587873367188

Epoch: 6| Step: 8
Training loss: 3.690600885608004
Validation loss: 3.9086874798099775

Epoch: 6| Step: 9
Training loss: 5.135226954837103
Validation loss: 3.903621960693467

Epoch: 6| Step: 10
Training loss: 3.024756959341682
Validation loss: 3.8993845905550195

Epoch: 6| Step: 11
Training loss: 4.597138899976139
Validation loss: 3.8969858195655234

Epoch: 6| Step: 12
Training loss: 4.203534074467574
Validation loss: 3.8906392538981884

Epoch: 6| Step: 13
Training loss: 4.560842134446422
Validation loss: 3.8845836249260484

Epoch: 14| Step: 0
Training loss: 4.635071999526642
Validation loss: 3.880439737636129

Epoch: 6| Step: 1
Training loss: 3.2873536516112347
Validation loss: 3.8699696201705893

Epoch: 6| Step: 2
Training loss: 3.9801206127657847
Validation loss: 3.867409715413508

Epoch: 6| Step: 3
Training loss: 4.471266244843332
Validation loss: 3.8688911875685372

Epoch: 6| Step: 4
Training loss: 4.333994056996846
Validation loss: 3.8587290323851233

Epoch: 6| Step: 5
Training loss: 3.4539023512581197
Validation loss: 3.8563691971661966

Epoch: 6| Step: 6
Training loss: 4.557874869677394
Validation loss: 3.854472330084743

Epoch: 6| Step: 7
Training loss: 2.825688698465559
Validation loss: 3.8563808015643533

Epoch: 6| Step: 8
Training loss: 2.9236474194742494
Validation loss: 3.852524372178201

Epoch: 6| Step: 9
Training loss: 3.877831808683557
Validation loss: 3.8448761521584918

Epoch: 6| Step: 10
Training loss: 3.8633296334811495
Validation loss: 3.8411106265543555

Epoch: 6| Step: 11
Training loss: 4.247836066967634
Validation loss: 3.838438779717364

Epoch: 6| Step: 12
Training loss: 4.278410478071508
Validation loss: 3.83597493920425

Epoch: 6| Step: 13
Training loss: 5.47479785563436
Validation loss: 3.8270935222620435

Epoch: 15| Step: 0
Training loss: 4.072993883472535
Validation loss: 3.820359393050799

Epoch: 6| Step: 1
Training loss: 3.2527336947954737
Validation loss: 3.8139599889841507

Epoch: 6| Step: 2
Training loss: 3.908645139726566
Validation loss: 3.813086554857496

Epoch: 6| Step: 3
Training loss: 4.627595121868213
Validation loss: 3.8074084826065615

Epoch: 6| Step: 4
Training loss: 3.2602714205596093
Validation loss: 3.8066225976362995

Epoch: 6| Step: 5
Training loss: 3.023004702954005
Validation loss: 3.803190142651934

Epoch: 6| Step: 6
Training loss: 4.216049120969736
Validation loss: 3.803635606900855

Epoch: 6| Step: 7
Training loss: 4.5421991065329435
Validation loss: 3.79458052835887

Epoch: 6| Step: 8
Training loss: 3.7610274617522004
Validation loss: 3.790102291927558

Epoch: 6| Step: 9
Training loss: 4.111113785980546
Validation loss: 3.787059706333064

Epoch: 6| Step: 10
Training loss: 4.511328530879279
Validation loss: 3.7831781092481447

Epoch: 6| Step: 11
Training loss: 3.3353659790177836
Validation loss: 3.7830291470361916

Epoch: 6| Step: 12
Training loss: 4.6257406105713565
Validation loss: 3.780938706804665

Epoch: 6| Step: 13
Training loss: 3.715469965415386
Validation loss: 3.7740337301878584

Epoch: 16| Step: 0
Training loss: 4.51846298213754
Validation loss: 3.7716799972836785

Epoch: 6| Step: 1
Training loss: 3.0684950402157427
Validation loss: 3.7687391944033375

Epoch: 6| Step: 2
Training loss: 3.208631741076141
Validation loss: 3.766228361779227

Epoch: 6| Step: 3
Training loss: 4.835199500053981
Validation loss: 3.766241693784563

Epoch: 6| Step: 4
Training loss: 4.082052276411158
Validation loss: 3.7595327892530537

Epoch: 6| Step: 5
Training loss: 3.683523329125382
Validation loss: 3.7574801232031345

Epoch: 6| Step: 6
Training loss: 4.20974742938213
Validation loss: 3.757126396642312

Epoch: 6| Step: 7
Training loss: 4.723439494797276
Validation loss: 3.7617485944707925

Epoch: 6| Step: 8
Training loss: 4.181371046746079
Validation loss: 3.748320351715699

Epoch: 6| Step: 9
Training loss: 3.793195535026287
Validation loss: 3.7467410101455907

Epoch: 6| Step: 10
Training loss: 3.748255005783212
Validation loss: 3.743642801438727

Epoch: 6| Step: 11
Training loss: 3.2188488102532933
Validation loss: 3.7415051434697655

Epoch: 6| Step: 12
Training loss: 3.96624244109743
Validation loss: 3.7406964719835494

Epoch: 6| Step: 13
Training loss: 2.7554730658934075
Validation loss: 3.7392171410286843

Epoch: 17| Step: 0
Training loss: 3.821722663594474
Validation loss: 3.7375228410319816

Epoch: 6| Step: 1
Training loss: 3.6578874100449608
Validation loss: 3.7323686761612276

Epoch: 6| Step: 2
Training loss: 4.229658477198867
Validation loss: 3.730354073751637

Epoch: 6| Step: 3
Training loss: 2.9108780957731892
Validation loss: 3.729515365070029

Epoch: 6| Step: 4
Training loss: 4.750561329651196
Validation loss: 3.7318749840010277

Epoch: 6| Step: 5
Training loss: 3.145450964588366
Validation loss: 3.7284694938156737

Epoch: 6| Step: 6
Training loss: 3.7940658412724146
Validation loss: 3.724844470854614

Epoch: 6| Step: 7
Training loss: 4.711869029091795
Validation loss: 3.7186413558899947

Epoch: 6| Step: 8
Training loss: 3.246121366270914
Validation loss: 3.717181823607787

Epoch: 6| Step: 9
Training loss: 3.9971293639129906
Validation loss: 3.713565930521952

Epoch: 6| Step: 10
Training loss: 3.174167049211309
Validation loss: 3.7116154291653687

Epoch: 6| Step: 11
Training loss: 3.642102903400721
Validation loss: 3.708805884163539

Epoch: 6| Step: 12
Training loss: 5.030168500015661
Validation loss: 3.7121715479496578

Epoch: 6| Step: 13
Training loss: 3.8696779189029313
Validation loss: 3.70814853736398

Epoch: 18| Step: 0
Training loss: 3.737065706569105
Validation loss: 3.7038404864657863

Epoch: 6| Step: 1
Training loss: 3.8009172436808654
Validation loss: 3.703787333240459

Epoch: 6| Step: 2
Training loss: 3.2562314961030303
Validation loss: 3.6984861918325267

Epoch: 6| Step: 3
Training loss: 3.65702694194029
Validation loss: 3.7003664010464097

Epoch: 6| Step: 4
Training loss: 3.6342123636476384
Validation loss: 3.700474474626505

Epoch: 6| Step: 5
Training loss: 3.85226885835551
Validation loss: 3.6990712109523307

Epoch: 6| Step: 6
Training loss: 3.547823472440753
Validation loss: 3.6927372882860903

Epoch: 6| Step: 7
Training loss: 4.378347805325033
Validation loss: 3.6914254428451168

Epoch: 6| Step: 8
Training loss: 4.172927095143388
Validation loss: 3.6904490465871236

Epoch: 6| Step: 9
Training loss: 3.967094616818649
Validation loss: 3.6890851189608673

Epoch: 6| Step: 10
Training loss: 4.3544178332054555
Validation loss: 3.6860171966351896

Epoch: 6| Step: 11
Training loss: 4.262777530886644
Validation loss: 3.68435730801735

Epoch: 6| Step: 12
Training loss: 4.008097558545495
Validation loss: 3.6807204143750876

Epoch: 6| Step: 13
Training loss: 3.16845277976146
Validation loss: 3.679017830324386

Epoch: 19| Step: 0
Training loss: 3.12899494402615
Validation loss: 3.6772788919948223

Epoch: 6| Step: 1
Training loss: 4.433573315275044
Validation loss: 3.676112274081449

Epoch: 6| Step: 2
Training loss: 4.4525143924161386
Validation loss: 3.67426399426603

Epoch: 6| Step: 3
Training loss: 4.222630051664798
Validation loss: 3.672510094702027

Epoch: 6| Step: 4
Training loss: 3.301988008649507
Validation loss: 3.672475435748099

Epoch: 6| Step: 5
Training loss: 3.4727648620441234
Validation loss: 3.6689333821855232

Epoch: 6| Step: 6
Training loss: 3.308349744498212
Validation loss: 3.664332179910375

Epoch: 6| Step: 7
Training loss: 4.336998392172971
Validation loss: 3.6662057104876205

Epoch: 6| Step: 8
Training loss: 4.179239808821537
Validation loss: 3.663736508479027

Epoch: 6| Step: 9
Training loss: 3.836364349421049
Validation loss: 3.662847811414661

Epoch: 6| Step: 10
Training loss: 3.9819547595333393
Validation loss: 3.659848827674158

Epoch: 6| Step: 11
Training loss: 3.617919056945899
Validation loss: 3.6578599323068564

Epoch: 6| Step: 12
Training loss: 3.93806308171559
Validation loss: 3.6545227040282344

Epoch: 6| Step: 13
Training loss: 3.050744675577018
Validation loss: 3.6548367498191086

Epoch: 20| Step: 0
Training loss: 4.29680086938895
Validation loss: 3.6526042879304854

Epoch: 6| Step: 1
Training loss: 3.8203596802588957
Validation loss: 3.6518344683985475

Epoch: 6| Step: 2
Training loss: 3.838771542308884
Validation loss: 3.653366015820791

Epoch: 6| Step: 3
Training loss: 2.534836477088053
Validation loss: 3.6528308139382304

Epoch: 6| Step: 4
Training loss: 2.8704223678236183
Validation loss: 3.64911313151618

Epoch: 6| Step: 5
Training loss: 3.7483901064994463
Validation loss: 3.6441403111279316

Epoch: 6| Step: 6
Training loss: 4.97208968873277
Validation loss: 3.6439579982150345

Epoch: 6| Step: 7
Training loss: 2.835331287168328
Validation loss: 3.6423597129189993

Epoch: 6| Step: 8
Training loss: 4.749298646245105
Validation loss: 3.642953288639631

Epoch: 6| Step: 9
Training loss: 4.165903911711278
Validation loss: 3.640293787033635

Epoch: 6| Step: 10
Training loss: 3.853183490343265
Validation loss: 3.6439623769948497

Epoch: 6| Step: 11
Training loss: 3.8991017358641273
Validation loss: 3.6387162954461822

Epoch: 6| Step: 12
Training loss: 3.108874716839661
Validation loss: 3.6397005235034956

Epoch: 6| Step: 13
Training loss: 4.3876199993884155
Validation loss: 3.637777512805301

Epoch: 21| Step: 0
Training loss: 4.780577169710947
Validation loss: 3.6373911622664012

Epoch: 6| Step: 1
Training loss: 3.3994557225524686
Validation loss: 3.631877961121449

Epoch: 6| Step: 2
Training loss: 3.3815980629866003
Validation loss: 3.633159938485698

Epoch: 6| Step: 3
Training loss: 4.139393749352991
Validation loss: 3.632876377115293

Epoch: 6| Step: 4
Training loss: 3.7728077617720728
Validation loss: 3.6329429543940175

Epoch: 6| Step: 5
Training loss: 4.2280699462013045
Validation loss: 3.632639728786146

Epoch: 6| Step: 6
Training loss: 3.730303599911107
Validation loss: 3.6323549749738646

Epoch: 6| Step: 7
Training loss: 3.516116366486374
Validation loss: 3.6309364939633597

Epoch: 6| Step: 8
Training loss: 3.2985338132847466
Validation loss: 3.6305031946734134

Epoch: 6| Step: 9
Training loss: 4.5260820054106565
Validation loss: 3.629145940551897

Epoch: 6| Step: 10
Training loss: 3.118622643081623
Validation loss: 3.626159216707904

Epoch: 6| Step: 11
Training loss: 3.826091615576037
Validation loss: 3.6264032244148425

Epoch: 6| Step: 12
Training loss: 3.735463003852322
Validation loss: 3.6213351540460406

Epoch: 6| Step: 13
Training loss: 3.6520920284245344
Validation loss: 3.621079525356184

Epoch: 22| Step: 0
Training loss: 3.703753840495657
Validation loss: 3.6212982113993064

Epoch: 6| Step: 1
Training loss: 4.200488543479943
Validation loss: 3.6194924045011145

Epoch: 6| Step: 2
Training loss: 4.003088474032596
Validation loss: 3.6181230302890612

Epoch: 6| Step: 3
Training loss: 3.1678078418888234
Validation loss: 3.6164218238650103

Epoch: 6| Step: 4
Training loss: 2.905531271384657
Validation loss: 3.6157523908970672

Epoch: 6| Step: 5
Training loss: 3.541382961503782
Validation loss: 3.6146981570770382

Epoch: 6| Step: 6
Training loss: 4.052596712646898
Validation loss: 3.613007819182339

Epoch: 6| Step: 7
Training loss: 4.188781314506265
Validation loss: 3.611624580764742

Epoch: 6| Step: 8
Training loss: 4.156582238248188
Validation loss: 3.6098743923017795

Epoch: 6| Step: 9
Training loss: 3.670437405581386
Validation loss: 3.607007711428429

Epoch: 6| Step: 10
Training loss: 4.082811490922666
Validation loss: 3.6069847743902352

Epoch: 6| Step: 11
Training loss: 3.9303123629535786
Validation loss: 3.6069579252474906

Epoch: 6| Step: 12
Training loss: 3.887924053455079
Validation loss: 3.6061431631219136

Epoch: 6| Step: 13
Training loss: 3.4210033961471296
Validation loss: 3.605510691294593

Epoch: 23| Step: 0
Training loss: 4.620704718342886
Validation loss: 3.602603894813563

Epoch: 6| Step: 1
Training loss: 3.6479972884184817
Validation loss: 3.6020826628260365

Epoch: 6| Step: 2
Training loss: 3.366702865808848
Validation loss: 3.601326110383875

Epoch: 6| Step: 3
Training loss: 2.923876887483743
Validation loss: 3.598207336305772

Epoch: 6| Step: 4
Training loss: 4.066054447137894
Validation loss: 3.5986076435691565

Epoch: 6| Step: 5
Training loss: 4.012145200830702
Validation loss: 3.598029588807107

Epoch: 6| Step: 6
Training loss: 3.4619654383969913
Validation loss: 3.5972701571391945

Epoch: 6| Step: 7
Training loss: 4.536943318501232
Validation loss: 3.5943351550991376

Epoch: 6| Step: 8
Training loss: 3.7202109664654457
Validation loss: 3.593896666855969

Epoch: 6| Step: 9
Training loss: 3.793160713594629
Validation loss: 3.593085460026078

Epoch: 6| Step: 10
Training loss: 3.761533041358008
Validation loss: 3.5942926925360923

Epoch: 6| Step: 11
Training loss: 3.260077770686284
Validation loss: 3.5900518406657174

Epoch: 6| Step: 12
Training loss: 3.368308745805211
Validation loss: 3.590041237756886

Epoch: 6| Step: 13
Training loss: 4.497783750920441
Validation loss: 3.589011818127968

Epoch: 24| Step: 0
Training loss: 2.972972236511364
Validation loss: 3.5887766448489185

Epoch: 6| Step: 1
Training loss: 3.763924495689696
Validation loss: 3.5870012101579714

Epoch: 6| Step: 2
Training loss: 3.0065287438989543
Validation loss: 3.588025489221445

Epoch: 6| Step: 3
Training loss: 4.08976773225079
Validation loss: 3.5850243099687784

Epoch: 6| Step: 4
Training loss: 4.17828881934767
Validation loss: 3.5858689475718064

Epoch: 6| Step: 5
Training loss: 3.9137905734507603
Validation loss: 3.5838703507661123

Epoch: 6| Step: 6
Training loss: 3.650090694607111
Validation loss: 3.5832027307525727

Epoch: 6| Step: 7
Training loss: 3.8290581013616802
Validation loss: 3.5821505729203724

Epoch: 6| Step: 8
Training loss: 4.471759343067832
Validation loss: 3.581134829038059

Epoch: 6| Step: 9
Training loss: 3.2647151866026216
Validation loss: 3.5806392611704703

Epoch: 6| Step: 10
Training loss: 3.77154860202303
Validation loss: 3.580749234349314

Epoch: 6| Step: 11
Training loss: 4.449421088463188
Validation loss: 3.5775604325678523

Epoch: 6| Step: 12
Training loss: 3.80778825115862
Validation loss: 3.578940895746435

Epoch: 6| Step: 13
Training loss: 3.1647451158915736
Validation loss: 3.5782452756681016

Epoch: 25| Step: 0
Training loss: 4.348741915071126
Validation loss: 3.575544424873707

Epoch: 6| Step: 1
Training loss: 4.338190926261235
Validation loss: 3.5744465786318216

Epoch: 6| Step: 2
Training loss: 4.498740549801003
Validation loss: 3.5753018363731237

Epoch: 6| Step: 3
Training loss: 3.251656770233262
Validation loss: 3.5717965316489773

Epoch: 6| Step: 4
Training loss: 3.853343868923194
Validation loss: 3.57125233580151

Epoch: 6| Step: 5
Training loss: 3.59523470519648
Validation loss: 3.57087515353497

Epoch: 6| Step: 6
Training loss: 2.782507280064302
Validation loss: 3.571472607061328

Epoch: 6| Step: 7
Training loss: 3.1693014594264546
Validation loss: 3.5690861090064443

Epoch: 6| Step: 8
Training loss: 4.035711850287357
Validation loss: 3.5697026679187394

Epoch: 6| Step: 9
Training loss: 3.6485934173138177
Validation loss: 3.5682294203511535

Epoch: 6| Step: 10
Training loss: 3.7985635150451325
Validation loss: 3.5678848231331273

Epoch: 6| Step: 11
Training loss: 3.5611406376316017
Validation loss: 3.56745941944102

Epoch: 6| Step: 12
Training loss: 4.255929288950749
Validation loss: 3.565810504190488

Epoch: 6| Step: 13
Training loss: 2.7936361302461266
Validation loss: 3.565332519727229

Epoch: 26| Step: 0
Training loss: 4.751710282661556
Validation loss: 3.562736378174808

Epoch: 6| Step: 1
Training loss: 3.4884477428247287
Validation loss: 3.564158530137256

Epoch: 6| Step: 2
Training loss: 3.802479065806732
Validation loss: 3.562104814015957

Epoch: 6| Step: 3
Training loss: 3.69952655546884
Validation loss: 3.5607378519310906

Epoch: 6| Step: 4
Training loss: 3.591082304276646
Validation loss: 3.5603845904137548

Epoch: 6| Step: 5
Training loss: 3.2827072540653934
Validation loss: 3.561181278245757

Epoch: 6| Step: 6
Training loss: 2.9757277552252277
Validation loss: 3.559693261866928

Epoch: 6| Step: 7
Training loss: 3.8942953055487264
Validation loss: 3.5592299923532775

Epoch: 6| Step: 8
Training loss: 3.4632276961585204
Validation loss: 3.557184677930585

Epoch: 6| Step: 9
Training loss: 3.4164689789933447
Validation loss: 3.5574439856084767

Epoch: 6| Step: 10
Training loss: 4.225008694792158
Validation loss: 3.555351948697938

Epoch: 6| Step: 11
Training loss: 4.116978330564884
Validation loss: 3.554140231503491

Epoch: 6| Step: 12
Training loss: 3.347601552937052
Validation loss: 3.554229939827102

Epoch: 6| Step: 13
Training loss: 4.6300357518968225
Validation loss: 3.5525162700973194

Epoch: 27| Step: 0
Training loss: 4.358799612705395
Validation loss: 3.553265932478156

Epoch: 6| Step: 1
Training loss: 3.5052752930063487
Validation loss: 3.552787843453963

Epoch: 6| Step: 2
Training loss: 3.4281260905094553
Validation loss: 3.5499706967877724

Epoch: 6| Step: 3
Training loss: 3.677366784313149
Validation loss: 3.5503737855282873

Epoch: 6| Step: 4
Training loss: 2.6052647729551266
Validation loss: 3.5471689097862047

Epoch: 6| Step: 5
Training loss: 4.308821726601236
Validation loss: 3.5444979001993646

Epoch: 6| Step: 6
Training loss: 3.767875030826368
Validation loss: 3.540561488147523

Epoch: 6| Step: 7
Training loss: 3.634816263164862
Validation loss: 3.5398302479431587

Epoch: 6| Step: 8
Training loss: 3.9111804821143035
Validation loss: 3.536155139044833

Epoch: 6| Step: 9
Training loss: 3.645076273472026
Validation loss: 3.532180831878833

Epoch: 6| Step: 10
Training loss: 3.297617751789019
Validation loss: 3.52751797051068

Epoch: 6| Step: 11
Training loss: 4.465019536333393
Validation loss: 3.5238091177545594

Epoch: 6| Step: 12
Training loss: 4.036553258292432
Validation loss: 3.5219056557784807

Epoch: 6| Step: 13
Training loss: 3.115604467142566
Validation loss: 3.521810332107646

Epoch: 28| Step: 0
Training loss: 4.23641096766625
Validation loss: 3.5256862283406694

Epoch: 6| Step: 1
Training loss: 3.268942867737853
Validation loss: 3.5246119345306077

Epoch: 6| Step: 2
Training loss: 2.561469638505281
Validation loss: 3.5332492719306687

Epoch: 6| Step: 3
Training loss: 3.608417334397407
Validation loss: 3.526545236424877

Epoch: 6| Step: 4
Training loss: 4.455623742139652
Validation loss: 3.5247424296078074

Epoch: 6| Step: 5
Training loss: 2.9807344770653614
Validation loss: 3.519057911449967

Epoch: 6| Step: 6
Training loss: 3.23778586285461
Validation loss: 3.5186541175211743

Epoch: 6| Step: 7
Training loss: 4.211177557222805
Validation loss: 3.5195386068726964

Epoch: 6| Step: 8
Training loss: 4.002766844356328
Validation loss: 3.521240817088353

Epoch: 6| Step: 9
Training loss: 4.3939977974831885
Validation loss: 3.520735634758121

Epoch: 6| Step: 10
Training loss: 4.015326225357651
Validation loss: 3.521205036143693

Epoch: 6| Step: 11
Training loss: 3.9519771070319214
Validation loss: 3.5187832773442973

Epoch: 6| Step: 12
Training loss: 3.313939483532054
Validation loss: 3.512995698573271

Epoch: 6| Step: 13
Training loss: 3.1961995504766727
Validation loss: 3.511929132371577

Epoch: 29| Step: 0
Training loss: 3.4643171699455424
Validation loss: 3.509763183899682

Epoch: 6| Step: 1
Training loss: 3.3843533924712763
Validation loss: 3.5095089481024635

Epoch: 6| Step: 2
Training loss: 4.258615400573863
Validation loss: 3.5076519971223377

Epoch: 6| Step: 3
Training loss: 3.32787569213672
Validation loss: 3.50884687855443

Epoch: 6| Step: 4
Training loss: 3.799617326441253
Validation loss: 3.5087897376057633

Epoch: 6| Step: 5
Training loss: 3.6826524067694026
Validation loss: 3.508278756441428

Epoch: 6| Step: 6
Training loss: 4.430234522069032
Validation loss: 3.509972584981999

Epoch: 6| Step: 7
Training loss: 2.890996795663077
Validation loss: 3.50541537466829

Epoch: 6| Step: 8
Training loss: 2.447655186316548
Validation loss: 3.507839191542684

Epoch: 6| Step: 9
Training loss: 3.8267403725981284
Validation loss: 3.5041090815256286

Epoch: 6| Step: 10
Training loss: 3.626917627804888
Validation loss: 3.502954981820939

Epoch: 6| Step: 11
Training loss: 3.472165462453831
Validation loss: 3.5045608053813306

Epoch: 6| Step: 12
Training loss: 4.388690128466712
Validation loss: 3.5005919692734615

Epoch: 6| Step: 13
Training loss: 4.96237541445912
Validation loss: 3.5014750394615914

Epoch: 30| Step: 0
Training loss: 3.781295902194269
Validation loss: 3.500141259608155

Epoch: 6| Step: 1
Training loss: 3.6759628591560243
Validation loss: 3.4998351064123976

Epoch: 6| Step: 2
Training loss: 3.6476470940614503
Validation loss: 3.4993307086061383

Epoch: 6| Step: 3
Training loss: 3.761541788250645
Validation loss: 3.498708891160904

Epoch: 6| Step: 4
Training loss: 3.0848612393374837
Validation loss: 3.4992998128894555

Epoch: 6| Step: 5
Training loss: 3.767223731064108
Validation loss: 3.4988272001388556

Epoch: 6| Step: 6
Training loss: 3.2828500388757607
Validation loss: 3.4968182579641423

Epoch: 6| Step: 7
Training loss: 4.277218221973691
Validation loss: 3.496521145224983

Epoch: 6| Step: 8
Training loss: 4.338618698749035
Validation loss: 3.4959205638167363

Epoch: 6| Step: 9
Training loss: 4.20888082637997
Validation loss: 3.493501497348904

Epoch: 6| Step: 10
Training loss: 3.3982103293775077
Validation loss: 3.494453903260782

Epoch: 6| Step: 11
Training loss: 3.8690719790966868
Validation loss: 3.4916333400310515

Epoch: 6| Step: 12
Training loss: 2.887123089916349
Validation loss: 3.4932651883498567

Epoch: 6| Step: 13
Training loss: 3.613301309065943
Validation loss: 3.4921838118425472

Epoch: 31| Step: 0
Training loss: 4.029538523185858
Validation loss: 3.4915065490096673

Epoch: 6| Step: 1
Training loss: 3.765747701458184
Validation loss: 3.4910511283001493

Epoch: 6| Step: 2
Training loss: 3.958101660657987
Validation loss: 3.4917722098456765

Epoch: 6| Step: 3
Training loss: 3.0209199739505963
Validation loss: 3.489400447386868

Epoch: 6| Step: 4
Training loss: 3.1324342418445084
Validation loss: 3.4884241085414587

Epoch: 6| Step: 5
Training loss: 3.0723824936548665
Validation loss: 3.4882014107599875

Epoch: 6| Step: 6
Training loss: 4.660959000366833
Validation loss: 3.4873841061982698

Epoch: 6| Step: 7
Training loss: 4.011495998182301
Validation loss: 3.4870649590034613

Epoch: 6| Step: 8
Training loss: 3.214383320613137
Validation loss: 3.4865384777052455

Epoch: 6| Step: 9
Training loss: 4.131761961824481
Validation loss: 3.4853190467481348

Epoch: 6| Step: 10
Training loss: 3.414411374212052
Validation loss: 3.4858261479137993

Epoch: 6| Step: 11
Training loss: 4.003251661430505
Validation loss: 3.485660257995697

Epoch: 6| Step: 12
Training loss: 3.865326157955244
Validation loss: 3.4841426810727496

Epoch: 6| Step: 13
Training loss: 2.5882911688847448
Validation loss: 3.4834489754813864

Epoch: 32| Step: 0
Training loss: 3.3897819349882172
Validation loss: 3.485293608253091

Epoch: 6| Step: 1
Training loss: 4.132902494146583
Validation loss: 3.4839567300080305

Epoch: 6| Step: 2
Training loss: 3.998193094312627
Validation loss: 3.482562072050899

Epoch: 6| Step: 3
Training loss: 2.7868037975221345
Validation loss: 3.4820134364489896

Epoch: 6| Step: 4
Training loss: 2.6674337674528226
Validation loss: 3.4824762448528013

Epoch: 6| Step: 5
Training loss: 4.70949267852308
Validation loss: 3.479990839382133

Epoch: 6| Step: 6
Training loss: 2.8408177947200084
Validation loss: 3.4810374383816014

Epoch: 6| Step: 7
Training loss: 4.437219960147507
Validation loss: 3.480335416311849

Epoch: 6| Step: 8
Training loss: 4.136080338706842
Validation loss: 3.4811051212326625

Epoch: 6| Step: 9
Training loss: 3.483901466386533
Validation loss: 3.480629952501554

Epoch: 6| Step: 10
Training loss: 3.663788417170934
Validation loss: 3.481798597270479

Epoch: 6| Step: 11
Training loss: 4.142343071110168
Validation loss: 3.4783340031465535

Epoch: 6| Step: 12
Training loss: 3.2329711816118643
Validation loss: 3.4772642693138796

Epoch: 6| Step: 13
Training loss: 3.222274776190939
Validation loss: 3.4783177810523225

Epoch: 33| Step: 0
Training loss: 3.7501031225648456
Validation loss: 3.4783354609939336

Epoch: 6| Step: 1
Training loss: 3.551964154672609
Validation loss: 3.4784185867651574

Epoch: 6| Step: 2
Training loss: 3.8379141071562155
Validation loss: 3.478333698015629

Epoch: 6| Step: 3
Training loss: 3.511281224916925
Validation loss: 3.4777390840817493

Epoch: 6| Step: 4
Training loss: 3.593826160453176
Validation loss: 3.4761927917943463

Epoch: 6| Step: 5
Training loss: 3.5897900864800207
Validation loss: 3.4767261399787226

Epoch: 6| Step: 6
Training loss: 3.5211362238206094
Validation loss: 3.474876252405021

Epoch: 6| Step: 7
Training loss: 2.884099740132986
Validation loss: 3.4752779877402413

Epoch: 6| Step: 8
Training loss: 3.803947235720227
Validation loss: 3.475634334964061

Epoch: 6| Step: 9
Training loss: 2.941365721728592
Validation loss: 3.4745723066626253

Epoch: 6| Step: 10
Training loss: 4.8885468281425295
Validation loss: 3.4743432533426106

Epoch: 6| Step: 11
Training loss: 3.103008557734735
Validation loss: 3.474260347359252

Epoch: 6| Step: 12
Training loss: 4.62809484911157
Validation loss: 3.4737293792582413

Epoch: 6| Step: 13
Training loss: 3.4721686210733638
Validation loss: 3.47349050437115

Epoch: 34| Step: 0
Training loss: 1.8949321519285585
Validation loss: 3.472705938848242

Epoch: 6| Step: 1
Training loss: 3.8795918975616464
Validation loss: 3.47184882395176

Epoch: 6| Step: 2
Training loss: 3.962935867164123
Validation loss: 3.4721703975187106

Epoch: 6| Step: 3
Training loss: 3.4849400083613262
Validation loss: 3.470676834071776

Epoch: 6| Step: 4
Training loss: 3.6202708999686966
Validation loss: 3.470862546004386

Epoch: 6| Step: 5
Training loss: 3.80394096805244
Validation loss: 3.4716140879561586

Epoch: 6| Step: 6
Training loss: 4.760345436192105
Validation loss: 3.470032716878021

Epoch: 6| Step: 7
Training loss: 2.6552723600126535
Validation loss: 3.4692517462481924

Epoch: 6| Step: 8
Training loss: 3.7695069623569886
Validation loss: 3.4684142889171663

Epoch: 6| Step: 9
Training loss: 3.8141570945676864
Validation loss: 3.468379728078675

Epoch: 6| Step: 10
Training loss: 3.3042831714642253
Validation loss: 3.4675588265162003

Epoch: 6| Step: 11
Training loss: 3.6144022754244927
Validation loss: 3.468637015422274

Epoch: 6| Step: 12
Training loss: 4.140904140060232
Validation loss: 3.466639979577658

Epoch: 6| Step: 13
Training loss: 4.396541207012728
Validation loss: 3.468568220089787

Epoch: 35| Step: 0
Training loss: 3.2311154955496493
Validation loss: 3.4664776006754745

Epoch: 6| Step: 1
Training loss: 3.1462090038467294
Validation loss: 3.4682910042363835

Epoch: 6| Step: 2
Training loss: 2.8795518086630105
Validation loss: 3.4678733329079585

Epoch: 6| Step: 3
Training loss: 3.0503059046193006
Validation loss: 3.467239890752951

Epoch: 6| Step: 4
Training loss: 4.371595529454267
Validation loss: 3.4654113494774217

Epoch: 6| Step: 5
Training loss: 3.945057352710391
Validation loss: 3.4651992822060707

Epoch: 6| Step: 6
Training loss: 4.198409714942252
Validation loss: 3.464605081600085

Epoch: 6| Step: 7
Training loss: 4.303025161814986
Validation loss: 3.4642393048754814

Epoch: 6| Step: 8
Training loss: 3.130628780789947
Validation loss: 3.464067143003784

Epoch: 6| Step: 9
Training loss: 2.946204093539858
Validation loss: 3.4635140233398185

Epoch: 6| Step: 10
Training loss: 3.8151974750170488
Validation loss: 3.4621686300115475

Epoch: 6| Step: 11
Training loss: 4.435086305761229
Validation loss: 3.4629557220400047

Epoch: 6| Step: 12
Training loss: 3.432836802851928
Validation loss: 3.46326991139343

Epoch: 6| Step: 13
Training loss: 4.412692075012368
Validation loss: 3.46225162413566

Epoch: 36| Step: 0
Training loss: 4.010687378833262
Validation loss: 3.461544478358363

Epoch: 6| Step: 1
Training loss: 4.320120450212667
Validation loss: 3.4604518113200613

Epoch: 6| Step: 2
Training loss: 4.134342134075481
Validation loss: 3.462768585851364

Epoch: 6| Step: 3
Training loss: 4.2089245572895555
Validation loss: 3.4613863509204266

Epoch: 6| Step: 4
Training loss: 3.3920813741999667
Validation loss: 3.460233748608338

Epoch: 6| Step: 5
Training loss: 2.748091121878594
Validation loss: 3.4602467955958423

Epoch: 6| Step: 6
Training loss: 3.6685490255855924
Validation loss: 3.4596636709470787

Epoch: 6| Step: 7
Training loss: 3.559496098334715
Validation loss: 3.4589800896440313

Epoch: 6| Step: 8
Training loss: 3.3576898650952822
Validation loss: 3.4598139353418125

Epoch: 6| Step: 9
Training loss: 3.6651065859837
Validation loss: 3.4581527252618036

Epoch: 6| Step: 10
Training loss: 4.0644948903128055
Validation loss: 3.4584268176039092

Epoch: 6| Step: 11
Training loss: 3.3769412638961738
Validation loss: 3.458258996592789

Epoch: 6| Step: 12
Training loss: 3.083016937793353
Validation loss: 3.456514607993171

Epoch: 6| Step: 13
Training loss: 3.4909354403975215
Validation loss: 3.4564291264033082

Epoch: 37| Step: 0
Training loss: 3.450049502252564
Validation loss: 3.4561292150604817

Epoch: 6| Step: 1
Training loss: 4.125760095098197
Validation loss: 3.4561682792270747

Epoch: 6| Step: 2
Training loss: 3.367645161763168
Validation loss: 3.455419322119005

Epoch: 6| Step: 3
Training loss: 4.167789816478957
Validation loss: 3.4551490794909125

Epoch: 6| Step: 4
Training loss: 3.4770809172813717
Validation loss: 3.453524400372328

Epoch: 6| Step: 5
Training loss: 4.025620188823467
Validation loss: 3.455002439493974

Epoch: 6| Step: 6
Training loss: 3.2308287414198045
Validation loss: 3.453457611179922

Epoch: 6| Step: 7
Training loss: 3.216620175778391
Validation loss: 3.4540860400552327

Epoch: 6| Step: 8
Training loss: 3.742621219483652
Validation loss: 3.4530324615876777

Epoch: 6| Step: 9
Training loss: 3.3235621448237387
Validation loss: 3.4530121367186335

Epoch: 6| Step: 10
Training loss: 3.6253753993895614
Validation loss: 3.452178069467299

Epoch: 6| Step: 11
Training loss: 4.126195329814171
Validation loss: 3.45171794697015

Epoch: 6| Step: 12
Training loss: 3.773185263470468
Validation loss: 3.4519097075315974

Epoch: 6| Step: 13
Training loss: 3.5416281454945935
Validation loss: 3.451161429281711

Epoch: 38| Step: 0
Training loss: 3.5487492520558965
Validation loss: 3.4502228539914004

Epoch: 6| Step: 1
Training loss: 3.235483467966476
Validation loss: 3.450720961423155

Epoch: 6| Step: 2
Training loss: 3.7776114872878552
Validation loss: 3.450553302051032

Epoch: 6| Step: 3
Training loss: 4.0418750407719
Validation loss: 3.4494698858945028

Epoch: 6| Step: 4
Training loss: 4.881653964120669
Validation loss: 3.4493878239195164

Epoch: 6| Step: 5
Training loss: 3.318359231303337
Validation loss: 3.447870006170579

Epoch: 6| Step: 6
Training loss: 2.7783045226923897
Validation loss: 3.448467415247672

Epoch: 6| Step: 7
Training loss: 3.5784493511730933
Validation loss: 3.4486252310980356

Epoch: 6| Step: 8
Training loss: 3.3096120949339523
Validation loss: 3.4475520880892767

Epoch: 6| Step: 9
Training loss: 4.066507094540863
Validation loss: 3.447558793230937

Epoch: 6| Step: 10
Training loss: 3.4144569012034376
Validation loss: 3.4468536750849963

Epoch: 6| Step: 11
Training loss: 3.9198704190148526
Validation loss: 3.446502346895594

Epoch: 6| Step: 12
Training loss: 2.934237352419199
Validation loss: 3.445362428428907

Epoch: 6| Step: 13
Training loss: 4.352555605091124
Validation loss: 3.4452046759359534

Epoch: 39| Step: 0
Training loss: 3.4893336572099107
Validation loss: 3.4448085648245614

Epoch: 6| Step: 1
Training loss: 4.473903218981987
Validation loss: 3.444645176150451

Epoch: 6| Step: 2
Training loss: 2.981622994879425
Validation loss: 3.4448402737266424

Epoch: 6| Step: 3
Training loss: 3.811237188601082
Validation loss: 3.443139276738625

Epoch: 6| Step: 4
Training loss: 4.076161814568922
Validation loss: 3.444176081378139

Epoch: 6| Step: 5
Training loss: 3.6361882102439886
Validation loss: 3.4431250674328413

Epoch: 6| Step: 6
Training loss: 3.771508397046102
Validation loss: 3.442821301573994

Epoch: 6| Step: 7
Training loss: 3.928747713171463
Validation loss: 3.4426315979434596

Epoch: 6| Step: 8
Training loss: 3.0380534480242045
Validation loss: 3.441132282997555

Epoch: 6| Step: 9
Training loss: 4.012014465427659
Validation loss: 3.4430358640564602

Epoch: 6| Step: 10
Training loss: 3.2008334266631464
Validation loss: 3.4475916093461128

Epoch: 6| Step: 11
Training loss: 3.7008477142015637
Validation loss: 3.4572413260242145

Epoch: 6| Step: 12
Training loss: 3.782518410546477
Validation loss: 3.4574998648634

Epoch: 6| Step: 13
Training loss: 2.7043426064582623
Validation loss: 3.4521872556077096

Epoch: 40| Step: 0
Training loss: 3.734670970472557
Validation loss: 3.4494231450847863

Epoch: 6| Step: 1
Training loss: 3.3207184666798737
Validation loss: 3.445577793967842

Epoch: 6| Step: 2
Training loss: 3.6095274525602563
Validation loss: 3.445661792596301

Epoch: 6| Step: 3
Training loss: 3.3055288988707288
Validation loss: 3.4442872520865717

Epoch: 6| Step: 4
Training loss: 3.2857603046203696
Validation loss: 3.445637807546176

Epoch: 6| Step: 5
Training loss: 4.087347950571735
Validation loss: 3.444854959683738

Epoch: 6| Step: 6
Training loss: 3.519577043004672
Validation loss: 3.4444101425414138

Epoch: 6| Step: 7
Training loss: 5.114641840561914
Validation loss: 3.4448463032074312

Epoch: 6| Step: 8
Training loss: 3.6078413970834124
Validation loss: 3.444314033987139

Epoch: 6| Step: 9
Training loss: 3.1026886017530413
Validation loss: 3.4439571020195836

Epoch: 6| Step: 10
Training loss: 3.3371998455506175
Validation loss: 3.44302608016598

Epoch: 6| Step: 11
Training loss: 3.8913808800743976
Validation loss: 3.442586004933344

Epoch: 6| Step: 12
Training loss: 3.503815886864344
Validation loss: 3.44194482916116

Epoch: 6| Step: 13
Training loss: 3.3596611433367616
Validation loss: 3.441638845136463

Epoch: 41| Step: 0
Training loss: 4.314753068243534
Validation loss: 3.440807011424352

Epoch: 6| Step: 1
Training loss: 4.129465633671956
Validation loss: 3.4402616994715296

Epoch: 6| Step: 2
Training loss: 2.6958665361280842
Validation loss: 3.4399899053747443

Epoch: 6| Step: 3
Training loss: 3.6856290305744532
Validation loss: 3.4393627440929326

Epoch: 6| Step: 4
Training loss: 3.884282100729724
Validation loss: 3.4380232292506836

Epoch: 6| Step: 5
Training loss: 2.954783302016823
Validation loss: 3.4380485805433216

Epoch: 6| Step: 6
Training loss: 3.4429375384157956
Validation loss: 3.4366633003827642

Epoch: 6| Step: 7
Training loss: 3.5806870262671833
Validation loss: 3.437183704908101

Epoch: 6| Step: 8
Training loss: 3.1780221688017702
Validation loss: 3.437108254880397

Epoch: 6| Step: 9
Training loss: 3.3776671149575015
Validation loss: 3.4359978609045596

Epoch: 6| Step: 10
Training loss: 4.42851379023017
Validation loss: 3.4355274570594005

Epoch: 6| Step: 11
Training loss: 4.140823071618639
Validation loss: 3.4354854770099914

Epoch: 6| Step: 12
Training loss: 3.1760650170154845
Validation loss: 3.4344932912820076

Epoch: 6| Step: 13
Training loss: 3.866980591450301
Validation loss: 3.4344508484833565

Epoch: 42| Step: 0
Training loss: 3.2436373123263973
Validation loss: 3.4333504295182324

Epoch: 6| Step: 1
Training loss: 3.911729311371677
Validation loss: 3.4334587916115678

Epoch: 6| Step: 2
Training loss: 3.0472803090796377
Validation loss: 3.4333604022650586

Epoch: 6| Step: 3
Training loss: 3.4222208484079926
Validation loss: 3.432798469422143

Epoch: 6| Step: 4
Training loss: 3.4239243593417266
Validation loss: 3.433193301917289

Epoch: 6| Step: 5
Training loss: 4.453923311118875
Validation loss: 3.4321684217290764

Epoch: 6| Step: 6
Training loss: 3.0679918211090604
Validation loss: 3.433651637602534

Epoch: 6| Step: 7
Training loss: 3.678052923878618
Validation loss: 3.430941928980045

Epoch: 6| Step: 8
Training loss: 3.525271054932115
Validation loss: 3.4308069656594533

Epoch: 6| Step: 9
Training loss: 3.8143014872813166
Validation loss: 3.4300945854306124

Epoch: 6| Step: 10
Training loss: 4.025636534974159
Validation loss: 3.4307209967132333

Epoch: 6| Step: 11
Training loss: 3.7998137227629663
Validation loss: 3.4304223023864657

Epoch: 6| Step: 12
Training loss: 3.6564260587118604
Validation loss: 3.430136872115665

Epoch: 6| Step: 13
Training loss: 4.007566924128303
Validation loss: 3.430246005363638

Epoch: 43| Step: 0
Training loss: 3.4275332139156753
Validation loss: 3.4297061497049515

Epoch: 6| Step: 1
Training loss: 4.31267580420359
Validation loss: 3.4286792723394677

Epoch: 6| Step: 2
Training loss: 4.329826598891097
Validation loss: 3.4287718653810053

Epoch: 6| Step: 3
Training loss: 4.0644535942755615
Validation loss: 3.4281834901348085

Epoch: 6| Step: 4
Training loss: 3.86691523662798
Validation loss: 3.42782715810126

Epoch: 6| Step: 5
Training loss: 3.578954475575881
Validation loss: 3.4273218540122494

Epoch: 6| Step: 6
Training loss: 3.9350796481339745
Validation loss: 3.427557737776773

Epoch: 6| Step: 7
Training loss: 3.6387079127559865
Validation loss: 3.427104888667697

Epoch: 6| Step: 8
Training loss: 3.8714213920691587
Validation loss: 3.426367826051895

Epoch: 6| Step: 9
Training loss: 3.9091590730236505
Validation loss: 3.4256307081239745

Epoch: 6| Step: 10
Training loss: 2.633210104058907
Validation loss: 3.4256221871679617

Epoch: 6| Step: 11
Training loss: 2.1004988804382667
Validation loss: 3.4255912343512387

Epoch: 6| Step: 12
Training loss: 2.9887575256176326
Validation loss: 3.4246540083744126

Epoch: 6| Step: 13
Training loss: 3.850161284003801
Validation loss: 3.4245584128842985

Epoch: 44| Step: 0
Training loss: 3.821963587285549
Validation loss: 3.4240595602562003

Epoch: 6| Step: 1
Training loss: 2.8793997891491125
Validation loss: 3.423893645751269

Epoch: 6| Step: 2
Training loss: 3.927311871234006
Validation loss: 3.4237311736119187

Epoch: 6| Step: 3
Training loss: 3.4376589651631533
Validation loss: 3.4236868766662374

Epoch: 6| Step: 4
Training loss: 3.330843249711759
Validation loss: 3.4238309972590604

Epoch: 6| Step: 5
Training loss: 4.100349290437202
Validation loss: 3.4230641585556696

Epoch: 6| Step: 6
Training loss: 3.3809386386758353
Validation loss: 3.4224910289271975

Epoch: 6| Step: 7
Training loss: 3.7664738248449554
Validation loss: 3.422103082338899

Epoch: 6| Step: 8
Training loss: 3.991112013622976
Validation loss: 3.4207581189049137

Epoch: 6| Step: 9
Training loss: 4.148513821979185
Validation loss: 3.4217856217513

Epoch: 6| Step: 10
Training loss: 3.100941478138903
Validation loss: 3.4213149887570626

Epoch: 6| Step: 11
Training loss: 3.811955897793629
Validation loss: 3.4208349907300377

Epoch: 6| Step: 12
Training loss: 3.1307221475989064
Validation loss: 3.4206814162276094

Epoch: 6| Step: 13
Training loss: 4.183107948057585
Validation loss: 3.420495872813921

Epoch: 45| Step: 0
Training loss: 3.352617146765805
Validation loss: 3.4209588038411343

Epoch: 6| Step: 1
Training loss: 3.517008327019807
Validation loss: 3.42004418225412

Epoch: 6| Step: 2
Training loss: 3.2317573901605643
Validation loss: 3.4196084071776474

Epoch: 6| Step: 3
Training loss: 4.510692608551141
Validation loss: 3.419453641008105

Epoch: 6| Step: 4
Training loss: 3.404169409636782
Validation loss: 3.4196139443714277

Epoch: 6| Step: 5
Training loss: 3.3272600796227474
Validation loss: 3.419938368091747

Epoch: 6| Step: 6
Training loss: 3.5958654397096184
Validation loss: 3.4187427794005725

Epoch: 6| Step: 7
Training loss: 4.804536646513929
Validation loss: 3.4193574217943095

Epoch: 6| Step: 8
Training loss: 3.4334561230328116
Validation loss: 3.418636886712011

Epoch: 6| Step: 9
Training loss: 2.733789871825093
Validation loss: 3.418658196594077

Epoch: 6| Step: 10
Training loss: 4.193674119242958
Validation loss: 3.418433454152695

Epoch: 6| Step: 11
Training loss: 4.258273430469511
Validation loss: 3.41764608061952

Epoch: 6| Step: 12
Training loss: 2.6419640029776685
Validation loss: 3.4170650131910643

Epoch: 6| Step: 13
Training loss: 3.045481827922962
Validation loss: 3.4182126531580046

Epoch: 46| Step: 0
Training loss: 3.4641398819129634
Validation loss: 3.4165260732213323

Epoch: 6| Step: 1
Training loss: 3.780101507125808
Validation loss: 3.4163243722317493

Epoch: 6| Step: 2
Training loss: 3.5397746399089836
Validation loss: 3.4159213037676968

Epoch: 6| Step: 3
Training loss: 3.826418126327837
Validation loss: 3.4157045471885716

Epoch: 6| Step: 4
Training loss: 4.0246248437657695
Validation loss: 3.4159250637584497

Epoch: 6| Step: 5
Training loss: 4.2608105664708456
Validation loss: 3.414909133354447

Epoch: 6| Step: 6
Training loss: 3.5811416369915245
Validation loss: 3.4145157003711724

Epoch: 6| Step: 7
Training loss: 3.2528326454678522
Validation loss: 3.414544275947584

Epoch: 6| Step: 8
Training loss: 3.1482827122504236
Validation loss: 3.414099599069237

Epoch: 6| Step: 9
Training loss: 3.0631530999539223
Validation loss: 3.414495715344854

Epoch: 6| Step: 10
Training loss: 4.3022387509602105
Validation loss: 3.4134008045557613

Epoch: 6| Step: 11
Training loss: 3.285349873065599
Validation loss: 3.4130945318160406

Epoch: 6| Step: 12
Training loss: 3.9769366075251233
Validation loss: 3.4128575695367886

Epoch: 6| Step: 13
Training loss: 2.7501442611309046
Validation loss: 3.412458536036724

Epoch: 47| Step: 0
Training loss: 3.73631510754724
Validation loss: 3.4126104041983054

Epoch: 6| Step: 1
Training loss: 2.6271078638499032
Validation loss: 3.4126369208600003

Epoch: 6| Step: 2
Training loss: 3.5253729061621892
Validation loss: 3.4126096800166548

Epoch: 6| Step: 3
Training loss: 3.974495880980954
Validation loss: 3.4114174220489146

Epoch: 6| Step: 4
Training loss: 2.849662084791381
Validation loss: 3.4113806710620245

Epoch: 6| Step: 5
Training loss: 3.7552737981175386
Validation loss: 3.411462844711636

Epoch: 6| Step: 6
Training loss: 3.533605279593726
Validation loss: 3.410813469499668

Epoch: 6| Step: 7
Training loss: 3.8567477407371555
Validation loss: 3.4111797766052705

Epoch: 6| Step: 8
Training loss: 4.193209726748711
Validation loss: 3.4105312419999687

Epoch: 6| Step: 9
Training loss: 3.9167478566513583
Validation loss: 3.4105848471478337

Epoch: 6| Step: 10
Training loss: 3.1622814298948647
Validation loss: 3.4096671503350717

Epoch: 6| Step: 11
Training loss: 4.275865273161505
Validation loss: 3.4098422167321636

Epoch: 6| Step: 12
Training loss: 3.8144713761244113
Validation loss: 3.409060646723287

Epoch: 6| Step: 13
Training loss: 3.0259614409658155
Validation loss: 3.4092928543512064

Epoch: 48| Step: 0
Training loss: 3.173892577470566
Validation loss: 3.4086784834495854

Epoch: 6| Step: 1
Training loss: 4.076638838848998
Validation loss: 3.4084787549912883

Epoch: 6| Step: 2
Training loss: 3.6358307144490185
Validation loss: 3.408231979160063

Epoch: 6| Step: 3
Training loss: 3.7872506440419147
Validation loss: 3.4086872092125833

Epoch: 6| Step: 4
Training loss: 3.0131400350446
Validation loss: 3.4073601191610816

Epoch: 6| Step: 5
Training loss: 3.4851538638679904
Validation loss: 3.40662543403003

Epoch: 6| Step: 6
Training loss: 4.029295928259705
Validation loss: 3.4068051213526873

Epoch: 6| Step: 7
Training loss: 3.938624993328729
Validation loss: 3.406908161167045

Epoch: 6| Step: 8
Training loss: 3.647268757487342
Validation loss: 3.4067446110708994

Epoch: 6| Step: 9
Training loss: 3.3048046623365157
Validation loss: 3.4065283527723302

Epoch: 6| Step: 10
Training loss: 3.457577695601093
Validation loss: 3.4061155779076255

Epoch: 6| Step: 11
Training loss: 3.926596182129587
Validation loss: 3.405686418313443

Epoch: 6| Step: 12
Training loss: 3.751370751669247
Validation loss: 3.405525478932441

Epoch: 6| Step: 13
Training loss: 3.361246696518778
Validation loss: 3.4049828272066893

Epoch: 49| Step: 0
Training loss: 4.006336914643202
Validation loss: 3.40420495070716

Epoch: 6| Step: 1
Training loss: 4.178309817852186
Validation loss: 3.4043239730119725

Epoch: 6| Step: 2
Training loss: 3.8259622497929615
Validation loss: 3.4045359843159515

Epoch: 6| Step: 3
Training loss: 3.8022752826609327
Validation loss: 3.404250739204587

Epoch: 6| Step: 4
Training loss: 2.951732650384052
Validation loss: 3.4038420745510996

Epoch: 6| Step: 5
Training loss: 3.422134459252317
Validation loss: 3.403480476370797

Epoch: 6| Step: 6
Training loss: 3.7875533097043714
Validation loss: 3.4032416017460605

Epoch: 6| Step: 7
Training loss: 3.4458951219571845
Validation loss: 3.4028251871223554

Epoch: 6| Step: 8
Training loss: 3.450525332273993
Validation loss: 3.402624232064928

Epoch: 6| Step: 9
Training loss: 3.421417345073518
Validation loss: 3.4023829479631393

Epoch: 6| Step: 10
Training loss: 3.12346367264469
Validation loss: 3.402298057905537

Epoch: 6| Step: 11
Training loss: 3.642089811018987
Validation loss: 3.4022618925996726

Epoch: 6| Step: 12
Training loss: 3.8909127615406547
Validation loss: 3.4010846660840386

Epoch: 6| Step: 13
Training loss: 3.751542981918003
Validation loss: 3.401841605860223

Epoch: 50| Step: 0
Training loss: 4.494048951965923
Validation loss: 3.400054998574303

Epoch: 6| Step: 1
Training loss: 3.3709582393280915
Validation loss: 3.4007226917853637

Epoch: 6| Step: 2
Training loss: 3.2111477748210655
Validation loss: 3.400641170791445

Epoch: 6| Step: 3
Training loss: 3.208724175629017
Validation loss: 3.400070669669094

Epoch: 6| Step: 4
Training loss: 2.835187828663863
Validation loss: 3.3991162719961805

Epoch: 6| Step: 5
Training loss: 3.9244206286416103
Validation loss: 3.399699328843142

Epoch: 6| Step: 6
Training loss: 3.5659398654525063
Validation loss: 3.3995710018432472

Epoch: 6| Step: 7
Training loss: 2.9380940587391082
Validation loss: 3.3988230941835567

Epoch: 6| Step: 8
Training loss: 3.909633544373941
Validation loss: 3.398095550891431

Epoch: 6| Step: 9
Training loss: 3.8265723991966945
Validation loss: 3.3979318157918206

Epoch: 6| Step: 10
Training loss: 3.797017287111752
Validation loss: 3.398099670855927

Epoch: 6| Step: 11
Training loss: 3.8515560622093763
Validation loss: 3.397220082059409

Epoch: 6| Step: 12
Training loss: 3.4495709802104035
Validation loss: 3.398038532514238

Epoch: 6| Step: 13
Training loss: 4.3435741361516
Validation loss: 3.3969792804816366

Epoch: 51| Step: 0
Training loss: 3.855381555933666
Validation loss: 3.396818337618509

Epoch: 6| Step: 1
Training loss: 3.3712714050088683
Validation loss: 3.3980089459842797

Epoch: 6| Step: 2
Training loss: 3.6657791508541417
Validation loss: 3.395926015195448

Epoch: 6| Step: 3
Training loss: 4.136191935219591
Validation loss: 3.39589531562165

Epoch: 6| Step: 4
Training loss: 3.4488142214827633
Validation loss: 3.3963574074855525

Epoch: 6| Step: 5
Training loss: 3.2886916289012085
Validation loss: 3.3960844050653964

Epoch: 6| Step: 6
Training loss: 3.5209129068686016
Validation loss: 3.3961997867131815

Epoch: 6| Step: 7
Training loss: 3.4684329876078572
Validation loss: 3.395521675956028

Epoch: 6| Step: 8
Training loss: 2.945623002014195
Validation loss: 3.3948734456058545

Epoch: 6| Step: 9
Training loss: 3.816389632408486
Validation loss: 3.3939741928811693

Epoch: 6| Step: 10
Training loss: 3.484116891102286
Validation loss: 3.394228245566124

Epoch: 6| Step: 11
Training loss: 3.637496586434247
Validation loss: 3.394467295290083

Epoch: 6| Step: 12
Training loss: 4.362458919124044
Validation loss: 3.3934116411576944

Epoch: 6| Step: 13
Training loss: 3.4769573544642713
Validation loss: 3.393946259898937

Epoch: 52| Step: 0
Training loss: 3.33059901305555
Validation loss: 3.3942908890823578

Epoch: 6| Step: 1
Training loss: 4.373075007237001
Validation loss: 3.3927015812163632

Epoch: 6| Step: 2
Training loss: 3.611474949692419
Validation loss: 3.3932413843538876

Epoch: 6| Step: 3
Training loss: 3.8909429090905148
Validation loss: 3.392234260437556

Epoch: 6| Step: 4
Training loss: 3.915973615539944
Validation loss: 3.393122076052858

Epoch: 6| Step: 5
Training loss: 3.660993710264228
Validation loss: 3.3927131393741985

Epoch: 6| Step: 6
Training loss: 3.7632785942031837
Validation loss: 3.390524316658259

Epoch: 6| Step: 7
Training loss: 3.3862616946672195
Validation loss: 3.391746068382159

Epoch: 6| Step: 8
Training loss: 3.5193670405990733
Validation loss: 3.391889174385354

Epoch: 6| Step: 9
Training loss: 3.5580620143347086
Validation loss: 3.392403639786634

Epoch: 6| Step: 10
Training loss: 3.481747718720994
Validation loss: 3.3913323485080165

Epoch: 6| Step: 11
Training loss: 3.0634488562661684
Validation loss: 3.3907047430771806

Epoch: 6| Step: 12
Training loss: 3.5230007535320236
Validation loss: 3.3895517730640297

Epoch: 6| Step: 13
Training loss: 3.3531783328121136
Validation loss: 3.3897180419315296

Epoch: 53| Step: 0
Training loss: 4.111157860934013
Validation loss: 3.3897024681851047

Epoch: 6| Step: 1
Training loss: 3.855115385394397
Validation loss: 3.3888152742271886

Epoch: 6| Step: 2
Training loss: 4.113707372722162
Validation loss: 3.3893328732295243

Epoch: 6| Step: 3
Training loss: 3.376806835141073
Validation loss: 3.388531284123383

Epoch: 6| Step: 4
Training loss: 4.130058192842993
Validation loss: 3.388420003843148

Epoch: 6| Step: 5
Training loss: 3.644773550861637
Validation loss: 3.3883995153564137

Epoch: 6| Step: 6
Training loss: 3.685619974144246
Validation loss: 3.3877135849519573

Epoch: 6| Step: 7
Training loss: 4.022165634455052
Validation loss: 3.3881586952318985

Epoch: 6| Step: 8
Training loss: 2.9062189900374333
Validation loss: 3.3872359745781164

Epoch: 6| Step: 9
Training loss: 3.403437862254365
Validation loss: 3.386259871639684

Epoch: 6| Step: 10
Training loss: 3.186432603622232
Validation loss: 3.387326550539459

Epoch: 6| Step: 11
Training loss: 3.1682328985416865
Validation loss: 3.3861129208847283

Epoch: 6| Step: 12
Training loss: 3.3501575432926094
Validation loss: 3.386389982465925

Epoch: 6| Step: 13
Training loss: 3.2873788905589776
Validation loss: 3.3864360496937587

Epoch: 54| Step: 0
Training loss: 3.751111183839449
Validation loss: 3.3883780007988125

Epoch: 6| Step: 1
Training loss: 3.277359754411906
Validation loss: 3.3853759722791965

Epoch: 6| Step: 2
Training loss: 3.3636220655207687
Validation loss: 3.3869764562997076

Epoch: 6| Step: 3
Training loss: 4.261711589132389
Validation loss: 3.3855090218465866

Epoch: 6| Step: 4
Training loss: 3.5671337843805278
Validation loss: 3.3865073704465156

Epoch: 6| Step: 5
Training loss: 3.4298657347088506
Validation loss: 3.3840020163982016

Epoch: 6| Step: 6
Training loss: 3.844895851103767
Validation loss: 3.3853097529918665

Epoch: 6| Step: 7
Training loss: 3.0329353916872224
Validation loss: 3.3853867307842886

Epoch: 6| Step: 8
Training loss: 3.3511228473108168
Validation loss: 3.384584607781387

Epoch: 6| Step: 9
Training loss: 3.9751328931942247
Validation loss: 3.382781049370991

Epoch: 6| Step: 10
Training loss: 3.421474346238085
Validation loss: 3.3855984051989774

Epoch: 6| Step: 11
Training loss: 3.9501750327816887
Validation loss: 3.385357220729665

Epoch: 6| Step: 12
Training loss: 3.708441543429028
Validation loss: 3.3854677035868117

Epoch: 6| Step: 13
Training loss: 3.4129418949844488
Validation loss: 3.38222071536032

Epoch: 55| Step: 0
Training loss: 4.174562881337894
Validation loss: 3.382334706899568

Epoch: 6| Step: 1
Training loss: 3.5176764034455914
Validation loss: 3.381791913532524

Epoch: 6| Step: 2
Training loss: 3.208105615898771
Validation loss: 3.381512851289261

Epoch: 6| Step: 3
Training loss: 3.259573261671774
Validation loss: 3.3817016957361083

Epoch: 6| Step: 4
Training loss: 3.639872853919515
Validation loss: 3.381241777112189

Epoch: 6| Step: 5
Training loss: 2.9064198105947257
Validation loss: 3.3815765097049324

Epoch: 6| Step: 6
Training loss: 3.029769221163272
Validation loss: 3.383636699318718

Epoch: 6| Step: 7
Training loss: 3.7519930311679173
Validation loss: 3.3807983495297766

Epoch: 6| Step: 8
Training loss: 3.942110541246805
Validation loss: 3.381488340720834

Epoch: 6| Step: 9
Training loss: 3.9560996462438536
Validation loss: 3.379980021960953

Epoch: 6| Step: 10
Training loss: 3.818914052183404
Validation loss: 3.381707743787812

Epoch: 6| Step: 11
Training loss: 4.050462465608431
Validation loss: 3.3793238952477376

Epoch: 6| Step: 12
Training loss: 3.388599265252348
Validation loss: 3.3804306128340573

Epoch: 6| Step: 13
Training loss: 3.7189627193870765
Validation loss: 3.379830137308348

Epoch: 56| Step: 0
Training loss: 4.125421444720238
Validation loss: 3.3794339495051786

Epoch: 6| Step: 1
Training loss: 4.151135273272462
Validation loss: 3.378886972410668

Epoch: 6| Step: 2
Training loss: 3.657266328847555
Validation loss: 3.378236656555481

Epoch: 6| Step: 3
Training loss: 2.84746870095699
Validation loss: 3.37901662816609

Epoch: 6| Step: 4
Training loss: 3.556612202144804
Validation loss: 3.3779226794553177

Epoch: 6| Step: 5
Training loss: 4.119167944581049
Validation loss: 3.3775276796988893

Epoch: 6| Step: 6
Training loss: 3.4604108767123227
Validation loss: 3.3767257282969734

Epoch: 6| Step: 7
Training loss: 1.9858588730608728
Validation loss: 3.378032854496129

Epoch: 6| Step: 8
Training loss: 2.465079850921109
Validation loss: 3.376919932935268

Epoch: 6| Step: 9
Training loss: 4.67625053938042
Validation loss: 3.3764704315758824

Epoch: 6| Step: 10
Training loss: 3.687269300582686
Validation loss: 3.3761240486135717

Epoch: 6| Step: 11
Training loss: 3.1354054971455865
Validation loss: 3.3764155984279243

Epoch: 6| Step: 12
Training loss: 3.492244847998081
Validation loss: 3.3770823737136384

Epoch: 6| Step: 13
Training loss: 4.6189579030323875
Validation loss: 3.3762603694293065

Epoch: 57| Step: 0
Training loss: 2.887291548169471
Validation loss: 3.3760882498949365

Epoch: 6| Step: 1
Training loss: 3.2247390582360893
Validation loss: 3.3764397434060354

Epoch: 6| Step: 2
Training loss: 4.6380852836344655
Validation loss: 3.374833720071224

Epoch: 6| Step: 3
Training loss: 4.142821452734042
Validation loss: 3.376380297855463

Epoch: 6| Step: 4
Training loss: 3.654713886715347
Validation loss: 3.373906276231012

Epoch: 6| Step: 5
Training loss: 4.145588214215891
Validation loss: 3.3732581480459904

Epoch: 6| Step: 6
Training loss: 2.872449323906029
Validation loss: 3.3740607002434633

Epoch: 6| Step: 7
Training loss: 3.8191536548006355
Validation loss: 3.3726963292119323

Epoch: 6| Step: 8
Training loss: 3.6124889598004555
Validation loss: 3.3719865083106937

Epoch: 6| Step: 9
Training loss: 3.6904334345624665
Validation loss: 3.3723601161623598

Epoch: 6| Step: 10
Training loss: 3.3084366546050386
Validation loss: 3.3742359789962735

Epoch: 6| Step: 11
Training loss: 2.2841368920344363
Validation loss: 3.372722697534876

Epoch: 6| Step: 12
Training loss: 3.619736895615681
Validation loss: 3.3716443880132543

Epoch: 6| Step: 13
Training loss: 4.167931453748899
Validation loss: 3.3720279446222237

Epoch: 58| Step: 0
Training loss: 3.4676899707904263
Validation loss: 3.371960178327195

Epoch: 6| Step: 1
Training loss: 2.6662484874265004
Validation loss: 3.371950215577121

Epoch: 6| Step: 2
Training loss: 3.723854472528211
Validation loss: 3.37451400812668

Epoch: 6| Step: 3
Training loss: 4.032876566304485
Validation loss: 3.3767046298123566

Epoch: 6| Step: 4
Training loss: 3.455327363024949
Validation loss: 3.3710377768771673

Epoch: 6| Step: 5
Training loss: 3.8492444473625933
Validation loss: 3.371348562660336

Epoch: 6| Step: 6
Training loss: 2.855730579651149
Validation loss: 3.371333854585981

Epoch: 6| Step: 7
Training loss: 3.544081339744421
Validation loss: 3.3715063004803607

Epoch: 6| Step: 8
Training loss: 3.7117586211205063
Validation loss: 3.3729083401998934

Epoch: 6| Step: 9
Training loss: 4.3031302125853506
Validation loss: 3.3718362774546633

Epoch: 6| Step: 10
Training loss: 3.778097556797818
Validation loss: 3.3717286979645507

Epoch: 6| Step: 11
Training loss: 3.629687731213671
Validation loss: 3.3717853697580664

Epoch: 6| Step: 12
Training loss: 3.252380966131203
Validation loss: 3.3712623740430074

Epoch: 6| Step: 13
Training loss: 4.076472038765496
Validation loss: 3.369690766600413

Epoch: 59| Step: 0
Training loss: 3.61251535907371
Validation loss: 3.3704947462968375

Epoch: 6| Step: 1
Training loss: 3.726000729489626
Validation loss: 3.369552150119304

Epoch: 6| Step: 2
Training loss: 2.8443790620336027
Validation loss: 3.3713694011436752

Epoch: 6| Step: 3
Training loss: 3.4779073450032056
Validation loss: 3.371486531950007

Epoch: 6| Step: 4
Training loss: 3.878445477888167
Validation loss: 3.3725498516669434

Epoch: 6| Step: 5
Training loss: 3.518693322492585
Validation loss: 3.3728522922993642

Epoch: 6| Step: 6
Training loss: 3.689658874622962
Validation loss: 3.3713691730190987

Epoch: 6| Step: 7
Training loss: 3.006659745111837
Validation loss: 3.3726785242064135

Epoch: 6| Step: 8
Training loss: 4.008086137557922
Validation loss: 3.3706900263931643

Epoch: 6| Step: 9
Training loss: 3.462339784516717
Validation loss: 3.369016284095703

Epoch: 6| Step: 10
Training loss: 3.94204836738599
Validation loss: 3.368370798982377

Epoch: 6| Step: 11
Training loss: 3.85122648247432
Validation loss: 3.368300581409218

Epoch: 6| Step: 12
Training loss: 2.9102920807751174
Validation loss: 3.367454009483042

Epoch: 6| Step: 13
Training loss: 4.636336994604584
Validation loss: 3.3670879248695753

Epoch: 60| Step: 0
Training loss: 4.442133244288128
Validation loss: 3.366520067111925

Epoch: 6| Step: 1
Training loss: 3.168003369011677
Validation loss: 3.367038605218374

Epoch: 6| Step: 2
Training loss: 3.6459058191268956
Validation loss: 3.366281277863955

Epoch: 6| Step: 3
Training loss: 4.895209652830614
Validation loss: 3.365840944401904

Epoch: 6| Step: 4
Training loss: 3.395876706710321
Validation loss: 3.364971253707268

Epoch: 6| Step: 5
Training loss: 2.4794529554546885
Validation loss: 3.3647345930487207

Epoch: 6| Step: 6
Training loss: 3.763680236838791
Validation loss: 3.363658653895026

Epoch: 6| Step: 7
Training loss: 2.9994175663459544
Validation loss: 3.3640146072302914

Epoch: 6| Step: 8
Training loss: 4.313233244106607
Validation loss: 3.3635430218108033

Epoch: 6| Step: 9
Training loss: 2.9025399101989713
Validation loss: 3.3641761927884977

Epoch: 6| Step: 10
Training loss: 2.379173827508504
Validation loss: 3.362279040357055

Epoch: 6| Step: 11
Training loss: 3.421079081460118
Validation loss: 3.3637291528065196

Epoch: 6| Step: 12
Training loss: 3.472459064459321
Validation loss: 3.3637195985757278

Epoch: 6| Step: 13
Training loss: 4.501549983644414
Validation loss: 3.3634593999763616

Epoch: 61| Step: 0
Training loss: 3.413753399506772
Validation loss: 3.363499767557599

Epoch: 6| Step: 1
Training loss: 3.723553032149205
Validation loss: 3.362344059452385

Epoch: 6| Step: 2
Training loss: 3.4452635054445753
Validation loss: 3.3643218050290407

Epoch: 6| Step: 3
Training loss: 3.5366118916959706
Validation loss: 3.360339157585544

Epoch: 6| Step: 4
Training loss: 3.416713776302429
Validation loss: 3.3637341951369097

Epoch: 6| Step: 5
Training loss: 3.9690753473005307
Validation loss: 3.3615802064199687

Epoch: 6| Step: 6
Training loss: 3.828443366066388
Validation loss: 3.3613911909809477

Epoch: 6| Step: 7
Training loss: 3.66377527213255
Validation loss: 3.3621282011260254

Epoch: 6| Step: 8
Training loss: 3.694105019588906
Validation loss: 3.3618056077746714

Epoch: 6| Step: 9
Training loss: 3.908486908346979
Validation loss: 3.3667568017652383

Epoch: 6| Step: 10
Training loss: 3.325824354276402
Validation loss: 3.362071414587862

Epoch: 6| Step: 11
Training loss: 2.6995291193327566
Validation loss: 3.359407112366836

Epoch: 6| Step: 12
Training loss: 4.104552016910187
Validation loss: 3.3579879854527697

Epoch: 6| Step: 13
Training loss: 3.244957753804294
Validation loss: 3.3584971481680195

Epoch: 62| Step: 0
Training loss: 3.6539985702169426
Validation loss: 3.358751359398575

Epoch: 6| Step: 1
Training loss: 3.7778135715609005
Validation loss: 3.3598123321553763

Epoch: 6| Step: 2
Training loss: 3.102718416528581
Validation loss: 3.3607194290302735

Epoch: 6| Step: 3
Training loss: 3.9107543609815276
Validation loss: 3.369467143554271

Epoch: 6| Step: 4
Training loss: 4.1909463848816
Validation loss: 3.3584568319043657

Epoch: 6| Step: 5
Training loss: 2.4034762558610376
Validation loss: 3.3591732757282164

Epoch: 6| Step: 6
Training loss: 3.277041979458279
Validation loss: 3.3575471217356574

Epoch: 6| Step: 7
Training loss: 3.7772601807747637
Validation loss: 3.3570426244665517

Epoch: 6| Step: 8
Training loss: 3.8560888222717358
Validation loss: 3.3574023579873815

Epoch: 6| Step: 9
Training loss: 3.9106630345598745
Validation loss: 3.3578278794914143

Epoch: 6| Step: 10
Training loss: 3.345731486808786
Validation loss: 3.3577475968883665

Epoch: 6| Step: 11
Training loss: 3.531504799081414
Validation loss: 3.3566304241309006

Epoch: 6| Step: 12
Training loss: 3.3798596751411174
Validation loss: 3.35660705622559

Epoch: 6| Step: 13
Training loss: 4.020821263323178
Validation loss: 3.358960197845248

Epoch: 63| Step: 0
Training loss: 3.4773773952785647
Validation loss: 3.357443690243282

Epoch: 6| Step: 1
Training loss: 4.264149616787115
Validation loss: 3.35863055723075

Epoch: 6| Step: 2
Training loss: 3.893597428714177
Validation loss: 3.3580388580181624

Epoch: 6| Step: 3
Training loss: 3.6484228619888364
Validation loss: 3.358947844271169

Epoch: 6| Step: 4
Training loss: 4.161832115501199
Validation loss: 3.3576097838186536

Epoch: 6| Step: 5
Training loss: 4.143364687305094
Validation loss: 3.357468819212035

Epoch: 6| Step: 6
Training loss: 3.4039465438912866
Validation loss: 3.3559836705074173

Epoch: 6| Step: 7
Training loss: 3.69696021090644
Validation loss: 3.355503992466263

Epoch: 6| Step: 8
Training loss: 3.61945985146873
Validation loss: 3.356013348709611

Epoch: 6| Step: 9
Training loss: 3.460489971770842
Validation loss: 3.3537411020751544

Epoch: 6| Step: 10
Training loss: 3.28352233678366
Validation loss: 3.354840264426503

Epoch: 6| Step: 11
Training loss: 2.4811191937537544
Validation loss: 3.354887532083242

Epoch: 6| Step: 12
Training loss: 3.2073006557443113
Validation loss: 3.3541467404001355

Epoch: 6| Step: 13
Training loss: 2.688879679129025
Validation loss: 3.35475944876219

Epoch: 64| Step: 0
Training loss: 3.4204480405311863
Validation loss: 3.353698953650067

Epoch: 6| Step: 1
Training loss: 3.7202450607961204
Validation loss: 3.3553319405071704

Epoch: 6| Step: 2
Training loss: 3.16254891821379
Validation loss: 3.3556210964403728

Epoch: 6| Step: 3
Training loss: 2.9981162196784865
Validation loss: 3.3524876094239007

Epoch: 6| Step: 4
Training loss: 3.851396104417851
Validation loss: 3.3527409091325446

Epoch: 6| Step: 5
Training loss: 3.483880114799715
Validation loss: 3.3533027059539062

Epoch: 6| Step: 6
Training loss: 3.9316583321291523
Validation loss: 3.3505172692567644

Epoch: 6| Step: 7
Training loss: 3.497856846370388
Validation loss: 3.349607112609545

Epoch: 6| Step: 8
Training loss: 3.4171698285044045
Validation loss: 3.3501435074168535

Epoch: 6| Step: 9
Training loss: 3.5148863970222664
Validation loss: 3.349526994224857

Epoch: 6| Step: 10
Training loss: 3.238423932179689
Validation loss: 3.3487502379040053

Epoch: 6| Step: 11
Training loss: 4.624016115853496
Validation loss: 3.348748977806064

Epoch: 6| Step: 12
Training loss: 3.793680487660506
Validation loss: 3.349132734564446

Epoch: 6| Step: 13
Training loss: 2.9673702848600985
Validation loss: 3.3497109299601218

Epoch: 65| Step: 0
Training loss: 3.3454318941521803
Validation loss: 3.3505505208812

Epoch: 6| Step: 1
Training loss: 3.4332476583611875
Validation loss: 3.3495774855623885

Epoch: 6| Step: 2
Training loss: 3.9284964665778994
Validation loss: 3.351582384517822

Epoch: 6| Step: 3
Training loss: 3.8649614805446313
Validation loss: 3.3493954345780756

Epoch: 6| Step: 4
Training loss: 3.5563051672010295
Validation loss: 3.350610066616961

Epoch: 6| Step: 5
Training loss: 3.8480070777161792
Validation loss: 3.3488792599305492

Epoch: 6| Step: 6
Training loss: 3.442644881425043
Validation loss: 3.347005503479617

Epoch: 6| Step: 7
Training loss: 3.8531505723090738
Validation loss: 3.34740820378672

Epoch: 6| Step: 8
Training loss: 2.0901957848211916
Validation loss: 3.3473804367100066

Epoch: 6| Step: 9
Training loss: 3.52506220336573
Validation loss: 3.3482828054922322

Epoch: 6| Step: 10
Training loss: 3.5290785332986645
Validation loss: 3.346307950877579

Epoch: 6| Step: 11
Training loss: 4.03024681679632
Validation loss: 3.3470756056016855

Epoch: 6| Step: 12
Training loss: 4.051728508457841
Validation loss: 3.3458189721337477

Epoch: 6| Step: 13
Training loss: 2.9390376510259184
Validation loss: 3.346735997531226

Epoch: 66| Step: 0
Training loss: 4.281062435301682
Validation loss: 3.345264812765903

Epoch: 6| Step: 1
Training loss: 3.3745812050276953
Validation loss: 3.3443898572159845

Epoch: 6| Step: 2
Training loss: 3.807027171802274
Validation loss: 3.3456532786189195

Epoch: 6| Step: 3
Training loss: 3.3539620726049746
Validation loss: 3.343945035708137

Epoch: 6| Step: 4
Training loss: 2.7165766831767946
Validation loss: 3.343469513874903

Epoch: 6| Step: 5
Training loss: 3.439368832371412
Validation loss: 3.345087241904174

Epoch: 6| Step: 6
Training loss: 4.123716674929049
Validation loss: 3.342975588497391

Epoch: 6| Step: 7
Training loss: 3.5526994784226225
Validation loss: 3.3434493449436804

Epoch: 6| Step: 8
Training loss: 2.9456984370818686
Validation loss: 3.3436377491825033

Epoch: 6| Step: 9
Training loss: 3.128324037787708
Validation loss: 3.3448265396672

Epoch: 6| Step: 10
Training loss: 3.5097360073701647
Validation loss: 3.3432782698814942

Epoch: 6| Step: 11
Training loss: 4.208756655310231
Validation loss: 3.343061161323847

Epoch: 6| Step: 12
Training loss: 3.7162435082598
Validation loss: 3.344563755198489

Epoch: 6| Step: 13
Training loss: 3.603378533130726
Validation loss: 3.342588569329812

Epoch: 67| Step: 0
Training loss: 3.4907041808789474
Validation loss: 3.3444492796114105

Epoch: 6| Step: 1
Training loss: 3.9274451833647483
Validation loss: 3.3427246778888207

Epoch: 6| Step: 2
Training loss: 3.497444036989029
Validation loss: 3.3436794862010184

Epoch: 6| Step: 3
Training loss: 3.136015132595064
Validation loss: 3.3412050980728316

Epoch: 6| Step: 4
Training loss: 3.7278277730329106
Validation loss: 3.341653127466154

Epoch: 6| Step: 5
Training loss: 3.8609998734243707
Validation loss: 3.3420616351831507

Epoch: 6| Step: 6
Training loss: 3.777986110914154
Validation loss: 3.3424302445452274

Epoch: 6| Step: 7
Training loss: 3.2021353332493376
Validation loss: 3.3429427507968863

Epoch: 6| Step: 8
Training loss: 3.7832917304979534
Validation loss: 3.3405356618700104

Epoch: 6| Step: 9
Training loss: 3.3961902423047903
Validation loss: 3.343323327773813

Epoch: 6| Step: 10
Training loss: 3.2132183058583985
Validation loss: 3.340418868652906

Epoch: 6| Step: 11
Training loss: 3.863486628767345
Validation loss: 3.3410359468631414

Epoch: 6| Step: 12
Training loss: 3.6450244696571534
Validation loss: 3.3416213861191735

Epoch: 6| Step: 13
Training loss: 3.3056944987982124
Validation loss: 3.3413786753718617

Epoch: 68| Step: 0
Training loss: 2.773323336118628
Validation loss: 3.341336570489155

Epoch: 6| Step: 1
Training loss: 3.4173349021653014
Validation loss: 3.341356601793297

Epoch: 6| Step: 2
Training loss: 3.1490028195651707
Validation loss: 3.3404197205343182

Epoch: 6| Step: 3
Training loss: 3.9542104565225986
Validation loss: 3.3399423189987094

Epoch: 6| Step: 4
Training loss: 3.3866353976190364
Validation loss: 3.340002053858068

Epoch: 6| Step: 5
Training loss: 3.7834429726419674
Validation loss: 3.3423135957687173

Epoch: 6| Step: 6
Training loss: 4.141726941003355
Validation loss: 3.3422372696976046

Epoch: 6| Step: 7
Training loss: 3.5203821167748126
Validation loss: 3.3398989463878963

Epoch: 6| Step: 8
Training loss: 3.7590239984873217
Validation loss: 3.3433915901557856

Epoch: 6| Step: 9
Training loss: 3.974715787695586
Validation loss: 3.338601664117192

Epoch: 6| Step: 10
Training loss: 3.405030338415472
Validation loss: 3.3379130026005774

Epoch: 6| Step: 11
Training loss: 3.2321063207474663
Validation loss: 3.3388044001697352

Epoch: 6| Step: 12
Training loss: 3.711859209136595
Validation loss: 3.337352360714495

Epoch: 6| Step: 13
Training loss: 3.6290398810248488
Validation loss: 3.3382651044097376

Epoch: 69| Step: 0
Training loss: 3.5556104195520972
Validation loss: 3.3366586754303778

Epoch: 6| Step: 1
Training loss: 4.3136497844505906
Validation loss: 3.336463812352806

Epoch: 6| Step: 2
Training loss: 3.9072872158110954
Validation loss: 3.3371894425549313

Epoch: 6| Step: 3
Training loss: 3.104760968625805
Validation loss: 3.33658711587999

Epoch: 6| Step: 4
Training loss: 4.0085032204349424
Validation loss: 3.3358279819719243

Epoch: 6| Step: 5
Training loss: 4.106616352524458
Validation loss: 3.335621831666155

Epoch: 6| Step: 6
Training loss: 3.8312355327488627
Validation loss: 3.334549969223311

Epoch: 6| Step: 7
Training loss: 3.3419806531874623
Validation loss: 3.334880817793597

Epoch: 6| Step: 8
Training loss: 3.222312363280868
Validation loss: 3.335131000234154

Epoch: 6| Step: 9
Training loss: 3.9420336100221096
Validation loss: 3.3413276719112788

Epoch: 6| Step: 10
Training loss: 2.8962721640801115
Validation loss: 3.340275904525218

Epoch: 6| Step: 11
Training loss: 2.7762819988909127
Validation loss: 3.338841771108587

Epoch: 6| Step: 12
Training loss: 3.2273174446417214
Validation loss: 3.3384218251864968

Epoch: 6| Step: 13
Training loss: 3.250645500049519
Validation loss: 3.3368567262483717

Epoch: 70| Step: 0
Training loss: 4.580929258601845
Validation loss: 3.3349404326839567

Epoch: 6| Step: 1
Training loss: 3.9505476559872763
Validation loss: 3.3343184927797584

Epoch: 6| Step: 2
Training loss: 3.4864356272816384
Validation loss: 3.334068777619942

Epoch: 6| Step: 3
Training loss: 3.074165702468777
Validation loss: 3.331615308791849

Epoch: 6| Step: 4
Training loss: 2.8991525595697216
Validation loss: 3.33189229631355

Epoch: 6| Step: 5
Training loss: 3.404886235200554
Validation loss: 3.3310957117506956

Epoch: 6| Step: 6
Training loss: 4.01319140600476
Validation loss: 3.331250243308246

Epoch: 6| Step: 7
Training loss: 4.171431728630588
Validation loss: 3.3305841142523813

Epoch: 6| Step: 8
Training loss: 3.243804013899548
Validation loss: 3.33057770088055

Epoch: 6| Step: 9
Training loss: 3.8444679644189206
Validation loss: 3.331202360124729

Epoch: 6| Step: 10
Training loss: 2.6513965021975183
Validation loss: 3.3299081160116777

Epoch: 6| Step: 11
Training loss: 3.3525898388140676
Validation loss: 3.3302045155879823

Epoch: 6| Step: 12
Training loss: 3.208433190975712
Validation loss: 3.329680629283946

Epoch: 6| Step: 13
Training loss: 3.5776137607275698
Validation loss: 3.3294958149021143

Epoch: 71| Step: 0
Training loss: 3.711127796313251
Validation loss: 3.3284873767044516

Epoch: 6| Step: 1
Training loss: 3.3048542963595255
Validation loss: 3.3308652451869847

Epoch: 6| Step: 2
Training loss: 3.5087595725260186
Validation loss: 3.329154396570989

Epoch: 6| Step: 3
Training loss: 2.967218586305366
Validation loss: 3.3294517225537286

Epoch: 6| Step: 4
Training loss: 3.8053967952484418
Validation loss: 3.3287629733051296

Epoch: 6| Step: 5
Training loss: 4.187134684099972
Validation loss: 3.328931585270067

Epoch: 6| Step: 6
Training loss: 2.624552734054511
Validation loss: 3.3281404382321718

Epoch: 6| Step: 7
Training loss: 3.3531732134450247
Validation loss: 3.328178753886458

Epoch: 6| Step: 8
Training loss: 2.5626615147745597
Validation loss: 3.3274142707947036

Epoch: 6| Step: 9
Training loss: 3.607471575185518
Validation loss: 3.3275199793521537

Epoch: 6| Step: 10
Training loss: 3.6159537994252133
Validation loss: 3.3280981805038428

Epoch: 6| Step: 11
Training loss: 3.7442625022955043
Validation loss: 3.327405968304029

Epoch: 6| Step: 12
Training loss: 4.5314838217554145
Validation loss: 3.327106232667414

Epoch: 6| Step: 13
Training loss: 4.053808921929189
Validation loss: 3.325904775396856

Epoch: 72| Step: 0
Training loss: 3.5808308460942193
Validation loss: 3.3265589745787523

Epoch: 6| Step: 1
Training loss: 3.363954908579056
Validation loss: 3.3259786675051566

Epoch: 6| Step: 2
Training loss: 3.458169971575592
Validation loss: 3.3269616592971376

Epoch: 6| Step: 3
Training loss: 3.135893488690601
Validation loss: 3.3251142543419863

Epoch: 6| Step: 4
Training loss: 3.6742399350950086
Validation loss: 3.3252327785634224

Epoch: 6| Step: 5
Training loss: 3.9020193154127267
Validation loss: 3.3242971663294125

Epoch: 6| Step: 6
Training loss: 3.579649221614415
Validation loss: 3.324504139938455

Epoch: 6| Step: 7
Training loss: 2.941614394403408
Validation loss: 3.325205711387155

Epoch: 6| Step: 8
Training loss: 3.3683519230826184
Validation loss: 3.32411982041332

Epoch: 6| Step: 9
Training loss: 3.380710574290793
Validation loss: 3.324083345179084

Epoch: 6| Step: 10
Training loss: 4.343221728358967
Validation loss: 3.3247369273416187

Epoch: 6| Step: 11
Training loss: 3.3259419189813735
Validation loss: 3.3248197974411045

Epoch: 6| Step: 12
Training loss: 3.829481857549693
Validation loss: 3.3228498857126647

Epoch: 6| Step: 13
Training loss: 3.9212149866381396
Validation loss: 3.3216371426189886

Epoch: 73| Step: 0
Training loss: 3.2016319703011455
Validation loss: 3.3226606838953185

Epoch: 6| Step: 1
Training loss: 3.469682173011509
Validation loss: 3.321687682807158

Epoch: 6| Step: 2
Training loss: 4.42847567336107
Validation loss: 3.3210245190096357

Epoch: 6| Step: 3
Training loss: 3.685451132334836
Validation loss: 3.3220910289914376

Epoch: 6| Step: 4
Training loss: 3.0197828022744613
Validation loss: 3.3206655570614307

Epoch: 6| Step: 5
Training loss: 3.6117556428768185
Validation loss: 3.321019703627579

Epoch: 6| Step: 6
Training loss: 3.6877715447224295
Validation loss: 3.3207920403283944

Epoch: 6| Step: 7
Training loss: 3.2093805032625347
Validation loss: 3.320442467980308

Epoch: 6| Step: 8
Training loss: 3.3660464732179918
Validation loss: 3.3196507928954295

Epoch: 6| Step: 9
Training loss: 3.2858396855704965
Validation loss: 3.3200180542770386

Epoch: 6| Step: 10
Training loss: 3.7118196422728698
Validation loss: 3.319689377976903

Epoch: 6| Step: 11
Training loss: 3.341287008837649
Validation loss: 3.32062360643967

Epoch: 6| Step: 12
Training loss: 3.4553094229038033
Validation loss: 3.317475527470878

Epoch: 6| Step: 13
Training loss: 4.485817707073999
Validation loss: 3.3196662473694625

Epoch: 74| Step: 0
Training loss: 3.142153543509803
Validation loss: 3.318762909399259

Epoch: 6| Step: 1
Training loss: 3.649422816796096
Validation loss: 3.3178619865873142

Epoch: 6| Step: 2
Training loss: 3.585372847105136
Validation loss: 3.317879481527872

Epoch: 6| Step: 3
Training loss: 3.8203921319506087
Validation loss: 3.3190351594781107

Epoch: 6| Step: 4
Training loss: 3.544332660226415
Validation loss: 3.3179957592652425

Epoch: 6| Step: 5
Training loss: 3.632645535477661
Validation loss: 3.3192159483935155

Epoch: 6| Step: 6
Training loss: 3.0186170844913742
Validation loss: 3.3190880054891414

Epoch: 6| Step: 7
Training loss: 3.5849335372488706
Validation loss: 3.316760441697365

Epoch: 6| Step: 8
Training loss: 2.670271721490035
Validation loss: 3.318430065278045

Epoch: 6| Step: 9
Training loss: 3.862188016766593
Validation loss: 3.317786830388748

Epoch: 6| Step: 10
Training loss: 3.811792401796311
Validation loss: 3.321870943581986

Epoch: 6| Step: 11
Training loss: 3.970998292413948
Validation loss: 3.320049030773636

Epoch: 6| Step: 12
Training loss: 3.7856162847702324
Validation loss: 3.3178067597043017

Epoch: 6| Step: 13
Training loss: 3.3781961918756616
Validation loss: 3.31711394637894

Epoch: 75| Step: 0
Training loss: 3.857141133969038
Validation loss: 3.31530565198396

Epoch: 6| Step: 1
Training loss: 3.6867576757123364
Validation loss: 3.3156665411060025

Epoch: 6| Step: 2
Training loss: 3.487283220014084
Validation loss: 3.3152643588795327

Epoch: 6| Step: 3
Training loss: 3.4487868456585002
Validation loss: 3.3132414681595046

Epoch: 6| Step: 4
Training loss: 2.4777853079920424
Validation loss: 3.3130856656203003

Epoch: 6| Step: 5
Training loss: 3.6709802714342223
Validation loss: 3.315056441057399

Epoch: 6| Step: 6
Training loss: 3.5671361905324894
Validation loss: 3.3132530559098656

Epoch: 6| Step: 7
Training loss: 3.9608067598153074
Validation loss: 3.314111471243898

Epoch: 6| Step: 8
Training loss: 3.7325323818102647
Validation loss: 3.3120630834811755

Epoch: 6| Step: 9
Training loss: 3.2022781369071116
Validation loss: 3.3143444533290163

Epoch: 6| Step: 10
Training loss: 3.741249301348263
Validation loss: 3.312097289297638

Epoch: 6| Step: 11
Training loss: 3.4042318822682973
Validation loss: 3.3106511444118367

Epoch: 6| Step: 12
Training loss: 3.8614600105511823
Validation loss: 3.312787376873531

Epoch: 6| Step: 13
Training loss: 3.2504000784304754
Validation loss: 3.3133202696336963

Epoch: 76| Step: 0
Training loss: 3.689650215793468
Validation loss: 3.311158908484232

Epoch: 6| Step: 1
Training loss: 3.1598918790065773
Validation loss: 3.3132486625354587

Epoch: 6| Step: 2
Training loss: 3.5105400780662612
Validation loss: 3.31239877315118

Epoch: 6| Step: 3
Training loss: 3.48341554851944
Validation loss: 3.313199298186343

Epoch: 6| Step: 4
Training loss: 3.4064199422737236
Validation loss: 3.311879244387151

Epoch: 6| Step: 5
Training loss: 3.318382941168527
Validation loss: 3.3107854546816924

Epoch: 6| Step: 6
Training loss: 3.46297489586548
Validation loss: 3.3129384080991113

Epoch: 6| Step: 7
Training loss: 3.6745190779340855
Validation loss: 3.3127546562741275

Epoch: 6| Step: 8
Training loss: 3.49408248929767
Validation loss: 3.311255504692289

Epoch: 6| Step: 9
Training loss: 4.295266033988392
Validation loss: 3.3154086304153787

Epoch: 6| Step: 10
Training loss: 3.2463699021374484
Validation loss: 3.3166049567426428

Epoch: 6| Step: 11
Training loss: 3.305644733141419
Validation loss: 3.3158265535809566

Epoch: 6| Step: 12
Training loss: 4.064613379454247
Validation loss: 3.313178502388762

Epoch: 6| Step: 13
Training loss: 3.2886597302936758
Validation loss: 3.314906943248798

Epoch: 77| Step: 0
Training loss: 3.6746346999283452
Validation loss: 3.3130732369428437

Epoch: 6| Step: 1
Training loss: 4.066499589916974
Validation loss: 3.3107535645197146

Epoch: 6| Step: 2
Training loss: 4.041849794204522
Validation loss: 3.31109342238853

Epoch: 6| Step: 3
Training loss: 3.6428234355232565
Validation loss: 3.309068110509076

Epoch: 6| Step: 4
Training loss: 3.4311598135347214
Validation loss: 3.311092226933932

Epoch: 6| Step: 5
Training loss: 2.5723659116388977
Validation loss: 3.3072862556121927

Epoch: 6| Step: 6
Training loss: 3.371184276015116
Validation loss: 3.307319092323951

Epoch: 6| Step: 7
Training loss: 3.5657029058987466
Validation loss: 3.307014156161606

Epoch: 6| Step: 8
Training loss: 3.540031923484181
Validation loss: 3.3039945319357735

Epoch: 6| Step: 9
Training loss: 2.886578506139567
Validation loss: 3.3070222400737426

Epoch: 6| Step: 10
Training loss: 2.703130644864048
Validation loss: 3.3067161624551185

Epoch: 6| Step: 11
Training loss: 3.6300171957318046
Validation loss: 3.3053281107827113

Epoch: 6| Step: 12
Training loss: 3.8679749582973177
Validation loss: 3.3058140124183395

Epoch: 6| Step: 13
Training loss: 4.641248462038738
Validation loss: 3.308200706149658

Epoch: 78| Step: 0
Training loss: 3.942311934277398
Validation loss: 3.3058029135222036

Epoch: 6| Step: 1
Training loss: 3.7589546101745546
Validation loss: 3.3052267651176996

Epoch: 6| Step: 2
Training loss: 3.351748161242005
Validation loss: 3.303895499581195

Epoch: 6| Step: 3
Training loss: 3.986328364236274
Validation loss: 3.3054687543122

Epoch: 6| Step: 4
Training loss: 3.102855653012266
Validation loss: 3.3048450652820156

Epoch: 6| Step: 5
Training loss: 3.944933338641565
Validation loss: 3.30644233436193

Epoch: 6| Step: 6
Training loss: 3.0957239192420696
Validation loss: 3.3066586243309692

Epoch: 6| Step: 7
Training loss: 2.5703168596503208
Validation loss: 3.3040103172465534

Epoch: 6| Step: 8
Training loss: 3.800503476569261
Validation loss: 3.3042117843854886

Epoch: 6| Step: 9
Training loss: 4.488378140272734
Validation loss: 3.3062868239794216

Epoch: 6| Step: 10
Training loss: 4.0268315193922986
Validation loss: 3.3044496406677824

Epoch: 6| Step: 11
Training loss: 2.7613562274495242
Validation loss: 3.3058181861271865

Epoch: 6| Step: 12
Training loss: 2.8458117043458437
Validation loss: 3.3050804869367516

Epoch: 6| Step: 13
Training loss: 3.143171350452543
Validation loss: 3.3067008978740366

Epoch: 79| Step: 0
Training loss: 3.7647633180023643
Validation loss: 3.304186475391011

Epoch: 6| Step: 1
Training loss: 3.801292455624918
Validation loss: 3.307199825335567

Epoch: 6| Step: 2
Training loss: 3.756787578687003
Validation loss: 3.305114353919533

Epoch: 6| Step: 3
Training loss: 3.780302449191181
Validation loss: 3.3061006072582813

Epoch: 6| Step: 4
Training loss: 3.3941890425537284
Validation loss: 3.3022999005221174

Epoch: 6| Step: 5
Training loss: 3.391505816970239
Validation loss: 3.302566015315547

Epoch: 6| Step: 6
Training loss: 4.032543832312488
Validation loss: 3.303924896896282

Epoch: 6| Step: 7
Training loss: 3.900098549991525
Validation loss: 3.3034184646969487

Epoch: 6| Step: 8
Training loss: 2.9293541477015457
Validation loss: 3.303215376008858

Epoch: 6| Step: 9
Training loss: 3.73967287315912
Validation loss: 3.3013141960790127

Epoch: 6| Step: 10
Training loss: 3.3451006291738543
Validation loss: 3.3006665654460843

Epoch: 6| Step: 11
Training loss: 3.243260952755115
Validation loss: 3.3011481100459745

Epoch: 6| Step: 12
Training loss: 2.879059454931721
Validation loss: 3.301907706889737

Epoch: 6| Step: 13
Training loss: 3.235823449777865
Validation loss: 3.3013887682580725

Epoch: 80| Step: 0
Training loss: 3.6518025532772933
Validation loss: 3.3002574167381424

Epoch: 6| Step: 1
Training loss: 3.9757638065482444
Validation loss: 3.301373094658551

Epoch: 6| Step: 2
Training loss: 3.239515265008282
Validation loss: 3.3003915464341538

Epoch: 6| Step: 3
Training loss: 2.7258740624425175
Validation loss: 3.301669318849337

Epoch: 6| Step: 4
Training loss: 3.7647445725809
Validation loss: 3.30228737069757

Epoch: 6| Step: 5
Training loss: 3.143610356226952
Validation loss: 3.302061741876951

Epoch: 6| Step: 6
Training loss: 3.255138736235166
Validation loss: 3.3010317296783738

Epoch: 6| Step: 7
Training loss: 4.030348566093134
Validation loss: 3.301889940983466

Epoch: 6| Step: 8
Training loss: 3.893367796336019
Validation loss: 3.299087005522884

Epoch: 6| Step: 9
Training loss: 3.9925699368097964
Validation loss: 3.3004613740886537

Epoch: 6| Step: 10
Training loss: 3.329797888456041
Validation loss: 3.301339106982

Epoch: 6| Step: 11
Training loss: 3.7336897600420906
Validation loss: 3.299671468605236

Epoch: 6| Step: 12
Training loss: 3.356799464649925
Validation loss: 3.299415404718465

Epoch: 6| Step: 13
Training loss: 2.735081434275389
Validation loss: 3.298689086084559

Epoch: 81| Step: 0
Training loss: 4.7661156573747405
Validation loss: 3.2992065440340337

Epoch: 6| Step: 1
Training loss: 2.8722858056270346
Validation loss: 3.300313486477389

Epoch: 6| Step: 2
Training loss: 3.426969176519743
Validation loss: 3.3022696099391635

Epoch: 6| Step: 3
Training loss: 3.6249063413951426
Validation loss: 3.302802111712725

Epoch: 6| Step: 4
Training loss: 4.081283106530873
Validation loss: 3.2976934158507833

Epoch: 6| Step: 5
Training loss: 3.1120489689913926
Validation loss: 3.30035853360207

Epoch: 6| Step: 6
Training loss: 3.5482105311879133
Validation loss: 3.300022443401079

Epoch: 6| Step: 7
Training loss: 2.854772981346225
Validation loss: 3.298702810869847

Epoch: 6| Step: 8
Training loss: 2.467866956948795
Validation loss: 3.298406356792198

Epoch: 6| Step: 9
Training loss: 3.7076082413680065
Validation loss: 3.297951538141207

Epoch: 6| Step: 10
Training loss: 3.7495091434931416
Validation loss: 3.29994812157387

Epoch: 6| Step: 11
Training loss: 3.961323314889903
Validation loss: 3.299976091214376

Epoch: 6| Step: 12
Training loss: 3.4038563288437524
Validation loss: 3.2982570813268453

Epoch: 6| Step: 13
Training loss: 3.0106002769223257
Validation loss: 3.296592356199958

Epoch: 82| Step: 0
Training loss: 3.365596103101414
Validation loss: 3.2960621708011173

Epoch: 6| Step: 1
Training loss: 4.136929918181987
Validation loss: 3.2959490161267464

Epoch: 6| Step: 2
Training loss: 3.6527066789934928
Validation loss: 3.295766988243919

Epoch: 6| Step: 3
Training loss: 3.016794560989822
Validation loss: 3.2952414966556822

Epoch: 6| Step: 4
Training loss: 3.534410395896132
Validation loss: 3.294100236575246

Epoch: 6| Step: 5
Training loss: 4.204770585015004
Validation loss: 3.295386551435762

Epoch: 6| Step: 6
Training loss: 3.3697657085442834
Validation loss: 3.2962045404325666

Epoch: 6| Step: 7
Training loss: 3.442393339966172
Validation loss: 3.2939881725835503

Epoch: 6| Step: 8
Training loss: 3.3425921280346804
Validation loss: 3.2966154947283326

Epoch: 6| Step: 9
Training loss: 3.0754813833180235
Validation loss: 3.2925706299483743

Epoch: 6| Step: 10
Training loss: 3.65681231486555
Validation loss: 3.292719517767489

Epoch: 6| Step: 11
Training loss: 2.8848998413682514
Validation loss: 3.2930952943685976

Epoch: 6| Step: 12
Training loss: 4.006629456925427
Validation loss: 3.2908943415610437

Epoch: 6| Step: 13
Training loss: 3.350007236529833
Validation loss: 3.2908606974916097

Epoch: 83| Step: 0
Training loss: 3.55022067606436
Validation loss: 3.2922872553091596

Epoch: 6| Step: 1
Training loss: 3.787939286644737
Validation loss: 3.2908217666018813

Epoch: 6| Step: 2
Training loss: 3.7600618795619263
Validation loss: 3.291466440632757

Epoch: 6| Step: 3
Training loss: 3.006440560691447
Validation loss: 3.2893800988175275

Epoch: 6| Step: 4
Training loss: 3.93763611573386
Validation loss: 3.291214885578331

Epoch: 6| Step: 5
Training loss: 3.5358546120456387
Validation loss: 3.291159178831223

Epoch: 6| Step: 6
Training loss: 3.7069830132613113
Validation loss: 3.291348580728621

Epoch: 6| Step: 7
Training loss: 4.026519839112991
Validation loss: 3.290297869419212

Epoch: 6| Step: 8
Training loss: 3.9727479517132465
Validation loss: 3.2888614892326373

Epoch: 6| Step: 9
Training loss: 3.7637894458154326
Validation loss: 3.289671442077162

Epoch: 6| Step: 10
Training loss: 2.9875714026182183
Validation loss: 3.2886023697073488

Epoch: 6| Step: 11
Training loss: 2.6835913512373284
Validation loss: 3.2868029554128775

Epoch: 6| Step: 12
Training loss: 2.947432101877535
Validation loss: 3.2891583297074583

Epoch: 6| Step: 13
Training loss: 3.1694425830469695
Validation loss: 3.2907145021160806

Epoch: 84| Step: 0
Training loss: 3.9244219651975873
Validation loss: 3.2910585325850876

Epoch: 6| Step: 1
Training loss: 3.7149391202186814
Validation loss: 3.291006037280433

Epoch: 6| Step: 2
Training loss: 3.5331668208731175
Validation loss: 3.295653695861408

Epoch: 6| Step: 3
Training loss: 3.3200664833030444
Validation loss: 3.295198903387557

Epoch: 6| Step: 4
Training loss: 2.2872173697549583
Validation loss: 3.2996890708689373

Epoch: 6| Step: 5
Training loss: 4.097719088382575
Validation loss: 3.2994081490990173

Epoch: 6| Step: 6
Training loss: 2.897937659583623
Validation loss: 3.3076810915483077

Epoch: 6| Step: 7
Training loss: 3.29637829261486
Validation loss: 3.3041861402123467

Epoch: 6| Step: 8
Training loss: 4.484420935631454
Validation loss: 3.2991659616947633

Epoch: 6| Step: 9
Training loss: 3.0258977771544244
Validation loss: 3.2888937210615485

Epoch: 6| Step: 10
Training loss: 3.018498292147482
Validation loss: 3.286194296246144

Epoch: 6| Step: 11
Training loss: 3.3754143637144787
Validation loss: 3.2862615344876978

Epoch: 6| Step: 12
Training loss: 3.9371171795472177
Validation loss: 3.2908095366265204

Epoch: 6| Step: 13
Training loss: 4.163499060438171
Validation loss: 3.2897834318013897

Epoch: 85| Step: 0
Training loss: 3.5582015222321153
Validation loss: 3.283501871456837

Epoch: 6| Step: 1
Training loss: 3.051858123351398
Validation loss: 3.285583085202579

Epoch: 6| Step: 2
Training loss: 3.855033378407094
Validation loss: 3.2872004762704568

Epoch: 6| Step: 3
Training loss: 4.0188891729340055
Validation loss: 3.2830402520073396

Epoch: 6| Step: 4
Training loss: 2.581427937948689
Validation loss: 3.284900949514166

Epoch: 6| Step: 5
Training loss: 3.3805607796632735
Validation loss: 3.28459576003114

Epoch: 6| Step: 6
Training loss: 3.057554338772395
Validation loss: 3.282517555059352

Epoch: 6| Step: 7
Training loss: 3.1967506063801863
Validation loss: 3.2830787933770504

Epoch: 6| Step: 8
Training loss: 3.5197019546213335
Validation loss: 3.286945868045002

Epoch: 6| Step: 9
Training loss: 3.668716695657102
Validation loss: 3.285151842461691

Epoch: 6| Step: 10
Training loss: 2.936033166744815
Validation loss: 3.2821758458304875

Epoch: 6| Step: 11
Training loss: 4.302296606262385
Validation loss: 3.2852019482073382

Epoch: 6| Step: 12
Training loss: 3.5833818890734284
Validation loss: 3.2844682075656078

Epoch: 6| Step: 13
Training loss: 4.611372796003453
Validation loss: 3.2851912510131935

Epoch: 86| Step: 0
Training loss: 2.6194516537044485
Validation loss: 3.2846836248915827

Epoch: 6| Step: 1
Training loss: 3.443929312411438
Validation loss: 3.283888248134258

Epoch: 6| Step: 2
Training loss: 3.014256932941863
Validation loss: 3.2826219853670726

Epoch: 6| Step: 3
Training loss: 3.6122631061323323
Validation loss: 3.2824379703676523

Epoch: 6| Step: 4
Training loss: 3.8554222467433568
Validation loss: 3.285030451787803

Epoch: 6| Step: 5
Training loss: 4.2441442202584865
Validation loss: 3.2814021468352084

Epoch: 6| Step: 6
Training loss: 3.238411416450551
Validation loss: 3.2842628034983394

Epoch: 6| Step: 7
Training loss: 4.262896101549676
Validation loss: 3.2861386970838264

Epoch: 6| Step: 8
Training loss: 4.26715976925377
Validation loss: 3.282427767142605

Epoch: 6| Step: 9
Training loss: 3.3895474316915837
Validation loss: 3.279357778644999

Epoch: 6| Step: 10
Training loss: 3.2485239638527506
Validation loss: 3.27901351190996

Epoch: 6| Step: 11
Training loss: 3.0217643267810357
Validation loss: 3.279918729128909

Epoch: 6| Step: 12
Training loss: 3.358633411969233
Validation loss: 3.2816674720375154

Epoch: 6| Step: 13
Training loss: 2.9158645253467763
Validation loss: 3.2797654926391524

Epoch: 87| Step: 0
Training loss: 2.866502560494459
Validation loss: 3.279303838958252

Epoch: 6| Step: 1
Training loss: 2.6292693523620794
Validation loss: 3.277853216713636

Epoch: 6| Step: 2
Training loss: 4.560490622980168
Validation loss: 3.277921250161927

Epoch: 6| Step: 3
Training loss: 3.6683134946816733
Validation loss: 3.2788390991159178

Epoch: 6| Step: 4
Training loss: 3.496371704645531
Validation loss: 3.2788148296420507

Epoch: 6| Step: 5
Training loss: 3.14145964354416
Validation loss: 3.2771022428537786

Epoch: 6| Step: 6
Training loss: 3.295265853645744
Validation loss: 3.2791107243532673

Epoch: 6| Step: 7
Training loss: 4.299116957726428
Validation loss: 3.2781986844972435

Epoch: 6| Step: 8
Training loss: 3.4679454523392366
Validation loss: 3.276528477608388

Epoch: 6| Step: 9
Training loss: 3.8639358567626068
Validation loss: 3.2756438836541264

Epoch: 6| Step: 10
Training loss: 3.1636878274500573
Validation loss: 3.27756187261357

Epoch: 6| Step: 11
Training loss: 3.4929504243885754
Validation loss: 3.2751603597723977

Epoch: 6| Step: 12
Training loss: 3.0617796381536513
Validation loss: 3.275177946612987

Epoch: 6| Step: 13
Training loss: 3.8199815977362324
Validation loss: 3.2746732901243685

Epoch: 88| Step: 0
Training loss: 3.502971205453358
Validation loss: 3.273887491159431

Epoch: 6| Step: 1
Training loss: 4.218860313951247
Validation loss: 3.274958209212873

Epoch: 6| Step: 2
Training loss: 3.0071476981930165
Validation loss: 3.2757989611023293

Epoch: 6| Step: 3
Training loss: 2.8874365465202287
Validation loss: 3.272914471805735

Epoch: 6| Step: 4
Training loss: 3.2497282648193857
Validation loss: 3.2725459876079857

Epoch: 6| Step: 5
Training loss: 4.366522286238867
Validation loss: 3.272924908342852

Epoch: 6| Step: 6
Training loss: 2.752562109638842
Validation loss: 3.2728709597661823

Epoch: 6| Step: 7
Training loss: 3.848586226643323
Validation loss: 3.2738736858347766

Epoch: 6| Step: 8
Training loss: 2.7305599955974023
Validation loss: 3.27281936337212

Epoch: 6| Step: 9
Training loss: 4.052061785303139
Validation loss: 3.273699563039817

Epoch: 6| Step: 10
Training loss: 3.3691680818627576
Validation loss: 3.2733490638496114

Epoch: 6| Step: 11
Training loss: 4.126523285707986
Validation loss: 3.273462786723553

Epoch: 6| Step: 12
Training loss: 3.039109570450064
Validation loss: 3.2744963193409165

Epoch: 6| Step: 13
Training loss: 3.375545175106832
Validation loss: 3.273625112687257

Epoch: 89| Step: 0
Training loss: 3.6601192509135823
Validation loss: 3.274574036471678

Epoch: 6| Step: 1
Training loss: 3.7482033558234864
Validation loss: 3.274093337853983

Epoch: 6| Step: 2
Training loss: 3.622533419437144
Validation loss: 3.2757887559809657

Epoch: 6| Step: 3
Training loss: 3.0045751018003193
Validation loss: 3.272864072983153

Epoch: 6| Step: 4
Training loss: 3.143659198276306
Validation loss: 3.2742364873434124

Epoch: 6| Step: 5
Training loss: 3.6337374914457263
Validation loss: 3.27382520307801

Epoch: 6| Step: 6
Training loss: 3.9768325324266294
Validation loss: 3.273616191374367

Epoch: 6| Step: 7
Training loss: 3.472945691502107
Validation loss: 3.2720599006907145

Epoch: 6| Step: 8
Training loss: 3.5076805038935657
Validation loss: 3.270031312537507

Epoch: 6| Step: 9
Training loss: 4.088462151728114
Validation loss: 3.2715814154430904

Epoch: 6| Step: 10
Training loss: 3.43304515357565
Validation loss: 3.2706797333619666

Epoch: 6| Step: 11
Training loss: 3.0069256949091026
Validation loss: 3.274566384467916

Epoch: 6| Step: 12
Training loss: 3.478375388675503
Validation loss: 3.2713951948680764

Epoch: 6| Step: 13
Training loss: 2.8071785492952332
Validation loss: 3.272888519744041

Epoch: 90| Step: 0
Training loss: 2.670300560796753
Validation loss: 3.2695320074408616

Epoch: 6| Step: 1
Training loss: 3.4802881744156675
Validation loss: 3.2690747399904434

Epoch: 6| Step: 2
Training loss: 4.2230175897664175
Validation loss: 3.2715320649433854

Epoch: 6| Step: 3
Training loss: 2.5238545076177745
Validation loss: 3.271458136928239

Epoch: 6| Step: 4
Training loss: 3.2884997976104966
Validation loss: 3.2713612671930004

Epoch: 6| Step: 5
Training loss: 3.3154751354580134
Validation loss: 3.268220365020793

Epoch: 6| Step: 6
Training loss: 3.655580899563958
Validation loss: 3.275091254503412

Epoch: 6| Step: 7
Training loss: 3.843350645579387
Validation loss: 3.2763031883304428

Epoch: 6| Step: 8
Training loss: 4.13609878461914
Validation loss: 3.28207109357214

Epoch: 6| Step: 9
Training loss: 3.1422646261240983
Validation loss: 3.2712372284298765

Epoch: 6| Step: 10
Training loss: 4.071803780765072
Validation loss: 3.269546963333488

Epoch: 6| Step: 11
Training loss: 3.638937104530995
Validation loss: 3.2687572952484305

Epoch: 6| Step: 12
Training loss: 3.166860741808489
Validation loss: 3.268397763472019

Epoch: 6| Step: 13
Training loss: 3.4381015598016087
Validation loss: 3.2676108758859113

Epoch: 91| Step: 0
Training loss: 4.275667435148717
Validation loss: 3.2673909889410915

Epoch: 6| Step: 1
Training loss: 4.044298449059906
Validation loss: 3.2654095862413723

Epoch: 6| Step: 2
Training loss: 3.5730943255653367
Validation loss: 3.2653516861205922

Epoch: 6| Step: 3
Training loss: 3.235911128932713
Validation loss: 3.2666538205834903

Epoch: 6| Step: 4
Training loss: 3.7323117481954498
Validation loss: 3.263999907113065

Epoch: 6| Step: 5
Training loss: 3.1742574829772874
Validation loss: 3.2651053214011965

Epoch: 6| Step: 6
Training loss: 3.7036593409813063
Validation loss: 3.2662091277143546

Epoch: 6| Step: 7
Training loss: 3.346839689465634
Validation loss: 3.264001426132666

Epoch: 6| Step: 8
Training loss: 3.4746085515913863
Validation loss: 3.263023876473603

Epoch: 6| Step: 9
Training loss: 3.337530894618682
Validation loss: 3.2625283519427764

Epoch: 6| Step: 10
Training loss: 3.00037890266718
Validation loss: 3.2623041240860564

Epoch: 6| Step: 11
Training loss: 2.1464732675724894
Validation loss: 3.2610077267019495

Epoch: 6| Step: 12
Training loss: 3.6462691273676353
Validation loss: 3.261856925228041

Epoch: 6| Step: 13
Training loss: 4.162353852143532
Validation loss: 3.263071763918907

Epoch: 92| Step: 0
Training loss: 3.050789846488769
Validation loss: 3.262539682134011

Epoch: 6| Step: 1
Training loss: 3.319982462917108
Validation loss: 3.264172981260267

Epoch: 6| Step: 2
Training loss: 3.1080336241308633
Validation loss: 3.263949457038742

Epoch: 6| Step: 3
Training loss: 3.8697306584118154
Validation loss: 3.2641150505646994

Epoch: 6| Step: 4
Training loss: 3.247724176411815
Validation loss: 3.265644900659779

Epoch: 6| Step: 5
Training loss: 4.123568430936276
Validation loss: 3.2642968722154357

Epoch: 6| Step: 6
Training loss: 3.34050728971465
Validation loss: 3.262225661991774

Epoch: 6| Step: 7
Training loss: 2.8560903892745664
Validation loss: 3.2610911109749248

Epoch: 6| Step: 8
Training loss: 3.834650076129485
Validation loss: 3.262514397971239

Epoch: 6| Step: 9
Training loss: 3.517575956065406
Validation loss: 3.2637110229170103

Epoch: 6| Step: 10
Training loss: 3.806157699493105
Validation loss: 3.2619053092246157

Epoch: 6| Step: 11
Training loss: 3.3828412554710274
Validation loss: 3.260128815400507

Epoch: 6| Step: 12
Training loss: 4.146431475610515
Validation loss: 3.2595934053396105

Epoch: 6| Step: 13
Training loss: 2.713939313009052
Validation loss: 3.261136318623268

Epoch: 93| Step: 0
Training loss: 3.538131220814961
Validation loss: 3.262164768561071

Epoch: 6| Step: 1
Training loss: 1.704618936168596
Validation loss: 3.259587888887588

Epoch: 6| Step: 2
Training loss: 3.658493266740843
Validation loss: 3.2601053880267563

Epoch: 6| Step: 3
Training loss: 3.866771205497432
Validation loss: 3.2606515389291237

Epoch: 6| Step: 4
Training loss: 3.778707358737709
Validation loss: 3.26001346981694

Epoch: 6| Step: 5
Training loss: 4.324953535414698
Validation loss: 3.2608849403669224

Epoch: 6| Step: 6
Training loss: 2.473807261355057
Validation loss: 3.260508451900022

Epoch: 6| Step: 7
Training loss: 3.925001501581184
Validation loss: 3.2581842768623326

Epoch: 6| Step: 8
Training loss: 3.76605298154639
Validation loss: 3.2583054670515423

Epoch: 6| Step: 9
Training loss: 2.5749363456191454
Validation loss: 3.2582023172752645

Epoch: 6| Step: 10
Training loss: 3.6387490608845754
Validation loss: 3.257252815837326

Epoch: 6| Step: 11
Training loss: 3.790953740317925
Validation loss: 3.257752329901048

Epoch: 6| Step: 12
Training loss: 3.6338569042225934
Validation loss: 3.260037067710161

Epoch: 6| Step: 13
Training loss: 3.2195284004078477
Validation loss: 3.258165982988493

Epoch: 94| Step: 0
Training loss: 3.001078729600369
Validation loss: 3.2602989167389635

Epoch: 6| Step: 1
Training loss: 3.285040419052644
Validation loss: 3.2595039368364778

Epoch: 6| Step: 2
Training loss: 4.3454841061381435
Validation loss: 3.2572527418540536

Epoch: 6| Step: 3
Training loss: 2.0374248841838085
Validation loss: 3.2604766935056695

Epoch: 6| Step: 4
Training loss: 3.0870407257112285
Validation loss: 3.259110278495452

Epoch: 6| Step: 5
Training loss: 3.5170464248868782
Validation loss: 3.2568777856365743

Epoch: 6| Step: 6
Training loss: 3.7757495565443846
Validation loss: 3.255947122459883

Epoch: 6| Step: 7
Training loss: 4.330409799966342
Validation loss: 3.2565713617701912

Epoch: 6| Step: 8
Training loss: 4.230189433083406
Validation loss: 3.256257269150131

Epoch: 6| Step: 9
Training loss: 3.2091564427201953
Validation loss: 3.2584006246200006

Epoch: 6| Step: 10
Training loss: 3.9820219384455577
Validation loss: 3.2587945755841647

Epoch: 6| Step: 11
Training loss: 3.2140019034170555
Validation loss: 3.258314834700413

Epoch: 6| Step: 12
Training loss: 3.4684093411164643
Validation loss: 3.2601989879960973

Epoch: 6| Step: 13
Training loss: 1.5614738146332778
Validation loss: 3.2566245459715537

Epoch: 95| Step: 0
Training loss: 2.891738594619053
Validation loss: 3.2580205599547694

Epoch: 6| Step: 1
Training loss: 3.3275552897800162
Validation loss: 3.2557411017101465

Epoch: 6| Step: 2
Training loss: 3.398917609315794
Validation loss: 3.2566225370163218

Epoch: 6| Step: 3
Training loss: 2.439196460864689
Validation loss: 3.2586397667115192

Epoch: 6| Step: 4
Training loss: 2.9618010456924915
Validation loss: 3.253471030752007

Epoch: 6| Step: 5
Training loss: 3.7574211440247756
Validation loss: 3.2527855230977334

Epoch: 6| Step: 6
Training loss: 2.9503100668678233
Validation loss: 3.2534208634071806

Epoch: 6| Step: 7
Training loss: 4.249581484664085
Validation loss: 3.2522543857325976

Epoch: 6| Step: 8
Training loss: 4.5972169003387
Validation loss: 3.2527767172310726

Epoch: 6| Step: 9
Training loss: 3.6141196767965513
Validation loss: 3.251617082978743

Epoch: 6| Step: 10
Training loss: 2.9351030675412138
Validation loss: 3.2524525244737155

Epoch: 6| Step: 11
Training loss: 3.8312040441348736
Validation loss: 3.2516149353213715

Epoch: 6| Step: 12
Training loss: 4.031049383331761
Validation loss: 3.251110376285665

Epoch: 6| Step: 13
Training loss: 2.950507078394038
Validation loss: 3.2511804659716095

Epoch: 96| Step: 0
Training loss: 3.76199888016209
Validation loss: 3.251469179867089

Epoch: 6| Step: 1
Training loss: 2.8826173132177795
Validation loss: 3.25169355726334

Epoch: 6| Step: 2
Training loss: 3.5818187854451233
Validation loss: 3.248960650638758

Epoch: 6| Step: 3
Training loss: 3.6929301996480595
Validation loss: 3.2500801376294475

Epoch: 6| Step: 4
Training loss: 3.2763133378585128
Validation loss: 3.250609729577339

Epoch: 6| Step: 5
Training loss: 3.665156804954902
Validation loss: 3.2502085584893132

Epoch: 6| Step: 6
Training loss: 4.050237370822822
Validation loss: 3.250764228444286

Epoch: 6| Step: 7
Training loss: 3.6662752347143397
Validation loss: 3.252576825605576

Epoch: 6| Step: 8
Training loss: 4.1627128661200885
Validation loss: 3.257473645269121

Epoch: 6| Step: 9
Training loss: 3.257723507477557
Validation loss: 3.262201400945422

Epoch: 6| Step: 10
Training loss: 3.2593348031568996
Validation loss: 3.2639886299020113

Epoch: 6| Step: 11
Training loss: 2.907252641227087
Validation loss: 3.2576692300367225

Epoch: 6| Step: 12
Training loss: 3.3082688857814873
Validation loss: 3.253726334352087

Epoch: 6| Step: 13
Training loss: 2.7606186031157756
Validation loss: 3.249918369501756

Epoch: 97| Step: 0
Training loss: 2.898929029877012
Validation loss: 3.2478609342210345

Epoch: 6| Step: 1
Training loss: 3.606198452956311
Validation loss: 3.247120361633239

Epoch: 6| Step: 2
Training loss: 3.7552476405583355
Validation loss: 3.2491713209662016

Epoch: 6| Step: 3
Training loss: 3.320604594229162
Validation loss: 3.2468045398776653

Epoch: 6| Step: 4
Training loss: 4.346258303722385
Validation loss: 3.2475060753611285

Epoch: 6| Step: 5
Training loss: 3.5486641963033074
Validation loss: 3.247914393660192

Epoch: 6| Step: 6
Training loss: 2.799059478291359
Validation loss: 3.2488320178974086

Epoch: 6| Step: 7
Training loss: 3.5695108060361966
Validation loss: 3.249224201811041

Epoch: 6| Step: 8
Training loss: 2.806923572610121
Validation loss: 3.2467820499407987

Epoch: 6| Step: 9
Training loss: 3.2857794607107627
Validation loss: 3.2474291551125414

Epoch: 6| Step: 10
Training loss: 3.6213505231068224
Validation loss: 3.2463297901444066

Epoch: 6| Step: 11
Training loss: 3.9201540875804275
Validation loss: 3.2466846291227363

Epoch: 6| Step: 12
Training loss: 3.388485703864694
Validation loss: 3.2465233551153783

Epoch: 6| Step: 13
Training loss: 3.6955593421867188
Validation loss: 3.24597198856998

Epoch: 98| Step: 0
Training loss: 3.233410530217496
Validation loss: 3.246078897706813

Epoch: 6| Step: 1
Training loss: 3.478213623233929
Validation loss: 3.2452407694932006

Epoch: 6| Step: 2
Training loss: 3.530143091689448
Validation loss: 3.2470743453871793

Epoch: 6| Step: 3
Training loss: 2.332827638141344
Validation loss: 3.2476517639718843

Epoch: 6| Step: 4
Training loss: 3.2279877182018994
Validation loss: 3.2448850836953747

Epoch: 6| Step: 5
Training loss: 3.915170356678489
Validation loss: 3.247592202910216

Epoch: 6| Step: 6
Training loss: 3.5920700790773736
Validation loss: 3.24705359665032

Epoch: 6| Step: 7
Training loss: 4.421906487989698
Validation loss: 3.2470843581053845

Epoch: 6| Step: 8
Training loss: 3.004824573645488
Validation loss: 3.245336122918734

Epoch: 6| Step: 9
Training loss: 3.296807021755488
Validation loss: 3.2448687942817496

Epoch: 6| Step: 10
Training loss: 3.8597529299631197
Validation loss: 3.242759046747026

Epoch: 6| Step: 11
Training loss: 2.9295737282596392
Validation loss: 3.2448205876303025

Epoch: 6| Step: 12
Training loss: 3.8306583663376044
Validation loss: 3.2426852885265047

Epoch: 6| Step: 13
Training loss: 3.702276333808686
Validation loss: 3.242823155331248

Epoch: 99| Step: 0
Training loss: 2.2510844901932323
Validation loss: 3.2436955550001048

Epoch: 6| Step: 1
Training loss: 3.149030227336769
Validation loss: 3.2413785120612673

Epoch: 6| Step: 2
Training loss: 3.825943804219031
Validation loss: 3.241386297775899

Epoch: 6| Step: 3
Training loss: 2.73187891792081
Validation loss: 3.240622609184944

Epoch: 6| Step: 4
Training loss: 3.156750780923145
Validation loss: 3.239993301553308

Epoch: 6| Step: 5
Training loss: 3.0795390177969475
Validation loss: 3.240255619169736

Epoch: 6| Step: 6
Training loss: 3.8641450261528862
Validation loss: 3.239517506154619

Epoch: 6| Step: 7
Training loss: 4.43398306729564
Validation loss: 3.239137562219384

Epoch: 6| Step: 8
Training loss: 3.8714972631205113
Validation loss: 3.239284133718868

Epoch: 6| Step: 9
Training loss: 3.9208179280339555
Validation loss: 3.238850942097056

Epoch: 6| Step: 10
Training loss: 3.5987824076352384
Validation loss: 3.240269487025295

Epoch: 6| Step: 11
Training loss: 3.656273996649351
Validation loss: 3.239138426491168

Epoch: 6| Step: 12
Training loss: 3.4303445034683597
Validation loss: 3.2396040581665857

Epoch: 6| Step: 13
Training loss: 2.8500191470389753
Validation loss: 3.23922603807666

Epoch: 100| Step: 0
Training loss: 2.8379595144985097
Validation loss: 3.2449753779289607

Epoch: 6| Step: 1
Training loss: 3.7896962058671235
Validation loss: 3.2452593416187097

Epoch: 6| Step: 2
Training loss: 2.7327917256337226
Validation loss: 3.241051118646495

Epoch: 6| Step: 3
Training loss: 3.528834504248396
Validation loss: 3.2369527944973306

Epoch: 6| Step: 4
Training loss: 2.9517594667045257
Validation loss: 3.2370659919309865

Epoch: 6| Step: 5
Training loss: 4.128756575456466
Validation loss: 3.237665599078763

Epoch: 6| Step: 6
Training loss: 3.6599595252128525
Validation loss: 3.2371956069617793

Epoch: 6| Step: 7
Training loss: 2.5247155133116954
Validation loss: 3.2370179177583234

Epoch: 6| Step: 8
Training loss: 3.7580820094037723
Validation loss: 3.2349455813005368

Epoch: 6| Step: 9
Training loss: 3.704587237265542
Validation loss: 3.236949681175381

Epoch: 6| Step: 10
Training loss: 4.182372184665594
Validation loss: 3.2355696968618273

Epoch: 6| Step: 11
Training loss: 3.518195674726473
Validation loss: 3.2353044628554577

Epoch: 6| Step: 12
Training loss: 3.057580071037896
Validation loss: 3.2350052484095486

Epoch: 6| Step: 13
Training loss: 4.028764061733114
Validation loss: 3.2350481603089234

Epoch: 101| Step: 0
Training loss: 3.2260245181793845
Validation loss: 3.2344109373358587

Epoch: 6| Step: 1
Training loss: 2.9653950255355026
Validation loss: 3.2344443807343133

Epoch: 6| Step: 2
Training loss: 3.9430776177046227
Validation loss: 3.2348875654488927

Epoch: 6| Step: 3
Training loss: 3.982654394496336
Validation loss: 3.2360820707051845

Epoch: 6| Step: 4
Training loss: 2.99184485483054
Validation loss: 3.2355495858659493

Epoch: 6| Step: 5
Training loss: 3.719435941119671
Validation loss: 3.2366187039535617

Epoch: 6| Step: 6
Training loss: 3.6373391446862358
Validation loss: 3.2346011433432165

Epoch: 6| Step: 7
Training loss: 3.822262131928654
Validation loss: 3.2339474149345406

Epoch: 6| Step: 8
Training loss: 3.7489220659403073
Validation loss: 3.2382810853332447

Epoch: 6| Step: 9
Training loss: 3.080276434494611
Validation loss: 3.2374907467763276

Epoch: 6| Step: 10
Training loss: 3.0804623477258795
Validation loss: 3.233968423743504

Epoch: 6| Step: 11
Training loss: 3.2784295448829948
Validation loss: 3.2327903014891297

Epoch: 6| Step: 12
Training loss: 3.3242061269589946
Validation loss: 3.233215618834547

Epoch: 6| Step: 13
Training loss: 3.738268111792809
Validation loss: 3.2324631572878344

Epoch: 102| Step: 0
Training loss: 4.003523466839695
Validation loss: 3.2317536158025932

Epoch: 6| Step: 1
Training loss: 4.364226673396686
Validation loss: 3.2320989060965326

Epoch: 6| Step: 2
Training loss: 3.33362593955999
Validation loss: 3.2287944127935857

Epoch: 6| Step: 3
Training loss: 3.7912737185135295
Validation loss: 3.2302695040788065

Epoch: 6| Step: 4
Training loss: 3.323766442265752
Validation loss: 3.2294429400204683

Epoch: 6| Step: 5
Training loss: 3.8553841532322224
Validation loss: 3.2299742123911535

Epoch: 6| Step: 6
Training loss: 3.546554349277672
Validation loss: 3.229300304006798

Epoch: 6| Step: 7
Training loss: 2.98638784225364
Validation loss: 3.228868896431552

Epoch: 6| Step: 8
Training loss: 2.985553768299235
Validation loss: 3.227310346264104

Epoch: 6| Step: 9
Training loss: 2.4723472944570672
Validation loss: 3.227494922837703

Epoch: 6| Step: 10
Training loss: 3.122775086868099
Validation loss: 3.227262884597713

Epoch: 6| Step: 11
Training loss: 3.5501803822425644
Validation loss: 3.2272495788737294

Epoch: 6| Step: 12
Training loss: 3.7646498307795735
Validation loss: 3.2278130262738363

Epoch: 6| Step: 13
Training loss: 2.644606077862613
Validation loss: 3.229810699058348

Epoch: 103| Step: 0
Training loss: 3.872865519699748
Validation loss: 3.22949712665418

Epoch: 6| Step: 1
Training loss: 3.2590408753754785
Validation loss: 3.228231459099684

Epoch: 6| Step: 2
Training loss: 2.938987030893677
Validation loss: 3.2272791341883695

Epoch: 6| Step: 3
Training loss: 4.1867281074227165
Validation loss: 3.2294752695298796

Epoch: 6| Step: 4
Training loss: 3.207948356089055
Validation loss: 3.228676123115771

Epoch: 6| Step: 5
Training loss: 2.659282613689304
Validation loss: 3.2312244227268945

Epoch: 6| Step: 6
Training loss: 3.199649320699326
Validation loss: 3.2302444823972114

Epoch: 6| Step: 7
Training loss: 3.1774231442356577
Validation loss: 3.231391536172079

Epoch: 6| Step: 8
Training loss: 3.6290078205393335
Validation loss: 3.231768448258374

Epoch: 6| Step: 9
Training loss: 3.3856090940904977
Validation loss: 3.2278198296798455

Epoch: 6| Step: 10
Training loss: 3.764388645178423
Validation loss: 3.2301886114762266

Epoch: 6| Step: 11
Training loss: 3.799047405906088
Validation loss: 3.2291064306721653

Epoch: 6| Step: 12
Training loss: 4.09979709960561
Validation loss: 3.225841063857251

Epoch: 6| Step: 13
Training loss: 2.5699714967802065
Validation loss: 3.2253943279250032

Epoch: 104| Step: 0
Training loss: 4.45757213523464
Validation loss: 3.2240744832628345

Epoch: 6| Step: 1
Training loss: 3.3368841967587257
Validation loss: 3.223787301645388

Epoch: 6| Step: 2
Training loss: 2.534496815266869
Validation loss: 3.2231638363778767

Epoch: 6| Step: 3
Training loss: 2.860508094950842
Validation loss: 3.224779530212198

Epoch: 6| Step: 4
Training loss: 2.669681831290438
Validation loss: 3.2237899863284554

Epoch: 6| Step: 5
Training loss: 3.697722667208019
Validation loss: 3.2246395396453034

Epoch: 6| Step: 6
Training loss: 3.5962041022030644
Validation loss: 3.223882903931068

Epoch: 6| Step: 7
Training loss: 3.2499859149334207
Validation loss: 3.222258946901723

Epoch: 6| Step: 8
Training loss: 3.125157619316
Validation loss: 3.2231825548007027

Epoch: 6| Step: 9
Training loss: 2.951822629484621
Validation loss: 3.2219551703541205

Epoch: 6| Step: 10
Training loss: 3.5981826645612127
Validation loss: 3.2223443498323134

Epoch: 6| Step: 11
Training loss: 4.191756177872984
Validation loss: 3.222389097056922

Epoch: 6| Step: 12
Training loss: 4.0394237364151895
Validation loss: 3.225714282852039

Epoch: 6| Step: 13
Training loss: 3.7417607392604095
Validation loss: 3.221557580258485

Epoch: 105| Step: 0
Training loss: 4.022004637151669
Validation loss: 3.2220127149047273

Epoch: 6| Step: 1
Training loss: 4.207393025009018
Validation loss: 3.2225402791276907

Epoch: 6| Step: 2
Training loss: 4.388029913133534
Validation loss: 3.2204793618513317

Epoch: 6| Step: 3
Training loss: 3.2037025489225206
Validation loss: 3.222107121483142

Epoch: 6| Step: 4
Training loss: 2.9352016791695767
Validation loss: 3.223486521872152

Epoch: 6| Step: 5
Training loss: 2.9396687070550604
Validation loss: 3.225457736466057

Epoch: 6| Step: 6
Training loss: 2.7878622255913927
Validation loss: 3.229573259481776

Epoch: 6| Step: 7
Training loss: 3.0687408695745506
Validation loss: 3.228631925947549

Epoch: 6| Step: 8
Training loss: 3.8385962694167355
Validation loss: 3.2257553791802267

Epoch: 6| Step: 9
Training loss: 3.970216735381498
Validation loss: 3.230265031173804

Epoch: 6| Step: 10
Training loss: 3.289785853782145
Validation loss: 3.220692340938219

Epoch: 6| Step: 11
Training loss: 3.1860936372147157
Validation loss: 3.221314201047709

Epoch: 6| Step: 12
Training loss: 2.6774442753482686
Validation loss: 3.2212364834557556

Epoch: 6| Step: 13
Training loss: 3.344441565184623
Validation loss: 3.2202495948957495

Epoch: 106| Step: 0
Training loss: 3.6816850492594986
Validation loss: 3.217842534845035

Epoch: 6| Step: 1
Training loss: 3.903308584936723
Validation loss: 3.2166726018957252

Epoch: 6| Step: 2
Training loss: 3.1292524777230644
Validation loss: 3.2179125126292103

Epoch: 6| Step: 3
Training loss: 4.093746505619334
Validation loss: 3.2184102362644693

Epoch: 6| Step: 4
Training loss: 3.5462840928222876
Validation loss: 3.215695905988422

Epoch: 6| Step: 5
Training loss: 4.02116753699665
Validation loss: 3.216186160231282

Epoch: 6| Step: 6
Training loss: 3.4852604446621296
Validation loss: 3.216445665090769

Epoch: 6| Step: 7
Training loss: 3.4967026846175835
Validation loss: 3.2157557126287384

Epoch: 6| Step: 8
Training loss: 2.9555883074342395
Validation loss: 3.2149451339529227

Epoch: 6| Step: 9
Training loss: 2.720126537997993
Validation loss: 3.216688987870843

Epoch: 6| Step: 10
Training loss: 3.435684001846921
Validation loss: 3.2141293777245594

Epoch: 6| Step: 11
Training loss: 3.6552444770760304
Validation loss: 3.2145297655298637

Epoch: 6| Step: 12
Training loss: 2.947032962258761
Validation loss: 3.215125458375776

Epoch: 6| Step: 13
Training loss: 2.6836043222988164
Validation loss: 3.2162114028786304

Epoch: 107| Step: 0
Training loss: 3.6408775143785093
Validation loss: 3.212126125015927

Epoch: 6| Step: 1
Training loss: 3.5978786470178497
Validation loss: 3.2132068568047836

Epoch: 6| Step: 2
Training loss: 3.0356991551126344
Validation loss: 3.214526088976542

Epoch: 6| Step: 3
Training loss: 2.9477313806830456
Validation loss: 3.2122495444843855

Epoch: 6| Step: 4
Training loss: 3.1165483244869323
Validation loss: 3.2134532505788673

Epoch: 6| Step: 5
Training loss: 4.251998880093733
Validation loss: 3.213862178059722

Epoch: 6| Step: 6
Training loss: 3.9353794261058224
Validation loss: 3.2143546165572636

Epoch: 6| Step: 7
Training loss: 3.7647547052527415
Validation loss: 3.2135101368401187

Epoch: 6| Step: 8
Training loss: 3.5948963493080113
Validation loss: 3.213749430085266

Epoch: 6| Step: 9
Training loss: 3.3889803083696988
Validation loss: 3.2130833687885905

Epoch: 6| Step: 10
Training loss: 3.424590544345899
Validation loss: 3.2124720358378607

Epoch: 6| Step: 11
Training loss: 3.4077802947777585
Validation loss: 3.212181349194049

Epoch: 6| Step: 12
Training loss: 2.7061082551762246
Validation loss: 3.2113920191048586

Epoch: 6| Step: 13
Training loss: 3.1528168693131833
Validation loss: 3.2100558702218875

Epoch: 108| Step: 0
Training loss: 3.372082614959096
Validation loss: 3.2119750561711125

Epoch: 6| Step: 1
Training loss: 3.7291483674408448
Validation loss: 3.2100318729567734

Epoch: 6| Step: 2
Training loss: 4.405588952657226
Validation loss: 3.2101949163388963

Epoch: 6| Step: 3
Training loss: 2.0401843262591557
Validation loss: 3.2095254591151776

Epoch: 6| Step: 4
Training loss: 2.8263707911489706
Validation loss: 3.2097781161365746

Epoch: 6| Step: 5
Training loss: 3.8704212578472386
Validation loss: 3.212053961991678

Epoch: 6| Step: 6
Training loss: 4.488030515461636
Validation loss: 3.208315525769943

Epoch: 6| Step: 7
Training loss: 2.717939321737468
Validation loss: 3.211702889565452

Epoch: 6| Step: 8
Training loss: 2.518242179471425
Validation loss: 3.2089137902784617

Epoch: 6| Step: 9
Training loss: 2.9699755899473
Validation loss: 3.2102629190453302

Epoch: 6| Step: 10
Training loss: 3.1271905469379235
Validation loss: 3.210545141954258

Epoch: 6| Step: 11
Training loss: 3.821222676637126
Validation loss: 3.2097790250538036

Epoch: 6| Step: 12
Training loss: 3.3141882570858527
Validation loss: 3.208869790681848

Epoch: 6| Step: 13
Training loss: 4.629822974229692
Validation loss: 3.209224767793563

Epoch: 109| Step: 0
Training loss: 3.7894699664125553
Validation loss: 3.213033970338283

Epoch: 6| Step: 1
Training loss: 3.4507468479437535
Validation loss: 3.209440417203705

Epoch: 6| Step: 2
Training loss: 2.8535955001440523
Validation loss: 3.2139970856224465

Epoch: 6| Step: 3
Training loss: 4.092658676398987
Validation loss: 3.21639136219587

Epoch: 6| Step: 4
Training loss: 4.2308803650458
Validation loss: 3.2099114007484766

Epoch: 6| Step: 5
Training loss: 3.8986634091530203
Validation loss: 3.2068463701715513

Epoch: 6| Step: 6
Training loss: 2.000774710338053
Validation loss: 3.207245397885286

Epoch: 6| Step: 7
Training loss: 3.526754302562702
Validation loss: 3.206288500441952

Epoch: 6| Step: 8
Training loss: 3.5207284464063626
Validation loss: 3.205757921830517

Epoch: 6| Step: 9
Training loss: 3.2642059893589432
Validation loss: 3.2058027062476655

Epoch: 6| Step: 10
Training loss: 3.5621024462078954
Validation loss: 3.20942076872385

Epoch: 6| Step: 11
Training loss: 1.856896295004875
Validation loss: 3.2052542831701576

Epoch: 6| Step: 12
Training loss: 3.4035502242553024
Validation loss: 3.2053135304160296

Epoch: 6| Step: 13
Training loss: 4.36840519451681
Validation loss: 3.2054707307439965

Epoch: 110| Step: 0
Training loss: 3.4938356064901255
Validation loss: 3.2056533115288772

Epoch: 6| Step: 1
Training loss: 2.9140999717450855
Validation loss: 3.2044910478309543

Epoch: 6| Step: 2
Training loss: 3.719512092013779
Validation loss: 3.2050215066167698

Epoch: 6| Step: 3
Training loss: 3.3417153986725285
Validation loss: 3.205128154776725

Epoch: 6| Step: 4
Training loss: 2.9145486134734986
Validation loss: 3.206256898222809

Epoch: 6| Step: 5
Training loss: 2.7228199103710007
Validation loss: 3.2073621879520706

Epoch: 6| Step: 6
Training loss: 3.225547945062736
Validation loss: 3.21043707587765

Epoch: 6| Step: 7
Training loss: 3.963247494635599
Validation loss: 3.208667028743544

Epoch: 6| Step: 8
Training loss: 3.4470492805696558
Validation loss: 3.205996591037997

Epoch: 6| Step: 9
Training loss: 3.2527326686245823
Validation loss: 3.202621129800816

Epoch: 6| Step: 10
Training loss: 3.689178601982319
Validation loss: 3.203150720140394

Epoch: 6| Step: 11
Training loss: 4.226322414045211
Validation loss: 3.2027690378523

Epoch: 6| Step: 12
Training loss: 3.404923626999684
Validation loss: 3.2046564034476956

Epoch: 6| Step: 13
Training loss: 3.8486407419513595
Validation loss: 3.206420659651841

Epoch: 111| Step: 0
Training loss: 4.037192762276812
Validation loss: 3.208582628843481

Epoch: 6| Step: 1
Training loss: 3.687169981590831
Validation loss: 3.2053097073237082

Epoch: 6| Step: 2
Training loss: 2.8798521809260236
Validation loss: 3.2019501258954657

Epoch: 6| Step: 3
Training loss: 3.621453753932268
Validation loss: 3.202444453742556

Epoch: 6| Step: 4
Training loss: 4.1065575982344615
Validation loss: 3.2028285792046334

Epoch: 6| Step: 5
Training loss: 3.6157075890659227
Validation loss: 3.2002093892015044

Epoch: 6| Step: 6
Training loss: 3.340446337497972
Validation loss: 3.1995166638502304

Epoch: 6| Step: 7
Training loss: 2.94326152271817
Validation loss: 3.1996514968270517

Epoch: 6| Step: 8
Training loss: 3.375138456542202
Validation loss: 3.19866352366046

Epoch: 6| Step: 9
Training loss: 2.1660528291580547
Validation loss: 3.198873933709529

Epoch: 6| Step: 10
Training loss: 3.032411962176249
Validation loss: 3.198531940018821

Epoch: 6| Step: 11
Training loss: 3.1657808135568803
Validation loss: 3.1985458332833243

Epoch: 6| Step: 12
Training loss: 3.648215570990425
Validation loss: 3.19914330357674

Epoch: 6| Step: 13
Training loss: 4.610520870216526
Validation loss: 3.1975740505267867

Epoch: 112| Step: 0
Training loss: 4.074649425942794
Validation loss: 3.1990953887651026

Epoch: 6| Step: 1
Training loss: 3.59326964775462
Validation loss: 3.2017286456984344

Epoch: 6| Step: 2
Training loss: 2.54946299863734
Validation loss: 3.200569203664233

Epoch: 6| Step: 3
Training loss: 3.670683192553895
Validation loss: 3.1995243639372903

Epoch: 6| Step: 4
Training loss: 3.2514278503137506
Validation loss: 3.204267767089375

Epoch: 6| Step: 5
Training loss: 3.6652591922801636
Validation loss: 3.2033224865820653

Epoch: 6| Step: 6
Training loss: 3.16729525969477
Validation loss: 3.2049708112623483

Epoch: 6| Step: 7
Training loss: 3.5096425335781674
Validation loss: 3.2073553859123685

Epoch: 6| Step: 8
Training loss: 2.976236160291003
Validation loss: 3.2022620022238257

Epoch: 6| Step: 9
Training loss: 4.243433198635192
Validation loss: 3.1990882293689973

Epoch: 6| Step: 10
Training loss: 2.798248124437497
Validation loss: 3.196498975206033

Epoch: 6| Step: 11
Training loss: 3.8304394012266694
Validation loss: 3.1954684658333483

Epoch: 6| Step: 12
Training loss: 3.685059078990378
Validation loss: 3.1970872368904355

Epoch: 6| Step: 13
Training loss: 2.0153538721173505
Validation loss: 3.195600693865618

Epoch: 113| Step: 0
Training loss: 3.0393028654543435
Validation loss: 3.196165408518887

Epoch: 6| Step: 1
Training loss: 3.0916170416154127
Validation loss: 3.1953249213851302

Epoch: 6| Step: 2
Training loss: 3.977783375445452
Validation loss: 3.1935626833750983

Epoch: 6| Step: 3
Training loss: 3.710858988684281
Validation loss: 3.194601172790017

Epoch: 6| Step: 4
Training loss: 2.8932199738382494
Validation loss: 3.1937623361466834

Epoch: 6| Step: 5
Training loss: 3.4619971175245143
Validation loss: 3.1929610551717365

Epoch: 6| Step: 6
Training loss: 4.037132525181568
Validation loss: 3.1934613198055857

Epoch: 6| Step: 7
Training loss: 3.1709609946285315
Validation loss: 3.1952120263727797

Epoch: 6| Step: 8
Training loss: 3.7739846285055654
Validation loss: 3.1935320927365933

Epoch: 6| Step: 9
Training loss: 3.43807423737038
Validation loss: 3.1925455936610483

Epoch: 6| Step: 10
Training loss: 3.6741697242835416
Validation loss: 3.1923610048199773

Epoch: 6| Step: 11
Training loss: 3.3700648358727223
Validation loss: 3.192886284680732

Epoch: 6| Step: 12
Training loss: 2.666284434422123
Validation loss: 3.1921770887440153

Epoch: 6| Step: 13
Training loss: 3.669601060976017
Validation loss: 3.192547322537467

Epoch: 114| Step: 0
Training loss: 3.508297621182032
Validation loss: 3.194308821349573

Epoch: 6| Step: 1
Training loss: 3.53701824237238
Validation loss: 3.1922197427597436

Epoch: 6| Step: 2
Training loss: 4.261511527529589
Validation loss: 3.1923242712787365

Epoch: 6| Step: 3
Training loss: 3.8277772083721895
Validation loss: 3.1922022835293897

Epoch: 6| Step: 4
Training loss: 3.0870445873128585
Validation loss: 3.192830424062171

Epoch: 6| Step: 5
Training loss: 2.7465663628025303
Validation loss: 3.1915621416502806

Epoch: 6| Step: 6
Training loss: 3.9096087854678907
Validation loss: 3.190376911302918

Epoch: 6| Step: 7
Training loss: 3.15766618135778
Validation loss: 3.18983105205056

Epoch: 6| Step: 8
Training loss: 4.167525978487965
Validation loss: 3.1892509533268325

Epoch: 6| Step: 9
Training loss: 2.5029412134257147
Validation loss: 3.1894114628453676

Epoch: 6| Step: 10
Training loss: 2.8046502666073994
Validation loss: 3.1894482492249465

Epoch: 6| Step: 11
Training loss: 3.390787850261853
Validation loss: 3.1893104351655075

Epoch: 6| Step: 12
Training loss: 3.546726845491251
Validation loss: 3.1906190435177924

Epoch: 6| Step: 13
Training loss: 2.962005181173446
Validation loss: 3.1897835671823644

Epoch: 115| Step: 0
Training loss: 3.172907318348596
Validation loss: 3.1889186439151658

Epoch: 6| Step: 1
Training loss: 3.1258168488076903
Validation loss: 3.188303057088662

Epoch: 6| Step: 2
Training loss: 2.818342625177618
Validation loss: 3.1892304586111084

Epoch: 6| Step: 3
Training loss: 3.5904812750010007
Validation loss: 3.1892970780130723

Epoch: 6| Step: 4
Training loss: 4.610051716413052
Validation loss: 3.1916282183906133

Epoch: 6| Step: 5
Training loss: 3.579993680383656
Validation loss: 3.1900669228156664

Epoch: 6| Step: 6
Training loss: 3.358290244331681
Validation loss: 3.189193788689518

Epoch: 6| Step: 7
Training loss: 3.641988998103191
Validation loss: 3.1872680550718715

Epoch: 6| Step: 8
Training loss: 3.6090877798497965
Validation loss: 3.1879700280575722

Epoch: 6| Step: 9
Training loss: 2.7488127659895354
Validation loss: 3.187768349399399

Epoch: 6| Step: 10
Training loss: 2.9837273499132935
Validation loss: 3.187136145745405

Epoch: 6| Step: 11
Training loss: 3.360652095322921
Validation loss: 3.186778109650957

Epoch: 6| Step: 12
Training loss: 3.9557532217044824
Validation loss: 3.1871224939275775

Epoch: 6| Step: 13
Training loss: 2.917168401523834
Validation loss: 3.1864090004856735

Epoch: 116| Step: 0
Training loss: 2.9110332217324117
Validation loss: 3.1863524695507506

Epoch: 6| Step: 1
Training loss: 3.6199729526415587
Validation loss: 3.18603792223042

Epoch: 6| Step: 2
Training loss: 3.0478116674235314
Validation loss: 3.1861901419973635

Epoch: 6| Step: 3
Training loss: 4.070785289989791
Validation loss: 3.1857899295669174

Epoch: 6| Step: 4
Training loss: 4.017304659202924
Validation loss: 3.185163618458828

Epoch: 6| Step: 5
Training loss: 3.8791417783163453
Validation loss: 3.186339606074532

Epoch: 6| Step: 6
Training loss: 3.6263117554385524
Validation loss: 3.1858904903164165

Epoch: 6| Step: 7
Training loss: 2.9336421876202543
Validation loss: 3.1876967560605984

Epoch: 6| Step: 8
Training loss: 1.8786537809726458
Validation loss: 3.183993810131644

Epoch: 6| Step: 9
Training loss: 3.671458768587892
Validation loss: 3.1836915054074444

Epoch: 6| Step: 10
Training loss: 4.014281764413958
Validation loss: 3.184489173568823

Epoch: 6| Step: 11
Training loss: 3.334874718642079
Validation loss: 3.1835299159035255

Epoch: 6| Step: 12
Training loss: 2.9815216004713347
Validation loss: 3.1837730761352248

Epoch: 6| Step: 13
Training loss: 3.406539204770392
Validation loss: 3.185628580898148

Epoch: 117| Step: 0
Training loss: 2.84330662215798
Validation loss: 3.185267750755747

Epoch: 6| Step: 1
Training loss: 3.4182388286152747
Validation loss: 3.1839898487169784

Epoch: 6| Step: 2
Training loss: 3.9208947890705317
Validation loss: 3.18711758804263

Epoch: 6| Step: 3
Training loss: 3.5744922304014306
Validation loss: 3.186946303653896

Epoch: 6| Step: 4
Training loss: 4.058086873951577
Validation loss: 3.1861011878952534

Epoch: 6| Step: 5
Training loss: 3.3560382683882968
Validation loss: 3.183750676421311

Epoch: 6| Step: 6
Training loss: 4.0592687814631265
Validation loss: 3.1853226494324485

Epoch: 6| Step: 7
Training loss: 3.507909013061898
Validation loss: 3.1807817616685066

Epoch: 6| Step: 8
Training loss: 3.018135725434016
Validation loss: 3.182341741567321

Epoch: 6| Step: 9
Training loss: 3.4229178733769383
Validation loss: 3.18074788461403

Epoch: 6| Step: 10
Training loss: 3.331590880511138
Validation loss: 3.1823716640042625

Epoch: 6| Step: 11
Training loss: 2.8200531309276573
Validation loss: 3.180796796349594

Epoch: 6| Step: 12
Training loss: 3.0517776561854846
Validation loss: 3.18008500750526

Epoch: 6| Step: 13
Training loss: 3.280460080932297
Validation loss: 3.17928311778679

Epoch: 118| Step: 0
Training loss: 3.6125498098351585
Validation loss: 3.180156406217679

Epoch: 6| Step: 1
Training loss: 3.420972452498259
Validation loss: 3.179589398151101

Epoch: 6| Step: 2
Training loss: 3.5963156125126514
Validation loss: 3.178758467605954

Epoch: 6| Step: 3
Training loss: 3.08974775895853
Validation loss: 3.1782343035211733

Epoch: 6| Step: 4
Training loss: 3.4355027378667082
Validation loss: 3.179702767218093

Epoch: 6| Step: 5
Training loss: 4.1305790943625755
Validation loss: 3.179450284324017

Epoch: 6| Step: 6
Training loss: 2.854978422761474
Validation loss: 3.1810876704769515

Epoch: 6| Step: 7
Training loss: 3.4148759723889412
Validation loss: 3.178022693142441

Epoch: 6| Step: 8
Training loss: 2.9555173195809177
Validation loss: 3.1786899070522288

Epoch: 6| Step: 9
Training loss: 3.5867772666962012
Validation loss: 3.1796256208983573

Epoch: 6| Step: 10
Training loss: 3.7773833879286616
Validation loss: 3.1781213257306433

Epoch: 6| Step: 11
Training loss: 3.2400348181089957
Validation loss: 3.179373893058263

Epoch: 6| Step: 12
Training loss: 3.428796743755067
Validation loss: 3.1770648462869526

Epoch: 6| Step: 13
Training loss: 3.12023012437428
Validation loss: 3.175431021005369

Epoch: 119| Step: 0
Training loss: 3.448418218699636
Validation loss: 3.1750091662414697

Epoch: 6| Step: 1
Training loss: 3.1584676373460137
Validation loss: 3.1783292724198673

Epoch: 6| Step: 2
Training loss: 3.485452664940526
Validation loss: 3.1747327549821187

Epoch: 6| Step: 3
Training loss: 3.992305865837913
Validation loss: 3.1748672823224497

Epoch: 6| Step: 4
Training loss: 3.8275882266768986
Validation loss: 3.1764205706653437

Epoch: 6| Step: 5
Training loss: 3.4682354244678506
Validation loss: 3.1753153324545194

Epoch: 6| Step: 6
Training loss: 2.4754655496491966
Validation loss: 3.1748741830358065

Epoch: 6| Step: 7
Training loss: 3.1276651842876153
Validation loss: 3.1749778792650925

Epoch: 6| Step: 8
Training loss: 3.597492160430701
Validation loss: 3.1734887154383924

Epoch: 6| Step: 9
Training loss: 4.22283308451134
Validation loss: 3.174696524051955

Epoch: 6| Step: 10
Training loss: 3.3432274525979664
Validation loss: 3.174075309271722

Epoch: 6| Step: 11
Training loss: 3.865125194856128
Validation loss: 3.1741302957246904

Epoch: 6| Step: 12
Training loss: 2.675724402053513
Validation loss: 3.173781912013637

Epoch: 6| Step: 13
Training loss: 2.213832079218202
Validation loss: 3.1736714688773127

Epoch: 120| Step: 0
Training loss: 3.426877062927549
Validation loss: 3.173445822585987

Epoch: 6| Step: 1
Training loss: 4.4014806163620595
Validation loss: 3.173576126330047

Epoch: 6| Step: 2
Training loss: 2.5519644780930495
Validation loss: 3.172974268349927

Epoch: 6| Step: 3
Training loss: 3.970872326579713
Validation loss: 3.1741427499270585

Epoch: 6| Step: 4
Training loss: 2.5735613572518132
Validation loss: 3.1712155228612837

Epoch: 6| Step: 5
Training loss: 3.2336155096456958
Validation loss: 3.1745089333265635

Epoch: 6| Step: 6
Training loss: 2.218299712574279
Validation loss: 3.1731544539704544

Epoch: 6| Step: 7
Training loss: 3.708188357716106
Validation loss: 3.174904910649887

Epoch: 6| Step: 8
Training loss: 3.9774154617657387
Validation loss: 3.177056977182717

Epoch: 6| Step: 9
Training loss: 2.9052627691505806
Validation loss: 3.1751711320543325

Epoch: 6| Step: 10
Training loss: 3.6665292338422217
Validation loss: 3.1795498998411675

Epoch: 6| Step: 11
Training loss: 3.196969122820179
Validation loss: 3.179101019177106

Epoch: 6| Step: 12
Training loss: 4.014210255102237
Validation loss: 3.1777333262234246

Epoch: 6| Step: 13
Training loss: 3.30467970826874
Validation loss: 3.173076767905548

Epoch: 121| Step: 0
Training loss: 3.341832832397141
Validation loss: 3.171227634428719

Epoch: 6| Step: 1
Training loss: 3.2981323447985154
Validation loss: 3.172194675687312

Epoch: 6| Step: 2
Training loss: 3.5317431080280337
Validation loss: 3.169874382233176

Epoch: 6| Step: 3
Training loss: 2.752985720624102
Validation loss: 3.170587987898282

Epoch: 6| Step: 4
Training loss: 3.928238891795613
Validation loss: 3.171069905572047

Epoch: 6| Step: 5
Training loss: 4.2891094156558625
Validation loss: 3.1699998963622784

Epoch: 6| Step: 6
Training loss: 3.5516461115408915
Validation loss: 3.17175430786757

Epoch: 6| Step: 7
Training loss: 3.5390967226373764
Validation loss: 3.1708945324894366

Epoch: 6| Step: 8
Training loss: 2.672279728803594
Validation loss: 3.1701147534729164

Epoch: 6| Step: 9
Training loss: 3.465456937355876
Validation loss: 3.1686281423544798

Epoch: 6| Step: 10
Training loss: 3.2828346422366512
Validation loss: 3.1690617497082036

Epoch: 6| Step: 11
Training loss: 3.706038604419977
Validation loss: 3.1697345249873985

Epoch: 6| Step: 12
Training loss: 3.4640318253621145
Validation loss: 3.168459618388631

Epoch: 6| Step: 13
Training loss: 2.0371125350152264
Validation loss: 3.168482331716443

Epoch: 122| Step: 0
Training loss: 3.565463122104259
Validation loss: 3.1687628592843295

Epoch: 6| Step: 1
Training loss: 3.5665669566920206
Validation loss: 3.1674611746978276

Epoch: 6| Step: 2
Training loss: 3.0931452921188067
Validation loss: 3.166265932405642

Epoch: 6| Step: 3
Training loss: 3.362797754427497
Validation loss: 3.167278676458117

Epoch: 6| Step: 4
Training loss: 3.239556920637948
Validation loss: 3.1673343167268295

Epoch: 6| Step: 5
Training loss: 4.3396837701161335
Validation loss: 3.166517960684217

Epoch: 6| Step: 6
Training loss: 3.4470196773984436
Validation loss: 3.168203763414281

Epoch: 6| Step: 7
Training loss: 3.2712015969205126
Validation loss: 3.1684941899636767

Epoch: 6| Step: 8
Training loss: 3.572576093243726
Validation loss: 3.1683879140176616

Epoch: 6| Step: 9
Training loss: 3.1908731003564097
Validation loss: 3.165878216092764

Epoch: 6| Step: 10
Training loss: 3.108908766867102
Validation loss: 3.167052448415241

Epoch: 6| Step: 11
Training loss: 2.799131708391524
Validation loss: 3.1671836959324127

Epoch: 6| Step: 12
Training loss: 4.072715240466935
Validation loss: 3.1689783692198055

Epoch: 6| Step: 13
Training loss: 2.4428835374239584
Validation loss: 3.1652890081527882

Epoch: 123| Step: 0
Training loss: 3.4448672329104895
Validation loss: 3.1680143000600145

Epoch: 6| Step: 1
Training loss: 2.7146501870070447
Validation loss: 3.1723790083796297

Epoch: 6| Step: 2
Training loss: 3.678564074293343
Validation loss: 3.17949851453725

Epoch: 6| Step: 3
Training loss: 2.6783714510427306
Validation loss: 3.188781392247206

Epoch: 6| Step: 4
Training loss: 3.787239816120005
Validation loss: 3.1980728432476386

Epoch: 6| Step: 5
Training loss: 3.8804489709708325
Validation loss: 3.1908693386986586

Epoch: 6| Step: 6
Training loss: 3.297335479542298
Validation loss: 3.17817382952452

Epoch: 6| Step: 7
Training loss: 2.628854555525826
Validation loss: 3.165586261884569

Epoch: 6| Step: 8
Training loss: 3.9620090216544055
Validation loss: 3.1633758581750553

Epoch: 6| Step: 9
Training loss: 3.767921349062983
Validation loss: 3.162749658214872

Epoch: 6| Step: 10
Training loss: 2.8096847855600746
Validation loss: 3.161383454610748

Epoch: 6| Step: 11
Training loss: 2.7552630605953135
Validation loss: 3.168279114787542

Epoch: 6| Step: 12
Training loss: 4.112064540267479
Validation loss: 3.1819514996448808

Epoch: 6| Step: 13
Training loss: 4.1541529362846035
Validation loss: 3.1799855635373295

Epoch: 124| Step: 0
Training loss: 3.0941628845284876
Validation loss: 3.1693652889005635

Epoch: 6| Step: 1
Training loss: 3.361755946771612
Validation loss: 3.164714360917717

Epoch: 6| Step: 2
Training loss: 3.1507370646561648
Validation loss: 3.162126948497122

Epoch: 6| Step: 3
Training loss: 3.2764441763961183
Validation loss: 3.160871206156344

Epoch: 6| Step: 4
Training loss: 3.927132171947777
Validation loss: 3.161907838693859

Epoch: 6| Step: 5
Training loss: 3.630962335482076
Validation loss: 3.1601755330819636

Epoch: 6| Step: 6
Training loss: 3.338781783603557
Validation loss: 3.1636510202906027

Epoch: 6| Step: 7
Training loss: 3.5848931015442442
Validation loss: 3.169974901979808

Epoch: 6| Step: 8
Training loss: 3.7163847766486007
Validation loss: 3.170879893103715

Epoch: 6| Step: 9
Training loss: 3.6395280355973925
Validation loss: 3.1766204841120795

Epoch: 6| Step: 10
Training loss: 3.52777522797046
Validation loss: 3.1713120681169173

Epoch: 6| Step: 11
Training loss: 3.4365224662100786
Validation loss: 3.17193150688469

Epoch: 6| Step: 12
Training loss: 2.963816187009724
Validation loss: 3.165398086714282

Epoch: 6| Step: 13
Training loss: 2.846971133772811
Validation loss: 3.1631450328109914

Epoch: 125| Step: 0
Training loss: 3.527721971953199
Validation loss: 3.161378308485026

Epoch: 6| Step: 1
Training loss: 3.800294443066735
Validation loss: 3.1601431744296864

Epoch: 6| Step: 2
Training loss: 2.248684392526524
Validation loss: 3.163411080144875

Epoch: 6| Step: 3
Training loss: 3.0060088062880728
Validation loss: 3.159286192057449

Epoch: 6| Step: 4
Training loss: 3.6178866343115934
Validation loss: 3.1603605797875605

Epoch: 6| Step: 5
Training loss: 4.423015757364264
Validation loss: 3.1628014242486646

Epoch: 6| Step: 6
Training loss: 3.5618815638168266
Validation loss: 3.162322262635636

Epoch: 6| Step: 7
Training loss: 2.363460313302801
Validation loss: 3.158530723132453

Epoch: 6| Step: 8
Training loss: 3.1279856343049226
Validation loss: 3.1589215210940234

Epoch: 6| Step: 9
Training loss: 3.828712760801484
Validation loss: 3.1570530912118597

Epoch: 6| Step: 10
Training loss: 3.3437226196308885
Validation loss: 3.1598135967009893

Epoch: 6| Step: 11
Training loss: 3.160331579750727
Validation loss: 3.16062506001107

Epoch: 6| Step: 12
Training loss: 3.723737433579758
Validation loss: 3.15913791662163

Epoch: 6| Step: 13
Training loss: 3.4460394475165734
Validation loss: 3.1587662634349365

Epoch: 126| Step: 0
Training loss: 2.7291503692218
Validation loss: 3.1582168401337043

Epoch: 6| Step: 1
Training loss: 3.257688963672438
Validation loss: 3.1617516460317034

Epoch: 6| Step: 2
Training loss: 3.6680375195313832
Validation loss: 3.1593847263493555

Epoch: 6| Step: 3
Training loss: 3.381096314271002
Validation loss: 3.1596035567504557

Epoch: 6| Step: 4
Training loss: 3.491567945033107
Validation loss: 3.159869288909275

Epoch: 6| Step: 5
Training loss: 3.329780560843916
Validation loss: 3.1589384468534942

Epoch: 6| Step: 6
Training loss: 3.0420678975831326
Validation loss: 3.1585971434969586

Epoch: 6| Step: 7
Training loss: 4.063368719091345
Validation loss: 3.1568860761704145

Epoch: 6| Step: 8
Training loss: 3.7010931565260137
Validation loss: 3.1567953347919113

Epoch: 6| Step: 9
Training loss: 4.136368777246167
Validation loss: 3.1551118250609025

Epoch: 6| Step: 10
Training loss: 2.615568747878352
Validation loss: 3.1550575358411925

Epoch: 6| Step: 11
Training loss: 3.0942630535071376
Validation loss: 3.155479214387206

Epoch: 6| Step: 12
Training loss: 3.690462248053634
Validation loss: 3.1540312472030876

Epoch: 6| Step: 13
Training loss: 2.953621797301845
Validation loss: 3.1550371180295995

Epoch: 127| Step: 0
Training loss: 2.468492904989776
Validation loss: 3.1562481789516155

Epoch: 6| Step: 1
Training loss: 3.563923735302461
Validation loss: 3.153969832007781

Epoch: 6| Step: 2
Training loss: 2.8352722564703634
Validation loss: 3.1561912239553336

Epoch: 6| Step: 3
Training loss: 1.9721981309783438
Validation loss: 3.153764041176164

Epoch: 6| Step: 4
Training loss: 3.260110241482808
Validation loss: 3.1526542689856916

Epoch: 6| Step: 5
Training loss: 3.1130530298840267
Validation loss: 3.1539585182096452

Epoch: 6| Step: 6
Training loss: 3.8816807899420174
Validation loss: 3.156105602709436

Epoch: 6| Step: 7
Training loss: 3.6610037393475308
Validation loss: 3.1528135062179694

Epoch: 6| Step: 8
Training loss: 3.1710430989868814
Validation loss: 3.1514156506411686

Epoch: 6| Step: 9
Training loss: 3.857081546498006
Validation loss: 3.153243462188683

Epoch: 6| Step: 10
Training loss: 2.888874575587622
Validation loss: 3.1533727906271247

Epoch: 6| Step: 11
Training loss: 4.43996285878361
Validation loss: 3.153300746848297

Epoch: 6| Step: 12
Training loss: 3.7395043041552847
Validation loss: 3.1527871347435217

Epoch: 6| Step: 13
Training loss: 4.4147907567796985
Validation loss: 3.155220077319944

Epoch: 128| Step: 0
Training loss: 2.5963758482389645
Validation loss: 3.1519410261047933

Epoch: 6| Step: 1
Training loss: 3.8529609787581562
Validation loss: 3.156088395328535

Epoch: 6| Step: 2
Training loss: 4.166826372264816
Validation loss: 3.157632226801169

Epoch: 6| Step: 3
Training loss: 3.3585519181543817
Validation loss: 3.156033235065527

Epoch: 6| Step: 4
Training loss: 2.6333717182436116
Validation loss: 3.1540320941551228

Epoch: 6| Step: 5
Training loss: 2.743545934783059
Validation loss: 3.151396009711742

Epoch: 6| Step: 6
Training loss: 2.8977318082015775
Validation loss: 3.1534934712746963

Epoch: 6| Step: 7
Training loss: 4.0931335450993505
Validation loss: 3.1543042498441745

Epoch: 6| Step: 8
Training loss: 3.6776721400071493
Validation loss: 3.155072262455181

Epoch: 6| Step: 9
Training loss: 3.725227420700312
Validation loss: 3.1509205779231717

Epoch: 6| Step: 10
Training loss: 3.714325909868664
Validation loss: 3.1492468710831587

Epoch: 6| Step: 11
Training loss: 3.7730531990431913
Validation loss: 3.148443626471742

Epoch: 6| Step: 12
Training loss: 2.6509226614291603
Validation loss: 3.148472471375533

Epoch: 6| Step: 13
Training loss: 2.9400344628630233
Validation loss: 3.1472113102059454

Epoch: 129| Step: 0
Training loss: 3.7621253755435364
Validation loss: 3.148320254426255

Epoch: 6| Step: 1
Training loss: 2.9416876629160247
Validation loss: 3.1470866198782628

Epoch: 6| Step: 2
Training loss: 3.452600775925291
Validation loss: 3.147155515375363

Epoch: 6| Step: 3
Training loss: 3.693353565197374
Validation loss: 3.1474522018605375

Epoch: 6| Step: 4
Training loss: 3.475010626248366
Validation loss: 3.1459685010474567

Epoch: 6| Step: 5
Training loss: 4.035354062869791
Validation loss: 3.145885214200887

Epoch: 6| Step: 6
Training loss: 2.6255735951390147
Validation loss: 3.144593540869687

Epoch: 6| Step: 7
Training loss: 3.490069060421124
Validation loss: 3.1478707579462157

Epoch: 6| Step: 8
Training loss: 3.138694055712696
Validation loss: 3.1476004454312556

Epoch: 6| Step: 9
Training loss: 3.323235013215882
Validation loss: 3.1487535628324466

Epoch: 6| Step: 10
Training loss: 2.7674815525174092
Validation loss: 3.150460385666941

Epoch: 6| Step: 11
Training loss: 3.7336797984892174
Validation loss: 3.1502744563255645

Epoch: 6| Step: 12
Training loss: 3.322428955512625
Validation loss: 3.152716387977923

Epoch: 6| Step: 13
Training loss: 3.727424825707264
Validation loss: 3.149548373813553

Epoch: 130| Step: 0
Training loss: 2.97584809468316
Validation loss: 3.1464614653963845

Epoch: 6| Step: 1
Training loss: 2.8826025909668385
Validation loss: 3.144939624620234

Epoch: 6| Step: 2
Training loss: 3.3712603725659918
Validation loss: 3.1436309240968923

Epoch: 6| Step: 3
Training loss: 3.3219228631605917
Validation loss: 3.1429949598408964

Epoch: 6| Step: 4
Training loss: 3.9033055308780034
Validation loss: 3.141352563974071

Epoch: 6| Step: 5
Training loss: 3.6625382561361914
Validation loss: 3.1434581835704227

Epoch: 6| Step: 6
Training loss: 3.500025067920831
Validation loss: 3.1422197373155316

Epoch: 6| Step: 7
Training loss: 3.3781967564812576
Validation loss: 3.1427540552787625

Epoch: 6| Step: 8
Training loss: 3.2429268970513565
Validation loss: 3.1409851938632176

Epoch: 6| Step: 9
Training loss: 3.8075781147809287
Validation loss: 3.1428374267341113

Epoch: 6| Step: 10
Training loss: 3.7326136309732676
Validation loss: 3.141658605732394

Epoch: 6| Step: 11
Training loss: 3.3893855066293104
Validation loss: 3.14477639200385

Epoch: 6| Step: 12
Training loss: 3.259732273084325
Validation loss: 3.1428332609057135

Epoch: 6| Step: 13
Training loss: 2.601230726193575
Validation loss: 3.1429537658863596

Epoch: 131| Step: 0
Training loss: 3.340362115977388
Validation loss: 3.144086017704455

Epoch: 6| Step: 1
Training loss: 3.3980590609603745
Validation loss: 3.1452865733921938

Epoch: 6| Step: 2
Training loss: 4.079152646428693
Validation loss: 3.14149363417087

Epoch: 6| Step: 3
Training loss: 3.158852891955809
Validation loss: 3.141961729267664

Epoch: 6| Step: 4
Training loss: 3.206862934263077
Validation loss: 3.142071542583706

Epoch: 6| Step: 5
Training loss: 3.0417779005082717
Validation loss: 3.1405906179471827

Epoch: 6| Step: 6
Training loss: 2.4768768977413758
Validation loss: 3.1411021092692075

Epoch: 6| Step: 7
Training loss: 3.681399973484341
Validation loss: 3.1413279357768866

Epoch: 6| Step: 8
Training loss: 3.607980433967131
Validation loss: 3.1388520017704558

Epoch: 6| Step: 9
Training loss: 4.059252570745687
Validation loss: 3.139796300791113

Epoch: 6| Step: 10
Training loss: 3.308150981294394
Validation loss: 3.140203650228134

Epoch: 6| Step: 11
Training loss: 3.4611028283028427
Validation loss: 3.1408128898005185

Epoch: 6| Step: 12
Training loss: 2.8192062110243588
Validation loss: 3.1387410442294295

Epoch: 6| Step: 13
Training loss: 3.7090278289483196
Validation loss: 3.1394217421795587

Epoch: 132| Step: 0
Training loss: 3.251511149113227
Validation loss: 3.140474385536722

Epoch: 6| Step: 1
Training loss: 3.152848327415005
Validation loss: 3.1390023641293285

Epoch: 6| Step: 2
Training loss: 3.7627722353365387
Validation loss: 3.1376408150748705

Epoch: 6| Step: 3
Training loss: 3.743788725026983
Validation loss: 3.1378681929849845

Epoch: 6| Step: 4
Training loss: 3.297976919857993
Validation loss: 3.137831751272372

Epoch: 6| Step: 5
Training loss: 2.7776719984470866
Validation loss: 3.1368541361136364

Epoch: 6| Step: 6
Training loss: 3.5291169062097265
Validation loss: 3.1386636498984113

Epoch: 6| Step: 7
Training loss: 3.363903736810092
Validation loss: 3.1349705498754235

Epoch: 6| Step: 8
Training loss: 3.8470624591386815
Validation loss: 3.1355801014645994

Epoch: 6| Step: 9
Training loss: 3.303046935285913
Validation loss: 3.1360617402531505

Epoch: 6| Step: 10
Training loss: 3.494563922008708
Validation loss: 3.1384113436245005

Epoch: 6| Step: 11
Training loss: 3.2318420812154542
Validation loss: 3.136878225719955

Epoch: 6| Step: 12
Training loss: 3.5959855797025537
Validation loss: 3.1363980757107766

Epoch: 6| Step: 13
Training loss: 2.656007463938785
Validation loss: 3.1376232531392385

Epoch: 133| Step: 0
Training loss: 3.003638127815775
Validation loss: 3.1372318646282147

Epoch: 6| Step: 1
Training loss: 3.310232141888378
Validation loss: 3.1391752853315964

Epoch: 6| Step: 2
Training loss: 3.734437694581924
Validation loss: 3.1372319880203463

Epoch: 6| Step: 3
Training loss: 2.8128948358377905
Validation loss: 3.13625781443743

Epoch: 6| Step: 4
Training loss: 2.851137396074406
Validation loss: 3.13676316340912

Epoch: 6| Step: 5
Training loss: 2.774773246504846
Validation loss: 3.1382849647706474

Epoch: 6| Step: 6
Training loss: 3.6932195498799856
Validation loss: 3.1398137525928895

Epoch: 6| Step: 7
Training loss: 3.3449981356445955
Validation loss: 3.1401725814181054

Epoch: 6| Step: 8
Training loss: 3.31849214805742
Validation loss: 3.138215635994219

Epoch: 6| Step: 9
Training loss: 3.5884544830730962
Validation loss: 3.138366378462862

Epoch: 6| Step: 10
Training loss: 3.825942308628058
Validation loss: 3.1366474650901375

Epoch: 6| Step: 11
Training loss: 4.3672637113905886
Validation loss: 3.1348075390845516

Epoch: 6| Step: 12
Training loss: 2.934152521996576
Validation loss: 3.135050142681435

Epoch: 6| Step: 13
Training loss: 3.5803720673024784
Validation loss: 3.136958000584318

Epoch: 134| Step: 0
Training loss: 2.674224890953455
Validation loss: 3.137558929892677

Epoch: 6| Step: 1
Training loss: 3.465124486583351
Validation loss: 3.138032376426381

Epoch: 6| Step: 2
Training loss: 3.7171418375206753
Validation loss: 3.1374350203396495

Epoch: 6| Step: 3
Training loss: 3.6600343079339988
Validation loss: 3.138216103266868

Epoch: 6| Step: 4
Training loss: 3.470253833204441
Validation loss: 3.1412419763225126

Epoch: 6| Step: 5
Training loss: 3.1612101944015802
Validation loss: 3.1371713839217

Epoch: 6| Step: 6
Training loss: 2.7738361770562436
Validation loss: 3.139309634551477

Epoch: 6| Step: 7
Training loss: 4.419486003696044
Validation loss: 3.136016966210024

Epoch: 6| Step: 8
Training loss: 3.631713044522701
Validation loss: 3.135110090270653

Epoch: 6| Step: 9
Training loss: 3.500087055758497
Validation loss: 3.1340262790501168

Epoch: 6| Step: 10
Training loss: 3.7646937821523365
Validation loss: 3.133946247957404

Epoch: 6| Step: 11
Training loss: 2.517163108551226
Validation loss: 3.131259928234751

Epoch: 6| Step: 12
Training loss: 3.2093885263605535
Validation loss: 3.132929885690801

Epoch: 6| Step: 13
Training loss: 2.5785943731110637
Validation loss: 3.1321570273019654

Epoch: 135| Step: 0
Training loss: 2.7824173095699947
Validation loss: 3.130856464877902

Epoch: 6| Step: 1
Training loss: 3.212896116304198
Validation loss: 3.131083233398678

Epoch: 6| Step: 2
Training loss: 3.528496538032692
Validation loss: 3.132036580022917

Epoch: 6| Step: 3
Training loss: 3.8673371873650177
Validation loss: 3.1293779581178196

Epoch: 6| Step: 4
Training loss: 3.222962816857752
Validation loss: 3.130668503254576

Epoch: 6| Step: 5
Training loss: 2.970082997661932
Validation loss: 3.1296486453063257

Epoch: 6| Step: 6
Training loss: 3.4528238156530544
Validation loss: 3.130761690368477

Epoch: 6| Step: 7
Training loss: 4.1224637181598025
Validation loss: 3.1289504613186905

Epoch: 6| Step: 8
Training loss: 2.020776833075399
Validation loss: 3.130603611285403

Epoch: 6| Step: 9
Training loss: 3.099465840987876
Validation loss: 3.130044497377053

Epoch: 6| Step: 10
Training loss: 3.3149241088649646
Validation loss: 3.1291593947724183

Epoch: 6| Step: 11
Training loss: 3.4462272139091024
Validation loss: 3.1294502794258965

Epoch: 6| Step: 12
Training loss: 3.6847161598569484
Validation loss: 3.1296932213013986

Epoch: 6| Step: 13
Training loss: 4.581591859060854
Validation loss: 3.1262185754158653

Epoch: 136| Step: 0
Training loss: 3.7937243540869545
Validation loss: 3.128806970535577

Epoch: 6| Step: 1
Training loss: 4.061704117502254
Validation loss: 3.130141647458723

Epoch: 6| Step: 2
Training loss: 3.091939685484948
Validation loss: 3.13170763807357

Epoch: 6| Step: 3
Training loss: 3.2379723046044946
Validation loss: 3.1299005079662656

Epoch: 6| Step: 4
Training loss: 2.642356350115111
Validation loss: 3.129667334896346

Epoch: 6| Step: 5
Training loss: 2.9616326394288297
Validation loss: 3.1310629245330848

Epoch: 6| Step: 6
Training loss: 3.168827340350316
Validation loss: 3.1309731296680345

Epoch: 6| Step: 7
Training loss: 3.9301968617915977
Validation loss: 3.1329827532310057

Epoch: 6| Step: 8
Training loss: 3.3429521696210407
Validation loss: 3.1332684179199886

Epoch: 6| Step: 9
Training loss: 4.052329140131751
Validation loss: 3.131339117585694

Epoch: 6| Step: 10
Training loss: 3.0324758037158466
Validation loss: 3.129342082747144

Epoch: 6| Step: 11
Training loss: 2.9830213742387164
Validation loss: 3.127903278345853

Epoch: 6| Step: 12
Training loss: 3.5966273191867013
Validation loss: 3.1285327819943194

Epoch: 6| Step: 13
Training loss: 2.8816866860283588
Validation loss: 3.1263255033851696

Epoch: 137| Step: 0
Training loss: 3.3959957778239427
Validation loss: 3.1267817399564266

Epoch: 6| Step: 1
Training loss: 3.447063390402917
Validation loss: 3.126330842512495

Epoch: 6| Step: 2
Training loss: 3.891373895473494
Validation loss: 3.1252617412595343

Epoch: 6| Step: 3
Training loss: 3.0703134318343053
Validation loss: 3.126826768404726

Epoch: 6| Step: 4
Training loss: 3.266600102764995
Validation loss: 3.124860346965368

Epoch: 6| Step: 5
Training loss: 3.5916137980547744
Validation loss: 3.1273809899145806

Epoch: 6| Step: 6
Training loss: 3.1620677547060185
Validation loss: 3.1255856709641527

Epoch: 6| Step: 7
Training loss: 3.5112247310501896
Validation loss: 3.1275975922641828

Epoch: 6| Step: 8
Training loss: 3.4972697917223585
Validation loss: 3.127005750895264

Epoch: 6| Step: 9
Training loss: 3.1292247443432935
Validation loss: 3.1260399611817586

Epoch: 6| Step: 10
Training loss: 3.4299440049029983
Validation loss: 3.1269456889281173

Epoch: 6| Step: 11
Training loss: 2.7547164699093525
Validation loss: 3.1267001902445273

Epoch: 6| Step: 12
Training loss: 3.7515781896375113
Validation loss: 3.1296664829889904

Epoch: 6| Step: 13
Training loss: 3.1567140747935976
Validation loss: 3.128635415000014

Epoch: 138| Step: 0
Training loss: 4.262181048052388
Validation loss: 3.1355562896814675

Epoch: 6| Step: 1
Training loss: 3.7294747990724515
Validation loss: 3.139517592807106

Epoch: 6| Step: 2
Training loss: 3.4951060002615035
Validation loss: 3.1378951473576273

Epoch: 6| Step: 3
Training loss: 3.3251343664110027
Validation loss: 3.1404673831125054

Epoch: 6| Step: 4
Training loss: 3.5886009148669737
Validation loss: 3.12453608197001

Epoch: 6| Step: 5
Training loss: 2.846552882306524
Validation loss: 3.1218230425918643

Epoch: 6| Step: 6
Training loss: 2.707395762993354
Validation loss: 3.1211464056949048

Epoch: 6| Step: 7
Training loss: 3.8826653742403807
Validation loss: 3.1231765743225615

Epoch: 6| Step: 8
Training loss: 3.5630350882242223
Validation loss: 3.1200667871537218

Epoch: 6| Step: 9
Training loss: 2.3225276147947898
Validation loss: 3.1241511974407383

Epoch: 6| Step: 10
Training loss: 2.588845269086298
Validation loss: 3.12387640329511

Epoch: 6| Step: 11
Training loss: 3.0281297807685266
Validation loss: 3.123911561816084

Epoch: 6| Step: 12
Training loss: 3.744610537559671
Validation loss: 3.1309494416959334

Epoch: 6| Step: 13
Training loss: 4.001034364475988
Validation loss: 3.135334191371899

Epoch: 139| Step: 0
Training loss: 4.113746319713818
Validation loss: 3.1234581176784513

Epoch: 6| Step: 1
Training loss: 2.6319016145852037
Validation loss: 3.120564355908213

Epoch: 6| Step: 2
Training loss: 2.954664364002492
Validation loss: 3.1221371603698196

Epoch: 6| Step: 3
Training loss: 3.0036387628284995
Validation loss: 3.1197846394586985

Epoch: 6| Step: 4
Training loss: 3.5225026313549903
Validation loss: 3.120663539423507

Epoch: 6| Step: 5
Training loss: 3.641329848530053
Validation loss: 3.1165509181112623

Epoch: 6| Step: 6
Training loss: 3.3945888430996014
Validation loss: 3.122271181890794

Epoch: 6| Step: 7
Training loss: 3.4341507287424307
Validation loss: 3.1208695266416564

Epoch: 6| Step: 8
Training loss: 3.1290059163082438
Validation loss: 3.125293097748504

Epoch: 6| Step: 9
Training loss: 4.08469933737574
Validation loss: 3.1244947504941907

Epoch: 6| Step: 10
Training loss: 2.92141409926006
Validation loss: 3.1319978980745415

Epoch: 6| Step: 11
Training loss: 2.843412945233953
Validation loss: 3.130111507471393

Epoch: 6| Step: 12
Training loss: 3.976286932909539
Validation loss: 3.130650430529189

Epoch: 6| Step: 13
Training loss: 3.130230303204324
Validation loss: 3.1269082033139166

Epoch: 140| Step: 0
Training loss: 3.855768657796244
Validation loss: 3.117839378168201

Epoch: 6| Step: 1
Training loss: 3.9736108523831013
Validation loss: 3.112257752074473

Epoch: 6| Step: 2
Training loss: 3.01260651839366
Validation loss: 3.1185818875877787

Epoch: 6| Step: 3
Training loss: 3.9184705083977733
Validation loss: 3.116621379469528

Epoch: 6| Step: 4
Training loss: 3.7598256133607184
Validation loss: 3.11895896696038

Epoch: 6| Step: 5
Training loss: 4.291418765911113
Validation loss: 3.1153954672735673

Epoch: 6| Step: 6
Training loss: 2.384230295092448
Validation loss: 3.115668178086403

Epoch: 6| Step: 7
Training loss: 2.8305665325949816
Validation loss: 3.1185711959438

Epoch: 6| Step: 8
Training loss: 3.675186157701703
Validation loss: 3.114749530458883

Epoch: 6| Step: 9
Training loss: 2.930096488379415
Validation loss: 3.1168068471349857

Epoch: 6| Step: 10
Training loss: 3.613635962318847
Validation loss: 3.1174224699985524

Epoch: 6| Step: 11
Training loss: 3.2257996920545575
Validation loss: 3.1173742876084365

Epoch: 6| Step: 12
Training loss: 2.513093610641993
Validation loss: 3.1186099013954447

Epoch: 6| Step: 13
Training loss: 1.8284735714111038
Validation loss: 3.1157195258764805

Epoch: 141| Step: 0
Training loss: 3.650984534643305
Validation loss: 3.1142898741235103

Epoch: 6| Step: 1
Training loss: 3.3242768440594275
Validation loss: 3.1161961967066216

Epoch: 6| Step: 2
Training loss: 3.3156403824344225
Validation loss: 3.11482804491089

Epoch: 6| Step: 3
Training loss: 2.6362770897462386
Validation loss: 3.117117230730531

Epoch: 6| Step: 4
Training loss: 4.016056972677067
Validation loss: 3.1197468894812816

Epoch: 6| Step: 5
Training loss: 3.4827374771546924
Validation loss: 3.1193127512185588

Epoch: 6| Step: 6
Training loss: 3.042245957763655
Validation loss: 3.120551548212243

Epoch: 6| Step: 7
Training loss: 2.8581323476997653
Validation loss: 3.1192242955602505

Epoch: 6| Step: 8
Training loss: 3.2451605344776473
Validation loss: 3.1212310672508607

Epoch: 6| Step: 9
Training loss: 2.8314804488619725
Validation loss: 3.118361367272679

Epoch: 6| Step: 10
Training loss: 3.5928727115769408
Validation loss: 3.1217598539081837

Epoch: 6| Step: 11
Training loss: 3.375680360387786
Validation loss: 3.1169986729857104

Epoch: 6| Step: 12
Training loss: 4.389929230973331
Validation loss: 3.1201981730875152

Epoch: 6| Step: 13
Training loss: 2.7716842052419404
Validation loss: 3.118298588564975

Epoch: 142| Step: 0
Training loss: 4.079762097322827
Validation loss: 3.1154494272657924

Epoch: 6| Step: 1
Training loss: 2.7518321782994715
Validation loss: 3.1157191539669977

Epoch: 6| Step: 2
Training loss: 3.788840124152662
Validation loss: 3.1231815519163844

Epoch: 6| Step: 3
Training loss: 3.615467296909822
Validation loss: 3.118131902587238

Epoch: 6| Step: 4
Training loss: 3.3608630765782226
Validation loss: 3.118662215960842

Epoch: 6| Step: 5
Training loss: 3.4515002817095515
Validation loss: 3.117781404133872

Epoch: 6| Step: 6
Training loss: 3.1071898483456253
Validation loss: 3.118886787061215

Epoch: 6| Step: 7
Training loss: 3.344783159876987
Validation loss: 3.1147387137227684

Epoch: 6| Step: 8
Training loss: 3.460378080670036
Validation loss: 3.1173860623053162

Epoch: 6| Step: 9
Training loss: 2.9541075348596655
Validation loss: 3.1138192032150562

Epoch: 6| Step: 10
Training loss: 3.7772663664756427
Validation loss: 3.1160150704467835

Epoch: 6| Step: 11
Training loss: 3.2028308268117724
Validation loss: 3.113733559612716

Epoch: 6| Step: 12
Training loss: 2.869128825122519
Validation loss: 3.111970741952902

Epoch: 6| Step: 13
Training loss: 2.9505861055719156
Validation loss: 3.110716601805522

Epoch: 143| Step: 0
Training loss: 3.8843569840299597
Validation loss: 3.111515981163632

Epoch: 6| Step: 1
Training loss: 4.063329054527961
Validation loss: 3.109094655036191

Epoch: 6| Step: 2
Training loss: 3.057111085999112
Validation loss: 3.1097519822743065

Epoch: 6| Step: 3
Training loss: 3.4318632206725947
Validation loss: 3.1111826307660166

Epoch: 6| Step: 4
Training loss: 2.7303123593054734
Validation loss: 3.1110584403326844

Epoch: 6| Step: 5
Training loss: 2.7684535847390492
Validation loss: 3.1081120723350937

Epoch: 6| Step: 6
Training loss: 3.8453033533960195
Validation loss: 3.1090280000453174

Epoch: 6| Step: 7
Training loss: 3.5663367240621757
Validation loss: 3.1065755563952626

Epoch: 6| Step: 8
Training loss: 4.076858967081837
Validation loss: 3.106763576979795

Epoch: 6| Step: 9
Training loss: 2.544564351565472
Validation loss: 3.1085800677578366

Epoch: 6| Step: 10
Training loss: 2.739216730418317
Validation loss: 3.106853044233914

Epoch: 6| Step: 11
Training loss: 2.8129042440878558
Validation loss: 3.1077971787610887

Epoch: 6| Step: 12
Training loss: 4.028191877687407
Validation loss: 3.108193463099813

Epoch: 6| Step: 13
Training loss: 2.6138454677782788
Validation loss: 3.1067012446971662

Epoch: 144| Step: 0
Training loss: 2.7553224209466998
Validation loss: 3.107162724965914

Epoch: 6| Step: 1
Training loss: 2.9817824362094574
Validation loss: 3.105698448659159

Epoch: 6| Step: 2
Training loss: 3.3675757801617228
Validation loss: 3.106671374071528

Epoch: 6| Step: 3
Training loss: 3.4569835250060255
Validation loss: 3.107491810767832

Epoch: 6| Step: 4
Training loss: 3.3560558866773884
Validation loss: 3.1069210916870924

Epoch: 6| Step: 5
Training loss: 3.3390534118328734
Validation loss: 3.108977334172022

Epoch: 6| Step: 6
Training loss: 3.481608571294794
Validation loss: 3.1057617775713284

Epoch: 6| Step: 7
Training loss: 3.6123254120029316
Validation loss: 3.109731850666604

Epoch: 6| Step: 8
Training loss: 3.5964255283281688
Validation loss: 3.105867556757354

Epoch: 6| Step: 9
Training loss: 2.8249361385452825
Validation loss: 3.1058964842404713

Epoch: 6| Step: 10
Training loss: 3.6168936492665886
Validation loss: 3.1060995550823844

Epoch: 6| Step: 11
Training loss: 3.3012076740086487
Validation loss: 3.104500115018316

Epoch: 6| Step: 12
Training loss: 3.589879480958264
Validation loss: 3.1051702870757

Epoch: 6| Step: 13
Training loss: 3.890879672497531
Validation loss: 3.1043345066065426

Epoch: 145| Step: 0
Training loss: 3.2880997143403836
Validation loss: 3.1042791022610867

Epoch: 6| Step: 1
Training loss: 4.2511604071275535
Validation loss: 3.103634204663094

Epoch: 6| Step: 2
Training loss: 3.088852830793778
Validation loss: 3.1027884905339933

Epoch: 6| Step: 3
Training loss: 4.06778971272762
Validation loss: 3.103603997239119

Epoch: 6| Step: 4
Training loss: 3.025350118505059
Validation loss: 3.1005455005538805

Epoch: 6| Step: 5
Training loss: 3.5451565919625674
Validation loss: 3.1024477132409287

Epoch: 6| Step: 6
Training loss: 2.8378355121971235
Validation loss: 3.103177967732091

Epoch: 6| Step: 7
Training loss: 2.221780453587089
Validation loss: 3.102440764637685

Epoch: 6| Step: 8
Training loss: 4.24590822602401
Validation loss: 3.101627535045305

Epoch: 6| Step: 9
Training loss: 3.5908727655011083
Validation loss: 3.1022439372721102

Epoch: 6| Step: 10
Training loss: 2.325703430411545
Validation loss: 3.100056106041135

Epoch: 6| Step: 11
Training loss: 4.072864632953
Validation loss: 3.1029312693752438

Epoch: 6| Step: 12
Training loss: 2.7123340889955183
Validation loss: 3.102259868236365

Epoch: 6| Step: 13
Training loss: 2.455462368778745
Validation loss: 3.1012510250374703

Epoch: 146| Step: 0
Training loss: 3.8049947939622832
Validation loss: 3.102850188389999

Epoch: 6| Step: 1
Training loss: 3.7805444989279025
Validation loss: 3.1013936167569325

Epoch: 6| Step: 2
Training loss: 3.431322129677887
Validation loss: 3.1006661070275454

Epoch: 6| Step: 3
Training loss: 3.372024354640846
Validation loss: 3.100685945279878

Epoch: 6| Step: 4
Training loss: 3.405750763031214
Validation loss: 3.1024371395247843

Epoch: 6| Step: 5
Training loss: 3.691134585117652
Validation loss: 3.103507523149321

Epoch: 6| Step: 6
Training loss: 2.2401429534323793
Validation loss: 3.100453201203204

Epoch: 6| Step: 7
Training loss: 3.5373801976059274
Validation loss: 3.1001175605746463

Epoch: 6| Step: 8
Training loss: 2.934340218204821
Validation loss: 3.098232317362267

Epoch: 6| Step: 9
Training loss: 3.490390938447761
Validation loss: 3.0997784249241302

Epoch: 6| Step: 10
Training loss: 3.5734547616719343
Validation loss: 3.0987864649946233

Epoch: 6| Step: 11
Training loss: 2.9881170489507234
Validation loss: 3.099411652353636

Epoch: 6| Step: 12
Training loss: 2.9116534791533857
Validation loss: 3.098562670989578

Epoch: 6| Step: 13
Training loss: 3.6447454228083638
Validation loss: 3.0989009568874724

Epoch: 147| Step: 0
Training loss: 3.8147561323582972
Validation loss: 3.098774101728385

Epoch: 6| Step: 1
Training loss: 3.423299693159302
Validation loss: 3.0961959432623245

Epoch: 6| Step: 2
Training loss: 3.1421274415607
Validation loss: 3.0996306161259755

Epoch: 6| Step: 3
Training loss: 3.060285896708392
Validation loss: 3.0987919930397596

Epoch: 6| Step: 4
Training loss: 3.667756453312825
Validation loss: 3.098570396909287

Epoch: 6| Step: 5
Training loss: 3.584801454459578
Validation loss: 3.098668943304858

Epoch: 6| Step: 6
Training loss: 3.559619743098145
Validation loss: 3.0982649593711034

Epoch: 6| Step: 7
Training loss: 2.946496214647514
Validation loss: 3.096039618469667

Epoch: 6| Step: 8
Training loss: 3.3419943505358702
Validation loss: 3.0968871474709467

Epoch: 6| Step: 9
Training loss: 2.9435779108175857
Validation loss: 3.0989564681398702

Epoch: 6| Step: 10
Training loss: 3.8503899017670773
Validation loss: 3.097405595901514

Epoch: 6| Step: 11
Training loss: 2.9172316594349463
Validation loss: 3.0988856531052997

Epoch: 6| Step: 12
Training loss: 3.2774752748489338
Validation loss: 3.0969080215103686

Epoch: 6| Step: 13
Training loss: 3.231301731898208
Validation loss: 3.0968867021080078

Epoch: 148| Step: 0
Training loss: 3.79814082893311
Validation loss: 3.0975422922736686

Epoch: 6| Step: 1
Training loss: 2.9119824715076286
Validation loss: 3.0966552040481985

Epoch: 6| Step: 2
Training loss: 4.076825983693486
Validation loss: 3.0941885575916532

Epoch: 6| Step: 3
Training loss: 2.6328939996890557
Validation loss: 3.0946536964549796

Epoch: 6| Step: 4
Training loss: 2.626115743481776
Validation loss: 3.0947227701281106

Epoch: 6| Step: 5
Training loss: 3.140235686963279
Validation loss: 3.0956028452703133

Epoch: 6| Step: 6
Training loss: 2.3179176378930957
Validation loss: 3.094355222673401

Epoch: 6| Step: 7
Training loss: 4.099651712650608
Validation loss: 3.0928122287352795

Epoch: 6| Step: 8
Training loss: 2.939783385724273
Validation loss: 3.0938911965107523

Epoch: 6| Step: 9
Training loss: 3.5412313455560938
Validation loss: 3.0946525847291815

Epoch: 6| Step: 10
Training loss: 3.265309587788203
Validation loss: 3.091938622531529

Epoch: 6| Step: 11
Training loss: 3.855727599632889
Validation loss: 3.0924337973755383

Epoch: 6| Step: 12
Training loss: 3.321225460422698
Validation loss: 3.0932777220808845

Epoch: 6| Step: 13
Training loss: 4.107597866088182
Validation loss: 3.091789558351252

Epoch: 149| Step: 0
Training loss: 2.9593298581314853
Validation loss: 3.096191159092554

Epoch: 6| Step: 1
Training loss: 3.0966758379134856
Validation loss: 3.0963893738553954

Epoch: 6| Step: 2
Training loss: 3.1723611393352202
Validation loss: 3.094631857845712

Epoch: 6| Step: 3
Training loss: 2.4406211628315906
Validation loss: 3.0944932757606742

Epoch: 6| Step: 4
Training loss: 3.7168040593729827
Validation loss: 3.0932996581001633

Epoch: 6| Step: 5
Training loss: 3.4068915086765075
Validation loss: 3.093646547757446

Epoch: 6| Step: 6
Training loss: 4.104316179421266
Validation loss: 3.095011643112447

Epoch: 6| Step: 7
Training loss: 3.0443997232102453
Validation loss: 3.0999419809946382

Epoch: 6| Step: 8
Training loss: 3.949178663403128
Validation loss: 3.096189403735921

Epoch: 6| Step: 9
Training loss: 3.025585111667549
Validation loss: 3.0927911612706254

Epoch: 6| Step: 10
Training loss: 3.0736717891167094
Validation loss: 3.0953964819078794

Epoch: 6| Step: 11
Training loss: 3.209457910464091
Validation loss: 3.0955201594609267

Epoch: 6| Step: 12
Training loss: 3.8250917211767668
Validation loss: 3.0923782925585863

Epoch: 6| Step: 13
Training loss: 3.5961059808782063
Validation loss: 3.0929396956060464

Epoch: 150| Step: 0
Training loss: 3.0509394215158987
Validation loss: 3.0932269208852294

Epoch: 6| Step: 1
Training loss: 3.506394811349555
Validation loss: 3.089676901299435

Epoch: 6| Step: 2
Training loss: 3.5874879099147052
Validation loss: 3.0900261863235823

Epoch: 6| Step: 3
Training loss: 2.9917444443930434
Validation loss: 3.0895077118809917

Epoch: 6| Step: 4
Training loss: 3.737285549173626
Validation loss: 3.089916593405157

Epoch: 6| Step: 5
Training loss: 4.0495954523429525
Validation loss: 3.0905924370281213

Epoch: 6| Step: 6
Training loss: 3.3596378667140576
Validation loss: 3.087500544562891

Epoch: 6| Step: 7
Training loss: 3.509807741382671
Validation loss: 3.089426552436573

Epoch: 6| Step: 8
Training loss: 3.0186009719740916
Validation loss: 3.090163861207127

Epoch: 6| Step: 9
Training loss: 3.588650477088024
Validation loss: 3.090031354209937

Epoch: 6| Step: 10
Training loss: 2.853968945265444
Validation loss: 3.08746400489731

Epoch: 6| Step: 11
Training loss: 2.7008071399404514
Validation loss: 3.0868883455461127

Epoch: 6| Step: 12
Training loss: 3.3729942861056794
Validation loss: 3.088288643561353

Epoch: 6| Step: 13
Training loss: 3.2600700186014535
Validation loss: 3.0891859791545575

Epoch: 151| Step: 0
Training loss: 3.608043342431498
Validation loss: 3.0878060738391993

Epoch: 6| Step: 1
Training loss: 4.846509184519799
Validation loss: 3.086874924742348

Epoch: 6| Step: 2
Training loss: 3.308310972918095
Validation loss: 3.088359131304497

Epoch: 6| Step: 3
Training loss: 2.398143240804846
Validation loss: 3.0863654275448136

Epoch: 6| Step: 4
Training loss: 3.243932488807891
Validation loss: 3.086618488979576

Epoch: 6| Step: 5
Training loss: 3.586865539804185
Validation loss: 3.0860745556491183

Epoch: 6| Step: 6
Training loss: 3.2885156027278883
Validation loss: 3.0860217069303

Epoch: 6| Step: 7
Training loss: 3.2337926073072767
Validation loss: 3.0858250178082494

Epoch: 6| Step: 8
Training loss: 2.921825224916524
Validation loss: 3.0837202483456365

Epoch: 6| Step: 9
Training loss: 2.980290518814917
Validation loss: 3.0858916256787867

Epoch: 6| Step: 10
Training loss: 3.6648157968066997
Validation loss: 3.084274744148499

Epoch: 6| Step: 11
Training loss: 2.950789562533797
Validation loss: 3.0860341810972494

Epoch: 6| Step: 12
Training loss: 3.1535327659055086
Validation loss: 3.0829349921236697

Epoch: 6| Step: 13
Training loss: 2.867334180193045
Validation loss: 3.0847433608222183

Epoch: 152| Step: 0
Training loss: 3.032326418695963
Validation loss: 3.084104252571692

Epoch: 6| Step: 1
Training loss: 3.3791176437666444
Validation loss: 3.0870442459972964

Epoch: 6| Step: 2
Training loss: 3.509750544494939
Validation loss: 3.0849878987468387

Epoch: 6| Step: 3
Training loss: 3.5622384494002843
Validation loss: 3.0874547731786075

Epoch: 6| Step: 4
Training loss: 3.496331881292951
Validation loss: 3.0857659222241587

Epoch: 6| Step: 5
Training loss: 3.7662603704928217
Validation loss: 3.0851061767574324

Epoch: 6| Step: 6
Training loss: 2.969259118043255
Validation loss: 3.0905554154755124

Epoch: 6| Step: 7
Training loss: 3.701878591416907
Validation loss: 3.0878055590862363

Epoch: 6| Step: 8
Training loss: 3.916973440182012
Validation loss: 3.0834612272477964

Epoch: 6| Step: 9
Training loss: 3.318260797627175
Validation loss: 3.084424465734604

Epoch: 6| Step: 10
Training loss: 2.606146728518724
Validation loss: 3.08395993872876

Epoch: 6| Step: 11
Training loss: 2.996871429536699
Validation loss: 3.0872178565592763

Epoch: 6| Step: 12
Training loss: 3.2485615407978017
Validation loss: 3.0839258559751057

Epoch: 6| Step: 13
Training loss: 2.8243736551732783
Validation loss: 3.080751794788426

Epoch: 153| Step: 0
Training loss: 3.526911002446368
Validation loss: 3.080895485876583

Epoch: 6| Step: 1
Training loss: 3.210444725816723
Validation loss: 3.0823785419908662

Epoch: 6| Step: 2
Training loss: 3.187733211587707
Validation loss: 3.0809786790038287

Epoch: 6| Step: 3
Training loss: 3.210300948631784
Validation loss: 3.080842480081989

Epoch: 6| Step: 4
Training loss: 3.598071477166256
Validation loss: 3.0794657990455816

Epoch: 6| Step: 5
Training loss: 3.58872103231306
Validation loss: 3.0801231054355545

Epoch: 6| Step: 6
Training loss: 3.2430324694301658
Validation loss: 3.078209863715824

Epoch: 6| Step: 7
Training loss: 3.6780896129218488
Validation loss: 3.078143750905005

Epoch: 6| Step: 8
Training loss: 3.5491124292764424
Validation loss: 3.0790461312413044

Epoch: 6| Step: 9
Training loss: 3.2218849692574305
Validation loss: 3.0793798710175033

Epoch: 6| Step: 10
Training loss: 2.2028196948460645
Validation loss: 3.0787961844499723

Epoch: 6| Step: 11
Training loss: 3.4402657219922763
Validation loss: 3.076601200852679

Epoch: 6| Step: 12
Training loss: 3.7851814450270864
Validation loss: 3.0798510720591423

Epoch: 6| Step: 13
Training loss: 2.8381312268963153
Validation loss: 3.0798040632451524

Epoch: 154| Step: 0
Training loss: 3.4692480056272053
Validation loss: 3.081998786249456

Epoch: 6| Step: 1
Training loss: 3.4966339546421423
Validation loss: 3.0796187845616827

Epoch: 6| Step: 2
Training loss: 3.260854640871255
Validation loss: 3.0841134012205944

Epoch: 6| Step: 3
Training loss: 2.603111378793238
Validation loss: 3.0823198219751182

Epoch: 6| Step: 4
Training loss: 3.0711646996383455
Validation loss: 3.0873337353032664

Epoch: 6| Step: 5
Training loss: 3.883214304222667
Validation loss: 3.0818321483648687

Epoch: 6| Step: 6
Training loss: 3.301339403622438
Validation loss: 3.0792280208986846

Epoch: 6| Step: 7
Training loss: 4.173971613701083
Validation loss: 3.079850374515318

Epoch: 6| Step: 8
Training loss: 3.581341359835578
Validation loss: 3.07785510223982

Epoch: 6| Step: 9
Training loss: 1.7814868970245106
Validation loss: 3.0774442641355413

Epoch: 6| Step: 10
Training loss: 3.1637892616877323
Validation loss: 3.079579740561852

Epoch: 6| Step: 11
Training loss: 3.2238591209187106
Validation loss: 3.07802034046775

Epoch: 6| Step: 12
Training loss: 3.373410451055291
Validation loss: 3.0761125122947117

Epoch: 6| Step: 13
Training loss: 3.9963459968193376
Validation loss: 3.0794597850940577

Epoch: 155| Step: 0
Training loss: 2.874017796460655
Validation loss: 3.076208000433253

Epoch: 6| Step: 1
Training loss: 3.2803671966263392
Validation loss: 3.0767528781533935

Epoch: 6| Step: 2
Training loss: 3.340749517391518
Validation loss: 3.073088692670838

Epoch: 6| Step: 3
Training loss: 3.3712122820086856
Validation loss: 3.0761274535029766

Epoch: 6| Step: 4
Training loss: 3.829935572109697
Validation loss: 3.075492476497853

Epoch: 6| Step: 5
Training loss: 3.5208167502710586
Validation loss: 3.0740685296796966

Epoch: 6| Step: 6
Training loss: 3.4960026393505057
Validation loss: 3.0723987813835794

Epoch: 6| Step: 7
Training loss: 3.1532360832374824
Validation loss: 3.0750523980004383

Epoch: 6| Step: 8
Training loss: 3.129600647870096
Validation loss: 3.0768175877265227

Epoch: 6| Step: 9
Training loss: 3.8205483954681503
Validation loss: 3.0777709734027905

Epoch: 6| Step: 10
Training loss: 3.7501046484014817
Validation loss: 3.0760228251834194

Epoch: 6| Step: 11
Training loss: 2.968857291441163
Validation loss: 3.0818160885106374

Epoch: 6| Step: 12
Training loss: 2.4499323777189255
Validation loss: 3.076432611471157

Epoch: 6| Step: 13
Training loss: 3.5797579175199647
Validation loss: 3.074355097268866

Epoch: 156| Step: 0
Training loss: 2.7499033304042895
Validation loss: 3.0745498952749717

Epoch: 6| Step: 1
Training loss: 2.653791299463543
Validation loss: 3.074191635931032

Epoch: 6| Step: 2
Training loss: 3.2512608063256803
Validation loss: 3.0713498314080896

Epoch: 6| Step: 3
Training loss: 3.585697207575746
Validation loss: 3.0727106430264413

Epoch: 6| Step: 4
Training loss: 3.690080418731291
Validation loss: 3.0739262074717715

Epoch: 6| Step: 5
Training loss: 3.1215508308921947
Validation loss: 3.073562843344326

Epoch: 6| Step: 6
Training loss: 2.6139004690751797
Validation loss: 3.0734589943721025

Epoch: 6| Step: 7
Training loss: 2.8975267650299523
Validation loss: 3.0704143989146746

Epoch: 6| Step: 8
Training loss: 3.3737951883269854
Validation loss: 3.0686524415452974

Epoch: 6| Step: 9
Training loss: 4.085421177642578
Validation loss: 3.0722245733063254

Epoch: 6| Step: 10
Training loss: 4.067837304851943
Validation loss: 3.071577430137375

Epoch: 6| Step: 11
Training loss: 3.7305188560116664
Validation loss: 3.0751095269152

Epoch: 6| Step: 12
Training loss: 3.5102171949694756
Validation loss: 3.074041727856277

Epoch: 6| Step: 13
Training loss: 2.3912462412141093
Validation loss: 3.071256510244158

Epoch: 157| Step: 0
Training loss: 2.572660631627285
Validation loss: 3.071384969366453

Epoch: 6| Step: 1
Training loss: 2.4419713213249628
Validation loss: 3.0688200239872128

Epoch: 6| Step: 2
Training loss: 3.821956600587571
Validation loss: 3.0683300802577396

Epoch: 6| Step: 3
Training loss: 3.373185128988433
Validation loss: 3.0704251647332605

Epoch: 6| Step: 4
Training loss: 3.273007749329789
Validation loss: 3.0708651483258795

Epoch: 6| Step: 5
Training loss: 3.3170713155473095
Validation loss: 3.072074000116972

Epoch: 6| Step: 6
Training loss: 3.896747719797632
Validation loss: 3.0694290422694

Epoch: 6| Step: 7
Training loss: 3.661161596104177
Validation loss: 3.0682483790173607

Epoch: 6| Step: 8
Training loss: 3.678896938530104
Validation loss: 3.06727496392152

Epoch: 6| Step: 9
Training loss: 3.6618848889528746
Validation loss: 3.0685435673677435

Epoch: 6| Step: 10
Training loss: 3.0772065472238523
Validation loss: 3.0694819210998254

Epoch: 6| Step: 11
Training loss: 3.5906350609594413
Validation loss: 3.068305367249002

Epoch: 6| Step: 12
Training loss: 2.744175030367057
Validation loss: 3.0673027074735013

Epoch: 6| Step: 13
Training loss: 3.0101239723199695
Validation loss: 3.0660747678360405

Epoch: 158| Step: 0
Training loss: 2.998571691646109
Validation loss: 3.066803639573352

Epoch: 6| Step: 1
Training loss: 3.331536349072366
Validation loss: 3.068109678109021

Epoch: 6| Step: 2
Training loss: 3.8171660839203008
Validation loss: 3.0669373599338474

Epoch: 6| Step: 3
Training loss: 3.1243366300298985
Validation loss: 3.0670668951637303

Epoch: 6| Step: 4
Training loss: 3.749186872699319
Validation loss: 3.0657674775825488

Epoch: 6| Step: 5
Training loss: 3.35715073871557
Validation loss: 3.065541536517269

Epoch: 6| Step: 6
Training loss: 3.107811155937445
Validation loss: 3.0672869518346393

Epoch: 6| Step: 7
Training loss: 3.013739594386588
Validation loss: 3.068318315326311

Epoch: 6| Step: 8
Training loss: 3.551345494996101
Validation loss: 3.069192563060238

Epoch: 6| Step: 9
Training loss: 2.946026217248802
Validation loss: 3.0671421283895413

Epoch: 6| Step: 10
Training loss: 3.8180381698338994
Validation loss: 3.069926759766049

Epoch: 6| Step: 11
Training loss: 3.747771809132087
Validation loss: 3.066539082296374

Epoch: 6| Step: 12
Training loss: 2.9966683961936136
Validation loss: 3.070245085713561

Epoch: 6| Step: 13
Training loss: 2.400779351215996
Validation loss: 3.0647746418569914

Epoch: 159| Step: 0
Training loss: 3.5978913701502115
Validation loss: 3.0642077280547952

Epoch: 6| Step: 1
Training loss: 3.3429892556956102
Validation loss: 3.0652041405563937

Epoch: 6| Step: 2
Training loss: 3.503503952832045
Validation loss: 3.0650519695405123

Epoch: 6| Step: 3
Training loss: 3.1074683703211505
Validation loss: 3.063748494237908

Epoch: 6| Step: 4
Training loss: 4.122502119758945
Validation loss: 3.0639123579294423

Epoch: 6| Step: 5
Training loss: 3.6575643671177374
Validation loss: 3.062469821301575

Epoch: 6| Step: 6
Training loss: 2.710773210192016
Validation loss: 3.0635713767120527

Epoch: 6| Step: 7
Training loss: 2.851139235763737
Validation loss: 3.0643225698865706

Epoch: 6| Step: 8
Training loss: 2.9513573578789556
Validation loss: 3.0626557950708455

Epoch: 6| Step: 9
Training loss: 3.22103297185262
Validation loss: 3.0627023773595377

Epoch: 6| Step: 10
Training loss: 3.365640873636908
Validation loss: 3.062999702153334

Epoch: 6| Step: 11
Training loss: 3.184122427824655
Validation loss: 3.062964836271469

Epoch: 6| Step: 12
Training loss: 3.6550163078727063
Validation loss: 3.062037644215127

Epoch: 6| Step: 13
Training loss: 2.8691256674005956
Validation loss: 3.0621343833487824

Epoch: 160| Step: 0
Training loss: 2.9641044810795485
Validation loss: 3.0632228772497134

Epoch: 6| Step: 1
Training loss: 3.5823254313665895
Validation loss: 3.0639623599844548

Epoch: 6| Step: 2
Training loss: 3.082379339599277
Validation loss: 3.061538797415798

Epoch: 6| Step: 3
Training loss: 3.9101771031146617
Validation loss: 3.0642463412857706

Epoch: 6| Step: 4
Training loss: 2.1900095032786235
Validation loss: 3.0623314856951964

Epoch: 6| Step: 5
Training loss: 2.999497689474049
Validation loss: 3.0628741724075037

Epoch: 6| Step: 6
Training loss: 3.2858350417651665
Validation loss: 3.062340664229243

Epoch: 6| Step: 7
Training loss: 3.4141351268733904
Validation loss: 3.0607268101515266

Epoch: 6| Step: 8
Training loss: 3.5633855689430605
Validation loss: 3.062101238140455

Epoch: 6| Step: 9
Training loss: 3.2186780014133483
Validation loss: 3.062033076265492

Epoch: 6| Step: 10
Training loss: 4.102087020032836
Validation loss: 3.0662447878839427

Epoch: 6| Step: 11
Training loss: 3.187514361180883
Validation loss: 3.06241274540493

Epoch: 6| Step: 12
Training loss: 2.7123562401150436
Validation loss: 3.060847483856303

Epoch: 6| Step: 13
Training loss: 4.195596411846429
Validation loss: 3.0589730297342856

Epoch: 161| Step: 0
Training loss: 2.48782761299786
Validation loss: 3.0600192511634794

Epoch: 6| Step: 1
Training loss: 3.7011234330602982
Validation loss: 3.059700800593549

Epoch: 6| Step: 2
Training loss: 3.8151006114886736
Validation loss: 3.0592878907111323

Epoch: 6| Step: 3
Training loss: 3.18855387899176
Validation loss: 3.057851454857412

Epoch: 6| Step: 4
Training loss: 3.3794746405966043
Validation loss: 3.0574844480414867

Epoch: 6| Step: 5
Training loss: 2.446543618242756
Validation loss: 3.0582529788444823

Epoch: 6| Step: 6
Training loss: 3.3181097645139457
Validation loss: 3.0581828903164183

Epoch: 6| Step: 7
Training loss: 3.533062495041953
Validation loss: 3.056153690516676

Epoch: 6| Step: 8
Training loss: 3.062177057171543
Validation loss: 3.0593994547902805

Epoch: 6| Step: 9
Training loss: 3.267146581961835
Validation loss: 3.0600500999562184

Epoch: 6| Step: 10
Training loss: 4.235054890570778
Validation loss: 3.0578629423147086

Epoch: 6| Step: 11
Training loss: 3.365307063791647
Validation loss: 3.0603285787150902

Epoch: 6| Step: 12
Training loss: 3.1129108816515276
Validation loss: 3.058676299188406

Epoch: 6| Step: 13
Training loss: 3.0512387058497543
Validation loss: 3.060793625820253

Epoch: 162| Step: 0
Training loss: 3.857136065361058
Validation loss: 3.059263017507498

Epoch: 6| Step: 1
Training loss: 3.668806636444624
Validation loss: 3.0555080300740354

Epoch: 6| Step: 2
Training loss: 3.1784599615302347
Validation loss: 3.055885050196358

Epoch: 6| Step: 3
Training loss: 3.374368961821296
Validation loss: 3.0551978989551447

Epoch: 6| Step: 4
Training loss: 3.44006917484727
Validation loss: 3.0559864016996334

Epoch: 6| Step: 5
Training loss: 3.214202038114793
Validation loss: 3.056615393089329

Epoch: 6| Step: 6
Training loss: 2.978147710371337
Validation loss: 3.0548123347626497

Epoch: 6| Step: 7
Training loss: 3.2247995358640185
Validation loss: 3.053870334011681

Epoch: 6| Step: 8
Training loss: 3.248643151728196
Validation loss: 3.054051113294395

Epoch: 6| Step: 9
Training loss: 3.9804625206955673
Validation loss: 3.0554661927590714

Epoch: 6| Step: 10
Training loss: 2.7907677147267265
Validation loss: 3.054138686518327

Epoch: 6| Step: 11
Training loss: 3.3205167101724062
Validation loss: 3.054356987902084

Epoch: 6| Step: 12
Training loss: 3.031470693832602
Validation loss: 3.054070929488

Epoch: 6| Step: 13
Training loss: 2.6530587267826484
Validation loss: 3.0553353778145556

Epoch: 163| Step: 0
Training loss: 3.139291052997426
Validation loss: 3.054523892596894

Epoch: 6| Step: 1
Training loss: 3.0731422643232804
Validation loss: 3.054361253419397

Epoch: 6| Step: 2
Training loss: 2.931150676288985
Validation loss: 3.052377863756802

Epoch: 6| Step: 3
Training loss: 3.540280029514322
Validation loss: 3.0517152668405245

Epoch: 6| Step: 4
Training loss: 4.068827704231127
Validation loss: 3.0536438778668615

Epoch: 6| Step: 5
Training loss: 3.4725101470249737
Validation loss: 3.0522643245655776

Epoch: 6| Step: 6
Training loss: 3.2678321789778892
Validation loss: 3.051148936235353

Epoch: 6| Step: 7
Training loss: 2.7937234352436167
Validation loss: 3.0504857177329034

Epoch: 6| Step: 8
Training loss: 3.706046452971748
Validation loss: 3.0507044569869257

Epoch: 6| Step: 9
Training loss: 3.1842715799685046
Validation loss: 3.051901970721488

Epoch: 6| Step: 10
Training loss: 3.3849831327978834
Validation loss: 3.0518916200504043

Epoch: 6| Step: 11
Training loss: 3.2404874825797214
Validation loss: 3.050474931967905

Epoch: 6| Step: 12
Training loss: 2.75391663894317
Validation loss: 3.0518164544096935

Epoch: 6| Step: 13
Training loss: 3.893082788409734
Validation loss: 3.054483035538585

Epoch: 164| Step: 0
Training loss: 2.3846090579363097
Validation loss: 3.052203880370113

Epoch: 6| Step: 1
Training loss: 3.1990720834054707
Validation loss: 3.0572915436817913

Epoch: 6| Step: 2
Training loss: 3.798432207437309
Validation loss: 3.051258478974391

Epoch: 6| Step: 3
Training loss: 3.0508975349957215
Validation loss: 3.0512974972059577

Epoch: 6| Step: 4
Training loss: 3.154399669377665
Validation loss: 3.054319180486663

Epoch: 6| Step: 5
Training loss: 3.6675113803138286
Validation loss: 3.051509979016013

Epoch: 6| Step: 6
Training loss: 3.4964233924986567
Validation loss: 3.0503821168418077

Epoch: 6| Step: 7
Training loss: 3.1199700119338023
Validation loss: 3.0496951194417754

Epoch: 6| Step: 8
Training loss: 3.987746065493806
Validation loss: 3.0500015292406744

Epoch: 6| Step: 9
Training loss: 3.0754545604640304
Validation loss: 3.0522153151692293

Epoch: 6| Step: 10
Training loss: 3.1661493648495345
Validation loss: 3.05524308877588

Epoch: 6| Step: 11
Training loss: 3.431553361333565
Validation loss: 3.0560772824843365

Epoch: 6| Step: 12
Training loss: 3.502729986074673
Validation loss: 3.05032567202436

Epoch: 6| Step: 13
Training loss: 2.909442747579067
Validation loss: 3.054858396342644

Epoch: 165| Step: 0
Training loss: 3.322305956040104
Validation loss: 3.051907971776197

Epoch: 6| Step: 1
Training loss: 4.074977083668309
Validation loss: 3.0568456294888606

Epoch: 6| Step: 2
Training loss: 2.8853548412837595
Validation loss: 3.0512316649934386

Epoch: 6| Step: 3
Training loss: 3.1068213630056714
Validation loss: 3.049759269989994

Epoch: 6| Step: 4
Training loss: 3.882692883988131
Validation loss: 3.0534567431597233

Epoch: 6| Step: 5
Training loss: 2.6528970537338914
Validation loss: 3.0496437452396616

Epoch: 6| Step: 6
Training loss: 3.980652270517898
Validation loss: 3.050860128388371

Epoch: 6| Step: 7
Training loss: 3.765807974394367
Validation loss: 3.050239775330852

Epoch: 6| Step: 8
Training loss: 2.728681992064733
Validation loss: 3.0549883673712803

Epoch: 6| Step: 9
Training loss: 3.43153279568779
Validation loss: 3.04922033115382

Epoch: 6| Step: 10
Training loss: 2.531820915734963
Validation loss: 3.053002499027955

Epoch: 6| Step: 11
Training loss: 3.106927723319242
Validation loss: 3.051838073541344

Epoch: 6| Step: 12
Training loss: 2.91867461342018
Validation loss: 3.0501826563298184

Epoch: 6| Step: 13
Training loss: 3.5886681492425825
Validation loss: 3.0483628612943248

Epoch: 166| Step: 0
Training loss: 2.9612064289769884
Validation loss: 3.0542055808411956

Epoch: 6| Step: 1
Training loss: 4.0660929123995215
Validation loss: 3.0547117273176503

Epoch: 6| Step: 2
Training loss: 3.2076492736285656
Validation loss: 3.048805023097636

Epoch: 6| Step: 3
Training loss: 3.754608882441342
Validation loss: 3.0515959600897347

Epoch: 6| Step: 4
Training loss: 2.3335640884011077
Validation loss: 3.0476515082066795

Epoch: 6| Step: 5
Training loss: 3.35740227552089
Validation loss: 3.050053659770949

Epoch: 6| Step: 6
Training loss: 2.938018103827471
Validation loss: 3.049687912781347

Epoch: 6| Step: 7
Training loss: 3.795250816048113
Validation loss: 3.0482381375024143

Epoch: 6| Step: 8
Training loss: 3.3813930290841188
Validation loss: 3.047567795628422

Epoch: 6| Step: 9
Training loss: 2.5800860720330863
Validation loss: 3.0505716024589877

Epoch: 6| Step: 10
Training loss: 2.9931076666791485
Validation loss: 3.0535304512359014

Epoch: 6| Step: 11
Training loss: 4.000987884602298
Validation loss: 3.053806675297334

Epoch: 6| Step: 12
Training loss: 2.857009492895093
Validation loss: 3.057432343589976

Epoch: 6| Step: 13
Training loss: 3.7736414504763074
Validation loss: 3.0499549975707136

Epoch: 167| Step: 0
Training loss: 3.0207930638928713
Validation loss: 3.0488093266537546

Epoch: 6| Step: 1
Training loss: 3.201102460256399
Validation loss: 3.046857818563486

Epoch: 6| Step: 2
Training loss: 3.2107625574871657
Validation loss: 3.0434035936812838

Epoch: 6| Step: 3
Training loss: 3.4363745494263735
Validation loss: 3.047659652555008

Epoch: 6| Step: 4
Training loss: 2.420293574693247
Validation loss: 3.047077438322697

Epoch: 6| Step: 5
Training loss: 3.017879927767646
Validation loss: 3.0445678490815715

Epoch: 6| Step: 6
Training loss: 3.3580467259585154
Validation loss: 3.0442966301594687

Epoch: 6| Step: 7
Training loss: 3.6743114423243046
Validation loss: 3.0458067084222833

Epoch: 6| Step: 8
Training loss: 2.5152080498372427
Validation loss: 3.0454070748222737

Epoch: 6| Step: 9
Training loss: 3.9795180693176753
Validation loss: 3.045408278603999

Epoch: 6| Step: 10
Training loss: 3.6728452009466976
Validation loss: 3.04293565214655

Epoch: 6| Step: 11
Training loss: 3.4246931620795653
Validation loss: 3.044194709246212

Epoch: 6| Step: 12
Training loss: 3.603448932309666
Validation loss: 3.0446696194143503

Epoch: 6| Step: 13
Training loss: 3.497664898795008
Validation loss: 3.04249989307752

Epoch: 168| Step: 0
Training loss: 2.743977801830933
Validation loss: 3.0437001033406768

Epoch: 6| Step: 1
Training loss: 3.076394461193066
Validation loss: 3.041801521007807

Epoch: 6| Step: 2
Training loss: 3.434050893025418
Validation loss: 3.0427106301073272

Epoch: 6| Step: 3
Training loss: 3.3250144786089253
Validation loss: 3.0392605402037134

Epoch: 6| Step: 4
Training loss: 3.1861136918601156
Validation loss: 3.040985818996452

Epoch: 6| Step: 5
Training loss: 3.445724358886223
Validation loss: 3.043700516056708

Epoch: 6| Step: 6
Training loss: 3.3464690944464808
Validation loss: 3.042499241739971

Epoch: 6| Step: 7
Training loss: 3.345551477882549
Validation loss: 3.047492925449344

Epoch: 6| Step: 8
Training loss: 2.9921600898303935
Validation loss: 3.0434581831564897

Epoch: 6| Step: 9
Training loss: 3.4614574308773993
Validation loss: 3.0423484411261823

Epoch: 6| Step: 10
Training loss: 3.280336670693376
Validation loss: 3.043356088433438

Epoch: 6| Step: 11
Training loss: 3.5473194264000303
Validation loss: 3.0427674007028815

Epoch: 6| Step: 12
Training loss: 3.4488713228815064
Validation loss: 3.0414351036491545

Epoch: 6| Step: 13
Training loss: 3.7275215370379864
Validation loss: 3.042254831173924

Epoch: 169| Step: 0
Training loss: 3.632398487413283
Validation loss: 3.0380833418650752

Epoch: 6| Step: 1
Training loss: 3.596958486216167
Validation loss: 3.0392403482416954

Epoch: 6| Step: 2
Training loss: 3.5832871426702844
Validation loss: 3.037378571938982

Epoch: 6| Step: 3
Training loss: 3.1109575241264458
Validation loss: 3.0426648926938396

Epoch: 6| Step: 4
Training loss: 4.509552036545593
Validation loss: 3.0497948845033482

Epoch: 6| Step: 5
Training loss: 2.4757978058993024
Validation loss: 3.045282010251729

Epoch: 6| Step: 6
Training loss: 3.2534934122016823
Validation loss: 3.0452983713709094

Epoch: 6| Step: 7
Training loss: 2.662635577694494
Validation loss: 3.0486900609079846

Epoch: 6| Step: 8
Training loss: 3.1240669383400688
Validation loss: 3.04154894931538

Epoch: 6| Step: 9
Training loss: 3.7718006951599112
Validation loss: 3.0486758782712884

Epoch: 6| Step: 10
Training loss: 3.133340767249629
Validation loss: 3.0400438203497675

Epoch: 6| Step: 11
Training loss: 3.0636672306280937
Validation loss: 3.040059336858772

Epoch: 6| Step: 12
Training loss: 3.2407739706202747
Validation loss: 3.037759209291684

Epoch: 6| Step: 13
Training loss: 2.1876173805351304
Validation loss: 3.037343632244892

Epoch: 170| Step: 0
Training loss: 2.7653757618813097
Validation loss: 3.0368753622221085

Epoch: 6| Step: 1
Training loss: 2.195896383269463
Validation loss: 3.0385306485794112

Epoch: 6| Step: 2
Training loss: 3.307550150865181
Validation loss: 3.0423523299621262

Epoch: 6| Step: 3
Training loss: 4.035266147235932
Validation loss: 3.045515635500726

Epoch: 6| Step: 4
Training loss: 3.3415405959957303
Validation loss: 3.0421800611384704

Epoch: 6| Step: 5
Training loss: 3.159805863126937
Validation loss: 3.042610624332254

Epoch: 6| Step: 6
Training loss: 3.4663699120883855
Validation loss: 3.040599305890908

Epoch: 6| Step: 7
Training loss: 3.7935198492534195
Validation loss: 3.040850926232734

Epoch: 6| Step: 8
Training loss: 2.9392373649012162
Validation loss: 3.034718431958328

Epoch: 6| Step: 9
Training loss: 2.8358651984800325
Validation loss: 3.0381665310297667

Epoch: 6| Step: 10
Training loss: 3.3230801883909695
Validation loss: 3.0315960025995174

Epoch: 6| Step: 11
Training loss: 4.0905028998888415
Validation loss: 3.032280416434629

Epoch: 6| Step: 12
Training loss: 3.3112263660156294
Validation loss: 3.0334352566988567

Epoch: 6| Step: 13
Training loss: 3.1459819598593146
Validation loss: 3.0325625341103035

Epoch: 171| Step: 0
Training loss: 3.349394979928074
Validation loss: 3.0319975884762638

Epoch: 6| Step: 1
Training loss: 2.9930182914646535
Validation loss: 3.03161481804428

Epoch: 6| Step: 2
Training loss: 3.311231262223137
Validation loss: 3.032593668121635

Epoch: 6| Step: 3
Training loss: 2.838873066353132
Validation loss: 3.030778158677338

Epoch: 6| Step: 4
Training loss: 2.9240613295232842
Validation loss: 3.032180090329106

Epoch: 6| Step: 5
Training loss: 3.7760574375568647
Validation loss: 3.0298813187954483

Epoch: 6| Step: 6
Training loss: 3.298860214375453
Validation loss: 3.0314643326544677

Epoch: 6| Step: 7
Training loss: 3.1889983002977216
Validation loss: 3.0316855402399816

Epoch: 6| Step: 8
Training loss: 3.033245255864841
Validation loss: 3.029642257010341

Epoch: 6| Step: 9
Training loss: 4.013985503257495
Validation loss: 3.029452828984316

Epoch: 6| Step: 10
Training loss: 3.0403381651466446
Validation loss: 3.0293019179926355

Epoch: 6| Step: 11
Training loss: 2.687841349370302
Validation loss: 3.02870260290598

Epoch: 6| Step: 12
Training loss: 4.11566817392052
Validation loss: 3.0297593127251243

Epoch: 6| Step: 13
Training loss: 3.3660838714866883
Validation loss: 3.030417814917121

Epoch: 172| Step: 0
Training loss: 4.267848738202052
Validation loss: 3.028807344012335

Epoch: 6| Step: 1
Training loss: 3.3040283122847036
Validation loss: 3.0301767082863713

Epoch: 6| Step: 2
Training loss: 3.0338765199462636
Validation loss: 3.031443079017532

Epoch: 6| Step: 3
Training loss: 3.26524810806382
Validation loss: 3.027924439902624

Epoch: 6| Step: 4
Training loss: 3.3008965285897793
Validation loss: 3.0286843754301254

Epoch: 6| Step: 5
Training loss: 4.012107169152835
Validation loss: 3.0309230863696572

Epoch: 6| Step: 6
Training loss: 2.8183949045967345
Validation loss: 3.028082424501036

Epoch: 6| Step: 7
Training loss: 3.143227481077807
Validation loss: 3.0291959439867577

Epoch: 6| Step: 8
Training loss: 3.4374833540079917
Validation loss: 3.028376162624893

Epoch: 6| Step: 9
Training loss: 2.9369077694224157
Validation loss: 3.0274904205115702

Epoch: 6| Step: 10
Training loss: 2.742088381288229
Validation loss: 3.0261286147887496

Epoch: 6| Step: 11
Training loss: 2.9527752381540426
Validation loss: 3.0278757282765514

Epoch: 6| Step: 12
Training loss: 3.4015478874176543
Validation loss: 3.025330299766326

Epoch: 6| Step: 13
Training loss: 3.114425774270818
Validation loss: 3.028027054928167

Epoch: 173| Step: 0
Training loss: 3.584101986319564
Validation loss: 3.029393730472523

Epoch: 6| Step: 1
Training loss: 3.194472372697751
Validation loss: 3.0316091852620297

Epoch: 6| Step: 2
Training loss: 3.0104179690313106
Validation loss: 3.0388646847904317

Epoch: 6| Step: 3
Training loss: 2.9980093391379876
Validation loss: 3.037633092224579

Epoch: 6| Step: 4
Training loss: 2.96578236876864
Validation loss: 3.0328722664800125

Epoch: 6| Step: 5
Training loss: 3.4661550352154493
Validation loss: 3.031266307459222

Epoch: 6| Step: 6
Training loss: 3.3820419314879544
Validation loss: 3.0250743714786053

Epoch: 6| Step: 7
Training loss: 3.5354923657548105
Validation loss: 3.0268148645521764

Epoch: 6| Step: 8
Training loss: 3.417037819652791
Validation loss: 3.022691025778522

Epoch: 6| Step: 9
Training loss: 3.3065542445247837
Validation loss: 3.0230730019404155

Epoch: 6| Step: 10
Training loss: 3.2510465257472467
Validation loss: 3.023043473575459

Epoch: 6| Step: 11
Training loss: 3.6211809232191814
Validation loss: 3.024647762083398

Epoch: 6| Step: 12
Training loss: 2.5591574477445094
Validation loss: 3.0237164417587956

Epoch: 6| Step: 13
Training loss: 3.9925224029351987
Validation loss: 3.022648089645063

Epoch: 174| Step: 0
Training loss: 3.3746898649913724
Validation loss: 3.021258978864988

Epoch: 6| Step: 1
Training loss: 3.385385429042582
Validation loss: 3.022264789099159

Epoch: 6| Step: 2
Training loss: 3.2333645186608124
Validation loss: 3.0222613095695103

Epoch: 6| Step: 3
Training loss: 2.3783160700591424
Validation loss: 3.0217324686456672

Epoch: 6| Step: 4
Training loss: 3.2083507058470064
Validation loss: 3.0247524147612084

Epoch: 6| Step: 5
Training loss: 3.4616082706096067
Validation loss: 3.0224240390328303

Epoch: 6| Step: 6
Training loss: 3.3163772060528864
Validation loss: 3.022614199319841

Epoch: 6| Step: 7
Training loss: 2.7513089099419616
Validation loss: 3.020720025222883

Epoch: 6| Step: 8
Training loss: 3.341302849679503
Validation loss: 3.0227568714764423

Epoch: 6| Step: 9
Training loss: 3.706321013157884
Validation loss: 3.02589200579731

Epoch: 6| Step: 10
Training loss: 3.6316447688494833
Validation loss: 3.023874379150252

Epoch: 6| Step: 11
Training loss: 3.8787228328676675
Validation loss: 3.02089009017723

Epoch: 6| Step: 12
Training loss: 2.971069393614832
Validation loss: 3.0258527531601374

Epoch: 6| Step: 13
Training loss: 3.110413344411913
Validation loss: 3.0234101272424585

Epoch: 175| Step: 0
Training loss: 2.7538526597456396
Validation loss: 3.024460160675355

Epoch: 6| Step: 1
Training loss: 3.302088949076373
Validation loss: 3.024651433811601

Epoch: 6| Step: 2
Training loss: 3.6117115467089644
Validation loss: 3.031167950548893

Epoch: 6| Step: 3
Training loss: 3.6063565930987624
Validation loss: 3.0276258069290236

Epoch: 6| Step: 4
Training loss: 3.505540821617453
Validation loss: 3.024071893138759

Epoch: 6| Step: 5
Training loss: 2.9971567031476107
Validation loss: 3.0255361513916728

Epoch: 6| Step: 6
Training loss: 3.137143763041508
Validation loss: 3.021555300369733

Epoch: 6| Step: 7
Training loss: 3.1338832480879826
Validation loss: 3.0195086082655282

Epoch: 6| Step: 8
Training loss: 4.281723330429551
Validation loss: 3.0204800533213736

Epoch: 6| Step: 9
Training loss: 2.9932362284836183
Validation loss: 3.019420315086274

Epoch: 6| Step: 10
Training loss: 3.2098031743631656
Validation loss: 3.0202443522870097

Epoch: 6| Step: 11
Training loss: 2.9061522108464004
Validation loss: 3.0198989582931053

Epoch: 6| Step: 12
Training loss: 2.9875088360388418
Validation loss: 3.022089424979253

Epoch: 6| Step: 13
Training loss: 3.419348633290962
Validation loss: 3.0207610673644485

Epoch: 176| Step: 0
Training loss: 3.425933799696419
Validation loss: 3.0197353303888215

Epoch: 6| Step: 1
Training loss: 3.0049831012879054
Validation loss: 3.0210653041306967

Epoch: 6| Step: 2
Training loss: 2.615634013061308
Validation loss: 3.0202345187034823

Epoch: 6| Step: 3
Training loss: 3.2526126043954973
Validation loss: 3.0190321721275337

Epoch: 6| Step: 4
Training loss: 2.684036329441394
Validation loss: 3.0190809406769885

Epoch: 6| Step: 5
Training loss: 3.5118554823822383
Validation loss: 3.019462317327403

Epoch: 6| Step: 6
Training loss: 2.7245899486874663
Validation loss: 3.0200544926829145

Epoch: 6| Step: 7
Training loss: 2.648600795516612
Validation loss: 3.01876740099558

Epoch: 6| Step: 8
Training loss: 3.6015534969722074
Validation loss: 3.018421800625525

Epoch: 6| Step: 9
Training loss: 4.360660267802504
Validation loss: 3.0182865313653795

Epoch: 6| Step: 10
Training loss: 3.8348302544499067
Validation loss: 3.0193112236980255

Epoch: 6| Step: 11
Training loss: 3.3394283995659553
Validation loss: 3.017033684005201

Epoch: 6| Step: 12
Training loss: 3.462315958688711
Validation loss: 3.0169446700382907

Epoch: 6| Step: 13
Training loss: 2.9247047470926044
Validation loss: 3.018110769606936

Epoch: 177| Step: 0
Training loss: 2.8130045120414624
Validation loss: 3.017488912146457

Epoch: 6| Step: 1
Training loss: 3.4019550929259292
Validation loss: 3.0172792819752323

Epoch: 6| Step: 2
Training loss: 3.1029968788458286
Validation loss: 3.0202875772338342

Epoch: 6| Step: 3
Training loss: 3.149545933527934
Validation loss: 3.0182310194593964

Epoch: 6| Step: 4
Training loss: 2.4977412510339616
Validation loss: 3.02259674681609

Epoch: 6| Step: 5
Training loss: 2.8272428032340486
Validation loss: 3.0211120796522133

Epoch: 6| Step: 6
Training loss: 3.075758125696903
Validation loss: 3.020590358604654

Epoch: 6| Step: 7
Training loss: 3.475226327674854
Validation loss: 3.0218012909937384

Epoch: 6| Step: 8
Training loss: 3.404911443200125
Validation loss: 3.0164575649009233

Epoch: 6| Step: 9
Training loss: 3.246280155269502
Validation loss: 3.0141574953584573

Epoch: 6| Step: 10
Training loss: 3.8180658954511033
Validation loss: 3.0115780942312402

Epoch: 6| Step: 11
Training loss: 3.210872454576118
Validation loss: 3.014003475193493

Epoch: 6| Step: 12
Training loss: 3.898548193451326
Validation loss: 3.012260081815487

Epoch: 6| Step: 13
Training loss: 4.1270162105477635
Validation loss: 3.0156558889220073

Epoch: 178| Step: 0
Training loss: 3.5178031446975186
Validation loss: 3.012668151887271

Epoch: 6| Step: 1
Training loss: 2.4436985332406094
Validation loss: 3.01414310600559

Epoch: 6| Step: 2
Training loss: 3.4750233875832386
Validation loss: 3.0147488606219004

Epoch: 6| Step: 3
Training loss: 3.524628093390324
Validation loss: 3.0130752988376823

Epoch: 6| Step: 4
Training loss: 3.4571551112168364
Validation loss: 3.0109227583922085

Epoch: 6| Step: 5
Training loss: 3.330206851205187
Validation loss: 3.0124072595086155

Epoch: 6| Step: 6
Training loss: 3.5713653013892035
Validation loss: 3.015461646876534

Epoch: 6| Step: 7
Training loss: 3.2534715744519116
Validation loss: 3.0110427776480804

Epoch: 6| Step: 8
Training loss: 2.8653929704850567
Validation loss: 3.013297594332022

Epoch: 6| Step: 9
Training loss: 2.5207623453364776
Validation loss: 3.0105163600858664

Epoch: 6| Step: 10
Training loss: 3.1741421118724826
Validation loss: 3.0114539385800367

Epoch: 6| Step: 11
Training loss: 3.2082746095773946
Validation loss: 3.009607202758721

Epoch: 6| Step: 12
Training loss: 3.756876172573406
Validation loss: 3.013313440840183

Epoch: 6| Step: 13
Training loss: 3.7770026446457687
Validation loss: 3.0113208405160323

Epoch: 179| Step: 0
Training loss: 2.952750045950775
Validation loss: 3.014105831835804

Epoch: 6| Step: 1
Training loss: 3.088780891884578
Validation loss: 3.014611735948113

Epoch: 6| Step: 2
Training loss: 3.4596377444400024
Validation loss: 3.019189242217433

Epoch: 6| Step: 3
Training loss: 3.505235434772682
Validation loss: 3.019718955564794

Epoch: 6| Step: 4
Training loss: 3.516077987309411
Validation loss: 3.017994419045959

Epoch: 6| Step: 5
Training loss: 3.315047382228999
Validation loss: 3.0171784341161585

Epoch: 6| Step: 6
Training loss: 3.7551348816155694
Validation loss: 3.027129106113645

Epoch: 6| Step: 7
Training loss: 2.9106135271504447
Validation loss: 3.0170321375103186

Epoch: 6| Step: 8
Training loss: 3.3031364390194105
Validation loss: 3.009399833905134

Epoch: 6| Step: 9
Training loss: 2.8024155279218848
Validation loss: 3.0088600579296227

Epoch: 6| Step: 10
Training loss: 2.059778093589288
Validation loss: 3.006333952219248

Epoch: 6| Step: 11
Training loss: 3.8856483097245476
Validation loss: 3.008157168221184

Epoch: 6| Step: 12
Training loss: 3.48156666162987
Validation loss: 3.011884195733236

Epoch: 6| Step: 13
Training loss: 3.641165893714781
Validation loss: 3.009566899524102

Epoch: 180| Step: 0
Training loss: 3.1763732283346604
Validation loss: 3.0098393655941833

Epoch: 6| Step: 1
Training loss: 2.7236104029420507
Validation loss: 3.0127657189386357

Epoch: 6| Step: 2
Training loss: 3.2537476866190334
Validation loss: 3.0093030709680604

Epoch: 6| Step: 3
Training loss: 3.758140628946511
Validation loss: 3.012086814539603

Epoch: 6| Step: 4
Training loss: 3.034783417768265
Validation loss: 3.009272616910426

Epoch: 6| Step: 5
Training loss: 3.9110555157780054
Validation loss: 3.0088871702710254

Epoch: 6| Step: 6
Training loss: 3.636399465080963
Validation loss: 3.0079287586029593

Epoch: 6| Step: 7
Training loss: 3.7381036889649177
Validation loss: 3.007898323018342

Epoch: 6| Step: 8
Training loss: 2.591275977056481
Validation loss: 3.0076224505830607

Epoch: 6| Step: 9
Training loss: 3.266606963513846
Validation loss: 3.0051850576255243

Epoch: 6| Step: 10
Training loss: 3.610666151427998
Validation loss: 3.0086841221135683

Epoch: 6| Step: 11
Training loss: 3.25423448974683
Validation loss: 3.0059845156381435

Epoch: 6| Step: 12
Training loss: 2.2606466384370982
Validation loss: 3.0055776065536133

Epoch: 6| Step: 13
Training loss: 3.306753680509701
Validation loss: 3.0052576412730323

Epoch: 181| Step: 0
Training loss: 3.1871508238778894
Validation loss: 3.007642394530712

Epoch: 6| Step: 1
Training loss: 2.9830535039959702
Validation loss: 3.0059799358538406

Epoch: 6| Step: 2
Training loss: 2.6023239533522564
Validation loss: 3.0062293542243355

Epoch: 6| Step: 3
Training loss: 4.037826732725259
Validation loss: 3.00786797576616

Epoch: 6| Step: 4
Training loss: 3.7160890178797055
Validation loss: 3.0049311503527267

Epoch: 6| Step: 5
Training loss: 2.9296126292516393
Validation loss: 3.004867848066603

Epoch: 6| Step: 6
Training loss: 3.2974887656251126
Validation loss: 3.0032253189424005

Epoch: 6| Step: 7
Training loss: 3.7451308109677246
Validation loss: 3.0049554631677693

Epoch: 6| Step: 8
Training loss: 2.9062746108458954
Validation loss: 3.004523632728631

Epoch: 6| Step: 9
Training loss: 3.7846927575569467
Validation loss: 3.0060650112441563

Epoch: 6| Step: 10
Training loss: 2.3006834258702824
Validation loss: 3.0043494030228857

Epoch: 6| Step: 11
Training loss: 2.918748457783653
Validation loss: 3.002167928476622

Epoch: 6| Step: 12
Training loss: 3.3695207552765214
Validation loss: 3.002253246805559

Epoch: 6| Step: 13
Training loss: 3.8630306829922096
Validation loss: 3.0038034433842635

Epoch: 182| Step: 0
Training loss: 2.7466437927083733
Validation loss: 3.0040168668764635

Epoch: 6| Step: 1
Training loss: 3.495091265795186
Validation loss: 3.0047066250320946

Epoch: 6| Step: 2
Training loss: 3.1572016423873466
Validation loss: 3.006505876339093

Epoch: 6| Step: 3
Training loss: 3.4039424814638477
Validation loss: 3.0057690296536284

Epoch: 6| Step: 4
Training loss: 3.575453114638141
Validation loss: 3.006857922668838

Epoch: 6| Step: 5
Training loss: 2.3631975143352393
Validation loss: 3.003891811541241

Epoch: 6| Step: 6
Training loss: 3.8642179551188733
Validation loss: 3.003088339072764

Epoch: 6| Step: 7
Training loss: 2.7542194594163045
Validation loss: 3.0016613106677736

Epoch: 6| Step: 8
Training loss: 3.586121265631089
Validation loss: 3.0025005703537624

Epoch: 6| Step: 9
Training loss: 3.013077841142214
Validation loss: 3.000507586959669

Epoch: 6| Step: 10
Training loss: 3.8984810438763056
Validation loss: 3.000169537310211

Epoch: 6| Step: 11
Training loss: 3.28826981730795
Validation loss: 3.001824907484839

Epoch: 6| Step: 12
Training loss: 3.547935562546401
Validation loss: 3.0003495815964873

Epoch: 6| Step: 13
Training loss: 2.280072051800418
Validation loss: 3.000869544631178

Epoch: 183| Step: 0
Training loss: 3.4973562337300375
Validation loss: 3.00250745994198

Epoch: 6| Step: 1
Training loss: 2.88229522612949
Validation loss: 3.0008370255535963

Epoch: 6| Step: 2
Training loss: 3.4534980952112786
Validation loss: 3.000373793117836

Epoch: 6| Step: 3
Training loss: 2.3651840746419075
Validation loss: 2.9993991472282073

Epoch: 6| Step: 4
Training loss: 3.4417850489419175
Validation loss: 3.0007773079396

Epoch: 6| Step: 5
Training loss: 3.1376866501689484
Validation loss: 3.0009341973028207

Epoch: 6| Step: 6
Training loss: 3.3077782140368535
Validation loss: 2.9996394108193263

Epoch: 6| Step: 7
Training loss: 4.018387493674099
Validation loss: 3.002036529716099

Epoch: 6| Step: 8
Training loss: 3.421723105486491
Validation loss: 3.000789738350177

Epoch: 6| Step: 9
Training loss: 3.3540311671465473
Validation loss: 2.999590233877984

Epoch: 6| Step: 10
Training loss: 3.285190795281359
Validation loss: 3.0011418025810928

Epoch: 6| Step: 11
Training loss: 2.628219083900449
Validation loss: 3.0017767809486067

Epoch: 6| Step: 12
Training loss: 3.764700621801095
Validation loss: 3.0026106567215907

Epoch: 6| Step: 13
Training loss: 2.5926130629543738
Validation loss: 3.0011473524547423

Epoch: 184| Step: 0
Training loss: 3.1791700837269854
Validation loss: 3.0001541716772406

Epoch: 6| Step: 1
Training loss: 3.2904812251576874
Validation loss: 2.9990295170102472

Epoch: 6| Step: 2
Training loss: 3.7423911148774747
Validation loss: 2.997905352016123

Epoch: 6| Step: 3
Training loss: 3.13966620693844
Validation loss: 2.9997695489101783

Epoch: 6| Step: 4
Training loss: 3.830514590202841
Validation loss: 2.9990194027226162

Epoch: 6| Step: 5
Training loss: 3.414208590177409
Validation loss: 3.002637503610842

Epoch: 6| Step: 6
Training loss: 3.4360359542084655
Validation loss: 3.0025301931656045

Epoch: 6| Step: 7
Training loss: 2.60009137506577
Validation loss: 3.005551327561695

Epoch: 6| Step: 8
Training loss: 3.709397809698456
Validation loss: 3.001364163643858

Epoch: 6| Step: 9
Training loss: 3.3608312954475954
Validation loss: 3.003259093442897

Epoch: 6| Step: 10
Training loss: 3.1027974089302477
Validation loss: 3.001013994616661

Epoch: 6| Step: 11
Training loss: 2.93861757487135
Validation loss: 2.997826980468945

Epoch: 6| Step: 12
Training loss: 2.7390284586747944
Validation loss: 3.0003374962693647

Epoch: 6| Step: 13
Training loss: 2.888023236580145
Validation loss: 3.0026597619965343

Epoch: 185| Step: 0
Training loss: 3.225517491657619
Validation loss: 3.001715021187779

Epoch: 6| Step: 1
Training loss: 3.0730378380285326
Validation loss: 2.99660682031341

Epoch: 6| Step: 2
Training loss: 3.7191613234312695
Validation loss: 2.995938544472761

Epoch: 6| Step: 3
Training loss: 3.6183231293053977
Validation loss: 2.9945529021129667

Epoch: 6| Step: 4
Training loss: 3.538586851918338
Validation loss: 2.9965633461723744

Epoch: 6| Step: 5
Training loss: 2.7956717689400588
Validation loss: 2.996021133019652

Epoch: 6| Step: 6
Training loss: 3.1428703518379364
Validation loss: 2.9957072931573294

Epoch: 6| Step: 7
Training loss: 3.7291066823784447
Validation loss: 2.997476703553577

Epoch: 6| Step: 8
Training loss: 2.450982585756405
Validation loss: 2.9949692979576654

Epoch: 6| Step: 9
Training loss: 3.3563022488695204
Validation loss: 2.994875979028085

Epoch: 6| Step: 10
Training loss: 3.22225775826981
Validation loss: 2.994576797517143

Epoch: 6| Step: 11
Training loss: 3.192798623596904
Validation loss: 2.9997327089017487

Epoch: 6| Step: 12
Training loss: 3.0502463444516774
Validation loss: 2.991849984087047

Epoch: 6| Step: 13
Training loss: 3.5204526857247718
Validation loss: 2.9939815797753107

Epoch: 186| Step: 0
Training loss: 3.2269789309243846
Validation loss: 2.994282343045052

Epoch: 6| Step: 1
Training loss: 3.2514152379855585
Validation loss: 2.9906859572475413

Epoch: 6| Step: 2
Training loss: 2.7399870039638636
Validation loss: 2.99435563617815

Epoch: 6| Step: 3
Training loss: 2.731801418621729
Validation loss: 2.9954760051608287

Epoch: 6| Step: 4
Training loss: 3.434073248702423
Validation loss: 2.993435942186146

Epoch: 6| Step: 5
Training loss: 2.978046517874103
Validation loss: 2.992299377702569

Epoch: 6| Step: 6
Training loss: 3.4346354253050997
Validation loss: 2.9968388354234787

Epoch: 6| Step: 7
Training loss: 3.171440357814769
Validation loss: 3.001836777587807

Epoch: 6| Step: 8
Training loss: 3.831742550924122
Validation loss: 2.9921115490871495

Epoch: 6| Step: 9
Training loss: 3.2349524235948763
Validation loss: 3.000340109178632

Epoch: 6| Step: 10
Training loss: 3.287868400789582
Validation loss: 2.998580680618197

Epoch: 6| Step: 11
Training loss: 3.539257861002083
Validation loss: 3.000285640059437

Epoch: 6| Step: 12
Training loss: 3.041221655773531
Validation loss: 2.9898819249947723

Epoch: 6| Step: 13
Training loss: 3.9066626979256567
Validation loss: 2.9910608406315915

Epoch: 187| Step: 0
Training loss: 3.1968283193989224
Validation loss: 2.991825825263481

Epoch: 6| Step: 1
Training loss: 3.3583344023318675
Validation loss: 2.9902691192654265

Epoch: 6| Step: 2
Training loss: 2.8832005185388234
Validation loss: 2.990369166023184

Epoch: 6| Step: 3
Training loss: 3.282005005213741
Validation loss: 2.994240044095906

Epoch: 6| Step: 4
Training loss: 3.384818312757123
Validation loss: 2.9955931892714656

Epoch: 6| Step: 5
Training loss: 3.6743323361884745
Validation loss: 2.9933922310086705

Epoch: 6| Step: 6
Training loss: 3.0755170433975025
Validation loss: 2.9940873043319094

Epoch: 6| Step: 7
Training loss: 3.5005541771438335
Validation loss: 2.992047958442399

Epoch: 6| Step: 8
Training loss: 2.661524752530267
Validation loss: 2.9912729775559224

Epoch: 6| Step: 9
Training loss: 3.1194903823158886
Validation loss: 2.990365743683431

Epoch: 6| Step: 10
Training loss: 3.403269452408704
Validation loss: 2.9903582525864043

Epoch: 6| Step: 11
Training loss: 3.033128608530108
Validation loss: 2.98987583117133

Epoch: 6| Step: 12
Training loss: 3.3388643312177018
Validation loss: 2.99260045738302

Epoch: 6| Step: 13
Training loss: 3.9948574626068214
Validation loss: 2.9952817922239405

Epoch: 188| Step: 0
Training loss: 3.300079668412733
Validation loss: 2.991203698781147

Epoch: 6| Step: 1
Training loss: 2.7721088504309668
Validation loss: 2.98934472222196

Epoch: 6| Step: 2
Training loss: 3.2357172000887524
Validation loss: 2.9885872173994463

Epoch: 6| Step: 3
Training loss: 3.1855022677555853
Validation loss: 2.9889691535785428

Epoch: 6| Step: 4
Training loss: 3.430779424476546
Validation loss: 2.9890201194290604

Epoch: 6| Step: 5
Training loss: 3.246811109250181
Validation loss: 2.9901722979627667

Epoch: 6| Step: 6
Training loss: 3.6542078819835875
Validation loss: 2.9883601241051285

Epoch: 6| Step: 7
Training loss: 3.013917904278089
Validation loss: 2.9860435734486828

Epoch: 6| Step: 8
Training loss: 3.463954600717232
Validation loss: 2.9889501554498827

Epoch: 6| Step: 9
Training loss: 3.5122318423394634
Validation loss: 2.9888573536452823

Epoch: 6| Step: 10
Training loss: 3.341433284026716
Validation loss: 2.9863838041399253

Epoch: 6| Step: 11
Training loss: 2.520434976003491
Validation loss: 2.9856489568096145

Epoch: 6| Step: 12
Training loss: 3.8788938339664707
Validation loss: 2.986228920673969

Epoch: 6| Step: 13
Training loss: 2.6081905760612445
Validation loss: 2.986208039605959

Epoch: 189| Step: 0
Training loss: 2.7944171697736158
Validation loss: 2.9879335648758873

Epoch: 6| Step: 1
Training loss: 3.5098365432630625
Validation loss: 2.9867571692206396

Epoch: 6| Step: 2
Training loss: 2.999583692275535
Validation loss: 2.9821969943205184

Epoch: 6| Step: 3
Training loss: 3.3080676672771037
Validation loss: 2.9859461240284957

Epoch: 6| Step: 4
Training loss: 3.050993810616776
Validation loss: 2.988104756286822

Epoch: 6| Step: 5
Training loss: 3.12203075490071
Validation loss: 2.986368091155688

Epoch: 6| Step: 6
Training loss: 3.551957979348932
Validation loss: 2.986675756676124

Epoch: 6| Step: 7
Training loss: 3.1581520921008255
Validation loss: 2.9857252721793452

Epoch: 6| Step: 8
Training loss: 3.6593033520519813
Validation loss: 2.9851261888580645

Epoch: 6| Step: 9
Training loss: 3.0210610840981915
Validation loss: 2.9872767811214116

Epoch: 6| Step: 10
Training loss: 2.833649355897828
Validation loss: 2.985846215839486

Epoch: 6| Step: 11
Training loss: 3.5266831836662194
Validation loss: 2.988249898809468

Epoch: 6| Step: 12
Training loss: 3.480836859523116
Validation loss: 2.9849244221738673

Epoch: 6| Step: 13
Training loss: 3.6110977091092242
Validation loss: 2.979901900646811

Epoch: 190| Step: 0
Training loss: 3.1929042106809256
Validation loss: 2.984103368651333

Epoch: 6| Step: 1
Training loss: 3.9394585718619384
Validation loss: 2.9810069382646347

Epoch: 6| Step: 2
Training loss: 2.773572461780047
Validation loss: 2.9859331596091705

Epoch: 6| Step: 3
Training loss: 3.320740292983603
Validation loss: 2.981415591976129

Epoch: 6| Step: 4
Training loss: 3.1853148506280875
Validation loss: 2.9854210286008787

Epoch: 6| Step: 5
Training loss: 3.3189596853448426
Validation loss: 2.9834930193863265

Epoch: 6| Step: 6
Training loss: 3.642343402080479
Validation loss: 2.9839614369436105

Epoch: 6| Step: 7
Training loss: 3.222963704557275
Validation loss: 2.986270988847754

Epoch: 6| Step: 8
Training loss: 3.118095705434179
Validation loss: 2.9856649878443613

Epoch: 6| Step: 9
Training loss: 3.2809373979162433
Validation loss: 2.983610392308955

Epoch: 6| Step: 10
Training loss: 2.7190673467524737
Validation loss: 2.982575861110964

Epoch: 6| Step: 11
Training loss: 2.7014911984179024
Validation loss: 2.9831835165770477

Epoch: 6| Step: 12
Training loss: 3.5921433547710184
Validation loss: 2.9832277803715743

Epoch: 6| Step: 13
Training loss: 3.543438830834218
Validation loss: 2.9800234462644024

Epoch: 191| Step: 0
Training loss: 3.1257454555209643
Validation loss: 2.9791364392181947

Epoch: 6| Step: 1
Training loss: 3.5231849596823377
Validation loss: 2.978675017493899

Epoch: 6| Step: 2
Training loss: 2.691878367347285
Validation loss: 2.9776594010760578

Epoch: 6| Step: 3
Training loss: 3.6210121055048807
Validation loss: 2.977729852461944

Epoch: 6| Step: 4
Training loss: 3.1065387921627368
Validation loss: 2.9803214943922836

Epoch: 6| Step: 5
Training loss: 3.527107442077571
Validation loss: 2.976802941209157

Epoch: 6| Step: 6
Training loss: 2.9047437476693228
Validation loss: 2.9793400245400474

Epoch: 6| Step: 7
Training loss: 3.788243281889478
Validation loss: 2.9791360786554906

Epoch: 6| Step: 8
Training loss: 3.580659326970427
Validation loss: 2.9779178702088025

Epoch: 6| Step: 9
Training loss: 3.051602808563544
Validation loss: 2.978979935413563

Epoch: 6| Step: 10
Training loss: 3.7780519943819484
Validation loss: 2.981955983034842

Epoch: 6| Step: 11
Training loss: 3.2251468536297736
Validation loss: 2.976877245137856

Epoch: 6| Step: 12
Training loss: 2.1800489775379157
Validation loss: 2.9754347922192723

Epoch: 6| Step: 13
Training loss: 2.948390334034592
Validation loss: 2.979365786119634

Epoch: 192| Step: 0
Training loss: 3.0842979228274645
Validation loss: 2.9757211473809884

Epoch: 6| Step: 1
Training loss: 3.6195757831260393
Validation loss: 2.9757114070299853

Epoch: 6| Step: 2
Training loss: 3.095101109641856
Validation loss: 2.9778144332486907

Epoch: 6| Step: 3
Training loss: 2.7548138360682057
Validation loss: 2.9755892596667866

Epoch: 6| Step: 4
Training loss: 2.6810052150859147
Validation loss: 2.973881517155284

Epoch: 6| Step: 5
Training loss: 3.1901340446889526
Validation loss: 2.9753194731698365

Epoch: 6| Step: 6
Training loss: 2.827960099107403
Validation loss: 2.975293704989466

Epoch: 6| Step: 7
Training loss: 3.423860435529232
Validation loss: 2.9751132180742896

Epoch: 6| Step: 8
Training loss: 2.692303822063976
Validation loss: 2.9756324647283834

Epoch: 6| Step: 9
Training loss: 3.7249317239738238
Validation loss: 2.9726815011803196

Epoch: 6| Step: 10
Training loss: 3.6410101821870193
Validation loss: 2.9741899907902734

Epoch: 6| Step: 11
Training loss: 3.4925911006637387
Validation loss: 2.977265825851626

Epoch: 6| Step: 12
Training loss: 3.7592798488939083
Validation loss: 2.975715514763714

Epoch: 6| Step: 13
Training loss: 3.3193074938101708
Validation loss: 2.97378023552231

Epoch: 193| Step: 0
Training loss: 3.2348832915065064
Validation loss: 2.97342215534987

Epoch: 6| Step: 1
Training loss: 3.0413000504231906
Validation loss: 2.972910156031312

Epoch: 6| Step: 2
Training loss: 3.3621674043459215
Validation loss: 2.975819451979857

Epoch: 6| Step: 3
Training loss: 3.267996916808001
Validation loss: 2.9762228124710615

Epoch: 6| Step: 4
Training loss: 3.408858673970871
Validation loss: 2.9754663508108

Epoch: 6| Step: 5
Training loss: 4.159376760893692
Validation loss: 2.97250704633228

Epoch: 6| Step: 6
Training loss: 2.140972693948456
Validation loss: 2.9725971822705026

Epoch: 6| Step: 7
Training loss: 3.30775572557338
Validation loss: 2.9725118657026077

Epoch: 6| Step: 8
Training loss: 3.4817651117582633
Validation loss: 2.973007532608077

Epoch: 6| Step: 9
Training loss: 3.237888804768987
Validation loss: 2.972773076304897

Epoch: 6| Step: 10
Training loss: 2.4427705172585887
Validation loss: 2.971912145964216

Epoch: 6| Step: 11
Training loss: 3.461784999577643
Validation loss: 2.9706205725884387

Epoch: 6| Step: 12
Training loss: 3.1669190122212254
Validation loss: 2.9707226937421924

Epoch: 6| Step: 13
Training loss: 3.4547479880432195
Validation loss: 2.969982716831973

Epoch: 194| Step: 0
Training loss: 2.5455268146733774
Validation loss: 2.971949374827022

Epoch: 6| Step: 1
Training loss: 2.8993014053243957
Validation loss: 2.9727278392979284

Epoch: 6| Step: 2
Training loss: 3.5764293400885183
Validation loss: 2.9703252105295075

Epoch: 6| Step: 3
Training loss: 3.3609223816344067
Validation loss: 2.9719229563396357

Epoch: 6| Step: 4
Training loss: 3.3995201052657356
Validation loss: 2.9721120107853753

Epoch: 6| Step: 5
Training loss: 4.080800315303225
Validation loss: 2.9695433372130715

Epoch: 6| Step: 6
Training loss: 3.0813643552285166
Validation loss: 2.9702495939007765

Epoch: 6| Step: 7
Training loss: 2.9916029077676187
Validation loss: 2.9722642427585013

Epoch: 6| Step: 8
Training loss: 2.2518916125800437
Validation loss: 2.9692445041997155

Epoch: 6| Step: 9
Training loss: 3.591694384923013
Validation loss: 2.9695700436313444

Epoch: 6| Step: 10
Training loss: 3.622467866680034
Validation loss: 2.970173708640352

Epoch: 6| Step: 11
Training loss: 3.308795945295657
Validation loss: 2.9683015390730345

Epoch: 6| Step: 12
Training loss: 2.751046588454682
Validation loss: 2.9694790474433153

Epoch: 6| Step: 13
Training loss: 3.736765842352353
Validation loss: 2.9685218727703124

Epoch: 195| Step: 0
Training loss: 3.5401549011219817
Validation loss: 2.968019526216259

Epoch: 6| Step: 1
Training loss: 3.290620919394431
Validation loss: 2.970819684660454

Epoch: 6| Step: 2
Training loss: 2.952275391125697
Validation loss: 2.9684251729548197

Epoch: 6| Step: 3
Training loss: 3.9303886743591607
Validation loss: 2.9686429913874828

Epoch: 6| Step: 4
Training loss: 2.4291094616740585
Validation loss: 2.9696501407263907

Epoch: 6| Step: 5
Training loss: 3.5650327279192338
Validation loss: 2.9714390819309133

Epoch: 6| Step: 6
Training loss: 3.5614176662042683
Validation loss: 2.971232869809933

Epoch: 6| Step: 7
Training loss: 3.25288028731065
Validation loss: 2.969418772577496

Epoch: 6| Step: 8
Training loss: 3.3203047449357963
Validation loss: 2.968776056405244

Epoch: 6| Step: 9
Training loss: 2.214918131983749
Validation loss: 2.970790261695333

Epoch: 6| Step: 10
Training loss: 3.2538489511855566
Validation loss: 2.968378719305683

Epoch: 6| Step: 11
Training loss: 2.999083855932433
Validation loss: 2.9680394719713714

Epoch: 6| Step: 12
Training loss: 3.317985311511307
Validation loss: 2.966887361554176

Epoch: 6| Step: 13
Training loss: 3.5593628036651777
Validation loss: 2.9662271035264616

Epoch: 196| Step: 0
Training loss: 3.4550349274345233
Validation loss: 2.96588255521141

Epoch: 6| Step: 1
Training loss: 2.6115366496538686
Validation loss: 2.963713263026129

Epoch: 6| Step: 2
Training loss: 2.8752746450848776
Validation loss: 2.9664758474553334

Epoch: 6| Step: 3
Training loss: 2.0687956237372
Validation loss: 2.967142716839392

Epoch: 6| Step: 4
Training loss: 3.1230978708117596
Validation loss: 2.9644720163946094

Epoch: 6| Step: 5
Training loss: 3.6809779534585174
Validation loss: 2.9642014342797856

Epoch: 6| Step: 6
Training loss: 4.1664992998205665
Validation loss: 2.964994514338655

Epoch: 6| Step: 7
Training loss: 3.2825970019311543
Validation loss: 2.9678712918533896

Epoch: 6| Step: 8
Training loss: 4.087766511493805
Validation loss: 2.965673286481176

Epoch: 6| Step: 9
Training loss: 2.751982061316553
Validation loss: 2.9694661820703323

Epoch: 6| Step: 10
Training loss: 3.248171658851516
Validation loss: 2.968432807492581

Epoch: 6| Step: 11
Training loss: 3.0187938426370327
Validation loss: 2.965032942831227

Epoch: 6| Step: 12
Training loss: 3.3360532789664106
Validation loss: 2.970766525323924

Epoch: 6| Step: 13
Training loss: 2.990572421290349
Validation loss: 2.966592061619966

Epoch: 197| Step: 0
Training loss: 3.3770528131071105
Validation loss: 2.968314643548098

Epoch: 6| Step: 1
Training loss: 2.8496923715637847
Validation loss: 2.9652292718432927

Epoch: 6| Step: 2
Training loss: 2.493908709301443
Validation loss: 2.9633608180994413

Epoch: 6| Step: 3
Training loss: 3.389709630362729
Validation loss: 2.9631680855183635

Epoch: 6| Step: 4
Training loss: 2.926694108780771
Validation loss: 2.9666788316868784

Epoch: 6| Step: 5
Training loss: 3.5482274640440794
Validation loss: 2.9654354155927396

Epoch: 6| Step: 6
Training loss: 4.16028989478702
Validation loss: 2.9656740618819457

Epoch: 6| Step: 7
Training loss: 3.6547749470152167
Validation loss: 2.9657560500766187

Epoch: 6| Step: 8
Training loss: 3.462692057106527
Validation loss: 2.970061801963319

Epoch: 6| Step: 9
Training loss: 2.7058967095430795
Validation loss: 2.9706236483129453

Epoch: 6| Step: 10
Training loss: 3.2402123007272503
Validation loss: 2.9674714578451784

Epoch: 6| Step: 11
Training loss: 3.3535763396786193
Validation loss: 2.9667122428004515

Epoch: 6| Step: 12
Training loss: 3.141133129710043
Validation loss: 2.9635186528158726

Epoch: 6| Step: 13
Training loss: 2.196885492291634
Validation loss: 2.9648020193922973

Epoch: 198| Step: 0
Training loss: 2.9267918632799828
Validation loss: 2.96304307117777

Epoch: 6| Step: 1
Training loss: 4.371520920676477
Validation loss: 2.9620517157374473

Epoch: 6| Step: 2
Training loss: 2.7942589827419857
Validation loss: 2.9623486763835065

Epoch: 6| Step: 3
Training loss: 3.7510098687013893
Validation loss: 2.9617300872971364

Epoch: 6| Step: 4
Training loss: 3.2824974958376836
Validation loss: 2.963737343067534

Epoch: 6| Step: 5
Training loss: 2.8220902437938107
Validation loss: 2.958972427429058

Epoch: 6| Step: 6
Training loss: 3.4165945898377514
Validation loss: 2.9613390940335047

Epoch: 6| Step: 7
Training loss: 2.808978779892912
Validation loss: 2.9621860236521127

Epoch: 6| Step: 8
Training loss: 2.2954598563241855
Validation loss: 2.9602288414834694

Epoch: 6| Step: 9
Training loss: 3.294660502470336
Validation loss: 2.9619235729846003

Epoch: 6| Step: 10
Training loss: 3.1859707623401583
Validation loss: 2.9640576691057055

Epoch: 6| Step: 11
Training loss: 3.0546934317997074
Validation loss: 2.962913085070185

Epoch: 6| Step: 12
Training loss: 3.1298951528130363
Validation loss: 2.9628362054768793

Epoch: 6| Step: 13
Training loss: 4.070628558461446
Validation loss: 2.964336677399673

Epoch: 199| Step: 0
Training loss: 2.5956516877898257
Validation loss: 2.9640140116293163

Epoch: 6| Step: 1
Training loss: 3.59607482016763
Validation loss: 2.9656738838077623

Epoch: 6| Step: 2
Training loss: 2.8021088968881154
Validation loss: 2.9684808718113955

Epoch: 6| Step: 3
Training loss: 2.9444033082051835
Validation loss: 2.9682530935555835

Epoch: 6| Step: 4
Training loss: 3.4467832579037125
Validation loss: 2.9676245187543957

Epoch: 6| Step: 5
Training loss: 3.5843222975909703
Validation loss: 2.968947269640598

Epoch: 6| Step: 6
Training loss: 3.3695080189177147
Validation loss: 2.9634340325352677

Epoch: 6| Step: 7
Training loss: 3.080988757218522
Validation loss: 2.9602062328739365

Epoch: 6| Step: 8
Training loss: 3.56978731862896
Validation loss: 2.9674370393051226

Epoch: 6| Step: 9
Training loss: 3.1808944773291867
Validation loss: 2.9692219227949015

Epoch: 6| Step: 10
Training loss: 3.6938323913783235
Validation loss: 2.9629944687353826

Epoch: 6| Step: 11
Training loss: 3.008148887946816
Validation loss: 2.9637872048604623

Epoch: 6| Step: 12
Training loss: 3.341900465500652
Validation loss: 2.960773069178831

Epoch: 6| Step: 13
Training loss: 2.725018083004929
Validation loss: 2.9583682714326165

Epoch: 200| Step: 0
Training loss: 3.3748635158492486
Validation loss: 2.958216699683866

Epoch: 6| Step: 1
Training loss: 2.2060238860109007
Validation loss: 2.959145715333416

Epoch: 6| Step: 2
Training loss: 3.2439701189388845
Validation loss: 2.9561867252118557

Epoch: 6| Step: 3
Training loss: 3.899699341359912
Validation loss: 2.959860533297442

Epoch: 6| Step: 4
Training loss: 2.8771664293697854
Validation loss: 2.9563477985170543

Epoch: 6| Step: 5
Training loss: 3.553249462299686
Validation loss: 2.9580130021640008

Epoch: 6| Step: 6
Training loss: 2.566873028951575
Validation loss: 2.9558310029277712

Epoch: 6| Step: 7
Training loss: 3.3107349803675756
Validation loss: 2.9582372271675528

Epoch: 6| Step: 8
Training loss: 3.055496615987735
Validation loss: 2.9578716473006583

Epoch: 6| Step: 9
Training loss: 3.47171745869924
Validation loss: 2.9577592231707177

Epoch: 6| Step: 10
Training loss: 2.897833007950557
Validation loss: 2.9563931144658846

Epoch: 6| Step: 11
Training loss: 3.8281918889644118
Validation loss: 2.957539224928734

Epoch: 6| Step: 12
Training loss: 3.5312845684148706
Validation loss: 2.956660457316511

Epoch: 6| Step: 13
Training loss: 2.9894125398946194
Validation loss: 2.9557631381114864

Epoch: 201| Step: 0
Training loss: 3.6407166825566755
Validation loss: 2.9543908999895194

Epoch: 6| Step: 1
Training loss: 3.9843204270159696
Validation loss: 2.9594374356498694

Epoch: 6| Step: 2
Training loss: 3.667345735494861
Validation loss: 2.9564940040836567

Epoch: 6| Step: 3
Training loss: 2.5550103873024925
Validation loss: 2.9565451300146988

Epoch: 6| Step: 4
Training loss: 2.755355561811066
Validation loss: 2.9561101910267262

Epoch: 6| Step: 5
Training loss: 3.002654808303337
Validation loss: 2.955679190909184

Epoch: 6| Step: 6
Training loss: 3.4160013869235866
Validation loss: 2.956868580475096

Epoch: 6| Step: 7
Training loss: 2.741992041422551
Validation loss: 2.9563570095268084

Epoch: 6| Step: 8
Training loss: 3.149636014465895
Validation loss: 2.9570313262928605

Epoch: 6| Step: 9
Training loss: 3.775849197568775
Validation loss: 2.9568764139184265

Epoch: 6| Step: 10
Training loss: 2.2738801191028135
Validation loss: 2.9578276887698527

Epoch: 6| Step: 11
Training loss: 2.951612781684022
Validation loss: 2.9562070335129778

Epoch: 6| Step: 12
Training loss: 3.2628836921354276
Validation loss: 2.959781386498644

Epoch: 6| Step: 13
Training loss: 3.8378031558098624
Validation loss: 2.9569210082278605

Epoch: 202| Step: 0
Training loss: 2.753121511779723
Validation loss: 2.9631437274552948

Epoch: 6| Step: 1
Training loss: 3.005188587637326
Validation loss: 2.9582819768829074

Epoch: 6| Step: 2
Training loss: 2.5568201338635324
Validation loss: 2.9688921097235528

Epoch: 6| Step: 3
Training loss: 3.271152035358145
Validation loss: 2.9710251851080236

Epoch: 6| Step: 4
Training loss: 3.9311179862121914
Validation loss: 2.9722841772794037

Epoch: 6| Step: 5
Training loss: 3.597836103717264
Validation loss: 2.963372441728874

Epoch: 6| Step: 6
Training loss: 3.398731859108934
Validation loss: 2.963055710070163

Epoch: 6| Step: 7
Training loss: 3.4826754543472034
Validation loss: 2.9687158907542965

Epoch: 6| Step: 8
Training loss: 2.7898123451757764
Validation loss: 2.954708527507061

Epoch: 6| Step: 9
Training loss: 3.0609514642136966
Validation loss: 2.9528451025036078

Epoch: 6| Step: 10
Training loss: 3.3161692899738435
Validation loss: 2.9526655615953104

Epoch: 6| Step: 11
Training loss: 2.808422269082677
Validation loss: 2.9497213034208976

Epoch: 6| Step: 12
Training loss: 3.8828883940803385
Validation loss: 2.9504158687689674

Epoch: 6| Step: 13
Training loss: 3.0531598341954735
Validation loss: 2.952719628527276

Epoch: 203| Step: 0
Training loss: 3.5486010414241114
Validation loss: 2.95063217206873

Epoch: 6| Step: 1
Training loss: 3.636613330071149
Validation loss: 2.949580940097148

Epoch: 6| Step: 2
Training loss: 2.8365824152638304
Validation loss: 2.9486029534232077

Epoch: 6| Step: 3
Training loss: 2.231830775651465
Validation loss: 2.9490301099987684

Epoch: 6| Step: 4
Training loss: 3.2334456283365416
Validation loss: 2.946513470578673

Epoch: 6| Step: 5
Training loss: 2.4608552464862568
Validation loss: 2.94812329255645

Epoch: 6| Step: 6
Training loss: 3.024175824841483
Validation loss: 2.948194447141919

Epoch: 6| Step: 7
Training loss: 3.4518421949119023
Validation loss: 2.949221477739539

Epoch: 6| Step: 8
Training loss: 3.356049919202732
Validation loss: 2.950013083193775

Epoch: 6| Step: 9
Training loss: 3.008966397981155
Validation loss: 2.952599600195189

Epoch: 6| Step: 10
Training loss: 3.6986007415884607
Validation loss: 2.9562249490685546

Epoch: 6| Step: 11
Training loss: 3.710625757876244
Validation loss: 2.9731577700173895

Epoch: 6| Step: 12
Training loss: 3.4254329769697605
Validation loss: 2.9802679987401155

Epoch: 6| Step: 13
Training loss: 3.3627838582192
Validation loss: 2.9811235878096927

Epoch: 204| Step: 0
Training loss: 3.1099521733865867
Validation loss: 2.9850196238826174

Epoch: 6| Step: 1
Training loss: 3.1513699111004656
Validation loss: 2.9908038904886736

Epoch: 6| Step: 2
Training loss: 3.6001927218243948
Validation loss: 3.0011077172308256

Epoch: 6| Step: 3
Training loss: 2.9091432997472566
Validation loss: 2.9885078260097857

Epoch: 6| Step: 4
Training loss: 2.940133071275285
Validation loss: 2.9790671226025247

Epoch: 6| Step: 5
Training loss: 3.6689229583262306
Validation loss: 2.948201452332653

Epoch: 6| Step: 6
Training loss: 3.424769462010534
Validation loss: 2.948762166646557

Epoch: 6| Step: 7
Training loss: 4.144467970844091
Validation loss: 2.94982443402312

Epoch: 6| Step: 8
Training loss: 2.1225687592313225
Validation loss: 2.9575287581138934

Epoch: 6| Step: 9
Training loss: 2.9908898629916796
Validation loss: 2.969256774790897

Epoch: 6| Step: 10
Training loss: 3.465914142678867
Validation loss: 2.975820137726336

Epoch: 6| Step: 11
Training loss: 3.2741098373528614
Validation loss: 2.9675202271270367

Epoch: 6| Step: 12
Training loss: 2.9540592713914937
Validation loss: 2.9587965698921983

Epoch: 6| Step: 13
Training loss: 3.174140459391302
Validation loss: 2.952188830769809

Epoch: 205| Step: 0
Training loss: 2.8055583483825814
Validation loss: 2.961930085242753

Epoch: 6| Step: 1
Training loss: 3.434905859311009
Validation loss: 2.976821356320682

Epoch: 6| Step: 2
Training loss: 2.6805237113189953
Validation loss: 2.9855279648001236

Epoch: 6| Step: 3
Training loss: 2.8270132503570076
Validation loss: 2.9946078573195223

Epoch: 6| Step: 4
Training loss: 2.7077177864323145
Validation loss: 3.0018240141720756

Epoch: 6| Step: 5
Training loss: 3.0656373438844247
Validation loss: 3.0041377440301624

Epoch: 6| Step: 6
Training loss: 3.359284297694498
Validation loss: 3.0109872599073064

Epoch: 6| Step: 7
Training loss: 3.1880382008674912
Validation loss: 3.0050425877338816

Epoch: 6| Step: 8
Training loss: 4.019340962909597
Validation loss: 3.008769601600528

Epoch: 6| Step: 9
Training loss: 2.2997154267112614
Validation loss: 3.0085536785646556

Epoch: 6| Step: 10
Training loss: 3.0549060323845016
Validation loss: 3.006792073257137

Epoch: 6| Step: 11
Training loss: 4.451266573559341
Validation loss: 3.000549640347031

Epoch: 6| Step: 12
Training loss: 3.9326316164451587
Validation loss: 3.0014657034315437

Epoch: 6| Step: 13
Training loss: 3.368462907380522
Validation loss: 3.0004858337978164

Epoch: 206| Step: 0
Training loss: 3.8492264849935602
Validation loss: 2.9912898869076114

Epoch: 6| Step: 1
Training loss: 2.7962490638727933
Validation loss: 2.998229162151082

Epoch: 6| Step: 2
Training loss: 3.50199901169916
Validation loss: 2.993829431378566

Epoch: 6| Step: 3
Training loss: 3.7125295978226855
Validation loss: 2.9907327621654196

Epoch: 6| Step: 4
Training loss: 2.584796204197988
Validation loss: 2.994840326043192

Epoch: 6| Step: 5
Training loss: 3.2996179821958442
Validation loss: 2.99565125501014

Epoch: 6| Step: 6
Training loss: 2.905619891369998
Validation loss: 3.003801096355027

Epoch: 6| Step: 7
Training loss: 3.4622209291886916
Validation loss: 2.9944498103319583

Epoch: 6| Step: 8
Training loss: 2.8775683002336825
Validation loss: 2.9957740665442425

Epoch: 6| Step: 9
Training loss: 3.1178240974534037
Validation loss: 2.990269835991323

Epoch: 6| Step: 10
Training loss: 3.4049870660791086
Validation loss: 2.9846773841064076

Epoch: 6| Step: 11
Training loss: 3.8519249797737087
Validation loss: 2.9780542844202316

Epoch: 6| Step: 12
Training loss: 3.0002736920442525
Validation loss: 2.9716113046666903

Epoch: 6| Step: 13
Training loss: 2.8709323137011635
Validation loss: 2.9583683485575696

Epoch: 207| Step: 0
Training loss: 3.3632092263266684
Validation loss: 2.9533513721315257

Epoch: 6| Step: 1
Training loss: 3.5189292469071853
Validation loss: 2.9595197066310113

Epoch: 6| Step: 2
Training loss: 2.857303390080211
Validation loss: 2.960031700132207

Epoch: 6| Step: 3
Training loss: 2.8739218970977056
Validation loss: 2.9577659352825085

Epoch: 6| Step: 4
Training loss: 3.264813920190809
Validation loss: 2.9628634170938972

Epoch: 6| Step: 5
Training loss: 2.924582303210904
Validation loss: 2.970717683341823

Epoch: 6| Step: 6
Training loss: 3.2418918704639537
Validation loss: 2.9735782102283173

Epoch: 6| Step: 7
Training loss: 3.7273191567550903
Validation loss: 2.9714694474986683

Epoch: 6| Step: 8
Training loss: 3.7748437002805626
Validation loss: 2.956362109302487

Epoch: 6| Step: 9
Training loss: 3.811064653203033
Validation loss: 2.9527056881887446

Epoch: 6| Step: 10
Training loss: 2.7303465023152422
Validation loss: 2.9457601128394137

Epoch: 6| Step: 11
Training loss: 2.155785662646615
Validation loss: 2.9443247663658467

Epoch: 6| Step: 12
Training loss: 3.19061964372714
Validation loss: 2.9455277663551773

Epoch: 6| Step: 13
Training loss: 3.613809346965584
Validation loss: 2.9461354935652118

Epoch: 208| Step: 0
Training loss: 3.038093000383545
Validation loss: 2.948505558608063

Epoch: 6| Step: 1
Training loss: 2.996251625566674
Validation loss: 2.947278083648756

Epoch: 6| Step: 2
Training loss: 2.721647450585009
Validation loss: 2.9447155340922957

Epoch: 6| Step: 3
Training loss: 3.051713437177371
Validation loss: 2.9421754630990695

Epoch: 6| Step: 4
Training loss: 3.543863236167236
Validation loss: 2.9472708579346363

Epoch: 6| Step: 5
Training loss: 2.3560135497592474
Validation loss: 2.943044286585015

Epoch: 6| Step: 6
Training loss: 3.2823943549512777
Validation loss: 2.946558311339472

Epoch: 6| Step: 7
Training loss: 4.2252513381868315
Validation loss: 2.9432432312343115

Epoch: 6| Step: 8
Training loss: 2.455296909534761
Validation loss: 2.944713881711536

Epoch: 6| Step: 9
Training loss: 4.008729469144446
Validation loss: 2.9430868378903647

Epoch: 6| Step: 10
Training loss: 3.6201962178620586
Validation loss: 2.9436652268929784

Epoch: 6| Step: 11
Training loss: 2.8713792308643185
Validation loss: 2.941786360575052

Epoch: 6| Step: 12
Training loss: 3.164843050905563
Validation loss: 2.940170432229149

Epoch: 6| Step: 13
Training loss: 3.38859673232609
Validation loss: 2.9440785622672094

Epoch: 209| Step: 0
Training loss: 2.7737428309041534
Validation loss: 2.939339438200119

Epoch: 6| Step: 1
Training loss: 4.0653411320450665
Validation loss: 2.9411743998294035

Epoch: 6| Step: 2
Training loss: 2.976408065834595
Validation loss: 2.938551844270012

Epoch: 6| Step: 3
Training loss: 2.767342761361936
Validation loss: 2.938336921880346

Epoch: 6| Step: 4
Training loss: 2.5732882356233264
Validation loss: 2.940364801279698

Epoch: 6| Step: 5
Training loss: 2.927941699891141
Validation loss: 2.9405105835855516

Epoch: 6| Step: 6
Training loss: 2.8639368240911414
Validation loss: 2.941704778858087

Epoch: 6| Step: 7
Training loss: 3.2323892735799302
Validation loss: 2.9431211770917236

Epoch: 6| Step: 8
Training loss: 3.339232057471085
Validation loss: 2.9361727658777976

Epoch: 6| Step: 9
Training loss: 3.205648033340477
Validation loss: 2.9421731819252

Epoch: 6| Step: 10
Training loss: 4.0712959726869276
Validation loss: 2.948642564086649

Epoch: 6| Step: 11
Training loss: 3.483737356917835
Validation loss: 2.947641988129735

Epoch: 6| Step: 12
Training loss: 3.3904970206441813
Validation loss: 2.9428123555195804

Epoch: 6| Step: 13
Training loss: 2.906410951156838
Validation loss: 2.9428064142482144

Epoch: 210| Step: 0
Training loss: 3.4210068807747382
Validation loss: 2.9412792944141035

Epoch: 6| Step: 1
Training loss: 3.039500697692299
Validation loss: 2.9394330820791574

Epoch: 6| Step: 2
Training loss: 3.6174239870216875
Validation loss: 2.940572199020998

Epoch: 6| Step: 3
Training loss: 3.3902800072452504
Validation loss: 2.9376775111505427

Epoch: 6| Step: 4
Training loss: 2.920853543359018
Validation loss: 2.9378457233587754

Epoch: 6| Step: 5
Training loss: 2.6117465269646787
Validation loss: 2.937909659971894

Epoch: 6| Step: 6
Training loss: 3.425319105444206
Validation loss: 2.937177763897939

Epoch: 6| Step: 7
Training loss: 3.46858778565667
Validation loss: 2.936543921945415

Epoch: 6| Step: 8
Training loss: 2.9951584212702103
Validation loss: 2.936529482277053

Epoch: 6| Step: 9
Training loss: 3.311878937853711
Validation loss: 2.9390703854721627

Epoch: 6| Step: 10
Training loss: 3.305545343833843
Validation loss: 2.935136469498515

Epoch: 6| Step: 11
Training loss: 2.7033469930351517
Validation loss: 2.9336660705646933

Epoch: 6| Step: 12
Training loss: 3.140737958556302
Validation loss: 2.9331676972889653

Epoch: 6| Step: 13
Training loss: 3.769149840038546
Validation loss: 2.934721593407656

Epoch: 211| Step: 0
Training loss: 3.3167720094242235
Validation loss: 2.9355635551618606

Epoch: 6| Step: 1
Training loss: 2.988925839384417
Validation loss: 2.9318691517468913

Epoch: 6| Step: 2
Training loss: 3.011295828211244
Validation loss: 2.9346079189919907

Epoch: 6| Step: 3
Training loss: 3.3862488804586874
Validation loss: 2.932363593872581

Epoch: 6| Step: 4
Training loss: 3.18731180271243
Validation loss: 2.9331013708279703

Epoch: 6| Step: 5
Training loss: 2.6738489901144447
Validation loss: 2.9324861394717963

Epoch: 6| Step: 6
Training loss: 3.061132476033606
Validation loss: 2.933069167612958

Epoch: 6| Step: 7
Training loss: 2.8972792457567955
Validation loss: 2.931960091939579

Epoch: 6| Step: 8
Training loss: 3.522983564075913
Validation loss: 2.931576429232621

Epoch: 6| Step: 9
Training loss: 3.5194472494484685
Validation loss: 2.9316822880965914

Epoch: 6| Step: 10
Training loss: 3.7844870086902547
Validation loss: 2.9333545475926326

Epoch: 6| Step: 11
Training loss: 3.5495996974856387
Validation loss: 2.9321295816678368

Epoch: 6| Step: 12
Training loss: 3.452918965678882
Validation loss: 2.931434861272816

Epoch: 6| Step: 13
Training loss: 1.4855741776699065
Validation loss: 2.9313291727595616

Epoch: 212| Step: 0
Training loss: 3.13556958878577
Validation loss: 2.9302230238318856

Epoch: 6| Step: 1
Training loss: 2.7920164392091182
Validation loss: 2.931950609297667

Epoch: 6| Step: 2
Training loss: 3.5420168236064233
Validation loss: 2.9316079195265616

Epoch: 6| Step: 3
Training loss: 3.5402059497300304
Validation loss: 2.9330626105041935

Epoch: 6| Step: 4
Training loss: 3.1545695750928626
Validation loss: 2.9281427764239165

Epoch: 6| Step: 5
Training loss: 3.885553079755275
Validation loss: 2.9309913845642295

Epoch: 6| Step: 6
Training loss: 2.888406097792795
Validation loss: 2.9376760433091578

Epoch: 6| Step: 7
Training loss: 3.0691659742553603
Validation loss: 2.9293439171149216

Epoch: 6| Step: 8
Training loss: 2.685518820876196
Validation loss: 2.9281942450267264

Epoch: 6| Step: 9
Training loss: 3.165337953046188
Validation loss: 2.929421981975647

Epoch: 6| Step: 10
Training loss: 3.1378611079465695
Validation loss: 2.9308106378590715

Epoch: 6| Step: 11
Training loss: 3.1329099112037597
Validation loss: 2.929501528945684

Epoch: 6| Step: 12
Training loss: 3.094669089922709
Validation loss: 2.9299381700696485

Epoch: 6| Step: 13
Training loss: 3.807646617007645
Validation loss: 2.928812804327044

Epoch: 213| Step: 0
Training loss: 3.0620101225503134
Validation loss: 2.928096184506828

Epoch: 6| Step: 1
Training loss: 2.91633954711466
Validation loss: 2.927981604951205

Epoch: 6| Step: 2
Training loss: 3.2102664886804533
Validation loss: 2.927096515781002

Epoch: 6| Step: 3
Training loss: 2.7942760475776045
Validation loss: 2.9285099682599567

Epoch: 6| Step: 4
Training loss: 2.693030234205734
Validation loss: 2.927805217777964

Epoch: 6| Step: 5
Training loss: 3.6035402374667598
Validation loss: 2.925777610161983

Epoch: 6| Step: 6
Training loss: 3.5927467604422065
Validation loss: 2.9266113302404815

Epoch: 6| Step: 7
Training loss: 3.332853441662059
Validation loss: 2.9252136408022817

Epoch: 6| Step: 8
Training loss: 2.773060947699008
Validation loss: 2.9279187614151265

Epoch: 6| Step: 9
Training loss: 3.451968314342572
Validation loss: 2.928877117562536

Epoch: 6| Step: 10
Training loss: 3.3235374675972813
Validation loss: 2.928409720964221

Epoch: 6| Step: 11
Training loss: 2.6367995864344707
Validation loss: 2.9257409223747657

Epoch: 6| Step: 12
Training loss: 4.31009418995334
Validation loss: 2.925764549993355

Epoch: 6| Step: 13
Training loss: 2.5162715673304064
Validation loss: 2.927029717172223

Epoch: 214| Step: 0
Training loss: 2.897644428014102
Validation loss: 2.9246656984243438

Epoch: 6| Step: 1
Training loss: 2.8040111863298165
Validation loss: 2.925922471167535

Epoch: 6| Step: 2
Training loss: 2.8733316639528788
Validation loss: 2.9248901694346077

Epoch: 6| Step: 3
Training loss: 3.1321159216230128
Validation loss: 2.9260502770461985

Epoch: 6| Step: 4
Training loss: 3.5810337820241305
Validation loss: 2.924062003736031

Epoch: 6| Step: 5
Training loss: 3.519298211277689
Validation loss: 2.923813627793755

Epoch: 6| Step: 6
Training loss: 3.6918622093566786
Validation loss: 2.9289340183900174

Epoch: 6| Step: 7
Training loss: 2.420538355002777
Validation loss: 2.925922418596614

Epoch: 6| Step: 8
Training loss: 3.906469476256137
Validation loss: 2.926250321860607

Epoch: 6| Step: 9
Training loss: 3.529005029092666
Validation loss: 2.925709193683392

Epoch: 6| Step: 10
Training loss: 2.411283504555875
Validation loss: 2.9286401770315362

Epoch: 6| Step: 11
Training loss: 3.324806815823865
Validation loss: 2.9261675395270874

Epoch: 6| Step: 12
Training loss: 3.0000653259794268
Validation loss: 2.928238988978112

Epoch: 6| Step: 13
Training loss: 3.5502674163247185
Validation loss: 2.9241241156856557

Epoch: 215| Step: 0
Training loss: 3.377626315563622
Validation loss: 2.925204320333782

Epoch: 6| Step: 1
Training loss: 2.9629852541332258
Validation loss: 2.9286930111978244

Epoch: 6| Step: 2
Training loss: 3.44957346836496
Validation loss: 2.9244655013846073

Epoch: 6| Step: 3
Training loss: 3.2409034484304433
Validation loss: 2.9250541011342497

Epoch: 6| Step: 4
Training loss: 1.9871535185133877
Validation loss: 2.9229657976155914

Epoch: 6| Step: 5
Training loss: 2.5128400088596434
Validation loss: 2.9215990644402554

Epoch: 6| Step: 6
Training loss: 3.5465032575961546
Validation loss: 2.927739768935974

Epoch: 6| Step: 7
Training loss: 3.1233845922388674
Validation loss: 2.924305770114147

Epoch: 6| Step: 8
Training loss: 3.3505746946310206
Validation loss: 2.926023937418367

Epoch: 6| Step: 9
Training loss: 3.464500504859098
Validation loss: 2.924162136630754

Epoch: 6| Step: 10
Training loss: 2.4887254159844536
Validation loss: 2.9260246523580085

Epoch: 6| Step: 11
Training loss: 4.164403046214816
Validation loss: 2.9261058030050737

Epoch: 6| Step: 12
Training loss: 3.626146464087753
Validation loss: 2.9281763330715105

Epoch: 6| Step: 13
Training loss: 2.880810877504923
Validation loss: 2.9231222238231713

Epoch: 216| Step: 0
Training loss: 3.2956819952079113
Validation loss: 2.919501317381642

Epoch: 6| Step: 1
Training loss: 2.903244761777682
Validation loss: 2.92184490166201

Epoch: 6| Step: 2
Training loss: 3.3573852324025735
Validation loss: 2.92235134668989

Epoch: 6| Step: 3
Training loss: 3.3403778184558313
Validation loss: 2.9190898380782455

Epoch: 6| Step: 4
Training loss: 3.570351097515998
Validation loss: 2.9177234674673294

Epoch: 6| Step: 5
Training loss: 3.388255895757686
Validation loss: 2.9200891030713994

Epoch: 6| Step: 6
Training loss: 3.412213346298015
Validation loss: 2.9217593043090675

Epoch: 6| Step: 7
Training loss: 3.026944120548534
Validation loss: 2.918893342669162

Epoch: 6| Step: 8
Training loss: 3.0957360876596822
Validation loss: 2.9208307554785318

Epoch: 6| Step: 9
Training loss: 3.033037425548896
Validation loss: 2.9172291513607265

Epoch: 6| Step: 10
Training loss: 3.1648077946496525
Validation loss: 2.9167725053092135

Epoch: 6| Step: 11
Training loss: 3.5524121054957782
Validation loss: 2.9184560935329844

Epoch: 6| Step: 12
Training loss: 2.8438237778032622
Validation loss: 2.9170159659587234

Epoch: 6| Step: 13
Training loss: 2.3370426077266093
Validation loss: 2.9192120240597315

Epoch: 217| Step: 0
Training loss: 3.088368523018613
Validation loss: 2.9167594074558645

Epoch: 6| Step: 1
Training loss: 3.1286348184681994
Validation loss: 2.917570772692635

Epoch: 6| Step: 2
Training loss: 3.618312059431003
Validation loss: 2.917860460688754

Epoch: 6| Step: 3
Training loss: 3.212653154217965
Validation loss: 2.917299420562417

Epoch: 6| Step: 4
Training loss: 3.6125536376772613
Validation loss: 2.9170493307046206

Epoch: 6| Step: 5
Training loss: 3.732340110629793
Validation loss: 2.9169239586997127

Epoch: 6| Step: 6
Training loss: 3.3459089208087622
Validation loss: 2.9162821350694332

Epoch: 6| Step: 7
Training loss: 2.6616869764164237
Validation loss: 2.9179386342123705

Epoch: 6| Step: 8
Training loss: 2.822590761034721
Validation loss: 2.916994488366134

Epoch: 6| Step: 9
Training loss: 2.830341292651072
Validation loss: 2.915023111812403

Epoch: 6| Step: 10
Training loss: 2.8057243959423968
Validation loss: 2.9139694158971694

Epoch: 6| Step: 11
Training loss: 3.0026043078292104
Validation loss: 2.9148304856593654

Epoch: 6| Step: 12
Training loss: 2.7559368033450955
Validation loss: 2.915234398356714

Epoch: 6| Step: 13
Training loss: 4.382634069173166
Validation loss: 2.913196470553

Epoch: 218| Step: 0
Training loss: 3.0520724837768887
Validation loss: 2.9146271036351306

Epoch: 6| Step: 1
Training loss: 2.5682174353304856
Validation loss: 2.9207151650061443

Epoch: 6| Step: 2
Training loss: 3.7984453886162814
Validation loss: 2.9212370724427337

Epoch: 6| Step: 3
Training loss: 2.992619336393072
Validation loss: 2.916843179263292

Epoch: 6| Step: 4
Training loss: 2.937395296868625
Validation loss: 2.914581014285448

Epoch: 6| Step: 5
Training loss: 3.5569355657498893
Validation loss: 2.9139404271306253

Epoch: 6| Step: 6
Training loss: 2.3466154765195584
Validation loss: 2.920152645366362

Epoch: 6| Step: 7
Training loss: 2.9711533305001754
Validation loss: 2.9140713625678036

Epoch: 6| Step: 8
Training loss: 3.825080003088732
Validation loss: 2.9096688969641495

Epoch: 6| Step: 9
Training loss: 2.8090687484069106
Validation loss: 2.909458394908104

Epoch: 6| Step: 10
Training loss: 2.823488935245905
Validation loss: 2.9109924150235793

Epoch: 6| Step: 11
Training loss: 3.5130190537063846
Validation loss: 2.9140890242812714

Epoch: 6| Step: 12
Training loss: 3.9351668938770583
Validation loss: 2.909035783492559

Epoch: 6| Step: 13
Training loss: 3.2676226332985605
Validation loss: 2.9130636177661238

Epoch: 219| Step: 0
Training loss: 2.6284870419965642
Validation loss: 2.910417187049334

Epoch: 6| Step: 1
Training loss: 2.7302148179713823
Validation loss: 2.9111534764881744

Epoch: 6| Step: 2
Training loss: 3.1825268414512418
Validation loss: 2.9121606049408015

Epoch: 6| Step: 3
Training loss: 3.088351230421943
Validation loss: 2.9124161548843377

Epoch: 6| Step: 4
Training loss: 4.145100258786934
Validation loss: 2.911159257799327

Epoch: 6| Step: 5
Training loss: 3.6130784096359223
Validation loss: 2.9155756642908885

Epoch: 6| Step: 6
Training loss: 3.324117333986552
Validation loss: 2.9131493509420485

Epoch: 6| Step: 7
Training loss: 2.9453707823311746
Validation loss: 2.915721333738995

Epoch: 6| Step: 8
Training loss: 2.9194364928929617
Validation loss: 2.9152085836215083

Epoch: 6| Step: 9
Training loss: 2.6894406253964704
Validation loss: 2.912529876836006

Epoch: 6| Step: 10
Training loss: 3.1005591780341333
Validation loss: 2.9115593124971104

Epoch: 6| Step: 11
Training loss: 3.0857293553716034
Validation loss: 2.91250274948898

Epoch: 6| Step: 12
Training loss: 3.5625038816196644
Validation loss: 2.9120645425602922

Epoch: 6| Step: 13
Training loss: 3.624833333360461
Validation loss: 2.908588252548891

Epoch: 220| Step: 0
Training loss: 3.4033591225817976
Validation loss: 2.9125772441218927

Epoch: 6| Step: 1
Training loss: 3.7962942424930577
Validation loss: 2.9110011997516407

Epoch: 6| Step: 2
Training loss: 3.4587425694525407
Validation loss: 2.9102329488225656

Epoch: 6| Step: 3
Training loss: 3.424041341006185
Validation loss: 2.910659007291452

Epoch: 6| Step: 4
Training loss: 3.148632715576731
Validation loss: 2.906696708222338

Epoch: 6| Step: 5
Training loss: 2.635008306616877
Validation loss: 2.9105662265566705

Epoch: 6| Step: 6
Training loss: 3.1818681217584577
Validation loss: 2.9104125361582414

Epoch: 6| Step: 7
Training loss: 3.70841634135978
Validation loss: 2.9085309078546713

Epoch: 6| Step: 8
Training loss: 3.3855206439361107
Validation loss: 2.908479785860559

Epoch: 6| Step: 9
Training loss: 2.5178214962493066
Validation loss: 2.9082803328285203

Epoch: 6| Step: 10
Training loss: 2.8498608672328984
Validation loss: 2.9066936724547427

Epoch: 6| Step: 11
Training loss: 2.847931187966381
Validation loss: 2.9090248821848954

Epoch: 6| Step: 12
Training loss: 2.843491930308059
Validation loss: 2.9098937654078316

Epoch: 6| Step: 13
Training loss: 3.361965156760402
Validation loss: 2.9071643972925036

Epoch: 221| Step: 0
Training loss: 2.5724693455181096
Validation loss: 2.907340399266747

Epoch: 6| Step: 1
Training loss: 2.3412353249582316
Validation loss: 2.9089803313677445

Epoch: 6| Step: 2
Training loss: 3.83910877415704
Validation loss: 2.908833736935815

Epoch: 6| Step: 3
Training loss: 3.1816338807766917
Validation loss: 2.9076296446687753

Epoch: 6| Step: 4
Training loss: 2.9496033676666245
Validation loss: 2.907154818780025

Epoch: 6| Step: 5
Training loss: 3.446917447670055
Validation loss: 2.9087370675977313

Epoch: 6| Step: 6
Training loss: 2.9936140758263
Validation loss: 2.9070578943102294

Epoch: 6| Step: 7
Training loss: 2.955491828072069
Validation loss: 2.906447113794081

Epoch: 6| Step: 8
Training loss: 3.40660723291598
Validation loss: 2.9113544929373956

Epoch: 6| Step: 9
Training loss: 3.6860976057868036
Validation loss: 2.9061257393910265

Epoch: 6| Step: 10
Training loss: 2.621337606396819
Validation loss: 2.906703951011243

Epoch: 6| Step: 11
Training loss: 3.220928899047181
Validation loss: 2.9059663374587847

Epoch: 6| Step: 12
Training loss: 3.661565063715284
Validation loss: 2.90184387213659

Epoch: 6| Step: 13
Training loss: 3.6080718887678223
Validation loss: 2.9073811196775736

Epoch: 222| Step: 0
Training loss: 3.2183785826078277
Validation loss: 2.907040017032015

Epoch: 6| Step: 1
Training loss: 2.4309740003029496
Validation loss: 2.905329687026064

Epoch: 6| Step: 2
Training loss: 3.7115573084365265
Validation loss: 2.9063631993447596

Epoch: 6| Step: 3
Training loss: 2.9705198132339445
Validation loss: 2.9050022745507427

Epoch: 6| Step: 4
Training loss: 2.793582107312296
Validation loss: 2.9050682259429803

Epoch: 6| Step: 5
Training loss: 3.2009140199401354
Validation loss: 2.9084716554776735

Epoch: 6| Step: 6
Training loss: 2.8064465970032377
Validation loss: 2.902074701090111

Epoch: 6| Step: 7
Training loss: 2.71641054018706
Validation loss: 2.904108105691675

Epoch: 6| Step: 8
Training loss: 3.0611087986759866
Validation loss: 2.903132036904092

Epoch: 6| Step: 9
Training loss: 3.3206015786383007
Validation loss: 2.9027554411284764

Epoch: 6| Step: 10
Training loss: 3.447599936206258
Validation loss: 2.9027620878948763

Epoch: 6| Step: 11
Training loss: 3.3956245092921375
Validation loss: 2.904830181790767

Epoch: 6| Step: 12
Training loss: 4.053888907462543
Validation loss: 2.90107180704434

Epoch: 6| Step: 13
Training loss: 3.2420889598165346
Validation loss: 2.9022258288026013

Epoch: 223| Step: 0
Training loss: 3.4929254422097857
Validation loss: 2.9036632506233837

Epoch: 6| Step: 1
Training loss: 2.8223073566875727
Validation loss: 2.9072369626263486

Epoch: 6| Step: 2
Training loss: 3.3930088927098763
Validation loss: 2.9038295769197546

Epoch: 6| Step: 3
Training loss: 2.5535471759753414
Validation loss: 2.8998635405986875

Epoch: 6| Step: 4
Training loss: 3.505794632932851
Validation loss: 2.901470411051759

Epoch: 6| Step: 5
Training loss: 3.5955307239020273
Validation loss: 2.9009334315509028

Epoch: 6| Step: 6
Training loss: 2.438157897586461
Validation loss: 2.901842194460192

Epoch: 6| Step: 7
Training loss: 3.7192847885142823
Validation loss: 2.9044487317913923

Epoch: 6| Step: 8
Training loss: 2.603420750920458
Validation loss: 2.902358107124936

Epoch: 6| Step: 9
Training loss: 3.1205851077145366
Validation loss: 2.9037124497390545

Epoch: 6| Step: 10
Training loss: 3.4056635360511724
Validation loss: 2.900216837206694

Epoch: 6| Step: 11
Training loss: 3.3488849890920434
Validation loss: 2.9004529680927043

Epoch: 6| Step: 12
Training loss: 3.1510029603877032
Validation loss: 2.902918236601587

Epoch: 6| Step: 13
Training loss: 3.196548484020438
Validation loss: 2.905556273011458

Epoch: 224| Step: 0
Training loss: 3.051002406506635
Validation loss: 2.9028723552285576

Epoch: 6| Step: 1
Training loss: 3.2853458091304923
Validation loss: 2.906349121337012

Epoch: 6| Step: 2
Training loss: 4.110595985879768
Validation loss: 2.9059704679116294

Epoch: 6| Step: 3
Training loss: 2.4417616928756423
Validation loss: 2.9047197028238503

Epoch: 6| Step: 4
Training loss: 3.5547121822632093
Validation loss: 2.9008716608479417

Epoch: 6| Step: 5
Training loss: 3.433793028515712
Validation loss: 2.898004006174086

Epoch: 6| Step: 6
Training loss: 3.165672363649948
Validation loss: 2.8998189997668065

Epoch: 6| Step: 7
Training loss: 2.632526778386522
Validation loss: 2.898446094582123

Epoch: 6| Step: 8
Training loss: 3.0863537471447837
Validation loss: 2.899760028215897

Epoch: 6| Step: 9
Training loss: 3.6662965645549703
Validation loss: 2.9012365482109295

Epoch: 6| Step: 10
Training loss: 2.4782735888273315
Validation loss: 2.9035614435503097

Epoch: 6| Step: 11
Training loss: 2.838199774541087
Validation loss: 2.9008808429790944

Epoch: 6| Step: 12
Training loss: 3.1194937451766576
Validation loss: 2.9006656332251604

Epoch: 6| Step: 13
Training loss: 3.5430165280250794
Validation loss: 2.9002195367823798

Epoch: 225| Step: 0
Training loss: 2.529708769851999
Validation loss: 2.8995033451318757

Epoch: 6| Step: 1
Training loss: 2.9764412282033605
Validation loss: 2.901520255232971

Epoch: 6| Step: 2
Training loss: 3.7497344876707395
Validation loss: 2.9015183564816116

Epoch: 6| Step: 3
Training loss: 3.0458391042533783
Validation loss: 2.9032541412648

Epoch: 6| Step: 4
Training loss: 2.712207507699095
Validation loss: 2.9012268352542065

Epoch: 6| Step: 5
Training loss: 3.3149947362889636
Validation loss: 2.902141668625626

Epoch: 6| Step: 6
Training loss: 2.9967656184214557
Validation loss: 2.90255543399148

Epoch: 6| Step: 7
Training loss: 3.303955862881959
Validation loss: 2.89879105000433

Epoch: 6| Step: 8
Training loss: 3.226199815515739
Validation loss: 2.900494311095822

Epoch: 6| Step: 9
Training loss: 3.195288324614383
Validation loss: 2.897207325615245

Epoch: 6| Step: 10
Training loss: 3.888171667233765
Validation loss: 2.8995040029508843

Epoch: 6| Step: 11
Training loss: 2.961936600948702
Validation loss: 2.896581587783231

Epoch: 6| Step: 12
Training loss: 3.0392724285824726
Validation loss: 2.9022916798730654

Epoch: 6| Step: 13
Training loss: 3.615339890748139
Validation loss: 2.897271550699294

Epoch: 226| Step: 0
Training loss: 3.32235575917561
Validation loss: 2.8991346185111793

Epoch: 6| Step: 1
Training loss: 2.6257313209151865
Validation loss: 2.9004804945109353

Epoch: 6| Step: 2
Training loss: 3.4256243784012534
Validation loss: 2.8966025724154423

Epoch: 6| Step: 3
Training loss: 2.914284705314141
Validation loss: 2.8976694003702916

Epoch: 6| Step: 4
Training loss: 3.29377868755667
Validation loss: 2.8976148247083917

Epoch: 6| Step: 5
Training loss: 1.8624967767060314
Validation loss: 2.8960057565298403

Epoch: 6| Step: 6
Training loss: 3.15174635056322
Validation loss: 2.901755626278623

Epoch: 6| Step: 7
Training loss: 3.3195403513937363
Validation loss: 2.899003642501863

Epoch: 6| Step: 8
Training loss: 2.8575189955940212
Validation loss: 2.8967521244512677

Epoch: 6| Step: 9
Training loss: 2.065527803151248
Validation loss: 2.8993007704493277

Epoch: 6| Step: 10
Training loss: 3.910123079904263
Validation loss: 2.898224317549972

Epoch: 6| Step: 11
Training loss: 4.308707297135383
Validation loss: 2.896575091455475

Epoch: 6| Step: 12
Training loss: 3.2220397729484835
Validation loss: 2.8953918937390797

Epoch: 6| Step: 13
Training loss: 3.6510993347112195
Validation loss: 2.893612635532274

Epoch: 227| Step: 0
Training loss: 2.9872989411312827
Validation loss: 2.894959801752156

Epoch: 6| Step: 1
Training loss: 3.178866493649622
Validation loss: 2.892341518732547

Epoch: 6| Step: 2
Training loss: 3.6744858570249748
Validation loss: 2.8939323291131136

Epoch: 6| Step: 3
Training loss: 3.296734558296098
Validation loss: 2.894329688711188

Epoch: 6| Step: 4
Training loss: 3.5300176039734974
Validation loss: 2.8940822033849916

Epoch: 6| Step: 5
Training loss: 3.0827651316526845
Validation loss: 2.8921934121531296

Epoch: 6| Step: 6
Training loss: 3.1895489558570946
Validation loss: 2.8930001958751963

Epoch: 6| Step: 7
Training loss: 3.091268449690476
Validation loss: 2.8914318338904423

Epoch: 6| Step: 8
Training loss: 3.2889508661095284
Validation loss: 2.8930254670744278

Epoch: 6| Step: 9
Training loss: 2.798484467027613
Validation loss: 2.8903895456546302

Epoch: 6| Step: 10
Training loss: 3.6019739673103746
Validation loss: 2.8894104166042887

Epoch: 6| Step: 11
Training loss: 2.9443718903277567
Validation loss: 2.8893731534750837

Epoch: 6| Step: 12
Training loss: 2.6831866403923854
Validation loss: 2.892912826078859

Epoch: 6| Step: 13
Training loss: 2.95306267243668
Validation loss: 2.891221525616876

Epoch: 228| Step: 0
Training loss: 2.8387019027606293
Validation loss: 2.8927698161802895

Epoch: 6| Step: 1
Training loss: 3.5190288426441363
Validation loss: 2.8905063798817063

Epoch: 6| Step: 2
Training loss: 3.995685038169972
Validation loss: 2.8927681217204317

Epoch: 6| Step: 3
Training loss: 3.4071151614598687
Validation loss: 2.891093536780109

Epoch: 6| Step: 4
Training loss: 2.400148061317793
Validation loss: 2.8942288527564353

Epoch: 6| Step: 5
Training loss: 2.7788781328470624
Validation loss: 2.8956643904630717

Epoch: 6| Step: 6
Training loss: 3.0961654943546892
Validation loss: 2.898034434387371

Epoch: 6| Step: 7
Training loss: 3.1128542043609144
Validation loss: 2.895474411139319

Epoch: 6| Step: 8
Training loss: 3.584071386460804
Validation loss: 2.8964077520058376

Epoch: 6| Step: 9
Training loss: 3.346626826754622
Validation loss: 2.8966168128489844

Epoch: 6| Step: 10
Training loss: 2.994367875783619
Validation loss: 2.889914803035268

Epoch: 6| Step: 11
Training loss: 3.610172860611538
Validation loss: 2.887689068730443

Epoch: 6| Step: 12
Training loss: 2.7121512474488005
Validation loss: 2.888061885911276

Epoch: 6| Step: 13
Training loss: 2.4568559981343734
Validation loss: 2.8878322689814784

Epoch: 229| Step: 0
Training loss: 2.7492908083509566
Validation loss: 2.88907884322189

Epoch: 6| Step: 1
Training loss: 3.7788557559100626
Validation loss: 2.889332960075902

Epoch: 6| Step: 2
Training loss: 2.6342519566229194
Validation loss: 2.891152414654204

Epoch: 6| Step: 3
Training loss: 3.3575967029725313
Validation loss: 2.891909230717385

Epoch: 6| Step: 4
Training loss: 3.3652131206706923
Validation loss: 2.8891774941970803

Epoch: 6| Step: 5
Training loss: 3.1509972098921395
Validation loss: 2.892676229463216

Epoch: 6| Step: 6
Training loss: 2.608008478022176
Validation loss: 2.889636078157733

Epoch: 6| Step: 7
Training loss: 2.9150192694575097
Validation loss: 2.8915730729476783

Epoch: 6| Step: 8
Training loss: 3.268706843308258
Validation loss: 2.888468941852115

Epoch: 6| Step: 9
Training loss: 3.239460213990495
Validation loss: 2.889176307842749

Epoch: 6| Step: 10
Training loss: 3.4504755825698354
Validation loss: 2.889475472876225

Epoch: 6| Step: 11
Training loss: 2.908817920555752
Validation loss: 2.889624701767181

Epoch: 6| Step: 12
Training loss: 2.923618061926264
Validation loss: 2.887709078397244

Epoch: 6| Step: 13
Training loss: 4.383180653822401
Validation loss: 2.8852204950292606

Epoch: 230| Step: 0
Training loss: 3.188546700750392
Validation loss: 2.8883225041816116

Epoch: 6| Step: 1
Training loss: 3.4489556597798474
Validation loss: 2.8928977042688464

Epoch: 6| Step: 2
Training loss: 3.294316605361771
Validation loss: 2.8919432680811874

Epoch: 6| Step: 3
Training loss: 3.1558378347064737
Validation loss: 2.90682920465856

Epoch: 6| Step: 4
Training loss: 3.1550765169419885
Validation loss: 2.906944208750525

Epoch: 6| Step: 5
Training loss: 3.0501911603712855
Validation loss: 2.910612534499424

Epoch: 6| Step: 6
Training loss: 3.598213807017752
Validation loss: 2.916834129998965

Epoch: 6| Step: 7
Training loss: 2.8756988339479044
Validation loss: 2.89833409147834

Epoch: 6| Step: 8
Training loss: 3.397441709353824
Validation loss: 2.895277994489717

Epoch: 6| Step: 9
Training loss: 3.1934355280483993
Validation loss: 2.8899553981762236

Epoch: 6| Step: 10
Training loss: 3.057596134099907
Validation loss: 2.88284864563348

Epoch: 6| Step: 11
Training loss: 2.8546141299218553
Validation loss: 2.883256768338593

Epoch: 6| Step: 12
Training loss: 3.10459678452098
Validation loss: 2.8857115932478203

Epoch: 6| Step: 13
Training loss: 3.0410407132073662
Validation loss: 2.8843135274665372

Epoch: 231| Step: 0
Training loss: 3.1128110063815626
Validation loss: 2.8845248282127556

Epoch: 6| Step: 1
Training loss: 3.628734900758179
Validation loss: 2.885117431159825

Epoch: 6| Step: 2
Training loss: 2.741856220807994
Validation loss: 2.886228542619487

Epoch: 6| Step: 3
Training loss: 3.8801496189804108
Validation loss: 2.8865422926423765

Epoch: 6| Step: 4
Training loss: 2.894507198259553
Validation loss: 2.8867067537742996

Epoch: 6| Step: 5
Training loss: 3.7290226714963386
Validation loss: 2.889715053364651

Epoch: 6| Step: 6
Training loss: 3.2718942140672693
Validation loss: 2.886099546240363

Epoch: 6| Step: 7
Training loss: 2.3873292232770287
Validation loss: 2.8883017025923845

Epoch: 6| Step: 8
Training loss: 3.108765662214815
Validation loss: 2.8867550047990167

Epoch: 6| Step: 9
Training loss: 2.875259553554283
Validation loss: 2.8859485298774454

Epoch: 6| Step: 10
Training loss: 3.022762410500043
Validation loss: 2.8834506742249184

Epoch: 6| Step: 11
Training loss: 3.0678937474916625
Validation loss: 2.8827536981268533

Epoch: 6| Step: 12
Training loss: 3.03617537386741
Validation loss: 2.882231667528442

Epoch: 6| Step: 13
Training loss: 3.6570556274722916
Validation loss: 2.8854071095466303

Epoch: 232| Step: 0
Training loss: 3.189320362362379
Validation loss: 2.8859394832306036

Epoch: 6| Step: 1
Training loss: 3.3066074574717237
Validation loss: 2.886809334636731

Epoch: 6| Step: 2
Training loss: 3.343370933080413
Validation loss: 2.8897690330195047

Epoch: 6| Step: 3
Training loss: 2.1407753550497945
Validation loss: 2.8914234445510845

Epoch: 6| Step: 4
Training loss: 3.1977771310258496
Validation loss: 2.899552462758242

Epoch: 6| Step: 5
Training loss: 3.9486556892205935
Validation loss: 2.89304265735412

Epoch: 6| Step: 6
Training loss: 2.8578840861002326
Validation loss: 2.9003508211693454

Epoch: 6| Step: 7
Training loss: 3.133742653374416
Validation loss: 2.9009341305809033

Epoch: 6| Step: 8
Training loss: 2.52851333559128
Validation loss: 2.901192509164272

Epoch: 6| Step: 9
Training loss: 3.6267317220051494
Validation loss: 2.895314007523234

Epoch: 6| Step: 10
Training loss: 2.979145201136656
Validation loss: 2.8829797864677564

Epoch: 6| Step: 11
Training loss: 3.542756634706074
Validation loss: 2.8830745477987345

Epoch: 6| Step: 12
Training loss: 3.239353494780702
Validation loss: 2.883342109233876

Epoch: 6| Step: 13
Training loss: 2.930931539255937
Validation loss: 2.8799864366726426

Epoch: 233| Step: 0
Training loss: 2.9616273262646895
Validation loss: 2.8793913246880685

Epoch: 6| Step: 1
Training loss: 3.3581759419882444
Validation loss: 2.8810562629918994

Epoch: 6| Step: 2
Training loss: 3.091198572331843
Validation loss: 2.8821404515757805

Epoch: 6| Step: 3
Training loss: 2.9459842957947577
Validation loss: 2.8794618237097347

Epoch: 6| Step: 4
Training loss: 2.375289297052033
Validation loss: 2.8835313311363624

Epoch: 6| Step: 5
Training loss: 2.7693191253390697
Validation loss: 2.885267669134725

Epoch: 6| Step: 6
Training loss: 2.5193955495796407
Validation loss: 2.8892597108261016

Epoch: 6| Step: 7
Training loss: 4.114438958190269
Validation loss: 2.88455358112473

Epoch: 6| Step: 8
Training loss: 3.786719661686565
Validation loss: 2.885568329511827

Epoch: 6| Step: 9
Training loss: 3.0977092031255786
Validation loss: 2.882932803461731

Epoch: 6| Step: 10
Training loss: 3.3522121982370505
Validation loss: 2.8843046285693146

Epoch: 6| Step: 11
Training loss: 3.1253985341575965
Validation loss: 2.883546612308448

Epoch: 6| Step: 12
Training loss: 3.4135585386767073
Validation loss: 2.8860180612594917

Epoch: 6| Step: 13
Training loss: 3.1025167769993605
Validation loss: 2.882022605719382

Epoch: 234| Step: 0
Training loss: 2.6795935433601095
Validation loss: 2.877729838198671

Epoch: 6| Step: 1
Training loss: 3.253766444982063
Validation loss: 2.8792715828856115

Epoch: 6| Step: 2
Training loss: 3.1344747723324673
Validation loss: 2.8796610346808165

Epoch: 6| Step: 3
Training loss: 2.9971420662333554
Validation loss: 2.8800714044837203

Epoch: 6| Step: 4
Training loss: 3.3332779085001913
Validation loss: 2.8848950498113357

Epoch: 6| Step: 5
Training loss: 2.9609210736063156
Validation loss: 2.8849500278278

Epoch: 6| Step: 6
Training loss: 2.489773241618147
Validation loss: 2.8877215480808727

Epoch: 6| Step: 7
Training loss: 3.3381878947589714
Validation loss: 2.8861062304773872

Epoch: 6| Step: 8
Training loss: 3.3401249995797135
Validation loss: 2.8838788226469996

Epoch: 6| Step: 9
Training loss: 3.7280083816335865
Validation loss: 2.8813393296374508

Epoch: 6| Step: 10
Training loss: 3.02508421221076
Validation loss: 2.8814631341914567

Epoch: 6| Step: 11
Training loss: 3.324489990357
Validation loss: 2.880306554123607

Epoch: 6| Step: 12
Training loss: 3.4923475258706826
Validation loss: 2.879180860822035

Epoch: 6| Step: 13
Training loss: 3.311725453925451
Validation loss: 2.8814657196614064

Epoch: 235| Step: 0
Training loss: 3.0178955701250127
Validation loss: 2.877971598131289

Epoch: 6| Step: 1
Training loss: 3.666705709307333
Validation loss: 2.8794896416040645

Epoch: 6| Step: 2
Training loss: 3.6854436280748852
Validation loss: 2.879803784867656

Epoch: 6| Step: 3
Training loss: 3.2058174540522506
Validation loss: 2.8836709035162693

Epoch: 6| Step: 4
Training loss: 3.173449196129511
Validation loss: 2.8835653998242083

Epoch: 6| Step: 5
Training loss: 2.9828106839717496
Validation loss: 2.889525393548442

Epoch: 6| Step: 6
Training loss: 2.0773791358576505
Validation loss: 2.8917181216887275

Epoch: 6| Step: 7
Training loss: 3.1748510971596358
Validation loss: 2.8884436059360956

Epoch: 6| Step: 8
Training loss: 3.2503642831731394
Validation loss: 2.886579999964323

Epoch: 6| Step: 9
Training loss: 2.945737934501263
Validation loss: 2.8837671471976956

Epoch: 6| Step: 10
Training loss: 2.7775787812055346
Validation loss: 2.877358573500802

Epoch: 6| Step: 11
Training loss: 3.137631636210009
Validation loss: 2.877647502400063

Epoch: 6| Step: 12
Training loss: 3.1526580616035025
Validation loss: 2.874896760560902

Epoch: 6| Step: 13
Training loss: 4.287993751322051
Validation loss: 2.87657963540875

Epoch: 236| Step: 0
Training loss: 2.9780298656147095
Validation loss: 2.873022256136732

Epoch: 6| Step: 1
Training loss: 2.7254169320139083
Validation loss: 2.8744924524405038

Epoch: 6| Step: 2
Training loss: 3.027860653955282
Validation loss: 2.871150139662357

Epoch: 6| Step: 3
Training loss: 3.435103812391162
Validation loss: 2.8724125119078736

Epoch: 6| Step: 4
Training loss: 3.370708987312378
Validation loss: 2.8733401855223546

Epoch: 6| Step: 5
Training loss: 3.3438796258916996
Validation loss: 2.871635299659954

Epoch: 6| Step: 6
Training loss: 2.9781041595914632
Validation loss: 2.872557879336519

Epoch: 6| Step: 7
Training loss: 3.060113560931741
Validation loss: 2.8740537958065597

Epoch: 6| Step: 8
Training loss: 3.128142493443921
Validation loss: 2.8726401450453

Epoch: 6| Step: 9
Training loss: 3.326705414948351
Validation loss: 2.8719520793187163

Epoch: 6| Step: 10
Training loss: 3.6128251401312053
Validation loss: 2.87152343284897

Epoch: 6| Step: 11
Training loss: 2.9686618189514773
Validation loss: 2.873196930396281

Epoch: 6| Step: 12
Training loss: 3.022270825250793
Validation loss: 2.8761131366314183

Epoch: 6| Step: 13
Training loss: 3.45254649844337
Validation loss: 2.871911246657166

Epoch: 237| Step: 0
Training loss: 3.292864489007823
Validation loss: 2.872154141701259

Epoch: 6| Step: 1
Training loss: 3.333128700332977
Validation loss: 2.8726550254448924

Epoch: 6| Step: 2
Training loss: 3.217316243364095
Validation loss: 2.8719227922999386

Epoch: 6| Step: 3
Training loss: 2.5834000691643557
Validation loss: 2.868718211698752

Epoch: 6| Step: 4
Training loss: 3.6143295829303406
Validation loss: 2.873043439614927

Epoch: 6| Step: 5
Training loss: 2.869789709700917
Validation loss: 2.8702931809063106

Epoch: 6| Step: 6
Training loss: 2.899196802918143
Validation loss: 2.872436246177753

Epoch: 6| Step: 7
Training loss: 2.0106482759455937
Validation loss: 2.870128557250739

Epoch: 6| Step: 8
Training loss: 3.646150382652235
Validation loss: 2.8743666209326917

Epoch: 6| Step: 9
Training loss: 3.937239138726839
Validation loss: 2.8706476028562147

Epoch: 6| Step: 10
Training loss: 2.4337481454333747
Validation loss: 2.8695684668934778

Epoch: 6| Step: 11
Training loss: 3.137106979496502
Validation loss: 2.872351385420177

Epoch: 6| Step: 12
Training loss: 3.167577378337253
Validation loss: 2.873418084754234

Epoch: 6| Step: 13
Training loss: 3.9634176160504144
Validation loss: 2.8719992508846275

Epoch: 238| Step: 0
Training loss: 2.932187572594302
Validation loss: 2.871925793409626

Epoch: 6| Step: 1
Training loss: 3.29747632947268
Validation loss: 2.8734004674769427

Epoch: 6| Step: 2
Training loss: 2.027807987400348
Validation loss: 2.874066207439442

Epoch: 6| Step: 3
Training loss: 3.0735690873664208
Validation loss: 2.882782297959685

Epoch: 6| Step: 4
Training loss: 3.791948804034922
Validation loss: 2.8929401681382747

Epoch: 6| Step: 5
Training loss: 3.6441601792272023
Validation loss: 2.886611608120231

Epoch: 6| Step: 6
Training loss: 3.2564682783013574
Validation loss: 2.895941237354981

Epoch: 6| Step: 7
Training loss: 3.943334223235786
Validation loss: 2.8944349231534106

Epoch: 6| Step: 8
Training loss: 3.389978021871164
Validation loss: 2.874246758101429

Epoch: 6| Step: 9
Training loss: 2.692056740603531
Validation loss: 2.870699567804052

Epoch: 6| Step: 10
Training loss: 3.446864464087479
Validation loss: 2.8681065084434127

Epoch: 6| Step: 11
Training loss: 2.7690310436752785
Validation loss: 2.8687224368903204

Epoch: 6| Step: 12
Training loss: 2.895405213981182
Validation loss: 2.867972285643606

Epoch: 6| Step: 13
Training loss: 2.308445753075293
Validation loss: 2.8698857337446273

Epoch: 239| Step: 0
Training loss: 3.587954683100582
Validation loss: 2.8760539972283774

Epoch: 6| Step: 1
Training loss: 3.0681856277390795
Validation loss: 2.877978828586556

Epoch: 6| Step: 2
Training loss: 3.543256485094614
Validation loss: 2.8783749517441968

Epoch: 6| Step: 3
Training loss: 2.299487645676138
Validation loss: 2.8832189864341795

Epoch: 6| Step: 4
Training loss: 3.584013645146144
Validation loss: 2.880316754173189

Epoch: 6| Step: 5
Training loss: 2.9416088829813134
Validation loss: 2.878408441979484

Epoch: 6| Step: 6
Training loss: 3.0915093833488494
Validation loss: 2.875070020867159

Epoch: 6| Step: 7
Training loss: 2.855272863012118
Validation loss: 2.8739983292594484

Epoch: 6| Step: 8
Training loss: 2.8512305497606087
Validation loss: 2.8731378960389558

Epoch: 6| Step: 9
Training loss: 3.6748559417515883
Validation loss: 2.8734316888656863

Epoch: 6| Step: 10
Training loss: 3.3784861044333336
Validation loss: 2.8717760893788014

Epoch: 6| Step: 11
Training loss: 3.2427313291079667
Validation loss: 2.8732171337837364

Epoch: 6| Step: 12
Training loss: 2.756272791208164
Validation loss: 2.8722855592849594

Epoch: 6| Step: 13
Training loss: 3.3747750666508547
Validation loss: 2.8708327964407037

Epoch: 240| Step: 0
Training loss: 3.458747394700029
Validation loss: 2.8709723280544783

Epoch: 6| Step: 1
Training loss: 3.225364333280422
Validation loss: 2.8706264642123758

Epoch: 6| Step: 2
Training loss: 3.055736156867635
Validation loss: 2.86818500656273

Epoch: 6| Step: 3
Training loss: 3.5524329109487756
Validation loss: 2.8680593524062106

Epoch: 6| Step: 4
Training loss: 3.6636836460004556
Validation loss: 2.868977384585761

Epoch: 6| Step: 5
Training loss: 3.240226869764138
Validation loss: 2.8686390400379285

Epoch: 6| Step: 6
Training loss: 2.757204329132219
Validation loss: 2.8666439940015525

Epoch: 6| Step: 7
Training loss: 3.0770856777656594
Validation loss: 2.8674767832130823

Epoch: 6| Step: 8
Training loss: 2.6259081041769208
Validation loss: 2.8665003353646212

Epoch: 6| Step: 9
Training loss: 2.607889997771861
Validation loss: 2.8659482995447205

Epoch: 6| Step: 10
Training loss: 2.9628598859747752
Validation loss: 2.8631534564405725

Epoch: 6| Step: 11
Training loss: 3.3350515864327317
Validation loss: 2.8601751859245543

Epoch: 6| Step: 12
Training loss: 3.5134555480759486
Validation loss: 2.864427751509326

Epoch: 6| Step: 13
Training loss: 2.9162136452669767
Validation loss: 2.8669246170716978

Epoch: 241| Step: 0
Training loss: 2.437360906300303
Validation loss: 2.86306698995275

Epoch: 6| Step: 1
Training loss: 3.735232458272709
Validation loss: 2.861864211141111

Epoch: 6| Step: 2
Training loss: 3.6902009802775386
Validation loss: 2.8648190332958348

Epoch: 6| Step: 3
Training loss: 2.691867561834903
Validation loss: 2.8687428085176596

Epoch: 6| Step: 4
Training loss: 2.931265688205536
Validation loss: 2.876289973101199

Epoch: 6| Step: 5
Training loss: 3.3539022179523137
Validation loss: 2.877869944042094

Epoch: 6| Step: 6
Training loss: 3.278217040188988
Validation loss: 2.8884072480734306

Epoch: 6| Step: 7
Training loss: 2.822974895331886
Validation loss: 2.8854422311408148

Epoch: 6| Step: 8
Training loss: 3.277859780171256
Validation loss: 2.8807134146306823

Epoch: 6| Step: 9
Training loss: 3.406161105894594
Validation loss: 2.868232248126979

Epoch: 6| Step: 10
Training loss: 2.760742964742772
Validation loss: 2.8743680925633233

Epoch: 6| Step: 11
Training loss: 2.786136748869021
Validation loss: 2.8633051539710075

Epoch: 6| Step: 12
Training loss: 3.2343175026026127
Validation loss: 2.8597538060180985

Epoch: 6| Step: 13
Training loss: 3.7830390165910006
Validation loss: 2.8580454575165617

Epoch: 242| Step: 0
Training loss: 3.4547848401790744
Validation loss: 2.862089627018626

Epoch: 6| Step: 1
Training loss: 2.4971926185155415
Validation loss: 2.8584494300593084

Epoch: 6| Step: 2
Training loss: 3.350170780212823
Validation loss: 2.8604844508133245

Epoch: 6| Step: 3
Training loss: 3.1603397273683744
Validation loss: 2.862243724914432

Epoch: 6| Step: 4
Training loss: 3.1083404506843904
Validation loss: 2.8584091462281633

Epoch: 6| Step: 5
Training loss: 3.438504991140289
Validation loss: 2.858795385207561

Epoch: 6| Step: 6
Training loss: 2.485206512835098
Validation loss: 2.8596645212908336

Epoch: 6| Step: 7
Training loss: 2.8584581583272675
Validation loss: 2.856172923747211

Epoch: 6| Step: 8
Training loss: 3.513617048106152
Validation loss: 2.857328095928248

Epoch: 6| Step: 9
Training loss: 3.304437578278675
Validation loss: 2.8578724532423485

Epoch: 6| Step: 10
Training loss: 3.066207509980806
Validation loss: 2.8579921022085575

Epoch: 6| Step: 11
Training loss: 3.728459481185794
Validation loss: 2.856394857671469

Epoch: 6| Step: 12
Training loss: 2.922970000523851
Validation loss: 2.8579074647002565

Epoch: 6| Step: 13
Training loss: 3.0798102862897467
Validation loss: 2.860736157367838

Epoch: 243| Step: 0
Training loss: 2.3135682808829348
Validation loss: 2.8569104723467307

Epoch: 6| Step: 1
Training loss: 3.4101389112173757
Validation loss: 2.8590063095772926

Epoch: 6| Step: 2
Training loss: 3.351529350205743
Validation loss: 2.858377055798787

Epoch: 6| Step: 3
Training loss: 2.695764918296931
Validation loss: 2.860327922446199

Epoch: 6| Step: 4
Training loss: 3.3911048092609257
Validation loss: 2.8562093786827876

Epoch: 6| Step: 5
Training loss: 2.9865122227529612
Validation loss: 2.8568405896808735

Epoch: 6| Step: 6
Training loss: 3.40483357788824
Validation loss: 2.8594131283386828

Epoch: 6| Step: 7
Training loss: 3.2431780301660225
Validation loss: 2.860364091398345

Epoch: 6| Step: 8
Training loss: 3.3931450685788396
Validation loss: 2.858353571618484

Epoch: 6| Step: 9
Training loss: 3.2855318741483734
Validation loss: 2.857885058493056

Epoch: 6| Step: 10
Training loss: 3.1235473308173907
Validation loss: 2.866432047722625

Epoch: 6| Step: 11
Training loss: 3.1685591781312565
Validation loss: 2.8631256875578375

Epoch: 6| Step: 12
Training loss: 3.0334808949500336
Validation loss: 2.86270193356834

Epoch: 6| Step: 13
Training loss: 3.2465933037784636
Validation loss: 2.8602736470975536

Epoch: 244| Step: 0
Training loss: 2.548358508580933
Validation loss: 2.863376125151693

Epoch: 6| Step: 1
Training loss: 3.185599265261249
Validation loss: 2.8649631824893427

Epoch: 6| Step: 2
Training loss: 2.8147987296479537
Validation loss: 2.8668144014394246

Epoch: 6| Step: 3
Training loss: 3.925601480647683
Validation loss: 2.859974013506728

Epoch: 6| Step: 4
Training loss: 3.296917811111259
Validation loss: 2.866534228161913

Epoch: 6| Step: 5
Training loss: 2.97005538349339
Validation loss: 2.864895602719812

Epoch: 6| Step: 6
Training loss: 3.3220318101419823
Validation loss: 2.866990829186709

Epoch: 6| Step: 7
Training loss: 2.913786274190363
Validation loss: 2.856073580676356

Epoch: 6| Step: 8
Training loss: 3.2914705499742296
Validation loss: 2.8567782146644802

Epoch: 6| Step: 9
Training loss: 3.2338114814236922
Validation loss: 2.854123230105039

Epoch: 6| Step: 10
Training loss: 3.2875816654171666
Validation loss: 2.8574663589600657

Epoch: 6| Step: 11
Training loss: 3.014194445690773
Validation loss: 2.8516733725347225

Epoch: 6| Step: 12
Training loss: 3.391987750877
Validation loss: 2.855202202204242

Epoch: 6| Step: 13
Training loss: 2.3818899901615804
Validation loss: 2.851124282633763

Epoch: 245| Step: 0
Training loss: 2.7068884785751917
Validation loss: 2.855889260358069

Epoch: 6| Step: 1
Training loss: 3.3629593999784357
Validation loss: 2.853832972377347

Epoch: 6| Step: 2
Training loss: 3.284906003585579
Validation loss: 2.8505441179700504

Epoch: 6| Step: 3
Training loss: 3.4956594527736287
Validation loss: 2.8525372452828113

Epoch: 6| Step: 4
Training loss: 3.3080862617638913
Validation loss: 2.854701944458306

Epoch: 6| Step: 5
Training loss: 3.3571292911707644
Validation loss: 2.852878254303317

Epoch: 6| Step: 6
Training loss: 3.475813538531472
Validation loss: 2.8535870283171665

Epoch: 6| Step: 7
Training loss: 3.0110932924025713
Validation loss: 2.854048942459639

Epoch: 6| Step: 8
Training loss: 2.68433015761485
Validation loss: 2.8540274634987717

Epoch: 6| Step: 9
Training loss: 2.948329685425285
Validation loss: 2.8572801788059543

Epoch: 6| Step: 10
Training loss: 3.5650989355026144
Validation loss: 2.853281282746674

Epoch: 6| Step: 11
Training loss: 2.622215610790359
Validation loss: 2.8511061418551655

Epoch: 6| Step: 12
Training loss: 2.998178246816326
Validation loss: 2.8556444512910826

Epoch: 6| Step: 13
Training loss: 3.146480434801226
Validation loss: 2.851516012570557

Epoch: 246| Step: 0
Training loss: 2.4688369156228975
Validation loss: 2.854297640024225

Epoch: 6| Step: 1
Training loss: 3.13216966231366
Validation loss: 2.8549266785642033

Epoch: 6| Step: 2
Training loss: 2.848923222094731
Validation loss: 2.852240780725695

Epoch: 6| Step: 3
Training loss: 3.061867940645009
Validation loss: 2.853463370920653

Epoch: 6| Step: 4
Training loss: 3.293984832209933
Validation loss: 2.8532820608376745

Epoch: 6| Step: 5
Training loss: 3.5749340238018563
Validation loss: 2.8534874667447805

Epoch: 6| Step: 6
Training loss: 2.89384816870387
Validation loss: 2.8520539924835004

Epoch: 6| Step: 7
Training loss: 3.085354752384089
Validation loss: 2.8504707299570606

Epoch: 6| Step: 8
Training loss: 3.536026416559061
Validation loss: 2.852358318315056

Epoch: 6| Step: 9
Training loss: 3.5510130283092005
Validation loss: 2.851500895991267

Epoch: 6| Step: 10
Training loss: 3.303343298852428
Validation loss: 2.851063250031528

Epoch: 6| Step: 11
Training loss: 3.235178234962503
Validation loss: 2.84977403611024

Epoch: 6| Step: 12
Training loss: 2.8754295359962296
Validation loss: 2.850541499957135

Epoch: 6| Step: 13
Training loss: 3.04572372204503
Validation loss: 2.854455761826542

Epoch: 247| Step: 0
Training loss: 2.636970926164297
Validation loss: 2.8466572397484273

Epoch: 6| Step: 1
Training loss: 3.1785450225516994
Validation loss: 2.8498602987065325

Epoch: 6| Step: 2
Training loss: 3.3285334520027097
Validation loss: 2.84710015522905

Epoch: 6| Step: 3
Training loss: 2.555582338920704
Validation loss: 2.8502368038481865

Epoch: 6| Step: 4
Training loss: 3.2806443881688145
Validation loss: 2.847153860519204

Epoch: 6| Step: 5
Training loss: 2.553928460800291
Validation loss: 2.851127231904332

Epoch: 6| Step: 6
Training loss: 3.6468531172356538
Validation loss: 2.8498436386746815

Epoch: 6| Step: 7
Training loss: 3.030964316837367
Validation loss: 2.848843531811305

Epoch: 6| Step: 8
Training loss: 3.177608025588151
Validation loss: 2.8485808576383933

Epoch: 6| Step: 9
Training loss: 3.672886615759343
Validation loss: 2.8449132695326935

Epoch: 6| Step: 10
Training loss: 2.9649314013002903
Validation loss: 2.846419321065843

Epoch: 6| Step: 11
Training loss: 3.4330344585463886
Validation loss: 2.849263389599396

Epoch: 6| Step: 12
Training loss: 3.416238959609001
Validation loss: 2.8479546797747557

Epoch: 6| Step: 13
Training loss: 2.760531805744122
Validation loss: 2.8470501245856736

Epoch: 248| Step: 0
Training loss: 3.241263752064805
Validation loss: 2.8458576507699296

Epoch: 6| Step: 1
Training loss: 2.643809007207093
Validation loss: 2.846672230752282

Epoch: 6| Step: 2
Training loss: 4.032476194326819
Validation loss: 2.8453351362536585

Epoch: 6| Step: 3
Training loss: 2.6769248133728776
Validation loss: 2.847506638501109

Epoch: 6| Step: 4
Training loss: 2.3109154298462258
Validation loss: 2.8535368005579844

Epoch: 6| Step: 5
Training loss: 2.3650728858862253
Validation loss: 2.8553232685326493

Epoch: 6| Step: 6
Training loss: 2.652712721856343
Validation loss: 2.8513800836469008

Epoch: 6| Step: 7
Training loss: 3.2407848587262493
Validation loss: 2.8535827888007175

Epoch: 6| Step: 8
Training loss: 3.449098474775153
Validation loss: 2.8597995338227173

Epoch: 6| Step: 9
Training loss: 3.140387379021866
Validation loss: 2.8648783142411403

Epoch: 6| Step: 10
Training loss: 3.4040989514592086
Validation loss: 2.86513719113525

Epoch: 6| Step: 11
Training loss: 3.3292062641664657
Validation loss: 2.871882717098053

Epoch: 6| Step: 12
Training loss: 3.8490749783664793
Validation loss: 2.8606394130594954

Epoch: 6| Step: 13
Training loss: 3.2477476678369626
Validation loss: 2.8427243605929857

Epoch: 249| Step: 0
Training loss: 3.3480254318018834
Validation loss: 2.8471974181115174

Epoch: 6| Step: 1
Training loss: 3.271834606952415
Validation loss: 2.8440207165804003

Epoch: 6| Step: 2
Training loss: 3.739931449873896
Validation loss: 2.8461493901911656

Epoch: 6| Step: 3
Training loss: 3.3576645866040957
Validation loss: 2.8483313999075737

Epoch: 6| Step: 4
Training loss: 3.5768964898988456
Validation loss: 2.843280496100466

Epoch: 6| Step: 5
Training loss: 3.365484315841597
Validation loss: 2.846735817811719

Epoch: 6| Step: 6
Training loss: 2.910465259915467
Validation loss: 2.84657610720265

Epoch: 6| Step: 7
Training loss: 3.0568799202457657
Validation loss: 2.8478081554905432

Epoch: 6| Step: 8
Training loss: 2.173195636381321
Validation loss: 2.8447394134479156

Epoch: 6| Step: 9
Training loss: 2.9971875677107764
Validation loss: 2.8530410104955855

Epoch: 6| Step: 10
Training loss: 2.7253311131045908
Validation loss: 2.8450239984024353

Epoch: 6| Step: 11
Training loss: 3.140957487356034
Validation loss: 2.8448328829717604

Epoch: 6| Step: 12
Training loss: 3.2012557367275662
Validation loss: 2.844278335398404

Epoch: 6| Step: 13
Training loss: 2.7512491163627595
Validation loss: 2.8453216365719256

Epoch: 250| Step: 0
Training loss: 2.836394470220643
Validation loss: 2.845306515014291

Epoch: 6| Step: 1
Training loss: 3.1126875365110407
Validation loss: 2.84412325780746

Epoch: 6| Step: 2
Training loss: 3.030802900238281
Validation loss: 2.8485618870830196

Epoch: 6| Step: 3
Training loss: 3.0030384571256468
Validation loss: 2.8490317741014177

Epoch: 6| Step: 4
Training loss: 2.617257552846282
Validation loss: 2.8484560685030713

Epoch: 6| Step: 5
Training loss: 3.8019538474133703
Validation loss: 2.8421635079341003

Epoch: 6| Step: 6
Training loss: 3.053038325099501
Validation loss: 2.8426442259763887

Epoch: 6| Step: 7
Training loss: 3.598269465204916
Validation loss: 2.8434919212922405

Epoch: 6| Step: 8
Training loss: 3.1574955361667714
Validation loss: 2.844401264586624

Epoch: 6| Step: 9
Training loss: 3.529564109020067
Validation loss: 2.8439266939203627

Epoch: 6| Step: 10
Training loss: 2.352705060107092
Validation loss: 2.8527553426211685

Epoch: 6| Step: 11
Training loss: 3.3432879262359148
Validation loss: 2.844303107514241

Epoch: 6| Step: 12
Training loss: 3.335132939607283
Validation loss: 2.841105743895652

Epoch: 6| Step: 13
Training loss: 2.802574020211318
Validation loss: 2.8424536269725658

Epoch: 251| Step: 0
Training loss: 3.515823562100951
Validation loss: 2.8464886373012965

Epoch: 6| Step: 1
Training loss: 2.651531561433289
Validation loss: 2.843652487580246

Epoch: 6| Step: 2
Training loss: 2.8533064016812144
Validation loss: 2.8423725981194137

Epoch: 6| Step: 3
Training loss: 3.3507180028075143
Validation loss: 2.850807238037662

Epoch: 6| Step: 4
Training loss: 3.216218415752753
Validation loss: 2.8444407851348283

Epoch: 6| Step: 5
Training loss: 2.672914269422218
Validation loss: 2.843838733260996

Epoch: 6| Step: 6
Training loss: 4.0570792786127825
Validation loss: 2.8433064111740762

Epoch: 6| Step: 7
Training loss: 3.0610067658622215
Validation loss: 2.842070725466461

Epoch: 6| Step: 8
Training loss: 3.095951722569563
Validation loss: 2.839504867352068

Epoch: 6| Step: 9
Training loss: 3.539535659250443
Validation loss: 2.841090840824945

Epoch: 6| Step: 10
Training loss: 2.459516229900515
Validation loss: 2.840431419897356

Epoch: 6| Step: 11
Training loss: 2.4690921401502037
Validation loss: 2.837160195889089

Epoch: 6| Step: 12
Training loss: 2.879054983119495
Validation loss: 2.8394371132357175

Epoch: 6| Step: 13
Training loss: 4.058542289811513
Validation loss: 2.836639962740939

Epoch: 252| Step: 0
Training loss: 2.8474489406063723
Validation loss: 2.8406407846813004

Epoch: 6| Step: 1
Training loss: 3.571954595791975
Validation loss: 2.8396728074192406

Epoch: 6| Step: 2
Training loss: 3.0476667891464144
Validation loss: 2.835759724269626

Epoch: 6| Step: 3
Training loss: 3.371887184382672
Validation loss: 2.8373801130842446

Epoch: 6| Step: 4
Training loss: 2.682162995940402
Validation loss: 2.836424981814148

Epoch: 6| Step: 5
Training loss: 2.767109359421982
Validation loss: 2.836067930968206

Epoch: 6| Step: 6
Training loss: 2.723023574547735
Validation loss: 2.8367393474445777

Epoch: 6| Step: 7
Training loss: 3.0851232299428664
Validation loss: 2.834001775956866

Epoch: 6| Step: 8
Training loss: 2.8845710662958592
Validation loss: 2.8373897247548006

Epoch: 6| Step: 9
Training loss: 2.849044900772652
Validation loss: 2.8367222940468992

Epoch: 6| Step: 10
Training loss: 2.7969984315029706
Validation loss: 2.8427087517585337

Epoch: 6| Step: 11
Training loss: 3.6918122244929426
Validation loss: 2.8396533683842375

Epoch: 6| Step: 12
Training loss: 3.7805376879434673
Validation loss: 2.8374131714744584

Epoch: 6| Step: 13
Training loss: 3.811234436103468
Validation loss: 2.8395961735875166

Epoch: 253| Step: 0
Training loss: 3.3222374934508556
Validation loss: 2.837349902699592

Epoch: 6| Step: 1
Training loss: 2.8702725228571504
Validation loss: 2.8410242145887223

Epoch: 6| Step: 2
Training loss: 3.8554847044455225
Validation loss: 2.845052861272031

Epoch: 6| Step: 3
Training loss: 2.270902288480705
Validation loss: 2.840533444490585

Epoch: 6| Step: 4
Training loss: 3.380601261540078
Validation loss: 2.8360539505683144

Epoch: 6| Step: 5
Training loss: 3.1453239247417324
Validation loss: 2.838378563483332

Epoch: 6| Step: 6
Training loss: 2.6540500281878683
Validation loss: 2.838174693528576

Epoch: 6| Step: 7
Training loss: 3.0505997802842337
Validation loss: 2.841925609962517

Epoch: 6| Step: 8
Training loss: 3.6379998037412653
Validation loss: 2.847011210254693

Epoch: 6| Step: 9
Training loss: 2.8841643846516223
Validation loss: 2.8376469201713768

Epoch: 6| Step: 10
Training loss: 3.508398877858278
Validation loss: 2.8373022535578185

Epoch: 6| Step: 11
Training loss: 3.0276771804787734
Validation loss: 2.8367519978002167

Epoch: 6| Step: 12
Training loss: 2.8597288486016317
Validation loss: 2.8372149712223185

Epoch: 6| Step: 13
Training loss: 3.07015113309451
Validation loss: 2.8424176278627398

Epoch: 254| Step: 0
Training loss: 2.589196125604096
Validation loss: 2.8327772950908856

Epoch: 6| Step: 1
Training loss: 3.7186935805200165
Validation loss: 2.8344001649601247

Epoch: 6| Step: 2
Training loss: 2.9685444007754036
Validation loss: 2.8335536500758556

Epoch: 6| Step: 3
Training loss: 3.7829540605934597
Validation loss: 2.834849517139398

Epoch: 6| Step: 4
Training loss: 3.009503887264633
Validation loss: 2.8330839621620028

Epoch: 6| Step: 5
Training loss: 3.1713514976513206
Validation loss: 2.8327077338409095

Epoch: 6| Step: 6
Training loss: 3.2828185192635795
Validation loss: 2.8338758816586775

Epoch: 6| Step: 7
Training loss: 2.9455232823076125
Validation loss: 2.8361854708096566

Epoch: 6| Step: 8
Training loss: 2.6501339680619047
Validation loss: 2.832288439610191

Epoch: 6| Step: 9
Training loss: 2.857047045327372
Validation loss: 2.834812819173693

Epoch: 6| Step: 10
Training loss: 3.3829221641613945
Validation loss: 2.83631552250245

Epoch: 6| Step: 11
Training loss: 2.2660875571725954
Validation loss: 2.8304468129879803

Epoch: 6| Step: 12
Training loss: 3.178434457782163
Validation loss: 2.834388623851176

Epoch: 6| Step: 13
Training loss: 4.057607198581267
Validation loss: 2.8359746109907733

Epoch: 255| Step: 0
Training loss: 2.909132645589367
Validation loss: 2.8418859191234582

Epoch: 6| Step: 1
Training loss: 3.060679770617005
Validation loss: 2.8420962276195976

Epoch: 6| Step: 2
Training loss: 2.415889505411197
Validation loss: 2.8413909860181277

Epoch: 6| Step: 3
Training loss: 2.5364218728162387
Validation loss: 2.8425178639668633

Epoch: 6| Step: 4
Training loss: 3.188874191563402
Validation loss: 2.8500944158274764

Epoch: 6| Step: 5
Training loss: 3.032476118202863
Validation loss: 2.8457255694673633

Epoch: 6| Step: 6
Training loss: 4.021176074874922
Validation loss: 2.8425014801718524

Epoch: 6| Step: 7
Training loss: 3.068551293677711
Validation loss: 2.8384737263850552

Epoch: 6| Step: 8
Training loss: 3.6680788586292086
Validation loss: 2.831814721485838

Epoch: 6| Step: 9
Training loss: 3.281911438169574
Validation loss: 2.8328450564573564

Epoch: 6| Step: 10
Training loss: 2.930985877657355
Validation loss: 2.8327237896517783

Epoch: 6| Step: 11
Training loss: 3.285216341138138
Validation loss: 2.829110848891999

Epoch: 6| Step: 12
Training loss: 2.8048026823656627
Validation loss: 2.8300386258196153

Epoch: 6| Step: 13
Training loss: 3.490080400431636
Validation loss: 2.82961244456694

Epoch: 256| Step: 0
Training loss: 3.274508863124016
Validation loss: 2.8306954495396948

Epoch: 6| Step: 1
Training loss: 2.721097349372036
Validation loss: 2.8286734220179666

Epoch: 6| Step: 2
Training loss: 3.5905697226523174
Validation loss: 2.832307518258595

Epoch: 6| Step: 3
Training loss: 3.287417473863175
Validation loss: 2.830361927847331

Epoch: 6| Step: 4
Training loss: 2.9860681653939025
Validation loss: 2.8297316957571566

Epoch: 6| Step: 5
Training loss: 2.8468691309712417
Validation loss: 2.8303983429587922

Epoch: 6| Step: 6
Training loss: 2.8175822645225987
Validation loss: 2.8266858405159265

Epoch: 6| Step: 7
Training loss: 3.3627835746225143
Validation loss: 2.8304344768220484

Epoch: 6| Step: 8
Training loss: 3.57695687895675
Validation loss: 2.828879611560365

Epoch: 6| Step: 9
Training loss: 3.3931200542262836
Validation loss: 2.8277045829032224

Epoch: 6| Step: 10
Training loss: 2.587639101868921
Validation loss: 2.827839921030641

Epoch: 6| Step: 11
Training loss: 3.6731918246318136
Validation loss: 2.830946715785237

Epoch: 6| Step: 12
Training loss: 3.1497805927703557
Validation loss: 2.8279244766482026

Epoch: 6| Step: 13
Training loss: 1.1641953155735272
Validation loss: 2.828679119044948

Epoch: 257| Step: 0
Training loss: 3.6233211444367797
Validation loss: 2.82848135135869

Epoch: 6| Step: 1
Training loss: 2.758610769266345
Validation loss: 2.8319257597323224

Epoch: 6| Step: 2
Training loss: 2.44099000357863
Validation loss: 2.8337109046936324

Epoch: 6| Step: 3
Training loss: 3.2866529758727916
Validation loss: 2.8346739504223786

Epoch: 6| Step: 4
Training loss: 3.167632173281026
Validation loss: 2.8371935491509364

Epoch: 6| Step: 5
Training loss: 3.39463786669988
Validation loss: 2.8370569602154205

Epoch: 6| Step: 6
Training loss: 3.116187831657914
Validation loss: 2.839566837243886

Epoch: 6| Step: 7
Training loss: 3.512447701604445
Validation loss: 2.8395709252464254

Epoch: 6| Step: 8
Training loss: 3.254157414995068
Validation loss: 2.8348013349098453

Epoch: 6| Step: 9
Training loss: 2.5360380499479285
Validation loss: 2.830828776395028

Epoch: 6| Step: 10
Training loss: 3.499786370433469
Validation loss: 2.8299859454979526

Epoch: 6| Step: 11
Training loss: 3.214372194731377
Validation loss: 2.8321223599690195

Epoch: 6| Step: 12
Training loss: 2.6311440996981648
Validation loss: 2.8265036281440223

Epoch: 6| Step: 13
Training loss: 3.0667449181013073
Validation loss: 2.8263706950023813

Epoch: 258| Step: 0
Training loss: 2.480632434160084
Validation loss: 2.831450965053128

Epoch: 6| Step: 1
Training loss: 3.8315324837871865
Validation loss: 2.8261824445924195

Epoch: 6| Step: 2
Training loss: 3.0093381505118324
Validation loss: 2.8305559703161842

Epoch: 6| Step: 3
Training loss: 3.347883432662901
Validation loss: 2.82815043754607

Epoch: 6| Step: 4
Training loss: 3.156063867500496
Validation loss: 2.8313716585665265

Epoch: 6| Step: 5
Training loss: 2.8664435063225935
Validation loss: 2.827236349790713

Epoch: 6| Step: 6
Training loss: 3.6402213073358376
Validation loss: 2.829467188440284

Epoch: 6| Step: 7
Training loss: 3.36859087453203
Validation loss: 2.8282621145677385

Epoch: 6| Step: 8
Training loss: 3.1611652437419635
Validation loss: 2.827418563904717

Epoch: 6| Step: 9
Training loss: 3.008174250263154
Validation loss: 2.8301580030792053

Epoch: 6| Step: 10
Training loss: 2.6926250826118094
Validation loss: 2.830395963545733

Epoch: 6| Step: 11
Training loss: 3.4539098063556106
Validation loss: 2.835656016311926

Epoch: 6| Step: 12
Training loss: 2.761632332535633
Validation loss: 2.832483123949718

Epoch: 6| Step: 13
Training loss: 2.3707705533565657
Validation loss: 2.8337528441776225

Epoch: 259| Step: 0
Training loss: 3.497051632044843
Validation loss: 2.826770729029893

Epoch: 6| Step: 1
Training loss: 3.8440430072041796
Validation loss: 2.8262211459080504

Epoch: 6| Step: 2
Training loss: 3.170626540256023
Validation loss: 2.8270938842594933

Epoch: 6| Step: 3
Training loss: 3.12036246468431
Validation loss: 2.8263113583271995

Epoch: 6| Step: 4
Training loss: 2.9848191495004532
Validation loss: 2.822274181763036

Epoch: 6| Step: 5
Training loss: 2.6592413719663437
Validation loss: 2.825781327513945

Epoch: 6| Step: 6
Training loss: 2.512255858900489
Validation loss: 2.823495888464516

Epoch: 6| Step: 7
Training loss: 2.9649579374214925
Validation loss: 2.8252220086901074

Epoch: 6| Step: 8
Training loss: 3.154679313599922
Validation loss: 2.8246053503324875

Epoch: 6| Step: 9
Training loss: 3.2398308335399326
Validation loss: 2.82368926425169

Epoch: 6| Step: 10
Training loss: 2.3962049002624437
Validation loss: 2.821088706634085

Epoch: 6| Step: 11
Training loss: 4.0300875621587915
Validation loss: 2.8212242440037456

Epoch: 6| Step: 12
Training loss: 2.530084035329672
Validation loss: 2.822387891595491

Epoch: 6| Step: 13
Training loss: 3.326337307340034
Validation loss: 2.824204732729937

Epoch: 260| Step: 0
Training loss: 2.7058375865862514
Validation loss: 2.8219044623422613

Epoch: 6| Step: 1
Training loss: 2.7642235087439517
Validation loss: 2.8235733097353797

Epoch: 6| Step: 2
Training loss: 3.9435372465997864
Validation loss: 2.8250500434191292

Epoch: 6| Step: 3
Training loss: 3.013734847750204
Validation loss: 2.827161981339547

Epoch: 6| Step: 4
Training loss: 3.082910989927209
Validation loss: 2.8290836728794515

Epoch: 6| Step: 5
Training loss: 2.9356397866617168
Validation loss: 2.83997893751839

Epoch: 6| Step: 6
Training loss: 3.484792231054202
Validation loss: 2.8345434770167017

Epoch: 6| Step: 7
Training loss: 3.5541683279006016
Validation loss: 2.826653091550821

Epoch: 6| Step: 8
Training loss: 2.626788665274883
Validation loss: 2.826038724865867

Epoch: 6| Step: 9
Training loss: 3.1489493661530514
Validation loss: 2.8226378011410094

Epoch: 6| Step: 10
Training loss: 2.3584707181923115
Validation loss: 2.82182317774826

Epoch: 6| Step: 11
Training loss: 3.5511926930901723
Validation loss: 2.820411172958181

Epoch: 6| Step: 12
Training loss: 3.3192705741118846
Validation loss: 2.821046297162813

Epoch: 6| Step: 13
Training loss: 2.7657688771555082
Validation loss: 2.8217006922547427

Epoch: 261| Step: 0
Training loss: 3.167291646486216
Validation loss: 2.818460555854889

Epoch: 6| Step: 1
Training loss: 2.7422384491015652
Validation loss: 2.8197902504623564

Epoch: 6| Step: 2
Training loss: 3.238130609669085
Validation loss: 2.8187616410099294

Epoch: 6| Step: 3
Training loss: 3.0447383333473317
Validation loss: 2.820992881840979

Epoch: 6| Step: 4
Training loss: 2.786031235141195
Validation loss: 2.818266748527032

Epoch: 6| Step: 5
Training loss: 2.647771520910938
Validation loss: 2.823251706555643

Epoch: 6| Step: 6
Training loss: 3.0626964895312927
Validation loss: 2.821276689926095

Epoch: 6| Step: 7
Training loss: 3.454414092536864
Validation loss: 2.8242061742190203

Epoch: 6| Step: 8
Training loss: 3.2477470805534048
Validation loss: 2.8225721970884408

Epoch: 6| Step: 9
Training loss: 2.6950796717826098
Validation loss: 2.821395524729733

Epoch: 6| Step: 10
Training loss: 3.822461107154715
Validation loss: 2.8192101412253705

Epoch: 6| Step: 11
Training loss: 2.9909939688797436
Validation loss: 2.823580240955661

Epoch: 6| Step: 12
Training loss: 3.5884684355433065
Validation loss: 2.824372690304322

Epoch: 6| Step: 13
Training loss: 2.8727514347162133
Validation loss: 2.8279189920459746

Epoch: 262| Step: 0
Training loss: 2.734639966933267
Validation loss: 2.8259758695673236

Epoch: 6| Step: 1
Training loss: 3.0315130060676023
Validation loss: 2.8320952508729267

Epoch: 6| Step: 2
Training loss: 3.2855222953953667
Validation loss: 2.8270868274452727

Epoch: 6| Step: 3
Training loss: 3.544857846357017
Validation loss: 2.8363813627340826

Epoch: 6| Step: 4
Training loss: 2.8965102211949496
Validation loss: 2.8249400208444087

Epoch: 6| Step: 5
Training loss: 3.011342857642486
Validation loss: 2.832659147738582

Epoch: 6| Step: 6
Training loss: 3.284617412706016
Validation loss: 2.842304434325312

Epoch: 6| Step: 7
Training loss: 2.53717797401727
Validation loss: 2.8364855539197813

Epoch: 6| Step: 8
Training loss: 3.7591441247684627
Validation loss: 2.8324101884708175

Epoch: 6| Step: 9
Training loss: 3.1939893002077056
Validation loss: 2.8229179610873123

Epoch: 6| Step: 10
Training loss: 3.4372686134837114
Validation loss: 2.8249329486671826

Epoch: 6| Step: 11
Training loss: 2.42408022003759
Validation loss: 2.824385276236048

Epoch: 6| Step: 12
Training loss: 3.194701791615849
Validation loss: 2.819812244776426

Epoch: 6| Step: 13
Training loss: 3.1705211136467897
Validation loss: 2.818597278314407

Epoch: 263| Step: 0
Training loss: 2.793486689847034
Validation loss: 2.818192350785712

Epoch: 6| Step: 1
Training loss: 2.926394633841874
Validation loss: 2.817523587143577

Epoch: 6| Step: 2
Training loss: 3.240549432062882
Validation loss: 2.8202831303254614

Epoch: 6| Step: 3
Training loss: 3.2529175207574177
Validation loss: 2.818768082023591

Epoch: 6| Step: 4
Training loss: 3.503571731436269
Validation loss: 2.8145738737620576

Epoch: 6| Step: 5
Training loss: 3.0700111920777133
Validation loss: 2.817134372388432

Epoch: 6| Step: 6
Training loss: 3.316021468954681
Validation loss: 2.815755750362191

Epoch: 6| Step: 7
Training loss: 3.047596381449426
Validation loss: 2.8136474629454358

Epoch: 6| Step: 8
Training loss: 3.2923909287862676
Validation loss: 2.8143249023880372

Epoch: 6| Step: 9
Training loss: 2.5274695906050195
Validation loss: 2.8167258205878025

Epoch: 6| Step: 10
Training loss: 2.781543159036195
Validation loss: 2.8151284645437964

Epoch: 6| Step: 11
Training loss: 3.735950600454734
Validation loss: 2.8153479318611248

Epoch: 6| Step: 12
Training loss: 3.207242970325623
Validation loss: 2.8145174800485115

Epoch: 6| Step: 13
Training loss: 2.542367890563204
Validation loss: 2.8257569509789766

Epoch: 264| Step: 0
Training loss: 3.3743356121411896
Validation loss: 2.8258147515757397

Epoch: 6| Step: 1
Training loss: 2.622606912330089
Validation loss: 2.8252730928072562

Epoch: 6| Step: 2
Training loss: 3.4149485819619376
Validation loss: 2.8339700315233234

Epoch: 6| Step: 3
Training loss: 3.110939897261366
Validation loss: 2.8383105404156574

Epoch: 6| Step: 4
Training loss: 2.5699640750971673
Validation loss: 2.8393122319262365

Epoch: 6| Step: 5
Training loss: 2.979725356279088
Validation loss: 2.82980991124867

Epoch: 6| Step: 6
Training loss: 2.932989675447102
Validation loss: 2.8270920896793923

Epoch: 6| Step: 7
Training loss: 2.8036590645780426
Validation loss: 2.8189355041073307

Epoch: 6| Step: 8
Training loss: 3.772307991010348
Validation loss: 2.818150572717406

Epoch: 6| Step: 9
Training loss: 2.6731940688708313
Validation loss: 2.815354007341768

Epoch: 6| Step: 10
Training loss: 3.8628657689405337
Validation loss: 2.81472965947447

Epoch: 6| Step: 11
Training loss: 3.1859084999369807
Validation loss: 2.815637271176902

Epoch: 6| Step: 12
Training loss: 2.9612837214097745
Validation loss: 2.814736914855076

Epoch: 6| Step: 13
Training loss: 3.201896915870853
Validation loss: 2.8128415856247733

Epoch: 265| Step: 0
Training loss: 3.6044993311362425
Validation loss: 2.817318615718986

Epoch: 6| Step: 1
Training loss: 3.0680025452922823
Validation loss: 2.8111148736791747

Epoch: 6| Step: 2
Training loss: 3.372258803874284
Validation loss: 2.8136241502945425

Epoch: 6| Step: 3
Training loss: 2.478166223402003
Validation loss: 2.8114983309703923

Epoch: 6| Step: 4
Training loss: 2.839038341127604
Validation loss: 2.812900840060297

Epoch: 6| Step: 5
Training loss: 3.3249014703593334
Validation loss: 2.8119689376218306

Epoch: 6| Step: 6
Training loss: 2.69767494051568
Validation loss: 2.8089939035296276

Epoch: 6| Step: 7
Training loss: 3.2862368517613003
Validation loss: 2.812120114356215

Epoch: 6| Step: 8
Training loss: 3.653086801921499
Validation loss: 2.8101825039658794

Epoch: 6| Step: 9
Training loss: 3.2837253497897114
Validation loss: 2.8137920697755283

Epoch: 6| Step: 10
Training loss: 2.3658318493408337
Validation loss: 2.8163671543867417

Epoch: 6| Step: 11
Training loss: 3.709788704790597
Validation loss: 2.813751915573133

Epoch: 6| Step: 12
Training loss: 2.992704899528455
Validation loss: 2.814302803245912

Epoch: 6| Step: 13
Training loss: 2.1134099727215903
Validation loss: 2.8113791343566805

Epoch: 266| Step: 0
Training loss: 3.2102424259089015
Validation loss: 2.8209972912014996

Epoch: 6| Step: 1
Training loss: 3.2632121978606605
Validation loss: 2.8181818158136456

Epoch: 6| Step: 2
Training loss: 2.8785368683696717
Validation loss: 2.8350035674482945

Epoch: 6| Step: 3
Training loss: 3.0695931948544866
Validation loss: 2.8300301523202833

Epoch: 6| Step: 4
Training loss: 3.437129885082004
Validation loss: 2.8255075749940177

Epoch: 6| Step: 5
Training loss: 2.5583219194520037
Validation loss: 2.829538144908618

Epoch: 6| Step: 6
Training loss: 3.2412858191768095
Validation loss: 2.815884287465461

Epoch: 6| Step: 7
Training loss: 3.194120525209628
Validation loss: 2.8181559216837737

Epoch: 6| Step: 8
Training loss: 2.895503860136426
Validation loss: 2.812222413979591

Epoch: 6| Step: 9
Training loss: 2.9973639987257026
Validation loss: 2.8145834421728746

Epoch: 6| Step: 10
Training loss: 3.3858192243633387
Validation loss: 2.8131937645694816

Epoch: 6| Step: 11
Training loss: 2.4429253086659655
Validation loss: 2.808180471048846

Epoch: 6| Step: 12
Training loss: 3.1741664483138816
Validation loss: 2.814343766683323

Epoch: 6| Step: 13
Training loss: 4.074937766132332
Validation loss: 2.8113266952916285

Epoch: 267| Step: 0
Training loss: 3.3060507701707014
Validation loss: 2.8110967911630578

Epoch: 6| Step: 1
Training loss: 2.0598689550550326
Validation loss: 2.8101687989246136

Epoch: 6| Step: 2
Training loss: 2.583389732811656
Validation loss: 2.8121198463340993

Epoch: 6| Step: 3
Training loss: 3.3678702881361033
Validation loss: 2.8103516197505187

Epoch: 6| Step: 4
Training loss: 2.756860239027898
Validation loss: 2.8091203270475904

Epoch: 6| Step: 5
Training loss: 3.313013864641917
Validation loss: 2.8089244396319737

Epoch: 6| Step: 6
Training loss: 3.436937043302368
Validation loss: 2.8091593373458137

Epoch: 6| Step: 7
Training loss: 3.5264284418575675
Validation loss: 2.812523758581664

Epoch: 6| Step: 8
Training loss: 3.315222862657857
Validation loss: 2.8106919195431965

Epoch: 6| Step: 9
Training loss: 3.0021243521230683
Validation loss: 2.8080203679217894

Epoch: 6| Step: 10
Training loss: 3.693070423073499
Validation loss: 2.807653481240406

Epoch: 6| Step: 11
Training loss: 2.5548830103358324
Validation loss: 2.806525190134065

Epoch: 6| Step: 12
Training loss: 3.4515823439670474
Validation loss: 2.8073500413460897

Epoch: 6| Step: 13
Training loss: 2.5263351007819352
Validation loss: 2.8049059526363056

Epoch: 268| Step: 0
Training loss: 3.925350275628527
Validation loss: 2.8076468576769105

Epoch: 6| Step: 1
Training loss: 2.954813640933879
Validation loss: 2.8072646221919237

Epoch: 6| Step: 2
Training loss: 2.605563091989267
Validation loss: 2.8044163030110574

Epoch: 6| Step: 3
Training loss: 3.3511043493313397
Validation loss: 2.805311672099616

Epoch: 6| Step: 4
Training loss: 2.404004324771082
Validation loss: 2.8083347409527417

Epoch: 6| Step: 5
Training loss: 3.279055342830495
Validation loss: 2.8083341585425075

Epoch: 6| Step: 6
Training loss: 3.1178994955096164
Validation loss: 2.8067071248147792

Epoch: 6| Step: 7
Training loss: 3.2862937309689855
Validation loss: 2.8058395850812428

Epoch: 6| Step: 8
Training loss: 2.2777215503586072
Validation loss: 2.800959182775801

Epoch: 6| Step: 9
Training loss: 3.4792270007964827
Validation loss: 2.8042980194106604

Epoch: 6| Step: 10
Training loss: 3.2776582951149944
Validation loss: 2.8061621002953396

Epoch: 6| Step: 11
Training loss: 2.6938754023771616
Validation loss: 2.8065927942870363

Epoch: 6| Step: 12
Training loss: 3.100416918375499
Validation loss: 2.809970342472084

Epoch: 6| Step: 13
Training loss: 3.6205020491066495
Validation loss: 2.8114670819912053

Epoch: 269| Step: 0
Training loss: 3.0496752268992493
Validation loss: 2.8213877276553783

Epoch: 6| Step: 1
Training loss: 3.2111658910752157
Validation loss: 2.8200629652870646

Epoch: 6| Step: 2
Training loss: 3.6508485722145765
Validation loss: 2.825761080733888

Epoch: 6| Step: 3
Training loss: 3.4843867690909702
Validation loss: 2.820779903884543

Epoch: 6| Step: 4
Training loss: 3.020138540058628
Validation loss: 2.8149918704974755

Epoch: 6| Step: 5
Training loss: 2.7868401571808934
Validation loss: 2.8180778512387907

Epoch: 6| Step: 6
Training loss: 3.0600643203557594
Validation loss: 2.811908748193621

Epoch: 6| Step: 7
Training loss: 2.986424087170169
Validation loss: 2.8218494061674484

Epoch: 6| Step: 8
Training loss: 2.954193083551301
Validation loss: 2.80837927763341

Epoch: 6| Step: 9
Training loss: 3.0217876812253492
Validation loss: 2.809483002635932

Epoch: 6| Step: 10
Training loss: 2.7340460879188297
Validation loss: 2.8107115296900793

Epoch: 6| Step: 11
Training loss: 3.2364406899932137
Validation loss: 2.8129893297676993

Epoch: 6| Step: 12
Training loss: 3.1956609335448993
Validation loss: 2.8059099458129944

Epoch: 6| Step: 13
Training loss: 2.985133209578873
Validation loss: 2.80996793025134

Epoch: 270| Step: 0
Training loss: 2.712910662385505
Validation loss: 2.8020099051289185

Epoch: 6| Step: 1
Training loss: 3.4823230123901587
Validation loss: 2.800570686768365

Epoch: 6| Step: 2
Training loss: 3.041085401064058
Validation loss: 2.8058940865014805

Epoch: 6| Step: 3
Training loss: 2.9867520277847097
Validation loss: 2.8037929748574597

Epoch: 6| Step: 4
Training loss: 2.9375318160261714
Validation loss: 2.801963940539578

Epoch: 6| Step: 5
Training loss: 3.0072487042622713
Validation loss: 2.8012893203801994

Epoch: 6| Step: 6
Training loss: 2.9415122693169224
Validation loss: 2.8051482577477342

Epoch: 6| Step: 7
Training loss: 3.3127200935228114
Validation loss: 2.803867761071667

Epoch: 6| Step: 8
Training loss: 3.0201606439975603
Validation loss: 2.8025500803170824

Epoch: 6| Step: 9
Training loss: 3.3862750720859296
Validation loss: 2.8033481617124787

Epoch: 6| Step: 10
Training loss: 3.380087655866388
Validation loss: 2.803011321115683

Epoch: 6| Step: 11
Training loss: 3.2663643470016144
Validation loss: 2.8034948388009346

Epoch: 6| Step: 12
Training loss: 2.9421205907051915
Validation loss: 2.80303097219208

Epoch: 6| Step: 13
Training loss: 2.9285873585443847
Validation loss: 2.8008997104896376

Epoch: 271| Step: 0
Training loss: 2.9841712762292283
Validation loss: 2.8010929319994613

Epoch: 6| Step: 1
Training loss: 2.8174304554843013
Validation loss: 2.809025483932183

Epoch: 6| Step: 2
Training loss: 3.308522121190035
Validation loss: 2.802889970883305

Epoch: 6| Step: 3
Training loss: 2.8964231334135966
Validation loss: 2.800295653423584

Epoch: 6| Step: 4
Training loss: 3.4417875427251188
Validation loss: 2.7995930004895397

Epoch: 6| Step: 5
Training loss: 2.6826950411891763
Validation loss: 2.808007785329867

Epoch: 6| Step: 6
Training loss: 3.4055718263033783
Validation loss: 2.8003488034799817

Epoch: 6| Step: 7
Training loss: 3.190148692955628
Validation loss: 2.8021546065922904

Epoch: 6| Step: 8
Training loss: 2.376296843779897
Validation loss: 2.8064462325235855

Epoch: 6| Step: 9
Training loss: 3.4991249625499288
Validation loss: 2.8023950327404057

Epoch: 6| Step: 10
Training loss: 3.438377684471882
Validation loss: 2.8076929337608356

Epoch: 6| Step: 11
Training loss: 2.9001502557173318
Validation loss: 2.813850827701316

Epoch: 6| Step: 12
Training loss: 3.7585390146028805
Validation loss: 2.8109448087997015

Epoch: 6| Step: 13
Training loss: 1.8497684333832474
Validation loss: 2.810249393424109

Epoch: 272| Step: 0
Training loss: 3.389390289930563
Validation loss: 2.808357089713162

Epoch: 6| Step: 1
Training loss: 3.559859518644025
Validation loss: 2.8093138044478954

Epoch: 6| Step: 2
Training loss: 3.579378000281122
Validation loss: 2.8044721109534683

Epoch: 6| Step: 3
Training loss: 2.781092264224419
Validation loss: 2.8073401478411197

Epoch: 6| Step: 4
Training loss: 3.275139486822216
Validation loss: 2.798738996104178

Epoch: 6| Step: 5
Training loss: 2.8705373211872898
Validation loss: 2.800495140585818

Epoch: 6| Step: 6
Training loss: 2.8916901146838594
Validation loss: 2.7992438159561366

Epoch: 6| Step: 7
Training loss: 2.3159414921948644
Validation loss: 2.8019945864277203

Epoch: 6| Step: 8
Training loss: 3.0981463396985465
Validation loss: 2.8040039059391453

Epoch: 6| Step: 9
Training loss: 2.8574899598860553
Validation loss: 2.7996082132887414

Epoch: 6| Step: 10
Training loss: 3.1986448637248555
Validation loss: 2.8103455307189327

Epoch: 6| Step: 11
Training loss: 2.045039628071618
Validation loss: 2.7966847256766947

Epoch: 6| Step: 12
Training loss: 3.8847990116086706
Validation loss: 2.7956947654578017

Epoch: 6| Step: 13
Training loss: 3.372845986662251
Validation loss: 2.799190185161545

Epoch: 273| Step: 0
Training loss: 3.0090348571401386
Validation loss: 2.799891835861483

Epoch: 6| Step: 1
Training loss: 2.6115145563241775
Validation loss: 2.7990728796142936

Epoch: 6| Step: 2
Training loss: 3.6569030700138283
Validation loss: 2.7989123965706884

Epoch: 6| Step: 3
Training loss: 3.444560896706308
Validation loss: 2.798241854237219

Epoch: 6| Step: 4
Training loss: 3.1963981145943667
Validation loss: 2.7996776308804505

Epoch: 6| Step: 5
Training loss: 3.3267876888831207
Validation loss: 2.7989024329389203

Epoch: 6| Step: 6
Training loss: 2.8758523755551724
Validation loss: 2.7981196301658926

Epoch: 6| Step: 7
Training loss: 3.0244519013010756
Validation loss: 2.7969839075209313

Epoch: 6| Step: 8
Training loss: 2.8078410236860694
Validation loss: 2.798639736749926

Epoch: 6| Step: 9
Training loss: 3.2528206249542015
Validation loss: 2.7997326157756803

Epoch: 6| Step: 10
Training loss: 3.5160424556837904
Validation loss: 2.7960752928588346

Epoch: 6| Step: 11
Training loss: 2.8513032978299275
Validation loss: 2.8003245561863044

Epoch: 6| Step: 12
Training loss: 2.818458941334004
Validation loss: 2.8003546185514434

Epoch: 6| Step: 13
Training loss: 2.7737952632915595
Validation loss: 2.7991292227193587

Epoch: 274| Step: 0
Training loss: 3.633673190632757
Validation loss: 2.7963106235963298

Epoch: 6| Step: 1
Training loss: 3.44306287608707
Validation loss: 2.803425171890116

Epoch: 6| Step: 2
Training loss: 2.658171553357698
Validation loss: 2.801275827161813

Epoch: 6| Step: 3
Training loss: 3.62553625415441
Validation loss: 2.8038886953317217

Epoch: 6| Step: 4
Training loss: 3.4385332808709625
Validation loss: 2.7947225770998747

Epoch: 6| Step: 5
Training loss: 2.794716796175454
Validation loss: 2.7927418124457004

Epoch: 6| Step: 6
Training loss: 3.9739275223257096
Validation loss: 2.7936274637417617

Epoch: 6| Step: 7
Training loss: 2.7837144883849416
Validation loss: 2.7933432207170688

Epoch: 6| Step: 8
Training loss: 3.020825896856867
Validation loss: 2.7986142086827965

Epoch: 6| Step: 9
Training loss: 3.214705064454315
Validation loss: 2.793623676496608

Epoch: 6| Step: 10
Training loss: 2.2302154023012264
Validation loss: 2.793472863432346

Epoch: 6| Step: 11
Training loss: 3.015536450286717
Validation loss: 2.7948885181063687

Epoch: 6| Step: 12
Training loss: 2.3029233225664205
Validation loss: 2.7964851317112687

Epoch: 6| Step: 13
Training loss: 2.3952972033386124
Validation loss: 2.7949631582596863

Epoch: 275| Step: 0
Training loss: 3.6326477669723443
Validation loss: 2.793999985378535

Epoch: 6| Step: 1
Training loss: 2.889321853112599
Validation loss: 2.8073426956457146

Epoch: 6| Step: 2
Training loss: 2.7493312195875528
Validation loss: 2.8008099601108087

Epoch: 6| Step: 3
Training loss: 2.641118923243997
Validation loss: 2.7963992275765444

Epoch: 6| Step: 4
Training loss: 3.493995693350432
Validation loss: 2.802093603430443

Epoch: 6| Step: 5
Training loss: 3.0180202320752954
Validation loss: 2.803271485961688

Epoch: 6| Step: 6
Training loss: 3.5360355864240156
Validation loss: 2.8071684716230454

Epoch: 6| Step: 7
Training loss: 2.6484684675088492
Validation loss: 2.8046197914197535

Epoch: 6| Step: 8
Training loss: 2.8312588184210936
Validation loss: 2.798839144088975

Epoch: 6| Step: 9
Training loss: 3.3969122610005025
Validation loss: 2.79708491206955

Epoch: 6| Step: 10
Training loss: 3.5982483947067587
Validation loss: 2.7942200176433314

Epoch: 6| Step: 11
Training loss: 3.281613429696638
Validation loss: 2.7930854344448792

Epoch: 6| Step: 12
Training loss: 2.4208870133857117
Validation loss: 2.789694496421271

Epoch: 6| Step: 13
Training loss: 2.796498534370146
Validation loss: 2.7911370919485954

Epoch: 276| Step: 0
Training loss: 2.76824999012237
Validation loss: 2.794157085154977

Epoch: 6| Step: 1
Training loss: 2.9040645462828563
Validation loss: 2.791122626560597

Epoch: 6| Step: 2
Training loss: 3.1735986996404986
Validation loss: 2.7900451636888457

Epoch: 6| Step: 3
Training loss: 3.5897866328596755
Validation loss: 2.7950802281332225

Epoch: 6| Step: 4
Training loss: 3.5122854689928382
Validation loss: 2.796828965686856

Epoch: 6| Step: 5
Training loss: 2.8664947421246767
Validation loss: 2.794527097798689

Epoch: 6| Step: 6
Training loss: 3.1412459181953745
Validation loss: 2.7907493239970496

Epoch: 6| Step: 7
Training loss: 2.009498452388398
Validation loss: 2.7949200808594417

Epoch: 6| Step: 8
Training loss: 3.343565178157282
Validation loss: 2.7909785821455246

Epoch: 6| Step: 9
Training loss: 3.0191754406611913
Validation loss: 2.7920847270411855

Epoch: 6| Step: 10
Training loss: 2.960536959891119
Validation loss: 2.7997578021744616

Epoch: 6| Step: 11
Training loss: 3.0184074570815205
Validation loss: 2.7956541926798306

Epoch: 6| Step: 12
Training loss: 3.4237892683993767
Validation loss: 2.8021858313388446

Epoch: 6| Step: 13
Training loss: 3.4898085032831534
Validation loss: 2.795248136273077

Epoch: 277| Step: 0
Training loss: 3.347073908290433
Validation loss: 2.797827528136063

Epoch: 6| Step: 1
Training loss: 2.8807693312199203
Validation loss: 2.7970881676182815

Epoch: 6| Step: 2
Training loss: 2.8486544059324705
Validation loss: 2.799159852017928

Epoch: 6| Step: 3
Training loss: 3.168812744000972
Validation loss: 2.797601681161143

Epoch: 6| Step: 4
Training loss: 3.1043404310777394
Validation loss: 2.793972052199435

Epoch: 6| Step: 5
Training loss: 3.51411642980516
Validation loss: 2.7900470059879754

Epoch: 6| Step: 6
Training loss: 2.6708017614187707
Validation loss: 2.799976337277207

Epoch: 6| Step: 7
Training loss: 2.8243418306621852
Validation loss: 2.7861422862763354

Epoch: 6| Step: 8
Training loss: 3.4522858717780767
Validation loss: 2.7951223840474397

Epoch: 6| Step: 9
Training loss: 2.974471030772166
Validation loss: 2.7899190859750047

Epoch: 6| Step: 10
Training loss: 2.772596720736029
Validation loss: 2.7857192428518016

Epoch: 6| Step: 11
Training loss: 3.287999359613435
Validation loss: 2.7860289981910817

Epoch: 6| Step: 12
Training loss: 3.0119937518841504
Validation loss: 2.7929315246859554

Epoch: 6| Step: 13
Training loss: 3.510779402619165
Validation loss: 2.7897950131941798

Epoch: 278| Step: 0
Training loss: 3.3468282915376926
Validation loss: 2.789641545887854

Epoch: 6| Step: 1
Training loss: 3.4349835982062986
Validation loss: 2.78948976530016

Epoch: 6| Step: 2
Training loss: 2.8106215243734765
Validation loss: 2.7873651065097937

Epoch: 6| Step: 3
Training loss: 2.686008039239483
Validation loss: 2.7873794819497792

Epoch: 6| Step: 4
Training loss: 3.297732851774067
Validation loss: 2.791171771283561

Epoch: 6| Step: 5
Training loss: 3.448706237802902
Validation loss: 2.7887014654764783

Epoch: 6| Step: 6
Training loss: 3.0909367881390724
Validation loss: 2.788473042452155

Epoch: 6| Step: 7
Training loss: 2.873062476058084
Validation loss: 2.7944117671105992

Epoch: 6| Step: 8
Training loss: 2.447594111409018
Validation loss: 2.7881234251988687

Epoch: 6| Step: 9
Training loss: 3.173269031284563
Validation loss: 2.7847295198128506

Epoch: 6| Step: 10
Training loss: 3.6671813834764713
Validation loss: 2.792439474240397

Epoch: 6| Step: 11
Training loss: 2.5548470823508747
Validation loss: 2.783695796875722

Epoch: 6| Step: 12
Training loss: 3.012029055431192
Validation loss: 2.790457504220025

Epoch: 6| Step: 13
Training loss: 3.266314858027318
Validation loss: 2.7831598747906967

Epoch: 279| Step: 0
Training loss: 3.5819937101870147
Validation loss: 2.7843203159758967

Epoch: 6| Step: 1
Training loss: 2.867565992771638
Validation loss: 2.786987117122108

Epoch: 6| Step: 2
Training loss: 2.6932928064652426
Validation loss: 2.7863444520765897

Epoch: 6| Step: 3
Training loss: 2.7445002092864184
Validation loss: 2.7922088183542058

Epoch: 6| Step: 4
Training loss: 3.227390875711218
Validation loss: 2.79147611202478

Epoch: 6| Step: 5
Training loss: 2.2618256380587742
Validation loss: 2.79671006877342

Epoch: 6| Step: 6
Training loss: 2.5078498623640577
Validation loss: 2.7938938216626843

Epoch: 6| Step: 7
Training loss: 3.318887561885383
Validation loss: 2.7965529602393433

Epoch: 6| Step: 8
Training loss: 3.258681805668621
Validation loss: 2.8076480346525967

Epoch: 6| Step: 9
Training loss: 2.483591399982177
Validation loss: 2.8023717298553175

Epoch: 6| Step: 10
Training loss: 2.895244474481663
Validation loss: 2.788323610357226

Epoch: 6| Step: 11
Training loss: 3.4508841998630233
Validation loss: 2.7925600915908286

Epoch: 6| Step: 12
Training loss: 4.083405448640068
Validation loss: 2.789202220516156

Epoch: 6| Step: 13
Training loss: 3.684504181050778
Validation loss: 2.7803413978155387

Epoch: 280| Step: 0
Training loss: 2.960210303233146
Validation loss: 2.786265749750485

Epoch: 6| Step: 1
Training loss: 3.3038008562345658
Validation loss: 2.7801711767038935

Epoch: 6| Step: 2
Training loss: 3.579102495097082
Validation loss: 2.781836991253262

Epoch: 6| Step: 3
Training loss: 2.8990954862977305
Validation loss: 2.779778428931811

Epoch: 6| Step: 4
Training loss: 3.659706894233031
Validation loss: 2.780963937838413

Epoch: 6| Step: 5
Training loss: 3.1697097679152555
Validation loss: 2.780739984855314

Epoch: 6| Step: 6
Training loss: 2.9609188189961486
Validation loss: 2.7811894527166667

Epoch: 6| Step: 7
Training loss: 3.1732532532255355
Validation loss: 2.783600491803469

Epoch: 6| Step: 8
Training loss: 2.7651070147425605
Validation loss: 2.7813615038039616

Epoch: 6| Step: 9
Training loss: 3.3558823993342823
Validation loss: 2.7810067179529927

Epoch: 6| Step: 10
Training loss: 2.655656366771274
Validation loss: 2.7903379021643078

Epoch: 6| Step: 11
Training loss: 2.817264674732844
Validation loss: 2.7841087849619757

Epoch: 6| Step: 12
Training loss: 2.4906992519515225
Validation loss: 2.787368859031029

Epoch: 6| Step: 13
Training loss: 3.392279155517352
Validation loss: 2.783852690776683

Epoch: 281| Step: 0
Training loss: 2.831402139176007
Validation loss: 2.786768518310598

Epoch: 6| Step: 1
Training loss: 3.3853817668974355
Validation loss: 2.782098785110622

Epoch: 6| Step: 2
Training loss: 3.258069510807874
Validation loss: 2.781455531631145

Epoch: 6| Step: 3
Training loss: 3.4881133821940216
Validation loss: 2.782502236633991

Epoch: 6| Step: 4
Training loss: 2.8326169585602887
Validation loss: 2.7779471057295355

Epoch: 6| Step: 5
Training loss: 3.1709961824709922
Validation loss: 2.778908177213621

Epoch: 6| Step: 6
Training loss: 2.964108663711249
Validation loss: 2.7809234903112108

Epoch: 6| Step: 7
Training loss: 2.6478460771189125
Validation loss: 2.778905197423299

Epoch: 6| Step: 8
Training loss: 3.387521756373285
Validation loss: 2.7786707886170334

Epoch: 6| Step: 9
Training loss: 3.422520406814048
Validation loss: 2.783126021365848

Epoch: 6| Step: 10
Training loss: 3.058008130598518
Validation loss: 2.7796669437074657

Epoch: 6| Step: 11
Training loss: 2.4730851944849994
Validation loss: 2.7803754123882176

Epoch: 6| Step: 12
Training loss: 3.5323894991535782
Validation loss: 2.7850884697672336

Epoch: 6| Step: 13
Training loss: 1.9881477835775896
Validation loss: 2.783303746331523

Epoch: 282| Step: 0
Training loss: 3.7595861615042057
Validation loss: 2.788019942477792

Epoch: 6| Step: 1
Training loss: 2.680257842200539
Validation loss: 2.794159052275443

Epoch: 6| Step: 2
Training loss: 3.2224289692581376
Validation loss: 2.7881892890466884

Epoch: 6| Step: 3
Training loss: 3.1601843154849236
Validation loss: 2.782211605728611

Epoch: 6| Step: 4
Training loss: 3.515046610407868
Validation loss: 2.780585115162855

Epoch: 6| Step: 5
Training loss: 2.8129038202934846
Validation loss: 2.775733807089832

Epoch: 6| Step: 6
Training loss: 2.30403795302444
Validation loss: 2.7747357521375804

Epoch: 6| Step: 7
Training loss: 2.451215644840781
Validation loss: 2.775712000115164

Epoch: 6| Step: 8
Training loss: 3.5993870849194534
Validation loss: 2.7750636485452658

Epoch: 6| Step: 9
Training loss: 3.2683053584038753
Validation loss: 2.7770058221351968

Epoch: 6| Step: 10
Training loss: 3.255327113718308
Validation loss: 2.7755961157662714

Epoch: 6| Step: 11
Training loss: 3.11564548374739
Validation loss: 2.778572155736937

Epoch: 6| Step: 12
Training loss: 3.064252857790468
Validation loss: 2.775764415625003

Epoch: 6| Step: 13
Training loss: 2.316024259878331
Validation loss: 2.774529151692082

Epoch: 283| Step: 0
Training loss: 2.2627613780749543
Validation loss: 2.776819020358699

Epoch: 6| Step: 1
Training loss: 2.8848388497286654
Validation loss: 2.7791652242260096

Epoch: 6| Step: 2
Training loss: 2.908397742344286
Validation loss: 2.775861961512239

Epoch: 6| Step: 3
Training loss: 3.160634083688607
Validation loss: 2.7800603075510106

Epoch: 6| Step: 4
Training loss: 3.211888379011406
Validation loss: 2.779746675807068

Epoch: 6| Step: 5
Training loss: 3.365334977003967
Validation loss: 2.778112496612593

Epoch: 6| Step: 6
Training loss: 3.085091854069644
Validation loss: 2.7948039068893213

Epoch: 6| Step: 7
Training loss: 3.321781327226867
Validation loss: 2.7989494626547917

Epoch: 6| Step: 8
Training loss: 3.5244106801123283
Validation loss: 2.8049434979553354

Epoch: 6| Step: 9
Training loss: 2.6446509735639325
Validation loss: 2.795725657044984

Epoch: 6| Step: 10
Training loss: 2.8303268039034877
Validation loss: 2.7890949504174722

Epoch: 6| Step: 11
Training loss: 3.085393543830754
Validation loss: 2.7919078659036436

Epoch: 6| Step: 12
Training loss: 3.261805733074829
Validation loss: 2.78720019844649

Epoch: 6| Step: 13
Training loss: 3.722818281043854
Validation loss: 2.780639158271258

Epoch: 284| Step: 0
Training loss: 2.8553852533534525
Validation loss: 2.7813432361460038

Epoch: 6| Step: 1
Training loss: 2.7483132130950705
Validation loss: 2.781476369127818

Epoch: 6| Step: 2
Training loss: 2.9769736979651777
Validation loss: 2.779964366031418

Epoch: 6| Step: 3
Training loss: 3.3888542368077856
Validation loss: 2.7770246805303307

Epoch: 6| Step: 4
Training loss: 3.141286751789816
Validation loss: 2.7816798509489695

Epoch: 6| Step: 5
Training loss: 3.522819921667937
Validation loss: 2.7759704771569886

Epoch: 6| Step: 6
Training loss: 2.5325860159332367
Validation loss: 2.7734690600709224

Epoch: 6| Step: 7
Training loss: 2.5430576291351596
Validation loss: 2.7796074484142133

Epoch: 6| Step: 8
Training loss: 3.0257573653503957
Validation loss: 2.7735319129302534

Epoch: 6| Step: 9
Training loss: 2.828596212848231
Validation loss: 2.7767727818815042

Epoch: 6| Step: 10
Training loss: 3.214290603755078
Validation loss: 2.7755540622982906

Epoch: 6| Step: 11
Training loss: 3.350376586244197
Validation loss: 2.781038000385757

Epoch: 6| Step: 12
Training loss: 3.6850189655701
Validation loss: 2.7795606558936203

Epoch: 6| Step: 13
Training loss: 3.127230954143259
Validation loss: 2.775962784295606

Epoch: 285| Step: 0
Training loss: 2.5632204113093993
Validation loss: 2.778045004087849

Epoch: 6| Step: 1
Training loss: 3.010799361634798
Validation loss: 2.7801235443881014

Epoch: 6| Step: 2
Training loss: 2.8665438145180615
Validation loss: 2.774827891545185

Epoch: 6| Step: 3
Training loss: 2.8838176680663024
Validation loss: 2.782440828405242

Epoch: 6| Step: 4
Training loss: 3.3610853942083416
Validation loss: 2.779836705070663

Epoch: 6| Step: 5
Training loss: 3.3972659843192865
Validation loss: 2.7798606552042724

Epoch: 6| Step: 6
Training loss: 3.232211361394704
Validation loss: 2.779217912218983

Epoch: 6| Step: 7
Training loss: 3.2604159191646676
Validation loss: 2.786690477452109

Epoch: 6| Step: 8
Training loss: 2.724191678752027
Validation loss: 2.7764601037807832

Epoch: 6| Step: 9
Training loss: 3.1308343973192674
Validation loss: 2.7752575372448245

Epoch: 6| Step: 10
Training loss: 2.8775447695486576
Validation loss: 2.7744347699254055

Epoch: 6| Step: 11
Training loss: 3.1261136931515727
Validation loss: 2.7794422516371675

Epoch: 6| Step: 12
Training loss: 3.612828439743849
Validation loss: 2.7721832531283126

Epoch: 6| Step: 13
Training loss: 2.819556898516749
Validation loss: 2.7740308622259664

Epoch: 286| Step: 0
Training loss: 3.1168137711132613
Validation loss: 2.771367559036714

Epoch: 6| Step: 1
Training loss: 2.9058624337302428
Validation loss: 2.768780494595528

Epoch: 6| Step: 2
Training loss: 3.3340151248490413
Validation loss: 2.770918719369831

Epoch: 6| Step: 3
Training loss: 2.8433674984750525
Validation loss: 2.7669461330310594

Epoch: 6| Step: 4
Training loss: 2.754684619609952
Validation loss: 2.771166942743717

Epoch: 6| Step: 5
Training loss: 3.564153722442699
Validation loss: 2.772000156794713

Epoch: 6| Step: 6
Training loss: 3.0450673536546704
Validation loss: 2.7695427568391215

Epoch: 6| Step: 7
Training loss: 3.755420962736513
Validation loss: 2.771448993281407

Epoch: 6| Step: 8
Training loss: 3.02887341646587
Validation loss: 2.7684794149926897

Epoch: 6| Step: 9
Training loss: 3.2103342199579483
Validation loss: 2.770565335191312

Epoch: 6| Step: 10
Training loss: 2.1036331583125887
Validation loss: 2.7789259331920584

Epoch: 6| Step: 11
Training loss: 3.274027404800958
Validation loss: 2.7822744398451076

Epoch: 6| Step: 12
Training loss: 3.1306190327080845
Validation loss: 2.778857636585145

Epoch: 6| Step: 13
Training loss: 2.4823944066266486
Validation loss: 2.772588462806399

Epoch: 287| Step: 0
Training loss: 3.3092269561765253
Validation loss: 2.7691840710601467

Epoch: 6| Step: 1
Training loss: 2.806376424205844
Validation loss: 2.7786993978079995

Epoch: 6| Step: 2
Training loss: 2.619629588842525
Validation loss: 2.7719006335964393

Epoch: 6| Step: 3
Training loss: 3.0110804652038325
Validation loss: 2.7702066457769186

Epoch: 6| Step: 4
Training loss: 3.0308560774163658
Validation loss: 2.767771393699153

Epoch: 6| Step: 5
Training loss: 2.5882456640300986
Validation loss: 2.765103670547448

Epoch: 6| Step: 6
Training loss: 2.8853553370672698
Validation loss: 2.7666511502098303

Epoch: 6| Step: 7
Training loss: 3.4916724181450305
Validation loss: 2.765412343018594

Epoch: 6| Step: 8
Training loss: 3.426967645951582
Validation loss: 2.771161033120017

Epoch: 6| Step: 9
Training loss: 3.3297848569545025
Validation loss: 2.7705412750933958

Epoch: 6| Step: 10
Training loss: 3.1257494218574506
Validation loss: 2.772863776743577

Epoch: 6| Step: 11
Training loss: 2.682014900422148
Validation loss: 2.7713170085482424

Epoch: 6| Step: 12
Training loss: 3.169736394902798
Validation loss: 2.7662087156983657

Epoch: 6| Step: 13
Training loss: 3.714873401030128
Validation loss: 2.7693684366634015

Epoch: 288| Step: 0
Training loss: 2.807562074866687
Validation loss: 2.766231970126015

Epoch: 6| Step: 1
Training loss: 3.065023511388813
Validation loss: 2.7835751426320092

Epoch: 6| Step: 2
Training loss: 3.768881375124877
Validation loss: 2.772624880359276

Epoch: 6| Step: 3
Training loss: 2.8651335216785094
Validation loss: 2.778859692030213

Epoch: 6| Step: 4
Training loss: 2.573723752673959
Validation loss: 2.7767374813976478

Epoch: 6| Step: 5
Training loss: 3.1116729372843683
Validation loss: 2.768495438629686

Epoch: 6| Step: 6
Training loss: 3.0340028827329153
Validation loss: 2.776446084543127

Epoch: 6| Step: 7
Training loss: 3.2728878461093727
Validation loss: 2.7720998761769464

Epoch: 6| Step: 8
Training loss: 3.3627668423757306
Validation loss: 2.771342205278164

Epoch: 6| Step: 9
Training loss: 3.0067737717875405
Validation loss: 2.7674481159195548

Epoch: 6| Step: 10
Training loss: 2.943931033000432
Validation loss: 2.769387970992305

Epoch: 6| Step: 11
Training loss: 3.2717735413247797
Validation loss: 2.7639019729926497

Epoch: 6| Step: 12
Training loss: 3.114223820957486
Validation loss: 2.769833841473915

Epoch: 6| Step: 13
Training loss: 2.4280414463823186
Validation loss: 2.76810486568979

Epoch: 289| Step: 0
Training loss: 2.623032786430193
Validation loss: 2.768138861142827

Epoch: 6| Step: 1
Training loss: 2.3741366172309064
Validation loss: 2.7674564336526104

Epoch: 6| Step: 2
Training loss: 2.891016588235382
Validation loss: 2.776569645854724

Epoch: 6| Step: 3
Training loss: 2.5841812670050346
Validation loss: 2.776930443588698

Epoch: 6| Step: 4
Training loss: 2.6278396868878646
Validation loss: 2.77256242302892

Epoch: 6| Step: 5
Training loss: 3.467958652166252
Validation loss: 2.781004686218949

Epoch: 6| Step: 6
Training loss: 3.2702624233766047
Validation loss: 2.7910268173051342

Epoch: 6| Step: 7
Training loss: 3.69127384331815
Validation loss: 2.802639748444162

Epoch: 6| Step: 8
Training loss: 3.5365512182128747
Validation loss: 2.781141328088495

Epoch: 6| Step: 9
Training loss: 3.631294179309494
Validation loss: 2.7748960535945684

Epoch: 6| Step: 10
Training loss: 2.8102458821845038
Validation loss: 2.766286848762253

Epoch: 6| Step: 11
Training loss: 3.032488383171052
Validation loss: 2.76819836398889

Epoch: 6| Step: 12
Training loss: 2.9106081208535635
Validation loss: 2.7636080938128087

Epoch: 6| Step: 13
Training loss: 3.4005942330268266
Validation loss: 2.7633654638022316

Epoch: 290| Step: 0
Training loss: 3.483624433068787
Validation loss: 2.7639863967563136

Epoch: 6| Step: 1
Training loss: 3.4915174144325336
Validation loss: 2.7647803919308274

Epoch: 6| Step: 2
Training loss: 3.382716646664496
Validation loss: 2.7661831830532457

Epoch: 6| Step: 3
Training loss: 3.3487316349518434
Validation loss: 2.7622172418678153

Epoch: 6| Step: 4
Training loss: 2.4402127942333505
Validation loss: 2.7641161661344302

Epoch: 6| Step: 5
Training loss: 2.287035151709796
Validation loss: 2.761928321055541

Epoch: 6| Step: 6
Training loss: 3.3502262893087082
Validation loss: 2.76362384235659

Epoch: 6| Step: 7
Training loss: 3.3827045238432936
Validation loss: 2.763035947183414

Epoch: 6| Step: 8
Training loss: 3.3077214159563333
Validation loss: 2.7624227047219447

Epoch: 6| Step: 9
Training loss: 3.537552467199733
Validation loss: 2.7636431742508822

Epoch: 6| Step: 10
Training loss: 3.028942055400794
Validation loss: 2.761974487819273

Epoch: 6| Step: 11
Training loss: 2.525028164394914
Validation loss: 2.7620138317110308

Epoch: 6| Step: 12
Training loss: 2.5773201350771924
Validation loss: 2.759815166473361

Epoch: 6| Step: 13
Training loss: 1.9651311887866025
Validation loss: 2.7608342850665166

Epoch: 291| Step: 0
Training loss: 2.7518501993483078
Validation loss: 2.758292584151868

Epoch: 6| Step: 1
Training loss: 3.5429178757889606
Validation loss: 2.764001604261052

Epoch: 6| Step: 2
Training loss: 3.0440570026328877
Validation loss: 2.7810009085171306

Epoch: 6| Step: 3
Training loss: 3.2570952213599558
Validation loss: 2.7876790729754126

Epoch: 6| Step: 4
Training loss: 3.463725945104567
Validation loss: 2.792829021478466

Epoch: 6| Step: 5
Training loss: 2.6605128470779
Validation loss: 2.795488570408952

Epoch: 6| Step: 6
Training loss: 3.21090482894723
Validation loss: 2.794585457175447

Epoch: 6| Step: 7
Training loss: 3.177188275381117
Validation loss: 2.802566415010881

Epoch: 6| Step: 8
Training loss: 3.5836195424833472
Validation loss: 2.8236043666266637

Epoch: 6| Step: 9
Training loss: 3.2472067346811766
Validation loss: 2.7971273732195043

Epoch: 6| Step: 10
Training loss: 2.699445921948143
Validation loss: 2.7838357720118956

Epoch: 6| Step: 11
Training loss: 2.8443406717755697
Validation loss: 2.7880466065968426

Epoch: 6| Step: 12
Training loss: 2.4247430370296517
Validation loss: 2.788536652071519

Epoch: 6| Step: 13
Training loss: 2.8119151884939053
Validation loss: 2.778746596009395

Epoch: 292| Step: 0
Training loss: 2.5534834051061677
Validation loss: 2.770087152216727

Epoch: 6| Step: 1
Training loss: 2.88586760117706
Validation loss: 2.7639747564104122

Epoch: 6| Step: 2
Training loss: 3.5311936905683976
Validation loss: 2.7574451713989396

Epoch: 6| Step: 3
Training loss: 3.485587691636994
Validation loss: 2.7537809465769034

Epoch: 6| Step: 4
Training loss: 2.8735384335819245
Validation loss: 2.7546436410299426

Epoch: 6| Step: 5
Training loss: 3.2726414698132467
Validation loss: 2.7565615486866846

Epoch: 6| Step: 6
Training loss: 2.5073031564810337
Validation loss: 2.7576759674327183

Epoch: 6| Step: 7
Training loss: 3.0674440607941125
Validation loss: 2.7556755475721584

Epoch: 6| Step: 8
Training loss: 3.6347097385379827
Validation loss: 2.7571154948846117

Epoch: 6| Step: 9
Training loss: 2.9268459526997592
Validation loss: 2.757965284450338

Epoch: 6| Step: 10
Training loss: 3.05363504762592
Validation loss: 2.7557433581787403

Epoch: 6| Step: 11
Training loss: 2.6705092123844425
Validation loss: 2.754670134972593

Epoch: 6| Step: 12
Training loss: 2.87668792268835
Validation loss: 2.7549010294865535

Epoch: 6| Step: 13
Training loss: 3.6165541553722425
Validation loss: 2.754057479728734

Epoch: 293| Step: 0
Training loss: 2.390789450181441
Validation loss: 2.7589898484865985

Epoch: 6| Step: 1
Training loss: 3.0315098601968464
Validation loss: 2.7625886519712237

Epoch: 6| Step: 2
Training loss: 2.521869940203161
Validation loss: 2.7847066674991314

Epoch: 6| Step: 3
Training loss: 3.224221772917395
Validation loss: 2.788972722588823

Epoch: 6| Step: 4
Training loss: 3.0446268248245802
Validation loss: 2.8149947319461592

Epoch: 6| Step: 5
Training loss: 3.7115056616868305
Validation loss: 2.803984993109202

Epoch: 6| Step: 6
Training loss: 4.005818664849818
Validation loss: 2.7786117074773395

Epoch: 6| Step: 7
Training loss: 1.961998944798457
Validation loss: 2.763001558631844

Epoch: 6| Step: 8
Training loss: 3.358203488498875
Validation loss: 2.753669640517632

Epoch: 6| Step: 9
Training loss: 2.9172592832604103
Validation loss: 2.7572920187634606

Epoch: 6| Step: 10
Training loss: 3.0504761371113753
Validation loss: 2.754714186125596

Epoch: 6| Step: 11
Training loss: 2.865000376543217
Validation loss: 2.753711512433892

Epoch: 6| Step: 12
Training loss: 3.0849511996819245
Validation loss: 2.755779560178372

Epoch: 6| Step: 13
Training loss: 3.364317057714915
Validation loss: 2.760406977674615

Epoch: 294| Step: 0
Training loss: 2.8053892315032463
Validation loss: 2.7596167369859916

Epoch: 6| Step: 1
Training loss: 3.172390900547867
Validation loss: 2.7621573540116335

Epoch: 6| Step: 2
Training loss: 2.631713909653632
Validation loss: 2.7629856803533395

Epoch: 6| Step: 3
Training loss: 2.8331843692290737
Validation loss: 2.755625086935989

Epoch: 6| Step: 4
Training loss: 2.763250851322403
Validation loss: 2.749910796910384

Epoch: 6| Step: 5
Training loss: 2.9520022563977393
Validation loss: 2.750146071431748

Epoch: 6| Step: 6
Training loss: 3.164363441755089
Validation loss: 2.7502883627568315

Epoch: 6| Step: 7
Training loss: 3.2192415028826025
Validation loss: 2.751725152600092

Epoch: 6| Step: 8
Training loss: 3.4123536466298403
Validation loss: 2.755842664852607

Epoch: 6| Step: 9
Training loss: 3.374749916136003
Validation loss: 2.7558381558955163

Epoch: 6| Step: 10
Training loss: 3.2966171091467156
Validation loss: 2.750466740620538

Epoch: 6| Step: 11
Training loss: 3.692053230546648
Validation loss: 2.754912319193199

Epoch: 6| Step: 12
Training loss: 2.9129053840606045
Validation loss: 2.7489442448789947

Epoch: 6| Step: 13
Training loss: 2.296357180814841
Validation loss: 2.751173274393479

Epoch: 295| Step: 0
Training loss: 3.190607089927389
Validation loss: 2.7520065556865676

Epoch: 6| Step: 1
Training loss: 2.5493717242400122
Validation loss: 2.758984978569286

Epoch: 6| Step: 2
Training loss: 2.871031302467128
Validation loss: 2.748831352421514

Epoch: 6| Step: 3
Training loss: 3.1420046684381004
Validation loss: 2.752975243426396

Epoch: 6| Step: 4
Training loss: 3.4244890374837937
Validation loss: 2.7595556091417293

Epoch: 6| Step: 5
Training loss: 2.7392660810648377
Validation loss: 2.76519265331541

Epoch: 6| Step: 6
Training loss: 3.3299551216744234
Validation loss: 2.7588333898481108

Epoch: 6| Step: 7
Training loss: 2.3901404594103774
Validation loss: 2.75777685828006

Epoch: 6| Step: 8
Training loss: 2.711393466388
Validation loss: 2.757729845941513

Epoch: 6| Step: 9
Training loss: 3.461454813508961
Validation loss: 2.752637161751141

Epoch: 6| Step: 10
Training loss: 3.063454615447763
Validation loss: 2.753084662105859

Epoch: 6| Step: 11
Training loss: 3.0664140251692826
Validation loss: 2.7592778227002714

Epoch: 6| Step: 12
Training loss: 3.2625699149054257
Validation loss: 2.754290670646139

Epoch: 6| Step: 13
Training loss: 3.6578683776367944
Validation loss: 2.756542976245963

Epoch: 296| Step: 0
Training loss: 3.3343064477196283
Validation loss: 2.7625803112300864

Epoch: 6| Step: 1
Training loss: 2.117225449563311
Validation loss: 2.7542999486526645

Epoch: 6| Step: 2
Training loss: 3.3590539113448727
Validation loss: 2.7575404674920305

Epoch: 6| Step: 3
Training loss: 3.1490677801392484
Validation loss: 2.7584845057561833

Epoch: 6| Step: 4
Training loss: 2.300072552739102
Validation loss: 2.7525967562072573

Epoch: 6| Step: 5
Training loss: 3.056466055568151
Validation loss: 2.747716481382771

Epoch: 6| Step: 6
Training loss: 3.2764738653925787
Validation loss: 2.7484045080142017

Epoch: 6| Step: 7
Training loss: 3.120509621740885
Validation loss: 2.7494420299358455

Epoch: 6| Step: 8
Training loss: 3.6972186795421593
Validation loss: 2.7449264177286294

Epoch: 6| Step: 9
Training loss: 3.120510385778106
Validation loss: 2.7456700794297295

Epoch: 6| Step: 10
Training loss: 2.837748472115034
Validation loss: 2.749332453231493

Epoch: 6| Step: 11
Training loss: 2.7879592893465923
Validation loss: 2.7466980416247924

Epoch: 6| Step: 12
Training loss: 3.0948145412411603
Validation loss: 2.749792346590865

Epoch: 6| Step: 13
Training loss: 3.340836441014488
Validation loss: 2.7412375958720285

Epoch: 297| Step: 0
Training loss: 2.8790149021220133
Validation loss: 2.7454673183171674

Epoch: 6| Step: 1
Training loss: 3.0630045883836794
Validation loss: 2.7459124207087084

Epoch: 6| Step: 2
Training loss: 3.4020970777400206
Validation loss: 2.7460003878414794

Epoch: 6| Step: 3
Training loss: 3.2118987711991585
Validation loss: 2.7421988186764645

Epoch: 6| Step: 4
Training loss: 3.597333630604469
Validation loss: 2.7458336014520066

Epoch: 6| Step: 5
Training loss: 2.831933255308891
Validation loss: 2.7602099207520996

Epoch: 6| Step: 6
Training loss: 2.6439646532290126
Validation loss: 2.752244503223555

Epoch: 6| Step: 7
Training loss: 3.257516239152131
Validation loss: 2.7536071759237752

Epoch: 6| Step: 8
Training loss: 2.8712844058720997
Validation loss: 2.7504572595397074

Epoch: 6| Step: 9
Training loss: 2.543222628575992
Validation loss: 2.745431676940591

Epoch: 6| Step: 10
Training loss: 3.506560444135601
Validation loss: 2.754818392301374

Epoch: 6| Step: 11
Training loss: 3.024140663094742
Validation loss: 2.7548389706356105

Epoch: 6| Step: 12
Training loss: 2.696901510910623
Validation loss: 2.7515362450641083

Epoch: 6| Step: 13
Training loss: 3.022346398273975
Validation loss: 2.7533925721458226

Epoch: 298| Step: 0
Training loss: 3.5066201407340043
Validation loss: 2.750063867470564

Epoch: 6| Step: 1
Training loss: 2.872477378390938
Validation loss: 2.7598992173655383

Epoch: 6| Step: 2
Training loss: 3.041372485283294
Validation loss: 2.7568352567974777

Epoch: 6| Step: 3
Training loss: 2.422233308928118
Validation loss: 2.7500975997959762

Epoch: 6| Step: 4
Training loss: 2.728550227388858
Validation loss: 2.753198721016232

Epoch: 6| Step: 5
Training loss: 3.218896658806126
Validation loss: 2.742120296558239

Epoch: 6| Step: 6
Training loss: 3.386163967499938
Validation loss: 2.7362845592311693

Epoch: 6| Step: 7
Training loss: 3.0802512014427097
Validation loss: 2.738477591297552

Epoch: 6| Step: 8
Training loss: 3.7299442581634312
Validation loss: 2.738183355884807

Epoch: 6| Step: 9
Training loss: 2.208436879543478
Validation loss: 2.735885783101695

Epoch: 6| Step: 10
Training loss: 3.3786359910433004
Validation loss: 2.7339798649133784

Epoch: 6| Step: 11
Training loss: 3.4213175559072817
Validation loss: 2.7386819819718005

Epoch: 6| Step: 12
Training loss: 2.4903417945581574
Validation loss: 2.736001471643029

Epoch: 6| Step: 13
Training loss: 2.8132080882187918
Validation loss: 2.736402411936621

Epoch: 299| Step: 0
Training loss: 2.6804554898082187
Validation loss: 2.7350512243544096

Epoch: 6| Step: 1
Training loss: 3.757388402280342
Validation loss: 2.7381162376773034

Epoch: 6| Step: 2
Training loss: 3.5280852863789827
Validation loss: 2.7394446029794084

Epoch: 6| Step: 3
Training loss: 2.7766667008905612
Validation loss: 2.7343967719317317

Epoch: 6| Step: 4
Training loss: 2.4670547266017127
Validation loss: 2.7336554592832076

Epoch: 6| Step: 5
Training loss: 3.1800111048282607
Validation loss: 2.7383658785290277

Epoch: 6| Step: 6
Training loss: 3.239569431941553
Validation loss: 2.7380050841276287

Epoch: 6| Step: 7
Training loss: 2.354657642400491
Validation loss: 2.7380792937326923

Epoch: 6| Step: 8
Training loss: 2.7051931418745263
Validation loss: 2.7423473351655723

Epoch: 6| Step: 9
Training loss: 2.38071787337787
Validation loss: 2.736653232089087

Epoch: 6| Step: 10
Training loss: 3.6051685212384066
Validation loss: 2.7356314158368207

Epoch: 6| Step: 11
Training loss: 2.944902224512467
Validation loss: 2.7527058788716743

Epoch: 6| Step: 12
Training loss: 3.4935439374887016
Validation loss: 2.752176888652212

Epoch: 6| Step: 13
Training loss: 3.1916805602353104
Validation loss: 2.7572086805792915

Epoch: 300| Step: 0
Training loss: 3.2750819771094446
Validation loss: 2.761027473827608

Epoch: 6| Step: 1
Training loss: 2.8998246896305337
Validation loss: 2.764835547876999

Epoch: 6| Step: 2
Training loss: 2.907886003634227
Validation loss: 2.7699348549834277

Epoch: 6| Step: 3
Training loss: 3.193075502243081
Validation loss: 2.7678437081189506

Epoch: 6| Step: 4
Training loss: 2.5439475617792358
Validation loss: 2.7771000625193487

Epoch: 6| Step: 5
Training loss: 2.8509571007612267
Validation loss: 2.7625606990677576

Epoch: 6| Step: 6
Training loss: 3.2485101659591344
Validation loss: 2.777835494402336

Epoch: 6| Step: 7
Training loss: 2.8750809367853294
Validation loss: 2.7802549128069773

Epoch: 6| Step: 8
Training loss: 3.157602303751184
Validation loss: 2.7558985699122642

Epoch: 6| Step: 9
Training loss: 3.030662243677759
Validation loss: 2.746838344428469

Epoch: 6| Step: 10
Training loss: 2.853795846578335
Validation loss: 2.741953683668487

Epoch: 6| Step: 11
Training loss: 3.3348346825936503
Validation loss: 2.7353090196392325

Epoch: 6| Step: 12
Training loss: 3.1785669250211455
Validation loss: 2.730718304192522

Epoch: 6| Step: 13
Training loss: 3.4965683598937627
Validation loss: 2.733709834655379

Epoch: 301| Step: 0
Training loss: 3.2701580217075867
Validation loss: 2.7309705156529303

Epoch: 6| Step: 1
Training loss: 3.468330701625057
Validation loss: 2.73716901642904

Epoch: 6| Step: 2
Training loss: 2.7272440323620555
Validation loss: 2.7397680508461018

Epoch: 6| Step: 3
Training loss: 2.940541093300129
Validation loss: 2.732127229977855

Epoch: 6| Step: 4
Training loss: 2.8202672727556535
Validation loss: 2.7344569733926423

Epoch: 6| Step: 5
Training loss: 2.9952270368264626
Validation loss: 2.727154982682935

Epoch: 6| Step: 6
Training loss: 3.0208077440603045
Validation loss: 2.734705424934014

Epoch: 6| Step: 7
Training loss: 3.269446222619375
Validation loss: 2.7311369500112628

Epoch: 6| Step: 8
Training loss: 2.810640186407056
Validation loss: 2.73231572908289

Epoch: 6| Step: 9
Training loss: 3.4818838477309026
Validation loss: 2.7324367233902986

Epoch: 6| Step: 10
Training loss: 3.2646683017081877
Validation loss: 2.739352809178653

Epoch: 6| Step: 11
Training loss: 2.7288499216403284
Validation loss: 2.7344250539953543

Epoch: 6| Step: 12
Training loss: 2.773173574865188
Validation loss: 2.7433985017605655

Epoch: 6| Step: 13
Training loss: 3.017361630077681
Validation loss: 2.7388993586205377

Epoch: 302| Step: 0
Training loss: 3.393468271156905
Validation loss: 2.7349421715431066

Epoch: 6| Step: 1
Training loss: 2.1013248124837376
Validation loss: 2.72646162567707

Epoch: 6| Step: 2
Training loss: 3.281178500895117
Validation loss: 2.7275463073149493

Epoch: 6| Step: 3
Training loss: 2.5368909734470706
Validation loss: 2.7255930341918146

Epoch: 6| Step: 4
Training loss: 3.5457802313934828
Validation loss: 2.7271989706605853

Epoch: 6| Step: 5
Training loss: 3.0416142359007625
Validation loss: 2.729535879526221

Epoch: 6| Step: 6
Training loss: 2.9324371861903793
Validation loss: 2.7274093368270704

Epoch: 6| Step: 7
Training loss: 3.073383222603943
Validation loss: 2.734711683321167

Epoch: 6| Step: 8
Training loss: 2.3014569933625446
Validation loss: 2.732330807924083

Epoch: 6| Step: 9
Training loss: 3.0012514365247207
Validation loss: 2.7277361619783096

Epoch: 6| Step: 10
Training loss: 3.1501534379191884
Validation loss: 2.7274989393362707

Epoch: 6| Step: 11
Training loss: 3.246138405980443
Validation loss: 2.726048420697981

Epoch: 6| Step: 12
Training loss: 3.482468977527777
Validation loss: 2.7283525872360337

Epoch: 6| Step: 13
Training loss: 3.3055757812251656
Validation loss: 2.7310538936789666

Epoch: 303| Step: 0
Training loss: 2.895916358983377
Validation loss: 2.724737194160933

Epoch: 6| Step: 1
Training loss: 2.8665742556144713
Validation loss: 2.728330344235337

Epoch: 6| Step: 2
Training loss: 3.502096229603608
Validation loss: 2.731741338354179

Epoch: 6| Step: 3
Training loss: 2.995589351843869
Validation loss: 2.7292217104114966

Epoch: 6| Step: 4
Training loss: 2.9816121199344883
Validation loss: 2.7255265785222687

Epoch: 6| Step: 5
Training loss: 3.321833865609912
Validation loss: 2.7231120155940345

Epoch: 6| Step: 6
Training loss: 2.695918272194612
Validation loss: 2.723965083532915

Epoch: 6| Step: 7
Training loss: 2.496384103808947
Validation loss: 2.7243781584565046

Epoch: 6| Step: 8
Training loss: 3.287486806632717
Validation loss: 2.7258803411057206

Epoch: 6| Step: 9
Training loss: 3.3151066438716112
Validation loss: 2.7270560282907006

Epoch: 6| Step: 10
Training loss: 3.1652624798209246
Validation loss: 2.7299746479232203

Epoch: 6| Step: 11
Training loss: 2.7401934815752127
Validation loss: 2.7229055711665913

Epoch: 6| Step: 12
Training loss: 3.363274728234821
Validation loss: 2.7225730794900542

Epoch: 6| Step: 13
Training loss: 2.5900851176057653
Validation loss: 2.729038678584026

Epoch: 304| Step: 0
Training loss: 3.66179269464089
Validation loss: 2.727253534921316

Epoch: 6| Step: 1
Training loss: 3.318928077647168
Validation loss: 2.728205241831343

Epoch: 6| Step: 2
Training loss: 2.7455093825580628
Validation loss: 2.729340008044437

Epoch: 6| Step: 3
Training loss: 2.882981540923843
Validation loss: 2.7456969167264673

Epoch: 6| Step: 4
Training loss: 2.8127161578718565
Validation loss: 2.7398047661648373

Epoch: 6| Step: 5
Training loss: 3.1076989952445437
Validation loss: 2.737609924231115

Epoch: 6| Step: 6
Training loss: 2.514874743305881
Validation loss: 2.7490972573523926

Epoch: 6| Step: 7
Training loss: 3.203311672818893
Validation loss: 2.7458034650131156

Epoch: 6| Step: 8
Training loss: 2.8465607554486607
Validation loss: 2.746771570240962

Epoch: 6| Step: 9
Training loss: 3.216762039931678
Validation loss: 2.74474372237367

Epoch: 6| Step: 10
Training loss: 3.478528236396285
Validation loss: 2.7547508176397724

Epoch: 6| Step: 11
Training loss: 2.2787342570269025
Validation loss: 2.750606664785166

Epoch: 6| Step: 12
Training loss: 3.5132644527373915
Validation loss: 2.7346019457321886

Epoch: 6| Step: 13
Training loss: 2.4236286336367994
Validation loss: 2.731887395563583

Epoch: 305| Step: 0
Training loss: 2.6369758989189664
Validation loss: 2.730594255684602

Epoch: 6| Step: 1
Training loss: 3.423712946624081
Validation loss: 2.7328237382175806

Epoch: 6| Step: 2
Training loss: 3.8345890199955597
Validation loss: 2.7281751390078495

Epoch: 6| Step: 3
Training loss: 3.108736365594787
Validation loss: 2.7250348598707435

Epoch: 6| Step: 4
Training loss: 3.3191938602739186
Validation loss: 2.7251624238926655

Epoch: 6| Step: 5
Training loss: 3.0560749152023585
Validation loss: 2.7255252372209307

Epoch: 6| Step: 6
Training loss: 2.700705884566637
Validation loss: 2.732915991461784

Epoch: 6| Step: 7
Training loss: 2.425294492478004
Validation loss: 2.723021242529521

Epoch: 6| Step: 8
Training loss: 2.595126694396064
Validation loss: 2.726630989509925

Epoch: 6| Step: 9
Training loss: 2.6881074440690376
Validation loss: 2.726743755620787

Epoch: 6| Step: 10
Training loss: 3.136286685587645
Validation loss: 2.728254867774362

Epoch: 6| Step: 11
Training loss: 3.298330988896793
Validation loss: 2.7358716730827486

Epoch: 6| Step: 12
Training loss: 2.767272544686983
Validation loss: 2.7377075026765905

Epoch: 6| Step: 13
Training loss: 3.4197185811043274
Validation loss: 2.7274142321056294

Epoch: 306| Step: 0
Training loss: 2.7395444995366303
Validation loss: 2.7213134260150915

Epoch: 6| Step: 1
Training loss: 3.592362509202262
Validation loss: 2.7237635086576124

Epoch: 6| Step: 2
Training loss: 2.4739710971436093
Validation loss: 2.728930430147824

Epoch: 6| Step: 3
Training loss: 3.114690942510733
Validation loss: 2.7216651444824937

Epoch: 6| Step: 4
Training loss: 3.8046709565541255
Validation loss: 2.723107395013301

Epoch: 6| Step: 5
Training loss: 3.0123725705875626
Validation loss: 2.7260654028168783

Epoch: 6| Step: 6
Training loss: 3.2093637141221505
Validation loss: 2.721267085687157

Epoch: 6| Step: 7
Training loss: 3.0080364986092394
Validation loss: 2.721892455314546

Epoch: 6| Step: 8
Training loss: 3.11807230770498
Validation loss: 2.7208838758532607

Epoch: 6| Step: 9
Training loss: 2.2409950833894383
Validation loss: 2.721308893760464

Epoch: 6| Step: 10
Training loss: 3.057211065231756
Validation loss: 2.7215192413937928

Epoch: 6| Step: 11
Training loss: 3.376562816332123
Validation loss: 2.723365440745204

Epoch: 6| Step: 12
Training loss: 2.8696032749009515
Validation loss: 2.724500374714765

Epoch: 6| Step: 13
Training loss: 2.1358774819972766
Validation loss: 2.724863279957672

Epoch: 307| Step: 0
Training loss: 2.806777133157106
Validation loss: 2.7219967915833716

Epoch: 6| Step: 1
Training loss: 3.1585976207406565
Validation loss: 2.717890862888249

Epoch: 6| Step: 2
Training loss: 2.786605650433048
Validation loss: 2.7307564104472726

Epoch: 6| Step: 3
Training loss: 2.7368147075011455
Validation loss: 2.721325634143769

Epoch: 6| Step: 4
Training loss: 3.1415792505327524
Validation loss: 2.7463773076517097

Epoch: 6| Step: 5
Training loss: 3.3288771088440816
Validation loss: 2.7617051599878932

Epoch: 6| Step: 6
Training loss: 3.63548315182348
Validation loss: 2.7848757865660456

Epoch: 6| Step: 7
Training loss: 3.241223589535415
Validation loss: 2.769905363010506

Epoch: 6| Step: 8
Training loss: 2.9749245129152344
Validation loss: 2.7609841715123085

Epoch: 6| Step: 9
Training loss: 2.717921163565084
Validation loss: 2.7391595901480756

Epoch: 6| Step: 10
Training loss: 2.670630449592571
Validation loss: 2.74225906294117

Epoch: 6| Step: 11
Training loss: 3.310171496509465
Validation loss: 2.723638354620302

Epoch: 6| Step: 12
Training loss: 2.693794685577287
Validation loss: 2.7228560962918755

Epoch: 6| Step: 13
Training loss: 3.365838083589858
Validation loss: 2.720997847749463

Epoch: 308| Step: 0
Training loss: 2.9845790293987946
Validation loss: 2.7184192285112205

Epoch: 6| Step: 1
Training loss: 3.6906247881082574
Validation loss: 2.7196055192950426

Epoch: 6| Step: 2
Training loss: 3.007577228014387
Validation loss: 2.7219767090060905

Epoch: 6| Step: 3
Training loss: 2.0133983526194132
Validation loss: 2.7155835405320032

Epoch: 6| Step: 4
Training loss: 2.3933209943674663
Validation loss: 2.7188100943726616

Epoch: 6| Step: 5
Training loss: 3.235026860545697
Validation loss: 2.721392385515967

Epoch: 6| Step: 6
Training loss: 3.0515535869165467
Validation loss: 2.7211961436072047

Epoch: 6| Step: 7
Training loss: 2.9611629510969535
Validation loss: 2.718327341499449

Epoch: 6| Step: 8
Training loss: 3.296822353141556
Validation loss: 2.7194058555178953

Epoch: 6| Step: 9
Training loss: 3.018323886406486
Validation loss: 2.717266772464084

Epoch: 6| Step: 10
Training loss: 3.0537045353406667
Validation loss: 2.720088700347796

Epoch: 6| Step: 11
Training loss: 3.606295241893556
Validation loss: 2.7180749104304094

Epoch: 6| Step: 12
Training loss: 3.1784170551071944
Validation loss: 2.720013133742059

Epoch: 6| Step: 13
Training loss: 2.362592309833703
Validation loss: 2.713965011267283

Epoch: 309| Step: 0
Training loss: 3.247755449334078
Validation loss: 2.717416256289354

Epoch: 6| Step: 1
Training loss: 3.08886703312717
Validation loss: 2.720804323062074

Epoch: 6| Step: 2
Training loss: 3.072252277168239
Validation loss: 2.7200292892646507

Epoch: 6| Step: 3
Training loss: 3.1462243112963493
Validation loss: 2.7184499203238053

Epoch: 6| Step: 4
Training loss: 3.2558485373057477
Validation loss: 2.714652491274654

Epoch: 6| Step: 5
Training loss: 2.964836351790012
Validation loss: 2.712856229222107

Epoch: 6| Step: 6
Training loss: 3.065302597964815
Validation loss: 2.7229706701002607

Epoch: 6| Step: 7
Training loss: 1.7914585909410914
Validation loss: 2.710598240111563

Epoch: 6| Step: 8
Training loss: 2.902159735081735
Validation loss: 2.718645055374605

Epoch: 6| Step: 9
Training loss: 2.4692005760326916
Validation loss: 2.727349000481364

Epoch: 6| Step: 10
Training loss: 2.7689366744857153
Validation loss: 2.725763116002882

Epoch: 6| Step: 11
Training loss: 3.4421086714865994
Validation loss: 2.7153981137751964

Epoch: 6| Step: 12
Training loss: 3.4746538387753687
Validation loss: 2.7184954599412303

Epoch: 6| Step: 13
Training loss: 3.657282104885314
Validation loss: 2.7229084936095678

Epoch: 310| Step: 0
Training loss: 3.4061385670204523
Validation loss: 2.7267317579073773

Epoch: 6| Step: 1
Training loss: 2.7375206863806194
Validation loss: 2.7180756046126264

Epoch: 6| Step: 2
Training loss: 2.921940930280561
Validation loss: 2.7233629009811473

Epoch: 6| Step: 3
Training loss: 2.877237030129994
Validation loss: 2.720703558444791

Epoch: 6| Step: 4
Training loss: 3.595296377770037
Validation loss: 2.7163269019110787

Epoch: 6| Step: 5
Training loss: 3.0518879659745624
Validation loss: 2.7112965530577986

Epoch: 6| Step: 6
Training loss: 3.2335407452733254
Validation loss: 2.7173047767745047

Epoch: 6| Step: 7
Training loss: 2.7839423017880702
Validation loss: 2.71630124581788

Epoch: 6| Step: 8
Training loss: 2.9161591951218893
Validation loss: 2.7234225236238303

Epoch: 6| Step: 9
Training loss: 2.846077270627644
Validation loss: 2.7242136506421266

Epoch: 6| Step: 10
Training loss: 2.936606088533814
Validation loss: 2.720008801018352

Epoch: 6| Step: 11
Training loss: 3.1385372681349
Validation loss: 2.720104238098017

Epoch: 6| Step: 12
Training loss: 2.9526453991133566
Validation loss: 2.720039566317472

Epoch: 6| Step: 13
Training loss: 2.9027726894822816
Validation loss: 2.718084998691497

Epoch: 311| Step: 0
Training loss: 2.1024736322479995
Validation loss: 2.7347271539252516

Epoch: 6| Step: 1
Training loss: 3.283490097511942
Validation loss: 2.729522520936485

Epoch: 6| Step: 2
Training loss: 2.9999014520353544
Validation loss: 2.732894818415443

Epoch: 6| Step: 3
Training loss: 2.8318611883206763
Validation loss: 2.727284823854157

Epoch: 6| Step: 4
Training loss: 3.7336118548812967
Validation loss: 2.7185751906279845

Epoch: 6| Step: 5
Training loss: 2.8666545985951086
Validation loss: 2.715115198632073

Epoch: 6| Step: 6
Training loss: 2.7449345319268015
Validation loss: 2.7121347481907128

Epoch: 6| Step: 7
Training loss: 3.084412944216325
Validation loss: 2.7062785593127923

Epoch: 6| Step: 8
Training loss: 2.696246441452798
Validation loss: 2.7098747010142477

Epoch: 6| Step: 9
Training loss: 2.311484242644042
Validation loss: 2.70988537228603

Epoch: 6| Step: 10
Training loss: 3.6779353349735597
Validation loss: 2.710482003594479

Epoch: 6| Step: 11
Training loss: 3.393370189454104
Validation loss: 2.7125770136390797

Epoch: 6| Step: 12
Training loss: 2.93946058709601
Validation loss: 2.7112287077886554

Epoch: 6| Step: 13
Training loss: 3.6230091021026234
Validation loss: 2.712355724051593

Epoch: 312| Step: 0
Training loss: 2.6044305794820226
Validation loss: 2.70443199777736

Epoch: 6| Step: 1
Training loss: 3.1643204948828965
Validation loss: 2.7104702602104456

Epoch: 6| Step: 2
Training loss: 2.6172647493263663
Validation loss: 2.7087292153902762

Epoch: 6| Step: 3
Training loss: 2.793640653445954
Validation loss: 2.71518856941624

Epoch: 6| Step: 4
Training loss: 3.0672388586485106
Validation loss: 2.7140915030397528

Epoch: 6| Step: 5
Training loss: 2.9301365215797053
Validation loss: 2.71069572126858

Epoch: 6| Step: 6
Training loss: 2.826621398818222
Validation loss: 2.7140199813909454

Epoch: 6| Step: 7
Training loss: 2.827418117804762
Validation loss: 2.721819127728633

Epoch: 6| Step: 8
Training loss: 2.65225188106039
Validation loss: 2.730960168964656

Epoch: 6| Step: 9
Training loss: 3.848598492654958
Validation loss: 2.7269469622221685

Epoch: 6| Step: 10
Training loss: 2.586918025519567
Validation loss: 2.7414116718007393

Epoch: 6| Step: 11
Training loss: 2.8563115954278837
Validation loss: 2.730587922140265

Epoch: 6| Step: 12
Training loss: 3.5017913593772794
Validation loss: 2.7325692651077715

Epoch: 6| Step: 13
Training loss: 4.285122866922154
Validation loss: 2.7323746872444623

Epoch: 313| Step: 0
Training loss: 2.989103555671553
Validation loss: 2.7318110414019934

Epoch: 6| Step: 1
Training loss: 2.9899728412734343
Validation loss: 2.7163292057001156

Epoch: 6| Step: 2
Training loss: 3.2613667006866396
Validation loss: 2.7116569766955876

Epoch: 6| Step: 3
Training loss: 3.0157573453492295
Validation loss: 2.7085559996392123

Epoch: 6| Step: 4
Training loss: 3.144216125999781
Validation loss: 2.708770739980515

Epoch: 6| Step: 5
Training loss: 2.495093012205534
Validation loss: 2.7108756593768915

Epoch: 6| Step: 6
Training loss: 3.6584051578454506
Validation loss: 2.707116734234978

Epoch: 6| Step: 7
Training loss: 2.961683355515887
Validation loss: 2.705419156422389

Epoch: 6| Step: 8
Training loss: 2.5626971471358515
Validation loss: 2.7067140387657025

Epoch: 6| Step: 9
Training loss: 2.4713652074236934
Validation loss: 2.7092511012727756

Epoch: 6| Step: 10
Training loss: 3.2439879049035687
Validation loss: 2.7063180062296466

Epoch: 6| Step: 11
Training loss: 3.1201708292043833
Validation loss: 2.7082358166829343

Epoch: 6| Step: 12
Training loss: 3.2490244648424134
Validation loss: 2.7097250272691906

Epoch: 6| Step: 13
Training loss: 3.1471783791975123
Validation loss: 2.707920677862048

Epoch: 314| Step: 0
Training loss: 2.886161864047295
Validation loss: 2.7093418076961764

Epoch: 6| Step: 1
Training loss: 3.3623105020553123
Validation loss: 2.7135374335169633

Epoch: 6| Step: 2
Training loss: 2.40118092252393
Validation loss: 2.7120413154081615

Epoch: 6| Step: 3
Training loss: 2.7732452755788675
Validation loss: 2.7135637099894705

Epoch: 6| Step: 4
Training loss: 2.95773633565641
Validation loss: 2.70679803089956

Epoch: 6| Step: 5
Training loss: 3.1869687404338376
Validation loss: 2.7212064021217657

Epoch: 6| Step: 6
Training loss: 2.7147981708460307
Validation loss: 2.712995605119627

Epoch: 6| Step: 7
Training loss: 3.0061563267061984
Validation loss: 2.7223037720137966

Epoch: 6| Step: 8
Training loss: 2.5658438660059693
Validation loss: 2.7296235122448613

Epoch: 6| Step: 9
Training loss: 3.199534120025145
Validation loss: 2.723681250137054

Epoch: 6| Step: 10
Training loss: 3.6991340603343486
Validation loss: 2.7193259144418636

Epoch: 6| Step: 11
Training loss: 3.4808189138878363
Validation loss: 2.710882482502048

Epoch: 6| Step: 12
Training loss: 2.8909819511449224
Validation loss: 2.71578733769753

Epoch: 6| Step: 13
Training loss: 3.053045197208238
Validation loss: 2.7126816987516644

Epoch: 315| Step: 0
Training loss: 2.7002114707642666
Validation loss: 2.7068874339454667

Epoch: 6| Step: 1
Training loss: 2.8370258355240026
Validation loss: 2.7035091624362795

Epoch: 6| Step: 2
Training loss: 3.177199531473113
Validation loss: 2.70748665750829

Epoch: 6| Step: 3
Training loss: 2.797078812488176
Validation loss: 2.7134265410336664

Epoch: 6| Step: 4
Training loss: 3.341986360422788
Validation loss: 2.7045919343099603

Epoch: 6| Step: 5
Training loss: 3.1226233027526
Validation loss: 2.707029075617542

Epoch: 6| Step: 6
Training loss: 2.5228159230470206
Validation loss: 2.7116597921393977

Epoch: 6| Step: 7
Training loss: 3.2439895218046133
Validation loss: 2.7135972852692993

Epoch: 6| Step: 8
Training loss: 2.9316438780378355
Validation loss: 2.7050970299344734

Epoch: 6| Step: 9
Training loss: 3.3366546931958627
Validation loss: 2.712403687287499

Epoch: 6| Step: 10
Training loss: 2.679458207977792
Validation loss: 2.7110356309003065

Epoch: 6| Step: 11
Training loss: 3.468517398768044
Validation loss: 2.704006446126589

Epoch: 6| Step: 12
Training loss: 3.428279926760005
Validation loss: 2.704206316904511

Epoch: 6| Step: 13
Training loss: 2.1573261395150958
Validation loss: 2.709152564123039

Epoch: 316| Step: 0
Training loss: 2.964338377650553
Validation loss: 2.7038101379783064

Epoch: 6| Step: 1
Training loss: 2.769199281497186
Validation loss: 2.7006472213300268

Epoch: 6| Step: 2
Training loss: 3.169888329930718
Validation loss: 2.701217419287949

Epoch: 6| Step: 3
Training loss: 3.112307598494481
Validation loss: 2.6988918341005417

Epoch: 6| Step: 4
Training loss: 2.977460750702292
Validation loss: 2.7004964627659978

Epoch: 6| Step: 5
Training loss: 2.932979595645302
Validation loss: 2.7072046324382915

Epoch: 6| Step: 6
Training loss: 2.756899069138548
Validation loss: 2.7051440035945937

Epoch: 6| Step: 7
Training loss: 2.8838892634132764
Validation loss: 2.7060917531784563

Epoch: 6| Step: 8
Training loss: 2.9543751487465584
Validation loss: 2.69955020887264

Epoch: 6| Step: 9
Training loss: 2.8255211239769196
Validation loss: 2.701525754078535

Epoch: 6| Step: 10
Training loss: 3.2411395849802846
Validation loss: 2.702436743743444

Epoch: 6| Step: 11
Training loss: 3.2895475559974727
Validation loss: 2.7095986817264146

Epoch: 6| Step: 12
Training loss: 3.1933668410654312
Validation loss: 2.7081732280600526

Epoch: 6| Step: 13
Training loss: 3.3870959220392938
Validation loss: 2.714124222635326

Epoch: 317| Step: 0
Training loss: 3.8201357560725797
Validation loss: 2.707780260609022

Epoch: 6| Step: 1
Training loss: 2.5404476202385156
Validation loss: 2.716858310030944

Epoch: 6| Step: 2
Training loss: 3.0698302377987954
Validation loss: 2.7162274784809366

Epoch: 6| Step: 3
Training loss: 2.758436353974295
Validation loss: 2.7093852891175576

Epoch: 6| Step: 4
Training loss: 3.2261482323813584
Validation loss: 2.7032426501103806

Epoch: 6| Step: 5
Training loss: 2.9444258187462644
Validation loss: 2.707952254551835

Epoch: 6| Step: 6
Training loss: 3.1117860273922173
Validation loss: 2.70470340891116

Epoch: 6| Step: 7
Training loss: 2.5695917574148175
Validation loss: 2.7010296053695995

Epoch: 6| Step: 8
Training loss: 2.7590616223213646
Validation loss: 2.7010981832699104

Epoch: 6| Step: 9
Training loss: 2.4885512464511113
Validation loss: 2.7096033310198173

Epoch: 6| Step: 10
Training loss: 3.009692112583749
Validation loss: 2.70232687187772

Epoch: 6| Step: 11
Training loss: 3.3332234046611484
Validation loss: 2.704080202706256

Epoch: 6| Step: 12
Training loss: 3.2237403479583597
Validation loss: 2.7013341427132205

Epoch: 6| Step: 13
Training loss: 3.3252565442691906
Validation loss: 2.703455145929718

Epoch: 318| Step: 0
Training loss: 2.7287283004198506
Validation loss: 2.696829874642207

Epoch: 6| Step: 1
Training loss: 2.8436948330736724
Validation loss: 2.6983966641917565

Epoch: 6| Step: 2
Training loss: 3.2889972598747885
Validation loss: 2.6997475897673646

Epoch: 6| Step: 3
Training loss: 2.063833672475285
Validation loss: 2.7006737722529066

Epoch: 6| Step: 4
Training loss: 2.8411328355938843
Validation loss: 2.701353134586621

Epoch: 6| Step: 5
Training loss: 2.6271354526933126
Validation loss: 2.6990064430597753

Epoch: 6| Step: 6
Training loss: 2.971097319342781
Validation loss: 2.6953851952483143

Epoch: 6| Step: 7
Training loss: 3.099943492743557
Validation loss: 2.705467356340926

Epoch: 6| Step: 8
Training loss: 3.059214483926714
Validation loss: 2.7002656470980946

Epoch: 6| Step: 9
Training loss: 3.6196467894325024
Validation loss: 2.7011594410140036

Epoch: 6| Step: 10
Training loss: 3.1851438902445994
Validation loss: 2.7196057436461265

Epoch: 6| Step: 11
Training loss: 3.1937493788985454
Validation loss: 2.709788829804022

Epoch: 6| Step: 12
Training loss: 3.2066324522713794
Validation loss: 2.7114991209189876

Epoch: 6| Step: 13
Training loss: 3.5702938020913564
Validation loss: 2.711032849796698

Epoch: 319| Step: 0
Training loss: 3.0000796307485773
Validation loss: 2.702686275871125

Epoch: 6| Step: 1
Training loss: 2.271152777178668
Validation loss: 2.6998807743673576

Epoch: 6| Step: 2
Training loss: 3.436168204590226
Validation loss: 2.7028301893160824

Epoch: 6| Step: 3
Training loss: 2.887409793386004
Validation loss: 2.693261917443771

Epoch: 6| Step: 4
Training loss: 2.590458815597186
Validation loss: 2.693341361413799

Epoch: 6| Step: 5
Training loss: 3.277144124768081
Validation loss: 2.6987209403279926

Epoch: 6| Step: 6
Training loss: 3.518511727161062
Validation loss: 2.700493456261629

Epoch: 6| Step: 7
Training loss: 3.0011918561419972
Validation loss: 2.696898006092547

Epoch: 6| Step: 8
Training loss: 3.38817342560668
Validation loss: 2.6968190148212505

Epoch: 6| Step: 9
Training loss: 2.9108880882963275
Validation loss: 2.7037141949592782

Epoch: 6| Step: 10
Training loss: 3.17063090162369
Validation loss: 2.712425896437749

Epoch: 6| Step: 11
Training loss: 2.9144612466483975
Validation loss: 2.7079557119280158

Epoch: 6| Step: 12
Training loss: 2.966346490562961
Validation loss: 2.708243754461806

Epoch: 6| Step: 13
Training loss: 2.453627808181498
Validation loss: 2.7042547830250685

Epoch: 320| Step: 0
Training loss: 3.0905856508965
Validation loss: 2.710978409189943

Epoch: 6| Step: 1
Training loss: 1.890221418701722
Validation loss: 2.7092491775370022

Epoch: 6| Step: 2
Training loss: 2.727972764424598
Validation loss: 2.7142328849446713

Epoch: 6| Step: 3
Training loss: 3.062861207174439
Validation loss: 2.718248919198522

Epoch: 6| Step: 4
Training loss: 2.7467795501894336
Validation loss: 2.7095967213382015

Epoch: 6| Step: 5
Training loss: 2.5991683803730856
Validation loss: 2.695739021812788

Epoch: 6| Step: 6
Training loss: 2.571509549213134
Validation loss: 2.698362943476479

Epoch: 6| Step: 7
Training loss: 3.0157495976931386
Validation loss: 2.6998220191366835

Epoch: 6| Step: 8
Training loss: 3.082008352061645
Validation loss: 2.7029387602960853

Epoch: 6| Step: 9
Training loss: 3.4811071287797244
Validation loss: 2.6989233008037203

Epoch: 6| Step: 10
Training loss: 3.7150098440622594
Validation loss: 2.6972284180717816

Epoch: 6| Step: 11
Training loss: 3.2053328185670833
Validation loss: 2.698665124691548

Epoch: 6| Step: 12
Training loss: 3.032336797261539
Validation loss: 2.6995098325751945

Epoch: 6| Step: 13
Training loss: 3.9834766048272523
Validation loss: 2.698185919197073

Epoch: 321| Step: 0
Training loss: 3.266602000420374
Validation loss: 2.7001896121291598

Epoch: 6| Step: 1
Training loss: 3.545550397319728
Validation loss: 2.6899445975260465

Epoch: 6| Step: 2
Training loss: 3.0164286278934718
Validation loss: 2.691222853476827

Epoch: 6| Step: 3
Training loss: 2.866242380310924
Validation loss: 2.6937025514975828

Epoch: 6| Step: 4
Training loss: 2.353439849013525
Validation loss: 2.694515733149692

Epoch: 6| Step: 5
Training loss: 3.7774930843590395
Validation loss: 2.69724423768473

Epoch: 6| Step: 6
Training loss: 2.7642950966085427
Validation loss: 2.6969984263091415

Epoch: 6| Step: 7
Training loss: 3.0759649297949765
Validation loss: 2.699275342482381

Epoch: 6| Step: 8
Training loss: 2.937575319014444
Validation loss: 2.69439382378337

Epoch: 6| Step: 9
Training loss: 2.674861733258978
Validation loss: 2.6918753074088633

Epoch: 6| Step: 10
Training loss: 3.0902912572978685
Validation loss: 2.693348076664378

Epoch: 6| Step: 11
Training loss: 2.565455151603258
Validation loss: 2.691469403790779

Epoch: 6| Step: 12
Training loss: 2.9357916551617027
Validation loss: 2.69492689801211

Epoch: 6| Step: 13
Training loss: 3.2625536917875966
Validation loss: 2.696152470436133

Epoch: 322| Step: 0
Training loss: 3.9309683015021313
Validation loss: 2.7078434036407923

Epoch: 6| Step: 1
Training loss: 2.78093863469538
Validation loss: 2.6917099712787844

Epoch: 6| Step: 2
Training loss: 3.3145987142081723
Validation loss: 2.6990776900723548

Epoch: 6| Step: 3
Training loss: 2.4436171629722123
Validation loss: 2.690744652062988

Epoch: 6| Step: 4
Training loss: 2.8051973267367756
Validation loss: 2.6936150064507873

Epoch: 6| Step: 5
Training loss: 2.570894030612344
Validation loss: 2.690444489404792

Epoch: 6| Step: 6
Training loss: 3.2149182075786777
Validation loss: 2.69610475438365

Epoch: 6| Step: 7
Training loss: 3.1154789652217616
Validation loss: 2.6984873260116697

Epoch: 6| Step: 8
Training loss: 2.581847861005828
Validation loss: 2.7164721660968794

Epoch: 6| Step: 9
Training loss: 3.2971551423577083
Validation loss: 2.700526213403495

Epoch: 6| Step: 10
Training loss: 2.978152353615445
Validation loss: 2.696893085841205

Epoch: 6| Step: 11
Training loss: 3.0363333639838053
Validation loss: 2.7108488215846536

Epoch: 6| Step: 12
Training loss: 3.0947747893350983
Validation loss: 2.704799027758778

Epoch: 6| Step: 13
Training loss: 2.6109744897455998
Validation loss: 2.6962535478598992

Epoch: 323| Step: 0
Training loss: 3.096274530762515
Validation loss: 2.7312138646161435

Epoch: 6| Step: 1
Training loss: 3.181089050178573
Validation loss: 2.7122465110962355

Epoch: 6| Step: 2
Training loss: 3.0409563532879815
Validation loss: 2.7131505807220484

Epoch: 6| Step: 3
Training loss: 3.2247412762620393
Validation loss: 2.7068401959930917

Epoch: 6| Step: 4
Training loss: 3.4772026929868836
Validation loss: 2.7025298597308685

Epoch: 6| Step: 5
Training loss: 2.9511938491901963
Validation loss: 2.6981749242134923

Epoch: 6| Step: 6
Training loss: 2.97271014652192
Validation loss: 2.6958808003756953

Epoch: 6| Step: 7
Training loss: 2.236765829504197
Validation loss: 2.69474628119366

Epoch: 6| Step: 8
Training loss: 2.8041981559750075
Validation loss: 2.699034818611807

Epoch: 6| Step: 9
Training loss: 2.869646810670812
Validation loss: 2.6994922721897487

Epoch: 6| Step: 10
Training loss: 3.1673240146659127
Validation loss: 2.6966864756621924

Epoch: 6| Step: 11
Training loss: 2.639443398379111
Validation loss: 2.690622988208908

Epoch: 6| Step: 12
Training loss: 3.682049359771399
Validation loss: 2.692133823273165

Epoch: 6| Step: 13
Training loss: 2.220062404992654
Validation loss: 2.69293673738234

Epoch: 324| Step: 0
Training loss: 2.925804718697597
Validation loss: 2.694135144152133

Epoch: 6| Step: 1
Training loss: 2.9354328430322076
Validation loss: 2.6910984666955753

Epoch: 6| Step: 2
Training loss: 2.7760090685869443
Validation loss: 2.6882887567798925

Epoch: 6| Step: 3
Training loss: 2.8756655047191666
Validation loss: 2.6891337601643057

Epoch: 6| Step: 4
Training loss: 2.7590782135526672
Validation loss: 2.6959366803142144

Epoch: 6| Step: 5
Training loss: 3.5253987404684985
Validation loss: 2.6904290366869446

Epoch: 6| Step: 6
Training loss: 3.2107070134733857
Validation loss: 2.686412758289471

Epoch: 6| Step: 7
Training loss: 2.4662019158619244
Validation loss: 2.689322960605883

Epoch: 6| Step: 8
Training loss: 2.8489685802287066
Validation loss: 2.6902411700102986

Epoch: 6| Step: 9
Training loss: 3.026090970625305
Validation loss: 2.696339757906488

Epoch: 6| Step: 10
Training loss: 2.933976027855587
Validation loss: 2.696492589485402

Epoch: 6| Step: 11
Training loss: 3.481122196392396
Validation loss: 2.693214118766622

Epoch: 6| Step: 12
Training loss: 3.2311036893971297
Validation loss: 2.6967450539426254

Epoch: 6| Step: 13
Training loss: 3.0423846682001465
Validation loss: 2.697408849679724

Epoch: 325| Step: 0
Training loss: 2.7081240255220704
Validation loss: 2.7032583842650633

Epoch: 6| Step: 1
Training loss: 3.0275500811743075
Validation loss: 2.710222915658451

Epoch: 6| Step: 2
Training loss: 2.75254443972103
Validation loss: 2.7047700501511276

Epoch: 6| Step: 3
Training loss: 3.631923903210046
Validation loss: 2.7089249938815634

Epoch: 6| Step: 4
Training loss: 2.7754342641493523
Validation loss: 2.7066109366837097

Epoch: 6| Step: 5
Training loss: 3.05275389993956
Validation loss: 2.7056888824183

Epoch: 6| Step: 6
Training loss: 2.6871699640647004
Validation loss: 2.7022925361221315

Epoch: 6| Step: 7
Training loss: 3.2715458832837214
Validation loss: 2.6895394129073553

Epoch: 6| Step: 8
Training loss: 2.968504885543085
Validation loss: 2.694005230717764

Epoch: 6| Step: 9
Training loss: 3.369015509452233
Validation loss: 2.6900721892364534

Epoch: 6| Step: 10
Training loss: 3.2225841907189907
Validation loss: 2.687171529627398

Epoch: 6| Step: 11
Training loss: 3.299233122064215
Validation loss: 2.6911383799949733

Epoch: 6| Step: 12
Training loss: 2.106226061223672
Validation loss: 2.689996079619177

Epoch: 6| Step: 13
Training loss: 3.120168995315185
Validation loss: 2.6866136745842204

Epoch: 326| Step: 0
Training loss: 3.107849973948435
Validation loss: 2.6857522736549013

Epoch: 6| Step: 1
Training loss: 2.8229945736277875
Validation loss: 2.68844564579581

Epoch: 6| Step: 2
Training loss: 3.602221778222706
Validation loss: 2.693482940670364

Epoch: 6| Step: 3
Training loss: 2.7991675672182357
Validation loss: 2.694081552515019

Epoch: 6| Step: 4
Training loss: 2.4197851208584473
Validation loss: 2.6980625565610623

Epoch: 6| Step: 5
Training loss: 3.7231852264681677
Validation loss: 2.7028597795801805

Epoch: 6| Step: 6
Training loss: 3.431203172708131
Validation loss: 2.7050761404859816

Epoch: 6| Step: 7
Training loss: 3.2743061524587613
Validation loss: 2.6974322182257673

Epoch: 6| Step: 8
Training loss: 2.407981150746632
Validation loss: 2.694479018202639

Epoch: 6| Step: 9
Training loss: 2.3797425552381557
Validation loss: 2.695204445538279

Epoch: 6| Step: 10
Training loss: 2.994641286419155
Validation loss: 2.6945528804907815

Epoch: 6| Step: 11
Training loss: 3.152048014367086
Validation loss: 2.6968810570436537

Epoch: 6| Step: 12
Training loss: 3.127643230277923
Validation loss: 2.701195027819654

Epoch: 6| Step: 13
Training loss: 2.1628544599621184
Validation loss: 2.689789729782608

Epoch: 327| Step: 0
Training loss: 2.6504885852901108
Validation loss: 2.6864433806110912

Epoch: 6| Step: 1
Training loss: 3.410715238675175
Validation loss: 2.6904544011278824

Epoch: 6| Step: 2
Training loss: 3.2180945460511596
Validation loss: 2.684578496441637

Epoch: 6| Step: 3
Training loss: 3.240308396296993
Validation loss: 2.6844259730817543

Epoch: 6| Step: 4
Training loss: 2.6409790885123403
Validation loss: 2.683850248086011

Epoch: 6| Step: 5
Training loss: 2.797021446443125
Validation loss: 2.6824591796510506

Epoch: 6| Step: 6
Training loss: 3.0851530599106702
Validation loss: 2.6833238523429537

Epoch: 6| Step: 7
Training loss: 3.134374215001382
Validation loss: 2.6829700080943897

Epoch: 6| Step: 8
Training loss: 3.182195250969904
Validation loss: 2.682528733074546

Epoch: 6| Step: 9
Training loss: 3.17346737733466
Validation loss: 2.685447389790366

Epoch: 6| Step: 10
Training loss: 2.8878587838410166
Validation loss: 2.6840487749361395

Epoch: 6| Step: 11
Training loss: 3.171458249830813
Validation loss: 2.686522641647421

Epoch: 6| Step: 12
Training loss: 2.315339072588965
Validation loss: 2.6800569745795375

Epoch: 6| Step: 13
Training loss: 3.1031391738921323
Validation loss: 2.685968221505807

Epoch: 328| Step: 0
Training loss: 3.293687626575647
Validation loss: 2.6918733350657584

Epoch: 6| Step: 1
Training loss: 3.717825510207953
Validation loss: 2.6933620858320277

Epoch: 6| Step: 2
Training loss: 2.3592981995467985
Validation loss: 2.7002176030751026

Epoch: 6| Step: 3
Training loss: 2.448374041311293
Validation loss: 2.7040521209097763

Epoch: 6| Step: 4
Training loss: 3.671796822222946
Validation loss: 2.706665721815656

Epoch: 6| Step: 5
Training loss: 2.8356881360429993
Validation loss: 2.6962427484717355

Epoch: 6| Step: 6
Training loss: 3.354898708537034
Validation loss: 2.7085939387667617

Epoch: 6| Step: 7
Training loss: 2.722984699157247
Validation loss: 2.7082550630705158

Epoch: 6| Step: 8
Training loss: 2.9714091388098405
Validation loss: 2.712327998256597

Epoch: 6| Step: 9
Training loss: 2.7716166791997874
Validation loss: 2.704527122882089

Epoch: 6| Step: 10
Training loss: 2.9368905591826553
Validation loss: 2.722060409135966

Epoch: 6| Step: 11
Training loss: 2.971324246272907
Validation loss: 2.718590333422936

Epoch: 6| Step: 12
Training loss: 2.8082862653853597
Validation loss: 2.7019070165685646

Epoch: 6| Step: 13
Training loss: 2.853029808971744
Validation loss: 2.7022201633105953

Epoch: 329| Step: 0
Training loss: 3.1444930364525896
Validation loss: 2.7057002462375452

Epoch: 6| Step: 1
Training loss: 3.4200911379265366
Validation loss: 2.683840439494049

Epoch: 6| Step: 2
Training loss: 3.22977994612113
Validation loss: 2.693252815628229

Epoch: 6| Step: 3
Training loss: 2.691249449748024
Validation loss: 2.6890437077507388

Epoch: 6| Step: 4
Training loss: 2.70314281656204
Validation loss: 2.68560535356052

Epoch: 6| Step: 5
Training loss: 2.7921371822594363
Validation loss: 2.6878888534974337

Epoch: 6| Step: 6
Training loss: 3.036080355971739
Validation loss: 2.6894777579996587

Epoch: 6| Step: 7
Training loss: 3.482096932356376
Validation loss: 2.6850180224481397

Epoch: 6| Step: 8
Training loss: 2.768891469126942
Validation loss: 2.6891297094482622

Epoch: 6| Step: 9
Training loss: 2.685888117524332
Validation loss: 2.687285767449351

Epoch: 6| Step: 10
Training loss: 2.450564463460448
Validation loss: 2.6862229701709572

Epoch: 6| Step: 11
Training loss: 3.517724389440696
Validation loss: 2.6934938976994665

Epoch: 6| Step: 12
Training loss: 2.9645309182682937
Validation loss: 2.695844395013444

Epoch: 6| Step: 13
Training loss: 3.0244083866390072
Validation loss: 2.683375913353112

Epoch: 330| Step: 0
Training loss: 2.9587245915252223
Validation loss: 2.7043330205500316

Epoch: 6| Step: 1
Training loss: 2.8973054140199603
Validation loss: 2.691868834194334

Epoch: 6| Step: 2
Training loss: 3.1193904119809046
Validation loss: 2.704982829722665

Epoch: 6| Step: 3
Training loss: 2.7006794886884595
Validation loss: 2.7044401813353636

Epoch: 6| Step: 4
Training loss: 2.5466816834644472
Validation loss: 2.696094883401407

Epoch: 6| Step: 5
Training loss: 2.5326172703425027
Validation loss: 2.702826484463582

Epoch: 6| Step: 6
Training loss: 3.330995709588555
Validation loss: 2.7067680101270755

Epoch: 6| Step: 7
Training loss: 3.1347224247412693
Validation loss: 2.7048660068989907

Epoch: 6| Step: 8
Training loss: 2.9980341510316313
Validation loss: 2.7090773823300096

Epoch: 6| Step: 9
Training loss: 3.299566101679217
Validation loss: 2.7027914142641585

Epoch: 6| Step: 10
Training loss: 3.3793719196817036
Validation loss: 2.700664344189622

Epoch: 6| Step: 11
Training loss: 3.1377381678912757
Validation loss: 2.6897356788954405

Epoch: 6| Step: 12
Training loss: 3.091796875
Validation loss: 2.681655657056121

Epoch: 6| Step: 13
Training loss: 2.7224795312873904
Validation loss: 2.683587842410172

Epoch: 331| Step: 0
Training loss: 2.7987381680414396
Validation loss: 2.67893966858609

Epoch: 6| Step: 1
Training loss: 3.5240997571735595
Validation loss: 2.6844320755577415

Epoch: 6| Step: 2
Training loss: 2.9588978367605447
Validation loss: 2.681930748686933

Epoch: 6| Step: 3
Training loss: 2.662666021910799
Validation loss: 2.6837573527819867

Epoch: 6| Step: 4
Training loss: 3.070274605165318
Validation loss: 2.6805171982581837

Epoch: 6| Step: 5
Training loss: 3.003837197729169
Validation loss: 2.6756772012632792

Epoch: 6| Step: 6
Training loss: 3.4803598303401073
Validation loss: 2.684511427492648

Epoch: 6| Step: 7
Training loss: 2.4048118752481393
Validation loss: 2.6750178610498954

Epoch: 6| Step: 8
Training loss: 2.3559355265372175
Validation loss: 2.6862131969652414

Epoch: 6| Step: 9
Training loss: 3.1354266364022525
Validation loss: 2.681134394922369

Epoch: 6| Step: 10
Training loss: 3.0863318082736533
Validation loss: 2.6796098057635613

Epoch: 6| Step: 11
Training loss: 3.117773015381244
Validation loss: 2.6812142364750398

Epoch: 6| Step: 12
Training loss: 2.6769325619604576
Validation loss: 2.688423063084266

Epoch: 6| Step: 13
Training loss: 3.8571554743848036
Validation loss: 2.692119604879161

Epoch: 332| Step: 0
Training loss: 3.000400039703772
Validation loss: 2.693574649210439

Epoch: 6| Step: 1
Training loss: 2.5756928965323707
Validation loss: 2.688105167592775

Epoch: 6| Step: 2
Training loss: 2.751459168070344
Validation loss: 2.6801422698549717

Epoch: 6| Step: 3
Training loss: 3.059364114650419
Validation loss: 2.684694230175526

Epoch: 6| Step: 4
Training loss: 3.1931649525103505
Validation loss: 2.6865988315345404

Epoch: 6| Step: 5
Training loss: 3.060847556723943
Validation loss: 2.681372355929684

Epoch: 6| Step: 6
Training loss: 2.669016508066372
Validation loss: 2.681339876306591

Epoch: 6| Step: 7
Training loss: 3.220650121323254
Validation loss: 2.6821241715763358

Epoch: 6| Step: 8
Training loss: 2.975837038398031
Validation loss: 2.681665758045735

Epoch: 6| Step: 9
Training loss: 2.661841756197047
Validation loss: 2.6816791810414853

Epoch: 6| Step: 10
Training loss: 3.1826410096626856
Validation loss: 2.6846768307090003

Epoch: 6| Step: 11
Training loss: 3.0245657301735296
Validation loss: 2.679016153554699

Epoch: 6| Step: 12
Training loss: 3.6401531912458442
Validation loss: 2.684018525502076

Epoch: 6| Step: 13
Training loss: 2.7970368748710532
Validation loss: 2.6824445334263127

Epoch: 333| Step: 0
Training loss: 3.07785885042661
Validation loss: 2.6765820995735976

Epoch: 6| Step: 1
Training loss: 2.7645682347184093
Validation loss: 2.6716370355775862

Epoch: 6| Step: 2
Training loss: 2.437845058959683
Validation loss: 2.6739172852643613

Epoch: 6| Step: 3
Training loss: 3.31562398754108
Validation loss: 2.6787067992443507

Epoch: 6| Step: 4
Training loss: 3.2231720112850097
Validation loss: 2.6775876851718574

Epoch: 6| Step: 5
Training loss: 3.5758303818297503
Validation loss: 2.686113836169409

Epoch: 6| Step: 6
Training loss: 3.2032771376789064
Validation loss: 2.679079097995141

Epoch: 6| Step: 7
Training loss: 3.210808298894684
Validation loss: 2.6889461757708233

Epoch: 6| Step: 8
Training loss: 3.105218918065805
Validation loss: 2.6912336158534726

Epoch: 6| Step: 9
Training loss: 2.8205118293804925
Validation loss: 2.6926819564858118

Epoch: 6| Step: 10
Training loss: 2.2515549055364525
Validation loss: 2.7042933095773494

Epoch: 6| Step: 11
Training loss: 3.005066725613697
Validation loss: 2.7001526012008497

Epoch: 6| Step: 12
Training loss: 2.925508738560617
Validation loss: 2.6971975693695622

Epoch: 6| Step: 13
Training loss: 2.7601422635330604
Validation loss: 2.7005215731648144

Epoch: 334| Step: 0
Training loss: 2.290773344765877
Validation loss: 2.701760858247321

Epoch: 6| Step: 1
Training loss: 2.8522206004297117
Validation loss: 2.679824745702963

Epoch: 6| Step: 2
Training loss: 2.5674327730851147
Validation loss: 2.677820906492262

Epoch: 6| Step: 3
Training loss: 2.1307940311360456
Validation loss: 2.6776294351554863

Epoch: 6| Step: 4
Training loss: 3.2273926486741304
Validation loss: 2.679315356593643

Epoch: 6| Step: 5
Training loss: 3.164444059748156
Validation loss: 2.6787578197384234

Epoch: 6| Step: 6
Training loss: 3.351104207038794
Validation loss: 2.6749031740547355

Epoch: 6| Step: 7
Training loss: 2.9278491953906554
Validation loss: 2.6727140392912627

Epoch: 6| Step: 8
Training loss: 3.675675134211502
Validation loss: 2.677480484707786

Epoch: 6| Step: 9
Training loss: 2.359411782489565
Validation loss: 2.6799790117301803

Epoch: 6| Step: 10
Training loss: 3.4848243868350206
Validation loss: 2.673372035547971

Epoch: 6| Step: 11
Training loss: 3.685404424537408
Validation loss: 2.671506669105043

Epoch: 6| Step: 12
Training loss: 3.158344140617246
Validation loss: 2.671038418156464

Epoch: 6| Step: 13
Training loss: 2.349414440005633
Validation loss: 2.6757178274886435

Epoch: 335| Step: 0
Training loss: 3.5066315632019207
Validation loss: 2.6763499101872807

Epoch: 6| Step: 1
Training loss: 3.31813247021646
Validation loss: 2.678351017428479

Epoch: 6| Step: 2
Training loss: 2.678077147155347
Validation loss: 2.6768095060699384

Epoch: 6| Step: 3
Training loss: 2.9847357566845756
Validation loss: 2.672028255139234

Epoch: 6| Step: 4
Training loss: 3.1287462286444447
Validation loss: 2.6756105147393243

Epoch: 6| Step: 5
Training loss: 3.5959211342451516
Validation loss: 2.6729131578040306

Epoch: 6| Step: 6
Training loss: 2.965025482840173
Validation loss: 2.6774188058489106

Epoch: 6| Step: 7
Training loss: 2.8787525399942657
Validation loss: 2.67183132552115

Epoch: 6| Step: 8
Training loss: 2.7344426609932353
Validation loss: 2.6754356885098267

Epoch: 6| Step: 9
Training loss: 2.4294286264949028
Validation loss: 2.671540048441058

Epoch: 6| Step: 10
Training loss: 3.157873359407045
Validation loss: 2.672160283730608

Epoch: 6| Step: 11
Training loss: 2.81308892759813
Validation loss: 2.67550899472949

Epoch: 6| Step: 12
Training loss: 3.0396208654696295
Validation loss: 2.6779216763889164

Epoch: 6| Step: 13
Training loss: 2.2191068335486674
Validation loss: 2.676640170590972

Epoch: 336| Step: 0
Training loss: 3.3803089912525413
Validation loss: 2.6768992900888637

Epoch: 6| Step: 1
Training loss: 3.23242718560742
Validation loss: 2.676079877814185

Epoch: 6| Step: 2
Training loss: 2.9139872277895633
Validation loss: 2.671548603364158

Epoch: 6| Step: 3
Training loss: 2.7341863076635153
Validation loss: 2.6701676692859135

Epoch: 6| Step: 4
Training loss: 3.8321355247503592
Validation loss: 2.677316545284757

Epoch: 6| Step: 5
Training loss: 2.858634644429832
Validation loss: 2.6688928854684204

Epoch: 6| Step: 6
Training loss: 2.7912047464244543
Validation loss: 2.675556792553156

Epoch: 6| Step: 7
Training loss: 2.6774902232443067
Validation loss: 2.6757884749508185

Epoch: 6| Step: 8
Training loss: 2.608695758425669
Validation loss: 2.6720791441101275

Epoch: 6| Step: 9
Training loss: 3.444187110257494
Validation loss: 2.672499046425661

Epoch: 6| Step: 10
Training loss: 2.121006972643638
Validation loss: 2.67352060694763

Epoch: 6| Step: 11
Training loss: 2.937431334646677
Validation loss: 2.6656778791072395

Epoch: 6| Step: 12
Training loss: 3.3018370976782747
Validation loss: 2.6716401666745053

Epoch: 6| Step: 13
Training loss: 2.633512047445488
Validation loss: 2.6708032127520904

Epoch: 337| Step: 0
Training loss: 2.787961598311072
Validation loss: 2.666561605962935

Epoch: 6| Step: 1
Training loss: 3.3831823556471945
Validation loss: 2.682057596601206

Epoch: 6| Step: 2
Training loss: 3.5345056430406268
Validation loss: 2.6836869265619776

Epoch: 6| Step: 3
Training loss: 2.404689034801685
Validation loss: 2.676746136654317

Epoch: 6| Step: 4
Training loss: 2.6749636103926813
Validation loss: 2.6953437716569435

Epoch: 6| Step: 5
Training loss: 2.8172477491455945
Validation loss: 2.7148118606315137

Epoch: 6| Step: 6
Training loss: 2.3396080547961744
Validation loss: 2.697536250848065

Epoch: 6| Step: 7
Training loss: 3.6268177079088724
Validation loss: 2.6989799270269166

Epoch: 6| Step: 8
Training loss: 2.5646576520210864
Validation loss: 2.6896939242942115

Epoch: 6| Step: 9
Training loss: 3.322027647542994
Validation loss: 2.701720775458088

Epoch: 6| Step: 10
Training loss: 3.1425500540134568
Validation loss: 2.6903899199604475

Epoch: 6| Step: 11
Training loss: 3.7286790639106373
Validation loss: 2.6750739314608256

Epoch: 6| Step: 12
Training loss: 2.3860132951070265
Validation loss: 2.667492892978602

Epoch: 6| Step: 13
Training loss: 2.6561457894022547
Validation loss: 2.675067469340478

Epoch: 338| Step: 0
Training loss: 2.0906109408831037
Validation loss: 2.6722941669205764

Epoch: 6| Step: 1
Training loss: 2.6296336739120467
Validation loss: 2.667416548530864

Epoch: 6| Step: 2
Training loss: 3.587937406132145
Validation loss: 2.6765520032918677

Epoch: 6| Step: 3
Training loss: 3.2569843950421897
Validation loss: 2.667549263795198

Epoch: 6| Step: 4
Training loss: 3.293208248167112
Validation loss: 2.672484508691941

Epoch: 6| Step: 5
Training loss: 2.7110360866946417
Validation loss: 2.6695795845369017

Epoch: 6| Step: 6
Training loss: 2.980788387492601
Validation loss: 2.6729677934347653

Epoch: 6| Step: 7
Training loss: 3.1723851888216354
Validation loss: 2.6733458866641637

Epoch: 6| Step: 8
Training loss: 2.8431102326471462
Validation loss: 2.671175646615399

Epoch: 6| Step: 9
Training loss: 2.7932289269114277
Validation loss: 2.675891423350604

Epoch: 6| Step: 10
Training loss: 3.165595994611225
Validation loss: 2.679557865800123

Epoch: 6| Step: 11
Training loss: 3.1676905800345847
Validation loss: 2.6808321597913762

Epoch: 6| Step: 12
Training loss: 3.2833772575680573
Validation loss: 2.6797689497658377

Epoch: 6| Step: 13
Training loss: 2.4710393021042676
Validation loss: 2.6768178085532317

Epoch: 339| Step: 0
Training loss: 3.137300316280884
Validation loss: 2.7043757729456344

Epoch: 6| Step: 1
Training loss: 2.9052683495228555
Validation loss: 2.6933353923938785

Epoch: 6| Step: 2
Training loss: 2.942975075484309
Validation loss: 2.6887369307047644

Epoch: 6| Step: 3
Training loss: 2.9855667051709616
Validation loss: 2.702461084797485

Epoch: 6| Step: 4
Training loss: 2.2251624273098307
Validation loss: 2.693954872982169

Epoch: 6| Step: 5
Training loss: 3.089824150785264
Validation loss: 2.6880112677045984

Epoch: 6| Step: 6
Training loss: 3.172789042647347
Validation loss: 2.6804680733936563

Epoch: 6| Step: 7
Training loss: 3.4241033118161366
Validation loss: 2.6677347211897326

Epoch: 6| Step: 8
Training loss: 3.4135054563794713
Validation loss: 2.6655611744923955

Epoch: 6| Step: 9
Training loss: 2.613261269805206
Validation loss: 2.6642430607893006

Epoch: 6| Step: 10
Training loss: 3.236894004399176
Validation loss: 2.6621743042624586

Epoch: 6| Step: 11
Training loss: 2.579964091620326
Validation loss: 2.6667914415849867

Epoch: 6| Step: 12
Training loss: 3.239276360362936
Validation loss: 2.668588110138974

Epoch: 6| Step: 13
Training loss: 2.586833602673574
Validation loss: 2.6675235229839567

Epoch: 340| Step: 0
Training loss: 3.078297876450898
Validation loss: 2.6654993525507487

Epoch: 6| Step: 1
Training loss: 2.9595257858645643
Validation loss: 2.6686226144092595

Epoch: 6| Step: 2
Training loss: 3.0627864781506053
Validation loss: 2.6714936325877052

Epoch: 6| Step: 3
Training loss: 2.983703857371923
Validation loss: 2.6722991852272204

Epoch: 6| Step: 4
Training loss: 3.0253181227190544
Validation loss: 2.6902392946221045

Epoch: 6| Step: 5
Training loss: 2.982572800290582
Validation loss: 2.6808644131910895

Epoch: 6| Step: 6
Training loss: 2.9737541988258176
Validation loss: 2.6800639230368324

Epoch: 6| Step: 7
Training loss: 2.6218891784502842
Validation loss: 2.669756701309766

Epoch: 6| Step: 8
Training loss: 2.4054515554291167
Validation loss: 2.6793271389324764

Epoch: 6| Step: 9
Training loss: 3.3100012225468616
Validation loss: 2.670976557902107

Epoch: 6| Step: 10
Training loss: 2.7367286361790195
Validation loss: 2.6721605907350052

Epoch: 6| Step: 11
Training loss: 3.5461788082405894
Validation loss: 2.6740605180142905

Epoch: 6| Step: 12
Training loss: 3.2358881410143376
Validation loss: 2.670845104303767

Epoch: 6| Step: 13
Training loss: 2.8490917632514483
Validation loss: 2.6732772757943364

Epoch: 341| Step: 0
Training loss: 2.9645309182682937
Validation loss: 2.6764258570918043

Epoch: 6| Step: 1
Training loss: 3.336471764978834
Validation loss: 2.6695990020607057

Epoch: 6| Step: 2
Training loss: 3.1883439087546948
Validation loss: 2.676696529784499

Epoch: 6| Step: 3
Training loss: 3.616936100242146
Validation loss: 2.6738193213724046

Epoch: 6| Step: 4
Training loss: 2.973488329053534
Validation loss: 2.670818093672505

Epoch: 6| Step: 5
Training loss: 2.9900972321179675
Validation loss: 2.6786619938913403

Epoch: 6| Step: 6
Training loss: 2.717151215603318
Validation loss: 2.6737955086705374

Epoch: 6| Step: 7
Training loss: 3.0156049184179974
Validation loss: 2.669263482532639

Epoch: 6| Step: 8
Training loss: 2.957065274686598
Validation loss: 2.6783583177637795

Epoch: 6| Step: 9
Training loss: 3.219193511332197
Validation loss: 2.68825494741966

Epoch: 6| Step: 10
Training loss: 2.7888879374096764
Validation loss: 2.6710761789763375

Epoch: 6| Step: 11
Training loss: 2.281711583927246
Validation loss: 2.6659482852244705

Epoch: 6| Step: 12
Training loss: 2.74642851133451
Validation loss: 2.6721120845622233

Epoch: 6| Step: 13
Training loss: 2.882560243398866
Validation loss: 2.6787741369804627

Epoch: 342| Step: 0
Training loss: 3.240550903532643
Validation loss: 2.665224699374191

Epoch: 6| Step: 1
Training loss: 2.088842990159055
Validation loss: 2.668354683281464

Epoch: 6| Step: 2
Training loss: 2.8005505497406813
Validation loss: 2.665119394893426

Epoch: 6| Step: 3
Training loss: 2.5939911879578785
Validation loss: 2.66549395500083

Epoch: 6| Step: 4
Training loss: 3.688777637591446
Validation loss: 2.6635055231606257

Epoch: 6| Step: 5
Training loss: 2.854047471130826
Validation loss: 2.668823024704275

Epoch: 6| Step: 6
Training loss: 3.3763009848729575
Validation loss: 2.6655854627684508

Epoch: 6| Step: 7
Training loss: 2.7828878659169107
Validation loss: 2.6653170406934374

Epoch: 6| Step: 8
Training loss: 3.3013892341784414
Validation loss: 2.656726259294602

Epoch: 6| Step: 9
Training loss: 3.1004587510823436
Validation loss: 2.6625779474381623

Epoch: 6| Step: 10
Training loss: 2.432400969854562
Validation loss: 2.662630946522927

Epoch: 6| Step: 11
Training loss: 3.424430833289296
Validation loss: 2.6662599784797

Epoch: 6| Step: 12
Training loss: 2.9902834897583026
Validation loss: 2.661167181266668

Epoch: 6| Step: 13
Training loss: 2.679567295414601
Validation loss: 2.667717832867675

Epoch: 343| Step: 0
Training loss: 3.127959871459111
Validation loss: 2.666980900503292

Epoch: 6| Step: 1
Training loss: 3.0726708437769212
Validation loss: 2.6799750724904143

Epoch: 6| Step: 2
Training loss: 3.1411487655022965
Validation loss: 2.6685211965019153

Epoch: 6| Step: 3
Training loss: 3.1418973708167357
Validation loss: 2.6670883528510094

Epoch: 6| Step: 4
Training loss: 3.4161912230632203
Validation loss: 2.665150046405418

Epoch: 6| Step: 5
Training loss: 2.737724563236625
Validation loss: 2.6784505403333783

Epoch: 6| Step: 6
Training loss: 2.2913051204429893
Validation loss: 2.667074802593552

Epoch: 6| Step: 7
Training loss: 2.656316330025457
Validation loss: 2.66503474814014

Epoch: 6| Step: 8
Training loss: 3.2271905246283454
Validation loss: 2.6614656995908135

Epoch: 6| Step: 9
Training loss: 3.2507982007432523
Validation loss: 2.668873409015291

Epoch: 6| Step: 10
Training loss: 3.0575122309617124
Validation loss: 2.6704601184563637

Epoch: 6| Step: 11
Training loss: 2.767568562665423
Validation loss: 2.6722034769838596

Epoch: 6| Step: 12
Training loss: 3.1184431334071085
Validation loss: 2.6609417184551285

Epoch: 6| Step: 13
Training loss: 2.3021668178788715
Validation loss: 2.6700056985441947

Epoch: 344| Step: 0
Training loss: 3.8503165870398983
Validation loss: 2.683183709081664

Epoch: 6| Step: 1
Training loss: 2.8294900371337692
Validation loss: 2.6824754065234013

Epoch: 6| Step: 2
Training loss: 2.8071609683684944
Validation loss: 2.68053482556728

Epoch: 6| Step: 3
Training loss: 3.3155515038832295
Validation loss: 2.6868274597942485

Epoch: 6| Step: 4
Training loss: 2.443434313898757
Validation loss: 2.68779237363046

Epoch: 6| Step: 5
Training loss: 2.5939393491455998
Validation loss: 2.6792781931844916

Epoch: 6| Step: 6
Training loss: 2.610656332312454
Validation loss: 2.6670213573692063

Epoch: 6| Step: 7
Training loss: 2.85640558198865
Validation loss: 2.668650793318233

Epoch: 6| Step: 8
Training loss: 3.889756929310135
Validation loss: 2.65781861134089

Epoch: 6| Step: 9
Training loss: 2.5825998023690735
Validation loss: 2.6627490745046334

Epoch: 6| Step: 10
Training loss: 2.7611624711869562
Validation loss: 2.657342157102772

Epoch: 6| Step: 11
Training loss: 2.7016544641889477
Validation loss: 2.6609192838459523

Epoch: 6| Step: 12
Training loss: 2.9292315725964713
Validation loss: 2.6605280755932195

Epoch: 6| Step: 13
Training loss: 3.446080820651329
Validation loss: 2.6617796292383997

Epoch: 345| Step: 0
Training loss: 3.131317619157063
Validation loss: 2.6634852604025876

Epoch: 6| Step: 1
Training loss: 2.8605165964680985
Validation loss: 2.6647437334932698

Epoch: 6| Step: 2
Training loss: 3.0286999230489893
Validation loss: 2.6641917094067447

Epoch: 6| Step: 3
Training loss: 2.7627444163462695
Validation loss: 2.660948040498843

Epoch: 6| Step: 4
Training loss: 3.680347812635737
Validation loss: 2.6629337504194965

Epoch: 6| Step: 5
Training loss: 2.967400013011262
Validation loss: 2.6651759419208894

Epoch: 6| Step: 6
Training loss: 3.0051816060923344
Validation loss: 2.6652103508915626

Epoch: 6| Step: 7
Training loss: 3.3258384049110163
Validation loss: 2.6700396669741218

Epoch: 6| Step: 8
Training loss: 2.7152679770559187
Validation loss: 2.6677542972485364

Epoch: 6| Step: 9
Training loss: 2.8068830561941662
Validation loss: 2.675603470399104

Epoch: 6| Step: 10
Training loss: 3.4009885136343883
Validation loss: 2.684969087825575

Epoch: 6| Step: 11
Training loss: 2.7878063803311535
Validation loss: 2.678917233499764

Epoch: 6| Step: 12
Training loss: 2.737822359518205
Validation loss: 2.6875941848372227

Epoch: 6| Step: 13
Training loss: 1.9899538570594315
Validation loss: 2.6689726878767317

Epoch: 346| Step: 0
Training loss: 3.3530085363009197
Validation loss: 2.6729875364139803

Epoch: 6| Step: 1
Training loss: 3.158005330173664
Validation loss: 2.6595759069918423

Epoch: 6| Step: 2
Training loss: 2.8596166289748477
Validation loss: 2.6665182694039538

Epoch: 6| Step: 3
Training loss: 2.6583424124567654
Validation loss: 2.66620766691288

Epoch: 6| Step: 4
Training loss: 2.9676550201058367
Validation loss: 2.660987309668958

Epoch: 6| Step: 5
Training loss: 2.73243766818278
Validation loss: 2.6692428226436897

Epoch: 6| Step: 6
Training loss: 3.127703908345745
Validation loss: 2.6656004295605964

Epoch: 6| Step: 7
Training loss: 2.3827878856951017
Validation loss: 2.670190193248111

Epoch: 6| Step: 8
Training loss: 3.21851503570112
Validation loss: 2.6785455142680337

Epoch: 6| Step: 9
Training loss: 3.2243809009667332
Validation loss: 2.6665188289496022

Epoch: 6| Step: 10
Training loss: 3.4699405311083806
Validation loss: 2.673673540514133

Epoch: 6| Step: 11
Training loss: 3.302466401384788
Validation loss: 2.6740411472684515

Epoch: 6| Step: 12
Training loss: 1.9052229443951518
Validation loss: 2.6747097494270733

Epoch: 6| Step: 13
Training loss: 3.1937238479409484
Validation loss: 2.6793568060083337

Epoch: 347| Step: 0
Training loss: 3.4054939760909
Validation loss: 2.6801635143364644

Epoch: 6| Step: 1
Training loss: 2.922465382053611
Validation loss: 2.6780318909166025

Epoch: 6| Step: 2
Training loss: 3.094176908380716
Validation loss: 2.669222219261077

Epoch: 6| Step: 3
Training loss: 3.2420880773535994
Validation loss: 2.6752172795673324

Epoch: 6| Step: 4
Training loss: 3.423902355201103
Validation loss: 2.679700606674123

Epoch: 6| Step: 5
Training loss: 3.1153350909463713
Validation loss: 2.677900562508846

Epoch: 6| Step: 6
Training loss: 2.9380809128372243
Validation loss: 2.6884400988311596

Epoch: 6| Step: 7
Training loss: 2.8684536583455
Validation loss: 2.694304312555729

Epoch: 6| Step: 8
Training loss: 3.018423728607354
Validation loss: 2.6990963615887344

Epoch: 6| Step: 9
Training loss: 2.1995973955579156
Validation loss: 2.6995087171887966

Epoch: 6| Step: 10
Training loss: 2.6517304510584783
Validation loss: 2.6878799528563264

Epoch: 6| Step: 11
Training loss: 3.2463474289320136
Validation loss: 2.6947369008891626

Epoch: 6| Step: 12
Training loss: 2.7731480407101565
Validation loss: 2.6776894643366504

Epoch: 6| Step: 13
Training loss: 2.6185015212282776
Validation loss: 2.673471116668356

Epoch: 348| Step: 0
Training loss: 3.1831036336688414
Validation loss: 2.667771511107621

Epoch: 6| Step: 1
Training loss: 2.4623650179819006
Validation loss: 2.6584847032370287

Epoch: 6| Step: 2
Training loss: 2.5635184148369223
Validation loss: 2.658573273957807

Epoch: 6| Step: 3
Training loss: 3.0628093641078444
Validation loss: 2.6581469600847254

Epoch: 6| Step: 4
Training loss: 3.136639395692211
Validation loss: 2.6614928205482506

Epoch: 6| Step: 5
Training loss: 2.4201610776400053
Validation loss: 2.659617626447864

Epoch: 6| Step: 6
Training loss: 3.140936840764376
Validation loss: 2.657504188698601

Epoch: 6| Step: 7
Training loss: 3.5129623163136614
Validation loss: 2.657493055305594

Epoch: 6| Step: 8
Training loss: 3.054961443468893
Validation loss: 2.6605231131341847

Epoch: 6| Step: 9
Training loss: 3.1630517169247216
Validation loss: 2.6602676081828256

Epoch: 6| Step: 10
Training loss: 3.511799676660692
Validation loss: 2.665314677421925

Epoch: 6| Step: 11
Training loss: 2.8172414866525397
Validation loss: 2.6640508464610915

Epoch: 6| Step: 12
Training loss: 2.7630139110213614
Validation loss: 2.667107500150009

Epoch: 6| Step: 13
Training loss: 2.6501955931834362
Validation loss: 2.6756022458777884

Epoch: 349| Step: 0
Training loss: 2.606527545156285
Validation loss: 2.664083553225367

Epoch: 6| Step: 1
Training loss: 2.831040033971649
Validation loss: 2.680531167367421

Epoch: 6| Step: 2
Training loss: 2.347000309713739
Validation loss: 2.672993378236224

Epoch: 6| Step: 3
Training loss: 2.9707010383272587
Validation loss: 2.682434508959251

Epoch: 6| Step: 4
Training loss: 2.945454642106385
Validation loss: 2.6749861716004157

Epoch: 6| Step: 5
Training loss: 2.892689230753586
Validation loss: 2.684472880614999

Epoch: 6| Step: 6
Training loss: 3.40645801713953
Validation loss: 2.6852477323770327

Epoch: 6| Step: 7
Training loss: 3.5443128835111533
Validation loss: 2.6678700699160216

Epoch: 6| Step: 8
Training loss: 2.852926184254541
Validation loss: 2.6843735246414204

Epoch: 6| Step: 9
Training loss: 3.2573322335500445
Validation loss: 2.6609712610187706

Epoch: 6| Step: 10
Training loss: 3.015374365950851
Validation loss: 2.6619539212240557

Epoch: 6| Step: 11
Training loss: 2.986692317812757
Validation loss: 2.657698007027537

Epoch: 6| Step: 12
Training loss: 2.829883681963339
Validation loss: 2.6538679605239412

Epoch: 6| Step: 13
Training loss: 3.1913600810900817
Validation loss: 2.6558278075821353

Epoch: 350| Step: 0
Training loss: 2.6761763009583346
Validation loss: 2.659842532597526

Epoch: 6| Step: 1
Training loss: 3.1101206743188734
Validation loss: 2.655777981806681

Epoch: 6| Step: 2
Training loss: 3.1206549382545234
Validation loss: 2.655301071618359

Epoch: 6| Step: 3
Training loss: 3.6048804368338194
Validation loss: 2.65187255041333

Epoch: 6| Step: 4
Training loss: 3.0209202896406095
Validation loss: 2.6524564133229664

Epoch: 6| Step: 5
Training loss: 2.6210051520164876
Validation loss: 2.6555212228751617

Epoch: 6| Step: 6
Training loss: 2.8476416819007504
Validation loss: 2.6569532917096264

Epoch: 6| Step: 7
Training loss: 2.79171669379052
Validation loss: 2.654293277223154

Epoch: 6| Step: 8
Training loss: 3.0970971082687857
Validation loss: 2.6481358740577163

Epoch: 6| Step: 9
Training loss: 2.588853005018206
Validation loss: 2.653928093440857

Epoch: 6| Step: 10
Training loss: 2.9474363081685837
Validation loss: 2.6572914123309923

Epoch: 6| Step: 11
Training loss: 3.0789264081069048
Validation loss: 2.658900257763797

Epoch: 6| Step: 12
Training loss: 3.48597837772109
Validation loss: 2.664260281938844

Epoch: 6| Step: 13
Training loss: 2.2426788110793545
Validation loss: 2.662023376727821

Epoch: 351| Step: 0
Training loss: 2.5320851396465613
Validation loss: 2.684126993979346

Epoch: 6| Step: 1
Training loss: 2.9465371578403996
Validation loss: 2.671927328220391

Epoch: 6| Step: 2
Training loss: 3.3968530227806477
Validation loss: 2.699492236102094

Epoch: 6| Step: 3
Training loss: 2.8297264665167154
Validation loss: 2.6638926718139286

Epoch: 6| Step: 4
Training loss: 2.6875060325377427
Validation loss: 2.6655163602436986

Epoch: 6| Step: 5
Training loss: 3.2146040501465727
Validation loss: 2.6733085520436584

Epoch: 6| Step: 6
Training loss: 3.488943073502576
Validation loss: 2.6759472484040083

Epoch: 6| Step: 7
Training loss: 3.4035519054540826
Validation loss: 2.662125674874438

Epoch: 6| Step: 8
Training loss: 2.9103323863957873
Validation loss: 2.656080240788363

Epoch: 6| Step: 9
Training loss: 2.867221426698119
Validation loss: 2.6557477858719434

Epoch: 6| Step: 10
Training loss: 2.637045878144698
Validation loss: 2.65613144978585

Epoch: 6| Step: 11
Training loss: 2.664357904517612
Validation loss: 2.6533233028902887

Epoch: 6| Step: 12
Training loss: 2.4963258447333145
Validation loss: 2.651349564006899

Epoch: 6| Step: 13
Training loss: 3.669928761344324
Validation loss: 2.645782435977869

Epoch: 352| Step: 0
Training loss: 2.589487825219584
Validation loss: 2.6462332207179666

Epoch: 6| Step: 1
Training loss: 2.5354389332838645
Validation loss: 2.6448914425327716

Epoch: 6| Step: 2
Training loss: 2.9368689650599205
Validation loss: 2.6489571829123024

Epoch: 6| Step: 3
Training loss: 3.5599803379673136
Validation loss: 2.650597181110785

Epoch: 6| Step: 4
Training loss: 2.5086251246493023
Validation loss: 2.6488318866412595

Epoch: 6| Step: 5
Training loss: 2.9217113102231105
Validation loss: 2.6529281363640522

Epoch: 6| Step: 6
Training loss: 3.176994214084773
Validation loss: 2.645634113111175

Epoch: 6| Step: 7
Training loss: 3.3340570300006678
Validation loss: 2.650019406146804

Epoch: 6| Step: 8
Training loss: 2.6662225552133156
Validation loss: 2.6471783348457856

Epoch: 6| Step: 9
Training loss: 2.8467766720721697
Validation loss: 2.6491330733418597

Epoch: 6| Step: 10
Training loss: 2.736196205722188
Validation loss: 2.652227952045833

Epoch: 6| Step: 11
Training loss: 3.4785518141014764
Validation loss: 2.656008000602958

Epoch: 6| Step: 12
Training loss: 3.2857714790200045
Validation loss: 2.666208014025455

Epoch: 6| Step: 13
Training loss: 2.9213050653624157
Validation loss: 2.660305402391037

Epoch: 353| Step: 0
Training loss: 2.686818413467997
Validation loss: 2.652878445534549

Epoch: 6| Step: 1
Training loss: 2.724387101708576
Validation loss: 2.6481438230537897

Epoch: 6| Step: 2
Training loss: 2.1329579286284743
Validation loss: 2.658335790081074

Epoch: 6| Step: 3
Training loss: 3.412328493608289
Validation loss: 2.6621710416587363

Epoch: 6| Step: 4
Training loss: 3.122861664643739
Validation loss: 2.659713222752931

Epoch: 6| Step: 5
Training loss: 2.311039643935137
Validation loss: 2.6595999260501926

Epoch: 6| Step: 6
Training loss: 3.526915734431193
Validation loss: 2.6515396994205673

Epoch: 6| Step: 7
Training loss: 3.37108809204334
Validation loss: 2.6670924120514305

Epoch: 6| Step: 8
Training loss: 2.4074939633429437
Validation loss: 2.6554086026958275

Epoch: 6| Step: 9
Training loss: 3.53455259111364
Validation loss: 2.6584362165835325

Epoch: 6| Step: 10
Training loss: 2.570980275147072
Validation loss: 2.6535248783436356

Epoch: 6| Step: 11
Training loss: 2.793202295742542
Validation loss: 2.6619563905273327

Epoch: 6| Step: 12
Training loss: 3.466016912701919
Validation loss: 2.6551884276184614

Epoch: 6| Step: 13
Training loss: 3.226503237718098
Validation loss: 2.658517815988743

Epoch: 354| Step: 0
Training loss: 3.497866934232863
Validation loss: 2.653164256793578

Epoch: 6| Step: 1
Training loss: 3.095049190346031
Validation loss: 2.6513077042965856

Epoch: 6| Step: 2
Training loss: 3.1382212383599652
Validation loss: 2.653234548218012

Epoch: 6| Step: 3
Training loss: 2.471759651666045
Validation loss: 2.6481400533099966

Epoch: 6| Step: 4
Training loss: 2.9711430591922086
Validation loss: 2.642818493504449

Epoch: 6| Step: 5
Training loss: 3.2408807901870773
Validation loss: 2.649392392438064

Epoch: 6| Step: 6
Training loss: 2.5865296207415427
Validation loss: 2.6436105679793123

Epoch: 6| Step: 7
Training loss: 3.277932515416167
Validation loss: 2.647394258748519

Epoch: 6| Step: 8
Training loss: 3.2011930268329563
Validation loss: 2.654827521208415

Epoch: 6| Step: 9
Training loss: 2.5804170534624444
Validation loss: 2.6499124027632988

Epoch: 6| Step: 10
Training loss: 2.9014159987794983
Validation loss: 2.654458807576751

Epoch: 6| Step: 11
Training loss: 2.9221754276636958
Validation loss: 2.6554655969002576

Epoch: 6| Step: 12
Training loss: 2.579225062714245
Validation loss: 2.6605022350522307

Epoch: 6| Step: 13
Training loss: 3.0331867755515582
Validation loss: 2.66711689880903

Epoch: 355| Step: 0
Training loss: 3.1532926395793326
Validation loss: 2.6940618204297575

Epoch: 6| Step: 1
Training loss: 3.417798544869277
Validation loss: 2.698214039243338

Epoch: 6| Step: 2
Training loss: 2.928761246806557
Validation loss: 2.6770098876326784

Epoch: 6| Step: 3
Training loss: 2.7616638437125083
Validation loss: 2.6918734398256894

Epoch: 6| Step: 4
Training loss: 2.8591153386518626
Validation loss: 2.6905011025565564

Epoch: 6| Step: 5
Training loss: 2.915125757714163
Validation loss: 2.6767305086021773

Epoch: 6| Step: 6
Training loss: 2.4441084654943355
Validation loss: 2.660439207631804

Epoch: 6| Step: 7
Training loss: 2.4649071058059544
Validation loss: 2.651140929940741

Epoch: 6| Step: 8
Training loss: 2.789601164445779
Validation loss: 2.6544001740272365

Epoch: 6| Step: 9
Training loss: 3.5909985167910072
Validation loss: 2.6481574362955036

Epoch: 6| Step: 10
Training loss: 3.0331273508524594
Validation loss: 2.650302614636088

Epoch: 6| Step: 11
Training loss: 2.853012594158455
Validation loss: 2.6487624791524262

Epoch: 6| Step: 12
Training loss: 3.019647790947161
Validation loss: 2.645500455429771

Epoch: 6| Step: 13
Training loss: 3.4613266977923507
Validation loss: 2.653163288603094

Epoch: 356| Step: 0
Training loss: 3.015037677080316
Validation loss: 2.6458262168188478

Epoch: 6| Step: 1
Training loss: 3.4590877644592144
Validation loss: 2.653982380944164

Epoch: 6| Step: 2
Training loss: 2.7564140426709827
Validation loss: 2.6429242810800875

Epoch: 6| Step: 3
Training loss: 2.7479320900700883
Validation loss: 2.6469738974055126

Epoch: 6| Step: 4
Training loss: 3.0623713875058733
Validation loss: 2.64888948012962

Epoch: 6| Step: 5
Training loss: 2.7670505965845362
Validation loss: 2.6424373245439696

Epoch: 6| Step: 6
Training loss: 3.25414481324605
Validation loss: 2.6503030547580524

Epoch: 6| Step: 7
Training loss: 2.712022196090925
Validation loss: 2.653684559753379

Epoch: 6| Step: 8
Training loss: 2.56590881636391
Validation loss: 2.65475635939613

Epoch: 6| Step: 9
Training loss: 3.118890359353697
Validation loss: 2.655877669103113

Epoch: 6| Step: 10
Training loss: 3.066555529805846
Validation loss: 2.648856759965733

Epoch: 6| Step: 11
Training loss: 3.2703746951951325
Validation loss: 2.6439537381957248

Epoch: 6| Step: 12
Training loss: 3.143823617486549
Validation loss: 2.6502119102270645

Epoch: 6| Step: 13
Training loss: 2.225761831780643
Validation loss: 2.6454132630927

Epoch: 357| Step: 0
Training loss: 2.9270047938623978
Validation loss: 2.6519501060357356

Epoch: 6| Step: 1
Training loss: 2.4884747919480987
Validation loss: 2.6496381879876885

Epoch: 6| Step: 2
Training loss: 2.9077762984820823
Validation loss: 2.6534846234126115

Epoch: 6| Step: 3
Training loss: 3.2921875811098413
Validation loss: 2.650651192520007

Epoch: 6| Step: 4
Training loss: 2.2385969488584756
Validation loss: 2.64983753221749

Epoch: 6| Step: 5
Training loss: 3.03514179633785
Validation loss: 2.669068759779701

Epoch: 6| Step: 6
Training loss: 2.5528546679289064
Validation loss: 2.6484104883160358

Epoch: 6| Step: 7
Training loss: 3.859173603440153
Validation loss: 2.6732501526011743

Epoch: 6| Step: 8
Training loss: 3.0022674574676778
Validation loss: 2.66193589158106

Epoch: 6| Step: 9
Training loss: 2.4583080958563417
Validation loss: 2.6570183884595395

Epoch: 6| Step: 10
Training loss: 3.2265248146350225
Validation loss: 2.6505644762245533

Epoch: 6| Step: 11
Training loss: 2.886052985325537
Validation loss: 2.670055194487184

Epoch: 6| Step: 12
Training loss: 3.3991638109014817
Validation loss: 2.658020448692746

Epoch: 6| Step: 13
Training loss: 3.008419778133099
Validation loss: 2.6566916806111363

Epoch: 358| Step: 0
Training loss: 2.7236757052803076
Validation loss: 2.648920120075184

Epoch: 6| Step: 1
Training loss: 2.285250356969836
Validation loss: 2.648773914435493

Epoch: 6| Step: 2
Training loss: 2.5757011347892043
Validation loss: 2.655490480494253

Epoch: 6| Step: 3
Training loss: 2.5427648225224195
Validation loss: 2.6529269265013484

Epoch: 6| Step: 4
Training loss: 3.005881425306955
Validation loss: 2.657965918624159

Epoch: 6| Step: 5
Training loss: 3.263044149686414
Validation loss: 2.655226442811325

Epoch: 6| Step: 6
Training loss: 2.8853695494916747
Validation loss: 2.6651759255685388

Epoch: 6| Step: 7
Training loss: 3.58622763795951
Validation loss: 2.6538220383436495

Epoch: 6| Step: 8
Training loss: 3.6000647750960946
Validation loss: 2.6537821163713944

Epoch: 6| Step: 9
Training loss: 3.3154607532602
Validation loss: 2.654865656480111

Epoch: 6| Step: 10
Training loss: 2.8666901949722776
Validation loss: 2.6498206304474032

Epoch: 6| Step: 11
Training loss: 2.8348228428840327
Validation loss: 2.6432575676313257

Epoch: 6| Step: 12
Training loss: 3.0932525851409154
Validation loss: 2.6559530614586433

Epoch: 6| Step: 13
Training loss: 2.4468841864363493
Validation loss: 2.646851149489568

Epoch: 359| Step: 0
Training loss: 3.3117435959236943
Validation loss: 2.6561041640530503

Epoch: 6| Step: 1
Training loss: 2.526490717559981
Validation loss: 2.650257962673848

Epoch: 6| Step: 2
Training loss: 3.0924905082045053
Validation loss: 2.6506086384614336

Epoch: 6| Step: 3
Training loss: 3.4760408503038276
Validation loss: 2.6412273335772154

Epoch: 6| Step: 4
Training loss: 3.427163413985699
Validation loss: 2.6456837210109265

Epoch: 6| Step: 5
Training loss: 3.202569234130912
Validation loss: 2.6426863057071626

Epoch: 6| Step: 6
Training loss: 2.55179668036319
Validation loss: 2.6510132535190327

Epoch: 6| Step: 7
Training loss: 2.496757311667327
Validation loss: 2.6433433961859722

Epoch: 6| Step: 8
Training loss: 2.836686973215196
Validation loss: 2.6411569875818763

Epoch: 6| Step: 9
Training loss: 3.0925373822036732
Validation loss: 2.6471592031903555

Epoch: 6| Step: 10
Training loss: 2.5809624980580086
Validation loss: 2.6573260700374015

Epoch: 6| Step: 11
Training loss: 3.267024420267175
Validation loss: 2.6578861975992645

Epoch: 6| Step: 12
Training loss: 2.394235714072659
Validation loss: 2.668685127705766

Epoch: 6| Step: 13
Training loss: 3.0174346395902627
Validation loss: 2.6651368729837865

Epoch: 360| Step: 0
Training loss: 3.6006904257875876
Validation loss: 2.6611744719043586

Epoch: 6| Step: 1
Training loss: 3.162905785381877
Validation loss: 2.675078752884362

Epoch: 6| Step: 2
Training loss: 2.876277805477459
Validation loss: 2.671247255878038

Epoch: 6| Step: 3
Training loss: 2.3053221782343103
Validation loss: 2.664223796679418

Epoch: 6| Step: 4
Training loss: 2.8018118479834158
Validation loss: 2.657951382420592

Epoch: 6| Step: 5
Training loss: 3.2780065582377365
Validation loss: 2.647989520557029

Epoch: 6| Step: 6
Training loss: 2.8645249979263783
Validation loss: 2.65899224312634

Epoch: 6| Step: 7
Training loss: 2.6087929996004675
Validation loss: 2.648112422879723

Epoch: 6| Step: 8
Training loss: 2.5222384317393485
Validation loss: 2.6549332339030225

Epoch: 6| Step: 9
Training loss: 3.229609272474992
Validation loss: 2.648220722138867

Epoch: 6| Step: 10
Training loss: 3.1506097839145437
Validation loss: 2.6503892205250694

Epoch: 6| Step: 11
Training loss: 2.8872657846027097
Validation loss: 2.64787702153078

Epoch: 6| Step: 12
Training loss: 3.10675045410703
Validation loss: 2.6425434654730253

Epoch: 6| Step: 13
Training loss: 2.8873871686284227
Validation loss: 2.643251486966449

Epoch: 361| Step: 0
Training loss: 2.2689876463458365
Validation loss: 2.637780912387368

Epoch: 6| Step: 1
Training loss: 2.1563057270312425
Validation loss: 2.6464455445085946

Epoch: 6| Step: 2
Training loss: 2.774214600775067
Validation loss: 2.641610779201333

Epoch: 6| Step: 3
Training loss: 2.7179650236774724
Validation loss: 2.6456687025948287

Epoch: 6| Step: 4
Training loss: 3.0357145485757666
Validation loss: 2.6527396810348396

Epoch: 6| Step: 5
Training loss: 2.7421901083387703
Validation loss: 2.6500857881268365

Epoch: 6| Step: 6
Training loss: 3.4490423449015277
Validation loss: 2.6643845274492506

Epoch: 6| Step: 7
Training loss: 3.1834008281269783
Validation loss: 2.649947034113402

Epoch: 6| Step: 8
Training loss: 3.017445543456758
Validation loss: 2.650758153024402

Epoch: 6| Step: 9
Training loss: 3.290376450588059
Validation loss: 2.642790908322416

Epoch: 6| Step: 10
Training loss: 3.5277561694373687
Validation loss: 2.655425930376379

Epoch: 6| Step: 11
Training loss: 3.198614452332893
Validation loss: 2.6543752869728183

Epoch: 6| Step: 12
Training loss: 3.131805638641635
Validation loss: 2.648597106760918

Epoch: 6| Step: 13
Training loss: 2.62004038626724
Validation loss: 2.645467508256942

Epoch: 362| Step: 0
Training loss: 2.6536244599614345
Validation loss: 2.6444178059915093

Epoch: 6| Step: 1
Training loss: 3.5811954301068467
Validation loss: 2.6389333489872935

Epoch: 6| Step: 2
Training loss: 3.203514410399416
Validation loss: 2.6394749551029206

Epoch: 6| Step: 3
Training loss: 3.1191154006004944
Validation loss: 2.6458204826396243

Epoch: 6| Step: 4
Training loss: 2.27275300618255
Validation loss: 2.6401158100560758

Epoch: 6| Step: 5
Training loss: 3.001147845339746
Validation loss: 2.6436660060506134

Epoch: 6| Step: 6
Training loss: 2.853064739681432
Validation loss: 2.6479719457431816

Epoch: 6| Step: 7
Training loss: 2.7520971104876004
Validation loss: 2.65201813185468

Epoch: 6| Step: 8
Training loss: 3.1260247648384523
Validation loss: 2.652193340812989

Epoch: 6| Step: 9
Training loss: 2.8514454438731183
Validation loss: 2.6648658313733997

Epoch: 6| Step: 10
Training loss: 3.299378660257444
Validation loss: 2.6645354848038143

Epoch: 6| Step: 11
Training loss: 2.9645264145370325
Validation loss: 2.645555493416495

Epoch: 6| Step: 12
Training loss: 2.789883618268889
Validation loss: 2.6435551985688615

Epoch: 6| Step: 13
Training loss: 2.9066803316209255
Validation loss: 2.639907591892307

Epoch: 363| Step: 0
Training loss: 3.0630828925513303
Validation loss: 2.645649967003653

Epoch: 6| Step: 1
Training loss: 2.4295651322242775
Validation loss: 2.6316467111198203

Epoch: 6| Step: 2
Training loss: 3.256918073130334
Validation loss: 2.634339558280703

Epoch: 6| Step: 3
Training loss: 2.3890541251156145
Validation loss: 2.637205327636438

Epoch: 6| Step: 4
Training loss: 2.7711486828168987
Validation loss: 2.6338618770546702

Epoch: 6| Step: 5
Training loss: 3.6283804817506558
Validation loss: 2.640696585341981

Epoch: 6| Step: 6
Training loss: 2.8751847580961605
Validation loss: 2.6336677179566186

Epoch: 6| Step: 7
Training loss: 3.3356294512062328
Validation loss: 2.635593378388562

Epoch: 6| Step: 8
Training loss: 2.6295865271273926
Validation loss: 2.6392064865374567

Epoch: 6| Step: 9
Training loss: 2.83741221691246
Validation loss: 2.6407795192369274

Epoch: 6| Step: 10
Training loss: 3.1913907110239816
Validation loss: 2.6401750987477883

Epoch: 6| Step: 11
Training loss: 3.0078572059380537
Validation loss: 2.648833537772682

Epoch: 6| Step: 12
Training loss: 3.0083815791804316
Validation loss: 2.6527578794851285

Epoch: 6| Step: 13
Training loss: 2.7763022657727774
Validation loss: 2.6467785208377643

Epoch: 364| Step: 0
Training loss: 3.3127781013492736
Validation loss: 2.6629643722149035

Epoch: 6| Step: 1
Training loss: 3.3128709405458854
Validation loss: 2.642802029927969

Epoch: 6| Step: 2
Training loss: 2.9219957622520845
Validation loss: 2.647778996571601

Epoch: 6| Step: 3
Training loss: 3.061856572036745
Validation loss: 2.6535235103081956

Epoch: 6| Step: 4
Training loss: 2.489525021517894
Validation loss: 2.6536896113199164

Epoch: 6| Step: 5
Training loss: 3.0945276381219453
Validation loss: 2.6459702164137133

Epoch: 6| Step: 6
Training loss: 2.408691554723921
Validation loss: 2.638792277303511

Epoch: 6| Step: 7
Training loss: 3.058525464695116
Validation loss: 2.639395688636139

Epoch: 6| Step: 8
Training loss: 2.7142630196103
Validation loss: 2.637814533837325

Epoch: 6| Step: 9
Training loss: 2.960423085158547
Validation loss: 2.632815520499443

Epoch: 6| Step: 10
Training loss: 3.540970513234775
Validation loss: 2.6386004309889426

Epoch: 6| Step: 11
Training loss: 2.4363144167608777
Validation loss: 2.635210721712141

Epoch: 6| Step: 12
Training loss: 2.5124882636104537
Validation loss: 2.629373154934305

Epoch: 6| Step: 13
Training loss: 3.6270814378891574
Validation loss: 2.651139460107583

Epoch: 365| Step: 0
Training loss: 2.800796487466178
Validation loss: 2.6322585955490996

Epoch: 6| Step: 1
Training loss: 2.8684704480230647
Validation loss: 2.639432459792331

Epoch: 6| Step: 2
Training loss: 3.4195085817160464
Validation loss: 2.6367571082870462

Epoch: 6| Step: 3
Training loss: 3.164753854831355
Validation loss: 2.6401641262939566

Epoch: 6| Step: 4
Training loss: 2.6432719310188757
Validation loss: 2.6366545658055056

Epoch: 6| Step: 5
Training loss: 2.2480579047839755
Validation loss: 2.639548426707605

Epoch: 6| Step: 6
Training loss: 3.398668443571843
Validation loss: 2.637810950511309

Epoch: 6| Step: 7
Training loss: 3.123728684272105
Validation loss: 2.638223444208801

Epoch: 6| Step: 8
Training loss: 2.4955519206034835
Validation loss: 2.6475263547940755

Epoch: 6| Step: 9
Training loss: 3.284534082452783
Validation loss: 2.6426492829752766

Epoch: 6| Step: 10
Training loss: 3.4295855878491097
Validation loss: 2.6479126321846698

Epoch: 6| Step: 11
Training loss: 2.8300892452550674
Validation loss: 2.650361414283114

Epoch: 6| Step: 12
Training loss: 2.6008950600168808
Validation loss: 2.6601153996049773

Epoch: 6| Step: 13
Training loss: 2.8367182389923116
Validation loss: 2.651645396234893

Epoch: 366| Step: 0
Training loss: 2.39069540880027
Validation loss: 2.6380302047518494

Epoch: 6| Step: 1
Training loss: 2.6897663939623744
Validation loss: 2.645012102552022

Epoch: 6| Step: 2
Training loss: 3.2082315073739966
Validation loss: 2.642933465038757

Epoch: 6| Step: 3
Training loss: 2.991410675005705
Validation loss: 2.6600256475766058

Epoch: 6| Step: 4
Training loss: 2.760090176449858
Validation loss: 2.650118311251059

Epoch: 6| Step: 5
Training loss: 3.5398786332182404
Validation loss: 2.642388016610554

Epoch: 6| Step: 6
Training loss: 3.3239410320243348
Validation loss: 2.6458434154062287

Epoch: 6| Step: 7
Training loss: 2.7020524383245355
Validation loss: 2.636442673851075

Epoch: 6| Step: 8
Training loss: 2.3820053984983622
Validation loss: 2.6351968353452766

Epoch: 6| Step: 9
Training loss: 3.2869352950785635
Validation loss: 2.6444675927872328

Epoch: 6| Step: 10
Training loss: 3.3433669396711654
Validation loss: 2.6463883289184307

Epoch: 6| Step: 11
Training loss: 3.1620006483681755
Validation loss: 2.6443474023569156

Epoch: 6| Step: 12
Training loss: 2.6722546580992526
Validation loss: 2.6581948723925284

Epoch: 6| Step: 13
Training loss: 2.4562497010364304
Validation loss: 2.667789385996646

Epoch: 367| Step: 0
Training loss: 2.5557888818272296
Validation loss: 2.6593213724207376

Epoch: 6| Step: 1
Training loss: 3.0534384434805624
Validation loss: 2.677460717409165

Epoch: 6| Step: 2
Training loss: 2.6691337041599046
Validation loss: 2.666525999199422

Epoch: 6| Step: 3
Training loss: 3.137042379251704
Validation loss: 2.669542291355456

Epoch: 6| Step: 4
Training loss: 3.085563849511006
Validation loss: 2.6605024923314797

Epoch: 6| Step: 5
Training loss: 3.394174150970197
Validation loss: 2.651951650822167

Epoch: 6| Step: 6
Training loss: 3.1715864980498036
Validation loss: 2.661197863849899

Epoch: 6| Step: 7
Training loss: 2.7437686545882696
Validation loss: 2.6328722413689865

Epoch: 6| Step: 8
Training loss: 3.733334703672248
Validation loss: 2.628170021323801

Epoch: 6| Step: 9
Training loss: 3.1271803306938843
Validation loss: 2.6317148126752152

Epoch: 6| Step: 10
Training loss: 2.5699039586746277
Validation loss: 2.6348452944336964

Epoch: 6| Step: 11
Training loss: 2.4349670943713773
Validation loss: 2.6357933879916824

Epoch: 6| Step: 12
Training loss: 2.8224443742053444
Validation loss: 2.636952820008238

Epoch: 6| Step: 13
Training loss: 2.6280671320836775
Validation loss: 2.6345053157377736

Epoch: 368| Step: 0
Training loss: 2.6930054452120764
Validation loss: 2.6380533859932638

Epoch: 6| Step: 1
Training loss: 3.0537185888435485
Validation loss: 2.6401107286333954

Epoch: 6| Step: 2
Training loss: 3.080413277629892
Validation loss: 2.641254453664281

Epoch: 6| Step: 3
Training loss: 2.7648827370306375
Validation loss: 2.6633011492613314

Epoch: 6| Step: 4
Training loss: 3.264406405784811
Validation loss: 2.653322233306815

Epoch: 6| Step: 5
Training loss: 3.304162960042394
Validation loss: 2.651677339486631

Epoch: 6| Step: 6
Training loss: 3.4041848177914256
Validation loss: 2.6755471610020245

Epoch: 6| Step: 7
Training loss: 2.617344729127462
Validation loss: 2.672281806746033

Epoch: 6| Step: 8
Training loss: 2.4636620350331677
Validation loss: 2.646008357262491

Epoch: 6| Step: 9
Training loss: 2.3718095732700526
Validation loss: 2.657199118209347

Epoch: 6| Step: 10
Training loss: 3.1877436825223926
Validation loss: 2.6461123247617695

Epoch: 6| Step: 11
Training loss: 2.705648842660488
Validation loss: 2.6373989852396966

Epoch: 6| Step: 12
Training loss: 3.1096514861664932
Validation loss: 2.6430915855311268

Epoch: 6| Step: 13
Training loss: 3.381114366106159
Validation loss: 2.650916364797333

Epoch: 369| Step: 0
Training loss: 2.729613425303869
Validation loss: 2.63714570387086

Epoch: 6| Step: 1
Training loss: 3.4352859302549215
Validation loss: 2.6260204177668864

Epoch: 6| Step: 2
Training loss: 2.439860839002153
Validation loss: 2.6414108073141342

Epoch: 6| Step: 3
Training loss: 3.429504528682804
Validation loss: 2.638139877999794

Epoch: 6| Step: 4
Training loss: 2.5182526885508443
Validation loss: 2.6323417300378558

Epoch: 6| Step: 5
Training loss: 3.020765281875372
Validation loss: 2.635260890637162

Epoch: 6| Step: 6
Training loss: 2.8528307459031823
Validation loss: 2.637989140005261

Epoch: 6| Step: 7
Training loss: 3.589016126798938
Validation loss: 2.642434446987634

Epoch: 6| Step: 8
Training loss: 3.0919332082623434
Validation loss: 2.6299225240807624

Epoch: 6| Step: 9
Training loss: 2.6556124651391517
Validation loss: 2.6363104191955813

Epoch: 6| Step: 10
Training loss: 2.953079142542431
Validation loss: 2.633197254719005

Epoch: 6| Step: 11
Training loss: 3.3309398800209475
Validation loss: 2.632739407141338

Epoch: 6| Step: 12
Training loss: 2.4920715496390766
Validation loss: 2.635712167623418

Epoch: 6| Step: 13
Training loss: 2.173049938275861
Validation loss: 2.6484581043911914

Epoch: 370| Step: 0
Training loss: 2.381384049294522
Validation loss: 2.6550270397123406

Epoch: 6| Step: 1
Training loss: 3.1971228957432714
Validation loss: 2.6752873863691997

Epoch: 6| Step: 2
Training loss: 3.113564280970971
Validation loss: 2.6729922522645833

Epoch: 6| Step: 3
Training loss: 2.6188342023982503
Validation loss: 2.696244849782383

Epoch: 6| Step: 4
Training loss: 2.402477924352678
Validation loss: 2.6864605233857244

Epoch: 6| Step: 5
Training loss: 3.2431764128604046
Validation loss: 2.706129587594166

Epoch: 6| Step: 6
Training loss: 2.8249905746437762
Validation loss: 2.7438633297205297

Epoch: 6| Step: 7
Training loss: 3.595163614637813
Validation loss: 2.72211909215623

Epoch: 6| Step: 8
Training loss: 3.527104738233989
Validation loss: 2.7190863967321115

Epoch: 6| Step: 9
Training loss: 2.5570286280790198
Validation loss: 2.680420568781931

Epoch: 6| Step: 10
Training loss: 3.1201589089053283
Validation loss: 2.6406817239900575

Epoch: 6| Step: 11
Training loss: 2.9644104411005006
Validation loss: 2.6369781563423316

Epoch: 6| Step: 12
Training loss: 2.824893770499293
Validation loss: 2.6313515966783054

Epoch: 6| Step: 13
Training loss: 2.7888545965929272
Validation loss: 2.631145000966621

Epoch: 371| Step: 0
Training loss: 3.0020184084780874
Validation loss: 2.6340136765862736

Epoch: 6| Step: 1
Training loss: 3.215085360044969
Validation loss: 2.6335629807641183

Epoch: 6| Step: 2
Training loss: 3.0455599563451172
Validation loss: 2.6400259083110185

Epoch: 6| Step: 3
Training loss: 2.5181812070101532
Validation loss: 2.637561068819049

Epoch: 6| Step: 4
Training loss: 3.060678680055119
Validation loss: 2.636789265931258

Epoch: 6| Step: 5
Training loss: 2.834834617352352
Validation loss: 2.632746260413356

Epoch: 6| Step: 6
Training loss: 2.368848966680003
Validation loss: 2.6322920216538703

Epoch: 6| Step: 7
Training loss: 2.739033420232115
Validation loss: 2.6290460676840524

Epoch: 6| Step: 8
Training loss: 3.4804734081232858
Validation loss: 2.6311374468658886

Epoch: 6| Step: 9
Training loss: 3.2964083806895457
Validation loss: 2.62921008003722

Epoch: 6| Step: 10
Training loss: 3.1386834211439774
Validation loss: 2.648277249553181

Epoch: 6| Step: 11
Training loss: 3.0296777796872174
Validation loss: 2.6554930996539396

Epoch: 6| Step: 12
Training loss: 3.139722400227173
Validation loss: 2.6583884581011294

Epoch: 6| Step: 13
Training loss: 2.4377495075562163
Validation loss: 2.6523236764743903

Epoch: 372| Step: 0
Training loss: 2.987433020188045
Validation loss: 2.650175815840021

Epoch: 6| Step: 1
Training loss: 2.9794619398354016
Validation loss: 2.6576636599566026

Epoch: 6| Step: 2
Training loss: 2.9794853057831867
Validation loss: 2.653196321864629

Epoch: 6| Step: 3
Training loss: 2.9163035757128117
Validation loss: 2.651342269075425

Epoch: 6| Step: 4
Training loss: 2.6751672638980057
Validation loss: 2.6408807589761425

Epoch: 6| Step: 5
Training loss: 3.474880403066096
Validation loss: 2.6485489492016625

Epoch: 6| Step: 6
Training loss: 2.480760259845234
Validation loss: 2.6556992560062955

Epoch: 6| Step: 7
Training loss: 3.3325866021753336
Validation loss: 2.6489185454544466

Epoch: 6| Step: 8
Training loss: 2.851610993273453
Validation loss: 2.6396699243593

Epoch: 6| Step: 9
Training loss: 2.688637780933949
Validation loss: 2.641118491298216

Epoch: 6| Step: 10
Training loss: 3.1270990569964465
Validation loss: 2.632050322684277

Epoch: 6| Step: 11
Training loss: 2.7342098513185418
Validation loss: 2.6279497093294335

Epoch: 6| Step: 12
Training loss: 2.729924443774861
Validation loss: 2.6401267089124785

Epoch: 6| Step: 13
Training loss: 3.4718987547356224
Validation loss: 2.647898395145111

Epoch: 373| Step: 0
Training loss: 2.155388922766894
Validation loss: 2.6422198729668485

Epoch: 6| Step: 1
Training loss: 3.0231461889799256
Validation loss: 2.643648135816932

Epoch: 6| Step: 2
Training loss: 2.978650739763255
Validation loss: 2.651358715397289

Epoch: 6| Step: 3
Training loss: 2.537380753144033
Validation loss: 2.646174191768853

Epoch: 6| Step: 4
Training loss: 3.0124029626690167
Validation loss: 2.6783565709304096

Epoch: 6| Step: 5
Training loss: 3.356858557400006
Validation loss: 2.651879389041555

Epoch: 6| Step: 6
Training loss: 3.359066687341852
Validation loss: 2.646650494486597

Epoch: 6| Step: 7
Training loss: 3.2404983716482985
Validation loss: 2.6352238540580384

Epoch: 6| Step: 8
Training loss: 3.526101063500871
Validation loss: 2.631663232793688

Epoch: 6| Step: 9
Training loss: 2.5602610040768465
Validation loss: 2.6298079614903056

Epoch: 6| Step: 10
Training loss: 2.9985290736000225
Validation loss: 2.627853088253932

Epoch: 6| Step: 11
Training loss: 2.9805967370947193
Validation loss: 2.62530439831779

Epoch: 6| Step: 12
Training loss: 2.858569756193714
Validation loss: 2.6344454415920064

Epoch: 6| Step: 13
Training loss: 2.0127149763261896
Validation loss: 2.6393561361003184

Epoch: 374| Step: 0
Training loss: 2.7480761994815097
Validation loss: 2.6443632358489415

Epoch: 6| Step: 1
Training loss: 2.801748366820301
Validation loss: 2.634572844212448

Epoch: 6| Step: 2
Training loss: 3.2856532026027088
Validation loss: 2.6473972974722266

Epoch: 6| Step: 3
Training loss: 3.016475577299983
Validation loss: 2.632071119641737

Epoch: 6| Step: 4
Training loss: 3.2059572677382144
Validation loss: 2.642016093983959

Epoch: 6| Step: 5
Training loss: 2.4515988407395546
Validation loss: 2.6397173533306897

Epoch: 6| Step: 6
Training loss: 3.590788309153346
Validation loss: 2.6410738655797212

Epoch: 6| Step: 7
Training loss: 2.8941773727252658
Validation loss: 2.6461658144535067

Epoch: 6| Step: 8
Training loss: 3.2749247302076103
Validation loss: 2.642400901784136

Epoch: 6| Step: 9
Training loss: 2.746739795816198
Validation loss: 2.638744593677946

Epoch: 6| Step: 10
Training loss: 2.4234894324517535
Validation loss: 2.629061062092146

Epoch: 6| Step: 11
Training loss: 2.610526099401329
Validation loss: 2.6279308971646542

Epoch: 6| Step: 12
Training loss: 3.4251480126245974
Validation loss: 2.6470655485702212

Epoch: 6| Step: 13
Training loss: 2.2481964088109234
Validation loss: 2.658059328063259

Epoch: 375| Step: 0
Training loss: 3.132627714800489
Validation loss: 2.66111309332088

Epoch: 6| Step: 1
Training loss: 3.077918495958142
Validation loss: 2.659950174038794

Epoch: 6| Step: 2
Training loss: 3.0105834879516706
Validation loss: 2.683048886347435

Epoch: 6| Step: 3
Training loss: 3.351297577033275
Validation loss: 2.6634001160561454

Epoch: 6| Step: 4
Training loss: 1.9229550311999528
Validation loss: 2.6527586622737216

Epoch: 6| Step: 5
Training loss: 2.8948261146833896
Validation loss: 2.6665840334804973

Epoch: 6| Step: 6
Training loss: 3.4514114478073554
Validation loss: 2.660885624833351

Epoch: 6| Step: 7
Training loss: 2.989089996004039
Validation loss: 2.655940221762544

Epoch: 6| Step: 8
Training loss: 3.2704309754616117
Validation loss: 2.663983286687142

Epoch: 6| Step: 9
Training loss: 2.6645559262279677
Validation loss: 2.65581319210535

Epoch: 6| Step: 10
Training loss: 2.8711495530291304
Validation loss: 2.6630039803611347

Epoch: 6| Step: 11
Training loss: 2.2724390098520386
Validation loss: 2.661819582954697

Epoch: 6| Step: 12
Training loss: 3.0257442851311653
Validation loss: 2.67453817797765

Epoch: 6| Step: 13
Training loss: 3.03693729416037
Validation loss: 2.6875985526472874

Epoch: 376| Step: 0
Training loss: 2.6717919230790996
Validation loss: 2.6756483844572303

Epoch: 6| Step: 1
Training loss: 3.3386048277753573
Validation loss: 2.6743961920495294

Epoch: 6| Step: 2
Training loss: 2.5831651837988936
Validation loss: 2.6822819898466435

Epoch: 6| Step: 3
Training loss: 2.2579031005421797
Validation loss: 2.6503588848456476

Epoch: 6| Step: 4
Training loss: 3.0796758936987985
Validation loss: 2.6612259277478216

Epoch: 6| Step: 5
Training loss: 2.6622055607279465
Validation loss: 2.6731063901916197

Epoch: 6| Step: 6
Training loss: 3.663428408285976
Validation loss: 2.666756152246162

Epoch: 6| Step: 7
Training loss: 2.9837228751577696
Validation loss: 2.6571945586052306

Epoch: 6| Step: 8
Training loss: 2.471804503775089
Validation loss: 2.6455433688002414

Epoch: 6| Step: 9
Training loss: 3.062032858584437
Validation loss: 2.6340000661621565

Epoch: 6| Step: 10
Training loss: 3.3524013794368503
Validation loss: 2.6428527298875935

Epoch: 6| Step: 11
Training loss: 2.9836234699296327
Validation loss: 2.636421960969953

Epoch: 6| Step: 12
Training loss: 3.117635670809423
Validation loss: 2.6234554731535638

Epoch: 6| Step: 13
Training loss: 2.8074992332559354
Validation loss: 2.622368446196742

Epoch: 377| Step: 0
Training loss: 3.420846723622465
Validation loss: 2.624950042225784

Epoch: 6| Step: 1
Training loss: 3.359713657076142
Validation loss: 2.62767912663256

Epoch: 6| Step: 2
Training loss: 2.7366657361932334
Validation loss: 2.6295465647884244

Epoch: 6| Step: 3
Training loss: 2.7923001002495265
Validation loss: 2.623568031473008

Epoch: 6| Step: 4
Training loss: 2.6101372798902833
Validation loss: 2.632833553841164

Epoch: 6| Step: 5
Training loss: 2.7592750539856232
Validation loss: 2.6275433077247805

Epoch: 6| Step: 6
Training loss: 2.386131901243994
Validation loss: 2.6371235733060368

Epoch: 6| Step: 7
Training loss: 2.3791425615771966
Validation loss: 2.6465818550893156

Epoch: 6| Step: 8
Training loss: 3.6742706924585673
Validation loss: 2.6457815232233424

Epoch: 6| Step: 9
Training loss: 2.5686703337778423
Validation loss: 2.656203963612481

Epoch: 6| Step: 10
Training loss: 3.1824423363579055
Validation loss: 2.667257056298982

Epoch: 6| Step: 11
Training loss: 2.968018773022118
Validation loss: 2.639427665526192

Epoch: 6| Step: 12
Training loss: 3.0807169733695634
Validation loss: 2.644611355187584

Epoch: 6| Step: 13
Training loss: 3.2793085076476225
Validation loss: 2.6309122023216465

Epoch: 378| Step: 0
Training loss: 2.9628276981719974
Validation loss: 2.6212461647403376

Epoch: 6| Step: 1
Training loss: 2.9015785327770396
Validation loss: 2.6269183046968774

Epoch: 6| Step: 2
Training loss: 2.508143988356112
Validation loss: 2.6263533198137554

Epoch: 6| Step: 3
Training loss: 3.258618591257807
Validation loss: 2.623263167807316

Epoch: 6| Step: 4
Training loss: 2.959134723129609
Validation loss: 2.6209974865294416

Epoch: 6| Step: 5
Training loss: 2.69136000816362
Validation loss: 2.6157396798480526

Epoch: 6| Step: 6
Training loss: 2.643869066375398
Validation loss: 2.6280336834582285

Epoch: 6| Step: 7
Training loss: 2.945691962044556
Validation loss: 2.6304764896731427

Epoch: 6| Step: 8
Training loss: 3.3420288790191868
Validation loss: 2.636935392326732

Epoch: 6| Step: 9
Training loss: 3.6648021350027484
Validation loss: 2.634080485774705

Epoch: 6| Step: 10
Training loss: 2.6207568070034806
Validation loss: 2.634247289175924

Epoch: 6| Step: 11
Training loss: 2.564055645158846
Validation loss: 2.6445574385386488

Epoch: 6| Step: 12
Training loss: 2.947747071760443
Validation loss: 2.6298289925932328

Epoch: 6| Step: 13
Training loss: 3.1215644261904814
Validation loss: 2.623112302049737

Epoch: 379| Step: 0
Training loss: 2.991507749312506
Validation loss: 2.6397579677648357

Epoch: 6| Step: 1
Training loss: 3.2848601326858033
Validation loss: 2.631204942907852

Epoch: 6| Step: 2
Training loss: 3.0812495295464273
Validation loss: 2.6293447764111324

Epoch: 6| Step: 3
Training loss: 2.452900481427967
Validation loss: 2.6323828039983654

Epoch: 6| Step: 4
Training loss: 3.178560474309522
Validation loss: 2.6366448534018385

Epoch: 6| Step: 5
Training loss: 2.811661319723813
Validation loss: 2.635285722782919

Epoch: 6| Step: 6
Training loss: 2.826400399607704
Validation loss: 2.6349987428393677

Epoch: 6| Step: 7
Training loss: 2.8888597201643567
Validation loss: 2.631196565674702

Epoch: 6| Step: 8
Training loss: 2.485272515319564
Validation loss: 2.624346912121201

Epoch: 6| Step: 9
Training loss: 3.1296526034195584
Validation loss: 2.6313381459052807

Epoch: 6| Step: 10
Training loss: 3.4592790957340545
Validation loss: 2.6371868517430035

Epoch: 6| Step: 11
Training loss: 2.826715613457214
Validation loss: 2.627738811537998

Epoch: 6| Step: 12
Training loss: 2.889301223753673
Validation loss: 2.6329400006219283

Epoch: 6| Step: 13
Training loss: 2.6376571680761907
Validation loss: 2.6267730449888242

Epoch: 380| Step: 0
Training loss: 3.186552617520777
Validation loss: 2.627784109072924

Epoch: 6| Step: 1
Training loss: 2.3185136288984145
Validation loss: 2.6382832379596164

Epoch: 6| Step: 2
Training loss: 2.627079911699923
Validation loss: 2.6296618835856114

Epoch: 6| Step: 3
Training loss: 3.0857248740039793
Validation loss: 2.6424154527087746

Epoch: 6| Step: 4
Training loss: 3.2785524451439056
Validation loss: 2.6270327210351936

Epoch: 6| Step: 5
Training loss: 3.0978175694910854
Validation loss: 2.6437030232716308

Epoch: 6| Step: 6
Training loss: 2.9320306385099615
Validation loss: 2.640743005655426

Epoch: 6| Step: 7
Training loss: 3.3783994437927034
Validation loss: 2.6428174672015357

Epoch: 6| Step: 8
Training loss: 3.040207203529566
Validation loss: 2.6576365616593365

Epoch: 6| Step: 9
Training loss: 3.3796284339318174
Validation loss: 2.6570051998075646

Epoch: 6| Step: 10
Training loss: 2.262381501018859
Validation loss: 2.6482047887660167

Epoch: 6| Step: 11
Training loss: 2.7007560271965922
Validation loss: 2.6402058835199402

Epoch: 6| Step: 12
Training loss: 2.7762622471264016
Validation loss: 2.6459006282460775

Epoch: 6| Step: 13
Training loss: 2.8656745265728514
Validation loss: 2.648746874242568

Epoch: 381| Step: 0
Training loss: 2.8850360348465807
Validation loss: 2.642104019425168

Epoch: 6| Step: 1
Training loss: 2.958293287695693
Validation loss: 2.6403129593748447

Epoch: 6| Step: 2
Training loss: 3.299832576781743
Validation loss: 2.6464829074241183

Epoch: 6| Step: 3
Training loss: 2.779745573709818
Validation loss: 2.633106373884174

Epoch: 6| Step: 4
Training loss: 3.1698248490522993
Validation loss: 2.640198322329982

Epoch: 6| Step: 5
Training loss: 2.793963744587051
Validation loss: 2.6469999039106176

Epoch: 6| Step: 6
Training loss: 2.96113815231652
Validation loss: 2.638129664775143

Epoch: 6| Step: 7
Training loss: 2.883616430978347
Validation loss: 2.6478162515957298

Epoch: 6| Step: 8
Training loss: 3.5686640366657936
Validation loss: 2.649219641984097

Epoch: 6| Step: 9
Training loss: 2.4572187149023206
Validation loss: 2.649923234239035

Epoch: 6| Step: 10
Training loss: 2.9128029072299393
Validation loss: 2.6457478150362657

Epoch: 6| Step: 11
Training loss: 2.9946517955901073
Validation loss: 2.6299434840827316

Epoch: 6| Step: 12
Training loss: 2.57958554598414
Validation loss: 2.628321921348851

Epoch: 6| Step: 13
Training loss: 2.666253852680497
Validation loss: 2.6268539112936398

Epoch: 382| Step: 0
Training loss: 2.5798359135634703
Validation loss: 2.631899495995133

Epoch: 6| Step: 1
Training loss: 3.0222944913276684
Validation loss: 2.6212761233883435

Epoch: 6| Step: 2
Training loss: 2.775486149174197
Validation loss: 2.617172662860981

Epoch: 6| Step: 3
Training loss: 2.4102715908255083
Validation loss: 2.629293989536671

Epoch: 6| Step: 4
Training loss: 3.1111089577743103
Validation loss: 2.624848253480532

Epoch: 6| Step: 5
Training loss: 2.885300800370416
Validation loss: 2.6223016886085864

Epoch: 6| Step: 6
Training loss: 2.9372918887176276
Validation loss: 2.6309112327632933

Epoch: 6| Step: 7
Training loss: 2.7263184358944033
Validation loss: 2.6442832995944534

Epoch: 6| Step: 8
Training loss: 3.050671525415584
Validation loss: 2.6393309197259303

Epoch: 6| Step: 9
Training loss: 3.275982798101515
Validation loss: 2.6331953455186596

Epoch: 6| Step: 10
Training loss: 3.432514250990366
Validation loss: 2.631422579884803

Epoch: 6| Step: 11
Training loss: 3.1186336518565607
Validation loss: 2.63396101755847

Epoch: 6| Step: 12
Training loss: 2.8342831833340294
Validation loss: 2.633893440304487

Epoch: 6| Step: 13
Training loss: 2.8861537685022003
Validation loss: 2.6392602133241363

Epoch: 383| Step: 0
Training loss: 3.1251045209571373
Validation loss: 2.636673396429561

Epoch: 6| Step: 1
Training loss: 2.932131142341466
Validation loss: 2.6426713662959678

Epoch: 6| Step: 2
Training loss: 3.3073203418519848
Validation loss: 2.6385313072079115

Epoch: 6| Step: 3
Training loss: 3.3692354492996452
Validation loss: 2.6259723225915304

Epoch: 6| Step: 4
Training loss: 3.371054144103958
Validation loss: 2.6285898943193025

Epoch: 6| Step: 5
Training loss: 3.2321501372751382
Validation loss: 2.630056728760457

Epoch: 6| Step: 6
Training loss: 2.8679682113077503
Validation loss: 2.6270257055012833

Epoch: 6| Step: 7
Training loss: 2.7195214240409786
Validation loss: 2.626930320095781

Epoch: 6| Step: 8
Training loss: 2.3753087696336728
Validation loss: 2.6127826971651227

Epoch: 6| Step: 9
Training loss: 2.9748781900552674
Validation loss: 2.615783568553444

Epoch: 6| Step: 10
Training loss: 3.070665800233896
Validation loss: 2.6183748224017447

Epoch: 6| Step: 11
Training loss: 2.897483319027982
Validation loss: 2.6155641333444124

Epoch: 6| Step: 12
Training loss: 2.309682418328363
Validation loss: 2.6152411408275476

Epoch: 6| Step: 13
Training loss: 1.8010658817049696
Validation loss: 2.620737969618413

Epoch: 384| Step: 0
Training loss: 2.269554886555326
Validation loss: 2.633628088157422

Epoch: 6| Step: 1
Training loss: 3.1568977522195345
Validation loss: 2.642911660359854

Epoch: 6| Step: 2
Training loss: 2.5571480663456567
Validation loss: 2.6544776461425057

Epoch: 6| Step: 3
Training loss: 2.6456471375157187
Validation loss: 2.654693024628655

Epoch: 6| Step: 4
Training loss: 2.5494998441383028
Validation loss: 2.6556856254347663

Epoch: 6| Step: 5
Training loss: 2.3857218007213272
Validation loss: 2.6434105747460177

Epoch: 6| Step: 6
Training loss: 3.088797564570631
Validation loss: 2.6346761040824096

Epoch: 6| Step: 7
Training loss: 3.081718399936761
Validation loss: 2.6463948068203167

Epoch: 6| Step: 8
Training loss: 3.4542172460837044
Validation loss: 2.6381039906333164

Epoch: 6| Step: 9
Training loss: 3.029496777233242
Validation loss: 2.640037295982934

Epoch: 6| Step: 10
Training loss: 3.3864112371202837
Validation loss: 2.6403442629685485

Epoch: 6| Step: 11
Training loss: 3.037060389476339
Validation loss: 2.6311574637726225

Epoch: 6| Step: 12
Training loss: 3.313388345467651
Validation loss: 2.620744604830563

Epoch: 6| Step: 13
Training loss: 2.9190732201086473
Validation loss: 2.631573212767928

Epoch: 385| Step: 0
Training loss: 3.1053830692779285
Validation loss: 2.631681764026521

Epoch: 6| Step: 1
Training loss: 2.8922917689854386
Validation loss: 2.649187974893823

Epoch: 6| Step: 2
Training loss: 2.676901389345302
Validation loss: 2.6254952486524497

Epoch: 6| Step: 3
Training loss: 3.026587292082731
Validation loss: 2.636944281178121

Epoch: 6| Step: 4
Training loss: 2.507247528418805
Validation loss: 2.644933829781068

Epoch: 6| Step: 5
Training loss: 2.0513485078561353
Validation loss: 2.646128388931061

Epoch: 6| Step: 6
Training loss: 3.335833581382354
Validation loss: 2.655610605841661

Epoch: 6| Step: 7
Training loss: 2.651512588813501
Validation loss: 2.6349330943045377

Epoch: 6| Step: 8
Training loss: 3.0524997535599243
Validation loss: 2.6468032894805016

Epoch: 6| Step: 9
Training loss: 3.3868161795746334
Validation loss: 2.6317509118538336

Epoch: 6| Step: 10
Training loss: 2.5401592057562805
Validation loss: 2.6402218884689406

Epoch: 6| Step: 11
Training loss: 3.0382756879328428
Validation loss: 2.6357693922315044

Epoch: 6| Step: 12
Training loss: 3.1324144524342317
Validation loss: 2.6289859653531513

Epoch: 6| Step: 13
Training loss: 3.7725581374596064
Validation loss: 2.6288309528230003

Epoch: 386| Step: 0
Training loss: 3.1354415402529434
Validation loss: 2.618000685001492

Epoch: 6| Step: 1
Training loss: 3.4445373632005176
Validation loss: 2.616256316550481

Epoch: 6| Step: 2
Training loss: 3.392930613704628
Validation loss: 2.618829603407497

Epoch: 6| Step: 3
Training loss: 3.3208558838452373
Validation loss: 2.6266025157823836

Epoch: 6| Step: 4
Training loss: 3.1796848006553344
Validation loss: 2.623076628364295

Epoch: 6| Step: 5
Training loss: 2.4215822104393863
Validation loss: 2.6217758176182486

Epoch: 6| Step: 6
Training loss: 2.2510497505387645
Validation loss: 2.6160331020456704

Epoch: 6| Step: 7
Training loss: 3.0378836181528426
Validation loss: 2.612033212375558

Epoch: 6| Step: 8
Training loss: 3.2591468036241085
Validation loss: 2.616914137166011

Epoch: 6| Step: 9
Training loss: 2.889251217576381
Validation loss: 2.627745986630602

Epoch: 6| Step: 10
Training loss: 1.8328038520316277
Validation loss: 2.6516151580734095

Epoch: 6| Step: 11
Training loss: 2.7235990230178144
Validation loss: 2.6371720386607636

Epoch: 6| Step: 12
Training loss: 2.812036094553253
Validation loss: 2.641197760416596

Epoch: 6| Step: 13
Training loss: 3.0987857717131995
Validation loss: 2.6444769633337075

Epoch: 387| Step: 0
Training loss: 2.404533269247885
Validation loss: 2.6335335162290376

Epoch: 6| Step: 1
Training loss: 2.697353662687971
Validation loss: 2.6410944478227734

Epoch: 6| Step: 2
Training loss: 3.1531358217747427
Validation loss: 2.63828514639322

Epoch: 6| Step: 3
Training loss: 2.700729102132509
Validation loss: 2.6426157521402716

Epoch: 6| Step: 4
Training loss: 3.495827776632034
Validation loss: 2.647786676505635

Epoch: 6| Step: 5
Training loss: 3.184412938604195
Validation loss: 2.645773130130333

Epoch: 6| Step: 6
Training loss: 2.1686392632172105
Validation loss: 2.645601423424148

Epoch: 6| Step: 7
Training loss: 2.6885904273471906
Validation loss: 2.631002081265253

Epoch: 6| Step: 8
Training loss: 2.773764061842727
Validation loss: 2.631146411816515

Epoch: 6| Step: 9
Training loss: 3.185890539402246
Validation loss: 2.6266808097222896

Epoch: 6| Step: 10
Training loss: 3.0487532084105227
Validation loss: 2.6339153488396576

Epoch: 6| Step: 11
Training loss: 3.5878656393727186
Validation loss: 2.6184387761794223

Epoch: 6| Step: 12
Training loss: 3.0310384145609954
Validation loss: 2.628070542377782

Epoch: 6| Step: 13
Training loss: 2.4453128900009675
Validation loss: 2.633922509539991

Epoch: 388| Step: 0
Training loss: 2.2754094855709748
Validation loss: 2.618886244437717

Epoch: 6| Step: 1
Training loss: 2.970948058093847
Validation loss: 2.6273463828166013

Epoch: 6| Step: 2
Training loss: 3.339429541886184
Validation loss: 2.624636887194804

Epoch: 6| Step: 3
Training loss: 2.640676464053326
Validation loss: 2.63081614512424

Epoch: 6| Step: 4
Training loss: 3.166177226607134
Validation loss: 2.6187609543364316

Epoch: 6| Step: 5
Training loss: 2.8794368839755506
Validation loss: 2.609549699475979

Epoch: 6| Step: 6
Training loss: 2.8828373109323584
Validation loss: 2.613186509736222

Epoch: 6| Step: 7
Training loss: 3.0729735978019868
Validation loss: 2.607765144739973

Epoch: 6| Step: 8
Training loss: 2.5537505225182446
Validation loss: 2.61383024975396

Epoch: 6| Step: 9
Training loss: 2.8542584778064306
Validation loss: 2.6120476360661065

Epoch: 6| Step: 10
Training loss: 3.38717743298523
Validation loss: 2.6142747215868956

Epoch: 6| Step: 11
Training loss: 3.352020161288134
Validation loss: 2.621631954928068

Epoch: 6| Step: 12
Training loss: 2.5599945659877803
Validation loss: 2.6100567865313438

Epoch: 6| Step: 13
Training loss: 2.9881788049228963
Validation loss: 2.6183140971769716

Epoch: 389| Step: 0
Training loss: 3.3993477139550015
Validation loss: 2.62232598846572

Epoch: 6| Step: 1
Training loss: 2.58577614825402
Validation loss: 2.624131484338047

Epoch: 6| Step: 2
Training loss: 2.9715092735806956
Validation loss: 2.6357522271193408

Epoch: 6| Step: 3
Training loss: 3.2408947676935873
Validation loss: 2.625321340742269

Epoch: 6| Step: 4
Training loss: 2.6535165522526167
Validation loss: 2.6354917536381794

Epoch: 6| Step: 5
Training loss: 2.537475653470505
Validation loss: 2.6406064558024247

Epoch: 6| Step: 6
Training loss: 2.8069318117258764
Validation loss: 2.6460927242310963

Epoch: 6| Step: 7
Training loss: 3.37558034922764
Validation loss: 2.637270473424307

Epoch: 6| Step: 8
Training loss: 3.2387474101861207
Validation loss: 2.643285368588542

Epoch: 6| Step: 9
Training loss: 2.6518317783275953
Validation loss: 2.6453870413552223

Epoch: 6| Step: 10
Training loss: 2.8290253781380126
Validation loss: 2.634283705942825

Epoch: 6| Step: 11
Training loss: 2.7382418946663667
Validation loss: 2.6434826558650877

Epoch: 6| Step: 12
Training loss: 3.127756657669315
Validation loss: 2.665329958335045

Epoch: 6| Step: 13
Training loss: 2.535655391323869
Validation loss: 2.6631185174936527

Epoch: 390| Step: 0
Training loss: 2.917822327316909
Validation loss: 2.6770138341086778

Epoch: 6| Step: 1
Training loss: 2.8880263736397676
Validation loss: 2.712617308373479

Epoch: 6| Step: 2
Training loss: 3.486651442465966
Validation loss: 2.728172478742358

Epoch: 6| Step: 3
Training loss: 3.5513712746343282
Validation loss: 2.7274253131866404

Epoch: 6| Step: 4
Training loss: 2.3694374797917943
Validation loss: 2.7041867250601457

Epoch: 6| Step: 5
Training loss: 2.3882424443429997
Validation loss: 2.7037889361223755

Epoch: 6| Step: 6
Training loss: 2.9529777369036223
Validation loss: 2.663754239518234

Epoch: 6| Step: 7
Training loss: 3.121975770532499
Validation loss: 2.630873599006631

Epoch: 6| Step: 8
Training loss: 3.2357640623789017
Validation loss: 2.6107262638543376

Epoch: 6| Step: 9
Training loss: 3.095480078715515
Validation loss: 2.6054106630825036

Epoch: 6| Step: 10
Training loss: 2.8972089688111833
Validation loss: 2.598867979819154

Epoch: 6| Step: 11
Training loss: 2.527020818487955
Validation loss: 2.607637421880681

Epoch: 6| Step: 12
Training loss: 3.128532244442528
Validation loss: 2.6026131542266784

Epoch: 6| Step: 13
Training loss: 2.046866846432353
Validation loss: 2.6048333867920723

Epoch: 391| Step: 0
Training loss: 3.2566988937621093
Validation loss: 2.6062004925281546

Epoch: 6| Step: 1
Training loss: 2.664319783872815
Validation loss: 2.609353033774913

Epoch: 6| Step: 2
Training loss: 2.863506729802809
Validation loss: 2.6058851954910187

Epoch: 6| Step: 3
Training loss: 2.9961130074450377
Validation loss: 2.608048372278768

Epoch: 6| Step: 4
Training loss: 3.062491592084281
Validation loss: 2.6053035107032585

Epoch: 6| Step: 5
Training loss: 2.4954871453955585
Validation loss: 2.604608816368849

Epoch: 6| Step: 6
Training loss: 3.256667121046406
Validation loss: 2.603645402155097

Epoch: 6| Step: 7
Training loss: 2.987014003152529
Validation loss: 2.6036017342071136

Epoch: 6| Step: 8
Training loss: 3.3581704042603753
Validation loss: 2.6057321606840174

Epoch: 6| Step: 9
Training loss: 3.006381558971682
Validation loss: 2.6085092661810205

Epoch: 6| Step: 10
Training loss: 2.5889130497988813
Validation loss: 2.6133457139528486

Epoch: 6| Step: 11
Training loss: 2.5897468099963894
Validation loss: 2.6192492520430597

Epoch: 6| Step: 12
Training loss: 3.4465158311709114
Validation loss: 2.631323911744214

Epoch: 6| Step: 13
Training loss: 2.262607011319221
Validation loss: 2.629125305878049

Epoch: 392| Step: 0
Training loss: 3.075051724378792
Validation loss: 2.6318505663176683

Epoch: 6| Step: 1
Training loss: 3.171325936737106
Validation loss: 2.652446507485568

Epoch: 6| Step: 2
Training loss: 2.20021384240283
Validation loss: 2.6404847031781213

Epoch: 6| Step: 3
Training loss: 2.9174660450088012
Validation loss: 2.638285029788355

Epoch: 6| Step: 4
Training loss: 2.3938202292396547
Validation loss: 2.6615667458121113

Epoch: 6| Step: 5
Training loss: 2.9508905585951766
Validation loss: 2.6589641797568637

Epoch: 6| Step: 6
Training loss: 3.4378021107476697
Validation loss: 2.6690058270755195

Epoch: 6| Step: 7
Training loss: 2.5519737272016325
Validation loss: 2.6536669241172453

Epoch: 6| Step: 8
Training loss: 3.2193040093230336
Validation loss: 2.63204041796838

Epoch: 6| Step: 9
Training loss: 3.1606191477646903
Validation loss: 2.622768076332408

Epoch: 6| Step: 10
Training loss: 3.2567813256759326
Validation loss: 2.610932605730205

Epoch: 6| Step: 11
Training loss: 2.9630311192073417
Validation loss: 2.61261425056009

Epoch: 6| Step: 12
Training loss: 2.9724101742967264
Validation loss: 2.6131997233313067

Epoch: 6| Step: 13
Training loss: 2.3146790213137987
Validation loss: 2.598336165394381

Epoch: 393| Step: 0
Training loss: 2.741447414068485
Validation loss: 2.5899307176239232

Epoch: 6| Step: 1
Training loss: 3.0341597287221735
Validation loss: 2.5994481203849227

Epoch: 6| Step: 2
Training loss: 2.4425415329149778
Validation loss: 2.599112178618774

Epoch: 6| Step: 3
Training loss: 2.7674514859986177
Validation loss: 2.5975546036771044

Epoch: 6| Step: 4
Training loss: 3.0280398645233486
Validation loss: 2.5958294440628973

Epoch: 6| Step: 5
Training loss: 2.613284716867562
Validation loss: 2.596343354941048

Epoch: 6| Step: 6
Training loss: 2.931293342448835
Validation loss: 2.6000720970942317

Epoch: 6| Step: 7
Training loss: 2.9066237342650276
Validation loss: 2.6022999671726033

Epoch: 6| Step: 8
Training loss: 3.013138294265813
Validation loss: 2.6033112950155246

Epoch: 6| Step: 9
Training loss: 3.1084315723375324
Validation loss: 2.6163516266520745

Epoch: 6| Step: 10
Training loss: 3.23857794531012
Validation loss: 2.6223226019848114

Epoch: 6| Step: 11
Training loss: 3.361662613641366
Validation loss: 2.631544794647387

Epoch: 6| Step: 12
Training loss: 2.8283406380907663
Validation loss: 2.6435593976698075

Epoch: 6| Step: 13
Training loss: 3.2072410375487856
Validation loss: 2.638268001535922

Epoch: 394| Step: 0
Training loss: 3.0913673242254105
Validation loss: 2.628795372345119

Epoch: 6| Step: 1
Training loss: 2.2121225153569632
Validation loss: 2.62339979463947

Epoch: 6| Step: 2
Training loss: 3.1844063499936506
Validation loss: 2.612080400200041

Epoch: 6| Step: 3
Training loss: 2.956510026718316
Validation loss: 2.6195954795498175

Epoch: 6| Step: 4
Training loss: 3.0412944060759246
Validation loss: 2.604117625769442

Epoch: 6| Step: 5
Training loss: 3.0218413326435343
Validation loss: 2.601769695747843

Epoch: 6| Step: 6
Training loss: 3.045464135236406
Validation loss: 2.599584610336931

Epoch: 6| Step: 7
Training loss: 2.6923693524101338
Validation loss: 2.6049522255287934

Epoch: 6| Step: 8
Training loss: 3.3641598713519323
Validation loss: 2.597368820637792

Epoch: 6| Step: 9
Training loss: 2.5313574685724474
Validation loss: 2.596678635063119

Epoch: 6| Step: 10
Training loss: 2.9578696590488693
Validation loss: 2.6005845278149557

Epoch: 6| Step: 11
Training loss: 2.586747241518565
Validation loss: 2.6019739664883432

Epoch: 6| Step: 12
Training loss: 3.0970464541554388
Validation loss: 2.6044891252943447

Epoch: 6| Step: 13
Training loss: 3.284978727971476
Validation loss: 2.606792352541327

Epoch: 395| Step: 0
Training loss: 2.692457638746447
Validation loss: 2.609703245708498

Epoch: 6| Step: 1
Training loss: 3.4720624624162397
Validation loss: 2.635950525593988

Epoch: 6| Step: 2
Training loss: 2.3031176376742697
Validation loss: 2.6477796936920996

Epoch: 6| Step: 3
Training loss: 2.5992612082542514
Validation loss: 2.6553793100854657

Epoch: 6| Step: 4
Training loss: 2.807660835258548
Validation loss: 2.6490119022973504

Epoch: 6| Step: 5
Training loss: 2.436350233385339
Validation loss: 2.655800853688319

Epoch: 6| Step: 6
Training loss: 2.573011841860525
Validation loss: 2.641548074524193

Epoch: 6| Step: 7
Training loss: 2.6530728356363316
Validation loss: 2.6550468649239947

Epoch: 6| Step: 8
Training loss: 3.591945825571813
Validation loss: 2.627792595719068

Epoch: 6| Step: 9
Training loss: 2.941180581482651
Validation loss: 2.6355237798402453

Epoch: 6| Step: 10
Training loss: 3.2412603684276804
Validation loss: 2.6410630424626445

Epoch: 6| Step: 11
Training loss: 3.1788901939183485
Validation loss: 2.6326091613954175

Epoch: 6| Step: 12
Training loss: 3.0973449781540787
Validation loss: 2.630321153681977

Epoch: 6| Step: 13
Training loss: 3.3115401406796385
Validation loss: 2.635358535869331

Epoch: 396| Step: 0
Training loss: 3.154539041110388
Validation loss: 2.6131098275773623

Epoch: 6| Step: 1
Training loss: 2.422205945445366
Validation loss: 2.609953370844473

Epoch: 6| Step: 2
Training loss: 2.960749718340495
Validation loss: 2.61045398623774

Epoch: 6| Step: 3
Training loss: 2.6254283010659587
Validation loss: 2.602304066354257

Epoch: 6| Step: 4
Training loss: 2.615408677210528
Validation loss: 2.6057376387359326

Epoch: 6| Step: 5
Training loss: 2.9971283838358236
Validation loss: 2.6024320913542773

Epoch: 6| Step: 6
Training loss: 2.906736271692674
Validation loss: 2.598803739746109

Epoch: 6| Step: 7
Training loss: 3.2062913085180087
Validation loss: 2.6011724746610003

Epoch: 6| Step: 8
Training loss: 3.726238500557514
Validation loss: 2.6103251790844233

Epoch: 6| Step: 9
Training loss: 2.5633158431760688
Validation loss: 2.6106259434466867

Epoch: 6| Step: 10
Training loss: 3.220958063458389
Validation loss: 2.618743562221776

Epoch: 6| Step: 11
Training loss: 2.8199514226584763
Validation loss: 2.6124953884455575

Epoch: 6| Step: 12
Training loss: 3.0611354356904314
Validation loss: 2.6110101009890236

Epoch: 6| Step: 13
Training loss: 2.208225595497238
Validation loss: 2.6206147265229043

Epoch: 397| Step: 0
Training loss: 2.912001630195748
Validation loss: 2.6082860314970446

Epoch: 6| Step: 1
Training loss: 3.500937063933392
Validation loss: 2.6110628360389527

Epoch: 6| Step: 2
Training loss: 2.054451700466765
Validation loss: 2.6069764737639023

Epoch: 6| Step: 3
Training loss: 3.3013833123256595
Validation loss: 2.6241047324280253

Epoch: 6| Step: 4
Training loss: 2.7042692551944314
Validation loss: 2.607418085709788

Epoch: 6| Step: 5
Training loss: 2.950614063555378
Validation loss: 2.6278428194401338

Epoch: 6| Step: 6
Training loss: 2.9525859683939495
Validation loss: 2.6545052769560322

Epoch: 6| Step: 7
Training loss: 3.125605562664908
Validation loss: 2.6551001379293204

Epoch: 6| Step: 8
Training loss: 3.1259073084721605
Validation loss: 2.6699144594181776

Epoch: 6| Step: 9
Training loss: 2.8258107870138627
Validation loss: 2.6628696560750673

Epoch: 6| Step: 10
Training loss: 3.185343293234177
Validation loss: 2.642704702408915

Epoch: 6| Step: 11
Training loss: 2.9288390698567137
Validation loss: 2.6316941181092495

Epoch: 6| Step: 12
Training loss: 2.537513800522432
Validation loss: 2.6403612855982743

Epoch: 6| Step: 13
Training loss: 2.5419058035828805
Validation loss: 2.617083735238751

Epoch: 398| Step: 0
Training loss: 1.871626680489949
Validation loss: 2.6023777687553724

Epoch: 6| Step: 1
Training loss: 2.4018625661392647
Validation loss: 2.602465237591235

Epoch: 6| Step: 2
Training loss: 2.9531046548778344
Validation loss: 2.603502758100089

Epoch: 6| Step: 3
Training loss: 2.712749128723145
Validation loss: 2.5952264838620915

Epoch: 6| Step: 4
Training loss: 2.8790635954924038
Validation loss: 2.5936139680545747

Epoch: 6| Step: 5
Training loss: 3.2134385218623778
Validation loss: 2.5929658759377348

Epoch: 6| Step: 6
Training loss: 3.0509262929669716
Validation loss: 2.591754583138948

Epoch: 6| Step: 7
Training loss: 3.623930016816642
Validation loss: 2.5992118002785696

Epoch: 6| Step: 8
Training loss: 3.2498892251723155
Validation loss: 2.590478100782808

Epoch: 6| Step: 9
Training loss: 2.5107908062435795
Validation loss: 2.589808869280495

Epoch: 6| Step: 10
Training loss: 2.8027684013613974
Validation loss: 2.588528150251365

Epoch: 6| Step: 11
Training loss: 3.0148757240911053
Validation loss: 2.5963652673251705

Epoch: 6| Step: 12
Training loss: 3.2593304141863757
Validation loss: 2.599037713861066

Epoch: 6| Step: 13
Training loss: 3.117377942226476
Validation loss: 2.590804850382494

Epoch: 399| Step: 0
Training loss: 2.812734297423998
Validation loss: 2.595027483956738

Epoch: 6| Step: 1
Training loss: 3.2750068489760205
Validation loss: 2.6013270638065404

Epoch: 6| Step: 2
Training loss: 2.9024442960797203
Validation loss: 2.5903813215888065

Epoch: 6| Step: 3
Training loss: 3.2650832315442027
Validation loss: 2.5935940251436564

Epoch: 6| Step: 4
Training loss: 2.2464808387575954
Validation loss: 2.604448096706587

Epoch: 6| Step: 5
Training loss: 2.7725714392440226
Validation loss: 2.6058446424178845

Epoch: 6| Step: 6
Training loss: 3.397175311137842
Validation loss: 2.60869288001122

Epoch: 6| Step: 7
Training loss: 3.1620933904591357
Validation loss: 2.6173194456504274

Epoch: 6| Step: 8
Training loss: 2.4804735559131594
Validation loss: 2.604308194816413

Epoch: 6| Step: 9
Training loss: 2.9182893507987435
Validation loss: 2.596975537644972

Epoch: 6| Step: 10
Training loss: 3.3475189358871513
Validation loss: 2.6029339819222725

Epoch: 6| Step: 11
Training loss: 2.549949615579137
Validation loss: 2.5939021643491795

Epoch: 6| Step: 12
Training loss: 2.7932617033861176
Validation loss: 2.5981058545063753

Epoch: 6| Step: 13
Training loss: 2.759839401824814
Validation loss: 2.6014955376454756

Epoch: 400| Step: 0
Training loss: 2.2610080373183363
Validation loss: 2.6129990193885493

Epoch: 6| Step: 1
Training loss: 3.6370630480315356
Validation loss: 2.618024089617576

Epoch: 6| Step: 2
Training loss: 2.708753426078316
Validation loss: 2.6163299071348596

Epoch: 6| Step: 3
Training loss: 2.9281933038616614
Validation loss: 2.620452477201203

Epoch: 6| Step: 4
Training loss: 2.87797657669853
Validation loss: 2.6307123634328184

Epoch: 6| Step: 5
Training loss: 3.236490046445338
Validation loss: 2.6269235511936064

Epoch: 6| Step: 6
Training loss: 1.9322623553113636
Validation loss: 2.6297768054358484

Epoch: 6| Step: 7
Training loss: 2.763898666296384
Validation loss: 2.6382573340435456

Epoch: 6| Step: 8
Training loss: 3.0954626718031757
Validation loss: 2.6274821153092187

Epoch: 6| Step: 9
Training loss: 2.884284245973733
Validation loss: 2.6248218770883853

Epoch: 6| Step: 10
Training loss: 2.993320818183184
Validation loss: 2.628903017296692

Epoch: 6| Step: 11
Training loss: 2.4267481843999144
Validation loss: 2.635058789749825

Epoch: 6| Step: 12
Training loss: 3.635507810191565
Validation loss: 2.621351497722764

Epoch: 6| Step: 13
Training loss: 3.034773833192175
Validation loss: 2.6553107553672044

Testing loss: 2.8167857278493282
